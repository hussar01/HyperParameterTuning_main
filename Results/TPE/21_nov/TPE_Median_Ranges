EPOCHS = 24
CLASSES = 10
INNER_FOLD = 2
NUM_SAMPLES = 24
DIR = os.getcwd()

#---------PRUNER SETTINGS--------------
N_STARTUP_TRIALS_PRUNNER = 8 #The pruner will not prune any trials until n trials have been completed  unlike asha pruning start from 1 or 2 trials
N_WARMUP_STEPS = 8           #Each trial must reach at least n epochs before it becomes eligible for pruning.
INTERVAL_STEPS = 1           #The pruner will check for pruning opportunities after every epoch following the warm-up period

N_MIN_TRIALS = 8             #At least n trials must have reported intermediate results at the same step, but since n_start_up trial have this covered
                             #Ensures that the median is calculated from a minimum of n data points at each epoch.
#---------TPE SETTINGS-----------------
N_STARTUP_TRIALS = 8  

----------------------------------------------------------------------------------------------------------------------------------
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  2
  Number of complete trials:  22
Best hyperparameters found:
{'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16}
Best trial:
  Value:  0.06275290202573758
----------------------------------------**STATS for Epoch 24**-----------------------------------------------------
Average training loss: 0.0001
Using best hyperparameters {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16} on final Test set to find Test loss for overfitting
Testing loss : 0.0434
Calculated Overfitting : 0.0433
Using best hyperparameters {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9864
Total time taken for hyperparameter tuning and evaluation: 3:43:3


--------------------------------------------------------------------------------------------
[I 2024-11-21 17:31:08,636] A new study created in RDB with name: MedianPruner_ranges_21_nov

Selected Hyperparameters for Trial 1:
  l1: 256, l2: 64, lr: 4.207988669606632e-05, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3119720458984374
[Epoch 1, Batch 200] loss: 2.305656387805939
[Epoch 1, Batch 300] loss: 2.308618576526642
[Epoch 1, Batch 400] loss: 2.3058917784690856
**STATS for Epoch 1** : 
Average training loss: 0.3392
Average validation loss: 2.3058
Validation Accuracy: 0.0769
Overfitting: 1.9666
Best model saved at epoch 1 with validation loss: 2.3058
[Epoch 2, Batch 100] loss: 2.303876097202301
[Epoch 2, Batch 200] loss: 2.3032843041419984
[Epoch 2, Batch 300] loss: 2.3050038504600523
[Epoch 2, Batch 400] loss: 2.302710769176483
**STATS for Epoch 2** : 
Average training loss: 0.3383
Average validation loss: 2.3011
Validation Accuracy: 0.0947
Overfitting: 1.9628
Best model saved at epoch 2 with validation loss: 2.3011
[Epoch 3, Batch 100] loss: 2.301134617328644
[Epoch 3, Batch 200] loss: 2.3003925895690918
[Epoch 3, Batch 300] loss: 2.2978447222709657
[Epoch 3, Batch 400] loss: 2.296111958026886
**STATS for Epoch 3** : 
Average training loss: 0.3378
Average validation loss: 2.2965
Validation Accuracy: 0.1214
Overfitting: 1.9586
Best model saved at epoch 3 with validation loss: 2.2965
[Epoch 4, Batch 100] loss: 2.2958958292007448
[Epoch 4, Batch 200] loss: 2.2958715057373045
[Epoch 4, Batch 300] loss: 2.2934538650512697
[Epoch 4, Batch 400] loss: 2.291327202320099
**STATS for Epoch 4** : 
Average training loss: 0.3372
Average validation loss: 2.2918
Validation Accuracy: 0.1379
Overfitting: 1.9545
Best model saved at epoch 4 with validation loss: 2.2918
[Epoch 5, Batch 100] loss: 2.2915960597991942
[Epoch 5, Batch 200] loss: 2.2915806722640992
[Epoch 5, Batch 300] loss: 2.2883694553375244
[Epoch 5, Batch 400] loss: 2.287725958824158
**STATS for Epoch 5** : 
Average training loss: 0.3362
Average validation loss: 2.2870
Validation Accuracy: 0.1445
Overfitting: 1.9507
Best model saved at epoch 5 with validation loss: 2.2870
[Epoch 6, Batch 100] loss: 2.285492784976959
[Epoch 6, Batch 200] loss: 2.2854769372940065
[Epoch 6, Batch 300] loss: 2.284030520915985
[Epoch 6, Batch 400] loss: 2.2833236503601073
**STATS for Epoch 6** : 
Average training loss: 0.3357
Average validation loss: 2.2816
Validation Accuracy: 0.1439
Overfitting: 1.9460
Best model saved at epoch 6 with validation loss: 2.2816
[Epoch 7, Batch 100] loss: 2.2813954591751098
[Epoch 7, Batch 200] loss: 2.2797146129608152
[Epoch 7, Batch 300] loss: 2.2782287573814393
[Epoch 7, Batch 400] loss: 2.2759554386138916
**STATS for Epoch 7** : 
Average training loss: 0.3349
Average validation loss: 2.2755
Validation Accuracy: 0.1436
Overfitting: 1.9406
Best model saved at epoch 7 with validation loss: 2.2755
[Epoch 8, Batch 100] loss: 2.2760666942596437
[Epoch 8, Batch 200] loss: 2.27111287355423
[Epoch 8, Batch 300] loss: 2.271959671974182
[Epoch 8, Batch 400] loss: 2.2702406311035155
**STATS for Epoch 8** : 
Average training loss: 0.3337
Average validation loss: 2.2680
Validation Accuracy: 0.1491
Overfitting: 1.9343
Best model saved at epoch 8 with validation loss: 2.2680
[Epoch 9, Batch 100] loss: 2.2656831622123716
[Epoch 9, Batch 200] loss: 2.2646284675598145
[Epoch 9, Batch 300] loss: 2.263620436191559
[Epoch 9, Batch 400] loss: 2.2618396353721617
**STATS for Epoch 9** : 
Average training loss: 0.3325
Average validation loss: 2.2587
Validation Accuracy: 0.1687
Overfitting: 1.9261
Best model saved at epoch 9 with validation loss: 2.2587
[Epoch 10, Batch 100] loss: 2.2573806858062744
[Epoch 10, Batch 200] loss: 2.254539315700531
[Epoch 10, Batch 300] loss: 2.2519798350334166
[Epoch 10, Batch 400] loss: 2.2501866817474365
**STATS for Epoch 10** : 
Average training loss: 0.3308
Average validation loss: 2.2465
Validation Accuracy: 0.1956
Overfitting: 1.9157
Best model saved at epoch 10 with validation loss: 2.2465
[Epoch 11, Batch 100] loss: 2.2448198413848877
[Epoch 11, Batch 200] loss: 2.240606715679169
[Epoch 11, Batch 300] loss: 2.239861228466034
[Epoch 11, Batch 400] loss: 2.234649772644043
**STATS for Epoch 11** : 
Average training loss: 0.3280
Average validation loss: 2.2298
Validation Accuracy: 0.2342
Overfitting: 1.9017
Best model saved at epoch 11 with validation loss: 2.2298
[Epoch 12, Batch 100] loss: 2.2279412865638735
[Epoch 12, Batch 200] loss: 2.222934489250183
[Epoch 12, Batch 300] loss: 2.2165995764732362
[Epoch 12, Batch 400] loss: 2.2124153542518616
**STATS for Epoch 12** : 
Average training loss: 0.3251
Average validation loss: 2.2060
Validation Accuracy: 0.3266
Overfitting: 1.8809
Best model saved at epoch 12 with validation loss: 2.2060
[Epoch 13, Batch 100] loss: 2.203295836448669
[Epoch 13, Batch 200] loss: 2.1954687547683718
[Epoch 13, Batch 300] loss: 2.187138080596924
[Epoch 13, Batch 400] loss: 2.181972839832306
**STATS for Epoch 13** : 
Average training loss: 0.3199
Average validation loss: 2.1702
Validation Accuracy: 0.4128
Overfitting: 1.8503
Best model saved at epoch 13 with validation loss: 2.1702
[Epoch 14, Batch 100] loss: 2.1658444929122926
[Epoch 14, Batch 200] loss: 2.154087383747101
[Epoch 14, Batch 300] loss: 2.144106583595276
[Epoch 14, Batch 400] loss: 2.13104318857193
**STATS for Epoch 14** : 
Average training loss: 0.3119
Average validation loss: 2.1153
Validation Accuracy: 0.5001
Overfitting: 1.8034
Best model saved at epoch 14 with validation loss: 2.1153
[Epoch 15, Batch 100] loss: 2.1059568428993227
[Epoch 15, Batch 200] loss: 2.0924674534797667
[Epoch 15, Batch 300] loss: 2.0761186933517455
[Epoch 15, Batch 400] loss: 2.0567944252491
**STATS for Epoch 15** : 
Average training loss: 0.2995
Average validation loss: 2.0295
Validation Accuracy: 0.5307
Overfitting: 1.7300
Best model saved at epoch 15 with validation loss: 2.0295
[Epoch 16, Batch 100] loss: 2.0138134598731994
[Epoch 16, Batch 200] loss: 1.9917342340946198
[Epoch 16, Batch 300] loss: 1.9661227667331695
[Epoch 16, Batch 400] loss: 1.937332513332367
**STATS for Epoch 16** : 
Average training loss: 0.2799
Average validation loss: 1.8913
Validation Accuracy: 0.5726
Overfitting: 1.6114
Best model saved at epoch 16 with validation loss: 1.8913
[Epoch 17, Batch 100] loss: 1.8718367648124694
[Epoch 17, Batch 200] loss: 1.8288651382923127
[Epoch 17, Batch 300] loss: 1.7979404497146607
[Epoch 17, Batch 400] loss: 1.7404116094112396
**STATS for Epoch 17** : 
Average training loss: 0.2512
Average validation loss: 1.6843
Validation Accuracy: 0.6159
Overfitting: 1.4330
Best model saved at epoch 17 with validation loss: 1.6843
[Epoch 18, Batch 100] loss: 1.6595752131938935
[Epoch 18, Batch 200] loss: 1.6008327400684357
[Epoch 18, Batch 300] loss: 1.554827437400818
[Epoch 18, Batch 400] loss: 1.4891447401046753
**STATS for Epoch 18** : 
Average training loss: 0.2128
Average validation loss: 1.4202
Validation Accuracy: 0.6706
Overfitting: 1.2075
Best model saved at epoch 18 with validation loss: 1.4202
[Epoch 19, Batch 100] loss: 1.385447074174881
[Epoch 19, Batch 200] loss: 1.3355412101745605
[Epoch 19, Batch 300] loss: 1.271271755695343
[Epoch 19, Batch 400] loss: 1.2123380613327026
**STATS for Epoch 19** : 
Average training loss: 0.1709
Average validation loss: 1.1378
Validation Accuracy: 0.7285
Overfitting: 0.9670
Best model saved at epoch 19 with validation loss: 1.1378
[Epoch 20, Batch 100] loss: 1.1122548866271973
[Epoch 20, Batch 200] loss: 1.0593185967206955
[Epoch 20, Batch 300] loss: 1.0118996715545654
[Epoch 20, Batch 400] loss: 0.9659648990631103
**STATS for Epoch 20** : 
Average training loss: 0.1385
Average validation loss: 0.9154
Validation Accuracy: 0.7748
Overfitting: 0.7769
Best model saved at epoch 20 with validation loss: 0.9154
[Epoch 21, Batch 100] loss: 0.9135636675357819
[Epoch 21, Batch 200] loss: 0.8556099343299866
[Epoch 21, Batch 300] loss: 0.8338196855783463
[Epoch 21, Batch 400] loss: 0.7981813657283783
**STATS for Epoch 21** : 
Average training loss: 0.1114
Average validation loss: 0.7608
Validation Accuracy: 0.8047
Overfitting: 0.6494
Best model saved at epoch 21 with validation loss: 0.7608
[Epoch 22, Batch 100] loss: 0.7645712411403656
[Epoch 22, Batch 200] loss: 0.7209903737902641
[Epoch 22, Batch 300] loss: 0.7051283103227616
[Epoch 22, Batch 400] loss: 0.6833282887935639
**STATS for Epoch 22** : 
Average training loss: 0.0966
Average validation loss: 0.6556
Validation Accuracy: 0.8257
Overfitting: 0.5590
Best model saved at epoch 22 with validation loss: 0.6556
[Epoch 23, Batch 100] loss: 0.6545204222202301
[Epoch 23, Batch 200] loss: 0.6300773382186889
[Epoch 23, Batch 300] loss: 0.6204265174269676
[Epoch 23, Batch 400] loss: 0.6077708077430725
**STATS for Epoch 23** : 
Average training loss: 0.0846
Average validation loss: 0.5817
Validation Accuracy: 0.8410
Overfitting: 0.4971
Best model saved at epoch 23 with validation loss: 0.5817
[Epoch 24, Batch 100] loss: 0.57438471108675
[Epoch 24, Batch 200] loss: 0.5529569414258003
[Epoch 24, Batch 300] loss: 0.546264053285122
[Epoch 24, Batch 400] loss: 0.5518693605065346
**STATS for Epoch 24** : 
Average training loss: 0.0810
Average validation loss: 0.5248
Validation Accuracy: 0.8569
Overfitting: 0.4438
Best model saved at epoch 24 with validation loss: 0.5248
Fold 1 validation loss: 0.5248
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.298560254573822
[Epoch 1, Batch 200] loss: 2.2991408824920656
[Epoch 1, Batch 300] loss: 2.297896234989166
[Epoch 1, Batch 400] loss: 2.29590948343277
**STATS for Epoch 1** : 
Average training loss: 0.3378
Average validation loss: 2.2957
Validation Accuracy: 0.1544
Overfitting: 1.9579
Best model saved at epoch 1 with validation loss: 2.2957
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
[Epoch 2, Batch 100] loss: 2.2953908133506773
[Epoch 2, Batch 200] loss: 2.295517318248749
[Epoch 2, Batch 300] loss: 2.2927840518951417
[Epoch 2, Batch 400] loss: 2.292295413017273
**STATS for Epoch 2** : 
Average training loss: 0.3370
Average validation loss: 2.2914
Validation Accuracy: 0.1919
Overfitting: 1.9544
Best model saved at epoch 2 with validation loss: 2.2914
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 1 is already reported.
  warnings.warn(
[Epoch 3, Batch 100] loss: 2.290314726829529
[Epoch 3, Batch 200] loss: 2.2896337008476255
[Epoch 3, Batch 300] loss: 2.290320019721985
[Epoch 3, Batch 400] loss: 2.28740478515625
**STATS for Epoch 3** : 
Average training loss: 0.3364
Average validation loss: 2.2867
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 2 is already reported.
  warnings.warn(
Validation Accuracy: 0.2194
Overfitting: 1.9503
Best model saved at epoch 3 with validation loss: 2.2867
[Epoch 4, Batch 100] loss: 2.2848322081565855
[Epoch 4, Batch 200] loss: 2.2855976152420046
[Epoch 4, Batch 300] loss: 2.283107159137726
[Epoch 4, Batch 400] loss: 2.283630175590515
**STATS for Epoch 4** : 
Average training loss: 0.3358
Average validation loss: 2.2814
Validation Accuracy: 0.2391
Overfitting: 1.9456
Best model saved at epoch 4 with validation loss: 2.2814
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 3 is already reported.
  warnings.warn(
[Epoch 5, Batch 100] loss: 2.2807346272468565
[Epoch 5, Batch 200] loss: 2.279856584072113
[Epoch 5, Batch 300] loss: 2.2771191930770875
[Epoch 5, Batch 400] loss: 2.2763885831832886
**STATS for Epoch 5** : 
Average training loss: 0.3349
Average validation loss: 2.2752
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 4 is already reported.
  warnings.warn(
Validation Accuracy: 0.2537
Overfitting: 1.9402
Best model saved at epoch 5 with validation loss: 2.2752
[Epoch 6, Batch 100] loss: 2.2732405710220336
[Epoch 6, Batch 200] loss: 2.2720747590065002
[Epoch 6, Batch 300] loss: 2.2724396848678587
[Epoch 6, Batch 400] loss: 2.269981837272644
**STATS for Epoch 6** : 
Average training loss: 0.3337
Average validation loss: 2.2677
Validation Accuracy: 0.2620
Overfitting: 1.9339
Best model saved at epoch 6 with validation loss: 2.2677
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 5 is already reported.
  warnings.warn(
[Epoch 7, Batch 100] loss: 2.2663009428977965
[Epoch 7, Batch 200] loss: 2.265692195892334
[Epoch 7, Batch 300] loss: 2.261856119632721
[Epoch 7, Batch 400] loss: 2.260402703285217
**STATS for Epoch 7** : 
Average training loss: 0.3324
Average validation loss: 2.2582
Validation Accuracy: 0.2750
Overfitting: 1.9258
Best model saved at epoch 7 with validation loss: 2.2582
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 6 is already reported.
  warnings.warn(
[Epoch 8, Batch 100] loss: 2.2564945578575135
[Epoch 8, Batch 200] loss: 2.2561115193367005
[Epoch 8, Batch 300] loss: 2.251109697818756
[Epoch 8, Batch 400] loss: 2.249305329322815
**STATS for Epoch 8** : 
Average training loss: 0.3304
Average validation loss: 2.2458
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 7 is already reported.
  warnings.warn(
Validation Accuracy: 0.2970
Overfitting: 1.9155
Best model saved at epoch 8 with validation loss: 2.2458
[Epoch 9, Batch 100] loss: 2.2442822742462156
[Epoch 9, Batch 200] loss: 2.2401253604888915
[Epoch 9, Batch 300] loss: 2.236116874217987
[Epoch 9, Batch 400] loss: 2.23435626745224
**STATS for Epoch 9** : 
Average training loss: 0.3284
Average validation loss: 2.2292
Validation Accuracy: 0.3491
Overfitting: 1.9008
Best model saved at epoch 9 with validation loss: 2.2292
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 8 is already reported.
  warnings.warn(
[Epoch 10, Batch 100] loss: 2.225448124408722
[Epoch 10, Batch 200] loss: 2.2228394603729247
[Epoch 10, Batch 300] loss: 2.2195086097717285
[Epoch 10, Batch 400] loss: 2.213073844909668
**STATS for Epoch 10** : 
Average training loss: 0.3243
Average validation loss: 2.2058
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 9 is already reported.
  warnings.warn(
Validation Accuracy: 0.4418
Overfitting: 1.8815
Best model saved at epoch 10 with validation loss: 2.2058
[Epoch 11, Batch 100] loss: 2.203077630996704
[Epoch 11, Batch 200] loss: 2.19785361289978
[Epoch 11, Batch 300] loss: 2.1879422569274904
[Epoch 11, Batch 400] loss: 2.181146297454834
**STATS for Epoch 11** : 
Average training loss: 0.3196
Average validation loss: 2.1719
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 10 is already reported.
  warnings.warn(
Validation Accuracy: 0.5173
Overfitting: 1.8523
Best model saved at epoch 11 with validation loss: 2.1719
[Epoch 12, Batch 100] loss: 2.166904315948486
[Epoch 12, Batch 200] loss: 2.159167799949646
[Epoch 12, Batch 300] loss: 2.1445497989654543
[Epoch 12, Batch 400] loss: 2.1384253454208375
**STATS for Epoch 12** : 
Average training loss: 0.3118
Average validation loss: 2.1203
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 11 is already reported.
  warnings.warn(
Validation Accuracy: 0.5660
Overfitting: 1.8085
Best model saved at epoch 12 with validation loss: 2.1203
[Epoch 13, Batch 100] loss: 2.112596347332001
[Epoch 13, Batch 200] loss: 2.1001655745506285
[Epoch 13, Batch 300] loss: 2.078943235874176
[Epoch 13, Batch 400] loss: 2.0616291666030886
**STATS for Epoch 13** : 
Average training loss: 0.3007
Average validation loss: 2.0385
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 12 is already reported.
  warnings.warn(
Validation Accuracy: 0.5944
Overfitting: 1.7377
Best model saved at epoch 13 with validation loss: 2.0385
[Epoch 14, Batch 100] loss: 2.0258797085285187
[Epoch 14, Batch 200] loss: 2.005533905029297
[Epoch 14, Batch 300] loss: 1.974562816619873
[Epoch 14, Batch 400] loss: 1.9426641190052032
**STATS for Epoch 14** : 
Average training loss: 0.2821
Average validation loss: 1.9068
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 13 is already reported.
  warnings.warn(
Validation Accuracy: 0.6282
Overfitting: 1.6247
Best model saved at epoch 14 with validation loss: 1.9068
[Epoch 15, Batch 100] loss: 1.8866682898998262
[Epoch 15, Batch 200] loss: 1.8443058788776399
[Epoch 15, Batch 300] loss: 1.809642058610916
[Epoch 15, Batch 400] loss: 1.7617601311206819
**STATS for Epoch 15** : 
Average training loss: 0.2529
Average validation loss: 1.7029
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 14 is already reported.
  warnings.warn(
Validation Accuracy: 0.6539
Overfitting: 1.4500
Best model saved at epoch 15 with validation loss: 1.7029
[Epoch 16, Batch 100] loss: 1.6781288266181946
[Epoch 16, Batch 200] loss: 1.6203526616096497
[Epoch 16, Batch 300] loss: 1.5524903798103333
[Epoch 16, Batch 400] loss: 1.5066571784019471
**STATS for Epoch 16** : 
Average training loss: 0.2139
Average validation loss: 1.4320
Validation Accuracy: 0.6917
Overfitting: 1.2181
Best model saved at epoch 16 with validation loss: 1.4320
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 15 is already reported.
  warnings.warn(
[Epoch 17, Batch 100] loss: 1.3863109576702117
[Epoch 17, Batch 200] loss: 1.3386415600776673
[Epoch 17, Batch 300] loss: 1.288922667503357
[Epoch 17, Batch 400] loss: 1.213143824338913
**STATS for Epoch 17** : 
Average training loss: 0.1717
Average validation loss: 1.1485
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 16 is already reported.
  warnings.warn(
Validation Accuracy: 0.7393
Overfitting: 0.9768
Best model saved at epoch 17 with validation loss: 1.1485
[Epoch 18, Batch 100] loss: 1.1159389585256576
[Epoch 18, Batch 200] loss: 1.0616034686565399
[Epoch 18, Batch 300] loss: 1.0091787457466126
[Epoch 18, Batch 400] loss: 0.9644467425346375
**STATS for Epoch 18** : 
Average training loss: 0.1381
Average validation loss: 0.9160
Validation Accuracy: 0.7792
Overfitting: 0.7779
Best model saved at epoch 18 with validation loss: 0.9160
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 17 is already reported.
  warnings.warn(
[Epoch 19, Batch 100] loss: 0.8878929263353348
[Epoch 19, Batch 200] loss: 0.8569813930988311
[Epoch 19, Batch 300] loss: 0.8281436967849731
[Epoch 19, Batch 400] loss: 0.7762452274560928
**STATS for Epoch 19** : 
Average training loss: 0.1112
Average validation loss: 0.7565
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 18 is already reported.
  warnings.warn(
Validation Accuracy: 0.8037
Overfitting: 0.6453
Best model saved at epoch 19 with validation loss: 0.7565
[Epoch 20, Batch 100] loss: 0.7438530963659287
[Epoch 20, Batch 200] loss: 0.7065105986595154
[Epoch 20, Batch 300] loss: 0.6794467443227767
[Epoch 20, Batch 400] loss: 0.6660309019684791
**STATS for Epoch 20** : 
Average training loss: 0.0974
Average validation loss: 0.6508
Validation Accuracy: 0.8236
Overfitting: 0.5534
Best model saved at epoch 20 with validation loss: 0.6508
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 19 is already reported.
  warnings.warn(
[Epoch 21, Batch 100] loss: 0.6369986972212791
[Epoch 21, Batch 200] loss: 0.6355976986885071
[Epoch 21, Batch 300] loss: 0.6054446125030517
[Epoch 21, Batch 400] loss: 0.5737909537553787
**STATS for Epoch 21** : 
Average training loss: 0.0854
Average validation loss: 0.5833
Validation Accuracy: 0.8371
Overfitting: 0.4979
Best model saved at epoch 21 with validation loss: 0.5833
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 20 is already reported.
  warnings.warn(
[Epoch 22, Batch 100] loss: 0.5743940800428391
[Epoch 22, Batch 200] loss: 0.5489661878347397
[Epoch 22, Batch 300] loss: 0.5393064075708389
[Epoch 22, Batch 400] loss: 0.5388831076025963
**STATS for Epoch 22** : 
Average training loss: 0.0805
Average validation loss: 0.5358
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 21 is already reported.
  warnings.warn(
Validation Accuracy: 0.8490
Overfitting: 0.4553
Best model saved at epoch 22 with validation loss: 0.5358
[Epoch 23, Batch 100] loss: 0.5313964557647705
[Epoch 23, Batch 200] loss: 0.51456125497818
[Epoch 23, Batch 300] loss: 0.5000869941711426
[Epoch 23, Batch 400] loss: 0.5046159210801124
**STATS for Epoch 23** : 
Average training loss: 0.0716
Average validation loss: 0.5014
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 22 is already reported.
  warnings.warn(
Validation Accuracy: 0.8559
Overfitting: 0.4297
Best model saved at epoch 23 with validation loss: 0.5014
[Epoch 24, Batch 100] loss: 0.48556222170591357
[Epoch 24, Batch 200] loss: 0.4905853173136711
[Epoch 24, Batch 300] loss: 0.4698952755331993
[Epoch 24, Batch 400] loss: 0.4699424946308136
**STATS for Epoch 24** : 
Average training loss: 0.0694
Average validation loss: 0.4734
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 23 is already reported.
  warnings.warn(
Validation Accuracy: 0.8628
Overfitting: 0.4040
Best model saved at epoch 24 with validation loss: 0.4734
Fold 2 validation loss: 0.4734
Mean validation loss across all folds for Trial 1 is 0.4991 with trial config:  l1: 256, l2: 64, lr: 4.207988669606632e-05, batch_size: 64
[I 2024-11-21 17:39:54,496] Trial 0 finished with value: 0.4990804825129031 and parameters: {'l1': 256, 'l2': 64, 'lr': 4.207988669606632e-05, 'batch_size': 64}. Best is trial 0 with value: 0.4990804825129031.

Selected Hyperparameters for Trial 2:
  l1: 256, l2: 64, lr: 5.3370327626039544e-05, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3042178606987
[Epoch 1, Batch 200] loss: 2.3001183795928957
[Epoch 1, Batch 300] loss: 2.2998417162895204
[Epoch 1, Batch 400] loss: 2.2988680267333983
**STATS for Epoch 1** : 
Average training loss: 0.3379
Average validation loss: 2.2967
Validation Accuracy: 0.0914
Overfitting: 1.9588
Best model saved at epoch 1 with validation loss: 2.2967
[Epoch 2, Batch 100] loss: 2.2961797976493834
[Epoch 2, Batch 200] loss: 2.2949979591369627
[Epoch 2, Batch 300] loss: 2.29359539270401
[Epoch 2, Batch 400] loss: 2.2903842329978943
**STATS for Epoch 2** : 
Average training loss: 0.3366
Average validation loss: 2.2887
Validation Accuracy: 0.0943
Overfitting: 1.9521
Best model saved at epoch 2 with validation loss: 2.2887
[Epoch 3, Batch 100] loss: 2.2886794662475585
[Epoch 3, Batch 200] loss: 2.28570969581604
[Epoch 3, Batch 300] loss: 2.2828886318206787
[Epoch 3, Batch 400] loss: 2.2818537545204163
**STATS for Epoch 3** : 
Average training loss: 0.3353
Average validation loss: 2.2785
Validation Accuracy: 0.1076
Overfitting: 1.9432
Best model saved at epoch 3 with validation loss: 2.2785
[Epoch 4, Batch 100] loss: 2.277001700401306
[Epoch 4, Batch 200] loss: 2.2748711609840395
[Epoch 4, Batch 300] loss: 2.2725233674049377
[Epoch 4, Batch 400] loss: 2.2684449195861816
**STATS for Epoch 4** : 
Average training loss: 0.3335
Average validation loss: 2.2650
Validation Accuracy: 0.1676
Overfitting: 1.9315
Best model saved at epoch 4 with validation loss: 2.2650
[Epoch 5, Batch 100] loss: 2.2633842539787294
[Epoch 5, Batch 200] loss: 2.2594603872299195
[Epoch 5, Batch 300] loss: 2.2558587431907653
[Epoch 5, Batch 400] loss: 2.2520714664459227
**STATS for Epoch 5** : 
Average training loss: 0.3307
Average validation loss: 2.2459
Validation Accuracy: 0.3640
Overfitting: 1.9152
Best model saved at epoch 5 with validation loss: 2.2459
[Epoch 6, Batch 100] loss: 2.242239956855774
[Epoch 6, Batch 200] loss: 2.2390785932540895
[Epoch 6, Batch 300] loss: 2.2331068181991576
[Epoch 6, Batch 400] loss: 2.2251103281974793
**STATS for Epoch 6** : 
Average training loss: 0.3267
Average validation loss: 2.2170
Validation Accuracy: 0.5065
Overfitting: 1.8903
Best model saved at epoch 6 with validation loss: 2.2170
[Epoch 7, Batch 100] loss: 2.2113192772865293
[Epoch 7, Batch 200] loss: 2.2056825947761536
[Epoch 7, Batch 300] loss: 2.194701981544495
[Epoch 7, Batch 400] loss: 2.184784564971924
**STATS for Epoch 7** : 
Average training loss: 0.3201
Average validation loss: 2.1691
Validation Accuracy: 0.5342
Overfitting: 1.8490
Best model saved at epoch 7 with validation loss: 2.1691
[Epoch 8, Batch 100] loss: 2.16121431350708
[Epoch 8, Batch 200] loss: 2.1501258397102356
[Epoch 8, Batch 300] loss: 2.1327193546295167
[Epoch 8, Batch 400] loss: 2.1101301550865172
**STATS for Epoch 8** : 
Average training loss: 0.3077
Average validation loss: 2.0843
Validation Accuracy: 0.5564
Overfitting: 1.7766
Best model saved at epoch 8 with validation loss: 2.0843
[Epoch 9, Batch 100] loss: 2.074483208656311
[Epoch 9, Batch 200] loss: 2.0413134515285494
[Epoch 9, Batch 300] loss: 2.012951387166977
[Epoch 9, Batch 400] loss: 1.9793164825439453
**STATS for Epoch 9** : 
Average training loss: 0.2853
Average validation loss: 1.9248
Validation Accuracy: 0.5449
Overfitting: 1.6394
Best model saved at epoch 9 with validation loss: 1.9248
[Epoch 10, Batch 100] loss: 1.9060144007205964
[Epoch 10, Batch 200] loss: 1.8511728692054747
[Epoch 10, Batch 300] loss: 1.7880389761924744
[Epoch 10, Batch 400] loss: 1.726831215620041
**STATS for Epoch 10** : 
Average training loss: 0.2484
Average validation loss: 1.6489
Validation Accuracy: 0.5820
Overfitting: 1.4005
Best model saved at epoch 10 with validation loss: 1.6489
[Epoch 11, Batch 100] loss: 1.6155269849300384
[Epoch 11, Batch 200] loss: 1.54644087433815
[Epoch 11, Batch 300] loss: 1.4677049648761749
[Epoch 11, Batch 400] loss: 1.3787462079524995
**STATS for Epoch 11** : 
Average training loss: 0.1927
Average validation loss: 1.2850
Validation Accuracy: 0.6881
Overfitting: 1.0923
Best model saved at epoch 11 with validation loss: 1.2850
[Epoch 12, Batch 100] loss: 1.2674764788150787
[Epoch 12, Batch 200] loss: 1.1603540563583374
[Epoch 12, Batch 300] loss: 1.0993085157871247
[Epoch 12, Batch 400] loss: 1.0412102782726287
**STATS for Epoch 12** : 
Average training loss: 0.1450
Average validation loss: 0.9617
Validation Accuracy: 0.7622
Overfitting: 0.8166
Best model saved at epoch 12 with validation loss: 0.9617
[Epoch 13, Batch 100] loss: 0.9414803433418274
[Epoch 13, Batch 200] loss: 0.8823905199766159
[Epoch 13, Batch 300] loss: 0.8457583749294281
[Epoch 13, Batch 400] loss: 0.8073528689146042
**STATS for Epoch 13** : 
Average training loss: 0.1155
Average validation loss: 0.7588
Validation Accuracy: 0.7934
Overfitting: 0.6433
Best model saved at epoch 13 with validation loss: 0.7588
[Epoch 14, Batch 100] loss: 0.7328507649898529
[Epoch 14, Batch 200] loss: 0.7311626222729682
[Epoch 14, Batch 300] loss: 0.7081927001476288
[Epoch 14, Batch 400] loss: 0.6622357472777367
**STATS for Epoch 14** : 
Average training loss: 0.0949
Average validation loss: 0.6367
Validation Accuracy: 0.8197
Overfitting: 0.5418
Best model saved at epoch 14 with validation loss: 0.6367
[Epoch 15, Batch 100] loss: 0.6417817583680153
[Epoch 15, Batch 200] loss: 0.6032903915643693
[Epoch 15, Batch 300] loss: 0.5920948642492294
[Epoch 15, Batch 400] loss: 0.5925751608610154
**STATS for Epoch 15** : 
Average training loss: 0.0845
Average validation loss: 0.5599
Validation Accuracy: 0.8388
Overfitting: 0.4755
Best model saved at epoch 15 with validation loss: 0.5599
[Epoch 16, Batch 100] loss: 0.5448186534643173
[Epoch 16, Batch 200] loss: 0.5498518019914627
[Epoch 16, Batch 300] loss: 0.5498652437329292
[Epoch 16, Batch 400] loss: 0.5278086742758751
**STATS for Epoch 16** : 
Average training loss: 0.0750
Average validation loss: 0.5087
Validation Accuracy: 0.8504
Overfitting: 0.4337
Best model saved at epoch 16 with validation loss: 0.5087
[Epoch 17, Batch 100] loss: 0.5037827056646347
[Epoch 17, Batch 200] loss: 0.48791608154773713
[Epoch 17, Batch 300] loss: 0.4960419088602066
[Epoch 17, Batch 400] loss: 0.48240660861134527
**STATS for Epoch 17** : 
Average training loss: 0.0729
Average validation loss: 0.4710
Validation Accuracy: 0.8593
Overfitting: 0.3981
Best model saved at epoch 17 with validation loss: 0.4710
[Epoch 18, Batch 100] loss: 0.4736828622221947
[Epoch 18, Batch 200] loss: 0.45663431465625764
[Epoch 18, Batch 300] loss: 0.45882212191820143
[Epoch 18, Batch 400] loss: 0.4497563326358795
**STATS for Epoch 18** : 
Average training loss: 0.0674
Average validation loss: 0.4411
Validation Accuracy: 0.8687
Overfitting: 0.3737
Best model saved at epoch 18 with validation loss: 0.4411
[Epoch 19, Batch 100] loss: 0.4447351476550102
[Epoch 19, Batch 200] loss: 0.4323834685981274
[Epoch 19, Batch 300] loss: 0.4359134443104267
[Epoch 19, Batch 400] loss: 0.42733858242630957
**STATS for Epoch 19** : 
Average training loss: 0.0621
Average validation loss: 0.4196
Validation Accuracy: 0.8746
Overfitting: 0.3575
Best model saved at epoch 19 with validation loss: 0.4196
[Epoch 20, Batch 100] loss: 0.406882114559412
[Epoch 20, Batch 200] loss: 0.39484579548239707
[Epoch 20, Batch 300] loss: 0.4384092465043068
[Epoch 20, Batch 400] loss: 0.41302681058645246
**STATS for Epoch 20** : 
Average training loss: 0.0600
Average validation loss: 0.4017
Validation Accuracy: 0.8811
Overfitting: 0.3417
Best model saved at epoch 20 with validation loss: 0.4017
[Epoch 21, Batch 100] loss: 0.41298977345228194
[Epoch 21, Batch 200] loss: 0.3849060390889645
[Epoch 21, Batch 300] loss: 0.4042495170235634
[Epoch 21, Batch 400] loss: 0.39493770569562914
**STATS for Epoch 21** : 
Average training loss: 0.0537
Average validation loss: 0.3848
Validation Accuracy: 0.8857
Overfitting: 0.3311
Best model saved at epoch 21 with validation loss: 0.3848
[Epoch 22, Batch 100] loss: 0.3916879890859127
[Epoch 22, Batch 200] loss: 0.37367639973759653
[Epoch 22, Batch 300] loss: 0.3743546396493912
[Epoch 22, Batch 400] loss: 0.3688747580349445
**STATS for Epoch 22** : 
Average training loss: 0.0569
Average validation loss: 0.3695
Validation Accuracy: 0.8897
Overfitting: 0.3127
Best model saved at epoch 22 with validation loss: 0.3695
[Epoch 23, Batch 100] loss: 0.3806311745941639
[Epoch 23, Batch 200] loss: 0.3473741239309311
[Epoch 23, Batch 300] loss: 0.3603683690726757
[Epoch 23, Batch 400] loss: 0.36229338943958284
**STATS for Epoch 23** : 
Average training loss: 0.0548
Average validation loss: 0.3576
Validation Accuracy: 0.8935
Overfitting: 0.3027
Best model saved at epoch 23 with validation loss: 0.3576
[Epoch 24, Batch 100] loss: 0.3665715599060059
[Epoch 24, Batch 200] loss: 0.3325769901275635
[Epoch 24, Batch 300] loss: 0.3599360339343548
[Epoch 24, Batch 400] loss: 0.35500938519835473
**STATS for Epoch 24** : 
Average training loss: 0.0504
Average validation loss: 0.3461
Validation Accuracy: 0.8964
Overfitting: 0.2957
Best model saved at epoch 24 with validation loss: 0.3461
Fold 1 validation loss: 0.3461
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.307028741836548
[Epoch 1, Batch 200] loss: 2.3063489389419556
[Epoch 1, Batch 300] loss: 2.3057376527786255
[Epoch 1, Batch 400] loss: 2.303392653465271
**STATS for Epoch 1** : 
Average training loss: 0.3392
Average validation loss: 2.3044
Validation Accuracy: 0.1044
Overfitting: 1.9652
Best model saved at epoch 1 with validation loss: 2.3044
[Epoch 2, Batch 100] loss: 2.3034592032432557
[Epoch 2, Batch 200] loss: 2.302913727760315
[Epoch 2, Batch 300] loss: 2.3018849372863768
[Epoch 2, Batch 400] loss: 2.303826835155487
**STATS for Epoch 2** : 
Average training loss: 0.3385
Average validation loss: 2.3016
Validation Accuracy: 0.1176
Overfitting: 1.9630
Best model saved at epoch 2 with validation loss: 2.3016
[Epoch 3, Batch 100] loss: 2.301104276180267
[Epoch 3, Batch 200] loss: 2.3007407426834106
[Epoch 3, Batch 300] loss: 2.298721489906311
[Epoch 3, Batch 400] loss: 2.300999562740326
**STATS for Epoch 3** : 
Average training loss: 0.3378
Average validation loss: 2.2986
Validation Accuracy: 0.1403
Overfitting: 1.9607
Best model saved at epoch 3 with validation loss: 2.2986
[Epoch 4, Batch 100] loss: 2.297566874027252
[Epoch 4, Batch 200] loss: 2.298177189826965
[Epoch 4, Batch 300] loss: 2.296918070316315
[Epoch 4, Batch 400] loss: 2.2950434422492982
**STATS for Epoch 4** : 
Average training loss: 0.3376
Average validation loss: 2.2951
Validation Accuracy: 0.1661
Overfitting: 1.9575
Best model saved at epoch 4 with validation loss: 2.2951
[Epoch 5, Batch 100] loss: 2.293581638336182
[Epoch 5, Batch 200] loss: 2.2937118291854857
[Epoch 5, Batch 300] loss: 2.292828872203827
[Epoch 5, Batch 400] loss: 2.2927950835227966
**STATS for Epoch 5** : 
Average training loss: 0.3370
Average validation loss: 2.2911
Validation Accuracy: 0.1931
Overfitting: 1.9541
Best model saved at epoch 5 with validation loss: 2.2911
[Epoch 6, Batch 100] loss: 2.2897281360626223
[Epoch 6, Batch 200] loss: 2.2899589371681213
[Epoch 6, Batch 300] loss: 2.2877453899383546
[Epoch 6, Batch 400] loss: 2.287187707424164
**STATS for Epoch 6** : 
Average training loss: 0.3365
Average validation loss: 2.2864
Validation Accuracy: 0.2226
Overfitting: 1.9499
Best model saved at epoch 6 with validation loss: 2.2864
[Epoch 7, Batch 100] loss: 2.286025483608246
[Epoch 7, Batch 200] loss: 2.2834345865249634
[Epoch 7, Batch 300] loss: 2.282832567691803
[Epoch 7, Batch 400] loss: 2.283472559452057
**STATS for Epoch 7** : 
Average training loss: 0.3353
Average validation loss: 2.2806
Validation Accuracy: 0.2609
Overfitting: 1.9453
Best model saved at epoch 7 with validation loss: 2.2806
[Epoch 8, Batch 100] loss: 2.2799768447875977
[Epoch 8, Batch 200] loss: 2.2779454159736634
[Epoch 8, Batch 300] loss: 2.275891330242157
[Epoch 8, Batch 400] loss: 2.2754331254959106
**STATS for Epoch 8** : 
Average training loss: 0.3345
Average validation loss: 2.2733
Validation Accuracy: 0.3024
Overfitting: 1.9388
Best model saved at epoch 8 with validation loss: 2.2733
[Epoch 9, Batch 100] loss: 2.2713846564292908
[Epoch 9, Batch 200] loss: 2.2702063012123106
[Epoch 9, Batch 300] loss: 2.267715125083923
[Epoch 9, Batch 400] loss: 2.266315803527832
**STATS for Epoch 9** : 
Average training loss: 0.3332
Average validation loss: 2.2635
Validation Accuracy: 0.3647
Overfitting: 1.9303
Best model saved at epoch 9 with validation loss: 2.2635
[Epoch 10, Batch 100] loss: 2.261009202003479
[Epoch 10, Batch 200] loss: 2.2595734143257142
[Epoch 10, Batch 300] loss: 2.2564613938331606
[Epoch 10, Batch 400] loss: 2.25335636138916
**STATS for Epoch 10** : 
Average training loss: 0.3313
Average validation loss: 2.2499
Validation Accuracy: 0.4263
Overfitting: 1.9187
Best model saved at epoch 10 with validation loss: 2.2499
[Epoch 11, Batch 100] loss: 2.2483328413963317
[Epoch 11, Batch 200] loss: 2.2434592700004576
[Epoch 11, Batch 300] loss: 2.2397965741157533
[Epoch 11, Batch 400] loss: 2.2361082077026366
**STATS for Epoch 11** : 
Average training loss: 0.3282
Average validation loss: 2.2301
Validation Accuracy: 0.4506
Overfitting: 1.9020
Best model saved at epoch 11 with validation loss: 2.2301
[Epoch 12, Batch 100] loss: 2.2258056521415712
[Epoch 12, Batch 200] loss: 2.222258756160736
[Epoch 12, Batch 300] loss: 2.2154380774497984
[Epoch 12, Batch 400] loss: 2.208656711578369
**STATS for Epoch 12** : 
Average training loss: 0.3239
Average validation loss: 2.1998
Validation Accuracy: 0.4584
Overfitting: 1.8759
Best model saved at epoch 12 with validation loss: 2.1998
[Epoch 13, Batch 100] loss: 2.193916153907776
[Epoch 13, Batch 200] loss: 2.1845991683006285
[Epoch 13, Batch 300] loss: 2.1787472438812254
[Epoch 13, Batch 400] loss: 2.164872097969055
**STATS for Epoch 13** : 
Average training loss: 0.3169
Average validation loss: 2.1502
Validation Accuracy: 0.4538
Overfitting: 1.8333
Best model saved at epoch 13 with validation loss: 2.1502
[Epoch 14, Batch 100] loss: 2.144476642608643
[Epoch 14, Batch 200] loss: 2.1281199979782106
[Epoch 14, Batch 300] loss: 2.1064279961585997
[Epoch 14, Batch 400] loss: 2.0878725934028624
**STATS for Epoch 14** : 
Average training loss: 0.3049
Average validation loss: 2.0633
Validation Accuracy: 0.4692
Overfitting: 1.7584
Best model saved at epoch 14 with validation loss: 2.0633
[Epoch 15, Batch 100] loss: 2.0535671031475067
[Epoch 15, Batch 200] loss: 2.019363206624985
[Epoch 15, Batch 300] loss: 1.9877699899673462
[Epoch 15, Batch 400] loss: 1.9583419823646546
**STATS for Epoch 15** : 
Average training loss: 0.2814
Average validation loss: 1.9056
Validation Accuracy: 0.5294
Overfitting: 1.6241
Best model saved at epoch 15 with validation loss: 1.9056
[Epoch 16, Batch 100] loss: 1.8809524631500245
[Epoch 16, Batch 200] loss: 1.833459233045578
[Epoch 16, Batch 300] loss: 1.7776693177223206
[Epoch 16, Batch 400] loss: 1.7102353858947754
**STATS for Epoch 16** : 
Average training loss: 0.2444
Average validation loss: 1.6387
Validation Accuracy: 0.6165
Overfitting: 1.3942
Best model saved at epoch 16 with validation loss: 1.6387
[Epoch 17, Batch 100] loss: 1.6068772840499879
[Epoch 17, Batch 200] loss: 1.532596892118454
[Epoch 17, Batch 300] loss: 1.4548056483268739
[Epoch 17, Batch 400] loss: 1.3946495258808136
**STATS for Epoch 17** : 
Average training loss: 0.1923
Average validation loss: 1.3002
Validation Accuracy: 0.6906
Overfitting: 1.1079
Best model saved at epoch 17 with validation loss: 1.3002
[Epoch 18, Batch 100] loss: 1.270986201763153
[Epoch 18, Batch 200] loss: 1.1913466095924377
[Epoch 18, Batch 300] loss: 1.1325394451618194
[Epoch 18, Batch 400] loss: 1.0731393724679947
**STATS for Epoch 18** : 
Average training loss: 0.1470
Average validation loss: 1.0050
Validation Accuracy: 0.7413
Overfitting: 0.8580
Best model saved at epoch 18 with validation loss: 1.0050
[Epoch 19, Batch 100] loss: 0.9864197832345962
[Epoch 19, Batch 200] loss: 0.9437144917249679
[Epoch 19, Batch 300] loss: 0.88221475481987
[Epoch 19, Batch 400] loss: 0.830963380932808
**STATS for Epoch 19** : 
Average training loss: 0.1206
Average validation loss: 0.8119
Validation Accuracy: 0.7749
Overfitting: 0.6913
Best model saved at epoch 19 with validation loss: 0.8119
[Epoch 20, Batch 100] loss: 0.7988594383001327
[Epoch 20, Batch 200] loss: 0.7512838894128799
[Epoch 20, Batch 300] loss: 0.7552350759506226
[Epoch 20, Batch 400] loss: 0.7239522808790206
**STATS for Epoch 20** : 
Average training loss: 0.0994
Average validation loss: 0.6951
Validation Accuracy: 0.8014
Overfitting: 0.5957
Best model saved at epoch 20 with validation loss: 0.6951
[Epoch 21, Batch 100] loss: 0.6928360223770141
[Epoch 21, Batch 200] loss: 0.6542553788423539
[Epoch 21, Batch 300] loss: 0.6657591342926026
[Epoch 21, Batch 400] loss: 0.6244447973370552
**STATS for Epoch 21** : 
Average training loss: 0.0898
Average validation loss: 0.6214
Validation Accuracy: 0.8177
Overfitting: 0.5316
Best model saved at epoch 21 with validation loss: 0.6214
[Epoch 22, Batch 100] loss: 0.6051170819997788
[Epoch 22, Batch 200] loss: 0.5921649059653282
[Epoch 22, Batch 300] loss: 0.5980954551696778
[Epoch 22, Batch 400] loss: 0.573094120323658
**STATS for Epoch 22** : 
Average training loss: 0.0859
Average validation loss: 0.5715
Validation Accuracy: 0.8320
Overfitting: 0.4856
Best model saved at epoch 22 with validation loss: 0.5715
[Epoch 23, Batch 100] loss: 0.5853046196699142
[Epoch 23, Batch 200] loss: 0.545276894569397
[Epoch 23, Batch 300] loss: 0.5372456005215644
[Epoch 23, Batch 400] loss: 0.5346776995062829
**STATS for Epoch 23** : 
Average training loss: 0.0774
Average validation loss: 0.5338
Validation Accuracy: 0.8425
Overfitting: 0.4564
Best model saved at epoch 23 with validation loss: 0.5338
[Epoch 24, Batch 100] loss: 0.5130225223302841
[Epoch 24, Batch 200] loss: 0.532530574798584
[Epoch 24, Batch 300] loss: 0.501693204343319
[Epoch 24, Batch 400] loss: 0.5119280856847763
**STATS for Epoch 24** : 
Average training loss: 0.0740
Average validation loss: 0.5057
Validation Accuracy: 0.8495
Overfitting: 0.4317
Best model saved at epoch 24 with validation loss: 0.5057
Fold 2 validation loss: 0.5057
Mean validation loss across all folds for Trial 2 is 0.4259 with trial config:  l1: 256, l2: 64, lr: 5.3370327626039544e-05, batch_size: 64
[I 2024-11-21 17:48:36,297] Trial 1 finished with value: 0.4258693002307339 and parameters: {'l1': 256, 'l2': 64, 'lr': 5.3370327626039544e-05, 'batch_size': 64}. Best is trial 1 with value: 0.4258693002307339.

Selected Hyperparameters for Trial 3:
  l1: 128, l2: 128, lr: 0.0006672367170464204, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3048680424690247
[Epoch 1, Batch 200] loss: 2.291494197845459
[Epoch 1, Batch 300] loss: 2.2785455560684205
[Epoch 1, Batch 400] loss: 2.2550065231323244
[Epoch 1, Batch 500] loss: 2.2060614800453187
[Epoch 1, Batch 600] loss: 2.0638222444057464
[Epoch 1, Batch 700] loss: 1.5433482348918914
[Epoch 1, Batch 800] loss: 0.8558230558037758
[Epoch 1, Batch 900] loss: 0.599307999163866
[Epoch 1, Batch 1000] loss: 0.49149572059512137
[Epoch 1, Batch 1100] loss: 0.4464610156416893
[Epoch 1, Batch 1200] loss: 0.40374427422881126
[Epoch 1, Batch 1300] loss: 0.36356041513383386
[Epoch 1, Batch 1400] loss: 0.34678523380309345
[Epoch 1, Batch 1500] loss: 0.3142442555725575
[Epoch 1, Batch 1600] loss: 0.32727287817746403
[Epoch 1, Batch 1700] loss: 0.29515373906120657
[Epoch 1, Batch 1800] loss: 0.28319087335839865
**STATS for Epoch 1** : 
Average training loss: 0.0105
Average validation loss: 0.2420
Validation Accuracy: 0.9264
Overfitting: 0.2315
Best model saved at epoch 1 with validation loss: 0.2420
[Epoch 2, Batch 100] loss: 0.24560592020861804
[Epoch 2, Batch 200] loss: 0.25909361742436887
[Epoch 2, Batch 300] loss: 0.20084647888317705
[Epoch 2, Batch 400] loss: 0.21861870299093425
[Epoch 2, Batch 500] loss: 0.21242220410145818
[Epoch 2, Batch 600] loss: 0.228620150052011
[Epoch 2, Batch 700] loss: 0.18576102321967483
[Epoch 2, Batch 800] loss: 0.17740081992931664
[Epoch 2, Batch 900] loss: 0.16925422986969352
[Epoch 2, Batch 1000] loss: 0.19541535068303348
[Epoch 2, Batch 1100] loss: 0.18306933496147393
[Epoch 2, Batch 1200] loss: 0.19867852910421788
[Epoch 2, Batch 1300] loss: 0.17890462609939278
[Epoch 2, Batch 1400] loss: 0.1715139425219968
[Epoch 2, Batch 1500] loss: 0.1637048602104187
[Epoch 2, Batch 1600] loss: 0.1279185916483402
[Epoch 2, Batch 1700] loss: 0.1474680727068335
[Epoch 2, Batch 1800] loss: 0.12883990297093986
**STATS for Epoch 2** : 
Average training loss: 0.0052
Average validation loss: 0.1245
Validation Accuracy: 0.9620
Overfitting: 0.1193
Best model saved at epoch 2 with validation loss: 0.1245
[Epoch 3, Batch 100] loss: 0.14532285605324433
[Epoch 3, Batch 200] loss: 0.10525158975739032
[Epoch 3, Batch 300] loss: 0.11839283619308844
[Epoch 3, Batch 400] loss: 0.13242959644645452
[Epoch 3, Batch 500] loss: 0.10963627552613615
[Epoch 3, Batch 600] loss: 0.11815071048680693
[Epoch 3, Batch 700] loss: 0.12844998352695255
[Epoch 3, Batch 800] loss: 0.12354398461058735
[Epoch 3, Batch 900] loss: 0.11699720931705088
[Epoch 3, Batch 1000] loss: 0.11615775836165994
[Epoch 3, Batch 1100] loss: 0.10209046877454966
[Epoch 3, Batch 1200] loss: 0.1175545049761422
[Epoch 3, Batch 1300] loss: 0.12443259168765508
[Epoch 3, Batch 1400] loss: 0.12920987992547453
[Epoch 3, Batch 1500] loss: 0.12802246785722673
[Epoch 3, Batch 1600] loss: 0.08782027400564402
[Epoch 3, Batch 1700] loss: 0.12001452881842851
[Epoch 3, Batch 1800] loss: 0.08554388137417845
**STATS for Epoch 3** : 
Average training loss: 0.0041
Average validation loss: 0.1119
Validation Accuracy: 0.9659
Overfitting: 0.1078
Best model saved at epoch 3 with validation loss: 0.1119
[Epoch 4, Batch 100] loss: 0.08056228328496218
[Epoch 4, Batch 200] loss: 0.09888416324509308
[Epoch 4, Batch 300] loss: 0.0973028454463929
[Epoch 4, Batch 400] loss: 0.07463238648022524
[Epoch 4, Batch 500] loss: 0.07989450874272734
[Epoch 4, Batch 600] loss: 0.08592632382293232
[Epoch 4, Batch 700] loss: 0.10335227795643732
[Epoch 4, Batch 800] loss: 0.09865085368044674
[Epoch 4, Batch 900] loss: 0.07391106808325276
[Epoch 4, Batch 1000] loss: 0.11045983685646206
[Epoch 4, Batch 1100] loss: 0.11700539062498137
[Epoch 4, Batch 1200] loss: 0.08243248956743628
[Epoch 4, Batch 1300] loss: 0.08229508473072202
[Epoch 4, Batch 1400] loss: 0.08469546413165517
[Epoch 4, Batch 1500] loss: 0.10034738064976409
[Epoch 4, Batch 1600] loss: 0.09861013716203161
[Epoch 4, Batch 1700] loss: 0.09017247526207939
[Epoch 4, Batch 1800] loss: 0.07285887887817807
**STATS for Epoch 4** : 
Average training loss: 0.0027
Average validation loss: 0.0854
Validation Accuracy: 0.9726
Overfitting: 0.0827
Best model saved at epoch 4 with validation loss: 0.0854
[Epoch 5, Batch 100] loss: 0.06820925964508205
[Epoch 5, Batch 200] loss: 0.06344390373444185
[Epoch 5, Batch 300] loss: 0.06536706384620629
[Epoch 5, Batch 400] loss: 0.1046952711767517
[Epoch 5, Batch 500] loss: 0.06976082373876125
[Epoch 5, Batch 600] loss: 0.08668654472508934
[Epoch 5, Batch 700] loss: 0.07183404970215633
[Epoch 5, Batch 800] loss: 0.08971113434294238
[Epoch 5, Batch 900] loss: 0.0682639814238064
[Epoch 5, Batch 1000] loss: 0.07870886055752635
[Epoch 5, Batch 1100] loss: 0.046074986927269496
[Epoch 5, Batch 1200] loss: 0.07244112431129907
[Epoch 5, Batch 1300] loss: 0.09382563546067103
[Epoch 5, Batch 1400] loss: 0.06605844841804355
[Epoch 5, Batch 1500] loss: 0.05637031357968226
[Epoch 5, Batch 1600] loss: 0.09017186433426104
[Epoch 5, Batch 1700] loss: 0.06514091375574935
[Epoch 5, Batch 1800] loss: 0.07376909517683089
**STATS for Epoch 5** : 
Average training loss: 0.0023
Average validation loss: 0.0740
Validation Accuracy: 0.9764
Overfitting: 0.0717
Best model saved at epoch 5 with validation loss: 0.0740
[Epoch 6, Batch 100] loss: 0.05393576915434096
[Epoch 6, Batch 200] loss: 0.06460926285362803
[Epoch 6, Batch 300] loss: 0.06445311317103915
[Epoch 6, Batch 400] loss: 0.049641651960555463
[Epoch 6, Batch 500] loss: 0.06380990974488668
[Epoch 6, Batch 600] loss: 0.04520354053645861
[Epoch 6, Batch 700] loss: 0.07784218601940665
[Epoch 6, Batch 800] loss: 0.058522947379387916
[Epoch 6, Batch 900] loss: 0.07479445658391341
[Epoch 6, Batch 1000] loss: 0.06671491445507854
[Epoch 6, Batch 1100] loss: 0.06287615389330313
[Epoch 6, Batch 1200] loss: 0.05218245459604077
[Epoch 6, Batch 1300] loss: 0.04529369469790254
[Epoch 6, Batch 1400] loss: 0.06561603862675838
[Epoch 6, Batch 1500] loss: 0.055422322639497
[Epoch 6, Batch 1600] loss: 0.07058391020109411
[Epoch 6, Batch 1700] loss: 0.06043037360475864
[Epoch 6, Batch 1800] loss: 0.08516575983958319
**STATS for Epoch 6** : 
Average training loss: 0.0030
Average validation loss: 0.0757
Validation Accuracy: 0.9756
Overfitting: 0.0727
[Epoch 7, Batch 100] loss: 0.04377379148529144
[Epoch 7, Batch 200] loss: 0.06342219779791776
[Epoch 7, Batch 300] loss: 0.04181960026558954
[Epoch 7, Batch 400] loss: 0.06025099044141825
[Epoch 7, Batch 500] loss: 0.06363794193137437
[Epoch 7, Batch 600] loss: 0.06096291892579757
[Epoch 7, Batch 700] loss: 0.0567149490347947
[Epoch 7, Batch 800] loss: 0.04808101527945837
[Epoch 7, Batch 900] loss: 0.05785673038975801
[Epoch 7, Batch 1000] loss: 0.07175045481562847
[Epoch 7, Batch 1100] loss: 0.04519796703592874
[Epoch 7, Batch 1200] loss: 0.049203892645891756
[Epoch 7, Batch 1300] loss: 0.06014793037029449
[Epoch 7, Batch 1400] loss: 0.045897984699404336
[Epoch 7, Batch 1500] loss: 0.058471011275833006
[Epoch 7, Batch 1600] loss: 0.04164404059003573
[Epoch 7, Batch 1700] loss: 0.06060791374533437
[Epoch 7, Batch 1800] loss: 0.05230897150118835
**STATS for Epoch 7** : 
Average training loss: 0.0026
Average validation loss: 0.0699
Validation Accuracy: 0.9772
Overfitting: 0.0673
Best model saved at epoch 7 with validation loss: 0.0699
[Epoch 8, Batch 100] loss: 0.04807693053560797
[Epoch 8, Batch 200] loss: 0.06400039767439011
[Epoch 8, Batch 300] loss: 0.04766525199491298
[Epoch 8, Batch 400] loss: 0.05018097862135619
[Epoch 8, Batch 500] loss: 0.05155803098110482
[Epoch 8, Batch 600] loss: 0.041009507719427345
[Epoch 8, Batch 700] loss: 0.049362591955577954
[Epoch 8, Batch 800] loss: 0.041166885736165566
[Epoch 8, Batch 900] loss: 0.04559985881147441
[Epoch 8, Batch 1000] loss: 0.04576091611917946
[Epoch 8, Batch 1100] loss: 0.035986859937693225
[Epoch 8, Batch 1200] loss: 0.04505162554298295
[Epoch 8, Batch 1300] loss: 0.051685237811179834
[Epoch 8, Batch 1400] loss: 0.037029017037421
[Epoch 8, Batch 1500] loss: 0.042220201321761124
[Epoch 8, Batch 1600] loss: 0.05036490110185696
[Epoch 8, Batch 1700] loss: 0.04309498508577235
[Epoch 8, Batch 1800] loss: 0.04451044638233725
**STATS for Epoch 8** : 
Average training loss: 0.0027
Average validation loss: 0.0737
Validation Accuracy: 0.9757
Overfitting: 0.0709
[Epoch 9, Batch 100] loss: 0.04061467967403587
[Epoch 9, Batch 200] loss: 0.047104815862549006
[Epoch 9, Batch 300] loss: 0.025627612062962726
[Epoch 9, Batch 400] loss: 0.03645837245028815
[Epoch 9, Batch 500] loss: 0.03481193904139218
[Epoch 9, Batch 600] loss: 0.04867077510862146
[Epoch 9, Batch 700] loss: 0.03573556646995712
[Epoch 9, Batch 800] loss: 0.03678913720010314
[Epoch 9, Batch 900] loss: 0.04622286063269712
[Epoch 9, Batch 1000] loss: 0.03312504552188329
[Epoch 9, Batch 1100] loss: 0.060644791310478466
[Epoch 9, Batch 1200] loss: 0.04627018587882049
[Epoch 9, Batch 1300] loss: 0.04099159823614173
[Epoch 9, Batch 1400] loss: 0.04034680785494857
[Epoch 9, Batch 1500] loss: 0.04716402251011459
[Epoch 9, Batch 1600] loss: 0.03939934930211166
[Epoch 9, Batch 1700] loss: 0.036904642076260645
[Epoch 9, Batch 1800] loss: 0.04416908897925168
**STATS for Epoch 9** : 
Average training loss: 0.0011
Average validation loss: 0.0600
Validation Accuracy: 0.9816
Overfitting: 0.0589
Best model saved at epoch 9 with validation loss: 0.0600
[Epoch 10, Batch 100] loss: 0.033012196451963974
[Epoch 10, Batch 200] loss: 0.048256688448527714
[Epoch 10, Batch 300] loss: 0.04204811556235654
[Epoch 10, Batch 400] loss: 0.023830986037210095
[Epoch 10, Batch 500] loss: 0.02845399201789405
[Epoch 10, Batch 600] loss: 0.03345774441899266
[Epoch 10, Batch 700] loss: 0.037174094325018815
[Epoch 10, Batch 800] loss: 0.030925251718290383
[Epoch 10, Batch 900] loss: 0.02508404761851125
[Epoch 10, Batch 1000] loss: 0.04276010022498667
[Epoch 10, Batch 1100] loss: 0.04166794785007369
[Epoch 10, Batch 1200] loss: 0.04643213325965917
[Epoch 10, Batch 1300] loss: 0.030071349156060023
[Epoch 10, Batch 1400] loss: 0.051248996413778516
[Epoch 10, Batch 1500] loss: 0.03866676385878236
[Epoch 10, Batch 1600] loss: 0.041480074869759846
[Epoch 10, Batch 1700] loss: 0.029705181500321486
[Epoch 10, Batch 1800] loss: 0.026687261756160298
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0675
Validation Accuracy: 0.9797
Overfitting: 0.0659
[Epoch 11, Batch 100] loss: 0.0366313306747179
[Epoch 11, Batch 200] loss: 0.031989121453952975
[Epoch 11, Batch 300] loss: 0.026630988004762914
[Epoch 11, Batch 400] loss: 0.049010038260021246
[Epoch 11, Batch 500] loss: 0.06240745063259965
[Epoch 11, Batch 600] loss: 0.02623971756926039
[Epoch 11, Batch 700] loss: 0.0406796993885655
[Epoch 11, Batch 800] loss: 0.02522941455274122
[Epoch 11, Batch 900] loss: 0.034131381924744346
[Epoch 11, Batch 1000] loss: 0.034249887523110374
[Epoch 11, Batch 1100] loss: 0.030365431108220944
[Epoch 11, Batch 1200] loss: 0.0338855091714504
[Epoch 11, Batch 1300] loss: 0.023469603741687023
[Epoch 11, Batch 1400] loss: 0.024896775588276795
[Epoch 11, Batch 1500] loss: 0.03372069964250841
[Epoch 11, Batch 1600] loss: 0.03883670207309478
[Epoch 11, Batch 1700] loss: 0.02845788830483798
[Epoch 11, Batch 1800] loss: 0.030731151080253767
**STATS for Epoch 11** : 
Average training loss: 0.0013
Average validation loss: 0.0567
Validation Accuracy: 0.9831
Overfitting: 0.0554
Best model saved at epoch 11 with validation loss: 0.0567
[Epoch 12, Batch 100] loss: 0.0279887465039792
[Epoch 12, Batch 200] loss: 0.030370785878330933
[Epoch 12, Batch 300] loss: 0.022742779670807067
[Epoch 12, Batch 400] loss: 0.023423526698898058
[Epoch 12, Batch 500] loss: 0.027351435834498262
[Epoch 12, Batch 600] loss: 0.035451478054746986
[Epoch 12, Batch 700] loss: 0.03339229621211416
[Epoch 12, Batch 800] loss: 0.03394617325986474
[Epoch 12, Batch 900] loss: 0.04416521356164594
[Epoch 12, Batch 1000] loss: 0.01896154469970497
[Epoch 12, Batch 1100] loss: 0.018646240917078102
[Epoch 12, Batch 1200] loss: 0.033846484445748504
[Epoch 12, Batch 1300] loss: 0.024332490878805402
[Epoch 12, Batch 1400] loss: 0.02645999543456128
[Epoch 12, Batch 1500] loss: 0.02662116140782018
[Epoch 12, Batch 1600] loss: 0.03185440239176387
[Epoch 12, Batch 1700] loss: 0.02732013396544062
[Epoch 12, Batch 1800] loss: 0.03052141908228805
**STATS for Epoch 12** : 
Average training loss: 0.0014
Average validation loss: 0.0559
Validation Accuracy: 0.9827
Overfitting: 0.0546
Best model saved at epoch 12 with validation loss: 0.0559
[Epoch 13, Batch 100] loss: 0.026009423880968826
[Epoch 13, Batch 200] loss: 0.028197729825915303
[Epoch 13, Batch 300] loss: 0.02068647235417302
[Epoch 13, Batch 400] loss: 0.048286731617554327
[Epoch 13, Batch 500] loss: 0.0336506597083644
[Epoch 13, Batch 600] loss: 0.03165972585142299
[Epoch 13, Batch 700] loss: 0.01691036537202308
[Epoch 13, Batch 800] loss: 0.03244990420353133
[Epoch 13, Batch 900] loss: 0.028409561874286737
[Epoch 13, Batch 1000] loss: 0.022870045061172278
[Epoch 13, Batch 1100] loss: 0.023794965815686738
[Epoch 13, Batch 1200] loss: 0.017724226403224748
[Epoch 13, Batch 1300] loss: 0.023056901415875474
[Epoch 13, Batch 1400] loss: 0.021336770431917104
[Epoch 13, Batch 1500] loss: 0.03333418263457134
[Epoch 13, Batch 1600] loss: 0.03674705943252775
[Epoch 13, Batch 1700] loss: 0.026164881786098704
[Epoch 13, Batch 1800] loss: 0.017382818214209693
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0688
Validation Accuracy: 0.9791
Overfitting: 0.0678
[Epoch 14, Batch 100] loss: 0.02385209545653197
[Epoch 14, Batch 200] loss: 0.018576477926108056
[Epoch 14, Batch 300] loss: 0.015265909878253296
[Epoch 14, Batch 400] loss: 0.020061686891222053
[Epoch 14, Batch 500] loss: 0.026326603125162364
[Epoch 14, Batch 600] loss: 0.02230730921422946
[Epoch 14, Batch 700] loss: 0.026384595504277967
[Epoch 14, Batch 800] loss: 0.0364088619141603
[Epoch 14, Batch 900] loss: 0.027363521443694482
[Epoch 14, Batch 1000] loss: 0.027055779969268768
[Epoch 14, Batch 1100] loss: 0.015805368893852575
[Epoch 14, Batch 1200] loss: 0.0320092345485682
[Epoch 14, Batch 1300] loss: 0.018123073863498575
[Epoch 14, Batch 1400] loss: 0.0257436902376503
[Epoch 14, Batch 1500] loss: 0.02967672564816894
[Epoch 14, Batch 1600] loss: 0.015941623849757888
[Epoch 14, Batch 1700] loss: 0.024633394983065954
[Epoch 14, Batch 1800] loss: 0.01517390705867001
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0607
Validation Accuracy: 0.9819
Overfitting: 0.0602
[Epoch 15, Batch 100] loss: 0.019765543141475064
[Epoch 15, Batch 200] loss: 0.01992469292934402
[Epoch 15, Batch 300] loss: 0.017661383049344295
[Epoch 15, Batch 400] loss: 0.011548729590358561
[Epoch 15, Batch 500] loss: 0.0188066830999378
[Epoch 15, Batch 600] loss: 0.0216621050017784
[Epoch 15, Batch 700] loss: 0.02498146016305327
[Epoch 15, Batch 800] loss: 0.023608530135861658
[Epoch 15, Batch 900] loss: 0.022558464260691836
[Epoch 15, Batch 1000] loss: 0.030387605944270035
[Epoch 15, Batch 1100] loss: 0.012637859107999248
[Epoch 15, Batch 1200] loss: 0.025056319387877012
[Epoch 15, Batch 1300] loss: 0.035692466888503985
[Epoch 15, Batch 1400] loss: 0.029741428973575238
[Epoch 15, Batch 1500] loss: 0.01997933169499447
[Epoch 15, Batch 1600] loss: 0.03753035543340957
[Epoch 15, Batch 1700] loss: 0.01832954619483644
[Epoch 15, Batch 1800] loss: 0.021380486625239427
**STATS for Epoch 15** : 
Average training loss: 0.0014
Average validation loss: 0.0574
Validation Accuracy: 0.9825
Overfitting: 0.0560
[Epoch 16, Batch 100] loss: 0.0125908319815062
[Epoch 16, Batch 200] loss: 0.01160478058976878
[Epoch 16, Batch 300] loss: 0.013586520509124966
[Epoch 16, Batch 400] loss: 0.015934136751311598
[Epoch 16, Batch 500] loss: 0.019099924426627696
[Epoch 16, Batch 600] loss: 0.021414718926862406
[Epoch 16, Batch 700] loss: 0.029822602243802974
[Epoch 16, Batch 800] loss: 0.012917773104491062
[Epoch 16, Batch 900] loss: 0.025016045580850913
[Epoch 16, Batch 1000] loss: 0.023964160706855184
[Epoch 16, Batch 1100] loss: 0.02994858587757335
[Epoch 16, Batch 1200] loss: 0.022984892027598108
[Epoch 16, Batch 1300] loss: 0.014159787201515428
[Epoch 16, Batch 1400] loss: 0.021352597469231113
[Epoch 16, Batch 1500] loss: 0.012112480982541456
[Epoch 16, Batch 1600] loss: 0.023370522097175127
[Epoch 16, Batch 1700] loss: 0.020396047191879915
[Epoch 16, Batch 1800] loss: 0.01965291842338047
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0589
Validation Accuracy: 0.9832
Overfitting: 0.0579
[Epoch 17, Batch 100] loss: 0.015451674604482832
[Epoch 17, Batch 200] loss: 0.018712631367743596
[Epoch 17, Batch 300] loss: 0.030402255743174466
[Epoch 17, Batch 400] loss: 0.01496541306256404
[Epoch 17, Batch 500] loss: 0.0144963421196735
[Epoch 17, Batch 600] loss: 0.01758041344692174
[Epoch 17, Batch 700] loss: 0.022185307727158942
[Epoch 17, Batch 800] loss: 0.010706865386709978
[Epoch 17, Batch 900] loss: 0.012329855783355015
[Epoch 17, Batch 1000] loss: 0.020104943172791535
[Epoch 17, Batch 1100] loss: 0.016969368164955086
[Epoch 17, Batch 1200] loss: 0.01748514274160698
[Epoch 17, Batch 1300] loss: 0.011598994878622761
[Epoch 17, Batch 1400] loss: 0.012711880303650105
[Epoch 17, Batch 1500] loss: 0.01592177778173209
[Epoch 17, Batch 1600] loss: 0.014106318263038702
[Epoch 17, Batch 1700] loss: 0.01987150562552415
[Epoch 17, Batch 1800] loss: 0.022520602223485186
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0627
Validation Accuracy: 0.9819
Overfitting: 0.0621
[Epoch 18, Batch 100] loss: 0.009989795292358394
[Epoch 18, Batch 200] loss: 0.010510209159147053
[Epoch 18, Batch 300] loss: 0.007879267531916413
[Epoch 18, Batch 400] loss: 0.011751360747248328
[Epoch 18, Batch 500] loss: 0.02335059676312085
[Epoch 18, Batch 600] loss: 0.013338687438554188
[Epoch 18, Batch 700] loss: 0.022968031071409312
[Epoch 18, Batch 800] loss: 0.008360102198184904
[Epoch 18, Batch 900] loss: 0.023116826348132235
[Epoch 18, Batch 1000] loss: 0.017133444689106908
[Epoch 18, Batch 1100] loss: 0.018345205227342377
[Epoch 18, Batch 1200] loss: 0.00921422407584032
[Epoch 18, Batch 1300] loss: 0.009808833016977587
[Epoch 18, Batch 1400] loss: 0.010253999224987638
[Epoch 18, Batch 1500] loss: 0.013196931145212148
[Epoch 18, Batch 1600] loss: 0.012096471602405926
[Epoch 18, Batch 1700] loss: 0.014190834708879265
[Epoch 18, Batch 1800] loss: 0.024869482927479113
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0599
Validation Accuracy: 0.9827
Overfitting: 0.0590
[Epoch 19, Batch 100] loss: 0.01814811186690349
[Epoch 19, Batch 200] loss: 0.010185679833939502
[Epoch 19, Batch 300] loss: 0.0064596238592275765
[Epoch 19, Batch 400] loss: 0.007605101380127053
[Epoch 19, Batch 500] loss: 0.01940715203552827
[Epoch 19, Batch 600] loss: 0.00806563658066807
[Epoch 19, Batch 700] loss: 0.013492812894464806
[Epoch 19, Batch 800] loss: 0.025055348027917715
[Epoch 19, Batch 900] loss: 0.014851593688308639
[Epoch 19, Batch 1000] loss: 0.013920043702455587
[Epoch 19, Batch 1100] loss: 0.014788051846990129
[Epoch 19, Batch 1200] loss: 0.008378377397143595
[Epoch 19, Batch 1300] loss: 0.010780283404783405
[Epoch 19, Batch 1400] loss: 0.018334369275726202
[Epoch 19, Batch 1500] loss: 0.0183871434165485
[Epoch 19, Batch 1600] loss: 0.011276575063020574
[Epoch 19, Batch 1700] loss: 0.011280014635090083
[Epoch 19, Batch 1800] loss: 0.013646674553101548
**STATS for Epoch 19** : 
Average training loss: 0.0009
Average validation loss: 0.0609
Validation Accuracy: 0.9827
Overfitting: 0.0600
[Epoch 20, Batch 100] loss: 0.01241233311531687
[Epoch 20, Batch 200] loss: 0.006688665373712865
[Epoch 20, Batch 300] loss: 0.00934390099364009
[Epoch 20, Batch 400] loss: 0.008694082929278011
[Epoch 20, Batch 500] loss: 0.005030781357654632
[Epoch 20, Batch 600] loss: 0.013305979334345465
[Epoch 20, Batch 700] loss: 0.006092912327285376
[Epoch 20, Batch 800] loss: 0.01722700793161039
[Epoch 20, Batch 900] loss: 0.019662522220226037
[Epoch 20, Batch 1000] loss: 0.014617442761846178
[Epoch 20, Batch 1100] loss: 0.02266628495051009
[Epoch 20, Batch 1200] loss: 0.011190033276852774
[Epoch 20, Batch 1300] loss: 0.011881044318124622
[Epoch 20, Batch 1400] loss: 0.011333702971530784
[Epoch 20, Batch 1500] loss: 0.016769815777342954
[Epoch 20, Batch 1600] loss: 0.015302577609809305
[Epoch 20, Batch 1700] loss: 0.008036745711608546
[Epoch 20, Batch 1800] loss: 0.011039702397288237
**STATS for Epoch 20** : 
Average training loss: 0.0008
Average validation loss: 0.0602
Validation Accuracy: 0.9838
Overfitting: 0.0594
[Epoch 21, Batch 100] loss: 0.007743070050337337
[Epoch 21, Batch 200] loss: 0.008965060456289394
[Epoch 21, Batch 300] loss: 0.008896365381633586
[Epoch 21, Batch 400] loss: 0.013738027705385321
[Epoch 21, Batch 500] loss: 0.007643104220251189
[Epoch 21, Batch 600] loss: 0.006878191779869667
[Epoch 21, Batch 700] loss: 0.009445262931062643
[Epoch 21, Batch 800] loss: 0.007247621084375168
[Epoch 21, Batch 900] loss: 0.00864163254953496
[Epoch 21, Batch 1000] loss: 0.009474505767291247
[Epoch 21, Batch 1100] loss: 0.006757940306783894
[Epoch 21, Batch 1200] loss: 0.013379368814407827
[Epoch 21, Batch 1300] loss: 0.015562012152304305
[Epoch 21, Batch 1400] loss: 0.014437560846945417
[Epoch 21, Batch 1500] loss: 0.011795024768325675
[Epoch 21, Batch 1600] loss: 0.014737590268699136
[Epoch 21, Batch 1700] loss: 0.015065304389645462
[Epoch 21, Batch 1800] loss: 0.021345614950328128
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0586
Validation Accuracy: 0.9841
Overfitting: 0.0581
[Epoch 22, Batch 100] loss: 0.013130731213100261
[Epoch 22, Batch 200] loss: 0.017025209088978956
[Epoch 22, Batch 300] loss: 0.008538663920589898
[Epoch 22, Batch 400] loss: 0.005568125392696857
[Epoch 22, Batch 500] loss: 0.0076721650181571024
[Epoch 22, Batch 600] loss: 0.006188579333447706
[Epoch 22, Batch 700] loss: 0.013030026476867533
[Epoch 22, Batch 800] loss: 0.01157763816014267
[Epoch 22, Batch 900] loss: 0.012421385803945669
[Epoch 22, Batch 1000] loss: 0.006732974883780116
[Epoch 22, Batch 1100] loss: 0.006604259581924907
[Epoch 22, Batch 1200] loss: 0.005461288079350197
[Epoch 22, Batch 1300] loss: 0.004935926249781914
[Epoch 22, Batch 1400] loss: 0.010702269794680887
[Epoch 22, Batch 1500] loss: 0.01463428844421287
[Epoch 22, Batch 1600] loss: 0.009578167072995712
[Epoch 22, Batch 1700] loss: 0.009349323296492002
[Epoch 22, Batch 1800] loss: 0.008522504540555928
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0588
Validation Accuracy: 0.9850
Overfitting: 0.0582
[Epoch 23, Batch 100] loss: 0.007917983108250155
[Epoch 23, Batch 200] loss: 0.010767697907822367
[Epoch 23, Batch 300] loss: 0.017799299199796222
[Epoch 23, Batch 400] loss: 0.006648397852122798
[Epoch 23, Batch 500] loss: 0.007445564652134635
[Epoch 23, Batch 600] loss: 0.009426018837302763
[Epoch 23, Batch 700] loss: 0.009060603988036747
[Epoch 23, Batch 800] loss: 0.011834939558787028
[Epoch 23, Batch 900] loss: 0.007185475110750303
[Epoch 23, Batch 1000] loss: 0.0033305371026676766
[Epoch 23, Batch 1100] loss: 0.00501311547754085
[Epoch 23, Batch 1200] loss: 0.0045466316238798755
[Epoch 23, Batch 1300] loss: 0.007112363600977005
[Epoch 23, Batch 1400] loss: 0.003981444460259808
[Epoch 23, Batch 1500] loss: 0.005573820030440402
[Epoch 23, Batch 1600] loss: 0.007366511005134271
[Epoch 23, Batch 1700] loss: 0.012588300028442063
[Epoch 23, Batch 1800] loss: 0.016555162970184938
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0668
Validation Accuracy: 0.9831
Overfitting: 0.0664
[Epoch 24, Batch 100] loss: 0.010809140253795703
[Epoch 24, Batch 200] loss: 0.0038271417484270387
[Epoch 24, Batch 300] loss: 0.007750782040629929
[Epoch 24, Batch 400] loss: 0.005503738495362996
[Epoch 24, Batch 500] loss: 0.0035573623303531577
[Epoch 24, Batch 600] loss: 0.004398394186043788
[Epoch 24, Batch 700] loss: 0.005665028346074905
[Epoch 24, Batch 800] loss: 0.019031808667041333
[Epoch 24, Batch 900] loss: 0.0076342736067908845
[Epoch 24, Batch 1000] loss: 0.0054262918520430505
[Epoch 24, Batch 1100] loss: 0.01151103933336799
[Epoch 24, Batch 1200] loss: 0.010433704682875487
[Epoch 24, Batch 1300] loss: 0.005264392733115528
[Epoch 24, Batch 1400] loss: 0.005897820736267931
[Epoch 24, Batch 1500] loss: 0.004568656863752949
[Epoch 24, Batch 1600] loss: 0.004901960851332206
[Epoch 24, Batch 1700] loss: 0.01043398749281252
[Epoch 24, Batch 1800] loss: 0.007961145198714803
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0597
Validation Accuracy: 0.9849
Overfitting: 0.0594
Fold 1 validation loss: 0.0597
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.294465548992157
[Epoch 1, Batch 200] loss: 2.274897835254669
[Epoch 1, Batch 300] loss: 2.2416848015785216
[Epoch 1, Batch 400] loss: 2.144875522851944
[Epoch 1, Batch 500] loss: 1.7547002601623536
[Epoch 1, Batch 600] loss: 1.0155534064769745
[Epoch 1, Batch 700] loss: 0.6538350763916969
[Epoch 1, Batch 800] loss: 0.5482774324715137
[Epoch 1, Batch 900] loss: 0.4474426102638245
[Epoch 1, Batch 1000] loss: 0.41278058383613825
[Epoch 1, Batch 1100] loss: 0.3453949420899153
[Epoch 1, Batch 1200] loss: 0.39665980510413645
[Epoch 1, Batch 1300] loss: 0.3492752816900611
[Epoch 1, Batch 1400] loss: 0.31691050097346307
[Epoch 1, Batch 1500] loss: 0.3176927365735173
[Epoch 1, Batch 1600] loss: 0.2722727736830711
[Epoch 1, Batch 1700] loss: 0.2767079274728894
[Epoch 1, Batch 1800] loss: 0.2613747931458056
**STATS for Epoch 1** : 
Average training loss: 0.0083
Average validation loss: 0.2360
Validation Accuracy: 0.9278
Overfitting: 0.2277
Best model saved at epoch 1 with validation loss: 0.2360
[Epoch 2, Batch 100] loss: 0.2539446358196437
[Epoch 2, Batch 200] loss: 0.21604185305535795
[Epoch 2, Batch 300] loss: 0.22251033309847115
[Epoch 2, Batch 400] loss: 0.24067463735118508
[Epoch 2, Batch 500] loss: 0.21969281680881977
[Epoch 2, Batch 600] loss: 0.19275551493279636
[Epoch 2, Batch 700] loss: 0.1873553346283734
[Epoch 2, Batch 800] loss: 0.18189885664731265
[Epoch 2, Batch 900] loss: 0.1727498722076416
[Epoch 2, Batch 1000] loss: 0.19479985540732742
[Epoch 2, Batch 1100] loss: 0.12914189259754494
[Epoch 2, Batch 1200] loss: 0.13638080517761408
[Epoch 2, Batch 1300] loss: 0.13828953223302962
[Epoch 2, Batch 1400] loss: 0.16224679947830736
[Epoch 2, Batch 1500] loss: 0.1689163152500987
[Epoch 2, Batch 1600] loss: 0.1522274582274258
[Epoch 2, Batch 1700] loss: 0.15069162892643362
[Epoch 2, Batch 1800] loss: 0.1199978265631944
**STATS for Epoch 2** : 
Average training loss: 0.0055
Average validation loss: 0.1364
Validation Accuracy: 0.9592
Overfitting: 0.1310
Best model saved at epoch 2 with validation loss: 0.1364
[Epoch 3, Batch 100] loss: 0.13947396466508508
[Epoch 3, Batch 200] loss: 0.12219817291945219
[Epoch 3, Batch 300] loss: 0.1401643655076623
[Epoch 3, Batch 400] loss: 0.12327411881182343
[Epoch 3, Batch 500] loss: 0.14730575684458017
[Epoch 3, Batch 600] loss: 0.12729777224361896
[Epoch 3, Batch 700] loss: 0.1106691290717572
[Epoch 3, Batch 800] loss: 0.1259348379820585
[Epoch 3, Batch 900] loss: 0.11746914324117824
[Epoch 3, Batch 1000] loss: 0.13355856758076698
[Epoch 3, Batch 1100] loss: 0.12949657392688096
[Epoch 3, Batch 1200] loss: 0.11027147356420755
[Epoch 3, Batch 1300] loss: 0.13337598031153902
[Epoch 3, Batch 1400] loss: 0.09651676836423576
[Epoch 3, Batch 1500] loss: 0.07921401872648857
[Epoch 3, Batch 1600] loss: 0.08712810207856819
[Epoch 3, Batch 1700] loss: 0.08281546105630695
[Epoch 3, Batch 1800] loss: 0.11006718023214489
**STATS for Epoch 3** : 
Average training loss: 0.0039
Average validation loss: 0.0979
Validation Accuracy: 0.9695
Overfitting: 0.0940
Best model saved at epoch 3 with validation loss: 0.0979
[Epoch 4, Batch 100] loss: 0.08231358536402694
[Epoch 4, Batch 200] loss: 0.0849669666076079
[Epoch 4, Batch 300] loss: 0.10629855486331508
[Epoch 4, Batch 400] loss: 0.08604547862429172
[Epoch 4, Batch 500] loss: 0.10381856822408736
[Epoch 4, Batch 600] loss: 0.09246265813941136
[Epoch 4, Batch 700] loss: 0.0888221273641102
[Epoch 4, Batch 800] loss: 0.08340578403905965
[Epoch 4, Batch 900] loss: 0.1070863615523558
[Epoch 4, Batch 1000] loss: 0.08987118917517364
[Epoch 4, Batch 1100] loss: 0.08155172289756592
[Epoch 4, Batch 1200] loss: 0.09417668820824474
[Epoch 4, Batch 1300] loss: 0.09362341824918985
[Epoch 4, Batch 1400] loss: 0.09646883741719649
[Epoch 4, Batch 1500] loss: 0.09778367369668559
[Epoch 4, Batch 1600] loss: 0.07448945436161011
[Epoch 4, Batch 1700] loss: 0.08665857169311493
[Epoch 4, Batch 1800] loss: 0.07297487478586845
**STATS for Epoch 4** : 
Average training loss: 0.0035
Average validation loss: 0.0898
Validation Accuracy: 0.9724
Overfitting: 0.0863
Best model saved at epoch 4 with validation loss: 0.0898
[Epoch 5, Batch 100] loss: 0.07353010387625546
[Epoch 5, Batch 200] loss: 0.06937032228102907
[Epoch 5, Batch 300] loss: 0.0665353974129539
[Epoch 5, Batch 400] loss: 0.08199750376399606
[Epoch 5, Batch 500] loss: 0.07335029045119881
[Epoch 5, Batch 600] loss: 0.06711093015153892
[Epoch 5, Batch 700] loss: 0.08695785324962343
[Epoch 5, Batch 800] loss: 0.10034175761276856
[Epoch 5, Batch 900] loss: 0.07443212115380447
[Epoch 5, Batch 1000] loss: 0.06636140442453325
[Epoch 5, Batch 1100] loss: 0.07886294626223389
[Epoch 5, Batch 1200] loss: 0.07053151987260207
[Epoch 5, Batch 1300] loss: 0.051687052753986794
[Epoch 5, Batch 1400] loss: 0.060958684915676714
[Epoch 5, Batch 1500] loss: 0.07606374372844585
[Epoch 5, Batch 1600] loss: 0.08533627117460128
[Epoch 5, Batch 1700] loss: 0.07517310707480647
[Epoch 5, Batch 1800] loss: 0.06438052462064661
**STATS for Epoch 5** : 
Average training loss: 0.0026
Average validation loss: 0.0750
Validation Accuracy: 0.9764
Overfitting: 0.0723
Best model saved at epoch 5 with validation loss: 0.0750
[Epoch 6, Batch 100] loss: 0.06141263792174868
[Epoch 6, Batch 200] loss: 0.0654560252733063
[Epoch 6, Batch 300] loss: 0.06680761162540876
[Epoch 6, Batch 400] loss: 0.05325167061702814
[Epoch 6, Batch 500] loss: 0.061526099200127644
[Epoch 6, Batch 600] loss: 0.08132771346427034
[Epoch 6, Batch 700] loss: 0.07810749236959964
[Epoch 6, Batch 800] loss: 0.05791518716956489
[Epoch 6, Batch 900] loss: 0.0479473806306487
[Epoch 6, Batch 1000] loss: 0.061841103326296436
[Epoch 6, Batch 1100] loss: 0.06342301588854753
[Epoch 6, Batch 1200] loss: 0.0642012313666055
[Epoch 6, Batch 1300] loss: 0.03905650805681944
[Epoch 6, Batch 1400] loss: 0.06741877189837396
[Epoch 6, Batch 1500] loss: 0.061514461433980615
[Epoch 6, Batch 1600] loss: 0.05140844198584091
[Epoch 6, Batch 1700] loss: 0.05610097878845408
[Epoch 6, Batch 1800] loss: 0.0663676345651038
**STATS for Epoch 6** : 
Average training loss: 0.0034
Average validation loss: 0.0729
Validation Accuracy: 0.9769
Overfitting: 0.0695
Best model saved at epoch 6 with validation loss: 0.0729
[Epoch 7, Batch 100] loss: 0.04354209226905368
[Epoch 7, Batch 200] loss: 0.05165037306578597
[Epoch 7, Batch 300] loss: 0.05189218296727631
[Epoch 7, Batch 400] loss: 0.06314739776425995
[Epoch 7, Batch 500] loss: 0.05682244610856287
[Epoch 7, Batch 600] loss: 0.05603212557703955
[Epoch 7, Batch 700] loss: 0.0621832942214678
[Epoch 7, Batch 800] loss: 0.05946559460193385
[Epoch 7, Batch 900] loss: 0.07281506196595729
[Epoch 7, Batch 1000] loss: 0.059037996426341124
[Epoch 7, Batch 1100] loss: 0.04114723863545805
[Epoch 7, Batch 1200] loss: 0.053527755053946746
[Epoch 7, Batch 1300] loss: 0.05178649145847885
[Epoch 7, Batch 1400] loss: 0.052299759094021285
[Epoch 7, Batch 1500] loss: 0.05105183668609243
[Epoch 7, Batch 1600] loss: 0.03137103578541428
[Epoch 7, Batch 1700] loss: 0.05456590130692348
[Epoch 7, Batch 1800] loss: 0.04238578924516332
**STATS for Epoch 7** : 
Average training loss: 0.0018
Average validation loss: 0.0640
Validation Accuracy: 0.9804
Overfitting: 0.0623
Best model saved at epoch 7 with validation loss: 0.0640
[Epoch 8, Batch 100] loss: 0.04873003321205033
[Epoch 8, Batch 200] loss: 0.06550301347044296
[Epoch 8, Batch 300] loss: 0.04773693770868704
[Epoch 8, Batch 400] loss: 0.05590677165193483
[Epoch 8, Batch 500] loss: 0.05689134076179471
[Epoch 8, Batch 600] loss: 0.03967802404280519
[Epoch 8, Batch 700] loss: 0.038247048890334555
[Epoch 8, Batch 800] loss: 0.045485696769319475
[Epoch 8, Batch 900] loss: 0.04340613561682403
[Epoch 8, Batch 1000] loss: 0.06058033617213368
[Epoch 8, Batch 1100] loss: 0.04014219130651327
[Epoch 8, Batch 1200] loss: 0.032393518328899515
[Epoch 8, Batch 1300] loss: 0.041733045097789724
[Epoch 8, Batch 1400] loss: 0.04096617860268452
[Epoch 8, Batch 1500] loss: 0.040560745997936465
[Epoch 8, Batch 1600] loss: 0.04282477417556947
[Epoch 8, Batch 1700] loss: 0.040311013669124804
[Epoch 8, Batch 1800] loss: 0.04687952283449704
**STATS for Epoch 8** : 
Average training loss: 0.0022
Average validation loss: 0.0671
Validation Accuracy: 0.9792
Overfitting: 0.0649
[Epoch 9, Batch 100] loss: 0.04037883333687205
[Epoch 9, Batch 200] loss: 0.03510578587316559
[Epoch 9, Batch 300] loss: 0.03446533402151544
[Epoch 9, Batch 400] loss: 0.04466550468183414
[Epoch 9, Batch 500] loss: 0.03280393170600291
[Epoch 9, Batch 600] loss: 0.03410980836924864
[Epoch 9, Batch 700] loss: 0.03992277416225989
[Epoch 9, Batch 800] loss: 0.045619374067318856
[Epoch 9, Batch 900] loss: 0.04449352628056658
[Epoch 9, Batch 1000] loss: 0.050165917667618486
[Epoch 9, Batch 1100] loss: 0.051527179362019525
[Epoch 9, Batch 1200] loss: 0.039281893221777865
[Epoch 9, Batch 1300] loss: 0.03434588216070551
[Epoch 9, Batch 1400] loss: 0.045790266349213196
[Epoch 9, Batch 1500] loss: 0.045635560426162555
[Epoch 9, Batch 1600] loss: 0.042688598383101635
[Epoch 9, Batch 1700] loss: 0.03684348119946662
[Epoch 9, Batch 1800] loss: 0.039816438585403374
**STATS for Epoch 9** : 
Average training loss: 0.0011
Average validation loss: 0.0619
Validation Accuracy: 0.9815
Overfitting: 0.0608
Best model saved at epoch 9 with validation loss: 0.0619
[Epoch 10, Batch 100] loss: 0.047567063921596854
[Epoch 10, Batch 200] loss: 0.03999883292170125
[Epoch 10, Batch 300] loss: 0.037764749407506314
[Epoch 10, Batch 400] loss: 0.03268482551255147
[Epoch 10, Batch 500] loss: 0.035930651893722826
[Epoch 10, Batch 600] loss: 0.033040381957835055
[Epoch 10, Batch 700] loss: 0.03283943363203434
[Epoch 10, Batch 800] loss: 0.03110037936225126
[Epoch 10, Batch 900] loss: 0.036019610648509115
[Epoch 10, Batch 1000] loss: 0.03512313609186094
[Epoch 10, Batch 1100] loss: 0.0302146337787417
[Epoch 10, Batch 1200] loss: 0.03020656032473198
[Epoch 10, Batch 1300] loss: 0.04211580203700578
[Epoch 10, Batch 1400] loss: 0.0286650203060708
[Epoch 10, Batch 1500] loss: 0.040247311338971484
[Epoch 10, Batch 1600] loss: 0.042498796733561904
[Epoch 10, Batch 1700] loss: 0.03567834225686965
[Epoch 10, Batch 1800] loss: 0.035951093306357505
**STATS for Epoch 10** : 
Average training loss: 0.0015
Average validation loss: 0.0731
Validation Accuracy: 0.9776
Overfitting: 0.0716
[Epoch 11, Batch 100] loss: 0.04148593911260832
[Epoch 11, Batch 200] loss: 0.02929006041260436
[Epoch 11, Batch 300] loss: 0.03650418093340704
[Epoch 11, Batch 400] loss: 0.027753624570541435
[Epoch 11, Batch 500] loss: 0.04006464108882937
[Epoch 11, Batch 600] loss: 0.02719570933812065
[Epoch 11, Batch 700] loss: 0.017123407552717254
[Epoch 11, Batch 800] loss: 0.03118340022934717
[Epoch 11, Batch 900] loss: 0.031895848101266895
[Epoch 11, Batch 1000] loss: 0.028138759099438176
[Epoch 11, Batch 1100] loss: 0.037459262995107566
[Epoch 11, Batch 1200] loss: 0.03941124896053225
[Epoch 11, Batch 1300] loss: 0.038197659189609115
[Epoch 11, Batch 1400] loss: 0.028294871953257826
[Epoch 11, Batch 1500] loss: 0.024666656305198556
[Epoch 11, Batch 1600] loss: 0.039336701248103054
[Epoch 11, Batch 1700] loss: 0.03772106388641987
[Epoch 11, Batch 1800] loss: 0.025233501953989615
**STATS for Epoch 11** : 
Average training loss: 0.0019
Average validation loss: 0.0681
Validation Accuracy: 0.9803
Overfitting: 0.0662
[Epoch 12, Batch 100] loss: 0.031246228129894006
[Epoch 12, Batch 200] loss: 0.029756722360143612
[Epoch 12, Batch 300] loss: 0.020639054382481845
[Epoch 12, Batch 400] loss: 0.032495702990272546
[Epoch 12, Batch 500] loss: 0.03747253793735581
[Epoch 12, Batch 600] loss: 0.0208631446029176
[Epoch 12, Batch 700] loss: 0.03294749102176866
[Epoch 12, Batch 800] loss: 0.027212508634111145
[Epoch 12, Batch 900] loss: 0.02986504525775672
[Epoch 12, Batch 1000] loss: 0.03289053451211657
[Epoch 12, Batch 1100] loss: 0.03103283796139294
[Epoch 12, Batch 1200] loss: 0.032090962010843216
[Epoch 12, Batch 1300] loss: 0.039001804729705325
[Epoch 12, Batch 1400] loss: 0.02799927848667721
[Epoch 12, Batch 1500] loss: 0.03064276670840627
[Epoch 12, Batch 1600] loss: 0.03562741970490606
[Epoch 12, Batch 1700] loss: 0.031114575882529607
[Epoch 12, Batch 1800] loss: 0.033128510542737785
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0694
Validation Accuracy: 0.9794
Overfitting: 0.0684
[Epoch 13, Batch 100] loss: 0.03321396825791453
[Epoch 13, Batch 200] loss: 0.021916435909806752
[Epoch 13, Batch 300] loss: 0.019055593155389943
[Epoch 13, Batch 400] loss: 0.013781785770333954
[Epoch 13, Batch 500] loss: 0.02666554828523658
[Epoch 13, Batch 600] loss: 0.021822963473387063
[Epoch 13, Batch 700] loss: 0.022872105100832416
[Epoch 13, Batch 800] loss: 0.02273490046936786
[Epoch 13, Batch 900] loss: 0.024577034625181113
[Epoch 13, Batch 1000] loss: 0.041451548644108695
[Epoch 13, Batch 1100] loss: 0.03737922510350472
[Epoch 13, Batch 1200] loss: 0.025351514935755402
[Epoch 13, Batch 1300] loss: 0.02183253416995285
[Epoch 13, Batch 1400] loss: 0.028238847110260396
[Epoch 13, Batch 1500] loss: 0.028810361990181263
[Epoch 13, Batch 1600] loss: 0.030835255086785765
[Epoch 13, Batch 1700] loss: 0.022881117994402303
[Epoch 13, Batch 1800] loss: 0.028322119950753403
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0651
Validation Accuracy: 0.9805
Overfitting: 0.0641
[Epoch 14, Batch 100] loss: 0.023545314918919757
[Epoch 14, Batch 200] loss: 0.02483906458088313
[Epoch 14, Batch 300] loss: 0.018558493949039984
[Epoch 14, Batch 400] loss: 0.021637696483630862
[Epoch 14, Batch 500] loss: 0.021570848853552888
[Epoch 14, Batch 600] loss: 0.02148226163139043
[Epoch 14, Batch 700] loss: 0.027080215378446154
[Epoch 14, Batch 800] loss: 0.022222073696066217
[Epoch 14, Batch 900] loss: 0.023800840645781137
[Epoch 14, Batch 1000] loss: 0.020090143835768685
[Epoch 14, Batch 1100] loss: 0.027925508366679425
[Epoch 14, Batch 1200] loss: 0.01826396312128054
[Epoch 14, Batch 1300] loss: 0.03960669267413323
[Epoch 14, Batch 1400] loss: 0.02544383280808688
[Epoch 14, Batch 1500] loss: 0.018493974713783244
[Epoch 14, Batch 1600] loss: 0.023829901497301763
[Epoch 14, Batch 1700] loss: 0.029806497736426536
[Epoch 14, Batch 1800] loss: 0.03145775073928234
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0523
Validation Accuracy: 0.9845
Overfitting: 0.0516
Best model saved at epoch 14 with validation loss: 0.0523
[Epoch 15, Batch 100] loss: 0.016282891802911762
[Epoch 15, Batch 200] loss: 0.014422279449972849
[Epoch 15, Batch 300] loss: 0.021047488283984422
[Epoch 15, Batch 400] loss: 0.01721444629945836
[Epoch 15, Batch 500] loss: 0.015528991723440412
[Epoch 15, Batch 600] loss: 0.017264338297791254
[Epoch 15, Batch 700] loss: 0.0353017870747135
[Epoch 15, Batch 800] loss: 0.01606722488286323
[Epoch 15, Batch 900] loss: 0.01685779641444242
[Epoch 15, Batch 1000] loss: 0.028631121938233264
[Epoch 15, Batch 1100] loss: 0.029275643686414696
[Epoch 15, Batch 1200] loss: 0.02199296814505942
[Epoch 15, Batch 1300] loss: 0.01753704414702952
[Epoch 15, Batch 1400] loss: 0.03940038168722822
[Epoch 15, Batch 1500] loss: 0.021756164753169285
[Epoch 15, Batch 1600] loss: 0.02522936451343412
[Epoch 15, Batch 1700] loss: 0.015674010780394383
[Epoch 15, Batch 1800] loss: 0.02480698509382819
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0509
Validation Accuracy: 0.9849
Overfitting: 0.0505
Best model saved at epoch 15 with validation loss: 0.0509
[Epoch 16, Batch 100] loss: 0.02042747865016281
[Epoch 16, Batch 200] loss: 0.01988920569041511
[Epoch 16, Batch 300] loss: 0.017537060305839985
[Epoch 16, Batch 400] loss: 0.021278239760940777
[Epoch 16, Batch 500] loss: 0.014944525109385723
[Epoch 16, Batch 600] loss: 0.017235555026672955
[Epoch 16, Batch 700] loss: 0.021427294895729573
[Epoch 16, Batch 800] loss: 0.012580224931080011
[Epoch 16, Batch 900] loss: 0.01894692787387612
[Epoch 16, Batch 1000] loss: 0.012482445489513338
[Epoch 16, Batch 1100] loss: 0.018997756603348535
[Epoch 16, Batch 1200] loss: 0.015536717792756463
[Epoch 16, Batch 1300] loss: 0.020914209697948535
[Epoch 16, Batch 1400] loss: 0.02245328977551253
[Epoch 16, Batch 1500] loss: 0.017262619624707442
[Epoch 16, Batch 1600] loss: 0.0240135345008639
[Epoch 16, Batch 1700] loss: 0.02691030371141096
[Epoch 16, Batch 1800] loss: 0.014641237263640505
**STATS for Epoch 16** : 
Average training loss: 0.0008
Average validation loss: 0.0556
Validation Accuracy: 0.9848
Overfitting: 0.0548
[Epoch 17, Batch 100] loss: 0.0083528176902837
[Epoch 17, Batch 200] loss: 0.020760644159308866
[Epoch 17, Batch 300] loss: 0.012968214409156645
[Epoch 17, Batch 400] loss: 0.014986089602061839
[Epoch 17, Batch 500] loss: 0.0123158521660298
[Epoch 17, Batch 600] loss: 0.021002294645568326
[Epoch 17, Batch 700] loss: 0.011516937456926826
[Epoch 17, Batch 800] loss: 0.017600165451522116
[Epoch 17, Batch 900] loss: 0.017804935769054283
[Epoch 17, Batch 1000] loss: 0.018563056876300835
[Epoch 17, Batch 1100] loss: 0.014149117959350406
[Epoch 17, Batch 1200] loss: 0.01445934437066171
[Epoch 17, Batch 1300] loss: 0.019466237409596944
[Epoch 17, Batch 1400] loss: 0.02224789140490884
[Epoch 17, Batch 1500] loss: 0.027241975057640956
[Epoch 17, Batch 1600] loss: 0.015506729125700076
[Epoch 17, Batch 1700] loss: 0.013179234465860645
[Epoch 17, Batch 1800] loss: 0.03893402106419672
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0669
Validation Accuracy: 0.9811
Overfitting: 0.0662
[Epoch 18, Batch 100] loss: 0.01095662343251206
[Epoch 18, Batch 200] loss: 0.010012069623408025
[Epoch 18, Batch 300] loss: 0.014324668898625532
[Epoch 18, Batch 400] loss: 0.012494957015951514
[Epoch 18, Batch 500] loss: 0.02521000967994496
[Epoch 18, Batch 600] loss: 0.019244262975498715
[Epoch 18, Batch 700] loss: 0.013559413039911306
[Epoch 18, Batch 800] loss: 0.011825550197063422
[Epoch 18, Batch 900] loss: 0.017443145650686345
[Epoch 18, Batch 1000] loss: 0.015639255558016884
[Epoch 18, Batch 1100] loss: 0.014186867378948592
[Epoch 18, Batch 1200] loss: 0.01738815260690899
[Epoch 18, Batch 1300] loss: 0.007930462768536017
[Epoch 18, Batch 1400] loss: 0.021254233765585013
[Epoch 18, Batch 1500] loss: 0.018469788664115184
[Epoch 18, Batch 1600] loss: 0.016341277230549168
[Epoch 18, Batch 1700] loss: 0.016184138439566596
[Epoch 18, Batch 1800] loss: 0.010887276400735573
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0550
Validation Accuracy: 0.9844
Overfitting: 0.0543
[Epoch 19, Batch 100] loss: 0.012503301837696199
[Epoch 19, Batch 200] loss: 0.011692139350116123
[Epoch 19, Batch 300] loss: 0.013101558299167664
[Epoch 19, Batch 400] loss: 0.015352347305288276
[Epoch 19, Batch 500] loss: 0.006623495898129477
[Epoch 19, Batch 600] loss: 0.013669624723224843
[Epoch 19, Batch 700] loss: 0.0200907172126972
[Epoch 19, Batch 800] loss: 0.009119924096248724
[Epoch 19, Batch 900] loss: 0.020097735590152297
[Epoch 19, Batch 1000] loss: 0.012592604928267975
[Epoch 19, Batch 1100] loss: 0.010852470651657313
[Epoch 19, Batch 1200] loss: 0.013234226031145227
[Epoch 19, Batch 1300] loss: 0.008304907886194996
[Epoch 19, Batch 1400] loss: 0.009188357386105963
[Epoch 19, Batch 1500] loss: 0.019188883184779116
[Epoch 19, Batch 1600] loss: 0.022415233473220723
[Epoch 19, Batch 1700] loss: 0.019371909518085886
[Epoch 19, Batch 1800] loss: 0.016080735791274493
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0592
Validation Accuracy: 0.9834
Overfitting: 0.0586
[Epoch 20, Batch 100] loss: 0.02054861703115421
[Epoch 20, Batch 200] loss: 0.010942274513035954
[Epoch 20, Batch 300] loss: 0.008643790796038503
[Epoch 20, Batch 400] loss: 0.010287567217637843
[Epoch 20, Batch 500] loss: 0.014651620619879395
[Epoch 20, Batch 600] loss: 0.014483048991914984
[Epoch 20, Batch 700] loss: 0.01331771929711067
[Epoch 20, Batch 800] loss: 0.010332718037552695
[Epoch 20, Batch 900] loss: 0.01501892174988825
[Epoch 20, Batch 1000] loss: 0.012494672923494363
[Epoch 20, Batch 1100] loss: 0.0064490282956830925
[Epoch 20, Batch 1200] loss: 0.011889436423343796
[Epoch 20, Batch 1300] loss: 0.010314286778675524
[Epoch 20, Batch 1400] loss: 0.015588560952346597
[Epoch 20, Batch 1500] loss: 0.012616028714546701
[Epoch 20, Batch 1600] loss: 0.008719684989432607
[Epoch 20, Batch 1700] loss: 0.015222161961223718
[Epoch 20, Batch 1800] loss: 0.010319881109785456
**STATS for Epoch 20** : 
Average training loss: 0.0007
Average validation loss: 0.0573
Validation Accuracy: 0.9845
Overfitting: 0.0566
[Epoch 21, Batch 100] loss: 0.011985769855955368
[Epoch 21, Batch 200] loss: 0.004955988832971343
[Epoch 21, Batch 300] loss: 0.006724320877201535
[Epoch 21, Batch 400] loss: 0.009132463628106961
[Epoch 21, Batch 500] loss: 0.0077364704630872435
[Epoch 21, Batch 600] loss: 0.006313751479865459
[Epoch 21, Batch 700] loss: 0.012060939679568037
[Epoch 21, Batch 800] loss: 0.00804552391639845
[Epoch 21, Batch 900] loss: 0.013372784915136436
[Epoch 21, Batch 1000] loss: 0.01861339317334114
[Epoch 21, Batch 1100] loss: 0.017843621843530853
[Epoch 21, Batch 1200] loss: 0.014209580477731833
[Epoch 21, Batch 1300] loss: 0.021028335005785267
[Epoch 21, Batch 1400] loss: 0.013264062595235373
[Epoch 21, Batch 1500] loss: 0.015043227344699516
[Epoch 21, Batch 1600] loss: 0.014072831263920307
[Epoch 21, Batch 1700] loss: 0.008468067917137887
[Epoch 21, Batch 1800] loss: 0.01538196337932277
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0656
Validation Accuracy: 0.9825
Overfitting: 0.0650
[Epoch 22, Batch 100] loss: 0.008524960027207271
[Epoch 22, Batch 200] loss: 0.011471062642494872
[Epoch 22, Batch 300] loss: 0.0069101461038917475
[Epoch 22, Batch 400] loss: 0.005055576626580205
[Epoch 22, Batch 500] loss: 0.007172790654730079
[Epoch 22, Batch 600] loss: 0.0032721663268876
[Epoch 22, Batch 700] loss: 0.011916266962853115
[Epoch 22, Batch 800] loss: 0.009937483397334291
[Epoch 22, Batch 900] loss: 0.0049777658578636875
[Epoch 22, Batch 1000] loss: 0.009706083344553917
[Epoch 22, Batch 1100] loss: 0.012566810442242513
[Epoch 22, Batch 1200] loss: 0.012841515808340774
[Epoch 22, Batch 1300] loss: 0.005622432640079751
[Epoch 22, Batch 1400] loss: 0.007827095305729018
[Epoch 22, Batch 1500] loss: 0.00856544649604075
[Epoch 22, Batch 1600] loss: 0.014013527822062315
[Epoch 22, Batch 1700] loss: 0.0066342869983236595
[Epoch 22, Batch 1800] loss: 0.008523629401524886
**STATS for Epoch 22** : 
Average training loss: 0.0008
Average validation loss: 0.0677
Validation Accuracy: 0.9824
Overfitting: 0.0669
[Epoch 23, Batch 100] loss: 0.011470189557257982
[Epoch 23, Batch 200] loss: 0.012731181638273484
[Epoch 23, Batch 300] loss: 0.011031533214018055
[Epoch 23, Batch 400] loss: 0.015227368338146334
[Epoch 23, Batch 500] loss: 0.00805868498892778
[Epoch 23, Batch 600] loss: 0.01021468924027431
[Epoch 23, Batch 700] loss: 0.006034289180852284
[Epoch 23, Batch 800] loss: 0.013577340714909951
[Epoch 23, Batch 900] loss: 0.0040968076681747335
[Epoch 23, Batch 1000] loss: 0.00771963644000607
[Epoch 23, Batch 1100] loss: 0.013673381653175056
[Epoch 23, Batch 1200] loss: 0.017473215157624507
[Epoch 23, Batch 1300] loss: 0.013182296167979075
[Epoch 23, Batch 1400] loss: 0.007373760318447466
[Epoch 23, Batch 1500] loss: 0.01296006271881197
[Epoch 23, Batch 1600] loss: 0.009338895081991722
[Epoch 23, Batch 1700] loss: 0.010018216026592199
[Epoch 23, Batch 1800] loss: 0.008051456056939514
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0617
Validation Accuracy: 0.9844
Overfitting: 0.0614
[Epoch 24, Batch 100] loss: 0.003219218576439289
[Epoch 24, Batch 200] loss: 0.009869648455769493
[Epoch 24, Batch 300] loss: 0.007597837040584636
[Epoch 24, Batch 400] loss: 0.008161910451676704
[Epoch 24, Batch 500] loss: 0.008770125335258854
[Epoch 24, Batch 600] loss: 0.003065488531747178
[Epoch 24, Batch 700] loss: 0.007477055784358413
[Epoch 24, Batch 800] loss: 0.009705321234673648
[Epoch 24, Batch 900] loss: 0.012341537099609922
[Epoch 24, Batch 1000] loss: 0.00870481668596085
[Epoch 24, Batch 1100] loss: 0.009615997208084082
[Epoch 24, Batch 1200] loss: 0.007990415478598151
[Epoch 24, Batch 1300] loss: 0.008410205946888709
[Epoch 24, Batch 1400] loss: 0.007570973535221129
[Epoch 24, Batch 1500] loss: 0.011118522093117917
[Epoch 24, Batch 1600] loss: 0.008163789896455
[Epoch 24, Batch 1700] loss: 0.005557986624463638
[Epoch 24, Batch 1800] loss: 0.006523695674195551
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0658
Validation Accuracy: 0.9832
Overfitting: 0.0656
Fold 2 validation loss: 0.0658
Mean validation loss across all folds for Trial 3 is 0.0628 with trial config:  l1: 128, l2: 128, lr: 0.0006672367170464204, batch_size: 16
[I 2024-11-21 18:00:04,945] Trial 2 finished with value: 0.06275290202573758 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 4:
  l1: 128, l2: 128, lr: 0.07286653737491042, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.976794649362564
[Epoch 1, Batch 200] loss: 1.7520852613449096
[Epoch 1, Batch 300] loss: 1.5316461980342866
[Epoch 1, Batch 400] loss: 1.5572682377696037
[Epoch 1, Batch 500] loss: 1.3218606451153756
[Epoch 1, Batch 600] loss: 1.2217635810375214
[Epoch 1, Batch 700] loss: 1.2639872580766678
[Epoch 1, Batch 800] loss: 1.2247250598669053
[Epoch 1, Batch 900] loss: 1.1628744128346442
[Epoch 1, Batch 1000] loss: 1.4935701102018357
[Epoch 1, Batch 1100] loss: 1.524070953130722
[Epoch 1, Batch 1200] loss: 1.2914527702331542
[Epoch 1, Batch 1300] loss: 1.7544138842821122
[Epoch 1, Batch 1400] loss: 2.449535154104233
[Epoch 1, Batch 1500] loss: 2.3136607837677
[Epoch 1, Batch 1600] loss: 2.3144064807891844
[Epoch 1, Batch 1700] loss: 2.3147880101203917
[Epoch 1, Batch 1800] loss: 2.3031088638305666
**STATS for Epoch 1** : 
Average training loss: 0.0926
Average validation loss: 2.3195
Validation Accuracy: 0.0986
Overfitting: 2.2269
Best model saved at epoch 1 with validation loss: 2.3195
[Epoch 2, Batch 100] loss: 2.3119782280921934
[Epoch 2, Batch 200] loss: 2.3058370542526245
[Epoch 2, Batch 300] loss: 2.312542736530304
[Epoch 2, Batch 400] loss: 2.313803515434265
[Epoch 2, Batch 500] loss: 2.310574929714203
[Epoch 2, Batch 600] loss: 2.3113451337814332
[Epoch 2, Batch 700] loss: 2.309700064659119
[Epoch 2, Batch 800] loss: 2.3164909648895264
[Epoch 2, Batch 900] loss: 2.314157691001892
[Epoch 2, Batch 1000] loss: 2.3077665066719053
[Epoch 2, Batch 1100] loss: 2.3125694608688354
[Epoch 2, Batch 1200] loss: 2.312137017250061
[Epoch 2, Batch 1300] loss: 2.310258004665375
[Epoch 2, Batch 1400] loss: 2.31255357503891
[Epoch 2, Batch 1500] loss: 2.318054678440094
[Epoch 2, Batch 1600] loss: 2.311152925491333
[Epoch 2, Batch 1700] loss: 2.310955364704132
[Epoch 2, Batch 1800] loss: 2.310277099609375
**STATS for Epoch 2** : 
Average training loss: 0.0925
Average validation loss: 2.3107
Validation Accuracy: 0.1007
Overfitting: 2.2182
Best model saved at epoch 2 with validation loss: 2.3107
[Epoch 3, Batch 100] loss: 2.3138516044616697
[Epoch 3, Batch 200] loss: 2.3114977407455446
[Epoch 3, Batch 300] loss: 2.3113250589370726
[Epoch 3, Batch 400] loss: 2.313483803272247
[Epoch 3, Batch 500] loss: 2.3148802757263183
[Epoch 3, Batch 600] loss: 2.3143763399124144
[Epoch 3, Batch 700] loss: 2.312362539768219
[Epoch 3, Batch 800] loss: 2.3113314843177797
[Epoch 3, Batch 900] loss: 2.313977837562561
[Epoch 3, Batch 1000] loss: 2.312723274230957
[Epoch 3, Batch 1100] loss: 2.3054105186462404
[Epoch 3, Batch 1200] loss: 2.3119576525688172
[Epoch 3, Batch 1300] loss: 2.3126506447792052
[Epoch 3, Batch 1400] loss: 2.3088729310035707
[Epoch 3, Batch 1500] loss: 2.3130717968940733
[Epoch 3, Batch 1600] loss: 2.3125130319595337
[Epoch 3, Batch 1700] loss: 2.3141839718818664
[Epoch 3, Batch 1800] loss: 2.3075011348724366
**STATS for Epoch 3** : 
Average training loss: 0.0923
Average validation loss: 2.3175
Validation Accuracy: 0.1122
Overfitting: 2.2251
[Epoch 4, Batch 100] loss: 2.311592080593109
[Epoch 4, Batch 200] loss: 2.3069472312927246
[Epoch 4, Batch 300] loss: 2.310034236907959
[Epoch 4, Batch 400] loss: 2.3080074858665465
[Epoch 4, Batch 500] loss: 2.3157753920555115
[Epoch 4, Batch 600] loss: 2.3077686166763307
[Epoch 4, Batch 700] loss: 2.3093245029449463
[Epoch 4, Batch 800] loss: 2.309364869594574
[Epoch 4, Batch 900] loss: 2.312864124774933
[Epoch 4, Batch 1000] loss: 2.315200548171997
[Epoch 4, Batch 1100] loss: 2.3121538305282594
[Epoch 4, Batch 1200] loss: 2.312579646110535
[Epoch 4, Batch 1300] loss: 2.3111469769477844
[Epoch 4, Batch 1400] loss: 2.319024209976196
[Epoch 4, Batch 1500] loss: 2.3072587871551513
[Epoch 4, Batch 1600] loss: 2.3100810265541076
[Epoch 4, Batch 1700] loss: 2.3103315162658693
[Epoch 4, Batch 1800] loss: 2.3146728706359863
**STATS for Epoch 4** : 
Average training loss: 0.0925
Average validation loss: 2.3107
Validation Accuracy: 0.0986
Overfitting: 2.2182
Best model saved at epoch 4 with validation loss: 2.3107
[Epoch 5, Batch 100] loss: 2.314012405872345
[Epoch 5, Batch 200] loss: 2.3138036847114565
[Epoch 5, Batch 300] loss: 2.3118419814109803
[Epoch 5, Batch 400] loss: 2.309142999649048
[Epoch 5, Batch 500] loss: 2.30987806558609
[Epoch 5, Batch 600] loss: 2.310858955383301
[Epoch 5, Batch 700] loss: 2.313346266746521
[Epoch 5, Batch 800] loss: 2.316189727783203
[Epoch 5, Batch 900] loss: 2.3086461639404297
[Epoch 5, Batch 1000] loss: 2.309007205963135
[Epoch 5, Batch 1100] loss: 2.3150919914245605
[Epoch 5, Batch 1200] loss: 2.309144089221954
[Epoch 5, Batch 1300] loss: 2.3115343022346497
[Epoch 5, Batch 1400] loss: 2.3091373372077943
[Epoch 5, Batch 1500] loss: 2.3128683614730834
[Epoch 5, Batch 1600] loss: 2.309902701377869
[Epoch 5, Batch 1700] loss: 2.3122368359565737
[Epoch 5, Batch 1800] loss: 2.307045440673828
**STATS for Epoch 5** : 
Average training loss: 0.0926
Average validation loss: 2.3080
Validation Accuracy: 0.1122
Overfitting: 2.2154
Best model saved at epoch 5 with validation loss: 2.3080
[Epoch 6, Batch 100] loss: 2.309605371952057
[Epoch 6, Batch 200] loss: 2.3092559123039247
[Epoch 6, Batch 300] loss: 2.3165150594711306
[Epoch 6, Batch 400] loss: 2.3117932271957398
[Epoch 6, Batch 500] loss: 2.3065982627868653
[Epoch 6, Batch 600] loss: 2.315324409008026
[Epoch 6, Batch 700] loss: 2.3092204213142393
[Epoch 6, Batch 800] loss: 2.3159492588043213
[Epoch 6, Batch 900] loss: 2.31032812833786
[Epoch 6, Batch 1000] loss: 2.30998557806015
[Epoch 6, Batch 1100] loss: 2.3080449891090393
[Epoch 6, Batch 1200] loss: 2.3062924909591676
[Epoch 6, Batch 1300] loss: 2.316157205104828
[Epoch 6, Batch 1400] loss: 2.312983205318451
[Epoch 6, Batch 1500] loss: 2.313731937408447
[Epoch 6, Batch 1600] loss: 2.309425804615021
[Epoch 6, Batch 1700] loss: 2.3108886742591856
[Epoch 6, Batch 1800] loss: 2.311445369720459
**STATS for Epoch 6** : 
Average training loss: 0.0923
Average validation loss: 2.3142
Validation Accuracy: 0.1036
Overfitting: 2.2218
[Epoch 7, Batch 100] loss: 2.3104409861564634
[Epoch 7, Batch 200] loss: 2.3152468395233154
[Epoch 7, Batch 300] loss: 2.3092244386672975
[Epoch 7, Batch 400] loss: 2.308793296813965
[Epoch 7, Batch 500] loss: 2.316322157382965
[Epoch 7, Batch 600] loss: 2.310776195526123
[Epoch 7, Batch 700] loss: 2.3120615458488465
[Epoch 7, Batch 800] loss: 2.3066989612579345
[Epoch 7, Batch 900] loss: 2.3126251816749575
[Epoch 7, Batch 1000] loss: 2.3108666729927063
[Epoch 7, Batch 1100] loss: 2.306825261116028
[Epoch 7, Batch 1200] loss: 2.315113055706024
[Epoch 7, Batch 1300] loss: 2.315113162994385
[Epoch 7, Batch 1400] loss: 2.3173027205467225
[Epoch 7, Batch 1500] loss: 2.312711217403412
[Epoch 7, Batch 1600] loss: 2.312683844566345
[Epoch 7, Batch 1700] loss: 2.3093062376976015
[Epoch 7, Batch 1800] loss: 2.311688041687012
**STATS for Epoch 7** : 
Average training loss: 0.0927
Average validation loss: 2.3066
Validation Accuracy: 0.1122
Overfitting: 2.2140
Best model saved at epoch 7 with validation loss: 2.3066
[Epoch 8, Batch 100] loss: 2.3066745138168336
[Epoch 8, Batch 200] loss: 2.312607707977295
[Epoch 8, Batch 300] loss: 2.3112459564208985
[Epoch 8, Batch 400] loss: 2.31160138130188
[Epoch 8, Batch 500] loss: 2.3135624933242798
[Epoch 8, Batch 600] loss: 2.3127671003341677
[Epoch 8, Batch 700] loss: 2.310489912033081
[Epoch 8, Batch 800] loss: 2.308305344581604
[Epoch 8, Batch 900] loss: 2.314495325088501
[Epoch 8, Batch 1000] loss: 2.313584876060486
[Epoch 8, Batch 1100] loss: 2.309560327529907
[Epoch 8, Batch 1200] loss: 2.3126703119277954
[Epoch 8, Batch 1300] loss: 2.3141131067276
[Epoch 8, Batch 1400] loss: 2.313165616989136
[Epoch 8, Batch 1500] loss: 2.311689372062683
[Epoch 8, Batch 1600] loss: 2.308667459487915
[Epoch 8, Batch 1700] loss: 2.315285711288452
[Epoch 8, Batch 1800] loss: 2.312701151371002
**STATS for Epoch 8** : 
Average training loss: 0.0926
Average validation loss: 2.3144
Validation Accuracy: 0.1122
Overfitting: 2.2218
[Epoch 9, Batch 100] loss: 2.315758140087128
[Epoch 9, Batch 200] loss: 2.3089394617080687
[Epoch 9, Batch 300] loss: 2.3131447434425354
[Epoch 9, Batch 400] loss: 2.3083072662353517
[Epoch 9, Batch 500] loss: 2.3122602033615114
[Epoch 9, Batch 600] loss: 2.3125335669517515
[Epoch 9, Batch 700] loss: 2.3154805207252505
[Epoch 9, Batch 800] loss: 2.3157718777656555
[Epoch 9, Batch 900] loss: 2.31266637802124
[Epoch 9, Batch 1000] loss: 2.307141740322113
[Epoch 9, Batch 1100] loss: 2.3088919639587404
[Epoch 9, Batch 1200] loss: 2.3085625314712526
[Epoch 9, Batch 1300] loss: 2.3113990139961245
[Epoch 9, Batch 1400] loss: 2.310982928276062
[Epoch 9, Batch 1500] loss: 2.3125566482543944
[Epoch 9, Batch 1600] loss: 2.3153706192970276
[Epoch 9, Batch 1700] loss: 2.307958765029907
[Epoch 9, Batch 1800] loss: 2.3143359637260437
**STATS for Epoch 9** : 
Average training loss: 0.0925
Average validation loss: 2.3109
Validation Accuracy: 0.1007
Overfitting: 2.2184
[Epoch 10, Batch 100] loss: 2.311893813610077
[Epoch 10, Batch 200] loss: 2.3102554368972776
[Epoch 10, Batch 300] loss: 2.3084053444862365
[Epoch 10, Batch 400] loss: 2.31017454624176
[Epoch 10, Batch 500] loss: 2.3092282485961912
[Epoch 10, Batch 600] loss: 2.3102781629562377
[Epoch 10, Batch 700] loss: 2.314259684085846
[Epoch 10, Batch 800] loss: 2.313333673477173
[Epoch 10, Batch 900] loss: 2.3110338997840882
[Epoch 10, Batch 1000] loss: 2.3076971626281737
[Epoch 10, Batch 1100] loss: 2.314500992298126
[Epoch 10, Batch 1200] loss: 2.309198331832886
[Epoch 10, Batch 1300] loss: 2.3131740212440492
[Epoch 10, Batch 1400] loss: 2.311015977859497
[Epoch 10, Batch 1500] loss: 2.311164059638977
[Epoch 10, Batch 1600] loss: 2.313549346923828
[Epoch 10, Batch 1700] loss: 2.309257447719574
[Epoch 10, Batch 1800] loss: 2.314290223121643
**STATS for Epoch 10** : 
Average training loss: 0.0925
Average validation loss: 2.3071
Validation Accuracy: 0.1122
Overfitting: 2.2146
[Epoch 11, Batch 100] loss: 2.310167610645294
[Epoch 11, Batch 200] loss: 2.311925296783447
[Epoch 11, Batch 300] loss: 2.3084483838081358
[Epoch 11, Batch 400] loss: 2.312566728591919
[Epoch 11, Batch 500] loss: 2.3065111899375914
[Epoch 11, Batch 600] loss: 2.3100572419166565
[Epoch 11, Batch 700] loss: 2.3140640330314635
[Epoch 11, Batch 800] loss: 2.3095014572143553
[Epoch 11, Batch 900] loss: 2.311504819393158
[Epoch 11, Batch 1000] loss: 2.3155491971969604
[Epoch 11, Batch 1100] loss: 2.313045952320099
[Epoch 11, Batch 1200] loss: 2.3113919568061827
[Epoch 11, Batch 1300] loss: 2.315634789466858
[Epoch 11, Batch 1400] loss: 2.31558984041214
[Epoch 11, Batch 1500] loss: 2.3175116276741026
[Epoch 11, Batch 1600] loss: 2.303927865028381
[Epoch 11, Batch 1700] loss: 2.3148348569869994
[Epoch 11, Batch 1800] loss: 2.3091890621185303
**STATS for Epoch 11** : 
Average training loss: 0.0926
Average validation loss: 2.3053
Validation Accuracy: 0.1122
Overfitting: 2.2127
Best model saved at epoch 11 with validation loss: 2.3053
[Epoch 12, Batch 100] loss: 2.306463809013367
[Epoch 12, Batch 200] loss: 2.313503737449646
[Epoch 12, Batch 300] loss: 2.3144389677047728
[Epoch 12, Batch 400] loss: 2.311548526287079
[Epoch 12, Batch 500] loss: 2.3146810483932496
[Epoch 12, Batch 600] loss: 2.3139614343643187
[Epoch 12, Batch 700] loss: 2.3141090202331545
[Epoch 12, Batch 800] loss: 2.3143397855758665
[Epoch 12, Batch 900] loss: 2.306814649105072
[Epoch 12, Batch 1000] loss: 2.3096092891693116
[Epoch 12, Batch 1100] loss: 2.312348177433014
[Epoch 12, Batch 1200] loss: 2.312649955749512
[Epoch 12, Batch 1300] loss: 2.311251277923584
[Epoch 12, Batch 1400] loss: 2.313166995048523
[Epoch 12, Batch 1500] loss: 2.3088677382469176
[Epoch 12, Batch 1600] loss: 2.313350167274475
[Epoch 12, Batch 1700] loss: 2.3143085837364197
[Epoch 12, Batch 1800] loss: 2.312737538814545
**STATS for Epoch 12** : 
Average training loss: 0.0922
Average validation loss: 2.3169
Validation Accuracy: 0.0986
Overfitting: 2.2246
[Epoch 13, Batch 100] loss: 2.311665117740631
[Epoch 13, Batch 200] loss: 2.3110837650299074
[Epoch 13, Batch 300] loss: 2.3133983206748963
[Epoch 13, Batch 400] loss: 2.3112432503700258
[Epoch 13, Batch 500] loss: 2.31573237657547
[Epoch 13, Batch 600] loss: 2.311949915885925
[Epoch 13, Batch 700] loss: 2.315939347743988
[Epoch 13, Batch 800] loss: 2.306452491283417
[Epoch 13, Batch 900] loss: 2.309596025943756
[Epoch 13, Batch 1000] loss: 2.3083824706077576
[Epoch 13, Batch 1100] loss: 2.312062985897064
[Epoch 13, Batch 1200] loss: 2.3119091391563416
[Epoch 13, Batch 1300] loss: 2.3144718384742737
[Epoch 13, Batch 1400] loss: 2.308888165950775
[Epoch 13, Batch 1500] loss: 2.3100799560546874
[Epoch 13, Batch 1600] loss: 2.3113893818855287
[Epoch 13, Batch 1700] loss: 2.311429696083069
[Epoch 13, Batch 1800] loss: 2.3093959069252015
**STATS for Epoch 13** : 
Average training loss: 0.0922
Average validation loss: 2.3118
Validation Accuracy: 0.1122
Overfitting: 2.2196
[Epoch 14, Batch 100] loss: 2.3071074056625367
[Epoch 14, Batch 200] loss: 2.308992018699646
[Epoch 14, Batch 300] loss: 2.3122122144699095
[Epoch 14, Batch 400] loss: 2.3100844120979307
[Epoch 14, Batch 500] loss: 2.3104878664016724
[Epoch 14, Batch 600] loss: 2.312477641105652
[Epoch 14, Batch 700] loss: 2.3137578439712523
[Epoch 14, Batch 800] loss: 2.3105060982704164
[Epoch 14, Batch 900] loss: 2.310680727958679
[Epoch 14, Batch 1000] loss: 2.3116360974311827
[Epoch 14, Batch 1100] loss: 2.311934633255005
[Epoch 14, Batch 1200] loss: 2.30821506023407
[Epoch 14, Batch 1300] loss: 2.316229922771454
[Epoch 14, Batch 1400] loss: 2.3104179096221924
[Epoch 14, Batch 1500] loss: 2.311639688014984
[Epoch 14, Batch 1600] loss: 2.30946400642395
[Epoch 14, Batch 1700] loss: 2.3150109100341796
[Epoch 14, Batch 1800] loss: 2.312416877746582
**STATS for Epoch 14** : 
Average training loss: 0.0926
Average validation loss: 2.3129
Validation Accuracy: 0.0986
Overfitting: 2.2204
[Epoch 15, Batch 100] loss: 2.3129205083847046
[Epoch 15, Batch 200] loss: 2.3114114570617676
[Epoch 15, Batch 300] loss: 2.3042461681365967
[Epoch 15, Batch 400] loss: 2.3098603749275206
[Epoch 15, Batch 500] loss: 2.3097708296775816
[Epoch 15, Batch 600] loss: 2.3112309312820436
[Epoch 15, Batch 700] loss: 2.307999837398529
[Epoch 15, Batch 800] loss: 2.309959692955017
[Epoch 15, Batch 900] loss: 2.309714674949646
[Epoch 15, Batch 1000] loss: 2.3103453969955443
[Epoch 15, Batch 1100] loss: 2.308110439777374
[Epoch 15, Batch 1200] loss: 2.3121375370025636
[Epoch 15, Batch 1300] loss: 2.3146484422683717
[Epoch 15, Batch 1400] loss: 2.3152528738975526
[Epoch 15, Batch 1500] loss: 2.3104062557220457
[Epoch 15, Batch 1600] loss: 2.314654202461243
[Epoch 15, Batch 1700] loss: 2.312900273799896
[Epoch 15, Batch 1800] loss: 2.311327750682831
**STATS for Epoch 15** : 
Average training loss: 0.0924
Average validation loss: 2.3063
Validation Accuracy: 0.1122
Overfitting: 2.2138
[Epoch 16, Batch 100] loss: 2.3122320771217346
[Epoch 16, Batch 200] loss: 2.3035047817230225
[Epoch 16, Batch 300] loss: 2.309319214820862
[Epoch 16, Batch 400] loss: 2.313417868614197
[Epoch 16, Batch 500] loss: 2.3145596981048584
[Epoch 16, Batch 600] loss: 2.3168946957588195
[Epoch 16, Batch 700] loss: 2.3133988046646117
[Epoch 16, Batch 800] loss: 2.310515604019165
[Epoch 16, Batch 900] loss: 2.312766737937927
[Epoch 16, Batch 1000] loss: 2.3109186124801635
[Epoch 16, Batch 1100] loss: 2.310633432865143
[Epoch 16, Batch 1200] loss: 2.31235782623291
[Epoch 16, Batch 1300] loss: 2.3088961172103883
[Epoch 16, Batch 1400] loss: 2.314901785850525
[Epoch 16, Batch 1500] loss: 2.3118728804588318
[Epoch 16, Batch 1600] loss: 2.3145733857154847
[Epoch 16, Batch 1700] loss: 2.31274507522583
[Epoch 16, Batch 1800] loss: 2.309884078502655
**STATS for Epoch 16** : 
Average training loss: 0.0926
Average validation loss: 2.3102
Validation Accuracy: 0.0991
Overfitting: 2.2176
[Epoch 17, Batch 100] loss: 2.3167196774482726
[Epoch 17, Batch 200] loss: 2.311902232170105
[Epoch 17, Batch 300] loss: 2.3085267758369445
[Epoch 17, Batch 400] loss: 2.310299174785614
[Epoch 17, Batch 500] loss: 2.3090853929519652
[Epoch 17, Batch 600] loss: 2.3125813698768614
[Epoch 17, Batch 700] loss: 2.312879354953766
[Epoch 17, Batch 800] loss: 2.3137574696540835
[Epoch 17, Batch 900] loss: 2.311136212348938
[Epoch 17, Batch 1000] loss: 2.3124236607551576
[Epoch 17, Batch 1100] loss: 2.309565508365631
[Epoch 17, Batch 1200] loss: 2.311785616874695
[Epoch 17, Batch 1300] loss: 2.309443621635437
[Epoch 17, Batch 1400] loss: 2.308730916976929
[Epoch 17, Batch 1500] loss: 2.309775493144989
[Epoch 17, Batch 1600] loss: 2.3112346720695496
[Epoch 17, Batch 1700] loss: 2.308802342414856
[Epoch 17, Batch 1800] loss: 2.3133923983573914
**STATS for Epoch 17** : 
Average training loss: 0.0924
Average validation loss: 2.3095
Validation Accuracy: 0.1007
Overfitting: 2.2172
[Epoch 18, Batch 100] loss: 2.3164387917518616
[Epoch 18, Batch 200] loss: 2.311993899345398
[Epoch 18, Batch 300] loss: 2.318507695198059
[Epoch 18, Batch 400] loss: 2.3121400475502014
[Epoch 18, Batch 500] loss: 2.3118901371955873
[Epoch 18, Batch 600] loss: 2.3157084465026854
[Epoch 18, Batch 700] loss: 2.3101372075080873
[Epoch 18, Batch 800] loss: 2.315936563014984
[Epoch 18, Batch 900] loss: 2.3083019948005674
[Epoch 18, Batch 1000] loss: 2.312123408317566
[Epoch 18, Batch 1100] loss: 2.311129057407379
[Epoch 18, Batch 1200] loss: 2.309935314655304
[Epoch 18, Batch 1300] loss: 2.309395143985748
[Epoch 18, Batch 1400] loss: 2.3108413100242613
[Epoch 18, Batch 1500] loss: 2.304103581905365
[Epoch 18, Batch 1600] loss: 2.3107940912246705
[Epoch 18, Batch 1700] loss: 2.3118973922729493
[Epoch 18, Batch 1800] loss: 2.3151374292373657
**STATS for Epoch 18** : 
Average training loss: 0.0925
Average validation loss: 2.3183
Validation Accuracy: 0.1007
Overfitting: 2.2258
[Epoch 19, Batch 100] loss: 2.3118425393104554
[Epoch 19, Batch 200] loss: 2.3109652328491213
[Epoch 19, Batch 300] loss: 2.3062593960762023
[Epoch 19, Batch 400] loss: 2.3061713552474976
[Epoch 19, Batch 500] loss: 2.3112792944908143
[Epoch 19, Batch 600] loss: 2.306191129684448
[Epoch 19, Batch 700] loss: 2.310128245353699
[Epoch 19, Batch 800] loss: 2.3144556784629824
[Epoch 19, Batch 900] loss: 2.3113764238357546
[Epoch 19, Batch 1000] loss: 2.3109353804588317
[Epoch 19, Batch 1100] loss: 2.312429621219635
[Epoch 19, Batch 1200] loss: 2.311484293937683
[Epoch 19, Batch 1300] loss: 2.309670112133026
[Epoch 19, Batch 1400] loss: 2.3161045598983763
[Epoch 19, Batch 1500] loss: 2.3109747338294984
[Epoch 19, Batch 1600] loss: 2.3094703125953675
[Epoch 19, Batch 1700] loss: 2.3129570269584656
[Epoch 19, Batch 1800] loss: 2.3134424543380736
**STATS for Epoch 19** : 
Average training loss: 0.0924
Average validation loss: 2.3079
Validation Accuracy: 0.1036
Overfitting: 2.2155
[Epoch 20, Batch 100] loss: 2.3091230034828185
[Epoch 20, Batch 200] loss: 2.310595736503601
[Epoch 20, Batch 300] loss: 2.313851041793823
[Epoch 20, Batch 400] loss: 2.3057825446128843
[Epoch 20, Batch 500] loss: 2.309069905281067
[Epoch 20, Batch 600] loss: 2.3130112171173094
[Epoch 20, Batch 700] loss: 2.3091810035705564
[Epoch 20, Batch 800] loss: 2.3132904291152956
[Epoch 20, Batch 900] loss: 2.311356289386749
[Epoch 20, Batch 1000] loss: 2.316730217933655
[Epoch 20, Batch 1100] loss: 2.313116044998169
[Epoch 20, Batch 1200] loss: 2.3128812956809996
[Epoch 20, Batch 1300] loss: 2.3115237045288084
[Epoch 20, Batch 1400] loss: 2.3120387840270995
[Epoch 20, Batch 1500] loss: 2.304042088985443
[Epoch 20, Batch 1600] loss: 2.311199288368225
[Epoch 20, Batch 1700] loss: 2.314414656162262
[Epoch 20, Batch 1800] loss: 2.3159078693389894
**STATS for Epoch 20** : 
Average training loss: 0.0927
Average validation loss: 2.3081
Validation Accuracy: 0.1122
Overfitting: 2.2154
[Epoch 21, Batch 100] loss: 2.3115935730934143
[Epoch 21, Batch 200] loss: 2.3105376768112182
[Epoch 21, Batch 300] loss: 2.313670566082001
[Epoch 21, Batch 400] loss: 2.311112570762634
[Epoch 21, Batch 500] loss: 2.309011878967285
[Epoch 21, Batch 600] loss: 2.315867781639099
[Epoch 21, Batch 700] loss: 2.3140491032600403
[Epoch 21, Batch 800] loss: 2.307501029968262
[Epoch 21, Batch 900] loss: 2.3180076479911804
[Epoch 21, Batch 1000] loss: 2.311713631153107
[Epoch 21, Batch 1100] loss: 2.3096698117256165
[Epoch 21, Batch 1200] loss: 2.305951483249664
[Epoch 21, Batch 1300] loss: 2.310571241378784
[Epoch 21, Batch 1400] loss: 2.3120388746261598
[Epoch 21, Batch 1500] loss: 2.3106052350997923
[Epoch 21, Batch 1600] loss: 2.3086227560043335
[Epoch 21, Batch 1700] loss: 2.309246599674225
[Epoch 21, Batch 1800] loss: 2.3095548272132875
**STATS for Epoch 21** : 
Average training loss: 0.0926
Average validation loss: 2.3106
Validation Accuracy: 0.0982
Overfitting: 2.2180
[Epoch 22, Batch 100] loss: 2.313016574382782
[Epoch 22, Batch 200] loss: 2.3094846487045286
[Epoch 22, Batch 300] loss: 2.314952940940857
[Epoch 22, Batch 400] loss: 2.3134171199798583
[Epoch 22, Batch 500] loss: 2.3114276051521303
[Epoch 22, Batch 600] loss: 2.314616401195526
[Epoch 22, Batch 700] loss: 2.3094081830978395
[Epoch 22, Batch 800] loss: 2.3158361291885377
[Epoch 22, Batch 900] loss: 2.314064521789551
[Epoch 22, Batch 1000] loss: 2.308771095275879
[Epoch 22, Batch 1100] loss: 2.309516990184784
[Epoch 22, Batch 1200] loss: 2.3156488275527956
[Epoch 22, Batch 1300] loss: 2.3078847670555116
[Epoch 22, Batch 1400] loss: 2.314431917667389
[Epoch 22, Batch 1500] loss: 2.308140950202942
[Epoch 22, Batch 1600] loss: 2.3103085422515868
[Epoch 22, Batch 1700] loss: 2.3137230348587035
[Epoch 22, Batch 1800] loss: 2.310801525115967
**STATS for Epoch 22** : 
Average training loss: 0.0924
Average validation loss: 2.3247
Validation Accuracy: 0.0991
Overfitting: 2.2323
[Epoch 23, Batch 100] loss: 2.3150005865097047
[Epoch 23, Batch 200] loss: 2.3067211890220642
[Epoch 23, Batch 300] loss: 2.3186550760269165
[Epoch 23, Batch 400] loss: 2.3152657651901247
[Epoch 23, Batch 500] loss: 2.3104169869422915
[Epoch 23, Batch 600] loss: 2.311054139137268
[Epoch 23, Batch 700] loss: 2.3119670653343203
[Epoch 23, Batch 800] loss: 2.31045437335968
[Epoch 23, Batch 900] loss: 2.30951783657074
[Epoch 23, Batch 1000] loss: 2.3149200224876405
[Epoch 23, Batch 1100] loss: 2.3081273317337034
[Epoch 23, Batch 1200] loss: 2.3161167764663695
[Epoch 23, Batch 1300] loss: 2.31053893327713
[Epoch 23, Batch 1400] loss: 2.3129458832740784
[Epoch 23, Batch 1500] loss: 2.3142471861839295
[Epoch 23, Batch 1600] loss: 2.3130010414123534
[Epoch 23, Batch 1700] loss: 2.315050423145294
[Epoch 23, Batch 1800] loss: 2.3062006855010986
**STATS for Epoch 23** : 
Average training loss: 0.0921
Average validation loss: 2.3237
Validation Accuracy: 0.1007
Overfitting: 2.2315
[Epoch 24, Batch 100] loss: 2.3160513710975645
[Epoch 24, Batch 200] loss: 2.309839918613434
[Epoch 24, Batch 300] loss: 2.311920340061188
[Epoch 24, Batch 400] loss: 2.310871286392212
[Epoch 24, Batch 500] loss: 2.3089171266555786
[Epoch 24, Batch 600] loss: 2.310391991138458
[Epoch 24, Batch 700] loss: 2.3105390286445617
[Epoch 24, Batch 800] loss: 2.3090145444869994
[Epoch 24, Batch 900] loss: 2.3076992726325987
[Epoch 24, Batch 1000] loss: 2.3151339745521544
[Epoch 24, Batch 1100] loss: 2.3102935767173767
[Epoch 24, Batch 1200] loss: 2.3130175709724425
[Epoch 24, Batch 1300] loss: 2.314802181720734
[Epoch 24, Batch 1400] loss: 2.3172175979614256
[Epoch 24, Batch 1500] loss: 2.3085108757019044
[Epoch 24, Batch 1600] loss: 2.3111447262763978
[Epoch 24, Batch 1700] loss: 2.3110156631469727
[Epoch 24, Batch 1800] loss: 2.314864389896393
**STATS for Epoch 24** : 
Average training loss: 0.0926
Average validation loss: 2.3122
Validation Accuracy: 0.1036
Overfitting: 2.2196
Fold 1 validation loss: 2.3122
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.965055404305458
[Epoch 1, Batch 200] loss: 2.3173912358283997
[Epoch 1, Batch 300] loss: 2.0538837337493896
[Epoch 1, Batch 400] loss: 1.6681940865516662
[Epoch 1, Batch 500] loss: 1.7430737525224687
[Epoch 1, Batch 600] loss: 1.807698490023613
[Epoch 1, Batch 700] loss: 1.7441875648498535
[Epoch 1, Batch 800] loss: 1.5672361302375792
[Epoch 1, Batch 900] loss: 1.4339889174699783
[Epoch 1, Batch 1000] loss: 1.4730150669813156
[Epoch 1, Batch 1100] loss: 1.5396975126862527
[Epoch 1, Batch 1200] loss: 2.0373116332292556
[Epoch 1, Batch 1300] loss: 2.0925612699985505
[Epoch 1, Batch 1400] loss: 2.0608683049678804
[Epoch 1, Batch 1500] loss: 2.3279366278648377
[Epoch 1, Batch 1600] loss: 2.313171994686127
[Epoch 1, Batch 1700] loss: 2.312801835536957
[Epoch 1, Batch 1800] loss: 2.3123074078559878
**STATS for Epoch 1** : 
Average training loss: 0.0926
Average validation loss: 2.3069
Validation Accuracy: 0.1037
Overfitting: 2.2144
Best model saved at epoch 1 with validation loss: 2.3069
[Epoch 2, Batch 100] loss: 2.3104096603393556
[Epoch 2, Batch 200] loss: 2.3127056884765627
[Epoch 2, Batch 300] loss: 2.3092569756507872
[Epoch 2, Batch 400] loss: 2.3096584033966066
[Epoch 2, Batch 500] loss: 2.313368015289307
[Epoch 2, Batch 600] loss: 2.31262855052948
[Epoch 2, Batch 700] loss: 2.3147368693351744
[Epoch 2, Batch 800] loss: 2.3120145988464356
[Epoch 2, Batch 900] loss: 2.31307505607605
[Epoch 2, Batch 1000] loss: 2.316033296585083
[Epoch 2, Batch 1100] loss: 2.3114587378501894
[Epoch 2, Batch 1200] loss: 2.3164621996879577
[Epoch 2, Batch 1300] loss: 2.3112032556533815
[Epoch 2, Batch 1400] loss: 2.3116051721572877
[Epoch 2, Batch 1500] loss: 2.3082622408866884
[Epoch 2, Batch 1600] loss: 2.316179494857788
[Epoch 2, Batch 1700] loss: 2.31324147939682
[Epoch 2, Batch 1800] loss: 2.3089317679405212
**STATS for Epoch 2** : 
Average training loss: 0.0925
Average validation loss: 2.3119
Validation Accuracy: 0.1126
Overfitting: 2.2194
[Epoch 3, Batch 100] loss: 2.313895945549011
[Epoch 3, Batch 200] loss: 2.309670491218567
[Epoch 3, Batch 300] loss: 2.310944540500641
[Epoch 3, Batch 400] loss: 2.3069434785842895
[Epoch 3, Batch 500] loss: 2.311003818511963
[Epoch 3, Batch 600] loss: 2.314818632602692
[Epoch 3, Batch 700] loss: 2.3128419947624206
[Epoch 3, Batch 800] loss: 2.3104747557640075
[Epoch 3, Batch 900] loss: 2.3127603554725646
[Epoch 3, Batch 1000] loss: 2.30861289024353
[Epoch 3, Batch 1100] loss: 2.3141072297096255
[Epoch 3, Batch 1200] loss: 2.3070085430145264
[Epoch 3, Batch 1300] loss: 2.312777373790741
[Epoch 3, Batch 1400] loss: 2.311854028701782
[Epoch 3, Batch 1500] loss: 2.312198078632355
[Epoch 3, Batch 1600] loss: 2.3130515027046203
[Epoch 3, Batch 1700] loss: 2.311556134223938
[Epoch 3, Batch 1800] loss: 2.3122482824325563
**STATS for Epoch 3** : 
Average training loss: 0.0926
Average validation loss: 2.3080
Validation Accuracy: 0.1052
Overfitting: 2.2154
[Epoch 4, Batch 100] loss: 2.3089558029174806
[Epoch 4, Batch 200] loss: 2.3106138920783996
[Epoch 4, Batch 300] loss: 2.3069653964042662
[Epoch 4, Batch 400] loss: 2.312967917919159
[Epoch 4, Batch 500] loss: 2.3149375033378603
[Epoch 4, Batch 600] loss: 2.3094246768951416
[Epoch 4, Batch 700] loss: 2.3144243931770325
[Epoch 4, Batch 800] loss: 2.313596761226654
[Epoch 4, Batch 900] loss: 2.310919795036316
[Epoch 4, Batch 1000] loss: 2.3173352789878847
[Epoch 4, Batch 1100] loss: 2.315156569480896
[Epoch 4, Batch 1200] loss: 2.315024290084839
[Epoch 4, Batch 1300] loss: 2.3158168983459473
[Epoch 4, Batch 1400] loss: 2.3131278562545776
[Epoch 4, Batch 1500] loss: 2.3080983567237854
[Epoch 4, Batch 1600] loss: 2.3169844436645506
[Epoch 4, Batch 1700] loss: 2.311212430000305
[Epoch 4, Batch 1800] loss: 2.3133854937553404
**STATS for Epoch 4** : 
Average training loss: 0.0925
Average validation loss: 2.3163
Validation Accuracy: 0.0992
Overfitting: 2.2238
[Epoch 5, Batch 100] loss: 2.316075713634491
[Epoch 5, Batch 200] loss: 2.308396244049072
[Epoch 5, Batch 300] loss: 2.312608091831207
[Epoch 5, Batch 400] loss: 2.3077780532836916
[Epoch 5, Batch 500] loss: 2.310940248966217
[Epoch 5, Batch 600] loss: 2.316738827228546
[Epoch 5, Batch 700] loss: 2.311568033695221
[Epoch 5, Batch 800] loss: 2.3103465962409975
[Epoch 5, Batch 900] loss: 2.310342071056366
[Epoch 5, Batch 1000] loss: 2.316271526813507
[Epoch 5, Batch 1100] loss: 2.317001209259033
[Epoch 5, Batch 1200] loss: 2.310045013427734
[Epoch 5, Batch 1300] loss: 2.3110173654556276
[Epoch 5, Batch 1400] loss: 2.3113459849357607
[Epoch 5, Batch 1500] loss: 2.308619740009308
[Epoch 5, Batch 1600] loss: 2.3095606350898743
[Epoch 5, Batch 1700] loss: 2.3095687937736513
[Epoch 5, Batch 1800] loss: 2.3130926299095154
**STATS for Epoch 5** : 
Average training loss: 0.0926
Average validation loss: 2.3063
Validation Accuracy: 0.1052
Overfitting: 2.2137
Best model saved at epoch 5 with validation loss: 2.3063
[Epoch 6, Batch 100] loss: 2.3183762431144714
[Epoch 6, Batch 200] loss: 2.3082984828948976
[Epoch 6, Batch 300] loss: 2.310840947628021
[Epoch 6, Batch 400] loss: 2.3155940532684327
[Epoch 6, Batch 500] loss: 2.3103658246994017
[Epoch 6, Batch 600] loss: 2.3134489011764527
[Epoch 6, Batch 700] loss: 2.313321044445038
[Epoch 6, Batch 800] loss: 2.3060602140426636
[Epoch 6, Batch 900] loss: 2.315557723045349
[Epoch 6, Batch 1000] loss: 2.312196500301361
[Epoch 6, Batch 1100] loss: 2.310687017440796
[Epoch 6, Batch 1200] loss: 2.3115174889564516
[Epoch 6, Batch 1300] loss: 2.3118615102767945
[Epoch 6, Batch 1400] loss: 2.31417448759079
[Epoch 6, Batch 1500] loss: 2.309191932678223
[Epoch 6, Batch 1600] loss: 2.3106123852729796
[Epoch 6, Batch 1700] loss: 2.3110549902915953
[Epoch 6, Batch 1800] loss: 2.3163451457023623
**STATS for Epoch 6** : 
Average training loss: 0.0924
Average validation loss: 2.3070
Validation Accuracy: 0.0976
Overfitting: 2.2146
[Epoch 7, Batch 100] loss: 2.309780378341675
[Epoch 7, Batch 200] loss: 2.309134364128113
[Epoch 7, Batch 300] loss: 2.3110974407196045
[Epoch 7, Batch 400] loss: 2.3133417534828187
[Epoch 7, Batch 500] loss: 2.3123195481300356
[Epoch 7, Batch 600] loss: 2.3143668127059938
[Epoch 7, Batch 700] loss: 2.312341084480286
[Epoch 7, Batch 800] loss: 2.3163905501365663
[Epoch 7, Batch 900] loss: 2.31151221036911
[Epoch 7, Batch 1000] loss: 2.3130368995666504
[Epoch 7, Batch 1100] loss: 2.315264410972595
[Epoch 7, Batch 1200] loss: 2.3111896872520448
[Epoch 7, Batch 1300] loss: 2.3095419096946714
[Epoch 7, Batch 1400] loss: 2.3119428062438967
[Epoch 7, Batch 1500] loss: 2.315743682384491
[Epoch 7, Batch 1600] loss: 2.3127223539352415
[Epoch 7, Batch 1700] loss: 2.313004038333893
[Epoch 7, Batch 1800] loss: 2.3087241792678834
**STATS for Epoch 7** : 
Average training loss: 0.0921
Average validation loss: 2.3118
Validation Accuracy: 0.1126
Overfitting: 2.2197
[Epoch 8, Batch 100] loss: 2.3118953323364257
[Epoch 8, Batch 200] loss: 2.31277583360672
[Epoch 8, Batch 300] loss: 2.3099958992004392
[Epoch 8, Batch 400] loss: 2.3112831020355227
[Epoch 8, Batch 500] loss: 2.3135914182662964
[Epoch 8, Batch 600] loss: 2.3094338893890383
[Epoch 8, Batch 700] loss: 2.312703700065613
[Epoch 8, Batch 800] loss: 2.3103678369522096
[Epoch 8, Batch 900] loss: 2.315106763839722
[Epoch 8, Batch 1000] loss: 2.315940613746643
[Epoch 8, Batch 1100] loss: 2.3083940362930297
[Epoch 8, Batch 1200] loss: 2.310692801475525
[Epoch 8, Batch 1300] loss: 2.3125294923782347
[Epoch 8, Batch 1400] loss: 2.3105999636650085
[Epoch 8, Batch 1500] loss: 2.316264431476593
[Epoch 8, Batch 1600] loss: 2.312029013633728
[Epoch 8, Batch 1700] loss: 2.3127619576454164
[Epoch 8, Batch 1800] loss: 2.3117023658752442
**STATS for Epoch 8** : 
Average training loss: 0.0925
Average validation loss: 2.3074
Validation Accuracy: 0.1126
Overfitting: 2.2149
[Epoch 9, Batch 100] loss: 2.310681004524231
[Epoch 9, Batch 200] loss: 2.3100769567489623
[Epoch 9, Batch 300] loss: 2.3117403411865234
[Epoch 9, Batch 400] loss: 2.3096796894073486
[Epoch 9, Batch 500] loss: 2.3094547724723817
[Epoch 9, Batch 600] loss: 2.309557943344116
[Epoch 9, Batch 700] loss: 2.3098926901817323
[Epoch 9, Batch 800] loss: 2.306976442337036
[Epoch 9, Batch 900] loss: 2.3123572754859922
[Epoch 9, Batch 1000] loss: 2.3090917587280275
[Epoch 9, Batch 1100] loss: 2.306478433609009
[Epoch 9, Batch 1200] loss: 2.30829941034317
[Epoch 9, Batch 1300] loss: 2.309577691555023
[Epoch 9, Batch 1400] loss: 2.3130182313919065
[Epoch 9, Batch 1500] loss: 2.3128039145469668
[Epoch 9, Batch 1600] loss: 2.315044264793396
[Epoch 9, Batch 1700] loss: 2.3142000460624694
[Epoch 9, Batch 1800] loss: 2.311390209197998
**STATS for Epoch 9** : 
Average training loss: 0.0924
Average validation loss: 2.3114
Validation Accuracy: 0.1052
Overfitting: 2.2190
[Epoch 10, Batch 100] loss: 2.310620512962341
[Epoch 10, Batch 200] loss: 2.310104672908783
[Epoch 10, Batch 300] loss: 2.3149676871299745
[Epoch 10, Batch 400] loss: 2.3082592606544496
[Epoch 10, Batch 500] loss: 2.308620390892029
[Epoch 10, Batch 600] loss: 2.3095982837677003
[Epoch 10, Batch 700] loss: 2.3152934312820435
[Epoch 10, Batch 800] loss: 2.3137369394302367
[Epoch 10, Batch 900] loss: 2.30832284450531
[Epoch 10, Batch 1000] loss: 2.3090397262573243
[Epoch 10, Batch 1100] loss: 2.3117237186431883
[Epoch 10, Batch 1200] loss: 2.3076224374771117
[Epoch 10, Batch 1300] loss: 2.313598625659943
[Epoch 10, Batch 1400] loss: 2.3112767720222473
[Epoch 10, Batch 1500] loss: 2.3057160234451293
[Epoch 10, Batch 1600] loss: 2.3131900596618653
[Epoch 10, Batch 1700] loss: 2.31115327835083
[Epoch 10, Batch 1800] loss: 2.3120870208740234
**STATS for Epoch 10** : 
Average training loss: 0.0927
Average validation loss: 2.3057
Validation Accuracy: 0.1126
Overfitting: 2.2130
Best model saved at epoch 10 with validation loss: 2.3057
[Epoch 11, Batch 100] loss: 2.3083684062957763
[Epoch 11, Batch 200] loss: 2.309057152271271
[Epoch 11, Batch 300] loss: 2.312776198387146
[Epoch 11, Batch 400] loss: 2.3132813143730164
[Epoch 11, Batch 500] loss: 2.309135000705719
[Epoch 11, Batch 600] loss: 2.3090898299217226
[Epoch 11, Batch 700] loss: 2.3169053530693056
[Epoch 11, Batch 800] loss: 2.31470823764801
[Epoch 11, Batch 900] loss: 2.3143461894989015
[Epoch 11, Batch 1000] loss: 2.311725907325745
[Epoch 11, Batch 1100] loss: 2.307160828113556
[Epoch 11, Batch 1200] loss: 2.3117004299163817
[Epoch 11, Batch 1300] loss: 2.3137601804733277
[Epoch 11, Batch 1400] loss: 2.3104022407531737
[Epoch 11, Batch 1500] loss: 2.3103246331214904
[Epoch 11, Batch 1600] loss: 2.3094199514389038
[Epoch 11, Batch 1700] loss: 2.3124974393844604
[Epoch 11, Batch 1800] loss: 2.3099369263648986
**STATS for Epoch 11** : 
Average training loss: 0.0925
Average validation loss: 2.3087
Validation Accuracy: 0.1126
Overfitting: 2.2162
[Epoch 12, Batch 100] loss: 2.3134735321998594
[Epoch 12, Batch 200] loss: 2.309864110946655
[Epoch 12, Batch 300] loss: 2.310754208564758
[Epoch 12, Batch 400] loss: 2.3084399342536925
[Epoch 12, Batch 500] loss: 2.309762065410614
[Epoch 12, Batch 600] loss: 2.309983458518982
[Epoch 12, Batch 700] loss: 2.312266418933868
[Epoch 12, Batch 800] loss: 2.3084996581077575
[Epoch 12, Batch 900] loss: 2.3180325722694395
[Epoch 12, Batch 1000] loss: 2.313318269252777
[Epoch 12, Batch 1100] loss: 2.3131649827957155
[Epoch 12, Batch 1200] loss: 2.317140200138092
[Epoch 12, Batch 1300] loss: 2.3085683727264406
[Epoch 12, Batch 1400] loss: 2.3091883516311644
[Epoch 12, Batch 1500] loss: 2.309880328178406
[Epoch 12, Batch 1600] loss: 2.306835722923279
[Epoch 12, Batch 1700] loss: 2.315390329360962
[Epoch 12, Batch 1800] loss: 2.3083849501609803
**STATS for Epoch 12** : 
Average training loss: 0.0923
Average validation loss: 2.3078
Validation Accuracy: 0.1126
Overfitting: 2.2155
[Epoch 13, Batch 100] loss: 2.3107326459884643
[Epoch 13, Batch 200] loss: 2.3141592526435852
[Epoch 13, Batch 300] loss: 2.3093653297424317
[Epoch 13, Batch 400] loss: 2.3170771741867067
[Epoch 13, Batch 500] loss: 2.315227255821228
[Epoch 13, Batch 600] loss: 2.3095403265953065
[Epoch 13, Batch 700] loss: 2.3132824373245238
[Epoch 13, Batch 800] loss: 2.3159417390823362
[Epoch 13, Batch 900] loss: 2.3107924890518188
[Epoch 13, Batch 1000] loss: 2.305364141464233
[Epoch 13, Batch 1100] loss: 2.315069115161896
[Epoch 13, Batch 1200] loss: 2.3084199452400207
[Epoch 13, Batch 1300] loss: 2.310830636024475
[Epoch 13, Batch 1400] loss: 2.3145552396774294
[Epoch 13, Batch 1500] loss: 2.313059947490692
[Epoch 13, Batch 1600] loss: 2.3122101998329163
[Epoch 13, Batch 1700] loss: 2.308545250892639
[Epoch 13, Batch 1800] loss: 2.3147299337387084
**STATS for Epoch 13** : 
Average training loss: 0.0925
Average validation loss: 2.3050
Validation Accuracy: 0.1052
Overfitting: 2.2126
Best model saved at epoch 13 with validation loss: 2.3050
[Epoch 14, Batch 100] loss: 2.314295282363892
[Epoch 14, Batch 200] loss: 2.310163929462433
[Epoch 14, Batch 300] loss: 2.3108933925628663
[Epoch 14, Batch 400] loss: 2.312462785243988
[Epoch 14, Batch 500] loss: 2.3126970434188845
[Epoch 14, Batch 600] loss: 2.306476182937622
[Epoch 14, Batch 700] loss: 2.3130677151679992
[Epoch 14, Batch 800] loss: 2.3063923382759093
[Epoch 14, Batch 900] loss: 2.312894914150238
[Epoch 14, Batch 1000] loss: 2.309245946407318
[Epoch 14, Batch 1100] loss: 2.313920383453369
[Epoch 14, Batch 1200] loss: 2.311065616607666
[Epoch 14, Batch 1300] loss: 2.3096801447868347
[Epoch 14, Batch 1400] loss: 2.306713175773621
[Epoch 14, Batch 1500] loss: 2.3144943737983703
[Epoch 14, Batch 1600] loss: 2.316087050437927
[Epoch 14, Batch 1700] loss: 2.312986738681793
[Epoch 14, Batch 1800] loss: 2.3126378083229064
**STATS for Epoch 14** : 
Average training loss: 0.0924
Average validation loss: 2.3162
Validation Accuracy: 0.0976
Overfitting: 2.2238
[Epoch 15, Batch 100] loss: 2.311012670993805
[Epoch 15, Batch 200] loss: 2.3124544334411623
[Epoch 15, Batch 300] loss: 2.314567446708679
[Epoch 15, Batch 400] loss: 2.313273403644562
[Epoch 15, Batch 500] loss: 2.317183666229248
[Epoch 15, Batch 600] loss: 2.3116303372383116
[Epoch 15, Batch 700] loss: 2.3093018102645875
[Epoch 15, Batch 800] loss: 2.309912621974945
[Epoch 15, Batch 900] loss: 2.3066307616233828
[Epoch 15, Batch 1000] loss: 2.312732319831848
[Epoch 15, Batch 1100] loss: 2.316903541088104
[Epoch 15, Batch 1200] loss: 2.313902373313904
[Epoch 15, Batch 1300] loss: 2.3113713574409487
[Epoch 15, Batch 1400] loss: 2.3144631814956664
[Epoch 15, Batch 1500] loss: 2.309996705055237
[Epoch 15, Batch 1600] loss: 2.3132788133621216
[Epoch 15, Batch 1700] loss: 2.311519823074341
[Epoch 15, Batch 1800] loss: 2.3154633140563963
**STATS for Epoch 15** : 
Average training loss: 0.0925
Average validation loss: 2.3047
Validation Accuracy: 0.1126
Overfitting: 2.2122
Best model saved at epoch 15 with validation loss: 2.3047
[Epoch 16, Batch 100] loss: 2.308017539978027
[Epoch 16, Batch 200] loss: 2.313518464565277
[Epoch 16, Batch 300] loss: 2.3112989902496337
[Epoch 16, Batch 400] loss: 2.3121183109283447
[Epoch 16, Batch 500] loss: 2.3090437388420106
[Epoch 16, Batch 600] loss: 2.311170814037323
[Epoch 16, Batch 700] loss: 2.313578152656555
[Epoch 16, Batch 800] loss: 2.3140523433685303
[Epoch 16, Batch 900] loss: 2.3109788370132445
[Epoch 16, Batch 1000] loss: 2.3081360626220704
[Epoch 16, Batch 1100] loss: 2.312847535610199
[Epoch 16, Batch 1200] loss: 2.315718047618866
[Epoch 16, Batch 1300] loss: 2.3097395730018615
[Epoch 16, Batch 1400] loss: 2.3089365005493163
[Epoch 16, Batch 1500] loss: 2.315978856086731
[Epoch 16, Batch 1600] loss: 2.3079946970939638
[Epoch 16, Batch 1700] loss: 2.315076403617859
[Epoch 16, Batch 1800] loss: 2.3129762625694275
**STATS for Epoch 16** : 
Average training loss: 0.0922
Average validation loss: 2.3172
Validation Accuracy: 0.1052
Overfitting: 2.2249
[Epoch 17, Batch 100] loss: 2.3115802907943728
[Epoch 17, Batch 200] loss: 2.306962397098541
[Epoch 17, Batch 300] loss: 2.3128547739982603
[Epoch 17, Batch 400] loss: 2.3112498831748964
[Epoch 17, Batch 500] loss: 2.310265860557556
[Epoch 17, Batch 600] loss: 2.3120207619667053
[Epoch 17, Batch 700] loss: 2.3119146704673765
[Epoch 17, Batch 800] loss: 2.3168764972686766
[Epoch 17, Batch 900] loss: 2.308904678821564
[Epoch 17, Batch 1000] loss: 2.3049308276176452
[Epoch 17, Batch 1100] loss: 2.3102107548713686
[Epoch 17, Batch 1200] loss: 2.314638028144836
[Epoch 17, Batch 1300] loss: 2.3110323905944825
[Epoch 17, Batch 1400] loss: 2.314041621685028
[Epoch 17, Batch 1500] loss: 2.3135698938369753
[Epoch 17, Batch 1600] loss: 2.3153072500228884
[Epoch 17, Batch 1700] loss: 2.3149544906616213
[Epoch 17, Batch 1800] loss: 2.3098046875
**STATS for Epoch 17** : 
Average training loss: 0.0926
Average validation loss: 2.3147
Validation Accuracy: 0.1000
Overfitting: 2.2221
[Epoch 18, Batch 100] loss: 2.3150288319587706
[Epoch 18, Batch 200] loss: 2.3120808935165407
[Epoch 18, Batch 300] loss: 2.3165566515922547
[Epoch 18, Batch 400] loss: 2.312292251586914
[Epoch 18, Batch 500] loss: 2.304996726512909
[Epoch 18, Batch 600] loss: 2.3086318612098693
[Epoch 18, Batch 700] loss: 2.312307147979736
[Epoch 18, Batch 800] loss: 2.3102202439308166
[Epoch 18, Batch 900] loss: 2.3090784549713135
[Epoch 18, Batch 1000] loss: 2.311801886558533
[Epoch 18, Batch 1100] loss: 2.314567413330078
[Epoch 18, Batch 1200] loss: 2.3134423899650574
[Epoch 18, Batch 1300] loss: 2.3129685974121093
[Epoch 18, Batch 1400] loss: 2.30994734287262
[Epoch 18, Batch 1500] loss: 2.314302096366882
[Epoch 18, Batch 1600] loss: 2.3114159440994264
[Epoch 18, Batch 1700] loss: 2.314928035736084
[Epoch 18, Batch 1800] loss: 2.3136580419540405
**STATS for Epoch 18** : 
Average training loss: 0.0924
Average validation loss: 2.3142
Validation Accuracy: 0.1052
Overfitting: 2.2219
[Epoch 19, Batch 100] loss: 2.312499635219574
[Epoch 19, Batch 200] loss: 2.3137025356292726
[Epoch 19, Batch 300] loss: 2.3118513345718386
[Epoch 19, Batch 400] loss: 2.312703092098236
[Epoch 19, Batch 500] loss: 2.3101282715797424
[Epoch 19, Batch 600] loss: 2.314461097717285
[Epoch 19, Batch 700] loss: 2.3119808554649355
[Epoch 19, Batch 800] loss: 2.3156891441345215
[Epoch 19, Batch 900] loss: 2.313834512233734
[Epoch 19, Batch 1000] loss: 2.310159022808075
[Epoch 19, Batch 1100] loss: 2.3120629596710205
[Epoch 19, Batch 1200] loss: 2.3193538784980774
[Epoch 19, Batch 1300] loss: 2.3102559232711792
[Epoch 19, Batch 1400] loss: 2.3140286302566526
[Epoch 19, Batch 1500] loss: 2.3100085282325744
[Epoch 19, Batch 1600] loss: 2.3151190519332885
[Epoch 19, Batch 1700] loss: 2.314765477180481
[Epoch 19, Batch 1800] loss: 2.3151358652114866
**STATS for Epoch 19** : 
Average training loss: 0.0923
Average validation loss: 2.3162
Validation Accuracy: 0.0985
Overfitting: 2.2240
[Epoch 20, Batch 100] loss: 2.3107156944274903
[Epoch 20, Batch 200] loss: 2.318353419303894
[Epoch 20, Batch 300] loss: 2.3084401726722716
[Epoch 20, Batch 400] loss: 2.3115215945243834
[Epoch 20, Batch 500] loss: 2.31216413974762
[Epoch 20, Batch 600] loss: 2.3193377685546874
[Epoch 20, Batch 700] loss: 2.310363507270813
[Epoch 20, Batch 800] loss: 2.3110334372520445
[Epoch 20, Batch 900] loss: 2.3120312595367434
[Epoch 20, Batch 1000] loss: 2.3134415316581727
[Epoch 20, Batch 1100] loss: 2.3101708269119263
[Epoch 20, Batch 1200] loss: 2.3098754835128785
[Epoch 20, Batch 1300] loss: 2.3120360732078553
[Epoch 20, Batch 1400] loss: 2.3135180401802065
[Epoch 20, Batch 1500] loss: 2.3090552949905394
[Epoch 20, Batch 1600] loss: 2.312597966194153
[Epoch 20, Batch 1700] loss: 2.3131301522254946
[Epoch 20, Batch 1800] loss: 2.313717632293701
**STATS for Epoch 20** : 
Average training loss: 0.0924
Average validation loss: 2.3221
Validation Accuracy: 0.1126
Overfitting: 2.2297
[Epoch 21, Batch 100] loss: 2.3110334634780885
[Epoch 21, Batch 200] loss: 2.310787944793701
[Epoch 21, Batch 300] loss: 2.3096720337867738
[Epoch 21, Batch 400] loss: 2.307891490459442
[Epoch 21, Batch 500] loss: 2.3151387310028078
[Epoch 21, Batch 600] loss: 2.312477571964264
[Epoch 21, Batch 700] loss: 2.309686403274536
[Epoch 21, Batch 800] loss: 2.313499000072479
[Epoch 21, Batch 900] loss: 2.3120821833610536
[Epoch 21, Batch 1000] loss: 2.311360008716583
[Epoch 21, Batch 1100] loss: 2.310848729610443
[Epoch 21, Batch 1200] loss: 2.3155350995063784
[Epoch 21, Batch 1300] loss: 2.315612075328827
[Epoch 21, Batch 1400] loss: 2.3108227849006653
[Epoch 21, Batch 1500] loss: 2.3132782983779907
[Epoch 21, Batch 1600] loss: 2.3104680514335634
[Epoch 21, Batch 1700] loss: 2.3118943047523497
[Epoch 21, Batch 1800] loss: 2.314133036136627
**STATS for Epoch 21** : 
Average training loss: 0.0925
Average validation loss: 2.3093
Validation Accuracy: 0.1126
Overfitting: 2.2169
[Epoch 22, Batch 100] loss: 2.3131157994270324
[Epoch 22, Batch 200] loss: 2.312241582870483
[Epoch 22, Batch 300] loss: 2.3146874737739562
[Epoch 22, Batch 400] loss: 2.3113908886909487
[Epoch 22, Batch 500] loss: 2.3133453488349915
[Epoch 22, Batch 600] loss: 2.3111722970008852
[Epoch 22, Batch 700] loss: 2.3150260162353518
[Epoch 22, Batch 800] loss: 2.3104069948196413
[Epoch 22, Batch 900] loss: 2.315588300228119
[Epoch 22, Batch 1000] loss: 2.3167002534866334
[Epoch 22, Batch 1100] loss: 2.3076480793952943
[Epoch 22, Batch 1200] loss: 2.309434988498688
[Epoch 22, Batch 1300] loss: 2.3049260449409483
[Epoch 22, Batch 1400] loss: 2.3095065474510195
[Epoch 22, Batch 1500] loss: 2.3103600215911864
[Epoch 22, Batch 1600] loss: 2.308651669025421
[Epoch 22, Batch 1700] loss: 2.310130808353424
[Epoch 22, Batch 1800] loss: 2.3086496686935423
**STATS for Epoch 22** : 
Average training loss: 0.0924
Average validation loss: 2.3078
Validation Accuracy: 0.1126
Overfitting: 2.2154
[Epoch 23, Batch 100] loss: 2.3159234046936037
[Epoch 23, Batch 200] loss: 2.312961177825928
[Epoch 23, Batch 300] loss: 2.3088321590423586
[Epoch 23, Batch 400] loss: 2.306896824836731
[Epoch 23, Batch 500] loss: 2.3179530787467955
[Epoch 23, Batch 600] loss: 2.312580578327179
[Epoch 23, Batch 700] loss: 2.3097691559791564
[Epoch 23, Batch 800] loss: 2.3080370879173278
[Epoch 23, Batch 900] loss: 2.3104490137100218
[Epoch 23, Batch 1000] loss: 2.314573471546173
[Epoch 23, Batch 1100] loss: 2.309282166957855
[Epoch 23, Batch 1200] loss: 2.3138543725013734
[Epoch 23, Batch 1300] loss: 2.314347195625305
[Epoch 23, Batch 1400] loss: 2.3119691014289856
[Epoch 23, Batch 1500] loss: 2.31320387840271
[Epoch 23, Batch 1600] loss: 2.31416579246521
[Epoch 23, Batch 1700] loss: 2.311747603416443
[Epoch 23, Batch 1800] loss: 2.309074082374573
**STATS for Epoch 23** : 
Average training loss: 0.0924
Average validation loss: 2.3069
Validation Accuracy: 0.1126
Overfitting: 2.2145
[Epoch 24, Batch 100] loss: 2.3177105927467347
[Epoch 24, Batch 200] loss: 2.3129663395881654
[Epoch 24, Batch 300] loss: 2.3091971707344054
[Epoch 24, Batch 400] loss: 2.311149263381958
[Epoch 24, Batch 500] loss: 2.31188316822052
[Epoch 24, Batch 600] loss: 2.307822563648224
[Epoch 24, Batch 700] loss: 2.3109110951423646
[Epoch 24, Batch 800] loss: 2.3154656004905703
[Epoch 24, Batch 900] loss: 2.3120744013786316
[Epoch 24, Batch 1000] loss: 2.316903603076935
[Epoch 24, Batch 1100] loss: 2.313367507457733
[Epoch 24, Batch 1200] loss: 2.3055694127082824
[Epoch 24, Batch 1300] loss: 2.310026910305023
[Epoch 24, Batch 1400] loss: 2.3102396869659425
[Epoch 24, Batch 1500] loss: 2.310739531517029
[Epoch 24, Batch 1600] loss: 2.3142571377754213
[Epoch 24, Batch 1700] loss: 2.309944441318512
[Epoch 24, Batch 1800] loss: 2.310849733352661
**STATS for Epoch 24** : 
Average training loss: 0.0926
Average validation loss: 2.3052
Validation Accuracy: 0.1126
Overfitting: 2.2126
Fold 2 validation loss: 2.3052
Mean validation loss across all folds for Trial 4 is 2.3087 with trial config:  l1: 128, l2: 128, lr: 0.07286653737491042, batch_size: 16
[I 2024-11-21 18:11:28,959] Trial 3 finished with value: 2.3087004138946536 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.07286653737491042, 'batch_size': 16}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 5:
  l1: 256, l2: 128, lr: 0.00010842262717330161, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3007000946998595
[Epoch 1, Batch 200] loss: 2.2951866960525513
[Epoch 1, Batch 300] loss: 2.2887566447257996
[Epoch 1, Batch 400] loss: 2.2802877759933473
[Epoch 1, Batch 500] loss: 2.273284833431244
[Epoch 1, Batch 600] loss: 2.2699366545677186
[Epoch 1, Batch 700] loss: 2.2598711228370667
[Epoch 1, Batch 800] loss: 2.2508296251296995
[Epoch 1, Batch 900] loss: 2.2382356095314027
[Epoch 1, Batch 1000] loss: 2.225270571708679
[Epoch 1, Batch 1100] loss: 2.2017003083229065
[Epoch 1, Batch 1200] loss: 2.1814649653434754
[Epoch 1, Batch 1300] loss: 2.15930135846138
[Epoch 1, Batch 1400] loss: 2.1226895689964294
[Epoch 1, Batch 1500] loss: 2.072177973985672
[Epoch 1, Batch 1600] loss: 2.0157232439517974
[Epoch 1, Batch 1700] loss: 1.922902981042862
[Epoch 1, Batch 1800] loss: 1.7931375467777253
**STATS for Epoch 1** : 
Average training loss: 0.0680
Average validation loss: 1.6280
Validation Accuracy: 0.6468
Overfitting: 1.5601
Best model saved at epoch 1 with validation loss: 1.6280
[Epoch 2, Batch 100] loss: 1.548200217485428
[Epoch 2, Batch 200] loss: 1.3942767345905305
[Epoch 2, Batch 300] loss: 1.2134302312135696
[Epoch 2, Batch 400] loss: 1.0390916413068771
[Epoch 2, Batch 500] loss: 0.9374887877702713
[Epoch 2, Batch 600] loss: 0.8417537993192673
[Epoch 2, Batch 700] loss: 0.7226802536845207
[Epoch 2, Batch 800] loss: 0.7178762227296829
[Epoch 2, Batch 900] loss: 0.6612723404169083
[Epoch 2, Batch 1000] loss: 0.6260665121674538
[Epoch 2, Batch 1100] loss: 0.5627890630066394
[Epoch 2, Batch 1200] loss: 0.5343035352230072
[Epoch 2, Batch 1300] loss: 0.5544701907038688
[Epoch 2, Batch 1400] loss: 0.5063288755714893
[Epoch 2, Batch 1500] loss: 0.5270791140198707
[Epoch 2, Batch 1600] loss: 0.47171941518783567
[Epoch 2, Batch 1700] loss: 0.4492387643456459
[Epoch 2, Batch 1800] loss: 0.4806188663840294
**STATS for Epoch 2** : 
Average training loss: 0.0167
Average validation loss: 0.4261
Validation Accuracy: 0.8763
Overfitting: 0.4094
Best model saved at epoch 2 with validation loss: 0.4261
[Epoch 3, Batch 100] loss: 0.4295141959190369
[Epoch 3, Batch 200] loss: 0.41574475683271883
[Epoch 3, Batch 300] loss: 0.4233001083880663
[Epoch 3, Batch 400] loss: 0.41707858435809614
[Epoch 3, Batch 500] loss: 0.35952652543783187
[Epoch 3, Batch 600] loss: 0.4017898391187191
[Epoch 3, Batch 700] loss: 0.41302929051220416
[Epoch 3, Batch 800] loss: 0.39342605113983153
[Epoch 3, Batch 900] loss: 0.36879157699644566
[Epoch 3, Batch 1000] loss: 0.3843972456455231
[Epoch 3, Batch 1100] loss: 0.36100488156080246
[Epoch 3, Batch 1200] loss: 0.3635748188197613
[Epoch 3, Batch 1300] loss: 0.3668842477351427
[Epoch 3, Batch 1400] loss: 0.3278027452528477
[Epoch 3, Batch 1500] loss: 0.36742401659488677
[Epoch 3, Batch 1600] loss: 0.3464658669382334
[Epoch 3, Batch 1700] loss: 0.30279382899403573
[Epoch 3, Batch 1800] loss: 0.3122406678646803
**STATS for Epoch 3** : 
Average training loss: 0.0142
Average validation loss: 0.3169
Validation Accuracy: 0.9053
Overfitting: 0.3028
Best model saved at epoch 3 with validation loss: 0.3169
[Epoch 4, Batch 100] loss: 0.33515030302107335
[Epoch 4, Batch 200] loss: 0.32058650489896534
[Epoch 4, Batch 300] loss: 0.2877827088907361
[Epoch 4, Batch 400] loss: 0.32045294880867004
[Epoch 4, Batch 500] loss: 0.29287331327795985
[Epoch 4, Batch 600] loss: 0.29134786676615476
[Epoch 4, Batch 700] loss: 0.3152468417584896
[Epoch 4, Batch 800] loss: 0.30064391795545814
[Epoch 4, Batch 900] loss: 0.3223291864618659
[Epoch 4, Batch 1000] loss: 0.2848998136818409
[Epoch 4, Batch 1100] loss: 0.3186776311323047
[Epoch 4, Batch 1200] loss: 0.31998480318114164
[Epoch 4, Batch 1300] loss: 0.2876159417629242
[Epoch 4, Batch 1400] loss: 0.2661551064997911
[Epoch 4, Batch 1500] loss: 0.24663201484829186
[Epoch 4, Batch 1600] loss: 0.25384433031082154
[Epoch 4, Batch 1700] loss: 0.25652897944673897
[Epoch 4, Batch 1800] loss: 0.24334043297916652
**STATS for Epoch 4** : 
Average training loss: 0.0113
Average validation loss: 0.2583
Validation Accuracy: 0.9212
Overfitting: 0.2470
Best model saved at epoch 4 with validation loss: 0.2583
[Epoch 5, Batch 100] loss: 0.2844099259749055
[Epoch 5, Batch 200] loss: 0.24821765407919882
[Epoch 5, Batch 300] loss: 0.25486533887684343
[Epoch 5, Batch 400] loss: 0.2836980587244034
[Epoch 5, Batch 500] loss: 0.22667834661900998
[Epoch 5, Batch 600] loss: 0.2730637382902205
[Epoch 5, Batch 700] loss: 0.24500390682369472
[Epoch 5, Batch 800] loss: 0.21479803150519727
[Epoch 5, Batch 900] loss: 0.24212184216827154
[Epoch 5, Batch 1000] loss: 0.24725629409775138
[Epoch 5, Batch 1100] loss: 0.21671133568510415
[Epoch 5, Batch 1200] loss: 0.25773749718442557
[Epoch 5, Batch 1300] loss: 0.24677742134779693
[Epoch 5, Batch 1400] loss: 0.23734447568655015
[Epoch 5, Batch 1500] loss: 0.24386418743059038
[Epoch 5, Batch 1600] loss: 0.20695699479430915
[Epoch 5, Batch 1700] loss: 0.22671468598768116
[Epoch 5, Batch 1800] loss: 0.2257747358828783
**STATS for Epoch 5** : 
Average training loss: 0.0092
Average validation loss: 0.2278
Validation Accuracy: 0.9300
Overfitting: 0.2186
Best model saved at epoch 5 with validation loss: 0.2278
[Epoch 6, Batch 100] loss: 0.2161201367713511
[Epoch 6, Batch 200] loss: 0.2081535834632814
[Epoch 6, Batch 300] loss: 0.2049563081935048
[Epoch 6, Batch 400] loss: 0.2016226758249104
[Epoch 6, Batch 500] loss: 0.21372722752392292
[Epoch 6, Batch 600] loss: 0.2207554342597723
[Epoch 6, Batch 700] loss: 0.20870714092627168
[Epoch 6, Batch 800] loss: 0.1978821331076324
[Epoch 6, Batch 900] loss: 0.22901408419013022
[Epoch 6, Batch 1000] loss: 0.20905009193345905
[Epoch 6, Batch 1100] loss: 0.1885616804473102
[Epoch 6, Batch 1200] loss: 0.20262470994144677
[Epoch 6, Batch 1300] loss: 0.186284354403615
[Epoch 6, Batch 1400] loss: 0.21913876574486493
[Epoch 6, Batch 1500] loss: 0.19757812356576324
[Epoch 6, Batch 1600] loss: 0.2040221632923931
[Epoch 6, Batch 1700] loss: 0.17663002280518414
[Epoch 6, Batch 1800] loss: 0.19407570015639067
**STATS for Epoch 6** : 
Average training loss: 0.0084
Average validation loss: 0.1924
Validation Accuracy: 0.9401
Overfitting: 0.1841
Best model saved at epoch 6 with validation loss: 0.1924
[Epoch 7, Batch 100] loss: 0.17004985427483915
[Epoch 7, Batch 200] loss: 0.18039622239768505
[Epoch 7, Batch 300] loss: 0.17029224386438727
[Epoch 7, Batch 400] loss: 0.2000761992763728
[Epoch 7, Batch 500] loss: 0.1950207824073732
[Epoch 7, Batch 600] loss: 0.17936290193349122
[Epoch 7, Batch 700] loss: 0.18615995877422392
[Epoch 7, Batch 800] loss: 0.18686307130381466
[Epoch 7, Batch 900] loss: 0.17037911331281066
[Epoch 7, Batch 1000] loss: 0.1623971754964441
[Epoch 7, Batch 1100] loss: 0.17590319650247693
[Epoch 7, Batch 1200] loss: 0.18707674578763545
[Epoch 7, Batch 1300] loss: 0.1746334288176149
[Epoch 7, Batch 1400] loss: 0.15772465963847934
[Epoch 7, Batch 1500] loss: 0.16281018057838081
[Epoch 7, Batch 1600] loss: 0.18128534467890858
[Epoch 7, Batch 1700] loss: 0.19014026321470737
[Epoch 7, Batch 1800] loss: 0.1703182219993323
**STATS for Epoch 7** : 
Average training loss: 0.0063
Average validation loss: 0.1714
Validation Accuracy: 0.9477
Overfitting: 0.1650
Best model saved at epoch 7 with validation loss: 0.1714
[Epoch 8, Batch 100] loss: 0.14595221842639147
[Epoch 8, Batch 200] loss: 0.12054538881406188
[Epoch 8, Batch 300] loss: 0.17058440195396543
[Epoch 8, Batch 400] loss: 0.15144472052343189
[Epoch 8, Batch 500] loss: 0.17864488529972733
[Epoch 8, Batch 600] loss: 0.171086668651551
[Epoch 8, Batch 700] loss: 0.15597787593491375
[Epoch 8, Batch 800] loss: 0.17936056531965733
[Epoch 8, Batch 900] loss: 0.17442107351496816
[Epoch 8, Batch 1000] loss: 0.12880709522869438
[Epoch 8, Batch 1100] loss: 0.16724565237760544
[Epoch 8, Batch 1200] loss: 0.15106606917921453
[Epoch 8, Batch 1300] loss: 0.16028285847976803
[Epoch 8, Batch 1400] loss: 0.15514390770345926
[Epoch 8, Batch 1500] loss: 0.1361740447767079
[Epoch 8, Batch 1600] loss: 0.15829264456406236
[Epoch 8, Batch 1700] loss: 0.14885980819584801
[Epoch 8, Batch 1800] loss: 0.17462174880318343
**STATS for Epoch 8** : 
Average training loss: 0.0058
Average validation loss: 0.1528
Validation Accuracy: 0.9538
Overfitting: 0.1470
Best model saved at epoch 8 with validation loss: 0.1528
[Epoch 9, Batch 100] loss: 0.153202711250633
[Epoch 9, Batch 200] loss: 0.12046429366804659
[Epoch 9, Batch 300] loss: 0.1436850585974753
[Epoch 9, Batch 400] loss: 0.1425653289584443
[Epoch 9, Batch 500] loss: 0.1286896647932008
[Epoch 9, Batch 600] loss: 0.15010035989806056
[Epoch 9, Batch 700] loss: 0.14460446650628
[Epoch 9, Batch 800] loss: 0.14369322072248905
[Epoch 9, Batch 900] loss: 0.1514384715259075
[Epoch 9, Batch 1000] loss: 0.13255409179721028
[Epoch 9, Batch 1100] loss: 0.1612181799625978
[Epoch 9, Batch 1200] loss: 0.17264527739025654
[Epoch 9, Batch 1300] loss: 0.1174181818170473
[Epoch 9, Batch 1400] loss: 0.14730104812886566
[Epoch 9, Batch 1500] loss: 0.12523839487694205
[Epoch 9, Batch 1600] loss: 0.14518468581605704
[Epoch 9, Batch 1700] loss: 0.12551065626554192
[Epoch 9, Batch 1800] loss: 0.13976037536747754
**STATS for Epoch 9** : 
Average training loss: 0.0048
Average validation loss: 0.1398
Validation Accuracy: 0.9581
Overfitting: 0.1350
Best model saved at epoch 9 with validation loss: 0.1398
[Epoch 10, Batch 100] loss: 0.1137538533192128
[Epoch 10, Batch 200] loss: 0.1299755757022649
[Epoch 10, Batch 300] loss: 0.13131013727281243
[Epoch 10, Batch 400] loss: 0.15583037950098513
[Epoch 10, Batch 500] loss: 0.1322295464249328
[Epoch 10, Batch 600] loss: 0.1352739307936281
[Epoch 10, Batch 700] loss: 0.12960570021299644
[Epoch 10, Batch 800] loss: 0.1091832786402665
[Epoch 10, Batch 900] loss: 0.12955687815323472
[Epoch 10, Batch 1000] loss: 0.1435446048900485
[Epoch 10, Batch 1100] loss: 0.10783264392986894
[Epoch 10, Batch 1200] loss: 0.12722170914523304
[Epoch 10, Batch 1300] loss: 0.1210157616250217
[Epoch 10, Batch 1400] loss: 0.15160910682287068
[Epoch 10, Batch 1500] loss: 0.12353809437248855
[Epoch 10, Batch 1600] loss: 0.12285926267970354
[Epoch 10, Batch 1700] loss: 0.11542872938793153
[Epoch 10, Batch 1800] loss: 0.09448004444129765
**STATS for Epoch 10** : 
Average training loss: 0.0054
Average validation loss: 0.1418
Validation Accuracy: 0.9566
Overfitting: 0.1364
[Epoch 11, Batch 100] loss: 0.11896577158942818
[Epoch 11, Batch 200] loss: 0.1207226205104962
[Epoch 11, Batch 300] loss: 0.10250128216343
[Epoch 11, Batch 400] loss: 0.1148793234815821
[Epoch 11, Batch 500] loss: 0.11965745536610484
[Epoch 11, Batch 600] loss: 0.11071365227224306
[Epoch 11, Batch 700] loss: 0.14176471894606948
[Epoch 11, Batch 800] loss: 0.11784171405248343
[Epoch 11, Batch 900] loss: 0.10652265518438071
[Epoch 11, Batch 1000] loss: 0.13216946478933095
[Epoch 11, Batch 1100] loss: 0.12149384135846049
[Epoch 11, Batch 1200] loss: 0.09525691507849843
[Epoch 11, Batch 1300] loss: 0.13879105109721424
[Epoch 11, Batch 1400] loss: 0.12516427457798274
[Epoch 11, Batch 1500] loss: 0.10945758929476142
[Epoch 11, Batch 1600] loss: 0.09111708882730454
[Epoch 11, Batch 1700] loss: 0.1126808676449582
[Epoch 11, Batch 1800] loss: 0.12023195748683065
**STATS for Epoch 11** : 
Average training loss: 0.0044
Average validation loss: 0.1290
Validation Accuracy: 0.9612
Overfitting: 0.1245
Best model saved at epoch 11 with validation loss: 0.1290
[Epoch 12, Batch 100] loss: 0.1321117627574131
[Epoch 12, Batch 200] loss: 0.1155626674927771
[Epoch 12, Batch 300] loss: 0.09037732140626759
[Epoch 12, Batch 400] loss: 0.0910469243908301
[Epoch 12, Batch 500] loss: 0.10370118533726781
[Epoch 12, Batch 600] loss: 0.13722286690957844
[Epoch 12, Batch 700] loss: 0.10079045029124245
[Epoch 12, Batch 800] loss: 0.11110479474067687
[Epoch 12, Batch 900] loss: 0.0912766390806064
[Epoch 12, Batch 1000] loss: 0.1210892222984694
[Epoch 12, Batch 1100] loss: 0.10307678473880515
[Epoch 12, Batch 1200] loss: 0.10413721670745872
[Epoch 12, Batch 1300] loss: 0.10279332069214434
[Epoch 12, Batch 1400] loss: 0.11894795396598055
[Epoch 12, Batch 1500] loss: 0.10078477516071871
[Epoch 12, Batch 1600] loss: 0.1141552310436964
[Epoch 12, Batch 1700] loss: 0.09962192956358194
[Epoch 12, Batch 1800] loss: 0.12461516081355511
**STATS for Epoch 12** : 
Average training loss: 0.0040
Average validation loss: 0.1278
Validation Accuracy: 0.9607
Overfitting: 0.1238
Best model saved at epoch 12 with validation loss: 0.1278
[Epoch 13, Batch 100] loss: 0.1022039827471599
[Epoch 13, Batch 200] loss: 0.09627092956099659
[Epoch 13, Batch 300] loss: 0.11850990212056786
[Epoch 13, Batch 400] loss: 0.08646275193430483
[Epoch 13, Batch 500] loss: 0.11003549421438948
[Epoch 13, Batch 600] loss: 0.10848135442938656
[Epoch 13, Batch 700] loss: 0.08199633007403463
[Epoch 13, Batch 800] loss: 0.10652620065025985
[Epoch 13, Batch 900] loss: 0.13408108424395324
[Epoch 13, Batch 1000] loss: 0.0909804810071364
[Epoch 13, Batch 1100] loss: 0.11009117771871388
[Epoch 13, Batch 1200] loss: 0.09772285560378804
[Epoch 13, Batch 1300] loss: 0.09310869389679283
[Epoch 13, Batch 1400] loss: 0.11141048261662945
[Epoch 13, Batch 1500] loss: 0.08030455574858934
[Epoch 13, Batch 1600] loss: 0.09444710540119558
[Epoch 13, Batch 1700] loss: 0.11229824690730311
[Epoch 13, Batch 1800] loss: 0.09625255662831478
**STATS for Epoch 13** : 
Average training loss: 0.0033
Average validation loss: 0.1101
Validation Accuracy: 0.9667
Overfitting: 0.1068
Best model saved at epoch 13 with validation loss: 0.1101
[Epoch 14, Batch 100] loss: 0.10109186514280737
[Epoch 14, Batch 200] loss: 0.09014982698485255
[Epoch 14, Batch 300] loss: 0.07642714853398502
[Epoch 14, Batch 400] loss: 0.08500346716726198
[Epoch 14, Batch 500] loss: 0.0946276668109931
[Epoch 14, Batch 600] loss: 0.07849639094318263
[Epoch 14, Batch 700] loss: 0.07748009259696119
[Epoch 14, Batch 800] loss: 0.10541874925373122
[Epoch 14, Batch 900] loss: 0.0992702449450735
[Epoch 14, Batch 1000] loss: 0.11292327072937042
[Epoch 14, Batch 1100] loss: 0.09167115320451558
[Epoch 14, Batch 1200] loss: 0.09243757934309542
[Epoch 14, Batch 1300] loss: 0.10332714864518494
[Epoch 14, Batch 1400] loss: 0.09956971023231745
[Epoch 14, Batch 1500] loss: 0.08016505223116838
[Epoch 14, Batch 1600] loss: 0.10418102808296681
[Epoch 14, Batch 1700] loss: 0.10847181060817093
[Epoch 14, Batch 1800] loss: 0.11040337485959753
**STATS for Epoch 14** : 
Average training loss: 0.0031
Average validation loss: 0.1102
Validation Accuracy: 0.9656
Overfitting: 0.1071
[Epoch 15, Batch 100] loss: 0.09259048295440152
[Epoch 15, Batch 200] loss: 0.09925040203845129
[Epoch 15, Batch 300] loss: 0.08072561488253996
[Epoch 15, Batch 400] loss: 0.09944555199472234
[Epoch 15, Batch 500] loss: 0.09052060502348468
[Epoch 15, Batch 600] loss: 0.0985216240142472
[Epoch 15, Batch 700] loss: 0.10306058751652017
[Epoch 15, Batch 800] loss: 0.08963679367676378
[Epoch 15, Batch 900] loss: 0.0768755589670036
[Epoch 15, Batch 1000] loss: 0.07819249650696293
[Epoch 15, Batch 1100] loss: 0.09717280039098114
[Epoch 15, Batch 1200] loss: 0.07280986452708021
[Epoch 15, Batch 1300] loss: 0.08787361507420428
[Epoch 15, Batch 1400] loss: 0.10156277351314202
[Epoch 15, Batch 1500] loss: 0.08978700060630217
[Epoch 15, Batch 1600] loss: 0.07928772548679262
[Epoch 15, Batch 1700] loss: 0.07895873797358945
[Epoch 15, Batch 1800] loss: 0.1091471068537794
**STATS for Epoch 15** : 
Average training loss: 0.0030
Average validation loss: 0.1002
Validation Accuracy: 0.9688
Overfitting: 0.0972
Best model saved at epoch 15 with validation loss: 0.1002
[Epoch 16, Batch 100] loss: 0.09510884735267609
[Epoch 16, Batch 200] loss: 0.0894024297920987
[Epoch 16, Batch 300] loss: 0.07684328254777938
[Epoch 16, Batch 400] loss: 0.07663092214148491
[Epoch 16, Batch 500] loss: 0.08030138693982736
[Epoch 16, Batch 600] loss: 0.09376766855129973
[Epoch 16, Batch 700] loss: 0.0892636159574613
[Epoch 16, Batch 800] loss: 0.08009225808549672
[Epoch 16, Batch 900] loss: 0.10889691869728267
[Epoch 16, Batch 1000] loss: 0.07417273791274055
[Epoch 16, Batch 1100] loss: 0.09335551653522998
[Epoch 16, Batch 1200] loss: 0.08567443041829392
[Epoch 16, Batch 1300] loss: 0.08149677481502295
[Epoch 16, Batch 1400] loss: 0.09253611724125221
[Epoch 16, Batch 1500] loss: 0.09853642839239911
[Epoch 16, Batch 1600] loss: 0.07865042364341207
[Epoch 16, Batch 1700] loss: 0.079698946129065
[Epoch 16, Batch 1800] loss: 0.06446848027640954
**STATS for Epoch 16** : 
Average training loss: 0.0029
Average validation loss: 0.0958
Validation Accuracy: 0.9698
Overfitting: 0.0929
Best model saved at epoch 16 with validation loss: 0.0958
[Epoch 17, Batch 100] loss: 0.06962133655091747
[Epoch 17, Batch 200] loss: 0.06787699166452513
[Epoch 17, Batch 300] loss: 0.10271058408077806
[Epoch 17, Batch 400] loss: 0.07379754210822284
[Epoch 17, Batch 500] loss: 0.09207510054344312
[Epoch 17, Batch 600] loss: 0.07434733347734436
[Epoch 17, Batch 700] loss: 0.07815611537196673
[Epoch 17, Batch 800] loss: 0.09032878882833756
[Epoch 17, Batch 900] loss: 0.07768121514818631
[Epoch 17, Batch 1000] loss: 0.08616402580984868
[Epoch 17, Batch 1100] loss: 0.09212823444977403
[Epoch 17, Batch 1200] loss: 0.07123764877440408
[Epoch 17, Batch 1300] loss: 0.08300797523232177
[Epoch 17, Batch 1400] loss: 0.09321655881358311
[Epoch 17, Batch 1500] loss: 0.09118135165888816
[Epoch 17, Batch 1600] loss: 0.07832001041271724
[Epoch 17, Batch 1700] loss: 0.07568547940813004
[Epoch 17, Batch 1800] loss: 0.07052403560373932
**STATS for Epoch 17** : 
Average training loss: 0.0029
Average validation loss: 0.0924
Validation Accuracy: 0.9716
Overfitting: 0.0895
Best model saved at epoch 17 with validation loss: 0.0924
[Epoch 18, Batch 100] loss: 0.10030264833243564
[Epoch 18, Batch 200] loss: 0.0771167103992775
[Epoch 18, Batch 300] loss: 0.09029704378219322
[Epoch 18, Batch 400] loss: 0.09286659056437202
[Epoch 18, Batch 500] loss: 0.054013470557983966
[Epoch 18, Batch 600] loss: 0.06439438059460371
[Epoch 18, Batch 700] loss: 0.08178035722346977
[Epoch 18, Batch 800] loss: 0.08506035934668034
[Epoch 18, Batch 900] loss: 0.06844339662813581
[Epoch 18, Batch 1000] loss: 0.07964420859236271
[Epoch 18, Batch 1100] loss: 0.06786478478228673
[Epoch 18, Batch 1200] loss: 0.08763210450299085
[Epoch 18, Batch 1300] loss: 0.06554383106296882
[Epoch 18, Batch 1400] loss: 0.0728790963103529
[Epoch 18, Batch 1500] loss: 0.06902896356943529
[Epoch 18, Batch 1600] loss: 0.070569302343647
[Epoch 18, Batch 1700] loss: 0.07025031523196958
[Epoch 18, Batch 1800] loss: 0.0918088483781321
**STATS for Epoch 18** : 
Average training loss: 0.0030
Average validation loss: 0.0866
Validation Accuracy: 0.9733
Overfitting: 0.0836
Best model saved at epoch 18 with validation loss: 0.0866
[Epoch 19, Batch 100] loss: 0.0847369621839607
[Epoch 19, Batch 200] loss: 0.0876438300596783
[Epoch 19, Batch 300] loss: 0.06704030909459106
[Epoch 19, Batch 400] loss: 0.06159075983567163
[Epoch 19, Batch 500] loss: 0.07347442861122545
[Epoch 19, Batch 600] loss: 0.0645054002571851
[Epoch 19, Batch 700] loss: 0.08073770968127064
[Epoch 19, Batch 800] loss: 0.07075562853948213
[Epoch 19, Batch 900] loss: 0.08217633863212541
[Epoch 19, Batch 1000] loss: 0.07007884966908023
[Epoch 19, Batch 1100] loss: 0.06948666523909196
[Epoch 19, Batch 1200] loss: 0.08958218525745906
[Epoch 19, Batch 1300] loss: 0.06866993049858137
[Epoch 19, Batch 1400] loss: 0.07628498770762235
[Epoch 19, Batch 1500] loss: 0.08348613865673542
[Epoch 19, Batch 1600] loss: 0.0694301702931989
[Epoch 19, Batch 1700] loss: 0.06788566493429243
[Epoch 19, Batch 1800] loss: 0.06924678156501614
**STATS for Epoch 19** : 
Average training loss: 0.0028
Average validation loss: 0.0859
Validation Accuracy: 0.9735
Overfitting: 0.0831
Best model saved at epoch 19 with validation loss: 0.0859
[Epoch 20, Batch 100] loss: 0.05901101486873813
[Epoch 20, Batch 200] loss: 0.07776489390991628
[Epoch 20, Batch 300] loss: 0.06001155909558292
[Epoch 20, Batch 400] loss: 0.07233439319184981
[Epoch 20, Batch 500] loss: 0.06038517967215739
[Epoch 20, Batch 600] loss: 0.07351957914303058
[Epoch 20, Batch 700] loss: 0.06629658374818974
[Epoch 20, Batch 800] loss: 0.06044833532010671
[Epoch 20, Batch 900] loss: 0.07488546566804871
[Epoch 20, Batch 1000] loss: 0.0652013845363399
[Epoch 20, Batch 1100] loss: 0.07331761250738054
[Epoch 20, Batch 1200] loss: 0.09390435245353729
[Epoch 20, Batch 1300] loss: 0.08198784802225419
[Epoch 20, Batch 1400] loss: 0.07508845245232805
[Epoch 20, Batch 1500] loss: 0.07055212901730556
[Epoch 20, Batch 1600] loss: 0.06221169988857582
[Epoch 20, Batch 1700] loss: 0.06539190498413518
[Epoch 20, Batch 1800] loss: 0.07297220770502463
**STATS for Epoch 20** : 
Average training loss: 0.0030
Average validation loss: 0.0921
Validation Accuracy: 0.9720
Overfitting: 0.0892
[Epoch 21, Batch 100] loss: 0.05392045151093043
[Epoch 21, Batch 200] loss: 0.08083044059341774
[Epoch 21, Batch 300] loss: 0.06124067177763209
[Epoch 21, Batch 400] loss: 0.06452322432072834
[Epoch 21, Batch 500] loss: 0.08437961398856714
[Epoch 21, Batch 600] loss: 0.08602933256421239
[Epoch 21, Batch 700] loss: 0.05593329993193038
[Epoch 21, Batch 800] loss: 0.07392783072544262
[Epoch 21, Batch 900] loss: 0.0565955765201943
[Epoch 21, Batch 1000] loss: 0.0594369951239787
[Epoch 21, Batch 1100] loss: 0.0791677211143542
[Epoch 21, Batch 1200] loss: 0.07128104051458649
[Epoch 21, Batch 1300] loss: 0.06647179489489645
[Epoch 21, Batch 1400] loss: 0.06319977511418984
[Epoch 21, Batch 1500] loss: 0.07873968867235817
[Epoch 21, Batch 1600] loss: 0.08429761048988439
[Epoch 21, Batch 1700] loss: 0.045751598422648386
[Epoch 21, Batch 1800] loss: 0.054426030496833845
**STATS for Epoch 21** : 
Average training loss: 0.0023
Average validation loss: 0.0843
Validation Accuracy: 0.9741
Overfitting: 0.0820
Best model saved at epoch 21 with validation loss: 0.0843
[Epoch 22, Batch 100] loss: 0.04657024630927481
[Epoch 22, Batch 200] loss: 0.06683729139855131
[Epoch 22, Batch 300] loss: 0.06684939525322989
[Epoch 22, Batch 400] loss: 0.05678472971427254
[Epoch 22, Batch 500] loss: 0.060705371248768646
[Epoch 22, Batch 600] loss: 0.0729088615666842
[Epoch 22, Batch 700] loss: 0.06127316112921108
[Epoch 22, Batch 800] loss: 0.06987156428163871
[Epoch 22, Batch 900] loss: 0.05678179688053206
[Epoch 22, Batch 1000] loss: 0.0810958468739409
[Epoch 22, Batch 1100] loss: 0.08003371200000402
[Epoch 22, Batch 1200] loss: 0.0668762525805505
[Epoch 22, Batch 1300] loss: 0.06614259182475507
[Epoch 22, Batch 1400] loss: 0.06203231077524833
[Epoch 22, Batch 1500] loss: 0.07060446205548943
[Epoch 22, Batch 1600] loss: 0.0709449041390326
[Epoch 22, Batch 1700] loss: 0.06823423927358817
[Epoch 22, Batch 1800] loss: 0.064055219568545
**STATS for Epoch 22** : 
Average training loss: 0.0018
Average validation loss: 0.0835
Validation Accuracy: 0.9738
Overfitting: 0.0817
Best model saved at epoch 22 with validation loss: 0.0835
[Epoch 23, Batch 100] loss: 0.07345815639710054
[Epoch 23, Batch 200] loss: 0.07055912521085701
[Epoch 23, Batch 300] loss: 0.04970001931767911
[Epoch 23, Batch 400] loss: 0.051284470112295824
[Epoch 23, Batch 500] loss: 0.07635994580225088
[Epoch 23, Batch 600] loss: 0.056689240665291435
[Epoch 23, Batch 700] loss: 0.06152086336282082
[Epoch 23, Batch 800] loss: 0.06236099666683003
[Epoch 23, Batch 900] loss: 0.04909710008068942
[Epoch 23, Batch 1000] loss: 0.05871970689389855
[Epoch 23, Batch 1100] loss: 0.055740322502097116
[Epoch 23, Batch 1200] loss: 0.056859280843054874
[Epoch 23, Batch 1300] loss: 0.07169938016973902
[Epoch 23, Batch 1400] loss: 0.07553326416411438
[Epoch 23, Batch 1500] loss: 0.06495716867153532
[Epoch 23, Batch 1600] loss: 0.058928871690295634
[Epoch 23, Batch 1700] loss: 0.07299131733831019
[Epoch 23, Batch 1800] loss: 0.05887106829555705
**STATS for Epoch 23** : 
Average training loss: 0.0025
Average validation loss: 0.0768
Validation Accuracy: 0.9758
Overfitting: 0.0743
Best model saved at epoch 23 with validation loss: 0.0768
[Epoch 24, Batch 100] loss: 0.07063554522581399
[Epoch 24, Batch 200] loss: 0.05845793227665126
[Epoch 24, Batch 300] loss: 0.039748624982312325
[Epoch 24, Batch 400] loss: 0.07184579604538158
[Epoch 24, Batch 500] loss: 0.06527062646811828
[Epoch 24, Batch 600] loss: 0.045627074444200846
[Epoch 24, Batch 700] loss: 0.06908559811301529
[Epoch 24, Batch 800] loss: 0.05824564050184563
[Epoch 24, Batch 900] loss: 0.0663241098902654
[Epoch 24, Batch 1000] loss: 0.07203666494926438
[Epoch 24, Batch 1100] loss: 0.058414128815056754
[Epoch 24, Batch 1200] loss: 0.04181898479582742
[Epoch 24, Batch 1300] loss: 0.05233010216383263
[Epoch 24, Batch 1400] loss: 0.05843321624211967
[Epoch 24, Batch 1500] loss: 0.06906591050443239
[Epoch 24, Batch 1600] loss: 0.0679967399383895
[Epoch 24, Batch 1700] loss: 0.06367910214117728
[Epoch 24, Batch 1800] loss: 0.08074679990997538
**STATS for Epoch 24** : 
Average training loss: 0.0017
Average validation loss: 0.0736
Validation Accuracy: 0.9767
Overfitting: 0.0719
Best model saved at epoch 24 with validation loss: 0.0736
Fold 1 validation loss: 0.0736
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.3005083107948305
[Epoch 1, Batch 200] loss: 2.2947704935073854
[Epoch 1, Batch 300] loss: 2.292419910430908
[Epoch 1, Batch 400] loss: 2.292555477619171
[Epoch 1, Batch 500] loss: 2.288722560405731
[Epoch 1, Batch 600] loss: 2.2863633608818055
[Epoch 1, Batch 700] loss: 2.2853048968315126
[Epoch 1, Batch 800] loss: 2.2767608976364135
[Epoch 1, Batch 900] loss: 2.2760552310943605
[Epoch 1, Batch 1000] loss: 2.2697691535949707
[Epoch 1, Batch 1100] loss: 2.2652063250541685
[Epoch 1, Batch 1200] loss: 2.2603143310546874
[Epoch 1, Batch 1300] loss: 2.25373042345047
[Epoch 1, Batch 1400] loss: 2.2470746994018556
[Epoch 1, Batch 1500] loss: 2.2377680373191833
[Epoch 1, Batch 1600] loss: 2.228666479587555
[Epoch 1, Batch 1700] loss: 2.2193896627426146
[Epoch 1, Batch 1800] loss: 2.197865743637085
**STATS for Epoch 1** : 
Average training loss: 0.0875
Average validation loss: 2.1788
Validation Accuracy: 0.3256
Overfitting: 2.0914
Best model saved at epoch 1 with validation loss: 2.1788
[Epoch 2, Batch 100] loss: 2.1657831621170045
[Epoch 2, Batch 200] loss: 2.1399974060058593
[Epoch 2, Batch 300] loss: 2.0984861993789674
[Epoch 2, Batch 400] loss: 2.051456381082535
[Epoch 2, Batch 500] loss: 2.000695449113846
[Epoch 2, Batch 600] loss: 1.911622326374054
[Epoch 2, Batch 700] loss: 1.8222447478771209
[Epoch 2, Batch 800] loss: 1.6463980305194854
[Epoch 2, Batch 900] loss: 1.4997250306606293
[Epoch 2, Batch 1000] loss: 1.298414957523346
[Epoch 2, Batch 1100] loss: 1.1354707437753677
[Epoch 2, Batch 1200] loss: 1.014280133843422
[Epoch 2, Batch 1300] loss: 0.8933398795127868
[Epoch 2, Batch 1400] loss: 0.8436127051711082
[Epoch 2, Batch 1500] loss: 0.7699714607000351
[Epoch 2, Batch 1600] loss: 0.6649952620267868
[Epoch 2, Batch 1700] loss: 0.6868447676301003
[Epoch 2, Batch 1800] loss: 0.6275233356654644
**STATS for Epoch 2** : 
Average training loss: 0.0251
Average validation loss: 0.6018
Validation Accuracy: 0.8241
Overfitting: 0.5766
Best model saved at epoch 2 with validation loss: 0.6018
[Epoch 3, Batch 100] loss: 0.6011715471744538
[Epoch 3, Batch 200] loss: 0.5531088238954545
[Epoch 3, Batch 300] loss: 0.5367678898572922
[Epoch 3, Batch 400] loss: 0.5049402987957001
[Epoch 3, Batch 500] loss: 0.5115845210850238
[Epoch 3, Batch 600] loss: 0.5160966557264328
[Epoch 3, Batch 700] loss: 0.4961527363955975
[Epoch 3, Batch 800] loss: 0.46776898466050626
[Epoch 3, Batch 900] loss: 0.4942755404859781
[Epoch 3, Batch 1000] loss: 0.44781712517142297
[Epoch 3, Batch 1100] loss: 0.4473020484298468
[Epoch 3, Batch 1200] loss: 0.45597657084465026
[Epoch 3, Batch 1300] loss: 0.42208620250225065
[Epoch 3, Batch 1400] loss: 0.3842809147387743
[Epoch 3, Batch 1500] loss: 0.4311602834612131
[Epoch 3, Batch 1600] loss: 0.4099820712953806
[Epoch 3, Batch 1700] loss: 0.4049595598131418
[Epoch 3, Batch 1800] loss: 0.38901328973472116
**STATS for Epoch 3** : 
Average training loss: 0.0154
Average validation loss: 0.3881
Validation Accuracy: 0.8864
Overfitting: 0.3727
Best model saved at epoch 3 with validation loss: 0.3881
[Epoch 4, Batch 100] loss: 0.399190831258893
[Epoch 4, Batch 200] loss: 0.3854734731838107
[Epoch 4, Batch 300] loss: 0.41380701698362826
[Epoch 4, Batch 400] loss: 0.3742626940459013
[Epoch 4, Batch 500] loss: 0.3308732962608337
[Epoch 4, Batch 600] loss: 0.349744681045413
[Epoch 4, Batch 700] loss: 0.3683355649188161
[Epoch 4, Batch 800] loss: 0.35889802109450103
[Epoch 4, Batch 900] loss: 0.3501749507710338
[Epoch 4, Batch 1000] loss: 0.3544768783450127
[Epoch 4, Batch 1100] loss: 0.319320203140378
[Epoch 4, Batch 1200] loss: 0.3233473027125001
[Epoch 4, Batch 1300] loss: 0.337047405205667
[Epoch 4, Batch 1400] loss: 0.31757429111748936
[Epoch 4, Batch 1500] loss: 0.3401892490684986
[Epoch 4, Batch 1600] loss: 0.32602164581418036
[Epoch 4, Batch 1700] loss: 0.3163215684145689
[Epoch 4, Batch 1800] loss: 0.3032113172486424
**STATS for Epoch 4** : 
Average training loss: 0.0143
Average validation loss: 0.3191
Validation Accuracy: 0.9023
Overfitting: 0.3048
Best model saved at epoch 4 with validation loss: 0.3191
[Epoch 5, Batch 100] loss: 0.3338231673836708
[Epoch 5, Batch 200] loss: 0.2876557556539774
[Epoch 5, Batch 300] loss: 0.31689445931464433
[Epoch 5, Batch 400] loss: 0.30212460827082394
[Epoch 5, Batch 500] loss: 0.31115003272891045
[Epoch 5, Batch 600] loss: 0.3174566466733813
[Epoch 5, Batch 700] loss: 0.2865938290581107
[Epoch 5, Batch 800] loss: 0.29220898155122993
[Epoch 5, Batch 900] loss: 0.2944793886691332
[Epoch 5, Batch 1000] loss: 0.28021395836025476
[Epoch 5, Batch 1100] loss: 0.28385716423392293
[Epoch 5, Batch 1200] loss: 0.2702657826244831
[Epoch 5, Batch 1300] loss: 0.2630572408437729
[Epoch 5, Batch 1400] loss: 0.2532730492949486
[Epoch 5, Batch 1500] loss: 0.30567720357328654
[Epoch 5, Batch 1600] loss: 0.251873761434108
[Epoch 5, Batch 1700] loss: 0.25757395723834636
[Epoch 5, Batch 1800] loss: 0.2629861042276025
**STATS for Epoch 5** : 
Average training loss: 0.0101
Average validation loss: 0.2861
Validation Accuracy: 0.9112
Overfitting: 0.2760
Best model saved at epoch 5 with validation loss: 0.2861
[Epoch 6, Batch 100] loss: 0.24294803569093346
[Epoch 6, Batch 200] loss: 0.24437481187283994
[Epoch 6, Batch 300] loss: 0.2288810372725129
[Epoch 6, Batch 400] loss: 0.28427949383854867
[Epoch 6, Batch 500] loss: 0.24350792568176985
[Epoch 6, Batch 600] loss: 0.2735191867686808
[Epoch 6, Batch 700] loss: 0.23398809876292945
[Epoch 6, Batch 800] loss: 0.24269227929413317
[Epoch 6, Batch 900] loss: 0.2322554870788008
[Epoch 6, Batch 1000] loss: 0.2602203708700836
[Epoch 6, Batch 1100] loss: 0.24064025124534966
[Epoch 6, Batch 1200] loss: 0.27098591446876524
[Epoch 6, Batch 1300] loss: 0.23208407314494253
[Epoch 6, Batch 1400] loss: 0.2553203000780195
[Epoch 6, Batch 1500] loss: 0.24348194263875483
[Epoch 6, Batch 1600] loss: 0.22996938940137623
[Epoch 6, Batch 1700] loss: 0.22076574785634875
[Epoch 6, Batch 1800] loss: 0.23446233302354813
**STATS for Epoch 6** : 
Average training loss: 0.0089
Average validation loss: 0.2308
Validation Accuracy: 0.9287
Overfitting: 0.2219
Best model saved at epoch 6 with validation loss: 0.2308
[Epoch 7, Batch 100] loss: 0.19608084289357067
[Epoch 7, Batch 200] loss: 0.23631436662748456
[Epoch 7, Batch 300] loss: 0.22111897574737668
[Epoch 7, Batch 400] loss: 0.2301205456163734
[Epoch 7, Batch 500] loss: 0.21779897700063885
[Epoch 7, Batch 600] loss: 0.2197548671811819
[Epoch 7, Batch 700] loss: 0.2238853818271309
[Epoch 7, Batch 800] loss: 0.23417355496436357
[Epoch 7, Batch 900] loss: 0.21175397109240293
[Epoch 7, Batch 1000] loss: 0.2213597200019285
[Epoch 7, Batch 1100] loss: 0.19706917176023125
[Epoch 7, Batch 1200] loss: 0.23231467118486762
[Epoch 7, Batch 1300] loss: 0.19043788621202112
[Epoch 7, Batch 1400] loss: 0.18638288884423673
[Epoch 7, Batch 1500] loss: 0.22009299654513598
[Epoch 7, Batch 1600] loss: 0.20042318599298597
[Epoch 7, Batch 1700] loss: 0.17754204969853163
[Epoch 7, Batch 1800] loss: 0.21593552635982632
**STATS for Epoch 7** : 
Average training loss: 0.0075
Average validation loss: 0.2196
Validation Accuracy: 0.9317
Overfitting: 0.2121
Best model saved at epoch 7 with validation loss: 0.2196
[Epoch 8, Batch 100] loss: 0.18343671226873995
[Epoch 8, Batch 200] loss: 0.1929513962008059
[Epoch 8, Batch 300] loss: 0.19312650796957315
[Epoch 8, Batch 400] loss: 0.20121887823566795
[Epoch 8, Batch 500] loss: 0.21094035520218313
[Epoch 8, Batch 600] loss: 0.17611144473776222
[Epoch 8, Batch 700] loss: 0.18722897268831729
[Epoch 8, Batch 800] loss: 0.17789650136604906
[Epoch 8, Batch 900] loss: 0.17043884295970202
[Epoch 8, Batch 1000] loss: 0.19655093570239843
[Epoch 8, Batch 1100] loss: 0.22974327831529082
[Epoch 8, Batch 1200] loss: 0.18377527959644793
[Epoch 8, Batch 1300] loss: 0.18806053179316223
[Epoch 8, Batch 1400] loss: 0.17006645027548076
[Epoch 8, Batch 1500] loss: 0.17446036665700376
[Epoch 8, Batch 1600] loss: 0.16620378120336682
[Epoch 8, Batch 1700] loss: 0.1830095979012549
[Epoch 8, Batch 1800] loss: 0.20053455710411072
**STATS for Epoch 8** : 
Average training loss: 0.0068
Average validation loss: 0.1886
Validation Accuracy: 0.9433
Overfitting: 0.1817
Best model saved at epoch 8 with validation loss: 0.1886
[Epoch 9, Batch 100] loss: 0.16554181511513888
[Epoch 9, Batch 200] loss: 0.17194039333611727
[Epoch 9, Batch 300] loss: 0.1445186742953956
[Epoch 9, Batch 400] loss: 0.16191886723041535
[Epoch 9, Batch 500] loss: 0.18675161949358882
[Epoch 9, Batch 600] loss: 0.19614386745728551
[Epoch 9, Batch 700] loss: 0.17441307116299867
[Epoch 9, Batch 800] loss: 0.1631480251532048
[Epoch 9, Batch 900] loss: 0.1669880195520818
[Epoch 9, Batch 1000] loss: 0.16790893353521824
[Epoch 9, Batch 1100] loss: 0.20102689587511122
[Epoch 9, Batch 1200] loss: 0.17177219806239008
[Epoch 9, Batch 1300] loss: 0.15082297931425273
[Epoch 9, Batch 1400] loss: 0.16668517798185348
[Epoch 9, Batch 1500] loss: 0.14651800035499035
[Epoch 9, Batch 1600] loss: 0.1755550719797611
[Epoch 9, Batch 1700] loss: 0.15753641117364167
[Epoch 9, Batch 1800] loss: 0.17527992134913803
**STATS for Epoch 9** : 
Average training loss: 0.0053
Average validation loss: 0.1637
Validation Accuracy: 0.9512
Overfitting: 0.1584
Best model saved at epoch 9 with validation loss: 0.1637
[Epoch 10, Batch 100] loss: 0.1530261024273932
[Epoch 10, Batch 200] loss: 0.1556531574577093
[Epoch 10, Batch 300] loss: 0.12906715990044176
[Epoch 10, Batch 400] loss: 0.16334605762269347
[Epoch 10, Batch 500] loss: 0.16155935886316
[Epoch 10, Batch 600] loss: 0.1576809041388333
[Epoch 10, Batch 700] loss: 0.16628959525842218
[Epoch 10, Batch 800] loss: 0.14577825939282774
[Epoch 10, Batch 900] loss: 0.13194084336049855
[Epoch 10, Batch 1000] loss: 0.16315195940900595
[Epoch 10, Batch 1100] loss: 0.13397025945130736
[Epoch 10, Batch 1200] loss: 0.1644797667581588
[Epoch 10, Batch 1300] loss: 0.14913926104083658
[Epoch 10, Batch 1400] loss: 0.16400038469582795
[Epoch 10, Batch 1500] loss: 0.1323660770058632
[Epoch 10, Batch 1600] loss: 0.1534998517949134
[Epoch 10, Batch 1700] loss: 0.1558415698260069
[Epoch 10, Batch 1800] loss: 0.14589289790485055
**STATS for Epoch 10** : 
Average training loss: 0.0054
Average validation loss: 0.1522
Validation Accuracy: 0.9547
Overfitting: 0.1468
Best model saved at epoch 10 with validation loss: 0.1522
[Epoch 11, Batch 100] loss: 0.14333369290456177
[Epoch 11, Batch 200] loss: 0.14985344825312497
[Epoch 11, Batch 300] loss: 0.13561007854063065
[Epoch 11, Batch 400] loss: 0.1505422073416412
[Epoch 11, Batch 500] loss: 0.14467251183465124
[Epoch 11, Batch 600] loss: 0.1504575255792588
[Epoch 11, Batch 700] loss: 0.13856345503591
[Epoch 11, Batch 800] loss: 0.14768146263435483
[Epoch 11, Batch 900] loss: 0.1390332202380523
[Epoch 11, Batch 1000] loss: 0.15976902952417732
[Epoch 11, Batch 1100] loss: 0.13274123199749738
[Epoch 11, Batch 1200] loss: 0.11792631174437701
[Epoch 11, Batch 1300] loss: 0.1298526863195002
[Epoch 11, Batch 1400] loss: 0.15557713966351003
[Epoch 11, Batch 1500] loss: 0.13084392852149904
[Epoch 11, Batch 1600] loss: 0.15151027999818326
[Epoch 11, Batch 1700] loss: 0.1205777104292065
[Epoch 11, Batch 1800] loss: 0.12758734185248613
**STATS for Epoch 11** : 
Average training loss: 0.0052
Average validation loss: 0.1419
Validation Accuracy: 0.9570
Overfitting: 0.1367
Best model saved at epoch 11 with validation loss: 0.1419
[Epoch 12, Batch 100] loss: 0.14213055754080414
[Epoch 12, Batch 200] loss: 0.15479848866350948
[Epoch 12, Batch 300] loss: 0.1441445269715041
[Epoch 12, Batch 400] loss: 0.11091784071177244
[Epoch 12, Batch 500] loss: 0.12950929793529212
[Epoch 12, Batch 600] loss: 0.13301038627978415
[Epoch 12, Batch 700] loss: 0.1138589698402211
[Epoch 12, Batch 800] loss: 0.1475871512433514
[Epoch 12, Batch 900] loss: 0.13745231380220502
[Epoch 12, Batch 1000] loss: 0.10480660648550838
[Epoch 12, Batch 1100] loss: 0.10365152426064014
[Epoch 12, Batch 1200] loss: 0.12674021437298508
[Epoch 12, Batch 1300] loss: 0.11322948074899614
[Epoch 12, Batch 1400] loss: 0.12576814635656774
[Epoch 12, Batch 1500] loss: 0.12490754767088219
[Epoch 12, Batch 1600] loss: 0.12405986506491899
[Epoch 12, Batch 1700] loss: 0.12187211498152464
[Epoch 12, Batch 1800] loss: 0.1299458023812622
**STATS for Epoch 12** : 
Average training loss: 0.0047
Average validation loss: 0.1345
Validation Accuracy: 0.9588
Overfitting: 0.1298
Best model saved at epoch 12 with validation loss: 0.1345
[Epoch 13, Batch 100] loss: 0.12122268383391202
[Epoch 13, Batch 200] loss: 0.0957556638121605
[Epoch 13, Batch 300] loss: 0.13180556069128216
[Epoch 13, Batch 400] loss: 0.10165785402525217
[Epoch 13, Batch 500] loss: 0.1423657403793186
[Epoch 13, Batch 600] loss: 0.1161659068474546
[Epoch 13, Batch 700] loss: 0.12452550660818815
[Epoch 13, Batch 800] loss: 0.12593231982551514
[Epoch 13, Batch 900] loss: 0.1128668667981401
[Epoch 13, Batch 1000] loss: 0.13315290808444843
[Epoch 13, Batch 1100] loss: 0.1371268165530637
[Epoch 13, Batch 1200] loss: 0.10793333255220204
[Epoch 13, Batch 1300] loss: 0.14685191134922207
[Epoch 13, Batch 1400] loss: 0.11010080473031848
[Epoch 13, Batch 1500] loss: 0.11862152311950921
[Epoch 13, Batch 1600] loss: 0.1111901688016951
[Epoch 13, Batch 1700] loss: 0.11922968172002583
[Epoch 13, Batch 1800] loss: 0.1158412169571966
**STATS for Epoch 13** : 
Average training loss: 0.0035
Average validation loss: 0.1236
Validation Accuracy: 0.9623
Overfitting: 0.1201
Best model saved at epoch 13 with validation loss: 0.1236
[Epoch 14, Batch 100] loss: 0.09544612099649384
[Epoch 14, Batch 200] loss: 0.1083189093740657
[Epoch 14, Batch 300] loss: 0.09150158669333905
[Epoch 14, Batch 400] loss: 0.11399630955886096
[Epoch 14, Batch 500] loss: 0.1078640156146139
[Epoch 14, Batch 600] loss: 0.11293588189408182
[Epoch 14, Batch 700] loss: 0.0945290203555487
[Epoch 14, Batch 800] loss: 0.12215459894854576
[Epoch 14, Batch 900] loss: 0.10907266659429297
[Epoch 14, Batch 1000] loss: 0.10502304506953805
[Epoch 14, Batch 1100] loss: 0.10237694073468447
[Epoch 14, Batch 1200] loss: 0.11155696753878147
[Epoch 14, Batch 1300] loss: 0.11331133466679603
[Epoch 14, Batch 1400] loss: 0.12083289431408048
[Epoch 14, Batch 1500] loss: 0.10873008579947055
[Epoch 14, Batch 1600] loss: 0.11664406697032974
[Epoch 14, Batch 1700] loss: 0.11005553340073675
[Epoch 14, Batch 1800] loss: 0.14059233373496682
**STATS for Epoch 14** : 
Average training loss: 0.0043
Average validation loss: 0.1187
Validation Accuracy: 0.9638
Overfitting: 0.1144
Best model saved at epoch 14 with validation loss: 0.1187
[Epoch 15, Batch 100] loss: 0.10265631241956726
[Epoch 15, Batch 200] loss: 0.10694421448744834
[Epoch 15, Batch 300] loss: 0.10622812975663692
[Epoch 15, Batch 400] loss: 0.09886464197188616
[Epoch 15, Batch 500] loss: 0.08946108524454757
[Epoch 15, Batch 600] loss: 0.11238409536308609
[Epoch 15, Batch 700] loss: 0.11184918244136498
[Epoch 15, Batch 800] loss: 0.0925225075869821
[Epoch 15, Batch 900] loss: 0.10834555177716539
[Epoch 15, Batch 1000] loss: 0.09938339265529067
[Epoch 15, Batch 1100] loss: 0.09907838108483702
[Epoch 15, Batch 1200] loss: 0.12738651695661246
[Epoch 15, Batch 1300] loss: 0.08824855013750493
[Epoch 15, Batch 1400] loss: 0.09088060694979504
[Epoch 15, Batch 1500] loss: 0.10797603756189346
[Epoch 15, Batch 1600] loss: 0.12904437058838084
[Epoch 15, Batch 1700] loss: 0.11720723775215447
[Epoch 15, Batch 1800] loss: 0.08266325311851688
**STATS for Epoch 15** : 
Average training loss: 0.0043
Average validation loss: 0.1154
Validation Accuracy: 0.9647
Overfitting: 0.1111
Best model saved at epoch 15 with validation loss: 0.1154
[Epoch 16, Batch 100] loss: 0.10709214244270697
[Epoch 16, Batch 200] loss: 0.1051657128916122
[Epoch 16, Batch 300] loss: 0.1186303342715837
[Epoch 16, Batch 400] loss: 0.09405728766694665
[Epoch 16, Batch 500] loss: 0.09655383096309379
[Epoch 16, Batch 600] loss: 0.08889587340410798
[Epoch 16, Batch 700] loss: 0.08433089620433748
[Epoch 16, Batch 800] loss: 0.11049397910013795
[Epoch 16, Batch 900] loss: 0.08419878808548674
[Epoch 16, Batch 1000] loss: 0.08299580574734136
[Epoch 16, Batch 1100] loss: 0.08178771772654728
[Epoch 16, Batch 1200] loss: 0.09831821161089466
[Epoch 16, Batch 1300] loss: 0.08957794249756262
[Epoch 16, Batch 1400] loss: 0.11590188796864823
[Epoch 16, Batch 1500] loss: 0.10632444018963724
[Epoch 16, Batch 1600] loss: 0.09212123242206871
[Epoch 16, Batch 1700] loss: 0.08925295562716201
[Epoch 16, Batch 1800] loss: 0.09100498390384018
**STATS for Epoch 16** : 
Average training loss: 0.0044
Average validation loss: 0.1115
Validation Accuracy: 0.9657
Overfitting: 0.1072
Best model saved at epoch 16 with validation loss: 0.1115
[Epoch 17, Batch 100] loss: 0.10829024518374354
[Epoch 17, Batch 200] loss: 0.10770628687459975
[Epoch 17, Batch 300] loss: 0.09047967227408663
[Epoch 17, Batch 400] loss: 0.07680352196795866
[Epoch 17, Batch 500] loss: 0.09837368958862498
[Epoch 17, Batch 600] loss: 0.10300996193429456
[Epoch 17, Batch 700] loss: 0.10125309377908706
[Epoch 17, Batch 800] loss: 0.11724661105778068
[Epoch 17, Batch 900] loss: 0.0856370211520698
[Epoch 17, Batch 1000] loss: 0.11242674192879348
[Epoch 17, Batch 1100] loss: 0.07380352550186217
[Epoch 17, Batch 1200] loss: 0.07545851269969717
[Epoch 17, Batch 1300] loss: 0.09152285574469715
[Epoch 17, Batch 1400] loss: 0.0674327273631934
[Epoch 17, Batch 1500] loss: 0.06340048540616408
[Epoch 17, Batch 1600] loss: 0.0895494828489609
[Epoch 17, Batch 1700] loss: 0.08344079149421305
[Epoch 17, Batch 1800] loss: 0.09814013223862275
**STATS for Epoch 17** : 
Average training loss: 0.0049
Average validation loss: 0.1141
Validation Accuracy: 0.9650
Overfitting: 0.1091
[Epoch 18, Batch 100] loss: 0.0883258150680922
[Epoch 18, Batch 200] loss: 0.09173450399655848
[Epoch 18, Batch 300] loss: 0.097814499696251
[Epoch 18, Batch 400] loss: 0.0714798313821666
[Epoch 18, Batch 500] loss: 0.0859948822343722
[Epoch 18, Batch 600] loss: 0.08438786334125326
[Epoch 18, Batch 700] loss: 0.0898446369660087
[Epoch 18, Batch 800] loss: 0.09059208089485765
[Epoch 18, Batch 900] loss: 0.0697891253256239
[Epoch 18, Batch 1000] loss: 0.0932565310318023
[Epoch 18, Batch 1100] loss: 0.08646494602435269
[Epoch 18, Batch 1200] loss: 0.08372563517419622
[Epoch 18, Batch 1300] loss: 0.09730492945527658
[Epoch 18, Batch 1400] loss: 0.08036467575468123
[Epoch 18, Batch 1500] loss: 0.08937495692167431
[Epoch 18, Batch 1600] loss: 0.09308295120019466
[Epoch 18, Batch 1700] loss: 0.09134215895901435
[Epoch 18, Batch 1800] loss: 0.09071522903861479
**STATS for Epoch 18** : 
Average training loss: 0.0034
Average validation loss: 0.0984
Validation Accuracy: 0.9703
Overfitting: 0.0950
Best model saved at epoch 18 with validation loss: 0.0984
[Epoch 19, Batch 100] loss: 0.078048653495498
[Epoch 19, Batch 200] loss: 0.08289183164946735
[Epoch 19, Batch 300] loss: 0.08232281905831769
[Epoch 19, Batch 400] loss: 0.08204525424866006
[Epoch 19, Batch 500] loss: 0.06985264863120393
[Epoch 19, Batch 600] loss: 0.07125926316250115
[Epoch 19, Batch 700] loss: 0.08331931085907854
[Epoch 19, Batch 800] loss: 0.07625074136420153
[Epoch 19, Batch 900] loss: 0.08046223537065089
[Epoch 19, Batch 1000] loss: 0.09115787519607693
[Epoch 19, Batch 1100] loss: 0.08843062018742785
[Epoch 19, Batch 1200] loss: 0.06809179910691456
[Epoch 19, Batch 1300] loss: 0.08881378073943778
[Epoch 19, Batch 1400] loss: 0.0757874646433629
[Epoch 19, Batch 1500] loss: 0.10374453274300321
[Epoch 19, Batch 1600] loss: 0.06500042740022764
[Epoch 19, Batch 1700] loss: 0.10901985980453902
[Epoch 19, Batch 1800] loss: 0.10798678091261536
**STATS for Epoch 19** : 
Average training loss: 0.0031
Average validation loss: 0.0950
Validation Accuracy: 0.9710
Overfitting: 0.0919
Best model saved at epoch 19 with validation loss: 0.0950
[Epoch 20, Batch 100] loss: 0.07654747763299383
[Epoch 20, Batch 200] loss: 0.09752681652666069
[Epoch 20, Batch 300] loss: 0.06373213613405823
[Epoch 20, Batch 400] loss: 0.07695559023763053
[Epoch 20, Batch 500] loss: 0.09475472673424519
[Epoch 20, Batch 600] loss: 0.08678738986374811
[Epoch 20, Batch 700] loss: 0.08284289846662432
[Epoch 20, Batch 800] loss: 0.08636084291152656
[Epoch 20, Batch 900] loss: 0.09050592687912286
[Epoch 20, Batch 1000] loss: 0.060247316621243954
[Epoch 20, Batch 1100] loss: 0.07702607419108971
[Epoch 20, Batch 1200] loss: 0.07582261711824685
[Epoch 20, Batch 1300] loss: 0.07410271659668069
[Epoch 20, Batch 1400] loss: 0.07681061498704367
[Epoch 20, Batch 1500] loss: 0.0738081535231322
[Epoch 20, Batch 1600] loss: 0.0757047427399084
[Epoch 20, Batch 1700] loss: 0.07301382479839959
[Epoch 20, Batch 1800] loss: 0.07743215128779411
**STATS for Epoch 20** : 
Average training loss: 0.0042
Average validation loss: 0.0939
Validation Accuracy: 0.9711
Overfitting: 0.0897
Best model saved at epoch 20 with validation loss: 0.0939
[Epoch 21, Batch 100] loss: 0.07813045996124857
[Epoch 21, Batch 200] loss: 0.09382057358860038
[Epoch 21, Batch 300] loss: 0.08787853791611269
[Epoch 21, Batch 400] loss: 0.08323801446298602
[Epoch 21, Batch 500] loss: 0.07062420405680314
[Epoch 21, Batch 600] loss: 0.05776945305755362
[Epoch 21, Batch 700] loss: 0.07713139144179877
[Epoch 21, Batch 800] loss: 0.06561347402690444
[Epoch 21, Batch 900] loss: 0.06710612208582462
[Epoch 21, Batch 1000] loss: 0.09156272440217435
[Epoch 21, Batch 1100] loss: 0.07462596385972574
[Epoch 21, Batch 1200] loss: 0.07517251410754397
[Epoch 21, Batch 1300] loss: 0.06980112900026142
[Epoch 21, Batch 1400] loss: 0.06752722489123698
[Epoch 21, Batch 1500] loss: 0.07463909914018586
[Epoch 21, Batch 1600] loss: 0.09318673788104206
[Epoch 21, Batch 1700] loss: 0.07481376178911887
[Epoch 21, Batch 1800] loss: 0.0751030162582174
**STATS for Epoch 21** : 
Average training loss: 0.0029
Average validation loss: 0.0893
Validation Accuracy: 0.9731
Overfitting: 0.0864
Best model saved at epoch 21 with validation loss: 0.0893
[Epoch 22, Batch 100] loss: 0.06607481829589233
[Epoch 22, Batch 200] loss: 0.08598173926468007
[Epoch 22, Batch 300] loss: 0.07089103657053783
[Epoch 22, Batch 400] loss: 0.07196680831955746
[Epoch 22, Batch 500] loss: 0.07237255890853703
[Epoch 22, Batch 600] loss: 0.06414774825563654
[Epoch 22, Batch 700] loss: 0.0817092237516772
[Epoch 22, Batch 800] loss: 0.06747405583853833
[Epoch 22, Batch 900] loss: 0.06941403609525879
[Epoch 22, Batch 1000] loss: 0.06640135464258493
[Epoch 22, Batch 1100] loss: 0.08656279652728699
[Epoch 22, Batch 1200] loss: 0.08194219580618664
[Epoch 22, Batch 1300] loss: 0.06355607861012685
[Epoch 22, Batch 1400] loss: 0.08734677074244246
[Epoch 22, Batch 1500] loss: 0.07297168915974908
[Epoch 22, Batch 1600] loss: 0.07018160216975958
[Epoch 22, Batch 1700] loss: 0.07088569766492583
[Epoch 22, Batch 1800] loss: 0.08088583010714501
**STATS for Epoch 22** : 
Average training loss: 0.0037
Average validation loss: 0.0865
Validation Accuracy: 0.9736
Overfitting: 0.0828
Best model saved at epoch 22 with validation loss: 0.0865
[Epoch 23, Batch 100] loss: 0.05900897736661136
[Epoch 23, Batch 200] loss: 0.09127506175951566
[Epoch 23, Batch 300] loss: 0.06792544537980576
[Epoch 23, Batch 400] loss: 0.06994294355623425
[Epoch 23, Batch 500] loss: 0.05828059790714178
[Epoch 23, Batch 600] loss: 0.077424696496455
[Epoch 23, Batch 700] loss: 0.0659218213148415
[Epoch 23, Batch 800] loss: 0.06019877978193108
[Epoch 23, Batch 900] loss: 0.07713941791793331
[Epoch 23, Batch 1000] loss: 0.06578105981461704
[Epoch 23, Batch 1100] loss: 0.07302662257803604
[Epoch 23, Batch 1200] loss: 0.06501829725108109
[Epoch 23, Batch 1300] loss: 0.07151318841380999
[Epoch 23, Batch 1400] loss: 0.10203593687154353
[Epoch 23, Batch 1500] loss: 0.07045864301500843
[Epoch 23, Batch 1600] loss: 0.07743671790231019
[Epoch 23, Batch 1700] loss: 0.06351799319498241
[Epoch 23, Batch 1800] loss: 0.073559992602095
**STATS for Epoch 23** : 
Average training loss: 0.0022
Average validation loss: 0.0888
Validation Accuracy: 0.9726
Overfitting: 0.0866
[Epoch 24, Batch 100] loss: 0.0768139582988806
[Epoch 24, Batch 200] loss: 0.054992316676070914
[Epoch 24, Batch 300] loss: 0.05798363541718572
[Epoch 24, Batch 400] loss: 0.06293875094153918
[Epoch 24, Batch 500] loss: 0.05947054989868775
[Epoch 24, Batch 600] loss: 0.07059411624562927
[Epoch 24, Batch 700] loss: 0.06203152995323762
[Epoch 24, Batch 800] loss: 0.09059600345557556
[Epoch 24, Batch 900] loss: 0.08554619175731204
[Epoch 24, Batch 1000] loss: 0.06443992207059637
[Epoch 24, Batch 1100] loss: 0.06150987072964199
[Epoch 24, Batch 1200] loss: 0.07661634478019551
[Epoch 24, Batch 1300] loss: 0.06442727279383689
[Epoch 24, Batch 1400] loss: 0.060067695193574765
[Epoch 24, Batch 1500] loss: 0.06773561083478853
[Epoch 24, Batch 1600] loss: 0.05747357782092877
[Epoch 24, Batch 1700] loss: 0.08271328362752683
[Epoch 24, Batch 1800] loss: 0.051345425395993516
**STATS for Epoch 24** : 
Average training loss: 0.0033
Average validation loss: 0.0878
Validation Accuracy: 0.9739
Overfitting: 0.0844
Fold 2 validation loss: 0.0878
Mean validation loss across all folds for Trial 5 is 0.0807 with trial config:  l1: 256, l2: 128, lr: 0.00010842262717330161, batch_size: 16
[I 2024-11-21 18:22:45,931] Trial 4 finished with value: 0.08066754772460555 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.00010842262717330161, 'batch_size': 16}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 6:
  l1: 128, l2: 64, lr: 0.002463768595899745, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2583599042892457
[Epoch 1, Batch 200] loss: 1.4813739413022995
[Epoch 1, Batch 300] loss: 0.6994822939485311
[Epoch 1, Batch 400] loss: 0.4379984147101641
[Epoch 1, Batch 500] loss: 0.36055184934288265
[Epoch 1, Batch 600] loss: 0.3067774314805865
[Epoch 1, Batch 700] loss: 0.2263273106701672
[Epoch 1, Batch 800] loss: 0.24857283762656152
[Epoch 1, Batch 900] loss: 0.20483029563445598
[Epoch 1, Batch 1000] loss: 0.18053904550150038
[Epoch 1, Batch 1100] loss: 0.19934872708283366
[Epoch 1, Batch 1200] loss: 0.14986827740911393
[Epoch 1, Batch 1300] loss: 0.16949145818129183
[Epoch 1, Batch 1400] loss: 0.13103403694927693
[Epoch 1, Batch 1500] loss: 0.1283594550867565
[Epoch 1, Batch 1600] loss: 0.1344764504907653
[Epoch 1, Batch 1700] loss: 0.13225406142184512
[Epoch 1, Batch 1800] loss: 0.12751577855786309
**STATS for Epoch 1** : 
Average training loss: 0.0047
Average validation loss: 0.1099
Validation Accuracy: 0.9646
Overfitting: 0.1052
Best model saved at epoch 1 with validation loss: 0.1099
[Epoch 2, Batch 100] loss: 0.102486928391736
[Epoch 2, Batch 200] loss: 0.11723728594486602
[Epoch 2, Batch 300] loss: 0.08282038071309217
[Epoch 2, Batch 400] loss: 0.10740573881659657
[Epoch 2, Batch 500] loss: 0.11449412361951544
[Epoch 2, Batch 600] loss: 0.08877490666345693
[Epoch 2, Batch 700] loss: 0.09054264962906018
[Epoch 2, Batch 800] loss: 0.11362161800963805
[Epoch 2, Batch 900] loss: 0.09626884007127956
[Epoch 2, Batch 1000] loss: 0.10422807731549255
[Epoch 2, Batch 1100] loss: 0.09757835640077246
[Epoch 2, Batch 1200] loss: 0.07531243685923983
[Epoch 2, Batch 1300] loss: 0.07680922858591657
[Epoch 2, Batch 1400] loss: 0.08324088223365834
[Epoch 2, Batch 1500] loss: 0.0929784578451654
[Epoch 2, Batch 1600] loss: 0.07243519182200543
[Epoch 2, Batch 1700] loss: 0.07357991618424421
[Epoch 2, Batch 1800] loss: 0.08426601803977973
**STATS for Epoch 2** : 
Average training loss: 0.0033
Average validation loss: 0.0865
Validation Accuracy: 0.9720
Overfitting: 0.0832
Best model saved at epoch 2 with validation loss: 0.0865
[Epoch 3, Batch 100] loss: 0.06257393815089017
[Epoch 3, Batch 200] loss: 0.07218766676902305
[Epoch 3, Batch 300] loss: 0.05758034246100578
[Epoch 3, Batch 400] loss: 0.08727181877824478
[Epoch 3, Batch 500] loss: 0.05918797114194604
[Epoch 3, Batch 600] loss: 0.07033079787564929
[Epoch 3, Batch 700] loss: 0.07677792731032242
[Epoch 3, Batch 800] loss: 0.050410807804146314
[Epoch 3, Batch 900] loss: 0.07098862907441798
[Epoch 3, Batch 1000] loss: 0.04958258160913829
[Epoch 3, Batch 1100] loss: 0.06026820125218364
[Epoch 3, Batch 1200] loss: 0.0716507479120628
[Epoch 3, Batch 1300] loss: 0.041966460225521585
[Epoch 3, Batch 1400] loss: 0.06665022140688961
[Epoch 3, Batch 1500] loss: 0.0747285040296265
[Epoch 3, Batch 1600] loss: 0.06016912203573156
[Epoch 3, Batch 1700] loss: 0.06284421919379383
[Epoch 3, Batch 1800] loss: 0.045464680118166144
**STATS for Epoch 3** : 
Average training loss: 0.0024
Average validation loss: 0.0622
Validation Accuracy: 0.9806
Overfitting: 0.0598
Best model saved at epoch 3 with validation loss: 0.0622
[Epoch 4, Batch 100] loss: 0.046015690106723926
[Epoch 4, Batch 200] loss: 0.05122997933882289
[Epoch 4, Batch 300] loss: 0.049598053100635295
[Epoch 4, Batch 400] loss: 0.04225512503500795
[Epoch 4, Batch 500] loss: 0.04243304140603868
[Epoch 4, Batch 600] loss: 0.043943315513897685
[Epoch 4, Batch 700] loss: 0.052291961561422795
[Epoch 4, Batch 800] loss: 0.0515489158660057
[Epoch 4, Batch 900] loss: 0.037613218973856416
[Epoch 4, Batch 1000] loss: 0.03080560801245156
[Epoch 4, Batch 1100] loss: 0.059725786659837465
[Epoch 4, Batch 1200] loss: 0.04118910016302834
[Epoch 4, Batch 1300] loss: 0.07611761519619904
[Epoch 4, Batch 1400] loss: 0.04313182469282765
[Epoch 4, Batch 1500] loss: 0.057189729573510706
[Epoch 4, Batch 1600] loss: 0.03147069152255426
[Epoch 4, Batch 1700] loss: 0.03580713816660136
[Epoch 4, Batch 1800] loss: 0.04969548538036179
**STATS for Epoch 4** : 
Average training loss: 0.0025
Average validation loss: 0.0636
Validation Accuracy: 0.9797
Overfitting: 0.0611
[Epoch 5, Batch 100] loss: 0.029452280327022892
[Epoch 5, Batch 200] loss: 0.024289682591406746
[Epoch 5, Batch 300] loss: 0.029069496814081504
[Epoch 5, Batch 400] loss: 0.044834465944404656
[Epoch 5, Batch 500] loss: 0.051673681864267566
[Epoch 5, Batch 600] loss: 0.03579994869563961
[Epoch 5, Batch 700] loss: 0.04608876815276744
[Epoch 5, Batch 800] loss: 0.04919981218896283
[Epoch 5, Batch 900] loss: 0.02704630848260422
[Epoch 5, Batch 1000] loss: 0.04223525388442795
[Epoch 5, Batch 1100] loss: 0.03331201805209275
[Epoch 5, Batch 1200] loss: 0.04524734415987041
[Epoch 5, Batch 1300] loss: 0.024124991300850523
[Epoch 5, Batch 1400] loss: 0.0413650412804418
[Epoch 5, Batch 1500] loss: 0.03725919299475208
[Epoch 5, Batch 1600] loss: 0.04673194366208918
[Epoch 5, Batch 1700] loss: 0.03652039865759434
[Epoch 5, Batch 1800] loss: 0.03877318076614756
**STATS for Epoch 5** : 
Average training loss: 0.0023
Average validation loss: 0.0655
Validation Accuracy: 0.9813
Overfitting: 0.0631
[Epoch 6, Batch 100] loss: 0.030504175697860774
[Epoch 6, Batch 200] loss: 0.0334194463779022
[Epoch 6, Batch 300] loss: 0.029820177221990887
[Epoch 6, Batch 400] loss: 0.0241657462423791
[Epoch 6, Batch 500] loss: 0.03412241278991132
[Epoch 6, Batch 600] loss: 0.024116123149578925
[Epoch 6, Batch 700] loss: 0.033364841135316965
[Epoch 6, Batch 800] loss: 0.038241551458631874
[Epoch 6, Batch 900] loss: 0.0594467193383025
[Epoch 6, Batch 1000] loss: 0.020958869903624874
[Epoch 6, Batch 1100] loss: 0.024455747934480312
[Epoch 6, Batch 1200] loss: 0.023821062673523557
[Epoch 6, Batch 1300] loss: 0.0413713485095468
[Epoch 6, Batch 1400] loss: 0.02252381661288382
[Epoch 6, Batch 1500] loss: 0.024389979680490795
[Epoch 6, Batch 1600] loss: 0.03115893021975353
[Epoch 6, Batch 1700] loss: 0.0347634949501662
[Epoch 6, Batch 1800] loss: 0.04501054858264979
**STATS for Epoch 6** : 
Average training loss: 0.0010
Average validation loss: 0.0620
Validation Accuracy: 0.9825
Overfitting: 0.0610
Best model saved at epoch 6 with validation loss: 0.0620
[Epoch 7, Batch 100] loss: 0.015817337094085816
[Epoch 7, Batch 200] loss: 0.029996699072798946
[Epoch 7, Batch 300] loss: 0.016492283320912973
[Epoch 7, Batch 400] loss: 0.026783240353579457
[Epoch 7, Batch 500] loss: 0.014742710350092239
[Epoch 7, Batch 600] loss: 0.022066671258580754
[Epoch 7, Batch 700] loss: 0.018576555782419745
[Epoch 7, Batch 800] loss: 0.02658342374638778
[Epoch 7, Batch 900] loss: 0.02762306061846175
[Epoch 7, Batch 1000] loss: 0.030469403892147966
[Epoch 7, Batch 1100] loss: 0.023685537559904334
[Epoch 7, Batch 1200] loss: 0.028792956087127095
[Epoch 7, Batch 1300] loss: 0.02842923951382545
[Epoch 7, Batch 1400] loss: 0.030630902164539293
[Epoch 7, Batch 1500] loss: 0.03278578131030372
[Epoch 7, Batch 1600] loss: 0.0212687342197205
[Epoch 7, Batch 1700] loss: 0.02404082314211337
[Epoch 7, Batch 1800] loss: 0.023964177221587307
**STATS for Epoch 7** : 
Average training loss: 0.0007
Average validation loss: 0.0619
Validation Accuracy: 0.9829
Overfitting: 0.0612
Best model saved at epoch 7 with validation loss: 0.0619
[Epoch 8, Batch 100] loss: 0.01185851383546833
[Epoch 8, Batch 200] loss: 0.019061692425652838
[Epoch 8, Batch 300] loss: 0.018015653449801904
[Epoch 8, Batch 400] loss: 0.025205747650379636
[Epoch 8, Batch 500] loss: 0.020961355738008933
[Epoch 8, Batch 600] loss: 0.020133323881427714
[Epoch 8, Batch 700] loss: 0.017148526883942167
[Epoch 8, Batch 800] loss: 0.010125421633615588
[Epoch 8, Batch 900] loss: 0.014251066372976311
[Epoch 8, Batch 1000] loss: 0.019667989096051317
[Epoch 8, Batch 1100] loss: 0.020765267540182323
[Epoch 8, Batch 1200] loss: 0.03164932468160259
[Epoch 8, Batch 1300] loss: 0.025559280472830324
[Epoch 8, Batch 1400] loss: 0.026882990219360182
[Epoch 8, Batch 1500] loss: 0.020895830322660913
[Epoch 8, Batch 1600] loss: 0.027624562763257927
[Epoch 8, Batch 1700] loss: 0.026021726027811384
[Epoch 8, Batch 1800] loss: 0.018674174499674335
**STATS for Epoch 8** : 
Average training loss: 0.0014
Average validation loss: 0.0603
Validation Accuracy: 0.9833
Overfitting: 0.0589
Best model saved at epoch 8 with validation loss: 0.0603
[Epoch 9, Batch 100] loss: 0.006647653084646663
[Epoch 9, Batch 200] loss: 0.01209003496483092
[Epoch 9, Batch 300] loss: 0.014298508177016628
[Epoch 9, Batch 400] loss: 0.018941198869069923
[Epoch 9, Batch 500] loss: 0.01793004139117329
[Epoch 9, Batch 600] loss: 0.020402222808979787
[Epoch 9, Batch 700] loss: 0.0177567908655692
[Epoch 9, Batch 800] loss: 0.019063375598052518
[Epoch 9, Batch 900] loss: 0.014812701730702428
[Epoch 9, Batch 1000] loss: 0.0201032746344481
[Epoch 9, Batch 1100] loss: 0.013734441950109613
[Epoch 9, Batch 1200] loss: 0.015254274300359612
[Epoch 9, Batch 1300] loss: 0.020361851572774866
[Epoch 9, Batch 1400] loss: 0.0093230690155724
[Epoch 9, Batch 1500] loss: 0.018671248378464043
[Epoch 9, Batch 1600] loss: 0.01527556361659208
[Epoch 9, Batch 1700] loss: 0.014606050786828745
[Epoch 9, Batch 1800] loss: 0.01883457586311124
**STATS for Epoch 9** : 
Average training loss: 0.0008
Average validation loss: 0.0603
Validation Accuracy: 0.9840
Overfitting: 0.0595
[Epoch 10, Batch 100] loss: 0.011283038327173927
[Epoch 10, Batch 200] loss: 0.00664651369661442
[Epoch 10, Batch 300] loss: 0.02030037949860798
[Epoch 10, Batch 400] loss: 0.014266700635234884
[Epoch 10, Batch 500] loss: 0.014311767371814312
[Epoch 10, Batch 600] loss: 0.015658363285501763
[Epoch 10, Batch 700] loss: 0.013284474864192361
[Epoch 10, Batch 800] loss: 0.009316451775016504
[Epoch 10, Batch 900] loss: 0.0032816870127709307
[Epoch 10, Batch 1000] loss: 0.01199374472447289
[Epoch 10, Batch 1100] loss: 0.013850444345785036
[Epoch 10, Batch 1200] loss: 0.011264611219421567
[Epoch 10, Batch 1300] loss: 0.006742518832361384
[Epoch 10, Batch 1400] loss: 0.014058221324930856
[Epoch 10, Batch 1500] loss: 0.017217189324810533
[Epoch 10, Batch 1600] loss: 0.012239298383219648
[Epoch 10, Batch 1700] loss: 0.014060753721159926
[Epoch 10, Batch 1800] loss: 0.015947261747023732
**STATS for Epoch 10** : 
Average training loss: 0.0007
Average validation loss: 0.0661
Validation Accuracy: 0.9831
Overfitting: 0.0654
[Epoch 11, Batch 100] loss: 0.008673470138370476
[Epoch 11, Batch 200] loss: 0.007460604671661031
[Epoch 11, Batch 300] loss: 0.01233775939860152
[Epoch 11, Batch 400] loss: 0.005195977638118165
[Epoch 11, Batch 500] loss: 0.0063401772164388605
[Epoch 11, Batch 600] loss: 0.01245493132955744
[Epoch 11, Batch 700] loss: 0.017680118760698634
[Epoch 11, Batch 800] loss: 0.008091656306856976
[Epoch 11, Batch 900] loss: 0.008030430361804975
[Epoch 11, Batch 1000] loss: 0.0059841030343295645
[Epoch 11, Batch 1100] loss: 0.016022814789633345
[Epoch 11, Batch 1200] loss: 0.019712900916864555
[Epoch 11, Batch 1300] loss: 0.009550308735297221
[Epoch 11, Batch 1400] loss: 0.009081648554943058
[Epoch 11, Batch 1500] loss: 0.01128305620783408
[Epoch 11, Batch 1600] loss: 0.01547306709542795
[Epoch 11, Batch 1700] loss: 0.017351446510879213
[Epoch 11, Batch 1800] loss: 0.02324088088524604
**STATS for Epoch 11** : 
Average training loss: 0.0010
Average validation loss: 0.0679
Validation Accuracy: 0.9825
Overfitting: 0.0668
[Epoch 12, Batch 100] loss: 0.01090768237975226
[Epoch 12, Batch 200] loss: 0.006611009630905756
[Epoch 12, Batch 300] loss: 0.011849321632175815
[Epoch 12, Batch 400] loss: 0.0126810338314408
[Epoch 12, Batch 500] loss: 0.016548065374217914
[Epoch 12, Batch 600] loss: 0.006403567466680613
[Epoch 12, Batch 700] loss: 0.011878319295958591
[Epoch 12, Batch 800] loss: 0.010369796405391297
[Epoch 12, Batch 900] loss: 0.010381503909000002
[Epoch 12, Batch 1000] loss: 0.011897291864235058
[Epoch 12, Batch 1100] loss: 0.013029020227527326
[Epoch 12, Batch 1200] loss: 0.024020235902260084
[Epoch 12, Batch 1300] loss: 0.013093669123782093
[Epoch 12, Batch 1400] loss: 0.014849665830486174
[Epoch 12, Batch 1500] loss: 0.008062860547413493
[Epoch 12, Batch 1600] loss: 0.005561274742140085
[Epoch 12, Batch 1700] loss: 0.011099272484460698
[Epoch 12, Batch 1800] loss: 0.009583117022759779
**STATS for Epoch 12** : 
Average training loss: 0.0004
Average validation loss: 0.0652
Validation Accuracy: 0.9842
Overfitting: 0.0648
[Epoch 13, Batch 100] loss: 0.0028938996307328324
[Epoch 13, Batch 200] loss: 0.002688536914991744
[Epoch 13, Batch 300] loss: 0.003639750412892937
[Epoch 13, Batch 400] loss: 0.005510976862635175
[Epoch 13, Batch 500] loss: 0.004976680188185014
[Epoch 13, Batch 600] loss: 0.005707016617172371
[Epoch 13, Batch 700] loss: 0.01401569157327117
[Epoch 13, Batch 800] loss: 0.0027017997653376825
[Epoch 13, Batch 900] loss: 0.01317967823942837
[Epoch 13, Batch 1000] loss: 0.012156038439370818
[Epoch 13, Batch 1100] loss: 0.017334358663109412
[Epoch 13, Batch 1200] loss: 0.010919356432414134
[Epoch 13, Batch 1300] loss: 0.0033025744634687724
[Epoch 13, Batch 1400] loss: 0.003997493463030537
[Epoch 13, Batch 1500] loss: 0.008190283383855074
[Epoch 13, Batch 1600] loss: 0.009085863219563634
[Epoch 13, Batch 1700] loss: 0.007971101438678812
[Epoch 13, Batch 1800] loss: 0.007876209500967235
**STATS for Epoch 13** : 
Average training loss: 0.0002
Average validation loss: 0.0668
Validation Accuracy: 0.9850
Overfitting: 0.0666
[Epoch 14, Batch 100] loss: 0.003111911559977898
[Epoch 14, Batch 200] loss: 0.0056759477972212835
[Epoch 14, Batch 300] loss: 0.006108824353508311
[Epoch 14, Batch 400] loss: 0.019116733447870047
[Epoch 14, Batch 500] loss: 0.008612665149769327
[Epoch 14, Batch 600] loss: 0.00525447368784512
[Epoch 14, Batch 700] loss: 0.015088453338767032
[Epoch 14, Batch 800] loss: 0.011666322413492197
[Epoch 14, Batch 900] loss: 0.01193887654932439
[Epoch 14, Batch 1000] loss: 0.005525069075507609
[Epoch 14, Batch 1100] loss: 0.0027262010839655204
[Epoch 14, Batch 1200] loss: 0.002482856143823824
[Epoch 14, Batch 1300] loss: 0.004753096079632861
[Epoch 14, Batch 1400] loss: 0.009806933150948875
[Epoch 14, Batch 1500] loss: 0.006527218784842716
[Epoch 14, Batch 1600] loss: 0.011423900653715862
[Epoch 14, Batch 1700] loss: 0.00558624903424942
[Epoch 14, Batch 1800] loss: 0.015333390630056556
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0613
Validation Accuracy: 0.9860
Overfitting: 0.0609
[Epoch 15, Batch 100] loss: 0.004781746847297655
[Epoch 15, Batch 200] loss: 0.0020580749059043056
[Epoch 15, Batch 300] loss: 0.005055362325906146
[Epoch 15, Batch 400] loss: 0.004541039530223543
[Epoch 15, Batch 500] loss: 0.0054040561098912575
[Epoch 15, Batch 600] loss: 0.0012694336429927944
[Epoch 15, Batch 700] loss: 0.0012843952977226536
[Epoch 15, Batch 800] loss: 0.000836369508996313
[Epoch 15, Batch 900] loss: 0.004252078716637864
[Epoch 15, Batch 1000] loss: 0.005651872625147405
[Epoch 15, Batch 1100] loss: 0.0031091250001772154
[Epoch 15, Batch 1200] loss: 0.006081930797597579
[Epoch 15, Batch 1300] loss: 0.0039691147642992065
[Epoch 15, Batch 1400] loss: 0.002276434747838607
[Epoch 15, Batch 1500] loss: 0.00570330689859361
[Epoch 15, Batch 1600] loss: 0.0050802194059581755
[Epoch 15, Batch 1700] loss: 0.005521701065042066
[Epoch 15, Batch 1800] loss: 0.012087136728293615
**STATS for Epoch 15** : 
Average training loss: 0.0002
Average validation loss: 0.0662
Validation Accuracy: 0.9861
Overfitting: 0.0660
[Epoch 16, Batch 100] loss: 0.00217773271042077
[Epoch 16, Batch 200] loss: 0.007831185624724527
[Epoch 16, Batch 300] loss: 0.006359191712467904
[Epoch 16, Batch 400] loss: 0.004508802668857044
[Epoch 16, Batch 500] loss: 0.00786932641043684
[Epoch 16, Batch 600] loss: 0.004933979996549098
[Epoch 16, Batch 700] loss: 0.0013690065161332753
[Epoch 16, Batch 800] loss: 0.005468799340864621
[Epoch 16, Batch 900] loss: 0.0015630169659874582
[Epoch 16, Batch 1000] loss: 0.0034689435970842552
[Epoch 16, Batch 1100] loss: 0.006361922550721868
[Epoch 16, Batch 1200] loss: 0.002704627740820911
[Epoch 16, Batch 1300] loss: 0.005622511524217861
[Epoch 16, Batch 1400] loss: 0.010513316300200018
[Epoch 16, Batch 1500] loss: 0.007353303764196681
[Epoch 16, Batch 1600] loss: 0.0023199418128558593
[Epoch 16, Batch 1700] loss: 0.0047094413002091605
[Epoch 16, Batch 1800] loss: 0.0024460985953311367
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0685
Validation Accuracy: 0.9864
Overfitting: 0.0684
[Epoch 17, Batch 100] loss: 0.0008255306235265891
[Epoch 17, Batch 200] loss: 0.002283772444095149
[Epoch 17, Batch 300] loss: 0.0033345408725593017
[Epoch 17, Batch 400] loss: 0.0008581234583559194
[Epoch 17, Batch 500] loss: 0.0008876648750800697
[Epoch 17, Batch 600] loss: 0.004030080934584248
[Epoch 17, Batch 700] loss: 0.0029912813941820105
[Epoch 17, Batch 800] loss: 0.0038412411525666455
[Epoch 17, Batch 900] loss: 0.006840281853013437
[Epoch 17, Batch 1000] loss: 0.0030726140395709177
[Epoch 17, Batch 1100] loss: 0.0036667986260809473
[Epoch 17, Batch 1200] loss: 0.0017565121560428843
[Epoch 17, Batch 1300] loss: 0.002294337427987072
[Epoch 17, Batch 1400] loss: 0.0012794993300178704
[Epoch 17, Batch 1500] loss: 0.0008178972925956129
[Epoch 17, Batch 1600] loss: 0.002517704382436925
[Epoch 17, Batch 1700] loss: 0.017721401108963766
[Epoch 17, Batch 1800] loss: 0.00446729755420364
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0918
Validation Accuracy: 0.9821
Overfitting: 0.0915
[Epoch 18, Batch 100] loss: 0.007993700892579057
[Epoch 18, Batch 200] loss: 0.006611305362163869
[Epoch 18, Batch 300] loss: 0.002597563090121184
[Epoch 18, Batch 400] loss: 0.002844327864004441
[Epoch 18, Batch 500] loss: 0.003237666410414821
[Epoch 18, Batch 600] loss: 0.007645203005352599
[Epoch 18, Batch 700] loss: 0.008653442712219928
[Epoch 18, Batch 800] loss: 0.019626539183777533
[Epoch 18, Batch 900] loss: 0.01802705027262192
[Epoch 18, Batch 1000] loss: 0.01086874380524364
[Epoch 18, Batch 1100] loss: 0.0033628071798932524
[Epoch 18, Batch 1200] loss: 0.0013977502768652529
[Epoch 18, Batch 1300] loss: 0.010196943038048972
[Epoch 18, Batch 1400] loss: 0.007614497679359716
[Epoch 18, Batch 1500] loss: 0.013521121256940206
[Epoch 18, Batch 1600] loss: 0.00872487549966536
[Epoch 18, Batch 1700] loss: 0.004715680532479496
[Epoch 18, Batch 1800] loss: 0.006824419472753505
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0665
Validation Accuracy: 0.9858
Overfitting: 0.0663
[Epoch 19, Batch 100] loss: 0.0014003333403404383
[Epoch 19, Batch 200] loss: 0.0014373778405547455
[Epoch 19, Batch 300] loss: 0.0020515875824886898
[Epoch 19, Batch 400] loss: 0.002943027406515597
[Epoch 19, Batch 500] loss: 0.0010828408148569934
[Epoch 19, Batch 600] loss: 0.002742482669590469
[Epoch 19, Batch 700] loss: 0.0010056577396052458
[Epoch 19, Batch 800] loss: 0.0009083528007568553
[Epoch 19, Batch 900] loss: 0.0008586286774540497
[Epoch 19, Batch 1000] loss: 0.002723199595537018
[Epoch 19, Batch 1100] loss: 0.004715199186766768
[Epoch 19, Batch 1200] loss: 0.0002405475811313451
[Epoch 19, Batch 1300] loss: 0.0025383727644424335
[Epoch 19, Batch 1400] loss: 0.0012199873641815183
[Epoch 19, Batch 1500] loss: 0.0024957883586972686
[Epoch 19, Batch 1600] loss: 0.003730069416826396
[Epoch 19, Batch 1700] loss: 0.001945101239848057
[Epoch 19, Batch 1800] loss: 0.001476723983481456
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0711
Validation Accuracy: 0.9866
Overfitting: 0.0710
[Epoch 20, Batch 100] loss: 0.00039528473864705485
[Epoch 20, Batch 200] loss: 0.0037120626218149866
[Epoch 20, Batch 300] loss: 0.00042112620789655606
[Epoch 20, Batch 400] loss: 0.0006193266211266746
[Epoch 20, Batch 500] loss: 0.00036096546504900574
[Epoch 20, Batch 600] loss: 0.0012873874978621869
[Epoch 20, Batch 700] loss: 0.002623494376451703
[Epoch 20, Batch 800] loss: 0.001462938659861912
[Epoch 20, Batch 900] loss: 0.0009227256448023269
[Epoch 20, Batch 1000] loss: 0.0010689928734831033
[Epoch 20, Batch 1100] loss: 0.0008740274909277091
[Epoch 20, Batch 1200] loss: 0.0013955779628177822
[Epoch 20, Batch 1300] loss: 0.00028879780016575205
[Epoch 20, Batch 1400] loss: 0.0009065269607536086
[Epoch 20, Batch 1500] loss: 0.0008662885880023552
[Epoch 20, Batch 1600] loss: 0.0016592637734416816
[Epoch 20, Batch 1700] loss: 0.0008245911887899159
[Epoch 20, Batch 1800] loss: 0.0004568441216221153
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0707
Validation Accuracy: 0.9872
Overfitting: 0.0707
[Epoch 21, Batch 100] loss: 0.00019720859041992168
[Epoch 21, Batch 200] loss: 0.0012206651627530273
[Epoch 21, Batch 300] loss: 0.0002001363151999369
[Epoch 21, Batch 400] loss: 0.00013372110756808996
[Epoch 21, Batch 500] loss: 0.00033227839945844997
[Epoch 21, Batch 600] loss: 0.0004028793444288503
[Epoch 21, Batch 700] loss: 0.001271335103514204
[Epoch 21, Batch 800] loss: 0.00022379059285774884
[Epoch 21, Batch 900] loss: 0.0002612120773621296
[Epoch 21, Batch 1000] loss: 0.0002736720451392571
[Epoch 21, Batch 1100] loss: 0.00029072011464567285
[Epoch 21, Batch 1200] loss: 0.00024484610597382163
[Epoch 21, Batch 1300] loss: 0.00018010121664545407
[Epoch 21, Batch 1400] loss: 0.000232710546077457
[Epoch 21, Batch 1500] loss: 0.0003445219910810549
[Epoch 21, Batch 1600] loss: 0.00019313920881361302
[Epoch 21, Batch 1700] loss: 0.00038533366884352827
[Epoch 21, Batch 1800] loss: 0.00034773842263055246
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0708
Validation Accuracy: 0.9871
Overfitting: 0.0708
[Epoch 22, Batch 100] loss: 0.00048427584184932646
[Epoch 22, Batch 200] loss: 0.0011727621535971976
[Epoch 22, Batch 300] loss: 0.0014446996487491326
[Epoch 22, Batch 400] loss: 0.0004979133797258406
[Epoch 22, Batch 500] loss: 0.0010567102456670251
[Epoch 22, Batch 600] loss: 0.0006033789139111167
[Epoch 22, Batch 700] loss: 9.9631035306329e-05
[Epoch 22, Batch 800] loss: 0.000366763566392132
[Epoch 22, Batch 900] loss: 0.00036567708612341934
[Epoch 22, Batch 1000] loss: 0.0003359921086173712
[Epoch 22, Batch 1100] loss: 0.00014486535312187244
[Epoch 22, Batch 1200] loss: 6.92866938480341e-05
[Epoch 22, Batch 1300] loss: 0.00018894344881183577
[Epoch 22, Batch 1400] loss: 0.0003072895943675658
[Epoch 22, Batch 1500] loss: 0.0002916983496685388
[Epoch 22, Batch 1600] loss: 0.0004966202716883173
[Epoch 22, Batch 1700] loss: 0.0002597006036947036
[Epoch 22, Batch 1800] loss: 0.00021526408737663428
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0713
Validation Accuracy: 0.9873
Overfitting: 0.0713
[Epoch 23, Batch 100] loss: 0.00019453502412731806
[Epoch 23, Batch 200] loss: 0.0001416102580375389
[Epoch 23, Batch 300] loss: 9.312059879021284e-05
[Epoch 23, Batch 400] loss: 7.925641449680664e-05
[Epoch 23, Batch 500] loss: 0.00010082081276790777
[Epoch 23, Batch 600] loss: 8.378588942492104e-05
[Epoch 23, Batch 700] loss: 9.692460310271045e-05
[Epoch 23, Batch 800] loss: 7.378640058808283e-05
[Epoch 23, Batch 900] loss: 0.0002494788761170863
[Epoch 23, Batch 1000] loss: 0.0005055220991688891
[Epoch 23, Batch 1100] loss: 0.00015740855622821127
[Epoch 23, Batch 1200] loss: 5.856163982183915e-05
[Epoch 23, Batch 1300] loss: 8.574553441177635e-05
[Epoch 23, Batch 1400] loss: 0.00014348665808773918
[Epoch 23, Batch 1500] loss: 0.00016459745113054148
[Epoch 23, Batch 1600] loss: 8.633099706401026e-05
[Epoch 23, Batch 1700] loss: 0.0003938832926023839
[Epoch 23, Batch 1800] loss: 0.00020248822123068776
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0725
Validation Accuracy: 0.9873
Overfitting: 0.0725
[Epoch 24, Batch 100] loss: 0.00011785945894973615
[Epoch 24, Batch 200] loss: 0.0001728323396659004
[Epoch 24, Batch 300] loss: 7.817251672962211e-05
[Epoch 24, Batch 400] loss: 0.00010707349750354477
[Epoch 24, Batch 500] loss: 0.0001000047064080789
[Epoch 24, Batch 600] loss: 8.06376702901046e-05
[Epoch 24, Batch 700] loss: 0.00012341219652590941
[Epoch 24, Batch 800] loss: 0.00012090374259885462
[Epoch 24, Batch 900] loss: 8.500192107961268e-05
[Epoch 24, Batch 1000] loss: 0.00010425595437912438
[Epoch 24, Batch 1100] loss: 8.104503974493582e-05
[Epoch 24, Batch 1200] loss: 0.00022214572335197858
[Epoch 24, Batch 1300] loss: 9.39244557777652e-05
[Epoch 24, Batch 1400] loss: 7.191909126457397e-05
[Epoch 24, Batch 1500] loss: 0.00013158916619880666
[Epoch 24, Batch 1600] loss: 0.00011573362464945003
[Epoch 24, Batch 1700] loss: 0.00014485370806105458
[Epoch 24, Batch 1800] loss: 0.00011586638480088673
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0739
Validation Accuracy: 0.9876
Overfitting: 0.0739
Fold 1 validation loss: 0.0739
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.29691349029541
[Epoch 1, Batch 200] loss: 2.242989945411682
[Epoch 1, Batch 300] loss: 1.3818170630931854
[Epoch 1, Batch 400] loss: 0.6633145868778229
[Epoch 1, Batch 500] loss: 0.48690373353660105
[Epoch 1, Batch 600] loss: 0.3673071239516139
[Epoch 1, Batch 700] loss: 0.32431881098076704
[Epoch 1, Batch 800] loss: 0.25457827497273683
[Epoch 1, Batch 900] loss: 0.22572440825402737
[Epoch 1, Batch 1000] loss: 0.22379836595617233
[Epoch 1, Batch 1100] loss: 0.22199209270067513
[Epoch 1, Batch 1200] loss: 0.17311212250962854
[Epoch 1, Batch 1300] loss: 0.1774776606541127
[Epoch 1, Batch 1400] loss: 0.14947513838764281
[Epoch 1, Batch 1500] loss: 0.15715365113690496
[Epoch 1, Batch 1600] loss: 0.13470451559405774
[Epoch 1, Batch 1700] loss: 0.13737992655835116
[Epoch 1, Batch 1800] loss: 0.12860457957722246
**STATS for Epoch 1** : 
Average training loss: 0.0055
Average validation loss: 0.1358
Validation Accuracy: 0.9580
Overfitting: 0.1303
Best model saved at epoch 1 with validation loss: 0.1358
[Epoch 2, Batch 100] loss: 0.1237163476360729
[Epoch 2, Batch 200] loss: 0.13193185799522325
[Epoch 2, Batch 300] loss: 0.11979619903722778
[Epoch 2, Batch 400] loss: 0.12635023544542492
[Epoch 2, Batch 500] loss: 0.11552963639318477
[Epoch 2, Batch 600] loss: 0.12821555735310539
[Epoch 2, Batch 700] loss: 0.09223522971034981
[Epoch 2, Batch 800] loss: 0.1320940940757282
[Epoch 2, Batch 900] loss: 0.12818167224293575
[Epoch 2, Batch 1000] loss: 0.08067074446356855
[Epoch 2, Batch 1100] loss: 0.08854491371545009
[Epoch 2, Batch 1200] loss: 0.060436862647766244
[Epoch 2, Batch 1300] loss: 0.08859719354077242
[Epoch 2, Batch 1400] loss: 0.1250025386037305
[Epoch 2, Batch 1500] loss: 0.08795179185690358
[Epoch 2, Batch 1600] loss: 0.09141425304871519
[Epoch 2, Batch 1700] loss: 0.10102555531193502
[Epoch 2, Batch 1800] loss: 0.08625264261267147
**STATS for Epoch 2** : 
Average training loss: 0.0042
Average validation loss: 0.0994
Validation Accuracy: 0.9694
Overfitting: 0.0952
Best model saved at epoch 2 with validation loss: 0.0994
[Epoch 3, Batch 100] loss: 0.07420864519430324
[Epoch 3, Batch 200] loss: 0.06367968167061917
[Epoch 3, Batch 300] loss: 0.08435493541008326
[Epoch 3, Batch 400] loss: 0.07925135886878706
[Epoch 3, Batch 500] loss: 0.09040181620861404
[Epoch 3, Batch 600] loss: 0.05999035853426903
[Epoch 3, Batch 700] loss: 0.08362097416073083
[Epoch 3, Batch 800] loss: 0.07629064882406965
[Epoch 3, Batch 900] loss: 0.06237916251528077
[Epoch 3, Batch 1000] loss: 0.0622114255692577
[Epoch 3, Batch 1100] loss: 0.08082963196357014
[Epoch 3, Batch 1200] loss: 0.07268718885112321
[Epoch 3, Batch 1300] loss: 0.08126279004791286
[Epoch 3, Batch 1400] loss: 0.07291280500066932
[Epoch 3, Batch 1500] loss: 0.06467790646725917
[Epoch 3, Batch 1600] loss: 0.06650104244356043
[Epoch 3, Batch 1700] loss: 0.0680822349654045
[Epoch 3, Batch 1800] loss: 0.07557025568676182
**STATS for Epoch 3** : 
Average training loss: 0.0033
Average validation loss: 0.0904
Validation Accuracy: 0.9725
Overfitting: 0.0870
Best model saved at epoch 3 with validation loss: 0.0904
[Epoch 4, Batch 100] loss: 0.053594920143368655
[Epoch 4, Batch 200] loss: 0.058087599974824114
[Epoch 4, Batch 300] loss: 0.06074610705836676
[Epoch 4, Batch 400] loss: 0.05343386278633261
[Epoch 4, Batch 500] loss: 0.06866130636291928
[Epoch 4, Batch 600] loss: 0.06112842997710686
[Epoch 4, Batch 700] loss: 0.07448138036939782
[Epoch 4, Batch 800] loss: 0.03988896295733866
[Epoch 4, Batch 900] loss: 0.04951005507915397
[Epoch 4, Batch 1000] loss: 0.06391872366686585
[Epoch 4, Batch 1100] loss: 0.03379717760341009
[Epoch 4, Batch 1200] loss: 0.03129712129608379
[Epoch 4, Batch 1300] loss: 0.049276382543321236
[Epoch 4, Batch 1400] loss: 0.053747488304506985
[Epoch 4, Batch 1500] loss: 0.06986030141153605
[Epoch 4, Batch 1600] loss: 0.052919270310812866
[Epoch 4, Batch 1700] loss: 0.06291087102843448
[Epoch 4, Batch 1800] loss: 0.055389581206836735
**STATS for Epoch 4** : 
Average training loss: 0.0028
Average validation loss: 0.0662
Validation Accuracy: 0.9798
Overfitting: 0.0633
Best model saved at epoch 4 with validation loss: 0.0662
[Epoch 5, Batch 100] loss: 0.03192287565470906
[Epoch 5, Batch 200] loss: 0.033927678261352415
[Epoch 5, Batch 300] loss: 0.04195787199365441
[Epoch 5, Batch 400] loss: 0.05413645310458378
[Epoch 5, Batch 500] loss: 0.04503929926999262
[Epoch 5, Batch 600] loss: 0.04329164794515236
[Epoch 5, Batch 700] loss: 0.03130294609378325
[Epoch 5, Batch 800] loss: 0.04223610502362135
[Epoch 5, Batch 900] loss: 0.03146536461521464
[Epoch 5, Batch 1000] loss: 0.035300802354322515
[Epoch 5, Batch 1100] loss: 0.03925668367039179
[Epoch 5, Batch 1200] loss: 0.053197541885747344
[Epoch 5, Batch 1300] loss: 0.04519906661385903
[Epoch 5, Batch 1400] loss: 0.039180914954922624
[Epoch 5, Batch 1500] loss: 0.045233653812356354
[Epoch 5, Batch 1600] loss: 0.060937976415007145
[Epoch 5, Batch 1700] loss: 0.04420907936684671
[Epoch 5, Batch 1800] loss: 0.03986880661948817
**STATS for Epoch 5** : 
Average training loss: 0.0015
Average validation loss: 0.0697
Validation Accuracy: 0.9796
Overfitting: 0.0682
[Epoch 6, Batch 100] loss: 0.047162112876794705
[Epoch 6, Batch 200] loss: 0.02926568565162597
[Epoch 6, Batch 300] loss: 0.027890063340237248
[Epoch 6, Batch 400] loss: 0.03640415718531585
[Epoch 6, Batch 500] loss: 0.0320801455869514
[Epoch 6, Batch 600] loss: 0.034080955690878906
[Epoch 6, Batch 700] loss: 0.019915769315430223
[Epoch 6, Batch 800] loss: 0.03439440901733178
[Epoch 6, Batch 900] loss: 0.028713056872038577
[Epoch 6, Batch 1000] loss: 0.032755460011176185
[Epoch 6, Batch 1100] loss: 0.034336734172247814
[Epoch 6, Batch 1200] loss: 0.04882000420751865
[Epoch 6, Batch 1300] loss: 0.040661300945212135
[Epoch 6, Batch 1400] loss: 0.04237632476280851
[Epoch 6, Batch 1500] loss: 0.03551193073624745
[Epoch 6, Batch 1600] loss: 0.04133201226541132
[Epoch 6, Batch 1700] loss: 0.029940754121271312
[Epoch 6, Batch 1800] loss: 0.03227099697396625
**STATS for Epoch 6** : 
Average training loss: 0.0028
Average validation loss: 0.0597
Validation Accuracy: 0.9827
Overfitting: 0.0569
Best model saved at epoch 6 with validation loss: 0.0597
[Epoch 7, Batch 100] loss: 0.04500575744372327
[Epoch 7, Batch 200] loss: 0.03135394729528343
[Epoch 7, Batch 300] loss: 0.03482038636851939
[Epoch 7, Batch 400] loss: 0.01778251263865968
[Epoch 7, Batch 500] loss: 0.04134589652165232
[Epoch 7, Batch 600] loss: 0.02683369568838316
[Epoch 7, Batch 700] loss: 0.024085923139900843
[Epoch 7, Batch 800] loss: 0.02280550229043001
[Epoch 7, Batch 900] loss: 0.04243201228629914
[Epoch 7, Batch 1000] loss: 0.023829703957235323
[Epoch 7, Batch 1100] loss: 0.034168077335343695
[Epoch 7, Batch 1200] loss: 0.021199292941673775
[Epoch 7, Batch 1300] loss: 0.030505340421877917
[Epoch 7, Batch 1400] loss: 0.027298574223932517
[Epoch 7, Batch 1500] loss: 0.02421841509560181
[Epoch 7, Batch 1600] loss: 0.0292075337224378
[Epoch 7, Batch 1700] loss: 0.02757207324852061
[Epoch 7, Batch 1800] loss: 0.024010105605811988
**STATS for Epoch 7** : 
Average training loss: 0.0008
Average validation loss: 0.0585
Validation Accuracy: 0.9839
Overfitting: 0.0576
Best model saved at epoch 7 with validation loss: 0.0585
[Epoch 8, Batch 100] loss: 0.014562128288089298
[Epoch 8, Batch 200] loss: 0.02595906588595426
[Epoch 8, Batch 300] loss: 0.024529514874902816
[Epoch 8, Batch 400] loss: 0.022377573081685115
[Epoch 8, Batch 500] loss: 0.02799614813403423
[Epoch 8, Batch 600] loss: 0.01699484287875748
[Epoch 8, Batch 700] loss: 0.02026875264771661
[Epoch 8, Batch 800] loss: 0.02517694670619676
[Epoch 8, Batch 900] loss: 0.03467819029163365
[Epoch 8, Batch 1000] loss: 0.020990173026330012
[Epoch 8, Batch 1100] loss: 0.02506631165630097
[Epoch 8, Batch 1200] loss: 0.031215554317604984
[Epoch 8, Batch 1300] loss: 0.022078630820578836
[Epoch 8, Batch 1400] loss: 0.029527111204342874
[Epoch 8, Batch 1500] loss: 0.025335305095813963
[Epoch 8, Batch 1600] loss: 0.03739840346114079
[Epoch 8, Batch 1700] loss: 0.019427514907947627
[Epoch 8, Batch 1800] loss: 0.03696567373774997
**STATS for Epoch 8** : 
Average training loss: 0.0005
Average validation loss: 0.0554
Validation Accuracy: 0.9847
Overfitting: 0.0549
Best model saved at epoch 8 with validation loss: 0.0554
[Epoch 9, Batch 100] loss: 0.005772424986380429
[Epoch 9, Batch 200] loss: 0.015194869867209491
[Epoch 9, Batch 300] loss: 0.015807479032155243
[Epoch 9, Batch 400] loss: 0.008900551130536768
[Epoch 9, Batch 500] loss: 0.012215171005191223
[Epoch 9, Batch 600] loss: 0.014399884468821256
[Epoch 9, Batch 700] loss: 0.020354216770901986
[Epoch 9, Batch 800] loss: 0.018753413435024412
[Epoch 9, Batch 900] loss: 0.026682736476750506
[Epoch 9, Batch 1000] loss: 0.019896850951063243
[Epoch 9, Batch 1100] loss: 0.02753747511727852
[Epoch 9, Batch 1200] loss: 0.022358186490819207
[Epoch 9, Batch 1300] loss: 0.02737796933946811
[Epoch 9, Batch 1400] loss: 0.015983706712031562
[Epoch 9, Batch 1500] loss: 0.029664630689330805
[Epoch 9, Batch 1600] loss: 0.035007740034925516
[Epoch 9, Batch 1700] loss: 0.0245907796125357
[Epoch 9, Batch 1800] loss: 0.027981156761734384
**STATS for Epoch 9** : 
Average training loss: 0.0013
Average validation loss: 0.0559
Validation Accuracy: 0.9846
Overfitting: 0.0547
[Epoch 10, Batch 100] loss: 0.009904239303850773
[Epoch 10, Batch 200] loss: 0.019134146959713688
[Epoch 10, Batch 300] loss: 0.01327169431618131
[Epoch 10, Batch 400] loss: 0.01492107088994544
[Epoch 10, Batch 500] loss: 0.014677702314766066
[Epoch 10, Batch 600] loss: 0.017764323294381937
[Epoch 10, Batch 700] loss: 0.013408789005534345
[Epoch 10, Batch 800] loss: 0.023044659770998805
[Epoch 10, Batch 900] loss: 0.020405245424453825
[Epoch 10, Batch 1000] loss: 0.020585944734173155
[Epoch 10, Batch 1100] loss: 0.023587076776238974
[Epoch 10, Batch 1200] loss: 0.02238933174783597
[Epoch 10, Batch 1300] loss: 0.01331288283629874
[Epoch 10, Batch 1400] loss: 0.018883719549530723
[Epoch 10, Batch 1500] loss: 0.015018458506619935
[Epoch 10, Batch 1600] loss: 0.011025798529888107
[Epoch 10, Batch 1700] loss: 0.03070021158664531
[Epoch 10, Batch 1800] loss: 0.0151279649161188
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0661
Validation Accuracy: 0.9828
Overfitting: 0.0645
[Epoch 11, Batch 100] loss: 0.015776794939267803
[Epoch 11, Batch 200] loss: 0.020886482436361577
[Epoch 11, Batch 300] loss: 0.01002568782081653
[Epoch 11, Batch 400] loss: 0.00945497257644547
[Epoch 11, Batch 500] loss: 0.013571794670617691
[Epoch 11, Batch 600] loss: 0.02484869728465128
[Epoch 11, Batch 700] loss: 0.015898582575889577
[Epoch 11, Batch 800] loss: 0.017769919123757062
[Epoch 11, Batch 900] loss: 0.014637996925594053
[Epoch 11, Batch 1000] loss: 0.012209191660967917
[Epoch 11, Batch 1100] loss: 0.012445062083078256
[Epoch 11, Batch 1200] loss: 0.014374041286586134
[Epoch 11, Batch 1300] loss: 0.01591881598980649
[Epoch 11, Batch 1400] loss: 0.013860276004647858
[Epoch 11, Batch 1500] loss: 0.015208865938793678
[Epoch 11, Batch 1600] loss: 0.019479982420536997
[Epoch 11, Batch 1700] loss: 0.010791825724925274
[Epoch 11, Batch 1800] loss: 0.005509071323285752
**STATS for Epoch 11** : 
Average training loss: 0.0004
Average validation loss: 0.0584
Validation Accuracy: 0.9862
Overfitting: 0.0580
[Epoch 12, Batch 100] loss: 0.005027466906142308
[Epoch 12, Batch 200] loss: 0.014132412032329284
[Epoch 12, Batch 300] loss: 0.014777882924990137
[Epoch 12, Batch 400] loss: 0.015928689381097455
[Epoch 12, Batch 500] loss: 0.010272826571117548
[Epoch 12, Batch 600] loss: 0.007233082881066366
[Epoch 12, Batch 700] loss: 0.006899845018172073
[Epoch 12, Batch 800] loss: 0.0332959510532919
[Epoch 12, Batch 900] loss: 0.01140241281433873
[Epoch 12, Batch 1000] loss: 0.007501327028094238
[Epoch 12, Batch 1100] loss: 0.008027348205717998
[Epoch 12, Batch 1200] loss: 0.015999070060602208
[Epoch 12, Batch 1300] loss: 0.01497793644882222
[Epoch 12, Batch 1400] loss: 0.020307323378287948
[Epoch 12, Batch 1500] loss: 0.007749164362007832
[Epoch 12, Batch 1600] loss: 0.0057255128707424776
[Epoch 12, Batch 1700] loss: 0.012287386797926275
[Epoch 12, Batch 1800] loss: 0.01038734280572271
**STATS for Epoch 12** : 
Average training loss: 0.0006
Average validation loss: 0.0576
Validation Accuracy: 0.9859
Overfitting: 0.0570
[Epoch 13, Batch 100] loss: 0.005805158590037536
[Epoch 13, Batch 200] loss: 0.011681243386909158
[Epoch 13, Batch 300] loss: 0.010370886783853166
[Epoch 13, Batch 400] loss: 0.01575192947150981
[Epoch 13, Batch 500] loss: 0.012348402489110413
[Epoch 13, Batch 600] loss: 0.020805459032686713
[Epoch 13, Batch 700] loss: 0.014552358007103977
[Epoch 13, Batch 800] loss: 0.018870683252723664
[Epoch 13, Batch 900] loss: 0.013413303133580712
[Epoch 13, Batch 1000] loss: 0.013734489836077729
[Epoch 13, Batch 1100] loss: 0.01624378678199264
[Epoch 13, Batch 1200] loss: 0.012797646565086324
[Epoch 13, Batch 1300] loss: 0.005897659862330329
[Epoch 13, Batch 1400] loss: 0.014494124448651747
[Epoch 13, Batch 1500] loss: 0.012188926232722679
[Epoch 13, Batch 1600] loss: 0.015372692814285074
[Epoch 13, Batch 1700] loss: 0.013324435221511522
[Epoch 13, Batch 1800] loss: 0.013944303512080296
**STATS for Epoch 13** : 
Average training loss: 0.0007
Average validation loss: 0.0608
Validation Accuracy: 0.9839
Overfitting: 0.0601
[Epoch 14, Batch 100] loss: 0.008368024261880009
[Epoch 14, Batch 200] loss: 0.0196297477800681
[Epoch 14, Batch 300] loss: 0.013778762290392023
[Epoch 14, Batch 400] loss: 0.012596210664905811
[Epoch 14, Batch 500] loss: 0.01040257954490471
[Epoch 14, Batch 600] loss: 0.006510964837054871
[Epoch 14, Batch 700] loss: 0.004248467958866513
[Epoch 14, Batch 800] loss: 0.013183964832961123
[Epoch 14, Batch 900] loss: 0.013295422969642914
[Epoch 14, Batch 1000] loss: 0.013999872031496352
[Epoch 14, Batch 1100] loss: 0.008235168074293142
[Epoch 14, Batch 1200] loss: 0.007228057859026507
[Epoch 14, Batch 1300] loss: 0.007603498537650921
[Epoch 14, Batch 1400] loss: 0.011377187298492117
[Epoch 14, Batch 1500] loss: 0.009552881589404478
[Epoch 14, Batch 1600] loss: 0.005578357397876061
[Epoch 14, Batch 1700] loss: 0.010198080908755855
[Epoch 14, Batch 1800] loss: 0.006544501132373171
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0581
Validation Accuracy: 0.9857
Overfitting: 0.0577
[Epoch 15, Batch 100] loss: 0.0036651755745651824
[Epoch 15, Batch 200] loss: 0.003820552622079276
[Epoch 15, Batch 300] loss: 0.005322953823427525
[Epoch 15, Batch 400] loss: 0.008123658923665289
[Epoch 15, Batch 500] loss: 0.0020513201153090676
[Epoch 15, Batch 600] loss: 0.00806486884727974
[Epoch 15, Batch 700] loss: 0.008297537741456154
[Epoch 15, Batch 800] loss: 0.007579113756892184
[Epoch 15, Batch 900] loss: 0.009129132367049805
[Epoch 15, Batch 1000] loss: 0.009796433552400572
[Epoch 15, Batch 1100] loss: 0.006645809519367702
[Epoch 15, Batch 1200] loss: 0.0065088930451884155
[Epoch 15, Batch 1300] loss: 0.005821270739985777
[Epoch 15, Batch 1400] loss: 0.018954468845855103
[Epoch 15, Batch 1500] loss: 0.009049154688584906
[Epoch 15, Batch 1600] loss: 0.015309879031407262
[Epoch 15, Batch 1700] loss: 0.015347723978750309
[Epoch 15, Batch 1800] loss: 0.009602778804097625
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0659
Validation Accuracy: 0.9837
Overfitting: 0.0651
[Epoch 16, Batch 100] loss: 0.005549379646668058
[Epoch 16, Batch 200] loss: 0.007167529868383724
[Epoch 16, Batch 300] loss: 0.006826330700830852
[Epoch 16, Batch 400] loss: 0.0022442061856412466
[Epoch 16, Batch 500] loss: 0.0010917203914277706
[Epoch 16, Batch 600] loss: 0.010772701906879546
[Epoch 16, Batch 700] loss: 0.0020443719547409956
[Epoch 16, Batch 800] loss: 0.0017675858081521766
[Epoch 16, Batch 900] loss: 0.0013821123455823425
[Epoch 16, Batch 1000] loss: 0.007460357980968126
[Epoch 16, Batch 1100] loss: 0.0027120243150022816
[Epoch 16, Batch 1200] loss: 0.0014785105266529896
[Epoch 16, Batch 1300] loss: 0.0041912188321040844
[Epoch 16, Batch 1400] loss: 0.007773100887786484
[Epoch 16, Batch 1500] loss: 0.003559427789119525
[Epoch 16, Batch 1600] loss: 0.003651114889947138
[Epoch 16, Batch 1700] loss: 0.003040208587127324
[Epoch 16, Batch 1800] loss: 0.001461416452111166
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0618
Validation Accuracy: 0.9866
Overfitting: 0.0617
[Epoch 17, Batch 100] loss: 0.005162073112602314
[Epoch 17, Batch 200] loss: 0.0012293752986406758
[Epoch 17, Batch 300] loss: 0.008963727234083264
[Epoch 17, Batch 400] loss: 0.00272158593617263
[Epoch 17, Batch 500] loss: 0.0032500993924094246
[Epoch 17, Batch 600] loss: 0.0005923651490484616
[Epoch 17, Batch 700] loss: 0.0022683408695158393
[Epoch 17, Batch 800] loss: 0.007364501479147094
[Epoch 17, Batch 900] loss: 0.006117072225651867
[Epoch 17, Batch 1000] loss: 0.007066499386243094
[Epoch 17, Batch 1100] loss: 0.004298180538510365
[Epoch 17, Batch 1200] loss: 0.002048704448266392
[Epoch 17, Batch 1300] loss: 0.0051713098940058795
[Epoch 17, Batch 1400] loss: 0.005788279668505254
[Epoch 17, Batch 1500] loss: 0.003165553280885334
[Epoch 17, Batch 1600] loss: 0.0018475900711705862
[Epoch 17, Batch 1700] loss: 0.0018261736987298471
[Epoch 17, Batch 1800] loss: 0.0018500104968981646
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0622
Validation Accuracy: 0.9873
Overfitting: 0.0621
[Epoch 18, Batch 100] loss: 0.0006176648462691503
[Epoch 18, Batch 200] loss: 0.003108065263322768
[Epoch 18, Batch 300] loss: 0.001200280722647662
[Epoch 18, Batch 400] loss: 0.001023603167642122
[Epoch 18, Batch 500] loss: 0.0024495853662220668
[Epoch 18, Batch 600] loss: 0.001422533707394531
[Epoch 18, Batch 700] loss: 0.001304693218023445
[Epoch 18, Batch 800] loss: 0.0015082326758201958
[Epoch 18, Batch 900] loss: 0.0008921541090507779
[Epoch 18, Batch 1000] loss: 0.0017211161481838033
[Epoch 18, Batch 1100] loss: 0.00242756732082142
[Epoch 18, Batch 1200] loss: 0.0015349722206136106
[Epoch 18, Batch 1300] loss: 0.0022071016661538946
[Epoch 18, Batch 1400] loss: 0.002533625338221377
[Epoch 18, Batch 1500] loss: 0.0048706247107046605
[Epoch 18, Batch 1600] loss: 0.023624291411426412
[Epoch 18, Batch 1700] loss: 0.007552943383585226
[Epoch 18, Batch 1800] loss: 0.0034284075765070553
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0722
Validation Accuracy: 0.9853
Overfitting: 0.0721
[Epoch 19, Batch 100] loss: 0.0017627079163656844
[Epoch 19, Batch 200] loss: 0.002110438501365475
[Epoch 19, Batch 300] loss: 0.0027021598830036454
[Epoch 19, Batch 400] loss: 0.0019454103508268262
[Epoch 19, Batch 500] loss: 0.0014589380098792048
[Epoch 19, Batch 600] loss: 0.0017669444471727048
[Epoch 19, Batch 700] loss: 0.0017822985309010786
[Epoch 19, Batch 800] loss: 0.00356963931034338
[Epoch 19, Batch 900] loss: 0.006197316201148837
[Epoch 19, Batch 1000] loss: 0.002106285927777698
[Epoch 19, Batch 1100] loss: 0.017707458500947765
[Epoch 19, Batch 1200] loss: 0.008830560455723306
[Epoch 19, Batch 1300] loss: 0.00789269921025152
[Epoch 19, Batch 1400] loss: 0.009918991916011066
[Epoch 19, Batch 1500] loss: 0.01233968766468422
[Epoch 19, Batch 1600] loss: 0.00878453552544769
[Epoch 19, Batch 1700] loss: 0.011593210977968624
[Epoch 19, Batch 1800] loss: 0.007990765249136302
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0715
Validation Accuracy: 0.9844
Overfitting: 0.0708
[Epoch 20, Batch 100] loss: 0.017874430327966238
[Epoch 20, Batch 200] loss: 0.00892761518492449
[Epoch 20, Batch 300] loss: 0.010380374707539204
[Epoch 20, Batch 400] loss: 0.01610076771592901
[Epoch 20, Batch 500] loss: 0.012977002615122614
[Epoch 20, Batch 600] loss: 0.007051245561928141
[Epoch 20, Batch 700] loss: 0.00805885552177898
[Epoch 20, Batch 800] loss: 0.015932858481191053
[Epoch 20, Batch 900] loss: 0.023248406283804285
[Epoch 20, Batch 1000] loss: 0.011471811641744978
[Epoch 20, Batch 1100] loss: 0.004350748551715213
[Epoch 20, Batch 1200] loss: 0.004595593185518112
[Epoch 20, Batch 1300] loss: 0.007265524188912869
[Epoch 20, Batch 1400] loss: 0.011046833112619652
[Epoch 20, Batch 1500] loss: 0.00632092072226893
[Epoch 20, Batch 1600] loss: 0.0024231334610596276
[Epoch 20, Batch 1700] loss: 0.004385762782561713
[Epoch 20, Batch 1800] loss: 0.01725594151289968
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0736
Validation Accuracy: 0.9849
Overfitting: 0.0730
[Epoch 21, Batch 100] loss: 0.003274872842183778
[Epoch 21, Batch 200] loss: 0.004085037155677896
[Epoch 21, Batch 300] loss: 0.003865014083639764
[Epoch 21, Batch 400] loss: 0.0012808342585034183
[Epoch 21, Batch 500] loss: 0.004627139319378752
[Epoch 21, Batch 600] loss: 0.012508869580352524
[Epoch 21, Batch 700] loss: 0.013970279040898355
[Epoch 21, Batch 800] loss: 0.006062777723372364
[Epoch 21, Batch 900] loss: 0.008545978718510728
[Epoch 21, Batch 1000] loss: 0.008335580057642743
[Epoch 21, Batch 1100] loss: 0.0023290251346706013
[Epoch 21, Batch 1200] loss: 0.007586667557668037
[Epoch 21, Batch 1300] loss: 0.009124955635991637
[Epoch 21, Batch 1400] loss: 0.005429224306780931
[Epoch 21, Batch 1500] loss: 0.012661534025533844
[Epoch 21, Batch 1600] loss: 0.010328188333846243
[Epoch 21, Batch 1700] loss: 0.00982202686542621
[Epoch 21, Batch 1800] loss: 0.006433318553578431
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0636
Validation Accuracy: 0.9864
Overfitting: 0.0630
[Epoch 22, Batch 100] loss: 0.008560657503074078
[Epoch 22, Batch 200] loss: 0.007597359412357605
[Epoch 22, Batch 300] loss: 0.002596165231052652
[Epoch 22, Batch 400] loss: 0.002713319540549861
[Epoch 22, Batch 500] loss: 0.002416987506950079
[Epoch 22, Batch 600] loss: 0.004527524101446758
[Epoch 22, Batch 700] loss: 0.0032168222611414876
[Epoch 22, Batch 800] loss: 0.0011737804688999277
[Epoch 22, Batch 900] loss: 0.005126204122150639
[Epoch 22, Batch 1000] loss: 0.0012539541394196618
[Epoch 22, Batch 1100] loss: 0.0036748602975583823
[Epoch 22, Batch 1200] loss: 0.005095971021896748
[Epoch 22, Batch 1300] loss: 0.0019459127971819612
[Epoch 22, Batch 1400] loss: 0.0029575739586787985
[Epoch 22, Batch 1500] loss: 0.003131654711398677
[Epoch 22, Batch 1600] loss: 0.003535476853755455
[Epoch 22, Batch 1700] loss: 0.0043160687642213435
[Epoch 22, Batch 1800] loss: 0.003260257335309973
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0675
Validation Accuracy: 0.9865
Overfitting: 0.0672
[Epoch 23, Batch 100] loss: 0.017753573820731564
[Epoch 23, Batch 200] loss: 0.004559853813002732
[Epoch 23, Batch 300] loss: 0.0028596146770092546
[Epoch 23, Batch 400] loss: 0.0028429205593396034
[Epoch 23, Batch 500] loss: 0.003644838838815048
[Epoch 23, Batch 600] loss: 0.01033837274768132
[Epoch 23, Batch 700] loss: 0.008789064788450105
[Epoch 23, Batch 800] loss: 0.004249508707641319
[Epoch 23, Batch 900] loss: 0.001153141548108181
[Epoch 23, Batch 1000] loss: 0.0017702330943877341
[Epoch 23, Batch 1100] loss: 0.0010167300005391412
[Epoch 23, Batch 1200] loss: 0.0012251930434977786
[Epoch 23, Batch 1300] loss: 0.00233822265485756
[Epoch 23, Batch 1400] loss: 0.0017262962640288437
[Epoch 23, Batch 1500] loss: 0.0026783838025762918
[Epoch 23, Batch 1600] loss: 0.006156589443386409
[Epoch 23, Batch 1700] loss: 0.00047978231987816144
[Epoch 23, Batch 1800] loss: 0.0006165815006378495
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0649
Validation Accuracy: 0.9867
Overfitting: 0.0648
[Epoch 24, Batch 100] loss: 0.0002611791870618685
[Epoch 24, Batch 200] loss: 0.00041484653806804326
[Epoch 24, Batch 300] loss: 0.0003421561859411959
[Epoch 24, Batch 400] loss: 0.0003197440815875341
[Epoch 24, Batch 500] loss: 0.0002891079521563356
[Epoch 24, Batch 600] loss: 0.0009619105404241424
[Epoch 24, Batch 700] loss: 0.001418341241943235
[Epoch 24, Batch 800] loss: 0.0010657481256935242
[Epoch 24, Batch 900] loss: 0.0007173038913229268
[Epoch 24, Batch 1000] loss: 0.0003165945379930468
[Epoch 24, Batch 1100] loss: 0.0002464049570600535
[Epoch 24, Batch 1200] loss: 0.00037647980568891184
[Epoch 24, Batch 1300] loss: 0.00030187222137150637
[Epoch 24, Batch 1400] loss: 0.0008987574836820045
[Epoch 24, Batch 1500] loss: 0.00041934600998180474
[Epoch 24, Batch 1600] loss: 0.00044901170339220806
[Epoch 24, Batch 1700] loss: 0.00035804563160855894
[Epoch 24, Batch 1800] loss: 0.0004072353389302785
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0660
Validation Accuracy: 0.9877
Overfitting: 0.0660
Fold 2 validation loss: 0.0660
Mean validation loss across all folds for Trial 6 is 0.0699 with trial config:  l1: 128, l2: 64, lr: 0.002463768595899745, batch_size: 16
[I 2024-11-21 18:34:07,821] Trial 5 finished with value: 0.06993779215604778 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.002463768595899745, 'batch_size': 16}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 7:
  l1: 128, l2: 64, lr: 0.000132965214572995, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3048904061317446
**STATS for Epoch 1** : 
Average training loss: 0.3515
Average validation loss: 2.3033
Validation Accuracy: 0.0981
Overfitting: 1.9518
Best model saved at epoch 1 with validation loss: 2.3033
[Epoch 2, Batch 100] loss: 2.3031286573410035
**STATS for Epoch 2** : 
Average training loss: 0.3513
Average validation loss: 2.3017
Validation Accuracy: 0.1056
Overfitting: 1.9503
Best model saved at epoch 2 with validation loss: 2.3017
[Epoch 3, Batch 100] loss: 2.3015728187561035
**STATS for Epoch 3** : 
Average training loss: 0.3509
Average validation loss: 2.2998
Validation Accuracy: 0.1167
Overfitting: 1.9489
Best model saved at epoch 3 with validation loss: 2.2998
[Epoch 4, Batch 100] loss: 2.2997371315956117
**STATS for Epoch 4** : 
Average training loss: 0.3506
Average validation loss: 2.2981
Validation Accuracy: 0.1262
Overfitting: 1.9475
Best model saved at epoch 4 with validation loss: 2.2981
[Epoch 5, Batch 100] loss: 2.29798663854599
**STATS for Epoch 5** : 
Average training loss: 0.3503
Average validation loss: 2.2962
Validation Accuracy: 0.1396
Overfitting: 1.9460
Best model saved at epoch 5 with validation loss: 2.2962
[Epoch 6, Batch 100] loss: 2.296009311676025
**STATS for Epoch 6** : 
Average training loss: 0.3501
Average validation loss: 2.2944
Validation Accuracy: 0.1504
Overfitting: 1.9442
Best model saved at epoch 6 with validation loss: 2.2944
[Epoch 7, Batch 100] loss: 2.2939371275901794
**STATS for Epoch 7** : 
Average training loss: 0.3499
Average validation loss: 2.2924
Validation Accuracy: 0.1601
Overfitting: 1.9426
Best model saved at epoch 7 with validation loss: 2.2924
[Epoch 8, Batch 100] loss: 2.2919771909713744
**STATS for Epoch 8** : 
Average training loss: 0.3494
Average validation loss: 2.2904
Validation Accuracy: 0.1703
Overfitting: 1.9409
Best model saved at epoch 8 with validation loss: 2.2904
[Epoch 9, Batch 100] loss: 2.28975448846817
**STATS for Epoch 9** : 
Average training loss: 0.3491
Average validation loss: 2.2880
Validation Accuracy: 0.1798
Overfitting: 1.9389
Best model saved at epoch 9 with validation loss: 2.2880
[Epoch 10, Batch 100] loss: 2.2873041653633117
**STATS for Epoch 10** : 
Average training loss: 0.3487
Average validation loss: 2.2853
Validation Accuracy: 0.1885
Overfitting: 1.9366
Best model saved at epoch 10 with validation loss: 2.2853
[Epoch 11, Batch 100] loss: 2.2844945096969607
**STATS for Epoch 11** : 
Average training loss: 0.3483
Average validation loss: 2.2823
Validation Accuracy: 0.1995
Overfitting: 1.9340
Best model saved at epoch 11 with validation loss: 2.2823
[Epoch 12, Batch 100] loss: 2.2812827825546265
**STATS for Epoch 12** : 
Average training loss: 0.3478
Average validation loss: 2.2790
Validation Accuracy: 0.2274
Overfitting: 1.9312
Best model saved at epoch 12 with validation loss: 2.2790
[Epoch 13, Batch 100] loss: 2.2775847792625425
**STATS for Epoch 13** : 
Average training loss: 0.3472
Average validation loss: 2.2752
Validation Accuracy: 0.2779
Overfitting: 1.9279
Best model saved at epoch 13 with validation loss: 2.2752
[Epoch 14, Batch 100] loss: 2.2738114762306214
**STATS for Epoch 14** : 
Average training loss: 0.3463
Average validation loss: 2.2708
Validation Accuracy: 0.3404
Overfitting: 1.9245
Best model saved at epoch 14 with validation loss: 2.2708
[Epoch 15, Batch 100] loss: 2.268789618015289
**STATS for Epoch 15** : 
Average training loss: 0.3458
Average validation loss: 2.2656
Validation Accuracy: 0.3952
Overfitting: 1.9198
Best model saved at epoch 15 with validation loss: 2.2656
[Epoch 16, Batch 100] loss: 2.263257668018341
**STATS for Epoch 16** : 
Average training loss: 0.3448
Average validation loss: 2.2595
Validation Accuracy: 0.4396
Overfitting: 1.9147
Best model saved at epoch 16 with validation loss: 2.2595
[Epoch 17, Batch 100] loss: 2.2568949389457704
**STATS for Epoch 17** : 
Average training loss: 0.3435
Average validation loss: 2.2523
Validation Accuracy: 0.4629
Overfitting: 1.9088
Best model saved at epoch 17 with validation loss: 2.2523
[Epoch 18, Batch 100] loss: 2.2487911939620973
**STATS for Epoch 18** : 
Average training loss: 0.3421
Average validation loss: 2.2433
Validation Accuracy: 0.4722
Overfitting: 1.9011
Best model saved at epoch 18 with validation loss: 2.2433
[Epoch 19, Batch 100] loss: 2.238896062374115
**STATS for Epoch 19** : 
Average training loss: 0.3404
Average validation loss: 2.2320
Validation Accuracy: 0.4830
Overfitting: 1.8915
Best model saved at epoch 19 with validation loss: 2.2320
[Epoch 20, Batch 100] loss: 2.226081235408783
**STATS for Epoch 20** : 
Average training loss: 0.3387
Average validation loss: 2.2177
Validation Accuracy: 0.4981
Overfitting: 1.8790
Best model saved at epoch 20 with validation loss: 2.2177
[Epoch 21, Batch 100] loss: 2.2102876830101015
**STATS for Epoch 21** : 
Average training loss: 0.3359
Average validation loss: 2.1995
Validation Accuracy: 0.5187
Overfitting: 1.8637
Best model saved at epoch 21 with validation loss: 2.1995
[Epoch 22, Batch 100] loss: 2.189665651321411
**STATS for Epoch 22** : 
Average training loss: 0.3325
Average validation loss: 2.1758
Validation Accuracy: 0.5392
Overfitting: 1.8433
Best model saved at epoch 22 with validation loss: 2.1758
[Epoch 23, Batch 100] loss: 2.1631316184997558
**STATS for Epoch 23** : 
Average training loss: 0.3274
Average validation loss: 2.1442
Validation Accuracy: 0.5584
Overfitting: 1.8168
Best model saved at epoch 23 with validation loss: 2.1442
[Epoch 24, Batch 100] loss: 2.1264121532440186
**STATS for Epoch 24** : 
Average training loss: 0.3212
Average validation loss: 2.1005
Validation Accuracy: 0.5807
Overfitting: 1.7793
Best model saved at epoch 24 with validation loss: 2.1005
Fold 1 validation loss: 2.1005
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.3041703367233275
**STATS for Epoch 1** : 
Average training loss: 0.3515
Average validation loss: 2.3040
Validation Accuracy: 0.1186
Overfitting: 1.9526
Best model saved at epoch 1 with validation loss: 2.3040
[Epoch 2, Batch 100] loss: 2.302821309566498
**STATS for Epoch 2** : 
Average training loss: 0.3510
Average validation loss: 2.3022
Validation Accuracy: 0.1187
Overfitting: 1.9512
Best model saved at epoch 2 with validation loss: 2.3022
[Epoch 3, Batch 100] loss: 2.3010276699066163
**STATS for Epoch 3** : 
Average training loss: 0.3509
Average validation loss: 2.3006
Validation Accuracy: 0.1182
Overfitting: 1.9497
Best model saved at epoch 3 with validation loss: 2.3006
[Epoch 4, Batch 100] loss: 2.2998210525512697
**STATS for Epoch 4** : 
Average training loss: 0.3503
Average validation loss: 2.2989
Validation Accuracy: 0.1189
Overfitting: 1.9486
Best model saved at epoch 4 with validation loss: 2.2989
[Epoch 5, Batch 100] loss: 2.297955906391144
**STATS for Epoch 5** : 
Average training loss: 0.3502
Average validation loss: 2.2971
Validation Accuracy: 0.1191
Overfitting: 1.9469
Best model saved at epoch 5 with validation loss: 2.2971
[Epoch 6, Batch 100] loss: 2.296164290904999
**STATS for Epoch 6** : 
Average training loss: 0.3499
Average validation loss: 2.2951
Validation Accuracy: 0.1203
Overfitting: 1.9452
Best model saved at epoch 6 with validation loss: 2.2951
[Epoch 7, Batch 100] loss: 2.2940093517303466
**STATS for Epoch 7** : 
Average training loss: 0.3498
Average validation loss: 2.2931
Validation Accuracy: 0.1219
Overfitting: 1.9434
Best model saved at epoch 7 with validation loss: 2.2931
[Epoch 8, Batch 100] loss: 2.2916175055503847
**STATS for Epoch 8** : 
Average training loss: 0.3495
Average validation loss: 2.2905
Validation Accuracy: 0.1243
Overfitting: 1.9410
Best model saved at epoch 8 with validation loss: 2.2905
[Epoch 9, Batch 100] loss: 2.2893352723121643
**STATS for Epoch 9** : 
Average training loss: 0.3491
Average validation loss: 2.2883
Validation Accuracy: 0.1274
Overfitting: 1.9392
Best model saved at epoch 9 with validation loss: 2.2883
[Epoch 10, Batch 100] loss: 2.286766035556793
**STATS for Epoch 10** : 
Average training loss: 0.3487
Average validation loss: 2.2856
Validation Accuracy: 0.1308
Overfitting: 1.9369
Best model saved at epoch 10 with validation loss: 2.2856
[Epoch 11, Batch 100] loss: 2.284000053405762
**STATS for Epoch 11** : 
Average training loss: 0.3483
Average validation loss: 2.2826
Validation Accuracy: 0.1348
Overfitting: 1.9343
Best model saved at epoch 11 with validation loss: 2.2826
[Epoch 12, Batch 100] loss: 2.2810039377212523
**STATS for Epoch 12** : 
Average training loss: 0.3477
Average validation loss: 2.2792
Validation Accuracy: 0.1409
Overfitting: 1.9315
Best model saved at epoch 12 with validation loss: 2.2792
[Epoch 13, Batch 100] loss: 2.2774846720695496
**STATS for Epoch 13** : 
Average training loss: 0.3471
Average validation loss: 2.2755
Validation Accuracy: 0.1491
Overfitting: 1.9284
Best model saved at epoch 13 with validation loss: 2.2755
[Epoch 14, Batch 100] loss: 2.273667016029358
**STATS for Epoch 14** : 
Average training loss: 0.3464
Average validation loss: 2.2713
Validation Accuracy: 0.1652
Overfitting: 1.9249
Best model saved at epoch 14 with validation loss: 2.2713
[Epoch 15, Batch 100] loss: 2.2690070986747743
**STATS for Epoch 15** : 
Average training loss: 0.3459
Average validation loss: 2.2664
Validation Accuracy: 0.1985
Overfitting: 1.9205
Best model saved at epoch 15 with validation loss: 2.2664
[Epoch 16, Batch 100] loss: 2.2638465785980224
**STATS for Epoch 16** : 
Average training loss: 0.3451
Average validation loss: 2.2608
Validation Accuracy: 0.2347
Overfitting: 1.9157
Best model saved at epoch 16 with validation loss: 2.2608
[Epoch 17, Batch 100] loss: 2.258067615032196
**STATS for Epoch 17** : 
Average training loss: 0.3438
Average validation loss: 2.2541
Validation Accuracy: 0.2683
Overfitting: 1.9104
Best model saved at epoch 17 with validation loss: 2.2541
[Epoch 18, Batch 100] loss: 2.2504786038398743
**STATS for Epoch 18** : 
Average training loss: 0.3429
Average validation loss: 2.2461
Validation Accuracy: 0.2938
Overfitting: 1.9032
Best model saved at epoch 18 with validation loss: 2.2461
[Epoch 19, Batch 100] loss: 2.2421024322509764
**STATS for Epoch 19** : 
Average training loss: 0.3410
Average validation loss: 2.2361
Validation Accuracy: 0.3218
Overfitting: 1.8951
Best model saved at epoch 19 with validation loss: 2.2361
[Epoch 20, Batch 100] loss: 2.230997769832611
**STATS for Epoch 20** : 
Average training loss: 0.3393
Average validation loss: 2.2233
Validation Accuracy: 0.3539
Overfitting: 1.8841
Best model saved at epoch 20 with validation loss: 2.2233
[Epoch 21, Batch 100] loss: 2.2172629404067994
**STATS for Epoch 21** : 
Average training loss: 0.3364
Average validation loss: 2.2075
Validation Accuracy: 0.3803
Overfitting: 1.8710
Best model saved at epoch 21 with validation loss: 2.2075
[Epoch 22, Batch 100] loss: 2.199104382991791
**STATS for Epoch 22** : 
Average training loss: 0.3335
Average validation loss: 2.1858
Validation Accuracy: 0.3955
Overfitting: 1.8523
Best model saved at epoch 22 with validation loss: 2.1858
[Epoch 23, Batch 100] loss: 2.1737612771987913
**STATS for Epoch 23** : 
Average training loss: 0.3300
Average validation loss: 2.1570
Validation Accuracy: 0.4000
Overfitting: 1.8269
Best model saved at epoch 23 with validation loss: 2.1570
[Epoch 24, Batch 100] loss: 2.142587881088257
**STATS for Epoch 24** : 
Average training loss: 0.3227
Average validation loss: 2.1172
Validation Accuracy: 0.4006
Overfitting: 1.7945
Best model saved at epoch 24 with validation loss: 2.1172
Fold 2 validation loss: 2.1172
Mean validation loss across all folds for Trial 7 is 2.1089 with trial config:  l1: 128, l2: 64, lr: 0.000132965214572995, batch_size: 256
[I 2024-11-21 18:42:09,615] Trial 6 finished with value: 2.108888026011192 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.000132965214572995, 'batch_size': 256}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 8:
  l1: 128, l2: 128, lr: 0.00672093005015611, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.6958469420671463
[Epoch 1, Batch 200] loss: 0.4733795799314976
[Epoch 1, Batch 300] loss: 0.26718898929655555
[Epoch 1, Batch 400] loss: 0.20211012855172159
[Epoch 1, Batch 500] loss: 0.16752160468138755
[Epoch 1, Batch 600] loss: 0.16097406906075776
[Epoch 1, Batch 700] loss: 0.12691329622641206
[Epoch 1, Batch 800] loss: 0.12188479146454484
[Epoch 1, Batch 900] loss: 0.12761285306420178
**STATS for Epoch 1** : 
Average training loss: 0.0048
Average validation loss: 0.1054
Validation Accuracy: 0.9681
Overfitting: 0.1007
Best model saved at epoch 1 with validation loss: 0.1054
[Epoch 2, Batch 100] loss: 0.0929269498353824
[Epoch 2, Batch 200] loss: 0.0705558859091252
[Epoch 2, Batch 300] loss: 0.08911564695590642
[Epoch 2, Batch 400] loss: 0.09699474205030129
[Epoch 2, Batch 500] loss: 0.07678032520459965
[Epoch 2, Batch 600] loss: 0.08440091992262751
[Epoch 2, Batch 700] loss: 0.07946521375095472
[Epoch 2, Batch 800] loss: 0.08534090143628419
[Epoch 2, Batch 900] loss: 0.0759272127575241
**STATS for Epoch 2** : 
Average training loss: 0.0029
Average validation loss: 0.0806
Validation Accuracy: 0.9760
Overfitting: 0.0777
Best model saved at epoch 2 with validation loss: 0.0806
[Epoch 3, Batch 100] loss: 0.05493796795257367
[Epoch 3, Batch 200] loss: 0.05788580450345762
[Epoch 3, Batch 300] loss: 0.061789541769539935
[Epoch 3, Batch 400] loss: 0.05543900236894842
[Epoch 3, Batch 500] loss: 0.04665897045750171
[Epoch 3, Batch 600] loss: 0.056124833803623916
[Epoch 3, Batch 700] loss: 0.0623151806066744
[Epoch 3, Batch 800] loss: 0.055576853705570105
[Epoch 3, Batch 900] loss: 0.062415009763790295
**STATS for Epoch 3** : 
Average training loss: 0.0020
Average validation loss: 0.0853
Validation Accuracy: 0.9745
Overfitting: 0.0833
[Epoch 4, Batch 100] loss: 0.042725947115686724
[Epoch 4, Batch 200] loss: 0.028445608895854093
[Epoch 4, Batch 300] loss: 0.046296941793116275
[Epoch 4, Batch 400] loss: 0.045296937960665674
[Epoch 4, Batch 500] loss: 0.051503974602674134
[Epoch 4, Batch 600] loss: 0.03338407655479386
[Epoch 4, Batch 700] loss: 0.05887905685172882
[Epoch 4, Batch 800] loss: 0.04691369228356052
[Epoch 4, Batch 900] loss: 0.03948290303931572
**STATS for Epoch 4** : 
Average training loss: 0.0014
Average validation loss: 0.0607
Validation Accuracy: 0.9821
Overfitting: 0.0593
Best model saved at epoch 4 with validation loss: 0.0607
[Epoch 5, Batch 100] loss: 0.03806658465153305
[Epoch 5, Batch 200] loss: 0.037230931471131046
[Epoch 5, Batch 300] loss: 0.04253580630524084
[Epoch 5, Batch 400] loss: 0.03734386436684872
[Epoch 5, Batch 500] loss: 0.0352300769512658
[Epoch 5, Batch 600] loss: 0.03051225330447778
[Epoch 5, Batch 700] loss: 0.03367242138134316
[Epoch 5, Batch 800] loss: 0.024734979429922532
[Epoch 5, Batch 900] loss: 0.03577881608422104
**STATS for Epoch 5** : 
Average training loss: 0.0011
Average validation loss: 0.0541
Validation Accuracy: 0.9850
Overfitting: 0.0530
Best model saved at epoch 5 with validation loss: 0.0541
[Epoch 6, Batch 100] loss: 0.028523906860646094
[Epoch 6, Batch 200] loss: 0.028956703823641874
[Epoch 6, Batch 300] loss: 0.032218629995040826
[Epoch 6, Batch 400] loss: 0.027402472819376272
[Epoch 6, Batch 500] loss: 0.024929468350892423
[Epoch 6, Batch 600] loss: 0.027358501199487364
[Epoch 6, Batch 700] loss: 0.01760728684545029
[Epoch 6, Batch 800] loss: 0.030727558787039016
[Epoch 6, Batch 900] loss: 0.04016317579924362
**STATS for Epoch 6** : 
Average training loss: 0.0014
Average validation loss: 0.0587
Validation Accuracy: 0.9836
Overfitting: 0.0574
[Epoch 7, Batch 100] loss: 0.0204596844977641
[Epoch 7, Batch 200] loss: 0.022698119321939884
[Epoch 7, Batch 300] loss: 0.02030549719274859
[Epoch 7, Batch 400] loss: 0.022596005481973408
[Epoch 7, Batch 500] loss: 0.02251332826890575
[Epoch 7, Batch 600] loss: 0.017926008187641854
[Epoch 7, Batch 700] loss: 0.021839057486358796
[Epoch 7, Batch 800] loss: 0.01706570304457273
[Epoch 7, Batch 900] loss: 0.023036107151492614
**STATS for Epoch 7** : 
Average training loss: 0.0010
Average validation loss: 0.0567
Validation Accuracy: 0.9855
Overfitting: 0.0557
[Epoch 8, Batch 100] loss: 0.024580896848783597
[Epoch 8, Batch 200] loss: 0.014818232608231483
[Epoch 8, Batch 300] loss: 0.014451654007043544
[Epoch 8, Batch 400] loss: 0.024134820769886572
[Epoch 8, Batch 500] loss: 0.023775936628662748
[Epoch 8, Batch 600] loss: 0.018810906212165718
[Epoch 8, Batch 700] loss: 0.024146584754034847
[Epoch 8, Batch 800] loss: 0.013303712451906903
[Epoch 8, Batch 900] loss: 0.011220880354740075
**STATS for Epoch 8** : 
Average training loss: 0.0009
Average validation loss: 0.0791
Validation Accuracy: 0.9805
Overfitting: 0.0782
[Epoch 9, Batch 100] loss: 0.011071997334715889
[Epoch 9, Batch 200] loss: 0.011795780872907925
[Epoch 9, Batch 300] loss: 0.009174162422350491
[Epoch 9, Batch 400] loss: 0.016023589183278092
[Epoch 9, Batch 500] loss: 0.017286647143573645
[Epoch 9, Batch 600] loss: 0.017172641482393374
[Epoch 9, Batch 700] loss: 0.021748912835791997
[Epoch 9, Batch 800] loss: 0.015478353908838472
[Epoch 9, Batch 900] loss: 0.014768968558946653
**STATS for Epoch 9** : 
Average training loss: 0.0006
Average validation loss: 0.0607
Validation Accuracy: 0.9849
Overfitting: 0.0601
[Epoch 10, Batch 100] loss: 0.012369672316781362
[Epoch 10, Batch 200] loss: 0.013249738599788542
[Epoch 10, Batch 300] loss: 0.009826531231519766
[Epoch 10, Batch 400] loss: 0.017597284445491822
[Epoch 10, Batch 500] loss: 0.012616025956594968
[Epoch 10, Batch 600] loss: 0.01423303941191989
[Epoch 10, Batch 700] loss: 0.019758230743318565
[Epoch 10, Batch 800] loss: 0.01383335060236277
[Epoch 10, Batch 900] loss: 0.020793023298983825
**STATS for Epoch 10** : 
Average training loss: 0.0004
Average validation loss: 0.0654
Validation Accuracy: 0.9846
Overfitting: 0.0650
[Epoch 11, Batch 100] loss: 0.014109066819737564
[Epoch 11, Batch 200] loss: 0.016035420512007476
[Epoch 11, Batch 300] loss: 0.017144452461252513
[Epoch 11, Batch 400] loss: 0.018473559108315385
[Epoch 11, Batch 500] loss: 0.010040495464836567
[Epoch 11, Batch 600] loss: 0.009244935486067333
[Epoch 11, Batch 700] loss: 0.003467884769661396
[Epoch 11, Batch 800] loss: 0.013685629556748609
[Epoch 11, Batch 900] loss: 0.01024552330593906
**STATS for Epoch 11** : 
Average training loss: 0.0006
Average validation loss: 0.0652
Validation Accuracy: 0.9847
Overfitting: 0.0646
[Epoch 12, Batch 100] loss: 0.023197140273641708
[Epoch 12, Batch 200] loss: 0.011434778033190015
[Epoch 12, Batch 300] loss: 0.011777687874209733
[Epoch 12, Batch 400] loss: 0.008459712122906922
[Epoch 12, Batch 500] loss: 0.017758035304641453
[Epoch 12, Batch 600] loss: 0.015708871459319197
[Epoch 12, Batch 700] loss: 0.008395340661372756
[Epoch 12, Batch 800] loss: 0.010230994813664438
[Epoch 12, Batch 900] loss: 0.014773737497753245
**STATS for Epoch 12** : 
Average training loss: 0.0006
Average validation loss: 0.0788
Validation Accuracy: 0.9815
Overfitting: 0.0783
[Epoch 13, Batch 100] loss: 0.006204394115547985
[Epoch 13, Batch 200] loss: 0.005121643889449388
[Epoch 13, Batch 300] loss: 0.008665712218262343
[Epoch 13, Batch 400] loss: 0.003433732579082971
[Epoch 13, Batch 500] loss: 0.014147879021699054
[Epoch 13, Batch 600] loss: 0.009410897082016163
[Epoch 13, Batch 700] loss: 0.013791793896734817
[Epoch 13, Batch 800] loss: 0.01389336122199893
[Epoch 13, Batch 900] loss: 0.013022524996094943
**STATS for Epoch 13** : 
Average training loss: 0.0005
Average validation loss: 0.0592
Validation Accuracy: 0.9859
Overfitting: 0.0587
[Epoch 14, Batch 100] loss: 0.010870689103394398
[Epoch 14, Batch 200] loss: 0.005207120570257757
[Epoch 14, Batch 300] loss: 0.002551008023965551
[Epoch 14, Batch 400] loss: 0.0025967066697330666
[Epoch 14, Batch 500] loss: 0.004199988646660131
[Epoch 14, Batch 600] loss: 0.0015107800369423786
[Epoch 14, Batch 700] loss: 0.0037591800759992113
[Epoch 14, Batch 800] loss: 0.002311424053683595
[Epoch 14, Batch 900] loss: 0.0047375745385829756
**STATS for Epoch 14** : 
Average training loss: 0.0002
Average validation loss: 0.0666
Validation Accuracy: 0.9863
Overfitting: 0.0664
[Epoch 15, Batch 100] loss: 0.003312087367617096
[Epoch 15, Batch 200] loss: 0.003403898452925205
[Epoch 15, Batch 300] loss: 0.002197648945086712
[Epoch 15, Batch 400] loss: 0.0019300196729498253
[Epoch 15, Batch 500] loss: 0.002269265813285983
[Epoch 15, Batch 600] loss: 0.0013924160312251388
[Epoch 15, Batch 700] loss: 0.0007949529597044602
[Epoch 15, Batch 800] loss: 0.0016633449955628522
[Epoch 15, Batch 900] loss: 0.003248871320909075
**STATS for Epoch 15** : 
Average training loss: 0.0001
Average validation loss: 0.0653
Validation Accuracy: 0.9869
Overfitting: 0.0652
[Epoch 16, Batch 100] loss: 0.0012627207795736695
[Epoch 16, Batch 200] loss: 0.003365811447572753
[Epoch 16, Batch 300] loss: 0.006826917975086815
[Epoch 16, Batch 400] loss: 0.007547306742562227
[Epoch 16, Batch 500] loss: 0.00983825860933564
[Epoch 16, Batch 600] loss: 0.003177431991322237
[Epoch 16, Batch 700] loss: 0.003926158135608375
[Epoch 16, Batch 800] loss: 0.003363887813960673
[Epoch 16, Batch 900] loss: 0.0025243540485132597
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0656
Validation Accuracy: 0.9876
Overfitting: 0.0655
[Epoch 17, Batch 100] loss: 0.006045992270790066
[Epoch 17, Batch 200] loss: 0.005444237647614045
[Epoch 17, Batch 300] loss: 0.004508788759328866
[Epoch 17, Batch 400] loss: 0.008796901967880615
[Epoch 17, Batch 500] loss: 0.008084180888758966
[Epoch 17, Batch 600] loss: 0.016881998399746863
[Epoch 17, Batch 700] loss: 0.012884010657467115
[Epoch 17, Batch 800] loss: 0.003814707334619243
[Epoch 17, Batch 900] loss: 0.009151208989173938
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0546
Validation Accuracy: 0.9883
Overfitting: 0.0545
[Epoch 18, Batch 100] loss: 0.0021462140093660765
[Epoch 18, Batch 200] loss: 0.00933594459140295
[Epoch 18, Batch 300] loss: 0.002401976397102317
[Epoch 18, Batch 400] loss: 0.006668007747874185
[Epoch 18, Batch 500] loss: 0.004449371182527102
[Epoch 18, Batch 600] loss: 0.002672355361750078
[Epoch 18, Batch 700] loss: 0.005581896780699083
[Epoch 18, Batch 800] loss: 0.003179617306426792
[Epoch 18, Batch 900] loss: 0.002311216464311201
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9881
Overfitting: 0.0608
[Epoch 19, Batch 100] loss: 0.00038751469053067923
[Epoch 19, Batch 200] loss: 0.0008619643796056665
[Epoch 19, Batch 300] loss: 0.001890677236105489
[Epoch 19, Batch 400] loss: 0.0027885817279604905
[Epoch 19, Batch 500] loss: 0.003521591466933387
[Epoch 19, Batch 600] loss: 0.002384836792543865
[Epoch 19, Batch 700] loss: 0.004118823378356069
[Epoch 19, Batch 800] loss: 0.0016597617472103822
[Epoch 19, Batch 900] loss: 0.0027512205646507935
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0641
Validation Accuracy: 0.9875
Overfitting: 0.0640
[Epoch 20, Batch 100] loss: 0.0031485175267663124
[Epoch 20, Batch 200] loss: 0.000601998135738313
[Epoch 20, Batch 300] loss: 0.0008232219745866587
[Epoch 20, Batch 400] loss: 0.00582015822759331
[Epoch 20, Batch 500] loss: 0.002021377157401503
[Epoch 20, Batch 600] loss: 0.0009446604788328727
[Epoch 20, Batch 700] loss: 0.005429309300373006
[Epoch 20, Batch 800] loss: 0.0013514355690142565
[Epoch 20, Batch 900] loss: 0.00046025217083276
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0620
Validation Accuracy: 0.9884
Overfitting: 0.0620
[Epoch 21, Batch 100] loss: 0.00022733022944478875
[Epoch 21, Batch 200] loss: 0.0002310867406059103
[Epoch 21, Batch 300] loss: 0.00030380247728317044
[Epoch 21, Batch 400] loss: 0.0003308043235821145
[Epoch 21, Batch 500] loss: 0.00013377750974825632
[Epoch 21, Batch 600] loss: 0.0006018216771369467
[Epoch 21, Batch 700] loss: 0.0004864447444134612
[Epoch 21, Batch 800] loss: 0.0003135395982382505
[Epoch 21, Batch 900] loss: 0.0016634529799588905
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0627
Validation Accuracy: 0.9885
Overfitting: 0.0627
[Epoch 22, Batch 100] loss: 0.00019963140061406647
[Epoch 22, Batch 200] loss: 0.0002654892652820706
[Epoch 22, Batch 300] loss: 0.00012068058392827652
[Epoch 22, Batch 400] loss: 0.00014704232870961674
[Epoch 22, Batch 500] loss: 9.18210429327182e-05
[Epoch 22, Batch 600] loss: 0.00013536222557675615
[Epoch 22, Batch 700] loss: 0.00013252495591171255
[Epoch 22, Batch 800] loss: 0.0009085645213735916
[Epoch 22, Batch 900] loss: 0.000545467393530501
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0664
Validation Accuracy: 0.9887
Overfitting: 0.0664
[Epoch 23, Batch 100] loss: 9.897242991661948e-05
[Epoch 23, Batch 200] loss: 0.00010102370526055892
[Epoch 23, Batch 300] loss: 9.97500943148566e-05
[Epoch 23, Batch 400] loss: 0.00016421053256987506
[Epoch 23, Batch 500] loss: 0.0001946687380573664
[Epoch 23, Batch 600] loss: 8.053327490486594e-05
[Epoch 23, Batch 700] loss: 0.00026076318596267355
[Epoch 23, Batch 800] loss: 0.00028674072308987775
[Epoch 23, Batch 900] loss: 8.599154495716022e-05
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0656
Validation Accuracy: 0.9887
Overfitting: 0.0656
[Epoch 24, Batch 100] loss: 8.19590601286535e-05
[Epoch 24, Batch 200] loss: 5.678721484514426e-05
[Epoch 24, Batch 300] loss: 0.000209585585040315
[Epoch 24, Batch 400] loss: 6.484450700547484e-05
[Epoch 24, Batch 500] loss: 0.00011911525997856386
[Epoch 24, Batch 600] loss: 6.467497201757766e-05
[Epoch 24, Batch 700] loss: 9.181990469144364e-05
[Epoch 24, Batch 800] loss: 9.260459324691439e-05
[Epoch 24, Batch 900] loss: 0.00015896170396523246
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0667
Validation Accuracy: 0.9887
Overfitting: 0.0667
Fold 1 validation loss: 0.0667
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.0151470351219176
[Epoch 1, Batch 200] loss: 0.6182905913889408
[Epoch 1, Batch 300] loss: 0.3390032347291708
[Epoch 1, Batch 400] loss: 0.22955511264503003
[Epoch 1, Batch 500] loss: 0.19380285311490297
[Epoch 1, Batch 600] loss: 0.16818245563656092
[Epoch 1, Batch 700] loss: 0.1506098399683833
[Epoch 1, Batch 800] loss: 0.15110592203214765
[Epoch 1, Batch 900] loss: 0.11572541119065136
**STATS for Epoch 1** : 
Average training loss: 0.0049
Average validation loss: 0.1122
Validation Accuracy: 0.9653
Overfitting: 0.1073
Best model saved at epoch 1 with validation loss: 0.1122
[Epoch 2, Batch 100] loss: 0.10203709843801334
[Epoch 2, Batch 200] loss: 0.09835493923630566
[Epoch 2, Batch 300] loss: 0.11639790539164097
[Epoch 2, Batch 400] loss: 0.07977801103144884
[Epoch 2, Batch 500] loss: 0.10668700779555365
[Epoch 2, Batch 600] loss: 0.08265665429411456
[Epoch 2, Batch 700] loss: 0.10588087096111849
[Epoch 2, Batch 800] loss: 0.07879976456053556
[Epoch 2, Batch 900] loss: 0.10319709219504147
**STATS for Epoch 2** : 
Average training loss: 0.0028
Average validation loss: 0.0784
Validation Accuracy: 0.9757
Overfitting: 0.0756
Best model saved at epoch 2 with validation loss: 0.0784
[Epoch 3, Batch 100] loss: 0.06776613073481713
[Epoch 3, Batch 200] loss: 0.060808499747654426
[Epoch 3, Batch 300] loss: 0.06352046261890791
[Epoch 3, Batch 400] loss: 0.06262407801346853
[Epoch 3, Batch 500] loss: 0.08251443028682842
[Epoch 3, Batch 600] loss: 0.057129700155928734
[Epoch 3, Batch 700] loss: 0.05685080693743658
[Epoch 3, Batch 800] loss: 0.08555023092660122
[Epoch 3, Batch 900] loss: 0.0602278767246753
**STATS for Epoch 3** : 
Average training loss: 0.0018
Average validation loss: 0.0768
Validation Accuracy: 0.9761
Overfitting: 0.0750
Best model saved at epoch 3 with validation loss: 0.0768
[Epoch 4, Batch 100] loss: 0.04393830112414435
[Epoch 4, Batch 200] loss: 0.05076267989119515
[Epoch 4, Batch 300] loss: 0.053471317799412645
[Epoch 4, Batch 400] loss: 0.04501105033006752
[Epoch 4, Batch 500] loss: 0.049158596462220885
[Epoch 4, Batch 600] loss: 0.04407636924908729
[Epoch 4, Batch 700] loss: 0.05284220383153297
[Epoch 4, Batch 800] loss: 0.04693379688367713
[Epoch 4, Batch 900] loss: 0.05242520931409672
**STATS for Epoch 4** : 
Average training loss: 0.0023
Average validation loss: 0.0611
Validation Accuracy: 0.9820
Overfitting: 0.0588
Best model saved at epoch 4 with validation loss: 0.0611
[Epoch 5, Batch 100] loss: 0.03826060810679337
[Epoch 5, Batch 200] loss: 0.031855850279098374
[Epoch 5, Batch 300] loss: 0.034920562994084324
[Epoch 5, Batch 400] loss: 0.04379228630772559
[Epoch 5, Batch 500] loss: 0.039180702966987155
[Epoch 5, Batch 600] loss: 0.03700458032893948
[Epoch 5, Batch 700] loss: 0.039886811656178904
[Epoch 5, Batch 800] loss: 0.03352335084869992
[Epoch 5, Batch 900] loss: 0.04143232006666949
**STATS for Epoch 5** : 
Average training loss: 0.0012
Average validation loss: 0.0606
Validation Accuracy: 0.9824
Overfitting: 0.0593
Best model saved at epoch 5 with validation loss: 0.0606
[Epoch 6, Batch 100] loss: 0.02485404213453876
[Epoch 6, Batch 200] loss: 0.022494872082897927
[Epoch 6, Batch 300] loss: 0.040185591143090275
[Epoch 6, Batch 400] loss: 0.03179390950128436
[Epoch 6, Batch 500] loss: 0.026264384217502084
[Epoch 6, Batch 600] loss: 0.032034770648315315
[Epoch 6, Batch 700] loss: 0.03215186124623869
[Epoch 6, Batch 800] loss: 0.037840630347491244
[Epoch 6, Batch 900] loss: 0.02881467617346061
**STATS for Epoch 6** : 
Average training loss: 0.0009
Average validation loss: 0.0584
Validation Accuracy: 0.9832
Overfitting: 0.0575
Best model saved at epoch 6 with validation loss: 0.0584
[Epoch 7, Batch 100] loss: 0.029296927506220528
[Epoch 7, Batch 200] loss: 0.018091586988339257
[Epoch 7, Batch 300] loss: 0.012713637410888623
[Epoch 7, Batch 400] loss: 0.022741917115199614
[Epoch 7, Batch 500] loss: 0.030878444270783803
[Epoch 7, Batch 600] loss: 0.03169237870301003
[Epoch 7, Batch 700] loss: 0.030290858330699846
[Epoch 7, Batch 800] loss: 0.027761898706521605
[Epoch 7, Batch 900] loss: 0.04448226751221227
**STATS for Epoch 7** : 
Average training loss: 0.0012
Average validation loss: 0.0590
Validation Accuracy: 0.9833
Overfitting: 0.0578
[Epoch 8, Batch 100] loss: 0.01753785373592109
[Epoch 8, Batch 200] loss: 0.0250132755645609
[Epoch 8, Batch 300] loss: 0.023355272813278136
[Epoch 8, Batch 400] loss: 0.030439157829387112
[Epoch 8, Batch 500] loss: 0.019540970156449476
[Epoch 8, Batch 600] loss: 0.022880506464425708
[Epoch 8, Batch 700] loss: 0.01374762997693324
[Epoch 8, Batch 800] loss: 0.019911193092848407
[Epoch 8, Batch 900] loss: 0.031142176191788166
**STATS for Epoch 8** : 
Average training loss: 0.0008
Average validation loss: 0.0532
Validation Accuracy: 0.9853
Overfitting: 0.0524
Best model saved at epoch 8 with validation loss: 0.0532
[Epoch 9, Batch 100] loss: 0.019871469416757465
[Epoch 9, Batch 200] loss: 0.01221320901713625
[Epoch 9, Batch 300] loss: 0.020224533532491477
[Epoch 9, Batch 400] loss: 0.01712003158598236
[Epoch 9, Batch 500] loss: 0.01822647449294891
[Epoch 9, Batch 600] loss: 0.022054989102434773
[Epoch 9, Batch 700] loss: 0.010193889158376806
[Epoch 9, Batch 800] loss: 0.027235257098436706
[Epoch 9, Batch 900] loss: 0.022835415059671505
**STATS for Epoch 9** : 
Average training loss: 0.0007
Average validation loss: 0.0599
Validation Accuracy: 0.9845
Overfitting: 0.0592
[Epoch 10, Batch 100] loss: 0.01425787296902854
[Epoch 10, Batch 200] loss: 0.01607526494351987
[Epoch 10, Batch 300] loss: 0.009642913390498506
[Epoch 10, Batch 400] loss: 0.013277424751204308
[Epoch 10, Batch 500] loss: 0.018392196281401995
[Epoch 10, Batch 600] loss: 0.01793769631678515
[Epoch 10, Batch 700] loss: 0.016892926114433066
[Epoch 10, Batch 800] loss: 0.026801045650499872
[Epoch 10, Batch 900] loss: 0.01870819315125118
**STATS for Epoch 10** : 
Average training loss: 0.0011
Average validation loss: 0.0525
Validation Accuracy: 0.9856
Overfitting: 0.0514
Best model saved at epoch 10 with validation loss: 0.0525
[Epoch 11, Batch 100] loss: 0.011255133208887855
[Epoch 11, Batch 200] loss: 0.0170173983181121
[Epoch 11, Batch 300] loss: 0.012740755938430083
[Epoch 11, Batch 400] loss: 0.011304523559319933
[Epoch 11, Batch 500] loss: 0.012018757324858598
[Epoch 11, Batch 600] loss: 0.008192164684510317
[Epoch 11, Batch 700] loss: 0.00941024961977746
[Epoch 11, Batch 800] loss: 0.01765438017431734
[Epoch 11, Batch 900] loss: 0.011803141029486142
**STATS for Epoch 11** : 
Average training loss: 0.0003
Average validation loss: 0.0539
Validation Accuracy: 0.9870
Overfitting: 0.0536
[Epoch 12, Batch 100] loss: 0.01534803631981049
[Epoch 12, Batch 200] loss: 0.009854820231739723
[Epoch 12, Batch 300] loss: 0.007160423712734882
[Epoch 12, Batch 400] loss: 0.008873376361348164
[Epoch 12, Batch 500] loss: 0.010391760641359724
[Epoch 12, Batch 600] loss: 0.00937380061715885
[Epoch 12, Batch 700] loss: 0.007623994449822931
[Epoch 12, Batch 800] loss: 0.013152045995566368
[Epoch 12, Batch 900] loss: 0.009777504276653417
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0792
Validation Accuracy: 0.9811
Overfitting: 0.0779
[Epoch 13, Batch 100] loss: 0.01037437765685354
[Epoch 13, Batch 200] loss: 0.006814031776111733
[Epoch 13, Batch 300] loss: 0.0052657236046593425
[Epoch 13, Batch 400] loss: 0.008974578663414832
[Epoch 13, Batch 500] loss: 0.010446590343117351
[Epoch 13, Batch 600] loss: 0.01087559080729534
[Epoch 13, Batch 700] loss: 0.007104292864869422
[Epoch 13, Batch 800] loss: 0.011253702716385306
[Epoch 13, Batch 900] loss: 0.022245178268003655
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0571
Validation Accuracy: 0.9866
Overfitting: 0.0563
[Epoch 14, Batch 100] loss: 0.01902120367662974
[Epoch 14, Batch 200] loss: 0.009657598571848211
[Epoch 14, Batch 300] loss: 0.00718906139540195
[Epoch 14, Batch 400] loss: 0.012508232242480518
[Epoch 14, Batch 500] loss: 0.00987710724054068
[Epoch 14, Batch 600] loss: 0.004346298848874994
[Epoch 14, Batch 700] loss: 0.007127168163556234
[Epoch 14, Batch 800] loss: 0.01281441431702092
[Epoch 14, Batch 900] loss: 0.01033746522077081
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0555
Validation Accuracy: 0.9868
Overfitting: 0.0550
[Epoch 15, Batch 100] loss: 0.0019886072123836127
[Epoch 15, Batch 200] loss: 0.0032800864684872978
[Epoch 15, Batch 300] loss: 0.0022127989030985874
[Epoch 15, Batch 400] loss: 0.0042174613954580305
[Epoch 15, Batch 500] loss: 0.002354642363655728
[Epoch 15, Batch 600] loss: 0.0024164441994469145
[Epoch 15, Batch 700] loss: 0.002827503215111733
[Epoch 15, Batch 800] loss: 0.007259415313484396
[Epoch 15, Batch 900] loss: 0.018307951563232335
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0653
Validation Accuracy: 0.9846
Overfitting: 0.0648
[Epoch 16, Batch 100] loss: 0.0053613862502999154
[Epoch 16, Batch 200] loss: 0.004007937505257715
[Epoch 16, Batch 300] loss: 0.00417669817690907
[Epoch 16, Batch 400] loss: 0.0037105592047890924
[Epoch 16, Batch 500] loss: 0.0032165238653377058
[Epoch 16, Batch 600] loss: 0.001628141053138279
[Epoch 16, Batch 700] loss: 0.007009500768825347
[Epoch 16, Batch 800] loss: 0.005164609847960264
[Epoch 16, Batch 900] loss: 0.009182027260103497
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0646
Validation Accuracy: 0.9861
Overfitting: 0.0645
[Epoch 17, Batch 100] loss: 0.0016788447327564882
[Epoch 17, Batch 200] loss: 0.004680299334595474
[Epoch 17, Batch 300] loss: 0.004003586118680005
[Epoch 17, Batch 400] loss: 0.0034031807930000467
[Epoch 17, Batch 500] loss: 0.002383298647420702
[Epoch 17, Batch 600] loss: 0.004165224826502936
[Epoch 17, Batch 700] loss: 0.007222980466196987
[Epoch 17, Batch 800] loss: 0.011467549821395551
[Epoch 17, Batch 900] loss: 0.005238486830719467
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0673
Validation Accuracy: 0.9858
Overfitting: 0.0669
[Epoch 18, Batch 100] loss: 0.01378343595141132
[Epoch 18, Batch 200] loss: 0.009988291505237043
[Epoch 18, Batch 300] loss: 0.007085838700063221
[Epoch 18, Batch 400] loss: 0.008683227540491317
[Epoch 18, Batch 500] loss: 0.009830558532735267
[Epoch 18, Batch 600] loss: 0.013871901529819297
[Epoch 18, Batch 700] loss: 0.005692949509668779
[Epoch 18, Batch 800] loss: 0.00477912308725081
[Epoch 18, Batch 900] loss: 0.004697104566238295
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0859
Validation Accuracy: 0.9837
Overfitting: 0.0857
[Epoch 19, Batch 100] loss: 0.008768208377064752
[Epoch 19, Batch 200] loss: 0.00427862260006691
[Epoch 19, Batch 300] loss: 0.005879251417094338
[Epoch 19, Batch 400] loss: 0.001548649741203576
[Epoch 19, Batch 500] loss: 0.0019952445309098722
[Epoch 19, Batch 600] loss: 0.004615760140919889
[Epoch 19, Batch 700] loss: 0.003576011386086293
[Epoch 19, Batch 800] loss: 0.004101566427465571
[Epoch 19, Batch 900] loss: 0.004101140139045185
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0625
Validation Accuracy: 0.9883
Overfitting: 0.0625
[Epoch 20, Batch 100] loss: 0.0022426958721460722
[Epoch 20, Batch 200] loss: 0.005520640612020316
[Epoch 20, Batch 300] loss: 0.015160762628787551
[Epoch 20, Batch 400] loss: 0.008139239467998322
[Epoch 20, Batch 500] loss: 0.011662442613020971
[Epoch 20, Batch 600] loss: 0.012898199717331521
[Epoch 20, Batch 700] loss: 0.00539802066242018
[Epoch 20, Batch 800] loss: 0.005409493807368335
[Epoch 20, Batch 900] loss: 0.005482641765966889
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0661
Validation Accuracy: 0.9869
Overfitting: 0.0661
[Epoch 21, Batch 100] loss: 0.006399056170056951
[Epoch 21, Batch 200] loss: 0.003535979795428048
[Epoch 21, Batch 300] loss: 0.003416894403448509
[Epoch 21, Batch 400] loss: 0.004258872636962678
[Epoch 21, Batch 500] loss: 0.0030519734845086076
[Epoch 21, Batch 600] loss: 0.004054179900215331
[Epoch 21, Batch 700] loss: 0.0014285810564330604
[Epoch 21, Batch 800] loss: 0.0016422692002697659
[Epoch 21, Batch 900] loss: 0.0038227534973461273
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0594
Validation Accuracy: 0.9882
Overfitting: 0.0593
[Epoch 22, Batch 100] loss: 0.0007595106136299989
[Epoch 22, Batch 200] loss: 0.0004777925461246113
[Epoch 22, Batch 300] loss: 0.00045766687940584916
[Epoch 22, Batch 400] loss: 0.0002851636653701917
[Epoch 22, Batch 500] loss: 0.000573369587339414
[Epoch 22, Batch 600] loss: 0.0005816617908401156
[Epoch 22, Batch 700] loss: 0.0019155210094490371
[Epoch 22, Batch 800] loss: 0.002070460628360138
[Epoch 22, Batch 900] loss: 0.0017119625933942472
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0759
Validation Accuracy: 0.9854
Overfitting: 0.0758
[Epoch 23, Batch 100] loss: 0.001808575144740203
[Epoch 23, Batch 200] loss: 0.0009916527871389746
[Epoch 23, Batch 300] loss: 0.0012140602140851752
[Epoch 23, Batch 400] loss: 0.0005876947427010748
[Epoch 23, Batch 500] loss: 0.00020569141259608515
[Epoch 23, Batch 600] loss: 0.00033487746142675246
[Epoch 23, Batch 700] loss: 0.004384463050463925
[Epoch 23, Batch 800] loss: 0.0004184948826161161
[Epoch 23, Batch 900] loss: 0.002536071341782673
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0714
Validation Accuracy: 0.9864
Overfitting: 0.0714
[Epoch 24, Batch 100] loss: 0.005702036474670535
[Epoch 24, Batch 200] loss: 0.005169391543803954
[Epoch 24, Batch 300] loss: 0.006292611529588044
[Epoch 24, Batch 400] loss: 0.001974023193475638
[Epoch 24, Batch 500] loss: 0.004041075650956429
[Epoch 24, Batch 600] loss: 0.0014316347242040628
[Epoch 24, Batch 700] loss: 0.0007018143553658973
[Epoch 24, Batch 800] loss: 0.0005590805015155809
[Epoch 24, Batch 900] loss: 0.0014182391266676574
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0641
Validation Accuracy: 0.9887
Overfitting: 0.0641
Fold 2 validation loss: 0.0641
Mean validation loss across all folds for Trial 8 is 0.0654 with trial config:  l1: 128, l2: 128, lr: 0.00672093005015611, batch_size: 32
[I 2024-11-21 18:51:59,219] Trial 7 finished with value: 0.06543528191306722 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.00672093005015611, 'batch_size': 32}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 9:
  l1: 128, l2: 128, lr: 2.8450125275404295e-05, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.308365111351013
[Epoch 1, Batch 200] loss: 2.30391471862793
[Epoch 1, Batch 300] loss: 2.3037172055244444
[Epoch 1, Batch 400] loss: 2.302227485179901
[Epoch 1, Batch 500] loss: 2.3048198199272156
[Epoch 1, Batch 600] loss: 2.3013148069381715
[Epoch 1, Batch 700] loss: 2.3018351721763612
[Epoch 1, Batch 800] loss: 2.299519724845886
[Epoch 1, Batch 900] loss: 2.2992702531814575
[Epoch 1, Batch 1000] loss: 2.2983129739761354
[Epoch 1, Batch 1100] loss: 2.2964181780815123
[Epoch 1, Batch 1200] loss: 2.297048511505127
[Epoch 1, Batch 1300] loss: 2.2930587935447693
[Epoch 1, Batch 1400] loss: 2.292050292491913
[Epoch 1, Batch 1500] loss: 2.292439458370209
[Epoch 1, Batch 1600] loss: 2.291770420074463
[Epoch 1, Batch 1700] loss: 2.290540270805359
[Epoch 1, Batch 1800] loss: 2.2910649824142455
**STATS for Epoch 1** : 
Average training loss: 0.0915
Average validation loss: 2.2880
Validation Accuracy: 0.1629
Overfitting: 2.1965
Best model saved at epoch 1 with validation loss: 2.2880
[Epoch 2, Batch 100] loss: 2.2883967399597167
[Epoch 2, Batch 200] loss: 2.2878431224823
[Epoch 2, Batch 300] loss: 2.284941453933716
[Epoch 2, Batch 400] loss: 2.2837097454071045
[Epoch 2, Batch 500] loss: 2.2828000950813294
[Epoch 2, Batch 600] loss: 2.2805081462860106
[Epoch 2, Batch 700] loss: 2.279940824508667
[Epoch 2, Batch 800] loss: 2.2799797868728637
[Epoch 2, Batch 900] loss: 2.2784283113479615
[Epoch 2, Batch 1000] loss: 2.2767053508758544
[Epoch 2, Batch 1100] loss: 2.2753381085395814
[Epoch 2, Batch 1200] loss: 2.273169481754303
[Epoch 2, Batch 1300] loss: 2.2714224672317505
[Epoch 2, Batch 1400] loss: 2.269375467300415
[Epoch 2, Batch 1500] loss: 2.267234454154968
[Epoch 2, Batch 1600] loss: 2.267025902271271
[Epoch 2, Batch 1700] loss: 2.263804154396057
[Epoch 2, Batch 1800] loss: 2.2650407481193544
**STATS for Epoch 2** : 
Average training loss: 0.0904
Average validation loss: 2.2605
Validation Accuracy: 0.3036
Overfitting: 2.1701
Best model saved at epoch 2 with validation loss: 2.2605
[Epoch 3, Batch 100] loss: 2.258217475414276
[Epoch 3, Batch 200] loss: 2.2582357573509215
[Epoch 3, Batch 300] loss: 2.2548049330711364
[Epoch 3, Batch 400] loss: 2.2497429776191713
[Epoch 3, Batch 500] loss: 2.2496465682983398
[Epoch 3, Batch 600] loss: 2.2502699494361877
[Epoch 3, Batch 700] loss: 2.2460602593421934
[Epoch 3, Batch 800] loss: 2.240718836784363
[Epoch 3, Batch 900] loss: 2.2393055891990663
[Epoch 3, Batch 1000] loss: 2.234797267913818
[Epoch 3, Batch 1100] loss: 2.2314546251297
[Epoch 3, Batch 1200] loss: 2.2312928104400633
[Epoch 3, Batch 1300] loss: 2.227762906551361
[Epoch 3, Batch 1400] loss: 2.2229728269577027
[Epoch 3, Batch 1500] loss: 2.2173172497749327
[Epoch 3, Batch 1600] loss: 2.2157564687728883
[Epoch 3, Batch 1700] loss: 2.20770058631897
[Epoch 3, Batch 1800] loss: 2.205757508277893
**STATS for Epoch 3** : 
Average training loss: 0.0879
Average validation loss: 2.1982
Validation Accuracy: 0.4983
Overfitting: 2.1104
Best model saved at epoch 3 with validation loss: 2.1982
[Epoch 4, Batch 100] loss: 2.1949550795555113
[Epoch 4, Batch 200] loss: 2.1906441116333006
[Epoch 4, Batch 300] loss: 2.184123055934906
[Epoch 4, Batch 400] loss: 2.175659921169281
[Epoch 4, Batch 500] loss: 2.169310109615326
[Epoch 4, Batch 600] loss: 2.161354277133942
[Epoch 4, Batch 700] loss: 2.154790909290314
[Epoch 4, Batch 800] loss: 2.141053535938263
[Epoch 4, Batch 900] loss: 2.1377596831321717
[Epoch 4, Batch 1000] loss: 2.137166028022766
[Epoch 4, Batch 1100] loss: 2.122877609729767
[Epoch 4, Batch 1200] loss: 2.1084647393226623
[Epoch 4, Batch 1300] loss: 2.102577283382416
[Epoch 4, Batch 1400] loss: 2.0876956224441527
[Epoch 4, Batch 1500] loss: 2.0712470746040346
[Epoch 4, Batch 1600] loss: 2.0618855500221254
[Epoch 4, Batch 1700] loss: 2.0470041000843047
[Epoch 4, Batch 1800] loss: 2.0221982192993164
**STATS for Epoch 4** : 
Average training loss: 0.0802
Average validation loss: 2.0015
Validation Accuracy: 0.5872
Overfitting: 1.9213
Best model saved at epoch 4 with validation loss: 2.0015
[Epoch 5, Batch 100] loss: 2.001124529838562
[Epoch 5, Batch 200] loss: 1.961750180721283
[Epoch 5, Batch 300] loss: 1.940479131937027
[Epoch 5, Batch 400] loss: 1.9270023465156556
[Epoch 5, Batch 500] loss: 1.8949563109874725
[Epoch 5, Batch 600] loss: 1.8611722791194916
[Epoch 5, Batch 700] loss: 1.8309998190402985
[Epoch 5, Batch 800] loss: 1.8031137001514435
[Epoch 5, Batch 900] loss: 1.767996152639389
[Epoch 5, Batch 1000] loss: 1.7137819349765777
[Epoch 5, Batch 1100] loss: 1.6851741981506347
[Epoch 5, Batch 1200] loss: 1.6487711620330812
[Epoch 5, Batch 1300] loss: 1.5815054810047149
[Epoch 5, Batch 1400] loss: 1.5443012416362762
[Epoch 5, Batch 1500] loss: 1.5031067824363709
[Epoch 5, Batch 1600] loss: 1.4208142614364625
[Epoch 5, Batch 1700] loss: 1.3856587779521943
[Epoch 5, Batch 1800] loss: 1.3400102400779723
**STATS for Epoch 5** : 
Average training loss: 0.0529
Average validation loss: 1.2857
Validation Accuracy: 0.7377
Overfitting: 1.2327
Best model saved at epoch 5 with validation loss: 1.2857
[Epoch 6, Batch 100] loss: 1.2463660871982574
[Epoch 6, Batch 200] loss: 1.2149494403600694
[Epoch 6, Batch 300] loss: 1.1919876021146774
[Epoch 6, Batch 400] loss: 1.133742055296898
[Epoch 6, Batch 500] loss: 1.0938563340902328
[Epoch 6, Batch 600] loss: 1.0490498703718185
[Epoch 6, Batch 700] loss: 1.011072468161583
[Epoch 6, Batch 800] loss: 0.9896341526508331
[Epoch 6, Batch 900] loss: 0.9678923630714417
[Epoch 6, Batch 1000] loss: 0.9327807480096817
[Epoch 6, Batch 1100] loss: 0.8804500314593315
[Epoch 6, Batch 1200] loss: 0.8819096523523331
[Epoch 6, Batch 1300] loss: 0.8384800985455513
[Epoch 6, Batch 1400] loss: 0.8397611942887306
[Epoch 6, Batch 1500] loss: 0.7829581248760223
[Epoch 6, Batch 1600] loss: 0.7596077105402946
[Epoch 6, Batch 1700] loss: 0.7467531523108483
[Epoch 6, Batch 1800] loss: 0.731762067079544
**STATS for Epoch 6** : 
Average training loss: 0.0291
Average validation loss: 0.7251
Validation Accuracy: 0.8054
Overfitting: 0.6961
Best model saved at epoch 6 with validation loss: 0.7251
[Epoch 7, Batch 100] loss: 0.7673236152529717
[Epoch 7, Batch 200] loss: 0.7173266890645027
[Epoch 7, Batch 300] loss: 0.6898370665311814
[Epoch 7, Batch 400] loss: 0.6661764886975289
[Epoch 7, Batch 500] loss: 0.6680740612745285
[Epoch 7, Batch 600] loss: 0.6233378612995147
[Epoch 7, Batch 700] loss: 0.6343052980303764
[Epoch 7, Batch 800] loss: 0.617698242366314
[Epoch 7, Batch 900] loss: 0.6432476735115051
[Epoch 7, Batch 1000] loss: 0.6257482096552849
[Epoch 7, Batch 1100] loss: 0.606863049864769
[Epoch 7, Batch 1200] loss: 0.5884155356884002
[Epoch 7, Batch 1300] loss: 0.5918181468546391
[Epoch 7, Batch 1400] loss: 0.5919132605195045
[Epoch 7, Batch 1500] loss: 0.5860644146800041
[Epoch 7, Batch 1600] loss: 0.5521191185712815
[Epoch 7, Batch 1700] loss: 0.547761048823595
[Epoch 7, Batch 1800] loss: 0.5900180092453957
**STATS for Epoch 7** : 
Average training loss: 0.0234
Average validation loss: 0.5502
Validation Accuracy: 0.8450
Overfitting: 0.5268
Best model saved at epoch 7 with validation loss: 0.5502
[Epoch 8, Batch 100] loss: 0.6041663201153278
[Epoch 8, Batch 200] loss: 0.5255836614966393
[Epoch 8, Batch 300] loss: 0.5648687645792961
[Epoch 8, Batch 400] loss: 0.5046821866929531
[Epoch 8, Batch 500] loss: 0.5320811641216278
[Epoch 8, Batch 600] loss: 0.4922531518340111
[Epoch 8, Batch 700] loss: 0.5282398825883865
[Epoch 8, Batch 800] loss: 0.54445551648736
[Epoch 8, Batch 900] loss: 0.4957524125277996
[Epoch 8, Batch 1000] loss: 0.5169045630842447
[Epoch 8, Batch 1100] loss: 0.5135239085555077
[Epoch 8, Batch 1200] loss: 0.5240606394410133
[Epoch 8, Batch 1300] loss: 0.47600010842084883
[Epoch 8, Batch 1400] loss: 0.4761910793185234
[Epoch 8, Batch 1500] loss: 0.4736509002745152
[Epoch 8, Batch 1600] loss: 0.4587855853140354
[Epoch 8, Batch 1700] loss: 0.4637859174609184
[Epoch 8, Batch 1800] loss: 0.46262834638357164
**STATS for Epoch 8** : 
Average training loss: 0.0194
Average validation loss: 0.4660
Validation Accuracy: 0.8665
Overfitting: 0.4466
Best model saved at epoch 8 with validation loss: 0.4660
[Epoch 9, Batch 100] loss: 0.453550178706646
[Epoch 9, Batch 200] loss: 0.44909222722053527
[Epoch 9, Batch 300] loss: 0.4660770291090012
[Epoch 9, Batch 400] loss: 0.49901823297142983
[Epoch 9, Batch 500] loss: 0.4492750169336796
[Epoch 9, Batch 600] loss: 0.43746378712356093
[Epoch 9, Batch 700] loss: 0.454223510697484
[Epoch 9, Batch 800] loss: 0.4630985069274902
[Epoch 9, Batch 900] loss: 0.442085340321064
[Epoch 9, Batch 1000] loss: 0.47215884931385516
[Epoch 9, Batch 1100] loss: 0.4422047230601311
[Epoch 9, Batch 1200] loss: 0.43059314019978046
[Epoch 9, Batch 1300] loss: 0.43526105470955373
[Epoch 9, Batch 1400] loss: 0.42048418045043945
[Epoch 9, Batch 1500] loss: 0.41221902146935463
[Epoch 9, Batch 1600] loss: 0.4186472462117672
[Epoch 9, Batch 1700] loss: 0.40461532458662985
[Epoch 9, Batch 1800] loss: 0.45579909682273867
**STATS for Epoch 9** : 
Average training loss: 0.0171
Average validation loss: 0.4155
Validation Accuracy: 0.8797
Overfitting: 0.3985
Best model saved at epoch 9 with validation loss: 0.4155
[Epoch 10, Batch 100] loss: 0.4207370549440384
[Epoch 10, Batch 200] loss: 0.4411248327046633
[Epoch 10, Batch 300] loss: 0.4472953654080629
[Epoch 10, Batch 400] loss: 0.4532358456403017
[Epoch 10, Batch 500] loss: 0.43840372942388056
[Epoch 10, Batch 600] loss: 0.3543496537208557
[Epoch 10, Batch 700] loss: 0.4453536114096642
[Epoch 10, Batch 800] loss: 0.42143257811665535
[Epoch 10, Batch 900] loss: 0.3951881343871355
[Epoch 10, Batch 1000] loss: 0.3926748652011156
[Epoch 10, Batch 1100] loss: 0.3689652918279171
[Epoch 10, Batch 1200] loss: 0.39253322571516036
[Epoch 10, Batch 1300] loss: 0.4153557962924242
[Epoch 10, Batch 1400] loss: 0.3520285126939416
[Epoch 10, Batch 1500] loss: 0.39553423013538125
[Epoch 10, Batch 1600] loss: 0.3665810939669609
[Epoch 10, Batch 1700] loss: 0.4342835060507059
[Epoch 10, Batch 1800] loss: 0.33916143491864204
**STATS for Epoch 10** : 
Average training loss: 0.0145
Average validation loss: 0.3857
Validation Accuracy: 0.8869
Overfitting: 0.3712
Best model saved at epoch 10 with validation loss: 0.3857
[Epoch 11, Batch 100] loss: 0.41309056483209133
[Epoch 11, Batch 200] loss: 0.4019856817275286
[Epoch 11, Batch 300] loss: 0.3641699629276991
[Epoch 11, Batch 400] loss: 0.3763495828956366
[Epoch 11, Batch 500] loss: 0.3627546257525682
[Epoch 11, Batch 600] loss: 0.38548145100474357
[Epoch 11, Batch 700] loss: 0.345518377199769
[Epoch 11, Batch 800] loss: 0.37517945416271686
[Epoch 11, Batch 900] loss: 0.3936588101089001
[Epoch 11, Batch 1000] loss: 0.37561075903475283
[Epoch 11, Batch 1100] loss: 0.3699733082577586
[Epoch 11, Batch 1200] loss: 0.39500886723399165
[Epoch 11, Batch 1300] loss: 0.3266543547809124
[Epoch 11, Batch 1400] loss: 0.3468746585026383
[Epoch 11, Batch 1500] loss: 0.37217505000531675
[Epoch 11, Batch 1600] loss: 0.362093987390399
[Epoch 11, Batch 1700] loss: 0.36278987139463426
[Epoch 11, Batch 1800] loss: 0.38650265365839004
**STATS for Epoch 11** : 
Average training loss: 0.0128
Average validation loss: 0.3573
Validation Accuracy: 0.8962
Overfitting: 0.3445
Best model saved at epoch 11 with validation loss: 0.3573
[Epoch 12, Batch 100] loss: 0.33345039919018743
[Epoch 12, Batch 200] loss: 0.3752719333767891
[Epoch 12, Batch 300] loss: 0.35406853951513767
[Epoch 12, Batch 400] loss: 0.41261209473013877
[Epoch 12, Batch 500] loss: 0.34584247030317783
[Epoch 12, Batch 600] loss: 0.3414034685492516
[Epoch 12, Batch 700] loss: 0.35450249817222357
[Epoch 12, Batch 800] loss: 0.34971370827406645
[Epoch 12, Batch 900] loss: 0.3461077358201146
[Epoch 12, Batch 1000] loss: 0.33794165596365927
[Epoch 12, Batch 1100] loss: 0.34463335171341897
[Epoch 12, Batch 1200] loss: 0.3243549023941159
[Epoch 12, Batch 1300] loss: 0.34349200282245873
[Epoch 12, Batch 1400] loss: 0.3389642111957073
[Epoch 12, Batch 1500] loss: 0.3693873600289226
[Epoch 12, Batch 1600] loss: 0.3233951687067747
[Epoch 12, Batch 1700] loss: 0.3265038459002972
[Epoch 12, Batch 1800] loss: 0.2948363533243537
**STATS for Epoch 12** : 
Average training loss: 0.0140
Average validation loss: 0.3302
Validation Accuracy: 0.9027
Overfitting: 0.3162
Best model saved at epoch 12 with validation loss: 0.3302
[Epoch 13, Batch 100] loss: 0.35371341928839684
[Epoch 13, Batch 200] loss: 0.31869788076728583
[Epoch 13, Batch 300] loss: 0.3324373735487461
[Epoch 13, Batch 400] loss: 0.3487052082642913
[Epoch 13, Batch 500] loss: 0.3254322720319033
[Epoch 13, Batch 600] loss: 0.32149342622607946
[Epoch 13, Batch 700] loss: 0.3472851125895977
[Epoch 13, Batch 800] loss: 0.32734678510576487
[Epoch 13, Batch 900] loss: 0.3241761299967766
[Epoch 13, Batch 1000] loss: 0.32258718349039556
[Epoch 13, Batch 1100] loss: 0.3609519857913256
[Epoch 13, Batch 1200] loss: 0.32445086508989335
[Epoch 13, Batch 1300] loss: 0.2937198753282428
[Epoch 13, Batch 1400] loss: 0.3019066996872425
[Epoch 13, Batch 1500] loss: 0.3094991705566645
[Epoch 13, Batch 1600] loss: 0.3248031421750784
[Epoch 13, Batch 1700] loss: 0.32360542375594376
[Epoch 13, Batch 1800] loss: 0.2946815887466073
**STATS for Epoch 13** : 
Average training loss: 0.0121
Average validation loss: 0.3117
Validation Accuracy: 0.9085
Overfitting: 0.2996
Best model saved at epoch 13 with validation loss: 0.3117
[Epoch 14, Batch 100] loss: 0.3174632842466235
[Epoch 14, Batch 200] loss: 0.3149434696137905
[Epoch 14, Batch 300] loss: 0.28335816986858847
[Epoch 14, Batch 400] loss: 0.33511461421847344
[Epoch 14, Batch 500] loss: 0.2933844953402877
[Epoch 14, Batch 600] loss: 0.3270191227272153
[Epoch 14, Batch 700] loss: 0.2965741817653179
[Epoch 14, Batch 800] loss: 0.31843402069061993
[Epoch 14, Batch 900] loss: 0.31277772326022385
[Epoch 14, Batch 1000] loss: 0.30083637960255144
[Epoch 14, Batch 1100] loss: 0.28559584949165584
[Epoch 14, Batch 1200] loss: 0.30773703011684117
[Epoch 14, Batch 1300] loss: 0.28832269228994845
[Epoch 14, Batch 1400] loss: 0.3029175327345729
[Epoch 14, Batch 1500] loss: 0.30636340495198966
[Epoch 14, Batch 1600] loss: 0.2762187411636114
[Epoch 14, Batch 1700] loss: 0.3034493123739958
[Epoch 14, Batch 1800] loss: 0.31353009650483726
**STATS for Epoch 14** : 
Average training loss: 0.0131
Average validation loss: 0.2962
Validation Accuracy: 0.9123
Overfitting: 0.2831
Best model saved at epoch 14 with validation loss: 0.2962
[Epoch 15, Batch 100] loss: 0.3311791004985571
[Epoch 15, Batch 200] loss: 0.3025343656912446
[Epoch 15, Batch 300] loss: 0.26735613159835336
[Epoch 15, Batch 400] loss: 0.3024248339049518
[Epoch 15, Batch 500] loss: 0.2999045322649181
[Epoch 15, Batch 600] loss: 0.29557244570925834
[Epoch 15, Batch 700] loss: 0.3212144319340587
[Epoch 15, Batch 800] loss: 0.2879751782119274
[Epoch 15, Batch 900] loss: 0.30267681896686555
[Epoch 15, Batch 1000] loss: 0.2633523494005203
[Epoch 15, Batch 1100] loss: 0.30244857285171745
[Epoch 15, Batch 1200] loss: 0.29199093524366615
[Epoch 15, Batch 1300] loss: 0.28487812863662837
[Epoch 15, Batch 1400] loss: 0.2779392696917057
[Epoch 15, Batch 1500] loss: 0.28825967516750095
[Epoch 15, Batch 1600] loss: 0.2648933881148696
[Epoch 15, Batch 1700] loss: 0.286475880574435
[Epoch 15, Batch 1800] loss: 0.2673871484398842
**STATS for Epoch 15** : 
Average training loss: 0.0096
Average validation loss: 0.2790
Validation Accuracy: 0.9165
Overfitting: 0.2693
Best model saved at epoch 15 with validation loss: 0.2790
[Epoch 16, Batch 100] loss: 0.2729284372925758
[Epoch 16, Batch 200] loss: 0.2940836511552334
[Epoch 16, Batch 300] loss: 0.2701083508506417
[Epoch 16, Batch 400] loss: 0.27101862408220767
[Epoch 16, Batch 500] loss: 0.28133081272244453
[Epoch 16, Batch 600] loss: 0.27227993179112675
[Epoch 16, Batch 700] loss: 0.29237025912851095
[Epoch 16, Batch 800] loss: 0.253742709569633
[Epoch 16, Batch 900] loss: 0.24570909338071942
[Epoch 16, Batch 1000] loss: 0.27359384249895813
[Epoch 16, Batch 1100] loss: 0.26808985315263273
[Epoch 16, Batch 1200] loss: 0.2920890388265252
[Epoch 16, Batch 1300] loss: 0.23308281682431697
[Epoch 16, Batch 1400] loss: 0.28877458887174723
[Epoch 16, Batch 1500] loss: 0.2949972877278924
[Epoch 16, Batch 1600] loss: 0.24982390142977237
[Epoch 16, Batch 1700] loss: 0.2986995706893504
[Epoch 16, Batch 1800] loss: 0.2882912661135197
**STATS for Epoch 16** : 
Average training loss: 0.0102
Average validation loss: 0.2665
Validation Accuracy: 0.9199
Overfitting: 0.2563
Best model saved at epoch 16 with validation loss: 0.2665
[Epoch 17, Batch 100] loss: 0.2506778251379728
[Epoch 17, Batch 200] loss: 0.2506882093846798
[Epoch 17, Batch 300] loss: 0.24812728315591812
[Epoch 17, Batch 400] loss: 0.25075782760977744
[Epoch 17, Batch 500] loss: 0.2879906973615289
[Epoch 17, Batch 600] loss: 0.2676805841550231
[Epoch 17, Batch 700] loss: 0.2680636338889599
[Epoch 17, Batch 800] loss: 0.2695237918943167
[Epoch 17, Batch 900] loss: 0.26753116220235823
[Epoch 17, Batch 1000] loss: 0.3029987060464919
[Epoch 17, Batch 1100] loss: 0.2567197259515524
[Epoch 17, Batch 1200] loss: 0.24628993384540082
[Epoch 17, Batch 1300] loss: 0.24320503279566766
[Epoch 17, Batch 1400] loss: 0.28542421616613867
[Epoch 17, Batch 1500] loss: 0.26548136861994864
[Epoch 17, Batch 1600] loss: 0.23723791804164648
[Epoch 17, Batch 1700] loss: 0.22501568533480168
[Epoch 17, Batch 1800] loss: 0.22456092528998853
**STATS for Epoch 17** : 
Average training loss: 0.0131
Average validation loss: 0.2580
Validation Accuracy: 0.9230
Overfitting: 0.2449
Best model saved at epoch 17 with validation loss: 0.2580
[Epoch 18, Batch 100] loss: 0.24921588376164436
[Epoch 18, Batch 200] loss: 0.25656077755615114
[Epoch 18, Batch 300] loss: 0.24351965176872908
[Epoch 18, Batch 400] loss: 0.24667791841551662
[Epoch 18, Batch 500] loss: 0.24061253026127816
[Epoch 18, Batch 600] loss: 0.24008964989334344
[Epoch 18, Batch 700] loss: 0.2378242588043213
[Epoch 18, Batch 800] loss: 0.25805934350937604
[Epoch 18, Batch 900] loss: 0.26831302285194397
[Epoch 18, Batch 1000] loss: 0.22553114963695406
[Epoch 18, Batch 1100] loss: 0.22918353057466448
[Epoch 18, Batch 1200] loss: 0.2776342298835516
[Epoch 18, Batch 1300] loss: 0.24939782336354255
[Epoch 18, Batch 1400] loss: 0.23367686895653605
[Epoch 18, Batch 1500] loss: 0.2575226990133524
[Epoch 18, Batch 1600] loss: 0.2323640127852559
[Epoch 18, Batch 1700] loss: 0.24659205120056868
[Epoch 18, Batch 1800] loss: 0.2755110831558704
**STATS for Epoch 18** : 
Average training loss: 0.0103
Average validation loss: 0.2434
Validation Accuracy: 0.9272
Overfitting: 0.2330
Best model saved at epoch 18 with validation loss: 0.2434
[Epoch 19, Batch 100] loss: 0.23385390385985375
[Epoch 19, Batch 200] loss: 0.23079725535586476
[Epoch 19, Batch 300] loss: 0.2640031683817506
[Epoch 19, Batch 400] loss: 0.21567245690152048
[Epoch 19, Batch 500] loss: 0.22222794061526657
[Epoch 19, Batch 600] loss: 0.22998025473207234
[Epoch 19, Batch 700] loss: 0.2320947614684701
[Epoch 19, Batch 800] loss: 0.24776337059214712
[Epoch 19, Batch 900] loss: 0.24437471628189086
[Epoch 19, Batch 1000] loss: 0.22173874747008085
[Epoch 19, Batch 1100] loss: 0.2471123778820038
[Epoch 19, Batch 1200] loss: 0.23223150914534926
[Epoch 19, Batch 1300] loss: 0.2313859522715211
[Epoch 19, Batch 1400] loss: 0.24057803807780145
[Epoch 19, Batch 1500] loss: 0.23500514537096023
[Epoch 19, Batch 1600] loss: 0.2179868468269706
[Epoch 19, Batch 1700] loss: 0.2582600511051714
[Epoch 19, Batch 1800] loss: 0.2652641996368766
**STATS for Epoch 19** : 
Average training loss: 0.0094
Average validation loss: 0.2378
Validation Accuracy: 0.9302
Overfitting: 0.2283
Best model saved at epoch 19 with validation loss: 0.2378
[Epoch 20, Batch 100] loss: 0.2443978495616466
[Epoch 20, Batch 200] loss: 0.22473826257511972
[Epoch 20, Batch 300] loss: 0.21206969326362013
[Epoch 20, Batch 400] loss: 0.22257353067398072
[Epoch 20, Batch 500] loss: 0.22989928375929594
[Epoch 20, Batch 600] loss: 0.2541725656948984
[Epoch 20, Batch 700] loss: 0.24480900324881077
[Epoch 20, Batch 800] loss: 0.2527388410829008
[Epoch 20, Batch 900] loss: 0.21789747275412083
[Epoch 20, Batch 1000] loss: 0.21862362468615174
[Epoch 20, Batch 1100] loss: 0.22559830388054253
[Epoch 20, Batch 1200] loss: 0.21387309584766626
[Epoch 20, Batch 1300] loss: 0.21412650503218175
[Epoch 20, Batch 1400] loss: 0.24485491028055548
[Epoch 20, Batch 1500] loss: 0.22682266913354396
[Epoch 20, Batch 1600] loss: 0.21102895187214016
[Epoch 20, Batch 1700] loss: 0.20604175284504891
[Epoch 20, Batch 1800] loss: 0.23732693789992482
**STATS for Epoch 20** : 
Average training loss: 0.0092
Average validation loss: 0.2249
Validation Accuracy: 0.9331
Overfitting: 0.2157
Best model saved at epoch 20 with validation loss: 0.2249
[Epoch 21, Batch 100] loss: 0.24264583475887774
[Epoch 21, Batch 200] loss: 0.22497642669826745
[Epoch 21, Batch 300] loss: 0.20101775400340557
[Epoch 21, Batch 400] loss: 0.2116515140235424
[Epoch 21, Batch 500] loss: 0.21948151126503945
[Epoch 21, Batch 600] loss: 0.21837154553271831
[Epoch 21, Batch 700] loss: 0.2198550042975694
[Epoch 21, Batch 800] loss: 0.23192268196493387
[Epoch 21, Batch 900] loss: 0.19340829037129878
[Epoch 21, Batch 1000] loss: 0.2146082948334515
[Epoch 21, Batch 1100] loss: 0.1981366643216461
[Epoch 21, Batch 1200] loss: 0.243763665035367
[Epoch 21, Batch 1300] loss: 0.24329524325206875
[Epoch 21, Batch 1400] loss: 0.21561031652614474
[Epoch 21, Batch 1500] loss: 0.21638023087754846
[Epoch 21, Batch 1600] loss: 0.23824747648090125
[Epoch 21, Batch 1700] loss: 0.17631772082298994
[Epoch 21, Batch 1800] loss: 0.2201426263898611
**STATS for Epoch 21** : 
Average training loss: 0.0087
Average validation loss: 0.2230
Validation Accuracy: 0.9327
Overfitting: 0.2143
Best model saved at epoch 21 with validation loss: 0.2230
[Epoch 22, Batch 100] loss: 0.2370133857242763
[Epoch 22, Batch 200] loss: 0.18989774856716393
[Epoch 22, Batch 300] loss: 0.203212411403656
[Epoch 22, Batch 400] loss: 0.19196775501593946
[Epoch 22, Batch 500] loss: 0.21527925208210946
[Epoch 22, Batch 600] loss: 0.21065371425822377
[Epoch 22, Batch 700] loss: 0.21964467959478498
[Epoch 22, Batch 800] loss: 0.2004538520332426
[Epoch 22, Batch 900] loss: 0.21346783937886357
[Epoch 22, Batch 1000] loss: 0.21603634094819427
[Epoch 22, Batch 1100] loss: 0.2357418491691351
[Epoch 22, Batch 1200] loss: 0.2487316664494574
[Epoch 22, Batch 1300] loss: 0.20574218820780515
[Epoch 22, Batch 1400] loss: 0.26956930588930844
[Epoch 22, Batch 1500] loss: 0.17911562859080732
[Epoch 22, Batch 1600] loss: 0.1998415594547987
[Epoch 22, Batch 1700] loss: 0.1959772370941937
[Epoch 22, Batch 1800] loss: 0.17256551563739778
**STATS for Epoch 22** : 
Average training loss: 0.0072
Average validation loss: 0.2060
Validation Accuracy: 0.9386
Overfitting: 0.1988
Best model saved at epoch 22 with validation loss: 0.2060
[Epoch 23, Batch 100] loss: 0.20193449448794126
[Epoch 23, Batch 200] loss: 0.21282374592497943
[Epoch 23, Batch 300] loss: 0.19982821543700993
[Epoch 23, Batch 400] loss: 0.18303675853647292
[Epoch 23, Batch 500] loss: 0.1758166967984289
[Epoch 23, Batch 600] loss: 0.19086434900760652
[Epoch 23, Batch 700] loss: 0.19951145673170687
[Epoch 23, Batch 800] loss: 0.2233980729058385
[Epoch 23, Batch 900] loss: 0.22184072113595904
[Epoch 23, Batch 1000] loss: 0.2065685726888478
[Epoch 23, Batch 1100] loss: 0.1927194642648101
[Epoch 23, Batch 1200] loss: 0.1958917852398008
[Epoch 23, Batch 1300] loss: 0.2086586689390242
[Epoch 23, Batch 1400] loss: 0.1995603453554213
[Epoch 23, Batch 1500] loss: 0.20740076794289053
[Epoch 23, Batch 1600] loss: 0.20351135103031992
[Epoch 23, Batch 1700] loss: 0.2158599143847823
[Epoch 23, Batch 1800] loss: 0.2074142500385642
**STATS for Epoch 23** : 
Average training loss: 0.0078
Average validation loss: 0.2014
Validation Accuracy: 0.9400
Overfitting: 0.1936
Best model saved at epoch 23 with validation loss: 0.2014
[Epoch 24, Batch 100] loss: 0.1941191112715751
[Epoch 24, Batch 200] loss: 0.19980928779579699
[Epoch 24, Batch 300] loss: 0.1987006143014878
[Epoch 24, Batch 400] loss: 0.22697343830019234
[Epoch 24, Batch 500] loss: 0.19941587544977665
[Epoch 24, Batch 600] loss: 0.2073663303628564
[Epoch 24, Batch 700] loss: 0.16609477607533335
[Epoch 24, Batch 800] loss: 0.19528524750843645
[Epoch 24, Batch 900] loss: 0.20196246288716793
[Epoch 24, Batch 1000] loss: 0.16916924238204956
[Epoch 24, Batch 1100] loss: 0.18137534823268653
[Epoch 24, Batch 1200] loss: 0.2278118338622153
[Epoch 24, Batch 1300] loss: 0.18035990742966532
[Epoch 24, Batch 1400] loss: 0.1839891531318426
[Epoch 24, Batch 1500] loss: 0.16365673998370767
[Epoch 24, Batch 1600] loss: 0.188796481853351
[Epoch 24, Batch 1700] loss: 0.18805016015656292
[Epoch 24, Batch 1800] loss: 0.20743899440392852
**STATS for Epoch 24** : 
Average training loss: 0.0088
Average validation loss: 0.1988
Validation Accuracy: 0.9396
Overfitting: 0.1900
Best model saved at epoch 24 with validation loss: 0.1988
Fold 1 validation loss: 0.1988
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.3035486578941344
[Epoch 1, Batch 200] loss: 2.3035550546646117
[Epoch 1, Batch 300] loss: 2.3019610977172853
[Epoch 1, Batch 400] loss: 2.300804622173309
[Epoch 1, Batch 500] loss: 2.3025175642967226
[Epoch 1, Batch 600] loss: 2.298707354068756
[Epoch 1, Batch 700] loss: 2.298861973285675
[Epoch 1, Batch 800] loss: 2.29991352558136
[Epoch 1, Batch 900] loss: 2.3012952256202697
[Epoch 1, Batch 1000] loss: 2.2995032453536988
[Epoch 1, Batch 1100] loss: 2.300833067893982
[Epoch 1, Batch 1200] loss: 2.2989448142051696
[Epoch 1, Batch 1300] loss: 2.299377257823944
[Epoch 1, Batch 1400] loss: 2.2981227612495423
[Epoch 1, Batch 1500] loss: 2.299280490875244
[Epoch 1, Batch 1600] loss: 2.297584342956543
[Epoch 1, Batch 1700] loss: 2.298079240322113
[Epoch 1, Batch 1800] loss: 2.29928079366684
**STATS for Epoch 1** : 
Average training loss: 0.0918
Average validation loss: 2.2968
Validation Accuracy: 0.0966
Overfitting: 2.2050
Best model saved at epoch 1 with validation loss: 2.2968
[Epoch 2, Batch 100] loss: 2.2971639037132263
[Epoch 2, Batch 200] loss: 2.296874487400055
[Epoch 2, Batch 300] loss: 2.2963401055336
[Epoch 2, Batch 400] loss: 2.29549489736557
[Epoch 2, Batch 500] loss: 2.295992727279663
[Epoch 2, Batch 600] loss: 2.296135272979736
[Epoch 2, Batch 700] loss: 2.294521760940552
[Epoch 2, Batch 800] loss: 2.2932864737510683
[Epoch 2, Batch 900] loss: 2.2962273788452148
[Epoch 2, Batch 1000] loss: 2.2924311208724975
[Epoch 2, Batch 1100] loss: 2.2928743290901186
[Epoch 2, Batch 1200] loss: 2.2929428124427798
[Epoch 2, Batch 1300] loss: 2.2916824650764465
[Epoch 2, Batch 1400] loss: 2.291970613002777
[Epoch 2, Batch 1500] loss: 2.291902630329132
[Epoch 2, Batch 1600] loss: 2.2902310514450073
[Epoch 2, Batch 1700] loss: 2.2910985779762267
[Epoch 2, Batch 1800] loss: 2.291105816364288
**STATS for Epoch 2** : 
Average training loss: 0.0916
Average validation loss: 2.2901
Validation Accuracy: 0.1833
Overfitting: 2.1984
Best model saved at epoch 2 with validation loss: 2.2901
[Epoch 3, Batch 100] loss: 2.2907817649841307
[Epoch 3, Batch 200] loss: 2.2913404941558837
[Epoch 3, Batch 300] loss: 2.2865845799446105
[Epoch 3, Batch 400] loss: 2.2880937838554383
[Epoch 3, Batch 500] loss: 2.2870502042770386
[Epoch 3, Batch 600] loss: 2.2881110215187075
[Epoch 3, Batch 700] loss: 2.2875727438926696
[Epoch 3, Batch 800] loss: 2.2863353085517883
[Epoch 3, Batch 900] loss: 2.2872108936309816
[Epoch 3, Batch 1000] loss: 2.2871103715896606
[Epoch 3, Batch 1100] loss: 2.283662962913513
[Epoch 3, Batch 1200] loss: 2.2835632395744323
[Epoch 3, Batch 1300] loss: 2.283720428943634
[Epoch 3, Batch 1400] loss: 2.283887348175049
[Epoch 3, Batch 1500] loss: 2.2839098525047303
[Epoch 3, Batch 1600] loss: 2.2855157089233398
[Epoch 3, Batch 1700] loss: 2.280975923538208
[Epoch 3, Batch 1800] loss: 2.2836626076698305
**STATS for Epoch 3** : 
Average training loss: 0.0913
Average validation loss: 2.2811
Validation Accuracy: 0.2187
Overfitting: 2.1898
Best model saved at epoch 3 with validation loss: 2.2811
[Epoch 4, Batch 100] loss: 2.280121946334839
[Epoch 4, Batch 200] loss: 2.283041229248047
[Epoch 4, Batch 300] loss: 2.279590094089508
[Epoch 4, Batch 400] loss: 2.280902578830719
[Epoch 4, Batch 500] loss: 2.278853642940521
[Epoch 4, Batch 600] loss: 2.2800178027153013
[Epoch 4, Batch 700] loss: 2.277050025463104
[Epoch 4, Batch 800] loss: 2.2756092977523803
[Epoch 4, Batch 900] loss: 2.275275099277496
[Epoch 4, Batch 1000] loss: 2.274509062767029
[Epoch 4, Batch 1100] loss: 2.273218550682068
[Epoch 4, Batch 1200] loss: 2.2728883743286135
[Epoch 4, Batch 1300] loss: 2.2708934640884397
[Epoch 4, Batch 1400] loss: 2.2704460644721984
[Epoch 4, Batch 1500] loss: 2.271572060585022
[Epoch 4, Batch 1600] loss: 2.267440402507782
[Epoch 4, Batch 1700] loss: 2.2670677161216735
[Epoch 4, Batch 1800] loss: 2.2661983156204224
**STATS for Epoch 4** : 
Average training loss: 0.0906
Average validation loss: 2.2662
Validation Accuracy: 0.2849
Overfitting: 2.1756
Best model saved at epoch 4 with validation loss: 2.2662
[Epoch 5, Batch 100] loss: 2.266823787689209
[Epoch 5, Batch 200] loss: 2.261849443912506
[Epoch 5, Batch 300] loss: 2.2656408023834227
[Epoch 5, Batch 400] loss: 2.2624269199371336
[Epoch 5, Batch 500] loss: 2.2624223589897157
[Epoch 5, Batch 600] loss: 2.257677676677704
[Epoch 5, Batch 700] loss: 2.2618361043930055
[Epoch 5, Batch 800] loss: 2.2557607913017272
[Epoch 5, Batch 900] loss: 2.253077862262726
[Epoch 5, Batch 1000] loss: 2.253394002914429
[Epoch 5, Batch 1100] loss: 2.251082081794739
[Epoch 5, Batch 1200] loss: 2.251690013408661
[Epoch 5, Batch 1300] loss: 2.2524615025520323
[Epoch 5, Batch 1400] loss: 2.2437858986854553
[Epoch 5, Batch 1500] loss: 2.2414997673034667
[Epoch 5, Batch 1600] loss: 2.2432306432724
[Epoch 5, Batch 1700] loss: 2.2410904216766356
[Epoch 5, Batch 1800] loss: 2.2379784560203553
**STATS for Epoch 5** : 
Average training loss: 0.0893
Average validation loss: 2.2355
Validation Accuracy: 0.4003
Overfitting: 2.1462
Best model saved at epoch 5 with validation loss: 2.2355
[Epoch 6, Batch 100] loss: 2.2326331615447996
[Epoch 6, Batch 200] loss: 2.230770020484924
[Epoch 6, Batch 300] loss: 2.2297335147857664
[Epoch 6, Batch 400] loss: 2.2265511989593505
[Epoch 6, Batch 500] loss: 2.224955453872681
[Epoch 6, Batch 600] loss: 2.22035658121109
[Epoch 6, Batch 700] loss: 2.219442346096039
[Epoch 6, Batch 800] loss: 2.214480276107788
[Epoch 6, Batch 900] loss: 2.209195227622986
[Epoch 6, Batch 1000] loss: 2.2018735885620115
[Epoch 6, Batch 1100] loss: 2.1993637824058534
[Epoch 6, Batch 1200] loss: 2.1930471587181093
[Epoch 6, Batch 1300] loss: 2.185674161911011
[Epoch 6, Batch 1400] loss: 2.182367510795593
[Epoch 6, Batch 1500] loss: 2.1838525557518005
[Epoch 6, Batch 1600] loss: 2.176236050128937
[Epoch 6, Batch 1700] loss: 2.172969191074371
[Epoch 6, Batch 1800] loss: 2.1666718482971192
**STATS for Epoch 6** : 
Average training loss: 0.0861
Average validation loss: 2.1542
Validation Accuracy: 0.4903
Overfitting: 2.0680
Best model saved at epoch 6 with validation loss: 2.1542
[Epoch 7, Batch 100] loss: 2.144693019390106
[Epoch 7, Batch 200] loss: 2.143776204586029
[Epoch 7, Batch 300] loss: 2.1309419965744016
[Epoch 7, Batch 400] loss: 2.12658668756485
[Epoch 7, Batch 500] loss: 2.1076769435405733
[Epoch 7, Batch 600] loss: 2.109977812767029
[Epoch 7, Batch 700] loss: 2.093743259906769
[Epoch 7, Batch 800] loss: 2.0800582253932953
[Epoch 7, Batch 900] loss: 2.067039984464645
[Epoch 7, Batch 1000] loss: 2.052373933792114
[Epoch 7, Batch 1100] loss: 2.0342847323417663
[Epoch 7, Batch 1200] loss: 2.024504724740982
[Epoch 7, Batch 1300] loss: 1.9930608546733857
[Epoch 7, Batch 1400] loss: 1.9774935603141786
[Epoch 7, Batch 1500] loss: 1.9502509558200836
[Epoch 7, Batch 1600] loss: 1.9310500276088716
[Epoch 7, Batch 1700] loss: 1.9119155859947206
[Epoch 7, Batch 1800] loss: 1.8870971035957336
**STATS for Epoch 7** : 
Average training loss: 0.0746
Average validation loss: 1.8454
Validation Accuracy: 0.5680
Overfitting: 1.7708
Best model saved at epoch 7 with validation loss: 1.8454
[Epoch 8, Batch 100] loss: 1.8308874905109405
[Epoch 8, Batch 200] loss: 1.7853996098041534
[Epoch 8, Batch 300] loss: 1.7497218573093414
[Epoch 8, Batch 400] loss: 1.7179250776767732
[Epoch 8, Batch 500] loss: 1.678216713666916
[Epoch 8, Batch 600] loss: 1.645051041841507
[Epoch 8, Batch 700] loss: 1.6140702688694
[Epoch 8, Batch 800] loss: 1.5499870085716247
[Epoch 8, Batch 900] loss: 1.5059837877750397
[Epoch 8, Batch 1000] loss: 1.4731317901611327
[Epoch 8, Batch 1100] loss: 1.4405376243591308
[Epoch 8, Batch 1200] loss: 1.395363221168518
[Epoch 8, Batch 1300] loss: 1.3003026682138443
[Epoch 8, Batch 1400] loss: 1.3077466636896133
[Epoch 8, Batch 1500] loss: 1.2342323929071426
[Epoch 8, Batch 1600] loss: 1.2134524875879287
[Epoch 8, Batch 1700] loss: 1.1753944039344788
[Epoch 8, Batch 1800] loss: 1.1304457545280457
**STATS for Epoch 8** : 
Average training loss: 0.0436
Average validation loss: 1.0827
Validation Accuracy: 0.7314
Overfitting: 1.0391
Best model saved at epoch 8 with validation loss: 1.0827
[Epoch 9, Batch 100] loss: 1.0383650273084641
[Epoch 9, Batch 200] loss: 0.9986209869384766
[Epoch 9, Batch 300] loss: 0.9994332808256149
[Epoch 9, Batch 400] loss: 0.9558430564403534
[Epoch 9, Batch 500] loss: 0.9639914602041244
[Epoch 9, Batch 600] loss: 0.9136100077629089
[Epoch 9, Batch 700] loss: 0.8931509017944336
[Epoch 9, Batch 800] loss: 0.8805656963586808
[Epoch 9, Batch 900] loss: 0.8788854178786277
[Epoch 9, Batch 1000] loss: 0.8239180248975754
[Epoch 9, Batch 1100] loss: 0.8213610550761223
[Epoch 9, Batch 1200] loss: 0.7653897535800934
[Epoch 9, Batch 1300] loss: 0.7900162950158119
[Epoch 9, Batch 1400] loss: 0.763707640171051
[Epoch 9, Batch 1500] loss: 0.7518830314278603
[Epoch 9, Batch 1600] loss: 0.739400038421154
[Epoch 9, Batch 1700] loss: 0.732609526515007
[Epoch 9, Batch 1800] loss: 0.6937420055270195
**STATS for Epoch 9** : 
Average training loss: 0.0287
Average validation loss: 0.7065
Validation Accuracy: 0.7964
Overfitting: 0.6777
Best model saved at epoch 9 with validation loss: 0.7065
[Epoch 10, Batch 100] loss: 0.6622342319786548
[Epoch 10, Batch 200] loss: 0.6731172022223473
[Epoch 10, Batch 300] loss: 0.6428037598729134
[Epoch 10, Batch 400] loss: 0.673817355632782
[Epoch 10, Batch 500] loss: 0.6379381988942623
[Epoch 10, Batch 600] loss: 0.655960753262043
[Epoch 10, Batch 700] loss: 0.6448753321170807
[Epoch 10, Batch 800] loss: 0.6472669869661332
[Epoch 10, Batch 900] loss: 0.6001262545585633
[Epoch 10, Batch 1000] loss: 0.6000931967794895
[Epoch 10, Batch 1100] loss: 0.5947450323402882
[Epoch 10, Batch 1200] loss: 0.5961445888876915
[Epoch 10, Batch 1300] loss: 0.5858410555124283
[Epoch 10, Batch 1400] loss: 0.645041061937809
[Epoch 10, Batch 1500] loss: 0.5998175130784511
[Epoch 10, Batch 1600] loss: 0.6080239191651344
[Epoch 10, Batch 1700] loss: 0.5983612942695617
[Epoch 10, Batch 1800] loss: 0.5875507551431656
**STATS for Epoch 10** : 
Average training loss: 0.0232
Average validation loss: 0.5771
Validation Accuracy: 0.8282
Overfitting: 0.5539
Best model saved at epoch 10 with validation loss: 0.5771
[Epoch 11, Batch 100] loss: 0.5678367178142071
[Epoch 11, Batch 200] loss: 0.5624951642751693
[Epoch 11, Batch 300] loss: 0.5869919529557228
[Epoch 11, Batch 400] loss: 0.5058769825100898
[Epoch 11, Batch 500] loss: 0.5350222247838974
[Epoch 11, Batch 600] loss: 0.5499062763154506
[Epoch 11, Batch 700] loss: 0.5434375147521496
[Epoch 11, Batch 800] loss: 0.4988143017888069
[Epoch 11, Batch 900] loss: 0.5174661061167717
[Epoch 11, Batch 1000] loss: 0.5626485906541348
[Epoch 11, Batch 1100] loss: 0.5171821705996991
[Epoch 11, Batch 1200] loss: 0.5227037590742111
[Epoch 11, Batch 1300] loss: 0.5348940522968769
[Epoch 11, Batch 1400] loss: 0.5187006641924381
[Epoch 11, Batch 1500] loss: 0.5247369468212127
[Epoch 11, Batch 1600] loss: 0.5505948381125927
[Epoch 11, Batch 1700] loss: 0.4963965305685997
[Epoch 11, Batch 1800] loss: 0.46695058353245256
**STATS for Epoch 11** : 
Average training loss: 0.0220
Average validation loss: 0.5079
Validation Accuracy: 0.8462
Overfitting: 0.4859
Best model saved at epoch 11 with validation loss: 0.5079
[Epoch 12, Batch 100] loss: 0.510319820791483
[Epoch 12, Batch 200] loss: 0.4908681707084179
[Epoch 12, Batch 300] loss: 0.5026180782914161
[Epoch 12, Batch 400] loss: 0.514504896402359
[Epoch 12, Batch 500] loss: 0.5328514775633812
[Epoch 12, Batch 600] loss: 0.45645199686288834
[Epoch 12, Batch 700] loss: 0.4474025445431471
[Epoch 12, Batch 800] loss: 0.4584401980787516
[Epoch 12, Batch 900] loss: 0.4819104677438736
[Epoch 12, Batch 1000] loss: 0.4716795787215233
[Epoch 12, Batch 1100] loss: 0.4615319694578648
[Epoch 12, Batch 1200] loss: 0.4872904520481825
[Epoch 12, Batch 1300] loss: 0.4467557840794325
[Epoch 12, Batch 1400] loss: 0.4906627540290356
[Epoch 12, Batch 1500] loss: 0.47451346695423124
[Epoch 12, Batch 1600] loss: 0.4624762786179781
[Epoch 12, Batch 1700] loss: 0.46877617575228214
[Epoch 12, Batch 1800] loss: 0.4478124067187309
**STATS for Epoch 12** : 
Average training loss: 0.0173
Average validation loss: 0.4662
Validation Accuracy: 0.8582
Overfitting: 0.4489
Best model saved at epoch 12 with validation loss: 0.4662
[Epoch 13, Batch 100] loss: 0.44327847003936766
[Epoch 13, Batch 200] loss: 0.45302063032984735
[Epoch 13, Batch 300] loss: 0.4792701728641987
[Epoch 13, Batch 400] loss: 0.4587202224135399
[Epoch 13, Batch 500] loss: 0.42572910845279693
[Epoch 13, Batch 600] loss: 0.44900739178061483
[Epoch 13, Batch 700] loss: 0.43832857377827167
[Epoch 13, Batch 800] loss: 0.4652180753648281
[Epoch 13, Batch 900] loss: 0.4396227143704891
[Epoch 13, Batch 1000] loss: 0.42165365256369114
[Epoch 13, Batch 1100] loss: 0.4138151036202908
[Epoch 13, Batch 1200] loss: 0.4420672859996557
[Epoch 13, Batch 1300] loss: 0.4209886083006859
[Epoch 13, Batch 1400] loss: 0.39075253672897814
[Epoch 13, Batch 1500] loss: 0.44923485547304154
[Epoch 13, Batch 1600] loss: 0.4014192907512188
[Epoch 13, Batch 1700] loss: 0.3955415013432503
[Epoch 13, Batch 1800] loss: 0.4106536214053631
**STATS for Epoch 13** : 
Average training loss: 0.0198
Average validation loss: 0.4293
Validation Accuracy: 0.8706
Overfitting: 0.4095
Best model saved at epoch 13 with validation loss: 0.4293
[Epoch 14, Batch 100] loss: 0.4368487532436848
[Epoch 14, Batch 200] loss: 0.42163926593959333
[Epoch 14, Batch 300] loss: 0.3972931644320488
[Epoch 14, Batch 400] loss: 0.3954452433437109
[Epoch 14, Batch 500] loss: 0.41685258388519286
[Epoch 14, Batch 600] loss: 0.4069952803105116
[Epoch 14, Batch 700] loss: 0.4069837512820959
[Epoch 14, Batch 800] loss: 0.4216270200908184
[Epoch 14, Batch 900] loss: 0.3851685272529721
[Epoch 14, Batch 1000] loss: 0.38456526182591916
[Epoch 14, Batch 1100] loss: 0.42570002518594263
[Epoch 14, Batch 1200] loss: 0.39361514791846275
[Epoch 14, Batch 1300] loss: 0.3789083603769541
[Epoch 14, Batch 1400] loss: 0.4257535191625357
[Epoch 14, Batch 1500] loss: 0.3837879650294781
[Epoch 14, Batch 1600] loss: 0.3940530230849981
[Epoch 14, Batch 1700] loss: 0.40544322967529295
[Epoch 14, Batch 1800] loss: 0.3589788231998682
**STATS for Epoch 14** : 
Average training loss: 0.0163
Average validation loss: 0.4017
Validation Accuracy: 0.8780
Overfitting: 0.3854
Best model saved at epoch 14 with validation loss: 0.4017
[Epoch 15, Batch 100] loss: 0.3821896342933178
[Epoch 15, Batch 200] loss: 0.4346694846451282
[Epoch 15, Batch 300] loss: 0.38357725098729134
[Epoch 15, Batch 400] loss: 0.3879909896105528
[Epoch 15, Batch 500] loss: 0.37564993418753145
[Epoch 15, Batch 600] loss: 0.34957079097628596
[Epoch 15, Batch 700] loss: 0.37910093531012534
[Epoch 15, Batch 800] loss: 0.3999402091652155
[Epoch 15, Batch 900] loss: 0.35324347235262393
[Epoch 15, Batch 1000] loss: 0.3818383488804102
[Epoch 15, Batch 1100] loss: 0.3811531588435173
[Epoch 15, Batch 1200] loss: 0.36768543846905233
[Epoch 15, Batch 1300] loss: 0.3658774323388934
[Epoch 15, Batch 1400] loss: 0.3687628956139088
[Epoch 15, Batch 1500] loss: 0.3661431473121047
[Epoch 15, Batch 1600] loss: 0.34317395608872175
[Epoch 15, Batch 1700] loss: 0.38555003989487885
[Epoch 15, Batch 1800] loss: 0.36363330513238906
**STATS for Epoch 15** : 
Average training loss: 0.0143
Average validation loss: 0.3772
Validation Accuracy: 0.8840
Overfitting: 0.3629
Best model saved at epoch 15 with validation loss: 0.3772
[Epoch 16, Batch 100] loss: 0.40474620170891284
[Epoch 16, Batch 200] loss: 0.3520762465149164
[Epoch 16, Batch 300] loss: 0.374988958388567
[Epoch 16, Batch 400] loss: 0.35925198785960677
[Epoch 16, Batch 500] loss: 0.34949684478342535
[Epoch 16, Batch 600] loss: 0.3658319095522165
[Epoch 16, Batch 700] loss: 0.313221441321075
[Epoch 16, Batch 800] loss: 0.3618070155754685
[Epoch 16, Batch 900] loss: 0.31969287067651747
[Epoch 16, Batch 1000] loss: 0.37111426047980783
[Epoch 16, Batch 1100] loss: 0.34371358051896095
[Epoch 16, Batch 1200] loss: 0.36264823205769064
[Epoch 16, Batch 1300] loss: 0.346790617108345
[Epoch 16, Batch 1400] loss: 0.3688397301360965
[Epoch 16, Batch 1500] loss: 0.36520597375929353
[Epoch 16, Batch 1600] loss: 0.3241326518729329
[Epoch 16, Batch 1700] loss: 0.32346490152180196
[Epoch 16, Batch 1800] loss: 0.3124648133665323
**STATS for Epoch 16** : 
Average training loss: 0.0144
Average validation loss: 0.3565
Validation Accuracy: 0.8928
Overfitting: 0.3421
Best model saved at epoch 16 with validation loss: 0.3565
[Epoch 17, Batch 100] loss: 0.345661462508142
[Epoch 17, Batch 200] loss: 0.3702032367885113
[Epoch 17, Batch 300] loss: 0.3586458822339773
[Epoch 17, Batch 400] loss: 0.34597742013633254
[Epoch 17, Batch 500] loss: 0.3133413676917553
[Epoch 17, Batch 600] loss: 0.29991348944604396
[Epoch 17, Batch 700] loss: 0.3538690320402384
[Epoch 17, Batch 800] loss: 0.31382325153797863
[Epoch 17, Batch 900] loss: 0.3177228113263845
[Epoch 17, Batch 1000] loss: 0.34335525281727314
[Epoch 17, Batch 1100] loss: 0.3224255222082138
[Epoch 17, Batch 1200] loss: 0.3320289721339941
[Epoch 17, Batch 1300] loss: 0.3021757693961263
[Epoch 17, Batch 1400] loss: 0.3411740317195654
[Epoch 17, Batch 1500] loss: 0.2845989536494017
[Epoch 17, Batch 1600] loss: 0.36601856831461194
[Epoch 17, Batch 1700] loss: 0.3240562480315566
[Epoch 17, Batch 1800] loss: 0.33388196863234043
**STATS for Epoch 17** : 
Average training loss: 0.0123
Average validation loss: 0.3301
Validation Accuracy: 0.9001
Overfitting: 0.3178
Best model saved at epoch 17 with validation loss: 0.3301
[Epoch 18, Batch 100] loss: 0.288862277045846
[Epoch 18, Batch 200] loss: 0.307585923448205
[Epoch 18, Batch 300] loss: 0.3309545804187655
[Epoch 18, Batch 400] loss: 0.314813789576292
[Epoch 18, Batch 500] loss: 0.3032493991777301
[Epoch 18, Batch 600] loss: 0.3007130217179656
[Epoch 18, Batch 700] loss: 0.28600376576185227
[Epoch 18, Batch 800] loss: 0.2923445781692863
[Epoch 18, Batch 900] loss: 0.3206350741907954
[Epoch 18, Batch 1000] loss: 0.32967602416872976
[Epoch 18, Batch 1100] loss: 0.3042715806514025
[Epoch 18, Batch 1200] loss: 0.34986221190541983
[Epoch 18, Batch 1300] loss: 0.31724751118570566
[Epoch 18, Batch 1400] loss: 0.35480556420981885
[Epoch 18, Batch 1500] loss: 0.307240273989737
[Epoch 18, Batch 1600] loss: 0.33441270135343076
[Epoch 18, Batch 1700] loss: 0.32563723292201757
[Epoch 18, Batch 1800] loss: 0.27716923225671053
**STATS for Epoch 18** : 
Average training loss: 0.0116
Average validation loss: 0.3153
Validation Accuracy: 0.9060
Overfitting: 0.3037
Best model saved at epoch 18 with validation loss: 0.3153
[Epoch 19, Batch 100] loss: 0.2945170292258263
[Epoch 19, Batch 200] loss: 0.3082205244153738
[Epoch 19, Batch 300] loss: 0.33420181579887864
[Epoch 19, Batch 400] loss: 0.32674206875264644
[Epoch 19, Batch 500] loss: 0.2884764538891613
[Epoch 19, Batch 600] loss: 0.3239897606894374
[Epoch 19, Batch 700] loss: 0.3030398944020271
[Epoch 19, Batch 800] loss: 0.2778680841997266
[Epoch 19, Batch 900] loss: 0.3018659096956253
[Epoch 19, Batch 1000] loss: 0.3102284204959869
[Epoch 19, Batch 1100] loss: 0.28143750671297313
[Epoch 19, Batch 1200] loss: 0.2717950815707445
[Epoch 19, Batch 1300] loss: 0.31584211606532336
[Epoch 19, Batch 1400] loss: 0.28921562554314734
[Epoch 19, Batch 1500] loss: 0.25395441457629203
[Epoch 19, Batch 1600] loss: 0.29116988435387614
[Epoch 19, Batch 1700] loss: 0.2990830525755882
[Epoch 19, Batch 1800] loss: 0.2818659598752856
**STATS for Epoch 19** : 
Average training loss: 0.0110
Average validation loss: 0.2989
Validation Accuracy: 0.9102
Overfitting: 0.2879
Best model saved at epoch 19 with validation loss: 0.2989
[Epoch 20, Batch 100] loss: 0.2847743519023061
[Epoch 20, Batch 200] loss: 0.29842303492128847
[Epoch 20, Batch 300] loss: 0.291124166212976
[Epoch 20, Batch 400] loss: 0.26513815008103847
[Epoch 20, Batch 500] loss: 0.2463229651376605
[Epoch 20, Batch 600] loss: 0.2681670533120632
[Epoch 20, Batch 700] loss: 0.2648972173407674
[Epoch 20, Batch 800] loss: 0.3003298565000296
[Epoch 20, Batch 900] loss: 0.27773051887750627
[Epoch 20, Batch 1000] loss: 0.28344514617696404
[Epoch 20, Batch 1100] loss: 0.27819713708013294
[Epoch 20, Batch 1200] loss: 0.3025504440255463
[Epoch 20, Batch 1300] loss: 0.29327731907367705
[Epoch 20, Batch 1400] loss: 0.2734360871091485
[Epoch 20, Batch 1500] loss: 0.30525095224380494
[Epoch 20, Batch 1600] loss: 0.29807299729436637
[Epoch 20, Batch 1700] loss: 0.2608255406655371
[Epoch 20, Batch 1800] loss: 0.30408462807536124
**STATS for Epoch 20** : 
Average training loss: 0.0103
Average validation loss: 0.2868
Validation Accuracy: 0.9144
Overfitting: 0.2765
Best model saved at epoch 20 with validation loss: 0.2868
[Epoch 21, Batch 100] loss: 0.27358787128701806
[Epoch 21, Batch 200] loss: 0.26742231599986555
[Epoch 21, Batch 300] loss: 0.2875274667143822
[Epoch 21, Batch 400] loss: 0.28767804216593507
[Epoch 21, Batch 500] loss: 0.25699160747230054
[Epoch 21, Batch 600] loss: 0.2607411391288042
[Epoch 21, Batch 700] loss: 0.279104735981673
[Epoch 21, Batch 800] loss: 0.2629146225005388
[Epoch 21, Batch 900] loss: 0.2840136827901006
[Epoch 21, Batch 1000] loss: 0.249425865188241
[Epoch 21, Batch 1100] loss: 0.29184395080432296
[Epoch 21, Batch 1200] loss: 0.23964770760387183
[Epoch 21, Batch 1300] loss: 0.288619057610631
[Epoch 21, Batch 1400] loss: 0.2334712715819478
[Epoch 21, Batch 1500] loss: 0.2855691036954522
[Epoch 21, Batch 1600] loss: 0.25485622495412824
[Epoch 21, Batch 1700] loss: 0.25140608739107845
[Epoch 21, Batch 1800] loss: 0.2459961698576808
**STATS for Epoch 21** : 
Average training loss: 0.0123
Average validation loss: 0.2739
Validation Accuracy: 0.9184
Overfitting: 0.2617
Best model saved at epoch 21 with validation loss: 0.2739
[Epoch 22, Batch 100] loss: 0.30465261355042456
[Epoch 22, Batch 200] loss: 0.255021103695035
[Epoch 22, Batch 300] loss: 0.26104626145213844
[Epoch 22, Batch 400] loss: 0.2664077354595065
[Epoch 22, Batch 500] loss: 0.25916475875303147
[Epoch 22, Batch 600] loss: 0.2623213676922023
[Epoch 22, Batch 700] loss: 0.2606950307637453
[Epoch 22, Batch 800] loss: 0.22246955022215842
[Epoch 22, Batch 900] loss: 0.24912199102342128
[Epoch 22, Batch 1000] loss: 0.26205616870895027
[Epoch 22, Batch 1100] loss: 0.22432592984288932
[Epoch 22, Batch 1200] loss: 0.25214178242720664
[Epoch 22, Batch 1300] loss: 0.25631995908915994
[Epoch 22, Batch 1400] loss: 0.25350728606805206
[Epoch 22, Batch 1500] loss: 0.26176342826336624
[Epoch 22, Batch 1600] loss: 0.2722677531838417
[Epoch 22, Batch 1700] loss: 0.2496791661437601
[Epoch 22, Batch 1800] loss: 0.2565671380236745
**STATS for Epoch 22** : 
Average training loss: 0.0097
Average validation loss: 0.2592
Validation Accuracy: 0.9218
Overfitting: 0.2496
Best model saved at epoch 22 with validation loss: 0.2592
[Epoch 23, Batch 100] loss: 0.2586378508247435
[Epoch 23, Batch 200] loss: 0.2545146523788571
[Epoch 23, Batch 300] loss: 0.27718928465619685
[Epoch 23, Batch 400] loss: 0.26763416059315204
[Epoch 23, Batch 500] loss: 0.2399401320144534
[Epoch 23, Batch 600] loss: 0.22844120282679797
[Epoch 23, Batch 700] loss: 0.23289813557639719
[Epoch 23, Batch 800] loss: 0.24872966041788458
[Epoch 23, Batch 900] loss: 0.2452162322960794
[Epoch 23, Batch 1000] loss: 0.268793416172266
[Epoch 23, Batch 1100] loss: 0.22189090691506863
[Epoch 23, Batch 1200] loss: 0.2437482201680541
[Epoch 23, Batch 1300] loss: 0.22364348456263541
[Epoch 23, Batch 1400] loss: 0.24643959444016217
[Epoch 23, Batch 1500] loss: 0.25619609756395223
[Epoch 23, Batch 1600] loss: 0.24444349478930236
[Epoch 23, Batch 1700] loss: 0.24092728950083256
[Epoch 23, Batch 1800] loss: 0.237347614467144
**STATS for Epoch 23** : 
Average training loss: 0.0089
Average validation loss: 0.2496
Validation Accuracy: 0.9235
Overfitting: 0.2407
Best model saved at epoch 23 with validation loss: 0.2496
[Epoch 24, Batch 100] loss: 0.21346242813393473
[Epoch 24, Batch 200] loss: 0.23441022776067258
[Epoch 24, Batch 300] loss: 0.24394104555249213
[Epoch 24, Batch 400] loss: 0.25075672458857295
[Epoch 24, Batch 500] loss: 0.2248619206994772
[Epoch 24, Batch 600] loss: 0.26534932512789966
[Epoch 24, Batch 700] loss: 0.21788538379594682
[Epoch 24, Batch 800] loss: 0.2476028675213456
[Epoch 24, Batch 900] loss: 0.24472210949286818
[Epoch 24, Batch 1000] loss: 0.19986855274066329
[Epoch 24, Batch 1100] loss: 0.24072623528540135
[Epoch 24, Batch 1200] loss: 0.210306436419487
[Epoch 24, Batch 1300] loss: 0.23968225829303264
[Epoch 24, Batch 1400] loss: 0.24643891287967562
[Epoch 24, Batch 1500] loss: 0.23843657787889241
[Epoch 24, Batch 1600] loss: 0.2300148006528616
[Epoch 24, Batch 1700] loss: 0.2494606870226562
[Epoch 24, Batch 1800] loss: 0.23832791928201913
**STATS for Epoch 24** : 
Average training loss: 0.0090
Average validation loss: 0.2406
Validation Accuracy: 0.9271
Overfitting: 0.2316
Best model saved at epoch 24 with validation loss: 0.2406
Fold 2 validation loss: 0.2406
Mean validation loss across all folds for Trial 9 is 0.2197 with trial config:  l1: 128, l2: 128, lr: 2.8450125275404295e-05, batch_size: 16
[I 2024-11-21 19:03:25,704] Trial 8 finished with value: 0.21970059694213173 and parameters: {'l1': 128, 'l2': 128, 'lr': 2.8450125275404295e-05, 'batch_size': 16}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 10:
  l1: 256, l2: 128, lr: 0.007255685482622854, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.9460510271787643
[Epoch 1, Batch 200] loss: 0.38854805670678616
[Epoch 1, Batch 300] loss: 0.19995481438934803
[Epoch 1, Batch 400] loss: 0.16716066222637893
**STATS for Epoch 1** : 
Average training loss: 0.0230
Average validation loss: 0.1433
Validation Accuracy: 0.9531
Overfitting: 0.1204
Best model saved at epoch 1 with validation loss: 0.1433
[Epoch 2, Batch 100] loss: 0.11608489486388862
[Epoch 2, Batch 200] loss: 0.1052474819123745
[Epoch 2, Batch 300] loss: 0.0966093536792323
[Epoch 2, Batch 400] loss: 0.10690885566174985
**STATS for Epoch 2** : 
Average training loss: 0.0133
Average validation loss: 0.0830
Validation Accuracy: 0.9740
Overfitting: 0.0697
Best model saved at epoch 2 with validation loss: 0.0830
[Epoch 3, Batch 100] loss: 0.06733637324534357
[Epoch 3, Batch 200] loss: 0.08437035613693297
[Epoch 3, Batch 300] loss: 0.072991589945741
[Epoch 3, Batch 400] loss: 0.06620288634672761
**STATS for Epoch 3** : 
Average training loss: 0.0107
Average validation loss: 0.0751
Validation Accuracy: 0.9765
Overfitting: 0.0645
Best model saved at epoch 3 with validation loss: 0.0751
[Epoch 4, Batch 100] loss: 0.05886337563861162
[Epoch 4, Batch 200] loss: 0.04861024283105508
[Epoch 4, Batch 300] loss: 0.055118965227156876
[Epoch 4, Batch 400] loss: 0.06173933433834464
**STATS for Epoch 4** : 
Average training loss: 0.0066
Average validation loss: 0.0840
Validation Accuracy: 0.9744
Overfitting: 0.0774
[Epoch 5, Batch 100] loss: 0.0439085833216086
[Epoch 5, Batch 200] loss: 0.043117413911968466
[Epoch 5, Batch 300] loss: 0.044916753884172066
[Epoch 5, Batch 400] loss: 0.04979775060666725
**STATS for Epoch 5** : 
Average training loss: 0.0060
Average validation loss: 0.0638
Validation Accuracy: 0.9800
Overfitting: 0.0578
Best model saved at epoch 5 with validation loss: 0.0638
[Epoch 6, Batch 100] loss: 0.029159113231580703
[Epoch 6, Batch 200] loss: 0.03582138669095002
[Epoch 6, Batch 300] loss: 0.040818290275055916
[Epoch 6, Batch 400] loss: 0.03422840951243415
**STATS for Epoch 6** : 
Average training loss: 0.0052
Average validation loss: 0.0652
Validation Accuracy: 0.9807
Overfitting: 0.0600
[Epoch 7, Batch 100] loss: 0.026995002781040965
[Epoch 7, Batch 200] loss: 0.02668022216297686
[Epoch 7, Batch 300] loss: 0.02110178903385531
[Epoch 7, Batch 400] loss: 0.03222171148750931
**STATS for Epoch 7** : 
Average training loss: 0.0043
Average validation loss: 0.0576
Validation Accuracy: 0.9830
Overfitting: 0.0533
Best model saved at epoch 7 with validation loss: 0.0576
[Epoch 8, Batch 100] loss: 0.02831165954063181
[Epoch 8, Batch 200] loss: 0.01891350914782379
[Epoch 8, Batch 300] loss: 0.030846821325831116
[Epoch 8, Batch 400] loss: 0.02753789080423303
**STATS for Epoch 8** : 
Average training loss: 0.0030
Average validation loss: 0.0693
Validation Accuracy: 0.9801
Overfitting: 0.0663
[Epoch 9, Batch 100] loss: 0.019477999351511243
[Epoch 9, Batch 200] loss: 0.02135969591297908
[Epoch 9, Batch 300] loss: 0.02324957392294891
[Epoch 9, Batch 400] loss: 0.01984744925808627
**STATS for Epoch 9** : 
Average training loss: 0.0028
Average validation loss: 0.0617
Validation Accuracy: 0.9828
Overfitting: 0.0589
[Epoch 10, Batch 100] loss: 0.018315958030871115
[Epoch 10, Batch 200] loss: 0.016992038278258407
[Epoch 10, Batch 300] loss: 0.015668082411866634
[Epoch 10, Batch 400] loss: 0.021362651157542132
**STATS for Epoch 10** : 
Average training loss: 0.0021
Average validation loss: 0.0578
Validation Accuracy: 0.9844
Overfitting: 0.0557
[Epoch 11, Batch 100] loss: 0.013299207294476218
[Epoch 11, Batch 200] loss: 0.010457336740219035
[Epoch 11, Batch 300] loss: 0.014322896805970231
[Epoch 11, Batch 400] loss: 0.014243116149300477
**STATS for Epoch 11** : 
Average training loss: 0.0022
Average validation loss: 0.0636
Validation Accuracy: 0.9842
Overfitting: 0.0614
[Epoch 12, Batch 100] loss: 0.010849360864813206
[Epoch 12, Batch 200] loss: 0.006939191762648988
[Epoch 12, Batch 300] loss: 0.014059231334540527
[Epoch 12, Batch 400] loss: 0.007676966633516713
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0682
Validation Accuracy: 0.9838
Overfitting: 0.0668
[Epoch 13, Batch 100] loss: 0.008738031265820609
[Epoch 13, Batch 200] loss: 0.005477695213048719
[Epoch 13, Batch 300] loss: 0.00805604263106943
[Epoch 13, Batch 400] loss: 0.006603539350289793
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0708
Validation Accuracy: 0.9841
Overfitting: 0.0700
[Epoch 14, Batch 100] loss: 0.0039454258525802284
[Epoch 14, Batch 200] loss: 0.012486667670254975
[Epoch 14, Batch 300] loss: 0.006765369041459053
[Epoch 14, Batch 400] loss: 0.012253750227464479
**STATS for Epoch 14** : 
Average training loss: 0.0019
Average validation loss: 0.0593
Validation Accuracy: 0.9851
Overfitting: 0.0575
[Epoch 15, Batch 100] loss: 0.007401524632805376
[Epoch 15, Batch 200] loss: 0.011413133728638059
[Epoch 15, Batch 300] loss: 0.008221160124594461
[Epoch 15, Batch 400] loss: 0.005227421190866153
**STATS for Epoch 15** : 
Average training loss: 0.0012
Average validation loss: 0.0627
Validation Accuracy: 0.9858
Overfitting: 0.0615
[Epoch 16, Batch 100] loss: 0.00591636830016796
[Epoch 16, Batch 200] loss: 0.011565672166616423
[Epoch 16, Batch 300] loss: 0.00813190922657668
[Epoch 16, Batch 400] loss: 0.0033829850324764267
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0615
Validation Accuracy: 0.9861
Overfitting: 0.0609
[Epoch 17, Batch 100] loss: 0.002144906736118628
[Epoch 17, Batch 200] loss: 0.00302865211999233
[Epoch 17, Batch 300] loss: 0.007703005286275584
[Epoch 17, Batch 400] loss: 0.002505005086222809
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0642
Validation Accuracy: 0.9861
Overfitting: 0.0639
[Epoch 18, Batch 100] loss: 0.00461903037976299
[Epoch 18, Batch 200] loss: 0.0017068524632850312
[Epoch 18, Batch 300] loss: 0.0020261120746431515
[Epoch 18, Batch 400] loss: 0.002652706185804163
**STATS for Epoch 18** : 
Average training loss: 0.0005
Average validation loss: 0.0630
Validation Accuracy: 0.9871
Overfitting: 0.0625
[Epoch 19, Batch 100] loss: 0.001265580541721647
[Epoch 19, Batch 200] loss: 0.001799238928088016
[Epoch 19, Batch 300] loss: 0.0010766414823694958
[Epoch 19, Batch 400] loss: 0.0008634232864369551
**STATS for Epoch 19** : 
Average training loss: 0.0009
Average validation loss: 0.0673
Validation Accuracy: 0.9856
Overfitting: 0.0664
[Epoch 20, Batch 100] loss: 0.001090902095702404
[Epoch 20, Batch 200] loss: 0.0008316036508767866
[Epoch 20, Batch 300] loss: 0.0004509264626676668
[Epoch 20, Batch 400] loss: 0.0008749973418389345
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0636
Validation Accuracy: 0.9876
Overfitting: 0.0635
[Epoch 21, Batch 100] loss: 0.0002252151276513814
[Epoch 21, Batch 200] loss: 0.0004725658624533935
[Epoch 21, Batch 300] loss: 0.0003108230558837022
[Epoch 21, Batch 400] loss: 0.0003630827819188198
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9883
Overfitting: 0.0636
[Epoch 22, Batch 100] loss: 0.00017267484684907686
[Epoch 22, Batch 200] loss: 0.0003568333454018102
[Epoch 22, Batch 300] loss: 0.00022326489588976982
[Epoch 22, Batch 400] loss: 0.00019663042165802836
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0655
Validation Accuracy: 0.9879
Overfitting: 0.0655
[Epoch 23, Batch 100] loss: 0.00014345610923669483
[Epoch 23, Batch 200] loss: 0.00017673008797601143
[Epoch 23, Batch 300] loss: 0.0001306850959753092
[Epoch 23, Batch 400] loss: 0.00025916138638422127
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9879
Overfitting: 0.0665
[Epoch 24, Batch 100] loss: 0.00015712971398215814
[Epoch 24, Batch 200] loss: 0.00014504361957961008
[Epoch 24, Batch 300] loss: 0.0001344415640369334
[Epoch 24, Batch 400] loss: 0.00020355151876174204
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0671
Validation Accuracy: 0.9880
Overfitting: 0.0671
Fold 1 validation loss: 0.0671
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.5060923820734025
[Epoch 1, Batch 200] loss: 0.3436022765934467
[Epoch 1, Batch 300] loss: 0.18844238437712194
[Epoch 1, Batch 400] loss: 0.15362402675673364
**STATS for Epoch 1** : 
Average training loss: 0.0203
Average validation loss: 0.1276
Validation Accuracy: 0.9617
Overfitting: 0.1073
Best model saved at epoch 1 with validation loss: 0.1276
[Epoch 2, Batch 100] loss: 0.09747967313975096
[Epoch 2, Batch 200] loss: 0.09137057536747306
[Epoch 2, Batch 300] loss: 0.10041991468518972
[Epoch 2, Batch 400] loss: 0.0861522924201563
**STATS for Epoch 2** : 
Average training loss: 0.0139
Average validation loss: 0.1178
Validation Accuracy: 0.9642
Overfitting: 0.1038
Best model saved at epoch 2 with validation loss: 0.1178
[Epoch 3, Batch 100] loss: 0.059736983007751404
[Epoch 3, Batch 200] loss: 0.06469375574029983
[Epoch 3, Batch 300] loss: 0.05568911392241716
[Epoch 3, Batch 400] loss: 0.0678413721686229
**STATS for Epoch 3** : 
Average training loss: 0.0117
Average validation loss: 0.0630
Validation Accuracy: 0.9808
Overfitting: 0.0513
Best model saved at epoch 3 with validation loss: 0.0630
[Epoch 4, Batch 100] loss: 0.04446336491964757
[Epoch 4, Batch 200] loss: 0.042758156957570466
[Epoch 4, Batch 300] loss: 0.04516014903783798
[Epoch 4, Batch 400] loss: 0.05030807224102318
**STATS for Epoch 4** : 
Average training loss: 0.0078
Average validation loss: 0.0622
Validation Accuracy: 0.9814
Overfitting: 0.0544
Best model saved at epoch 4 with validation loss: 0.0622
[Epoch 5, Batch 100] loss: 0.038846051571890715
[Epoch 5, Batch 200] loss: 0.036692507355473934
[Epoch 5, Batch 300] loss: 0.04206475317827426
[Epoch 5, Batch 400] loss: 0.03503182499553077
**STATS for Epoch 5** : 
Average training loss: 0.0060
Average validation loss: 0.0539
Validation Accuracy: 0.9827
Overfitting: 0.0480
Best model saved at epoch 5 with validation loss: 0.0539
[Epoch 6, Batch 100] loss: 0.028524952885927633
[Epoch 6, Batch 200] loss: 0.03693712944746949
[Epoch 6, Batch 300] loss: 0.036447330124210565
[Epoch 6, Batch 400] loss: 0.03343761757481843
**STATS for Epoch 6** : 
Average training loss: 0.0037
Average validation loss: 0.0496
Validation Accuracy: 0.9859
Overfitting: 0.0459
Best model saved at epoch 6 with validation loss: 0.0496
[Epoch 7, Batch 100] loss: 0.027851608663331716
[Epoch 7, Batch 200] loss: 0.029587152749300002
[Epoch 7, Batch 300] loss: 0.030678228209726512
[Epoch 7, Batch 400] loss: 0.028281816067756153
**STATS for Epoch 7** : 
Average training loss: 0.0037
Average validation loss: 0.0563
Validation Accuracy: 0.9842
Overfitting: 0.0526
[Epoch 8, Batch 100] loss: 0.022697444271179847
[Epoch 8, Batch 200] loss: 0.01657357345917262
[Epoch 8, Batch 300] loss: 0.02744043269805843
[Epoch 8, Batch 400] loss: 0.018660636703134514
**STATS for Epoch 8** : 
Average training loss: 0.0036
Average validation loss: 0.0530
Validation Accuracy: 0.9852
Overfitting: 0.0494
[Epoch 9, Batch 100] loss: 0.01780161796952598
[Epoch 9, Batch 200] loss: 0.018763390294043347
[Epoch 9, Batch 300] loss: 0.015937592021073213
[Epoch 9, Batch 400] loss: 0.017400913594756276
**STATS for Epoch 9** : 
Average training loss: 0.0036
Average validation loss: 0.0610
Validation Accuracy: 0.9832
Overfitting: 0.0575
[Epoch 10, Batch 100] loss: 0.021240085644531063
[Epoch 10, Batch 200] loss: 0.017124179060338064
[Epoch 10, Batch 300] loss: 0.014948795719828923
[Epoch 10, Batch 400] loss: 0.017892108143423683
**STATS for Epoch 10** : 
Average training loss: 0.0019
Average validation loss: 0.0493
Validation Accuracy: 0.9867
Overfitting: 0.0474
Best model saved at epoch 10 with validation loss: 0.0493
[Epoch 11, Batch 100] loss: 0.013129012685531051
[Epoch 11, Batch 200] loss: 0.01455689528491348
[Epoch 11, Batch 300] loss: 0.013417663301515859
[Epoch 11, Batch 400] loss: 0.014019746954145375
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0524
Validation Accuracy: 0.9866
Overfitting: 0.0507
[Epoch 12, Batch 100] loss: 0.010054319592709362
[Epoch 12, Batch 200] loss: 0.008087890283495653
[Epoch 12, Batch 300] loss: 0.0131913340043684
[Epoch 12, Batch 400] loss: 0.011947431986482116
**STATS for Epoch 12** : 
Average training loss: 0.0026
Average validation loss: 0.0566
Validation Accuracy: 0.9862
Overfitting: 0.0541
[Epoch 13, Batch 100] loss: 0.009436478622701543
[Epoch 13, Batch 200] loss: 0.009780588233988965
[Epoch 13, Batch 300] loss: 0.01045006512654254
[Epoch 13, Batch 400] loss: 0.017631027655806975
**STATS for Epoch 13** : 
Average training loss: 0.0026
Average validation loss: 0.0539
Validation Accuracy: 0.9855
Overfitting: 0.0513
[Epoch 14, Batch 100] loss: 0.008627349266716919
[Epoch 14, Batch 200] loss: 0.008539661030226853
[Epoch 14, Batch 300] loss: 0.009660752523996053
[Epoch 14, Batch 400] loss: 0.012498477991830442
**STATS for Epoch 14** : 
Average training loss: 0.0019
Average validation loss: 0.0716
Validation Accuracy: 0.9821
Overfitting: 0.0696
[Epoch 15, Batch 100] loss: 0.009407214994862443
[Epoch 15, Batch 200] loss: 0.006977234875230351
[Epoch 15, Batch 300] loss: 0.00335210246299539
[Epoch 15, Batch 400] loss: 0.00674154373100464
**STATS for Epoch 15** : 
Average training loss: 0.0020
Average validation loss: 0.0516
Validation Accuracy: 0.9879
Overfitting: 0.0496
[Epoch 16, Batch 100] loss: 0.005742479842738248
[Epoch 16, Batch 200] loss: 0.0066060720286623105
[Epoch 16, Batch 300] loss: 0.003706622317276924
[Epoch 16, Batch 400] loss: 0.005751887924525363
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0595
Validation Accuracy: 0.9868
Overfitting: 0.0588
[Epoch 17, Batch 100] loss: 0.0021129883150024396
[Epoch 17, Batch 200] loss: 0.0037501138064908444
[Epoch 17, Batch 300] loss: 0.011594133682374377
[Epoch 17, Batch 400] loss: 0.006157100519958476
**STATS for Epoch 17** : 
Average training loss: 0.0010
Average validation loss: 0.0624
Validation Accuracy: 0.9866
Overfitting: 0.0615
[Epoch 18, Batch 100] loss: 0.004673018573885202
[Epoch 18, Batch 200] loss: 0.003618029812887471
[Epoch 18, Batch 300] loss: 0.004260597985048662
[Epoch 18, Batch 400] loss: 0.004801055854877632
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0612
Validation Accuracy: 0.9872
Overfitting: 0.0604
[Epoch 19, Batch 100] loss: 0.0036540720966877415
[Epoch 19, Batch 200] loss: 0.0045872001214956985
[Epoch 19, Batch 300] loss: 0.0047475480105003956
[Epoch 19, Batch 400] loss: 0.0030635824436012625
**STATS for Epoch 19** : 
Average training loss: 0.0009
Average validation loss: 0.0600
Validation Accuracy: 0.9877
Overfitting: 0.0591
[Epoch 20, Batch 100] loss: 0.0037641996577167445
[Epoch 20, Batch 200] loss: 0.007365625388119952
[Epoch 20, Batch 300] loss: 0.006824641669809352
[Epoch 20, Batch 400] loss: 0.00580006692378447
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0637
Validation Accuracy: 0.9860
Overfitting: 0.0631
[Epoch 21, Batch 100] loss: 0.0030116779136551484
[Epoch 21, Batch 200] loss: 0.009927470254333458
[Epoch 21, Batch 300] loss: 0.005913862522920681
[Epoch 21, Batch 400] loss: 0.002415044445442618
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0583
Validation Accuracy: 0.9882
Overfitting: 0.0580
[Epoch 22, Batch 100] loss: 0.0015239561278622205
[Epoch 22, Batch 200] loss: 0.0008969351791870395
[Epoch 22, Batch 300] loss: 0.002243339111437308
[Epoch 22, Batch 400] loss: 0.005143694120956752
**STATS for Epoch 22** : 
Average training loss: 0.0008
Average validation loss: 0.0608
Validation Accuracy: 0.9875
Overfitting: 0.0600
[Epoch 23, Batch 100] loss: 0.0012965462197075794
[Epoch 23, Batch 200] loss: 0.0008764571840129066
[Epoch 23, Batch 300] loss: 0.001152038646011988
[Epoch 23, Batch 400] loss: 0.001183504185073616
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0598
Validation Accuracy: 0.9880
Overfitting: 0.0596
[Epoch 24, Batch 100] loss: 0.00042730343172365793
[Epoch 24, Batch 200] loss: 0.00039509534799663014
[Epoch 24, Batch 300] loss: 0.0003761995050945188
[Epoch 24, Batch 400] loss: 0.00025136427457255194
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0610
Validation Accuracy: 0.9885
Overfitting: 0.0610
Fold 2 validation loss: 0.0610
Mean validation loss across all folds for Trial 10 is 0.0641 with trial config:  l1: 256, l2: 128, lr: 0.007255685482622854, batch_size: 64
[I 2024-11-21 19:12:26,982] Trial 9 finished with value: 0.06406875806310333 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.007255685482622854, 'batch_size': 64}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 11:
  l1: 128, l2: 128, lr: 0.0007958528878666696, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.302547101974487
[Epoch 1, Batch 200] loss: 2.2791141271591187
**STATS for Epoch 1** : 
Average training loss: 0.3365
Average validation loss: 2.2487
Validation Accuracy: 0.2348
Overfitting: 1.9123
Best model saved at epoch 1 with validation loss: 2.2487
[Epoch 2, Batch 100] loss: 2.20729914188385
[Epoch 2, Batch 200] loss: 1.932534077167511
**STATS for Epoch 2** : 
Average training loss: 0.2020
Average validation loss: 1.1230
Validation Accuracy: 0.7608
Overfitting: 0.9210
Best model saved at epoch 2 with validation loss: 1.1230
[Epoch 3, Batch 100] loss: 0.7713113462924958
[Epoch 3, Batch 200] loss: 0.4910137128829956
**STATS for Epoch 3** : 
Average training loss: 0.0624
Average validation loss: 0.4033
Validation Accuracy: 0.8830
Overfitting: 0.3409
Best model saved at epoch 3 with validation loss: 0.4033
[Epoch 4, Batch 100] loss: 0.39108598917722703
[Epoch 4, Batch 200] loss: 0.34019941091537476
**STATS for Epoch 4** : 
Average training loss: 0.0450
Average validation loss: 0.3137
Validation Accuracy: 0.9090
Overfitting: 0.2687
Best model saved at epoch 4 with validation loss: 0.3137
[Epoch 5, Batch 100] loss: 0.2951377026736736
[Epoch 5, Batch 200] loss: 0.2744759282469749
**STATS for Epoch 5** : 
Average training loss: 0.0369
Average validation loss: 0.2578
Validation Accuracy: 0.9222
Overfitting: 0.2209
Best model saved at epoch 5 with validation loss: 0.2578
[Epoch 6, Batch 100] loss: 0.23310764253139496
[Epoch 6, Batch 200] loss: 0.23618781074881554
**STATS for Epoch 6** : 
Average training loss: 0.0305
Average validation loss: 0.2147
Validation Accuracy: 0.9379
Overfitting: 0.1842
Best model saved at epoch 6 with validation loss: 0.2147
[Epoch 7, Batch 100] loss: 0.19927237890660762
[Epoch 7, Batch 200] loss: 0.1982593820989132
**STATS for Epoch 7** : 
Average training loss: 0.0283
Average validation loss: 0.1941
Validation Accuracy: 0.9432
Overfitting: 0.1658
Best model saved at epoch 7 with validation loss: 0.1941
[Epoch 8, Batch 100] loss: 0.18109785176813603
[Epoch 8, Batch 200] loss: 0.1710622861236334
**STATS for Epoch 8** : 
Average training loss: 0.0238
Average validation loss: 0.1673
Validation Accuracy: 0.9491
Overfitting: 0.1436
Best model saved at epoch 8 with validation loss: 0.1673
[Epoch 9, Batch 100] loss: 0.15744972560554743
[Epoch 9, Batch 200] loss: 0.14775327857583762
**STATS for Epoch 9** : 
Average training loss: 0.0226
Average validation loss: 0.1501
Validation Accuracy: 0.9559
Overfitting: 0.1274
Best model saved at epoch 9 with validation loss: 0.1501
[Epoch 10, Batch 100] loss: 0.14140496127307414
[Epoch 10, Batch 200] loss: 0.1380506807565689
**STATS for Epoch 10** : 
Average training loss: 0.0211
Average validation loss: 0.1347
Validation Accuracy: 0.9601
Overfitting: 0.1137
Best model saved at epoch 10 with validation loss: 0.1347
[Epoch 11, Batch 100] loss: 0.13365462221205235
[Epoch 11, Batch 200] loss: 0.1215126420557499
**STATS for Epoch 11** : 
Average training loss: 0.0204
Average validation loss: 0.1264
Validation Accuracy: 0.9615
Overfitting: 0.1060
Best model saved at epoch 11 with validation loss: 0.1264
[Epoch 12, Batch 100] loss: 0.11964529238641262
[Epoch 12, Batch 200] loss: 0.11843036875128746
**STATS for Epoch 12** : 
Average training loss: 0.0172
Average validation loss: 0.1228
Validation Accuracy: 0.9632
Overfitting: 0.1056
Best model saved at epoch 12 with validation loss: 0.1228
[Epoch 13, Batch 100] loss: 0.11952008206397295
[Epoch 13, Batch 200] loss: 0.1064646141603589
**STATS for Epoch 13** : 
Average training loss: 0.0141
Average validation loss: 0.1115
Validation Accuracy: 0.9657
Overfitting: 0.0973
Best model saved at epoch 13 with validation loss: 0.1115
[Epoch 14, Batch 100] loss: 0.11191329341381788
[Epoch 14, Batch 200] loss: 0.10138696156442166
**STATS for Epoch 14** : 
Average training loss: 0.0144
Average validation loss: 0.1088
Validation Accuracy: 0.9660
Overfitting: 0.0944
Best model saved at epoch 14 with validation loss: 0.1088
[Epoch 15, Batch 100] loss: 0.09495370548218489
[Epoch 15, Batch 200] loss: 0.09574053687974811
**STATS for Epoch 15** : 
Average training loss: 0.0174
Average validation loss: 0.1082
Validation Accuracy: 0.9663
Overfitting: 0.0908
Best model saved at epoch 15 with validation loss: 0.1082
[Epoch 16, Batch 100] loss: 0.09389619765803218
[Epoch 16, Batch 200] loss: 0.09855103334411978
**STATS for Epoch 16** : 
Average training loss: 0.0136
Average validation loss: 0.1009
Validation Accuracy: 0.9694
Overfitting: 0.0873
Best model saved at epoch 16 with validation loss: 0.1009
[Epoch 17, Batch 100] loss: 0.08671038700267672
[Epoch 17, Batch 200] loss: 0.08637183975428343
**STATS for Epoch 17** : 
Average training loss: 0.0138
Average validation loss: 0.0973
Validation Accuracy: 0.9704
Overfitting: 0.0835
Best model saved at epoch 17 with validation loss: 0.0973
[Epoch 18, Batch 100] loss: 0.08733210060745478
[Epoch 18, Batch 200] loss: 0.08207148969173432
**STATS for Epoch 18** : 
Average training loss: 0.0131
Average validation loss: 0.0982
Validation Accuracy: 0.9686
Overfitting: 0.0851
[Epoch 19, Batch 100] loss: 0.08290660347789526
[Epoch 19, Batch 200] loss: 0.08335305389016867
**STATS for Epoch 19** : 
Average training loss: 0.0118
Average validation loss: 0.0916
Validation Accuracy: 0.9722
Overfitting: 0.0798
Best model saved at epoch 19 with validation loss: 0.0916
[Epoch 20, Batch 100] loss: 0.07617377190850676
[Epoch 20, Batch 200] loss: 0.07901827426627278
**STATS for Epoch 20** : 
Average training loss: 0.0139
Average validation loss: 0.0896
Validation Accuracy: 0.9721
Overfitting: 0.0758
Best model saved at epoch 20 with validation loss: 0.0896
[Epoch 21, Batch 100] loss: 0.07948240509256721
[Epoch 21, Batch 200] loss: 0.06988689173012971
**STATS for Epoch 21** : 
Average training loss: 0.0130
Average validation loss: 0.0877
Validation Accuracy: 0.9732
Overfitting: 0.0747
Best model saved at epoch 21 with validation loss: 0.0877
[Epoch 22, Batch 100] loss: 0.07205804593861104
[Epoch 22, Batch 200] loss: 0.07369986986741424
**STATS for Epoch 22** : 
Average training loss: 0.0111
Average validation loss: 0.0965
Validation Accuracy: 0.9712
Overfitting: 0.0854
[Epoch 23, Batch 100] loss: 0.07223732889629901
[Epoch 23, Batch 200] loss: 0.0687150947470218
**STATS for Epoch 23** : 
Average training loss: 0.0111
Average validation loss: 0.0905
Validation Accuracy: 0.9727
Overfitting: 0.0794
[Epoch 24, Batch 100] loss: 0.0672842896450311
[Epoch 24, Batch 200] loss: 0.07009763214737177
**STATS for Epoch 24** : 
Average training loss: 0.0098
Average validation loss: 0.0927
Validation Accuracy: 0.9720
Overfitting: 0.0829
Fold 1 validation loss: 0.0927
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.289986515045166
[Epoch 1, Batch 200] loss: 2.2598094272613527
**STATS for Epoch 1** : 
Average training loss: 0.3306
Average validation loss: 2.2022
Validation Accuracy: 0.4839
Overfitting: 1.8716
Best model saved at epoch 1 with validation loss: 2.2022
[Epoch 2, Batch 100] loss: 2.097838832139969
[Epoch 2, Batch 200] loss: 1.4621436631679534
**STATS for Epoch 2** : 
Average training loss: 0.1228
Average validation loss: 0.7301
Validation Accuracy: 0.7983
Overfitting: 0.6073
Best model saved at epoch 2 with validation loss: 0.7301
[Epoch 3, Batch 100] loss: 0.5810585591197014
[Epoch 3, Batch 200] loss: 0.4490382201969624
**STATS for Epoch 3** : 
Average training loss: 0.0608
Average validation loss: 0.3806
Validation Accuracy: 0.8881
Overfitting: 0.3198
Best model saved at epoch 3 with validation loss: 0.3806
[Epoch 4, Batch 100] loss: 0.34963341668248177
[Epoch 4, Batch 200] loss: 0.3241504243016243
**STATS for Epoch 4** : 
Average training loss: 0.0463
Average validation loss: 0.2966
Validation Accuracy: 0.9123
Overfitting: 0.2502
Best model saved at epoch 4 with validation loss: 0.2966
[Epoch 5, Batch 100] loss: 0.28566945567727087
[Epoch 5, Batch 200] loss: 0.25522381871938704
**STATS for Epoch 5** : 
Average training loss: 0.0390
Average validation loss: 0.2643
Validation Accuracy: 0.9201
Overfitting: 0.2254
Best model saved at epoch 5 with validation loss: 0.2643
[Epoch 6, Batch 100] loss: 0.24502290025353432
[Epoch 6, Batch 200] loss: 0.2193203055113554
**STATS for Epoch 6** : 
Average training loss: 0.0315
Average validation loss: 0.2177
Validation Accuracy: 0.9348
Overfitting: 0.1862
Best model saved at epoch 6 with validation loss: 0.2177
[Epoch 7, Batch 100] loss: 0.21045793764293194
[Epoch 7, Batch 200] loss: 0.19413668476045132
**STATS for Epoch 7** : 
Average training loss: 0.0308
Average validation loss: 0.1955
Validation Accuracy: 0.9415
Overfitting: 0.1647
Best model saved at epoch 7 with validation loss: 0.1955
[Epoch 8, Batch 100] loss: 0.18447783038020135
[Epoch 8, Batch 200] loss: 0.17806076616048813
**STATS for Epoch 8** : 
Average training loss: 0.0264
Average validation loss: 0.1721
Validation Accuracy: 0.9483
Overfitting: 0.1457
Best model saved at epoch 8 with validation loss: 0.1721
[Epoch 9, Batch 100] loss: 0.16129361160099506
[Epoch 9, Batch 200] loss: 0.16699546426534653
**STATS for Epoch 9** : 
Average training loss: 0.0224
Average validation loss: 0.1610
Validation Accuracy: 0.9504
Overfitting: 0.1386
Best model saved at epoch 9 with validation loss: 0.1610
[Epoch 10, Batch 100] loss: 0.15315400056540965
[Epoch 10, Batch 200] loss: 0.15101941205561162
**STATS for Epoch 10** : 
Average training loss: 0.0208
Average validation loss: 0.1562
Validation Accuracy: 0.9530
Overfitting: 0.1355
Best model saved at epoch 10 with validation loss: 0.1562
[Epoch 11, Batch 100] loss: 0.14815281923860313
[Epoch 11, Batch 200] loss: 0.12765632946044206
**STATS for Epoch 11** : 
Average training loss: 0.0197
Average validation loss: 0.1419
Validation Accuracy: 0.9572
Overfitting: 0.1222
Best model saved at epoch 11 with validation loss: 0.1419
[Epoch 12, Batch 100] loss: 0.13676751296967268
[Epoch 12, Batch 200] loss: 0.12370553463697434
**STATS for Epoch 12** : 
Average training loss: 0.0171
Average validation loss: 0.1302
Validation Accuracy: 0.9615
Overfitting: 0.1132
Best model saved at epoch 12 with validation loss: 0.1302
[Epoch 13, Batch 100] loss: 0.12154188603162766
[Epoch 13, Batch 200] loss: 0.11414454720914363
**STATS for Epoch 13** : 
Average training loss: 0.0177
Average validation loss: 0.1246
Validation Accuracy: 0.9628
Overfitting: 0.1069
Best model saved at epoch 13 with validation loss: 0.1246
[Epoch 14, Batch 100] loss: 0.11382656160742044
[Epoch 14, Batch 200] loss: 0.11784332081675529
**STATS for Epoch 14** : 
Average training loss: 0.0138
Average validation loss: 0.1139
Validation Accuracy: 0.9653
Overfitting: 0.1001
Best model saved at epoch 14 with validation loss: 0.1139
[Epoch 15, Batch 100] loss: 0.10793276596814394
[Epoch 15, Batch 200] loss: 0.1090708789229393
**STATS for Epoch 15** : 
Average training loss: 0.0143
Average validation loss: 0.1147
Validation Accuracy: 0.9656
Overfitting: 0.1004
[Epoch 16, Batch 100] loss: 0.09771362360566854
[Epoch 16, Batch 200] loss: 0.10381306879222393
**STATS for Epoch 16** : 
Average training loss: 0.0134
Average validation loss: 0.1115
Validation Accuracy: 0.9657
Overfitting: 0.0981
Best model saved at epoch 16 with validation loss: 0.1115
[Epoch 17, Batch 100] loss: 0.09353916699066758
[Epoch 17, Batch 200] loss: 0.098317806199193
**STATS for Epoch 17** : 
Average training loss: 0.0131
Average validation loss: 0.1017
Validation Accuracy: 0.9688
Overfitting: 0.0886
Best model saved at epoch 17 with validation loss: 0.1017
[Epoch 18, Batch 100] loss: 0.09245392905548215
[Epoch 18, Batch 200] loss: 0.08537229854613543
**STATS for Epoch 18** : 
Average training loss: 0.0137
Average validation loss: 0.0998
Validation Accuracy: 0.9699
Overfitting: 0.0861
Best model saved at epoch 18 with validation loss: 0.0998
[Epoch 19, Batch 100] loss: 0.08378681313246489
[Epoch 19, Batch 200] loss: 0.08549389265477657
**STATS for Epoch 19** : 
Average training loss: 0.0129
Average validation loss: 0.0964
Validation Accuracy: 0.9705
Overfitting: 0.0836
Best model saved at epoch 19 with validation loss: 0.0964
[Epoch 20, Batch 100] loss: 0.08509673718363046
[Epoch 20, Batch 200] loss: 0.08315968671813607
**STATS for Epoch 20** : 
Average training loss: 0.0113
Average validation loss: 0.0951
Validation Accuracy: 0.9709
Overfitting: 0.0838
Best model saved at epoch 20 with validation loss: 0.0951
[Epoch 21, Batch 100] loss: 0.07963815174996852
[Epoch 21, Batch 200] loss: 0.07482034771703183
**STATS for Epoch 21** : 
Average training loss: 0.0126
Average validation loss: 0.0861
Validation Accuracy: 0.9738
Overfitting: 0.0736
Best model saved at epoch 21 with validation loss: 0.0861
[Epoch 22, Batch 100] loss: 0.07392785308882593
[Epoch 22, Batch 200] loss: 0.07559236031025648
**STATS for Epoch 22** : 
Average training loss: 0.0119
Average validation loss: 0.0895
Validation Accuracy: 0.9726
Overfitting: 0.0775
[Epoch 23, Batch 100] loss: 0.07434574151411652
[Epoch 23, Batch 200] loss: 0.06986068457365036
**STATS for Epoch 23** : 
Average training loss: 0.0110
Average validation loss: 0.0898
Validation Accuracy: 0.9719
Overfitting: 0.0788
[Epoch 24, Batch 100] loss: 0.07692628704011441
[Epoch 24, Batch 200] loss: 0.06587432779371738
**STATS for Epoch 24** : 
Average training loss: 0.0084
Average validation loss: 0.0797
Validation Accuracy: 0.9758
Overfitting: 0.0713
Best model saved at epoch 24 with validation loss: 0.0797
Fold 2 validation loss: 0.0797
Mean validation loss across all folds for Trial 11 is 0.0862 with trial config:  l1: 128, l2: 128, lr: 0.0007958528878666696, batch_size: 128
[I 2024-11-21 19:21:11,303] Trial 10 finished with value: 0.08622119581683518 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0007958528878666696, 'batch_size': 128}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 12:
  l1: 256, l2: 128, lr: 0.06942779375197834, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 0.9828587427735329
[Epoch 1, Batch 200] loss: 0.3087416972219944
[Epoch 1, Batch 300] loss: 0.22887904824689032
[Epoch 1, Batch 400] loss: 0.16224096590653062
**STATS for Epoch 1** : 
Average training loss: 0.0216
Average validation loss: 0.1311
Validation Accuracy: 0.9637
Overfitting: 0.1096
Best model saved at epoch 1 with validation loss: 0.1311
[Epoch 2, Batch 100] loss: 0.13173186099156736
[Epoch 2, Batch 200] loss: 0.1616176530532539
[Epoch 2, Batch 300] loss: 0.13410916388966143
[Epoch 2, Batch 400] loss: 0.14450875552836806
**STATS for Epoch 2** : 
Average training loss: 0.0188
Average validation loss: 0.1063
Validation Accuracy: 0.9712
Overfitting: 0.0875
Best model saved at epoch 2 with validation loss: 0.1063
[Epoch 3, Batch 100] loss: 0.09164197485428303
[Epoch 3, Batch 200] loss: 0.0919332652608864
[Epoch 3, Batch 300] loss: 0.09764535832218826
[Epoch 3, Batch 400] loss: 0.10038521140580997
**STATS for Epoch 3** : 
Average training loss: 0.0163
Average validation loss: 0.0957
Validation Accuracy: 0.9750
Overfitting: 0.0794
Best model saved at epoch 3 with validation loss: 0.0957
[Epoch 4, Batch 100] loss: 0.08104529357660795
[Epoch 4, Batch 200] loss: 0.09805225274176337
[Epoch 4, Batch 300] loss: 0.10893470910494216
[Epoch 4, Batch 400] loss: 0.08481620026635937
**STATS for Epoch 4** : 
Average training loss: 0.0122
Average validation loss: 0.0791
Validation Accuracy: 0.9803
Overfitting: 0.0669
Best model saved at epoch 4 with validation loss: 0.0791
[Epoch 5, Batch 100] loss: 0.05608038729988039
[Epoch 5, Batch 200] loss: 0.06387455480056815
[Epoch 5, Batch 300] loss: 0.07835367723717354
[Epoch 5, Batch 400] loss: 0.08886700872040819
**STATS for Epoch 5** : 
Average training loss: 0.0121
Average validation loss: 0.1090
Validation Accuracy: 0.9743
Overfitting: 0.0969
[Epoch 6, Batch 100] loss: 0.08126121556735598
[Epoch 6, Batch 200] loss: 0.08527243816526607
[Epoch 6, Batch 300] loss: 0.07743756636918989
[Epoch 6, Batch 400] loss: 0.06832039304776118
**STATS for Epoch 6** : 
Average training loss: 0.0113
Average validation loss: 0.0963
Validation Accuracy: 0.9772
Overfitting: 0.0850
[Epoch 7, Batch 100] loss: 0.0645171667006798
[Epoch 7, Batch 200] loss: 0.05036710685497383
[Epoch 7, Batch 300] loss: 0.0834664568194421
[Epoch 7, Batch 400] loss: 0.06941378741990775
**STATS for Epoch 7** : 
Average training loss: 0.0120
Average validation loss: 0.1140
Validation Accuracy: 0.9782
Overfitting: 0.1020
[Epoch 8, Batch 100] loss: 0.06826613608849584
[Epoch 8, Batch 200] loss: 0.06904059980603051
[Epoch 8, Batch 300] loss: 0.10561791885898857
[Epoch 8, Batch 400] loss: 0.06738473910052561
**STATS for Epoch 8** : 
Average training loss: 0.0149
Average validation loss: 0.1066
Validation Accuracy: 0.9778
Overfitting: 0.0917
[Epoch 9, Batch 100] loss: 0.06363819135047379
[Epoch 9, Batch 200] loss: 0.0782602814931306
[Epoch 9, Batch 300] loss: 0.06768440640800691
[Epoch 9, Batch 400] loss: 0.06091427539358847
**STATS for Epoch 9** : 
Average training loss: 0.0145
Average validation loss: 0.1099
Validation Accuracy: 0.9730
Overfitting: 0.0954
[Epoch 10, Batch 100] loss: 0.0650434140546713
[Epoch 10, Batch 200] loss: 0.06218720240925904
[Epoch 10, Batch 300] loss: 0.07129162845434621
[Epoch 10, Batch 400] loss: 0.08726209510932677
**STATS for Epoch 10** : 
Average training loss: 0.0113
Average validation loss: 0.1232
Validation Accuracy: 0.9790
Overfitting: 0.1118
[Epoch 11, Batch 100] loss: 0.05975584463783889
[Epoch 11, Batch 200] loss: 0.073321095292049
[Epoch 11, Batch 300] loss: 0.051700497423880734
[Epoch 11, Batch 400] loss: 0.0750973968269318
**STATS for Epoch 11** : 
Average training loss: 0.0103
Average validation loss: 0.1442
Validation Accuracy: 0.9745
Overfitting: 0.1339
[Epoch 12, Batch 100] loss: 0.0687509337379015
[Epoch 12, Batch 200] loss: 0.06629331993586675
[Epoch 12, Batch 300] loss: 0.060605306401484996
[Epoch 12, Batch 400] loss: 0.08765260618645698
**STATS for Epoch 12** : 
Average training loss: 0.0165
Average validation loss: 0.1318
Validation Accuracy: 0.9735
Overfitting: 0.1153
[Epoch 13, Batch 100] loss: 0.07119518309867999
[Epoch 13, Batch 200] loss: 0.08423567279459349
[Epoch 13, Batch 300] loss: 0.07170656995924218
[Epoch 13, Batch 400] loss: 0.08093424388534913
**STATS for Epoch 13** : 
Average training loss: 0.0274
Average validation loss: 0.1701
Validation Accuracy: 0.9673
Overfitting: 0.1428
[Epoch 14, Batch 100] loss: 0.15267925459425896
[Epoch 14, Batch 200] loss: 0.15648975015617908
[Epoch 14, Batch 300] loss: 0.17838639482855798
[Epoch 14, Batch 400] loss: 0.1526757129118778
**STATS for Epoch 14** : 
Average training loss: 0.0198
Average validation loss: 0.1911
Validation Accuracy: 0.9713
Overfitting: 0.1712
[Epoch 15, Batch 100] loss: 0.12555159531068058
[Epoch 15, Batch 200] loss: 0.10816857381665614
[Epoch 15, Batch 300] loss: 0.09837243928879616
[Epoch 15, Batch 400] loss: 0.10960366230108776
**STATS for Epoch 15** : 
Average training loss: 0.0093
Average validation loss: 0.1669
Validation Accuracy: 0.9756
Overfitting: 0.1577
[Epoch 16, Batch 100] loss: 0.07448802258440992
[Epoch 16, Batch 200] loss: 0.1547113448106029
[Epoch 16, Batch 300] loss: 0.18106580446474255
[Epoch 16, Batch 400] loss: 0.1508745697886843
**STATS for Epoch 16** : 
Average training loss: 0.0261
Average validation loss: 0.2451
Validation Accuracy: 0.9620
Overfitting: 0.2191
[Epoch 17, Batch 100] loss: 0.14064816617012185
[Epoch 17, Batch 200] loss: 0.2187933190516196
[Epoch 17, Batch 300] loss: 0.3259508033283055
[Epoch 17, Batch 400] loss: 0.3283820037433179
**STATS for Epoch 17** : 
Average training loss: 0.0507
Average validation loss: 1.0262
Validation Accuracy: 0.9266
Overfitting: 0.9755
[Epoch 18, Batch 100] loss: 2.0852129849791528
[Epoch 18, Batch 200] loss: 2.304261522293091
[Epoch 18, Batch 300] loss: 2.303174514770508
[Epoch 18, Batch 400] loss: 2.3037166690826414
**STATS for Epoch 18** : 
Average training loss: 0.3386
Average validation loss: 2.3040
Validation Accuracy: 0.0987
Overfitting: 1.9654
[Epoch 19, Batch 100] loss: 2.3034955430030823
[Epoch 19, Batch 200] loss: 2.303229105472565
[Epoch 19, Batch 300] loss: 2.303334710597992
[Epoch 19, Batch 400] loss: 2.3032328605651857
**STATS for Epoch 19** : 
Average training loss: 0.3390
Average validation loss: 2.3026
Validation Accuracy: 0.1122
Overfitting: 1.9636
[Epoch 20, Batch 100] loss: 2.3035786485672
[Epoch 20, Batch 200] loss: 2.303258230686188
[Epoch 20, Batch 300] loss: 2.303449101448059
[Epoch 20, Batch 400] loss: 2.3033384108543395
**STATS for Epoch 20** : 
Average training loss: 0.3388
Average validation loss: 2.3048
Validation Accuracy: 0.1122
Overfitting: 1.9660
[Epoch 21, Batch 100] loss: 2.3046115922927854
[Epoch 21, Batch 200] loss: 2.304529252052307
[Epoch 21, Batch 300] loss: 2.3028948760032653
[Epoch 21, Batch 400] loss: 2.3032947731018067
**STATS for Epoch 21** : 
Average training loss: 0.3388
Average validation loss: 2.3035
Validation Accuracy: 0.1122
Overfitting: 1.9646
[Epoch 22, Batch 100] loss: 2.3027034831047057
[Epoch 22, Batch 200] loss: 2.303947422504425
[Epoch 22, Batch 300] loss: 2.3034789967536926
[Epoch 22, Batch 400] loss: 2.3031023740768433
**STATS for Epoch 22** : 
Average training loss: 0.3387
Average validation loss: 2.3046
Validation Accuracy: 0.1036
Overfitting: 1.9658
[Epoch 23, Batch 100] loss: 2.3022253251075746
[Epoch 23, Batch 200] loss: 2.3040902185440064
[Epoch 23, Batch 300] loss: 2.3036170649528502
[Epoch 23, Batch 400] loss: 2.3037602186203
**STATS for Epoch 23** : 
Average training loss: 0.3389
Average validation loss: 2.3065
Validation Accuracy: 0.0998
Overfitting: 1.9676
[Epoch 24, Batch 100] loss: 2.303729946613312
[Epoch 24, Batch 200] loss: 2.3033497953414916
[Epoch 24, Batch 300] loss: 2.3030665063858033
[Epoch 24, Batch 400] loss: 2.3022963881492613
**STATS for Epoch 24** : 
Average training loss: 0.3387
Average validation loss: 2.3021
Validation Accuracy: 0.1122
Overfitting: 1.9635
Fold 1 validation loss: 2.3021
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 0.9892897787690162
[Epoch 1, Batch 200] loss: 0.2574620107933879
[Epoch 1, Batch 300] loss: 0.2662311632372439
[Epoch 1, Batch 400] loss: 0.1374053468555212
**STATS for Epoch 1** : 
Average training loss: 0.0239
Average validation loss: 0.1382
Validation Accuracy: 0.9619
Overfitting: 0.1143
Best model saved at epoch 1 with validation loss: 0.1382
[Epoch 2, Batch 100] loss: 0.15963598537258805
[Epoch 2, Batch 200] loss: 0.1460349878296256
[Epoch 2, Batch 300] loss: 0.11776494480669498
[Epoch 2, Batch 400] loss: 0.1177759546553716
**STATS for Epoch 2** : 
Average training loss: 0.0176
Average validation loss: 0.1150
Validation Accuracy: 0.9692
Overfitting: 0.0974
Best model saved at epoch 2 with validation loss: 0.1150
[Epoch 3, Batch 100] loss: 0.08467403340153395
[Epoch 3, Batch 200] loss: 0.09784445771132595
[Epoch 3, Batch 300] loss: 0.08617723905248567
[Epoch 3, Batch 400] loss: 0.10022836205200292
**STATS for Epoch 3** : 
Average training loss: 0.0142
Average validation loss: 0.1146
Validation Accuracy: 0.9689
Overfitting: 0.1004
Best model saved at epoch 3 with validation loss: 0.1146
[Epoch 4, Batch 100] loss: 0.064245331940474
[Epoch 4, Batch 200] loss: 0.08307614019955509
[Epoch 4, Batch 300] loss: 0.08019882581429556
[Epoch 4, Batch 400] loss: 0.07664053896791302
**STATS for Epoch 4** : 
Average training loss: 0.0112
Average validation loss: 0.1041
Validation Accuracy: 0.9744
Overfitting: 0.0929
Best model saved at epoch 4 with validation loss: 0.1041
[Epoch 5, Batch 100] loss: 0.08652989955036901
[Epoch 5, Batch 200] loss: 0.09377310182433575
[Epoch 5, Batch 300] loss: 0.094972636285529
[Epoch 5, Batch 400] loss: 0.07595028233597986
**STATS for Epoch 5** : 
Average training loss: 0.0126
Average validation loss: 0.1159
Validation Accuracy: 0.9710
Overfitting: 0.1033
[Epoch 6, Batch 100] loss: 0.060664677180029686
[Epoch 6, Batch 200] loss: 0.06393507451110053
[Epoch 6, Batch 300] loss: 0.10216542545997072
[Epoch 6, Batch 400] loss: 0.08931497796089388
**STATS for Epoch 6** : 
Average training loss: 0.0146
Average validation loss: 0.1186
Validation Accuracy: 0.9773
Overfitting: 0.1040
[Epoch 7, Batch 100] loss: 0.08464612311858218
[Epoch 7, Batch 200] loss: 0.09179635499138385
[Epoch 7, Batch 300] loss: 0.07105904724077845
[Epoch 7, Batch 400] loss: 0.08617497518396704
**STATS for Epoch 7** : 
Average training loss: 0.0110
Average validation loss: 0.1031
Validation Accuracy: 0.9769
Overfitting: 0.0922
Best model saved at epoch 7 with validation loss: 0.1031
[Epoch 8, Batch 100] loss: 0.053511222764791457
[Epoch 8, Batch 200] loss: 0.08355307490070117
[Epoch 8, Batch 300] loss: 0.06549056288902648
[Epoch 8, Batch 400] loss: 0.07009683338343166
**STATS for Epoch 8** : 
Average training loss: 0.0098
Average validation loss: 0.1171
Validation Accuracy: 0.9736
Overfitting: 0.1073
[Epoch 9, Batch 100] loss: 0.049268745864392255
[Epoch 9, Batch 200] loss: 0.06002519959351048
[Epoch 9, Batch 300] loss: 0.06563338353589643
[Epoch 9, Batch 400] loss: 0.06276884573249845
**STATS for Epoch 9** : 
Average training loss: 0.0105
Average validation loss: 0.0868
Validation Accuracy: 0.9799
Overfitting: 0.0763
Best model saved at epoch 9 with validation loss: 0.0868
[Epoch 10, Batch 100] loss: 0.04874521896788792
[Epoch 10, Batch 200] loss: 0.06676042769177001
[Epoch 10, Batch 300] loss: 0.07812343967292691
[Epoch 10, Batch 400] loss: 0.07351333225495182
**STATS for Epoch 10** : 
Average training loss: 0.0077
Average validation loss: 0.1161
Validation Accuracy: 0.9793
Overfitting: 0.1083
[Epoch 11, Batch 100] loss: 0.0466913313895202
[Epoch 11, Batch 200] loss: 0.0710299890267197
[Epoch 11, Batch 300] loss: 0.05222979564779962
[Epoch 11, Batch 400] loss: 0.05046872713501216
**STATS for Epoch 11** : 
Average training loss: 0.0117
Average validation loss: 0.1292
Validation Accuracy: 0.9732
Overfitting: 0.1175
[Epoch 12, Batch 100] loss: 0.0738232398479886
[Epoch 12, Batch 200] loss: 0.10753595449627028
[Epoch 12, Batch 300] loss: 0.22449961347403588
[Epoch 12, Batch 400] loss: 0.14308304683305323
**STATS for Epoch 12** : 
Average training loss: 0.0149
Average validation loss: 0.1768
Validation Accuracy: 0.9675
Overfitting: 0.1619
[Epoch 13, Batch 100] loss: 0.12157261800311972
[Epoch 13, Batch 200] loss: 0.14891591437510215
[Epoch 13, Batch 300] loss: 0.10126661579186474
[Epoch 13, Batch 400] loss: 0.1039465725744958
**STATS for Epoch 13** : 
Average training loss: 0.0162
Average validation loss: 0.1075
Validation Accuracy: 0.9781
Overfitting: 0.0913
[Epoch 14, Batch 100] loss: 0.07932123327947921
[Epoch 14, Batch 200] loss: 0.14838069224264472
[Epoch 14, Batch 300] loss: 0.5705578099191189
[Epoch 14, Batch 400] loss: 0.2655444544088095
**STATS for Epoch 14** : 
Average training loss: 0.0249
Average validation loss: 0.2139
Validation Accuracy: 0.9629
Overfitting: 0.1889
[Epoch 15, Batch 100] loss: 0.16085064549464734
[Epoch 15, Batch 200] loss: 0.14613015124108641
[Epoch 15, Batch 300] loss: 0.11200706551317126
[Epoch 15, Batch 400] loss: 0.12711334267514757
**STATS for Epoch 15** : 
Average training loss: 0.0194
Average validation loss: 0.1357
Validation Accuracy: 0.9707
Overfitting: 0.1163
[Epoch 16, Batch 100] loss: 0.09586685860849684
[Epoch 16, Batch 200] loss: 0.16602051176363603
[Epoch 16, Batch 300] loss: 0.1327420216286555
[Epoch 16, Batch 400] loss: 0.2625954724662006
**STATS for Epoch 16** : 
Average training loss: 0.0340
Average validation loss: 0.2637
Validation Accuracy: 0.9550
Overfitting: 0.2297
[Epoch 17, Batch 100] loss: 0.23716526151634754
[Epoch 17, Batch 200] loss: 0.2209618995594792
[Epoch 17, Batch 300] loss: 0.22609962868271397
[Epoch 17, Batch 400] loss: 0.16794323220383375
**STATS for Epoch 17** : 
Average training loss: 0.0244
Average validation loss: 0.2178
Validation Accuracy: 0.9589
Overfitting: 0.1934
[Epoch 18, Batch 100] loss: 0.1542221840430284
[Epoch 18, Batch 200] loss: 0.20881101214210504
[Epoch 18, Batch 300] loss: 0.22021470989682712
[Epoch 18, Batch 400] loss: 0.2568075449950993
**STATS for Epoch 18** : 
Average training loss: 0.0677
Average validation loss: 0.6142
Validation Accuracy: 0.9108
Overfitting: 0.5465
[Epoch 19, Batch 100] loss: 1.411886006742716
[Epoch 19, Batch 200] loss: 2.354840133190155
[Epoch 19, Batch 300] loss: 2.303746976852417
[Epoch 19, Batch 400] loss: 2.305201997756958
**STATS for Epoch 19** : 
Average training loss: 0.3387
Average validation loss: 2.3039
Validation Accuracy: 0.1126
Overfitting: 1.9652
[Epoch 20, Batch 100] loss: 2.302732701301575
[Epoch 20, Batch 200] loss: 2.303094334602356
[Epoch 20, Batch 300] loss: 2.304235460758209
[Epoch 20, Batch 400] loss: 2.3037248992919923
**STATS for Epoch 20** : 
Average training loss: 0.3391
Average validation loss: 2.3037
Validation Accuracy: 0.1126
Overfitting: 1.9646
[Epoch 21, Batch 100] loss: 2.303441278934479
[Epoch 21, Batch 200] loss: 2.3050716614723203
[Epoch 21, Batch 300] loss: 2.3035795068740845
[Epoch 21, Batch 400] loss: 2.3034367895126344
**STATS for Epoch 21** : 
Average training loss: 0.3390
Average validation loss: 2.3026
Validation Accuracy: 0.0976
Overfitting: 1.9636
[Epoch 22, Batch 100] loss: 2.3024649000167847
[Epoch 22, Batch 200] loss: 2.3038613748550416
[Epoch 22, Batch 300] loss: 2.3045986485481262
[Epoch 22, Batch 400] loss: 2.3030647158622743
**STATS for Epoch 22** : 
Average training loss: 0.3390
Average validation loss: 2.3037
Validation Accuracy: 0.1126
Overfitting: 1.9647
[Epoch 23, Batch 100] loss: 2.303411705493927
[Epoch 23, Batch 200] loss: 2.303339879512787
[Epoch 23, Batch 300] loss: 2.3045880365371705
[Epoch 23, Batch 400] loss: 2.303959650993347
**STATS for Epoch 23** : 
Average training loss: 0.3390
Average validation loss: 2.3021
Validation Accuracy: 0.1126
Overfitting: 1.9631
[Epoch 24, Batch 100] loss: 2.3031073951721193
[Epoch 24, Batch 200] loss: 2.302665526866913
[Epoch 24, Batch 300] loss: 2.3040087485313414
[Epoch 24, Batch 400] loss: 2.3025086760520934
**STATS for Epoch 24** : 
Average training loss: 0.3390
Average validation loss: 2.3031
Validation Accuracy: 0.1037
Overfitting: 1.9642
Fold 2 validation loss: 2.3031
Mean validation loss across all folds for Trial 12 is 2.3026 with trial config:  l1: 256, l2: 128, lr: 0.06942779375197834, batch_size: 64
[I 2024-11-21 19:30:14,620] Trial 11 finished with value: 2.302630370359685 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.06942779375197834, 'batch_size': 64}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 13:
  l1: 256, l2: 128, lr: 0.0007380817523374673, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.290132396221161
[Epoch 1, Batch 200] loss: 2.2497354388237
[Epoch 1, Batch 300] loss: 2.139849613904953
[Epoch 1, Batch 400] loss: 1.6336137175559997
**STATS for Epoch 1** : 
Average training loss: 0.1379
Average validation loss: 0.7368
Validation Accuracy: 0.7695
Overfitting: 0.5989
Best model saved at epoch 1 with validation loss: 0.7368
[Epoch 2, Batch 100] loss: 0.6349201327562333
[Epoch 2, Batch 200] loss: 0.4842631846666336
[Epoch 2, Batch 300] loss: 0.43341672033071516
[Epoch 2, Batch 400] loss: 0.3677700135111809
**STATS for Epoch 2** : 
Average training loss: 0.0517
Average validation loss: 0.3148
Validation Accuracy: 0.9075
Overfitting: 0.2630
Best model saved at epoch 2 with validation loss: 0.3148
[Epoch 3, Batch 100] loss: 0.3068083716928959
[Epoch 3, Batch 200] loss: 0.2916796354949474
[Epoch 3, Batch 300] loss: 0.25672873444855215
[Epoch 3, Batch 400] loss: 0.2495021641999483
**STATS for Epoch 3** : 
Average training loss: 0.0349
Average validation loss: 0.2238
Validation Accuracy: 0.9311
Overfitting: 0.1889
Best model saved at epoch 3 with validation loss: 0.2238
[Epoch 4, Batch 100] loss: 0.2203521280735731
[Epoch 4, Batch 200] loss: 0.20631710410118104
[Epoch 4, Batch 300] loss: 0.19168915182352067
[Epoch 4, Batch 400] loss: 0.17468321427702904
**STATS for Epoch 4** : 
Average training loss: 0.0275
Average validation loss: 0.1767
Validation Accuracy: 0.9463
Overfitting: 0.1492
Best model saved at epoch 4 with validation loss: 0.1767
[Epoch 5, Batch 100] loss: 0.16293094404041766
[Epoch 5, Batch 200] loss: 0.15721321187913417
[Epoch 5, Batch 300] loss: 0.1563776021823287
[Epoch 5, Batch 400] loss: 0.1544171565771103
**STATS for Epoch 5** : 
Average training loss: 0.0225
Average validation loss: 0.1660
Validation Accuracy: 0.9497
Overfitting: 0.1434
Best model saved at epoch 5 with validation loss: 0.1660
[Epoch 6, Batch 100] loss: 0.15359477560967208
[Epoch 6, Batch 200] loss: 0.1291017687320709
[Epoch 6, Batch 300] loss: 0.12607169752940536
[Epoch 6, Batch 400] loss: 0.1265299554169178
**STATS for Epoch 6** : 
Average training loss: 0.0175
Average validation loss: 0.1254
Validation Accuracy: 0.9620
Overfitting: 0.1079
Best model saved at epoch 6 with validation loss: 0.1254
[Epoch 7, Batch 100] loss: 0.12258195996284485
[Epoch 7, Batch 200] loss: 0.11299571203067899
[Epoch 7, Batch 300] loss: 0.1244521907158196
[Epoch 7, Batch 400] loss: 0.11772972475737334
**STATS for Epoch 7** : 
Average training loss: 0.0158
Average validation loss: 0.1205
Validation Accuracy: 0.9638
Overfitting: 0.1047
Best model saved at epoch 7 with validation loss: 0.1205
[Epoch 8, Batch 100] loss: 0.11197227887809276
[Epoch 8, Batch 200] loss: 0.10201559398323297
[Epoch 8, Batch 300] loss: 0.10782739745453
[Epoch 8, Batch 400] loss: 0.09742259535007179
**STATS for Epoch 8** : 
Average training loss: 0.0138
Average validation loss: 0.1045
Validation Accuracy: 0.9681
Overfitting: 0.0907
Best model saved at epoch 8 with validation loss: 0.1045
[Epoch 9, Batch 100] loss: 0.10111032515764236
[Epoch 9, Batch 200] loss: 0.09248501687310635
[Epoch 9, Batch 300] loss: 0.09714839546009899
[Epoch 9, Batch 400] loss: 0.08733021876774728
**STATS for Epoch 9** : 
Average training loss: 0.0120
Average validation loss: 0.0942
Validation Accuracy: 0.9714
Overfitting: 0.0822
Best model saved at epoch 9 with validation loss: 0.0942
[Epoch 10, Batch 100] loss: 0.0795529727358371
[Epoch 10, Batch 200] loss: 0.08269830900244415
[Epoch 10, Batch 300] loss: 0.09294466005638241
[Epoch 10, Batch 400] loss: 0.08569727871567011
**STATS for Epoch 10** : 
Average training loss: 0.0132
Average validation loss: 0.0972
Validation Accuracy: 0.9693
Overfitting: 0.0840
[Epoch 11, Batch 100] loss: 0.07947364024352283
[Epoch 11, Batch 200] loss: 0.08142690922133625
[Epoch 11, Batch 300] loss: 0.0762259207200259
[Epoch 11, Batch 400] loss: 0.07413179492577911
**STATS for Epoch 11** : 
Average training loss: 0.0121
Average validation loss: 0.0902
Validation Accuracy: 0.9722
Overfitting: 0.0780
Best model saved at epoch 11 with validation loss: 0.0902
[Epoch 12, Batch 100] loss: 0.07074354602023959
[Epoch 12, Batch 200] loss: 0.07692296421155334
[Epoch 12, Batch 300] loss: 0.07407324482686818
[Epoch 12, Batch 400] loss: 0.07580901963636279
**STATS for Epoch 12** : 
Average training loss: 0.0107
Average validation loss: 0.0883
Validation Accuracy: 0.9732
Overfitting: 0.0775
Best model saved at epoch 12 with validation loss: 0.0883
[Epoch 13, Batch 100] loss: 0.06881316826213152
[Epoch 13, Batch 200] loss: 0.06554249768145383
[Epoch 13, Batch 300] loss: 0.07157097708433867
[Epoch 13, Batch 400] loss: 0.06971847478765994
**STATS for Epoch 13** : 
Average training loss: 0.0098
Average validation loss: 0.0810
Validation Accuracy: 0.9758
Overfitting: 0.0712
Best model saved at epoch 13 with validation loss: 0.0810
[Epoch 14, Batch 100] loss: 0.06562157965730876
[Epoch 14, Batch 200] loss: 0.06541564472019673
[Epoch 14, Batch 300] loss: 0.06390091620385646
[Epoch 14, Batch 400] loss: 0.06522846788866446
**STATS for Epoch 14** : 
Average training loss: 0.0091
Average validation loss: 0.0821
Validation Accuracy: 0.9741
Overfitting: 0.0729
[Epoch 15, Batch 100] loss: 0.05640616879798472
[Epoch 15, Batch 200] loss: 0.05413244124967605
[Epoch 15, Batch 300] loss: 0.06350540756713599
[Epoch 15, Batch 400] loss: 0.07220255385152996
**STATS for Epoch 15** : 
Average training loss: 0.0083
Average validation loss: 0.0804
Validation Accuracy: 0.9748
Overfitting: 0.0721
Best model saved at epoch 15 with validation loss: 0.0804
[Epoch 16, Batch 100] loss: 0.055276322029531005
[Epoch 16, Batch 200] loss: 0.05925036575645208
[Epoch 16, Batch 300] loss: 0.055791746792383495
[Epoch 16, Batch 400] loss: 0.056356088137254116
**STATS for Epoch 16** : 
Average training loss: 0.0093
Average validation loss: 0.0810
Validation Accuracy: 0.9751
Overfitting: 0.0716
[Epoch 17, Batch 100] loss: 0.054320310950279234
[Epoch 17, Batch 200] loss: 0.05436384123750031
[Epoch 17, Batch 300] loss: 0.05205252410378307
[Epoch 17, Batch 400] loss: 0.052009115614928304
**STATS for Epoch 17** : 
Average training loss: 0.0085
Average validation loss: 0.0768
Validation Accuracy: 0.9761
Overfitting: 0.0682
Best model saved at epoch 17 with validation loss: 0.0768
[Epoch 18, Batch 100] loss: 0.048268603140022605
[Epoch 18, Batch 200] loss: 0.05555257579311729
[Epoch 18, Batch 300] loss: 0.04576616511214524
[Epoch 18, Batch 400] loss: 0.05933879546821117
**STATS for Epoch 18** : 
Average training loss: 0.0067
Average validation loss: 0.0685
Validation Accuracy: 0.9787
Overfitting: 0.0618
Best model saved at epoch 18 with validation loss: 0.0685
[Epoch 19, Batch 100] loss: 0.04372830885462463
[Epoch 19, Batch 200] loss: 0.051565860533155504
[Epoch 19, Batch 300] loss: 0.041656080642715095
[Epoch 19, Batch 400] loss: 0.056604508182499555
**STATS for Epoch 19** : 
Average training loss: 0.0079
Average validation loss: 0.0721
Validation Accuracy: 0.9770
Overfitting: 0.0642
[Epoch 20, Batch 100] loss: 0.04179363049333915
[Epoch 20, Batch 200] loss: 0.05298354720696807
[Epoch 20, Batch 300] loss: 0.049066874650307
[Epoch 20, Batch 400] loss: 0.04484615719411522
**STATS for Epoch 20** : 
Average training loss: 0.0067
Average validation loss: 0.0679
Validation Accuracy: 0.9790
Overfitting: 0.0612
Best model saved at epoch 20 with validation loss: 0.0679
[Epoch 21, Batch 100] loss: 0.04634009338449687
[Epoch 21, Batch 200] loss: 0.042389753358438614
[Epoch 21, Batch 300] loss: 0.04143880358198657
[Epoch 21, Batch 400] loss: 0.044801485727075485
**STATS for Epoch 21** : 
Average training loss: 0.0064
Average validation loss: 0.0715
Validation Accuracy: 0.9784
Overfitting: 0.0651
[Epoch 22, Batch 100] loss: 0.0378775767586194
[Epoch 22, Batch 200] loss: 0.04571532274596393
[Epoch 22, Batch 300] loss: 0.040249937900807706
[Epoch 22, Batch 400] loss: 0.042820302327163516
**STATS for Epoch 22** : 
Average training loss: 0.0068
Average validation loss: 0.0697
Validation Accuracy: 0.9783
Overfitting: 0.0629
[Epoch 23, Batch 100] loss: 0.038498810473829505
[Epoch 23, Batch 200] loss: 0.041239613555371764
[Epoch 23, Batch 300] loss: 0.03743982685729861
[Epoch 23, Batch 400] loss: 0.03943863551481627
**STATS for Epoch 23** : 
Average training loss: 0.0060
Average validation loss: 0.0649
Validation Accuracy: 0.9800
Overfitting: 0.0589
Best model saved at epoch 23 with validation loss: 0.0649
[Epoch 24, Batch 100] loss: 0.03614971352275461
[Epoch 24, Batch 200] loss: 0.036698902500793336
[Epoch 24, Batch 300] loss: 0.03380616839975119
[Epoch 24, Batch 400] loss: 0.04307226774282753
**STATS for Epoch 24** : 
Average training loss: 0.0058
Average validation loss: 0.0647
Validation Accuracy: 0.9802
Overfitting: 0.0588
Best model saved at epoch 24 with validation loss: 0.0647
Fold 1 validation loss: 0.0647
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.301577069759369
[Epoch 1, Batch 200] loss: 2.2897313404083253
[Epoch 1, Batch 300] loss: 2.27197035074234
[Epoch 1, Batch 400] loss: 2.231445631980896
**STATS for Epoch 1** : 
Average training loss: 0.3129
Average validation loss: 2.0261
Validation Accuracy: 0.5513
Overfitting: 1.7132
Best model saved at epoch 1 with validation loss: 2.0261
[Epoch 2, Batch 100] loss: 1.6927901589870453
[Epoch 2, Batch 200] loss: 0.86929572224617
[Epoch 2, Batch 300] loss: 0.5734232223033905
[Epoch 2, Batch 400] loss: 0.4676628741621971
**STATS for Epoch 2** : 
Average training loss: 0.0629
Average validation loss: 0.4280
Validation Accuracy: 0.8688
Overfitting: 0.3650
Best model saved at epoch 2 with validation loss: 0.4280
[Epoch 3, Batch 100] loss: 0.4100304900109768
[Epoch 3, Batch 200] loss: 0.36861410334706307
[Epoch 3, Batch 300] loss: 0.3378102779388428
[Epoch 3, Batch 400] loss: 0.3091370186209679
**STATS for Epoch 3** : 
Average training loss: 0.0395
Average validation loss: 0.2745
Validation Accuracy: 0.9177
Overfitting: 0.2349
Best model saved at epoch 3 with validation loss: 0.2745
[Epoch 4, Batch 100] loss: 0.26528076104819776
[Epoch 4, Batch 200] loss: 0.26072947926819323
[Epoch 4, Batch 300] loss: 0.23126150235533716
[Epoch 4, Batch 400] loss: 0.22843882374465466
**STATS for Epoch 4** : 
Average training loss: 0.0308
Average validation loss: 0.2121
Validation Accuracy: 0.9354
Overfitting: 0.1812
Best model saved at epoch 4 with validation loss: 0.2121
[Epoch 5, Batch 100] loss: 0.2033607641607523
[Epoch 5, Batch 200] loss: 0.20451675809919834
[Epoch 5, Batch 300] loss: 0.19079011522233486
[Epoch 5, Batch 400] loss: 0.1799224441871047
**STATS for Epoch 5** : 
Average training loss: 0.0245
Average validation loss: 0.1761
Validation Accuracy: 0.9462
Overfitting: 0.1516
Best model saved at epoch 5 with validation loss: 0.1761
[Epoch 6, Batch 100] loss: 0.16510186560451984
[Epoch 6, Batch 200] loss: 0.1574891620501876
[Epoch 6, Batch 300] loss: 0.14953167647123336
[Epoch 6, Batch 400] loss: 0.15093796323984862
**STATS for Epoch 6** : 
Average training loss: 0.0237
Average validation loss: 0.1657
Validation Accuracy: 0.9502
Overfitting: 0.1420
Best model saved at epoch 6 with validation loss: 0.1657
[Epoch 7, Batch 100] loss: 0.1420207111351192
[Epoch 7, Batch 200] loss: 0.13980302438139916
[Epoch 7, Batch 300] loss: 0.13484762804582714
[Epoch 7, Batch 400] loss: 0.12541264169849456
**STATS for Epoch 7** : 
Average training loss: 0.0192
Average validation loss: 0.1513
Validation Accuracy: 0.9515
Overfitting: 0.1321
Best model saved at epoch 7 with validation loss: 0.1513
[Epoch 8, Batch 100] loss: 0.1131020037084818
[Epoch 8, Batch 200] loss: 0.12180377226322889
[Epoch 8, Batch 300] loss: 0.12141903327777982
[Epoch 8, Batch 400] loss: 0.11947782311588526
**STATS for Epoch 8** : 
Average training loss: 0.0170
Average validation loss: 0.1235
Validation Accuracy: 0.9625
Overfitting: 0.1064
Best model saved at epoch 8 with validation loss: 0.1235
[Epoch 9, Batch 100] loss: 0.11063734877854586
[Epoch 9, Batch 200] loss: 0.09738373793661595
[Epoch 9, Batch 300] loss: 0.11067161174491048
[Epoch 9, Batch 400] loss: 0.10140190158970654
**STATS for Epoch 9** : 
Average training loss: 0.0163
Average validation loss: 0.1118
Validation Accuracy: 0.9645
Overfitting: 0.0956
Best model saved at epoch 9 with validation loss: 0.1118
[Epoch 10, Batch 100] loss: 0.08573702812194824
[Epoch 10, Batch 200] loss: 0.10835132298991085
[Epoch 10, Batch 300] loss: 0.09526123959571123
[Epoch 10, Batch 400] loss: 0.09773555617779493
**STATS for Epoch 10** : 
Average training loss: 0.0146
Average validation loss: 0.1394
Validation Accuracy: 0.9577
Overfitting: 0.1248
[Epoch 11, Batch 100] loss: 0.09483062016777694
[Epoch 11, Batch 200] loss: 0.08705480121076108
[Epoch 11, Batch 300] loss: 0.09167381569743156
[Epoch 11, Batch 400] loss: 0.08697449615225196
**STATS for Epoch 11** : 
Average training loss: 0.0123
Average validation loss: 0.0922
Validation Accuracy: 0.9718
Overfitting: 0.0799
Best model saved at epoch 11 with validation loss: 0.0922
[Epoch 12, Batch 100] loss: 0.08567619690671563
[Epoch 12, Batch 200] loss: 0.0772312599234283
[Epoch 12, Batch 300] loss: 0.074899474196136
[Epoch 12, Batch 400] loss: 0.08702427291311324
**STATS for Epoch 12** : 
Average training loss: 0.0124
Average validation loss: 0.0963
Validation Accuracy: 0.9699
Overfitting: 0.0839
[Epoch 13, Batch 100] loss: 0.07795025289058685
[Epoch 13, Batch 200] loss: 0.06972028224729002
[Epoch 13, Batch 300] loss: 0.08361388463526964
[Epoch 13, Batch 400] loss: 0.06886871392838657
**STATS for Epoch 13** : 
Average training loss: 0.0123
Average validation loss: 0.0842
Validation Accuracy: 0.9739
Overfitting: 0.0719
Best model saved at epoch 13 with validation loss: 0.0842
[Epoch 14, Batch 100] loss: 0.07356303699780256
[Epoch 14, Batch 200] loss: 0.07429908256977796
[Epoch 14, Batch 300] loss: 0.07668790109455585
[Epoch 14, Batch 400] loss: 0.07298107896000147
**STATS for Epoch 14** : 
Average training loss: 0.0093
Average validation loss: 0.0815
Validation Accuracy: 0.9758
Overfitting: 0.0721
Best model saved at epoch 14 with validation loss: 0.0815
[Epoch 15, Batch 100] loss: 0.06082959416788072
[Epoch 15, Batch 200] loss: 0.06582956335041672
[Epoch 15, Batch 300] loss: 0.07165780492126941
[Epoch 15, Batch 400] loss: 0.06348691653925925
**STATS for Epoch 15** : 
Average training loss: 0.0111
Average validation loss: 0.0837
Validation Accuracy: 0.9737
Overfitting: 0.0726
[Epoch 16, Batch 100] loss: 0.061813731179572645
[Epoch 16, Batch 200] loss: 0.06039697063155472
[Epoch 16, Batch 300] loss: 0.06434001034358516
[Epoch 16, Batch 400] loss: 0.06816288105910644
**STATS for Epoch 16** : 
Average training loss: 0.0113
Average validation loss: 0.0858
Validation Accuracy: 0.9738
Overfitting: 0.0745
[Epoch 17, Batch 100] loss: 0.0594739030348137
[Epoch 17, Batch 200] loss: 0.057031792388297614
[Epoch 17, Batch 300] loss: 0.06916211361065507
[Epoch 17, Batch 400] loss: 0.05962326443288475
**STATS for Epoch 17** : 
Average training loss: 0.0087
Average validation loss: 0.0768
Validation Accuracy: 0.9754
Overfitting: 0.0681
Best model saved at epoch 17 with validation loss: 0.0768
[Epoch 18, Batch 100] loss: 0.05973546944092959
[Epoch 18, Batch 200] loss: 0.06300343068083748
[Epoch 18, Batch 300] loss: 0.061261319741606715
[Epoch 18, Batch 400] loss: 0.051635429835878315
**STATS for Epoch 18** : 
Average training loss: 0.0083
Average validation loss: 0.0735
Validation Accuracy: 0.9772
Overfitting: 0.0653
Best model saved at epoch 18 with validation loss: 0.0735
[Epoch 19, Batch 100] loss: 0.06083502061665058
[Epoch 19, Batch 200] loss: 0.049041186636313794
[Epoch 19, Batch 300] loss: 0.05319064027164131
[Epoch 19, Batch 400] loss: 0.05681382894515991
**STATS for Epoch 19** : 
Average training loss: 0.0071
Average validation loss: 0.0730
Validation Accuracy: 0.9776
Overfitting: 0.0659
Best model saved at epoch 19 with validation loss: 0.0730
[Epoch 20, Batch 100] loss: 0.04475830870680511
[Epoch 20, Batch 200] loss: 0.05706612471723929
[Epoch 20, Batch 300] loss: 0.05733196294633672
[Epoch 20, Batch 400] loss: 0.05544278814457357
**STATS for Epoch 20** : 
Average training loss: 0.0071
Average validation loss: 0.0735
Validation Accuracy: 0.9778
Overfitting: 0.0664
[Epoch 21, Batch 100] loss: 0.04713404047070071
[Epoch 21, Batch 200] loss: 0.05145812161266804
[Epoch 21, Batch 300] loss: 0.04841386576648801
[Epoch 21, Batch 400] loss: 0.0480447021801956
**STATS for Epoch 21** : 
Average training loss: 0.0069
Average validation loss: 0.0698
Validation Accuracy: 0.9795
Overfitting: 0.0629
Best model saved at epoch 21 with validation loss: 0.0698
[Epoch 22, Batch 100] loss: 0.05042141533922404
[Epoch 22, Batch 200] loss: 0.040891594267450274
[Epoch 22, Batch 300] loss: 0.04439977510133758
[Epoch 22, Batch 400] loss: 0.05351813672343269
**STATS for Epoch 22** : 
Average training loss: 0.0060
Average validation loss: 0.0762
Validation Accuracy: 0.9752
Overfitting: 0.0702
[Epoch 23, Batch 100] loss: 0.04505827843211591
[Epoch 23, Batch 200] loss: 0.04760671745520085
[Epoch 23, Batch 300] loss: 0.05009849664056674
[Epoch 23, Batch 400] loss: 0.03971403266303241
**STATS for Epoch 23** : 
Average training loss: 0.0062
Average validation loss: 0.0649
Validation Accuracy: 0.9803
Overfitting: 0.0587
Best model saved at epoch 23 with validation loss: 0.0649
[Epoch 24, Batch 100] loss: 0.046491175992414355
[Epoch 24, Batch 200] loss: 0.04240845130989328
[Epoch 24, Batch 300] loss: 0.03945518204942346
[Epoch 24, Batch 400] loss: 0.04413068068912253
**STATS for Epoch 24** : 
Average training loss: 0.0059
Average validation loss: 0.0670
Validation Accuracy: 0.9805
Overfitting: 0.0611
Fold 2 validation loss: 0.0670
Mean validation loss across all folds for Trial 13 is 0.0658 with trial config:  l1: 256, l2: 128, lr: 0.0007380817523374673, batch_size: 64
[I 2024-11-21 19:39:11,415] Trial 12 finished with value: 0.06583501209220938 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0007380817523374673, 'batch_size': 64}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 14:
  l1: 128, l2: 128, lr: 0.0011062854566266248, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2988746190071105
[Epoch 1, Batch 200] loss: 2.285942153930664
[Epoch 1, Batch 300] loss: 2.263516802787781
[Epoch 1, Batch 400] loss: 2.187808299064636
[Epoch 1, Batch 500] loss: 1.7469569909572602
[Epoch 1, Batch 600] loss: 0.7199383407831192
[Epoch 1, Batch 700] loss: 0.5304681631922722
[Epoch 1, Batch 800] loss: 0.43277469888329506
[Epoch 1, Batch 900] loss: 0.37883154608309266
[Epoch 1, Batch 1000] loss: 0.32267001520842314
[Epoch 1, Batch 1100] loss: 0.27885506618767975
[Epoch 1, Batch 1200] loss: 0.25078625258058307
[Epoch 1, Batch 1300] loss: 0.26104381067678334
[Epoch 1, Batch 1400] loss: 0.2120300710387528
[Epoch 1, Batch 1500] loss: 0.2041825664881617
[Epoch 1, Batch 1600] loss: 0.1803535362891853
[Epoch 1, Batch 1700] loss: 0.2065463122073561
[Epoch 1, Batch 1800] loss: 0.17216371460584923
**STATS for Epoch 1** : 
Average training loss: 0.0073
Average validation loss: 0.1726
Validation Accuracy: 0.9463
Overfitting: 0.1653
Best model saved at epoch 1 with validation loss: 0.1726
[Epoch 2, Batch 100] loss: 0.14077453555073588
[Epoch 2, Batch 200] loss: 0.16028781446628274
[Epoch 2, Batch 300] loss: 0.16215644526761025
[Epoch 2, Batch 400] loss: 0.16318611915688963
[Epoch 2, Batch 500] loss: 0.13734937290661037
[Epoch 2, Batch 600] loss: 0.13150786696467548
[Epoch 2, Batch 700] loss: 0.13920710205100476
[Epoch 2, Batch 800] loss: 0.11228486232808792
[Epoch 2, Batch 900] loss: 0.10327292803674937
[Epoch 2, Batch 1000] loss: 0.12138847625348717
[Epoch 2, Batch 1100] loss: 0.12662976594408973
[Epoch 2, Batch 1200] loss: 0.12966041481355206
[Epoch 2, Batch 1300] loss: 0.11165149173000827
[Epoch 2, Batch 1400] loss: 0.13309802850009875
[Epoch 2, Batch 1500] loss: 0.09858334231423214
[Epoch 2, Batch 1600] loss: 0.11264832613989711
[Epoch 2, Batch 1700] loss: 0.11614914808887988
[Epoch 2, Batch 1800] loss: 0.10328621486900375
**STATS for Epoch 2** : 
Average training loss: 0.0048
Average validation loss: 0.0989
Validation Accuracy: 0.9689
Overfitting: 0.0941
Best model saved at epoch 2 with validation loss: 0.0989
[Epoch 3, Batch 100] loss: 0.08824563137022778
[Epoch 3, Batch 200] loss: 0.10333778342232108
[Epoch 3, Batch 300] loss: 0.08591046088724397
[Epoch 3, Batch 400] loss: 0.1076234897854738
[Epoch 3, Batch 500] loss: 0.09326799453119747
[Epoch 3, Batch 600] loss: 0.0759383609239012
[Epoch 3, Batch 700] loss: 0.07972976072924212
[Epoch 3, Batch 800] loss: 0.10177678628242574
[Epoch 3, Batch 900] loss: 0.11361989329103381
[Epoch 3, Batch 1000] loss: 0.09093906768248416
[Epoch 3, Batch 1100] loss: 0.0808043401458417
[Epoch 3, Batch 1200] loss: 0.07757094407919794
[Epoch 3, Batch 1300] loss: 0.09678959484328516
[Epoch 3, Batch 1400] loss: 0.06088462779240217
[Epoch 3, Batch 1500] loss: 0.07478038224915508
[Epoch 3, Batch 1600] loss: 0.0900810565194115
[Epoch 3, Batch 1700] loss: 0.07795019199664238
[Epoch 3, Batch 1800] loss: 0.08981225483876187
**STATS for Epoch 3** : 
Average training loss: 0.0040
Average validation loss: 0.0807
Validation Accuracy: 0.9745
Overfitting: 0.0766
Best model saved at epoch 3 with validation loss: 0.0807
[Epoch 4, Batch 100] loss: 0.06638488981407135
[Epoch 4, Batch 200] loss: 0.07185675696207909
[Epoch 4, Batch 300] loss: 0.08408158456673846
[Epoch 4, Batch 400] loss: 0.06222007164265961
[Epoch 4, Batch 500] loss: 0.08077010292792693
[Epoch 4, Batch 600] loss: 0.09912091519159731
[Epoch 4, Batch 700] loss: 0.07455124138621613
[Epoch 4, Batch 800] loss: 0.07569730131712277
[Epoch 4, Batch 900] loss: 0.055231936363270506
[Epoch 4, Batch 1000] loss: 0.06653750024968758
[Epoch 4, Batch 1100] loss: 0.07099399621540214
[Epoch 4, Batch 1200] loss: 0.07564650165033526
[Epoch 4, Batch 1300] loss: 0.06393079225905239
[Epoch 4, Batch 1400] loss: 0.0660006960798637
[Epoch 4, Batch 1500] loss: 0.05429352721897885
[Epoch 4, Batch 1600] loss: 0.06358938124903943
[Epoch 4, Batch 1700] loss: 0.07061425790539942
[Epoch 4, Batch 1800] loss: 0.08130682224989869
**STATS for Epoch 4** : 
Average training loss: 0.0013
Average validation loss: 0.0690
Validation Accuracy: 0.9786
Overfitting: 0.0677
Best model saved at epoch 4 with validation loss: 0.0690
[Epoch 5, Batch 100] loss: 0.05080296981905121
[Epoch 5, Batch 200] loss: 0.06321655991836451
[Epoch 5, Batch 300] loss: 0.04823134971782565
[Epoch 5, Batch 400] loss: 0.04747452647425234
[Epoch 5, Batch 500] loss: 0.054967331892403305
[Epoch 5, Batch 600] loss: 0.0536175006016856
[Epoch 5, Batch 700] loss: 0.05164981324633118
[Epoch 5, Batch 800] loss: 0.05943174939835444
[Epoch 5, Batch 900] loss: 0.05465293662447948
[Epoch 5, Batch 1000] loss: 0.06967306508566252
[Epoch 5, Batch 1100] loss: 0.04763200380490162
[Epoch 5, Batch 1200] loss: 0.0632160566415405
[Epoch 5, Batch 1300] loss: 0.06628262517246185
[Epoch 5, Batch 1400] loss: 0.054029548557009546
[Epoch 5, Batch 1500] loss: 0.07150120827718638
[Epoch 5, Batch 1600] loss: 0.07932998837670312
[Epoch 5, Batch 1700] loss: 0.050450779180973765
[Epoch 5, Batch 1800] loss: 0.05882945574849145
**STATS for Epoch 5** : 
Average training loss: 0.0022
Average validation loss: 0.0666
Validation Accuracy: 0.9785
Overfitting: 0.0644
Best model saved at epoch 5 with validation loss: 0.0666
[Epoch 6, Batch 100] loss: 0.036528754707978804
[Epoch 6, Batch 200] loss: 0.04651213059551083
[Epoch 6, Batch 300] loss: 0.04022037135524442
[Epoch 6, Batch 400] loss: 0.04408383260437404
[Epoch 6, Batch 500] loss: 0.06266074769722764
[Epoch 6, Batch 600] loss: 0.050991347781964576
[Epoch 6, Batch 700] loss: 0.058352687416772825
[Epoch 6, Batch 800] loss: 0.05399680479313247
[Epoch 6, Batch 900] loss: 0.05041361416748259
[Epoch 6, Batch 1000] loss: 0.03415320658008568
[Epoch 6, Batch 1100] loss: 0.04252515773347113
[Epoch 6, Batch 1200] loss: 0.05557842609239742
[Epoch 6, Batch 1300] loss: 0.052129419861157655
[Epoch 6, Batch 1400] loss: 0.048291594684123994
[Epoch 6, Batch 1500] loss: 0.05234198748890776
[Epoch 6, Batch 1600] loss: 0.05773297085775994
[Epoch 6, Batch 1700] loss: 0.04872494599112542
[Epoch 6, Batch 1800] loss: 0.045091023875575044
**STATS for Epoch 6** : 
Average training loss: 0.0022
Average validation loss: 0.0667
Validation Accuracy: 0.9795
Overfitting: 0.0645
[Epoch 7, Batch 100] loss: 0.04246029828034807
[Epoch 7, Batch 200] loss: 0.03217289844309562
[Epoch 7, Batch 300] loss: 0.044711228456581015
[Epoch 7, Batch 400] loss: 0.05126157129969215
[Epoch 7, Batch 500] loss: 0.03926698933675652
[Epoch 7, Batch 600] loss: 0.04339337284451176
[Epoch 7, Batch 700] loss: 0.040050930772922586
[Epoch 7, Batch 800] loss: 0.04201322090520989
[Epoch 7, Batch 900] loss: 0.0354262471444963
[Epoch 7, Batch 1000] loss: 0.04331369511754019
[Epoch 7, Batch 1100] loss: 0.039229598161691685
[Epoch 7, Batch 1200] loss: 0.027739994794756057
[Epoch 7, Batch 1300] loss: 0.047676314913260284
[Epoch 7, Batch 1400] loss: 0.036773719849297774
[Epoch 7, Batch 1500] loss: 0.04088302735530305
[Epoch 7, Batch 1600] loss: 0.036440974881115834
[Epoch 7, Batch 1700] loss: 0.04853950366890786
[Epoch 7, Batch 1800] loss: 0.049479652368609094
**STATS for Epoch 7** : 
Average training loss: 0.0017
Average validation loss: 0.1030
Validation Accuracy: 0.9708
Overfitting: 0.1013
[Epoch 8, Batch 100] loss: 0.04423167013650527
[Epoch 8, Batch 200] loss: 0.03566105559264542
[Epoch 8, Batch 300] loss: 0.04334391781827435
[Epoch 8, Batch 400] loss: 0.03568790094985161
[Epoch 8, Batch 500] loss: 0.03954640307696536
[Epoch 8, Batch 600] loss: 0.036333924535720145
[Epoch 8, Batch 700] loss: 0.036490014022965624
[Epoch 8, Batch 800] loss: 0.043193769947320104
[Epoch 8, Batch 900] loss: 0.036033414015109885
[Epoch 8, Batch 1000] loss: 0.025776322258316213
[Epoch 8, Batch 1100] loss: 0.030731854413461407
[Epoch 8, Batch 1200] loss: 0.040834335856779945
[Epoch 8, Batch 1300] loss: 0.025317491849782527
[Epoch 8, Batch 1400] loss: 0.02861359978072869
[Epoch 8, Batch 1500] loss: 0.03564633016212611
[Epoch 8, Batch 1600] loss: 0.03407990986466757
[Epoch 8, Batch 1700] loss: 0.03534640691323147
[Epoch 8, Batch 1800] loss: 0.0383529705402907
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0642
Validation Accuracy: 0.9814
Overfitting: 0.0618
Best model saved at epoch 8 with validation loss: 0.0642
[Epoch 9, Batch 100] loss: 0.0289679592619359
[Epoch 9, Batch 200] loss: 0.028361688456789123
[Epoch 9, Batch 300] loss: 0.028191373490553815
[Epoch 9, Batch 400] loss: 0.027635941059852485
[Epoch 9, Batch 500] loss: 0.01840353507301188
[Epoch 9, Batch 600] loss: 0.027208162902315963
[Epoch 9, Batch 700] loss: 0.04130408827390056
[Epoch 9, Batch 800] loss: 0.03629647744091926
[Epoch 9, Batch 900] loss: 0.037166306862782224
[Epoch 9, Batch 1000] loss: 0.026125389195804018
[Epoch 9, Batch 1100] loss: 0.0228601582814008
[Epoch 9, Batch 1200] loss: 0.03256497312890133
[Epoch 9, Batch 1300] loss: 0.039903817077720304
[Epoch 9, Batch 1400] loss: 0.028714491480131984
[Epoch 9, Batch 1500] loss: 0.02875764951793826
[Epoch 9, Batch 1600] loss: 0.026446152692078614
[Epoch 9, Batch 1700] loss: 0.053868912701582304
[Epoch 9, Batch 1800] loss: 0.030220638684913866
**STATS for Epoch 9** : 
Average training loss: 0.0010
Average validation loss: 0.0600
Validation Accuracy: 0.9817
Overfitting: 0.0590
Best model saved at epoch 9 with validation loss: 0.0600
[Epoch 10, Batch 100] loss: 0.02870715280467266
[Epoch 10, Batch 200] loss: 0.019898137289674198
[Epoch 10, Batch 300] loss: 0.02728356412728317
[Epoch 10, Batch 400] loss: 0.0158695647733839
[Epoch 10, Batch 500] loss: 0.028979703708719173
[Epoch 10, Batch 600] loss: 0.0268524986958073
[Epoch 10, Batch 700] loss: 0.02891921123795328
[Epoch 10, Batch 800] loss: 0.019482870283864032
[Epoch 10, Batch 900] loss: 0.030733669719775206
[Epoch 10, Batch 1000] loss: 0.03214568069794041
[Epoch 10, Batch 1100] loss: 0.035644838632870234
[Epoch 10, Batch 1200] loss: 0.023952436345862225
[Epoch 10, Batch 1300] loss: 0.024483395529241534
[Epoch 10, Batch 1400] loss: 0.035297836548124906
[Epoch 10, Batch 1500] loss: 0.02754960006175679
[Epoch 10, Batch 1600] loss: 0.02448599441086117
[Epoch 10, Batch 1700] loss: 0.03277382839434722
[Epoch 10, Batch 1800] loss: 0.020715681321453305
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0540
Validation Accuracy: 0.9832
Overfitting: 0.0524
Best model saved at epoch 10 with validation loss: 0.0540
[Epoch 11, Batch 100] loss: 0.018588046357454004
[Epoch 11, Batch 200] loss: 0.015352660942262446
[Epoch 11, Batch 300] loss: 0.02229367268169881
[Epoch 11, Batch 400] loss: 0.02553735600238724
[Epoch 11, Batch 500] loss: 0.038259795540725464
[Epoch 11, Batch 600] loss: 0.021695844134446817
[Epoch 11, Batch 700] loss: 0.012432842173648168
[Epoch 11, Batch 800] loss: 0.020533031237555406
[Epoch 11, Batch 900] loss: 0.013712416647758801
[Epoch 11, Batch 1000] loss: 0.008860222290895763
[Epoch 11, Batch 1100] loss: 0.017184468188806933
[Epoch 11, Batch 1200] loss: 0.01967841718947966
[Epoch 11, Batch 1300] loss: 0.0384252339278828
[Epoch 11, Batch 1400] loss: 0.02493993678070183
[Epoch 11, Batch 1500] loss: 0.01770602642613085
[Epoch 11, Batch 1600] loss: 0.02549935159164306
[Epoch 11, Batch 1700] loss: 0.0224270061635616
[Epoch 11, Batch 1800] loss: 0.02299000236107531
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0592
Validation Accuracy: 0.9825
Overfitting: 0.0580
[Epoch 12, Batch 100] loss: 0.022915987720825797
[Epoch 12, Batch 200] loss: 0.018385282362614816
[Epoch 12, Batch 300] loss: 0.01585567273741617
[Epoch 12, Batch 400] loss: 0.017543258738389796
[Epoch 12, Batch 500] loss: 0.020754331612224633
[Epoch 12, Batch 600] loss: 0.013382974029882462
[Epoch 12, Batch 700] loss: 0.01239230144839894
[Epoch 12, Batch 800] loss: 0.02284438643247995
[Epoch 12, Batch 900] loss: 0.026959831098938594
[Epoch 12, Batch 1000] loss: 0.017519709242842508
[Epoch 12, Batch 1100] loss: 0.022723491032047606
[Epoch 12, Batch 1200] loss: 0.019564130200051294
[Epoch 12, Batch 1300] loss: 0.02664598394514542
[Epoch 12, Batch 1400] loss: 0.013686167749183369
[Epoch 12, Batch 1500] loss: 0.01906637549967854
[Epoch 12, Batch 1600] loss: 0.009895270464839996
[Epoch 12, Batch 1700] loss: 0.02169998105529885
[Epoch 12, Batch 1800] loss: 0.02608855092203157
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0577
Validation Accuracy: 0.9834
Overfitting: 0.0563
[Epoch 13, Batch 100] loss: 0.017334892878461686
[Epoch 13, Batch 200] loss: 0.01060916402242583
[Epoch 13, Batch 300] loss: 0.012809831180820765
[Epoch 13, Batch 400] loss: 0.01614157551599874
[Epoch 13, Batch 500] loss: 0.015566739436271746
[Epoch 13, Batch 600] loss: 0.016769686833868036
[Epoch 13, Batch 700] loss: 0.011395740189655043
[Epoch 13, Batch 800] loss: 0.01769841589339194
[Epoch 13, Batch 900] loss: 0.013988812317329576
[Epoch 13, Batch 1000] loss: 0.011487706375719426
[Epoch 13, Batch 1100] loss: 0.021458138218995372
[Epoch 13, Batch 1200] loss: 0.013086661708257452
[Epoch 13, Batch 1300] loss: 0.030989033353698688
[Epoch 13, Batch 1400] loss: 0.009779599515477458
[Epoch 13, Batch 1500] loss: 0.01395815022622628
[Epoch 13, Batch 1600] loss: 0.01349991936871902
[Epoch 13, Batch 1700] loss: 0.022020083068237
[Epoch 13, Batch 1800] loss: 0.013141001664862414
**STATS for Epoch 13** : 
Average training loss: 0.0012
Average validation loss: 0.0710
Validation Accuracy: 0.9802
Overfitting: 0.0699
[Epoch 14, Batch 100] loss: 0.015538665025997035
[Epoch 14, Batch 200] loss: 0.008239212105527258
[Epoch 14, Batch 300] loss: 0.010949181876021612
[Epoch 14, Batch 400] loss: 0.008577696472730167
[Epoch 14, Batch 500] loss: 0.013994876984443181
[Epoch 14, Batch 600] loss: 0.007236890919648431
[Epoch 14, Batch 700] loss: 0.02265952390991515
[Epoch 14, Batch 800] loss: 0.012429858220020833
[Epoch 14, Batch 900] loss: 0.016007912196473625
[Epoch 14, Batch 1000] loss: 0.01620679240884783
[Epoch 14, Batch 1100] loss: 0.02330857327870035
[Epoch 14, Batch 1200] loss: 0.016369204807015193
[Epoch 14, Batch 1300] loss: 0.015804768331618105
[Epoch 14, Batch 1400] loss: 0.008435224341192225
[Epoch 14, Batch 1500] loss: 0.024900642121538114
[Epoch 14, Batch 1600] loss: 0.01816573182037246
[Epoch 14, Batch 1700] loss: 0.011589043485209914
[Epoch 14, Batch 1800] loss: 0.011358294868869053
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0545
Validation Accuracy: 0.9858
Overfitting: 0.0540
[Epoch 15, Batch 100] loss: 0.017186544607575342
[Epoch 15, Batch 200] loss: 0.01464393454223682
[Epoch 15, Batch 300] loss: 0.014317347085416259
[Epoch 15, Batch 400] loss: 0.004431807643568391
[Epoch 15, Batch 500] loss: 0.008956113807034854
[Epoch 15, Batch 600] loss: 0.019257048475647024
[Epoch 15, Batch 700] loss: 0.01399418765680366
[Epoch 15, Batch 800] loss: 0.021748574380471838
[Epoch 15, Batch 900] loss: 0.019309095081443958
[Epoch 15, Batch 1000] loss: 0.008965283287361672
[Epoch 15, Batch 1100] loss: 0.019118053912106917
[Epoch 15, Batch 1200] loss: 0.01553586221187743
[Epoch 15, Batch 1300] loss: 0.007896483270578757
[Epoch 15, Batch 1400] loss: 0.004709888344414139
[Epoch 15, Batch 1500] loss: 0.011178304150444091
[Epoch 15, Batch 1600] loss: 0.012808158069726688
[Epoch 15, Batch 1700] loss: 0.01592929330057359
[Epoch 15, Batch 1800] loss: 0.016176161061730455
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0696
Validation Accuracy: 0.9820
Overfitting: 0.0691
[Epoch 16, Batch 100] loss: 0.008503894275545463
[Epoch 16, Batch 200] loss: 0.010029643766026766
[Epoch 16, Batch 300] loss: 0.010781235690328685
[Epoch 16, Batch 400] loss: 0.007168619477643006
[Epoch 16, Batch 500] loss: 0.009402299800103719
[Epoch 16, Batch 600] loss: 0.008092697793954358
[Epoch 16, Batch 700] loss: 0.018082794321762775
[Epoch 16, Batch 800] loss: 0.007900373198363014
[Epoch 16, Batch 900] loss: 0.015604404213700036
[Epoch 16, Batch 1000] loss: 0.006752572122622951
[Epoch 16, Batch 1100] loss: 0.011714299915320225
[Epoch 16, Batch 1200] loss: 0.015039914791150294
[Epoch 16, Batch 1300] loss: 0.009515522241381405
[Epoch 16, Batch 1400] loss: 0.019774827820310748
[Epoch 16, Batch 1500] loss: 0.015398398766737955
[Epoch 16, Batch 1600] loss: 0.0133213570249427
[Epoch 16, Batch 1700] loss: 0.012798871889790462
[Epoch 16, Batch 1800] loss: 0.006108837310757735
**STATS for Epoch 16** : 
Average training loss: 0.0002
Average validation loss: 0.0579
Validation Accuracy: 0.9853
Overfitting: 0.0577
[Epoch 17, Batch 100] loss: 0.00835146486829899
[Epoch 17, Batch 200] loss: 0.005421403278760408
[Epoch 17, Batch 300] loss: 0.0030651738086089606
[Epoch 17, Batch 400] loss: 0.009327262734974511
[Epoch 17, Batch 500] loss: 0.012019930687602027
[Epoch 17, Batch 600] loss: 0.010220060080173425
[Epoch 17, Batch 700] loss: 0.007044248876532037
[Epoch 17, Batch 800] loss: 0.014028827199173293
[Epoch 17, Batch 900] loss: 0.010642029223427017
[Epoch 17, Batch 1000] loss: 0.004476843273079112
[Epoch 17, Batch 1100] loss: 0.0052347922404464954
[Epoch 17, Batch 1200] loss: 0.00950801328365742
[Epoch 17, Batch 1300] loss: 0.006245361439114277
[Epoch 17, Batch 1400] loss: 0.009020347580963062
[Epoch 17, Batch 1500] loss: 0.013871404112003348
[Epoch 17, Batch 1600] loss: 0.015048092301955194
[Epoch 17, Batch 1700] loss: 0.012420115398963958
[Epoch 17, Batch 1800] loss: 0.008515619836050519
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0575
Validation Accuracy: 0.9858
Overfitting: 0.0571
[Epoch 18, Batch 100] loss: 0.006989943543835579
[Epoch 18, Batch 200] loss: 0.006716335349428846
[Epoch 18, Batch 300] loss: 0.006090758725574688
[Epoch 18, Batch 400] loss: 0.006658327050356547
[Epoch 18, Batch 500] loss: 0.003198181691561217
[Epoch 18, Batch 600] loss: 0.00749376566286628
[Epoch 18, Batch 700] loss: 0.003053148838997686
[Epoch 18, Batch 800] loss: 0.005370108127405047
[Epoch 18, Batch 900] loss: 0.008237402756369647
[Epoch 18, Batch 1000] loss: 0.003773027627016745
[Epoch 18, Batch 1100] loss: 0.012898008969171143
[Epoch 18, Batch 1200] loss: 0.006194496304618724
[Epoch 18, Batch 1300] loss: 0.004977434065269222
[Epoch 18, Batch 1400] loss: 0.008987513890060654
[Epoch 18, Batch 1500] loss: 0.01345077608660631
[Epoch 18, Batch 1600] loss: 0.005707141595673875
[Epoch 18, Batch 1700] loss: 0.002500378538647965
[Epoch 18, Batch 1800] loss: 0.010545844263789376
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0705
Validation Accuracy: 0.9824
Overfitting: 0.0701
[Epoch 19, Batch 100] loss: 0.006763737688283982
[Epoch 19, Batch 200] loss: 0.014078089352587995
[Epoch 19, Batch 300] loss: 0.004874631398432711
[Epoch 19, Batch 400] loss: 0.01085301682964655
[Epoch 19, Batch 500] loss: 0.019385658962707168
[Epoch 19, Batch 600] loss: 0.009732469431883146
[Epoch 19, Batch 700] loss: 0.0091213890940071
[Epoch 19, Batch 800] loss: 0.009077731816084907
[Epoch 19, Batch 900] loss: 0.007161443670845528
[Epoch 19, Batch 1000] loss: 0.008448310019111886
[Epoch 19, Batch 1100] loss: 0.0062197811190890205
[Epoch 19, Batch 1200] loss: 0.007169100122653162
[Epoch 19, Batch 1300] loss: 0.012437169992663257
[Epoch 19, Batch 1400] loss: 0.005882712811510942
[Epoch 19, Batch 1500] loss: 0.004670201328099211
[Epoch 19, Batch 1600] loss: 0.004051632623916248
[Epoch 19, Batch 1700] loss: 0.005614727079564546
[Epoch 19, Batch 1800] loss: 0.00895976263380362
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0570
Validation Accuracy: 0.9860
Overfitting: 0.0569
[Epoch 20, Batch 100] loss: 0.0109550433547804
[Epoch 20, Batch 200] loss: 0.003399114486585404
[Epoch 20, Batch 300] loss: 0.0031893699425154408
[Epoch 20, Batch 400] loss: 0.007794810703485382
[Epoch 20, Batch 500] loss: 0.005569137114111982
[Epoch 20, Batch 600] loss: 0.009203438689050927
[Epoch 20, Batch 700] loss: 0.004779604716612766
[Epoch 20, Batch 800] loss: 0.0028874158354608424
[Epoch 20, Batch 900] loss: 0.007292242631974659
[Epoch 20, Batch 1000] loss: 0.005209900587738047
[Epoch 20, Batch 1100] loss: 0.01159439079631511
[Epoch 20, Batch 1200] loss: 0.006431420249291477
[Epoch 20, Batch 1300] loss: 0.006658499506423823
[Epoch 20, Batch 1400] loss: 0.0032564138478710447
[Epoch 20, Batch 1500] loss: 0.006650903770892
[Epoch 20, Batch 1600] loss: 0.003994038930077864
[Epoch 20, Batch 1700] loss: 0.007596641886123052
[Epoch 20, Batch 1800] loss: 0.007016712137988463
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0612
Validation Accuracy: 0.9854
Overfitting: 0.0609
[Epoch 21, Batch 100] loss: 0.001691374075251133
[Epoch 21, Batch 200] loss: 0.003084957168441633
[Epoch 21, Batch 300] loss: 0.002166538204523931
[Epoch 21, Batch 400] loss: 0.0039631661836989455
[Epoch 21, Batch 500] loss: 0.005209833457837476
[Epoch 21, Batch 600] loss: 0.0018254844760156174
[Epoch 21, Batch 700] loss: 0.001520631932331753
[Epoch 21, Batch 800] loss: 0.003042362312971818
[Epoch 21, Batch 900] loss: 0.003748753074571525
[Epoch 21, Batch 1000] loss: 0.0029328592737590496
[Epoch 21, Batch 1100] loss: 0.003659829849876246
[Epoch 21, Batch 1200] loss: 0.002762287605103211
[Epoch 21, Batch 1300] loss: 0.013828753670990181
[Epoch 21, Batch 1400] loss: 0.004119801863591874
[Epoch 21, Batch 1500] loss: 0.003946305844650055
[Epoch 21, Batch 1600] loss: 0.0027040483516634593
[Epoch 21, Batch 1700] loss: 0.0033402422443873547
[Epoch 21, Batch 1800] loss: 0.005567556300132992
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0598
Validation Accuracy: 0.9857
Overfitting: 0.0597
[Epoch 22, Batch 100] loss: 0.0018457667593918359
[Epoch 22, Batch 200] loss: 0.004482808697478049
[Epoch 22, Batch 300] loss: 0.0015348769764815984
[Epoch 22, Batch 400] loss: 0.0025374763010472634
[Epoch 22, Batch 500] loss: 0.0016891295486121294
[Epoch 22, Batch 600] loss: 0.0018693505956446188
[Epoch 22, Batch 700] loss: 0.0032077559452136483
[Epoch 22, Batch 800] loss: 0.0017128334919812005
[Epoch 22, Batch 900] loss: 0.0019397978027484442
[Epoch 22, Batch 1000] loss: 0.004465205114661331
[Epoch 22, Batch 1100] loss: 0.005175667086455178
[Epoch 22, Batch 1200] loss: 0.0028650370011268932
[Epoch 22, Batch 1300] loss: 0.0012203422030415822
[Epoch 22, Batch 1400] loss: 0.0031022231447975913
[Epoch 22, Batch 1500] loss: 0.0051926622759475545
[Epoch 22, Batch 1600] loss: 0.007083656708066996
[Epoch 22, Batch 1700] loss: 0.009076581161500598
[Epoch 22, Batch 1800] loss: 0.005165028910003002
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0748
Validation Accuracy: 0.9828
Overfitting: 0.0743
[Epoch 23, Batch 100] loss: 0.0025875286673542066
[Epoch 23, Batch 200] loss: 0.0022353129280494955
[Epoch 23, Batch 300] loss: 0.0022756148723415315
[Epoch 23, Batch 400] loss: 0.00174360031704623
[Epoch 23, Batch 500] loss: 0.0035858236458830104
[Epoch 23, Batch 600] loss: 0.005733484114805378
[Epoch 23, Batch 700] loss: 0.005892983314814728
[Epoch 23, Batch 800] loss: 0.0023812871159138637
[Epoch 23, Batch 900] loss: 0.005177302743005044
[Epoch 23, Batch 1000] loss: 0.0020191110902118225
[Epoch 23, Batch 1100] loss: 0.0014230387640728282
[Epoch 23, Batch 1200] loss: 0.0015907358117391369
[Epoch 23, Batch 1300] loss: 0.0023330662563084558
[Epoch 23, Batch 1400] loss: 0.006327412746680068
[Epoch 23, Batch 1500] loss: 0.005469130574619782
[Epoch 23, Batch 1600] loss: 0.0068482531710257885
[Epoch 23, Batch 1700] loss: 0.005503857028328412
[Epoch 23, Batch 1800] loss: 0.002456769876038578
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0659
Validation Accuracy: 0.9848
Overfitting: 0.0658
[Epoch 24, Batch 100] loss: 0.00592342081223876
[Epoch 24, Batch 200] loss: 0.003420646147111057
[Epoch 24, Batch 300] loss: 0.0031195660601760268
[Epoch 24, Batch 400] loss: 0.00142246328896789
[Epoch 24, Batch 500] loss: 0.0010195187722686684
[Epoch 24, Batch 600] loss: 0.0011212628415560744
[Epoch 24, Batch 700] loss: 0.0014258352164233656
[Epoch 24, Batch 800] loss: 0.0008974341550282361
[Epoch 24, Batch 900] loss: 0.0038080487878289658
[Epoch 24, Batch 1000] loss: 0.004915764306595065
[Epoch 24, Batch 1100] loss: 0.001704570490584274
[Epoch 24, Batch 1200] loss: 0.0016188077114331634
[Epoch 24, Batch 1300] loss: 0.0015329191690067034
[Epoch 24, Batch 1400] loss: 0.0013649094813147754
[Epoch 24, Batch 1500] loss: 0.0016122778957381456
[Epoch 24, Batch 1600] loss: 0.0019528957255884195
[Epoch 24, Batch 1700] loss: 0.0015205179467649187
[Epoch 24, Batch 1800] loss: 0.0007444952418752493
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0905
Validation Accuracy: 0.9819
Overfitting: 0.0903
Fold 1 validation loss: 0.0905
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.291611611843109
[Epoch 1, Batch 200] loss: 2.2526553297042846
[Epoch 1, Batch 300] loss: 2.0350135815143586
[Epoch 1, Batch 400] loss: 1.0074346786737443
[Epoch 1, Batch 500] loss: 0.5895295785367489
[Epoch 1, Batch 600] loss: 0.5482203355431556
[Epoch 1, Batch 700] loss: 0.4279043611139059
[Epoch 1, Batch 800] loss: 0.3911345496028662
[Epoch 1, Batch 900] loss: 0.3513160502910614
[Epoch 1, Batch 1000] loss: 0.34191279735416175
[Epoch 1, Batch 1100] loss: 0.31492751933634283
[Epoch 1, Batch 1200] loss: 0.3393700063601136
[Epoch 1, Batch 1300] loss: 0.23549591425806285
[Epoch 1, Batch 1400] loss: 0.2279010927118361
[Epoch 1, Batch 1500] loss: 0.24013836478814482
[Epoch 1, Batch 1600] loss: 0.27704603005200623
[Epoch 1, Batch 1700] loss: 0.2309112793020904
[Epoch 1, Batch 1800] loss: 0.21272379881702363
**STATS for Epoch 1** : 
Average training loss: 0.0082
Average validation loss: 0.1987
Validation Accuracy: 0.9369
Overfitting: 0.1905
Best model saved at epoch 1 with validation loss: 0.1987
[Epoch 2, Batch 100] loss: 0.16092794032301755
[Epoch 2, Batch 200] loss: 0.1924235118366778
[Epoch 2, Batch 300] loss: 0.16948959063738583
[Epoch 2, Batch 400] loss: 0.18974184922408313
[Epoch 2, Batch 500] loss: 0.1388794728834182
[Epoch 2, Batch 600] loss: 0.15672033692710102
[Epoch 2, Batch 700] loss: 0.15570333638228476
[Epoch 2, Batch 800] loss: 0.1382316985866055
[Epoch 2, Batch 900] loss: 0.16849700999911874
[Epoch 2, Batch 1000] loss: 0.1480156046291813
[Epoch 2, Batch 1100] loss: 0.14356769806705416
[Epoch 2, Batch 1200] loss: 0.15127864329144358
[Epoch 2, Batch 1300] loss: 0.12009174276608973
[Epoch 2, Batch 1400] loss: 0.12207341357599943
[Epoch 2, Batch 1500] loss: 0.132053912084084
[Epoch 2, Batch 1600] loss: 0.13600620803888888
[Epoch 2, Batch 1700] loss: 0.12465728077571839
[Epoch 2, Batch 1800] loss: 0.12642477242974565
**STATS for Epoch 2** : 
Average training loss: 0.0035
Average validation loss: 0.1086
Validation Accuracy: 0.9655
Overfitting: 0.1051
Best model saved at epoch 2 with validation loss: 0.1086
[Epoch 3, Batch 100] loss: 0.09943197906482965
[Epoch 3, Batch 200] loss: 0.11953989536501468
[Epoch 3, Batch 300] loss: 0.09733503856230527
[Epoch 3, Batch 400] loss: 0.0903934979508631
[Epoch 3, Batch 500] loss: 0.1045377647713758
[Epoch 3, Batch 600] loss: 0.09413560788612813
[Epoch 3, Batch 700] loss: 0.10256360409781337
[Epoch 3, Batch 800] loss: 0.10679093140875921
[Epoch 3, Batch 900] loss: 0.1120880945166573
[Epoch 3, Batch 1000] loss: 0.08442246549064293
[Epoch 3, Batch 1100] loss: 0.10477020687190816
[Epoch 3, Batch 1200] loss: 0.10276948641287163
[Epoch 3, Batch 1300] loss: 0.10284041582606733
[Epoch 3, Batch 1400] loss: 0.08106943001737818
[Epoch 3, Batch 1500] loss: 0.08503314279310871
[Epoch 3, Batch 1600] loss: 0.08599249216378667
[Epoch 3, Batch 1700] loss: 0.087581854875898
[Epoch 3, Batch 1800] loss: 0.10526080658659338
**STATS for Epoch 3** : 
Average training loss: 0.0032
Average validation loss: 0.0793
Validation Accuracy: 0.9756
Overfitting: 0.0761
Best model saved at epoch 3 with validation loss: 0.0793
[Epoch 4, Batch 100] loss: 0.08991743125137873
[Epoch 4, Batch 200] loss: 0.0721405769867124
[Epoch 4, Batch 300] loss: 0.058947574644116686
[Epoch 4, Batch 400] loss: 0.06949301400920377
[Epoch 4, Batch 500] loss: 0.07894600509782322
[Epoch 4, Batch 600] loss: 0.09340524362400174
[Epoch 4, Batch 700] loss: 0.07782566412119195
[Epoch 4, Batch 800] loss: 0.051689534438191916
[Epoch 4, Batch 900] loss: 0.08652453406713903
[Epoch 4, Batch 1000] loss: 0.07634581404505297
[Epoch 4, Batch 1100] loss: 0.07428214703046251
[Epoch 4, Batch 1200] loss: 0.07766779495315859
[Epoch 4, Batch 1300] loss: 0.06089887466747314
[Epoch 4, Batch 1400] loss: 0.1042783499485813
[Epoch 4, Batch 1500] loss: 0.08004304108209909
[Epoch 4, Batch 1600] loss: 0.06044261713162996
[Epoch 4, Batch 1700] loss: 0.06335771445126738
[Epoch 4, Batch 1800] loss: 0.058250596000580114
**STATS for Epoch 4** : 
Average training loss: 0.0026
Average validation loss: 0.0815
Validation Accuracy: 0.9743
Overfitting: 0.0789
[Epoch 5, Batch 100] loss: 0.0512921914679464
[Epoch 5, Batch 200] loss: 0.055897073510568586
[Epoch 5, Batch 300] loss: 0.05130186838330701
[Epoch 5, Batch 400] loss: 0.06659083295147866
[Epoch 5, Batch 500] loss: 0.07638165512296836
[Epoch 5, Batch 600] loss: 0.06617874894174747
[Epoch 5, Batch 700] loss: 0.0858546609384939
[Epoch 5, Batch 800] loss: 0.0539901460276451
[Epoch 5, Batch 900] loss: 0.07517490085272584
[Epoch 5, Batch 1000] loss: 0.04986541787046008
[Epoch 5, Batch 1100] loss: 0.04225819768325891
[Epoch 5, Batch 1200] loss: 0.06225365297286771
[Epoch 5, Batch 1300] loss: 0.06044364824774675
[Epoch 5, Batch 1400] loss: 0.059189414794091136
[Epoch 5, Batch 1500] loss: 0.04775046627561096
[Epoch 5, Batch 1600] loss: 0.056137425384949896
[Epoch 5, Batch 1700] loss: 0.061848283652216195
[Epoch 5, Batch 1800] loss: 0.04402233515458647
**STATS for Epoch 5** : 
Average training loss: 0.0021
Average validation loss: 0.0605
Validation Accuracy: 0.9809
Overfitting: 0.0584
Best model saved at epoch 5 with validation loss: 0.0605
[Epoch 6, Batch 100] loss: 0.04372635030260426
[Epoch 6, Batch 200] loss: 0.044803699736658015
[Epoch 6, Batch 300] loss: 0.05270290207874496
[Epoch 6, Batch 400] loss: 0.04352484574526898
[Epoch 6, Batch 500] loss: 0.05875792189966887
[Epoch 6, Batch 600] loss: 0.04971888488216791
[Epoch 6, Batch 700] loss: 0.04039717269828543
[Epoch 6, Batch 800] loss: 0.049433453229939917
[Epoch 6, Batch 900] loss: 0.06297723068186314
[Epoch 6, Batch 1000] loss: 0.064971588512999
[Epoch 6, Batch 1100] loss: 0.04085572841577232
[Epoch 6, Batch 1200] loss: 0.05473161484813318
[Epoch 6, Batch 1300] loss: 0.03813769724831218
[Epoch 6, Batch 1400] loss: 0.04753882996767061
[Epoch 6, Batch 1500] loss: 0.060661834347702094
[Epoch 6, Batch 1600] loss: 0.06072264603280928
[Epoch 6, Batch 1700] loss: 0.057670337883464526
[Epoch 6, Batch 1800] loss: 0.045739506904792504
**STATS for Epoch 6** : 
Average training loss: 0.0021
Average validation loss: 0.0643
Validation Accuracy: 0.9799
Overfitting: 0.0622
[Epoch 7, Batch 100] loss: 0.04240818533464335
[Epoch 7, Batch 200] loss: 0.03563678764738142
[Epoch 7, Batch 300] loss: 0.04312690242717508
[Epoch 7, Batch 400] loss: 0.039024144356080794
[Epoch 7, Batch 500] loss: 0.03897668529796647
[Epoch 7, Batch 600] loss: 0.04109086228592787
[Epoch 7, Batch 700] loss: 0.039024662413576154
[Epoch 7, Batch 800] loss: 0.04881514827458886
[Epoch 7, Batch 900] loss: 0.041571105173788966
[Epoch 7, Batch 1000] loss: 0.047168132843798956
[Epoch 7, Batch 1100] loss: 0.036192351712088566
[Epoch 7, Batch 1200] loss: 0.05010747301537776
[Epoch 7, Batch 1300] loss: 0.045367742921807806
[Epoch 7, Batch 1400] loss: 0.05232887454418233
[Epoch 7, Batch 1500] loss: 0.042285845564329065
[Epoch 7, Batch 1600] loss: 0.038556276814779265
[Epoch 7, Batch 1700] loss: 0.038783184170897586
[Epoch 7, Batch 1800] loss: 0.04103999367878714
**STATS for Epoch 7** : 
Average training loss: 0.0018
Average validation loss: 0.0637
Validation Accuracy: 0.9801
Overfitting: 0.0619
[Epoch 8, Batch 100] loss: 0.040181037172296784
[Epoch 8, Batch 200] loss: 0.03612304448717623
[Epoch 8, Batch 300] loss: 0.0312732816170319
[Epoch 8, Batch 400] loss: 0.03864363600790966
[Epoch 8, Batch 500] loss: 0.03315688055154169
[Epoch 8, Batch 600] loss: 0.03657622491060465
[Epoch 8, Batch 700] loss: 0.028346817223209655
[Epoch 8, Batch 800] loss: 0.024860670645721256
[Epoch 8, Batch 900] loss: 0.03402085275301943
[Epoch 8, Batch 1000] loss: 0.02165949099246063
[Epoch 8, Batch 1100] loss: 0.046495030910591595
[Epoch 8, Batch 1200] loss: 0.03236821830185363
[Epoch 8, Batch 1300] loss: 0.026785032079351366
[Epoch 8, Batch 1400] loss: 0.04377368030698563
[Epoch 8, Batch 1500] loss: 0.032197874867852076
[Epoch 8, Batch 1600] loss: 0.04251738667633617
[Epoch 8, Batch 1700] loss: 0.03461992201540852
[Epoch 8, Batch 1800] loss: 0.0380028259289611
**STATS for Epoch 8** : 
Average training loss: 0.0018
Average validation loss: 0.0585
Validation Accuracy: 0.9821
Overfitting: 0.0567
Best model saved at epoch 8 with validation loss: 0.0585
[Epoch 9, Batch 100] loss: 0.026060878179341673
[Epoch 9, Batch 200] loss: 0.028457944929104997
[Epoch 9, Batch 300] loss: 0.024635436458593177
[Epoch 9, Batch 400] loss: 0.029938425564760108
[Epoch 9, Batch 500] loss: 0.02342880657990463
[Epoch 9, Batch 600] loss: 0.03484420382967073
[Epoch 9, Batch 700] loss: 0.025637949310839757
[Epoch 9, Batch 800] loss: 0.028082114526841905
[Epoch 9, Batch 900] loss: 0.02950660522830731
[Epoch 9, Batch 1000] loss: 0.0386025497593073
[Epoch 9, Batch 1100] loss: 0.02808971952428692
[Epoch 9, Batch 1200] loss: 0.047890856169105975
[Epoch 9, Batch 1300] loss: 0.03208862785439123
[Epoch 9, Batch 1400] loss: 0.034800835394671596
[Epoch 9, Batch 1500] loss: 0.03788307703995088
[Epoch 9, Batch 1600] loss: 0.034646093242336064
[Epoch 9, Batch 1700] loss: 0.03123850279065664
[Epoch 9, Batch 1800] loss: 0.03009389796425239
**STATS for Epoch 9** : 
Average training loss: 0.0014
Average validation loss: 0.0700
Validation Accuracy: 0.9795
Overfitting: 0.0686
[Epoch 10, Batch 100] loss: 0.02266519508746569
[Epoch 10, Batch 200] loss: 0.03091976129617251
[Epoch 10, Batch 300] loss: 0.024874478114797968
[Epoch 10, Batch 400] loss: 0.02827954508451512
[Epoch 10, Batch 500] loss: 0.02100448413460981
[Epoch 10, Batch 600] loss: 0.028225583410821854
[Epoch 10, Batch 700] loss: 0.028784351860304015
[Epoch 10, Batch 800] loss: 0.023664148841526185
[Epoch 10, Batch 900] loss: 0.017755238428944723
[Epoch 10, Batch 1000] loss: 0.024031358490974528
[Epoch 10, Batch 1100] loss: 0.026206383654425736
[Epoch 10, Batch 1200] loss: 0.028388323294457223
[Epoch 10, Batch 1300] loss: 0.04277072469818449
[Epoch 10, Batch 1400] loss: 0.024242317337066197
[Epoch 10, Batch 1500] loss: 0.032836242389857946
[Epoch 10, Batch 1600] loss: 0.038215759608356166
[Epoch 10, Batch 1700] loss: 0.03943785152936471
[Epoch 10, Batch 1800] loss: 0.021467397500018706
**STATS for Epoch 10** : 
Average training loss: 0.0005
Average validation loss: 0.0532
Validation Accuracy: 0.9846
Overfitting: 0.0527
Best model saved at epoch 10 with validation loss: 0.0532
[Epoch 11, Batch 100] loss: 0.026320603429485345
[Epoch 11, Batch 200] loss: 0.019209100089065033
[Epoch 11, Batch 300] loss: 0.018376878527196824
[Epoch 11, Batch 400] loss: 0.016273679323421674
[Epoch 11, Batch 500] loss: 0.015565362013803678
[Epoch 11, Batch 600] loss: 0.01967691514029866
[Epoch 11, Batch 700] loss: 0.022508866020070854
[Epoch 11, Batch 800] loss: 0.021125518741391715
[Epoch 11, Batch 900] loss: 0.019078550061494753
[Epoch 11, Batch 1000] loss: 0.026101965398047468
[Epoch 11, Batch 1100] loss: 0.023775532681538605
[Epoch 11, Batch 1200] loss: 0.029623473587689658
[Epoch 11, Batch 1300] loss: 0.03954792417775024
[Epoch 11, Batch 1400] loss: 0.02389419012801227
[Epoch 11, Batch 1500] loss: 0.03450646211305866
[Epoch 11, Batch 1600] loss: 0.02904881770562497
[Epoch 11, Batch 1700] loss: 0.022502430106906102
[Epoch 11, Batch 1800] loss: 0.013262830489475163
**STATS for Epoch 11** : 
Average training loss: 0.0011
Average validation loss: 0.0538
Validation Accuracy: 0.9840
Overfitting: 0.0527
[Epoch 12, Batch 100] loss: 0.019234486468485558
[Epoch 12, Batch 200] loss: 0.015406819621421163
[Epoch 12, Batch 300] loss: 0.027418241857558315
[Epoch 12, Batch 400] loss: 0.017626891837244328
[Epoch 12, Batch 500] loss: 0.021062455023711665
[Epoch 12, Batch 600] loss: 0.025921872928011
[Epoch 12, Batch 700] loss: 0.017159714873541815
[Epoch 12, Batch 800] loss: 0.024232756447927387
[Epoch 12, Batch 900] loss: 0.021955477827068536
[Epoch 12, Batch 1000] loss: 0.019584709522951015
[Epoch 12, Batch 1100] loss: 0.029255101523158373
[Epoch 12, Batch 1200] loss: 0.014412465302884812
[Epoch 12, Batch 1300] loss: 0.030769446137655906
[Epoch 12, Batch 1400] loss: 0.02747088304906356
[Epoch 12, Batch 1500] loss: 0.023325819275542017
[Epoch 12, Batch 1600] loss: 0.014547038077835169
[Epoch 12, Batch 1700] loss: 0.020087218613934966
[Epoch 12, Batch 1800] loss: 0.030946048004116166
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0571
Validation Accuracy: 0.9836
Overfitting: 0.0563
[Epoch 13, Batch 100] loss: 0.016342700180866813
[Epoch 13, Batch 200] loss: 0.008858239112469165
[Epoch 13, Batch 300] loss: 0.011851141096558422
[Epoch 13, Batch 400] loss: 0.007063516328889819
[Epoch 13, Batch 500] loss: 0.014568453305346339
[Epoch 13, Batch 600] loss: 0.028816466753341957
[Epoch 13, Batch 700] loss: 0.021395080832444364
[Epoch 13, Batch 800] loss: 0.018224761698120345
[Epoch 13, Batch 900] loss: 0.02112019917945872
[Epoch 13, Batch 1000] loss: 0.022211178017550993
[Epoch 13, Batch 1100] loss: 0.026526980823618942
[Epoch 13, Batch 1200] loss: 0.022541979179004558
[Epoch 13, Batch 1300] loss: 0.023404645727241588
[Epoch 13, Batch 1400] loss: 0.022919920210661075
[Epoch 13, Batch 1500] loss: 0.013834920704612159
[Epoch 13, Batch 1600] loss: 0.01056153640804041
[Epoch 13, Batch 1700] loss: 0.029773534210289655
[Epoch 13, Batch 1800] loss: 0.017493509163005003
**STATS for Epoch 13** : 
Average training loss: 0.0007
Average validation loss: 0.0578
Validation Accuracy: 0.9836
Overfitting: 0.0571
[Epoch 14, Batch 100] loss: 0.013414858026635557
[Epoch 14, Batch 200] loss: 0.018608298576800734
[Epoch 14, Batch 300] loss: 0.008232936564436386
[Epoch 14, Batch 400] loss: 0.012641559211897403
[Epoch 14, Batch 500] loss: 0.01634723713163112
[Epoch 14, Batch 600] loss: 0.01476186500654876
[Epoch 14, Batch 700] loss: 0.018664559569533595
[Epoch 14, Batch 800] loss: 0.013247431141371635
[Epoch 14, Batch 900] loss: 0.018486843922221396
[Epoch 14, Batch 1000] loss: 0.019060422280854254
[Epoch 14, Batch 1100] loss: 0.03247841033273289
[Epoch 14, Batch 1200] loss: 0.01766860307296156
[Epoch 14, Batch 1300] loss: 0.020195880449209655
[Epoch 14, Batch 1400] loss: 0.011454021850595382
[Epoch 14, Batch 1500] loss: 0.007400774492657547
[Epoch 14, Batch 1600] loss: 0.016853849458275363
[Epoch 14, Batch 1700] loss: 0.013022865123930387
[Epoch 14, Batch 1800] loss: 0.022932906529476896
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0608
Validation Accuracy: 0.9839
Overfitting: 0.0602
[Epoch 15, Batch 100] loss: 0.011212285705087198
[Epoch 15, Batch 200] loss: 0.010328683106517928
[Epoch 15, Batch 300] loss: 0.011820663032194716
[Epoch 15, Batch 400] loss: 0.017005477020920808
[Epoch 15, Batch 500] loss: 0.014389352746711666
[Epoch 15, Batch 600] loss: 0.01870578858706722
[Epoch 15, Batch 700] loss: 0.010292080181361598
[Epoch 15, Batch 800] loss: 0.014132537398791101
[Epoch 15, Batch 900] loss: 0.01433525641756205
[Epoch 15, Batch 1000] loss: 0.02112499914590444
[Epoch 15, Batch 1100] loss: 0.010152760866665176
[Epoch 15, Batch 1200] loss: 0.015055797186014387
[Epoch 15, Batch 1300] loss: 0.009894009572126378
[Epoch 15, Batch 1400] loss: 0.017050556992089697
[Epoch 15, Batch 1500] loss: 0.013343584984268091
[Epoch 15, Batch 1600] loss: 0.025454173193393218
[Epoch 15, Batch 1700] loss: 0.009075967346016114
[Epoch 15, Batch 1800] loss: 0.022700757269522
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0629
Validation Accuracy: 0.9835
Overfitting: 0.0623
[Epoch 16, Batch 100] loss: 0.022796140883820044
[Epoch 16, Batch 200] loss: 0.011756665855518805
[Epoch 16, Batch 300] loss: 0.01899146777554961
[Epoch 16, Batch 400] loss: 0.013287698884346355
[Epoch 16, Batch 500] loss: 0.01277276578695819
[Epoch 16, Batch 600] loss: 0.017387805168673366
[Epoch 16, Batch 700] loss: 0.010130557864667935
[Epoch 16, Batch 800] loss: 0.007778934156194736
[Epoch 16, Batch 900] loss: 0.009450781197842843
[Epoch 16, Batch 1000] loss: 0.008274435568582704
[Epoch 16, Batch 1100] loss: 0.011449699328049973
[Epoch 16, Batch 1200] loss: 0.013181767627847875
[Epoch 16, Batch 1300] loss: 0.01966315097231927
[Epoch 16, Batch 1400] loss: 0.009002490812781616
[Epoch 16, Batch 1500] loss: 0.009350368192044697
[Epoch 16, Batch 1600] loss: 0.014379989104900232
[Epoch 16, Batch 1700] loss: 0.006259154126455542
[Epoch 16, Batch 1800] loss: 0.004548850836022212
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0587
Validation Accuracy: 0.9841
Overfitting: 0.0584
[Epoch 17, Batch 100] loss: 0.010253179854262271
[Epoch 17, Batch 200] loss: 0.0104312777185919
[Epoch 17, Batch 300] loss: 0.014374373099899458
[Epoch 17, Batch 400] loss: 0.010186045037689837
[Epoch 17, Batch 500] loss: 0.009653484098125774
[Epoch 17, Batch 600] loss: 0.01544253173440211
[Epoch 17, Batch 700] loss: 0.011711157583554267
[Epoch 17, Batch 800] loss: 0.011574299402600446
[Epoch 17, Batch 900] loss: 0.010504341654947211
[Epoch 17, Batch 1000] loss: 0.00466441673113593
[Epoch 17, Batch 1100] loss: 0.00867386483057544
[Epoch 17, Batch 1200] loss: 0.025523524179116065
[Epoch 17, Batch 1300] loss: 0.006212157301926027
[Epoch 17, Batch 1400] loss: 0.011128137811383568
[Epoch 17, Batch 1500] loss: 0.00862903874199219
[Epoch 17, Batch 1600] loss: 0.010400529083526636
[Epoch 17, Batch 1700] loss: 0.007399178773230233
[Epoch 17, Batch 1800] loss: 0.009646782710728986
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0575
Validation Accuracy: 0.9849
Overfitting: 0.0574
[Epoch 18, Batch 100] loss: 0.00645337895519333
[Epoch 18, Batch 200] loss: 0.009428637624343992
[Epoch 18, Batch 300] loss: 0.0054039772205942424
[Epoch 18, Batch 400] loss: 0.007693769446620991
[Epoch 18, Batch 500] loss: 0.005781259339821645
[Epoch 18, Batch 600] loss: 0.02368345996035714
[Epoch 18, Batch 700] loss: 0.008051616959578496
[Epoch 18, Batch 800] loss: 0.007319269435744218
[Epoch 18, Batch 900] loss: 0.00363683857882279
[Epoch 18, Batch 1000] loss: 0.013107477323142262
[Epoch 18, Batch 1100] loss: 0.01726829184746066
[Epoch 18, Batch 1200] loss: 0.017600707193041673
[Epoch 18, Batch 1300] loss: 0.011012460280888377
[Epoch 18, Batch 1400] loss: 0.005579952881353165
[Epoch 18, Batch 1500] loss: 0.006179275873721508
[Epoch 18, Batch 1600] loss: 0.00908804125237566
[Epoch 18, Batch 1700] loss: 0.005132020910696156
[Epoch 18, Batch 1800] loss: 0.01129039193688186
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0604
Validation Accuracy: 0.9857
Overfitting: 0.0598
[Epoch 19, Batch 100] loss: 0.010337757589941248
[Epoch 19, Batch 200] loss: 0.0037370023798598594
[Epoch 19, Batch 300] loss: 0.005797622918885281
[Epoch 19, Batch 400] loss: 0.009662840793436373
[Epoch 19, Batch 500] loss: 0.012895800536489333
[Epoch 19, Batch 600] loss: 0.00977903823573115
[Epoch 19, Batch 700] loss: 0.00627722876463963
[Epoch 19, Batch 800] loss: 0.008364912236675081
[Epoch 19, Batch 900] loss: 0.007929175527933693
[Epoch 19, Batch 1000] loss: 0.004567145432711186
[Epoch 19, Batch 1100] loss: 0.009446450470118179
[Epoch 19, Batch 1200] loss: 0.008182185881005354
[Epoch 19, Batch 1300] loss: 0.0077218449331076045
[Epoch 19, Batch 1400] loss: 0.0030974169999944934
[Epoch 19, Batch 1500] loss: 0.006037417449688292
[Epoch 19, Batch 1600] loss: 0.0036893696861557148
[Epoch 19, Batch 1700] loss: 0.008319874837083035
[Epoch 19, Batch 1800] loss: 0.009624877694041061
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0589
Validation Accuracy: 0.9858
Overfitting: 0.0587
[Epoch 20, Batch 100] loss: 0.003465277061997085
[Epoch 20, Batch 200] loss: 0.005281278557787345
[Epoch 20, Batch 300] loss: 0.00973474854589199
[Epoch 20, Batch 400] loss: 0.00224477935499408
[Epoch 20, Batch 500] loss: 0.002134207376834638
[Epoch 20, Batch 600] loss: 0.004236566372464949
[Epoch 20, Batch 700] loss: 0.002209323573876816
[Epoch 20, Batch 800] loss: 0.005964712326492645
[Epoch 20, Batch 900] loss: 0.00678322663327208
[Epoch 20, Batch 1000] loss: 0.0063604860890689
[Epoch 20, Batch 1100] loss: 0.005235155938559615
[Epoch 20, Batch 1200] loss: 0.0034453573050817
[Epoch 20, Batch 1300] loss: 0.008268203830029961
[Epoch 20, Batch 1400] loss: 0.005995939779946866
[Epoch 20, Batch 1500] loss: 0.002084218810539369
[Epoch 20, Batch 1600] loss: 0.004962631606235846
[Epoch 20, Batch 1700] loss: 0.006391975823725034
[Epoch 20, Batch 1800] loss: 0.010255542386462367
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0744
Validation Accuracy: 0.9828
Overfitting: 0.0740
[Epoch 21, Batch 100] loss: 0.007254226733194003
[Epoch 21, Batch 200] loss: 0.0028816946010229573
[Epoch 21, Batch 300] loss: 0.0022692117426345248
[Epoch 21, Batch 400] loss: 0.004699813938802322
[Epoch 21, Batch 500] loss: 0.0030900115519273187
[Epoch 21, Batch 600] loss: 0.004170911671960767
[Epoch 21, Batch 700] loss: 0.0018167839314730827
[Epoch 21, Batch 800] loss: 0.001555072174761527
[Epoch 21, Batch 900] loss: 0.004136545422540507
[Epoch 21, Batch 1000] loss: 0.003166202598052621
[Epoch 21, Batch 1100] loss: 0.0066901128950758
[Epoch 21, Batch 1200] loss: 0.004810690030062688
[Epoch 21, Batch 1300] loss: 0.00431664893694915
[Epoch 21, Batch 1400] loss: 0.006606394691624473
[Epoch 21, Batch 1500] loss: 0.004575290599906055
[Epoch 21, Batch 1600] loss: 0.009376604113501798
[Epoch 21, Batch 1700] loss: 0.0027589068441557173
[Epoch 21, Batch 1800] loss: 0.005982974792918867
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0618
Validation Accuracy: 0.9851
Overfitting: 0.0616
[Epoch 22, Batch 100] loss: 0.005570750761161775
[Epoch 22, Batch 200] loss: 0.002205095299285773
[Epoch 22, Batch 300] loss: 0.0029110052708142577
[Epoch 22, Batch 400] loss: 0.0016620079754613925
[Epoch 22, Batch 500] loss: 0.00222291874806821
[Epoch 22, Batch 600] loss: 0.01898782757554244
[Epoch 22, Batch 700] loss: 0.01336055455996302
[Epoch 22, Batch 800] loss: 0.009546546170925296
[Epoch 22, Batch 900] loss: 0.004195486207588601
[Epoch 22, Batch 1000] loss: 0.01355584874251349
[Epoch 22, Batch 1100] loss: 0.012383641749925118
[Epoch 22, Batch 1200] loss: 0.02176920690398447
[Epoch 22, Batch 1300] loss: 0.017754653104730095
[Epoch 22, Batch 1400] loss: 0.008416094094250183
[Epoch 22, Batch 1500] loss: 0.008332756941488242
[Epoch 22, Batch 1600] loss: 0.010734743927441741
[Epoch 22, Batch 1700] loss: 0.011064955686393034
[Epoch 22, Batch 1800] loss: 0.009135190726881319
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0688
Validation Accuracy: 0.9836
Overfitting: 0.0684
[Epoch 23, Batch 100] loss: 0.0063164994616249715
[Epoch 23, Batch 200] loss: 0.0016133591706545757
[Epoch 23, Batch 300] loss: 0.007770450649084637
[Epoch 23, Batch 400] loss: 0.0031865076530340273
[Epoch 23, Batch 500] loss: 0.006917296322676521
[Epoch 23, Batch 600] loss: 0.006177501467765296
[Epoch 23, Batch 700] loss: 0.006999531276524351
[Epoch 23, Batch 800] loss: 0.004494311240564457
[Epoch 23, Batch 900] loss: 0.005446755751522403
[Epoch 23, Batch 1000] loss: 0.005056181277337828
[Epoch 23, Batch 1100] loss: 0.0031536385769877027
[Epoch 23, Batch 1200] loss: 0.005636391321456245
[Epoch 23, Batch 1300] loss: 0.0025965643483327836
[Epoch 23, Batch 1400] loss: 0.002887106338055503
[Epoch 23, Batch 1500] loss: 0.003333050518626237
[Epoch 23, Batch 1600] loss: 0.005315412881199109
[Epoch 23, Batch 1700] loss: 0.002781637508751089
[Epoch 23, Batch 1800] loss: 0.004604311743024141
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0599
Validation Accuracy: 0.9868
Overfitting: 0.0598
[Epoch 24, Batch 100] loss: 0.002448818357956384
[Epoch 24, Batch 200] loss: 0.0023262934705059026
[Epoch 24, Batch 300] loss: 0.0049907038751746315
[Epoch 24, Batch 400] loss: 0.0023185898293570516
[Epoch 24, Batch 500] loss: 0.0008033952110289988
[Epoch 24, Batch 600] loss: 0.0018532406344419882
[Epoch 24, Batch 700] loss: 0.00170448245866595
[Epoch 24, Batch 800] loss: 0.0014767434730937623
[Epoch 24, Batch 900] loss: 0.0016648047368778406
[Epoch 24, Batch 1000] loss: 0.001172864655403032
[Epoch 24, Batch 1100] loss: 0.001053583881234772
[Epoch 24, Batch 1200] loss: 0.0010396191214626072
[Epoch 24, Batch 1300] loss: 0.0012522578422721154
[Epoch 24, Batch 1400] loss: 0.001876434641403648
[Epoch 24, Batch 1500] loss: 0.003906927872813242
[Epoch 24, Batch 1600] loss: 0.004975453539921659
[Epoch 24, Batch 1700] loss: 0.005672785027080636
[Epoch 24, Batch 1800] loss: 0.0038131843540492125
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0651
Validation Accuracy: 0.9856
Overfitting: 0.0650
Fold 2 validation loss: 0.0651
Mean validation loss across all folds for Trial 14 is 0.0778 with trial config:  l1: 128, l2: 128, lr: 0.0011062854566266248, batch_size: 16
[I 2024-11-21 19:50:38,572] Trial 13 finished with value: 0.07782575960523849 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0011062854566266248, 'batch_size': 16}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 15:
  l1: 256, l2: 128, lr: 0.009836048672425646, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.6356346887350082
**STATS for Epoch 1** : 
Average training loss: 0.0646
Average validation loss: 0.4046
Validation Accuracy: 0.8746
Overfitting: 0.3400
Best model saved at epoch 1 with validation loss: 0.4046
[Epoch 2, Batch 100] loss: 0.2820870320498943
**STATS for Epoch 2** : 
Average training loss: 0.0292
Average validation loss: 0.1881
Validation Accuracy: 0.9408
Overfitting: 0.1590
Best model saved at epoch 2 with validation loss: 0.1881
[Epoch 3, Batch 100] loss: 0.15262999154627324
**STATS for Epoch 3** : 
Average training loss: 0.0181
Average validation loss: 0.1222
Validation Accuracy: 0.9614
Overfitting: 0.1041
Best model saved at epoch 3 with validation loss: 0.1222
[Epoch 4, Batch 100] loss: 0.11258526895195246
**STATS for Epoch 4** : 
Average training loss: 0.0136
Average validation loss: 0.0991
Validation Accuracy: 0.9693
Overfitting: 0.0855
Best model saved at epoch 4 with validation loss: 0.0991
[Epoch 5, Batch 100] loss: 0.0870116190239787
**STATS for Epoch 5** : 
Average training loss: 0.0119
Average validation loss: 0.0818
Validation Accuracy: 0.9746
Overfitting: 0.0699
Best model saved at epoch 5 with validation loss: 0.0818
[Epoch 6, Batch 100] loss: 0.06836183281615377
**STATS for Epoch 6** : 
Average training loss: 0.0100
Average validation loss: 0.0841
Validation Accuracy: 0.9737
Overfitting: 0.0741
[Epoch 7, Batch 100] loss: 0.05847748262807727
**STATS for Epoch 7** : 
Average training loss: 0.0079
Average validation loss: 0.0766
Validation Accuracy: 0.9762
Overfitting: 0.0687
Best model saved at epoch 7 with validation loss: 0.0766
[Epoch 8, Batch 100] loss: 0.04740425206720829
**STATS for Epoch 8** : 
Average training loss: 0.0088
Average validation loss: 0.0835
Validation Accuracy: 0.9749
Overfitting: 0.0747
[Epoch 9, Batch 100] loss: 0.046101670851930975
**STATS for Epoch 9** : 
Average training loss: 0.0085
Average validation loss: 0.0759
Validation Accuracy: 0.9761
Overfitting: 0.0674
Best model saved at epoch 9 with validation loss: 0.0759
[Epoch 10, Batch 100] loss: 0.04140884591266513
**STATS for Epoch 10** : 
Average training loss: 0.0050
Average validation loss: 0.0676
Validation Accuracy: 0.9792
Overfitting: 0.0626
Best model saved at epoch 10 with validation loss: 0.0676
[Epoch 11, Batch 100] loss: 0.033413429097272455
**STATS for Epoch 11** : 
Average training loss: 0.0079
Average validation loss: 0.0731
Validation Accuracy: 0.9780
Overfitting: 0.0651
[Epoch 12, Batch 100] loss: 0.030915295821614563
**STATS for Epoch 12** : 
Average training loss: 0.0044
Average validation loss: 0.0629
Validation Accuracy: 0.9806
Overfitting: 0.0585
Best model saved at epoch 12 with validation loss: 0.0629
[Epoch 13, Batch 100] loss: 0.02609211812959984
**STATS for Epoch 13** : 
Average training loss: 0.0039
Average validation loss: 0.0719
Validation Accuracy: 0.9798
Overfitting: 0.0680
[Epoch 14, Batch 100] loss: 0.022909800163470207
**STATS for Epoch 14** : 
Average training loss: 0.0036
Average validation loss: 0.0664
Validation Accuracy: 0.9807
Overfitting: 0.0628
[Epoch 15, Batch 100] loss: 0.01872274520341307
**STATS for Epoch 15** : 
Average training loss: 0.0040
Average validation loss: 0.0701
Validation Accuracy: 0.9797
Overfitting: 0.0661
[Epoch 16, Batch 100] loss: 0.01548197521129623
**STATS for Epoch 16** : 
Average training loss: 0.0030
Average validation loss: 0.0639
Validation Accuracy: 0.9824
Overfitting: 0.0609
[Epoch 17, Batch 100] loss: 0.01690316977677867
**STATS for Epoch 17** : 
Average training loss: 0.0027
Average validation loss: 0.0715
Validation Accuracy: 0.9809
Overfitting: 0.0689
[Epoch 18, Batch 100] loss: 0.01379772183019668
**STATS for Epoch 18** : 
Average training loss: 0.0013
Average validation loss: 0.0675
Validation Accuracy: 0.9821
Overfitting: 0.0663
[Epoch 19, Batch 100] loss: 0.0107738583360333
**STATS for Epoch 19** : 
Average training loss: 0.0022
Average validation loss: 0.0699
Validation Accuracy: 0.9814
Overfitting: 0.0677
[Epoch 20, Batch 100] loss: 0.009957217649789527
**STATS for Epoch 20** : 
Average training loss: 0.0014
Average validation loss: 0.0655
Validation Accuracy: 0.9834
Overfitting: 0.0641
[Epoch 21, Batch 100] loss: 0.008185862686950714
**STATS for Epoch 21** : 
Average training loss: 0.0017
Average validation loss: 0.0688
Validation Accuracy: 0.9825
Overfitting: 0.0671
[Epoch 22, Batch 100] loss: 0.00851137779187411
**STATS for Epoch 22** : 
Average training loss: 0.0013
Average validation loss: 0.0664
Validation Accuracy: 0.9831
Overfitting: 0.0651
[Epoch 23, Batch 100] loss: 0.006428815282997675
**STATS for Epoch 23** : 
Average training loss: 0.0009
Average validation loss: 0.0728
Validation Accuracy: 0.9828
Overfitting: 0.0719
[Epoch 24, Batch 100] loss: 0.005233875729609281
**STATS for Epoch 24** : 
Average training loss: 0.0011
Average validation loss: 0.0788
Validation Accuracy: 0.9811
Overfitting: 0.0777
Fold 1 validation loss: 0.0788
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.4280753555893897
**STATS for Epoch 1** : 
Average training loss: 0.0569
Average validation loss: 0.3078
Validation Accuracy: 0.9073
Overfitting: 0.2509
Best model saved at epoch 1 with validation loss: 0.3078
[Epoch 2, Batch 100] loss: 0.23871628411114215
**STATS for Epoch 2** : 
Average training loss: 0.0238
Average validation loss: 0.1509
Validation Accuracy: 0.9535
Overfitting: 0.1270
Best model saved at epoch 2 with validation loss: 0.1509
[Epoch 3, Batch 100] loss: 0.1260676843672991
**STATS for Epoch 3** : 
Average training loss: 0.0191
Average validation loss: 0.1168
Validation Accuracy: 0.9638
Overfitting: 0.0978
Best model saved at epoch 3 with validation loss: 0.1168
[Epoch 4, Batch 100] loss: 0.0987100200727582
**STATS for Epoch 4** : 
Average training loss: 0.0116
Average validation loss: 0.0869
Validation Accuracy: 0.9732
Overfitting: 0.0753
Best model saved at epoch 4 with validation loss: 0.0869
[Epoch 5, Batch 100] loss: 0.07477878347039223
**STATS for Epoch 5** : 
Average training loss: 0.0132
Average validation loss: 0.0841
Validation Accuracy: 0.9745
Overfitting: 0.0709
Best model saved at epoch 5 with validation loss: 0.0841
[Epoch 6, Batch 100] loss: 0.06484205488115549
**STATS for Epoch 6** : 
Average training loss: 0.0083
Average validation loss: 0.0750
Validation Accuracy: 0.9776
Overfitting: 0.0667
Best model saved at epoch 6 with validation loss: 0.0750
[Epoch 7, Batch 100] loss: 0.05172860234044492
**STATS for Epoch 7** : 
Average training loss: 0.0079
Average validation loss: 0.0665
Validation Accuracy: 0.9801
Overfitting: 0.0586
Best model saved at epoch 7 with validation loss: 0.0665
[Epoch 8, Batch 100] loss: 0.045971535639837385
**STATS for Epoch 8** : 
Average training loss: 0.0064
Average validation loss: 0.0687
Validation Accuracy: 0.9790
Overfitting: 0.0623
[Epoch 9, Batch 100] loss: 0.03979349425062537
**STATS for Epoch 9** : 
Average training loss: 0.0052
Average validation loss: 0.0662
Validation Accuracy: 0.9797
Overfitting: 0.0610
Best model saved at epoch 9 with validation loss: 0.0662
[Epoch 10, Batch 100] loss: 0.034517156993970274
**STATS for Epoch 10** : 
Average training loss: 0.0068
Average validation loss: 0.0663
Validation Accuracy: 0.9801
Overfitting: 0.0596
[Epoch 11, Batch 100] loss: 0.03659036038443446
**STATS for Epoch 11** : 
Average training loss: 0.0036
Average validation loss: 0.0572
Validation Accuracy: 0.9831
Overfitting: 0.0536
Best model saved at epoch 11 with validation loss: 0.0572
[Epoch 12, Batch 100] loss: 0.02669552848674357
**STATS for Epoch 12** : 
Average training loss: 0.0044
Average validation loss: 0.0600
Validation Accuracy: 0.9823
Overfitting: 0.0556
[Epoch 13, Batch 100] loss: 0.025282306130975485
**STATS for Epoch 13** : 
Average training loss: 0.0033
Average validation loss: 0.0629
Validation Accuracy: 0.9813
Overfitting: 0.0595
[Epoch 14, Batch 100] loss: 0.02140422573313117
**STATS for Epoch 14** : 
Average training loss: 0.0030
Average validation loss: 0.0533
Validation Accuracy: 0.9842
Overfitting: 0.0503
Best model saved at epoch 14 with validation loss: 0.0533
[Epoch 15, Batch 100] loss: 0.0178802228346467
**STATS for Epoch 15** : 
Average training loss: 0.0025
Average validation loss: 0.0557
Validation Accuracy: 0.9835
Overfitting: 0.0532
[Epoch 16, Batch 100] loss: 0.019771921901265158
**STATS for Epoch 16** : 
Average training loss: 0.0035
Average validation loss: 0.0541
Validation Accuracy: 0.9832
Overfitting: 0.0506
[Epoch 17, Batch 100] loss: 0.017269631524104625
**STATS for Epoch 17** : 
Average training loss: 0.0031
Average validation loss: 0.0596
Validation Accuracy: 0.9836
Overfitting: 0.0565
[Epoch 18, Batch 100] loss: 0.012989365494577213
**STATS for Epoch 18** : 
Average training loss: 0.0020
Average validation loss: 0.0559
Validation Accuracy: 0.9841
Overfitting: 0.0538
[Epoch 19, Batch 100] loss: 0.011559058035491034
**STATS for Epoch 19** : 
Average training loss: 0.0021
Average validation loss: 0.0577
Validation Accuracy: 0.9838
Overfitting: 0.0556
[Epoch 20, Batch 100] loss: 0.008915783792035654
**STATS for Epoch 20** : 
Average training loss: 0.0020
Average validation loss: 0.0587
Validation Accuracy: 0.9835
Overfitting: 0.0567
[Epoch 21, Batch 100] loss: 0.009876859145006165
**STATS for Epoch 21** : 
Average training loss: 0.0013
Average validation loss: 0.0543
Validation Accuracy: 0.9849
Overfitting: 0.0530
[Epoch 22, Batch 100] loss: 0.0077621668978827075
**STATS for Epoch 22** : 
Average training loss: 0.0012
Average validation loss: 0.0542
Validation Accuracy: 0.9859
Overfitting: 0.0530
[Epoch 23, Batch 100] loss: 0.005843328961054795
**STATS for Epoch 23** : 
Average training loss: 0.0013
Average validation loss: 0.0568
Validation Accuracy: 0.9848
Overfitting: 0.0555
[Epoch 24, Batch 100] loss: 0.006982120461761951
**STATS for Epoch 24** : 
Average training loss: 0.0012
Average validation loss: 0.0551
Validation Accuracy: 0.9860
Overfitting: 0.0540
Fold 2 validation loss: 0.0551
Mean validation loss across all folds for Trial 15 is 0.0670 with trial config:  l1: 256, l2: 128, lr: 0.009836048672425646, batch_size: 256
[I 2024-11-21 19:58:59,774] Trial 14 finished with value: 0.06695232073129234 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.009836048672425646, 'batch_size': 256}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 16:
  l1: 128, l2: 128, lr: 0.008482971226840623, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.5178491470217705
[Epoch 1, Batch 200] loss: 0.33642201371490954
[Epoch 1, Batch 300] loss: 0.22793155662715436
[Epoch 1, Batch 400] loss: 0.15835961388424039
**STATS for Epoch 1** : 
Average training loss: 0.0198
Average validation loss: 0.1297
Validation Accuracy: 0.9600
Overfitting: 0.1099
Best model saved at epoch 1 with validation loss: 0.1297
[Epoch 2, Batch 100] loss: 0.11648296590894461
[Epoch 2, Batch 200] loss: 0.09753213634714485
[Epoch 2, Batch 300] loss: 0.09784607118926943
[Epoch 2, Batch 400] loss: 0.08164238523691893
**STATS for Epoch 2** : 
Average training loss: 0.0134
Average validation loss: 0.0902
Validation Accuracy: 0.9711
Overfitting: 0.0768
Best model saved at epoch 2 with validation loss: 0.0902
[Epoch 3, Batch 100] loss: 0.07355072759557515
[Epoch 3, Batch 200] loss: 0.06311320412904024
[Epoch 3, Batch 300] loss: 0.06053910327609628
[Epoch 3, Batch 400] loss: 0.06251182923093439
**STATS for Epoch 3** : 
Average training loss: 0.0083
Average validation loss: 0.0740
Validation Accuracy: 0.9758
Overfitting: 0.0657
Best model saved at epoch 3 with validation loss: 0.0740
[Epoch 4, Batch 100] loss: 0.0457562068104744
[Epoch 4, Batch 200] loss: 0.054896700752433386
[Epoch 4, Batch 300] loss: 0.053655489401426164
[Epoch 4, Batch 400] loss: 0.05655823782784864
**STATS for Epoch 4** : 
Average training loss: 0.0077
Average validation loss: 0.0685
Validation Accuracy: 0.9793
Overfitting: 0.0608
Best model saved at epoch 4 with validation loss: 0.0685
[Epoch 5, Batch 100] loss: 0.035314944969723004
[Epoch 5, Batch 200] loss: 0.048645402395632115
[Epoch 5, Batch 300] loss: 0.04037013957975432
[Epoch 5, Batch 400] loss: 0.039389032224426045
**STATS for Epoch 5** : 
Average training loss: 0.0061
Average validation loss: 0.0599
Validation Accuracy: 0.9813
Overfitting: 0.0537
Best model saved at epoch 5 with validation loss: 0.0599
[Epoch 6, Batch 100] loss: 0.02930567410425283
[Epoch 6, Batch 200] loss: 0.03365418024826795
[Epoch 6, Batch 300] loss: 0.024491134892450646
[Epoch 6, Batch 400] loss: 0.035865121621463915
**STATS for Epoch 6** : 
Average training loss: 0.0059
Average validation loss: 0.0580
Validation Accuracy: 0.9834
Overfitting: 0.0521
Best model saved at epoch 6 with validation loss: 0.0580
[Epoch 7, Batch 100] loss: 0.021456553263706154
[Epoch 7, Batch 200] loss: 0.023252134567010217
[Epoch 7, Batch 300] loss: 0.0372940989973722
[Epoch 7, Batch 400] loss: 0.027279220547061413
**STATS for Epoch 7** : 
Average training loss: 0.0053
Average validation loss: 0.0652
Validation Accuracy: 0.9809
Overfitting: 0.0598
[Epoch 8, Batch 100] loss: 0.01748844739107881
[Epoch 8, Batch 200] loss: 0.024895568236534018
[Epoch 8, Batch 300] loss: 0.03019077322096564
[Epoch 8, Batch 400] loss: 0.028983271392062308
**STATS for Epoch 8** : 
Average training loss: 0.0044
Average validation loss: 0.0530
Validation Accuracy: 0.9852
Overfitting: 0.0487
Best model saved at epoch 8 with validation loss: 0.0530
[Epoch 9, Batch 100] loss: 0.019774039451149292
[Epoch 9, Batch 200] loss: 0.022147741533408406
[Epoch 9, Batch 300] loss: 0.01582410822244128
[Epoch 9, Batch 400] loss: 0.022574419401353227
**STATS for Epoch 9** : 
Average training loss: 0.0022
Average validation loss: 0.0523
Validation Accuracy: 0.9858
Overfitting: 0.0501
Best model saved at epoch 9 with validation loss: 0.0523
[Epoch 10, Batch 100] loss: 0.018018428892100927
[Epoch 10, Batch 200] loss: 0.013905238451552577
[Epoch 10, Batch 300] loss: 0.021503435884224018
[Epoch 10, Batch 400] loss: 0.012289852138492279
**STATS for Epoch 10** : 
Average training loss: 0.0027
Average validation loss: 0.0561
Validation Accuracy: 0.9851
Overfitting: 0.0534
[Epoch 11, Batch 100] loss: 0.01502977073279908
[Epoch 11, Batch 200] loss: 0.019135827618301845
[Epoch 11, Batch 300] loss: 0.022342627156904202
[Epoch 11, Batch 400] loss: 0.013180074503034121
**STATS for Epoch 11** : 
Average training loss: 0.0024
Average validation loss: 0.0587
Validation Accuracy: 0.9852
Overfitting: 0.0563
[Epoch 12, Batch 100] loss: 0.009074663845203758
[Epoch 12, Batch 200] loss: 0.01050555654001073
[Epoch 12, Batch 300] loss: 0.00839432866720017
[Epoch 12, Batch 400] loss: 0.01822777997716912
**STATS for Epoch 12** : 
Average training loss: 0.0020
Average validation loss: 0.0561
Validation Accuracy: 0.9859
Overfitting: 0.0541
[Epoch 13, Batch 100] loss: 0.010159920431033243
[Epoch 13, Batch 200] loss: 0.00992227568582166
[Epoch 13, Batch 300] loss: 0.006097319071777747
[Epoch 13, Batch 400] loss: 0.00866025895724306
**STATS for Epoch 13** : 
Average training loss: 0.0021
Average validation loss: 0.0647
Validation Accuracy: 0.9845
Overfitting: 0.0626
[Epoch 14, Batch 100] loss: 0.009139141432824545
[Epoch 14, Batch 200] loss: 0.009470609114359832
[Epoch 14, Batch 300] loss: 0.007118848170703132
[Epoch 14, Batch 400] loss: 0.006166342399847053
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0603
Validation Accuracy: 0.9860
Overfitting: 0.0595
[Epoch 15, Batch 100] loss: 0.004759340130767668
[Epoch 15, Batch 200] loss: 0.00712646715604933
[Epoch 15, Batch 300] loss: 0.008128457273396634
[Epoch 15, Batch 400] loss: 0.006296018271168578
**STATS for Epoch 15** : 
Average training loss: 0.0014
Average validation loss: 0.0651
Validation Accuracy: 0.9861
Overfitting: 0.0637
[Epoch 16, Batch 100] loss: 0.003524427152815406
[Epoch 16, Batch 200] loss: 0.007480749099777313
[Epoch 16, Batch 300] loss: 0.002566732455979945
[Epoch 16, Batch 400] loss: 0.0033539878859846794
**STATS for Epoch 16** : 
Average training loss: 0.0011
Average validation loss: 0.0659
Validation Accuracy: 0.9858
Overfitting: 0.0648
[Epoch 17, Batch 100] loss: 0.0019214486091550498
[Epoch 17, Batch 200] loss: 0.0054942436226883724
[Epoch 17, Batch 300] loss: 0.004166190441428626
[Epoch 17, Batch 400] loss: 0.007981728452832612
**STATS for Epoch 17** : 
Average training loss: 0.0013
Average validation loss: 0.0708
Validation Accuracy: 0.9851
Overfitting: 0.0695
[Epoch 18, Batch 100] loss: 0.005883753819671256
[Epoch 18, Batch 200] loss: 0.006221737820796988
[Epoch 18, Batch 300] loss: 0.0033556045952536804
[Epoch 18, Batch 400] loss: 0.0072212022755775256
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0642
Validation Accuracy: 0.9859
Overfitting: 0.0633
[Epoch 19, Batch 100] loss: 0.007652368206963729
[Epoch 19, Batch 200] loss: 0.010754537151424302
[Epoch 19, Batch 300] loss: 0.0060818053311231775
[Epoch 19, Batch 400] loss: 0.007338844926912316
**STATS for Epoch 19** : 
Average training loss: 0.0014
Average validation loss: 0.0690
Validation Accuracy: 0.9845
Overfitting: 0.0676
[Epoch 20, Batch 100] loss: 0.00655314589941554
[Epoch 20, Batch 200] loss: 0.0027098681356710584
[Epoch 20, Batch 300] loss: 0.013685857991681587
[Epoch 20, Batch 400] loss: 0.011105441686340782
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0708
Validation Accuracy: 0.9854
Overfitting: 0.0701
[Epoch 21, Batch 100] loss: 0.0053029633013647985
[Epoch 21, Batch 200] loss: 0.0025804634186715704
[Epoch 21, Batch 300] loss: 0.005106783953378908
[Epoch 21, Batch 400] loss: 0.003886773257609093
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0675
Validation Accuracy: 0.9868
Overfitting: 0.0670
[Epoch 22, Batch 100] loss: 0.002479296957853876
[Epoch 22, Batch 200] loss: 0.0014324204914805704
[Epoch 22, Batch 300] loss: 0.0019936286766574084
[Epoch 22, Batch 400] loss: 0.004549270777338279
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0726
Validation Accuracy: 0.9873
Overfitting: 0.0720
[Epoch 23, Batch 100] loss: 0.002490850378021605
[Epoch 23, Batch 200] loss: 0.0025078368044341914
[Epoch 23, Batch 300] loss: 0.0011937016772230892
[Epoch 23, Batch 400] loss: 0.0023011844807331273
**STATS for Epoch 23** : 
Average training loss: 0.0010
Average validation loss: 0.0686
Validation Accuracy: 0.9868
Overfitting: 0.0676
[Epoch 24, Batch 100] loss: 0.001359161810655678
[Epoch 24, Batch 200] loss: 0.004928995756527002
[Epoch 24, Batch 300] loss: 0.005782876839421078
[Epoch 24, Batch 400] loss: 0.009649232758738436
**STATS for Epoch 24** : 
Average training loss: 0.0016
Average validation loss: 0.0859
Validation Accuracy: 0.9839
Overfitting: 0.0843
Fold 1 validation loss: 0.0859
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.8177611881494522
[Epoch 1, Batch 200] loss: 0.4141939980536699
[Epoch 1, Batch 300] loss: 0.230256078094244
[Epoch 1, Batch 400] loss: 0.17460915189236403
**STATS for Epoch 1** : 
Average training loss: 0.0224
Average validation loss: 0.1306
Validation Accuracy: 0.9591
Overfitting: 0.1082
Best model saved at epoch 1 with validation loss: 0.1306
[Epoch 2, Batch 100] loss: 0.12206421053037048
[Epoch 2, Batch 200] loss: 0.10700579892843962
[Epoch 2, Batch 300] loss: 0.10132852524518966
[Epoch 2, Batch 400] loss: 0.09525843383278698
**STATS for Epoch 2** : 
Average training loss: 0.0126
Average validation loss: 0.0950
Validation Accuracy: 0.9711
Overfitting: 0.0824
Best model saved at epoch 2 with validation loss: 0.0950
[Epoch 3, Batch 100] loss: 0.06580403213389217
[Epoch 3, Batch 200] loss: 0.06806135787628591
[Epoch 3, Batch 300] loss: 0.0699713405361399
[Epoch 3, Batch 400] loss: 0.07648448050487787
**STATS for Epoch 3** : 
Average training loss: 0.0085
Average validation loss: 0.0683
Validation Accuracy: 0.9798
Overfitting: 0.0598
Best model saved at epoch 3 with validation loss: 0.0683
[Epoch 4, Batch 100] loss: 0.05054478060686961
[Epoch 4, Batch 200] loss: 0.051179784550331536
[Epoch 4, Batch 300] loss: 0.050775376738165505
[Epoch 4, Batch 400] loss: 0.053034415883012116
**STATS for Epoch 4** : 
Average training loss: 0.0078
Average validation loss: 0.0641
Validation Accuracy: 0.9816
Overfitting: 0.0563
Best model saved at epoch 4 with validation loss: 0.0641
[Epoch 5, Batch 100] loss: 0.03434967536944896
[Epoch 5, Batch 200] loss: 0.03835992475331295
[Epoch 5, Batch 300] loss: 0.04421179223922081
[Epoch 5, Batch 400] loss: 0.044180121028330174
**STATS for Epoch 5** : 
Average training loss: 0.0058
Average validation loss: 0.0553
Validation Accuracy: 0.9838
Overfitting: 0.0495
Best model saved at epoch 5 with validation loss: 0.0553
[Epoch 6, Batch 100] loss: 0.03546666400739923
[Epoch 6, Batch 200] loss: 0.0335908585251309
[Epoch 6, Batch 300] loss: 0.03546805048332317
[Epoch 6, Batch 400] loss: 0.03229037085780874
**STATS for Epoch 6** : 
Average training loss: 0.0051
Average validation loss: 0.0510
Validation Accuracy: 0.9854
Overfitting: 0.0458
Best model saved at epoch 6 with validation loss: 0.0510
[Epoch 7, Batch 100] loss: 0.027032115757465364
[Epoch 7, Batch 200] loss: 0.02560815990320407
[Epoch 7, Batch 300] loss: 0.03137033604842145
[Epoch 7, Batch 400] loss: 0.026015820315806196
**STATS for Epoch 7** : 
Average training loss: 0.0053
Average validation loss: 0.0634
Validation Accuracy: 0.9816
Overfitting: 0.0581
[Epoch 8, Batch 100] loss: 0.02516953529266175
[Epoch 8, Batch 200] loss: 0.021532168999983697
[Epoch 8, Batch 300] loss: 0.02802032786858035
[Epoch 8, Batch 400] loss: 0.025380728722375352
**STATS for Epoch 8** : 
Average training loss: 0.0029
Average validation loss: 0.0559
Validation Accuracy: 0.9848
Overfitting: 0.0530
[Epoch 9, Batch 100] loss: 0.014804559417825658
[Epoch 9, Batch 200] loss: 0.01792114094772842
[Epoch 9, Batch 300] loss: 0.0205012146855006
[Epoch 9, Batch 400] loss: 0.02525603082962334
**STATS for Epoch 9** : 
Average training loss: 0.0025
Average validation loss: 0.0590
Validation Accuracy: 0.9841
Overfitting: 0.0564
[Epoch 10, Batch 100] loss: 0.014101424672990106
[Epoch 10, Batch 200] loss: 0.012001125681272241
[Epoch 10, Batch 300] loss: 0.019244804619738716
[Epoch 10, Batch 400] loss: 0.015198161446751329
**STATS for Epoch 10** : 
Average training loss: 0.0024
Average validation loss: 0.0566
Validation Accuracy: 0.9862
Overfitting: 0.0542
[Epoch 11, Batch 100] loss: 0.01741798113747791
[Epoch 11, Batch 200] loss: 0.01783751726470655
[Epoch 11, Batch 300] loss: 0.011819308164122048
[Epoch 11, Batch 400] loss: 0.015279508414678275
**STATS for Epoch 11** : 
Average training loss: 0.0029
Average validation loss: 0.0557
Validation Accuracy: 0.9860
Overfitting: 0.0527
[Epoch 12, Batch 100] loss: 0.0102570457982074
[Epoch 12, Batch 200] loss: 0.011374132946511963
[Epoch 12, Batch 300] loss: 0.01925550866559206
[Epoch 12, Batch 400] loss: 0.011839316021796548
**STATS for Epoch 12** : 
Average training loss: 0.0015
Average validation loss: 0.0531
Validation Accuracy: 0.9868
Overfitting: 0.0516
[Epoch 13, Batch 100] loss: 0.00541769025126996
[Epoch 13, Batch 200] loss: 0.0070189096654939935
[Epoch 13, Batch 300] loss: 0.012055231821177586
[Epoch 13, Batch 400] loss: 0.010991513027474866
**STATS for Epoch 13** : 
Average training loss: 0.0022
Average validation loss: 0.0558
Validation Accuracy: 0.9865
Overfitting: 0.0535
[Epoch 14, Batch 100] loss: 0.007443801843874098
[Epoch 14, Batch 200] loss: 0.007630474160432641
[Epoch 14, Batch 300] loss: 0.006745333954604575
[Epoch 14, Batch 400] loss: 0.009223083664801379
**STATS for Epoch 14** : 
Average training loss: 0.0013
Average validation loss: 0.0538
Validation Accuracy: 0.9871
Overfitting: 0.0525
[Epoch 15, Batch 100] loss: 0.004576180180665687
[Epoch 15, Batch 200] loss: 0.007331836479788762
[Epoch 15, Batch 300] loss: 0.007165393757441052
[Epoch 15, Batch 400] loss: 0.009759763329329872
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0612
Validation Accuracy: 0.9864
Overfitting: 0.0603
[Epoch 16, Batch 100] loss: 0.009009416122280527
[Epoch 16, Batch 200] loss: 0.00967405195489846
[Epoch 16, Batch 300] loss: 0.008717410901808761
[Epoch 16, Batch 400] loss: 0.009147481984182377
**STATS for Epoch 16** : 
Average training loss: 0.0019
Average validation loss: 0.0670
Validation Accuracy: 0.9850
Overfitting: 0.0651
[Epoch 17, Batch 100] loss: 0.0037029492068359105
[Epoch 17, Batch 200] loss: 0.011054011777487176
[Epoch 17, Batch 300] loss: 0.005557528569515853
[Epoch 17, Batch 400] loss: 0.007824869274954835
**STATS for Epoch 17** : 
Average training loss: 0.0018
Average validation loss: 0.0571
Validation Accuracy: 0.9876
Overfitting: 0.0553
[Epoch 18, Batch 100] loss: 0.0038115861291316833
[Epoch 18, Batch 200] loss: 0.0023732000013569634
[Epoch 18, Batch 300] loss: 0.004766483644216351
[Epoch 18, Batch 400] loss: 0.006710451061762796
**STATS for Epoch 18** : 
Average training loss: 0.0018
Average validation loss: 0.0974
Validation Accuracy: 0.9791
Overfitting: 0.0956
[Epoch 19, Batch 100] loss: 0.015634181374689433
[Epoch 19, Batch 200] loss: 0.007119858068672329
[Epoch 19, Batch 300] loss: 0.008406827299659199
[Epoch 19, Batch 400] loss: 0.008380584584156168
**STATS for Epoch 19** : 
Average training loss: 0.0022
Average validation loss: 0.0599
Validation Accuracy: 0.9871
Overfitting: 0.0577
[Epoch 20, Batch 100] loss: 0.004149517913810996
[Epoch 20, Batch 200] loss: 0.0027855824595644663
[Epoch 20, Batch 300] loss: 0.0035801997199359902
[Epoch 20, Batch 400] loss: 0.0025283213765032995
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0604
Validation Accuracy: 0.9879
Overfitting: 0.0598
[Epoch 21, Batch 100] loss: 0.0008937556709679484
[Epoch 21, Batch 200] loss: 0.0011989093895590486
[Epoch 21, Batch 300] loss: 0.0006980453285905242
[Epoch 21, Batch 400] loss: 0.0014398829934680179
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0600
Validation Accuracy: 0.9884
Overfitting: 0.0599
[Epoch 22, Batch 100] loss: 0.000612329783629093
[Epoch 22, Batch 200] loss: 0.002060864516736274
[Epoch 22, Batch 300] loss: 0.0015520179488680696
[Epoch 22, Batch 400] loss: 0.0027101649868427557
**STATS for Epoch 22** : 
Average training loss: 0.0007
Average validation loss: 0.0653
Validation Accuracy: 0.9880
Overfitting: 0.0646
[Epoch 23, Batch 100] loss: 0.0016643826522386006
[Epoch 23, Batch 200] loss: 0.001023838389833145
[Epoch 23, Batch 300] loss: 0.0025561191833287466
[Epoch 23, Batch 400] loss: 0.006869014203798543
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0667
Validation Accuracy: 0.9876
Overfitting: 0.0663
[Epoch 24, Batch 100] loss: 0.0034180338920486975
[Epoch 24, Batch 200] loss: 0.010543245178350844
[Epoch 24, Batch 300] loss: 0.010613159670192544
[Epoch 24, Batch 400] loss: 0.006265773987970533
**STATS for Epoch 24** : 
Average training loss: 0.0019
Average validation loss: 0.0681
Validation Accuracy: 0.9862
Overfitting: 0.0662
Fold 2 validation loss: 0.0681
Mean validation loss across all folds for Trial 16 is 0.0770 with trial config:  l1: 128, l2: 128, lr: 0.008482971226840623, batch_size: 64
[I 2024-11-21 20:07:44,954] Trial 15 finished with value: 0.0770064502233182 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.008482971226840623, 'batch_size': 64}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 17:
  l1: 256, l2: 64, lr: 0.011006881336688933, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.4129761067032813
[Epoch 1, Batch 200] loss: 0.26523760341107844
**STATS for Epoch 1** : 
Average training loss: 0.0246
Average validation loss: 0.1655
Validation Accuracy: 0.9479
Overfitting: 0.1409
Best model saved at epoch 1 with validation loss: 0.1655
[Epoch 2, Batch 100] loss: 0.1380506868287921
[Epoch 2, Batch 200] loss: 0.10787663573399187
**STATS for Epoch 2** : 
Average training loss: 0.0166
Average validation loss: 0.1101
Validation Accuracy: 0.9647
Overfitting: 0.0934
Best model saved at epoch 2 with validation loss: 0.1101
[Epoch 3, Batch 100] loss: 0.07666848530992866
[Epoch 3, Batch 200] loss: 0.08086989611387253
**STATS for Epoch 3** : 
Average training loss: 0.0110
Average validation loss: 0.0929
Validation Accuracy: 0.9707
Overfitting: 0.0819
Best model saved at epoch 3 with validation loss: 0.0929
[Epoch 4, Batch 100] loss: 0.058467141911387445
[Epoch 4, Batch 200] loss: 0.06516856376081705
**STATS for Epoch 4** : 
Average training loss: 0.0088
Average validation loss: 0.0693
Validation Accuracy: 0.9795
Overfitting: 0.0605
Best model saved at epoch 4 with validation loss: 0.0693
[Epoch 5, Batch 100] loss: 0.040667068129405376
[Epoch 5, Batch 200] loss: 0.04869969080667943
**STATS for Epoch 5** : 
Average training loss: 0.0059
Average validation loss: 0.0695
Validation Accuracy: 0.9790
Overfitting: 0.0637
[Epoch 6, Batch 100] loss: 0.04198092630598694
[Epoch 6, Batch 200] loss: 0.03927431975258514
**STATS for Epoch 6** : 
Average training loss: 0.0044
Average validation loss: 0.0571
Validation Accuracy: 0.9829
Overfitting: 0.0527
Best model saved at epoch 6 with validation loss: 0.0571
[Epoch 7, Batch 100] loss: 0.02962770583573729
[Epoch 7, Batch 200] loss: 0.029334014854393898
**STATS for Epoch 7** : 
Average training loss: 0.0054
Average validation loss: 0.0541
Validation Accuracy: 0.9846
Overfitting: 0.0486
Best model saved at epoch 7 with validation loss: 0.0541
[Epoch 8, Batch 100] loss: 0.02307448583189398
[Epoch 8, Batch 200] loss: 0.02762228013947606
**STATS for Epoch 8** : 
Average training loss: 0.0047
Average validation loss: 0.0657
Validation Accuracy: 0.9808
Overfitting: 0.0610
[Epoch 9, Batch 100] loss: 0.02081193536403589
[Epoch 9, Batch 200] loss: 0.02183863990823738
**STATS for Epoch 9** : 
Average training loss: 0.0028
Average validation loss: 0.0587
Validation Accuracy: 0.9841
Overfitting: 0.0558
[Epoch 10, Batch 100] loss: 0.01607949148863554
[Epoch 10, Batch 200] loss: 0.018371353334514423
**STATS for Epoch 10** : 
Average training loss: 0.0024
Average validation loss: 0.0568
Validation Accuracy: 0.9842
Overfitting: 0.0545
[Epoch 11, Batch 100] loss: 0.012737616113154217
[Epoch 11, Batch 200] loss: 0.016312217353843153
**STATS for Epoch 11** : 
Average training loss: 0.0024
Average validation loss: 0.0613
Validation Accuracy: 0.9834
Overfitting: 0.0589
[Epoch 12, Batch 100] loss: 0.012824332941090689
[Epoch 12, Batch 200] loss: 0.015147966271615586
**STATS for Epoch 12** : 
Average training loss: 0.0015
Average validation loss: 0.0581
Validation Accuracy: 0.9854
Overfitting: 0.0566
[Epoch 13, Batch 100] loss: 0.009021395862509963
[Epoch 13, Batch 200] loss: 0.010271501471288502
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0610
Validation Accuracy: 0.9851
Overfitting: 0.0596
[Epoch 14, Batch 100] loss: 0.009475345558603293
[Epoch 14, Batch 200] loss: 0.010582683784596156
**STATS for Epoch 14** : 
Average training loss: 0.0014
Average validation loss: 0.0592
Validation Accuracy: 0.9853
Overfitting: 0.0578
[Epoch 15, Batch 100] loss: 0.0070565511329914446
[Epoch 15, Batch 200] loss: 0.008975055425253231
**STATS for Epoch 15** : 
Average training loss: 0.0011
Average validation loss: 0.0641
Validation Accuracy: 0.9851
Overfitting: 0.0630
[Epoch 16, Batch 100] loss: 0.0053452869535976786
[Epoch 16, Batch 200] loss: 0.004536266471259296
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0665
Validation Accuracy: 0.9846
Overfitting: 0.0657
[Epoch 17, Batch 100] loss: 0.0033901230210904034
[Epoch 17, Batch 200] loss: 0.0036605763345141894
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0622
Validation Accuracy: 0.9856
Overfitting: 0.0613
[Epoch 18, Batch 100] loss: 0.003470231132087065
[Epoch 18, Batch 200] loss: 0.003526896640541963
**STATS for Epoch 18** : 
Average training loss: 0.0010
Average validation loss: 0.0637
Validation Accuracy: 0.9864
Overfitting: 0.0627
[Epoch 19, Batch 100] loss: 0.004205749913962791
[Epoch 19, Batch 200] loss: 0.0027262117921782194
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0610
Validation Accuracy: 0.9869
Overfitting: 0.0606
[Epoch 20, Batch 100] loss: 0.00291236422241127
[Epoch 20, Batch 200] loss: 0.0015408860311799798
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0632
Validation Accuracy: 0.9869
Overfitting: 0.0630
[Epoch 21, Batch 100] loss: 0.0013661109953318374
[Epoch 21, Batch 200] loss: 0.0008823875199232134
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0632
Validation Accuracy: 0.9875
Overfitting: 0.0630
[Epoch 22, Batch 100] loss: 0.0004287569636289845
[Epoch 22, Batch 200] loss: 0.0005414674877647485
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0637
Validation Accuracy: 0.9874
Overfitting: 0.0636
[Epoch 23, Batch 100] loss: 0.0002670156343810959
[Epoch 23, Batch 200] loss: 0.0007761211681463465
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0649
Validation Accuracy: 0.9876
Overfitting: 0.0649
[Epoch 24, Batch 100] loss: 0.0007534371263227513
[Epoch 24, Batch 200] loss: 0.00032400494819739833
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0651
Validation Accuracy: 0.9878
Overfitting: 0.0651
Fold 1 validation loss: 0.0651
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.4785643801093102
[Epoch 1, Batch 200] loss: 0.29007813848555086
**STATS for Epoch 1** : 
Average training loss: 0.0283
Average validation loss: 0.1588
Validation Accuracy: 0.9506
Overfitting: 0.1305
Best model saved at epoch 1 with validation loss: 0.1588
[Epoch 2, Batch 100] loss: 0.1355628425627947
[Epoch 2, Batch 200] loss: 0.12466993518173694
**STATS for Epoch 2** : 
Average training loss: 0.0164
Average validation loss: 0.1171
Validation Accuracy: 0.9654
Overfitting: 0.1006
Best model saved at epoch 2 with validation loss: 0.1171
[Epoch 3, Batch 100] loss: 0.08568380685523153
[Epoch 3, Batch 200] loss: 0.08268544437363744
**STATS for Epoch 3** : 
Average training loss: 0.0114
Average validation loss: 0.0873
Validation Accuracy: 0.9737
Overfitting: 0.0759
Best model saved at epoch 3 with validation loss: 0.0873
[Epoch 4, Batch 100] loss: 0.07297180607914924
[Epoch 4, Batch 200] loss: 0.06333329856395721
**STATS for Epoch 4** : 
Average training loss: 0.0088
Average validation loss: 0.0728
Validation Accuracy: 0.9781
Overfitting: 0.0640
Best model saved at epoch 4 with validation loss: 0.0728
[Epoch 5, Batch 100] loss: 0.05069648056756705
[Epoch 5, Batch 200] loss: 0.05052475603297353
**STATS for Epoch 5** : 
Average training loss: 0.0088
Average validation loss: 0.0700
Validation Accuracy: 0.9792
Overfitting: 0.0613
Best model saved at epoch 5 with validation loss: 0.0700
[Epoch 6, Batch 100] loss: 0.0418273321678862
[Epoch 6, Batch 200] loss: 0.04668867802247405
**STATS for Epoch 6** : 
Average training loss: 0.0072
Average validation loss: 0.0646
Validation Accuracy: 0.9801
Overfitting: 0.0573
Best model saved at epoch 6 with validation loss: 0.0646
[Epoch 7, Batch 100] loss: 0.03646872516954318
[Epoch 7, Batch 200] loss: 0.033550778930075464
**STATS for Epoch 7** : 
Average training loss: 0.0065
Average validation loss: 0.0552
Validation Accuracy: 0.9825
Overfitting: 0.0487
Best model saved at epoch 7 with validation loss: 0.0552
[Epoch 8, Batch 100] loss: 0.03174429850419983
[Epoch 8, Batch 200] loss: 0.03029744792729616
**STATS for Epoch 8** : 
Average training loss: 0.0051
Average validation loss: 0.0603
Validation Accuracy: 0.9819
Overfitting: 0.0552
[Epoch 9, Batch 100] loss: 0.024596392698585986
[Epoch 9, Batch 200] loss: 0.02628146853297949
**STATS for Epoch 9** : 
Average training loss: 0.0045
Average validation loss: 0.0599
Validation Accuracy: 0.9828
Overfitting: 0.0554
[Epoch 10, Batch 100] loss: 0.023542630309821108
[Epoch 10, Batch 200] loss: 0.02116288834484294
**STATS for Epoch 10** : 
Average training loss: 0.0036
Average validation loss: 0.0568
Validation Accuracy: 0.9831
Overfitting: 0.0532
[Epoch 11, Batch 100] loss: 0.01889530910877511
[Epoch 11, Batch 200] loss: 0.02121288626338355
**STATS for Epoch 11** : 
Average training loss: 0.0040
Average validation loss: 0.0647
Validation Accuracy: 0.9823
Overfitting: 0.0607
[Epoch 12, Batch 100] loss: 0.015622455641278066
[Epoch 12, Batch 200] loss: 0.01998104263562709
**STATS for Epoch 12** : 
Average training loss: 0.0032
Average validation loss: 0.0625
Validation Accuracy: 0.9825
Overfitting: 0.0593
[Epoch 13, Batch 100] loss: 0.01510491840832401
[Epoch 13, Batch 200] loss: 0.013480962555622682
**STATS for Epoch 13** : 
Average training loss: 0.0026
Average validation loss: 0.0601
Validation Accuracy: 0.9834
Overfitting: 0.0576
[Epoch 14, Batch 100] loss: 0.014947222667688038
[Epoch 14, Batch 200] loss: 0.009843007001618389
**STATS for Epoch 14** : 
Average training loss: 0.0014
Average validation loss: 0.0550
Validation Accuracy: 0.9857
Overfitting: 0.0536
Best model saved at epoch 14 with validation loss: 0.0550
[Epoch 15, Batch 100] loss: 0.00986130146018695
[Epoch 15, Batch 200] loss: 0.00975198894215282
**STATS for Epoch 15** : 
Average training loss: 0.0013
Average validation loss: 0.0605
Validation Accuracy: 0.9851
Overfitting: 0.0592
[Epoch 16, Batch 100] loss: 0.00817016828310443
[Epoch 16, Batch 200] loss: 0.006653753909340594
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0611
Validation Accuracy: 0.9859
Overfitting: 0.0601
[Epoch 17, Batch 100] loss: 0.008095256628803327
[Epoch 17, Batch 200] loss: 0.01005858829972567
**STATS for Epoch 17** : 
Average training loss: 0.0010
Average validation loss: 0.0611
Validation Accuracy: 0.9854
Overfitting: 0.0601
[Epoch 18, Batch 100] loss: 0.006596966296638129
[Epoch 18, Batch 200] loss: 0.005749738273443654
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0630
Validation Accuracy: 0.9860
Overfitting: 0.0621
[Epoch 19, Batch 100] loss: 0.004111909457278671
[Epoch 19, Batch 200] loss: 0.0069302120301290415
**STATS for Epoch 19** : 
Average training loss: 0.0011
Average validation loss: 0.0662
Validation Accuracy: 0.9854
Overfitting: 0.0651
[Epoch 20, Batch 100] loss: 0.006487424731458305
[Epoch 20, Batch 200] loss: 0.004967389053927036
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0635
Validation Accuracy: 0.9859
Overfitting: 0.0629
[Epoch 21, Batch 100] loss: 0.0016477565321110887
[Epoch 21, Batch 200] loss: 0.0019976790804503253
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0677
Validation Accuracy: 0.9865
Overfitting: 0.0671
[Epoch 22, Batch 100] loss: 0.001743307408542023
[Epoch 22, Batch 200] loss: 0.0015175949851754921
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0666
Validation Accuracy: 0.9858
Overfitting: 0.0661
[Epoch 23, Batch 100] loss: 0.0010085794678889215
[Epoch 23, Batch 200] loss: 0.000691268594309804
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0635
Validation Accuracy: 0.9869
Overfitting: 0.0632
[Epoch 24, Batch 100] loss: 0.0013587638037643047
[Epoch 24, Batch 200] loss: 0.001215070569578529
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0658
Validation Accuracy: 0.9865
Overfitting: 0.0656
Fold 2 validation loss: 0.0658
Mean validation loss across all folds for Trial 17 is 0.0654 with trial config:  l1: 256, l2: 64, lr: 0.011006881336688933, batch_size: 128
[I 2024-11-21 20:16:01,634] Trial 16 finished with value: 0.06544145817858427 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.011006881336688933, 'batch_size': 128}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 18:
  l1: 256, l2: 128, lr: 0.009287011926825201, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.7183431857824325
[Epoch 1, Batch 200] loss: 0.5128335686679929
[Epoch 1, Batch 300] loss: 0.2833712752908468
[Epoch 1, Batch 400] loss: 0.24583849196322263
[Epoch 1, Batch 500] loss: 0.24120169079629705
[Epoch 1, Batch 600] loss: 0.19424841177649796
[Epoch 1, Batch 700] loss: 0.15687919717514887
[Epoch 1, Batch 800] loss: 0.130721018545446
[Epoch 1, Batch 900] loss: 0.1557041014567949
[Epoch 1, Batch 1000] loss: 0.12345591827644967
[Epoch 1, Batch 1100] loss: 0.1407508731808048
[Epoch 1, Batch 1200] loss: 0.11929468808230012
[Epoch 1, Batch 1300] loss: 0.1272491189435823
[Epoch 1, Batch 1400] loss: 0.09156279630085919
[Epoch 1, Batch 1500] loss: 0.11227333293587435
[Epoch 1, Batch 1600] loss: 0.10919361776148434
[Epoch 1, Batch 1700] loss: 0.13656927307369188
[Epoch 1, Batch 1800] loss: 0.1020328961731866
**STATS for Epoch 1** : 
Average training loss: 0.0039
Average validation loss: 0.1041
Validation Accuracy: 0.9676
Overfitting: 0.1002
Best model saved at epoch 1 with validation loss: 0.1041
[Epoch 2, Batch 100] loss: 0.0759716665185988
[Epoch 2, Batch 200] loss: 0.0744373479825299
[Epoch 2, Batch 300] loss: 0.08513028897687036
[Epoch 2, Batch 400] loss: 0.09579021408775588
[Epoch 2, Batch 500] loss: 0.08251315028741374
[Epoch 2, Batch 600] loss: 0.08065836964626215
[Epoch 2, Batch 700] loss: 0.06977812938021088
[Epoch 2, Batch 800] loss: 0.06603902863935218
[Epoch 2, Batch 900] loss: 0.08790901350148488
[Epoch 2, Batch 1000] loss: 0.08412634162174072
[Epoch 2, Batch 1100] loss: 0.06912226189480862
[Epoch 2, Batch 1200] loss: 0.07364583141083131
[Epoch 2, Batch 1300] loss: 0.09677773006806092
[Epoch 2, Batch 1400] loss: 0.06836313632084057
[Epoch 2, Batch 1500] loss: 0.061079849269008266
[Epoch 2, Batch 1600] loss: 0.05674497862768476
[Epoch 2, Batch 1700] loss: 0.06719873774132794
[Epoch 2, Batch 1800] loss: 0.07380924441822571
**STATS for Epoch 2** : 
Average training loss: 0.0034
Average validation loss: 0.0668
Validation Accuracy: 0.9807
Overfitting: 0.0634
Best model saved at epoch 2 with validation loss: 0.0668
[Epoch 3, Batch 100] loss: 0.040207861077069536
[Epoch 3, Batch 200] loss: 0.04276477546321985
[Epoch 3, Batch 300] loss: 0.04358350830561904
[Epoch 3, Batch 400] loss: 0.07997283750872157
[Epoch 3, Batch 500] loss: 0.05005164313610294
[Epoch 3, Batch 600] loss: 0.06560608572006459
[Epoch 3, Batch 700] loss: 0.043274863725309844
[Epoch 3, Batch 800] loss: 0.054053951479136234
[Epoch 3, Batch 900] loss: 0.032031315832682594
[Epoch 3, Batch 1000] loss: 0.050685021920071446
[Epoch 3, Batch 1100] loss: 0.04520426690209206
[Epoch 3, Batch 1200] loss: 0.042673729295602245
[Epoch 3, Batch 1300] loss: 0.048690164877843924
[Epoch 3, Batch 1400] loss: 0.06062173479491321
[Epoch 3, Batch 1500] loss: 0.0434909339441947
[Epoch 3, Batch 1600] loss: 0.052799630481167696
[Epoch 3, Batch 1700] loss: 0.06338712093725916
[Epoch 3, Batch 1800] loss: 0.052897745501686584
**STATS for Epoch 3** : 
Average training loss: 0.0037
Average validation loss: 0.1503
Validation Accuracy: 0.9573
Overfitting: 0.1466
[Epoch 4, Batch 100] loss: 0.05157285684719682
[Epoch 4, Batch 200] loss: 0.02722674817923689
[Epoch 4, Batch 300] loss: 0.04168577422760791
[Epoch 4, Batch 400] loss: 0.04279612816742883
[Epoch 4, Batch 500] loss: 0.043493106206515225
[Epoch 4, Batch 600] loss: 0.03736354831962672
[Epoch 4, Batch 700] loss: 0.08081598049844615
[Epoch 4, Batch 800] loss: 0.03228421756935859
[Epoch 4, Batch 900] loss: 0.03368037108233693
[Epoch 4, Batch 1000] loss: 0.028535453068780043
[Epoch 4, Batch 1100] loss: 0.03343205903830494
[Epoch 4, Batch 1200] loss: 0.044660529607062925
[Epoch 4, Batch 1300] loss: 0.057092625510867946
[Epoch 4, Batch 1400] loss: 0.040510021036789114
[Epoch 4, Batch 1500] loss: 0.03756666733168459
[Epoch 4, Batch 1600] loss: 0.03739955233922046
[Epoch 4, Batch 1700] loss: 0.031222741189158115
[Epoch 4, Batch 1800] loss: 0.050767244795370065
**STATS for Epoch 4** : 
Average training loss: 0.0015
Average validation loss: 0.0798
Validation Accuracy: 0.9801
Overfitting: 0.0783
[Epoch 5, Batch 100] loss: 0.03653485468270446
[Epoch 5, Batch 200] loss: 0.028605792075941282
[Epoch 5, Batch 300] loss: 0.029654243528930237
[Epoch 5, Batch 400] loss: 0.031131086033917656
[Epoch 5, Batch 500] loss: 0.03805541237268699
[Epoch 5, Batch 600] loss: 0.02128239609379307
[Epoch 5, Batch 700] loss: 0.02918878955931177
[Epoch 5, Batch 800] loss: 0.036169821262383266
[Epoch 5, Batch 900] loss: 0.04323950100086222
[Epoch 5, Batch 1000] loss: 0.02636598990751281
[Epoch 5, Batch 1100] loss: 0.03146828963031112
[Epoch 5, Batch 1200] loss: 0.04204146845562718
[Epoch 5, Batch 1300] loss: 0.015331217414372987
[Epoch 5, Batch 1400] loss: 0.029490300354336797
[Epoch 5, Batch 1500] loss: 0.03645651989240832
[Epoch 5, Batch 1600] loss: 0.04406725375076349
[Epoch 5, Batch 1700] loss: 0.032728816188537166
[Epoch 5, Batch 1800] loss: 0.040617620496923336
**STATS for Epoch 5** : 
Average training loss: 0.0011
Average validation loss: 0.0563
Validation Accuracy: 0.9848
Overfitting: 0.0552
Best model saved at epoch 5 with validation loss: 0.0563
[Epoch 6, Batch 100] loss: 0.015813403192269107
[Epoch 6, Batch 200] loss: 0.013006354205448361
[Epoch 6, Batch 300] loss: 0.020551309410125215
[Epoch 6, Batch 400] loss: 0.015287528187446924
[Epoch 6, Batch 500] loss: 0.06735364845890217
[Epoch 6, Batch 600] loss: 0.022816132116449808
[Epoch 6, Batch 700] loss: 0.029055161639225845
[Epoch 6, Batch 800] loss: 0.022597391617327958
[Epoch 6, Batch 900] loss: 0.023507115733686988
[Epoch 6, Batch 1000] loss: 0.04082655977734248
[Epoch 6, Batch 1100] loss: 0.03731719123416952
[Epoch 6, Batch 1200] loss: 0.021814119017117262
[Epoch 6, Batch 1300] loss: 0.031521864976884896
[Epoch 6, Batch 1400] loss: 0.021607477658451443
[Epoch 6, Batch 1500] loss: 0.05424909145639503
[Epoch 6, Batch 1600] loss: 0.035826994330382146
[Epoch 6, Batch 1700] loss: 0.042655401693509704
[Epoch 6, Batch 1800] loss: 0.04050724992941923
**STATS for Epoch 6** : 
Average training loss: 0.0011
Average validation loss: 0.0753
Validation Accuracy: 0.9817
Overfitting: 0.0742
[Epoch 7, Batch 100] loss: 0.019457724437997967
[Epoch 7, Batch 200] loss: 0.01836634452862654
[Epoch 7, Batch 300] loss: 0.02483078916096929
[Epoch 7, Batch 400] loss: 0.024882801168314473
[Epoch 7, Batch 500] loss: 0.021668993267057887
[Epoch 7, Batch 600] loss: 0.024055821039760304
[Epoch 7, Batch 700] loss: 0.026223411738816368
[Epoch 7, Batch 800] loss: 0.005651606822211761
[Epoch 7, Batch 900] loss: 0.01771504748919881
[Epoch 7, Batch 1000] loss: 0.03905446007838293
[Epoch 7, Batch 1100] loss: 0.044324472857442745
[Epoch 7, Batch 1200] loss: 0.020843284603861322
[Epoch 7, Batch 1300] loss: 0.031165100749514067
[Epoch 7, Batch 1400] loss: 0.03015810021728612
[Epoch 7, Batch 1500] loss: 0.0340144372537361
[Epoch 7, Batch 1600] loss: 0.032930621476484706
[Epoch 7, Batch 1700] loss: 0.02308745799228518
[Epoch 7, Batch 1800] loss: 0.0482126366715238
**STATS for Epoch 7** : 
Average training loss: 0.0013
Average validation loss: 0.0785
Validation Accuracy: 0.9802
Overfitting: 0.0772
[Epoch 8, Batch 100] loss: 0.018585026190967257
[Epoch 8, Batch 200] loss: 0.01900923267432404
[Epoch 8, Batch 300] loss: 0.05003281879254235
[Epoch 8, Batch 400] loss: 0.020941713368961244
[Epoch 8, Batch 500] loss: 0.006413537012132054
[Epoch 8, Batch 600] loss: 0.03065730773228893
[Epoch 8, Batch 700] loss: 0.007461269791689346
[Epoch 8, Batch 800] loss: 0.020410924600106597
[Epoch 8, Batch 900] loss: 0.02693592073704508
[Epoch 8, Batch 1000] loss: 0.03461572605195101
[Epoch 8, Batch 1100] loss: 0.01256767113756041
[Epoch 8, Batch 1200] loss: 0.021478944002056154
[Epoch 8, Batch 1300] loss: 0.03551376929945946
[Epoch 8, Batch 1400] loss: 0.026801366592612796
[Epoch 8, Batch 1500] loss: 0.017294937883308423
[Epoch 8, Batch 1600] loss: 0.022709446581652627
[Epoch 8, Batch 1700] loss: 0.04067556912396867
[Epoch 8, Batch 1800] loss: 0.04014042011195215
**STATS for Epoch 8** : 
Average training loss: 0.0004
Average validation loss: 0.0593
Validation Accuracy: 0.9859
Overfitting: 0.0590
[Epoch 9, Batch 100] loss: 0.012011089438865384
[Epoch 9, Batch 200] loss: 0.02118529570892349
[Epoch 9, Batch 300] loss: 0.02575565235079921
[Epoch 9, Batch 400] loss: 0.021095277677632113
[Epoch 9, Batch 500] loss: 0.008796640008116157
[Epoch 9, Batch 600] loss: 0.04794432749212319
[Epoch 9, Batch 700] loss: 0.014395615724607751
[Epoch 9, Batch 800] loss: 0.01736720731212472
[Epoch 9, Batch 900] loss: 0.011223006753101004
[Epoch 9, Batch 1000] loss: 0.019072039099348785
[Epoch 9, Batch 1100] loss: 0.0073852517820057525
[Epoch 9, Batch 1200] loss: 0.011255321487358855
[Epoch 9, Batch 1300] loss: 0.026859756815113087
[Epoch 9, Batch 1400] loss: 0.013133167122059737
[Epoch 9, Batch 1500] loss: 0.015547171394433689
[Epoch 9, Batch 1600] loss: 0.014236473771379678
[Epoch 9, Batch 1700] loss: 0.017546162997507508
[Epoch 9, Batch 1800] loss: 0.007453557189203366
**STATS for Epoch 9** : 
Average training loss: 0.0005
Average validation loss: 0.0734
Validation Accuracy: 0.9838
Overfitting: 0.0729
[Epoch 10, Batch 100] loss: 0.005980997379695623
[Epoch 10, Batch 200] loss: 0.019644673667430935
[Epoch 10, Batch 300] loss: 0.00850130475956803
[Epoch 10, Batch 400] loss: 0.010362261369594138
[Epoch 10, Batch 500] loss: 0.023871378868268033
[Epoch 10, Batch 600] loss: 0.010551612330039291
[Epoch 10, Batch 700] loss: 0.016425424223324967
[Epoch 10, Batch 800] loss: 0.017799433171116805
[Epoch 10, Batch 900] loss: 0.011577591529360234
[Epoch 10, Batch 1000] loss: 0.01684928832990771
[Epoch 10, Batch 1100] loss: 0.01073237868994596
[Epoch 10, Batch 1200] loss: 0.021584969889535125
[Epoch 10, Batch 1300] loss: 0.015557905901996315
[Epoch 10, Batch 1400] loss: 0.01863499983736915
[Epoch 10, Batch 1500] loss: 0.017718586426357204
[Epoch 10, Batch 1600] loss: 0.027399963075424694
[Epoch 10, Batch 1700] loss: 0.022503153843786095
[Epoch 10, Batch 1800] loss: 0.025192988999475575
**STATS for Epoch 10** : 
Average training loss: 0.0006
Average validation loss: 0.0706
Validation Accuracy: 0.9844
Overfitting: 0.0699
[Epoch 11, Batch 100] loss: 0.012136788849709888
[Epoch 11, Batch 200] loss: 0.01500894684812689
[Epoch 11, Batch 300] loss: 0.019170179697485707
[Epoch 11, Batch 400] loss: 0.007510240049491475
[Epoch 11, Batch 500] loss: 0.010204324429820347
[Epoch 11, Batch 600] loss: 0.008706059624883977
[Epoch 11, Batch 700] loss: 0.006247762637228682
[Epoch 11, Batch 800] loss: 0.01411350066377187
[Epoch 11, Batch 900] loss: 0.02197681758721608
[Epoch 11, Batch 1000] loss: 0.01712146924868904
[Epoch 11, Batch 1100] loss: 0.0077725732686869265
[Epoch 11, Batch 1200] loss: 0.01703074199094516
[Epoch 11, Batch 1300] loss: 0.012238808568070424
[Epoch 11, Batch 1400] loss: 0.013356466121589392
[Epoch 11, Batch 1500] loss: 0.023972610596426448
[Epoch 11, Batch 1600] loss: 0.017289476719144332
[Epoch 11, Batch 1700] loss: 0.007186081579532906
[Epoch 11, Batch 1800] loss: 0.025629647381646237
**STATS for Epoch 11** : 
Average training loss: 0.0010
Average validation loss: 0.0880
Validation Accuracy: 0.9813
Overfitting: 0.0870
[Epoch 12, Batch 100] loss: 0.022777739038999982
[Epoch 12, Batch 200] loss: 0.005938290443028178
[Epoch 12, Batch 300] loss: 0.009144314438270414
[Epoch 12, Batch 400] loss: 0.03237325597827592
[Epoch 12, Batch 500] loss: 0.012426053358633454
[Epoch 12, Batch 600] loss: 0.004187566091608446
[Epoch 12, Batch 700] loss: 0.020318283852374604
[Epoch 12, Batch 800] loss: 0.006993285348419534
[Epoch 12, Batch 900] loss: 0.007662948448723342
[Epoch 12, Batch 1000] loss: 0.02391560337652606
[Epoch 12, Batch 1100] loss: 0.020844834381963436
[Epoch 12, Batch 1200] loss: 0.010881937626648073
[Epoch 12, Batch 1300] loss: 0.017109374967726722
[Epoch 12, Batch 1400] loss: 0.019048645554691265
[Epoch 12, Batch 1500] loss: 0.006439016214233053
[Epoch 12, Batch 1600] loss: 0.011072279164345935
[Epoch 12, Batch 1700] loss: 0.017022633849116175
[Epoch 12, Batch 1800] loss: 0.02718055029970458
**STATS for Epoch 12** : 
Average training loss: 0.0005
Average validation loss: 0.0758
Validation Accuracy: 0.9836
Overfitting: 0.0752
[Epoch 13, Batch 100] loss: 0.0187222149175469
[Epoch 13, Batch 200] loss: 0.018362803502433262
[Epoch 13, Batch 300] loss: 0.024467411266114035
[Epoch 13, Batch 400] loss: 0.009588166657451316
[Epoch 13, Batch 500] loss: 0.006930304739546802
[Epoch 13, Batch 600] loss: 0.010890693249855974
[Epoch 13, Batch 700] loss: 0.0073326666410751164
[Epoch 13, Batch 800] loss: 0.022630036822730945
[Epoch 13, Batch 900] loss: 0.012718712229844584
[Epoch 13, Batch 1000] loss: 0.033177207503817085
[Epoch 13, Batch 1100] loss: 0.012105363811642587
[Epoch 13, Batch 1200] loss: 0.0396697755418261
[Epoch 13, Batch 1300] loss: 0.03379295547813882
[Epoch 13, Batch 1400] loss: 0.011575962204798671
[Epoch 13, Batch 1500] loss: 0.006380860499792078
[Epoch 13, Batch 1600] loss: 0.01632940968142144
[Epoch 13, Batch 1700] loss: 0.02945503952732537
[Epoch 13, Batch 1800] loss: 0.028220740125857447
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0980
Validation Accuracy: 0.9809
Overfitting: 0.0969
[Epoch 14, Batch 100] loss: 0.014762592429528638
[Epoch 14, Batch 200] loss: 0.0183792386813343
[Epoch 14, Batch 300] loss: 0.015001768990647833
[Epoch 14, Batch 400] loss: 0.01396821871611408
[Epoch 14, Batch 500] loss: 0.015936212231557754
[Epoch 14, Batch 600] loss: 0.013923895832829292
[Epoch 14, Batch 700] loss: 0.017596129801605395
[Epoch 14, Batch 800] loss: 0.01138997442118182
[Epoch 14, Batch 900] loss: 0.010092133252520128
[Epoch 14, Batch 1000] loss: 0.011337561429741063
[Epoch 14, Batch 1100] loss: 0.023632563161912715
[Epoch 14, Batch 1200] loss: 0.021442496117554624
[Epoch 14, Batch 1300] loss: 0.008793358766887813
[Epoch 14, Batch 1400] loss: 0.009481832374276347
[Epoch 14, Batch 1500] loss: 0.008178342016492798
[Epoch 14, Batch 1600] loss: 0.030330960922397024
[Epoch 14, Batch 1700] loss: 0.01436895829648762
[Epoch 14, Batch 1800] loss: 0.011993209864234555
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0856
Validation Accuracy: 0.9822
Overfitting: 0.0850
[Epoch 15, Batch 100] loss: 0.012276072740455612
[Epoch 15, Batch 200] loss: 0.016653991874626822
[Epoch 15, Batch 300] loss: 0.012199294189365446
[Epoch 15, Batch 400] loss: 0.014432521543990759
[Epoch 15, Batch 500] loss: 0.026775138952522218
[Epoch 15, Batch 600] loss: 0.0064800316815876256
[Epoch 15, Batch 700] loss: 0.030677860908658285
[Epoch 15, Batch 800] loss: 0.01445514772226744
[Epoch 15, Batch 900] loss: 0.00817130542000021
[Epoch 15, Batch 1000] loss: 0.01400606022733788
[Epoch 15, Batch 1100] loss: 0.017598719093832642
[Epoch 15, Batch 1200] loss: 0.011684332516216176
[Epoch 15, Batch 1300] loss: 0.01088754320961483
[Epoch 15, Batch 1400] loss: 0.007631538678516696
[Epoch 15, Batch 1500] loss: 0.008936109739179764
[Epoch 15, Batch 1600] loss: 0.01605921667618386
[Epoch 15, Batch 1700] loss: 0.03929337148236815
[Epoch 15, Batch 1800] loss: 0.02769330573725945
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0953
Validation Accuracy: 0.9827
Overfitting: 0.0943
[Epoch 16, Batch 100] loss: 0.010649238016974429
[Epoch 16, Batch 200] loss: 0.007295964962366575
[Epoch 16, Batch 300] loss: 0.004983323777380306
[Epoch 16, Batch 400] loss: 0.02179412135865647
[Epoch 16, Batch 500] loss: 0.010300683803570862
[Epoch 16, Batch 600] loss: 0.039652843727201334
[Epoch 16, Batch 700] loss: 0.017112375467479807
[Epoch 16, Batch 800] loss: 0.01427833136425459
[Epoch 16, Batch 900] loss: 0.018298779430855134
[Epoch 16, Batch 1000] loss: 0.011109759932587764
[Epoch 16, Batch 1100] loss: 0.018013991343866033
[Epoch 16, Batch 1200] loss: 0.011627655077990701
[Epoch 16, Batch 1300] loss: 0.013632204495287535
[Epoch 16, Batch 1400] loss: 0.015814897461666106
[Epoch 16, Batch 1500] loss: 0.022932450499905138
[Epoch 16, Batch 1600] loss: 0.02650834687190894
[Epoch 16, Batch 1700] loss: 0.020349878328130722
[Epoch 16, Batch 1800] loss: 0.03248821547906815
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0714
Validation Accuracy: 0.9847
Overfitting: 0.0705
[Epoch 17, Batch 100] loss: 0.008945436589845306
[Epoch 17, Batch 200] loss: 0.005329320383172167
[Epoch 17, Batch 300] loss: 0.010748360668804935
[Epoch 17, Batch 400] loss: 0.003174512312359621
[Epoch 17, Batch 500] loss: 0.004365523102291462
[Epoch 17, Batch 600] loss: 0.0012760163596480113
[Epoch 17, Batch 700] loss: 0.0023863371906271123
[Epoch 17, Batch 800] loss: 0.0025070725515181636
[Epoch 17, Batch 900] loss: 0.015684739193552556
[Epoch 17, Batch 1000] loss: 0.007363075983477039
[Epoch 17, Batch 1100] loss: 0.004132556990020362
[Epoch 17, Batch 1200] loss: 0.002222500340450488
[Epoch 17, Batch 1300] loss: 0.002738842740284819
[Epoch 17, Batch 1400] loss: 0.004116010522342526
[Epoch 17, Batch 1500] loss: 0.0031905961231042035
[Epoch 17, Batch 1600] loss: 0.0007558783286030035
[Epoch 17, Batch 1700] loss: 0.0005071204210360936
[Epoch 17, Batch 1800] loss: 0.0027699270823833767
**STATS for Epoch 17** : 
Average training loss: 0.0002
Average validation loss: 0.0933
Validation Accuracy: 0.9857
Overfitting: 0.0931
[Epoch 18, Batch 100] loss: 0.003026249853016281
[Epoch 18, Batch 200] loss: 0.011651509531533212
[Epoch 18, Batch 300] loss: 0.0120161037455697
[Epoch 18, Batch 400] loss: 0.0009994932986688587
[Epoch 18, Batch 500] loss: 0.00225954522369908
[Epoch 18, Batch 600] loss: 0.010434093691078955
[Epoch 18, Batch 700] loss: 0.003745678730236146
[Epoch 18, Batch 800] loss: 0.014671280310328499
[Epoch 18, Batch 900] loss: 0.0017658651753155574
[Epoch 18, Batch 1000] loss: 0.003605796693369587
[Epoch 18, Batch 1100] loss: 0.0045968463472931195
[Epoch 18, Batch 1200] loss: 0.0033212949354273526
[Epoch 18, Batch 1300] loss: 0.023556480848771363
[Epoch 18, Batch 1400] loss: 0.012347384184554699
[Epoch 18, Batch 1500] loss: 0.011354960294946875
[Epoch 18, Batch 1600] loss: 0.007866443636576128
[Epoch 18, Batch 1700] loss: 0.015772739810560196
[Epoch 18, Batch 1800] loss: 0.010806731763386628
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0936
Validation Accuracy: 0.9832
Overfitting: 0.0927
[Epoch 19, Batch 100] loss: 0.007166484784133007
[Epoch 19, Batch 200] loss: 0.012438700461760033
[Epoch 19, Batch 300] loss: 0.03341562868088031
[Epoch 19, Batch 400] loss: 0.011856319183551954
[Epoch 19, Batch 500] loss: 0.010199980726505502
[Epoch 19, Batch 600] loss: 0.02354575180644261
[Epoch 19, Batch 700] loss: 0.02463801910633066
[Epoch 19, Batch 800] loss: 0.015695979225299368
[Epoch 19, Batch 900] loss: 0.007321775805787123
[Epoch 19, Batch 1000] loss: 0.011948145170378406
[Epoch 19, Batch 1100] loss: 0.006482734345840728
[Epoch 19, Batch 1200] loss: 0.0022211706829023425
[Epoch 19, Batch 1300] loss: 0.010605493453120736
[Epoch 19, Batch 1400] loss: 0.003090800526738846
[Epoch 19, Batch 1500] loss: 0.017095918485712697
[Epoch 19, Batch 1600] loss: 0.01573028349410356
[Epoch 19, Batch 1700] loss: 0.012690844317974874
[Epoch 19, Batch 1800] loss: 0.00994042254727706
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0894
Validation Accuracy: 0.9845
Overfitting: 0.0892
[Epoch 20, Batch 100] loss: 0.024878039003652423
[Epoch 20, Batch 200] loss: 0.023810961790768203
[Epoch 20, Batch 300] loss: 0.00899518372869732
[Epoch 20, Batch 400] loss: 0.012368116186386748
[Epoch 20, Batch 500] loss: 0.00297163083278285
[Epoch 20, Batch 600] loss: 0.005409339417146981
[Epoch 20, Batch 700] loss: 0.005873654633656518
[Epoch 20, Batch 800] loss: 0.005991509815473663
[Epoch 20, Batch 900] loss: 0.0018923242546553087
[Epoch 20, Batch 1000] loss: 0.006508805964652619
[Epoch 20, Batch 1100] loss: 0.004774510930831477
[Epoch 20, Batch 1200] loss: 0.0035786959948807874
[Epoch 20, Batch 1300] loss: 0.013732309419314763
[Epoch 20, Batch 1400] loss: 0.008165823711002744
[Epoch 20, Batch 1500] loss: 0.007978791537920178
[Epoch 20, Batch 1600] loss: 0.012940743818994727
[Epoch 20, Batch 1700] loss: 0.04214231357451161
[Epoch 20, Batch 1800] loss: 0.025542563807946478
**STATS for Epoch 20** : 
Average training loss: 0.0007
Average validation loss: 0.0974
Validation Accuracy: 0.9832
Overfitting: 0.0967
[Epoch 21, Batch 100] loss: 0.012867521619038426
[Epoch 21, Batch 200] loss: 0.005242376111466971
[Epoch 21, Batch 300] loss: 0.005028739906632049
[Epoch 21, Batch 400] loss: 0.0012254181870292858
[Epoch 21, Batch 500] loss: 0.003731048710682936
[Epoch 21, Batch 600] loss: 0.009584831982045041
[Epoch 21, Batch 700] loss: 0.002133092003362922
[Epoch 21, Batch 800] loss: 0.004986243724331953
[Epoch 21, Batch 900] loss: 0.00908675804350557
[Epoch 21, Batch 1000] loss: 0.005762077433240447
[Epoch 21, Batch 1100] loss: 0.004588788745358032
[Epoch 21, Batch 1200] loss: 0.02736066898265094
[Epoch 21, Batch 1300] loss: 0.010945826482692688
[Epoch 21, Batch 1400] loss: 0.006037231453215988
[Epoch 21, Batch 1500] loss: 0.008974510047906637
[Epoch 21, Batch 1600] loss: 0.006231760952669383
[Epoch 21, Batch 1700] loss: 0.0026593942504735237
[Epoch 21, Batch 1800] loss: 0.003947153370216321
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0837
Validation Accuracy: 0.9878
Overfitting: 0.0837
[Epoch 22, Batch 100] loss: 0.0009578911189061667
[Epoch 22, Batch 200] loss: 0.004501763779858203
[Epoch 22, Batch 300] loss: 0.016133036470432485
[Epoch 22, Batch 400] loss: 0.010656580765584822
[Epoch 22, Batch 500] loss: 0.010284632807358349
[Epoch 22, Batch 600] loss: 0.016729708955065724
[Epoch 22, Batch 700] loss: 0.011244356544986971
[Epoch 22, Batch 800] loss: 0.002668480252885104
[Epoch 22, Batch 900] loss: 0.0030223304165453513
[Epoch 22, Batch 1000] loss: 0.018473071736506537
[Epoch 22, Batch 1100] loss: 0.019824573736694127
[Epoch 22, Batch 1200] loss: 0.022135290709954823
[Epoch 22, Batch 1300] loss: 0.01873058739909977
[Epoch 22, Batch 1400] loss: 0.007823881096885804
[Epoch 22, Batch 1500] loss: 0.010213068397141992
[Epoch 22, Batch 1600] loss: 0.00916452781633792
[Epoch 22, Batch 1700] loss: 0.010733000785009281
[Epoch 22, Batch 1800] loss: 0.022593261207415432
**STATS for Epoch 22** : 
Average training loss: 0.0010
Average validation loss: 0.1279
Validation Accuracy: 0.9791
Overfitting: 0.1269
[Epoch 23, Batch 100] loss: 0.04414439175617185
[Epoch 23, Batch 200] loss: 0.05292539131075335
[Epoch 23, Batch 300] loss: 0.01682744221873678
[Epoch 23, Batch 400] loss: 0.016221484530191895
[Epoch 23, Batch 500] loss: 0.02072383721044464
[Epoch 23, Batch 600] loss: 0.00938535610345248
[Epoch 23, Batch 700] loss: 0.012888144888241592
[Epoch 23, Batch 800] loss: 0.006440415258153287
[Epoch 23, Batch 900] loss: 0.008945765913413032
[Epoch 23, Batch 1000] loss: 0.007930690494727539
[Epoch 23, Batch 1100] loss: 0.023314052872002933
[Epoch 23, Batch 1200] loss: 0.014344694654326523
[Epoch 23, Batch 1300] loss: 0.010380401122963425
[Epoch 23, Batch 1400] loss: 0.010215450749592141
[Epoch 23, Batch 1500] loss: 0.004218597730717702
[Epoch 23, Batch 1600] loss: 0.008588313877823342
[Epoch 23, Batch 1700] loss: 0.0033392772432692475
[Epoch 23, Batch 1800] loss: 0.013312661681242281
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0767
Validation Accuracy: 0.9864
Overfitting: 0.0764
[Epoch 24, Batch 100] loss: 0.0014313291788403282
[Epoch 24, Batch 200] loss: 0.0007746127306720263
[Epoch 24, Batch 300] loss: 0.002739873263868229
[Epoch 24, Batch 400] loss: 0.00040107333551985035
[Epoch 24, Batch 500] loss: 0.0012028115335565692
[Epoch 24, Batch 600] loss: 0.0059239618888452085
[Epoch 24, Batch 700] loss: 0.0024291518836717873
[Epoch 24, Batch 800] loss: 0.009266387107743515
[Epoch 24, Batch 900] loss: 0.0011277665681721195
[Epoch 24, Batch 1000] loss: 0.0008170409223174868
[Epoch 24, Batch 1100] loss: 0.0013607829922477731
[Epoch 24, Batch 1200] loss: 0.007833041223403989
[Epoch 24, Batch 1300] loss: 0.007448143615323231
[Epoch 24, Batch 1400] loss: 0.012728425536089666
[Epoch 24, Batch 1500] loss: 0.007547746126048511
[Epoch 24, Batch 1600] loss: 0.019683423305340418
[Epoch 24, Batch 1700] loss: 0.04040773804611737
[Epoch 24, Batch 1800] loss: 0.017086866091572565
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.1039
Validation Accuracy: 0.9831
Overfitting: 0.1034
Fold 1 validation loss: 0.1039
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.747763982117176
[Epoch 1, Batch 200] loss: 0.49011830374598503
[Epoch 1, Batch 300] loss: 0.269036015002057
[Epoch 1, Batch 400] loss: 0.1968592059612274
[Epoch 1, Batch 500] loss: 0.19962010256480425
[Epoch 1, Batch 600] loss: 0.1698118163086474
[Epoch 1, Batch 700] loss: 0.17602766899159178
[Epoch 1, Batch 800] loss: 0.1505407552747056
[Epoch 1, Batch 900] loss: 0.15305633027805016
[Epoch 1, Batch 1000] loss: 0.12665466462494807
[Epoch 1, Batch 1100] loss: 0.1308344956120709
[Epoch 1, Batch 1200] loss: 0.10431228860339616
[Epoch 1, Batch 1300] loss: 0.1275687593460316
[Epoch 1, Batch 1400] loss: 0.10172142978582997
[Epoch 1, Batch 1500] loss: 0.1110600828169845
[Epoch 1, Batch 1600] loss: 0.13668506515736226
[Epoch 1, Batch 1700] loss: 0.13264536123140716
[Epoch 1, Batch 1800] loss: 0.08285265155100205
**STATS for Epoch 1** : 
Average training loss: 0.0048
Average validation loss: 0.1175
Validation Accuracy: 0.9645
Overfitting: 0.1127
Best model saved at epoch 1 with validation loss: 0.1175
[Epoch 2, Batch 100] loss: 0.08780792675184784
[Epoch 2, Batch 200] loss: 0.07765761780145113
[Epoch 2, Batch 300] loss: 0.06387301963928621
[Epoch 2, Batch 400] loss: 0.14734755722107365
[Epoch 2, Batch 500] loss: 0.08647126523283077
[Epoch 2, Batch 600] loss: 0.06664001379605906
[Epoch 2, Batch 700] loss: 0.06988550841400866
[Epoch 2, Batch 800] loss: 0.054218114029063146
[Epoch 2, Batch 900] loss: 0.10272902921889909
[Epoch 2, Batch 1000] loss: 0.09093021442313329
[Epoch 2, Batch 1100] loss: 0.08319840062787989
[Epoch 2, Batch 1200] loss: 0.0715479998003866
[Epoch 2, Batch 1300] loss: 0.08272565871811821
[Epoch 2, Batch 1400] loss: 0.05759314698210801
[Epoch 2, Batch 1500] loss: 0.07170504899768275
[Epoch 2, Batch 1600] loss: 0.06751811502879718
[Epoch 2, Batch 1700] loss: 0.07061967710542376
[Epoch 2, Batch 1800] loss: 0.07388132928157574
**STATS for Epoch 2** : 
Average training loss: 0.0019
Average validation loss: 0.0687
Validation Accuracy: 0.9801
Overfitting: 0.0668
Best model saved at epoch 2 with validation loss: 0.0687
[Epoch 3, Batch 100] loss: 0.06918770694595879
[Epoch 3, Batch 200] loss: 0.0635377678880468
[Epoch 3, Batch 300] loss: 0.056922216900566126
[Epoch 3, Batch 400] loss: 0.056997206364758315
[Epoch 3, Batch 500] loss: 0.06336918147804681
[Epoch 3, Batch 600] loss: 0.05769028726466786
[Epoch 3, Batch 700] loss: 0.06879632162657799
[Epoch 3, Batch 800] loss: 0.06979927177613718
[Epoch 3, Batch 900] loss: 0.03454104296812147
[Epoch 3, Batch 1000] loss: 0.03966763654903843
[Epoch 3, Batch 1100] loss: 0.07233834237995325
[Epoch 3, Batch 1200] loss: 0.03692926865289337
[Epoch 3, Batch 1300] loss: 0.056714196106513556
[Epoch 3, Batch 1400] loss: 0.05478495498424309
[Epoch 3, Batch 1500] loss: 0.04493966518492016
[Epoch 3, Batch 1600] loss: 0.06648957454264746
[Epoch 3, Batch 1700] loss: 0.04139166310713335
[Epoch 3, Batch 1800] loss: 0.07712400085147238
**STATS for Epoch 3** : 
Average training loss: 0.0016
Average validation loss: 0.0566
Validation Accuracy: 0.9840
Overfitting: 0.0550
Best model saved at epoch 3 with validation loss: 0.0566
[Epoch 4, Batch 100] loss: 0.023651835936834686
[Epoch 4, Batch 200] loss: 0.04564685831056977
[Epoch 4, Batch 300] loss: 0.044794210656218636
[Epoch 4, Batch 400] loss: 0.044681638892907355
[Epoch 4, Batch 500] loss: 0.07240130874431998
[Epoch 4, Batch 600] loss: 0.03642806506635679
[Epoch 4, Batch 700] loss: 0.0321473795757629
[Epoch 4, Batch 800] loss: 0.037517812043406595
[Epoch 4, Batch 900] loss: 0.04043603235913906
[Epoch 4, Batch 1000] loss: 0.0396517674029019
[Epoch 4, Batch 1100] loss: 0.05495009549413225
[Epoch 4, Batch 1200] loss: 0.047866294171763
[Epoch 4, Batch 1300] loss: 0.03871243904093717
[Epoch 4, Batch 1400] loss: 0.051365241660337235
[Epoch 4, Batch 1500] loss: 0.05054048415225225
[Epoch 4, Batch 1600] loss: 0.03724744242387715
[Epoch 4, Batch 1700] loss: 0.04613186446276814
[Epoch 4, Batch 1800] loss: 0.042265765985648615
**STATS for Epoch 4** : 
Average training loss: 0.0019
Average validation loss: 0.0561
Validation Accuracy: 0.9844
Overfitting: 0.0542
Best model saved at epoch 4 with validation loss: 0.0561
[Epoch 5, Batch 100] loss: 0.02483336085493647
[Epoch 5, Batch 200] loss: 0.03563752902624401
[Epoch 5, Batch 300] loss: 0.02474438229030966
[Epoch 5, Batch 400] loss: 0.02114685008737979
[Epoch 5, Batch 500] loss: 0.016250714344773768
[Epoch 5, Batch 600] loss: 0.036664074018704015
[Epoch 5, Batch 700] loss: 0.041346349237351206
[Epoch 5, Batch 800] loss: 0.045270831229836404
[Epoch 5, Batch 900] loss: 0.07578221826512163
[Epoch 5, Batch 1000] loss: 0.043921983545460536
[Epoch 5, Batch 1100] loss: 0.02942713126520175
[Epoch 5, Batch 1200] loss: 0.03443772163503127
[Epoch 5, Batch 1300] loss: 0.036066764842776135
[Epoch 5, Batch 1400] loss: 0.03336861016654438
[Epoch 5, Batch 1500] loss: 0.04941999604315697
[Epoch 5, Batch 1600] loss: 0.02872993257679809
[Epoch 5, Batch 1700] loss: 0.04024237348587121
[Epoch 5, Batch 1800] loss: 0.042112932520885805
**STATS for Epoch 5** : 
Average training loss: 0.0024
Average validation loss: 0.0587
Validation Accuracy: 0.9843
Overfitting: 0.0562
[Epoch 6, Batch 100] loss: 0.03349653379733354
[Epoch 6, Batch 200] loss: 0.019903157580620244
[Epoch 6, Batch 300] loss: 0.026582419051110265
[Epoch 6, Batch 400] loss: 0.03199769251477392
[Epoch 6, Batch 500] loss: 0.021778915226009304
[Epoch 6, Batch 600] loss: 0.008915098676473008
[Epoch 6, Batch 700] loss: 0.02910271496277005
[Epoch 6, Batch 800] loss: 0.018452431260946013
[Epoch 6, Batch 900] loss: 0.02876334784466053
[Epoch 6, Batch 1000] loss: 0.0439470588618542
[Epoch 6, Batch 1100] loss: 0.034326654292472086
[Epoch 6, Batch 1200] loss: 0.04287605784245898
[Epoch 6, Batch 1300] loss: 0.04676096579089517
[Epoch 6, Batch 1400] loss: 0.039481089433811574
[Epoch 6, Batch 1500] loss: 0.023065321743747518
[Epoch 6, Batch 1600] loss: 0.048376231072622886
[Epoch 6, Batch 1700] loss: 0.04024129107578574
[Epoch 6, Batch 1800] loss: 0.04539389878547809
**STATS for Epoch 6** : 
Average training loss: 0.0010
Average validation loss: 0.0617
Validation Accuracy: 0.9833
Overfitting: 0.0606
[Epoch 7, Batch 100] loss: 0.013141271589192911
[Epoch 7, Batch 200] loss: 0.00593539799355483
[Epoch 7, Batch 300] loss: 0.041725478613068676
[Epoch 7, Batch 400] loss: 0.02107999296528028
[Epoch 7, Batch 500] loss: 0.03007693430452946
[Epoch 7, Batch 600] loss: 0.02872591368995927
[Epoch 7, Batch 700] loss: 0.0260447398334054
[Epoch 7, Batch 800] loss: 0.01253138226484225
[Epoch 7, Batch 900] loss: 0.04656045499510583
[Epoch 7, Batch 1000] loss: 0.03873831827742833
[Epoch 7, Batch 1100] loss: 0.026101748768251127
[Epoch 7, Batch 1200] loss: 0.014618225426045229
[Epoch 7, Batch 1300] loss: 0.049500044257797526
[Epoch 7, Batch 1400] loss: 0.018191737829051816
[Epoch 7, Batch 1500] loss: 0.02640857468911918
[Epoch 7, Batch 1600] loss: 0.027276117840556252
[Epoch 7, Batch 1700] loss: 0.03766818087352022
[Epoch 7, Batch 1800] loss: 0.05109855484555283
**STATS for Epoch 7** : 
Average training loss: 0.0010
Average validation loss: 0.0611
Validation Accuracy: 0.9844
Overfitting: 0.0601
[Epoch 8, Batch 100] loss: 0.007889474994599369
[Epoch 8, Batch 200] loss: 0.009545272264704181
[Epoch 8, Batch 300] loss: 0.02108062617241103
[Epoch 8, Batch 400] loss: 0.014848920455202119
[Epoch 8, Batch 500] loss: 0.02075636605458726
[Epoch 8, Batch 600] loss: 0.019717980188277126
[Epoch 8, Batch 700] loss: 0.020598110014027497
[Epoch 8, Batch 800] loss: 0.022909939481629636
[Epoch 8, Batch 900] loss: 0.030237127790666705
[Epoch 8, Batch 1000] loss: 0.02268305829790961
[Epoch 8, Batch 1100] loss: 0.019950246180460453
[Epoch 8, Batch 1200] loss: 0.023035616471333925
[Epoch 8, Batch 1300] loss: 0.020288260792388543
[Epoch 8, Batch 1400] loss: 0.045259009018107005
[Epoch 8, Batch 1500] loss: 0.031747141880755406
[Epoch 8, Batch 1600] loss: 0.020620462623642196
[Epoch 8, Batch 1700] loss: 0.017822454320485123
[Epoch 8, Batch 1800] loss: 0.02573860004858375
**STATS for Epoch 8** : 
Average training loss: 0.0008
Average validation loss: 0.0618
Validation Accuracy: 0.9845
Overfitting: 0.0610
[Epoch 9, Batch 100] loss: 0.009518763451320779
[Epoch 9, Batch 200] loss: 0.02906096492777891
[Epoch 9, Batch 300] loss: 0.01736855364092662
[Epoch 9, Batch 400] loss: 0.022354978528695568
[Epoch 9, Batch 500] loss: 0.028472558853309238
[Epoch 9, Batch 600] loss: 0.018359095239266026
[Epoch 9, Batch 700] loss: 0.019484324601951358
[Epoch 9, Batch 800] loss: 0.02027525528948047
[Epoch 9, Batch 900] loss: 0.01450984369689877
[Epoch 9, Batch 1000] loss: 0.03479767638188548
[Epoch 9, Batch 1100] loss: 0.017525133729477033
[Epoch 9, Batch 1200] loss: 0.020597443885387746
[Epoch 9, Batch 1300] loss: 0.015116880023665544
[Epoch 9, Batch 1400] loss: 0.026427237937087966
[Epoch 9, Batch 1500] loss: 0.01687243416228739
[Epoch 9, Batch 1600] loss: 0.023947714232044604
[Epoch 9, Batch 1700] loss: 0.01911466123076991
[Epoch 9, Batch 1800] loss: 0.021384562297998854
**STATS for Epoch 9** : 
Average training loss: 0.0009
Average validation loss: 0.0613
Validation Accuracy: 0.9849
Overfitting: 0.0604
[Epoch 10, Batch 100] loss: 0.012771366109847122
[Epoch 10, Batch 200] loss: 0.019940250680237737
[Epoch 10, Batch 300] loss: 0.01684240433336129
[Epoch 10, Batch 400] loss: 0.022349977558425563
[Epoch 10, Batch 500] loss: 0.016904283246497863
[Epoch 10, Batch 600] loss: 0.012978928110572668
[Epoch 10, Batch 700] loss: 0.02413000848906222
[Epoch 10, Batch 800] loss: 0.014072155904853058
[Epoch 10, Batch 900] loss: 0.021043727294218967
[Epoch 10, Batch 1000] loss: 0.048067900795608694
[Epoch 10, Batch 1100] loss: 0.03254455985724576
[Epoch 10, Batch 1200] loss: 0.013065330059355632
[Epoch 10, Batch 1300] loss: 0.026516253029268883
[Epoch 10, Batch 1400] loss: 0.02710342291793495
[Epoch 10, Batch 1500] loss: 0.017416094685666083
[Epoch 10, Batch 1600] loss: 0.02336166480543568
[Epoch 10, Batch 1700] loss: 0.020617228505957427
[Epoch 10, Batch 1800] loss: 0.036479459291892696
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0678
Validation Accuracy: 0.9842
Overfitting: 0.0666
[Epoch 11, Batch 100] loss: 0.022885072910098288
[Epoch 11, Batch 200] loss: 0.01564923461977017
[Epoch 11, Batch 300] loss: 0.019393314459911153
[Epoch 11, Batch 400] loss: 0.01684608805637822
[Epoch 11, Batch 500] loss: 0.022679243576423005
[Epoch 11, Batch 600] loss: 0.01826635483663267
[Epoch 11, Batch 700] loss: 0.013653302618701844
[Epoch 11, Batch 800] loss: 0.024233709443286865
[Epoch 11, Batch 900] loss: 0.022091048374807788
[Epoch 11, Batch 1000] loss: 0.01832016970165796
[Epoch 11, Batch 1100] loss: 0.018926501021610136
[Epoch 11, Batch 1200] loss: 0.03362777204187808
[Epoch 11, Batch 1300] loss: 0.016254084439834136
[Epoch 11, Batch 1400] loss: 0.019989918191702996
[Epoch 11, Batch 1500] loss: 0.020849272177247257
[Epoch 11, Batch 1600] loss: 0.020402171267814993
[Epoch 11, Batch 1700] loss: 0.013964516696361357
[Epoch 11, Batch 1800] loss: 0.00853962491484907
**STATS for Epoch 11** : 
Average training loss: 0.0007
Average validation loss: 0.0735
Validation Accuracy: 0.9839
Overfitting: 0.0728
[Epoch 12, Batch 100] loss: 0.010356244626941003
[Epoch 12, Batch 200] loss: 0.004836299608001262
[Epoch 12, Batch 300] loss: 0.01233416771933193
[Epoch 12, Batch 400] loss: 0.015798572665408912
[Epoch 12, Batch 500] loss: 0.002988488136300571
[Epoch 12, Batch 600] loss: 0.03491219332384063
[Epoch 12, Batch 700] loss: 0.030819420226105194
[Epoch 12, Batch 800] loss: 0.010169964869772912
[Epoch 12, Batch 900] loss: 0.023392771676851113
[Epoch 12, Batch 1000] loss: 0.013276015863293545
[Epoch 12, Batch 1100] loss: 0.01135882553368063
[Epoch 12, Batch 1200] loss: 0.011735803421135671
[Epoch 12, Batch 1300] loss: 0.0314222139768799
[Epoch 12, Batch 1400] loss: 0.011045493553008896
[Epoch 12, Batch 1500] loss: 0.019037318137516614
[Epoch 12, Batch 1600] loss: 0.0308224555287876
[Epoch 12, Batch 1700] loss: 0.02545303120334552
[Epoch 12, Batch 1800] loss: 0.020417745766740155
**STATS for Epoch 12** : 
Average training loss: 0.0011
Average validation loss: 0.0569
Validation Accuracy: 0.9860
Overfitting: 0.0558
[Epoch 13, Batch 100] loss: 0.010841633725897281
[Epoch 13, Batch 200] loss: 0.006275742676618848
[Epoch 13, Batch 300] loss: 0.01549997264810159
[Epoch 13, Batch 400] loss: 0.022810608101012805
[Epoch 13, Batch 500] loss: 0.006411636741608931
[Epoch 13, Batch 600] loss: 0.003565767285170618
[Epoch 13, Batch 700] loss: 0.009821918259839978
[Epoch 13, Batch 800] loss: 0.008891606865871466
[Epoch 13, Batch 900] loss: 0.022438478464785874
[Epoch 13, Batch 1000] loss: 0.019421614969587324
[Epoch 13, Batch 1100] loss: 0.026236532027722886
[Epoch 13, Batch 1200] loss: 0.01586682461897233
[Epoch 13, Batch 1300] loss: 0.047713663034820684
[Epoch 13, Batch 1400] loss: 0.015311703433330876
[Epoch 13, Batch 1500] loss: 0.0078559964204495
[Epoch 13, Batch 1600] loss: 0.011654129437382324
[Epoch 13, Batch 1700] loss: 0.017262889329043515
[Epoch 13, Batch 1800] loss: 0.010010979743122156
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0858
Validation Accuracy: 0.9820
Overfitting: 0.0850
[Epoch 14, Batch 100] loss: 0.031996052845894525
[Epoch 14, Batch 200] loss: 0.024126080254135474
[Epoch 14, Batch 300] loss: 0.006561962081995887
[Epoch 14, Batch 400] loss: 0.010515179227872692
[Epoch 14, Batch 500] loss: 0.021268226192379548
[Epoch 14, Batch 600] loss: 0.009495189475361059
[Epoch 14, Batch 700] loss: 0.01742330270114845
[Epoch 14, Batch 800] loss: 0.011136202789777202
[Epoch 14, Batch 900] loss: 0.013124534355338096
[Epoch 14, Batch 1000] loss: 0.009389108910196842
[Epoch 14, Batch 1100] loss: 0.005873704887681725
[Epoch 14, Batch 1200] loss: 0.03858144381078645
[Epoch 14, Batch 1300] loss: 0.03904702331708648
[Epoch 14, Batch 1400] loss: 0.0485751605025024
[Epoch 14, Batch 1500] loss: 0.08475061605539225
[Epoch 14, Batch 1600] loss: 0.045000492614567233
[Epoch 14, Batch 1700] loss: 0.024873993554268167
[Epoch 14, Batch 1800] loss: 0.010537558949055122
**STATS for Epoch 14** : 
Average training loss: 0.0018
Average validation loss: 0.0784
Validation Accuracy: 0.9843
Overfitting: 0.0766
[Epoch 15, Batch 100] loss: 0.011357334007669095
[Epoch 15, Batch 200] loss: 0.020818337949095565
[Epoch 15, Batch 300] loss: 0.020824359989001097
[Epoch 15, Batch 400] loss: 0.011589414596154342
[Epoch 15, Batch 500] loss: 0.0036437473615814043
[Epoch 15, Batch 600] loss: 0.0051265349862907785
[Epoch 15, Batch 700] loss: 0.007781823655366846
[Epoch 15, Batch 800] loss: 0.007729524718667875
[Epoch 15, Batch 900] loss: 0.008882582289404292
[Epoch 15, Batch 1000] loss: 0.006375312418115567
[Epoch 15, Batch 1100] loss: 0.019683914137953167
[Epoch 15, Batch 1200] loss: 0.02164121029014563
[Epoch 15, Batch 1300] loss: 0.01637674559414954
[Epoch 15, Batch 1400] loss: 0.020054461564968165
[Epoch 15, Batch 1500] loss: 0.010169336622224492
[Epoch 15, Batch 1600] loss: 0.023870732779703873
[Epoch 15, Batch 1700] loss: 0.011336892125063116
[Epoch 15, Batch 1800] loss: 0.008147880795766725
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0713
Validation Accuracy: 0.9852
Overfitting: 0.0708
[Epoch 16, Batch 100] loss: 0.0026639413848799087
[Epoch 16, Batch 200] loss: 0.004651640919314395
[Epoch 16, Batch 300] loss: 0.0032937493544011433
[Epoch 16, Batch 400] loss: 0.0016816472557121909
[Epoch 16, Batch 500] loss: 0.011907082620268773
[Epoch 16, Batch 600] loss: 0.015703884254953237
[Epoch 16, Batch 700] loss: 0.005977955649058195
[Epoch 16, Batch 800] loss: 0.00418427082016668
[Epoch 16, Batch 900] loss: 0.006483358255940494
[Epoch 16, Batch 1000] loss: 0.007331330146097552
[Epoch 16, Batch 1100] loss: 0.005254236548762852
[Epoch 16, Batch 1200] loss: 0.013268278188709806
[Epoch 16, Batch 1300] loss: 0.005947484181536882
[Epoch 16, Batch 1400] loss: 0.018518929835942322
[Epoch 16, Batch 1500] loss: 0.018814410055096355
[Epoch 16, Batch 1600] loss: 0.015224412857425236
[Epoch 16, Batch 1700] loss: 0.020623161388662794
[Epoch 16, Batch 1800] loss: 0.016491871460330466
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0723
Validation Accuracy: 0.9870
Overfitting: 0.0721
[Epoch 17, Batch 100] loss: 0.01113332382738637
[Epoch 17, Batch 200] loss: 0.003984981926241722
[Epoch 17, Batch 300] loss: 0.010702041137879146
[Epoch 17, Batch 400] loss: 0.01995322426272096
[Epoch 17, Batch 500] loss: 0.013073077833370764
[Epoch 17, Batch 600] loss: 0.028754475852432418
[Epoch 17, Batch 700] loss: 0.022477687951648395
[Epoch 17, Batch 800] loss: 0.04476811059841971
[Epoch 17, Batch 900] loss: 0.042938453102875654
[Epoch 17, Batch 1000] loss: 0.022419026421297606
[Epoch 17, Batch 1100] loss: 0.016853384649066196
[Epoch 17, Batch 1200] loss: 0.0248313006892953
[Epoch 17, Batch 1300] loss: 0.02560635874661045
[Epoch 17, Batch 1400] loss: 0.015175555701838483
[Epoch 17, Batch 1500] loss: 0.00924444726092661
[Epoch 17, Batch 1600] loss: 0.02276344516836488
[Epoch 17, Batch 1700] loss: 0.029242693763419824
[Epoch 17, Batch 1800] loss: 0.017965955572690716
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0720
Validation Accuracy: 0.9855
Overfitting: 0.0713
[Epoch 18, Batch 100] loss: 0.002221030759116358
[Epoch 18, Batch 200] loss: 0.011822988531192449
[Epoch 18, Batch 300] loss: 0.006133888861782371
[Epoch 18, Batch 400] loss: 0.007227364026846082
[Epoch 18, Batch 500] loss: 0.009788003630887365
[Epoch 18, Batch 600] loss: 0.014434760860707883
[Epoch 18, Batch 700] loss: 0.009970322152457528
[Epoch 18, Batch 800] loss: 0.017818223108444827
[Epoch 18, Batch 900] loss: 0.017862356709467876
[Epoch 18, Batch 1000] loss: 0.008087146003737323
[Epoch 18, Batch 1100] loss: 0.016469561583395013
[Epoch 18, Batch 1200] loss: 0.018551181809703755
[Epoch 18, Batch 1300] loss: 0.02294652977118908
[Epoch 18, Batch 1400] loss: 0.016386258334872325
[Epoch 18, Batch 1500] loss: 0.015935063646204953
[Epoch 18, Batch 1600] loss: 0.005348373678138447
[Epoch 18, Batch 1700] loss: 0.0070310769861871595
[Epoch 18, Batch 1800] loss: 0.01550916681475793
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0757
Validation Accuracy: 0.9858
Overfitting: 0.0750
[Epoch 19, Batch 100] loss: 0.023329204744270055
[Epoch 19, Batch 200] loss: 0.010184155178113961
[Epoch 19, Batch 300] loss: 0.007830543194268347
[Epoch 19, Batch 400] loss: 0.009990352887526388
[Epoch 19, Batch 500] loss: 0.021387445840118403
[Epoch 19, Batch 600] loss: 0.007346946963220531
[Epoch 19, Batch 700] loss: 0.009586671073235102
[Epoch 19, Batch 800] loss: 0.008077842095544812
[Epoch 19, Batch 900] loss: 0.0037409134274505006
[Epoch 19, Batch 1000] loss: 0.00398324886270982
[Epoch 19, Batch 1100] loss: 0.00994153805076424
[Epoch 19, Batch 1200] loss: 0.008576907552040089
[Epoch 19, Batch 1300] loss: 0.013084137537231512
[Epoch 19, Batch 1400] loss: 0.01080489472417013
[Epoch 19, Batch 1500] loss: 0.0056994601144438614
[Epoch 19, Batch 1600] loss: 0.01076754298506307
[Epoch 19, Batch 1700] loss: 0.013717162398795066
[Epoch 19, Batch 1800] loss: 0.016689559351642104
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0805
Validation Accuracy: 0.9863
Overfitting: 0.0802
[Epoch 20, Batch 100] loss: 0.007486023208419596
[Epoch 20, Batch 200] loss: 0.0036926968127051697
[Epoch 20, Batch 300] loss: 0.01367256221646148
[Epoch 20, Batch 400] loss: 0.004765221715846506
[Epoch 20, Batch 500] loss: 0.004459031748118658
[Epoch 20, Batch 600] loss: 0.004505766726430824
[Epoch 20, Batch 700] loss: 0.00696591111263917
[Epoch 20, Batch 800] loss: 0.019220775850062023
[Epoch 20, Batch 900] loss: 0.01658733792816682
[Epoch 20, Batch 1000] loss: 0.0361469653693851
[Epoch 20, Batch 1100] loss: 0.024906248208808813
[Epoch 20, Batch 1200] loss: 0.013405255647538361
[Epoch 20, Batch 1300] loss: 0.01066102196790041
[Epoch 20, Batch 1400] loss: 0.004998968956431465
[Epoch 20, Batch 1500] loss: 0.008906954341248854
[Epoch 20, Batch 1600] loss: 0.002076385169096078
[Epoch 20, Batch 1700] loss: 0.010159428039996175
[Epoch 20, Batch 1800] loss: 0.006832446792113087
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0924
Validation Accuracy: 0.9854
Overfitting: 0.0921
[Epoch 21, Batch 100] loss: 0.022204369075090005
[Epoch 21, Batch 200] loss: 0.008177266010643836
[Epoch 21, Batch 300] loss: 0.0021833873016880423
[Epoch 21, Batch 400] loss: 0.002908448554671583
[Epoch 21, Batch 500] loss: 0.0018552983262593826
[Epoch 21, Batch 600] loss: 0.0033731625678628595
[Epoch 21, Batch 700] loss: 0.008482760817847254
[Epoch 21, Batch 800] loss: 0.007452375915863887
[Epoch 21, Batch 900] loss: 0.007715801050202877
[Epoch 21, Batch 1000] loss: 0.013923082367247602
[Epoch 21, Batch 1100] loss: 0.005050205424711031
[Epoch 21, Batch 1200] loss: 0.005044207979229602
[Epoch 21, Batch 1300] loss: 0.001451864169675834
[Epoch 21, Batch 1400] loss: 0.005181060660444472
[Epoch 21, Batch 1500] loss: 0.0009748385750137922
[Epoch 21, Batch 1600] loss: 0.0074602413875532216
[Epoch 21, Batch 1700] loss: 0.0007551602506648569
[Epoch 21, Batch 1800] loss: 0.006544171896635893
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0783
Validation Accuracy: 0.9869
Overfitting: 0.0781
[Epoch 22, Batch 100] loss: 0.011285701464715733
[Epoch 22, Batch 200] loss: 0.012416367904385025
[Epoch 22, Batch 300] loss: 0.0076932754081020785
[Epoch 22, Batch 400] loss: 0.015628184169149274
[Epoch 22, Batch 500] loss: 0.011395341350384683
[Epoch 22, Batch 600] loss: 0.008300686088642149
[Epoch 22, Batch 700] loss: 0.014033822870049235
[Epoch 22, Batch 800] loss: 0.010868490827323964
[Epoch 22, Batch 900] loss: 0.005231824691689164
[Epoch 22, Batch 1000] loss: 0.002464437250610314
[Epoch 22, Batch 1100] loss: 0.0009674425968982092
[Epoch 22, Batch 1200] loss: 0.005480053659727786
[Epoch 22, Batch 1300] loss: 0.005682414884432428
[Epoch 22, Batch 1400] loss: 0.0007027356627677416
[Epoch 22, Batch 1500] loss: 0.0038311212589042976
[Epoch 22, Batch 1600] loss: 0.004007874816058838
[Epoch 22, Batch 1700] loss: 0.023813844505842025
[Epoch 22, Batch 1800] loss: 0.04568496849646216
**STATS for Epoch 22** : 
Average training loss: 0.0009
Average validation loss: 0.0846
Validation Accuracy: 0.9829
Overfitting: 0.0838
[Epoch 23, Batch 100] loss: 0.02770813504614389
[Epoch 23, Batch 200] loss: 0.018521396366616826
[Epoch 23, Batch 300] loss: 0.018493489496192127
[Epoch 23, Batch 400] loss: 0.0024587353213342046
[Epoch 23, Batch 500] loss: 0.01114219773387406
[Epoch 23, Batch 600] loss: 0.004714577797757733
[Epoch 23, Batch 700] loss: 0.0017089390547456729
[Epoch 23, Batch 800] loss: 0.002370273142123631
[Epoch 23, Batch 900] loss: 0.0013111629499733901
[Epoch 23, Batch 1000] loss: 0.0008723360020910054
[Epoch 23, Batch 1100] loss: 0.0023600817240407366
[Epoch 23, Batch 1200] loss: 0.0022558754874684615
[Epoch 23, Batch 1300] loss: 0.006689612928187052
[Epoch 23, Batch 1400] loss: 0.006264462141027649
[Epoch 23, Batch 1500] loss: 0.031678094039481415
[Epoch 23, Batch 1600] loss: 0.017098367408517123
[Epoch 23, Batch 1700] loss: 0.020479531657628346
[Epoch 23, Batch 1800] loss: 0.029390152644049518
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0928
Validation Accuracy: 0.9831
Overfitting: 0.0924
[Epoch 24, Batch 100] loss: 0.004451777522564262
[Epoch 24, Batch 200] loss: 0.0054774811001021325
[Epoch 24, Batch 300] loss: 0.010822767859927737
[Epoch 24, Batch 400] loss: 0.012018153831600254
[Epoch 24, Batch 500] loss: 0.008924598616278732
[Epoch 24, Batch 600] loss: 0.015141015274617824
[Epoch 24, Batch 700] loss: 0.004464778501583088
[Epoch 24, Batch 800] loss: 0.025616609480272737
[Epoch 24, Batch 900] loss: 0.0353743352589819
[Epoch 24, Batch 1000] loss: 0.013345571340414017
[Epoch 24, Batch 1100] loss: 0.013173823844143989
[Epoch 24, Batch 1200] loss: 0.05559384164388625
[Epoch 24, Batch 1300] loss: 0.013418630867541234
[Epoch 24, Batch 1400] loss: 0.015054102671491236
[Epoch 24, Batch 1500] loss: 0.0449785688994476
[Epoch 24, Batch 1600] loss: 0.0732438742279578
[Epoch 24, Batch 1700] loss: 0.03266385112070992
[Epoch 24, Batch 1800] loss: 0.008451353015417738
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0715
Validation Accuracy: 0.9853
Overfitting: 0.0712
Fold 2 validation loss: 0.0715
Mean validation loss across all folds for Trial 18 is 0.0877 with trial config:  l1: 256, l2: 128, lr: 0.009287011926825201, batch_size: 16
[I 2024-11-21 20:27:34,076] Trial 17 finished with value: 0.08770021621184991 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.009287011926825201, 'batch_size': 16}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 19:
  l1: 256, l2: 64, lr: 0.024286525795066936, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.270752519890666
[Epoch 1, Batch 200] loss: 0.22308171121403575
[Epoch 1, Batch 300] loss: 0.13429287385195493
[Epoch 1, Batch 400] loss: 0.1347949080122635
**STATS for Epoch 1** : 
Average training loss: 0.0129
Average validation loss: 0.1060
Validation Accuracy: 0.9670
Overfitting: 0.0931
Best model saved at epoch 1 with validation loss: 0.1060
[Epoch 2, Batch 100] loss: 0.08101319033652545
[Epoch 2, Batch 200] loss: 0.0706938197487034
[Epoch 2, Batch 300] loss: 0.07098173450212926
[Epoch 2, Batch 400] loss: 0.07497013373300433
**STATS for Epoch 2** : 
Average training loss: 0.0094
Average validation loss: 0.0595
Validation Accuracy: 0.9822
Overfitting: 0.0502
Best model saved at epoch 2 with validation loss: 0.0595
[Epoch 3, Batch 100] loss: 0.054090554016875105
[Epoch 3, Batch 200] loss: 0.055129059252794835
[Epoch 3, Batch 300] loss: 0.05825772383366711
[Epoch 3, Batch 400] loss: 0.04344318400486372
**STATS for Epoch 3** : 
Average training loss: 0.0079
Average validation loss: 0.0654
Validation Accuracy: 0.9804
Overfitting: 0.0575
[Epoch 4, Batch 100] loss: 0.03789886561455205
[Epoch 4, Batch 200] loss: 0.03776109909755178
[Epoch 4, Batch 300] loss: 0.042125832948659084
[Epoch 4, Batch 400] loss: 0.04798531576641835
**STATS for Epoch 4** : 
Average training loss: 0.0076
Average validation loss: 0.0666
Validation Accuracy: 0.9806
Overfitting: 0.0590
[Epoch 5, Batch 100] loss: 0.02403479329776019
[Epoch 5, Batch 200] loss: 0.025010000860493164
[Epoch 5, Batch 300] loss: 0.026949620433297242
[Epoch 5, Batch 400] loss: 0.027561186572129373
**STATS for Epoch 5** : 
Average training loss: 0.0063
Average validation loss: 0.0553
Validation Accuracy: 0.9841
Overfitting: 0.0490
Best model saved at epoch 5 with validation loss: 0.0553
[Epoch 6, Batch 100] loss: 0.024171214669477196
[Epoch 6, Batch 200] loss: 0.01885193927504588
[Epoch 6, Batch 300] loss: 0.02209218191506807
[Epoch 6, Batch 400] loss: 0.03315701485407772
**STATS for Epoch 6** : 
Average training loss: 0.0034
Average validation loss: 0.0623
Validation Accuracy: 0.9842
Overfitting: 0.0589
[Epoch 7, Batch 100] loss: 0.015098000047364621
[Epoch 7, Batch 200] loss: 0.01943776453612372
[Epoch 7, Batch 300] loss: 0.02734713151003234
[Epoch 7, Batch 400] loss: 0.030168376115470893
**STATS for Epoch 7** : 
Average training loss: 0.0030
Average validation loss: 0.0620
Validation Accuracy: 0.9849
Overfitting: 0.0589
[Epoch 8, Batch 100] loss: 0.018852902897051535
[Epoch 8, Batch 200] loss: 0.016723712665916535
[Epoch 8, Batch 300] loss: 0.024922012720926433
[Epoch 8, Batch 400] loss: 0.027593033729062882
**STATS for Epoch 8** : 
Average training loss: 0.0028
Average validation loss: 0.0590
Validation Accuracy: 0.9848
Overfitting: 0.0562
[Epoch 9, Batch 100] loss: 0.01296623806720163
[Epoch 9, Batch 200] loss: 0.008272744763162336
[Epoch 9, Batch 300] loss: 0.005567607908524223
[Epoch 9, Batch 400] loss: 0.012791455377409874
**STATS for Epoch 9** : 
Average training loss: 0.0024
Average validation loss: 0.0896
Validation Accuracy: 0.9802
Overfitting: 0.0873
[Epoch 10, Batch 100] loss: 0.012389938837259251
[Epoch 10, Batch 200] loss: 0.02188498210683065
[Epoch 10, Batch 300] loss: 0.0141253438642525
[Epoch 10, Batch 400] loss: 0.015600233271325124
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0584
Validation Accuracy: 0.9856
Overfitting: 0.0568
[Epoch 11, Batch 100] loss: 0.00668473003022882
[Epoch 11, Batch 200] loss: 0.008040282476185894
[Epoch 11, Batch 300] loss: 0.00927738292293725
[Epoch 11, Batch 400] loss: 0.01970137631684338
**STATS for Epoch 11** : 
Average training loss: 0.0052
Average validation loss: 0.0622
Validation Accuracy: 0.9836
Overfitting: 0.0570
[Epoch 12, Batch 100] loss: 0.009478000490707928
[Epoch 12, Batch 200] loss: 0.012422938369891199
[Epoch 12, Batch 300] loss: 0.013412540382023507
[Epoch 12, Batch 400] loss: 0.013970753207513554
**STATS for Epoch 12** : 
Average training loss: 0.0030
Average validation loss: 0.0754
Validation Accuracy: 0.9822
Overfitting: 0.0724
[Epoch 13, Batch 100] loss: 0.01088691400083917
[Epoch 13, Batch 200] loss: 0.017287168474640565
[Epoch 13, Batch 300] loss: 0.014276809129014509
[Epoch 13, Batch 400] loss: 0.012342686682186467
**STATS for Epoch 13** : 
Average training loss: 0.0026
Average validation loss: 0.0802
Validation Accuracy: 0.9834
Overfitting: 0.0776
[Epoch 14, Batch 100] loss: 0.004576145811524839
[Epoch 14, Batch 200] loss: 0.015546414432756138
[Epoch 14, Batch 300] loss: 0.005681966043575812
[Epoch 14, Batch 400] loss: 0.011782732755596043
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0652
Validation Accuracy: 0.9857
Overfitting: 0.0643
[Epoch 15, Batch 100] loss: 0.004237737209050465
[Epoch 15, Batch 200] loss: 0.002024807358957332
[Epoch 15, Batch 300] loss: 0.013866585109358311
[Epoch 15, Batch 400] loss: 0.017421854007243383
**STATS for Epoch 15** : 
Average training loss: 0.0021
Average validation loss: 0.0573
Validation Accuracy: 0.9869
Overfitting: 0.0552
[Epoch 16, Batch 100] loss: 0.003035142992866895
[Epoch 16, Batch 200] loss: 0.010154100590780217
[Epoch 16, Batch 300] loss: 0.0030901671956439715
[Epoch 16, Batch 400] loss: 0.007628931167837436
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0650
Validation Accuracy: 0.9872
Overfitting: 0.0645
[Epoch 17, Batch 100] loss: 0.005843935907514606
[Epoch 17, Batch 200] loss: 0.008770946727986484
[Epoch 17, Batch 300] loss: 0.005207233367095796
[Epoch 17, Batch 400] loss: 0.005489223810876638
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0867
Validation Accuracy: 0.9848
Overfitting: 0.0859
[Epoch 18, Batch 100] loss: 0.008943932403927306
[Epoch 18, Batch 200] loss: 0.005402698642876657
[Epoch 18, Batch 300] loss: 0.009768373588955229
[Epoch 18, Batch 400] loss: 0.006346245474449006
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0645
Validation Accuracy: 0.9864
Overfitting: 0.0641
[Epoch 19, Batch 100] loss: 0.004699814624468672
[Epoch 19, Batch 200] loss: 0.002456594591615158
[Epoch 19, Batch 300] loss: 0.0025235320512445015
[Epoch 19, Batch 400] loss: 0.00530659432626976
**STATS for Epoch 19** : 
Average training loss: 0.0049
Average validation loss: 0.1137
Validation Accuracy: 0.9796
Overfitting: 0.1088
[Epoch 20, Batch 100] loss: 0.019754053075212143
[Epoch 20, Batch 200] loss: 0.006659750382868879
[Epoch 20, Batch 300] loss: 0.009348192134903002
[Epoch 20, Batch 400] loss: 0.007673901650988455
**STATS for Epoch 20** : 
Average training loss: 0.0007
Average validation loss: 0.0639
Validation Accuracy: 0.9868
Overfitting: 0.0632
[Epoch 21, Batch 100] loss: 0.0018624225417897833
[Epoch 21, Batch 200] loss: 0.005643499285493476
[Epoch 21, Batch 300] loss: 0.001587217502437852
[Epoch 21, Batch 400] loss: 0.004206816129477602
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0635
Validation Accuracy: 0.9877
Overfitting: 0.0634
[Epoch 22, Batch 100] loss: 0.0009135661136934913
[Epoch 22, Batch 200] loss: 0.0006839646265467536
[Epoch 22, Batch 300] loss: 0.0013765408648953325
[Epoch 22, Batch 400] loss: 0.0008719762694499877
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0675
Validation Accuracy: 0.9885
Overfitting: 0.0674
[Epoch 23, Batch 100] loss: 0.0005273666590964865
[Epoch 23, Batch 200] loss: 0.0002889249095278501
[Epoch 23, Batch 300] loss: 0.0003429357096661079
[Epoch 23, Batch 400] loss: 0.00011866443998599152
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0679
Validation Accuracy: 0.9887
Overfitting: 0.0679
[Epoch 24, Batch 100] loss: 5.7132777156319036e-05
[Epoch 24, Batch 200] loss: 0.00027903029158196093
[Epoch 24, Batch 300] loss: 7.319839815949081e-05
[Epoch 24, Batch 400] loss: 6.770205899982785e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0687
Validation Accuracy: 0.9889
Overfitting: 0.0687
Fold 1 validation loss: 0.0687
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.016730595678091
[Epoch 1, Batch 200] loss: 0.20971180517226456
[Epoch 1, Batch 300] loss: 0.14674467276781797
[Epoch 1, Batch 400] loss: 0.12382877535186708
**STATS for Epoch 1** : 
Average training loss: 0.0161
Average validation loss: 0.1032
Validation Accuracy: 0.9685
Overfitting: 0.0870
Best model saved at epoch 1 with validation loss: 0.1032
[Epoch 2, Batch 100] loss: 0.08445517899468541
[Epoch 2, Batch 200] loss: 0.0775182941649109
[Epoch 2, Batch 300] loss: 0.07292211298365146
[Epoch 2, Batch 400] loss: 0.06805620467755943
**STATS for Epoch 2** : 
Average training loss: 0.0113
Average validation loss: 0.0825
Validation Accuracy: 0.9751
Overfitting: 0.0711
Best model saved at epoch 2 with validation loss: 0.0825
[Epoch 3, Batch 100] loss: 0.059857831600820643
[Epoch 3, Batch 200] loss: 0.04989946654299274
[Epoch 3, Batch 300] loss: 0.04784859081381001
[Epoch 3, Batch 400] loss: 0.05778365866513923
**STATS for Epoch 3** : 
Average training loss: 0.0086
Average validation loss: 0.0666
Validation Accuracy: 0.9799
Overfitting: 0.0580
Best model saved at epoch 3 with validation loss: 0.0666
[Epoch 4, Batch 100] loss: 0.044263494999613615
[Epoch 4, Batch 200] loss: 0.03627314632118214
[Epoch 4, Batch 300] loss: 0.04216210960992612
[Epoch 4, Batch 400] loss: 0.03270546698622638
**STATS for Epoch 4** : 
Average training loss: 0.0055
Average validation loss: 0.0700
Validation Accuracy: 0.9813
Overfitting: 0.0645
[Epoch 5, Batch 100] loss: 0.03353280854702462
[Epoch 5, Batch 200] loss: 0.03814279385609552
[Epoch 5, Batch 300] loss: 0.037685376192384865
[Epoch 5, Batch 400] loss: 0.03794160055636894
**STATS for Epoch 5** : 
Average training loss: 0.0067
Average validation loss: 0.0899
Validation Accuracy: 0.9751
Overfitting: 0.0832
[Epoch 6, Batch 100] loss: 0.028322068315173966
[Epoch 6, Batch 200] loss: 0.021833628884050996
[Epoch 6, Batch 300] loss: 0.029334194574039428
[Epoch 6, Batch 400] loss: 0.03594519235892221
**STATS for Epoch 6** : 
Average training loss: 0.0063
Average validation loss: 0.0489
Validation Accuracy: 0.9858
Overfitting: 0.0426
Best model saved at epoch 6 with validation loss: 0.0489
[Epoch 7, Batch 100] loss: 0.018053492581093452
[Epoch 7, Batch 200] loss: 0.032207210106716955
[Epoch 7, Batch 300] loss: 0.03021643697284162
[Epoch 7, Batch 400] loss: 0.02244792447265354
**STATS for Epoch 7** : 
Average training loss: 0.0027
Average validation loss: 0.0557
Validation Accuracy: 0.9857
Overfitting: 0.0530
[Epoch 8, Batch 100] loss: 0.015166518912956235
[Epoch 8, Batch 200] loss: 0.01652851900396854
[Epoch 8, Batch 300] loss: 0.02338170445716969
[Epoch 8, Batch 400] loss: 0.01635004228068283
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0614
Validation Accuracy: 0.9849
Overfitting: 0.0594
[Epoch 9, Batch 100] loss: 0.010059133114082216
[Epoch 9, Batch 200] loss: 0.012167319499385485
[Epoch 9, Batch 300] loss: 0.025889714480945257
[Epoch 9, Batch 400] loss: 0.020295362243850833
**STATS for Epoch 9** : 
Average training loss: 0.0024
Average validation loss: 0.0542
Validation Accuracy: 0.9868
Overfitting: 0.0518
[Epoch 10, Batch 100] loss: 0.012632691115541092
[Epoch 10, Batch 200] loss: 0.016077001483863568
[Epoch 10, Batch 300] loss: 0.015554748995255068
[Epoch 10, Batch 400] loss: 0.013500382577876734
**STATS for Epoch 10** : 
Average training loss: 0.0026
Average validation loss: 0.0575
Validation Accuracy: 0.9866
Overfitting: 0.0550
[Epoch 11, Batch 100] loss: 0.011087786160205724
[Epoch 11, Batch 200] loss: 0.01065124966960866
[Epoch 11, Batch 300] loss: 0.016570918958705078
[Epoch 11, Batch 400] loss: 0.016167535249296636
**STATS for Epoch 11** : 
Average training loss: 0.0029
Average validation loss: 0.0558
Validation Accuracy: 0.9862
Overfitting: 0.0529
[Epoch 12, Batch 100] loss: 0.007179081764625153
[Epoch 12, Batch 200] loss: 0.009625288297238513
[Epoch 12, Batch 300] loss: 0.009701102470517071
[Epoch 12, Batch 400] loss: 0.014179799235935207
**STATS for Epoch 12** : 
Average training loss: 0.0023
Average validation loss: 0.0597
Validation Accuracy: 0.9867
Overfitting: 0.0575
[Epoch 13, Batch 100] loss: 0.0039009427759310713
[Epoch 13, Batch 200] loss: 0.005269205520073683
[Epoch 13, Batch 300] loss: 0.015221814445358178
[Epoch 13, Batch 400] loss: 0.015424817583698314
**STATS for Epoch 13** : 
Average training loss: 0.0028
Average validation loss: 0.0728
Validation Accuracy: 0.9837
Overfitting: 0.0700
[Epoch 14, Batch 100] loss: 0.016578014661390625
[Epoch 14, Batch 200] loss: 0.008825078986174049
[Epoch 14, Batch 300] loss: 0.012466016639009467
[Epoch 14, Batch 400] loss: 0.01500937697754125
**STATS for Epoch 14** : 
Average training loss: 0.0024
Average validation loss: 0.0671
Validation Accuracy: 0.9845
Overfitting: 0.0647
[Epoch 15, Batch 100] loss: 0.014546908998418075
[Epoch 15, Batch 200] loss: 0.01325432584668306
[Epoch 15, Batch 300] loss: 0.011555148024508527
[Epoch 15, Batch 400] loss: 0.01067666995604668
**STATS for Epoch 15** : 
Average training loss: 0.0030
Average validation loss: 0.0674
Validation Accuracy: 0.9860
Overfitting: 0.0644
[Epoch 16, Batch 100] loss: 0.012010001802782427
[Epoch 16, Batch 200] loss: 0.0036718070661208913
[Epoch 16, Batch 300] loss: 0.011265496785972573
[Epoch 16, Batch 400] loss: 0.007181591777480207
**STATS for Epoch 16** : 
Average training loss: 0.0015
Average validation loss: 0.0702
Validation Accuracy: 0.9863
Overfitting: 0.0687
[Epoch 17, Batch 100] loss: 0.007191491875064457
[Epoch 17, Batch 200] loss: 0.012737217420153683
[Epoch 17, Batch 300] loss: 0.014910602662403107
[Epoch 17, Batch 400] loss: 0.010480882981191826
**STATS for Epoch 17** : 
Average training loss: 0.0014
Average validation loss: 0.0602
Validation Accuracy: 0.9867
Overfitting: 0.0587
[Epoch 18, Batch 100] loss: 0.004583486651690691
[Epoch 18, Batch 200] loss: 0.009823689148142876
[Epoch 18, Batch 300] loss: 0.004765489201573132
[Epoch 18, Batch 400] loss: 0.005492323672644375
**STATS for Epoch 18** : 
Average training loss: 0.0015
Average validation loss: 0.0696
Validation Accuracy: 0.9859
Overfitting: 0.0681
[Epoch 19, Batch 100] loss: 0.008631829875058656
[Epoch 19, Batch 200] loss: 0.011099491155273427
[Epoch 19, Batch 300] loss: 0.01700477273353272
[Epoch 19, Batch 400] loss: 0.020105589576251078
**STATS for Epoch 19** : 
Average training loss: 0.0022
Average validation loss: 0.0595
Validation Accuracy: 0.9874
Overfitting: 0.0572
[Epoch 20, Batch 100] loss: 0.0053755561420848605
[Epoch 20, Batch 200] loss: 0.007980986884635968
[Epoch 20, Batch 300] loss: 0.002535846698563091
[Epoch 20, Batch 400] loss: 0.004276757114439533
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0696
Validation Accuracy: 0.9869
Overfitting: 0.0690
[Epoch 21, Batch 100] loss: 0.0014406296843424116
[Epoch 21, Batch 200] loss: 0.003265985920975254
[Epoch 21, Batch 300] loss: 0.0015578973095159653
[Epoch 21, Batch 400] loss: 0.0011532654330017066
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0614
Validation Accuracy: 0.9885
Overfitting: 0.0610
[Epoch 22, Batch 100] loss: 0.0023923819802149637
[Epoch 22, Batch 200] loss: 0.0009952592952912197
[Epoch 22, Batch 300] loss: 0.0005956327483484359
[Epoch 22, Batch 400] loss: 0.0003746227363623689
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0680
Validation Accuracy: 0.9877
Overfitting: 0.0679
[Epoch 23, Batch 100] loss: 0.002778921852661611
[Epoch 23, Batch 200] loss: 0.000564316689416593
[Epoch 23, Batch 300] loss: 0.00030483406138642977
[Epoch 23, Batch 400] loss: 0.00015606088395115237
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0661
Validation Accuracy: 0.9888
Overfitting: 0.0660
[Epoch 24, Batch 100] loss: 7.100737928858792e-05
[Epoch 24, Batch 200] loss: 0.0006522842363115089
[Epoch 24, Batch 300] loss: 0.00015873085837910138
[Epoch 24, Batch 400] loss: 8.99525540155821e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0670
Validation Accuracy: 0.9889
Overfitting: 0.0670
Fold 2 validation loss: 0.0670
Mean validation loss across all folds for Trial 19 is 0.0678 with trial config:  l1: 256, l2: 64, lr: 0.024286525795066936, batch_size: 64
[I 2024-11-21 20:36:23,482] Trial 18 finished with value: 0.06784917629246698 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.024286525795066936, 'batch_size': 64}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 20:
  l1: 256, l2: 64, lr: 0.0006552521072923581, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3043930292129517
[Epoch 1, Batch 200] loss: 2.2904391789436342
[Epoch 1, Batch 300] loss: 2.2694536447525024
[Epoch 1, Batch 400] loss: 2.2270029854774473
[Epoch 1, Batch 500] loss: 2.093165044784546
[Epoch 1, Batch 600] loss: 1.5869887113571166
[Epoch 1, Batch 700] loss: 0.8488871261477471
[Epoch 1, Batch 800] loss: 0.5982027667760849
[Epoch 1, Batch 900] loss: 0.485201748162508
**STATS for Epoch 1** : 
Average training loss: 0.0192
Average validation loss: 0.4298
Validation Accuracy: 0.8710
Overfitting: 0.4106
Best model saved at epoch 1 with validation loss: 0.4298
[Epoch 2, Batch 100] loss: 0.42551748231053355
[Epoch 2, Batch 200] loss: 0.38230832785367963
[Epoch 2, Batch 300] loss: 0.35566469982266424
[Epoch 2, Batch 400] loss: 0.3194279630482197
[Epoch 2, Batch 500] loss: 0.3091002883017063
[Epoch 2, Batch 600] loss: 0.27691536728292704
[Epoch 2, Batch 700] loss: 0.27956174142658713
[Epoch 2, Batch 800] loss: 0.26611215315759185
[Epoch 2, Batch 900] loss: 0.25260936535894873
**STATS for Epoch 2** : 
Average training loss: 0.0093
Average validation loss: 0.2328
Validation Accuracy: 0.9296
Overfitting: 0.2235
Best model saved at epoch 2 with validation loss: 0.2328
[Epoch 3, Batch 100] loss: 0.20628121435642244
[Epoch 3, Batch 200] loss: 0.2233790479786694
[Epoch 3, Batch 300] loss: 0.2094070648960769
[Epoch 3, Batch 400] loss: 0.18605188071727752
[Epoch 3, Batch 500] loss: 0.18462649362161757
[Epoch 3, Batch 600] loss: 0.17691190995275974
[Epoch 3, Batch 700] loss: 0.16895739002153276
[Epoch 3, Batch 800] loss: 0.1715589851140976
[Epoch 3, Batch 900] loss: 0.16686058636754753
**STATS for Epoch 3** : 
Average training loss: 0.0064
Average validation loss: 0.2051
Validation Accuracy: 0.9363
Overfitting: 0.1988
Best model saved at epoch 3 with validation loss: 0.2051
[Epoch 4, Batch 100] loss: 0.14693095363676548
[Epoch 4, Batch 200] loss: 0.16119724225252866
[Epoch 4, Batch 300] loss: 0.14719729777425528
[Epoch 4, Batch 400] loss: 0.13089111655950547
[Epoch 4, Batch 500] loss: 0.1269283042382449
[Epoch 4, Batch 600] loss: 0.12071786741726101
[Epoch 4, Batch 700] loss: 0.13392918453551828
[Epoch 4, Batch 800] loss: 0.1150332578830421
[Epoch 4, Batch 900] loss: 0.15747657203115523
**STATS for Epoch 4** : 
Average training loss: 0.0048
Average validation loss: 0.1293
Validation Accuracy: 0.9594
Overfitting: 0.1244
Best model saved at epoch 4 with validation loss: 0.1293
[Epoch 5, Batch 100] loss: 0.11213393967133016
[Epoch 5, Batch 200] loss: 0.1060126551054418
[Epoch 5, Batch 300] loss: 0.11745589062571525
[Epoch 5, Batch 400] loss: 0.11723328557796776
[Epoch 5, Batch 500] loss: 0.1028898138832301
[Epoch 5, Batch 600] loss: 0.11138446987606584
[Epoch 5, Batch 700] loss: 0.10158124077133834
[Epoch 5, Batch 800] loss: 0.10431226703338325
[Epoch 5, Batch 900] loss: 0.1154811303759925
**STATS for Epoch 5** : 
Average training loss: 0.0053
Average validation loss: 0.1216
Validation Accuracy: 0.9614
Overfitting: 0.1162
Best model saved at epoch 5 with validation loss: 0.1216
[Epoch 6, Batch 100] loss: 0.10802922236733138
[Epoch 6, Batch 200] loss: 0.09928271014709025
[Epoch 6, Batch 300] loss: 0.08395545663777738
[Epoch 6, Batch 400] loss: 0.10208339374512435
[Epoch 6, Batch 500] loss: 0.08784277509897948
[Epoch 6, Batch 600] loss: 0.0835571018839255
[Epoch 6, Batch 700] loss: 0.09883579529821873
[Epoch 6, Batch 800] loss: 0.08094273173250258
[Epoch 6, Batch 900] loss: 0.09717313721310347
**STATS for Epoch 6** : 
Average training loss: 0.0044
Average validation loss: 0.1028
Validation Accuracy: 0.9673
Overfitting: 0.0984
Best model saved at epoch 6 with validation loss: 0.1028
[Epoch 7, Batch 100] loss: 0.09581526780501008
[Epoch 7, Batch 200] loss: 0.09175620852038265
[Epoch 7, Batch 300] loss: 0.07536217534681783
[Epoch 7, Batch 400] loss: 0.07836010784376413
[Epoch 7, Batch 500] loss: 0.07761778532061726
[Epoch 7, Batch 600] loss: 0.0869644972961396
[Epoch 7, Batch 700] loss: 0.08409387385006994
[Epoch 7, Batch 800] loss: 0.07576116364449263
[Epoch 7, Batch 900] loss: 0.07889354936778545
**STATS for Epoch 7** : 
Average training loss: 0.0034
Average validation loss: 0.0928
Validation Accuracy: 0.9710
Overfitting: 0.0894
Best model saved at epoch 7 with validation loss: 0.0928
[Epoch 8, Batch 100] loss: 0.08237568811047823
[Epoch 8, Batch 200] loss: 0.07889953593257815
[Epoch 8, Batch 300] loss: 0.06817075088154524
[Epoch 8, Batch 400] loss: 0.0704048068728298
[Epoch 8, Batch 500] loss: 0.07488855758681894
[Epoch 8, Batch 600] loss: 0.0703205115790479
[Epoch 8, Batch 700] loss: 0.06873502011410892
[Epoch 8, Batch 800] loss: 0.06936554403509945
[Epoch 8, Batch 900] loss: 0.06699842352885753
**STATS for Epoch 8** : 
Average training loss: 0.0025
Average validation loss: 0.0851
Validation Accuracy: 0.9735
Overfitting: 0.0826
Best model saved at epoch 8 with validation loss: 0.0851
[Epoch 9, Batch 100] loss: 0.06858756236732005
[Epoch 9, Batch 200] loss: 0.08713368580909446
[Epoch 9, Batch 300] loss: 0.05751457314589061
[Epoch 9, Batch 400] loss: 0.07075758831808343
[Epoch 9, Batch 500] loss: 0.0644082406105008
[Epoch 9, Batch 600] loss: 0.05879166254540905
[Epoch 9, Batch 700] loss: 0.06767332232091576
[Epoch 9, Batch 800] loss: 0.06782770067220553
[Epoch 9, Batch 900] loss: 0.05339936145814136
**STATS for Epoch 9** : 
Average training loss: 0.0029
Average validation loss: 0.0796
Validation Accuracy: 0.9751
Overfitting: 0.0767
Best model saved at epoch 9 with validation loss: 0.0796
[Epoch 10, Batch 100] loss: 0.07057437795796431
[Epoch 10, Batch 200] loss: 0.055241769968997684
[Epoch 10, Batch 300] loss: 0.050903784641996026
[Epoch 10, Batch 400] loss: 0.060604594789911065
[Epoch 10, Batch 500] loss: 0.060478866875637326
[Epoch 10, Batch 600] loss: 0.06213880476076156
[Epoch 10, Batch 700] loss: 0.06265810532495379
[Epoch 10, Batch 800] loss: 0.06004664267646149
[Epoch 10, Batch 900] loss: 0.059876078884117306
**STATS for Epoch 10** : 
Average training loss: 0.0017
Average validation loss: 0.0718
Validation Accuracy: 0.9777
Overfitting: 0.0702
[I 2024-11-21 20:38:24,720] Trial 19 pruned. 

Selected Hyperparameters for Trial 21:
  l1: 128, l2: 128, lr: 0.0001422055773698847, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3036746072769163
[Epoch 1, Batch 200] loss: 2.302122836112976
[Epoch 1, Batch 300] loss: 2.301237301826477
[Epoch 1, Batch 400] loss: 2.300254855155945
[Epoch 1, Batch 500] loss: 2.2991208720207212
[Epoch 1, Batch 600] loss: 2.2971727561950686
[Epoch 1, Batch 700] loss: 2.295471749305725
[Epoch 1, Batch 800] loss: 2.294073841571808
[Epoch 1, Batch 900] loss: 2.292725121974945
**STATS for Epoch 1** : 
Average training loss: 0.0929
Average validation loss: 2.2914
Validation Accuracy: 0.1447
Overfitting: 2.1985
Best model saved at epoch 1 with validation loss: 2.2914
[Epoch 2, Batch 100] loss: 2.2904256796836853
[Epoch 2, Batch 200] loss: 2.28749258518219
[Epoch 2, Batch 300] loss: 2.284759237766266
[Epoch 2, Batch 400] loss: 2.2840989327430723
[Epoch 2, Batch 500] loss: 2.2796922659873964
[Epoch 2, Batch 600] loss: 2.2752029037475587
[Epoch 2, Batch 700] loss: 2.2730807209014894
[Epoch 2, Batch 800] loss: 2.269108474254608
[Epoch 2, Batch 900] loss: 2.2634982442855835
**STATS for Epoch 2** : 
Average training loss: 0.0915
Average validation loss: 2.2574
Validation Accuracy: 0.2364
Overfitting: 2.1659
Best model saved at epoch 2 with validation loss: 2.2574
[Epoch 3, Batch 100] loss: 2.2546508073806764
[Epoch 3, Batch 200] loss: 2.2453156876564027
[Epoch 3, Batch 300] loss: 2.234186706542969
[Epoch 3, Batch 400] loss: 2.2219089436531068
[Epoch 3, Batch 500] loss: 2.2012754321098327
[Epoch 3, Batch 600] loss: 2.177704219818115
[Epoch 3, Batch 700] loss: 2.148697330951691
[Epoch 3, Batch 800] loss: 2.105959212779999
[Epoch 3, Batch 900] loss: 2.0433852076530457
**STATS for Epoch 3** : 
Average training loss: 0.0802
Average validation loss: 1.9677
Validation Accuracy: 0.5640
Overfitting: 1.8875
Best model saved at epoch 3 with validation loss: 1.9677
[Epoch 4, Batch 100] loss: 1.906819794178009
[Epoch 4, Batch 200] loss: 1.7654859495162964
[Epoch 4, Batch 300] loss: 1.5666540896892547
[Epoch 4, Batch 400] loss: 1.3412617576122283
[Epoch 4, Batch 500] loss: 1.1107340025901795
[Epoch 4, Batch 600] loss: 0.9416184973716736
[Epoch 4, Batch 700] loss: 0.8042799225449562
[Epoch 4, Batch 800] loss: 0.6987203362584115
[Epoch 4, Batch 900] loss: 0.6246216896176339
**STATS for Epoch 4** : 
Average training loss: 0.0264
Average validation loss: 0.5861
Validation Accuracy: 0.8361
Overfitting: 0.5597
Best model saved at epoch 4 with validation loss: 0.5861
[Epoch 5, Batch 100] loss: 0.5706568193435669
[Epoch 5, Batch 200] loss: 0.5350460880994796
[Epoch 5, Batch 300] loss: 0.5120318883657455
[Epoch 5, Batch 400] loss: 0.5009180718660354
[Epoch 5, Batch 500] loss: 0.47905669555068014
[Epoch 5, Batch 600] loss: 0.47200218215584755
[Epoch 5, Batch 700] loss: 0.44616576984524725
[Epoch 5, Batch 800] loss: 0.4098368452489376
[Epoch 5, Batch 900] loss: 0.4034926003217697
**STATS for Epoch 5** : 
Average training loss: 0.0170
Average validation loss: 0.4035
Validation Accuracy: 0.8767
Overfitting: 0.3866
Best model saved at epoch 5 with validation loss: 0.4035
[Epoch 6, Batch 100] loss: 0.36277639962732794
[Epoch 6, Batch 200] loss: 0.3773560102283955
[Epoch 6, Batch 300] loss: 0.37035536386072637
[Epoch 6, Batch 400] loss: 0.38438462391495704
[Epoch 6, Batch 500] loss: 0.3824759016185999
[Epoch 6, Batch 600] loss: 0.36865744791924954
[Epoch 6, Batch 700] loss: 0.3525978530943394
[Epoch 6, Batch 800] loss: 0.3471484822034836
[Epoch 6, Batch 900] loss: 0.33413895286619666
**STATS for Epoch 6** : 
Average training loss: 0.0147
Average validation loss: 0.3285
Validation Accuracy: 0.9017
Overfitting: 0.3138
Best model saved at epoch 6 with validation loss: 0.3285
[Epoch 7, Batch 100] loss: 0.33168605878949164
[Epoch 7, Batch 200] loss: 0.3481863564997911
[Epoch 7, Batch 300] loss: 0.33690813031047584
[Epoch 7, Batch 400] loss: 0.31377260748296976
[Epoch 7, Batch 500] loss: 0.28833512507379055
[Epoch 7, Batch 600] loss: 0.30548651568591595
[Epoch 7, Batch 700] loss: 0.2950450579077005
[Epoch 7, Batch 800] loss: 0.2714968265593052
[Epoch 7, Batch 900] loss: 0.277120917737484
**STATS for Epoch 7** : 
Average training loss: 0.0104
Average validation loss: 0.2822
Validation Accuracy: 0.9169
Overfitting: 0.2719
Best model saved at epoch 7 with validation loss: 0.2822
[Epoch 8, Batch 100] loss: 0.28319522373378275
[Epoch 8, Batch 200] loss: 0.2694104025512934
[Epoch 8, Batch 300] loss: 0.28666259557008744
[Epoch 8, Batch 400] loss: 0.26757231704890727
[Epoch 8, Batch 500] loss: 0.2782656506076455
[Epoch 8, Batch 600] loss: 0.25124361194670203
[Epoch 8, Batch 700] loss: 0.2605084213241935
[Epoch 8, Batch 800] loss: 0.2546473324671388
[Epoch 8, Batch 900] loss: 0.24014318726956843
**STATS for Epoch 8** : 
Average training loss: 0.0095
Average validation loss: 0.2462
Validation Accuracy: 0.9262
Overfitting: 0.2367
Best model saved at epoch 8 with validation loss: 0.2462
[Epoch 9, Batch 100] loss: 0.2407554841414094
[Epoch 9, Batch 200] loss: 0.25186353355646135
[Epoch 9, Batch 300] loss: 0.2458081179484725
[Epoch 9, Batch 400] loss: 0.23444337461143733
[Epoch 9, Batch 500] loss: 0.22589914068579675
[Epoch 9, Batch 600] loss: 0.2362209764868021
[Epoch 9, Batch 700] loss: 0.22699575990438461
[Epoch 9, Batch 800] loss: 0.2308779190480709
[Epoch 9, Batch 900] loss: 0.22666090350598098
**STATS for Epoch 9** : 
Average training loss: 0.0084
Average validation loss: 0.2215
Validation Accuracy: 0.9323
Overfitting: 0.2130
[I 2024-11-21 20:40:14,643] Trial 20 pruned. 

Selected Hyperparameters for Trial 22:
  l1: 128, l2: 128, lr: 0.00988782688183443, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.5714979481697082
[Epoch 1, Batch 200] loss: 0.46133054330945017
[Epoch 1, Batch 300] loss: 0.24218721475452185
[Epoch 1, Batch 400] loss: 0.20453556098043918
[Epoch 1, Batch 500] loss: 0.18235290128737688
[Epoch 1, Batch 600] loss: 0.1613578536361456
[Epoch 1, Batch 700] loss: 0.1514400763437152
[Epoch 1, Batch 800] loss: 0.14853911625221372
[Epoch 1, Batch 900] loss: 0.12836335939355195
**STATS for Epoch 1** : 
Average training loss: 0.0048
Average validation loss: 0.1331
Validation Accuracy: 0.9595
Overfitting: 0.1283
Best model saved at epoch 1 with validation loss: 0.1331
[Epoch 2, Batch 100] loss: 0.10372859780909494
[Epoch 2, Batch 200] loss: 0.09924725702498108
[Epoch 2, Batch 300] loss: 0.11588113267440349
[Epoch 2, Batch 400] loss: 0.09884993840707466
[Epoch 2, Batch 500] loss: 0.09921692506759427
[Epoch 2, Batch 600] loss: 0.07579887957312166
[Epoch 2, Batch 700] loss: 0.07794918665429577
[Epoch 2, Batch 800] loss: 0.09552331587765366
[Epoch 2, Batch 900] loss: 0.07988297046162188
**STATS for Epoch 2** : 
Average training loss: 0.0039
Average validation loss: 0.0763
Validation Accuracy: 0.9765
Overfitting: 0.0724
Best model saved at epoch 2 with validation loss: 0.0763
[Epoch 3, Batch 100] loss: 0.05890023923013359
[Epoch 3, Batch 200] loss: 0.05782909141969867
[Epoch 3, Batch 300] loss: 0.07055220384616405
[Epoch 3, Batch 400] loss: 0.06300565193407237
[Epoch 3, Batch 500] loss: 0.0650916994625004
[Epoch 3, Batch 600] loss: 0.0659964643791318
[Epoch 3, Batch 700] loss: 0.05135380452207755
[Epoch 3, Batch 800] loss: 0.0628429586288985
[Epoch 3, Batch 900] loss: 0.06740729779063258
**STATS for Epoch 3** : 
Average training loss: 0.0023
Average validation loss: 0.0669
Validation Accuracy: 0.9796
Overfitting: 0.0646
Best model saved at epoch 3 with validation loss: 0.0669
[Epoch 4, Batch 100] loss: 0.035964015487697905
[Epoch 4, Batch 200] loss: 0.036445147332269695
[Epoch 4, Batch 300] loss: 0.04483730565480073
[Epoch 4, Batch 400] loss: 0.0463860150394612
[Epoch 4, Batch 500] loss: 0.04521564202776062
[Epoch 4, Batch 600] loss: 0.04635879725392442
[Epoch 4, Batch 700] loss: 0.035892477879278885
[Epoch 4, Batch 800] loss: 0.044035730776959096
[Epoch 4, Batch 900] loss: 0.04511596538242884
**STATS for Epoch 4** : 
Average training loss: 0.0028
Average validation loss: 0.0875
Validation Accuracy: 0.9757
Overfitting: 0.0847
[Epoch 5, Batch 100] loss: 0.037887109379953474
[Epoch 5, Batch 200] loss: 0.03257701756432652
[Epoch 5, Batch 300] loss: 0.047881241971335836
[Epoch 5, Batch 400] loss: 0.04490052388464392
[Epoch 5, Batch 500] loss: 0.03069188392284559
[Epoch 5, Batch 600] loss: 0.05015682578989072
[Epoch 5, Batch 700] loss: 0.03235379468562314
[Epoch 5, Batch 800] loss: 0.04139680057764053
[Epoch 5, Batch 900] loss: 0.037457464313338275
**STATS for Epoch 5** : 
Average training loss: 0.0018
Average validation loss: 0.0651
Validation Accuracy: 0.9807
Overfitting: 0.0633
Best model saved at epoch 5 with validation loss: 0.0651
[Epoch 6, Batch 100] loss: 0.027932230484148023
[Epoch 6, Batch 200] loss: 0.018728069232747658
[Epoch 6, Batch 300] loss: 0.02023394939787977
[Epoch 6, Batch 400] loss: 0.025566244913461558
[Epoch 6, Batch 500] loss: 0.0350973267104564
[Epoch 6, Batch 600] loss: 0.023395550098648528
[Epoch 6, Batch 700] loss: 0.02833163713399699
[Epoch 6, Batch 800] loss: 0.027631571052916117
[Epoch 6, Batch 900] loss: 0.03243992578029065
**STATS for Epoch 6** : 
Average training loss: 0.0014
Average validation loss: 0.0653
Validation Accuracy: 0.9815
Overfitting: 0.0640
[Epoch 7, Batch 100] loss: 0.017663482011266753
[Epoch 7, Batch 200] loss: 0.030151215895893983
[Epoch 7, Batch 300] loss: 0.01642427724054869
[Epoch 7, Batch 400] loss: 0.02017111630990257
[Epoch 7, Batch 500] loss: 0.01877111243484251
[Epoch 7, Batch 600] loss: 0.01862071334879147
[Epoch 7, Batch 700] loss: 0.03734156210979563
[Epoch 7, Batch 800] loss: 0.03015756348047944
[Epoch 7, Batch 900] loss: 0.02281249095656676
**STATS for Epoch 7** : 
Average training loss: 0.0006
Average validation loss: 0.0597
Validation Accuracy: 0.9845
Overfitting: 0.0592
Best model saved at epoch 7 with validation loss: 0.0597
[Epoch 8, Batch 100] loss: 0.017154903099853982
[Epoch 8, Batch 200] loss: 0.01071437307215092
[Epoch 8, Batch 300] loss: 0.0188911481893183
[Epoch 8, Batch 400] loss: 0.013439819621271453
[Epoch 8, Batch 500] loss: 0.015112313200734206
[Epoch 8, Batch 600] loss: 0.02075528252885306
[Epoch 8, Batch 700] loss: 0.023953787377031403
[Epoch 8, Batch 800] loss: 0.02803463622396521
[Epoch 8, Batch 900] loss: 0.02029325131486985
**STATS for Epoch 8** : 
Average training loss: 0.0005
Average validation loss: 0.0690
Validation Accuracy: 0.9824
Overfitting: 0.0685
[Epoch 9, Batch 100] loss: 0.005080949832827173
[Epoch 9, Batch 200] loss: 0.014066869510761535
[Epoch 9, Batch 300] loss: 0.008300916625175887
[Epoch 9, Batch 400] loss: 0.017797234690442566
[Epoch 9, Batch 500] loss: 0.0164378210187715
[Epoch 9, Batch 600] loss: 0.01910106365003685
[Epoch 9, Batch 700] loss: 0.024987650516213763
[Epoch 9, Batch 800] loss: 0.02933113765714097
[Epoch 9, Batch 900] loss: 0.025667010865677183
**STATS for Epoch 9** : 
Average training loss: 0.0005
Average validation loss: 0.0663
Validation Accuracy: 0.9839
Overfitting: 0.0659
[Epoch 10, Batch 100] loss: 0.016668950825151116
[Epoch 10, Batch 200] loss: 0.016860280297023564
[Epoch 10, Batch 300] loss: 0.01101093848822984
[Epoch 10, Batch 400] loss: 0.006210493669800599
[Epoch 10, Batch 500] loss: 0.012385777229515043
[Epoch 10, Batch 600] loss: 0.020255693043391147
[Epoch 10, Batch 700] loss: 0.02515592343773278
[Epoch 10, Batch 800] loss: 0.020677010494446223
[Epoch 10, Batch 900] loss: 0.02144334375019753
**STATS for Epoch 10** : 
Average training loss: 0.0011
Average validation loss: 0.0718
Validation Accuracy: 0.9829
Overfitting: 0.0708
[Epoch 11, Batch 100] loss: 0.006302828442255759
[Epoch 11, Batch 200] loss: 0.011015561267304292
[Epoch 11, Batch 300] loss: 0.014609533830189321
[Epoch 11, Batch 400] loss: 0.011754176218755675
[Epoch 11, Batch 500] loss: 0.01327502257820015
[Epoch 11, Batch 600] loss: 0.004828392497238383
[Epoch 11, Batch 700] loss: 0.021141206473803322
[Epoch 11, Batch 800] loss: 0.0190596705554799
[Epoch 11, Batch 900] loss: 0.020294607366595302
**STATS for Epoch 11** : 
Average training loss: 0.0004
Average validation loss: 0.0649
Validation Accuracy: 0.9835
Overfitting: 0.0645
[Epoch 12, Batch 100] loss: 0.007751469558334065
[Epoch 12, Batch 200] loss: 0.013281816197468288
[Epoch 12, Batch 300] loss: 0.019116154119665225
[Epoch 12, Batch 400] loss: 0.012654587562415144
[Epoch 12, Batch 500] loss: 0.003760470436218384
[Epoch 12, Batch 600] loss: 0.008293786965768959
[Epoch 12, Batch 700] loss: 0.011628986963883108
[Epoch 12, Batch 800] loss: 0.025182139021335957
[Epoch 12, Batch 900] loss: 0.02039288066964218
**STATS for Epoch 12** : 
Average training loss: 0.0007
Average validation loss: 0.0743
Validation Accuracy: 0.9832
Overfitting: 0.0736
[Epoch 13, Batch 100] loss: 0.012053325177148508
[Epoch 13, Batch 200] loss: 0.005527891992987861
[Epoch 13, Batch 300] loss: 0.008259335459758859
[Epoch 13, Batch 400] loss: 0.0105671371831977
[Epoch 13, Batch 500] loss: 0.013592347774747396
[Epoch 13, Batch 600] loss: 0.007330321895602765
[Epoch 13, Batch 700] loss: 0.012167083624390215
[Epoch 13, Batch 800] loss: 0.0077452248666440935
[Epoch 13, Batch 900] loss: 0.013198080467294631
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0740
Validation Accuracy: 0.9848
Overfitting: 0.0730
[Epoch 14, Batch 100] loss: 0.008921975362254671
[Epoch 14, Batch 200] loss: 0.010661854132207509
[Epoch 14, Batch 300] loss: 0.007421295548853948
[Epoch 14, Batch 400] loss: 0.00869882254126196
[Epoch 14, Batch 500] loss: 0.007020156907960313
[Epoch 14, Batch 600] loss: 0.006010362904712565
[Epoch 14, Batch 700] loss: 0.007589042327361994
[Epoch 14, Batch 800] loss: 0.02376498428721334
[Epoch 14, Batch 900] loss: 0.014405941226468712
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0768
Validation Accuracy: 0.9845
Overfitting: 0.0764
[Epoch 15, Batch 100] loss: 0.004556734150719599
[Epoch 15, Batch 200] loss: 0.0031930864555033624
[Epoch 15, Batch 300] loss: 0.004266834659903225
[Epoch 15, Batch 400] loss: 0.013364505033919158
[Epoch 15, Batch 500] loss: 0.013998367207082084
[Epoch 15, Batch 600] loss: 0.01306873622346302
[Epoch 15, Batch 700] loss: 0.008802023561651709
[Epoch 15, Batch 800] loss: 0.007413294132346664
[Epoch 15, Batch 900] loss: 0.00978408700449501
**STATS for Epoch 15** : 
Average training loss: 0.0001
Average validation loss: 0.0722
Validation Accuracy: 0.9847
Overfitting: 0.0721
[Epoch 16, Batch 100] loss: 0.0024021855440747686
[Epoch 16, Batch 200] loss: 0.008733281682836491
[Epoch 16, Batch 300] loss: 0.007474015616135716
[Epoch 16, Batch 400] loss: 0.019159529718656358
[Epoch 16, Batch 500] loss: 0.014877794204753627
[Epoch 16, Batch 600] loss: 0.011833400417694975
[Epoch 16, Batch 700] loss: 0.013225919944796943
[Epoch 16, Batch 800] loss: 0.014537600470521283
[Epoch 16, Batch 900] loss: 0.004476892829900123
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0830
Validation Accuracy: 0.9846
Overfitting: 0.0826
[Epoch 17, Batch 100] loss: 0.009701504682532232
[Epoch 17, Batch 200] loss: 0.00737195340247581
[Epoch 17, Batch 300] loss: 0.003757386771430191
[Epoch 17, Batch 400] loss: 0.004919968888871153
[Epoch 17, Batch 500] loss: 0.004996776347558125
[Epoch 17, Batch 600] loss: 0.002602675621005801
[Epoch 17, Batch 700] loss: 0.00609656753257525
[Epoch 17, Batch 800] loss: 0.0058168596081497985
[Epoch 17, Batch 900] loss: 0.01175100123090715
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0769
Validation Accuracy: 0.9833
Overfitting: 0.0764
[Epoch 18, Batch 100] loss: 0.0032173934154047855
[Epoch 18, Batch 200] loss: 0.0015447867813476535
[Epoch 18, Batch 300] loss: 0.0018462190898443963
[Epoch 18, Batch 400] loss: 0.0007939385048945269
[Epoch 18, Batch 500] loss: 0.0011501128113201276
[Epoch 18, Batch 600] loss: 0.003296177156744875
[Epoch 18, Batch 700] loss: 0.0052551572547483265
[Epoch 18, Batch 800] loss: 0.004219321689819253
[Epoch 18, Batch 900] loss: 0.002533777484190409
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0909
Validation Accuracy: 0.9834
Overfitting: 0.0908
[Epoch 19, Batch 100] loss: 0.007725308713285699
[Epoch 19, Batch 200] loss: 0.004874517008895225
[Epoch 19, Batch 300] loss: 0.002678857101621759
[Epoch 19, Batch 400] loss: 0.0023769117021834063
[Epoch 19, Batch 500] loss: 0.005106982637639561
[Epoch 19, Batch 600] loss: 0.010743884999077977
[Epoch 19, Batch 700] loss: 0.00741246036085883
[Epoch 19, Batch 800] loss: 0.014390949326469098
[Epoch 19, Batch 900] loss: 0.01955915316340338
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0721
Validation Accuracy: 0.9855
Overfitting: 0.0719
[Epoch 20, Batch 100] loss: 0.002236855119432448
[Epoch 20, Batch 200] loss: 0.0020792585498045925
[Epoch 20, Batch 300] loss: 0.0042062103072544234
[Epoch 20, Batch 400] loss: 0.007014914628581294
[Epoch 20, Batch 500] loss: 0.0019492289455121182
[Epoch 20, Batch 600] loss: 0.0010075434932977601
[Epoch 20, Batch 700] loss: 0.0015846050694358382
[Epoch 20, Batch 800] loss: 0.002469645265136364
[Epoch 20, Batch 900] loss: 0.00037627191387628044
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0771
Validation Accuracy: 0.9855
Overfitting: 0.0770
[Epoch 21, Batch 100] loss: 0.0023287193436799924
[Epoch 21, Batch 200] loss: 0.0004569127419671304
[Epoch 21, Batch 300] loss: 0.00026940217516489894
[Epoch 21, Batch 400] loss: 0.00038800127744327285
[Epoch 21, Batch 500] loss: 0.0009468302256833639
[Epoch 21, Batch 600] loss: 0.0006771646676773458
[Epoch 21, Batch 700] loss: 0.0014758243717727915
[Epoch 21, Batch 800] loss: 0.002213528515001144
[Epoch 21, Batch 900] loss: 0.000547438696844047
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0753
Validation Accuracy: 0.9875
Overfitting: 0.0753
[Epoch 22, Batch 100] loss: 0.0001102616461470518
[Epoch 22, Batch 200] loss: 0.0010773976659023353
[Epoch 22, Batch 300] loss: 0.0019860707970695657
[Epoch 22, Batch 400] loss: 0.00033903943434026473
[Epoch 22, Batch 500] loss: 0.0009265605535038546
[Epoch 22, Batch 600] loss: 0.0002700493716549701
[Epoch 22, Batch 700] loss: 0.0002233367063004188
[Epoch 22, Batch 800] loss: 0.00014365662692419123
[Epoch 22, Batch 900] loss: 0.00010322335985779807
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0775
Validation Accuracy: 0.9876
Overfitting: 0.0775
[Epoch 23, Batch 100] loss: 8.864677885259908e-05
[Epoch 23, Batch 200] loss: 0.00013821117517070824
[Epoch 23, Batch 300] loss: 5.921294661180854e-05
[Epoch 23, Batch 400] loss: 0.00012822161084834028
[Epoch 23, Batch 500] loss: 5.742017459825277e-05
[Epoch 23, Batch 600] loss: 0.00015405634395470713
[Epoch 23, Batch 700] loss: 0.00010652498657503174
[Epoch 23, Batch 800] loss: 7.611130751253192e-05
[Epoch 23, Batch 900] loss: 5.013543129529507e-05
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0782
Validation Accuracy: 0.9877
Overfitting: 0.0782
[Epoch 24, Batch 100] loss: 4.0510096427990304e-05
[Epoch 24, Batch 200] loss: 3.990313473761109e-05
[Epoch 24, Batch 300] loss: 4.728212002750309e-05
[Epoch 24, Batch 400] loss: 4.335921620555183e-05
[Epoch 24, Batch 500] loss: 4.005088088535613e-05
[Epoch 24, Batch 600] loss: 0.0001186286699662631
[Epoch 24, Batch 700] loss: 4.240624047100239e-05
[Epoch 24, Batch 800] loss: 5.191228726774133e-05
[Epoch 24, Batch 900] loss: 9.274058491548943e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0803
Validation Accuracy: 0.9879
Overfitting: 0.0803
Fold 1 validation loss: 0.0803
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.583520515859127
[Epoch 1, Batch 200] loss: 0.40100762851536276
[Epoch 1, Batch 300] loss: 0.2573980349861085
[Epoch 1, Batch 400] loss: 0.19400357838720084
[Epoch 1, Batch 500] loss: 0.15370740776881575
[Epoch 1, Batch 600] loss: 0.14453639929182827
[Epoch 1, Batch 700] loss: 0.13631623268593102
[Epoch 1, Batch 800] loss: 0.129706493858248
[Epoch 1, Batch 900] loss: 0.11646163736237213
**STATS for Epoch 1** : 
Average training loss: 0.0034
Average validation loss: 0.1175
Validation Accuracy: 0.9634
Overfitting: 0.1142
Best model saved at epoch 1 with validation loss: 0.1175
[Epoch 2, Batch 100] loss: 0.09369561763945967
[Epoch 2, Batch 200] loss: 0.08586116084421519
[Epoch 2, Batch 300] loss: 0.0770035996939987
[Epoch 2, Batch 400] loss: 0.07620331286452711
[Epoch 2, Batch 500] loss: 0.06759399827278685
[Epoch 2, Batch 600] loss: 0.07912485426757485
[Epoch 2, Batch 700] loss: 0.06550585346645675
[Epoch 2, Batch 800] loss: 0.07017977877287195
[Epoch 2, Batch 900] loss: 0.06993324975133873
**STATS for Epoch 2** : 
Average training loss: 0.0032
Average validation loss: 0.1123
Validation Accuracy: 0.9658
Overfitting: 0.1091
Best model saved at epoch 2 with validation loss: 0.1123
[Epoch 3, Batch 100] loss: 0.04479355732968543
[Epoch 3, Batch 200] loss: 0.058664114658604376
[Epoch 3, Batch 300] loss: 0.05220012887468329
[Epoch 3, Batch 400] loss: 0.05135420376987895
[Epoch 3, Batch 500] loss: 0.06672506561968476
[Epoch 3, Batch 600] loss: 0.06487387573346495
[Epoch 3, Batch 700] loss: 0.06477618291159161
[Epoch 3, Batch 800] loss: 0.05785870795021765
[Epoch 3, Batch 900] loss: 0.057044193569454366
**STATS for Epoch 3** : 
Average training loss: 0.0016
Average validation loss: 0.0509
Validation Accuracy: 0.9852
Overfitting: 0.0493
Best model saved at epoch 3 with validation loss: 0.0509
[Epoch 4, Batch 100] loss: 0.03023358959937468
[Epoch 4, Batch 200] loss: 0.03207983554922975
[Epoch 4, Batch 300] loss: 0.034918420221074484
[Epoch 4, Batch 400] loss: 0.03903834750268288
[Epoch 4, Batch 500] loss: 0.046281401960877704
[Epoch 4, Batch 600] loss: 0.0425737217097776
[Epoch 4, Batch 700] loss: 0.048645192316762405
[Epoch 4, Batch 800] loss: 0.04955173858674243
[Epoch 4, Batch 900] loss: 0.04177515362680424
**STATS for Epoch 4** : 
Average training loss: 0.0013
Average validation loss: 0.0572
Validation Accuracy: 0.9851
Overfitting: 0.0559
[Epoch 5, Batch 100] loss: 0.03092616606532829
[Epoch 5, Batch 200] loss: 0.02772823231156508
[Epoch 5, Batch 300] loss: 0.03531117395745241
[Epoch 5, Batch 400] loss: 0.03638483542701579
[Epoch 5, Batch 500] loss: 0.036118390358169564
[Epoch 5, Batch 600] loss: 0.02992593443428632
[Epoch 5, Batch 700] loss: 0.028218644233056693
[Epoch 5, Batch 800] loss: 0.03939462836482562
[Epoch 5, Batch 900] loss: 0.041900289723125754
**STATS for Epoch 5** : 
Average training loss: 0.0015
Average validation loss: 0.0789
Validation Accuracy: 0.9766
Overfitting: 0.0774
[Epoch 6, Batch 100] loss: 0.024955489572021178
[Epoch 6, Batch 200] loss: 0.016493838055666857
[Epoch 6, Batch 300] loss: 0.03409199450055894
[Epoch 6, Batch 400] loss: 0.0308953100022336
[Epoch 6, Batch 500] loss: 0.018503975111016188
[Epoch 6, Batch 600] loss: 0.033487571870500686
[Epoch 6, Batch 700] loss: 0.029069907569282804
[Epoch 6, Batch 800] loss: 0.03369575297067058
[Epoch 6, Batch 900] loss: 0.029808597288501916
**STATS for Epoch 6** : 
Average training loss: 0.0007
Average validation loss: 0.0482
Validation Accuracy: 0.9877
Overfitting: 0.0475
Best model saved at epoch 6 with validation loss: 0.0482
[Epoch 7, Batch 100] loss: 0.0344962026871508
[Epoch 7, Batch 200] loss: 0.026376768037152942
[Epoch 7, Batch 300] loss: 0.0218922078741889
[Epoch 7, Batch 400] loss: 0.014535744933818933
[Epoch 7, Batch 500] loss: 0.021323008701074286
[Epoch 7, Batch 600] loss: 0.020623881409592287
[Epoch 7, Batch 700] loss: 0.014344087390963978
[Epoch 7, Batch 800] loss: 0.02451227153007494
[Epoch 7, Batch 900] loss: 0.028764948111056583
**STATS for Epoch 7** : 
Average training loss: 0.0005
Average validation loss: 0.0511
Validation Accuracy: 0.9867
Overfitting: 0.0506
[Epoch 8, Batch 100] loss: 0.013361920295301389
[Epoch 8, Batch 200] loss: 0.015749093980466568
[Epoch 8, Batch 300] loss: 0.013397553303875612
[Epoch 8, Batch 400] loss: 0.016339004478722927
[Epoch 8, Batch 500] loss: 0.020032585168955848
[Epoch 8, Batch 600] loss: 0.018533732708583557
[Epoch 8, Batch 700] loss: 0.016049898295368622
[Epoch 8, Batch 800] loss: 0.02620511522087327
[Epoch 8, Batch 900] loss: 0.041139668990253994
**STATS for Epoch 8** : 
Average training loss: 0.0008
Average validation loss: 0.0615
Validation Accuracy: 0.9830
Overfitting: 0.0607
[Epoch 9, Batch 100] loss: 0.009967674002450622
[Epoch 9, Batch 200] loss: 0.011949930827904609
[Epoch 9, Batch 300] loss: 0.037819456496545174
[Epoch 9, Batch 400] loss: 0.01996909843550384
[Epoch 9, Batch 500] loss: 0.019263871814691812
[Epoch 9, Batch 600] loss: 0.022044796812842833
[Epoch 9, Batch 700] loss: 0.01809367823039793
[Epoch 9, Batch 800] loss: 0.019837244765194554
[Epoch 9, Batch 900] loss: 0.01906537198406113
**STATS for Epoch 9** : 
Average training loss: 0.0004
Average validation loss: 0.0514
Validation Accuracy: 0.9875
Overfitting: 0.0510
[Epoch 10, Batch 100] loss: 0.00703778310376947
[Epoch 10, Batch 200] loss: 0.007986832522556142
[Epoch 10, Batch 300] loss: 0.011446631834423897
[Epoch 10, Batch 400] loss: 0.009894525742947736
[Epoch 10, Batch 500] loss: 0.018230855144574887
[Epoch 10, Batch 600] loss: 0.009922423276675545
[Epoch 10, Batch 700] loss: 0.015496347816060733
[Epoch 10, Batch 800] loss: 0.014790033101198787
[Epoch 10, Batch 900] loss: 0.021014498858198748
**STATS for Epoch 10** : 
Average training loss: 0.0011
Average validation loss: 0.0584
Validation Accuracy: 0.9859
Overfitting: 0.0573
[Epoch 11, Batch 100] loss: 0.01242925424618079
[Epoch 11, Batch 200] loss: 0.012908215062961971
[Epoch 11, Batch 300] loss: 0.013497372696929234
[Epoch 11, Batch 400] loss: 0.011872484013788381
[Epoch 11, Batch 500] loss: 0.008560336156624543
[Epoch 11, Batch 600] loss: 0.006840201822769814
[Epoch 11, Batch 700] loss: 0.00941223036722249
[Epoch 11, Batch 800] loss: 0.009907669882377377
[Epoch 11, Batch 900] loss: 0.014582256185358347
**STATS for Epoch 11** : 
Average training loss: 0.0008
Average validation loss: 0.0685
Validation Accuracy: 0.9855
Overfitting: 0.0677
[Epoch 12, Batch 100] loss: 0.012380133300898705
[Epoch 12, Batch 200] loss: 0.013880935051060988
[Epoch 12, Batch 300] loss: 0.014317609994436679
[Epoch 12, Batch 400] loss: 0.017682633418860404
[Epoch 12, Batch 500] loss: 0.012575458061173777
[Epoch 12, Batch 600] loss: 0.013879240460223628
[Epoch 12, Batch 700] loss: 0.0173325279870096
[Epoch 12, Batch 800] loss: 0.008619304427556927
[Epoch 12, Batch 900] loss: 0.010500786916290963
**STATS for Epoch 12** : 
Average training loss: 0.0005
Average validation loss: 0.0513
Validation Accuracy: 0.9882
Overfitting: 0.0509
[Epoch 13, Batch 100] loss: 0.0028736773965778186
[Epoch 13, Batch 200] loss: 0.015473345888662494
[Epoch 13, Batch 300] loss: 0.003954598919001455
[Epoch 13, Batch 400] loss: 0.009641200830865273
[Epoch 13, Batch 500] loss: 0.00972673196235519
[Epoch 13, Batch 600] loss: 0.00825003725226452
[Epoch 13, Batch 700] loss: 0.012466649457744552
[Epoch 13, Batch 800] loss: 0.0026114026927143642
[Epoch 13, Batch 900] loss: 0.009146841600431799
**STATS for Epoch 13** : 
Average training loss: 0.0004
Average validation loss: 0.0563
Validation Accuracy: 0.9880
Overfitting: 0.0559
[Epoch 14, Batch 100] loss: 0.009538413331640641
[Epoch 14, Batch 200] loss: 0.005648014333517039
[Epoch 14, Batch 300] loss: 0.00591806755700901
[Epoch 14, Batch 400] loss: 0.009363828279402924
[Epoch 14, Batch 500] loss: 0.011215339879404382
[Epoch 14, Batch 600] loss: 0.007515173306398992
[Epoch 14, Batch 700] loss: 0.0076419305222202635
[Epoch 14, Batch 800] loss: 0.011197917769436572
[Epoch 14, Batch 900] loss: 0.01568966220429729
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0688
Validation Accuracy: 0.9871
Overfitting: 0.0680
[Epoch 15, Batch 100] loss: 0.011260025500860138
[Epoch 15, Batch 200] loss: 0.009696320161381208
[Epoch 15, Batch 300] loss: 0.008335467068411618
[Epoch 15, Batch 400] loss: 0.012853265203855244
[Epoch 15, Batch 500] loss: 0.015032779238667473
[Epoch 15, Batch 600] loss: 0.012765429503870109
[Epoch 15, Batch 700] loss: 0.011108722209168604
[Epoch 15, Batch 800] loss: 0.012576537718234703
[Epoch 15, Batch 900] loss: 0.008022029579378795
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0746
Validation Accuracy: 0.9851
Overfitting: 0.0739
[Epoch 16, Batch 100] loss: 0.011054923191626358
[Epoch 16, Batch 200] loss: 0.009955481729491567
[Epoch 16, Batch 300] loss: 0.015505012115984868
[Epoch 16, Batch 400] loss: 0.015574743944866895
[Epoch 16, Batch 500] loss: 0.012243508217905017
[Epoch 16, Batch 600] loss: 0.015558801531960853
[Epoch 16, Batch 700] loss: 0.016482710603060013
[Epoch 16, Batch 800] loss: 0.02530008529380666
[Epoch 16, Batch 900] loss: 0.028458063318441872
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0595
Validation Accuracy: 0.9869
Overfitting: 0.0588
[Epoch 17, Batch 100] loss: 0.012131511908808078
[Epoch 17, Batch 200] loss: 0.00599589924761517
[Epoch 17, Batch 300] loss: 0.008895708117167942
[Epoch 17, Batch 400] loss: 0.010024750532231223
[Epoch 17, Batch 500] loss: 0.009376331128321312
[Epoch 17, Batch 600] loss: 0.00758351159019071
[Epoch 17, Batch 700] loss: 0.02082466237023709
[Epoch 17, Batch 800] loss: 0.009777997752352122
[Epoch 17, Batch 900] loss: 0.0130592109985389
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0600
Validation Accuracy: 0.9872
Overfitting: 0.0598
[Epoch 18, Batch 100] loss: 0.0033933286286463725
[Epoch 18, Batch 200] loss: 0.004090745149765809
[Epoch 18, Batch 300] loss: 0.0023505858154885574
[Epoch 18, Batch 400] loss: 0.006754676509365254
[Epoch 18, Batch 500] loss: 0.001835647306794783
[Epoch 18, Batch 600] loss: 0.002586090181230247
[Epoch 18, Batch 700] loss: 0.0053403208916583365
[Epoch 18, Batch 800] loss: 0.002016904217662283
[Epoch 18, Batch 900] loss: 0.006669556771565297
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0748
Validation Accuracy: 0.9864
Overfitting: 0.0744
[Epoch 19, Batch 100] loss: 0.0025910361817670946
[Epoch 19, Batch 200] loss: 0.007448765902160517
[Epoch 19, Batch 300] loss: 0.004352149364424349
[Epoch 19, Batch 400] loss: 0.00427804302221773
[Epoch 19, Batch 500] loss: 0.001444833364588609
[Epoch 19, Batch 600] loss: 0.007062322505359049
[Epoch 19, Batch 700] loss: 0.0077447414719256265
[Epoch 19, Batch 800] loss: 0.005128550483252284
[Epoch 19, Batch 900] loss: 0.002677907695523771
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0640
Validation Accuracy: 0.9887
Overfitting: 0.0638
[Epoch 20, Batch 100] loss: 0.007670980826038374
[Epoch 20, Batch 200] loss: 0.0033488524618807956
[Epoch 20, Batch 300] loss: 0.005031125647444838
[Epoch 20, Batch 400] loss: 0.011500804362459576
[Epoch 20, Batch 500] loss: 0.010613666045709352
[Epoch 20, Batch 600] loss: 0.01751366624168668
[Epoch 20, Batch 700] loss: 0.0055120004532187745
[Epoch 20, Batch 800] loss: 0.014568048904982334
[Epoch 20, Batch 900] loss: 0.02218201724473033
**STATS for Epoch 20** : 
Average training loss: 0.0009
Average validation loss: 0.0655
Validation Accuracy: 0.9865
Overfitting: 0.0646
[Epoch 21, Batch 100] loss: 0.008617890923392223
[Epoch 21, Batch 200] loss: 0.0032382052235431047
[Epoch 21, Batch 300] loss: 0.009517361786627987
[Epoch 21, Batch 400] loss: 0.01305167982289575
[Epoch 21, Batch 500] loss: 0.005906461539666381
[Epoch 21, Batch 600] loss: 0.012746446505655058
[Epoch 21, Batch 700] loss: 0.0033426783805779793
[Epoch 21, Batch 800] loss: 0.008265439593465089
[Epoch 21, Batch 900] loss: 0.0016339144062308718
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0675
Validation Accuracy: 0.9881
Overfitting: 0.0673
[Epoch 22, Batch 100] loss: 0.004587973014566629
[Epoch 22, Batch 200] loss: 0.001369587215974377
[Epoch 22, Batch 300] loss: 0.0009010322036328944
[Epoch 22, Batch 400] loss: 0.0009959200481299035
[Epoch 22, Batch 500] loss: 0.0017990970117875093
[Epoch 22, Batch 600] loss: 0.0005589748112333081
[Epoch 22, Batch 700] loss: 0.0017803706397549934
[Epoch 22, Batch 800] loss: 0.007766592945684714
[Epoch 22, Batch 900] loss: 0.004358277216711599
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0628
Validation Accuracy: 0.9881
Overfitting: 0.0626
[Epoch 23, Batch 100] loss: 0.003161435077034227
[Epoch 23, Batch 200] loss: 0.001877114542616809
[Epoch 23, Batch 300] loss: 0.0007389093242515976
[Epoch 23, Batch 400] loss: 0.00910987353327755
[Epoch 23, Batch 500] loss: 0.003939351584921837
[Epoch 23, Batch 600] loss: 0.002479803776341214
[Epoch 23, Batch 700] loss: 0.0009152878780381002
[Epoch 23, Batch 800] loss: 0.0017515280544017032
[Epoch 23, Batch 900] loss: 0.0016184165717265842
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0610
Validation Accuracy: 0.9890
Overfitting: 0.0610
[Epoch 24, Batch 100] loss: 0.0021213675065818193
[Epoch 24, Batch 200] loss: 0.0017891213184617527
[Epoch 24, Batch 300] loss: 0.005907438514531975
[Epoch 24, Batch 400] loss: 0.007908438875891512
[Epoch 24, Batch 500] loss: 0.005974168479148929
[Epoch 24, Batch 600] loss: 0.003054556789390066
[Epoch 24, Batch 700] loss: 0.004100253665819196
[Epoch 24, Batch 800] loss: 0.0022792249336839633
[Epoch 24, Batch 900] loss: 0.004552199023484924
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0791
Validation Accuracy: 0.9876
Overfitting: 0.0789
Fold 2 validation loss: 0.0791
Mean validation loss across all folds for Trial 22 is 0.0797 with trial config:  l1: 128, l2: 128, lr: 0.00988782688183443, batch_size: 32
[I 2024-11-21 20:49:58,327] Trial 21 finished with value: 0.07969187300128686 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.00988782688183443, 'batch_size': 32}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 23:
  l1: 128, l2: 64, lr: 0.012949512022530455, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.751666937172413
[Epoch 1, Batch 200] loss: 0.44780445404350755
[Epoch 1, Batch 300] loss: 0.274507646150887
[Epoch 1, Batch 400] loss: 0.18949930330738426
[Epoch 1, Batch 500] loss: 0.15650515554472805
[Epoch 1, Batch 600] loss: 0.16075405789306388
[Epoch 1, Batch 700] loss: 0.14885405476205052
[Epoch 1, Batch 800] loss: 0.13034628307446838
[Epoch 1, Batch 900] loss: 0.12022089307429269
**STATS for Epoch 1** : 
Average training loss: 0.0039
Average validation loss: 0.1348
Validation Accuracy: 0.9597
Overfitting: 0.1309
Best model saved at epoch 1 with validation loss: 0.1348
[Epoch 2, Batch 100] loss: 0.09559837645967491
[Epoch 2, Batch 200] loss: 0.09839830932673067
[Epoch 2, Batch 300] loss: 0.0903630716225598
[Epoch 2, Batch 400] loss: 0.09796432558912783
[Epoch 2, Batch 500] loss: 0.08071224322193302
[Epoch 2, Batch 600] loss: 0.06961303890682757
[Epoch 2, Batch 700] loss: 0.08859458086022641
[Epoch 2, Batch 800] loss: 0.07020295533584431
[Epoch 2, Batch 900] loss: 0.08744834469282069
**STATS for Epoch 2** : 
Average training loss: 0.0034
Average validation loss: 0.0692
Validation Accuracy: 0.9794
Overfitting: 0.0658
Best model saved at epoch 2 with validation loss: 0.0692
[Epoch 3, Batch 100] loss: 0.05127221675706096
[Epoch 3, Batch 200] loss: 0.04574334834353067
[Epoch 3, Batch 300] loss: 0.06395438360283151
[Epoch 3, Batch 400] loss: 0.0680381520302035
[Epoch 3, Batch 500] loss: 0.05071639784000581
[Epoch 3, Batch 600] loss: 0.061397124410723335
[Epoch 3, Batch 700] loss: 0.044068515208782626
[Epoch 3, Batch 800] loss: 0.0575611558984383
[Epoch 3, Batch 900] loss: 0.06059443949023262
**STATS for Epoch 3** : 
Average training loss: 0.0027
Average validation loss: 0.0861
Validation Accuracy: 0.9734
Overfitting: 0.0833
[Epoch 4, Batch 100] loss: 0.04300742692779749
[Epoch 4, Batch 200] loss: 0.04266200247744564
[Epoch 4, Batch 300] loss: 0.04708556910220068
[Epoch 4, Batch 400] loss: 0.04459519131603883
[Epoch 4, Batch 500] loss: 0.0406011980304902
[Epoch 4, Batch 600] loss: 0.04777214914400247
[Epoch 4, Batch 700] loss: 0.048044387921108864
[Epoch 4, Batch 800] loss: 0.04059650554874679
[Epoch 4, Batch 900] loss: 0.04694333210907644
**STATS for Epoch 4** : 
Average training loss: 0.0021
Average validation loss: 0.0658
Validation Accuracy: 0.9814
Overfitting: 0.0637
Best model saved at epoch 4 with validation loss: 0.0658
[Epoch 5, Batch 100] loss: 0.02792331055359682
[Epoch 5, Batch 200] loss: 0.03244394576333434
[Epoch 5, Batch 300] loss: 0.05198438387073111
[Epoch 5, Batch 400] loss: 0.032081411722756456
[Epoch 5, Batch 500] loss: 0.047333338808130065
[Epoch 5, Batch 600] loss: 0.035013261494314066
[Epoch 5, Batch 700] loss: 0.04891896135755815
[Epoch 5, Batch 800] loss: 0.04815162525017513
[Epoch 5, Batch 900] loss: 0.03594983242579474
**STATS for Epoch 5** : 
Average training loss: 0.0018
Average validation loss: 0.0514
Validation Accuracy: 0.9848
Overfitting: 0.0496
Best model saved at epoch 5 with validation loss: 0.0514
[Epoch 6, Batch 100] loss: 0.016932915800280172
[Epoch 6, Batch 200] loss: 0.022215413613230338
[Epoch 6, Batch 300] loss: 0.026458788593881764
[Epoch 6, Batch 400] loss: 0.01994610186695354
[Epoch 6, Batch 500] loss: 0.028580164667364443
[Epoch 6, Batch 600] loss: 0.034116638496416274
[Epoch 6, Batch 700] loss: 0.028210625717456424
[Epoch 6, Batch 800] loss: 0.034160570300227844
[Epoch 6, Batch 900] loss: 0.03149972014323794
**STATS for Epoch 6** : 
Average training loss: 0.0013
Average validation loss: 0.0610
Validation Accuracy: 0.9822
Overfitting: 0.0596
[Epoch 7, Batch 100] loss: 0.015125416766441049
[Epoch 7, Batch 200] loss: 0.01811852898383222
[Epoch 7, Batch 300] loss: 0.0313186143454368
[Epoch 7, Batch 400] loss: 0.030335141419782302
[Epoch 7, Batch 500] loss: 0.030001610473773324
[Epoch 7, Batch 600] loss: 0.02203704845186621
[Epoch 7, Batch 700] loss: 0.023259547836460115
[Epoch 7, Batch 800] loss: 0.02100881570886486
[Epoch 7, Batch 900] loss: 0.04008794463152299
**STATS for Epoch 7** : 
Average training loss: 0.0014
Average validation loss: 0.0834
Validation Accuracy: 0.9782
Overfitting: 0.0820
[Epoch 8, Batch 100] loss: 0.018793216716949245
[Epoch 8, Batch 200] loss: 0.019564800952030056
[Epoch 8, Batch 300] loss: 0.01623150822446405
[Epoch 8, Batch 400] loss: 0.016465970374010794
[Epoch 8, Batch 500] loss: 0.024858551327415625
[Epoch 8, Batch 600] loss: 0.01181001336508416
[Epoch 8, Batch 700] loss: 0.03207561924245965
[Epoch 8, Batch 800] loss: 0.03810392945058993
[Epoch 8, Batch 900] loss: 0.02878937057670555
**STATS for Epoch 8** : 
Average training loss: 0.0004
Average validation loss: 0.0584
Validation Accuracy: 0.9858
Overfitting: 0.0580
[Epoch 9, Batch 100] loss: 0.012212192808510736
[Epoch 9, Batch 200] loss: 0.034336723563610574
[Epoch 9, Batch 300] loss: 0.023593978473745666
[Epoch 9, Batch 400] loss: 0.018291810964074104
[Epoch 9, Batch 500] loss: 0.01134483099109275
[Epoch 9, Batch 600] loss: 0.009990286804418247
[Epoch 9, Batch 700] loss: 0.009580104941392165
[Epoch 9, Batch 800] loss: 0.02371494758685003
[Epoch 9, Batch 900] loss: 0.01931324922978092
**STATS for Epoch 9** : 
Average training loss: 0.0008
Average validation loss: 0.0681
Validation Accuracy: 0.9844
Overfitting: 0.0673
[Epoch 10, Batch 100] loss: 0.0073115723768296444
[Epoch 10, Batch 200] loss: 0.02081954555610537
[Epoch 10, Batch 300] loss: 0.011430424556256185
[Epoch 10, Batch 400] loss: 0.014672744211820828
[Epoch 10, Batch 500] loss: 0.02418806556637719
[Epoch 10, Batch 600] loss: 0.015131868808196032
[Epoch 10, Batch 700] loss: 0.023180188166843436
[Epoch 10, Batch 800] loss: 0.012871713436195477
[Epoch 10, Batch 900] loss: 0.030031011106821097
**STATS for Epoch 10** : 
Average training loss: 0.0009
Average validation loss: 0.0674
Validation Accuracy: 0.9828
Overfitting: 0.0665
[Epoch 11, Batch 100] loss: 0.022076958182424278
[Epoch 11, Batch 200] loss: 0.014728269095612631
[Epoch 11, Batch 300] loss: 0.016222048849786005
[Epoch 11, Batch 400] loss: 0.01065306059370414
[Epoch 11, Batch 500] loss: 0.006761268466466391
[Epoch 11, Batch 600] loss: 0.007460653806315349
[Epoch 11, Batch 700] loss: 0.013784529726390247
[Epoch 11, Batch 800] loss: 0.013380329492742931
[Epoch 11, Batch 900] loss: 0.01615811074033445
**STATS for Epoch 11** : 
Average training loss: 0.0006
Average validation loss: 0.0583
Validation Accuracy: 0.9861
Overfitting: 0.0576
[Epoch 12, Batch 100] loss: 0.011739022761128126
[Epoch 12, Batch 200] loss: 0.016188364194720747
[Epoch 12, Batch 300] loss: 0.014028488828435002
[Epoch 12, Batch 400] loss: 0.011785141545115039
[Epoch 12, Batch 500] loss: 0.020851771729066968
[Epoch 12, Batch 600] loss: 0.016771258370181386
[Epoch 12, Batch 700] loss: 0.0255570610687073
[Epoch 12, Batch 800] loss: 0.01522872779064528
[Epoch 12, Batch 900] loss: 0.01707451740912802
**STATS for Epoch 12** : 
Average training loss: 0.0003
Average validation loss: 0.0676
Validation Accuracy: 0.9844
Overfitting: 0.0673
[Epoch 13, Batch 100] loss: 0.016291993534186987
[Epoch 13, Batch 200] loss: 0.00955174898047062
[Epoch 13, Batch 300] loss: 0.005766339092748467
[Epoch 13, Batch 400] loss: 0.01432746843629502
[Epoch 13, Batch 500] loss: 0.01605325683593037
[Epoch 13, Batch 600] loss: 0.013769930955716632
[Epoch 13, Batch 700] loss: 0.017902210324610337
[Epoch 13, Batch 800] loss: 0.026543073677521532
[Epoch 13, Batch 900] loss: 0.017195004330838516
**STATS for Epoch 13** : 
Average training loss: 0.0004
Average validation loss: 0.0647
Validation Accuracy: 0.9850
Overfitting: 0.0643
[Epoch 14, Batch 100] loss: 0.009686011329540634
[Epoch 14, Batch 200] loss: 0.021194256865101124
[Epoch 14, Batch 300] loss: 0.014584941450875704
[Epoch 14, Batch 400] loss: 0.0109150427913346
[Epoch 14, Batch 500] loss: 0.010930795174881497
[Epoch 14, Batch 600] loss: 0.008784808514596988
[Epoch 14, Batch 700] loss: 0.018479541831093228
[Epoch 14, Batch 800] loss: 0.012047205871422193
[Epoch 14, Batch 900] loss: 0.01376684626919996
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0877
Validation Accuracy: 0.9822
Overfitting: 0.0873
[Epoch 15, Batch 100] loss: 0.01816649867291744
[Epoch 15, Batch 200] loss: 0.013703735160975157
[Epoch 15, Batch 300] loss: 0.019245563351626062
[Epoch 15, Batch 400] loss: 0.034180228675838864
[Epoch 15, Batch 500] loss: 0.012196510900387238
[Epoch 15, Batch 600] loss: 0.013192090099025791
[Epoch 15, Batch 700] loss: 0.009599247614205523
[Epoch 15, Batch 800] loss: 0.004228723226949569
[Epoch 15, Batch 900] loss: 0.014791350265347773
**STATS for Epoch 15** : 
Average training loss: 0.0001
Average validation loss: 0.0622
Validation Accuracy: 0.9870
Overfitting: 0.0621
[Epoch 16, Batch 100] loss: 0.0059612782493530855
[Epoch 16, Batch 200] loss: 0.00555177809309555
[Epoch 16, Batch 300] loss: 0.010940195444591723
[Epoch 16, Batch 400] loss: 0.005894642196142286
[Epoch 16, Batch 500] loss: 0.006487338850106426
[Epoch 16, Batch 600] loss: 0.006034856232954553
[Epoch 16, Batch 700] loss: 0.006397184763231962
[Epoch 16, Batch 800] loss: 0.015518430165697055
[Epoch 16, Batch 900] loss: 0.010341550612856736
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0626
Validation Accuracy: 0.9869
Overfitting: 0.0621
[Epoch 17, Batch 100] loss: 0.003729940158579552
[Epoch 17, Batch 200] loss: 0.0027984584031935356
[Epoch 17, Batch 300] loss: 0.0006469351378912335
[Epoch 17, Batch 400] loss: 0.0024711067225887005
[Epoch 17, Batch 500] loss: 0.006529993855334339
[Epoch 17, Batch 600] loss: 0.006828541955468381
[Epoch 17, Batch 700] loss: 0.009114298715661846
[Epoch 17, Batch 800] loss: 0.006806631750392853
[Epoch 17, Batch 900] loss: 0.0027191658602015423
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0797
Validation Accuracy: 0.9848
Overfitting: 0.0790
[Epoch 18, Batch 100] loss: 0.005512290994429918
[Epoch 18, Batch 200] loss: 0.005086653059695898
[Epoch 18, Batch 300] loss: 0.005150525994194339
[Epoch 18, Batch 400] loss: 0.009038917610629653
[Epoch 18, Batch 500] loss: 0.005470259374966275
[Epoch 18, Batch 600] loss: 0.008020091712978683
[Epoch 18, Batch 700] loss: 0.003514326425011518
[Epoch 18, Batch 800] loss: 0.0029448273347241383
[Epoch 18, Batch 900] loss: 0.012553060245396068
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0918
Validation Accuracy: 0.9847
Overfitting: 0.0917
[Epoch 19, Batch 100] loss: 0.029351864823123606
[Epoch 19, Batch 200] loss: 0.012699516181412492
[Epoch 19, Batch 300] loss: 0.00894745867432448
[Epoch 19, Batch 400] loss: 0.014081433752862154
[Epoch 19, Batch 500] loss: 0.004470651434035347
[Epoch 19, Batch 600] loss: 0.0052174388886419365
[Epoch 19, Batch 700] loss: 0.02740670705099092
[Epoch 19, Batch 800] loss: 0.023150492194522487
[Epoch 19, Batch 900] loss: 0.015983665190763077
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0705
Validation Accuracy: 0.9854
Overfitting: 0.0700
[Epoch 20, Batch 100] loss: 0.005653531404486784
[Epoch 20, Batch 200] loss: 0.0028604675747129706
[Epoch 20, Batch 300] loss: 0.00875271074365628
[Epoch 20, Batch 400] loss: 0.009473636451660923
[Epoch 20, Batch 500] loss: 0.006175748527632265
[Epoch 20, Batch 600] loss: 0.015092915751117176
[Epoch 20, Batch 700] loss: 0.005741816029172639
[Epoch 20, Batch 800] loss: 0.009905997285325725
[Epoch 20, Batch 900] loss: 0.01728255534466243
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0767
Validation Accuracy: 0.9850
Overfitting: 0.0758
[Epoch 21, Batch 100] loss: 0.00707544995344847
[Epoch 21, Batch 200] loss: 0.007527283285177191
[Epoch 21, Batch 300] loss: 0.005987409399273531
[Epoch 21, Batch 400] loss: 0.0034029154503701876
[Epoch 21, Batch 500] loss: 0.007366514313099231
[Epoch 21, Batch 600] loss: 0.011268691465742293
[Epoch 21, Batch 700] loss: 0.004503620695437575
[Epoch 21, Batch 800] loss: 0.004242772731865046
[Epoch 21, Batch 900] loss: 0.0050155227400223625
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0730
Validation Accuracy: 0.9855
Overfitting: 0.0727
[Epoch 22, Batch 100] loss: 0.005405942981818441
[Epoch 22, Batch 200] loss: 0.0051639701289762745
[Epoch 22, Batch 300] loss: 0.009443234078315115
[Epoch 22, Batch 400] loss: 0.003738528419989109
[Epoch 22, Batch 500] loss: 0.00395601832130879
[Epoch 22, Batch 600] loss: 0.005861962750090299
[Epoch 22, Batch 700] loss: 0.0014067790000773072
[Epoch 22, Batch 800] loss: 0.004872613835735571
[Epoch 22, Batch 900] loss: 0.0021263509036133056
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0819
Validation Accuracy: 0.9861
Overfitting: 0.0818
[Epoch 23, Batch 100] loss: 0.001503605271164552
[Epoch 23, Batch 200] loss: 0.008870071802384114
[Epoch 23, Batch 300] loss: 0.005219122487000334
[Epoch 23, Batch 400] loss: 0.004169047400854744
[Epoch 23, Batch 500] loss: 0.005715049845238696
[Epoch 23, Batch 600] loss: 0.0032771449312139554
[Epoch 23, Batch 700] loss: 0.0036245567603248197
[Epoch 23, Batch 800] loss: 0.00932114670296726
[Epoch 23, Batch 900] loss: 0.009750470226506991
**STATS for Epoch 23** : 
Average training loss: 0.0014
Average validation loss: 0.0768
Validation Accuracy: 0.9856
Overfitting: 0.0754
[Epoch 24, Batch 100] loss: 0.023501442327108178
[Epoch 24, Batch 200] loss: 0.01564042496303614
[Epoch 24, Batch 300] loss: 0.003502494064844086
[Epoch 24, Batch 400] loss: 0.003759834459819018
[Epoch 24, Batch 500] loss: 0.004361745858897024
[Epoch 24, Batch 600] loss: 0.005211130312036687
[Epoch 24, Batch 700] loss: 0.004185533079154986
[Epoch 24, Batch 800] loss: 0.011234755626536667
[Epoch 24, Batch 900] loss: 0.01632084962459544
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.1075
Validation Accuracy: 0.9821
Overfitting: 0.1072
Fold 1 validation loss: 0.1075
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.384048147201538
[Epoch 1, Batch 200] loss: 0.32799108393490317
[Epoch 1, Batch 300] loss: 0.22224328830838203
[Epoch 1, Batch 400] loss: 0.19592346902936697
[Epoch 1, Batch 500] loss: 0.14021612264215946
[Epoch 1, Batch 600] loss: 0.13017674419563263
[Epoch 1, Batch 700] loss: 0.10927867267280816
[Epoch 1, Batch 800] loss: 0.11399895773967728
[Epoch 1, Batch 900] loss: 0.09916848222841508
**STATS for Epoch 1** : 
Average training loss: 0.0033
Average validation loss: 0.0961
Validation Accuracy: 0.9709
Overfitting: 0.0928
Best model saved at epoch 1 with validation loss: 0.0961
[Epoch 2, Batch 100] loss: 0.08510864645475522
[Epoch 2, Batch 200] loss: 0.09161365778243635
[Epoch 2, Batch 300] loss: 0.07969895414891653
[Epoch 2, Batch 400] loss: 0.08537590989028104
[Epoch 2, Batch 500] loss: 0.0957863466301933
[Epoch 2, Batch 600] loss: 0.07562328367028386
[Epoch 2, Batch 700] loss: 0.048613021081546325
[Epoch 2, Batch 800] loss: 0.07502792667248287
[Epoch 2, Batch 900] loss: 0.0785029202059377
**STATS for Epoch 2** : 
Average training loss: 0.0033
Average validation loss: 0.0698
Validation Accuracy: 0.9792
Overfitting: 0.0665
Best model saved at epoch 2 with validation loss: 0.0698
[Epoch 3, Batch 100] loss: 0.06795244644512423
[Epoch 3, Batch 200] loss: 0.06018689970747801
[Epoch 3, Batch 300] loss: 0.0514444565505255
[Epoch 3, Batch 400] loss: 0.06806566571467557
[Epoch 3, Batch 500] loss: 0.04709655590471812
[Epoch 3, Batch 600] loss: 0.053262326929543635
[Epoch 3, Batch 700] loss: 0.06124625671072863
[Epoch 3, Batch 800] loss: 0.04740871006419184
[Epoch 3, Batch 900] loss: 0.060226671354612335
**STATS for Epoch 3** : 
Average training loss: 0.0019
Average validation loss: 0.0598
Validation Accuracy: 0.9816
Overfitting: 0.0579
Best model saved at epoch 3 with validation loss: 0.0598
[Epoch 4, Batch 100] loss: 0.03333343835358391
[Epoch 4, Batch 200] loss: 0.03949037485494045
[Epoch 4, Batch 300] loss: 0.047328037614788626
[Epoch 4, Batch 400] loss: 0.047722551247352384
[Epoch 4, Batch 500] loss: 0.04907986345671816
[Epoch 4, Batch 600] loss: 0.04098284616949968
[Epoch 4, Batch 700] loss: 0.03484378866367479
[Epoch 4, Batch 800] loss: 0.05174833290817332
[Epoch 4, Batch 900] loss: 0.058877699583827055
**STATS for Epoch 4** : 
Average training loss: 0.0016
Average validation loss: 0.0609
Validation Accuracy: 0.9826
Overfitting: 0.0593
[Epoch 5, Batch 100] loss: 0.03344315171096241
[Epoch 5, Batch 200] loss: 0.03703869823650166
[Epoch 5, Batch 300] loss: 0.030716411404573592
[Epoch 5, Batch 400] loss: 0.03832322803278657
[Epoch 5, Batch 500] loss: 0.03369477529980941
[Epoch 5, Batch 600] loss: 0.026835992607084337
[Epoch 5, Batch 700] loss: 0.031232379228749777
[Epoch 5, Batch 800] loss: 0.04334566747522331
[Epoch 5, Batch 900] loss: 0.0352441947394982
**STATS for Epoch 5** : 
Average training loss: 0.0019
Average validation loss: 0.0631
Validation Accuracy: 0.9830
Overfitting: 0.0612
[Epoch 6, Batch 100] loss: 0.029007062054151902
[Epoch 6, Batch 200] loss: 0.023788880925276316
[Epoch 6, Batch 300] loss: 0.025789249566369108
[Epoch 6, Batch 400] loss: 0.01874151484033064
[Epoch 6, Batch 500] loss: 0.02876215471105752
[Epoch 6, Batch 600] loss: 0.05037240327335894
[Epoch 6, Batch 700] loss: 0.03500839163951241
[Epoch 6, Batch 800] loss: 0.0301885696838508
[Epoch 6, Batch 900] loss: 0.029041235913464334
**STATS for Epoch 6** : 
Average training loss: 0.0012
Average validation loss: 0.0667
Validation Accuracy: 0.9812
Overfitting: 0.0656
[Epoch 7, Batch 100] loss: 0.017972820300892634
[Epoch 7, Batch 200] loss: 0.016120195600897204
[Epoch 7, Batch 300] loss: 0.01957704903845297
[Epoch 7, Batch 400] loss: 0.03959040027563901
[Epoch 7, Batch 500] loss: 0.027863170918335525
[Epoch 7, Batch 600] loss: 0.023124613452819177
[Epoch 7, Batch 700] loss: 0.03447917126002722
[Epoch 7, Batch 800] loss: 0.018873831930995948
[Epoch 7, Batch 900] loss: 0.025155961808441134
**STATS for Epoch 7** : 
Average training loss: 0.0010
Average validation loss: 0.0594
Validation Accuracy: 0.9854
Overfitting: 0.0584
Best model saved at epoch 7 with validation loss: 0.0594
[Epoch 8, Batch 100] loss: 0.026779353402562264
[Epoch 8, Batch 200] loss: 0.02451049079430959
[Epoch 8, Batch 300] loss: 0.025415652580049936
[Epoch 8, Batch 400] loss: 0.021550827459268476
[Epoch 8, Batch 500] loss: 0.015762007992580037
[Epoch 8, Batch 600] loss: 0.023818214559796616
[Epoch 8, Batch 700] loss: 0.021218650073024037
[Epoch 8, Batch 800] loss: 0.026478878996240383
[Epoch 8, Batch 900] loss: 0.0299968728555541
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0827
Validation Accuracy: 0.9778
Overfitting: 0.0808
[Epoch 9, Batch 100] loss: 0.02490479490836151
[Epoch 9, Batch 200] loss: 0.01870063913247577
[Epoch 9, Batch 300] loss: 0.016301227442436356
[Epoch 9, Batch 400] loss: 0.017745921801642906
[Epoch 9, Batch 500] loss: 0.01521945068151581
[Epoch 9, Batch 600] loss: 0.02209860378053236
[Epoch 9, Batch 700] loss: 0.016681131689119867
[Epoch 9, Batch 800] loss: 0.019136304188941723
[Epoch 9, Batch 900] loss: 0.021351735485359312
**STATS for Epoch 9** : 
Average training loss: 0.0017
Average validation loss: 0.0664
Validation Accuracy: 0.9834
Overfitting: 0.0647
[Epoch 10, Batch 100] loss: 0.00959184542291041
[Epoch 10, Batch 200] loss: 0.018006314573858616
[Epoch 10, Batch 300] loss: 0.01894040498027607
[Epoch 10, Batch 400] loss: 0.01375103739228507
[Epoch 10, Batch 500] loss: 0.011169520117055071
[Epoch 10, Batch 600] loss: 0.018355546194063665
[Epoch 10, Batch 700] loss: 0.013040429004308862
[Epoch 10, Batch 800] loss: 0.009421109838590382
[Epoch 10, Batch 900] loss: 0.00774327700683898
**STATS for Epoch 10** : 
Average training loss: 0.0011
Average validation loss: 0.0826
Validation Accuracy: 0.9824
Overfitting: 0.0815
[Epoch 11, Batch 100] loss: 0.022931492974930735
[Epoch 11, Batch 200] loss: 0.01686314908627537
[Epoch 11, Batch 300] loss: 0.007042458924959191
[Epoch 11, Batch 400] loss: 0.014212852110658787
[Epoch 11, Batch 500] loss: 0.007961989133048065
[Epoch 11, Batch 600] loss: 0.016854831322493737
[Epoch 11, Batch 700] loss: 0.013738958067669955
[Epoch 11, Batch 800] loss: 0.019169112659128587
[Epoch 11, Batch 900] loss: 0.01601683505406072
**STATS for Epoch 11** : 
Average training loss: 0.0010
Average validation loss: 0.0714
Validation Accuracy: 0.9828
Overfitting: 0.0704
[Epoch 12, Batch 100] loss: 0.013356909677631847
[Epoch 12, Batch 200] loss: 0.015761284307313873
[Epoch 12, Batch 300] loss: 0.012970796389345196
[Epoch 12, Batch 400] loss: 0.013576776115230586
[Epoch 12, Batch 500] loss: 0.028068817491939627
[Epoch 12, Batch 600] loss: 0.009983202569692366
[Epoch 12, Batch 700] loss: 0.006826978452120329
[Epoch 12, Batch 800] loss: 0.014513612033256322
[Epoch 12, Batch 900] loss: 0.011402267532953375
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0651
Validation Accuracy: 0.9850
Overfitting: 0.0643
[Epoch 13, Batch 100] loss: 0.01080836614490181
[Epoch 13, Batch 200] loss: 0.00812635762765467
[Epoch 13, Batch 300] loss: 0.010923256258092807
[Epoch 13, Batch 400] loss: 0.017197644697205305
[Epoch 13, Batch 500] loss: 0.007160111334997055
[Epoch 13, Batch 600] loss: 0.017834559288116905
[Epoch 13, Batch 700] loss: 0.019368722783693785
[Epoch 13, Batch 800] loss: 0.023172910218099786
[Epoch 13, Batch 900] loss: 0.016991142958647742
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0799
Validation Accuracy: 0.9829
Overfitting: 0.0793
[Epoch 14, Batch 100] loss: 0.010369073084901856
[Epoch 14, Batch 200] loss: 0.01864951276676038
[Epoch 14, Batch 300] loss: 0.008965620794533606
[Epoch 14, Batch 400] loss: 0.01886347163654136
[Epoch 14, Batch 500] loss: 0.013721950845820174
[Epoch 14, Batch 600] loss: 0.00957204311204805
[Epoch 14, Batch 700] loss: 0.007507113329088497
[Epoch 14, Batch 800] loss: 0.008314759638411716
[Epoch 14, Batch 900] loss: 0.012637419921138076
**STATS for Epoch 14** : 
Average training loss: 0.0013
Average validation loss: 0.0766
Validation Accuracy: 0.9843
Overfitting: 0.0753
[Epoch 15, Batch 100] loss: 0.011185192732107226
[Epoch 15, Batch 200] loss: 0.01044482865661422
[Epoch 15, Batch 300] loss: 0.0022887188936363146
[Epoch 15, Batch 400] loss: 0.01064185551943183
[Epoch 15, Batch 500] loss: 0.023149732112149195
[Epoch 15, Batch 600] loss: 0.004672805571601657
[Epoch 15, Batch 700] loss: 0.01052988953855106
[Epoch 15, Batch 800] loss: 0.012400620140247155
[Epoch 15, Batch 900] loss: 0.0208242889807093
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0893
Validation Accuracy: 0.9815
Overfitting: 0.0885
[Epoch 16, Batch 100] loss: 0.018393748193307146
[Epoch 16, Batch 200] loss: 0.006626748569269694
[Epoch 16, Batch 300] loss: 0.0036405312350984787
[Epoch 16, Batch 400] loss: 0.009419389739958883
[Epoch 16, Batch 500] loss: 0.022290675833971818
[Epoch 16, Batch 600] loss: 0.00834806344554636
[Epoch 16, Batch 700] loss: 0.007057693112997186
[Epoch 16, Batch 800] loss: 0.009514572951853779
[Epoch 16, Batch 900] loss: 0.017542280814232356
**STATS for Epoch 16** : 
Average training loss: 0.0013
Average validation loss: 0.0892
Validation Accuracy: 0.9819
Overfitting: 0.0878
[Epoch 17, Batch 100] loss: 0.016615259371733374
[Epoch 17, Batch 200] loss: 0.015495208034799361
[Epoch 17, Batch 300] loss: 0.00555032516516576
[Epoch 17, Batch 400] loss: 0.004423652407398322
[Epoch 17, Batch 500] loss: 0.014235941718724235
[Epoch 17, Batch 600] loss: 0.016943404235933032
[Epoch 17, Batch 700] loss: 0.015053347678117461
[Epoch 17, Batch 800] loss: 0.025184807574314617
[Epoch 17, Batch 900] loss: 0.007193373422956029
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0674
Validation Accuracy: 0.9855
Overfitting: 0.0668
[Epoch 18, Batch 100] loss: 0.007291701674688511
[Epoch 18, Batch 200] loss: 0.006566288181240907
[Epoch 18, Batch 300] loss: 0.00477273943067189
[Epoch 18, Batch 400] loss: 0.005314678007675582
[Epoch 18, Batch 500] loss: 0.004922224122016133
[Epoch 18, Batch 600] loss: 0.006113548991445867
[Epoch 18, Batch 700] loss: 0.005033732010395511
[Epoch 18, Batch 800] loss: 0.008344223171925479
[Epoch 18, Batch 900] loss: 0.018775260954549823
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0855
Validation Accuracy: 0.9839
Overfitting: 0.0847
[Epoch 19, Batch 100] loss: 0.014321407537504455
[Epoch 19, Batch 200] loss: 0.005400966780737235
[Epoch 19, Batch 300] loss: 0.020101523954053846
[Epoch 19, Batch 400] loss: 0.01992031323799438
[Epoch 19, Batch 500] loss: 0.011214107074868024
[Epoch 19, Batch 600] loss: 0.01179857553979673
[Epoch 19, Batch 700] loss: 0.007722976356619711
[Epoch 19, Batch 800] loss: 0.01156790579136441
[Epoch 19, Batch 900] loss: 0.007491295770633428
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0715
Validation Accuracy: 0.9861
Overfitting: 0.0709
[Epoch 20, Batch 100] loss: 0.00216838713470338
[Epoch 20, Batch 200] loss: 0.00554941987980051
[Epoch 20, Batch 300] loss: 0.012010505062776743
[Epoch 20, Batch 400] loss: 0.004661494775434676
[Epoch 20, Batch 500] loss: 0.005360634608102259
[Epoch 20, Batch 600] loss: 0.0035737372230101984
[Epoch 20, Batch 700] loss: 0.012838255773472156
[Epoch 20, Batch 800] loss: 0.0060424290660455425
[Epoch 20, Batch 900] loss: 0.004526654525754452
**STATS for Epoch 20** : 
Average training loss: 0.0008
Average validation loss: 0.0751
Validation Accuracy: 0.9859
Overfitting: 0.0743
[Epoch 21, Batch 100] loss: 0.0058363101470513355
[Epoch 21, Batch 200] loss: 0.005448419042343424
[Epoch 21, Batch 300] loss: 0.003336378031982008
[Epoch 21, Batch 400] loss: 0.0032272815064499126
[Epoch 21, Batch 500] loss: 0.0035391883407896786
[Epoch 21, Batch 600] loss: 0.003224038641626734
[Epoch 21, Batch 700] loss: 0.004159632170882617
[Epoch 21, Batch 800] loss: 0.0009477946073620558
[Epoch 21, Batch 900] loss: 0.0026989744968327046
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0970
Validation Accuracy: 0.9849
Overfitting: 0.0969
[Epoch 22, Batch 100] loss: 0.008012500460419575
[Epoch 22, Batch 200] loss: 0.007017404695991161
[Epoch 22, Batch 300] loss: 0.006236028113026464
[Epoch 22, Batch 400] loss: 0.001997588484099424
[Epoch 22, Batch 500] loss: 0.010155463825883402
[Epoch 22, Batch 600] loss: 0.007332446515381861
[Epoch 22, Batch 700] loss: 0.009259818321405931
[Epoch 22, Batch 800] loss: 0.008554411436009275
[Epoch 22, Batch 900] loss: 0.006809149653026907
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0746
Validation Accuracy: 0.9861
Overfitting: 0.0745
[Epoch 23, Batch 100] loss: 0.006472257238043539
[Epoch 23, Batch 200] loss: 0.0013602520621500958
[Epoch 23, Batch 300] loss: 0.007404420628131021
[Epoch 23, Batch 400] loss: 0.017820564072039816
[Epoch 23, Batch 500] loss: 0.010665137730904065
[Epoch 23, Batch 600] loss: 0.009041614019760119
[Epoch 23, Batch 700] loss: 0.003367233191636387
[Epoch 23, Batch 800] loss: 0.002700815546930926
[Epoch 23, Batch 900] loss: 0.005615075887584453
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0682
Validation Accuracy: 0.9874
Overfitting: 0.0681
[Epoch 24, Batch 100] loss: 0.0012846870264394284
[Epoch 24, Batch 200] loss: 0.00473168554670739
[Epoch 24, Batch 300] loss: 0.008567880210768309
[Epoch 24, Batch 400] loss: 0.014801228400717611
[Epoch 24, Batch 500] loss: 0.015436461805384454
[Epoch 24, Batch 600] loss: 0.01566335752743754
[Epoch 24, Batch 700] loss: 0.029033214200769635
[Epoch 24, Batch 800] loss: 0.01720268216064767
[Epoch 24, Batch 900] loss: 0.00870576394146191
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0880
Validation Accuracy: 0.9837
Overfitting: 0.0877
Fold 2 validation loss: 0.0880
Mean validation loss across all folds for Trial 23 is 0.0978 with trial config:  l1: 128, l2: 64, lr: 0.012949512022530455, batch_size: 32
[I 2024-11-21 20:59:43,264] Trial 22 finished with value: 0.09777157216019408 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.012949512022530455, 'batch_size': 32}. Best is trial 2 with value: 0.06275290202573758.

Selected Hyperparameters for Trial 24:
  l1: 256, l2: 128, lr: 0.0037749843539924962, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2343502223491667
[Epoch 1, Batch 200] loss: 1.000448732972145
[Epoch 1, Batch 300] loss: 0.41626805685460566
[Epoch 1, Batch 400] loss: 0.30058691434562207
[Epoch 1, Batch 500] loss: 0.24777455657720565
[Epoch 1, Batch 600] loss: 0.21007282696664334
[Epoch 1, Batch 700] loss: 0.1599429732374847
[Epoch 1, Batch 800] loss: 0.15932008255273103
[Epoch 1, Batch 900] loss: 0.1247197070531547
**STATS for Epoch 1** : 
Average training loss: 0.0064
Average validation loss: 0.1286
Validation Accuracy: 0.9604
Overfitting: 0.1222
Best model saved at epoch 1 with validation loss: 0.1286
[Epoch 2, Batch 100] loss: 0.10963085466995835
[Epoch 2, Batch 200] loss: 0.0942214045720175
[Epoch 2, Batch 300] loss: 0.11346276708878576
[Epoch 2, Batch 400] loss: 0.107503716875799
[Epoch 2, Batch 500] loss: 0.08848530773073435
[Epoch 2, Batch 600] loss: 0.10231934409588575
[Epoch 2, Batch 700] loss: 0.08894506082404405
[Epoch 2, Batch 800] loss: 0.08918277549091727
[Epoch 2, Batch 900] loss: 0.0701617205934599
**STATS for Epoch 2** : 
Average training loss: 0.0036
Average validation loss: 0.0796
Validation Accuracy: 0.9755
Overfitting: 0.0760
Best model saved at epoch 2 with validation loss: 0.0796
[Epoch 3, Batch 100] loss: 0.07176992963883094
[Epoch 3, Batch 200] loss: 0.06990686474833638
[Epoch 3, Batch 300] loss: 0.07267553886864335
[Epoch 3, Batch 400] loss: 0.061296247566351665
[Epoch 3, Batch 500] loss: 0.06613617281778715
[Epoch 3, Batch 600] loss: 0.05960163139039651
[Epoch 3, Batch 700] loss: 0.06944721390260383
[Epoch 3, Batch 800] loss: 0.07248028466361575
[Epoch 3, Batch 900] loss: 0.06576756766822654
**STATS for Epoch 3** : 
Average training loss: 0.0027
Average validation loss: 0.0705
Validation Accuracy: 0.9770
Overfitting: 0.0678
Best model saved at epoch 3 with validation loss: 0.0705
[Epoch 4, Batch 100] loss: 0.05246716134482995
[Epoch 4, Batch 200] loss: 0.04652417238568887
[Epoch 4, Batch 300] loss: 0.04069464985455852
[Epoch 4, Batch 400] loss: 0.04744730891019572
[Epoch 4, Batch 500] loss: 0.06250857237260789
[Epoch 4, Batch 600] loss: 0.0395609540422447
[Epoch 4, Batch 700] loss: 0.04883262261166237
[Epoch 4, Batch 800] loss: 0.05521396987955086
[Epoch 4, Batch 900] loss: 0.056677958448417484
**STATS for Epoch 4** : 
Average training loss: 0.0020
Average validation loss: 0.0640
Validation Accuracy: 0.9802
Overfitting: 0.0620
Best model saved at epoch 4 with validation loss: 0.0640
[Epoch 5, Batch 100] loss: 0.04601054616738111
[Epoch 5, Batch 200] loss: 0.028599161739111877
[Epoch 5, Batch 300] loss: 0.03789846822794061
[Epoch 5, Batch 400] loss: 0.04757229560666019
[Epoch 5, Batch 500] loss: 0.036511895235162226
[Epoch 5, Batch 600] loss: 0.03765089690947207
[Epoch 5, Batch 700] loss: 0.03293574534938671
[Epoch 5, Batch 800] loss: 0.03861572856665589
[Epoch 5, Batch 900] loss: 0.03493005332187749
**STATS for Epoch 5** : 
Average training loss: 0.0017
Average validation loss: 0.0590
Validation Accuracy: 0.9826
Overfitting: 0.0573
Best model saved at epoch 5 with validation loss: 0.0590
[Epoch 6, Batch 100] loss: 0.03174171149701579
[Epoch 6, Batch 200] loss: 0.036686924078530865
[Epoch 6, Batch 300] loss: 0.0347411420676508
[Epoch 6, Batch 400] loss: 0.03286527099990053
[Epoch 6, Batch 500] loss: 0.033421063598943875
[Epoch 6, Batch 600] loss: 0.033195109449734445
[Epoch 6, Batch 700] loss: 0.03473214794998057
[Epoch 6, Batch 800] loss: 0.02313678846214316
[Epoch 6, Batch 900] loss: 0.02611213273834437
**STATS for Epoch 6** : 
Average training loss: 0.0010
Average validation loss: 0.0601
Validation Accuracy: 0.9822
Overfitting: 0.0590
[Epoch 7, Batch 100] loss: 0.016247954877326266
[Epoch 7, Batch 200] loss: 0.02757343005607254
[Epoch 7, Batch 300] loss: 0.029952446327370125
[Epoch 7, Batch 400] loss: 0.02063783209050598
[Epoch 7, Batch 500] loss: 0.028213957809202838
[Epoch 7, Batch 600] loss: 0.026550375604856527
[Epoch 7, Batch 700] loss: 0.031233540748362428
[Epoch 7, Batch 800] loss: 0.025974103624612326
[Epoch 7, Batch 900] loss: 0.02263551084382925
**STATS for Epoch 7** : 
Average training loss: 0.0004
Average validation loss: 0.0551
Validation Accuracy: 0.9843
Overfitting: 0.0547
Best model saved at epoch 7 with validation loss: 0.0551
[Epoch 8, Batch 100] loss: 0.015972764231992186
[Epoch 8, Batch 200] loss: 0.023038704851351212
[Epoch 8, Batch 300] loss: 0.026571225928055355
[Epoch 8, Batch 400] loss: 0.024213441961619536
[Epoch 8, Batch 500] loss: 0.014522909453953617
[Epoch 8, Batch 600] loss: 0.014338520392557256
[Epoch 8, Batch 700] loss: 0.025476512845925753
[Epoch 8, Batch 800] loss: 0.012898770959000104
[Epoch 8, Batch 900] loss: 0.03534716986730928
**STATS for Epoch 8** : 
Average training loss: 0.0013
Average validation loss: 0.0554
Validation Accuracy: 0.9835
Overfitting: 0.0541
[Epoch 9, Batch 100] loss: 0.010495196005122125
[Epoch 9, Batch 200] loss: 0.014738377311223303
[Epoch 9, Batch 300] loss: 0.01237610789561586
[Epoch 9, Batch 400] loss: 0.017658407587987313
[Epoch 9, Batch 500] loss: 0.01935459475578682
[Epoch 9, Batch 600] loss: 0.014976649424625066
[Epoch 9, Batch 700] loss: 0.02263528431445593
[Epoch 9, Batch 800] loss: 0.019676126050762834
[Epoch 9, Batch 900] loss: 0.019424556629310245
**STATS for Epoch 9** : 
Average training loss: 0.0008
Average validation loss: 0.0597
Validation Accuracy: 0.9838
Overfitting: 0.0589
[Epoch 10, Batch 100] loss: 0.012234892454889632
[Epoch 10, Batch 200] loss: 0.005649362673466385
[Epoch 10, Batch 300] loss: 0.014549014806291324
[Epoch 10, Batch 400] loss: 0.014357952271238901
[Epoch 10, Batch 500] loss: 0.007218749616049536
[Epoch 10, Batch 600] loss: 0.015915819461624778
[Epoch 10, Batch 700] loss: 0.008521465684170835
[Epoch 10, Batch 800] loss: 0.019874135820000447
[Epoch 10, Batch 900] loss: 0.014819311315391133
**STATS for Epoch 10** : 
Average training loss: 0.0005
Average validation loss: 0.0590
Validation Accuracy: 0.9850
Overfitting: 0.0585
[Epoch 11, Batch 100] loss: 0.009124926729346044
[Epoch 11, Batch 200] loss: 0.00814869448196987
[Epoch 11, Batch 300] loss: 0.009018346339184974
[Epoch 11, Batch 400] loss: 0.008704051435697692
[Epoch 11, Batch 500] loss: 0.0131627348148686
[Epoch 11, Batch 600] loss: 0.005611081193965219
[Epoch 11, Batch 700] loss: 0.013132401004913846
[Epoch 11, Batch 800] loss: 0.012786551380850142
[Epoch 11, Batch 900] loss: 0.013317888140954892
**STATS for Epoch 11** : 
Average training loss: 0.0004
Average validation loss: 0.0673
Validation Accuracy: 0.9819
Overfitting: 0.0669
[Epoch 12, Batch 100] loss: 0.011018164821034588
[Epoch 12, Batch 200] loss: 0.007216569756074023
[Epoch 12, Batch 300] loss: 0.004979216174979229
[Epoch 12, Batch 400] loss: 0.006245485701601865
[Epoch 12, Batch 500] loss: 0.010026772997707666
[Epoch 12, Batch 600] loss: 0.006283619700716372
[Epoch 12, Batch 700] loss: 0.009612517448103972
[Epoch 12, Batch 800] loss: 0.007248351016278321
[Epoch 12, Batch 900] loss: 0.006553166868634434
**STATS for Epoch 12** : 
Average training loss: 0.0003
Average validation loss: 0.0589
Validation Accuracy: 0.9860
Overfitting: 0.0586
[Epoch 13, Batch 100] loss: 0.005973930955278774
[Epoch 13, Batch 200] loss: 0.003283426111074732
[Epoch 13, Batch 300] loss: 0.009444399681469803
[Epoch 13, Batch 400] loss: 0.008758015653111215
[Epoch 13, Batch 500] loss: 0.009374098223906913
[Epoch 13, Batch 600] loss: 0.01423261848556649
[Epoch 13, Batch 700] loss: 0.003735415374369495
[Epoch 13, Batch 800] loss: 0.010776984200588232
[Epoch 13, Batch 900] loss: 0.01675119103570978
**STATS for Epoch 13** : 
Average training loss: 0.0003
Average validation loss: 0.0627
Validation Accuracy: 0.9854
Overfitting: 0.0623
[Epoch 14, Batch 100] loss: 0.004745558501308551
[Epoch 14, Batch 200] loss: 0.0027349669464092584
[Epoch 14, Batch 300] loss: 0.0046317337161417525
[Epoch 14, Batch 400] loss: 0.003666231596480429
[Epoch 14, Batch 500] loss: 0.004972745969912467
[Epoch 14, Batch 600] loss: 0.006028781131676624
[Epoch 14, Batch 700] loss: 0.01605835522256484
[Epoch 14, Batch 800] loss: 0.0060444361563804705
[Epoch 14, Batch 900] loss: 0.0047131608214203875
**STATS for Epoch 14** : 
Average training loss: 0.0002
Average validation loss: 0.0738
Validation Accuracy: 0.9837
Overfitting: 0.0736
[Epoch 15, Batch 100] loss: 0.0054512027475095695
[Epoch 15, Batch 200] loss: 0.0038197931646641336
[Epoch 15, Batch 300] loss: 0.002049610481783475
[Epoch 15, Batch 400] loss: 0.004814639885889847
[Epoch 15, Batch 500] loss: 0.0029476769792199774
[Epoch 15, Batch 600] loss: 0.0031598444494454724
[Epoch 15, Batch 700] loss: 0.010280843994755741
[Epoch 15, Batch 800] loss: 0.006163741030336496
[Epoch 15, Batch 900] loss: 0.008858777834268495
**STATS for Epoch 15** : 
Average training loss: 0.0002
Average validation loss: 0.0613
Validation Accuracy: 0.9865
Overfitting: 0.0611
[Epoch 16, Batch 100] loss: 0.003145473544816468
[Epoch 16, Batch 200] loss: 0.003322052572442544
[Epoch 16, Batch 300] loss: 0.001773049028913647
[Epoch 16, Batch 400] loss: 0.001048429521173375
[Epoch 16, Batch 500] loss: 0.004729695140414378
[Epoch 16, Batch 600] loss: 0.003018074584961141
[Epoch 16, Batch 700] loss: 0.0032172238228395144
[Epoch 16, Batch 800] loss: 0.002868734941198454
[Epoch 16, Batch 900] loss: 0.004324328283973955
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0633
Validation Accuracy: 0.9858
Overfitting: 0.0632
[Epoch 17, Batch 100] loss: 0.001732490373881319
[Epoch 17, Batch 200] loss: 0.0030447205476706075
[Epoch 17, Batch 300] loss: 0.0017482815458225787
[Epoch 17, Batch 400] loss: 0.0008555805586297538
[Epoch 17, Batch 500] loss: 0.0031396142829362363
[Epoch 17, Batch 600] loss: 0.002431407126141494
[Epoch 17, Batch 700] loss: 0.001078662530613883
[Epoch 17, Batch 800] loss: 0.000844999789026133
[Epoch 17, Batch 900] loss: 0.0008406095546763481
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9869
Overfitting: 0.0634
[Epoch 18, Batch 100] loss: 0.0024123613644621857
[Epoch 18, Batch 200] loss: 0.0009827595237152308
[Epoch 18, Batch 300] loss: 0.00048068199428257685
[Epoch 18, Batch 400] loss: 0.000362785270486512
[Epoch 18, Batch 500] loss: 0.000603691843426759
[Epoch 18, Batch 600] loss: 0.00038942308093737666
[Epoch 18, Batch 700] loss: 0.0005401807983076879
[Epoch 18, Batch 800] loss: 0.0018261286274926646
[Epoch 18, Batch 900] loss: 0.0037245844416815997
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0615
Validation Accuracy: 0.9874
Overfitting: 0.0614
[Epoch 19, Batch 100] loss: 0.0010191166542824702
[Epoch 19, Batch 200] loss: 0.0011232073531505194
[Epoch 19, Batch 300] loss: 0.0008836227982146739
[Epoch 19, Batch 400] loss: 0.00026024293073533043
[Epoch 19, Batch 500] loss: 0.00024083733441102595
[Epoch 19, Batch 600] loss: 0.0010816532485468143
[Epoch 19, Batch 700] loss: 0.0026336941809742597
[Epoch 19, Batch 800] loss: 0.0002534652237483215
[Epoch 19, Batch 900] loss: 0.0002717420437329565
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0650
Validation Accuracy: 0.9870
Overfitting: 0.0649
[Epoch 20, Batch 100] loss: 0.0012581696683633937
[Epoch 20, Batch 200] loss: 0.00048183456089049057
[Epoch 20, Batch 300] loss: 0.0004977885515631896
[Epoch 20, Batch 400] loss: 0.00029187198575932884
[Epoch 20, Batch 500] loss: 0.00028491792498641644
[Epoch 20, Batch 600] loss: 0.0002707803218635263
[Epoch 20, Batch 700] loss: 0.0004361589640805619
[Epoch 20, Batch 800] loss: 0.0005657932264489319
[Epoch 20, Batch 900] loss: 0.003879403031085289
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0625
Validation Accuracy: 0.9870
Overfitting: 0.0625
[Epoch 21, Batch 100] loss: 0.0004807232327092947
[Epoch 21, Batch 200] loss: 0.0005393005631219693
[Epoch 21, Batch 300] loss: 0.0002617309996065842
[Epoch 21, Batch 400] loss: 0.0002999799503359668
[Epoch 21, Batch 500] loss: 0.0003178504046434227
[Epoch 21, Batch 600] loss: 0.00026051096546012784
[Epoch 21, Batch 700] loss: 0.0008694070752210337
[Epoch 21, Batch 800] loss: 0.0015113045520160995
[Epoch 21, Batch 900] loss: 0.0008259910839126405
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0662
Validation Accuracy: 0.9869
Overfitting: 0.0661
[Epoch 22, Batch 100] loss: 0.0003691036655465041
[Epoch 22, Batch 200] loss: 0.0002312919343215114
[Epoch 22, Batch 300] loss: 0.0005959206417587382
[Epoch 22, Batch 400] loss: 0.000341641595171609
[Epoch 22, Batch 500] loss: 0.00013512084667098633
[Epoch 22, Batch 600] loss: 0.0003640913257896727
[Epoch 22, Batch 700] loss: 0.00019348597139043022
[Epoch 22, Batch 800] loss: 0.00023527933617856434
[Epoch 22, Batch 900] loss: 0.0002013151611990338
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0652
Validation Accuracy: 0.9877
Overfitting: 0.0652
[Epoch 23, Batch 100] loss: 0.00013189384989544805
[Epoch 23, Batch 200] loss: 0.0002462716466352788
[Epoch 23, Batch 300] loss: 0.00013332187831974096
[Epoch 23, Batch 400] loss: 0.00015040480365598795
[Epoch 23, Batch 500] loss: 0.00011779734419747002
[Epoch 23, Batch 600] loss: 0.00026300291110629813
[Epoch 23, Batch 700] loss: 0.00012234678631532604
[Epoch 23, Batch 800] loss: 0.00019200472073702457
[Epoch 23, Batch 900] loss: 0.00011274155932937902
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0662
Validation Accuracy: 0.9877
Overfitting: 0.0662
[Epoch 24, Batch 100] loss: 0.00011558661966871497
[Epoch 24, Batch 200] loss: 0.00011344305137608757
[Epoch 24, Batch 300] loss: 0.00012378004881465898
[Epoch 24, Batch 400] loss: 0.00010788556937313843
[Epoch 24, Batch 500] loss: 9.410543453398645e-05
[Epoch 24, Batch 600] loss: 0.00011968874330548828
[Epoch 24, Batch 700] loss: 0.00016060430108829848
[Epoch 24, Batch 800] loss: 0.00016308530715640756
[Epoch 24, Batch 900] loss: 0.00020900404845640707
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0677
Validation Accuracy: 0.9876
Overfitting: 0.0677
Fold 1 validation loss: 0.0677
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.249774830341339
[Epoch 1, Batch 200] loss: 0.9430361431837082
[Epoch 1, Batch 300] loss: 0.362655680552125
[Epoch 1, Batch 400] loss: 0.25967555832117795
[Epoch 1, Batch 500] loss: 0.22701368562877178
[Epoch 1, Batch 600] loss: 0.18157706373371185
[Epoch 1, Batch 700] loss: 0.18735245095565914
[Epoch 1, Batch 800] loss: 0.1645774078834802
[Epoch 1, Batch 900] loss: 0.1314761469978839
**STATS for Epoch 1** : 
Average training loss: 0.0063
Average validation loss: 0.1360
Validation Accuracy: 0.9591
Overfitting: 0.1297
Best model saved at epoch 1 with validation loss: 0.1360
[Epoch 2, Batch 100] loss: 0.123870391077362
[Epoch 2, Batch 200] loss: 0.10638945779763162
[Epoch 2, Batch 300] loss: 0.11021198047325015
[Epoch 2, Batch 400] loss: 0.09851294248364866
[Epoch 2, Batch 500] loss: 0.10554075547493995
[Epoch 2, Batch 600] loss: 0.09729874692857265
[Epoch 2, Batch 700] loss: 0.07328669725451618
[Epoch 2, Batch 800] loss: 0.07971561508253217
[Epoch 2, Batch 900] loss: 0.08796985913999379
**STATS for Epoch 2** : 
Average training loss: 0.0043
Average validation loss: 0.0896
Validation Accuracy: 0.9728
Overfitting: 0.0853
Best model saved at epoch 2 with validation loss: 0.0896
[Epoch 3, Batch 100] loss: 0.07079636226873845
[Epoch 3, Batch 200] loss: 0.06829736565239727
[Epoch 3, Batch 300] loss: 0.06309774041175842
[Epoch 3, Batch 400] loss: 0.06757650750689209
[Epoch 3, Batch 500] loss: 0.07028587262262591
[Epoch 3, Batch 600] loss: 0.07266530045075342
[Epoch 3, Batch 700] loss: 0.06438591676997021
[Epoch 3, Batch 800] loss: 0.06733107910724356
[Epoch 3, Batch 900] loss: 0.061662825553212314
**STATS for Epoch 3** : 
Average training loss: 0.0026
Average validation loss: 0.0726
Validation Accuracy: 0.9770
Overfitting: 0.0700
Best model saved at epoch 3 with validation loss: 0.0726
[Epoch 4, Batch 100] loss: 0.04076007669733372
[Epoch 4, Batch 200] loss: 0.041565769179724155
[Epoch 4, Batch 300] loss: 0.055130462988745424
[Epoch 4, Batch 400] loss: 0.05703324597561732
[Epoch 4, Batch 500] loss: 0.04573345721233636
[Epoch 4, Batch 600] loss: 0.05045469250762835
[Epoch 4, Batch 700] loss: 0.04968320543819573
[Epoch 4, Batch 800] loss: 0.05269101266050711
[Epoch 4, Batch 900] loss: 0.04426001443178393
**STATS for Epoch 4** : 
Average training loss: 0.0014
Average validation loss: 0.0645
Validation Accuracy: 0.9795
Overfitting: 0.0630
Best model saved at epoch 4 with validation loss: 0.0645
[Epoch 5, Batch 100] loss: 0.04072185429511592
[Epoch 5, Batch 200] loss: 0.030457499328185804
[Epoch 5, Batch 300] loss: 0.046687193067045885
[Epoch 5, Batch 400] loss: 0.030575687273521907
[Epoch 5, Batch 500] loss: 0.03071970786433667
[Epoch 5, Batch 600] loss: 0.04159609571157489
[Epoch 5, Batch 700] loss: 0.0445118773804279
[Epoch 5, Batch 800] loss: 0.051471583214588466
[Epoch 5, Batch 900] loss: 0.05236254697199911
**STATS for Epoch 5** : 
Average training loss: 0.0011
Average validation loss: 0.0612
Validation Accuracy: 0.9813
Overfitting: 0.0601
Best model saved at epoch 5 with validation loss: 0.0612
[Epoch 6, Batch 100] loss: 0.024871351185429377
[Epoch 6, Batch 200] loss: 0.037848905020800884
[Epoch 6, Batch 300] loss: 0.03217312025954015
[Epoch 6, Batch 400] loss: 0.032079180578293745
[Epoch 6, Batch 500] loss: 0.03594908742990811
[Epoch 6, Batch 600] loss: 0.03042805591569049
[Epoch 6, Batch 700] loss: 0.03722313844395103
[Epoch 6, Batch 800] loss: 0.027316067102801753
[Epoch 6, Batch 900] loss: 0.044467403068847486
**STATS for Epoch 6** : 
Average training loss: 0.0017
Average validation loss: 0.0598
Validation Accuracy: 0.9818
Overfitting: 0.0582
Best model saved at epoch 6 with validation loss: 0.0598
[Epoch 7, Batch 100] loss: 0.023347594453953208
[Epoch 7, Batch 200] loss: 0.029806342128431425
[Epoch 7, Batch 300] loss: 0.02985695385475992
[Epoch 7, Batch 400] loss: 0.021042245906137395
[Epoch 7, Batch 500] loss: 0.015982582010183252
[Epoch 7, Batch 600] loss: 0.02955707014014479
[Epoch 7, Batch 700] loss: 0.023756997893215157
[Epoch 7, Batch 800] loss: 0.03419990839596721
[Epoch 7, Batch 900] loss: 0.027420013988557913
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0704
Validation Accuracy: 0.9794
Overfitting: 0.0685
[Epoch 8, Batch 100] loss: 0.026113702000002376
[Epoch 8, Batch 200] loss: 0.01488728984433692
[Epoch 8, Batch 300] loss: 0.022169871270743897
[Epoch 8, Batch 400] loss: 0.0212820381167694
[Epoch 8, Batch 500] loss: 0.017627257874482893
[Epoch 8, Batch 600] loss: 0.028836712096381233
[Epoch 8, Batch 700] loss: 0.022841548272117505
[Epoch 8, Batch 800] loss: 0.026105041182599962
[Epoch 8, Batch 900] loss: 0.023532543494948186
**STATS for Epoch 8** : 
Average training loss: 0.0010
Average validation loss: 0.0498
Validation Accuracy: 0.9854
Overfitting: 0.0488
Best model saved at epoch 8 with validation loss: 0.0498
[Epoch 9, Batch 100] loss: 0.017816481590853073
[Epoch 9, Batch 200] loss: 0.023535532981477446
[Epoch 9, Batch 300] loss: 0.014964997588394908
[Epoch 9, Batch 400] loss: 0.013679394288628828
[Epoch 9, Batch 500] loss: 0.015436282740702155
[Epoch 9, Batch 600] loss: 0.01988792276213644
[Epoch 9, Batch 700] loss: 0.015887417795020155
[Epoch 9, Batch 800] loss: 0.026467143753980054
[Epoch 9, Batch 900] loss: 0.015086524018333875
**STATS for Epoch 9** : 
Average training loss: 0.0011
Average validation loss: 0.0584
Validation Accuracy: 0.9838
Overfitting: 0.0572
[Epoch 10, Batch 100] loss: 0.017213703569868812
[Epoch 10, Batch 200] loss: 0.01779004185431404
[Epoch 10, Batch 300] loss: 0.010905565508292057
[Epoch 10, Batch 400] loss: 0.014113046561942611
[Epoch 10, Batch 500] loss: 0.014499108515519766
[Epoch 10, Batch 600] loss: 0.017664587186736753
[Epoch 10, Batch 700] loss: 0.018169835340740972
[Epoch 10, Batch 800] loss: 0.02580799999224837
[Epoch 10, Batch 900] loss: 0.021537028293823823
**STATS for Epoch 10** : 
Average training loss: 0.0006
Average validation loss: 0.0551
Validation Accuracy: 0.9848
Overfitting: 0.0544
[Epoch 11, Batch 100] loss: 0.013590221893391572
[Epoch 11, Batch 200] loss: 0.015387878719739092
[Epoch 11, Batch 300] loss: 0.01549613930430496
[Epoch 11, Batch 400] loss: 0.010007518410129706
[Epoch 11, Batch 500] loss: 0.011693849889288685
[Epoch 11, Batch 600] loss: 0.013217941301918472
[Epoch 11, Batch 700] loss: 0.02260728960223787
[Epoch 11, Batch 800] loss: 0.01290551289486757
[Epoch 11, Batch 900] loss: 0.00972034711834567
**STATS for Epoch 11** : 
Average training loss: 0.0005
Average validation loss: 0.0568
Validation Accuracy: 0.9846
Overfitting: 0.0563
[Epoch 12, Batch 100] loss: 0.007627215522843471
[Epoch 12, Batch 200] loss: 0.005044130241294624
[Epoch 12, Batch 300] loss: 0.01037091917862199
[Epoch 12, Batch 400] loss: 0.011083092933386069
[Epoch 12, Batch 500] loss: 0.019670091648367815
[Epoch 12, Batch 600] loss: 0.01361233424358943
[Epoch 12, Batch 700] loss: 0.013901372040509159
[Epoch 12, Batch 800] loss: 0.007986819325024043
[Epoch 12, Batch 900] loss: 0.01809967069191771
**STATS for Epoch 12** : 
Average training loss: 0.0007
Average validation loss: 0.0605
Validation Accuracy: 0.9839
Overfitting: 0.0598
[Epoch 13, Batch 100] loss: 0.006431233594776131
[Epoch 13, Batch 200] loss: 0.006529957541570184
[Epoch 13, Batch 300] loss: 0.006978547805333619
[Epoch 13, Batch 400] loss: 0.011921221252487157
[Epoch 13, Batch 500] loss: 0.010768602125663164
[Epoch 13, Batch 600] loss: 0.012270631130813853
[Epoch 13, Batch 700] loss: 0.014279529062750953
[Epoch 13, Batch 800] loss: 0.006814866359509324
[Epoch 13, Batch 900] loss: 0.010630441571047413
**STATS for Epoch 13** : 
Average training loss: 0.0001
Average validation loss: 0.0528
Validation Accuracy: 0.9870
Overfitting: 0.0527
[Epoch 14, Batch 100] loss: 0.007528191602632433
[Epoch 14, Batch 200] loss: 0.005343536479085742
[Epoch 14, Batch 300] loss: 0.007961366717252076
[Epoch 14, Batch 400] loss: 0.011057898739800294
[Epoch 14, Batch 500] loss: 0.008240789070332539
[Epoch 14, Batch 600] loss: 0.0062174577473479075
[Epoch 14, Batch 700] loss: 0.005742051780816837
[Epoch 14, Batch 800] loss: 0.009424858406127896
[Epoch 14, Batch 900] loss: 0.01025246763612813
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0578
Validation Accuracy: 0.9859
Overfitting: 0.0569
[Epoch 15, Batch 100] loss: 0.012337497488842927
[Epoch 15, Batch 200] loss: 0.006534165298908192
[Epoch 15, Batch 300] loss: 0.007063330125338325
[Epoch 15, Batch 400] loss: 0.004163343617938154
[Epoch 15, Batch 500] loss: 0.011742159161676681
[Epoch 15, Batch 600] loss: 0.0051228844941670106
[Epoch 15, Batch 700] loss: 0.011471893759908197
[Epoch 15, Batch 800] loss: 0.00482394420872879
[Epoch 15, Batch 900] loss: 0.009537933088568025
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0717
Validation Accuracy: 0.9826
Overfitting: 0.0710
[Epoch 16, Batch 100] loss: 0.0056500350306487234
[Epoch 16, Batch 200] loss: 0.006756533161305925
[Epoch 16, Batch 300] loss: 0.012008827638419461
[Epoch 16, Batch 400] loss: 0.009782149665143151
[Epoch 16, Batch 500] loss: 0.004954633056036073
[Epoch 16, Batch 600] loss: 0.008595203516292713
[Epoch 16, Batch 700] loss: 0.005221348499314899
[Epoch 16, Batch 800] loss: 0.005281050614328251
[Epoch 16, Batch 900] loss: 0.006683003012976769
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0563
Validation Accuracy: 0.9868
Overfitting: 0.0559
[Epoch 17, Batch 100] loss: 0.002564656257914066
[Epoch 17, Batch 200] loss: 0.002471924871142619
[Epoch 17, Batch 300] loss: 0.002121698410830959
[Epoch 17, Batch 400] loss: 0.005226598124968404
[Epoch 17, Batch 500] loss: 0.0018677459049285972
[Epoch 17, Batch 600] loss: 0.0041731749619975745
[Epoch 17, Batch 700] loss: 0.011863868922982874
[Epoch 17, Batch 800] loss: 0.0020542312264569774
[Epoch 17, Batch 900] loss: 0.0036768634396185007
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0551
Validation Accuracy: 0.9874
Overfitting: 0.0550
[Epoch 18, Batch 100] loss: 0.003704461759851938
[Epoch 18, Batch 200] loss: 0.002396559772823821
[Epoch 18, Batch 300] loss: 0.0031572091423771554
[Epoch 18, Batch 400] loss: 0.006001538430610936
[Epoch 18, Batch 500] loss: 0.0020161010456786243
[Epoch 18, Batch 600] loss: 0.001479921576083143
[Epoch 18, Batch 700] loss: 0.006744416062369965
[Epoch 18, Batch 800] loss: 0.00397475358965039
[Epoch 18, Batch 900] loss: 0.001289293714185078
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0778
Validation Accuracy: 0.9826
Overfitting: 0.0771
[Epoch 19, Batch 100] loss: 0.0035171927152606486
[Epoch 19, Batch 200] loss: 0.0077824484069037685
[Epoch 19, Batch 300] loss: 0.004455854108957737
[Epoch 19, Batch 400] loss: 0.0021008032971371903
[Epoch 19, Batch 500] loss: 0.0028579513683979485
[Epoch 19, Batch 600] loss: 0.001415304429445996
[Epoch 19, Batch 700] loss: 0.003442616931358771
[Epoch 19, Batch 800] loss: 0.005570699495339113
[Epoch 19, Batch 900] loss: 0.008406193902089854
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0677
Validation Accuracy: 0.9850
Overfitting: 0.0674
[Epoch 20, Batch 100] loss: 0.005282068065516796
[Epoch 20, Batch 200] loss: 0.0020095161256222125
[Epoch 20, Batch 300] loss: 0.0017781713288940182
[Epoch 20, Batch 400] loss: 0.0040181363850092565
[Epoch 20, Batch 500] loss: 0.0022658067986094464
[Epoch 20, Batch 600] loss: 0.0034823834151654865
[Epoch 20, Batch 700] loss: 0.0020119658556257036
[Epoch 20, Batch 800] loss: 0.002375881792955852
[Epoch 20, Batch 900] loss: 0.00273500214935666
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0669
Validation Accuracy: 0.9858
Overfitting: 0.0668
[Epoch 21, Batch 100] loss: 0.001234411749684341
[Epoch 21, Batch 200] loss: 0.0010356377467900303
[Epoch 21, Batch 300] loss: 0.0005819904066447634
[Epoch 21, Batch 400] loss: 0.0026818540569840364
[Epoch 21, Batch 500] loss: 0.007078295650126165
[Epoch 21, Batch 600] loss: 0.002739467036724932
[Epoch 21, Batch 700] loss: 0.005840876533336541
[Epoch 21, Batch 800] loss: 0.01628834325232219
[Epoch 21, Batch 900] loss: 0.0037848844363088576
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0597
Validation Accuracy: 0.9870
Overfitting: 0.0597
[Epoch 22, Batch 100] loss: 0.0038512310716123464
[Epoch 22, Batch 200] loss: 0.001831233119422322
[Epoch 22, Batch 300] loss: 0.0020807506079307814
[Epoch 22, Batch 400] loss: 0.0049235132996147965
[Epoch 22, Batch 500] loss: 0.001786777963284294
[Epoch 22, Batch 600] loss: 0.0008074590907915535
[Epoch 22, Batch 700] loss: 0.0009373435101548466
[Epoch 22, Batch 800] loss: 0.005917284382670687
[Epoch 22, Batch 900] loss: 0.002687612139609996
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0685
Validation Accuracy: 0.9856
Overfitting: 0.0682
[Epoch 23, Batch 100] loss: 0.004009019497282225
[Epoch 23, Batch 200] loss: 0.001634236471602435
[Epoch 23, Batch 300] loss: 0.0015709680453358033
[Epoch 23, Batch 400] loss: 0.001464257113850067
[Epoch 23, Batch 500] loss: 0.0020807202065714135
[Epoch 23, Batch 600] loss: 0.003661211568232261
[Epoch 23, Batch 700] loss: 0.004661091782840572
[Epoch 23, Batch 800] loss: 0.002817329936167141
[Epoch 23, Batch 900] loss: 0.0010824386114677508
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0601
Validation Accuracy: 0.9878
Overfitting: 0.0601
[Epoch 24, Batch 100] loss: 0.002045202605504244
[Epoch 24, Batch 200] loss: 0.000982607664010402
[Epoch 24, Batch 300] loss: 0.0008150788987916258
[Epoch 24, Batch 400] loss: 0.0005754508139978043
[Epoch 24, Batch 500] loss: 0.0007191663553305716
[Epoch 24, Batch 600] loss: 0.002667156602300338
[Epoch 24, Batch 700] loss: 0.00031762171453181054
[Epoch 24, Batch 800] loss: 0.00037269212827084174
[Epoch 24, Batch 900] loss: 0.0012044535463627427
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0607
Validation Accuracy: 0.9880
Overfitting: 0.0606
Fold 2 validation loss: 0.0607
Mean validation loss across all folds for Trial 24 is 0.0642 with trial config:  l1: 256, l2: 128, lr: 0.0037749843539924962, batch_size: 32
[I 2024-11-21 21:09:25,629] Trial 23 finished with value: 0.0641929983081479 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0037749843539924962, 'batch_size': 32}. Best is trial 2 with value: 0.06275290202573758.
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  2
  Number of complete trials:  22
Best hyperparameters found:
{'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16}
Best trial:
  Value:  0.06275290202573758
Loaded best model checkpoint from: best_checkpoint_trial_2/model.pth
Using best hyperparameters {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 2.2885967445373536
[Epoch 1, Batch 200] loss: 2.2353462290763857
[Epoch 1, Batch 300] loss: 2.077161351442337
[Epoch 1, Batch 400] loss: 1.4462253594398498
[Epoch 1, Batch 500] loss: 0.8097771167755127
[Epoch 1, Batch 600] loss: 0.5978917707502842
[Epoch 1, Batch 700] loss: 0.5911267752945423
[Epoch 1, Batch 800] loss: 0.46917602598667146
[Epoch 1, Batch 900] loss: 0.51007622808218
[Epoch 1, Batch 1000] loss: 0.43332763746380804
[Epoch 1, Batch 1100] loss: 0.4374465376138687
[Epoch 1, Batch 1200] loss: 0.4086189466714859
[Epoch 1, Batch 1300] loss: 0.33375962279737
[Epoch 1, Batch 1400] loss: 0.31920183781534434
[Epoch 1, Batch 1500] loss: 0.2954607453942299
[Epoch 1, Batch 1600] loss: 0.3259832235239446
[Epoch 1, Batch 1700] loss: 0.2815393256954849
[Epoch 1, Batch 1800] loss: 0.25795058619230987
[Epoch 1, Batch 1900] loss: 0.2762428801506758
[Epoch 1, Batch 2000] loss: 0.24681495860219002
[Epoch 1, Batch 2100] loss: 0.26573623782023786
[Epoch 1, Batch 2200] loss: 0.24362784104421734
[Epoch 1, Batch 2300] loss: 0.22974554618820547
[Epoch 1, Batch 2400] loss: 0.2028535865712911
[Epoch 1, Batch 2500] loss: 0.22117712675593793
[Epoch 1, Batch 2600] loss: 0.2227254589088261
[Epoch 1, Batch 2700] loss: 0.19660574978217482
[Epoch 1, Batch 2800] loss: 0.20602836648002268
[Epoch 1, Batch 2900] loss: 0.1884704081248492
[Epoch 1, Batch 3000] loss: 0.15786808302626013
[Epoch 1, Batch 3100] loss: 0.17347281300462783
[Epoch 1, Batch 3200] loss: 0.16370224946178497
[Epoch 1, Batch 3300] loss: 0.16091351341456175
[Epoch 1, Batch 3400] loss: 0.16619783053174614
[Epoch 1, Batch 3500] loss: 0.15538656840100884
[Epoch 1, Batch 3600] loss: 0.13549152760766447
[Epoch 1, Batch 3700] loss: 0.14348260327242315
**STATS for Epoch 1** : 
Average training loss: 0.0023
Best model saved at epoch 1 with training loss: 0.0023
[Epoch 2, Batch 100] loss: 0.15115605832543225
[Epoch 2, Batch 200] loss: 0.1316188003588468
[Epoch 2, Batch 300] loss: 0.13474001702386887
[Epoch 2, Batch 400] loss: 0.13214641460683196
[Epoch 2, Batch 500] loss: 0.13668828377733008
[Epoch 2, Batch 600] loss: 0.14785352599807083
[Epoch 2, Batch 700] loss: 0.1415826888475567
[Epoch 2, Batch 800] loss: 0.11517037832876667
[Epoch 2, Batch 900] loss: 0.11762842453084886
[Epoch 2, Batch 1000] loss: 0.1073118663020432
[Epoch 2, Batch 1100] loss: 0.10910055291373283
[Epoch 2, Batch 1200] loss: 0.10630009602638893
[Epoch 2, Batch 1300] loss: 0.10347346608527004
[Epoch 2, Batch 1400] loss: 0.10055292540928348
[Epoch 2, Batch 1500] loss: 0.1247105062380433
[Epoch 2, Batch 1600] loss: 0.11895644747186453
[Epoch 2, Batch 1700] loss: 0.09804933081148193
[Epoch 2, Batch 1800] loss: 0.11571577435359359
[Epoch 2, Batch 1900] loss: 0.10668063636519946
[Epoch 2, Batch 2000] loss: 0.10932732141111046
[Epoch 2, Batch 2100] loss: 0.10080114194657654
[Epoch 2, Batch 2200] loss: 0.11239206745987758
[Epoch 2, Batch 2300] loss: 0.09309241653769278
[Epoch 2, Batch 2400] loss: 0.08791941336588933
[Epoch 2, Batch 2500] loss: 0.10123261199332774
[Epoch 2, Batch 2600] loss: 0.09798118395265192
[Epoch 2, Batch 2700] loss: 0.09693229470402003
[Epoch 2, Batch 2800] loss: 0.09680599085520952
[Epoch 2, Batch 2900] loss: 0.09629402772989124
[Epoch 2, Batch 3000] loss: 0.07631519105576444
[Epoch 2, Batch 3100] loss: 0.07223192740697414
[Epoch 2, Batch 3200] loss: 0.10442316017753911
[Epoch 2, Batch 3300] loss: 0.0976172622118611
[Epoch 2, Batch 3400] loss: 0.11767962664365768
[Epoch 2, Batch 3500] loss: 0.0977588886092417
[Epoch 2, Batch 3600] loss: 0.11306750315241515
[Epoch 2, Batch 3700] loss: 0.09395711880642921
**STATS for Epoch 2** : 
Average training loss: 0.0012
Best model saved at epoch 2 with training loss: 0.0012
[Epoch 3, Batch 100] loss: 0.08122588062658906
[Epoch 3, Batch 200] loss: 0.08831986626260914
[Epoch 3, Batch 300] loss: 0.08635960496845656
[Epoch 3, Batch 400] loss: 0.08062150737503543
[Epoch 3, Batch 500] loss: 0.08806629189988598
[Epoch 3, Batch 600] loss: 0.08143130335723982
[Epoch 3, Batch 700] loss: 0.08024798645288683
[Epoch 3, Batch 800] loss: 0.08517505034804344
[Epoch 3, Batch 900] loss: 0.08209386938251555
[Epoch 3, Batch 1000] loss: 0.08727287002839149
[Epoch 3, Batch 1100] loss: 0.09205884087597951
[Epoch 3, Batch 1200] loss: 0.07676761562586762
[Epoch 3, Batch 1300] loss: 0.06860015632584691
[Epoch 3, Batch 1400] loss: 0.08859414173988625
[Epoch 3, Batch 1500] loss: 0.09528280959930271
[Epoch 3, Batch 1600] loss: 0.07611746928771027
[Epoch 3, Batch 1700] loss: 0.08890402125485707
[Epoch 3, Batch 1800] loss: 0.0719761541445041
[Epoch 3, Batch 1900] loss: 0.0806632432108745
[Epoch 3, Batch 2000] loss: 0.08479802889283747
[Epoch 3, Batch 2100] loss: 0.08644635572913102
[Epoch 3, Batch 2200] loss: 0.06268561052973382
[Epoch 3, Batch 2300] loss: 0.07387818310293369
[Epoch 3, Batch 2400] loss: 0.06033422152046114
[Epoch 3, Batch 2500] loss: 0.06302983755478636
[Epoch 3, Batch 2600] loss: 0.0804372470418457
[Epoch 3, Batch 2700] loss: 0.07959977658465504
[Epoch 3, Batch 2800] loss: 0.06679318905924447
[Epoch 3, Batch 2900] loss: 0.0859140923130326
[Epoch 3, Batch 3000] loss: 0.06481696196482517
[Epoch 3, Batch 3100] loss: 0.06690774091519415
[Epoch 3, Batch 3200] loss: 0.05899921736796387
[Epoch 3, Batch 3300] loss: 0.046053869404131545
[Epoch 3, Batch 3400] loss: 0.07094820574799086
[Epoch 3, Batch 3500] loss: 0.07672253336786525
[Epoch 3, Batch 3600] loss: 0.056465354358660985
[Epoch 3, Batch 3700] loss: 0.05278697315399768
**STATS for Epoch 3** : 
Average training loss: 0.0008
Best model saved at epoch 3 with training loss: 0.0008
[Epoch 4, Batch 100] loss: 0.053614297864260155
[Epoch 4, Batch 200] loss: 0.07007511110045016
[Epoch 4, Batch 300] loss: 0.05376051063823979
[Epoch 4, Batch 400] loss: 0.058041671448736454
[Epoch 4, Batch 500] loss: 0.06429154522018507
[Epoch 4, Batch 600] loss: 0.06453896194754634
[Epoch 4, Batch 700] loss: 0.057727664494887
[Epoch 4, Batch 800] loss: 0.0732308793469565
[Epoch 4, Batch 900] loss: 0.061111519253172444
[Epoch 4, Batch 1000] loss: 0.05492372910841368
[Epoch 4, Batch 1100] loss: 0.06322155876317993
[Epoch 4, Batch 1200] loss: 0.05211761732498417
[Epoch 4, Batch 1300] loss: 0.06561806069366867
[Epoch 4, Batch 1400] loss: 0.0523314852398471
[Epoch 4, Batch 1500] loss: 0.06201565722818486
[Epoch 4, Batch 1600] loss: 0.057988783696200696
[Epoch 4, Batch 1700] loss: 0.057517731341067704
[Epoch 4, Batch 1800] loss: 0.07582608885713853
[Epoch 4, Batch 1900] loss: 0.045904654430341904
[Epoch 4, Batch 2000] loss: 0.06754437258350662
[Epoch 4, Batch 2100] loss: 0.06011596857802942
[Epoch 4, Batch 2200] loss: 0.06579734070401173
[Epoch 4, Batch 2300] loss: 0.0686138109921012
[Epoch 4, Batch 2400] loss: 0.047721099478076213
[Epoch 4, Batch 2500] loss: 0.05414558760530781
[Epoch 4, Batch 2600] loss: 0.07002148568746634
[Epoch 4, Batch 2700] loss: 0.05395010046951938
[Epoch 4, Batch 2800] loss: 0.04626824497710914
[Epoch 4, Batch 2900] loss: 0.04295356525864918
[Epoch 4, Batch 3000] loss: 0.06932394929754082
[Epoch 4, Batch 3100] loss: 0.04836822033452336
[Epoch 4, Batch 3200] loss: 0.05468247163982596
[Epoch 4, Batch 3300] loss: 0.05820130972249899
[Epoch 4, Batch 3400] loss: 0.05523575800296385
[Epoch 4, Batch 3500] loss: 0.05000378040771466
[Epoch 4, Batch 3600] loss: 0.09169297814019955
[Epoch 4, Batch 3700] loss: 0.05338962809211807
**STATS for Epoch 4** : 
Average training loss: 0.0006
Best model saved at epoch 4 with training loss: 0.0006
[Epoch 5, Batch 100] loss: 0.06534496363368816
[Epoch 5, Batch 200] loss: 0.044518930594204
[Epoch 5, Batch 300] loss: 0.0567556831141701
[Epoch 5, Batch 400] loss: 0.06090550160195562
[Epoch 5, Batch 500] loss: 0.04510655024147127
[Epoch 5, Batch 600] loss: 0.049346495969803075
[Epoch 5, Batch 700] loss: 0.05116548534628237
[Epoch 5, Batch 800] loss: 0.0475635908334516
[Epoch 5, Batch 900] loss: 0.03474487453961046
[Epoch 5, Batch 1000] loss: 0.03297340888078906
[Epoch 5, Batch 1100] loss: 0.04714768689824268
[Epoch 5, Batch 1200] loss: 0.06987073536380194
[Epoch 5, Batch 1300] loss: 0.05704035633883905
[Epoch 5, Batch 1400] loss: 0.0317072658406687
[Epoch 5, Batch 1500] loss: 0.051347078412072734
[Epoch 5, Batch 1600] loss: 0.04725901803176384
[Epoch 5, Batch 1700] loss: 0.05749181846360443
[Epoch 5, Batch 1800] loss: 0.034799929760047234
[Epoch 5, Batch 1900] loss: 0.04057087858513114
[Epoch 5, Batch 2000] loss: 0.036188368498405905
[Epoch 5, Batch 2100] loss: 0.0705870535352733
[Epoch 5, Batch 2200] loss: 0.025975420605100226
[Epoch 5, Batch 2300] loss: 0.05347497167706024
[Epoch 5, Batch 2400] loss: 0.05179419052961748
[Epoch 5, Batch 2500] loss: 0.06452240172075108
[Epoch 5, Batch 2600] loss: 0.04383139929792378
[Epoch 5, Batch 2700] loss: 0.06106225393654313
[Epoch 5, Batch 2800] loss: 0.055575735301245
[Epoch 5, Batch 2900] loss: 0.061177918071043676
[Epoch 5, Batch 3000] loss: 0.03918560239399085
[Epoch 5, Batch 3100] loss: 0.05614300051471219
[Epoch 5, Batch 3200] loss: 0.047772131749079565
[Epoch 5, Batch 3300] loss: 0.038792842400434895
[Epoch 5, Batch 3400] loss: 0.05116843824536772
[Epoch 5, Batch 3500] loss: 0.03668794885830721
[Epoch 5, Batch 3600] loss: 0.045178818622371185
[Epoch 5, Batch 3700] loss: 0.05399875604634872
**STATS for Epoch 5** : 
Average training loss: 0.0007
[Epoch 6, Batch 100] loss: 0.05525493333931081
[Epoch 6, Batch 200] loss: 0.04318184687872417
[Epoch 6, Batch 300] loss: 0.049895482131978496
[Epoch 6, Batch 400] loss: 0.033774556098505853
[Epoch 6, Batch 500] loss: 0.04056821618607501
[Epoch 6, Batch 600] loss: 0.02835951149900211
[Epoch 6, Batch 700] loss: 0.05101158579273033
[Epoch 6, Batch 800] loss: 0.03499583145450742
[Epoch 6, Batch 900] loss: 0.058603361641580705
[Epoch 6, Batch 1000] loss: 0.0441652690427145
[Epoch 6, Batch 1100] loss: 0.03869761785084847
[Epoch 6, Batch 1200] loss: 0.04069877975940472
[Epoch 6, Batch 1300] loss: 0.042633424933155764
[Epoch 6, Batch 1400] loss: 0.04750365196843632
[Epoch 6, Batch 1500] loss: 0.0473781862614851
[Epoch 6, Batch 1600] loss: 0.030798707295616623
[Epoch 6, Batch 1700] loss: 0.038308417835942236
[Epoch 6, Batch 1800] loss: 0.049586344790295694
[Epoch 6, Batch 1900] loss: 0.05892902391016833
[Epoch 6, Batch 2000] loss: 0.0362301804026356
[Epoch 6, Batch 2100] loss: 0.056086351314734204
[Epoch 6, Batch 2200] loss: 0.04986450170312309
[Epoch 6, Batch 2300] loss: 0.03312658610404469
[Epoch 6, Batch 2400] loss: 0.041778210077027325
[Epoch 6, Batch 2500] loss: 0.039980511784378905
[Epoch 6, Batch 2600] loss: 0.04388769857716397
[Epoch 6, Batch 2700] loss: 0.05039543502323795
[Epoch 6, Batch 2800] loss: 0.038571828813874165
[Epoch 6, Batch 2900] loss: 0.04770506296132226
[Epoch 6, Batch 3000] loss: 0.03623350149486214
[Epoch 6, Batch 3100] loss: 0.049040656323777514
[Epoch 6, Batch 3200] loss: 0.02623123706871411
[Epoch 6, Batch 3300] loss: 0.04188623071211623
[Epoch 6, Batch 3400] loss: 0.027000413639761973
[Epoch 6, Batch 3500] loss: 0.05064579387122649
[Epoch 6, Batch 3600] loss: 0.034602725704171465
[Epoch 6, Batch 3700] loss: 0.03712129662235384
**STATS for Epoch 6** : 
Average training loss: 0.0003
Best model saved at epoch 6 with training loss: 0.0003
[Epoch 7, Batch 100] loss: 0.03319109463598579
[Epoch 7, Batch 200] loss: 0.024686214656976516
[Epoch 7, Batch 300] loss: 0.03787320620976971
[Epoch 7, Batch 400] loss: 0.03343398093769792
[Epoch 7, Batch 500] loss: 0.04757011243345914
[Epoch 7, Batch 600] loss: 0.03312985179189127
[Epoch 7, Batch 700] loss: 0.03458042078797007
[Epoch 7, Batch 800] loss: 0.04084802697005216
[Epoch 7, Batch 900] loss: 0.03217433728335891
[Epoch 7, Batch 1000] loss: 0.030675398511375532
[Epoch 7, Batch 1100] loss: 0.039231098154268694
[Epoch 7, Batch 1200] loss: 0.0293944277180708
[Epoch 7, Batch 1300] loss: 0.03125357196229743
[Epoch 7, Batch 1400] loss: 0.0359373259570566
[Epoch 7, Batch 1500] loss: 0.026886150916107
[Epoch 7, Batch 1600] loss: 0.042192027875425996
[Epoch 7, Batch 1700] loss: 0.03496980721873115
[Epoch 7, Batch 1800] loss: 0.033179305845769703
[Epoch 7, Batch 1900] loss: 0.031400449813809246
[Epoch 7, Batch 2000] loss: 0.04026541256986093
[Epoch 7, Batch 2100] loss: 0.03682555046761991
[Epoch 7, Batch 2200] loss: 0.03744076372502605
[Epoch 7, Batch 2300] loss: 0.03302549712512701
[Epoch 7, Batch 2400] loss: 0.048913601205858866
[Epoch 7, Batch 2500] loss: 0.03666228389760363
[Epoch 7, Batch 2600] loss: 0.05192225596358185
[Epoch 7, Batch 2700] loss: 0.027017680109711364
[Epoch 7, Batch 2800] loss: 0.04529318620538106
[Epoch 7, Batch 2900] loss: 0.03525337260085507
[Epoch 7, Batch 3000] loss: 0.03772477961239929
[Epoch 7, Batch 3100] loss: 0.04255430907651316
[Epoch 7, Batch 3200] loss: 0.03310186023096321
[Epoch 7, Batch 3300] loss: 0.04893065934476908
[Epoch 7, Batch 3400] loss: 0.04042172308749287
[Epoch 7, Batch 3500] loss: 0.045872741287894314
[Epoch 7, Batch 3600] loss: 0.04687456925224978
[Epoch 7, Batch 3700] loss: 0.029988668050209527
**STATS for Epoch 7** : 
Average training loss: 0.0004
[Epoch 8, Batch 100] loss: 0.03949122360703768
[Epoch 8, Batch 200] loss: 0.024203175583825214
[Epoch 8, Batch 300] loss: 0.025076556765270652
[Epoch 8, Batch 400] loss: 0.03828460435222951
[Epoch 8, Batch 500] loss: 0.026536172149935738
[Epoch 8, Batch 600] loss: 0.02796083662135061
[Epoch 8, Batch 700] loss: 0.024592292820016154
[Epoch 8, Batch 800] loss: 0.029339248235992273
[Epoch 8, Batch 900] loss: 0.036648416779644324
[Epoch 8, Batch 1000] loss: 0.03702351900923531
[Epoch 8, Batch 1100] loss: 0.050315342482790584
[Epoch 8, Batch 1200] loss: 0.03294229934239411
[Epoch 8, Batch 1300] loss: 0.024744152955390744
[Epoch 8, Batch 1400] loss: 0.04400262789102271
[Epoch 8, Batch 1500] loss: 0.020674267472859355
[Epoch 8, Batch 1600] loss: 0.029257046642014756
[Epoch 8, Batch 1700] loss: 0.0260519877900515
[Epoch 8, Batch 1800] loss: 0.02939155084619415
[Epoch 8, Batch 1900] loss: 0.02949257883010432
[Epoch 8, Batch 2000] loss: 0.038828075662022454
[Epoch 8, Batch 2100] loss: 0.030860577518033096
[Epoch 8, Batch 2200] loss: 0.03687758498817857
[Epoch 8, Batch 2300] loss: 0.029924842309410452
[Epoch 8, Batch 2400] loss: 0.03700196173092991
[Epoch 8, Batch 2500] loss: 0.048035553028894354
[Epoch 8, Batch 2600] loss: 0.034304334801709045
[Epoch 8, Batch 2700] loss: 0.0318370665393013
[Epoch 8, Batch 2800] loss: 0.03753507031215122
[Epoch 8, Batch 2900] loss: 0.026183399231886142
[Epoch 8, Batch 3000] loss: 0.022323718130719497
[Epoch 8, Batch 3100] loss: 0.0225729111473629
[Epoch 8, Batch 3200] loss: 0.03056511462862545
[Epoch 8, Batch 3300] loss: 0.02664557341639011
[Epoch 8, Batch 3400] loss: 0.044277512703756655
[Epoch 8, Batch 3500] loss: 0.03356128534025629
[Epoch 8, Batch 3600] loss: 0.028772562467638638
[Epoch 8, Batch 3700] loss: 0.03158658525950159
**STATS for Epoch 8** : 
Average training loss: 0.0005
[Epoch 9, Batch 100] loss: 0.025609643761854387
[Epoch 9, Batch 200] loss: 0.04650418946883292
[Epoch 9, Batch 300] loss: 0.02256788701444748
[Epoch 9, Batch 400] loss: 0.024865317929215962
[Epoch 9, Batch 500] loss: 0.02681537855809438
[Epoch 9, Batch 600] loss: 0.03429607986472547
[Epoch 9, Batch 700] loss: 0.021033742394211005
[Epoch 9, Batch 800] loss: 0.031540432468755174
[Epoch 9, Batch 900] loss: 0.03190100106585305
[Epoch 9, Batch 1000] loss: 0.024976078036415855
[Epoch 9, Batch 1100] loss: 0.03141970130636764
[Epoch 9, Batch 1200] loss: 0.028061238008522196
[Epoch 9, Batch 1300] loss: 0.026730404267727863
[Epoch 9, Batch 1400] loss: 0.020217082228555228
[Epoch 9, Batch 1500] loss: 0.024342332097294275
[Epoch 9, Batch 1600] loss: 0.021238282348276696
[Epoch 9, Batch 1700] loss: 0.02215164153065416
[Epoch 9, Batch 1800] loss: 0.033170884776882306
[Epoch 9, Batch 1900] loss: 0.01881138350821857
[Epoch 9, Batch 2000] loss: 0.031989037242310586
[Epoch 9, Batch 2100] loss: 0.03860227907855005
[Epoch 9, Batch 2200] loss: 0.021933237087068846
[Epoch 9, Batch 2300] loss: 0.03536039614918991
[Epoch 9, Batch 2400] loss: 0.025037625909608324
[Epoch 9, Batch 2500] loss: 0.018020730511052532
[Epoch 9, Batch 2600] loss: 0.0392093616296188
[Epoch 9, Batch 2700] loss: 0.03746429300357704
[Epoch 9, Batch 2800] loss: 0.03744453086583235
[Epoch 9, Batch 2900] loss: 0.039269439561176116
[Epoch 9, Batch 3000] loss: 0.022607963570917492
[Epoch 9, Batch 3100] loss: 0.01817662268069398
[Epoch 9, Batch 3200] loss: 0.03532229377204203
[Epoch 9, Batch 3300] loss: 0.03573159119929187
[Epoch 9, Batch 3400] loss: 0.0447126481225132
[Epoch 9, Batch 3500] loss: 0.04050762597384164
[Epoch 9, Batch 3600] loss: 0.031219607641905896
[Epoch 9, Batch 3700] loss: 0.0216641884073033
**STATS for Epoch 9** : 
Average training loss: 0.0004
[Epoch 10, Batch 100] loss: 0.016105078815635353
[Epoch 10, Batch 200] loss: 0.027187062615485046
[Epoch 10, Batch 300] loss: 0.025222595049708616
[Epoch 10, Batch 400] loss: 0.02512317366832576
[Epoch 10, Batch 500] loss: 0.015084882898372598
[Epoch 10, Batch 600] loss: 0.019325091528917256
[Epoch 10, Batch 700] loss: 0.034610677233613385
[Epoch 10, Batch 800] loss: 0.022822307431779335
[Epoch 10, Batch 900] loss: 0.021945313820033334
[Epoch 10, Batch 1000] loss: 0.04119328040416804
[Epoch 10, Batch 1100] loss: 0.03214901464751165
[Epoch 10, Batch 1200] loss: 0.022805978511642025
[Epoch 10, Batch 1300] loss: 0.01818071814814175
[Epoch 10, Batch 1400] loss: 0.029701545701100257
[Epoch 10, Batch 1500] loss: 0.02112491173120361
[Epoch 10, Batch 1600] loss: 0.02292032896497403
[Epoch 10, Batch 1700] loss: 0.03519292624609079
[Epoch 10, Batch 1800] loss: 0.021378377596920472
[Epoch 10, Batch 1900] loss: 0.033327416769607224
[Epoch 10, Batch 2000] loss: 0.03508251218459918
[Epoch 10, Batch 2100] loss: 0.026019351012200785
[Epoch 10, Batch 2200] loss: 0.028798486019295525
[Epoch 10, Batch 2300] loss: 0.020883108673297103
[Epoch 10, Batch 2400] loss: 0.027410684997739736
[Epoch 10, Batch 2500] loss: 0.022050523567086203
[Epoch 10, Batch 2600] loss: 0.029793099512062327
[Epoch 10, Batch 2700] loss: 0.02809227512076177
[Epoch 10, Batch 2800] loss: 0.0322095487297338
[Epoch 10, Batch 2900] loss: 0.032366586860152896
[Epoch 10, Batch 3000] loss: 0.01671153304290783
[Epoch 10, Batch 3100] loss: 0.02306254326387716
[Epoch 10, Batch 3200] loss: 0.019675082340327207
[Epoch 10, Batch 3300] loss: 0.026088185151420477
[Epoch 10, Batch 3400] loss: 0.050485800364549506
[Epoch 10, Batch 3500] loss: 0.023807396251067984
[Epoch 10, Batch 3600] loss: 0.018245563368363946
[Epoch 10, Batch 3700] loss: 0.051185393426712834
**STATS for Epoch 10** : 
Average training loss: 0.0006
[Epoch 11, Batch 100] loss: 0.016866520320036216
[Epoch 11, Batch 200] loss: 0.02415036518319539
[Epoch 11, Batch 300] loss: 0.020009819113183766
[Epoch 11, Batch 400] loss: 0.018126026779136738
[Epoch 11, Batch 500] loss: 0.014171237223126808
[Epoch 11, Batch 600] loss: 0.017465269336025813
[Epoch 11, Batch 700] loss: 0.0188847160662408
[Epoch 11, Batch 800] loss: 0.022247371330322493
[Epoch 11, Batch 900] loss: 0.023877015059661062
[Epoch 11, Batch 1000] loss: 0.014668167630516109
[Epoch 11, Batch 1100] loss: 0.0202416160138182
[Epoch 11, Batch 1200] loss: 0.015586686896167521
[Epoch 11, Batch 1300] loss: 0.013032110249368997
[Epoch 11, Batch 1400] loss: 0.019559316700797354
[Epoch 11, Batch 1500] loss: 0.016529503997735447
[Epoch 11, Batch 1600] loss: 0.02494261128906146
[Epoch 11, Batch 1700] loss: 0.022915579885666375
[Epoch 11, Batch 1800] loss: 0.04431635481314515
[Epoch 11, Batch 1900] loss: 0.013169893096783198
[Epoch 11, Batch 2000] loss: 0.02480828432231647
[Epoch 11, Batch 2100] loss: 0.016588532591104013
[Epoch 11, Batch 2200] loss: 0.034661935984513545
[Epoch 11, Batch 2300] loss: 0.0330584869334416
[Epoch 11, Batch 2400] loss: 0.033831844943924806
[Epoch 11, Batch 2500] loss: 0.020869814521429362
[Epoch 11, Batch 2600] loss: 0.04236167084807676
[Epoch 11, Batch 2700] loss: 0.025018352860788583
[Epoch 11, Batch 2800] loss: 0.027679954457707937
[Epoch 11, Batch 2900] loss: 0.028685185589602043
[Epoch 11, Batch 3000] loss: 0.02057843134010909
[Epoch 11, Batch 3100] loss: 0.01718172337168653
[Epoch 11, Batch 3200] loss: 0.026599366622976958
[Epoch 11, Batch 3300] loss: 0.02405084163241554
[Epoch 11, Batch 3400] loss: 0.025085197657099344
[Epoch 11, Batch 3500] loss: 0.029815444497580758
[Epoch 11, Batch 3600] loss: 0.021515436967165444
[Epoch 11, Batch 3700] loss: 0.030463531295754364
**STATS for Epoch 11** : 
Average training loss: 0.0004
[Epoch 12, Batch 100] loss: 0.010857051440980285
[Epoch 12, Batch 200] loss: 0.02305897109043144
[Epoch 12, Batch 300] loss: 0.013855444074579282
[Epoch 12, Batch 400] loss: 0.025875590335490414
[Epoch 12, Batch 500] loss: 0.025714003642351598
[Epoch 12, Batch 600] loss: 0.013069333459170593
[Epoch 12, Batch 700] loss: 0.02182423968810326
[Epoch 12, Batch 800] loss: 0.014468066336994524
[Epoch 12, Batch 900] loss: 0.018349192878777103
[Epoch 12, Batch 1000] loss: 0.028918554565211706
[Epoch 12, Batch 1100] loss: 0.030264246118676966
[Epoch 12, Batch 1200] loss: 0.026117542004722053
[Epoch 12, Batch 1300] loss: 0.020315695547578796
[Epoch 12, Batch 1400] loss: 0.018247441020030238
[Epoch 12, Batch 1500] loss: 0.020123047025481355
[Epoch 12, Batch 1600] loss: 0.01831893590657273
[Epoch 12, Batch 1700] loss: 0.013112430522960494
[Epoch 12, Batch 1800] loss: 0.024511505442351336
[Epoch 12, Batch 1900] loss: 0.017279281212504428
[Epoch 12, Batch 2000] loss: 0.024273947904766828
[Epoch 12, Batch 2100] loss: 0.011094014681657428
[Epoch 12, Batch 2200] loss: 0.007565421553917986
[Epoch 12, Batch 2300] loss: 0.016663668318406055
[Epoch 12, Batch 2400] loss: 0.03315210419053983
[Epoch 12, Batch 2500] loss: 0.01874965100116242
[Epoch 12, Batch 2600] loss: 0.02121400263858959
[Epoch 12, Batch 2700] loss: 0.04158560228272108
[Epoch 12, Batch 2800] loss: 0.027975805768292047
[Epoch 12, Batch 2900] loss: 0.02160530282100808
[Epoch 12, Batch 3000] loss: 0.013689843426263906
[Epoch 12, Batch 3100] loss: 0.023767148505885415
[Epoch 12, Batch 3200] loss: 0.03195076599797176
[Epoch 12, Batch 3300] loss: 0.022265131159583687
[Epoch 12, Batch 3400] loss: 0.011444967237985111
[Epoch 12, Batch 3500] loss: 0.023938065978127268
[Epoch 12, Batch 3600] loss: 0.02594038475144771
[Epoch 12, Batch 3700] loss: 0.041627811299767926
**STATS for Epoch 12** : 
Average training loss: 0.0003
Best model saved at epoch 12 with training loss: 0.0003
[Epoch 13, Batch 100] loss: 0.018693730987142772
[Epoch 13, Batch 200] loss: 0.01199139533970083
[Epoch 13, Batch 300] loss: 0.019873450483246416
[Epoch 13, Batch 400] loss: 0.01920923779882287
[Epoch 13, Batch 500] loss: 0.018312631596090798
[Epoch 13, Batch 600] loss: 0.01942301249375305
[Epoch 13, Batch 700] loss: 0.014180942081693501
[Epoch 13, Batch 800] loss: 0.022092869991211045
[Epoch 13, Batch 900] loss: 0.02510070699689095
[Epoch 13, Batch 1000] loss: 0.021903068768660886
[Epoch 13, Batch 1100] loss: 0.034524008507141844
[Epoch 13, Batch 1200] loss: 0.01607763824689755
[Epoch 13, Batch 1300] loss: 0.010428082262933458
[Epoch 13, Batch 1400] loss: 0.027352689658946473
[Epoch 13, Batch 1500] loss: 0.028141615088570687
[Epoch 13, Batch 1600] loss: 0.013352878506248089
[Epoch 13, Batch 1700] loss: 0.012210606441949495
[Epoch 13, Batch 1800] loss: 0.014256878491432872
[Epoch 13, Batch 1900] loss: 0.02535450718325592
[Epoch 13, Batch 2000] loss: 0.02553234653281834
[Epoch 13, Batch 2100] loss: 0.02402123308809678
[Epoch 13, Batch 2200] loss: 0.023488773648423375
[Epoch 13, Batch 2300] loss: 0.02007534551066783
[Epoch 13, Batch 2400] loss: 0.01495025498632458
[Epoch 13, Batch 2500] loss: 0.017573669277062436
[Epoch 13, Batch 2600] loss: 0.02333241656084283
[Epoch 13, Batch 2700] loss: 0.013183842622875091
[Epoch 13, Batch 2800] loss: 0.014987293175963715
[Epoch 13, Batch 2900] loss: 0.01742556515862816
[Epoch 13, Batch 3000] loss: 0.015475222158638644
[Epoch 13, Batch 3100] loss: 0.02637845008441218
[Epoch 13, Batch 3200] loss: 0.020048036117859738
[Epoch 13, Batch 3300] loss: 0.017953612733308547
[Epoch 13, Batch 3400] loss: 0.02075708434142143
[Epoch 13, Batch 3500] loss: 0.01800556632651933
[Epoch 13, Batch 3600] loss: 0.020556014392204815
[Epoch 13, Batch 3700] loss: 0.011634835364056927
**STATS for Epoch 13** : 
Average training loss: 0.0003
[Epoch 14, Batch 100] loss: 0.023461700776897486
[Epoch 14, Batch 200] loss: 0.019983606806226815
[Epoch 14, Batch 300] loss: 0.015109361911891028
[Epoch 14, Batch 400] loss: 0.015030206308219931
[Epoch 14, Batch 500] loss: 0.02152305505980621
[Epoch 14, Batch 600] loss: 0.02372359420704015
[Epoch 14, Batch 700] loss: 0.018994358481977544
[Epoch 14, Batch 800] loss: 0.02636983064687229
[Epoch 14, Batch 900] loss: 0.010746839687344618
[Epoch 14, Batch 1000] loss: 0.009635074093675939
[Epoch 14, Batch 1100] loss: 0.011773221767070937
[Epoch 14, Batch 1200] loss: 0.025449868990708637
[Epoch 14, Batch 1300] loss: 0.029171232138614868
[Epoch 14, Batch 1400] loss: 0.01935891937566339
[Epoch 14, Batch 1500] loss: 0.01775518163666675
[Epoch 14, Batch 1600] loss: 0.017312993972955156
[Epoch 14, Batch 1700] loss: 0.019458910982757517
[Epoch 14, Batch 1800] loss: 0.02177846311689791
[Epoch 14, Batch 1900] loss: 0.013690926747149206
[Epoch 14, Batch 2000] loss: 0.010072925436152218
[Epoch 14, Batch 2100] loss: 0.018201861515390192
[Epoch 14, Batch 2200] loss: 0.021757219721303046
[Epoch 14, Batch 2300] loss: 0.029611818181838317
[Epoch 14, Batch 2400] loss: 0.019235673190360104
[Epoch 14, Batch 2500] loss: 0.024428509818553722
[Epoch 14, Batch 2600] loss: 0.026422433847728827
[Epoch 14, Batch 2700] loss: 0.013736439386157144
[Epoch 14, Batch 2800] loss: 0.008883325567785505
[Epoch 14, Batch 2900] loss: 0.016916387548608327
[Epoch 14, Batch 3000] loss: 0.025120085134803957
[Epoch 14, Batch 3100] loss: 0.013857931716920575
[Epoch 14, Batch 3200] loss: 0.010013885161806685
[Epoch 14, Batch 3300] loss: 0.013239530439786904
[Epoch 14, Batch 3400] loss: 0.010368191644574835
[Epoch 14, Batch 3500] loss: 0.007508150441844918
[Epoch 14, Batch 3600] loss: 0.013490629233665459
[Epoch 14, Batch 3700] loss: 0.016680186954345116
**STATS for Epoch 14** : 
Average training loss: 0.0002
Best model saved at epoch 14 with training loss: 0.0002
[Epoch 15, Batch 100] loss: 0.012216720237502159
[Epoch 15, Batch 200] loss: 0.014663770835331888
[Epoch 15, Batch 300] loss: 0.013779585470620076
[Epoch 15, Batch 400] loss: 0.009594126678912289
[Epoch 15, Batch 500] loss: 0.016974105025547033
[Epoch 15, Batch 600] loss: 0.017038849094096805
[Epoch 15, Batch 700] loss: 0.010401354626883403
[Epoch 15, Batch 800] loss: 0.013817170713246014
[Epoch 15, Batch 900] loss: 0.009681297924526006
[Epoch 15, Batch 1000] loss: 0.01847812945629812
[Epoch 15, Batch 1100] loss: 0.0115649512834716
[Epoch 15, Batch 1200] loss: 0.012567209982526037
[Epoch 15, Batch 1300] loss: 0.01247678911413459
[Epoch 15, Batch 1400] loss: 0.010325270994471794
[Epoch 15, Batch 1500] loss: 0.02337719990741789
[Epoch 15, Batch 1600] loss: 0.015535025288745601
[Epoch 15, Batch 1700] loss: 0.017109156089827594
[Epoch 15, Batch 1800] loss: 0.01187458212572892
[Epoch 15, Batch 1900] loss: 0.01028951712169146
[Epoch 15, Batch 2000] loss: 0.015578520567833038
[Epoch 15, Batch 2100] loss: 0.03388815806670209
[Epoch 15, Batch 2200] loss: 0.01760288850036886
[Epoch 15, Batch 2300] loss: 0.020554563983278058
[Epoch 15, Batch 2400] loss: 0.014462921709755392
[Epoch 15, Batch 2500] loss: 0.023301755194133876
[Epoch 15, Batch 2600] loss: 0.016652509765299327
[Epoch 15, Batch 2700] loss: 0.019264396764197046
[Epoch 15, Batch 2800] loss: 0.01836864425407839
[Epoch 15, Batch 2900] loss: 0.020755597323986876
[Epoch 15, Batch 3000] loss: 0.019244958071258225
[Epoch 15, Batch 3100] loss: 0.008437226910627942
[Epoch 15, Batch 3200] loss: 0.01995650449538516
[Epoch 15, Batch 3300] loss: 0.0277321459844552
[Epoch 15, Batch 3400] loss: 0.013556095174208168
[Epoch 15, Batch 3500] loss: 0.011427252041166867
[Epoch 15, Batch 3600] loss: 0.011039802442464861
[Epoch 15, Batch 3700] loss: 0.017198771157709417
**STATS for Epoch 15** : 
Average training loss: 0.0002
Best model saved at epoch 15 with training loss: 0.0002
[Epoch 16, Batch 100] loss: 0.021170636287224626
[Epoch 16, Batch 200] loss: 0.011090586268946935
[Epoch 16, Batch 300] loss: 0.012635417567007607
[Epoch 16, Batch 400] loss: 0.014113810374656168
[Epoch 16, Batch 500] loss: 0.022146585639502517
[Epoch 16, Batch 600] loss: 0.017281892602891275
[Epoch 16, Batch 700] loss: 0.0174860551772872
[Epoch 16, Batch 800] loss: 0.007261212426892598
[Epoch 16, Batch 900] loss: 0.010516159125672856
[Epoch 16, Batch 1000] loss: 0.02699452071603446
[Epoch 16, Batch 1100] loss: 0.008181037506801658
[Epoch 16, Batch 1200] loss: 0.007268679640255868
[Epoch 16, Batch 1300] loss: 0.016119423852378533
[Epoch 16, Batch 1400] loss: 0.005898035539175907
[Epoch 16, Batch 1500] loss: 0.015254541013405287
[Epoch 16, Batch 1600] loss: 0.021487087827536014
[Epoch 16, Batch 1700] loss: 0.0196783279552983
[Epoch 16, Batch 1800] loss: 0.012522530150799866
[Epoch 16, Batch 1900] loss: 0.012345552796741686
[Epoch 16, Batch 2000] loss: 0.01903093819988726
[Epoch 16, Batch 2100] loss: 0.017849021861975414
[Epoch 16, Batch 2200] loss: 0.0209794334497019
[Epoch 16, Batch 2300] loss: 0.014766011094934584
[Epoch 16, Batch 2400] loss: 0.012562655966212333
[Epoch 16, Batch 2500] loss: 0.01791860418734359
[Epoch 16, Batch 2600] loss: 0.009094761399683193
[Epoch 16, Batch 2700] loss: 0.01075566694978079
[Epoch 16, Batch 2800] loss: 0.021316057046471996
[Epoch 16, Batch 2900] loss: 0.014275458756019361
[Epoch 16, Batch 3000] loss: 0.009277852244767928
[Epoch 16, Batch 3100] loss: 0.024772054916084016
[Epoch 16, Batch 3200] loss: 0.013582342869976855
[Epoch 16, Batch 3300] loss: 0.012626717818520775
[Epoch 16, Batch 3400] loss: 0.019910989066702314
[Epoch 16, Batch 3500] loss: 0.011341804389012396
[Epoch 16, Batch 3600] loss: 0.016620145216511447
[Epoch 16, Batch 3700] loss: 0.014774295831703057
**STATS for Epoch 16** : 
Average training loss: 0.0002
[Epoch 17, Batch 100] loss: 0.017978891012098756
[Epoch 17, Batch 200] loss: 0.010867061452827328
[Epoch 17, Batch 300] loss: 0.01059919241909938
[Epoch 17, Batch 400] loss: 0.009925189228079034
[Epoch 17, Batch 500] loss: 0.007825407455175081
[Epoch 17, Batch 600] loss: 0.010241694937617467
[Epoch 17, Batch 700] loss: 0.021002927742592874
[Epoch 17, Batch 800] loss: 0.014474196400296933
[Epoch 17, Batch 900] loss: 0.018587577083590077
[Epoch 17, Batch 1000] loss: 0.01123803558331474
[Epoch 17, Batch 1100] loss: 0.010924505207767651
[Epoch 17, Batch 1200] loss: 0.011214636990159762
[Epoch 17, Batch 1300] loss: 0.008085177646630654
[Epoch 17, Batch 1400] loss: 0.00955356621334431
[Epoch 17, Batch 1500] loss: 0.010100669516555172
[Epoch 17, Batch 1600] loss: 0.014516910746874601
[Epoch 17, Batch 1700] loss: 0.012641661419820593
[Epoch 17, Batch 1800] loss: 0.006271494773145605
[Epoch 17, Batch 1900] loss: 0.017596277459970226
[Epoch 17, Batch 2000] loss: 0.016874584360966765
[Epoch 17, Batch 2100] loss: 0.02144000187868187
[Epoch 17, Batch 2200] loss: 0.014876671927304415
[Epoch 17, Batch 2300] loss: 0.007979547777968037
[Epoch 17, Batch 2400] loss: 0.0338180368527901
[Epoch 17, Batch 2500] loss: 0.010105450806240696
[Epoch 17, Batch 2600] loss: 0.012152898152507988
[Epoch 17, Batch 2700] loss: 0.01509675694978796
[Epoch 17, Batch 2800] loss: 0.02234628727634117
[Epoch 17, Batch 2900] loss: 0.010932696305517312
[Epoch 17, Batch 3000] loss: 0.009936118408440962
[Epoch 17, Batch 3100] loss: 0.0102114390262318
[Epoch 17, Batch 3200] loss: 0.008072882426936302
[Epoch 17, Batch 3300] loss: 0.007937030975556354
[Epoch 17, Batch 3400] loss: 0.018094633509272172
[Epoch 17, Batch 3500] loss: 0.013237013963171194
[Epoch 17, Batch 3600] loss: 0.026723621122255282
[Epoch 17, Batch 3700] loss: 0.021104717242897097
**STATS for Epoch 17** : 
Average training loss: 0.0003
[Epoch 18, Batch 100] loss: 0.009681788785801473
[Epoch 18, Batch 200] loss: 0.006972372073196311
[Epoch 18, Batch 300] loss: 0.009712484408423734
[Epoch 18, Batch 400] loss: 0.014557694645718584
[Epoch 18, Batch 500] loss: 0.012882674490385852
[Epoch 18, Batch 600] loss: 0.004945095440198202
[Epoch 18, Batch 700] loss: 0.01138004857546548
[Epoch 18, Batch 800] loss: 0.02096181984103623
[Epoch 18, Batch 900] loss: 0.01398489436640375
[Epoch 18, Batch 1000] loss: 0.009162750899058665
[Epoch 18, Batch 1100] loss: 0.013933964320412997
[Epoch 18, Batch 1200] loss: 0.0154842683487459
[Epoch 18, Batch 1300] loss: 0.00830824177188333
[Epoch 18, Batch 1400] loss: 0.006280703835836903
[Epoch 18, Batch 1500] loss: 0.007916958900286772
[Epoch 18, Batch 1600] loss: 0.006887346138155408
[Epoch 18, Batch 1700] loss: 0.0051624063362396555
[Epoch 18, Batch 1800] loss: 0.018683088336883882
[Epoch 18, Batch 1900] loss: 0.016818056458823775
[Epoch 18, Batch 2000] loss: 0.009893720487348219
[Epoch 18, Batch 2100] loss: 0.009138243305933429
[Epoch 18, Batch 2200] loss: 0.015224422510618752
[Epoch 18, Batch 2300] loss: 0.013804029427919886
[Epoch 18, Batch 2400] loss: 0.013324999821315941
[Epoch 18, Batch 2500] loss: 0.013835790017119508
[Epoch 18, Batch 2600] loss: 0.007687157059999663
[Epoch 18, Batch 2700] loss: 0.012154605994810481
[Epoch 18, Batch 2800] loss: 0.009028738965707817
[Epoch 18, Batch 2900] loss: 0.00803037833144117
[Epoch 18, Batch 3000] loss: 0.01160040665301949
[Epoch 18, Batch 3100] loss: 0.011513056569447145
[Epoch 18, Batch 3200] loss: 0.008714281148349982
[Epoch 18, Batch 3300] loss: 0.013061074675370037
[Epoch 18, Batch 3400] loss: 0.021528382652049913
[Epoch 18, Batch 3500] loss: 0.023420900974979304
[Epoch 18, Batch 3600] loss: 0.010932292091647469
[Epoch 18, Batch 3700] loss: 0.011336218291362457
**STATS for Epoch 18** : 
Average training loss: 0.0001
Best model saved at epoch 18 with training loss: 0.0001
[Epoch 19, Batch 100] loss: 0.010940624075037703
[Epoch 19, Batch 200] loss: 0.009765998774100807
[Epoch 19, Batch 300] loss: 0.010702404376279446
[Epoch 19, Batch 400] loss: 0.013791072898679885
[Epoch 19, Batch 500] loss: 0.012950379187805084
[Epoch 19, Batch 600] loss: 0.009852484113771424
[Epoch 19, Batch 700] loss: 0.00867697626537847
[Epoch 19, Batch 800] loss: 0.010126378067161568
[Epoch 19, Batch 900] loss: 0.008016979511012323
[Epoch 19, Batch 1000] loss: 0.007908921001251202
[Epoch 19, Batch 1100] loss: 0.011323675953940437
[Epoch 19, Batch 1200] loss: 0.013263035172126365
[Epoch 19, Batch 1300] loss: 0.007543126194830166
[Epoch 19, Batch 1400] loss: 0.0073025215403390575
[Epoch 19, Batch 1500] loss: 0.012106906390527002
[Epoch 19, Batch 1600] loss: 0.01002994836183575
[Epoch 19, Batch 1700] loss: 0.013696102851245087
[Epoch 19, Batch 1800] loss: 0.01006956411703868
[Epoch 19, Batch 1900] loss: 0.00531294972273372
[Epoch 19, Batch 2000] loss: 0.01633367913413167
[Epoch 19, Batch 2100] loss: 0.00873567403965808
[Epoch 19, Batch 2200] loss: 0.010711152809808482
[Epoch 19, Batch 2300] loss: 0.010604366822587964
[Epoch 19, Batch 2400] loss: 0.0130710842813005
[Epoch 19, Batch 2500] loss: 0.010984074598000007
[Epoch 19, Batch 2600] loss: 0.007469753662398944
[Epoch 19, Batch 2700] loss: 0.00943618671726199
[Epoch 19, Batch 2800] loss: 0.006288159421430919
[Epoch 19, Batch 2900] loss: 0.0047797620471635585
[Epoch 19, Batch 3000] loss: 0.017568336385875228
[Epoch 19, Batch 3100] loss: 0.00821160987859912
[Epoch 19, Batch 3200] loss: 0.015532938064775409
[Epoch 19, Batch 3300] loss: 0.014731254998105214
[Epoch 19, Batch 3400] loss: 0.01936787385698153
[Epoch 19, Batch 3500] loss: 0.011232182287758406
[Epoch 19, Batch 3600] loss: 0.004491226209311207
[Epoch 19, Batch 3700] loss: 0.008510242266104341
**STATS for Epoch 19** : 
Average training loss: 0.0000
Best model saved at epoch 19 with training loss: 0.0000
[Epoch 20, Batch 100] loss: 0.006457765124255274
[Epoch 20, Batch 200] loss: 0.004341497261025324
[Epoch 20, Batch 300] loss: 0.009524356577412619
[Epoch 20, Batch 400] loss: 0.006497787159887593
[Epoch 20, Batch 500] loss: 0.006771329758694264
[Epoch 20, Batch 600] loss: 0.009612622048111917
[Epoch 20, Batch 700] loss: 0.006350209030588303
[Epoch 20, Batch 800] loss: 0.00985662507525376
[Epoch 20, Batch 900] loss: 0.010559320045590539
[Epoch 20, Batch 1000] loss: 0.009923395059486211
[Epoch 20, Batch 1100] loss: 0.0043415216108087405
[Epoch 20, Batch 1200] loss: 0.009262899398885338
[Epoch 20, Batch 1300] loss: 0.009894497661939568
[Epoch 20, Batch 1400] loss: 0.00405956463143184
[Epoch 20, Batch 1500] loss: 0.004096345777195438
[Epoch 20, Batch 1600] loss: 0.01550672188820954
[Epoch 20, Batch 1700] loss: 0.01074031518978245
[Epoch 20, Batch 1800] loss: 0.009705788817341273
[Epoch 20, Batch 1900] loss: 0.016649474366558933
[Epoch 20, Batch 2000] loss: 0.006924914671789679
[Epoch 20, Batch 2100] loss: 0.00759742133378495
[Epoch 20, Batch 2200] loss: 0.011505249196511613
[Epoch 20, Batch 2300] loss: 0.012078838981783519
[Epoch 20, Batch 2400] loss: 0.014730234770479456
[Epoch 20, Batch 2500] loss: 0.002885589464851819
[Epoch 20, Batch 2600] loss: 0.010289292367133385
[Epoch 20, Batch 2700] loss: 0.010026128928784602
[Epoch 20, Batch 2800] loss: 0.007402625644317595
[Epoch 20, Batch 2900] loss: 0.008770427167742128
[Epoch 20, Batch 3000] loss: 0.01008007095116227
[Epoch 20, Batch 3100] loss: 0.013870292428787252
[Epoch 20, Batch 3200] loss: 0.006196644184396974
[Epoch 20, Batch 3300] loss: 0.011051983856218613
[Epoch 20, Batch 3400] loss: 0.014265820861376143
[Epoch 20, Batch 3500] loss: 0.019381881222525408
[Epoch 20, Batch 3600] loss: 0.011706380025125328
[Epoch 20, Batch 3700] loss: 0.018897383589863922
**STATS for Epoch 20** : 
Average training loss: 0.0002
[Epoch 21, Batch 100] loss: 0.006888008844260298
[Epoch 21, Batch 200] loss: 0.004824862732062911
[Epoch 21, Batch 300] loss: 0.004500059016281739
[Epoch 21, Batch 400] loss: 0.011597176479876908
[Epoch 21, Batch 500] loss: 0.0069065837096377435
[Epoch 21, Batch 600] loss: 0.010706853690034563
[Epoch 21, Batch 700] loss: 0.010077215441452837
[Epoch 21, Batch 800] loss: 0.015962842778089906
[Epoch 21, Batch 900] loss: 0.008014028657980817
[Epoch 21, Batch 1000] loss: 0.004740227438550165
[Epoch 21, Batch 1100] loss: 0.02327921528583488
[Epoch 21, Batch 1200] loss: 0.01995990424897627
[Epoch 21, Batch 1300] loss: 0.010016455719278384
[Epoch 21, Batch 1400] loss: 0.008812685095967936
[Epoch 21, Batch 1500] loss: 0.010219719876336058
[Epoch 21, Batch 1600] loss: 0.005274745264623562
[Epoch 21, Batch 1700] loss: 0.006751344503491055
[Epoch 21, Batch 1800] loss: 0.010642911610389091
[Epoch 21, Batch 1900] loss: 0.006057699077273355
[Epoch 21, Batch 2000] loss: 0.007210416641962638
[Epoch 21, Batch 2100] loss: 0.013140267310827767
[Epoch 21, Batch 2200] loss: 0.013066355596911307
[Epoch 21, Batch 2300] loss: 0.015447038995589538
[Epoch 21, Batch 2400] loss: 0.009328681522265469
[Epoch 21, Batch 2500] loss: 0.004081705191338187
[Epoch 21, Batch 2600] loss: 0.006593414369635866
[Epoch 21, Batch 2700] loss: 0.008719685107425903
[Epoch 21, Batch 2800] loss: 0.007507637895382686
[Epoch 21, Batch 2900] loss: 0.006973877106269697
[Epoch 21, Batch 3000] loss: 0.007457452477594871
[Epoch 21, Batch 3100] loss: 0.012919781336877349
[Epoch 21, Batch 3200] loss: 0.0074219966779764945
[Epoch 21, Batch 3300] loss: 0.00935966861652105
[Epoch 21, Batch 3400] loss: 0.015585466480418973
[Epoch 21, Batch 3500] loss: 0.0092944956281724
[Epoch 21, Batch 3600] loss: 0.007353723981636904
[Epoch 21, Batch 3700] loss: 0.008617692518901094
**STATS for Epoch 21** : 
Average training loss: 0.0001
[Epoch 22, Batch 100] loss: 0.0072827099309120055
[Epoch 22, Batch 200] loss: 0.005034257324562077
[Epoch 22, Batch 300] loss: 0.004367672264086195
[Epoch 22, Batch 400] loss: 0.005306260597544679
[Epoch 22, Batch 500] loss: 0.007858720207701708
[Epoch 22, Batch 600] loss: 0.006361454015191157
[Epoch 22, Batch 700] loss: 0.007373674792447673
[Epoch 22, Batch 800] loss: 0.0091666078258379
[Epoch 22, Batch 900] loss: 0.01146008688330312
[Epoch 22, Batch 1000] loss: 0.009056138314417695
[Epoch 22, Batch 1100] loss: 0.004722260743037623
[Epoch 22, Batch 1200] loss: 0.0068119120875900305
[Epoch 22, Batch 1300] loss: 0.009444347125011063
[Epoch 22, Batch 1400] loss: 0.011043163019376152
[Epoch 22, Batch 1500] loss: 0.010846334879379355
[Epoch 22, Batch 1600] loss: 0.008942607285364374
[Epoch 22, Batch 1700] loss: 0.005343220419943009
[Epoch 22, Batch 1800] loss: 0.007420202854983699
[Epoch 22, Batch 1900] loss: 0.004614080355753458
[Epoch 22, Batch 2000] loss: 0.004063567637367669
[Epoch 22, Batch 2100] loss: 0.011064927661889214
[Epoch 22, Batch 2200] loss: 0.0076345492706786896
[Epoch 22, Batch 2300] loss: 0.013349113959037595
[Epoch 22, Batch 2400] loss: 0.02336587215576401
[Epoch 22, Batch 2500] loss: 0.00559497694701804
[Epoch 22, Batch 2600] loss: 0.00843532807256338
[Epoch 22, Batch 2700] loss: 0.017303126218921536
[Epoch 22, Batch 2800] loss: 0.004934468711489899
[Epoch 22, Batch 2900] loss: 0.008069273879082175
[Epoch 22, Batch 3000] loss: 0.014088701086038782
[Epoch 22, Batch 3100] loss: 0.003540997103818597
[Epoch 22, Batch 3200] loss: 0.005805045621382305
[Epoch 22, Batch 3300] loss: 0.012909164208883795
[Epoch 22, Batch 3400] loss: 0.004258319465390059
[Epoch 22, Batch 3500] loss: 0.008483745161895513
[Epoch 22, Batch 3600] loss: 0.004883021495176081
[Epoch 22, Batch 3700] loss: 0.007382428677976236
**STATS for Epoch 22** : 
Average training loss: 0.0002
[Epoch 23, Batch 100] loss: 0.00446457816527527
[Epoch 23, Batch 200] loss: 0.009263900500409079
[Epoch 23, Batch 300] loss: 0.01995934074831439
[Epoch 23, Batch 400] loss: 0.005995770442232242
[Epoch 23, Batch 500] loss: 0.008439168706927376
[Epoch 23, Batch 600] loss: 0.006596210938716922
[Epoch 23, Batch 700] loss: 0.004553420700473225
[Epoch 23, Batch 800] loss: 0.0027548138995166483
[Epoch 23, Batch 900] loss: 0.009418232871083773
[Epoch 23, Batch 1000] loss: 0.010863481647799062
[Epoch 23, Batch 1100] loss: 0.005176021368190504
[Epoch 23, Batch 1200] loss: 0.007427132761117719
[Epoch 23, Batch 1300] loss: 0.003946851627987371
[Epoch 23, Batch 1400] loss: 0.0060705254780828
[Epoch 23, Batch 1500] loss: 0.008536563882357769
[Epoch 23, Batch 1600] loss: 0.007306876712567601
[Epoch 23, Batch 1700] loss: 0.009246758814074383
[Epoch 23, Batch 1800] loss: 0.010381403816800229
[Epoch 23, Batch 1900] loss: 0.015926783026110912
[Epoch 23, Batch 2000] loss: 0.011302853426719252
[Epoch 23, Batch 2100] loss: 0.007431100202566086
[Epoch 23, Batch 2200] loss: 0.008705585739162415
[Epoch 23, Batch 2300] loss: 0.006175251968072643
[Epoch 23, Batch 2400] loss: 0.007394417011416863
[Epoch 23, Batch 2500] loss: 0.00814209764344696
[Epoch 23, Batch 2600] loss: 0.0032385060939623144
[Epoch 23, Batch 2700] loss: 0.017087108161294964
[Epoch 23, Batch 2800] loss: 0.018340040083132864
[Epoch 23, Batch 2900] loss: 0.009777680151764799
[Epoch 23, Batch 3000] loss: 0.0049769195819749255
[Epoch 23, Batch 3100] loss: 0.01086368975661287
[Epoch 23, Batch 3200] loss: 0.003907746547013175
[Epoch 23, Batch 3300] loss: 0.004435773816393294
[Epoch 23, Batch 3400] loss: 0.005814314378341123
[Epoch 23, Batch 3500] loss: 0.004784481052206501
[Epoch 23, Batch 3600] loss: 0.006318334727982346
[Epoch 23, Batch 3700] loss: 0.007017346605716739
**STATS for Epoch 23** : 
Average training loss: 0.0001
[Epoch 24, Batch 100] loss: 0.007233954237921125
[Epoch 24, Batch 200] loss: 0.003971848243750174
[Epoch 24, Batch 300] loss: 0.005195134533352075
[Epoch 24, Batch 400] loss: 0.004425953938620637
[Epoch 24, Batch 500] loss: 0.0023712707442297186
[Epoch 24, Batch 600] loss: 0.004363307599541031
[Epoch 24, Batch 700] loss: 0.0022161096823407433
[Epoch 24, Batch 800] loss: 0.008606507555621193
[Epoch 24, Batch 900] loss: 0.005248430415643952
[Epoch 24, Batch 1000] loss: 0.004973727575315934
[Epoch 24, Batch 1100] loss: 0.0058110025563871655
[Epoch 24, Batch 1200] loss: 0.014685782838384967
[Epoch 24, Batch 1300] loss: 0.0031293090911822218
[Epoch 24, Batch 1400] loss: 0.008458145951985898
[Epoch 24, Batch 1500] loss: 0.007892542009540194
[Epoch 24, Batch 1600] loss: 0.00625656026600609
[Epoch 24, Batch 1700] loss: 0.01027905853905395
[Epoch 24, Batch 1800] loss: 0.006556233487553981
[Epoch 24, Batch 1900] loss: 0.005909204494485038
[Epoch 24, Batch 2000] loss: 0.006102568932676035
[Epoch 24, Batch 2100] loss: 0.002567826179903818
[Epoch 24, Batch 2200] loss: 0.006247524666656545
[Epoch 24, Batch 2300] loss: 0.0023843028294572833
[Epoch 24, Batch 2400] loss: 0.006158405093096917
[Epoch 24, Batch 2500] loss: 0.003301411056244348
[Epoch 24, Batch 2600] loss: 0.005300892403186026
[Epoch 24, Batch 2700] loss: 0.008631869527757772
[Epoch 24, Batch 2800] loss: 0.01081134679312754
[Epoch 24, Batch 2900] loss: 0.017572838332241644
[Epoch 24, Batch 3000] loss: 0.006928794239197487
[Epoch 24, Batch 3100] loss: 0.017162129532639483
[Epoch 24, Batch 3200] loss: 0.012386242163738358
[Epoch 24, Batch 3300] loss: 0.003383210856188725
[Epoch 24, Batch 3400] loss: 0.005839463891045398
[Epoch 24, Batch 3500] loss: 0.0058606298596635045
[Epoch 24, Batch 3600] loss: 0.0062448356503182366
[Epoch 24, Batch 3700] loss: 0.006338344295500917
**STATS for Epoch 24** : 
Average training loss: 0.0001
Using best hyperparameters {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16} on final Test set to find Test loss for overfitting
Testing loss : 0.0434
Calculated Overfitting : 0.0433
Using best hyperparameters {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9864
Total time taken for hyperparameter tuning and evaluation: 3:43:3
/home/ahussain/PycharmProjects/optunaNew/optuna_MedianPruner.py:455: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.


Process finished with exit code 0

