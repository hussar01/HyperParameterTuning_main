ss: 0.01480562716175312
[Epoch 10, Batch 800] loss: 0.02687413762712353
[Epoch 10, Batch 900] loss: 0.007348376136536885
[Epoch 10, Batch 1000] loss: 0.022402233140429183
[Epoch 10, Batch 1100] loss: 0.03837655177498846
[Epoch 10, Batch 1200] loss: 0.038343200169921376
[Epoch 10, Batch 1300] loss: 0.021798879684332348
[Epoch 10, Batch 1400] loss: 0.019513905356257057
[Epoch 10, Batch 1500] loss: 0.019478369063411948
[Epoch 10, Batch 1600] loss: 0.012138770210098002
[Epoch 10, Batch 1700] loss: 0.02165413347863506
[Epoch 10, Batch 1800] loss: 0.009498943803360476
[Epoch 10, Batch 1900] loss: 0.03139830283278769
[Epoch 10, Batch 2000] loss: 0.017250698596285474
[Epoch 10, Batch 2100] loss: 0.02159967932250993
[Epoch 10, Batch 2200] loss: 0.02088779921618425
[Epoch 10, Batch 2300] loss: 0.016567714848204317
[Epoch 10, Batch 2400] loss: 0.016153486367136587
[Epoch 10, Batch 2500] loss: 0.022476816527963593
[Epoch 10, Batch 2600] loss: 0.012750123609854995
[Epoch 10, Batch 2700] loss: 0.011724055456848674
[Epoch 10, Batch 2800] loss: 0.007846428211255656
[Epoch 10, Batch 2900] loss: 0.025165810597323174
[Epoch 10, Batch 3000] loss: 0.03283858868626169
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9859
Overfitting: 0.0632
[Epoch 11, Batch 100] loss: 0.018254160426726573
[Epoch 11, Batch 200] loss: 0.01591092958177569
[Epoch 11, Batch 300] loss: 0.02116114951434156
[Epoch 11, Batch 400] loss: 0.01201691592103728
[Epoch 11, Batch 500] loss: 0.012791323889791784
[Epoch 11, Batch 600] loss: 0.023033232113665605
[Epoch 11, Batch 700] loss: 0.02025159707491069
[Epoch 11, Batch 800] loss: 0.013157319723462138
[Epoch 11, Batch 900] loss: 0.013551196650617641
[Epoch 11, Batch 1000] loss: 0.016305557832691022
[Epoch 11, Batch 1100] loss: 0.010984510500435363
[Epoch 11, Batch 1200] loss: 0.015446805894155204
[Epoch 11, Batch 1300] loss: 0.01134197760040042
[Epoch 11, Batch 1400] loss: 0.020018087978258662
[Epoch 11, Batch 1500] loss: 0.04552604821208945
[Epoch 11, Batch 1600] loss: 0.03899016721940143
[Epoch 11, Batch 1700] loss: 0.010226402247380974
[Epoch 11, Batch 1800] loss: 0.019060403307317984
[Epoch 11, Batch 1900] loss: 0.03861739429051056
[Epoch 11, Batch 2000] loss: 0.007298322723859201
[Epoch 11, Batch 2100] loss: 0.015309188294904743
[Epoch 11, Batch 2200] loss: 0.010351445692746779
[Epoch 11, Batch 2300] loss: 0.026653911738202397
[Epoch 11, Batch 2400] loss: 0.031083638761888324
[Epoch 11, Batch 2500] loss: 0.031425077653343576
[Epoch 11, Batch 2600] loss: 0.014926915557891789
[Epoch 11, Batch 2700] loss: 0.029967357407563212
[Epoch 11, Batch 2800] loss: 0.012413772250451984
[Epoch 11, Batch 2900] loss: 0.018865851400503147
[Epoch 11, Batch 3000] loss: 0.019415972680781123
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9872
Overfitting: 0.0536
[Epoch 12, Batch 100] loss: 0.009623505963823505
[Epoch 12, Batch 200] loss: 0.0057382885782828194
[Epoch 12, Batch 300] loss: 0.010624065274004333
[Epoch 12, Batch 400] loss: 0.0038056374098681543
[Epoch 12, Batch 500] loss: 0.010621402457996112
[Epoch 12, Batch 600] loss: 0.013401042458504549
[Epoch 12, Batch 700] loss: 0.01673493236008994
[Epoch 12, Batch 800] loss: 0.02007064853397175
[Epoch 12, Batch 900] loss: 0.018386635770889583
[Epoch 12, Batch 1000] loss: 0.01954730734531822
[Epoch 12, Batch 1100] loss: 0.0034529914412180143
[Epoch 12, Batch 1200] loss: 0.011594994998932436
[Epoch 12, Batch 1300] loss: 0.010402448769449384
[Epoch 12, Batch 1400] loss: 0.018127806428685597
[Epoch 12, Batch 1500] loss: 0.023853659199154543
[Epoch 12, Batch 1600] loss: 0.026802746569331647
[Epoch 12, Batch 1700] loss: 0.02903629388980235
[Epoch 12, Batch 1800] loss: 0.018095392519481807
[Epoch 12, Batch 1900] loss: 0.02651487092429129
[Epoch 12, Batch 2000] loss: 0.03252646543259303
[Epoch 12, Batch 2100] loss: 0.02486122865033245
[Epoch 12, Batch 2200] loss: 0.010566159453587147
[Epoch 12, Batch 2300] loss: 0.015148702629218712
[Epoch 12, Batch 2400] loss: 0.011753825926598394
[Epoch 12, Batch 2500] loss: 0.025978706823130082
[Epoch 12, Batch 2600] loss: 0.0384716859202274
[Epoch 12, Batch 2700] loss: 0.027102221845150324
[Epoch 12, Batch 2800] loss: 0.015046838195517474
[Epoch 12, Batch 2900] loss: 0.030922948900673503
[Epoch 12, Batch 3000] loss: 0.02579187021638006
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0611
Validation Accuracy: 0.9866
Overfitting: 0.0611
[Epoch 13, Batch 100] loss: 0.011285028111885254
[Epoch 13, Batch 200] loss: 0.016989924813086647
[Epoch 13, Batch 300] loss: 0.014957358313248488
[Epoch 13, Batch 400] loss: 0.018114609168242844
[Epoch 13, Batch 500] loss: 0.01419856164914659
[Epoch 13, Batch 600] loss: 0.009802187906200964
[Epoch 13, Batch 700] loss: 0.013860525939634015
[Epoch 13, Batch 800] loss: 0.02173343376687978
[Epoch 13, Batch 900] loss: 0.026902847957509968
[Epoch 13, Batch 1000] loss: 0.01791323891021132
[Epoch 13, Batch 1100] loss: 0.014917869790325397
[Epoch 13, Batch 1200] loss: 0.02323399383518762
[Epoch 13, Batch 1300] loss: 0.013443970398005546
[Epoch 13, Batch 1400] loss: 0.01922307324932312
[Epoch 13, Batch 1500] loss: 0.01873208385735708
[Epoch 13, Batch 1600] loss: 0.018929434249013256
[Epoch 13, Batch 1700] loss: 0.026924933519298686
[Epoch 13, Batch 1800] loss: 0.012988020257290244
[Epoch 13, Batch 1900] loss: 0.017024853893395572
[Epoch 13, Batch 2000] loss: 0.022571537039626718
[Epoch 13, Batch 2100] loss: 0.028426691885268838
[Epoch 13, Batch 2200] loss: 0.015109337638050703
[Epoch 13, Batch 2300] loss: 0.03295262400680826
[Epoch 13, Batch 2400] loss: 0.018191285729876442
[Epoch 13, Batch 2500] loss: 0.018677767907300337
[Epoch 13, Batch 2600] loss: 0.04100335655024082
[Epoch 13, Batch 2700] loss: 0.014805017659480769
[Epoch 13, Batch 2800] loss: 0.01817933806896491
[Epoch 13, Batch 2900] loss: 0.024873391539525187
[Epoch 13, Batch 3000] loss: 0.010775850131851285
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0776
Validation Accuracy: 0.9834
Overfitting: 0.0776
[Epoch 14, Batch 100] loss: 0.010750840230849122
[Epoch 14, Batch 200] loss: 0.01714290243593382
[Epoch 14, Batch 300] loss: 0.014001108945712968
[Epoch 14, Batch 400] loss: 0.014551166962298794
[Epoch 14, Batch 500] loss: 0.017008130495914174
[Epoch 14, Batch 600] loss: 0.011665557944491383
[Epoch 14, Batch 700] loss: 0.018249168680239337
[Epoch 14, Batch 800] loss: 0.004574161015595806
[Epoch 14, Batch 900] loss: 0.013441950941548556
[Epoch 14, Batch 1000] loss: 0.003181097437134426
[Epoch 14, Batch 1100] loss: 0.033431897123144184
[Epoch 14, Batch 1200] loss: 0.015181348729533467
[Epoch 14, Batch 1300] loss: 0.005642288420125503
[Epoch 14, Batch 1400] loss: 0.01173633106318931
[Epoch 14, Batch 1500] loss: 0.007952351741171664
[Epoch 14, Batch 1600] loss: 0.036241797105759865
[Epoch 14, Batch 1700] loss: 0.013099303374592104
[Epoch 14, Batch 1800] loss: 0.011240156369832378
[Epoch 14, Batch 1900] loss: 0.010028532947366635
[Epoch 14, Batch 2000] loss: 0.014542233711104515
[Epoch 14, Batch 2100] loss: 0.01629566670997889
[Epoch 14, Batch 2200] loss: 0.015418087322223783
[Epoch 14, Batch 2300] loss: 0.01626734288542309
[Epoch 14, Batch 2400] loss: 0.022449318481137653
[Epoch 14, Batch 2500] loss: 0.01731301840738297
[Epoch 14, Batch 2600] loss: 0.01674552929191819
[Epoch 14, Batch 2700] loss: 0.011358861672515274
[Epoch 14, Batch 2800] loss: 0.015223483178160392
[Epoch 14, Batch 2900] loss: 0.03545321245069402
[Epoch 14, Batch 3000] loss: 0.007734954614682011
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0672
Validation Accuracy: 0.9847
Overfitting: 0.0672
[Epoch 15, Batch 100] loss: 0.00805450477464781
[Epoch 15, Batch 200] loss: 0.00645075179091581
[Epoch 15, Batch 300] loss: 0.016471745630418085
[Epoch 15, Batch 400] loss: 0.010519507250721451
[Epoch 15, Batch 500] loss: 0.02097659151649708
[Epoch 15, Batch 600] loss: 0.013320547099563526
[Epoch 15, Batch 700] loss: 0.016449075009807926
[Epoch 15, Batch 800] loss: 0.015219568967632569
[Epoch 15, Batch 900] loss: 0.003244396802916447
[Epoch 15, Batch 1000] loss: 0.01903879431078856
[Epoch 15, Batch 1100] loss: 0.009295557635718623
[Epoch 15, Batch 1200] loss: 0.007239815047105402
[Epoch 15, Batch 1300] loss: 0.023734348173661383
[Epoch 15, Batch 1400] loss: 0.009975072386125685
[Epoch 15, Batch 1500] loss: 0.015000961656731988
[Epoch 15, Batch 1600] loss: 0.005886450266941949
[Epoch 15, Batch 1700] loss: 0.007271863508637324
[Epoch 15, Batch 1800] loss: 0.0076128827054402805
[Epoch 15, Batch 1900] loss: 0.010635130154545553
[Epoch 15, Batch 2000] loss: 0.00970485115202795
[Epoch 15, Batch 2100] loss: 0.0212082843125264
[Epoch 15, Batch 2200] loss: 0.0027470633137821566
[Epoch 15, Batch 2300] loss: 0.02041162323534239
[Epoch 15, Batch 2400] loss: 0.023029675598834773
[Epoch 15, Batch 2500] loss: 0.016684385566158148
[Epoch 15, Batch 2600] loss: 0.008134133081687013
[Epoch 15, Batch 2700] loss: 0.0078021117445995665
[Epoch 15, Batch 2800] loss: 0.015009941516980102
[Epoch 15, Batch 2900] loss: 0.019029918571453024
[Epoch 15, Batch 3000] loss: 0.03314420406007624
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0668
Validation Accuracy: 0.9862
Overfitting: 0.0668
[Epoch 16, Batch 100] loss: 0.011966324008291992
[Epoch 16, Batch 200] loss: 0.013596549296786317
[Epoch 16, Batch 300] loss: 0.009878128895190165
[Epoch 16, Batch 400] loss: 0.005225428197391527
[Epoch 16, Batch 500] loss: 0.018192632354401113
[Epoch 16, Batch 600] loss: 0.008861323768331526
[Epoch 16, Batch 700] loss: 0.01901976944111304
[Epoch 16, Batch 800] loss: 0.0076550156842224125
[Epoch 16, Batch 900] loss: 0.020023070906422292
[Epoch 16, Batch 1000] loss: 0.01442642618266035
[Epoch 16, Batch 1100] loss: 0.0165751810800975
[Epoch 16, Batch 1200] loss: 0.013588567514799123
[Epoch 16, Batch 1300] loss: 0.013128182269143132
[Epoch 16, Batch 1400] loss: 0.008820628758909623
[Epoch 16, Batch 1500] loss: 0.011312795188059659
[Epoch 16, Batch 1600] loss: 0.022661880878938306
[Epoch 16, Batch 1700] loss: 0.008397529318285812
[Epoch 16, Batch 1800] loss: 0.009682138770868036
[Epoch 16, Batch 1900] loss: 0.034004766329825784
[Epoch 16, Batch 2000] loss: 0.03459640364979407
[Epoch 16, Batch 2100] loss: 0.02203970463032391
[Epoch 16, Batch 2200] loss: 0.017635763288255647
[Epoch 16, Batch 2300] loss: 0.025121985254296743
[Epoch 16, Batch 2400] loss: 0.023048698236325434
[Epoch 16, Batch 2500] loss: 0.03291263700449292
[Epoch 16, Batch 2600] loss: 0.009295121075977733
[Epoch 16, Batch 2700] loss: 0.01936946913862192
[Epoch 16, Batch 2800] loss: 0.015969051045534713
[Epoch 16, Batch 2900] loss: 0.013769876059049708
[Epoch 16, Batch 3000] loss: 0.014236522794913498
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0917
Validation Accuracy: 0.9840
Overfitting: 0.0917
[Epoch 17, Batch 100] loss: 0.01211531433263675
[Epoch 17, Batch 200] loss: 0.03672553250304475
[Epoch 17, Batch 300] loss: 0.027295558824435774
[Epoch 17, Batch 400] loss: 0.012950944897154008
[Epoch 17, Batch 500] loss: 0.04615443961960011
[Epoch 17, Batch 600] loss: 0.00897810363856653
[Epoch 17, Batch 700] loss: 0.02593284276039185
[Epoch 17, Batch 800] loss: 0.00916159573885384
[Epoch 17, Batch 900] loss: 0.01250082035103393
[Epoch 17, Batch 1000] loss: 0.03125969797705931
[Epoch 17, Batch 1100] loss: 0.01675324986988315
[Epoch 17, Batch 1200] loss: 0.014118588932746947
[Epoch 17, Batch 1300] loss: 0.025681167213811876
[Epoch 17, Batch 1400] loss: 0.01423854260277892
[Epoch 17, Batch 1500] loss: 0.019800208264944066
[Epoch 17, Batch 1600] loss: 0.031667189013604116
[Epoch 17, Batch 1700] loss: 0.022433435965571676
[Epoch 17, Batch 1800] loss: 0.008973462910398099
[Epoch 17, Batch 1900] loss: 0.018653864597657163
[Epoch 17, Batch 2000] loss: 0.01578933828260176
[Epoch 17, Batch 2100] loss: 0.006078973414395534
[Epoch 17, Batch 2200] loss: 0.014313182118443244
[Epoch 17, Batch 2300] loss: 0.010256061989091413
[Epoch 17, Batch 2400] loss: 0.01584872511150877
[Epoch 17, Batch 2500] loss: 0.020392004804373868
[Epoch 17, Batch 2600] loss: 0.01160564747625271
[Epoch 17, Batch 2700] loss: 0.014541014364634038
[Epoch 17, Batch 2800] loss: 0.026394600894325392
[Epoch 17, Batch 2900] loss: 0.022092268889027836
[Epoch 17, Batch 3000] loss: 0.006385763660993273
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0860
Validation Accuracy: 0.9848
Overfitting: 0.0860
[Epoch 18, Batch 100] loss: 0.009813026719560653
[Epoch 18, Batch 200] loss: 0.02102364432320342
[Epoch 18, Batch 300] loss: 0.011144701010462353
[Epoch 18, Batch 400] loss: 0.02174489184388029
[Epoch 18, Batch 500] loss: 0.007896078585503261
[Epoch 18, Batch 600] loss: 0.02361060388491353
[Epoch 18, Batch 700] loss: 0.009247408316323051
[Epoch 18, Batch 800] loss: 0.020181150871385944
[Epoch 18, Batch 900] loss: 0.004544503549061907
[Epoch 18, Batch 1000] loss: 0.018282058799493617
[Epoch 18, Batch 1100] loss: 0.02399391663126913
[Epoch 18, Batch 1200] loss: 0.014205830071088102
[Epoch 18, Batch 1300] loss: 0.006170373967675253
[Epoch 18, Batch 1400] loss: 0.019202413694555887
[Epoch 18, Batch 1500] loss: 0.02741286003821469
[Epoch 18, Batch 1600] loss: 0.009871666785412856
[Epoch 18, Batch 1700] loss: 0.005513415179963701
[Epoch 18, Batch 1800] loss: 0.00713117323942047
[Epoch 18, Batch 1900] loss: 0.008713814934986096
[Epoch 18, Batch 2000] loss: 0.007693806550517523
[Epoch 18, Batch 2100] loss: 0.012588274430339661
[Epoch 18, Batch 2200] loss: 0.00922576847329771
[Epoch 18, Batch 2300] loss: 0.026606756988030042
[Epoch 18, Batch 2400] loss: 0.024673151525332206
[Epoch 18, Batch 2500] loss: 0.014510939884032438
[Epoch 18, Batch 2600] loss: 0.014820013409906992
[Epoch 18, Batch 2700] loss: 0.021041048599266487
[Epoch 18, Batch 2800] loss: 0.007281959765995865
[Epoch 18, Batch 2900] loss: 0.007277165694082637
[Epoch 18, Batch 3000] loss: 0.020840056957506903
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0803
Validation Accuracy: 0.9862
Overfitting: 0.0803
[Epoch 19, Batch 100] loss: 0.008594907148375021
[Epoch 19, Batch 200] loss: 0.005575071853653384
[Epoch 19, Batch 300] loss: 0.008413201404888469
[Epoch 19, Batch 400] loss: 0.013942986685994878
[Epoch 19, Batch 500] loss: 0.006970995456125495
[Epoch 19, Batch 600] loss: 0.03599309538898623
[Epoch 19, Batch 700] loss: 0.03554109846514095
[Epoch 19, Batch 800] loss: 0.014931287721308273
[Epoch 19, Batch 900] loss: 0.03224803797310585
[Epoch 19, Batch 1000] loss: 0.023094946538737483
[Epoch 19, Batch 1100] loss: 0.015061081091711897
[Epoch 19, Batch 1200] loss: 0.01097828240137467
[Epoch 19, Batch 1300] loss: 0.009046426003884273
[Epoch 19, Batch 1400] loss: 0.01228907643293066
[Epoch 19, Batch 1500] loss: 0.008166615652605173
[Epoch 19, Batch 1600] loss: 0.01122086493727643
[Epoch 19, Batch 1700] loss: 0.01416646734526354
[Epoch 19, Batch 1800] loss: 0.01477544465866961
[Epoch 19, Batch 1900] loss: 0.024830176788084763
[Epoch 19, Batch 2000] loss: 0.012424882607592131
[Epoch 19, Batch 2100] loss: 0.008422308139041554
[Epoch 19, Batch 2200] loss: 0.002205986915122722
[Epoch 19, Batch 2300] loss: 0.012393447775885842
[Epoch 19, Batch 2400] loss: 0.014122078323875086
[Epoch 19, Batch 2500] loss: 0.018938403081927412
[Epoch 19, Batch 2600] loss: 0.007221804672508015
[Epoch 19, Batch 2700] loss: 0.0030005245046312366
[Epoch 19, Batch 2800] loss: 0.003171721688559863
[Epoch 19, Batch 2900] loss: 0.005671871516793896
[Epoch 19, Batch 3000] loss: 0.005577655679991693
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0640
Validation Accuracy: 0.9882
Overfitting: 0.0640
[Epoch 20, Batch 100] loss: 0.0023640562861983127
[Epoch 20, Batch 200] loss: 0.0010848684091570515
[Epoch 20, Batch 300] loss: 0.0010913317932632395
[Epoch 20, Batch 400] loss: 0.006949590067664735
[Epoch 20, Batch 500] loss: 0.007808182490406526
[Epoch 20, Batch 600] loss: 0.0069673140321698315
[Epoch 20, Batch 700] loss: 0.016870460399915344
[Epoch 20, Batch 800] loss: 0.009023961603112713
[Epoch 20, Batch 900] loss: 0.0073475410152192035
[Epoch 20, Batch 1000] loss: 0.019843257072409103
[Epoch 20, Batch 1100] loss: 0.008707014638267268
[Epoch 20, Batch 1200] loss: 0.012824131044380387
[Epoch 20, Batch 1300] loss: 0.012578582050791084
[Epoch 20, Batch 1400] loss: 0.008021180666482573
[Epoch 20, Batch 1500] loss: 0.011913959061633079
[Epoch 20, Batch 1600] loss: 0.022694557954503352
[Epoch 20, Batch 1700] loss: 0.019681407635379483
[Epoch 20, Batch 1800] loss: 0.02241700529686204
[Epoch 20, Batch 1900] loss: 0.013275355617423497
[Epoch 20, Batch 2000] loss: 0.003083802257682753
[Epoch 20, Batch 2100] loss: 0.004710777837052777
[Epoch 20, Batch 2200] loss: 0.024346610712634685
[Epoch 20, Batch 2300] loss: 0.029201819555686886
[Epoch 20, Batch 2400] loss: 0.013639394517388222
[Epoch 20, Batch 2500] loss: 0.003019519351964033
[Epoch 20, Batch 2600] loss: 0.008503851254200358
[Epoch 20, Batch 2700] loss: 0.00853302606789427
[Epoch 20, Batch 2800] loss: 0.007093420161580224
[Epoch 20, Batch 2900] loss: 0.009534492478985484
[Epoch 20, Batch 3000] loss: 0.0044339344209226896
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0710
Validation Accuracy: 0.9878
Overfitting: 0.0710
[Epoch 21, Batch 100] loss: 0.0019878221802871066
[Epoch 21, Batch 200] loss: 0.0064762896864732425
[Epoch 21, Batch 300] loss: 0.020230533263465272
[Epoch 21, Batch 400] loss: 0.0204466011923925
[Epoch 21, Batch 500] loss: 0.004949137700496768
[Epoch 21, Batch 600] loss: 0.003439410671138998
[Epoch 21, Batch 700] loss: 0.0036628037572883575
[Epoch 21, Batch 800] loss: 0.003038489761471115
[Epoch 21, Batch 900] loss: 0.0016007779580117143
[Epoch 21, Batch 1000] loss: 0.004504116982113975
[Epoch 21, Batch 1100] loss: 0.0039017922486164025
[Epoch 21, Batch 1200] loss: 0.021561899311786637
[Epoch 21, Batch 1300] loss: 0.027091550183488935
[Epoch 21, Batch 1400] loss: 0.022394405053742395
[Epoch 21, Batch 1500] loss: 0.005109552472150884
[Epoch 21, Batch 1600] loss: 0.016363796295809578
[Epoch 21, Batch 1700] loss: 0.03084325922489434
[Epoch 21, Batch 1800] loss: 0.02229215522821835
[Epoch 21, Batch 1900] loss: 0.010413167469019324
[Epoch 21, Batch 2000] loss: 0.013459303407523535
[Epoch 21, Batch 2100] loss: 0.014347252936657213
[Epoch 21, Batch 2200] loss: 0.009230649754501052
[Epoch 21, Batch 2300] loss: 0.025961504502267682
[Epoch 21, Batch 2400] loss: 0.03134554120890073
[Epoch 21, Batch 2500] loss: 0.028471180487703373
[Epoch 21, Batch 2600] loss: 0.007718025636586354
[Epoch 21, Batch 2700] loss: 0.006224025638093984
[Epoch 21, Batch 2800] loss: 0.00651174818756382
[Epoch 21, Batch 2900] loss: 0.009995765561674972
[Epoch 21, Batch 3000] loss: 0.028157811245950178
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0747
Validation Accuracy: 0.9852
Overfitting: 0.0747
[Epoch 22, Batch 100] loss: 0.0033583234191556376
[Epoch 22, Batch 200] loss: 0.0072362505216127014
[Epoch 22, Batch 300] loss: 0.010931073208355797
[Epoch 22, Batch 400] loss: 0.025863386364160964
[Epoch 22, Batch 500] loss: 0.013852865608580966
[Epoch 22, Batch 600] loss: 0.027277059562907727
[Epoch 22, Batch 700] loss: 0.01673249327049031
[Epoch 22, Batch 800] loss: 0.007336073534596963
[Epoch 22, Batch 900] loss: 0.005080815345295928
[Epoch 22, Batch 1000] loss: 0.0011507145648370941
[Epoch 22, Batch 1100] loss: 0.002174177068404064
[Epoch 22, Batch 1200] loss: 0.003999882537032544
[Epoch 22, Batch 1300] loss: 0.01757249757072756
[Epoch 22, Batch 1400] loss: 0.016487523061413604
[Epoch 22, Batch 1500] loss: 0.018827483494429552
[Epoch 22, Batch 1600] loss: 0.009157808935622777
[Epoch 22, Batch 1700] loss: 0.00751695870041015
[Epoch 22, Batch 1800] loss: 0.03816187497845682
[Epoch 22, Batch 1900] loss: 0.022458977673146183
[Epoch 22, Batch 2000] loss: 0.01971282801101767
[Epoch 22, Batch 2100] loss: 0.018493847447831193
[Epoch 22, Batch 2200] loss: 0.021860687967741512
[Epoch 22, Batch 2300] loss: 0.019610193627896795
[Epoch 22, Batch 2400] loss: 0.03393601365306253
[Epoch 22, Batch 2500] loss: 0.038957446176493764
[Epoch 22, Batch 2600] loss: 0.051869947210139315
[Epoch 22, Batch 2700] loss: 0.04500673172540713
[Epoch 22, Batch 2800] loss: 0.024566215303610077
[Epoch 22, Batch 2900] loss: 0.025452916544074923
[Epoch 22, Batch 3000] loss: 0.0222138466840957
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0696
Validation Accuracy: 0.9852
Overfitting: 0.0696
[Epoch 23, Batch 100] loss: 0.012037784350447396
[Epoch 23, Batch 200] loss: 0.02148666448602853
[Epoch 23, Batch 300] loss: 0.009491898924221403
[Epoch 23, Batch 400] loss: 0.008413610835822781
[Epoch 23, Batch 500] loss: 0.01941955483674171
[Epoch 23, Batch 600] loss: 0.0034232684165017703
[Epoch 23, Batch 700] loss: 0.00814434415707879
[Epoch 23, Batch 800] loss: 0.006064492785185891
[Epoch 23, Batch 900] loss: 0.015581178115388132
[Epoch 23, Batch 1000] loss: 0.04609665678000575
[Epoch 23, Batch 1100] loss: 0.025810956557887437
[Epoch 23, Batch 1200] loss: 0.0034312607402338813
[Epoch 23, Batch 1300] loss: 0.01255490579690754
[Epoch 23, Batch 1400] loss: 0.00533111174085394
[Epoch 23, Batch 1500] loss: 0.013374158000103619
[Epoch 23, Batch 1600] loss: 0.006624839839417183
[Epoch 23, Batch 1700] loss: 0.005098927357803396
[Epoch 23, Batch 1800] loss: 0.005392467829447934
[Epoch 23, Batch 1900] loss: 0.0049975280506349895
[Epoch 23, Batch 2000] loss: 0.01689200573763221
[Epoch 23, Batch 2100] loss: 0.02021037068587912
[Epoch 23, Batch 2200] loss: 0.013170262931891408
[Epoch 23, Batch 2300] loss: 0.014086436201344789
[Epoch 23, Batch 2400] loss: 0.011837128934750538
[Epoch 23, Batch 2500] loss: 0.006533393749773935
[Epoch 23, Batch 2600] loss: 0.012539096291606006
[Epoch 23, Batch 2700] loss: 0.005863462009864433
[Epoch 23, Batch 2800] loss: 0.008209589655197904
[Epoch 23, Batch 2900] loss: 0.004431770686789327
[Epoch 23, Batch 3000] loss: 0.0050182209300196415
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.1015
Validation Accuracy: 0.9837
Overfitting: 0.1015
[Epoch 24, Batch 100] loss: 0.008146378750107952
[Epoch 24, Batch 200] loss: 0.031627453218849286
[Epoch 24, Batch 300] loss: 0.04480126867843779
[Epoch 24, Batch 400] loss: 0.03331837843321976
[Epoch 24, Batch 500] loss: 0.009363385670459414
[Epoch 24, Batch 600] loss: 0.02239460647466018
[Epoch 24, Batch 700] loss: 0.014208627512312316
[Epoch 24, Batch 800] loss: 0.017358756929975527
[Epoch 24, Batch 900] loss: 0.015886423411514593
[Epoch 24, Batch 1000] loss: 0.009989610448159816
[Epoch 24, Batch 1100] loss: 0.009476501730466165
[Epoch 24, Batch 1200] loss: 0.0035461005090553677
[Epoch 24, Batch 1300] loss: 0.0042527356799129555
[Epoch 24, Batch 1400] loss: 0.006024538338122394
[Epoch 24, Batch 1500] loss: 0.004727018691804776
[Epoch 24, Batch 1600] loss: 0.02190153736740953
[Epoch 24, Batch 1700] loss: 0.023886207561286524
[Epoch 24, Batch 1800] loss: 0.014528206863239208
[Epoch 24, Batch 1900] loss: 0.0051420381372294655
[Epoch 24, Batch 2000] loss: 0.009958114111146861
[Epoch 24, Batch 2100] loss: 0.015432294662724794
[Epoch 24, Batch 2200] loss: 0.010553959299746668
[Epoch 24, Batch 2300] loss: 0.04768467105051975
[Epoch 24, Batch 2400] loss: 0.01982639919593583
[Epoch 24, Batch 2500] loss: 0.01132317693339025
[Epoch 24, Batch 2600] loss: 0.024480524775652747
[Epoch 24, Batch 2700] loss: 0.030042490408669357
[Epoch 24, Batch 2800] loss: 0.020504789338821886
[Epoch 24, Batch 2900] loss: 0.036889819374189725
[Epoch 24, Batch 3000] loss: 0.01436808448722971
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0752
Validation Accuracy: 0.9874
Overfitting: 0.0752
Fold 5 validation loss: 0.0752
Mean validation loss across all folds for Trial 4 is 0.0827 with trial config:  l1: 128, l2: 128, lr: 0.00853618986286683, batch_size: 16
[I 2024-12-11 02:45:56,885] Trial 3 finished with value: 0.08271378804401155 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.00853618986286683, 'batch_size': 16}. Best is trial 2 with value: 0.05102975802061105.

Selected Hyperparameters for Trial 5:
  l1: 256, l2: 128, lr: 0.00032927591344236165, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3047276163101196
[Epoch 1, Batch 200] loss: 2.298876266479492
[Epoch 1, Batch 300] loss: 2.2939349102973936
[Epoch 1, Batch 400] loss: 2.2900767374038695
[Epoch 1, Batch 500] loss: 2.28693098783493
[Epoch 1, Batch 600] loss: 2.281325078010559
[Epoch 1, Batch 700] loss: 2.2730445408821107
[Epoch 1, Batch 800] loss: 2.2603996872901915
[Epoch 1, Batch 900] loss: 2.2435225105285643
[Epoch 1, Batch 1000] loss: 2.217412040233612
[Epoch 1, Batch 1100] loss: 2.18225302696228
[Epoch 1, Batch 1200] loss: 2.110640697479248
[Epoch 1, Batch 1300] loss: 1.9499711382389069
[Epoch 1, Batch 1400] loss: 1.6104422056674956
[Epoch 1, Batch 1500] loss: 1.1355823385715484
[Epoch 1, Batch 1600] loss: 0.7794660004973412
[Epoch 1, Batch 1700] loss: 0.6312723024189473
[Epoch 1, Batch 1800] loss: 0.5296493965387344
[Epoch 1, Batch 1900] loss: 0.4440132408589125
[Epoch 1, Batch 2000] loss: 0.3917115346342325
[Epoch 1, Batch 2100] loss: 0.43813954286277296
[Epoch 1, Batch 2200] loss: 0.38497905910015107
[Epoch 1, Batch 2300] loss: 0.34719943668693304
[Epoch 1, Batch 2400] loss: 0.3341075903922319
[Epoch 1, Batch 2500] loss: 0.32126516388729215
[Epoch 1, Batch 2600] loss: 0.29420975007116795
[Epoch 1, Batch 2700] loss: 0.30380375679582355
[Epoch 1, Batch 2800] loss: 0.26606841530650854
[Epoch 1, Batch 2900] loss: 0.3198243824392557
[Epoch 1, Batch 3000] loss: 0.24048489816486834
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2517
Validation Accuracy: 0.9256
Overfitting: 0.2517
Best model saved at epoch 1 with validation loss: 0.2517
[Epoch 2, Batch 100] loss: 0.24196114905178548
[Epoch 2, Batch 200] loss: 0.2682126462459564
[Epoch 2, Batch 300] loss: 0.2579529413022101
[Epoch 2, Batch 400] loss: 0.23190793013200164
[Epoch 2, Batch 500] loss: 0.2600722290016711
[Epoch 2, Batch 600] loss: 0.24936501029878855
[Epoch 2, Batch 700] loss: 0.25608316307887435
[Epoch 2, Batch 800] loss: 0.21354395700618625
[Epoch 2, Batch 900] loss: 0.2198769679106772
[Epoch 2, Batch 1000] loss: 0.19066206393763424
[Epoch 2, Batch 1100] loss: 0.21669292772188783
[Epoch 2, Batch 1200] loss: 0.21514262417331337
[Epoch 2, Batch 1300] loss: 0.18753061599098145
[Epoch 2, Batch 1400] loss: 0.20640095002017916
[Epoch 2, Batch 1500] loss: 0.21852259775623678
[Epoch 2, Batch 1600] loss: 0.2094999090395868
[Epoch 2, Batch 1700] loss: 0.2021209845133126
[Epoch 2, Batch 1800] loss: 0.16130326399579645
[Epoch 2, Batch 1900] loss: 0.1761745554767549
[Epoch 2, Batch 2000] loss: 0.16786307941190898
[Epoch 2, Batch 2100] loss: 0.18214010239578785
[Epoch 2, Batch 2200] loss: 0.16791890599764883
[Epoch 2, Batch 2300] loss: 0.17802288247272371
[Epoch 2, Batch 2400] loss: 0.17418869559653102
[Epoch 2, Batch 2500] loss: 0.16974675791338087
[Epoch 2, Batch 2600] loss: 0.14988088130950927
[Epoch 2, Batch 2700] loss: 0.12683206076268105
[Epoch 2, Batch 2800] loss: 0.135772614646703
[Epoch 2, Batch 2900] loss: 0.1960352405626327
[Epoch 2, Batch 3000] loss: 0.14577793325763197
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1359
Validation Accuracy: 0.9597
Overfitting: 0.1359
Best model saved at epoch 2 with validation loss: 0.1359
[Epoch 3, Batch 100] loss: 0.14977419110946358
[Epoch 3, Batch 200] loss: 0.11671771728433669
[Epoch 3, Batch 300] loss: 0.14286558560561388
[Epoch 3, Batch 400] loss: 0.1485846898704767
[Epoch 3, Batch 500] loss: 0.10745852577500045
[Epoch 3, Batch 600] loss: 0.11357027243357151
[Epoch 3, Batch 700] loss: 0.14141721853520722
[Epoch 3, Batch 800] loss: 0.12619237726088614
[Epoch 3, Batch 900] loss: 0.13349850146099926
[Epoch 3, Batch 1000] loss: 0.1449848672747612
[Epoch 3, Batch 1100] loss: 0.13531833193264903
[Epoch 3, Batch 1200] loss: 0.14109035996254535
[Epoch 3, Batch 1300] loss: 0.1369256893917918
[Epoch 3, Batch 1400] loss: 0.13353507787920535
[Epoch 3, Batch 1500] loss: 0.14918862689752133
[Epoch 3, Batch 1600] loss: 0.1255529490346089
[Epoch 3, Batch 1700] loss: 0.12601117183454336
[Epoch 3, Batch 1800] loss: 0.1426578774675727
[Epoch 3, Batch 1900] loss: 0.13764053762424738
[Epoch 3, Batch 2000] loss: 0.10330272180959582
[Epoch 3, Batch 2100] loss: 0.1211377606948372
[Epoch 3, Batch 2200] loss: 0.1372617534198798
[Epoch 3, Batch 2300] loss: 0.14719537733122706
[Epoch 3, Batch 2400] loss: 0.11237525419564917
[Epoch 3, Batch 2500] loss: 0.12498289234004915
[Epoch 3, Batch 2600] loss: 0.11448528598528356
[Epoch 3, Batch 2700] loss: 0.10823678382206708
[Epoch 3, Batch 2800] loss: 0.11544732306385413
[Epoch 3, Batch 2900] loss: 0.11756293882383034
[Epoch 3, Batch 3000] loss: 0.12123804952949285
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1056
Validation Accuracy: 0.9689
Overfitting: 0.1056
Best model saved at epoch 3 with validation loss: 0.1056
[Epoch 4, Batch 100] loss: 0.09862395030446351
[Epoch 4, Batch 200] loss: 0.10763559072744101
[Epoch 4, Batch 300] loss: 0.16405287643428892
[Epoch 4, Batch 400] loss: 0.08080885312054306
[Epoch 4, Batch 500] loss: 0.11420244677457958
[Epoch 4, Batch 600] loss: 0.1108889986667782
[Epoch 4, Batch 700] loss: 0.0919807676761411
[Epoch 4, Batch 800] loss: 0.11064215810620226
[Epoch 4, Batch 900] loss: 0.10900756821967661
[Epoch 4, Batch 1000] loss: 0.10709411958698184
[Epoch 4, Batch 1100] loss: 0.12177568562095985
[Epoch 4, Batch 1200] loss: 0.09731695491820574
[Epoch 4, Batch 1300] loss: 0.08993182364851236
[Epoch 4, Batch 1400] loss: 0.09989920273656025
[Epoch 4, Batch 1500] loss: 0.10523669360205531
[Epoch 4, Batch 1600] loss: 0.10134944290854037
[Epoch 4, Batch 1700] loss: 0.11416133399121463
[Epoch 4, Batch 1800] loss: 0.10016975857783109
[Epoch 4, Batch 1900] loss: 0.07523096624063327
[Epoch 4, Batch 2000] loss: 0.10236030558589845
[Epoch 4, Batch 2100] loss: 0.09629574432736263
[Epoch 4, Batch 2200] loss: 0.08995307395234704
[Epoch 4, Batch 2300] loss: 0.11096124566509388
[Epoch 4, Batch 2400] loss: 0.07824748984538019
[Epoch 4, Batch 2500] loss: 0.07490397981135175
[Epoch 4, Batch 2600] loss: 0.08699267569696531
[Epoch 4, Batch 2700] loss: 0.08334756653290241
[Epoch 4, Batch 2800] loss: 0.09040967781445942
[Epoch 4, Batch 2900] loss: 0.09477778266882524
[Epoch 4, Batch 3000] loss: 0.07897791024763137
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0812
Validation Accuracy: 0.9748
Overfitting: 0.0812
Best model saved at epoch 4 with validation loss: 0.0812
[Epoch 5, Batch 100] loss: 0.08832160685444251
[Epoch 5, Batch 200] loss: 0.10651602269383148
[Epoch 5, Batch 300] loss: 0.10824156992137432
[Epoch 5, Batch 400] loss: 0.06761541343177668
[Epoch 5, Batch 500] loss: 0.09350562181323767
[Epoch 5, Batch 600] loss: 0.06933668309007772
[Epoch 5, Batch 700] loss: 0.07979321725782938
[Epoch 5, Batch 800] loss: 0.07418092102918308
[Epoch 5, Batch 900] loss: 0.07688607451622374
[Epoch 5, Batch 1000] loss: 0.08219545548781752
[Epoch 5, Batch 1100] loss: 0.08934463991434313
[Epoch 5, Batch 1200] loss: 0.08797624409082345
[Epoch 5, Batch 1300] loss: 0.0871063291595783
[Epoch 5, Batch 1400] loss: 0.09917057636659593
[Epoch 5, Batch 1500] loss: 0.08224231502157636
[Epoch 5, Batch 1600] loss: 0.11671245562145487
[Epoch 5, Batch 1700] loss: 0.06600591048132629
[Epoch 5, Batch 1800] loss: 0.07138057510601356
[Epoch 5, Batch 1900] loss: 0.0720089958840981
[Epoch 5, Batch 2000] loss: 0.08563265371834859
[Epoch 5, Batch 2100] loss: 0.0860348236223217
[Epoch 5, Batch 2200] loss: 0.08369066766696051
[Epoch 5, Batch 2300] loss: 0.08178732942556963
[Epoch 5, Batch 2400] loss: 0.07187381285242736
[Epoch 5, Batch 2500] loss: 0.07463664990034885
[Epoch 5, Batch 2600] loss: 0.06407647160405759
[Epoch 5, Batch 2700] loss: 0.08031620407185983
[Epoch 5, Batch 2800] loss: 0.07439457363449037
[Epoch 5, Batch 2900] loss: 0.1012985642667627
[Epoch 5, Batch 3000] loss: 0.08550326686585322
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0851
Validation Accuracy: 0.9746
Overfitting: 0.0851
[Epoch 6, Batch 100] loss: 0.08066567800007761
[Epoch 6, Batch 200] loss: 0.06471602705540136
[Epoch 6, Batch 300] loss: 0.07985840261098928
[Epoch 6, Batch 400] loss: 0.06921171321009752
[Epoch 6, Batch 500] loss: 0.07529349518415984
[Epoch 6, Batch 600] loss: 0.07674803241156042
[Epoch 6, Batch 700] loss: 0.07626324654906057
[Epoch 6, Batch 800] loss: 0.06226984097680543
[Epoch 6, Batch 900] loss: 0.06543243087711743
[Epoch 6, Batch 1000] loss: 0.07250567729584873
[Epoch 6, Batch 1100] loss: 0.0910244232590776
[Epoch 6, Batch 1200] loss: 0.06511737365275622
[Epoch 6, Batch 1300] loss: 0.08776809243601746
[Epoch 6, Batch 1400] loss: 0.06766182110528461
[Epoch 6, Batch 1500] loss: 0.08296809166611638
[Epoch 6, Batch 1600] loss: 0.05331492103287019
[Epoch 6, Batch 1700] loss: 0.056580334119498726
[Epoch 6, Batch 1800] loss: 0.05709219015669078
[Epoch 6, Batch 1900] loss: 0.05176802418893203
[Epoch 6, Batch 2000] loss: 0.08047284698230214
[Epoch 6, Batch 2100] loss: 0.056189449576777406
[Epoch 6, Batch 2200] loss: 0.06940642597561236
[Epoch 6, Batch 2300] loss: 0.07876837763993536
[Epoch 6, Batch 2400] loss: 0.07379628280294127
[Epoch 6, Batch 2500] loss: 0.05683514050731901
[Epoch 6, Batch 2600] loss: 0.06885833833133802
[Epoch 6, Batch 2700] loss: 0.08138799049076624
[Epoch 6, Batch 2800] loss: 0.08423907244927249
[Epoch 6, Batch 2900] loss: 0.08512724744621664
[Epoch 6, Batch 3000] loss: 0.08111428396077827
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0708
Validation Accuracy: 0.9772
Overfitting: 0.0708
Best model saved at epoch 6 with validation loss: 0.0708
[Epoch 7, Batch 100] loss: 0.055875188246136534
[Epoch 7, Batch 200] loss: 0.07473193005542271
[Epoch 7, Batch 300] loss: 0.06507940807379782
[Epoch 7, Batch 400] loss: 0.0738069366873242
[Epoch 7, Batch 500] loss: 0.06958259201608598
[Epoch 7, Batch 600] loss: 0.06124705380992964
[Epoch 7, Batch 700] loss: 0.0586126903980039
[Epoch 7, Batch 800] loss: 0.049657196023035796
[Epoch 7, Batch 900] loss: 0.07618326938711106
[Epoch 7, Batch 1000] loss: 0.06642366543179377
[Epoch 7, Batch 1100] loss: 0.06976845499593765
[Epoch 7, Batch 1200] loss: 0.07486973748658783
[Epoch 7, Batch 1300] loss: 0.06080181301513221
[Epoch 7, Batch 1400] loss: 0.06226202717283741
[Epoch 7, Batch 1500] loss: 0.05779934983234852
[Epoch 7, Batch 1600] loss: 0.06956969605875202
[Epoch 7, Batch 1700] loss: 0.07469324238947593
[Epoch 7, Batch 1800] loss: 0.06018156429112423
[Epoch 7, Batch 1900] loss: 0.04768168804090237
[Epoch 7, Batch 2000] loss: 0.06249522334721405
[Epoch 7, Batch 2100] loss: 0.06110519957612268
[Epoch 7, Batch 2200] loss: 0.058053046788554635
[Epoch 7, Batch 2300] loss: 0.07597056542872452
[Epoch 7, Batch 2400] loss: 0.0634660224034451
[Epoch 7, Batch 2500] loss: 0.0522318352968432
[Epoch 7, Batch 2600] loss: 0.058702035970054564
[Epoch 7, Batch 2700] loss: 0.05630406705895439
[Epoch 7, Batch 2800] loss: 0.06591660175879951
[Epoch 7, Batch 2900] loss: 0.04820875189034268
[Epoch 7, Batch 3000] loss: 0.05752828907134244
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9803
Overfitting: 0.0630
Best model saved at epoch 7 with validation loss: 0.0630
[Epoch 8, Batch 100] loss: 0.066817443119362
[Epoch 8, Batch 200] loss: 0.05837716102134436
[Epoch 8, Batch 300] loss: 0.05089283903536852
[Epoch 8, Batch 400] loss: 0.05049732542887796
[Epoch 8, Batch 500] loss: 0.07593207385973073
[Epoch 8, Batch 600] loss: 0.051411009697476404
[Epoch 8, Batch 700] loss: 0.05416413994855247
[Epoch 8, Batch 800] loss: 0.04995595222455449
[Epoch 8, Batch 900] loss: 0.0564466563356109
[Epoch 8, Batch 1000] loss: 0.0582709915790474
[Epoch 8, Batch 1100] loss: 0.0544110924412962
[Epoch 8, Batch 1200] loss: 0.06476891224971042
[Epoch 8, Batch 1300] loss: 0.060721354021225124
[Epoch 8, Batch 1400] loss: 0.0586726745555643
[Epoch 8, Batch 1500] loss: 0.04416001305799
[Epoch 8, Batch 1600] loss: 0.04061997020762646
[Epoch 8, Batch 1700] loss: 0.07158531701235915
[Epoch 8, Batch 1800] loss: 0.06777566039585509
[Epoch 8, Batch 1900] loss: 0.06545165406365414
[Epoch 8, Batch 2000] loss: 0.07729667924751993
[Epoch 8, Batch 2100] loss: 0.0488206288011861
[Epoch 8, Batch 2200] loss: 0.06117113106214674
[Epoch 8, Batch 2300] loss: 0.06870034892577678
[Epoch 8, Batch 2400] loss: 0.0408381691458635
[Epoch 8, Batch 2500] loss: 0.06491406979970633
[Epoch 8, Batch 2600] loss: 0.0586455137754092
[Epoch 8, Batch 2700] loss: 0.04539845738327131
[Epoch 8, Batch 2800] loss: 0.060386513840348925
[Epoch 8, Batch 2900] loss: 0.05221383790834807
[Epoch 8, Batch 3000] loss: 0.04790645918692462
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0627
Validation Accuracy: 0.9806
Overfitting: 0.0627
Best model saved at epoch 8 with validation loss: 0.0627
[Epoch 9, Batch 100] loss: 0.0535249481536448
[Epoch 9, Batch 200] loss: 0.037288923289161176
[Epoch 9, Batch 300] loss: 0.03985154761292506
[Epoch 9, Batch 400] loss: 0.05873846842747298
[Epoch 9, Batch 500] loss: 0.05490285838022828
[Epoch 9, Batch 600] loss: 0.057827109939535146
[Epoch 9, Batch 700] loss: 0.04777850628364831
[Epoch 9, Batch 800] loss: 0.05235212441170006
[Epoch 9, Batch 900] loss: 0.05961855623929296
[Epoch 9, Batch 1000] loss: 0.04609254207578488
[Epoch 9, Batch 1100] loss: 0.05178538357722573
[Epoch 9, Batch 1200] loss: 0.05118196072522551
[Epoch 9, Batch 1300] loss: 0.052368327270960434
[Epoch 9, Batch 1400] loss: 0.057252229368314145
[Epoch 9, Batch 1500] loss: 0.042616487266786865
[Epoch 9, Batch 1600] loss: 0.04423542313335929
[Epoch 9, Batch 1700] loss: 0.04702812674921006
[Epoch 9, Batch 1800] loss: 0.05016027404519264
[Epoch 9, Batch 1900] loss: 0.03630453720572405
[Epoch 9, Batch 2000] loss: 0.04005477643077029
[Epoch 9, Batch 2100] loss: 0.06573032296873862
[Epoch 9, Batch 2200] loss: 0.05066206615389092
[Epoch 9, Batch 2300] loss: 0.05220900002575945
[Epoch 9, Batch 2400] loss: 0.05567314674481168
[Epoch 9, Batch 2500] loss: 0.038685391497274395
[Epoch 9, Batch 2600] loss: 0.05107961569854524
[Epoch 9, Batch 2700] loss: 0.05026358075498138
[Epoch 9, Batch 2800] loss: 0.05814620008910424
[Epoch 9, Batch 2900] loss: 0.058300918074673976
[Epoch 9, Batch 3000] loss: 0.05896441657911055
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0612
Validation Accuracy: 0.9820
Overfitting: 0.0612
Best model saved at epoch 9 with validation loss: 0.0612
[Epoch 10, Batch 100] loss: 0.04729914424970048
[Epoch 10, Batch 200] loss: 0.0435764043481322
[Epoch 10, Batch 300] loss: 0.05669669224298559
[Epoch 10, Batch 400] loss: 0.034205123031279074
[Epoch 10, Batch 500] loss: 0.051985667498665865
[Epoch 10, Batch 600] loss: 0.037517923996783796
[Epoch 10, Batch 700] loss: 0.04820080540608615
[Epoch 10, Batch 800] loss: 0.051128365244949237
[Epoch 10, Batch 900] loss: 0.04421579892426962
[Epoch 10, Batch 1000] loss: 0.05494625499704853
[Epoch 10, Batch 1100] loss: 0.03873040526465047
[Epoch 10, Batch 1200] loss: 0.05206901015189942
[Epoch 10, Batch 1300] loss: 0.059462145566067194
[Epoch 10, Batch 1400] loss: 0.07118092379852897
[Epoch 10, Batch 1500] loss: 0.04157110027153976
[Epoch 10, Batch 1600] loss: 0.039705563715833704
[Epoch 10, Batch 1700] loss: 0.04112697120464873
[Epoch 10, Batch 1800] loss: 0.06040132826892659
[Epoch 10, Batch 1900] loss: 0.047370264426572245
[Epoch 10, Batch 2000] loss: 0.03567161463550292
[Epoch 10, Batch 2100] loss: 0.05126623210031539
[Epoch 10, Batch 2200] loss: 0.04335792927828152
[Epoch 10, Batch 2300] loss: 0.048766499405610376
[Epoch 10, Batch 2400] loss: 0.02940605970856268
[Epoch 10, Batch 2500] loss: 0.03856508919619955
[Epoch 10, Batch 2600] loss: 0.04900954375727452
[Epoch 10, Batch 2700] loss: 0.04214807065771311
[Epoch 10, Batch 2800] loss: 0.04711454955016961
[Epoch 10, Batch 2900] loss: 0.03661150772328256
[Epoch 10, Batch 3000] loss: 0.04862385705549968
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9818
Overfitting: 0.0567
Best model saved at epoch 10 with validation loss: 0.0567
[Epoch 11, Batch 100] loss: 0.047694945821422155
[Epoch 11, Batch 200] loss: 0.040465075714309934
[Epoch 11, Batch 300] loss: 0.03759031105371832
[Epoch 11, Batch 400] loss: 0.03400606308190618
[Epoch 11, Batch 500] loss: 0.037225887044623956
[Epoch 11, Batch 600] loss: 0.03632570149260573
[Epoch 11, Batch 700] loss: 0.03274982905422803
[Epoch 11, Batch 800] loss: 0.06479389981745044
[Epoch 11, Batch 900] loss: 0.04686481108627049
[Epoch 11, Batch 1000] loss: 0.052242415823275226
[Epoch 11, Batch 1100] loss: 0.04222298306849552
[Epoch 11, Batch 1200] loss: 0.04359485559747554
[Epoch 11, Batch 1300] loss: 0.041021770880324764
[Epoch 11, Batch 1400] loss: 0.0414944980450673
[Epoch 11, Batch 1500] loss: 0.03137097801518394
[Epoch 11, Batch 1600] loss: 0.03968862136258394
[Epoch 11, Batch 1700] loss: 0.036001474319491536
[Epoch 11, Batch 1800] loss: 0.0633097854036896
[Epoch 11, Batch 1900] loss: 0.04249344523967011
[Epoch 11, Batch 2000] loss: 0.03508732234942727
[Epoch 11, Batch 2100] loss: 0.03290502725052647
[Epoch 11, Batch 2200] loss: 0.049350605108775196
[Epoch 11, Batch 2300] loss: 0.05524531838178518
[Epoch 11, Batch 2400] loss: 0.04199258058622945
[Epoch 11, Batch 2500] loss: 0.04385703625681345
[Epoch 11, Batch 2600] loss: 0.05023564892602735
[Epoch 11, Batch 2700] loss: 0.040962162313007866
[Epoch 11, Batch 2800] loss: 0.045635821702016986
[Epoch 11, Batch 2900] loss: 0.03844102671107976
[Epoch 11, Batch 3000] loss: 0.04065574511740124
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0622
Validation Accuracy: 0.9816
Overfitting: 0.0622
[Epoch 12, Batch 100] loss: 0.030722198719740846
[Epoch 12, Batch 200] loss: 0.03221256484277547
[Epoch 12, Batch 300] loss: 0.05237294684273366
[Epoch 12, Batch 400] loss: 0.050462302981759424
[Epoch 12, Batch 500] loss: 0.026589542112196794
[Epoch 12, Batch 600] loss: 0.04871701834606938
[Epoch 12, Batch 700] loss: 0.04147694883082295
[Epoch 12, Batch 800] loss: 0.03948346190882148
[Epoch 12, Batch 900] loss: 0.027537353021034505
[Epoch 12, Batch 1000] loss: 0.042845855718187525
[Epoch 12, Batch 1100] loss: 0.039232847965322434
[Epoch 12, Batch 1200] loss: 0.04387772024929291
[Epoch 12, Batch 1300] loss: 0.026389197435055394
[Epoch 12, Batch 1400] loss: 0.05854159866576083
[Epoch 12, Batch 1500] loss: 0.040547261759347746
[Epoch 12, Batch 1600] loss: 0.042977604277257345
[Epoch 12, Batch 1700] loss: 0.03882433839433361
[Epoch 12, Batch 1800] loss: 0.038173797709168865
[Epoch 12, Batch 1900] loss: 0.037551709823019336
[Epoch 12, Batch 2000] loss: 0.0411788332494325
[Epoch 12, Batch 2100] loss: 0.041623572999669706
[Epoch 12, Batch 2200] loss: 0.029520664935407694
[Epoch 12, Batch 2300] loss: 0.039044359924446326
[Epoch 12, Batch 2400] loss: 0.03541589638974983
[Epoch 12, Batch 2500] loss: 0.04299556365571334
[Epoch 12, Batch 2600] loss: 0.036334013883315495
[Epoch 12, Batch 2700] loss: 0.05049684235753375
[Epoch 12, Batch 2800] loss: 0.030080166972475127
[Epoch 12, Batch 2900] loss: 0.04487153583977488
[Epoch 12, Batch 3000] loss: 0.02907980676915031
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9841
Overfitting: 0.0520
Best model saved at epoch 12 with validation loss: 0.0520
[Epoch 13, Batch 100] loss: 0.035082537224370755
[Epoch 13, Batch 200] loss: 0.03288334694691002
[Epoch 13, Batch 300] loss: 0.030390942338854074
[Epoch 13, Batch 400] loss: 0.04199587081355276
[Epoch 13, Batch 500] loss: 0.03312938605326053
[Epoch 13, Batch 600] loss: 0.03480710132920649
[Epoch 13, Batch 700] loss: 0.03613622864242643
[Epoch 13, Batch 800] loss: 0.03581539002989302
[Epoch 13, Batch 900] loss: 0.03755534113472095
[Epoch 13, Batch 1000] loss: 0.05216070772847161
[Epoch 13, Batch 1100] loss: 0.026163278149324468
[Epoch 13, Batch 1200] loss: 0.03853519746437087
[Epoch 13, Batch 1300] loss: 0.03916951078746934
[Epoch 13, Batch 1400] loss: 0.030541007331194123
[Epoch 13, Batch 1500] loss: 0.025649672701765668
[Epoch 13, Batch 1600] loss: 0.039998620984843
[Epoch 13, Batch 1700] loss: 0.03273853150589275
[Epoch 13, Batch 1800] loss: 0.04290856945619453
[Epoch 13, Batch 1900] loss: 0.04317975047713844
[Epoch 13, Batch 2000] loss: 0.03910365915820876
[Epoch 13, Batch 2100] loss: 0.047593840723420724
[Epoch 13, Batch 2200] loss: 0.03181386616735835
[Epoch 13, Batch 2300] loss: 0.0404557872658188
[Epoch 13, Batch 2400] loss: 0.04222665632900316
[Epoch 13, Batch 2500] loss: 0.0206820992417488
[Epoch 13, Batch 2600] loss: 0.04221934365748894
[Epoch 13, Batch 2700] loss: 0.038697182084433734
[Epoch 13, Batch 2800] loss: 0.04372238391311839
[Epoch 13, Batch 2900] loss: 0.024036400667682756
[Epoch 13, Batch 3000] loss: 0.02866699353318836
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0503
Validation Accuracy: 0.9855
Overfitting: 0.0503
Best model saved at epoch 13 with validation loss: 0.0503
[Epoch 14, Batch 100] loss: 0.02493873870873358
[Epoch 14, Batch 200] loss: 0.02419615862396313
[Epoch 14, Batch 300] loss: 0.027934528086334467
[Epoch 14, Batch 400] loss: 0.029208388298429783
[Epoch 14, Batch 500] loss: 0.03936243955307873
[Epoch 14, Batch 600] loss: 0.034102071387314935
[Epoch 14, Batch 700] loss: 0.027894007855211386
[Epoch 14, Batch 800] loss: 0.031608356926590205
[Epoch 14, Batch 900] loss: 0.036409493652899985
[Epoch 14, Batch 1000] loss: 0.033805648611451036
[Epoch 14, Batch 1100] loss: 0.040202519506856334
[Epoch 14, Batch 1200] loss: 0.031169171209767227
[Epoch 14, Batch 1300] loss: 0.026698849310632794
[Epoch 14, Batch 1400] loss: 0.04331548414855206
[Epoch 14, Batch 1500] loss: 0.032882348130951866
[Epoch 14, Batch 1600] loss: 0.04654446768516209
[Epoch 14, Batch 1700] loss: 0.032425355251325526
[Epoch 14, Batch 1800] loss: 0.02857197446959617
[Epoch 14, Batch 1900] loss: 0.03661847175040748
[Epoch 14, Batch 2000] loss: 0.02830296996748075
[Epoch 14, Batch 2100] loss: 0.03180581508480827
[Epoch 14, Batch 2200] loss: 0.034415068096750476
[Epoch 14, Batch 2300] loss: 0.03146376115910243
[Epoch 14, Batch 2400] loss: 0.02687429560770397
[Epoch 14, Batch 2500] loss: 0.032035486599706925
[Epoch 14, Batch 2600] loss: 0.03831759381107986
[Epoch 14, Batch 2700] loss: 0.03611961927934317
[Epoch 14, Batch 2800] loss: 0.034144168955972415
[Epoch 14, Batch 2900] loss: 0.0376716720002878
[Epoch 14, Batch 3000] loss: 0.043792827478937396
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9845
Overfitting: 0.0505
[Epoch 15, Batch 100] loss: 0.02406529804720776
[Epoch 15, Batch 200] loss: 0.02813255012690206
[Epoch 15, Batch 300] loss: 0.03366437004733598
[Epoch 15, Batch 400] loss: 0.0348633366348804
[Epoch 15, Batch 500] loss: 0.03454166343741236
[Epoch 15, Batch 600] loss: 0.039674084959951866
[Epoch 15, Batch 700] loss: 0.03919665179317235
[Epoch 15, Batch 800] loss: 0.038786984491162003
[Epoch 15, Batch 900] loss: 0.028288524804083864
[Epoch 15, Batch 1000] loss: 0.03803862288958044
[Epoch 15, Batch 1100] loss: 0.036096583627222574
[Epoch 15, Batch 1200] loss: 0.030535311243147588
[Epoch 15, Batch 1300] loss: 0.027037158752646066
[Epoch 15, Batch 1400] loss: 0.022589978386531585
[Epoch 15, Batch 1500] loss: 0.02670305517160159
[Epoch 15, Batch 1600] loss: 0.027795662649950828
[Epoch 15, Batch 1700] loss: 0.02995292990366579
[Epoch 15, Batch 1800] loss: 0.04000146299775224
[Epoch 15, Batch 1900] loss: 0.04597726063155278
[Epoch 15, Batch 2000] loss: 0.02933400118010468
[Epoch 15, Batch 2100] loss: 0.03164585807717231
[Epoch 15, Batch 2200] loss: 0.042013312018534636
[Epoch 15, Batch 2300] loss: 0.023920663425378734
[Epoch 15, Batch 2400] loss: 0.025669974555494263
[Epoch 15, Batch 2500] loss: 0.035392993302666584
[Epoch 15, Batch 2600] loss: 0.025457039372849977
[Epoch 15, Batch 2700] loss: 0.02752513423169148
[Epoch 15, Batch 2800] loss: 0.019973780889995397
[Epoch 15, Batch 2900] loss: 0.02772728246782208
[Epoch 15, Batch 3000] loss: 0.02962616518871073
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9847
Overfitting: 0.0477
Best model saved at epoch 15 with validation loss: 0.0477
[Epoch 16, Batch 100] loss: 0.02362808396850596
[Epoch 16, Batch 200] loss: 0.02024079412498395
[Epoch 16, Batch 300] loss: 0.03059580069806543
[Epoch 16, Batch 400] loss: 0.01591801828108146
[Epoch 16, Batch 500] loss: 0.0336659717434668
[Epoch 16, Batch 600] loss: 0.02314959620067384
[Epoch 16, Batch 700] loss: 0.028656511330555075
[Epoch 16, Batch 800] loss: 0.03036910057926434
[Epoch 16, Batch 900] loss: 0.030412263888338203
[Epoch 16, Batch 1000] loss: 0.021625219026682317
[Epoch 16, Batch 1100] loss: 0.03500552457804588
[Epoch 16, Batch 1200] loss: 0.01846388525373186
[Epoch 16, Batch 1300] loss: 0.036622959763117253
[Epoch 16, Batch 1400] loss: 0.028412006755279436
[Epoch 16, Batch 1500] loss: 0.019067400143903797
[Epoch 16, Batch 1600] loss: 0.02923751072055893
[Epoch 16, Batch 1700] loss: 0.030685919396310057
[Epoch 16, Batch 1800] loss: 0.032478550078812986
[Epoch 16, Batch 1900] loss: 0.024772499893806525
[Epoch 16, Batch 2000] loss: 0.04269238447101088
[Epoch 16, Batch 2100] loss: 0.027168867505242816
[Epoch 16, Batch 2200] loss: 0.03248859122453723
[Epoch 16, Batch 2300] loss: 0.02793672195810359
[Epoch 16, Batch 2400] loss: 0.030816235134734596
[Epoch 16, Batch 2500] loss: 0.04162533579074079
[Epoch 16, Batch 2600] loss: 0.027171723486389965
[Epoch 16, Batch 2700] loss: 0.027968054699304048
[Epoch 16, Batch 2800] loss: 0.02754850817087572
[Epoch 16, Batch 2900] loss: 0.031766687019407984
[Epoch 16, Batch 3000] loss: 0.03417889374410152
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9846
Overfitting: 0.0493
[Epoch 17, Batch 100] loss: 0.021778427823155654
[Epoch 17, Batch 200] loss: 0.019920325671191678
[Epoch 17, Batch 300] loss: 0.029551817112369462
[Epoch 17, Batch 400] loss: 0.01914026564147207
[Epoch 17, Batch 500] loss: 0.026165279323504365
[Epoch 17, Batch 600] loss: 0.02231366209423868
[Epoch 17, Batch 700] loss: 0.022238396133761853
[Epoch 17, Batch 800] loss: 0.02350098634160531
[Epoch 17, Batch 900] loss: 0.026722596852414425
[Epoch 17, Batch 1000] loss: 0.03217309987761837
[Epoch 17, Batch 1100] loss: 0.02797561698629579
[Epoch 17, Batch 1200] loss: 0.019511691194056765
[Epoch 17, Batch 1300] loss: 0.022725220304273534
[Epoch 17, Batch 1400] loss: 0.02313020092988154
[Epoch 17, Batch 1500] loss: 0.029947900392435257
[Epoch 17, Batch 1600] loss: 0.04201664372929372
[Epoch 17, Batch 1700] loss: 0.028083723750605714
[Epoch 17, Batch 1800] loss: 0.025789076078945074
[Epoch 17, Batch 1900] loss: 0.02106596858102421
[Epoch 17, Batch 2000] loss: 0.02478973755009065
[Epoch 17, Batch 2100] loss: 0.02186282228314667
[Epoch 17, Batch 2200] loss: 0.023989394619056838
[Epoch 17, Batch 2300] loss: 0.042489877668049306
[Epoch 17, Batch 2400] loss: 0.02726630603945523
[Epoch 17, Batch 2500] loss: 0.03349387713751639
[Epoch 17, Batch 2600] loss: 0.034486049995903156
[Epoch 17, Batch 2700] loss: 0.030751580110118085
[Epoch 17, Batch 2800] loss: 0.02757571746391477
[Epoch 17, Batch 2900] loss: 0.02824279224310885
[Epoch 17, Batch 3000] loss: 0.023991569234549388
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9861
Overfitting: 0.0449
Best model saved at epoch 17 with validation loss: 0.0449
[Epoch 18, Batch 100] loss: 0.021214538214553613
[Epoch 18, Batch 200] loss: 0.020223886744061018
[Epoch 18, Batch 300] loss: 0.028404884071060222
[Epoch 18, Batch 400] loss: 0.02168234326207312
[Epoch 18, Batch 500] loss: 0.023556962879083584
[Epoch 18, Batch 600] loss: 0.031002232532628113
[Epoch 18, Batch 700] loss: 0.02296925356691645
[Epoch 18, Batch 800] loss: 0.029014396207785467
[Epoch 18, Batch 900] loss: 0.022112686394611957
[Epoch 18, Batch 1000] loss: 0.03110250386685948
[Epoch 18, Batch 1100] loss: 0.04223396126719308
[Epoch 18, Batch 1200] loss: 0.03344758707655274
[Epoch 18, Batch 1300] loss: 0.027386273213123785
[Epoch 18, Batch 1400] loss: 0.027128215139746316
[Epoch 18, Batch 1500] loss: 0.019441321912454443
[Epoch 18, Batch 1600] loss: 0.02343549510173034
[Epoch 18, Batch 1700] loss: 0.020296135737080476
[Epoch 18, Batch 1800] loss: 0.029885662851520466
[Epoch 18, Batch 1900] loss: 0.020014548367907992
[Epoch 18, Batch 2000] loss: 0.020763581178362075
[Epoch 18, Batch 2100] loss: 0.01793565213094553
[Epoch 18, Batch 2200] loss: 0.023804004906414777
[Epoch 18, Batch 2300] loss: 0.0329846228178576
[Epoch 18, Batch 2400] loss: 0.027379891359050817
[Epoch 18, Batch 2500] loss: 0.020807873418671078
[Epoch 18, Batch 2600] loss: 0.024944822193356232
[Epoch 18, Batch 2700] loss: 0.032118308193894336
[Epoch 18, Batch 2800] loss: 0.02301883648699004
[Epoch 18, Batch 2900] loss: 0.01807411962112383
[Epoch 18, Batch 3000] loss: 0.03191486088784586
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9853
Overfitting: 0.0477
[Epoch 19, Batch 100] loss: 0.02494781655002953
[Epoch 19, Batch 200] loss: 0.02975848787882569
[Epoch 19, Batch 300] loss: 0.026074405701256183
[Epoch 19, Batch 400] loss: 0.023786737936825376
[Epoch 19, Batch 500] loss: 0.023093329745424853
[Epoch 19, Batch 600] loss: 0.027282661583740264
[Epoch 19, Batch 700] loss: 0.030896993026690325
[Epoch 19, Batch 800] loss: 0.012706609775996185
[Epoch 19, Batch 900] loss: 0.018706555949902396
[Epoch 19, Batch 1000] loss: 0.025695973312613207
[Epoch 19, Batch 1100] loss: 0.01771299204800016
[Epoch 19, Batch 1200] loss: 0.019030355667164257
[Epoch 19, Batch 1300] loss: 0.029441575800810825
[Epoch 19, Batch 1400] loss: 0.017037225773601675
[Epoch 19, Batch 1500] loss: 0.02055507568802568
[Epoch 19, Batch 1600] loss: 0.021230826578321284
[Epoch 19, Batch 1700] loss: 0.020587507087329867
[Epoch 19, Batch 1800] loss: 0.021584356190123798
[Epoch 19, Batch 1900] loss: 0.023982802568680198
[Epoch 19, Batch 2000] loss: 0.01996602131439431
[Epoch 19, Batch 2100] loss: 0.02897063527811042
[Epoch 19, Batch 2200] loss: 0.030306868576972193
[Epoch 19, Batch 2300] loss: 0.02185440540975833
[Epoch 19, Batch 2400] loss: 0.0191431655845372
[Epoch 19, Batch 2500] loss: 0.0329228432369564
[Epoch 19, Batch 2600] loss: 0.028570086541658383
[Epoch 19, Batch 2700] loss: 0.022084805561862594
[Epoch 19, Batch 2800] loss: 0.02296489839631249
[Epoch 19, Batch 2900] loss: 0.025195904620341027
[Epoch 19, Batch 3000] loss: 0.021875334777505487
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9857
Overfitting: 0.0482
[Epoch 20, Batch 100] loss: 0.016425073226128007
[Epoch 20, Batch 200] loss: 0.022226331298006698
[Epoch 20, Batch 300] loss: 0.016302068988006794
[Epoch 20, Batch 400] loss: 0.016017424030651456
[Epoch 20, Batch 500] loss: 0.0323118739309939
[Epoch 20, Batch 600] loss: 0.02182079400969087
[Epoch 20, Batch 700] loss: 0.018426279219384015
[Epoch 20, Batch 800] loss: 0.017274904846090067
[Epoch 20, Batch 900] loss: 0.024458071859698977
[Epoch 20, Batch 1000] loss: 0.01944576986039465
[Epoch 20, Batch 1100] loss: 0.026392470998616774
[Epoch 20, Batch 1200] loss: 0.021504841784735617
[Epoch 20, Batch 1300] loss: 0.019146893935612752
[Epoch 20, Batch 1400] loss: 0.017693666053091875
[Epoch 20, Batch 1500] loss: 0.011839218555833213
[Epoch 20, Batch 1600] loss: 0.03053451573548955
[Epoch 20, Batch 1700] loss: 0.022646985576848237
[Epoch 20, Batch 1800] loss: 0.02072593523946125
[Epoch 20, Batch 1900] loss: 0.015082796487367886
[Epoch 20, Batch 2000] loss: 0.026439238595194182
[Epoch 20, Batch 2100] loss: 0.018796572066385124
[Epoch 20, Batch 2200] loss: 0.021852709031809355
[Epoch 20, Batch 2300] loss: 0.025921596344887804
[Epoch 20, Batch 2400] loss: 0.015450320751333492
[Epoch 20, Batch 2500] loss: 0.01998917648179486
[Epoch 20, Batch 2600] loss: 0.020720720591270947
[Epoch 20, Batch 2700] loss: 0.030794721437960106
[Epoch 20, Batch 2800] loss: 0.020903097287373384
[Epoch 20, Batch 2900] loss: 0.019893116218772777
[Epoch 20, Batch 3000] loss: 0.03163358671758033
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9868
Overfitting: 0.0459
[Epoch 21, Batch 100] loss: 0.022263653779882587
[Epoch 21, Batch 200] loss: 0.019019510894559062
[Epoch 21, Batch 300] loss: 0.012102864731041336
[Epoch 21, Batch 400] loss: 0.03003862072378979
[Epoch 21, Batch 500] loss: 0.019019411770495934
[Epoch 21, Batch 600] loss: 0.013476108499708062
[Epoch 21, Batch 700] loss: 0.020491247498066512
[Epoch 21, Batch 800] loss: 0.02409029348684271
[Epoch 21, Batch 900] loss: 0.02090180327024427
[Epoch 21, Batch 1000] loss: 0.016981772334365815
[Epoch 21, Batch 1100] loss: 0.022893330386359594
[Epoch 21, Batch 1200] loss: 0.012572785865704645
[Epoch 21, Batch 1300] loss: 0.02688726906097145
[Epoch 21, Batch 1400] loss: 0.01327878646865429
[Epoch 21, Batch 1500] loss: 0.028741290026082424
[Epoch 21, Batch 1600] loss: 0.023086635565523466
[Epoch 21, Batch 1700] loss: 0.01830720620455395
[Epoch 21, Batch 1800] loss: 0.02503120462752122
[Epoch 21, Batch 1900] loss: 0.013235964043087734
[Epoch 21, Batch 2000] loss: 0.019231905574670236
[Epoch 21, Batch 2100] loss: 0.022543443642371132
[Epoch 21, Batch 2200] loss: 0.013927472874638625
[Epoch 21, Batch 2300] loss: 0.02942874583743105
[Epoch 21, Batch 2400] loss: 0.024313454550701864
[Epoch 21, Batch 2500] loss: 0.021497797681804515
[Epoch 21, Batch 2600] loss: 0.020365428032673664
[Epoch 21, Batch 2700] loss: 0.020714381250872976
[Epoch 21, Batch 2800] loss: 0.022294370188610628
[Epoch 21, Batch 2900] loss: 0.01375177891718522
[Epoch 21, Batch 3000] loss: 0.01371432486215781
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9848
Overfitting: 0.0516
[Epoch 22, Batch 100] loss: 0.025841496824614296
[Epoch 22, Batch 200] loss: 0.023674877596567966
[Epoch 22, Batch 300] loss: 0.012887191670160973
[Epoch 22, Batch 400] loss: 0.02076459995314508
[Epoch 22, Batch 500] loss: 0.01679939153022133
[Epoch 22, Batch 600] loss: 0.01818772957667534
[Epoch 22, Batch 700] loss: 0.024788578480511206
[Epoch 22, Batch 800] loss: 0.012250545069546205
[Epoch 22, Batch 900] loss: 0.023992803243017988
[Epoch 22, Batch 1000] loss: 0.012795709078779964
[Epoch 22, Batch 1100] loss: 0.028118621761750548
[Epoch 22, Batch 1200] loss: 0.012825945015465549
[Epoch 22, Batch 1300] loss: 0.014199247760134313
[Epoch 22, Batch 1400] loss: 0.02340723628858541
[Epoch 22, Batch 1500] loss: 0.017376262224570383
[Epoch 22, Batch 1600] loss: 0.014790279566404933
[Epoch 22, Batch 1700] loss: 0.020346895816946927
[Epoch 22, Batch 1800] loss: 0.021584882951210603
[Epoch 22, Batch 1900] loss: 0.01591841648980335
[Epoch 22, Batch 2000] loss: 0.009199530438309012
[Epoch 22, Batch 2100] loss: 0.018505894099325813
[Epoch 22, Batch 2200] loss: 0.017437860071877368
[Epoch 22, Batch 2300] loss: 0.022937738468954194
[Epoch 22, Batch 2400] loss: 0.018980145852037823
[Epoch 22, Batch 2500] loss: 0.018183678631758085
[Epoch 22, Batch 2600] loss: 0.024064116045810807
[Epoch 22, Batch 2700] loss: 0.014526470334276382
[Epoch 22, Batch 2800] loss: 0.018683046010992257
[Epoch 22, Batch 2900] loss: 0.019053617754925655
[Epoch 22, Batch 3000] loss: 0.01659160632189014
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0433
Validation Accuracy: 0.9865
Overfitting: 0.0433
Best model saved at epoch 22 with validation loss: 0.0433
[Epoch 23, Batch 100] loss: 0.015619736696880864
[Epoch 23, Batch 200] loss: 0.01699888566923619
[Epoch 23, Batch 300] loss: 0.013354245222744794
[Epoch 23, Batch 400] loss: 0.019045009862456937
[Epoch 23, Batch 500] loss: 0.01622335958554686
[Epoch 23, Batch 600] loss: 0.018567159709637054
[Epoch 23, Batch 700] loss: 0.018593099365607487
[Epoch 23, Batch 800] loss: 0.021675380288625094
[Epoch 23, Batch 900] loss: 0.007818557389109628
[Epoch 23, Batch 1000] loss: 0.010432301724795251
[Epoch 23, Batch 1100] loss: 0.014770990423930925
[Epoch 23, Batch 1200] loss: 0.016398234741463968
[Epoch 23, Batch 1300] loss: 0.010032429102502648
[Epoch 23, Batch 1400] loss: 0.016213401884961058
[Epoch 23, Batch 1500] loss: 0.018167215047396892
[Epoch 23, Batch 1600] loss: 0.02029861332670407
[Epoch 23, Batch 1700] loss: 0.015791059096882235
[Epoch 23, Batch 1800] loss: 0.010429307287513439
[Epoch 23, Batch 1900] loss: 0.022733810561121573
[Epoch 23, Batch 2000] loss: 0.026748694184025226
[Epoch 23, Batch 2100] loss: 0.0314575685402815
[Epoch 23, Batch 2200] loss: 0.018637716115699733
[Epoch 23, Batch 2300] loss: 0.014622155907400156
[Epoch 23, Batch 2400] loss: 0.016790276568463013
[Epoch 23, Batch 2500] loss: 0.015496470129655791
[Epoch 23, Batch 2600] loss: 0.018563686448233058
[Epoch 23, Batch 2700] loss: 0.01192415424237879
[Epoch 23, Batch 2800] loss: 0.028234766649493395
[Epoch 23, Batch 2900] loss: 0.028203342755878113
[Epoch 23, Batch 3000] loss: 0.011045488230192859
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0420
Validation Accuracy: 0.9878
Overfitting: 0.0420
Best model saved at epoch 23 with validation loss: 0.0420
[Epoch 24, Batch 100] loss: 0.013600756894793448
[Epoch 24, Batch 200] loss: 0.013032550288626226
[Epoch 24, Batch 300] loss: 0.015008810283761704
[Epoch 24, Batch 400] loss: 0.012099252894004167
[Epoch 24, Batch 500] loss: 0.013473686736469972
[Epoch 24, Batch 600] loss: 0.007944975899081328
[Epoch 24, Batch 700] loss: 0.017938187303498124
[Epoch 24, Batch 800] loss: 0.012954279485747976
[Epoch 24, Batch 900] loss: 0.016939018031043817
[Epoch 24, Batch 1000] loss: 0.008457532383254147
[Epoch 24, Batch 1100] loss: 0.0116118635348721
[Epoch 24, Batch 1200] loss: 0.022198679144858034
[Epoch 24, Batch 1300] loss: 0.030635666659945854
[Epoch 24, Batch 1400] loss: 0.022925855664361734
[Epoch 24, Batch 1500] loss: 0.015139534060726873
[Epoch 24, Batch 1600] loss: 0.015201151587843924
[Epoch 24, Batch 1700] loss: 0.026286239019900678
[Epoch 24, Batch 1800] loss: 0.025509107836278418
[Epoch 24, Batch 1900] loss: 0.015256228728012501
[Epoch 24, Batch 2000] loss: 0.014582354286922054
[Epoch 24, Batch 2100] loss: 0.02145346614113805
[Epoch 24, Batch 2200] loss: 0.024556834688264643
[Epoch 24, Batch 2300] loss: 0.010724227210366734
[Epoch 24, Batch 2400] loss: 0.015512964271911187
[Epoch 24, Batch 2500] loss: 0.01755762037129898
[Epoch 24, Batch 2600] loss: 0.008620049624823878
[Epoch 24, Batch 2700] loss: 0.014838023942229484
[Epoch 24, Batch 2800] loss: 0.01611906318228648
[Epoch 24, Batch 2900] loss: 0.02304355670120458
[Epoch 24, Batch 3000] loss: 0.013901554421081527
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0415
Validation Accuracy: 0.9878
Overfitting: 0.0415
Best model saved at epoch 24 with validation loss: 0.0415
Fold 1 validation loss: 0.0415
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.301285676956177
[Epoch 1, Batch 200] loss: 2.2944640588760374
[Epoch 1, Batch 300] loss: 2.282685272693634
[Epoch 1, Batch 400] loss: 2.2757926869392393
[Epoch 1, Batch 500] loss: 2.2560894012451174
[Epoch 1, Batch 600] loss: 2.2267072868347166
[Epoch 1, Batch 700] loss: 2.1804322504997256
[Epoch 1, Batch 800] loss: 2.0800213050842284
[Epoch 1, Batch 900] loss: 1.8662153744697572
[Epoch 1, Batch 1000] loss: 1.4624699091911315
[Epoch 1, Batch 1100] loss: 1.0395483094453812
[Epoch 1, Batch 1200] loss: 0.7307052758336067
[Epoch 1, Batch 1300] loss: 0.6205546693503856
[Epoch 1, Batch 1400] loss: 0.6105529874563217
[Epoch 1, Batch 1500] loss: 0.517817959934473
[Epoch 1, Batch 1600] loss: 0.4706619081646204
[Epoch 1, Batch 1700] loss: 0.4658015951514244
[Epoch 1, Batch 1800] loss: 0.43717951826751233
[Epoch 1, Batch 1900] loss: 0.4655112265050411
[Epoch 1, Batch 2000] loss: 0.4131483405828476
[Epoch 1, Batch 2100] loss: 0.36044763203710317
[Epoch 1, Batch 2200] loss: 0.34668820306658743
[Epoch 1, Batch 2300] loss: 0.3690104417130351
[Epoch 1, Batch 2400] loss: 0.3261391302756965
[Epoch 1, Batch 2500] loss: 0.34723801501095297
[Epoch 1, Batch 2600] loss: 0.3156298965960741
[Epoch 1, Batch 2700] loss: 0.3005123994126916
[Epoch 1, Batch 2800] loss: 0.29055512737482786
[Epoch 1, Batch 2900] loss: 0.22340828597545623
[Epoch 1, Batch 3000] loss: 0.2557154186815023
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2749
Validation Accuracy: 0.9174
Overfitting: 0.2749
Best model saved at epoch 1 with validation loss: 0.2749
[Epoch 2, Batch 100] loss: 0.291373675763607
[Epoch 2, Batch 200] loss: 0.2469290604069829
[Epoch 2, Batch 300] loss: 0.2539271469041705
[Epoch 2, Batch 400] loss: 0.19736799854785203
[Epoch 2, Batch 500] loss: 0.2197653190791607
[Epoch 2, Batch 600] loss: 0.23864451698958875
[Epoch 2, Batch 700] loss: 0.2254165673442185
[Epoch 2, Batch 800] loss: 0.19998443422839046
[Epoch 2, Batch 900] loss: 0.188782022241503
[Epoch 2, Batch 1000] loss: 0.20674989491701126
[Epoch 2, Batch 1100] loss: 0.1825389644317329
[Epoch 2, Batch 1200] loss: 0.20797401817515493
[Epoch 2, Batch 1300] loss: 0.2100173114798963
[Epoch 2, Batch 1400] loss: 0.18717541720718145
[Epoch 2, Batch 1500] loss: 0.17179908372461797
[Epoch 2, Batch 1600] loss: 0.1758879095967859
[Epoch 2, Batch 1700] loss: 0.15939777437597513
[Epoch 2, Batch 1800] loss: 0.17900710621383042
[Epoch 2, Batch 1900] loss: 0.17560396876186132
[Epoch 2, Batch 2000] loss: 0.17192814270500092
[Epoch 2, Batch 2100] loss: 0.15009194632526487
[Epoch 2, Batch 2200] loss: 0.18143097798340022
[Epoch 2, Batch 2300] loss: 0.1583123688586056
[Epoch 2, Batch 2400] loss: 0.16872705930843948
[Epoch 2, Batch 2500] loss: 0.17332571275532246
[Epoch 2, Batch 2600] loss: 0.1317925545712933
[Epoch 2, Batch 2700] loss: 0.11990606719627976
[Epoch 2, Batch 2800] loss: 0.15316644487902523
[Epoch 2, Batch 2900] loss: 0.16322915194556117
[Epoch 2, Batch 3000] loss: 0.142444812245667
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1504
Validation Accuracy: 0.9537
Overfitting: 0.1504
Best model saved at epoch 2 with validation loss: 0.1504
[Epoch 3, Batch 100] loss: 0.12220899730920792
[Epoch 3, Batch 200] loss: 0.12746208150871097
[Epoch 3, Batch 300] loss: 0.13263974968343972
[Epoch 3, Batch 400] loss: 0.11198975831037387
[Epoch 3, Batch 500] loss: 0.11996181296184659
[Epoch 3, Batch 600] loss: 0.12080824631266296
[Epoch 3, Batch 700] loss: 0.13733662128448487
[Epoch 3, Batch 800] loss: 0.12651025526691229
[Epoch 3, Batch 900] loss: 0.1324156422330998
[Epoch 3, Batch 1000] loss: 0.14165706385858357
[Epoch 3, Batch 1100] loss: 0.1272112133866176
[Epoch 3, Batch 1200] loss: 0.12499478705227375
[Epoch 3, Batch 1300] loss: 0.13141339437104763
[Epoch 3, Batch 1400] loss: 0.10754908214788884
[Epoch 3, Batch 1500] loss: 0.11857264942023903
[Epoch 3, Batch 1600] loss: 0.12730197622673586
[Epoch 3, Batch 1700] loss: 0.09764082938199863
[Epoch 3, Batch 1800] loss: 0.14267936930060388
[Epoch 3, Batch 1900] loss: 0.10761624644976109
[Epoch 3, Batch 2000] loss: 0.11462040244601666
[Epoch 3, Batch 2100] loss: 0.12262010408565402
[Epoch 3, Batch 2200] loss: 0.1394750795606524
[Epoch 3, Batch 2300] loss: 0.09122867398196831
[Epoch 3, Batch 2400] loss: 0.1214588118204847
[Epoch 3, Batch 2500] loss: 0.1043775798752904
[Epoch 3, Batch 2600] loss: 0.13342215022537857
[Epoch 3, Batch 2700] loss: 0.11673675054684281
[Epoch 3, Batch 2800] loss: 0.09770541980164126
[Epoch 3, Batch 2900] loss: 0.10206706138327717
[Epoch 3, Batch 3000] loss: 0.10245917357038707
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1136
Validation Accuracy: 0.9637
Overfitting: 0.1136
Best model saved at epoch 3 with validation loss: 0.1136
[Epoch 4, Batch 100] loss: 0.11175036785658449
[Epoch 4, Batch 200] loss: 0.10430961207719519
[Epoch 4, Batch 300] loss: 0.09770050902850926
[Epoch 4, Batch 400] loss: 0.10305236441316083
[Epoch 4, Batch 500] loss: 0.10368360886117443
[Epoch 4, Batch 600] loss: 0.11063399400329217
[Epoch 4, Batch 700] loss: 0.09654406846035272
[Epoch 4, Batch 800] loss: 0.10612503514275887
[Epoch 4, Batch 900] loss: 0.09839428251842036
[Epoch 4, Batch 1000] loss: 0.09026899840682745
[Epoch 4, Batch 1100] loss: 0.09237574330763891
[Epoch 4, Batch 1200] loss: 0.07150177890551276
[Epoch 4, Batch 1300] loss: 0.1015536393597722
[Epoch 4, Batch 1400] loss: 0.11188505931058898
[Epoch 4, Batch 1500] loss: 0.06983630527975038
[Epoch 4, Batch 1600] loss: 0.08788951265159994
[Epoch 4, Batch 1700] loss: 0.08819970605429261
[Epoch 4, Batch 1800] loss: 0.07845328027848154
[Epoch 4, Batch 1900] loss: 0.08257509706774727
[Epoch 4, Batch 2000] loss: 0.09563510552397929
[Epoch 4, Batch 2100] loss: 0.07566003847168759
[Epoch 4, Batch 2200] loss: 0.0974094196059741
[Epoch 4, Batch 2300] loss: 0.09915822831680998
[Epoch 4, Batch 2400] loss: 0.08914073163759895
[Epoch 4, Batch 2500] loss: 0.08941111809224822
[Epoch 4, Batch 2600] loss: 0.08584766405401752
[Epoch 4, Batch 2700] loss: 0.0947140044462867
[Epoch 4, Batch 2800] loss: 0.06760045454604552
[Epoch 4, Batch 2900] loss: 0.11163579635089263
[Epoch 4, Batch 3000] loss: 0.06534135947818868
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0926
Validation Accuracy: 0.9708
Overfitting: 0.0926
Best model saved at epoch 4 with validation loss: 0.0926
[Epoch 5, Batch 100] loss: 0.08574302342021838
[Epoch 5, Batch 200] loss: 0.08603239252930507
[Epoch 5, Batch 300] loss: 0.06853738269070163
[Epoch 5, Batch 400] loss: 0.06220099787635263
[Epoch 5, Batch 500] loss: 0.08923210052598733
[Epoch 5, Batch 600] loss: 0.08194990566233173
[Epoch 5, Batch 700] loss: 0.09351435057120398
[Epoch 5, Batch 800] loss: 0.0773303728864994
[Epoch 5, Batch 900] loss: 0.07723363113822415
[Epoch 5, Batch 1000] loss: 0.073379934564
[Epoch 5, Batch 1100] loss: 0.07687977761263028
[Epoch 5, Batch 1200] loss: 0.07716367118991911
[Epoch 5, Batch 1300] loss: 0.0836604217987042
[Epoch 5, Batch 1400] loss: 0.0872110335342586
[Epoch 5, Batch 1500] loss: 0.08052708598203026
[Epoch 5, Batch 1600] loss: 0.07171678435523063
[Epoch 5, Batch 1700] loss: 0.07799413403263315
[Epoch 5, Batch 1800] loss: 0.07822971895919181
[Epoch 5, Batch 1900] loss: 0.059079418738838284
[Epoch 5, Batch 2000] loss: 0.07795201728353277
[Epoch 5, Batch 2100] loss: 0.08226196035102476
[Epoch 5, Batch 2200] loss: 0.0663062088843435
[Epoch 5, Batch 2300] loss: 0.07886798888677732
[Epoch 5, Batch 2400] loss: 0.06984401020919905
[Epoch 5, Batch 2500] loss: 0.05766403038869612
[Epoch 5, Batch 2600] loss: 0.1047929790103808
[Epoch 5, Batch 2700] loss: 0.06300308914273046
[Epoch 5, Batch 2800] loss: 0.08083219543041195
[Epoch 5, Batch 2900] loss: 0.06986290522618219
[Epoch 5, Batch 3000] loss: 0.0693359599460382
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0881
Validation Accuracy: 0.9728
Overfitting: 0.0881
Best model saved at epoch 5 with validation loss: 0.0881
[Epoch 6, Batch 100] loss: 0.07671472231158986
[Epoch 6, Batch 200] loss: 0.06194766676519066
[Epoch 6, Batch 300] loss: 0.05317584479926154
[Epoch 6, Batch 400] loss: 0.055265499783563425
[Epoch 6, Batch 500] loss: 0.08334899443201721
[Epoch 6, Batch 600] loss: 0.06405231087235734
[Epoch 6, Batch 700] loss: 0.06148447905550711
[Epoch 6, Batch 800] loss: 0.06607714852550998
[Epoch 6, Batch 900] loss: 0.07337050329660996
[Epoch 6, Batch 1000] loss: 0.054096199423074726
[Epoch 6, Batch 1100] loss: 0.07534549058589618
[Epoch 6, Batch 1200] loss: 0.07349153574730735
[Epoch 6, Batch 1300] loss: 0.0823676291340962
[Epoch 6, Batch 1400] loss: 0.06909898971905931
[Epoch 6, Batch 1500] loss: 0.06239816797664389
[Epoch 6, Batch 1600] loss: 0.051348521636100486
[Epoch 6, Batch 1700] loss: 0.06844081657647622
[Epoch 6, Batch 1800] loss: 0.062138795407954604
[Epoch 6, Batch 1900] loss: 0.07218250813253689
[Epoch 6, Batch 2000] loss: 0.062490077058319
[Epoch 6, Batch 2100] loss: 0.05163004861737136
[Epoch 6, Batch 2200] loss: 0.08423167860368266
[Epoch 6, Batch 2300] loss: 0.053693444875534624
[Epoch 6, Batch 2400] loss: 0.05311598526022863
[Epoch 6, Batch 2500] loss: 0.06555131791043095
[Epoch 6, Batch 2600] loss: 0.056456037334864956
[Epoch 6, Batch 2700] loss: 0.06283643805945757
[Epoch 6, Batch 2800] loss: 0.08873691678862088
[Epoch 6, Batch 2900] loss: 0.04954963337397203
[Epoch 6, Batch 3000] loss: 0.08210518196807243
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0781
Validation Accuracy: 0.9752
Overfitting: 0.0781
Best model saved at epoch 6 with validation loss: 0.0781
[Epoch 7, Batch 100] loss: 0.07842831074376591
[Epoch 7, Batch 200] loss: 0.04270107514807023
[Epoch 7, Batch 300] loss: 0.07295530611474532
[Epoch 7, Batch 400] loss: 0.07464729649364017
[Epoch 7, Batch 500] loss: 0.06318112590583042
[Epoch 7, Batch 600] loss: 0.0738393669045763
[Epoch 7, Batch 700] loss: 0.054335322598926726
[Epoch 7, Batch 800] loss: 0.057387263507116586
[Epoch 7, Batch 900] loss: 0.05324415027804207
[Epoch 7, Batch 1000] loss: 0.06677375435247086
[Epoch 7, Batch 1100] loss: 0.05757086419383995
[Epoch 7, Batch 1200] loss: 0.046196834791335274
[Epoch 7, Batch 1300] loss: 0.06578675013442989
[Epoch 7, Batch 1400] loss: 0.05184869513701415
[Epoch 7, Batch 1500] loss: 0.05259192486817483
[Epoch 7, Batch 1600] loss: 0.055252005814108995
[Epoch 7, Batch 1700] loss: 0.06254140022734646
[Epoch 7, Batch 1800] loss: 0.053239856543950734
[Epoch 7, Batch 1900] loss: 0.06577005555387587
[Epoch 7, Batch 2000] loss: 0.056908176694996655
[Epoch 7, Batch 2100] loss: 0.05842614551715087
[Epoch 7, Batch 2200] loss: 0.05805568154901266
[Epoch 7, Batch 2300] loss: 0.05162318036716897
[Epoch 7, Batch 2400] loss: 0.048657272567506876
[Epoch 7, Batch 2500] loss: 0.053237621715816204
[Epoch 7, Batch 2600] loss: 0.06493752224108902
[Epoch 7, Batch 2700] loss: 0.05002624876738992
[Epoch 7, Batch 2800] loss: 0.05241491130553186
[Epoch 7, Batch 2900] loss: 0.05160872193810064
[Epoch 7, Batch 3000] loss: 0.057360478268237786
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0695
Validation Accuracy: 0.9780
Overfitting: 0.0695
Best model saved at epoch 7 with validation loss: 0.0695
[Epoch 8, Batch 100] loss: 0.05085770285979379
[Epoch 8, Batch 200] loss: 0.03957572159240954
[Epoch 8, Batch 300] loss: 0.04028370506479405
[Epoch 8, Batch 400] loss: 0.04608987525047269
[Epoch 8, Batch 500] loss: 0.043325418189051564
[Epoch 8, Batch 600] loss: 0.0601385984022636
[Epoch 8, Batch 700] loss: 0.03801728170074057
[Epoch 8, Batch 800] loss: 0.05683646631252486
[Epoch 8, Batch 900] loss: 0.05473448087373981
[Epoch 8, Batch 1000] loss: 0.04844564790662844
[Epoch 8, Batch 1100] loss: 0.043906971355900166
[Epoch 8, Batch 1200] loss: 0.05650826028722804
[Epoch 8, Batch 1300] loss: 0.04635997059289366
[Epoch 8, Batch 1400] loss: 0.049273811542079785
[Epoch 8, Batch 1500] loss: 0.04595031022108742
[Epoch 8, Batch 1600] loss: 0.05908615433378145
[Epoch 8, Batch 1700] loss: 0.06142923558072653
[Epoch 8, Batch 1800] loss: 0.053602222661720586
[Epoch 8, Batch 1900] loss: 0.05309418820863357
[Epoch 8, Batch 2000] loss: 0.06499139703402762
[Epoch 8, Batch 2100] loss: 0.04573440956824925
[Epoch 8, Batch 2200] loss: 0.06016216646588873
[Epoch 8, Batch 2300] loss: 0.027178867804759647
[Epoch 8, Batch 2400] loss: 0.043465523222694175
[Epoch 8, Batch 2500] loss: 0.05894361690530786
[Epoch 8, Batch 2600] loss: 0.06234058947622543
[Epoch 8, Batch 2700] loss: 0.06007680973503739
[Epoch 8, Batch 2800] loss: 0.06285306772973855
[Epoch 8, Batch 2900] loss: 0.0536793503043009
[Epoch 8, Batch 3000] loss: 0.05970596999919508
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0670
Validation Accuracy: 0.9792
Overfitting: 0.0670
Best model saved at epoch 8 with validation loss: 0.0670
[Epoch 9, Batch 100] loss: 0.044503755397745405
[Epoch 9, Batch 200] loss: 0.07092491906310898
[Epoch 9, Batch 300] loss: 0.04809461191936862
[Epoch 9, Batch 400] loss: 0.05594269597670063
[Epoch 9, Batch 500] loss: 0.04947729013976641
[Epoch 9, Batch 600] loss: 0.040767312296666205
[Epoch 9, Batch 700] loss: 0.0507171271124389
[Epoch 9, Batch 800] loss: 0.05336373807978816
[Epoch 9, Batch 900] loss: 0.030951586228911764
[Epoch 9, Batch 1000] loss: 0.04455004247400211
[Epoch 9, Batch 1100] loss: 0.032500266319257204
[Epoch 9, Batch 1200] loss: 0.03527622822439298
[Epoch 9, Batch 1300] loss: 0.06555253063765122
[Epoch 9, Batch 1400] loss: 0.05776233097480144
[Epoch 9, Batch 1500] loss: 0.053610234317020514
[Epoch 9, Batch 1600] loss: 0.04968080507969717
[Epoch 9, Batch 1700] loss: 0.04546006411197595
[Epoch 9, Batch 1800] loss: 0.044682257881504484
[Epoch 9, Batch 1900] loss: 0.03577437292813556
[Epoch 9, Batch 2000] loss: 0.0467445029807277
[Epoch 9, Batch 2100] loss: 0.04618637264560675
[Epoch 9, Batch 2200] loss: 0.04127409585926216
[Epoch 9, Batch 2300] loss: 0.03141367493692087
[Epoch 9, Batch 2400] loss: 0.038258060371881585
[Epoch 9, Batch 2500] loss: 0.04299055860727094
[Epoch 9, Batch 2600] loss: 0.041317639975168276
[Epoch 9, Batch 2700] loss: 0.040171312841994225
[Epoch 9, Batch 2800] loss: 0.028897871276712978
[Epoch 9, Batch 2900] loss: 0.04225537683814764
[Epoch 9, Batch 3000] loss: 0.04274055392394075
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0680
Validation Accuracy: 0.9795
Overfitting: 0.0680
[Epoch 10, Batch 100] loss: 0.037101752264716195
[Epoch 10, Batch 200] loss: 0.062166941728792155
[Epoch 10, Batch 300] loss: 0.0343787008599611
[Epoch 10, Batch 400] loss: 0.031012985721754375
[Epoch 10, Batch 500] loss: 0.03277196187598747
[Epoch 10, Batch 600] loss: 0.04787324381468352
[Epoch 10, Batch 700] loss: 0.038671478713076794
[Epoch 10, Batch 800] loss: 0.037603508582396895
[Epoch 10, Batch 900] loss: 0.04236752769793384
[Epoch 10, Batch 1000] loss: 0.03489757067145547
[Epoch 10, Batch 1100] loss: 0.04214976430725073
[Epoch 10, Batch 1200] loss: 0.04387610313133337
[Epoch 10, Batch 1300] loss: 0.047796507356397344
[Epoch 10, Batch 1400] loss: 0.038961364256683735
[Epoch 10, Batch 1500] loss: 0.03884195561928209
[Epoch 10, Batch 1600] loss: 0.05036011586082168
[Epoch 10, Batch 1700] loss: 0.03154964790883241
[Epoch 10, Batch 1800] loss: 0.03839311942399945
[Epoch 10, Batch 1900] loss: 0.04892666871484835
[Epoch 10, Batch 2000] loss: 0.033818570471194104
[Epoch 10, Batch 2100] loss: 0.044192058836342765
[Epoch 10, Batch 2200] loss: 0.05214997619157657
[Epoch 10, Batch 2300] loss: 0.032424532983568496
[Epoch 10, Batch 2400] loss: 0.030278141476446762
[Epoch 10, Batch 2500] loss: 0.04370693139760988
[Epoch 10, Batch 2600] loss: 0.04042640124709578
[Epoch 10, Batch 2700] loss: 0.06279999507823959
[Epoch 10, Batch 2800] loss: 0.042734088996076024
[Epoch 10, Batch 2900] loss: 0.0423293645249214
[Epoch 10, Batch 3000] loss: 0.038057798441150224
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9822
Overfitting: 0.0605
Best model saved at epoch 10 with validation loss: 0.0605
[Epoch 11, Batch 100] loss: 0.027904693377786317
[Epoch 11, Batch 200] loss: 0.03422783013433218
[Epoch 11, Batch 300] loss: 0.04440710701455828
[Epoch 11, Batch 400] loss: 0.039288388051500076
[Epoch 11, Batch 500] loss: 0.031699759482871744
[Epoch 11, Batch 600] loss: 0.038066082204895796
[Epoch 11, Batch 700] loss: 0.043961043480085206
[Epoch 11, Batch 800] loss: 0.030573635773616843
[Epoch 11, Batch 900] loss: 0.03220671713032061
[Epoch 11, Batch 1000] loss: 0.036745335650921335
[Epoch 11, Batch 1100] loss: 0.02979804426722694
[Epoch 11, Batch 1200] loss: 0.02068808308831649
[Epoch 11, Batch 1300] loss: 0.033268942638824225
[Epoch 11, Batch 1400] loss: 0.04856117296498269
[Epoch 11, Batch 1500] loss: 0.04054170040297322
[Epoch 11, Batch 1600] loss: 0.045260301660746335
[Epoch 11, Batch 1700] loss: 0.029257949722814373
[Epoch 11, Batch 1800] loss: 0.04765316129574785
[Epoch 11, Batch 1900] loss: 0.044465790041140284
[Epoch 11, Batch 2000] loss: 0.035200037406175395
[Epoch 11, Batch 2100] loss: 0.0369485183377401
[Epoch 11, Batch 2200] loss: 0.045103916476946324
[Epoch 11, Batch 2300] loss: 0.03030840441060718
[Epoch 11, Batch 2400] loss: 0.035075373705476524
[Epoch 11, Batch 2500] loss: 0.038085582939093005
[Epoch 11, Batch 2600] loss: 0.038324111806578
[Epoch 11, Batch 2700] loss: 0.029234665826661514
[Epoch 11, Batch 2800] loss: 0.039740036089206114
[Epoch 11, Batch 2900] loss: 0.0371121306475834
[Epoch 11, Batch 3000] loss: 0.04261336103416397
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0629
Validation Accuracy: 0.9803
Overfitting: 0.0629
[Epoch 12, Batch 100] loss: 0.03213089114840841
[Epoch 12, Batch 200] loss: 0.027332049560209272
[Epoch 12, Batch 300] loss: 0.016848874659772264
[Epoch 12, Batch 400] loss: 0.031049573735508602
[Epoch 12, Batch 500] loss: 0.031047274232842027
[Epoch 12, Batch 600] loss: 0.05341937446792144
[Epoch 12, Batch 700] loss: 0.03459578850568505
[Epoch 12, Batch 800] loss: 0.02313945621979656
[Epoch 12, Batch 900] loss: 0.03134904397767969
[Epoch 12, Batch 1000] loss: 0.03793310090593877
[Epoch 12, Batch 1100] loss: 0.030065093169178
[Epoch 12, Batch 1200] loss: 0.042310076066860346
[Epoch 12, Batch 1300] loss: 0.04033025769807864
[Epoch 12, Batch 1400] loss: 0.0325339752304717
[Epoch 12, Batch 1500] loss: 0.03175106238661101
[Epoch 12, Batch 1600] loss: 0.036724203104677146
[Epoch 12, Batch 1700] loss: 0.03129751871456392
[Epoch 12, Batch 1800] loss: 0.028995929098164196
[Epoch 12, Batch 1900] loss: 0.03250015605182852
[Epoch 12, Batch 2000] loss: 0.049106346260232386
[Epoch 12, Batch 2100] loss: 0.028124930183548714
[Epoch 12, Batch 2200] loss: 0.0283903070105589
[Epoch 12, Batch 2300] loss: 0.038774868820109984
[Epoch 12, Batch 2400] loss: 0.0482267335090728
[Epoch 12, Batch 2500] loss: 0.024693507927586324
[Epoch 12, Batch 2600] loss: 0.022925267210957827
[Epoch 12, Batch 2700] loss: 0.03857279811913031
[Epoch 12, Batch 2800] loss: 0.03870899722391186
[Epoch 12, Batch 2900] loss: 0.03996071679022862
[Epoch 12, Batch 3000] loss: 0.041282082518446256
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0612
Validation Accuracy: 0.9808
Overfitting: 0.0612
[Epoch 13, Batch 100] loss: 0.02235816930711735
[Epoch 13, Batch 200] loss: 0.03278629887034185
[Epoch 13, Batch 300] loss: 0.043885304730792996
[Epoch 13, Batch 400] loss: 0.027442462616672856
[Epoch 13, Batch 500] loss: 0.024993827150028666
[Epoch 13, Batch 600] loss: 0.034171672773372845
[Epoch 13, Batch 700] loss: 0.03846379967246321
[Epoch 13, Batch 800] loss: 0.02276968104444677
[Epoch 13, Batch 900] loss: 0.027765979885007255
[Epoch 13, Batch 1000] loss: 0.03571126620459836
[Epoch 13, Batch 1100] loss: 0.04388079367738101
[Epoch 13, Batch 1200] loss: 0.030016623538977
[Epoch 13, Batch 1300] loss: 0.033933248057437596
[Epoch 13, Batch 1400] loss: 0.026372902942239308
[Epoch 13, Batch 1500] loss: 0.03210510386386886
[Epoch 13, Batch 1600] loss: 0.025072252160462084
[Epoch 13, Batch 1700] loss: 0.02020095576750464
[Epoch 13, Batch 1800] loss: 0.02385496230679564
[Epoch 13, Batch 1900] loss: 0.02967000089403882
[Epoch 13, Batch 2000] loss: 0.03674755742336856
[Epoch 13, Batch 2100] loss: 0.03227664229205402
[Epoch 13, Batch 2200] loss: 0.024675831652857597
[Epoch 13, Batch 2300] loss: 0.02517766199394828
[Epoch 13, Batch 2400] loss: 0.03709838221388054
[Epoch 13, Batch 2500] loss: 0.03799977286282228
[Epoch 13, Batch 2600] loss: 0.027811990376503674
[Epoch 13, Batch 2700] loss: 0.03721836086304393
[Epoch 13, Batch 2800] loss: 0.029448157552396877
[Epoch 13, Batch 2900] loss: 0.02482904074480757
[Epoch 13, Batch 3000] loss: 0.03251670570942224
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0631
Validation Accuracy: 0.9804
Overfitting: 0.0631
[Epoch 14, Batch 100] loss: 0.028652034000260757
[Epoch 14, Batch 200] loss: 0.026153672726941295
[Epoch 14, Batch 300] loss: 0.020715265793987782
[Epoch 14, Batch 400] loss: 0.028492687692923936
[Epoch 14, Batch 500] loss: 0.03743741287704325
[Epoch 14, Batch 600] loss: 0.029782742753450293
[Epoch 14, Batch 700] loss: 0.027943469447054666
[Epoch 14, Batch 800] loss: 0.03679857245369931
[Epoch 14, Batch 900] loss: 0.01819785550411325
[Epoch 14, Batch 1000] loss: 0.02612415681083803
[Epoch 14, Batch 1100] loss: 0.029626639178895856
[Epoch 14, Batch 1200] loss: 0.03788340218088706
[Epoch 14, Batch 1300] loss: 0.0239214421264478
[Epoch 14, Batch 1400] loss: 0.0221276007569395
[Epoch 14, Batch 1500] loss: 0.019845816596862277
[Epoch 14, Batch 1600] loss: 0.023077111847378547
[Epoch 14, Batch 1700] loss: 0.022220839761284878
[Epoch 14, Batch 1800] loss: 0.023818076987954555
[Epoch 14, Batch 1900] loss: 0.035692412671487546
[Epoch 14, Batch 2000] loss: 0.04055670266912784
[Epoch 14, Batch 2100] loss: 0.025768938131950563
[Epoch 14, Batch 2200] loss: 0.01860755667094054
[Epoch 14, Batch 2300] loss: 0.03439353139270679
[Epoch 14, Batch 2400] loss: 0.035442385818605544
[Epoch 14, Batch 2500] loss: 0.02437380121802562
[Epoch 14, Batch 2600] loss: 0.033074363140622155
[Epoch 14, Batch 2700] loss: 0.02804303885845002
[Epoch 14, Batch 2800] loss: 0.033344669520738536
[Epoch 14, Batch 2900] loss: 0.030423916330037173
[Epoch 14, Batch 3000] loss: 0.03611669252684806
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0682
Validation Accuracy: 0.9811
Overfitting: 0.0682
[Epoch 15, Batch 100] loss: 0.024136848145353725
[Epoch 15, Batch 200] loss: 0.029016206148880883
[Epoch 15, Batch 300] loss: 0.024845054559991694
[Epoch 15, Batch 400] loss: 0.01759910308930557
[Epoch 15, Batch 500] loss: 0.016185398820598492
[Epoch 15, Batch 600] loss: 0.024546048587071708
[Epoch 15, Batch 700] loss: 0.034027897752712304
[Epoch 15, Batch 800] loss: 0.019718776426598198
[Epoch 15, Batch 900] loss: 0.024989871023935847
[Epoch 15, Batch 1000] loss: 0.021911590156232705
[Epoch 15, Batch 1100] loss: 0.019153771825149307
[Epoch 15, Batch 1200] loss: 0.022696828062762506
[Epoch 15, Batch 1300] loss: 0.025481384164886548
[Epoch 15, Batch 1400] loss: 0.02236220568593126
[Epoch 15, Batch 1500] loss: 0.028547456534797674
[Epoch 15, Batch 1600] loss: 0.02508244428805483
[Epoch 15, Batch 1700] loss: 0.018868153575313046
[Epoch 15, Batch 1800] loss: 0.029288594616227782
[Epoch 15, Batch 1900] loss: 0.034626762861917085
[Epoch 15, Batch 2000] loss: 0.0326644976825628
[Epoch 15, Batch 2100] loss: 0.014844867912506743
[Epoch 15, Batch 2200] loss: 0.024544856515258288
[Epoch 15, Batch 2300] loss: 0.03311085358473065
[Epoch 15, Batch 2400] loss: 0.030948718724539505
[Epoch 15, Batch 2500] loss: 0.05009759565666173
[Epoch 15, Batch 2600] loss: 0.017713967116651474
[Epoch 15, Batch 2700] loss: 0.02410278149154692
[Epoch 15, Batch 2800] loss: 0.02456874063340365
[Epoch 15, Batch 2900] loss: 0.03704027666986803
[Epoch 15, Batch 3000] loss: 0.029225173240847654
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0629
Validation Accuracy: 0.9815
Overfitting: 0.0629
[Epoch 16, Batch 100] loss: 0.015475443483301205
[Epoch 16, Batch 200] loss: 0.026334315411077114
[Epoch 16, Batch 300] loss: 0.03615139614674263
[Epoch 16, Batch 400] loss: 0.017857448170543647
[Epoch 16, Batch 500] loss: 0.03230469836198609
[Epoch 16, Batch 600] loss: 0.016753099520137767
[Epoch 16, Batch 700] loss: 0.026823420293585514
[Epoch 16, Batch 800] loss: 0.030908263613782766
[Epoch 16, Batch 900] loss: 0.021004282702633645
[Epoch 16, Batch 1000] loss: 0.028307953947223723
[Epoch 16, Batch 1100] loss: 0.023547557513156788
[Epoch 16, Batch 1200] loss: 0.027498687644911115
[Epoch 16, Batch 1300] loss: 0.024538101864309284
[Epoch 16, Batch 1400] loss: 0.01949203131487593
[Epoch 16, Batch 1500] loss: 0.013773537528395536
[Epoch 16, Batch 1600] loss: 0.026694545201680738
[Epoch 16, Batch 1700] loss: 0.026610820447931473
[Epoch 16, Batch 1800] loss: 0.015733087165499454
[Epoch 16, Batch 1900] loss: 0.023496033121045912
[Epoch 16, Batch 2000] loss: 0.03307623902052001
[Epoch 16, Batch 2100] loss: 0.01754561697049212
[Epoch 16, Batch 2200] loss: 0.03192950852768263
[Epoch 16, Batch 2300] loss: 0.019577543216801132
[Epoch 16, Batch 2400] loss: 0.027400458128668106
[Epoch 16, Batch 2500] loss: 0.032185974427447944
[Epoch 16, Batch 2600] loss: 0.024127703587073484
[Epoch 16, Batch 2700] loss: 0.023621302832107175
[Epoch 16, Batch 2800] loss: 0.0217249170813011
[Epoch 16, Batch 2900] loss: 0.040400250305101505
[Epoch 16, Batch 3000] loss: 0.021864470422515297
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9842
Overfitting: 0.0533
Best model saved at epoch 16 with validation loss: 0.0533
[Epoch 17, Batch 100] loss: 0.01682087707631581
[Epoch 17, Batch 200] loss: 0.030775716666321385
[Epoch 17, Batch 300] loss: 0.019513469832381815
[Epoch 17, Batch 400] loss: 0.022011157883607666
[Epoch 17, Batch 500] loss: 0.030796683778753504
[Epoch 17, Batch 600] loss: 0.01769893752076314
[Epoch 17, Batch 700] loss: 0.021806100160829373
[Epoch 17, Batch 800] loss: 0.01839761256429483
[Epoch 17, Batch 900] loss: 0.021900607280767873
[Epoch 17, Batch 1000] loss: 0.01527514777626493
[Epoch 17, Batch 1100] loss: 0.019472819181974046
[Epoch 17, Batch 1200] loss: 0.02792968335110345
[Epoch 17, Batch 1300] loss: 0.01441673360128334
[Epoch 17, Batch 1400] loss: 0.014922589685629645
[Epoch 17, Batch 1500] loss: 0.03266766665343312
[Epoch 17, Batch 1600] loss: 0.01792617103928933
[Epoch 17, Batch 1700] loss: 0.029571260390075623
[Epoch 17, Batch 1800] loss: 0.016903942205972272
[Epoch 17, Batch 1900] loss: 0.017677168883092235
[Epoch 17, Batch 2000] loss: 0.024749122696739505
[Epoch 17, Batch 2100] loss: 0.02679579081661359
[Epoch 17, Batch 2200] loss: 0.021027226226651693
[Epoch 17, Batch 2300] loss: 0.02666398220244446
[Epoch 17, Batch 2400] loss: 0.021402899935565073
[Epoch 17, Batch 2500] loss: 0.019406764588529767
[Epoch 17, Batch 2600] loss: 0.02264022179384483
[Epoch 17, Batch 2700] loss: 0.023480696395799895
[Epoch 17, Batch 2800] loss: 0.020544034589620425
[Epoch 17, Batch 2900] loss: 0.02291541037389834
[Epoch 17, Batch 3000] loss: 0.028867891900590623
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0583
Validation Accuracy: 0.9835
Overfitting: 0.0583
[Epoch 18, Batch 100] loss: 0.014225019343430177
[Epoch 18, Batch 200] loss: 0.019323097566793877
[Epoch 18, Batch 300] loss: 0.027273906090922537
[Epoch 18, Batch 400] loss: 0.014279279986512848
[Epoch 18, Batch 500] loss: 0.017588968358759303
[Epoch 18, Batch 600] loss: 0.016253864009268
[Epoch 18, Batch 700] loss: 0.015889113710618404
[Epoch 18, Batch 800] loss: 0.021793357242095225
[Epoch 18, Batch 900] loss: 0.016734688553369778
[Epoch 18, Batch 1000] loss: 0.01664227232653502
[Epoch 18, Batch 1100] loss: 0.015059296398630977
[Epoch 18, Batch 1200] loss: 0.017016087800257082
[Epoch 18, Batch 1300] loss: 0.024237099270903853
[Epoch 18, Batch 1400] loss: 0.027771978144046444
[Epoch 18, Batch 1500] loss: 0.033057792321124
[Epoch 18, Batch 1600] loss: 0.011807790638158622
[Epoch 18, Batch 1700] loss: 0.015444442491752853
[Epoch 18, Batch 1800] loss: 0.01779045321047306
[Epoch 18, Batch 1900] loss: 0.021102863300457103
[Epoch 18, Batch 2000] loss: 0.01888738742680289
[Epoch 18, Batch 2100] loss: 0.04051032488474448
[Epoch 18, Batch 2200] loss: 0.018747463639592753
[Epoch 18, Batch 2300] loss: 0.030068873188574798
[Epoch 18, Batch 2400] loss: 0.014344151364675782
[Epoch 18, Batch 2500] loss: 0.024916454914055065
[Epoch 18, Batch 2600] loss: 0.015079105089371296
[Epoch 18, Batch 2700] loss: 0.023330814959481357
[Epoch 18, Batch 2800] loss: 0.02574517828092212
[Epoch 18, Batch 2900] loss: 0.028914450187367036
[Epoch 18, Batch 3000] loss: 0.025304124542890348
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0634
Validation Accuracy: 0.9827
Overfitting: 0.0634
[Epoch 19, Batch 100] loss: 0.026523413486720528
[Epoch 19, Batch 200] loss: 0.014754848502852837
[Epoch 19, Batch 300] loss: 0.03223054573230911
[Epoch 19, Batch 400] loss: 0.013816494580969447
[Epoch 19, Batch 500] loss: 0.019574061104503927
[Epoch 19, Batch 600] loss: 0.01408139959021355
[Epoch 19, Batch 700] loss: 0.013401049985041026
[Epoch 19, Batch 800] loss: 0.024485039029023027
[Epoch 19, Batch 900] loss: 0.014940646981704048
[Epoch 19, Batch 1000] loss: 0.01628304633151856
[Epoch 19, Batch 1100] loss: 0.02003779076135288
[Epoch 19, Batch 1200] loss: 0.02390299822916859
[Epoch 19, Batch 1300] loss: 0.02200931659719572
[Epoch 19, Batch 1400] loss: 0.01897706995026965
[Epoch 19, Batch 1500] loss: 0.009906829953142732
[Epoch 19, Batch 1600] loss: 0.017061271839702387
[Epoch 19, Batch 1700] loss: 0.017450842110010852
[Epoch 19, Batch 1800] loss: 0.02289910139003041
[Epoch 19, Batch 1900] loss: 0.02398126923624659
[Epoch 19, Batch 2000] loss: 0.038351849586179015
[Epoch 19, Batch 2100] loss: 0.02382980172489624
[Epoch 19, Batch 2200] loss: 0.0175684876357991
[Epoch 19, Batch 2300] loss: 0.019343642760577495
[Epoch 19, Batch 2400] loss: 0.018683597805938916
[Epoch 19, Batch 2500] loss: 0.023092248729099082
[Epoch 19, Batch 2600] loss: 0.019053632799441403
[Epoch 19, Batch 2700] loss: 0.024646145613696716
[Epoch 19, Batch 2800] loss: 0.024561889638353023
[Epoch 19, Batch 2900] loss: 0.023454354663554115
[Epoch 19, Batch 3000] loss: 0.010986153252306395
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9856
Overfitting: 0.0501
Best model saved at epoch 19 with validation loss: 0.0501
[Epoch 20, Batch 100] loss: 0.012597099587328558
[Epoch 20, Batch 200] loss: 0.018356353983617738
[Epoch 20, Batch 300] loss: 0.013919719366786012
[Epoch 20, Batch 400] loss: 0.016477512746496357
[Epoch 20, Batch 500] loss: 0.01269881825948687
[Epoch 20, Batch 600] loss: 0.02768835253395082
[Epoch 20, Batch 700] loss: 0.01718355639496622
[Epoch 20, Batch 800] loss: 0.01321545544135006
[Epoch 20, Batch 900] loss: 0.03644267889805633
[Epoch 20, Batch 1000] loss: 0.023009600307632355
[Epoch 20, Batch 1100] loss: 0.007920191427219834
[Epoch 20, Batch 1200] loss: 0.014875500906200614
[Epoch 20, Batch 1300] loss: 0.01772072103485698
[Epoch 20, Batch 1400] loss: 0.0168344365133089
[Epoch 20, Batch 1500] loss: 0.02124373247799667
[Epoch 20, Batch 1600] loss: 0.019465852066750812
[Epoch 20, Batch 1700] loss: 0.023577773193392205
[Epoch 20, Batch 1800] loss: 0.014707707004126859
[Epoch 20, Batch 1900] loss: 0.025860655372980546
[Epoch 20, Batch 2000] loss: 0.012317368765743596
[Epoch 20, Batch 2100] loss: 0.01871136869151087
[Epoch 20, Batch 2200] loss: 0.03483071774448035
[Epoch 20, Batch 2300] loss: 0.016883096707606456
[Epoch 20, Batch 2400] loss: 0.013086061738813442
[Epoch 20, Batch 2500] loss: 0.009059895153550315
[Epoch 20, Batch 2600] loss: 0.022484308180064545
[Epoch 20, Batch 2700] loss: 0.013475826645480993
[Epoch 20, Batch 2800] loss: 0.016486284258426166
[Epoch 20, Batch 2900] loss: 0.01938745917912456
[Epoch 20, Batch 3000] loss: 0.011458689042046898
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9848
Overfitting: 0.0536
[Epoch 21, Batch 100] loss: 0.01376488730442361
[Epoch 21, Batch 200] loss: 0.009514411079908313
[Epoch 21, Batch 300] loss: 0.017967645554781485
[Epoch 21, Batch 400] loss: 0.009807268871300038
[Epoch 21, Batch 500] loss: 0.016411984212099925
[Epoch 21, Batch 600] loss: 0.012673122696724022
[Epoch 21, Batch 700] loss: 0.01563617806597904
[Epoch 21, Batch 800] loss: 0.015492943276258301
[Epoch 21, Batch 900] loss: 0.01543273683717416
[Epoch 21, Batch 1000] loss: 0.013391762108039985
[Epoch 21, Batch 1100] loss: 0.023884278982004615
[Epoch 21, Batch 1200] loss: 0.015806570579334222
[Epoch 21, Batch 1300] loss: 0.020924532928383997
[Epoch 21, Batch 1400] loss: 0.013389069269687753
[Epoch 21, Batch 1500] loss: 0.023574452294997172
[Epoch 21, Batch 1600] loss: 0.011446732705026079
[Epoch 21, Batch 1700] loss: 0.013981947683350881
[Epoch 21, Batch 1800] loss: 0.01332531649075463
[Epoch 21, Batch 1900] loss: 0.019478520628908882
[Epoch 21, Batch 2000] loss: 0.024810903519573914
[Epoch 21, Batch 2100] loss: 0.02581196878250921
[Epoch 21, Batch 2200] loss: 0.013487804879296163
[Epoch 21, Batch 2300] loss: 0.015812496996022673
[Epoch 21, Batch 2400] loss: 0.013569518193544355
[Epoch 21, Batch 2500] loss: 0.014797099340976274
[Epoch 21, Batch 2600] loss: 0.03364061841897637
[Epoch 21, Batch 2700] loss: 0.01100822394251736
[Epoch 21, Batch 2800] loss: 0.024370117550206488
[Epoch 21, Batch 2900] loss: 0.012462226091483898
[Epoch 21, Batch 3000] loss: 0.011968353398842738
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9852
Overfitting: 0.0526
[Epoch 22, Batch 100] loss: 0.014642817018393544
[Epoch 22, Batch 200] loss: 0.01714216442846009
[Epoch 22, Batch 300] loss: 0.016004274449278454
[Epoch 22, Batch 400] loss: 0.013100362893101191
[Epoch 22, Batch 500] loss: 0.014305639027134021
[Epoch 22, Batch 600] loss: 0.013714512375790945
[Epoch 22, Batch 700] loss: 0.02014447334659053
[Epoch 22, Batch 800] loss: 0.018483158435556105
[Epoch 22, Batch 900] loss: 0.010464852524455637
[Epoch 22, Batch 1000] loss: 0.011496318390818487
[Epoch 22, Batch 1100] loss: 0.009438474007911282
[Epoch 22, Batch 1200] loss: 0.01350160111218429
[Epoch 22, Batch 1300] loss: 0.015317327322482015
[Epoch 22, Batch 1400] loss: 0.017813497561292024
[Epoch 22, Batch 1500] loss: 0.025814128559031816
[Epoch 22, Batch 1600] loss: 0.010844054319459246
[Epoch 22, Batch 1700] loss: 0.015524202891247113
[Epoch 22, Batch 1800] loss: 0.010819339291992946
[Epoch 22, Batch 1900] loss: 0.012648757848655805
[Epoch 22, Batch 2000] loss: 0.014605690220078031
[Epoch 22, Batch 2100] loss: 0.013890857957426306
[Epoch 22, Batch 2200] loss: 0.017814957881346346
[Epoch 22, Batch 2300] loss: 0.01646172148590267
[Epoch 22, Batch 2400] loss: 0.010626455575074942
[Epoch 22, Batch 2500] loss: 0.02043905636326599
[Epoch 22, Batch 2600] loss: 0.018599467757121603
[Epoch 22, Batch 2700] loss: 0.017826025844478864
[Epoch 22, Batch 2800] loss: 0.01348240958180213
[Epoch 22, Batch 2900] loss: 0.01724055714254064
[Epoch 22, Batch 3000] loss: 0.022841695357928984
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9843
Overfitting: 0.0529
[Epoch 23, Batch 100] loss: 0.010162499402267712
[Epoch 23, Batch 200] loss: 0.01401456636551302
[Epoch 23, Batch 300] loss: 0.01173542883754635
[Epoch 23, Batch 400] loss: 0.016526633933754056
[Epoch 23, Batch 500] loss: 0.015686275818170545
[Epoch 23, Batch 600] loss: 0.014820684115038603
[Epoch 23, Batch 700] loss: 0.02253708944803293
[Epoch 23, Batch 800] loss: 0.011786620921684516
[Epoch 23, Batch 900] loss: 0.010189783439345774
[Epoch 23, Batch 1000] loss: 0.007882659511687961
[Epoch 23, Batch 1100] loss: 0.020721427827629667
[Epoch 23, Batch 1200] loss: 0.009951545326148335
[Epoch 23, Batch 1300] loss: 0.008965488312569506
[Epoch 23, Batch 1400] loss: 0.01876068136851245
[Epoch 23, Batch 1500] loss: 0.010617983460833784
[Epoch 23, Batch 1600] loss: 0.015478969953983323
[Epoch 23, Batch 1700] loss: 0.016957905975941684
[Epoch 23, Batch 1800] loss: 0.007804106978728669
[Epoch 23, Batch 1900] loss: 0.014254133974063735
[Epoch 23, Batch 2000] loss: 0.016353547636717848
[Epoch 23, Batch 2100] loss: 0.019949328547063487
[Epoch 23, Batch 2200] loss: 0.01306678749546336
[Epoch 23, Batch 2300] loss: 0.008975075158923573
[Epoch 23, Batch 2400] loss: 0.010519118088977849
[Epoch 23, Batch 2500] loss: 0.01499170198570937
[Epoch 23, Batch 2600] loss: 0.018114761449610342
[Epoch 23, Batch 2700] loss: 0.010968032929449692
[Epoch 23, Batch 2800] loss: 0.014411501859522105
[Epoch 23, Batch 2900] loss: 0.017602125771509235
[Epoch 23, Batch 3000] loss: 0.00828850048958884
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9860
Overfitting: 0.0508
[Epoch 24, Batch 100] loss: 0.008390559096333162
[Epoch 24, Batch 200] loss: 0.007712356394231392
[Epoch 24, Batch 300] loss: 0.024521253817201796
[Epoch 24, Batch 400] loss: 0.012391965589467873
[Epoch 24, Batch 500] loss: 0.01216282178857
[Epoch 24, Batch 600] loss: 0.01208447215241904
[Epoch 24, Batch 700] loss: 0.015302798030352277
[Epoch 24, Batch 800] loss: 0.01752095514215398
[Epoch 24, Batch 900] loss: 0.011181597996201163
[Epoch 24, Batch 1000] loss: 0.014768607569058076
[Epoch 24, Batch 1100] loss: 0.009029977118989336
[Epoch 24, Batch 1200] loss: 0.011522744163830794
[Epoch 24, Batch 1300] loss: 0.009197102860143786
[Epoch 24, Batch 1400] loss: 0.013344145892078814
[Epoch 24, Batch 1500] loss: 0.01941282940986639
[Epoch 24, Batch 1600] loss: 0.013138159040190658
[Epoch 24, Batch 1700] loss: 0.009424984048237092
[Epoch 24, Batch 1800] loss: 0.015737096965531237
[Epoch 24, Batch 1900] loss: 0.011243735476255097
[Epoch 24, Batch 2000] loss: 0.010198062345989457
[Epoch 24, Batch 2100] loss: 0.01611663089373906
[Epoch 24, Batch 2200] loss: 0.01617556594679627
[Epoch 24, Batch 2300] loss: 0.020837380001939892
[Epoch 24, Batch 2400] loss: 0.023961540294167208
[Epoch 24, Batch 2500] loss: 0.015823103784441628
[Epoch 24, Batch 2600] loss: 0.014793067906339274
[Epoch 24, Batch 2700] loss: 0.0075389646302755865
[Epoch 24, Batch 2800] loss: 0.013005603601177427
[Epoch 24, Batch 2900] loss: 0.014868413868189236
[Epoch 24, Batch 3000] loss: 0.011712533844693097
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9858
Overfitting: 0.0523
Fold 2 validation loss: 0.0523
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3001128435134888
[Epoch 1, Batch 200] loss: 2.2982678699493406
[Epoch 1, Batch 300] loss: 2.2923296737670897
[Epoch 1, Batch 400] loss: 2.2872076869010924
[Epoch 1, Batch 500] loss: 2.2787442946434022
[Epoch 1, Batch 600] loss: 2.268579754829407
[Epoch 1, Batch 700] loss: 2.253453543186188
[Epoch 1, Batch 800] loss: 2.229449872970581
[Epoch 1, Batch 900] loss: 2.1920753812789915
[Epoch 1, Batch 1000] loss: 2.116757643222809
[Epoch 1, Batch 1100] loss: 1.9551123464107514
[Epoch 1, Batch 1200] loss: 1.6236359775066376
[Epoch 1, Batch 1300] loss: 1.1128794705867768
[Epoch 1, Batch 1400] loss: 0.7494424042105675
[Epoch 1, Batch 1500] loss: 0.5703492987155915
[Epoch 1, Batch 1600] loss: 0.4679796252399683
[Epoch 1, Batch 1700] loss: 0.4521519911289215
[Epoch 1, Batch 1800] loss: 0.36265914253890513
[Epoch 1, Batch 1900] loss: 0.3676229474321008
[Epoch 1, Batch 2000] loss: 0.3329646996036172
[Epoch 1, Batch 2100] loss: 0.3530663543194532
[Epoch 1, Batch 2200] loss: 0.30133912809193136
[Epoch 1, Batch 2300] loss: 0.31922489173710344
[Epoch 1, Batch 2400] loss: 0.25269353670999406
[Epoch 1, Batch 2500] loss: 0.2971147535741329
[Epoch 1, Batch 2600] loss: 0.25817916354164483
[Epoch 1, Batch 2700] loss: 0.2650905800238252
[Epoch 1, Batch 2800] loss: 0.24473161032423377
[Epoch 1, Batch 2900] loss: 0.24022599501535297
[Epoch 1, Batch 3000] loss: 0.25045315550640224
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2230
Validation Accuracy: 0.9343
Overfitting: 0.2230
Best model saved at epoch 1 with validation loss: 0.2230
[Epoch 2, Batch 100] loss: 0.21158025443553924
[Epoch 2, Batch 200] loss: 0.23141458434984088
[Epoch 2, Batch 300] loss: 0.23286811353638767
[Epoch 2, Batch 400] loss: 0.22304392261430622
[Epoch 2, Batch 500] loss: 0.23107129827141762
[Epoch 2, Batch 600] loss: 0.22864237362518908
[Epoch 2, Batch 700] loss: 0.16086239643394948
[Epoch 2, Batch 800] loss: 0.20163179516792298
[Epoch 2, Batch 900] loss: 0.1946003930270672
[Epoch 2, Batch 1000] loss: 0.18770023185759782
[Epoch 2, Batch 1100] loss: 0.17130067536607385
[Epoch 2, Batch 1200] loss: 0.1676500261714682
[Epoch 2, Batch 1300] loss: 0.1925543880276382
[Epoch 2, Batch 1400] loss: 0.17365207642316818
[Epoch 2, Batch 1500] loss: 0.18347886860370635
[Epoch 2, Batch 1600] loss: 0.16364288702141494
[Epoch 2, Batch 1700] loss: 0.15499378585256637
[Epoch 2, Batch 1800] loss: 0.17607229159213603
[Epoch 2, Batch 1900] loss: 0.14510430187918247
[Epoch 2, Batch 2000] loss: 0.15568272044416517
[Epoch 2, Batch 2100] loss: 0.1717544828914106
[Epoch 2, Batch 2200] loss: 0.16044635015074163
[Epoch 2, Batch 2300] loss: 0.17449505906552076
[Epoch 2, Batch 2400] loss: 0.20590939896181226
[Epoch 2, Batch 2500] loss: 0.130583727248013
[Epoch 2, Batch 2600] loss: 0.13921429610811173
[Epoch 2, Batch 2700] loss: 0.16418198062106967
[Epoch 2, Batch 2800] loss: 0.16428419919684528
[Epoch 2, Batch 2900] loss: 0.14154831807129084
[Epoch 2, Batch 3000] loss: 0.12754315590485932
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1509
Validation Accuracy: 0.9551
Overfitting: 0.1509
Best model saved at epoch 2 with validation loss: 0.1509
[Epoch 3, Batch 100] loss: 0.13003494196105747
[Epoch 3, Batch 200] loss: 0.14706822541542353
[Epoch 3, Batch 300] loss: 0.14511528433300555
[Epoch 3, Batch 400] loss: 0.15020981307141482
[Epoch 3, Batch 500] loss: 0.11133161221630872
[Epoch 3, Batch 600] loss: 0.13734951387159527
[Epoch 3, Batch 700] loss: 0.12165203302167356
[Epoch 3, Batch 800] loss: 0.14278191428165882
[Epoch 3, Batch 900] loss: 0.11858082056511193
[Epoch 3, Batch 1000] loss: 0.13085314401891082
[Epoch 3, Batch 1100] loss: 0.11057500125374645
[Epoch 3, Batch 1200] loss: 0.12658601290546356
[Epoch 3, Batch 1300] loss: 0.09895026005106047
[Epoch 3, Batch 1400] loss: 0.11226778964977711
[Epoch 3, Batch 1500] loss: 0.14248423208482563
[Epoch 3, Batch 1600] loss: 0.13345260839909315
[Epoch 3, Batch 1700] loss: 0.11373670709319413
[Epoch 3, Batch 1800] loss: 0.10905834817327559
[Epoch 3, Batch 1900] loss: 0.10895510565955192
[Epoch 3, Batch 2000] loss: 0.10857299837865866
[Epoch 3, Batch 2100] loss: 0.10155429455684498
[Epoch 3, Batch 2200] loss: 0.10651054407004266
[Epoch 3, Batch 2300] loss: 0.12265204160241411
[Epoch 3, Batch 2400] loss: 0.13207210071152076
[Epoch 3, Batch 2500] loss: 0.11482371803373098
[Epoch 3, Batch 2600] loss: 0.12380137639120221
[Epoch 3, Batch 2700] loss: 0.14124319360824303
[Epoch 3, Batch 2800] loss: 0.1272617824235931
[Epoch 3, Batch 2900] loss: 0.10118739873636513
[Epoch 3, Batch 3000] loss: 0.09822669313754886
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1091
Validation Accuracy: 0.9680
Overfitting: 0.1091
Best model saved at epoch 3 with validation loss: 0.1091
[Epoch 4, Batch 100] loss: 0.12447188676800579
[Epoch 4, Batch 200] loss: 0.09340132874902338
[Epoch 4, Batch 300] loss: 0.0911701812595129
[Epoch 4, Batch 400] loss: 0.12258638576837257
[Epoch 4, Batch 500] loss: 0.10173609195975587
[Epoch 4, Batch 600] loss: 0.1068598017655313
[Epoch 4, Batch 700] loss: 0.12572703568730503
[Epoch 4, Batch 800] loss: 0.10005381798371672
[Epoch 4, Batch 900] loss: 0.08055527688935399
[Epoch 4, Batch 1000] loss: 0.10893650445155799
[Epoch 4, Batch 1100] loss: 0.12406615917221643
[Epoch 4, Batch 1200] loss: 0.08873918595258147
[Epoch 4, Batch 1300] loss: 0.10828476203139871
[Epoch 4, Batch 1400] loss: 0.09981402242090553
[Epoch 4, Batch 1500] loss: 0.10816441018600016
[Epoch 4, Batch 1600] loss: 0.09626268903259189
[Epoch 4, Batch 1700] loss: 0.10574384127743543
[Epoch 4, Batch 1800] loss: 0.10610916916979476
[Epoch 4, Batch 1900] loss: 0.08624400843633338
[Epoch 4, Batch 2000] loss: 0.0926701023709029
[Epoch 4, Batch 2100] loss: 0.10456547228386626
[Epoch 4, Batch 2200] loss: 0.08759138692636043
[Epoch 4, Batch 2300] loss: 0.07840329323895276
[Epoch 4, Batch 2400] loss: 0.07494936694623902
[Epoch 4, Batch 2500] loss: 0.08888988828286529
[Epoch 4, Batch 2600] loss: 0.07297396288719028
[Epoch 4, Batch 2700] loss: 0.09836372546385974
[Epoch 4, Batch 2800] loss: 0.10097069122246466
[Epoch 4, Batch 2900] loss: 0.10158395866397768
[Epoch 4, Batch 3000] loss: 0.08831267850939184
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0965
Validation Accuracy: 0.9708
Overfitting: 0.0965
Best model saved at epoch 4 with validation loss: 0.0965
[Epoch 5, Batch 100] loss: 0.10930859636282549
[Epoch 5, Batch 200] loss: 0.07205628021503799
[Epoch 5, Batch 300] loss: 0.09135490485234186
[Epoch 5, Batch 400] loss: 0.10912973119877278
[Epoch 5, Batch 500] loss: 0.07788692192174494
[Epoch 5, Batch 600] loss: 0.0746350016957149
[Epoch 5, Batch 700] loss: 0.0943967675510794
[Epoch 5, Batch 800] loss: 0.0826567515078932
[Epoch 5, Batch 900] loss: 0.06063536670058966
[Epoch 5, Batch 1000] loss: 0.11816311416914686
[Epoch 5, Batch 1100] loss: 0.07772346795536578
[Epoch 5, Batch 1200] loss: 0.06532462705858051
[Epoch 5, Batch 1300] loss: 0.05772314117406495
[Epoch 5, Batch 1400] loss: 0.09453011096455156
[Epoch 5, Batch 1500] loss: 0.11644902451895177
[Epoch 5, Batch 1600] loss: 0.08705159418517723
[Epoch 5, Batch 1700] loss: 0.08204721330548637
[Epoch 5, Batch 1800] loss: 0.07318733799969777
[Epoch 5, Batch 1900] loss: 0.06933716259314679
[Epoch 5, Batch 2000] loss: 0.07963092045334634
[Epoch 5, Batch 2100] loss: 0.07362319074571133
[Epoch 5, Batch 2200] loss: 0.11073190993163734
[Epoch 5, Batch 2300] loss: 0.07080669305170886
[Epoch 5, Batch 2400] loss: 0.07327758815605194
[Epoch 5, Batch 2500] loss: 0.09137715136283077
[Epoch 5, Batch 2600] loss: 0.08460004219785333
[Epoch 5, Batch 2700] loss: 0.08199488581623882
[Epoch 5, Batch 2800] loss: 0.10252879212843254
[Epoch 5, Batch 2900] loss: 0.07888598702615127
[Epoch 5, Batch 3000] loss: 0.08143209540750831
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0797
Validation Accuracy: 0.9753
Overfitting: 0.0797
Best model saved at epoch 5 with validation loss: 0.0797
[Epoch 6, Batch 100] loss: 0.06439772412879392
[Epoch 6, Batch 200] loss: 0.07160650147590786
[Epoch 6, Batch 300] loss: 0.07872235292219557
[Epoch 6, Batch 400] loss: 0.06696342772105708
[Epoch 6, Batch 500] loss: 0.0772374945692718
[Epoch 6, Batch 600] loss: 0.07675891331862658
[Epoch 6, Batch 700] loss: 0.05959803445613943
[Epoch 6, Batch 800] loss: 0.09150906346156262
[Epoch 6, Batch 900] loss: 0.08885554622393102
[Epoch 6, Batch 1000] loss: 0.06502183357952163
[Epoch 6, Batch 1100] loss: 0.07127031928743235
[Epoch 6, Batch 1200] loss: 0.07216229792800732
[Epoch 6, Batch 1300] loss: 0.04991520165465772
[Epoch 6, Batch 1400] loss: 0.06707146243890748
[Epoch 6, Batch 1500] loss: 0.05820276306476444
[Epoch 6, Batch 1600] loss: 0.09123642795020714
[Epoch 6, Batch 1700] loss: 0.08196259127231315
[Epoch 6, Batch 1800] loss: 0.09078536261979026
[Epoch 6, Batch 1900] loss: 0.08629107457469218
[Epoch 6, Batch 2000] loss: 0.09156807208433747
[Epoch 6, Batch 2100] loss: 0.06974111032788642
[Epoch 6, Batch 2200] loss: 0.07754454368609004
[Epoch 6, Batch 2300] loss: 0.08880720755783841
[Epoch 6, Batch 2400] loss: 0.05996008436311968
[Epoch 6, Batch 2500] loss: 0.085993550211424
[Epoch 6, Batch 2600] loss: 0.0680599811533466
[Epoch 6, Batch 2700] loss: 0.07357426514849066
[Epoch 6, Batch 2800] loss: 0.07179989149793982
[Epoch 6, Batch 2900] loss: 0.06374489148147404
[Epoch 6, Batch 3000] loss: 0.06143875376554206
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0909
Validation Accuracy: 0.9724
Overfitting: 0.0909
[Epoch 7, Batch 100] loss: 0.048402357216691595
[Epoch 7, Batch 200] loss: 0.0669608047453221
[Epoch 7, Batch 300] loss: 0.07778435365762562
[Epoch 7, Batch 400] loss: 0.06539436714607291
[Epoch 7, Batch 500] loss: 0.07858281536959112
[Epoch 7, Batch 600] loss: 0.06820481148781254
[Epoch 7, Batch 700] loss: 0.07177914136787876
[Epoch 7, Batch 800] loss: 0.06817840999574401
[Epoch 7, Batch 900] loss: 0.07762112617027014
[Epoch 7, Batch 1000] loss: 0.0669162983482238
[Epoch 7, Batch 1100] loss: 0.07012380146188661
[Epoch 7, Batch 1200] loss: 0.07602384270867332
[Epoch 7, Batch 1300] loss: 0.07418950278195552
[Epoch 7, Batch 1400] loss: 0.06295842013205402
[Epoch 7, Batch 1500] loss: 0.061039461511536504
[Epoch 7, Batch 1600] loss: 0.06447157643735409
[Epoch 7, Batch 1700] loss: 0.05943106133956462
[Epoch 7, Batch 1800] loss: 0.05521697371732444
[Epoch 7, Batch 1900] loss: 0.03681512442126404
[Epoch 7, Batch 2000] loss: 0.06163530704390723
[Epoch 7, Batch 2100] loss: 0.05748043399944436
[Epoch 7, Batch 2200] loss: 0.06686236115870997
[Epoch 7, Batch 2300] loss: 0.05755814886651933
[Epoch 7, Batch 2400] loss: 0.06947323558008066
[Epoch 7, Batch 2500] loss: 0.05663491607585456
[Epoch 7, Batch 2600] loss: 0.07353003652533516
[Epoch 7, Batch 2700] loss: 0.06496334175113588
[Epoch 7, Batch 2800] loss: 0.058405556901125234
[Epoch 7, Batch 2900] loss: 0.06524997777538374
[Epoch 7, Batch 3000] loss: 0.07439324852486606
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0720
Validation Accuracy: 0.9771
Overfitting: 0.0720
Best model saved at epoch 7 with validation loss: 0.0720
[Epoch 8, Batch 100] loss: 0.04787359267938882
[Epoch 8, Batch 200] loss: 0.06378438900399487
[Epoch 8, Batch 300] loss: 0.0517175414529629
[Epoch 8, Batch 400] loss: 0.055691932163317685
[Epoch 8, Batch 500] loss: 0.07601467185013462
[Epoch 8, Batch 600] loss: 0.058913068977417424
[Epoch 8, Batch 700] loss: 0.05394580037391279
[Epoch 8, Batch 800] loss: 0.04895939912414178
[Epoch 8, Batch 900] loss: 0.06201079602673417
[Epoch 8, Batch 1000] loss: 0.0650588442053413
[Epoch 8, Batch 1100] loss: 0.03751930538972374
[Epoch 8, Batch 1200] loss: 0.05896060979750473
[Epoch 8, Batch 1300] loss: 0.0518591923522763
[Epoch 8, Batch 1400] loss: 0.064254736272851
[Epoch 8, Batch 1500] loss: 0.07080390887334943
[Epoch 8, Batch 1600] loss: 0.02693428269441938
[Epoch 8, Batch 1700] loss: 0.0714811784104677
[Epoch 8, Batch 1800] loss: 0.054108741364907474
[Epoch 8, Batch 1900] loss: 0.05617177106149029
[Epoch 8, Batch 2000] loss: 0.05982300352770835
[Epoch 8, Batch 2100] loss: 0.05740922999320901
[Epoch 8, Batch 2200] loss: 0.049190331035060805
[Epoch 8, Batch 2300] loss: 0.05775641601998359
[Epoch 8, Batch 2400] loss: 0.06555364615865983
[Epoch 8, Batch 2500] loss: 0.06397021597076673
[Epoch 8, Batch 2600] loss: 0.049087292319745755
[Epoch 8, Batch 2700] loss: 0.05784854125464335
[Epoch 8, Batch 2800] loss: 0.07639377691317349
[Epoch 8, Batch 2900] loss: 0.07330924835026963
[Epoch 8, Batch 3000] loss: 0.07127701403864194
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0706
Validation Accuracy: 0.9771
Overfitting: 0.0706
Best model saved at epoch 8 with validation loss: 0.0706
[Epoch 9, Batch 100] loss: 0.05986202384752687
[Epoch 9, Batch 200] loss: 0.056001553960959426
[Epoch 9, Batch 300] loss: 0.049377349577262065
[Epoch 9, Batch 400] loss: 0.06537265775725246
[Epoch 9, Batch 500] loss: 0.04819095184415346
[Epoch 9, Batch 600] loss: 0.04475733030063566
[Epoch 9, Batch 700] loss: 0.04591020298539661
[Epoch 9, Batch 800] loss: 0.061475617508403954
[Epoch 9, Batch 900] loss: 0.042057532913750036
[Epoch 9, Batch 1000] loss: 0.059194142827764154
[Epoch 9, Batch 1100] loss: 0.05273021914588753
[Epoch 9, Batch 1200] loss: 0.05813902219990268
[Epoch 9, Batch 1300] loss: 0.05946431510732509
[Epoch 9, Batch 1400] loss: 0.0659110045817215
[Epoch 9, Batch 1500] loss: 0.06134530985553283
[Epoch 9, Batch 1600] loss: 0.0408066936902469
[Epoch 9, Batch 1700] loss: 0.06290048523107544
[Epoch 9, Batch 1800] loss: 0.055596857843920586
[Epoch 9, Batch 1900] loss: 0.06584215107723139
[Epoch 9, Batch 2000] loss: 0.06209517234237864
[Epoch 9, Batch 2100] loss: 0.05538460639538243
[Epoch 9, Batch 2200] loss: 0.04069974763988284
[Epoch 9, Batch 2300] loss: 0.054922653809771876
[Epoch 9, Batch 2400] loss: 0.058071522221434864
[Epoch 9, Batch 2500] loss: 0.04755532865819987
[Epoch 9, Batch 2600] loss: 0.048695823526068126
[Epoch 9, Batch 2700] loss: 0.04161639520025347
[Epoch 9, Batch 2800] loss: 0.0584037701721536
[Epoch 9, Batch 2900] loss: 0.04026840463397093
[Epoch 9, Batch 3000] loss: 0.04541391913429834
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9818
Overfitting: 0.0605
Best model saved at epoch 9 with validation loss: 0.0605
[Epoch 10, Batch 100] loss: 0.05144522601738572
[Epoch 10, Batch 200] loss: 0.05662533927301411
[Epoch 10, Batch 300] loss: 0.05784016106743366
[Epoch 10, Batch 400] loss: 0.04505996726686135
[Epoch 10, Batch 500] loss: 0.04910171693831217
[Epoch 10, Batch 600] loss: 0.05612061442778213
[Epoch 10, Batch 700] loss: 0.03600302235223353
[Epoch 10, Batch 800] loss: 0.04107675637176726
[Epoch 10, Batch 900] loss: 0.052861188047972976
[Epoch 10, Batch 1000] loss: 0.04859706483141053
[Epoch 10, Batch 1100] loss: 0.05122410180512816
[Epoch 10, Batch 1200] loss: 0.045997115424543156
[Epoch 10, Batch 1300] loss: 0.04474926262890221
[Epoch 10, Batch 1400] loss: 0.05501081618480384
[Epoch 10, Batch 1500] loss: 0.0646580442879349
[Epoch 10, Batch 1600] loss: 0.0454066893766867
[Epoch 10, Batch 1700] loss: 0.0493326115392847
[Epoch 10, Batch 1800] loss: 0.04521373038180172
[Epoch 10, Batch 1900] loss: 0.04960271065123379
[Epoch 10, Batch 2000] loss: 0.03875935368196224
[Epoch 10, Batch 2100] loss: 0.06425181624712423
[Epoch 10, Batch 2200] loss: 0.05676680728473002
[Epoch 10, Batch 2300] loss: 0.03684609855117742
[Epoch 10, Batch 2400] loss: 0.03921232429740485
[Epoch 10, Batch 2500] loss: 0.03784878280886914
[Epoch 10, Batch 2600] loss: 0.04947227433658554
[Epoch 10, Batch 2700] loss: 0.04891552555083763
[Epoch 10, Batch 2800] loss: 0.047200673585757615
[Epoch 10, Batch 2900] loss: 0.05219539135228843
[Epoch 10, Batch 3000] loss: 0.060443017287761906
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0647
Validation Accuracy: 0.9800
Overfitting: 0.0647
[Epoch 11, Batch 100] loss: 0.04170142511022277
[Epoch 11, Batch 200] loss: 0.054013295121258124
[Epoch 11, Batch 300] loss: 0.046512402090011166
[Epoch 11, Batch 400] loss: 0.043963291530671994
[Epoch 11, Batch 500] loss: 0.03476030982637894
[Epoch 11, Batch 600] loss: 0.04952267435146496
[Epoch 11, Batch 700] loss: 0.04011512743541971
[Epoch 11, Batch 800] loss: 0.043378839219221844
[Epoch 11, Batch 900] loss: 0.046052250214852396
[Epoch 11, Batch 1000] loss: 0.04856456804904155
[Epoch 11, Batch 1100] loss: 0.04939695884531829
[Epoch 11, Batch 1200] loss: 0.0531233005062677
[Epoch 11, Batch 1300] loss: 0.04806545282335719
[Epoch 11, Batch 1400] loss: 0.04475677304537385
[Epoch 11, Batch 1500] loss: 0.03645870387408649
[Epoch 11, Batch 1600] loss: 0.058034133900655434
[Epoch 11, Batch 1700] loss: 0.04856992228422314
[Epoch 11, Batch 1800] loss: 0.04462422995595262
[Epoch 11, Batch 1900] loss: 0.03922741091431817
[Epoch 11, Batch 2000] loss: 0.047475079811410976
[Epoch 11, Batch 2100] loss: 0.05265718446986284
[Epoch 11, Batch 2200] loss: 0.041927571628039007
[Epoch 11, Batch 2300] loss: 0.040972326377523134
[Epoch 11, Batch 2400] loss: 0.050179575459624176
[Epoch 11, Batch 2500] loss: 0.03537530635570874
[Epoch 11, Batch 2600] loss: 0.05036375523690367
[Epoch 11, Batch 2700] loss: 0.027807616192731074
[Epoch 11, Batch 2800] loss: 0.04784214718849398
[Epoch 11, Batch 2900] loss: 0.04892276375496294
[Epoch 11, Batch 3000] loss: 0.0435231891652802
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0624
Validation Accuracy: 0.9807
Overfitting: 0.0624
[Epoch 12, Batch 100] loss: 0.039314192275633104
[Epoch 12, Batch 200] loss: 0.0378641476429766
[Epoch 12, Batch 300] loss: 0.04687521832005587
[Epoch 12, Batch 400] loss: 0.05653907328378409
[Epoch 12, Batch 500] loss: 0.06357011704531032
[Epoch 12, Batch 600] loss: 0.027487409497844055
[Epoch 12, Batch 700] loss: 0.042201145187718794
[Epoch 12, Batch 800] loss: 0.043450612078304404
[Epoch 12, Batch 900] loss: 0.028800875117158283
[Epoch 12, Batch 1000] loss: 0.03757530614151619
[Epoch 12, Batch 1100] loss: 0.03649828113586409
[Epoch 12, Batch 1200] loss: 0.03694780455058208
[Epoch 12, Batch 1300] loss: 0.04895588995597791
[Epoch 12, Batch 1400] loss: 0.04468464589182986
[Epoch 12, Batch 1500] loss: 0.05008733184804441
[Epoch 12, Batch 1600] loss: 0.035256319890904705
[Epoch 12, Batch 1700] loss: 0.03280977624148363
[Epoch 12, Batch 1800] loss: 0.04056190090821474
[Epoch 12, Batch 1900] loss: 0.032119469698227474
[Epoch 12, Batch 2000] loss: 0.045542612884019035
[Epoch 12, Batch 2100] loss: 0.041354911623056975
[Epoch 12, Batch 2200] loss: 0.03611775118682999
[Epoch 12, Batch 2300] loss: 0.0459286402122234
[Epoch 12, Batch 2400] loss: 0.04177298190552392
[Epoch 12, Batch 2500] loss: 0.03247874938533642
[Epoch 12, Batch 2600] loss: 0.04669620147673413
[Epoch 12, Batch 2700] loss: 0.04450432743527927
[Epoch 12, Batch 2800] loss: 0.03141624801792205
[Epoch 12, Batch 2900] loss: 0.04239067058413639
[Epoch 12, Batch 3000] loss: 0.040239898710569835
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0591
Validation Accuracy: 0.9818
Overfitting: 0.0591
Best model saved at epoch 12 with validation loss: 0.0591
[Epoch 13, Batch 100] loss: 0.025345094770455035
[Epoch 13, Batch 200] loss: 0.033355874046101235
[Epoch 13, Batch 300] loss: 0.033569016650726556
[Epoch 13, Batch 400] loss: 0.037577918507158754
[Epoch 13, Batch 500] loss: 0.028535377389343922
[Epoch 13, Batch 600] loss: 0.039584294697560835
[Epoch 13, Batch 700] loss: 0.03243382173532154
[Epoch 13, Batch 800] loss: 0.045826414389302954
[Epoch 13, Batch 900] loss: 0.02876679430628428
[Epoch 13, Batch 1000] loss: 0.04000183718831977
[Epoch 13, Batch 1100] loss: 0.045197824834613126
[Epoch 13, Batch 1200] loss: 0.037862951993301974
[Epoch 13, Batch 1300] loss: 0.038231612204399426
[Epoch 13, Batch 1400] loss: 0.0306719665665878
[Epoch 13, Batch 1500] loss: 0.03365938319693669
[Epoch 13, Batch 1600] loss: 0.03542817736248253
[Epoch 13, Batch 1700] loss: 0.04485281714529265
[Epoch 13, Batch 1800] loss: 0.032852388181781864
[Epoch 13, Batch 1900] loss: 0.048843499899812744
[Epoch 13, Batch 2000] loss: 0.035377087435044814
[Epoch 13, Batch 2100] loss: 0.0498132484650705
[Epoch 13, Batch 2200] loss: 0.048755720100889445
[Epoch 13, Batch 2300] loss: 0.043098159610235595
[Epoch 13, Batch 2400] loss: 0.0453116172720911
[Epoch 13, Batch 2500] loss: 0.04018904384545749
[Epoch 13, Batch 2600] loss: 0.022669792028900702
[Epoch 13, Batch 2700] loss: 0.025615521884319606
[Epoch 13, Batch 2800] loss: 0.03524665297882166
[Epoch 13, Batch 2900] loss: 0.05694113551726332
[Epoch 13, Batch 3000] loss: 0.03822551296005258
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9838
Overfitting: 0.0539
Best model saved at epoch 13 with validation loss: 0.0539
[Epoch 14, Batch 100] loss: 0.04365389709797455
[Epoch 14, Batch 200] loss: 0.02573449613104458
[Epoch 14, Batch 300] loss: 0.01860395833326038
[Epoch 14, Batch 400] loss: 0.030930618684797084
[Epoch 14, Batch 500] loss: 0.04735590688258526
[Epoch 14, Batch 600] loss: 0.04062789963973046
[Epoch 14, Batch 700] loss: 0.03326100499703898
[Epoch 14, Batch 800] loss: 0.03849757045332808
[Epoch 14, Batch 900] loss: 0.039622433636250204
[Epoch 14, Batch 1000] loss: 0.030290158795614842
[Epoch 14, Batch 1100] loss: 0.026189355027017882
[Epoch 14, Batch 1200] loss: 0.03921884637849871
[Epoch 14, Batch 1300] loss: 0.03203062647953629
[Epoch 14, Batch 1400] loss: 0.0308029936546518
[Epoch 14, Batch 1500] loss: 0.03971261440885428
[Epoch 14, Batch 1600] loss: 0.03893354823201662
[Epoch 14, Batch 1700] loss: 0.0340110218571499
[Epoch 14, Batch 1800] loss: 0.04958871925846324
[Epoch 14, Batch 1900] loss: 0.038802782399579884
[Epoch 14, Batch 2000] loss: 0.02911606794310501
[Epoch 14, Batch 2100] loss: 0.042171351720462553
[Epoch 14, Batch 2200] loss: 0.031666746788250745
[Epoch 14, Batch 2300] loss: 0.03381743025616743
[Epoch 14, Batch 2400] loss: 0.04743721355102025
[Epoch 14, Batch 2500] loss: 0.030167187364131678
[Epoch 14, Batch 2600] loss: 0.037607406769529915
[Epoch 14, Batch 2700] loss: 0.03895486095541855
[Epoch 14, Batch 2800] loss: 0.026169948985625524
[Epoch 14, Batch 2900] loss: 0.04224519269366283
[Epoch 14, Batch 3000] loss: 0.02990177438085084
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0498
Validation Accuracy: 0.9851
Overfitting: 0.0498
Best model saved at epoch 14 with validation loss: 0.0498
[Epoch 15, Batch 100] loss: 0.04193827687005978
[Epoch 15, Batch 200] loss: 0.03731278423278127
[Epoch 15, Batch 300] loss: 0.021186920936743264
[Epoch 15, Batch 400] loss: 0.041154383291432166
[Epoch 15, Batch 500] loss: 0.030589318497513885
[Epoch 15, Batch 600] loss: 0.03147469213145086
[Epoch 15, Batch 700] loss: 0.02786098728480283
[Epoch 15, Batch 800] loss: 0.026042476283037103
[Epoch 15, Batch 900] loss: 0.049971007193380504
[Epoch 15, Batch 1000] loss: 0.027383621509579827
[Epoch 15, Batch 1100] loss: 0.025846891387191137
[Epoch 15, Batch 1200] loss: 0.04029124331209459
[Epoch 15, Batch 1300] loss: 0.040796513508830685
[Epoch 15, Batch 1400] loss: 0.0289392287247756
[Epoch 15, Batch 1500] loss: 0.034230833557303414
[Epoch 15, Batch 1600] loss: 0.027277743110316804
[Epoch 15, Batch 1700] loss: 0.028033839908021038
[Epoch 15, Batch 1800] loss: 0.02489110487018479
[Epoch 15, Batch 1900] loss: 0.031085667444494904
[Epoch 15, Batch 2000] loss: 0.038734778350044505
[Epoch 15, Batch 2100] loss: 0.03417017958840006
[Epoch 15, Batch 2200] loss: 0.027281992551870644
[Epoch 15, Batch 2300] loss: 0.03279128613008652
[Epoch 15, Batch 2400] loss: 0.03867325028462801
[Epoch 15, Batch 2500] loss: 0.0261808844958432
[Epoch 15, Batch 2600] loss: 0.030644428235536907
[Epoch 15, Batch 2700] loss: 0.05313009734949446
[Epoch 15, Batch 2800] loss: 0.029194187649845844
[Epoch 15, Batch 2900] loss: 0.02284520289336797
[Epoch 15, Batch 3000] loss: 0.032368296384520365
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9845
Overfitting: 0.0515
[Epoch 16, Batch 100] loss: 0.027003279945347458
[Epoch 16, Batch 200] loss: 0.033604222745780135
[Epoch 16, Batch 300] loss: 0.034477294661119234
[Epoch 16, Batch 400] loss: 0.028313969233713578
[Epoch 16, Batch 500] loss: 0.027582907312462338
[Epoch 16, Batch 600] loss: 0.027886981493793428
[Epoch 16, Batch 700] loss: 0.0257043834029173
[Epoch 16, Batch 800] loss: 0.01885965499546728
[Epoch 16, Batch 900] loss: 0.027825374488165834
[Epoch 16, Batch 1000] loss: 0.028140559061430395
[Epoch 16, Batch 1100] loss: 0.046006946507841345
[Epoch 16, Batch 1200] loss: 0.020276582067308483
[Epoch 16, Batch 1300] loss: 0.028228406084963353
[Epoch 16, Batch 1400] loss: 0.0327893749953364
[Epoch 16, Batch 1500] loss: 0.03978256545669865
[Epoch 16, Batch 1600] loss: 0.03239981513092061
[Epoch 16, Batch 1700] loss: 0.026779019293899184
[Epoch 16, Batch 1800] loss: 0.03166039778414415
[Epoch 16, Batch 1900] loss: 0.027336505301500436
[Epoch 16, Batch 2000] loss: 0.03806151962118747
[Epoch 16, Batch 2100] loss: 0.023697925741653306
[Epoch 16, Batch 2200] loss: 0.03677914993153536
[Epoch 16, Batch 2300] loss: 0.02998834379395703
[Epoch 16, Batch 2400] loss: 0.026728981973428746
[Epoch 16, Batch 2500] loss: 0.02689106885562069
[Epoch 16, Batch 2600] loss: 0.0364771846732765
[Epoch 16, Batch 2700] loss: 0.03625268756732112
[Epoch 16, Batch 2800] loss: 0.0297767360531725
[Epoch 16, Batch 2900] loss: 0.030324443573481404
[Epoch 16, Batch 3000] loss: 0.02405999701783003
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9842
Overfitting: 0.0506
[Epoch 17, Batch 100] loss: 0.026054268607695122
[Epoch 17, Batch 200] loss: 0.025806145187525543
[Epoch 17, Batch 300] loss: 0.03597780594252981
[Epoch 17, Batch 400] loss: 0.02670709165162407
[Epoch 17, Batch 500] loss: 0.028037720066568
[Epoch 17, Batch 600] loss: 0.01974346751550911
[Epoch 17, Batch 700] loss: 0.026592594357643974
[Epoch 17, Batch 800] loss: 0.02560160693094076
[Epoch 17, Batch 900] loss: 0.028751106258278016
[Epoch 17, Batch 1000] loss: 0.026489171669090865
[Epoch 17, Batch 1100] loss: 0.019599489380198065
[Epoch 17, Batch 1200] loss: 0.020219528364832512
[Epoch 17, Batch 1300] loss: 0.027155816949525614
[Epoch 17, Batch 1400] loss: 0.03157869668939384
[Epoch 17, Batch 1500] loss: 0.024227908141328955
[Epoch 17, Batch 1600] loss: 0.025060845472326038
[Epoch 17, Batch 1700] loss: 0.021485589509393322
[Epoch 17, Batch 1800] loss: 0.03251637542038224
[Epoch 17, Batch 1900] loss: 0.022098608490850893
[Epoch 17, Batch 2000] loss: 0.02552670040677185
[Epoch 17, Batch 2100] loss: 0.04203574448765721
[Epoch 17, Batch 2200] loss: 0.02897790945164161
[Epoch 17, Batch 2300] loss: 0.04115236295037903
[Epoch 17, Batch 2400] loss: 0.03072449583254638
[Epoch 17, Batch 2500] loss: 0.023915559650558863
[Epoch 17, Batch 2600] loss: 0.021715270254208007
[Epoch 17, Batch 2700] loss: 0.03461021554408944
[Epoch 17, Batch 2800] loss: 0.026385773070869617
[Epoch 17, Batch 2900] loss: 0.034001842685975135
[Epoch 17, Batch 3000] loss: 0.04082674360033707
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9839
Overfitting: 0.0524
[Epoch 18, Batch 100] loss: 0.024502079661906463
[Epoch 18, Batch 200] loss: 0.02210716398025397
[Epoch 18, Batch 300] loss: 0.030688015202031238
[Epoch 18, Batch 400] loss: 0.014309161720975681
[Epoch 18, Batch 500] loss: 0.02890552711469354
[Epoch 18, Batch 600] loss: 0.01565716641365725
[Epoch 18, Batch 700] loss: 0.023785018561175094
[Epoch 18, Batch 800] loss: 0.019627933776791905
[Epoch 18, Batch 900] loss: 0.026155205760951504
[Epoch 18, Batch 1000] loss: 0.036583934428927024
[Epoch 18, Batch 1100] loss: 0.02655525900729117
[Epoch 18, Batch 1200] loss: 0.02809429137294501
[Epoch 18, Batch 1300] loss: 0.03365558192912431
[Epoch 18, Batch 1400] loss: 0.020440898722736165
[Epoch 18, Batch 1500] loss: 0.017875573708734008
[Epoch 18, Batch 1600] loss: 0.028303667857835536
[Epoch 18, Batch 1700] loss: 0.028541389576130314
[Epoch 18, Batch 1800] loss: 0.027028328259621048
[Epoch 18, Batch 1900] loss: 0.03364364607768948
[Epoch 18, Batch 2000] loss: 0.029330695417156674
[Epoch 18, Batch 2100] loss: 0.028596436723528313
[Epoch 18, Batch 2200] loss: 0.02942366304268944
[Epoch 18, Batch 2300] loss: 0.0233458459211397
[Epoch 18, Batch 2400] loss: 0.019545847151894124
[Epoch 18, Batch 2500] loss: 0.0286958749529731
[Epoch 18, Batch 2600] loss: 0.027906431367446204
[Epoch 18, Batch 2700] loss: 0.03379382077830087
[Epoch 18, Batch 2800] loss: 0.016996646779443837
[Epoch 18, Batch 2900] loss: 0.035486606911290436
[Epoch 18, Batch 3000] loss: 0.018481752280858927
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9850
Overfitting: 0.0499
[Epoch 19, Batch 100] loss: 0.024910555282913263
[Epoch 19, Batch 200] loss: 0.023306605009711347
[Epoch 19, Batch 300] loss: 0.018559503266078536
[Epoch 19, Batch 400] loss: 0.023924702881777192
[Epoch 19, Batch 500] loss: 0.021402326385868947
[Epoch 19, Batch 600] loss: 0.028053352658389485
[Epoch 19, Batch 700] loss: 0.021739432488320744
[Epoch 19, Batch 800] loss: 0.022474089648603694
[Epoch 19, Batch 900] loss: 0.017910206938977352
[Epoch 19, Batch 1000] loss: 0.02130146268040335
[Epoch 19, Batch 1100] loss: 0.032778660317489994
[Epoch 19, Batch 1200] loss: 0.019065734278265155
[Epoch 19, Batch 1300] loss: 0.017461662384448573
[Epoch 19, Batch 1400] loss: 0.023074715675538756
[Epoch 19, Batch 1500] loss: 0.01889627851858677
[Epoch 19, Batch 1600] loss: 0.036278963566473976
[Epoch 19, Batch 1700] loss: 0.019831985744167467
[Epoch 19, Batch 1800] loss: 0.03163732854787668
[Epoch 19, Batch 1900] loss: 0.027240828718640843
[Epoch 19, Batch 2000] loss: 0.029118622852765837
[Epoch 19, Batch 2100] loss: 0.025300487976055594
[Epoch 19, Batch 2200] loss: 0.0391998081978818
[Epoch 19, Batch 2300] loss: 0.021390808937940164
[Epoch 19, Batch 2400] loss: 0.02032805247225042
[Epoch 19, Batch 2500] loss: 0.02757879375567427
[Epoch 19, Batch 2600] loss: 0.0234193942947968
[Epoch 19, Batch 2700] loss: 0.018435808306967373
[Epoch 19, Batch 2800] loss: 0.021057399573473957
[Epoch 19, Batch 2900] loss: 0.018460498616768746
[Epoch 19, Batch 3000] loss: 0.02500882298692886
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9851
Overfitting: 0.0497
Best model saved at epoch 19 with validation loss: 0.0497
[Epoch 20, Batch 100] loss: 0.01727776878302393
[Epoch 20, Batch 200] loss: 0.01702977529494092
[Epoch 20, Batch 300] loss: 0.02258945741386924
[Epoch 20, Batch 400] loss: 0.014852622810867615
[Epoch 20, Batch 500] loss: 0.012628062962758122
[Epoch 20, Batch 600] loss: 0.023524267504253658
[Epoch 20, Batch 700] loss: 0.015034307640344196
[Epoch 20, Batch 800] loss: 0.02115059998941433
[Epoch 20, Batch 900] loss: 0.02776726955715276
[Epoch 20, Batch 1000] loss: 0.01656356527673779
[Epoch 20, Batch 1100] loss: 0.017899015755028815
[Epoch 20, Batch 1200] loss: 0.03068993219112599
[Epoch 20, Batch 1300] loss: 0.03144824954484648
[Epoch 20, Batch 1400] loss: 0.02566754572908394
[Epoch 20, Batch 1500] loss: 0.01865918959665578
[Epoch 20, Batch 1600] loss: 0.025471156480998614
[Epoch 20, Batch 1700] loss: 0.03188785070509766
[Epoch 20, Batch 1800] loss: 0.01968277967560425
[Epoch 20, Batch 1900] loss: 0.03775117497661995
[Epoch 20, Batch 2000] loss: 0.026931573105830466
[Epoch 20, Batch 2100] loss: 0.022508491188418703
[Epoch 20, Batch 2200] loss: 0.025268486805725843
[Epoch 20, Batch 2300] loss: 0.0164901961175201
[Epoch 20, Batch 2400] loss: 0.02166974336205385
[Epoch 20, Batch 2500] loss: 0.035098185342358194
[Epoch 20, Batch 2600] loss: 0.02066404170629539
[Epoch 20, Batch 2700] loss: 0.020047052778172657
[Epoch 20, Batch 2800] loss: 0.02042586881418174
[Epoch 20, Batch 2900] loss: 0.030022272388014245
[Epoch 20, Batch 3000] loss: 0.019787049188962555
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9838
Overfitting: 0.0546
[Epoch 21, Batch 100] loss: 0.023229927510474226
[Epoch 21, Batch 200] loss: 0.016361332732922163
[Epoch 21, Batch 300] loss: 0.017269733320281377
[Epoch 21, Batch 400] loss: 0.01701029445772292
[Epoch 21, Batch 500] loss: 0.02530503212736221
[Epoch 21, Batch 600] loss: 0.022226462811158854
[Epoch 21, Batch 700] loss: 0.02662549075521383
[Epoch 21, Batch 800] loss: 0.00900871734138491
[Epoch 21, Batch 900] loss: 0.02043264214808005
[Epoch 21, Batch 1000] loss: 0.015289913148808409
[Epoch 21, Batch 1100] loss: 0.01691665682112216
[Epoch 21, Batch 1200] loss: 0.026427109064752586
[Epoch 21, Batch 1300] loss: 0.020524298416785314
[Epoch 21, Batch 1400] loss: 0.025136805703441498
[Epoch 21, Batch 1500] loss: 0.012026473928635824
[Epoch 21, Batch 1600] loss: 0.018240309693064772
[Epoch 21, Batch 1700] loss: 0.02054442734362965
[Epoch 21, Batch 1800] loss: 0.022010933670826488
[Epoch 21, Batch 1900] loss: 0.019004662027764425
[Epoch 21, Batch 2000] loss: 0.011863167254632571
[Epoch 21, Batch 2100] loss: 0.01663400366989663
[Epoch 21, Batch 2200] loss: 0.02156119019644393
[Epoch 21, Batch 2300] loss: 0.034864837115528645
[Epoch 21, Batch 2400] loss: 0.03074999971286161
[Epoch 21, Batch 2500] loss: 0.018103557838403502
[Epoch 21, Batch 2600] loss: 0.024122115743739413
[Epoch 21, Batch 2700] loss: 0.018156692448064858
[Epoch 21, Batch 2800] loss: 0.029939819042920136
[Epoch 21, Batch 2900] loss: 0.023674483738795972
[Epoch 21, Batch 3000] loss: 0.01898587551782839
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9881
Overfitting: 0.0441
Best model saved at epoch 21 with validation loss: 0.0441
[Epoch 22, Batch 100] loss: 0.01787197603720415
[Epoch 22, Batch 200] loss: 0.017939493216981645
[Epoch 22, Batch 300] loss: 0.017542079727609235
[Epoch 22, Batch 400] loss: 0.0149840818708617
[Epoch 22, Batch 500] loss: 0.013982640679896576
[Epoch 22, Batch 600] loss: 0.015173808061881573
[Epoch 22, Batch 700] loss: 0.014731421234901064
[Epoch 22, Batch 800] loss: 0.013824162205419271
[Epoch 22, Batch 900] loss: 0.016507442661677488
[Epoch 22, Batch 1000] loss: 0.018736527754308552
[Epoch 22, Batch 1100] loss: 0.011488452543635503
[Epoch 22, Batch 1200] loss: 0.016765808202399056
[Epoch 22, Batch 1300] loss: 0.015141778512424936
[Epoch 22, Batch 1400] loss: 0.01618519235707936
[Epoch 22, Batch 1500] loss: 0.02010526982237934
[Epoch 22, Batch 1600] loss: 0.018046347957679246
[Epoch 22, Batch 1700] loss: 0.03440045930656197
[Epoch 22, Batch 1800] loss: 0.019843177795482916
[Epoch 22, Batch 1900] loss: 0.018392950259585632
[Epoch 22, Batch 2000] loss: 0.014090721014144946
[Epoch 22, Batch 2100] loss: 0.021116717404183874
[Epoch 22, Batch 2200] loss: 0.03940315681829816
[Epoch 22, Batch 2300] loss: 0.026614519048453075
[Epoch 22, Batch 2400] loss: 0.030093568332085853
[Epoch 22, Batch 2500] loss: 0.025101958602535886
[Epoch 22, Batch 2600] loss: 0.016885821936702995
[Epoch 22, Batch 2700] loss: 0.01797479302418651
[Epoch 22, Batch 2800] loss: 0.015039600590826012
[Epoch 22, Batch 2900] loss: 0.01687506548591955
[Epoch 22, Batch 3000] loss: 0.013199646129596659
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9852
Overfitting: 0.0502
[Epoch 23, Batch 100] loss: 0.012874210475692961
[Epoch 23, Batch 200] loss: 0.018816521896205814
[Epoch 23, Batch 300] loss: 0.010816424277663828
[Epoch 23, Batch 400] loss: 0.019214398722524492
[Epoch 23, Batch 500] loss: 0.02222633205274178
[Epoch 23, Batch 600] loss: 0.01380175034129934
[Epoch 23, Batch 700] loss: 0.012977094626403413
[Epoch 23, Batch 800] loss: 0.014789885835562018
[Epoch 23, Batch 900] loss: 0.010778698101094051
[Epoch 23, Batch 1000] loss: 0.011682208738056943
[Epoch 23, Batch 1100] loss: 0.01941479155331763
[Epoch 23, Batch 1200] loss: 0.019997385634228523
[Epoch 23, Batch 1300] loss: 0.022023953975603944
[Epoch 23, Batch 1400] loss: 0.02153201531917148
[Epoch 23, Batch 1500] loss: 0.020631311501383608
[Epoch 23, Batch 1600] loss: 0.018570279671512254
[Epoch 23, Batch 1700] loss: 0.016062925065198214
[Epoch 23, Batch 1800] loss: 0.028489278717861454
[Epoch 23, Batch 1900] loss: 0.012503299899217382
[Epoch 23, Batch 2000] loss: 0.016196198794859812
[Epoch 23, Batch 2100] loss: 0.011355881162071455
[Epoch 23, Batch 2200] loss: 0.014252534963029575
[Epoch 23, Batch 2300] loss: 0.009346721144502225
[Epoch 23, Batch 2400] loss: 0.020381623599023443
[Epoch 23, Batch 2500] loss: 0.020840321932919324
[Epoch 23, Batch 2600] loss: 0.02110904419692815
[Epoch 23, Batch 2700] loss: 0.02273648512422369
[Epoch 23, Batch 2800] loss: 0.02882668952735912
[Epoch 23, Batch 2900] loss: 0.014160159358289093
[Epoch 23, Batch 3000] loss: 0.023796726691070944
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0461
Validation Accuracy: 0.9858
Overfitting: 0.0461
[Epoch 24, Batch 100] loss: 0.016827035533169693
[Epoch 24, Batch 200] loss: 0.013420900056553364
[Epoch 24, Batch 300] loss: 0.016349365985952317
[Epoch 24, Batch 400] loss: 0.013254332725591667
[Epoch 24, Batch 500] loss: 0.018981822764599202
[Epoch 24, Batch 600] loss: 0.01188419573740248
[Epoch 24, Batch 700] loss: 0.025589808494187308
[Epoch 24, Batch 800] loss: 0.01259434138863071
[Epoch 24, Batch 900] loss: 0.0189739124280095
[Epoch 24, Batch 1000] loss: 0.02370206371324457
[Epoch 24, Batch 1100] loss: 0.01595742698792492
[Epoch 24, Batch 1200] loss: 0.02070250487588055
[Epoch 24, Batch 1300] loss: 0.013950376453012723
[Epoch 24, Batch 1400] loss: 0.018586707211652537
[Epoch 24, Batch 1500] loss: 0.018887811844870157
[Epoch 24, Batch 1600] loss: 0.01699180026691465
[Epoch 24, Batch 1700] loss: 0.01224221787051647
[Epoch 24, Batch 1800] loss: 0.02065315120595187
[Epoch 24, Batch 1900] loss: 0.01317084646465446
[Epoch 24, Batch 2000] loss: 0.013888861482409993
[Epoch 24, Batch 2100] loss: 0.017031755922425874
[Epoch 24, Batch 2200] loss: 0.015126050978833518
[Epoch 24, Batch 2300] loss: 0.019837299518658254
[Epoch 24, Batch 2400] loss: 0.020358016397294704
[Epoch 24, Batch 2500] loss: 0.014964089295353915
[Epoch 24, Batch 2600] loss: 0.017439505930033194
[Epoch 24, Batch 2700] loss: 0.015733049743121227
[Epoch 24, Batch 2800] loss: 0.022499666208095733
[Epoch 24, Batch 2900] loss: 0.019230379883756542
[Epoch 24, Batch 3000] loss: 0.014244263283144392
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9848
Overfitting: 0.0486
Fold 3 validation loss: 0.0486
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.301610462665558
[Epoch 1, Batch 200] loss: 2.293203821182251
[Epoch 1, Batch 300] loss: 2.2784467124938965
[Epoch 1, Batch 400] loss: 2.26225182056427
[Epoch 1, Batch 500] loss: 2.235485758781433
[Epoch 1, Batch 600] loss: 2.184751620292664
[Epoch 1, Batch 700] loss: 2.0920782780647276
[Epoch 1, Batch 800] loss: 1.863141577243805
[Epoch 1, Batch 900] loss: 1.48660600066185
[Epoch 1, Batch 1000] loss: 1.0258270710706712
[Epoch 1, Batch 1100] loss: 0.7372745770215988
[Epoch 1, Batch 1200] loss: 0.5834686434268952
[Epoch 1, Batch 1300] loss: 0.5043733569979668
[Epoch 1, Batch 1400] loss: 0.4729642604291439
[Epoch 1, Batch 1500] loss: 0.45562658555805685
[Epoch 1, Batch 1600] loss: 0.3927926682680845
[Epoch 1, Batch 1700] loss: 0.37478393249213693
[Epoch 1, Batch 1800] loss: 0.38697007700800895
[Epoch 1, Batch 1900] loss: 0.32615566831082105
[Epoch 1, Batch 2000] loss: 0.317380682900548
[Epoch 1, Batch 2100] loss: 0.32060283593833444
[Epoch 1, Batch 2200] loss: 0.32046090262010696
[Epoch 1, Batch 2300] loss: 0.25330178797245023
[Epoch 1, Batch 2400] loss: 0.27971612876281143
[Epoch 1, Batch 2500] loss: 0.2640825017169118
[Epoch 1, Batch 2600] loss: 0.26640062741935255
[Epoch 1, Batch 2700] loss: 0.2603201520629227
[Epoch 1, Batch 2800] loss: 0.2580279386602342
[Epoch 1, Batch 2900] loss: 0.25808943098410964
[Epoch 1, Batch 3000] loss: 0.24842823112383486
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2186
Validation Accuracy: 0.9356
Overfitting: 0.2186
Best model saved at epoch 1 with validation loss: 0.2186
[Epoch 2, Batch 100] loss: 0.22788663232699036
[Epoch 2, Batch 200] loss: 0.20017920464277267
[Epoch 2, Batch 300] loss: 0.19864179797470569
[Epoch 2, Batch 400] loss: 0.2065707154944539
[Epoch 2, Batch 500] loss: 0.19379116009920835
[Epoch 2, Batch 600] loss: 0.1966682254523039
[Epoch 2, Batch 700] loss: 0.2299277545977384
[Epoch 2, Batch 800] loss: 0.17147179236635565
[Epoch 2, Batch 900] loss: 0.19681954646483063
[Epoch 2, Batch 1000] loss: 0.18884390619583427
[Epoch 2, Batch 1100] loss: 0.15978324475698172
[Epoch 2, Batch 1200] loss: 0.16165651207789777
[Epoch 2, Batch 1300] loss: 0.13381931490730495
[Epoch 2, Batch 1400] loss: 0.18224993256852032
[Epoch 2, Batch 1500] loss: 0.17948342660441996
[Epoch 2, Batch 1600] loss: 0.17116277418099343
[Epoch 2, Batch 1700] loss: 0.15698027996346353
[Epoch 2, Batch 1800] loss: 0.166931740231812
[Epoch 2, Batch 1900] loss: 0.176837438037619
[Epoch 2, Batch 2000] loss: 0.16955955853685736
[Epoch 2, Batch 2100] loss: 0.16469936058856546
[Epoch 2, Batch 2200] loss: 0.15456393585540354
[Epoch 2, Batch 2300] loss: 0.1700898036826402
[Epoch 2, Batch 2400] loss: 0.12079625992570073
[Epoch 2, Batch 2500] loss: 0.1408075461210683
[Epoch 2, Batch 2600] loss: 0.15303514924831688
[Epoch 2, Batch 2700] loss: 0.14425997571554036
[Epoch 2, Batch 2800] loss: 0.10947103693149984
[Epoch 2, Batch 2900] loss: 0.12427999866660684
[Epoch 2, Batch 3000] loss: 0.11058003518963233
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1410
Validation Accuracy: 0.9537
Overfitting: 0.1410
Best model saved at epoch 2 with validation loss: 0.1410
[Epoch 3, Batch 100] loss: 0.14164887880906463
[Epoch 3, Batch 200] loss: 0.13160640514921396
[Epoch 3, Batch 300] loss: 0.10874009645078331
[Epoch 3, Batch 400] loss: 0.14018755289260298
[Epoch 3, Batch 500] loss: 0.12211190544068813
[Epoch 3, Batch 600] loss: 0.1404974478064105
[Epoch 3, Batch 700] loss: 0.15370348379015922
[Epoch 3, Batch 800] loss: 0.10991371838375925
[Epoch 3, Batch 900] loss: 0.11858359599951655
[Epoch 3, Batch 1000] loss: 0.11811129382345825
[Epoch 3, Batch 1100] loss: 0.10274819511454553
[Epoch 3, Batch 1200] loss: 0.1011556790128816
[Epoch 3, Batch 1300] loss: 0.1230164832866285
[Epoch 3, Batch 1400] loss: 0.11821533790323883
[Epoch 3, Batch 1500] loss: 0.1099499258166179
[Epoch 3, Batch 1600] loss: 0.11330144570674747
[Epoch 3, Batch 1700] loss: 0.10258662024280056
[Epoch 3, Batch 1800] loss: 0.10214830991695635
[Epoch 3, Batch 1900] loss: 0.11684703514911235
[Epoch 3, Batch 2000] loss: 0.10833323072176426
[Epoch 3, Batch 2100] loss: 0.1004080220637843
[Epoch 3, Batch 2200] loss: 0.12402064066845923
[Epoch 3, Batch 2300] loss: 0.1034151311730966
[Epoch 3, Batch 2400] loss: 0.08299070345703513
[Epoch 3, Batch 2500] loss: 0.12338840577751398
[Epoch 3, Batch 2600] loss: 0.09847748998552561
[Epoch 3, Batch 2700] loss: 0.085844098450616
[Epoch 3, Batch 2800] loss: 0.10496203766902909
[Epoch 3, Batch 2900] loss: 0.077175170306582
[Epoch 3, Batch 3000] loss: 0.11357384393457323
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0927
Validation Accuracy: 0.9709
Overfitting: 0.0927
Best model saved at epoch 3 with validation loss: 0.0927
[Epoch 4, Batch 100] loss: 0.0940349292731844
[Epoch 4, Batch 200] loss: 0.07945681980112568
[Epoch 4, Batch 300] loss: 0.10958117688307539
[Epoch 4, Batch 400] loss: 0.09763576353667304
[Epoch 4, Batch 500] loss: 0.07622915412299335
[Epoch 4, Batch 600] loss: 0.08029601655201986
[Epoch 4, Batch 700] loss: 0.10271093708928675
[Epoch 4, Batch 800] loss: 0.10362715738941915
[Epoch 4, Batch 900] loss: 0.10704016169765965
[Epoch 4, Batch 1000] loss: 0.07831661551026628
[Epoch 4, Batch 1100] loss: 0.08405308542307466
[Epoch 4, Batch 1200] loss: 0.11458750993711873
[Epoch 4, Batch 1300] loss: 0.07669559586211108
[Epoch 4, Batch 1400] loss: 0.1241308870865032
[Epoch 4, Batch 1500] loss: 0.11394750812556595
[Epoch 4, Batch 1600] loss: 0.09563598268665373
[Epoch 4, Batch 1700] loss: 0.07961889825528487
[Epoch 4, Batch 1800] loss: 0.06779096866725012
[Epoch 4, Batch 1900] loss: 0.08197274231584743
[Epoch 4, Batch 2000] loss: 0.10103773250710218
[Epoch 4, Batch 2100] loss: 0.07601384336245247
[Epoch 4, Batch 2200] loss: 0.10324284806731157
[Epoch 4, Batch 2300] loss: 0.07852090548025444
[Epoch 4, Batch 2400] loss: 0.07150249515194446
[Epoch 4, Batch 2500] loss: 0.06609210327034816
[Epoch 4, Batch 2600] loss: 0.07144116017501802
[Epoch 4, Batch 2700] loss: 0.08545013775816188
[Epoch 4, Batch 2800] loss: 0.10587121446151286
[Epoch 4, Batch 2900] loss: 0.07768675980390981
[Epoch 4, Batch 3000] loss: 0.08789866540697404
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0760
Validation Accuracy: 0.9754
Overfitting: 0.0760
Best model saved at epoch 4 with validation loss: 0.0760
[Epoch 5, Batch 100] loss: 0.08603258014540188
[Epoch 5, Batch 200] loss: 0.05724784579477273
[Epoch 5, Batch 300] loss: 0.08202145308372565
[Epoch 5, Batch 400] loss: 0.08463028225232846
[Epoch 5, Batch 500] loss: 0.0896067027375102
[Epoch 5, Batch 600] loss: 0.09038393507013097
[Epoch 5, Batch 700] loss: 0.0744985177158378
[Epoch 5, Batch 800] loss: 0.08549684243043884
[Epoch 5, Batch 900] loss: 0.0744371328316629
[Epoch 5, Batch 1000] loss: 0.08698579812189564
[Epoch 5, Batch 1100] loss: 0.07011329690692947
[Epoch 5, Batch 1200] loss: 0.08863802883541211
[Epoch 5, Batch 1300] loss: 0.0710955183475744
[Epoch 5, Batch 1400] loss: 0.07791862009442412
[Epoch 5, Batch 1500] loss: 0.07724220536649228
[Epoch 5, Batch 1600] loss: 0.05869774651015178
[Epoch 5, Batch 1700] loss: 0.08694548630272038
[Epoch 5, Batch 1800] loss: 0.08451543142320589
[Epoch 5, Batch 1900] loss: 0.06999060178175569
[Epoch 5, Batch 2000] loss: 0.060766720761894245
[Epoch 5, Batch 2100] loss: 0.08988073422107845
[Epoch 5, Batch 2200] loss: 0.09307840622146614
[Epoch 5, Batch 2300] loss: 0.08140704663004726
[Epoch 5, Batch 2400] loss: 0.053396903423126786
[Epoch 5, Batch 2500] loss: 0.07251451211282983
[Epoch 5, Batch 2600] loss: 0.0661481720325537
[Epoch 5, Batch 2700] loss: 0.04597503056516871
[Epoch 5, Batch 2800] loss: 0.06232490511785727
[Epoch 5, Batch 2900] loss: 0.0736151919933036
[Epoch 5, Batch 3000] loss: 0.05681318458984606
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0793
Validation Accuracy: 0.9748
Overfitting: 0.0793
[Epoch 6, Batch 100] loss: 0.06779476277413778
[Epoch 6, Batch 200] loss: 0.06997850212384947
[Epoch 6, Batch 300] loss: 0.05633127514156513
[Epoch 6, Batch 400] loss: 0.06304586893995293
[Epoch 6, Batch 500] loss: 0.08193768911529332
[Epoch 6, Batch 600] loss: 0.08796849968377501
[Epoch 6, Batch 700] loss: 0.06161956538213417
[Epoch 6, Batch 800] loss: 0.07803182475734502
[Epoch 6, Batch 900] loss: 0.08537554086826277
[Epoch 6, Batch 1000] loss: 0.07531013466534205
[Epoch 6, Batch 1100] loss: 0.07785731065785512
[Epoch 6, Batch 1200] loss: 0.05286522151902318
[Epoch 6, Batch 1300] loss: 0.05824759264185559
[Epoch 6, Batch 1400] loss: 0.06351727187284269
[Epoch 6, Batch 1500] loss: 0.07561660810082685
[Epoch 6, Batch 1600] loss: 0.04162467346759513
[Epoch 6, Batch 1700] loss: 0.061323206212837246
[Epoch 6, Batch 1800] loss: 0.06687174607417547
[Epoch 6, Batch 1900] loss: 0.060121042949613186
[Epoch 6, Batch 2000] loss: 0.07621396556613036
[Epoch 6, Batch 2100] loss: 0.05415138880140148
[Epoch 6, Batch 2200] loss: 0.060681825983920135
[Epoch 6, Batch 2300] loss: 0.05827893926296383
[Epoch 6, Batch 2400] loss: 0.06185404160292819
[Epoch 6, Batch 2500] loss: 0.05436445212573744
[Epoch 6, Batch 2600] loss: 0.05673636788909789
[Epoch 6, Batch 2700] loss: 0.08121490179561079
[Epoch 6, Batch 2800] loss: 0.05690546594792977
[Epoch 6, Batch 2900] loss: 0.057777330863755194
[Epoch 6, Batch 3000] loss: 0.06296787697530817
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0677
Validation Accuracy: 0.9792
Overfitting: 0.0677
Best model saved at epoch 6 with validation loss: 0.0677
[Epoch 7, Batch 100] loss: 0.04869586591958068
[Epoch 7, Batch 200] loss: 0.05674330099835061
[Epoch 7, Batch 300] loss: 0.05367426054086536
[Epoch 7, Batch 400] loss: 0.04430477536399849
[Epoch 7, Batch 500] loss: 0.046032121310709044
[Epoch 7, Batch 600] loss: 0.0530599901266396
[Epoch 7, Batch 700] loss: 0.0634908484609332
[Epoch 7, Batch 800] loss: 0.07517393388436176
[Epoch 7, Batch 900] loss: 0.050454734434606505
[Epoch 7, Batch 1000] loss: 0.05523072806186974
[Epoch 7, Batch 1100] loss: 0.06730615163687617
[Epoch 7, Batch 1200] loss: 0.06419303256785497
[Epoch 7, Batch 1300] loss: 0.058157002893276515
[Epoch 7, Batch 1400] loss: 0.053965979496133513
[Epoch 7, Batch 1500] loss: 0.05204911117209122
[Epoch 7, Batch 1600] loss: 0.0633798169333022
[Epoch 7, Batch 1700] loss: 0.06643589517916552
[Epoch 7, Batch 1800] loss: 0.0451463389309356
[Epoch 7, Batch 1900] loss: 0.046565519666764886
[Epoch 7, Batch 2000] loss: 0.06472014495753683
[Epoch 7, Batch 2100] loss: 0.05574116375530139
[Epoch 7, Batch 2200] loss: 0.06506461583310738
[Epoch 7, Batch 2300] loss: 0.05667135735042393
[Epoch 7, Batch 2400] loss: 0.07902056661027018
[Epoch 7, Batch 2500] loss: 0.07117401741445065
[Epoch 7, Batch 2600] loss: 0.04600838626036421
[Epoch 7, Batch 2700] loss: 0.05535357348620892
[Epoch 7, Batch 2800] loss: 0.048155250663985495
[Epoch 7, Batch 2900] loss: 0.05424484733317513
[Epoch 7, Batch 3000] loss: 0.048002049277420154
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0638
Validation Accuracy: 0.9801
Overfitting: 0.0638
Best model saved at epoch 7 with validation loss: 0.0638
[Epoch 8, Batch 100] loss: 0.054684778808732515
[Epoch 8, Batch 200] loss: 0.0628445985687722
[Epoch 8, Batch 300] loss: 0.06439849377755308
[Epoch 8, Batch 400] loss: 0.037631126389605925
[Epoch 8, Batch 500] loss: 0.03272330539533869
[Epoch 8, Batch 600] loss: 0.045468332025920974
[Epoch 8, Batch 700] loss: 0.05999880430288613
[Epoch 8, Batch 800] loss: 0.04775650278374087
[Epoch 8, Batch 900] loss: 0.07074351084767841
[Epoch 8, Batch 1000] loss: 0.0416304235503776
[Epoch 8, Batch 1100] loss: 0.04388914674113039
[Epoch 8, Batch 1200] loss: 0.03883018452266697
[Epoch 8, Batch 1300] loss: 0.059544633939221964
[Epoch 8, Batch 1400] loss: 0.05630753632169217
[Epoch 8, Batch 1500] loss: 0.051493973600736355
[Epoch 8, Batch 1600] loss: 0.05686896260245703
[Epoch 8, Batch 1700] loss: 0.06294846397067885
[Epoch 8, Batch 1800] loss: 0.028470947024179624
[Epoch 8, Batch 1900] loss: 0.07077400917623891
[Epoch 8, Batch 2000] loss: 0.03914926129684318
[Epoch 8, Batch 2100] loss: 0.04346910852880683
[Epoch 8, Batch 2200] loss: 0.062262102564709494
[Epoch 8, Batch 2300] loss: 0.04679601885669399
[Epoch 8, Batch 2400] loss: 0.04971076675981749
[Epoch 8, Batch 2500] loss: 0.06999160399587709
[Epoch 8, Batch 2600] loss: 0.05000535080383997
[Epoch 8, Batch 2700] loss: 0.046607494273921475
[Epoch 8, Batch 2800] loss: 0.0720175617991481
[Epoch 8, Batch 2900] loss: 0.04203263088682434
[Epoch 8, Batch 3000] loss: 0.05564718067762442
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9832
Overfitting: 0.0548
Best model saved at epoch 8 with validation loss: 0.0548
[Epoch 9, Batch 100] loss: 0.04309720518940594
[Epoch 9, Batch 200] loss: 0.028573809143854306
[Epoch 9, Batch 300] loss: 0.03688849020662019
[Epoch 9, Batch 400] loss: 0.039684340209350924
[Epoch 9, Batch 500] loss: 0.05180768780293874
[Epoch 9, Batch 600] loss: 0.05411560604581609
[Epoch 9, Batch 700] loss: 0.04286289373209001
[Epoch 9, Batch 800] loss: 0.04679679625231074
[Epoch 9, Batch 900] loss: 0.047756692385300996
[Epoch 9, Batch 1000] loss: 0.03800414274897776
[Epoch 9, Batch 1100] loss: 0.054050444181775674
[Epoch 9, Batch 1200] loss: 0.04726674902020022
[Epoch 9, Batch 1300] loss: 0.061606766908662396
[Epoch 9, Batch 1400] loss: 0.028186584489594678
[Epoch 9, Batch 1500] loss: 0.04472769267536933
[Epoch 9, Batch 1600] loss: 0.07403971330350032
[Epoch 9, Batch 1700] loss: 0.04782560272258706
[Epoch 9, Batch 1800] loss: 0.04050374036538415
[Epoch 9, Batch 1900] loss: 0.06129389167937916
[Epoch 9, Batch 2000] loss: 0.044509471098717765
[Epoch 9, Batch 2100] loss: 0.04795441145193763
[Epoch 9, Batch 2200] loss: 0.04682942804938648
[Epoch 9, Batch 2300] loss: 0.047596361007890664
[Epoch 9, Batch 2400] loss: 0.04927648990240414
[Epoch 9, Batch 2500] loss: 0.056155765801668166
[Epoch 9, Batch 2600] loss: 0.046383485730038955
[Epoch 9, Batch 2700] loss: 0.048074952983297406
[Epoch 9, Batch 2800] loss: 0.046633113025163764
[Epoch 9, Batch 2900] loss: 0.051629935597884466
[Epoch 9, Batch 3000] loss: 0.045690461149206385
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9803
Overfitting: 0.0619
[Epoch 10, Batch 100] loss: 0.0343098087477847
[Epoch 10, Batch 200] loss: 0.061528445325966456
[Epoch 10, Batch 300] loss: 0.038312330609624044
[Epoch 10, Batch 400] loss: 0.05600484485854395
[Epoch 10, Batch 500] loss: 0.03300554955800181
[Epoch 10, Batch 600] loss: 0.039087027992936785
[Epoch 10, Batch 700] loss: 0.05192370654054684
[Epoch 10, Batch 800] loss: 0.04541518276091665
[Epoch 10, Batch 900] loss: 0.03112872772384435
[Epoch 10, Batch 1000] loss: 0.04356831291326671
[Epoch 10, Batch 1100] loss: 0.051487703941529614
[Epoch 10, Batch 1200] loss: 0.041179746338457335
[Epoch 10, Batch 1300] loss: 0.03776795687066624
[Epoch 10, Batch 1400] loss: 0.033870825832127596
[Epoch 10, Batch 1500] loss: 0.03306345106277149
[Epoch 10, Batch 1600] loss: 0.05703904278198024
[Epoch 10, Batch 1700] loss: 0.0504936242007534
[Epoch 10, Batch 1800] loss: 0.0431071932852501
[Epoch 10, Batch 1900] loss: 0.03786825228278758
[Epoch 10, Batch 2000] loss: 0.0493595146673033
[Epoch 10, Batch 2100] loss: 0.04576346163245035
[Epoch 10, Batch 2200] loss: 0.03627160266449209
[Epoch 10, Batch 2300] loss: 0.03303784701944096
[Epoch 10, Batch 2400] loss: 0.029558359377333546
[Epoch 10, Batch 2500] loss: 0.061802165445988065
[Epoch 10, Batch 2600] loss: 0.031786302994878494
[Epoch 10, Batch 2700] loss: 0.037774463375099
[Epoch 10, Batch 2800] loss: 0.05073983890586533
[Epoch 10, Batch 2900] loss: 0.040912320105126125
[Epoch 10, Batch 3000] loss: 0.04081259512560791
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0602
Validation Accuracy: 0.9808
Overfitting: 0.0602
[Epoch 11, Batch 100] loss: 0.03056185629655374
[Epoch 11, Batch 200] loss: 0.04734966985706705
[Epoch 11, Batch 300] loss: 0.04055758017784683
[Epoch 11, Batch 400] loss: 0.04182941515900893
[Epoch 11, Batch 500] loss: 0.047880513724230696
[Epoch 11, Batch 600] loss: 0.05168355735950172
[Epoch 11, Batch 700] loss: 0.04028871278860606
[Epoch 11, Batch 800] loss: 0.04358676570118405
[Epoch 11, Batch 900] loss: 0.03667913156008581
[Epoch 11, Batch 1000] loss: 0.03445054438052466
[Epoch 11, Batch 1100] loss: 0.023719296753406525
[Epoch 11, Batch 1200] loss: 0.05715926928707631
[Epoch 11, Batch 1300] loss: 0.04102233337122016
[Epoch 11, Batch 1400] loss: 0.04121585296583362
[Epoch 11, Batch 1500] loss: 0.039047509995289144
[Epoch 11, Batch 1600] loss: 0.026086004172684626
[Epoch 11, Batch 1700] loss: 0.04153819771949202
[Epoch 11, Batch 1800] loss: 0.03523980994941667
[Epoch 11, Batch 1900] loss: 0.03826189532541321
[Epoch 11, Batch 2000] loss: 0.03661781011585845
[Epoch 11, Batch 2100] loss: 0.031600841762992785
[Epoch 11, Batch 2200] loss: 0.03242166999043548
[Epoch 11, Batch 2300] loss: 0.046796211760956795
[Epoch 11, Batch 2400] loss: 0.03796100673178444
[Epoch 11, Batch 2500] loss: 0.03545114907639799
[Epoch 11, Batch 2600] loss: 0.0369951673973992
[Epoch 11, Batch 2700] loss: 0.03585075030918233
[Epoch 11, Batch 2800] loss: 0.03703575759427622
[Epoch 11, Batch 2900] loss: 0.030361595618815046
[Epoch 11, Batch 3000] loss: 0.044869030079862565
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9822
Overfitting: 0.0542
Best model saved at epoch 11 with validation loss: 0.0542
[Epoch 12, Batch 100] loss: 0.05444887368750642
[Epoch 12, Batch 200] loss: 0.026790619025705384
[Epoch 12, Batch 300] loss: 0.033047674648696554
[Epoch 12, Batch 400] loss: 0.04014497984928312
[Epoch 12, Batch 500] loss: 0.03827401032358466
[Epoch 12, Batch 600] loss: 0.04345185579717509
[Epoch 12, Batch 700] loss: 0.038827386909979396
[Epoch 12, Batch 800] loss: 0.03393618122529005
[Epoch 12, Batch 900] loss: 0.02907505642186152
[Epoch 12, Batch 1000] loss: 0.02741539987306169
[Epoch 12, Batch 1100] loss: 0.04365637424052693
[Epoch 12, Batch 1200] loss: 0.032153416146466045
[Epoch 12, Batch 1300] loss: 0.030827806131273974
[Epoch 12, Batch 1400] loss: 0.02536390603694599
[Epoch 12, Batch 1500] loss: 0.025838600582210346
[Epoch 12, Batch 1600] loss: 0.038001449796720405
[Epoch 12, Batch 1700] loss: 0.035392773032581315
[Epoch 12, Batch 1800] loss: 0.03348270838498138
[Epoch 12, Batch 1900] loss: 0.03798907006013905
[Epoch 12, Batch 2000] loss: 0.039135570704529526
[Epoch 12, Batch 2100] loss: 0.04083648831001483
[Epoch 12, Batch 2200] loss: 0.0237286516961467
[Epoch 12, Batch 2300] loss: 0.05046417107922025
[Epoch 12, Batch 2400] loss: 0.024591963137936546
[Epoch 12, Batch 2500] loss: 0.03922296574048232
[Epoch 12, Batch 2600] loss: 0.039255746531562184
[Epoch 12, Batch 2700] loss: 0.038482353651488665
[Epoch 12, Batch 2800] loss: 0.03393516358686611
[Epoch 12, Batch 2900] loss: 0.039020435898564756
[Epoch 12, Batch 3000] loss: 0.049663706202991306
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9828
Overfitting: 0.0581
[Epoch 13, Batch 100] loss: 0.027075276436808054
[Epoch 13, Batch 200] loss: 0.031200381754752017
[Epoch 13, Batch 300] loss: 0.026101558408117852
[Epoch 13, Batch 400] loss: 0.031214688838954317
[Epoch 13, Batch 500] loss: 0.022891460924583953
[Epoch 13, Batch 600] loss: 0.026668678458372598
[Epoch 13, Batch 700] loss: 0.035207117993122664
[Epoch 13, Batch 800] loss: 0.027928932903523673
[Epoch 13, Batch 900] loss: 0.038611856226925735
[Epoch 13, Batch 1000] loss: 0.0268943946940999
[Epoch 13, Batch 1100] loss: 0.029139102331682806
[Epoch 13, Batch 1200] loss: 0.01992452578728262
[Epoch 13, Batch 1300] loss: 0.03049954065514612
[Epoch 13, Batch 1400] loss: 0.04174565957247978
[Epoch 13, Batch 1500] loss: 0.028750342043640558
[Epoch 13, Batch 1600] loss: 0.03117531686264556
[Epoch 13, Batch 1700] loss: 0.0348042579680623
[Epoch 13, Batch 1800] loss: 0.03289497243225924
[Epoch 13, Batch 1900] loss: 0.024993639672284188
[Epoch 13, Batch 2000] loss: 0.03997297511581564
[Epoch 13, Batch 2100] loss: 0.04738109834084753
[Epoch 13, Batch 2200] loss: 0.047079114057778496
[Epoch 13, Batch 2300] loss: 0.04800054496015946
[Epoch 13, Batch 2400] loss: 0.02740764029847924
[Epoch 13, Batch 2500] loss: 0.028231572739896363
[Epoch 13, Batch 2600] loss: 0.034081313517090164
[Epoch 13, Batch 2700] loss: 0.04016751120449044
[Epoch 13, Batch 2800] loss: 0.03250021831132471
[Epoch 13, Batch 2900] loss: 0.03665145756822312
[Epoch 13, Batch 3000] loss: 0.03714435429894365
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9848
Overfitting: 0.0480
Best model saved at epoch 13 with validation loss: 0.0480
[Epoch 14, Batch 100] loss: 0.02091606327230693
[Epoch 14, Batch 200] loss: 0.03230664943548618
[Epoch 14, Batch 300] loss: 0.037793069889594334
[Epoch 14, Batch 400] loss: 0.0178276185838331
[Epoch 14, Batch 500] loss: 0.023886869577036122
[Epoch 14, Batch 600] loss: 0.04240128580990131
[Epoch 14, Batch 700] loss: 0.03619467276497744
[Epoch 14, Batch 800] loss: 0.03753441953973379
[Epoch 14, Batch 900] loss: 0.03529505057755159
[Epoch 14, Batch 1000] loss: 0.046082647650328
[Epoch 14, Batch 1100] loss: 0.021586591850063997
[Epoch 14, Batch 1200] loss: 0.02467662717041094
[Epoch 14, Batch 1300] loss: 0.029770717058599985
[Epoch 14, Batch 1400] loss: 0.019049846141133458
[Epoch 14, Batch 1500] loss: 0.04013853072363418
[Epoch 14, Batch 1600] loss: 0.032793606196937615
[Epoch 14, Batch 1700] loss: 0.030209886896118407
[Epoch 14, Batch 1800] loss: 0.03556497724464862
[Epoch 14, Batch 1900] loss: 0.030037117806714378
[Epoch 14, Batch 2000] loss: 0.02395615634508431
[Epoch 14, Batch 2100] loss: 0.013626891006460938
[Epoch 14, Batch 2200] loss: 0.03019026506008231
[Epoch 14, Batch 2300] loss: 0.02342387419208535
[Epoch 14, Batch 2400] loss: 0.04039399204062647
[Epoch 14, Batch 2500] loss: 0.031228571833344175
[Epoch 14, Batch 2600] loss: 0.029411458906542974
[Epoch 14, Batch 2700] loss: 0.039422992557374525
[Epoch 14, Batch 2800] loss: 0.02408049307196052
[Epoch 14, Batch 2900] loss: 0.031165600017557152
[Epoch 14, Batch 3000] loss: 0.037027268227539024
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9848
Overfitting: 0.0484
[Epoch 15, Batch 100] loss: 0.028346973912266548
[Epoch 15, Batch 200] loss: 0.025324025605223142
[Epoch 15, Batch 300] loss: 0.03508778954826994
[Epoch 15, Batch 400] loss: 0.01832200534758158
[Epoch 15, Batch 500] loss: 0.032469574817514515
[Epoch 15, Batch 600] loss: 0.036630516046861884
[Epoch 15, Batch 700] loss: 0.03653556118006236
[Epoch 15, Batch 800] loss: 0.02102348532775068
[Epoch 15, Batch 900] loss: 0.03349028345401166
[Epoch 15, Batch 1000] loss: 0.022490724193048664
[Epoch 15, Batch 1100] loss: 0.023317251727858094
[Epoch 15, Batch 1200] loss: 0.020626525158877484
[Epoch 15, Batch 1300] loss: 0.030296824937249767
[Epoch 15, Batch 1400] loss: 0.021990744260838257
[Epoch 15, Batch 1500] loss: 0.024352335694420617
[Epoch 15, Batch 1600] loss: 0.029830529065075096
[Epoch 15, Batch 1700] loss: 0.02116197834846389
[Epoch 15, Batch 1800] loss: 0.02170874782357714
[Epoch 15, Batch 1900] loss: 0.015868394846474985
[Epoch 15, Batch 2000] loss: 0.035852999448616175
[Epoch 15, Batch 2100] loss: 0.02471268188644899
[Epoch 15, Batch 2200] loss: 0.022247982602129922
[Epoch 15, Batch 2300] loss: 0.024126658397653954
[Epoch 15, Batch 2400] loss: 0.02968762450538634
[Epoch 15, Batch 2500] loss: 0.037608158287839616
[Epoch 15, Batch 2600] loss: 0.03051863357919501
[Epoch 15, Batch 2700] loss: 0.03580077469348907
[Epoch 15, Batch 2800] loss: 0.04569683128065662
[Epoch 15, Batch 2900] loss: 0.026513305404077984
[Epoch 15, Batch 3000] loss: 0.027402071733231424
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9858
Overfitting: 0.0446
Best model saved at epoch 15 with validation loss: 0.0446
[Epoch 16, Batch 100] loss: 0.014930909766044352
[Epoch 16, Batch 200] loss: 0.035127248381322716
[Epoch 16, Batch 300] loss: 0.021710505498194834
[Epoch 16, Batch 400] loss: 0.022857405498361915
[Epoch 16, Batch 500] loss: 0.028200879125506617
[Epoch 16, Batch 600] loss: 0.026313440057892875
[Epoch 16, Batch 700] loss: 0.024905677328715684
[Epoch 16, Batch 800] loss: 0.028367592117283492
[Epoch 16, Batch 900] loss: 0.03170311282185139
[Epoch 16, Batch 1000] loss: 0.01721197843518894
[Epoch 16, Batch 1100] loss: 0.023774199008039433
[Epoch 16, Batch 1200] loss: 0.020583853220086892
[Epoch 16, Batch 1300] loss: 0.03404922423389507
[Epoch 16, Batch 1400] loss: 0.0193324312270488
[Epoch 16, Batch 1500] loss: 0.023658737870282495
[Epoch 16, Batch 1600] loss: 0.021274796800134936
[Epoch 16, Batch 1700] loss: 0.02627452301574522
[Epoch 16, Batch 1800] loss: 0.02278265280794585
[Epoch 16, Batch 1900] loss: 0.036552287187078036
[Epoch 16, Batch 2000] loss: 0.02905784290502197
[Epoch 16, Batch 2100] loss: 0.030128423428541284
[Epoch 16, Batch 2200] loss: 0.02095519200665876
[Epoch 16, Batch 2300] loss: 0.02900572807433491
[Epoch 16, Batch 2400] loss: 0.018181316638365388
[Epoch 16, Batch 2500] loss: 0.03171569771977374
[Epoch 16, Batch 2600] loss: 0.03222380207284004
[Epoch 16, Batch 2700] loss: 0.025336534815578488
[Epoch 16, Batch 2800] loss: 0.026232159226055957
[Epoch 16, Batch 2900] loss: 0.03307460327021545
[Epoch 16, Batch 3000] loss: 0.019708544394525233
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9852
Overfitting: 0.0478
[Epoch 17, Batch 100] loss: 0.021802208649969543
[Epoch 17, Batch 200] loss: 0.01242279573882115
[Epoch 17, Batch 300] loss: 0.018059983954663038
[Epoch 17, Batch 400] loss: 0.023339486418080924
[Epoch 17, Batch 500] loss: 0.01990952717344044
[Epoch 17, Batch 600] loss: 0.0300011625411571
[Epoch 17, Batch 700] loss: 0.019933337599868536
[Epoch 17, Batch 800] loss: 0.02251512000533694
[Epoch 17, Batch 900] loss: 0.022838780128440702
[Epoch 17, Batch 1000] loss: 0.024323862924138667
[Epoch 17, Batch 1100] loss: 0.01780502627054375
[Epoch 17, Batch 1200] loss: 0.02149789739305561
[Epoch 17, Batch 1300] loss: 0.030645632933301387
[Epoch 17, Batch 1400] loss: 0.025127582475470263
[Epoch 17, Batch 1500] loss: 0.02826376908289603
[Epoch 17, Batch 1600] loss: 0.021184374168806242
[Epoch 17, Batch 1700] loss: 0.03217405519895692
[Epoch 17, Batch 1800] loss: 0.021728775040101025
[Epoch 17, Batch 1900] loss: 0.018189668628838262
[Epoch 17, Batch 2000] loss: 0.026778118638612795
[Epoch 17, Batch 2100] loss: 0.034788551863166504
[Epoch 17, Batch 2200] loss: 0.02163075726602983
[Epoch 17, Batch 2300] loss: 0.024585816583930865
[Epoch 17, Batch 2400] loss: 0.030758283844297695
[Epoch 17, Batch 2500] loss: 0.022958958413582878
[Epoch 17, Batch 2600] loss: 0.016677981557004385
[Epoch 17, Batch 2700] loss: 0.027221925554113114
[Epoch 17, Batch 2800] loss: 0.030750105883707874
[Epoch 17, Batch 2900] loss: 0.02300881590221252
[Epoch 17, Batch 3000] loss: 0.0214283540208271
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9862
Overfitting: 0.0430
Best model saved at epoch 17 with validation loss: 0.0430
[Epoch 18, Batch 100] loss: 0.01776219481464068
[Epoch 18, Batch 200] loss: 0.033027034134429416
[Epoch 18, Batch 300] loss: 0.019612457066396017
[Epoch 18, Batch 400] loss: 0.015929662048147292
[Epoch 18, Batch 500] loss: 0.023590548581123586
[Epoch 18, Batch 600] loss: 0.026840370591671672
[Epoch 18, Batch 700] loss: 0.014931731631768343
[Epoch 18, Batch 800] loss: 0.02761261784373346
[Epoch 18, Batch 900] loss: 0.023962435506145994
[Epoch 18, Batch 1000] loss: 0.018987116751377472
[Epoch 18, Batch 1100] loss: 0.03951406604293879
[Epoch 18, Batch 1200] loss: 0.0149288518062167
[Epoch 18, Batch 1300] loss: 0.02378780768987781
[Epoch 18, Batch 1400] loss: 0.01622792159600067
[Epoch 18, Batch 1500] loss: 0.019946086909258157
[Epoch 18, Batch 1600] loss: 0.026694433874436072
[Epoch 18, Batch 1700] loss: 0.028063859551766653
[Epoch 18, Batch 1800] loss: 0.016241273221894517
[Epoch 18, Batch 1900] loss: 0.029591298153391107
[Epoch 18, Batch 2000] loss: 0.012264819037482085
[Epoch 18, Batch 2100] loss: 0.025742158572465996
[Epoch 18, Batch 2200] loss: 0.021941621886635402
[Epoch 18, Batch 2300] loss: 0.025833069332584273
[Epoch 18, Batch 2400] loss: 0.026397046182100894
[Epoch 18, Batch 2500] loss: 0.0166243176142234
[Epoch 18, Batch 2600] loss: 0.018742040806318982
[Epoch 18, Batch 2700] loss: 0.015377017047831032
[Epoch 18, Batch 2800] loss: 0.027636407989775763
[Epoch 18, Batch 2900] loss: 0.04038137565519719
[Epoch 18, Batch 3000] loss: 0.017793535571108805
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9857
Overfitting: 0.0449
[Epoch 19, Batch 100] loss: 0.010243755352785228
[Epoch 19, Batch 200] loss: 0.018386513853110954
[Epoch 19, Batch 300] loss: 0.014986784917164186
[Epoch 19, Batch 400] loss: 0.030816192620040966
[Epoch 19, Batch 500] loss: 0.04596886239812193
[Epoch 19, Batch 600] loss: 0.014653209891366713
[Epoch 19, Batch 700] loss: 0.017340412387420658
[Epoch 19, Batch 800] loss: 0.01540873418758565
[Epoch 19, Batch 900] loss: 0.008820936565170997
[Epoch 19, Batch 1000] loss: 0.01979911808797624
[Epoch 19, Batch 1100] loss: 0.02318978183553554
[Epoch 19, Batch 1200] loss: 0.02407039704878116
[Epoch 19, Batch 1300] loss: 0.025451345478068106
[Epoch 19, Batch 1400] loss: 0.019927931855709177
[Epoch 19, Batch 1500] loss: 0.017616066554619465
[Epoch 19, Batch 1600] loss: 0.022451194732529985
[Epoch 19, Batch 1700] loss: 0.021085664706406534
[Epoch 19, Batch 1800] loss: 0.022341453583721887
[Epoch 19, Batch 1900] loss: 0.012833582233251945
[Epoch 19, Batch 2000] loss: 0.02197302906341065
[Epoch 19, Batch 2100] loss: 0.019316298779194767
[Epoch 19, Batch 2200] loss: 0.03919424139212424
[Epoch 19, Batch 2300] loss: 0.019173895258500124
[Epoch 19, Batch 2400] loss: 0.024802117814851955
[Epoch 19, Batch 2500] loss: 0.016518694729129493
[Epoch 19, Batch 2600] loss: 0.018109654843137833
[Epoch 19, Batch 2700] loss: 0.016093342365657008
[Epoch 19, Batch 2800] loss: 0.024018934422929305
[Epoch 19, Batch 2900] loss: 0.02534175084758317
[Epoch 19, Batch 3000] loss: 0.019119285102351568
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9851
Overfitting: 0.0455
[Epoch 20, Batch 100] loss: 0.017014496298215817
[Epoch 20, Batch 200] loss: 0.02046189181470254
[Epoch 20, Batch 300] loss: 0.017750619670769085
[Epoch 20, Batch 400] loss: 0.019556023588484094
[Epoch 20, Batch 500] loss: 0.01908864540188006
[Epoch 20, Batch 600] loss: 0.019749327111567253
[Epoch 20, Batch 700] loss: 0.018558929863247614
[Epoch 20, Batch 800] loss: 0.021145623901356884
[Epoch 20, Batch 900] loss: 0.019189147381475778
[Epoch 20, Batch 1000] loss: 0.015424671072760248
[Epoch 20, Batch 1100] loss: 0.027813363923523866
[Epoch 20, Batch 1200] loss: 0.017464477611138136
[Epoch 20, Batch 1300] loss: 0.018806558853357275
[Epoch 20, Batch 1400] loss: 0.02223465164243862
[Epoch 20, Batch 1500] loss: 0.015017341725106235
[Epoch 20, Batch 1600] loss: 0.022296880740323103
[Epoch 20, Batch 1700] loss: 0.016992738417211512
[Epoch 20, Batch 1800] loss: 0.021317678351479116
[Epoch 20, Batch 1900] loss: 0.02206907971867622
[Epoch 20, Batch 2000] loss: 0.021166602062985474
[Epoch 20, Batch 2100] loss: 0.022310750384785933
[Epoch 20, Batch 2200] loss: 0.02557066751531238
[Epoch 20, Batch 2300] loss: 0.021290336530400963
[Epoch 20, Batch 2400] loss: 0.030669997549266553
[Epoch 20, Batch 2500] loss: 0.02392349284644297
[Epoch 20, Batch 2600] loss: 0.011274762662214926
[Epoch 20, Batch 2700] loss: 0.011194966675202523
[Epoch 20, Batch 2800] loss: 0.020359310456187815
[Epoch 20, Batch 2900] loss: 0.02407781269073894
[Epoch 20, Batch 3000] loss: 0.014445529637632716
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9869
Overfitting: 0.0430
Best model saved at epoch 20 with validation loss: 0.0430
[Epoch 21, Batch 100] loss: 0.0184028138222493
[Epoch 21, Batch 200] loss: 0.009906831176413106
[Epoch 21, Batch 300] loss: 0.033877376782111245
[Epoch 21, Batch 400] loss: 0.015521577873951174
[Epoch 21, Batch 500] loss: 0.0183540190576241
[Epoch 21, Batch 600] loss: 0.013302955398212362
[Epoch 21, Batch 700] loss: 0.010877974255527079
[Epoch 21, Batch 800] loss: 0.009146789591395645
[Epoch 21, Batch 900] loss: 0.018104178783141835
[Epoch 21, Batch 1000] loss: 0.016666951993393013
[Epoch 21, Batch 1100] loss: 0.018375895182980457
[Epoch 21, Batch 1200] loss: 0.017776491938602704
[Epoch 21, Batch 1300] loss: 0.017409693202134802
[Epoch 21, Batch 1400] loss: 0.021671330481476615
[Epoch 21, Batch 1500] loss: 0.02051312181069079
[Epoch 21, Batch 1600] loss: 0.019056417843203236
[Epoch 21, Batch 1700] loss: 0.02007162774894823
[Epoch 21, Batch 1800] loss: 0.019796505215999786
[Epoch 21, Batch 1900] loss: 0.007097911778555499
[Epoch 21, Batch 2000] loss: 0.015556249240180477
[Epoch 21, Batch 2100] loss: 0.015925203236365634
[Epoch 21, Batch 2200] loss: 0.026441855870889413
[Epoch 21, Batch 2300] loss: 0.026480023218900896
[Epoch 21, Batch 2400] loss: 0.02199700079025206
[Epoch 21, Batch 2500] loss: 0.015709348796081032
[Epoch 21, Batch 2600] loss: 0.02497375005230424
[Epoch 21, Batch 2700] loss: 0.018481457134130325
[Epoch 21, Batch 2800] loss: 0.014003738206811249
[Epoch 21, Batch 2900] loss: 0.017714152870685212
[Epoch 21, Batch 3000] loss: 0.021196861254320538
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0433
Validation Accuracy: 0.9859
Overfitting: 0.0433
[Epoch 22, Batch 100] loss: 0.014171153355928254
[Epoch 22, Batch 200] loss: 0.01731893086885975
[Epoch 22, Batch 300] loss: 0.02081549253027333
[Epoch 22, Batch 400] loss: 0.011338050414669851
[Epoch 22, Batch 500] loss: 0.010327330858781352
[Epoch 22, Batch 600] loss: 0.026731329397389345
[Epoch 22, Batch 700] loss: 0.009922413277636224
[Epoch 22, Batch 800] loss: 0.016436260700465936
[Epoch 22, Batch 900] loss: 0.01762965114949111
[Epoch 22, Batch 1000] loss: 0.012964725319980061
[Epoch 22, Batch 1100] loss: 0.011998152996166028
[Epoch 22, Batch 1200] loss: 0.018735206490055133
[Epoch 22, Batch 1300] loss: 0.017057095665950327
[Epoch 22, Batch 1400] loss: 0.019389658291802333
[Epoch 22, Batch 1500] loss: 0.012982173549935395
[Epoch 22, Batch 1600] loss: 0.010528848636240581
[Epoch 22, Batch 1700] loss: 0.011054352399150957
[Epoch 22, Batch 1800] loss: 0.020056501337494412
[Epoch 22, Batch 1900] loss: 0.010509130462342
[Epoch 22, Batch 2000] loss: 0.02037457472717506
[Epoch 22, Batch 2100] loss: 0.016903918648604303
[Epoch 22, Batch 2200] loss: 0.014984102570288087
[Epoch 22, Batch 2300] loss: 0.02064585557933242
[Epoch 22, Batch 2400] loss: 0.014259601767962522
[Epoch 22, Batch 2500] loss: 0.018355543536490587
[Epoch 22, Batch 2600] loss: 0.0206641469636088
[Epoch 22, Batch 2700] loss: 0.014949572917612387
[Epoch 22, Batch 2800] loss: 0.02181876401165937
[Epoch 22, Batch 2900] loss: 0.01587620719525148
[Epoch 22, Batch 3000] loss: 0.021930547306001243
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0461
Validation Accuracy: 0.9868
Overfitting: 0.0461
[Epoch 23, Batch 100] loss: 0.02175519145665021
[Epoch 23, Batch 200] loss: 0.016228504414139023
[Epoch 23, Batch 300] loss: 0.016888946732287878
[Epoch 23, Batch 400] loss: 0.012432538599241524
[Epoch 23, Batch 500] loss: 0.022257269906695
[Epoch 23, Batch 600] loss: 0.012373933337730705
[Epoch 23, Batch 700] loss: 0.01322954176539497
[Epoch 23, Batch 800] loss: 0.011959012097977393
[Epoch 23, Batch 900] loss: 0.010598891518056916
[Epoch 23, Batch 1000] loss: 0.011984615575420321
[Epoch 23, Batch 1100] loss: 0.011198069903766737
[Epoch 23, Batch 1200] loss: 0.017182657214234495
[Epoch 23, Batch 1300] loss: 0.012944434152204849
[Epoch 23, Batch 1400] loss: 0.026741616812523718
[Epoch 23, Batch 1500] loss: 0.016324929571965185
[Epoch 23, Batch 1600] loss: 0.011669623212437728
[Epoch 23, Batch 1700] loss: 0.010413003176963684
[Epoch 23, Batch 1800] loss: 0.01067897509678005
[Epoch 23, Batch 1900] loss: 0.012094215099932627
[Epoch 23, Batch 2000] loss: 0.008261650190379442
[Epoch 23, Batch 2100] loss: 0.015405324263374496
[Epoch 23, Batch 2200] loss: 0.01732593407387185
[Epoch 23, Batch 2300] loss: 0.017785283969310513
[Epoch 23, Batch 2400] loss: 0.02339228363813163
[Epoch 23, Batch 2500] loss: 0.014467146893439349
[Epoch 23, Batch 2600] loss: 0.01364196076468943
[Epoch 23, Batch 2700] loss: 0.013932881371292751
[Epoch 23, Batch 2800] loss: 0.018260197000054178
[Epoch 23, Batch 2900] loss: 0.021205525058576313
[Epoch 23, Batch 3000] loss: 0.01471972680291401
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9868
Overfitting: 0.0422
Best model saved at epoch 23 with validation loss: 0.0422
[Epoch 24, Batch 100] loss: 0.010525275550644437
[Epoch 24, Batch 200] loss: 0.014865342585399049
[Epoch 24, Batch 300] loss: 0.018404268887352374
[Epoch 24, Batch 400] loss: 0.02179478225982166
[Epoch 24, Batch 500] loss: 0.013095232857049268
[Epoch 24, Batch 600] loss: 0.013472091666171764
[Epoch 24, Batch 700] loss: 0.019826778793594714
[Epoch 24, Batch 800] loss: 0.01123775286398086
[Epoch 24, Batch 900] loss: 0.010775988537243392
[Epoch 24, Batch 1000] loss: 0.006354741253330758
[Epoch 24, Batch 1100] loss: 0.014560403985815356
[Epoch 24, Batch 1200] loss: 0.016793628701570924
[Epoch 24, Batch 1300] loss: 0.014145919902111927
[Epoch 24, Batch 1400] loss: 0.008581186431329116
[Epoch 24, Batch 1500] loss: 0.02133913018912608
[Epoch 24, Batch 1600] loss: 0.01761801846725575
[Epoch 24, Batch 1700] loss: 0.015465123636076897
[Epoch 24, Batch 1800] loss: 0.018826302856759868
[Epoch 24, Batch 1900] loss: 0.010532044068204413
[Epoch 24, Batch 2000] loss: 0.014133874837134498
[Epoch 24, Batch 2100] loss: 0.015170926620394312
[Epoch 24, Batch 2200] loss: 0.01078639159028171
[Epoch 24, Batch 2300] loss: 0.033410957002270154
[Epoch 24, Batch 2400] loss: 0.013051687056286027
[Epoch 24, Batch 2500] loss: 0.015695836085578774
[Epoch 24, Batch 2600] loss: 0.022902827156367492
[Epoch 24, Batch 2700] loss: 0.006262316914699113
[Epoch 24, Batch 2800] loss: 0.009586202401333139
[Epoch 24, Batch 2900] loss: 0.02196063701365347
[Epoch 24, Batch 3000] loss: 0.016796752340014792
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0442
Validation Accuracy: 0.9867
Overfitting: 0.0442
Fold 4 validation loss: 0.0442
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.3048496770858766
[Epoch 1, Batch 200] loss: 2.283026340007782
[Epoch 1, Batch 300] loss: 2.267062919139862
[Epoch 1, Batch 400] loss: 2.2400960993766783
[Epoch 1, Batch 500] loss: 2.186182999610901
[Epoch 1, Batch 600] loss: 2.0787087094783785
[Epoch 1, Batch 700] loss: 1.8241374504566192
[Epoch 1, Batch 800] loss: 1.36427803337574
[Epoch 1, Batch 900] loss: 0.9268901473283768
[Epoch 1, Batch 1000] loss: 0.7074290665984154
[Epoch 1, Batch 1100] loss: 0.5966034390032291
[Epoch 1, Batch 1200] loss: 0.5567071838676929
[Epoch 1, Batch 1300] loss: 0.4874165712296963
[Epoch 1, Batch 1400] loss: 0.5018872916698456
[Epoch 1, Batch 1500] loss: 0.4614733935892582
[Epoch 1, Batch 1600] loss: 0.39213650844991205
[Epoch 1, Batch 1700] loss: 0.4109615247696638
[Epoch 1, Batch 1800] loss: 0.41405017822980883
[Epoch 1, Batch 1900] loss: 0.3647791445627809
[Epoch 1, Batch 2000] loss: 0.36323910534381865
[Epoch 1, Batch 2100] loss: 0.32626589097082614
[Epoch 1, Batch 2200] loss: 0.2928092309087515
[Epoch 1, Batch 2300] loss: 0.29866858137771485
[Epoch 1, Batch 2400] loss: 0.34258968736976386
[Epoch 1, Batch 2500] loss: 0.2475106928497553
[Epoch 1, Batch 2600] loss: 0.3185600493475795
[Epoch 1, Batch 2700] loss: 0.2537576526403427
[Epoch 1, Batch 2800] loss: 0.2894056951627135
[Epoch 1, Batch 2900] loss: 0.28708756875246766
[Epoch 1, Batch 3000] loss: 0.23812887150794268
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2620
Validation Accuracy: 0.9209
Overfitting: 0.2620
Best model saved at epoch 1 with validation loss: 0.2620
[Epoch 2, Batch 100] loss: 0.305491774007678
[Epoch 2, Batch 200] loss: 0.26328702341765164
[Epoch 2, Batch 300] loss: 0.23772348856553435
[Epoch 2, Batch 400] loss: 0.22642023874446748
[Epoch 2, Batch 500] loss: 0.1957560845836997
[Epoch 2, Batch 600] loss: 0.21726663302630186
[Epoch 2, Batch 700] loss: 0.19464400913566351
[Epoch 2, Batch 800] loss: 0.21069744762033224
[Epoch 2, Batch 900] loss: 0.222573929913342
[Epoch 2, Batch 1000] loss: 0.20326327351853252
[Epoch 2, Batch 1100] loss: 0.20440801253542304
[Epoch 2, Batch 1200] loss: 0.18166073474567385
[Epoch 2, Batch 1300] loss: 0.1696449265256524
[Epoch 2, Batch 1400] loss: 0.19139516815077515
[Epoch 2, Batch 1500] loss: 0.1678195973392576
[Epoch 2, Batch 1600] loss: 0.17766315169632435
[Epoch 2, Batch 1700] loss: 0.19530658654868602
[Epoch 2, Batch 1800] loss: 0.17949462749063969
[Epoch 2, Batch 1900] loss: 0.19887584065087138
[Epoch 2, Batch 2000] loss: 0.17314366682432591
[Epoch 2, Batch 2100] loss: 0.17730077726766466
[Epoch 2, Batch 2200] loss: 0.1687287432095036
[Epoch 2, Batch 2300] loss: 0.16606693958863616
[Epoch 2, Batch 2400] loss: 0.16519204018637537
[Epoch 2, Batch 2500] loss: 0.16097149942535907
[Epoch 2, Batch 2600] loss: 0.13956780309788883
[Epoch 2, Batch 2700] loss: 0.15316075010458008
[Epoch 2, Batch 2800] loss: 0.16882075403816998
[Epoch 2, Batch 2900] loss: 0.14911106226034462
[Epoch 2, Batch 3000] loss: 0.18682612739503385
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1459
Validation Accuracy: 0.9591
Overfitting: 0.1459
Best model saved at epoch 2 with validation loss: 0.1459
[Epoch 3, Batch 100] loss: 0.17196798168122768
[Epoch 3, Batch 200] loss: 0.12803842303343116
[Epoch 3, Batch 300] loss: 0.15613719438202678
[Epoch 3, Batch 400] loss: 0.12399212737567723
[Epoch 3, Batch 500] loss: 0.1247927730064839
[Epoch 3, Batch 600] loss: 0.13659223324852066
[Epoch 3, Batch 700] loss: 0.1581930451374501
[Epoch 3, Batch 800] loss: 0.14603476088494063
[Epoch 3, Batch 900] loss: 0.1429031987627968
[Epoch 3, Batch 1000] loss: 0.1427364408550784
[Epoch 3, Batch 1100] loss: 0.11157573521719315
[Epoch 3, Batch 1200] loss: 0.13255243533756583
[Epoch 3, Batch 1300] loss: 0.12972883278504013
[Epoch 3, Batch 1400] loss: 0.11198162623215467
[Epoch 3, Batch 1500] loss: 0.13953260135371237
[Epoch 3, Batch 1600] loss: 0.11192386620212347
[Epoch 3, Batch 1700] loss: 0.12875379308825358
[Epoch 3, Batch 1800] loss: 0.11301717437338084
[Epoch 3, Batch 1900] loss: 0.11365761728025973
[Epoch 3, Batch 2000] loss: 0.12398992026690393
[Epoch 3, Batch 2100] loss: 0.09856970599386841
[Epoch 3, Batch 2200] loss: 0.12116982268169522
[Epoch 3, Batch 2300] loss: 0.09056347229052335
[Epoch 3, Batch 2400] loss: 0.08725601394893602
[Epoch 3, Batch 2500] loss: 0.10673315659165382
[Epoch 3, Batch 2600] loss: 0.12940069118048997
[Epoch 3, Batch 2700] loss: 0.09368244433542713
[Epoch 3, Batch 2800] loss: 0.10691115339752287
[Epoch 3, Batch 2900] loss: 0.11997799501288682
[Epoch 3, Batch 3000] loss: 0.12709739544428886
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1131
Validation Accuracy: 0.9673
Overfitting: 0.1131
Best model saved at epoch 3 with validation loss: 0.1131
[Epoch 4, Batch 100] loss: 0.08915308313677088
[Epoch 4, Batch 200] loss: 0.0964027678919956
[Epoch 4, Batch 300] loss: 0.09788559301756322
[Epoch 4, Batch 400] loss: 0.09831816357793287
[Epoch 4, Batch 500] loss: 0.10523556960048154
[Epoch 4, Batch 600] loss: 0.11947541933972389
[Epoch 4, Batch 700] loss: 0.09597951864125207
[Epoch 4, Batch 800] loss: 0.11000144596910104
[Epoch 4, Batch 900] loss: 0.10631447061896324
[Epoch 4, Batch 1000] loss: 0.10967314473120496
[Epoch 4, Batch 1100] loss: 0.0860149174137041
[Epoch 4, Batch 1200] loss: 0.07683288432192058
[Epoch 4, Batch 1300] loss: 0.09392021714476868
[Epoch 4, Batch 1400] loss: 0.09021728976280428
[Epoch 4, Batch 1500] loss: 0.0941797675541602
[Epoch 4, Batch 1600] loss: 0.09628227059496566
[Epoch 4, Batch 1700] loss: 0.07330121582141146
[Epoch 4, Batch 1800] loss: 0.09910202163970099
[Epoch 4, Batch 1900] loss: 0.08696560263051652
[Epoch 4, Batch 2000] loss: 0.086993267434882
[Epoch 4, Batch 2100] loss: 0.1279662411264144
[Epoch 4, Batch 2200] loss: 0.09294115595053881
[Epoch 4, Batch 2300] loss: 0.09967414734186604
[Epoch 4, Batch 2400] loss: 0.07800727542024105
[Epoch 4, Batch 2500] loss: 0.08273017390398309
[Epoch 4, Batch 2600] loss: 0.07152551659848541
[Epoch 4, Batch 2700] loss: 0.08919245659606531
[Epoch 4, Batch 2800] loss: 0.09892065900377929
[Epoch 4, Batch 2900] loss: 0.09904657409759238
[Epoch 4, Batch 3000] loss: 0.10248650077963248
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0892
Validation Accuracy: 0.9733
Overfitting: 0.0892
Best model saved at epoch 4 with validation loss: 0.0892
[Epoch 5, Batch 100] loss: 0.0721316820057109
[Epoch 5, Batch 200] loss: 0.09876593939494342
[Epoch 5, Batch 300] loss: 0.09218582918867468
[Epoch 5, Batch 400] loss: 0.11173779665026813
[Epoch 5, Batch 500] loss: 0.0630441020685248
[Epoch 5, Batch 600] loss: 0.07390734803746454
[Epoch 5, Batch 700] loss: 0.06981162891956046
[Epoch 5, Batch 800] loss: 0.08586731315706857
[Epoch 5, Batch 900] loss: 0.06301544515532441
[Epoch 5, Batch 1000] loss: 0.06751870939042419
[Epoch 5, Batch 1100] loss: 0.07995742924278602
[Epoch 5, Batch 1200] loss: 0.08201021421467886
[Epoch 5, Batch 1300] loss: 0.08844115077634342
[Epoch 5, Batch 1400] loss: 0.0848943859024439
[Epoch 5, Batch 1500] loss: 0.07134333876485471
[Epoch 5, Batch 1600] loss: 0.07554696929641068
[Epoch 5, Batch 1700] loss: 0.07569446063134819
[Epoch 5, Batch 1800] loss: 0.08677119981497526
[Epoch 5, Batch 1900] loss: 0.08072121328441426
[Epoch 5, Batch 2000] loss: 0.09588536530034616
[Epoch 5, Batch 2100] loss: 0.061339511554106135
[Epoch 5, Batch 2200] loss: 0.08642300590814557
[Epoch 5, Batch 2300] loss: 0.07621005687862635
[Epoch 5, Batch 2400] loss: 0.08036897493293509
[Epoch 5, Batch 2500] loss: 0.06109883952245582
[Epoch 5, Batch 2600] loss: 0.07844010243657977
[Epoch 5, Batch 2700] loss: 0.07951435723225586
[Epoch 5, Batch 2800] loss: 0.05780572857707739
[Epoch 5, Batch 2900] loss: 0.06781243365141564
[Epoch 5, Batch 3000] loss: 0.0868837693327805
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0870
Validation Accuracy: 0.9728
Overfitting: 0.0870
Best model saved at epoch 5 with validation loss: 0.0870
[Epoch 6, Batch 100] loss: 0.059128253380768
[Epoch 6, Batch 200] loss: 0.06588007501442916
[Epoch 6, Batch 300] loss: 0.06564957737340592
[Epoch 6, Batch 400] loss: 0.08095140229444951
[Epoch 6, Batch 500] loss: 0.052368479318683964
[Epoch 6, Batch 600] loss: 0.06610648344736546
[Epoch 6, Batch 700] loss: 0.05561435107840225
[Epoch 6, Batch 800] loss: 0.07207322250469587
[Epoch 6, Batch 900] loss: 0.07457729752757586
[Epoch 6, Batch 1000] loss: 0.07803552958066576
[Epoch 6, Batch 1100] loss: 0.07817401470732875
[Epoch 6, Batch 1200] loss: 0.06865884384023957
[Epoch 6, Batch 1300] loss: 0.06971057518618182
[Epoch 6, Batch 1400] loss: 0.05824582443572581
[Epoch 6, Batch 1500] loss: 0.07404017774155364
[Epoch 6, Batch 1600] loss: 0.07304033028776757
[Epoch 6, Batch 1700] loss: 0.06798647115356289
[Epoch 6, Batch 1800] loss: 0.053012997800833545
[Epoch 6, Batch 1900] loss: 0.0769428100832738
[Epoch 6, Batch 2000] loss: 0.057399871784728024
[Epoch 6, Batch 2100] loss: 0.057470475939335304
[Epoch 6, Batch 2200] loss: 0.08942877289722674
[Epoch 6, Batch 2300] loss: 0.08038914750679396
[Epoch 6, Batch 2400] loss: 0.061891011273255574
[Epoch 6, Batch 2500] loss: 0.057285970591474326
[Epoch 6, Batch 2600] loss: 0.06303208855097182
[Epoch 6, Batch 2700] loss: 0.07231576273799874
[Epoch 6, Batch 2800] loss: 0.06473465074028355
[Epoch 6, Batch 2900] loss: 0.062337215655716136
[Epoch 6, Batch 3000] loss: 0.07328512490028516
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0784
Validation Accuracy: 0.9762
Overfitting: 0.0784
Best model saved at epoch 6 with validation loss: 0.0784
[Epoch 7, Batch 100] loss: 0.05431981835863553
[Epoch 7, Batch 200] loss: 0.044711907758028246
[Epoch 7, Batch 300] loss: 0.05292927464703098
[Epoch 7, Batch 400] loss: 0.04993725290405564
[Epoch 7, Batch 500] loss: 0.07653403247881214
[Epoch 7, Batch 600] loss: 0.06698143005254678
[Epoch 7, Batch 700] loss: 0.056166066663572566
[Epoch 7, Batch 800] loss: 0.06567161630460759
[Epoch 7, Batch 900] loss: 0.050909197127330115
[Epoch 7, Batch 1000] loss: 0.0553137654994498
[Epoch 7, Batch 1100] loss: 0.05535523815779016
[Epoch 7, Batch 1200] loss: 0.06257242873311043
[Epoch 7, Batch 1300] loss: 0.06564831913332454
[Epoch 7, Batch 1400] loss: 0.05440514606190845
[Epoch 7, Batch 1500] loss: 0.06909875988843851
[Epoch 7, Batch 1600] loss: 0.05367285822576377
[Epoch 7, Batch 1700] loss: 0.05936329676245805
[Epoch 7, Batch 1800] loss: 0.06972094486933202
[Epoch 7, Batch 1900] loss: 0.0720023806404788
[Epoch 7, Batch 2000] loss: 0.05804525597312022
[Epoch 7, Batch 2100] loss: 0.06264967852272094
[Epoch 7, Batch 2200] loss: 0.06584728438407182
[Epoch 7, Batch 2300] loss: 0.0459738215332618
[Epoch 7, Batch 2400] loss: 0.05493373965029605
[Epoch 7, Batch 2500] loss: 0.05561802239506505
[Epoch 7, Batch 2600] loss: 0.0648898334254045
[Epoch 7, Batch 2700] loss: 0.07133369849529117
[Epoch 7, Batch 2800] loss: 0.06429084732662886
[Epoch 7, Batch 2900] loss: 0.06542795826215297
[Epoch 7, Batch 3000] loss: 0.06272197222569957
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0680
Validation Accuracy: 0.9802
Overfitting: 0.0680
Best model saved at epoch 7 with validation loss: 0.0680
[Epoch 8, Batch 100] loss: 0.04579852286435198
[Epoch 8, Batch 200] loss: 0.04908738897764124
[Epoch 8, Batch 300] loss: 0.06171660823980346
[Epoch 8, Batch 400] loss: 0.04961093438672833
[Epoch 8, Batch 500] loss: 0.05224304430244956
[Epoch 8, Batch 600] loss: 0.06440543038770556
[Epoch 8, Batch 700] loss: 0.054048418920719994
[Epoch 8, Batch 800] loss: 0.04812854173127562
[Epoch 8, Batch 900] loss: 0.05254858366010012
[Epoch 8, Batch 1000] loss: 0.05808937271562172
[Epoch 8, Batch 1100] loss: 0.0519021860283101
[Epoch 8, Batch 1200] loss: 0.055630689358222296
[Epoch 8, Batch 1300] loss: 0.05100330231303815
[Epoch 8, Batch 1400] loss: 0.05257125233183615
[Epoch 8, Batch 1500] loss: 0.05543551892507821
[Epoch 8, Batch 1600] loss: 0.05168138652326888
[Epoch 8, Batch 1700] loss: 0.04309965566382743
[Epoch 8, Batch 1800] loss: 0.06366631438140757
[Epoch 8, Batch 1900] loss: 0.049641080393339504
[Epoch 8, Batch 2000] loss: 0.0558614952058997
[Epoch 8, Batch 2100] loss: 0.05061361708736513
[Epoch 8, Batch 2200] loss: 0.043703853800543584
[Epoch 8, Batch 2300] loss: 0.057133256841625554
[Epoch 8, Batch 2400] loss: 0.05404552734806203
[Epoch 8, Batch 2500] loss: 0.051761805013520644
[Epoch 8, Batch 2600] loss: 0.058609558028983884
[Epoch 8, Batch 2700] loss: 0.057983493434730915
[Epoch 8, Batch 2800] loss: 0.04845558046305087
[Epoch 8, Batch 2900] loss: 0.05074607949092751
[Epoch 8, Batch 3000] loss: 0.0730183018615935
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0682
Validation Accuracy: 0.9796
Overfitting: 0.0682
[Epoch 9, Batch 100] loss: 0.05566135670815129
[Epoch 9, Batch 200] loss: 0.050409858425846325
[Epoch 9, Batch 300] loss: 0.05059763249591924
[Epoch 9, Batch 400] loss: 0.03902263336000033
[Epoch 9, Batch 500] loss: 0.05394374716677703
[Epoch 9, Batch 600] loss: 0.06610413903836161
[Epoch 9, Batch 700] loss: 0.04187818860635161
[Epoch 9, Batch 800] loss: 0.05387539558898425
[Epoch 9, Batch 900] loss: 0.04021857716317754
[Epoch 9, Batch 1000] loss: 0.048769521733338476
[Epoch 9, Batch 1100] loss: 0.03943870426563081
[Epoch 9, Batch 1200] loss: 0.061521176550304514
[Epoch 9, Batch 1300] loss: 0.0540449384690146
[Epoch 9, Batch 1400] loss: 0.04620411010226235
[Epoch 9, Batch 1500] loss: 0.05037612817832269
[Epoch 9, Batch 1600] loss: 0.04956147314165719
[Epoch 9, Batch 1700] loss: 0.035953102032653984
[Epoch 9, Batch 1800] loss: 0.03758767609717324
[Epoch 9, Batch 1900] loss: 0.03788811632141005
[Epoch 9, Batch 2000] loss: 0.04501202838902827
[Epoch 9, Batch 2100] loss: 0.05289578748343047
[Epoch 9, Batch 2200] loss: 0.05976780983037315
[Epoch 9, Batch 2300] loss: 0.04915355787423323
[Epoch 9, Batch 2400] loss: 0.06027508017490618
[Epoch 9, Batch 2500] loss: 0.04296385108144023
[Epoch 9, Batch 2600] loss: 0.03767403781792382
[Epoch 9, Batch 2700] loss: 0.057424973271699854
[Epoch 9, Batch 2800] loss: 0.04674146287376061
[Epoch 9, Batch 2900] loss: 0.03708903811901109
[Epoch 9, Batch 3000] loss: 0.05263915521791205
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0676
Validation Accuracy: 0.9799
Overfitting: 0.0676
Best model saved at epoch 9 with validation loss: 0.0676
[Epoch 10, Batch 100] loss: 0.03951614606310613
[Epoch 10, Batch 200] loss: 0.05552954763174057
[Epoch 10, Batch 300] loss: 0.04770224369189236
[Epoch 10, Batch 400] loss: 0.036295153265818954
[Epoch 10, Batch 500] loss: 0.05821828775922768
[Epoch 10, Batch 600] loss: 0.038593282544461545
[Epoch 10, Batch 700] loss: 0.029270870298787485
[Epoch 10, Batch 800] loss: 0.04350481476692949
[Epoch 10, Batch 900] loss: 0.04557170739513822
[Epoch 10, Batch 1000] loss: 0.03156047602693434
[Epoch 10, Batch 1100] loss: 0.047635329619806724
[Epoch 10, Batch 1200] loss: 0.044285842412500644
[Epoch 10, Batch 1300] loss: 0.04865052343491698
[Epoch 10, Batch 1400] loss: 0.042434233514068186
[Epoch 10, Batch 1500] loss: 0.048981387065869054
[Epoch 10, Batch 1600] loss: 0.04710133940156083
[Epoch 10, Batch 1700] loss: 0.04930012758035446
[Epoch 10, Batch 1800] loss: 0.03796672982134623
[Epoch 10, Batch 1900] loss: 0.03430082128077629
[Epoch 10, Batch 2000] loss: 0.04113591063636704
[Epoch 10, Batch 2100] loss: 0.048832639873289736
[Epoch 10, Batch 2200] loss: 0.03344503258209443
[Epoch 10, Batch 2300] loss: 0.053924101736629385
[Epoch 10, Batch 2400] loss: 0.036215779473277504
[Epoch 10, Batch 2500] loss: 0.04317173892661231
[Epoch 10, Batch 2600] loss: 0.04375154492183356
[Epoch 10, Batch 2700] loss: 0.039096099520102144
[Epoch 10, Batch 2800] loss: 0.05157676092901966
[Epoch 10, Batch 2900] loss: 0.039543484408641236
[Epoch 10, Batch 3000] loss: 0.03694249585299986
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0701
Validation Accuracy: 0.9782
Overfitting: 0.0701
[Epoch 11, Batch 100] loss: 0.03091713849134976
[Epoch 11, Batch 200] loss: 0.03890641106525436
[Epoch 11, Batch 300] loss: 0.028233609326998702
[Epoch 11, Batch 400] loss: 0.03659624066145625
[Epoch 11, Batch 500] loss: 0.03304026686178986
[Epoch 11, Batch 600] loss: 0.026426469760772307
[Epoch 11, Batch 700] loss: 0.035438184596423526
[Epoch 11, Batch 800] loss: 0.030956293250492307
[Epoch 11, Batch 900] loss: 0.036779167439090085
[Epoch 11, Batch 1000] loss: 0.06312760049971984
[Epoch 11, Batch 1100] loss: 0.03683297796465922
[Epoch 11, Batch 1200] loss: 0.037823528147564504
[Epoch 11, Batch 1300] loss: 0.042934023402631284
[Epoch 11, Batch 1400] loss: 0.02931714750797255
[Epoch 11, Batch 1500] loss: 0.04240934623157955
[Epoch 11, Batch 1600] loss: 0.047001322117284874
[Epoch 11, Batch 1700] loss: 0.03978369709686376
[Epoch 11, Batch 1800] loss: 0.03192967569048051
[Epoch 11, Batch 1900] loss: 0.036542292473022826
[Epoch 11, Batch 2000] loss: 0.05781783987746167
[Epoch 11, Batch 2100] loss: 0.04781183724393486
[Epoch 11, Batch 2200] loss: 0.040987200572853905
[Epoch 11, Batch 2300] loss: 0.030940106135676614
[Epoch 11, Batch 2400] loss: 0.04139440890226979
[Epoch 11, Batch 2500] loss: 0.05409482882212615
[Epoch 11, Batch 2600] loss: 0.03566295655531576
[Epoch 11, Batch 2700] loss: 0.049837712464650394
[Epoch 11, Batch 2800] loss: 0.03966379444551421
[Epoch 11, Batch 2900] loss: 0.041885739176359495
[Epoch 11, Batch 3000] loss: 0.02822729288964183
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9842
Overfitting: 0.0532
Best model saved at epoch 11 with validation loss: 0.0532
[Epoch 12, Batch 100] loss: 0.03676683024677914
[Epoch 12, Batch 200] loss: 0.02578624987479998
[Epoch 12, Batch 300] loss: 0.03445369203865994
[Epoch 12, Batch 400] loss: 0.023910813471084112
[Epoch 12, Batch 500] loss: 0.032520043161493956
[Epoch 12, Batch 600] loss: 0.05898240022594109
[Epoch 12, Batch 700] loss: 0.037916573816764866
[Epoch 12, Batch 800] loss: 0.03107562252356729
[Epoch 12, Batch 900] loss: 0.03666269318666309
[Epoch 12, Batch 1000] loss: 0.04713039335649228
[Epoch 12, Batch 1100] loss: 0.0359742554629338
[Epoch 12, Batch 1200] loss: 0.041511639929376544
[Epoch 12, Batch 1300] loss: 0.043013786116207486
[Epoch 12, Batch 1400] loss: 0.03401784929999849
[Epoch 12, Batch 1500] loss: 0.044701268336502835
[Epoch 12, Batch 1600] loss: 0.030524007021740546
[Epoch 12, Batch 1700] loss: 0.04335701755451737
[Epoch 12, Batch 1800] loss: 0.040959498959127816
[Epoch 12, Batch 1900] loss: 0.04213583009695867
[Epoch 12, Batch 2000] loss: 0.03489111572242109
[Epoch 12, Batch 2100] loss: 0.03856319973710924
[Epoch 12, Batch 2200] loss: 0.033195838994433874
[Epoch 12, Batch 2300] loss: 0.03855439793740516
[Epoch 12, Batch 2400] loss: 0.029880071497755126
[Epoch 12, Batch 2500] loss: 0.02582173825241625
[Epoch 12, Batch 2600] loss: 0.03180331645067781
[Epoch 12, Batch 2700] loss: 0.04152950653064181
[Epoch 12, Batch 2800] loss: 0.036133401506667724
[Epoch 12, Batch 2900] loss: 0.024538763950040447
[Epoch 12, Batch 3000] loss: 0.03673444276646478
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9838
Overfitting: 0.0546
[Epoch 13, Batch 100] loss: 0.027830029806937093
[Epoch 13, Batch 200] loss: 0.03124257809824485
[Epoch 13, Batch 300] loss: 0.016500808229357063
[Epoch 13, Batch 400] loss: 0.03610136236864491
[Epoch 13, Batch 500] loss: 0.05199234537925804
[Epoch 13, Batch 600] loss: 0.028296360449458005
[Epoch 13, Batch 700] loss: 0.03245414935212466
[Epoch 13, Batch 800] loss: 0.030356191611499526
[Epoch 13, Batch 900] loss: 0.019617629888816736
[Epoch 13, Batch 1000] loss: 0.03636090474654338
[Epoch 13, Batch 1100] loss: 0.030011556299286896
[Epoch 13, Batch 1200] loss: 0.03031713068805402
[Epoch 13, Batch 1300] loss: 0.02952869802058558
[Epoch 13, Batch 1400] loss: 0.03409235038037878
[Epoch 13, Batch 1500] loss: 0.03317851505606086
[Epoch 13, Batch 1600] loss: 0.05372760771482717
[Epoch 13, Batch 1700] loss: 0.04515830045718758
[Epoch 13, Batch 1800] loss: 0.032463311553801756
[Epoch 13, Batch 1900] loss: 0.038156931184712445
[Epoch 13, Batch 2000] loss: 0.04943527387862559
[Epoch 13, Batch 2100] loss: 0.0368613393267151
[Epoch 13, Batch 2200] loss: 0.026778913184825795
[Epoch 13, Batch 2300] loss: 0.024120822476397734
[Epoch 13, Batch 2400] loss: 0.030179578875395238
[Epoch 13, Batch 2500] loss: 0.03364872197591467
[Epoch 13, Batch 2600] loss: 0.038314219892199616
[Epoch 13, Batch 2700] loss: 0.03486534436349757
[Epoch 13, Batch 2800] loss: 0.039476905495394024
[Epoch 13, Batch 2900] loss: 0.023026928060426145
[Epoch 13, Batch 3000] loss: 0.030572995743787034
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9836
Overfitting: 0.0550
[Epoch 14, Batch 100] loss: 0.03256014729602612
[Epoch 14, Batch 200] loss: 0.025537382167967734
[Epoch 14, Batch 300] loss: 0.03851316092797788
[Epoch 14, Batch 400] loss: 0.030151818107260624
[Epoch 14, Batch 500] loss: 0.03354868943526526
[Epoch 14, Batch 600] loss: 0.025735200235503727
[Epoch 14, Batch 700] loss: 0.023024098020396195
[Epoch 14, Batch 800] loss: 0.029656659960892284
[Epoch 14, Batch 900] loss: 0.04503857540970785
[Epoch 14, Batch 1000] loss: 0.03175946412273333
[Epoch 14, Batch 1100] loss: 0.022228687197348336
[Epoch 14, Batch 1200] loss: 0.0345182876495528
[Epoch 14, Batch 1300] loss: 0.039235395964933556
[Epoch 14, Batch 1400] loss: 0.036208373154804574
[Epoch 14, Batch 1500] loss: 0.03608893824290135
[Epoch 14, Batch 1600] loss: 0.024019376641372218
[Epoch 14, Batch 1700] loss: 0.03270744020614075
[Epoch 14, Batch 1800] loss: 0.025204942302807468
[Epoch 14, Batch 1900] loss: 0.03752508464443963
[Epoch 14, Batch 2000] loss: 0.03180379396770149
[Epoch 14, Batch 2100] loss: 0.03586629468074534
[Epoch 14, Batch 2200] loss: 0.023228677807346686
[Epoch 14, Batch 2300] loss: 0.03406397179205669
[Epoch 14, Batch 2400] loss: 0.03445114986199769
[Epoch 14, Batch 2500] loss: 0.021257116758206393
[Epoch 14, Batch 2600] loss: 0.024908127653907285
[Epoch 14, Batch 2700] loss: 0.02804466883215355
[Epoch 14, Batch 2800] loss: 0.03801411479937087
[Epoch 14, Batch 2900] loss: 0.030429323091957484
[Epoch 14, Batch 3000] loss: 0.02390079646691447
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9847
Overfitting: 0.0518
Best model saved at epoch 14 with validation loss: 0.0518
[Epoch 15, Batch 100] loss: 0.02506693830669974
[Epoch 15, Batch 200] loss: 0.03365543616528157
[Epoch 15, Batch 300] loss: 0.03268145437410567
[Epoch 15, Batch 400] loss: 0.030861413098391494
[Epoch 15, Batch 500] loss: 0.019095723691934838
[Epoch 15, Batch 600] loss: 0.027254786314042576
[Epoch 15, Batch 700] loss: 0.025758846262542646
[Epoch 15, Batch 800] loss: 0.03878878916453687
[Epoch 15, Batch 900] loss: 0.02769379860110348
[Epoch 15, Batch 1000] loss: 0.03063748439344636
[Epoch 15, Batch 1100] loss: 0.035338054380263204
[Epoch 15, Batch 1200] loss: 0.017943301582199638
[Epoch 15, Batch 1300] loss: 0.0318084504212311
[Epoch 15, Batch 1400] loss: 0.04387948364223121
[Epoch 15, Batch 1500] loss: 0.03182866455274052
[Epoch 15, Batch 1600] loss: 0.022476059703767533
[Epoch 15, Batch 1700] loss: 0.03370021882285073
[Epoch 15, Batch 1800] loss: 0.024219993011065526
[Epoch 15, Batch 1900] loss: 0.03154219467687654
[Epoch 15, Batch 2000] loss: 0.0217621915928612
[Epoch 15, Batch 2100] loss: 0.018659385188875603
[Epoch 15, Batch 2200] loss: 0.037475532720563934
[Epoch 15, Batch 2300] loss: 0.03276689935577451
[Epoch 15, Batch 2400] loss: 0.027846702784008814
[Epoch 15, Batch 2500] loss: 0.0218705117792706
[Epoch 15, Batch 2600] loss: 0.04352743159746751
[Epoch 15, Batch 2700] loss: 0.024574453770546824
[Epoch 15, Batch 2800] loss: 0.024661033511947608
[Epoch 15, Batch 2900] loss: 0.030883317943953444
[Epoch 15, Batch 3000] loss: 0.02915551136196882
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9849
Overfitting: 0.0510
Best model saved at epoch 15 with validation loss: 0.0510
[Epoch 16, Batch 100] loss: 0.027023261452268344
[Epoch 16, Batch 200] loss: 0.030174391564360123
[Epoch 16, Batch 300] loss: 0.01721893859030388
[Epoch 16, Batch 400] loss: 0.02082693375821691
[Epoch 16, Batch 500] loss: 0.01632292427988432
[Epoch 16, Batch 600] loss: 0.02675461397957406
[Epoch 16, Batch 700] loss: 0.03303593997217831
[Epoch 16, Batch 800] loss: 0.040583108575083314
[Epoch 16, Batch 900] loss: 0.02152975997181784
[Epoch 16, Batch 1000] loss: 0.019448281507939102
[Epoch 16, Batch 1100] loss: 0.03347657662045094
[Epoch 16, Batch 1200] loss: 0.026024560985388235
[Epoch 16, Batch 1300] loss: 0.018039571870904183
[Epoch 16, Batch 1400] loss: 0.025944403692628838
[Epoch 16, Batch 1500] loss: 0.031094653500003913
[Epoch 16, Batch 1600] loss: 0.027491616983315908
[Epoch 16, Batch 1700] loss: 0.01562508261813491
[Epoch 16, Batch 1800] loss: 0.023495270039638853
[Epoch 16, Batch 1900] loss: 0.029046685199282364
[Epoch 16, Batch 2000] loss: 0.023746678986863116
[Epoch 16, Batch 2100] loss: 0.014505817069366458
[Epoch 16, Batch 2200] loss: 0.030733231052581685
[Epoch 16, Batch 2300] loss: 0.03274879254939151
[Epoch 16, Batch 2400] loss: 0.03406504948667134
[Epoch 16, Batch 2500] loss: 0.02365125661883212
[Epoch 16, Batch 2600] loss: 0.027483011786825953
[Epoch 16, Batch 2700] loss: 0.023997248888845205
[Epoch 16, Batch 2800] loss: 0.044701971146096184
[Epoch 16, Batch 2900] loss: 0.029023953215655637
[Epoch 16, Batch 3000] loss: 0.03375237137064687
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9854
Overfitting: 0.0491
Best model saved at epoch 16 with validation loss: 0.0491
[Epoch 17, Batch 100] loss: 0.020460064384387806
[Epoch 17, Batch 200] loss: 0.026418346987120457
[Epoch 17, Batch 300] loss: 0.021356202928727724
[Epoch 17, Batch 400] loss: 0.025928700116783148
[Epoch 17, Batch 500] loss: 0.03328507208148949
[Epoch 17, Batch 600] loss: 0.019729297141893767
[Epoch 17, Batch 700] loss: 0.027745201329962582
[Epoch 17, Batch 800] loss: 0.02095086802073638
[Epoch 17, Batch 900] loss: 0.025869391063824878
[Epoch 17, Batch 1000] loss: 0.026776514307093748
[Epoch 17, Batch 1100] loss: 0.01412309965606255
[Epoch 17, Batch 1200] loss: 0.022423274888133164
[Epoch 17, Batch 1300] loss: 0.020289854918773928
[Epoch 17, Batch 1400] loss: 0.023704697961729835
[Epoch 17, Batch 1500] loss: 0.024703758610812657
[Epoch 17, Batch 1600] loss: 0.02700633283377101
[Epoch 17, Batch 1700] loss: 0.02660177511294023
[Epoch 17, Batch 1800] loss: 0.031854582224113984
[Epoch 17, Batch 1900] loss: 0.02692710454466578
[Epoch 17, Batch 2000] loss: 0.022191145478136606
[Epoch 17, Batch 2100] loss: 0.030443702359625603
[Epoch 17, Batch 2200] loss: 0.02427568738727132
[Epoch 17, Batch 2300] loss: 0.02715874423942296
[Epoch 17, Batch 2400] loss: 0.025077508245813077
[Epoch 17, Batch 2500] loss: 0.024537647226025
[Epoch 17, Batch 2600] loss: 0.02731737800015253
[Epoch 17, Batch 2700] loss: 0.024973951783103986
[Epoch 17, Batch 2800] loss: 0.024717463633132864
[Epoch 17, Batch 2900] loss: 0.03713698514024145
[Epoch 17, Batch 3000] loss: 0.018616543586322223
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9863
Overfitting: 0.0470
Best model saved at epoch 17 with validation loss: 0.0470
[Epoch 18, Batch 100] loss: 0.021650557160028255
[Epoch 18, Batch 200] loss: 0.03488542553044681
[Epoch 18, Batch 300] loss: 0.014933211980387568
[Epoch 18, Batch 400] loss: 0.013897359440597938
[Epoch 18, Batch 500] loss: 0.024942612983068102
[Epoch 18, Batch 600] loss: 0.027511209341500944
[Epoch 18, Batch 700] loss: 0.023773819624839234
[Epoch 18, Batch 800] loss: 0.02433790361727006
[Epoch 18, Batch 900] loss: 0.024115875662027976
[Epoch 18, Batch 1000] loss: 0.021587017646052118
[Epoch 18, Batch 1100] loss: 0.02402384370972868
[Epoch 18, Batch 1200] loss: 0.017227694481553046
[Epoch 18, Batch 1300] loss: 0.01769758235444897
[Epoch 18, Batch 1400] loss: 0.04077784922228602
[Epoch 18, Batch 1500] loss: 0.021963972226512852
[Epoch 18, Batch 1600] loss: 0.023509508902207016
[Epoch 18, Batch 1700] loss: 0.020178455067944013
[Epoch 18, Batch 1800] loss: 0.02000047578010708
[Epoch 18, Batch 1900] loss: 0.018504217501758832
[Epoch 18, Batch 2000] loss: 0.023755939164948357
[Epoch 18, Batch 2100] loss: 0.024690661339482178
[Epoch 18, Batch 2200] loss: 0.03907981046086206
[Epoch 18, Batch 2300] loss: 0.021802255775473896
[Epoch 18, Batch 2400] loss: 0.027360997823416257
[Epoch 18, Batch 2500] loss: 0.022058011920198625
[Epoch 18, Batch 2600] loss: 0.022239205163023145
[Epoch 18, Batch 2700] loss: 0.0270750800800306
[Epoch 18, Batch 2800] loss: 0.015898020311760776
[Epoch 18, Batch 2900] loss: 0.020757259386009537
[Epoch 18, Batch 3000] loss: 0.027986186271555198
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9853
Overfitting: 0.0484
[Epoch 19, Batch 100] loss: 0.02152589746132435
[Epoch 19, Batch 200] loss: 0.015821463926640716
[Epoch 19, Batch 300] loss: 0.022215572387285647
[Epoch 19, Batch 400] loss: 0.01876677705167822
[Epoch 19, Batch 500] loss: 0.028668151157216926
[Epoch 19, Batch 600] loss: 0.0152350455047781
[Epoch 19, Batch 700] loss: 0.01831466107050801
[Epoch 19, Batch 800] loss: 0.026170624938458786
[Epoch 19, Batch 900] loss: 0.02633948856193456
[Epoch 19, Batch 1000] loss: 0.019244488465992617
[Epoch 19, Batch 1100] loss: 0.023802609206541092
[Epoch 19, Batch 1200] loss: 0.018465040783212316
[Epoch 19, Batch 1300] loss: 0.01810803587024566
[Epoch 19, Batch 1400] loss: 0.026222542749601417
[Epoch 19, Batch 1500] loss: 0.0240690711112984
[Epoch 19, Batch 1600] loss: 0.0188143678598135
[Epoch 19, Batch 1700] loss: 0.022780315346899442
[Epoch 19, Batch 1800] loss: 0.0325011124163575
[Epoch 19, Batch 1900] loss: 0.020488930679166514
[Epoch 19, Batch 2000] loss: 0.009868407857247803
[Epoch 19, Batch 2100] loss: 0.020373181742743326
[Epoch 19, Batch 2200] loss: 0.01376450491938158
[Epoch 19, Batch 2300] loss: 0.024875348188215865
[Epoch 19, Batch 2400] loss: 0.024875133048626593
[Epoch 19, Batch 2500] loss: 0.02664161672237242
[Epoch 19, Batch 2600] loss: 0.02284421912932885
[Epoch 19, Batch 2700] loss: 0.014026930780455587
[Epoch 19, Batch 2800] loss: 0.021854686224778562
[Epoch 19, Batch 2900] loss: 0.014679319740025676
[Epoch 19, Batch 3000] loss: 0.030039431843324565
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0633
Validation Accuracy: 0.9810
Overfitting: 0.0633
[Epoch 20, Batch 100] loss: 0.017545787851995554
[Epoch 20, Batch 200] loss: 0.0316399039447424
[Epoch 20, Batch 300] loss: 0.014561606871902768
[Epoch 20, Batch 400] loss: 0.015486042582087975
[Epoch 20, Batch 500] loss: 0.01509814115575864
[Epoch 20, Batch 600] loss: 0.020356850800380924
[Epoch 20, Batch 700] loss: 0.014754856595918681
[Epoch 20, Batch 800] loss: 0.026306393143277092
[Epoch 20, Batch 900] loss: 0.008454532443647623
[Epoch 20, Batch 1000] loss: 0.02550581788749696
[Epoch 20, Batch 1100] loss: 0.030068677013732666
[Epoch 20, Batch 1200] loss: 0.030998479314112048
[Epoch 20, Batch 1300] loss: 0.011783627526965575
[Epoch 20, Batch 1400] loss: 0.020818044105208173
[Epoch 20, Batch 1500] loss: 0.018980494878705942
[Epoch 20, Batch 1600] loss: 0.015128943570671254
[Epoch 20, Batch 1700] loss: 0.020663198213806026
[Epoch 20, Batch 1800] loss: 0.02156474866598728
[Epoch 20, Batch 1900] loss: 0.02689075767964823
[Epoch 20, Batch 2000] loss: 0.02794676290919597
[Epoch 20, Batch 2100] loss: 0.02176721914234804
[Epoch 20, Batch 2200] loss: 0.015458505612623413
[Epoch 20, Batch 2300] loss: 0.016754485395331357
[Epoch 20, Batch 2400] loss: 0.015577146120231191
[Epoch 20, Batch 2500] loss: 0.012203041790817224
[Epoch 20, Batch 2600] loss: 0.023855292017597094
[Epoch 20, Batch 2700] loss: 0.024907992888729497
[Epoch 20, Batch 2800] loss: 0.01765871291339863
[Epoch 20, Batch 2900] loss: 0.021951679290323226
[Epoch 20, Batch 3000] loss: 0.011914807449156796
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9874
Overfitting: 0.0436
Best model saved at epoch 20 with validation loss: 0.0436
[Epoch 21, Batch 100] loss: 0.013882156929685151
[Epoch 21, Batch 200] loss: 0.017573944726173067
[Epoch 21, Batch 300] loss: 0.010824804109652177
[Epoch 21, Batch 400] loss: 0.025911830895056484
[Epoch 21, Batch 500] loss: 0.018925333527149632
[Epoch 21, Batch 600] loss: 0.020283211990972633
[Epoch 21, Batch 700] loss: 0.018641769960122474
[Epoch 21, Batch 800] loss: 0.028981214632513002
[Epoch 21, Batch 900] loss: 0.015360765890582115
[Epoch 21, Batch 1000] loss: 0.0168214763405922
[Epoch 21, Batch 1100] loss: 0.016528696712484817
[Epoch 21, Batch 1200] loss: 0.021007092723521054
[Epoch 21, Batch 1300] loss: 0.017780965548517998
[Epoch 21, Batch 1400] loss: 0.023173615190462443
[Epoch 21, Batch 1500] loss: 0.009645653120696807
[Epoch 21, Batch 1600] loss: 0.015674009318317986
[Epoch 21, Batch 1700] loss: 0.023994691713705833
[Epoch 21, Batch 1800] loss: 0.014660415381695203
[Epoch 21, Batch 1900] loss: 0.013561906225695565
[Epoch 21, Batch 2000] loss: 0.016781870469239946
[Epoch 21, Batch 2100] loss: 0.020322920819962745
[Epoch 21, Batch 2200] loss: 0.025481180509741533
[Epoch 21, Batch 2300] loss: 0.016395028824408655
[Epoch 21, Batch 2400] loss: 0.013084786457620795
[Epoch 21, Batch 2500] loss: 0.020685222143947614
[Epoch 21, Batch 2600] loss: 0.022722719393477746
[Epoch 21, Batch 2700] loss: 0.01557755180521781
[Epoch 21, Batch 2800] loss: 0.009675476535248891
[Epoch 21, Batch 2900] loss: 0.015288164881858392
[Epoch 21, Batch 3000] loss: 0.023224192057314214
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9867
Overfitting: 0.0450
[Epoch 22, Batch 100] loss: 0.01638627172669658
[Epoch 22, Batch 200] loss: 0.014151366282767412
[Epoch 22, Batch 300] loss: 0.023479004325336065
[Epoch 22, Batch 400] loss: 0.009684646416735632
[Epoch 22, Batch 500] loss: 0.022411716186707054
[Epoch 22, Batch 600] loss: 0.008059244573123578
[Epoch 22, Batch 700] loss: 0.01937440294402222
[Epoch 22, Batch 800] loss: 0.01392476313492807
[Epoch 22, Batch 900] loss: 0.01825127770756808
[Epoch 22, Batch 1000] loss: 0.019278910222528794
[Epoch 22, Batch 1100] loss: 0.013234745829322492
[Epoch 22, Batch 1200] loss: 0.018796061912726144
[Epoch 22, Batch 1300] loss: 0.02090903432601408
[Epoch 22, Batch 1400] loss: 0.022425703415356112
[Epoch 22, Batch 1500] loss: 0.023023077134694175
[Epoch 22, Batch 1600] loss: 0.019905703120275575
[Epoch 22, Batch 1700] loss: 0.014793909346499276
[Epoch 22, Batch 1800] loss: 0.01719557163405625
[Epoch 22, Batch 1900] loss: 0.017269074707946856
[Epoch 22, Batch 2000] loss: 0.018175832821871154
[Epoch 22, Batch 2100] loss: 0.016044813046901255
[Epoch 22, Batch 2200] loss: 0.0193759144905016
[Epoch 22, Batch 2300] loss: 0.017491300685651367
[Epoch 22, Batch 2400] loss: 0.016679182934349227
[Epoch 22, Batch 2500] loss: 0.011938293343373516
[Epoch 22, Batch 2600] loss: 0.025584567290206906
[Epoch 22, Batch 2700] loss: 0.008605311742321646
[Epoch 22, Batch 2800] loss: 0.020185327963008603
[Epoch 22, Batch 2900] loss: 0.017545535084427685
[Epoch 22, Batch 3000] loss: 0.015022991262630967
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9859
Overfitting: 0.0465
[Epoch 23, Batch 100] loss: 0.014918669656472048
[Epoch 23, Batch 200] loss: 0.015544131895003374
[Epoch 23, Batch 300] loss: 0.022531470430621994
[Epoch 23, Batch 400] loss: 0.010338466059765778
[Epoch 23, Batch 500] loss: 0.0199912681780188
[Epoch 23, Batch 600] loss: 0.017700558479082248
[Epoch 23, Batch 700] loss: 0.025487162889403406
[Epoch 23, Batch 800] loss: 0.012613816274315468
[Epoch 23, Batch 900] loss: 0.020498588134469174
[Epoch 23, Batch 1000] loss: 0.014375944044986681
[Epoch 23, Batch 1100] loss: 0.011806395728017378
[Epoch 23, Batch 1200] loss: 0.01055426008687391
[Epoch 23, Batch 1300] loss: 0.011762835374320275
[Epoch 23, Batch 1400] loss: 0.01698279125055706
[Epoch 23, Batch 1500] loss: 0.017639246092330724
[Epoch 23, Batch 1600] loss: 0.016404128103822586
[Epoch 23, Batch 1700] loss: 0.016003165398960847
[Epoch 23, Batch 1800] loss: 0.0213697969617715
[Epoch 23, Batch 1900] loss: 0.012135311965666916
[Epoch 23, Batch 2000] loss: 0.01579925530663786
[Epoch 23, Batch 2100] loss: 0.017098227993319597
[Epoch 23, Batch 2200] loss: 0.019806831771129508
[Epoch 23, Batch 2300] loss: 0.020046068359724813
[Epoch 23, Batch 2400] loss: 0.015287065016527776
[Epoch 23, Batch 2500] loss: 0.016631587178799236
[Epoch 23, Batch 2600] loss: 0.015775397941215488
[Epoch 23, Batch 2700] loss: 0.013140007656402304
[Epoch 23, Batch 2800] loss: 0.015298184312705417
[Epoch 23, Batch 2900] loss: 0.015520300659718487
[Epoch 23, Batch 3000] loss: 0.010105629379650054
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9875
Overfitting: 0.0453
[Epoch 24, Batch 100] loss: 0.008215314156814202
[Epoch 24, Batch 200] loss: 0.018782797221811053
[Epoch 24, Batch 300] loss: 0.010407804171991301
[Epoch 24, Batch 400] loss: 0.012608821635694767
[Epoch 24, Batch 500] loss: 0.010344910197782156
[Epoch 24, Batch 600] loss: 0.012352265829213139
[Epoch 24, Batch 700] loss: 0.010783071393088903
[Epoch 24, Batch 800] loss: 0.019689377333052108
[Epoch 24, Batch 900] loss: 0.013795824992084817
[Epoch 24, Batch 1000] loss: 0.015935245927666982
[Epoch 24, Batch 1100] loss: 0.008190786682207544
[Epoch 24, Batch 1200] loss: 0.0068737762404362
[Epoch 24, Batch 1300] loss: 0.025712869388444234
[Epoch 24, Batch 1400] loss: 0.011277849862581206
[Epoch 24, Batch 1500] loss: 0.013383769134834437
[Epoch 24, Batch 1600] loss: 0.013810386347458917
[Epoch 24, Batch 1700] loss: 0.01595914245914173
[Epoch 24, Batch 1800] loss: 0.02280254080214945
[Epoch 24, Batch 1900] loss: 0.018176250155338494
[Epoch 24, Batch 2000] loss: 0.017694396094416334
[Epoch 24, Batch 2100] loss: 0.01070196246049818
[Epoch 24, Batch 2200] loss: 0.018356030375616682
[Epoch 24, Batch 2300] loss: 0.015755640426195896
[Epoch 24, Batch 2400] loss: 0.019923821557358678
[Epoch 24, Batch 2500] loss: 0.011990544871696329
[Epoch 24, Batch 2600] loss: 0.010155922801232009
[Epoch 24, Batch 2700] loss: 0.03835202485030095
[Epoch 24, Batch 2800] loss: 0.01504366545668745
[Epoch 24, Batch 2900] loss: 0.015234596088612306
[Epoch 24, Batch 3000] loss: 0.01151150577131375
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9866
Overfitting: 0.0481
Fold 5 validation loss: 0.0481
Mean validation loss across all folds for Trial 5 is 0.0469 with trial config:  l1: 256, l2: 128, lr: 0.00032927591344236165, batch_size: 16
[I 2024-12-11 03:15:35,989] Trial 4 finished with value: 0.046929042829858846 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16}. Best is trial 4 with value: 0.046929042829858846.

Selected Hyperparameters for Trial 6:
  l1: 256, l2: 128, lr: 0.00011348084525743877, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3030641007423402
[Epoch 1, Batch 200] loss: 2.3000927925109864
[Epoch 1, Batch 300] loss: 2.2997962260246276
[Epoch 1, Batch 400] loss: 2.2946894001960754
[Epoch 1, Batch 500] loss: 2.2933273673057557
[Epoch 1, Batch 600] loss: 2.2913989567756654
[Epoch 1, Batch 700] loss: 2.2892668890953063
[Epoch 1, Batch 800] loss: 2.284777464866638
[Epoch 1, Batch 900] loss: 2.2813225984573364
[Epoch 1, Batch 1000] loss: 2.277557821273804
[Epoch 1, Batch 1100] loss: 2.2762962222099303
[Epoch 1, Batch 1200] loss: 2.2703557896614073
[Epoch 1, Batch 1300] loss: 2.265020778179169
[Epoch 1, Batch 1400] loss: 2.260360612869263
[Epoch 1, Batch 1500] loss: 2.254936165809631
[Epoch 1, Batch 1600] loss: 2.249261033535004
[Epoch 1, Batch 1700] loss: 2.2397251963615417
[Epoch 1, Batch 1800] loss: 2.2287501430511476
[Epoch 1, Batch 1900] loss: 2.2208551573753357
[Epoch 1, Batch 2000] loss: 2.2033799123764037
[Epoch 1, Batch 2100] loss: 2.1831228351593017
[Epoch 1, Batch 2200] loss: 2.1665886425971985
[Epoch 1, Batch 2300] loss: 2.138853704929352
[Epoch 1, Batch 2400] loss: 2.1000534796714785
[Epoch 1, Batch 2500] loss: 2.0589199221134185
[Epoch 1, Batch 2600] loss: 1.991055487394333
[Epoch 1, Batch 2700] loss: 1.9130196678638458
[Epoch 1, Batch 2800] loss: 1.796645691394806
[Epoch 1, Batch 2900] loss: 1.6321521043777465
[Epoch 1, Batch 3000] loss: 1.4659104251861572
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 1.3779
Validation Accuracy: 0.7286
Overfitting: 1.3779
Best model saved at epoch 1 with validation loss: 1.3779
[Epoch 2, Batch 100] loss: 1.278375096321106
[Epoch 2, Batch 200] loss: 1.116662909388542
[Epoch 2, Batch 300] loss: 0.9812382304668427
[Epoch 2, Batch 400] loss: 0.8637218859791755
[Epoch 2, Batch 500] loss: 0.77404776096344
[Epoch 2, Batch 600] loss: 0.7424751159548759
[Epoch 2, Batch 700] loss: 0.6860484135150909
[Epoch 2, Batch 800] loss: 0.6286300317943097
[Epoch 2, Batch 900] loss: 0.5939600810408592
[Epoch 2, Batch 1000] loss: 0.5779077784717083
[Epoch 2, Batch 1100] loss: 0.5654190643131733
[Epoch 2, Batch 1200] loss: 0.46592477336525917
[Epoch 2, Batch 1300] loss: 0.5059835658967495
[Epoch 2, Batch 1400] loss: 0.5072221554815769
[Epoch 2, Batch 1500] loss: 0.5375355112552643
[Epoch 2, Batch 1600] loss: 0.45523417338728905
[Epoch 2, Batch 1700] loss: 0.40693503990769386
[Epoch 2, Batch 1800] loss: 0.38293012000620363
[Epoch 2, Batch 1900] loss: 0.42944420769810676
[Epoch 2, Batch 2000] loss: 0.4134381178021431
[Epoch 2, Batch 2100] loss: 0.4195453506708145
[Epoch 2, Batch 2200] loss: 0.3897988623380661
[Epoch 2, Batch 2300] loss: 0.4016556091606617
[Epoch 2, Batch 2400] loss: 0.34024727910757063
[Epoch 2, Batch 2500] loss: 0.4192503882944584
[Epoch 2, Batch 2600] loss: 0.3266224554181099
[Epoch 2, Batch 2700] loss: 0.36716282114386556
[Epoch 2, Batch 2800] loss: 0.35634034998714925
[Epoch 2, Batch 2900] loss: 0.34987028189003466
[Epoch 2, Batch 3000] loss: 0.337116410471499
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.3229
Validation Accuracy: 0.9049
Overfitting: 0.3229
Best model saved at epoch 2 with validation loss: 0.3229
[Epoch 3, Batch 100] loss: 0.3563328005000949
[Epoch 3, Batch 200] loss: 0.35121908858418466
[Epoch 3, Batch 300] loss: 0.2925921507924795
[Epoch 3, Batch 400] loss: 0.2916762649640441
[Epoch 3, Batch 500] loss: 0.29244680585339666
[Epoch 3, Batch 600] loss: 0.31905936043709515
[Epoch 3, Batch 700] loss: 0.30412898063659666
[Epoch 3, Batch 800] loss: 0.27562707118690016
[Epoch 3, Batch 900] loss: 0.3096981237456202
[Epoch 3, Batch 1000] loss: 0.3029004293307662
[Epoch 3, Batch 1100] loss: 0.2797809736803174
[Epoch 3, Batch 1200] loss: 0.3032882861420512
[Epoch 3, Batch 1300] loss: 0.29046777959913017
[Epoch 3, Batch 1400] loss: 0.2756472000107169
[Epoch 3, Batch 1500] loss: 0.32236254623159766
[Epoch 3, Batch 1600] loss: 0.27906277146190406
[Epoch 3, Batch 1700] loss: 0.26896198159083723
[Epoch 3, Batch 1800] loss: 0.29087992329150436
[Epoch 3, Batch 1900] loss: 0.26912947490811345
[Epoch 3, Batch 2000] loss: 0.25103712441399695
[Epoch 3, Batch 2100] loss: 0.31037613889202476
[Epoch 3, Batch 2200] loss: 0.2785787633992732
[Epoch 3, Batch 2300] loss: 0.27440319646149874
[Epoch 3, Batch 2400] loss: 0.27083546955138443
[Epoch 3, Batch 2500] loss: 0.2334189808368683
[Epoch 3, Batch 2600] loss: 0.2508053878322244
[Epoch 3, Batch 2700] loss: 0.25278904624283316
[Epoch 3, Batch 2800] loss: 0.2790294748917222
[Epoch 3, Batch 2900] loss: 0.24141388459131122
[Epoch 3, Batch 3000] loss: 0.2657901260443032
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.2313
Validation Accuracy: 0.9313
Overfitting: 0.2313
Best model saved at epoch 3 with validation loss: 0.2313
[Epoch 4, Batch 100] loss: 0.22467897169291973
[Epoch 4, Batch 200] loss: 0.25457899294793607
[Epoch 4, Batch 300] loss: 0.22509766494855285
[Epoch 4, Batch 400] loss: 0.2543403203971684
[Epoch 4, Batch 500] loss: 0.2342811982706189
[Epoch 4, Batch 600] loss: 0.21303703166544438
[Epoch 4, Batch 700] loss: 0.22616763159632683
[Epoch 4, Batch 800] loss: 0.22203218445181847
[Epoch 4, Batch 900] loss: 0.21524157567881047
[Epoch 4, Batch 1000] loss: 0.20737630816176533
[Epoch 4, Batch 1100] loss: 0.2055727895256132
[Epoch 4, Batch 1200] loss: 0.21994310902431607
[Epoch 4, Batch 1300] loss: 0.18354779785498976
[Epoch 4, Batch 1400] loss: 0.23633429357782007
[Epoch 4, Batch 1500] loss: 0.24354311445727944
[Epoch 4, Batch 1600] loss: 0.2027488934621215
[Epoch 4, Batch 1700] loss: 0.2155294705182314
[Epoch 4, Batch 1800] loss: 0.24277229078114032
[Epoch 4, Batch 1900] loss: 0.18641513981390745
[Epoch 4, Batch 2000] loss: 0.20562308475375177
[Epoch 4, Batch 2100] loss: 0.19598554618656636
[Epoch 4, Batch 2200] loss: 0.19189733021892608
[Epoch 4, Batch 2300] loss: 0.18694051973521708
[Epoch 4, Batch 2400] loss: 0.22178363731130957
[Epoch 4, Batch 2500] loss: 0.20529513602145016
[Epoch 4, Batch 2600] loss: 0.22347196636721492
[Epoch 4, Batch 2700] loss: 0.2437409495934844
[Epoch 4, Batch 2800] loss: 0.1920028800703585
[Epoch 4, Batch 2900] loss: 0.18374895920976997
[Epoch 4, Batch 3000] loss: 0.1827129505202174
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1739
Validation Accuracy: 0.9478
Overfitting: 0.1739
Best model saved at epoch 4 with validation loss: 0.1739
[Epoch 5, Batch 100] loss: 0.20489395331591367
[Epoch 5, Batch 200] loss: 0.1838405552506447
[Epoch 5, Batch 300] loss: 0.15037820795550944
[Epoch 5, Batch 400] loss: 0.20332588403485716
[Epoch 5, Batch 500] loss: 0.17357372615486383
[Epoch 5, Batch 600] loss: 0.1726298324111849
[Epoch 5, Batch 700] loss: 0.2083528997283429
[Epoch 5, Batch 800] loss: 0.1642587126372382
[Epoch 5, Batch 900] loss: 0.20027024027891457
[Epoch 5, Batch 1000] loss: 0.1953917166823521
[Epoch 5, Batch 1100] loss: 0.18343887424096464
[Epoch 5, Batch 1200] loss: 0.17307749247178436
[Epoch 5, Batch 1300] loss: 0.18034262756817043
[Epoch 5, Batch 1400] loss: 0.163625462166965
[Epoch 5, Batch 1500] loss: 0.17059493179200216
[Epoch 5, Batch 1600] loss: 0.18281559336930514
[Epoch 5, Batch 1700] loss: 0.173073014523834
[Epoch 5, Batch 1800] loss: 0.19485147162340583
[Epoch 5, Batch 1900] loss: 0.17528197650797664
[Epoch 5, Batch 2000] loss: 0.16344055372290314
[Epoch 5, Batch 2100] loss: 0.15567770367488265
[Epoch 5, Batch 2200] loss: 0.1695634207688272
[Epoch 5, Batch 2300] loss: 0.17692984195426106
[Epoch 5, Batch 2400] loss: 0.15729091393761338
[Epoch 5, Batch 2500] loss: 0.18331989225000142
[Epoch 5, Batch 2600] loss: 0.17136569736525417
[Epoch 5, Batch 2700] loss: 0.14774285034276546
[Epoch 5, Batch 2800] loss: 0.13381767695304006
[Epoch 5, Batch 2900] loss: 0.16502738330047578
[Epoch 5, Batch 3000] loss: 0.15619799871463327
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1410
Validation Accuracy: 0.9578
Overfitting: 0.1410
Best model saved at epoch 5 with validation loss: 0.1410
[Epoch 6, Batch 100] loss: 0.15634274061769246
[Epoch 6, Batch 200] loss: 0.13927739981561899
[Epoch 6, Batch 300] loss: 0.18499146427959204
[Epoch 6, Batch 400] loss: 0.1337926568137482
[Epoch 6, Batch 500] loss: 0.16254349544644356
[Epoch 6, Batch 600] loss: 0.13403463368304075
[Epoch 6, Batch 700] loss: 0.18014202982652933
[Epoch 6, Batch 800] loss: 0.15994210494682193
[Epoch 6, Batch 900] loss: 0.14820901651401072
[Epoch 6, Batch 1000] loss: 0.14233635973185302
[Epoch 6, Batch 1100] loss: 0.14038019187981263
[Epoch 6, Batch 1200] loss: 0.1562523864535615
[Epoch 6, Batch 1300] loss: 0.13915340787731112
[Epoch 6, Batch 1400] loss: 0.13780198836699128
[Epoch 6, Batch 1500] loss: 0.14336955684702843
[Epoch 6, Batch 1600] loss: 0.1285404648189433
[Epoch 6, Batch 1700] loss: 0.14831322117242962
[Epoch 6, Batch 1800] loss: 0.12244425512850285
[Epoch 6, Batch 1900] loss: 0.17699461988173426
[Epoch 6, Batch 2000] loss: 0.1366624361090362
[Epoch 6, Batch 2100] loss: 0.18848784688394515
[Epoch 6, Batch 2200] loss: 0.18189620139077306
[Epoch 6, Batch 2300] loss: 0.14350094542838632
[Epoch 6, Batch 2400] loss: 0.12844076727516948
[Epoch 6, Batch 2500] loss: 0.1348655227199197
[Epoch 6, Batch 2600] loss: 0.12511147705838085
[Epoch 6, Batch 2700] loss: 0.13818180677480996
[Epoch 6, Batch 2800] loss: 0.11781619066838175
[Epoch 6, Batch 2900] loss: 0.1519193369941786
[Epoch 6, Batch 3000] loss: 0.14685299597680568
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.1203
Validation Accuracy: 0.9653
Overfitting: 0.1203
[I 2024-12-11 03:17:04,127] Trial 5 pruned. 

Selected Hyperparameters for Trial 7:
  l1: 256, l2: 128, lr: 0.002439578684743188, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2833504843711854
[Epoch 1, Batch 200] loss: 1.8599033099412918
[Epoch 1, Batch 300] loss: 0.6622356832027435
[Epoch 1, Batch 400] loss: 0.4475628753006458
[Epoch 1, Batch 500] loss: 0.35083838254213334
[Epoch 1, Batch 600] loss: 0.2990068892389536
[Epoch 1, Batch 700] loss: 0.25215882278978824
**STATS for Epoch 1** : 
Average training loss: 0.0171
Average validation loss: 0.2536
Validation Accuracy: 0.9163
Overfitting: 0.2365
Best model saved at epoch 1 with validation loss: 0.2536
[Epoch 2, Batch 100] loss: 0.21372166708111762
[Epoch 2, Batch 200] loss: 0.18670536413788796
[Epoch 2, Batch 300] loss: 0.1666793731600046
[Epoch 2, Batch 400] loss: 0.15684386257082225
[Epoch 2, Batch 500] loss: 0.152035488858819
[Epoch 2, Batch 600] loss: 0.12713264228776097
[Epoch 2, Batch 700] loss: 0.12740974923595785
**STATS for Epoch 2** : 
Average training loss: 0.0070
Average validation loss: 0.1007
Validation Accuracy: 0.9681
Overfitting: 0.0937
Best model saved at epoch 2 with validation loss: 0.1007
[Epoch 3, Batch 100] loss: 0.10915417938493192
[Epoch 3, Batch 200] loss: 0.10017994625493884
[Epoch 3, Batch 300] loss: 0.10040722226724029
[Epoch 3, Batch 400] loss: 0.09436572616919875
[Epoch 3, Batch 500] loss: 0.10510705955326557
[Epoch 3, Batch 600] loss: 0.0863662622589618
[Epoch 3, Batch 700] loss: 0.08511823322158307
**STATS for Epoch 3** : 
Average training loss: 0.0043
Average validation loss: 0.0840
Validation Accuracy: 0.9723
Overfitting: 0.0796
Best model saved at epoch 3 with validation loss: 0.0840
[Epoch 4, Batch 100] loss: 0.07570804462768138
[Epoch 4, Batch 200] loss: 0.07851113978773355
[Epoch 4, Batch 300] loss: 0.07093336086720228
[Epoch 4, Batch 400] loss: 0.06087709580548108
[Epoch 4, Batch 500] loss: 0.07149763124063611
[Epoch 4, Batch 600] loss: 0.07195033669471741
[Epoch 4, Batch 700] loss: 0.06964141985867173
**STATS for Epoch 4** : 
Average training loss: 0.0046
Average validation loss: 0.0650
Validation Accuracy: 0.9789
Overfitting: 0.0604
Best model saved at epoch 4 with validation loss: 0.0650
[Epoch 5, Batch 100] loss: 0.059856137461028996
[Epoch 5, Batch 200] loss: 0.05618227545171976
[Epoch 5, Batch 300] loss: 0.06547343729063869
[Epoch 5, Batch 400] loss: 0.05893289251253009
[Epoch 5, Batch 500] loss: 0.06296271214727313
[Epoch 5, Batch 600] loss: 0.04844144215108827
[Epoch 5, Batch 700] loss: 0.0585729858558625
**STATS for Epoch 5** : 
Average training loss: 0.0037
Average validation loss: 0.0649
Validation Accuracy: 0.9782
Overfitting: 0.0611
Best model saved at epoch 5 with validation loss: 0.0649
[Epoch 6, Batch 100] loss: 0.041666672732681036
[Epoch 6, Batch 200] loss: 0.05452322357334197
[Epoch 6, Batch 300] loss: 0.04467191929463297
[Epoch 6, Batch 400] loss: 0.05029204387450591
[Epoch 6, Batch 500] loss: 0.05076898708939552
[Epoch 6, Batch 600] loss: 0.047384293577633796
[Epoch 6, Batch 700] loss: 0.0532181156007573
**STATS for Epoch 6** : 
Average training loss: 0.0030
Average validation loss: 0.0578
Validation Accuracy: 0.9816
Overfitting: 0.0547
Best model saved at epoch 6 with validation loss: 0.0578
[Epoch 7, Batch 100] loss: 0.041947279633022846
[Epoch 7, Batch 200] loss: 0.04228894597617909
[Epoch 7, Batch 300] loss: 0.048819839057978244
[Epoch 7, Batch 400] loss: 0.03705036255996674
[Epoch 7, Batch 500] loss: 0.04204794422490522
[Epoch 7, Batch 600] loss: 0.04068048703484237
[Epoch 7, Batch 700] loss: 0.04156950944568962
**STATS for Epoch 7** : 
Average training loss: 0.0029
Average validation loss: 0.0501
Validation Accuracy: 0.9844
Overfitting: 0.0472
Best model saved at epoch 7 with validation loss: 0.0501
[Epoch 8, Batch 100] loss: 0.03732912055915222
[Epoch 8, Batch 200] loss: 0.03174713266664184
[Epoch 8, Batch 300] loss: 0.03296905759721994
[Epoch 8, Batch 400] loss: 0.039651596522890034
[Epoch 8, Batch 500] loss: 0.04558884494472295
[Epoch 8, Batch 600] loss: 0.03262941307504661
[Epoch 8, Batch 700] loss: 0.03565435317170341
**STATS for Epoch 8** : 
Average training loss: 0.0025
Average validation loss: 0.0512
Validation Accuracy: 0.9835
Overfitting: 0.0487
[Epoch 9, Batch 100] loss: 0.030267794652609155
[Epoch 9, Batch 200] loss: 0.03670207501971163
[Epoch 9, Batch 300] loss: 0.030085060459095984
[Epoch 9, Batch 400] loss: 0.023613599318778142
[Epoch 9, Batch 500] loss: 0.04098709261161275
[Epoch 9, Batch 600] loss: 0.035041739011649045
[Epoch 9, Batch 700] loss: 0.02754173456458375
**STATS for Epoch 9** : 
Average training loss: 0.0021
Average validation loss: 0.0416
Validation Accuracy: 0.9875
Overfitting: 0.0396
Best model saved at epoch 9 with validation loss: 0.0416
[Epoch 10, Batch 100] loss: 0.024905370101332664
[Epoch 10, Batch 200] loss: 0.035605952370679005
[Epoch 10, Batch 300] loss: 0.02667201097588986
[Epoch 10, Batch 400] loss: 0.022032491835998372
[Epoch 10, Batch 500] loss: 0.027861193885328248
[Epoch 10, Batch 600] loss: 0.030698700366774575
[Epoch 10, Batch 700] loss: 0.02909281860862393
**STATS for Epoch 10** : 
Average training loss: 0.0018
Average validation loss: 0.0470
Validation Accuracy: 0.9850
Overfitting: 0.0451
[Epoch 11, Batch 100] loss: 0.023920115864020774
[Epoch 11, Batch 200] loss: 0.02300522326841019
[Epoch 11, Batch 300] loss: 0.021823838989948854
[Epoch 11, Batch 400] loss: 0.026913720725569874
[Epoch 11, Batch 500] loss: 0.02329875305178575
[Epoch 11, Batch 600] loss: 0.023825920532108285
[Epoch 11, Batch 700] loss: 0.024374631633982062
**STATS for Epoch 11** : 
Average training loss: 0.0015
Average validation loss: 0.0482
Validation Accuracy: 0.9846
Overfitting: 0.0466
[Epoch 12, Batch 100] loss: 0.01772460305597633
[Epoch 12, Batch 200] loss: 0.01947801379719749
[Epoch 12, Batch 300] loss: 0.01726365641647135
[Epoch 12, Batch 400] loss: 0.021631132217589766
[Epoch 12, Batch 500] loss: 0.03072822661488317
[Epoch 12, Batch 600] loss: 0.021516521298908627
[Epoch 12, Batch 700] loss: 0.023963012239837555
**STATS for Epoch 12** : 
Average training loss: 0.0014
Average validation loss: 0.0440
Validation Accuracy: 0.9862
Overfitting: 0.0426
[Epoch 13, Batch 100] loss: 0.020461420280626044
[Epoch 13, Batch 200] loss: 0.023440383044071495
[Epoch 13, Batch 300] loss: 0.01671540566952899
[Epoch 13, Batch 400] loss: 0.0151885231398046
[Epoch 13, Batch 500] loss: 0.019411380813107827
[Epoch 13, Batch 600] loss: 0.01919133876770502
[Epoch 13, Batch 700] loss: 0.016990790708805433
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0445
Validation Accuracy: 0.9868
Overfitting: 0.0431
[Epoch 14, Batch 100] loss: 0.017134347895625977
[Epoch 14, Batch 200] loss: 0.023926846809335985
[Epoch 14, Batch 300] loss: 0.012399842533050105
[Epoch 14, Batch 400] loss: 0.01595302019850351
[Epoch 14, Batch 500] loss: 0.017661478858208284
[Epoch 14, Batch 600] loss: 0.020083538354665507
[Epoch 14, Batch 700] loss: 0.020024114386178554
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0394
Validation Accuracy: 0.9883
Overfitting: 0.0385
Best model saved at epoch 14 with validation loss: 0.0394
[Epoch 15, Batch 100] loss: 0.013322464771044906
[Epoch 15, Batch 200] loss: 0.01211854362511076
[Epoch 15, Batch 300] loss: 0.012944025970209622
[Epoch 15, Batch 400] loss: 0.019246665145037697
[Epoch 15, Batch 500] loss: 0.01676266299909912
[Epoch 15, Batch 600] loss: 0.014126314451859799
[Epoch 15, Batch 700] loss: 0.014575331565138185
**STATS for Epoch 15** : 
Average training loss: 0.0011
Average validation loss: 0.0394
Validation Accuracy: 0.9884
Overfitting: 0.0382
Best model saved at epoch 15 with validation loss: 0.0394
[Epoch 16, Batch 100] loss: 0.015736152726167348
[Epoch 16, Batch 200] loss: 0.013080729743815028
[Epoch 16, Batch 300] loss: 0.011034907010616735
[Epoch 16, Batch 400] loss: 0.011875213238454307
[Epoch 16, Batch 500] loss: 0.012647417818952818
[Epoch 16, Batch 600] loss: 0.014257916021306301
[Epoch 16, Batch 700] loss: 0.011083948811829033
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0445
Validation Accuracy: 0.9873
Overfitting: 0.0435
[Epoch 17, Batch 100] loss: 0.012583188626740594
[Epoch 17, Batch 200] loss: 0.010817947093310068
[Epoch 17, Batch 300] loss: 0.01043039442942245
[Epoch 17, Batch 400] loss: 0.008933652953710408
[Epoch 17, Batch 500] loss: 0.012305402379715814
[Epoch 17, Batch 600] loss: 0.015740051890024916
[Epoch 17, Batch 700] loss: 0.016079410610545894
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0396
Validation Accuracy: 0.9891
Overfitting: 0.0389
[Epoch 18, Batch 100] loss: 0.013126282808661927
[Epoch 18, Batch 200] loss: 0.011290668645815459
[Epoch 18, Batch 300] loss: 0.010062484869849867
[Epoch 18, Batch 400] loss: 0.010580289945319237
[Epoch 18, Batch 500] loss: 0.011503691476827954
[Epoch 18, Batch 600] loss: 0.011204581536803744
[Epoch 18, Batch 700] loss: 0.009835951959248633
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0420
Validation Accuracy: 0.9881
Overfitting: 0.0413
[Epoch 19, Batch 100] loss: 0.011831490167387528
[Epoch 19, Batch 200] loss: 0.009037199561716988
[Epoch 19, Batch 300] loss: 0.011976957260339987
[Epoch 19, Batch 400] loss: 0.011497478925302857
[Epoch 19, Batch 500] loss: 0.00874670343051548
[Epoch 19, Batch 600] loss: 0.009498825585324085
[Epoch 19, Batch 700] loss: 0.006787520590878557
**STATS for Epoch 19** : 
Average training loss: 0.0009
Average validation loss: 0.0587
Validation Accuracy: 0.9831
Overfitting: 0.0577
[Epoch 20, Batch 100] loss: 0.007128446343413089
[Epoch 20, Batch 200] loss: 0.00895936649365467
[Epoch 20, Batch 300] loss: 0.007188252716478018
[Epoch 20, Batch 400] loss: 0.007725898351054639
[Epoch 20, Batch 500] loss: 0.00970327471222845
[Epoch 20, Batch 600] loss: 0.013031481921789236
[Epoch 20, Batch 700] loss: 0.013059893996542086
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0391
Validation Accuracy: 0.9887
Overfitting: 0.0386
Best model saved at epoch 20 with validation loss: 0.0391
[Epoch 21, Batch 100] loss: 0.010751879348099465
[Epoch 21, Batch 200] loss: 0.00617519336330588
[Epoch 21, Batch 300] loss: 0.006229024024250975
[Epoch 21, Batch 400] loss: 0.00584806289512926
[Epoch 21, Batch 500] loss: 0.004420170932135079
[Epoch 21, Batch 600] loss: 0.00789237334542122
[Epoch 21, Batch 700] loss: 0.0069544435471470935
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0449
Validation Accuracy: 0.9877
Overfitting: 0.0444
[Epoch 22, Batch 100] loss: 0.00862981126687373
[Epoch 22, Batch 200] loss: 0.004561727252221317
[Epoch 22, Batch 300] loss: 0.0047349346843839155
[Epoch 22, Batch 400] loss: 0.0052958637000483574
[Epoch 22, Batch 500] loss: 0.007520343807300378
[Epoch 22, Batch 600] loss: 0.008066202011214045
[Epoch 22, Batch 700] loss: 0.006857867504586466
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0444
Validation Accuracy: 0.9882
Overfitting: 0.0441
[Epoch 23, Batch 100] loss: 0.00742752027217648
[Epoch 23, Batch 200] loss: 0.004844055010580633
[Epoch 23, Batch 300] loss: 0.00349458238844818
[Epoch 23, Batch 400] loss: 0.006076922399588511
[Epoch 23, Batch 500] loss: 0.003899570766079705
[Epoch 23, Batch 600] loss: 0.005811097468977095
[Epoch 23, Batch 700] loss: 0.006398489213825087
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0381
Validation Accuracy: 0.9896
Overfitting: 0.0374
Best model saved at epoch 23 with validation loss: 0.0381
[Epoch 24, Batch 100] loss: 0.006872260363161331
[Epoch 24, Batch 200] loss: 0.00446443818973421
[Epoch 24, Batch 300] loss: 0.004120418116563087
[Epoch 24, Batch 400] loss: 0.006646837620428414
[Epoch 24, Batch 500] loss: 0.004970163135731127
[Epoch 24, Batch 600] loss: 0.004189292908049538
[Epoch 24, Batch 700] loss: 0.006519126473858705
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0412
Validation Accuracy: 0.9890
Overfitting: 0.0409
Fold 1 validation loss: 0.0412
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.230522582530975
[Epoch 1, Batch 200] loss: 1.1149777036905288
[Epoch 1, Batch 300] loss: 0.5052447637915611
[Epoch 1, Batch 400] loss: 0.37651891574263574
[Epoch 1, Batch 500] loss: 0.3016600877791643
[Epoch 1, Batch 600] loss: 0.24035031318664551
[Epoch 1, Batch 700] loss: 0.2082327576726675
**STATS for Epoch 1** : 
Average training loss: 0.0133
Average validation loss: 0.2114
Validation Accuracy: 0.9326
Overfitting: 0.1981
Best model saved at epoch 1 with validation loss: 0.2114
[Epoch 2, Batch 100] loss: 0.16679729275405408
[Epoch 2, Batch 200] loss: 0.1394412281177938
[Epoch 2, Batch 300] loss: 0.15804984968155622
[Epoch 2, Batch 400] loss: 0.138419857788831
[Epoch 2, Batch 500] loss: 0.11899499481543899
[Epoch 2, Batch 600] loss: 0.11089193161576986
[Epoch 2, Batch 700] loss: 0.11635178389027714
**STATS for Epoch 2** : 
Average training loss: 0.0069
Average validation loss: 0.1158
Validation Accuracy: 0.9645
Overfitting: 0.1089
Best model saved at epoch 2 with validation loss: 0.1158
[Epoch 3, Batch 100] loss: 0.10323309168219566
[Epoch 3, Batch 200] loss: 0.10246971029788256
[Epoch 3, Batch 300] loss: 0.08663225950673223
[Epoch 3, Batch 400] loss: 0.07812458454631269
[Epoch 3, Batch 500] loss: 0.08459578145295382
[Epoch 3, Batch 600] loss: 0.08367860185913742
[Epoch 3, Batch 700] loss: 0.07216546793468297
**STATS for Epoch 3** : 
Average training loss: 0.0046
Average validation loss: 0.0816
Validation Accuracy: 0.9746
Overfitting: 0.0771
Best model saved at epoch 3 with validation loss: 0.0816
[Epoch 4, Batch 100] loss: 0.06438364444300532
[Epoch 4, Batch 200] loss: 0.06257178345229476
[Epoch 4, Batch 300] loss: 0.0737879827618599
[Epoch 4, Batch 400] loss: 0.07071517931297422
[Epoch 4, Batch 500] loss: 0.06711545298341662
[Epoch 4, Batch 600] loss: 0.06054869711399078
[Epoch 4, Batch 700] loss: 0.0627291193883866
**STATS for Epoch 4** : 
Average training loss: 0.0039
Average validation loss: 0.0716
Validation Accuracy: 0.9782
Overfitting: 0.0677
Best model saved at epoch 4 with validation loss: 0.0716
[Epoch 5, Batch 100] loss: 0.053987022866494955
[Epoch 5, Batch 200] loss: 0.05216067322064191
[Epoch 5, Batch 300] loss: 0.04963669152231887
[Epoch 5, Batch 400] loss: 0.05345055152894929
[Epoch 5, Batch 500] loss: 0.05750972807873041
[Epoch 5, Batch 600] loss: 0.06307909514755011
[Epoch 5, Batch 700] loss: 0.047667076145298776
**STATS for Epoch 5** : 
Average training loss: 0.0031
Average validation loss: 0.0654
Validation Accuracy: 0.9794
Overfitting: 0.0623
Best model saved at epoch 5 with validation loss: 0.0654
[Epoch 6, Batch 100] loss: 0.05063628913718276
[Epoch 6, Batch 200] loss: 0.048156125989044084
[Epoch 6, Batch 300] loss: 0.04872297082329169
[Epoch 6, Batch 400] loss: 0.05042032251600176
[Epoch 6, Batch 500] loss: 0.04554414002690464
[Epoch 6, Batch 600] loss: 0.04285302538890392
[Epoch 6, Batch 700] loss: 0.04052689618431032
**STATS for Epoch 6** : 
Average training loss: 0.0030
Average validation loss: 0.0567
Validation Accuracy: 0.9826
Overfitting: 0.0537
Best model saved at epoch 6 with validation loss: 0.0567
[Epoch 7, Batch 100] loss: 0.041619443241506814
[Epoch 7, Batch 200] loss: 0.03531299750437029
[Epoch 7, Batch 300] loss: 0.04273362311301753
[Epoch 7, Batch 400] loss: 0.036132506190333515
[Epoch 7, Batch 500] loss: 0.03697597218793817
[Epoch 7, Batch 600] loss: 0.0442680819449015
[Epoch 7, Batch 700] loss: 0.04540747153339907
**STATS for Epoch 7** : 
Average training loss: 0.0025
Average validation loss: 0.0514
Validation Accuracy: 0.9835
Overfitting: 0.0489
Best model saved at epoch 7 with validation loss: 0.0514
[Epoch 8, Batch 100] loss: 0.037297498569823805
[Epoch 8, Batch 200] loss: 0.032649035601643846
[Epoch 8, Batch 300] loss: 0.032426521435845644
[Epoch 8, Batch 400] loss: 0.04309299309970811
[Epoch 8, Batch 500] loss: 0.032221217188052834
[Epoch 8, Batch 600] loss: 0.038367726856376974
[Epoch 8, Batch 700] loss: 0.030419276014436038
**STATS for Epoch 8** : 
Average training loss: 0.0026
Average validation loss: 0.0574
Validation Accuracy: 0.9821
Overfitting: 0.0548
[Epoch 9, Batch 100] loss: 0.027614599427906797
[Epoch 9, Batch 200] loss: 0.0338301310595125
[Epoch 9, Batch 300] loss: 0.03132799053331837
[Epoch 9, Batch 400] loss: 0.03311856183805503
[Epoch 9, Batch 500] loss: 0.026975435408821795
[Epoch 9, Batch 600] loss: 0.03112175022775773
[Epoch 9, Batch 700] loss: 0.033751342806499454
**STATS for Epoch 9** : 
Average training loss: 0.0024
Average validation loss: 0.0528
Validation Accuracy: 0.9851
Overfitting: 0.0504
[Epoch 10, Batch 100] loss: 0.026380139127140864
[Epoch 10, Batch 200] loss: 0.02577441377856303
[Epoch 10, Batch 300] loss: 0.025132887184154244
[Epoch 10, Batch 400] loss: 0.031672905441373585
[Epoch 10, Batch 500] loss: 0.027778343884274363
[Epoch 10, Batch 600] loss: 0.018601096023921855
[Epoch 10, Batch 700] loss: 0.029376120390370488
**STATS for Epoch 10** : 
Average training loss: 0.0019
Average validation loss: 0.0581
Validation Accuracy: 0.9832
Overfitting: 0.0562
[Epoch 11, Batch 100] loss: 0.022359853716334328
[Epoch 11, Batch 200] loss: 0.028362352313415613
[Epoch 11, Batch 300] loss: 0.024694710860494525
[Epoch 11, Batch 400] loss: 0.019390570311807097
[Epoch 11, Batch 500] loss: 0.02594197618076578
[Epoch 11, Batch 600] loss: 0.026373789997305722
[Epoch 11, Batch 700] loss: 0.029542940446408466
**STATS for Epoch 11** : 
Average training loss: 0.0014
Average validation loss: 0.0483
Validation Accuracy: 0.9860
Overfitting: 0.0469
Best model saved at epoch 11 with validation loss: 0.0483
[Epoch 12, Batch 100] loss: 0.023339755017659627
[Epoch 12, Batch 200] loss: 0.017868571272701958
[Epoch 12, Batch 300] loss: 0.026255448498995974
[Epoch 12, Batch 400] loss: 0.02033865024743136
[Epoch 12, Batch 500] loss: 0.01990748421230819
[Epoch 12, Batch 600] loss: 0.022225924512604252
[Epoch 12, Batch 700] loss: 0.02139125671586953
**STATS for Epoch 12** : 
Average training loss: 0.0014
Average validation loss: 0.0530
Validation Accuracy: 0.9852
Overfitting: 0.0516
[Epoch 13, Batch 100] loss: 0.016051261739048642
[Epoch 13, Batch 200] loss: 0.020485821636975744
[Epoch 13, Batch 300] loss: 0.018271022681728935
[Epoch 13, Batch 400] loss: 0.022504520447400863
[Epoch 13, Batch 500] loss: 0.021992235086800066
[Epoch 13, Batch 600] loss: 0.01672266155394027
[Epoch 13, Batch 700] loss: 0.015387979885563254
**STATS for Epoch 13** : 
Average training loss: 0.0016
Average validation loss: 0.0537
Validation Accuracy: 0.9847
Overfitting: 0.0521
[Epoch 14, Batch 100] loss: 0.015754641052044462
[Epoch 14, Batch 200] loss: 0.01891186940425541
[Epoch 14, Batch 300] loss: 0.014180026242975145
[Epoch 14, Batch 400] loss: 0.015864653984317557
[Epoch 14, Batch 500] loss: 0.01759742295223987
[Epoch 14, Batch 600] loss: 0.019556360989517997
[Epoch 14, Batch 700] loss: 0.02080010287812911
**STATS for Epoch 14** : 
Average training loss: 0.0016
Average validation loss: 0.0463
Validation Accuracy: 0.9876
Overfitting: 0.0448
Best model saved at epoch 14 with validation loss: 0.0463
[Epoch 15, Batch 100] loss: 0.015048752277652965
[Epoch 15, Batch 200] loss: 0.01011979669739958
[Epoch 15, Batch 300] loss: 0.019228864966571564
[Epoch 15, Batch 400] loss: 0.01712609517853707
[Epoch 15, Batch 500] loss: 0.01722771581778943
[Epoch 15, Batch 600] loss: 0.014526306613261113
[Epoch 15, Batch 700] loss: 0.017405903430335455
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0529
Validation Accuracy: 0.9852
Overfitting: 0.0520
[Epoch 16, Batch 100] loss: 0.012213842639466748
[Epoch 16, Batch 200] loss: 0.01027411858405685
[Epoch 16, Batch 300] loss: 0.010218927334062756
[Epoch 16, Batch 400] loss: 0.010384163923445157
[Epoch 16, Batch 500] loss: 0.017478709180722946
[Epoch 16, Batch 600] loss: 0.010156451742368518
[Epoch 16, Batch 700] loss: 0.01599428832443664
**STATS for Epoch 16** : 
Average training loss: 0.0012
Average validation loss: 0.0512
Validation Accuracy: 0.9866
Overfitting: 0.0500
[Epoch 17, Batch 100] loss: 0.011265705894766142
[Epoch 17, Batch 200] loss: 0.011084343035327038
[Epoch 17, Batch 300] loss: 0.008555812749254982
[Epoch 17, Batch 400] loss: 0.015852201902598607
[Epoch 17, Batch 500] loss: 0.010568162189010764
[Epoch 17, Batch 600] loss: 0.014956544766537263
[Epoch 17, Batch 700] loss: 0.012215178550759447
**STATS for Epoch 17** : 
Average training loss: 0.0010
Average validation loss: 0.0605
Validation Accuracy: 0.9838
Overfitting: 0.0595
[Epoch 18, Batch 100] loss: 0.009582867843855638
[Epoch 18, Batch 200] loss: 0.014515594460171997
[Epoch 18, Batch 300] loss: 0.01446966545889154
[Epoch 18, Batch 400] loss: 0.010691154286905657
[Epoch 18, Batch 500] loss: 0.009442657034960576
[Epoch 18, Batch 600] loss: 0.009832113890151959
[Epoch 18, Batch 700] loss: 0.008409518557309639
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0610
Validation Accuracy: 0.9854
Overfitting: 0.0602
[Epoch 19, Batch 100] loss: 0.012399185326576117
[Epoch 19, Batch 200] loss: 0.006995139046484838
[Epoch 19, Batch 300] loss: 0.00735092221715604
[Epoch 19, Batch 400] loss: 0.010963097334461054
[Epoch 19, Batch 500] loss: 0.011137493725691457
[Epoch 19, Batch 600] loss: 0.009300294518179725
[Epoch 19, Batch 700] loss: 0.011676672235917068
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0556
Validation Accuracy: 0.9852
Overfitting: 0.0549
[Epoch 20, Batch 100] loss: 0.006669722885126248
[Epoch 20, Batch 200] loss: 0.00743813429340662
[Epoch 20, Batch 300] loss: 0.007128334912922582
[Epoch 20, Batch 400] loss: 0.009579167884912749
[Epoch 20, Batch 500] loss: 0.0071158052949613195
[Epoch 20, Batch 600] loss: 0.006831936330308963
[Epoch 20, Batch 700] loss: 0.012078526676195906
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0518
Validation Accuracy: 0.9870
Overfitting: 0.0513
[Epoch 21, Batch 100] loss: 0.006279767378291581
[Epoch 21, Batch 200] loss: 0.007081122879390023
[Epoch 21, Batch 300] loss: 0.008958377431918052
[Epoch 21, Batch 400] loss: 0.006867467075535387
[Epoch 21, Batch 500] loss: 0.006619063446851215
[Epoch 21, Batch 600] loss: 0.009137620966357644
[Epoch 21, Batch 700] loss: 0.006131068787180993
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0503
Validation Accuracy: 0.9878
Overfitting: 0.0499
[Epoch 22, Batch 100] loss: 0.006636408305494115
[Epoch 22, Batch 200] loss: 0.003720773723543971
[Epoch 22, Batch 300] loss: 0.0030837359413635568
[Epoch 22, Batch 400] loss: 0.0055995722838270015
[Epoch 22, Batch 500] loss: 0.01018113254554919
[Epoch 22, Batch 600] loss: 0.00732765869164723
[Epoch 22, Batch 700] loss: 0.0063563342232191644
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0512
Validation Accuracy: 0.9868
Overfitting: 0.0508
[Epoch 23, Batch 100] loss: 0.0046015990894375134
[Epoch 23, Batch 200] loss: 0.007216663235203669
[Epoch 23, Batch 300] loss: 0.006731353319219124
[Epoch 23, Batch 400] loss: 0.004458409486578603
[Epoch 23, Batch 500] loss: 0.004859557022646186
[Epoch 23, Batch 600] loss: 0.0053000712411630955
[Epoch 23, Batch 700] loss: 0.007335718356334837
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0525
Validation Accuracy: 0.9882
Overfitting: 0.0520
[Epoch 24, Batch 100] loss: 0.00810176416998729
[Epoch 24, Batch 200] loss: 0.00509225306512235
[Epoch 24, Batch 300] loss: 0.005544598314154428
[Epoch 24, Batch 400] loss: 0.005749252131499816
[Epoch 24, Batch 500] loss: 0.0061978696349979144
[Epoch 24, Batch 600] loss: 0.006941706035504467
[Epoch 24, Batch 700] loss: 0.007202658746427915
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0532
Validation Accuracy: 0.9870
Overfitting: 0.0527
Fold 2 validation loss: 0.0532
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2379800057411194
[Epoch 1, Batch 200] loss: 1.0485722935199737
[Epoch 1, Batch 300] loss: 0.45464506596326826
[Epoch 1, Batch 400] loss: 0.3469586420059204
[Epoch 1, Batch 500] loss: 0.2932206230610609
[Epoch 1, Batch 600] loss: 0.2310888618975878
[Epoch 1, Batch 700] loss: 0.20075534269213677
**STATS for Epoch 1** : 
Average training loss: 0.0135
Average validation loss: 0.1775
Validation Accuracy: 0.9443
Overfitting: 0.1640
Best model saved at epoch 1 with validation loss: 0.1775
[Epoch 2, Batch 100] loss: 0.1721039516851306
[Epoch 2, Batch 200] loss: 0.16519494220614434
[Epoch 2, Batch 300] loss: 0.14251291036605834
[Epoch 2, Batch 400] loss: 0.12645936181768774
[Epoch 2, Batch 500] loss: 0.1296827530860901
[Epoch 2, Batch 600] loss: 0.12333264887332916
[Epoch 2, Batch 700] loss: 0.10940323051065207
**STATS for Epoch 2** : 
Average training loss: 0.0069
Average validation loss: 0.1127
Validation Accuracy: 0.9656
Overfitting: 0.1058
Best model saved at epoch 2 with validation loss: 0.1127
[Epoch 3, Batch 100] loss: 0.0953197355568409
[Epoch 3, Batch 200] loss: 0.09882889883592724
[Epoch 3, Batch 300] loss: 0.09103829129599035
[Epoch 3, Batch 400] loss: 0.08872625146061182
[Epoch 3, Batch 500] loss: 0.0831143079418689
[Epoch 3, Batch 600] loss: 0.08374616567045451
[Epoch 3, Batch 700] loss: 0.0821095491759479
**STATS for Epoch 3** : 
Average training loss: 0.0062
Average validation loss: 0.0930
Validation Accuracy: 0.9709
Overfitting: 0.0868
Best model saved at epoch 3 with validation loss: 0.0930
[Epoch 4, Batch 100] loss: 0.07206999917514623
[Epoch 4, Batch 200] loss: 0.07588617101311684
[Epoch 4, Batch 300] loss: 0.0647853425052017
[Epoch 4, Batch 400] loss: 0.06525478302501142
[Epoch 4, Batch 500] loss: 0.0713487864844501
[Epoch 4, Batch 600] loss: 0.07237532410770654
[Epoch 4, Batch 700] loss: 0.06646995517890901
**STATS for Epoch 4** : 
Average training loss: 0.0039
Average validation loss: 0.0714
Validation Accuracy: 0.9785
Overfitting: 0.0675
Best model saved at epoch 4 with validation loss: 0.0714
[Epoch 5, Batch 100] loss: 0.05701375178527087
[Epoch 5, Batch 200] loss: 0.061872935090214014
[Epoch 5, Batch 300] loss: 0.05680654108058661
[Epoch 5, Batch 400] loss: 0.06434891842305661
[Epoch 5, Batch 500] loss: 0.04826811080798507
[Epoch 5, Batch 600] loss: 0.06037433923687786
[Epoch 5, Batch 700] loss: 0.05723759929649532
**STATS for Epoch 5** : 
Average training loss: 0.0045
Average validation loss: 0.0706
Validation Accuracy: 0.9792
Overfitting: 0.0661
Best model saved at epoch 5 with validation loss: 0.0706
[Epoch 6, Batch 100] loss: 0.048625242230482396
[Epoch 6, Batch 200] loss: 0.0485872465884313
[Epoch 6, Batch 300] loss: 0.05080993935465813
[Epoch 6, Batch 400] loss: 0.05435582970269024
[Epoch 6, Batch 500] loss: 0.043149105990305546
[Epoch 6, Batch 600] loss: 0.05159190897014923
[Epoch 6, Batch 700] loss: 0.045038230023346844
**STATS for Epoch 6** : 
Average training loss: 0.0035
Average validation loss: 0.0665
Validation Accuracy: 0.9802
Overfitting: 0.0630
Best model saved at epoch 6 with validation loss: 0.0665
[Epoch 7, Batch 100] loss: 0.044606540116947146
[Epoch 7, Batch 200] loss: 0.04193898823810741
[Epoch 7, Batch 300] loss: 0.03240338262170553
[Epoch 7, Batch 400] loss: 0.033525382552761586
[Epoch 7, Batch 500] loss: 0.045986593002453446
[Epoch 7, Batch 600] loss: 0.044233194682747126
[Epoch 7, Batch 700] loss: 0.04655433393199928
**STATS for Epoch 7** : 
Average training loss: 0.0027
Average validation loss: 0.0574
Validation Accuracy: 0.9830
Overfitting: 0.0547
Best model saved at epoch 7 with validation loss: 0.0574
[Epoch 8, Batch 100] loss: 0.032247828878462316
[Epoch 8, Batch 200] loss: 0.03608624460524879
[Epoch 8, Batch 300] loss: 0.0409463799232617
[Epoch 8, Batch 400] loss: 0.03836853523505852
[Epoch 8, Batch 500] loss: 0.03256857307860628
[Epoch 8, Batch 600] loss: 0.038556170964147894
[Epoch 8, Batch 700] loss: 0.04188257757341489
**STATS for Epoch 8** : 
Average training loss: 0.0023
Average validation loss: 0.0540
Validation Accuracy: 0.9838
Overfitting: 0.0517
Best model saved at epoch 8 with validation loss: 0.0540
[Epoch 9, Batch 100] loss: 0.03196014731307514
[Epoch 9, Batch 200] loss: 0.03508575834799558
[Epoch 9, Batch 300] loss: 0.03864040338085033
[Epoch 9, Batch 400] loss: 0.02878611381922383
[Epoch 9, Batch 500] loss: 0.029607540846336634
[Epoch 9, Batch 600] loss: 0.027245581842726095
[Epoch 9, Batch 700] loss: 0.03191936112707481
**STATS for Epoch 9** : 
Average training loss: 0.0019
Average validation loss: 0.0496
Validation Accuracy: 0.9851
Overfitting: 0.0477
Best model saved at epoch 9 with validation loss: 0.0496
[Epoch 10, Batch 100] loss: 0.02358438399154693
[Epoch 10, Batch 200] loss: 0.024089449218590745
[Epoch 10, Batch 300] loss: 0.027954183695837857
[Epoch 10, Batch 400] loss: 0.03265008306247182
[Epoch 10, Batch 500] loss: 0.027407510971534065
[Epoch 10, Batch 600] loss: 0.022506118193268775
[Epoch 10, Batch 700] loss: 0.03170864925108617
**STATS for Epoch 10** : 
Average training loss: 0.0023
Average validation loss: 0.0482
Validation Accuracy: 0.9864
Overfitting: 0.0459
Best model saved at epoch 10 with validation loss: 0.0482
[Epoch 11, Batch 100] loss: 0.022307145777740515
[Epoch 11, Batch 200] loss: 0.024507834411924705
[Epoch 11, Batch 300] loss: 0.021584254343179055
[Epoch 11, Batch 400] loss: 0.02536690596549306
[Epoch 11, Batch 500] loss: 0.02065056452760473
[Epoch 11, Batch 600] loss: 0.031112834856612606
[Epoch 11, Batch 700] loss: 0.02919402434490621
**STATS for Epoch 11** : 
Average training loss: 0.0019
Average validation loss: 0.0471
Validation Accuracy: 0.9868
Overfitting: 0.0452
Best model saved at epoch 11 with validation loss: 0.0471
[Epoch 12, Batch 100] loss: 0.02056036291352939
[Epoch 12, Batch 200] loss: 0.02351079145912081
[Epoch 12, Batch 300] loss: 0.018628074094594924
[Epoch 12, Batch 400] loss: 0.024842226778855548
[Epoch 12, Batch 500] loss: 0.020557337830541655
[Epoch 12, Batch 600] loss: 0.026347803902463055
[Epoch 12, Batch 700] loss: 0.020221025128266776
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0479
Validation Accuracy: 0.9860
Overfitting: 0.0466
[Epoch 13, Batch 100] loss: 0.017103219804994296
[Epoch 13, Batch 200] loss: 0.019542608449992258
[Epoch 13, Batch 300] loss: 0.020203287244949023
[Epoch 13, Batch 400] loss: 0.0177533644187497
[Epoch 13, Batch 500] loss: 0.017975639860960655
[Epoch 13, Batch 600] loss: 0.019898491735802964
[Epoch 13, Batch 700] loss: 0.021565708928974345
**STATS for Epoch 13** : 
Average training loss: 0.0013
Average validation loss: 0.0469
Validation Accuracy: 0.9871
Overfitting: 0.0456
Best model saved at epoch 13 with validation loss: 0.0469
[Epoch 14, Batch 100] loss: 0.012166159929693094
[Epoch 14, Batch 200] loss: 0.014662844550330192
[Epoch 14, Batch 300] loss: 0.018266801590216347
[Epoch 14, Batch 400] loss: 0.019181140403961763
[Epoch 14, Batch 500] loss: 0.018297003043990116
[Epoch 14, Batch 600] loss: 0.01666912093263818
[Epoch 14, Batch 700] loss: 0.01826366496650735
**STATS for Epoch 14** : 
Average training loss: 0.0013
Average validation loss: 0.0465
Validation Accuracy: 0.9871
Overfitting: 0.0452
Best model saved at epoch 14 with validation loss: 0.0465
[Epoch 15, Batch 100] loss: 0.011661045181681403
[Epoch 15, Batch 200] loss: 0.010124692671233788
[Epoch 15, Batch 300] loss: 0.011876503047824371
[Epoch 15, Batch 400] loss: 0.01846072100903257
[Epoch 15, Batch 500] loss: 0.014020941971539287
[Epoch 15, Batch 600] loss: 0.015885829265607755
[Epoch 15, Batch 700] loss: 0.014392287580121774
**STATS for Epoch 15** : 
Average training loss: 0.0017
Average validation loss: 0.0484
Validation Accuracy: 0.9860
Overfitting: 0.0466
[Epoch 16, Batch 100] loss: 0.010921267274825367
[Epoch 16, Batch 200] loss: 0.010800001072348096
[Epoch 16, Batch 300] loss: 0.011654984407650773
[Epoch 16, Batch 400] loss: 0.01450267698528478
[Epoch 16, Batch 500] loss: 0.014078289638855495
[Epoch 16, Batch 600] loss: 0.015687056569731794
[Epoch 16, Batch 700] loss: 0.013691974737303098
**STATS for Epoch 16** : 
Average training loss: 0.0013
Average validation loss: 0.0659
Validation Accuracy: 0.9824
Overfitting: 0.0645
[Epoch 17, Batch 100] loss: 0.00974805216465029
[Epoch 17, Batch 200] loss: 0.011873319524456747
[Epoch 17, Batch 300] loss: 0.008730861547228415
[Epoch 17, Batch 400] loss: 0.013192781905236189
[Epoch 17, Batch 500] loss: 0.011157941699784714
[Epoch 17, Batch 600] loss: 0.012868399615035742
[Epoch 17, Batch 700] loss: 0.01650534803207847
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0520
Validation Accuracy: 0.9863
Overfitting: 0.0512
[Epoch 18, Batch 100] loss: 0.011142129337531514
[Epoch 18, Batch 200] loss: 0.006676902324252296
[Epoch 18, Batch 300] loss: 0.009438939079336706
[Epoch 18, Batch 400] loss: 0.009692078429070534
[Epoch 18, Batch 500] loss: 0.010740587311593117
[Epoch 18, Batch 600] loss: 0.009210509532495052
[Epoch 18, Batch 700] loss: 0.0101422761046706
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0546
Validation Accuracy: 0.9862
Overfitting: 0.0538
[Epoch 19, Batch 100] loss: 0.010022316876493277
[Epoch 19, Batch 200] loss: 0.009510436315467814
[Epoch 19, Batch 300] loss: 0.00999530724624492
[Epoch 19, Batch 400] loss: 0.005997533940026187
[Epoch 19, Batch 500] loss: 0.010347244332369882
[Epoch 19, Batch 600] loss: 0.011154069077892927
[Epoch 19, Batch 700] loss: 0.012045097877416993
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0594
Validation Accuracy: 0.9848
Overfitting: 0.0587
[Epoch 20, Batch 100] loss: 0.0073668982926028545
[Epoch 20, Batch 200] loss: 0.006771374471718446
[Epoch 20, Batch 300] loss: 0.007610417594405589
[Epoch 20, Batch 400] loss: 0.007842736725579016
[Epoch 20, Batch 500] loss: 0.008406410945171956
[Epoch 20, Batch 600] loss: 0.008425538519077236
[Epoch 20, Batch 700] loss: 0.007692701804844546
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0537
Validation Accuracy: 0.9872
Overfitting: 0.0526
[Epoch 21, Batch 100] loss: 0.005663867846669746
[Epoch 21, Batch 200] loss: 0.005394937257187848
[Epoch 21, Batch 300] loss: 0.0072235614355304276
[Epoch 21, Batch 400] loss: 0.007525113642186625
[Epoch 21, Batch 500] loss: 0.004059509545040783
[Epoch 21, Batch 600] loss: 0.006087264872767264
[Epoch 21, Batch 700] loss: 0.0053760635817889126
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0574
Validation Accuracy: 0.9864
Overfitting: 0.0567
[Epoch 22, Batch 100] loss: 0.005050168718134955
[Epoch 22, Batch 200] loss: 0.0061137270035032994
[Epoch 22, Batch 300] loss: 0.004893627135643328
[Epoch 22, Batch 400] loss: 0.006716407849453389
[Epoch 22, Batch 500] loss: 0.009340390819706954
[Epoch 22, Batch 600] loss: 0.009567007602090599
[Epoch 22, Batch 700] loss: 0.006242843541513139
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0524
Validation Accuracy: 0.9880
Overfitting: 0.0519
[Epoch 23, Batch 100] loss: 0.0059536322347412355
[Epoch 23, Batch 200] loss: 0.003918488898816577
[Epoch 23, Batch 300] loss: 0.006295058228806738
[Epoch 23, Batch 400] loss: 0.006281672299955972
[Epoch 23, Batch 500] loss: 0.004805678814918792
[Epoch 23, Batch 600] loss: 0.004780991686457128
[Epoch 23, Batch 700] loss: 0.006826386785687646
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0551
Validation Accuracy: 0.9868
Overfitting: 0.0548
[Epoch 24, Batch 100] loss: 0.002310137702297652
[Epoch 24, Batch 200] loss: 0.0033912586377118715
[Epoch 24, Batch 300] loss: 0.004702884330763482
[Epoch 24, Batch 400] loss: 0.005586787155916682
[Epoch 24, Batch 500] loss: 0.003617207062234229
[Epoch 24, Batch 600] loss: 0.0034511684812241583
[Epoch 24, Batch 700] loss: 0.004505414828963694
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0579
Validation Accuracy: 0.9875
Overfitting: 0.0575
Fold 3 validation loss: 0.0579
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.272234864234924
[Epoch 1, Batch 200] loss: 1.4663101443648339
[Epoch 1, Batch 300] loss: 0.486503526866436
[Epoch 1, Batch 400] loss: 0.35314598336815833
[Epoch 1, Batch 500] loss: 0.2965581913292408
[Epoch 1, Batch 600] loss: 0.22357417605817317
[Epoch 1, Batch 700] loss: 0.17825792249292136
**STATS for Epoch 1** : 
Average training loss: 0.0114
Average validation loss: 0.1660
Validation Accuracy: 0.9473
Overfitting: 0.1546
Best model saved at epoch 1 with validation loss: 0.1660
[Epoch 2, Batch 100] loss: 0.16095839831978082
[Epoch 2, Batch 200] loss: 0.13902743570506573
[Epoch 2, Batch 300] loss: 0.13431515015661716
[Epoch 2, Batch 400] loss: 0.14088713201694192
[Epoch 2, Batch 500] loss: 0.1238981917500496
[Epoch 2, Batch 600] loss: 0.10613246841356158
[Epoch 2, Batch 700] loss: 0.11150761805474758
**STATS for Epoch 2** : 
Average training loss: 0.0084
Average validation loss: 0.1198
Validation Accuracy: 0.9613
Overfitting: 0.1114
Best model saved at epoch 2 with validation loss: 0.1198
[Epoch 3, Batch 100] loss: 0.09362877434119582
[Epoch 3, Batch 200] loss: 0.09119070537388324
[Epoch 3, Batch 300] loss: 0.08396073329262435
[Epoch 3, Batch 400] loss: 0.10240179868414997
[Epoch 3, Batch 500] loss: 0.08451168211176992
[Epoch 3, Batch 600] loss: 0.07919423365965486
[Epoch 3, Batch 700] loss: 0.09042427719570696
**STATS for Epoch 3** : 
Average training loss: 0.0059
Average validation loss: 0.0751
Validation Accuracy: 0.9766
Overfitting: 0.0692
Best model saved at epoch 3 with validation loss: 0.0751
[Epoch 4, Batch 100] loss: 0.07307204862125218
[Epoch 4, Batch 200] loss: 0.06247723049018532
[Epoch 4, Batch 300] loss: 0.07840272404719144
[Epoch 4, Batch 400] loss: 0.07649054596666247
[Epoch 4, Batch 500] loss: 0.06432539901230484
[Epoch 4, Batch 600] loss: 0.073763019843027
[Epoch 4, Batch 700] loss: 0.07908704075496643
**STATS for Epoch 4** : 
Average training loss: 0.0044
Average validation loss: 0.0792
Validation Accuracy: 0.9755
Overfitting: 0.0748
[Epoch 5, Batch 100] loss: 0.0682622255035676
[Epoch 5, Batch 200] loss: 0.05494348641019314
[Epoch 5, Batch 300] loss: 0.06795089828781783
[Epoch 5, Batch 400] loss: 0.061015818547457454
[Epoch 5, Batch 500] loss: 0.06045412687584758
[Epoch 5, Batch 600] loss: 0.06308358639013022
[Epoch 5, Batch 700] loss: 0.058603688878938555
**STATS for Epoch 5** : 
Average training loss: 0.0039
Average validation loss: 0.0674
Validation Accuracy: 0.9788
Overfitting: 0.0635
Best model saved at epoch 5 with validation loss: 0.0674
[Epoch 6, Batch 100] loss: 0.05007424361072481
[Epoch 6, Batch 200] loss: 0.045961369562428446
[Epoch 6, Batch 300] loss: 0.05227406172314659
[Epoch 6, Batch 400] loss: 0.05564213467761874
[Epoch 6, Batch 500] loss: 0.04866697421530262
[Epoch 6, Batch 600] loss: 0.05976744162850082
[Epoch 6, Batch 700] loss: 0.053812398854643104
**STATS for Epoch 6** : 
Average training loss: 0.0035
Average validation loss: 0.0605
Validation Accuracy: 0.9797
Overfitting: 0.0570
Best model saved at epoch 6 with validation loss: 0.0605
[Epoch 7, Batch 100] loss: 0.03797160847578198
[Epoch 7, Batch 200] loss: 0.05141409418080002
[Epoch 7, Batch 300] loss: 0.04303558791987598
[Epoch 7, Batch 400] loss: 0.04361246022512205
[Epoch 7, Batch 500] loss: 0.042953353999182584
[Epoch 7, Batch 600] loss: 0.04294801243115216
[Epoch 7, Batch 700] loss: 0.053891575674060735
**STATS for Epoch 7** : 
Average training loss: 0.0027
Average validation loss: 0.0543
Validation Accuracy: 0.9835
Overfitting: 0.0517
Best model saved at epoch 7 with validation loss: 0.0543
[Epoch 8, Batch 100] loss: 0.03814051298424601
[Epoch 8, Batch 200] loss: 0.03198412418947555
[Epoch 8, Batch 300] loss: 0.04067814321373589
[Epoch 8, Batch 400] loss: 0.03768275867099874
[Epoch 8, Batch 500] loss: 0.041114376381738114
[Epoch 8, Batch 600] loss: 0.037896133405156435
[Epoch 8, Batch 700] loss: 0.04233543145237491
**STATS for Epoch 8** : 
Average training loss: 0.0025
Average validation loss: 0.0463
Validation Accuracy: 0.9854
Overfitting: 0.0439
Best model saved at epoch 8 with validation loss: 0.0463
[Epoch 9, Batch 100] loss: 0.027406360022723675
[Epoch 9, Batch 200] loss: 0.03449684652267024
[Epoch 9, Batch 300] loss: 0.04283228097949177
[Epoch 9, Batch 400] loss: 0.03811814736109227
[Epoch 9, Batch 500] loss: 0.032938071753596886
[Epoch 9, Batch 600] loss: 0.035368777511175724
[Epoch 9, Batch 700] loss: 0.03294698131037876
**STATS for Epoch 9** : 
Average training loss: 0.0021
Average validation loss: 0.0655
Validation Accuracy: 0.9798
Overfitting: 0.0634
[Epoch 10, Batch 100] loss: 0.03755725516937673
[Epoch 10, Batch 200] loss: 0.02813748461077921
[Epoch 10, Batch 300] loss: 0.024352614482631908
[Epoch 10, Batch 400] loss: 0.029997303177951837
[Epoch 10, Batch 500] loss: 0.03351079531596042
[Epoch 10, Batch 600] loss: 0.03654791403445415
[Epoch 10, Batch 700] loss: 0.027301191790029405
**STATS for Epoch 10** : 
Average training loss: 0.0018
Average validation loss: 0.0504
Validation Accuracy: 0.9838
Overfitting: 0.0486
[Epoch 11, Batch 100] loss: 0.02975529803079553
[Epoch 11, Batch 200] loss: 0.02662850372842513
[Epoch 11, Batch 300] loss: 0.023453477266884876
[Epoch 11, Batch 400] loss: 0.028511789876502006
[Epoch 11, Batch 500] loss: 0.02695018518366851
[Epoch 11, Batch 600] loss: 0.02783729456947185
[Epoch 11, Batch 700] loss: 0.032934818878420626
**STATS for Epoch 11** : 
Average training loss: 0.0013
Average validation loss: 0.0422
Validation Accuracy: 0.9866
Overfitting: 0.0409
Best model saved at epoch 11 with validation loss: 0.0422
[Epoch 12, Batch 100] loss: 0.0292226827389095
[Epoch 12, Batch 200] loss: 0.023854235648177565
[Epoch 12, Batch 300] loss: 0.022841122445533983
[Epoch 12, Batch 400] loss: 0.02385730072390288
[Epoch 12, Batch 500] loss: 0.020504493955522774
[Epoch 12, Batch 600] loss: 0.023298549292376264
[Epoch 12, Batch 700] loss: 0.025113831559428944
**STATS for Epoch 12** : 
Average training loss: 0.0016
Average validation loss: 0.0493
Validation Accuracy: 0.9857
Overfitting: 0.0477
[Epoch 13, Batch 100] loss: 0.01822745064739138
[Epoch 13, Batch 200] loss: 0.020570346518652513
[Epoch 13, Batch 300] loss: 0.01979008221416734
[Epoch 13, Batch 400] loss: 0.021665496331406756
[Epoch 13, Batch 500] loss: 0.02497794590657577
[Epoch 13, Batch 600] loss: 0.026161716736387463
[Epoch 13, Batch 700] loss: 0.02783474884694442
**STATS for Epoch 13** : 
Average training loss: 0.0015
Average validation loss: 0.0401
Validation Accuracy: 0.9875
Overfitting: 0.0386
Best model saved at epoch 13 with validation loss: 0.0401
[Epoch 14, Batch 100] loss: 0.016006267658085563
[Epoch 14, Batch 200] loss: 0.018534988192259336
[Epoch 14, Batch 300] loss: 0.01798737548844656
[Epoch 14, Batch 400] loss: 0.021907454393513034
[Epoch 14, Batch 500] loss: 0.024025125599000604
[Epoch 14, Batch 600] loss: 0.017522534996678586
[Epoch 14, Batch 700] loss: 0.021994088062783704
**STATS for Epoch 14** : 
Average training loss: 0.0019
Average validation loss: 0.0513
Validation Accuracy: 0.9835
Overfitting: 0.0494
[Epoch 15, Batch 100] loss: 0.013723400403105188
[Epoch 15, Batch 200] loss: 0.016478770390967838
[Epoch 15, Batch 300] loss: 0.013483780388778541
[Epoch 15, Batch 400] loss: 0.01756484333978733
[Epoch 15, Batch 500] loss: 0.019733410603657832
[Epoch 15, Batch 600] loss: 0.025863726384122855
[Epoch 15, Batch 700] loss: 0.018522992362559308
**STATS for Epoch 15** : 
Average training loss: 0.0013
Average validation loss: 0.0435
Validation Accuracy: 0.9876
Overfitting: 0.0421
[Epoch 16, Batch 100] loss: 0.01331312188616721
[Epoch 16, Batch 200] loss: 0.011625222393631703
[Epoch 16, Batch 300] loss: 0.012344282253470737
[Epoch 16, Batch 400] loss: 0.017001323646109085
[Epoch 16, Batch 500] loss: 0.018289546289597638
[Epoch 16, Batch 600] loss: 0.016732211435592035
[Epoch 16, Batch 700] loss: 0.013944256459508324
**STATS for Epoch 16** : 
Average training loss: 0.0012
Average validation loss: 0.0456
Validation Accuracy: 0.9856
Overfitting: 0.0444
[Epoch 17, Batch 100] loss: 0.008463097239873605
[Epoch 17, Batch 200] loss: 0.009852330624271417
[Epoch 17, Batch 300] loss: 0.015080838263238548
[Epoch 17, Batch 400] loss: 0.014073493399191648
[Epoch 17, Batch 500] loss: 0.013675226982122694
[Epoch 17, Batch 600] loss: 0.01235811893187929
[Epoch 17, Batch 700] loss: 0.016717326265134034
**STATS for Epoch 17** : 
Average training loss: 0.0014
Average validation loss: 0.0437
Validation Accuracy: 0.9866
Overfitting: 0.0423
[Epoch 18, Batch 100] loss: 0.01286852027347777
[Epoch 18, Batch 200] loss: 0.011269612240430433
[Epoch 18, Batch 300] loss: 0.015303655181487557
[Epoch 18, Batch 400] loss: 0.012871358367410721
[Epoch 18, Batch 500] loss: 0.01372870490711648
[Epoch 18, Batch 600] loss: 0.009393023051961791
[Epoch 18, Batch 700] loss: 0.013005230161070358
**STATS for Epoch 18** : 
Average training loss: 0.0012
Average validation loss: 0.0446
Validation Accuracy: 0.9871
Overfitting: 0.0434
[Epoch 19, Batch 100] loss: 0.011407216514635365
[Epoch 19, Batch 200] loss: 0.009086574170360108
[Epoch 19, Batch 300] loss: 0.011158137962629553
[Epoch 19, Batch 400] loss: 0.010895676768923295
[Epoch 19, Batch 500] loss: 0.011384385945639224
[Epoch 19, Batch 600] loss: 0.01137017775530694
[Epoch 19, Batch 700] loss: 0.013154724806954619
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0421
Validation Accuracy: 0.9872
Overfitting: 0.0415
[Epoch 20, Batch 100] loss: 0.006841853181249462
[Epoch 20, Batch 200] loss: 0.010192695366713451
[Epoch 20, Batch 300] loss: 0.007496776586631313
[Epoch 20, Batch 400] loss: 0.00927299700982985
[Epoch 20, Batch 500] loss: 0.0068288424346246756
[Epoch 20, Batch 600] loss: 0.010005374384927563
[Epoch 20, Batch 700] loss: 0.011201602874643867
**STATS for Epoch 20** : 
Average training loss: 0.0008
Average validation loss: 0.0529
Validation Accuracy: 0.9842
Overfitting: 0.0521
[Epoch 21, Batch 100] loss: 0.008064336742390878
[Epoch 21, Batch 200] loss: 0.0068828517184738305
[Epoch 21, Batch 300] loss: 0.007523509417951573
[Epoch 21, Batch 400] loss: 0.009359067744080676
[Epoch 21, Batch 500] loss: 0.012105651368547115
[Epoch 21, Batch 600] loss: 0.010705167871055892
[Epoch 21, Batch 700] loss: 0.008977427715290105
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0440
Validation Accuracy: 0.9870
Overfitting: 0.0434
[Epoch 22, Batch 100] loss: 0.0063114458841300805
[Epoch 22, Batch 200] loss: 0.00710510067481664
[Epoch 22, Batch 300] loss: 0.008204785978305153
[Epoch 22, Batch 400] loss: 0.011786354379946715
[Epoch 22, Batch 500] loss: 0.006108925114531303
[Epoch 22, Batch 600] loss: 0.0069880512469535465
[Epoch 22, Batch 700] loss: 0.010063050503231353
**STATS for Epoch 22** : 
Average training loss: 0.0007
Average validation loss: 0.0484
Validation Accuracy: 0.9873
Overfitting: 0.0477
[Epoch 23, Batch 100] loss: 0.008082885741241625
[Epoch 23, Batch 200] loss: 0.006972771185683086
[Epoch 23, Batch 300] loss: 0.0065409324316715355
[Epoch 23, Batch 400] loss: 0.005553777917266416
[Epoch 23, Batch 500] loss: 0.004721772551711183
[Epoch 23, Batch 600] loss: 0.007573185654400731
[Epoch 23, Batch 700] loss: 0.006301092625872116
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0450
Validation Accuracy: 0.9868
Overfitting: 0.0444
[Epoch 24, Batch 100] loss: 0.0037092311917513144
[Epoch 24, Batch 200] loss: 0.004320674233895261
[Epoch 24, Batch 300] loss: 0.004284396982620819
[Epoch 24, Batch 400] loss: 0.006557613945551566
[Epoch 24, Batch 500] loss: 0.009603170342561498
[Epoch 24, Batch 600] loss: 0.0075713413896301065
[Epoch 24, Batch 700] loss: 0.0107460499404624
**STATS for Epoch 24** : 
Average training loss: 0.0006
Average validation loss: 0.0481
Validation Accuracy: 0.9872
Overfitting: 0.0475
Fold 4 validation loss: 0.0481
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.224793770313263
[Epoch 1, Batch 200] loss: 1.0309582808613778
[Epoch 1, Batch 300] loss: 0.43851050853729245
[Epoch 1, Batch 400] loss: 0.3351000836491585
[Epoch 1, Batch 500] loss: 0.2555685019493103
[Epoch 1, Batch 600] loss: 0.23292705401778221
[Epoch 1, Batch 700] loss: 0.20931631207466125
**STATS for Epoch 1** : 
Average training loss: 0.0134
Average validation loss: 0.1835
Validation Accuracy: 0.9443
Overfitting: 0.1701
Best model saved at epoch 1 with validation loss: 0.1835
[Epoch 2, Batch 100] loss: 0.14857936050742865
[Epoch 2, Batch 200] loss: 0.1497162360884249
[Epoch 2, Batch 300] loss: 0.1478981429338455
[Epoch 2, Batch 400] loss: 0.13397405698895454
[Epoch 2, Batch 500] loss: 0.12049845485016704
[Epoch 2, Batch 600] loss: 0.11550461359322071
[Epoch 2, Batch 700] loss: 0.1145579986460507
**STATS for Epoch 2** : 
Average training loss: 0.0063
Average validation loss: 0.1049
Validation Accuracy: 0.9674
Overfitting: 0.0986
Best model saved at epoch 2 with validation loss: 0.1049
[Epoch 3, Batch 100] loss: 0.10062244888395071
[Epoch 3, Batch 200] loss: 0.10447576069273054
[Epoch 3, Batch 300] loss: 0.09582966143265366
[Epoch 3, Batch 400] loss: 0.0838972130510956
[Epoch 3, Batch 500] loss: 0.08490652163978667
[Epoch 3, Batch 600] loss: 0.0789374725613743
[Epoch 3, Batch 700] loss: 0.07926997162401676
**STATS for Epoch 3** : 
Average training loss: 0.0047
Average validation loss: 0.0931
Validation Accuracy: 0.9715
Overfitting: 0.0884
Best model saved at epoch 3 with validation loss: 0.0931
[Epoch 4, Batch 100] loss: 0.07364574631210416
[Epoch 4, Batch 200] loss: 0.06353201038204133
[Epoch 4, Batch 300] loss: 0.0624691508570686
[Epoch 4, Batch 400] loss: 0.07603972196113318
[Epoch 4, Batch 500] loss: 0.06556254159193486
[Epoch 4, Batch 600] loss: 0.06101248373510316
[Epoch 4, Batch 700] loss: 0.07002772673498839
**STATS for Epoch 4** : 
Average training loss: 0.0049
Average validation loss: 0.0648
Validation Accuracy: 0.9796
Overfitting: 0.0599
Best model saved at epoch 4 with validation loss: 0.0648
[Epoch 5, Batch 100] loss: 0.05956367190927267
[Epoch 5, Batch 200] loss: 0.06100158613640815
[Epoch 5, Batch 300] loss: 0.060540142324753105
[Epoch 5, Batch 400] loss: 0.0560899524949491
[Epoch 5, Batch 500] loss: 0.05086410048184917
[Epoch 5, Batch 600] loss: 0.05068909659399651
[Epoch 5, Batch 700] loss: 0.04669399162754417
**STATS for Epoch 5** : 
Average training loss: 0.0045
Average validation loss: 0.0626
Validation Accuracy: 0.9808
Overfitting: 0.0581
Best model saved at epoch 5 with validation loss: 0.0626
[Epoch 6, Batch 100] loss: 0.054137553074397146
[Epoch 6, Batch 200] loss: 0.047216996741481124
[Epoch 6, Batch 300] loss: 0.046248643572907894
[Epoch 6, Batch 400] loss: 0.04623324541607872
[Epoch 6, Batch 500] loss: 0.041728380280546845
[Epoch 6, Batch 600] loss: 0.046040414673043414
[Epoch 6, Batch 700] loss: 0.047027846784330904
**STATS for Epoch 6** : 
Average training loss: 0.0033
Average validation loss: 0.0496
Validation Accuracy: 0.9832
Overfitting: 0.0463
Best model saved at epoch 6 with validation loss: 0.0496
[Epoch 7, Batch 100] loss: 0.03926904157968238
[Epoch 7, Batch 200] loss: 0.04321726101974491
[Epoch 7, Batch 300] loss: 0.04064162054797635
[Epoch 7, Batch 400] loss: 0.04027933841920458
[Epoch 7, Batch 500] loss: 0.04224485458340496
[Epoch 7, Batch 600] loss: 0.03624911846127361
[Epoch 7, Batch 700] loss: 0.046612042168853805
**STATS for Epoch 7** : 
Average training loss: 0.0034
Average validation loss: 0.0578
Validation Accuracy: 0.9821
Overfitting: 0.0545
[Epoch 8, Batch 100] loss: 0.03963742411928251
[Epoch 8, Batch 200] loss: 0.030940978681319394
[Epoch 8, Batch 300] loss: 0.03880189202725887
[Epoch 8, Batch 400] loss: 0.0348053075268399
[Epoch 8, Batch 500] loss: 0.03788679705932736
[Epoch 8, Batch 600] loss: 0.028509000620106237
[Epoch 8, Batch 700] loss: 0.041275213488261214
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0476
Validation Accuracy: 0.9850
Overfitting: 0.0452
Best model saved at epoch 8 with validation loss: 0.0476
[Epoch 9, Batch 100] loss: 0.028486721241497436
[Epoch 9, Batch 200] loss: 0.0379222418559948
[Epoch 9, Batch 300] loss: 0.0340912977908738
[Epoch 9, Batch 400] loss: 0.034254681820748374
[Epoch 9, Batch 500] loss: 0.03648949678987265
[Epoch 9, Batch 600] loss: 0.03426810434786603
[Epoch 9, Batch 700] loss: 0.027531430971575902
**STATS for Epoch 9** : 
Average training loss: 0.0021
Average validation loss: 0.0473
Validation Accuracy: 0.9861
Overfitting: 0.0452
Best model saved at epoch 9 with validation loss: 0.0473
[Epoch 10, Batch 100] loss: 0.031930600613122806
[Epoch 10, Batch 200] loss: 0.02746668051695451
[Epoch 10, Batch 300] loss: 0.02936999243684113
[Epoch 10, Batch 400] loss: 0.024129570880904793
[Epoch 10, Batch 500] loss: 0.02941593630006537
[Epoch 10, Batch 600] loss: 0.029363269639434295
[Epoch 10, Batch 700] loss: 0.028585549391573296
**STATS for Epoch 10** : 
Average training loss: 0.0019
Average validation loss: 0.0461
Validation Accuracy: 0.9862
Overfitting: 0.0442
Best model saved at epoch 10 with validation loss: 0.0461
[Epoch 11, Batch 100] loss: 0.026473427268792874
[Epoch 11, Batch 200] loss: 0.02491890452685766
[Epoch 11, Batch 300] loss: 0.029050775782670825
[Epoch 11, Batch 400] loss: 0.026808578784693962
[Epoch 11, Batch 500] loss: 0.024578526591067202
[Epoch 11, Batch 600] loss: 0.017893407301453407
[Epoch 11, Batch 700] loss: 0.026073719345149585
**STATS for Epoch 11** : 
Average training loss: 0.0015
Average validation loss: 0.0434
Validation Accuracy: 0.9866
Overfitting: 0.0419
Best model saved at epoch 11 with validation loss: 0.0434
[Epoch 12, Batch 100] loss: 0.020021599172614514
[Epoch 12, Batch 200] loss: 0.020086066706571728
[Epoch 12, Batch 300] loss: 0.025554577470757067
[Epoch 12, Batch 400] loss: 0.024611477497965096
[Epoch 12, Batch 500] loss: 0.027062411407823676
[Epoch 12, Batch 600] loss: 0.023921658683684656
[Epoch 12, Batch 700] loss: 0.019232630282640457
**STATS for Epoch 12** : 
Average training loss: 0.0014
Average validation loss: 0.0405
Validation Accuracy: 0.9874
Overfitting: 0.0391
Best model saved at epoch 12 with validation loss: 0.0405
[Epoch 13, Batch 100] loss: 0.019139378549298272
[Epoch 13, Batch 200] loss: 0.016688897525600623
[Epoch 13, Batch 300] loss: 0.018063268731348215
[Epoch 13, Batch 400] loss: 0.02422320371872047
[Epoch 13, Batch 500] loss: 0.024629540636087768
[Epoch 13, Batch 600] loss: 0.022468719959433656
[Epoch 13, Batch 700] loss: 0.02118381984939333
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0488
Validation Accuracy: 0.9851
Overfitting: 0.0473
[Epoch 14, Batch 100] loss: 0.018044122918217907
[Epoch 14, Batch 200] loss: 0.0203065984492423
[Epoch 14, Batch 300] loss: 0.013368648201285395
[Epoch 14, Batch 400] loss: 0.017912221853912343
[Epoch 14, Batch 500] loss: 0.02134049085812876
[Epoch 14, Batch 600] loss: 0.02046372088836506
[Epoch 14, Batch 700] loss: 0.021163810155703688
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0456
Validation Accuracy: 0.9868
Overfitting: 0.0444
[Epoch 15, Batch 100] loss: 0.016866041317698546
[Epoch 15, Batch 200] loss: 0.01873611026618164
[Epoch 15, Batch 300] loss: 0.018474882169539342
[Epoch 15, Batch 400] loss: 0.01833901968668215
[Epoch 15, Batch 500] loss: 0.01111377487104619
[Epoch 15, Batch 600] loss: 0.01949485502409516
[Epoch 15, Batch 700] loss: 0.012596485063259024
**STATS for Epoch 15** : 
Average training loss: 0.0012
Average validation loss: 0.0481
Validation Accuracy: 0.9867
Overfitting: 0.0469
[Epoch 16, Batch 100] loss: 0.014416411064448766
[Epoch 16, Batch 200] loss: 0.010315552926040255
[Epoch 16, Batch 300] loss: 0.01021235785621684
[Epoch 16, Batch 400] loss: 0.017443605410226156
[Epoch 16, Batch 500] loss: 0.013316936595365404
[Epoch 16, Batch 600] loss: 0.018499785066087498
[Epoch 16, Batch 700] loss: 0.016653699835005684
**STATS for Epoch 16** : 
Average training loss: 0.0011
Average validation loss: 0.0459
Validation Accuracy: 0.9865
Overfitting: 0.0447
[Epoch 17, Batch 100] loss: 0.01116591593803605
[Epoch 17, Batch 200] loss: 0.012957010619575158
[Epoch 17, Batch 300] loss: 0.012740350820240564
[Epoch 17, Batch 400] loss: 0.013751183656859211
[Epoch 17, Batch 500] loss: 0.013438819586008321
[Epoch 17, Batch 600] loss: 0.010983209254336544
[Epoch 17, Batch 700] loss: 0.012411500121015707
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0443
Validation Accuracy: 0.9872
Overfitting: 0.0437
[Epoch 18, Batch 100] loss: 0.008540162885765312
[Epoch 18, Batch 200] loss: 0.009910827709536534
[Epoch 18, Batch 300] loss: 0.01304783491345006
[Epoch 18, Batch 400] loss: 0.014147139782144222
[Epoch 18, Batch 500] loss: 0.016046343376219737
[Epoch 18, Batch 600] loss: 0.00905403106517042
[Epoch 18, Batch 700] loss: 0.01426998129900312
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0458
Validation Accuracy: 0.9872
Overfitting: 0.0451
[Epoch 19, Batch 100] loss: 0.008561098700447474
[Epoch 19, Batch 200] loss: 0.00869001911036321
[Epoch 19, Batch 300] loss: 0.009312271957605844
[Epoch 19, Batch 400] loss: 0.013225790750584564
[Epoch 19, Batch 500] loss: 0.007486291706736665
[Epoch 19, Batch 600] loss: 0.010065445952204755
[Epoch 19, Batch 700] loss: 0.01056458562881744
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0446
Validation Accuracy: 0.9885
Overfitting: 0.0438
[Epoch 20, Batch 100] loss: 0.007432695407769643
[Epoch 20, Batch 200] loss: 0.009989604235670413
[Epoch 20, Batch 300] loss: 0.008226930205055397
[Epoch 20, Batch 400] loss: 0.01001126171744545
[Epoch 20, Batch 500] loss: 0.007982724556641188
[Epoch 20, Batch 600] loss: 0.006408961500092118
[Epoch 20, Batch 700] loss: 0.00794416477670893
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0435
Validation Accuracy: 0.9894
Overfitting: 0.0429
[Epoch 21, Batch 100] loss: 0.004798119397601113
[Epoch 21, Batch 200] loss: 0.005658467010143795
[Epoch 21, Batch 300] loss: 0.006750186203134945
[Epoch 21, Batch 400] loss: 0.012892310181996436
[Epoch 21, Batch 500] loss: 0.005930703556732624
[Epoch 21, Batch 600] loss: 0.006717675823601894
[Epoch 21, Batch 700] loss: 0.008561215436202474
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0443
Validation Accuracy: 0.9892
Overfitting: 0.0438
[Epoch 22, Batch 100] loss: 0.0064688251315965315
[Epoch 22, Batch 200] loss: 0.0057974739042401776
[Epoch 22, Batch 300] loss: 0.0073067120630003046
[Epoch 22, Batch 400] loss: 0.007544585595533135
[Epoch 22, Batch 500] loss: 0.007463836166571127
[Epoch 22, Batch 600] loss: 0.00730944726812595
[Epoch 22, Batch 700] loss: 0.005916346847661771
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0425
Validation Accuracy: 0.9882
Overfitting: 0.0422
[Epoch 23, Batch 100] loss: 0.005373994593392126
[Epoch 23, Batch 200] loss: 0.004780673633522383
[Epoch 23, Batch 300] loss: 0.008757295116374735
[Epoch 23, Batch 400] loss: 0.006408445641609433
[Epoch 23, Batch 500] loss: 0.004070642136030074
[Epoch 23, Batch 600] loss: 0.005557618463249128
[Epoch 23, Batch 700] loss: 0.00558192387688905
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0496
Validation Accuracy: 0.9873
Overfitting: 0.0491
[Epoch 24, Batch 100] loss: 0.004822683984339164
[Epoch 24, Batch 200] loss: 0.006086786639389175
[Epoch 24, Batch 300] loss: 0.003062708180223126
[Epoch 24, Batch 400] loss: 0.004154927634226624
[Epoch 24, Batch 500] loss: 0.008671802973549348
[Epoch 24, Batch 600] loss: 0.00487710911402246
[Epoch 24, Batch 700] loss: 0.0031365669842853094
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0438
Validation Accuracy: 0.9882
Overfitting: 0.0433
Fold 5 validation loss: 0.0438
Mean validation loss across all folds for Trial 7 is 0.0488 with trial config:  l1: 256, l2: 128, lr: 0.002439578684743188, batch_size: 64
[I 2024-12-11 03:37:12,872] Trial 6 finished with value: 0.04883194716786091 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.002439578684743188, 'batch_size': 64}. Best is trial 4 with value: 0.046929042829858846.

Selected Hyperparameters for Trial 8:
  l1: 256, l2: 128, lr: 0.0006380434077440606, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.285627536773682
**STATS for Epoch 1** : 
Average training loss: 1.0493
Average validation loss: 2.2096
Validation Accuracy: 0.3902
Overfitting: 1.1603
Best model saved at epoch 1 with validation loss: 2.2096
[Epoch 2, Batch 100] loss: 2.1332282543182375
**STATS for Epoch 2** : 
Average training loss: 0.8148
Average validation loss: 1.3548
Validation Accuracy: 0.7078
Overfitting: 0.5400
Best model saved at epoch 2 with validation loss: 1.3548
[Epoch 3, Batch 100] loss: 0.9538306111097336
**STATS for Epoch 3** : 
Average training loss: 0.2780
Average validation loss: 0.5112
Validation Accuracy: 0.8508
Overfitting: 0.2332
Best model saved at epoch 3 with validation loss: 0.5112
[Epoch 4, Batch 100] loss: 0.4793810099363327
**STATS for Epoch 4** : 
Average training loss: 0.1984
Average validation loss: 0.3771
Validation Accuracy: 0.8878
Overfitting: 0.1786
Best model saved at epoch 4 with validation loss: 0.3771
[Epoch 5, Batch 100] loss: 0.3783832034468651
**STATS for Epoch 5** : 
Average training loss: 0.1602
Average validation loss: 0.3146
Validation Accuracy: 0.9070
Overfitting: 0.1544
Best model saved at epoch 5 with validation loss: 0.3146
[Epoch 6, Batch 100] loss: 0.3109380626678467
**STATS for Epoch 6** : 
Average training loss: 0.1404
Average validation loss: 0.2811
Validation Accuracy: 0.9142
Overfitting: 0.1406
[I 2024-12-11 03:38:04,471] Trial 7 pruned. 

Selected Hyperparameters for Trial 9:
  l1: 256, l2: 64, lr: 0.0011075021673381486, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2970440220832824
[Epoch 1, Batch 200] loss: 2.267493631839752
[Epoch 1, Batch 300] loss: 2.135984570980072
[Epoch 1, Batch 400] loss: 1.377213306427002
[Epoch 1, Batch 500] loss: 0.7466563251614571
[Epoch 1, Batch 600] loss: 0.5504840879142284
[Epoch 1, Batch 700] loss: 0.5041615103185176
[Epoch 1, Batch 800] loss: 0.44798000499606133
[Epoch 1, Batch 900] loss: 0.37658537589013574
[Epoch 1, Batch 1000] loss: 0.34557028345763685
[Epoch 1, Batch 1100] loss: 0.35246230401098727
[Epoch 1, Batch 1200] loss: 0.28407685849815606
[Epoch 1, Batch 1300] loss: 0.2646004100330174
[Epoch 1, Batch 1400] loss: 0.24779283372685312
[Epoch 1, Batch 1500] loss: 0.28533971594646573
[Epoch 1, Batch 1600] loss: 0.2141457429714501
[Epoch 1, Batch 1700] loss: 0.21137744767591357
[Epoch 1, Batch 1800] loss: 0.20057904912158847
[Epoch 1, Batch 1900] loss: 0.19104247430339455
[Epoch 1, Batch 2000] loss: 0.19611404726281761
[Epoch 1, Batch 2100] loss: 0.16847787662874908
[Epoch 1, Batch 2200] loss: 0.16501973843667656
[Epoch 1, Batch 2300] loss: 0.16273023039102555
[Epoch 1, Batch 2400] loss: 0.13171654780395328
[Epoch 1, Batch 2500] loss: 0.16349406122695653
[Epoch 1, Batch 2600] loss: 0.1451186524447985
[Epoch 1, Batch 2700] loss: 0.16414543332066386
[Epoch 1, Batch 2800] loss: 0.14932099564000964
[Epoch 1, Batch 2900] loss: 0.14723415466956793
[Epoch 1, Batch 3000] loss: 0.12135821231640875
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1011
Validation Accuracy: 0.9674
Overfitting: 0.1011
Best model saved at epoch 1 with validation loss: 0.1011
[Epoch 2, Batch 100] loss: 0.12676895197946578
[Epoch 2, Batch 200] loss: 0.13193863324355334
[Epoch 2, Batch 300] loss: 0.102705131303519
[Epoch 2, Batch 400] loss: 0.12227772151585668
[Epoch 2, Batch 500] loss: 0.127691580359824
[Epoch 2, Batch 600] loss: 0.09503025477752089
[Epoch 2, Batch 700] loss: 0.13338002228178084
[Epoch 2, Batch 800] loss: 0.11173953001154587
[Epoch 2, Batch 900] loss: 0.10861185929970815
[Epoch 2, Batch 1000] loss: 0.0836251410888508
[Epoch 2, Batch 1100] loss: 0.10103496867930517
[Epoch 2, Batch 1200] loss: 0.08841751445434057
[Epoch 2, Batch 1300] loss: 0.08259521740605123
[Epoch 2, Batch 1400] loss: 0.11973883996950463
[Epoch 2, Batch 1500] loss: 0.08109058400150389
[Epoch 2, Batch 1600] loss: 0.09759167321957647
[Epoch 2, Batch 1700] loss: 0.07666622310876846
[Epoch 2, Batch 1800] loss: 0.10789927269564942
[Epoch 2, Batch 1900] loss: 0.08457984631881117
[Epoch 2, Batch 2000] loss: 0.1137393032363616
[Epoch 2, Batch 2100] loss: 0.10564091809210367
[Epoch 2, Batch 2200] loss: 0.09739708279259503
[Epoch 2, Batch 2300] loss: 0.08144404670689255
[Epoch 2, Batch 2400] loss: 0.09506892765872181
[Epoch 2, Batch 2500] loss: 0.07854752093553544
[Epoch 2, Batch 2600] loss: 0.09270596045418643
[Epoch 2, Batch 2700] loss: 0.08143541667261162
[Epoch 2, Batch 2800] loss: 0.11175977552658878
[Epoch 2, Batch 2900] loss: 0.06792164554004558
[Epoch 2, Batch 3000] loss: 0.07494124408694916
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0671
Validation Accuracy: 0.9789
Overfitting: 0.0671
Best model saved at epoch 2 with validation loss: 0.0671
[Epoch 3, Batch 100] loss: 0.07327936540474184
[Epoch 3, Batch 200] loss: 0.0631752640591003
[Epoch 3, Batch 300] loss: 0.07879267607582734
[Epoch 3, Batch 400] loss: 0.06016419804131146
[Epoch 3, Batch 500] loss: 0.08119194189552217
[Epoch 3, Batch 600] loss: 0.05398276380845345
[Epoch 3, Batch 700] loss: 0.06475593603856396
[Epoch 3, Batch 800] loss: 0.08386810805008281
[Epoch 3, Batch 900] loss: 0.08534668897162191
[Epoch 3, Batch 1000] loss: 0.06453995751391631
[Epoch 3, Batch 1100] loss: 0.06242386787780561
[Epoch 3, Batch 1200] loss: 0.0806162379507441
[Epoch 3, Batch 1300] loss: 0.06559835013991687
[Epoch 3, Batch 1400] loss: 0.06282765590120107
[Epoch 3, Batch 1500] loss: 0.06068063024955336
[Epoch 3, Batch 1600] loss: 0.0703380354802357
[Epoch 3, Batch 1700] loss: 0.057599274294334465
[Epoch 3, Batch 1800] loss: 0.0781770327850245
[Epoch 3, Batch 1900] loss: 0.07130583598220255
[Epoch 3, Batch 2000] loss: 0.06962885244283826
[Epoch 3, Batch 2100] loss: 0.08239962173858657
[Epoch 3, Batch 2200] loss: 0.05892461606534198
[Epoch 3, Batch 2300] loss: 0.07841085927793756
[Epoch 3, Batch 2400] loss: 0.06180974337039515
[Epoch 3, Batch 2500] loss: 0.05798557549598627
[Epoch 3, Batch 2600] loss: 0.058497966637369246
[Epoch 3, Batch 2700] loss: 0.047910834018402966
[Epoch 3, Batch 2800] loss: 0.062213724937755614
[Epoch 3, Batch 2900] loss: 0.0675537170044845
[Epoch 3, Batch 3000] loss: 0.07004255800973624
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9809
Overfitting: 0.0605
Best model saved at epoch 3 with validation loss: 0.0605
[Epoch 4, Batch 100] loss: 0.05613794652046636
[Epoch 4, Batch 200] loss: 0.05462810383120086
[Epoch 4, Batch 300] loss: 0.04988840513804462
[Epoch 4, Batch 400] loss: 0.054031728157424366
[Epoch 4, Batch 500] loss: 0.052916900217242074
[Epoch 4, Batch 600] loss: 0.054869014006108045
[Epoch 4, Batch 700] loss: 0.056744205661816524
[Epoch 4, Batch 800] loss: 0.06908181940991198
[Epoch 4, Batch 900] loss: 0.046889174909156284
[Epoch 4, Batch 1000] loss: 0.03586459172802279
[Epoch 4, Batch 1100] loss: 0.048114048561255916
[Epoch 4, Batch 1200] loss: 0.04586222073354293
[Epoch 4, Batch 1300] loss: 0.059225021106540224
[Epoch 4, Batch 1400] loss: 0.04353193530580029
[Epoch 4, Batch 1500] loss: 0.05591006731905509
[Epoch 4, Batch 1600] loss: 0.05578458157193381
[Epoch 4, Batch 1700] loss: 0.0491473580582533
[Epoch 4, Batch 1800] loss: 0.0460261060121411
[Epoch 4, Batch 1900] loss: 0.06679963863396551
[Epoch 4, Batch 2000] loss: 0.07006151231238618
[Epoch 4, Batch 2100] loss: 0.04461853398999665
[Epoch 4, Batch 2200] loss: 0.04627261978486786
[Epoch 4, Batch 2300] loss: 0.06413459932868136
[Epoch 4, Batch 2400] loss: 0.06232764243512065
[Epoch 4, Batch 2500] loss: 0.051112332661286924
[Epoch 4, Batch 2600] loss: 0.0543029617384309
[Epoch 4, Batch 2700] loss: 0.05152600407309364
[Epoch 4, Batch 2800] loss: 0.056472768526291475
[Epoch 4, Batch 2900] loss: 0.05059172761306399
[Epoch 4, Batch 3000] loss: 0.05539300793898292
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0681
Validation Accuracy: 0.9788
Overfitting: 0.0681
[Epoch 5, Batch 100] loss: 0.03354261860542465
[Epoch 5, Batch 200] loss: 0.03712781477355748
[Epoch 5, Batch 300] loss: 0.03407365962091717
[Epoch 5, Batch 400] loss: 0.04497881629387848
[Epoch 5, Batch 500] loss: 0.038797682437871114
[Epoch 5, Batch 600] loss: 0.0391519623703789
[Epoch 5, Batch 700] loss: 0.046554288962215654
[Epoch 5, Batch 800] loss: 0.05428482645191252
[Epoch 5, Batch 900] loss: 0.04881215137022082
[Epoch 5, Batch 1000] loss: 0.038840544572740325
[Epoch 5, Batch 1100] loss: 0.05015469337289687
[Epoch 5, Batch 1200] loss: 0.03801894420554163
[Epoch 5, Batch 1300] loss: 0.035222664561879356
[Epoch 5, Batch 1400] loss: 0.06598371881758794
[Epoch 5, Batch 1500] loss: 0.0377040741230303
[Epoch 5, Batch 1600] loss: 0.031407711574283896
[Epoch 5, Batch 1700] loss: 0.04896742893717601
[Epoch 5, Batch 1800] loss: 0.051981579177372624
[Epoch 5, Batch 1900] loss: 0.037832108462098404
[Epoch 5, Batch 2000] loss: 0.04114737688767491
[Epoch 5, Batch 2100] loss: 0.03226610274548875
[Epoch 5, Batch 2200] loss: 0.034178911059862004
[Epoch 5, Batch 2300] loss: 0.03554556620270887
[Epoch 5, Batch 2400] loss: 0.04277819056595036
[Epoch 5, Batch 2500] loss: 0.0320937839729595
[Epoch 5, Batch 2600] loss: 0.046638899457029766
[Epoch 5, Batch 2700] loss: 0.06444055298779858
[Epoch 5, Batch 2800] loss: 0.06173111084499396
[Epoch 5, Batch 2900] loss: 0.045265271242242305
[Epoch 5, Batch 3000] loss: 0.04422715103166411
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0530
Validation Accuracy: 0.9830
Overfitting: 0.0530
Best model saved at epoch 5 with validation loss: 0.0530
[Epoch 6, Batch 100] loss: 0.03871331102345721
[Epoch 6, Batch 200] loss: 0.02932902207947336
[Epoch 6, Batch 300] loss: 0.03367692334097228
[Epoch 6, Batch 400] loss: 0.046509215763653626
[Epoch 6, Batch 500] loss: 0.04147750818243367
[Epoch 6, Batch 600] loss: 0.031568024314474315
[Epoch 6, Batch 700] loss: 0.026472935573547147
[Epoch 6, Batch 800] loss: 0.028705866451055044
[Epoch 6, Batch 900] loss: 0.03913740004296415
[Epoch 6, Batch 1000] loss: 0.03100515945960069
[Epoch 6, Batch 1100] loss: 0.04100450194870064
[Epoch 6, Batch 1200] loss: 0.03587391813853173
[Epoch 6, Batch 1300] loss: 0.042135495469119634
[Epoch 6, Batch 1400] loss: 0.03204843821105897
[Epoch 6, Batch 1500] loss: 0.04332089892195654
[Epoch 6, Batch 1600] loss: 0.030282906184293096
[Epoch 6, Batch 1700] loss: 0.027941025597101543
[Epoch 6, Batch 1800] loss: 0.03176292168966029
[Epoch 6, Batch 1900] loss: 0.03900797860071179
[Epoch 6, Batch 2000] loss: 0.04049205007671844
[Epoch 6, Batch 2100] loss: 0.02916138439468341
[Epoch 6, Batch 2200] loss: 0.0336236396379536
[Epoch 6, Batch 2300] loss: 0.028223871901864185
[Epoch 6, Batch 2400] loss: 0.038965866844228
[Epoch 6, Batch 2500] loss: 0.030937245586901554
[Epoch 6, Batch 2600] loss: 0.026222280429537934
[Epoch 6, Batch 2700] loss: 0.02789203491542139
[Epoch 6, Batch 2800] loss: 0.03230732281363089
[Epoch 6, Batch 2900] loss: 0.046614802025433166
[Epoch 6, Batch 3000] loss: 0.04783005621909979
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0460
Validation Accuracy: 0.9842
Overfitting: 0.0460
Best model saved at epoch 6 with validation loss: 0.0460
[Epoch 7, Batch 100] loss: 0.033093368276313415
[Epoch 7, Batch 200] loss: 0.020715618661779445
[Epoch 7, Batch 300] loss: 0.02482563737865348
[Epoch 7, Batch 400] loss: 0.01789966686301341
[Epoch 7, Batch 500] loss: 0.035755239863865425
[Epoch 7, Batch 600] loss: 0.028598940086594665
[Epoch 7, Batch 700] loss: 0.04492710157272086
[Epoch 7, Batch 800] loss: 0.03136238875777053
[Epoch 7, Batch 900] loss: 0.027298400055879028
[Epoch 7, Batch 1000] loss: 0.025538811704391266
[Epoch 7, Batch 1100] loss: 0.024265528724718023
[Epoch 7, Batch 1200] loss: 0.020887898965956993
[Epoch 7, Batch 1300] loss: 0.039753157086233844
[Epoch 7, Batch 1400] loss: 0.029587680130352966
[Epoch 7, Batch 1500] loss: 0.021309853343409485
[Epoch 7, Batch 1600] loss: 0.030721901549550238
[Epoch 7, Batch 1700] loss: 0.029234106965595856
[Epoch 7, Batch 1800] loss: 0.03763833794451785
[Epoch 7, Batch 1900] loss: 0.03160912831343012
[Epoch 7, Batch 2000] loss: 0.03701767521793954
[Epoch 7, Batch 2100] loss: 0.039762270151113624
[Epoch 7, Batch 2200] loss: 0.018496313337091123
[Epoch 7, Batch 2300] loss: 0.04919745975719707
[Epoch 7, Batch 2400] loss: 0.026976338927270263
[Epoch 7, Batch 2500] loss: 0.030024887290819605
[Epoch 7, Batch 2600] loss: 0.021258250525861513
[Epoch 7, Batch 2700] loss: 0.02204065010231716
[Epoch 7, Batch 2800] loss: 0.02030722553992746
[Epoch 7, Batch 2900] loss: 0.02831810333264002
[Epoch 7, Batch 3000] loss: 0.039078927666705565
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9872
Overfitting: 0.0422
Best model saved at epoch 7 with validation loss: 0.0422
[Epoch 8, Batch 100] loss: 0.0337098760464869
[Epoch 8, Batch 200] loss: 0.025031813454843357
[Epoch 8, Batch 300] loss: 0.022786825559232966
[Epoch 8, Batch 400] loss: 0.029714968601620057
[Epoch 8, Batch 500] loss: 0.034635714451942475
[Epoch 8, Batch 600] loss: 0.03502039334234723
[Epoch 8, Batch 700] loss: 0.030249189770256635
[Epoch 8, Batch 800] loss: 0.013475873062197934
[Epoch 8, Batch 900] loss: 0.023255314098169038
[Epoch 8, Batch 1000] loss: 0.011118945316411555
[Epoch 8, Batch 1100] loss: 0.024534066465457728
[Epoch 8, Batch 1200] loss: 0.02317864785092752
[Epoch 8, Batch 1300] loss: 0.025301096225375658
[Epoch 8, Batch 1400] loss: 0.027133025570983592
[Epoch 8, Batch 1500] loss: 0.013176245830381959
[Epoch 8, Batch 1600] loss: 0.021749524392143938
[Epoch 8, Batch 1700] loss: 0.028493829664403166
[Epoch 8, Batch 1800] loss: 0.017794512108193886
[Epoch 8, Batch 1900] loss: 0.03737777570575417
[Epoch 8, Batch 2000] loss: 0.032958190038698376
[Epoch 8, Batch 2100] loss: 0.01717081305647298
[Epoch 8, Batch 2200] loss: 0.018999827307216038
[Epoch 8, Batch 2300] loss: 0.02353135196139192
[Epoch 8, Batch 2400] loss: 0.025322634094154636
[Epoch 8, Batch 2500] loss: 0.03012237198661751
[Epoch 8, Batch 2600] loss: 0.01954486769176583
[Epoch 8, Batch 2700] loss: 0.03415260254419991
[Epoch 8, Batch 2800] loss: 0.043218204857912494
[Epoch 8, Batch 2900] loss: 0.02775351260046591
[Epoch 8, Batch 3000] loss: 0.02898335728663369
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9858
Overfitting: 0.0469
[Epoch 9, Batch 100] loss: 0.021545658006216398
[Epoch 9, Batch 200] loss: 0.020285870346851878
[Epoch 9, Batch 300] loss: 0.019485007186158327
[Epoch 9, Batch 400] loss: 0.023340516608805047
[Epoch 9, Batch 500] loss: 0.021402350209027646
[Epoch 9, Batch 600] loss: 0.016378243322360504
[Epoch 9, Batch 700] loss: 0.021089072928662064
[Epoch 9, Batch 800] loss: 0.028889845084559055
[Epoch 9, Batch 900] loss: 0.013274950896757218
[Epoch 9, Batch 1000] loss: 0.01096863324251899
[Epoch 9, Batch 1100] loss: 0.024905861271881803
[Epoch 9, Batch 1200] loss: 0.02387238702533068
[Epoch 9, Batch 1300] loss: 0.0279430217362642
[Epoch 9, Batch 1400] loss: 0.021386282675830443
[Epoch 9, Batch 1500] loss: 0.023158788831397034
[Epoch 9, Batch 1600] loss: 0.016055951653324883
[Epoch 9, Batch 1700] loss: 0.02740158949010947
[Epoch 9, Batch 1800] loss: 0.026049248660419834
[Epoch 9, Batch 1900] loss: 0.02431581103031931
[Epoch 9, Batch 2000] loss: 0.01500450488016213
[Epoch 9, Batch 2100] loss: 0.01965331604835228
[Epoch 9, Batch 2200] loss: 0.022230457194618792
[Epoch 9, Batch 2300] loss: 0.027290933503936684
[Epoch 9, Batch 2400] loss: 0.016409406085331285
[Epoch 9, Batch 2500] loss: 0.02013669689076778
[Epoch 9, Batch 2600] loss: 0.024886005920998287
[Epoch 9, Batch 2700] loss: 0.0194840238019151
[Epoch 9, Batch 2800] loss: 0.02648816473005354
[Epoch 9, Batch 2900] loss: 0.023656728640416985
[Epoch 9, Batch 3000] loss: 0.020475654977090016
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9852
Overfitting: 0.0492
[Epoch 10, Batch 100] loss: 0.013751796342785384
[Epoch 10, Batch 200] loss: 0.00725284367272252
[Epoch 10, Batch 300] loss: 0.00926069122451736
[Epoch 10, Batch 400] loss: 0.019742838788552035
[Epoch 10, Batch 500] loss: 0.013098483489029604
[Epoch 10, Batch 600] loss: 0.008992416060536926
[Epoch 10, Batch 700] loss: 0.020483845566996024
[Epoch 10, Batch 800] loss: 0.02848412397010179
[Epoch 10, Batch 900] loss: 0.022386191408913875
[Epoch 10, Batch 1000] loss: 0.034317231977402114
[Epoch 10, Batch 1100] loss: 0.0263445765920369
[Epoch 10, Batch 1200] loss: 0.015514186074324244
[Epoch 10, Batch 1300] loss: 0.020262413982927684
[Epoch 10, Batch 1400] loss: 0.01249466533849045
[Epoch 10, Batch 1500] loss: 0.010458117416965252
[Epoch 10, Batch 1600] loss: 0.01695050629633897
[Epoch 10, Batch 1700] loss: 0.017468689605211692
[Epoch 10, Batch 1800] loss: 0.019052432203461648
[Epoch 10, Batch 1900] loss: 0.014587929191966395
[Epoch 10, Batch 2000] loss: 0.01658060625233702
[Epoch 10, Batch 2100] loss: 0.01921707834339031
[Epoch 10, Batch 2200] loss: 0.0114779507034973
[Epoch 10, Batch 2300] loss: 0.021192079859765726
[Epoch 10, Batch 2400] loss: 0.03439754430722133
[Epoch 10, Batch 2500] loss: 0.023034994656227353
[Epoch 10, Batch 2600] loss: 0.017654064976522933
[Epoch 10, Batch 2700] loss: 0.02640970827973888
[Epoch 10, Batch 2800] loss: 0.028438777206192752
[Epoch 10, Batch 2900] loss: 0.02790510525496302
[Epoch 10, Batch 3000] loss: 0.013290055561719782
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0396
Validation Accuracy: 0.9879
Overfitting: 0.0396
Best model saved at epoch 10 with validation loss: 0.0396
[Epoch 11, Batch 100] loss: 0.008854317384411843
[Epoch 11, Batch 200] loss: 0.007854151286956039
[Epoch 11, Batch 300] loss: 0.017509703798968986
[Epoch 11, Batch 400] loss: 0.00923182219177761
[Epoch 11, Batch 500] loss: 0.010261323734557664
[Epoch 11, Batch 600] loss: 0.02351536745822159
[Epoch 11, Batch 700] loss: 0.02204810231902229
[Epoch 11, Batch 800] loss: 0.012153130747983597
[Epoch 11, Batch 900] loss: 0.023126583697444403
[Epoch 11, Batch 1000] loss: 0.015403395183457179
[Epoch 11, Batch 1100] loss: 0.01929303211214574
[Epoch 11, Batch 1200] loss: 0.016853810958123175
[Epoch 11, Batch 1300] loss: 0.01312794339026368
[Epoch 11, Batch 1400] loss: 0.01459312819499246
[Epoch 11, Batch 1500] loss: 0.010276430638747343
[Epoch 11, Batch 1600] loss: 0.015788274529013505
[Epoch 11, Batch 1700] loss: 0.014784107257974029
[Epoch 11, Batch 1800] loss: 0.013087949489608945
[Epoch 11, Batch 1900] loss: 0.02320148178625459
[Epoch 11, Batch 2000] loss: 0.013110829162160371
[Epoch 11, Batch 2100] loss: 0.012602314921878133
[Epoch 11, Batch 2200] loss: 0.015816687021244887
[Epoch 11, Batch 2300] loss: 0.023120103783380728
[Epoch 11, Batch 2400] loss: 0.023716555152036564
[Epoch 11, Batch 2500] loss: 0.01792780538828083
[Epoch 11, Batch 2600] loss: 0.017141756076734963
[Epoch 11, Batch 2700] loss: 0.027665827121326175
[Epoch 11, Batch 2800] loss: 0.020182742144424993
[Epoch 11, Batch 2900] loss: 0.013820057309403637
[Epoch 11, Batch 3000] loss: 0.02008788268274657
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0386
Validation Accuracy: 0.9897
Overfitting: 0.0386
Best model saved at epoch 11 with validation loss: 0.0386
[Epoch 12, Batch 100] loss: 0.009514455630496741
[Epoch 12, Batch 200] loss: 0.013740590564802915
[Epoch 12, Batch 300] loss: 0.013558459909236263
[Epoch 12, Batch 400] loss: 0.007081444299019495
[Epoch 12, Batch 500] loss: 0.011331073268120235
[Epoch 12, Batch 600] loss: 0.00966862303466769
[Epoch 12, Batch 700] loss: 0.021212350586665707
[Epoch 12, Batch 800] loss: 0.009028982609233936
[Epoch 12, Batch 900] loss: 0.015067084977781633
[Epoch 12, Batch 1000] loss: 0.009875232255835727
[Epoch 12, Batch 1100] loss: 0.007007299127990336
[Epoch 12, Batch 1200] loss: 0.007284845947315262
[Epoch 12, Batch 1300] loss: 0.02930960813263482
[Epoch 12, Batch 1400] loss: 0.012629698717187238
[Epoch 12, Batch 1500] loss: 0.011177467620636889
[Epoch 12, Batch 1600] loss: 0.01695030260039857
[Epoch 12, Batch 1700] loss: 0.02228090610644358
[Epoch 12, Batch 1800] loss: 0.015594059437617033
[Epoch 12, Batch 1900] loss: 0.022265343465464868
[Epoch 12, Batch 2000] loss: 0.012437148123499355
[Epoch 12, Batch 2100] loss: 0.01792086092284535
[Epoch 12, Batch 2200] loss: 0.01462188555718967
[Epoch 12, Batch 2300] loss: 0.012623893375275657
[Epoch 12, Batch 2400] loss: 0.012111457139417326
[Epoch 12, Batch 2500] loss: 0.01557196879372441
[Epoch 12, Batch 2600] loss: 0.014604462963561674
[Epoch 12, Batch 2700] loss: 0.013155826268448436
[Epoch 12, Batch 2800] loss: 0.008264514973379846
[Epoch 12, Batch 2900] loss: 0.00853827875985644
[Epoch 12, Batch 3000] loss: 0.009064663833123631
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9879
Overfitting: 0.0486
[Epoch 13, Batch 100] loss: 0.007426377965462052
[Epoch 13, Batch 200] loss: 0.005624297047324945
[Epoch 13, Batch 300] loss: 0.012251356242222755
[Epoch 13, Batch 400] loss: 0.015599068238698237
[Epoch 13, Batch 500] loss: 0.00972393031754109
[Epoch 13, Batch 600] loss: 0.0065985687601369135
[Epoch 13, Batch 700] loss: 0.009584739782633278
[Epoch 13, Batch 800] loss: 0.01039287443536864
[Epoch 13, Batch 900] loss: 0.005393122554264665
[Epoch 13, Batch 1000] loss: 0.01445496639911653
[Epoch 13, Batch 1100] loss: 0.008002418095147732
[Epoch 13, Batch 1200] loss: 0.007069077387125162
[Epoch 13, Batch 1300] loss: 0.007852736105628538
[Epoch 13, Batch 1400] loss: 0.012317198962348357
[Epoch 13, Batch 1500] loss: 0.025396520719987166
[Epoch 13, Batch 1600] loss: 0.021147987265685515
[Epoch 13, Batch 1700] loss: 0.009246463831404981
[Epoch 13, Batch 1800] loss: 0.011692938260596293
[Epoch 13, Batch 1900] loss: 0.014485448743130291
[Epoch 13, Batch 2000] loss: 0.019651488529543713
[Epoch 13, Batch 2100] loss: 0.008356661621584181
[Epoch 13, Batch 2200] loss: 0.022959981429253276
[Epoch 13, Batch 2300] loss: 0.011094389890686215
[Epoch 13, Batch 2400] loss: 0.013486467328993968
[Epoch 13, Batch 2500] loss: 0.01757247190147723
[Epoch 13, Batch 2600] loss: 0.019652695167624187
[Epoch 13, Batch 2700] loss: 0.010619292963465341
[Epoch 13, Batch 2800] loss: 0.012527814685681734
[Epoch 13, Batch 2900] loss: 0.010841801507694981
[Epoch 13, Batch 3000] loss: 0.011062919725131905
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0443
Validation Accuracy: 0.9887
Overfitting: 0.0443
[Epoch 14, Batch 100] loss: 0.010765614983879459
[Epoch 14, Batch 200] loss: 0.008974228873441917
[Epoch 14, Batch 300] loss: 0.0056510978720962154
[Epoch 14, Batch 400] loss: 0.010427666330565443
[Epoch 14, Batch 500] loss: 0.006227762231819724
[Epoch 14, Batch 600] loss: 0.009544667449333702
[Epoch 14, Batch 700] loss: 0.010423494651745387
[Epoch 14, Batch 800] loss: 0.018796185393968018
[Epoch 14, Batch 900] loss: 0.008170156414055328
[Epoch 14, Batch 1000] loss: 0.0145443647604975
[Epoch 14, Batch 1100] loss: 0.015042730509894681
[Epoch 14, Batch 1200] loss: 0.013221672280596976
[Epoch 14, Batch 1300] loss: 0.008084471748304622
[Epoch 14, Batch 1400] loss: 0.007234468470269349
[Epoch 14, Batch 1500] loss: 0.006297519803022169
[Epoch 14, Batch 1600] loss: 0.006417392613994935
[Epoch 14, Batch 1700] loss: 0.01702750325949637
[Epoch 14, Batch 1800] loss: 0.011692355625334584
[Epoch 14, Batch 1900] loss: 0.013105936011240828
[Epoch 14, Batch 2000] loss: 0.008703503365427422
[Epoch 14, Batch 2100] loss: 0.013141160422264875
[Epoch 14, Batch 2200] loss: 0.007855089427257553
[Epoch 14, Batch 2300] loss: 0.008591118103586268
[Epoch 14, Batch 2400] loss: 0.009842452813729778
[Epoch 14, Batch 2500] loss: 0.008214631808930334
[Epoch 14, Batch 2600] loss: 0.010539949646699824
[Epoch 14, Batch 2700] loss: 0.013968310686636868
[Epoch 14, Batch 2800] loss: 0.010195624047497631
[Epoch 14, Batch 2900] loss: 0.01674228792450549
[Epoch 14, Batch 3000] loss: 0.013764996006181036
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0404
Validation Accuracy: 0.9898
Overfitting: 0.0404
[Epoch 15, Batch 100] loss: 0.005611036780067025
[Epoch 15, Batch 200] loss: 0.006733104758966419
[Epoch 15, Batch 300] loss: 0.00518245371222065
[Epoch 15, Batch 400] loss: 0.0037024607450871373
[Epoch 15, Batch 500] loss: 0.017194344205586277
[Epoch 15, Batch 600] loss: 0.011165435697845396
[Epoch 15, Batch 700] loss: 0.005169721355637194
[Epoch 15, Batch 800] loss: 0.004640096563575753
[Epoch 15, Batch 900] loss: 0.01085917419841735
[Epoch 15, Batch 1000] loss: 0.009404043149179414
[Epoch 15, Batch 1100] loss: 0.00737926954959903
[Epoch 15, Batch 1200] loss: 0.021732417044190697
[Epoch 15, Batch 1300] loss: 0.01401365188773525
[Epoch 15, Batch 1400] loss: 0.013572270731187927
[Epoch 15, Batch 1500] loss: 0.0047127752089659225
[Epoch 15, Batch 1600] loss: 0.011141234143250358
[Epoch 15, Batch 1700] loss: 0.007985050929792124
[Epoch 15, Batch 1800] loss: 0.012986530049583962
[Epoch 15, Batch 1900] loss: 0.0075641221087289524
[Epoch 15, Batch 2000] loss: 0.006766107637422465
[Epoch 15, Batch 2100] loss: 0.012504945304649483
[Epoch 15, Batch 2200] loss: 0.009112676265872324
[Epoch 15, Batch 2300] loss: 0.011621743445266475
[Epoch 15, Batch 2400] loss: 0.005025067996837151
[Epoch 15, Batch 2500] loss: 0.005876383420627462
[Epoch 15, Batch 2600] loss: 0.00447996111108182
[Epoch 15, Batch 2700] loss: 0.011927126655500615
[Epoch 15, Batch 2800] loss: 0.010071990209823412
[Epoch 15, Batch 2900] loss: 0.008534396832849324
[Epoch 15, Batch 3000] loss: 0.017662251239767102
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9893
Overfitting: 0.0441
[Epoch 16, Batch 100] loss: 0.0027420770375192662
[Epoch 16, Batch 200] loss: 0.005508787250971636
[Epoch 16, Batch 300] loss: 0.0057191392549361805
[Epoch 16, Batch 400] loss: 0.003548371046815646
[Epoch 16, Batch 500] loss: 0.006050323641308353
[Epoch 16, Batch 600] loss: 0.004026618125078585
[Epoch 16, Batch 700] loss: 0.003914017451013479
[Epoch 16, Batch 800] loss: 0.00949030196634908
[Epoch 16, Batch 900] loss: 0.020877417733231596
[Epoch 16, Batch 1000] loss: 0.005994447497641886
[Epoch 16, Batch 1100] loss: 0.002895053848392308
[Epoch 16, Batch 1200] loss: 0.01103416885325089
[Epoch 16, Batch 1300] loss: 0.010859831720898683
[Epoch 16, Batch 1400] loss: 0.005416914589138741
[Epoch 16, Batch 1500] loss: 0.011727746414580907
[Epoch 16, Batch 1600] loss: 0.007189363182662873
[Epoch 16, Batch 1700] loss: 0.006506322409233007
[Epoch 16, Batch 1800] loss: 0.012195980638634864
[Epoch 16, Batch 1900] loss: 0.0047502952503828055
[Epoch 16, Batch 2000] loss: 0.00797485432312044
[Epoch 16, Batch 2100] loss: 0.0037376979515875066
[Epoch 16, Batch 2200] loss: 0.006663019001942985
[Epoch 16, Batch 2300] loss: 0.005410757496053975
[Epoch 16, Batch 2400] loss: 0.004107015057527406
[Epoch 16, Batch 2500] loss: 0.003724605819829776
[Epoch 16, Batch 2600] loss: 0.002752624279924021
[Epoch 16, Batch 2700] loss: 0.017334289716475267
[Epoch 16, Batch 2800] loss: 0.010788354087934523
[Epoch 16, Batch 2900] loss: 0.009669624845378167
[Epoch 16, Batch 3000] loss: 0.0067065710406450305
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0426
Validation Accuracy: 0.9889
Overfitting: 0.0426
[Epoch 17, Batch 100] loss: 0.0032327716634517854
[Epoch 17, Batch 200] loss: 0.002081254357360649
[Epoch 17, Batch 300] loss: 0.009047367994926957
[Epoch 17, Batch 400] loss: 0.005344730380155625
[Epoch 17, Batch 500] loss: 0.004178590359962868
[Epoch 17, Batch 600] loss: 0.003919944431308977
[Epoch 17, Batch 700] loss: 0.014045451468587372
[Epoch 17, Batch 800] loss: 0.007328312207304748
[Epoch 17, Batch 900] loss: 0.004354004684691972
[Epoch 17, Batch 1000] loss: 0.0058294169370833515
[Epoch 17, Batch 1100] loss: 0.00747237972998036
[Epoch 17, Batch 1200] loss: 0.00880102816152018
[Epoch 17, Batch 1300] loss: 0.007830230320276996
[Epoch 17, Batch 1400] loss: 0.013415852766952412
[Epoch 17, Batch 1500] loss: 0.006233049350898909
[Epoch 17, Batch 1600] loss: 0.002963776761584427
[Epoch 17, Batch 1700] loss: 0.008076673501163896
[Epoch 17, Batch 1800] loss: 0.004212154237774257
[Epoch 17, Batch 1900] loss: 0.005167430570466536
[Epoch 17, Batch 2000] loss: 0.00455304984136319
[Epoch 17, Batch 2100] loss: 0.009348479892733508
[Epoch 17, Batch 2200] loss: 0.005461899939620025
[Epoch 17, Batch 2300] loss: 0.011481348765548773
[Epoch 17, Batch 2400] loss: 0.013783543767323181
[Epoch 17, Batch 2500] loss: 0.005960605699638109
[Epoch 17, Batch 2600] loss: 0.005806869364959084
[Epoch 17, Batch 2700] loss: 0.015709621385358332
[Epoch 17, Batch 2800] loss: 0.028186214825359455
[Epoch 17, Batch 2900] loss: 0.013537902291527928
[Epoch 17, Batch 3000] loss: 0.01738925773147912
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9880
Overfitting: 0.0466
[Epoch 18, Batch 100] loss: 0.0079135497699383
[Epoch 18, Batch 200] loss: 0.013266320499278663
[Epoch 18, Batch 300] loss: 0.006596346888813969
[Epoch 18, Batch 400] loss: 0.003229996743054926
[Epoch 18, Batch 500] loss: 0.0042977089849296135
[Epoch 18, Batch 600] loss: 0.006200053553262137
[Epoch 18, Batch 700] loss: 0.0037778943436910595
[Epoch 18, Batch 800] loss: 0.009129788442659787
[Epoch 18, Batch 900] loss: 0.0051952773651134975
[Epoch 18, Batch 1000] loss: 0.006204153307352272
[Epoch 18, Batch 1100] loss: 0.0030925741035508734
[Epoch 18, Batch 1200] loss: 0.0055562596228799065
[Epoch 18, Batch 1300] loss: 0.004790374293149408
[Epoch 18, Batch 1400] loss: 0.005094009456932724
[Epoch 18, Batch 1500] loss: 0.0031597522056506476
[Epoch 18, Batch 1600] loss: 0.004663541182880522
[Epoch 18, Batch 1700] loss: 0.0032704397268503273
[Epoch 18, Batch 1800] loss: 0.002419643095588242
[Epoch 18, Batch 1900] loss: 0.0038769970805196865
[Epoch 18, Batch 2000] loss: 0.010569424032718188
[Epoch 18, Batch 2100] loss: 0.008566012820311926
[Epoch 18, Batch 2200] loss: 0.008210114812795837
[Epoch 18, Batch 2300] loss: 0.01235708157580433
[Epoch 18, Batch 2400] loss: 0.007907701713545521
[Epoch 18, Batch 2500] loss: 0.005735856339701968
[Epoch 18, Batch 2600] loss: 0.0076870339585684636
[Epoch 18, Batch 2700] loss: 0.0076587112299512225
[Epoch 18, Batch 2800] loss: 0.009597968101770675
[Epoch 18, Batch 2900] loss: 0.004477654700505127
[Epoch 18, Batch 3000] loss: 0.005262037533310604
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0440
Validation Accuracy: 0.9899
Overfitting: 0.0440
[Epoch 19, Batch 100] loss: 0.0031690337355337306
[Epoch 19, Batch 200] loss: 0.002574515648962006
[Epoch 19, Batch 300] loss: 0.0026404896024806133
[Epoch 19, Batch 400] loss: 0.0022853899203772697
[Epoch 19, Batch 500] loss: 0.0030419263041750353
[Epoch 19, Batch 600] loss: 0.0066010378337341535
[Epoch 19, Batch 700] loss: 0.004376904987009596
[Epoch 19, Batch 800] loss: 0.0025817343994694398
[Epoch 19, Batch 900] loss: 0.005977552171031135
[Epoch 19, Batch 1000] loss: 0.0033791329695586113
[Epoch 19, Batch 1100] loss: 0.0035931896809478303
[Epoch 19, Batch 1200] loss: 0.0020276730411313794
[Epoch 19, Batch 1300] loss: 0.0010644293238664204
[Epoch 19, Batch 1400] loss: 0.0012243211404907584
[Epoch 19, Batch 1500] loss: 0.0013471869634037149
[Epoch 19, Batch 1600] loss: 0.0039195983347696025
[Epoch 19, Batch 1700] loss: 0.0038184493886357983
[Epoch 19, Batch 1800] loss: 0.01019928320732788
[Epoch 19, Batch 1900] loss: 0.006424004560790202
[Epoch 19, Batch 2000] loss: 0.008470275113925823
[Epoch 19, Batch 2100] loss: 0.008087622888086798
[Epoch 19, Batch 2200] loss: 0.013515826255347108
[Epoch 19, Batch 2300] loss: 0.005726509538598066
[Epoch 19, Batch 2400] loss: 0.0018328525401648222
[Epoch 19, Batch 2500] loss: 0.0030570846229559835
[Epoch 19, Batch 2600] loss: 0.0018026617102847808
[Epoch 19, Batch 2700] loss: 0.003764495169208004
[Epoch 19, Batch 2800] loss: 0.0041053072247182595
[Epoch 19, Batch 2900] loss: 0.002869950164131865
[Epoch 19, Batch 3000] loss: 0.006636821863059481
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9882
Overfitting: 0.0508
[Epoch 20, Batch 100] loss: 0.005623416656922018
[Epoch 20, Batch 200] loss: 0.00701886040166471
[Epoch 20, Batch 300] loss: 0.0068134510911327965
[Epoch 20, Batch 400] loss: 0.0072378602750188745
[Epoch 20, Batch 500] loss: 0.003980167088579378
[Epoch 20, Batch 600] loss: 0.0028171164670900595
[Epoch 20, Batch 700] loss: 0.004194257197604543
[Epoch 20, Batch 800] loss: 0.002595685539325103
[Epoch 20, Batch 900] loss: 0.004870285097099139
[Epoch 20, Batch 1000] loss: 0.009277089310976976
[Epoch 20, Batch 1100] loss: 0.007198754235241403
[Epoch 20, Batch 1200] loss: 0.001775189133592221
[Epoch 20, Batch 1300] loss: 0.0011086683637699934
[Epoch 20, Batch 1400] loss: 0.002014401541171615
[Epoch 20, Batch 1500] loss: 0.004028568150248404
[Epoch 20, Batch 1600] loss: 0.0023706436504294004
[Epoch 20, Batch 1700] loss: 0.001033817866023412
[Epoch 20, Batch 1800] loss: 0.0013151354453702169
[Epoch 20, Batch 1900] loss: 0.002281049648845155
[Epoch 20, Batch 2000] loss: 0.004123831325336198
[Epoch 20, Batch 2100] loss: 0.001967287183060904
[Epoch 20, Batch 2200] loss: 0.0033665212256636322
[Epoch 20, Batch 2300] loss: 0.0008670501581383405
[Epoch 20, Batch 2400] loss: 0.0012989870581608188
[Epoch 20, Batch 2500] loss: 0.0032055693202705984
[Epoch 20, Batch 2600] loss: 0.003595586309086585
[Epoch 20, Batch 2700] loss: 0.001592647247572927
[Epoch 20, Batch 2800] loss: 0.004631480962713965
[Epoch 20, Batch 2900] loss: 0.008196383397298633
[Epoch 20, Batch 3000] loss: 0.008478455203512852
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9866
Overfitting: 0.0592
[Epoch 21, Batch 100] loss: 0.002396233948937834
[Epoch 21, Batch 200] loss: 0.002503980713738656
[Epoch 21, Batch 300] loss: 0.004568566934067348
[Epoch 21, Batch 400] loss: 0.005361796489179654
[Epoch 21, Batch 500] loss: 0.007628637253925064
[Epoch 21, Batch 600] loss: 0.009458568376324764
[Epoch 21, Batch 700] loss: 0.0021069857231528744
[Epoch 21, Batch 800] loss: 0.0018502925592667908
[Epoch 21, Batch 900] loss: 0.002864283347240644
[Epoch 21, Batch 1000] loss: 0.002173081142516082
[Epoch 21, Batch 1100] loss: 0.0027364432206481125
[Epoch 21, Batch 1200] loss: 0.002414790586219624
[Epoch 21, Batch 1300] loss: 0.009513371308978762
[Epoch 21, Batch 1400] loss: 0.005275891913187252
[Epoch 21, Batch 1500] loss: 0.00693697771021661
[Epoch 21, Batch 1600] loss: 0.0015419319009623677
[Epoch 21, Batch 1700] loss: 0.003929682213245868
[Epoch 21, Batch 1800] loss: 0.002459999484274675
[Epoch 21, Batch 1900] loss: 0.0024415674274882804
[Epoch 21, Batch 2000] loss: 0.0011596434487695718
[Epoch 21, Batch 2100] loss: 0.0069366478591304315
[Epoch 21, Batch 2200] loss: 0.010660699179336462
[Epoch 21, Batch 2300] loss: 0.003824902346900352
[Epoch 21, Batch 2400] loss: 0.003928491815387929
[Epoch 21, Batch 2500] loss: 0.014926554190273294
[Epoch 21, Batch 2600] loss: 0.006642889396219118
[Epoch 21, Batch 2700] loss: 0.00675333914794436
[Epoch 21, Batch 2800] loss: 0.002353245125087824
[Epoch 21, Batch 2900] loss: 0.0067331661404693224
[Epoch 21, Batch 3000] loss: 0.008069199659673813
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9892
Overfitting: 0.0501
[Epoch 22, Batch 100] loss: 0.0096945971974489
[Epoch 22, Batch 200] loss: 0.0009888886039830424
[Epoch 22, Batch 300] loss: 0.0011791965901947776
[Epoch 22, Batch 400] loss: 0.0028436244887558005
[Epoch 22, Batch 500] loss: 0.006213510804267344
[Epoch 22, Batch 600] loss: 0.002189077668554944
[Epoch 22, Batch 700] loss: 0.002711866114545174
[Epoch 22, Batch 800] loss: 0.005064413590016521
[Epoch 22, Batch 900] loss: 0.0018413247985762382
[Epoch 22, Batch 1000] loss: 0.0017393348754742987
[Epoch 22, Batch 1100] loss: 0.0019457704416308275
[Epoch 22, Batch 1200] loss: 0.010322240647629427
[Epoch 22, Batch 1300] loss: 0.0038616306448258798
[Epoch 22, Batch 1400] loss: 0.0012332279378572152
[Epoch 22, Batch 1500] loss: 0.003163364632872554
[Epoch 22, Batch 1600] loss: 0.001573511971642798
[Epoch 22, Batch 1700] loss: 0.0010919582114416037
[Epoch 22, Batch 1800] loss: 0.007472316601973565
[Epoch 22, Batch 1900] loss: 0.004358579684787287
[Epoch 22, Batch 2000] loss: 0.0013278751799173706
[Epoch 22, Batch 2100] loss: 0.0017363270705149604
[Epoch 22, Batch 2200] loss: 0.0009477096910995719
[Epoch 22, Batch 2300] loss: 0.0086263023013737
[Epoch 22, Batch 2400] loss: 0.00703367487788789
[Epoch 22, Batch 2500] loss: 0.0022272657914396633
[Epoch 22, Batch 2600] loss: 0.0015321837024673357
[Epoch 22, Batch 2700] loss: 0.002778058737189024
[Epoch 22, Batch 2800] loss: 0.0014435933257115963
[Epoch 22, Batch 2900] loss: 0.004823048880743914
[Epoch 22, Batch 3000] loss: 0.0012791697396855285
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9900
Overfitting: 0.0457
[Epoch 23, Batch 100] loss: 0.0006658974090530023
[Epoch 23, Batch 200] loss: 0.0018755992792230814
[Epoch 23, Batch 300] loss: 0.002365279515464209
[Epoch 23, Batch 400] loss: 0.001053973125082166
[Epoch 23, Batch 500] loss: 0.0006271022694544825
[Epoch 23, Batch 600] loss: 0.0007509298020438137
[Epoch 23, Batch 700] loss: 0.0027760978641939004
[Epoch 23, Batch 800] loss: 0.0011670732061032395
[Epoch 23, Batch 900] loss: 0.0012300899081674288
[Epoch 23, Batch 1000] loss: 0.0020232749408492625
[Epoch 23, Batch 1100] loss: 0.006367935362854951
[Epoch 23, Batch 1200] loss: 0.0018482088154586052
[Epoch 23, Batch 1300] loss: 0.0037441021210661064
[Epoch 23, Batch 1400] loss: 0.003002376100754134
[Epoch 23, Batch 1500] loss: 0.0012000664426441432
[Epoch 23, Batch 1600] loss: 0.0008567160161931042
[Epoch 23, Batch 1700] loss: 0.0006530648856106324
[Epoch 23, Batch 1800] loss: 0.0031583417760783303
[Epoch 23, Batch 1900] loss: 0.0010468988701224902
[Epoch 23, Batch 2000] loss: 0.0016365377240637714
[Epoch 23, Batch 2100] loss: 0.0010838770175298862
[Epoch 23, Batch 2200] loss: 0.00046635234282007334
[Epoch 23, Batch 2300] loss: 0.0006722532118743629
[Epoch 23, Batch 2400] loss: 0.0005787467884128717
[Epoch 23, Batch 2500] loss: 0.0005042973712080112
[Epoch 23, Batch 2600] loss: 0.0024045150125587256
[Epoch 23, Batch 2700] loss: 0.001434636695043139
[Epoch 23, Batch 2800] loss: 0.0031784789272799683
[Epoch 23, Batch 2900] loss: 0.0011004357319950486
[Epoch 23, Batch 3000] loss: 0.000518079386284569
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9912
Overfitting: 0.0455
[Epoch 24, Batch 100] loss: 0.00036113933240621064
[Epoch 24, Batch 200] loss: 0.0003929567326254357
[Epoch 24, Batch 300] loss: 0.001436557405105674
[Epoch 24, Batch 400] loss: 0.0015635549254027126
[Epoch 24, Batch 500] loss: 0.0032037532326603026
[Epoch 24, Batch 600] loss: 0.0010590510663086939
[Epoch 24, Batch 700] loss: 0.0006799835642567232
[Epoch 24, Batch 800] loss: 0.0030918206024205474
[Epoch 24, Batch 900] loss: 0.0049918446987876845
[Epoch 24, Batch 1000] loss: 0.0009702957552408975
[Epoch 24, Batch 1100] loss: 0.0016829451297518006
[Epoch 24, Batch 1200] loss: 0.0016240049092616715
[Epoch 24, Batch 1300] loss: 0.0007514723857756778
[Epoch 24, Batch 1400] loss: 0.0007493649420113258
[Epoch 24, Batch 1500] loss: 0.002131047612370587
[Epoch 24, Batch 1600] loss: 0.0013152659990500837
[Epoch 24, Batch 1700] loss: 0.0011971494857102095
[Epoch 24, Batch 1800] loss: 0.001068057977576018
[Epoch 24, Batch 1900] loss: 0.0009980417207109582
[Epoch 24, Batch 2000] loss: 0.0010488150455207545
[Epoch 24, Batch 2100] loss: 0.0011113621295648457
[Epoch 24, Batch 2200] loss: 0.0005576917296690808
[Epoch 24, Batch 2300] loss: 0.0024301598807479506
[Epoch 24, Batch 2400] loss: 0.0016197928762136816
[Epoch 24, Batch 2500] loss: 0.0008141056132739521
[Epoch 24, Batch 2600] loss: 0.0006463457299116015
[Epoch 24, Batch 2700] loss: 0.00046649580093202305
[Epoch 24, Batch 2800] loss: 0.000812354809281075
[Epoch 24, Batch 2900] loss: 0.0010596325260078742
[Epoch 24, Batch 3000] loss: 0.0011831056031639386
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9905
Overfitting: 0.0495
Fold 1 validation loss: 0.0495
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2699822926521303
[Epoch 1, Batch 200] loss: 2.082689414024353
[Epoch 1, Batch 300] loss: 1.251598044037819
[Epoch 1, Batch 400] loss: 0.7816784852743148
[Epoch 1, Batch 500] loss: 0.5689367234706879
[Epoch 1, Batch 600] loss: 0.5121031181514263
[Epoch 1, Batch 700] loss: 0.45628753781318665
[Epoch 1, Batch 800] loss: 0.3914073745906353
[Epoch 1, Batch 900] loss: 0.34435490421950815
[Epoch 1, Batch 1000] loss: 0.30129929814487694
[Epoch 1, Batch 1100] loss: 0.25449549581855535
[Epoch 1, Batch 1200] loss: 0.23894959416240455
[Epoch 1, Batch 1300] loss: 0.2534760221466422
[Epoch 1, Batch 1400] loss: 0.23955013986676932
[Epoch 1, Batch 1500] loss: 0.2228633624035865
[Epoch 1, Batch 1600] loss: 0.178582719611004
[Epoch 1, Batch 1700] loss: 0.17940654955804347
[Epoch 1, Batch 1800] loss: 0.1806079162750393
[Epoch 1, Batch 1900] loss: 0.16268692802637816
[Epoch 1, Batch 2000] loss: 0.1744707453995943
[Epoch 1, Batch 2100] loss: 0.19089098180644215
[Epoch 1, Batch 2200] loss: 0.14700327586382628
[Epoch 1, Batch 2300] loss: 0.14326104692649097
[Epoch 1, Batch 2400] loss: 0.12448695777915418
[Epoch 1, Batch 2500] loss: 0.11391816037939861
[Epoch 1, Batch 2600] loss: 0.13956820658408106
[Epoch 1, Batch 2700] loss: 0.14508267319761217
[Epoch 1, Batch 2800] loss: 0.12296132129151374
[Epoch 1, Batch 2900] loss: 0.11253638132475316
[Epoch 1, Batch 3000] loss: 0.13169470293913035
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1144
Validation Accuracy: 0.9656
Overfitting: 0.1144
Best model saved at epoch 1 with validation loss: 0.1144
[Epoch 2, Batch 100] loss: 0.10034963602665811
[Epoch 2, Batch 200] loss: 0.08635262250434607
[Epoch 2, Batch 300] loss: 0.10836470519891009
[Epoch 2, Batch 400] loss: 0.09466043110704049
[Epoch 2, Batch 500] loss: 0.10812261292710901
[Epoch 2, Batch 600] loss: 0.08335157697321847
[Epoch 2, Batch 700] loss: 0.11866494343499653
[Epoch 2, Batch 800] loss: 0.11241007338569034
[Epoch 2, Batch 900] loss: 0.09295641720527784
[Epoch 2, Batch 1000] loss: 0.09396857691463083
[Epoch 2, Batch 1100] loss: 0.08781021520728245
[Epoch 2, Batch 1200] loss: 0.10472341909538954
[Epoch 2, Batch 1300] loss: 0.08675546780927107
[Epoch 2, Batch 1400] loss: 0.08991926322923974
[Epoch 2, Batch 1500] loss: 0.07789451645920054
[Epoch 2, Batch 1600] loss: 0.0766666304913815
[Epoch 2, Batch 1700] loss: 0.09311957400059327
[Epoch 2, Batch 1800] loss: 0.07642823096131907
[Epoch 2, Batch 1900] loss: 0.09382014348171651
[Epoch 2, Batch 2000] loss: 0.06796010150923394
[Epoch 2, Batch 2100] loss: 0.09089455374458338
[Epoch 2, Batch 2200] loss: 0.0853657940775156
[Epoch 2, Batch 2300] loss: 0.08290717636118643
[Epoch 2, Batch 2400] loss: 0.09319806413725018
[Epoch 2, Batch 2500] loss: 0.07972979033598676
[Epoch 2, Batch 2600] loss: 0.0736375650356058
[Epoch 2, Batch 2700] loss: 0.09576769180130214
[Epoch 2, Batch 2800] loss: 0.07750667522195727
[Epoch 2, Batch 2900] loss: 0.08778019012650475
[Epoch 2, Batch 3000] loss: 0.09076075875200332
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0856
Validation Accuracy: 0.9720
Overfitting: 0.0856
Best model saved at epoch 2 with validation loss: 0.0856
[Epoch 3, Batch 100] loss: 0.05852402462624014
[Epoch 3, Batch 200] loss: 0.05941694376815576
[Epoch 3, Batch 300] loss: 0.07640568547067232
[Epoch 3, Batch 400] loss: 0.062133547178818846
[Epoch 3, Batch 500] loss: 0.06211109151714481
[Epoch 3, Batch 600] loss: 0.06964657095668372
[Epoch 3, Batch 700] loss: 0.06394317652622704
[Epoch 3, Batch 800] loss: 0.053848667916026896
[Epoch 3, Batch 900] loss: 0.07166753324912861
[Epoch 3, Batch 1000] loss: 0.08350156758562662
[Epoch 3, Batch 1100] loss: 0.06093972858972847
[Epoch 3, Batch 1200] loss: 0.07606490773730912
[Epoch 3, Batch 1300] loss: 0.05620988538837992
[Epoch 3, Batch 1400] loss: 0.06286620942119044
[Epoch 3, Batch 1500] loss: 0.036246020709368165
[Epoch 3, Batch 1600] loss: 0.056632626882055774
[Epoch 3, Batch 1700] loss: 0.06396223700139672
[Epoch 3, Batch 1800] loss: 0.05970479937794153
[Epoch 3, Batch 1900] loss: 0.059417684302316046
[Epoch 3, Batch 2000] loss: 0.061195102242636495
[Epoch 3, Batch 2100] loss: 0.04937200165528338
[Epoch 3, Batch 2200] loss: 0.05683437870349735
[Epoch 3, Batch 2300] loss: 0.0474594558699755
[Epoch 3, Batch 2400] loss: 0.05223053009773139
[Epoch 3, Batch 2500] loss: 0.05834280537383165
[Epoch 3, Batch 2600] loss: 0.08476397565798834
[Epoch 3, Batch 2700] loss: 0.06088862541888375
[Epoch 3, Batch 2800] loss: 0.06394367783679628
[Epoch 3, Batch 2900] loss: 0.06536435103509575
[Epoch 3, Batch 3000] loss: 0.04165825706120813
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0670
Validation Accuracy: 0.9789
Overfitting: 0.0670
Best model saved at epoch 3 with validation loss: 0.0670
[Epoch 4, Batch 100] loss: 0.052248564650071785
[Epoch 4, Batch 200] loss: 0.0382479951827554
[Epoch 4, Batch 300] loss: 0.049874053935636764
[Epoch 4, Batch 400] loss: 0.04735747225990053
[Epoch 4, Batch 500] loss: 0.0421112664413522
[Epoch 4, Batch 600] loss: 0.052201599880645516
[Epoch 4, Batch 700] loss: 0.060841874005855064
[Epoch 4, Batch 800] loss: 0.06355382688168902
[Epoch 4, Batch 900] loss: 0.04132617127761477
[Epoch 4, Batch 1000] loss: 0.055084287170320746
[Epoch 4, Batch 1100] loss: 0.04505267007509246
[Epoch 4, Batch 1200] loss: 0.06324875899677863
[Epoch 4, Batch 1300] loss: 0.06785035569162573
[Epoch 4, Batch 1400] loss: 0.04913839565590024
[Epoch 4, Batch 1500] loss: 0.04654085943824612
[Epoch 4, Batch 1600] loss: 0.06086614181753248
[Epoch 4, Batch 1700] loss: 0.047225878539320545
[Epoch 4, Batch 1800] loss: 0.03278583961800905
[Epoch 4, Batch 1900] loss: 0.03801899553218391
[Epoch 4, Batch 2000] loss: 0.03687736197229242
[Epoch 4, Batch 2100] loss: 0.03252592429053038
[Epoch 4, Batch 2200] loss: 0.054186330570519206
[Epoch 4, Batch 2300] loss: 0.04046692693606019
[Epoch 4, Batch 2400] loss: 0.05087035831995308
[Epoch 4, Batch 2500] loss: 0.03957767549785785
[Epoch 4, Batch 2600] loss: 0.050616140573110896
[Epoch 4, Batch 2700] loss: 0.048626288670056965
[Epoch 4, Batch 2800] loss: 0.043141708679468135
[Epoch 4, Batch 2900] loss: 0.05782088578329422
[Epoch 4, Batch 3000] loss: 0.04340937314729672
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0555
Validation Accuracy: 0.9819
Overfitting: 0.0555
Best model saved at epoch 4 with validation loss: 0.0555
[Epoch 5, Batch 100] loss: 0.027361848557484338
[Epoch 5, Batch 200] loss: 0.038987484115859845
[Epoch 5, Batch 300] loss: 0.037352134701504836
[Epoch 5, Batch 400] loss: 0.038592227395420196
[Epoch 5, Batch 500] loss: 0.04005541082151467
[Epoch 5, Batch 600] loss: 0.044464860145562855
[Epoch 5, Batch 700] loss: 0.0636505232116906
[Epoch 5, Batch 800] loss: 0.028101538953196722
[Epoch 5, Batch 900] loss: 0.0249009338876931
[Epoch 5, Batch 1000] loss: 0.03049804554801085
[Epoch 5, Batch 1100] loss: 0.03858550044329604
[Epoch 5, Batch 1200] loss: 0.038646608498384014
[Epoch 5, Batch 1300] loss: 0.030278096051479225
[Epoch 5, Batch 1400] loss: 0.02509887331398204
[Epoch 5, Batch 1500] loss: 0.03146866983901418
[Epoch 5, Batch 1600] loss: 0.03962857137492392
[Epoch 5, Batch 1700] loss: 0.039597229003848045
[Epoch 5, Batch 1800] loss: 0.051465025930083355
[Epoch 5, Batch 1900] loss: 0.055600687187979926
[Epoch 5, Batch 2000] loss: 0.022369736440596172
[Epoch 5, Batch 2100] loss: 0.03446765981017961
[Epoch 5, Batch 2200] loss: 0.04218240768357646
[Epoch 5, Batch 2300] loss: 0.04656044840005052
[Epoch 5, Batch 2400] loss: 0.043230888178222814
[Epoch 5, Batch 2500] loss: 0.0493297077252646
[Epoch 5, Batch 2600] loss: 0.0361807122384198
[Epoch 5, Batch 2700] loss: 0.04067122485488653
[Epoch 5, Batch 2800] loss: 0.043138726732213396
[Epoch 5, Batch 2900] loss: 0.05179774867603555
[Epoch 5, Batch 3000] loss: 0.035286285735492126
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9813
Overfitting: 0.0561
[Epoch 6, Batch 100] loss: 0.023526815018558408
[Epoch 6, Batch 200] loss: 0.022824675001756986
[Epoch 6, Batch 300] loss: 0.031238691407197622
[Epoch 6, Batch 400] loss: 0.03874291287516826
[Epoch 6, Batch 500] loss: 0.03910538366588298
[Epoch 6, Batch 600] loss: 0.043543574309442196
[Epoch 6, Batch 700] loss: 0.027608641707047354
[Epoch 6, Batch 800] loss: 0.028652255595807218
[Epoch 6, Batch 900] loss: 0.044451839872053825
[Epoch 6, Batch 1000] loss: 0.02482715465099318
[Epoch 6, Batch 1100] loss: 0.039176198339191615
[Epoch 6, Batch 1200] loss: 0.04512938036568812
[Epoch 6, Batch 1300] loss: 0.02746224599744892
[Epoch 6, Batch 1400] loss: 0.030926097847841446
[Epoch 6, Batch 1500] loss: 0.03171992003786727
[Epoch 6, Batch 1600] loss: 0.03109751003124984
[Epoch 6, Batch 1700] loss: 0.03659963175829034
[Epoch 6, Batch 1800] loss: 0.020890512340702116
[Epoch 6, Batch 1900] loss: 0.025926625198626426
[Epoch 6, Batch 2000] loss: 0.025959778030846793
[Epoch 6, Batch 2100] loss: 0.023601375018406544
[Epoch 6, Batch 2200] loss: 0.0312403345801431
[Epoch 6, Batch 2300] loss: 0.0265441643941449
[Epoch 6, Batch 2400] loss: 0.04072658991688513
[Epoch 6, Batch 2500] loss: 0.043106567636932595
[Epoch 6, Batch 2600] loss: 0.04455324093796662
[Epoch 6, Batch 2700] loss: 0.03039981439767871
[Epoch 6, Batch 2800] loss: 0.032198613737637063
[Epoch 6, Batch 2900] loss: 0.03221628589606553
[Epoch 6, Batch 3000] loss: 0.035351255972636865
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9857
Overfitting: 0.0496
Best model saved at epoch 6 with validation loss: 0.0496
[Epoch 7, Batch 100] loss: 0.03132372988307907
[Epoch 7, Batch 200] loss: 0.02255916135793086
[Epoch 7, Batch 300] loss: 0.03139733835370862
[Epoch 7, Batch 400] loss: 0.02299163425210281
[Epoch 7, Batch 500] loss: 0.03363683227886213
[Epoch 7, Batch 600] loss: 0.023720736633913476
[Epoch 7, Batch 700] loss: 0.03360533940882306
[Epoch 7, Batch 800] loss: 0.02580093684126041
[Epoch 7, Batch 900] loss: 0.028575989182463672
[Epoch 7, Batch 1000] loss: 0.02211259658302879
[Epoch 7, Batch 1100] loss: 0.032617426523356696
[Epoch 7, Batch 1200] loss: 0.02210629232751671
[Epoch 7, Batch 1300] loss: 0.01319762284943863
[Epoch 7, Batch 1400] loss: 0.03030014971147466
[Epoch 7, Batch 1500] loss: 0.021134788923081942
[Epoch 7, Batch 1600] loss: 0.026871606953500306
[Epoch 7, Batch 1700] loss: 0.044559805892495204
[Epoch 7, Batch 1800] loss: 0.026235147058832807
[Epoch 7, Batch 1900] loss: 0.015212415306741604
[Epoch 7, Batch 2000] loss: 0.023378733495883354
[Epoch 7, Batch 2100] loss: 0.0294941058924087
[Epoch 7, Batch 2200] loss: 0.02920489530042687
[Epoch 7, Batch 2300] loss: 0.017110019918000034
[Epoch 7, Batch 2400] loss: 0.046989433619819464
[Epoch 7, Batch 2500] loss: 0.01587403476012696
[Epoch 7, Batch 2600] loss: 0.031584216346745964
[Epoch 7, Batch 2700] loss: 0.03152288671262795
[Epoch 7, Batch 2800] loss: 0.03264921036650776
[Epoch 7, Batch 2900] loss: 0.018007902816316347
[Epoch 7, Batch 3000] loss: 0.019469640487077413
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9839
Overfitting: 0.0551
[Epoch 8, Batch 100] loss: 0.01622891637158318
[Epoch 8, Batch 200] loss: 0.020246029079935397
[Epoch 8, Batch 300] loss: 0.02095562498714571
[Epoch 8, Batch 400] loss: 0.020614369945396904
[Epoch 8, Batch 500] loss: 0.025343601021177165
[Epoch 8, Batch 600] loss: 0.029386466875002952
[Epoch 8, Batch 700] loss: 0.032728845115416336
[Epoch 8, Batch 800] loss: 0.019337163660529767
[Epoch 8, Batch 900] loss: 0.020003256240415795
[Epoch 8, Batch 1000] loss: 0.020141620920257994
[Epoch 8, Batch 1100] loss: 0.025574877288818243
[Epoch 8, Batch 1200] loss: 0.0193044289374302
[Epoch 8, Batch 1300] loss: 0.02876287892489927
[Epoch 8, Batch 1400] loss: 0.020453992239927176
[Epoch 8, Batch 1500] loss: 0.023307067869900493
[Epoch 8, Batch 1600] loss: 0.019241698344121688
[Epoch 8, Batch 1700] loss: 0.01384345801674499
[Epoch 8, Batch 1800] loss: 0.023320609612201223
[Epoch 8, Batch 1900] loss: 0.017256869123630166
[Epoch 8, Batch 2000] loss: 0.02487063838612812
[Epoch 8, Batch 2100] loss: 0.015654024731029493
[Epoch 8, Batch 2200] loss: 0.022283623504117712
[Epoch 8, Batch 2300] loss: 0.03871428747092068
[Epoch 8, Batch 2400] loss: 0.02620047748026991
[Epoch 8, Batch 2500] loss: 0.023261770958233684
[Epoch 8, Batch 2600] loss: 0.03981377337899175
[Epoch 8, Batch 2700] loss: 0.018712906796572497
[Epoch 8, Batch 2800] loss: 0.021210268257527788
[Epoch 8, Batch 2900] loss: 0.027862221813393262
[Epoch 8, Batch 3000] loss: 0.03724871978745796
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9838
Overfitting: 0.0550
[Epoch 9, Batch 100] loss: 0.01777804388981167
[Epoch 9, Batch 200] loss: 0.011851971102696552
[Epoch 9, Batch 300] loss: 0.012501429548406122
[Epoch 9, Batch 400] loss: 0.025624394657770607
[Epoch 9, Batch 500] loss: 0.0166293748541284
[Epoch 9, Batch 600] loss: 0.024693452369519947
[Epoch 9, Batch 700] loss: 0.01925472240560339
[Epoch 9, Batch 800] loss: 0.013195524154725717
[Epoch 9, Batch 900] loss: 0.016195035253331297
[Epoch 9, Batch 1000] loss: 0.011671483930695104
[Epoch 9, Batch 1100] loss: 0.024691427760553778
[Epoch 9, Batch 1200] loss: 0.01674559420949663
[Epoch 9, Batch 1300] loss: 0.017264298503287135
[Epoch 9, Batch 1400] loss: 0.03406255143854651
[Epoch 9, Batch 1500] loss: 0.021398967282366357
[Epoch 9, Batch 1600] loss: 0.019198229789435573
[Epoch 9, Batch 1700] loss: 0.029941191402140247
[Epoch 9, Batch 1800] loss: 0.017749520068173298
[Epoch 9, Batch 1900] loss: 0.017887081266308086
[Epoch 9, Batch 2000] loss: 0.02057344622317032
[Epoch 9, Batch 2100] loss: 0.02723499386185722
[Epoch 9, Batch 2200] loss: 0.018254984801424144
[Epoch 9, Batch 2300] loss: 0.013284679939624766
[Epoch 9, Batch 2400] loss: 0.023251441165339202
[Epoch 9, Batch 2500] loss: 0.019161465540673817
[Epoch 9, Batch 2600] loss: 0.03255791492766548
[Epoch 9, Batch 2700] loss: 0.010225752566893788
[Epoch 9, Batch 2800] loss: 0.014595998573604448
[Epoch 9, Batch 2900] loss: 0.01849023428179862
[Epoch 9, Batch 3000] loss: 0.024158861055875603
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9843
Overfitting: 0.0529
[Epoch 10, Batch 100] loss: 0.016806467604310454
[Epoch 10, Batch 200] loss: 0.013183906685535476
[Epoch 10, Batch 300] loss: 0.015150604123027734
[Epoch 10, Batch 400] loss: 0.011310257981604082
[Epoch 10, Batch 500] loss: 0.012427141094231047
[Epoch 10, Batch 600] loss: 0.015321051463361072
[Epoch 10, Batch 700] loss: 0.019086234092610538
[Epoch 10, Batch 800] loss: 0.01586531924426481
[Epoch 10, Batch 900] loss: 0.020327278741797274
[Epoch 10, Batch 1000] loss: 0.01617462633055311
[Epoch 10, Batch 1100] loss: 0.022675908324090416
[Epoch 10, Batch 1200] loss: 0.018978783428938186
[Epoch 10, Batch 1300] loss: 0.01865054742213033
[Epoch 10, Batch 1400] loss: 0.019963424349116396
[Epoch 10, Batch 1500] loss: 0.005486135726459907
[Epoch 10, Batch 1600] loss: 0.02167085951577974
[Epoch 10, Batch 1700] loss: 0.02452439247586881
[Epoch 10, Batch 1800] loss: 0.01332252424906983
[Epoch 10, Batch 1900] loss: 0.01535119737189234
[Epoch 10, Batch 2000] loss: 0.03318233091202274
[Epoch 10, Batch 2100] loss: 0.023462435055189416
[Epoch 10, Batch 2200] loss: 0.013252894243814808
[Epoch 10, Batch 2300] loss: 0.015118984463515516
[Epoch 10, Batch 2400] loss: 0.012149755405234828
[Epoch 10, Batch 2500] loss: 0.017064497367341572
[Epoch 10, Batch 2600] loss: 0.029030120192587675
[Epoch 10, Batch 2700] loss: 0.017666159846085064
[Epoch 10, Batch 2800] loss: 0.011962821837050797
[Epoch 10, Batch 2900] loss: 0.014681833597815058
[Epoch 10, Batch 3000] loss: 0.016979407460048605
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9872
Overfitting: 0.0483
Best model saved at epoch 10 with validation loss: 0.0483
[Epoch 11, Batch 100] loss: 0.019797963537675968
[Epoch 11, Batch 200] loss: 0.013693745513082832
[Epoch 11, Batch 300] loss: 0.022585718467125843
[Epoch 11, Batch 400] loss: 0.01153038449538144
[Epoch 11, Batch 500] loss: 0.011590118715830613
[Epoch 11, Batch 600] loss: 0.018636324299368425
[Epoch 11, Batch 700] loss: 0.015110589199048263
[Epoch 11, Batch 800] loss: 0.009215141021941235
[Epoch 11, Batch 900] loss: 0.022407935726996585
[Epoch 11, Batch 1000] loss: 0.028089631390571412
[Epoch 11, Batch 1100] loss: 0.013790016257662501
[Epoch 11, Batch 1200] loss: 0.014410559161133278
[Epoch 11, Batch 1300] loss: 0.007332313905671981
[Epoch 11, Batch 1400] loss: 0.012935149719251058
[Epoch 11, Batch 1500] loss: 0.011381235013068362
[Epoch 11, Batch 1600] loss: 0.012722925569773906
[Epoch 11, Batch 1700] loss: 0.009688074155492358
[Epoch 11, Batch 1800] loss: 0.013884312816271631
[Epoch 11, Batch 1900] loss: 0.015500084541281467
[Epoch 11, Batch 2000] loss: 0.016002460330601025
[Epoch 11, Batch 2100] loss: 0.019519104923074338
[Epoch 11, Batch 2200] loss: 0.007588661809631958
[Epoch 11, Batch 2300] loss: 0.012350505442145731
[Epoch 11, Batch 2400] loss: 0.016075828313287275
[Epoch 11, Batch 2500] loss: 0.012147126011677755
[Epoch 11, Batch 2600] loss: 0.012302573349074919
[Epoch 11, Batch 2700] loss: 0.021602871443765253
[Epoch 11, Batch 2800] loss: 0.020154140972827007
[Epoch 11, Batch 2900] loss: 0.012875461899820948
[Epoch 11, Batch 3000] loss: 0.024284239717635502
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9852
Overfitting: 0.0528
[Epoch 12, Batch 100] loss: 0.020418055300478955
[Epoch 12, Batch 200] loss: 0.009804190560516872
[Epoch 12, Batch 300] loss: 0.004634885170999041
[Epoch 12, Batch 400] loss: 0.01927223904982384
[Epoch 12, Batch 500] loss: 0.010966919765942294
[Epoch 12, Batch 600] loss: 0.009831964180830256
[Epoch 12, Batch 700] loss: 0.00941178794741063
[Epoch 12, Batch 800] loss: 0.008118194826840864
[Epoch 12, Batch 900] loss: 0.006908398307878087
[Epoch 12, Batch 1000] loss: 0.011034758238138239
[Epoch 12, Batch 1100] loss: 0.020704814913096926
[Epoch 12, Batch 1200] loss: 0.02045879201587013
[Epoch 12, Batch 1300] loss: 0.024601627913471022
[Epoch 12, Batch 1400] loss: 0.008807984892243895
[Epoch 12, Batch 1500] loss: 0.01341714128700005
[Epoch 12, Batch 1600] loss: 0.007439391414927741
[Epoch 12, Batch 1700] loss: 0.009475848815679911
[Epoch 12, Batch 1800] loss: 0.013775149574985334
[Epoch 12, Batch 1900] loss: 0.01129382894142509
[Epoch 12, Batch 2000] loss: 0.012726816179419984
[Epoch 12, Batch 2100] loss: 0.016670005299583863
[Epoch 12, Batch 2200] loss: 0.009595133786133374
[Epoch 12, Batch 2300] loss: 0.011462205623374758
[Epoch 12, Batch 2400] loss: 0.01189764714129069
[Epoch 12, Batch 2500] loss: 0.02849035349417136
[Epoch 12, Batch 2600] loss: 0.01635824421806319
[Epoch 12, Batch 2700] loss: 0.01563154853651213
[Epoch 12, Batch 2800] loss: 0.009465836580820905
[Epoch 12, Batch 2900] loss: 0.012539041858713063
[Epoch 12, Batch 3000] loss: 0.011319016873567306
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9868
Overfitting: 0.0540
[Epoch 13, Batch 100] loss: 0.013279152800587326
[Epoch 13, Batch 200] loss: 0.0063725778941307
[Epoch 13, Batch 300] loss: 0.003988768632252686
[Epoch 13, Batch 400] loss: 0.014004871552597251
[Epoch 13, Batch 500] loss: 0.01868984160346372
[Epoch 13, Batch 600] loss: 0.011518827610061635
[Epoch 13, Batch 700] loss: 0.010625342596747488
[Epoch 13, Batch 800] loss: 0.006260316394145775
[Epoch 13, Batch 900] loss: 0.007644545504467715
[Epoch 13, Batch 1000] loss: 0.01360308091357183
[Epoch 13, Batch 1100] loss: 0.007126989431139918
[Epoch 13, Batch 1200] loss: 0.00502043510619842
[Epoch 13, Batch 1300] loss: 0.008639866568037178
[Epoch 13, Batch 1400] loss: 0.015207413129314774
[Epoch 13, Batch 1500] loss: 0.004755228365983157
[Epoch 13, Batch 1600] loss: 0.015080999361944123
[Epoch 13, Batch 1700] loss: 0.02063770805826607
[Epoch 13, Batch 1800] loss: 0.01062780126780126
[Epoch 13, Batch 1900] loss: 0.013532599929567369
[Epoch 13, Batch 2000] loss: 0.021812048964620773
[Epoch 13, Batch 2100] loss: 0.00975207410283474
[Epoch 13, Batch 2200] loss: 0.010386709240437995
[Epoch 13, Batch 2300] loss: 0.00989086027760095
[Epoch 13, Batch 2400] loss: 0.009257388618646018
[Epoch 13, Batch 2500] loss: 0.009231427725885623
[Epoch 13, Batch 2600] loss: 0.01737270232328683
[Epoch 13, Batch 2700] loss: 0.010720250310105256
[Epoch 13, Batch 2800] loss: 0.003357157584323431
[Epoch 13, Batch 2900] loss: 0.0060323224859826045
[Epoch 13, Batch 3000] loss: 0.009249148145299842
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0673
Validation Accuracy: 0.9842
Overfitting: 0.0673
[Epoch 14, Batch 100] loss: 0.015201728825691135
[Epoch 14, Batch 200] loss: 0.006523059911002065
[Epoch 14, Batch 300] loss: 0.005168455466555315
[Epoch 14, Batch 400] loss: 0.005997601307235527
[Epoch 14, Batch 500] loss: 0.006248119022965284
[Epoch 14, Batch 600] loss: 0.010834792385303445
[Epoch 14, Batch 700] loss: 0.0069535332795157955
[Epoch 14, Batch 800] loss: 0.018126997974122788
[Epoch 14, Batch 900] loss: 0.010091794166128239
[Epoch 14, Batch 1000] loss: 0.01134405471224909
[Epoch 14, Batch 1100] loss: 0.008320736437976848
[Epoch 14, Batch 1200] loss: 0.0088760448605899
[Epoch 14, Batch 1300] loss: 0.0030791617397255776
[Epoch 14, Batch 1400] loss: 0.0024329730252702574
[Epoch 14, Batch 1500] loss: 0.0028461257448839207
[Epoch 14, Batch 1600] loss: 0.022508534677310763
[Epoch 14, Batch 1700] loss: 0.0072004055702745975
[Epoch 14, Batch 1800] loss: 0.006537783066178236
[Epoch 14, Batch 1900] loss: 0.012463098200350941
[Epoch 14, Batch 2000] loss: 0.005180649758067375
[Epoch 14, Batch 2100] loss: 0.0051318278824896875
[Epoch 14, Batch 2200] loss: 0.00449538118131386
[Epoch 14, Batch 2300] loss: 0.024525778121449092
[Epoch 14, Batch 2400] loss: 0.02130400281110042
[Epoch 14, Batch 2500] loss: 0.01273624192470379
[Epoch 14, Batch 2600] loss: 0.010858234377865301
[Epoch 14, Batch 2700] loss: 0.011820469920896812
[Epoch 14, Batch 2800] loss: 0.016836657775347704
[Epoch 14, Batch 2900] loss: 0.008300618853049856
[Epoch 14, Batch 3000] loss: 0.00912819561016022
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9863
Overfitting: 0.0567
[Epoch 15, Batch 100] loss: 0.019378202264820173
[Epoch 15, Batch 200] loss: 0.00749849242062055
[Epoch 15, Batch 300] loss: 0.006134216539392128
[Epoch 15, Batch 400] loss: 0.008786586870974134
[Epoch 15, Batch 500] loss: 0.004603548650147786
[Epoch 15, Batch 600] loss: 0.00545509244564073
[Epoch 15, Batch 700] loss: 0.008126074847345989
[Epoch 15, Batch 800] loss: 0.005436664403346185
[Epoch 15, Batch 900] loss: 0.004216508660507543
[Epoch 15, Batch 1000] loss: 0.008513943744110292
[Epoch 15, Batch 1100] loss: 0.00489568983825393
[Epoch 15, Batch 1200] loss: 0.005568732680017092
[Epoch 15, Batch 1300] loss: 0.0085748370551687
[Epoch 15, Batch 1400] loss: 0.015509483585865382
[Epoch 15, Batch 1500] loss: 0.009327666191102252
[Epoch 15, Batch 1600] loss: 0.009076113052303754
[Epoch 15, Batch 1700] loss: 0.007032207372042194
[Epoch 15, Batch 1800] loss: 0.01155712349840087
[Epoch 15, Batch 1900] loss: 0.009059365826728935
[Epoch 15, Batch 2000] loss: 0.010929018932456529
[Epoch 15, Batch 2100] loss: 0.00863991000122951
[Epoch 15, Batch 2200] loss: 0.005677888894450405
[Epoch 15, Batch 2300] loss: 0.006353949135700532
[Epoch 15, Batch 2400] loss: 0.010220172283020475
[Epoch 15, Batch 2500] loss: 0.012760243558122965
[Epoch 15, Batch 2600] loss: 0.010057176189329766
[Epoch 15, Batch 2700] loss: 0.021537483187745465
[Epoch 15, Batch 2800] loss: 0.008236169215467725
[Epoch 15, Batch 2900] loss: 0.008094101631641024
[Epoch 15, Batch 3000] loss: 0.013587614634996043
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9872
Overfitting: 0.0543
[Epoch 16, Batch 100] loss: 0.006202651521225562
[Epoch 16, Batch 200] loss: 0.005597499483726552
[Epoch 16, Batch 300] loss: 0.007493896026990115
[Epoch 16, Batch 400] loss: 0.0063904410159216244
[Epoch 16, Batch 500] loss: 0.006634906384799137
[Epoch 16, Batch 600] loss: 0.0046066430831479014
[Epoch 16, Batch 700] loss: 0.0026620773397098675
[Epoch 16, Batch 800] loss: 0.0020113353811348133
[Epoch 16, Batch 900] loss: 0.009762342142615808
[Epoch 16, Batch 1000] loss: 0.014125820224049903
[Epoch 16, Batch 1100] loss: 0.013353580515843077
[Epoch 16, Batch 1200] loss: 0.005543192751460992
[Epoch 16, Batch 1300] loss: 0.005731681117736116
[Epoch 16, Batch 1400] loss: 0.010154269272306919
[Epoch 16, Batch 1500] loss: 0.009154202233717683
[Epoch 16, Batch 1600] loss: 0.0016349628254693016
[Epoch 16, Batch 1700] loss: 0.003971732051163599
[Epoch 16, Batch 1800] loss: 0.006528303253032846
[Epoch 16, Batch 1900] loss: 0.005602719265667701
[Epoch 16, Batch 2000] loss: 0.008210172080775919
[Epoch 16, Batch 2100] loss: 0.014230538382574877
[Epoch 16, Batch 2200] loss: 0.0034682147973012435
[Epoch 16, Batch 2300] loss: 0.0029179619630804155
[Epoch 16, Batch 2400] loss: 0.006913540391784636
[Epoch 16, Batch 2500] loss: 0.009431073671143509
[Epoch 16, Batch 2600] loss: 0.004651248004233821
[Epoch 16, Batch 2700] loss: 0.008162117162842151
[Epoch 16, Batch 2800] loss: 0.006554282319088997
[Epoch 16, Batch 2900] loss: 0.006399859768985152
[Epoch 16, Batch 3000] loss: 0.006548279366409133
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9863
Overfitting: 0.0603
[Epoch 17, Batch 100] loss: 0.00251519981092315
[Epoch 17, Batch 200] loss: 0.002800945507802055
[Epoch 17, Batch 300] loss: 0.0031623189056745105
[Epoch 17, Batch 400] loss: 0.0016126819306180097
[Epoch 17, Batch 500] loss: 0.00370384983487952
[Epoch 17, Batch 600] loss: 0.008228234027567395
[Epoch 17, Batch 700] loss: 0.011362655709997399
[Epoch 17, Batch 800] loss: 0.011796981721809062
[Epoch 17, Batch 900] loss: 0.007131163587989704
[Epoch 17, Batch 1000] loss: 0.004072142349766637
[Epoch 17, Batch 1100] loss: 0.004163837369747511
[Epoch 17, Batch 1200] loss: 0.005765885172523895
[Epoch 17, Batch 1300] loss: 0.0062226235314665245
[Epoch 17, Batch 1400] loss: 0.011770229415616314
[Epoch 17, Batch 1500] loss: 0.010774446866639096
[Epoch 17, Batch 1600] loss: 0.007828235715724077
[Epoch 17, Batch 1700] loss: 0.0055853554829366206
[Epoch 17, Batch 1800] loss: 0.0076704496758020465
[Epoch 17, Batch 1900] loss: 0.006104996594874592
[Epoch 17, Batch 2000] loss: 0.005570849946668659
[Epoch 17, Batch 2100] loss: 0.0031953936348526214
[Epoch 17, Batch 2200] loss: 0.0035096596216749277
[Epoch 17, Batch 2300] loss: 0.008395624455085909
[Epoch 17, Batch 2400] loss: 0.01436026501780816
[Epoch 17, Batch 2500] loss: 0.005476090501939517
[Epoch 17, Batch 2600] loss: 0.006890742319209267
[Epoch 17, Batch 2700] loss: 0.017821221707097264
[Epoch 17, Batch 2800] loss: 0.006422985566357511
[Epoch 17, Batch 2900] loss: 0.0038198851775098318
[Epoch 17, Batch 3000] loss: 0.006833406384828322
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9876
Overfitting: 0.0567
[Epoch 18, Batch 100] loss: 0.004202876250510599
[Epoch 18, Batch 200] loss: 0.0023942116014495697
[Epoch 18, Batch 300] loss: 0.0015349930997538763
[Epoch 18, Batch 400] loss: 0.006349630847381604
[Epoch 18, Batch 500] loss: 0.0033308720785913694
[Epoch 18, Batch 600] loss: 0.00277746109616146
[Epoch 18, Batch 700] loss: 0.005327167232267698
[Epoch 18, Batch 800] loss: 0.0023764171525846225
[Epoch 18, Batch 900] loss: 0.005299003155582796
[Epoch 18, Batch 1000] loss: 0.00422845327104028
[Epoch 18, Batch 1100] loss: 0.0064817189303227
[Epoch 18, Batch 1200] loss: 0.008069241188229626
[Epoch 18, Batch 1300] loss: 0.005350416688136192
[Epoch 18, Batch 1400] loss: 0.0014741923296165283
[Epoch 18, Batch 1500] loss: 0.0036587246284602772
[Epoch 18, Batch 1600] loss: 0.009719099724071612
[Epoch 18, Batch 1700] loss: 0.008043893914457385
[Epoch 18, Batch 1800] loss: 0.003346501039072791
[Epoch 18, Batch 1900] loss: 0.004402361716854557
[Epoch 18, Batch 2000] loss: 0.004272309413216817
[Epoch 18, Batch 2100] loss: 0.007306299692577341
[Epoch 18, Batch 2200] loss: 0.005964902566856267
[Epoch 18, Batch 2300] loss: 0.0026557461149923256
[Epoch 18, Batch 2400] loss: 0.004551103146760624
[Epoch 18, Batch 2500] loss: 0.009472984586723214
[Epoch 18, Batch 2600] loss: 0.0014183717742366753
[Epoch 18, Batch 2700] loss: 0.002558174560984412
[Epoch 18, Batch 2800] loss: 0.008858075538785214
[Epoch 18, Batch 2900] loss: 0.004454105413209959
[Epoch 18, Batch 3000] loss: 0.006762651379699349
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0717
Validation Accuracy: 0.9851
Overfitting: 0.0717
[Epoch 19, Batch 100] loss: 0.0038040991440044538
[Epoch 19, Batch 200] loss: 0.005622856091225686
[Epoch 19, Batch 300] loss: 0.003660613744497141
[Epoch 19, Batch 400] loss: 0.004126801213938904
[Epoch 19, Batch 500] loss: 0.0019499866246854936
[Epoch 19, Batch 600] loss: 0.008804041406216356
[Epoch 19, Batch 700] loss: 0.011864866302989868
[Epoch 19, Batch 800] loss: 0.002499218787932804
[Epoch 19, Batch 900] loss: 0.0011642011803445484
[Epoch 19, Batch 1000] loss: 0.004010233371038794
[Epoch 19, Batch 1100] loss: 0.0022794537748421816
[Epoch 19, Batch 1200] loss: 0.0009973489937266321
[Epoch 19, Batch 1300] loss: 0.0040460259042771445
[Epoch 19, Batch 1400] loss: 0.009176069871062112
[Epoch 19, Batch 1500] loss: 0.002958586312614102
[Epoch 19, Batch 1600] loss: 0.006976111057483081
[Epoch 19, Batch 1700] loss: 0.0022005705309226186
[Epoch 19, Batch 1800] loss: 0.004566307657369179
[Epoch 19, Batch 1900] loss: 0.003662176765223393
[Epoch 19, Batch 2000] loss: 0.003414430606320593
[Epoch 19, Batch 2100] loss: 0.003082063885583466
[Epoch 19, Batch 2200] loss: 0.010112044333834263
[Epoch 19, Batch 2300] loss: 0.0063365244715168955
[Epoch 19, Batch 2400] loss: 0.012746494686330151
[Epoch 19, Batch 2500] loss: 0.007100875503312522
[Epoch 19, Batch 2600] loss: 0.004181773104330659
[Epoch 19, Batch 2700] loss: 0.005843647406416039
[Epoch 19, Batch 2800] loss: 0.014101454700540899
[Epoch 19, Batch 2900] loss: 0.0035128953962062326
[Epoch 19, Batch 3000] loss: 0.006082898295293262
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0634
Validation Accuracy: 0.9864
Overfitting: 0.0634
[Epoch 20, Batch 100] loss: 0.007391085569029201
[Epoch 20, Batch 200] loss: 0.013763534273064124
[Epoch 20, Batch 300] loss: 0.005182157942949743
[Epoch 20, Batch 400] loss: 0.0018419988473851844
[Epoch 20, Batch 500] loss: 0.003050107068023067
[Epoch 20, Batch 600] loss: 0.0024840164289861378
[Epoch 20, Batch 700] loss: 0.0032184215771849265
[Epoch 20, Batch 800] loss: 0.0015712303085079781
[Epoch 20, Batch 900] loss: 0.0045908208535922765
[Epoch 20, Batch 1000] loss: 0.005097298520944378
[Epoch 20, Batch 1100] loss: 0.007763258204639669
[Epoch 20, Batch 1200] loss: 0.004050790882689626
[Epoch 20, Batch 1300] loss: 0.007967186860291235
[Epoch 20, Batch 1400] loss: 0.005428277448811514
[Epoch 20, Batch 1500] loss: 0.0075026492120838385
[Epoch 20, Batch 1600] loss: 0.003610133562416422
[Epoch 20, Batch 1700] loss: 0.005369683465027038
[Epoch 20, Batch 1800] loss: 0.002900070163913853
[Epoch 20, Batch 1900] loss: 0.008055937451402428
[Epoch 20, Batch 2000] loss: 0.0020242634574901787
[Epoch 20, Batch 2100] loss: 0.009412782292301927
[Epoch 20, Batch 2200] loss: 0.0038517961532377855
[Epoch 20, Batch 2300] loss: 0.004298613318396747
[Epoch 20, Batch 2400] loss: 0.004680663987664673
[Epoch 20, Batch 2500] loss: 0.0025730339329822984
[Epoch 20, Batch 2600] loss: 0.003570817985211647
[Epoch 20, Batch 2700] loss: 0.007257217881468136
[Epoch 20, Batch 2800] loss: 0.0035071705904803708
[Epoch 20, Batch 2900] loss: 0.007143976108522452
[Epoch 20, Batch 3000] loss: 0.010957840165264656
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0704
Validation Accuracy: 0.9839
Overfitting: 0.0704
[Epoch 21, Batch 100] loss: 0.007638124625126466
[Epoch 21, Batch 200] loss: 0.002958634311833919
[Epoch 21, Batch 300] loss: 0.0026410958755070622
[Epoch 21, Batch 400] loss: 0.007232405135507634
[Epoch 21, Batch 500] loss: 0.005894960066912631
[Epoch 21, Batch 600] loss: 0.002878222049586725
[Epoch 21, Batch 700] loss: 0.007919539803761779
[Epoch 21, Batch 800] loss: 0.004420474939529342
[Epoch 21, Batch 900] loss: 0.0022810504305775226
[Epoch 21, Batch 1000] loss: 0.0021003455115396717
[Epoch 21, Batch 1100] loss: 0.004692630805692488
[Epoch 21, Batch 1200] loss: 0.005987131958157761
[Epoch 21, Batch 1300] loss: 0.0021380589843533926
[Epoch 21, Batch 1400] loss: 0.0019303025008679242
[Epoch 21, Batch 1500] loss: 0.004742736639616964
[Epoch 21, Batch 1600] loss: 0.0020971009051501
[Epoch 21, Batch 1700] loss: 0.004006022845401276
[Epoch 21, Batch 1800] loss: 0.009195359957709854
[Epoch 21, Batch 1900] loss: 0.003165875550056967
[Epoch 21, Batch 2000] loss: 0.004332198656585433
[Epoch 21, Batch 2100] loss: 0.0037965011286755865
[Epoch 21, Batch 2200] loss: 0.0027390057726563556
[Epoch 21, Batch 2300] loss: 0.002676014845332304
[Epoch 21, Batch 2400] loss: 0.012422244766819973
[Epoch 21, Batch 2500] loss: 0.0019244604293714928
[Epoch 21, Batch 2600] loss: 0.006039079694252365
[Epoch 21, Batch 2700] loss: 0.001485860656320881
[Epoch 21, Batch 2800] loss: 0.0006666400974847875
[Epoch 21, Batch 2900] loss: 0.0016345258366310133
[Epoch 21, Batch 3000] loss: 0.004969567795366742
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0631
Validation Accuracy: 0.9875
Overfitting: 0.0631
[Epoch 22, Batch 100] loss: 0.0023829861314422374
[Epoch 22, Batch 200] loss: 0.0019252602807364383
[Epoch 22, Batch 300] loss: 0.0018994617976949258
[Epoch 22, Batch 400] loss: 0.0027686356759348742
[Epoch 22, Batch 500] loss: 0.0013950078651854625
[Epoch 22, Batch 600] loss: 0.0008704754243863987
[Epoch 22, Batch 700] loss: 0.0016065606273568988
[Epoch 22, Batch 800] loss: 0.0052086968691483545
[Epoch 22, Batch 900] loss: 0.0029007815428366258
[Epoch 22, Batch 1000] loss: 0.0007972278405281941
[Epoch 22, Batch 1100] loss: 0.0028897456394798835
[Epoch 22, Batch 1200] loss: 0.001567744341002708
[Epoch 22, Batch 1300] loss: 0.00392106062159371
[Epoch 22, Batch 1400] loss: 0.003467529877090669
[Epoch 22, Batch 1500] loss: 0.003085941319160952
[Epoch 22, Batch 1600] loss: 0.0018241517767251026
[Epoch 22, Batch 1700] loss: 0.0022254707093657088
[Epoch 22, Batch 1800] loss: 0.001397513614953141
[Epoch 22, Batch 1900] loss: 0.005152815987937202
[Epoch 22, Batch 2000] loss: 0.0014893095622429088
[Epoch 22, Batch 2100] loss: 0.0014782233366202036
[Epoch 22, Batch 2200] loss: 0.003316248391157011
[Epoch 22, Batch 2300] loss: 0.002060293342967583
[Epoch 22, Batch 2400] loss: 0.0012576413700276135
[Epoch 22, Batch 2500] loss: 0.0026539320297403178
[Epoch 22, Batch 2600] loss: 0.001386956325702009
[Epoch 22, Batch 2700] loss: 0.0006492935999984084
[Epoch 22, Batch 2800] loss: 0.002761134665766747
[Epoch 22, Batch 2900] loss: 0.000393236238992678
[Epoch 22, Batch 3000] loss: 0.0012677031638207836
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0670
Validation Accuracy: 0.9869
Overfitting: 0.0670
[Epoch 23, Batch 100] loss: 0.00224053560159291
[Epoch 23, Batch 200] loss: 0.001226937902231171
[Epoch 23, Batch 300] loss: 0.0010336831406371338
[Epoch 23, Batch 400] loss: 0.001156997874522716
[Epoch 23, Batch 500] loss: 0.0009424262136862094
[Epoch 23, Batch 600] loss: 0.00043753626333057125
[Epoch 23, Batch 700] loss: 0.0011750097493612088
[Epoch 23, Batch 800] loss: 0.0013222994895117069
[Epoch 23, Batch 900] loss: 0.0011847691894265467
[Epoch 23, Batch 1000] loss: 0.002089941053071982
[Epoch 23, Batch 1100] loss: 0.0007384391544070467
[Epoch 23, Batch 1200] loss: 0.0007412382216104873
[Epoch 23, Batch 1300] loss: 0.004873234398255164
[Epoch 23, Batch 1400] loss: 0.0038588472084765614
[Epoch 23, Batch 1500] loss: 0.0033260852284983855
[Epoch 23, Batch 1600] loss: 0.0011708076413719938
[Epoch 23, Batch 1700] loss: 0.0011861975648178459
[Epoch 23, Batch 1800] loss: 0.0033756950277609122
[Epoch 23, Batch 1900] loss: 0.0018272640461665902
[Epoch 23, Batch 2000] loss: 0.0018417362053435938
[Epoch 23, Batch 2100] loss: 0.0023786530988611433
[Epoch 23, Batch 2200] loss: 0.0030071689762723964
[Epoch 23, Batch 2300] loss: 0.007078286194409031
[Epoch 23, Batch 2400] loss: 0.003523937782793638
[Epoch 23, Batch 2500] loss: 0.0007576413315300101
[Epoch 23, Batch 2600] loss: 0.0020609053211222772
[Epoch 23, Batch 2700] loss: 0.004925407335172061
[Epoch 23, Batch 2800] loss: 0.000976995563271288
[Epoch 23, Batch 2900] loss: 0.0012163138912837112
[Epoch 23, Batch 3000] loss: 0.0013989681374327035
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0645
Validation Accuracy: 0.9878
Overfitting: 0.0645
[Epoch 24, Batch 100] loss: 0.0036248569266147967
[Epoch 24, Batch 200] loss: 0.0015649728870812396
[Epoch 24, Batch 300] loss: 0.000669860483429403
[Epoch 24, Batch 400] loss: 0.0009374337239771035
[Epoch 24, Batch 500] loss: 0.0015340248546002755
[Epoch 24, Batch 600] loss: 0.0011291159696503429
[Epoch 24, Batch 700] loss: 0.0012986456680749825
[Epoch 24, Batch 800] loss: 0.0025744226237372912
[Epoch 24, Batch 900] loss: 0.0008311740240874244
[Epoch 24, Batch 1000] loss: 0.0007074359067640046
[Epoch 24, Batch 1100] loss: 0.0012291785895220642
[Epoch 24, Batch 1200] loss: 0.0016031842079411262
[Epoch 24, Batch 1300] loss: 0.001109590953712214
[Epoch 24, Batch 1400] loss: 0.000531370863298406
[Epoch 24, Batch 1500] loss: 0.0008299162747773892
[Epoch 24, Batch 1600] loss: 0.0006249769665325644
[Epoch 24, Batch 1700] loss: 0.00045442285524450733
[Epoch 24, Batch 1800] loss: 0.0013790117200592534
[Epoch 24, Batch 1900] loss: 0.000715337579264883
[Epoch 24, Batch 2000] loss: 0.001539658959602974
[Epoch 24, Batch 2100] loss: 0.0006086623693431647
[Epoch 24, Batch 2200] loss: 0.0005830548573052852
[Epoch 24, Batch 2300] loss: 0.0027653074273175805
[Epoch 24, Batch 2400] loss: 0.0013534659163499897
[Epoch 24, Batch 2500] loss: 0.00025077966659850406
[Epoch 24, Batch 2600] loss: 0.0002517715839031709
[Epoch 24, Batch 2700] loss: 0.0006949080370171767
[Epoch 24, Batch 2800] loss: 0.0007838473558979154
[Epoch 24, Batch 2900] loss: 0.0007884466273891632
[Epoch 24, Batch 3000] loss: 0.004128653841488727
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0821
Validation Accuracy: 0.9851
Overfitting: 0.0821
Fold 2 validation loss: 0.0821
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.285428249835968
[Epoch 1, Batch 200] loss: 2.213072509765625
[Epoch 1, Batch 300] loss: 1.718811057806015
[Epoch 1, Batch 400] loss: 0.8368856707215309
[Epoch 1, Batch 500] loss: 0.6162301769852638
[Epoch 1, Batch 600] loss: 0.5192151287198067
[Epoch 1, Batch 700] loss: 0.3980916772037745
[Epoch 1, Batch 800] loss: 0.3902452979236841
[Epoch 1, Batch 900] loss: 0.31813252963125704
[Epoch 1, Batch 1000] loss: 0.2771683888323605
[Epoch 1, Batch 1100] loss: 0.269795434102416
[Epoch 1, Batch 1200] loss: 0.26678476378321647
[Epoch 1, Batch 1300] loss: 0.21015063393861055
[Epoch 1, Batch 1400] loss: 0.1949232653900981
[Epoch 1, Batch 1500] loss: 0.2350057948101312
[Epoch 1, Batch 1600] loss: 0.1872532965056598
[Epoch 1, Batch 1700] loss: 0.18439326718449592
[Epoch 1, Batch 1800] loss: 0.2007665823865682
[Epoch 1, Batch 1900] loss: 0.1825254794303328
[Epoch 1, Batch 2000] loss: 0.15974155278876423
[Epoch 1, Batch 2100] loss: 0.15442929022945465
[Epoch 1, Batch 2200] loss: 0.14477228805422782
[Epoch 1, Batch 2300] loss: 0.14018266600556673
[Epoch 1, Batch 2400] loss: 0.13732751020696013
[Epoch 1, Batch 2500] loss: 0.1758236926794052
[Epoch 1, Batch 2600] loss: 0.13397530659101903
[Epoch 1, Batch 2700] loss: 0.10223693403182552
[Epoch 1, Batch 2800] loss: 0.11991191726876423
[Epoch 1, Batch 2900] loss: 0.1285078355204314
[Epoch 1, Batch 3000] loss: 0.1200968302716501
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1402
Validation Accuracy: 0.9553
Overfitting: 0.1402
Best model saved at epoch 1 with validation loss: 0.1402
[Epoch 2, Batch 100] loss: 0.11231680659810081
[Epoch 2, Batch 200] loss: 0.11540749087929726
[Epoch 2, Batch 300] loss: 0.0909979206090793
[Epoch 2, Batch 400] loss: 0.12855573988286778
[Epoch 2, Batch 500] loss: 0.08307835564482957
[Epoch 2, Batch 600] loss: 0.12190907072741539
[Epoch 2, Batch 700] loss: 0.10475471237208694
[Epoch 2, Batch 800] loss: 0.08011566136032343
[Epoch 2, Batch 900] loss: 0.10927012102911249
[Epoch 2, Batch 1000] loss: 0.10147380100796
[Epoch 2, Batch 1100] loss: 0.08633461329271086
[Epoch 2, Batch 1200] loss: 0.11277214088244364
[Epoch 2, Batch 1300] loss: 0.08370647901669144
[Epoch 2, Batch 1400] loss: 0.09896753818844445
[Epoch 2, Batch 1500] loss: 0.07955786857521162
[Epoch 2, Batch 1600] loss: 0.10068661433528177
[Epoch 2, Batch 1700] loss: 0.09316151477280073
[Epoch 2, Batch 1800] loss: 0.09436886661802418
[Epoch 2, Batch 1900] loss: 0.09835904302773997
[Epoch 2, Batch 2000] loss: 0.08366263378644362
[Epoch 2, Batch 2100] loss: 0.07332353980862535
[Epoch 2, Batch 2200] loss: 0.09958455729327398
[Epoch 2, Batch 2300] loss: 0.08293871780042536
[Epoch 2, Batch 2400] loss: 0.09063272036146372
[Epoch 2, Batch 2500] loss: 0.072833210604731
[Epoch 2, Batch 2600] loss: 0.07096950232516974
[Epoch 2, Batch 2700] loss: 0.07789173484314232
[Epoch 2, Batch 2800] loss: 0.08873991359840147
[Epoch 2, Batch 2900] loss: 0.10215361620765179
[Epoch 2, Batch 3000] loss: 0.06019835039274767
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0787
Validation Accuracy: 0.9762
Overfitting: 0.0787
Best model saved at epoch 2 with validation loss: 0.0787
[Epoch 3, Batch 100] loss: 0.0716226558375638
[Epoch 3, Batch 200] loss: 0.06498300470528193
[Epoch 3, Batch 300] loss: 0.07290223328396678
[Epoch 3, Batch 400] loss: 0.05200718358391896
[Epoch 3, Batch 500] loss: 0.06221466390474234
[Epoch 3, Batch 600] loss: 0.08431920574512333
[Epoch 3, Batch 700] loss: 0.05026892416062765
[Epoch 3, Batch 800] loss: 0.05873243327136152
[Epoch 3, Batch 900] loss: 0.06001716519705951
[Epoch 3, Batch 1000] loss: 0.06776209561445284
[Epoch 3, Batch 1100] loss: 0.06724910152843222
[Epoch 3, Batch 1200] loss: 0.0940627076313831
[Epoch 3, Batch 1300] loss: 0.0696370524552185
[Epoch 3, Batch 1400] loss: 0.06505032305431087
[Epoch 3, Batch 1500] loss: 0.05177663936163299
[Epoch 3, Batch 1600] loss: 0.06671929045580327
[Epoch 3, Batch 1700] loss: 0.05728316004795488
[Epoch 3, Batch 1800] loss: 0.06576500443421537
[Epoch 3, Batch 1900] loss: 0.07363995110499673
[Epoch 3, Batch 2000] loss: 0.06263538199826144
[Epoch 3, Batch 2100] loss: 0.07208399927709251
[Epoch 3, Batch 2200] loss: 0.0587946337275207
[Epoch 3, Batch 2300] loss: 0.05454449029930401
[Epoch 3, Batch 2400] loss: 0.06607132745208219
[Epoch 3, Batch 2500] loss: 0.04555212762352312
[Epoch 3, Batch 2600] loss: 0.06766192817944101
[Epoch 3, Batch 2700] loss: 0.06836344653071137
[Epoch 3, Batch 2800] loss: 0.05184688871871913
[Epoch 3, Batch 2900] loss: 0.05299079378892202
[Epoch 3, Batch 3000] loss: 0.04198355669883313
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0654
Validation Accuracy: 0.9798
Overfitting: 0.0654
Best model saved at epoch 3 with validation loss: 0.0654
[Epoch 4, Batch 100] loss: 0.05682984370854683
[Epoch 4, Batch 200] loss: 0.059964952016598544
[Epoch 4, Batch 300] loss: 0.043754741069860756
[Epoch 4, Batch 400] loss: 0.04378172635217197
[Epoch 4, Batch 500] loss: 0.04245647509786068
[Epoch 4, Batch 600] loss: 0.05378871547844028
[Epoch 4, Batch 700] loss: 0.042802623790921646
[Epoch 4, Batch 800] loss: 0.06482027602265589
[Epoch 4, Batch 900] loss: 0.05271134169539437
[Epoch 4, Batch 1000] loss: 0.042206834539538246
[Epoch 4, Batch 1100] loss: 0.05083519201871241
[Epoch 4, Batch 1200] loss: 0.0467738448624732
[Epoch 4, Batch 1300] loss: 0.06400907883915352
[Epoch 4, Batch 1400] loss: 0.04998197966866428
[Epoch 4, Batch 1500] loss: 0.055635395997960586
[Epoch 4, Batch 1600] loss: 0.043641300093440805
[Epoch 4, Batch 1700] loss: 0.054299705317243936
[Epoch 4, Batch 1800] loss: 0.051388590380665844
[Epoch 4, Batch 1900] loss: 0.054187905747094194
[Epoch 4, Batch 2000] loss: 0.07164989236160181
[Epoch 4, Batch 2100] loss: 0.04576916551683098
[Epoch 4, Batch 2200] loss: 0.03291608980303863
[Epoch 4, Batch 2300] loss: 0.05202281567791942
[Epoch 4, Batch 2400] loss: 0.05345601242792327
[Epoch 4, Batch 2500] loss: 0.052892159174662084
[Epoch 4, Batch 2600] loss: 0.0718198437152023
[Epoch 4, Batch 2700] loss: 0.04028968247177545
[Epoch 4, Batch 2800] loss: 0.04862920824511093
[Epoch 4, Batch 2900] loss: 0.04776075640125782
[Epoch 4, Batch 3000] loss: 0.026875284667185043
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9837
Overfitting: 0.0539
Best model saved at epoch 4 with validation loss: 0.0539
[Epoch 5, Batch 100] loss: 0.032484630680119156
[Epoch 5, Batch 200] loss: 0.054394714300979106
[Epoch 5, Batch 300] loss: 0.04015765619900776
[Epoch 5, Batch 400] loss: 0.025723210370051673
[Epoch 5, Batch 500] loss: 0.046762528722247225
[Epoch 5, Batch 600] loss: 0.05559553081606282
[Epoch 5, Batch 700] loss: 0.0381016350221762
[Epoch 5, Batch 800] loss: 0.05600237553000625
[Epoch 5, Batch 900] loss: 0.03782934783375822
[Epoch 5, Batch 1000] loss: 0.03752483399672201
[Epoch 5, Batch 1100] loss: 0.04077630393148866
[Epoch 5, Batch 1200] loss: 0.03945673169044312
[Epoch 5, Batch 1300] loss: 0.021897219114907784
[Epoch 5, Batch 1400] loss: 0.054275090571900365
[Epoch 5, Batch 1500] loss: 0.029523153474146965
[Epoch 5, Batch 1600] loss: 0.041278642464312724
[Epoch 5, Batch 1700] loss: 0.04195569533796515
[Epoch 5, Batch 1800] loss: 0.026423795969749336
[Epoch 5, Batch 1900] loss: 0.05072328543712502
[Epoch 5, Batch 2000] loss: 0.05706466353221913
[Epoch 5, Batch 2100] loss: 0.04670020552730421
[Epoch 5, Batch 2200] loss: 0.04606577131577069
[Epoch 5, Batch 2300] loss: 0.031959418501064644
[Epoch 5, Batch 2400] loss: 0.03686521001160145
[Epoch 5, Batch 2500] loss: 0.03386311005393509
[Epoch 5, Batch 2600] loss: 0.041206209086376476
[Epoch 5, Batch 2700] loss: 0.032291956560511606
[Epoch 5, Batch 2800] loss: 0.03515293344709789
[Epoch 5, Batch 2900] loss: 0.048928223990369585
[Epoch 5, Batch 3000] loss: 0.04618082878587302
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0541
Validation Accuracy: 0.9837
Overfitting: 0.0541
[Epoch 6, Batch 100] loss: 0.03375384139770176
[Epoch 6, Batch 200] loss: 0.025673225034115604
[Epoch 6, Batch 300] loss: 0.0349192443870561
[Epoch 6, Batch 400] loss: 0.04027651247117319
[Epoch 6, Batch 500] loss: 0.03600878403645766
[Epoch 6, Batch 600] loss: 0.024759252371150068
[Epoch 6, Batch 700] loss: 0.04281963997367711
[Epoch 6, Batch 800] loss: 0.025674679575313348
[Epoch 6, Batch 900] loss: 0.020686320011591305
[Epoch 6, Batch 1000] loss: 0.030260324687696995
[Epoch 6, Batch 1100] loss: 0.030569305271201302
[Epoch 6, Batch 1200] loss: 0.02147548776185431
[Epoch 6, Batch 1300] loss: 0.03460477315224125
[Epoch 6, Batch 1400] loss: 0.031281474366114705
[Epoch 6, Batch 1500] loss: 0.05340421981323743
[Epoch 6, Batch 1600] loss: 0.04691399328628904
[Epoch 6, Batch 1700] loss: 0.04251445855916245
[Epoch 6, Batch 1800] loss: 0.03356722420983715
[Epoch 6, Batch 1900] loss: 0.04142692115492537
[Epoch 6, Batch 2000] loss: 0.0362226374738384
[Epoch 6, Batch 2100] loss: 0.02813184026228555
[Epoch 6, Batch 2200] loss: 0.0511515872614109
[Epoch 6, Batch 2300] loss: 0.027088251305831364
[Epoch 6, Batch 2400] loss: 0.030000919627855182
[Epoch 6, Batch 2500] loss: 0.029322035484219668
[Epoch 6, Batch 2600] loss: 0.033483508206991246
[Epoch 6, Batch 2700] loss: 0.034238864330545765
[Epoch 6, Batch 2800] loss: 0.02499192288145423
[Epoch 6, Batch 2900] loss: 0.034262675048958045
[Epoch 6, Batch 3000] loss: 0.043240159698762
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9870
Overfitting: 0.0447
Best model saved at epoch 6 with validation loss: 0.0447
[Epoch 7, Batch 100] loss: 0.024912827016232767
[Epoch 7, Batch 200] loss: 0.02227640131903172
[Epoch 7, Batch 300] loss: 0.01908622597315116
[Epoch 7, Batch 400] loss: 0.023554513495473658
[Epoch 7, Batch 500] loss: 0.024775577208347385
[Epoch 7, Batch 600] loss: 0.024057639482198283
[Epoch 7, Batch 700] loss: 0.020444687508861536
[Epoch 7, Batch 800] loss: 0.032498644362276535
[Epoch 7, Batch 900] loss: 0.027142073377763153
[Epoch 7, Batch 1000] loss: 0.04550529024971183
[Epoch 7, Batch 1100] loss: 0.02823234309798863
[Epoch 7, Batch 1200] loss: 0.029562842987652403
[Epoch 7, Batch 1300] loss: 0.028000832198667922
[Epoch 7, Batch 1400] loss: 0.054245022507384416
[Epoch 7, Batch 1500] loss: 0.03378581901881262
[Epoch 7, Batch 1600] loss: 0.02396267409731081
[Epoch 7, Batch 1700] loss: 0.023603341737543814
[Epoch 7, Batch 1800] loss: 0.03505108584315167
[Epoch 7, Batch 1900] loss: 0.026106710638414368
[Epoch 7, Batch 2000] loss: 0.01448749611776293
[Epoch 7, Batch 2100] loss: 0.01662369044202933
[Epoch 7, Batch 2200] loss: 0.0323702317925563
[Epoch 7, Batch 2300] loss: 0.04424785675364547
[Epoch 7, Batch 2400] loss: 0.029765168066660408
[Epoch 7, Batch 2500] loss: 0.03704942083873902
[Epoch 7, Batch 2600] loss: 0.01510053346530185
[Epoch 7, Batch 2700] loss: 0.034346048625047844
[Epoch 7, Batch 2800] loss: 0.03539568529820827
[Epoch 7, Batch 2900] loss: 0.025830672305673943
[Epoch 7, Batch 3000] loss: 0.023430772251813323
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0451
Validation Accuracy: 0.9854
Overfitting: 0.0451
[Epoch 8, Batch 100] loss: 0.014502976519434014
[Epoch 8, Batch 200] loss: 0.01599168040193035
[Epoch 8, Batch 300] loss: 0.023487900229811204
[Epoch 8, Batch 400] loss: 0.01913125851384393
[Epoch 8, Batch 500] loss: 0.013846979187364923
[Epoch 8, Batch 600] loss: 0.027412948123619572
[Epoch 8, Batch 700] loss: 0.024898372759998892
[Epoch 8, Batch 800] loss: 0.015762012470586343
[Epoch 8, Batch 900] loss: 0.020880086395554828
[Epoch 8, Batch 1000] loss: 0.026500228485820117
[Epoch 8, Batch 1100] loss: 0.025703144144463296
[Epoch 8, Batch 1200] loss: 0.026261723087955033
[Epoch 8, Batch 1300] loss: 0.02255820690494147
[Epoch 8, Batch 1400] loss: 0.02423052267566163
[Epoch 8, Batch 1500] loss: 0.023150547609184287
[Epoch 8, Batch 1600] loss: 0.01426769967954897
[Epoch 8, Batch 1700] loss: 0.02191210922330356
[Epoch 8, Batch 1800] loss: 0.017784895529039203
[Epoch 8, Batch 1900] loss: 0.03603677193124895
[Epoch 8, Batch 2000] loss: 0.03329220659303246
[Epoch 8, Batch 2100] loss: 0.018193417268448683
[Epoch 8, Batch 2200] loss: 0.03817579405527795
[Epoch 8, Batch 2300] loss: 0.03253622233223723
[Epoch 8, Batch 2400] loss: 0.020467587638340775
[Epoch 8, Batch 2500] loss: 0.02612589000706066
[Epoch 8, Batch 2600] loss: 0.027592873694666196
[Epoch 8, Batch 2700] loss: 0.01881192261229444
[Epoch 8, Batch 2800] loss: 0.015358931920891336
[Epoch 8, Batch 2900] loss: 0.03474976128704839
[Epoch 8, Batch 3000] loss: 0.03133886449773854
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9861
Overfitting: 0.0482
[Epoch 9, Batch 100] loss: 0.037063166107618596
[Epoch 9, Batch 200] loss: 0.015217780738385044
[Epoch 9, Batch 300] loss: 0.014590993005767813
[Epoch 9, Batch 400] loss: 0.020462112991172034
[Epoch 9, Batch 500] loss: 0.019523508494257838
[Epoch 9, Batch 600] loss: 0.0135818704860867
[Epoch 9, Batch 700] loss: 0.022797411985993676
[Epoch 9, Batch 800] loss: 0.020082291358849032
[Epoch 9, Batch 900] loss: 0.014996630078094313
[Epoch 9, Batch 1000] loss: 0.021815619632106972
[Epoch 9, Batch 1100] loss: 0.016959990720788482
[Epoch 9, Batch 1200] loss: 0.016471502892454738
[Epoch 9, Batch 1300] loss: 0.014376879949741123
[Epoch 9, Batch 1400] loss: 0.013192073396703563
[Epoch 9, Batch 1500] loss: 0.016777487387589645
[Epoch 9, Batch 1600] loss: 0.0205761635756744
[Epoch 9, Batch 1700] loss: 0.016575682600050642
[Epoch 9, Batch 1800] loss: 0.012727558428887278
[Epoch 9, Batch 1900] loss: 0.02187896118603021
[Epoch 9, Batch 2000] loss: 0.018676050791837043
[Epoch 9, Batch 2100] loss: 0.022632140770219848
[Epoch 9, Batch 2200] loss: 0.021980258084686285
[Epoch 9, Batch 2300] loss: 0.024600797712118948
[Epoch 9, Batch 2400] loss: 0.014731962192163337
[Epoch 9, Batch 2500] loss: 0.029056734771056653
[Epoch 9, Batch 2600] loss: 0.03317995847974089
[Epoch 9, Batch 2700] loss: 0.01965827223710221
[Epoch 9, Batch 2800] loss: 0.01357181676905384
[Epoch 9, Batch 2900] loss: 0.04077072527177734
[Epoch 9, Batch 3000] loss: 0.026132969494792633
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9867
Overfitting: 0.0465
[Epoch 10, Batch 100] loss: 0.011082153776260383
[Epoch 10, Batch 200] loss: 0.01665300442768057
[Epoch 10, Batch 300] loss: 0.010291849475888739
[Epoch 10, Batch 400] loss: 0.014578649176073669
[Epoch 10, Batch 500] loss: 0.01613306296601877
[Epoch 10, Batch 600] loss: 0.019501171412812254
[Epoch 10, Batch 700] loss: 0.027041663981090095
[Epoch 10, Batch 800] loss: 0.01397489225902973
[Epoch 10, Batch 900] loss: 0.01063824685079453
[Epoch 10, Batch 1000] loss: 0.02272527695629833
[Epoch 10, Batch 1100] loss: 0.02030991897212516
[Epoch 10, Batch 1200] loss: 0.031510073349782036
[Epoch 10, Batch 1300] loss: 0.025797900636280246
[Epoch 10, Batch 1400] loss: 0.01761689807746734
[Epoch 10, Batch 1500] loss: 0.022825779702216095
[Epoch 10, Batch 1600] loss: 0.01855339360301514
[Epoch 10, Batch 1700] loss: 0.009511366638689652
[Epoch 10, Batch 1800] loss: 0.012492125966027744
[Epoch 10, Batch 1900] loss: 0.018996267277543666
[Epoch 10, Batch 2000] loss: 0.022213094334074413
[Epoch 10, Batch 2100] loss: 0.01957192565355399
[Epoch 10, Batch 2200] loss: 0.022607982311601518
[Epoch 10, Batch 2300] loss: 0.019174462409791884
[Epoch 10, Batch 2400] loss: 0.025757091418963683
[Epoch 10, Batch 2500] loss: 0.018715555979106284
[Epoch 10, Batch 2600] loss: 0.02429369427427446
[Epoch 10, Batch 2700] loss: 0.013227765886113048
[Epoch 10, Batch 2800] loss: 0.019860044168981402
[Epoch 10, Batch 2900] loss: 0.008191749627821992
[Epoch 10, Batch 3000] loss: 0.016055978970798607
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9878
Overfitting: 0.0478
[Epoch 11, Batch 100] loss: 0.009825099446570675
[Epoch 11, Batch 200] loss: 0.017269620095662505
[Epoch 11, Batch 300] loss: 0.01898223497634717
[Epoch 11, Batch 400] loss: 0.010147567611384148
[Epoch 11, Batch 500] loss: 0.022268178395079302
[Epoch 11, Batch 600] loss: 0.016262655184300458
[Epoch 11, Batch 700] loss: 0.020193764541199925
[Epoch 11, Batch 800] loss: 0.008364779320454546
[Epoch 11, Batch 900] loss: 0.014891072781592811
[Epoch 11, Batch 1000] loss: 0.018865457946258175
[Epoch 11, Batch 1100] loss: 0.01767237055770238
[Epoch 11, Batch 1200] loss: 0.020698242287362518
[Epoch 11, Batch 1300] loss: 0.011296239499861258
[Epoch 11, Batch 1400] loss: 0.01309305707065505
[Epoch 11, Batch 1500] loss: 0.02576693327693647
[Epoch 11, Batch 1600] loss: 0.020270182328840747
[Epoch 11, Batch 1700] loss: 0.019400933617926056
[Epoch 11, Batch 1800] loss: 0.01644172300853825
[Epoch 11, Batch 1900] loss: 0.011443287338588562
[Epoch 11, Batch 2000] loss: 0.013761846023426188
[Epoch 11, Batch 2100] loss: 0.015336358698250478
[Epoch 11, Batch 2200] loss: 0.012590890426563419
[Epoch 11, Batch 2300] loss: 0.014400756894101505
[Epoch 11, Batch 2400] loss: 0.013450565226476101
[Epoch 11, Batch 2500] loss: 0.020816945737660717
[Epoch 11, Batch 2600] loss: 0.010191525211812404
[Epoch 11, Batch 2700] loss: 0.010808672146940807
[Epoch 11, Batch 2800] loss: 0.013043176446476536
[Epoch 11, Batch 2900] loss: 0.022508008460822567
[Epoch 11, Batch 3000] loss: 0.012880749844161982
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0442
Validation Accuracy: 0.9873
Overfitting: 0.0442
Best model saved at epoch 11 with validation loss: 0.0442
[Epoch 12, Batch 100] loss: 0.00732609826391581
[Epoch 12, Batch 200] loss: 0.010608983268766678
[Epoch 12, Batch 300] loss: 0.01493962132206434
[Epoch 12, Batch 400] loss: 0.011433757162876645
[Epoch 12, Batch 500] loss: 0.02022392845296963
[Epoch 12, Batch 600] loss: 0.011615004986288114
[Epoch 12, Batch 700] loss: 0.015590383776943781
[Epoch 12, Batch 800] loss: 0.006937311042838701
[Epoch 12, Batch 900] loss: 0.018914991110568734
[Epoch 12, Batch 1000] loss: 0.013334687491096701
[Epoch 12, Batch 1100] loss: 0.01502687999464797
[Epoch 12, Batch 1200] loss: 0.014734827394152035
[Epoch 12, Batch 1300] loss: 0.015897246191716476
[Epoch 12, Batch 1400] loss: 0.0042768410001372105
[Epoch 12, Batch 1500] loss: 0.011436089415992683
[Epoch 12, Batch 1600] loss: 0.015497062346457823
[Epoch 12, Batch 1700] loss: 0.01693384984777367
[Epoch 12, Batch 1800] loss: 0.009810156826188177
[Epoch 12, Batch 1900] loss: 0.012011546438693586
[Epoch 12, Batch 2000] loss: 0.012813234653062864
[Epoch 12, Batch 2100] loss: 0.014425115877907046
[Epoch 12, Batch 2200] loss: 0.014983571989387202
[Epoch 12, Batch 2300] loss: 0.007664274517587728
[Epoch 12, Batch 2400] loss: 0.009947438141475686
[Epoch 12, Batch 2500] loss: 0.010188021556386958
[Epoch 12, Batch 2600] loss: 0.018832570394702087
[Epoch 12, Batch 2700] loss: 0.013126929619470502
[Epoch 12, Batch 2800] loss: 0.012539072020422282
[Epoch 12, Batch 2900] loss: 0.016181383204204848
[Epoch 12, Batch 3000] loss: 0.010880754143954618
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9876
Overfitting: 0.0490
[Epoch 13, Batch 100] loss: 0.011327760892645528
[Epoch 13, Batch 200] loss: 0.010255021723060054
[Epoch 13, Batch 300] loss: 0.007012930447372128
[Epoch 13, Batch 400] loss: 0.02031557390901071
[Epoch 13, Batch 500] loss: 0.01034640336368284
[Epoch 13, Batch 600] loss: 0.01675217718057638
[Epoch 13, Batch 700] loss: 0.009072403982863762
[Epoch 13, Batch 800] loss: 0.00796150730145655
[Epoch 13, Batch 900] loss: 0.006800455098762086
[Epoch 13, Batch 1000] loss: 0.017467180836379156
[Epoch 13, Batch 1100] loss: 0.005578139555345842
[Epoch 13, Batch 1200] loss: 0.00355869169298785
[Epoch 13, Batch 1300] loss: 0.010463028609783577
[Epoch 13, Batch 1400] loss: 0.006477192162828942
[Epoch 13, Batch 1500] loss: 0.020978592660703725
[Epoch 13, Batch 1600] loss: 0.013101728017072673
[Epoch 13, Batch 1700] loss: 0.0145955853327564
[Epoch 13, Batch 1800] loss: 0.011130439592448057
[Epoch 13, Batch 1900] loss: 0.011027986055415795
[Epoch 13, Batch 2000] loss: 0.006374539200696745
[Epoch 13, Batch 2100] loss: 0.006655942324046009
[Epoch 13, Batch 2200] loss: 0.006499616138157762
[Epoch 13, Batch 2300] loss: 0.010154366577971814
[Epoch 13, Batch 2400] loss: 0.009395397950668212
[Epoch 13, Batch 2500] loss: 0.020180765847544534
[Epoch 13, Batch 2600] loss: 0.010995274537644945
[Epoch 13, Batch 2700] loss: 0.010989701833843242
[Epoch 13, Batch 2800] loss: 0.014720242867947491
[Epoch 13, Batch 2900] loss: 0.008400887284642522
[Epoch 13, Batch 3000] loss: 0.013012812869042135
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9871
Overfitting: 0.0497
[Epoch 14, Batch 100] loss: 0.005426136207529453
[Epoch 14, Batch 200] loss: 0.005883215130802455
[Epoch 14, Batch 300] loss: 0.004132224714921904
[Epoch 14, Batch 400] loss: 0.004891368878845697
[Epoch 14, Batch 500] loss: 0.011057416960570663
[Epoch 14, Batch 600] loss: 0.007895505609217252
[Epoch 14, Batch 700] loss: 0.010801385327813478
[Epoch 14, Batch 800] loss: 0.005635560652608547
[Epoch 14, Batch 900] loss: 0.0028100732444727326
[Epoch 14, Batch 1000] loss: 0.012703100013159201
[Epoch 14, Batch 1100] loss: 0.005843346128019675
[Epoch 14, Batch 1200] loss: 0.004072011694131561
[Epoch 14, Batch 1300] loss: 0.017113361067954427
[Epoch 14, Batch 1400] loss: 0.008621393996105554
[Epoch 14, Batch 1500] loss: 0.00904219201152955
[Epoch 14, Batch 1600] loss: 0.008341956063695762
[Epoch 14, Batch 1700] loss: 0.005286301079173654
[Epoch 14, Batch 1800] loss: 0.010716470116017262
[Epoch 14, Batch 1900] loss: 0.006454297166219476
[Epoch 14, Batch 2000] loss: 0.008785092431351131
[Epoch 14, Batch 2100] loss: 0.00542762707789052
[Epoch 14, Batch 2200] loss: 0.007129650431338632
[Epoch 14, Batch 2300] loss: 0.022893854468998144
[Epoch 14, Batch 2400] loss: 0.012293827437783875
[Epoch 14, Batch 2500] loss: 0.013818372095001905
[Epoch 14, Batch 2600] loss: 0.013692138846250828
[Epoch 14, Batch 2700] loss: 0.010035933787585237
[Epoch 14, Batch 2800] loss: 0.013795292064846762
[Epoch 14, Batch 2900] loss: 0.017776974529894005
[Epoch 14, Batch 3000] loss: 0.015814616571101395
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9862
Overfitting: 0.0552
[Epoch 15, Batch 100] loss: 0.007232383551370276
[Epoch 15, Batch 200] loss: 0.00760017503729614
[Epoch 15, Batch 300] loss: 0.008251337974588751
[Epoch 15, Batch 400] loss: 0.003893887141241521
[Epoch 15, Batch 500] loss: 0.00962492422098194
[Epoch 15, Batch 600] loss: 0.00480102103480931
[Epoch 15, Batch 700] loss: 0.012944141721341111
[Epoch 15, Batch 800] loss: 0.005020247383486094
[Epoch 15, Batch 900] loss: 0.011754528852170551
[Epoch 15, Batch 1000] loss: 0.004461243527322836
[Epoch 15, Batch 1100] loss: 0.005006097634454818
[Epoch 15, Batch 1200] loss: 0.003134257869839985
[Epoch 15, Batch 1300] loss: 0.012900078260722694
[Epoch 15, Batch 1400] loss: 0.0081027851324734
[Epoch 15, Batch 1500] loss: 0.006450481635806682
[Epoch 15, Batch 1600] loss: 0.004272902407195147
[Epoch 15, Batch 1700] loss: 0.009784679514596065
[Epoch 15, Batch 1800] loss: 0.005885012387294637
[Epoch 15, Batch 1900] loss: 0.013742795370239947
[Epoch 15, Batch 2000] loss: 0.009591957699690283
[Epoch 15, Batch 2100] loss: 0.009225114483249398
[Epoch 15, Batch 2200] loss: 0.015491156895811854
[Epoch 15, Batch 2300] loss: 0.007714130065307359
[Epoch 15, Batch 2400] loss: 0.01208880701408134
[Epoch 15, Batch 2500] loss: 0.010366860208077923
[Epoch 15, Batch 2600] loss: 0.018737614826970343
[Epoch 15, Batch 2700] loss: 0.0048898402517511385
[Epoch 15, Batch 2800] loss: 0.01334710880720536
[Epoch 15, Batch 2900] loss: 0.012267964375523662
[Epoch 15, Batch 3000] loss: 0.01108932071917934
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0587
Validation Accuracy: 0.9849
Overfitting: 0.0587
[Epoch 16, Batch 100] loss: 0.010967955926871583
[Epoch 16, Batch 200] loss: 0.012594009399149399
[Epoch 16, Batch 300] loss: 0.016244276988222738
[Epoch 16, Batch 400] loss: 0.013596600550827134
[Epoch 16, Batch 500] loss: 0.009553551588108177
[Epoch 16, Batch 600] loss: 0.017873115664906437
[Epoch 16, Batch 700] loss: 0.007932384040618672
[Epoch 16, Batch 800] loss: 0.0049053535524853946
[Epoch 16, Batch 900] loss: 0.007418139921846887
[Epoch 16, Batch 1000] loss: 0.012819248924818111
[Epoch 16, Batch 1100] loss: 0.005851723387681886
[Epoch 16, Batch 1200] loss: 0.0062281807019962795
[Epoch 16, Batch 1300] loss: 0.00470711815191521
[Epoch 16, Batch 1400] loss: 0.008173842579363395
[Epoch 16, Batch 1500] loss: 0.008338960477642559
[Epoch 16, Batch 1600] loss: 0.006878328945878138
[Epoch 16, Batch 1700] loss: 0.007757113257311233
[Epoch 16, Batch 1800] loss: 0.010375402032352099
[Epoch 16, Batch 1900] loss: 0.010295008743159997
[Epoch 16, Batch 2000] loss: 0.010688247636335291
[Epoch 16, Batch 2100] loss: 0.012373509616766113
[Epoch 16, Batch 2200] loss: 0.01351694246780653
[Epoch 16, Batch 2300] loss: 0.006478118668892137
[Epoch 16, Batch 2400] loss: 0.005875809281538977
[Epoch 16, Batch 2500] loss: 0.002810786344896314
[Epoch 16, Batch 2600] loss: 0.009673999098681066
[Epoch 16, Batch 2700] loss: 0.0042821615463282114
[Epoch 16, Batch 2800] loss: 0.006438296045313336
[Epoch 16, Batch 2900] loss: 0.005931308837939468
[Epoch 16, Batch 3000] loss: 0.006810989013342805
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9889
Overfitting: 0.0449
[Epoch 17, Batch 100] loss: 0.0035870175425554863
[Epoch 17, Batch 200] loss: 0.004425945240621445
[Epoch 17, Batch 300] loss: 0.012617740292084819
[Epoch 17, Batch 400] loss: 0.001778975091929169
[Epoch 17, Batch 500] loss: 0.013850256083925956
[Epoch 17, Batch 600] loss: 0.009494614310715405
[Epoch 17, Batch 700] loss: 0.006074225189802291
[Epoch 17, Batch 800] loss: 0.006687484370140737
[Epoch 17, Batch 900] loss: 0.003170786998787207
[Epoch 17, Batch 1000] loss: 0.010624310138277906
[Epoch 17, Batch 1100] loss: 0.0030731887042384186
[Epoch 17, Batch 1200] loss: 0.003132964036193755
[Epoch 17, Batch 1300] loss: 0.003809306771505021
[Epoch 17, Batch 1400] loss: 0.003362892231468777
[Epoch 17, Batch 1500] loss: 0.005064908895079441
[Epoch 17, Batch 1600] loss: 0.010765740283109154
[Epoch 17, Batch 1700] loss: 0.006437581575642071
[Epoch 17, Batch 1800] loss: 0.005104035973927807
[Epoch 17, Batch 1900] loss: 0.003603600564058311
[Epoch 17, Batch 2000] loss: 0.0026406940788115205
[Epoch 17, Batch 2100] loss: 0.006175522994012397
[Epoch 17, Batch 2200] loss: 0.012034784663450608
[Epoch 17, Batch 2300] loss: 0.012989017170873467
[Epoch 17, Batch 2400] loss: 0.016347588161256112
[Epoch 17, Batch 2500] loss: 0.006256114602438174
[Epoch 17, Batch 2600] loss: 0.013011654045324122
[Epoch 17, Batch 2700] loss: 0.009399532661348076
[Epoch 17, Batch 2800] loss: 0.007747431986508672
[Epoch 17, Batch 2900] loss: 0.007355832341541344
[Epoch 17, Batch 3000] loss: 0.007277803662242946
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9880
Overfitting: 0.0520
[Epoch 18, Batch 100] loss: 0.0062425472548274285
[Epoch 18, Batch 200] loss: 0.006490875921763291
[Epoch 18, Batch 300] loss: 0.009433160653768482
[Epoch 18, Batch 400] loss: 0.003974399850875443
[Epoch 18, Batch 500] loss: 0.005709689680221572
[Epoch 18, Batch 600] loss: 0.010987097464551282
[Epoch 18, Batch 700] loss: 0.004685243953481688
[Epoch 18, Batch 800] loss: 0.0035802990204831533
[Epoch 18, Batch 900] loss: 0.0031774564013221608
[Epoch 18, Batch 1000] loss: 0.004122156808322188
[Epoch 18, Batch 1100] loss: 0.005063148733506182
[Epoch 18, Batch 1200] loss: 0.004441022688806839
[Epoch 18, Batch 1300] loss: 0.0031090104750444423
[Epoch 18, Batch 1400] loss: 0.0026774447344479315
[Epoch 18, Batch 1500] loss: 0.001943038793962657
[Epoch 18, Batch 1600] loss: 0.0033406604039691954
[Epoch 18, Batch 1700] loss: 0.004668761578989234
[Epoch 18, Batch 1800] loss: 0.00694076561828382
[Epoch 18, Batch 1900] loss: 0.01313769042895018
[Epoch 18, Batch 2000] loss: 0.0069516300863801915
[Epoch 18, Batch 2100] loss: 0.004934994713537435
[Epoch 18, Batch 2200] loss: 0.0019086083578281432
[Epoch 18, Batch 2300] loss: 0.003126798481960975
[Epoch 18, Batch 2400] loss: 0.0035000864465786208
[Epoch 18, Batch 2500] loss: 0.006611675129287988
[Epoch 18, Batch 2600] loss: 0.0016152854705141805
[Epoch 18, Batch 2700] loss: 0.005281374970277852
[Epoch 18, Batch 2800] loss: 0.006613088799692832
[Epoch 18, Batch 2900] loss: 0.00784438953173563
[Epoch 18, Batch 3000] loss: 0.013770183123562561
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0711
Validation Accuracy: 0.9841
Overfitting: 0.0711
[Epoch 19, Batch 100] loss: 0.006545819730727658
[Epoch 19, Batch 200] loss: 0.00667194846491384
[Epoch 19, Batch 300] loss: 0.013448973305683011
[Epoch 19, Batch 400] loss: 0.0038679407501160767
[Epoch 19, Batch 500] loss: 0.0068411669649111675
[Epoch 19, Batch 600] loss: 0.01046277535869251
[Epoch 19, Batch 700] loss: 0.0060708630807789635
[Epoch 19, Batch 800] loss: 0.0019256172591013865
[Epoch 19, Batch 900] loss: 0.0026578385367426447
[Epoch 19, Batch 1000] loss: 0.0022196849175483637
[Epoch 19, Batch 1100] loss: 0.00488409923147401
[Epoch 19, Batch 1200] loss: 0.0058002466833113435
[Epoch 19, Batch 1300] loss: 0.004711686628993164
[Epoch 19, Batch 1400] loss: 0.002164101625549506
[Epoch 19, Batch 1500] loss: 0.004735084746537979
[Epoch 19, Batch 1600] loss: 0.005318991486079199
[Epoch 19, Batch 1700] loss: 0.0017360520418851877
[Epoch 19, Batch 1800] loss: 0.0021724042822179965
[Epoch 19, Batch 1900] loss: 0.005516667815851122
[Epoch 19, Batch 2000] loss: 0.00565301896694109
[Epoch 19, Batch 2100] loss: 0.00341185038355988
[Epoch 19, Batch 2200] loss: 0.0025996509670983413
[Epoch 19, Batch 2300] loss: 0.005592575569674097
[Epoch 19, Batch 2400] loss: 0.004978855965259754
[Epoch 19, Batch 2500] loss: 0.008696637475065928
[Epoch 19, Batch 2600] loss: 0.006069582473323862
[Epoch 19, Batch 2700] loss: 0.007727029452681222
[Epoch 19, Batch 2800] loss: 0.003984144422471445
[Epoch 19, Batch 2900] loss: 0.00786845371766617
[Epoch 19, Batch 3000] loss: 0.002843857682500861
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9884
Overfitting: 0.0540
[Epoch 20, Batch 100] loss: 0.004788190033901856
[Epoch 20, Batch 200] loss: 0.0010576228404349309
[Epoch 20, Batch 300] loss: 0.001515217168374079
[Epoch 20, Batch 400] loss: 0.0014377715880567622
[Epoch 20, Batch 500] loss: 0.010206378981107203
[Epoch 20, Batch 600] loss: 0.006356902034224845
[Epoch 20, Batch 700] loss: 0.003192877882528933
[Epoch 20, Batch 800] loss: 0.005184423563972587
[Epoch 20, Batch 900] loss: 0.00701503504744764
[Epoch 20, Batch 1000] loss: 0.002900224389780135
[Epoch 20, Batch 1100] loss: 0.00366866435825699
[Epoch 20, Batch 1200] loss: 0.0032922826509962986
[Epoch 20, Batch 1300] loss: 0.0025960418792934092
[Epoch 20, Batch 1400] loss: 0.001495311444699894
[Epoch 20, Batch 1500] loss: 0.0030242288810535456
[Epoch 20, Batch 1600] loss: 0.002133181430640967
[Epoch 20, Batch 1700] loss: 0.002751400084417739
[Epoch 20, Batch 1800] loss: 0.011805800968431868
[Epoch 20, Batch 1900] loss: 0.009858945969004367
[Epoch 20, Batch 2000] loss: 0.004379494465080711
[Epoch 20, Batch 2100] loss: 0.00756234484592305
[Epoch 20, Batch 2200] loss: 0.004153193150883539
[Epoch 20, Batch 2300] loss: 0.0038112131545119565
[Epoch 20, Batch 2400] loss: 0.011998253936134233
[Epoch 20, Batch 2500] loss: 0.002551889482615479
[Epoch 20, Batch 2600] loss: 0.004189148798940892
[Epoch 20, Batch 2700] loss: 0.0033522872468500966
[Epoch 20, Batch 2800] loss: 0.003015476742493064
[Epoch 20, Batch 2900] loss: 0.006440892519499641
[Epoch 20, Batch 3000] loss: 0.0023332456763805708
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9890
Overfitting: 0.0533
[Epoch 21, Batch 100] loss: 0.0010487352378356718
[Epoch 21, Batch 200] loss: 0.00194397620571948
[Epoch 21, Batch 300] loss: 0.00436499301588114
[Epoch 21, Batch 400] loss: 0.001034027613214903
[Epoch 21, Batch 500] loss: 0.0012139995058625885
[Epoch 21, Batch 600] loss: 0.0017768509015953526
[Epoch 21, Batch 700] loss: 0.0034104889823123406
[Epoch 21, Batch 800] loss: 0.0015763525523679789
[Epoch 21, Batch 900] loss: 0.004939387945216253
[Epoch 21, Batch 1000] loss: 0.003818437150974887
[Epoch 21, Batch 1100] loss: 0.0019177313396042451
[Epoch 21, Batch 1200] loss: 0.002365299333009716
[Epoch 21, Batch 1300] loss: 0.002352909089224653
[Epoch 21, Batch 1400] loss: 0.0056363447213523266
[Epoch 21, Batch 1500] loss: 0.005845178169537064
[Epoch 21, Batch 1600] loss: 0.0017998501417096691
[Epoch 21, Batch 1700] loss: 0.001567811802073038
[Epoch 21, Batch 1800] loss: 0.002761353424006643
[Epoch 21, Batch 1900] loss: 0.011816441200779125
[Epoch 21, Batch 2000] loss: 0.0029127924138455798
[Epoch 21, Batch 2100] loss: 0.0020675672923319154
[Epoch 21, Batch 2200] loss: 0.0043860328576468535
[Epoch 21, Batch 2300] loss: 0.0023575606058068386
[Epoch 21, Batch 2400] loss: 0.002480891815205908
[Epoch 21, Batch 2500] loss: 0.0018692267398731132
[Epoch 21, Batch 2600] loss: 0.0025090680690725265
[Epoch 21, Batch 2700] loss: 0.004894080250186335
[Epoch 21, Batch 2800] loss: 0.001431477279147657
[Epoch 21, Batch 2900] loss: 0.0013015072702887666
[Epoch 21, Batch 3000] loss: 0.0008349565216853704
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9896
Overfitting: 0.0528
[Epoch 22, Batch 100] loss: 0.0009604781977793664
[Epoch 22, Batch 200] loss: 0.0007742832198528049
[Epoch 22, Batch 300] loss: 0.0005207226843118207
[Epoch 22, Batch 400] loss: 0.0019401404448808534
[Epoch 22, Batch 500] loss: 0.0012624509575786603
[Epoch 22, Batch 600] loss: 0.0006183886366882164
[Epoch 22, Batch 700] loss: 0.0014021916365671671
[Epoch 22, Batch 800] loss: 0.0012845740211304957
[Epoch 22, Batch 900] loss: 0.0011435073188975054
[Epoch 22, Batch 1000] loss: 0.004140057129359178
[Epoch 22, Batch 1100] loss: 0.002215287617792541
[Epoch 22, Batch 1200] loss: 0.004050064276988934
[Epoch 22, Batch 1300] loss: 0.002106260062317915
[Epoch 22, Batch 1400] loss: 0.012057524767533039
[Epoch 22, Batch 1500] loss: 0.0009855629461655725
[Epoch 22, Batch 1600] loss: 0.0017704914731930899
[Epoch 22, Batch 1700] loss: 0.00047986078598665215
[Epoch 22, Batch 1800] loss: 0.000583421245958533
[Epoch 22, Batch 1900] loss: 0.0011814140460185386
[Epoch 22, Batch 2000] loss: 0.0005159748330195412
[Epoch 22, Batch 2100] loss: 0.0014425633109617308
[Epoch 22, Batch 2200] loss: 0.0014283480244290513
[Epoch 22, Batch 2300] loss: 0.0011091312682727761
[Epoch 22, Batch 2400] loss: 0.0011787184452003885
[Epoch 22, Batch 2500] loss: 0.003076367280668002
[Epoch 22, Batch 2600] loss: 0.002692921577950167
[Epoch 22, Batch 2700] loss: 0.0015068502968920683
[Epoch 22, Batch 2800] loss: 0.0014764261426889647
[Epoch 22, Batch 2900] loss: 0.0014700888197457119
[Epoch 22, Batch 3000] loss: 0.001318194220374025
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9889
Overfitting: 0.0536
[Epoch 23, Batch 100] loss: 0.0008330120911801409
[Epoch 23, Batch 200] loss: 0.0009533811421562088
[Epoch 23, Batch 300] loss: 0.0008518336501812484
[Epoch 23, Batch 400] loss: 0.0006441029964734124
[Epoch 23, Batch 500] loss: 0.00039032793351018836
[Epoch 23, Batch 600] loss: 0.0003214065992126791
[Epoch 23, Batch 700] loss: 0.001308505646654101
[Epoch 23, Batch 800] loss: 0.0048364599738413006
[Epoch 23, Batch 900] loss: 0.0023383429191102677
[Epoch 23, Batch 1000] loss: 0.003762978846507856
[Epoch 23, Batch 1100] loss: 0.0009834227861033008
[Epoch 23, Batch 1200] loss: 0.0004413182995088505
[Epoch 23, Batch 1300] loss: 0.0005715091030044661
[Epoch 23, Batch 1400] loss: 0.0005914770267970226
[Epoch 23, Batch 1500] loss: 0.002934207313648187
[Epoch 23, Batch 1600] loss: 0.0005234390707095394
[Epoch 23, Batch 1700] loss: 0.0008331732149800075
[Epoch 23, Batch 1800] loss: 0.0012772745704449885
[Epoch 23, Batch 1900] loss: 0.0009713448061971475
[Epoch 23, Batch 2000] loss: 0.0009564377639894417
[Epoch 23, Batch 2100] loss: 0.0006602474192020935
[Epoch 23, Batch 2200] loss: 0.0008379258957199687
[Epoch 23, Batch 2300] loss: 0.0004566643940268289
[Epoch 23, Batch 2400] loss: 0.0028235057303363843
[Epoch 23, Batch 2500] loss: 0.0011988372774682076
[Epoch 23, Batch 2600] loss: 0.0014355482140105335
[Epoch 23, Batch 2700] loss: 0.0005338630365714181
[Epoch 23, Batch 2800] loss: 0.0008367136867700253
[Epoch 23, Batch 2900] loss: 0.0005592060866059923
[Epoch 23, Batch 3000] loss: 0.0012406919048549448
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9883
Overfitting: 0.0581
[Epoch 24, Batch 100] loss: 0.0005033648782951739
[Epoch 24, Batch 200] loss: 0.0014980952001526404
[Epoch 24, Batch 300] loss: 0.0029140380278572975
[Epoch 24, Batch 400] loss: 0.0012554303613444384
[Epoch 24, Batch 500] loss: 0.00039627544135704794
[Epoch 24, Batch 600] loss: 0.000948504450783787
[Epoch 24, Batch 700] loss: 0.0004743718408923847
[Epoch 24, Batch 800] loss: 0.0008795872089284273
[Epoch 24, Batch 900] loss: 0.005575277297623198
[Epoch 24, Batch 1000] loss: 0.0033756672337068496
[Epoch 24, Batch 1100] loss: 0.0015141369037174179
[Epoch 24, Batch 1200] loss: 0.007728424812843269
[Epoch 24, Batch 1300] loss: 0.0008767609211004412
[Epoch 24, Batch 1400] loss: 0.001582980245751102
[Epoch 24, Batch 1500] loss: 0.0018199163966019683
[Epoch 24, Batch 1600] loss: 0.00043618237456452655
[Epoch 24, Batch 1700] loss: 0.0004696542733376674
[Epoch 24, Batch 1800] loss: 0.0008960935344433096
[Epoch 24, Batch 1900] loss: 0.009690617806163053
[Epoch 24, Batch 2000] loss: 0.010281192532562712
[Epoch 24, Batch 2100] loss: 0.004242538706792622
[Epoch 24, Batch 2200] loss: 0.0021837676815289696
[Epoch 24, Batch 2300] loss: 0.004774974847090902
[Epoch 24, Batch 2400] loss: 0.002560550551060885
[Epoch 24, Batch 2500] loss: 0.0031195517365125627
[Epoch 24, Batch 2600] loss: 0.002216435682743949
[Epoch 24, Batch 2700] loss: 0.0006585599822407629
[Epoch 24, Batch 2800] loss: 0.001328528519354748
[Epoch 24, Batch 2900] loss: 0.001662010983701987
[Epoch 24, Batch 3000] loss: 0.0021500918451833684
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0626
Validation Accuracy: 0.9872
Overfitting: 0.0626
Fold 3 validation loss: 0.0626
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2918928813934327
[Epoch 1, Batch 200] loss: 2.2421574449539183
[Epoch 1, Batch 300] loss: 1.9314227294921875
[Epoch 1, Batch 400] loss: 0.972836255133152
[Epoch 1, Batch 500] loss: 0.6524201835691928
[Epoch 1, Batch 600] loss: 0.5231646996736526
[Epoch 1, Batch 700] loss: 0.41201884262263777
[Epoch 1, Batch 800] loss: 0.4186217986047268
[Epoch 1, Batch 900] loss: 0.3388839007914066
[Epoch 1, Batch 1000] loss: 0.315357001721859
[Epoch 1, Batch 1100] loss: 0.2823535615205765
[Epoch 1, Batch 1200] loss: 0.21931528235320003
[Epoch 1, Batch 1300] loss: 0.24762500658631326
[Epoch 1, Batch 1400] loss: 0.19203550862148405
[Epoch 1, Batch 1500] loss: 0.19922712394967676
[Epoch 1, Batch 1600] loss: 0.22228690857067704
[Epoch 1, Batch 1700] loss: 0.21349438490346073
[Epoch 1, Batch 1800] loss: 0.16700595849193633
[Epoch 1, Batch 1900] loss: 0.17599737755954264
[Epoch 1, Batch 2000] loss: 0.17121538767591118
[Epoch 1, Batch 2100] loss: 0.15250199748203158
[Epoch 1, Batch 2200] loss: 0.15461647076532245
[Epoch 1, Batch 2300] loss: 0.14333119933959096
[Epoch 1, Batch 2400] loss: 0.1480009944923222
[Epoch 1, Batch 2500] loss: 0.1018852330930531
[Epoch 1, Batch 2600] loss: 0.1343537911097519
[Epoch 1, Batch 2700] loss: 0.13301610810449346
[Epoch 1, Batch 2800] loss: 0.13608112450689078
[Epoch 1, Batch 2900] loss: 0.14361865042708813
[Epoch 1, Batch 3000] loss: 0.11270677664782852
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1139
Validation Accuracy: 0.9646
Overfitting: 0.1139
Best model saved at epoch 1 with validation loss: 0.1139
[Epoch 2, Batch 100] loss: 0.1025656617921777
[Epoch 2, Batch 200] loss: 0.08550648735836149
[Epoch 2, Batch 300] loss: 0.10657616541371681
[Epoch 2, Batch 400] loss: 0.0958444007113576
[Epoch 2, Batch 500] loss: 0.10181811614194886
[Epoch 2, Batch 600] loss: 0.11789090025937185
[Epoch 2, Batch 700] loss: 0.08501901975250803
[Epoch 2, Batch 800] loss: 0.1164223824441433
[Epoch 2, Batch 900] loss: 0.10337719520088286
[Epoch 2, Batch 1000] loss: 0.09115629317006096
[Epoch 2, Batch 1100] loss: 0.10055320251267404
[Epoch 2, Batch 1200] loss: 0.09010198818752542
[Epoch 2, Batch 1300] loss: 0.10811591340927407
[Epoch 2, Batch 1400] loss: 0.11171409201808274
[Epoch 2, Batch 1500] loss: 0.08578385126776994
[Epoch 2, Batch 1600] loss: 0.07928159413859248
[Epoch 2, Batch 1700] loss: 0.10246467334567569
[Epoch 2, Batch 1800] loss: 0.07887100250576623
[Epoch 2, Batch 1900] loss: 0.10720168869942427
[Epoch 2, Batch 2000] loss: 0.07559356564073823
[Epoch 2, Batch 2100] loss: 0.0896254546334967
[Epoch 2, Batch 2200] loss: 0.09584275092929602
[Epoch 2, Batch 2300] loss: 0.06794973475625739
[Epoch 2, Batch 2400] loss: 0.09369956852518953
[Epoch 2, Batch 2500] loss: 0.07300071246689185
[Epoch 2, Batch 2600] loss: 0.07515664230333641
[Epoch 2, Batch 2700] loss: 0.07387177768046968
[Epoch 2, Batch 2800] loss: 0.0751404009386897
[Epoch 2, Batch 2900] loss: 0.06412769795104395
[Epoch 2, Batch 3000] loss: 0.0911211204045685
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0717
Validation Accuracy: 0.9782
Overfitting: 0.0717
Best model saved at epoch 2 with validation loss: 0.0717
[Epoch 3, Batch 100] loss: 0.08860244611918461
[Epoch 3, Batch 200] loss: 0.06067521910532378
[Epoch 3, Batch 300] loss: 0.061818952759495005
[Epoch 3, Batch 400] loss: 0.056461274663452056
[Epoch 3, Batch 500] loss: 0.06459653568395879
[Epoch 3, Batch 600] loss: 0.05901077027083375
[Epoch 3, Batch 700] loss: 0.07312361435848289
[Epoch 3, Batch 800] loss: 0.054299290074268355
[Epoch 3, Batch 900] loss: 0.08029251395375468
[Epoch 3, Batch 1000] loss: 0.06278158881585114
[Epoch 3, Batch 1100] loss: 0.08338291937136091
[Epoch 3, Batch 1200] loss: 0.07570739200455137
[Epoch 3, Batch 1300] loss: 0.05356061630183831
[Epoch 3, Batch 1400] loss: 0.06933286732295528
[Epoch 3, Batch 1500] loss: 0.060740184574970046
[Epoch 3, Batch 1600] loss: 0.052912249910295944
[Epoch 3, Batch 1700] loss: 0.05057555022882298
[Epoch 3, Batch 1800] loss: 0.053158161410829054
[Epoch 3, Batch 1900] loss: 0.05912633541360265
[Epoch 3, Batch 2000] loss: 0.09474873199360445
[Epoch 3, Batch 2100] loss: 0.060788735185633415
[Epoch 3, Batch 2200] loss: 0.06142771660350263
[Epoch 3, Batch 2300] loss: 0.04977795884595253
[Epoch 3, Batch 2400] loss: 0.06274674120242707
[Epoch 3, Batch 2500] loss: 0.06433287843421567
[Epoch 3, Batch 2600] loss: 0.03953829852223862
[Epoch 3, Batch 2700] loss: 0.0421997202312923
[Epoch 3, Batch 2800] loss: 0.051663240498746744
[Epoch 3, Batch 2900] loss: 0.07573307240905706
[Epoch 3, Batch 3000] loss: 0.04944738864491228
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9796
Overfitting: 0.0635
Best model saved at epoch 3 with validation loss: 0.0635
[Epoch 4, Batch 100] loss: 0.05757271032431163
[Epoch 4, Batch 200] loss: 0.04889131423260551
[Epoch 4, Batch 300] loss: 0.042707517656526764
[Epoch 4, Batch 400] loss: 0.05617579319747165
[Epoch 4, Batch 500] loss: 0.04118630528275389
[Epoch 4, Batch 600] loss: 0.04861261416692287
[Epoch 4, Batch 700] loss: 0.05315886170952581
[Epoch 4, Batch 800] loss: 0.036545543599931986
[Epoch 4, Batch 900] loss: 0.0646225399398827
[Epoch 4, Batch 1000] loss: 0.053075110054342074
[Epoch 4, Batch 1100] loss: 0.045655219233594835
[Epoch 4, Batch 1200] loss: 0.04241518820053898
[Epoch 4, Batch 1300] loss: 0.03612869109871099
[Epoch 4, Batch 1400] loss: 0.046026705969998145
[Epoch 4, Batch 1500] loss: 0.05838903620140627
[Epoch 4, Batch 1600] loss: 0.050396762845339255
[Epoch 4, Batch 1700] loss: 0.05102708131656982
[Epoch 4, Batch 1800] loss: 0.05679887466787477
[Epoch 4, Batch 1900] loss: 0.039310519488935824
[Epoch 4, Batch 2000] loss: 0.04194553540946799
[Epoch 4, Batch 2100] loss: 0.0633825635552057
[Epoch 4, Batch 2200] loss: 0.03550380724249408
[Epoch 4, Batch 2300] loss: 0.041885520946816544
[Epoch 4, Batch 2400] loss: 0.04639625833835453
[Epoch 4, Batch 2500] loss: 0.0439929103772738
[Epoch 4, Batch 2600] loss: 0.0436643890599953
[Epoch 4, Batch 2700] loss: 0.05263334904710064
[Epoch 4, Batch 2800] loss: 0.05633547355013434
[Epoch 4, Batch 2900] loss: 0.045498742880881765
[Epoch 4, Batch 3000] loss: 0.04333950955769979
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9832
Overfitting: 0.0538
Best model saved at epoch 4 with validation loss: 0.0538
[Epoch 5, Batch 100] loss: 0.03695113457622938
[Epoch 5, Batch 200] loss: 0.03847681674058549
[Epoch 5, Batch 300] loss: 0.06015721681294963
[Epoch 5, Batch 400] loss: 0.02935459657703177
[Epoch 5, Batch 500] loss: 0.027271862725319805
[Epoch 5, Batch 600] loss: 0.033200020020012745
[Epoch 5, Batch 700] loss: 0.039610061299317746
[Epoch 5, Batch 800] loss: 0.033630503384702026
[Epoch 5, Batch 900] loss: 0.04500486146687763
[Epoch 5, Batch 1000] loss: 0.046515564003784676
[Epoch 5, Batch 1100] loss: 0.0368781576337642
[Epoch 5, Batch 1200] loss: 0.031263911087444286
[Epoch 5, Batch 1300] loss: 0.051000511569145604
[Epoch 5, Batch 1400] loss: 0.030574950568261556
[Epoch 5, Batch 1500] loss: 0.03901317940966692
[Epoch 5, Batch 1600] loss: 0.031464889100607255
[Epoch 5, Batch 1700] loss: 0.053361148912226784
[Epoch 5, Batch 1800] loss: 0.044506089032365706
[Epoch 5, Batch 1900] loss: 0.04075442350891535
[Epoch 5, Batch 2000] loss: 0.050564726910670287
[Epoch 5, Batch 2100] loss: 0.024704664078162752
[Epoch 5, Batch 2200] loss: 0.03412245902276481
[Epoch 5, Batch 2300] loss: 0.03190235924572335
[Epoch 5, Batch 2400] loss: 0.043266546145023316
[Epoch 5, Batch 2500] loss: 0.04371306947767153
[Epoch 5, Batch 2600] loss: 0.046107832698035055
[Epoch 5, Batch 2700] loss: 0.05611849104665453
[Epoch 5, Batch 2800] loss: 0.03593827646443969
[Epoch 5, Batch 2900] loss: 0.03775907059229212
[Epoch 5, Batch 3000] loss: 0.03744696704299713
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9838
Overfitting: 0.0551
[Epoch 6, Batch 100] loss: 0.0369891494337935
[Epoch 6, Batch 200] loss: 0.03614262160110229
[Epoch 6, Batch 300] loss: 0.05189618962591339
[Epoch 6, Batch 400] loss: 0.023755176886334085
[Epoch 6, Batch 500] loss: 0.03546969495044323
[Epoch 6, Batch 600] loss: 0.016699262510264816
[Epoch 6, Batch 700] loss: 0.026900741291647136
[Epoch 6, Batch 800] loss: 0.03033775239950046
[Epoch 6, Batch 900] loss: 0.030894963225728135
[Epoch 6, Batch 1000] loss: 0.03052900346912793
[Epoch 6, Batch 1100] loss: 0.024430212223596755
[Epoch 6, Batch 1200] loss: 0.03259421796705283
[Epoch 6, Batch 1300] loss: 0.042405137059977276
[Epoch 6, Batch 1400] loss: 0.029580634853628
[Epoch 6, Batch 1500] loss: 0.034489929576884605
[Epoch 6, Batch 1600] loss: 0.029843458138639107
[Epoch 6, Batch 1700] loss: 0.03853617812288576
[Epoch 6, Batch 1800] loss: 0.036140012226533146
[Epoch 6, Batch 1900] loss: 0.033297339000419014
[Epoch 6, Batch 2000] loss: 0.0436687107400212
[Epoch 6, Batch 2100] loss: 0.03476355220453115
[Epoch 6, Batch 2200] loss: 0.029044522525073262
[Epoch 6, Batch 2300] loss: 0.03918483307032147
[Epoch 6, Batch 2400] loss: 0.02986049869490671
[Epoch 6, Batch 2500] loss: 0.0397048177527904
[Epoch 6, Batch 2600] loss: 0.039688277008535805
[Epoch 6, Batch 2700] loss: 0.04458153435618442
[Epoch 6, Batch 2800] loss: 0.027279700587969274
[Epoch 6, Batch 2900] loss: 0.03391625132317131
[Epoch 6, Batch 3000] loss: 0.029610903786669952
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9828
Overfitting: 0.0540
[Epoch 7, Batch 100] loss: 0.021521693472459448
[Epoch 7, Batch 200] loss: 0.023959957215120085
[Epoch 7, Batch 300] loss: 0.026332035903906217
[Epoch 7, Batch 400] loss: 0.025715341475370225
[Epoch 7, Batch 500] loss: 0.038725481603651135
[Epoch 7, Batch 600] loss: 0.023165431617235298
[Epoch 7, Batch 700] loss: 0.02502021100590355
[Epoch 7, Batch 800] loss: 0.02533102771907579
[Epoch 7, Batch 900] loss: 0.032556594036141175
[Epoch 7, Batch 1000] loss: 0.025566219971806275
[Epoch 7, Batch 1100] loss: 0.02225981982795929
[Epoch 7, Batch 1200] loss: 0.03208048636312014
[Epoch 7, Batch 1300] loss: 0.04040923815220594
[Epoch 7, Batch 1400] loss: 0.02639865655612084
[Epoch 7, Batch 1500] loss: 0.034463530482862555
[Epoch 7, Batch 1600] loss: 0.029307219148031437
[Epoch 7, Batch 1700] loss: 0.029425110656957257
[Epoch 7, Batch 1800] loss: 0.035134932099317666
[Epoch 7, Batch 1900] loss: 0.017483166694510145
[Epoch 7, Batch 2000] loss: 0.03852607449138304
[Epoch 7, Batch 2100] loss: 0.017026164080307354
[Epoch 7, Batch 2200] loss: 0.018384806456597288
[Epoch 7, Batch 2300] loss: 0.03007363248594629
[Epoch 7, Batch 2400] loss: 0.019620758003729862
[Epoch 7, Batch 2500] loss: 0.030169487136990938
[Epoch 7, Batch 2600] loss: 0.022291548247849277
[Epoch 7, Batch 2700] loss: 0.02547806159534957
[Epoch 7, Batch 2800] loss: 0.029869156958229722
[Epoch 7, Batch 2900] loss: 0.027257072791835524
[Epoch 7, Batch 3000] loss: 0.02866447972577589
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0426
Validation Accuracy: 0.9868
Overfitting: 0.0426
Best model saved at epoch 7 with validation loss: 0.0426
[Epoch 8, Batch 100] loss: 0.028655257933278337
[Epoch 8, Batch 200] loss: 0.017704900927928976
[Epoch 8, Batch 300] loss: 0.020139007862017024
[Epoch 8, Batch 400] loss: 0.013336165684449952
[Epoch 8, Batch 500] loss: 0.016744525487301872
[Epoch 8, Batch 600] loss: 0.03312736821186263
[Epoch 8, Batch 700] loss: 0.037562085354184094
[Epoch 8, Batch 800] loss: 0.0184908216396434
[Epoch 8, Batch 900] loss: 0.017518419033222016
[Epoch 8, Batch 1000] loss: 0.019758630824435387
[Epoch 8, Batch 1100] loss: 0.02850997008208651
[Epoch 8, Batch 1200] loss: 0.026013257021841128
[Epoch 8, Batch 1300] loss: 0.02928693334983109
[Epoch 8, Batch 1400] loss: 0.018019540189106918
[Epoch 8, Batch 1500] loss: 0.019215447820206465
[Epoch 8, Batch 1600] loss: 0.013175402266788296
[Epoch 8, Batch 1700] loss: 0.024511482568850624
[Epoch 8, Batch 1800] loss: 0.020029139006510377
[Epoch 8, Batch 1900] loss: 0.026375750285078537
[Epoch 8, Batch 2000] loss: 0.03881695989079162
[Epoch 8, Batch 2100] loss: 0.0281377355215227
[Epoch 8, Batch 2200] loss: 0.021906242490877047
[Epoch 8, Batch 2300] loss: 0.0227076525024313
[Epoch 8, Batch 2400] loss: 0.023722546122698987
[Epoch 8, Batch 2500] loss: 0.03769272016255854
[Epoch 8, Batch 2600] loss: 0.01751042180170771
[Epoch 8, Batch 2700] loss: 0.01716339630074799
[Epoch 8, Batch 2800] loss: 0.031151901908087892
[Epoch 8, Batch 2900] loss: 0.038249590451305264
[Epoch 8, Batch 3000] loss: 0.036770270242122934
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9867
Overfitting: 0.0456
[Epoch 9, Batch 100] loss: 0.024307888053372154
[Epoch 9, Batch 200] loss: 0.02672378446950461
[Epoch 9, Batch 300] loss: 0.010443665513994347
[Epoch 9, Batch 400] loss: 0.018711241631317533
[Epoch 9, Batch 500] loss: 0.012165572789963336
[Epoch 9, Batch 600] loss: 0.018186335887949098
[Epoch 9, Batch 700] loss: 0.020797763409536856
[Epoch 9, Batch 800] loss: 0.03126558083486088
[Epoch 9, Batch 900] loss: 0.023038680169884175
[Epoch 9, Batch 1000] loss: 0.015017117400038842
[Epoch 9, Batch 1100] loss: 0.016830217485785396
[Epoch 9, Batch 1200] loss: 0.01847045466896816
[Epoch 9, Batch 1300] loss: 0.011001147279093857
[Epoch 9, Batch 1400] loss: 0.014997289924685901
[Epoch 9, Batch 1500] loss: 0.018844163990997913
[Epoch 9, Batch 1600] loss: 0.023379979331730284
[Epoch 9, Batch 1700] loss: 0.021240615474262085
[Epoch 9, Batch 1800] loss: 0.028898998085624045
[Epoch 9, Batch 1900] loss: 0.023855662345522433
[Epoch 9, Batch 2000] loss: 0.01928394218575704
[Epoch 9, Batch 2100] loss: 0.024088515299154095
[Epoch 9, Batch 2200] loss: 0.026158015736145897
[Epoch 9, Batch 2300] loss: 0.026953680436163266
[Epoch 9, Batch 2400] loss: 0.018958246412239532
[Epoch 9, Batch 2500] loss: 0.02687288665227243
[Epoch 9, Batch 2600] loss: 0.024950934344451524
[Epoch 9, Batch 2700] loss: 0.02062213802244514
[Epoch 9, Batch 2800] loss: 0.02001003587658488
[Epoch 9, Batch 2900] loss: 0.029659685719307164
[Epoch 9, Batch 3000] loss: 0.018466700380031398
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0424
Validation Accuracy: 0.9864
Overfitting: 0.0424
Best model saved at epoch 9 with validation loss: 0.0424
[Epoch 10, Batch 100] loss: 0.014461827496998012
[Epoch 10, Batch 200] loss: 0.012305197738387506
[Epoch 10, Batch 300] loss: 0.01821355380510795
[Epoch 10, Batch 400] loss: 0.013977280671679183
[Epoch 10, Batch 500] loss: 0.012491647956394444
[Epoch 10, Batch 600] loss: 0.014711643708360499
[Epoch 10, Batch 700] loss: 0.013570523404378037
[Epoch 10, Batch 800] loss: 0.010905938811083616
[Epoch 10, Batch 900] loss: 0.01643944099854707
[Epoch 10, Batch 1000] loss: 0.020222242864947476
[Epoch 10, Batch 1100] loss: 0.029827562365353513
[Epoch 10, Batch 1200] loss: 0.01571616348606767
[Epoch 10, Batch 1300] loss: 0.014601417307449082
[Epoch 10, Batch 1400] loss: 0.017580165534400293
[Epoch 10, Batch 1500] loss: 0.012642039422498783
[Epoch 10, Batch 1600] loss: 0.015326140062134072
[Epoch 10, Batch 1700] loss: 0.015393814972485416
[Epoch 10, Batch 1800] loss: 0.030108992762998242
[Epoch 10, Batch 1900] loss: 0.014288112231952255
[Epoch 10, Batch 2000] loss: 0.028702468439551012
[Epoch 10, Batch 2100] loss: 0.017619092396816995
[Epoch 10, Batch 2200] loss: 0.016497722113090276
[Epoch 10, Batch 2300] loss: 0.014843583880319785
[Epoch 10, Batch 2400] loss: 0.016045352400133196
[Epoch 10, Batch 2500] loss: 0.02693970907062976
[Epoch 10, Batch 2600] loss: 0.0202914660587885
[Epoch 10, Batch 2700] loss: 0.011393114430175046
[Epoch 10, Batch 2800] loss: 0.014243456850326765
[Epoch 10, Batch 2900] loss: 0.011967024740806664
[Epoch 10, Batch 3000] loss: 0.01717053597116319
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0427
Validation Accuracy: 0.9868
Overfitting: 0.0427
[Epoch 11, Batch 100] loss: 0.016990448133328756
[Epoch 11, Batch 200] loss: 0.012336071135650854
[Epoch 11, Batch 300] loss: 0.01982542110472423
[Epoch 11, Batch 400] loss: 0.013831358202287447
[Epoch 11, Batch 500] loss: 0.017469444868329447
[Epoch 11, Batch 600] loss: 0.02173334431157855
[Epoch 11, Batch 700] loss: 0.010352324536943342
[Epoch 11, Batch 800] loss: 0.015497889051584935
[Epoch 11, Batch 900] loss: 0.007790351439834922
[Epoch 11, Batch 1000] loss: 0.015192744886990113
[Epoch 11, Batch 1100] loss: 0.008835350298423918
[Epoch 11, Batch 1200] loss: 0.005075451227521626
[Epoch 11, Batch 1300] loss: 0.008167713354587249
[Epoch 11, Batch 1400] loss: 0.020942777055352052
[Epoch 11, Batch 1500] loss: 0.009789634809176278
[Epoch 11, Batch 1600] loss: 0.01490718411598209
[Epoch 11, Batch 1700] loss: 0.014481595796296461
[Epoch 11, Batch 1800] loss: 0.020489388943205997
[Epoch 11, Batch 1900] loss: 0.01633200004234823
[Epoch 11, Batch 2000] loss: 0.010320763730578619
[Epoch 11, Batch 2100] loss: 0.016411873061406367
[Epoch 11, Batch 2200] loss: 0.011385446082172165
[Epoch 11, Batch 2300] loss: 0.013211083256087476
[Epoch 11, Batch 2400] loss: 0.019122553705128668
[Epoch 11, Batch 2500] loss: 0.029371253912413523
[Epoch 11, Batch 2600] loss: 0.016059978156135912
[Epoch 11, Batch 2700] loss: 0.021591565043995616
[Epoch 11, Batch 2800] loss: 0.01694512135853074
[Epoch 11, Batch 2900] loss: 0.021677506932501273
[Epoch 11, Batch 3000] loss: 0.016005655642766216
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0390
Validation Accuracy: 0.9883
Overfitting: 0.0390
Best model saved at epoch 11 with validation loss: 0.0390
[Epoch 12, Batch 100] loss: 0.016295565813506982
[Epoch 12, Batch 200] loss: 0.017326143124037116
[Epoch 12, Batch 300] loss: 0.015987977768709243
[Epoch 12, Batch 400] loss: 0.015353422370353656
[Epoch 12, Batch 500] loss: 0.01611475121055264
[Epoch 12, Batch 600] loss: 0.007494862238072528
[Epoch 12, Batch 700] loss: 0.009597381414896517
[Epoch 12, Batch 800] loss: 0.013136284772790531
[Epoch 12, Batch 900] loss: 0.006091118301235383
[Epoch 12, Batch 1000] loss: 0.006853754148678491
[Epoch 12, Batch 1100] loss: 0.007424259858980804
[Epoch 12, Batch 1200] loss: 0.024407622010676276
[Epoch 12, Batch 1300] loss: 0.010652233960263402
[Epoch 12, Batch 1400] loss: 0.012429207031436818
[Epoch 12, Batch 1500] loss: 0.018434969316340356
[Epoch 12, Batch 1600] loss: 0.01912558316656032
[Epoch 12, Batch 1700] loss: 0.010306965491436131
[Epoch 12, Batch 1800] loss: 0.009574151145834549
[Epoch 12, Batch 1900] loss: 0.014112559109867107
[Epoch 12, Batch 2000] loss: 0.014512390167310514
[Epoch 12, Batch 2100] loss: 0.011853640876292957
[Epoch 12, Batch 2200] loss: 0.01471159161721289
[Epoch 12, Batch 2300] loss: 0.005826508946415743
[Epoch 12, Batch 2400] loss: 0.01096033079415065
[Epoch 12, Batch 2500] loss: 0.020736866698575794
[Epoch 12, Batch 2600] loss: 0.013281575186324517
[Epoch 12, Batch 2700] loss: 0.009728166600339136
[Epoch 12, Batch 2800] loss: 0.020304353688115954
[Epoch 12, Batch 2900] loss: 0.013059158339638088
[Epoch 12, Batch 3000] loss: 0.02026714029748291
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9860
Overfitting: 0.0465
[Epoch 13, Batch 100] loss: 0.010470608412761066
[Epoch 13, Batch 200] loss: 0.012258109701551802
[Epoch 13, Batch 300] loss: 0.004910806135048915
[Epoch 13, Batch 400] loss: 0.007525321415751023
[Epoch 13, Batch 500] loss: 0.013545063629317155
[Epoch 13, Batch 600] loss: 0.013937027433566982
[Epoch 13, Batch 700] loss: 0.007579288013112091
[Epoch 13, Batch 800] loss: 0.007726432865292736
[Epoch 13, Batch 900] loss: 0.007263233681403563
[Epoch 13, Batch 1000] loss: 0.004094491736550481
[Epoch 13, Batch 1100] loss: 0.007402982267499283
[Epoch 13, Batch 1200] loss: 0.010298146456698305
[Epoch 13, Batch 1300] loss: 0.012209804652325146
[Epoch 13, Batch 1400] loss: 0.011279916008961664
[Epoch 13, Batch 1500] loss: 0.014403787983121674
[Epoch 13, Batch 1600] loss: 0.008811466637680496
[Epoch 13, Batch 1700] loss: 0.015780696240071848
[Epoch 13, Batch 1800] loss: 0.00888761777794116
[Epoch 13, Batch 1900] loss: 0.006911185202532124
[Epoch 13, Batch 2000] loss: 0.007142284141723394
[Epoch 13, Batch 2100] loss: 0.027821838030482694
[Epoch 13, Batch 2200] loss: 0.007697836220640966
[Epoch 13, Batch 2300] loss: 0.01174168323070262
[Epoch 13, Batch 2400] loss: 0.007237391529704382
[Epoch 13, Batch 2500] loss: 0.015723512355370985
[Epoch 13, Batch 2600] loss: 0.004837099063828418
[Epoch 13, Batch 2700] loss: 0.014769309336488732
[Epoch 13, Batch 2800] loss: 0.016242846021752938
[Epoch 13, Batch 2900] loss: 0.02665078754410388
[Epoch 13, Batch 3000] loss: 0.011123037633442436
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9853
Overfitting: 0.0502
[Epoch 14, Batch 100] loss: 0.010817397975079074
[Epoch 14, Batch 200] loss: 0.00578704384181492
[Epoch 14, Batch 300] loss: 0.002187195958586017
[Epoch 14, Batch 400] loss: 0.0075755546471054916
[Epoch 14, Batch 500] loss: 0.006065397979914451
[Epoch 14, Batch 600] loss: 0.008657738829897425
[Epoch 14, Batch 700] loss: 0.006966954358877047
[Epoch 14, Batch 800] loss: 0.006302861712920276
[Epoch 14, Batch 900] loss: 0.016146563659749518
[Epoch 14, Batch 1000] loss: 0.007887543711030958
[Epoch 14, Batch 1100] loss: 0.009129726300920992
[Epoch 14, Batch 1200] loss: 0.013052292101692729
[Epoch 14, Batch 1300] loss: 0.006641439925133454
[Epoch 14, Batch 1400] loss: 0.011386944584078264
[Epoch 14, Batch 1500] loss: 0.009423385097563823
[Epoch 14, Batch 1600] loss: 0.007645322664361629
[Epoch 14, Batch 1700] loss: 0.011788424672563452
[Epoch 14, Batch 1800] loss: 0.00517572238759044
[Epoch 14, Batch 1900] loss: 0.004206612256703011
[Epoch 14, Batch 2000] loss: 0.009601957482266244
[Epoch 14, Batch 2100] loss: 0.0056913610536139456
[Epoch 14, Batch 2200] loss: 0.014856618698854619
[Epoch 14, Batch 2300] loss: 0.014449041416266937
[Epoch 14, Batch 2400] loss: 0.006057902941995508
[Epoch 14, Batch 2500] loss: 0.014722484718549821
[Epoch 14, Batch 2600] loss: 0.012209578825004428
[Epoch 14, Batch 2700] loss: 0.01130987510694581
[Epoch 14, Batch 2800] loss: 0.007802704324444676
[Epoch 14, Batch 2900] loss: 0.00475251996804218
[Epoch 14, Batch 3000] loss: 0.006510841876136055
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9879
Overfitting: 0.0501
[Epoch 15, Batch 100] loss: 0.009856793564807731
[Epoch 15, Batch 200] loss: 0.010898921843554489
[Epoch 15, Batch 300] loss: 0.011391107923918753
[Epoch 15, Batch 400] loss: 0.004935236845349209
[Epoch 15, Batch 500] loss: 0.006412419100078068
[Epoch 15, Batch 600] loss: 0.0033266222921656662
[Epoch 15, Batch 700] loss: 0.007403414969012374
[Epoch 15, Batch 800] loss: 0.0052946967049388146
[Epoch 15, Batch 900] loss: 0.011648073912717792
[Epoch 15, Batch 1000] loss: 0.002943338927627792
[Epoch 15, Batch 1100] loss: 0.009952792305240337
[Epoch 15, Batch 1200] loss: 0.0027467542021315694
[Epoch 15, Batch 1300] loss: 0.004210541399000931
[Epoch 15, Batch 1400] loss: 0.011950296441464161
[Epoch 15, Batch 1500] loss: 0.004875594684336875
[Epoch 15, Batch 1600] loss: 0.014995982622900783
[Epoch 15, Batch 1700] loss: 0.012198787748177438
[Epoch 15, Batch 1800] loss: 0.00801267109171249
[Epoch 15, Batch 1900] loss: 0.003866737135699623
[Epoch 15, Batch 2000] loss: 0.00821864479539272
[Epoch 15, Batch 2100] loss: 0.0061253684321536635
[Epoch 15, Batch 2200] loss: 0.004325025939635907
[Epoch 15, Batch 2300] loss: 0.005397009423373902
[Epoch 15, Batch 2400] loss: 0.013337174512230376
[Epoch 15, Batch 2500] loss: 0.019762677619228272
[Epoch 15, Batch 2600] loss: 0.008082523371940624
[Epoch 15, Batch 2700] loss: 0.008617792693364663
[Epoch 15, Batch 2800] loss: 0.019203202536876348
[Epoch 15, Batch 2900] loss: 0.010817773054424152
[Epoch 15, Batch 3000] loss: 0.009637242272922321
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9892
Overfitting: 0.0430
[Epoch 16, Batch 100] loss: 0.004275354473472817
[Epoch 16, Batch 200] loss: 0.0019097993994461149
[Epoch 16, Batch 300] loss: 0.006928205826404792
[Epoch 16, Batch 400] loss: 0.013454467835026662
[Epoch 16, Batch 500] loss: 0.006112341295599321
[Epoch 16, Batch 600] loss: 0.005805564762990798
[Epoch 16, Batch 700] loss: 0.010353931015223878
[Epoch 16, Batch 800] loss: 0.0058720936134614024
[Epoch 16, Batch 900] loss: 0.00558740743083149
[Epoch 16, Batch 1000] loss: 0.015138986771169129
[Epoch 16, Batch 1100] loss: 0.009653445071076022
[Epoch 16, Batch 1200] loss: 0.005729383213435995
[Epoch 16, Batch 1300] loss: 0.008524652011658418
[Epoch 16, Batch 1400] loss: 0.0043968403738006145
[Epoch 16, Batch 1500] loss: 0.01049622076774085
[Epoch 16, Batch 1600] loss: 0.004441571673852423
[Epoch 16, Batch 1700] loss: 0.004517485967697894
[Epoch 16, Batch 1800] loss: 0.01482414538500052
[Epoch 16, Batch 1900] loss: 0.009604923157619396
[Epoch 16, Batch 2000] loss: 0.0023067900050273236
[Epoch 16, Batch 2100] loss: 0.006600514674664737
[Epoch 16, Batch 2200] loss: 0.0048955945301474915
[Epoch 16, Batch 2300] loss: 0.003340680280758761
[Epoch 16, Batch 2400] loss: 0.0055066766819936675
[Epoch 16, Batch 2500] loss: 0.006978899445414299
[Epoch 16, Batch 2600] loss: 0.009614782155522335
[Epoch 16, Batch 2700] loss: 0.004365417069156408
[Epoch 16, Batch 2800] loss: 0.008949254870999538
[Epoch 16, Batch 2900] loss: 0.00939767648693305
[Epoch 16, Batch 3000] loss: 0.006721618372921512
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9876
Overfitting: 0.0450
[Epoch 17, Batch 100] loss: 0.007131664204432581
[Epoch 17, Batch 200] loss: 0.004169399191365813
[Epoch 17, Batch 300] loss: 0.010342394479332597
[Epoch 17, Batch 400] loss: 0.0037478610682165937
[Epoch 17, Batch 500] loss: 0.008803914562453202
[Epoch 17, Batch 600] loss: 0.005131319032163901
[Epoch 17, Batch 700] loss: 0.0035180583130909326
[Epoch 17, Batch 800] loss: 0.006991191921192694
[Epoch 17, Batch 900] loss: 0.006259543063521846
[Epoch 17, Batch 1000] loss: 0.008535352678680396
[Epoch 17, Batch 1100] loss: 0.003617384757653781
[Epoch 17, Batch 1200] loss: 0.00424940872327852
[Epoch 17, Batch 1300] loss: 0.011069384668144267
[Epoch 17, Batch 1400] loss: 0.005680739516079712
[Epoch 17, Batch 1500] loss: 0.01003943298049137
[Epoch 17, Batch 1600] loss: 0.007725590251668564
[Epoch 17, Batch 1700] loss: 0.01038120249113831
[Epoch 17, Batch 1800] loss: 0.004501243331569498
[Epoch 17, Batch 1900] loss: 0.0051809542886735475
[Epoch 17, Batch 2000] loss: 0.004839466270971684
[Epoch 17, Batch 2100] loss: 0.007828907202059554
[Epoch 17, Batch 2200] loss: 0.01029508229377143
[Epoch 17, Batch 2300] loss: 0.012324343873316365
[Epoch 17, Batch 2400] loss: 0.0060726731635975285
[Epoch 17, Batch 2500] loss: 0.013938745150489922
[Epoch 17, Batch 2600] loss: 0.003621167444387652
[Epoch 17, Batch 2700] loss: 0.007743484884013014
[Epoch 17, Batch 2800] loss: 0.0027273789681004244
[Epoch 17, Batch 2900] loss: 0.010608170772461562
[Epoch 17, Batch 3000] loss: 0.005612715603284073
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9884
Overfitting: 0.0459
[Epoch 18, Batch 100] loss: 0.0062915852135105865
[Epoch 18, Batch 200] loss: 0.003721614555439601
[Epoch 18, Batch 300] loss: 0.006989922873981982
[Epoch 18, Batch 400] loss: 0.009098917522123884
[Epoch 18, Batch 500] loss: 0.007294205001637692
[Epoch 18, Batch 600] loss: 0.0038246664620169213
[Epoch 18, Batch 700] loss: 0.006849299660418637
[Epoch 18, Batch 800] loss: 0.009391379010474736
[Epoch 18, Batch 900] loss: 0.001673811253679105
[Epoch 18, Batch 1000] loss: 0.002026501206843818
[Epoch 18, Batch 1100] loss: 0.005093354979850346
[Epoch 18, Batch 1200] loss: 0.008933523028198352
[Epoch 18, Batch 1300] loss: 0.005779252212978463
[Epoch 18, Batch 1400] loss: 0.016354598928992346
[Epoch 18, Batch 1500] loss: 0.006050382284250873
[Epoch 18, Batch 1600] loss: 0.006347851703775404
[Epoch 18, Batch 1700] loss: 0.006482318811592904
[Epoch 18, Batch 1800] loss: 0.007980545986251855
[Epoch 18, Batch 1900] loss: 0.004725641786479855
[Epoch 18, Batch 2000] loss: 0.0019243754544714874
[Epoch 18, Batch 2100] loss: 0.008667586230392316
[Epoch 18, Batch 2200] loss: 0.002647164944588667
[Epoch 18, Batch 2300] loss: 0.0018706500057078302
[Epoch 18, Batch 2400] loss: 0.00215422768567862
[Epoch 18, Batch 2500] loss: 0.0064401494601679585
[Epoch 18, Batch 2600] loss: 0.007425135226429802
[Epoch 18, Batch 2700] loss: 0.0024460875523607227
[Epoch 18, Batch 2800] loss: 0.0025568297602222858
[Epoch 18, Batch 2900] loss: 0.003796109031257515
[Epoch 18, Batch 3000] loss: 0.00866328117185276
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9874
Overfitting: 0.0482
[Epoch 19, Batch 100] loss: 0.005826310044573688
[Epoch 19, Batch 200] loss: 0.0021243442720403037
[Epoch 19, Batch 300] loss: 0.0035498685843913334
[Epoch 19, Batch 400] loss: 0.00667419030246947
[Epoch 19, Batch 500] loss: 0.0016436902299611234
[Epoch 19, Batch 600] loss: 0.0051213258078115585
[Epoch 19, Batch 700] loss: 0.010782443597399834
[Epoch 19, Batch 800] loss: 0.0050567207165204305
[Epoch 19, Batch 900] loss: 0.007724756671796058
[Epoch 19, Batch 1000] loss: 0.0022181553152069
[Epoch 19, Batch 1100] loss: 0.006372709237480479
[Epoch 19, Batch 1200] loss: 0.0038419700574968373
[Epoch 19, Batch 1300] loss: 0.002007911220658798
[Epoch 19, Batch 1400] loss: 0.005063924584063671
[Epoch 19, Batch 1500] loss: 0.001987017622953431
[Epoch 19, Batch 1600] loss: 0.004203622665254442
[Epoch 19, Batch 1700] loss: 0.004883272013928206
[Epoch 19, Batch 1800] loss: 0.0027774681515461454
[Epoch 19, Batch 1900] loss: 0.0030067525122478857
[Epoch 19, Batch 2000] loss: 0.004244412855761084
[Epoch 19, Batch 2100] loss: 0.007142422788844272
[Epoch 19, Batch 2200] loss: 0.004998110618063265
[Epoch 19, Batch 2300] loss: 0.0034502720511377307
[Epoch 19, Batch 2400] loss: 0.0033528092155722788
[Epoch 19, Batch 2500] loss: 0.00367905167215298
[Epoch 19, Batch 2600] loss: 0.0020204806542329836
[Epoch 19, Batch 2700] loss: 0.003654214893765868
[Epoch 19, Batch 2800] loss: 0.004357795364083472
[Epoch 19, Batch 2900] loss: 0.0036687655623204307
[Epoch 19, Batch 3000] loss: 0.009812779564158517
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9885
Overfitting: 0.0436
[Epoch 20, Batch 100] loss: 0.002216742765925801
[Epoch 20, Batch 200] loss: 0.0028315961967956584
[Epoch 20, Batch 300] loss: 0.0025124466940830816
[Epoch 20, Batch 400] loss: 0.0018390413443637498
[Epoch 20, Batch 500] loss: 0.0007232142744450698
[Epoch 20, Batch 600] loss: 0.002132592695530491
[Epoch 20, Batch 700] loss: 0.002522753590206008
[Epoch 20, Batch 800] loss: 0.003301860334433542
[Epoch 20, Batch 900] loss: 0.004145925140418427
[Epoch 20, Batch 1000] loss: 0.005415510588427708
[Epoch 20, Batch 1100] loss: 0.002138539457912714
[Epoch 20, Batch 1200] loss: 0.001756743399455445
[Epoch 20, Batch 1300] loss: 0.0014766019995434477
[Epoch 20, Batch 1400] loss: 0.0017449692203004474
[Epoch 20, Batch 1500] loss: 0.0006334770208306395
[Epoch 20, Batch 1600] loss: 0.002094306059536208
[Epoch 20, Batch 1700] loss: 0.002923455825873589
[Epoch 20, Batch 1800] loss: 0.007928779181731613
[Epoch 20, Batch 1900] loss: 0.003927493291623278
[Epoch 20, Batch 2000] loss: 0.002853239536532328
[Epoch 20, Batch 2100] loss: 0.008170186893578376
[Epoch 20, Batch 2200] loss: 0.0025350306930249644
[Epoch 20, Batch 2300] loss: 0.0034115115076056666
[Epoch 20, Batch 2400] loss: 0.005428943188920527
[Epoch 20, Batch 2500] loss: 0.004366065872767706
[Epoch 20, Batch 2600] loss: 0.0035984162725921465
[Epoch 20, Batch 2700] loss: 0.0010176750715174877
[Epoch 20, Batch 2800] loss: 0.0007041657080949193
[Epoch 20, Batch 2900] loss: 0.00468744967603925
[Epoch 20, Batch 3000] loss: 0.003263757421077571
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9879
Overfitting: 0.0491
[Epoch 21, Batch 100] loss: 0.0014174598235958769
[Epoch 21, Batch 200] loss: 0.0030042716680554805
[Epoch 21, Batch 300] loss: 0.0008929193748360831
[Epoch 21, Batch 400] loss: 0.0008260871141117576
[Epoch 21, Batch 500] loss: 0.0007093164166528254
[Epoch 21, Batch 600] loss: 0.0018997627145812678
[Epoch 21, Batch 700] loss: 0.0010871088386801375
[Epoch 21, Batch 800] loss: 0.0015548848462720599
[Epoch 21, Batch 900] loss: 0.010182373728315425
[Epoch 21, Batch 1000] loss: 0.014867677155638432
[Epoch 21, Batch 1100] loss: 0.003211904870345066
[Epoch 21, Batch 1200] loss: 0.0024499122691779007
[Epoch 21, Batch 1300] loss: 0.004005812512812099
[Epoch 21, Batch 1400] loss: 0.0032331374875627715
[Epoch 21, Batch 1500] loss: 0.004743855126285439
[Epoch 21, Batch 1600] loss: 0.001373560665045659
[Epoch 21, Batch 1700] loss: 0.0017133519142643648
[Epoch 21, Batch 1800] loss: 0.0021672848637081187
[Epoch 21, Batch 1900] loss: 0.002653660160513596
[Epoch 21, Batch 2000] loss: 0.0011409716819433414
[Epoch 21, Batch 2100] loss: 0.006277415029775706
[Epoch 21, Batch 2200] loss: 0.005734114382293569
[Epoch 21, Batch 2300] loss: 0.004378002317719165
[Epoch 21, Batch 2400] loss: 0.0031589604338432766
[Epoch 21, Batch 2500] loss: 0.0025013272391302623
[Epoch 21, Batch 2600] loss: 0.004781409703347493
[Epoch 21, Batch 2700] loss: 0.002892882551663831
[Epoch 21, Batch 2800] loss: 0.0043917436760045805
[Epoch 21, Batch 2900] loss: 0.002193466187957256
[Epoch 21, Batch 3000] loss: 0.0010508760848699694
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9886
Overfitting: 0.0469
[Epoch 22, Batch 100] loss: 0.001204181380219751
[Epoch 22, Batch 200] loss: 0.003537962859293202
[Epoch 22, Batch 300] loss: 0.004939206764349677
[Epoch 22, Batch 400] loss: 0.0016565043455801743
[Epoch 22, Batch 500] loss: 0.0018169495818170845
[Epoch 22, Batch 600] loss: 0.004228615624843002
[Epoch 22, Batch 700] loss: 0.0020595355043180066
[Epoch 22, Batch 800] loss: 0.003744090152105457
[Epoch 22, Batch 900] loss: 0.003043157518023918
[Epoch 22, Batch 1000] loss: 0.0018174022418781276
[Epoch 22, Batch 1100] loss: 0.0015104033483891045
[Epoch 22, Batch 1200] loss: 0.006723056452137683
[Epoch 22, Batch 1300] loss: 0.004912260466788609
[Epoch 22, Batch 1400] loss: 0.0018352156563878452
[Epoch 22, Batch 1500] loss: 0.004165685041056974
[Epoch 22, Batch 1600] loss: 0.0016541615597888892
[Epoch 22, Batch 1700] loss: 0.0009783412164675554
[Epoch 22, Batch 1800] loss: 0.0016868839713768402
[Epoch 22, Batch 1900] loss: 0.003074070682853849
[Epoch 22, Batch 2000] loss: 0.0073767455406449755
[Epoch 22, Batch 2100] loss: 0.003264158045188519
[Epoch 22, Batch 2200] loss: 0.00802858347750032
[Epoch 22, Batch 2300] loss: 0.0016742690221417432
[Epoch 22, Batch 2400] loss: 0.0013475456465570801
[Epoch 22, Batch 2500] loss: 0.0031900660340005516
[Epoch 22, Batch 2600] loss: 0.002032003967849363
[Epoch 22, Batch 2700] loss: 0.0023056977011154346
[Epoch 22, Batch 2800] loss: 0.0014435689836823683
[Epoch 22, Batch 2900] loss: 0.002235069355923258
[Epoch 22, Batch 3000] loss: 0.0013061580419490325
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9888
Overfitting: 0.0509
[Epoch 23, Batch 100] loss: 0.0004988071803338734
[Epoch 23, Batch 200] loss: 0.0011458748372442074
[Epoch 23, Batch 300] loss: 0.0005622779157859981
[Epoch 23, Batch 400] loss: 0.0007660045761811318
[Epoch 23, Batch 500] loss: 0.0006187833380797514
[Epoch 23, Batch 600] loss: 0.0016870118469915951
[Epoch 23, Batch 700] loss: 0.001525416836912683
[Epoch 23, Batch 800] loss: 0.0006401352736440202
[Epoch 23, Batch 900] loss: 0.0018672450558054265
[Epoch 23, Batch 1000] loss: 0.0008057806927782351
[Epoch 23, Batch 1100] loss: 0.000994204089030344
[Epoch 23, Batch 1200] loss: 0.0008845928372326739
[Epoch 23, Batch 1300] loss: 0.0009768259202414954
[Epoch 23, Batch 1400] loss: 0.0008885306941833448
[Epoch 23, Batch 1500] loss: 0.0006709999315542347
[Epoch 23, Batch 1600] loss: 0.002046332893244056
[Epoch 23, Batch 1700] loss: 0.0006295641969126109
[Epoch 23, Batch 1800] loss: 0.0014652696210140448
[Epoch 23, Batch 1900] loss: 0.003378391859693011
[Epoch 23, Batch 2000] loss: 0.005226855672536885
[Epoch 23, Batch 2100] loss: 0.004545727561030333
[Epoch 23, Batch 2200] loss: 0.002215501553109789
[Epoch 23, Batch 2300] loss: 0.001557198533881774
[Epoch 23, Batch 2400] loss: 0.0012562072039404627
[Epoch 23, Batch 2500] loss: 0.003876567025630493
[Epoch 23, Batch 2600] loss: 0.0007985722576648868
[Epoch 23, Batch 2700] loss: 0.0015167483280959003
[Epoch 23, Batch 2800] loss: 0.0011922854622851275
[Epoch 23, Batch 2900] loss: 0.0014972941033183672
[Epoch 23, Batch 3000] loss: 0.0016151600866805805
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9873
Overfitting: 0.0538
[Epoch 24, Batch 100] loss: 0.0021615798594037017
[Epoch 24, Batch 200] loss: 0.0010105920289825443
[Epoch 24, Batch 300] loss: 0.003513845413694838
[Epoch 24, Batch 400] loss: 0.000983783261830382
[Epoch 24, Batch 500] loss: 0.0007447419796197608
[Epoch 24, Batch 600] loss: 0.0006073655327620031
[Epoch 24, Batch 700] loss: 0.0005231999504334794
[Epoch 24, Batch 800] loss: 0.0008416671933684583
[Epoch 24, Batch 900] loss: 0.0004041785258665698
[Epoch 24, Batch 1000] loss: 0.0006920552615270025
[Epoch 24, Batch 1100] loss: 0.0002483724837399137
[Epoch 24, Batch 1200] loss: 0.0005259922026837316
[Epoch 24, Batch 1300] loss: 0.002535642574943324
[Epoch 24, Batch 1400] loss: 0.0008864577129192242
[Epoch 24, Batch 1500] loss: 0.002098950562050028
[Epoch 24, Batch 1600] loss: 0.002058379445506371
[Epoch 24, Batch 1700] loss: 0.001788530072259249
[Epoch 24, Batch 1800] loss: 0.0010275317406782847
[Epoch 24, Batch 1900] loss: 0.0013201299775994358
[Epoch 24, Batch 2000] loss: 0.0013013493530072751
[Epoch 24, Batch 2100] loss: 0.0018934824140777451
[Epoch 24, Batch 2200] loss: 0.0009951814487813059
[Epoch 24, Batch 2300] loss: 0.0012027530107389594
[Epoch 24, Batch 2400] loss: 0.0028400384215332775
[Epoch 24, Batch 2500] loss: 0.0007492441399335093
[Epoch 24, Batch 2600] loss: 0.0011907538239406001
[Epoch 24, Batch 2700] loss: 0.000959505333155839
[Epoch 24, Batch 2800] loss: 0.0016822025877253034
[Epoch 24, Batch 2900] loss: 0.005083936026798881
[Epoch 24, Batch 3000] loss: 0.0023126471391914905
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9883
Overfitting: 0.0516
Fold 4 validation loss: 0.0516
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.282326304912567
[Epoch 1, Batch 200] loss: 2.1870932185649874
[Epoch 1, Batch 300] loss: 1.5177203458547592
[Epoch 1, Batch 400] loss: 0.6652687186002731
[Epoch 1, Batch 500] loss: 0.45922022968530657
[Epoch 1, Batch 600] loss: 0.42474030613899233
[Epoch 1, Batch 700] loss: 0.3443072222173214
[Epoch 1, Batch 800] loss: 0.3046954174339771
[Epoch 1, Batch 900] loss: 0.2883740957081318
[Epoch 1, Batch 1000] loss: 0.23465410485863686
[Epoch 1, Batch 1100] loss: 0.22029821360483764
[Epoch 1, Batch 1200] loss: 0.23585314681753516
[Epoch 1, Batch 1300] loss: 0.22994152661412953
[Epoch 1, Batch 1400] loss: 0.18527000676840544
[Epoch 1, Batch 1500] loss: 0.19113173536024988
[Epoch 1, Batch 1600] loss: 0.16871274853125215
[Epoch 1, Batch 1700] loss: 0.16059622868429868
[Epoch 1, Batch 1800] loss: 0.17204417487140744
[Epoch 1, Batch 1900] loss: 0.2129646584764123
[Epoch 1, Batch 2000] loss: 0.17144432204775512
[Epoch 1, Batch 2100] loss: 0.1625513407867402
[Epoch 1, Batch 2200] loss: 0.12607199586927892
[Epoch 1, Batch 2300] loss: 0.14673864224925637
[Epoch 1, Batch 2400] loss: 0.12597658119630067
[Epoch 1, Batch 2500] loss: 0.15495135068893431
[Epoch 1, Batch 2600] loss: 0.171003485028632
[Epoch 1, Batch 2700] loss: 0.1254653483396396
[Epoch 1, Batch 2800] loss: 0.11266352813690901
[Epoch 1, Batch 2900] loss: 0.10487278077984229
[Epoch 1, Batch 3000] loss: 0.10970489135943354
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1095
Validation Accuracy: 0.9656
Overfitting: 0.1095
Best model saved at epoch 1 with validation loss: 0.1095
[Epoch 2, Batch 100] loss: 0.09107359930290841
[Epoch 2, Batch 200] loss: 0.109418574788142
[Epoch 2, Batch 300] loss: 0.08966022478416562
[Epoch 2, Batch 400] loss: 0.09094832719420083
[Epoch 2, Batch 500] loss: 0.09256652355194092
[Epoch 2, Batch 600] loss: 0.10709341818699614
[Epoch 2, Batch 700] loss: 0.09437109474674799
[Epoch 2, Batch 800] loss: 0.10829797978512942
[Epoch 2, Batch 900] loss: 0.09967852442059666
[Epoch 2, Batch 1000] loss: 0.08848168015247211
[Epoch 2, Batch 1100] loss: 0.10127659022342414
[Epoch 2, Batch 1200] loss: 0.09462148485938088
[Epoch 2, Batch 1300] loss: 0.07048674409976229
[Epoch 2, Batch 1400] loss: 0.08564285822445526
[Epoch 2, Batch 1500] loss: 0.09616028149146587
[Epoch 2, Batch 1600] loss: 0.09508803421165794
[Epoch 2, Batch 1700] loss: 0.08485667906701565
[Epoch 2, Batch 1800] loss: 0.09812591568334028
[Epoch 2, Batch 1900] loss: 0.07154712416580879
[Epoch 2, Batch 2000] loss: 0.09698653309838846
[Epoch 2, Batch 2100] loss: 0.07065064540947788
[Epoch 2, Batch 2200] loss: 0.06147437308274675
[Epoch 2, Batch 2300] loss: 0.08209076203696895
[Epoch 2, Batch 2400] loss: 0.09788124819286168
[Epoch 2, Batch 2500] loss: 0.08676812161924317
[Epoch 2, Batch 2600] loss: 0.08299086779821664
[Epoch 2, Batch 2700] loss: 0.09004606645554304
[Epoch 2, Batch 2800] loss: 0.07895030696061439
[Epoch 2, Batch 2900] loss: 0.060356566444970665
[Epoch 2, Batch 3000] loss: 0.08026217993698083
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0789
Validation Accuracy: 0.9762
Overfitting: 0.0789
Best model saved at epoch 2 with validation loss: 0.0789
[Epoch 3, Batch 100] loss: 0.048421600902802314
[Epoch 3, Batch 200] loss: 0.06846436257939786
[Epoch 3, Batch 300] loss: 0.08363955343374982
[Epoch 3, Batch 400] loss: 0.06649501519510523
[Epoch 3, Batch 500] loss: 0.05407881017017644
[Epoch 3, Batch 600] loss: 0.06531248530605809
[Epoch 3, Batch 700] loss: 0.06936783669574652
[Epoch 3, Batch 800] loss: 0.05833089338382706
[Epoch 3, Batch 900] loss: 0.06447334906813922
[Epoch 3, Batch 1000] loss: 0.0670925264887046
[Epoch 3, Batch 1100] loss: 0.041212199078290726
[Epoch 3, Batch 1200] loss: 0.06234948267810978
[Epoch 3, Batch 1300] loss: 0.043765300634258895
[Epoch 3, Batch 1400] loss: 0.05688104370346991
[Epoch 3, Batch 1500] loss: 0.05251135955681093
[Epoch 3, Batch 1600] loss: 0.07144774419954046
[Epoch 3, Batch 1700] loss: 0.05929592135653365
[Epoch 3, Batch 1800] loss: 0.05810787579335738
[Epoch 3, Batch 1900] loss: 0.05999497376353247
[Epoch 3, Batch 2000] loss: 0.06356556420796551
[Epoch 3, Batch 2100] loss: 0.05302726917376276
[Epoch 3, Batch 2200] loss: 0.053585404173936695
[Epoch 3, Batch 2300] loss: 0.07864655226585456
[Epoch 3, Batch 2400] loss: 0.0603899607740459
[Epoch 3, Batch 2500] loss: 0.05004822194343433
[Epoch 3, Batch 2600] loss: 0.06064360446995124
[Epoch 3, Batch 2700] loss: 0.05914947352546733
[Epoch 3, Batch 2800] loss: 0.06664103878487367
[Epoch 3, Batch 2900] loss: 0.0739545903968974
[Epoch 3, Batch 3000] loss: 0.07350366327562369
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9828
Overfitting: 0.0564
Best model saved at epoch 3 with validation loss: 0.0564
[Epoch 4, Batch 100] loss: 0.0348693025787361
[Epoch 4, Batch 200] loss: 0.0368962699000258
[Epoch 4, Batch 300] loss: 0.053708260597195474
[Epoch 4, Batch 400] loss: 0.06740400184120517
[Epoch 4, Batch 500] loss: 0.04090270620479714
[Epoch 4, Batch 600] loss: 0.06425968669296708
[Epoch 4, Batch 700] loss: 0.04364478465053253
[Epoch 4, Batch 800] loss: 0.0639224303975061
[Epoch 4, Batch 900] loss: 0.04395879724965198
[Epoch 4, Batch 1000] loss: 0.06881260291993385
[Epoch 4, Batch 1100] loss: 0.07265362612961326
[Epoch 4, Batch 1200] loss: 0.0426462622237159
[Epoch 4, Batch 1300] loss: 0.04752026229631156
[Epoch 4, Batch 1400] loss: 0.04212961426645052
[Epoch 4, Batch 1500] loss: 0.043407884680782445
[Epoch 4, Batch 1600] loss: 0.05101700751547469
[Epoch 4, Batch 1700] loss: 0.060041386110242456
[Epoch 4, Batch 1800] loss: 0.045517532840895
[Epoch 4, Batch 1900] loss: 0.02818427439458901
[Epoch 4, Batch 2000] loss: 0.04030463171890006
[Epoch 4, Batch 2100] loss: 0.03538542259731912
[Epoch 4, Batch 2200] loss: 0.03675280137598747
[Epoch 4, Batch 2300] loss: 0.04129530770354904
[Epoch 4, Batch 2400] loss: 0.035704244086082325
[Epoch 4, Batch 2500] loss: 0.04362411522248294
[Epoch 4, Batch 2600] loss: 0.04394716701135622
[Epoch 4, Batch 2700] loss: 0.05105775980046019
[Epoch 4, Batch 2800] loss: 0.05359865727208671
[Epoch 4, Batch 2900] loss: 0.04076911305281101
[Epoch 4, Batch 3000] loss: 0.043359522493556145
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9858
Overfitting: 0.0456
Best model saved at epoch 4 with validation loss: 0.0456
[Epoch 5, Batch 100] loss: 0.03779803755664034
[Epoch 5, Batch 200] loss: 0.047675280931871386
[Epoch 5, Batch 300] loss: 0.029411532150406858
[Epoch 5, Batch 400] loss: 0.02747227989748353
[Epoch 5, Batch 500] loss: 0.03603689967967512
[Epoch 5, Batch 600] loss: 0.05139646938987426
[Epoch 5, Batch 700] loss: 0.05770430337041035
[Epoch 5, Batch 800] loss: 0.04303456217370694
[Epoch 5, Batch 900] loss: 0.05059288032032782
[Epoch 5, Batch 1000] loss: 0.038136266806104685
[Epoch 5, Batch 1100] loss: 0.04924924336999539
[Epoch 5, Batch 1200] loss: 0.03362104879226536
[Epoch 5, Batch 1300] loss: 0.0464318942007958
[Epoch 5, Batch 1400] loss: 0.03162601102812914
[Epoch 5, Batch 1500] loss: 0.0350977242301451
[Epoch 5, Batch 1600] loss: 0.04448338607384358
[Epoch 5, Batch 1700] loss: 0.030114296013780403
[Epoch 5, Batch 1800] loss: 0.03784922254038975
[Epoch 5, Batch 1900] loss: 0.05453952148134704
[Epoch 5, Batch 2000] loss: 0.046100537870806875
[Epoch 5, Batch 2100] loss: 0.018132587792060804
[Epoch 5, Batch 2200] loss: 0.051045392492669636
[Epoch 5, Batch 2300] loss: 0.03745264369776123
[Epoch 5, Batch 2400] loss: 0.038726095866513786
[Epoch 5, Batch 2500] loss: 0.028853303088253596
[Epoch 5, Batch 2600] loss: 0.04110826084128348
[Epoch 5, Batch 2700] loss: 0.041277203766076125
[Epoch 5, Batch 2800] loss: 0.04181308793238713
[Epoch 5, Batch 2900] loss: 0.034406459821766475
[Epoch 5, Batch 3000] loss: 0.0354061698053556
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9845
Overfitting: 0.0495
[Epoch 6, Batch 100] loss: 0.04782783431757707
[Epoch 6, Batch 200] loss: 0.03668341377764591
[Epoch 6, Batch 300] loss: 0.01911734021261509
[Epoch 6, Batch 400] loss: 0.02695113782174303
[Epoch 6, Batch 500] loss: 0.03279902736605436
[Epoch 6, Batch 600] loss: 0.029933230432725395
[Epoch 6, Batch 700] loss: 0.03355976080551045
[Epoch 6, Batch 800] loss: 0.024349502453478635
[Epoch 6, Batch 900] loss: 0.026935977307366556
[Epoch 6, Batch 1000] loss: 0.025199146325321636
[Epoch 6, Batch 1100] loss: 0.027496617984143087
[Epoch 6, Batch 1200] loss: 0.032439581436265144
[Epoch 6, Batch 1300] loss: 0.035222184322337854
[Epoch 6, Batch 1400] loss: 0.04454683381540235
[Epoch 6, Batch 1500] loss: 0.04442926375573734
[Epoch 6, Batch 1600] loss: 0.0255502542452723
[Epoch 6, Batch 1700] loss: 0.026852536705628153
[Epoch 6, Batch 1800] loss: 0.0381960742767842
[Epoch 6, Batch 1900] loss: 0.06124492455208383
[Epoch 6, Batch 2000] loss: 0.02878432165744016
[Epoch 6, Batch 2100] loss: 0.033500839463522426
[Epoch 6, Batch 2200] loss: 0.03258030325552681
[Epoch 6, Batch 2300] loss: 0.037258049337251575
[Epoch 6, Batch 2400] loss: 0.05292222276722896
[Epoch 6, Batch 2500] loss: 0.025585817754763412
[Epoch 6, Batch 2600] loss: 0.03890405210811878
[Epoch 6, Batch 2700] loss: 0.024820074425442727
[Epoch 6, Batch 2800] loss: 0.03248914363546646
[Epoch 6, Batch 2900] loss: 0.03756241339706321
[Epoch 6, Batch 3000] loss: 0.03327301177676418
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9832
Overfitting: 0.0533
[Epoch 7, Batch 100] loss: 0.03672366391263495
[Epoch 7, Batch 200] loss: 0.022669710846676027
[Epoch 7, Batch 300] loss: 0.023286563557630872
[Epoch 7, Batch 400] loss: 0.024779051550722214
[Epoch 7, Batch 500] loss: 0.03802151927844534
[Epoch 7, Batch 600] loss: 0.020963117658538977
[Epoch 7, Batch 700] loss: 0.02259273273215513
[Epoch 7, Batch 800] loss: 0.02352175431115029
[Epoch 7, Batch 900] loss: 0.02128249399662309
[Epoch 7, Batch 1000] loss: 0.02648670797556406
[Epoch 7, Batch 1100] loss: 0.024965484664426184
[Epoch 7, Batch 1200] loss: 0.03363867414198467
[Epoch 7, Batch 1300] loss: 0.03206824634573422
[Epoch 7, Batch 1400] loss: 0.03635353908175602
[Epoch 7, Batch 1500] loss: 0.02941764247501851
[Epoch 7, Batch 1600] loss: 0.028397841920159407
[Epoch 7, Batch 1700] loss: 0.030286449661580263
[Epoch 7, Batch 1800] loss: 0.03719494160293834
[Epoch 7, Batch 1900] loss: 0.04117195396873285
[Epoch 7, Batch 2000] loss: 0.039841541677742495
[Epoch 7, Batch 2100] loss: 0.024134803442284466
[Epoch 7, Batch 2200] loss: 0.015729929065601028
[Epoch 7, Batch 2300] loss: 0.028061028562879075
[Epoch 7, Batch 2400] loss: 0.021079465788734524
[Epoch 7, Batch 2500] loss: 0.025912635283748386
[Epoch 7, Batch 2600] loss: 0.030728759975900174
[Epoch 7, Batch 2700] loss: 0.03250856357648445
[Epoch 7, Batch 2800] loss: 0.03220153087488143
[Epoch 7, Batch 2900] loss: 0.023358255197599646
[Epoch 7, Batch 3000] loss: 0.036791631066662375
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0521
Validation Accuracy: 0.9832
Overfitting: 0.0521
[Epoch 8, Batch 100] loss: 0.017951099727943075
[Epoch 8, Batch 200] loss: 0.024941194991988595
[Epoch 8, Batch 300] loss: 0.022067467259985277
[Epoch 8, Batch 400] loss: 0.03290060511637421
[Epoch 8, Batch 500] loss: 0.026317117220241926
[Epoch 8, Batch 600] loss: 0.023306573423178635
[Epoch 8, Batch 700] loss: 0.031087287129921606
[Epoch 8, Batch 800] loss: 0.01762508456438809
[Epoch 8, Batch 900] loss: 0.01791784676279349
[Epoch 8, Batch 1000] loss: 0.017239880845299923
[Epoch 8, Batch 1100] loss: 0.030302194965079254
[Epoch 8, Batch 1200] loss: 0.023717128192729434
[Epoch 8, Batch 1300] loss: 0.022105227580723294
[Epoch 8, Batch 1400] loss: 0.02807715571785593
[Epoch 8, Batch 1500] loss: 0.029101889250960085
[Epoch 8, Batch 1600] loss: 0.02656519757329079
[Epoch 8, Batch 1700] loss: 0.015330892587626295
[Epoch 8, Batch 1800] loss: 0.022947345945394774
[Epoch 8, Batch 1900] loss: 0.024191036848060322
[Epoch 8, Batch 2000] loss: 0.024380415624691523
[Epoch 8, Batch 2100] loss: 0.02223849724046886
[Epoch 8, Batch 2200] loss: 0.015473707080964232
[Epoch 8, Batch 2300] loss: 0.037949629343274865
[Epoch 8, Batch 2400] loss: 0.026617298142737125
[Epoch 8, Batch 2500] loss: 0.0278361286209838
[Epoch 8, Batch 2600] loss: 0.01851552369686033
[Epoch 8, Batch 2700] loss: 0.03058202768872434
[Epoch 8, Batch 2800] loss: 0.053503518596335196
[Epoch 8, Batch 2900] loss: 0.022645492300071055
[Epoch 8, Batch 3000] loss: 0.016902251430692558
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0351
Validation Accuracy: 0.9897
Overfitting: 0.0351
Best model saved at epoch 8 with validation loss: 0.0351
[Epoch 9, Batch 100] loss: 0.011072532268735813
[Epoch 9, Batch 200] loss: 0.020745895092913996
[Epoch 9, Batch 300] loss: 0.015225273587730044
[Epoch 9, Batch 400] loss: 0.011141838098010339
[Epoch 9, Batch 500] loss: 0.01639886310276779
[Epoch 9, Batch 600] loss: 0.023018096246742063
[Epoch 9, Batch 700] loss: 0.022104836082107795
[Epoch 9, Batch 800] loss: 0.013881901654458488
[Epoch 9, Batch 900] loss: 0.015991173792899646
[Epoch 9, Batch 1000] loss: 0.020701712059453713
[Epoch 9, Batch 1100] loss: 0.021447731198313703
[Epoch 9, Batch 1200] loss: 0.03065811223721539
[Epoch 9, Batch 1300] loss: 0.023647832184087746
[Epoch 9, Batch 1400] loss: 0.03099634409391001
[Epoch 9, Batch 1500] loss: 0.020690975634206552
[Epoch 9, Batch 1600] loss: 0.023693574072312915
[Epoch 9, Batch 1700] loss: 0.015174689145933371
[Epoch 9, Batch 1800] loss: 0.024230435931385727
[Epoch 9, Batch 1900] loss: 0.025887607921067684
[Epoch 9, Batch 2000] loss: 0.01843964709519696
[Epoch 9, Batch 2100] loss: 0.01091116574811167
[Epoch 9, Batch 2200] loss: 0.013765909584471957
[Epoch 9, Batch 2300] loss: 0.013166196058373316
[Epoch 9, Batch 2400] loss: 0.034986871308501574
[Epoch 9, Batch 2500] loss: 0.021254899531631965
[Epoch 9, Batch 2600] loss: 0.01729932900823769
[Epoch 9, Batch 2700] loss: 0.009928500656933466
[Epoch 9, Batch 2800] loss: 0.035941076681301636
[Epoch 9, Batch 2900] loss: 0.03411014347930177
[Epoch 9, Batch 3000] loss: 0.033197456200323355
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0488
Validation Accuracy: 0.9839
Overfitting: 0.0488
[Epoch 10, Batch 100] loss: 0.00979471424159783
[Epoch 10, Batch 200] loss: 0.008377693253114557
[Epoch 10, Batch 300] loss: 0.01644598600527388
[Epoch 10, Batch 400] loss: 0.012791258810502769
[Epoch 10, Batch 500] loss: 0.008342585021437117
[Epoch 10, Batch 600] loss: 0.008260279636515407
[Epoch 10, Batch 700] loss: 0.01193661798586163
[Epoch 10, Batch 800] loss: 0.019069840090742217
[Epoch 10, Batch 900] loss: 0.023283316872475552
[Epoch 10, Batch 1000] loss: 0.019594167426494096
[Epoch 10, Batch 1100] loss: 0.013373044665022461
[Epoch 10, Batch 1200] loss: 0.031339686709657144
[Epoch 10, Batch 1300] loss: 0.027108029498958786
[Epoch 10, Batch 1400] loss: 0.024435032962519473
[Epoch 10, Batch 1500] loss: 0.027869593075301964
[Epoch 10, Batch 1600] loss: 0.02664203676242323
[Epoch 10, Batch 1700] loss: 0.017131243843505218
[Epoch 10, Batch 1800] loss: 0.01775575418425433
[Epoch 10, Batch 1900] loss: 0.02770520232279523
[Epoch 10, Batch 2000] loss: 0.01724587021145453
[Epoch 10, Batch 2100] loss: 0.017028292592221987
[Epoch 10, Batch 2200] loss: 0.01744690469942725
[Epoch 10, Batch 2300] loss: 0.017619780862150946
[Epoch 10, Batch 2400] loss: 0.010530114880857581
[Epoch 10, Batch 2500] loss: 0.009917723831458716
[Epoch 10, Batch 2600] loss: 0.022490483809597207
[Epoch 10, Batch 2700] loss: 0.021882493822949982
[Epoch 10, Batch 2800] loss: 0.02426797380336211
[Epoch 10, Batch 2900] loss: 0.014359134819060274
[Epoch 10, Batch 3000] loss: 0.014859651217884675
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0385
Validation Accuracy: 0.9884
Overfitting: 0.0385
[Epoch 11, Batch 100] loss: 0.00936918476541905
[Epoch 11, Batch 200] loss: 0.009751743283018185
[Epoch 11, Batch 300] loss: 0.021183160146210866
[Epoch 11, Batch 400] loss: 0.010407181874761591
[Epoch 11, Batch 500] loss: 0.015510599570479826
[Epoch 11, Batch 600] loss: 0.016145915583183523
[Epoch 11, Batch 700] loss: 0.009531184821134957
[Epoch 11, Batch 800] loss: 0.014108326911809854
[Epoch 11, Batch 900] loss: 0.0173126325722842
[Epoch 11, Batch 1000] loss: 0.011154846598928998
[Epoch 11, Batch 1100] loss: 0.01137275107980713
[Epoch 11, Batch 1200] loss: 0.019064687285026593
[Epoch 11, Batch 1300] loss: 0.017459452212933685
[Epoch 11, Batch 1400] loss: 0.015786238378545932
[Epoch 11, Batch 1500] loss: 0.013621311195674935
[Epoch 11, Batch 1600] loss: 0.03129217604109726
[Epoch 11, Batch 1700] loss: 0.018368464485138247
[Epoch 11, Batch 1800] loss: 0.013728844743441186
[Epoch 11, Batch 1900] loss: 0.006534416775175487
[Epoch 11, Batch 2000] loss: 0.014406344355152215
[Epoch 11, Batch 2100] loss: 0.011445148733055249
[Epoch 11, Batch 2200] loss: 0.016142431991447666
[Epoch 11, Batch 2300] loss: 0.014592350302627892
[Epoch 11, Batch 2400] loss: 0.03383974901094916
[Epoch 11, Batch 2500] loss: 0.019018366918528498
[Epoch 11, Batch 2600] loss: 0.018369300398771885
[Epoch 11, Batch 2700] loss: 0.016733691012232158
[Epoch 11, Batch 2800] loss: 0.0155032552695684
[Epoch 11, Batch 2900] loss: 0.017116868546354455
[Epoch 11, Batch 3000] loss: 0.0170253371578292
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9860
Overfitting: 0.0458
[Epoch 12, Batch 100] loss: 0.010882524056464718
[Epoch 12, Batch 200] loss: 0.01027703642475899
[Epoch 12, Batch 300] loss: 0.0061984715287053405
[Epoch 12, Batch 400] loss: 0.015459753205341258
[Epoch 12, Batch 500] loss: 0.018026445587890974
[Epoch 12, Batch 600] loss: 0.017514152329749778
[Epoch 12, Batch 700] loss: 0.012246515205533796
[Epoch 12, Batch 800] loss: 0.013682280159955554
[Epoch 12, Batch 900] loss: 0.00811891518567336
[Epoch 12, Batch 1000] loss: 0.008955176819099506
[Epoch 12, Batch 1100] loss: 0.007249412676974316
[Epoch 12, Batch 1200] loss: 0.018094269909952346
[Epoch 12, Batch 1300] loss: 0.008939654002078896
[Epoch 12, Batch 1400] loss: 0.025144699940410645
[Epoch 12, Batch 1500] loss: 0.016695173448033528
[Epoch 12, Batch 1600] loss: 0.00665276153613604
[Epoch 12, Batch 1700] loss: 0.010725793720539514
[Epoch 12, Batch 1800] loss: 0.006201883951744094
[Epoch 12, Batch 1900] loss: 0.014955661636795412
[Epoch 12, Batch 2000] loss: 0.010198871175871317
[Epoch 12, Batch 2100] loss: 0.012251210101157994
[Epoch 12, Batch 2200] loss: 0.010981066486706367
[Epoch 12, Batch 2300] loss: 0.005525906534116985
[Epoch 12, Batch 2400] loss: 0.020321685939343297
[Epoch 12, Batch 2500] loss: 0.022789443581918933
[Epoch 12, Batch 2600] loss: 0.01174915477666218
[Epoch 12, Batch 2700] loss: 0.012689374681549452
[Epoch 12, Batch 2800] loss: 0.010861593405597886
[Epoch 12, Batch 2900] loss: 0.00739644682144899
[Epoch 12, Batch 3000] loss: 0.02081778504027625
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0417
Validation Accuracy: 0.9878
Overfitting: 0.0417
[Epoch 13, Batch 100] loss: 0.005700114467833828
[Epoch 13, Batch 200] loss: 0.008372817238473544
[Epoch 13, Batch 300] loss: 0.012840664355480839
[Epoch 13, Batch 400] loss: 0.008696911420024662
[Epoch 13, Batch 500] loss: 0.006450781242419907
[Epoch 13, Batch 600] loss: 0.006993914242880237
[Epoch 13, Batch 700] loss: 0.00665185305080513
[Epoch 13, Batch 800] loss: 0.022616187263633947
[Epoch 13, Batch 900] loss: 0.015720015606439118
[Epoch 13, Batch 1000] loss: 0.015911135682672467
[Epoch 13, Batch 1100] loss: 0.021690865264017704
[Epoch 13, Batch 1200] loss: 0.013702227922753423
[Epoch 13, Batch 1300] loss: 0.00838982062377454
[Epoch 13, Batch 1400] loss: 0.01079189507243882
[Epoch 13, Batch 1500] loss: 0.017732423199190633
[Epoch 13, Batch 1600] loss: 0.012076441183380667
[Epoch 13, Batch 1700] loss: 0.025251529074394055
[Epoch 13, Batch 1800] loss: 0.00808117237908391
[Epoch 13, Batch 1900] loss: 0.008762200720289002
[Epoch 13, Batch 2000] loss: 0.013431214063712105
[Epoch 13, Batch 2100] loss: 0.011219262735221492
[Epoch 13, Batch 2200] loss: 0.01535217863023263
[Epoch 13, Batch 2300] loss: 0.005210068452479391
[Epoch 13, Batch 2400] loss: 0.014584018804262086
[Epoch 13, Batch 2500] loss: 0.01613609137236267
[Epoch 13, Batch 2600] loss: 0.008757208129973151
[Epoch 13, Batch 2700] loss: 0.00935473741320493
[Epoch 13, Batch 2800] loss: 0.009708829872577098
[Epoch 13, Batch 2900] loss: 0.008631843255029708
[Epoch 13, Batch 3000] loss: 0.012463278502968933
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0364
Validation Accuracy: 0.9888
Overfitting: 0.0364
[Epoch 14, Batch 100] loss: 0.018663207866666198
[Epoch 14, Batch 200] loss: 0.009286453731783694
[Epoch 14, Batch 300] loss: 0.006586059104611195
[Epoch 14, Batch 400] loss: 0.007499400967044494
[Epoch 14, Batch 500] loss: 0.006798322483273295
[Epoch 14, Batch 600] loss: 0.005546542527031306
[Epoch 14, Batch 700] loss: 0.005244681419990229
[Epoch 14, Batch 800] loss: 0.011201803672738606
[Epoch 14, Batch 900] loss: 0.010155587848998948
[Epoch 14, Batch 1000] loss: 0.009207555557900378
[Epoch 14, Batch 1100] loss: 0.003695530465026877
[Epoch 14, Batch 1200] loss: 0.007689285298365576
[Epoch 14, Batch 1300] loss: 0.008768102238379925
[Epoch 14, Batch 1400] loss: 0.007836364287062452
[Epoch 14, Batch 1500] loss: 0.006136633230745474
[Epoch 14, Batch 1600] loss: 0.02928139337170137
[Epoch 14, Batch 1700] loss: 0.01832835105687536
[Epoch 14, Batch 1800] loss: 0.00767128002117488
[Epoch 14, Batch 1900] loss: 0.022201736011816138
[Epoch 14, Batch 2000] loss: 0.014737671093930657
[Epoch 14, Batch 2100] loss: 0.013963945599671205
[Epoch 14, Batch 2200] loss: 0.014013436407331027
[Epoch 14, Batch 2300] loss: 0.012910230880702329
[Epoch 14, Batch 2400] loss: 0.007576432653199845
[Epoch 14, Batch 2500] loss: 0.006234728941690264
[Epoch 14, Batch 2600] loss: 0.007965114723974693
[Epoch 14, Batch 2700] loss: 0.00946023151574309
[Epoch 14, Batch 2800] loss: 0.015889183098770444
[Epoch 14, Batch 2900] loss: 0.009372415124430518
[Epoch 14, Batch 3000] loss: 0.020620569723778317
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9865
Overfitting: 0.0458
[Epoch 15, Batch 100] loss: 0.00419016101219313
[Epoch 15, Batch 200] loss: 0.01534522985464264
[Epoch 15, Batch 300] loss: 0.009047734670557474
[Epoch 15, Batch 400] loss: 0.015553728450577183
[Epoch 15, Batch 500] loss: 0.005955106642909413
[Epoch 15, Batch 600] loss: 0.00531438301230537
[Epoch 15, Batch 700] loss: 0.008761793005219261
[Epoch 15, Batch 800] loss: 0.01595563427621869
[Epoch 15, Batch 900] loss: 0.008220575918405188
[Epoch 15, Batch 1000] loss: 0.0076286684649176095
[Epoch 15, Batch 1100] loss: 0.004906821004647099
[Epoch 15, Batch 1200] loss: 0.01010634619515713
[Epoch 15, Batch 1300] loss: 0.005811462219260193
[Epoch 15, Batch 1400] loss: 0.005242558283280232
[Epoch 15, Batch 1500] loss: 0.005467474135236898
[Epoch 15, Batch 1600] loss: 0.007307148542165578
[Epoch 15, Batch 1700] loss: 0.015064752322778076
[Epoch 15, Batch 1800] loss: 0.005940374619203794
[Epoch 15, Batch 1900] loss: 0.012881674213060705
[Epoch 15, Batch 2000] loss: 0.00632032939703322
[Epoch 15, Batch 2100] loss: 0.014928993508130902
[Epoch 15, Batch 2200] loss: 0.005209914343513446
[Epoch 15, Batch 2300] loss: 0.009956283099845677
[Epoch 15, Batch 2400] loss: 0.012683727610873347
[Epoch 15, Batch 2500] loss: 0.010609358335580054
[Epoch 15, Batch 2600] loss: 0.01096501820415142
[Epoch 15, Batch 2700] loss: 0.013414122737964362
[Epoch 15, Batch 2800] loss: 0.010699573241890904
[Epoch 15, Batch 2900] loss: 0.013363232193778458
[Epoch 15, Batch 3000] loss: 0.013606404069582823
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0416
Validation Accuracy: 0.9886
Overfitting: 0.0416
[Epoch 16, Batch 100] loss: 0.0069268359479701756
[Epoch 16, Batch 200] loss: 0.005902175979440471
[Epoch 16, Batch 300] loss: 0.00638301172235515
[Epoch 16, Batch 400] loss: 0.01282477540878972
[Epoch 16, Batch 500] loss: 0.0072836210158357065
[Epoch 16, Batch 600] loss: 0.006884685469221949
[Epoch 16, Batch 700] loss: 0.013797607339524802
[Epoch 16, Batch 800] loss: 0.009258498093246317
[Epoch 16, Batch 900] loss: 0.005567001331364736
[Epoch 16, Batch 1000] loss: 0.002445099998121805
[Epoch 16, Batch 1100] loss: 0.0035988853262142583
[Epoch 16, Batch 1200] loss: 0.0067554623484801365
[Epoch 16, Batch 1300] loss: 0.0046366660370324555
[Epoch 16, Batch 1400] loss: 0.012005198484003473
[Epoch 16, Batch 1500] loss: 0.01082120628609573
[Epoch 16, Batch 1600] loss: 0.004040853208035742
[Epoch 16, Batch 1700] loss: 0.007705528755413979
[Epoch 16, Batch 1800] loss: 0.01141907212273054
[Epoch 16, Batch 1900] loss: 0.008783382365171519
[Epoch 16, Batch 2000] loss: 0.004356817600275917
[Epoch 16, Batch 2100] loss: 0.0036151122871558527
[Epoch 16, Batch 2200] loss: 0.008953688399016073
[Epoch 16, Batch 2300] loss: 0.008979920728170327
[Epoch 16, Batch 2400] loss: 0.006152880271611138
[Epoch 16, Batch 2500] loss: 0.008009636007614063
[Epoch 16, Batch 2600] loss: 0.006459396720858876
[Epoch 16, Batch 2700] loss: 0.009400657008278017
[Epoch 16, Batch 2800] loss: 0.007512185517762759
[Epoch 16, Batch 2900] loss: 0.011559309604358532
[Epoch 16, Batch 3000] loss: 0.01209035485011782
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0362
Validation Accuracy: 0.9899
Overfitting: 0.0362
[Epoch 17, Batch 100] loss: 0.007972563513476416
[Epoch 17, Batch 200] loss: 0.008993809778539799
[Epoch 17, Batch 300] loss: 0.00586043575295065
[Epoch 17, Batch 400] loss: 0.0031966464121364877
[Epoch 17, Batch 500] loss: 0.00924000319618017
[Epoch 17, Batch 600] loss: 0.00939514068983044
[Epoch 17, Batch 700] loss: 0.0037116903126661782
[Epoch 17, Batch 800] loss: 0.002636788309023359
[Epoch 17, Batch 900] loss: 0.0031883210583657728
[Epoch 17, Batch 1000] loss: 0.0035586868599079935
[Epoch 17, Batch 1100] loss: 0.002964080404331071
[Epoch 17, Batch 1200] loss: 0.003363011423355715
[Epoch 17, Batch 1300] loss: 0.006648353815355676
[Epoch 17, Batch 1400] loss: 0.003370575065596313
[Epoch 17, Batch 1500] loss: 0.009780646009415932
[Epoch 17, Batch 1600] loss: 0.003255780031799418
[Epoch 17, Batch 1700] loss: 0.011224978470671658
[Epoch 17, Batch 1800] loss: 0.007036257155225485
[Epoch 17, Batch 1900] loss: 0.009110352230527497
[Epoch 17, Batch 2000] loss: 0.005273961265902472
[Epoch 17, Batch 2100] loss: 0.0032326973505988122
[Epoch 17, Batch 2200] loss: 0.004449201732008845
[Epoch 17, Batch 2300] loss: 0.005335063934372783
[Epoch 17, Batch 2400] loss: 0.0032378450254987
[Epoch 17, Batch 2500] loss: 0.008013363563120492
[Epoch 17, Batch 2600] loss: 0.01102875206373028
[Epoch 17, Batch 2700] loss: 0.00342155350682674
[Epoch 17, Batch 2800] loss: 0.004754943687089508
[Epoch 17, Batch 2900] loss: 0.007889814244364288
[Epoch 17, Batch 3000] loss: 0.009682384125293311
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9882
Overfitting: 0.0439
[Epoch 18, Batch 100] loss: 0.007047280739109283
[Epoch 18, Batch 200] loss: 0.0019418757791527241
[Epoch 18, Batch 300] loss: 0.0027443284763842258
[Epoch 18, Batch 400] loss: 0.006714852088149996
[Epoch 18, Batch 500] loss: 0.005887942951827085
[Epoch 18, Batch 600] loss: 0.005174882394398992
[Epoch 18, Batch 700] loss: 0.003183053931485631
[Epoch 18, Batch 800] loss: 0.006314274190788751
[Epoch 18, Batch 900] loss: 0.004445580841847914
[Epoch 18, Batch 1000] loss: 0.005050814970571764
[Epoch 18, Batch 1100] loss: 0.0038478493704070613
[Epoch 18, Batch 1200] loss: 0.00102898295557452
[Epoch 18, Batch 1300] loss: 0.0059655040629399995
[Epoch 18, Batch 1400] loss: 0.009504302553305024
[Epoch 18, Batch 1500] loss: 0.009060527270670492
[Epoch 18, Batch 1600] loss: 0.010903807002958956
[Epoch 18, Batch 1700] loss: 0.010483804153498113
[Epoch 18, Batch 1800] loss: 0.008837289423656785
[Epoch 18, Batch 1900] loss: 0.006162225759552485
[Epoch 18, Batch 2000] loss: 0.009678385326733405
[Epoch 18, Batch 2100] loss: 0.008368954525369645
[Epoch 18, Batch 2200] loss: 0.0073042219030458
[Epoch 18, Batch 2300] loss: 0.00664801341074849
[Epoch 18, Batch 2400] loss: 0.001884949394875548
[Epoch 18, Batch 2500] loss: 0.0036862292481373514
[Epoch 18, Batch 2600] loss: 0.0036557364209647857
[Epoch 18, Batch 2700] loss: 0.004069983483034889
[Epoch 18, Batch 2800] loss: 0.009500556929199887
[Epoch 18, Batch 2900] loss: 0.009590602935030007
[Epoch 18, Batch 3000] loss: 0.009514966224969043
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0403
Validation Accuracy: 0.9895
Overfitting: 0.0403
[Epoch 19, Batch 100] loss: 0.002588886275987079
[Epoch 19, Batch 200] loss: 0.0023334885788045766
[Epoch 19, Batch 300] loss: 0.0021683177777364906
[Epoch 19, Batch 400] loss: 0.002299707936017512
[Epoch 19, Batch 500] loss: 0.005206052877600769
[Epoch 19, Batch 600] loss: 0.006217964315406163
[Epoch 19, Batch 700] loss: 0.0034571997994180493
[Epoch 19, Batch 800] loss: 0.0029558179934525697
[Epoch 19, Batch 900] loss: 0.0022121489589767406
[Epoch 19, Batch 1000] loss: 0.0019780748844203445
[Epoch 19, Batch 1100] loss: 0.002557652828359096
[Epoch 19, Batch 1200] loss: 0.004614413865630241
[Epoch 19, Batch 1300] loss: 0.002880868761076272
[Epoch 19, Batch 1400] loss: 0.011269599928455687
[Epoch 19, Batch 1500] loss: 0.00677634335690982
[Epoch 19, Batch 1600] loss: 0.005077213894043666
[Epoch 19, Batch 1700] loss: 0.011289844183149853
[Epoch 19, Batch 1800] loss: 0.007340285737000727
[Epoch 19, Batch 1900] loss: 0.0018226825044280303
[Epoch 19, Batch 2000] loss: 0.0021900099438741448
[Epoch 19, Batch 2100] loss: 0.004859962201098824
[Epoch 19, Batch 2200] loss: 0.005464998233686629
[Epoch 19, Batch 2300] loss: 0.014491254303885625
[Epoch 19, Batch 2400] loss: 0.005451072964704053
[Epoch 19, Batch 2500] loss: 0.00858586174368213
[Epoch 19, Batch 2600] loss: 0.007201467875333946
[Epoch 19, Batch 2700] loss: 0.0049003667461227
[Epoch 19, Batch 2800] loss: 0.001532005613931915
[Epoch 19, Batch 2900] loss: 0.010996181805305412
[Epoch 19, Batch 3000] loss: 0.007088789570832432
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0400
Validation Accuracy: 0.9899
Overfitting: 0.0400
[Epoch 20, Batch 100] loss: 0.011119756784040646
[Epoch 20, Batch 200] loss: 0.008182453754748166
[Epoch 20, Batch 300] loss: 0.004546963212353035
[Epoch 20, Batch 400] loss: 0.0011716774002525198
[Epoch 20, Batch 500] loss: 0.004681960588158063
[Epoch 20, Batch 600] loss: 0.0072971562545257026
[Epoch 20, Batch 700] loss: 0.006795866463151014
[Epoch 20, Batch 800] loss: 0.0053015421749775275
[Epoch 20, Batch 900] loss: 0.003271767193234041
[Epoch 20, Batch 1000] loss: 0.011088139691871675
[Epoch 20, Batch 1100] loss: 0.0016032787547928251
[Epoch 20, Batch 1200] loss: 0.002104733466582047
[Epoch 20, Batch 1300] loss: 0.004311078504356374
[Epoch 20, Batch 1400] loss: 0.003658262653542579
[Epoch 20, Batch 1500] loss: 0.0020193080056924374
[Epoch 20, Batch 1600] loss: 0.010403526854130405
[Epoch 20, Batch 1700] loss: 0.008626896403278721
[Epoch 20, Batch 1800] loss: 0.0029643141619908418
[Epoch 20, Batch 1900] loss: 0.004732853808192204
[Epoch 20, Batch 2000] loss: 0.0011828509971877565
[Epoch 20, Batch 2100] loss: 0.004348654359142188
[Epoch 20, Batch 2200] loss: 0.0012538688381737728
[Epoch 20, Batch 2300] loss: 0.005712718677370674
[Epoch 20, Batch 2400] loss: 0.008196920851811456
[Epoch 20, Batch 2500] loss: 0.0035495777167420784
[Epoch 20, Batch 2600] loss: 0.004270554562473308
[Epoch 20, Batch 2700] loss: 0.009171295047897843
[Epoch 20, Batch 2800] loss: 0.010952804310416581
[Epoch 20, Batch 2900] loss: 0.002564455765443654
[Epoch 20, Batch 3000] loss: 0.0059799964252751185
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9883
Overfitting: 0.0486
[Epoch 21, Batch 100] loss: 0.00379272494715579
[Epoch 21, Batch 200] loss: 0.0014927882969899998
[Epoch 21, Batch 300] loss: 0.004691813417950357
[Epoch 21, Batch 400] loss: 0.0021331869651200464
[Epoch 21, Batch 500] loss: 0.0013027581283347445
[Epoch 21, Batch 600] loss: 0.001301623035834325
[Epoch 21, Batch 700] loss: 0.0008559204486812178
[Epoch 21, Batch 800] loss: 0.0010646634794102283
[Epoch 21, Batch 900] loss: 0.006259616453687897
[Epoch 21, Batch 1000] loss: 0.0053507953124344
[Epoch 21, Batch 1100] loss: 0.0027555297956052983
[Epoch 21, Batch 1200] loss: 0.003971653367831891
[Epoch 21, Batch 1300] loss: 0.006544299384373744
[Epoch 21, Batch 1400] loss: 0.0087376705888488
[Epoch 21, Batch 1500] loss: 0.006063508497398402
[Epoch 21, Batch 1600] loss: 0.007145279455849618
[Epoch 21, Batch 1700] loss: 0.004193544149335935
[Epoch 21, Batch 1800] loss: 0.010522787717196707
[Epoch 21, Batch 1900] loss: 0.0028570401740148554
[Epoch 21, Batch 2000] loss: 0.010811120304780956
[Epoch 21, Batch 2100] loss: 0.0066620871709551464
[Epoch 21, Batch 2200] loss: 0.008697834972555541
[Epoch 21, Batch 2300] loss: 0.0021701016357162928
[Epoch 21, Batch 2400] loss: 0.004115642881413067
[Epoch 21, Batch 2500] loss: 0.003978217375590703
[Epoch 21, Batch 2600] loss: 0.0038504751928570614
[Epoch 21, Batch 2700] loss: 0.005769224234703927
[Epoch 21, Batch 2800] loss: 0.0018936646684454671
[Epoch 21, Batch 2900] loss: 0.007075569355677373
[Epoch 21, Batch 3000] loss: 0.006702823850544349
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0412
Validation Accuracy: 0.9894
Overfitting: 0.0412
[Epoch 22, Batch 100] loss: 0.0009537877212630974
[Epoch 22, Batch 200] loss: 0.0007775961672092535
[Epoch 22, Batch 300] loss: 0.0034396305541755366
[Epoch 22, Batch 400] loss: 0.006989244961224443
[Epoch 22, Batch 500] loss: 0.00555480170971407
[Epoch 22, Batch 600] loss: 0.002150002189525253
[Epoch 22, Batch 700] loss: 0.0017499561691544229
[Epoch 22, Batch 800] loss: 0.0016144005619399947
[Epoch 22, Batch 900] loss: 0.004910621377618405
[Epoch 22, Batch 1000] loss: 0.0035769093967593334
[Epoch 22, Batch 1100] loss: 0.005939029938513158
[Epoch 22, Batch 1200] loss: 0.004215392568960396
[Epoch 22, Batch 1300] loss: 0.0021249291312693684
[Epoch 22, Batch 1400] loss: 0.0013541815149568492
[Epoch 22, Batch 1500] loss: 0.0015715196966337385
[Epoch 22, Batch 1600] loss: 0.005050306829556455
[Epoch 22, Batch 1700] loss: 0.0038745680783188164
[Epoch 22, Batch 1800] loss: 0.0026617929136742192
[Epoch 22, Batch 1900] loss: 0.0009780365926897617
[Epoch 22, Batch 2000] loss: 0.00338289141214446
[Epoch 22, Batch 2100] loss: 0.004899048341137515
[Epoch 22, Batch 2200] loss: 0.0035047215196289017
[Epoch 22, Batch 2300] loss: 0.007423469950882265
[Epoch 22, Batch 2400] loss: 0.002375585135308711
[Epoch 22, Batch 2500] loss: 0.0019657272148936047
[Epoch 22, Batch 2600] loss: 0.0021189515241660218
[Epoch 22, Batch 2700] loss: 0.002214552559377978
[Epoch 22, Batch 2800] loss: 0.007084360335638564
[Epoch 22, Batch 2900] loss: 0.007818125542375891
[Epoch 22, Batch 3000] loss: 0.002910739199276264
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0423
Validation Accuracy: 0.9896
Overfitting: 0.0423
[Epoch 23, Batch 100] loss: 0.0017571936234233477
[Epoch 23, Batch 200] loss: 0.0037956896050310718
[Epoch 23, Batch 300] loss: 0.0036204769509953394
[Epoch 23, Batch 400] loss: 0.0021582957846123206
[Epoch 23, Batch 500] loss: 0.005731891359417532
[Epoch 23, Batch 600] loss: 0.002098948524236057
[Epoch 23, Batch 700] loss: 0.0018277272606349016
[Epoch 23, Batch 800] loss: 0.004435338138855229
[Epoch 23, Batch 900] loss: 0.0014406703888090533
[Epoch 23, Batch 1000] loss: 0.0017119379198416596
[Epoch 23, Batch 1100] loss: 0.0025621723629855354
[Epoch 23, Batch 1200] loss: 0.003586471455423208
[Epoch 23, Batch 1300] loss: 0.005103140018359511
[Epoch 23, Batch 1400] loss: 0.001193243300190261
[Epoch 23, Batch 1500] loss: 0.006049191984712721
[Epoch 23, Batch 1600] loss: 0.004462338336826903
[Epoch 23, Batch 1700] loss: 0.005080125359814076
[Epoch 23, Batch 1800] loss: 0.004809276978120777
[Epoch 23, Batch 1900] loss: 0.0035685532533266695
[Epoch 23, Batch 2000] loss: 0.004448875756907711
[Epoch 23, Batch 2100] loss: 0.003162708983212781
[Epoch 23, Batch 2200] loss: 0.0023034335757461124
[Epoch 23, Batch 2300] loss: 0.001334949230906375
[Epoch 23, Batch 2400] loss: 0.003096903628271548
[Epoch 23, Batch 2500] loss: 0.013188337743787314
[Epoch 23, Batch 2600] loss: 0.008152867953315308
[Epoch 23, Batch 2700] loss: 0.003279325505284296
[Epoch 23, Batch 2800] loss: 0.008122155086838915
[Epoch 23, Batch 2900] loss: 0.0017729887577615955
[Epoch 23, Batch 3000] loss: 0.004352760131007471
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9885
Overfitting: 0.0511
[Epoch 24, Batch 100] loss: 0.006078453451503094
[Epoch 24, Batch 200] loss: 0.00120344590226523
[Epoch 24, Batch 300] loss: 0.0011850120281843423
[Epoch 24, Batch 400] loss: 0.005572665754296793
[Epoch 24, Batch 500] loss: 0.005710569439349911
[Epoch 24, Batch 600] loss: 0.0031955507911004587
[Epoch 24, Batch 700] loss: 0.0016732397079408656
[Epoch 24, Batch 800] loss: 0.0017963588156132458
[Epoch 24, Batch 900] loss: 0.0012630542623899288
[Epoch 24, Batch 1000] loss: 0.0028807357084141925
[Epoch 24, Batch 1100] loss: 0.0020534323325478
[Epoch 24, Batch 1200] loss: 0.0031717313311324345
[Epoch 24, Batch 1300] loss: 0.0018361966587566415
[Epoch 24, Batch 1400] loss: 0.002092018199489445
[Epoch 24, Batch 1500] loss: 0.0015211976860571496
[Epoch 24, Batch 1600] loss: 0.0031488323383750583
[Epoch 24, Batch 1700] loss: 0.002902981187085416
[Epoch 24, Batch 1800] loss: 0.0025717728764857385
[Epoch 24, Batch 1900] loss: 0.010438440513264525
[Epoch 24, Batch 2000] loss: 0.004954319543673904
[Epoch 24, Batch 2100] loss: 0.006530230157557639
[Epoch 24, Batch 2200] loss: 0.002004088993367574
[Epoch 24, Batch 2300] loss: 0.0012411405423220856
[Epoch 24, Batch 2400] loss: 0.0009192760373562691
[Epoch 24, Batch 2500] loss: 0.002779896147336558
[Epoch 24, Batch 2600] loss: 0.001323625151389507
[Epoch 24, Batch 2700] loss: 0.0015345856448035987
[Epoch 24, Batch 2800] loss: 0.0014643597551182808
[Epoch 24, Batch 2900] loss: 0.000675674721901629
[Epoch 24, Batch 3000] loss: 0.0014992251605150386
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9901
Overfitting: 0.0456
Fold 5 validation loss: 0.0456
Mean validation loss across all folds for Trial 9 is 0.0583 with trial config:  l1: 256, l2: 64, lr: 0.0011075021673381486, batch_size: 16
[I 2024-12-11 04:06:25,709] Trial 8 finished with value: 0.058306684031112554 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0011075021673381486, 'batch_size': 16}. Best is trial 4 with value: 0.046929042829858846.

Selected Hyperparameters for Trial 10:
  l1: 256, l2: 64, lr: 0.009053062590497972, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.6476734399795532
[Epoch 1, Batch 200] loss: 0.3592334994673729
[Epoch 1, Batch 300] loss: 0.1882192649319768
**STATS for Epoch 1** : 
Average training loss: 0.0324
Average validation loss: 0.1233
Validation Accuracy: 0.9619
Overfitting: 0.0909
Best model saved at epoch 1 with validation loss: 0.1233
[Epoch 2, Batch 100] loss: 0.12900658909231424
[Epoch 2, Batch 200] loss: 0.10471593411639332
[Epoch 2, Batch 300] loss: 0.09243533307686448
**STATS for Epoch 2** : 
Average training loss: 0.0152
Average validation loss: 0.0688
Validation Accuracy: 0.9766
Overfitting: 0.0536
Best model saved at epoch 2 with validation loss: 0.0688
[Epoch 3, Batch 100] loss: 0.07639358443208039
[Epoch 3, Batch 200] loss: 0.07232751061208546
[Epoch 3, Batch 300] loss: 0.058009445881471035
**STATS for Epoch 3** : 
Average training loss: 0.0123
Average validation loss: 0.0550
Validation Accuracy: 0.9822
Overfitting: 0.0427
Best model saved at epoch 3 with validation loss: 0.0550
[Epoch 4, Batch 100] loss: 0.05080711041111499
[Epoch 4, Batch 200] loss: 0.04564741687383503
[Epoch 4, Batch 300] loss: 0.05432330700103193
**STATS for Epoch 4** : 
Average training loss: 0.0102
Average validation loss: 0.0564
Validation Accuracy: 0.9823
Overfitting: 0.0462
[Epoch 5, Batch 100] loss: 0.040177695851307364
[Epoch 5, Batch 200] loss: 0.04307132353074849
[Epoch 5, Batch 300] loss: 0.04423827194608748
**STATS for Epoch 5** : 
Average training loss: 0.0076
Average validation loss: 0.0558
Validation Accuracy: 0.9814
Overfitting: 0.0482
[Epoch 6, Batch 100] loss: 0.03375955958617851
[Epoch 6, Batch 200] loss: 0.03718400392215699
[Epoch 6, Batch 300] loss: 0.032781116138212385
**STATS for Epoch 6** : 
Average training loss: 0.0068
Average validation loss: 0.0481
Validation Accuracy: 0.9848
Overfitting: 0.0412
Best model saved at epoch 6 with validation loss: 0.0481
[Epoch 7, Batch 100] loss: 0.027290621851570905
[Epoch 7, Batch 200] loss: 0.027655620162840934
[Epoch 7, Batch 300] loss: 0.024910784332896584
**STATS for Epoch 7** : 
Average training loss: 0.0051
Average validation loss: 0.0505
Validation Accuracy: 0.9854
Overfitting: 0.0455
[Epoch 8, Batch 100] loss: 0.020211498744320124
[Epoch 8, Batch 200] loss: 0.028224256554385648
[Epoch 8, Batch 300] loss: 0.026797660269076005
**STATS for Epoch 8** : 
Average training loss: 0.0048
Average validation loss: 0.0463
Validation Accuracy: 0.9853
Overfitting: 0.0415
Best model saved at epoch 8 with validation loss: 0.0463
[Epoch 9, Batch 100] loss: 0.018903555496945047
[Epoch 9, Batch 200] loss: 0.020519719222793355
[Epoch 9, Batch 300] loss: 0.016171720204874875
**STATS for Epoch 9** : 
Average training loss: 0.0041
Average validation loss: 0.0510
Validation Accuracy: 0.9860
Overfitting: 0.0469
[Epoch 10, Batch 100] loss: 0.01736997568688821
[Epoch 10, Batch 200] loss: 0.019077091485960408
[Epoch 10, Batch 300] loss: 0.017218707400606947
**STATS for Epoch 10** : 
Average training loss: 0.0042
Average validation loss: 0.0433
Validation Accuracy: 0.9866
Overfitting: 0.0392
Best model saved at epoch 10 with validation loss: 0.0433
[Epoch 11, Batch 100] loss: 0.01564844022039324
[Epoch 11, Batch 200] loss: 0.01634525802335702
[Epoch 11, Batch 300] loss: 0.015514022776042111
**STATS for Epoch 11** : 
Average training loss: 0.0025
Average validation loss: 0.0431
Validation Accuracy: 0.9876
Overfitting: 0.0405
Best model saved at epoch 11 with validation loss: 0.0431
[Epoch 12, Batch 100] loss: 0.01115167686220957
[Epoch 12, Batch 200] loss: 0.012082413074094802
[Epoch 12, Batch 300] loss: 0.011823787991306744
**STATS for Epoch 12** : 
Average training loss: 0.0024
Average validation loss: 0.0482
Validation Accuracy: 0.9873
Overfitting: 0.0458
[Epoch 13, Batch 100] loss: 0.010731458817026578
[Epoch 13, Batch 200] loss: 0.01092437192404759
[Epoch 13, Batch 300] loss: 0.012445167143596336
**STATS for Epoch 13** : 
Average training loss: 0.0022
Average validation loss: 0.0434
Validation Accuracy: 0.9875
Overfitting: 0.0411
[Epoch 14, Batch 100] loss: 0.0075170469467411745
[Epoch 14, Batch 200] loss: 0.008325314373068977
[Epoch 14, Batch 300] loss: 0.014394502956129145
**STATS for Epoch 14** : 
Average training loss: 0.0024
Average validation loss: 0.0470
Validation Accuracy: 0.9873
Overfitting: 0.0447
[Epoch 15, Batch 100] loss: 0.007209594543382991
[Epoch 15, Batch 200] loss: 0.007723325619299431
[Epoch 15, Batch 300] loss: 0.007605681542772799
**STATS for Epoch 15** : 
Average training loss: 0.0012
Average validation loss: 0.0437
Validation Accuracy: 0.9888
Overfitting: 0.0425
[Epoch 16, Batch 100] loss: 0.007728848237748025
[Epoch 16, Batch 200] loss: 0.004625445456331363
[Epoch 16, Batch 300] loss: 0.007702289545777603
**STATS for Epoch 16** : 
Average training loss: 0.0015
Average validation loss: 0.0471
Validation Accuracy: 0.9880
Overfitting: 0.0456
[Epoch 17, Batch 100] loss: 0.0047205960618157405
[Epoch 17, Batch 200] loss: 0.0037576485142926685
[Epoch 17, Batch 300] loss: 0.004168823945292388
**STATS for Epoch 17** : 
Average training loss: 0.0015
Average validation loss: 0.0474
Validation Accuracy: 0.9882
Overfitting: 0.0459
[Epoch 18, Batch 100] loss: 0.0051943449756072365
[Epoch 18, Batch 200] loss: 0.004187261673650937
[Epoch 18, Batch 300] loss: 0.004325129735661903
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0506
Validation Accuracy: 0.9878
Overfitting: 0.0497
[Epoch 19, Batch 100] loss: 0.004375004848916433
[Epoch 19, Batch 200] loss: 0.0035277696545381334
[Epoch 19, Batch 300] loss: 0.003297859695230727
**STATS for Epoch 19** : 
Average training loss: 0.0009
Average validation loss: 0.0479
Validation Accuracy: 0.9880
Overfitting: 0.0470
[Epoch 20, Batch 100] loss: 0.002213790422210877
[Epoch 20, Batch 200] loss: 0.004053981789729733
[Epoch 20, Batch 300] loss: 0.0031960921031713952
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0536
Validation Accuracy: 0.9873
Overfitting: 0.0526
[Epoch 21, Batch 100] loss: 0.0025598970929422648
[Epoch 21, Batch 200] loss: 0.0062391029919672296
[Epoch 21, Batch 300] loss: 0.003865136050953879
**STATS for Epoch 21** : 
Average training loss: 0.0012
Average validation loss: 0.0480
Validation Accuracy: 0.9892
Overfitting: 0.0469
[Epoch 22, Batch 100] loss: 0.0031062648933948365
[Epoch 22, Batch 200] loss: 0.0028397379634043317
[Epoch 22, Batch 300] loss: 0.004799624872102868
**STATS for Epoch 22** : 
Average training loss: 0.0007
Average validation loss: 0.0506
Validation Accuracy: 0.9882
Overfitting: 0.0499
[Epoch 23, Batch 100] loss: 0.0015619302161212546
[Epoch 23, Batch 200] loss: 0.0026662672188467696
[Epoch 23, Batch 300] loss: 0.0023824746114951265
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0535
Validation Accuracy: 0.9877
Overfitting: 0.0529
[Epoch 24, Batch 100] loss: 0.0018806265023886227
[Epoch 24, Batch 200] loss: 0.0009220375569566386
[Epoch 24, Batch 300] loss: 0.0008754388108991407
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0531
Validation Accuracy: 0.9882
Overfitting: 0.0528
Fold 1 validation loss: 0.0531
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.6063373041152955
[Epoch 1, Batch 200] loss: 0.32488598227500914
[Epoch 1, Batch 300] loss: 0.18383208513259888
**STATS for Epoch 1** : 
Average training loss: 0.0256
Average validation loss: 0.1330
Validation Accuracy: 0.9573
Overfitting: 0.1074
Best model saved at epoch 1 with validation loss: 0.1330
[Epoch 2, Batch 100] loss: 0.10887183219194413
[Epoch 2, Batch 200] loss: 0.09308977380394935
[Epoch 2, Batch 300] loss: 0.08386702270247043
**STATS for Epoch 2** : 
Average training loss: 0.0151
Average validation loss: 0.0836
Validation Accuracy: 0.9732
Overfitting: 0.0686
Best model saved at epoch 2 with validation loss: 0.0836
[Epoch 3, Batch 100] loss: 0.06184564831666648
[Epoch 3, Batch 200] loss: 0.0573824592679739
[Epoch 3, Batch 300] loss: 0.0664958974532783
**STATS for Epoch 3** : 
Average training loss: 0.0106
Average validation loss: 0.0739
Validation Accuracy: 0.9782
Overfitting: 0.0633
Best model saved at epoch 3 with validation loss: 0.0739
[Epoch 4, Batch 100] loss: 0.044995712116360664
[Epoch 4, Batch 200] loss: 0.048125147074460986
[Epoch 4, Batch 300] loss: 0.049734290386550126
**STATS for Epoch 4** : 
Average training loss: 0.0093
Average validation loss: 0.0638
Validation Accuracy: 0.9798
Overfitting: 0.0545
Best model saved at epoch 4 with validation loss: 0.0638
[Epoch 5, Batch 100] loss: 0.03901821594685316
[Epoch 5, Batch 200] loss: 0.033904058798216286
[Epoch 5, Batch 300] loss: 0.03688497138442472
**STATS for Epoch 5** : 
Average training loss: 0.0083
Average validation loss: 0.0591
Validation Accuracy: 0.9822
Overfitting: 0.0509
Best model saved at epoch 5 with validation loss: 0.0591
[Epoch 6, Batch 100] loss: 0.030087949861772358
[Epoch 6, Batch 200] loss: 0.02685795793775469
[Epoch 6, Batch 300] loss: 0.034713512456510213
**STATS for Epoch 6** : 
Average training loss: 0.0073
Average validation loss: 0.0574
Validation Accuracy: 0.9825
Overfitting: 0.0501
Best model saved at epoch 6 with validation loss: 0.0574
[Epoch 7, Batch 100] loss: 0.023354276036843657
[Epoch 7, Batch 200] loss: 0.02177523012680467
[Epoch 7, Batch 300] loss: 0.02994555501965806
**STATS for Epoch 7** : 
Average training loss: 0.0059
Average validation loss: 0.0502
Validation Accuracy: 0.9848
Overfitting: 0.0443
Best model saved at epoch 7 with validation loss: 0.0502
[Epoch 8, Batch 100] loss: 0.024844136873725803
[Epoch 8, Batch 200] loss: 0.020230472127441317
[Epoch 8, Batch 300] loss: 0.02133039749925956
**STATS for Epoch 8** : 
Average training loss: 0.0043
Average validation loss: 0.0569
Validation Accuracy: 0.9828
Overfitting: 0.0526
[Epoch 9, Batch 100] loss: 0.018013621732825412
[Epoch 9, Batch 200] loss: 0.02280682130716741
[Epoch 9, Batch 300] loss: 0.017783427733229475
**STATS for Epoch 9** : 
Average training loss: 0.0052
Average validation loss: 0.0556
Validation Accuracy: 0.9848
Overfitting: 0.0504
[Epoch 10, Batch 100] loss: 0.016316452043829487
[Epoch 10, Batch 200] loss: 0.011776377728092485
[Epoch 10, Batch 300] loss: 0.019951040823361837
**STATS for Epoch 10** : 
Average training loss: 0.0048
Average validation loss: 0.0658
Validation Accuracy: 0.9822
Overfitting: 0.0611
[Epoch 11, Batch 100] loss: 0.017396881103049964
[Epoch 11, Batch 200] loss: 0.011820179973728955
[Epoch 11, Batch 300] loss: 0.014589564560446888
**STATS for Epoch 11** : 
Average training loss: 0.0032
Average validation loss: 0.0566
Validation Accuracy: 0.9848
Overfitting: 0.0533
[Epoch 12, Batch 100] loss: 0.01092173524244572
[Epoch 12, Batch 200] loss: 0.012038994577014819
[Epoch 12, Batch 300] loss: 0.011487840190529824
**STATS for Epoch 12** : 
Average training loss: 0.0024
Average validation loss: 0.0515
Validation Accuracy: 0.9860
Overfitting: 0.0491
[Epoch 13, Batch 100] loss: 0.011265012879739515
[Epoch 13, Batch 200] loss: 0.010354961884149815
[Epoch 13, Batch 300] loss: 0.010149794338794892
**STATS for Epoch 13** : 
Average training loss: 0.0018
Average validation loss: 0.0588
Validation Accuracy: 0.9847
Overfitting: 0.0570
[Epoch 14, Batch 100] loss: 0.007182867108349455
[Epoch 14, Batch 200] loss: 0.007725307586952113
[Epoch 14, Batch 300] loss: 0.00890059203869896
**STATS for Epoch 14** : 
Average training loss: 0.0016
Average validation loss: 0.0531
Validation Accuracy: 0.9863
Overfitting: 0.0515
[Epoch 15, Batch 100] loss: 0.007307120035693515
[Epoch 15, Batch 200] loss: 0.00763252665521577
[Epoch 15, Batch 300] loss: 0.009122522708494216
**STATS for Epoch 15** : 
Average training loss: 0.0029
Average validation loss: 0.0545
Validation Accuracy: 0.9858
Overfitting: 0.0516
[Epoch 16, Batch 100] loss: 0.0063099974978831595
[Epoch 16, Batch 200] loss: 0.005461552261804173
[Epoch 16, Batch 300] loss: 0.0062955058956868015
**STATS for Epoch 16** : 
Average training loss: 0.0025
Average validation loss: 0.0556
Validation Accuracy: 0.9861
Overfitting: 0.0532
[Epoch 17, Batch 100] loss: 0.0049754620956082365
[Epoch 17, Batch 200] loss: 0.00487291837882367
[Epoch 17, Batch 300] loss: 0.005785002915363293
**STATS for Epoch 17** : 
Average training loss: 0.0017
Average validation loss: 0.0548
Validation Accuracy: 0.9868
Overfitting: 0.0531
[Epoch 18, Batch 100] loss: 0.00470789109589532
[Epoch 18, Batch 200] loss: 0.005234124877824797
[Epoch 18, Batch 300] loss: 0.004917065088884556
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0553
Validation Accuracy: 0.9862
Overfitting: 0.0546
[Epoch 19, Batch 100] loss: 0.004034092564143066
[Epoch 19, Batch 200] loss: 0.0034184391145390693
[Epoch 19, Batch 300] loss: 0.004739451872592326
**STATS for Epoch 19** : 
Average training loss: 0.0013
Average validation loss: 0.0627
Validation Accuracy: 0.9850
Overfitting: 0.0614
[Epoch 20, Batch 100] loss: 0.006057360235063243
[Epoch 20, Batch 200] loss: 0.00315850118342496
[Epoch 20, Batch 300] loss: 0.002076889923555427
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0592
Validation Accuracy: 0.9866
Overfitting: 0.0587
[Epoch 21, Batch 100] loss: 0.0024578336581907935
[Epoch 21, Batch 200] loss: 0.001842004878217267
[Epoch 21, Batch 300] loss: 0.0025334006251068785
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0592
Validation Accuracy: 0.9870
Overfitting: 0.0588
[Epoch 22, Batch 100] loss: 0.0014625503453680722
[Epoch 22, Batch 200] loss: 0.004465010404474014
[Epoch 22, Batch 300] loss: 0.0027851106844173044
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0587
Validation Accuracy: 0.9872
Overfitting: 0.0582
[Epoch 23, Batch 100] loss: 0.0015351895814819728
[Epoch 23, Batch 200] loss: 0.0023648441546902177
[Epoch 23, Batch 300] loss: 0.0013215081419548369
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0616
Validation Accuracy: 0.9864
Overfitting: 0.0613
[Epoch 24, Batch 100] loss: 0.0020145450116251596
[Epoch 24, Batch 200] loss: 0.0009517166646401165
[Epoch 24, Batch 300] loss: 0.0011947891585441539
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0596
Validation Accuracy: 0.9874
Overfitting: 0.0594
Fold 2 validation loss: 0.0596
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 1.5864064332842827
[Epoch 1, Batch 200] loss: 0.29210392870008944
[Epoch 1, Batch 300] loss: 0.1725517049431801
**STATS for Epoch 1** : 
Average training loss: 0.0266
Average validation loss: 0.1098
Validation Accuracy: 0.9669
Overfitting: 0.0832
Best model saved at epoch 1 with validation loss: 0.1098
[Epoch 2, Batch 100] loss: 0.11018485773354769
[Epoch 2, Batch 200] loss: 0.09861197313293815
[Epoch 2, Batch 300] loss: 0.08330723560415208
**STATS for Epoch 2** : 
Average training loss: 0.0159
Average validation loss: 0.0890
Validation Accuracy: 0.9730
Overfitting: 0.0730
Best model saved at epoch 2 with validation loss: 0.0890
[Epoch 3, Batch 100] loss: 0.06977862977422773
[Epoch 3, Batch 200] loss: 0.06493529357016087
[Epoch 3, Batch 300] loss: 0.06303194780135528
**STATS for Epoch 3** : 
Average training loss: 0.0120
Average validation loss: 0.0688
Validation Accuracy: 0.9798
Overfitting: 0.0568
Best model saved at epoch 3 with validation loss: 0.0688
[Epoch 4, Batch 100] loss: 0.0514390917122364
[Epoch 4, Batch 200] loss: 0.04585732208099216
[Epoch 4, Batch 300] loss: 0.0504986700695008
**STATS for Epoch 4** : 
Average training loss: 0.0101
Average validation loss: 0.0535
Validation Accuracy: 0.9838
Overfitting: 0.0434
Best model saved at epoch 4 with validation loss: 0.0535
[Epoch 5, Batch 100] loss: 0.0379266080679372
[Epoch 5, Batch 200] loss: 0.03771903042215854
[Epoch 5, Batch 300] loss: 0.04074315925128758
**STATS for Epoch 5** : 
Average training loss: 0.0092
Average validation loss: 0.0467
Validation Accuracy: 0.9862
Overfitting: 0.0375
Best model saved at epoch 5 with validation loss: 0.0467
[Epoch 6, Batch 100] loss: 0.03443164183758199
[Epoch 6, Batch 200] loss: 0.03672922088531777
[Epoch 6, Batch 300] loss: 0.029785883023869246
**STATS for Epoch 6** : 
Average training loss: 0.0081
Average validation loss: 0.0488
Validation Accuracy: 0.9853
Overfitting: 0.0407
[Epoch 7, Batch 100] loss: 0.03313619927503168
[Epoch 7, Batch 200] loss: 0.030030150152742862
[Epoch 7, Batch 300] loss: 0.027474013343453407
**STATS for Epoch 7** : 
Average training loss: 0.0058
Average validation loss: 0.0457
Validation Accuracy: 0.9859
Overfitting: 0.0399
Best model saved at epoch 7 with validation loss: 0.0457
[Epoch 8, Batch 100] loss: 0.024987569866934792
[Epoch 8, Batch 200] loss: 0.023967311347369104
[Epoch 8, Batch 300] loss: 0.026085516416933387
**STATS for Epoch 8** : 
Average training loss: 0.0047
Average validation loss: 0.0448
Validation Accuracy: 0.9869
Overfitting: 0.0401
Best model saved at epoch 8 with validation loss: 0.0448
[Epoch 9, Batch 100] loss: 0.01805846588918939
[Epoch 9, Batch 200] loss: 0.019112077264580876
[Epoch 9, Batch 300] loss: 0.024596280687255785
**STATS for Epoch 9** : 
Average training loss: 0.0050
Average validation loss: 0.0507
Validation Accuracy: 0.9854
Overfitting: 0.0458
[Epoch 10, Batch 100] loss: 0.01873592552379705
[Epoch 10, Batch 200] loss: 0.01496112985536456
[Epoch 10, Batch 300] loss: 0.01877283370529767
**STATS for Epoch 10** : 
Average training loss: 0.0043
Average validation loss: 0.0427
Validation Accuracy: 0.9877
Overfitting: 0.0384
Best model saved at epoch 10 with validation loss: 0.0427
[Epoch 11, Batch 100] loss: 0.01686264973017387
[Epoch 11, Batch 200] loss: 0.015792569607729092
[Epoch 11, Batch 300] loss: 0.014619302161736413
**STATS for Epoch 11** : 
Average training loss: 0.0036
Average validation loss: 0.0415
Validation Accuracy: 0.9878
Overfitting: 0.0378
Best model saved at epoch 11 with validation loss: 0.0415
[Epoch 12, Batch 100] loss: 0.012808255277923309
[Epoch 12, Batch 200] loss: 0.010338947768323123
[Epoch 12, Batch 300] loss: 0.012541552699985914
**STATS for Epoch 12** : 
Average training loss: 0.0032
Average validation loss: 0.0535
Validation Accuracy: 0.9838
Overfitting: 0.0503
[Epoch 13, Batch 100] loss: 0.01029472321155481
[Epoch 13, Batch 200] loss: 0.013674908101093024
[Epoch 13, Batch 300] loss: 0.012862009963137098
**STATS for Epoch 13** : 
Average training loss: 0.0020
Average validation loss: 0.0477
Validation Accuracy: 0.9877
Overfitting: 0.0457
[Epoch 14, Batch 100] loss: 0.009205158280092291
[Epoch 14, Batch 200] loss: 0.00757047124177916
[Epoch 14, Batch 300] loss: 0.009831074176181573
**STATS for Epoch 14** : 
Average training loss: 0.0022
Average validation loss: 0.0435
Validation Accuracy: 0.9888
Overfitting: 0.0413
[Epoch 15, Batch 100] loss: 0.00830235936504323
[Epoch 15, Batch 200] loss: 0.010931746377900708
[Epoch 15, Batch 300] loss: 0.008330133766430664
**STATS for Epoch 15** : 
Average training loss: 0.0019
Average validation loss: 0.0497
Validation Accuracy: 0.9880
Overfitting: 0.0478
[Epoch 16, Batch 100] loss: 0.008695527147865504
[Epoch 16, Batch 200] loss: 0.008516190759692108
[Epoch 16, Batch 300] loss: 0.007136954282177612
**STATS for Epoch 16** : 
Average training loss: 0.0018
Average validation loss: 0.0489
Validation Accuracy: 0.9872
Overfitting: 0.0470
[Epoch 17, Batch 100] loss: 0.0057894121966091915
[Epoch 17, Batch 200] loss: 0.007136633330374025
[Epoch 17, Batch 300] loss: 0.005381621940905461
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0563
Validation Accuracy: 0.9868
Overfitting: 0.0552
[Epoch 18, Batch 100] loss: 0.004804804480954772
[Epoch 18, Batch 200] loss: 0.004411103205493419
[Epoch 18, Batch 300] loss: 0.005000893657488632
**STATS for Epoch 18** : 
Average training loss: 0.0017
Average validation loss: 0.0505
Validation Accuracy: 0.9882
Overfitting: 0.0489
[Epoch 19, Batch 100] loss: 0.003435809418806457
[Epoch 19, Batch 200] loss: 0.0044569231157584
[Epoch 19, Batch 300] loss: 0.004320810099925438
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0489
Validation Accuracy: 0.9883
Overfitting: 0.0482
[Epoch 20, Batch 100] loss: 0.0029873330079135483
[Epoch 20, Batch 200] loss: 0.0027657745926626376
[Epoch 20, Batch 300] loss: 0.004531585850127157
**STATS for Epoch 20** : 
Average training loss: 0.0018
Average validation loss: 0.0523
Validation Accuracy: 0.9878
Overfitting: 0.0506
[Epoch 21, Batch 100] loss: 0.006794901565808686
[Epoch 21, Batch 200] loss: 0.0056761678752081934
[Epoch 21, Batch 300] loss: 0.003466391900983581
**STATS for Epoch 21** : 
Average training loss: 0.0008
Average validation loss: 0.0501
Validation Accuracy: 0.9876
Overfitting: 0.0493
[Epoch 22, Batch 100] loss: 0.0030599979488761166
[Epoch 22, Batch 200] loss: 0.002213772917784809
[Epoch 22, Batch 300] loss: 0.0039186633200733925
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0549
Validation Accuracy: 0.9881
Overfitting: 0.0542
[Epoch 23, Batch 100] loss: 0.003429795258452941
[Epoch 23, Batch 200] loss: 0.0027071705428534185
[Epoch 23, Batch 300] loss: 0.002394902699852537
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0482
Validation Accuracy: 0.9891
Overfitting: 0.0478
[Epoch 24, Batch 100] loss: 0.0019196041132454411
[Epoch 24, Batch 200] loss: 0.001882306993165912
[Epoch 24, Batch 300] loss: 0.0011108455952671648
**STATS for Epoch 24** : 
Average training loss: 0.0011
Average validation loss: 0.0688
Validation Accuracy: 0.9857
Overfitting: 0.0677
Fold 3 validation loss: 0.0688
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.531083952486515
[Epoch 1, Batch 200] loss: 0.33571344062685965
[Epoch 1, Batch 300] loss: 0.17668077908456326
**STATS for Epoch 1** : 
Average training loss: 0.0313
Average validation loss: 0.1307
Validation Accuracy: 0.9587
Overfitting: 0.0993
Best model saved at epoch 1 with validation loss: 0.1307
[Epoch 2, Batch 100] loss: 0.12631990522146225
[Epoch 2, Batch 200] loss: 0.11725803706794977
[Epoch 2, Batch 300] loss: 0.09546738311648369
**STATS for Epoch 2** : 
Average training loss: 0.0164
Average validation loss: 0.0806
Validation Accuracy: 0.9769
Overfitting: 0.0642
Best model saved at epoch 2 with validation loss: 0.0806
[Epoch 3, Batch 100] loss: 0.07180864576250315
[Epoch 3, Batch 200] loss: 0.0705362293496728
[Epoch 3, Batch 300] loss: 0.07251795636489987
**STATS for Epoch 3** : 
Average training loss: 0.0137
Average validation loss: 0.0640
Validation Accuracy: 0.9802
Overfitting: 0.0503
Best model saved at epoch 3 with validation loss: 0.0640
[Epoch 4, Batch 100] loss: 0.05511935732327402
[Epoch 4, Batch 200] loss: 0.05802266293205321
[Epoch 4, Batch 300] loss: 0.054379105139523744
**STATS for Epoch 4** : 
Average training loss: 0.0096
Average validation loss: 0.0574
Validation Accuracy: 0.9820
Overfitting: 0.0478
Best model saved at epoch 4 with validation loss: 0.0574
[Epoch 5, Batch 100] loss: 0.04824162866920233
[Epoch 5, Batch 200] loss: 0.04211378252599388
[Epoch 5, Batch 300] loss: 0.04670064548496157
**STATS for Epoch 5** : 
Average training loss: 0.0076
Average validation loss: 0.0557
Validation Accuracy: 0.9819
Overfitting: 0.0481
Best model saved at epoch 5 with validation loss: 0.0557
[Epoch 6, Batch 100] loss: 0.03780002926010639
[Epoch 6, Batch 200] loss: 0.038297081158962104
[Epoch 6, Batch 300] loss: 0.03751134347054176
**STATS for Epoch 6** : 
Average training loss: 0.0073
Average validation loss: 0.0496
Validation Accuracy: 0.9842
Overfitting: 0.0424
Best model saved at epoch 6 with validation loss: 0.0496
[Epoch 7, Batch 100] loss: 0.03386023127939552
[Epoch 7, Batch 200] loss: 0.03062646131031215
[Epoch 7, Batch 300] loss: 0.03676366792991757
**STATS for Epoch 7** : 
Average training loss: 0.0065
Average validation loss: 0.0574
Validation Accuracy: 0.9824
Overfitting: 0.0509
[Epoch 8, Batch 100] loss: 0.029465253333328292
[Epoch 8, Batch 200] loss: 0.026107767571229488
[Epoch 8, Batch 300] loss: 0.02517045629909262
**STATS for Epoch 8** : 
Average training loss: 0.0049
Average validation loss: 0.0452
Validation Accuracy: 0.9852
Overfitting: 0.0403
Best model saved at epoch 8 with validation loss: 0.0452
[Epoch 9, Batch 100] loss: 0.027743847011588513
[Epoch 9, Batch 200] loss: 0.022994908460532315
[Epoch 9, Batch 300] loss: 0.022803307499270887
**STATS for Epoch 9** : 
Average training loss: 0.0045
Average validation loss: 0.0441
Validation Accuracy: 0.9870
Overfitting: 0.0396
Best model saved at epoch 9 with validation loss: 0.0441
[Epoch 10, Batch 100] loss: 0.021236560539109633
[Epoch 10, Batch 200] loss: 0.021494499538093806
[Epoch 10, Batch 300] loss: 0.020352994276909158
**STATS for Epoch 10** : 
Average training loss: 0.0032
Average validation loss: 0.0484
Validation Accuracy: 0.9855
Overfitting: 0.0451
[Epoch 11, Batch 100] loss: 0.01820493033505045
[Epoch 11, Batch 200] loss: 0.01785588916565757
[Epoch 11, Batch 300] loss: 0.01644019499362912
**STATS for Epoch 11** : 
Average training loss: 0.0034
Average validation loss: 0.0440
Validation Accuracy: 0.9865
Overfitting: 0.0406
Best model saved at epoch 11 with validation loss: 0.0440
[Epoch 12, Batch 100] loss: 0.012003642754280008
[Epoch 12, Batch 200] loss: 0.013006509471451863
[Epoch 12, Batch 300] loss: 0.013198542278259992
**STATS for Epoch 12** : 
Average training loss: 0.0037
Average validation loss: 0.0461
Validation Accuracy: 0.9864
Overfitting: 0.0424
[Epoch 13, Batch 100] loss: 0.011099935125093907
[Epoch 13, Batch 200] loss: 0.013864447654632385
[Epoch 13, Batch 300] loss: 0.011065262228948996
**STATS for Epoch 13** : 
Average training loss: 0.0027
Average validation loss: 0.0496
Validation Accuracy: 0.9861
Overfitting: 0.0469
[Epoch 14, Batch 100] loss: 0.009885910294833593
[Epoch 14, Batch 200] loss: 0.010820134481764398
[Epoch 14, Batch 300] loss: 0.012618404500244651
**STATS for Epoch 14** : 
Average training loss: 0.0029
Average validation loss: 0.0432
Validation Accuracy: 0.9884
Overfitting: 0.0403
Best model saved at epoch 14 with validation loss: 0.0432
[Epoch 15, Batch 100] loss: 0.007079673574262415
[Epoch 15, Batch 200] loss: 0.009434088753623655
[Epoch 15, Batch 300] loss: 0.012312738331384026
**STATS for Epoch 15** : 
Average training loss: 0.0019
Average validation loss: 0.0442
Validation Accuracy: 0.9881
Overfitting: 0.0423
[Epoch 16, Batch 100] loss: 0.009062042647929047
[Epoch 16, Batch 200] loss: 0.008663894510245882
[Epoch 16, Batch 300] loss: 0.010101373057696037
**STATS for Epoch 16** : 
Average training loss: 0.0020
Average validation loss: 0.0498
Validation Accuracy: 0.9868
Overfitting: 0.0479
[Epoch 17, Batch 100] loss: 0.005777670284878696
[Epoch 17, Batch 200] loss: 0.006157921767589869
[Epoch 17, Batch 300] loss: 0.005732581163028954
**STATS for Epoch 17** : 
Average training loss: 0.0016
Average validation loss: 0.0506
Validation Accuracy: 0.9876
Overfitting: 0.0491
[Epoch 18, Batch 100] loss: 0.004302603459218517
[Epoch 18, Batch 200] loss: 0.006537350760045229
[Epoch 18, Batch 300] loss: 0.005276178169442574
**STATS for Epoch 18** : 
Average training loss: 0.0011
Average validation loss: 0.0537
Validation Accuracy: 0.9875
Overfitting: 0.0525
[Epoch 19, Batch 100] loss: 0.00496395306829072
[Epoch 19, Batch 200] loss: 0.006680918141937582
[Epoch 19, Batch 300] loss: 0.004405694553643116
**STATS for Epoch 19** : 
Average training loss: 0.0016
Average validation loss: 0.0490
Validation Accuracy: 0.9883
Overfitting: 0.0474
[Epoch 20, Batch 100] loss: 0.006132495911151637
[Epoch 20, Batch 200] loss: 0.005194962765599485
[Epoch 20, Batch 300] loss: 0.008580259810987628
**STATS for Epoch 20** : 
Average training loss: 0.0022
Average validation loss: 0.0614
Validation Accuracy: 0.9857
Overfitting: 0.0592
[Epoch 21, Batch 100] loss: 0.006538742366392398
[Epoch 21, Batch 200] loss: 0.006823091543265036
[Epoch 21, Batch 300] loss: 0.008871277645157534
**STATS for Epoch 21** : 
Average training loss: 0.0012
Average validation loss: 0.0669
Validation Accuracy: 0.9852
Overfitting: 0.0658
[Epoch 22, Batch 100] loss: 0.0037802546578677722
[Epoch 22, Batch 200] loss: 0.0025867954719797125
[Epoch 22, Batch 300] loss: 0.004753335780842463
**STATS for Epoch 22** : 
Average training loss: 0.0010
Average validation loss: 0.0478
Validation Accuracy: 0.9884
Overfitting: 0.0469
[Epoch 23, Batch 100] loss: 0.0033462268586663415
[Epoch 23, Batch 200] loss: 0.0029056510817463276
[Epoch 23, Batch 300] loss: 0.0028623628757850385
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0516
Validation Accuracy: 0.9883
Overfitting: 0.0511
[Epoch 24, Batch 100] loss: 0.0019449163469471386
[Epoch 24, Batch 200] loss: 0.008226979810970078
[Epoch 24, Batch 300] loss: 0.004494001623752411
**STATS for Epoch 24** : 
Average training loss: 0.0014
Average validation loss: 0.0627
Validation Accuracy: 0.9859
Overfitting: 0.0614
Fold 4 validation loss: 0.0627
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 1.675384669005871
[Epoch 1, Batch 200] loss: 0.2778653956949711
[Epoch 1, Batch 300] loss: 0.16293166611343624
**STATS for Epoch 1** : 
Average training loss: 0.0305
Average validation loss: 0.1096
Validation Accuracy: 0.9673
Overfitting: 0.0791
Best model saved at epoch 1 with validation loss: 0.1096
[Epoch 2, Batch 100] loss: 0.10520849391818046
[Epoch 2, Batch 200] loss: 0.09576401820406318
[Epoch 2, Batch 300] loss: 0.08652780095115303
**STATS for Epoch 2** : 
Average training loss: 0.0148
Average validation loss: 0.0730
Validation Accuracy: 0.9782
Overfitting: 0.0582
Best model saved at epoch 2 with validation loss: 0.0730
[Epoch 3, Batch 100] loss: 0.06566594520583749
[Epoch 3, Batch 200] loss: 0.06254600343294442
[Epoch 3, Batch 300] loss: 0.0623313810583204
**STATS for Epoch 3** : 
Average training loss: 0.0120
Average validation loss: 0.0523
Validation Accuracy: 0.9842
Overfitting: 0.0403
Best model saved at epoch 3 with validation loss: 0.0523
[Epoch 4, Batch 100] loss: 0.0433396926894784
[Epoch 4, Batch 200] loss: 0.04928484707139433
[Epoch 4, Batch 300] loss: 0.049191645914688706
**STATS for Epoch 4** : 
Average training loss: 0.0097
Average validation loss: 0.0562
Validation Accuracy: 0.9822
Overfitting: 0.0465
[Epoch 5, Batch 100] loss: 0.03697858485393226
[Epoch 5, Batch 200] loss: 0.03972025999100879
[Epoch 5, Batch 300] loss: 0.03813053489662707
**STATS for Epoch 5** : 
Average training loss: 0.0092
Average validation loss: 0.0623
Validation Accuracy: 0.9811
Overfitting: 0.0531
[Epoch 6, Batch 100] loss: 0.03081072238041088
[Epoch 6, Batch 200] loss: 0.03371445204364136
[Epoch 6, Batch 300] loss: 0.03174497278407216
**STATS for Epoch 6** : 
Average training loss: 0.0069
Average validation loss: 0.0434
Validation Accuracy: 0.9864
Overfitting: 0.0365
Best model saved at epoch 6 with validation loss: 0.0434
[Epoch 7, Batch 100] loss: 0.02704086711164564
[Epoch 7, Batch 200] loss: 0.03146803708281368
[Epoch 7, Batch 300] loss: 0.03271027909126133
**STATS for Epoch 7** : 
Average training loss: 0.0059
Average validation loss: 0.0410
Validation Accuracy: 0.9879
Overfitting: 0.0352
Best model saved at epoch 7 with validation loss: 0.0410
[Epoch 8, Batch 100] loss: 0.020878362989751622
[Epoch 8, Batch 200] loss: 0.02071005171397701
[Epoch 8, Batch 300] loss: 0.029349148077890276
**STATS for Epoch 8** : 
Average training loss: 0.0049
Average validation loss: 0.0454
Validation Accuracy: 0.9861
Overfitting: 0.0405
[Epoch 9, Batch 100] loss: 0.020906378915533423
[Epoch 9, Batch 200] loss: 0.020653652193723247
[Epoch 9, Batch 300] loss: 0.021046380134066567
**STATS for Epoch 9** : 
Average training loss: 0.0040
Average validation loss: 0.0567
Validation Accuracy: 0.9842
Overfitting: 0.0528
[Epoch 10, Batch 100] loss: 0.017416977157699874
[Epoch 10, Batch 200] loss: 0.018928273849887774
[Epoch 10, Batch 300] loss: 0.01751436650636606
**STATS for Epoch 10** : 
Average training loss: 0.0042
Average validation loss: 0.0398
Validation Accuracy: 0.9884
Overfitting: 0.0355
Best model saved at epoch 10 with validation loss: 0.0398
[Epoch 11, Batch 100] loss: 0.014266640122514218
[Epoch 11, Batch 200] loss: 0.012354756359709427
[Epoch 11, Batch 300] loss: 0.016597859024768694
**STATS for Epoch 11** : 
Average training loss: 0.0027
Average validation loss: 0.0423
Validation Accuracy: 0.9875
Overfitting: 0.0396
[Epoch 12, Batch 100] loss: 0.010985829459386878
[Epoch 12, Batch 200] loss: 0.0110460908227833
[Epoch 12, Batch 300] loss: 0.012972027737996541
**STATS for Epoch 12** : 
Average training loss: 0.0024
Average validation loss: 0.0388
Validation Accuracy: 0.9885
Overfitting: 0.0364
Best model saved at epoch 12 with validation loss: 0.0388
[Epoch 13, Batch 100] loss: 0.010167678264260759
[Epoch 13, Batch 200] loss: 0.010998734662425704
[Epoch 13, Batch 300] loss: 0.0122909276271821
**STATS for Epoch 13** : 
Average training loss: 0.0026
Average validation loss: 0.0397
Validation Accuracy: 0.9893
Overfitting: 0.0370
[Epoch 14, Batch 100] loss: 0.008971923755016178
[Epoch 14, Batch 200] loss: 0.008197925252898131
[Epoch 14, Batch 300] loss: 0.01033166868815897
**STATS for Epoch 14** : 
Average training loss: 0.0025
Average validation loss: 0.0414
Validation Accuracy: 0.9889
Overfitting: 0.0390
[Epoch 15, Batch 100] loss: 0.007692140437284251
[Epoch 15, Batch 200] loss: 0.008281265136320144
[Epoch 15, Batch 300] loss: 0.01260209757834673
**STATS for Epoch 15** : 
Average training loss: 0.0020
Average validation loss: 0.0450
Validation Accuracy: 0.9882
Overfitting: 0.0430
[Epoch 16, Batch 100] loss: 0.005378662962684757
[Epoch 16, Batch 200] loss: 0.009374957328836898
[Epoch 16, Batch 300] loss: 0.008778841975145042
**STATS for Epoch 16** : 
Average training loss: 0.0015
Average validation loss: 0.0456
Validation Accuracy: 0.9885
Overfitting: 0.0440
[Epoch 17, Batch 100] loss: 0.009009162416332402
[Epoch 17, Batch 200] loss: 0.0068122604524251075
[Epoch 17, Batch 300] loss: 0.007721018935117172
**STATS for Epoch 17** : 
Average training loss: 0.0010
Average validation loss: 0.0440
Validation Accuracy: 0.9897
Overfitting: 0.0430
[Epoch 18, Batch 100] loss: 0.005135271436593029
[Epoch 18, Batch 200] loss: 0.00521313791105058
[Epoch 18, Batch 300] loss: 0.0058267326241912085
**STATS for Epoch 18** : 
Average training loss: 0.0015
Average validation loss: 0.0508
Validation Accuracy: 0.9883
Overfitting: 0.0493
[Epoch 19, Batch 100] loss: 0.005723570912377909
[Epoch 19, Batch 200] loss: 0.0038236380722810282
[Epoch 19, Batch 300] loss: 0.003802551335611497
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0462
Validation Accuracy: 0.9888
Overfitting: 0.0454
[Epoch 20, Batch 100] loss: 0.003955489140644204
[Epoch 20, Batch 200] loss: 0.005184331804484827
[Epoch 20, Batch 300] loss: 0.004593848315416835
**STATS for Epoch 20** : 
Average training loss: 0.0011
Average validation loss: 0.0449
Validation Accuracy: 0.9891
Overfitting: 0.0439
[Epoch 21, Batch 100] loss: 0.0023208737774075418
[Epoch 21, Batch 200] loss: 0.002950385105687019
[Epoch 21, Batch 300] loss: 0.003670151589467423
**STATS for Epoch 21** : 
Average training loss: 0.0008
Average validation loss: 0.0450
Validation Accuracy: 0.9893
Overfitting: 0.0442
[Epoch 22, Batch 100] loss: 0.00396302774483047
[Epoch 22, Batch 200] loss: 0.0036754604597808794
[Epoch 22, Batch 300] loss: 0.003771218018955551
**STATS for Epoch 22** : 
Average training loss: 0.0008
Average validation loss: 0.0525
Validation Accuracy: 0.9884
Overfitting: 0.0516
[Epoch 23, Batch 100] loss: 0.003134623300356907
[Epoch 23, Batch 200] loss: 0.0014772106520103989
[Epoch 23, Batch 300] loss: 0.0018664559162425577
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0470
Validation Accuracy: 0.9900
Overfitting: 0.0465
[Epoch 24, Batch 100] loss: 0.0021129721918259747
[Epoch 24, Batch 200] loss: 0.0022401210140742477
[Epoch 24, Batch 300] loss: 0.0014196867677128467
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0502
Validation Accuracy: 0.9899
Overfitting: 0.0496
Fold 5 validation loss: 0.0502
Mean validation loss across all folds for Trial 10 is 0.0589 with trial config:  l1: 256, l2: 64, lr: 0.009053062590497972, batch_size: 128
[I 2024-12-11 04:24:46,002] Trial 9 finished with value: 0.058863955688344086 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.009053062590497972, 'batch_size': 128}. Best is trial 4 with value: 0.046929042829858846.

Selected Hyperparameters for Trial 11:
  l1: 128, l2: 128, lr: 0.00017288172462230452, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3042712092399595
[Epoch 1, Batch 200] loss: 2.2994083642959593
[Epoch 1, Batch 300] loss: 2.292137441635132
[Epoch 1, Batch 400] loss: 2.288960039615631
[Epoch 1, Batch 500] loss: 2.285703568458557
[Epoch 1, Batch 600] loss: 2.2795362877845764
[Epoch 1, Batch 700] loss: 2.272949903011322
[Epoch 1, Batch 800] loss: 2.2642986392974853
[Epoch 1, Batch 900] loss: 2.252256145477295
[Epoch 1, Batch 1000] loss: 2.2393768930435183
[Epoch 1, Batch 1100] loss: 2.223139922618866
[Epoch 1, Batch 1200] loss: 2.1978898000717164
[Epoch 1, Batch 1300] loss: 2.1628842735290528
[Epoch 1, Batch 1400] loss: 2.114526891708374
[Epoch 1, Batch 1500] loss: 2.0366810190677644
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 1.9766
Validation Accuracy: 0.5334
Overfitting: 1.9766
Best model saved at epoch 1 with validation loss: 1.9766
[Epoch 2, Batch 100] loss: 1.9156501245498658
[Epoch 2, Batch 200] loss: 1.7177717196941376
[Epoch 2, Batch 300] loss: 1.5163639712333679
[Epoch 2, Batch 400] loss: 1.26965203166008
[Epoch 2, Batch 500] loss: 1.0435647529363632
[Epoch 2, Batch 600] loss: 0.8696335685253144
[Epoch 2, Batch 700] loss: 0.7713595435023308
[Epoch 2, Batch 800] loss: 0.6922617334127427
[Epoch 2, Batch 900] loss: 0.6391574159264565
[Epoch 2, Batch 1000] loss: 0.5963727980852127
[Epoch 2, Batch 1100] loss: 0.5666699892282486
[Epoch 2, Batch 1200] loss: 0.5396436470746994
[Epoch 2, Batch 1300] loss: 0.5157872952520848
[Epoch 2, Batch 1400] loss: 0.5248587872087955
[Epoch 2, Batch 1500] loss: 0.4675033177435398
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.4590
Validation Accuracy: 0.8604
Overfitting: 0.4590
Best model saved at epoch 2 with validation loss: 0.4590
[Epoch 3, Batch 100] loss: 0.4699975651502609
[Epoch 3, Batch 200] loss: 0.43476743340492247
[Epoch 3, Batch 300] loss: 0.4739968007802963
[Epoch 3, Batch 400] loss: 0.45353102684020996
[Epoch 3, Batch 500] loss: 0.4273689490556717
[Epoch 3, Batch 600] loss: 0.42304881557822227
[Epoch 3, Batch 700] loss: 0.4180661696195602
[Epoch 3, Batch 800] loss: 0.4180760186910629
[Epoch 3, Batch 900] loss: 0.39409651786088945
[Epoch 3, Batch 1000] loss: 0.3818193462491035
[Epoch 3, Batch 1100] loss: 0.3764361987262964
[Epoch 3, Batch 1200] loss: 0.3450467062741518
[Epoch 3, Batch 1300] loss: 0.3664026040583849
[Epoch 3, Batch 1400] loss: 0.3628447527438402
[Epoch 3, Batch 1500] loss: 0.34012884214520456
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.3350
Validation Accuracy: 0.8996
Overfitting: 0.3350
Best model saved at epoch 3 with validation loss: 0.3350
[Epoch 4, Batch 100] loss: 0.3631097224354744
[Epoch 4, Batch 200] loss: 0.35434908486902716
[Epoch 4, Batch 300] loss: 0.34367617227137087
[Epoch 4, Batch 400] loss: 0.32626567862927913
[Epoch 4, Batch 500] loss: 0.33382797773927453
[Epoch 4, Batch 600] loss: 0.3406017599999905
[Epoch 4, Batch 700] loss: 0.30040631011128427
[Epoch 4, Batch 800] loss: 0.2911564536392689
[Epoch 4, Batch 900] loss: 0.2969961456209421
[Epoch 4, Batch 1000] loss: 0.30041452385485173
[Epoch 4, Batch 1100] loss: 0.2998701529204845
[Epoch 4, Batch 1200] loss: 0.3103931960463524
[Epoch 4, Batch 1300] loss: 0.30265901148319246
[Epoch 4, Batch 1400] loss: 0.2773908193409443
[Epoch 4, Batch 1500] loss: 0.26253918692469597
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.2610
Validation Accuracy: 0.9229
Overfitting: 0.2610
Best model saved at epoch 4 with validation loss: 0.2610
[Epoch 5, Batch 100] loss: 0.27475032456219195
[Epoch 5, Batch 200] loss: 0.27902802020311357
[Epoch 5, Batch 300] loss: 0.27676814794540405
[Epoch 5, Batch 400] loss: 0.285647997148335
[Epoch 5, Batch 500] loss: 0.2639372675120831
[Epoch 5, Batch 600] loss: 0.26113175131380556
[Epoch 5, Batch 700] loss: 0.269179624915123
[Epoch 5, Batch 800] loss: 0.25286380130797625
[Epoch 5, Batch 900] loss: 0.21699877485632896
[Epoch 5, Batch 1000] loss: 0.25684151947498324
[Epoch 5, Batch 1100] loss: 0.26706482507288454
[Epoch 5, Batch 1200] loss: 0.23705387011170387
[Epoch 5, Batch 1300] loss: 0.25070061095058915
[Epoch 5, Batch 1400] loss: 0.2684448508918285
[Epoch 5, Batch 1500] loss: 0.21594590831547975
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.2222
Validation Accuracy: 0.9351
Overfitting: 0.2222
Best model saved at epoch 5 with validation loss: 0.2222
[Epoch 6, Batch 100] loss: 0.23198078945279121
[Epoch 6, Batch 200] loss: 0.23078890163451432
[Epoch 6, Batch 300] loss: 0.2218472707271576
[Epoch 6, Batch 400] loss: 0.21029787357896568
[Epoch 6, Batch 500] loss: 0.21483916319906712
[Epoch 6, Batch 600] loss: 0.19686542194336654
[Epoch 6, Batch 700] loss: 0.24153459921479226
[Epoch 6, Batch 800] loss: 0.2375309383496642
[Epoch 6, Batch 900] loss: 0.20597975686192513
[Epoch 6, Batch 1000] loss: 0.19534551844000816
[Epoch 6, Batch 1100] loss: 0.21019071608781814
[Epoch 6, Batch 1200] loss: 0.21411351297050715
[Epoch 6, Batch 1300] loss: 0.23345950096845627
[Epoch 6, Batch 1400] loss: 0.2296400274336338
[Epoch 6, Batch 1500] loss: 0.208816956281662
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.1918
Validation Accuracy: 0.9424
Overfitting: 0.1918
[I 2024-12-11 04:25:52,937] Trial 10 pruned. 

Selected Hyperparameters for Trial 12:
  l1: 256, l2: 128, lr: 0.0038848919298815317, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.201733250617981
[Epoch 1, Batch 200] loss: 0.7517862129211426
[Epoch 1, Batch 300] loss: 0.33083352535963056
[Epoch 1, Batch 400] loss: 0.24715343810617924
[Epoch 1, Batch 500] loss: 0.19556072045117617
[Epoch 1, Batch 600] loss: 0.1684946409612894
[Epoch 1, Batch 700] loss: 0.13308777425438165
**STATS for Epoch 1** : 
Average training loss: 0.0088
Average validation loss: 0.1016
Validation Accuracy: 0.9675
Overfitting: 0.0927
Best model saved at epoch 1 with validation loss: 0.1016
[Epoch 2, Batch 100] loss: 0.1141967405192554
[Epoch 2, Batch 200] loss: 0.11510044110938907
[Epoch 2, Batch 300] loss: 0.11841646982356906
[Epoch 2, Batch 400] loss: 0.10173436048440636
[Epoch 2, Batch 500] loss: 0.08909545383416116
[Epoch 2, Batch 600] loss: 0.09325274233706296
[Epoch 2, Batch 700] loss: 0.07966418390162289
**STATS for Epoch 2** : 
Average training loss: 0.0055
Average validation loss: 0.0760
Validation Accuracy: 0.9752
Overfitting: 0.0704
Best model saved at epoch 2 with validation loss: 0.0760
[Epoch 3, Batch 100] loss: 0.07315064391121268
[Epoch 3, Batch 200] loss: 0.06997723205946386
[Epoch 3, Batch 300] loss: 0.06992684670258313
[Epoch 3, Batch 400] loss: 0.06048470146022737
[Epoch 3, Batch 500] loss: 0.07825374313630164
[Epoch 3, Batch 600] loss: 0.068250537449494
[Epoch 3, Batch 700] loss: 0.06134703332791105
**STATS for Epoch 3** : 
Average training loss: 0.0054
Average validation loss: 0.0649
Validation Accuracy: 0.9798
Overfitting: 0.0595
Best model saved at epoch 3 with validation loss: 0.0649
[Epoch 4, Batch 100] loss: 0.05753550027264282
[Epoch 4, Batch 200] loss: 0.04885064544971101
[Epoch 4, Batch 300] loss: 0.05739180974895135
[Epoch 4, Batch 400] loss: 0.05795089665800333
[Epoch 4, Batch 500] loss: 0.060075686927884814
[Epoch 4, Batch 600] loss: 0.04756307251518592
[Epoch 4, Batch 700] loss: 0.052109920540824535
**STATS for Epoch 4** : 
Average training loss: 0.0037
Average validation loss: 0.0568
Validation Accuracy: 0.9814
Overfitting: 0.0531
Best model saved at epoch 4 with validation loss: 0.0568
[Epoch 5, Batch 100] loss: 0.04288897631689906
[Epoch 5, Batch 200] loss: 0.037906478999648247
[Epoch 5, Batch 300] loss: 0.04365079647162929
[Epoch 5, Batch 400] loss: 0.04715290953987278
[Epoch 5, Batch 500] loss: 0.048386161176022145
[Epoch 5, Batch 600] loss: 0.05184923048596829
[Epoch 5, Batch 700] loss: 0.04349796613445506
**STATS for Epoch 5** : 
Average training loss: 0.0023
Average validation loss: 0.0576
Validation Accuracy: 0.9825
Overfitting: 0.0552
[Epoch 6, Batch 100] loss: 0.037893262654542924
[Epoch 6, Batch 200] loss: 0.03937286565662362
[Epoch 6, Batch 300] loss: 0.036772654000669716
[Epoch 6, Batch 400] loss: 0.03634924365207553
[Epoch 6, Batch 500] loss: 0.04186996063683182
[Epoch 6, Batch 600] loss: 0.03892804277129471
[Epoch 6, Batch 700] loss: 0.030655058434931562
**STATS for Epoch 6** : 
Average training loss: 0.0030
Average validation loss: 0.0464
Validation Accuracy: 0.9848
Overfitting: 0.0434
Best model saved at epoch 6 with validation loss: 0.0464
[Epoch 7, Batch 100] loss: 0.03651029759901576
[Epoch 7, Batch 200] loss: 0.03254444698162842
[Epoch 7, Batch 300] loss: 0.03248616700409911
[Epoch 7, Batch 400] loss: 0.032156077766558155
[Epoch 7, Batch 500] loss: 0.026964679058874026
[Epoch 7, Batch 600] loss: 0.02632609391468577
[Epoch 7, Batch 700] loss: 0.035133201965363695
**STATS for Epoch 7** : 
Average training loss: 0.0022
Average validation loss: 0.0444
Validation Accuracy: 0.9852
Overfitting: 0.0422
Best model saved at epoch 7 with validation loss: 0.0444
[Epoch 8, Batch 100] loss: 0.02242269769194536
[Epoch 8, Batch 200] loss: 0.024478259677998722
[Epoch 8, Batch 300] loss: 0.03209318967536092
[Epoch 8, Batch 400] loss: 0.029202223697211593
[Epoch 8, Batch 500] loss: 0.0336689337156713
[Epoch 8, Batch 600] loss: 0.027243017482687718
[Epoch 8, Batch 700] loss: 0.029948651919839905
**STATS for Epoch 8** : 
Average training loss: 0.0017
Average validation loss: 0.0460
Validation Accuracy: 0.9859
Overfitting: 0.0443
[Epoch 9, Batch 100] loss: 0.023343560048379005
[Epoch 9, Batch 200] loss: 0.020040055960416792
[Epoch 9, Batch 300] loss: 0.025466510500991718
[Epoch 9, Batch 400] loss: 0.020784690031723584
[Epoch 9, Batch 500] loss: 0.028029755355091765
[Epoch 9, Batch 600] loss: 0.022538933940522837
[Epoch 9, Batch 700] loss: 0.020977772880578414
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0496
Validation Accuracy: 0.9840
Overfitting: 0.0480
[Epoch 10, Batch 100] loss: 0.018626027490827254
[Epoch 10, Batch 200] loss: 0.017861707113479498
[Epoch 10, Batch 300] loss: 0.01940600738453213
[Epoch 10, Batch 400] loss: 0.017239027974719646
[Epoch 10, Batch 500] loss: 0.02558348523452878
[Epoch 10, Batch 600] loss: 0.02452645475510508
[Epoch 10, Batch 700] loss: 0.02491498405681341
**STATS for Epoch 10** : 
Average training loss: 0.0015
Average validation loss: 0.0400
Validation Accuracy: 0.9884
Overfitting: 0.0386
Best model saved at epoch 10 with validation loss: 0.0400
[Epoch 11, Batch 100] loss: 0.012990811269264668
[Epoch 11, Batch 200] loss: 0.013968453297857196
[Epoch 11, Batch 300] loss: 0.01950199645070825
[Epoch 11, Batch 400] loss: 0.015216601942956914
[Epoch 11, Batch 500] loss: 0.027673677726997994
[Epoch 11, Batch 600] loss: 0.019445347446016968
[Epoch 11, Batch 700] loss: 0.02015466363343876
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0457
Validation Accuracy: 0.9857
Overfitting: 0.0440
[Epoch 12, Batch 100] loss: 0.01508911453478504
[Epoch 12, Batch 200] loss: 0.010831033972208389
[Epoch 12, Batch 300] loss: 0.014522494129050757
[Epoch 12, Batch 400] loss: 0.016012342717003775
[Epoch 12, Batch 500] loss: 0.013235792643390596
[Epoch 12, Batch 600] loss: 0.018219827487191653
[Epoch 12, Batch 700] loss: 0.019664840125151385
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0399
Validation Accuracy: 0.9874
Overfitting: 0.0388
Best model saved at epoch 12 with validation loss: 0.0399
[Epoch 13, Batch 100] loss: 0.009444433898315764
[Epoch 13, Batch 200] loss: 0.011785470315808198
[Epoch 13, Batch 300] loss: 0.014197936891578137
[Epoch 13, Batch 400] loss: 0.012296892804006348
[Epoch 13, Batch 500] loss: 0.00830837240908295
[Epoch 13, Batch 600] loss: 0.015817740325001068
[Epoch 13, Batch 700] loss: 0.014275076354097109
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0411
Validation Accuracy: 0.9882
Overfitting: 0.0400
[Epoch 14, Batch 100] loss: 0.01089969484397443
[Epoch 14, Batch 200] loss: 0.007838380137982312
[Epoch 14, Batch 300] loss: 0.009579237947546062
[Epoch 14, Batch 400] loss: 0.011759000302117784
[Epoch 14, Batch 500] loss: 0.011948443170258543
[Epoch 14, Batch 600] loss: 0.011994848682079465
[Epoch 14, Batch 700] loss: 0.013634132044680882
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0470
Validation Accuracy: 0.9869
Overfitting: 0.0463
[Epoch 15, Batch 100] loss: 0.009446100034256232
[Epoch 15, Batch 200] loss: 0.007122240227763541
[Epoch 15, Batch 300] loss: 0.0091916729627701
[Epoch 15, Batch 400] loss: 0.008350005168140343
[Epoch 15, Batch 500] loss: 0.012097050182783278
[Epoch 15, Batch 600] loss: 0.012503018892821273
[Epoch 15, Batch 700] loss: 0.013858049881237093
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0498
Validation Accuracy: 0.9863
Overfitting: 0.0491
[Epoch 16, Batch 100] loss: 0.010248104530037381
[Epoch 16, Batch 200] loss: 0.007196278835326666
[Epoch 16, Batch 300] loss: 0.007544515004119603
[Epoch 16, Batch 400] loss: 0.009117780421402131
[Epoch 16, Batch 500] loss: 0.009255517097772099
[Epoch 16, Batch 600] loss: 0.009140523040405241
[Epoch 16, Batch 700] loss: 0.008153034414281137
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0445
Validation Accuracy: 0.9890
Overfitting: 0.0442
[Epoch 17, Batch 100] loss: 0.005544037215695425
[Epoch 17, Batch 200] loss: 0.005736151419696398
[Epoch 17, Batch 300] loss: 0.005780599265854107
[Epoch 17, Batch 400] loss: 0.006715419456722885
[Epoch 17, Batch 500] loss: 0.011341880815889454
[Epoch 17, Batch 600] loss: 0.00868069079318957
[Epoch 17, Batch 700] loss: 0.005678126116636122
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0406
Validation Accuracy: 0.9885
Overfitting: 0.0404
[Epoch 18, Batch 100] loss: 0.004848810905386926
[Epoch 18, Batch 200] loss: 0.0057186670966348175
[Epoch 18, Batch 300] loss: 0.004809810047190694
[Epoch 18, Batch 400] loss: 0.005703972505507408
[Epoch 18, Batch 500] loss: 0.0038773890933771326
[Epoch 18, Batch 600] loss: 0.00713677422647379
[Epoch 18, Batch 700] loss: 0.007602095342026587
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0463
Validation Accuracy: 0.9880
Overfitting: 0.0461
[Epoch 19, Batch 100] loss: 0.003470594741011155
[Epoch 19, Batch 200] loss: 0.006300286832956772
[Epoch 19, Batch 300] loss: 0.0031517452085518018
[Epoch 19, Batch 400] loss: 0.003231839114196191
[Epoch 19, Batch 500] loss: 0.004077146268245997
[Epoch 19, Batch 600] loss: 0.006072493724568631
[Epoch 19, Batch 700] loss: 0.004884429178246137
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0411
Validation Accuracy: 0.9899
Overfitting: 0.0408
[Epoch 20, Batch 100] loss: 0.0038803283095876395
[Epoch 20, Batch 200] loss: 0.002150404720341612
[Epoch 20, Batch 300] loss: 0.0018067698278537137
[Epoch 20, Batch 400] loss: 0.005535919534204368
[Epoch 20, Batch 500] loss: 0.008768635663291207
[Epoch 20, Batch 600] loss: 0.005308739591855556
[Epoch 20, Batch 700] loss: 0.002823157827388059
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0546
Validation Accuracy: 0.9871
Overfitting: 0.0540
[Epoch 21, Batch 100] loss: 0.009117415222062846
[Epoch 21, Batch 200] loss: 0.004413061746636231
[Epoch 21, Batch 300] loss: 0.006276381064235465
[Epoch 21, Batch 400] loss: 0.006164572298494022
[Epoch 21, Batch 500] loss: 0.012309956011740723
[Epoch 21, Batch 600] loss: 0.008806176232574216
[Epoch 21, Batch 700] loss: 0.007797967159312975
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0479
Validation Accuracy: 0.9879
Overfitting: 0.0476
[Epoch 22, Batch 100] loss: 0.0030382671255938477
[Epoch 22, Batch 200] loss: 0.00623189466603435
[Epoch 22, Batch 300] loss: 0.011638577554404037
[Epoch 22, Batch 400] loss: 0.006453003424112467
[Epoch 22, Batch 500] loss: 0.008418385772529291
[Epoch 22, Batch 600] loss: 0.004625942343209317
[Epoch 22, Batch 700] loss: 0.005835158933477942
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0514
Validation Accuracy: 0.9869
Overfitting: 0.0509
[Epoch 23, Batch 100] loss: 0.00725189832450269
[Epoch 23, Batch 200] loss: 0.0031033115023819846
[Epoch 23, Batch 300] loss: 0.0026398742124911223
[Epoch 23, Batch 400] loss: 0.001999962068712193
[Epoch 23, Batch 500] loss: 0.0014562781048334727
[Epoch 23, Batch 600] loss: 0.002228780579130216
[Epoch 23, Batch 700] loss: 0.0028679503808871232
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0455
Validation Accuracy: 0.9885
Overfitting: 0.0454
[Epoch 24, Batch 100] loss: 0.001222550765814958
[Epoch 24, Batch 200] loss: 0.0035569920119814923
[Epoch 24, Batch 300] loss: 0.0021240199683325045
[Epoch 24, Batch 400] loss: 0.00147404113165976
[Epoch 24, Batch 500] loss: 0.0015530741400652914
[Epoch 24, Batch 600] loss: 0.003889812623110629
[Epoch 24, Batch 700] loss: 0.0023015667005074647
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0438
Validation Accuracy: 0.9899
Overfitting: 0.0437
Fold 1 validation loss: 0.0438
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2624537777900695
[Epoch 1, Batch 200] loss: 1.0631480690836907
[Epoch 1, Batch 300] loss: 0.3487065033614635
[Epoch 1, Batch 400] loss: 0.24179841708391905
[Epoch 1, Batch 500] loss: 0.19532885959371923
[Epoch 1, Batch 600] loss: 0.15430968223139643
[Epoch 1, Batch 700] loss: 0.1604314697906375
**STATS for Epoch 1** : 
Average training loss: 0.0096
Average validation loss: 0.1409
Validation Accuracy: 0.9565
Overfitting: 0.1313
Best model saved at epoch 1 with validation loss: 0.1409
[Epoch 2, Batch 100] loss: 0.11751910435035824
[Epoch 2, Batch 200] loss: 0.09824075339362025
[Epoch 2, Batch 300] loss: 0.11391844008117914
[Epoch 2, Batch 400] loss: 0.10080286803655326
[Epoch 2, Batch 500] loss: 0.08962670332752168
[Epoch 2, Batch 600] loss: 0.10260557894129306
[Epoch 2, Batch 700] loss: 0.09437624899670481
**STATS for Epoch 2** : 
Average training loss: 0.0053
Average validation loss: 0.1135
Validation Accuracy: 0.9647
Overfitting: 0.1082
Best model saved at epoch 2 with validation loss: 0.1135
[Epoch 3, Batch 100] loss: 0.062348963394761085
[Epoch 3, Batch 200] loss: 0.07550521998200566
[Epoch 3, Batch 300] loss: 0.07126737388782203
[Epoch 3, Batch 400] loss: 0.06295169945806264
[Epoch 3, Batch 500] loss: 0.07041695542167872
[Epoch 3, Batch 600] loss: 0.07357429803814738
[Epoch 3, Batch 700] loss: 0.06694715759251267
**STATS for Epoch 3** : 
Average training loss: 0.0035
Average validation loss: 0.0724
Validation Accuracy: 0.9769
Overfitting: 0.0688
Best model saved at epoch 3 with validation loss: 0.0724
[Epoch 4, Batch 100] loss: 0.05375351912807673
[Epoch 4, Batch 200] loss: 0.056464682433288546
[Epoch 4, Batch 300] loss: 0.05357522675767541
[Epoch 4, Batch 400] loss: 0.049121490565594284
[Epoch 4, Batch 500] loss: 0.058600238466169685
[Epoch 4, Batch 600] loss: 0.062096772587392476
[Epoch 4, Batch 700] loss: 0.041736054639332
**STATS for Epoch 4** : 
Average training loss: 0.0032
Average validation loss: 0.0724
Validation Accuracy: 0.9777
Overfitting: 0.0692
[Epoch 5, Batch 100] loss: 0.03985691342037171
[Epoch 5, Batch 200] loss: 0.03899313928093761
[Epoch 5, Batch 300] loss: 0.03948585789417848
[Epoch 5, Batch 400] loss: 0.0465132787451148
[Epoch 5, Batch 500] loss: 0.04410578132374212
[Epoch 5, Batch 600] loss: 0.04484582472126931
[Epoch 5, Batch 700] loss: 0.04413775552529842
**STATS for Epoch 5** : 
Average training loss: 0.0031
Average validation loss: 0.0583
Validation Accuracy: 0.9838
Overfitting: 0.0553
Best model saved at epoch 5 with validation loss: 0.0583
[Epoch 6, Batch 100] loss: 0.03315622692927718
[Epoch 6, Batch 200] loss: 0.03023252363607753
[Epoch 6, Batch 300] loss: 0.03818426165846176
[Epoch 6, Batch 400] loss: 0.03633992231450975
[Epoch 6, Batch 500] loss: 0.03955804212309886
[Epoch 6, Batch 600] loss: 0.033004359861370174
[Epoch 6, Batch 700] loss: 0.041904487870633604
**STATS for Epoch 6** : 
Average training loss: 0.0020
Average validation loss: 0.0567
Validation Accuracy: 0.9823
Overfitting: 0.0547
Best model saved at epoch 6 with validation loss: 0.0567
[Epoch 7, Batch 100] loss: 0.027142126553226262
[Epoch 7, Batch 200] loss: 0.026495958773302845
[Epoch 7, Batch 300] loss: 0.03059821041300893
[Epoch 7, Batch 400] loss: 0.03546883405768313
[Epoch 7, Batch 500] loss: 0.03897388013312593
[Epoch 7, Batch 600] loss: 0.03214165482437238
[Epoch 7, Batch 700] loss: 0.024034075398230926
**STATS for Epoch 7** : 
Average training loss: 0.0024
Average validation loss: 0.0569
Validation Accuracy: 0.9829
Overfitting: 0.0545
[Epoch 8, Batch 100] loss: 0.024648070159018973
[Epoch 8, Batch 200] loss: 0.024140018913894893
[Epoch 8, Batch 300] loss: 0.029371407628641464
[Epoch 8, Batch 400] loss: 0.024725181687972508
[Epoch 8, Batch 500] loss: 0.030522269046050498
[Epoch 8, Batch 600] loss: 0.030269489491183778
[Epoch 8, Batch 700] loss: 0.026084819191310088
**STATS for Epoch 8** : 
Average training loss: 0.0023
Average validation loss: 0.0556
Validation Accuracy: 0.9838
Overfitting: 0.0533
Best model saved at epoch 8 with validation loss: 0.0556
[Epoch 9, Batch 100] loss: 0.015437525112938602
[Epoch 9, Batch 200] loss: 0.024968891361786517
[Epoch 9, Batch 300] loss: 0.028163719994481654
[Epoch 9, Batch 400] loss: 0.02735471741936635
[Epoch 9, Batch 500] loss: 0.025723150915582665
[Epoch 9, Batch 600] loss: 0.026586357808555477
[Epoch 9, Batch 700] loss: 0.02157886688481085
**STATS for Epoch 9** : 
Average training loss: 0.0010
Average validation loss: 0.0565
Validation Accuracy: 0.9842
Overfitting: 0.0555
[Epoch 10, Batch 100] loss: 0.020137068098702002
[Epoch 10, Batch 200] loss: 0.017334077803534454
[Epoch 10, Batch 300] loss: 0.020046686033019796
[Epoch 10, Batch 400] loss: 0.02092240006022621
[Epoch 10, Batch 500] loss: 0.01575870767934248
[Epoch 10, Batch 600] loss: 0.02029617442720337
[Epoch 10, Batch 700] loss: 0.02031548043101793
**STATS for Epoch 10** : 
Average training loss: 0.0014
Average validation loss: 0.0582
Validation Accuracy: 0.9848
Overfitting: 0.0567
[Epoch 11, Batch 100] loss: 0.01259078697024961
[Epoch 11, Batch 200] loss: 0.014813895890765707
[Epoch 11, Batch 300] loss: 0.017139125983812845
[Epoch 11, Batch 400] loss: 0.017445576196187175
[Epoch 11, Batch 500] loss: 0.01715686565352371
[Epoch 11, Batch 600] loss: 0.01938715456693899
[Epoch 11, Batch 700] loss: 0.02039881994060124
**STATS for Epoch 11** : 
Average training loss: 0.0013
Average validation loss: 0.0547
Validation Accuracy: 0.9841
Overfitting: 0.0533
Best model saved at epoch 11 with validation loss: 0.0547
[Epoch 12, Batch 100] loss: 0.011557586596463807
[Epoch 12, Batch 200] loss: 0.012167779622541276
[Epoch 12, Batch 300] loss: 0.013388226272945758
[Epoch 12, Batch 400] loss: 0.013502400122815743
[Epoch 12, Batch 500] loss: 0.013692275310677359
[Epoch 12, Batch 600] loss: 0.012842697960368242
[Epoch 12, Batch 700] loss: 0.017918115640350153
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0621
Validation Accuracy: 0.9844
Overfitting: 0.0608
[Epoch 13, Batch 100] loss: 0.010932761859876336
[Epoch 13, Batch 200] loss: 0.00868036092571856
[Epoch 13, Batch 300] loss: 0.010324713936133776
[Epoch 13, Batch 400] loss: 0.010512268720922292
[Epoch 13, Batch 500] loss: 0.018333853609656215
[Epoch 13, Batch 600] loss: 0.013445341794431442
[Epoch 13, Batch 700] loss: 0.014634226568596205
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0624
Validation Accuracy: 0.9843
Overfitting: 0.0616
[Epoch 14, Batch 100] loss: 0.009057243674615165
[Epoch 14, Batch 200] loss: 0.012465630715887528
[Epoch 14, Batch 300] loss: 0.010966803357587197
[Epoch 14, Batch 400] loss: 0.012487510775972623
[Epoch 14, Batch 500] loss: 0.008907754698448116
[Epoch 14, Batch 600] loss: 0.011169811719155405
[Epoch 14, Batch 700] loss: 0.010160864515200955
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0688
Validation Accuracy: 0.9816
Overfitting: 0.0679
[Epoch 15, Batch 100] loss: 0.007375337469493388
[Epoch 15, Batch 200] loss: 0.008726589769321436
[Epoch 15, Batch 300] loss: 0.011307827089040075
[Epoch 15, Batch 400] loss: 0.006811623457797396
[Epoch 15, Batch 500] loss: 0.012175985354624573
[Epoch 15, Batch 600] loss: 0.00904066295872326
[Epoch 15, Batch 700] loss: 0.014734261512021476
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0534
Validation Accuracy: 0.9858
Overfitting: 0.0528
Best model saved at epoch 15 with validation loss: 0.0534
[Epoch 16, Batch 100] loss: 0.007617121720868454
[Epoch 16, Batch 200] loss: 0.009185247755376623
[Epoch 16, Batch 300] loss: 0.005925202953749249
[Epoch 16, Batch 400] loss: 0.011335215777799022
[Epoch 16, Batch 500] loss: 0.013789121536101448
[Epoch 16, Batch 600] loss: 0.009218959391291718
[Epoch 16, Batch 700] loss: 0.008957323286740575
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0590
Validation Accuracy: 0.9846
Overfitting: 0.0584
[Epoch 17, Batch 100] loss: 0.007178501094967942
[Epoch 17, Batch 200] loss: 0.006898741776749376
[Epoch 17, Batch 300] loss: 0.005760639655272825
[Epoch 17, Batch 400] loss: 0.006534117163846531
[Epoch 17, Batch 500] loss: 0.009675140756189648
[Epoch 17, Batch 600] loss: 0.005083896671749244
[Epoch 17, Batch 700] loss: 0.010275979229481891
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0538
Validation Accuracy: 0.9876
Overfitting: 0.0528
[Epoch 18, Batch 100] loss: 0.005205961914871295
[Epoch 18, Batch 200] loss: 0.005998938955999619
[Epoch 18, Batch 300] loss: 0.009853556572488742
[Epoch 18, Batch 400] loss: 0.005243918966662022
[Epoch 18, Batch 500] loss: 0.008995402168366126
[Epoch 18, Batch 600] loss: 0.005356692024847689
[Epoch 18, Batch 700] loss: 0.009032676323622582
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0608
Validation Accuracy: 0.9863
Overfitting: 0.0604
[Epoch 19, Batch 100] loss: 0.004572678881504544
[Epoch 19, Batch 200] loss: 0.003159959790573339
[Epoch 19, Batch 300] loss: 0.003203780741550872
[Epoch 19, Batch 400] loss: 0.0072431750030227705
[Epoch 19, Batch 500] loss: 0.006794255099011934
[Epoch 19, Batch 600] loss: 0.006957481648096291
[Epoch 19, Batch 700] loss: 0.006099291760692722
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0590
Validation Accuracy: 0.9855
Overfitting: 0.0585
[Epoch 20, Batch 100] loss: 0.004718481689160399
[Epoch 20, Batch 200] loss: 0.004770596289072273
[Epoch 20, Batch 300] loss: 0.0027498853864926787
[Epoch 20, Batch 400] loss: 0.00426699934352655
[Epoch 20, Batch 500] loss: 0.0063232913773026665
[Epoch 20, Batch 600] loss: 0.009706006680335121
[Epoch 20, Batch 700] loss: 0.0053753079184753
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0587
Validation Accuracy: 0.9872
Overfitting: 0.0584
[Epoch 21, Batch 100] loss: 0.004870567765788109
[Epoch 21, Batch 200] loss: 0.0031925284505086894
[Epoch 21, Batch 300] loss: 0.006170706612720096
[Epoch 21, Batch 400] loss: 0.003508257767607574
[Epoch 21, Batch 500] loss: 0.00423503951676139
[Epoch 21, Batch 600] loss: 0.003522319944913761
[Epoch 21, Batch 700] loss: 0.0030228658808073307
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0641
Validation Accuracy: 0.9861
Overfitting: 0.0640
[Epoch 22, Batch 100] loss: 0.002496457843508324
[Epoch 22, Batch 200] loss: 0.0019348675578476104
[Epoch 22, Batch 300] loss: 0.0026732985694616217
[Epoch 22, Batch 400] loss: 0.003703326702107006
[Epoch 22, Batch 500] loss: 0.003107604034757969
[Epoch 22, Batch 600] loss: 0.005569809120406717
[Epoch 22, Batch 700] loss: 0.002593857184783701
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0611
Validation Accuracy: 0.9864
Overfitting: 0.0608
[Epoch 23, Batch 100] loss: 0.0028252893511171353
[Epoch 23, Batch 200] loss: 0.00395518249527413
[Epoch 23, Batch 300] loss: 0.0026757390747479803
[Epoch 23, Batch 400] loss: 0.0030652231079329796
[Epoch 23, Batch 500] loss: 0.0035565010246227757
[Epoch 23, Batch 600] loss: 0.0035522604027391933
[Epoch 23, Batch 700] loss: 0.003888578489295469
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0591
Validation Accuracy: 0.9877
Overfitting: 0.0589
[Epoch 24, Batch 100] loss: 0.0015238059364492073
[Epoch 24, Batch 200] loss: 0.0014006414885579944
[Epoch 24, Batch 300] loss: 0.0017721404048677413
[Epoch 24, Batch 400] loss: 0.002487634767057898
[Epoch 24, Batch 500] loss: 0.0017594941599963932
[Epoch 24, Batch 600] loss: 0.0008945692099086955
[Epoch 24, Batch 700] loss: 0.0011346439902490601
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0616
Validation Accuracy: 0.9878
Overfitting: 0.0615
Fold 2 validation loss: 0.0616
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.1010381174087525
[Epoch 1, Batch 200] loss: 0.5519987486302853
[Epoch 1, Batch 300] loss: 0.3329601910710335
[Epoch 1, Batch 400] loss: 0.23293442234396936
[Epoch 1, Batch 500] loss: 0.20155503921210766
[Epoch 1, Batch 600] loss: 0.14331972524523734
[Epoch 1, Batch 700] loss: 0.1475119785964489
**STATS for Epoch 1** : 
Average training loss: 0.0086
Average validation loss: 0.1246
Validation Accuracy: 0.9614
Overfitting: 0.1160
Best model saved at epoch 1 with validation loss: 0.1246
[Epoch 2, Batch 100] loss: 0.11203608037903905
[Epoch 2, Batch 200] loss: 0.11093705302104354
[Epoch 2, Batch 300] loss: 0.1217985994182527
[Epoch 2, Batch 400] loss: 0.09761610439047218
[Epoch 2, Batch 500] loss: 0.09751814939081668
[Epoch 2, Batch 600] loss: 0.08842683410272002
[Epoch 2, Batch 700] loss: 0.07175070977769792
**STATS for Epoch 2** : 
Average training loss: 0.0063
Average validation loss: 0.1151
Validation Accuracy: 0.9624
Overfitting: 0.1087
Best model saved at epoch 2 with validation loss: 0.1151
[Epoch 3, Batch 100] loss: 0.07777949016541243
[Epoch 3, Batch 200] loss: 0.06735892531462014
[Epoch 3, Batch 300] loss: 0.08197650277987123
[Epoch 3, Batch 400] loss: 0.06691293079406023
[Epoch 3, Batch 500] loss: 0.06436185357160866
[Epoch 3, Batch 600] loss: 0.06545695488341152
[Epoch 3, Batch 700] loss: 0.06897644866257906
**STATS for Epoch 3** : 
Average training loss: 0.0039
Average validation loss: 0.0683
Validation Accuracy: 0.9795
Overfitting: 0.0643
Best model saved at epoch 3 with validation loss: 0.0683
[Epoch 4, Batch 100] loss: 0.0554401868628338
[Epoch 4, Batch 200] loss: 0.05296915944898501
[Epoch 4, Batch 300] loss: 0.056573518516961484
[Epoch 4, Batch 400] loss: 0.0472174093965441
[Epoch 4, Batch 500] loss: 0.04755448922282085
[Epoch 4, Batch 600] loss: 0.05809592608828098
[Epoch 4, Batch 700] loss: 0.05761518607148901
**STATS for Epoch 4** : 
Average training loss: 0.0037
Average validation loss: 0.0654
Validation Accuracy: 0.9798
Overfitting: 0.0617
Best model saved at epoch 4 with validation loss: 0.0654
[Epoch 5, Batch 100] loss: 0.04389262794051319
[Epoch 5, Batch 200] loss: 0.05074226318392903
[Epoch 5, Batch 300] loss: 0.043916070661507545
[Epoch 5, Batch 400] loss: 0.042278709423262624
[Epoch 5, Batch 500] loss: 0.040259322579950095
[Epoch 5, Batch 600] loss: 0.04073808384127915
[Epoch 5, Batch 700] loss: 0.045568013787269594
**STATS for Epoch 5** : 
Average training loss: 0.0023
Average validation loss: 0.0638
Validation Accuracy: 0.9804
Overfitting: 0.0614
Best model saved at epoch 5 with validation loss: 0.0638
[Epoch 6, Batch 100] loss: 0.03852224654867314
[Epoch 6, Batch 200] loss: 0.03385989838046953
[Epoch 6, Batch 300] loss: 0.03686041129520163
[Epoch 6, Batch 400] loss: 0.03871426863712259
[Epoch 6, Batch 500] loss: 0.03210515087179374
[Epoch 6, Batch 600] loss: 0.03879144314210862
[Epoch 6, Batch 700] loss: 0.03150415442418307
**STATS for Epoch 6** : 
Average training loss: 0.0033
Average validation loss: 0.0533
Validation Accuracy: 0.9833
Overfitting: 0.0501
Best model saved at epoch 6 with validation loss: 0.0533
[Epoch 7, Batch 100] loss: 0.030532428056467324
[Epoch 7, Batch 200] loss: 0.036534950234927234
[Epoch 7, Batch 300] loss: 0.03174273621989414
[Epoch 7, Batch 400] loss: 0.03282199034001678
[Epoch 7, Batch 500] loss: 0.03567076187464409
[Epoch 7, Batch 600] loss: 0.030202061297604815
[Epoch 7, Batch 700] loss: 0.028630847472231834
**STATS for Epoch 7** : 
Average training loss: 0.0026
Average validation loss: 0.0532
Validation Accuracy: 0.9837
Overfitting: 0.0505
Best model saved at epoch 7 with validation loss: 0.0532
[Epoch 8, Batch 100] loss: 0.02399665747245308
[Epoch 8, Batch 200] loss: 0.025416337830829434
[Epoch 8, Batch 300] loss: 0.02080005748081021
[Epoch 8, Batch 400] loss: 0.02725598959077615
[Epoch 8, Batch 500] loss: 0.03227231724653393
[Epoch 8, Batch 600] loss: 0.027459116854006423
[Epoch 8, Batch 700] loss: 0.02727657437149901
**STATS for Epoch 8** : 
Average training loss: 0.0017
Average validation loss: 0.0501
Validation Accuracy: 0.9853
Overfitting: 0.0485
Best model saved at epoch 8 with validation loss: 0.0501
[Epoch 9, Batch 100] loss: 0.019273597215651535
[Epoch 9, Batch 200] loss: 0.021975399150978774
[Epoch 9, Batch 300] loss: 0.01804553294816287
[Epoch 9, Batch 400] loss: 0.023156021952163427
[Epoch 9, Batch 500] loss: 0.025982661718153395
[Epoch 9, Batch 600] loss: 0.029062377915834076
[Epoch 9, Batch 700] loss: 0.025003541311598383
**STATS for Epoch 9** : 
Average training loss: 0.0022
Average validation loss: 0.0456
Validation Accuracy: 0.9863
Overfitting: 0.0434
Best model saved at epoch 9 with validation loss: 0.0456
[Epoch 10, Batch 100] loss: 0.01770382452494232
[Epoch 10, Batch 200] loss: 0.01654374705045484
[Epoch 10, Batch 300] loss: 0.019365714346349705
[Epoch 10, Batch 400] loss: 0.016734204632230104
[Epoch 10, Batch 500] loss: 0.021215163436718285
[Epoch 10, Batch 600] loss: 0.022869785030779896
[Epoch 10, Batch 700] loss: 0.021590108872478597
**STATS for Epoch 10** : 
Average training loss: 0.0014
Average validation loss: 0.0490
Validation Accuracy: 0.9858
Overfitting: 0.0476
[Epoch 11, Batch 100] loss: 0.015035907660494558
[Epoch 11, Batch 200] loss: 0.01426702332290006
[Epoch 11, Batch 300] loss: 0.018261887761182153
[Epoch 11, Batch 400] loss: 0.02097926083864877
[Epoch 11, Batch 500] loss: 0.021431315994705075
[Epoch 11, Batch 600] loss: 0.015860117734991946
[Epoch 11, Batch 700] loss: 0.01975464348186506
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0443
Validation Accuracy: 0.9870
Overfitting: 0.0434
Best model saved at epoch 11 with validation loss: 0.0443
[Epoch 12, Batch 100] loss: 0.014281815117574297
[Epoch 12, Batch 200] loss: 0.011174035447475035
[Epoch 12, Batch 300] loss: 0.014572634071082575
[Epoch 12, Batch 400] loss: 0.013897432892299548
[Epoch 12, Batch 500] loss: 0.016348323538113618
[Epoch 12, Batch 600] loss: 0.01688969416427426
[Epoch 12, Batch 700] loss: 0.01477725979697425
**STATS for Epoch 12** : 
Average training loss: 0.0016
Average validation loss: 0.0518
Validation Accuracy: 0.9853
Overfitting: 0.0502
[Epoch 13, Batch 100] loss: 0.012297081288998014
[Epoch 13, Batch 200] loss: 0.008528474400227424
[Epoch 13, Batch 300] loss: 0.012697940946964081
[Epoch 13, Batch 400] loss: 0.012472206662641839
[Epoch 13, Batch 500] loss: 0.012026418657696922
[Epoch 13, Batch 600] loss: 0.01477226543618599
[Epoch 13, Batch 700] loss: 0.012774131445912645
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0448
Validation Accuracy: 0.9877
Overfitting: 0.0440
[Epoch 14, Batch 100] loss: 0.007676514678823878
[Epoch 14, Batch 200] loss: 0.008976594827108783
[Epoch 14, Batch 300] loss: 0.012335741803981363
[Epoch 14, Batch 400] loss: 0.009213549433916342
[Epoch 14, Batch 500] loss: 0.011433985736439355
[Epoch 14, Batch 600] loss: 0.01478180149664695
[Epoch 14, Batch 700] loss: 0.008829356802161783
**STATS for Epoch 14** : 
Average training loss: 0.0011
Average validation loss: 0.0446
Validation Accuracy: 0.9887
Overfitting: 0.0435
[Epoch 15, Batch 100] loss: 0.007662569185922621
[Epoch 15, Batch 200] loss: 0.008891277891671052
[Epoch 15, Batch 300] loss: 0.006903882654223707
[Epoch 15, Batch 400] loss: 0.009021355393779231
[Epoch 15, Batch 500] loss: 0.009658023060910636
[Epoch 15, Batch 600] loss: 0.013018246361243655
[Epoch 15, Batch 700] loss: 0.010235195229324746
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0514
Validation Accuracy: 0.9861
Overfitting: 0.0504
[Epoch 16, Batch 100] loss: 0.0072921881139700415
[Epoch 16, Batch 200] loss: 0.007429624327487545
[Epoch 16, Batch 300] loss: 0.00895490431057624
[Epoch 16, Batch 400] loss: 0.005891832008928759
[Epoch 16, Batch 500] loss: 0.011682021122906007
[Epoch 16, Batch 600] loss: 0.01353829944098834
[Epoch 16, Batch 700] loss: 0.01055644914304139
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0525
Validation Accuracy: 0.9864
Overfitting: 0.0516
[Epoch 17, Batch 100] loss: 0.008157046090163931
[Epoch 17, Batch 200] loss: 0.007212128343089716
[Epoch 17, Batch 300] loss: 0.006247261736789369
[Epoch 17, Batch 400] loss: 0.0053050124125002185
[Epoch 17, Batch 500] loss: 0.005535636068452731
[Epoch 17, Batch 600] loss: 0.012104641114419792
[Epoch 17, Batch 700] loss: 0.007895872354929452
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0538
Validation Accuracy: 0.9868
Overfitting: 0.0531
[Epoch 18, Batch 100] loss: 0.004574907410096784
[Epoch 18, Batch 200] loss: 0.005234172392483742
[Epoch 18, Batch 300] loss: 0.0034997941823166913
[Epoch 18, Batch 400] loss: 0.0038970054920810073
[Epoch 18, Batch 500] loss: 0.006853291273600916
[Epoch 18, Batch 600] loss: 0.00720789729122771
[Epoch 18, Batch 700] loss: 0.0067898894569771075
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0526
Validation Accuracy: 0.9876
Overfitting: 0.0517
[Epoch 19, Batch 100] loss: 0.005635861846822081
[Epoch 19, Batch 200] loss: 0.003988663590926081
[Epoch 19, Batch 300] loss: 0.004270500149686995
[Epoch 19, Batch 400] loss: 0.004076258377099293
[Epoch 19, Batch 500] loss: 0.007410076797750662
[Epoch 19, Batch 600] loss: 0.0032278961656265893
[Epoch 19, Batch 700] loss: 0.002111054747601884
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0489
Validation Accuracy: 0.9888
Overfitting: 0.0486
[Epoch 20, Batch 100] loss: 0.0038312013669201408
[Epoch 20, Batch 200] loss: 0.0034207091496045905
[Epoch 20, Batch 300] loss: 0.0029344954486714412
[Epoch 20, Batch 400] loss: 0.0023560964796888583
[Epoch 20, Batch 500] loss: 0.007603749111585785
[Epoch 20, Batch 600] loss: 0.009986092834242299
[Epoch 20, Batch 700] loss: 0.00620316795520921
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0482
Validation Accuracy: 0.9896
Overfitting: 0.0481
[Epoch 21, Batch 100] loss: 0.0018028405165387085
[Epoch 21, Batch 200] loss: 0.002066493329007244
[Epoch 21, Batch 300] loss: 0.002496846311751142
[Epoch 21, Batch 400] loss: 0.002746716290967015
[Epoch 21, Batch 500] loss: 0.003198121600307786
[Epoch 21, Batch 600] loss: 0.0014796086778642347
[Epoch 21, Batch 700] loss: 0.0029870894687701365
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0516
Validation Accuracy: 0.9888
Overfitting: 0.0514
[Epoch 22, Batch 100] loss: 0.004220648904306472
[Epoch 22, Batch 200] loss: 0.002134171524321573
[Epoch 22, Batch 300] loss: 0.0031492444678224273
[Epoch 22, Batch 400] loss: 0.002216654749472582
[Epoch 22, Batch 500] loss: 0.003445489741136498
[Epoch 22, Batch 600] loss: 0.003652841771754538
[Epoch 22, Batch 700] loss: 0.005647916629382053
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0533
Validation Accuracy: 0.9886
Overfitting: 0.0531
[Epoch 23, Batch 100] loss: 0.0028141938374756136
[Epoch 23, Batch 200] loss: 0.008000230546699641
[Epoch 23, Batch 300] loss: 0.007066052766567736
[Epoch 23, Batch 400] loss: 0.004898423134600307
[Epoch 23, Batch 500] loss: 0.005768263540021508
[Epoch 23, Batch 600] loss: 0.002560225337074371
[Epoch 23, Batch 700] loss: 0.0026565516214941453
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0492
Validation Accuracy: 0.9890
Overfitting: 0.0491
[Epoch 24, Batch 100] loss: 0.0010352909847460977
[Epoch 24, Batch 200] loss: 0.0015471431015976122
[Epoch 24, Batch 300] loss: 0.0030765435115336004
[Epoch 24, Batch 400] loss: 0.0023891440216175395
[Epoch 24, Batch 500] loss: 0.002474449307019313
[Epoch 24, Batch 600] loss: 0.0022862095235450398
[Epoch 24, Batch 700] loss: 0.00463301514799241
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0543
Validation Accuracy: 0.9876
Overfitting: 0.0542
Fold 3 validation loss: 0.0543
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2528116631507875
[Epoch 1, Batch 200] loss: 0.9623559612035751
[Epoch 1, Batch 300] loss: 0.3400756472349167
[Epoch 1, Batch 400] loss: 0.21671584270894528
[Epoch 1, Batch 500] loss: 0.17351785905659198
[Epoch 1, Batch 600] loss: 0.15526989743113517
[Epoch 1, Batch 700] loss: 0.12883749233558775
**STATS for Epoch 1** : 
Average training loss: 0.0097
Average validation loss: 0.1629
Validation Accuracy: 0.9488
Overfitting: 0.1532
Best model saved at epoch 1 with validation loss: 0.1629
[Epoch 2, Batch 100] loss: 0.12641207130625845
[Epoch 2, Batch 200] loss: 0.1020995803270489
[Epoch 2, Batch 300] loss: 0.10626266364008188
[Epoch 2, Batch 400] loss: 0.10905344849452377
[Epoch 2, Batch 500] loss: 0.09792783631943167
[Epoch 2, Batch 600] loss: 0.08699191223829984
[Epoch 2, Batch 700] loss: 0.08551064987666905
**STATS for Epoch 2** : 
Average training loss: 0.0060
Average validation loss: 0.0889
Validation Accuracy: 0.9701
Overfitting: 0.0829
Best model saved at epoch 2 with validation loss: 0.0889
[Epoch 3, Batch 100] loss: 0.08098025299608708
[Epoch 3, Batch 200] loss: 0.06831679418683052
[Epoch 3, Batch 300] loss: 0.060470049241557716
[Epoch 3, Batch 400] loss: 0.0633625453338027
[Epoch 3, Batch 500] loss: 0.07488467837683857
[Epoch 3, Batch 600] loss: 0.07401311079971493
[Epoch 3, Batch 700] loss: 0.07197156681213528
**STATS for Epoch 3** : 
Average training loss: 0.0042
Average validation loss: 0.0849
Validation Accuracy: 0.9749
Overfitting: 0.0807
Best model saved at epoch 3 with validation loss: 0.0849
[Epoch 4, Batch 100] loss: 0.049646689344663174
[Epoch 4, Batch 200] loss: 0.05780737182823941
[Epoch 4, Batch 300] loss: 0.05660988484043628
[Epoch 4, Batch 400] loss: 0.05346370412968099
[Epoch 4, Batch 500] loss: 0.053535005212761465
[Epoch 4, Batch 600] loss: 0.061720784166827795
[Epoch 4, Batch 700] loss: 0.06012517824303359
**STATS for Epoch 4** : 
Average training loss: 0.0039
Average validation loss: 0.0615
Validation Accuracy: 0.9802
Overfitting: 0.0577
Best model saved at epoch 4 with validation loss: 0.0615
[Epoch 5, Batch 100] loss: 0.04536400978686288
[Epoch 5, Batch 200] loss: 0.04785943415481597
[Epoch 5, Batch 300] loss: 0.04929264109581709
[Epoch 5, Batch 400] loss: 0.05297195796389133
[Epoch 5, Batch 500] loss: 0.045164671133970845
[Epoch 5, Batch 600] loss: 0.04011925215367228
[Epoch 5, Batch 700] loss: 0.04290725024649873
**STATS for Epoch 5** : 
Average training loss: 0.0029
Average validation loss: 0.0559
Validation Accuracy: 0.9819
Overfitting: 0.0529
Best model saved at epoch 5 with validation loss: 0.0559
[Epoch 6, Batch 100] loss: 0.035315872956998645
[Epoch 6, Batch 200] loss: 0.03441901695798151
[Epoch 6, Batch 300] loss: 0.04179869238985703
[Epoch 6, Batch 400] loss: 0.03701061362866312
[Epoch 6, Batch 500] loss: 0.05003159046755172
[Epoch 6, Batch 600] loss: 0.03561661058687605
[Epoch 6, Batch 700] loss: 0.03839803392533213
**STATS for Epoch 6** : 
Average training loss: 0.0021
Average validation loss: 0.0521
Validation Accuracy: 0.9833
Overfitting: 0.0500
Best model saved at epoch 6 with validation loss: 0.0521
[Epoch 7, Batch 100] loss: 0.03308007095358335
[Epoch 7, Batch 200] loss: 0.029746117738541217
[Epoch 7, Batch 300] loss: 0.03661666703410447
[Epoch 7, Batch 400] loss: 0.036619316789438014
[Epoch 7, Batch 500] loss: 0.031918359422124926
[Epoch 7, Batch 600] loss: 0.035989785358542574
[Epoch 7, Batch 700] loss: 0.0341652123327367
**STATS for Epoch 7** : 
Average training loss: 0.0025
Average validation loss: 0.0447
Validation Accuracy: 0.9850
Overfitting: 0.0421
Best model saved at epoch 7 with validation loss: 0.0447
[Epoch 8, Batch 100] loss: 0.022807146312552505
[Epoch 8, Batch 200] loss: 0.020997632970975247
[Epoch 8, Batch 300] loss: 0.033480293781613
[Epoch 8, Batch 400] loss: 0.0290197479253402
[Epoch 8, Batch 500] loss: 0.03162430720491102
[Epoch 8, Batch 600] loss: 0.02916889503248967
[Epoch 8, Batch 700] loss: 0.032857518831733615
**STATS for Epoch 8** : 
Average training loss: 0.0016
Average validation loss: 0.0471
Validation Accuracy: 0.9860
Overfitting: 0.0455
[Epoch 9, Batch 100] loss: 0.023864377938443794
[Epoch 9, Batch 200] loss: 0.025638786045601592
[Epoch 9, Batch 300] loss: 0.027423048195196316
[Epoch 9, Batch 400] loss: 0.02608255684725009
[Epoch 9, Batch 500] loss: 0.016752167686354368
[Epoch 9, Batch 600] loss: 0.020811123426537962
[Epoch 9, Batch 700] loss: 0.025452077338122762
**STATS for Epoch 9** : 
Average training loss: 0.0021
Average validation loss: 0.0531
Validation Accuracy: 0.9822
Overfitting: 0.0510
[Epoch 10, Batch 100] loss: 0.018789002791891107
[Epoch 10, Batch 200] loss: 0.01734896335969097
[Epoch 10, Batch 300] loss: 0.023064616649062373
[Epoch 10, Batch 400] loss: 0.024068751107552088
[Epoch 10, Batch 500] loss: 0.018129810142563655
[Epoch 10, Batch 600] loss: 0.0260000853537349
[Epoch 10, Batch 700] loss: 0.019114191255066543
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0536
Validation Accuracy: 0.9832
Overfitting: 0.0520
[Epoch 11, Batch 100] loss: 0.017653150633559562
[Epoch 11, Batch 200] loss: 0.016635937843821013
[Epoch 11, Batch 300] loss: 0.017818396789371038
[Epoch 11, Batch 400] loss: 0.022643456155783497
[Epoch 11, Batch 500] loss: 0.017131314840808046
[Epoch 11, Batch 600] loss: 0.014844049634702969
[Epoch 11, Batch 700] loss: 0.019209222286663136
**STATS for Epoch 11** : 
Average training loss: 0.0011
Average validation loss: 0.0441
Validation Accuracy: 0.9866
Overfitting: 0.0431
Best model saved at epoch 11 with validation loss: 0.0441
[Epoch 12, Batch 100] loss: 0.012313646530892584
[Epoch 12, Batch 200] loss: 0.013751669805205893
[Epoch 12, Batch 300] loss: 0.011396033450291726
[Epoch 12, Batch 400] loss: 0.01794834816319053
[Epoch 12, Batch 500] loss: 0.012024690151156392
[Epoch 12, Batch 600] loss: 0.014799089687148808
[Epoch 12, Batch 700] loss: 0.017865378925926052
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0487
Validation Accuracy: 0.9861
Overfitting: 0.0474
[Epoch 13, Batch 100] loss: 0.014638944602629635
[Epoch 13, Batch 200] loss: 0.010767862037755548
[Epoch 13, Batch 300] loss: 0.01153588268411113
[Epoch 13, Batch 400] loss: 0.013588240630633663
[Epoch 13, Batch 500] loss: 0.013041810907598119
[Epoch 13, Batch 600] loss: 0.016072348852467257
[Epoch 13, Batch 700] loss: 0.01420050945758703
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0460
Validation Accuracy: 0.9867
Overfitting: 0.0449
[Epoch 14, Batch 100] loss: 0.007870910786368767
[Epoch 14, Batch 200] loss: 0.00961326912001823
[Epoch 14, Batch 300] loss: 0.011683047733968124
[Epoch 14, Batch 400] loss: 0.011791908882187271
[Epoch 14, Batch 500] loss: 0.012629422958270879
[Epoch 14, Batch 600] loss: 0.012277279192057905
[Epoch 14, Batch 700] loss: 0.008772569681459572
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0555
Validation Accuracy: 0.9851
Overfitting: 0.0542
[Epoch 15, Batch 100] loss: 0.010238113875093404
[Epoch 15, Batch 200] loss: 0.008272095486099716
[Epoch 15, Batch 300] loss: 0.007019517106600688
[Epoch 15, Batch 400] loss: 0.008876056902809069
[Epoch 15, Batch 500] loss: 0.01691582535917405
[Epoch 15, Batch 600] loss: 0.008597903812333243
[Epoch 15, Batch 700] loss: 0.013579058708273806
**STATS for Epoch 15** : 
Average training loss: 0.0014
Average validation loss: 0.0615
Validation Accuracy: 0.9832
Overfitting: 0.0601
[Epoch 16, Batch 100] loss: 0.00803967642626958
[Epoch 16, Batch 200] loss: 0.014489909497788176
[Epoch 16, Batch 300] loss: 0.007289382144917909
[Epoch 16, Batch 400] loss: 0.007093954953143111
[Epoch 16, Batch 500] loss: 0.0068307209009071815
[Epoch 16, Batch 600] loss: 0.009968098607860156
[Epoch 16, Batch 700] loss: 0.00868013865053399
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0435
Validation Accuracy: 0.9873
Overfitting: 0.0429
Best model saved at epoch 16 with validation loss: 0.0435
[Epoch 17, Batch 100] loss: 0.005213834077712818
[Epoch 17, Batch 200] loss: 0.0058914142494904806
[Epoch 17, Batch 300] loss: 0.0071735792871550075
[Epoch 17, Batch 400] loss: 0.008479977398237679
[Epoch 17, Batch 500] loss: 0.009167920923428028
[Epoch 17, Batch 600] loss: 0.011759384748147568
[Epoch 17, Batch 700] loss: 0.00533533601432282
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0483
Validation Accuracy: 0.9863
Overfitting: 0.0478
[Epoch 18, Batch 100] loss: 0.004908449187714723
[Epoch 18, Batch 200] loss: 0.005018312160191271
[Epoch 18, Batch 300] loss: 0.00481642259790533
[Epoch 18, Batch 400] loss: 0.004156093418932869
[Epoch 18, Batch 500] loss: 0.004889107328926912
[Epoch 18, Batch 600] loss: 0.00534570713450421
[Epoch 18, Batch 700] loss: 0.0044203463628218745
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0540
Validation Accuracy: 0.9854
Overfitting: 0.0535
[Epoch 19, Batch 100] loss: 0.005410057369026618
[Epoch 19, Batch 200] loss: 0.002439310751242374
[Epoch 19, Batch 300] loss: 0.002648621551552424
[Epoch 19, Batch 400] loss: 0.006529596601285448
[Epoch 19, Batch 500] loss: 0.006045377690807072
[Epoch 19, Batch 600] loss: 0.006694096015562537
[Epoch 19, Batch 700] loss: 0.0084160049815182
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0455
Validation Accuracy: 0.9876
Overfitting: 0.0449
[Epoch 20, Batch 100] loss: 0.00336078111844472
[Epoch 20, Batch 200] loss: 0.004090759567225178
[Epoch 20, Batch 300] loss: 0.0030678430790430865
[Epoch 20, Batch 400] loss: 0.003476143628868158
[Epoch 20, Batch 500] loss: 0.004093023128807545
[Epoch 20, Batch 600] loss: 0.005123845164380327
[Epoch 20, Batch 700] loss: 0.008148423048196492
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0514
Validation Accuracy: 0.9878
Overfitting: 0.0511
[Epoch 21, Batch 100] loss: 0.0036837500429101055
[Epoch 21, Batch 200] loss: 0.0025911802236214497
[Epoch 21, Batch 300] loss: 0.004486177852268156
[Epoch 21, Batch 400] loss: 0.004855382660207397
[Epoch 21, Batch 500] loss: 0.006399432387679553
[Epoch 21, Batch 600] loss: 0.005865391869992891
[Epoch 21, Batch 700] loss: 0.0036719037155671687
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0528
Validation Accuracy: 0.9869
Overfitting: 0.0522
[Epoch 22, Batch 100] loss: 0.004515312815069592
[Epoch 22, Batch 200] loss: 0.0027500439861159976
[Epoch 22, Batch 300] loss: 0.003307797852958174
[Epoch 22, Batch 400] loss: 0.003133231881547545
[Epoch 22, Batch 500] loss: 0.0017305458139890107
[Epoch 22, Batch 600] loss: 0.009918317031006154
[Epoch 22, Batch 700] loss: 0.002594986110998434
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0523
Validation Accuracy: 0.9882
Overfitting: 0.0521
[Epoch 23, Batch 100] loss: 0.002212303492215142
[Epoch 23, Batch 200] loss: 0.0030428315614881283
[Epoch 23, Batch 300] loss: 0.0024026081403098944
[Epoch 23, Batch 400] loss: 0.0013418093199106806
[Epoch 23, Batch 500] loss: 0.0013221382573010488
[Epoch 23, Batch 600] loss: 0.002297769436181625
[Epoch 23, Batch 700] loss: 0.004398058773376761
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0518
Validation Accuracy: 0.9877
Overfitting: 0.0517
[Epoch 24, Batch 100] loss: 0.0015444654653447288
[Epoch 24, Batch 200] loss: 0.0017278603958402528
[Epoch 24, Batch 300] loss: 0.0010488708050661443
[Epoch 24, Batch 400] loss: 0.0011522224069540244
[Epoch 24, Batch 500] loss: 0.001499089102489961
[Epoch 24, Batch 600] loss: 0.0006788432302255388
[Epoch 24, Batch 700] loss: 0.0011213484838481236
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0494
Validation Accuracy: 0.9878
Overfitting: 0.0493
Fold 4 validation loss: 0.0494
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2431577706336974
[Epoch 1, Batch 200] loss: 0.8222832551598549
[Epoch 1, Batch 300] loss: 0.34485755920410155
[Epoch 1, Batch 400] loss: 0.25939483076334
[Epoch 1, Batch 500] loss: 0.20288716904819012
[Epoch 1, Batch 600] loss: 0.16184579860419035
[Epoch 1, Batch 700] loss: 0.14299133826047183
**STATS for Epoch 1** : 
Average training loss: 0.0103
Average validation loss: 0.1258
Validation Accuracy: 0.9622
Overfitting: 0.1155
Best model saved at epoch 1 with validation loss: 0.1258
[Epoch 2, Batch 100] loss: 0.11673306250944733
[Epoch 2, Batch 200] loss: 0.10013089167885482
[Epoch 2, Batch 300] loss: 0.09672710681334137
[Epoch 2, Batch 400] loss: 0.10591572128236294
[Epoch 2, Batch 500] loss: 0.09359678811393678
[Epoch 2, Batch 600] loss: 0.07737871136516333
[Epoch 2, Batch 700] loss: 0.09037109828554094
**STATS for Epoch 2** : 
Average training loss: 0.0065
Average validation loss: 0.0923
Validation Accuracy: 0.9722
Overfitting: 0.0858
Best model saved at epoch 2 with validation loss: 0.0923
[Epoch 3, Batch 100] loss: 0.07160890657454728
[Epoch 3, Batch 200] loss: 0.07493991542607546
[Epoch 3, Batch 300] loss: 0.07286267889663577
[Epoch 3, Batch 400] loss: 0.06865058278664947
[Epoch 3, Batch 500] loss: 0.05964767988305539
[Epoch 3, Batch 600] loss: 0.06431430955883116
[Epoch 3, Batch 700] loss: 0.06250404924154282
**STATS for Epoch 3** : 
Average training loss: 0.0044
Average validation loss: 0.0626
Validation Accuracy: 0.9821
Overfitting: 0.0582
Best model saved at epoch 3 with validation loss: 0.0626
[Epoch 4, Batch 100] loss: 0.05437196793733165
[Epoch 4, Batch 200] loss: 0.05884807460941374
[Epoch 4, Batch 300] loss: 0.055775006711483
[Epoch 4, Batch 400] loss: 0.04589097091695294
[Epoch 4, Batch 500] loss: 0.04861743655055761
[Epoch 4, Batch 600] loss: 0.0464732096681837
[Epoch 4, Batch 700] loss: 0.049043688115198165
**STATS for Epoch 4** : 
Average training loss: 0.0044
Average validation loss: 0.0531
Validation Accuracy: 0.9848
Overfitting: 0.0487
Best model saved at epoch 4 with validation loss: 0.0531
[Epoch 5, Batch 100] loss: 0.0423439461318776
[Epoch 5, Batch 200] loss: 0.0408977806288749
[Epoch 5, Batch 300] loss: 0.03988085765624419
[Epoch 5, Batch 400] loss: 0.03909312143689021
[Epoch 5, Batch 500] loss: 0.04762625378090888
[Epoch 5, Batch 600] loss: 0.03842304348014295
[Epoch 5, Batch 700] loss: 0.04700995633378625
**STATS for Epoch 5** : 
Average training loss: 0.0033
Average validation loss: 0.0508
Validation Accuracy: 0.9848
Overfitting: 0.0475
Best model saved at epoch 5 with validation loss: 0.0508
[Epoch 6, Batch 100] loss: 0.03777349302312359
[Epoch 6, Batch 200] loss: 0.0338339948002249
[Epoch 6, Batch 300] loss: 0.04031642820220441
[Epoch 6, Batch 400] loss: 0.036809214099776
[Epoch 6, Batch 500] loss: 0.02989188928157091
[Epoch 6, Batch 600] loss: 0.03575593066925649
[Epoch 6, Batch 700] loss: 0.03247294160886668
**STATS for Epoch 6** : 
Average training loss: 0.0031
Average validation loss: 0.0473
Validation Accuracy: 0.9861
Overfitting: 0.0443
Best model saved at epoch 6 with validation loss: 0.0473
[Epoch 7, Batch 100] loss: 0.03014824285171926
[Epoch 7, Batch 200] loss: 0.03341404382372275
[Epoch 7, Batch 300] loss: 0.03173169781221077
[Epoch 7, Batch 400] loss: 0.026158273840555923
[Epoch 7, Batch 500] loss: 0.03387318440363742
[Epoch 7, Batch 600] loss: 0.03125219066161662
[Epoch 7, Batch 700] loss: 0.029671577323751988
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0522
Validation Accuracy: 0.9836
Overfitting: 0.0503
[Epoch 8, Batch 100] loss: 0.02825240283855237
[Epoch 8, Batch 200] loss: 0.02657619878766127
[Epoch 8, Batch 300] loss: 0.026632963813026437
[Epoch 8, Batch 400] loss: 0.028364796072128228
[Epoch 8, Batch 500] loss: 0.02632058234536089
[Epoch 8, Batch 600] loss: 0.02331238382263109
[Epoch 8, Batch 700] loss: 0.02890603743493557
**STATS for Epoch 8** : 
Average training loss: 0.0016
Average validation loss: 0.0493
Validation Accuracy: 0.9860
Overfitting: 0.0477
[Epoch 9, Batch 100] loss: 0.019137103933899197
[Epoch 9, Batch 200] loss: 0.0192188987127156
[Epoch 9, Batch 300] loss: 0.02662345409684349
[Epoch 9, Batch 400] loss: 0.020325103376526387
[Epoch 9, Batch 500] loss: 0.02604388594714692
[Epoch 9, Batch 600] loss: 0.024664692240767182
[Epoch 9, Batch 700] loss: 0.03255397220375016
**STATS for Epoch 9** : 
Average training loss: 0.0015
Average validation loss: 0.0430
Validation Accuracy: 0.9866
Overfitting: 0.0414
Best model saved at epoch 9 with validation loss: 0.0430
[Epoch 10, Batch 100] loss: 0.02103563579497859
[Epoch 10, Batch 200] loss: 0.016847179516917096
[Epoch 10, Batch 300] loss: 0.014699623560882174
[Epoch 10, Batch 400] loss: 0.02138309779111296
[Epoch 10, Batch 500] loss: 0.020350635805516503
[Epoch 10, Batch 600] loss: 0.02183128405129537
[Epoch 10, Batch 700] loss: 0.020375591393676586
**STATS for Epoch 10** : 
Average training loss: 0.0018
Average validation loss: 0.0421
Validation Accuracy: 0.9870
Overfitting: 0.0403
Best model saved at epoch 10 with validation loss: 0.0421
[Epoch 11, Batch 100] loss: 0.015062733650556765
[Epoch 11, Batch 200] loss: 0.01459035407518968
[Epoch 11, Batch 300] loss: 0.016864135794166943
[Epoch 11, Batch 400] loss: 0.017664522029517685
[Epoch 11, Batch 500] loss: 0.01644024753055419
[Epoch 11, Batch 600] loss: 0.02203600434702821
[Epoch 11, Batch 700] loss: 0.015805282547080423
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0442
Validation Accuracy: 0.9874
Overfitting: 0.0430
[Epoch 12, Batch 100] loss: 0.015507896369090304
[Epoch 12, Batch 200] loss: 0.015128456021338934
[Epoch 12, Batch 300] loss: 0.012880957443703664
[Epoch 12, Batch 400] loss: 0.017541542671388015
[Epoch 12, Batch 500] loss: 0.012999297293281415
[Epoch 12, Batch 600] loss: 0.01340044184558792
[Epoch 12, Batch 700] loss: 0.012851520589611027
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0411
Validation Accuracy: 0.9887
Overfitting: 0.0402
Best model saved at epoch 12 with validation loss: 0.0411
[Epoch 13, Batch 100] loss: 0.008826222622737988
[Epoch 13, Batch 200] loss: 0.012607562884804793
[Epoch 13, Batch 300] loss: 0.012070411495806184
[Epoch 13, Batch 400] loss: 0.016036967355175874
[Epoch 13, Batch 500] loss: 0.014909488957127905
[Epoch 13, Batch 600] loss: 0.0182209067203803
[Epoch 13, Batch 700] loss: 0.014457287439727224
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0403
Validation Accuracy: 0.9892
Overfitting: 0.0388
Best model saved at epoch 13 with validation loss: 0.0403
[Epoch 14, Batch 100] loss: 0.01043142026712303
[Epoch 14, Batch 200] loss: 0.00984740484127542
[Epoch 14, Batch 300] loss: 0.007293373672000598
[Epoch 14, Batch 400] loss: 0.009644865931695676
[Epoch 14, Batch 500] loss: 0.016213397144165354
[Epoch 14, Batch 600] loss: 0.015858892924734393
[Epoch 14, Batch 700] loss: 0.010325885045458562
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0418
Validation Accuracy: 0.9894
Overfitting: 0.0409
[Epoch 15, Batch 100] loss: 0.011845216559449909
[Epoch 15, Batch 200] loss: 0.009674148197082105
[Epoch 15, Batch 300] loss: 0.010059058964397991
[Epoch 15, Batch 400] loss: 0.010706056032504421
[Epoch 15, Batch 500] loss: 0.008527159455697984
[Epoch 15, Batch 600] loss: 0.01308513166681223
[Epoch 15, Batch 700] loss: 0.011669197210867423
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0413
Validation Accuracy: 0.9889
Overfitting: 0.0405
[Epoch 16, Batch 100] loss: 0.00664491117131547
[Epoch 16, Batch 200] loss: 0.005065690481133061
[Epoch 16, Batch 300] loss: 0.0070995606266660615
[Epoch 16, Batch 400] loss: 0.005906056132589583
[Epoch 16, Batch 500] loss: 0.010570916208016569
[Epoch 16, Batch 600] loss: 0.011046393628639635
[Epoch 16, Batch 700] loss: 0.0128397090202634
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0405
Validation Accuracy: 0.9896
Overfitting: 0.0395
[Epoch 17, Batch 100] loss: 0.010049777089152485
[Epoch 17, Batch 200] loss: 0.006647051522522815
[Epoch 17, Batch 300] loss: 0.009848364823010342
[Epoch 17, Batch 400] loss: 0.01227531567492406
[Epoch 17, Batch 500] loss: 0.006702378385671182
[Epoch 17, Batch 600] loss: 0.007381944494482013
[Epoch 17, Batch 700] loss: 0.006869186799995077
**STATS for Epoch 17** : 
Average training loss: 0.0002
Average validation loss: 0.0422
Validation Accuracy: 0.9895
Overfitting: 0.0420
[Epoch 18, Batch 100] loss: 0.003987761031094123
[Epoch 18, Batch 200] loss: 0.003862482462754997
[Epoch 18, Batch 300] loss: 0.006792785824436578
[Epoch 18, Batch 400] loss: 0.008569466572080273
[Epoch 18, Batch 500] loss: 0.004773932200914714
[Epoch 18, Batch 600] loss: 0.0058586471703620194
[Epoch 18, Batch 700] loss: 0.007432232296741859
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0478
Validation Accuracy: 0.9889
Overfitting: 0.0475
[Epoch 19, Batch 100] loss: 0.0049972535192137
[Epoch 19, Batch 200] loss: 0.004305190116192534
[Epoch 19, Batch 300] loss: 0.004764897941058734
[Epoch 19, Batch 400] loss: 0.004212640274745354
[Epoch 19, Batch 500] loss: 0.0048355091251141855
[Epoch 19, Batch 600] loss: 0.0033871006275421676
[Epoch 19, Batch 700] loss: 0.0050358304256587876
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0471
Validation Accuracy: 0.9880
Overfitting: 0.0466
[Epoch 20, Batch 100] loss: 0.0028050912119215354
[Epoch 20, Batch 200] loss: 0.002535540408898669
[Epoch 20, Batch 300] loss: 0.0023422124155285926
[Epoch 20, Batch 400] loss: 0.0015022733850491932
[Epoch 20, Batch 500] loss: 0.0038861524851927245
[Epoch 20, Batch 600] loss: 0.006588047658970027
[Epoch 20, Batch 700] loss: 0.004840606488751291
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0428
Validation Accuracy: 0.9898
Overfitting: 0.0425
[Epoch 21, Batch 100] loss: 0.002983444870533276
[Epoch 21, Batch 200] loss: 0.0033946498805198645
[Epoch 21, Batch 300] loss: 0.004667718515975139
[Epoch 21, Batch 400] loss: 0.0030759354327619805
[Epoch 21, Batch 500] loss: 0.004046171931618119
[Epoch 21, Batch 600] loss: 0.00287117111896805
[Epoch 21, Batch 700] loss: 0.0023683450633689065
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0449
Validation Accuracy: 0.9896
Overfitting: 0.0446
[Epoch 22, Batch 100] loss: 0.0015507248880021506
[Epoch 22, Batch 200] loss: 0.0021378706459563544
[Epoch 22, Batch 300] loss: 0.0033320872439890083
[Epoch 22, Batch 400] loss: 0.0019446892282530825
[Epoch 22, Batch 500] loss: 0.0014858205064319917
[Epoch 22, Batch 600] loss: 0.005149184216554659
[Epoch 22, Batch 700] loss: 0.006166292361576779
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0499
Validation Accuracy: 0.9896
Overfitting: 0.0497
[Epoch 23, Batch 100] loss: 0.002148455880351321
[Epoch 23, Batch 200] loss: 0.002195531487623157
[Epoch 23, Batch 300] loss: 0.007573707654178179
[Epoch 23, Batch 400] loss: 0.0014865747147996444
[Epoch 23, Batch 500] loss: 0.003802859330053252
[Epoch 23, Batch 600] loss: 0.00418321796139935
[Epoch 23, Batch 700] loss: 0.0027651767505176396
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0473
Validation Accuracy: 0.9898
Overfitting: 0.0472
[Epoch 24, Batch 100] loss: 0.0015998328975638286
[Epoch 24, Batch 200] loss: 0.0018371253984423674
[Epoch 24, Batch 300] loss: 0.0010055534612092743
[Epoch 24, Batch 400] loss: 0.002967574041001626
[Epoch 24, Batch 500] loss: 0.001662943644414554
[Epoch 24, Batch 600] loss: 0.003704332491515743
[Epoch 24, Batch 700] loss: 0.0033910303542870677
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0495
Validation Accuracy: 0.9894
Overfitting: 0.0491
Fold 5 validation loss: 0.0495
Mean validation loss across all folds for Trial 12 is 0.0517 with trial config:  l1: 256, l2: 128, lr: 0.0038848919298815317, batch_size: 64
[I 2024-12-11 04:45:58,480] Trial 11 finished with value: 0.051728686158145964 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0038848919298815317, 'batch_size': 64}. Best is trial 4 with value: 0.046929042829858846.

Selected Hyperparameters for Trial 13:
  l1: 256, l2: 128, lr: 0.0008723524285259445, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2909708857536315
[Epoch 1, Batch 200] loss: 2.2198500299453734
[Epoch 1, Batch 300] loss: 1.8475951695442199
[Epoch 1, Batch 400] loss: 0.8489648899435998
[Epoch 1, Batch 500] loss: 0.524987142086029
[Epoch 1, Batch 600] loss: 0.4483870904147625
[Epoch 1, Batch 700] loss: 0.37523060843348505
**STATS for Epoch 1** : 
Average training loss: 0.0229
Average validation loss: 0.3025
Validation Accuracy: 0.9124
Overfitting: 0.2795
Best model saved at epoch 1 with validation loss: 0.3025
[Epoch 2, Batch 100] loss: 0.31447454810142517
[Epoch 2, Batch 200] loss: 0.29664711199700833
[Epoch 2, Batch 300] loss: 0.26799736335873603
[Epoch 2, Batch 400] loss: 0.2420442494004965
[Epoch 2, Batch 500] loss: 0.2156532499194145
[Epoch 2, Batch 600] loss: 0.2075210277736187
[Epoch 2, Batch 700] loss: 0.1845456736907363
**STATS for Epoch 2** : 
Average training loss: 0.0125
Average validation loss: 0.1844
Validation Accuracy: 0.9460
Overfitting: 0.1719
Best model saved at epoch 2 with validation loss: 0.1844
[Epoch 3, Batch 100] loss: 0.18533295519649984
[Epoch 3, Batch 200] loss: 0.15730955924838783
[Epoch 3, Batch 300] loss: 0.16114362832158804
[Epoch 3, Batch 400] loss: 0.1540923311561346
[Epoch 3, Batch 500] loss: 0.168817425519228
[Epoch 3, Batch 600] loss: 0.1402230166643858
[Epoch 3, Batch 700] loss: 0.1397414597682655
**STATS for Epoch 3** : 
Average training loss: 0.0097
Average validation loss: 0.1196
Validation Accuracy: 0.9638
Overfitting: 0.1099
Best model saved at epoch 3 with validation loss: 0.1196
[Epoch 4, Batch 100] loss: 0.12329408839344978
[Epoch 4, Batch 200] loss: 0.12656841050833464
[Epoch 4, Batch 300] loss: 0.11238082811236381
[Epoch 4, Batch 400] loss: 0.12569698844105004
[Epoch 4, Batch 500] loss: 0.12743378715589643
[Epoch 4, Batch 600] loss: 0.12674008827656508
[Epoch 4, Batch 700] loss: 0.10531939659267664
**STATS for Epoch 4** : 
Average training loss: 0.0071
Average validation loss: 0.0970
Validation Accuracy: 0.9702
Overfitting: 0.0899
Best model saved at epoch 4 with validation loss: 0.0970
[Epoch 5, Batch 100] loss: 0.10858151094987989
[Epoch 5, Batch 200] loss: 0.10160851325839758
[Epoch 5, Batch 300] loss: 0.08431305284611881
[Epoch 5, Batch 400] loss: 0.11471529115922749
[Epoch 5, Batch 500] loss: 0.11606788867153227
[Epoch 5, Batch 600] loss: 0.09074699437245727
[Epoch 5, Batch 700] loss: 0.09188856028020381
**STATS for Epoch 5** : 
Average training loss: 0.0068
Average validation loss: 0.0938
Validation Accuracy: 0.9711
Overfitting: 0.0870
Best model saved at epoch 5 with validation loss: 0.0938
[Epoch 6, Batch 100] loss: 0.09085670240223408
[Epoch 6, Batch 200] loss: 0.09897190365940332
[Epoch 6, Batch 300] loss: 0.08894004256464541
[Epoch 6, Batch 400] loss: 0.08508497403003275
[Epoch 6, Batch 500] loss: 0.08616241307929158
[Epoch 6, Batch 600] loss: 0.07986717781051994
[Epoch 6, Batch 700] loss: 0.09302996535785496
**STATS for Epoch 6** : 
Average training loss: 0.0049
Average validation loss: 0.0763
Validation Accuracy: 0.9774
Overfitting: 0.0714
[I 2024-12-11 04:46:57,442] Trial 12 pruned. 

Selected Hyperparameters for Trial 14:
  l1: 256, l2: 128, lr: 0.0013627209043248864, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.299074890613556
[Epoch 1, Batch 200] loss: 2.2700263142585753
[Epoch 1, Batch 300] loss: 2.1300006771087645
[Epoch 1, Batch 400] loss: 1.1385279253125191
[Epoch 1, Batch 500] loss: 0.6369796131551265
[Epoch 1, Batch 600] loss: 0.4959780429303646
[Epoch 1, Batch 700] loss: 0.41737724021077155
[Epoch 1, Batch 800] loss: 0.3765182726830244
[Epoch 1, Batch 900] loss: 0.3129736974649131
[Epoch 1, Batch 1000] loss: 0.3004500967077911
[Epoch 1, Batch 1100] loss: 0.24122001096606255
[Epoch 1, Batch 1200] loss: 0.24184193462133408
[Epoch 1, Batch 1300] loss: 0.21056295204907655
[Epoch 1, Batch 1400] loss: 0.2214101266860962
[Epoch 1, Batch 1500] loss: 0.18614429993554948
[Epoch 1, Batch 1600] loss: 0.18866547845304013
[Epoch 1, Batch 1700] loss: 0.18782752620056273
[Epoch 1, Batch 1800] loss: 0.15610372143797577
[Epoch 1, Batch 1900] loss: 0.15428971441462636
[Epoch 1, Batch 2000] loss: 0.1296175025496632
[Epoch 1, Batch 2100] loss: 0.14507895314134658
[Epoch 1, Batch 2200] loss: 0.12713223742553964
[Epoch 1, Batch 2300] loss: 0.15621644369326532
[Epoch 1, Batch 2400] loss: 0.12842669311910868
[Epoch 1, Batch 2500] loss: 0.12759293226990848
[Epoch 1, Batch 2600] loss: 0.1405271067423746
[Epoch 1, Batch 2700] loss: 0.10135097779799253
[Epoch 1, Batch 2800] loss: 0.12981206819415092
[Epoch 1, Batch 2900] loss: 0.11205997170414776
[Epoch 1, Batch 3000] loss: 0.10957605095114559
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0901
Validation Accuracy: 0.9708
Overfitting: 0.0901
Best model saved at epoch 1 with validation loss: 0.0901
[Epoch 2, Batch 100] loss: 0.07547819732571952
[Epoch 2, Batch 200] loss: 0.09628770557930694
[Epoch 2, Batch 300] loss: 0.09750329984701239
[Epoch 2, Batch 400] loss: 0.07319439192535356
[Epoch 2, Batch 500] loss: 0.11054653444793075
[Epoch 2, Batch 600] loss: 0.08592942086281255
[Epoch 2, Batch 700] loss: 0.09661473980871961
[Epoch 2, Batch 800] loss: 0.08944396049831994
[Epoch 2, Batch 900] loss: 0.0879044433729723
[Epoch 2, Batch 1000] loss: 0.10615995847270825
[Epoch 2, Batch 1100] loss: 0.09804914335603826
[Epoch 2, Batch 1200] loss: 0.08374932901817374
[Epoch 2, Batch 1300] loss: 0.07953707425389439
[Epoch 2, Batch 1400] loss: 0.07016208557062782
[Epoch 2, Batch 1500] loss: 0.08563726198626682
[Epoch 2, Batch 1600] loss: 0.07097277916036546
[Epoch 2, Batch 1700] loss: 0.07231339868158101
[Epoch 2, Batch 1800] loss: 0.07735644391796086
[Epoch 2, Batch 1900] loss: 0.06013943098194432
[Epoch 2, Batch 2000] loss: 0.09596533756121062
[Epoch 2, Batch 2100] loss: 0.08530578935635276
[Epoch 2, Batch 2200] loss: 0.07804594863788225
[Epoch 2, Batch 2300] loss: 0.06265708298888058
[Epoch 2, Batch 2400] loss: 0.08994276837562211
[Epoch 2, Batch 2500] loss: 0.08218733108165907
[Epoch 2, Batch 2600] loss: 0.06507556744967587
[Epoch 2, Batch 2700] loss: 0.07459199988283217
[Epoch 2, Batch 2800] loss: 0.0737350205500843
[Epoch 2, Batch 2900] loss: 0.06424365000799298
[Epoch 2, Batch 3000] loss: 0.07072457356320229
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0877
Validation Accuracy: 0.9713
Overfitting: 0.0877
Best model saved at epoch 2 with validation loss: 0.0877
[Epoch 3, Batch 100] loss: 0.06628521762497258
[Epoch 3, Batch 200] loss: 0.057474386224057525
[Epoch 3, Batch 300] loss: 0.04401162026100792
[Epoch 3, Batch 400] loss: 0.05474076633632649
[Epoch 3, Batch 500] loss: 0.07035613645522971
[Epoch 3, Batch 600] loss: 0.06282743347226642
[Epoch 3, Batch 700] loss: 0.06273767911887262
[Epoch 3, Batch 800] loss: 0.05623091401706915
[Epoch 3, Batch 900] loss: 0.05760522122611292
[Epoch 3, Batch 1000] loss: 0.05231785812560702
[Epoch 3, Batch 1100] loss: 0.08222579566863715
[Epoch 3, Batch 1200] loss: 0.06796526794089004
[Epoch 3, Batch 1300] loss: 0.05986949873156846
[Epoch 3, Batch 1400] loss: 0.06080414259922691
[Epoch 3, Batch 1500] loss: 0.06259328623826149
[Epoch 3, Batch 1600] loss: 0.041872052165563216
[Epoch 3, Batch 1700] loss: 0.037237996489857324
[Epoch 3, Batch 1800] loss: 0.0636962792792474
[Epoch 3, Batch 1900] loss: 0.05725348264444619
[Epoch 3, Batch 2000] loss: 0.06718461012642366
[Epoch 3, Batch 2100] loss: 0.042388715734414294
[Epoch 3, Batch 2200] loss: 0.04807649887807201
[Epoch 3, Batch 2300] loss: 0.048520023954915815
[Epoch 3, Batch 2400] loss: 0.060495390350697564
[Epoch 3, Batch 2500] loss: 0.05480086851282977
[Epoch 3, Batch 2600] loss: 0.05813810099614784
[Epoch 3, Batch 2700] loss: 0.054830442169331944
[Epoch 3, Batch 2800] loss: 0.04331206875533098
[Epoch 3, Batch 2900] loss: 0.05350708764017327
[Epoch 3, Batch 3000] loss: 0.05221538966696244
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0600
Validation Accuracy: 0.9808
Overfitting: 0.0600
Best model saved at epoch 3 with validation loss: 0.0600
[Epoch 4, Batch 100] loss: 0.039684364576241936
[Epoch 4, Batch 200] loss: 0.04509381635376485
[Epoch 4, Batch 300] loss: 0.052083135518769266
[Epoch 4, Batch 400] loss: 0.0313630872083013
[Epoch 4, Batch 500] loss: 0.04634994986787205
[Epoch 4, Batch 600] loss: 0.036310873818292747
[Epoch 4, Batch 700] loss: 0.03546780595555901
[Epoch 4, Batch 800] loss: 0.03982304337288951
[Epoch 4, Batch 900] loss: 0.0566600519430358
[Epoch 4, Batch 1000] loss: 0.04474008187520667
[Epoch 4, Batch 1100] loss: 0.038290457665571015
[Epoch 4, Batch 1200] loss: 0.04736678887667949
[Epoch 4, Batch 1300] loss: 0.038658806776511484
[Epoch 4, Batch 1400] loss: 0.04338567756392877
[Epoch 4, Batch 1500] loss: 0.0511520512815332
[Epoch 4, Batch 1600] loss: 0.039446757830446585
[Epoch 4, Batch 1700] loss: 0.05068949977656303
[Epoch 4, Batch 1800] loss: 0.05917557360458886
[Epoch 4, Batch 1900] loss: 0.040750463237345685
[Epoch 4, Batch 2000] loss: 0.06140054913092172
[Epoch 4, Batch 2100] loss: 0.051742283020576
[Epoch 4, Batch 2200] loss: 0.030195588380011032
[Epoch 4, Batch 2300] loss: 0.03961480456608115
[Epoch 4, Batch 2400] loss: 0.049933838910365014
[Epoch 4, Batch 2500] loss: 0.052083756271749736
[Epoch 4, Batch 2600] loss: 0.04821578929637326
[Epoch 4, Batch 2700] loss: 0.04526953548629535
[Epoch 4, Batch 2800] loss: 0.02927603699557949
[Epoch 4, Batch 2900] loss: 0.04289650919672568
[Epoch 4, Batch 3000] loss: 0.05217175323254196
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9841
Overfitting: 0.0506
Best model saved at epoch 4 with validation loss: 0.0506
[Epoch 5, Batch 100] loss: 0.029307224499061705
[Epoch 5, Batch 200] loss: 0.04236529037210857
[Epoch 5, Batch 300] loss: 0.029560082977841375
[Epoch 5, Batch 400] loss: 0.026917588862270348
[Epoch 5, Batch 500] loss: 0.04055367276421748
[Epoch 5, Batch 600] loss: 0.018515950770524797
[Epoch 5, Batch 700] loss: 0.04073957319167675
[Epoch 5, Batch 800] loss: 0.052288222734350714
[Epoch 5, Batch 900] loss: 0.020440457691875052
[Epoch 5, Batch 1000] loss: 0.03626891799853183
[Epoch 5, Batch 1100] loss: 0.0307267851891811
[Epoch 5, Batch 1200] loss: 0.02178185304233921
[Epoch 5, Batch 1300] loss: 0.025399486580317897
[Epoch 5, Batch 1400] loss: 0.04281562160958856
[Epoch 5, Batch 1500] loss: 0.04218715543174767
[Epoch 5, Batch 1600] loss: 0.02976183087877871
[Epoch 5, Batch 1700] loss: 0.04413813006569398
[Epoch 5, Batch 1800] loss: 0.04467368956364225
[Epoch 5, Batch 1900] loss: 0.04311667247719015
[Epoch 5, Batch 2000] loss: 0.03508955419049016
[Epoch 5, Batch 2100] loss: 0.033392724647346765
[Epoch 5, Batch 2200] loss: 0.04065910926685319
[Epoch 5, Batch 2300] loss: 0.032512526429491116
[Epoch 5, Batch 2400] loss: 0.04847072382603074
[Epoch 5, Batch 2500] loss: 0.0465960695699323
[Epoch 5, Batch 2600] loss: 0.043444898402376565
[Epoch 5, Batch 2700] loss: 0.050201995379757135
[Epoch 5, Batch 2800] loss: 0.03966276178805856
[Epoch 5, Batch 2900] loss: 0.03913999770709779
[Epoch 5, Batch 3000] loss: 0.02488945487217279
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0460
Validation Accuracy: 0.9855
Overfitting: 0.0460
Best model saved at epoch 5 with validation loss: 0.0460
[Epoch 6, Batch 100] loss: 0.0340223309196881
[Epoch 6, Batch 200] loss: 0.032902739402779844
[Epoch 6, Batch 300] loss: 0.027895680368674222
[Epoch 6, Batch 400] loss: 0.030493197626929033
[Epoch 6, Batch 500] loss: 0.026733940035919657
[Epoch 6, Batch 600] loss: 0.02936242799143656
[Epoch 6, Batch 700] loss: 0.029547021563303133
[Epoch 6, Batch 800] loss: 0.02257608152103785
[Epoch 6, Batch 900] loss: 0.029708653673042137
[Epoch 6, Batch 1000] loss: 0.025636883668994415
[Epoch 6, Batch 1100] loss: 0.03517074919765946
[Epoch 6, Batch 1200] loss: 0.02571970517594309
[Epoch 6, Batch 1300] loss: 0.033586678164756446
[Epoch 6, Batch 1400] loss: 0.03272793752526923
[Epoch 6, Batch 1500] loss: 0.03341814217659703
[Epoch 6, Batch 1600] loss: 0.039224587795033586
[Epoch 6, Batch 1700] loss: 0.01579690884536831
[Epoch 6, Batch 1800] loss: 0.03248701235264889
[Epoch 6, Batch 1900] loss: 0.018753130471450278
[Epoch 6, Batch 2000] loss: 0.021543285577499773
[Epoch 6, Batch 2100] loss: 0.03097667075431673
[Epoch 6, Batch 2200] loss: 0.027904255706525872
[Epoch 6, Batch 2300] loss: 0.031575921969706544
[Epoch 6, Batch 2400] loss: 0.036488042018099805
[Epoch 6, Batch 2500] loss: 0.02562926927821536
[Epoch 6, Batch 2600] loss: 0.03327770842013706
[Epoch 6, Batch 2700] loss: 0.027939888797409367
[Epoch 6, Batch 2800] loss: 0.022012810233136407
[Epoch 6, Batch 2900] loss: 0.041325374854932304
[Epoch 6, Batch 3000] loss: 0.021058152873374637
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9849
Overfitting: 0.0466
[Epoch 7, Batch 100] loss: 0.026712140524759887
[Epoch 7, Batch 200] loss: 0.022588676070554356
[Epoch 7, Batch 300] loss: 0.029581193495178012
[Epoch 7, Batch 400] loss: 0.026098512317512357
[Epoch 7, Batch 500] loss: 0.01855538294323196
[Epoch 7, Batch 600] loss: 0.01686870358649685
[Epoch 7, Batch 700] loss: 0.02359813380295236
[Epoch 7, Batch 800] loss: 0.03873172998559312
[Epoch 7, Batch 900] loss: 0.01871225832532218
[Epoch 7, Batch 1000] loss: 0.023123865458983345
[Epoch 7, Batch 1100] loss: 0.013491817886060744
[Epoch 7, Batch 1200] loss: 0.025657873403906704
[Epoch 7, Batch 1300] loss: 0.02198948845198174
[Epoch 7, Batch 1400] loss: 0.012800783712009434
[Epoch 7, Batch 1500] loss: 0.020216026447051262
[Epoch 7, Batch 1600] loss: 0.018269452008389635
[Epoch 7, Batch 1700] loss: 0.025410359607840292
[Epoch 7, Batch 1800] loss: 0.02248794943481698
[Epoch 7, Batch 1900] loss: 0.03282474702642503
[Epoch 7, Batch 2000] loss: 0.027457407054935174
[Epoch 7, Batch 2100] loss: 0.017918701940216122
[Epoch 7, Batch 2200] loss: 0.03695594982476905
[Epoch 7, Batch 2300] loss: 0.023087443192453067
[Epoch 7, Batch 2400] loss: 0.03525758856205357
[Epoch 7, Batch 2500] loss: 0.03499076037071063
[Epoch 7, Batch 2600] loss: 0.029709029365221795
[Epoch 7, Batch 2700] loss: 0.01854018202797306
[Epoch 7, Batch 2800] loss: 0.01912841523779207
[Epoch 7, Batch 2900] loss: 0.023952530725982798
[Epoch 7, Batch 3000] loss: 0.023326173680361537
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0415
Validation Accuracy: 0.9879
Overfitting: 0.0415
Best model saved at epoch 7 with validation loss: 0.0415
[Epoch 8, Batch 100] loss: 0.016334587142118835
[Epoch 8, Batch 200] loss: 0.026160818685657432
[Epoch 8, Batch 300] loss: 0.01792156772498856
[Epoch 8, Batch 400] loss: 0.008105747063309536
[Epoch 8, Batch 500] loss: 0.023655979400718934
[Epoch 8, Batch 600] loss: 0.011531274690642022
[Epoch 8, Batch 700] loss: 0.011492708989608217
[Epoch 8, Batch 800] loss: 0.011172266634985136
[Epoch 8, Batch 900] loss: 0.014051892930747273
[Epoch 8, Batch 1000] loss: 0.01890782076989126
[Epoch 8, Batch 1100] loss: 0.02158961034242566
[Epoch 8, Batch 1200] loss: 0.02560327272885843
[Epoch 8, Batch 1300] loss: 0.029944826858009036
[Epoch 8, Batch 1400] loss: 0.02761606207841396
[Epoch 8, Batch 1500] loss: 0.02851201539493559
[Epoch 8, Batch 1600] loss: 0.03582399809762137
[Epoch 8, Batch 1700] loss: 0.023017392659439792
[Epoch 8, Batch 1800] loss: 0.02023488717029977
[Epoch 8, Batch 1900] loss: 0.0271842511797513
[Epoch 8, Batch 2000] loss: 0.02445607164194371
[Epoch 8, Batch 2100] loss: 0.011205096511512238
[Epoch 8, Batch 2200] loss: 0.010911989231008192
[Epoch 8, Batch 2300] loss: 0.014811159893542935
[Epoch 8, Batch 2400] loss: 0.020508851443755704
[Epoch 8, Batch 2500] loss: 0.016560938975962926
[Epoch 8, Batch 2600] loss: 0.023543378672238758
[Epoch 8, Batch 2700] loss: 0.01546761959534706
[Epoch 8, Batch 2800] loss: 0.025412925380587693
[Epoch 8, Batch 2900] loss: 0.02350095198609779
[Epoch 8, Batch 3000] loss: 0.010342841212459462
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0401
Validation Accuracy: 0.9888
Overfitting: 0.0401
Best model saved at epoch 8 with validation loss: 0.0401
[Epoch 9, Batch 100] loss: 0.014203750203541858
[Epoch 9, Batch 200] loss: 0.010478828292834806
[Epoch 9, Batch 300] loss: 0.018457967188778637
[Epoch 9, Batch 400] loss: 0.024727231379838486
[Epoch 9, Batch 500] loss: 0.017976831364612735
[Epoch 9, Batch 600] loss: 0.013436454963084543
[Epoch 9, Batch 700] loss: 0.02246847820235416
[Epoch 9, Batch 800] loss: 0.01490715710537188
[Epoch 9, Batch 900] loss: 0.022296565446586102
[Epoch 9, Batch 1000] loss: 0.011855099002414136
[Epoch 9, Batch 1100] loss: 0.01179566069469729
[Epoch 9, Batch 1200] loss: 0.01266422881068138
[Epoch 9, Batch 1300] loss: 0.016118037726173498
[Epoch 9, Batch 1400] loss: 0.015723526541469256
[Epoch 9, Batch 1500] loss: 0.009985498926653236
[Epoch 9, Batch 1600] loss: 0.017881158830932692
[Epoch 9, Batch 1700] loss: 0.020236521872138837
[Epoch 9, Batch 1800] loss: 0.022786279481892963
[Epoch 9, Batch 1900] loss: 0.017378255637186157
[Epoch 9, Batch 2000] loss: 0.013277102654355985
[Epoch 9, Batch 2100] loss: 0.017652623506755845
[Epoch 9, Batch 2200] loss: 0.029271360941675085
[Epoch 9, Batch 2300] loss: 0.03519017409062144
[Epoch 9, Batch 2400] loss: 0.02807187836842786
[Epoch 9, Batch 2500] loss: 0.019373590373397746
[Epoch 9, Batch 2600] loss: 0.020736256794625662
[Epoch 9, Batch 2700] loss: 0.022180474984597822
[Epoch 9, Batch 2800] loss: 0.011097476895793079
[Epoch 9, Batch 2900] loss: 0.017445202389408224
[Epoch 9, Batch 3000] loss: 0.005915110313981131
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0376
Validation Accuracy: 0.9892
Overfitting: 0.0376
Best model saved at epoch 9 with validation loss: 0.0376
[Epoch 10, Batch 100] loss: 0.008315793184460745
[Epoch 10, Batch 200] loss: 0.009946131357837657
[Epoch 10, Batch 300] loss: 0.010248521034809529
[Epoch 10, Batch 400] loss: 0.009482559900889101
[Epoch 10, Batch 500] loss: 0.006595079552243988
[Epoch 10, Batch 600] loss: 0.009245567913385457
[Epoch 10, Batch 700] loss: 0.010602649026363906
[Epoch 10, Batch 800] loss: 0.007650211625714292
[Epoch 10, Batch 900] loss: 0.012202004042969748
[Epoch 10, Batch 1000] loss: 0.01444156539992946
[Epoch 10, Batch 1100] loss: 0.02118925952903737
[Epoch 10, Batch 1200] loss: 0.01628327509394694
[Epoch 10, Batch 1300] loss: 0.018473933190234673
[Epoch 10, Batch 1400] loss: 0.01827026771930832
[Epoch 10, Batch 1500] loss: 0.016031233029352734
[Epoch 10, Batch 1600] loss: 0.015329664333630717
[Epoch 10, Batch 1700] loss: 0.009883442821228527
[Epoch 10, Batch 1800] loss: 0.018127782408155328
[Epoch 10, Batch 1900] loss: 0.010538634066779195
[Epoch 10, Batch 2000] loss: 0.0106462273555735
[Epoch 10, Batch 2100] loss: 0.020126581723889102
[Epoch 10, Batch 2200] loss: 0.016067629323229086
[Epoch 10, Batch 2300] loss: 0.010123414441877684
[Epoch 10, Batch 2400] loss: 0.0190755929390275
[Epoch 10, Batch 2500] loss: 0.015061924415094836
[Epoch 10, Batch 2600] loss: 0.010796390227624216
[Epoch 10, Batch 2700] loss: 0.009600736034819875
[Epoch 10, Batch 2800] loss: 0.014954634611267465
[Epoch 10, Batch 2900] loss: 0.009216505803360633
[Epoch 10, Batch 3000] loss: 0.00906740020197958
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9889
Overfitting: 0.0422
[Epoch 11, Batch 100] loss: 0.007295254519740411
[Epoch 11, Batch 200] loss: 0.006434861192601602
[Epoch 11, Batch 300] loss: 0.005190830337633088
[Epoch 11, Batch 400] loss: 0.00965825332638815
[Epoch 11, Batch 500] loss: 0.014235956102193087
[Epoch 11, Batch 600] loss: 0.010723122654080725
[Epoch 11, Batch 700] loss: 0.012384691737436242
[Epoch 11, Batch 800] loss: 0.014209946941236921
[Epoch 11, Batch 900] loss: 0.031062191859891754
[Epoch 11, Batch 1000] loss: 0.013302398285650269
[Epoch 11, Batch 1100] loss: 0.008266849336046107
[Epoch 11, Batch 1200] loss: 0.010663324958313751
[Epoch 11, Batch 1300] loss: 0.012006292378537183
[Epoch 11, Batch 1400] loss: 0.011906354401780846
[Epoch 11, Batch 1500] loss: 0.017279139078927985
[Epoch 11, Batch 1600] loss: 0.00469099719667156
[Epoch 11, Batch 1700] loss: 0.010365624846401715
[Epoch 11, Batch 1800] loss: 0.008659877349496128
[Epoch 11, Batch 1900] loss: 0.01244521227162295
[Epoch 11, Batch 2000] loss: 0.017479684643039946
[Epoch 11, Batch 2100] loss: 0.006002057320490622
[Epoch 11, Batch 2200] loss: 0.013225273818256368
[Epoch 11, Batch 2300] loss: 0.005859915102583955
[Epoch 11, Batch 2400] loss: 0.028571260749311024
[Epoch 11, Batch 2500] loss: 0.02224092985224786
[Epoch 11, Batch 2600] loss: 0.018904650326358022
[Epoch 11, Batch 2700] loss: 0.010188669265035059
[Epoch 11, Batch 2800] loss: 0.022394800771694465
[Epoch 11, Batch 2900] loss: 0.009656716037225123
[Epoch 11, Batch 3000] loss: 0.013939934020036161
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9860
Overfitting: 0.0506
[Epoch 12, Batch 100] loss: 0.010960666808523456
[Epoch 12, Batch 200] loss: 0.010253697205989738
[Epoch 12, Batch 300] loss: 0.012317420352619592
[Epoch 12, Batch 400] loss: 0.006343536501771041
[Epoch 12, Batch 500] loss: 0.009378261277370258
[Epoch 12, Batch 600] loss: 0.006551303240830748
[Epoch 12, Batch 700] loss: 0.009221482543655384
[Epoch 12, Batch 800] loss: 0.014472945967619354
[Epoch 12, Batch 900] loss: 0.015410171218361484
[Epoch 12, Batch 1000] loss: 0.006872169603666407
[Epoch 12, Batch 1100] loss: 0.013709674107803948
[Epoch 12, Batch 1200] loss: 0.0044224670762196185
[Epoch 12, Batch 1300] loss: 0.005672915044287947
[Epoch 12, Batch 1400] loss: 0.011666875478517795
[Epoch 12, Batch 1500] loss: 0.012575481171793398
[Epoch 12, Batch 1600] loss: 0.015875073918155066
[Epoch 12, Batch 1700] loss: 0.010726601821244231
[Epoch 12, Batch 1800] loss: 0.008932836116582622
[Epoch 12, Batch 1900] loss: 0.011871886892475914
[Epoch 12, Batch 2000] loss: 0.013534056378048262
[Epoch 12, Batch 2100] loss: 0.012698326316238991
[Epoch 12, Batch 2200] loss: 0.009817400231336251
[Epoch 12, Batch 2300] loss: 0.010651845833905327
[Epoch 12, Batch 2400] loss: 0.007294581461014787
[Epoch 12, Batch 2500] loss: 0.010941438536319766
[Epoch 12, Batch 2600] loss: 0.02178244073615133
[Epoch 12, Batch 2700] loss: 0.018048066070023197
[Epoch 12, Batch 2800] loss: 0.0116040987785982
[Epoch 12, Batch 2900] loss: 0.008541701774306602
[Epoch 12, Batch 3000] loss: 0.0118894155986618
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9862
Overfitting: 0.0531
[Epoch 13, Batch 100] loss: 0.006024567964127528
[Epoch 13, Batch 200] loss: 0.005217260259901196
[Epoch 13, Batch 300] loss: 0.004195494145540124
[Epoch 13, Batch 400] loss: 0.012338972189825199
[Epoch 13, Batch 500] loss: 0.008008158156976607
[Epoch 13, Batch 600] loss: 0.008236597542513664
[Epoch 13, Batch 700] loss: 0.010038166287633885
[Epoch 13, Batch 800] loss: 0.00685576514719287
[Epoch 13, Batch 900] loss: 0.012242117874714041
[Epoch 13, Batch 1000] loss: 0.006778222037535215
[Epoch 13, Batch 1100] loss: 0.005897964959422098
[Epoch 13, Batch 1200] loss: 0.006258820450050564
[Epoch 13, Batch 1300] loss: 0.0067959993766771734
[Epoch 13, Batch 1400] loss: 0.007702130749967182
[Epoch 13, Batch 1500] loss: 0.0043060970517149145
[Epoch 13, Batch 1600] loss: 0.0045218669282849075
[Epoch 13, Batch 1700] loss: 0.0028664462261565405
[Epoch 13, Batch 1800] loss: 0.025820714640972256
[Epoch 13, Batch 1900] loss: 0.0134820624244594
[Epoch 13, Batch 2000] loss: 0.013710425330145881
[Epoch 13, Batch 2100] loss: 0.009683523689527646
[Epoch 13, Batch 2200] loss: 0.005679225115909503
[Epoch 13, Batch 2300] loss: 0.007038618889332611
[Epoch 13, Batch 2400] loss: 0.0043047553732094455
[Epoch 13, Batch 2500] loss: 0.012010942931960927
[Epoch 13, Batch 2600] loss: 0.013056294078510292
[Epoch 13, Batch 2700] loss: 0.010199846052142903
[Epoch 13, Batch 2800] loss: 0.004419794737598295
[Epoch 13, Batch 2900] loss: 0.0034263945120773086
[Epoch 13, Batch 3000] loss: 0.0112537985673373
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0448
Validation Accuracy: 0.9886
Overfitting: 0.0448
[Epoch 14, Batch 100] loss: 0.004323673773204746
[Epoch 14, Batch 200] loss: 0.004802845839965358
[Epoch 14, Batch 300] loss: 0.004567890259733645
[Epoch 14, Batch 400] loss: 0.016881677475269044
[Epoch 14, Batch 500] loss: 0.008452501922216698
[Epoch 14, Batch 600] loss: 0.009610138442292566
[Epoch 14, Batch 700] loss: 0.010539619806736482
[Epoch 14, Batch 800] loss: 0.009235680616712897
[Epoch 14, Batch 900] loss: 0.006406948335241509
[Epoch 14, Batch 1000] loss: 0.015253140723261822
[Epoch 14, Batch 1100] loss: 0.007915173771434638
[Epoch 14, Batch 1200] loss: 0.002833171740379612
[Epoch 14, Batch 1300] loss: 0.007008925009777158
[Epoch 14, Batch 1400] loss: 0.008917408617060118
[Epoch 14, Batch 1500] loss: 0.00884870100356693
[Epoch 14, Batch 1600] loss: 0.012393382467200809
[Epoch 14, Batch 1700] loss: 0.006397545035601979
[Epoch 14, Batch 1800] loss: 0.004347776783783672
[Epoch 14, Batch 1900] loss: 0.012329893600366404
[Epoch 14, Batch 2000] loss: 0.005064559180273136
[Epoch 14, Batch 2100] loss: 0.007638845684781472
[Epoch 14, Batch 2200] loss: 0.0037807237257911196
[Epoch 14, Batch 2300] loss: 0.0069707022805482665
[Epoch 14, Batch 2400] loss: 0.007049444681837258
[Epoch 14, Batch 2500] loss: 0.008058847079970519
[Epoch 14, Batch 2600] loss: 0.008505605564617581
[Epoch 14, Batch 2700] loss: 0.005075599989190778
[Epoch 14, Batch 2800] loss: 0.005372670954720889
[Epoch 14, Batch 2900] loss: 0.004227957434370638
[Epoch 14, Batch 3000] loss: 0.00444505657294826
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9887
Overfitting: 0.0459
[Epoch 15, Batch 100] loss: 0.0020822244900159602
[Epoch 15, Batch 200] loss: 0.0017045047546048408
[Epoch 15, Batch 300] loss: 0.00198246019712542
[Epoch 15, Batch 400] loss: 0.0042838193756225
[Epoch 15, Batch 500] loss: 0.0025293621579709226
[Epoch 15, Batch 600] loss: 0.0031247841650031204
[Epoch 15, Batch 700] loss: 0.003160223534830493
[Epoch 15, Batch 800] loss: 0.005930714595330855
[Epoch 15, Batch 900] loss: 0.006165070056767945
[Epoch 15, Batch 1000] loss: 0.00264237611063578
[Epoch 15, Batch 1100] loss: 0.0026805438932258597
[Epoch 15, Batch 1200] loss: 0.001487146012914309
[Epoch 15, Batch 1300] loss: 0.015262564659572035
[Epoch 15, Batch 1400] loss: 0.0027885529186559665
[Epoch 15, Batch 1500] loss: 0.005846637181302867
[Epoch 15, Batch 1600] loss: 0.00805506146092739
[Epoch 15, Batch 1700] loss: 0.004255159955425825
[Epoch 15, Batch 1800] loss: 0.009024911385482141
[Epoch 15, Batch 1900] loss: 0.011544978453442241
[Epoch 15, Batch 2000] loss: 0.010801750289340361
[Epoch 15, Batch 2100] loss: 0.012620305916766484
[Epoch 15, Batch 2200] loss: 0.009201397984793403
[Epoch 15, Batch 2300] loss: 0.004861400283347166
[Epoch 15, Batch 2400] loss: 0.010975582928000448
[Epoch 15, Batch 2500] loss: 0.011936895370126877
[Epoch 15, Batch 2600] loss: 0.010419219369591701
[Epoch 15, Batch 2700] loss: 0.007496306363115934
[Epoch 15, Batch 2800] loss: 0.005504105406849931
[Epoch 15, Batch 2900] loss: 0.007556082489053324
[Epoch 15, Batch 3000] loss: 0.004241616122422442
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0448
Validation Accuracy: 0.9886
Overfitting: 0.0448
[Epoch 16, Batch 100] loss: 0.0020094052699914755
[Epoch 16, Batch 200] loss: 0.0011959605147501406
[Epoch 16, Batch 300] loss: 0.005037094731239904
[Epoch 16, Batch 400] loss: 0.003691761870737764
[Epoch 16, Batch 500] loss: 0.004030517488925938
[Epoch 16, Batch 600] loss: 0.002307471015385545
[Epoch 16, Batch 700] loss: 0.0036873336612165985
[Epoch 16, Batch 800] loss: 0.011008085416163453
[Epoch 16, Batch 900] loss: 0.004187177797882668
[Epoch 16, Batch 1000] loss: 0.008730655934010656
[Epoch 16, Batch 1100] loss: 0.0019548736905881017
[Epoch 16, Batch 1200] loss: 0.004486928058162221
[Epoch 16, Batch 1300] loss: 0.0046816570790360855
[Epoch 16, Batch 1400] loss: 0.010037677338549997
[Epoch 16, Batch 1500] loss: 0.0038848700760251375
[Epoch 16, Batch 1600] loss: 0.00521196981034052
[Epoch 16, Batch 1700] loss: 0.0012263997149324268
[Epoch 16, Batch 1800] loss: 0.00831102155175074
[Epoch 16, Batch 1900] loss: 0.0025928388265151624
[Epoch 16, Batch 2000] loss: 0.0019779012297638588
[Epoch 16, Batch 2100] loss: 0.006113316799369351
[Epoch 16, Batch 2200] loss: 0.001889514390628264
[Epoch 16, Batch 2300] loss: 0.008172165614009543
[Epoch 16, Batch 2400] loss: 0.0020181277325878
[Epoch 16, Batch 2500] loss: 0.003699781627892662
[Epoch 16, Batch 2600] loss: 0.0020639040876346826
[Epoch 16, Batch 2700] loss: 0.0015527405255335225
[Epoch 16, Batch 2800] loss: 0.0021514453895906628
[Epoch 16, Batch 2900] loss: 0.006153318545259623
[Epoch 16, Batch 3000] loss: 0.004034293550637358
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9895
Overfitting: 0.0466
[Epoch 17, Batch 100] loss: 0.002504078514572825
[Epoch 17, Batch 200] loss: 0.002077710695056396
[Epoch 17, Batch 300] loss: 0.0012912072957544573
[Epoch 17, Batch 400] loss: 0.006108213744318771
[Epoch 17, Batch 500] loss: 0.002404891022454123
[Epoch 17, Batch 600] loss: 0.0011939394764753075
[Epoch 17, Batch 700] loss: 0.003443031985544849
[Epoch 17, Batch 800] loss: 0.005604845676092154
[Epoch 17, Batch 900] loss: 0.0019837175924783423
[Epoch 17, Batch 1000] loss: 0.0042230671105653525
[Epoch 17, Batch 1100] loss: 0.0009657978045606797
[Epoch 17, Batch 1200] loss: 0.0030636699825487314
[Epoch 17, Batch 1300] loss: 0.0017910288251169958
[Epoch 17, Batch 1400] loss: 0.0033251257957169853
[Epoch 17, Batch 1500] loss: 0.003950966831102179
[Epoch 17, Batch 1600] loss: 0.009101385311823832
[Epoch 17, Batch 1700] loss: 0.0033405976268034722
[Epoch 17, Batch 1800] loss: 0.0027227575530298508
[Epoch 17, Batch 1900] loss: 0.0016481530516291797
[Epoch 17, Batch 2000] loss: 0.0075486285996876745
[Epoch 17, Batch 2100] loss: 0.012635683198629408
[Epoch 17, Batch 2200] loss: 0.006687136518014541
[Epoch 17, Batch 2300] loss: 0.005153670533612455
[Epoch 17, Batch 2400] loss: 0.013342301633294227
[Epoch 17, Batch 2500] loss: 0.009059361800131
[Epoch 17, Batch 2600] loss: 0.004089959921584452
[Epoch 17, Batch 2700] loss: 0.008934397570929918
[Epoch 17, Batch 2800] loss: 0.00926034947876019
[Epoch 17, Batch 2900] loss: 0.008011505515914905
[Epoch 17, Batch 3000] loss: 0.006589004622564118
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9878
Overfitting: 0.0485
[Epoch 18, Batch 100] loss: 0.0028467312503232733
[Epoch 18, Batch 200] loss: 0.003571167421683867
[Epoch 18, Batch 300] loss: 0.0014433743573516722
[Epoch 18, Batch 400] loss: 0.0033687304095904123
[Epoch 18, Batch 500] loss: 0.004220250016452383
[Epoch 18, Batch 600] loss: 0.005638533052342964
[Epoch 18, Batch 700] loss: 0.0075691682908674805
[Epoch 18, Batch 800] loss: 0.0030901215119223478
[Epoch 18, Batch 900] loss: 0.006123909521143105
[Epoch 18, Batch 1000] loss: 0.0060942689529463225
[Epoch 18, Batch 1100] loss: 0.014368614725406133
[Epoch 18, Batch 1200] loss: 0.0023900896408997597
[Epoch 18, Batch 1300] loss: 0.00204030862652985
[Epoch 18, Batch 1400] loss: 0.0041929194889367945
[Epoch 18, Batch 1500] loss: 0.005351382273499894
[Epoch 18, Batch 1600] loss: 0.0019760470859706914
[Epoch 18, Batch 1700] loss: 0.0027804036916249685
[Epoch 18, Batch 1800] loss: 0.011372937497842486
[Epoch 18, Batch 1900] loss: 0.002470341065433104
[Epoch 18, Batch 2000] loss: 0.0036436740046312368
[Epoch 18, Batch 2100] loss: 0.0028613594562602886
[Epoch 18, Batch 2200] loss: 0.0035668474969065755
[Epoch 18, Batch 2300] loss: 0.005896454132456625
[Epoch 18, Batch 2400] loss: 0.00503995214812079
[Epoch 18, Batch 2500] loss: 0.010935254300895848
[Epoch 18, Batch 2600] loss: 0.004290973787592804
[Epoch 18, Batch 2700] loss: 0.008776830038920025
[Epoch 18, Batch 2800] loss: 0.010113206538330815
[Epoch 18, Batch 2900] loss: 0.004536269977680831
[Epoch 18, Batch 3000] loss: 0.005271086278020221
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9899
Overfitting: 0.0462
[Epoch 19, Batch 100] loss: 0.001558777052915019
[Epoch 19, Batch 200] loss: 0.0009295866628229988
[Epoch 19, Batch 300] loss: 0.0011794210823529738
[Epoch 19, Batch 400] loss: 0.0010128046060950168
[Epoch 19, Batch 500] loss: 0.0023465716163563856
[Epoch 19, Batch 600] loss: 0.0020148987164916574
[Epoch 19, Batch 700] loss: 0.004496469780305574
[Epoch 19, Batch 800] loss: 0.004263845993868785
[Epoch 19, Batch 900] loss: 0.0016026480750463178
[Epoch 19, Batch 1000] loss: 0.002280266914108324
[Epoch 19, Batch 1100] loss: 0.002756504962479411
[Epoch 19, Batch 1200] loss: 0.0024796557737321832
[Epoch 19, Batch 1300] loss: 0.00521237383749039
[Epoch 19, Batch 1400] loss: 0.0020544043947673175
[Epoch 19, Batch 1500] loss: 0.0044801326710311425
[Epoch 19, Batch 1600] loss: 0.006984575870572485
[Epoch 19, Batch 1700] loss: 0.0017709456373294996
[Epoch 19, Batch 1800] loss: 0.0035445502557185193
[Epoch 19, Batch 1900] loss: 0.008072594428011542
[Epoch 19, Batch 2000] loss: 0.005565784261340241
[Epoch 19, Batch 2100] loss: 0.0021965436360278545
[Epoch 19, Batch 2200] loss: 0.009744699149820235
[Epoch 19, Batch 2300] loss: 0.006274869171085769
[Epoch 19, Batch 2400] loss: 0.008500875733636662
[Epoch 19, Batch 2500] loss: 0.0016415574647669472
[Epoch 19, Batch 2600] loss: 0.0024204158204128136
[Epoch 19, Batch 2700] loss: 0.0012900764658089336
[Epoch 19, Batch 2800] loss: 0.004793264093915752
[Epoch 19, Batch 2900] loss: 0.004681317317531466
[Epoch 19, Batch 3000] loss: 0.0044871070635079495
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9886
Overfitting: 0.0507
[Epoch 20, Batch 100] loss: 0.0025932343707245308
[Epoch 20, Batch 200] loss: 0.0021315370187712547
[Epoch 20, Batch 300] loss: 0.0013116619528522123
[Epoch 20, Batch 400] loss: 0.0036995160270398486
[Epoch 20, Batch 500] loss: 0.00392070193928987
[Epoch 20, Batch 600] loss: 0.006576405446048135
[Epoch 20, Batch 700] loss: 0.004487675214077589
[Epoch 20, Batch 800] loss: 0.006169856747540035
[Epoch 20, Batch 900] loss: 0.00416664950014578
[Epoch 20, Batch 1000] loss: 0.004917908403717987
[Epoch 20, Batch 1100] loss: 0.005056899906218746
[Epoch 20, Batch 1200] loss: 0.0015859162285528328
[Epoch 20, Batch 1300] loss: 0.009867147904766966
[Epoch 20, Batch 1400] loss: 0.004068553375168449
[Epoch 20, Batch 1500] loss: 0.0035313349133936
[Epoch 20, Batch 1600] loss: 0.001426924152228679
[Epoch 20, Batch 1700] loss: 0.0011085357445718813
[Epoch 20, Batch 1800] loss: 0.003430590861458924
[Epoch 20, Batch 1900] loss: 0.0015275848508925095
[Epoch 20, Batch 2000] loss: 0.0014335911536430502
[Epoch 20, Batch 2100] loss: 0.001701389634733914
[Epoch 20, Batch 2200] loss: 0.0019644503134954006
[Epoch 20, Batch 2300] loss: 0.0014594198577700013
[Epoch 20, Batch 2400] loss: 0.007917914655620847
[Epoch 20, Batch 2500] loss: 0.007590369440991793
[Epoch 20, Batch 2600] loss: 0.003523800855180923
[Epoch 20, Batch 2700] loss: 0.0030927830226340804
[Epoch 20, Batch 2800] loss: 0.007289746245503465
[Epoch 20, Batch 2900] loss: 0.0025518262271067727
[Epoch 20, Batch 3000] loss: 0.005379760876130036
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9905
Overfitting: 0.0470
[Epoch 21, Batch 100] loss: 0.0013266684807808637
[Epoch 21, Batch 200] loss: 0.002363226162433971
[Epoch 21, Batch 300] loss: 0.002623632756091894
[Epoch 21, Batch 400] loss: 0.00444356407984003
[Epoch 21, Batch 500] loss: 0.005408833182760286
[Epoch 21, Batch 600] loss: 0.0009708721528424569
[Epoch 21, Batch 700] loss: 0.002162487575050065
[Epoch 21, Batch 800] loss: 0.0016120155088924547
[Epoch 21, Batch 900] loss: 0.0050229616906399596
[Epoch 21, Batch 1000] loss: 0.001437165176184152
[Epoch 21, Batch 1100] loss: 0.006142115819293376
[Epoch 21, Batch 1200] loss: 0.005167398910710368
[Epoch 21, Batch 1300] loss: 0.008184888744075493
[Epoch 21, Batch 1400] loss: 0.0016092231138799206
[Epoch 21, Batch 1500] loss: 0.003065273327898974
[Epoch 21, Batch 1600] loss: 0.0009444127559774484
[Epoch 21, Batch 1700] loss: 0.002446375507183802
[Epoch 21, Batch 1800] loss: 0.0017723163139602605
[Epoch 21, Batch 1900] loss: 0.0024199867923663733
[Epoch 21, Batch 2000] loss: 0.005862431399951511
[Epoch 21, Batch 2100] loss: 0.012014244379073915
[Epoch 21, Batch 2200] loss: 0.0032825976552103508
[Epoch 21, Batch 2300] loss: 0.0014906871590111591
[Epoch 21, Batch 2400] loss: 0.001523397584252244
[Epoch 21, Batch 2500] loss: 0.0032463547008642736
[Epoch 21, Batch 2600] loss: 0.0043916075110034215
[Epoch 21, Batch 2700] loss: 0.004474519198007814
[Epoch 21, Batch 2800] loss: 0.003227223464938902
[Epoch 21, Batch 2900] loss: 0.0035295937315194337
[Epoch 21, Batch 3000] loss: 0.00527338987736071
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9894
Overfitting: 0.0540
[Epoch 22, Batch 100] loss: 0.0010783646135288905
[Epoch 22, Batch 200] loss: 0.0009172174088489982
[Epoch 22, Batch 300] loss: 0.0022770106630993327
[Epoch 22, Batch 400] loss: 0.0011158589225037474
[Epoch 22, Batch 500] loss: 0.0013719347391775382
[Epoch 22, Batch 600] loss: 0.0008676914882929054
[Epoch 22, Batch 700] loss: 0.0028000287449412653
[Epoch 22, Batch 800] loss: 0.0016079902093832654
[Epoch 22, Batch 900] loss: 0.0007653032378642699
[Epoch 22, Batch 1000] loss: 0.0006500582475443828
[Epoch 22, Batch 1100] loss: 0.0025153818748405764
[Epoch 22, Batch 1200] loss: 0.0009231057986316671
[Epoch 22, Batch 1300] loss: 0.0014327837195762072
[Epoch 22, Batch 1400] loss: 0.002778465887636408
[Epoch 22, Batch 1500] loss: 0.002402368138612729
[Epoch 22, Batch 1600] loss: 0.0008488499508927205
[Epoch 22, Batch 1700] loss: 0.0005117203392655334
[Epoch 22, Batch 1800] loss: 0.0009240647071166563
[Epoch 22, Batch 1900] loss: 0.00044727104388938345
[Epoch 22, Batch 2000] loss: 0.002769786139999333
[Epoch 22, Batch 2100] loss: 0.005475302145025491
[Epoch 22, Batch 2200] loss: 0.0016400009154934557
[Epoch 22, Batch 2300] loss: 0.004170406722005491
[Epoch 22, Batch 2400] loss: 0.0015536029139628304
[Epoch 22, Batch 2500] loss: 0.003971882165559606
[Epoch 22, Batch 2600] loss: 0.003340804543848641
[Epoch 22, Batch 2700] loss: 0.003958078601485262
[Epoch 22, Batch 2800] loss: 0.001863830125414836
[Epoch 22, Batch 2900] loss: 0.0008976903049806495
[Epoch 22, Batch 3000] loss: 0.0030259156910375394
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0558
Validation Accuracy: 0.9889
Overfitting: 0.0558
[Epoch 23, Batch 100] loss: 0.0027573666684055807
[Epoch 23, Batch 200] loss: 0.0032931844510752394
[Epoch 23, Batch 300] loss: 0.0015730027052022243
[Epoch 23, Batch 400] loss: 0.0005107900385950259
[Epoch 23, Batch 500] loss: 0.00646256107375816
[Epoch 23, Batch 600] loss: 0.0007914268228071641
[Epoch 23, Batch 700] loss: 0.001189337226304339
[Epoch 23, Batch 800] loss: 0.0007847720501395373
[Epoch 23, Batch 900] loss: 0.0013747599819688983
[Epoch 23, Batch 1000] loss: 0.0006798980996601944
[Epoch 23, Batch 1100] loss: 0.0006654079756021236
[Epoch 23, Batch 1200] loss: 0.001080329950054093
[Epoch 23, Batch 1300] loss: 0.00045998792628155094
[Epoch 23, Batch 1400] loss: 0.00024586112143816676
[Epoch 23, Batch 1500] loss: 0.0008253957863385208
[Epoch 23, Batch 1600] loss: 0.0002778513594074639
[Epoch 23, Batch 1700] loss: 0.0013748549469763916
[Epoch 23, Batch 1800] loss: 0.002494939470570898
[Epoch 23, Batch 1900] loss: 0.001001136761626693
[Epoch 23, Batch 2000] loss: 0.0008220919124825166
[Epoch 23, Batch 2100] loss: 0.0003781770363689807
[Epoch 23, Batch 2200] loss: 0.0005430576090692574
[Epoch 23, Batch 2300] loss: 0.0005617137162599972
[Epoch 23, Batch 2400] loss: 0.0014997916046797543
[Epoch 23, Batch 2500] loss: 0.001948592884849325
[Epoch 23, Batch 2600] loss: 0.005708400802610614
[Epoch 23, Batch 2700] loss: 0.0006900988787248608
[Epoch 23, Batch 2800] loss: 0.0005972500210182785
[Epoch 23, Batch 2900] loss: 0.0023890936273473786
[Epoch 23, Batch 3000] loss: 0.0011523752469461267
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9908
Overfitting: 0.0464
[Epoch 24, Batch 100] loss: 0.0006374310693679774
[Epoch 24, Batch 200] loss: 0.0005021997308631398
[Epoch 24, Batch 300] loss: 0.0006767157250498368
[Epoch 24, Batch 400] loss: 0.0003801174810349961
[Epoch 24, Batch 500] loss: 0.0002797790068082584
[Epoch 24, Batch 600] loss: 0.00036623534382021814
[Epoch 24, Batch 700] loss: 0.003832891986279221
[Epoch 24, Batch 800] loss: 0.00040180452141122205
[Epoch 24, Batch 900] loss: 0.0006201140383149628
[Epoch 24, Batch 1000] loss: 0.00034169624690247866
[Epoch 24, Batch 1100] loss: 0.00028975918510210975
[Epoch 24, Batch 1200] loss: 0.000512700072947272
[Epoch 24, Batch 1300] loss: 0.00015233970091468762
[Epoch 24, Batch 1400] loss: 0.0009460528262642498
[Epoch 24, Batch 1500] loss: 0.0022892313313299796
[Epoch 24, Batch 1600] loss: 0.0003181853325379258
[Epoch 24, Batch 1700] loss: 0.00047497095335959473
[Epoch 24, Batch 1800] loss: 0.00041399878191795915
[Epoch 24, Batch 1900] loss: 0.0003987574270900307
[Epoch 24, Batch 2000] loss: 0.00047280459113427045
[Epoch 24, Batch 2100] loss: 0.0003414502885719806
[Epoch 24, Batch 2200] loss: 0.0005183149176961299
[Epoch 24, Batch 2300] loss: 0.0003782629299713136
[Epoch 24, Batch 2400] loss: 0.00021169374324759183
[Epoch 24, Batch 2500] loss: 0.0007524218106298619
[Epoch 24, Batch 2600] loss: 0.0004024339825796908
[Epoch 24, Batch 2700] loss: 0.0003596259382027878
[Epoch 24, Batch 2800] loss: 0.0003211509015005021
[Epoch 24, Batch 2900] loss: 0.0007161217796213348
[Epoch 24, Batch 3000] loss: 0.00045972148299604497
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9912
Overfitting: 0.0484
Fold 1 validation loss: 0.0484
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.288032076358795
[Epoch 1, Batch 200] loss: 2.1764883625507356
[Epoch 1, Batch 300] loss: 1.3530161434412002
[Epoch 1, Batch 400] loss: 0.696723630130291
[Epoch 1, Batch 500] loss: 0.5644468796998262
[Epoch 1, Batch 600] loss: 0.40331260293722154
[Epoch 1, Batch 700] loss: 0.37663417641073466
[Epoch 1, Batch 800] loss: 0.29150018487125634
[Epoch 1, Batch 900] loss: 0.2977171568199992
[Epoch 1, Batch 1000] loss: 0.28564011812210083
[Epoch 1, Batch 1100] loss: 0.2634995250590146
[Epoch 1, Batch 1200] loss: 0.2528280570358038
[Epoch 1, Batch 1300] loss: 0.1980690362676978
[Epoch 1, Batch 1400] loss: 0.18403351350687444
[Epoch 1, Batch 1500] loss: 0.18754123098915443
[Epoch 1, Batch 1600] loss: 0.19135424332693218
[Epoch 1, Batch 1700] loss: 0.18458572377450763
[Epoch 1, Batch 1800] loss: 0.14825987022835763
[Epoch 1, Batch 1900] loss: 0.16495874367654323
[Epoch 1, Batch 2000] loss: 0.12797466876916588
[Epoch 1, Batch 2100] loss: 0.14170952658634633
[Epoch 1, Batch 2200] loss: 0.12191108450642787
[Epoch 1, Batch 2300] loss: 0.13321956534404308
[Epoch 1, Batch 2400] loss: 0.1239763898588717
[Epoch 1, Batch 2500] loss: 0.10898453983478248
[Epoch 1, Batch 2600] loss: 0.1289790176646784
[Epoch 1, Batch 2700] loss: 0.1409267316153273
[Epoch 1, Batch 2800] loss: 0.09983071909751744
[Epoch 1, Batch 2900] loss: 0.10199664512183518
[Epoch 1, Batch 3000] loss: 0.09925081484834664
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1178
Validation Accuracy: 0.9621
Overfitting: 0.1178
Best model saved at epoch 1 with validation loss: 0.1178
[Epoch 2, Batch 100] loss: 0.10989314808277413
[Epoch 2, Batch 200] loss: 0.09435891995206475
[Epoch 2, Batch 300] loss: 0.09345374215801712
[Epoch 2, Batch 400] loss: 0.10361427519470454
[Epoch 2, Batch 500] loss: 0.10183946713106706
[Epoch 2, Batch 600] loss: 0.09906870134873316
[Epoch 2, Batch 700] loss: 0.08600449565332383
[Epoch 2, Batch 800] loss: 0.09075738697079942
[Epoch 2, Batch 900] loss: 0.09638522234512494
[Epoch 2, Batch 1000] loss: 0.0691049668902997
[Epoch 2, Batch 1100] loss: 0.0987885951861972
[Epoch 2, Batch 1200] loss: 0.080085064569721
[Epoch 2, Batch 1300] loss: 0.06979934052564203
[Epoch 2, Batch 1400] loss: 0.07680874682962895
[Epoch 2, Batch 1500] loss: 0.08268221653881483
[Epoch 2, Batch 1600] loss: 0.07658356480125804
[Epoch 2, Batch 1700] loss: 0.07279043910792098
[Epoch 2, Batch 1800] loss: 0.08690589742385782
[Epoch 2, Batch 1900] loss: 0.0912413327395916
[Epoch 2, Batch 2000] loss: 0.07338895759137813
[Epoch 2, Batch 2100] loss: 0.07842456303304061
[Epoch 2, Batch 2200] loss: 0.0820847898768261
[Epoch 2, Batch 2300] loss: 0.07630016946641263
[Epoch 2, Batch 2400] loss: 0.07155342316487805
[Epoch 2, Batch 2500] loss: 0.07613855316594709
[Epoch 2, Batch 2600] loss: 0.07331993074563797
[Epoch 2, Batch 2700] loss: 0.08644168821454513
[Epoch 2, Batch 2800] loss: 0.07735159752424807
[Epoch 2, Batch 2900] loss: 0.07411886868358124
[Epoch 2, Batch 3000] loss: 0.07066906221210957
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0724
Validation Accuracy: 0.9756
Overfitting: 0.0724
Best model saved at epoch 2 with validation loss: 0.0724
[Epoch 3, Batch 100] loss: 0.06422522388864309
[Epoch 3, Batch 200] loss: 0.03335684088990092
[Epoch 3, Batch 300] loss: 0.04669423416664358
[Epoch 3, Batch 400] loss: 0.05640388043597341
[Epoch 3, Batch 500] loss: 0.06611840560566634
[Epoch 3, Batch 600] loss: 0.06501624069089303
[Epoch 3, Batch 700] loss: 0.06780743170180357
[Epoch 3, Batch 800] loss: 0.043255818363395517
[Epoch 3, Batch 900] loss: 0.0629770505410852
[Epoch 3, Batch 1000] loss: 0.09373395383474417
[Epoch 3, Batch 1100] loss: 0.05484766818291973
[Epoch 3, Batch 1200] loss: 0.06453858599998057
[Epoch 3, Batch 1300] loss: 0.055603555958368814
[Epoch 3, Batch 1400] loss: 0.05586463460873347
[Epoch 3, Batch 1500] loss: 0.05058016596973175
[Epoch 3, Batch 1600] loss: 0.03620580283459276
[Epoch 3, Batch 1700] loss: 0.06939897554460912
[Epoch 3, Batch 1800] loss: 0.06620140402199468
[Epoch 3, Batch 1900] loss: 0.07075689162273192
[Epoch 3, Batch 2000] loss: 0.05078705091960728
[Epoch 3, Batch 2100] loss: 0.054172509433119555
[Epoch 3, Batch 2200] loss: 0.04728533635701751
[Epoch 3, Batch 2300] loss: 0.054440386343630964
[Epoch 3, Batch 2400] loss: 0.050553278333391065
[Epoch 3, Batch 2500] loss: 0.0578817996016005
[Epoch 3, Batch 2600] loss: 0.0627360587628209
[Epoch 3, Batch 2700] loss: 0.06846032994188135
[Epoch 3, Batch 2800] loss: 0.03756112583563663
[Epoch 3, Batch 2900] loss: 0.06321851485321531
[Epoch 3, Batch 3000] loss: 0.06512723605788778
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0633
Validation Accuracy: 0.9803
Overfitting: 0.0633
Best model saved at epoch 3 with validation loss: 0.0633
[Epoch 4, Batch 100] loss: 0.045200703626615
[Epoch 4, Batch 200] loss: 0.029770744199922775
[Epoch 4, Batch 300] loss: 0.03922406886209501
[Epoch 4, Batch 400] loss: 0.04360351373121375
[Epoch 4, Batch 500] loss: 0.035881231103703615
[Epoch 4, Batch 600] loss: 0.046739911340991966
[Epoch 4, Batch 700] loss: 0.03804558897652896
[Epoch 4, Batch 800] loss: 0.05298102330554684
[Epoch 4, Batch 900] loss: 0.03935600309661822
[Epoch 4, Batch 1000] loss: 0.03381628941162489
[Epoch 4, Batch 1100] loss: 0.04830950184565154
[Epoch 4, Batch 1200] loss: 0.05458579061320051
[Epoch 4, Batch 1300] loss: 0.07532233743520919
[Epoch 4, Batch 1400] loss: 0.04341357461293228
[Epoch 4, Batch 1500] loss: 0.028991837390640283
[Epoch 4, Batch 1600] loss: 0.04631117025041021
[Epoch 4, Batch 1700] loss: 0.061988026961917055
[Epoch 4, Batch 1800] loss: 0.03039683953684289
[Epoch 4, Batch 1900] loss: 0.051236060563242064
[Epoch 4, Batch 2000] loss: 0.037522660452814306
[Epoch 4, Batch 2100] loss: 0.05753611193445977
[Epoch 4, Batch 2200] loss: 0.04067433635646012
[Epoch 4, Batch 2300] loss: 0.04380424354341812
[Epoch 4, Batch 2400] loss: 0.04595291370293125
[Epoch 4, Batch 2500] loss: 0.05889587989629945
[Epoch 4, Batch 2600] loss: 0.04058488844675594
[Epoch 4, Batch 2700] loss: 0.043575390930491266
[Epoch 4, Batch 2800] loss: 0.05542327281204052
[Epoch 4, Batch 2900] loss: 0.028908566723766852
[Epoch 4, Batch 3000] loss: 0.03674426526224124
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9818
Overfitting: 0.0564
Best model saved at epoch 4 with validation loss: 0.0564
[Epoch 5, Batch 100] loss: 0.039221883647405774
[Epoch 5, Batch 200] loss: 0.023183096123539144
[Epoch 5, Batch 300] loss: 0.02755512546922546
[Epoch 5, Batch 400] loss: 0.046843861138186185
[Epoch 5, Batch 500] loss: 0.02520566579682054
[Epoch 5, Batch 600] loss: 0.025348940360490815
[Epoch 5, Batch 700] loss: 0.030803518419415924
[Epoch 5, Batch 800] loss: 0.06086801687575644
[Epoch 5, Batch 900] loss: 0.05110147585510276
[Epoch 5, Batch 1000] loss: 0.039915187833685195
[Epoch 5, Batch 1100] loss: 0.03454009930384928
[Epoch 5, Batch 1200] loss: 0.030050145818386227
[Epoch 5, Batch 1300] loss: 0.03213387626412441
[Epoch 5, Batch 1400] loss: 0.0440269035944948
[Epoch 5, Batch 1500] loss: 0.030002229955862277
[Epoch 5, Batch 1600] loss: 0.02860611000331119
[Epoch 5, Batch 1700] loss: 0.03705588831682689
[Epoch 5, Batch 1800] loss: 0.016587022384483133
[Epoch 5, Batch 1900] loss: 0.04228459324824144
[Epoch 5, Batch 2000] loss: 0.0558038474341447
[Epoch 5, Batch 2100] loss: 0.044043499737599634
[Epoch 5, Batch 2200] loss: 0.04127535801315389
[Epoch 5, Batch 2300] loss: 0.0409275712366798
[Epoch 5, Batch 2400] loss: 0.030517236117157155
[Epoch 5, Batch 2500] loss: 0.04128178084472893
[Epoch 5, Batch 2600] loss: 0.03051055090603768
[Epoch 5, Batch 2700] loss: 0.058432142616802595
[Epoch 5, Batch 2800] loss: 0.04326360352599295
[Epoch 5, Batch 2900] loss: 0.024525423608865823
[Epoch 5, Batch 3000] loss: 0.029319491274945902
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0657
Validation Accuracy: 0.9795
Overfitting: 0.0657
[Epoch 6, Batch 100] loss: 0.016561340038315393
[Epoch 6, Batch 200] loss: 0.031036213741535902
[Epoch 6, Batch 300] loss: 0.019168537762052438
[Epoch 6, Batch 400] loss: 0.04274856198899215
[Epoch 6, Batch 500] loss: 0.03289022524801112
[Epoch 6, Batch 600] loss: 0.03580297546723159
[Epoch 6, Batch 700] loss: 0.022395576747003362
[Epoch 6, Batch 800] loss: 0.027497525844810296
[Epoch 6, Batch 900] loss: 0.018236864347272785
[Epoch 6, Batch 1000] loss: 0.032299595995500564
[Epoch 6, Batch 1100] loss: 0.029696379749148037
[Epoch 6, Batch 1200] loss: 0.03383440803940175
[Epoch 6, Batch 1300] loss: 0.019228032259998144
[Epoch 6, Batch 1400] loss: 0.023275480950105704
[Epoch 6, Batch 1500] loss: 0.020839391019471805
[Epoch 6, Batch 1600] loss: 0.026784257196704856
[Epoch 6, Batch 1700] loss: 0.016113878484393353
[Epoch 6, Batch 1800] loss: 0.043332727496890586
[Epoch 6, Batch 1900] loss: 0.022234479256167106
[Epoch 6, Batch 2000] loss: 0.0330758664032328
[Epoch 6, Batch 2100] loss: 0.03531022298513562
[Epoch 6, Batch 2200] loss: 0.02753442569373874
[Epoch 6, Batch 2300] loss: 0.030857018804817928
[Epoch 6, Batch 2400] loss: 0.03351947623319575
[Epoch 6, Batch 2500] loss: 0.043745920268265764
[Epoch 6, Batch 2600] loss: 0.03927449463008088
[Epoch 6, Batch 2700] loss: 0.02226699936989462
[Epoch 6, Batch 2800] loss: 0.03274702116730623
[Epoch 6, Batch 2900] loss: 0.03873893725285597
[Epoch 6, Batch 3000] loss: 0.051200220421233095
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9851
Overfitting: 0.0479
Best model saved at epoch 6 with validation loss: 0.0479
[Epoch 7, Batch 100] loss: 0.027332443154009525
[Epoch 7, Batch 200] loss: 0.025434175786631385
[Epoch 7, Batch 300] loss: 0.0391109309787862
[Epoch 7, Batch 400] loss: 0.028258054130492382
[Epoch 7, Batch 500] loss: 0.026056774495864375
[Epoch 7, Batch 600] loss: 0.017726314964493214
[Epoch 7, Batch 700] loss: 0.013693333500959852
[Epoch 7, Batch 800] loss: 0.014245031104765075
[Epoch 7, Batch 900] loss: 0.03793610524502583
[Epoch 7, Batch 1000] loss: 0.033156258730859915
[Epoch 7, Batch 1100] loss: 0.019201170758897206
[Epoch 7, Batch 1200] loss: 0.016610343770880717
[Epoch 7, Batch 1300] loss: 0.032716225091644444
[Epoch 7, Batch 1400] loss: 0.03354348433400446
[Epoch 7, Batch 1500] loss: 0.0280812171933394
[Epoch 7, Batch 1600] loss: 0.03061774748188327
[Epoch 7, Batch 1700] loss: 0.025088140659208877
[Epoch 7, Batch 1800] loss: 0.02078494194007362
[Epoch 7, Batch 1900] loss: 0.01814666313086491
[Epoch 7, Batch 2000] loss: 0.012787931746588583
[Epoch 7, Batch 2100] loss: 0.02387341460589596
[Epoch 7, Batch 2200] loss: 0.026202682192051727
[Epoch 7, Batch 2300] loss: 0.02559917957209109
[Epoch 7, Batch 2400] loss: 0.024824061406579858
[Epoch 7, Batch 2500] loss: 0.030750995001235425
[Epoch 7, Batch 2600] loss: 0.023064705635733845
[Epoch 7, Batch 2700] loss: 0.028609825425737655
[Epoch 7, Batch 2800] loss: 0.030154824516066582
[Epoch 7, Batch 2900] loss: 0.02475221517466707
[Epoch 7, Batch 3000] loss: 0.02840989048843767
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9872
Overfitting: 0.0465
Best model saved at epoch 7 with validation loss: 0.0465
[Epoch 8, Batch 100] loss: 0.026608334412812837
[Epoch 8, Batch 200] loss: 0.01929909995989874
[Epoch 8, Batch 300] loss: 0.014657115151712787
[Epoch 8, Batch 400] loss: 0.016181807679859047
[Epoch 8, Batch 500] loss: 0.01656929910677718
[Epoch 8, Batch 600] loss: 0.017200440970573255
[Epoch 8, Batch 700] loss: 0.014724138176788984
[Epoch 8, Batch 800] loss: 0.026180544028102305
[Epoch 8, Batch 900] loss: 0.026452351044426906
[Epoch 8, Batch 1000] loss: 0.015785460039551252
[Epoch 8, Batch 1100] loss: 0.018500247543888692
[Epoch 8, Batch 1200] loss: 0.01679388902397477
[Epoch 8, Batch 1300] loss: 0.01753720925055859
[Epoch 8, Batch 1400] loss: 0.01666183872432157
[Epoch 8, Batch 1500] loss: 0.03584901882313716
[Epoch 8, Batch 1600] loss: 0.019358155307691048
[Epoch 8, Batch 1700] loss: 0.01932205558377973
[Epoch 8, Batch 1800] loss: 0.02461894651853072
[Epoch 8, Batch 1900] loss: 0.02805966137046198
[Epoch 8, Batch 2000] loss: 0.022580203332272505
[Epoch 8, Batch 2100] loss: 0.03096457476473006
[Epoch 8, Batch 2200] loss: 0.013316380206924805
[Epoch 8, Batch 2300] loss: 0.017366427148099318
[Epoch 8, Batch 2400] loss: 0.016322901509083748
[Epoch 8, Batch 2500] loss: 0.032187679653452504
[Epoch 8, Batch 2600] loss: 0.01574810353031353
[Epoch 8, Batch 2700] loss: 0.03178693179896072
[Epoch 8, Batch 2800] loss: 0.025440540493509616
[Epoch 8, Batch 2900] loss: 0.01829958984264522
[Epoch 8, Batch 3000] loss: 0.036661323938787974
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9855
Overfitting: 0.0514
[Epoch 9, Batch 100] loss: 0.01427915042204404
[Epoch 9, Batch 200] loss: 0.012417832438150072
[Epoch 9, Batch 300] loss: 0.019393000270774792
[Epoch 9, Batch 400] loss: 0.015475281763756357
[Epoch 9, Batch 500] loss: 0.02198214170664869
[Epoch 9, Batch 600] loss: 0.011968133229493106
[Epoch 9, Batch 700] loss: 0.025566892848037242
[Epoch 9, Batch 800] loss: 0.018162852846580792
[Epoch 9, Batch 900] loss: 0.013917126921132877
[Epoch 9, Batch 1000] loss: 0.010614909484283999
[Epoch 9, Batch 1100] loss: 0.025438273653599026
[Epoch 9, Batch 1200] loss: 0.01991536243178416
[Epoch 9, Batch 1300] loss: 0.007272765960778998
[Epoch 9, Batch 1400] loss: 0.01747784354970463
[Epoch 9, Batch 1500] loss: 0.008921824488479614
[Epoch 9, Batch 1600] loss: 0.022676492293176125
[Epoch 9, Batch 1700] loss: 0.013108256236182569
[Epoch 9, Batch 1800] loss: 0.015010952240741062
[Epoch 9, Batch 1900] loss: 0.014528239812862012
[Epoch 9, Batch 2000] loss: 0.02912516949782912
[Epoch 9, Batch 2100] loss: 0.02870196899810253
[Epoch 9, Batch 2200] loss: 0.014635560009101028
[Epoch 9, Batch 2300] loss: 0.024780068918953475
[Epoch 9, Batch 2400] loss: 0.020360973461974935
[Epoch 9, Batch 2500] loss: 0.016509021334677527
[Epoch 9, Batch 2600] loss: 0.020907139889386597
[Epoch 9, Batch 2700] loss: 0.024772510358307045
[Epoch 9, Batch 2800] loss: 0.021412790396534546
[Epoch 9, Batch 2900] loss: 0.024864585951072514
[Epoch 9, Batch 3000] loss: 0.018972624742345942
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0650
Validation Accuracy: 0.9817
Overfitting: 0.0650
[Epoch 10, Batch 100] loss: 0.02163825321834338
[Epoch 10, Batch 200] loss: 0.01559938160215097
[Epoch 10, Batch 300] loss: 0.017232581917360223
[Epoch 10, Batch 400] loss: 0.009502472403546562
[Epoch 10, Batch 500] loss: 0.01280000106501575
[Epoch 10, Batch 600] loss: 0.02046025549798287
[Epoch 10, Batch 700] loss: 0.01907642780934111
[Epoch 10, Batch 800] loss: 0.013848391667088435
[Epoch 10, Batch 900] loss: 0.012190923960824876
[Epoch 10, Batch 1000] loss: 0.012898742262641462
[Epoch 10, Batch 1100] loss: 0.01333772455404187
[Epoch 10, Batch 1200] loss: 0.019810795019257057
[Epoch 10, Batch 1300] loss: 0.01491778241310385
[Epoch 10, Batch 1400] loss: 0.02612309946869573
[Epoch 10, Batch 1500] loss: 0.013286519710236462
[Epoch 10, Batch 1600] loss: 0.019966400063267428
[Epoch 10, Batch 1700] loss: 0.00664540532364299
[Epoch 10, Batch 1800] loss: 0.016609306815116725
[Epoch 10, Batch 1900] loss: 0.008058106380135542
[Epoch 10, Batch 2000] loss: 0.011930886603363434
[Epoch 10, Batch 2100] loss: 0.03167215287299086
[Epoch 10, Batch 2200] loss: 0.021011981662541077
[Epoch 10, Batch 2300] loss: 0.019964978299522044
[Epoch 10, Batch 2400] loss: 0.01953199049037721
[Epoch 10, Batch 2500] loss: 0.012476043817414392
[Epoch 10, Batch 2600] loss: 0.011567279500686709
[Epoch 10, Batch 2700] loss: 0.011356078414964941
[Epoch 10, Batch 2800] loss: 0.031059697771624997
[Epoch 10, Batch 2900] loss: 0.014131440755554649
[Epoch 10, Batch 3000] loss: 0.011197634381969692
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0568
Validation Accuracy: 0.9840
Overfitting: 0.0568
[Epoch 11, Batch 100] loss: 0.008007735408009467
[Epoch 11, Batch 200] loss: 0.008540662898903975
[Epoch 11, Batch 300] loss: 0.015179158090195415
[Epoch 11, Batch 400] loss: 0.020270550177847325
[Epoch 11, Batch 500] loss: 0.01344937202190522
[Epoch 11, Batch 600] loss: 0.016952648252972723
[Epoch 11, Batch 700] loss: 0.009649337072878551
[Epoch 11, Batch 800] loss: 0.005394516816752457
[Epoch 11, Batch 900] loss: 0.010875402550955187
[Epoch 11, Batch 1000] loss: 0.012988832453629584
[Epoch 11, Batch 1100] loss: 0.009018711642738708
[Epoch 11, Batch 1200] loss: 0.007369722850385187
[Epoch 11, Batch 1300] loss: 0.027527528608884494
[Epoch 11, Batch 1400] loss: 0.023571283447017775
[Epoch 11, Batch 1500] loss: 0.013853691927779436
[Epoch 11, Batch 1600] loss: 0.020619653153726176
[Epoch 11, Batch 1700] loss: 0.011821083344880207
[Epoch 11, Batch 1800] loss: 0.011571839123216705
[Epoch 11, Batch 1900] loss: 0.02024655857214384
[Epoch 11, Batch 2000] loss: 0.008072211346734548
[Epoch 11, Batch 2100] loss: 0.013221845059315456
[Epoch 11, Batch 2200] loss: 0.011578834225783794
[Epoch 11, Batch 2300] loss: 0.009832099176801421
[Epoch 11, Batch 2400] loss: 0.027890595538701747
[Epoch 11, Batch 2500] loss: 0.009811707933022263
[Epoch 11, Batch 2600] loss: 0.00933959462949133
[Epoch 11, Batch 2700] loss: 0.015598547697882168
[Epoch 11, Batch 2800] loss: 0.010605881521960327
[Epoch 11, Batch 2900] loss: 0.00968494140992334
[Epoch 11, Batch 3000] loss: 0.02522920314604562
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9869
Overfitting: 0.0483
[Epoch 12, Batch 100] loss: 0.010168474627657815
[Epoch 12, Batch 200] loss: 0.013773232199221185
[Epoch 12, Batch 300] loss: 0.012983900496874413
[Epoch 12, Batch 400] loss: 0.006409284001611013
[Epoch 12, Batch 500] loss: 0.007619133452139977
[Epoch 12, Batch 600] loss: 0.013268033796839518
[Epoch 12, Batch 700] loss: 0.005693697035271725
[Epoch 12, Batch 800] loss: 0.012339492674104804
[Epoch 12, Batch 900] loss: 0.015898826869633922
[Epoch 12, Batch 1000] loss: 0.009245396070919015
[Epoch 12, Batch 1100] loss: 0.008078004875951592
[Epoch 12, Batch 1200] loss: 0.01304338665835985
[Epoch 12, Batch 1300] loss: 0.007466716298758911
[Epoch 12, Batch 1400] loss: 0.0165363136706128
[Epoch 12, Batch 1500] loss: 0.006939501932647545
[Epoch 12, Batch 1600] loss: 0.010680210923464984
[Epoch 12, Batch 1700] loss: 0.02074830071126712
[Epoch 12, Batch 1800] loss: 0.022625891757670616
[Epoch 12, Batch 1900] loss: 0.00925718763453233
[Epoch 12, Batch 2000] loss: 0.010383594249251473
[Epoch 12, Batch 2100] loss: 0.011512393723978675
[Epoch 12, Batch 2200] loss: 0.01625471266135719
[Epoch 12, Batch 2300] loss: 0.006678451118805242
[Epoch 12, Batch 2400] loss: 0.005477169514556408
[Epoch 12, Batch 2500] loss: 0.011009598878661677
[Epoch 12, Batch 2600] loss: 0.02621574313754536
[Epoch 12, Batch 2700] loss: 0.010918719601431804
[Epoch 12, Batch 2800] loss: 0.017267634064278354
[Epoch 12, Batch 2900] loss: 0.016253222144073334
[Epoch 12, Batch 3000] loss: 0.009128210668991414
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9877
Overfitting: 0.0504
[Epoch 13, Batch 100] loss: 0.009042994263058973
[Epoch 13, Batch 200] loss: 0.012001253854218703
[Epoch 13, Batch 300] loss: 0.0042735412035608536
[Epoch 13, Batch 400] loss: 0.006535733227046876
[Epoch 13, Batch 500] loss: 0.004881225218687177
[Epoch 13, Batch 600] loss: 0.003158354408055857
[Epoch 13, Batch 700] loss: 0.010625423527274051
[Epoch 13, Batch 800] loss: 0.010475014887445297
[Epoch 13, Batch 900] loss: 0.016271559671183697
[Epoch 13, Batch 1000] loss: 0.011021606487652207
[Epoch 13, Batch 1100] loss: 0.011058865816339676
[Epoch 13, Batch 1200] loss: 0.004273187535184206
[Epoch 13, Batch 1300] loss: 0.008651790753569913
[Epoch 13, Batch 1400] loss: 0.012012770994789434
[Epoch 13, Batch 1500] loss: 0.010220712302531182
[Epoch 13, Batch 1600] loss: 0.009704244930999266
[Epoch 13, Batch 1700] loss: 0.007077213047862188
[Epoch 13, Batch 1800] loss: 0.007866630416083922
[Epoch 13, Batch 1900] loss: 0.009286476486581706
[Epoch 13, Batch 2000] loss: 0.0108211679867145
[Epoch 13, Batch 2100] loss: 0.008348039678253372
[Epoch 13, Batch 2200] loss: 0.02700646002373105
[Epoch 13, Batch 2300] loss: 0.012118996993012842
[Epoch 13, Batch 2400] loss: 0.010374554838745099
[Epoch 13, Batch 2500] loss: 0.01338846849866968
[Epoch 13, Batch 2600] loss: 0.011314554635146124
[Epoch 13, Batch 2700] loss: 0.008073410350699533
[Epoch 13, Batch 2800] loss: 0.012291261051271363
[Epoch 13, Batch 2900] loss: 0.013679101762941173
[Epoch 13, Batch 3000] loss: 0.017713392242003464
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9878
Overfitting: 0.0474
[Epoch 14, Batch 100] loss: 0.009579408342247006
[Epoch 14, Batch 200] loss: 0.0207825479732071
[Epoch 14, Batch 300] loss: 0.01210249674601073
[Epoch 14, Batch 400] loss: 0.00806314142539577
[Epoch 14, Batch 500] loss: 0.010963100680019124
[Epoch 14, Batch 600] loss: 0.005761802735851234
[Epoch 14, Batch 700] loss: 0.010900582401691282
[Epoch 14, Batch 800] loss: 0.006375536575287697
[Epoch 14, Batch 900] loss: 0.004986017903397624
[Epoch 14, Batch 1000] loss: 0.0042407858203876
[Epoch 14, Batch 1100] loss: 0.0038008743563835877
[Epoch 14, Batch 1200] loss: 0.004840700877267636
[Epoch 14, Batch 1300] loss: 0.011066869463716102
[Epoch 14, Batch 1400] loss: 0.011038215378514451
[Epoch 14, Batch 1500] loss: 0.009572258404194827
[Epoch 14, Batch 1600] loss: 0.0068394294243444165
[Epoch 14, Batch 1700] loss: 0.014915613988291625
[Epoch 14, Batch 1800] loss: 0.006588898625893762
[Epoch 14, Batch 1900] loss: 0.018617119376604024
[Epoch 14, Batch 2000] loss: 0.009950143194751036
[Epoch 14, Batch 2100] loss: 0.013006900746092924
[Epoch 14, Batch 2200] loss: 0.011482014221742247
[Epoch 14, Batch 2300] loss: 0.008626636755188884
[Epoch 14, Batch 2400] loss: 0.004509741168162691
[Epoch 14, Batch 2500] loss: 0.01211335049815375
[Epoch 14, Batch 2600] loss: 0.005564513947981595
[Epoch 14, Batch 2700] loss: 0.0048663027449947546
[Epoch 14, Batch 2800] loss: 0.00753869803468433
[Epoch 14, Batch 2900] loss: 0.003302238995266862
[Epoch 14, Batch 3000] loss: 0.005790724997528969
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9866
Overfitting: 0.0539
[Epoch 15, Batch 100] loss: 0.004643228280274343
[Epoch 15, Batch 200] loss: 0.003216545401719486
[Epoch 15, Batch 300] loss: 0.0053958603593713406
[Epoch 15, Batch 400] loss: 0.006860976253784372
[Epoch 15, Batch 500] loss: 0.0027745024645417973
[Epoch 15, Batch 600] loss: 0.014255077751967634
[Epoch 15, Batch 700] loss: 0.00909827037264563
[Epoch 15, Batch 800] loss: 0.00582359773330154
[Epoch 15, Batch 900] loss: 0.004123591875735997
[Epoch 15, Batch 1000] loss: 0.00625492748061788
[Epoch 15, Batch 1100] loss: 0.004330357178909594
[Epoch 15, Batch 1200] loss: 0.009234763935819502
[Epoch 15, Batch 1300] loss: 0.008914083388890503
[Epoch 15, Batch 1400] loss: 0.00565958939036932
[Epoch 15, Batch 1500] loss: 0.008012886312154705
[Epoch 15, Batch 1600] loss: 0.01015278191436323
[Epoch 15, Batch 1700] loss: 0.006817982327040681
[Epoch 15, Batch 1800] loss: 0.010958220592156067
[Epoch 15, Batch 1900] loss: 0.01789370268730181
[Epoch 15, Batch 2000] loss: 0.011348719116656412
[Epoch 15, Batch 2100] loss: 0.006238957829825722
[Epoch 15, Batch 2200] loss: 0.013443615117022318
[Epoch 15, Batch 2300] loss: 0.018198011207259696
[Epoch 15, Batch 2400] loss: 0.014694089079288233
[Epoch 15, Batch 2500] loss: 0.008594628614446265
[Epoch 15, Batch 2600] loss: 0.0087549916540911
[Epoch 15, Batch 2700] loss: 0.004280977638888999
[Epoch 15, Batch 2800] loss: 0.006313011719391568
[Epoch 15, Batch 2900] loss: 0.006940036248806791
[Epoch 15, Batch 3000] loss: 0.010273666104862684
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9858
Overfitting: 0.0573
[Epoch 16, Batch 100] loss: 0.003507235302807885
[Epoch 16, Batch 200] loss: 0.01592295305182006
[Epoch 16, Batch 300] loss: 0.0057603540430352495
[Epoch 16, Batch 400] loss: 0.004573231104882325
[Epoch 16, Batch 500] loss: 0.0076778925842722855
[Epoch 16, Batch 600] loss: 0.013486037301977376
[Epoch 16, Batch 700] loss: 0.00811695063094703
[Epoch 16, Batch 800] loss: 0.008430967882932237
[Epoch 16, Batch 900] loss: 0.00929965415912875
[Epoch 16, Batch 1000] loss: 0.006687020400736401
[Epoch 16, Batch 1100] loss: 0.005960214924875799
[Epoch 16, Batch 1200] loss: 0.0069351365866191375
[Epoch 16, Batch 1300] loss: 0.0028741568011150776
[Epoch 16, Batch 1400] loss: 0.002305425963314747
[Epoch 16, Batch 1500] loss: 0.0028243849142654655
[Epoch 16, Batch 1600] loss: 0.00803048171597652
[Epoch 16, Batch 1700] loss: 0.006742941162507066
[Epoch 16, Batch 1800] loss: 0.0074063392649941304
[Epoch 16, Batch 1900] loss: 0.010360644985833006
[Epoch 16, Batch 2000] loss: 0.003943692737561832
[Epoch 16, Batch 2100] loss: 0.011185142342006883
[Epoch 16, Batch 2200] loss: 0.007500238014019942
[Epoch 16, Batch 2300] loss: 0.007560537908093465
[Epoch 16, Batch 2400] loss: 0.009900763365775446
[Epoch 16, Batch 2500] loss: 0.006364109470924291
[Epoch 16, Batch 2600] loss: 0.005853191670291267
[Epoch 16, Batch 2700] loss: 0.007775889018498674
[Epoch 16, Batch 2800] loss: 0.0024735975687644896
[Epoch 16, Batch 2900] loss: 0.0026469899409823938
[Epoch 16, Batch 3000] loss: 0.003700083461144459
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9858
Overfitting: 0.0592
[Epoch 17, Batch 100] loss: 0.0058891862153137705
[Epoch 17, Batch 200] loss: 0.008254938339555906
[Epoch 17, Batch 300] loss: 0.0029885775178570386
[Epoch 17, Batch 400] loss: 0.01543597730212639
[Epoch 17, Batch 500] loss: 0.004043751267618631
[Epoch 17, Batch 600] loss: 0.00550797853275185
[Epoch 17, Batch 700] loss: 0.004534779229069272
[Epoch 17, Batch 800] loss: 0.0049310722747850375
[Epoch 17, Batch 900] loss: 0.005838121704871639
[Epoch 17, Batch 1000] loss: 0.008097541814448732
[Epoch 17, Batch 1100] loss: 0.003441370431161488
[Epoch 17, Batch 1200] loss: 0.0024405688765990873
[Epoch 17, Batch 1300] loss: 0.004462686232526778
[Epoch 17, Batch 1400] loss: 0.005758365581933446
[Epoch 17, Batch 1500] loss: 0.008084059876425157
[Epoch 17, Batch 1600] loss: 0.006668263448004268
[Epoch 17, Batch 1700] loss: 0.008857687379679078
[Epoch 17, Batch 1800] loss: 0.004316410733528073
[Epoch 17, Batch 1900] loss: 0.003060447976279761
[Epoch 17, Batch 2000] loss: 0.00484969573599642
[Epoch 17, Batch 2100] loss: 0.0038015532078838985
[Epoch 17, Batch 2200] loss: 0.0038871758387460887
[Epoch 17, Batch 2300] loss: 0.006688266579164975
[Epoch 17, Batch 2400] loss: 0.004735027638403153
[Epoch 17, Batch 2500] loss: 0.007950877076351616
[Epoch 17, Batch 2600] loss: 0.005707347346104825
[Epoch 17, Batch 2700] loss: 0.0019631277308519656
[Epoch 17, Batch 2800] loss: 0.004892224620073193
[Epoch 17, Batch 2900] loss: 0.0061216179295027475
[Epoch 17, Batch 3000] loss: 0.008155443438679981
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9867
Overfitting: 0.0549
[Epoch 18, Batch 100] loss: 0.005021271538051337
[Epoch 18, Batch 200] loss: 0.0017044376079297762
[Epoch 18, Batch 300] loss: 0.002523681287514137
[Epoch 18, Batch 400] loss: 0.006126411461360703
[Epoch 18, Batch 500] loss: 0.0011764372238701527
[Epoch 18, Batch 600] loss: 0.0020439045331150396
[Epoch 18, Batch 700] loss: 0.001818968391213218
[Epoch 18, Batch 800] loss: 0.0017469356172080098
[Epoch 18, Batch 900] loss: 0.0018951890332118636
[Epoch 18, Batch 1000] loss: 0.0026042585725156186
[Epoch 18, Batch 1100] loss: 0.0018088813913772128
[Epoch 18, Batch 1200] loss: 0.00225061692091856
[Epoch 18, Batch 1300] loss: 0.005571575167075054
[Epoch 18, Batch 1400] loss: 0.004197793427704255
[Epoch 18, Batch 1500] loss: 0.0022426396811192715
[Epoch 18, Batch 1600] loss: 0.0017508266394179372
[Epoch 18, Batch 1700] loss: 0.0010791204884525029
[Epoch 18, Batch 1800] loss: 0.0029859995515863604
[Epoch 18, Batch 1900] loss: 0.003125678802704783
[Epoch 18, Batch 2000] loss: 0.002839297392770277
[Epoch 18, Batch 2100] loss: 0.0020317391165667687
[Epoch 18, Batch 2200] loss: 0.008241982709109124
[Epoch 18, Batch 2300] loss: 0.0013446249259504838
[Epoch 18, Batch 2400] loss: 0.006854867069302344
[Epoch 18, Batch 2500] loss: 0.002219776231327728
[Epoch 18, Batch 2600] loss: 0.0035702111582158126
[Epoch 18, Batch 2700] loss: 0.0019660241189262706
[Epoch 18, Batch 2800] loss: 0.0030384105520501236
[Epoch 18, Batch 2900] loss: 0.0019481905266260924
[Epoch 18, Batch 3000] loss: 0.004606522177505212
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9876
Overfitting: 0.0525
[Epoch 19, Batch 100] loss: 0.0007441669354804504
[Epoch 19, Batch 200] loss: 0.0011566869244967392
[Epoch 19, Batch 300] loss: 0.0007614159247013319
[Epoch 19, Batch 400] loss: 0.0015352609788162397
[Epoch 19, Batch 500] loss: 0.001111481537043204
[Epoch 19, Batch 600] loss: 0.0012637918001581739
[Epoch 19, Batch 700] loss: 0.0008033775879372484
[Epoch 19, Batch 800] loss: 0.0006105169333574167
[Epoch 19, Batch 900] loss: 0.0004896174883120353
[Epoch 19, Batch 1000] loss: 0.0013967791257175578
[Epoch 19, Batch 1100] loss: 0.0014319945228096387
[Epoch 19, Batch 1200] loss: 0.003445216457277276
[Epoch 19, Batch 1300] loss: 0.000744457647318768
[Epoch 19, Batch 1400] loss: 0.0017665112975229036
[Epoch 19, Batch 1500] loss: 0.003045633367503342
[Epoch 19, Batch 1600] loss: 0.002576758542172115
[Epoch 19, Batch 1700] loss: 0.006483968390252243
[Epoch 19, Batch 1800] loss: 0.005556002425982171
[Epoch 19, Batch 1900] loss: 0.006524682381172937
[Epoch 19, Batch 2000] loss: 0.005157997786056257
[Epoch 19, Batch 2100] loss: 0.0025907991852926315
[Epoch 19, Batch 2200] loss: 0.0030319109258465458
[Epoch 19, Batch 2300] loss: 0.004104999923811477
[Epoch 19, Batch 2400] loss: 0.004992210030413773
[Epoch 19, Batch 2500] loss: 0.003853763157547263
[Epoch 19, Batch 2600] loss: 0.003871648936027725
[Epoch 19, Batch 2700] loss: 0.003819945999663332
[Epoch 19, Batch 2800] loss: 0.0044217362255312585
[Epoch 19, Batch 2900] loss: 0.002409749966333834
[Epoch 19, Batch 3000] loss: 0.0038630827701103955
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9863
Overfitting: 0.0619
[Epoch 20, Batch 100] loss: 0.004099892024628389
[Epoch 20, Batch 200] loss: 0.002331636029281299
[Epoch 20, Batch 300] loss: 0.0041249913263899885
[Epoch 20, Batch 400] loss: 0.00563277296413176
[Epoch 20, Batch 500] loss: 0.009789029855176636
[Epoch 20, Batch 600] loss: 0.0016245267038485166
[Epoch 20, Batch 700] loss: 0.010157323065272124
[Epoch 20, Batch 800] loss: 0.013438554484177984
[Epoch 20, Batch 900] loss: 0.00844309797641131
[Epoch 20, Batch 1000] loss: 0.005607606248045443
[Epoch 20, Batch 1100] loss: 0.002668197261312457
[Epoch 20, Batch 1200] loss: 0.003369019477497659
[Epoch 20, Batch 1300] loss: 0.0037997504054817456
[Epoch 20, Batch 1400] loss: 0.0029204360947375106
[Epoch 20, Batch 1500] loss: 0.0034401281369017054
[Epoch 20, Batch 1600] loss: 0.002256070277288975
[Epoch 20, Batch 1700] loss: 0.0011436522813357897
[Epoch 20, Batch 1800] loss: 0.0020543192684385047
[Epoch 20, Batch 1900] loss: 0.0037604178182792224
[Epoch 20, Batch 2000] loss: 0.00473682873378209
[Epoch 20, Batch 2100] loss: 0.00438806221275712
[Epoch 20, Batch 2200] loss: 0.0031016362308028535
[Epoch 20, Batch 2300] loss: 0.004913557238374437
[Epoch 20, Batch 2400] loss: 0.0024527466031777577
[Epoch 20, Batch 2500] loss: 0.003868269074067623
[Epoch 20, Batch 2600] loss: 0.005990692530801507
[Epoch 20, Batch 2700] loss: 0.003684727598260613
[Epoch 20, Batch 2800] loss: 0.003281975230661498
[Epoch 20, Batch 2900] loss: 0.007941782225862327
[Epoch 20, Batch 3000] loss: 0.006786132643508722
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0683
Validation Accuracy: 0.9856
Overfitting: 0.0683
[Epoch 21, Batch 100] loss: 0.002090420961853212
[Epoch 21, Batch 200] loss: 0.001280388648378512
[Epoch 21, Batch 300] loss: 0.0005897374088264229
[Epoch 21, Batch 400] loss: 0.0008650664097729077
[Epoch 21, Batch 500] loss: 0.0009140853865022081
[Epoch 21, Batch 600] loss: 0.0007964654446870156
[Epoch 21, Batch 700] loss: 0.0012964931495899278
[Epoch 21, Batch 800] loss: 0.0007798610127326811
[Epoch 21, Batch 900] loss: 0.004083344528936977
[Epoch 21, Batch 1000] loss: 0.0015092576122583167
[Epoch 21, Batch 1100] loss: 0.004147419547170159
[Epoch 21, Batch 1200] loss: 0.012109171897728217
[Epoch 21, Batch 1300] loss: 0.004744355162100647
[Epoch 21, Batch 1400] loss: 0.00931280839341241
[Epoch 21, Batch 1500] loss: 0.002409892695223306
[Epoch 21, Batch 1600] loss: 0.002278209876566559
[Epoch 21, Batch 1700] loss: 0.0022252681079060112
[Epoch 21, Batch 1800] loss: 0.0033028519497548814
[Epoch 21, Batch 1900] loss: 0.003007612033891287
[Epoch 21, Batch 2000] loss: 0.0020488685049481602
[Epoch 21, Batch 2100] loss: 0.00821085727582073
[Epoch 21, Batch 2200] loss: 0.008294908158356477
[Epoch 21, Batch 2300] loss: 0.0033790499345116133
[Epoch 21, Batch 2400] loss: 0.0022055537671957738
[Epoch 21, Batch 2500] loss: 0.0011464343700352232
[Epoch 21, Batch 2600] loss: 0.0014770636908292545
[Epoch 21, Batch 2700] loss: 0.0015236966487179693
[Epoch 21, Batch 2800] loss: 0.008287655462471122
[Epoch 21, Batch 2900] loss: 0.0032737320702085526
[Epoch 21, Batch 3000] loss: 0.0009835810453642947
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9875
Overfitting: 0.0546
[Epoch 22, Batch 100] loss: 0.0027296389210888974
[Epoch 22, Batch 200] loss: 0.0006874618777230523
[Epoch 22, Batch 300] loss: 0.0009218875906631752
[Epoch 22, Batch 400] loss: 0.0015589591810741465
[Epoch 22, Batch 500] loss: 0.0033666313728279817
[Epoch 22, Batch 600] loss: 0.0035099597906379644
[Epoch 22, Batch 700] loss: 0.0008183758197957757
[Epoch 22, Batch 800] loss: 0.0025451577432821183
[Epoch 22, Batch 900] loss: 0.0032373570381484694
[Epoch 22, Batch 1000] loss: 0.003960044804603271
[Epoch 22, Batch 1100] loss: 0.006713866470834589
[Epoch 22, Batch 1200] loss: 0.002743829999475764
[Epoch 22, Batch 1300] loss: 0.008213190400439031
[Epoch 22, Batch 1400] loss: 0.006527634482360724
[Epoch 22, Batch 1500] loss: 0.0049754848712973395
[Epoch 22, Batch 1600] loss: 0.006520702107099367
[Epoch 22, Batch 1700] loss: 0.0015757493339560824
[Epoch 22, Batch 1800] loss: 0.0015121187301031114
[Epoch 22, Batch 1900] loss: 0.0012655967097282429
[Epoch 22, Batch 2000] loss: 0.003144364672384352
[Epoch 22, Batch 2100] loss: 0.004223289975784326
[Epoch 22, Batch 2200] loss: 0.002316860354385426
[Epoch 22, Batch 2300] loss: 0.0015414209795092315
[Epoch 22, Batch 2400] loss: 0.005699599602768397
[Epoch 22, Batch 2500] loss: 0.0028128448512926953
[Epoch 22, Batch 2600] loss: 0.001225352880832986
[Epoch 22, Batch 2700] loss: 0.005493737104255412
[Epoch 22, Batch 2800] loss: 0.006513791449878852
[Epoch 22, Batch 2900] loss: 0.006580074903978002
[Epoch 22, Batch 3000] loss: 0.002763594201775703
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0650
Validation Accuracy: 0.9852
Overfitting: 0.0650
[Epoch 23, Batch 100] loss: 0.003140588113281524
[Epoch 23, Batch 200] loss: 0.0012180454875024794
[Epoch 23, Batch 300] loss: 0.0029753774971752025
[Epoch 23, Batch 400] loss: 0.0010750800698843932
[Epoch 23, Batch 500] loss: 0.0018702943403781092
[Epoch 23, Batch 600] loss: 0.001564678455141708
[Epoch 23, Batch 700] loss: 0.006050389844184139
[Epoch 23, Batch 800] loss: 0.0017657454248680437
[Epoch 23, Batch 900] loss: 0.002631810329178688
[Epoch 23, Batch 1000] loss: 0.0010624676820224011
[Epoch 23, Batch 1100] loss: 0.00047695975549661096
[Epoch 23, Batch 1200] loss: 0.0007473219418725919
[Epoch 23, Batch 1300] loss: 0.0009526956564172551
[Epoch 23, Batch 1400] loss: 0.0008387158999284594
[Epoch 23, Batch 1500] loss: 0.0009607690697273963
[Epoch 23, Batch 1600] loss: 0.0006101139682684176
[Epoch 23, Batch 1700] loss: 0.0006565572208014458
[Epoch 23, Batch 1800] loss: 0.0007753650724941963
[Epoch 23, Batch 1900] loss: 0.0005295842737485402
[Epoch 23, Batch 2000] loss: 0.001093339889746212
[Epoch 23, Batch 2100] loss: 0.000802057147510169
[Epoch 23, Batch 2200] loss: 0.00040911234509049876
[Epoch 23, Batch 2300] loss: 0.0006123591879448043
[Epoch 23, Batch 2400] loss: 0.000719479133773131
[Epoch 23, Batch 2500] loss: 0.0011543913488021218
[Epoch 23, Batch 2600] loss: 0.0014674540663795455
[Epoch 23, Batch 2700] loss: 0.0004020747505084188
[Epoch 23, Batch 2800] loss: 0.0017374885137408835
[Epoch 23, Batch 2900] loss: 0.002596597622345516
[Epoch 23, Batch 3000] loss: 0.005905739027510713
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0614
Validation Accuracy: 0.9862
Overfitting: 0.0614
[Epoch 24, Batch 100] loss: 0.0009034175846768733
[Epoch 24, Batch 200] loss: 0.000443485644437871
[Epoch 24, Batch 300] loss: 0.00047109623064029994
[Epoch 24, Batch 400] loss: 0.00026938723928687124
[Epoch 24, Batch 500] loss: 0.0002640540878024167
[Epoch 24, Batch 600] loss: 0.0004721891510851073
[Epoch 24, Batch 700] loss: 0.0004578028858607652
[Epoch 24, Batch 800] loss: 0.003984119883333648
[Epoch 24, Batch 900] loss: 0.00066325003830773
[Epoch 24, Batch 1000] loss: 0.0014835619157169155
[Epoch 24, Batch 1100] loss: 0.001397122142832572
[Epoch 24, Batch 1200] loss: 0.0006233172536421705
[Epoch 24, Batch 1300] loss: 0.0015478340303348359
[Epoch 24, Batch 1400] loss: 0.00031075318156684515
[Epoch 24, Batch 1500] loss: 0.00045570248237857046
[Epoch 24, Batch 1600] loss: 0.0013987644317660396
[Epoch 24, Batch 1700] loss: 0.00027708214842306236
[Epoch 24, Batch 1800] loss: 0.0031069437373018173
[Epoch 24, Batch 1900] loss: 0.003148407809011129
[Epoch 24, Batch 2000] loss: 0.004509085579992984
[Epoch 24, Batch 2100] loss: 0.002872020432153852
[Epoch 24, Batch 2200] loss: 0.005187364152876057
[Epoch 24, Batch 2300] loss: 0.0084583784721233
[Epoch 24, Batch 2400] loss: 0.0013590783153408737
[Epoch 24, Batch 2500] loss: 0.0006700826870472554
[Epoch 24, Batch 2600] loss: 0.0010267899138621183
[Epoch 24, Batch 2700] loss: 0.0004482765546039502
[Epoch 24, Batch 2800] loss: 0.0009488594714163412
[Epoch 24, Batch 2900] loss: 0.00039409848768140243
[Epoch 24, Batch 3000] loss: 0.0012157258632753366
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9885
Overfitting: 0.0551
Fold 2 validation loss: 0.0551
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2939936542510986
[Epoch 1, Batch 200] loss: 2.256220505237579
[Epoch 1, Batch 300] loss: 1.9582165920734405
[Epoch 1, Batch 400] loss: 0.8030434727668763
[Epoch 1, Batch 500] loss: 0.5001818132400513
[Epoch 1, Batch 600] loss: 0.4173987430334091
[Epoch 1, Batch 700] loss: 0.3800405614823103
[Epoch 1, Batch 800] loss: 0.3368753596395254
[Epoch 1, Batch 900] loss: 0.2664317212253809
[Epoch 1, Batch 1000] loss: 0.27795695485081523
[Epoch 1, Batch 1100] loss: 0.26137671979144217
[Epoch 1, Batch 1200] loss: 0.23936829637736082
[Epoch 1, Batch 1300] loss: 0.23085485521703958
[Epoch 1, Batch 1400] loss: 0.19752127705141903
[Epoch 1, Batch 1500] loss: 0.1816499228682369
[Epoch 1, Batch 1600] loss: 0.15820693707559258
[Epoch 1, Batch 1700] loss: 0.1515579369245097
[Epoch 1, Batch 1800] loss: 0.17767694899812342
[Epoch 1, Batch 1900] loss: 0.1327827667631209
[Epoch 1, Batch 2000] loss: 0.15328565632458777
[Epoch 1, Batch 2100] loss: 0.13863219188991935
[Epoch 1, Batch 2200] loss: 0.12904983082786203
[Epoch 1, Batch 2300] loss: 0.14074835310224443
[Epoch 1, Batch 2400] loss: 0.14636505789589138
[Epoch 1, Batch 2500] loss: 0.13468432115390896
[Epoch 1, Batch 2600] loss: 0.13580581130459904
[Epoch 1, Batch 2700] loss: 0.11461414247751237
[Epoch 1, Batch 2800] loss: 0.11168200804502704
[Epoch 1, Batch 2900] loss: 0.11355252352543176
[Epoch 1, Batch 3000] loss: 0.09697553325910122
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1163
Validation Accuracy: 0.9637
Overfitting: 0.1163
Best model saved at epoch 1 with validation loss: 0.1163
[Epoch 2, Batch 100] loss: 0.12168639931362123
[Epoch 2, Batch 200] loss: 0.10381156347459182
[Epoch 2, Batch 300] loss: 0.0842488748440519
[Epoch 2, Batch 400] loss: 0.10251386488671414
[Epoch 2, Batch 500] loss: 0.08385996839380823
[Epoch 2, Batch 600] loss: 0.07290028742514551
[Epoch 2, Batch 700] loss: 0.1211597051168792
[Epoch 2, Batch 800] loss: 0.09465528919827193
[Epoch 2, Batch 900] loss: 0.10019807496690192
[Epoch 2, Batch 1000] loss: 0.11000225836411119
[Epoch 2, Batch 1100] loss: 0.08217935136519372
[Epoch 2, Batch 1200] loss: 0.0947532254573889
[Epoch 2, Batch 1300] loss: 0.09059070455667097
[Epoch 2, Batch 1400] loss: 0.06683754960075021
[Epoch 2, Batch 1500] loss: 0.08165558146894909
[Epoch 2, Batch 1600] loss: 0.10122661146393512
[Epoch 2, Batch 1700] loss: 0.08331280682759826
[Epoch 2, Batch 1800] loss: 0.09093305427930318
[Epoch 2, Batch 1900] loss: 0.0768926499132067
[Epoch 2, Batch 2000] loss: 0.06494596120319329
[Epoch 2, Batch 2100] loss: 0.06296130601811456
[Epoch 2, Batch 2200] loss: 0.07732329766091425
[Epoch 2, Batch 2300] loss: 0.08898927353904583
[Epoch 2, Batch 2400] loss: 0.07945886332541705
[Epoch 2, Batch 2500] loss: 0.08652822084957734
[Epoch 2, Batch 2600] loss: 0.07941221162560395
[Epoch 2, Batch 2700] loss: 0.05968124539009295
[Epoch 2, Batch 2800] loss: 0.08509114538494032
[Epoch 2, Batch 2900] loss: 0.08042988454690203
[Epoch 2, Batch 3000] loss: 0.07840448960312642
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0741
Validation Accuracy: 0.9764
Overfitting: 0.0741
Best model saved at epoch 2 with validation loss: 0.0741
[Epoch 3, Batch 100] loss: 0.07113523471343797
[Epoch 3, Batch 200] loss: 0.07569977342849597
[Epoch 3, Batch 300] loss: 0.06263971953419968
[Epoch 3, Batch 400] loss: 0.07889331299811601
[Epoch 3, Batch 500] loss: 0.07674551658565179
[Epoch 3, Batch 600] loss: 0.07244861605111509
[Epoch 3, Batch 700] loss: 0.06294526495184982
[Epoch 3, Batch 800] loss: 0.06552063961920794
[Epoch 3, Batch 900] loss: 0.04461079699278343
[Epoch 3, Batch 1000] loss: 0.05802725950605236
[Epoch 3, Batch 1100] loss: 0.06660432754899376
[Epoch 3, Batch 1200] loss: 0.05533598230802454
[Epoch 3, Batch 1300] loss: 0.06598650164232822
[Epoch 3, Batch 1400] loss: 0.0454035148920957
[Epoch 3, Batch 1500] loss: 0.060875333524891176
[Epoch 3, Batch 1600] loss: 0.05987630933115724
[Epoch 3, Batch 1700] loss: 0.039207040252658774
[Epoch 3, Batch 1800] loss: 0.05655328551045386
[Epoch 3, Batch 1900] loss: 0.0655266360254609
[Epoch 3, Batch 2000] loss: 0.06194676151731983
[Epoch 3, Batch 2100] loss: 0.05313204963153112
[Epoch 3, Batch 2200] loss: 0.06576706022431608
[Epoch 3, Batch 2300] loss: 0.047478078963467854
[Epoch 3, Batch 2400] loss: 0.05289678085769992
[Epoch 3, Batch 2500] loss: 0.08534969569707755
[Epoch 3, Batch 2600] loss: 0.045664545152103525
[Epoch 3, Batch 2700] loss: 0.050097993937233694
[Epoch 3, Batch 2800] loss: 0.04505992100661388
[Epoch 3, Batch 2900] loss: 0.057970653356751424
[Epoch 3, Batch 3000] loss: 0.06685904489597305
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9808
Overfitting: 0.0619
Best model saved at epoch 3 with validation loss: 0.0619
[Epoch 4, Batch 100] loss: 0.050457953999284655
[Epoch 4, Batch 200] loss: 0.02835673698282335
[Epoch 4, Batch 300] loss: 0.051743836174136956
[Epoch 4, Batch 400] loss: 0.03459448625464574
[Epoch 4, Batch 500] loss: 0.051098928425635674
[Epoch 4, Batch 600] loss: 0.04627022347820457
[Epoch 4, Batch 700] loss: 0.05712978048861259
[Epoch 4, Batch 800] loss: 0.04173543711396633
[Epoch 4, Batch 900] loss: 0.03974946572590852
[Epoch 4, Batch 1000] loss: 0.05873336832621135
[Epoch 4, Batch 1100] loss: 0.050105461066486896
[Epoch 4, Batch 1200] loss: 0.05602135988068767
[Epoch 4, Batch 1300] loss: 0.047919497090624645
[Epoch 4, Batch 1400] loss: 0.037978484935010784
[Epoch 4, Batch 1500] loss: 0.05510821357922396
[Epoch 4, Batch 1600] loss: 0.0369991623252281
[Epoch 4, Batch 1700] loss: 0.05927764387248317
[Epoch 4, Batch 1800] loss: 0.05350469914556015
[Epoch 4, Batch 1900] loss: 0.05304455977442558
[Epoch 4, Batch 2000] loss: 0.03666338772367453
[Epoch 4, Batch 2100] loss: 0.05608171908359509
[Epoch 4, Batch 2200] loss: 0.04965986816940131
[Epoch 4, Batch 2300] loss: 0.03351104434608715
[Epoch 4, Batch 2400] loss: 0.05015957760770107
[Epoch 4, Batch 2500] loss: 0.04758231469721068
[Epoch 4, Batch 2600] loss: 0.03332903331349371
[Epoch 4, Batch 2700] loss: 0.04390161666262429
[Epoch 4, Batch 2800] loss: 0.038668195850332265
[Epoch 4, Batch 2900] loss: 0.047310981822956816
[Epoch 4, Batch 3000] loss: 0.03120432745286962
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9841
Overfitting: 0.0533
Best model saved at epoch 4 with validation loss: 0.0533
[Epoch 5, Batch 100] loss: 0.0421658168794238
[Epoch 5, Batch 200] loss: 0.04325094378611539
[Epoch 5, Batch 300] loss: 0.04243617393600289
[Epoch 5, Batch 400] loss: 0.01512065677852661
[Epoch 5, Batch 500] loss: 0.03505001481413274
[Epoch 5, Batch 600] loss: 0.02398112284281524
[Epoch 5, Batch 700] loss: 0.032587383517966376
[Epoch 5, Batch 800] loss: 0.03143913336476544
[Epoch 5, Batch 900] loss: 0.048702705669275016
[Epoch 5, Batch 1000] loss: 0.04077592179339263
[Epoch 5, Batch 1100] loss: 0.038568719436298124
[Epoch 5, Batch 1200] loss: 0.03727307723966078
[Epoch 5, Batch 1300] loss: 0.027026072782318805
[Epoch 5, Batch 1400] loss: 0.03205010217079689
[Epoch 5, Batch 1500] loss: 0.04987669772905065
[Epoch 5, Batch 1600] loss: 0.03148514185362728
[Epoch 5, Batch 1700] loss: 0.04646102721380885
[Epoch 5, Batch 1800] loss: 0.04957904199458426
[Epoch 5, Batch 1900] loss: 0.02543179880012758
[Epoch 5, Batch 2000] loss: 0.028563375974044902
[Epoch 5, Batch 2100] loss: 0.05772611351436353
[Epoch 5, Batch 2200] loss: 0.04508610498014605
[Epoch 5, Batch 2300] loss: 0.05714866742782761
[Epoch 5, Batch 2400] loss: 0.055578111959039236
[Epoch 5, Batch 2500] loss: 0.032957720622071064
[Epoch 5, Batch 2600] loss: 0.03977389656036394
[Epoch 5, Batch 2700] loss: 0.03167467832317925
[Epoch 5, Batch 2800] loss: 0.04018875061083236
[Epoch 5, Batch 2900] loss: 0.04273930978146381
[Epoch 5, Batch 3000] loss: 0.02952810799673898
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0582
Validation Accuracy: 0.9820
Overfitting: 0.0582
[Epoch 6, Batch 100] loss: 0.03015125744146644
[Epoch 6, Batch 200] loss: 0.041861952136241595
[Epoch 6, Batch 300] loss: 0.03824115277602687
[Epoch 6, Batch 400] loss: 0.03261262514482951
[Epoch 6, Batch 500] loss: 0.026336921477413854
[Epoch 6, Batch 600] loss: 0.035747059785207966
[Epoch 6, Batch 700] loss: 0.033306685009010836
[Epoch 6, Batch 800] loss: 0.05314054030837724
[Epoch 6, Batch 900] loss: 0.03647867144340125
[Epoch 6, Batch 1000] loss: 0.029998087160201976
[Epoch 6, Batch 1100] loss: 0.02861462107131956
[Epoch 6, Batch 1200] loss: 0.019427828995612798
[Epoch 6, Batch 1300] loss: 0.03205778831135831
[Epoch 6, Batch 1400] loss: 0.032714724862817096
[Epoch 6, Batch 1500] loss: 0.018754424946819198
[Epoch 6, Batch 1600] loss: 0.037254798905087226
[Epoch 6, Batch 1700] loss: 0.017851611537116695
[Epoch 6, Batch 1800] loss: 0.035337989258405283
[Epoch 6, Batch 1900] loss: 0.029875482080969958
[Epoch 6, Batch 2000] loss: 0.04044752084446372
[Epoch 6, Batch 2100] loss: 0.028674792736128437
[Epoch 6, Batch 2200] loss: 0.0151018819368619
[Epoch 6, Batch 2300] loss: 0.02570395933224063
[Epoch 6, Batch 2400] loss: 0.04020697190935607
[Epoch 6, Batch 2500] loss: 0.02314426508046381
[Epoch 6, Batch 2600] loss: 0.030186325174108786
[Epoch 6, Batch 2700] loss: 0.03984038582962967
[Epoch 6, Batch 2800] loss: 0.03822231488476973
[Epoch 6, Batch 2900] loss: 0.018461552963926806
[Epoch 6, Batch 3000] loss: 0.034326909424344194
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9846
Overfitting: 0.0515
Best model saved at epoch 6 with validation loss: 0.0515
[Epoch 7, Batch 100] loss: 0.02653037930955179
[Epoch 7, Batch 200] loss: 0.025117896821757312
[Epoch 7, Batch 300] loss: 0.015163124118043925
[Epoch 7, Batch 400] loss: 0.03612181087315548
[Epoch 7, Batch 500] loss: 0.014288215735577979
[Epoch 7, Batch 600] loss: 0.019078156265859434
[Epoch 7, Batch 700] loss: 0.019747289658662338
[Epoch 7, Batch 800] loss: 0.016582954621972023
[Epoch 7, Batch 900] loss: 0.015343873845527014
[Epoch 7, Batch 1000] loss: 0.02382263878607773
[Epoch 7, Batch 1100] loss: 0.0373672075302602
[Epoch 7, Batch 1200] loss: 0.03860209301325085
[Epoch 7, Batch 1300] loss: 0.039043230610477625
[Epoch 7, Batch 1400] loss: 0.02714606625493616
[Epoch 7, Batch 1500] loss: 0.02696471598090284
[Epoch 7, Batch 1600] loss: 0.030925436105026165
[Epoch 7, Batch 1700] loss: 0.030389474799885647
[Epoch 7, Batch 1800] loss: 0.020474891992616904
[Epoch 7, Batch 1900] loss: 0.03485986102161405
[Epoch 7, Batch 2000] loss: 0.022279451201247868
[Epoch 7, Batch 2100] loss: 0.028629366194654723
[Epoch 7, Batch 2200] loss: 0.020647579177311855
[Epoch 7, Batch 2300] loss: 0.03999366033618571
[Epoch 7, Batch 2400] loss: 0.022044775219183067
[Epoch 7, Batch 2500] loss: 0.039993722328108564
[Epoch 7, Batch 2600] loss: 0.028856914479038095
[Epoch 7, Batch 2700] loss: 0.028788052564596
[Epoch 7, Batch 2800] loss: 0.02320218086395471
[Epoch 7, Batch 2900] loss: 0.01974443030794646
[Epoch 7, Batch 3000] loss: 0.017298499520220504
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9853
Overfitting: 0.0479
Best model saved at epoch 7 with validation loss: 0.0479
[Epoch 8, Batch 100] loss: 0.01977921313544357
[Epoch 8, Batch 200] loss: 0.01605569830393506
[Epoch 8, Batch 300] loss: 0.01724749889006489
[Epoch 8, Batch 400] loss: 0.03380089081274491
[Epoch 8, Batch 500] loss: 0.02592227415279922
[Epoch 8, Batch 600] loss: 0.017507692094204684
[Epoch 8, Batch 700] loss: 0.018065304867268425
[Epoch 8, Batch 800] loss: 0.013942969929557876
[Epoch 8, Batch 900] loss: 0.026937755293256486
[Epoch 8, Batch 1000] loss: 0.02227034409714179
[Epoch 8, Batch 1100] loss: 0.016661813332848396
[Epoch 8, Batch 1200] loss: 0.019407565407273068
[Epoch 8, Batch 1300] loss: 0.01783755202885004
[Epoch 8, Batch 1400] loss: 0.024727059508441018
[Epoch 8, Batch 1500] loss: 0.02142135804584541
[Epoch 8, Batch 1600] loss: 0.024100415230859654
[Epoch 8, Batch 1700] loss: 0.026859119339969765
[Epoch 8, Batch 1800] loss: 0.03119768592856417
[Epoch 8, Batch 1900] loss: 0.018366782262964988
[Epoch 8, Batch 2000] loss: 0.021916975160711446
[Epoch 8, Batch 2100] loss: 0.015887557430105517
[Epoch 8, Batch 2200] loss: 0.01724555255679661
[Epoch 8, Batch 2300] loss: 0.022781159242949798
[Epoch 8, Batch 2400] loss: 0.024105856460519135
[Epoch 8, Batch 2500] loss: 0.02152356245973351
[Epoch 8, Batch 2600] loss: 0.031037120864457392
[Epoch 8, Batch 2700] loss: 0.029045025579962386
[Epoch 8, Batch 2800] loss: 0.0158601607264427
[Epoch 8, Batch 2900] loss: 0.03000591029633142
[Epoch 8, Batch 3000] loss: 0.01133500039755745
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9842
Overfitting: 0.0546
[Epoch 9, Batch 100] loss: 0.0160519690786532
[Epoch 9, Batch 200] loss: 0.015438629542868511
[Epoch 9, Batch 300] loss: 0.015267481837217928
[Epoch 9, Batch 400] loss: 0.023398478338021958
[Epoch 9, Batch 500] loss: 0.012411860514603176
[Epoch 9, Batch 600] loss: 0.017635161336684177
[Epoch 9, Batch 700] loss: 0.015730882991610996
[Epoch 9, Batch 800] loss: 0.011640331030052948
[Epoch 9, Batch 900] loss: 0.026116890402809078
[Epoch 9, Batch 1000] loss: 0.019982949211371306
[Epoch 9, Batch 1100] loss: 0.01953247937764445
[Epoch 9, Batch 1200] loss: 0.017880041012758738
[Epoch 9, Batch 1300] loss: 0.025636796589060394
[Epoch 9, Batch 1400] loss: 0.03383723060760531
[Epoch 9, Batch 1500] loss: 0.018868888658780635
[Epoch 9, Batch 1600] loss: 0.015281599215895766
[Epoch 9, Batch 1700] loss: 0.018818750649297725
[Epoch 9, Batch 1800] loss: 0.010205140217185544
[Epoch 9, Batch 1900] loss: 0.009499019236900495
[Epoch 9, Batch 2000] loss: 0.019988926177361463
[Epoch 9, Batch 2100] loss: 0.02174897491795491
[Epoch 9, Batch 2200] loss: 0.01516258275250948
[Epoch 9, Batch 2300] loss: 0.010828492323980754
[Epoch 9, Batch 2400] loss: 0.015355065224939608
[Epoch 9, Batch 2500] loss: 0.020643936264386865
[Epoch 9, Batch 2600] loss: 0.02209566521443776
[Epoch 9, Batch 2700] loss: 0.020159625853493707
[Epoch 9, Batch 2800] loss: 0.027349670474222876
[Epoch 9, Batch 2900] loss: 0.025104080345481634
[Epoch 9, Batch 3000] loss: 0.018990950022271136
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9872
Overfitting: 0.0474
Best model saved at epoch 9 with validation loss: 0.0474
[Epoch 10, Batch 100] loss: 0.013625849849631777
[Epoch 10, Batch 200] loss: 0.010679312677475537
[Epoch 10, Batch 300] loss: 0.011864726349504053
[Epoch 10, Batch 400] loss: 0.016991349485469983
[Epoch 10, Batch 500] loss: 0.018106260811691754
[Epoch 10, Batch 600] loss: 0.00758100651033601
[Epoch 10, Batch 700] loss: 0.013618854343949351
[Epoch 10, Batch 800] loss: 0.013504139494598348
[Epoch 10, Batch 900] loss: 0.017036786605658563
[Epoch 10, Batch 1000] loss: 0.011181139217596866
[Epoch 10, Batch 1100] loss: 0.01855808308799169
[Epoch 10, Batch 1200] loss: 0.017788856564038724
[Epoch 10, Batch 1300] loss: 0.018299207867175937
[Epoch 10, Batch 1400] loss: 0.017135053790098026
[Epoch 10, Batch 1500] loss: 0.014485027909677229
[Epoch 10, Batch 1600] loss: 0.010135374110639077
[Epoch 10, Batch 1700] loss: 0.011486540662917832
[Epoch 10, Batch 1800] loss: 0.01891553008928895
[Epoch 10, Batch 1900] loss: 0.0228858559139735
[Epoch 10, Batch 2000] loss: 0.031261129000668006
[Epoch 10, Batch 2100] loss: 0.021377926706409197
[Epoch 10, Batch 2200] loss: 0.017420858711402615
[Epoch 10, Batch 2300] loss: 0.016742890248115146
[Epoch 10, Batch 2400] loss: 0.013856169055507052
[Epoch 10, Batch 2500] loss: 0.015539424297257938
[Epoch 10, Batch 2600] loss: 0.01320455189788845
[Epoch 10, Batch 2700] loss: 0.010065874589395207
[Epoch 10, Batch 2800] loss: 0.016176952685309515
[Epoch 10, Batch 2900] loss: 0.01803994123043594
[Epoch 10, Batch 3000] loss: 0.006462315729932016
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9876
Overfitting: 0.0452
Best model saved at epoch 10 with validation loss: 0.0452
[Epoch 11, Batch 100] loss: 0.0108279817384755
[Epoch 11, Batch 200] loss: 0.018343638374135482
[Epoch 11, Batch 300] loss: 0.008590533185638379
[Epoch 11, Batch 400] loss: 0.011435816858183899
[Epoch 11, Batch 500] loss: 0.01318953736775711
[Epoch 11, Batch 600] loss: 0.0162201160782206
[Epoch 11, Batch 700] loss: 0.012270708007299617
[Epoch 11, Batch 800] loss: 0.00870251420752311
[Epoch 11, Batch 900] loss: 0.0054509666272406325
[Epoch 11, Batch 1000] loss: 0.008167673969237512
[Epoch 11, Batch 1100] loss: 0.013969234936839712
[Epoch 11, Batch 1200] loss: 0.013891887473391762
[Epoch 11, Batch 1300] loss: 0.012278910418945087
[Epoch 11, Batch 1400] loss: 0.00825337872738828
[Epoch 11, Batch 1500] loss: 0.00684999351748047
[Epoch 11, Batch 1600] loss: 0.0084218901874101
[Epoch 11, Batch 1700] loss: 0.02376865621217803
[Epoch 11, Batch 1800] loss: 0.009296100714545901
[Epoch 11, Batch 1900] loss: 0.01325334058495173
[Epoch 11, Batch 2000] loss: 0.016996649526201963
[Epoch 11, Batch 2100] loss: 0.007915903885123043
[Epoch 11, Batch 2200] loss: 0.009748594093780412
[Epoch 11, Batch 2300] loss: 0.014855727913405871
[Epoch 11, Batch 2400] loss: 0.0055187618313630084
[Epoch 11, Batch 2500] loss: 0.00827566002583012
[Epoch 11, Batch 2600] loss: 0.014435278324640421
[Epoch 11, Batch 2700] loss: 0.018550014739676043
[Epoch 11, Batch 2800] loss: 0.01675497702796747
[Epoch 11, Batch 2900] loss: 0.012172746049427587
[Epoch 11, Batch 3000] loss: 0.02509986184515583
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9865
Overfitting: 0.0501
[Epoch 12, Batch 100] loss: 0.01369951958605725
[Epoch 12, Batch 200] loss: 0.0066546615936795206
[Epoch 12, Batch 300] loss: 0.008543080029658085
[Epoch 12, Batch 400] loss: 0.007278772884042155
[Epoch 12, Batch 500] loss: 0.005366020299697993
[Epoch 12, Batch 600] loss: 0.009642256627948882
[Epoch 12, Batch 700] loss: 0.014742607865855462
[Epoch 12, Batch 800] loss: 0.01907961142356953
[Epoch 12, Batch 900] loss: 0.015620445476997702
[Epoch 12, Batch 1000] loss: 0.005971159603791421
[Epoch 12, Batch 1100] loss: 0.00908523815525541
[Epoch 12, Batch 1200] loss: 0.00848432724418899
[Epoch 12, Batch 1300] loss: 0.008332840511302493
[Epoch 12, Batch 1400] loss: 0.006363220602349884
[Epoch 12, Batch 1500] loss: 0.00617498707742925
[Epoch 12, Batch 1600] loss: 0.00559497304652723
[Epoch 12, Batch 1700] loss: 0.008442873900416998
[Epoch 12, Batch 1800] loss: 0.004252737042033914
[Epoch 12, Batch 1900] loss: 0.007647892897493875
[Epoch 12, Batch 2000] loss: 0.01041386671631244
[Epoch 12, Batch 2100] loss: 0.011674520461845077
[Epoch 12, Batch 2200] loss: 0.0153696897896657
[Epoch 12, Batch 2300] loss: 0.008263341787053378
[Epoch 12, Batch 2400] loss: 0.007760104602309639
[Epoch 12, Batch 2500] loss: 0.013471566081416314
[Epoch 12, Batch 2600] loss: 0.011305836442256805
[Epoch 12, Batch 2700] loss: 0.009804523489897292
[Epoch 12, Batch 2800] loss: 0.01616506276154951
[Epoch 12, Batch 2900] loss: 0.009322810721346286
[Epoch 12, Batch 3000] loss: 0.00757835104760261
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9855
Overfitting: 0.0508
[Epoch 13, Batch 100] loss: 0.00898263622479135
[Epoch 13, Batch 200] loss: 0.009744464102600431
[Epoch 13, Batch 300] loss: 0.01376342691743048
[Epoch 13, Batch 400] loss: 0.008886573280665288
[Epoch 13, Batch 500] loss: 0.006919796420324928
[Epoch 13, Batch 600] loss: 0.0028878949846171055
[Epoch 13, Batch 700] loss: 0.004869418885787127
[Epoch 13, Batch 800] loss: 0.007031463140301639
[Epoch 13, Batch 900] loss: 0.004235763369295
[Epoch 13, Batch 1000] loss: 0.007029639638728895
[Epoch 13, Batch 1100] loss: 0.004630692066984921
[Epoch 13, Batch 1200] loss: 0.006437000902581076
[Epoch 13, Batch 1300] loss: 0.01603479742216905
[Epoch 13, Batch 1400] loss: 0.005680108012775235
[Epoch 13, Batch 1500] loss: 0.01574314168920864
[Epoch 13, Batch 1600] loss: 0.008594066909936374
[Epoch 13, Batch 1700] loss: 0.008579434742509875
[Epoch 13, Batch 1800] loss: 0.0056458262201385875
[Epoch 13, Batch 1900] loss: 0.006458147146158808
[Epoch 13, Batch 2000] loss: 0.013725629497330374
[Epoch 13, Batch 2100] loss: 0.013838060757238963
[Epoch 13, Batch 2200] loss: 0.016748674288719484
[Epoch 13, Batch 2300] loss: 0.008144671379700413
[Epoch 13, Batch 2400] loss: 0.010955547765125856
[Epoch 13, Batch 2500] loss: 0.013944774444946972
[Epoch 13, Batch 2600] loss: 0.0019293857578520602
[Epoch 13, Batch 2700] loss: 0.007070978467568239
[Epoch 13, Batch 2800] loss: 0.004552279397496477
[Epoch 13, Batch 2900] loss: 0.00282547377619494
[Epoch 13, Batch 3000] loss: 0.014090630370285453
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9848
Overfitting: 0.0603
[Epoch 14, Batch 100] loss: 0.01997013313659295
[Epoch 14, Batch 200] loss: 0.0022693054975820815
[Epoch 14, Batch 300] loss: 0.0032766840855819623
[Epoch 14, Batch 400] loss: 0.009549335085430356
[Epoch 14, Batch 500] loss: 0.0041433377279957995
[Epoch 14, Batch 600] loss: 0.009925707292544246
[Epoch 14, Batch 700] loss: 0.017144509743632172
[Epoch 14, Batch 800] loss: 0.016774895837004353
[Epoch 14, Batch 900] loss: 0.004750496049405228
[Epoch 14, Batch 1000] loss: 0.01379798384450396
[Epoch 14, Batch 1100] loss: 0.007701107566517749
[Epoch 14, Batch 1200] loss: 0.006437077596774543
[Epoch 14, Batch 1300] loss: 0.004203444251477322
[Epoch 14, Batch 1400] loss: 0.006728560350443331
[Epoch 14, Batch 1500] loss: 0.006247440728853917
[Epoch 14, Batch 1600] loss: 0.004983435188196381
[Epoch 14, Batch 1700] loss: 0.003766731597306716
[Epoch 14, Batch 1800] loss: 0.003472924585813075
[Epoch 14, Batch 1900] loss: 0.00517539884606208
[Epoch 14, Batch 2000] loss: 0.010370225867889075
[Epoch 14, Batch 2100] loss: 0.004285431346052065
[Epoch 14, Batch 2200] loss: 0.008968488088930826
[Epoch 14, Batch 2300] loss: 0.010248823487149821
[Epoch 14, Batch 2400] loss: 0.005172015817149145
[Epoch 14, Batch 2500] loss: 0.0059864589647503404
[Epoch 14, Batch 2600] loss: 0.012798340989511416
[Epoch 14, Batch 2700] loss: 0.010425365922435504
[Epoch 14, Batch 2800] loss: 0.009019876464000732
[Epoch 14, Batch 2900] loss: 0.005694126822039038
[Epoch 14, Batch 3000] loss: 0.0031561206359651804
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9879
Overfitting: 0.0471
[Epoch 15, Batch 100] loss: 0.004483716113420542
[Epoch 15, Batch 200] loss: 0.0022602097023263924
[Epoch 15, Batch 300] loss: 0.006174703483160329
[Epoch 15, Batch 400] loss: 0.005221792826382625
[Epoch 15, Batch 500] loss: 0.004211243172522358
[Epoch 15, Batch 600] loss: 0.005594246230966746
[Epoch 15, Batch 700] loss: 0.007683785101519334
[Epoch 15, Batch 800] loss: 0.0045218421331242094
[Epoch 15, Batch 900] loss: 0.006201544537926793
[Epoch 15, Batch 1000] loss: 0.0032633743106305247
[Epoch 15, Batch 1100] loss: 0.002821387642886748
[Epoch 15, Batch 1200] loss: 0.01936400506819268
[Epoch 15, Batch 1300] loss: 0.012818482166878767
[Epoch 15, Batch 1400] loss: 0.007901996802661414
[Epoch 15, Batch 1500] loss: 0.011034700982872892
[Epoch 15, Batch 1600] loss: 0.014362723807046222
[Epoch 15, Batch 1700] loss: 0.0061091415780498435
[Epoch 15, Batch 1800] loss: 0.010660343648885373
[Epoch 15, Batch 1900] loss: 0.006210437730367176
[Epoch 15, Batch 2000] loss: 0.0042808402184709845
[Epoch 15, Batch 2100] loss: 0.0050628659867990675
[Epoch 15, Batch 2200] loss: 0.006125084701753849
[Epoch 15, Batch 2300] loss: 0.005616260542876716
[Epoch 15, Batch 2400] loss: 0.006814676752897526
[Epoch 15, Batch 2500] loss: 0.009000410769535847
[Epoch 15, Batch 2600] loss: 0.005067555665742702
[Epoch 15, Batch 2700] loss: 0.004856651364148093
[Epoch 15, Batch 2800] loss: 0.007854572771467474
[Epoch 15, Batch 2900] loss: 0.00983227695199048
[Epoch 15, Batch 3000] loss: 0.002700909042050057
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9888
Overfitting: 0.0465
[Epoch 16, Batch 100] loss: 0.005691114701393758
[Epoch 16, Batch 200] loss: 0.00440311839272681
[Epoch 16, Batch 300] loss: 0.013953026910708814
[Epoch 16, Batch 400] loss: 0.002335032658055525
[Epoch 16, Batch 500] loss: 0.004070761398351692
[Epoch 16, Batch 600] loss: 0.002806805716886629
[Epoch 16, Batch 700] loss: 0.00556041592304382
[Epoch 16, Batch 800] loss: 0.0043939118691625366
[Epoch 16, Batch 900] loss: 0.008345402148189579
[Epoch 16, Batch 1000] loss: 0.005317500897022569
[Epoch 16, Batch 1100] loss: 0.0048773540912316095
[Epoch 16, Batch 1200] loss: 0.0019006031765189846
[Epoch 16, Batch 1300] loss: 0.004138051781034875
[Epoch 16, Batch 1400] loss: 0.00405068079083776
[Epoch 16, Batch 1500] loss: 0.004434174616485507
[Epoch 16, Batch 1600] loss: 0.003192190759447726
[Epoch 16, Batch 1700] loss: 0.0050778602003489935
[Epoch 16, Batch 1800] loss: 0.008002972060585306
[Epoch 16, Batch 1900] loss: 0.00469697061012539
[Epoch 16, Batch 2000] loss: 0.018462165330981863
[Epoch 16, Batch 2100] loss: 0.0067496413749461226
[Epoch 16, Batch 2200] loss: 0.003794269087405837
[Epoch 16, Batch 2300] loss: 0.0021850418910662485
[Epoch 16, Batch 2400] loss: 0.006529844701098
[Epoch 16, Batch 2500] loss: 0.01123014009603878
[Epoch 16, Batch 2600] loss: 0.00936819939531233
[Epoch 16, Batch 2700] loss: 0.016806396688135123
[Epoch 16, Batch 2800] loss: 0.008903710647524576
[Epoch 16, Batch 2900] loss: 0.0075816247608315734
[Epoch 16, Batch 3000] loss: 0.010589886266210442
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9893
Overfitting: 0.0455
[Epoch 17, Batch 100] loss: 0.004537155814725793
[Epoch 17, Batch 200] loss: 0.004282844480843551
[Epoch 17, Batch 300] loss: 0.012137183255312038
[Epoch 17, Batch 400] loss: 0.003350747805104106
[Epoch 17, Batch 500] loss: 0.012295558994352404
[Epoch 17, Batch 600] loss: 0.003762216950075299
[Epoch 17, Batch 700] loss: 0.003574592506153067
[Epoch 17, Batch 800] loss: 0.004268506252975896
[Epoch 17, Batch 900] loss: 0.004847106757979986
[Epoch 17, Batch 1000] loss: 0.004131789085934656
[Epoch 17, Batch 1100] loss: 0.0059303701048759195
[Epoch 17, Batch 1200] loss: 0.002517982926289619
[Epoch 17, Batch 1300] loss: 0.005108148706103748
[Epoch 17, Batch 1400] loss: 0.0022974036277202004
[Epoch 17, Batch 1500] loss: 0.00195126994293787
[Epoch 17, Batch 1600] loss: 0.0059745472356060245
[Epoch 17, Batch 1700] loss: 0.0021214566421008385
[Epoch 17, Batch 1800] loss: 0.0018723662044740762
[Epoch 17, Batch 1900] loss: 0.006462688773587786
[Epoch 17, Batch 2000] loss: 0.002405156251395866
[Epoch 17, Batch 2100] loss: 0.0052990205565941915
[Epoch 17, Batch 2200] loss: 0.005202969757253868
[Epoch 17, Batch 2300] loss: 0.007347949366517241
[Epoch 17, Batch 2400] loss: 0.00964696351289831
[Epoch 17, Batch 2500] loss: 0.005825843688888881
[Epoch 17, Batch 2600] loss: 0.0025627147460382106
[Epoch 17, Batch 2700] loss: 0.006911289830463829
[Epoch 17, Batch 2800] loss: 0.004024359199406718
[Epoch 17, Batch 2900] loss: 0.006570680164729765
[Epoch 17, Batch 3000] loss: 0.005831885463575191
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9873
Overfitting: 0.0506
[Epoch 18, Batch 100] loss: 0.0036655585952132695
[Epoch 18, Batch 200] loss: 0.0032758453101905615
[Epoch 18, Batch 300] loss: 0.0009495840439817726
[Epoch 18, Batch 400] loss: 0.0016847274496134901
[Epoch 18, Batch 500] loss: 0.0011043956192587246
[Epoch 18, Batch 600] loss: 0.001361486363944664
[Epoch 18, Batch 700] loss: 0.0015284191726775021
[Epoch 18, Batch 800] loss: 0.0007247906544713346
[Epoch 18, Batch 900] loss: 0.0009908049818757548
[Epoch 18, Batch 1000] loss: 0.0021480989321471886
[Epoch 18, Batch 1100] loss: 0.0008727139415378815
[Epoch 18, Batch 1200] loss: 0.0011073555217549825
[Epoch 18, Batch 1300] loss: 0.003338852520502158
[Epoch 18, Batch 1400] loss: 0.0024977583230514
[Epoch 18, Batch 1500] loss: 0.004676879360114228
[Epoch 18, Batch 1600] loss: 0.0012531426023898006
[Epoch 18, Batch 1700] loss: 0.0018815832850656734
[Epoch 18, Batch 1800] loss: 0.0016674072726425493
[Epoch 18, Batch 1900] loss: 0.0017197710662242116
[Epoch 18, Batch 2000] loss: 0.006596853058560441
[Epoch 18, Batch 2100] loss: 0.0026605812254950935
[Epoch 18, Batch 2200] loss: 0.0073650254375368365
[Epoch 18, Batch 2300] loss: 0.005051052847784945
[Epoch 18, Batch 2400] loss: 0.004908450007043541
[Epoch 18, Batch 2500] loss: 0.002780538511938744
[Epoch 18, Batch 2600] loss: 0.006812598945890045
[Epoch 18, Batch 2700] loss: 0.006801863627439175
[Epoch 18, Batch 2800] loss: 0.009086429628644055
[Epoch 18, Batch 2900] loss: 0.005860673963777501
[Epoch 18, Batch 3000] loss: 0.012781534540711155
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0594
Validation Accuracy: 0.9872
Overfitting: 0.0594
[Epoch 19, Batch 100] loss: 0.004214588839270715
[Epoch 19, Batch 200] loss: 0.0022521881489947757
[Epoch 19, Batch 300] loss: 0.003090861459702552
[Epoch 19, Batch 400] loss: 0.004690223612441855
[Epoch 19, Batch 500] loss: 0.006622518033300367
[Epoch 19, Batch 600] loss: 0.009004699933383976
[Epoch 19, Batch 700] loss: 0.00276340272139862
[Epoch 19, Batch 800] loss: 0.004103962394045766
[Epoch 19, Batch 900] loss: 0.007008048562987597
[Epoch 19, Batch 1000] loss: 0.0038634855502589003
[Epoch 19, Batch 1100] loss: 0.004890017696527451
[Epoch 19, Batch 1200] loss: 0.0071057394507313635
[Epoch 19, Batch 1300] loss: 0.017001772675989173
[Epoch 19, Batch 1400] loss: 0.006142334459299264
[Epoch 19, Batch 1500] loss: 0.003278953046641888
[Epoch 19, Batch 1600] loss: 0.007861164057303683
[Epoch 19, Batch 1700] loss: 0.007543245558038905
[Epoch 19, Batch 1800] loss: 0.004218832443506528
[Epoch 19, Batch 1900] loss: 0.004633634173624443
[Epoch 19, Batch 2000] loss: 0.0053677064629792425
[Epoch 19, Batch 2100] loss: 0.003785968501671846
[Epoch 19, Batch 2200] loss: 0.0193774971510544
[Epoch 19, Batch 2300] loss: 0.009894932393457338
[Epoch 19, Batch 2400] loss: 0.010487967895217007
[Epoch 19, Batch 2500] loss: 0.007533356571651098
[Epoch 19, Batch 2600] loss: 0.005738736919561234
[Epoch 19, Batch 2700] loss: 0.0027982709570707697
[Epoch 19, Batch 2800] loss: 0.002430020869033314
[Epoch 19, Batch 2900] loss: 0.003035245203249133
[Epoch 19, Batch 3000] loss: 0.006561269410094042
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9885
Overfitting: 0.0506
[Epoch 20, Batch 100] loss: 0.003350178741777796
[Epoch 20, Batch 200] loss: 0.0014325371888577365
[Epoch 20, Batch 300] loss: 0.002268886105666752
[Epoch 20, Batch 400] loss: 0.0028628431899393545
[Epoch 20, Batch 500] loss: 0.001288692607060966
[Epoch 20, Batch 600] loss: 0.007370267174469909
[Epoch 20, Batch 700] loss: 0.0034272592576024864
[Epoch 20, Batch 800] loss: 0.003553441152547663
[Epoch 20, Batch 900] loss: 0.0018660892151621056
[Epoch 20, Batch 1000] loss: 0.0027942859448801018
[Epoch 20, Batch 1100] loss: 0.0016017321460097377
[Epoch 20, Batch 1200] loss: 0.00211472487536188
[Epoch 20, Batch 1300] loss: 0.0017923058136889835
[Epoch 20, Batch 1400] loss: 0.001609751135870283
[Epoch 20, Batch 1500] loss: 0.0009279327251292102
[Epoch 20, Batch 1600] loss: 0.0017133531770397426
[Epoch 20, Batch 1700] loss: 0.0022561026079890214
[Epoch 20, Batch 1800] loss: 0.0026814342579788786
[Epoch 20, Batch 1900] loss: 0.004234512461080797
[Epoch 20, Batch 2000] loss: 0.0022671463273513837
[Epoch 20, Batch 2100] loss: 0.004578526212635836
[Epoch 20, Batch 2200] loss: 0.0014719383019432541
[Epoch 20, Batch 2300] loss: 0.005887950689395751
[Epoch 20, Batch 2400] loss: 0.002061270670942186
[Epoch 20, Batch 2500] loss: 0.0035356072848701458
[Epoch 20, Batch 2600] loss: 0.002583732022783494
[Epoch 20, Batch 2700] loss: 0.002295988312956574
[Epoch 20, Batch 2800] loss: 0.0014145837505089532
[Epoch 20, Batch 2900] loss: 0.004320908288231067
[Epoch 20, Batch 3000] loss: 0.0024518226217983673
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9878
Overfitting: 0.0550
[Epoch 21, Batch 100] loss: 0.0026366649995190807
[Epoch 21, Batch 200] loss: 0.0014306547729625407
[Epoch 21, Batch 300] loss: 0.001142807253152931
[Epoch 21, Batch 400] loss: 0.00045417367777780273
[Epoch 21, Batch 500] loss: 0.0010387648202565458
[Epoch 21, Batch 600] loss: 0.001527436968726974
[Epoch 21, Batch 700] loss: 0.0007241311224809844
[Epoch 21, Batch 800] loss: 0.001217719239156736
[Epoch 21, Batch 900] loss: 0.001192874049286452
[Epoch 21, Batch 1000] loss: 0.003248529521197696
[Epoch 21, Batch 1100] loss: 0.0017300973349784953
[Epoch 21, Batch 1200] loss: 0.0008668085660274017
[Epoch 21, Batch 1300] loss: 0.0004507084184091781
[Epoch 21, Batch 1400] loss: 0.0006946425882162543
[Epoch 21, Batch 1500] loss: 0.0006224675529910683
[Epoch 21, Batch 1600] loss: 0.000992196757302395
[Epoch 21, Batch 1700] loss: 0.0008167649308974312
[Epoch 21, Batch 1800] loss: 0.0009312912485253389
[Epoch 21, Batch 1900] loss: 0.0009039193676815316
[Epoch 21, Batch 2000] loss: 0.0012940071875868853
[Epoch 21, Batch 2100] loss: 0.0004201171405016657
[Epoch 21, Batch 2200] loss: 0.000889088772285862
[Epoch 21, Batch 2300] loss: 0.0007668073517294216
[Epoch 21, Batch 2400] loss: 0.0009220156778145849
[Epoch 21, Batch 2500] loss: 0.0005477107643631651
[Epoch 21, Batch 2600] loss: 0.0008626949146615459
[Epoch 21, Batch 2700] loss: 0.0008551835688319898
[Epoch 21, Batch 2800] loss: 0.0016446064719377684
[Epoch 21, Batch 2900] loss: 0.0030049951250144956
[Epoch 21, Batch 3000] loss: 0.000415576468008112
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9894
Overfitting: 0.0531
[Epoch 22, Batch 100] loss: 0.0007125010213094907
[Epoch 22, Batch 200] loss: 0.0002638894418036086
[Epoch 22, Batch 300] loss: 0.00022695408929621408
[Epoch 22, Batch 400] loss: 0.00026521280065011865
[Epoch 22, Batch 500] loss: 0.00048497456973052523
[Epoch 22, Batch 600] loss: 0.0011277414979442568
[Epoch 22, Batch 700] loss: 0.0009057672857212351
[Epoch 22, Batch 800] loss: 0.0012435453520305683
[Epoch 22, Batch 900] loss: 0.0006099252755482531
[Epoch 22, Batch 1000] loss: 0.00047179550688255747
[Epoch 22, Batch 1100] loss: 0.0002540076429682614
[Epoch 22, Batch 1200] loss: 0.000749487817571608
[Epoch 22, Batch 1300] loss: 0.00039144183656038224
[Epoch 22, Batch 1400] loss: 0.00046607101651844116
[Epoch 22, Batch 1500] loss: 0.0006598316712917374
[Epoch 22, Batch 1600] loss: 0.00031002957829407763
[Epoch 22, Batch 1700] loss: 0.0006230101564565782
[Epoch 22, Batch 1800] loss: 0.001187884577341034
[Epoch 22, Batch 1900] loss: 0.0005552434906022086
[Epoch 22, Batch 2000] loss: 0.00045420321177516156
[Epoch 22, Batch 2100] loss: 0.00028126259169263256
[Epoch 22, Batch 2200] loss: 0.0002108810747927059
[Epoch 22, Batch 2300] loss: 0.00033724261051322203
[Epoch 22, Batch 2400] loss: 0.0005323850444101774
[Epoch 22, Batch 2500] loss: 0.0015595757123861276
[Epoch 22, Batch 2600] loss: 0.0008330712013557218
[Epoch 22, Batch 2700] loss: 0.00034040659336656456
[Epoch 22, Batch 2800] loss: 0.0004280563199614029
[Epoch 22, Batch 2900] loss: 0.0002454411389479283
[Epoch 22, Batch 3000] loss: 0.0003556700170601168
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9901
Overfitting: 0.0520
[Epoch 23, Batch 100] loss: 0.0002920481574695799
[Epoch 23, Batch 200] loss: 0.00022768234429971558
[Epoch 23, Batch 300] loss: 0.00019992279973145342
[Epoch 23, Batch 400] loss: 0.00019023891045669484
[Epoch 23, Batch 500] loss: 0.0003602461933004264
[Epoch 23, Batch 600] loss: 0.00024147601581148593
[Epoch 23, Batch 700] loss: 0.00022075640756936466
[Epoch 23, Batch 800] loss: 0.00019071004821354264
[Epoch 23, Batch 900] loss: 0.00022898279515780827
[Epoch 23, Batch 1000] loss: 0.000254688691532059
[Epoch 23, Batch 1100] loss: 0.00017568984904826836
[Epoch 23, Batch 1200] loss: 0.00017483592250132406
[Epoch 23, Batch 1300] loss: 0.0003274836511568946
[Epoch 23, Batch 1400] loss: 0.000505370258476816
[Epoch 23, Batch 1500] loss: 0.0004115109594462574
[Epoch 23, Batch 1600] loss: 0.0002511680589359333
[Epoch 23, Batch 1700] loss: 0.00055564684195053
[Epoch 23, Batch 1800] loss: 0.0009422821313722762
[Epoch 23, Batch 1900] loss: 0.0002537915967314053
[Epoch 23, Batch 2000] loss: 0.001195626553276896
[Epoch 23, Batch 2100] loss: 0.00033824858976515325
[Epoch 23, Batch 2200] loss: 0.0003195809587904108
[Epoch 23, Batch 2300] loss: 0.00033888693280607283
[Epoch 23, Batch 2400] loss: 0.0002842423922566528
[Epoch 23, Batch 2500] loss: 0.00021327440946816267
[Epoch 23, Batch 2600] loss: 0.00020497624215187304
[Epoch 23, Batch 2700] loss: 0.00021050187435269762
[Epoch 23, Batch 2800] loss: 0.0005408171056944422
[Epoch 23, Batch 2900] loss: 0.00028916782888129157
[Epoch 23, Batch 3000] loss: 0.00015639282317770232
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9900
Overfitting: 0.0523
[Epoch 24, Batch 100] loss: 0.00022765230115196823
[Epoch 24, Batch 200] loss: 0.0001517147105530192
[Epoch 24, Batch 300] loss: 0.00041904350708942494
[Epoch 24, Batch 400] loss: 0.00020511187845425382
[Epoch 24, Batch 500] loss: 0.0002577794869355854
[Epoch 24, Batch 600] loss: 0.00022347599635626824
[Epoch 24, Batch 700] loss: 0.0002881090487909699
[Epoch 24, Batch 800] loss: 0.00023881274494932825
[Epoch 24, Batch 900] loss: 0.00027580441707995005
[Epoch 24, Batch 1000] loss: 0.0001637105964205432
[Epoch 24, Batch 1100] loss: 0.0001838975241332097
[Epoch 24, Batch 1200] loss: 0.0003084761359149368
[Epoch 24, Batch 1300] loss: 0.00028183243108991006
[Epoch 24, Batch 1400] loss: 0.00016053596471357067
[Epoch 24, Batch 1500] loss: 0.0001599084865270939
[Epoch 24, Batch 1600] loss: 0.00038629955634527757
[Epoch 24, Batch 1700] loss: 0.000103583524562878
[Epoch 24, Batch 1800] loss: 0.0001765814392013576
[Epoch 24, Batch 1900] loss: 0.00017972104068569194
[Epoch 24, Batch 2000] loss: 0.00023036245365165353
[Epoch 24, Batch 2100] loss: 0.00013964039702189625
[Epoch 24, Batch 2200] loss: 0.00021647168284628205
[Epoch 24, Batch 2300] loss: 0.00022702809029190974
[Epoch 24, Batch 2400] loss: 0.00023053322747060623
[Epoch 24, Batch 2500] loss: 0.00013191396643049913
[Epoch 24, Batch 2600] loss: 0.00044502392504446763
[Epoch 24, Batch 2700] loss: 0.00017776210151597915
[Epoch 24, Batch 2800] loss: 0.0006403400298745421
[Epoch 24, Batch 2900] loss: 0.0003724081829867476
[Epoch 24, Batch 3000] loss: 0.00011969288283107726
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9896
Overfitting: 0.0548
Fold 3 validation loss: 0.0548
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2652030920982362
[Epoch 1, Batch 200] loss: 1.9024189734458923
[Epoch 1, Batch 300] loss: 0.8532935938239098
[Epoch 1, Batch 400] loss: 0.6503263296186924
[Epoch 1, Batch 500] loss: 0.453637807816267
[Epoch 1, Batch 600] loss: 0.40607456512749196
[Epoch 1, Batch 700] loss: 0.39664176538586615
[Epoch 1, Batch 800] loss: 0.31549622751772405
[Epoch 1, Batch 900] loss: 0.3088963630795479
[Epoch 1, Batch 1000] loss: 0.2799495892599225
[Epoch 1, Batch 1100] loss: 0.23467884238809347
[Epoch 1, Batch 1200] loss: 0.23583884185180068
[Epoch 1, Batch 1300] loss: 0.21726416532881557
[Epoch 1, Batch 1400] loss: 0.22154183248057963
[Epoch 1, Batch 1500] loss: 0.2371931567415595
[Epoch 1, Batch 1600] loss: 0.16207665593363343
[Epoch 1, Batch 1700] loss: 0.16325917730107903
[Epoch 1, Batch 1800] loss: 0.16561018716078252
[Epoch 1, Batch 1900] loss: 0.1670770002854988
[Epoch 1, Batch 2000] loss: 0.15022336199879646
[Epoch 1, Batch 2100] loss: 0.15802932910155504
[Epoch 1, Batch 2200] loss: 0.15584441899321974
[Epoch 1, Batch 2300] loss: 0.14722720713354648
[Epoch 1, Batch 2400] loss: 0.18810429491102695
[Epoch 1, Batch 2500] loss: 0.13680482361931354
[Epoch 1, Batch 2600] loss: 0.13064324009232223
[Epoch 1, Batch 2700] loss: 0.12451026964001358
[Epoch 1, Batch 2800] loss: 0.09206868805922568
[Epoch 1, Batch 2900] loss: 0.12931504022330045
[Epoch 1, Batch 3000] loss: 0.11121948309941217
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1113
Validation Accuracy: 0.9641
Overfitting: 0.1113
Best model saved at epoch 1 with validation loss: 0.1113
[Epoch 2, Batch 100] loss: 0.08323387605370954
[Epoch 2, Batch 200] loss: 0.08370175985619425
[Epoch 2, Batch 300] loss: 0.1423285696725361
[Epoch 2, Batch 400] loss: 0.12672336066607387
[Epoch 2, Batch 500] loss: 0.08804977922467515
[Epoch 2, Batch 600] loss: 0.09568386122235097
[Epoch 2, Batch 700] loss: 0.12453423107857815
[Epoch 2, Batch 800] loss: 0.08675300601404161
[Epoch 2, Batch 900] loss: 0.10032572464318947
[Epoch 2, Batch 1000] loss: 0.1177498256135732
[Epoch 2, Batch 1100] loss: 0.10053633037256077
[Epoch 2, Batch 1200] loss: 0.07809371711045969
[Epoch 2, Batch 1300] loss: 0.08822007261565887
[Epoch 2, Batch 1400] loss: 0.10147208302747458
[Epoch 2, Batch 1500] loss: 0.09908490406582132
[Epoch 2, Batch 1600] loss: 0.0912987993680872
[Epoch 2, Batch 1700] loss: 0.08288007380091585
[Epoch 2, Batch 1800] loss: 0.085301348506473
[Epoch 2, Batch 1900] loss: 0.10727535750484093
[Epoch 2, Batch 2000] loss: 0.07785390289500356
[Epoch 2, Batch 2100] loss: 0.08578532715910114
[Epoch 2, Batch 2200] loss: 0.10701037406455725
[Epoch 2, Batch 2300] loss: 0.08539034772198648
[Epoch 2, Batch 2400] loss: 0.09480913796025561
[Epoch 2, Batch 2500] loss: 0.07582683878659736
[Epoch 2, Batch 2600] loss: 0.09103301127790474
[Epoch 2, Batch 2700] loss: 0.08442874786327594
[Epoch 2, Batch 2800] loss: 0.06983382611302659
[Epoch 2, Batch 2900] loss: 0.0853385317325592
[Epoch 2, Batch 3000] loss: 0.05525358471088111
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0811
Validation Accuracy: 0.9737
Overfitting: 0.0811
Best model saved at epoch 2 with validation loss: 0.0811
[Epoch 3, Batch 100] loss: 0.08860745656653307
[Epoch 3, Batch 200] loss: 0.06384205977723469
[Epoch 3, Batch 300] loss: 0.06356666411971673
[Epoch 3, Batch 400] loss: 0.06092714055150281
[Epoch 3, Batch 500] loss: 0.04328448376909364
[Epoch 3, Batch 600] loss: 0.06024209711991716
[Epoch 3, Batch 700] loss: 0.06327205729903654
[Epoch 3, Batch 800] loss: 0.06524918467504903
[Epoch 3, Batch 900] loss: 0.08597011367091908
[Epoch 3, Batch 1000] loss: 0.08399216319783591
[Epoch 3, Batch 1100] loss: 0.06523382863146253
[Epoch 3, Batch 1200] loss: 0.0641947943030391
[Epoch 3, Batch 1300] loss: 0.03861364774493268
[Epoch 3, Batch 1400] loss: 0.07490714809246128
[Epoch 3, Batch 1500] loss: 0.06633682929561474
[Epoch 3, Batch 1600] loss: 0.06167791161278728
[Epoch 3, Batch 1700] loss: 0.04488631553074811
[Epoch 3, Batch 1800] loss: 0.06285860011004843
[Epoch 3, Batch 1900] loss: 0.06914375010004732
[Epoch 3, Batch 2000] loss: 0.07151613875423209
[Epoch 3, Batch 2100] loss: 0.06218995425966568
[Epoch 3, Batch 2200] loss: 0.0771179648861289
[Epoch 3, Batch 2300] loss: 0.05647895317641087
[Epoch 3, Batch 2400] loss: 0.060849019094603135
[Epoch 3, Batch 2500] loss: 0.07205784375779331
[Epoch 3, Batch 2600] loss: 0.051088554196758194
[Epoch 3, Batch 2700] loss: 0.047208588590438014
[Epoch 3, Batch 2800] loss: 0.06478959957137703
[Epoch 3, Batch 2900] loss: 0.07860142464749514
[Epoch 3, Batch 3000] loss: 0.05814341383986175
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0679
Validation Accuracy: 0.9786
Overfitting: 0.0679
Best model saved at epoch 3 with validation loss: 0.0679
[Epoch 4, Batch 100] loss: 0.051194993812969186
[Epoch 4, Batch 200] loss: 0.058698826754989566
[Epoch 4, Batch 300] loss: 0.05252253023674711
[Epoch 4, Batch 400] loss: 0.03261000908154529
[Epoch 4, Batch 500] loss: 0.05640380083452328
[Epoch 4, Batch 600] loss: 0.04363340719108237
[Epoch 4, Batch 700] loss: 0.05921504792931955
[Epoch 4, Batch 800] loss: 0.04903440982481697
[Epoch 4, Batch 900] loss: 0.044697182345262265
[Epoch 4, Batch 1000] loss: 0.05371603716455866
[Epoch 4, Batch 1100] loss: 0.05258450642519165
[Epoch 4, Batch 1200] loss: 0.06138526642476791
[Epoch 4, Batch 1300] loss: 0.0400320568033203
[Epoch 4, Batch 1400] loss: 0.054604363563412334
[Epoch 4, Batch 1500] loss: 0.05235299016174395
[Epoch 4, Batch 1600] loss: 0.05013632785499794
[Epoch 4, Batch 1700] loss: 0.04731403419311391
[Epoch 4, Batch 1800] loss: 0.041438379250466825
[Epoch 4, Batch 1900] loss: 0.052358707658640924
[Epoch 4, Batch 2000] loss: 0.03998597301892005
[Epoch 4, Batch 2100] loss: 0.06346795068559004
[Epoch 4, Batch 2200] loss: 0.031804536262934564
[Epoch 4, Batch 2300] loss: 0.05754340082668932
[Epoch 4, Batch 2400] loss: 0.05793445047165733
[Epoch 4, Batch 2500] loss: 0.06497235628019553
[Epoch 4, Batch 2600] loss: 0.0369411328737624
[Epoch 4, Batch 2700] loss: 0.05441951161585166
[Epoch 4, Batch 2800] loss: 0.03686433683848009
[Epoch 4, Batch 2900] loss: 0.03715771312272409
[Epoch 4, Batch 3000] loss: 0.05414362926981994
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0590
Validation Accuracy: 0.9824
Overfitting: 0.0590
Best model saved at epoch 4 with validation loss: 0.0590
[Epoch 5, Batch 100] loss: 0.06099858339817729
[Epoch 5, Batch 200] loss: 0.031497357112530155
[Epoch 5, Batch 300] loss: 0.0345531230350025
[Epoch 5, Batch 400] loss: 0.04461256887007039
[Epoch 5, Batch 500] loss: 0.04272723389702151
[Epoch 5, Batch 600] loss: 0.03530113169937977
[Epoch 5, Batch 700] loss: 0.022765677821153078
[Epoch 5, Batch 800] loss: 0.04415600886248285
[Epoch 5, Batch 900] loss: 0.042137938038940774
[Epoch 5, Batch 1000] loss: 0.04899594483787951
[Epoch 5, Batch 1100] loss: 0.025087725981575205
[Epoch 5, Batch 1200] loss: 0.05477492171383346
[Epoch 5, Batch 1300] loss: 0.03643810766574461
[Epoch 5, Batch 1400] loss: 0.035346048730716575
[Epoch 5, Batch 1500] loss: 0.032490092306252334
[Epoch 5, Batch 1600] loss: 0.03619960055737465
[Epoch 5, Batch 1700] loss: 0.049693037796314454
[Epoch 5, Batch 1800] loss: 0.041495230649597946
[Epoch 5, Batch 1900] loss: 0.05001053579762811
[Epoch 5, Batch 2000] loss: 0.04759171629055345
[Epoch 5, Batch 2100] loss: 0.04289577958959853
[Epoch 5, Batch 2200] loss: 0.03451705052473699
[Epoch 5, Batch 2300] loss: 0.03264706460322486
[Epoch 5, Batch 2400] loss: 0.0422368732225732
[Epoch 5, Batch 2500] loss: 0.04150117803495959
[Epoch 5, Batch 2600] loss: 0.021833901446370874
[Epoch 5, Batch 2700] loss: 0.03823529079167201
[Epoch 5, Batch 2800] loss: 0.05249518844371778
[Epoch 5, Batch 2900] loss: 0.024983552900666835
[Epoch 5, Batch 3000] loss: 0.051332418452802814
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9855
Overfitting: 0.0507
Best model saved at epoch 5 with validation loss: 0.0507
[Epoch 6, Batch 100] loss: 0.02417644414526876
[Epoch 6, Batch 200] loss: 0.023889809017055084
[Epoch 6, Batch 300] loss: 0.02506673130643321
[Epoch 6, Batch 400] loss: 0.025761067557759816
[Epoch 6, Batch 500] loss: 0.03129132661197218
[Epoch 6, Batch 600] loss: 0.03407386399623647
[Epoch 6, Batch 700] loss: 0.02168527770023502
[Epoch 6, Batch 800] loss: 0.03380152836420166
[Epoch 6, Batch 900] loss: 0.036489865369949255
[Epoch 6, Batch 1000] loss: 0.03604924861792824
[Epoch 6, Batch 1100] loss: 0.027669842996110673
[Epoch 6, Batch 1200] loss: 0.03428499055866269
[Epoch 6, Batch 1300] loss: 0.034748039699552466
[Epoch 6, Batch 1400] loss: 0.024402825483339257
[Epoch 6, Batch 1500] loss: 0.02131059590870791
[Epoch 6, Batch 1600] loss: 0.04783340433772537
[Epoch 6, Batch 1700] loss: 0.04229763099036063
[Epoch 6, Batch 1800] loss: 0.03509080379888473
[Epoch 6, Batch 1900] loss: 0.02477723683725344
[Epoch 6, Batch 2000] loss: 0.03197156663074566
[Epoch 6, Batch 2100] loss: 0.03824006720147736
[Epoch 6, Batch 2200] loss: 0.04677020819479367
[Epoch 6, Batch 2300] loss: 0.03677756236604182
[Epoch 6, Batch 2400] loss: 0.042131601256260184
[Epoch 6, Batch 2500] loss: 0.0330731478332018
[Epoch 6, Batch 2600] loss: 0.03774873743226635
[Epoch 6, Batch 2700] loss: 0.041376413935686286
[Epoch 6, Batch 2800] loss: 0.02241037752781267
[Epoch 6, Batch 2900] loss: 0.03931371059792582
[Epoch 6, Batch 3000] loss: 0.038310501101223055
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0597
Validation Accuracy: 0.9818
Overfitting: 0.0597
[Epoch 7, Batch 100] loss: 0.030482175188080874
[Epoch 7, Batch 200] loss: 0.025438015040926985
[Epoch 7, Batch 300] loss: 0.03499546460239799
[Epoch 7, Batch 400] loss: 0.026377681903977646
[Epoch 7, Batch 500] loss: 0.017376281991182622
[Epoch 7, Batch 600] loss: 0.021818922301754355
[Epoch 7, Batch 700] loss: 0.03250567054223211
[Epoch 7, Batch 800] loss: 0.023503523446161124
[Epoch 7, Batch 900] loss: 0.017736881071759854
[Epoch 7, Batch 1000] loss: 0.03196378517335688
[Epoch 7, Batch 1100] loss: 0.02763283323349242
[Epoch 7, Batch 1200] loss: 0.033500230919598833
[Epoch 7, Batch 1300] loss: 0.03726146915643767
[Epoch 7, Batch 1400] loss: 0.029341515316336882
[Epoch 7, Batch 1500] loss: 0.03446258723721257
[Epoch 7, Batch 1600] loss: 0.022084061839832428
[Epoch 7, Batch 1700] loss: 0.02565766458679718
[Epoch 7, Batch 1800] loss: 0.030462174637286808
[Epoch 7, Batch 1900] loss: 0.02775808359399889
[Epoch 7, Batch 2000] loss: 0.032442749474212176
[Epoch 7, Batch 2100] loss: 0.023549288262147458
[Epoch 7, Batch 2200] loss: 0.024848712094462825
[Epoch 7, Batch 2300] loss: 0.029372161979299562
[Epoch 7, Batch 2400] loss: 0.02242439875313721
[Epoch 7, Batch 2500] loss: 0.021274737445637584
[Epoch 7, Batch 2600] loss: 0.032363670793874914
[Epoch 7, Batch 2700] loss: 0.020570280513784383
[Epoch 7, Batch 2800] loss: 0.028351650759286712
[Epoch 7, Batch 2900] loss: 0.036214412919362074
[Epoch 7, Batch 3000] loss: 0.035020716749568234
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9853
Overfitting: 0.0464
Best model saved at epoch 7 with validation loss: 0.0464
[Epoch 8, Batch 100] loss: 0.01994133994441654
[Epoch 8, Batch 200] loss: 0.04011063253194152
[Epoch 8, Batch 300] loss: 0.02289649444304814
[Epoch 8, Batch 400] loss: 0.01550733347208734
[Epoch 8, Batch 500] loss: 0.033448704658512726
[Epoch 8, Batch 600] loss: 0.02212907977431314
[Epoch 8, Batch 700] loss: 0.03671907328247471
[Epoch 8, Batch 800] loss: 0.017612132635404124
[Epoch 8, Batch 900] loss: 0.01889937554456992
[Epoch 8, Batch 1000] loss: 0.02525221289390174
[Epoch 8, Batch 1100] loss: 0.035803510014229684
[Epoch 8, Batch 1200] loss: 0.0220893807685934
[Epoch 8, Batch 1300] loss: 0.019833878452700446
[Epoch 8, Batch 1400] loss: 0.02386776950497733
[Epoch 8, Batch 1500] loss: 0.011818058954595471
[Epoch 8, Batch 1600] loss: 0.020811772127708537
[Epoch 8, Batch 1700] loss: 0.027158650575220235
[Epoch 8, Batch 1800] loss: 0.01996464031526557
[Epoch 8, Batch 1900] loss: 0.025040367229703406
[Epoch 8, Batch 2000] loss: 0.01510186825040364
[Epoch 8, Batch 2100] loss: 0.026429096258198115
[Epoch 8, Batch 2200] loss: 0.026546168411005055
[Epoch 8, Batch 2300] loss: 0.018284565670910524
[Epoch 8, Batch 2400] loss: 0.02105648953209311
[Epoch 8, Batch 2500] loss: 0.021239023845519112
[Epoch 8, Batch 2600] loss: 0.023731517994856403
[Epoch 8, Batch 2700] loss: 0.014630993004248012
[Epoch 8, Batch 2800] loss: 0.016338294685065192
[Epoch 8, Batch 2900] loss: 0.01769897533195035
[Epoch 8, Batch 3000] loss: 0.02846974172962291
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0407
Validation Accuracy: 0.9880
Overfitting: 0.0407
Best model saved at epoch 8 with validation loss: 0.0407
[Epoch 9, Batch 100] loss: 0.011285553383022489
[Epoch 9, Batch 200] loss: 0.023058530157304632
[Epoch 9, Batch 300] loss: 0.025608034149991
[Epoch 9, Batch 400] loss: 0.013081605325187411
[Epoch 9, Batch 500] loss: 0.015087444136042905
[Epoch 9, Batch 600] loss: 0.010205008063294371
[Epoch 9, Batch 700] loss: 0.018005852091901035
[Epoch 9, Batch 800] loss: 0.02789415383912683
[Epoch 9, Batch 900] loss: 0.025332206692582987
[Epoch 9, Batch 1000] loss: 0.01898557641510706
[Epoch 9, Batch 1100] loss: 0.009076363652620784
[Epoch 9, Batch 1200] loss: 0.014739849700672493
[Epoch 9, Batch 1300] loss: 0.007785072405022219
[Epoch 9, Batch 1400] loss: 0.03172395268404216
[Epoch 9, Batch 1500] loss: 0.016539606100850507
[Epoch 9, Batch 1600] loss: 0.03976323799961392
[Epoch 9, Batch 1700] loss: 0.02196672777443382
[Epoch 9, Batch 1800] loss: 0.020493615298219085
[Epoch 9, Batch 1900] loss: 0.02045717845258878
[Epoch 9, Batch 2000] loss: 0.024826337194390362
[Epoch 9, Batch 2100] loss: 0.019198925426317147
[Epoch 9, Batch 2200] loss: 0.021718518855086587
[Epoch 9, Batch 2300] loss: 0.01856615709082689
[Epoch 9, Batch 2400] loss: 0.02675955559767317
[Epoch 9, Batch 2500] loss: 0.03178292512151529
[Epoch 9, Batch 2600] loss: 0.013538482099993416
[Epoch 9, Batch 2700] loss: 0.01824713778696605
[Epoch 9, Batch 2800] loss: 0.018866618062129418
[Epoch 9, Batch 2900] loss: 0.02676619937756186
[Epoch 9, Batch 3000] loss: 0.030100324651284607
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9848
Overfitting: 0.0526
[Epoch 10, Batch 100] loss: 0.01811593099919264
[Epoch 10, Batch 200] loss: 0.021387930996461364
[Epoch 10, Batch 300] loss: 0.011949515020933176
[Epoch 10, Batch 400] loss: 0.01378371136263013
[Epoch 10, Batch 500] loss: 0.0068962998162078295
[Epoch 10, Batch 600] loss: 0.015929839845503013
[Epoch 10, Batch 700] loss: 0.010306261441082825
[Epoch 10, Batch 800] loss: 0.01250917097888305
[Epoch 10, Batch 900] loss: 0.014115515240218883
[Epoch 10, Batch 1000] loss: 0.021701170392025234
[Epoch 10, Batch 1100] loss: 0.01758883502423032
[Epoch 10, Batch 1200] loss: 0.01696149368756778
[Epoch 10, Batch 1300] loss: 0.013168845224990946
[Epoch 10, Batch 1400] loss: 0.005048659988460713
[Epoch 10, Batch 1500] loss: 0.01728085390670458
[Epoch 10, Batch 1600] loss: 0.01945825759188665
[Epoch 10, Batch 1700] loss: 0.02022155576915793
[Epoch 10, Batch 1800] loss: 0.024064334878958107
[Epoch 10, Batch 1900] loss: 0.009509681327781436
[Epoch 10, Batch 2000] loss: 0.019567816488915923
[Epoch 10, Batch 2100] loss: 0.008559306143706636
[Epoch 10, Batch 2200] loss: 0.020592485736251546
[Epoch 10, Batch 2300] loss: 0.020391714011752812
[Epoch 10, Batch 2400] loss: 0.014517197455975293
[Epoch 10, Batch 2500] loss: 0.01940311468042637
[Epoch 10, Batch 2600] loss: 0.021685845567863
[Epoch 10, Batch 2700] loss: 0.01979802028834456
[Epoch 10, Batch 2800] loss: 0.03110854143731558
[Epoch 10, Batch 2900] loss: 0.019023579987842824
[Epoch 10, Batch 3000] loss: 0.02431331200215027
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9852
Overfitting: 0.0559
[Epoch 11, Batch 100] loss: 0.010609658074909021
[Epoch 11, Batch 200] loss: 0.011777221933971304
[Epoch 11, Batch 300] loss: 0.011656538637489576
[Epoch 11, Batch 400] loss: 0.021049538146435225
[Epoch 11, Batch 500] loss: 0.016296899730396035
[Epoch 11, Batch 600] loss: 0.014515721578504781
[Epoch 11, Batch 700] loss: 0.01633303226873977
[Epoch 11, Batch 800] loss: 0.010386402999483835
[Epoch 11, Batch 900] loss: 0.010830479783544433
[Epoch 11, Batch 1000] loss: 0.011299453204910605
[Epoch 11, Batch 1100] loss: 0.021201675003121635
[Epoch 11, Batch 1200] loss: 0.012246936415067466
[Epoch 11, Batch 1300] loss: 0.014610008748218207
[Epoch 11, Batch 1400] loss: 0.010465728310769008
[Epoch 11, Batch 1500] loss: 0.012244062490017313
[Epoch 11, Batch 1600] loss: 0.01193428779595706
[Epoch 11, Batch 1700] loss: 0.010998632914524933
[Epoch 11, Batch 1800] loss: 0.016318028795794817
[Epoch 11, Batch 1900] loss: 0.013878837130250758
[Epoch 11, Batch 2000] loss: 0.02264373760068338
[Epoch 11, Batch 2100] loss: 0.006713079324740647
[Epoch 11, Batch 2200] loss: 0.024852645525188562
[Epoch 11, Batch 2300] loss: 0.016235672706061452
[Epoch 11, Batch 2400] loss: 0.006443148109669891
[Epoch 11, Batch 2500] loss: 0.013876105017525333
[Epoch 11, Batch 2600] loss: 0.011570759677702255
[Epoch 11, Batch 2700] loss: 0.013705882179801848
[Epoch 11, Batch 2800] loss: 0.023054328808048013
[Epoch 11, Batch 2900] loss: 0.01985007688319456
[Epoch 11, Batch 3000] loss: 0.01213396933675085
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9879
Overfitting: 0.0520
[Epoch 12, Batch 100] loss: 0.008712994428042293
[Epoch 12, Batch 200] loss: 0.00882281238293217
[Epoch 12, Batch 300] loss: 0.005381131220210591
[Epoch 12, Batch 400] loss: 0.0051156632495531085
[Epoch 12, Batch 500] loss: 0.010068599969149545
[Epoch 12, Batch 600] loss: 0.012677606577863116
[Epoch 12, Batch 700] loss: 0.008044181408154145
[Epoch 12, Batch 800] loss: 0.007182111208940114
[Epoch 12, Batch 900] loss: 0.01362344769524725
[Epoch 12, Batch 1000] loss: 0.011084881354025243
[Epoch 12, Batch 1100] loss: 0.008638205491976123
[Epoch 12, Batch 1200] loss: 0.011731742394499634
[Epoch 12, Batch 1300] loss: 0.008584065353336428
[Epoch 12, Batch 1400] loss: 0.009248433615231305
[Epoch 12, Batch 1500] loss: 0.014791711117741215
[Epoch 12, Batch 1600] loss: 0.012792379022102977
[Epoch 12, Batch 1700] loss: 0.01673502622169508
[Epoch 12, Batch 1800] loss: 0.026504337023355903
[Epoch 12, Batch 1900] loss: 0.01340761732730016
[Epoch 12, Batch 2000] loss: 0.012902824362463435
[Epoch 12, Batch 2100] loss: 0.011745510888731587
[Epoch 12, Batch 2200] loss: 0.014519430672717135
[Epoch 12, Batch 2300] loss: 0.02334631256004286
[Epoch 12, Batch 2400] loss: 0.014195581262233645
[Epoch 12, Batch 2500] loss: 0.005621678797106142
[Epoch 12, Batch 2600] loss: 0.011045938492541154
[Epoch 12, Batch 2700] loss: 0.014227213756944366
[Epoch 12, Batch 2800] loss: 0.01728315941485107
[Epoch 12, Batch 2900] loss: 0.010507333337259298
[Epoch 12, Batch 3000] loss: 0.012691607868357551
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9860
Overfitting: 0.0507
[Epoch 13, Batch 100] loss: 0.0031726227725152965
[Epoch 13, Batch 200] loss: 0.014100239627478004
[Epoch 13, Batch 300] loss: 0.0039267958960431315
[Epoch 13, Batch 400] loss: 0.006318669558663714
[Epoch 13, Batch 500] loss: 0.005707260879348724
[Epoch 13, Batch 600] loss: 0.008695422832888653
[Epoch 13, Batch 700] loss: 0.017055813703785817
[Epoch 13, Batch 800] loss: 0.010628703068541655
[Epoch 13, Batch 900] loss: 0.006700180710920449
[Epoch 13, Batch 1000] loss: 0.006753867318725498
[Epoch 13, Batch 1100] loss: 0.0036999867677582187
[Epoch 13, Batch 1200] loss: 0.011974132442269934
[Epoch 13, Batch 1300] loss: 0.012499578892728777
[Epoch 13, Batch 1400] loss: 0.012686720839819827
[Epoch 13, Batch 1500] loss: 0.010701898948238977
[Epoch 13, Batch 1600] loss: 0.025246980424157073
[Epoch 13, Batch 1700] loss: 0.004235378024762895
[Epoch 13, Batch 1800] loss: 0.008315464453762616
[Epoch 13, Batch 1900] loss: 0.004664162804098737
[Epoch 13, Batch 2000] loss: 0.012488212606835986
[Epoch 13, Batch 2100] loss: 0.015987194747376633
[Epoch 13, Batch 2200] loss: 0.01072652840539149
[Epoch 13, Batch 2300] loss: 0.011869329494786598
[Epoch 13, Batch 2400] loss: 0.014806446815482559
[Epoch 13, Batch 2500] loss: 0.014810392150857297
[Epoch 13, Batch 2600] loss: 0.011053058912875714
[Epoch 13, Batch 2700] loss: 0.011756985896097376
[Epoch 13, Batch 2800] loss: 0.032639882078638036
[Epoch 13, Batch 2900] loss: 0.00701368153328076
[Epoch 13, Batch 3000] loss: 0.013497216217028835
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9864
Overfitting: 0.0504
[Epoch 14, Batch 100] loss: 0.00580203323564092
[Epoch 14, Batch 200] loss: 0.004219422616697557
[Epoch 14, Batch 300] loss: 0.008339893095035222
[Epoch 14, Batch 400] loss: 0.0032430889659895
[Epoch 14, Batch 500] loss: 0.009556213341695638
[Epoch 14, Batch 600] loss: 0.00566437177330954
[Epoch 14, Batch 700] loss: 0.007583793868834618
[Epoch 14, Batch 800] loss: 0.012835200448662362
[Epoch 14, Batch 900] loss: 0.007741425361696201
[Epoch 14, Batch 1000] loss: 0.0029958310458857796
[Epoch 14, Batch 1100] loss: 0.003682282911298671
[Epoch 14, Batch 1200] loss: 0.0073754729052438964
[Epoch 14, Batch 1300] loss: 0.0061187868814965895
[Epoch 14, Batch 1400] loss: 0.010163137635961448
[Epoch 14, Batch 1500] loss: 0.016276303898730474
[Epoch 14, Batch 1600] loss: 0.007633299680387609
[Epoch 14, Batch 1700] loss: 0.008209499924560078
[Epoch 14, Batch 1800] loss: 0.003783737439603101
[Epoch 14, Batch 1900] loss: 0.007229634328907651
[Epoch 14, Batch 2000] loss: 0.004358790776356045
[Epoch 14, Batch 2100] loss: 0.010159177523714504
[Epoch 14, Batch 2200] loss: 0.01567651404656317
[Epoch 14, Batch 2300] loss: 0.01270863205948558
[Epoch 14, Batch 2400] loss: 0.005295388452163934
[Epoch 14, Batch 2500] loss: 0.007572811626459384
[Epoch 14, Batch 2600] loss: 0.010564364516656042
[Epoch 14, Batch 2700] loss: 0.011721412078726417
[Epoch 14, Batch 2800] loss: 0.013868461617045113
[Epoch 14, Batch 2900] loss: 0.006057646376706316
[Epoch 14, Batch 3000] loss: 0.010419096013341686
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9869
Overfitting: 0.0493
[Epoch 15, Batch 100] loss: 0.011546464294326597
[Epoch 15, Batch 200] loss: 0.007797212666765745
[Epoch 15, Batch 300] loss: 0.007536883263815071
[Epoch 15, Batch 400] loss: 0.004770454786635128
[Epoch 15, Batch 500] loss: 0.004112508530683953
[Epoch 15, Batch 600] loss: 0.00924223239628418
[Epoch 15, Batch 700] loss: 0.009512183654496482
[Epoch 15, Batch 800] loss: 0.013080631393544309
[Epoch 15, Batch 900] loss: 0.00907020489451952
[Epoch 15, Batch 1000] loss: 0.00456702202222516
[Epoch 15, Batch 1100] loss: 0.0025570452941929035
[Epoch 15, Batch 1200] loss: 0.007804782391733056
[Epoch 15, Batch 1300] loss: 0.004198506940975903
[Epoch 15, Batch 1400] loss: 0.008669744172129583
[Epoch 15, Batch 1500] loss: 0.006730672998050977
[Epoch 15, Batch 1600] loss: 0.004434044603452775
[Epoch 15, Batch 1700] loss: 0.0023712410851328513
[Epoch 15, Batch 1800] loss: 0.008629625114939471
[Epoch 15, Batch 1900] loss: 0.005050289035778519
[Epoch 15, Batch 2000] loss: 0.007711941107695566
[Epoch 15, Batch 2100] loss: 0.004587029573145856
[Epoch 15, Batch 2200] loss: 0.0059614090332979685
[Epoch 15, Batch 2300] loss: 0.004758260175774467
[Epoch 15, Batch 2400] loss: 0.01011784361251273
[Epoch 15, Batch 2500] loss: 0.008925380868012952
[Epoch 15, Batch 2600] loss: 0.006655940240758013
[Epoch 15, Batch 2700] loss: 0.01170062003760563
[Epoch 15, Batch 2800] loss: 0.009829895785478583
[Epoch 15, Batch 2900] loss: 0.007708656824184459
[Epoch 15, Batch 3000] loss: 0.009910129184507852
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9861
Overfitting: 0.0536
[Epoch 16, Batch 100] loss: 0.005229909951122522
[Epoch 16, Batch 200] loss: 0.005314878394944742
[Epoch 16, Batch 300] loss: 0.0034574005392801156
[Epoch 16, Batch 400] loss: 0.0037198793807817765
[Epoch 16, Batch 500] loss: 0.0017643908389055696
[Epoch 16, Batch 600] loss: 0.004699624527469553
[Epoch 16, Batch 700] loss: 0.013500067946883973
[Epoch 16, Batch 800] loss: 0.0032915928557923735
[Epoch 16, Batch 900] loss: 0.004739852473524025
[Epoch 16, Batch 1000] loss: 0.007274780109491985
[Epoch 16, Batch 1100] loss: 0.01209197252336196
[Epoch 16, Batch 1200] loss: 0.006073603455980674
[Epoch 16, Batch 1300] loss: 0.006006724190597766
[Epoch 16, Batch 1400] loss: 0.002547600372723764
[Epoch 16, Batch 1500] loss: 0.0026569892689531117
[Epoch 16, Batch 1600] loss: 0.003300444083900089
[Epoch 16, Batch 1700] loss: 0.008445667706951383
[Epoch 16, Batch 1800] loss: 0.007756531413017456
[Epoch 16, Batch 1900] loss: 0.006405448645690992
[Epoch 16, Batch 2000] loss: 0.002664005481026379
[Epoch 16, Batch 2100] loss: 0.002877594395341845
[Epoch 16, Batch 2200] loss: 0.008170799470002236
[Epoch 16, Batch 2300] loss: 0.004203053690416709
[Epoch 16, Batch 2400] loss: 0.012324317869277764
[Epoch 16, Batch 2500] loss: 0.004548045007043129
[Epoch 16, Batch 2600] loss: 0.007269954828431509
[Epoch 16, Batch 2700] loss: 0.010985045354238991
[Epoch 16, Batch 2800] loss: 0.010784249247182345
[Epoch 16, Batch 2900] loss: 0.012784072279503107
[Epoch 16, Batch 3000] loss: 0.011013129369009675
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9870
Overfitting: 0.0510
[Epoch 17, Batch 100] loss: 0.004231202344078611
[Epoch 17, Batch 200] loss: 0.0019867238117325316
[Epoch 17, Batch 300] loss: 0.0034719457085355997
[Epoch 17, Batch 400] loss: 0.00782732822987839
[Epoch 17, Batch 500] loss: 0.021365617100878465
[Epoch 17, Batch 600] loss: 0.00843350675207148
[Epoch 17, Batch 700] loss: 0.0018250888293539448
[Epoch 17, Batch 800] loss: 0.00329320449898745
[Epoch 17, Batch 900] loss: 0.0021323157622953203
[Epoch 17, Batch 1000] loss: 0.0014600161162212544
[Epoch 17, Batch 1100] loss: 0.0026652564130952784
[Epoch 17, Batch 1200] loss: 0.0026389371568842535
[Epoch 17, Batch 1300] loss: 0.001995025140535063
[Epoch 17, Batch 1400] loss: 0.0031538770180522136
[Epoch 17, Batch 1500] loss: 0.004170402148682797
[Epoch 17, Batch 1600] loss: 0.006816004792439117
[Epoch 17, Batch 1700] loss: 0.008778028036627462
[Epoch 17, Batch 1800] loss: 0.006658028683596058
[Epoch 17, Batch 1900] loss: 0.01642870699228183
[Epoch 17, Batch 2000] loss: 0.010571628537195465
[Epoch 17, Batch 2100] loss: 0.003256636429333639
[Epoch 17, Batch 2200] loss: 0.008291164646171295
[Epoch 17, Batch 2300] loss: 0.0032581075851175
[Epoch 17, Batch 2400] loss: 0.002646680672079924
[Epoch 17, Batch 2500] loss: 0.006144316770553359
[Epoch 17, Batch 2600] loss: 0.009880504379710402
[Epoch 17, Batch 2700] loss: 0.011388198147088389
[Epoch 17, Batch 2800] loss: 0.008730489379527171
[Epoch 17, Batch 2900] loss: 0.010482008448596503
[Epoch 17, Batch 3000] loss: 0.005636395544194102
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9880
Overfitting: 0.0496
[Epoch 18, Batch 100] loss: 0.005180482500023799
[Epoch 18, Batch 200] loss: 0.006187204720804829
[Epoch 18, Batch 300] loss: 0.003795286286339774
[Epoch 18, Batch 400] loss: 0.004908041427790124
[Epoch 18, Batch 500] loss: 0.0025362593937370546
[Epoch 18, Batch 600] loss: 0.003924588225837055
[Epoch 18, Batch 700] loss: 0.002153033119291621
[Epoch 18, Batch 800] loss: 0.0017688648421837173
[Epoch 18, Batch 900] loss: 0.0015060923227704847
[Epoch 18, Batch 1000] loss: 0.003099448568661316
[Epoch 18, Batch 1100] loss: 0.0027780354428587374
[Epoch 18, Batch 1200] loss: 0.005278369214099996
[Epoch 18, Batch 1300] loss: 0.012620790525683958
[Epoch 18, Batch 1400] loss: 0.004966458340638766
[Epoch 18, Batch 1500] loss: 0.01901384497555853
[Epoch 18, Batch 1600] loss: 0.013834005666865608
[Epoch 18, Batch 1700] loss: 0.018141301648276736
[Epoch 18, Batch 1800] loss: 0.00875235139680683
[Epoch 18, Batch 1900] loss: 0.014823993813238304
[Epoch 18, Batch 2000] loss: 0.007906653101983921
[Epoch 18, Batch 2100] loss: 0.007222748772871768
[Epoch 18, Batch 2200] loss: 0.007469720610509966
[Epoch 18, Batch 2300] loss: 0.0052592751537054025
[Epoch 18, Batch 2400] loss: 0.011799729379100938
[Epoch 18, Batch 2500] loss: 0.008780970117977632
[Epoch 18, Batch 2600] loss: 0.00924963243007369
[Epoch 18, Batch 2700] loss: 0.019514241727534482
[Epoch 18, Batch 2800] loss: 0.016851801455110546
[Epoch 18, Batch 2900] loss: 0.0054257426908253595
[Epoch 18, Batch 3000] loss: 0.0032738718846549377
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0429
Validation Accuracy: 0.9885
Overfitting: 0.0429
[Epoch 19, Batch 100] loss: 0.009654293171121254
[Epoch 19, Batch 200] loss: 0.00520190186308298
[Epoch 19, Batch 300] loss: 0.005242473046429552
[Epoch 19, Batch 400] loss: 0.003464327650936241
[Epoch 19, Batch 500] loss: 0.002147823051083293
[Epoch 19, Batch 600] loss: 0.004110384570931842
[Epoch 19, Batch 700] loss: 0.003772084472496999
[Epoch 19, Batch 800] loss: 0.0030790125243993316
[Epoch 19, Batch 900] loss: 0.0035386930763984027
[Epoch 19, Batch 1000] loss: 0.0047636249652499175
[Epoch 19, Batch 1100] loss: 0.005248644213434659
[Epoch 19, Batch 1200] loss: 0.003369124416239231
[Epoch 19, Batch 1300] loss: 0.0027147170066390202
[Epoch 19, Batch 1400] loss: 0.0033622276889919787
[Epoch 19, Batch 1500] loss: 0.001854224409676135
[Epoch 19, Batch 1600] loss: 0.0047602765640340295
[Epoch 19, Batch 1700] loss: 0.0026866835015641756
[Epoch 19, Batch 1800] loss: 0.0017054535765883827
[Epoch 19, Batch 1900] loss: 0.0019865177989032644
[Epoch 19, Batch 2000] loss: 0.0009346399707376207
[Epoch 19, Batch 2100] loss: 0.003665246092138261
[Epoch 19, Batch 2200] loss: 0.005611153646828804
[Epoch 19, Batch 2300] loss: 0.0035557381147356183
[Epoch 19, Batch 2400] loss: 0.0038903507558926977
[Epoch 19, Batch 2500] loss: 0.004662253632043942
[Epoch 19, Batch 2600] loss: 0.0020344788192642226
[Epoch 19, Batch 2700] loss: 0.0019030554809424415
[Epoch 19, Batch 2800] loss: 0.001781842457469338
[Epoch 19, Batch 2900] loss: 0.002625843328119615
[Epoch 19, Batch 3000] loss: 0.002756450488985962
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9882
Overfitting: 0.0509
[Epoch 20, Batch 100] loss: 0.0008645083457514602
[Epoch 20, Batch 200] loss: 0.0017605294806312833
[Epoch 20, Batch 300] loss: 0.0009719872879659519
[Epoch 20, Batch 400] loss: 0.0026159490749644476
[Epoch 20, Batch 500] loss: 0.0008151005512575793
[Epoch 20, Batch 600] loss: 0.0007500484668032836
[Epoch 20, Batch 700] loss: 0.0038942564863729957
[Epoch 20, Batch 800] loss: 0.0023899088856897065
[Epoch 20, Batch 900] loss: 0.0025218937572434185
[Epoch 20, Batch 1000] loss: 0.001343597128572398
[Epoch 20, Batch 1100] loss: 0.0008415407145984589
[Epoch 20, Batch 1200] loss: 0.0010694309966730842
[Epoch 20, Batch 1300] loss: 0.002841479747106135
[Epoch 20, Batch 1400] loss: 0.0032734270997712756
[Epoch 20, Batch 1500] loss: 0.004955447994307742
[Epoch 20, Batch 1600] loss: 0.0021049292196637028
[Epoch 20, Batch 1700] loss: 0.0019081774491894522
[Epoch 20, Batch 1800] loss: 0.0008310512360090172
[Epoch 20, Batch 1900] loss: 0.0009987267802082922
[Epoch 20, Batch 2000] loss: 0.007790671240428608
[Epoch 20, Batch 2100] loss: 0.0038722066973034684
[Epoch 20, Batch 2200] loss: 0.004458228312429071
[Epoch 20, Batch 2300] loss: 0.0009443132162931533
[Epoch 20, Batch 2400] loss: 0.0028777166472886504
[Epoch 20, Batch 2500] loss: 0.0030363708671218605
[Epoch 20, Batch 2600] loss: 0.005609556915826772
[Epoch 20, Batch 2700] loss: 0.0008981078574201007
[Epoch 20, Batch 2800] loss: 0.001732165653483797
[Epoch 20, Batch 2900] loss: 0.0009207474113908632
[Epoch 20, Batch 3000] loss: 0.0012479156950441972
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9900
Overfitting: 0.0469
[Epoch 21, Batch 100] loss: 0.0008958261923984878
[Epoch 21, Batch 200] loss: 0.0023196052068698058
[Epoch 21, Batch 300] loss: 0.0006137218929177379
[Epoch 21, Batch 400] loss: 0.0017935863767187766
[Epoch 21, Batch 500] loss: 0.002108988531786835
[Epoch 21, Batch 600] loss: 0.0013478642098279892
[Epoch 21, Batch 700] loss: 0.0005206835770899687
[Epoch 21, Batch 800] loss: 0.001029501686726668
[Epoch 21, Batch 900] loss: 0.0009457516880125638
[Epoch 21, Batch 1000] loss: 0.0003465992520960937
[Epoch 21, Batch 1100] loss: 0.0005567536186906352
[Epoch 21, Batch 1200] loss: 0.001195558605046827
[Epoch 21, Batch 1300] loss: 0.0013933385963372303
[Epoch 21, Batch 1400] loss: 0.0006156186256696428
[Epoch 21, Batch 1500] loss: 0.0006675215491953068
[Epoch 21, Batch 1600] loss: 0.0017407822649690274
[Epoch 21, Batch 1700] loss: 0.001490265667074322
[Epoch 21, Batch 1800] loss: 0.0014009145331141816
[Epoch 21, Batch 1900] loss: 0.0006674521459142113
[Epoch 21, Batch 2000] loss: 0.0005855240078378187
[Epoch 21, Batch 2100] loss: 0.0007708774309220478
[Epoch 21, Batch 2200] loss: 0.0007334378216781933
[Epoch 21, Batch 2300] loss: 0.0008103401789919218
[Epoch 21, Batch 2400] loss: 0.0027018233087222664
[Epoch 21, Batch 2500] loss: 0.004249048548352441
[Epoch 21, Batch 2600] loss: 0.0014944245579797055
[Epoch 21, Batch 2700] loss: 0.0010510205401172178
[Epoch 21, Batch 2800] loss: 0.0007450025411458227
[Epoch 21, Batch 2900] loss: 0.0024253794485873705
[Epoch 21, Batch 3000] loss: 0.0037175725527804817
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0517
Validation Accuracy: 0.9886
Overfitting: 0.0517
[Epoch 22, Batch 100] loss: 0.0008153182988048435
[Epoch 22, Batch 200] loss: 0.0018806698620776885
[Epoch 22, Batch 300] loss: 0.0004147372700373975
[Epoch 22, Batch 400] loss: 0.0006071212684916416
[Epoch 22, Batch 500] loss: 0.0010133857723968731
[Epoch 22, Batch 600] loss: 0.0005714500350867891
[Epoch 22, Batch 700] loss: 0.003513897595570761
[Epoch 22, Batch 800] loss: 0.0017607626044876135
[Epoch 22, Batch 900] loss: 0.0047267269090275075
[Epoch 22, Batch 1000] loss: 0.002842850160040875
[Epoch 22, Batch 1100] loss: 0.0002917983227513776
[Epoch 22, Batch 1200] loss: 0.0010363870678422415
[Epoch 22, Batch 1300] loss: 0.0010557892706289707
[Epoch 22, Batch 1400] loss: 0.0011250666662974674
[Epoch 22, Batch 1500] loss: 0.0008816670710505025
[Epoch 22, Batch 1600] loss: 0.0003175413843850761
[Epoch 22, Batch 1700] loss: 0.0007923709385979549
[Epoch 22, Batch 1800] loss: 0.0003957823636997304
[Epoch 22, Batch 1900] loss: 0.0015614118152533507
[Epoch 22, Batch 2000] loss: 0.0014043323814880537
[Epoch 22, Batch 2100] loss: 0.0014315229316139266
[Epoch 22, Batch 2200] loss: 0.00256737151995182
[Epoch 22, Batch 2300] loss: 0.0021236102929899038
[Epoch 22, Batch 2400] loss: 0.00048406449634583735
[Epoch 22, Batch 2500] loss: 0.002081502472932999
[Epoch 22, Batch 2600] loss: 0.0025204214600206853
[Epoch 22, Batch 2700] loss: 0.0004401446410486187
[Epoch 22, Batch 2800] loss: 0.0005402359149653257
[Epoch 22, Batch 2900] loss: 0.003189324566305096
[Epoch 22, Batch 3000] loss: 0.002633752990310896
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9888
Overfitting: 0.0489
[Epoch 23, Batch 100] loss: 0.00369246851521587
[Epoch 23, Batch 200] loss: 0.0012679699160528556
[Epoch 23, Batch 300] loss: 0.0013441155238810155
[Epoch 23, Batch 400] loss: 0.000670563367800554
[Epoch 23, Batch 500] loss: 0.0007269367357949719
[Epoch 23, Batch 600] loss: 0.0003640888485017468
[Epoch 23, Batch 700] loss: 0.0009337334030414679
[Epoch 23, Batch 800] loss: 0.0005286960608998381
[Epoch 23, Batch 900] loss: 0.0006909170439302769
[Epoch 23, Batch 1000] loss: 0.0006539122208619741
[Epoch 23, Batch 1100] loss: 0.0003761967072689565
[Epoch 23, Batch 1200] loss: 0.0011903373728800125
[Epoch 23, Batch 1300] loss: 0.0010623929773264252
[Epoch 23, Batch 1400] loss: 0.0004169580598752187
[Epoch 23, Batch 1500] loss: 0.00040496095409796594
[Epoch 23, Batch 1600] loss: 0.0004518114922475647
[Epoch 23, Batch 1700] loss: 0.00040972559635167995
[Epoch 23, Batch 1800] loss: 0.0004950510472121917
[Epoch 23, Batch 1900] loss: 0.00023516677197383374
[Epoch 23, Batch 2000] loss: 0.001850416339225851
[Epoch 23, Batch 2100] loss: 0.0007652387587292786
[Epoch 23, Batch 2200] loss: 0.00016973866944506533
[Epoch 23, Batch 2300] loss: 0.00037618928647041637
[Epoch 23, Batch 2400] loss: 0.0014210471015464953
[Epoch 23, Batch 2500] loss: 0.0017998179169905627
[Epoch 23, Batch 2600] loss: 0.0006367263259890876
[Epoch 23, Batch 2700] loss: 0.0006277363939927039
[Epoch 23, Batch 2800] loss: 0.0002735088979433664
[Epoch 23, Batch 2900] loss: 0.0007055066870408311
[Epoch 23, Batch 3000] loss: 0.000991311249182889
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9892
Overfitting: 0.0534
[Epoch 24, Batch 100] loss: 0.0003069142635822164
[Epoch 24, Batch 200] loss: 0.00019482590400485834
[Epoch 24, Batch 300] loss: 0.00045467288149844795
[Epoch 24, Batch 400] loss: 0.00035943763729983757
[Epoch 24, Batch 500] loss: 0.0003108232209902662
[Epoch 24, Batch 600] loss: 0.00021670097259512744
[Epoch 24, Batch 700] loss: 0.00021160207017654198
[Epoch 24, Batch 800] loss: 0.000206471660382479
[Epoch 24, Batch 900] loss: 0.00033005207112117406
[Epoch 24, Batch 1000] loss: 0.00034036478437475813
[Epoch 24, Batch 1100] loss: 0.0005046081532033098
[Epoch 24, Batch 1200] loss: 0.0002590301914129789
[Epoch 24, Batch 1300] loss: 0.00026729740348665045
[Epoch 24, Batch 1400] loss: 0.00012561531281175765
[Epoch 24, Batch 1500] loss: 0.00044235155895502756
[Epoch 24, Batch 1600] loss: 0.00027611675158021763
[Epoch 24, Batch 1700] loss: 0.000172376238926768
[Epoch 24, Batch 1800] loss: 0.0004749321471911294
[Epoch 24, Batch 1900] loss: 0.0001622284463327217
[Epoch 24, Batch 2000] loss: 0.00032605789973864317
[Epoch 24, Batch 2100] loss: 0.0001386579618601491
[Epoch 24, Batch 2200] loss: 0.00018019836535609012
[Epoch 24, Batch 2300] loss: 0.00022922428502222036
[Epoch 24, Batch 2400] loss: 0.00030176131459219046
[Epoch 24, Batch 2500] loss: 0.0032878804571567334
[Epoch 24, Batch 2600] loss: 0.00030876426884133055
[Epoch 24, Batch 2700] loss: 0.001971458049286574
[Epoch 24, Batch 2800] loss: 0.0013032150595530246
[Epoch 24, Batch 2900] loss: 0.0009335249214465291
[Epoch 24, Batch 3000] loss: 0.0012391505942847747
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9892
Overfitting: 0.0519
Fold 4 validation loss: 0.0519
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2936805963516234
[Epoch 1, Batch 200] loss: 2.223989634513855
[Epoch 1, Batch 300] loss: 1.6254147171974183
[Epoch 1, Batch 400] loss: 0.6973004700243473
[Epoch 1, Batch 500] loss: 0.5036330063641071
[Epoch 1, Batch 600] loss: 0.37110454887151717
[Epoch 1, Batch 700] loss: 0.3384263298660517
[Epoch 1, Batch 800] loss: 0.2832849110662937
[Epoch 1, Batch 900] loss: 0.2572476536221802
[Epoch 1, Batch 1000] loss: 0.22423668442294
[Epoch 1, Batch 1100] loss: 0.22159446626901627
[Epoch 1, Batch 1200] loss: 0.2086947107128799
[Epoch 1, Batch 1300] loss: 0.1875466892682016
[Epoch 1, Batch 1400] loss: 0.15775995390489697
[Epoch 1, Batch 1500] loss: 0.17628632847219705
[Epoch 1, Batch 1600] loss: 0.1441257567051798
[Epoch 1, Batch 1700] loss: 0.13772514751646667
[Epoch 1, Batch 1800] loss: 0.19655910766683518
[Epoch 1, Batch 1900] loss: 0.15187567024724558
[Epoch 1, Batch 2000] loss: 0.1478534269426018
[Epoch 1, Batch 2100] loss: 0.15367367684841157
[Epoch 1, Batch 2200] loss: 0.14267565394286066
[Epoch 1, Batch 2300] loss: 0.10323641079477966
[Epoch 1, Batch 2400] loss: 0.11343127309926786
[Epoch 1, Batch 2500] loss: 0.12785018714610488
[Epoch 1, Batch 2600] loss: 0.12086463896092027
[Epoch 1, Batch 2700] loss: 0.11646248898701743
[Epoch 1, Batch 2800] loss: 0.0958021957310848
[Epoch 1, Batch 2900] loss: 0.09598073844565079
[Epoch 1, Batch 3000] loss: 0.09046315445681102
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1508
Validation Accuracy: 0.9542
Overfitting: 0.1508
Best model saved at epoch 1 with validation loss: 0.1508
[Epoch 2, Batch 100] loss: 0.09290880515240132
[Epoch 2, Batch 200] loss: 0.09618386167101561
[Epoch 2, Batch 300] loss: 0.08454649678664282
[Epoch 2, Batch 400] loss: 0.11283007129793987
[Epoch 2, Batch 500] loss: 0.08207693133386783
[Epoch 2, Batch 600] loss: 0.09656415411038324
[Epoch 2, Batch 700] loss: 0.06589754044660368
[Epoch 2, Batch 800] loss: 0.10248346836306155
[Epoch 2, Batch 900] loss: 0.10115174846025184
[Epoch 2, Batch 1000] loss: 0.10566585364751518
[Epoch 2, Batch 1100] loss: 0.09681610943982377
[Epoch 2, Batch 1200] loss: 0.06627185645746067
[Epoch 2, Batch 1300] loss: 0.07712085926206783
[Epoch 2, Batch 1400] loss: 0.05969501978252083
[Epoch 2, Batch 1500] loss: 0.09799198855936993
[Epoch 2, Batch 1600] loss: 0.06452564661158249
[Epoch 2, Batch 1700] loss: 0.0898802191449795
[Epoch 2, Batch 1800] loss: 0.07977866624598391
[Epoch 2, Batch 1900] loss: 0.08611927788588218
[Epoch 2, Batch 2000] loss: 0.06698424727306701
[Epoch 2, Batch 2100] loss: 0.08768100582412444
[Epoch 2, Batch 2200] loss: 0.07544775220565497
[Epoch 2, Batch 2300] loss: 0.06493417001969647
[Epoch 2, Batch 2400] loss: 0.06903161837137305
[Epoch 2, Batch 2500] loss: 0.08686848139390349
[Epoch 2, Batch 2600] loss: 0.08411274199606851
[Epoch 2, Batch 2700] loss: 0.07224175711977296
[Epoch 2, Batch 2800] loss: 0.04820049385307357
[Epoch 2, Batch 2900] loss: 0.04456007630767999
[Epoch 2, Batch 3000] loss: 0.05908874901069794
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0784
Validation Accuracy: 0.9758
Overfitting: 0.0784
Best model saved at epoch 2 with validation loss: 0.0784
[Epoch 3, Batch 100] loss: 0.06787291995220585
[Epoch 3, Batch 200] loss: 0.06661411807988771
[Epoch 3, Batch 300] loss: 0.06011767185642384
[Epoch 3, Batch 400] loss: 0.06706923919497058
[Epoch 3, Batch 500] loss: 0.06465503444749629
[Epoch 3, Batch 600] loss: 0.06734040773997549
[Epoch 3, Batch 700] loss: 0.07520546569838188
[Epoch 3, Batch 800] loss: 0.06870635030092671
[Epoch 3, Batch 900] loss: 0.07981959421304055
[Epoch 3, Batch 1000] loss: 0.06789266914653126
[Epoch 3, Batch 1100] loss: 0.05702296628151089
[Epoch 3, Batch 1200] loss: 0.04734019309602445
[Epoch 3, Batch 1300] loss: 0.04779506357182981
[Epoch 3, Batch 1400] loss: 0.05425827419152483
[Epoch 3, Batch 1500] loss: 0.05418916861963226
[Epoch 3, Batch 1600] loss: 0.04692812226974638
[Epoch 3, Batch 1700] loss: 0.03879272172489436
[Epoch 3, Batch 1800] loss: 0.051467880884883924
[Epoch 3, Batch 1900] loss: 0.054900274938554504
[Epoch 3, Batch 2000] loss: 0.038551714841742066
[Epoch 3, Batch 2100] loss: 0.054216593407763865
[Epoch 3, Batch 2200] loss: 0.05910853666922776
[Epoch 3, Batch 2300] loss: 0.04113856542622671
[Epoch 3, Batch 2400] loss: 0.0578620798594784
[Epoch 3, Batch 2500] loss: 0.06301757568260655
[Epoch 3, Batch 2600] loss: 0.05232803946302738
[Epoch 3, Batch 2700] loss: 0.05678880131104961
[Epoch 3, Batch 2800] loss: 0.061525386298890226
[Epoch 3, Batch 2900] loss: 0.05376206412562169
[Epoch 3, Batch 3000] loss: 0.050659671620232986
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0599
Validation Accuracy: 0.9807
Overfitting: 0.0599
Best model saved at epoch 3 with validation loss: 0.0599
[Epoch 4, Batch 100] loss: 0.05116600449371617
[Epoch 4, Batch 200] loss: 0.04678802358714165
[Epoch 4, Batch 300] loss: 0.034461544100486206
[Epoch 4, Batch 400] loss: 0.06003758417558856
[Epoch 4, Batch 500] loss: 0.04108495895532542
[Epoch 4, Batch 600] loss: 0.04690372898170608
[Epoch 4, Batch 700] loss: 0.041981448583828754
[Epoch 4, Batch 800] loss: 0.04192882178380387
[Epoch 4, Batch 900] loss: 0.0425027181749465
[Epoch 4, Batch 1000] loss: 0.04354633592971368
[Epoch 4, Batch 1100] loss: 0.05357427147013368
[Epoch 4, Batch 1200] loss: 0.0512232984660659
[Epoch 4, Batch 1300] loss: 0.04403965408506338
[Epoch 4, Batch 1400] loss: 0.05157749903068179
[Epoch 4, Batch 1500] loss: 0.058169963082909816
[Epoch 4, Batch 1600] loss: 0.031086351683479733
[Epoch 4, Batch 1700] loss: 0.03849317806510953
[Epoch 4, Batch 1800] loss: 0.04488451019438799
[Epoch 4, Batch 1900] loss: 0.0568593596376013
[Epoch 4, Batch 2000] loss: 0.04401207955132122
[Epoch 4, Batch 2100] loss: 0.05747672337834956
[Epoch 4, Batch 2200] loss: 0.03507155550672905
[Epoch 4, Batch 2300] loss: 0.038779228934145066
[Epoch 4, Batch 2400] loss: 0.04530027288943529
[Epoch 4, Batch 2500] loss: 0.04785084811584966
[Epoch 4, Batch 2600] loss: 0.040617648371844554
[Epoch 4, Batch 2700] loss: 0.03723930827574804
[Epoch 4, Batch 2800] loss: 0.040020722972985825
[Epoch 4, Batch 2900] loss: 0.04834047813114012
[Epoch 4, Batch 3000] loss: 0.04335743073228514
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9839
Overfitting: 0.0518
Best model saved at epoch 4 with validation loss: 0.0518
[Epoch 5, Batch 100] loss: 0.027646279551408953
[Epoch 5, Batch 200] loss: 0.03330754366761539
[Epoch 5, Batch 300] loss: 0.02488867359905271
[Epoch 5, Batch 400] loss: 0.02737781639836612
[Epoch 5, Batch 500] loss: 0.038827381344744935
[Epoch 5, Batch 600] loss: 0.045767454915621786
[Epoch 5, Batch 700] loss: 0.03665193390683271
[Epoch 5, Batch 800] loss: 0.04450404070172226
[Epoch 5, Batch 900] loss: 0.050591538659646176
[Epoch 5, Batch 1000] loss: 0.03890084196653334
[Epoch 5, Batch 1100] loss: 0.016497068524186035
[Epoch 5, Batch 1200] loss: 0.01920403113894281
[Epoch 5, Batch 1300] loss: 0.03852949048152368
[Epoch 5, Batch 1400] loss: 0.04404608931770781
[Epoch 5, Batch 1500] loss: 0.03380648387566907
[Epoch 5, Batch 1600] loss: 0.034183242351864464
[Epoch 5, Batch 1700] loss: 0.028839939828030764
[Epoch 5, Batch 1800] loss: 0.025823217093129642
[Epoch 5, Batch 1900] loss: 0.035222774798312456
[Epoch 5, Batch 2000] loss: 0.041683712652084065
[Epoch 5, Batch 2100] loss: 0.045591170845291344
[Epoch 5, Batch 2200] loss: 0.042807003566158526
[Epoch 5, Batch 2300] loss: 0.036748362549114975
[Epoch 5, Batch 2400] loss: 0.03483391542249592
[Epoch 5, Batch 2500] loss: 0.029648095476295565
[Epoch 5, Batch 2600] loss: 0.03881037119288521
[Epoch 5, Batch 2700] loss: 0.0503914002829697
[Epoch 5, Batch 2800] loss: 0.03138139889124432
[Epoch 5, Batch 2900] loss: 0.02706132343337231
[Epoch 5, Batch 3000] loss: 0.04597566494921921
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9839
Overfitting: 0.0529
[Epoch 6, Batch 100] loss: 0.037043662904325175
[Epoch 6, Batch 200] loss: 0.03379321171712945
[Epoch 6, Batch 300] loss: 0.033964378853852395
[Epoch 6, Batch 400] loss: 0.03707293320745521
[Epoch 6, Batch 500] loss: 0.02664010997643345
[Epoch 6, Batch 600] loss: 0.020369877007324247
[Epoch 6, Batch 700] loss: 0.02383407044908381
[Epoch 6, Batch 800] loss: 0.02136795109086961
[Epoch 6, Batch 900] loss: 0.0428026661509648
[Epoch 6, Batch 1000] loss: 0.0324151718824578
[Epoch 6, Batch 1100] loss: 0.030185555261705303
[Epoch 6, Batch 1200] loss: 0.02976296211272711
[Epoch 6, Batch 1300] loss: 0.021983135708251212
[Epoch 6, Batch 1400] loss: 0.026984867724459037
[Epoch 6, Batch 1500] loss: 0.01645883494791633
[Epoch 6, Batch 1600] loss: 0.02918731877100072
[Epoch 6, Batch 1700] loss: 0.02837919073179364
[Epoch 6, Batch 1800] loss: 0.032773914811004945
[Epoch 6, Batch 1900] loss: 0.04668368471931899
[Epoch 6, Batch 2000] loss: 0.027489018213454983
[Epoch 6, Batch 2100] loss: 0.034836307411969754
[Epoch 6, Batch 2200] loss: 0.02650555838114087
[Epoch 6, Batch 2300] loss: 0.05505047630016634
[Epoch 6, Batch 2400] loss: 0.026147771031537557
[Epoch 6, Batch 2500] loss: 0.028830997564218707
[Epoch 6, Batch 2600] loss: 0.025649241941573565
[Epoch 6, Batch 2700] loss: 0.030801454545144224
[Epoch 6, Batch 2800] loss: 0.03704685680764669
[Epoch 6, Batch 2900] loss: 0.027358044573047663
[Epoch 6, Batch 3000] loss: 0.03318667658153572
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0440
Validation Accuracy: 0.9865
Overfitting: 0.0440
Best model saved at epoch 6 with validation loss: 0.0440
[Epoch 7, Batch 100] loss: 0.026322985498991328
[Epoch 7, Batch 200] loss: 0.03183891189910355
[Epoch 7, Batch 300] loss: 0.03590084367286181
[Epoch 7, Batch 400] loss: 0.01932484265358653
[Epoch 7, Batch 500] loss: 0.028145796400276594
[Epoch 7, Batch 600] loss: 0.024141155260585946
[Epoch 7, Batch 700] loss: 0.022467979337016004
[Epoch 7, Batch 800] loss: 0.024487294290593126
[Epoch 7, Batch 900] loss: 0.020357834572932915
[Epoch 7, Batch 1000] loss: 0.03292399619531352
[Epoch 7, Batch 1100] loss: 0.026840434694204305
[Epoch 7, Batch 1200] loss: 0.021930381246711476
[Epoch 7, Batch 1300] loss: 0.01895429864362086
[Epoch 7, Batch 1400] loss: 0.027536395475035533
[Epoch 7, Batch 1500] loss: 0.019503444760539425
[Epoch 7, Batch 1600] loss: 0.038849092668097
[Epoch 7, Batch 1700] loss: 0.018175255505848326
[Epoch 7, Batch 1800] loss: 0.02679492742106959
[Epoch 7, Batch 1900] loss: 0.014913503578136443
[Epoch 7, Batch 2000] loss: 0.022654984894543304
[Epoch 7, Batch 2100] loss: 0.036538803560324594
[Epoch 7, Batch 2200] loss: 0.020942396851314698
[Epoch 7, Batch 2300] loss: 0.03698520452999219
[Epoch 7, Batch 2400] loss: 0.021325691052843466
[Epoch 7, Batch 2500] loss: 0.03318274815173936
[Epoch 7, Batch 2600] loss: 0.03272214260534383
[Epoch 7, Batch 2700] loss: 0.025246859197141022
[Epoch 7, Batch 2800] loss: 0.018415982880760566
[Epoch 7, Batch 2900] loss: 0.026463216087613546
[Epoch 7, Batch 3000] loss: 0.018669537614405273
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0440
Validation Accuracy: 0.9867
Overfitting: 0.0440
[Epoch 8, Batch 100] loss: 0.013106245562667027
[Epoch 8, Batch 200] loss: 0.012765377370324132
[Epoch 8, Batch 300] loss: 0.01921062095811067
[Epoch 8, Batch 400] loss: 0.020438213436736987
[Epoch 8, Batch 500] loss: 0.019079612102050305
[Epoch 8, Batch 600] loss: 0.02134232292395609
[Epoch 8, Batch 700] loss: 0.010944069442994078
[Epoch 8, Batch 800] loss: 0.012507777906539558
[Epoch 8, Batch 900] loss: 0.015832237100694327
[Epoch 8, Batch 1000] loss: 0.021129805695272806
[Epoch 8, Batch 1100] loss: 0.019636304766427203
[Epoch 8, Batch 1200] loss: 0.024059200316187343
[Epoch 8, Batch 1300] loss: 0.025498325090593424
[Epoch 8, Batch 1400] loss: 0.02890057031192555
[Epoch 8, Batch 1500] loss: 0.024273927172398544
[Epoch 8, Batch 1600] loss: 0.018346474021291213
[Epoch 8, Batch 1700] loss: 0.02369482957841683
[Epoch 8, Batch 1800] loss: 0.025588414806079526
[Epoch 8, Batch 1900] loss: 0.025065238716633756
[Epoch 8, Batch 2000] loss: 0.024443810775301243
[Epoch 8, Batch 2100] loss: 0.01714069454708806
[Epoch 8, Batch 2200] loss: 0.021363941789131785
[Epoch 8, Batch 2300] loss: 0.02657223600352154
[Epoch 8, Batch 2400] loss: 0.018076826863980388
[Epoch 8, Batch 2500] loss: 0.022962628766945273
[Epoch 8, Batch 2600] loss: 0.02625643038743874
[Epoch 8, Batch 2700] loss: 0.025217138663865626
[Epoch 8, Batch 2800] loss: 0.02336379045231297
[Epoch 8, Batch 2900] loss: 0.026192333477811188
[Epoch 8, Batch 3000] loss: 0.028721334497022327
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0395
Validation Accuracy: 0.9892
Overfitting: 0.0395
Best model saved at epoch 8 with validation loss: 0.0395
[Epoch 9, Batch 100] loss: 0.011489592150173849
[Epoch 9, Batch 200] loss: 0.01665949842052214
[Epoch 9, Batch 300] loss: 0.01816969394439184
[Epoch 9, Batch 400] loss: 0.018014203111233654
[Epoch 9, Batch 500] loss: 0.0109255972810206
[Epoch 9, Batch 600] loss: 0.010328830752559953
[Epoch 9, Batch 700] loss: 0.01602079436058375
[Epoch 9, Batch 800] loss: 0.010824315762101832
[Epoch 9, Batch 900] loss: 0.017064233331739162
[Epoch 9, Batch 1000] loss: 0.016590911246057657
[Epoch 9, Batch 1100] loss: 0.014799922480196983
[Epoch 9, Batch 1200] loss: 0.01608879917024751
[Epoch 9, Batch 1300] loss: 0.024271193218919507
[Epoch 9, Batch 1400] loss: 0.016182483146185405
[Epoch 9, Batch 1500] loss: 0.010222557679917373
[Epoch 9, Batch 1600] loss: 0.018904863447951357
[Epoch 9, Batch 1700] loss: 0.017690268135684164
[Epoch 9, Batch 1800] loss: 0.010216932562607327
[Epoch 9, Batch 1900] loss: 0.015766443594493466
[Epoch 9, Batch 2000] loss: 0.014141224888689977
[Epoch 9, Batch 2100] loss: 0.03106164749002346
[Epoch 9, Batch 2200] loss: 0.016546967547910754
[Epoch 9, Batch 2300] loss: 0.019071950384295634
[Epoch 9, Batch 2400] loss: 0.02470272688588011
[Epoch 9, Batch 2500] loss: 0.01509854708398052
[Epoch 9, Batch 2600] loss: 0.02515363482399607
[Epoch 9, Batch 2700] loss: 0.016278067164075764
[Epoch 9, Batch 2800] loss: 0.027262201789035316
[Epoch 9, Batch 2900] loss: 0.02189594523872074
[Epoch 9, Batch 3000] loss: 0.013269957549978244
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9871
Overfitting: 0.0465
[Epoch 10, Batch 100] loss: 0.008491502505721655
[Epoch 10, Batch 200] loss: 0.010857125505717704
[Epoch 10, Batch 300] loss: 0.010184578698558653
[Epoch 10, Batch 400] loss: 0.01757456929060936
[Epoch 10, Batch 500] loss: 0.01657544486095503
[Epoch 10, Batch 600] loss: 0.02496948486193105
[Epoch 10, Batch 700] loss: 0.016521707791562222
[Epoch 10, Batch 800] loss: 0.016185077413010732
[Epoch 10, Batch 900] loss: 0.008631208210690602
[Epoch 10, Batch 1000] loss: 0.01688645187763541
[Epoch 10, Batch 1100] loss: 0.013043916978876951
[Epoch 10, Batch 1200] loss: 0.015815004130145097
[Epoch 10, Batch 1300] loss: 0.019053357798820798
[Epoch 10, Batch 1400] loss: 0.011939737821485323
[Epoch 10, Batch 1500] loss: 0.024394853140947817
[Epoch 10, Batch 1600] loss: 0.016285299328246766
[Epoch 10, Batch 1700] loss: 0.009343564136670465
[Epoch 10, Batch 1800] loss: 0.01871065287910824
[Epoch 10, Batch 1900] loss: 0.01986128577888394
[Epoch 10, Batch 2000] loss: 0.00780034855231861
[Epoch 10, Batch 2100] loss: 0.013707574975815078
[Epoch 10, Batch 2200] loss: 0.020025636308582763
[Epoch 10, Batch 2300] loss: 0.022191366621104863
[Epoch 10, Batch 2400] loss: 0.012776895506847267
[Epoch 10, Batch 2500] loss: 0.015692026125616394
[Epoch 10, Batch 2600] loss: 0.010858911345867455
[Epoch 10, Batch 2700] loss: 0.015808292002675445
[Epoch 10, Batch 2800] loss: 0.021699972251426516
[Epoch 10, Batch 2900] loss: 0.020462123467982565
[Epoch 10, Batch 3000] loss: 0.019823942721609457
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0429
Validation Accuracy: 0.9882
Overfitting: 0.0429
[Epoch 11, Batch 100] loss: 0.011417076134748641
[Epoch 11, Batch 200] loss: 0.010211020644223936
[Epoch 11, Batch 300] loss: 0.01027314608335928
[Epoch 11, Batch 400] loss: 0.006737450016466937
[Epoch 11, Batch 500] loss: 0.010010440293244756
[Epoch 11, Batch 600] loss: 0.017757612637260535
[Epoch 11, Batch 700] loss: 0.01759788759822186
[Epoch 11, Batch 800] loss: 0.008019524207238646
[Epoch 11, Batch 900] loss: 0.008884086282387215
[Epoch 11, Batch 1000] loss: 0.014861051963380304
[Epoch 11, Batch 1100] loss: 0.0077738829499867275
[Epoch 11, Batch 1200] loss: 0.00927164597823321
[Epoch 11, Batch 1300] loss: 0.006992250669195527
[Epoch 11, Batch 1400] loss: 0.016057966890348326
[Epoch 11, Batch 1500] loss: 0.0095871141216071
[Epoch 11, Batch 1600] loss: 0.02126551944919811
[Epoch 11, Batch 1700] loss: 0.02174390258060157
[Epoch 11, Batch 1800] loss: 0.008235070045047905
[Epoch 11, Batch 1900] loss: 0.01545470913398276
[Epoch 11, Batch 2000] loss: 0.011099518856790383
[Epoch 11, Batch 2100] loss: 0.013696739763436199
[Epoch 11, Batch 2200] loss: 0.017199574081569153
[Epoch 11, Batch 2300] loss: 0.020779448774405865
[Epoch 11, Batch 2400] loss: 0.009834513455530214
[Epoch 11, Batch 2500] loss: 0.009956016148262279
[Epoch 11, Batch 2600] loss: 0.011457442493028793
[Epoch 11, Batch 2700] loss: 0.012588608006071809
[Epoch 11, Batch 2800] loss: 0.014617211906615921
[Epoch 11, Batch 2900] loss: 0.018040209616028733
[Epoch 11, Batch 3000] loss: 0.016636568622284357
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0396
Validation Accuracy: 0.9886
Overfitting: 0.0396
[Epoch 12, Batch 100] loss: 0.006543558809580645
[Epoch 12, Batch 200] loss: 0.00896444686655741
[Epoch 12, Batch 300] loss: 0.011585611424870877
[Epoch 12, Batch 400] loss: 0.008394032807618714
[Epoch 12, Batch 500] loss: 0.006316802895180444
[Epoch 12, Batch 600] loss: 0.016347518366405894
[Epoch 12, Batch 700] loss: 0.010798966801298776
[Epoch 12, Batch 800] loss: 0.015840953802230617
[Epoch 12, Batch 900] loss: 0.014051615213327295
[Epoch 12, Batch 1000] loss: 0.004903425574193534
[Epoch 12, Batch 1100] loss: 0.005412089768797159
[Epoch 12, Batch 1200] loss: 0.003983004504680139
[Epoch 12, Batch 1300] loss: 0.006977561366817327
[Epoch 12, Batch 1400] loss: 0.010264566001878847
[Epoch 12, Batch 1500] loss: 0.014376563054829603
[Epoch 12, Batch 1600] loss: 0.012069139643906511
[Epoch 12, Batch 1700] loss: 0.010062329789579962
[Epoch 12, Batch 1800] loss: 0.0082895027160248
[Epoch 12, Batch 1900] loss: 0.014695218602801105
[Epoch 12, Batch 2000] loss: 0.013542354541367558
[Epoch 12, Batch 2100] loss: 0.0185141164414199
[Epoch 12, Batch 2200] loss: 0.011655692217518663
[Epoch 12, Batch 2300] loss: 0.019274049097530225
[Epoch 12, Batch 2400] loss: 0.02086632679140166
[Epoch 12, Batch 2500] loss: 0.010434777609065122
[Epoch 12, Batch 2600] loss: 0.01050131790209889
[Epoch 12, Batch 2700] loss: 0.01186871162341049
[Epoch 12, Batch 2800] loss: 0.006138011330003792
[Epoch 12, Batch 2900] loss: 0.008714137692695658
[Epoch 12, Batch 3000] loss: 0.005941782707031962
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9878
Overfitting: 0.0494
[Epoch 13, Batch 100] loss: 0.00555425735017252
[Epoch 13, Batch 200] loss: 0.0050423057581156176
[Epoch 13, Batch 300] loss: 0.011786452715614359
[Epoch 13, Batch 400] loss: 0.007240284069343943
[Epoch 13, Batch 500] loss: 0.01114428147471699
[Epoch 13, Batch 600] loss: 0.005895738552624152
[Epoch 13, Batch 700] loss: 0.004567369125197729
[Epoch 13, Batch 800] loss: 0.010096356272424601
[Epoch 13, Batch 900] loss: 0.004077032130893627
[Epoch 13, Batch 1000] loss: 0.0076501681161516896
[Epoch 13, Batch 1100] loss: 0.007892035459008184
[Epoch 13, Batch 1200] loss: 0.004064236769685294
[Epoch 13, Batch 1300] loss: 0.009164778264992037
[Epoch 13, Batch 1400] loss: 0.011151887893549883
[Epoch 13, Batch 1500] loss: 0.013793622567666261
[Epoch 13, Batch 1600] loss: 0.013151539114303432
[Epoch 13, Batch 1700] loss: 0.01778999578036405
[Epoch 13, Batch 1800] loss: 0.025929402678912084
[Epoch 13, Batch 1900] loss: 0.021363784127934195
[Epoch 13, Batch 2000] loss: 0.01768799601437422
[Epoch 13, Batch 2100] loss: 0.006782739097304784
[Epoch 13, Batch 2200] loss: 0.01947334571917622
[Epoch 13, Batch 2300] loss: 0.008138174892303595
[Epoch 13, Batch 2400] loss: 0.007035276720098409
[Epoch 13, Batch 2500] loss: 0.007673385074667749
[Epoch 13, Batch 2600] loss: 0.01826985492847143
[Epoch 13, Batch 2700] loss: 0.010516927689718614
[Epoch 13, Batch 2800] loss: 0.008900465240242284
[Epoch 13, Batch 2900] loss: 0.007927119636028976
[Epoch 13, Batch 3000] loss: 0.01581863878958984
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0397
Validation Accuracy: 0.9894
Overfitting: 0.0397
[Epoch 14, Batch 100] loss: 0.008406515401165961
[Epoch 14, Batch 200] loss: 0.004594435152523601
[Epoch 14, Batch 300] loss: 0.0032937923014094393
[Epoch 14, Batch 400] loss: 0.0029661186663349783
[Epoch 14, Batch 500] loss: 0.005546465974862258
[Epoch 14, Batch 600] loss: 0.009303772086414029
[Epoch 14, Batch 700] loss: 0.004118640297901948
[Epoch 14, Batch 800] loss: 0.005581657445337669
[Epoch 14, Batch 900] loss: 0.004258900009347144
[Epoch 14, Batch 1000] loss: 0.014897634377237522
[Epoch 14, Batch 1100] loss: 0.008873611566202725
[Epoch 14, Batch 1200] loss: 0.006495688586242067
[Epoch 14, Batch 1300] loss: 0.011986603199453612
[Epoch 14, Batch 1400] loss: 0.00390266991203589
[Epoch 14, Batch 1500] loss: 0.009063012778369739
[Epoch 14, Batch 1600] loss: 0.012056036704334474
[Epoch 14, Batch 1700] loss: 0.009117484268576845
[Epoch 14, Batch 1800] loss: 0.013943202373729946
[Epoch 14, Batch 1900] loss: 0.014077919559159682
[Epoch 14, Batch 2000] loss: 0.016922136453647454
[Epoch 14, Batch 2100] loss: 0.010135077777486004
[Epoch 14, Batch 2200] loss: 0.012699035093216935
[Epoch 14, Batch 2300] loss: 0.010965550336395609
[Epoch 14, Batch 2400] loss: 0.012329891548465638
[Epoch 14, Batch 2500] loss: 0.015518075558929922
[Epoch 14, Batch 2600] loss: 0.012138807692799673
[Epoch 14, Batch 2700] loss: 0.00999799648990006
[Epoch 14, Batch 2800] loss: 0.009825470538720538
[Epoch 14, Batch 2900] loss: 0.005782642266724452
[Epoch 14, Batch 3000] loss: 0.015199314752753707
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9872
Overfitting: 0.0515
[Epoch 15, Batch 100] loss: 0.011732685227273124
[Epoch 15, Batch 200] loss: 0.005091172774787083
[Epoch 15, Batch 300] loss: 0.0045962339905088355
[Epoch 15, Batch 400] loss: 0.004234007333177487
[Epoch 15, Batch 500] loss: 0.008361643834388133
[Epoch 15, Batch 600] loss: 0.005663465457244285
[Epoch 15, Batch 700] loss: 0.013213338291100172
[Epoch 15, Batch 800] loss: 0.0050981108241842325
[Epoch 15, Batch 900] loss: 0.003758813750010006
[Epoch 15, Batch 1000] loss: 0.010165724901589214
[Epoch 15, Batch 1100] loss: 0.011179604915796518
[Epoch 15, Batch 1200] loss: 0.005006409367874198
[Epoch 15, Batch 1300] loss: 0.006846571454211699
[Epoch 15, Batch 1400] loss: 0.005412085074142397
[Epoch 15, Batch 1500] loss: 0.00835998367721004
[Epoch 15, Batch 1600] loss: 0.009091009484050118
[Epoch 15, Batch 1700] loss: 0.0025770307561720075
[Epoch 15, Batch 1800] loss: 0.002806816742553764
[Epoch 15, Batch 1900] loss: 0.014991276331599579
[Epoch 15, Batch 2000] loss: 0.004294850317207875
[Epoch 15, Batch 2100] loss: 0.007175430086488177
[Epoch 15, Batch 2200] loss: 0.009704405188267628
[Epoch 15, Batch 2300] loss: 0.007835597263647288
[Epoch 15, Batch 2400] loss: 0.009644837584019114
[Epoch 15, Batch 2500] loss: 0.00687483583183166
[Epoch 15, Batch 2600] loss: 0.0170765411902471
[Epoch 15, Batch 2700] loss: 0.015417722449228677
[Epoch 15, Batch 2800] loss: 0.0044871015745593466
[Epoch 15, Batch 2900] loss: 0.01041351258111547
[Epoch 15, Batch 3000] loss: 0.010559157855195735
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9873
Overfitting: 0.0474
[Epoch 16, Batch 100] loss: 0.007222192216632947
[Epoch 16, Batch 200] loss: 0.0032064182585834545
[Epoch 16, Batch 300] loss: 0.004511288302902585
[Epoch 16, Batch 400] loss: 0.006251129351745703
[Epoch 16, Batch 500] loss: 0.0030995108298930065
[Epoch 16, Batch 600] loss: 0.007745162287621668
[Epoch 16, Batch 700] loss: 0.006179055169280332
[Epoch 16, Batch 800] loss: 0.0020405547057072227
[Epoch 16, Batch 900] loss: 0.0015505092296808699
[Epoch 16, Batch 1000] loss: 0.0025298026462155575
[Epoch 16, Batch 1100] loss: 0.004781921566200253
[Epoch 16, Batch 1200] loss: 0.0029612998336449436
[Epoch 16, Batch 1300] loss: 0.002115856665639342
[Epoch 16, Batch 1400] loss: 0.00822437476757841
[Epoch 16, Batch 1500] loss: 0.007775275497181724
[Epoch 16, Batch 1600] loss: 0.003714167557175685
[Epoch 16, Batch 1700] loss: 0.004527120289599225
[Epoch 16, Batch 1800] loss: 0.0049903992766462575
[Epoch 16, Batch 1900] loss: 0.005184085631703965
[Epoch 16, Batch 2000] loss: 0.011311355122509071
[Epoch 16, Batch 2100] loss: 0.009968518028327367
[Epoch 16, Batch 2200] loss: 0.007742499560068268
[Epoch 16, Batch 2300] loss: 0.004746634492330486
[Epoch 16, Batch 2400] loss: 0.005852161928254987
[Epoch 16, Batch 2500] loss: 0.00627766033931664
[Epoch 16, Batch 2600] loss: 0.00476974829469384
[Epoch 16, Batch 2700] loss: 0.01071320922629205
[Epoch 16, Batch 2800] loss: 0.0035921649865252904
[Epoch 16, Batch 2900] loss: 0.02136850593137609
[Epoch 16, Batch 3000] loss: 0.01766841468702637
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9881
Overfitting: 0.0458
[Epoch 17, Batch 100] loss: 0.004699897741824088
[Epoch 17, Batch 200] loss: 0.01007038709162316
[Epoch 17, Batch 300] loss: 0.010594415951013616
[Epoch 17, Batch 400] loss: 0.0070422405386068474
[Epoch 17, Batch 500] loss: 0.005906592239687711
[Epoch 17, Batch 600] loss: 0.004052584753721078
[Epoch 17, Batch 700] loss: 0.007459099845037258
[Epoch 17, Batch 800] loss: 0.0035268166638775258
[Epoch 17, Batch 900] loss: 0.009477491699158236
[Epoch 17, Batch 1000] loss: 0.003750768142202787
[Epoch 17, Batch 1100] loss: 0.005342033537851875
[Epoch 17, Batch 1200] loss: 0.0044340782680737335
[Epoch 17, Batch 1300] loss: 0.0032799994837753844
[Epoch 17, Batch 1400] loss: 0.0022278370059905226
[Epoch 17, Batch 1500] loss: 0.0032829408444771248
[Epoch 17, Batch 1600] loss: 0.0015454257467948196
[Epoch 17, Batch 1700] loss: 0.005663791625688077
[Epoch 17, Batch 1800] loss: 0.008347569285631663
[Epoch 17, Batch 1900] loss: 0.007117803766458337
[Epoch 17, Batch 2000] loss: 0.014591214866137535
[Epoch 17, Batch 2100] loss: 0.00617626011908925
[Epoch 17, Batch 2200] loss: 0.004536857976886779
[Epoch 17, Batch 2300] loss: 0.008747147905446583
[Epoch 17, Batch 2400] loss: 0.0023498846624494265
[Epoch 17, Batch 2500] loss: 0.007101215904793321
[Epoch 17, Batch 2600] loss: 0.007149564315013777
[Epoch 17, Batch 2700] loss: 0.006732707525332557
[Epoch 17, Batch 2800] loss: 0.009210764045453458
[Epoch 17, Batch 2900] loss: 0.010074996999075126
[Epoch 17, Batch 3000] loss: 0.005901947775857935
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0503
Validation Accuracy: 0.9886
Overfitting: 0.0503
[Epoch 18, Batch 100] loss: 0.0021857162313290244
[Epoch 18, Batch 200] loss: 0.000904596183450792
[Epoch 18, Batch 300] loss: 0.0015266029838232954
[Epoch 18, Batch 400] loss: 0.0014733533731398295
[Epoch 18, Batch 500] loss: 0.0016402329527163318
[Epoch 18, Batch 600] loss: 0.006131551518789991
[Epoch 18, Batch 700] loss: 0.008528636336117189
[Epoch 18, Batch 800] loss: 0.006794361868023202
[Epoch 18, Batch 900] loss: 0.006419953926738771
[Epoch 18, Batch 1000] loss: 0.0052957503225081835
[Epoch 18, Batch 1100] loss: 0.0046911006183108835
[Epoch 18, Batch 1200] loss: 0.003999924187488659
[Epoch 18, Batch 1300] loss: 0.003928774999891384
[Epoch 18, Batch 1400] loss: 0.0031561077471710065
[Epoch 18, Batch 1500] loss: 0.017916856039528
[Epoch 18, Batch 1600] loss: 0.005002666615250675
[Epoch 18, Batch 1700] loss: 0.007482651087399859
[Epoch 18, Batch 1800] loss: 0.003243462492361999
[Epoch 18, Batch 1900] loss: 0.007220213593052165
[Epoch 18, Batch 2000] loss: 0.006779378883647951
[Epoch 18, Batch 2100] loss: 0.0051323152199216435
[Epoch 18, Batch 2200] loss: 0.004124035988930359
[Epoch 18, Batch 2300] loss: 0.00996372789105294
[Epoch 18, Batch 2400] loss: 0.008191350714040056
[Epoch 18, Batch 2500] loss: 0.007694180938208319
[Epoch 18, Batch 2600] loss: 0.0023977680305080186
[Epoch 18, Batch 2700] loss: 0.0027927763062467648
[Epoch 18, Batch 2800] loss: 0.0031174487988459986
[Epoch 18, Batch 2900] loss: 0.0020309201737799755
[Epoch 18, Batch 3000] loss: 0.0025365405985677113
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0411
Validation Accuracy: 0.9909
Overfitting: 0.0411
[Epoch 19, Batch 100] loss: 0.001101904113222325
[Epoch 19, Batch 200] loss: 0.0010832948894852023
[Epoch 19, Batch 300] loss: 0.0013843778921865636
[Epoch 19, Batch 400] loss: 0.0020880785960852677
[Epoch 19, Batch 500] loss: 0.0008068652579738966
[Epoch 19, Batch 600] loss: 0.00227546965117142
[Epoch 19, Batch 700] loss: 0.0037789911150662193
[Epoch 19, Batch 800] loss: 0.0027853304279301483
[Epoch 19, Batch 900] loss: 0.0012250186444177301
[Epoch 19, Batch 1000] loss: 0.0022974006794040493
[Epoch 19, Batch 1100] loss: 0.003785424087918585
[Epoch 19, Batch 1200] loss: 0.0038283268822578973
[Epoch 19, Batch 1300] loss: 0.002291903542809166
[Epoch 19, Batch 1400] loss: 0.0018342234884789832
[Epoch 19, Batch 1500] loss: 0.0012826514327403515
[Epoch 19, Batch 1600] loss: 0.0017194390505570567
[Epoch 19, Batch 1700] loss: 0.004772916952530792
[Epoch 19, Batch 1800] loss: 0.0009660861832689704
[Epoch 19, Batch 1900] loss: 0.0017740380594671024
[Epoch 19, Batch 2000] loss: 0.0020316534344851076
[Epoch 19, Batch 2100] loss: 0.003548162169563227
[Epoch 19, Batch 2200] loss: 0.0027962050948252683
[Epoch 19, Batch 2300] loss: 0.00281394791552394
[Epoch 19, Batch 2400] loss: 0.002287315462893389
[Epoch 19, Batch 2500] loss: 0.01831862662069092
[Epoch 19, Batch 2600] loss: 0.011374480859987556
[Epoch 19, Batch 2700] loss: 0.009931094227119104
[Epoch 19, Batch 2800] loss: 0.02422923426755858
[Epoch 19, Batch 2900] loss: 0.006696275120712585
[Epoch 19, Batch 3000] loss: 0.009153656959467753
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9877
Overfitting: 0.0525
[Epoch 20, Batch 100] loss: 0.009116138130299873
[Epoch 20, Batch 200] loss: 0.0015452998905675485
[Epoch 20, Batch 300] loss: 0.00311269460239771
[Epoch 20, Batch 400] loss: 0.005335031551494182
[Epoch 20, Batch 500] loss: 0.010750700083369723
[Epoch 20, Batch 600] loss: 0.0070586805502603055
[Epoch 20, Batch 700] loss: 0.006919959108964377
[Epoch 20, Batch 800] loss: 0.0014667453127708541
[Epoch 20, Batch 900] loss: 0.006623359478427027
[Epoch 20, Batch 1000] loss: 0.0016414353091440148
[Epoch 20, Batch 1100] loss: 0.013821507547633019
[Epoch 20, Batch 1200] loss: 0.004965410328126154
[Epoch 20, Batch 1300] loss: 0.0016022605752152685
[Epoch 20, Batch 1400] loss: 0.00342344040646509
[Epoch 20, Batch 1500] loss: 0.002593352492369547
[Epoch 20, Batch 1600] loss: 0.0016268368806827028
[Epoch 20, Batch 1700] loss: 0.008675700873861842
[Epoch 20, Batch 1800] loss: 0.0016638239538822575
[Epoch 20, Batch 1900] loss: 0.004872155861223177
[Epoch 20, Batch 2000] loss: 0.0059592750032811635
[Epoch 20, Batch 2100] loss: 0.007614296437001258
[Epoch 20, Batch 2200] loss: 0.003494121973495368
[Epoch 20, Batch 2300] loss: 0.008861472798845398
[Epoch 20, Batch 2400] loss: 0.007477031379075889
[Epoch 20, Batch 2500] loss: 0.0033203320323895013
[Epoch 20, Batch 2600] loss: 0.01155018517118208
[Epoch 20, Batch 2700] loss: 0.009782479516020005
[Epoch 20, Batch 2800] loss: 0.0026087131148852904
[Epoch 20, Batch 2900] loss: 0.0022725972080655764
[Epoch 20, Batch 3000] loss: 0.0020651378342139994
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9897
Overfitting: 0.0439
[Epoch 21, Batch 100] loss: 0.0024203626219787113
[Epoch 21, Batch 200] loss: 0.0005707061301096416
[Epoch 21, Batch 300] loss: 0.0008571016968039657
[Epoch 21, Batch 400] loss: 0.003323068909550653
[Epoch 21, Batch 500] loss: 0.004417704583799491
[Epoch 21, Batch 600] loss: 0.001946019422776999
[Epoch 21, Batch 700] loss: 0.0009378781844134166
[Epoch 21, Batch 800] loss: 0.005078752414530925
[Epoch 21, Batch 900] loss: 0.011437925504608941
[Epoch 21, Batch 1000] loss: 0.001286260527964842
[Epoch 21, Batch 1100] loss: 0.001920343110336944
[Epoch 21, Batch 1200] loss: 0.001381988556644025
[Epoch 21, Batch 1300] loss: 0.0023414942201258125
[Epoch 21, Batch 1400] loss: 0.003582253655151106
[Epoch 21, Batch 1500] loss: 0.004261787491415276
[Epoch 21, Batch 1600] loss: 0.0044446357554308235
[Epoch 21, Batch 1700] loss: 0.0024633969656076716
[Epoch 21, Batch 1800] loss: 0.0012708781066396568
[Epoch 21, Batch 1900] loss: 0.0029835114314334986
[Epoch 21, Batch 2000] loss: 0.000671919632964375
[Epoch 21, Batch 2100] loss: 0.006412368369629746
[Epoch 21, Batch 2200] loss: 0.0024394710830337374
[Epoch 21, Batch 2300] loss: 0.002292735845236038
[Epoch 21, Batch 2400] loss: 0.0020120645818731474
[Epoch 21, Batch 2500] loss: 0.0013563537954659922
[Epoch 21, Batch 2600] loss: 0.0010099871412010586
[Epoch 21, Batch 2700] loss: 0.00360396734851232
[Epoch 21, Batch 2800] loss: 0.003218544809848964
[Epoch 21, Batch 2900] loss: 0.0014815203024913614
[Epoch 21, Batch 3000] loss: 0.0020308201582322737
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9894
Overfitting: 0.0445
[Epoch 22, Batch 100] loss: 0.00305071775097268
[Epoch 22, Batch 200] loss: 0.004622344632723099
[Epoch 22, Batch 300] loss: 0.003456627989704515
[Epoch 22, Batch 400] loss: 0.003160327971533121
[Epoch 22, Batch 500] loss: 0.0045085422583480295
[Epoch 22, Batch 600] loss: 0.0034447100985664746
[Epoch 22, Batch 700] loss: 0.0015723902927788735
[Epoch 22, Batch 800] loss: 0.0016388468497765985
[Epoch 22, Batch 900] loss: 0.0045225473472891055
[Epoch 22, Batch 1000] loss: 0.005001018862918727
[Epoch 22, Batch 1100] loss: 0.0038284372045603375
[Epoch 22, Batch 1200] loss: 0.00468622572938088
[Epoch 22, Batch 1300] loss: 0.006923175676180335
[Epoch 22, Batch 1400] loss: 0.005718194628249193
[Epoch 22, Batch 1500] loss: 0.0017494408252164107
[Epoch 22, Batch 1600] loss: 0.0010711997369182136
[Epoch 22, Batch 1700] loss: 0.0007152665483096143
[Epoch 22, Batch 1800] loss: 0.000810146636856075
[Epoch 22, Batch 1900] loss: 0.002392562692374689
[Epoch 22, Batch 2000] loss: 0.0007007181285579378
[Epoch 22, Batch 2100] loss: 0.0016457185530768825
[Epoch 22, Batch 2200] loss: 0.006631730366703934
[Epoch 22, Batch 2300] loss: 0.003002238993474009
[Epoch 22, Batch 2400] loss: 0.0029349856339806026
[Epoch 22, Batch 2500] loss: 0.003641972000258402
[Epoch 22, Batch 2600] loss: 0.003976560014935124
[Epoch 22, Batch 2700] loss: 0.00527449676258243
[Epoch 22, Batch 2800] loss: 0.001974649047934491
[Epoch 22, Batch 2900] loss: 0.003125819779403116
[Epoch 22, Batch 3000] loss: 0.0014855920742915174
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9900
Overfitting: 0.0492
[Epoch 23, Batch 100] loss: 0.0014223088149123875
[Epoch 23, Batch 200] loss: 0.002048951539374855
[Epoch 23, Batch 300] loss: 0.0005230150738748307
[Epoch 23, Batch 400] loss: 0.0006435275549770836
[Epoch 23, Batch 500] loss: 0.00033081335251150534
[Epoch 23, Batch 600] loss: 0.00043472329505146235
[Epoch 23, Batch 700] loss: 0.0006954610864149124
[Epoch 23, Batch 800] loss: 0.0005708762668455591
[Epoch 23, Batch 900] loss: 0.0008076475340204148
[Epoch 23, Batch 1000] loss: 0.003620419608424257
[Epoch 23, Batch 1100] loss: 0.0027200462019952455
[Epoch 23, Batch 1200] loss: 0.0040367457491455915
[Epoch 23, Batch 1300] loss: 0.0009822429846810365
[Epoch 23, Batch 1400] loss: 0.001053188208838165
[Epoch 23, Batch 1500] loss: 0.001367831228958485
[Epoch 23, Batch 1600] loss: 0.0007449756882110847
[Epoch 23, Batch 1700] loss: 0.0006590669104165769
[Epoch 23, Batch 1800] loss: 0.00034736534189658383
[Epoch 23, Batch 1900] loss: 0.00038525694151573473
[Epoch 23, Batch 2000] loss: 0.0062366027379889034
[Epoch 23, Batch 2100] loss: 0.0006728817464420755
[Epoch 23, Batch 2200] loss: 0.0014403739331991616
[Epoch 23, Batch 2300] loss: 0.0007875024053843926
[Epoch 23, Batch 2400] loss: 0.003110994026579945
[Epoch 23, Batch 2500] loss: 0.0010503451732489567
[Epoch 23, Batch 2600] loss: 0.00045642075122287907
[Epoch 23, Batch 2700] loss: 0.000804649099644461
[Epoch 23, Batch 2800] loss: 0.0002439175381777936
[Epoch 23, Batch 2900] loss: 0.0015742132848261291
[Epoch 23, Batch 3000] loss: 0.0009407159135833965
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9903
Overfitting: 0.0474
[Epoch 24, Batch 100] loss: 0.0025723106242833537
[Epoch 24, Batch 200] loss: 0.0005080072789617285
[Epoch 24, Batch 300] loss: 0.0023736618122299504
[Epoch 24, Batch 400] loss: 0.0009306238292164437
[Epoch 24, Batch 500] loss: 0.00032197862607965535
[Epoch 24, Batch 600] loss: 0.002312918518814655
[Epoch 24, Batch 700] loss: 0.0017252149614832035
[Epoch 24, Batch 800] loss: 0.0007688439397960734
[Epoch 24, Batch 900] loss: 0.00023094188081735468
[Epoch 24, Batch 1000] loss: 0.008267936509668772
[Epoch 24, Batch 1100] loss: 0.005466518466248829
[Epoch 24, Batch 1200] loss: 0.0012059966650812015
[Epoch 24, Batch 1300] loss: 0.0021522301003990664
[Epoch 24, Batch 1400] loss: 0.005681487897970321
[Epoch 24, Batch 1500] loss: 0.00130308076062434
[Epoch 24, Batch 1600] loss: 0.0012177533108039995
[Epoch 24, Batch 1700] loss: 0.0005121277216715825
[Epoch 24, Batch 1800] loss: 0.004753343829399981
[Epoch 24, Batch 1900] loss: 0.005291988594101147
[Epoch 24, Batch 2000] loss: 0.001556441699756661
[Epoch 24, Batch 2100] loss: 0.005567811456272391
[Epoch 24, Batch 2200] loss: 0.001427837513584791
[Epoch 24, Batch 2300] loss: 0.0018222678952213257
[Epoch 24, Batch 2400] loss: 0.0005955413620268501
[Epoch 24, Batch 2500] loss: 0.0008979025419864595
[Epoch 24, Batch 2600] loss: 0.0005039877436732532
[Epoch 24, Batch 2700] loss: 0.0010666438934443744
[Epoch 24, Batch 2800] loss: 0.0005992044861129031
[Epoch 24, Batch 2900] loss: 0.0013140458572830482
[Epoch 24, Batch 3000] loss: 0.0040545790708527065
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0461
Validation Accuracy: 0.9902
Overfitting: 0.0461
Fold 5 validation loss: 0.0461
Mean validation loss across all folds for Trial 14 is 0.0513 with trial config:  l1: 256, l2: 128, lr: 0.0013627209043248864, batch_size: 16
[I 2024-12-11 05:16:29,478] Trial 13 finished with value: 0.051264334472150286 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0013627209043248864, 'batch_size': 16}. Best is trial 4 with value: 0.046929042829858846.

Selected Hyperparameters for Trial 15:
  l1: 128, l2: 64, lr: 0.0023049529603880324, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.293325891494751
[Epoch 1, Batch 200] loss: 2.2472570514678956
[Epoch 1, Batch 300] loss: 1.668746913075447
[Epoch 1, Batch 400] loss: 0.5404532516002655
[Epoch 1, Batch 500] loss: 0.3604699446260929
[Epoch 1, Batch 600] loss: 0.2511988250166178
[Epoch 1, Batch 700] loss: 0.24082502849400045
**STATS for Epoch 1** : 
Average training loss: 0.0143
Average validation loss: 0.1824
Validation Accuracy: 0.9447
Overfitting: 0.1680
Best model saved at epoch 1 with validation loss: 0.1824
[Epoch 2, Batch 100] loss: 0.18282180693000555
[Epoch 2, Batch 200] loss: 0.16009747136384248
[Epoch 2, Batch 300] loss: 0.1691025086864829
[Epoch 2, Batch 400] loss: 0.1417886273190379
[Epoch 2, Batch 500] loss: 0.1252613467350602
[Epoch 2, Batch 600] loss: 0.13646653465926648
[Epoch 2, Batch 700] loss: 0.11245265245437622
**STATS for Epoch 2** : 
Average training loss: 0.0083
Average validation loss: 0.1200
Validation Accuracy: 0.9585
Overfitting: 0.1117
Best model saved at epoch 2 with validation loss: 0.1200
[Epoch 3, Batch 100] loss: 0.11794385274872184
[Epoch 3, Batch 200] loss: 0.0973221246805042
[Epoch 3, Batch 300] loss: 0.09518405528739095
[Epoch 3, Batch 400] loss: 0.09186154359951615
[Epoch 3, Batch 500] loss: 0.10598984867334366
[Epoch 3, Batch 600] loss: 0.10300582839176059
[Epoch 3, Batch 700] loss: 0.084846559651196
**STATS for Epoch 3** : 
Average training loss: 0.0071
Average validation loss: 0.0765
Validation Accuracy: 0.9750
Overfitting: 0.0694
Best model saved at epoch 3 with validation loss: 0.0765
[Epoch 4, Batch 100] loss: 0.07372746118810028
[Epoch 4, Batch 200] loss: 0.08501115598715842
[Epoch 4, Batch 300] loss: 0.07743936839513481
[Epoch 4, Batch 400] loss: 0.07949428507126868
[Epoch 4, Batch 500] loss: 0.07602982006967068
[Epoch 4, Batch 600] loss: 0.07295194262173027
[Epoch 4, Batch 700] loss: 0.06953025590162724
**STATS for Epoch 4** : 
Average training loss: 0.0052
Average validation loss: 0.0656
Validation Accuracy: 0.9795
Overfitting: 0.0604
Best model saved at epoch 4 with validation loss: 0.0656
[Epoch 5, Batch 100] loss: 0.06841488768812269
[Epoch 5, Batch 200] loss: 0.062159158024005595
[Epoch 5, Batch 300] loss: 0.07777170514687896
[Epoch 5, Batch 400] loss: 0.06547085600439459
[Epoch 5, Batch 500] loss: 0.06344423092901706
[Epoch 5, Batch 600] loss: 0.05931594532448799
[Epoch 5, Batch 700] loss: 0.06790711618028582
**STATS for Epoch 5** : 
Average training loss: 0.0041
Average validation loss: 0.0649
Validation Accuracy: 0.9796
Overfitting: 0.0608
Best model saved at epoch 5 with validation loss: 0.0649
[Epoch 6, Batch 100] loss: 0.05299630060791969
[Epoch 6, Batch 200] loss: 0.05611829809146002
[Epoch 6, Batch 300] loss: 0.05215157302096486
[Epoch 6, Batch 400] loss: 0.05181434576632455
[Epoch 6, Batch 500] loss: 0.05276871992275119
[Epoch 6, Batch 600] loss: 0.0626728402567096
[Epoch 6, Batch 700] loss: 0.060238994269166145
**STATS for Epoch 6** : 
Average training loss: 0.0040
Average validation loss: 0.0674
Validation Accuracy: 0.9787
Overfitting: 0.0634
[I 2024-12-11 05:17:29,528] Trial 14 pruned. 

Selected Hyperparameters for Trial 16:
  l1: 256, l2: 128, lr: 0.00027530847826182466, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3000305247306825
[Epoch 1, Batch 200] loss: 2.2945462369918825
[Epoch 1, Batch 300] loss: 2.2888247752189637
**STATS for Epoch 1** : 
Average training loss: 0.4564
Average validation loss: 2.2797
Validation Accuracy: 0.2823
Overfitting: 1.8233
Best model saved at epoch 1 with validation loss: 2.2797
[Epoch 2, Batch 100] loss: 2.2755581641197207
[Epoch 2, Batch 200] loss: 2.264169433116913
[Epoch 2, Batch 300] loss: 2.2498325371742247
**STATS for Epoch 2** : 
Average training loss: 0.4460
Average validation loss: 2.2198
Validation Accuracy: 0.5212
Overfitting: 1.7738
Best model saved at epoch 2 with validation loss: 2.2198
[Epoch 3, Batch 100] loss: 2.201742172241211
[Epoch 3, Batch 200] loss: 2.1412836480140687
[Epoch 3, Batch 300] loss: 2.0291827690601347
**STATS for Epoch 3** : 
Average training loss: 0.3683
Average validation loss: 1.7169
Validation Accuracy: 0.6905
Overfitting: 1.3486
Best model saved at epoch 3 with validation loss: 1.7169
[Epoch 4, Batch 100] loss: 1.5040067291259767
[Epoch 4, Batch 200] loss: 1.0550248336791992
[Epoch 4, Batch 300] loss: 0.7803678345680237
**STATS for Epoch 4** : 
Average training loss: 0.1304
Average validation loss: 0.5983
Validation Accuracy: 0.8287
Overfitting: 0.4679
Best model saved at epoch 4 with validation loss: 0.5983
[Epoch 5, Batch 100] loss: 0.5798827186226845
[Epoch 5, Batch 200] loss: 0.5141898685693741
[Epoch 5, Batch 300] loss: 0.4728292241692543
**STATS for Epoch 5** : 
Average training loss: 0.0883
Average validation loss: 0.4133
Validation Accuracy: 0.8794
Overfitting: 0.3250
Best model saved at epoch 5 with validation loss: 0.4133
[Epoch 6, Batch 100] loss: 0.42640948697924613
[Epoch 6, Batch 200] loss: 0.3871315601468086
[Epoch 6, Batch 300] loss: 0.3808934850990772
**STATS for Epoch 6** : 
Average training loss: 0.0743
Average validation loss: 0.3461
Validation Accuracy: 0.8984
Overfitting: 0.2718
[I 2024-12-11 05:18:24,396] Trial 15 pruned. 

Selected Hyperparameters for Trial 17:
  l1: 256, l2: 128, lr: 0.007879160621951932, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.4791576486825944
**STATS for Epoch 1** : 
Average training loss: 0.1399
Average validation loss: 0.1850
Validation Accuracy: 0.9443
Overfitting: 0.0451
Best model saved at epoch 1 with validation loss: 0.1850
[Epoch 2, Batch 100] loss: 0.18299643114209174
**STATS for Epoch 2** : 
Average training loss: 0.0629
Average validation loss: 0.0996
Validation Accuracy: 0.9690
Overfitting: 0.0367
Best model saved at epoch 2 with validation loss: 0.0996
[Epoch 3, Batch 100] loss: 0.09992216687649488
**STATS for Epoch 3** : 
Average training loss: 0.0465
Average validation loss: 0.0760
Validation Accuracy: 0.9762
Overfitting: 0.0296
Best model saved at epoch 3 with validation loss: 0.0760
[Epoch 4, Batch 100] loss: 0.08759368984028697
**STATS for Epoch 4** : 
Average training loss: 0.0345
Average validation loss: 0.0690
Validation Accuracy: 0.9774
Overfitting: 0.0345
Best model saved at epoch 4 with validation loss: 0.0690
[Epoch 5, Batch 100] loss: 0.06426512721925974
**STATS for Epoch 5** : 
Average training loss: 0.0284
Average validation loss: 0.0603
Validation Accuracy: 0.9804
Overfitting: 0.0319
Best model saved at epoch 5 with validation loss: 0.0603
[Epoch 6, Batch 100] loss: 0.053018829710781576
**STATS for Epoch 6** : 
Average training loss: 0.0261
Average validation loss: 0.0580
Validation Accuracy: 0.9818
Overfitting: 0.0319
[I 2024-12-11 05:19:17,998] Trial 16 pruned. 

Selected Hyperparameters for Trial 18:
  l1: 128, l2: 64, lr: 0.00023911256355598057, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.300173635482788
**STATS for Epoch 1** : 
Average training loss: 1.0759
Average validation loss: 2.2965
Validation Accuracy: 0.0992
Overfitting: 1.2206
Best model saved at epoch 1 with validation loss: 2.2965
[Epoch 2, Batch 100] loss: 2.296445116996765
**STATS for Epoch 2** : 
Average training loss: 1.0738
Average validation loss: 2.2922
Validation Accuracy: 0.0992
Overfitting: 1.2184
Best model saved at epoch 2 with validation loss: 2.2922
[Epoch 3, Batch 100] loss: 2.291977643966675
**STATS for Epoch 3** : 
Average training loss: 1.0714
Average validation loss: 2.2870
Validation Accuracy: 0.1268
Overfitting: 1.2156
Best model saved at epoch 3 with validation loss: 2.2870
[Epoch 4, Batch 100] loss: 2.286469693183899
**STATS for Epoch 4** : 
Average training loss: 1.0683
Average validation loss: 2.2802
Validation Accuracy: 0.2352
Overfitting: 1.2119
Best model saved at epoch 4 with validation loss: 2.2802
[Epoch 5, Batch 100] loss: 2.278298044204712
**STATS for Epoch 5** : 
Average training loss: 1.0647
Average validation loss: 2.2711
Validation Accuracy: 0.3449
Overfitting: 1.2064
Best model saved at epoch 5 with validation loss: 2.2711
[Epoch 6, Batch 100] loss: 2.2690624046325683
**STATS for Epoch 6** : 
Average training loss: 1.0587
Average validation loss: 2.2581
Validation Accuracy: 0.4037
Overfitting: 1.1994
[I 2024-12-11 05:20:10,980] Trial 17 pruned. 

Selected Hyperparameters for Trial 19:
  l1: 256, l2: 128, lr: 0.001964936455612933, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2946737122535708
[Epoch 1, Batch 200] loss: 2.2618902111053467
[Epoch 1, Batch 300] loss: 1.849609899520874
[Epoch 1, Batch 400] loss: 0.6463026291131974
[Epoch 1, Batch 500] loss: 0.42241298615932465
[Epoch 1, Batch 600] loss: 0.32689182601869105
[Epoch 1, Batch 700] loss: 0.26201741978526116
[Epoch 1, Batch 800] loss: 0.2542184728011489
[Epoch 1, Batch 900] loss: 0.23156292967498301
[Epoch 1, Batch 1000] loss: 0.19915065079927444
[Epoch 1, Batch 1100] loss: 0.17684928499162197
[Epoch 1, Batch 1200] loss: 0.1796470112912357
[Epoch 1, Batch 1300] loss: 0.174817753713578
[Epoch 1, Batch 1400] loss: 0.14307755152694882
[Epoch 1, Batch 1500] loss: 0.13982900573872029
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1627
Validation Accuracy: 0.9477
Overfitting: 0.1627
Best model saved at epoch 1 with validation loss: 0.1627
[Epoch 2, Batch 100] loss: 0.135858694575727
[Epoch 2, Batch 200] loss: 0.12296042617410421
[Epoch 2, Batch 300] loss: 0.11354288782924414
[Epoch 2, Batch 400] loss: 0.10857099924236537
[Epoch 2, Batch 500] loss: 0.11645503571722657
[Epoch 2, Batch 600] loss: 0.1162209296086803
[Epoch 2, Batch 700] loss: 0.0938192970212549
[Epoch 2, Batch 800] loss: 0.09809850847348571
[Epoch 2, Batch 900] loss: 0.0983691621106118
[Epoch 2, Batch 1000] loss: 0.10826937519013882
[Epoch 2, Batch 1100] loss: 0.09947067196946591
[Epoch 2, Batch 1200] loss: 0.09214594316668809
[Epoch 2, Batch 1300] loss: 0.08624389624688775
[Epoch 2, Batch 1400] loss: 0.08792422703467309
[Epoch 2, Batch 1500] loss: 0.09404384588589892
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0790
Validation Accuracy: 0.9760
Overfitting: 0.0790
Best model saved at epoch 2 with validation loss: 0.0790
[Epoch 3, Batch 100] loss: 0.06723052098881453
[Epoch 3, Batch 200] loss: 0.07195178328547627
[Epoch 3, Batch 300] loss: 0.0706334134133067
[Epoch 3, Batch 400] loss: 0.06918742377776653
[Epoch 3, Batch 500] loss: 0.06743685657856986
[Epoch 3, Batch 600] loss: 0.08216196516761556
[Epoch 3, Batch 700] loss: 0.06887568375561387
[Epoch 3, Batch 800] loss: 0.06768777389544994
[Epoch 3, Batch 900] loss: 0.07803524881368502
[Epoch 3, Batch 1000] loss: 0.08131501720519736
[Epoch 3, Batch 1100] loss: 0.08275210655061528
[Epoch 3, Batch 1200] loss: 0.06568777706008405
[Epoch 3, Batch 1300] loss: 0.07259679016424343
[Epoch 3, Batch 1400] loss: 0.07328940332401544
[Epoch 3, Batch 1500] loss: 0.06351736597483977
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9811
Overfitting: 0.0593
Best model saved at epoch 3 with validation loss: 0.0593
[Epoch 4, Batch 100] loss: 0.05571306842379272
[Epoch 4, Batch 200] loss: 0.051686908073024826
[Epoch 4, Batch 300] loss: 0.06098907088511624
[Epoch 4, Batch 400] loss: 0.0652857964031864
[Epoch 4, Batch 500] loss: 0.05324109959881753
[Epoch 4, Batch 600] loss: 0.0644326682947576
[Epoch 4, Batch 700] loss: 0.06337874311720952
[Epoch 4, Batch 800] loss: 0.04683244888670743
[Epoch 4, Batch 900] loss: 0.0657510753790848
[Epoch 4, Batch 1000] loss: 0.05194678912288509
[Epoch 4, Batch 1100] loss: 0.053248326091561465
[Epoch 4, Batch 1200] loss: 0.06084880010923371
[Epoch 4, Batch 1300] loss: 0.05968472068896517
[Epoch 4, Batch 1400] loss: 0.05003400493238587
[Epoch 4, Batch 1500] loss: 0.0502513704172452
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9836
Overfitting: 0.0511
Best model saved at epoch 4 with validation loss: 0.0511
[Epoch 5, Batch 100] loss: 0.030195693231071345
[Epoch 5, Batch 200] loss: 0.03912443674402311
[Epoch 5, Batch 300] loss: 0.054407405638485215
[Epoch 5, Batch 400] loss: 0.04984360680100508
[Epoch 5, Batch 500] loss: 0.04888853710435796
[Epoch 5, Batch 600] loss: 0.04849366320646368
[Epoch 5, Batch 700] loss: 0.05051753194944467
[Epoch 5, Batch 800] loss: 0.037407977449474855
[Epoch 5, Batch 900] loss: 0.04868289429286961
[Epoch 5, Batch 1000] loss: 0.04612558511144016
[Epoch 5, Batch 1100] loss: 0.049257037314819174
[Epoch 5, Batch 1200] loss: 0.044838241185061634
[Epoch 5, Batch 1300] loss: 0.04465237599564716
[Epoch 5, Batch 1400] loss: 0.04800052003120072
[Epoch 5, Batch 1500] loss: 0.057667241132294295
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0600
Validation Accuracy: 0.9808
Overfitting: 0.0600
[Epoch 6, Batch 100] loss: 0.03654626668314449
[Epoch 6, Batch 200] loss: 0.029014241977711207
[Epoch 6, Batch 300] loss: 0.039120992575772104
[Epoch 6, Batch 400] loss: 0.03530102123098913
[Epoch 6, Batch 500] loss: 0.038843377433368007
[Epoch 6, Batch 600] loss: 0.04248941630357876
[Epoch 6, Batch 700] loss: 0.03179227640735917
[Epoch 6, Batch 800] loss: 0.05100763421680313
[Epoch 6, Batch 900] loss: 0.04091649344889447
[Epoch 6, Batch 1000] loss: 0.030114883398637174
[Epoch 6, Batch 1100] loss: 0.0468466406466905
[Epoch 6, Batch 1200] loss: 0.031639768757740966
[Epoch 6, Batch 1300] loss: 0.042078523002564906
[Epoch 6, Batch 1400] loss: 0.0367156067135511
[Epoch 6, Batch 1500] loss: 0.04557910813600756
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9818
Overfitting: 0.0569
[Epoch 7, Batch 100] loss: 0.03449085346597713
[Epoch 7, Batch 200] loss: 0.024792925270448903
[Epoch 7, Batch 300] loss: 0.02290715952141909
[Epoch 7, Batch 400] loss: 0.028898743690224365
[Epoch 7, Batch 500] loss: 0.03624468746507773
[Epoch 7, Batch 600] loss: 0.037874271372566
[Epoch 7, Batch 700] loss: 0.02988662583346013
[Epoch 7, Batch 800] loss: 0.03825359072419815
[Epoch 7, Batch 900] loss: 0.032050651553436185
[Epoch 7, Batch 1000] loss: 0.037180238930595806
[Epoch 7, Batch 1100] loss: 0.034857258289994204
[Epoch 7, Batch 1200] loss: 0.037689331941946874
[Epoch 7, Batch 1300] loss: 0.03825909403094556
[Epoch 7, Batch 1400] loss: 0.041756495681474916
[Epoch 7, Batch 1500] loss: 0.027272537590470165
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0433
Validation Accuracy: 0.9858
Overfitting: 0.0433
Best model saved at epoch 7 with validation loss: 0.0433
[Epoch 8, Batch 100] loss: 0.020386942527256906
[Epoch 8, Batch 200] loss: 0.0274429739714833
[Epoch 8, Batch 300] loss: 0.025354951900953892
[Epoch 8, Batch 400] loss: 0.024689607211912518
[Epoch 8, Batch 500] loss: 0.026271915530087425
[Epoch 8, Batch 600] loss: 0.025302414597390452
[Epoch 8, Batch 700] loss: 0.026145262470090528
[Epoch 8, Batch 800] loss: 0.03111496103607351
[Epoch 8, Batch 900] loss: 0.023470634979894385
[Epoch 8, Batch 1000] loss: 0.034982399444561454
[Epoch 8, Batch 1100] loss: 0.032259744344919454
[Epoch 8, Batch 1200] loss: 0.02727925707353279
[Epoch 8, Batch 1300] loss: 0.03172853529540589
[Epoch 8, Batch 1400] loss: 0.02769531155528966
[Epoch 8, Batch 1500] loss: 0.03065628618671326
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9852
Overfitting: 0.0472
[Epoch 9, Batch 100] loss: 0.01825137553823879
[Epoch 9, Batch 200] loss: 0.023786661741905846
[Epoch 9, Batch 300] loss: 0.0203470292253769
[Epoch 9, Batch 400] loss: 0.021551569317525717
[Epoch 9, Batch 500] loss: 0.022954268228495493
[Epoch 9, Batch 600] loss: 0.02712921432539588
[Epoch 9, Batch 700] loss: 0.02274996316555189
[Epoch 9, Batch 800] loss: 0.0248267332042451
[Epoch 9, Batch 900] loss: 0.025582960688916502
[Epoch 9, Batch 1000] loss: 0.030830653153097954
[Epoch 9, Batch 1100] loss: 0.02773446900653653
[Epoch 9, Batch 1200] loss: 0.026035141223110257
[Epoch 9, Batch 1300] loss: 0.02681943876450532
[Epoch 9, Batch 1400] loss: 0.02735096799384337
[Epoch 9, Batch 1500] loss: 0.015350941840515588
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9864
Overfitting: 0.0422
Best model saved at epoch 9 with validation loss: 0.0422
[Epoch 10, Batch 100] loss: 0.018613828314555575
[Epoch 10, Batch 200] loss: 0.01636481946989079
[Epoch 10, Batch 300] loss: 0.013077682989642198
[Epoch 10, Batch 400] loss: 0.025492810408759396
[Epoch 10, Batch 500] loss: 0.014306577661482151
[Epoch 10, Batch 600] loss: 0.030894856023660395
[Epoch 10, Batch 700] loss: 0.0195115603627346
[Epoch 10, Batch 800] loss: 0.021480394593672826
[Epoch 10, Batch 900] loss: 0.02090969736156694
[Epoch 10, Batch 1000] loss: 0.01940370617681765
[Epoch 10, Batch 1100] loss: 0.022376431522425265
[Epoch 10, Batch 1200] loss: 0.02669447084001149
[Epoch 10, Batch 1300] loss: 0.02315762233491114
[Epoch 10, Batch 1400] loss: 0.02830959678038198
[Epoch 10, Batch 1500] loss: 0.014628643388386991
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9864
Overfitting: 0.0430
[Epoch 11, Batch 100] loss: 0.01207591425656574
[Epoch 11, Batch 200] loss: 0.017042140559933614
[Epoch 11, Batch 300] loss: 0.024993841100949793
[Epoch 11, Batch 400] loss: 0.013880072538813692
[Epoch 11, Batch 500] loss: 0.014713921417423989
[Epoch 11, Batch 600] loss: 0.013909010827301244
[Epoch 11, Batch 700] loss: 0.019292745451602967
[Epoch 11, Batch 800] loss: 0.020438503447076074
[Epoch 11, Batch 900] loss: 0.015836467436529347
[Epoch 11, Batch 1000] loss: 0.015409309066599234
[Epoch 11, Batch 1100] loss: 0.017351012616163643
[Epoch 11, Batch 1200] loss: 0.019233994291134877
[Epoch 11, Batch 1300] loss: 0.015572891375923064
[Epoch 11, Batch 1400] loss: 0.0233935319667944
[Epoch 11, Batch 1500] loss: 0.02244287970923324
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0547
Validation Accuracy: 0.9835
Overfitting: 0.0547
[Epoch 12, Batch 100] loss: 0.015563122237363131
[Epoch 12, Batch 200] loss: 0.0140450115956628
[Epoch 12, Batch 300] loss: 0.01894862532724801
[Epoch 12, Batch 400] loss: 0.02138742920178629
[Epoch 12, Batch 500] loss: 0.016529734846953942
[Epoch 12, Batch 600] loss: 0.017161344915657538
[Epoch 12, Batch 700] loss: 0.012049754213367124
[Epoch 12, Batch 800] loss: 0.01656569246581057
[Epoch 12, Batch 900] loss: 0.010488274136005202
[Epoch 12, Batch 1000] loss: 0.014765854223733187
[Epoch 12, Batch 1100] loss: 0.014390616073469573
[Epoch 12, Batch 1200] loss: 0.01747064634640992
[Epoch 12, Batch 1300] loss: 0.01649221869312896
[Epoch 12, Batch 1400] loss: 0.01956384066834289
[Epoch 12, Batch 1500] loss: 0.024208535304387623
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0423
Validation Accuracy: 0.9877
Overfitting: 0.0423
[Epoch 13, Batch 100] loss: 0.009026691542931075
[Epoch 13, Batch 200] loss: 0.011721987800592614
[Epoch 13, Batch 300] loss: 0.012610991839792404
[Epoch 13, Batch 400] loss: 0.01412269721911798
[Epoch 13, Batch 500] loss: 0.016973551127339306
[Epoch 13, Batch 600] loss: 0.018486890924614273
[Epoch 13, Batch 700] loss: 0.010622126723028487
[Epoch 13, Batch 800] loss: 0.008412344998105255
[Epoch 13, Batch 900] loss: 0.012087695357249685
[Epoch 13, Batch 1000] loss: 0.017658923865164978
[Epoch 13, Batch 1100] loss: 0.019715976324077927
[Epoch 13, Batch 1200] loss: 0.01142138278177299
[Epoch 13, Batch 1300] loss: 0.01253066036311793
[Epoch 13, Batch 1400] loss: 0.012403560183065565
[Epoch 13, Batch 1500] loss: 0.012175712339958409
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9872
Overfitting: 0.0452
[Epoch 14, Batch 100] loss: 0.012984379018125764
[Epoch 14, Batch 200] loss: 0.007598790810807259
[Epoch 14, Batch 300] loss: 0.009094585078910313
[Epoch 14, Batch 400] loss: 0.014245053808481315
[Epoch 14, Batch 500] loss: 0.012699981816485888
[Epoch 14, Batch 600] loss: 0.017578625515434397
[Epoch 14, Batch 700] loss: 0.011193798766689723
[Epoch 14, Batch 800] loss: 0.010619637341005728
[Epoch 14, Batch 900] loss: 0.008965499968653604
[Epoch 14, Batch 1000] loss: 0.012146219327287327
[Epoch 14, Batch 1100] loss: 0.01490595222502634
[Epoch 14, Batch 1200] loss: 0.0138746603663094
[Epoch 14, Batch 1300] loss: 0.012958173450169853
[Epoch 14, Batch 1400] loss: 0.014569024817537865
[Epoch 14, Batch 1500] loss: 0.016215753050032616
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0412
Validation Accuracy: 0.9883
Overfitting: 0.0412
Best model saved at epoch 14 with validation loss: 0.0412
[Epoch 15, Batch 100] loss: 0.007949993841539254
[Epoch 15, Batch 200] loss: 0.005684216332601863
[Epoch 15, Batch 300] loss: 0.010076479295348691
[Epoch 15, Batch 400] loss: 0.007637379441930534
[Epoch 15, Batch 500] loss: 0.005330513726980826
[Epoch 15, Batch 600] loss: 0.012313591635211197
[Epoch 15, Batch 700] loss: 0.012540613497994854
[Epoch 15, Batch 800] loss: 0.0118088584265206
[Epoch 15, Batch 900] loss: 0.014558960337890312
[Epoch 15, Batch 1000] loss: 0.012037189359289187
[Epoch 15, Batch 1100] loss: 0.009456851779723364
[Epoch 15, Batch 1200] loss: 0.011537019924653578
[Epoch 15, Batch 1300] loss: 0.007540452855791955
[Epoch 15, Batch 1400] loss: 0.012113485517438675
[Epoch 15, Batch 1500] loss: 0.012326199190738407
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9864
Overfitting: 0.0495
[Epoch 16, Batch 100] loss: 0.005997158033787855
[Epoch 16, Batch 200] loss: 0.00576257524599896
[Epoch 16, Batch 300] loss: 0.010953877161628043
[Epoch 16, Batch 400] loss: 0.009320137215217983
[Epoch 16, Batch 500] loss: 0.006444740809420182
[Epoch 16, Batch 600] loss: 0.004047123652144364
[Epoch 16, Batch 700] loss: 0.01146518970865145
[Epoch 16, Batch 800] loss: 0.006006995390544034
[Epoch 16, Batch 900] loss: 0.00860909517190521
[Epoch 16, Batch 1000] loss: 0.010077585629396708
[Epoch 16, Batch 1100] loss: 0.005119981291209115
[Epoch 16, Batch 1200] loss: 0.008368805704258193
[Epoch 16, Batch 1300] loss: 0.023585946714802047
[Epoch 16, Batch 1400] loss: 0.014391003152013582
[Epoch 16, Batch 1500] loss: 0.008770442824570637
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9873
Overfitting: 0.0468
[Epoch 17, Batch 100] loss: 0.005645450376225654
[Epoch 17, Batch 200] loss: 0.010921108743783065
[Epoch 17, Batch 300] loss: 0.0034480526069182813
[Epoch 17, Batch 400] loss: 0.0032411871350632284
[Epoch 17, Batch 500] loss: 0.008897784217858772
[Epoch 17, Batch 600] loss: 0.005997655731757732
[Epoch 17, Batch 700] loss: 0.011434159455147893
[Epoch 17, Batch 800] loss: 0.008182783127003858
[Epoch 17, Batch 900] loss: 0.007017262643948925
[Epoch 17, Batch 1000] loss: 0.009048454758449224
[Epoch 17, Batch 1100] loss: 0.006252492684652679
[Epoch 17, Batch 1200] loss: 0.012257883517888786
[Epoch 17, Batch 1300] loss: 0.01033725044872881
[Epoch 17, Batch 1400] loss: 0.008500747191010304
[Epoch 17, Batch 1500] loss: 0.012531206570292852
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9871
Overfitting: 0.0487
[Epoch 18, Batch 100] loss: 0.006848286193981039
[Epoch 18, Batch 200] loss: 0.008358421581428957
[Epoch 18, Batch 300] loss: 0.007929027420339026
[Epoch 18, Batch 400] loss: 0.004960600573067495
[Epoch 18, Batch 500] loss: 0.003107936236335718
[Epoch 18, Batch 600] loss: 0.007350325219449587
[Epoch 18, Batch 700] loss: 0.004949226047256161
[Epoch 18, Batch 800] loss: 0.004295273701809492
[Epoch 18, Batch 900] loss: 0.009641719387218473
[Epoch 18, Batch 1000] loss: 0.0040203650996500076
[Epoch 18, Batch 1100] loss: 0.009940970965649285
[Epoch 18, Batch 1200] loss: 0.011722344250993047
[Epoch 18, Batch 1300] loss: 0.013447820206874895
[Epoch 18, Batch 1400] loss: 0.00971219318516887
[Epoch 18, Batch 1500] loss: 0.008399787488069705
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9882
Overfitting: 0.0462
[Epoch 19, Batch 100] loss: 0.007732636346318032
[Epoch 19, Batch 200] loss: 0.005148841209902457
[Epoch 19, Batch 300] loss: 0.005406859267411619
[Epoch 19, Batch 400] loss: 0.006331806101870825
[Epoch 19, Batch 500] loss: 0.005562682679376394
[Epoch 19, Batch 600] loss: 0.01057720718767996
[Epoch 19, Batch 700] loss: 0.00851016095479281
[Epoch 19, Batch 800] loss: 0.007610914883030091
[Epoch 19, Batch 900] loss: 0.006030928120080717
[Epoch 19, Batch 1000] loss: 0.008641483671999595
[Epoch 19, Batch 1100] loss: 0.0033288072007144364
[Epoch 19, Batch 1200] loss: 0.00496967208573551
[Epoch 19, Batch 1300] loss: 0.004576400216346883
[Epoch 19, Batch 1400] loss: 0.0026945609951280858
[Epoch 19, Batch 1500] loss: 0.012911120416865741
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9872
Overfitting: 0.0543
[Epoch 20, Batch 100] loss: 0.0199789441497569
[Epoch 20, Batch 200] loss: 0.008259262354681596
[Epoch 20, Batch 300] loss: 0.004476110830528342
[Epoch 20, Batch 400] loss: 0.0035214694351884644
[Epoch 20, Batch 500] loss: 0.004349474358009502
[Epoch 20, Batch 600] loss: 0.0026742172384092554
[Epoch 20, Batch 700] loss: 0.002803062655100348
[Epoch 20, Batch 800] loss: 0.005075173692762292
[Epoch 20, Batch 900] loss: 0.0022235502483613345
[Epoch 20, Batch 1000] loss: 0.005048749781940387
[Epoch 20, Batch 1100] loss: 0.007271479043743057
[Epoch 20, Batch 1200] loss: 0.007609356952195867
[Epoch 20, Batch 1300] loss: 0.004702063639833796
[Epoch 20, Batch 1400] loss: 0.006521489342151199
[Epoch 20, Batch 1500] loss: 0.00742173322538747
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9898
Overfitting: 0.0476
[Epoch 21, Batch 100] loss: 0.008742363602167416
[Epoch 21, Batch 200] loss: 0.00308648204131714
[Epoch 21, Batch 300] loss: 0.003425300416101891
[Epoch 21, Batch 400] loss: 0.005272608344250784
[Epoch 21, Batch 500] loss: 0.0040374442975735295
[Epoch 21, Batch 600] loss: 0.005999850715470529
[Epoch 21, Batch 700] loss: 0.005052867415267883
[Epoch 21, Batch 800] loss: 0.003776409869703912
[Epoch 21, Batch 900] loss: 0.004074010608132994
[Epoch 21, Batch 1000] loss: 0.006240609407305442
[Epoch 21, Batch 1100] loss: 0.0049988771133939736
[Epoch 21, Batch 1200] loss: 0.006066677410176453
[Epoch 21, Batch 1300] loss: 0.004053943757312482
[Epoch 21, Batch 1400] loss: 0.004855009522528917
[Epoch 21, Batch 1500] loss: 0.005634083399190786
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9884
Overfitting: 0.0515
[Epoch 22, Batch 100] loss: 0.003329012266835889
[Epoch 22, Batch 200] loss: 0.0019065655547592542
[Epoch 22, Batch 300] loss: 0.0032189267283411027
[Epoch 22, Batch 400] loss: 0.0019924997156022073
[Epoch 22, Batch 500] loss: 0.003786005977220839
[Epoch 22, Batch 600] loss: 0.0011927775084609492
[Epoch 22, Batch 700] loss: 0.002191838336257206
[Epoch 22, Batch 800] loss: 0.0016888409709986264
[Epoch 22, Batch 900] loss: 0.0016216644146356885
[Epoch 22, Batch 1000] loss: 0.005422292379007558
[Epoch 22, Batch 1100] loss: 0.004961314508555006
[Epoch 22, Batch 1200] loss: 0.002681830028946024
[Epoch 22, Batch 1300] loss: 0.0038450677591663407
[Epoch 22, Batch 1400] loss: 0.0052965057654000705
[Epoch 22, Batch 1500] loss: 0.004065180293966932
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0460
Validation Accuracy: 0.9892
Overfitting: 0.0460
[Epoch 23, Batch 100] loss: 0.004136560499804318
[Epoch 23, Batch 200] loss: 0.00272921036611649
[Epoch 23, Batch 300] loss: 0.0011826543675624635
[Epoch 23, Batch 400] loss: 0.002123519609967843
[Epoch 23, Batch 500] loss: 0.0009568795748634784
[Epoch 23, Batch 600] loss: 0.0007887269175967049
[Epoch 23, Batch 700] loss: 0.0012149235591351725
[Epoch 23, Batch 800] loss: 0.0009563200509103354
[Epoch 23, Batch 900] loss: 0.0015355225676535157
[Epoch 23, Batch 1000] loss: 0.0006369817139380984
[Epoch 23, Batch 1100] loss: 0.002098102813477567
[Epoch 23, Batch 1200] loss: 0.000873049162606776
[Epoch 23, Batch 1300] loss: 0.00445836617424618
[Epoch 23, Batch 1400] loss: 0.0020938745516912148
[Epoch 23, Batch 1500] loss: 0.004864237857078706
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9893
Overfitting: 0.0484
[Epoch 24, Batch 100] loss: 0.0012725539296332045
[Epoch 24, Batch 200] loss: 0.001290957615406043
[Epoch 24, Batch 300] loss: 0.0026685686941755192
[Epoch 24, Batch 400] loss: 0.0009771508486130641
[Epoch 24, Batch 500] loss: 0.0020117204970756574
[Epoch 24, Batch 600] loss: 0.0019160625337337933
[Epoch 24, Batch 700] loss: 0.00168373432235569
[Epoch 24, Batch 800] loss: 0.001986013893922518
[Epoch 24, Batch 900] loss: 0.0013414014337809021
[Epoch 24, Batch 1000] loss: 0.0007953023390615499
[Epoch 24, Batch 1100] loss: 0.0026009933311615897
[Epoch 24, Batch 1200] loss: 0.0024258944580674326
[Epoch 24, Batch 1300] loss: 0.006256485861731562
[Epoch 24, Batch 1400] loss: 0.003948189166184193
[Epoch 24, Batch 1500] loss: 0.0009723451808429218
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9893
Overfitting: 0.0491
Fold 1 validation loss: 0.0491
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.250951581001282
[Epoch 1, Batch 200] loss: 1.3012794914841652
[Epoch 1, Batch 300] loss: 0.5560196015238762
[Epoch 1, Batch 400] loss: 0.42264664351940157
[Epoch 1, Batch 500] loss: 0.3533295927196741
[Epoch 1, Batch 600] loss: 0.28521311689168216
[Epoch 1, Batch 700] loss: 0.23604623779654502
[Epoch 1, Batch 800] loss: 0.22692914187908172
[Epoch 1, Batch 900] loss: 0.1984725284576416
[Epoch 1, Batch 1000] loss: 0.18635428708046675
[Epoch 1, Batch 1100] loss: 0.16681469028815626
[Epoch 1, Batch 1200] loss: 0.14484012776985764
[Epoch 1, Batch 1300] loss: 0.1339502151682973
[Epoch 1, Batch 1400] loss: 0.11574516562744976
[Epoch 1, Batch 1500] loss: 0.12290763953700662
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1391
Validation Accuracy: 0.9563
Overfitting: 0.1391
Best model saved at epoch 1 with validation loss: 0.1391
[Epoch 2, Batch 100] loss: 0.11528354470385238
[Epoch 2, Batch 200] loss: 0.10796662230044603
[Epoch 2, Batch 300] loss: 0.10738545564934611
[Epoch 2, Batch 400] loss: 0.1050967588275671
[Epoch 2, Batch 500] loss: 0.11064566200599074
[Epoch 2, Batch 600] loss: 0.08230554923880845
[Epoch 2, Batch 700] loss: 0.08945186006836593
[Epoch 2, Batch 800] loss: 0.0944696332514286
[Epoch 2, Batch 900] loss: 0.10454805343877524
[Epoch 2, Batch 1000] loss: 0.10175162763334811
[Epoch 2, Batch 1100] loss: 0.09420173027552664
[Epoch 2, Batch 1200] loss: 0.07738124192692339
[Epoch 2, Batch 1300] loss: 0.08051984100602567
[Epoch 2, Batch 1400] loss: 0.07929648217512295
[Epoch 2, Batch 1500] loss: 0.0735247278958559
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0976
Validation Accuracy: 0.9698
Overfitting: 0.0976
Best model saved at epoch 2 with validation loss: 0.0976
[Epoch 3, Batch 100] loss: 0.0620785794313997
[Epoch 3, Batch 200] loss: 0.0595055036037229
[Epoch 3, Batch 300] loss: 0.06679753898875788
[Epoch 3, Batch 400] loss: 0.06359390712575987
[Epoch 3, Batch 500] loss: 0.07245813793502748
[Epoch 3, Batch 600] loss: 0.05474195561837405
[Epoch 3, Batch 700] loss: 0.05277287619421259
[Epoch 3, Batch 800] loss: 0.07047256545047276
[Epoch 3, Batch 900] loss: 0.06814027273096145
[Epoch 3, Batch 1000] loss: 0.06649051460903138
[Epoch 3, Batch 1100] loss: 0.06342381515773013
[Epoch 3, Batch 1200] loss: 0.05672624817350879
[Epoch 3, Batch 1300] loss: 0.06176499642431736
[Epoch 3, Batch 1400] loss: 0.07964350360562093
[Epoch 3, Batch 1500] loss: 0.055923171718604864
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0669
Validation Accuracy: 0.9788
Overfitting: 0.0669
Best model saved at epoch 3 with validation loss: 0.0669
[Epoch 4, Batch 100] loss: 0.044884383727330716
[Epoch 4, Batch 200] loss: 0.0555052892526146
[Epoch 4, Batch 300] loss: 0.05329542204504833
[Epoch 4, Batch 400] loss: 0.06492235867073759
[Epoch 4, Batch 500] loss: 0.044757338661002
[Epoch 4, Batch 600] loss: 0.047322845036396756
[Epoch 4, Batch 700] loss: 0.052890634369687176
[Epoch 4, Batch 800] loss: 0.04787493217969313
[Epoch 4, Batch 900] loss: 0.04679518604301847
[Epoch 4, Batch 1000] loss: 0.04430123569443822
[Epoch 4, Batch 1100] loss: 0.045798256915295495
[Epoch 4, Batch 1200] loss: 0.05363068526494317
[Epoch 4, Batch 1300] loss: 0.05245026731165126
[Epoch 4, Batch 1400] loss: 0.0434436610690318
[Epoch 4, Batch 1500] loss: 0.052108312966302035
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9808
Overfitting: 0.0605
Best model saved at epoch 4 with validation loss: 0.0605
[Epoch 5, Batch 100] loss: 0.03633501536969561
[Epoch 5, Batch 200] loss: 0.04688484689278994
[Epoch 5, Batch 300] loss: 0.03751266535487957
[Epoch 5, Batch 400] loss: 0.04806836111063603
[Epoch 5, Batch 500] loss: 0.03966885309491772
[Epoch 5, Batch 600] loss: 0.03541874981252477
[Epoch 5, Batch 700] loss: 0.03379261155438144
[Epoch 5, Batch 800] loss: 0.04493770510947798
[Epoch 5, Batch 900] loss: 0.04275537393637933
[Epoch 5, Batch 1000] loss: 0.03833187841053586
[Epoch 5, Batch 1100] loss: 0.04316990780149354
[Epoch 5, Batch 1200] loss: 0.037580872067483145
[Epoch 5, Batch 1300] loss: 0.038630714712198824
[Epoch 5, Batch 1400] loss: 0.048583932124311106
[Epoch 5, Batch 1500] loss: 0.04279218804789707
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9828
Overfitting: 0.0576
Best model saved at epoch 5 with validation loss: 0.0576
[Epoch 6, Batch 100] loss: 0.023830916507868095
[Epoch 6, Batch 200] loss: 0.03651555272997939
[Epoch 6, Batch 300] loss: 0.03204737359134015
[Epoch 6, Batch 400] loss: 0.027203747552703134
[Epoch 6, Batch 500] loss: 0.0326492069568485
[Epoch 6, Batch 600] loss: 0.03188241486233892
[Epoch 6, Batch 700] loss: 0.02607600024843123
[Epoch 6, Batch 800] loss: 0.03384305415005656
[Epoch 6, Batch 900] loss: 0.029330059837520822
[Epoch 6, Batch 1000] loss: 0.03213657391475863
[Epoch 6, Batch 1100] loss: 0.03493300031987019
[Epoch 6, Batch 1200] loss: 0.03349922673107358
[Epoch 6, Batch 1300] loss: 0.04464342449849937
[Epoch 6, Batch 1400] loss: 0.0441880325000966
[Epoch 6, Batch 1500] loss: 0.03109946844546357
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9852
Overfitting: 0.0515
Best model saved at epoch 6 with validation loss: 0.0515
[Epoch 7, Batch 100] loss: 0.025789681843161816
[Epoch 7, Batch 200] loss: 0.028766706020978746
[Epoch 7, Batch 300] loss: 0.03323250141140306
[Epoch 7, Batch 400] loss: 0.028568524133588652
[Epoch 7, Batch 500] loss: 0.028642520983412398
[Epoch 7, Batch 600] loss: 0.02482336606422905
[Epoch 7, Batch 700] loss: 0.03214015319696045
[Epoch 7, Batch 800] loss: 0.025283704151806887
[Epoch 7, Batch 900] loss: 0.0313522812735755
[Epoch 7, Batch 1000] loss: 0.031183948147809133
[Epoch 7, Batch 1100] loss: 0.024906067051924764
[Epoch 7, Batch 1200] loss: 0.02398586685740156
[Epoch 7, Batch 1300] loss: 0.02158951097873796
[Epoch 7, Batch 1400] loss: 0.02860205368458992
[Epoch 7, Batch 1500] loss: 0.038380150109005626
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9838
Overfitting: 0.0513
Best model saved at epoch 7 with validation loss: 0.0513
[Epoch 8, Batch 100] loss: 0.022957348796189762
[Epoch 8, Batch 200] loss: 0.017007271874463187
[Epoch 8, Batch 300] loss: 0.029763884579588194
[Epoch 8, Batch 400] loss: 0.02047947339247912
[Epoch 8, Batch 500] loss: 0.030043515897996257
[Epoch 8, Batch 600] loss: 0.019386256796569797
[Epoch 8, Batch 700] loss: 0.016539766417408827
[Epoch 8, Batch 800] loss: 0.027454540383478162
[Epoch 8, Batch 900] loss: 0.015426507085066987
[Epoch 8, Batch 1000] loss: 0.020590424202309804
[Epoch 8, Batch 1100] loss: 0.024698930044542065
[Epoch 8, Batch 1200] loss: 0.039264504796010444
[Epoch 8, Batch 1300] loss: 0.024248856354679448
[Epoch 8, Batch 1400] loss: 0.027521181039628573
[Epoch 8, Batch 1500] loss: 0.025846670536266173
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9845
Overfitting: 0.0504
Best model saved at epoch 8 with validation loss: 0.0504
[Epoch 9, Batch 100] loss: 0.01631816694571171
[Epoch 9, Batch 200] loss: 0.01859119077475043
[Epoch 9, Batch 300] loss: 0.020906735669486805
[Epoch 9, Batch 400] loss: 0.018974545703531475
[Epoch 9, Batch 500] loss: 0.019488891069486272
[Epoch 9, Batch 600] loss: 0.016273604087909916
[Epoch 9, Batch 700] loss: 0.017376711534161586
[Epoch 9, Batch 800] loss: 0.023678903722320684
[Epoch 9, Batch 900] loss: 0.02670027482803562
[Epoch 9, Batch 1000] loss: 0.014242403831303818
[Epoch 9, Batch 1100] loss: 0.017394558121377485
[Epoch 9, Batch 1200] loss: 0.020164351986386463
[Epoch 9, Batch 1300] loss: 0.025624337829649447
[Epoch 9, Batch 1400] loss: 0.022610591920092703
[Epoch 9, Batch 1500] loss: 0.027282101550954393
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9863
Overfitting: 0.0495
Best model saved at epoch 9 with validation loss: 0.0495
[Epoch 10, Batch 100] loss: 0.01479367596024531
[Epoch 10, Batch 200] loss: 0.014512097610277124
[Epoch 10, Batch 300] loss: 0.011481666958388814
[Epoch 10, Batch 400] loss: 0.012874907649093074
[Epoch 10, Batch 500] loss: 0.01754714096081443
[Epoch 10, Batch 600] loss: 0.017688987502770034
[Epoch 10, Batch 700] loss: 0.025837477811292045
[Epoch 10, Batch 800] loss: 0.021047008122768603
[Epoch 10, Batch 900] loss: 0.023038640352970107
[Epoch 10, Batch 1000] loss: 0.019005068984188255
[Epoch 10, Batch 1100] loss: 0.014501319326955127
[Epoch 10, Batch 1200] loss: 0.013868166966349236
[Epoch 10, Batch 1300] loss: 0.012742187985131749
[Epoch 10, Batch 1400] loss: 0.02298534690125962
[Epoch 10, Batch 1500] loss: 0.02501930754209752
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9842
Overfitting: 0.0549
[Epoch 11, Batch 100] loss: 0.01584979252413177
[Epoch 11, Batch 200] loss: 0.007057618607759651
[Epoch 11, Batch 300] loss: 0.01742205291884602
[Epoch 11, Batch 400] loss: 0.014928072941984283
[Epoch 11, Batch 500] loss: 0.011218551492020197
[Epoch 11, Batch 600] loss: 0.01910056887383689
[Epoch 11, Batch 700] loss: 0.015245518632764288
[Epoch 11, Batch 800] loss: 0.01845324912101205
[Epoch 11, Batch 900] loss: 0.010132647621285287
[Epoch 11, Batch 1000] loss: 0.022944064576113306
[Epoch 11, Batch 1100] loss: 0.015808867450396065
[Epoch 11, Batch 1200] loss: 0.019197883708256994
[Epoch 11, Batch 1300] loss: 0.014880391120605053
[Epoch 11, Batch 1400] loss: 0.011706080986186862
[Epoch 11, Batch 1500] loss: 0.021035540424927602
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9862
Overfitting: 0.0476
Best model saved at epoch 11 with validation loss: 0.0476
[Epoch 12, Batch 100] loss: 0.011337743693438825
[Epoch 12, Batch 200] loss: 0.013036654372590419
[Epoch 12, Batch 300] loss: 0.012354987770522711
[Epoch 12, Batch 400] loss: 0.010455124859727221
[Epoch 12, Batch 500] loss: 0.011504910061703413
[Epoch 12, Batch 600] loss: 0.008055617542777328
[Epoch 12, Batch 700] loss: 0.011902101635787404
[Epoch 12, Batch 800] loss: 0.02129641773579351
[Epoch 12, Batch 900] loss: 0.014021246710435663
[Epoch 12, Batch 1000] loss: 0.014948971600970253
[Epoch 12, Batch 1100] loss: 0.01733279125401168
[Epoch 12, Batch 1200] loss: 0.013107805558174732
[Epoch 12, Batch 1300] loss: 0.017801306205728906
[Epoch 12, Batch 1400] loss: 0.012116770652355627
[Epoch 12, Batch 1500] loss: 0.01816417206555343
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0563
Validation Accuracy: 0.9839
Overfitting: 0.0563
[Epoch 13, Batch 100] loss: 0.011032732909006882
[Epoch 13, Batch 200] loss: 0.006670982480718521
[Epoch 13, Batch 300] loss: 0.00405446713020865
[Epoch 13, Batch 400] loss: 0.0057614823284529845
[Epoch 13, Batch 500] loss: 0.008064108192793356
[Epoch 13, Batch 600] loss: 0.01590969133967519
[Epoch 13, Batch 700] loss: 0.011687985679491248
[Epoch 13, Batch 800] loss: 0.009002712659894314
[Epoch 13, Batch 900] loss: 0.01328757736908301
[Epoch 13, Batch 1000] loss: 0.011609438425293774
[Epoch 13, Batch 1100] loss: 0.012895212125913531
[Epoch 13, Batch 1200] loss: 0.011899732976207816
[Epoch 13, Batch 1300] loss: 0.015364788233018772
[Epoch 13, Batch 1400] loss: 0.01622862294236256
[Epoch 13, Batch 1500] loss: 0.020327487482027208
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9871
Overfitting: 0.0483
[Epoch 14, Batch 100] loss: 0.009071097620162618
[Epoch 14, Batch 200] loss: 0.011112601301119867
[Epoch 14, Batch 300] loss: 0.0049021598898252704
[Epoch 14, Batch 400] loss: 0.010657202938455157
[Epoch 14, Batch 500] loss: 0.007538624648514087
[Epoch 14, Batch 600] loss: 0.009422623702430428
[Epoch 14, Batch 700] loss: 0.007276941184136377
[Epoch 14, Batch 800] loss: 0.006302891499599355
[Epoch 14, Batch 900] loss: 0.01326598456519605
[Epoch 14, Batch 1000] loss: 0.019364564421866817
[Epoch 14, Batch 1100] loss: 0.011516862952830706
[Epoch 14, Batch 1200] loss: 0.014976228099840228
[Epoch 14, Batch 1300] loss: 0.012043398286077717
[Epoch 14, Batch 1400] loss: 0.01199673391163742
[Epoch 14, Batch 1500] loss: 0.009658184597119543
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9877
Overfitting: 0.0499
[Epoch 15, Batch 100] loss: 0.012509303076622019
[Epoch 15, Batch 200] loss: 0.009403409089536581
[Epoch 15, Batch 300] loss: 0.008750525427640241
[Epoch 15, Batch 400] loss: 0.005862016167448018
[Epoch 15, Batch 500] loss: 0.006976313606210169
[Epoch 15, Batch 600] loss: 0.007341277618797904
[Epoch 15, Batch 700] loss: 0.008646009597396188
[Epoch 15, Batch 800] loss: 0.00834460878275422
[Epoch 15, Batch 900] loss: 0.0073884123054722296
[Epoch 15, Batch 1000] loss: 0.012928979321986844
[Epoch 15, Batch 1100] loss: 0.013622509173892468
[Epoch 15, Batch 1200] loss: 0.01211355716608523
[Epoch 15, Batch 1300] loss: 0.009108405471670267
[Epoch 15, Batch 1400] loss: 0.010776473292862647
[Epoch 15, Batch 1500] loss: 0.005006258918947424
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9883
Overfitting: 0.0493
[Epoch 16, Batch 100] loss: 0.006129422181584232
[Epoch 16, Batch 200] loss: 0.008974188609536214
[Epoch 16, Batch 300] loss: 0.007550507639753051
[Epoch 16, Batch 400] loss: 0.0033289493324809884
[Epoch 16, Batch 500] loss: 0.005154726084042522
[Epoch 16, Batch 600] loss: 0.0063796904059745425
[Epoch 16, Batch 700] loss: 0.00553785310316016
[Epoch 16, Batch 800] loss: 0.007046217745901231
[Epoch 16, Batch 900] loss: 0.012264156190758513
[Epoch 16, Batch 1000] loss: 0.006623093832095037
[Epoch 16, Batch 1100] loss: 0.010890400065245559
[Epoch 16, Batch 1200] loss: 0.011097959583526062
[Epoch 16, Batch 1300] loss: 0.009905276844947367
[Epoch 16, Batch 1400] loss: 0.006109582428016438
[Epoch 16, Batch 1500] loss: 0.007981690964124937
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9860
Overfitting: 0.0544
[Epoch 17, Batch 100] loss: 0.0032372943898508312
[Epoch 17, Batch 200] loss: 0.006296256548644123
[Epoch 17, Batch 300] loss: 0.009809799861468491
[Epoch 17, Batch 400] loss: 0.003914257904580154
[Epoch 17, Batch 500] loss: 0.002687572969421126
[Epoch 17, Batch 600] loss: 0.007570569275999333
[Epoch 17, Batch 700] loss: 0.007318886828361428
[Epoch 17, Batch 800] loss: 0.006335966122765058
[Epoch 17, Batch 900] loss: 0.0038660510566114682
[Epoch 17, Batch 1000] loss: 0.006334663005854963
[Epoch 17, Batch 1100] loss: 0.005990635002240197
[Epoch 17, Batch 1200] loss: 0.005469257418353663
[Epoch 17, Batch 1300] loss: 0.010787461667241587
[Epoch 17, Batch 1400] loss: 0.010693585310518757
[Epoch 17, Batch 1500] loss: 0.011105133958080842
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9874
Overfitting: 0.0549
[Epoch 18, Batch 100] loss: 0.006235437509240001
[Epoch 18, Batch 200] loss: 0.004646517313026379
[Epoch 18, Batch 300] loss: 0.003013687418097106
[Epoch 18, Batch 400] loss: 0.0036180657686736596
[Epoch 18, Batch 500] loss: 0.009309458959951371
[Epoch 18, Batch 600] loss: 0.007569661479783463
[Epoch 18, Batch 700] loss: 0.003857905787551772
[Epoch 18, Batch 800] loss: 0.005949000561577123
[Epoch 18, Batch 900] loss: 0.009973180588731338
[Epoch 18, Batch 1000] loss: 0.006811678734648012
[Epoch 18, Batch 1100] loss: 0.0044051844601926855
[Epoch 18, Batch 1200] loss: 0.00840732256125193
[Epoch 18, Batch 1300] loss: 0.0053434963220752255
[Epoch 18, Batch 1400] loss: 0.0053581273214149405
[Epoch 18, Batch 1500] loss: 0.006281158701367531
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9885
Overfitting: 0.0499
[Epoch 19, Batch 100] loss: 0.005891903874444324
[Epoch 19, Batch 200] loss: 0.004522276755642452
[Epoch 19, Batch 300] loss: 0.0028462652466078
[Epoch 19, Batch 400] loss: 0.0031864416518646976
[Epoch 19, Batch 500] loss: 0.0030467310967674166
[Epoch 19, Batch 600] loss: 0.002150956817079077
[Epoch 19, Batch 700] loss: 0.0017219731633394985
[Epoch 19, Batch 800] loss: 0.003923483556632163
[Epoch 19, Batch 900] loss: 0.006233088972336418
[Epoch 19, Batch 1000] loss: 0.0034692232808333757
[Epoch 19, Batch 1100] loss: 0.0023634265136138312
[Epoch 19, Batch 1200] loss: 0.005284903116330497
[Epoch 19, Batch 1300] loss: 0.005339368096392718
[Epoch 19, Batch 1400] loss: 0.0027857991905557355
[Epoch 19, Batch 1500] loss: 0.005366712977634052
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0517
Validation Accuracy: 0.9882
Overfitting: 0.0517
[Epoch 20, Batch 100] loss: 0.0025500017773538277
[Epoch 20, Batch 200] loss: 0.002486692617251265
[Epoch 20, Batch 300] loss: 0.001897332586390803
[Epoch 20, Batch 400] loss: 0.0015664060169456207
[Epoch 20, Batch 500] loss: 0.0019133518531077697
[Epoch 20, Batch 600] loss: 0.0018029539193912569
[Epoch 20, Batch 700] loss: 0.0021568459550326225
[Epoch 20, Batch 800] loss: 0.01071134839349952
[Epoch 20, Batch 900] loss: 0.005443135677078317
[Epoch 20, Batch 1000] loss: 0.004221682632241937
[Epoch 20, Batch 1100] loss: 0.005960542015964734
[Epoch 20, Batch 1200] loss: 0.002534245577298293
[Epoch 20, Batch 1300] loss: 0.0035937142335990303
[Epoch 20, Batch 1400] loss: 0.007118991174722851
[Epoch 20, Batch 1500] loss: 0.00896175617025392
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0643
Validation Accuracy: 0.9854
Overfitting: 0.0643
[Epoch 21, Batch 100] loss: 0.0036084991739608087
[Epoch 21, Batch 200] loss: 0.004851217183968402
[Epoch 21, Batch 300] loss: 0.004235258899007022
[Epoch 21, Batch 400] loss: 0.004091817386836283
[Epoch 21, Batch 500] loss: 0.003417533151368843
[Epoch 21, Batch 600] loss: 0.0017261996739949836
[Epoch 21, Batch 700] loss: 0.0024882316230196012
[Epoch 21, Batch 800] loss: 0.0022779392841709976
[Epoch 21, Batch 900] loss: 0.002038859324384248
[Epoch 21, Batch 1000] loss: 0.0027665131745766305
[Epoch 21, Batch 1100] loss: 0.0009635616434923122
[Epoch 21, Batch 1200] loss: 0.0013063295313156687
[Epoch 21, Batch 1300] loss: 0.006193779065370109
[Epoch 21, Batch 1400] loss: 0.005519102998428025
[Epoch 21, Batch 1500] loss: 0.005430859906488195
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9879
Overfitting: 0.0573
[Epoch 22, Batch 100] loss: 0.00381808285531406
[Epoch 22, Batch 200] loss: 0.001985582108565609
[Epoch 22, Batch 300] loss: 0.0020083701840258074
[Epoch 22, Batch 400] loss: 0.00511782408250383
[Epoch 22, Batch 500] loss: 0.002292552022640848
[Epoch 22, Batch 600] loss: 0.0012070970332206344
[Epoch 22, Batch 700] loss: 0.00458107408216847
[Epoch 22, Batch 800] loss: 0.0031250048399203935
[Epoch 22, Batch 900] loss: 0.009076319772560452
[Epoch 22, Batch 1000] loss: 0.0019082173844481077
[Epoch 22, Batch 1100] loss: 0.0026610374731990305
[Epoch 22, Batch 1200] loss: 0.0012038752486932935
[Epoch 22, Batch 1300] loss: 0.0025618359978739134
[Epoch 22, Batch 1400] loss: 0.0019836683483356408
[Epoch 22, Batch 1500] loss: 0.0027955721145417555
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9879
Overfitting: 0.0573
[Epoch 23, Batch 100] loss: 0.001371662933420339
[Epoch 23, Batch 200] loss: 0.0006768369349038039
[Epoch 23, Batch 300] loss: 0.0010727382307538847
[Epoch 23, Batch 400] loss: 0.0005553104472130599
[Epoch 23, Batch 500] loss: 0.002209605457675252
[Epoch 23, Batch 600] loss: 0.0009708673267937229
[Epoch 23, Batch 700] loss: 0.0013209111153703644
[Epoch 23, Batch 800] loss: 0.003109479515142084
[Epoch 23, Batch 900] loss: 0.0013076717941163452
[Epoch 23, Batch 1000] loss: 0.0020524115684361277
[Epoch 23, Batch 1100] loss: 0.0021347242936963083
[Epoch 23, Batch 1200] loss: 0.0011885036442322416
[Epoch 23, Batch 1300] loss: 0.0017376206782205373
[Epoch 23, Batch 1400] loss: 0.0010468155998819384
[Epoch 23, Batch 1500] loss: 0.001868623919849597
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9871
Overfitting: 0.0606
[Epoch 24, Batch 100] loss: 0.0009558982007175132
[Epoch 24, Batch 200] loss: 0.0006522345011904918
[Epoch 24, Batch 300] loss: 0.0020843859288424936
[Epoch 24, Batch 400] loss: 0.0009558892449254585
[Epoch 24, Batch 500] loss: 0.0006493441676235534
[Epoch 24, Batch 600] loss: 0.0009892448029222578
[Epoch 24, Batch 700] loss: 0.0008688278065744725
[Epoch 24, Batch 800] loss: 0.0018095105025986414
[Epoch 24, Batch 900] loss: 0.0006499865590136267
[Epoch 24, Batch 1000] loss: 0.0007327577770792005
[Epoch 24, Batch 1100] loss: 0.0005115541361601573
[Epoch 24, Batch 1200] loss: 0.0014593962002828675
[Epoch 24, Batch 1300] loss: 0.0011400503980716792
[Epoch 24, Batch 1400] loss: 0.0012496396762708172
[Epoch 24, Batch 1500] loss: 0.001488102935303459
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0591
Validation Accuracy: 0.9877
Overfitting: 0.0591
Fold 2 validation loss: 0.0591
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2974617886543274
[Epoch 1, Batch 200] loss: 2.272599856853485
[Epoch 1, Batch 300] loss: 2.0898070585727693
[Epoch 1, Batch 400] loss: 0.9761352652311325
[Epoch 1, Batch 500] loss: 0.5167479540407658
[Epoch 1, Batch 600] loss: 0.38166184730827807
[Epoch 1, Batch 700] loss: 0.34595298156142235
[Epoch 1, Batch 800] loss: 0.2855178142338991
[Epoch 1, Batch 900] loss: 0.25765241771936415
[Epoch 1, Batch 1000] loss: 0.20791317380964755
[Epoch 1, Batch 1100] loss: 0.17639863517135382
[Epoch 1, Batch 1200] loss: 0.1757447918690741
[Epoch 1, Batch 1300] loss: 0.16771033169701696
[Epoch 1, Batch 1400] loss: 0.1451033036503941
[Epoch 1, Batch 1500] loss: 0.1302112621627748
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1400
Validation Accuracy: 0.9583
Overfitting: 0.1400
Best model saved at epoch 1 with validation loss: 0.1400
[Epoch 2, Batch 100] loss: 0.13063326586037874
[Epoch 2, Batch 200] loss: 0.1350506888050586
[Epoch 2, Batch 300] loss: 0.12172849208116532
[Epoch 2, Batch 400] loss: 0.12080532882362605
[Epoch 2, Batch 500] loss: 0.09207029605749995
[Epoch 2, Batch 600] loss: 0.1084906271006912
[Epoch 2, Batch 700] loss: 0.09136673794593662
[Epoch 2, Batch 800] loss: 0.10792094081640244
[Epoch 2, Batch 900] loss: 0.11769424012862145
[Epoch 2, Batch 1000] loss: 0.09818986227735876
[Epoch 2, Batch 1100] loss: 0.10447248339187354
[Epoch 2, Batch 1200] loss: 0.11320064229890704
[Epoch 2, Batch 1300] loss: 0.08074065923690796
[Epoch 2, Batch 1400] loss: 0.0771079210471362
[Epoch 2, Batch 1500] loss: 0.08999510882189497
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0937
Validation Accuracy: 0.9700
Overfitting: 0.0937
Best model saved at epoch 2 with validation loss: 0.0937
[Epoch 3, Batch 100] loss: 0.0844677287293598
[Epoch 3, Batch 200] loss: 0.06614143992308527
[Epoch 3, Batch 300] loss: 0.08028276579454541
[Epoch 3, Batch 400] loss: 0.06655827855225653
[Epoch 3, Batch 500] loss: 0.09498134020133875
[Epoch 3, Batch 600] loss: 0.07433162086410448
[Epoch 3, Batch 700] loss: 0.07581093906774186
[Epoch 3, Batch 800] loss: 0.06847815844463184
[Epoch 3, Batch 900] loss: 0.0680259167496115
[Epoch 3, Batch 1000] loss: 0.07541368150385097
[Epoch 3, Batch 1100] loss: 0.0801116095785983
[Epoch 3, Batch 1200] loss: 0.058396136830560864
[Epoch 3, Batch 1300] loss: 0.06217587739927694
[Epoch 3, Batch 1400] loss: 0.07173514864174649
[Epoch 3, Batch 1500] loss: 0.07038333739619702
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0772
Validation Accuracy: 0.9758
Overfitting: 0.0772
Best model saved at epoch 3 with validation loss: 0.0772
[Epoch 4, Batch 100] loss: 0.062030113665387035
[Epoch 4, Batch 200] loss: 0.05666055235080421
[Epoch 4, Batch 300] loss: 0.06450542785227299
[Epoch 4, Batch 400] loss: 0.0562174066551961
[Epoch 4, Batch 500] loss: 0.0496015463466756
[Epoch 4, Batch 600] loss: 0.06966130884247831
[Epoch 4, Batch 700] loss: 0.05818964226171374
[Epoch 4, Batch 800] loss: 0.05069280783412978
[Epoch 4, Batch 900] loss: 0.04900240674731322
[Epoch 4, Batch 1000] loss: 0.062130266768508594
[Epoch 4, Batch 1100] loss: 0.05761462759459391
[Epoch 4, Batch 1200] loss: 0.06011834123404697
[Epoch 4, Batch 1300] loss: 0.061367947614053266
[Epoch 4, Batch 1400] loss: 0.048334182220278306
[Epoch 4, Batch 1500] loss: 0.06048974870645907
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0620
Validation Accuracy: 0.9812
Overfitting: 0.0620
Best model saved at epoch 4 with validation loss: 0.0620
[Epoch 5, Batch 100] loss: 0.03413216245477088
[Epoch 5, Batch 200] loss: 0.04901894865790382
[Epoch 5, Batch 300] loss: 0.04941287748020841
[Epoch 5, Batch 400] loss: 0.04758477539930027
[Epoch 5, Batch 500] loss: 0.04589524657698348
[Epoch 5, Batch 600] loss: 0.04127698836964555
[Epoch 5, Batch 700] loss: 0.044463566046906634
[Epoch 5, Batch 800] loss: 0.05118438249977771
[Epoch 5, Batch 900] loss: 0.04899308594525792
[Epoch 5, Batch 1000] loss: 0.04436785765807144
[Epoch 5, Batch 1100] loss: 0.05265643509279471
[Epoch 5, Batch 1200] loss: 0.042881868434487845
[Epoch 5, Batch 1300] loss: 0.04646649188012816
[Epoch 5, Batch 1400] loss: 0.05331192367651966
[Epoch 5, Batch 1500] loss: 0.05392309042741544
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0583
Validation Accuracy: 0.9822
Overfitting: 0.0583
Best model saved at epoch 5 with validation loss: 0.0583
[Epoch 6, Batch 100] loss: 0.03778791967954021
[Epoch 6, Batch 200] loss: 0.03351920409302693
[Epoch 6, Batch 300] loss: 0.046580211798427626
[Epoch 6, Batch 400] loss: 0.03947472834319342
[Epoch 6, Batch 500] loss: 0.04076521352806594
[Epoch 6, Batch 600] loss: 0.03690794239693787
[Epoch 6, Batch 700] loss: 0.04132692308165133
[Epoch 6, Batch 800] loss: 0.044963988283998335
[Epoch 6, Batch 900] loss: 0.04355805401224643
[Epoch 6, Batch 1000] loss: 0.03795443991431966
[Epoch 6, Batch 1100] loss: 0.03343667900539003
[Epoch 6, Batch 1200] loss: 0.041071389057906346
[Epoch 6, Batch 1300] loss: 0.03770911925646942
[Epoch 6, Batch 1400] loss: 0.04664353221596684
[Epoch 6, Batch 1500] loss: 0.04153714827727526
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9795
Overfitting: 0.0635
[Epoch 7, Batch 100] loss: 0.03406322121503763
[Epoch 7, Batch 200] loss: 0.0453609381505521
[Epoch 7, Batch 300] loss: 0.03840636289212853
[Epoch 7, Batch 400] loss: 0.033404459868907
[Epoch 7, Batch 500] loss: 0.032247653694357725
[Epoch 7, Batch 600] loss: 0.03553662978461944
[Epoch 7, Batch 700] loss: 0.039702971762162635
[Epoch 7, Batch 800] loss: 0.026709926991024986
[Epoch 7, Batch 900] loss: 0.029392488175653854
[Epoch 7, Batch 1000] loss: 0.036569918630702886
[Epoch 7, Batch 1100] loss: 0.048720875589060596
[Epoch 7, Batch 1200] loss: 0.021845838825101965
[Epoch 7, Batch 1300] loss: 0.03516527422165382
[Epoch 7, Batch 1400] loss: 0.019782202660280745
[Epoch 7, Batch 1500] loss: 0.03663851191464346
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0617
Validation Accuracy: 0.9819
Overfitting: 0.0617
[Epoch 8, Batch 100] loss: 0.024127506980730688
[Epoch 8, Batch 200] loss: 0.023311378789658194
[Epoch 8, Batch 300] loss: 0.03140006735688075
[Epoch 8, Batch 400] loss: 0.02631358909129631
[Epoch 8, Batch 500] loss: 0.023800313139508943
[Epoch 8, Batch 600] loss: 0.035185229681083
[Epoch 8, Batch 700] loss: 0.029359314097964672
[Epoch 8, Batch 800] loss: 0.033785863122611774
[Epoch 8, Batch 900] loss: 0.04141559760697419
[Epoch 8, Batch 1000] loss: 0.0381292121388833
[Epoch 8, Batch 1100] loss: 0.021207160836202093
[Epoch 8, Batch 1200] loss: 0.025761507097631694
[Epoch 8, Batch 1300] loss: 0.036736531718343034
[Epoch 8, Batch 1400] loss: 0.030254372990457343
[Epoch 8, Batch 1500] loss: 0.02265850092866458
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9853
Overfitting: 0.0526
Best model saved at epoch 8 with validation loss: 0.0526
[Epoch 9, Batch 100] loss: 0.028859374687599484
[Epoch 9, Batch 200] loss: 0.01934785558063595
[Epoch 9, Batch 300] loss: 0.020257222265790915
[Epoch 9, Batch 400] loss: 0.027223686459183227
[Epoch 9, Batch 500] loss: 0.025226644735375885
[Epoch 9, Batch 600] loss: 0.016628572861081922
[Epoch 9, Batch 700] loss: 0.02507512950032833
[Epoch 9, Batch 800] loss: 0.026336337171160268
[Epoch 9, Batch 900] loss: 0.024304944016039373
[Epoch 9, Batch 1000] loss: 0.024956343147787264
[Epoch 9, Batch 1100] loss: 0.029071658309694614
[Epoch 9, Batch 1200] loss: 0.02612292331221397
[Epoch 9, Batch 1300] loss: 0.025212720550989616
[Epoch 9, Batch 1400] loss: 0.030052762622945012
[Epoch 9, Batch 1500] loss: 0.025108374575065682
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9862
Overfitting: 0.0510
Best model saved at epoch 9 with validation loss: 0.0510
[Epoch 10, Batch 100] loss: 0.025883497790782712
[Epoch 10, Batch 200] loss: 0.01525405492488062
[Epoch 10, Batch 300] loss: 0.017072290735450225
[Epoch 10, Batch 400] loss: 0.010695289796422003
[Epoch 10, Batch 500] loss: 0.0174798093897698
[Epoch 10, Batch 600] loss: 0.02157146531433682
[Epoch 10, Batch 700] loss: 0.029437413029081653
[Epoch 10, Batch 800] loss: 0.025183332131418865
[Epoch 10, Batch 900] loss: 0.020115970040933462
[Epoch 10, Batch 1000] loss: 0.017225870559450414
[Epoch 10, Batch 1100] loss: 0.020861402848313445
[Epoch 10, Batch 1200] loss: 0.02675734568227199
[Epoch 10, Batch 1300] loss: 0.013889667177481897
[Epoch 10, Batch 1400] loss: 0.019270689437689725
[Epoch 10, Batch 1500] loss: 0.035155389434075916
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9849
Overfitting: 0.0560
[Epoch 11, Batch 100] loss: 0.014560133372651763
[Epoch 11, Batch 200] loss: 0.016513958560826724
[Epoch 11, Batch 300] loss: 0.019387654408274103
[Epoch 11, Batch 400] loss: 0.014851170746223942
[Epoch 11, Batch 500] loss: 0.01666552595932444
[Epoch 11, Batch 600] loss: 0.024836958483610942
[Epoch 11, Batch 700] loss: 0.01594440859989845
[Epoch 11, Batch 800] loss: 0.017591787318888236
[Epoch 11, Batch 900] loss: 0.012530103992976365
[Epoch 11, Batch 1000] loss: 0.017539592960529263
[Epoch 11, Batch 1100] loss: 0.021719676989996516
[Epoch 11, Batch 1200] loss: 0.021073114289029037
[Epoch 11, Batch 1300] loss: 0.02453179688716773
[Epoch 11, Batch 1400] loss: 0.016467817638622363
[Epoch 11, Batch 1500] loss: 0.02598092025742517
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9868
Overfitting: 0.0477
Best model saved at epoch 11 with validation loss: 0.0477
[Epoch 12, Batch 100] loss: 0.022409803551854564
[Epoch 12, Batch 200] loss: 0.020580242292598996
[Epoch 12, Batch 300] loss: 0.014175552482047351
[Epoch 12, Batch 400] loss: 0.014761204972746782
[Epoch 12, Batch 500] loss: 0.01655147276222124
[Epoch 12, Batch 600] loss: 0.016827274155657504
[Epoch 12, Batch 700] loss: 0.018038635338380116
[Epoch 12, Batch 800] loss: 0.012939348428262746
[Epoch 12, Batch 900] loss: 0.014983922911524132
[Epoch 12, Batch 1000] loss: 0.012638838704660885
[Epoch 12, Batch 1100] loss: 0.020407662088691724
[Epoch 12, Batch 1200] loss: 0.018442679201871214
[Epoch 12, Batch 1300] loss: 0.016357849208507105
[Epoch 12, Batch 1400] loss: 0.015900345048466987
[Epoch 12, Batch 1500] loss: 0.016227350240660597
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9872
Overfitting: 0.0479
[Epoch 13, Batch 100] loss: 0.01829426735654124
[Epoch 13, Batch 200] loss: 0.011919684534077532
[Epoch 13, Batch 300] loss: 0.010655374389971257
[Epoch 13, Batch 400] loss: 0.007087899529869901
[Epoch 13, Batch 500] loss: 0.013912788380985149
[Epoch 13, Batch 600] loss: 0.011446942441907595
[Epoch 13, Batch 700] loss: 0.02207362623350491
[Epoch 13, Batch 800] loss: 0.009692273541149916
[Epoch 13, Batch 900] loss: 0.012733718272193073
[Epoch 13, Batch 1000] loss: 0.01616088755465171
[Epoch 13, Batch 1100] loss: 0.009728245747101027
[Epoch 13, Batch 1200] loss: 0.010356128907842503
[Epoch 13, Batch 1300] loss: 0.025709729005557166
[Epoch 13, Batch 1400] loss: 0.018459835730172926
[Epoch 13, Batch 1500] loss: 0.0120887002733798
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9877
Overfitting: 0.0483
[Epoch 14, Batch 100] loss: 0.013145538853932522
[Epoch 14, Batch 200] loss: 0.009899177939478249
[Epoch 14, Batch 300] loss: 0.0070064393481425215
[Epoch 14, Batch 400] loss: 0.007555179399823828
[Epoch 14, Batch 500] loss: 0.00818398394238102
[Epoch 14, Batch 600] loss: 0.011065519865569513
[Epoch 14, Batch 700] loss: 0.008204264090813922
[Epoch 14, Batch 800] loss: 0.008526205130092421
[Epoch 14, Batch 900] loss: 0.01653944777913239
[Epoch 14, Batch 1000] loss: 0.017107787284439836
[Epoch 14, Batch 1100] loss: 0.016194301015584642
[Epoch 14, Batch 1200] loss: 0.013082691889358102
[Epoch 14, Batch 1300] loss: 0.009666213330983737
[Epoch 14, Batch 1400] loss: 0.01838514422488515
[Epoch 14, Batch 1500] loss: 0.017284144226796343
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9862
Overfitting: 0.0509
[Epoch 15, Batch 100] loss: 0.009612188975333993
[Epoch 15, Batch 200] loss: 0.007463851477659773
[Epoch 15, Batch 300] loss: 0.007368100841576961
[Epoch 15, Batch 400] loss: 0.009954514016299073
[Epoch 15, Batch 500] loss: 0.008894758073292906
[Epoch 15, Batch 600] loss: 0.008220108368514048
[Epoch 15, Batch 700] loss: 0.013662703172703914
[Epoch 15, Batch 800] loss: 0.013109487933834317
[Epoch 15, Batch 900] loss: 0.010431107011245331
[Epoch 15, Batch 1000] loss: 0.012135899626991886
[Epoch 15, Batch 1100] loss: 0.018987547974757036
[Epoch 15, Batch 1200] loss: 0.012954357140806678
[Epoch 15, Batch 1300] loss: 0.01282417506476122
[Epoch 15, Batch 1400] loss: 0.010261976768197201
[Epoch 15, Batch 1500] loss: 0.010454039162796106
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9878
Overfitting: 0.0502
[Epoch 16, Batch 100] loss: 0.008454073894736212
[Epoch 16, Batch 200] loss: 0.006342507244589797
[Epoch 16, Batch 300] loss: 0.010874846466467716
[Epoch 16, Batch 400] loss: 0.006164626297486393
[Epoch 16, Batch 500] loss: 0.006822193271864308
[Epoch 16, Batch 600] loss: 0.012066455515650887
[Epoch 16, Batch 700] loss: 0.012116542655548982
[Epoch 16, Batch 800] loss: 0.008943443260122877
[Epoch 16, Batch 900] loss: 0.0073404507693703635
[Epoch 16, Batch 1000] loss: 0.006932623575075922
[Epoch 16, Batch 1100] loss: 0.010714182621486544
[Epoch 16, Batch 1200] loss: 0.010053173163578321
[Epoch 16, Batch 1300] loss: 0.00925811132781746
[Epoch 16, Batch 1400] loss: 0.007320404984038759
[Epoch 16, Batch 1500] loss: 0.007977882501345448
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9888
Overfitting: 0.0485
[Epoch 17, Batch 100] loss: 0.005740583370570675
[Epoch 17, Batch 200] loss: 0.003219463847908628
[Epoch 17, Batch 300] loss: 0.009261860064261782
[Epoch 17, Batch 400] loss: 0.004601893629551341
[Epoch 17, Batch 500] loss: 0.007554467122045026
[Epoch 17, Batch 600] loss: 0.00923649660197043
[Epoch 17, Batch 700] loss: 0.004199551407418766
[Epoch 17, Batch 800] loss: 0.0066417874193757595
[Epoch 17, Batch 900] loss: 0.004552615916409195
[Epoch 17, Batch 1000] loss: 0.005658207197739102
[Epoch 17, Batch 1100] loss: 0.0076731205271789804
[Epoch 17, Batch 1200] loss: 0.011093489057848273
[Epoch 17, Batch 1300] loss: 0.005022732011639164
[Epoch 17, Batch 1400] loss: 0.005501356865024718
[Epoch 17, Batch 1500] loss: 0.008512068326472217
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0566
Validation Accuracy: 0.9860
Overfitting: 0.0566
[Epoch 18, Batch 100] loss: 0.0058566582059165736
[Epoch 18, Batch 200] loss: 0.004939164037741648
[Epoch 18, Batch 300] loss: 0.012742823894614048
[Epoch 18, Batch 400] loss: 0.004334275578430607
[Epoch 18, Batch 500] loss: 0.0060869722316442675
[Epoch 18, Batch 600] loss: 0.005666082059037763
[Epoch 18, Batch 700] loss: 0.005119566157327426
[Epoch 18, Batch 800] loss: 0.006320941477210909
[Epoch 18, Batch 900] loss: 0.004411217951333129
[Epoch 18, Batch 1000] loss: 0.0103067644857947
[Epoch 18, Batch 1100] loss: 0.0034937221299878728
[Epoch 18, Batch 1200] loss: 0.007163989956643491
[Epoch 18, Batch 1300] loss: 0.008311147692274971
[Epoch 18, Batch 1400] loss: 0.012306801707800331
[Epoch 18, Batch 1500] loss: 0.0053187552430063074
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9871
Overfitting: 0.0548
[Epoch 19, Batch 100] loss: 0.006228870464437933
[Epoch 19, Batch 200] loss: 0.006895833787639276
[Epoch 19, Batch 300] loss: 0.007316499105190815
[Epoch 19, Batch 400] loss: 0.0038202292056803344
[Epoch 19, Batch 500] loss: 0.0027585431251554837
[Epoch 19, Batch 600] loss: 0.00405325460234053
[Epoch 19, Batch 700] loss: 0.005302491578477202
[Epoch 19, Batch 800] loss: 0.004213384224863148
[Epoch 19, Batch 900] loss: 0.010106278368975836
[Epoch 19, Batch 1000] loss: 0.0037071614921796938
[Epoch 19, Batch 1100] loss: 0.004000869013057126
[Epoch 19, Batch 1200] loss: 0.006603336046191543
[Epoch 19, Batch 1300] loss: 0.004719679836198338
[Epoch 19, Batch 1400] loss: 0.013558840917285124
[Epoch 19, Batch 1500] loss: 0.013064568854770187
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0624
Validation Accuracy: 0.9861
Overfitting: 0.0624
[Epoch 20, Batch 100] loss: 0.009298723945412347
[Epoch 20, Batch 200] loss: 0.008040798070433085
[Epoch 20, Batch 300] loss: 0.005173969216780278
[Epoch 20, Batch 400] loss: 0.006502327743228307
[Epoch 20, Batch 500] loss: 0.003852942082685331
[Epoch 20, Batch 600] loss: 0.004113090033806657
[Epoch 20, Batch 700] loss: 0.006088698998878499
[Epoch 20, Batch 800] loss: 0.004942755356159978
[Epoch 20, Batch 900] loss: 0.003555760166022992
[Epoch 20, Batch 1000] loss: 0.005223133900728954
[Epoch 20, Batch 1100] loss: 0.0034279196479474194
[Epoch 20, Batch 1200] loss: 0.002276780745855831
[Epoch 20, Batch 1300] loss: 0.00441097128097681
[Epoch 20, Batch 1400] loss: 0.011448842122749738
[Epoch 20, Batch 1500] loss: 0.004527701761313096
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0624
Validation Accuracy: 0.9862
Overfitting: 0.0624
[Epoch 21, Batch 100] loss: 0.004197460012305782
[Epoch 21, Batch 200] loss: 0.0040692523603081555
[Epoch 21, Batch 300] loss: 0.0025299429578581113
[Epoch 21, Batch 400] loss: 0.006329508223492439
[Epoch 21, Batch 500] loss: 0.004132810133555722
[Epoch 21, Batch 600] loss: 0.003547933634004039
[Epoch 21, Batch 700] loss: 0.007828787638229641
[Epoch 21, Batch 800] loss: 0.004055810636544379
[Epoch 21, Batch 900] loss: 0.0032322226839255563
[Epoch 21, Batch 1000] loss: 0.0050280711880463964
[Epoch 21, Batch 1100] loss: 0.010829666438932009
[Epoch 21, Batch 1200] loss: 0.011855338061761813
[Epoch 21, Batch 1300] loss: 0.004377437755001665
[Epoch 21, Batch 1400] loss: 0.00357896177704788
[Epoch 21, Batch 1500] loss: 0.004921765460775305
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0646
Validation Accuracy: 0.9866
Overfitting: 0.0646
[Epoch 22, Batch 100] loss: 0.005641359482970074
[Epoch 22, Batch 200] loss: 0.003861268357386507
[Epoch 22, Batch 300] loss: 0.00206801382057165
[Epoch 22, Batch 400] loss: 0.004283561193983587
[Epoch 22, Batch 500] loss: 0.0034068316845832667
[Epoch 22, Batch 600] loss: 0.005449079819395592
[Epoch 22, Batch 700] loss: 0.005819645398159992
[Epoch 22, Batch 800] loss: 0.002816625366046992
[Epoch 22, Batch 900] loss: 0.0027040865928995572
[Epoch 22, Batch 1000] loss: 0.0026634874158344246
[Epoch 22, Batch 1100] loss: 0.0027881880903100863
[Epoch 22, Batch 1200] loss: 0.0038350984963091152
[Epoch 22, Batch 1300] loss: 0.0074635974229602196
[Epoch 22, Batch 1400] loss: 0.006151523473893122
[Epoch 22, Batch 1500] loss: 0.0042428967572323015
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0623
Validation Accuracy: 0.9873
Overfitting: 0.0623
[Epoch 23, Batch 100] loss: 0.006968553222590117
[Epoch 23, Batch 200] loss: 0.004350208339042183
[Epoch 23, Batch 300] loss: 0.003115873304000161
[Epoch 23, Batch 400] loss: 0.0022108970058775414
[Epoch 23, Batch 500] loss: 0.0029044742240967023
[Epoch 23, Batch 600] loss: 0.0032997177538004506
[Epoch 23, Batch 700] loss: 0.0009679462637745928
[Epoch 23, Batch 800] loss: 0.0031364330132981877
[Epoch 23, Batch 900] loss: 0.00204744975212634
[Epoch 23, Batch 1000] loss: 0.007755620443786313
[Epoch 23, Batch 1100] loss: 0.004136630018519156
[Epoch 23, Batch 1200] loss: 0.003902658588945087
[Epoch 23, Batch 1300] loss: 0.002095117499159187
[Epoch 23, Batch 1400] loss: 0.0015558466362722357
[Epoch 23, Batch 1500] loss: 0.0018062865035426512
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9885
Overfitting: 0.0570
[Epoch 24, Batch 100] loss: 0.0015856920308686994
[Epoch 24, Batch 200] loss: 0.0012946838115487935
[Epoch 24, Batch 300] loss: 0.0009782821292043309
[Epoch 24, Batch 400] loss: 0.0010097558981124167
[Epoch 24, Batch 500] loss: 0.002761028192571757
[Epoch 24, Batch 600] loss: 0.0016370921526981874
[Epoch 24, Batch 700] loss: 0.0009626829711532991
[Epoch 24, Batch 800] loss: 0.00036688863942401894
[Epoch 24, Batch 900] loss: 0.0010968160072678756
[Epoch 24, Batch 1000] loss: 0.0020129560408059886
[Epoch 24, Batch 1100] loss: 0.002615142464073301
[Epoch 24, Batch 1200] loss: 0.002080152589346653
[Epoch 24, Batch 1300] loss: 0.0018166963911619405
[Epoch 24, Batch 1400] loss: 0.0031240223512020294
[Epoch 24, Batch 1500] loss: 0.0017335433119701803
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9880
Overfitting: 0.0606
Fold 3 validation loss: 0.0606
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.295535855293274
[Epoch 1, Batch 200] loss: 2.2546891713142396
[Epoch 1, Batch 300] loss: 1.649466399550438
[Epoch 1, Batch 400] loss: 0.6391088724136352
[Epoch 1, Batch 500] loss: 0.4493284800648689
[Epoch 1, Batch 600] loss: 0.31968912295997143
[Epoch 1, Batch 700] loss: 0.29565716855227947
[Epoch 1, Batch 800] loss: 0.2639280927553773
[Epoch 1, Batch 900] loss: 0.24266205705702304
[Epoch 1, Batch 1000] loss: 0.20463392252102494
[Epoch 1, Batch 1100] loss: 0.193938631657511
[Epoch 1, Batch 1200] loss: 0.1750021062605083
[Epoch 1, Batch 1300] loss: 0.1664577639847994
[Epoch 1, Batch 1400] loss: 0.14566342318430542
[Epoch 1, Batch 1500] loss: 0.15027582556940616
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1307
Validation Accuracy: 0.9615
Overfitting: 0.1307
Best model saved at epoch 1 with validation loss: 0.1307
[Epoch 2, Batch 100] loss: 0.12570250359363855
[Epoch 2, Batch 200] loss: 0.13065940784290433
[Epoch 2, Batch 300] loss: 0.11028666512109339
[Epoch 2, Batch 400] loss: 0.10888523124158382
[Epoch 2, Batch 500] loss: 0.11562110620550811
[Epoch 2, Batch 600] loss: 0.11027111471630632
[Epoch 2, Batch 700] loss: 0.10173321128822863
[Epoch 2, Batch 800] loss: 0.11860972367227078
[Epoch 2, Batch 900] loss: 0.09930596391670406
[Epoch 2, Batch 1000] loss: 0.11834783812053501
[Epoch 2, Batch 1100] loss: 0.09711106304079294
[Epoch 2, Batch 1200] loss: 0.09422206006012857
[Epoch 2, Batch 1300] loss: 0.10268081222195179
[Epoch 2, Batch 1400] loss: 0.09677822300232947
[Epoch 2, Batch 1500] loss: 0.09609635489527137
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0910
Validation Accuracy: 0.9725
Overfitting: 0.0910
Best model saved at epoch 2 with validation loss: 0.0910
[Epoch 3, Batch 100] loss: 0.08753849976696074
[Epoch 3, Batch 200] loss: 0.0772993512568064
[Epoch 3, Batch 300] loss: 0.06892537217820063
[Epoch 3, Batch 400] loss: 0.09075140744447709
[Epoch 3, Batch 500] loss: 0.06551987539744004
[Epoch 3, Batch 600] loss: 0.06925832679728046
[Epoch 3, Batch 700] loss: 0.06768361382186412
[Epoch 3, Batch 800] loss: 0.09198961531277745
[Epoch 3, Batch 900] loss: 0.061114860284142196
[Epoch 3, Batch 1000] loss: 0.06256923944223672
[Epoch 3, Batch 1100] loss: 0.07810762702720239
[Epoch 3, Batch 1200] loss: 0.06358843360096217
[Epoch 3, Batch 1300] loss: 0.07375942239770666
[Epoch 3, Batch 1400] loss: 0.06678793228697032
[Epoch 3, Batch 1500] loss: 0.07389480781275778
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0790
Validation Accuracy: 0.9745
Overfitting: 0.0790
Best model saved at epoch 3 with validation loss: 0.0790
[Epoch 4, Batch 100] loss: 0.04592167567461729
[Epoch 4, Batch 200] loss: 0.059539778437465427
[Epoch 4, Batch 300] loss: 0.04800410949974321
[Epoch 4, Batch 400] loss: 0.05474119368183892
[Epoch 4, Batch 500] loss: 0.06571368862641976
[Epoch 4, Batch 600] loss: 0.04835023567895405
[Epoch 4, Batch 700] loss: 0.04590639426955022
[Epoch 4, Batch 800] loss: 0.060230268384329974
[Epoch 4, Batch 900] loss: 0.055217883743462155
[Epoch 4, Batch 1000] loss: 0.05630655642249621
[Epoch 4, Batch 1100] loss: 0.06667434216011316
[Epoch 4, Batch 1200] loss: 0.06620443931780756
[Epoch 4, Batch 1300] loss: 0.06154139134567231
[Epoch 4, Batch 1400] loss: 0.05968499438837171
[Epoch 4, Batch 1500] loss: 0.047354665441671384
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9825
Overfitting: 0.0573
Best model saved at epoch 4 with validation loss: 0.0573
[Epoch 5, Batch 100] loss: 0.04183692399179563
[Epoch 5, Batch 200] loss: 0.04934333015815355
[Epoch 5, Batch 300] loss: 0.04663889371557161
[Epoch 5, Batch 400] loss: 0.03461162740190048
[Epoch 5, Batch 500] loss: 0.06206240683561191
[Epoch 5, Batch 600] loss: 0.04486117901513353
[Epoch 5, Batch 700] loss: 0.047957845568598716
[Epoch 5, Batch 800] loss: 0.04980070575780701
[Epoch 5, Batch 900] loss: 0.03710009096306749
[Epoch 5, Batch 1000] loss: 0.04895541972888168
[Epoch 5, Batch 1100] loss: 0.03792358766542748
[Epoch 5, Batch 1200] loss: 0.041338355340412816
[Epoch 5, Batch 1300] loss: 0.057026203389978034
[Epoch 5, Batch 1400] loss: 0.03869653881352861
[Epoch 5, Batch 1500] loss: 0.044728302781586536
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9853
Overfitting: 0.0497
Best model saved at epoch 5 with validation loss: 0.0497
[Epoch 6, Batch 100] loss: 0.04322046830900945
[Epoch 6, Batch 200] loss: 0.03583525671856478
[Epoch 6, Batch 300] loss: 0.04120815043861512
[Epoch 6, Batch 400] loss: 0.03145738741033711
[Epoch 6, Batch 500] loss: 0.04803328616908402
[Epoch 6, Batch 600] loss: 0.024923154059506486
[Epoch 6, Batch 700] loss: 0.04102043404505821
[Epoch 6, Batch 800] loss: 0.03798405473586172
[Epoch 6, Batch 900] loss: 0.03193154993641656
[Epoch 6, Batch 1000] loss: 0.030781032658705954
[Epoch 6, Batch 1100] loss: 0.0320868641450943
[Epoch 6, Batch 1200] loss: 0.03395507042005193
[Epoch 6, Batch 1300] loss: 0.045861276419018396
[Epoch 6, Batch 1400] loss: 0.037795968367136085
[Epoch 6, Batch 1500] loss: 0.051407652807538395
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0434
Validation Accuracy: 0.9868
Overfitting: 0.0434
Best model saved at epoch 6 with validation loss: 0.0434
[Epoch 7, Batch 100] loss: 0.04042192604742013
[Epoch 7, Batch 200] loss: 0.03843380315694958
[Epoch 7, Batch 300] loss: 0.030696433478442486
[Epoch 7, Batch 400] loss: 0.033175592498591866
[Epoch 7, Batch 500] loss: 0.030643611522827997
[Epoch 7, Batch 600] loss: 0.038709986383910294
[Epoch 7, Batch 700] loss: 0.028841925029410048
[Epoch 7, Batch 800] loss: 0.028160862999939126
[Epoch 7, Batch 900] loss: 0.03138305579079315
[Epoch 7, Batch 1000] loss: 0.031608741201052906
[Epoch 7, Batch 1100] loss: 0.03750188918580534
[Epoch 7, Batch 1200] loss: 0.03484815128351329
[Epoch 7, Batch 1300] loss: 0.02712518198241014
[Epoch 7, Batch 1400] loss: 0.03430685924133286
[Epoch 7, Batch 1500] loss: 0.025419808884034865
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9858
Overfitting: 0.0476
[Epoch 8, Batch 100] loss: 0.025687791389646008
[Epoch 8, Batch 200] loss: 0.02376926994038513
[Epoch 8, Batch 300] loss: 0.024683157842082436
[Epoch 8, Batch 400] loss: 0.030986001487181055
[Epoch 8, Batch 500] loss: 0.022940539372502827
[Epoch 8, Batch 600] loss: 0.023796442359162027
[Epoch 8, Batch 700] loss: 0.023507215072895632
[Epoch 8, Batch 800] loss: 0.02664679991052253
[Epoch 8, Batch 900] loss: 0.02611326444573933
[Epoch 8, Batch 1000] loss: 0.027269498983223457
[Epoch 8, Batch 1100] loss: 0.02838003493961878
[Epoch 8, Batch 1200] loss: 0.02979090950684622
[Epoch 8, Batch 1300] loss: 0.028412745351379273
[Epoch 8, Batch 1400] loss: 0.026274482069566146
[Epoch 8, Batch 1500] loss: 0.030375209783378522
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9863
Overfitting: 0.0459
[Epoch 9, Batch 100] loss: 0.017166292174661067
[Epoch 9, Batch 200] loss: 0.019750684897444443
[Epoch 9, Batch 300] loss: 0.023325601330434438
[Epoch 9, Batch 400] loss: 0.01594253286617459
[Epoch 9, Batch 500] loss: 0.02211250947060762
[Epoch 9, Batch 600] loss: 0.027091134971997236
[Epoch 9, Batch 700] loss: 0.021597669390030206
[Epoch 9, Batch 800] loss: 0.029132076657260766
[Epoch 9, Batch 900] loss: 0.023704143883442157
[Epoch 9, Batch 1000] loss: 0.025696127305272966
[Epoch 9, Batch 1100] loss: 0.021238389040372566
[Epoch 9, Batch 1200] loss: 0.029679883024655282
[Epoch 9, Batch 1300] loss: 0.029912127632997
[Epoch 9, Batch 1400] loss: 0.02046047239098698
[Epoch 9, Batch 1500] loss: 0.02736925396922743
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0398
Validation Accuracy: 0.9878
Overfitting: 0.0398
Best model saved at epoch 9 with validation loss: 0.0398
[Epoch 10, Batch 100] loss: 0.015007592513211421
[Epoch 10, Batch 200] loss: 0.01994749709396274
[Epoch 10, Batch 300] loss: 0.02081737771339249
[Epoch 10, Batch 400] loss: 0.01908306352343061
[Epoch 10, Batch 500] loss: 0.02806800742924679
[Epoch 10, Batch 600] loss: 0.016399998460692587
[Epoch 10, Batch 700] loss: 0.017802188773202943
[Epoch 10, Batch 800] loss: 0.02339310635899892
[Epoch 10, Batch 900] loss: 0.013991967232723255
[Epoch 10, Batch 1000] loss: 0.012557047040681937
[Epoch 10, Batch 1100] loss: 0.01700248186745739
[Epoch 10, Batch 1200] loss: 0.01933639803653932
[Epoch 10, Batch 1300] loss: 0.022728214305316213
[Epoch 10, Batch 1400] loss: 0.022644318236343677
[Epoch 10, Batch 1500] loss: 0.022053041769686386
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0451
Validation Accuracy: 0.9868
Overfitting: 0.0451
[Epoch 11, Batch 100] loss: 0.015115230907176737
[Epoch 11, Batch 200] loss: 0.018621435427558026
[Epoch 11, Batch 300] loss: 0.01713827806292102
[Epoch 11, Batch 400] loss: 0.019978371333709218
[Epoch 11, Batch 500] loss: 0.020866188875152146
[Epoch 11, Batch 600] loss: 0.018146391712944025
[Epoch 11, Batch 700] loss: 0.013131521129216707
[Epoch 11, Batch 800] loss: 0.02045151770209486
[Epoch 11, Batch 900] loss: 0.01390831060729397
[Epoch 11, Batch 1000] loss: 0.021329823868727546
[Epoch 11, Batch 1100] loss: 0.015237500058647128
[Epoch 11, Batch 1200] loss: 0.017909355998781393
[Epoch 11, Batch 1300] loss: 0.02433901838870952
[Epoch 11, Batch 1400] loss: 0.016180308779657936
[Epoch 11, Batch 1500] loss: 0.016417654530523577
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0438
Validation Accuracy: 0.9868
Overfitting: 0.0438
[Epoch 12, Batch 100] loss: 0.014266441262807348
[Epoch 12, Batch 200] loss: 0.012226450722009759
[Epoch 12, Batch 300] loss: 0.01865268116685911
[Epoch 12, Batch 400] loss: 0.013168750352997449
[Epoch 12, Batch 500] loss: 0.014557899658102542
[Epoch 12, Batch 600] loss: 0.02089251676290587
[Epoch 12, Batch 700] loss: 0.015741038442429273
[Epoch 12, Batch 800] loss: 0.013288741518044845
[Epoch 12, Batch 900] loss: 0.018252329883835045
[Epoch 12, Batch 1000] loss: 0.021781718320708025
[Epoch 12, Batch 1100] loss: 0.021717313726258
[Epoch 12, Batch 1200] loss: 0.01611485287110554
[Epoch 12, Batch 1300] loss: 0.01555090060675866
[Epoch 12, Batch 1400] loss: 0.01192451173570589
[Epoch 12, Batch 1500] loss: 0.015809932425654552
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9866
Overfitting: 0.0487
[Epoch 13, Batch 100] loss: 0.010431996597981196
[Epoch 13, Batch 200] loss: 0.012811645210022107
[Epoch 13, Batch 300] loss: 0.01701314639154589
[Epoch 13, Batch 400] loss: 0.014056886217385909
[Epoch 13, Batch 500] loss: 0.0080393602334334
[Epoch 13, Batch 600] loss: 0.011441094380315917
[Epoch 13, Batch 700] loss: 0.008447074965088177
[Epoch 13, Batch 800] loss: 0.01315526882368431
[Epoch 13, Batch 900] loss: 0.016568426226112935
[Epoch 13, Batch 1000] loss: 0.015244653584159096
[Epoch 13, Batch 1100] loss: 0.020827582579804584
[Epoch 13, Batch 1200] loss: 0.012063181526173139
[Epoch 13, Batch 1300] loss: 0.012376357954090055
[Epoch 13, Batch 1400] loss: 0.02103476041222166
[Epoch 13, Batch 1500] loss: 0.013072296763730264
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9879
Overfitting: 0.0439
[Epoch 14, Batch 100] loss: 0.012053699757234426
[Epoch 14, Batch 200] loss: 0.011993363133151434
[Epoch 14, Batch 300] loss: 0.008490559834026499
[Epoch 14, Batch 400] loss: 0.0069049312987408485
[Epoch 14, Batch 500] loss: 0.01374572907208858
[Epoch 14, Batch 600] loss: 0.011548278318659868
[Epoch 14, Batch 700] loss: 0.009937512894939573
[Epoch 14, Batch 800] loss: 0.012285132839569996
[Epoch 14, Batch 900] loss: 0.012339867608407076
[Epoch 14, Batch 1000] loss: 0.019967529422792722
[Epoch 14, Batch 1100] loss: 0.013191035525742335
[Epoch 14, Batch 1200] loss: 0.012590820376572083
[Epoch 14, Batch 1300] loss: 0.009460855313373031
[Epoch 14, Batch 1400] loss: 0.013575838508877495
[Epoch 14, Batch 1500] loss: 0.01588277964896406
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9851
Overfitting: 0.0551
[Epoch 15, Batch 100] loss: 0.010716364407126094
[Epoch 15, Batch 200] loss: 0.006295514095436374
[Epoch 15, Batch 300] loss: 0.0116900744114173
[Epoch 15, Batch 400] loss: 0.009507520507304435
[Epoch 15, Batch 500] loss: 0.011692033631625236
[Epoch 15, Batch 600] loss: 0.013351066504892515
[Epoch 15, Batch 700] loss: 0.009053420214277139
[Epoch 15, Batch 800] loss: 0.011628969234116084
[Epoch 15, Batch 900] loss: 0.008321640745780314
[Epoch 15, Batch 1000] loss: 0.006295781972585246
[Epoch 15, Batch 1100] loss: 0.00944616779584976
[Epoch 15, Batch 1200] loss: 0.01099190294442451
[Epoch 15, Batch 1300] loss: 0.011375950218825892
[Epoch 15, Batch 1400] loss: 0.011735289442549401
[Epoch 15, Batch 1500] loss: 0.01264723932110428
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9880
Overfitting: 0.0431
[Epoch 16, Batch 100] loss: 0.006593730010408762
[Epoch 16, Batch 200] loss: 0.009316488752119767
[Epoch 16, Batch 300] loss: 0.006499436505837366
[Epoch 16, Batch 400] loss: 0.007193359900375071
[Epoch 16, Batch 500] loss: 0.010402181233839656
[Epoch 16, Batch 600] loss: 0.012109449343533925
[Epoch 16, Batch 700] loss: 0.008595915900514228
[Epoch 16, Batch 800] loss: 0.006873575863937731
[Epoch 16, Batch 900] loss: 0.00750917178884265
[Epoch 16, Batch 1000] loss: 0.008478322340397425
[Epoch 16, Batch 1100] loss: 0.008575183763296081
[Epoch 16, Batch 1200] loss: 0.007661698663064272
[Epoch 16, Batch 1300] loss: 0.0110826225843266
[Epoch 16, Batch 1400] loss: 0.007074967950075006
[Epoch 16, Batch 1500] loss: 0.01448396350540861
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9888
Overfitting: 0.0437
[Epoch 17, Batch 100] loss: 0.008572748748883896
[Epoch 17, Batch 200] loss: 0.011827409616635122
[Epoch 17, Batch 300] loss: 0.008116738912194705
[Epoch 17, Batch 400] loss: 0.007306768866765196
[Epoch 17, Batch 500] loss: 0.00823139630851074
[Epoch 17, Batch 600] loss: 0.006619505755306818
[Epoch 17, Batch 700] loss: 0.011844181774158642
[Epoch 17, Batch 800] loss: 0.006079939329692934
[Epoch 17, Batch 900] loss: 0.007687807728095777
[Epoch 17, Batch 1000] loss: 0.004886091499201939
[Epoch 17, Batch 1100] loss: 0.005820546188660955
[Epoch 17, Batch 1200] loss: 0.005943663367179397
[Epoch 17, Batch 1300] loss: 0.010880254331605102
[Epoch 17, Batch 1400] loss: 0.005763874342446798
[Epoch 17, Batch 1500] loss: 0.008557726088126856
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9875
Overfitting: 0.0455
[Epoch 18, Batch 100] loss: 0.005644403127471378
[Epoch 18, Batch 200] loss: 0.002450130667148187
[Epoch 18, Batch 300] loss: 0.002704623777042343
[Epoch 18, Batch 400] loss: 0.005410876546625332
[Epoch 18, Batch 500] loss: 0.0076845783303815555
[Epoch 18, Batch 600] loss: 0.009777221745353018
[Epoch 18, Batch 700] loss: 0.006580530024029941
[Epoch 18, Batch 800] loss: 0.008413577663013712
[Epoch 18, Batch 900] loss: 0.005054639409481751
[Epoch 18, Batch 1000] loss: 0.0074639329439378345
[Epoch 18, Batch 1100] loss: 0.0075601119945349635
[Epoch 18, Batch 1200] loss: 0.005890668338233809
[Epoch 18, Batch 1300] loss: 0.005500428977593401
[Epoch 18, Batch 1400] loss: 0.0055476736396030905
[Epoch 18, Batch 1500] loss: 0.004020527961165499
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9882
Overfitting: 0.0482
[Epoch 19, Batch 100] loss: 0.0046864781346812375
[Epoch 19, Batch 200] loss: 0.004969688012224651
[Epoch 19, Batch 300] loss: 0.004826760366763665
[Epoch 19, Batch 400] loss: 0.002961933329684143
[Epoch 19, Batch 500] loss: 0.003448613544544514
[Epoch 19, Batch 600] loss: 0.006139425248647967
[Epoch 19, Batch 700] loss: 0.0038158637910737526
[Epoch 19, Batch 800] loss: 0.0024470253714548563
[Epoch 19, Batch 900] loss: 0.003835920695685218
[Epoch 19, Batch 1000] loss: 0.0030943890130697583
[Epoch 19, Batch 1100] loss: 0.003810604934415096
[Epoch 19, Batch 1200] loss: 0.0030716339025048
[Epoch 19, Batch 1300] loss: 0.0096336321834724
[Epoch 19, Batch 1400] loss: 0.009388568866561399
[Epoch 19, Batch 1500] loss: 0.006539087753608328
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9885
Overfitting: 0.0469
[Epoch 20, Batch 100] loss: 0.0055937511725210245
[Epoch 20, Batch 200] loss: 0.003825111885125807
[Epoch 20, Batch 300] loss: 0.007898256440471414
[Epoch 20, Batch 400] loss: 0.00732328079178842
[Epoch 20, Batch 500] loss: 0.0060223737470937524
[Epoch 20, Batch 600] loss: 0.003491011352566602
[Epoch 20, Batch 700] loss: 0.0061124665907846066
[Epoch 20, Batch 800] loss: 0.003478752798990854
[Epoch 20, Batch 900] loss: 0.004611813180267745
[Epoch 20, Batch 1000] loss: 0.006918378258890243
[Epoch 20, Batch 1100] loss: 0.003945742929327025
[Epoch 20, Batch 1200] loss: 0.005445536332340453
[Epoch 20, Batch 1300] loss: 0.0073620049149735675
[Epoch 20, Batch 1400] loss: 0.0035420023233950814
[Epoch 20, Batch 1500] loss: 0.00958664192662468
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0654
Validation Accuracy: 0.9840
Overfitting: 0.0654
[Epoch 21, Batch 100] loss: 0.009623155848498755
[Epoch 21, Batch 200] loss: 0.005728311041705183
[Epoch 21, Batch 300] loss: 0.006821083508821175
[Epoch 21, Batch 400] loss: 0.004037679718214804
[Epoch 21, Batch 500] loss: 0.005066764323964889
[Epoch 21, Batch 600] loss: 0.00935147220798683
[Epoch 21, Batch 700] loss: 0.005350174916327432
[Epoch 21, Batch 800] loss: 0.009390868295963629
[Epoch 21, Batch 900] loss: 0.010024472716818309
[Epoch 21, Batch 1000] loss: 0.004393165225756093
[Epoch 21, Batch 1100] loss: 0.0043276177953021034
[Epoch 21, Batch 1200] loss: 0.0011868494752695824
[Epoch 21, Batch 1300] loss: 0.002588766735766512
[Epoch 21, Batch 1400] loss: 0.0077711194793755566
[Epoch 21, Batch 1500] loss: 0.007604838443118638
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9889
Overfitting: 0.0487
[Epoch 22, Batch 100] loss: 0.0035279164585540457
[Epoch 22, Batch 200] loss: 0.005877595166762149
[Epoch 22, Batch 300] loss: 0.0025995728860266354
[Epoch 22, Batch 400] loss: 0.003724330733039096
[Epoch 22, Batch 500] loss: 0.0033234744754236088
[Epoch 22, Batch 600] loss: 0.005708492212550027
[Epoch 22, Batch 700] loss: 0.0024242134873361464
[Epoch 22, Batch 800] loss: 0.0022909222956946
[Epoch 22, Batch 900] loss: 0.0032773039486551168
[Epoch 22, Batch 1000] loss: 0.003374112783790224
[Epoch 22, Batch 1100] loss: 0.0020855594781596667
[Epoch 22, Batch 1200] loss: 0.003548352772754697
[Epoch 22, Batch 1300] loss: 0.004975737590968947
[Epoch 22, Batch 1400] loss: 0.008572750290280737
[Epoch 22, Batch 1500] loss: 0.00690247397202711
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9878
Overfitting: 0.0524
[Epoch 23, Batch 100] loss: 0.0031744517733113754
[Epoch 23, Batch 200] loss: 0.006121360234515123
[Epoch 23, Batch 300] loss: 0.009385965873557325
[Epoch 23, Batch 400] loss: 0.005739134975501656
[Epoch 23, Batch 500] loss: 0.004646225404858342
[Epoch 23, Batch 600] loss: 0.0034640119474852325
[Epoch 23, Batch 700] loss: 0.0023209949032843725
[Epoch 23, Batch 800] loss: 0.0015769851781578836
[Epoch 23, Batch 900] loss: 0.003169222703776313
[Epoch 23, Batch 1000] loss: 0.0024878128299383206
[Epoch 23, Batch 1100] loss: 0.006250209607358102
[Epoch 23, Batch 1200] loss: 0.010957431368806283
[Epoch 23, Batch 1300] loss: 0.0025761573071395104
[Epoch 23, Batch 1400] loss: 0.0034079907801606167
[Epoch 23, Batch 1500] loss: 0.0019868362374381833
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9894
Overfitting: 0.0458
[Epoch 24, Batch 100] loss: 0.0018079945203612624
[Epoch 24, Batch 200] loss: 0.0031443269301530564
[Epoch 24, Batch 300] loss: 0.00288274815192608
[Epoch 24, Batch 400] loss: 0.0027056198958938893
[Epoch 24, Batch 500] loss: 0.0031459298111303725
[Epoch 24, Batch 600] loss: 0.001547890628909272
[Epoch 24, Batch 700] loss: 0.0010917799996468603
[Epoch 24, Batch 800] loss: 0.0013686942492563503
[Epoch 24, Batch 900] loss: 0.0009361583595683953
[Epoch 24, Batch 1000] loss: 0.003799602359359824
[Epoch 24, Batch 1100] loss: 0.005121543831724012
[Epoch 24, Batch 1200] loss: 0.003953469125342508
[Epoch 24, Batch 1300] loss: 0.00446165539664662
[Epoch 24, Batch 1400] loss: 0.004932336074703016
[Epoch 24, Batch 1500] loss: 0.004586057261099086
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9884
Overfitting: 0.0525
Fold 4 validation loss: 0.0525
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2907710480690002
[Epoch 1, Batch 200] loss: 2.1768302369117736
[Epoch 1, Batch 300] loss: 0.9885712108016014
[Epoch 1, Batch 400] loss: 0.5217136486619711
[Epoch 1, Batch 500] loss: 0.3684975788742304
[Epoch 1, Batch 600] loss: 0.2988848086446524
[Epoch 1, Batch 700] loss: 0.27365642573684457
[Epoch 1, Batch 800] loss: 0.2145592352747917
[Epoch 1, Batch 900] loss: 0.22987427603453398
[Epoch 1, Batch 1000] loss: 0.1707048184610903
[Epoch 1, Batch 1100] loss: 0.18884944315999747
[Epoch 1, Batch 1200] loss: 0.15646517272107302
[Epoch 1, Batch 1300] loss: 0.14672660276293756
[Epoch 1, Batch 1400] loss: 0.15557127177715302
[Epoch 1, Batch 1500] loss: 0.14002273824065925
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1369
Validation Accuracy: 0.9582
Overfitting: 0.1369
Best model saved at epoch 1 with validation loss: 0.1369
[Epoch 2, Batch 100] loss: 0.13630236471071838
[Epoch 2, Batch 200] loss: 0.12794863884337246
[Epoch 2, Batch 300] loss: 0.11538496690336615
[Epoch 2, Batch 400] loss: 0.12595805590040982
[Epoch 2, Batch 500] loss: 0.11892769149970263
[Epoch 2, Batch 600] loss: 0.10887736496515572
[Epoch 2, Batch 700] loss: 0.08888900733087211
[Epoch 2, Batch 800] loss: 0.10486586630810052
[Epoch 2, Batch 900] loss: 0.08032334510236978
[Epoch 2, Batch 1000] loss: 0.07249135592835955
[Epoch 2, Batch 1100] loss: 0.09721239937935025
[Epoch 2, Batch 1200] loss: 0.0769538648123853
[Epoch 2, Batch 1300] loss: 0.08265231863828376
[Epoch 2, Batch 1400] loss: 0.10379083711653948
[Epoch 2, Batch 1500] loss: 0.08289204705040902
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0981
Validation Accuracy: 0.9696
Overfitting: 0.0981
Best model saved at epoch 2 with validation loss: 0.0981
[Epoch 3, Batch 100] loss: 0.0796784616925288
[Epoch 3, Batch 200] loss: 0.0821926833805628
[Epoch 3, Batch 300] loss: 0.0721016777306795
[Epoch 3, Batch 400] loss: 0.08226342329522594
[Epoch 3, Batch 500] loss: 0.06696731138741598
[Epoch 3, Batch 600] loss: 0.07565251298248768
[Epoch 3, Batch 700] loss: 0.059172931091161445
[Epoch 3, Batch 800] loss: 0.07306072052102536
[Epoch 3, Batch 900] loss: 0.060246245407615785
[Epoch 3, Batch 1000] loss: 0.07187021066201851
[Epoch 3, Batch 1100] loss: 0.05997256969567388
[Epoch 3, Batch 1200] loss: 0.07016431804862805
[Epoch 3, Batch 1300] loss: 0.07683641087729484
[Epoch 3, Batch 1400] loss: 0.05929146815324202
[Epoch 3, Batch 1500] loss: 0.06263277763850056
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0730
Validation Accuracy: 0.9783
Overfitting: 0.0730
Best model saved at epoch 3 with validation loss: 0.0730
[Epoch 4, Batch 100] loss: 0.050594962927279996
[Epoch 4, Batch 200] loss: 0.057755503462976775
[Epoch 4, Batch 300] loss: 0.056787095251493155
[Epoch 4, Batch 400] loss: 0.04948608103091828
[Epoch 4, Batch 500] loss: 0.045928587368689475
[Epoch 4, Batch 600] loss: 0.060362556045874954
[Epoch 4, Batch 700] loss: 0.06000358583871275
[Epoch 4, Batch 800] loss: 0.04734077709494158
[Epoch 4, Batch 900] loss: 0.06320877836318686
[Epoch 4, Batch 1000] loss: 0.06647138193249702
[Epoch 4, Batch 1100] loss: 0.04319453229545615
[Epoch 4, Batch 1200] loss: 0.05747608881967608
[Epoch 4, Batch 1300] loss: 0.05840635421918705
[Epoch 4, Batch 1400] loss: 0.05722715129260905
[Epoch 4, Batch 1500] loss: 0.04380234429350821
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0613
Validation Accuracy: 0.9809
Overfitting: 0.0613
Best model saved at epoch 4 with validation loss: 0.0613
[Epoch 5, Batch 100] loss: 0.060380336864618585
[Epoch 5, Batch 200] loss: 0.03823619698989205
[Epoch 5, Batch 300] loss: 0.03760003187693656
[Epoch 5, Batch 400] loss: 0.04311076205165591
[Epoch 5, Batch 500] loss: 0.04190601219102973
[Epoch 5, Batch 600] loss: 0.041775688432098834
[Epoch 5, Batch 700] loss: 0.044986119532841255
[Epoch 5, Batch 800] loss: 0.05775729116925504
[Epoch 5, Batch 900] loss: 0.04404576120665297
[Epoch 5, Batch 1000] loss: 0.049380947812460364
[Epoch 5, Batch 1100] loss: 0.041070209608878944
[Epoch 5, Batch 1200] loss: 0.05711679042200558
[Epoch 5, Batch 1300] loss: 0.042794526810757814
[Epoch 5, Batch 1400] loss: 0.04716092061426025
[Epoch 5, Batch 1500] loss: 0.0371144237939734
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9849
Overfitting: 0.0494
Best model saved at epoch 5 with validation loss: 0.0494
[Epoch 6, Batch 100] loss: 0.02550874201231636
[Epoch 6, Batch 200] loss: 0.043458189264929385
[Epoch 6, Batch 300] loss: 0.03211828007129952
[Epoch 6, Batch 400] loss: 0.024067674179095774
[Epoch 6, Batch 500] loss: 0.04489261128241196
[Epoch 6, Batch 600] loss: 0.03448822856473271
[Epoch 6, Batch 700] loss: 0.034575031083659266
[Epoch 6, Batch 800] loss: 0.03712297364429105
[Epoch 6, Batch 900] loss: 0.040067057321430184
[Epoch 6, Batch 1000] loss: 0.034636136448243635
[Epoch 6, Batch 1100] loss: 0.05533162748673931
[Epoch 6, Batch 1200] loss: 0.03855451851908583
[Epoch 6, Batch 1300] loss: 0.04546955024881754
[Epoch 6, Batch 1400] loss: 0.043177370345802046
[Epoch 6, Batch 1500] loss: 0.032619609814137224
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9850
Overfitting: 0.0474
Best model saved at epoch 6 with validation loss: 0.0474
[Epoch 7, Batch 100] loss: 0.02767754238549969
[Epoch 7, Batch 200] loss: 0.031774745346192505
[Epoch 7, Batch 300] loss: 0.03309331056094379
[Epoch 7, Batch 400] loss: 0.030132161361398176
[Epoch 7, Batch 500] loss: 0.033024130481644536
[Epoch 7, Batch 600] loss: 0.03202992163016461
[Epoch 7, Batch 700] loss: 0.03796411039540544
[Epoch 7, Batch 800] loss: 0.03178097478463315
[Epoch 7, Batch 900] loss: 0.03268792933755321
[Epoch 7, Batch 1000] loss: 0.03050767266424373
[Epoch 7, Batch 1100] loss: 0.03348760085325921
[Epoch 7, Batch 1200] loss: 0.023296317335334608
[Epoch 7, Batch 1300] loss: 0.02863633754059265
[Epoch 7, Batch 1400] loss: 0.03603521539247595
[Epoch 7, Batch 1500] loss: 0.033205427214561496
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9856
Overfitting: 0.0470
Best model saved at epoch 7 with validation loss: 0.0470
[Epoch 8, Batch 100] loss: 0.03117264444590546
[Epoch 8, Batch 200] loss: 0.03035908216217649
[Epoch 8, Batch 300] loss: 0.024307336182100698
[Epoch 8, Batch 400] loss: 0.02270961763919331
[Epoch 8, Batch 500] loss: 0.025266967149509583
[Epoch 8, Batch 600] loss: 0.030796937030099798
[Epoch 8, Batch 700] loss: 0.031499881873023695
[Epoch 8, Batch 800] loss: 0.03047666268364992
[Epoch 8, Batch 900] loss: 0.02162091289777891
[Epoch 8, Batch 1000] loss: 0.02388920143195719
[Epoch 8, Batch 1100] loss: 0.02258810868341243
[Epoch 8, Batch 1200] loss: 0.02208509175572544
[Epoch 8, Batch 1300] loss: 0.033912379615358076
[Epoch 8, Batch 1400] loss: 0.02729973644774873
[Epoch 8, Batch 1500] loss: 0.035519222558941695
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9860
Overfitting: 0.0470
[Epoch 9, Batch 100] loss: 0.02466293573146686
[Epoch 9, Batch 200] loss: 0.027892955624702155
[Epoch 9, Batch 300] loss: 0.01765976520400727
[Epoch 9, Batch 400] loss: 0.021310818561323684
[Epoch 9, Batch 500] loss: 0.021325815735108337
[Epoch 9, Batch 600] loss: 0.02705773643188877
[Epoch 9, Batch 700] loss: 0.018898225193224788
[Epoch 9, Batch 800] loss: 0.021242394006985705
[Epoch 9, Batch 900] loss: 0.01986154357829946
[Epoch 9, Batch 1000] loss: 0.026163369574351236
[Epoch 9, Batch 1100] loss: 0.022818993859837065
[Epoch 9, Batch 1200] loss: 0.022274509615526766
[Epoch 9, Batch 1300] loss: 0.026328808398830006
[Epoch 9, Batch 1400] loss: 0.034990897931566
[Epoch 9, Batch 1500] loss: 0.028057055569661316
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0408
Validation Accuracy: 0.9876
Overfitting: 0.0408
Best model saved at epoch 9 with validation loss: 0.0408
[Epoch 10, Batch 100] loss: 0.021804012171924115
[Epoch 10, Batch 200] loss: 0.015094629858067492
[Epoch 10, Batch 300] loss: 0.018174080069584306
[Epoch 10, Batch 400] loss: 0.01777516429690877
[Epoch 10, Batch 500] loss: 0.023801553468074416
[Epoch 10, Batch 600] loss: 0.014146012486016844
[Epoch 10, Batch 700] loss: 0.014135730955458711
[Epoch 10, Batch 800] loss: 0.016562713669991354
[Epoch 10, Batch 900] loss: 0.025865939603172593
[Epoch 10, Batch 1000] loss: 0.01847973026458931
[Epoch 10, Batch 1100] loss: 0.020182722355530133
[Epoch 10, Batch 1200] loss: 0.02685411581507651
[Epoch 10, Batch 1300] loss: 0.02646095635922393
[Epoch 10, Batch 1400] loss: 0.021359339770424413
[Epoch 10, Batch 1500] loss: 0.023177610956045102
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9845
Overfitting: 0.0477
[Epoch 11, Batch 100] loss: 0.017349889972247182
[Epoch 11, Batch 200] loss: 0.01626257601856196
[Epoch 11, Batch 300] loss: 0.022443763557384956
[Epoch 11, Batch 400] loss: 0.019076111319300253
[Epoch 11, Batch 500] loss: 0.015049551326665096
[Epoch 11, Batch 600] loss: 0.01755761004793385
[Epoch 11, Batch 700] loss: 0.015025408558503841
[Epoch 11, Batch 800] loss: 0.013716942821702105
[Epoch 11, Batch 900] loss: 0.0175951120670652
[Epoch 11, Batch 1000] loss: 0.01813108132315392
[Epoch 11, Batch 1100] loss: 0.015959056959145526
[Epoch 11, Batch 1200] loss: 0.011760672387026716
[Epoch 11, Batch 1300] loss: 0.017853244796024226
[Epoch 11, Batch 1400] loss: 0.029982654738414567
[Epoch 11, Batch 1500] loss: 0.02007828011381207
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9856
Overfitting: 0.0467
[Epoch 12, Batch 100] loss: 0.015515545620437478
[Epoch 12, Batch 200] loss: 0.013214572987053544
[Epoch 12, Batch 300] loss: 0.013761994683445664
[Epoch 12, Batch 400] loss: 0.014055303368295427
[Epoch 12, Batch 500] loss: 0.017611865901126292
[Epoch 12, Batch 600] loss: 0.01430663010221906
[Epoch 12, Batch 700] loss: 0.012719076057055644
[Epoch 12, Batch 800] loss: 0.019713660544657615
[Epoch 12, Batch 900] loss: 0.016680958541946893
[Epoch 12, Batch 1000] loss: 0.018743065837879838
[Epoch 12, Batch 1100] loss: 0.015788872664197696
[Epoch 12, Batch 1200] loss: 0.01596000279274449
[Epoch 12, Batch 1300] loss: 0.017368825113153435
[Epoch 12, Batch 1400] loss: 0.018297282209969127
[Epoch 12, Batch 1500] loss: 0.007941170086196507
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0423
Validation Accuracy: 0.9885
Overfitting: 0.0423
[Epoch 13, Batch 100] loss: 0.01563992841533036
[Epoch 13, Batch 200] loss: 0.017211393643447082
[Epoch 13, Batch 300] loss: 0.017642318625566988
[Epoch 13, Batch 400] loss: 0.01310484564917715
[Epoch 13, Batch 500] loss: 0.012664383583396556
[Epoch 13, Batch 600] loss: 0.012524612113375043
[Epoch 13, Batch 700] loss: 0.010997225618266384
[Epoch 13, Batch 800] loss: 0.013839001241785808
[Epoch 13, Batch 900] loss: 0.014173598703673634
[Epoch 13, Batch 1000] loss: 0.012601341755344038
[Epoch 13, Batch 1100] loss: 0.012131418942735762
[Epoch 13, Batch 1200] loss: 0.024672020745565532
[Epoch 13, Batch 1300] loss: 0.010660045942386205
[Epoch 13, Batch 1400] loss: 0.01502761282135907
[Epoch 13, Batch 1500] loss: 0.010084047594264121
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0409
Validation Accuracy: 0.9888
Overfitting: 0.0409
[Epoch 14, Batch 100] loss: 0.007422252109390684
[Epoch 14, Batch 200] loss: 0.006880305610466166
[Epoch 14, Batch 300] loss: 0.008685892553075973
[Epoch 14, Batch 400] loss: 0.011426284368808411
[Epoch 14, Batch 500] loss: 0.009832825811008661
[Epoch 14, Batch 600] loss: 0.023230439437757013
[Epoch 14, Batch 700] loss: 0.018956628162486597
[Epoch 14, Batch 800] loss: 0.011874578374772682
[Epoch 14, Batch 900] loss: 0.015156056599789736
[Epoch 14, Batch 1000] loss: 0.01067721994339081
[Epoch 14, Batch 1100] loss: 0.01145196285127895
[Epoch 14, Batch 1200] loss: 0.009538708977670467
[Epoch 14, Batch 1300] loss: 0.01262074098791345
[Epoch 14, Batch 1400] loss: 0.014866236817542813
[Epoch 14, Batch 1500] loss: 0.006853315642129019
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0382
Validation Accuracy: 0.9893
Overfitting: 0.0382
Best model saved at epoch 14 with validation loss: 0.0382
[Epoch 15, Batch 100] loss: 0.004129085969561856
[Epoch 15, Batch 200] loss: 0.009401014007489722
[Epoch 15, Batch 300] loss: 0.00707247893659769
[Epoch 15, Batch 400] loss: 0.008995570287752344
[Epoch 15, Batch 500] loss: 0.004687975935576105
[Epoch 15, Batch 600] loss: 0.01885950385760225
[Epoch 15, Batch 700] loss: 0.007623014161454194
[Epoch 15, Batch 800] loss: 0.011156742393504828
[Epoch 15, Batch 900] loss: 0.008795180743900346
[Epoch 15, Batch 1000] loss: 0.012860351115523371
[Epoch 15, Batch 1100] loss: 0.0078064209316107734
[Epoch 15, Batch 1200] loss: 0.012869144714659341
[Epoch 15, Batch 1300] loss: 0.012389351506953972
[Epoch 15, Batch 1400] loss: 0.015392677587733487
[Epoch 15, Batch 1500] loss: 0.014815770085879193
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9873
Overfitting: 0.0456
[Epoch 16, Batch 100] loss: 0.005452779502438716
[Epoch 16, Batch 200] loss: 0.009902129423389852
[Epoch 16, Batch 300] loss: 0.0179924239218235
[Epoch 16, Batch 400] loss: 0.011355701026386668
[Epoch 16, Batch 500] loss: 0.006495403165681637
[Epoch 16, Batch 600] loss: 0.010959358589270779
[Epoch 16, Batch 700] loss: 0.011056606258780449
[Epoch 16, Batch 800] loss: 0.006821365582436556
[Epoch 16, Batch 900] loss: 0.007341856769799051
[Epoch 16, Batch 1000] loss: 0.009280496808787574
[Epoch 16, Batch 1100] loss: 0.010374807057705765
[Epoch 16, Batch 1200] loss: 0.00733414895243186
[Epoch 16, Batch 1300] loss: 0.012757411445368233
[Epoch 16, Batch 1400] loss: 0.004919681330011372
[Epoch 16, Batch 1500] loss: 0.008188975656648835
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9872
Overfitting: 0.0459
[Epoch 17, Batch 100] loss: 0.006328019158218012
[Epoch 17, Batch 200] loss: 0.004024518684409486
[Epoch 17, Batch 300] loss: 0.00855111185701844
[Epoch 17, Batch 400] loss: 0.011679858466095538
[Epoch 17, Batch 500] loss: 0.008414839069100708
[Epoch 17, Batch 600] loss: 0.006877061469122054
[Epoch 17, Batch 700] loss: 0.004699633767413616
[Epoch 17, Batch 800] loss: 0.005225146011634933
[Epoch 17, Batch 900] loss: 0.004877973531520184
[Epoch 17, Batch 1000] loss: 0.007551740546632573
[Epoch 17, Batch 1100] loss: 0.014218187281912834
[Epoch 17, Batch 1200] loss: 0.009377056644279947
[Epoch 17, Batch 1300] loss: 0.013071812574094111
[Epoch 17, Batch 1400] loss: 0.00908453992642535
[Epoch 17, Batch 1500] loss: 0.009854358539869282
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9862
Overfitting: 0.0525
[Epoch 18, Batch 100] loss: 0.006671840489234455
[Epoch 18, Batch 200] loss: 0.006021939784504866
[Epoch 18, Batch 300] loss: 0.005206740180465203
[Epoch 18, Batch 400] loss: 0.0039147055224975705
[Epoch 18, Batch 500] loss: 0.004380257447246549
[Epoch 18, Batch 600] loss: 0.014769111889181659
[Epoch 18, Batch 700] loss: 0.009629514164917054
[Epoch 18, Batch 800] loss: 0.005087696612526997
[Epoch 18, Batch 900] loss: 0.0033878427678246227
[Epoch 18, Batch 1000] loss: 0.0055656014385840535
[Epoch 18, Batch 1100] loss: 0.009247374093361032
[Epoch 18, Batch 1200] loss: 0.008451910739895539
[Epoch 18, Batch 1300] loss: 0.00864606332918811
[Epoch 18, Batch 1400] loss: 0.006323983380393656
[Epoch 18, Batch 1500] loss: 0.01084609845382829
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0444
Validation Accuracy: 0.9891
Overfitting: 0.0444
[Epoch 19, Batch 100] loss: 0.009544549693555383
[Epoch 19, Batch 200] loss: 0.007611682701644895
[Epoch 19, Batch 300] loss: 0.0067835778861262954
[Epoch 19, Batch 400] loss: 0.0058015705390653234
[Epoch 19, Batch 500] loss: 0.008547938811116183
[Epoch 19, Batch 600] loss: 0.010171052183923166
[Epoch 19, Batch 700] loss: 0.00793583582136307
[Epoch 19, Batch 800] loss: 0.005498638976951043
[Epoch 19, Batch 900] loss: 0.0053076697950746165
[Epoch 19, Batch 1000] loss: 0.004569672843597345
[Epoch 19, Batch 1100] loss: 0.00990701748650963
[Epoch 19, Batch 1200] loss: 0.006060104509438133
[Epoch 19, Batch 1300] loss: 0.00502945758560827
[Epoch 19, Batch 1400] loss: 0.009693595683315834
[Epoch 19, Batch 1500] loss: 0.011914708979775241
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9879
Overfitting: 0.0465
[Epoch 20, Batch 100] loss: 0.009577528858426377
[Epoch 20, Batch 200] loss: 0.008694643214921598
[Epoch 20, Batch 300] loss: 0.007257444449405739
[Epoch 20, Batch 400] loss: 0.0025803059996633237
[Epoch 20, Batch 500] loss: 0.006479647459939315
[Epoch 20, Batch 600] loss: 0.0078088532373385535
[Epoch 20, Batch 700] loss: 0.008264488778131636
[Epoch 20, Batch 800] loss: 0.00526477959637532
[Epoch 20, Batch 900] loss: 0.00585472401241077
[Epoch 20, Batch 1000] loss: 0.005685171416985213
[Epoch 20, Batch 1100] loss: 0.005492022799553524
[Epoch 20, Batch 1200] loss: 0.004148562407344798
[Epoch 20, Batch 1300] loss: 0.006299685617780142
[Epoch 20, Batch 1400] loss: 0.007074285986172981
[Epoch 20, Batch 1500] loss: 0.006994323038775292
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9889
Overfitting: 0.0459
[Epoch 21, Batch 100] loss: 0.006059518657498302
[Epoch 21, Batch 200] loss: 0.002960991888071476
[Epoch 21, Batch 300] loss: 0.0029474909996679345
[Epoch 21, Batch 400] loss: 0.0035317391088346994
[Epoch 21, Batch 500] loss: 0.005209579873978782
[Epoch 21, Batch 600] loss: 0.0037208159624128713
[Epoch 21, Batch 700] loss: 0.005058574869569839
[Epoch 21, Batch 800] loss: 0.003980018217571341
[Epoch 21, Batch 900] loss: 0.002135065458605823
[Epoch 21, Batch 1000] loss: 0.0026396134396691195
[Epoch 21, Batch 1100] loss: 0.0039845392156667
[Epoch 21, Batch 1200] loss: 0.011600725655025599
[Epoch 21, Batch 1300] loss: 0.00507227219838569
[Epoch 21, Batch 1400] loss: 0.004835289438451582
[Epoch 21, Batch 1500] loss: 0.009707755625972822
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9888
Overfitting: 0.0471
[Epoch 22, Batch 100] loss: 0.002977199949295937
[Epoch 22, Batch 200] loss: 0.0013932423528649452
[Epoch 22, Batch 300] loss: 0.004963513387394869
[Epoch 22, Batch 400] loss: 0.0027012100266119886
[Epoch 22, Batch 500] loss: 0.002184553142310506
[Epoch 22, Batch 600] loss: 0.00305541319057852
[Epoch 22, Batch 700] loss: 0.0046655618211650565
[Epoch 22, Batch 800] loss: 0.003470620676134786
[Epoch 22, Batch 900] loss: 0.005378320244735732
[Epoch 22, Batch 1000] loss: 0.0036054898579027396
[Epoch 22, Batch 1100] loss: 0.004212079433593772
[Epoch 22, Batch 1200] loss: 0.006489327953088378
[Epoch 22, Batch 1300] loss: 0.0065099094101969965
[Epoch 22, Batch 1400] loss: 0.005970044048597174
[Epoch 22, Batch 1500] loss: 0.0021025054484994144
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0429
Validation Accuracy: 0.9902
Overfitting: 0.0429
[Epoch 23, Batch 100] loss: 0.002328332773452075
[Epoch 23, Batch 200] loss: 0.003790122422992681
[Epoch 23, Batch 300] loss: 0.0030178839393443014
[Epoch 23, Batch 400] loss: 0.0011665850126951227
[Epoch 23, Batch 500] loss: 0.0022033349807259127
[Epoch 23, Batch 600] loss: 0.0030811393991911017
[Epoch 23, Batch 700] loss: 0.0033311161388056123
[Epoch 23, Batch 800] loss: 0.006160109348676315
[Epoch 23, Batch 900] loss: 0.0030274307049177195
[Epoch 23, Batch 1000] loss: 0.0050247707026710485
[Epoch 23, Batch 1100] loss: 0.0086664839408445
[Epoch 23, Batch 1200] loss: 0.004668067533276599
[Epoch 23, Batch 1300] loss: 0.0028038930947445807
[Epoch 23, Batch 1400] loss: 0.003911389983143181
[Epoch 23, Batch 1500] loss: 0.004730001148993778
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9882
Overfitting: 0.0508
[Epoch 24, Batch 100] loss: 0.0009546770681208727
[Epoch 24, Batch 200] loss: 0.0011668756080575804
[Epoch 24, Batch 300] loss: 0.002257674610561935
[Epoch 24, Batch 400] loss: 0.002930873696100207
[Epoch 24, Batch 500] loss: 0.0032017069197002
[Epoch 24, Batch 600] loss: 0.001535580373472385
[Epoch 24, Batch 700] loss: 0.000685228743495827
[Epoch 24, Batch 800] loss: 0.0025298530256532103
[Epoch 24, Batch 900] loss: 0.0019465632120386545
[Epoch 24, Batch 1000] loss: 0.0025759632410233737
[Epoch 24, Batch 1100] loss: 0.002318903453948451
[Epoch 24, Batch 1200] loss: 0.0037916087849112047
[Epoch 24, Batch 1300] loss: 0.004439996446030818
[Epoch 24, Batch 1400] loss: 0.004084681399396004
[Epoch 24, Batch 1500] loss: 0.002821202916609309
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9888
Overfitting: 0.0476
Fold 5 validation loss: 0.0476
Mean validation loss across all folds for Trial 19 is 0.0538 with trial config:  l1: 256, l2: 128, lr: 0.001964936455612933, batch_size: 32
[I 2024-12-11 05:42:42,973] Trial 18 finished with value: 0.05377937521482875 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.001964936455612933, 'batch_size': 32}. Best is trial 4 with value: 0.046929042829858846.

Selected Hyperparameters for Trial 20:
  l1: 256, l2: 128, lr: 0.000421314399877729, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2906501126289367
[Epoch 1, Batch 200] loss: 2.262712690830231
[Epoch 1, Batch 300] loss: 2.2132114481925966
[Epoch 1, Batch 400] loss: 2.0943044352531435
[Epoch 1, Batch 500] loss: 1.8080802595615386
[Epoch 1, Batch 600] loss: 1.356823816895485
[Epoch 1, Batch 700] loss: 1.006952276825905
[Epoch 1, Batch 800] loss: 0.764664877653122
[Epoch 1, Batch 900] loss: 0.6177238462865353
[Epoch 1, Batch 1000] loss: 0.5114892463386059
[Epoch 1, Batch 1100] loss: 0.5247028606384992
[Epoch 1, Batch 1200] loss: 0.5016437963396311
[Epoch 1, Batch 1300] loss: 0.46010267674922944
[Epoch 1, Batch 1400] loss: 0.42134262397885325
[Epoch 1, Batch 1500] loss: 0.3720209862291813
[Epoch 1, Batch 1600] loss: 0.3823194118961692
[Epoch 1, Batch 1700] loss: 0.3334694990515709
[Epoch 1, Batch 1800] loss: 0.30997953586280347
[Epoch 1, Batch 1900] loss: 0.30691464073956015
[Epoch 1, Batch 2000] loss: 0.2797422942146659
[Epoch 1, Batch 2100] loss: 0.29424267847090957
[Epoch 1, Batch 2200] loss: 0.3056170063093305
[Epoch 1, Batch 2300] loss: 0.2965529765933752
[Epoch 1, Batch 2400] loss: 0.246498629078269
[Epoch 1, Batch 2500] loss: 0.25567170094698666
[Epoch 1, Batch 2600] loss: 0.26260819679126146
[Epoch 1, Batch 2700] loss: 0.23974069071933626
[Epoch 1, Batch 2800] loss: 0.24661214148625732
[Epoch 1, Batch 2900] loss: 0.25748449640348553
[Epoch 1, Batch 3000] loss: 0.22471488729119302
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2141
Validation Accuracy: 0.9342
Overfitting: 0.2141
Best model saved at epoch 1 with validation loss: 0.2141
[Epoch 2, Batch 100] loss: 0.24063931364566088
[Epoch 2, Batch 200] loss: 0.18439990589395167
[Epoch 2, Batch 300] loss: 0.20533260364085437
[Epoch 2, Batch 400] loss: 0.19100486202165484
[Epoch 2, Batch 500] loss: 0.21099752485752105
[Epoch 2, Batch 600] loss: 0.21169964022934437
[Epoch 2, Batch 700] loss: 0.22950022496283054
[Epoch 2, Batch 800] loss: 0.17715729667805136
[Epoch 2, Batch 900] loss: 0.16188999094534665
[Epoch 2, Batch 1000] loss: 0.16025127745233475
[Epoch 2, Batch 1100] loss: 0.19856420259922744
[Epoch 2, Batch 1200] loss: 0.1538829350285232
[Epoch 2, Batch 1300] loss: 0.16137849796563386
[Epoch 2, Batch 1400] loss: 0.17443651942536234
[Epoch 2, Batch 1500] loss: 0.16878192777745427
[Epoch 2, Batch 1600] loss: 0.153090216871351
[Epoch 2, Batch 1700] loss: 0.16355774302966894
[Epoch 2, Batch 1800] loss: 0.12369828808121383
[Epoch 2, Batch 1900] loss: 0.15457933908328414
[Epoch 2, Batch 2000] loss: 0.13623352343216538
[Epoch 2, Batch 2100] loss: 0.12755939522758125
[Epoch 2, Batch 2200] loss: 0.16016025949269533
[Epoch 2, Batch 2300] loss: 0.15323089411016555
[Epoch 2, Batch 2400] loss: 0.1325454929890111
[Epoch 2, Batch 2500] loss: 0.16502990767825396
[Epoch 2, Batch 2600] loss: 0.15509260199032723
[Epoch 2, Batch 2700] loss: 0.14949252587743103
[Epoch 2, Batch 2800] loss: 0.14603073589503765
[Epoch 2, Batch 2900] loss: 0.1444312839023769
[Epoch 2, Batch 3000] loss: 0.1313418451976031
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1289
Validation Accuracy: 0.9595
Overfitting: 0.1289
Best model saved at epoch 2 with validation loss: 0.1289
[Epoch 3, Batch 100] loss: 0.11043931145686656
[Epoch 3, Batch 200] loss: 0.1225886924029328
[Epoch 3, Batch 300] loss: 0.11011570319067687
[Epoch 3, Batch 400] loss: 0.1323744104197249
[Epoch 3, Batch 500] loss: 0.10964070182759315
[Epoch 3, Batch 600] loss: 0.10117248965427279
[Epoch 3, Batch 700] loss: 0.11887028716038912
[Epoch 3, Batch 800] loss: 0.1361359547218308
[Epoch 3, Batch 900] loss: 0.11184851649217308
[Epoch 3, Batch 1000] loss: 0.09214407116058282
[Epoch 3, Batch 1100] loss: 0.10862203740514814
[Epoch 3, Batch 1200] loss: 0.1527222057292238
[Epoch 3, Batch 1300] loss: 0.12195997935254127
[Epoch 3, Batch 1400] loss: 0.10765113120898605
[Epoch 3, Batch 1500] loss: 0.10098014204530045
[Epoch 3, Batch 1600] loss: 0.10898623297922314
[Epoch 3, Batch 1700] loss: 0.10029554013162852
[Epoch 3, Batch 1800] loss: 0.11605444538872689
[Epoch 3, Batch 1900] loss: 0.12309874809579924
[Epoch 3, Batch 2000] loss: 0.11937797646271064
[Epoch 3, Batch 2100] loss: 0.10221788916038349
[Epoch 3, Batch 2200] loss: 0.1014221540861763
[Epoch 3, Batch 2300] loss: 0.11605230199173093
[Epoch 3, Batch 2400] loss: 0.08197571909986437
[Epoch 3, Batch 2500] loss: 0.11106410817243159
[Epoch 3, Batch 2600] loss: 0.08272580666001886
[Epoch 3, Batch 2700] loss: 0.09335779976798221
[Epoch 3, Batch 2800] loss: 0.09534471599676181
[Epoch 3, Batch 2900] loss: 0.1030598174687475
[Epoch 3, Batch 3000] loss: 0.10634607111103833
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1286
Validation Accuracy: 0.9585
Overfitting: 0.1286
Best model saved at epoch 3 with validation loss: 0.1286
[Epoch 4, Batch 100] loss: 0.09235750813502819
[Epoch 4, Batch 200] loss: 0.10312509262468667
[Epoch 4, Batch 300] loss: 0.06678277739090845
[Epoch 4, Batch 400] loss: 0.07833648944506422
[Epoch 4, Batch 500] loss: 0.08464327838039026
[Epoch 4, Batch 600] loss: 0.07702721446170471
[Epoch 4, Batch 700] loss: 0.08791952728526667
[Epoch 4, Batch 800] loss: 0.07935373059706763
[Epoch 4, Batch 900] loss: 0.08093683466780931
[Epoch 4, Batch 1000] loss: 0.1119852548930794
[Epoch 4, Batch 1100] loss: 0.07932635922799819
[Epoch 4, Batch 1200] loss: 0.08994475427898578
[Epoch 4, Batch 1300] loss: 0.08521945581072941
[Epoch 4, Batch 1400] loss: 0.08857126850867644
[Epoch 4, Batch 1500] loss: 0.08341223738621921
[Epoch 4, Batch 1600] loss: 0.08203353162738494
[Epoch 4, Batch 1700] loss: 0.10250516462139786
[Epoch 4, Batch 1800] loss: 0.06134293289855122
[Epoch 4, Batch 1900] loss: 0.09279945734655484
[Epoch 4, Batch 2000] loss: 0.0681182290520519
[Epoch 4, Batch 2100] loss: 0.0814709600014612
[Epoch 4, Batch 2200] loss: 0.08275970084709115
[Epoch 4, Batch 2300] loss: 0.09491501915967092
[Epoch 4, Batch 2400] loss: 0.09151947489473969
[Epoch 4, Batch 2500] loss: 0.09872385454946198
[Epoch 4, Batch 2600] loss: 0.09759530151612125
[Epoch 4, Batch 2700] loss: 0.08239857835229486
[Epoch 4, Batch 2800] loss: 0.06520310036372394
[Epoch 4, Batch 2900] loss: 0.06531313282321208
[Epoch 4, Batch 3000] loss: 0.07080834999331273
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0844
Validation Accuracy: 0.9735
Overfitting: 0.0844
Best model saved at epoch 4 with validation loss: 0.0844
[Epoch 5, Batch 100] loss: 0.06854382446035742
[Epoch 5, Batch 200] loss: 0.06728997217840516
[Epoch 5, Batch 300] loss: 0.07369637627154589
[Epoch 5, Batch 400] loss: 0.06749898921174463
[Epoch 5, Batch 500] loss: 0.07230659989640116
[Epoch 5, Batch 600] loss: 0.07014112100820057
[Epoch 5, Batch 700] loss: 0.0739935916266404
[Epoch 5, Batch 800] loss: 0.08435827702633106
[Epoch 5, Batch 900] loss: 0.059573199851438406
[Epoch 5, Batch 1000] loss: 0.07141230586683378
[Epoch 5, Batch 1100] loss: 0.06619011252070778
[Epoch 5, Batch 1200] loss: 0.0969762831297703
[Epoch 5, Batch 1300] loss: 0.06513659276184626
[Epoch 5, Batch 1400] loss: 0.06206305405648891
[Epoch 5, Batch 1500] loss: 0.0779719614610076
[Epoch 5, Batch 1600] loss: 0.049468645873130296
[Epoch 5, Batch 1700] loss: 0.0708129003609065
[Epoch 5, Batch 1800] loss: 0.07496026475913822
[Epoch 5, Batch 1900] loss: 0.06522250284673646
[Epoch 5, Batch 2000] loss: 0.05684329168405384
[Epoch 5, Batch 2100] loss: 0.09262897619861178
[Epoch 5, Batch 2200] loss: 0.07101882724207825
[Epoch 5, Batch 2300] loss: 0.06584829517873005
[Epoch 5, Batch 2400] loss: 0.0606001071666833
[Epoch 5, Batch 2500] loss: 0.05589327058114577
[Epoch 5, Batch 2600] loss: 0.060224587711854835
[Epoch 5, Batch 2700] loss: 0.06860626094567124
[Epoch 5, Batch 2800] loss: 0.06760917839943431
[Epoch 5, Batch 2900] loss: 0.06941337828349788
[Epoch 5, Batch 3000] loss: 0.0658676935423864
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0686
Validation Accuracy: 0.9777
Overfitting: 0.0686
Best model saved at epoch 5 with validation loss: 0.0686
[Epoch 6, Batch 100] loss: 0.08135918775456957
[Epoch 6, Batch 200] loss: 0.08111688742064871
[Epoch 6, Batch 300] loss: 0.059394152287277395
[Epoch 6, Batch 400] loss: 0.05105942026246339
[Epoch 6, Batch 500] loss: 0.059339068318950014
[Epoch 6, Batch 600] loss: 0.05349810471292585
[Epoch 6, Batch 700] loss: 0.06496656115108636
[Epoch 6, Batch 800] loss: 0.05957281380542554
[Epoch 6, Batch 900] loss: 0.07423986095760483
[Epoch 6, Batch 1000] loss: 0.06658129363087938
[Epoch 6, Batch 1100] loss: 0.06776028512918857
[Epoch 6, Batch 1200] loss: 0.06516413742851
[Epoch 6, Batch 1300] loss: 0.06773594598053023
[Epoch 6, Batch 1400] loss: 0.04478889224759769
[Epoch 6, Batch 1500] loss: 0.05455891010933556
[Epoch 6, Batch 1600] loss: 0.05373555515136104
[Epoch 6, Batch 1700] loss: 0.051743803055142056
[Epoch 6, Batch 1800] loss: 0.0526559421105776
[Epoch 6, Batch 1900] loss: 0.05044020437635481
[Epoch 6, Batch 2000] loss: 0.04783210711029824
[Epoch 6, Batch 2100] loss: 0.06717779215599876
[Epoch 6, Batch 2200] loss: 0.06649767089838861
[Epoch 6, Batch 2300] loss: 0.05438101049745456
[Epoch 6, Batch 2400] loss: 0.04471485634334385
[Epoch 6, Batch 2500] loss: 0.057397595331567575
[Epoch 6, Batch 2600] loss: 0.057487178910523656
[Epoch 6, Batch 2700] loss: 0.03882571765687317
[Epoch 6, Batch 2800] loss: 0.048321305800927805
[Epoch 6, Batch 2900] loss: 0.05878152853460051
[Epoch 6, Batch 3000] loss: 0.046124043515010274
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0574
Validation Accuracy: 0.9816
Overfitting: 0.0574
[I 2024-12-11 05:44:07,236] Trial 19 pruned. 

Selected Hyperparameters for Trial 21:
  l1: 128, l2: 128, lr: 0.003723057268711563, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.247103431224823
[Epoch 1, Batch 200] loss: 0.9191748741269111
[Epoch 1, Batch 300] loss: 0.39002595737576484
[Epoch 1, Batch 400] loss: 0.2807432958483696
[Epoch 1, Batch 500] loss: 0.21007986649870872
[Epoch 1, Batch 600] loss: 0.16749264601618052
[Epoch 1, Batch 700] loss: 0.15320859773084522
**STATS for Epoch 1** : 
Average training loss: 0.0088
Average validation loss: 0.1341
Validation Accuracy: 0.9551
Overfitting: 0.1252
Best model saved at epoch 1 with validation loss: 0.1341
[Epoch 2, Batch 100] loss: 0.12898065082728863
[Epoch 2, Batch 200] loss: 0.11522101428359748
[Epoch 2, Batch 300] loss: 0.09846264611929655
[Epoch 2, Batch 400] loss: 0.10007395209744573
[Epoch 2, Batch 500] loss: 0.10138596704229713
[Epoch 2, Batch 600] loss: 0.08450145861599595
[Epoch 2, Batch 700] loss: 0.08597354780882598
**STATS for Epoch 2** : 
Average training loss: 0.0057
Average validation loss: 0.0667
Validation Accuracy: 0.9780
Overfitting: 0.0609
Best model saved at epoch 2 with validation loss: 0.0667
[Epoch 3, Batch 100] loss: 0.07285660089924932
[Epoch 3, Batch 200] loss: 0.0574929275130853
[Epoch 3, Batch 300] loss: 0.06757827753666788
[Epoch 3, Batch 400] loss: 0.06619379620999098
[Epoch 3, Batch 500] loss: 0.07462834926322102
[Epoch 3, Batch 600] loss: 0.06520862264558673
[Epoch 3, Batch 700] loss: 0.07835981829557567
**STATS for Epoch 3** : 
Average training loss: 0.0044
Average validation loss: 0.0575
Validation Accuracy: 0.9823
Overfitting: 0.0532
Best model saved at epoch 3 with validation loss: 0.0575
[Epoch 4, Batch 100] loss: 0.04775293998653069
[Epoch 4, Batch 200] loss: 0.05681299251038581
[Epoch 4, Batch 300] loss: 0.06617339680436998
[Epoch 4, Batch 400] loss: 0.061961962240748104
[Epoch 4, Batch 500] loss: 0.05569445898290724
[Epoch 4, Batch 600] loss: 0.052587047280976545
[Epoch 4, Batch 700] loss: 0.046951305372640494
**STATS for Epoch 4** : 
Average training loss: 0.0036
Average validation loss: 0.0481
Validation Accuracy: 0.9843
Overfitting: 0.0445
Best model saved at epoch 4 with validation loss: 0.0481
[Epoch 5, Batch 100] loss: 0.0442768619582057
[Epoch 5, Batch 200] loss: 0.051706004308070985
[Epoch 5, Batch 300] loss: 0.04352200776804239
[Epoch 5, Batch 400] loss: 0.04790841112844646
[Epoch 5, Batch 500] loss: 0.04220533507177606
[Epoch 5, Batch 600] loss: 0.04321979938074946
[Epoch 5, Batch 700] loss: 0.04540852013044059
**STATS for Epoch 5** : 
Average training loss: 0.0024
Average validation loss: 0.0544
Validation Accuracy: 0.9811
Overfitting: 0.0520
[Epoch 6, Batch 100] loss: 0.03307409620960243
[Epoch 6, Batch 200] loss: 0.03486506602377631
[Epoch 6, Batch 300] loss: 0.0403618004033342
[Epoch 6, Batch 400] loss: 0.0407348116626963
[Epoch 6, Batch 500] loss: 0.032510956407058984
[Epoch 6, Batch 600] loss: 0.036522750151343646
[Epoch 6, Batch 700] loss: 0.04188509375671856
**STATS for Epoch 6** : 
Average training loss: 0.0020
Average validation loss: 0.0427
Validation Accuracy: 0.9862
Overfitting: 0.0407
Best model saved at epoch 6 with validation loss: 0.0427
[Epoch 7, Batch 100] loss: 0.0274017277196981
[Epoch 7, Batch 200] loss: 0.030521218681242315
[Epoch 7, Batch 300] loss: 0.029907628365326674
[Epoch 7, Batch 400] loss: 0.03627759564551525
[Epoch 7, Batch 500] loss: 0.02622495403746143
[Epoch 7, Batch 600] loss: 0.03849731177673675
[Epoch 7, Batch 700] loss: 0.03523042890010401
**STATS for Epoch 7** : 
Average training loss: 0.0025
Average validation loss: 0.0451
Validation Accuracy: 0.9856
Overfitting: 0.0426
[Epoch 8, Batch 100] loss: 0.020840148123970722
[Epoch 8, Batch 200] loss: 0.026739245548669716
[Epoch 8, Batch 300] loss: 0.02728224198857788
[Epoch 8, Batch 400] loss: 0.030581765548558907
[Epoch 8, Batch 500] loss: 0.02869369507272495
[Epoch 8, Batch 600] loss: 0.028295648916391657
[Epoch 8, Batch 700] loss: 0.02758375421515666
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0427
Validation Accuracy: 0.9861
Overfitting: 0.0407
[Epoch 9, Batch 100] loss: 0.019779942323220893
[Epoch 9, Batch 200] loss: 0.018317262217169627
[Epoch 9, Batch 300] loss: 0.028914287827210502
[Epoch 9, Batch 400] loss: 0.025228498776850756
[Epoch 9, Batch 500] loss: 0.024837011114577763
[Epoch 9, Batch 600] loss: 0.02402407857327489
[Epoch 9, Batch 700] loss: 0.025657998247188517
**STATS for Epoch 9** : 
Average training loss: 0.0015
Average validation loss: 0.0379
Validation Accuracy: 0.9878
Overfitting: 0.0364
Best model saved at epoch 9 with validation loss: 0.0379
[Epoch 10, Batch 100] loss: 0.01830550867423881
[Epoch 10, Batch 200] loss: 0.020237213390355464
[Epoch 10, Batch 300] loss: 0.020201243911287747
[Epoch 10, Batch 400] loss: 0.02673801273864228
[Epoch 10, Batch 500] loss: 0.02053114361682674
[Epoch 10, Batch 600] loss: 0.02064724258496426
[Epoch 10, Batch 700] loss: 0.023551503464113922
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0392
Validation Accuracy: 0.9892
Overfitting: 0.0380
[Epoch 11, Batch 100] loss: 0.011636662025994155
[Epoch 11, Batch 200] loss: 0.019446224595740205
[Epoch 11, Batch 300] loss: 0.018020921425195412
[Epoch 11, Batch 400] loss: 0.019578737337724306
[Epoch 11, Batch 500] loss: 0.01973773706180509
[Epoch 11, Batch 600] loss: 0.021804708366980775
[Epoch 11, Batch 700] loss: 0.01638075163718895
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0384
Validation Accuracy: 0.9890
Overfitting: 0.0372
[Epoch 12, Batch 100] loss: 0.01488601059303619
[Epoch 12, Batch 200] loss: 0.016487772005493753
[Epoch 12, Batch 300] loss: 0.02075447127397638
[Epoch 12, Batch 400] loss: 0.011960602238978026
[Epoch 12, Batch 500] loss: 0.016578824692987836
[Epoch 12, Batch 600] loss: 0.020654739170568065
[Epoch 12, Batch 700] loss: 0.016202887096005723
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0429
Validation Accuracy: 0.9878
Overfitting: 0.0419
[Epoch 13, Batch 100] loss: 0.009431858767202357
[Epoch 13, Batch 200] loss: 0.013766145793706528
[Epoch 13, Batch 300] loss: 0.0130853533714253
[Epoch 13, Batch 400] loss: 0.01451403213010053
[Epoch 13, Batch 500] loss: 0.012850229574542026
[Epoch 13, Batch 600] loss: 0.019645275870570914
[Epoch 13, Batch 700] loss: 0.01984460136969574
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0473
Validation Accuracy: 0.9859
Overfitting: 0.0463
[Epoch 14, Batch 100] loss: 0.020685965728916927
[Epoch 14, Batch 200] loss: 0.008572111671528547
[Epoch 14, Batch 300] loss: 0.014399945453624241
[Epoch 14, Batch 400] loss: 0.011539582681652973
[Epoch 14, Batch 500] loss: 0.00808347031204903
[Epoch 14, Batch 600] loss: 0.008602204658818663
[Epoch 14, Batch 700] loss: 0.019493186882900772
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0432
Validation Accuracy: 0.9873
Overfitting: 0.0424
[Epoch 15, Batch 100] loss: 0.012977846006197068
[Epoch 15, Batch 200] loss: 0.010146483904391062
[Epoch 15, Batch 300] loss: 0.011615149195567937
[Epoch 15, Batch 400] loss: 0.008904792882021865
[Epoch 15, Batch 500] loss: 0.009111754539917456
[Epoch 15, Batch 600] loss: 0.011661652241891717
[Epoch 15, Batch 700] loss: 0.010323017849514145
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0597
Validation Accuracy: 0.9837
Overfitting: 0.0590
[Epoch 16, Batch 100] loss: 0.013386347720115736
[Epoch 16, Batch 200] loss: 0.012033627286691627
[Epoch 16, Batch 300] loss: 0.007466402238642331
[Epoch 16, Batch 400] loss: 0.013111040927396971
[Epoch 16, Batch 500] loss: 0.012618964890862117
[Epoch 16, Batch 600] loss: 0.011334657900297316
[Epoch 16, Batch 700] loss: 0.010852050186076666
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0411
Validation Accuracy: 0.9881
Overfitting: 0.0405
[Epoch 17, Batch 100] loss: 0.007049353010515915
[Epoch 17, Batch 200] loss: 0.00958486841105696
[Epoch 17, Batch 300] loss: 0.00664588046787685
[Epoch 17, Batch 400] loss: 0.008739787753356723
[Epoch 17, Batch 500] loss: 0.01068105317041045
[Epoch 17, Batch 600] loss: 0.010338235426170286
[Epoch 17, Batch 700] loss: 0.012118730721413158
**STATS for Epoch 17** : 
Average training loss: 0.0012
Average validation loss: 0.0547
Validation Accuracy: 0.9852
Overfitting: 0.0535
[Epoch 18, Batch 100] loss: 0.013412883276396314
[Epoch 18, Batch 200] loss: 0.005307078018886386
[Epoch 18, Batch 300] loss: 0.007242823683118332
[Epoch 18, Batch 400] loss: 0.009248330000773422
[Epoch 18, Batch 500] loss: 0.007899672589555849
[Epoch 18, Batch 600] loss: 0.008921329516015248
[Epoch 18, Batch 700] loss: 0.011064562132087303
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0426
Validation Accuracy: 0.9888
Overfitting: 0.0420
[Epoch 19, Batch 100] loss: 0.004225416529407084
[Epoch 19, Batch 200] loss: 0.005483588246588625
[Epoch 19, Batch 300] loss: 0.009954193738376488
[Epoch 19, Batch 400] loss: 0.006698465008194035
[Epoch 19, Batch 500] loss: 0.00691196187712194
[Epoch 19, Batch 600] loss: 0.011971614488138584
[Epoch 19, Batch 700] loss: 0.0065885771432294855
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0446
Validation Accuracy: 0.9888
Overfitting: 0.0441
[Epoch 20, Batch 100] loss: 0.005918596897099632
[Epoch 20, Batch 200] loss: 0.006240399676353263
[Epoch 20, Batch 300] loss: 0.003662566960501863
[Epoch 20, Batch 400] loss: 0.005441986747355259
[Epoch 20, Batch 500] loss: 0.007079473810572381
[Epoch 20, Batch 600] loss: 0.0072036112651767325
[Epoch 20, Batch 700] loss: 0.007158172529634612
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0418
Validation Accuracy: 0.9892
Overfitting: 0.0415
[Epoch 21, Batch 100] loss: 0.003509084598044865
[Epoch 21, Batch 200] loss: 0.006401751122548376
[Epoch 21, Batch 300] loss: 0.003630365135290958
[Epoch 21, Batch 400] loss: 0.005147691314268741
[Epoch 21, Batch 500] loss: 0.006479156041887108
[Epoch 21, Batch 600] loss: 0.005185152691046824
[Epoch 21, Batch 700] loss: 0.00697749784860207
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0450
Validation Accuracy: 0.9883
Overfitting: 0.0445
[Epoch 22, Batch 100] loss: 0.0023445906916640526
[Epoch 22, Batch 200] loss: 0.00340673568956845
[Epoch 22, Batch 300] loss: 0.0034692336525586143
[Epoch 22, Batch 400] loss: 0.005556203271080449
[Epoch 22, Batch 500] loss: 0.006511799681175034
[Epoch 22, Batch 600] loss: 0.006613658551650588
[Epoch 22, Batch 700] loss: 0.009556831764930393
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0411
Validation Accuracy: 0.9896
Overfitting: 0.0409
[Epoch 23, Batch 100] loss: 0.005133310027395055
[Epoch 23, Batch 200] loss: 0.0044567214777453045
[Epoch 23, Batch 300] loss: 0.005115313370829426
[Epoch 23, Batch 400] loss: 0.0025321724807145073
[Epoch 23, Batch 500] loss: 0.00464006538495596
[Epoch 23, Batch 600] loss: 0.0039130903616023715
[Epoch 23, Batch 700] loss: 0.0022360215676235384
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0471
Validation Accuracy: 0.9894
Overfitting: 0.0469
[Epoch 24, Batch 100] loss: 0.00302255005319239
[Epoch 24, Batch 200] loss: 0.0028148079527545635
[Epoch 24, Batch 300] loss: 0.0036574182151707644
[Epoch 24, Batch 400] loss: 0.003342720964246837
[Epoch 24, Batch 500] loss: 0.0025611929721435444
[Epoch 24, Batch 600] loss: 0.0033723829912196378
[Epoch 24, Batch 700] loss: 0.0025379424362972714
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0434
Validation Accuracy: 0.9900
Overfitting: 0.0431
Fold 1 validation loss: 0.0434
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2518440008163454
[Epoch 1, Batch 200] loss: 1.025030827820301
[Epoch 1, Batch 300] loss: 0.34039370223879817
[Epoch 1, Batch 400] loss: 0.24103392273187638
[Epoch 1, Batch 500] loss: 0.19788562696427106
[Epoch 1, Batch 600] loss: 0.1586889398097992
[Epoch 1, Batch 700] loss: 0.1521601814031601
**STATS for Epoch 1** : 
Average training loss: 0.0094
Average validation loss: 0.1516
Validation Accuracy: 0.9542
Overfitting: 0.1422
Best model saved at epoch 1 with validation loss: 0.1516
[Epoch 2, Batch 100] loss: 0.11965796942822635
[Epoch 2, Batch 200] loss: 0.11766810040920973
[Epoch 2, Batch 300] loss: 0.10973636345937848
[Epoch 2, Batch 400] loss: 0.09538593159988523
[Epoch 2, Batch 500] loss: 0.09664627892896532
[Epoch 2, Batch 600] loss: 0.08774285490624606
[Epoch 2, Batch 700] loss: 0.0850602432154119
**STATS for Epoch 2** : 
Average training loss: 0.0058
Average validation loss: 0.0943
Validation Accuracy: 0.9700
Overfitting: 0.0885
Best model saved at epoch 2 with validation loss: 0.0943
[Epoch 3, Batch 100] loss: 0.06975500843022019
[Epoch 3, Batch 200] loss: 0.07275451009161771
[Epoch 3, Batch 300] loss: 0.07076508097350598
[Epoch 3, Batch 400] loss: 0.07319183883955702
[Epoch 3, Batch 500] loss: 0.06184422725811601
[Epoch 3, Batch 600] loss: 0.07889556324575096
[Epoch 3, Batch 700] loss: 0.06979768006131053
**STATS for Epoch 3** : 
Average training loss: 0.0055
Average validation loss: 0.0772
Validation Accuracy: 0.9757
Overfitting: 0.0716
Best model saved at epoch 3 with validation loss: 0.0772
[Epoch 4, Batch 100] loss: 0.061362562654539946
[Epoch 4, Batch 200] loss: 0.055741906687617304
[Epoch 4, Batch 300] loss: 0.057671447955071925
[Epoch 4, Batch 400] loss: 0.05629030944546685
[Epoch 4, Batch 500] loss: 0.054373237346298994
[Epoch 4, Batch 600] loss: 0.05952816728269681
[Epoch 4, Batch 700] loss: 0.056236492446623744
**STATS for Epoch 4** : 
Average training loss: 0.0038
Average validation loss: 0.0648
Validation Accuracy: 0.9791
Overfitting: 0.0610
Best model saved at epoch 4 with validation loss: 0.0648
[Epoch 5, Batch 100] loss: 0.04687278818804771
[Epoch 5, Batch 200] loss: 0.05297672786284238
[Epoch 5, Batch 300] loss: 0.05096486161928624
[Epoch 5, Batch 400] loss: 0.04692802061326802
[Epoch 5, Batch 500] loss: 0.04177646283525974
[Epoch 5, Batch 600] loss: 0.04942771413130686
[Epoch 5, Batch 700] loss: 0.04176592993666418
**STATS for Epoch 5** : 
Average training loss: 0.0032
Average validation loss: 0.0653
Validation Accuracy: 0.9794
Overfitting: 0.0621
[Epoch 6, Batch 100] loss: 0.039330524544930086
[Epoch 6, Batch 200] loss: 0.03906506534956861
[Epoch 6, Batch 300] loss: 0.037725194685626774
[Epoch 6, Batch 400] loss: 0.04197071451810189
[Epoch 6, Batch 500] loss: 0.042889965679496524
[Epoch 6, Batch 600] loss: 0.03780392137356103
[Epoch 6, Batch 700] loss: 0.03985660634352826
**STATS for Epoch 6** : 
Average training loss: 0.0023
Average validation loss: 0.0625
Validation Accuracy: 0.9808
Overfitting: 0.0602
Best model saved at epoch 6 with validation loss: 0.0625
[Epoch 7, Batch 100] loss: 0.031172427966957912
[Epoch 7, Batch 200] loss: 0.03920506001217291
[Epoch 7, Batch 300] loss: 0.03412285515922122
[Epoch 7, Batch 400] loss: 0.03458260928513482
[Epoch 7, Batch 500] loss: 0.038060115077532826
[Epoch 7, Batch 600] loss: 0.03906685880036093
[Epoch 7, Batch 700] loss: 0.0411820291611366
**STATS for Epoch 7** : 
Average training loss: 0.0027
Average validation loss: 0.0621
Validation Accuracy: 0.9810
Overfitting: 0.0593
Best model saved at epoch 7 with validation loss: 0.0621
[Epoch 8, Batch 100] loss: 0.02666039952891879
[Epoch 8, Batch 200] loss: 0.028370801705750636
[Epoch 8, Batch 300] loss: 0.039789446181384844
[Epoch 8, Batch 400] loss: 0.024362073810189032
[Epoch 8, Batch 500] loss: 0.031409495862899345
[Epoch 8, Batch 600] loss: 0.024065914513776078
[Epoch 8, Batch 700] loss: 0.03632288367836736
**STATS for Epoch 8** : 
Average training loss: 0.0027
Average validation loss: 0.0536
Validation Accuracy: 0.9840
Overfitting: 0.0508
Best model saved at epoch 8 with validation loss: 0.0536
[Epoch 9, Batch 100] loss: 0.025256842384114863
[Epoch 9, Batch 200] loss: 0.028672904664999804
[Epoch 9, Batch 300] loss: 0.028032410446903668
[Epoch 9, Batch 400] loss: 0.025997875507455318
[Epoch 9, Batch 500] loss: 0.030643910397775472
[Epoch 9, Batch 600] loss: 0.024993736179312692
[Epoch 9, Batch 700] loss: 0.031903699364047494
**STATS for Epoch 9** : 
Average training loss: 0.0019
Average validation loss: 0.0552
Validation Accuracy: 0.9844
Overfitting: 0.0534
[Epoch 10, Batch 100] loss: 0.018110271339537576
[Epoch 10, Batch 200] loss: 0.0215796345952549
[Epoch 10, Batch 300] loss: 0.017599376238067635
[Epoch 10, Batch 400] loss: 0.029462957612704486
[Epoch 10, Batch 500] loss: 0.029096021893201394
[Epoch 10, Batch 600] loss: 0.024182238067733123
[Epoch 10, Batch 700] loss: 0.0247355399717344
**STATS for Epoch 10** : 
Average training loss: 0.0015
Average validation loss: 0.0494
Validation Accuracy: 0.9858
Overfitting: 0.0478
Best model saved at epoch 10 with validation loss: 0.0494
[Epoch 11, Batch 100] loss: 0.02454010052344529
[Epoch 11, Batch 200] loss: 0.017854536789818666
[Epoch 11, Batch 300] loss: 0.019030578780802897
[Epoch 11, Batch 400] loss: 0.022755143184913323
[Epoch 11, Batch 500] loss: 0.025303925424232147
[Epoch 11, Batch 600] loss: 0.02019375212606974
[Epoch 11, Batch 700] loss: 0.025928999951574952
**STATS for Epoch 11** : 
Average training loss: 0.0015
Average validation loss: 0.0664
Validation Accuracy: 0.9820
Overfitting: 0.0648
[Epoch 12, Batch 100] loss: 0.016342972831916994
[Epoch 12, Batch 200] loss: 0.017237802111776546
[Epoch 12, Batch 300] loss: 0.017159665396029596
[Epoch 12, Batch 400] loss: 0.01819774513322045
[Epoch 12, Batch 500] loss: 0.0225751085561933
[Epoch 12, Batch 600] loss: 0.020650037632731256
[Epoch 12, Batch 700] loss: 0.026450343822070864
**STATS for Epoch 12** : 
Average training loss: 0.0011
Average validation loss: 0.0579
Validation Accuracy: 0.9829
Overfitting: 0.0568
[Epoch 13, Batch 100] loss: 0.016546856839559042
[Epoch 13, Batch 200] loss: 0.012120606633543503
[Epoch 13, Batch 300] loss: 0.0181516948978242
[Epoch 13, Batch 400] loss: 0.020565557700465434
[Epoch 13, Batch 500] loss: 0.018675331152480795
[Epoch 13, Batch 600] loss: 0.01890877172612818
[Epoch 13, Batch 700] loss: 0.015540206079895142
**STATS for Epoch 13** : 
Average training loss: 0.0013
Average validation loss: 0.0536
Validation Accuracy: 0.9854
Overfitting: 0.0523
[Epoch 14, Batch 100] loss: 0.014252269539574626
[Epoch 14, Batch 200] loss: 0.01137821719108615
[Epoch 14, Batch 300] loss: 0.019701199856208405
[Epoch 14, Batch 400] loss: 0.01932301928784
[Epoch 14, Batch 500] loss: 0.012967086340941023
[Epoch 14, Batch 600] loss: 0.01239376334415283
[Epoch 14, Batch 700] loss: 0.016719303446734557
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0522
Validation Accuracy: 0.9864
Overfitting: 0.0511
[Epoch 15, Batch 100] loss: 0.010074935137963622
[Epoch 15, Batch 200] loss: 0.012169233592867385
[Epoch 15, Batch 300] loss: 0.016661932463612174
[Epoch 15, Batch 400] loss: 0.016661654068302598
[Epoch 15, Batch 500] loss: 0.011635429857706185
[Epoch 15, Batch 600] loss: 0.012648915935715195
[Epoch 15, Batch 700] loss: 0.015154277992842254
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0580
Validation Accuracy: 0.9847
Overfitting: 0.0571
[Epoch 16, Batch 100] loss: 0.009088437518075808
[Epoch 16, Batch 200] loss: 0.007571453641394328
[Epoch 16, Batch 300] loss: 0.01151362283533672
[Epoch 16, Batch 400] loss: 0.010804167933674762
[Epoch 16, Batch 500] loss: 0.011382674339256483
[Epoch 16, Batch 600] loss: 0.011993898415094009
[Epoch 16, Batch 700] loss: 0.016493469784909395
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0474
Validation Accuracy: 0.9875
Overfitting: 0.0467
Best model saved at epoch 16 with validation loss: 0.0474
[Epoch 17, Batch 100] loss: 0.01379869419921306
[Epoch 17, Batch 200] loss: 0.01188273775496782
[Epoch 17, Batch 300] loss: 0.010899849533670932
[Epoch 17, Batch 400] loss: 0.011251295688925893
[Epoch 17, Batch 500] loss: 0.009969753305776976
[Epoch 17, Batch 600] loss: 0.008157733362168074
[Epoch 17, Batch 700] loss: 0.008083157731234678
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0541
Validation Accuracy: 0.9862
Overfitting: 0.0530
[Epoch 18, Batch 100] loss: 0.006078416172276775
[Epoch 18, Batch 200] loss: 0.010504736993461848
[Epoch 18, Batch 300] loss: 0.004192884994699853
[Epoch 18, Batch 400] loss: 0.00691015225067531
[Epoch 18, Batch 500] loss: 0.009665013930352871
[Epoch 18, Batch 600] loss: 0.012859638666450337
[Epoch 18, Batch 700] loss: 0.012578231702500489
**STATS for Epoch 18** : 
Average training loss: 0.0013
Average validation loss: 0.0588
Validation Accuracy: 0.9859
Overfitting: 0.0575
[Epoch 19, Batch 100] loss: 0.008319437534664758
[Epoch 19, Batch 200] loss: 0.007610652117509744
[Epoch 19, Batch 300] loss: 0.007597898424282903
[Epoch 19, Batch 400] loss: 0.010349476859264541
[Epoch 19, Batch 500] loss: 0.01129645725057344
[Epoch 19, Batch 600] loss: 0.013322286814000108
[Epoch 19, Batch 700] loss: 0.008579263461724622
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0553
Validation Accuracy: 0.9855
Overfitting: 0.0547
[Epoch 20, Batch 100] loss: 0.006105775339037791
[Epoch 20, Batch 200] loss: 0.00801607258606964
[Epoch 20, Batch 300] loss: 0.005710856266741757
[Epoch 20, Batch 400] loss: 0.009204052425811824
[Epoch 20, Batch 500] loss: 0.010258108457855996
[Epoch 20, Batch 600] loss: 0.008353401919521275
[Epoch 20, Batch 700] loss: 0.007408617129840422
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0545
Validation Accuracy: 0.9868
Overfitting: 0.0541
[Epoch 21, Batch 100] loss: 0.00644791869747678
[Epoch 21, Batch 200] loss: 0.005301740652357694
[Epoch 21, Batch 300] loss: 0.0075690921307614185
[Epoch 21, Batch 400] loss: 0.010201765403035096
[Epoch 21, Batch 500] loss: 0.006416315711976495
[Epoch 21, Batch 600] loss: 0.005245990805606198
[Epoch 21, Batch 700] loss: 0.004651079550367285
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0562
Validation Accuracy: 0.9858
Overfitting: 0.0558
[Epoch 22, Batch 100] loss: 0.0028503000277305545
[Epoch 22, Batch 200] loss: 0.0038864404703963375
[Epoch 22, Batch 300] loss: 0.004055182354013595
[Epoch 22, Batch 400] loss: 0.006750744931232475
[Epoch 22, Batch 500] loss: 0.009409109034058928
[Epoch 22, Batch 600] loss: 0.005498310348912128
[Epoch 22, Batch 700] loss: 0.00694576482703269
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0568
Validation Accuracy: 0.9862
Overfitting: 0.0563
[Epoch 23, Batch 100] loss: 0.004414722401206745
[Epoch 23, Batch 200] loss: 0.005455833170708501
[Epoch 23, Batch 300] loss: 0.007416711942169058
[Epoch 23, Batch 400] loss: 0.0059384237533231495
[Epoch 23, Batch 500] loss: 0.008610672895447351
[Epoch 23, Batch 600] loss: 0.004285401966571953
[Epoch 23, Batch 700] loss: 0.0037863168606645558
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0535
Validation Accuracy: 0.9879
Overfitting: 0.0531
[Epoch 24, Batch 100] loss: 0.002322179699258413
[Epoch 24, Batch 200] loss: 0.002826048130127674
[Epoch 24, Batch 300] loss: 0.004342166457572603
[Epoch 24, Batch 400] loss: 0.002702626734017031
[Epoch 24, Batch 500] loss: 0.0033036193656334947
[Epoch 24, Batch 600] loss: 0.008200769721006508
[Epoch 24, Batch 700] loss: 0.003780469884386548
**STATS for Epoch 24** : 
Average training loss: 0.0006
Average validation loss: 0.0730
Validation Accuracy: 0.9828
Overfitting: 0.0723
Fold 2 validation loss: 0.0730
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.27100816488266
[Epoch 1, Batch 200] loss: 1.1781512680649757
[Epoch 1, Batch 300] loss: 0.3727920685708523
[Epoch 1, Batch 400] loss: 0.2552680222690105
[Epoch 1, Batch 500] loss: 0.1968231336399913
[Epoch 1, Batch 600] loss: 0.1752857406809926
[Epoch 1, Batch 700] loss: 0.13788392074406147
**STATS for Epoch 1** : 
Average training loss: 0.0100
Average validation loss: 0.1588
Validation Accuracy: 0.9555
Overfitting: 0.1488
Best model saved at epoch 1 with validation loss: 0.1588
[Epoch 2, Batch 100] loss: 0.1235931458696723
[Epoch 2, Batch 200] loss: 0.11600183984264731
[Epoch 2, Batch 300] loss: 0.11668182884342969
[Epoch 2, Batch 400] loss: 0.10510336000472308
[Epoch 2, Batch 500] loss: 0.11020903242751956
[Epoch 2, Batch 600] loss: 0.10129477331414818
[Epoch 2, Batch 700] loss: 0.0925963120162487
**STATS for Epoch 2** : 
Average training loss: 0.0073
Average validation loss: 0.0879
Validation Accuracy: 0.9733
Overfitting: 0.0806
Best model saved at epoch 2 with validation loss: 0.0879
[Epoch 3, Batch 100] loss: 0.08085266081616282
[Epoch 3, Batch 200] loss: 0.07612706495448947
[Epoch 3, Batch 300] loss: 0.07439025694504381
[Epoch 3, Batch 400] loss: 0.07718527672812342
[Epoch 3, Batch 500] loss: 0.07386804858222604
[Epoch 3, Batch 600] loss: 0.06690247609280049
[Epoch 3, Batch 700] loss: 0.06597419050522149
**STATS for Epoch 3** : 
Average training loss: 0.0038
Average validation loss: 0.0746
Validation Accuracy: 0.9773
Overfitting: 0.0708
Best model saved at epoch 3 with validation loss: 0.0746
[Epoch 4, Batch 100] loss: 0.06008619748055935
[Epoch 4, Batch 200] loss: 0.058658217783086004
[Epoch 4, Batch 300] loss: 0.05567244734149426
[Epoch 4, Batch 400] loss: 0.049951903712935744
[Epoch 4, Batch 500] loss: 0.06444234718102962
[Epoch 4, Batch 600] loss: 0.05577068886952475
[Epoch 4, Batch 700] loss: 0.04983558883192018
**STATS for Epoch 4** : 
Average training loss: 0.0034
Average validation loss: 0.0676
Validation Accuracy: 0.9786
Overfitting: 0.0643
Best model saved at epoch 4 with validation loss: 0.0676
[Epoch 5, Batch 100] loss: 0.041483507972443476
[Epoch 5, Batch 200] loss: 0.05222666990943253
[Epoch 5, Batch 300] loss: 0.044280493806581944
[Epoch 5, Batch 400] loss: 0.04388111899956129
[Epoch 5, Batch 500] loss: 0.057175463316962126
[Epoch 5, Batch 600] loss: 0.04371327007422224
[Epoch 5, Batch 700] loss: 0.04865615461021662
**STATS for Epoch 5** : 
Average training loss: 0.0035
Average validation loss: 0.0632
Validation Accuracy: 0.9806
Overfitting: 0.0597
Best model saved at epoch 5 with validation loss: 0.0632
[Epoch 6, Batch 100] loss: 0.03358232053695247
[Epoch 6, Batch 200] loss: 0.04489533340092748
[Epoch 6, Batch 300] loss: 0.03690686738700606
[Epoch 6, Batch 400] loss: 0.04743025473086163
[Epoch 6, Batch 500] loss: 0.038350381286581976
[Epoch 6, Batch 600] loss: 0.04138239505467936
[Epoch 6, Batch 700] loss: 0.04048456687247381
**STATS for Epoch 6** : 
Average training loss: 0.0029
Average validation loss: 0.0629
Validation Accuracy: 0.9808
Overfitting: 0.0599
Best model saved at epoch 6 with validation loss: 0.0629
[Epoch 7, Batch 100] loss: 0.0403990507859271
[Epoch 7, Batch 200] loss: 0.031040366743691265
[Epoch 7, Batch 300] loss: 0.030201494211796673
[Epoch 7, Batch 400] loss: 0.03737783612683415
[Epoch 7, Batch 500] loss: 0.02889553291723132
[Epoch 7, Batch 600] loss: 0.042809592409757895
[Epoch 7, Batch 700] loss: 0.03109520613332279
**STATS for Epoch 7** : 
Average training loss: 0.0026
Average validation loss: 0.0613
Validation Accuracy: 0.9822
Overfitting: 0.0587
Best model saved at epoch 7 with validation loss: 0.0613
[Epoch 8, Batch 100] loss: 0.02642505546566099
[Epoch 8, Batch 200] loss: 0.030581897923257204
[Epoch 8, Batch 300] loss: 0.025229020236292855
[Epoch 8, Batch 400] loss: 0.030218373305979186
[Epoch 8, Batch 500] loss: 0.031909094469156116
[Epoch 8, Batch 600] loss: 0.032384319818229416
[Epoch 8, Batch 700] loss: 0.0315172491746489
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0518
Validation Accuracy: 0.9840
Overfitting: 0.0494
Best model saved at epoch 8 with validation loss: 0.0518
[Epoch 9, Batch 100] loss: 0.024553528503747656
[Epoch 9, Batch 200] loss: 0.024210029257228597
[Epoch 9, Batch 300] loss: 0.025679620934533888
[Epoch 9, Batch 400] loss: 0.025749199591809883
[Epoch 9, Batch 500] loss: 0.02553496137901675
[Epoch 9, Batch 600] loss: 0.02828679047874175
[Epoch 9, Batch 700] loss: 0.029019885574234648
**STATS for Epoch 9** : 
Average training loss: 0.0017
Average validation loss: 0.0469
Validation Accuracy: 0.9859
Overfitting: 0.0452
Best model saved at epoch 9 with validation loss: 0.0469
[Epoch 10, Batch 100] loss: 0.018373206282267348
[Epoch 10, Batch 200] loss: 0.01661430482403375
[Epoch 10, Batch 300] loss: 0.025991187601175626
[Epoch 10, Batch 400] loss: 0.023900947590591387
[Epoch 10, Batch 500] loss: 0.025259679792216046
[Epoch 10, Batch 600] loss: 0.027176727956393733
[Epoch 10, Batch 700] loss: 0.02223569766210858
**STATS for Epoch 10** : 
Average training loss: 0.0014
Average validation loss: 0.0549
Validation Accuracy: 0.9836
Overfitting: 0.0536
[Epoch 11, Batch 100] loss: 0.018094939004804474
[Epoch 11, Batch 200] loss: 0.02054706427268684
[Epoch 11, Batch 300] loss: 0.02264281706273323
[Epoch 11, Batch 400] loss: 0.020424238117411734
[Epoch 11, Batch 500] loss: 0.019828740047232715
[Epoch 11, Batch 600] loss: 0.02643392524216324
[Epoch 11, Batch 700] loss: 0.02167945166671416
**STATS for Epoch 11** : 
Average training loss: 0.0013
Average validation loss: 0.0476
Validation Accuracy: 0.9861
Overfitting: 0.0463
[Epoch 12, Batch 100] loss: 0.013502972713467898
[Epoch 12, Batch 200] loss: 0.015647993276361377
[Epoch 12, Batch 300] loss: 0.016408821352233646
[Epoch 12, Batch 400] loss: 0.017487212087144145
[Epoch 12, Batch 500] loss: 0.018759039355500134
[Epoch 12, Batch 600] loss: 0.01659256183411344
[Epoch 12, Batch 700] loss: 0.020449755126028323
**STATS for Epoch 12** : 
Average training loss: 0.0016
Average validation loss: 0.0523
Validation Accuracy: 0.9852
Overfitting: 0.0507
[Epoch 13, Batch 100] loss: 0.013243510056345258
[Epoch 13, Batch 200] loss: 0.01974983608641196
[Epoch 13, Batch 300] loss: 0.01669796691625379
[Epoch 13, Batch 400] loss: 0.014793646275356877
[Epoch 13, Batch 500] loss: 0.016318514124141075
[Epoch 13, Batch 600] loss: 0.016221177999759674
[Epoch 13, Batch 700] loss: 0.015996580292157888
**STATS for Epoch 13** : 
Average training loss: 0.0016
Average validation loss: 0.0449
Validation Accuracy: 0.9878
Overfitting: 0.0433
Best model saved at epoch 13 with validation loss: 0.0449
[Epoch 14, Batch 100] loss: 0.013509383603959577
[Epoch 14, Batch 200] loss: 0.015057986571337096
[Epoch 14, Batch 300] loss: 0.011899936745758169
[Epoch 14, Batch 400] loss: 0.008844843630140532
[Epoch 14, Batch 500] loss: 0.014096643925695389
[Epoch 14, Batch 600] loss: 0.015820729039842264
[Epoch 14, Batch 700] loss: 0.012446883003867697
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0478
Validation Accuracy: 0.9874
Overfitting: 0.0468
[Epoch 15, Batch 100] loss: 0.012900985688174842
[Epoch 15, Batch 200] loss: 0.010752522121911169
[Epoch 15, Batch 300] loss: 0.013625777221604948
[Epoch 15, Batch 400] loss: 0.013556209169328213
[Epoch 15, Batch 500] loss: 0.01132083652933943
[Epoch 15, Batch 600] loss: 0.01053177631678409
[Epoch 15, Batch 700] loss: 0.014542405472893734
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0484
Validation Accuracy: 0.9878
Overfitting: 0.0476
[Epoch 16, Batch 100] loss: 0.006927107305018581
[Epoch 16, Batch 200] loss: 0.008512297436645895
[Epoch 16, Batch 300] loss: 0.011892817621555878
[Epoch 16, Batch 400] loss: 0.007355037609231658
[Epoch 16, Batch 500] loss: 0.01307816359010758
[Epoch 16, Batch 600] loss: 0.014285575816902565
[Epoch 16, Batch 700] loss: 0.008550869862810942
**STATS for Epoch 16** : 
Average training loss: 0.0011
Average validation loss: 0.0488
Validation Accuracy: 0.9869
Overfitting: 0.0477
[Epoch 17, Batch 100] loss: 0.006517879788880236
[Epoch 17, Batch 200] loss: 0.007805882557586301
[Epoch 17, Batch 300] loss: 0.009166980474547018
[Epoch 17, Batch 400] loss: 0.0075407761280075645
[Epoch 17, Batch 500] loss: 0.00850506501737982
[Epoch 17, Batch 600] loss: 0.01015284081142454
[Epoch 17, Batch 700] loss: 0.011842996346240397
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0484
Validation Accuracy: 0.9888
Overfitting: 0.0478
[Epoch 18, Batch 100] loss: 0.013673384879293735
[Epoch 18, Batch 200] loss: 0.006010318557746359
[Epoch 18, Batch 300] loss: 0.008460683835801319
[Epoch 18, Batch 400] loss: 0.009281331380989286
[Epoch 18, Batch 500] loss: 0.007809078828595375
[Epoch 18, Batch 600] loss: 0.010599101305851946
[Epoch 18, Batch 700] loss: 0.009162261806195601
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0539
Validation Accuracy: 0.9874
Overfitting: 0.0532
[Epoch 19, Batch 100] loss: 0.007006495426758193
[Epoch 19, Batch 200] loss: 0.004893031615647487
[Epoch 19, Batch 300] loss: 0.008050303168383835
[Epoch 19, Batch 400] loss: 0.0082254608310177
[Epoch 19, Batch 500] loss: 0.011531088142510271
[Epoch 19, Batch 600] loss: 0.014304790334426798
[Epoch 19, Batch 700] loss: 0.0073246344897597735
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0498
Validation Accuracy: 0.9875
Overfitting: 0.0490
[Epoch 20, Batch 100] loss: 0.005377779701011605
[Epoch 20, Batch 200] loss: 0.006988182613422395
[Epoch 20, Batch 300] loss: 0.005044894404345541
[Epoch 20, Batch 400] loss: 0.004529070133394271
[Epoch 20, Batch 500] loss: 0.006310850635563838
[Epoch 20, Batch 600] loss: 0.011073841968536726
[Epoch 20, Batch 700] loss: 0.009442288631253177
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0536
Validation Accuracy: 0.9879
Overfitting: 0.0531
[Epoch 21, Batch 100] loss: 0.0049183611996704716
[Epoch 21, Batch 200] loss: 0.005855652462014404
[Epoch 21, Batch 300] loss: 0.005888382305020059
[Epoch 21, Batch 400] loss: 0.007743034466784593
[Epoch 21, Batch 500] loss: 0.004255772849210189
[Epoch 21, Batch 600] loss: 0.004604790483535908
[Epoch 21, Batch 700] loss: 0.005917264985728252
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0520
Validation Accuracy: 0.9882
Overfitting: 0.0516
[Epoch 22, Batch 100] loss: 0.006061936998221427
[Epoch 22, Batch 200] loss: 0.004254678828292526
[Epoch 22, Batch 300] loss: 0.003003433521070633
[Epoch 22, Batch 400] loss: 0.005168412054254077
[Epoch 22, Batch 500] loss: 0.005990793120890885
[Epoch 22, Batch 600] loss: 0.0034749919991372735
[Epoch 22, Batch 700] loss: 0.004333877299413871
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0528
Validation Accuracy: 0.9882
Overfitting: 0.0526
[Epoch 23, Batch 100] loss: 0.0044238738605235995
[Epoch 23, Batch 200] loss: 0.002612794430087888
[Epoch 23, Batch 300] loss: 0.004067777999025566
[Epoch 23, Batch 400] loss: 0.00572074771655025
[Epoch 23, Batch 500] loss: 0.004819811578418012
[Epoch 23, Batch 600] loss: 0.004933754754010806
[Epoch 23, Batch 700] loss: 0.0034387396196325424
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0553
Validation Accuracy: 0.9878
Overfitting: 0.0551
[Epoch 24, Batch 100] loss: 0.004376823268257795
[Epoch 24, Batch 200] loss: 0.0034442952667052395
[Epoch 24, Batch 300] loss: 0.004989209124578338
[Epoch 24, Batch 400] loss: 0.005634520866760795
[Epoch 24, Batch 500] loss: 0.002172851261852884
[Epoch 24, Batch 600] loss: 0.003855363166640018
[Epoch 24, Batch 700] loss: 0.006066592859151569
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0568
Validation Accuracy: 0.9872
Overfitting: 0.0567
Fold 3 validation loss: 0.0568
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2455032992362978
[Epoch 1, Batch 200] loss: 0.9336834397912025
[Epoch 1, Batch 300] loss: 0.34365754552185535
[Epoch 1, Batch 400] loss: 0.2515478447079659
[Epoch 1, Batch 500] loss: 0.18525306724011897
[Epoch 1, Batch 600] loss: 0.16644764829427003
[Epoch 1, Batch 700] loss: 0.1458003396168351
**STATS for Epoch 1** : 
Average training loss: 0.0093
Average validation loss: 0.1470
Validation Accuracy: 0.9533
Overfitting: 0.1377
Best model saved at epoch 1 with validation loss: 0.1470
[Epoch 2, Batch 100] loss: 0.1288935896754265
[Epoch 2, Batch 200] loss: 0.11055707825347781
[Epoch 2, Batch 300] loss: 0.11029878206551075
[Epoch 2, Batch 400] loss: 0.09739017304964363
[Epoch 2, Batch 500] loss: 0.10143846191465855
[Epoch 2, Batch 600] loss: 0.09869915844872594
[Epoch 2, Batch 700] loss: 0.08069084897637367
**STATS for Epoch 2** : 
Average training loss: 0.0063
Average validation loss: 0.0798
Validation Accuracy: 0.9749
Overfitting: 0.0736
Best model saved at epoch 2 with validation loss: 0.0798
[Epoch 3, Batch 100] loss: 0.08078297098400071
[Epoch 3, Batch 200] loss: 0.07967782068997621
[Epoch 3, Batch 300] loss: 0.07753539762459695
[Epoch 3, Batch 400] loss: 0.06979035247117281
[Epoch 3, Batch 500] loss: 0.06756485864054412
[Epoch 3, Batch 600] loss: 0.07189454971812666
[Epoch 3, Batch 700] loss: 0.07584311472950503
**STATS for Epoch 3** : 
Average training loss: 0.0043
Average validation loss: 0.0740
Validation Accuracy: 0.9779
Overfitting: 0.0697
Best model saved at epoch 3 with validation loss: 0.0740
[Epoch 4, Batch 100] loss: 0.05641760841943324
[Epoch 4, Batch 200] loss: 0.0537083083530888
[Epoch 4, Batch 300] loss: 0.05889059434644878
[Epoch 4, Batch 400] loss: 0.05340200701728463
[Epoch 4, Batch 500] loss: 0.061335837950464336
[Epoch 4, Batch 600] loss: 0.06352466135285795
[Epoch 4, Batch 700] loss: 0.06117564601358026
**STATS for Epoch 4** : 
Average training loss: 0.0038
Average validation loss: 0.0596
Validation Accuracy: 0.9818
Overfitting: 0.0558
Best model saved at epoch 4 with validation loss: 0.0596
[Epoch 5, Batch 100] loss: 0.045535277219023555
[Epoch 5, Batch 200] loss: 0.053013541363179685
[Epoch 5, Batch 300] loss: 0.0442374646384269
[Epoch 5, Batch 400] loss: 0.0462430133507587
[Epoch 5, Batch 500] loss: 0.055385675551369785
[Epoch 5, Batch 600] loss: 0.055081431744620206
[Epoch 5, Batch 700] loss: 0.04380554852075875
**STATS for Epoch 5** : 
Average training loss: 0.0030
Average validation loss: 0.0499
Validation Accuracy: 0.9849
Overfitting: 0.0469
Best model saved at epoch 5 with validation loss: 0.0499
[Epoch 6, Batch 100] loss: 0.038896464540157466
[Epoch 6, Batch 200] loss: 0.04263415630208328
[Epoch 6, Batch 300] loss: 0.045724561484530565
[Epoch 6, Batch 400] loss: 0.04730463684303686
[Epoch 6, Batch 500] loss: 0.04002293182304129
[Epoch 6, Batch 600] loss: 0.040863852358888834
[Epoch 6, Batch 700] loss: 0.04925240904092789
**STATS for Epoch 6** : 
Average training loss: 0.0021
Average validation loss: 0.0496
Validation Accuracy: 0.9835
Overfitting: 0.0475
Best model saved at epoch 6 with validation loss: 0.0496
[Epoch 7, Batch 100] loss: 0.03626415446749889
[Epoch 7, Batch 200] loss: 0.03322804779745638
[Epoch 7, Batch 300] loss: 0.03837342801154591
[Epoch 7, Batch 400] loss: 0.03516774777672253
[Epoch 7, Batch 500] loss: 0.034999710302217865
[Epoch 7, Batch 600] loss: 0.03607552021217998
[Epoch 7, Batch 700] loss: 0.04010072930133902
**STATS for Epoch 7** : 
Average training loss: 0.0022
Average validation loss: 0.0466
Validation Accuracy: 0.9860
Overfitting: 0.0444
Best model saved at epoch 7 with validation loss: 0.0466
[Epoch 8, Batch 100] loss: 0.02683052104897797
[Epoch 8, Batch 200] loss: 0.029524067272432147
[Epoch 8, Batch 300] loss: 0.03477802533074282
[Epoch 8, Batch 400] loss: 0.030590024881530554
[Epoch 8, Batch 500] loss: 0.028982330776634625
[Epoch 8, Batch 600] loss: 0.03801562502863817
[Epoch 8, Batch 700] loss: 0.034460502777947113
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0494
Validation Accuracy: 0.9851
Overfitting: 0.0475
[Epoch 9, Batch 100] loss: 0.02387666202732362
[Epoch 9, Batch 200] loss: 0.024894999725511298
[Epoch 9, Batch 300] loss: 0.028964555265847593
[Epoch 9, Batch 400] loss: 0.027003066572942772
[Epoch 9, Batch 500] loss: 0.02953739069693256
[Epoch 9, Batch 600] loss: 0.03434485312609468
[Epoch 9, Batch 700] loss: 0.026575953646679407
**STATS for Epoch 9** : 
Average training loss: 0.0014
Average validation loss: 0.0504
Validation Accuracy: 0.9857
Overfitting: 0.0491
[Epoch 10, Batch 100] loss: 0.024792563739465548
[Epoch 10, Batch 200] loss: 0.024070428686682136
[Epoch 10, Batch 300] loss: 0.022193655114388092
[Epoch 10, Batch 400] loss: 0.02921563690295443
[Epoch 10, Batch 500] loss: 0.029437800822779536
[Epoch 10, Batch 600] loss: 0.02579456111328909
[Epoch 10, Batch 700] loss: 0.02418050843582023
**STATS for Epoch 10** : 
Average training loss: 0.0013
Average validation loss: 0.0426
Validation Accuracy: 0.9879
Overfitting: 0.0413
Best model saved at epoch 10 with validation loss: 0.0426
[Epoch 11, Batch 100] loss: 0.01944491458038101
[Epoch 11, Batch 200] loss: 0.024233207231154665
[Epoch 11, Batch 300] loss: 0.01936459061136702
[Epoch 11, Batch 400] loss: 0.027498377887532115
[Epoch 11, Batch 500] loss: 0.02399861763115041
[Epoch 11, Batch 600] loss: 0.015359142142697237
[Epoch 11, Batch 700] loss: 0.021767054484807886
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0401
Validation Accuracy: 0.9879
Overfitting: 0.0389
Best model saved at epoch 11 with validation loss: 0.0401
[Epoch 12, Batch 100] loss: 0.016048975051671733
[Epoch 12, Batch 200] loss: 0.020218762978474844
[Epoch 12, Batch 300] loss: 0.017314105558325535
[Epoch 12, Batch 400] loss: 0.019064237945131027
[Epoch 12, Batch 500] loss: 0.01667820318834856
[Epoch 12, Batch 600] loss: 0.030202980275353185
[Epoch 12, Batch 700] loss: 0.019576737817260437
**STATS for Epoch 12** : 
Average training loss: 0.0015
Average validation loss: 0.0427
Validation Accuracy: 0.9864
Overfitting: 0.0412
[Epoch 13, Batch 100] loss: 0.014699273039295803
[Epoch 13, Batch 200] loss: 0.019375919470039662
[Epoch 13, Batch 300] loss: 0.014006690057576633
[Epoch 13, Batch 400] loss: 0.01570244654547423
[Epoch 13, Batch 500] loss: 0.020624594162945868
[Epoch 13, Batch 600] loss: 0.018739222697913647
[Epoch 13, Batch 700] loss: 0.018756936856370886
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0385
Validation Accuracy: 0.9891
Overfitting: 0.0376
Best model saved at epoch 13 with validation loss: 0.0385
[Epoch 14, Batch 100] loss: 0.013095122886879836
[Epoch 14, Batch 200] loss: 0.016925052549340763
[Epoch 14, Batch 300] loss: 0.016120137173274998
[Epoch 14, Batch 400] loss: 0.01754476022659219
[Epoch 14, Batch 500] loss: 0.015821231107984203
[Epoch 14, Batch 600] loss: 0.016887649642303586
[Epoch 14, Batch 700] loss: 0.012065867041455932
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0438
Validation Accuracy: 0.9871
Overfitting: 0.0426
[Epoch 15, Batch 100] loss: 0.011377341741608689
[Epoch 15, Batch 200] loss: 0.012442103065986886
[Epoch 15, Batch 300] loss: 0.014381728933294653
[Epoch 15, Batch 400] loss: 0.01122883166273823
[Epoch 15, Batch 500] loss: 0.014412322939024306
[Epoch 15, Batch 600] loss: 0.013885065618233057
[Epoch 15, Batch 700] loss: 0.015845595670543843
**STATS for Epoch 15** : 
Average training loss: 0.0011
Average validation loss: 0.0492
Validation Accuracy: 0.9864
Overfitting: 0.0481
[Epoch 16, Batch 100] loss: 0.01046263139374787
[Epoch 16, Batch 200] loss: 0.0064441791848366846
[Epoch 16, Batch 300] loss: 0.010272050308049074
[Epoch 16, Batch 400] loss: 0.013431558341544587
[Epoch 16, Batch 500] loss: 0.01500472667736176
[Epoch 16, Batch 600] loss: 0.01332615114224609
[Epoch 16, Batch 700] loss: 0.015935233375712413
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0416
Validation Accuracy: 0.9881
Overfitting: 0.0407
[Epoch 17, Batch 100] loss: 0.011914842244441387
[Epoch 17, Batch 200] loss: 0.01063181039327901
[Epoch 17, Batch 300] loss: 0.009142418312258087
[Epoch 17, Batch 400] loss: 0.009397918718022993
[Epoch 17, Batch 500] loss: 0.019275503586104605
[Epoch 17, Batch 600] loss: 0.011948871976492227
[Epoch 17, Batch 700] loss: 0.012051031928422162
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0422
Validation Accuracy: 0.9878
Overfitting: 0.0415
[Epoch 18, Batch 100] loss: 0.010998594749544281
[Epoch 18, Batch 200] loss: 0.011770584935256921
[Epoch 18, Batch 300] loss: 0.010002862282999559
[Epoch 18, Batch 400] loss: 0.0105367797188228
[Epoch 18, Batch 500] loss: 0.009615558702462295
[Epoch 18, Batch 600] loss: 0.010118379158375318
[Epoch 18, Batch 700] loss: 0.013649533562129364
**STATS for Epoch 18** : 
Average training loss: 0.0010
Average validation loss: 0.0465
Validation Accuracy: 0.9873
Overfitting: 0.0455
[Epoch 19, Batch 100] loss: 0.006091389573339256
[Epoch 19, Batch 200] loss: 0.006400746360886842
[Epoch 19, Batch 300] loss: 0.006392072675153031
[Epoch 19, Batch 400] loss: 0.008401320155680878
[Epoch 19, Batch 500] loss: 0.007868127354886383
[Epoch 19, Batch 600] loss: 0.01563291470558397
[Epoch 19, Batch 700] loss: 0.01025566520220309
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0471
Validation Accuracy: 0.9860
Overfitting: 0.0465
[Epoch 20, Batch 100] loss: 0.0067865389157668685
[Epoch 20, Batch 200] loss: 0.009385678657527024
[Epoch 20, Batch 300] loss: 0.007054001912329113
[Epoch 20, Batch 400] loss: 0.008578906879665737
[Epoch 20, Batch 500] loss: 0.007984271726454608
[Epoch 20, Batch 600] loss: 0.009109639766029432
[Epoch 20, Batch 700] loss: 0.005304805311188829
**STATS for Epoch 20** : 
Average training loss: 0.0012
Average validation loss: 0.0522
Validation Accuracy: 0.9862
Overfitting: 0.0510
[Epoch 21, Batch 100] loss: 0.009167880320819676
[Epoch 21, Batch 200] loss: 0.0065595388637484575
[Epoch 21, Batch 300] loss: 0.0059492529225099134
[Epoch 21, Batch 400] loss: 0.006493149194720899
[Epoch 21, Batch 500] loss: 0.0057467730123607905
[Epoch 21, Batch 600] loss: 0.007177043457268155
[Epoch 21, Batch 700] loss: 0.009156445521621209
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0433
Validation Accuracy: 0.9885
Overfitting: 0.0429
[Epoch 22, Batch 100] loss: 0.004123284447305195
[Epoch 22, Batch 200] loss: 0.0022397582940538994
[Epoch 22, Batch 300] loss: 0.003217845546278113
[Epoch 22, Batch 400] loss: 0.0041141014096683646
[Epoch 22, Batch 500] loss: 0.009074631400471845
[Epoch 22, Batch 600] loss: 0.005840790069196373
[Epoch 22, Batch 700] loss: 0.005531175062442344
**STATS for Epoch 22** : 
Average training loss: 0.0010
Average validation loss: 0.0508
Validation Accuracy: 0.9866
Overfitting: 0.0497
[Epoch 23, Batch 100] loss: 0.007895985028517316
[Epoch 23, Batch 200] loss: 0.006038822081409307
[Epoch 23, Batch 300] loss: 0.004633762826815655
[Epoch 23, Batch 400] loss: 0.005176069998060484
[Epoch 23, Batch 500] loss: 0.004882004672053881
[Epoch 23, Batch 600] loss: 0.004751946983392372
[Epoch 23, Batch 700] loss: 0.005564922697649308
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0465
Validation Accuracy: 0.9878
Overfitting: 0.0462
[Epoch 24, Batch 100] loss: 0.002397265891108873
[Epoch 24, Batch 200] loss: 0.0040479988326933385
[Epoch 24, Batch 300] loss: 0.004831404253291111
[Epoch 24, Batch 400] loss: 0.0027231709507032063
[Epoch 24, Batch 500] loss: 0.00382579998962683
[Epoch 24, Batch 600] loss: 0.004789711719822663
[Epoch 24, Batch 700] loss: 0.004923124708197974
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0494
Validation Accuracy: 0.9882
Overfitting: 0.0490
Fold 4 validation loss: 0.0494
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.0424450314044953
[Epoch 1, Batch 200] loss: 0.6135389882326127
[Epoch 1, Batch 300] loss: 0.37045019075274466
[Epoch 1, Batch 400] loss: 0.26269203662872315
[Epoch 1, Batch 500] loss: 0.1954811490699649
[Epoch 1, Batch 600] loss: 0.1595835842192173
[Epoch 1, Batch 700] loss: 0.1444262035191059
**STATS for Epoch 1** : 
Average training loss: 0.0104
Average validation loss: 0.1240
Validation Accuracy: 0.9639
Overfitting: 0.1135
Best model saved at epoch 1 with validation loss: 0.1240
[Epoch 2, Batch 100] loss: 0.12328214719891548
[Epoch 2, Batch 200] loss: 0.11885942533612251
[Epoch 2, Batch 300] loss: 0.1034380185417831
[Epoch 2, Batch 400] loss: 0.09152155580930411
[Epoch 2, Batch 500] loss: 0.09132144098170102
[Epoch 2, Batch 600] loss: 0.0869785570167005
[Epoch 2, Batch 700] loss: 0.09642328307963907
**STATS for Epoch 2** : 
Average training loss: 0.0066
Average validation loss: 0.0803
Validation Accuracy: 0.9759
Overfitting: 0.0737
Best model saved at epoch 2 with validation loss: 0.0803
[Epoch 3, Batch 100] loss: 0.08109293019399047
[Epoch 3, Batch 200] loss: 0.0677047742716968
[Epoch 3, Batch 300] loss: 0.07800998831167817
[Epoch 3, Batch 400] loss: 0.06993209730833769
[Epoch 3, Batch 500] loss: 0.0746731083933264
[Epoch 3, Batch 600] loss: 0.07095663561485707
[Epoch 3, Batch 700] loss: 0.06302406650502235
**STATS for Epoch 3** : 
Average training loss: 0.0035
Average validation loss: 0.0674
Validation Accuracy: 0.9799
Overfitting: 0.0640
Best model saved at epoch 3 with validation loss: 0.0674
[Epoch 4, Batch 100] loss: 0.061815369923133405
[Epoch 4, Batch 200] loss: 0.06009895641123876
[Epoch 4, Batch 300] loss: 0.05584530563093722
[Epoch 4, Batch 400] loss: 0.04697023792658001
[Epoch 4, Batch 500] loss: 0.05069468755275011
[Epoch 4, Batch 600] loss: 0.06176334568066522
[Epoch 4, Batch 700] loss: 0.06391098784282803
**STATS for Epoch 4** : 
Average training loss: 0.0033
Average validation loss: 0.0601
Validation Accuracy: 0.9807
Overfitting: 0.0568
Best model saved at epoch 4 with validation loss: 0.0601
[Epoch 5, Batch 100] loss: 0.042241795391310004
[Epoch 5, Batch 200] loss: 0.049406139636412265
[Epoch 5, Batch 300] loss: 0.045134778467472644
[Epoch 5, Batch 400] loss: 0.04778847391717136
[Epoch 5, Batch 500] loss: 0.046941245726775375
[Epoch 5, Batch 600] loss: 0.047490811333991585
[Epoch 5, Batch 700] loss: 0.05112605518428609
**STATS for Epoch 5** : 
Average training loss: 0.0030
Average validation loss: 0.0597
Validation Accuracy: 0.9818
Overfitting: 0.0566
Best model saved at epoch 5 with validation loss: 0.0597
[Epoch 6, Batch 100] loss: 0.04622662477893755
[Epoch 6, Batch 200] loss: 0.035420739431865515
[Epoch 6, Batch 300] loss: 0.04157441296498291
[Epoch 6, Batch 400] loss: 0.034650076511316
[Epoch 6, Batch 500] loss: 0.033876610330771655
[Epoch 6, Batch 600] loss: 0.041550647001713514
[Epoch 6, Batch 700] loss: 0.038054875244852154
**STATS for Epoch 6** : 
Average training loss: 0.0028
Average validation loss: 0.0491
Validation Accuracy: 0.9852
Overfitting: 0.0462
Best model saved at epoch 6 with validation loss: 0.0491
[Epoch 7, Batch 100] loss: 0.0343139491090551
[Epoch 7, Batch 200] loss: 0.036137607145356014
[Epoch 7, Batch 300] loss: 0.03378867590101436
[Epoch 7, Batch 400] loss: 0.04023294791695662
[Epoch 7, Batch 500] loss: 0.03499362677684985
[Epoch 7, Batch 600] loss: 0.03812177877523936
[Epoch 7, Batch 700] loss: 0.03353733288589865
**STATS for Epoch 7** : 
Average training loss: 0.0020
Average validation loss: 0.0491
Validation Accuracy: 0.9850
Overfitting: 0.0471
[Epoch 8, Batch 100] loss: 0.031355759151047095
[Epoch 8, Batch 200] loss: 0.03224138687830418
[Epoch 8, Batch 300] loss: 0.030085950498469172
[Epoch 8, Batch 400] loss: 0.0332262131976313
[Epoch 8, Batch 500] loss: 0.03182693947572261
[Epoch 8, Batch 600] loss: 0.026914557750569657
[Epoch 8, Batch 700] loss: 0.03733724378282204
**STATS for Epoch 8** : 
Average training loss: 0.0018
Average validation loss: 0.0447
Validation Accuracy: 0.9857
Overfitting: 0.0429
Best model saved at epoch 8 with validation loss: 0.0447
[Epoch 9, Batch 100] loss: 0.023581702859373763
[Epoch 9, Batch 200] loss: 0.023335966185550207
[Epoch 9, Batch 300] loss: 0.02951515849912539
[Epoch 9, Batch 400] loss: 0.03142246223054826
[Epoch 9, Batch 500] loss: 0.028867772117373534
[Epoch 9, Batch 600] loss: 0.029868639373453333
[Epoch 9, Batch 700] loss: 0.026086037568747996
**STATS for Epoch 9** : 
Average training loss: 0.0014
Average validation loss: 0.0467
Validation Accuracy: 0.9861
Overfitting: 0.0453
[Epoch 10, Batch 100] loss: 0.02152446517779026
[Epoch 10, Batch 200] loss: 0.025949465365265496
[Epoch 10, Batch 300] loss: 0.025315884667797946
[Epoch 10, Batch 400] loss: 0.025525298313004895
[Epoch 10, Batch 500] loss: 0.022423612504499032
[Epoch 10, Batch 600] loss: 0.020867176527390258
[Epoch 10, Batch 700] loss: 0.026065712234412786
**STATS for Epoch 10** : 
Average training loss: 0.0019
Average validation loss: 0.0457
Validation Accuracy: 0.9872
Overfitting: 0.0438
[Epoch 11, Batch 100] loss: 0.01989037131133955
[Epoch 11, Batch 200] loss: 0.019084629649296404
[Epoch 11, Batch 300] loss: 0.01971432445337996
[Epoch 11, Batch 400] loss: 0.021412000950658695
[Epoch 11, Batch 500] loss: 0.025816974971676246
[Epoch 11, Batch 600] loss: 0.023278535300632938
[Epoch 11, Batch 700] loss: 0.026620844055432826
**STATS for Epoch 11** : 
Average training loss: 0.0018
Average validation loss: 0.0485
Validation Accuracy: 0.9848
Overfitting: 0.0466
[Epoch 12, Batch 100] loss: 0.017595608145347795
[Epoch 12, Batch 200] loss: 0.02074723852914758
[Epoch 12, Batch 300] loss: 0.018886625779559837
[Epoch 12, Batch 400] loss: 0.02111296484596096
[Epoch 12, Batch 500] loss: 0.016657256773905827
[Epoch 12, Batch 600] loss: 0.016251620563853066
[Epoch 12, Batch 700] loss: 0.021854078732576453
**STATS for Epoch 12** : 
Average training loss: 0.0016
Average validation loss: 0.0460
Validation Accuracy: 0.9862
Overfitting: 0.0444
[Epoch 13, Batch 100] loss: 0.018828423694358207
[Epoch 13, Batch 200] loss: 0.01270889310137136
[Epoch 13, Batch 300] loss: 0.01769563216745155
[Epoch 13, Batch 400] loss: 0.01738458862702828
[Epoch 13, Batch 500] loss: 0.012785859938521753
[Epoch 13, Batch 600] loss: 0.021531538604031085
[Epoch 13, Batch 700] loss: 0.018005055593675934
**STATS for Epoch 13** : 
Average training loss: 0.0013
Average validation loss: 0.0444
Validation Accuracy: 0.9875
Overfitting: 0.0431
Best model saved at epoch 13 with validation loss: 0.0444
[Epoch 14, Batch 100] loss: 0.017114650193834676
[Epoch 14, Batch 200] loss: 0.01363595673639793
[Epoch 14, Batch 300] loss: 0.012722879748616833
[Epoch 14, Batch 400] loss: 0.012714899624406827
[Epoch 14, Batch 500] loss: 0.01309135212097317
[Epoch 14, Batch 600] loss: 0.017855530039814767
[Epoch 14, Batch 700] loss: 0.015529053719365037
**STATS for Epoch 14** : 
Average training loss: 0.0015
Average validation loss: 0.0433
Validation Accuracy: 0.9878
Overfitting: 0.0418
Best model saved at epoch 14 with validation loss: 0.0433
[Epoch 15, Batch 100] loss: 0.009548552708292846
[Epoch 15, Batch 200] loss: 0.0176892838589265
[Epoch 15, Batch 300] loss: 0.014230179051446612
[Epoch 15, Batch 400] loss: 0.012566349620610708
[Epoch 15, Batch 500] loss: 0.013815041293564718
[Epoch 15, Batch 600] loss: 0.014798367642215452
[Epoch 15, Batch 700] loss: 0.014156803547375602
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0445
Validation Accuracy: 0.9880
Overfitting: 0.0435
[Epoch 16, Batch 100] loss: 0.013208058121381327
[Epoch 16, Batch 200] loss: 0.014926715047913604
[Epoch 16, Batch 300] loss: 0.012255111925187521
[Epoch 16, Batch 400] loss: 0.008874027939382358
[Epoch 16, Batch 500] loss: 0.009475331072026165
[Epoch 16, Batch 600] loss: 0.013828194892848842
[Epoch 16, Batch 700] loss: 0.010314922329052933
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0495
Validation Accuracy: 0.9873
Overfitting: 0.0486
[Epoch 17, Batch 100] loss: 0.010893907688587206
[Epoch 17, Batch 200] loss: 0.010167025923292385
[Epoch 17, Batch 300] loss: 0.008258108254885883
[Epoch 17, Batch 400] loss: 0.015210678403673229
[Epoch 17, Batch 500] loss: 0.01680367861634295
[Epoch 17, Batch 600] loss: 0.012406397224694957
[Epoch 17, Batch 700] loss: 0.00889737092606083
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0455
Validation Accuracy: 0.9880
Overfitting: 0.0444
[Epoch 18, Batch 100] loss: 0.009388499911146937
[Epoch 18, Batch 200] loss: 0.008627709227293962
[Epoch 18, Batch 300] loss: 0.013457709035574226
[Epoch 18, Batch 400] loss: 0.007137440166843589
[Epoch 18, Batch 500] loss: 0.010748451271138038
[Epoch 18, Batch 600] loss: 0.013051991288375576
[Epoch 18, Batch 700] loss: 0.009931097102162311
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0439
Validation Accuracy: 0.9890
Overfitting: 0.0432
[Epoch 19, Batch 100] loss: 0.006418723588503781
[Epoch 19, Batch 200] loss: 0.010700116549123777
[Epoch 19, Batch 300] loss: 0.006182255829189671
[Epoch 19, Batch 400] loss: 0.008257545232845586
[Epoch 19, Batch 500] loss: 0.007558806145534618
[Epoch 19, Batch 600] loss: 0.011010689010217902
[Epoch 19, Batch 700] loss: 0.010761859878402901
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0471
Validation Accuracy: 0.9880
Overfitting: 0.0463
[Epoch 20, Batch 100] loss: 0.005299493847487611
[Epoch 20, Batch 200] loss: 0.005740046949940733
[Epoch 20, Batch 300] loss: 0.004965741163578059
[Epoch 20, Batch 400] loss: 0.010246535404730821
[Epoch 20, Batch 500] loss: 0.004753139147251204
[Epoch 20, Batch 600] loss: 0.009300069430446456
[Epoch 20, Batch 700] loss: 0.008246523486377555
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0476
Validation Accuracy: 0.9888
Overfitting: 0.0471
[Epoch 21, Batch 100] loss: 0.0053697730883504845
[Epoch 21, Batch 200] loss: 0.00420619385991813
[Epoch 21, Batch 300] loss: 0.00870536366939632
[Epoch 21, Batch 400] loss: 0.00741132561906852
[Epoch 21, Batch 500] loss: 0.007496356657920842
[Epoch 21, Batch 600] loss: 0.007071807667780376
[Epoch 21, Batch 700] loss: 0.007004823841016332
**STATS for Epoch 21** : 
Average training loss: 0.0008
Average validation loss: 0.0472
Validation Accuracy: 0.9886
Overfitting: 0.0464
[Epoch 22, Batch 100] loss: 0.0036712912328584935
[Epoch 22, Batch 200] loss: 0.00398395247728331
[Epoch 22, Batch 300] loss: 0.0034744176782078285
[Epoch 22, Batch 400] loss: 0.0056855123401237505
[Epoch 22, Batch 500] loss: 0.006131632205469941
[Epoch 22, Batch 600] loss: 0.007021472952073964
[Epoch 22, Batch 700] loss: 0.007211199468874838
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0500
Validation Accuracy: 0.9888
Overfitting: 0.0497
[Epoch 23, Batch 100] loss: 0.005735080771155481
[Epoch 23, Batch 200] loss: 0.003402570385514991
[Epoch 23, Batch 300] loss: 0.0031712902426534128
[Epoch 23, Batch 400] loss: 0.005730586270592539
[Epoch 23, Batch 500] loss: 0.0029235884742229244
[Epoch 23, Batch 600] loss: 0.0027207749473382135
[Epoch 23, Batch 700] loss: 0.008099722378046863
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0490
Validation Accuracy: 0.9888
Overfitting: 0.0485
[Epoch 24, Batch 100] loss: 0.004276238387719786
[Epoch 24, Batch 200] loss: 0.003767122367353295
[Epoch 24, Batch 300] loss: 0.004462015579756553
[Epoch 24, Batch 400] loss: 0.0036794295900654107
[Epoch 24, Batch 500] loss: 0.004610096359247109
[Epoch 24, Batch 600] loss: 0.007754034499903355
[Epoch 24, Batch 700] loss: 0.0038479211198318808
**STATS for Epoch 24** : 
Average training loss: 0.0006
Average validation loss: 0.0511
Validation Accuracy: 0.9876
Overfitting: 0.0505
Fold 5 validation loss: 0.0511
Mean validation loss across all folds for Trial 21 is 0.0547 with trial config:  l1: 128, l2: 128, lr: 0.003723057268711563, batch_size: 64
[I 2024-12-11 06:03:36,754] Trial 20 finished with value: 0.05473463504861229 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.003723057268711563, 'batch_size': 64}. Best is trial 4 with value: 0.046929042829858846.

Selected Hyperparameters for Trial 22:
  l1: 128, l2: 128, lr: 0.0013350479148106298, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2941315960884094
[Epoch 1, Batch 200] loss: 2.2434924125671385
[Epoch 1, Batch 300] loss: 1.8720057332515716
**STATS for Epoch 1** : 
Average training loss: 0.1474
Average validation loss: 0.5348
Validation Accuracy: 0.8354
Overfitting: 0.3875
Best model saved at epoch 1 with validation loss: 0.5348
[Epoch 2, Batch 100] loss: 0.4731400647759438
[Epoch 2, Batch 200] loss: 0.3675454093515873
[Epoch 2, Batch 300] loss: 0.3253017944097519
**STATS for Epoch 2** : 
Average training loss: 0.0568
Average validation loss: 0.2494
Validation Accuracy: 0.9296
Overfitting: 0.1926
Best model saved at epoch 2 with validation loss: 0.2494
[Epoch 3, Batch 100] loss: 0.2562137810885906
[Epoch 3, Batch 200] loss: 0.2378863637149334
[Epoch 3, Batch 300] loss: 0.20853256799280642
**STATS for Epoch 3** : 
Average training loss: 0.0383
Average validation loss: 0.1921
Validation Accuracy: 0.9423
Overfitting: 0.1538
Best model saved at epoch 3 with validation loss: 0.1921
[Epoch 4, Batch 100] loss: 0.17954172752797604
[Epoch 4, Batch 200] loss: 0.16833397842943668
[Epoch 4, Batch 300] loss: 0.15664355715736747
**STATS for Epoch 4** : 
Average training loss: 0.0287
Average validation loss: 0.1472
Validation Accuracy: 0.9532
Overfitting: 0.1185
Best model saved at epoch 4 with validation loss: 0.1472
[Epoch 5, Batch 100] loss: 0.1430731575191021
[Epoch 5, Batch 200] loss: 0.13445947699248792
[Epoch 5, Batch 300] loss: 0.1329443084448576
**STATS for Epoch 5** : 
Average training loss: 0.0232
Average validation loss: 0.1085
Validation Accuracy: 0.9668
Overfitting: 0.0853
Best model saved at epoch 5 with validation loss: 0.1085
[Epoch 6, Batch 100] loss: 0.11651177801191807
[Epoch 6, Batch 200] loss: 0.11235469404608012
[Epoch 6, Batch 300] loss: 0.11234293773770332
**STATS for Epoch 6** : 
Average training loss: 0.0212
Average validation loss: 0.0977
Validation Accuracy: 0.9680
Overfitting: 0.0765
[I 2024-12-11 06:04:29,939] Trial 21 pruned. 

Selected Hyperparameters for Trial 23:
  l1: 128, l2: 128, lr: 0.0008028836717487803, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.300232071876526
[Epoch 1, Batch 200] loss: 2.2836289191246033
[Epoch 1, Batch 300] loss: 2.2569258880615233
[Epoch 1, Batch 400] loss: 2.1626146483421325
[Epoch 1, Batch 500] loss: 1.7187914061546326
[Epoch 1, Batch 600] loss: 0.905416588485241
[Epoch 1, Batch 700] loss: 0.6087610203772783
[Epoch 1, Batch 800] loss: 0.5323123703896999
[Epoch 1, Batch 900] loss: 0.45652923479676244
[Epoch 1, Batch 1000] loss: 0.37588994106277823
[Epoch 1, Batch 1100] loss: 0.327970100864768
[Epoch 1, Batch 1200] loss: 0.3170998065918684
[Epoch 1, Batch 1300] loss: 0.33570534907281396
[Epoch 1, Batch 1400] loss: 0.2556554344668984
[Epoch 1, Batch 1500] loss: 0.2925828987360001
[Epoch 1, Batch 1600] loss: 0.299953825622797
[Epoch 1, Batch 1700] loss: 0.2768548085540533
[Epoch 1, Batch 1800] loss: 0.25930828262120487
[Epoch 1, Batch 1900] loss: 0.2355305413529277
[Epoch 1, Batch 2000] loss: 0.23156193578615786
[Epoch 1, Batch 2100] loss: 0.19150533990003168
[Epoch 1, Batch 2200] loss: 0.1854703151062131
[Epoch 1, Batch 2300] loss: 0.20036723502911627
[Epoch 1, Batch 2400] loss: 0.1692590361647308
[Epoch 1, Batch 2500] loss: 0.18461529207415878
[Epoch 1, Batch 2600] loss: 0.16958083502482624
[Epoch 1, Batch 2700] loss: 0.15911056477576493
[Epoch 1, Batch 2800] loss: 0.154010458169505
[Epoch 1, Batch 2900] loss: 0.16198340096045286
[Epoch 1, Batch 3000] loss: 0.13261983909644187
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1277
Validation Accuracy: 0.9615
Overfitting: 0.1277
Best model saved at epoch 1 with validation loss: 0.1277
[Epoch 2, Batch 100] loss: 0.15331434301100672
[Epoch 2, Batch 200] loss: 0.1331795914610848
[Epoch 2, Batch 300] loss: 0.12111699372064322
[Epoch 2, Batch 400] loss: 0.16598345514386892
[Epoch 2, Batch 500] loss: 0.14784560810774564
[Epoch 2, Batch 600] loss: 0.1480495793139562
[Epoch 2, Batch 700] loss: 0.11784791772253811
[Epoch 2, Batch 800] loss: 0.12071130270138383
[Epoch 2, Batch 900] loss: 0.11882341188378633
[Epoch 2, Batch 1000] loss: 0.10954307984560728
[Epoch 2, Batch 1100] loss: 0.1185905411047861
[Epoch 2, Batch 1200] loss: 0.1376682686805725
[Epoch 2, Batch 1300] loss: 0.11846144523005933
[Epoch 2, Batch 1400] loss: 0.14990975566208362
[Epoch 2, Batch 1500] loss: 0.1122432983480394
[Epoch 2, Batch 1600] loss: 0.11427849677857012
[Epoch 2, Batch 1700] loss: 0.1122154751745984
[Epoch 2, Batch 1800] loss: 0.09545631954679265
[Epoch 2, Batch 1900] loss: 0.10038514466024935
[Epoch 2, Batch 2000] loss: 0.13468359387014062
[Epoch 2, Batch 2100] loss: 0.0870961695536971
[Epoch 2, Batch 2200] loss: 0.08714254641905426
[Epoch 2, Batch 2300] loss: 0.08873699671821669
[Epoch 2, Batch 2400] loss: 0.11240241463296115
[Epoch 2, Batch 2500] loss: 0.11409628961235285
[Epoch 2, Batch 2600] loss: 0.09168205249588937
[Epoch 2, Batch 2700] loss: 0.09877475193003192
[Epoch 2, Batch 2800] loss: 0.09084385906346143
[Epoch 2, Batch 2900] loss: 0.11527856762520969
[Epoch 2, Batch 3000] loss: 0.08263491098070518
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0866
Validation Accuracy: 0.9720
Overfitting: 0.0866
Best model saved at epoch 2 with validation loss: 0.0866
[Epoch 3, Batch 100] loss: 0.07571512887836435
[Epoch 3, Batch 200] loss: 0.08523719663964585
[Epoch 3, Batch 300] loss: 0.08383320059161634
[Epoch 3, Batch 400] loss: 0.09666026241146028
[Epoch 3, Batch 500] loss: 0.07553527127020061
[Epoch 3, Batch 600] loss: 0.09069888131227344
[Epoch 3, Batch 700] loss: 0.07596798803657294
[Epoch 3, Batch 800] loss: 0.08482698294334114
[Epoch 3, Batch 900] loss: 0.10075677964254283
[Epoch 3, Batch 1000] loss: 0.07198641288443469
[Epoch 3, Batch 1100] loss: 0.07283212347771041
[Epoch 3, Batch 1200] loss: 0.074483056840254
[Epoch 3, Batch 1300] loss: 0.06704017844574992
[Epoch 3, Batch 1400] loss: 0.0702893522544764
[Epoch 3, Batch 1500] loss: 0.0806384761328809
[Epoch 3, Batch 1600] loss: 0.05985329721472226
[Epoch 3, Batch 1700] loss: 0.08294229025021195
[Epoch 3, Batch 1800] loss: 0.08600127662415616
[Epoch 3, Batch 1900] loss: 0.1176589114649687
[Epoch 3, Batch 2000] loss: 0.08994717188877985
[Epoch 3, Batch 2100] loss: 0.058977753405924885
[Epoch 3, Batch 2200] loss: 0.09079511683434248
[Epoch 3, Batch 2300] loss: 0.0852780709695071
[Epoch 3, Batch 2400] loss: 0.06063108836649917
[Epoch 3, Batch 2500] loss: 0.08911340246908367
[Epoch 3, Batch 2600] loss: 0.05508672890951857
[Epoch 3, Batch 2700] loss: 0.05893354418512899
[Epoch 3, Batch 2800] loss: 0.045222545620054004
[Epoch 3, Batch 2900] loss: 0.059893840066506526
[Epoch 3, Batch 3000] loss: 0.10240994231658988
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0805
Validation Accuracy: 0.9742
Overfitting: 0.0805
Best model saved at epoch 3 with validation loss: 0.0805
[Epoch 4, Batch 100] loss: 0.06299703317112289
[Epoch 4, Batch 200] loss: 0.05862474675755948
[Epoch 4, Batch 300] loss: 0.06610264730930794
[Epoch 4, Batch 400] loss: 0.059042134472401815
[Epoch 4, Batch 500] loss: 0.06987433219677769
[Epoch 4, Batch 600] loss: 0.0571791308640968
[Epoch 4, Batch 700] loss: 0.06824050348077434
[Epoch 4, Batch 800] loss: 0.05203673148935195
[Epoch 4, Batch 900] loss: 0.044879332793061624
[Epoch 4, Batch 1000] loss: 0.07639197652286384
[Epoch 4, Batch 1100] loss: 0.06467802575149108
[Epoch 4, Batch 1200] loss: 0.06105113852070645
[Epoch 4, Batch 1300] loss: 0.05728162241051905
[Epoch 4, Batch 1400] loss: 0.0527022821130231
[Epoch 4, Batch 1500] loss: 0.06649055507208686
[Epoch 4, Batch 1600] loss: 0.052673265994526444
[Epoch 4, Batch 1700] loss: 0.06213453526375815
[Epoch 4, Batch 1800] loss: 0.0519386616742122
[Epoch 4, Batch 1900] loss: 0.06466435152629856
[Epoch 4, Batch 2000] loss: 0.05914972065773327
[Epoch 4, Batch 2100] loss: 0.062416008458239955
[Epoch 4, Batch 2200] loss: 0.0813529238163028
[Epoch 4, Batch 2300] loss: 0.05858818733831868
[Epoch 4, Batch 2400] loss: 0.057778159243171104
[Epoch 4, Batch 2500] loss: 0.06207456017145887
[Epoch 4, Batch 2600] loss: 0.06022663578041829
[Epoch 4, Batch 2700] loss: 0.08105830745451385
[Epoch 4, Batch 2800] loss: 0.05662186970701441
[Epoch 4, Batch 2900] loss: 0.04463372059981339
[Epoch 4, Batch 3000] loss: 0.05259156037354842
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0655
Validation Accuracy: 0.9792
Overfitting: 0.0655
Best model saved at epoch 4 with validation loss: 0.0655
[Epoch 5, Batch 100] loss: 0.05694561658194289
[Epoch 5, Batch 200] loss: 0.05763684859790374
[Epoch 5, Batch 300] loss: 0.07280105441139312
[Epoch 5, Batch 400] loss: 0.044450045799021606
[Epoch 5, Batch 500] loss: 0.051855674481194
[Epoch 5, Batch 600] loss: 0.06255242111830739
[Epoch 5, Batch 700] loss: 0.060178209638979754
[Epoch 5, Batch 800] loss: 0.045879091945535036
[Epoch 5, Batch 900] loss: 0.06156711920746602
[Epoch 5, Batch 1000] loss: 0.05905432643397944
[Epoch 5, Batch 1100] loss: 0.039246562426560556
[Epoch 5, Batch 1200] loss: 0.04578458526113536
[Epoch 5, Batch 1300] loss: 0.03889857888716506
[Epoch 5, Batch 1400] loss: 0.060500178028596564
[Epoch 5, Batch 1500] loss: 0.05546078439831035
[Epoch 5, Batch 1600] loss: 0.062339417841285466
[Epoch 5, Batch 1700] loss: 0.04569150229363004
[Epoch 5, Batch 1800] loss: 0.04942361487264861
[Epoch 5, Batch 1900] loss: 0.04997638563683722
[Epoch 5, Batch 2000] loss: 0.044897280743170995
[Epoch 5, Batch 2100] loss: 0.05422899333381793
[Epoch 5, Batch 2200] loss: 0.05192485691499314
[Epoch 5, Batch 2300] loss: 0.05196577186419745
[Epoch 5, Batch 2400] loss: 0.04256473913512309
[Epoch 5, Batch 2500] loss: 0.03136722560535418
[Epoch 5, Batch 2600] loss: 0.04456702675757697
[Epoch 5, Batch 2700] loss: 0.046327980755595494
[Epoch 5, Batch 2800] loss: 0.043910958974156526
[Epoch 5, Batch 2900] loss: 0.03951830398742459
[Epoch 5, Batch 3000] loss: 0.039240351300104524
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0574
Validation Accuracy: 0.9819
Overfitting: 0.0574
Best model saved at epoch 5 with validation loss: 0.0574
[Epoch 6, Batch 100] loss: 0.042435560522571907
[Epoch 6, Batch 200] loss: 0.03959325233154232
[Epoch 6, Batch 300] loss: 0.03868777469324414
[Epoch 6, Batch 400] loss: 0.057552874893299306
[Epoch 6, Batch 500] loss: 0.04039984459901461
[Epoch 6, Batch 600] loss: 0.03548842690332094
[Epoch 6, Batch 700] loss: 0.03371599923426402
[Epoch 6, Batch 800] loss: 0.027183450416196138
[Epoch 6, Batch 900] loss: 0.04122716231679078
[Epoch 6, Batch 1000] loss: 0.06377641553699505
[Epoch 6, Batch 1100] loss: 0.05335165856900858
[Epoch 6, Batch 1200] loss: 0.03491848197998479
[Epoch 6, Batch 1300] loss: 0.04953717913129367
[Epoch 6, Batch 1400] loss: 0.0453574749501422
[Epoch 6, Batch 1500] loss: 0.04341750667546876
[Epoch 6, Batch 1600] loss: 0.042197456232388506
[Epoch 6, Batch 1700] loss: 0.024400953445147023
[Epoch 6, Batch 1800] loss: 0.05771098932949826
[Epoch 6, Batch 1900] loss: 0.04157316893921234
[Epoch 6, Batch 2000] loss: 0.041423321447800844
[Epoch 6, Batch 2100] loss: 0.03597977472527418
[Epoch 6, Batch 2200] loss: 0.03928786232281709
[Epoch 6, Batch 2300] loss: 0.03711024790391093
[Epoch 6, Batch 2400] loss: 0.04730173828778789
[Epoch 6, Batch 2500] loss: 0.04020118169108173
[Epoch 6, Batch 2600] loss: 0.031456277153265544
[Epoch 6, Batch 2700] loss: 0.04610067130648531
[Epoch 6, Batch 2800] loss: 0.042925048688048265
[Epoch 6, Batch 2900] loss: 0.050685846296837554
[Epoch 6, Batch 3000] loss: 0.06092055202985648
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9806
Overfitting: 0.0546
[I 2024-12-11 06:05:55,601] Trial 22 pruned. 

Selected Hyperparameters for Trial 24:
  l1: 128, l2: 64, lr: 0.0002691104779323301, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3008844828605652
[Epoch 1, Batch 200] loss: 2.292025065422058
[Epoch 1, Batch 300] loss: 2.2821400475502016
[Epoch 1, Batch 400] loss: 2.2737614250183107
[Epoch 1, Batch 500] loss: 2.2608127999305725
[Epoch 1, Batch 600] loss: 2.2427467346191405
[Epoch 1, Batch 700] loss: 2.219926083087921
[Epoch 1, Batch 800] loss: 2.1834238958358765
[Epoch 1, Batch 900] loss: 2.11840031504631
[Epoch 1, Batch 1000] loss: 2.0046901071071623
[Epoch 1, Batch 1100] loss: 1.7880495274066925
[Epoch 1, Batch 1200] loss: 1.4399384260177612
[Epoch 1, Batch 1300] loss: 1.1097771286964417
[Epoch 1, Batch 1400] loss: 0.8664831757545471
[Epoch 1, Batch 1500] loss: 0.7062289509177208
[Epoch 1, Batch 1600] loss: 0.6554934850335121
[Epoch 1, Batch 1700] loss: 0.560056976377964
[Epoch 1, Batch 1800] loss: 0.47237217783927915
[Epoch 1, Batch 1900] loss: 0.5051534125208854
[Epoch 1, Batch 2000] loss: 0.47156407587230204
[Epoch 1, Batch 2100] loss: 0.4359526977688074
[Epoch 1, Batch 2200] loss: 0.4217339839786291
[Epoch 1, Batch 2300] loss: 0.4035070792585611
[Epoch 1, Batch 2400] loss: 0.38038014955818655
[Epoch 1, Batch 2500] loss: 0.346224926635623
[Epoch 1, Batch 2600] loss: 0.33886343777179717
[Epoch 1, Batch 2700] loss: 0.37711172737181187
[Epoch 1, Batch 2800] loss: 0.3353301726654172
[Epoch 1, Batch 2900] loss: 0.3688946515694261
[Epoch 1, Batch 3000] loss: 0.2787332333251834
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2962
Validation Accuracy: 0.9117
Overfitting: 0.2962
Best model saved at epoch 1 with validation loss: 0.2962
[Epoch 2, Batch 100] loss: 0.30184413939714433
[Epoch 2, Batch 200] loss: 0.2650784257426858
[Epoch 2, Batch 300] loss: 0.2689785948395729
[Epoch 2, Batch 400] loss: 0.2724791596271098
[Epoch 2, Batch 500] loss: 0.2586665018647909
[Epoch 2, Batch 600] loss: 0.27288758508861066
[Epoch 2, Batch 700] loss: 0.2399224373884499
[Epoch 2, Batch 800] loss: 0.2311984093859792
[Epoch 2, Batch 900] loss: 0.2737209177389741
[Epoch 2, Batch 1000] loss: 0.22936317263171077
[Epoch 2, Batch 1100] loss: 0.26222792381420734
[Epoch 2, Batch 1200] loss: 0.22364781607873738
[Epoch 2, Batch 1300] loss: 0.21468635914847256
[Epoch 2, Batch 1400] loss: 0.22611429568380118
[Epoch 2, Batch 1500] loss: 0.21139782529324294
[Epoch 2, Batch 1600] loss: 0.23949144169688225
[Epoch 2, Batch 1700] loss: 0.22482068432494998
[Epoch 2, Batch 1800] loss: 0.21536921489983796
[Epoch 2, Batch 1900] loss: 0.22607325479388238
[Epoch 2, Batch 2000] loss: 0.17469012649729848
[Epoch 2, Batch 2100] loss: 0.19554008564911782
[Epoch 2, Batch 2200] loss: 0.2078664286248386
[Epoch 2, Batch 2300] loss: 0.20169431252405048
[Epoch 2, Batch 2400] loss: 0.1861510606808588
[Epoch 2, Batch 2500] loss: 0.1757321321964264
[Epoch 2, Batch 2600] loss: 0.17604040686041117
[Epoch 2, Batch 2700] loss: 0.18218729943037032
[Epoch 2, Batch 2800] loss: 0.17587005116045476
[Epoch 2, Batch 2900] loss: 0.14589185102842747
[Epoch 2, Batch 3000] loss: 0.1816417401190847
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1525
Validation Accuracy: 0.9533
Overfitting: 0.1525
Best model saved at epoch 2 with validation loss: 0.1525
[Epoch 3, Batch 100] loss: 0.1556131836026907
[Epoch 3, Batch 200] loss: 0.161495737535879
[Epoch 3, Batch 300] loss: 0.15743563019670545
[Epoch 3, Batch 400] loss: 0.16076046639122069
[Epoch 3, Batch 500] loss: 0.15664061596617102
[Epoch 3, Batch 600] loss: 0.14770474201068282
[Epoch 3, Batch 700] loss: 0.16418910295236855
[Epoch 3, Batch 800] loss: 0.1656964483531192
[Epoch 3, Batch 900] loss: 0.16582067884504795
[Epoch 3, Batch 1000] loss: 0.14789518600795418
[Epoch 3, Batch 1100] loss: 0.13849941454362125
[Epoch 3, Batch 1200] loss: 0.15538002938963472
[Epoch 3, Batch 1300] loss: 0.1394058541022241
[Epoch 3, Batch 1400] loss: 0.1762569439667277
[Epoch 3, Batch 1500] loss: 0.1571689181262627
[Epoch 3, Batch 1600] loss: 0.12811595264822245
[Epoch 3, Batch 1700] loss: 0.1420096542686224
[Epoch 3, Batch 1800] loss: 0.13919690557289868
[Epoch 3, Batch 1900] loss: 0.1630340765789151
[Epoch 3, Batch 2000] loss: 0.13075021360069514
[Epoch 3, Batch 2100] loss: 0.1487197019904852
[Epoch 3, Batch 2200] loss: 0.17244833310600372
[Epoch 3, Batch 2300] loss: 0.1373156456835568
[Epoch 3, Batch 2400] loss: 0.15040144854225218
[Epoch 3, Batch 2500] loss: 0.12746708190534264
[Epoch 3, Batch 2600] loss: 0.1202165401680395
[Epoch 3, Batch 2700] loss: 0.11149745955597609
[Epoch 3, Batch 2800] loss: 0.14192125745583326
[Epoch 3, Batch 2900] loss: 0.11741607155650854
[Epoch 3, Batch 3000] loss: 0.136414907197468
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1211
Validation Accuracy: 0.9631
Overfitting: 0.1211
Best model saved at epoch 3 with validation loss: 0.1211
[Epoch 4, Batch 100] loss: 0.1382731023663655
[Epoch 4, Batch 200] loss: 0.09774010527762585
[Epoch 4, Batch 300] loss: 0.10139926730422304
[Epoch 4, Batch 400] loss: 0.10240236298530363
[Epoch 4, Batch 500] loss: 0.12205108302179724
[Epoch 4, Batch 600] loss: 0.12025204660138115
[Epoch 4, Batch 700] loss: 0.13991993819829077
[Epoch 4, Batch 800] loss: 0.12523596993647515
[Epoch 4, Batch 900] loss: 0.11941608479479328
[Epoch 4, Batch 1000] loss: 0.09844046365469694
[Epoch 4, Batch 1100] loss: 0.11560423129238188
[Epoch 4, Batch 1200] loss: 0.13264454482123256
[Epoch 4, Batch 1300] loss: 0.10948425406124443
[Epoch 4, Batch 1400] loss: 0.1199052493344061
[Epoch 4, Batch 1500] loss: 0.10066558460239321
[Epoch 4, Batch 1600] loss: 0.11375746314413845
[Epoch 4, Batch 1700] loss: 0.12738799725659192
[Epoch 4, Batch 1800] loss: 0.1155096147628501
[Epoch 4, Batch 1900] loss: 0.12425788454711437
[Epoch 4, Batch 2000] loss: 0.09675834219902754
[Epoch 4, Batch 2100] loss: 0.1173826377466321
[Epoch 4, Batch 2200] loss: 0.13584221817087383
[Epoch 4, Batch 2300] loss: 0.11038667305372656
[Epoch 4, Batch 2400] loss: 0.12067023873329162
[Epoch 4, Batch 2500] loss: 0.10294317232444883
[Epoch 4, Batch 2600] loss: 0.12198112550191581
[Epoch 4, Batch 2700] loss: 0.09211033934028819
[Epoch 4, Batch 2800] loss: 0.08969106758129783
[Epoch 4, Batch 2900] loss: 0.11220567868556827
[Epoch 4, Batch 3000] loss: 0.09323941560694948
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0954
Validation Accuracy: 0.9691
Overfitting: 0.0954
Best model saved at epoch 4 with validation loss: 0.0954
[Epoch 5, Batch 100] loss: 0.10015868167392909
[Epoch 5, Batch 200] loss: 0.09789952882332727
[Epoch 5, Batch 300] loss: 0.11164412922458723
[Epoch 5, Batch 400] loss: 0.0841553803300485
[Epoch 5, Batch 500] loss: 0.09947675077593886
[Epoch 5, Batch 600] loss: 0.11861399607267231
[Epoch 5, Batch 700] loss: 0.11830170339439064
[Epoch 5, Batch 800] loss: 0.08853326560929417
[Epoch 5, Batch 900] loss: 0.09348935717716814
[Epoch 5, Batch 1000] loss: 0.10070591444149614
[Epoch 5, Batch 1100] loss: 0.10361814005067572
[Epoch 5, Batch 1200] loss: 0.11105441747815348
[Epoch 5, Batch 1300] loss: 0.08569330729311332
[Epoch 5, Batch 1400] loss: 0.09716586841270328
[Epoch 5, Batch 1500] loss: 0.08561167203122749
[Epoch 5, Batch 1600] loss: 0.09071867896942422
[Epoch 5, Batch 1700] loss: 0.08749125876929612
[Epoch 5, Batch 1800] loss: 0.09613883975660428
[Epoch 5, Batch 1900] loss: 0.09837350532179698
[Epoch 5, Batch 2000] loss: 0.09371485478244722
[Epoch 5, Batch 2100] loss: 0.09059436379233375
[Epoch 5, Batch 2200] loss: 0.09937497490551322
[Epoch 5, Batch 2300] loss: 0.08719207851856481
[Epoch 5, Batch 2400] loss: 0.08911362078972161
[Epoch 5, Batch 2500] loss: 0.10582033992744982
[Epoch 5, Batch 2600] loss: 0.1044639085046947
[Epoch 5, Batch 2700] loss: 0.10267860954394564
[Epoch 5, Batch 2800] loss: 0.08752549962955528
[Epoch 5, Batch 2900] loss: 0.09242229020223021
[Epoch 5, Batch 3000] loss: 0.08139262486365624
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0921
Validation Accuracy: 0.9718
Overfitting: 0.0921
Best model saved at epoch 5 with validation loss: 0.0921
[Epoch 6, Batch 100] loss: 0.10038881720858626
[Epoch 6, Batch 200] loss: 0.08646616008540149
[Epoch 6, Batch 300] loss: 0.09776013726601378
[Epoch 6, Batch 400] loss: 0.11610370833659545
[Epoch 6, Batch 500] loss: 0.08330988481407985
[Epoch 6, Batch 600] loss: 0.07214661445003002
[Epoch 6, Batch 700] loss: 0.09187673318898305
[Epoch 6, Batch 800] loss: 0.08540406179847196
[Epoch 6, Batch 900] loss: 0.11480725032510236
[Epoch 6, Batch 1000] loss: 0.09245709280017764
[Epoch 6, Batch 1100] loss: 0.08659845392452553
[Epoch 6, Batch 1200] loss: 0.08673830949002877
[Epoch 6, Batch 1300] loss: 0.07582849998725578
[Epoch 6, Batch 1400] loss: 0.07569771357113496
[Epoch 6, Batch 1500] loss: 0.08015463635325432
[Epoch 6, Batch 1600] loss: 0.11357815878931433
[Epoch 6, Batch 1700] loss: 0.07234365058306139
[Epoch 6, Batch 1800] loss: 0.08235382098704576
[Epoch 6, Batch 1900] loss: 0.06362402343889699
[Epoch 6, Batch 2000] loss: 0.09100707529578358
[Epoch 6, Batch 2100] loss: 0.08015234667574987
[Epoch 6, Batch 2200] loss: 0.07093609251081943
[Epoch 6, Batch 2300] loss: 0.07777708617271856
[Epoch 6, Batch 2400] loss: 0.07101493003545328
[Epoch 6, Batch 2500] loss: 0.08304050432518124
[Epoch 6, Batch 2600] loss: 0.08296129025286064
[Epoch 6, Batch 2700] loss: 0.06696105413837358
[Epoch 6, Batch 2800] loss: 0.07244592375354841
[Epoch 6, Batch 2900] loss: 0.06944979948690161
[Epoch 6, Batch 3000] loss: 0.09193151077837683
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0745
Validation Accuracy: 0.9772
Overfitting: 0.0745
[I 2024-12-11 06:07:19,957] Trial 23 pruned. 
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  12
  Number of complete trials:  12
Best hyperparameters found:
{'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16}
Best trial:
  Value:  0.046929042829858846
Loaded best model checkpoint from: instances/1446697_20241211/best_checkpoint_trial_4/model.pth
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 2.300642192363739
[Epoch 1, Batch 200] loss: 2.2862558722496034
[Epoch 1, Batch 300] loss: 2.2715809893608094
[Epoch 1, Batch 400] loss: 2.2417567014694213
[Epoch 1, Batch 500] loss: 2.195907690525055
[Epoch 1, Batch 600] loss: 2.1027485859394073
[Epoch 1, Batch 700] loss: 1.8987231612205506
[Epoch 1, Batch 800] loss: 1.47162269115448
[Epoch 1, Batch 900] loss: 1.0265724992752074
[Epoch 1, Batch 1000] loss: 0.7379490569233894
[Epoch 1, Batch 1100] loss: 0.5944002686440945
[Epoch 1, Batch 1200] loss: 0.5430628287792206
[Epoch 1, Batch 1300] loss: 0.5036932449042797
[Epoch 1, Batch 1400] loss: 0.49243642792105674
[Epoch 1, Batch 1500] loss: 0.43198086217045784
[Epoch 1, Batch 1600] loss: 0.44876118898391726
[Epoch 1, Batch 1700] loss: 0.40200729697942733
[Epoch 1, Batch 1800] loss: 0.39061359837651255
[Epoch 1, Batch 1900] loss: 0.3504523998498917
[Epoch 1, Batch 2000] loss: 0.33478460140526295
[Epoch 1, Batch 2100] loss: 0.32338966362178323
[Epoch 1, Batch 2200] loss: 0.3072766468673944
[Epoch 1, Batch 2300] loss: 0.2610552066937089
[Epoch 1, Batch 2400] loss: 0.27995008274912836
[Epoch 1, Batch 2500] loss: 0.26853393783792856
[Epoch 1, Batch 2600] loss: 0.2912712563946843
[Epoch 1, Batch 2700] loss: 0.270048279389739
[Epoch 1, Batch 2800] loss: 0.2914518143609166
[Epoch 1, Batch 2900] loss: 0.283545786049217
[Epoch 1, Batch 3000] loss: 0.2502965512126684
[Epoch 1, Batch 3100] loss: 0.252949493881315
[Epoch 1, Batch 3200] loss: 0.24311773819848895
[Epoch 1, Batch 3300] loss: 0.24520738147199153
[Epoch 1, Batch 3400] loss: 0.21935058426111936
[Epoch 1, Batch 3500] loss: 0.2365395192615688
[Epoch 1, Batch 3600] loss: 0.23642686871811747
[Epoch 1, Batch 3700] loss: 0.21267682986333966
**STATS for Epoch 1** : 
Average training loss: 0.0029
Average validation loss: 0.1897
Overfitting: 0.1868
Best model saved at epoch 1 with training loss: 0.0029
[Epoch 2, Batch 100] loss: 0.19529570426791906
[Epoch 2, Batch 200] loss: 0.22463813641108574
[Epoch 2, Batch 300] loss: 0.18220890991389752
[Epoch 2, Batch 400] loss: 0.21044555138796567
[Epoch 2, Batch 500] loss: 0.15489677080884576
[Epoch 2, Batch 600] loss: 0.16761687219142915
[Epoch 2, Batch 700] loss: 0.17221773602999746
[Epoch 2, Batch 800] loss: 0.17739242179319262
[Epoch 2, Batch 900] loss: 0.1851855946984142
[Epoch 2, Batch 1000] loss: 0.1759971727989614
[Epoch 2, Batch 1100] loss: 0.1618117642123252
[Epoch 2, Batch 1200] loss: 0.15628592101857067
[Epoch 2, Batch 1300] loss: 0.16450827136635782
[Epoch 2, Batch 1400] loss: 0.16597382992040366
[Epoch 2, Batch 1500] loss: 0.17477873417083173
[Epoch 2, Batch 1600] loss: 0.13434763262979688
[Epoch 2, Batch 1700] loss: 0.1584684411296621
[Epoch 2, Batch 1800] loss: 0.1446274208300747
[Epoch 2, Batch 1900] loss: 0.1657730192411691
[Epoch 2, Batch 2000] loss: 0.1378113091364503
[Epoch 2, Batch 2100] loss: 0.15219086016993968
[Epoch 2, Batch 2200] loss: 0.13652986944653095
[Epoch 2, Batch 2300] loss: 0.1602892397623509
[Epoch 2, Batch 2400] loss: 0.13924158117733895
[Epoch 2, Batch 2500] loss: 0.12846294515766205
[Epoch 2, Batch 2600] loss: 0.15032147827092557
[Epoch 2, Batch 2700] loss: 0.12356012686155736
[Epoch 2, Batch 2800] loss: 0.12314447456272319
[Epoch 2, Batch 2900] loss: 0.1250099350954406
[Epoch 2, Batch 3000] loss: 0.12149054602254182
[Epoch 2, Batch 3100] loss: 0.11041730312630534
[Epoch 2, Batch 3200] loss: 0.13455160774290562
[Epoch 2, Batch 3300] loss: 0.10650766170118003
[Epoch 2, Batch 3400] loss: 0.12987938322126866
[Epoch 2, Batch 3500] loss: 0.11123073689639568
[Epoch 2, Batch 3600] loss: 0.12968107795808465
[Epoch 2, Batch 3700] loss: 0.11766646657139063
**STATS for Epoch 2** : 
Average training loss: 0.0016
Average validation loss: 0.1031
Overfitting: 0.1015
Best model saved at epoch 2 with training loss: 0.0016
[Epoch 3, Batch 100] loss: 0.10832062237430364
[Epoch 3, Batch 200] loss: 0.1379465859476477
[Epoch 3, Batch 300] loss: 0.12234921384369954
[Epoch 3, Batch 400] loss: 0.11351552563719451
[Epoch 3, Batch 500] loss: 0.1036166552407667
[Epoch 3, Batch 600] loss: 0.10316198392305523
[Epoch 3, Batch 700] loss: 0.09987768039107323
[Epoch 3, Batch 800] loss: 0.12011666340986267
[Epoch 3, Batch 900] loss: 0.09630414999322966
[Epoch 3, Batch 1000] loss: 0.12187252157600596
[Epoch 3, Batch 1100] loss: 0.08314973681466654
[Epoch 3, Batch 1200] loss: 0.10250999009236693
[Epoch 3, Batch 1300] loss: 0.11287810495123267
[Epoch 3, Batch 1400] loss: 0.09818612369243056
[Epoch 3, Batch 1500] loss: 0.1395548596547451
[Epoch 3, Batch 1600] loss: 0.11447875209152698
[Epoch 3, Batch 1700] loss: 0.085391449641902
[Epoch 3, Batch 1800] loss: 0.11066871612099931
[Epoch 3, Batch 1900] loss: 0.0762040750333108
[Epoch 3, Batch 2000] loss: 0.1211349742487073
[Epoch 3, Batch 2100] loss: 0.10338829095941036
[Epoch 3, Batch 2200] loss: 0.08825945066288114
[Epoch 3, Batch 2300] loss: 0.08717786004766821
[Epoch 3, Batch 2400] loss: 0.08870422598905861
[Epoch 3, Batch 2500] loss: 0.11900342707056552
[Epoch 3, Batch 2600] loss: 0.10993465798674151
[Epoch 3, Batch 2700] loss: 0.07572807542979718
[Epoch 3, Batch 2800] loss: 0.08806378891749773
[Epoch 3, Batch 2900] loss: 0.09978024359443224
[Epoch 3, Batch 3000] loss: 0.0757844280730933
[Epoch 3, Batch 3100] loss: 0.07864649389870465
[Epoch 3, Batch 3200] loss: 0.10176068305387162
[Epoch 3, Batch 3300] loss: 0.07609344083350152
[Epoch 3, Batch 3400] loss: 0.10913277984596789
[Epoch 3, Batch 3500] loss: 0.07316120269242674
[Epoch 3, Batch 3600] loss: 0.09679578796494752
[Epoch 3, Batch 3700] loss: 0.07513435176340863
**STATS for Epoch 3** : 
Average training loss: 0.0011
Average validation loss: 0.0751
Overfitting: 0.0740
Best model saved at epoch 3 with training loss: 0.0011
[Epoch 4, Batch 100] loss: 0.07262898177606986
[Epoch 4, Batch 200] loss: 0.09400270640966482
[Epoch 4, Batch 300] loss: 0.06889945082366467
[Epoch 4, Batch 400] loss: 0.09773007736192085
[Epoch 4, Batch 500] loss: 0.0929338902386371
[Epoch 4, Batch 600] loss: 0.0833979913033545
[Epoch 4, Batch 700] loss: 0.09083500041277148
[Epoch 4, Batch 800] loss: 0.09667273283819668
[Epoch 4, Batch 900] loss: 0.09274541094084271
[Epoch 4, Batch 1000] loss: 0.07325842696242034
[Epoch 4, Batch 1100] loss: 0.07892712756176479
[Epoch 4, Batch 1200] loss: 0.086316115653608
[Epoch 4, Batch 1300] loss: 0.06879777925438248
[Epoch 4, Batch 1400] loss: 0.07011535576311871
[Epoch 4, Batch 1500] loss: 0.10354892796836794
[Epoch 4, Batch 1600] loss: 0.08380013952264562
[Epoch 4, Batch 1700] loss: 0.06096514654229395
[Epoch 4, Batch 1800] loss: 0.06979753901599907
[Epoch 4, Batch 1900] loss: 0.07424804941867479
[Epoch 4, Batch 2000] loss: 0.08424060762510635
[Epoch 4, Batch 2100] loss: 0.08720291269826702
[Epoch 4, Batch 2200] loss: 0.08535332748317159
[Epoch 4, Batch 2300] loss: 0.06202068910817616
[Epoch 4, Batch 2400] loss: 0.07129576000850647
[Epoch 4, Batch 2500] loss: 0.07557817648281344
[Epoch 4, Batch 2600] loss: 0.06653016151860357
[Epoch 4, Batch 2700] loss: 0.07677317280205898
[Epoch 4, Batch 2800] loss: 0.07598581117927097
[Epoch 4, Batch 2900] loss: 0.0624052218766883
[Epoch 4, Batch 3000] loss: 0.09429082452668808
[Epoch 4, Batch 3100] loss: 0.08259557429235428
[Epoch 4, Batch 3200] loss: 0.08589409237611108
[Epoch 4, Batch 3300] loss: 0.06514743605977856
[Epoch 4, Batch 3400] loss: 0.06953642306034453
[Epoch 4, Batch 3500] loss: 0.08712763787480071
[Epoch 4, Batch 3600] loss: 0.07576631120638921
[Epoch 4, Batch 3700] loss: 0.06751329542370513
**STATS for Epoch 4** : 
Average training loss: 0.0011
Average validation loss: 0.0662
Overfitting: 0.0651
[Epoch 5, Batch 100] loss: 0.06615692987921648
[Epoch 5, Batch 200] loss: 0.07437315472750924
[Epoch 5, Batch 300] loss: 0.09579411126673222
[Epoch 5, Batch 400] loss: 0.05451816623273771
[Epoch 5, Batch 500] loss: 0.06650075777200982
[Epoch 5, Batch 600] loss: 0.05587186032789759
[Epoch 5, Batch 700] loss: 0.07903312638460193
[Epoch 5, Batch 800] loss: 0.07301578094688012
[Epoch 5, Batch 900] loss: 0.06543951121391728
[Epoch 5, Batch 1000] loss: 0.060025620869128035
[Epoch 5, Batch 1100] loss: 0.053722177678137084
[Epoch 5, Batch 1200] loss: 0.09443630928406492
[Epoch 5, Batch 1300] loss: 0.06500447864760645
[Epoch 5, Batch 1400] loss: 0.05871533430414275
[Epoch 5, Batch 1500] loss: 0.06982503145060036
[Epoch 5, Batch 1600] loss: 0.06071192126197275
[Epoch 5, Batch 1700] loss: 0.06207839628477814
[Epoch 5, Batch 1800] loss: 0.07169520018040203
[Epoch 5, Batch 1900] loss: 0.055023220699513334
[Epoch 5, Batch 2000] loss: 0.053253100591246036
[Epoch 5, Batch 2100] loss: 0.08068993526976556
[Epoch 5, Batch 2200] loss: 0.07249845490732695
[Epoch 5, Batch 2300] loss: 0.07008806673577056
[Epoch 5, Batch 2400] loss: 0.07135955389821902
[Epoch 5, Batch 2500] loss: 0.062273130263201894
[Epoch 5, Batch 2600] loss: 0.09495893135084771
[Epoch 5, Batch 2700] loss: 0.06057137984898873
[Epoch 5, Batch 2800] loss: 0.07471720971167088
[Epoch 5, Batch 2900] loss: 0.060974094573175534
[Epoch 5, Batch 3000] loss: 0.058597551042912525
[Epoch 5, Batch 3100] loss: 0.05404891070327721
[Epoch 5, Batch 3200] loss: 0.05067603615287226
[Epoch 5, Batch 3300] loss: 0.06211214246985037
[Epoch 5, Batch 3400] loss: 0.0601956789358519
[Epoch 5, Batch 3500] loss: 0.08249701628054026
[Epoch 5, Batch 3600] loss: 0.06047849798342213
[Epoch 5, Batch 3700] loss: 0.07456811357056722
**STATS for Epoch 5** : 
Average training loss: 0.0008
Average validation loss: 0.0611
Overfitting: 0.0603
Best model saved at epoch 5 with training loss: 0.0008
[Epoch 6, Batch 100] loss: 0.06559518329042476
[Epoch 6, Batch 200] loss: 0.04311827567173168
[Epoch 6, Batch 300] loss: 0.06722847178811207
[Epoch 6, Batch 400] loss: 0.057249083764618264
[Epoch 6, Batch 500] loss: 0.070661083261366
[Epoch 6, Batch 600] loss: 0.0545254028151976
[Epoch 6, Batch 700] loss: 0.06649263256404084
[Epoch 6, Batch 800] loss: 0.07769722373923287
[Epoch 6, Batch 900] loss: 0.054361994552309625
[Epoch 6, Batch 1000] loss: 0.05622568530379794
[Epoch 6, Batch 1100] loss: 0.0606883023068076
[Epoch 6, Batch 1200] loss: 0.04774424165603705
[Epoch 6, Batch 1300] loss: 0.08661101907375268
[Epoch 6, Batch 1400] loss: 0.06819215632218402
[Epoch 6, Batch 1500] loss: 0.05232974108075723
[Epoch 6, Batch 1600] loss: 0.06307393775903619
[Epoch 6, Batch 1700] loss: 0.060134147253120315
[Epoch 6, Batch 1800] loss: 0.04506127867905889
[Epoch 6, Batch 1900] loss: 0.05808436330058612
[Epoch 6, Batch 2000] loss: 0.051172395291505385
[Epoch 6, Batch 2100] loss: 0.04610396989155561
[Epoch 6, Batch 2200] loss: 0.06962496527470648
[Epoch 6, Batch 2300] loss: 0.0686055480732466
[Epoch 6, Batch 2400] loss: 0.03633198857365642
[Epoch 6, Batch 2500] loss: 0.05056754741235636
[Epoch 6, Batch 2600] loss: 0.05960856898920611
[Epoch 6, Batch 2700] loss: 0.05344255131902173
[Epoch 6, Batch 2800] loss: 0.05594400594010949
[Epoch 6, Batch 2900] loss: 0.059439215738675555
[Epoch 6, Batch 3000] loss: 0.05814765857066959
[Epoch 6, Batch 3100] loss: 0.05975967372010928
[Epoch 6, Batch 3200] loss: 0.03074233505729353
[Epoch 6, Batch 3300] loss: 0.06402098676655442
[Epoch 6, Batch 3400] loss: 0.05988340016454458
[Epoch 6, Batch 3500] loss: 0.05967019894625992
[Epoch 6, Batch 3600] loss: 0.05704946603043936
[Epoch 6, Batch 3700] loss: 0.06489645670517348
**STATS for Epoch 6** : 
Average training loss: 0.0007
Average validation loss: 0.0467
Overfitting: 0.0460
Best model saved at epoch 6 with training loss: 0.0007
[Epoch 7, Batch 100] loss: 0.06942962161672767
[Epoch 7, Batch 200] loss: 0.0615872015414061
[Epoch 7, Batch 300] loss: 0.06233360762242228
[Epoch 7, Batch 400] loss: 0.05747783360013273
[Epoch 7, Batch 500] loss: 0.05917410189867951
[Epoch 7, Batch 600] loss: 0.06156985046400223
[Epoch 7, Batch 700] loss: 0.05795234150835313
[Epoch 7, Batch 800] loss: 0.05966215820342768
[Epoch 7, Batch 900] loss: 0.05831134837353602
[Epoch 7, Batch 1000] loss: 0.03803004594577942
[Epoch 7, Batch 1100] loss: 0.045919230524450544
[Epoch 7, Batch 1200] loss: 0.05878542197053321
[Epoch 7, Batch 1300] loss: 0.031781511229346505
[Epoch 7, Batch 1400] loss: 0.044010381368862
[Epoch 7, Batch 1500] loss: 0.05990050821157638
[Epoch 7, Batch 1600] loss: 0.050989556215936316
[Epoch 7, Batch 1700] loss: 0.0657149063545512
[Epoch 7, Batch 1800] loss: 0.04597922060871497
[Epoch 7, Batch 1900] loss: 0.04720327041461132
[Epoch 7, Batch 2000] loss: 0.056209887751901985
[Epoch 7, Batch 2100] loss: 0.04849118275218643
[Epoch 7, Batch 2200] loss: 0.04489699740312062
[Epoch 7, Batch 2300] loss: 0.04321658990200376
[Epoch 7, Batch 2400] loss: 0.04632596032053698
[Epoch 7, Batch 2500] loss: 0.05264471274742391
[Epoch 7, Batch 2600] loss: 0.045884172540390865
[Epoch 7, Batch 2700] loss: 0.059504778589471244
[Epoch 7, Batch 2800] loss: 0.03807054723205511
[Epoch 7, Batch 2900] loss: 0.03585608383626095
[Epoch 7, Batch 3000] loss: 0.049734382285678294
[Epoch 7, Batch 3100] loss: 0.05821496373682748
[Epoch 7, Batch 3200] loss: 0.05175238627474755
[Epoch 7, Batch 3300] loss: 0.055760627424460835
[Epoch 7, Batch 3400] loss: 0.0546722321206471
[Epoch 7, Batch 3500] loss: 0.042704444928676824
[Epoch 7, Batch 3600] loss: 0.04000987025356153
[Epoch 7, Batch 3700] loss: 0.057053156651381866
**STATS for Epoch 7** : 
Average training loss: 0.0006
Average validation loss: 0.0394
Overfitting: 0.0388
Best model saved at epoch 7 with training loss: 0.0006
[Epoch 8, Batch 100] loss: 0.06211550924504991
[Epoch 8, Batch 200] loss: 0.04916533515206538
[Epoch 8, Batch 300] loss: 0.04473447410389781
[Epoch 8, Batch 400] loss: 0.048524367471109144
[Epoch 8, Batch 500] loss: 0.05684469275467564
[Epoch 8, Batch 600] loss: 0.04432126089814119
[Epoch 8, Batch 700] loss: 0.043991049667238255
[Epoch 8, Batch 800] loss: 0.03584683906083228
[Epoch 8, Batch 900] loss: 0.04182841285597533
[Epoch 8, Batch 1000] loss: 0.027659710814768913
[Epoch 8, Batch 1100] loss: 0.0339882009869325
[Epoch 8, Batch 1200] loss: 0.04559292373829521
[Epoch 8, Batch 1300] loss: 0.047860557474778034
[Epoch 8, Batch 1400] loss: 0.04774762130255113
[Epoch 8, Batch 1500] loss: 0.04482369956152979
[Epoch 8, Batch 1600] loss: 0.04630495237128343
[Epoch 8, Batch 1700] loss: 0.033892955877672645
[Epoch 8, Batch 1800] loss: 0.04860563911206554
[Epoch 8, Batch 1900] loss: 0.047519694424408954
[Epoch 8, Batch 2000] loss: 0.05423865496646613
[Epoch 8, Batch 2100] loss: 0.0441850903671002
[Epoch 8, Batch 2200] loss: 0.055146546537871474
[Epoch 8, Batch 2300] loss: 0.045725524210138244
[Epoch 8, Batch 2400] loss: 0.04222864710900467
[Epoch 8, Batch 2500] loss: 0.045644109331187795
[Epoch 8, Batch 2600] loss: 0.04551278771774378
[Epoch 8, Batch 2700] loss: 0.06093853114405647
[Epoch 8, Batch 2800] loss: 0.047538314671255646
[Epoch 8, Batch 2900] loss: 0.04823218802455813
[Epoch 8, Batch 3000] loss: 0.04936494705383666
[Epoch 8, Batch 3100] loss: 0.05177713279088494
[Epoch 8, Batch 3200] loss: 0.035078149879409465
[Epoch 8, Batch 3300] loss: 0.04159815620369045
[Epoch 8, Batch 3400] loss: 0.043733737155853304
[Epoch 8, Batch 3500] loss: 0.0462200657610083
[Epoch 8, Batch 3600] loss: 0.0561483003720059
[Epoch 8, Batch 3700] loss: 0.052827594416448846
**STATS for Epoch 8** : 
Average training loss: 0.0006
Average validation loss: 0.0417
Overfitting: 0.0411
[Epoch 9, Batch 100] loss: 0.03201686097949277
[Epoch 9, Batch 200] loss: 0.029553815071994904
[Epoch 9, Batch 300] loss: 0.052543160120840184
[Epoch 9, Batch 400] loss: 0.05393001708376687
[Epoch 9, Batch 500] loss: 0.038622763596940786
[Epoch 9, Batch 600] loss: 0.03360307782691962
[Epoch 9, Batch 700] loss: 0.037707197909403474
[Epoch 9, Batch 800] loss: 0.053543384631047956
[Epoch 9, Batch 900] loss: 0.0390275746100815
[Epoch 9, Batch 1000] loss: 0.048990715929248835
[Epoch 9, Batch 1100] loss: 0.04064786784903845
[Epoch 9, Batch 1200] loss: 0.045999167671543544
[Epoch 9, Batch 1300] loss: 0.030054810119909233
[Epoch 9, Batch 1400] loss: 0.0331155360097182
[Epoch 9, Batch 1500] loss: 0.03650281461450504
[Epoch 9, Batch 1600] loss: 0.029571124103385957
[Epoch 9, Batch 1700] loss: 0.03601196272356901
[Epoch 9, Batch 1800] loss: 0.046279554511711465
[Epoch 9, Batch 1900] loss: 0.03821846297360025
[Epoch 9, Batch 2000] loss: 0.049887890457030154
[Epoch 9, Batch 2100] loss: 0.04422876788448775
[Epoch 9, Batch 2200] loss: 0.02975135875720298
[Epoch 9, Batch 2300] loss: 0.037903933161578605
[Epoch 9, Batch 2400] loss: 0.05389361244939209
[Epoch 9, Batch 2500] loss: 0.0431593984173378
[Epoch 9, Batch 2600] loss: 0.040140440156683325
[Epoch 9, Batch 2700] loss: 0.044162616124231134
[Epoch 9, Batch 2800] loss: 0.043396079157537314
[Epoch 9, Batch 2900] loss: 0.04482682117071818
[Epoch 9, Batch 3000] loss: 0.04216061124112457
[Epoch 9, Batch 3100] loss: 0.05764072788326303
[Epoch 9, Batch 3200] loss: 0.04990429286001017
[Epoch 9, Batch 3300] loss: 0.04243079411884537
[Epoch 9, Batch 3400] loss: 0.042143740686879025
[Epoch 9, Batch 3500] loss: 0.03045131903490983
[Epoch 9, Batch 3600] loss: 0.040341767154022816
[Epoch 9, Batch 3700] loss: 0.03825720924069174
**STATS for Epoch 9** : 
Average training loss: 0.0009
Average validation loss: 0.0444
Overfitting: 0.0435
[Epoch 10, Batch 100] loss: 0.05268354961182922
[Epoch 10, Batch 200] loss: 0.03403029520966811
[Epoch 10, Batch 300] loss: 0.034203192226123065
[Epoch 10, Batch 400] loss: 0.0329800238617463
[Epoch 10, Batch 500] loss: 0.04997743278596317
[Epoch 10, Batch 600] loss: 0.037017158740927696
[Epoch 10, Batch 700] loss: 0.050173416357356476
[Epoch 10, Batch 800] loss: 0.042986495639488566
[Epoch 10, Batch 900] loss: 0.018733443099772557
[Epoch 10, Batch 1000] loss: 0.03170035613613436
[Epoch 10, Batch 1100] loss: 0.03030359925556695
[Epoch 10, Batch 1200] loss: 0.03760815287096193
[Epoch 10, Batch 1300] loss: 0.04069125101377722
[Epoch 10, Batch 1400] loss: 0.04292931865202263
[Epoch 10, Batch 1500] loss: 0.04274239037200459
[Epoch 10, Batch 1600] loss: 0.032662469740898814
[Epoch 10, Batch 1700] loss: 0.043767835140315584
[Epoch 10, Batch 1800] loss: 0.028106723614328075
[Epoch 10, Batch 1900] loss: 0.029901935432062602
[Epoch 10, Batch 2000] loss: 0.03664448313706089
[Epoch 10, Batch 2100] loss: 0.03001555844210088
[Epoch 10, Batch 2200] loss: 0.04429086027579615
[Epoch 10, Batch 2300] loss: 0.04789400316789397
[Epoch 10, Batch 2400] loss: 0.04315373941324651
[Epoch 10, Batch 2500] loss: 0.02129059052982484
[Epoch 10, Batch 2600] loss: 0.04544475207192591
[Epoch 10, Batch 2700] loss: 0.03233776695749839
[Epoch 10, Batch 2800] loss: 0.03790714330214542
[Epoch 10, Batch 2900] loss: 0.03942450324364472
[Epoch 10, Batch 3000] loss: 0.04161462732590735
[Epoch 10, Batch 3100] loss: 0.032254848282900636
[Epoch 10, Batch 3200] loss: 0.05820111528009875
[Epoch 10, Batch 3300] loss: 0.04544725524028763
[Epoch 10, Batch 3400] loss: 0.02961003266071202
[Epoch 10, Batch 3500] loss: 0.034153625898616154
[Epoch 10, Batch 3600] loss: 0.029150481097458394
[Epoch 10, Batch 3700] loss: 0.029513008948706555
**STATS for Epoch 10** : 
Average training loss: 0.0003
Average validation loss: 0.0393
Overfitting: 0.0390
Best model saved at epoch 10 with training loss: 0.0003
[Epoch 11, Batch 100] loss: 0.035103369617718275
[Epoch 11, Batch 200] loss: 0.04403760089160642
[Epoch 11, Batch 300] loss: 0.026943029992689844
[Epoch 11, Batch 400] loss: 0.02494085655664094
[Epoch 11, Batch 500] loss: 0.035383523423224685
[Epoch 11, Batch 600] loss: 0.03368482915044296
[Epoch 11, Batch 700] loss: 0.0241579142716364
[Epoch 11, Batch 800] loss: 0.033472422747290696
[Epoch 11, Batch 900] loss: 0.026605425301095238
[Epoch 11, Batch 1000] loss: 0.04245776301075239
[Epoch 11, Batch 1100] loss: 0.040143060695554594
[Epoch 11, Batch 1200] loss: 0.04408560133771971
[Epoch 11, Batch 1300] loss: 0.021497185560001526
[Epoch 11, Batch 1400] loss: 0.03143400853616186
[Epoch 11, Batch 1500] loss: 0.047084203455015086
[Epoch 11, Batch 1600] loss: 0.030859985185816185
[Epoch 11, Batch 1700] loss: 0.03957706058587064
[Epoch 11, Batch 1800] loss: 0.024934620571148116
[Epoch 11, Batch 1900] loss: 0.04153512893099105
[Epoch 11, Batch 2000] loss: 0.058919496652379166
[Epoch 11, Batch 2100] loss: 0.02866023526643403
[Epoch 11, Batch 2200] loss: 0.03684810274236952
[Epoch 11, Batch 2300] loss: 0.03747449098271318
[Epoch 11, Batch 2400] loss: 0.0381521121104015
[Epoch 11, Batch 2500] loss: 0.041518540063116234
[Epoch 11, Batch 2600] loss: 0.03760198906558799
[Epoch 11, Batch 2700] loss: 0.028433280933531934
[Epoch 11, Batch 2800] loss: 0.037146439175703566
[Epoch 11, Batch 2900] loss: 0.04068683667399455
[Epoch 11, Batch 3000] loss: 0.029589790182217256
[Epoch 11, Batch 3100] loss: 0.03282918818527833
[Epoch 11, Batch 3200] loss: 0.026748704733181514
[Epoch 11, Batch 3300] loss: 0.03289179064595373
[Epoch 11, Batch 3400] loss: 0.04018607387290103
[Epoch 11, Batch 3500] loss: 0.0412124951131409
[Epoch 11, Batch 3600] loss: 0.05138020194077399
[Epoch 11, Batch 3700] loss: 0.033077537266945
**STATS for Epoch 11** : 
Average training loss: 0.0004
Average validation loss: 0.0401
Overfitting: 0.0397
[Epoch 12, Batch 100] loss: 0.02133611771336291
[Epoch 12, Batch 200] loss: 0.02614848502285895
[Epoch 12, Batch 300] loss: 0.017190803506673548
[Epoch 12, Batch 400] loss: 0.031256553642015204
[Epoch 12, Batch 500] loss: 0.025804158388345967
[Epoch 12, Batch 600] loss: 0.025659513558348408
[Epoch 12, Batch 700] loss: 0.03046427857996605
[Epoch 12, Batch 800] loss: 0.023419466062478023
[Epoch 12, Batch 900] loss: 0.027241367753522355
[Epoch 12, Batch 1000] loss: 0.02813669842798845
[Epoch 12, Batch 1100] loss: 0.031229546968825163
[Epoch 12, Batch 1200] loss: 0.025851420444305405
[Epoch 12, Batch 1300] loss: 0.04526689593330957
[Epoch 12, Batch 1400] loss: 0.04277005070223822
[Epoch 12, Batch 1500] loss: 0.026658158781938255
[Epoch 12, Batch 1600] loss: 0.033780478989647235
[Epoch 12, Batch 1700] loss: 0.02984224666404771
[Epoch 12, Batch 1800] loss: 0.04580006895615952
[Epoch 12, Batch 1900] loss: 0.026474176425763288
[Epoch 12, Batch 2000] loss: 0.04565070626878878
[Epoch 12, Batch 2100] loss: 0.027738338419949285
[Epoch 12, Batch 2200] loss: 0.03763940067830845
[Epoch 12, Batch 2300] loss: 0.0367361812730087
[Epoch 12, Batch 2400] loss: 0.03768574589805212
[Epoch 12, Batch 2500] loss: 0.040806466471549355
[Epoch 12, Batch 2600] loss: 0.02961555529400357
[Epoch 12, Batch 2700] loss: 0.03783710329273163
[Epoch 12, Batch 2800] loss: 0.04515149698811001
[Epoch 12, Batch 2900] loss: 0.039115181837696585
[Epoch 12, Batch 3000] loss: 0.024542515263601673
[Epoch 12, Batch 3100] loss: 0.02021253018610878
[Epoch 12, Batch 3200] loss: 0.03907859410886885
[Epoch 12, Batch 3300] loss: 0.034785465449967884
[Epoch 12, Batch 3400] loss: 0.030953105379085175
[Epoch 12, Batch 3500] loss: 0.03207734520765371
[Epoch 12, Batch 3600] loss: 0.03703083010055707
[Epoch 12, Batch 3700] loss: 0.026131951306015252
**STATS for Epoch 12** : 
Average training loss: 0.0004
Average validation loss: 0.0351
Overfitting: 0.0347
[Epoch 13, Batch 100] loss: 0.029972365733701736
[Epoch 13, Batch 200] loss: 0.04605971304496052
[Epoch 13, Batch 300] loss: 0.031743442497827346
[Epoch 13, Batch 400] loss: 0.026691610931884498
[Epoch 13, Batch 500] loss: 0.01815154241383425
[Epoch 13, Batch 600] loss: 0.0267623688319145
[Epoch 13, Batch 700] loss: 0.020753648995014373
[Epoch 13, Batch 800] loss: 0.021747686166127097
[Epoch 13, Batch 900] loss: 0.04059743512654677
[Epoch 13, Batch 1000] loss: 0.03538077474440797
[Epoch 13, Batch 1100] loss: 0.03827508087575552
[Epoch 13, Batch 1200] loss: 0.029031310839782234
[Epoch 13, Batch 1300] loss: 0.024551547427035983
[Epoch 13, Batch 1400] loss: 0.025197790173842806
[Epoch 13, Batch 1500] loss: 0.018529997889127115
[Epoch 13, Batch 1600] loss: 0.021965423612346057
[Epoch 13, Batch 1700] loss: 0.03202102773808292
[Epoch 13, Batch 1800] loss: 0.023193880069302394
[Epoch 13, Batch 1900] loss: 0.042962425296282164
[Epoch 13, Batch 2000] loss: 0.0350437163249444
[Epoch 13, Batch 2100] loss: 0.026708039419172564
[Epoch 13, Batch 2200] loss: 0.0354314026056818
[Epoch 13, Batch 2300] loss: 0.030166995853360277
[Epoch 13, Batch 2400] loss: 0.02118394277014886
[Epoch 13, Batch 2500] loss: 0.029773322816145083
[Epoch 13, Batch 2600] loss: 0.03637915476923809
[Epoch 13, Batch 2700] loss: 0.019604820085369283
[Epoch 13, Batch 2800] loss: 0.028864729965498555
[Epoch 13, Batch 2900] loss: 0.028098108131380285
[Epoch 13, Batch 3000] loss: 0.021424252561700996
[Epoch 13, Batch 3100] loss: 0.02009270828719309
[Epoch 13, Batch 3200] loss: 0.02729674808870186
[Epoch 13, Batch 3300] loss: 0.02800985338340979
[Epoch 13, Batch 3400] loss: 0.027706573004543315
[Epoch 13, Batch 3500] loss: 0.029378186212125002
[Epoch 13, Batch 3600] loss: 0.038181483007210776
[Epoch 13, Batch 3700] loss: 0.02666997903623269
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0366
Overfitting: 0.0358
[Epoch 14, Batch 100] loss: 0.029003853545364108
[Epoch 14, Batch 200] loss: 0.022761310310743285
[Epoch 14, Batch 300] loss: 0.018092248040629783
[Epoch 14, Batch 400] loss: 0.02980150003073504
[Epoch 14, Batch 500] loss: 0.017549641008881737
[Epoch 14, Batch 600] loss: 0.03397048681319575
[Epoch 14, Batch 700] loss: 0.032068608195259
[Epoch 14, Batch 800] loss: 0.01769620421466243
[Epoch 14, Batch 900] loss: 0.019097905738162807
[Epoch 14, Batch 1000] loss: 0.028280739304973393
[Epoch 14, Batch 1100] loss: 0.03147953635663726
[Epoch 14, Batch 1200] loss: 0.02617448533390416
[Epoch 14, Batch 1300] loss: 0.019775829569916824
[Epoch 14, Batch 1400] loss: 0.023107951853162376
[Epoch 14, Batch 1500] loss: 0.022915343530112296
[Epoch 14, Batch 1600] loss: 0.03057179449358955
[Epoch 14, Batch 1700] loss: 0.027833022350205284
[Epoch 14, Batch 1800] loss: 0.02073062426992692
[Epoch 14, Batch 1900] loss: 0.032818344043189424
[Epoch 14, Batch 2000] loss: 0.022824540869260092
[Epoch 14, Batch 2100] loss: 0.0321374063067924
[Epoch 14, Batch 2200] loss: 0.025531665608723414
[Epoch 14, Batch 2300] loss: 0.022876308771810728
[Epoch 14, Batch 2400] loss: 0.022739020738372348
[Epoch 14, Batch 2500] loss: 0.028228961279482975
[Epoch 14, Batch 2600] loss: 0.04779435007185384
[Epoch 14, Batch 2700] loss: 0.022256182555429403
[Epoch 14, Batch 2800] loss: 0.02617469467164483
[Epoch 14, Batch 2900] loss: 0.03196593307191506
[Epoch 14, Batch 3000] loss: 0.017416034742273042
[Epoch 14, Batch 3100] loss: 0.03074156308277452
[Epoch 14, Batch 3200] loss: 0.028109542845813847
[Epoch 14, Batch 3300] loss: 0.02710824144036451
[Epoch 14, Batch 3400] loss: 0.03696946270472836
[Epoch 14, Batch 3500] loss: 0.027014602994677263
[Epoch 14, Batch 3600] loss: 0.027954614929767557
[Epoch 14, Batch 3700] loss: 0.02564231931857648
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0348
Overfitting: 0.0343
[Epoch 15, Batch 100] loss: 0.021876912752268253
[Epoch 15, Batch 200] loss: 0.01865338265284663
[Epoch 15, Batch 300] loss: 0.019801650155932292
[Epoch 15, Batch 400] loss: 0.02561819494330848
[Epoch 15, Batch 500] loss: 0.02755545373307541
[Epoch 15, Batch 600] loss: 0.019301412731438178
[Epoch 15, Batch 700] loss: 0.018459113137469105
[Epoch 15, Batch 800] loss: 0.02190774868497101
[Epoch 15, Batch 900] loss: 0.023438843330077362
[Epoch 15, Batch 1000] loss: 0.019839963518097647
[Epoch 15, Batch 1100] loss: 0.02628090023754339
[Epoch 15, Batch 1200] loss: 0.029768569983134513
[Epoch 15, Batch 1300] loss: 0.027194040144313477
[Epoch 15, Batch 1400] loss: 0.017181723082030656
[Epoch 15, Batch 1500] loss: 0.013521463702891196
[Epoch 15, Batch 1600] loss: 0.018991426472348395
[Epoch 15, Batch 1700] loss: 0.019336904833398876
[Epoch 15, Batch 1800] loss: 0.03419242145886528
[Epoch 15, Batch 1900] loss: 0.031339878104190574
[Epoch 15, Batch 2000] loss: 0.029684398348654214
[Epoch 15, Batch 2100] loss: 0.026734778337267926
[Epoch 15, Batch 2200] loss: 0.022521548689555856
[Epoch 15, Batch 2300] loss: 0.035396274762242684
[Epoch 15, Batch 2400] loss: 0.033513946624298116
[Epoch 15, Batch 2500] loss: 0.02343479335948359
[Epoch 15, Batch 2600] loss: 0.024073654836029162
[Epoch 15, Batch 2700] loss: 0.019630580438897597
[Epoch 15, Batch 2800] loss: 0.023070305341825588
[Epoch 15, Batch 2900] loss: 0.0229165500671661
[Epoch 15, Batch 3000] loss: 0.03392677287993138
[Epoch 15, Batch 3100] loss: 0.020710915543531883
[Epoch 15, Batch 3200] loss: 0.03057545021871192
[Epoch 15, Batch 3300] loss: 0.02623823013440415
[Epoch 15, Batch 3400] loss: 0.04518872760141676
[Epoch 15, Batch 3500] loss: 0.02610854822807596
[Epoch 15, Batch 3600] loss: 0.031101647047580627
[Epoch 15, Batch 3700] loss: 0.03026288190623745
**STATS for Epoch 15** : 
Average training loss: 0.0003
Average validation loss: 0.0353
Overfitting: 0.0350
[Epoch 16, Batch 100] loss: 0.026347418619989186
[Epoch 16, Batch 200] loss: 0.023437457015133986
[Epoch 16, Batch 300] loss: 0.030743495086426265
[Epoch 16, Batch 400] loss: 0.019933308039107943
[Epoch 16, Batch 500] loss: 0.024454047499166336
[Epoch 16, Batch 600] loss: 0.03695118603489391
[Epoch 16, Batch 700] loss: 0.01207767559637432
[Epoch 16, Batch 800] loss: 0.022408122228007414
[Epoch 16, Batch 900] loss: 0.018794285062976996
[Epoch 16, Batch 1000] loss: 0.01573069662292255
[Epoch 16, Batch 1100] loss: 0.027208465042313036
[Epoch 16, Batch 1200] loss: 0.032140164059455856
[Epoch 16, Batch 1300] loss: 0.018782734065862314
[Epoch 16, Batch 1400] loss: 0.021165428739841445
[Epoch 16, Batch 1500] loss: 0.022359212321971425
[Epoch 16, Batch 1600] loss: 0.015696528266162205
[Epoch 16, Batch 1700] loss: 0.016306637980160302
[Epoch 16, Batch 1800] loss: 0.029647932050575036
[Epoch 16, Batch 1900] loss: 0.023441143930776887
[Epoch 16, Batch 2000] loss: 0.026057526512886398
[Epoch 16, Batch 2100] loss: 0.01773077126199496
[Epoch 16, Batch 2200] loss: 0.01529625352788571
[Epoch 16, Batch 2300] loss: 0.026413178311195225
[Epoch 16, Batch 2400] loss: 0.020919881058580357
[Epoch 16, Batch 2500] loss: 0.040941368648491336
[Epoch 16, Batch 2600] loss: 0.01566236513775948
[Epoch 16, Batch 2700] loss: 0.02967588788313151
[Epoch 16, Batch 2800] loss: 0.028206444914176246
[Epoch 16, Batch 2900] loss: 0.02255832802351506
[Epoch 16, Batch 3000] loss: 0.021723994481217233
[Epoch 16, Batch 3100] loss: 0.018932293633988594
[Epoch 16, Batch 3200] loss: 0.020744901762664084
[Epoch 16, Batch 3300] loss: 0.02259953369401046
[Epoch 16, Batch 3400] loss: 0.022732884537253993
[Epoch 16, Batch 3500] loss: 0.019620390806740034
[Epoch 16, Batch 3600] loss: 0.01930236070540559
[Epoch 16, Batch 3700] loss: 0.03086698229126341
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0324
Overfitting: 0.0321
[Epoch 17, Batch 100] loss: 0.01762335770908976
[Epoch 17, Batch 200] loss: 0.019217590951811872
[Epoch 17, Batch 300] loss: 0.011796562887684558
[Epoch 17, Batch 400] loss: 0.02008868797103787
[Epoch 17, Batch 500] loss: 0.027723900831661014
[Epoch 17, Batch 600] loss: 0.01751878397179098
[Epoch 17, Batch 700] loss: 0.016334994424432807
[Epoch 17, Batch 800] loss: 0.014202226325651282
[Epoch 17, Batch 900] loss: 0.01695189374026086
[Epoch 17, Batch 1000] loss: 0.01656720073227916
[Epoch 17, Batch 1100] loss: 0.028905872638133587
[Epoch 17, Batch 1200] loss: 0.01948958331508038
[Epoch 17, Batch 1300] loss: 0.028979239551081264
[Epoch 17, Batch 1400] loss: 0.011452475297101045
[Epoch 17, Batch 1500] loss: 0.02150511972431559
[Epoch 17, Batch 1600] loss: 0.011795725098054391
[Epoch 17, Batch 1700] loss: 0.018798858566697163
[Epoch 17, Batch 1800] loss: 0.015663722180543117
[Epoch 17, Batch 1900] loss: 0.02790003150475968
[Epoch 17, Batch 2000] loss: 0.01889329376645037
[Epoch 17, Batch 2100] loss: 0.01497635049305245
[Epoch 17, Batch 2200] loss: 0.01709177167409507
[Epoch 17, Batch 2300] loss: 0.024265618322751835
[Epoch 17, Batch 2400] loss: 0.02080331703680713
[Epoch 17, Batch 2500] loss: 0.02783503140159155
[Epoch 17, Batch 2600] loss: 0.016088243500653333
[Epoch 17, Batch 2700] loss: 0.03005521065355424
[Epoch 17, Batch 2800] loss: 0.024909895311648143
[Epoch 17, Batch 2900] loss: 0.0227997671632329
[Epoch 17, Batch 3000] loss: 0.025961614674379234
[Epoch 17, Batch 3100] loss: 0.039561765615289915
[Epoch 17, Batch 3200] loss: 0.01569642208996811
[Epoch 17, Batch 3300] loss: 0.01824152780820441
[Epoch 17, Batch 3400] loss: 0.024877835606166628
[Epoch 17, Batch 3500] loss: 0.022363642580112354
[Epoch 17, Batch 3600] loss: 0.03261620941171714
[Epoch 17, Batch 3700] loss: 0.02339726174966927
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0373
Overfitting: 0.0369
[Epoch 18, Batch 100] loss: 0.022240853679613794
[Epoch 18, Batch 200] loss: 0.012315383082459448
[Epoch 18, Batch 300] loss: 0.016504713950380393
[Epoch 18, Batch 400] loss: 0.026314449906349183
[Epoch 18, Batch 500] loss: 0.009151245646862663
[Epoch 18, Batch 600] loss: 0.025767821727858974
[Epoch 18, Batch 700] loss: 0.01763696028119739
[Epoch 18, Batch 800] loss: 0.019193074591894402
[Epoch 18, Batch 900] loss: 0.016399229920607467
[Epoch 18, Batch 1000] loss: 0.016556731030505034
[Epoch 18, Batch 1100] loss: 0.027865088912840293
[Epoch 18, Batch 1200] loss: 0.013071056391490856
[Epoch 18, Batch 1300] loss: 0.020014156655306578
[Epoch 18, Batch 1400] loss: 0.023973595535571803
[Epoch 18, Batch 1500] loss: 0.020345215767956688
[Epoch 18, Batch 1600] loss: 0.0243351765645275
[Epoch 18, Batch 1700] loss: 0.03045489371612348
[Epoch 18, Batch 1800] loss: 0.019304333246727767
[Epoch 18, Batch 1900] loss: 0.017464337077981326
[Epoch 18, Batch 2000] loss: 0.023493909999597235
[Epoch 18, Batch 2100] loss: 0.013818185032432666
[Epoch 18, Batch 2200] loss: 0.016111152248558937
[Epoch 18, Batch 2300] loss: 0.03313182199050061
[Epoch 18, Batch 2400] loss: 0.01492228663935748
[Epoch 18, Batch 2500] loss: 0.026587150277555337
[Epoch 18, Batch 2600] loss: 0.030102152778272284
[Epoch 18, Batch 2700] loss: 0.017668091170999104
[Epoch 18, Batch 2800] loss: 0.02995184982977662
[Epoch 18, Batch 2900] loss: 0.018049312740986354
[Epoch 18, Batch 3000] loss: 0.02590595376521378
[Epoch 18, Batch 3100] loss: 0.018360937609795656
[Epoch 18, Batch 3200] loss: 0.02378961733687902
[Epoch 18, Batch 3300] loss: 0.016696959930995944
[Epoch 18, Batch 3400] loss: 0.02319562852862873
[Epoch 18, Batch 3500] loss: 0.017271549318393226
[Epoch 18, Batch 3600] loss: 0.021241971754971018
[Epoch 18, Batch 3700] loss: 0.02353549065603147
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0305
Overfitting: 0.0304
Best model saved at epoch 18 with training loss: 0.0002
[Epoch 19, Batch 100] loss: 0.020806277179872268
[Epoch 19, Batch 200] loss: 0.013740344473953883
[Epoch 19, Batch 300] loss: 0.00997078700664133
[Epoch 19, Batch 400] loss: 0.01672812981509196
[Epoch 19, Batch 500] loss: 0.01649218739923526
[Epoch 19, Batch 600] loss: 0.015547516217447993
[Epoch 19, Batch 700] loss: 0.02296869652091118
[Epoch 19, Batch 800] loss: 0.01077500727136794
[Epoch 19, Batch 900] loss: 0.010134355732843688
[Epoch 19, Batch 1000] loss: 0.014386383092205506
[Epoch 19, Batch 1100] loss: 0.024074919911472533
[Epoch 19, Batch 1200] loss: 0.011064939977732138
[Epoch 19, Batch 1300] loss: 0.019928154976696533
[Epoch 19, Batch 1400] loss: 0.024158877893823955
[Epoch 19, Batch 1500] loss: 0.024488771648102557
[Epoch 19, Batch 1600] loss: 0.02065758109867602
[Epoch 19, Batch 1700] loss: 0.015653065610677003
[Epoch 19, Batch 1800] loss: 0.017086912325466982
[Epoch 19, Batch 1900] loss: 0.011959374279467739
[Epoch 19, Batch 2000] loss: 0.014374723348846602
[Epoch 19, Batch 2100] loss: 0.017018487602235836
[Epoch 19, Batch 2200] loss: 0.019674981416483207
[Epoch 19, Batch 2300] loss: 0.010892731272397213
[Epoch 19, Batch 2400] loss: 0.027048760317884443
[Epoch 19, Batch 2500] loss: 0.02361518794466974
[Epoch 19, Batch 2600] loss: 0.027733868003579118
[Epoch 19, Batch 2700] loss: 0.030027141246282554
[Epoch 19, Batch 2800] loss: 0.011307801696966635
[Epoch 19, Batch 2900] loss: 0.014465191265699104
[Epoch 19, Batch 3000] loss: 0.024444001098854643
[Epoch 19, Batch 3100] loss: 0.02539573998674314
[Epoch 19, Batch 3200] loss: 0.020819076073094037
[Epoch 19, Batch 3300] loss: 0.020732412856232257
[Epoch 19, Batch 3400] loss: 0.014010103592008818
[Epoch 19, Batch 3500] loss: 0.014194192444847431
[Epoch 19, Batch 3600] loss: 0.019877962963691972
[Epoch 19, Batch 3700] loss: 0.02797208915992087
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0315
Overfitting: 0.0312
[Epoch 20, Batch 100] loss: 0.007872165671506082
[Epoch 20, Batch 200] loss: 0.010566086140843254
[Epoch 20, Batch 300] loss: 0.014535897265268431
[Epoch 20, Batch 400] loss: 0.016687127667719324
[Epoch 20, Batch 500] loss: 0.022329527105921444
[Epoch 20, Batch 600] loss: 0.02312283949890116
[Epoch 20, Batch 700] loss: 0.023042058791397722
[Epoch 20, Batch 800] loss: 0.013371576208046463
[Epoch 20, Batch 900] loss: 0.019865010025932862
[Epoch 20, Batch 1000] loss: 0.019387393068718665
[Epoch 20, Batch 1100] loss: 0.01738713996590377
[Epoch 20, Batch 1200] loss: 0.01359781912424296
[Epoch 20, Batch 1300] loss: 0.015127629015660204
[Epoch 20, Batch 1400] loss: 0.012177684086018416
[Epoch 20, Batch 1500] loss: 0.015315292413761198
[Epoch 20, Batch 1600] loss: 0.021456185440983974
[Epoch 20, Batch 1700] loss: 0.029709396007092437
[Epoch 20, Batch 1800] loss: 0.016229529163247207
[Epoch 20, Batch 1900] loss: 0.01639624374132836
[Epoch 20, Batch 2000] loss: 0.00891306591229295
[Epoch 20, Batch 2100] loss: 0.013436990342379431
[Epoch 20, Batch 2200] loss: 0.015064053539681481
[Epoch 20, Batch 2300] loss: 0.025165255364699986
[Epoch 20, Batch 2400] loss: 0.02235930361401188
[Epoch 20, Batch 2500] loss: 0.018200856973708143
[Epoch 20, Batch 2600] loss: 0.013313923912337487
[Epoch 20, Batch 2700] loss: 0.023798444463100168
[Epoch 20, Batch 2800] loss: 0.021293295230498187
[Epoch 20, Batch 2900] loss: 0.010548678049708542
[Epoch 20, Batch 3000] loss: 0.014714697363015148
[Epoch 20, Batch 3100] loss: 0.028372694935678736
[Epoch 20, Batch 3200] loss: 0.019853406733091106
[Epoch 20, Batch 3300] loss: 0.017864481710639667
[Epoch 20, Batch 3400] loss: 0.014533847770289867
[Epoch 20, Batch 3500] loss: 0.016243986004028557
[Epoch 20, Batch 3600] loss: 0.02003489949162031
[Epoch 20, Batch 3700] loss: 0.010293500025691174
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0305
Overfitting: 0.0302
[Epoch 21, Batch 100] loss: 0.011092629321319691
[Epoch 21, Batch 200] loss: 0.011598300463156193
[Epoch 21, Batch 300] loss: 0.01599756108254951
[Epoch 21, Batch 400] loss: 0.013549000667353539
[Epoch 21, Batch 500] loss: 0.013593910594445334
[Epoch 21, Batch 600] loss: 0.014160455850942525
[Epoch 21, Batch 700] loss: 0.017048274717326423
[Epoch 21, Batch 800] loss: 0.01604627662135499
[Epoch 21, Batch 900] loss: 0.01417748172818392
[Epoch 21, Batch 1000] loss: 0.0204815171042992
[Epoch 21, Batch 1100] loss: 0.016625089400113213
[Epoch 21, Batch 1200] loss: 0.014991891303707235
[Epoch 21, Batch 1300] loss: 0.006908247924902753
[Epoch 21, Batch 1400] loss: 0.009869778762913483
[Epoch 21, Batch 1500] loss: 0.009282164456326427
[Epoch 21, Batch 1600] loss: 0.018222055613987324
[Epoch 21, Batch 1700] loss: 0.017052298963662907
[Epoch 21, Batch 1800] loss: 0.04434103739386046
[Epoch 21, Batch 1900] loss: 0.024819226131949108
[Epoch 21, Batch 2000] loss: 0.022681646771379748
[Epoch 21, Batch 2100] loss: 0.016787925450444163
[Epoch 21, Batch 2200] loss: 0.01362948184741981
[Epoch 21, Batch 2300] loss: 0.02062952687158031
[Epoch 21, Batch 2400] loss: 0.013720185944512195
[Epoch 21, Batch 2500] loss: 0.027645326897363702
[Epoch 21, Batch 2600] loss: 0.01864847746968735
[Epoch 21, Batch 2700] loss: 0.009834406601912633
[Epoch 21, Batch 2800] loss: 0.013288529944566108
[Epoch 21, Batch 2900] loss: 0.012919036226303433
[Epoch 21, Batch 3000] loss: 0.01446542883750226
[Epoch 21, Batch 3100] loss: 0.017305992765577684
[Epoch 21, Batch 3200] loss: 0.01844328413135372
[Epoch 21, Batch 3300] loss: 0.021856990063024568
[Epoch 21, Batch 3400] loss: 0.010855176155982917
[Epoch 21, Batch 3500] loss: 0.009084892718256014
[Epoch 21, Batch 3600] loss: 0.0196185341751152
[Epoch 21, Batch 3700] loss: 0.014478599898029642
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0322
Overfitting: 0.0319
[Epoch 22, Batch 100] loss: 0.008223302925671305
[Epoch 22, Batch 200] loss: 0.017272406052470615
[Epoch 22, Batch 300] loss: 0.019381621823995374
[Epoch 22, Batch 400] loss: 0.007480686030357901
[Epoch 22, Batch 500] loss: 0.011776459031498234
[Epoch 22, Batch 600] loss: 0.015918771413926152
[Epoch 22, Batch 700] loss: 0.009148312363759032
[Epoch 22, Batch 800] loss: 0.008779278271758813
[Epoch 22, Batch 900] loss: 0.02862613167084419
[Epoch 22, Batch 1000] loss: 0.011485893975477666
[Epoch 22, Batch 1100] loss: 0.014775160882400086
[Epoch 22, Batch 1200] loss: 0.01924816569113318
[Epoch 22, Batch 1300] loss: 0.00923443736029185
[Epoch 22, Batch 1400] loss: 0.0156450473995028
[Epoch 22, Batch 1500] loss: 0.016409757955989333
[Epoch 22, Batch 1600] loss: 0.02126460854693505
[Epoch 22, Batch 1700] loss: 0.01702546086635266
[Epoch 22, Batch 1800] loss: 0.011128698774564327
[Epoch 22, Batch 1900] loss: 0.017932024600568183
[Epoch 22, Batch 2000] loss: 0.00894479600019622
[Epoch 22, Batch 2100] loss: 0.016863649904589693
[Epoch 22, Batch 2200] loss: 0.009442037966709903
[Epoch 22, Batch 2300] loss: 0.011749398521624243
[Epoch 22, Batch 2400] loss: 0.020160353776136616
[Epoch 22, Batch 2500] loss: 0.017114593338937993
[Epoch 22, Batch 2600] loss: 0.007710100967187827
[Epoch 22, Batch 2700] loss: 0.017287514977624596
[Epoch 22, Batch 2800] loss: 0.021993609219844074
[Epoch 22, Batch 2900] loss: 0.011441883592324302
[Epoch 22, Batch 3000] loss: 0.020548866503513636
[Epoch 22, Batch 3100] loss: 0.02677390795426618
[Epoch 22, Batch 3200] loss: 0.016065692137799487
[Epoch 22, Batch 3300] loss: 0.0202184725623556
[Epoch 22, Batch 3400] loss: 0.012732789616493392
[Epoch 22, Batch 3500] loss: 0.01336227445211989
[Epoch 22, Batch 3600] loss: 0.014222063968281873
[Epoch 22, Batch 3700] loss: 0.021525794593908357
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0297
Overfitting: 0.0295
[Epoch 23, Batch 100] loss: 0.011587493984043249
[Epoch 23, Batch 200] loss: 0.011517581284097104
[Epoch 23, Batch 300] loss: 0.011950887816747127
[Epoch 23, Batch 400] loss: 0.011349048899228364
[Epoch 23, Batch 500] loss: 0.013898194071880426
[Epoch 23, Batch 600] loss: 0.01881607801296923
[Epoch 23, Batch 700] loss: 0.018623981625605666
[Epoch 23, Batch 800] loss: 0.013472009458400862
[Epoch 23, Batch 900] loss: 0.005469433822727296
[Epoch 23, Batch 1000] loss: 0.013032026743421738
[Epoch 23, Batch 1100] loss: 0.013582165184543556
[Epoch 23, Batch 1200] loss: 0.014427883009936977
[Epoch 23, Batch 1300] loss: 0.010005503640641109
[Epoch 23, Batch 1400] loss: 0.01641309061211359
[Epoch 23, Batch 1500] loss: 0.014768981642837388
[Epoch 23, Batch 1600] loss: 0.00975175678616324
[Epoch 23, Batch 1700] loss: 0.018967039982817367
[Epoch 23, Batch 1800] loss: 0.01149887381073313
[Epoch 23, Batch 1900] loss: 0.014408485942167317
[Epoch 23, Batch 2000] loss: 0.007819903955678456
[Epoch 23, Batch 2100] loss: 0.02598571263287795
[Epoch 23, Batch 2200] loss: 0.01874683910341446
[Epoch 23, Batch 2300] loss: 0.011218022328666848
[Epoch 23, Batch 2400] loss: 0.013492500215252222
[Epoch 23, Batch 2500] loss: 0.007744865827335161
[Epoch 23, Batch 2600] loss: 0.010535741717303608
[Epoch 23, Batch 2700] loss: 0.018789755841344232
[Epoch 23, Batch 2800] loss: 0.013605402731445792
[Epoch 23, Batch 2900] loss: 0.015865682819458014
[Epoch 23, Batch 3000] loss: 0.013252307127622771
[Epoch 23, Batch 3100] loss: 0.011541814932547823
[Epoch 23, Batch 3200] loss: 0.025080223608110828
[Epoch 23, Batch 3300] loss: 0.010603275097846563
[Epoch 23, Batch 3400] loss: 0.012014142553971397
[Epoch 23, Batch 3500] loss: 0.009659415469432133
[Epoch 23, Batch 3600] loss: 0.01540647468274983
[Epoch 23, Batch 3700] loss: 0.022838418850569725
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0306
Overfitting: 0.0304
[Epoch 24, Batch 100] loss: 0.006380175097292522
[Epoch 24, Batch 200] loss: 0.0069145933249637895
[Epoch 24, Batch 300] loss: 0.01774986702766455
[Epoch 24, Batch 400] loss: 0.006202137855216279
[Epoch 24, Batch 500] loss: 0.0077361313097935635
[Epoch 24, Batch 600] loss: 0.01592237953493168
[Epoch 24, Batch 700] loss: 0.004584510147988112
[Epoch 24, Batch 800] loss: 0.006795970122780091
[Epoch 24, Batch 900] loss: 0.01619775052334262
[Epoch 24, Batch 1000] loss: 0.00886675640152589
[Epoch 24, Batch 1100] loss: 0.011527644480574964
[Epoch 24, Batch 1200] loss: 0.022550790651418993
[Epoch 24, Batch 1300] loss: 0.01327416197428647
[Epoch 24, Batch 1400] loss: 0.012958942189504797
[Epoch 24, Batch 1500] loss: 0.013931165855556173
[Epoch 24, Batch 1600] loss: 0.016467303485760566
[Epoch 24, Batch 1700] loss: 0.013824357004850754
[Epoch 24, Batch 1800] loss: 0.015160065261588897
[Epoch 24, Batch 1900] loss: 0.020113362377596786
[Epoch 24, Batch 2000] loss: 0.012501257355270355
[Epoch 24, Batch 2100] loss: 0.013392398824007614
[Epoch 24, Batch 2200] loss: 0.012624761316765216
[Epoch 24, Batch 2300] loss: 0.010384050950888195
[Epoch 24, Batch 2400] loss: 0.022083876790584326
[Epoch 24, Batch 2500] loss: 0.010798065572162159
[Epoch 24, Batch 2600] loss: 0.011453031127011855
[Epoch 24, Batch 2700] loss: 0.012368124432714466
[Epoch 24, Batch 2800] loss: 0.014757485059294594
[Epoch 24, Batch 2900] loss: 0.015389235351176467
[Epoch 24, Batch 3000] loss: 0.014130767849333098
[Epoch 24, Batch 3100] loss: 0.018449709654978507
[Epoch 24, Batch 3200] loss: 0.006517668114095159
[Epoch 24, Batch 3300] loss: 0.00857669681248808
[Epoch 24, Batch 3400] loss: 0.019854349422439556
[Epoch 24, Batch 3500] loss: 0.015172247525806598
[Epoch 24, Batch 3600] loss: 0.007353103143686895
[Epoch 24, Batch 3700] loss: 0.012366245549455925
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0328
Overfitting: 0.0326
qt.qpa.xcb: X server does not support XInput 2
+++FINAL STATS++++
Training Loss 0.00017900918087398167
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Test set to find Test loss for overfitting
 Testing loss : 0.0328
Calculated Overfitting : 0.0326
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9887
Total time taken for hyperparameter tuning and evaluation: 5:7:44
/home/ahussain/PycharmProjects/optunaNew/Median_pruner_Testing.py:493: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.


Process finished with exit code 0

