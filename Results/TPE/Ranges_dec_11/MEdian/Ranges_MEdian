, Batch 2500] loss: 0.00033933846512155695
[Epoch 23, Batch 2600] loss: 0.0001810350625830859
[Epoch 23, Batch 2700] loss: 0.0010123404535803094
[Epoch 23, Batch 2800] loss: 0.0004857068214529203
[Epoch 23, Batch 2900] loss: 0.0005441831621893023
[Epoch 23, Batch 3000] loss: 0.00039703854254561575
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9902
Overfitting: 0.0529
[Epoch 24, Batch 100] loss: 0.00026481908802327147
[Epoch 24, Batch 200] loss: 0.0005794532621276849
[Epoch 24, Batch 300] loss: 0.0003525330838259144
[Epoch 24, Batch 400] loss: 0.00017511109329044317
[Epoch 24, Batch 500] loss: 0.0002854746973590139
[Epoch 24, Batch 600] loss: 0.0003132028654131735
[Epoch 24, Batch 700] loss: 0.0006840500550788775
[Epoch 24, Batch 800] loss: 0.00035641758377177976
[Epoch 24, Batch 900] loss: 9.183245473769918e-05
[Epoch 24, Batch 1000] loss: 0.00034359801941361565
[Epoch 24, Batch 1100] loss: 0.00011102701851029462
[Epoch 24, Batch 1200] loss: 0.0002323873964964429
[Epoch 24, Batch 1300] loss: 0.0001010816535398229
[Epoch 24, Batch 1400] loss: 0.00010320107015016954
[Epoch 24, Batch 1500] loss: 0.00018481262274208098
[Epoch 24, Batch 1600] loss: 0.00013573291348135898
[Epoch 24, Batch 1700] loss: 0.00018205333783119393
[Epoch 24, Batch 1800] loss: 6.63080936875593e-05
[Epoch 24, Batch 1900] loss: 0.00014180935720529143
[Epoch 24, Batch 2000] loss: 0.0002790631306068825
[Epoch 24, Batch 2100] loss: 0.00010632897960012322
[Epoch 24, Batch 2200] loss: 0.00025445817551264846
[Epoch 24, Batch 2300] loss: 0.0003437404610609196
[Epoch 24, Batch 2400] loss: 8.287477752473293e-05
[Epoch 24, Batch 2500] loss: 0.00016728706169138796
[Epoch 24, Batch 2600] loss: 0.00010064479166440598
[Epoch 24, Batch 2700] loss: 0.0006753607057322908
[Epoch 24, Batch 2800] loss: 0.00013628712856236902
[Epoch 24, Batch 2900] loss: 8.343972945128453e-05
[Epoch 24, Batch 3000] loss: 7.877408765174288e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9909
Overfitting: 0.0531
Fold 1 validation loss: 0.0531
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2927197194099427
[Epoch 1, Batch 200] loss: 2.1395469307899475
[Epoch 1, Batch 300] loss: 1.0177997440099715
[Epoch 1, Batch 400] loss: 0.513163378983736
[Epoch 1, Batch 500] loss: 0.34300812423229216
[Epoch 1, Batch 600] loss: 0.27015633216127755
[Epoch 1, Batch 700] loss: 0.2332127090357244
[Epoch 1, Batch 800] loss: 0.22047025713138282
[Epoch 1, Batch 900] loss: 0.1967107493709773
[Epoch 1, Batch 1000] loss: 0.195956439524889
[Epoch 1, Batch 1100] loss: 0.19010001034475862
[Epoch 1, Batch 1200] loss: 0.17424903905019165
[Epoch 1, Batch 1300] loss: 0.15137501233257353
[Epoch 1, Batch 1400] loss: 0.10405212016077713
[Epoch 1, Batch 1500] loss: 0.14590366016956977
[Epoch 1, Batch 1600] loss: 0.1058626354765147
[Epoch 1, Batch 1700] loss: 0.1293264030723367
[Epoch 1, Batch 1800] loss: 0.11042189372936263
[Epoch 1, Batch 1900] loss: 0.09700863643316553
[Epoch 1, Batch 2000] loss: 0.10088944047456608
[Epoch 1, Batch 2100] loss: 0.10767592213116586
[Epoch 1, Batch 2200] loss: 0.12209465264109895
[Epoch 1, Batch 2300] loss: 0.10865094186272473
[Epoch 1, Batch 2400] loss: 0.09401025335770101
[Epoch 1, Batch 2500] loss: 0.10003271605819464
[Epoch 1, Batch 2600] loss: 0.08066833418328315
[Epoch 1, Batch 2700] loss: 0.08099451959016733
[Epoch 1, Batch 2800] loss: 0.10486248094355688
[Epoch 1, Batch 2900] loss: 0.07451134607719723
[Epoch 1, Batch 3000] loss: 0.06461149203474634
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1013
Validation Accuracy: 0.9683
Overfitting: 0.1013
Best model saved at epoch 1 with validation loss: 0.1013
[Epoch 2, Batch 100] loss: 0.07937733689555898
[Epoch 2, Batch 200] loss: 0.0754692512069596
[Epoch 2, Batch 300] loss: 0.07984323122596834
[Epoch 2, Batch 400] loss: 0.0720041357073933
[Epoch 2, Batch 500] loss: 0.06106201766524464
[Epoch 2, Batch 600] loss: 0.044772242059698326
[Epoch 2, Batch 700] loss: 0.06518504798528739
[Epoch 2, Batch 800] loss: 0.09035612625419162
[Epoch 2, Batch 900] loss: 0.07835530777112582
[Epoch 2, Batch 1000] loss: 0.0612083568633534
[Epoch 2, Batch 1100] loss: 0.06812079406983684
[Epoch 2, Batch 1200] loss: 0.05844535686832387
[Epoch 2, Batch 1300] loss: 0.055596514554927125
[Epoch 2, Batch 1400] loss: 0.07895303723053075
[Epoch 2, Batch 1500] loss: 0.06418313976959325
[Epoch 2, Batch 1600] loss: 0.05951881914283149
[Epoch 2, Batch 1700] loss: 0.05502354488446144
[Epoch 2, Batch 1800] loss: 0.057254146363120526
[Epoch 2, Batch 1900] loss: 0.06935906637198058
[Epoch 2, Batch 2000] loss: 0.04991779653879348
[Epoch 2, Batch 2100] loss: 0.049402774874470194
[Epoch 2, Batch 2200] loss: 0.09769311833602842
[Epoch 2, Batch 2300] loss: 0.07448825653526
[Epoch 2, Batch 2400] loss: 0.0489466576121049
[Epoch 2, Batch 2500] loss: 0.07484381481306628
[Epoch 2, Batch 2600] loss: 0.04133349180308869
[Epoch 2, Batch 2700] loss: 0.05914532863360364
[Epoch 2, Batch 2800] loss: 0.061520958052715284
[Epoch 2, Batch 2900] loss: 0.053813484137644994
[Epoch 2, Batch 3000] loss: 0.07352083829580806
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0671
Validation Accuracy: 0.9792
Overfitting: 0.0671
Best model saved at epoch 2 with validation loss: 0.0671
[Epoch 3, Batch 100] loss: 0.04636056201416068
[Epoch 3, Batch 200] loss: 0.05964458823174937
[Epoch 3, Batch 300] loss: 0.0431216053920798
[Epoch 3, Batch 400] loss: 0.06302205070620402
[Epoch 3, Batch 500] loss: 0.04082832971194875
[Epoch 3, Batch 600] loss: 0.0405586374962877
[Epoch 3, Batch 700] loss: 0.04917355206125649
[Epoch 3, Batch 800] loss: 0.04441431730578188
[Epoch 3, Batch 900] loss: 0.060178618380741684
[Epoch 3, Batch 1000] loss: 0.03252800627116812
[Epoch 3, Batch 1100] loss: 0.04685279412340606
[Epoch 3, Batch 1200] loss: 0.04934261805319693
[Epoch 3, Batch 1300] loss: 0.03473729740668205
[Epoch 3, Batch 1400] loss: 0.04528853453753982
[Epoch 3, Batch 1500] loss: 0.04025190376734827
[Epoch 3, Batch 1600] loss: 0.039077154534898
[Epoch 3, Batch 1700] loss: 0.04677721545493114
[Epoch 3, Batch 1800] loss: 0.04245944487091038
[Epoch 3, Batch 1900] loss: 0.04104420435396605
[Epoch 3, Batch 2000] loss: 0.05403443829374737
[Epoch 3, Batch 2100] loss: 0.03806766651978251
[Epoch 3, Batch 2200] loss: 0.03738445033566677
[Epoch 3, Batch 2300] loss: 0.04114545249627554
[Epoch 3, Batch 2400] loss: 0.04208876600721851
[Epoch 3, Batch 2500] loss: 0.06899661188421305
[Epoch 3, Batch 2600] loss: 0.041606719048868396
[Epoch 3, Batch 2700] loss: 0.04245273058739258
[Epoch 3, Batch 2800] loss: 0.03136775013321312
[Epoch 3, Batch 2900] loss: 0.03230906346434494
[Epoch 3, Batch 3000] loss: 0.04693105316080619
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0627
Validation Accuracy: 0.9812
Overfitting: 0.0627
Best model saved at epoch 3 with validation loss: 0.0627
[Epoch 4, Batch 100] loss: 0.04679557470808504
[Epoch 4, Batch 200] loss: 0.043611821907834386
[Epoch 4, Batch 300] loss: 0.02847500608957489
[Epoch 4, Batch 400] loss: 0.026806177588114224
[Epoch 4, Batch 500] loss: 0.020622451954259303
[Epoch 4, Batch 600] loss: 0.03992470643363049
[Epoch 4, Batch 700] loss: 0.020264578426722437
[Epoch 4, Batch 800] loss: 0.033918207467395406
[Epoch 4, Batch 900] loss: 0.03250153977616719
[Epoch 4, Batch 1000] loss: 0.03471943362193997
[Epoch 4, Batch 1100] loss: 0.02234908018115675
[Epoch 4, Batch 1200] loss: 0.026966185059427515
[Epoch 4, Batch 1300] loss: 0.034015816530118176
[Epoch 4, Batch 1400] loss: 0.04979028800065862
[Epoch 4, Batch 1500] loss: 0.04309892752116866
[Epoch 4, Batch 1600] loss: 0.037184171116241484
[Epoch 4, Batch 1700] loss: 0.0393209050106816
[Epoch 4, Batch 1800] loss: 0.03720008657655853
[Epoch 4, Batch 1900] loss: 0.02591969228524249
[Epoch 4, Batch 2000] loss: 0.0300891856297676
[Epoch 4, Batch 2100] loss: 0.029944817849027458
[Epoch 4, Batch 2200] loss: 0.03696422038072342
[Epoch 4, Batch 2300] loss: 0.025724068260460628
[Epoch 4, Batch 2400] loss: 0.0256718548291974
[Epoch 4, Batch 2500] loss: 0.02888574606691691
[Epoch 4, Batch 2600] loss: 0.04208861941267969
[Epoch 4, Batch 2700] loss: 0.028628824515035376
[Epoch 4, Batch 2800] loss: 0.028726858793452267
[Epoch 4, Batch 2900] loss: 0.039583145611104556
[Epoch 4, Batch 3000] loss: 0.04035441883846943
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9847
Overfitting: 0.0525
Best model saved at epoch 4 with validation loss: 0.0525
[Epoch 5, Batch 100] loss: 0.02000707834507921
[Epoch 5, Batch 200] loss: 0.019088615675573236
[Epoch 5, Batch 300] loss: 0.017299037104712624
[Epoch 5, Batch 400] loss: 0.02751575814181706
[Epoch 5, Batch 500] loss: 0.03701292961326544
[Epoch 5, Batch 600] loss: 0.022173850814870093
[Epoch 5, Batch 700] loss: 0.019031177660781395
[Epoch 5, Batch 800] loss: 0.04028209897969646
[Epoch 5, Batch 900] loss: 0.025821151495838423
[Epoch 5, Batch 1000] loss: 0.02608707722825784
[Epoch 5, Batch 1100] loss: 0.02775198892253684
[Epoch 5, Batch 1200] loss: 0.034122875164975995
[Epoch 5, Batch 1300] loss: 0.024935278202065092
[Epoch 5, Batch 1400] loss: 0.036358737213577116
[Epoch 5, Batch 1500] loss: 0.024782418850809337
[Epoch 5, Batch 1600] loss: 0.03235080842714524
[Epoch 5, Batch 1700] loss: 0.02449690722845844
[Epoch 5, Batch 1800] loss: 0.026995434790296712
[Epoch 5, Batch 1900] loss: 0.029449128338019364
[Epoch 5, Batch 2000] loss: 0.02455718354343844
[Epoch 5, Batch 2100] loss: 0.022702789785153072
[Epoch 5, Batch 2200] loss: 0.023525464872773228
[Epoch 5, Batch 2300] loss: 0.03550908561737742
[Epoch 5, Batch 2400] loss: 0.04439494908416236
[Epoch 5, Batch 2500] loss: 0.0352084153026226
[Epoch 5, Batch 2600] loss: 0.02823945364463725
[Epoch 5, Batch 2700] loss: 0.023840645870222943
[Epoch 5, Batch 2800] loss: 0.03341694819174336
[Epoch 5, Batch 2900] loss: 0.02190472984679218
[Epoch 5, Batch 3000] loss: 0.028078488277606083
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9844
Overfitting: 0.0527
[Epoch 6, Batch 100] loss: 0.013476821224248852
[Epoch 6, Batch 200] loss: 0.013496572758740513
[Epoch 6, Batch 300] loss: 0.01771473152864928
[Epoch 6, Batch 400] loss: 0.01652905583402571
[Epoch 6, Batch 500] loss: 0.02105133943447072
[Epoch 6, Batch 600] loss: 0.02439967432190315
[Epoch 6, Batch 700] loss: 0.01867572063794796
[Epoch 6, Batch 800] loss: 0.03638846540242412
[Epoch 6, Batch 900] loss: 0.023669980360136834
[Epoch 6, Batch 1000] loss: 0.023643683949994738
[Epoch 6, Batch 1100] loss: 0.01774195819896704
[Epoch 6, Batch 1200] loss: 0.01906053568935022
[Epoch 6, Batch 1300] loss: 0.027319654269667808
[Epoch 6, Batch 1400] loss: 0.025518977845495103
[Epoch 6, Batch 1500] loss: 0.014963231719157193
[Epoch 6, Batch 1600] loss: 0.02869257247182759
[Epoch 6, Batch 1700] loss: 0.022633542393050446
[Epoch 6, Batch 1800] loss: 0.02342440100030217
[Epoch 6, Batch 1900] loss: 0.023122219312863308
[Epoch 6, Batch 2000] loss: 0.013702882795569167
[Epoch 6, Batch 2100] loss: 0.030645740083218697
[Epoch 6, Batch 2200] loss: 0.026230089539476465
[Epoch 6, Batch 2300] loss: 0.018193210290737626
[Epoch 6, Batch 2400] loss: 0.02581593596987659
[Epoch 6, Batch 2500] loss: 0.02564650507430997
[Epoch 6, Batch 2600] loss: 0.01391437187736301
[Epoch 6, Batch 2700] loss: 0.021098983915690043
[Epoch 6, Batch 2800] loss: 0.02188104468923484
[Epoch 6, Batch 2900] loss: 0.01942212387872132
[Epoch 6, Batch 3000] loss: 0.02915765307534457
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0646
Validation Accuracy: 0.9813
Overfitting: 0.0646
[Epoch 7, Batch 100] loss: 0.018382827787008865
[Epoch 7, Batch 200] loss: 0.009980432033898978
[Epoch 7, Batch 300] loss: 0.01709228187344024
[Epoch 7, Batch 400] loss: 0.009329076822978096
[Epoch 7, Batch 500] loss: 0.03482216569256707
[Epoch 7, Batch 600] loss: 0.011567871988345359
[Epoch 7, Batch 700] loss: 0.019418620885326164
[Epoch 7, Batch 800] loss: 0.013889611425856856
[Epoch 7, Batch 900] loss: 0.01638177972779431
[Epoch 7, Batch 1000] loss: 0.020953854959025194
[Epoch 7, Batch 1100] loss: 0.010901516894009547
[Epoch 7, Batch 1200] loss: 0.02109743781312318
[Epoch 7, Batch 1300] loss: 0.019665000012628296
[Epoch 7, Batch 1400] loss: 0.021807995302915516
[Epoch 7, Batch 1500] loss: 0.018250493252753585
[Epoch 7, Batch 1600] loss: 0.017209083035531876
[Epoch 7, Batch 1700] loss: 0.02130848457297816
[Epoch 7, Batch 1800] loss: 0.018592491175459146
[Epoch 7, Batch 1900] loss: 0.020621357154132058
[Epoch 7, Batch 2000] loss: 0.027092864829487553
[Epoch 7, Batch 2100] loss: 0.026345189622552424
[Epoch 7, Batch 2200] loss: 0.017540579450123914
[Epoch 7, Batch 2300] loss: 0.02539041927210974
[Epoch 7, Batch 2400] loss: 0.020255397645269114
[Epoch 7, Batch 2500] loss: 0.020099007087756037
[Epoch 7, Batch 2600] loss: 0.026605357756634477
[Epoch 7, Batch 2700] loss: 0.02318967546742897
[Epoch 7, Batch 2800] loss: 0.014690188293702704
[Epoch 7, Batch 2900] loss: 0.025897803784901044
[Epoch 7, Batch 3000] loss: 0.018464776730415907
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9851
Overfitting: 0.0522
Best model saved at epoch 7 with validation loss: 0.0522
[Epoch 8, Batch 100] loss: 0.020309401311760667
[Epoch 8, Batch 200] loss: 0.00813180204211676
[Epoch 8, Batch 300] loss: 0.006783107137744082
[Epoch 8, Batch 400] loss: 0.003685922758520519
[Epoch 8, Batch 500] loss: 0.017574598582559702
[Epoch 8, Batch 600] loss: 0.01169070204559148
[Epoch 8, Batch 700] loss: 0.018950863518084587
[Epoch 8, Batch 800] loss: 0.009241406679677766
[Epoch 8, Batch 900] loss: 0.010780307749355416
[Epoch 8, Batch 1000] loss: 0.020982037378271343
[Epoch 8, Batch 1100] loss: 0.012624580638264432
[Epoch 8, Batch 1200] loss: 0.008903922613403665
[Epoch 8, Batch 1300] loss: 0.01474972478095424
[Epoch 8, Batch 1400] loss: 0.014001056004299245
[Epoch 8, Batch 1500] loss: 0.007760504180191674
[Epoch 8, Batch 1600] loss: 0.01165882192305162
[Epoch 8, Batch 1700] loss: 0.019287815730791635
[Epoch 8, Batch 1800] loss: 0.036895759147373614
[Epoch 8, Batch 1900] loss: 0.009411857896757282
[Epoch 8, Batch 2000] loss: 0.041781801505694605
[Epoch 8, Batch 2100] loss: 0.010941803410196372
[Epoch 8, Batch 2200] loss: 0.008067249966907185
[Epoch 8, Batch 2300] loss: 0.025078441538271365
[Epoch 8, Batch 2400] loss: 0.02084932571225181
[Epoch 8, Batch 2500] loss: 0.0324556146264149
[Epoch 8, Batch 2600] loss: 0.009884668280137702
[Epoch 8, Batch 2700] loss: 0.011717385324373027
[Epoch 8, Batch 2800] loss: 0.02689029434897293
[Epoch 8, Batch 2900] loss: 0.01355048651550078
[Epoch 8, Batch 3000] loss: 0.025790714037411816
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0541
Validation Accuracy: 0.9834
Overfitting: 0.0541
[Epoch 9, Batch 100] loss: 0.016857418548597708
[Epoch 9, Batch 200] loss: 0.006783963009020226
[Epoch 9, Batch 300] loss: 0.006584962563701993
[Epoch 9, Batch 400] loss: 0.01763992133787724
[Epoch 9, Batch 500] loss: 0.011702919650124386
[Epoch 9, Batch 600] loss: 0.010397554997584848
[Epoch 9, Batch 700] loss: 0.00890322553842907
[Epoch 9, Batch 800] loss: 0.007814819443183296
[Epoch 9, Batch 900] loss: 0.015965728004837275
[Epoch 9, Batch 1000] loss: 0.020765415443843267
[Epoch 9, Batch 1100] loss: 0.007370232660150577
[Epoch 9, Batch 1200] loss: 0.004782161371945221
[Epoch 9, Batch 1300] loss: 0.013210055154518159
[Epoch 9, Batch 1400] loss: 0.0077284276335575445
[Epoch 9, Batch 1500] loss: 0.009132926367074105
[Epoch 9, Batch 1600] loss: 0.014382473492078133
[Epoch 9, Batch 1700] loss: 0.01207307093550753
[Epoch 9, Batch 1800] loss: 0.014118354265006018
[Epoch 9, Batch 1900] loss: 0.015615626009412154
[Epoch 9, Batch 2000] loss: 0.021772788322605267
[Epoch 9, Batch 2100] loss: 0.011870788616033679
[Epoch 9, Batch 2200] loss: 0.014392402383914487
[Epoch 9, Batch 2300] loss: 0.006550665058503
[Epoch 9, Batch 2400] loss: 0.006944535812290269
[Epoch 9, Batch 2500] loss: 0.02512388537321385
[Epoch 9, Batch 2600] loss: 0.009158327331138026
[Epoch 9, Batch 2700] loss: 0.02011005438340817
[Epoch 9, Batch 2800] loss: 0.01361644288057505
[Epoch 9, Batch 2900] loss: 0.007004520405196217
[Epoch 9, Batch 3000] loss: 0.013690389979469728
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0574
Validation Accuracy: 0.9831
Overfitting: 0.0574
[Epoch 10, Batch 100] loss: 0.006374908932355083
[Epoch 10, Batch 200] loss: 0.01932063039967943
[Epoch 10, Batch 300] loss: 0.005645960121637472
[Epoch 10, Batch 400] loss: 0.013378633312651118
[Epoch 10, Batch 500] loss: 0.011829327210786006
[Epoch 10, Batch 600] loss: 0.00849154202104387
[Epoch 10, Batch 700] loss: 0.004104725173556289
[Epoch 10, Batch 800] loss: 0.0032119445702971914
[Epoch 10, Batch 900] loss: 0.004131781876670857
[Epoch 10, Batch 1000] loss: 0.003852195801169671
[Epoch 10, Batch 1100] loss: 0.017268817810160045
[Epoch 10, Batch 1200] loss: 0.008842550549543375
[Epoch 10, Batch 1300] loss: 0.015108287811279979
[Epoch 10, Batch 1400] loss: 0.009645880642697193
[Epoch 10, Batch 1500] loss: 0.00868038286764886
[Epoch 10, Batch 1600] loss: 0.014488769339607188
[Epoch 10, Batch 1700] loss: 0.016184128677250557
[Epoch 10, Batch 1800] loss: 0.009948219047164458
[Epoch 10, Batch 1900] loss: 0.011856109238416934
[Epoch 10, Batch 2000] loss: 0.016136611458414336
[Epoch 10, Batch 2100] loss: 0.020339747491910885
[Epoch 10, Batch 2200] loss: 0.011692546627914453
[Epoch 10, Batch 2300] loss: 0.006060698942856106
[Epoch 10, Batch 2400] loss: 0.004046623404396996
[Epoch 10, Batch 2500] loss: 0.014458381320457648
[Epoch 10, Batch 2600] loss: 0.01949591401936459
[Epoch 10, Batch 2700] loss: 0.02755097251205825
[Epoch 10, Batch 2800] loss: 0.006848941142334297
[Epoch 10, Batch 2900] loss: 0.006633527851136023
[Epoch 10, Batch 3000] loss: 0.007543498198840553
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9858
Overfitting: 0.0570
[Epoch 11, Batch 100] loss: 0.008550912653637397
[Epoch 11, Batch 200] loss: 0.00858212238939359
[Epoch 11, Batch 300] loss: 0.009257772026699059
[Epoch 11, Batch 400] loss: 0.002954207400962332
[Epoch 11, Batch 500] loss: 0.013444014742607067
[Epoch 11, Batch 600] loss: 0.0114653710818925
[Epoch 11, Batch 700] loss: 0.007102263046876942
[Epoch 11, Batch 800] loss: 0.0056174603712725
[Epoch 11, Batch 900] loss: 0.004840966609908719
[Epoch 11, Batch 1000] loss: 0.010556472999491575
[Epoch 11, Batch 1100] loss: 0.003938923572992508
[Epoch 11, Batch 1200] loss: 0.008994385998880717
[Epoch 11, Batch 1300] loss: 0.007713130905310664
[Epoch 11, Batch 1400] loss: 0.016452176023858556
[Epoch 11, Batch 1500] loss: 0.010173042586156953
[Epoch 11, Batch 1600] loss: 0.008354477225211668
[Epoch 11, Batch 1700] loss: 0.004417426042464285
[Epoch 11, Batch 1800] loss: 0.012615464361660998
[Epoch 11, Batch 1900] loss: 0.0040365809354079825
[Epoch 11, Batch 2000] loss: 0.011795246936951855
[Epoch 11, Batch 2100] loss: 0.009317863314492456
[Epoch 11, Batch 2200] loss: 0.0033135263036888317
[Epoch 11, Batch 2300] loss: 0.016805871763592675
[Epoch 11, Batch 2400] loss: 0.006194659629268244
[Epoch 11, Batch 2500] loss: 0.0063161344026622145
[Epoch 11, Batch 2600] loss: 0.005376493337404326
[Epoch 11, Batch 2700] loss: 0.0071344089769269205
[Epoch 11, Batch 2800] loss: 0.01751873332775176
[Epoch 11, Batch 2900] loss: 0.006721037493998665
[Epoch 11, Batch 3000] loss: 0.009476240072210658
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0568
Validation Accuracy: 0.9872
Overfitting: 0.0568
[Epoch 12, Batch 100] loss: 0.007655902874714684
[Epoch 12, Batch 200] loss: 0.0024687311953277913
[Epoch 12, Batch 300] loss: 0.005626997571741867
[Epoch 12, Batch 400] loss: 0.003013588166612067
[Epoch 12, Batch 500] loss: 0.006352640005815147
[Epoch 12, Batch 600] loss: 0.004093364965011475
[Epoch 12, Batch 700] loss: 0.0054439266199244685
[Epoch 12, Batch 800] loss: 0.003756235120223721
[Epoch 12, Batch 900] loss: 0.0022221306377991825
[Epoch 12, Batch 1000] loss: 0.0065042806224505515
[Epoch 12, Batch 1100] loss: 0.004080508769162066
[Epoch 12, Batch 1200] loss: 0.0036477266818206997
[Epoch 12, Batch 1300] loss: 0.012241353220811107
[Epoch 12, Batch 1400] loss: 0.003704224770141309
[Epoch 12, Batch 1500] loss: 0.006637333165665779
[Epoch 12, Batch 1600] loss: 0.006891191936586552
[Epoch 12, Batch 1700] loss: 0.008554542054449143
[Epoch 12, Batch 1800] loss: 0.004699201030946085
[Epoch 12, Batch 1900] loss: 0.0073920660604650835
[Epoch 12, Batch 2000] loss: 0.0048821499501667635
[Epoch 12, Batch 2100] loss: 0.007689524077559611
[Epoch 12, Batch 2200] loss: 0.00839597322677122
[Epoch 12, Batch 2300] loss: 0.016964705815937862
[Epoch 12, Batch 2400] loss: 0.009213251031675753
[Epoch 12, Batch 2500] loss: 0.011255956429949946
[Epoch 12, Batch 2600] loss: 0.011475849998668082
[Epoch 12, Batch 2700] loss: 0.012480531434853219
[Epoch 12, Batch 2800] loss: 0.008112572232371917
[Epoch 12, Batch 2900] loss: 0.016150095855324054
[Epoch 12, Batch 3000] loss: 0.025901211979245886
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0643
Validation Accuracy: 0.9848
Overfitting: 0.0643
[Epoch 13, Batch 100] loss: 0.009249115182685728
[Epoch 13, Batch 200] loss: 0.013855923854362118
[Epoch 13, Batch 300] loss: 0.0052411975876725594
[Epoch 13, Batch 400] loss: 0.008012633635687508
[Epoch 13, Batch 500] loss: 0.008216154153323031
[Epoch 13, Batch 600] loss: 0.00569742524603214
[Epoch 13, Batch 700] loss: 0.007943955376350119
[Epoch 13, Batch 800] loss: 0.006749267281745688
[Epoch 13, Batch 900] loss: 0.008563099081482051
[Epoch 13, Batch 1000] loss: 0.004701020232100745
[Epoch 13, Batch 1100] loss: 0.008245803549486225
[Epoch 13, Batch 1200] loss: 0.005534340399287316
[Epoch 13, Batch 1300] loss: 0.009238633919731001
[Epoch 13, Batch 1400] loss: 0.005348133236445278
[Epoch 13, Batch 1500] loss: 0.00658529704954546
[Epoch 13, Batch 1600] loss: 0.0015736505293583037
[Epoch 13, Batch 1700] loss: 0.003337811870956955
[Epoch 13, Batch 1800] loss: 0.012707784892472205
[Epoch 13, Batch 1900] loss: 0.008683896276019993
[Epoch 13, Batch 2000] loss: 0.005698265389787025
[Epoch 13, Batch 2100] loss: 0.005782159384673946
[Epoch 13, Batch 2200] loss: 0.0051904743263932575
[Epoch 13, Batch 2300] loss: 0.012317243205255296
[Epoch 13, Batch 2400] loss: 0.011188122176771459
[Epoch 13, Batch 2500] loss: 0.003991318946893756
[Epoch 13, Batch 2600] loss: 0.00801237352925618
[Epoch 13, Batch 2700] loss: 0.004223496841524934
[Epoch 13, Batch 2800] loss: 0.0027629799416728673
[Epoch 13, Batch 2900] loss: 0.0021396138701271637
[Epoch 13, Batch 3000] loss: 0.017003001287850168
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9881
Overfitting: 0.0522
Best model saved at epoch 13 with validation loss: 0.0522
[Epoch 14, Batch 100] loss: 0.007035277260646317
[Epoch 14, Batch 200] loss: 0.005142266186793734
[Epoch 14, Batch 300] loss: 0.007381838462168844
[Epoch 14, Batch 400] loss: 0.0033460995287073556
[Epoch 14, Batch 500] loss: 0.002764406988971473
[Epoch 14, Batch 600] loss: 0.0026595553311881304
[Epoch 14, Batch 700] loss: 0.004791085392752379
[Epoch 14, Batch 800] loss: 0.009499867636758025
[Epoch 14, Batch 900] loss: 0.009224729267494354
[Epoch 14, Batch 1000] loss: 0.006551649159499675
[Epoch 14, Batch 1100] loss: 0.005759871266253356
[Epoch 14, Batch 1200] loss: 0.003144599955886065
[Epoch 14, Batch 1300] loss: 0.00437946730613703
[Epoch 14, Batch 1400] loss: 0.0065036410155758515
[Epoch 14, Batch 1500] loss: 0.005950979897677087
[Epoch 14, Batch 1600] loss: 0.0014982886185089229
[Epoch 14, Batch 1700] loss: 0.002761937397779093
[Epoch 14, Batch 1800] loss: 0.0050576495158235705
[Epoch 14, Batch 1900] loss: 0.005054638523085373
[Epoch 14, Batch 2000] loss: 0.005184950697527313
[Epoch 14, Batch 2100] loss: 0.0053833936355579225
[Epoch 14, Batch 2200] loss: 0.005258125843723178
[Epoch 14, Batch 2300] loss: 0.011728172737727362
[Epoch 14, Batch 2400] loss: 0.00600256945686013
[Epoch 14, Batch 2500] loss: 0.010976807720699356
[Epoch 14, Batch 2600] loss: 0.011093680067879603
[Epoch 14, Batch 2700] loss: 0.018206983636254677
[Epoch 14, Batch 2800] loss: 0.01145054694745312
[Epoch 14, Batch 2900] loss: 0.013177441158921397
[Epoch 14, Batch 3000] loss: 0.011696150005277843
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9870
Overfitting: 0.0593
[Epoch 15, Batch 100] loss: 0.004227277703394634
[Epoch 15, Batch 200] loss: 0.004549338415827151
[Epoch 15, Batch 300] loss: 0.00642092425119813
[Epoch 15, Batch 400] loss: 0.004279504108806264
[Epoch 15, Batch 500] loss: 0.004284952691198214
[Epoch 15, Batch 600] loss: 0.001972188645831423
[Epoch 15, Batch 700] loss: 0.00788127374429429
[Epoch 15, Batch 800] loss: 0.0024808226313408
[Epoch 15, Batch 900] loss: 0.01032847219602445
[Epoch 15, Batch 1000] loss: 0.004063572541429039
[Epoch 15, Batch 1100] loss: 0.0011678754247343192
[Epoch 15, Batch 1200] loss: 0.0065431571848797885
[Epoch 15, Batch 1300] loss: 0.009566240582508528
[Epoch 15, Batch 1400] loss: 0.0029532797862007955
[Epoch 15, Batch 1500] loss: 0.006209789990199113
[Epoch 15, Batch 1600] loss: 0.00325033401351277
[Epoch 15, Batch 1700] loss: 0.006597053558221404
[Epoch 15, Batch 1800] loss: 0.0024549587633424606
[Epoch 15, Batch 1900] loss: 0.004924735852982849
[Epoch 15, Batch 2000] loss: 0.0010948019653154973
[Epoch 15, Batch 2100] loss: 0.003013890305904923
[Epoch 15, Batch 2200] loss: 0.006539857568197363
[Epoch 15, Batch 2300] loss: 0.007160615541698405
[Epoch 15, Batch 2400] loss: 0.005583594583497415
[Epoch 15, Batch 2500] loss: 0.004010673244321197
[Epoch 15, Batch 2600] loss: 0.007527379357778994
[Epoch 15, Batch 2700] loss: 0.0027004360361887335
[Epoch 15, Batch 2800] loss: 0.0016258153237004081
[Epoch 15, Batch 2900] loss: 0.009753023782841978
[Epoch 15, Batch 3000] loss: 0.00747866381371864
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0558
Validation Accuracy: 0.9879
Overfitting: 0.0558
[Epoch 16, Batch 100] loss: 0.0029706744275486583
[Epoch 16, Batch 200] loss: 0.004854654483397951
[Epoch 16, Batch 300] loss: 0.0039604652966608
[Epoch 16, Batch 400] loss: 0.005380167102634274
[Epoch 16, Batch 500] loss: 0.0037250275571526
[Epoch 16, Batch 600] loss: 0.0008840158947778276
[Epoch 16, Batch 700] loss: 0.002236784645342631
[Epoch 16, Batch 800] loss: 0.001628443396383261
[Epoch 16, Batch 900] loss: 0.0007225713325381377
[Epoch 16, Batch 1000] loss: 0.004437768341802837
[Epoch 16, Batch 1100] loss: 0.003587037567253937
[Epoch 16, Batch 1200] loss: 0.004419720251091413
[Epoch 16, Batch 1300] loss: 0.002785086492277813
[Epoch 16, Batch 1400] loss: 0.005359414836194993
[Epoch 16, Batch 1500] loss: 0.0032875559738675974
[Epoch 16, Batch 1600] loss: 0.021696879102574798
[Epoch 16, Batch 1700] loss: 0.005210557874146637
[Epoch 16, Batch 1800] loss: 0.005314000341262784
[Epoch 16, Batch 1900] loss: 0.011514098179985482
[Epoch 16, Batch 2000] loss: 0.002346962256354743
[Epoch 16, Batch 2100] loss: 0.012557262738550854
[Epoch 16, Batch 2200] loss: 0.007541659036471771
[Epoch 16, Batch 2300] loss: 0.004177031495795229
[Epoch 16, Batch 2400] loss: 0.0016109395940996762
[Epoch 16, Batch 2500] loss: 0.022962365345692605
[Epoch 16, Batch 2600] loss: 0.004856655246305764
[Epoch 16, Batch 2700] loss: 0.0026732216749753056
[Epoch 16, Batch 2800] loss: 0.00992673302891859
[Epoch 16, Batch 2900] loss: 0.021322905466806787
[Epoch 16, Batch 3000] loss: 0.003049638225745568
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0582
Validation Accuracy: 0.9875
Overfitting: 0.0582
[Epoch 17, Batch 100] loss: 0.005205685398808555
[Epoch 17, Batch 200] loss: 0.0125930083492581
[Epoch 17, Batch 300] loss: 0.009906531463230017
[Epoch 17, Batch 400] loss: 0.012685798849008733
[Epoch 17, Batch 500] loss: 0.004118475872249831
[Epoch 17, Batch 600] loss: 0.004947459362415287
[Epoch 17, Batch 700] loss: 0.005937354932576895
[Epoch 17, Batch 800] loss: 0.013856214663565253
[Epoch 17, Batch 900] loss: 0.016689870236662616
[Epoch 17, Batch 1000] loss: 0.017648995283865643
[Epoch 17, Batch 1100] loss: 0.010665428951032823
[Epoch 17, Batch 1200] loss: 0.0053484547277057
[Epoch 17, Batch 1300] loss: 0.006934305218031227
[Epoch 17, Batch 1400] loss: 0.003757529901269834
[Epoch 17, Batch 1500] loss: 0.012538181460417092
[Epoch 17, Batch 1600] loss: 0.006822709769649009
[Epoch 17, Batch 1700] loss: 0.024963740587342045
[Epoch 17, Batch 1800] loss: 0.008033711138694458
[Epoch 17, Batch 1900] loss: 0.0024048181388066324
[Epoch 17, Batch 2000] loss: 0.008842780552023867
[Epoch 17, Batch 2100] loss: 0.0049491033619003845
[Epoch 17, Batch 2200] loss: 0.0034529408173469235
[Epoch 17, Batch 2300] loss: 0.0025002425501872948
[Epoch 17, Batch 2400] loss: 0.0034279910006236314
[Epoch 17, Batch 2500] loss: 0.0011331528409562353
[Epoch 17, Batch 2600] loss: 0.007899703989036767
[Epoch 17, Batch 2700] loss: 0.0044154670164142824
[Epoch 17, Batch 2800] loss: 0.001427733357655252
[Epoch 17, Batch 2900] loss: 0.009025098875198409
[Epoch 17, Batch 3000] loss: 0.010134932892999587
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9884
Overfitting: 0.0559
[Epoch 18, Batch 100] loss: 0.002809345270893999
[Epoch 18, Batch 200] loss: 0.003107291304006594
[Epoch 18, Batch 300] loss: 0.002638917961737359
[Epoch 18, Batch 400] loss: 0.0052581125358199185
[Epoch 18, Batch 500] loss: 0.024413855664969154
[Epoch 18, Batch 600] loss: 0.010878991751138756
[Epoch 18, Batch 700] loss: 0.005937818211907242
[Epoch 18, Batch 800] loss: 0.008522586035906414
[Epoch 18, Batch 900] loss: 0.004200500190537895
[Epoch 18, Batch 1000] loss: 0.004912222504511732
[Epoch 18, Batch 1100] loss: 0.002126988922581745
[Epoch 18, Batch 1200] loss: 0.012042187688691825
[Epoch 18, Batch 1300] loss: 0.00352502135326219
[Epoch 18, Batch 1400] loss: 0.0056911101916747595
[Epoch 18, Batch 1500] loss: 0.0038859163142144835
[Epoch 18, Batch 1600] loss: 0.010221600975351918
[Epoch 18, Batch 1700] loss: 0.0036309217009721094
[Epoch 18, Batch 1800] loss: 0.003690407032706986
[Epoch 18, Batch 1900] loss: 0.0032502813569492118
[Epoch 18, Batch 2000] loss: 0.002345945156274496
[Epoch 18, Batch 2100] loss: 0.002997615544531698
[Epoch 18, Batch 2200] loss: 0.00701487531642826
[Epoch 18, Batch 2300] loss: 0.0019842915994475875
[Epoch 18, Batch 2400] loss: 0.008410324178968196
[Epoch 18, Batch 2500] loss: 0.010879139217783518
[Epoch 18, Batch 2600] loss: 0.010582794899009058
[Epoch 18, Batch 2700] loss: 0.013278033151888947
[Epoch 18, Batch 2800] loss: 0.004397134069350841
[Epoch 18, Batch 2900] loss: 0.00230133468531875
[Epoch 18, Batch 3000] loss: 0.0051498435711936
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0568
Validation Accuracy: 0.9887
Overfitting: 0.0568
[Epoch 19, Batch 100] loss: 0.001964689040487997
[Epoch 19, Batch 200] loss: 0.0048568930454996285
[Epoch 19, Batch 300] loss: 0.0026143597845211274
[Epoch 19, Batch 400] loss: 0.005266365450305664
[Epoch 19, Batch 500] loss: 0.0013665494577847425
[Epoch 19, Batch 600] loss: 0.007423147217005521
[Epoch 19, Batch 700] loss: 0.004463270384082687
[Epoch 19, Batch 800] loss: 0.0019838001379625324
[Epoch 19, Batch 900] loss: 0.0018738525382519767
[Epoch 19, Batch 1000] loss: 0.003105135614210326
[Epoch 19, Batch 1100] loss: 0.01740491157545218
[Epoch 19, Batch 1200] loss: 0.004042490984505136
[Epoch 19, Batch 1300] loss: 0.0019380758025499744
[Epoch 19, Batch 1400] loss: 0.0013061025812812232
[Epoch 19, Batch 1500] loss: 0.0005088244145192533
[Epoch 19, Batch 1600] loss: 0.0010656366351859247
[Epoch 19, Batch 1700] loss: 0.002670832775337857
[Epoch 19, Batch 1800] loss: 0.002090285431110317
[Epoch 19, Batch 1900] loss: 0.0020783936567142724
[Epoch 19, Batch 2000] loss: 0.0024878488516197404
[Epoch 19, Batch 2100] loss: 0.00533319794130648
[Epoch 19, Batch 2200] loss: 0.002208057184201304
[Epoch 19, Batch 2300] loss: 0.001545220722224272
[Epoch 19, Batch 2400] loss: 0.003601928101307479
[Epoch 19, Batch 2500] loss: 0.0029159291922351647
[Epoch 19, Batch 2600] loss: 0.0016328278723797141
[Epoch 19, Batch 2700] loss: 0.0012374602400213376
[Epoch 19, Batch 2800] loss: 0.006259781051453821
[Epoch 19, Batch 2900] loss: 0.0026746201482944444
[Epoch 19, Batch 3000] loss: 0.004231559297943548
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0631
Validation Accuracy: 0.9871
Overfitting: 0.0631
[Epoch 20, Batch 100] loss: 0.002786206699869047
[Epoch 20, Batch 200] loss: 0.002313721532320159
[Epoch 20, Batch 300] loss: 0.0010632230978708135
[Epoch 20, Batch 400] loss: 0.003517961829125227
[Epoch 20, Batch 500] loss: 0.0047914379368648955
[Epoch 20, Batch 600] loss: 0.0028477169516888346
[Epoch 20, Batch 700] loss: 0.011403156552248888
[Epoch 20, Batch 800] loss: 0.004123136589079613
[Epoch 20, Batch 900] loss: 0.000792297272481619
[Epoch 20, Batch 1000] loss: 0.002110301936590169
[Epoch 20, Batch 1100] loss: 0.00148065912824336
[Epoch 20, Batch 1200] loss: 0.0005966966358874259
[Epoch 20, Batch 1300] loss: 0.0012783514816974418
[Epoch 20, Batch 1400] loss: 0.006535849969927891
[Epoch 20, Batch 1500] loss: 0.002418282279207773
[Epoch 20, Batch 1600] loss: 0.0009229938815453664
[Epoch 20, Batch 1700] loss: 0.002772865752438207
[Epoch 20, Batch 1800] loss: 0.0008559778542868734
[Epoch 20, Batch 1900] loss: 0.0031036617874670115
[Epoch 20, Batch 2000] loss: 0.00547710529202881
[Epoch 20, Batch 2100] loss: 0.0009569737356491714
[Epoch 20, Batch 2200] loss: 0.002018376948087024
[Epoch 20, Batch 2300] loss: 0.0007983010125630585
[Epoch 20, Batch 2400] loss: 0.0015653770481726071
[Epoch 20, Batch 2500] loss: 0.0023296960422186873
[Epoch 20, Batch 2600] loss: 0.00272741372410926
[Epoch 20, Batch 2700] loss: 0.0021776779794015154
[Epoch 20, Batch 2800] loss: 0.0014307438426396058
[Epoch 20, Batch 2900] loss: 0.0007083873249417882
[Epoch 20, Batch 3000] loss: 0.0028505921650935663
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9888
Overfitting: 0.0548
[Epoch 21, Batch 100] loss: 0.0008867879066140461
[Epoch 21, Batch 200] loss: 0.00046476523123963
[Epoch 21, Batch 300] loss: 0.0006206194188960268
[Epoch 21, Batch 400] loss: 0.00031320827515280314
[Epoch 21, Batch 500] loss: 0.00028390869478343015
[Epoch 21, Batch 600] loss: 0.00023330957555415922
[Epoch 21, Batch 700] loss: 0.010981731190754154
[Epoch 21, Batch 800] loss: 0.001840094099064724
[Epoch 21, Batch 900] loss: 0.002194215133351278
[Epoch 21, Batch 1000] loss: 0.0022318775903357848
[Epoch 21, Batch 1100] loss: 0.0004915683348139366
[Epoch 21, Batch 1200] loss: 0.0002988863345484871
[Epoch 21, Batch 1300] loss: 0.0025174613118023005
[Epoch 21, Batch 1400] loss: 0.0010964358096123305
[Epoch 21, Batch 1500] loss: 0.003307142259062128
[Epoch 21, Batch 1600] loss: 0.0014417940573360254
[Epoch 21, Batch 1700] loss: 0.0010483295465361531
[Epoch 21, Batch 1800] loss: 0.001649552828614409
[Epoch 21, Batch 1900] loss: 0.000260679768747325
[Epoch 21, Batch 2000] loss: 0.0003190176268229372
[Epoch 21, Batch 2100] loss: 0.0005581662986004954
[Epoch 21, Batch 2200] loss: 0.001171013869909916
[Epoch 21, Batch 2300] loss: 0.0012532796980768701
[Epoch 21, Batch 2400] loss: 0.002775987572837617
[Epoch 21, Batch 2500] loss: 0.0007698297219104511
[Epoch 21, Batch 2600] loss: 0.00025700761050607924
[Epoch 21, Batch 2700] loss: 0.00046071904871313406
[Epoch 21, Batch 2800] loss: 0.0025618657401000446
[Epoch 21, Batch 2900] loss: 0.0008428870713476
[Epoch 21, Batch 3000] loss: 0.000653661563494885
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9892
Overfitting: 0.0603
[Epoch 22, Batch 100] loss: 0.0004190923968773719
[Epoch 22, Batch 200] loss: 0.00016834050001790057
[Epoch 22, Batch 300] loss: 0.00027793833432325775
[Epoch 22, Batch 400] loss: 0.0002834674944815685
[Epoch 22, Batch 500] loss: 0.00077585926979864
[Epoch 22, Batch 600] loss: 0.0002859168112301891
[Epoch 22, Batch 700] loss: 0.0005907034083349982
[Epoch 22, Batch 800] loss: 0.00040952728543713234
[Epoch 22, Batch 900] loss: 0.001946130871777223
[Epoch 22, Batch 1000] loss: 0.00030349464948709493
[Epoch 22, Batch 1100] loss: 0.0014167205458842337
[Epoch 22, Batch 1200] loss: 0.0006356699475409489
[Epoch 22, Batch 1300] loss: 0.0003881657931580529
[Epoch 22, Batch 1400] loss: 0.00019916193558349615
[Epoch 22, Batch 1500] loss: 0.00019654830063875917
[Epoch 22, Batch 1600] loss: 0.0017613093699778038
[Epoch 22, Batch 1700] loss: 0.0009179229311949344
[Epoch 22, Batch 1800] loss: 0.0004259557662083857
[Epoch 22, Batch 1900] loss: 0.0006587342071519187
[Epoch 22, Batch 2000] loss: 0.00021296199733775723
[Epoch 22, Batch 2100] loss: 0.00044876184622525626
[Epoch 22, Batch 2200] loss: 0.0004584627326370816
[Epoch 22, Batch 2300] loss: 0.0005929211509858634
[Epoch 22, Batch 2400] loss: 7.921969142313134e-05
[Epoch 22, Batch 2500] loss: 0.0002152966579595006
[Epoch 22, Batch 2600] loss: 0.0007180291861261345
[Epoch 22, Batch 2700] loss: 0.003515404465103513
[Epoch 22, Batch 2800] loss: 0.001700684523768028
[Epoch 22, Batch 2900] loss: 0.0009428507472237646
[Epoch 22, Batch 3000] loss: 0.0029834513066137225
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9901
Overfitting: 0.0593
[Epoch 23, Batch 100] loss: 0.0002283812505985239
[Epoch 23, Batch 200] loss: 0.004722150334761861
[Epoch 23, Batch 300] loss: 0.0016486451962158144
[Epoch 23, Batch 400] loss: 0.00027547692744487315
[Epoch 23, Batch 500] loss: 0.000311194698837185
[Epoch 23, Batch 600] loss: 0.0002907572020095994
[Epoch 23, Batch 700] loss: 0.0006469564410106043
[Epoch 23, Batch 800] loss: 0.000265549923914854
[Epoch 23, Batch 900] loss: 0.0034955266025517105
[Epoch 23, Batch 1000] loss: 0.0018713468860696869
[Epoch 23, Batch 1100] loss: 0.003626815033591835
[Epoch 23, Batch 1200] loss: 0.0014664017026232744
[Epoch 23, Batch 1300] loss: 0.007224364869188378
[Epoch 23, Batch 1400] loss: 0.005186617020020439
[Epoch 23, Batch 1500] loss: 0.004772592675365841
[Epoch 23, Batch 1600] loss: 0.0028098855131905333
[Epoch 23, Batch 1700] loss: 0.0016009261154908705
[Epoch 23, Batch 1800] loss: 0.0005197804205308065
[Epoch 23, Batch 1900] loss: 0.0006093469108750283
[Epoch 23, Batch 2000] loss: 0.00019609515628891128
[Epoch 23, Batch 2100] loss: 0.0004956081203648343
[Epoch 23, Batch 2200] loss: 0.001147203859749486
[Epoch 23, Batch 2300] loss: 0.00013627726509662263
[Epoch 23, Batch 2400] loss: 0.0012623955164061229
[Epoch 23, Batch 2500] loss: 0.0007563505304298834
[Epoch 23, Batch 2600] loss: 0.0007116774522362502
[Epoch 23, Batch 2700] loss: 0.001956391969702751
[Epoch 23, Batch 2800] loss: 0.0033170277698920405
[Epoch 23, Batch 2900] loss: 0.0019072174096467088
[Epoch 23, Batch 3000] loss: 0.005290025171239985
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0699
Validation Accuracy: 0.9883
Overfitting: 0.0699
[Epoch 24, Batch 100] loss: 0.0009468742789815421
[Epoch 24, Batch 200] loss: 0.010588136511212234
[Epoch 24, Batch 300] loss: 0.020748108517767285
[Epoch 24, Batch 400] loss: 0.0018678062606367618
[Epoch 24, Batch 500] loss: 0.001978119708921708
[Epoch 24, Batch 600] loss: 0.00242687976385497
[Epoch 24, Batch 700] loss: 0.000691737297493873
[Epoch 24, Batch 800] loss: 0.0003964671975024281
[Epoch 24, Batch 900] loss: 0.0011217060830148418
[Epoch 24, Batch 1000] loss: 0.0015838204979026571
[Epoch 24, Batch 1100] loss: 0.0005546815609240952
[Epoch 24, Batch 1200] loss: 0.0005043885568760142
[Epoch 24, Batch 1300] loss: 0.0003029838931094098
[Epoch 24, Batch 1400] loss: 0.0008321414616406475
[Epoch 24, Batch 1500] loss: 0.002847939958079273
[Epoch 24, Batch 1600] loss: 0.0028701638278827834
[Epoch 24, Batch 1700] loss: 0.0017628246400931858
[Epoch 24, Batch 1800] loss: 0.0016493936913206796
[Epoch 24, Batch 1900] loss: 0.0019796035568817906
[Epoch 24, Batch 2000] loss: 0.0005931509734758888
[Epoch 24, Batch 2100] loss: 0.0042678237413728845
[Epoch 24, Batch 2200] loss: 0.0012283454072567145
[Epoch 24, Batch 2300] loss: 0.003105599514939392
[Epoch 24, Batch 2400] loss: 0.00028947604105992395
[Epoch 24, Batch 2500] loss: 0.005769162834419461
[Epoch 24, Batch 2600] loss: 0.005030717245167411
[Epoch 24, Batch 2700] loss: 0.0051360301632507625
[Epoch 24, Batch 2800] loss: 0.0015245892244511161
[Epoch 24, Batch 2900] loss: 0.002147374465767378
[Epoch 24, Batch 3000] loss: 0.0028218077236277363
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9886
Overfitting: 0.0605
Fold 2 validation loss: 0.0605
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2642150068283082
[Epoch 1, Batch 200] loss: 1.4079315534234047
[Epoch 1, Batch 300] loss: 0.6348137947916984
[Epoch 1, Batch 400] loss: 0.4259469235688448
[Epoch 1, Batch 500] loss: 0.379596174955368
[Epoch 1, Batch 600] loss: 0.28585464768111707
[Epoch 1, Batch 700] loss: 0.26691552678123115
[Epoch 1, Batch 800] loss: 0.23049708568491042
[Epoch 1, Batch 900] loss: 0.2179343687556684
[Epoch 1, Batch 1000] loss: 0.17502020040526986
[Epoch 1, Batch 1100] loss: 0.18163374030962587
[Epoch 1, Batch 1200] loss: 0.16965090011246503
[Epoch 1, Batch 1300] loss: 0.1600897568045184
[Epoch 1, Batch 1400] loss: 0.14445625498890877
[Epoch 1, Batch 1500] loss: 0.1532805225730408
[Epoch 1, Batch 1600] loss: 0.14722625623922794
[Epoch 1, Batch 1700] loss: 0.144876969573088
[Epoch 1, Batch 1800] loss: 0.13515065752435476
[Epoch 1, Batch 1900] loss: 0.10988498818827792
[Epoch 1, Batch 2000] loss: 0.1350182991393376
[Epoch 1, Batch 2100] loss: 0.11886358337709681
[Epoch 1, Batch 2200] loss: 0.13068265543319285
[Epoch 1, Batch 2300] loss: 0.1005604477552697
[Epoch 1, Batch 2400] loss: 0.09461058319662698
[Epoch 1, Batch 2500] loss: 0.10345881049172022
[Epoch 1, Batch 2600] loss: 0.10295648482162506
[Epoch 1, Batch 2700] loss: 0.07497045200434513
[Epoch 1, Batch 2800] loss: 0.08599601677036844
[Epoch 1, Batch 2900] loss: 0.08273872826539445
[Epoch 1, Batch 3000] loss: 0.07622875642962754
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0835
Validation Accuracy: 0.9738
Overfitting: 0.0835
Best model saved at epoch 1 with validation loss: 0.0835
[Epoch 2, Batch 100] loss: 0.09297858305973933
[Epoch 2, Batch 200] loss: 0.06293410458369181
[Epoch 2, Batch 300] loss: 0.08428434456291142
[Epoch 2, Batch 400] loss: 0.07348145983938593
[Epoch 2, Batch 500] loss: 0.08474647931638174
[Epoch 2, Batch 600] loss: 0.08247585290228017
[Epoch 2, Batch 700] loss: 0.08245631104975473
[Epoch 2, Batch 800] loss: 0.09458111107698641
[Epoch 2, Batch 900] loss: 0.07789361837785691
[Epoch 2, Batch 1000] loss: 0.059579696233849976
[Epoch 2, Batch 1100] loss: 0.06796380271669478
[Epoch 2, Batch 1200] loss: 0.05271590578136966
[Epoch 2, Batch 1300] loss: 0.07186612989928108
[Epoch 2, Batch 1400] loss: 0.07988651475752703
[Epoch 2, Batch 1500] loss: 0.056583256824233104
[Epoch 2, Batch 1600] loss: 0.06666870150482282
[Epoch 2, Batch 1700] loss: 0.07427731901174411
[Epoch 2, Batch 1800] loss: 0.058896718543255705
[Epoch 2, Batch 1900] loss: 0.05465530397923431
[Epoch 2, Batch 2000] loss: 0.07851725204847754
[Epoch 2, Batch 2100] loss: 0.051297095287591216
[Epoch 2, Batch 2200] loss: 0.06860034540703054
[Epoch 2, Batch 2300] loss: 0.05557339855644386
[Epoch 2, Batch 2400] loss: 0.048491611649515105
[Epoch 2, Batch 2500] loss: 0.06736808272165945
[Epoch 2, Batch 2600] loss: 0.06857395277998876
[Epoch 2, Batch 2700] loss: 0.058508821930445265
[Epoch 2, Batch 2800] loss: 0.06133203506469727
[Epoch 2, Batch 2900] loss: 0.05811675684468355
[Epoch 2, Batch 3000] loss: 0.0745879471860826
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0653
Validation Accuracy: 0.9804
Overfitting: 0.0653
Best model saved at epoch 2 with validation loss: 0.0653
[Epoch 3, Batch 100] loss: 0.04731443114214926
[Epoch 3, Batch 200] loss: 0.04979860447638203
[Epoch 3, Batch 300] loss: 0.04764490898000076
[Epoch 3, Batch 400] loss: 0.0380140671213303
[Epoch 3, Batch 500] loss: 0.04562875801326299
[Epoch 3, Batch 600] loss: 0.04406927029325743
[Epoch 3, Batch 700] loss: 0.05289119951921748
[Epoch 3, Batch 800] loss: 0.05326224431628361
[Epoch 3, Batch 900] loss: 0.04314190350414719
[Epoch 3, Batch 1000] loss: 0.03206203244903008
[Epoch 3, Batch 1100] loss: 0.061898956505247044
[Epoch 3, Batch 1200] loss: 0.037765104919380975
[Epoch 3, Batch 1300] loss: 0.035811980543076063
[Epoch 3, Batch 1400] loss: 0.07768646759301191
[Epoch 3, Batch 1500] loss: 0.051065928588723185
[Epoch 3, Batch 1600] loss: 0.03796002190269064
[Epoch 3, Batch 1700] loss: 0.04704532174713677
[Epoch 3, Batch 1800] loss: 0.034432128311600536
[Epoch 3, Batch 1900] loss: 0.04940596829925198
[Epoch 3, Batch 2000] loss: 0.030761311782043776
[Epoch 3, Batch 2100] loss: 0.03811284646828426
[Epoch 3, Batch 2200] loss: 0.05077041618860676
[Epoch 3, Batch 2300] loss: 0.05702351473606541
[Epoch 3, Batch 2400] loss: 0.04502959032026411
[Epoch 3, Batch 2500] loss: 0.06235113368689781
[Epoch 3, Batch 2600] loss: 0.02942689256182348
[Epoch 3, Batch 2700] loss: 0.05025536954577547
[Epoch 3, Batch 2800] loss: 0.046205009322147814
[Epoch 3, Batch 2900] loss: 0.037314256629906596
[Epoch 3, Batch 3000] loss: 0.049792814825777895
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9842
Overfitting: 0.0569
Best model saved at epoch 3 with validation loss: 0.0569
[Epoch 4, Batch 100] loss: 0.03653798063518479
[Epoch 4, Batch 200] loss: 0.03923234549838526
[Epoch 4, Batch 300] loss: 0.027877498830785042
[Epoch 4, Batch 400] loss: 0.034876867589191535
[Epoch 4, Batch 500] loss: 0.018155499069398503
[Epoch 4, Batch 600] loss: 0.027923246182035656
[Epoch 4, Batch 700] loss: 0.04135593359656923
[Epoch 4, Batch 800] loss: 0.028583817516991985
[Epoch 4, Batch 900] loss: 0.041269545837276385
[Epoch 4, Batch 1000] loss: 0.029333837507583668
[Epoch 4, Batch 1100] loss: 0.021412771986069855
[Epoch 4, Batch 1200] loss: 0.022885883306516915
[Epoch 4, Batch 1300] loss: 0.04024514126791473
[Epoch 4, Batch 1400] loss: 0.04224269701902813
[Epoch 4, Batch 1500] loss: 0.026605383028581855
[Epoch 4, Batch 1600] loss: 0.042933604204590664
[Epoch 4, Batch 1700] loss: 0.024984956907865126
[Epoch 4, Batch 1800] loss: 0.039415791003539195
[Epoch 4, Batch 1900] loss: 0.03854074323433451
[Epoch 4, Batch 2000] loss: 0.040961541793440116
[Epoch 4, Batch 2100] loss: 0.03790912831565947
[Epoch 4, Batch 2200] loss: 0.03255517369150766
[Epoch 4, Batch 2300] loss: 0.028332698963640723
[Epoch 4, Batch 2400] loss: 0.03050099340674933
[Epoch 4, Batch 2500] loss: 0.04472360510852013
[Epoch 4, Batch 2600] loss: 0.04680214111769601
[Epoch 4, Batch 2700] loss: 0.0362588092921942
[Epoch 4, Batch 2800] loss: 0.04556587521379697
[Epoch 4, Batch 2900] loss: 0.03238216592868412
[Epoch 4, Batch 3000] loss: 0.042699902382082655
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9849
Overfitting: 0.0477
Best model saved at epoch 4 with validation loss: 0.0477
[Epoch 5, Batch 100] loss: 0.03374903742696915
[Epoch 5, Batch 200] loss: 0.051632771278746076
[Epoch 5, Batch 300] loss: 0.01731727156075067
[Epoch 5, Batch 400] loss: 0.02460628676642955
[Epoch 5, Batch 500] loss: 0.014352177344753726
[Epoch 5, Batch 600] loss: 0.022924462335595308
[Epoch 5, Batch 700] loss: 0.021501652223305426
[Epoch 5, Batch 800] loss: 0.028132577087853862
[Epoch 5, Batch 900] loss: 0.02866902424735599
[Epoch 5, Batch 1000] loss: 0.030235778269561708
[Epoch 5, Batch 1100] loss: 0.03292699134603026
[Epoch 5, Batch 1200] loss: 0.031144279930504126
[Epoch 5, Batch 1300] loss: 0.04544732737318555
[Epoch 5, Batch 1400] loss: 0.03528680670940958
[Epoch 5, Batch 1500] loss: 0.02236652497165778
[Epoch 5, Batch 1600] loss: 0.03685411424710765
[Epoch 5, Batch 1700] loss: 0.03401292749891582
[Epoch 5, Batch 1800] loss: 0.023506896640610647
[Epoch 5, Batch 1900] loss: 0.017666536226643076
[Epoch 5, Batch 2000] loss: 0.023041253778064857
[Epoch 5, Batch 2100] loss: 0.017065488797597936
[Epoch 5, Batch 2200] loss: 0.018651285934538464
[Epoch 5, Batch 2300] loss: 0.017971440279252418
[Epoch 5, Batch 2400] loss: 0.03245464706772509
[Epoch 5, Batch 2500] loss: 0.02881715891442582
[Epoch 5, Batch 2600] loss: 0.02426022734864091
[Epoch 5, Batch 2700] loss: 0.02021503018160729
[Epoch 5, Batch 2800] loss: 0.018332312320817435
[Epoch 5, Batch 2900] loss: 0.02883144029005052
[Epoch 5, Batch 3000] loss: 0.038287538790609685
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9869
Overfitting: 0.0474
Best model saved at epoch 5 with validation loss: 0.0474
[Epoch 6, Batch 100] loss: 0.022207107833783084
[Epoch 6, Batch 200] loss: 0.013178834199252379
[Epoch 6, Batch 300] loss: 0.024980844953697668
[Epoch 6, Batch 400] loss: 0.01341757000558573
[Epoch 6, Batch 500] loss: 0.027564349927306466
[Epoch 6, Batch 600] loss: 0.020710175728199828
[Epoch 6, Batch 700] loss: 0.022410067722630628
[Epoch 6, Batch 800] loss: 0.0181289823944644
[Epoch 6, Batch 900] loss: 0.02492219113431929
[Epoch 6, Batch 1000] loss: 0.023561372137446596
[Epoch 6, Batch 1100] loss: 0.025960934745635312
[Epoch 6, Batch 1200] loss: 0.016005583181176918
[Epoch 6, Batch 1300] loss: 0.021458006317297985
[Epoch 6, Batch 1400] loss: 0.016753490895134747
[Epoch 6, Batch 1500] loss: 0.01290824332005286
[Epoch 6, Batch 1600] loss: 0.02136736297212792
[Epoch 6, Batch 1700] loss: 0.030018197331210104
[Epoch 6, Batch 1800] loss: 0.02569246335731805
[Epoch 6, Batch 1900] loss: 0.033489863654958756
[Epoch 6, Batch 2000] loss: 0.029992750574238017
[Epoch 6, Batch 2100] loss: 0.015154304572570254
[Epoch 6, Batch 2200] loss: 0.01982787602834378
[Epoch 6, Batch 2300] loss: 0.03643999950727448
[Epoch 6, Batch 2400] loss: 0.022151834397136555
[Epoch 6, Batch 2500] loss: 0.018718854930848464
[Epoch 6, Batch 2600] loss: 0.01592754957760917
[Epoch 6, Batch 2700] loss: 0.03429138312199939
[Epoch 6, Batch 2800] loss: 0.027377342313411646
[Epoch 6, Batch 2900] loss: 0.019591109737957593
[Epoch 6, Batch 3000] loss: 0.01917329920503107
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9856
Overfitting: 0.0514
[Epoch 7, Batch 100] loss: 0.020054691425575585
[Epoch 7, Batch 200] loss: 0.012424262907661614
[Epoch 7, Batch 300] loss: 0.023649676137483765
[Epoch 7, Batch 400] loss: 0.0179467786708301
[Epoch 7, Batch 500] loss: 0.016112904278270435
[Epoch 7, Batch 600] loss: 0.007160323743964909
[Epoch 7, Batch 700] loss: 0.019420001503481218
[Epoch 7, Batch 800] loss: 0.01448945930193986
[Epoch 7, Batch 900] loss: 0.017078934494593342
[Epoch 7, Batch 1000] loss: 0.021545280673444724
[Epoch 7, Batch 1100] loss: 0.008284857422313507
[Epoch 7, Batch 1200] loss: 0.021687253094014522
[Epoch 7, Batch 1300] loss: 0.023881387718283804
[Epoch 7, Batch 1400] loss: 0.00909807897216524
[Epoch 7, Batch 1500] loss: 0.007460644427364969
[Epoch 7, Batch 1600] loss: 0.010531804707343327
[Epoch 7, Batch 1700] loss: 0.016346210779101967
[Epoch 7, Batch 1800] loss: 0.012192166586064559
[Epoch 7, Batch 1900] loss: 0.023532054387014795
[Epoch 7, Batch 2000] loss: 0.03182486763296765
[Epoch 7, Batch 2100] loss: 0.029096631311149396
[Epoch 7, Batch 2200] loss: 0.016265497318709094
[Epoch 7, Batch 2300] loss: 0.018360282959802136
[Epoch 7, Batch 2400] loss: 0.03337197188735445
[Epoch 7, Batch 2500] loss: 0.03192167557335779
[Epoch 7, Batch 2600] loss: 0.02986173612274797
[Epoch 7, Batch 2700] loss: 0.03112657141917225
[Epoch 7, Batch 2800] loss: 0.01745723738677043
[Epoch 7, Batch 2900] loss: 0.013529413127107546
[Epoch 7, Batch 3000] loss: 0.01446229485574804
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9865
Overfitting: 0.0477
[Epoch 8, Batch 100] loss: 0.008503377014291687
[Epoch 8, Batch 200] loss: 0.017299622237824223
[Epoch 8, Batch 300] loss: 0.010235510689308286
[Epoch 8, Batch 400] loss: 0.007689968963441061
[Epoch 8, Batch 500] loss: 0.013262242859836989
[Epoch 8, Batch 600] loss: 0.005183540613988953
[Epoch 8, Batch 700] loss: 0.020696754496748328
[Epoch 8, Batch 800] loss: 0.012801044768980318
[Epoch 8, Batch 900] loss: 0.022620591189161134
[Epoch 8, Batch 1000] loss: 0.01617149119458645
[Epoch 8, Batch 1100] loss: 0.016287773511667183
[Epoch 8, Batch 1200] loss: 0.01725606216307824
[Epoch 8, Batch 1300] loss: 0.013171105072819956
[Epoch 8, Batch 1400] loss: 0.008464936030563877
[Epoch 8, Batch 1500] loss: 0.014340674174904961
[Epoch 8, Batch 1600] loss: 0.021678437522127753
[Epoch 8, Batch 1700] loss: 0.021934351868967496
[Epoch 8, Batch 1800] loss: 0.02355479633544519
[Epoch 8, Batch 1900] loss: 0.005902100765647447
[Epoch 8, Batch 2000] loss: 0.024202638862689127
[Epoch 8, Batch 2100] loss: 0.011618059112115588
[Epoch 8, Batch 2200] loss: 0.007566062098217117
[Epoch 8, Batch 2300] loss: 0.007265456764980627
[Epoch 8, Batch 2400] loss: 0.02266413677968103
[Epoch 8, Batch 2500] loss: 0.017672723297746416
[Epoch 8, Batch 2600] loss: 0.015643291031997252
[Epoch 8, Batch 2700] loss: 0.01213036984446262
[Epoch 8, Batch 2800] loss: 0.017832465673363912
[Epoch 8, Batch 2900] loss: 0.010589675399460248
[Epoch 8, Batch 3000] loss: 0.011475290176510953
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0406
Validation Accuracy: 0.9879
Overfitting: 0.0406
Best model saved at epoch 8 with validation loss: 0.0406
[Epoch 9, Batch 100] loss: 0.008657393276071162
[Epoch 9, Batch 200] loss: 0.008903971777951937
[Epoch 9, Batch 300] loss: 0.0032470825464702103
[Epoch 9, Batch 400] loss: 0.017162654691417173
[Epoch 9, Batch 500] loss: 0.00949176401760269
[Epoch 9, Batch 600] loss: 0.014752529326258354
[Epoch 9, Batch 700] loss: 0.006100015026186156
[Epoch 9, Batch 800] loss: 0.007834669823894273
[Epoch 9, Batch 900] loss: 0.020135637821936142
[Epoch 9, Batch 1000] loss: 0.008799919133398362
[Epoch 9, Batch 1100] loss: 0.013886168422723132
[Epoch 9, Batch 1200] loss: 0.009359242844936944
[Epoch 9, Batch 1300] loss: 0.007022947354477083
[Epoch 9, Batch 1400] loss: 0.012955828213630411
[Epoch 9, Batch 1500] loss: 0.007713192504794506
[Epoch 9, Batch 1600] loss: 0.006508665326798564
[Epoch 9, Batch 1700] loss: 0.00987639883577458
[Epoch 9, Batch 1800] loss: 0.014038124690152927
[Epoch 9, Batch 1900] loss: 0.005768238342462837
[Epoch 9, Batch 2000] loss: 0.007234811861481489
[Epoch 9, Batch 2100] loss: 0.01794259866004097
[Epoch 9, Batch 2200] loss: 0.013645724090574731
[Epoch 9, Batch 2300] loss: 0.010156873709397586
[Epoch 9, Batch 2400] loss: 0.010406917190229023
[Epoch 9, Batch 2500] loss: 0.008263998269221702
[Epoch 9, Batch 2600] loss: 0.009973633418101712
[Epoch 9, Batch 2700] loss: 0.045264857278178854
[Epoch 9, Batch 2800] loss: 0.024805474952909207
[Epoch 9, Batch 2900] loss: 0.023512819959332774
[Epoch 9, Batch 3000] loss: 0.013706650494373206
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9888
Overfitting: 0.0436
[Epoch 10, Batch 100] loss: 0.0078445646539285
[Epoch 10, Batch 200] loss: 0.00954726098475021
[Epoch 10, Batch 300] loss: 0.009821492189817036
[Epoch 10, Batch 400] loss: 0.00399567306472477
[Epoch 10, Batch 500] loss: 0.009606555407333416
[Epoch 10, Batch 600] loss: 0.008563782391870518
[Epoch 10, Batch 700] loss: 0.003767239629838741
[Epoch 10, Batch 800] loss: 0.006792731410678243
[Epoch 10, Batch 900] loss: 0.005317380664771463
[Epoch 10, Batch 1000] loss: 0.012389622230228952
[Epoch 10, Batch 1100] loss: 0.009023014030067316
[Epoch 10, Batch 1200] loss: 0.007541886203800914
[Epoch 10, Batch 1300] loss: 0.014443306064649733
[Epoch 10, Batch 1400] loss: 0.015389335349400426
[Epoch 10, Batch 1500] loss: 0.005610849913011862
[Epoch 10, Batch 1600] loss: 0.010039895759935007
[Epoch 10, Batch 1700] loss: 0.011044838719708423
[Epoch 10, Batch 1800] loss: 0.013034712512240958
[Epoch 10, Batch 1900] loss: 0.016426495979867468
[Epoch 10, Batch 2000] loss: 0.011812592080588047
[Epoch 10, Batch 2100] loss: 0.013205013856853043
[Epoch 10, Batch 2200] loss: 0.0039067477773164685
[Epoch 10, Batch 2300] loss: 0.010275099829304963
[Epoch 10, Batch 2400] loss: 0.004018854356349948
[Epoch 10, Batch 2500] loss: 0.020450543081863087
[Epoch 10, Batch 2600] loss: 0.019860995296775742
[Epoch 10, Batch 2700] loss: 0.008481699369697253
[Epoch 10, Batch 2800] loss: 0.006698197971336413
[Epoch 10, Batch 2900] loss: 0.0158478819648235
[Epoch 10, Batch 3000] loss: 0.010237214021399267
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9878
Overfitting: 0.0476
[Epoch 11, Batch 100] loss: 0.006796055238339704
[Epoch 11, Batch 200] loss: 0.008506054492602288
[Epoch 11, Batch 300] loss: 0.005520530547912585
[Epoch 11, Batch 400] loss: 0.004508732353430673
[Epoch 11, Batch 500] loss: 0.006262191705694704
[Epoch 11, Batch 600] loss: 0.004104953553660379
[Epoch 11, Batch 700] loss: 0.0028944417626951234
[Epoch 11, Batch 800] loss: 0.00764463800372937
[Epoch 11, Batch 900] loss: 0.003221047787188809
[Epoch 11, Batch 1000] loss: 0.003948826402740906
[Epoch 11, Batch 1100] loss: 0.011801782599419539
[Epoch 11, Batch 1200] loss: 0.007169496794838892
[Epoch 11, Batch 1300] loss: 0.010208261897765851
[Epoch 11, Batch 1400] loss: 0.004338253682276729
[Epoch 11, Batch 1500] loss: 0.005788749441690868
[Epoch 11, Batch 1600] loss: 0.0018095425142803379
[Epoch 11, Batch 1700] loss: 0.007221013491572421
[Epoch 11, Batch 1800] loss: 0.006055245185982301
[Epoch 11, Batch 1900] loss: 0.011869833504497364
[Epoch 11, Batch 2000] loss: 0.016647613141791452
[Epoch 11, Batch 2100] loss: 0.007003038364797476
[Epoch 11, Batch 2200] loss: 0.030982150481101485
[Epoch 11, Batch 2300] loss: 0.008180730855099795
[Epoch 11, Batch 2400] loss: 0.01715796154155214
[Epoch 11, Batch 2500] loss: 0.00929780614598144
[Epoch 11, Batch 2600] loss: 0.007455726350694931
[Epoch 11, Batch 2700] loss: 0.006189367214940376
[Epoch 11, Batch 2800] loss: 0.01039911899978506
[Epoch 11, Batch 2900] loss: 0.00529900873646966
[Epoch 11, Batch 3000] loss: 0.011212440119663825
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9886
Overfitting: 0.0459
[Epoch 12, Batch 100] loss: 0.003966452477446865
[Epoch 12, Batch 200] loss: 0.011227989752729855
[Epoch 12, Batch 300] loss: 0.005033696589008514
[Epoch 12, Batch 400] loss: 0.006423133112672872
[Epoch 12, Batch 500] loss: 0.0063038448813725265
[Epoch 12, Batch 600] loss: 0.01052404166246589
[Epoch 12, Batch 700] loss: 0.011069807617414823
[Epoch 12, Batch 800] loss: 0.004077780249737373
[Epoch 12, Batch 900] loss: 0.004395636098347495
[Epoch 12, Batch 1000] loss: 0.0037538678545536185
[Epoch 12, Batch 1100] loss: 0.0019491338450947637
[Epoch 12, Batch 1200] loss: 0.006131230524023295
[Epoch 12, Batch 1300] loss: 0.017387931288734216
[Epoch 12, Batch 1400] loss: 0.0037212462379784482
[Epoch 12, Batch 1500] loss: 0.005114572513483324
[Epoch 12, Batch 1600] loss: 0.004402801007055502
[Epoch 12, Batch 1700] loss: 0.006388235979507044
[Epoch 12, Batch 1800] loss: 0.009828215936741814
[Epoch 12, Batch 1900] loss: 0.007268562779350702
[Epoch 12, Batch 2000] loss: 0.006876807725627714
[Epoch 12, Batch 2100] loss: 0.007253492493272801
[Epoch 12, Batch 2200] loss: 0.011869483443934428
[Epoch 12, Batch 2300] loss: 0.005392947430831328
[Epoch 12, Batch 2400] loss: 0.011770151623373977
[Epoch 12, Batch 2500] loss: 0.004322733990388201
[Epoch 12, Batch 2600] loss: 0.003268930414134843
[Epoch 12, Batch 2700] loss: 0.011790221657801964
[Epoch 12, Batch 2800] loss: 0.013583574998438052
[Epoch 12, Batch 2900] loss: 0.00903650077306679
[Epoch 12, Batch 3000] loss: 0.0055539485475679835
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0432
Validation Accuracy: 0.9899
Overfitting: 0.0432
[Epoch 13, Batch 100] loss: 0.010025362213152818
[Epoch 13, Batch 200] loss: 0.009102644877398234
[Epoch 13, Batch 300] loss: 0.0033948721043189777
[Epoch 13, Batch 400] loss: 0.004455002898262137
[Epoch 13, Batch 500] loss: 0.007710800710315908
[Epoch 13, Batch 600] loss: 0.004128656171666023
[Epoch 13, Batch 700] loss: 0.008937228050039039
[Epoch 13, Batch 800] loss: 0.0034989567263909293
[Epoch 13, Batch 900] loss: 0.007280548968362268
[Epoch 13, Batch 1000] loss: 0.0042858242336706095
[Epoch 13, Batch 1100] loss: 0.006769345720296229
[Epoch 13, Batch 1200] loss: 0.0047778479220451685
[Epoch 13, Batch 1300] loss: 0.01597725411603349
[Epoch 13, Batch 1400] loss: 0.0034643761702977827
[Epoch 13, Batch 1500] loss: 0.00718615118517981
[Epoch 13, Batch 1600] loss: 0.0030840051152875958
[Epoch 13, Batch 1700] loss: 0.0048680411172108504
[Epoch 13, Batch 1800] loss: 0.006977710158186028
[Epoch 13, Batch 1900] loss: 0.009535496612799114
[Epoch 13, Batch 2000] loss: 0.003961007819829376
[Epoch 13, Batch 2100] loss: 0.0046366731993870754
[Epoch 13, Batch 2200] loss: 0.0077034493569112785
[Epoch 13, Batch 2300] loss: 0.0046583386239373685
[Epoch 13, Batch 2400] loss: 0.001980192963551133
[Epoch 13, Batch 2500] loss: 0.0065392464436826005
[Epoch 13, Batch 2600] loss: 0.006869498678257031
[Epoch 13, Batch 2700] loss: 0.0031386317014153063
[Epoch 13, Batch 2800] loss: 0.006290941943283883
[Epoch 13, Batch 2900] loss: 0.001126564492507427
[Epoch 13, Batch 3000] loss: 0.007037438631355215
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9903
Overfitting: 0.0436
[Epoch 14, Batch 100] loss: 0.002558750451476044
[Epoch 14, Batch 200] loss: 0.00259935660072955
[Epoch 14, Batch 300] loss: 0.0032959893534629716
[Epoch 14, Batch 400] loss: 0.009052615510680652
[Epoch 14, Batch 500] loss: 0.004921144301328297
[Epoch 14, Batch 600] loss: 0.029565262049026975
[Epoch 14, Batch 700] loss: 0.016126966805193776
[Epoch 14, Batch 800] loss: 0.002392043299046236
[Epoch 14, Batch 900] loss: 0.000638144766049713
[Epoch 14, Batch 1000] loss: 0.0021734469456498574
[Epoch 14, Batch 1100] loss: 0.002291267865656721
[Epoch 14, Batch 1200] loss: 0.008271736695780163
[Epoch 14, Batch 1300] loss: 0.005218123204387836
[Epoch 14, Batch 1400] loss: 0.002373893467592154
[Epoch 14, Batch 1500] loss: 0.003857583905158606
[Epoch 14, Batch 1600] loss: 0.01257363496330953
[Epoch 14, Batch 1700] loss: 0.015454406096632739
[Epoch 14, Batch 1800] loss: 0.00798028399635939
[Epoch 14, Batch 1900] loss: 0.005912145327710334
[Epoch 14, Batch 2000] loss: 0.005722544049042995
[Epoch 14, Batch 2100] loss: 0.006802561374769454
[Epoch 14, Batch 2200] loss: 0.011560097526360452
[Epoch 14, Batch 2300] loss: 0.0036184970917773284
[Epoch 14, Batch 2400] loss: 0.00634898798405608
[Epoch 14, Batch 2500] loss: 0.004033510575075354
[Epoch 14, Batch 2600] loss: 0.008604552319247886
[Epoch 14, Batch 2700] loss: 0.006148613248264673
[Epoch 14, Batch 2800] loss: 0.006734326510198798
[Epoch 14, Batch 2900] loss: 0.01273350886535468
[Epoch 14, Batch 3000] loss: 0.013242966562293646
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0634
Validation Accuracy: 0.9852
Overfitting: 0.0634
[Epoch 15, Batch 100] loss: 0.019242687245802016
[Epoch 15, Batch 200] loss: 0.00817389527649567
[Epoch 15, Batch 300] loss: 0.01091116539517671
[Epoch 15, Batch 400] loss: 0.0022018466609949883
[Epoch 15, Batch 500] loss: 0.01462879511750515
[Epoch 15, Batch 600] loss: 0.002366189864791295
[Epoch 15, Batch 700] loss: 0.02036097948102302
[Epoch 15, Batch 800] loss: 0.008237680739800836
[Epoch 15, Batch 900] loss: 0.010153282360507774
[Epoch 15, Batch 1000] loss: 0.005664144200729595
[Epoch 15, Batch 1100] loss: 0.010174685110525274
[Epoch 15, Batch 1200] loss: 0.008682523141860372
[Epoch 15, Batch 1300] loss: 0.0050667896520071665
[Epoch 15, Batch 1400] loss: 0.009190606501639848
[Epoch 15, Batch 1500] loss: 0.0066721504015640675
[Epoch 15, Batch 1600] loss: 0.005435622277098986
[Epoch 15, Batch 1700] loss: 0.009875891942848786
[Epoch 15, Batch 1800] loss: 0.00316053752818803
[Epoch 15, Batch 1900] loss: 0.007909495820392038
[Epoch 15, Batch 2000] loss: 0.004456062526388678
[Epoch 15, Batch 2100] loss: 0.008414122402593307
[Epoch 15, Batch 2200] loss: 0.014953519156755704
[Epoch 15, Batch 2300] loss: 0.004403095879696561
[Epoch 15, Batch 2400] loss: 0.006402141546867596
[Epoch 15, Batch 2500] loss: 0.007062311198469047
[Epoch 15, Batch 2600] loss: 0.01858435129763194
[Epoch 15, Batch 2700] loss: 0.002181024495766053
[Epoch 15, Batch 2800] loss: 0.0051325225372136525
[Epoch 15, Batch 2900] loss: 0.0015856550355146126
[Epoch 15, Batch 3000] loss: 0.003882531856365787
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9900
Overfitting: 0.0475
[Epoch 16, Batch 100] loss: 0.002429136716833398
[Epoch 16, Batch 200] loss: 0.0018769233367084937
[Epoch 16, Batch 300] loss: 0.0008458475771174445
[Epoch 16, Batch 400] loss: 0.0012442951354533173
[Epoch 16, Batch 500] loss: 0.002830006192144623
[Epoch 16, Batch 600] loss: 0.0035476827647038744
[Epoch 16, Batch 700] loss: 0.0015751778586535047
[Epoch 16, Batch 800] loss: 0.0030235024062518034
[Epoch 16, Batch 900] loss: 0.0010638352293339003
[Epoch 16, Batch 1000] loss: 0.0018464673725086512
[Epoch 16, Batch 1100] loss: 0.0018722003278894127
[Epoch 16, Batch 1200] loss: 0.0009512825820877424
[Epoch 16, Batch 1300] loss: 0.0012878983660328514
[Epoch 16, Batch 1400] loss: 0.0007734770804203972
[Epoch 16, Batch 1500] loss: 0.015548026342383645
[Epoch 16, Batch 1600] loss: 0.00221048209585776
[Epoch 16, Batch 1700] loss: 0.007655892892791946
[Epoch 16, Batch 1800] loss: 0.006052805838124291
[Epoch 16, Batch 1900] loss: 0.002155903185819099
[Epoch 16, Batch 2000] loss: 0.007051289549926878
[Epoch 16, Batch 2100] loss: 0.0048840124898777044
[Epoch 16, Batch 2200] loss: 0.009475061892894345
[Epoch 16, Batch 2300] loss: 0.002977887106460031
[Epoch 16, Batch 2400] loss: 0.007832278116030409
[Epoch 16, Batch 2500] loss: 0.003432669957225727
[Epoch 16, Batch 2600] loss: 0.0034246134507810665
[Epoch 16, Batch 2700] loss: 0.002402529951665424
[Epoch 16, Batch 2800] loss: 0.005825536832922183
[Epoch 16, Batch 2900] loss: 0.005421695817934165
[Epoch 16, Batch 3000] loss: 0.0021538748166466306
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9895
Overfitting: 0.0542
[Epoch 17, Batch 100] loss: 0.001755196386025233
[Epoch 17, Batch 200] loss: 0.005339223656851146
[Epoch 17, Batch 300] loss: 0.002743211520832771
[Epoch 17, Batch 400] loss: 0.010392656872484593
[Epoch 17, Batch 500] loss: 0.0036822705426348356
[Epoch 17, Batch 600] loss: 0.0016391864688095304
[Epoch 17, Batch 700] loss: 0.0009031711587570612
[Epoch 17, Batch 800] loss: 0.0029946785508349017
[Epoch 17, Batch 900] loss: 0.0014909759870462124
[Epoch 17, Batch 1000] loss: 0.0016480705212359227
[Epoch 17, Batch 1100] loss: 0.0012731989062036676
[Epoch 17, Batch 1200] loss: 0.0020870138191575196
[Epoch 17, Batch 1300] loss: 0.0011671260564386898
[Epoch 17, Batch 1400] loss: 0.0018407662079701305
[Epoch 17, Batch 1500] loss: 0.0013166330030786354
[Epoch 17, Batch 1600] loss: 0.0036801932972234043
[Epoch 17, Batch 1700] loss: 0.0012401662031696415
[Epoch 17, Batch 1800] loss: 0.003740624178250016
[Epoch 17, Batch 1900] loss: 0.007383470603027469
[Epoch 17, Batch 2000] loss: 0.004382215751887255
[Epoch 17, Batch 2100] loss: 0.005780411736511235
[Epoch 17, Batch 2200] loss: 0.00851536353903913
[Epoch 17, Batch 2300] loss: 0.004160528491990774
[Epoch 17, Batch 2400] loss: 0.0004970372169677262
[Epoch 17, Batch 2500] loss: 0.0008331464426458002
[Epoch 17, Batch 2600] loss: 0.0056817313561199215
[Epoch 17, Batch 2700] loss: 0.003577966753686397
[Epoch 17, Batch 2800] loss: 0.004914051251257216
[Epoch 17, Batch 2900] loss: 0.00760404745398283
[Epoch 17, Batch 3000] loss: 0.009568851316380673
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9883
Overfitting: 0.0514
[Epoch 18, Batch 100] loss: 0.0039060056359017637
[Epoch 18, Batch 200] loss: 0.002326644716293522
[Epoch 18, Batch 300] loss: 0.00445479048228858
[Epoch 18, Batch 400] loss: 0.001316933199884831
[Epoch 18, Batch 500] loss: 0.0016797060040873557
[Epoch 18, Batch 600] loss: 0.0008140089766719783
[Epoch 18, Batch 700] loss: 0.004304248294222859
[Epoch 18, Batch 800] loss: 0.0006216137232465257
[Epoch 18, Batch 900] loss: 0.0052884717022832995
[Epoch 18, Batch 1000] loss: 0.006438703598166171
[Epoch 18, Batch 1100] loss: 0.005335958377256276
[Epoch 18, Batch 1200] loss: 0.010820015981657742
[Epoch 18, Batch 1300] loss: 0.0043955304174589215
[Epoch 18, Batch 1400] loss: 0.006458877057825667
[Epoch 18, Batch 1500] loss: 0.0012651214631669739
[Epoch 18, Batch 1600] loss: 0.004474550720618495
[Epoch 18, Batch 1700] loss: 0.00836243543430768
[Epoch 18, Batch 1800] loss: 0.010184781980563287
[Epoch 18, Batch 1900] loss: 0.003465564655009956
[Epoch 18, Batch 2000] loss: 0.00478537092145114
[Epoch 18, Batch 2100] loss: 0.006031869432158459
[Epoch 18, Batch 2200] loss: 0.0025106056080062755
[Epoch 18, Batch 2300] loss: 0.0031135390918906624
[Epoch 18, Batch 2400] loss: 0.0050046410449715315
[Epoch 18, Batch 2500] loss: 0.009584888593203505
[Epoch 18, Batch 2600] loss: 0.0018838660338936109
[Epoch 18, Batch 2700] loss: 0.0012746330831124198
[Epoch 18, Batch 2800] loss: 0.010580667924143139
[Epoch 18, Batch 2900] loss: 0.006089612068662121
[Epoch 18, Batch 3000] loss: 0.004646248479640925
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9876
Overfitting: 0.0576
[Epoch 19, Batch 100] loss: 0.0012443598197805095
[Epoch 19, Batch 200] loss: 0.0007713946442992636
[Epoch 19, Batch 300] loss: 0.0069562803016435335
[Epoch 19, Batch 400] loss: 0.0048211153597113345
[Epoch 19, Batch 500] loss: 0.0010460454233339788
[Epoch 19, Batch 600] loss: 0.000836418620743693
[Epoch 19, Batch 700] loss: 0.0005723169798507444
[Epoch 19, Batch 800] loss: 0.0009757098804111308
[Epoch 19, Batch 900] loss: 0.0009953119302126678
[Epoch 19, Batch 1000] loss: 0.00145157849762501
[Epoch 19, Batch 1100] loss: 0.001687745563144345
[Epoch 19, Batch 1200] loss: 0.00033664750274794655
[Epoch 19, Batch 1300] loss: 0.0006492863763472956
[Epoch 19, Batch 1400] loss: 0.0010057463394653433
[Epoch 19, Batch 1500] loss: 0.0032720229810808375
[Epoch 19, Batch 1600] loss: 0.0006954685273117134
[Epoch 19, Batch 1700] loss: 0.0003661495129605896
[Epoch 19, Batch 1800] loss: 0.0004060445223108955
[Epoch 19, Batch 1900] loss: 0.0013630872496082258
[Epoch 19, Batch 2000] loss: 0.0002057534841209474
[Epoch 19, Batch 2100] loss: 0.00040049136874026114
[Epoch 19, Batch 2200] loss: 0.000574709517925358
[Epoch 19, Batch 2300] loss: 0.0006917083003343017
[Epoch 19, Batch 2400] loss: 0.0010801453312374277
[Epoch 19, Batch 2500] loss: 0.000288686070183668
[Epoch 19, Batch 2600] loss: 0.0017720523745942307
[Epoch 19, Batch 2700] loss: 0.0009848150290045822
[Epoch 19, Batch 2800] loss: 0.00042896710909736237
[Epoch 19, Batch 2900] loss: 0.0016872261832323642
[Epoch 19, Batch 3000] loss: 0.0072405933039822925
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0574
Validation Accuracy: 0.9894
Overfitting: 0.0574
[Epoch 20, Batch 100] loss: 0.0008348764588315216
[Epoch 20, Batch 200] loss: 0.0006128531348365573
[Epoch 20, Batch 300] loss: 0.004912595747609547
[Epoch 20, Batch 400] loss: 0.001933127070575118
[Epoch 20, Batch 500] loss: 0.0005118228871298092
[Epoch 20, Batch 600] loss: 0.00035980447275900217
[Epoch 20, Batch 700] loss: 0.0022137279045384784
[Epoch 20, Batch 800] loss: 0.00021905995439510216
[Epoch 20, Batch 900] loss: 0.0001783629550565191
[Epoch 20, Batch 1000] loss: 0.0033483630604167125
[Epoch 20, Batch 1100] loss: 0.0012476020984631608
[Epoch 20, Batch 1200] loss: 0.0012203587845154428
[Epoch 20, Batch 1300] loss: 0.0007279755277941869
[Epoch 20, Batch 1400] loss: 0.004978078230054126
[Epoch 20, Batch 1500] loss: 0.0009213437286984138
[Epoch 20, Batch 1600] loss: 0.0005509033596315005
[Epoch 20, Batch 1700] loss: 0.000494633681010943
[Epoch 20, Batch 1800] loss: 0.0014902080271853623
[Epoch 20, Batch 1900] loss: 0.0001860556998045171
[Epoch 20, Batch 2000] loss: 0.0004114921090320145
[Epoch 20, Batch 2100] loss: 0.0002511376361414319
[Epoch 20, Batch 2200] loss: 0.00044625118605834846
[Epoch 20, Batch 2300] loss: 0.0002472446778092241
[Epoch 20, Batch 2400] loss: 0.0001104025280766896
[Epoch 20, Batch 2500] loss: 0.0005168078172606804
[Epoch 20, Batch 2600] loss: 0.0008026277263864401
[Epoch 20, Batch 2700] loss: 0.0008550015980400393
[Epoch 20, Batch 2800] loss: 0.0008164273827548208
[Epoch 20, Batch 2900] loss: 0.0006376340224534394
[Epoch 20, Batch 3000] loss: 0.00030679241718490236
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9910
Overfitting: 0.0474
[Epoch 21, Batch 100] loss: 0.00028252244016058637
[Epoch 21, Batch 200] loss: 0.0002989072642323887
[Epoch 21, Batch 300] loss: 0.00010450085177617475
[Epoch 21, Batch 400] loss: 0.00030189589044714803
[Epoch 21, Batch 500] loss: 0.0001318553772472697
[Epoch 21, Batch 600] loss: 0.0003214043275263023
[Epoch 21, Batch 700] loss: 0.0002076921830333589
[Epoch 21, Batch 800] loss: 0.000323163791979808
[Epoch 21, Batch 900] loss: 0.00013364242333403276
[Epoch 21, Batch 1000] loss: 0.0002782104629341609
[Epoch 21, Batch 1100] loss: 0.00018929650324600366
[Epoch 21, Batch 1200] loss: 0.00016871153992796816
[Epoch 21, Batch 1300] loss: 0.0002438860234497353
[Epoch 21, Batch 1400] loss: 0.00012884185934561199
[Epoch 21, Batch 1500] loss: 8.584697705560807e-05
[Epoch 21, Batch 1600] loss: 0.00010975312253636904
[Epoch 21, Batch 1700] loss: 5.607181800967531e-05
[Epoch 21, Batch 1800] loss: 0.0001641689970250182
[Epoch 21, Batch 1900] loss: 6.63592027597737e-05
[Epoch 21, Batch 2000] loss: 0.00018756827620972416
[Epoch 21, Batch 2100] loss: 6.122370950108369e-05
[Epoch 21, Batch 2200] loss: 6.757515311726082e-05
[Epoch 21, Batch 2300] loss: 9.994605296502535e-05
[Epoch 21, Batch 2400] loss: 0.00013954500259338865
[Epoch 21, Batch 2500] loss: 0.00024398632134098986
[Epoch 21, Batch 2600] loss: 0.00015455067732145
[Epoch 21, Batch 2700] loss: 0.0008398988909657889
[Epoch 21, Batch 2800] loss: 0.002900201974505876
[Epoch 21, Batch 2900] loss: 0.0002444049740731913
[Epoch 21, Batch 3000] loss: 0.0022550441146717403
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9892
Overfitting: 0.0636
[Epoch 22, Batch 100] loss: 0.009029167181212853
[Epoch 22, Batch 200] loss: 0.0022286859526291637
[Epoch 22, Batch 300] loss: 0.004045962889113848
[Epoch 22, Batch 400] loss: 0.0006103973699696397
[Epoch 22, Batch 500] loss: 0.0003714649438553641
[Epoch 22, Batch 600] loss: 0.00034964386766672906
[Epoch 22, Batch 700] loss: 0.0023607395994599887
[Epoch 22, Batch 800] loss: 0.0002722929853106093
[Epoch 22, Batch 900] loss: 0.0021335902520745577
[Epoch 22, Batch 1000] loss: 0.0035159760069641654
[Epoch 22, Batch 1100] loss: 0.00011174575022363964
[Epoch 22, Batch 1200] loss: 0.00023663051109669376
[Epoch 22, Batch 1300] loss: 0.000409176131241189
[Epoch 22, Batch 1400] loss: 0.00017430303361602118
[Epoch 22, Batch 1500] loss: 0.0010260392535510609
[Epoch 22, Batch 1600] loss: 0.0016445553968902349
[Epoch 22, Batch 1700] loss: 0.0006879737178400091
[Epoch 22, Batch 1800] loss: 0.00017025757555379605
[Epoch 22, Batch 1900] loss: 0.0002303482832682313
[Epoch 22, Batch 2000] loss: 0.00042531667346926925
[Epoch 22, Batch 2100] loss: 0.00015296144333619034
[Epoch 22, Batch 2200] loss: 0.0003039893257088355
[Epoch 22, Batch 2300] loss: 0.0005873354159132882
[Epoch 22, Batch 2400] loss: 0.00013110811717920612
[Epoch 22, Batch 2500] loss: 0.00017412658987526976
[Epoch 22, Batch 2600] loss: 0.00033373062149054443
[Epoch 22, Batch 2700] loss: 0.0001046438068504596
[Epoch 22, Batch 2800] loss: 0.000659891743883656
[Epoch 22, Batch 2900] loss: 0.0016162633806352123
[Epoch 22, Batch 3000] loss: 0.00023384808470589658
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9902
Overfitting: 0.0550
[Epoch 23, Batch 100] loss: 0.001329465267994241
[Epoch 23, Batch 200] loss: 0.00045572676405210456
[Epoch 23, Batch 300] loss: 0.0012608709727686706
[Epoch 23, Batch 400] loss: 0.0001119211976439649
[Epoch 23, Batch 500] loss: 8.798011013927187e-05
[Epoch 23, Batch 600] loss: 0.00017711808279452068
[Epoch 23, Batch 700] loss: 0.00011505750092278167
[Epoch 23, Batch 800] loss: 5.189615287807037e-05
[Epoch 23, Batch 900] loss: 0.0002041046355601983
[Epoch 23, Batch 1000] loss: 0.00018704543902308134
[Epoch 23, Batch 1100] loss: 0.007392092961722958
[Epoch 23, Batch 1200] loss: 0.0001807178902086992
[Epoch 23, Batch 1300] loss: 0.001313991714927587
[Epoch 23, Batch 1400] loss: 0.0016894946579376667
[Epoch 23, Batch 1500] loss: 0.0009808242827823177
[Epoch 23, Batch 1600] loss: 0.0005682682481557854
[Epoch 23, Batch 1700] loss: 0.0009443644813249997
[Epoch 23, Batch 1800] loss: 0.0011729961135773027
[Epoch 23, Batch 1900] loss: 0.0007396621138711579
[Epoch 23, Batch 2000] loss: 0.0013611977036495392
[Epoch 23, Batch 2100] loss: 0.004398109011546545
[Epoch 23, Batch 2200] loss: 0.002907008828713007
[Epoch 23, Batch 2300] loss: 0.0005471891538380679
[Epoch 23, Batch 2400] loss: 0.003209793066804774
[Epoch 23, Batch 2500] loss: 0.0005593496003566045
[Epoch 23, Batch 2600] loss: 0.0003873602629203754
[Epoch 23, Batch 2700] loss: 0.0013697039099233033
[Epoch 23, Batch 2800] loss: 0.01011557361195595
[Epoch 23, Batch 2900] loss: 0.0014943669631320856
[Epoch 23, Batch 3000] loss: 0.0014175980479104577
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0580
Validation Accuracy: 0.9894
Overfitting: 0.0580
[Epoch 24, Batch 100] loss: 0.0009576087414533907
[Epoch 24, Batch 200] loss: 0.0028742361513745384
[Epoch 24, Batch 300] loss: 0.003764334921590171
[Epoch 24, Batch 400] loss: 0.0007152464501964939
[Epoch 24, Batch 500] loss: 0.00376466832615022
[Epoch 24, Batch 600] loss: 0.0009018443461784642
[Epoch 24, Batch 700] loss: 0.0009148211178528199
[Epoch 24, Batch 800] loss: 0.00026728857828147936
[Epoch 24, Batch 900] loss: 0.005051689456228767
[Epoch 24, Batch 1000] loss: 0.0021837837630272494
[Epoch 24, Batch 1100] loss: 0.0007521868561823908
[Epoch 24, Batch 1200] loss: 0.00045922946783996557
[Epoch 24, Batch 1300] loss: 0.00994032645652851
[Epoch 24, Batch 1400] loss: 0.005036730493658004
[Epoch 24, Batch 1500] loss: 0.0006294423284268457
[Epoch 24, Batch 1600] loss: 0.0020462657904381175
[Epoch 24, Batch 1700] loss: 0.0010886683979094514
[Epoch 24, Batch 1800] loss: 0.0004842464564976634
[Epoch 24, Batch 1900] loss: 0.00021819488253924658
[Epoch 24, Batch 2000] loss: 0.0013209237285041375
[Epoch 24, Batch 2100] loss: 0.009443668342070874
[Epoch 24, Batch 2200] loss: 0.0003298721682325345
[Epoch 24, Batch 2300] loss: 0.0010827911309674177
[Epoch 24, Batch 2400] loss: 0.0030397713477029243
[Epoch 24, Batch 2500] loss: 0.0008612262314730889
[Epoch 24, Batch 2600] loss: 0.0006182451924034016
[Epoch 24, Batch 2700] loss: 0.0018598289782905608
[Epoch 24, Batch 2800] loss: 0.00925510042916354
[Epoch 24, Batch 2900] loss: 0.0016998359099219896
[Epoch 24, Batch 3000] loss: 0.006791830735448974
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9904
Overfitting: 0.0540
Fold 3 validation loss: 0.0540
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2827941393852234
[Epoch 1, Batch 200] loss: 1.7373619377613068
[Epoch 1, Batch 300] loss: 0.6744958618283272
[Epoch 1, Batch 400] loss: 0.4492697910964489
[Epoch 1, Batch 500] loss: 0.32280773820355535
[Epoch 1, Batch 600] loss: 0.24723916681483388
[Epoch 1, Batch 700] loss: 0.22209964787587524
[Epoch 1, Batch 800] loss: 0.18809708875603973
[Epoch 1, Batch 900] loss: 0.16754529478028415
[Epoch 1, Batch 1000] loss: 0.18437656128779054
[Epoch 1, Batch 1100] loss: 0.14597748328698798
[Epoch 1, Batch 1200] loss: 0.14242607707623392
[Epoch 1, Batch 1300] loss: 0.1239277842012234
[Epoch 1, Batch 1400] loss: 0.13857395601458847
[Epoch 1, Batch 1500] loss: 0.13659679997246713
[Epoch 1, Batch 1600] loss: 0.12470559746492654
[Epoch 1, Batch 1700] loss: 0.12106756661087274
[Epoch 1, Batch 1800] loss: 0.09809916028403677
[Epoch 1, Batch 1900] loss: 0.0986771381527069
[Epoch 1, Batch 2000] loss: 0.0881639098841697
[Epoch 1, Batch 2100] loss: 0.10964021148975008
[Epoch 1, Batch 2200] loss: 0.10368917053099722
[Epoch 1, Batch 2300] loss: 0.12048683622619137
[Epoch 1, Batch 2400] loss: 0.09610829989891499
[Epoch 1, Batch 2500] loss: 0.1362134937744122
[Epoch 1, Batch 2600] loss: 0.11175592436804437
[Epoch 1, Batch 2700] loss: 0.09068821801338345
[Epoch 1, Batch 2800] loss: 0.0810652752785245
[Epoch 1, Batch 2900] loss: 0.1133556217426667
[Epoch 1, Batch 3000] loss: 0.07019904183427571
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0806
Validation Accuracy: 0.9748
Overfitting: 0.0806
Best model saved at epoch 1 with validation loss: 0.0806
[Epoch 2, Batch 100] loss: 0.08071869763254653
[Epoch 2, Batch 200] loss: 0.05487628977221903
[Epoch 2, Batch 300] loss: 0.0740094649681123
[Epoch 2, Batch 400] loss: 0.08456557088531554
[Epoch 2, Batch 500] loss: 0.08275004636030645
[Epoch 2, Batch 600] loss: 0.07016261603159364
[Epoch 2, Batch 700] loss: 0.06604505679802969
[Epoch 2, Batch 800] loss: 0.09785948012256995
[Epoch 2, Batch 900] loss: 0.054860854185535574
[Epoch 2, Batch 1000] loss: 0.08337182717281394
[Epoch 2, Batch 1100] loss: 0.052098116300767286
[Epoch 2, Batch 1200] loss: 0.06579907347972039
[Epoch 2, Batch 1300] loss: 0.05722578463028185
[Epoch 2, Batch 1400] loss: 0.05303999868629035
[Epoch 2, Batch 1500] loss: 0.06101269714956288
[Epoch 2, Batch 1600] loss: 0.05576040094951168
[Epoch 2, Batch 1700] loss: 0.06813965415320127
[Epoch 2, Batch 1800] loss: 0.06650139814126305
[Epoch 2, Batch 1900] loss: 0.04442407302718493
[Epoch 2, Batch 2000] loss: 0.06407588571906672
[Epoch 2, Batch 2100] loss: 0.05973603415186517
[Epoch 2, Batch 2200] loss: 0.046497971964126916
[Epoch 2, Batch 2300] loss: 0.07025489520980045
[Epoch 2, Batch 2400] loss: 0.07049167808043422
[Epoch 2, Batch 2500] loss: 0.07366391981428023
[Epoch 2, Batch 2600] loss: 0.058018399489228614
[Epoch 2, Batch 2700] loss: 0.06265524273840128
[Epoch 2, Batch 2800] loss: 0.08061449366177839
[Epoch 2, Batch 2900] loss: 0.06744393369299359
[Epoch 2, Batch 3000] loss: 0.07638967722887173
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0615
Validation Accuracy: 0.9817
Overfitting: 0.0615
Best model saved at epoch 2 with validation loss: 0.0615
[Epoch 3, Batch 100] loss: 0.0526169960675179
[Epoch 3, Batch 200] loss: 0.052678136782196815
[Epoch 3, Batch 300] loss: 0.04651846798944462
[Epoch 3, Batch 400] loss: 0.05318223946254875
[Epoch 3, Batch 500] loss: 0.03716700205666711
[Epoch 3, Batch 600] loss: 0.042884685913377324
[Epoch 3, Batch 700] loss: 0.06882667607082112
[Epoch 3, Batch 800] loss: 0.04681525499268901
[Epoch 3, Batch 900] loss: 0.04712522958059708
[Epoch 3, Batch 1000] loss: 0.032041414163832084
[Epoch 3, Batch 1100] loss: 0.059028362006065434
[Epoch 3, Batch 1200] loss: 0.05615238932485227
[Epoch 3, Batch 1300] loss: 0.0341473732877057
[Epoch 3, Batch 1400] loss: 0.06423181076403126
[Epoch 3, Batch 1500] loss: 0.05652204516663915
[Epoch 3, Batch 1600] loss: 0.03791181463137036
[Epoch 3, Batch 1700] loss: 0.04210587665103958
[Epoch 3, Batch 1800] loss: 0.03485987721171114
[Epoch 3, Batch 1900] loss: 0.04500154791858222
[Epoch 3, Batch 2000] loss: 0.0533709217311116
[Epoch 3, Batch 2100] loss: 0.06003744406916667
[Epoch 3, Batch 2200] loss: 0.049340890142921125
[Epoch 3, Batch 2300] loss: 0.040975595410272944
[Epoch 3, Batch 2400] loss: 0.03256806595687522
[Epoch 3, Batch 2500] loss: 0.03165873627818655
[Epoch 3, Batch 2600] loss: 0.044113739896929474
[Epoch 3, Batch 2700] loss: 0.03900331230375741
[Epoch 3, Batch 2800] loss: 0.04348408746853238
[Epoch 3, Batch 2900] loss: 0.04732155594421784
[Epoch 3, Batch 3000] loss: 0.04495873320222017
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9839
Overfitting: 0.0516
Best model saved at epoch 3 with validation loss: 0.0516
[Epoch 4, Batch 100] loss: 0.03225191248988267
[Epoch 4, Batch 200] loss: 0.02700677054741391
[Epoch 4, Batch 300] loss: 0.01498569967217918
[Epoch 4, Batch 400] loss: 0.03235128104664909
[Epoch 4, Batch 500] loss: 0.054321674186867314
[Epoch 4, Batch 600] loss: 0.03780578836594941
[Epoch 4, Batch 700] loss: 0.043077457537801817
[Epoch 4, Batch 800] loss: 0.045396333176176994
[Epoch 4, Batch 900] loss: 0.02313355062244227
[Epoch 4, Batch 1000] loss: 0.02483527627453441
[Epoch 4, Batch 1100] loss: 0.028997067267791863
[Epoch 4, Batch 1200] loss: 0.03677333414554596
[Epoch 4, Batch 1300] loss: 0.039798348738913775
[Epoch 4, Batch 1400] loss: 0.024729920239042257
[Epoch 4, Batch 1500] loss: 0.04103438147445559
[Epoch 4, Batch 1600] loss: 0.04253051723644603
[Epoch 4, Batch 1700] loss: 0.034283927391443286
[Epoch 4, Batch 1800] loss: 0.03960639385717513
[Epoch 4, Batch 1900] loss: 0.05208802254550392
[Epoch 4, Batch 2000] loss: 0.024416308412328364
[Epoch 4, Batch 2100] loss: 0.03494345016311854
[Epoch 4, Batch 2200] loss: 0.05045418831839925
[Epoch 4, Batch 2300] loss: 0.026993711965114926
[Epoch 4, Batch 2400] loss: 0.026148502654832553
[Epoch 4, Batch 2500] loss: 0.040335778172448045
[Epoch 4, Batch 2600] loss: 0.03193220788409235
[Epoch 4, Batch 2700] loss: 0.04339172558873543
[Epoch 4, Batch 2800] loss: 0.04556870025160606
[Epoch 4, Batch 2900] loss: 0.03223649597886833
[Epoch 4, Batch 3000] loss: 0.04792470405402128
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0398
Validation Accuracy: 0.9873
Overfitting: 0.0398
Best model saved at epoch 4 with validation loss: 0.0398
[Epoch 5, Batch 100] loss: 0.02311538122212369
[Epoch 5, Batch 200] loss: 0.02834532800668967
[Epoch 5, Batch 300] loss: 0.02895084325798962
[Epoch 5, Batch 400] loss: 0.017110161542441348
[Epoch 5, Batch 500] loss: 0.032247658944324936
[Epoch 5, Batch 600] loss: 0.035238949740305545
[Epoch 5, Batch 700] loss: 0.04597276595290168
[Epoch 5, Batch 800] loss: 0.04158344472474709
[Epoch 5, Batch 900] loss: 0.03100044820275798
[Epoch 5, Batch 1000] loss: 0.032584711155104744
[Epoch 5, Batch 1100] loss: 0.02176984237652505
[Epoch 5, Batch 1200] loss: 0.017162613057007548
[Epoch 5, Batch 1300] loss: 0.02046125574495818
[Epoch 5, Batch 1400] loss: 0.022563857899222058
[Epoch 5, Batch 1500] loss: 0.03264797417217778
[Epoch 5, Batch 1600] loss: 0.028769186409917893
[Epoch 5, Batch 1700] loss: 0.04560789337709139
[Epoch 5, Batch 1800] loss: 0.024402379092789486
[Epoch 5, Batch 1900] loss: 0.02631713543090882
[Epoch 5, Batch 2000] loss: 0.018003850109889755
[Epoch 5, Batch 2100] loss: 0.021917218193993903
[Epoch 5, Batch 2200] loss: 0.03330342241482867
[Epoch 5, Batch 2300] loss: 0.024604158511556305
[Epoch 5, Batch 2400] loss: 0.046786970479006415
[Epoch 5, Batch 2500] loss: 0.01734612226178797
[Epoch 5, Batch 2600] loss: 0.03579077368009166
[Epoch 5, Batch 2700] loss: 0.02803238964334014
[Epoch 5, Batch 2800] loss: 0.0372999672331207
[Epoch 5, Batch 2900] loss: 0.024955886190582532
[Epoch 5, Batch 3000] loss: 0.01850544215158152
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0411
Validation Accuracy: 0.9882
Overfitting: 0.0411
[Epoch 6, Batch 100] loss: 0.019471878144086078
[Epoch 6, Batch 200] loss: 0.025647211007672012
[Epoch 6, Batch 300] loss: 0.027762528354833192
[Epoch 6, Batch 400] loss: 0.01622348088440049
[Epoch 6, Batch 500] loss: 0.01749782847146889
[Epoch 6, Batch 600] loss: 0.036952149991193436
[Epoch 6, Batch 700] loss: 0.02212442541906057
[Epoch 6, Batch 800] loss: 0.02071352551847667
[Epoch 6, Batch 900] loss: 0.017993413658405188
[Epoch 6, Batch 1000] loss: 0.016586891206661677
[Epoch 6, Batch 1100] loss: 0.03424662445553622
[Epoch 6, Batch 1200] loss: 0.024852504883529036
[Epoch 6, Batch 1300] loss: 0.021350630071465274
[Epoch 6, Batch 1400] loss: 0.023105411484029902
[Epoch 6, Batch 1500] loss: 0.03698056364617514
[Epoch 6, Batch 1600] loss: 0.038970781797834204
[Epoch 6, Batch 1700] loss: 0.022083187252173956
[Epoch 6, Batch 1800] loss: 0.02430686999574391
[Epoch 6, Batch 1900] loss: 0.02791158785974403
[Epoch 6, Batch 2000] loss: 0.023900189852674884
[Epoch 6, Batch 2100] loss: 0.016688485394897725
[Epoch 6, Batch 2200] loss: 0.014542633856190151
[Epoch 6, Batch 2300] loss: 0.015097262199251418
[Epoch 6, Batch 2400] loss: 0.018173103509107023
[Epoch 6, Batch 2500] loss: 0.020096554372858007
[Epoch 6, Batch 2600] loss: 0.02298101855252753
[Epoch 6, Batch 2700] loss: 0.02327760025007592
[Epoch 6, Batch 2800] loss: 0.016510281421260514
[Epoch 6, Batch 2900] loss: 0.02233347236580812
[Epoch 6, Batch 3000] loss: 0.020110514828825216
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0541
Validation Accuracy: 0.9849
Overfitting: 0.0541
[Epoch 7, Batch 100] loss: 0.015067728415688179
[Epoch 7, Batch 200] loss: 0.02056933508873044
[Epoch 7, Batch 300] loss: 0.023248403787965798
[Epoch 7, Batch 400] loss: 0.01896386250042269
[Epoch 7, Batch 500] loss: 0.011208099228470018
[Epoch 7, Batch 600] loss: 0.010424416608354931
[Epoch 7, Batch 700] loss: 0.03210475469014909
[Epoch 7, Batch 800] loss: 0.025036107681062278
[Epoch 7, Batch 900] loss: 0.01338651479827604
[Epoch 7, Batch 1000] loss: 0.010179723980913878
[Epoch 7, Batch 1100] loss: 0.016490347712592664
[Epoch 7, Batch 1200] loss: 0.016766284623395224
[Epoch 7, Batch 1300] loss: 0.012888374753729295
[Epoch 7, Batch 1400] loss: 0.0266444898631471
[Epoch 7, Batch 1500] loss: 0.018472198533163463
[Epoch 7, Batch 1600] loss: 0.028728211549478147
[Epoch 7, Batch 1700] loss: 0.027385995041186106
[Epoch 7, Batch 1800] loss: 0.027812412535240583
[Epoch 7, Batch 1900] loss: 0.022463019528022415
[Epoch 7, Batch 2000] loss: 0.026208653161684196
[Epoch 7, Batch 2100] loss: 0.026790603127519717
[Epoch 7, Batch 2200] loss: 0.020052587349673558
[Epoch 7, Batch 2300] loss: 0.01962778480581619
[Epoch 7, Batch 2400] loss: 0.010420143004394049
[Epoch 7, Batch 2500] loss: 0.013791030307934306
[Epoch 7, Batch 2600] loss: 0.017805653600562438
[Epoch 7, Batch 2700] loss: 0.014621876449855336
[Epoch 7, Batch 2800] loss: 0.01955355485393284
[Epoch 7, Batch 2900] loss: 0.025466823564593143
[Epoch 7, Batch 3000] loss: 0.02679881511368876
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9871
Overfitting: 0.0471
[Epoch 8, Batch 100] loss: 0.015829247056085478
[Epoch 8, Batch 200] loss: 0.013746206668797641
[Epoch 8, Batch 300] loss: 0.007537321694835555
[Epoch 8, Batch 400] loss: 0.012954190000095877
[Epoch 8, Batch 500] loss: 0.0172344082015843
[Epoch 8, Batch 600] loss: 0.011968994609369475
[Epoch 8, Batch 700] loss: 0.007383409558751736
[Epoch 8, Batch 800] loss: 0.01843979443632634
[Epoch 8, Batch 900] loss: 0.013971793428136153
[Epoch 8, Batch 1000] loss: 0.01957110877059222
[Epoch 8, Batch 1100] loss: 0.015079456088042207
[Epoch 8, Batch 1200] loss: 0.014388146749697626
[Epoch 8, Batch 1300] loss: 0.0242175616368786
[Epoch 8, Batch 1400] loss: 0.01945941905764812
[Epoch 8, Batch 1500] loss: 0.011283970524905271
[Epoch 8, Batch 1600] loss: 0.008143692752614697
[Epoch 8, Batch 1700] loss: 0.01753505326029881
[Epoch 8, Batch 1800] loss: 0.013036991020653659
[Epoch 8, Batch 1900] loss: 0.01447039313162918
[Epoch 8, Batch 2000] loss: 0.01952668968769558
[Epoch 8, Batch 2100] loss: 0.019995124549686806
[Epoch 8, Batch 2200] loss: 0.01830415415444804
[Epoch 8, Batch 2300] loss: 0.020112857068816083
[Epoch 8, Batch 2400] loss: 0.023220376391818717
[Epoch 8, Batch 2500] loss: 0.021102059612767333
[Epoch 8, Batch 2600] loss: 0.01198709608432182
[Epoch 8, Batch 2700] loss: 0.025052277829472586
[Epoch 8, Batch 2800] loss: 0.028699118370614087
[Epoch 8, Batch 2900] loss: 0.02280719802933163
[Epoch 8, Batch 3000] loss: 0.014977831775195228
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0424
Validation Accuracy: 0.9883
Overfitting: 0.0424
[Epoch 9, Batch 100] loss: 0.013509301591097938
[Epoch 9, Batch 200] loss: 0.01953276430194819
[Epoch 9, Batch 300] loss: 0.010275548751924362
[Epoch 9, Batch 400] loss: 0.00773694711451526
[Epoch 9, Batch 500] loss: 0.00967300466576944
[Epoch 9, Batch 600] loss: 0.02060807891826698
[Epoch 9, Batch 700] loss: 0.0073956287444161715
[Epoch 9, Batch 800] loss: 0.006202062140100679
[Epoch 9, Batch 900] loss: 0.01435463005955171
[Epoch 9, Batch 1000] loss: 0.02276254236726345
[Epoch 9, Batch 1100] loss: 0.013959152773459209
[Epoch 9, Batch 1200] loss: 0.009135179715262893
[Epoch 9, Batch 1300] loss: 0.009754107736616788
[Epoch 9, Batch 1400] loss: 0.023165334591049032
[Epoch 9, Batch 1500] loss: 0.018185885798720845
[Epoch 9, Batch 1600] loss: 0.020988351050839356
[Epoch 9, Batch 1700] loss: 0.018103575577351875
[Epoch 9, Batch 1800] loss: 0.013539767697814113
[Epoch 9, Batch 1900] loss: 0.021468546340142895
[Epoch 9, Batch 2000] loss: 0.022202263592362215
[Epoch 9, Batch 2100] loss: 0.01998451469625252
[Epoch 9, Batch 2200] loss: 0.020214387788369096
[Epoch 9, Batch 2300] loss: 0.015800761145783326
[Epoch 9, Batch 2400] loss: 0.019711827470700882
[Epoch 9, Batch 2500] loss: 0.013933506431512796
[Epoch 9, Batch 2600] loss: 0.013013675014844921
[Epoch 9, Batch 2700] loss: 0.013520054573964444
[Epoch 9, Batch 2800] loss: 0.017449133536101728
[Epoch 9, Batch 2900] loss: 0.012990556740060128
[Epoch 9, Batch 3000] loss: 0.015046465520395031
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9871
Overfitting: 0.0485
[Epoch 10, Batch 100] loss: 0.013177025974168827
[Epoch 10, Batch 200] loss: 0.006953024777262726
[Epoch 10, Batch 300] loss: 0.008554848135768225
[Epoch 10, Batch 400] loss: 0.006455584847583395
[Epoch 10, Batch 500] loss: 0.009868563258082759
[Epoch 10, Batch 600] loss: 0.008675429040652034
[Epoch 10, Batch 700] loss: 0.008043470379980135
[Epoch 10, Batch 800] loss: 0.0064621779883191266
[Epoch 10, Batch 900] loss: 0.004943098783220421
[Epoch 10, Batch 1000] loss: 0.01715196735985785
[Epoch 10, Batch 1100] loss: 0.011031146714634588
[Epoch 10, Batch 1200] loss: 0.012341467737729771
[Epoch 10, Batch 1300] loss: 0.011174715349967527
[Epoch 10, Batch 1400] loss: 0.017931214214736427
[Epoch 10, Batch 1500] loss: 0.009242938915773493
[Epoch 10, Batch 1600] loss: 0.019929963375416263
[Epoch 10, Batch 1700] loss: 0.006896768674002942
[Epoch 10, Batch 1800] loss: 0.011767129335084973
[Epoch 10, Batch 1900] loss: 0.008948310655398473
[Epoch 10, Batch 2000] loss: 0.01655620854953213
[Epoch 10, Batch 2100] loss: 0.0106398042460512
[Epoch 10, Batch 2200] loss: 0.015508885264653145
[Epoch 10, Batch 2300] loss: 0.02380510674663128
[Epoch 10, Batch 2400] loss: 0.012746819012245397
[Epoch 10, Batch 2500] loss: 0.018747242211748016
[Epoch 10, Batch 2600] loss: 0.01315284712674611
[Epoch 10, Batch 2700] loss: 0.006472880607910838
[Epoch 10, Batch 2800] loss: 0.01993229311713776
[Epoch 10, Batch 2900] loss: 0.013550132335103627
[Epoch 10, Batch 3000] loss: 0.009077499307101675
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0407
Validation Accuracy: 0.9894
Overfitting: 0.0407
[Epoch 11, Batch 100] loss: 0.0034161624611431306
[Epoch 11, Batch 200] loss: 0.005711801114537138
[Epoch 11, Batch 300] loss: 0.005945888208129873
[Epoch 11, Batch 400] loss: 0.0038050314675228945
[Epoch 11, Batch 500] loss: 0.012520965952212464
[Epoch 11, Batch 600] loss: 0.005225364856783017
[Epoch 11, Batch 700] loss: 0.012530471343891918
[Epoch 11, Batch 800] loss: 0.01431229797312568
[Epoch 11, Batch 900] loss: 0.014398346337010821
[Epoch 11, Batch 1000] loss: 0.006844620515627184
[Epoch 11, Batch 1100] loss: 0.014065631574984536
[Epoch 11, Batch 1200] loss: 0.005805061524592929
[Epoch 11, Batch 1300] loss: 0.005799396672296097
[Epoch 11, Batch 1400] loss: 0.009063823634594143
[Epoch 11, Batch 1500] loss: 0.00992669553301539
[Epoch 11, Batch 1600] loss: 0.007677864943793793
[Epoch 11, Batch 1700] loss: 0.012068253927862998
[Epoch 11, Batch 1800] loss: 0.013851422549096241
[Epoch 11, Batch 1900] loss: 0.007227560757839911
[Epoch 11, Batch 2000] loss: 0.005185938014964222
[Epoch 11, Batch 2100] loss: 0.009175210711434829
[Epoch 11, Batch 2200] loss: 0.010393693159847998
[Epoch 11, Batch 2300] loss: 0.013337846190172727
[Epoch 11, Batch 2400] loss: 0.01703678731702894
[Epoch 11, Batch 2500] loss: 0.008816445725072982
[Epoch 11, Batch 2600] loss: 0.009764725060924774
[Epoch 11, Batch 2700] loss: 0.009253781989712308
[Epoch 11, Batch 2800] loss: 0.005318836589525517
[Epoch 11, Batch 2900] loss: 0.009539026040075954
[Epoch 11, Batch 3000] loss: 0.009747671908351378
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9844
Overfitting: 0.0635
[Epoch 12, Batch 100] loss: 0.015253842772544886
[Epoch 12, Batch 200] loss: 0.010258706605346788
[Epoch 12, Batch 300] loss: 0.011121868905604088
[Epoch 12, Batch 400] loss: 0.011907350835316492
[Epoch 12, Batch 500] loss: 0.008459129452844535
[Epoch 12, Batch 600] loss: 0.007652923054687335
[Epoch 12, Batch 700] loss: 0.005654245812249314
[Epoch 12, Batch 800] loss: 0.011012018042993076
[Epoch 12, Batch 900] loss: 0.007700590963049194
[Epoch 12, Batch 1000] loss: 0.013106984905307399
[Epoch 12, Batch 1100] loss: 0.009677427317874673
[Epoch 12, Batch 1200] loss: 0.011473777955131936
[Epoch 12, Batch 1300] loss: 0.010563890145717778
[Epoch 12, Batch 1400] loss: 0.0036165716593484377
[Epoch 12, Batch 1500] loss: 0.0056926129506531704
[Epoch 12, Batch 1600] loss: 0.010247674226101254
[Epoch 12, Batch 1700] loss: 0.014683263962024285
[Epoch 12, Batch 1800] loss: 0.013887907616605162
[Epoch 12, Batch 1900] loss: 0.016860837762042138
[Epoch 12, Batch 2000] loss: 0.009223860973303317
[Epoch 12, Batch 2100] loss: 0.007906058405958448
[Epoch 12, Batch 2200] loss: 0.020223712566388486
[Epoch 12, Batch 2300] loss: 0.006187088346785004
[Epoch 12, Batch 2400] loss: 0.006032704574867296
[Epoch 12, Batch 2500] loss: 0.013171353616060059
[Epoch 12, Batch 2600] loss: 0.005350863013874232
[Epoch 12, Batch 2700] loss: 0.012254725114682969
[Epoch 12, Batch 2800] loss: 0.016423377263465683
[Epoch 12, Batch 2900] loss: 0.005941445002970908
[Epoch 12, Batch 3000] loss: 0.01764700292310522
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9872
Overfitting: 0.0508
[Epoch 13, Batch 100] loss: 0.009730079696309986
[Epoch 13, Batch 200] loss: 0.006012350231835626
[Epoch 13, Batch 300] loss: 0.007238568410484731
[Epoch 13, Batch 400] loss: 0.006897005820982258
[Epoch 13, Batch 500] loss: 0.006909147015668395
[Epoch 13, Batch 600] loss: 0.011291098934221892
[Epoch 13, Batch 700] loss: 0.013488236191473107
[Epoch 13, Batch 800] loss: 0.0021308313085012286
[Epoch 13, Batch 900] loss: 0.007750603049273081
[Epoch 13, Batch 1000] loss: 0.0020914887025355712
[Epoch 13, Batch 1100] loss: 0.0013533437578087159
[Epoch 13, Batch 1200] loss: 0.004919418723078195
[Epoch 13, Batch 1300] loss: 0.0037654624245561765
[Epoch 13, Batch 1400] loss: 0.016544532942378537
[Epoch 13, Batch 1500] loss: 0.014833121324262493
[Epoch 13, Batch 1600] loss: 0.010036263123426465
[Epoch 13, Batch 1700] loss: 0.010025562399233348
[Epoch 13, Batch 1800] loss: 0.009370661083218578
[Epoch 13, Batch 1900] loss: 0.013504586935898715
[Epoch 13, Batch 2000] loss: 0.006041885579099926
[Epoch 13, Batch 2100] loss: 0.01441393678508689
[Epoch 13, Batch 2200] loss: 0.008018950776485099
[Epoch 13, Batch 2300] loss: 0.011970181404030882
[Epoch 13, Batch 2400] loss: 0.005592627716751508
[Epoch 13, Batch 2500] loss: 0.013941215843781265
[Epoch 13, Batch 2600] loss: 0.01497869313884962
[Epoch 13, Batch 2700] loss: 0.01940656555179203
[Epoch 13, Batch 2800] loss: 0.011064845833768402
[Epoch 13, Batch 2900] loss: 0.003915148233873822
[Epoch 13, Batch 3000] loss: 0.01079570524335395
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9886
Overfitting: 0.0446
[Epoch 14, Batch 100] loss: 0.009794708094774477
[Epoch 14, Batch 200] loss: 0.005828186293774707
[Epoch 14, Batch 300] loss: 0.006570940299336598
[Epoch 14, Batch 400] loss: 0.017422940080138005
[Epoch 14, Batch 500] loss: 0.006639968523538186
[Epoch 14, Batch 600] loss: 0.009999742029192476
[Epoch 14, Batch 700] loss: 0.00391979836081589
[Epoch 14, Batch 800] loss: 0.014456043400016085
[Epoch 14, Batch 900] loss: 0.01407984762254145
[Epoch 14, Batch 1000] loss: 0.01179412916078995
[Epoch 14, Batch 1100] loss: 0.009184138980881471
[Epoch 14, Batch 1200] loss: 0.002687147845341258
[Epoch 14, Batch 1300] loss: 0.008623306991454527
[Epoch 14, Batch 1400] loss: 0.008084141414806751
[Epoch 14, Batch 1500] loss: 0.02657712379591338
[Epoch 14, Batch 1600] loss: 0.015022458872570326
[Epoch 14, Batch 1700] loss: 0.015545651381155495
[Epoch 14, Batch 1800] loss: 0.007367281663709946
[Epoch 14, Batch 1900] loss: 0.010247720514428807
[Epoch 14, Batch 2000] loss: 0.009141407536607176
[Epoch 14, Batch 2100] loss: 0.005459593946941368
[Epoch 14, Batch 2200] loss: 0.004852297251281925
[Epoch 14, Batch 2300] loss: 0.005245513860620008
[Epoch 14, Batch 2400] loss: 0.00368708485327204
[Epoch 14, Batch 2500] loss: 0.004705350636851335
[Epoch 14, Batch 2600] loss: 0.016595516587535712
[Epoch 14, Batch 2700] loss: 0.0057690332765452015
[Epoch 14, Batch 2800] loss: 0.004544849970928908
[Epoch 14, Batch 2900] loss: 0.0024847389170021116
[Epoch 14, Batch 3000] loss: 0.006760795451805279
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9882
Overfitting: 0.0470
[Epoch 15, Batch 100] loss: 0.0038503561032362655
[Epoch 15, Batch 200] loss: 0.002472052042159021
[Epoch 15, Batch 300] loss: 0.001822767493381292
[Epoch 15, Batch 400] loss: 0.005072021867346735
[Epoch 15, Batch 500] loss: 0.0013647787509327625
[Epoch 15, Batch 600] loss: 0.007204352636229672
[Epoch 15, Batch 700] loss: 0.005501916854962836
[Epoch 15, Batch 800] loss: 0.0032409663345083573
[Epoch 15, Batch 900] loss: 0.0034214338248939667
[Epoch 15, Batch 1000] loss: 0.0039045945635239575
[Epoch 15, Batch 1100] loss: 0.0014116658635807777
[Epoch 15, Batch 1200] loss: 0.005881840167717769
[Epoch 15, Batch 1300] loss: 0.0010598149949392166
[Epoch 15, Batch 1400] loss: 0.004586535255498632
[Epoch 15, Batch 1500] loss: 0.0018664464855117301
[Epoch 15, Batch 1600] loss: 0.003906927661418531
[Epoch 15, Batch 1700] loss: 0.006123923903027304
[Epoch 15, Batch 1800] loss: 0.00270143013763132
[Epoch 15, Batch 1900] loss: 0.000779230151690058
[Epoch 15, Batch 2000] loss: 0.0020929302471827784
[Epoch 15, Batch 2100] loss: 0.0012505384938617681
[Epoch 15, Batch 2200] loss: 0.002441523388091831
[Epoch 15, Batch 2300] loss: 0.003845698446830426
[Epoch 15, Batch 2400] loss: 0.010823878774547211
[Epoch 15, Batch 2500] loss: 0.010989479632678396
[Epoch 15, Batch 2600] loss: 0.004339385030467327
[Epoch 15, Batch 2700] loss: 0.006825342711902067
[Epoch 15, Batch 2800] loss: 0.005513107049338189
[Epoch 15, Batch 2900] loss: 0.020402887097404444
[Epoch 15, Batch 3000] loss: 0.010135150141918814
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9875
Overfitting: 0.0561
[Epoch 16, Batch 100] loss: 0.0033522547002246485
[Epoch 16, Batch 200] loss: 0.011950003629956569
[Epoch 16, Batch 300] loss: 0.0030842152430807348
[Epoch 16, Batch 400] loss: 0.004788777636766639
[Epoch 16, Batch 500] loss: 0.006618642316706414
[Epoch 16, Batch 600] loss: 0.005526919961877179
[Epoch 16, Batch 700] loss: 0.0021351138553200324
[Epoch 16, Batch 800] loss: 0.003007373345335367
[Epoch 16, Batch 900] loss: 0.0009385874625121459
[Epoch 16, Batch 1000] loss: 0.004296696545783316
[Epoch 16, Batch 1100] loss: 0.0008873421213638721
[Epoch 16, Batch 1200] loss: 0.001244701546283693
[Epoch 16, Batch 1300] loss: 0.003758288469441453
[Epoch 16, Batch 1400] loss: 0.0016934896836128387
[Epoch 16, Batch 1500] loss: 0.001836726307420662
[Epoch 16, Batch 1600] loss: 0.004569265461340124
[Epoch 16, Batch 1700] loss: 0.005896865365528043
[Epoch 16, Batch 1800] loss: 0.0026136432546324073
[Epoch 16, Batch 1900] loss: 0.003817887573693639
[Epoch 16, Batch 2000] loss: 0.00431942504614696
[Epoch 16, Batch 2100] loss: 0.0017509794382159739
[Epoch 16, Batch 2200] loss: 0.0023666963474897073
[Epoch 16, Batch 2300] loss: 0.002701589756146063
[Epoch 16, Batch 2400] loss: 0.0007950235167558617
[Epoch 16, Batch 2500] loss: 0.0009620718419462327
[Epoch 16, Batch 2600] loss: 0.006291472477533944
[Epoch 16, Batch 2700] loss: 0.0020421931375038584
[Epoch 16, Batch 2800] loss: 0.0024206303071672864
[Epoch 16, Batch 2900] loss: 0.00594461557306289
[Epoch 16, Batch 3000] loss: 0.005515532863955955
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9897
Overfitting: 0.0479
[Epoch 17, Batch 100] loss: 0.0021873315322445564
[Epoch 17, Batch 200] loss: 0.0028245737560785855
[Epoch 17, Batch 300] loss: 0.0010588124342807248
[Epoch 17, Batch 400] loss: 0.00252327036907765
[Epoch 17, Batch 500] loss: 0.0024019943020397072
[Epoch 17, Batch 600] loss: 0.0017422694767260083
[Epoch 17, Batch 700] loss: 0.00041015116058462197
[Epoch 17, Batch 800] loss: 0.0014077793106336146
[Epoch 17, Batch 900] loss: 0.004055451739143052
[Epoch 17, Batch 1000] loss: 0.003604982169654676
[Epoch 17, Batch 1100] loss: 0.003003712170687152
[Epoch 17, Batch 1200] loss: 0.002787913504937194
[Epoch 17, Batch 1300] loss: 0.003995720432557306
[Epoch 17, Batch 1400] loss: 0.0004096504351925656
[Epoch 17, Batch 1500] loss: 0.0019826134301088416
[Epoch 17, Batch 1600] loss: 0.0060721453849782135
[Epoch 17, Batch 1700] loss: 0.0009382535016337102
[Epoch 17, Batch 1800] loss: 0.000555033430752161
[Epoch 17, Batch 1900] loss: 0.0011034216684893039
[Epoch 17, Batch 2000] loss: 0.0011792394529074723
[Epoch 17, Batch 2100] loss: 0.0005364697625148462
[Epoch 17, Batch 2200] loss: 0.0005372797713918542
[Epoch 17, Batch 2300] loss: 0.0038711811174996845
[Epoch 17, Batch 2400] loss: 0.001832906966604879
[Epoch 17, Batch 2500] loss: 0.0049025633027340735
[Epoch 17, Batch 2600] loss: 0.0008385865927346448
[Epoch 17, Batch 2700] loss: 0.0010790704865027223
[Epoch 17, Batch 2800] loss: 0.0035961499486789703
[Epoch 17, Batch 2900] loss: 0.005682121630486563
[Epoch 17, Batch 3000] loss: 0.011037979432539232
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0563
Validation Accuracy: 0.9890
Overfitting: 0.0563
[Epoch 18, Batch 100] loss: 0.001550941445277818
[Epoch 18, Batch 200] loss: 0.005720974924659359
[Epoch 18, Batch 300] loss: 0.0013735368264120495
[Epoch 18, Batch 400] loss: 0.0009417263504348483
[Epoch 18, Batch 500] loss: 0.0005587562587653672
[Epoch 18, Batch 600] loss: 0.0008226395997356306
[Epoch 18, Batch 700] loss: 0.00033214560944852425
[Epoch 18, Batch 800] loss: 0.0005862741716948961
[Epoch 18, Batch 900] loss: 0.001684572825605244
[Epoch 18, Batch 1000] loss: 0.0011925887299847205
[Epoch 18, Batch 1100] loss: 0.00034099007918907186
[Epoch 18, Batch 1200] loss: 0.001337062525361521
[Epoch 18, Batch 1300] loss: 0.002797280451337225
[Epoch 18, Batch 1400] loss: 0.0002854685824395453
[Epoch 18, Batch 1500] loss: 0.0005304407166716452
[Epoch 18, Batch 1600] loss: 0.000588350489815035
[Epoch 18, Batch 1700] loss: 0.0012776666464512408
[Epoch 18, Batch 1800] loss: 0.0004161899312494377
[Epoch 18, Batch 1900] loss: 0.0018493708138715092
[Epoch 18, Batch 2000] loss: 0.0014389784766962066
[Epoch 18, Batch 2100] loss: 0.00514202754025682
[Epoch 18, Batch 2200] loss: 0.0010371523032190043
[Epoch 18, Batch 2300] loss: 0.000717681769829177
[Epoch 18, Batch 2400] loss: 0.0015297155049675837
[Epoch 18, Batch 2500] loss: 0.0025169135319120304
[Epoch 18, Batch 2600] loss: 0.0024593843720609244
[Epoch 18, Batch 2700] loss: 0.0013269328612743436
[Epoch 18, Batch 2800] loss: 0.0012123704937150048
[Epoch 18, Batch 2900] loss: 0.000676810241221899
[Epoch 18, Batch 3000] loss: 0.001143780043300051
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9898
Overfitting: 0.0550
[Epoch 19, Batch 100] loss: 0.00023337424239000982
[Epoch 19, Batch 200] loss: 0.0006971432186954729
[Epoch 19, Batch 300] loss: 0.001299884786117822
[Epoch 19, Batch 400] loss: 0.0006819088774212245
[Epoch 19, Batch 500] loss: 0.0014816622958312032
[Epoch 19, Batch 600] loss: 0.0007943255895494339
[Epoch 19, Batch 700] loss: 0.003919796793900812
[Epoch 19, Batch 800] loss: 0.0018147402638959242
[Epoch 19, Batch 900] loss: 0.0013248467937452756
[Epoch 19, Batch 1000] loss: 0.000525682302445909
[Epoch 19, Batch 1100] loss: 0.0008859419653922184
[Epoch 19, Batch 1200] loss: 0.00036064184352895267
[Epoch 19, Batch 1300] loss: 0.0017252034334184606
[Epoch 19, Batch 1400] loss: 0.0007831574639587658
[Epoch 19, Batch 1500] loss: 0.0012765914696709357
[Epoch 19, Batch 1600] loss: 0.0009724590168663161
[Epoch 19, Batch 1700] loss: 0.0006764115809008774
[Epoch 19, Batch 1800] loss: 0.0006036271654881009
[Epoch 19, Batch 1900] loss: 0.002578990962497687
[Epoch 19, Batch 2000] loss: 0.0005338473720930459
[Epoch 19, Batch 2100] loss: 0.0008680247126621588
[Epoch 19, Batch 2200] loss: 0.001427830372811001
[Epoch 19, Batch 2300] loss: 0.006854772454919118
[Epoch 19, Batch 2400] loss: 0.011531345571418536
[Epoch 19, Batch 2500] loss: 0.0010748045420771034
[Epoch 19, Batch 2600] loss: 0.0007231787966971304
[Epoch 19, Batch 2700] loss: 0.0005787138171049077
[Epoch 19, Batch 2800] loss: 0.0017889124063412431
[Epoch 19, Batch 2900] loss: 0.003526152991089897
[Epoch 19, Batch 3000] loss: 0.00038074627449214305
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9891
Overfitting: 0.0561
[Epoch 20, Batch 100] loss: 0.004104196555587918
[Epoch 20, Batch 200] loss: 0.001310811042376292
[Epoch 20, Batch 300] loss: 0.0017559272609524923
[Epoch 20, Batch 400] loss: 0.0035447827950579837
[Epoch 20, Batch 500] loss: 0.0050282913609095556
[Epoch 20, Batch 600] loss: 0.002974107755151798
[Epoch 20, Batch 700] loss: 0.0010044514258439109
[Epoch 20, Batch 800] loss: 0.0007882125126123185
[Epoch 20, Batch 900] loss: 0.0009072296542374891
[Epoch 20, Batch 1000] loss: 0.000803053520688346
[Epoch 20, Batch 1100] loss: 0.00046346141144492314
[Epoch 20, Batch 1200] loss: 0.00030645437975292735
[Epoch 20, Batch 1300] loss: 0.0024975851930238322
[Epoch 20, Batch 1400] loss: 0.00171137253441616
[Epoch 20, Batch 1500] loss: 0.005352718280775584
[Epoch 20, Batch 1600] loss: 0.00348420363681853
[Epoch 20, Batch 1700] loss: 0.003519246678301062
[Epoch 20, Batch 1800] loss: 0.001081872775849546
[Epoch 20, Batch 1900] loss: 0.003258836978462334
[Epoch 20, Batch 2000] loss: 0.018134869317368164
[Epoch 20, Batch 2100] loss: 0.0063961588284398374
[Epoch 20, Batch 2200] loss: 0.009843452363709768
[Epoch 20, Batch 2300] loss: 0.005895004068755365
[Epoch 20, Batch 2400] loss: 0.002925575589240785
[Epoch 20, Batch 2500] loss: 0.004251490055298111
[Epoch 20, Batch 2600] loss: 0.010663079145480014
[Epoch 20, Batch 2700] loss: 0.02292566626510474
[Epoch 20, Batch 2800] loss: 0.015345091225978748
[Epoch 20, Batch 2900] loss: 0.01858987811933039
[Epoch 20, Batch 3000] loss: 0.018594198622618876
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9881
Overfitting: 0.0581
[Epoch 21, Batch 100] loss: 0.016696427391350816
[Epoch 21, Batch 200] loss: 0.0036870462650377077
[Epoch 21, Batch 300] loss: 0.012211231427983228
[Epoch 21, Batch 400] loss: 0.009099337929170588
[Epoch 21, Batch 500] loss: 0.004916926309430139
[Epoch 21, Batch 600] loss: 0.005071159750872987
[Epoch 21, Batch 700] loss: 0.015596409716224287
[Epoch 21, Batch 800] loss: 0.005400773784956669
[Epoch 21, Batch 900] loss: 0.007713193153898015
[Epoch 21, Batch 1000] loss: 0.008315207845459617
[Epoch 21, Batch 1100] loss: 0.002320035662455311
[Epoch 21, Batch 1200] loss: 0.006004035025231213
[Epoch 21, Batch 1300] loss: 0.002190069334754674
[Epoch 21, Batch 1400] loss: 0.003756487269010336
[Epoch 21, Batch 1500] loss: 0.0064622110358786245
[Epoch 21, Batch 1600] loss: 0.007155193677688771
[Epoch 21, Batch 1700] loss: 0.004677942612584047
[Epoch 21, Batch 1800] loss: 0.01277019472456807
[Epoch 21, Batch 1900] loss: 0.007172157157198527
[Epoch 21, Batch 2000] loss: 0.015523618122861542
[Epoch 21, Batch 2100] loss: 0.013236089368969068
[Epoch 21, Batch 2200] loss: 0.005254046021119621
[Epoch 21, Batch 2300] loss: 0.005254804508824123
[Epoch 21, Batch 2400] loss: 0.0053394420041564675
[Epoch 21, Batch 2500] loss: 0.0025378831818282733
[Epoch 21, Batch 2600] loss: 0.002358642466783394
[Epoch 21, Batch 2700] loss: 0.011067678954413003
[Epoch 21, Batch 2800] loss: 0.0036558103486889594
[Epoch 21, Batch 2900] loss: 0.01728025147247539
[Epoch 21, Batch 3000] loss: 0.017376280516481726
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0795
Validation Accuracy: 0.9838
Overfitting: 0.0795
[Epoch 22, Batch 100] loss: 0.008984917818393256
[Epoch 22, Batch 200] loss: 0.0015586079681337139
[Epoch 22, Batch 300] loss: 0.006734539591162796
[Epoch 22, Batch 400] loss: 0.0023406662102152787
[Epoch 22, Batch 500] loss: 0.005954627898830971
[Epoch 22, Batch 600] loss: 0.009828275158178164
[Epoch 22, Batch 700] loss: 0.003260709686193053
[Epoch 22, Batch 800] loss: 0.0063264748054332465
[Epoch 22, Batch 900] loss: 0.017612817560699198
[Epoch 22, Batch 1000] loss: 0.004172538792409455
[Epoch 22, Batch 1100] loss: 0.004129685309754478
[Epoch 22, Batch 1200] loss: 0.003941036930914379
[Epoch 22, Batch 1300] loss: 0.00387439409853668
[Epoch 22, Batch 1400] loss: 0.0014605769056706209
[Epoch 22, Batch 1500] loss: 0.004081410100207421
[Epoch 22, Batch 1600] loss: 0.005361193000086999
[Epoch 22, Batch 1700] loss: 0.0009626911309421971
[Epoch 22, Batch 1800] loss: 0.0006569611807379871
[Epoch 22, Batch 1900] loss: 0.0051792916261238055
[Epoch 22, Batch 2000] loss: 0.003353757849844028
[Epoch 22, Batch 2100] loss: 0.0041669921485197
[Epoch 22, Batch 2200] loss: 0.009268760107068558
[Epoch 22, Batch 2300] loss: 0.004052806461057159
[Epoch 22, Batch 2400] loss: 0.006864218115167926
[Epoch 22, Batch 2500] loss: 0.005488393377391887
[Epoch 22, Batch 2600] loss: 0.003422174887027154
[Epoch 22, Batch 2700] loss: 0.0019911814218251146
[Epoch 22, Batch 2800] loss: 0.005274826646656639
[Epoch 22, Batch 2900] loss: 0.004850304828043761
[Epoch 22, Batch 3000] loss: 0.008236384941645998
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9896
Overfitting: 0.0527
[Epoch 23, Batch 100] loss: 0.002430386196163239
[Epoch 23, Batch 200] loss: 0.006710925524333766
[Epoch 23, Batch 300] loss: 0.0008336758619795237
[Epoch 23, Batch 400] loss: 0.001603734811643811
[Epoch 23, Batch 500] loss: 0.003636862254059117
[Epoch 23, Batch 600] loss: 0.0013941986805436457
[Epoch 23, Batch 700] loss: 0.0008388085712026338
[Epoch 23, Batch 800] loss: 0.0006664117851657591
[Epoch 23, Batch 900] loss: 0.0008931525140269647
[Epoch 23, Batch 1000] loss: 0.00038648465878267314
[Epoch 23, Batch 1100] loss: 0.0008860052572000354
[Epoch 23, Batch 1200] loss: 0.0012715323397757094
[Epoch 23, Batch 1300] loss: 0.0023919471804302274
[Epoch 23, Batch 1400] loss: 0.00460312798021846
[Epoch 23, Batch 1500] loss: 0.0020198261098248473
[Epoch 23, Batch 1600] loss: 0.007868304925287997
[Epoch 23, Batch 1700] loss: 0.0026936340297555716
[Epoch 23, Batch 1800] loss: 0.005992462843194542
[Epoch 23, Batch 1900] loss: 0.003411924985539976
[Epoch 23, Batch 2000] loss: 0.0033699832129631345
[Epoch 23, Batch 2100] loss: 0.003172839759559687
[Epoch 23, Batch 2200] loss: 0.0018158816282530489
[Epoch 23, Batch 2300] loss: 0.0020368766867903476
[Epoch 23, Batch 2400] loss: 0.0029831352481994155
[Epoch 23, Batch 2500] loss: 0.001612056048695365
[Epoch 23, Batch 2600] loss: 0.0016815713592279692
[Epoch 23, Batch 2700] loss: 0.007103012816719061
[Epoch 23, Batch 2800] loss: 0.0008022246829960978
[Epoch 23, Batch 2900] loss: 0.0022115254544278875
[Epoch 23, Batch 3000] loss: 0.001263434668473593
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9902
Overfitting: 0.0502
[Epoch 24, Batch 100] loss: 0.0008629284113076308
[Epoch 24, Batch 200] loss: 0.004427516683964821
[Epoch 24, Batch 300] loss: 0.0002590730474085623
[Epoch 24, Batch 400] loss: 0.0012930452112650092
[Epoch 24, Batch 500] loss: 0.0017581101235988595
[Epoch 24, Batch 600] loss: 0.0037797742668037415
[Epoch 24, Batch 700] loss: 0.0009528594993552986
[Epoch 24, Batch 800] loss: 0.001260069502249692
[Epoch 24, Batch 900] loss: 0.0005911442885151263
[Epoch 24, Batch 1000] loss: 0.0007941095794260055
[Epoch 24, Batch 1100] loss: 0.001125999168349865
[Epoch 24, Batch 1200] loss: 0.0012232609577808072
[Epoch 24, Batch 1300] loss: 0.0006883635496924745
[Epoch 24, Batch 1400] loss: 0.0008637957230315596
[Epoch 24, Batch 1500] loss: 0.0005481776078813106
[Epoch 24, Batch 1600] loss: 0.00097094082122132
[Epoch 24, Batch 1700] loss: 0.0007931606105002497
[Epoch 24, Batch 1800] loss: 0.0005546964170410895
[Epoch 24, Batch 1900] loss: 0.0002417037344759354
[Epoch 24, Batch 2000] loss: 0.0005059786254051168
[Epoch 24, Batch 2100] loss: 0.00025875035812946925
[Epoch 24, Batch 2200] loss: 0.00010229051315551186
[Epoch 24, Batch 2300] loss: 0.0003521993568199644
[Epoch 24, Batch 2400] loss: 0.0029264672488206324
[Epoch 24, Batch 2500] loss: 0.002755569150812622
[Epoch 24, Batch 2600] loss: 0.0005514864911049821
[Epoch 24, Batch 2700] loss: 0.0003798529060659428
[Epoch 24, Batch 2800] loss: 0.0026049175371787568
[Epoch 24, Batch 2900] loss: 0.0023938991925670948
[Epoch 24, Batch 3000] loss: 0.0005333879056282775
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9892
Overfitting: 0.0546
Fold 4 validation loss: 0.0546
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.27409884929657
[Epoch 1, Batch 200] loss: 1.5771188861131669
[Epoch 1, Batch 300] loss: 0.6058925881981849
[Epoch 1, Batch 400] loss: 0.4653087639436126
[Epoch 1, Batch 500] loss: 0.3063507360965014
[Epoch 1, Batch 600] loss: 0.28193887071684004
[Epoch 1, Batch 700] loss: 0.23649996087886394
[Epoch 1, Batch 800] loss: 0.22528335061855614
[Epoch 1, Batch 900] loss: 0.18521030370146035
[Epoch 1, Batch 1000] loss: 0.16203521204181015
[Epoch 1, Batch 1100] loss: 0.1769882301799953
[Epoch 1, Batch 1200] loss: 0.14520939704962074
[Epoch 1, Batch 1300] loss: 0.1464349663257599
[Epoch 1, Batch 1400] loss: 0.12732095113489778
[Epoch 1, Batch 1500] loss: 0.13169025460403647
[Epoch 1, Batch 1600] loss: 0.1133574671210954
[Epoch 1, Batch 1700] loss: 0.12081489992560819
[Epoch 1, Batch 1800] loss: 0.13409923943690955
[Epoch 1, Batch 1900] loss: 0.0928180547663942
[Epoch 1, Batch 2000] loss: 0.11237432704307139
[Epoch 1, Batch 2100] loss: 0.12783279243391008
[Epoch 1, Batch 2200] loss: 0.12567176236771047
[Epoch 1, Batch 2300] loss: 0.10072426007362083
[Epoch 1, Batch 2400] loss: 0.11137096845312044
[Epoch 1, Batch 2500] loss: 0.1358575157332234
[Epoch 1, Batch 2600] loss: 0.11531048239441588
[Epoch 1, Batch 2700] loss: 0.07982777562516276
[Epoch 1, Batch 2800] loss: 0.08219558883458376
[Epoch 1, Batch 2900] loss: 0.09069079166511074
[Epoch 1, Batch 3000] loss: 0.07062817841535435
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0768
Validation Accuracy: 0.9767
Overfitting: 0.0768
Best model saved at epoch 1 with validation loss: 0.0768
[Epoch 2, Batch 100] loss: 0.08529160283564124
[Epoch 2, Batch 200] loss: 0.0752109548865701
[Epoch 2, Batch 300] loss: 0.07514669348136521
[Epoch 2, Batch 400] loss: 0.06681443075765855
[Epoch 2, Batch 500] loss: 0.06379912713833619
[Epoch 2, Batch 600] loss: 0.07109176105994265
[Epoch 2, Batch 700] loss: 0.0848107872880064
[Epoch 2, Batch 800] loss: 0.06009081499942113
[Epoch 2, Batch 900] loss: 0.07360985849663848
[Epoch 2, Batch 1000] loss: 0.08220165383303538
[Epoch 2, Batch 1100] loss: 0.08354408696875908
[Epoch 2, Batch 1200] loss: 0.05456405072531197
[Epoch 2, Batch 1300] loss: 0.04903914151727804
[Epoch 2, Batch 1400] loss: 0.07757971917744726
[Epoch 2, Batch 1500] loss: 0.06003144405753119
[Epoch 2, Batch 1600] loss: 0.0765084139702958
[Epoch 2, Batch 1700] loss: 0.049650672070129076
[Epoch 2, Batch 1800] loss: 0.056040278845030114
[Epoch 2, Batch 1900] loss: 0.059416619448020354
[Epoch 2, Batch 2000] loss: 0.05441734390304191
[Epoch 2, Batch 2100] loss: 0.04147366591641912
[Epoch 2, Batch 2200] loss: 0.052363762237946504
[Epoch 2, Batch 2300] loss: 0.07756723103258992
[Epoch 2, Batch 2400] loss: 0.04341481377079617
[Epoch 2, Batch 2500] loss: 0.05258045951544773
[Epoch 2, Batch 2600] loss: 0.08454049580555875
[Epoch 2, Batch 2700] loss: 0.08386187212134245
[Epoch 2, Batch 2800] loss: 0.05019479721377138
[Epoch 2, Batch 2900] loss: 0.05390784389921464
[Epoch 2, Batch 3000] loss: 0.07690675257908879
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0793
Validation Accuracy: 0.9752
Overfitting: 0.0793
[Epoch 3, Batch 100] loss: 0.05673569853359368
[Epoch 3, Batch 200] loss: 0.0435967487457674
[Epoch 3, Batch 300] loss: 0.04446902207797393
[Epoch 3, Batch 400] loss: 0.051491860624664695
[Epoch 3, Batch 500] loss: 0.041528983731986956
[Epoch 3, Batch 600] loss: 0.04813523221644573
[Epoch 3, Batch 700] loss: 0.043886221961001864
[Epoch 3, Batch 800] loss: 0.03633268762197986
[Epoch 3, Batch 900] loss: 0.060556009722786255
[Epoch 3, Batch 1000] loss: 0.049881572027952646
[Epoch 3, Batch 1100] loss: 0.04571819823730038
[Epoch 3, Batch 1200] loss: 0.05519076967233559
[Epoch 3, Batch 1300] loss: 0.05168269637040794
[Epoch 3, Batch 1400] loss: 0.03775338831910631
[Epoch 3, Batch 1500] loss: 0.05364338901621522
[Epoch 3, Batch 1600] loss: 0.04021128983120434
[Epoch 3, Batch 1700] loss: 0.03250130489308503
[Epoch 3, Batch 1800] loss: 0.05295990147409611
[Epoch 3, Batch 1900] loss: 0.037244270216324364
[Epoch 3, Batch 2000] loss: 0.062464749619248326
[Epoch 3, Batch 2100] loss: 0.047176418340823145
[Epoch 3, Batch 2200] loss: 0.078797429279075
[Epoch 3, Batch 2300] loss: 0.05685771949909395
[Epoch 3, Batch 2400] loss: 0.034099794431240296
[Epoch 3, Batch 2500] loss: 0.031682997832649565
[Epoch 3, Batch 2600] loss: 0.036920845968270444
[Epoch 3, Batch 2700] loss: 0.04447142834789702
[Epoch 3, Batch 2800] loss: 0.04694393842946738
[Epoch 3, Batch 2900] loss: 0.03603452574781841
[Epoch 3, Batch 3000] loss: 0.036429996586812195
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9855
Overfitting: 0.0473
Best model saved at epoch 3 with validation loss: 0.0473
[Epoch 4, Batch 100] loss: 0.023517147118545835
[Epoch 4, Batch 200] loss: 0.03701250801590504
[Epoch 4, Batch 300] loss: 0.04150655576137069
[Epoch 4, Batch 400] loss: 0.028967584961355895
[Epoch 4, Batch 500] loss: 0.047152928171417446
[Epoch 4, Batch 600] loss: 0.03772241107100854
[Epoch 4, Batch 700] loss: 0.03502939455473097
[Epoch 4, Batch 800] loss: 0.02841381140089652
[Epoch 4, Batch 900] loss: 0.04270504485903075
[Epoch 4, Batch 1000] loss: 0.03945006863388698
[Epoch 4, Batch 1100] loss: 0.026159486433025448
[Epoch 4, Batch 1200] loss: 0.042560602624580494
[Epoch 4, Batch 1300] loss: 0.03172201172179484
[Epoch 4, Batch 1400] loss: 0.024933954375446776
[Epoch 4, Batch 1500] loss: 0.03920351597568697
[Epoch 4, Batch 1600] loss: 0.022257614232657943
[Epoch 4, Batch 1700] loss: 0.05462581246320042
[Epoch 4, Batch 1800] loss: 0.03341789764257555
[Epoch 4, Batch 1900] loss: 0.029932325095178385
[Epoch 4, Batch 2000] loss: 0.04297198875749018
[Epoch 4, Batch 2100] loss: 0.027657351609959732
[Epoch 4, Batch 2200] loss: 0.04084324858231412
[Epoch 4, Batch 2300] loss: 0.04393380260138656
[Epoch 4, Batch 2400] loss: 0.040898938935133626
[Epoch 4, Batch 2500] loss: 0.033058996796316936
[Epoch 4, Batch 2600] loss: 0.031059227231307888
[Epoch 4, Batch 2700] loss: 0.03212819943815703
[Epoch 4, Batch 2800] loss: 0.045953104821310264
[Epoch 4, Batch 2900] loss: 0.021039028546656482
[Epoch 4, Batch 3000] loss: 0.04314047083898913
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0415
Validation Accuracy: 0.9876
Overfitting: 0.0415
Best model saved at epoch 4 with validation loss: 0.0415
[Epoch 5, Batch 100] loss: 0.023576995084731607
[Epoch 5, Batch 200] loss: 0.028498753563471837
[Epoch 5, Batch 300] loss: 0.020017360751589875
[Epoch 5, Batch 400] loss: 0.025605266895508974
[Epoch 5, Batch 500] loss: 0.020181790840706527
[Epoch 5, Batch 600] loss: 0.028480408998948405
[Epoch 5, Batch 700] loss: 0.023060650361476292
[Epoch 5, Batch 800] loss: 0.02673755129895653
[Epoch 5, Batch 900] loss: 0.0433087240599707
[Epoch 5, Batch 1000] loss: 0.03038817543085315
[Epoch 5, Batch 1100] loss: 0.0312192708612929
[Epoch 5, Batch 1200] loss: 0.03223385409593902
[Epoch 5, Batch 1300] loss: 0.01945315681341526
[Epoch 5, Batch 1400] loss: 0.045564275575816285
[Epoch 5, Batch 1500] loss: 0.0388892618916725
[Epoch 5, Batch 1600] loss: 0.02549434190012107
[Epoch 5, Batch 1700] loss: 0.028003501411039907
[Epoch 5, Batch 1800] loss: 0.03249786058418977
[Epoch 5, Batch 1900] loss: 0.024185350294355885
[Epoch 5, Batch 2000] loss: 0.03311637488917768
[Epoch 5, Batch 2100] loss: 0.03544475757795226
[Epoch 5, Batch 2200] loss: 0.03076777683440014
[Epoch 5, Batch 2300] loss: 0.021129357835743576
[Epoch 5, Batch 2400] loss: 0.0257372708638286
[Epoch 5, Batch 2500] loss: 0.026302986657283325
[Epoch 5, Batch 2600] loss: 0.01510459736420671
[Epoch 5, Batch 2700] loss: 0.01694010236347822
[Epoch 5, Batch 2800] loss: 0.023805435655958718
[Epoch 5, Batch 2900] loss: 0.03906658621486713
[Epoch 5, Batch 3000] loss: 0.029802803786988078
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9851
Overfitting: 0.0522
[Epoch 6, Batch 100] loss: 0.01600007510098294
[Epoch 6, Batch 200] loss: 0.020299368326923285
[Epoch 6, Batch 300] loss: 0.023844054246001178
[Epoch 6, Batch 400] loss: 0.020665148962070817
[Epoch 6, Batch 500] loss: 0.016198979714245068
[Epoch 6, Batch 600] loss: 0.028813364219895447
[Epoch 6, Batch 700] loss: 0.02418075290373963
[Epoch 6, Batch 800] loss: 0.026117711794049682
[Epoch 6, Batch 900] loss: 0.01759027040396177
[Epoch 6, Batch 1000] loss: 0.02769756053246965
[Epoch 6, Batch 1100] loss: 0.024053309360315325
[Epoch 6, Batch 1200] loss: 0.014180472995358287
[Epoch 6, Batch 1300] loss: 0.01731321915044646
[Epoch 6, Batch 1400] loss: 0.02777142153564455
[Epoch 6, Batch 1500] loss: 0.024515843288204452
[Epoch 6, Batch 1600] loss: 0.03832716261087626
[Epoch 6, Batch 1700] loss: 0.03211223667709419
[Epoch 6, Batch 1800] loss: 0.02136248788003286
[Epoch 6, Batch 1900] loss: 0.028648535304600955
[Epoch 6, Batch 2000] loss: 0.02421263013367934
[Epoch 6, Batch 2100] loss: 0.03161059850894162
[Epoch 6, Batch 2200] loss: 0.04358257965068333
[Epoch 6, Batch 2300] loss: 0.03565136823723151
[Epoch 6, Batch 2400] loss: 0.016706959413058938
[Epoch 6, Batch 2500] loss: 0.02691418979662558
[Epoch 6, Batch 2600] loss: 0.03462016083947674
[Epoch 6, Batch 2700] loss: 0.0236530923119426
[Epoch 6, Batch 2800] loss: 0.020459646057133796
[Epoch 6, Batch 2900] loss: 0.03414215986726049
[Epoch 6, Batch 3000] loss: 0.025245043686754797
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9839
Overfitting: 0.0559
[Epoch 7, Batch 100] loss: 0.016523832577900067
[Epoch 7, Batch 200] loss: 0.01362888252700941
[Epoch 7, Batch 300] loss: 0.014412159882704145
[Epoch 7, Batch 400] loss: 0.03107029056333886
[Epoch 7, Batch 500] loss: 0.023144774520969805
[Epoch 7, Batch 600] loss: 0.019814626584957296
[Epoch 7, Batch 700] loss: 0.01659191919476143
[Epoch 7, Batch 800] loss: 0.024161013061602718
[Epoch 7, Batch 900] loss: 0.017538335612916855
[Epoch 7, Batch 1000] loss: 0.02578134293180483
[Epoch 7, Batch 1100] loss: 0.015986736601807935
[Epoch 7, Batch 1200] loss: 0.007915606515034597
[Epoch 7, Batch 1300] loss: 0.023669021167588653
[Epoch 7, Batch 1400] loss: 0.028449597884828107
[Epoch 7, Batch 1500] loss: 0.011389672330342365
[Epoch 7, Batch 1600] loss: 0.016249256248847814
[Epoch 7, Batch 1700] loss: 0.01840109809041678
[Epoch 7, Batch 1800] loss: 0.013624503880096199
[Epoch 7, Batch 1900] loss: 0.023131118850415078
[Epoch 7, Batch 2000] loss: 0.020363528835623583
[Epoch 7, Batch 2100] loss: 0.05190420961109339
[Epoch 7, Batch 2200] loss: 0.019746125024012143
[Epoch 7, Batch 2300] loss: 0.019046651850876516
[Epoch 7, Batch 2400] loss: 0.021478431395589723
[Epoch 7, Batch 2500] loss: 0.028806322640193685
[Epoch 7, Batch 2600] loss: 0.00964433967430523
[Epoch 7, Batch 2700] loss: 0.010351430055216042
[Epoch 7, Batch 2800] loss: 0.02068376288743366
[Epoch 7, Batch 2900] loss: 0.02504527300099653
[Epoch 7, Batch 3000] loss: 0.011977475299108847
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0425
Validation Accuracy: 0.9888
Overfitting: 0.0425
[Epoch 8, Batch 100] loss: 0.01083968035452017
[Epoch 8, Batch 200] loss: 0.012979991169249843
[Epoch 8, Batch 300] loss: 0.015710904682791807
[Epoch 8, Batch 400] loss: 0.013118728186468616
[Epoch 8, Batch 500] loss: 0.019431377022083324
[Epoch 8, Batch 600] loss: 0.009350524906385544
[Epoch 8, Batch 700] loss: 0.011703701339537248
[Epoch 8, Batch 800] loss: 0.019266248093217656
[Epoch 8, Batch 900] loss: 0.02535060610029177
[Epoch 8, Batch 1000] loss: 0.016360315012701677
[Epoch 8, Batch 1100] loss: 0.02521535706795021
[Epoch 8, Batch 1200] loss: 0.02383894850365323
[Epoch 8, Batch 1300] loss: 0.025307596715865657
[Epoch 8, Batch 1400] loss: 0.01783035362245755
[Epoch 8, Batch 1500] loss: 0.02188781526224375
[Epoch 8, Batch 1600] loss: 0.009241853607582015
[Epoch 8, Batch 1700] loss: 0.01453753788713584
[Epoch 8, Batch 1800] loss: 0.020489965967817624
[Epoch 8, Batch 1900] loss: 0.015096737042276799
[Epoch 8, Batch 2000] loss: 0.013318888623919065
[Epoch 8, Batch 2100] loss: 0.01749019310829226
[Epoch 8, Batch 2200] loss: 0.019255680751030013
[Epoch 8, Batch 2300] loss: 0.02017695403899779
[Epoch 8, Batch 2400] loss: 0.02938900188521984
[Epoch 8, Batch 2500] loss: 0.03029824898125298
[Epoch 8, Batch 2600] loss: 0.012072457776248484
[Epoch 8, Batch 2700] loss: 0.02786401326405212
[Epoch 8, Batch 2800] loss: 0.015014088184507272
[Epoch 8, Batch 2900] loss: 0.015208685632642301
[Epoch 8, Batch 3000] loss: 0.01151851946474835
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0579
Validation Accuracy: 0.9828
Overfitting: 0.0579
[Epoch 9, Batch 100] loss: 0.018933030595921992
[Epoch 9, Batch 200] loss: 0.006360174921328507
[Epoch 9, Batch 300] loss: 0.019289693697410258
[Epoch 9, Batch 400] loss: 0.015369987628805575
[Epoch 9, Batch 500] loss: 0.013768560181392785
[Epoch 9, Batch 600] loss: 0.008094109079813734
[Epoch 9, Batch 700] loss: 0.020485326113787325
[Epoch 9, Batch 800] loss: 0.006687631930308271
[Epoch 9, Batch 900] loss: 0.010698218258782503
[Epoch 9, Batch 1000] loss: 0.004033664276798845
[Epoch 9, Batch 1100] loss: 0.009195690513624868
[Epoch 9, Batch 1200] loss: 0.009993136243629124
[Epoch 9, Batch 1300] loss: 0.013075064742924952
[Epoch 9, Batch 1400] loss: 0.006678370519725831
[Epoch 9, Batch 1500] loss: 0.009331464619151575
[Epoch 9, Batch 1600] loss: 0.01154037059246093
[Epoch 9, Batch 1700] loss: 0.012874480018112991
[Epoch 9, Batch 1800] loss: 0.01656157335931084
[Epoch 9, Batch 1900] loss: 0.0193703130798076
[Epoch 9, Batch 2000] loss: 0.0123782274256223
[Epoch 9, Batch 2100] loss: 0.008677404605541596
[Epoch 9, Batch 2200] loss: 0.01872335517650299
[Epoch 9, Batch 2300] loss: 0.02583800392577359
[Epoch 9, Batch 2400] loss: 0.015523802992665878
[Epoch 9, Batch 2500] loss: 0.012271792309848024
[Epoch 9, Batch 2600] loss: 0.02199372633076564
[Epoch 9, Batch 2700] loss: 0.021376697524444807
[Epoch 9, Batch 2800] loss: 0.024103166752502146
[Epoch 9, Batch 2900] loss: 0.024731285828365798
[Epoch 9, Batch 3000] loss: 0.01276268852991052
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0409
Validation Accuracy: 0.9883
Overfitting: 0.0409
Best model saved at epoch 9 with validation loss: 0.0409
[Epoch 10, Batch 100] loss: 0.017621561847804515
[Epoch 10, Batch 200] loss: 0.008875960010745984
[Epoch 10, Batch 300] loss: 0.0208817766635093
[Epoch 10, Batch 400] loss: 0.008743672469699959
[Epoch 10, Batch 500] loss: 0.006061056406942953
[Epoch 10, Batch 600] loss: 0.006349480149353894
[Epoch 10, Batch 700] loss: 0.010338549184918975
[Epoch 10, Batch 800] loss: 0.011047239127656212
[Epoch 10, Batch 900] loss: 0.004799247969285716
[Epoch 10, Batch 1000] loss: 0.01695100946593584
[Epoch 10, Batch 1100] loss: 0.011470484196679535
[Epoch 10, Batch 1200] loss: 0.009961611435410305
[Epoch 10, Batch 1300] loss: 0.013391577908607814
[Epoch 10, Batch 1400] loss: 0.008844108277120313
[Epoch 10, Batch 1500] loss: 0.015336111872798028
[Epoch 10, Batch 1600] loss: 0.015172404454260687
[Epoch 10, Batch 1700] loss: 0.014339642238693386
[Epoch 10, Batch 1800] loss: 0.014514288148257037
[Epoch 10, Batch 1900] loss: 0.014928625595936183
[Epoch 10, Batch 2000] loss: 0.014573477425078635
[Epoch 10, Batch 2100] loss: 0.010551815761355101
[Epoch 10, Batch 2200] loss: 0.017927855590992293
[Epoch 10, Batch 2300] loss: 0.008660493125153152
[Epoch 10, Batch 2400] loss: 0.009828424056254335
[Epoch 10, Batch 2500] loss: 0.012995514040394483
[Epoch 10, Batch 2600] loss: 0.009491662548552994
[Epoch 10, Batch 2700] loss: 0.011082057737569357
[Epoch 10, Batch 2800] loss: 0.0160014973629427
[Epoch 10, Batch 2900] loss: 0.012228234404192335
[Epoch 10, Batch 3000] loss: 0.01011428279073698
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0438
Validation Accuracy: 0.9882
Overfitting: 0.0438
[Epoch 11, Batch 100] loss: 0.008558599894417967
[Epoch 11, Batch 200] loss: 0.009361402052199139
[Epoch 11, Batch 300] loss: 0.0060468655138947724
[Epoch 11, Batch 400] loss: 0.00423035131505003
[Epoch 11, Batch 500] loss: 0.006097137672459212
[Epoch 11, Batch 600] loss: 0.012846091095880183
[Epoch 11, Batch 700] loss: 0.0020342232559642072
[Epoch 11, Batch 800] loss: 0.008019489166260883
[Epoch 11, Batch 900] loss: 0.01427381758018555
[Epoch 11, Batch 1000] loss: 0.0028515654162805503
[Epoch 11, Batch 1100] loss: 0.005764635059197189
[Epoch 11, Batch 1200] loss: 0.007725382929227181
[Epoch 11, Batch 1300] loss: 0.007053819217600221
[Epoch 11, Batch 1400] loss: 0.016630363702029173
[Epoch 11, Batch 1500] loss: 0.00767260876427315
[Epoch 11, Batch 1600] loss: 0.008988549744784677
[Epoch 11, Batch 1700] loss: 0.007119912167959228
[Epoch 11, Batch 1800] loss: 0.02036997205243466
[Epoch 11, Batch 1900] loss: 0.011926165712557122
[Epoch 11, Batch 2000] loss: 0.00967032544321455
[Epoch 11, Batch 2100] loss: 0.009212057191583085
[Epoch 11, Batch 2200] loss: 0.008869378760825839
[Epoch 11, Batch 2300] loss: 0.02682276713176634
[Epoch 11, Batch 2400] loss: 0.01742600953167539
[Epoch 11, Batch 2500] loss: 0.014332276734028255
[Epoch 11, Batch 2600] loss: 0.0145881888033
[Epoch 11, Batch 2700] loss: 0.01175105650817386
[Epoch 11, Batch 2800] loss: 0.012182196636053959
[Epoch 11, Batch 2900] loss: 0.015061541918482817
[Epoch 11, Batch 3000] loss: 0.017787131956808935
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0409
Validation Accuracy: 0.9892
Overfitting: 0.0409
Best model saved at epoch 11 with validation loss: 0.0409
[Epoch 12, Batch 100] loss: 0.004719396641198728
[Epoch 12, Batch 200] loss: 0.009091494028911028
[Epoch 12, Batch 300] loss: 0.005245610508302434
[Epoch 12, Batch 400] loss: 0.017506347136213664
[Epoch 12, Batch 500] loss: 0.0075508034842823694
[Epoch 12, Batch 600] loss: 0.0032062458434893417
[Epoch 12, Batch 700] loss: 0.009050773107460372
[Epoch 12, Batch 800] loss: 0.005464473684805853
[Epoch 12, Batch 900] loss: 0.009522050476368804
[Epoch 12, Batch 1000] loss: 0.004701763561577081
[Epoch 12, Batch 1100] loss: 0.003145586619507412
[Epoch 12, Batch 1200] loss: 0.005978229293324375
[Epoch 12, Batch 1300] loss: 0.007849204553497201
[Epoch 12, Batch 1400] loss: 0.006074079684399294
[Epoch 12, Batch 1500] loss: 0.011886479718673399
[Epoch 12, Batch 1600] loss: 0.016518744773974275
[Epoch 12, Batch 1700] loss: 0.005022370557867362
[Epoch 12, Batch 1800] loss: 0.007391171657066593
[Epoch 12, Batch 1900] loss: 0.009688935979294228
[Epoch 12, Batch 2000] loss: 0.010567923533084382
[Epoch 12, Batch 2100] loss: 0.002873932497849836
[Epoch 12, Batch 2200] loss: 0.007811891119619076
[Epoch 12, Batch 2300] loss: 0.009242169209452982
[Epoch 12, Batch 2400] loss: 0.011718322531515923
[Epoch 12, Batch 2500] loss: 0.011931523401843265
[Epoch 12, Batch 2600] loss: 0.021216662737893445
[Epoch 12, Batch 2700] loss: 0.020904746024812085
[Epoch 12, Batch 2800] loss: 0.013680998623455025
[Epoch 12, Batch 2900] loss: 0.012983487944466106
[Epoch 12, Batch 3000] loss: 0.01586999173128788
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0398
Validation Accuracy: 0.9896
Overfitting: 0.0398
Best model saved at epoch 12 with validation loss: 0.0398
[Epoch 13, Batch 100] loss: 0.005883270160256871
[Epoch 13, Batch 200] loss: 0.005139165204603842
[Epoch 13, Batch 300] loss: 0.006975244576286741
[Epoch 13, Batch 400] loss: 0.005414877252644601
[Epoch 13, Batch 500] loss: 0.008174780539154653
[Epoch 13, Batch 600] loss: 0.002360060920213982
[Epoch 13, Batch 700] loss: 0.005744532526862542
[Epoch 13, Batch 800] loss: 0.0025059863838578166
[Epoch 13, Batch 900] loss: 0.004468202558509233
[Epoch 13, Batch 1000] loss: 0.0031592447406694644
[Epoch 13, Batch 1100] loss: 0.0026840870571186314
[Epoch 13, Batch 1200] loss: 0.0038927812927320813
[Epoch 13, Batch 1300] loss: 0.007168043628890928
[Epoch 13, Batch 1400] loss: 0.0049344964376083315
[Epoch 13, Batch 1500] loss: 0.004119346013894187
[Epoch 13, Batch 1600] loss: 0.002558880800312977
[Epoch 13, Batch 1700] loss: 0.003511643454968407
[Epoch 13, Batch 1800] loss: 0.005602437780847112
[Epoch 13, Batch 1900] loss: 0.010669622831833045
[Epoch 13, Batch 2000] loss: 0.010393196735497412
[Epoch 13, Batch 2100] loss: 0.003037782830539868
[Epoch 13, Batch 2200] loss: 0.002421528833360469
[Epoch 13, Batch 2300] loss: 0.0022373986936415234
[Epoch 13, Batch 2400] loss: 0.012222307324801989
[Epoch 13, Batch 2500] loss: 0.013817989657578095
[Epoch 13, Batch 2600] loss: 0.011235039513196625
[Epoch 13, Batch 2700] loss: 0.004585152930937042
[Epoch 13, Batch 2800] loss: 0.005929059502764389
[Epoch 13, Batch 2900] loss: 0.004410100745864724
[Epoch 13, Batch 3000] loss: 0.008793591970332955
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9859
Overfitting: 0.0538
[Epoch 14, Batch 100] loss: 0.0101665620087374
[Epoch 14, Batch 200] loss: 0.011953304348781302
[Epoch 14, Batch 300] loss: 0.01480938402782158
[Epoch 14, Batch 400] loss: 0.004961186368654182
[Epoch 14, Batch 500] loss: 0.002783022802730102
[Epoch 14, Batch 600] loss: 0.005185206758635558
[Epoch 14, Batch 700] loss: 0.00426198686405769
[Epoch 14, Batch 800] loss: 0.0044758509033982815
[Epoch 14, Batch 900] loss: 0.0074609001104101935
[Epoch 14, Batch 1000] loss: 0.010069878403178335
[Epoch 14, Batch 1100] loss: 0.008586135780581969
[Epoch 14, Batch 1200] loss: 0.015393192279485107
[Epoch 14, Batch 1300] loss: 0.014977835526501053
[Epoch 14, Batch 1400] loss: 0.0034158332740730655
[Epoch 14, Batch 1500] loss: 0.007463482149570382
[Epoch 14, Batch 1600] loss: 0.013295468667838008
[Epoch 14, Batch 1700] loss: 0.010382348123569045
[Epoch 14, Batch 1800] loss: 0.013413728291963451
[Epoch 14, Batch 1900] loss: 0.011192279151130151
[Epoch 14, Batch 2000] loss: 0.009626942376987122
[Epoch 14, Batch 2100] loss: 0.01660686956426048
[Epoch 14, Batch 2200] loss: 0.0019333244923655
[Epoch 14, Batch 2300] loss: 0.007005479392039433
[Epoch 14, Batch 2400] loss: 0.011599955045155638
[Epoch 14, Batch 2500] loss: 0.014174841671987223
[Epoch 14, Batch 2600] loss: 0.01884741633735757
[Epoch 14, Batch 2700] loss: 0.009572271416527656
[Epoch 14, Batch 2800] loss: 0.01888107779333268
[Epoch 14, Batch 2900] loss: 0.01940881276467394
[Epoch 14, Batch 3000] loss: 0.01896913030371053
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9887
Overfitting: 0.0441
[Epoch 15, Batch 100] loss: 0.007890942492476825
[Epoch 15, Batch 200] loss: 0.004022520384950212
[Epoch 15, Batch 300] loss: 0.006056995831268068
[Epoch 15, Batch 400] loss: 0.002210890667489593
[Epoch 15, Batch 500] loss: 0.002224860011584724
[Epoch 15, Batch 600] loss: 0.0032436083406523863
[Epoch 15, Batch 700] loss: 0.00500540845789601
[Epoch 15, Batch 800] loss: 0.0034659184988312577
[Epoch 15, Batch 900] loss: 0.008583298997017437
[Epoch 15, Batch 1000] loss: 0.00313972385037232
[Epoch 15, Batch 1100] loss: 0.006520882090474061
[Epoch 15, Batch 1200] loss: 0.00315732954813825
[Epoch 15, Batch 1300] loss: 0.0035016555394946636
[Epoch 15, Batch 1400] loss: 0.0079595313806567
[Epoch 15, Batch 1500] loss: 0.014260798162293895
[Epoch 15, Batch 1600] loss: 0.00929801698007509
[Epoch 15, Batch 1700] loss: 0.008629800329688351
[Epoch 15, Batch 1800] loss: 0.01172953640029334
[Epoch 15, Batch 1900] loss: 0.014518211033508522
[Epoch 15, Batch 2000] loss: 0.01888402939743543
[Epoch 15, Batch 2100] loss: 0.00489155709654824
[Epoch 15, Batch 2200] loss: 0.014582640275056064
[Epoch 15, Batch 2300] loss: 0.030018406600799637
[Epoch 15, Batch 2400] loss: 0.013418276206795098
[Epoch 15, Batch 2500] loss: 0.010582431913360325
[Epoch 15, Batch 2600] loss: 0.012216530982739187
[Epoch 15, Batch 2700] loss: 0.007065597257278569
[Epoch 15, Batch 2800] loss: 0.006880481070610927
[Epoch 15, Batch 2900] loss: 0.006140981843819873
[Epoch 15, Batch 3000] loss: 0.012351574432773304
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0419
Validation Accuracy: 0.9895
Overfitting: 0.0419
[Epoch 16, Batch 100] loss: 0.005506886784071412
[Epoch 16, Batch 200] loss: 0.012529341226763507
[Epoch 16, Batch 300] loss: 0.009232359331621467
[Epoch 16, Batch 400] loss: 0.009213282323078715
[Epoch 16, Batch 500] loss: 0.004072619007638422
[Epoch 16, Batch 600] loss: 0.008479994833035107
[Epoch 16, Batch 700] loss: 0.0013836011815229199
[Epoch 16, Batch 800] loss: 0.0019798470733570638
[Epoch 16, Batch 900] loss: 0.005396722457261376
[Epoch 16, Batch 1000] loss: 0.007849298385118502
[Epoch 16, Batch 1100] loss: 0.0018114511478060536
[Epoch 16, Batch 1200] loss: 0.005616624735955327
[Epoch 16, Batch 1300] loss: 0.0034460109045383546
[Epoch 16, Batch 1400] loss: 0.0038952365568010097
[Epoch 16, Batch 1500] loss: 0.003007284047475309
[Epoch 16, Batch 1600] loss: 0.0016530646769507484
[Epoch 16, Batch 1700] loss: 0.004179031666773199
[Epoch 16, Batch 1800] loss: 0.0022824346460865287
[Epoch 16, Batch 1900] loss: 0.002707338366647676
[Epoch 16, Batch 2000] loss: 0.00430843340652018
[Epoch 16, Batch 2100] loss: 0.0029574778920333955
[Epoch 16, Batch 2200] loss: 0.0034697589997247746
[Epoch 16, Batch 2300] loss: 0.0012905330578340112
[Epoch 16, Batch 2400] loss: 0.00458128002533389
[Epoch 16, Batch 2500] loss: 0.008923461918970971
[Epoch 16, Batch 2600] loss: 0.011774884557954692
[Epoch 16, Batch 2700] loss: 0.0038610645134070864
[Epoch 16, Batch 2800] loss: 0.005138266405935497
[Epoch 16, Batch 2900] loss: 0.006131391703953
[Epoch 16, Batch 3000] loss: 0.006785029795805713
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0438
Validation Accuracy: 0.9891
Overfitting: 0.0438
[Epoch 17, Batch 100] loss: 0.003238518405244122
[Epoch 17, Batch 200] loss: 0.0017066457105681821
[Epoch 17, Batch 300] loss: 0.0019058939813780284
[Epoch 17, Batch 400] loss: 0.0034530434463363236
[Epoch 17, Batch 500] loss: 0.0005569419901132733
[Epoch 17, Batch 600] loss: 0.0007996163372489207
[Epoch 17, Batch 700] loss: 0.0027619501936464986
[Epoch 17, Batch 800] loss: 0.0026805920600088485
[Epoch 17, Batch 900] loss: 0.0008044379634230481
[Epoch 17, Batch 1000] loss: 0.0013811457954223273
[Epoch 17, Batch 1100] loss: 0.003626052354685916
[Epoch 17, Batch 1200] loss: 0.0015193058852390263
[Epoch 17, Batch 1300] loss: 0.0007300372127833299
[Epoch 17, Batch 1400] loss: 0.005802639517425981
[Epoch 17, Batch 1500] loss: 0.002249462864846201
[Epoch 17, Batch 1600] loss: 0.0035937189593988703
[Epoch 17, Batch 1700] loss: 0.0009897511080843913
[Epoch 17, Batch 1800] loss: 0.006354196802196981
[Epoch 17, Batch 1900] loss: 0.00402781649606423
[Epoch 17, Batch 2000] loss: 0.0007451013599072098
[Epoch 17, Batch 2100] loss: 0.004602865178721629
[Epoch 17, Batch 2200] loss: 0.0102233224399815
[Epoch 17, Batch 2300] loss: 0.011768560005404183
[Epoch 17, Batch 2400] loss: 0.0035700843793678326
[Epoch 17, Batch 2500] loss: 0.005988323096833028
[Epoch 17, Batch 2600] loss: 0.006729806073360578
[Epoch 17, Batch 2700] loss: 0.008860911050248887
[Epoch 17, Batch 2800] loss: 0.011818759641060978
[Epoch 17, Batch 2900] loss: 0.011828082206968595
[Epoch 17, Batch 3000] loss: 0.004214794176534262
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9892
Overfitting: 0.0487
[Epoch 18, Batch 100] loss: 0.005021805919303972
[Epoch 18, Batch 200] loss: 0.007003573007743853
[Epoch 18, Batch 300] loss: 0.007515270673434315
[Epoch 18, Batch 400] loss: 0.023948642232285308
[Epoch 18, Batch 500] loss: 0.00882832527353429
[Epoch 18, Batch 600] loss: 0.013984390739337016
[Epoch 18, Batch 700] loss: 0.012905422632389616
[Epoch 18, Batch 800] loss: 0.0016190005491245074
[Epoch 18, Batch 900] loss: 0.004314596262136092
[Epoch 18, Batch 1000] loss: 0.005437662589393702
[Epoch 18, Batch 1100] loss: 0.0061150658734770505
[Epoch 18, Batch 1200] loss: 0.006055456153212049
[Epoch 18, Batch 1300] loss: 0.013339360294786218
[Epoch 18, Batch 1400] loss: 0.003930990790292981
[Epoch 18, Batch 1500] loss: 0.006040607082378244
[Epoch 18, Batch 1600] loss: 0.004987721539205268
[Epoch 18, Batch 1700] loss: 0.003070776268282316
[Epoch 18, Batch 1800] loss: 0.0015242780004708577
[Epoch 18, Batch 1900] loss: 0.0017540696575342452
[Epoch 18, Batch 2000] loss: 0.004829044104784668
[Epoch 18, Batch 2100] loss: 0.001874395678422962
[Epoch 18, Batch 2200] loss: 0.002190274054545398
[Epoch 18, Batch 2300] loss: 0.0012528120783531981
[Epoch 18, Batch 2400] loss: 0.003130372833791881
[Epoch 18, Batch 2500] loss: 0.00601435606164074
[Epoch 18, Batch 2600] loss: 0.004970623073300793
[Epoch 18, Batch 2700] loss: 0.007286811002445646
[Epoch 18, Batch 2800] loss: 0.0167811529551075
[Epoch 18, Batch 2900] loss: 0.005745508805671804
[Epoch 18, Batch 3000] loss: 0.004698068919473144
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9888
Overfitting: 0.0477
[Epoch 19, Batch 100] loss: 0.0009985530832420863
[Epoch 19, Batch 200] loss: 0.00253407898635615
[Epoch 19, Batch 300] loss: 0.000984611117212353
[Epoch 19, Batch 400] loss: 0.003585499599512083
[Epoch 19, Batch 500] loss: 0.0009247229349777797
[Epoch 19, Batch 600] loss: 0.006140708208970551
[Epoch 19, Batch 700] loss: 0.0021064586086596295
[Epoch 19, Batch 800] loss: 0.0023086925397028278
[Epoch 19, Batch 900] loss: 0.0014847634103529472
[Epoch 19, Batch 1000] loss: 0.0021286924270439924
[Epoch 19, Batch 1100] loss: 0.001970172011419384
[Epoch 19, Batch 1200] loss: 0.00876674700576615
[Epoch 19, Batch 1300] loss: 0.00938546551714552
[Epoch 19, Batch 1400] loss: 0.009262385946563114
[Epoch 19, Batch 1500] loss: 0.008275869526454614
[Epoch 19, Batch 1600] loss: 0.0050664946648961975
[Epoch 19, Batch 1700] loss: 0.0009289316774240852
[Epoch 19, Batch 1800] loss: 0.001776990817933175
[Epoch 19, Batch 1900] loss: 0.002556918736879079
[Epoch 19, Batch 2000] loss: 0.0023739197286343438
[Epoch 19, Batch 2100] loss: 0.00420921445419772
[Epoch 19, Batch 2200] loss: 0.000927680519442955
[Epoch 19, Batch 2300] loss: 0.0024942593800773238
[Epoch 19, Batch 2400] loss: 0.0021729981641589544
[Epoch 19, Batch 2500] loss: 0.004211404898832054
[Epoch 19, Batch 2600] loss: 0.002060846179316158
[Epoch 19, Batch 2700] loss: 0.003907033636601102
[Epoch 19, Batch 2800] loss: 0.002499735961892351
[Epoch 19, Batch 2900] loss: 0.005878207935278894
[Epoch 19, Batch 3000] loss: 0.0023339084881131454
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9887
Overfitting: 0.0525
[Epoch 20, Batch 100] loss: 0.008192036035074537
[Epoch 20, Batch 200] loss: 0.0013745729825932783
[Epoch 20, Batch 300] loss: 0.0015165314243071038
[Epoch 20, Batch 400] loss: 0.006752579616535286
[Epoch 20, Batch 500] loss: 0.0036433282316627926
[Epoch 20, Batch 600] loss: 0.007148978409187165
[Epoch 20, Batch 700] loss: 0.0022756989406938957
[Epoch 20, Batch 800] loss: 0.0009302372899097078
[Epoch 20, Batch 900] loss: 0.0019875703030374225
[Epoch 20, Batch 1000] loss: 0.0033812583150246668
[Epoch 20, Batch 1100] loss: 0.0038638217912052397
[Epoch 20, Batch 1200] loss: 0.0055663790743423645
[Epoch 20, Batch 1300] loss: 0.003194172606459205
[Epoch 20, Batch 1400] loss: 0.005814973659365439
[Epoch 20, Batch 1500] loss: 0.011530587188286354
[Epoch 20, Batch 1600] loss: 0.0061965754703261575
[Epoch 20, Batch 1700] loss: 0.002370792291972208
[Epoch 20, Batch 1800] loss: 0.008417963406353018
[Epoch 20, Batch 1900] loss: 0.0037906020014360563
[Epoch 20, Batch 2000] loss: 0.0010408197133563136
[Epoch 20, Batch 2100] loss: 0.0031182529189871387
[Epoch 20, Batch 2200] loss: 0.000535568477148658
[Epoch 20, Batch 2300] loss: 0.0013067297648158061
[Epoch 20, Batch 2400] loss: 0.004256256895595101
[Epoch 20, Batch 2500] loss: 0.002130083219645513
[Epoch 20, Batch 2600] loss: 0.0030747062721727713
[Epoch 20, Batch 2700] loss: 0.003137027886170216
[Epoch 20, Batch 2800] loss: 0.00485117918696524
[Epoch 20, Batch 2900] loss: 0.008052119467663505
[Epoch 20, Batch 3000] loss: 0.0030794074109459046
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9893
Overfitting: 0.0533
[Epoch 21, Batch 100] loss: 0.0022150404377211342
[Epoch 21, Batch 200] loss: 0.0010790037071198811
[Epoch 21, Batch 300] loss: 0.0008509196480429893
[Epoch 21, Batch 400] loss: 0.0010460277019860341
[Epoch 21, Batch 500] loss: 0.00039450008239171107
[Epoch 21, Batch 600] loss: 0.0003205301793996895
[Epoch 21, Batch 700] loss: 0.0008494059002275866
[Epoch 21, Batch 800] loss: 0.0021638071121011394
[Epoch 21, Batch 900] loss: 0.0008122993857071492
[Epoch 21, Batch 1000] loss: 0.0010002162027981853
[Epoch 21, Batch 1100] loss: 0.0017645220486622116
[Epoch 21, Batch 1200] loss: 0.0007188176752193565
[Epoch 21, Batch 1300] loss: 0.0009882044093592769
[Epoch 21, Batch 1400] loss: 0.002958911169966143
[Epoch 21, Batch 1500] loss: 0.0008774330334601643
[Epoch 21, Batch 1600] loss: 0.0005568006965605044
[Epoch 21, Batch 1700] loss: 0.00046501016062826305
[Epoch 21, Batch 1800] loss: 0.0011024583498699726
[Epoch 21, Batch 1900] loss: 0.0004659284047815859
[Epoch 21, Batch 2000] loss: 0.0005683258293177662
[Epoch 21, Batch 2100] loss: 0.0005305691615679598
[Epoch 21, Batch 2200] loss: 0.0033632012946936962
[Epoch 21, Batch 2300] loss: 0.0010229395719508006
[Epoch 21, Batch 2400] loss: 0.0007210543490323795
[Epoch 21, Batch 2500] loss: 0.007539803455302918
[Epoch 21, Batch 2600] loss: 0.0006040988559115146
[Epoch 21, Batch 2700] loss: 0.005371001142488368
[Epoch 21, Batch 2800] loss: 0.002049595945948397
[Epoch 21, Batch 2900] loss: 0.0005287605418476904
[Epoch 21, Batch 3000] loss: 0.0015876836241043434
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9898
Overfitting: 0.0515
[Epoch 22, Batch 100] loss: 0.0011310293827595252
[Epoch 22, Batch 200] loss: 0.0006678385153180066
[Epoch 22, Batch 300] loss: 0.0014904064042375875
[Epoch 22, Batch 400] loss: 0.00026894031203829273
[Epoch 22, Batch 500] loss: 0.000476459085941352
[Epoch 22, Batch 600] loss: 0.0012360959948191485
[Epoch 22, Batch 700] loss: 0.0001880043028531686
[Epoch 22, Batch 800] loss: 0.0006138808513691707
[Epoch 22, Batch 900] loss: 0.00045465367039194683
[Epoch 22, Batch 1000] loss: 0.00039641587609784423
[Epoch 22, Batch 1100] loss: 0.00036461448460504807
[Epoch 22, Batch 1200] loss: 0.00042560013550640985
[Epoch 22, Batch 1300] loss: 0.0004963515901682314
[Epoch 22, Batch 1400] loss: 0.00026117789231428824
[Epoch 22, Batch 1500] loss: 0.0007164193413677112
[Epoch 22, Batch 1600] loss: 0.001612843579745089
[Epoch 22, Batch 1700] loss: 0.0014277276893198908
[Epoch 22, Batch 1800] loss: 0.000667307798867327
[Epoch 22, Batch 1900] loss: 0.0003195491207970491
[Epoch 22, Batch 2000] loss: 0.004849272473764304
[Epoch 22, Batch 2100] loss: 0.0021506045514029194
[Epoch 22, Batch 2200] loss: 0.0014247590743097804
[Epoch 22, Batch 2300] loss: 0.00031407491256296716
[Epoch 22, Batch 2400] loss: 0.0015777379971470573
[Epoch 22, Batch 2500] loss: 0.0016455644750831234
[Epoch 22, Batch 2600] loss: 0.002532125354388701
[Epoch 22, Batch 2700] loss: 0.0005708625587462768
[Epoch 22, Batch 2800] loss: 0.00022211423984986212
[Epoch 22, Batch 2900] loss: 0.00210222965761373
[Epoch 22, Batch 3000] loss: 0.0006878505411262692
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9905
Overfitting: 0.0514
[Epoch 23, Batch 100] loss: 0.00036209481057634994
[Epoch 23, Batch 200] loss: 0.00022434591896826727
[Epoch 23, Batch 300] loss: 0.000151128569994321
[Epoch 23, Batch 400] loss: 0.0008178709927356475
[Epoch 23, Batch 500] loss: 0.0017452680871866333
[Epoch 23, Batch 600] loss: 0.00018604465320909647
[Epoch 23, Batch 700] loss: 0.0005288858900498905
[Epoch 23, Batch 800] loss: 0.00017875352078095653
[Epoch 23, Batch 900] loss: 0.003995771971003448
[Epoch 23, Batch 1000] loss: 0.00023563183920189968
[Epoch 23, Batch 1100] loss: 0.0005387803157539972
[Epoch 23, Batch 1200] loss: 0.0008375384532894836
[Epoch 23, Batch 1300] loss: 0.0027678389736206775
[Epoch 23, Batch 1400] loss: 0.004728134218102329
[Epoch 23, Batch 1500] loss: 0.00182874876706558
[Epoch 23, Batch 1600] loss: 0.0010733758311590603
[Epoch 23, Batch 1700] loss: 0.0004409582126256506
[Epoch 23, Batch 1800] loss: 0.00028899733237590207
[Epoch 23, Batch 1900] loss: 0.0027719240570211134
[Epoch 23, Batch 2000] loss: 0.00022967048963145942
[Epoch 23, Batch 2100] loss: 0.0013826620852303506
[Epoch 23, Batch 2200] loss: 0.00043796505449174907
[Epoch 23, Batch 2300] loss: 0.0005477693362228209
[Epoch 23, Batch 2400] loss: 0.0018939468257060943
[Epoch 23, Batch 2500] loss: 0.0016327847475000822
[Epoch 23, Batch 2600] loss: 0.0013748882476083857
[Epoch 23, Batch 2700] loss: 0.0005039726607326367
[Epoch 23, Batch 2800] loss: 0.0007335748222219962
[Epoch 23, Batch 2900] loss: 0.00019956157460229384
[Epoch 23, Batch 3000] loss: 0.0002057575874248352
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9908
Overfitting: 0.0505
[Epoch 24, Batch 100] loss: 0.00021151233487762155
[Epoch 24, Batch 200] loss: 0.00017213120889676857
[Epoch 24, Batch 300] loss: 0.00030660328748917555
[Epoch 24, Batch 400] loss: 0.0002470129696821033
[Epoch 24, Batch 500] loss: 0.00024236092511384922
[Epoch 24, Batch 600] loss: 0.0002219536580767345
[Epoch 24, Batch 700] loss: 0.0004927905891839357
[Epoch 24, Batch 800] loss: 0.00024364749771750737
[Epoch 24, Batch 900] loss: 0.00023071561867337386
[Epoch 24, Batch 1000] loss: 0.00010541322794066054
[Epoch 24, Batch 1100] loss: 0.00017207130064021304
[Epoch 24, Batch 1200] loss: 0.0004868590223184155
[Epoch 24, Batch 1300] loss: 0.00014224935968943254
[Epoch 24, Batch 1400] loss: 0.0003048533349905247
[Epoch 24, Batch 1500] loss: 5.583019319975957e-05
[Epoch 24, Batch 1600] loss: 0.0003345312803031897
[Epoch 24, Batch 1700] loss: 9.275346508754722e-05
[Epoch 24, Batch 1800] loss: 0.0005340048171879852
[Epoch 24, Batch 1900] loss: 0.00014309812894402807
[Epoch 24, Batch 2000] loss: 0.00031357143661788547
[Epoch 24, Batch 2100] loss: 0.000960250474479758
[Epoch 24, Batch 2200] loss: 0.0007871619769920146
[Epoch 24, Batch 2300] loss: 0.0014466533348560828
[Epoch 24, Batch 2400] loss: 0.0003541313699686466
[Epoch 24, Batch 2500] loss: 8.381326330979987e-05
[Epoch 24, Batch 2600] loss: 0.0001965328157925539
[Epoch 24, Batch 2700] loss: 0.00014874874396195726
[Epoch 24, Batch 2800] loss: 6.373199168114408e-05
[Epoch 24, Batch 2900] loss: 0.0004416149150829929
[Epoch 24, Batch 3000] loss: 4.86271497327273e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9903
Overfitting: 0.0538
Fold 5 validation loss: 0.0538
Mean validation loss across all folds for Trial 12 is 0.0552 with trial config:  l1: 256, l2: 64, lr: 0.0027085521441034656, batch_size: 16
[I 2024-12-11 04:57:24,808] Trial 11 finished with value: 0.05522732152076291 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0027085521441034656, 'batch_size': 16}. Best is trial 4 with value: 0.04724671796616846.

Selected Hyperparameters for Trial 13:
  l1: 128, l2: 64, lr: 0.0021608588039666666, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2994737339019777
[Epoch 1, Batch 200] loss: 2.262235548496246
[Epoch 1, Batch 300] loss: 1.7516847133636475
[Epoch 1, Batch 400] loss: 0.7435151399672031
[Epoch 1, Batch 500] loss: 0.5074455983191729
[Epoch 1, Batch 600] loss: 0.41627253279089926
[Epoch 1, Batch 700] loss: 0.3599392473511398
[Epoch 1, Batch 800] loss: 0.2622280957363546
[Epoch 1, Batch 900] loss: 0.21548521220684053
[Epoch 1, Batch 1000] loss: 0.17979100661352276
[Epoch 1, Batch 1100] loss: 0.16033707734197378
[Epoch 1, Batch 1200] loss: 0.18405815478414297
[Epoch 1, Batch 1300] loss: 0.18696501214988528
[Epoch 1, Batch 1400] loss: 0.1563871699757874
[Epoch 1, Batch 1500] loss: 0.15936878048814834
[Epoch 1, Batch 1600] loss: 0.1500086688855663
[Epoch 1, Batch 1700] loss: 0.13156835419125856
[Epoch 1, Batch 1800] loss: 0.13142778479028494
[Epoch 1, Batch 1900] loss: 0.12069753660354764
[Epoch 1, Batch 2000] loss: 0.12497126381844283
[Epoch 1, Batch 2100] loss: 0.11030154918087647
[Epoch 1, Batch 2200] loss: 0.09559473819797859
[Epoch 1, Batch 2300] loss: 0.12744667620863764
[Epoch 1, Batch 2400] loss: 0.09525423521175981
[Epoch 1, Batch 2500] loss: 0.10833328306383919
[Epoch 1, Batch 2600] loss: 0.11991127748275175
[Epoch 1, Batch 2700] loss: 0.10402548319776543
[Epoch 1, Batch 2800] loss: 0.08669008857570588
[Epoch 1, Batch 2900] loss: 0.0910661190393148
[Epoch 1, Batch 3000] loss: 0.09566529582371004
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1031
Validation Accuracy: 0.9654
Overfitting: 0.1031
Best model saved at epoch 1 with validation loss: 0.1031
[Epoch 2, Batch 100] loss: 0.09496022974373773
[Epoch 2, Batch 200] loss: 0.0963993121573003
[Epoch 2, Batch 300] loss: 0.10619186857133173
[Epoch 2, Batch 400] loss: 0.07899156725034118
[Epoch 2, Batch 500] loss: 0.08206416420813184
[Epoch 2, Batch 600] loss: 0.08347779789124615
[Epoch 2, Batch 700] loss: 0.06917434444185347
[Epoch 2, Batch 800] loss: 0.08510357999126426
[Epoch 2, Batch 900] loss: 0.08788336210418493
[Epoch 2, Batch 1000] loss: 0.07197287881514057
[Epoch 2, Batch 1100] loss: 0.08160745205066633
[Epoch 2, Batch 1200] loss: 0.060915195578709246
[Epoch 2, Batch 1300] loss: 0.07692844588018488
[Epoch 2, Batch 1400] loss: 0.0683171269216109
[Epoch 2, Batch 1500] loss: 0.07136012941773515
[Epoch 2, Batch 1600] loss: 0.07889762173290364
[Epoch 2, Batch 1700] loss: 0.06419517732807435
[Epoch 2, Batch 1800] loss: 0.06392802662187023
[Epoch 2, Batch 1900] loss: 0.08847227137302979
[Epoch 2, Batch 2000] loss: 0.07309442591678816
[Epoch 2, Batch 2100] loss: 0.0662163414718816
[Epoch 2, Batch 2200] loss: 0.08527320575667545
[Epoch 2, Batch 2300] loss: 0.07000353943789378
[Epoch 2, Batch 2400] loss: 0.0699763683625497
[Epoch 2, Batch 2500] loss: 0.08930266972631216
[Epoch 2, Batch 2600] loss: 0.05686290191355511
[Epoch 2, Batch 2700] loss: 0.09535789252317045
[Epoch 2, Batch 2800] loss: 0.052463917485438286
[Epoch 2, Batch 2900] loss: 0.060518596107140187
[Epoch 2, Batch 3000] loss: 0.0675106896366924
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0730
Validation Accuracy: 0.9754
Overfitting: 0.0730
Best model saved at epoch 2 with validation loss: 0.0730
[Epoch 3, Batch 100] loss: 0.06193169950682204
[Epoch 3, Batch 200] loss: 0.04037707170966314
[Epoch 3, Batch 300] loss: 0.039069802345475184
[Epoch 3, Batch 400] loss: 0.05994171500962693
[Epoch 3, Batch 500] loss: 0.046735309980431336
[Epoch 3, Batch 600] loss: 0.07277580292109632
[Epoch 3, Batch 700] loss: 0.056174785532057285
[Epoch 3, Batch 800] loss: 0.060964267769595605
[Epoch 3, Batch 900] loss: 0.06175122461863793
[Epoch 3, Batch 1000] loss: 0.05211642016482074
[Epoch 3, Batch 1100] loss: 0.05319061820700881
[Epoch 3, Batch 1200] loss: 0.05927523955208017
[Epoch 3, Batch 1300] loss: 0.05641283711709548
[Epoch 3, Batch 1400] loss: 0.052772170765529154
[Epoch 3, Batch 1500] loss: 0.07008113575575407
[Epoch 3, Batch 1600] loss: 0.041879023592337035
[Epoch 3, Batch 1700] loss: 0.051638267788803205
[Epoch 3, Batch 1800] loss: 0.0671202145915595
[Epoch 3, Batch 1900] loss: 0.04477113313652808
[Epoch 3, Batch 2000] loss: 0.044352566364686936
[Epoch 3, Batch 2100] loss: 0.039542116976808754
[Epoch 3, Batch 2200] loss: 0.04418715589490603
[Epoch 3, Batch 2300] loss: 0.05745157968092826
[Epoch 3, Batch 2400] loss: 0.07382698782370425
[Epoch 3, Batch 2500] loss: 0.04779345207149163
[Epoch 3, Batch 2600] loss: 0.037297538846178216
[Epoch 3, Batch 2700] loss: 0.0595965560345212
[Epoch 3, Batch 2800] loss: 0.04767070064888685
[Epoch 3, Batch 2900] loss: 0.04569297681184253
[Epoch 3, Batch 3000] loss: 0.03702603122626897
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9841
Overfitting: 0.0513
Best model saved at epoch 3 with validation loss: 0.0513
[Epoch 4, Batch 100] loss: 0.024223762364126742
[Epoch 4, Batch 200] loss: 0.030529099457198755
[Epoch 4, Batch 300] loss: 0.04719160491957155
[Epoch 4, Batch 400] loss: 0.05006238133704755
[Epoch 4, Batch 500] loss: 0.0359037672719569
[Epoch 4, Batch 600] loss: 0.022522267967869995
[Epoch 4, Batch 700] loss: 0.054560272670933045
[Epoch 4, Batch 800] loss: 0.04381038565912604
[Epoch 4, Batch 900] loss: 0.03942925451221527
[Epoch 4, Batch 1000] loss: 0.05159677870120504
[Epoch 4, Batch 1100] loss: 0.04677530309360009
[Epoch 4, Batch 1200] loss: 0.04147394231855287
[Epoch 4, Batch 1300] loss: 0.05370416672842111
[Epoch 4, Batch 1400] loss: 0.040434821546805326
[Epoch 4, Batch 1500] loss: 0.044564438243978655
[Epoch 4, Batch 1600] loss: 0.036324910208641085
[Epoch 4, Batch 1700] loss: 0.037998246053321055
[Epoch 4, Batch 1800] loss: 0.04596902769993903
[Epoch 4, Batch 1900] loss: 0.04805617316749704
[Epoch 4, Batch 2000] loss: 0.03760683308981243
[Epoch 4, Batch 2100] loss: 0.042238295959250535
[Epoch 4, Batch 2200] loss: 0.04426926256041042
[Epoch 4, Batch 2300] loss: 0.04390868424823566
[Epoch 4, Batch 2400] loss: 0.0400225369204054
[Epoch 4, Batch 2500] loss: 0.05108796685977723
[Epoch 4, Batch 2600] loss: 0.03070809245662531
[Epoch 4, Batch 2700] loss: 0.055990261209371964
[Epoch 4, Batch 2800] loss: 0.03906905295414617
[Epoch 4, Batch 2900] loss: 0.045217527376371434
[Epoch 4, Batch 3000] loss: 0.042166302993719
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0419
Validation Accuracy: 0.9869
Overfitting: 0.0419
Best model saved at epoch 4 with validation loss: 0.0419
[Epoch 5, Batch 100] loss: 0.0353741239412193
[Epoch 5, Batch 200] loss: 0.030328933084383607
[Epoch 5, Batch 300] loss: 0.03195733995242336
[Epoch 5, Batch 400] loss: 0.02111010453227209
[Epoch 5, Batch 500] loss: 0.026569730295232147
[Epoch 5, Batch 600] loss: 0.03516446858426207
[Epoch 5, Batch 700] loss: 0.03971816130666411
[Epoch 5, Batch 800] loss: 0.04079753242462175
[Epoch 5, Batch 900] loss: 0.0473992502821784
[Epoch 5, Batch 1000] loss: 0.035694283280172386
[Epoch 5, Batch 1100] loss: 0.0252995717144222
[Epoch 5, Batch 1200] loss: 0.020795946246071253
[Epoch 5, Batch 1300] loss: 0.03696516593285196
[Epoch 5, Batch 1400] loss: 0.035666931592277254
[Epoch 5, Batch 1500] loss: 0.03482803895341931
[Epoch 5, Batch 1600] loss: 0.03510582201954094
[Epoch 5, Batch 1700] loss: 0.03368724807147373
[Epoch 5, Batch 1800] loss: 0.035440947982751825
[Epoch 5, Batch 1900] loss: 0.03853740056132665
[Epoch 5, Batch 2000] loss: 0.03872293272019306
[Epoch 5, Batch 2100] loss: 0.042817574370565124
[Epoch 5, Batch 2200] loss: 0.04072509977748268
[Epoch 5, Batch 2300] loss: 0.041287824580067536
[Epoch 5, Batch 2400] loss: 0.03735061835148372
[Epoch 5, Batch 2500] loss: 0.04053461623989278
[Epoch 5, Batch 2600] loss: 0.03211938044660201
[Epoch 5, Batch 2700] loss: 0.033211025641794546
[Epoch 5, Batch 2800] loss: 0.027079691139078932
[Epoch 5, Batch 2900] loss: 0.027211277122114554
[Epoch 5, Batch 3000] loss: 0.04459880858557881
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0373
Validation Accuracy: 0.9885
Overfitting: 0.0373
Best model saved at epoch 5 with validation loss: 0.0373
[Epoch 6, Batch 100] loss: 0.018496262036205736
[Epoch 6, Batch 200] loss: 0.025672247038128263
[Epoch 6, Batch 300] loss: 0.04045943997785798
[Epoch 6, Batch 400] loss: 0.02691409561688488
[Epoch 6, Batch 500] loss: 0.02248914591680659
[Epoch 6, Batch 600] loss: 0.02991030062923528
[Epoch 6, Batch 700] loss: 0.023243456292584598
[Epoch 6, Batch 800] loss: 0.02117531700117979
[Epoch 6, Batch 900] loss: 0.026709042053116718
[Epoch 6, Batch 1000] loss: 0.02232531432480755
[Epoch 6, Batch 1100] loss: 0.02756986209272327
[Epoch 6, Batch 1200] loss: 0.03052290063620603
[Epoch 6, Batch 1300] loss: 0.0365293736169042
[Epoch 6, Batch 1400] loss: 0.022847519230526813
[Epoch 6, Batch 1500] loss: 0.024388077628827887
[Epoch 6, Batch 1600] loss: 0.03640225030525471
[Epoch 6, Batch 1700] loss: 0.03637344157425105
[Epoch 6, Batch 1800] loss: 0.04069680371794675
[Epoch 6, Batch 1900] loss: 0.02100932361165178
[Epoch 6, Batch 2000] loss: 0.02417600706416124
[Epoch 6, Batch 2100] loss: 0.024427158165635773
[Epoch 6, Batch 2200] loss: 0.02289513105148217
[Epoch 6, Batch 2300] loss: 0.05327772370830644
[Epoch 6, Batch 2400] loss: 0.022279549284685344
[Epoch 6, Batch 2500] loss: 0.034988583823469525
[Epoch 6, Batch 2600] loss: 0.023047461181013206
[Epoch 6, Batch 2700] loss: 0.039377773662708934
[Epoch 6, Batch 2800] loss: 0.02467264111439363
[Epoch 6, Batch 2900] loss: 0.03384041945450008
[Epoch 6, Batch 3000] loss: 0.02396133338499567
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9860
Overfitting: 0.0468
[Epoch 7, Batch 100] loss: 0.02370853491815069
[Epoch 7, Batch 200] loss: 0.021497663822665346
[Epoch 7, Batch 300] loss: 0.016227184937524727
[Epoch 7, Batch 400] loss: 0.031139423936729145
[Epoch 7, Batch 500] loss: 0.031490226710448044
[Epoch 7, Batch 600] loss: 0.015501874796682387
[Epoch 7, Batch 700] loss: 0.031994370635320596
[Epoch 7, Batch 800] loss: 0.01967511878385267
[Epoch 7, Batch 900] loss: 0.021749579816896583
[Epoch 7, Batch 1000] loss: 0.025741256075743877
[Epoch 7, Batch 1100] loss: 0.01688642814577179
[Epoch 7, Batch 1200] loss: 0.02246598007128341
[Epoch 7, Batch 1300] loss: 0.01934942892079562
[Epoch 7, Batch 1400] loss: 0.02315617805684269
[Epoch 7, Batch 1500] loss: 0.026638218065963882
[Epoch 7, Batch 1600] loss: 0.022664752521159244
[Epoch 7, Batch 1700] loss: 0.022983565047979937
[Epoch 7, Batch 1800] loss: 0.013235472107662644
[Epoch 7, Batch 1900] loss: 0.03163810077669041
[Epoch 7, Batch 2000] loss: 0.030394379175340873
[Epoch 7, Batch 2100] loss: 0.02291575301136618
[Epoch 7, Batch 2200] loss: 0.023885811633444973
[Epoch 7, Batch 2300] loss: 0.03973219222742046
[Epoch 7, Batch 2400] loss: 0.019534151013249356
[Epoch 7, Batch 2500] loss: 0.02346643831624533
[Epoch 7, Batch 2600] loss: 0.02170481879140425
[Epoch 7, Batch 2700] loss: 0.038212777618318795
[Epoch 7, Batch 2800] loss: 0.026189683386764955
[Epoch 7, Batch 2900] loss: 0.03384697528403194
[Epoch 7, Batch 3000] loss: 0.028235493541214966
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0425
Validation Accuracy: 0.9874
Overfitting: 0.0425
[Epoch 8, Batch 100] loss: 0.013041918354265363
[Epoch 8, Batch 200] loss: 0.012732786536544154
[Epoch 8, Batch 300] loss: 0.018606200272752175
[Epoch 8, Batch 400] loss: 0.01699311906511866
[Epoch 8, Batch 500] loss: 0.01837424653459493
[Epoch 8, Batch 600] loss: 0.013993217472807374
[Epoch 8, Batch 700] loss: 0.010096083112243833
[Epoch 8, Batch 800] loss: 0.015784492749844503
[Epoch 8, Batch 900] loss: 0.0295920980510391
[Epoch 8, Batch 1000] loss: 0.02377670639027201
[Epoch 8, Batch 1100] loss: 0.03175821257631469
[Epoch 8, Batch 1200] loss: 0.027047752450707774
[Epoch 8, Batch 1300] loss: 0.017922058573622054
[Epoch 8, Batch 1400] loss: 0.03348802219959907
[Epoch 8, Batch 1500] loss: 0.01860163077173638
[Epoch 8, Batch 1600] loss: 0.011574195599296217
[Epoch 8, Batch 1700] loss: 0.013199065765102205
[Epoch 8, Batch 1800] loss: 0.016487870479613774
[Epoch 8, Batch 1900] loss: 0.016225977896237965
[Epoch 8, Batch 2000] loss: 0.02749843766359845
[Epoch 8, Batch 2100] loss: 0.023545643964862393
[Epoch 8, Batch 2200] loss: 0.02814713810534158
[Epoch 8, Batch 2300] loss: 0.027847028181986387
[Epoch 8, Batch 2400] loss: 0.02917752517932968
[Epoch 8, Batch 2500] loss: 0.036290923522174126
[Epoch 8, Batch 2600] loss: 0.020317052889004115
[Epoch 8, Batch 2700] loss: 0.017313775329239434
[Epoch 8, Batch 2800] loss: 0.028985902045205875
[Epoch 8, Batch 2900] loss: 0.01662733710523753
[Epoch 8, Batch 3000] loss: 0.03507455515838956
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0404
Validation Accuracy: 0.9876
Overfitting: 0.0404
[Epoch 9, Batch 100] loss: 0.017303826494953684
[Epoch 9, Batch 200] loss: 0.01873624959072913
[Epoch 9, Batch 300] loss: 0.015440984665201541
[Epoch 9, Batch 400] loss: 0.017328538219080657
[Epoch 9, Batch 500] loss: 0.03264150706403598
[Epoch 9, Batch 600] loss: 0.0181433239980106
[Epoch 9, Batch 700] loss: 0.02238123986363462
[Epoch 9, Batch 800] loss: 0.024304045648277678
[Epoch 9, Batch 900] loss: 0.01646487973926014
[Epoch 9, Batch 1000] loss: 0.0104316385803304
[Epoch 9, Batch 1100] loss: 0.009910275706752146
[Epoch 9, Batch 1200] loss: 0.013688498027031528
[Epoch 9, Batch 1300] loss: 0.014071269383230174
[Epoch 9, Batch 1400] loss: 0.010017789927076137
[Epoch 9, Batch 1500] loss: 0.017693406784653688
[Epoch 9, Batch 1600] loss: 0.01745785324753342
[Epoch 9, Batch 1700] loss: 0.01074846418032621
[Epoch 9, Batch 1800] loss: 0.023903265324515813
[Epoch 9, Batch 1900] loss: 0.028938945617028367
[Epoch 9, Batch 2000] loss: 0.028233137431543584
[Epoch 9, Batch 2100] loss: 0.012507975811595316
[Epoch 9, Batch 2200] loss: 0.011242489262222079
[Epoch 9, Batch 2300] loss: 0.019279143131116144
[Epoch 9, Batch 2400] loss: 0.015501583424702403
[Epoch 9, Batch 2500] loss: 0.012147179359935763
[Epoch 9, Batch 2600] loss: 0.025214375910250057
[Epoch 9, Batch 2700] loss: 0.029975976324913063
[Epoch 9, Batch 2800] loss: 0.016001536246258184
[Epoch 9, Batch 2900] loss: 0.011793641503518302
[Epoch 9, Batch 3000] loss: 0.018649950166500274
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9851
Overfitting: 0.0549
[Epoch 10, Batch 100] loss: 0.01498188802365803
[Epoch 10, Batch 200] loss: 0.007362850254630757
[Epoch 10, Batch 300] loss: 0.01698231462658441
[Epoch 10, Batch 400] loss: 0.016337130106649056
[Epoch 10, Batch 500] loss: 0.010466452585001207
[Epoch 10, Batch 600] loss: 0.01981212763210351
[Epoch 10, Batch 700] loss: 0.013002358692419875
[Epoch 10, Batch 800] loss: 0.017395988245989428
[Epoch 10, Batch 900] loss: 0.013875414658823502
[Epoch 10, Batch 1000] loss: 0.017533934205521292
[Epoch 10, Batch 1100] loss: 0.019187628539511933
[Epoch 10, Batch 1200] loss: 0.007694763838908329
[Epoch 10, Batch 1300] loss: 0.007733498896850505
[Epoch 10, Batch 1400] loss: 0.00915971933853143
[Epoch 10, Batch 1500] loss: 0.010835633304259318
[Epoch 10, Batch 1600] loss: 0.008090271844184826
[Epoch 10, Batch 1700] loss: 0.02386504551498547
[Epoch 10, Batch 1800] loss: 0.013530071660607063
[Epoch 10, Batch 1900] loss: 0.008394635959609787
[Epoch 10, Batch 2000] loss: 0.008782018773292748
[Epoch 10, Batch 2100] loss: 0.02071560151895028
[Epoch 10, Batch 2200] loss: 0.008112954491275559
[Epoch 10, Batch 2300] loss: 0.008945808986468365
[Epoch 10, Batch 2400] loss: 0.018835605392096114
[Epoch 10, Batch 2500] loss: 0.016165125935035576
[Epoch 10, Batch 2600] loss: 0.022704974760872573
[Epoch 10, Batch 2700] loss: 0.017233594340532364
[Epoch 10, Batch 2800] loss: 0.02352966199892762
[Epoch 10, Batch 2900] loss: 0.013060065919180488
[Epoch 10, Batch 3000] loss: 0.013240048906809535
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0416
Validation Accuracy: 0.9886
Overfitting: 0.0416
[Epoch 11, Batch 100] loss: 0.008434589054421054
[Epoch 11, Batch 200] loss: 0.015112013028601722
[Epoch 11, Batch 300] loss: 0.01815312250651914
[Epoch 11, Batch 400] loss: 0.00538580247949767
[Epoch 11, Batch 500] loss: 0.009683176591543087
[Epoch 11, Batch 600] loss: 0.01600947235339845
[Epoch 11, Batch 700] loss: 0.008839853028152902
[Epoch 11, Batch 800] loss: 0.011752698682048503
[Epoch 11, Batch 900] loss: 0.009886410795588744
[Epoch 11, Batch 1000] loss: 0.020825107303080584
[Epoch 11, Batch 1100] loss: 0.0075116336061682885
[Epoch 11, Batch 1200] loss: 0.025902423607858507
[Epoch 11, Batch 1300] loss: 0.016255946196165497
[Epoch 11, Batch 1400] loss: 0.016044191129547015
[Epoch 11, Batch 1500] loss: 0.014606937555172408
[Epoch 11, Batch 1600] loss: 0.010015648076805519
[Epoch 11, Batch 1700] loss: 0.0081534726999962
[Epoch 11, Batch 1800] loss: 0.010472781825933452
[Epoch 11, Batch 1900] loss: 0.014571030992040051
[Epoch 11, Batch 2000] loss: 0.010734140758495414
[Epoch 11, Batch 2100] loss: 0.007199148352392513
[Epoch 11, Batch 2200] loss: 0.018059641593595188
[Epoch 11, Batch 2300] loss: 0.015516661803608257
[Epoch 11, Batch 2400] loss: 0.022382540403295934
[Epoch 11, Batch 2500] loss: 0.019908467864620433
[Epoch 11, Batch 2600] loss: 0.018956631163478052
[Epoch 11, Batch 2700] loss: 0.008444778412803089
[Epoch 11, Batch 2800] loss: 0.009763337688655156
[Epoch 11, Batch 2900] loss: 0.02462802236987045
[Epoch 11, Batch 3000] loss: 0.007231296107001981
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0406
Validation Accuracy: 0.9885
Overfitting: 0.0406
[Epoch 12, Batch 100] loss: 0.00945751965443833
[Epoch 12, Batch 200] loss: 0.004259183404815303
[Epoch 12, Batch 300] loss: 0.014046811488301501
[Epoch 12, Batch 400] loss: 0.012343876161278331
[Epoch 12, Batch 500] loss: 0.01197768166254491
[Epoch 12, Batch 600] loss: 0.016839524569218157
[Epoch 12, Batch 700] loss: 0.014773821624862649
[Epoch 12, Batch 800] loss: 0.018246940487576923
[Epoch 12, Batch 900] loss: 0.012814135962880755
[Epoch 12, Batch 1000] loss: 0.009177705014171806
[Epoch 12, Batch 1100] loss: 0.007082449051595176
[Epoch 12, Batch 1200] loss: 0.009161199294881043
[Epoch 12, Batch 1300] loss: 0.014722816125463396
[Epoch 12, Batch 1400] loss: 0.011586544092242548
[Epoch 12, Batch 1500] loss: 0.006990434215408641
[Epoch 12, Batch 1600] loss: 0.007416437697852416
[Epoch 12, Batch 1700] loss: 0.00970135093372619
[Epoch 12, Batch 1800] loss: 0.014207835653346592
[Epoch 12, Batch 1900] loss: 0.007973689036286941
[Epoch 12, Batch 2000] loss: 0.015654113497005254
[Epoch 12, Batch 2100] loss: 0.005626759762064921
[Epoch 12, Batch 2200] loss: 0.01331365298600076
[Epoch 12, Batch 2300] loss: 0.01014654777232181
[Epoch 12, Batch 2400] loss: 0.007867996203060557
[Epoch 12, Batch 2500] loss: 0.01624234499226759
[Epoch 12, Batch 2600] loss: 0.006380575952571235
[Epoch 12, Batch 2700] loss: 0.014030222978828989
[Epoch 12, Batch 2800] loss: 0.013751603173034255
[Epoch 12, Batch 2900] loss: 0.017649096813776168
[Epoch 12, Batch 3000] loss: 0.010317132455343199
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0390
Validation Accuracy: 0.9890
Overfitting: 0.0390
[Epoch 13, Batch 100] loss: 0.012302583185598905
[Epoch 13, Batch 200] loss: 0.01314417277350003
[Epoch 13, Batch 300] loss: 0.012551498825185945
[Epoch 13, Batch 400] loss: 0.01707185218869654
[Epoch 13, Batch 500] loss: 0.006927223121825818
[Epoch 13, Batch 600] loss: 0.008966338438415277
[Epoch 13, Batch 700] loss: 0.009870605548367167
[Epoch 13, Batch 800] loss: 0.016095230960659138
[Epoch 13, Batch 900] loss: 0.014334211865124758
[Epoch 13, Batch 1000] loss: 0.01398997647446322
[Epoch 13, Batch 1100] loss: 0.01099909564708014
[Epoch 13, Batch 1200] loss: 0.011985600026762881
[Epoch 13, Batch 1300] loss: 0.010293598080038465
[Epoch 13, Batch 1400] loss: 0.00862106932934239
[Epoch 13, Batch 1500] loss: 0.007803695442748904
[Epoch 13, Batch 1600] loss: 0.005509488668064932
[Epoch 13, Batch 1700] loss: 0.01449291948350492
[Epoch 13, Batch 1800] loss: 0.00663522838092149
[Epoch 13, Batch 1900] loss: 0.013342498067815995
[Epoch 13, Batch 2000] loss: 0.0116743239903235
[Epoch 13, Batch 2100] loss: 0.0038117784386037102
[Epoch 13, Batch 2200] loss: 0.025951291989554193
[Epoch 13, Batch 2300] loss: 0.010502600425541004
[Epoch 13, Batch 2400] loss: 0.011782845672687472
[Epoch 13, Batch 2500] loss: 0.008733198429490018
[Epoch 13, Batch 2600] loss: 0.007121288107099986
[Epoch 13, Batch 2700] loss: 0.01249772033370391
[Epoch 13, Batch 2800] loss: 0.008464159242739697
[Epoch 13, Batch 2900] loss: 0.012102418360753972
[Epoch 13, Batch 3000] loss: 0.013682659993228298
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0427
Validation Accuracy: 0.9890
Overfitting: 0.0427
[Epoch 14, Batch 100] loss: 0.009387944305203746
[Epoch 14, Batch 200] loss: 0.006573347408003655
[Epoch 14, Batch 300] loss: 0.008772705431598525
[Epoch 14, Batch 400] loss: 0.005302422070850525
[Epoch 14, Batch 500] loss: 0.007234049663594248
[Epoch 14, Batch 600] loss: 0.006268762687742537
[Epoch 14, Batch 700] loss: 0.014213198178031518
[Epoch 14, Batch 800] loss: 0.01247174495226318
[Epoch 14, Batch 900] loss: 0.010670438833464004
[Epoch 14, Batch 1000] loss: 0.006482799153510541
[Epoch 14, Batch 1100] loss: 0.01009100283162411
[Epoch 14, Batch 1200] loss: 0.005439062149874872
[Epoch 14, Batch 1300] loss: 0.011315044541806856
[Epoch 14, Batch 1400] loss: 0.008392265569971186
[Epoch 14, Batch 1500] loss: 0.011306539012236954
[Epoch 14, Batch 1600] loss: 0.006194674535072409
[Epoch 14, Batch 1700] loss: 0.0037975672266128413
[Epoch 14, Batch 1800] loss: 0.007592059044369535
[Epoch 14, Batch 1900] loss: 0.011149527498923817
[Epoch 14, Batch 2000] loss: 0.004215115726535715
[Epoch 14, Batch 2100] loss: 0.004808614930093995
[Epoch 14, Batch 2200] loss: 0.006244115179692926
[Epoch 14, Batch 2300] loss: 0.008297591670572046
[Epoch 14, Batch 2400] loss: 0.007519254106319124
[Epoch 14, Batch 2500] loss: 0.004360499008205352
[Epoch 14, Batch 2600] loss: 0.009264616270569093
[Epoch 14, Batch 2700] loss: 0.004885479952602054
[Epoch 14, Batch 2800] loss: 0.01086571088544133
[Epoch 14, Batch 2900] loss: 0.01658297985893114
[Epoch 14, Batch 3000] loss: 0.0045388726037936065
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0418
Validation Accuracy: 0.9891
Overfitting: 0.0418
[Epoch 15, Batch 100] loss: 0.0027812905217763275
[Epoch 15, Batch 200] loss: 0.0032677061539669694
[Epoch 15, Batch 300] loss: 0.004493482520917951
[Epoch 15, Batch 400] loss: 0.014953352399691084
[Epoch 15, Batch 500] loss: 0.008694094701343146
[Epoch 15, Batch 600] loss: 0.008583070747591818
[Epoch 15, Batch 700] loss: 0.005831218280095527
[Epoch 15, Batch 800] loss: 0.012491331566982353
[Epoch 15, Batch 900] loss: 0.003049163250703657
[Epoch 15, Batch 1000] loss: 0.008126201868662548
[Epoch 15, Batch 1100] loss: 0.0076543222094855425
[Epoch 15, Batch 1200] loss: 0.007537963516112427
[Epoch 15, Batch 1300] loss: 0.014695479115449644
[Epoch 15, Batch 1400] loss: 0.008873855138867839
[Epoch 15, Batch 1500] loss: 0.010853378146457544
[Epoch 15, Batch 1600] loss: 0.005625289938118101
[Epoch 15, Batch 1700] loss: 0.005044165554201072
[Epoch 15, Batch 1800] loss: 0.007364825657814436
[Epoch 15, Batch 1900] loss: 0.0033164365613089332
[Epoch 15, Batch 2000] loss: 0.008313670627144347
[Epoch 15, Batch 2100] loss: 0.00862641514439929
[Epoch 15, Batch 2200] loss: 0.009371686082615724
[Epoch 15, Batch 2300] loss: 0.010695454492342833
[Epoch 15, Batch 2400] loss: 0.001987104411650762
[Epoch 15, Batch 2500] loss: 0.003081759499597041
[Epoch 15, Batch 2600] loss: 0.0035072042931204805
[Epoch 15, Batch 2700] loss: 0.013051456707596571
[Epoch 15, Batch 2800] loss: 0.004883503874593416
[Epoch 15, Batch 2900] loss: 0.004096371707111075
[Epoch 15, Batch 3000] loss: 0.004364450952474499
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9886
Overfitting: 0.0471
[Epoch 16, Batch 100] loss: 0.003915230346680118
[Epoch 16, Batch 200] loss: 0.0019456859369878998
[Epoch 16, Batch 300] loss: 0.0056643702645618535
[Epoch 16, Batch 400] loss: 0.004113534033650268
[Epoch 16, Batch 500] loss: 0.0028227359476406377
[Epoch 16, Batch 600] loss: 0.007008210571443385
[Epoch 16, Batch 700] loss: 0.016364870353695552
[Epoch 16, Batch 800] loss: 0.005595851337192812
[Epoch 16, Batch 900] loss: 0.002984449534827718
[Epoch 16, Batch 1000] loss: 0.014830662862802484
[Epoch 16, Batch 1100] loss: 0.014899836462432177
[Epoch 16, Batch 1200] loss: 0.004037749698845801
[Epoch 16, Batch 1300] loss: 0.0031790510298765184
[Epoch 16, Batch 1400] loss: 0.003359835370496853
[Epoch 16, Batch 1500] loss: 0.010247813836735419
[Epoch 16, Batch 1600] loss: 0.003970586854989051
[Epoch 16, Batch 1700] loss: 0.017750594329671684
[Epoch 16, Batch 1800] loss: 0.0152479947117547
[Epoch 16, Batch 1900] loss: 0.013822212995946189
[Epoch 16, Batch 2000] loss: 0.00970276989100455
[Epoch 16, Batch 2100] loss: 0.004948842267802398
[Epoch 16, Batch 2200] loss: 0.005581278710175752
[Epoch 16, Batch 2300] loss: 0.003877314573884121
[Epoch 16, Batch 2400] loss: 0.004382754582683219
[Epoch 16, Batch 2500] loss: 0.004790659112839748
[Epoch 16, Batch 2600] loss: 0.004684243633817004
[Epoch 16, Batch 2700] loss: 0.009666639025634822
[Epoch 16, Batch 2800] loss: 0.009935747939421874
[Epoch 16, Batch 2900] loss: 0.003951094676178286
[Epoch 16, Batch 3000] loss: 0.00605220191266767
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0413
Validation Accuracy: 0.9897
Overfitting: 0.0413
[Epoch 17, Batch 100] loss: 0.008638729456732221
[Epoch 17, Batch 200] loss: 0.0016549958783446074
[Epoch 17, Batch 300] loss: 0.002391566061698427
[Epoch 17, Batch 400] loss: 0.001178383901013831
[Epoch 17, Batch 500] loss: 0.002478432407989999
[Epoch 17, Batch 600] loss: 0.0007542168100894742
[Epoch 17, Batch 700] loss: 0.0019945489765694903
[Epoch 17, Batch 800] loss: 0.0036927493877647066
[Epoch 17, Batch 900] loss: 0.007700168432992313
[Epoch 17, Batch 1000] loss: 0.004296240487202852
[Epoch 17, Batch 1100] loss: 0.01025060915762225
[Epoch 17, Batch 1200] loss: 0.0031407354507848595
[Epoch 17, Batch 1300] loss: 0.011405580819771331
[Epoch 17, Batch 1400] loss: 0.008975404889871611
[Epoch 17, Batch 1500] loss: 0.00426898206221086
[Epoch 17, Batch 1600] loss: 0.004314195721284477
[Epoch 17, Batch 1700] loss: 0.005034481179566228
[Epoch 17, Batch 1800] loss: 0.00682180215140761
[Epoch 17, Batch 1900] loss: 0.001955909019354607
[Epoch 17, Batch 2000] loss: 0.010970975821445563
[Epoch 17, Batch 2100] loss: 0.005427138103248126
[Epoch 17, Batch 2200] loss: 0.010159785757145982
[Epoch 17, Batch 2300] loss: 0.005081224880021296
[Epoch 17, Batch 2400] loss: 0.007016708306771164
[Epoch 17, Batch 2500] loss: 0.0064273537028787684
[Epoch 17, Batch 2600] loss: 0.007243237264576692
[Epoch 17, Batch 2700] loss: 0.010485832162034825
[Epoch 17, Batch 2800] loss: 0.006985914430149478
[Epoch 17, Batch 2900] loss: 0.007122322615847949
[Epoch 17, Batch 3000] loss: 0.00897657671774681
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9900
Overfitting: 0.0458
[Epoch 18, Batch 100] loss: 0.008930967947262615
[Epoch 18, Batch 200] loss: 0.0023922037435250587
[Epoch 18, Batch 300] loss: 0.003212299603005704
[Epoch 18, Batch 400] loss: 0.011085042420125575
[Epoch 18, Batch 500] loss: 0.0057867317331934485
[Epoch 18, Batch 600] loss: 0.002371774122134127
[Epoch 18, Batch 700] loss: 0.0019941082561399526
[Epoch 18, Batch 800] loss: 0.0022842507338452834
[Epoch 18, Batch 900] loss: 0.018993067734708758
[Epoch 18, Batch 1000] loss: 0.012683076918373786
[Epoch 18, Batch 1100] loss: 0.01252086153573373
[Epoch 18, Batch 1200] loss: 0.012889492322757405
[Epoch 18, Batch 1300] loss: 0.009972162515441028
[Epoch 18, Batch 1400] loss: 0.004723479780423077
[Epoch 18, Batch 1500] loss: 0.007955962046013383
[Epoch 18, Batch 1600] loss: 0.0031864993027693345
[Epoch 18, Batch 1700] loss: 0.00797885407326703
[Epoch 18, Batch 1800] loss: 0.0025999948864944143
[Epoch 18, Batch 1900] loss: 0.0017724759642311482
[Epoch 18, Batch 2000] loss: 0.0031619467654238065
[Epoch 18, Batch 2100] loss: 0.0030943098735440344
[Epoch 18, Batch 2200] loss: 0.007315392391051603
[Epoch 18, Batch 2300] loss: 0.018483030006413017
[Epoch 18, Batch 2400] loss: 0.009313428226823248
[Epoch 18, Batch 2500] loss: 0.0016833368193408659
[Epoch 18, Batch 2600] loss: 0.0064787775218184155
[Epoch 18, Batch 2700] loss: 0.002233464571125268
[Epoch 18, Batch 2800] loss: 0.011225327555697504
[Epoch 18, Batch 2900] loss: 0.006204552716894511
[Epoch 18, Batch 3000] loss: 0.007034446225320039
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9875
Overfitting: 0.0543
[Epoch 19, Batch 100] loss: 0.009608292353058233
[Epoch 19, Batch 200] loss: 0.00883993183272878
[Epoch 19, Batch 300] loss: 0.0030024553355215743
[Epoch 19, Batch 400] loss: 0.01110519005774421
[Epoch 19, Batch 500] loss: 0.004547194881305927
[Epoch 19, Batch 600] loss: 0.0020469600895985708
[Epoch 19, Batch 700] loss: 0.001580240238592694
[Epoch 19, Batch 800] loss: 0.000935986875197159
[Epoch 19, Batch 900] loss: 0.0025604773423497564
[Epoch 19, Batch 1000] loss: 0.0010237620192139474
[Epoch 19, Batch 1100] loss: 0.0036022400602322337
[Epoch 19, Batch 1200] loss: 0.0018638187086086155
[Epoch 19, Batch 1300] loss: 0.001752643377840286
[Epoch 19, Batch 1400] loss: 0.0033207721201225127
[Epoch 19, Batch 1500] loss: 0.003362179071428386
[Epoch 19, Batch 1600] loss: 0.005124895172610877
[Epoch 19, Batch 1700] loss: 0.007609583748224367
[Epoch 19, Batch 1800] loss: 0.009500134968148615
[Epoch 19, Batch 1900] loss: 0.00779888318936834
[Epoch 19, Batch 2000] loss: 0.006520686274133567
[Epoch 19, Batch 2100] loss: 0.022342166915424712
[Epoch 19, Batch 2200] loss: 0.016369112807586177
[Epoch 19, Batch 2300] loss: 0.013488626721941727
[Epoch 19, Batch 2400] loss: 0.013085544462687117
[Epoch 19, Batch 2500] loss: 0.005854335224975102
[Epoch 19, Batch 2600] loss: 0.009749556353586968
[Epoch 19, Batch 2700] loss: 0.0036566034217901233
[Epoch 19, Batch 2800] loss: 0.004167812499333792
[Epoch 19, Batch 2900] loss: 0.004707324829116573
[Epoch 19, Batch 3000] loss: 0.011451502140984645
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9881
Overfitting: 0.0533
[Epoch 20, Batch 100] loss: 0.010720816444528509
[Epoch 20, Batch 200] loss: 0.0025852347495106186
[Epoch 20, Batch 300] loss: 0.005462923630206546
[Epoch 20, Batch 400] loss: 0.007212163228294202
[Epoch 20, Batch 500] loss: 0.0014857100209759722
[Epoch 20, Batch 600] loss: 0.004960448187857196
[Epoch 20, Batch 700] loss: 0.00983682287669735
[Epoch 20, Batch 800] loss: 0.008471415794500671
[Epoch 20, Batch 900] loss: 0.003397035310488192
[Epoch 20, Batch 1000] loss: 0.0034326156147119493
[Epoch 20, Batch 1100] loss: 0.007563901362048711
[Epoch 20, Batch 1200] loss: 0.0031615167607384363
[Epoch 20, Batch 1300] loss: 0.0036928309015216597
[Epoch 20, Batch 1400] loss: 0.0030709962004855738
[Epoch 20, Batch 1500] loss: 0.0034874420704204567
[Epoch 20, Batch 1600] loss: 0.00644950215454216
[Epoch 20, Batch 1700] loss: 0.003963038657986715
[Epoch 20, Batch 1800] loss: 0.00455999049551636
[Epoch 20, Batch 1900] loss: 0.0015397912723690865
[Epoch 20, Batch 2000] loss: 0.0011703949745666263
[Epoch 20, Batch 2100] loss: 0.002117764852837176
[Epoch 20, Batch 2200] loss: 0.0014501100127259647
[Epoch 20, Batch 2300] loss: 0.0025925878233898827
[Epoch 20, Batch 2400] loss: 0.0013970515392004756
[Epoch 20, Batch 2500] loss: 0.007771215772416653
[Epoch 20, Batch 2600] loss: 0.002172268707556313
[Epoch 20, Batch 2700] loss: 0.0025643702897619925
[Epoch 20, Batch 2800] loss: 0.006511691440206313
[Epoch 20, Batch 2900] loss: 0.006641430638214549
[Epoch 20, Batch 3000] loss: 0.011791034424037719
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0579
Validation Accuracy: 0.9881
Overfitting: 0.0579
[Epoch 21, Batch 100] loss: 0.006940889784651745
[Epoch 21, Batch 200] loss: 0.001395540376095994
[Epoch 21, Batch 300] loss: 0.0022059245034399843
[Epoch 21, Batch 400] loss: 0.001785393371436328
[Epoch 21, Batch 500] loss: 0.0027736506384904657
[Epoch 21, Batch 600] loss: 0.0060959660199910014
[Epoch 21, Batch 700] loss: 0.0024416729188506993
[Epoch 21, Batch 800] loss: 0.0023587459307849203
[Epoch 21, Batch 900] loss: 0.0015338696004176366
[Epoch 21, Batch 1000] loss: 0.004256071976382145
[Epoch 21, Batch 1100] loss: 0.0013453748575859236
[Epoch 21, Batch 1200] loss: 0.0032829008446313424
[Epoch 21, Batch 1300] loss: 0.004966591129289917
[Epoch 21, Batch 1400] loss: 0.00795373100643328
[Epoch 21, Batch 1500] loss: 0.004156073208264104
[Epoch 21, Batch 1600] loss: 0.0086332282740109
[Epoch 21, Batch 1700] loss: 0.006623183713984844
[Epoch 21, Batch 1800] loss: 0.009934481200153514
[Epoch 21, Batch 1900] loss: 0.007744281702922038
[Epoch 21, Batch 2000] loss: 0.0032154491644293516
[Epoch 21, Batch 2100] loss: 0.009823856875172222
[Epoch 21, Batch 2200] loss: 0.0008865583999143211
[Epoch 21, Batch 2300] loss: 0.004109869026126773
[Epoch 21, Batch 2400] loss: 0.0006335478233458502
[Epoch 21, Batch 2500] loss: 0.002570121052869041
[Epoch 21, Batch 2600] loss: 0.0010700835835628908
[Epoch 21, Batch 2700] loss: 0.0027474899356011305
[Epoch 21, Batch 2800] loss: 0.0035300606303396887
[Epoch 21, Batch 2900] loss: 0.0014997618278034608
[Epoch 21, Batch 3000] loss: 0.00097759701988009
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9895
Overfitting: 0.0477
[Epoch 22, Batch 100] loss: 0.0007186701420100406
[Epoch 22, Batch 200] loss: 0.0014252971287869798
[Epoch 22, Batch 300] loss: 0.0009081426996837649
[Epoch 22, Batch 400] loss: 0.0009099734548795757
[Epoch 22, Batch 500] loss: 0.0019623878939433225
[Epoch 22, Batch 600] loss: 0.0008247637974260779
[Epoch 22, Batch 700] loss: 0.00036285737962735707
[Epoch 22, Batch 800] loss: 0.005137050412519955
[Epoch 22, Batch 900] loss: 0.0006038186863577711
[Epoch 22, Batch 1000] loss: 0.002771301002206883
[Epoch 22, Batch 1100] loss: 0.0022214481452037613
[Epoch 22, Batch 1200] loss: 0.0011207136796358697
[Epoch 22, Batch 1300] loss: 0.00158552907834717
[Epoch 22, Batch 1400] loss: 0.0016807971434911017
[Epoch 22, Batch 1500] loss: 0.0021974935637403712
[Epoch 22, Batch 1600] loss: 0.0014403071413576418
[Epoch 22, Batch 1700] loss: 0.0012049811404034473
[Epoch 22, Batch 1800] loss: 0.0025065214772194365
[Epoch 22, Batch 1900] loss: 0.002590665996781709
[Epoch 22, Batch 2000] loss: 0.005873261784097039
[Epoch 22, Batch 2100] loss: 0.0023904241839222172
[Epoch 22, Batch 2200] loss: 0.0014548218598247865
[Epoch 22, Batch 2300] loss: 0.0011228322766689302
[Epoch 22, Batch 2400] loss: 0.005386534825301896
[Epoch 22, Batch 2500] loss: 0.0019195012068572792
[Epoch 22, Batch 2600] loss: 0.0009213009103778935
[Epoch 22, Batch 2700] loss: 0.00032415543594281
[Epoch 22, Batch 2800] loss: 0.000954682664363844
[Epoch 22, Batch 2900] loss: 0.00032572274126440703
[Epoch 22, Batch 3000] loss: 0.010145447899072816
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0652
Validation Accuracy: 0.9868
Overfitting: 0.0652
[Epoch 23, Batch 100] loss: 0.0043277609717411285
[Epoch 23, Batch 200] loss: 0.009859917921355326
[Epoch 23, Batch 300] loss: 0.00167452330652889
[Epoch 23, Batch 400] loss: 0.00137438350536371
[Epoch 23, Batch 500] loss: 0.0041015103244460786
[Epoch 23, Batch 600] loss: 0.00616975419106609
[Epoch 23, Batch 700] loss: 0.006322600510872221
[Epoch 23, Batch 800] loss: 0.007325783801553882
[Epoch 23, Batch 900] loss: 0.0036617673107656222
[Epoch 23, Batch 1000] loss: 0.0029218093950207713
[Epoch 23, Batch 1100] loss: 0.003295282377409059
[Epoch 23, Batch 1200] loss: 0.0015785524653136917
[Epoch 23, Batch 1300] loss: 0.002740733231772552
[Epoch 23, Batch 1400] loss: 0.00779939642564246
[Epoch 23, Batch 1500] loss: 0.0007745724686402333
[Epoch 23, Batch 1600] loss: 0.0009704967120394769
[Epoch 23, Batch 1700] loss: 0.0039166239557035
[Epoch 23, Batch 1800] loss: 0.00924691871156316
[Epoch 23, Batch 1900] loss: 0.005414762571717766
[Epoch 23, Batch 2000] loss: 0.006573706355893201
[Epoch 23, Batch 2100] loss: 0.011008591435866038
[Epoch 23, Batch 2200] loss: 0.003125208953394747
[Epoch 23, Batch 2300] loss: 0.008421063593379224
[Epoch 23, Batch 2400] loss: 0.010388614292744052
[Epoch 23, Batch 2500] loss: 0.005553284810858799
[Epoch 23, Batch 2600] loss: 0.002696251355127117
[Epoch 23, Batch 2700] loss: 0.008038572787543075
[Epoch 23, Batch 2800] loss: 0.0056076885746321635
[Epoch 23, Batch 2900] loss: 0.004966191285241379
[Epoch 23, Batch 3000] loss: 0.00600495842316608
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0598
Validation Accuracy: 0.9878
Overfitting: 0.0598
[Epoch 24, Batch 100] loss: 0.0081878323154028
[Epoch 24, Batch 200] loss: 0.004943091129991188
[Epoch 24, Batch 300] loss: 0.006412941983556309
[Epoch 24, Batch 400] loss: 0.007141703758820768
[Epoch 24, Batch 500] loss: 0.0026760022089679404
[Epoch 24, Batch 600] loss: 0.0031119327393605545
[Epoch 24, Batch 700] loss: 0.002161215826693237
[Epoch 24, Batch 800] loss: 0.001472878265353721
[Epoch 24, Batch 900] loss: 0.0005493766145228563
[Epoch 24, Batch 1000] loss: 0.005165340156337343
[Epoch 24, Batch 1100] loss: 0.0008206543426935298
[Epoch 24, Batch 1200] loss: 0.0065730605744707925
[Epoch 24, Batch 1300] loss: 0.0024646190632763654
[Epoch 24, Batch 1400] loss: 0.0021444726151739245
[Epoch 24, Batch 1500] loss: 0.002393428582677899
[Epoch 24, Batch 1600] loss: 0.010704160195222058
[Epoch 24, Batch 1700] loss: 0.0010599380623449051
[Epoch 24, Batch 1800] loss: 0.001062833837338566
[Epoch 24, Batch 1900] loss: 0.0009426097375428632
[Epoch 24, Batch 2000] loss: 0.002858951284711009
[Epoch 24, Batch 2100] loss: 0.0027888682550238197
[Epoch 24, Batch 2200] loss: 0.0023574471677490915
[Epoch 24, Batch 2300] loss: 0.006318718171814024
[Epoch 24, Batch 2400] loss: 0.0009836475206875406
[Epoch 24, Batch 2500] loss: 0.0006946552785154791
[Epoch 24, Batch 2600] loss: 0.0006247617349182688
[Epoch 24, Batch 2700] loss: 0.002432178064009927
[Epoch 24, Batch 2800] loss: 0.004575734858106113
[Epoch 24, Batch 2900] loss: 0.0009797275579549547
[Epoch 24, Batch 3000] loss: 0.0008413002857264029
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9901
Overfitting: 0.0446
Fold 1 validation loss: 0.0446
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.295054705142975
[Epoch 1, Batch 200] loss: 2.2433956694602966
[Epoch 1, Batch 300] loss: 1.4535168725252152
[Epoch 1, Batch 400] loss: 0.6116433595120907
[Epoch 1, Batch 500] loss: 0.38219365149736406
[Epoch 1, Batch 600] loss: 0.2786585336457938
[Epoch 1, Batch 700] loss: 0.2864316795580089
[Epoch 1, Batch 800] loss: 0.26694851364940403
[Epoch 1, Batch 900] loss: 0.21231563802808523
[Epoch 1, Batch 1000] loss: 0.20606885842513292
[Epoch 1, Batch 1100] loss: 0.18453120147809388
[Epoch 1, Batch 1200] loss: 0.18379153099842369
[Epoch 1, Batch 1300] loss: 0.18922555222176016
[Epoch 1, Batch 1400] loss: 0.1767181050311774
[Epoch 1, Batch 1500] loss: 0.13633324642665684
[Epoch 1, Batch 1600] loss: 0.1264540460240096
[Epoch 1, Batch 1700] loss: 0.11729280087165535
[Epoch 1, Batch 1800] loss: 0.11037589985877276
[Epoch 1, Batch 1900] loss: 0.13603841504780576
[Epoch 1, Batch 2000] loss: 0.13049457849469037
[Epoch 1, Batch 2100] loss: 0.1527750719175674
[Epoch 1, Batch 2200] loss: 0.1227190429251641
[Epoch 1, Batch 2300] loss: 0.11518071586848237
[Epoch 1, Batch 2400] loss: 0.10163988471962511
[Epoch 1, Batch 2500] loss: 0.12535976151004433
[Epoch 1, Batch 2600] loss: 0.10203439586795866
[Epoch 1, Batch 2700] loss: 0.11226630772463977
[Epoch 1, Batch 2800] loss: 0.10379169222083874
[Epoch 1, Batch 2900] loss: 0.08934272833284922
[Epoch 1, Batch 3000] loss: 0.09651453539147042
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0952
Validation Accuracy: 0.9692
Overfitting: 0.0952
Best model saved at epoch 1 with validation loss: 0.0952
[Epoch 2, Batch 100] loss: 0.10120761637575924
[Epoch 2, Batch 200] loss: 0.08112322124332422
[Epoch 2, Batch 300] loss: 0.09490480766166001
[Epoch 2, Batch 400] loss: 0.07420299576129764
[Epoch 2, Batch 500] loss: 0.07621434495318681
[Epoch 2, Batch 600] loss: 0.08219492852105759
[Epoch 2, Batch 700] loss: 0.07840466679306701
[Epoch 2, Batch 800] loss: 0.07001577244896907
[Epoch 2, Batch 900] loss: 0.07495405831723474
[Epoch 2, Batch 1000] loss: 0.08997181466897018
[Epoch 2, Batch 1100] loss: 0.07234357311972417
[Epoch 2, Batch 1200] loss: 0.06263510824996046
[Epoch 2, Batch 1300] loss: 0.12372807544539682
[Epoch 2, Batch 1400] loss: 0.06547259893501177
[Epoch 2, Batch 1500] loss: 0.05934507858357392
[Epoch 2, Batch 1600] loss: 0.05591377602890134
[Epoch 2, Batch 1700] loss: 0.08495027184078935
[Epoch 2, Batch 1800] loss: 0.06929744065739214
[Epoch 2, Batch 1900] loss: 0.05992191810189979
[Epoch 2, Batch 2000] loss: 0.06376573559595272
[Epoch 2, Batch 2100] loss: 0.06690279297879898
[Epoch 2, Batch 2200] loss: 0.055899527649744415
[Epoch 2, Batch 2300] loss: 0.06738888039893937
[Epoch 2, Batch 2400] loss: 0.07434097159653902
[Epoch 2, Batch 2500] loss: 0.06382845251107938
[Epoch 2, Batch 2600] loss: 0.06377728731167735
[Epoch 2, Batch 2700] loss: 0.06895331148873084
[Epoch 2, Batch 2800] loss: 0.0441703055598191
[Epoch 2, Batch 2900] loss: 0.06382042223151074
[Epoch 2, Batch 3000] loss: 0.08341986179817468
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0802
Validation Accuracy: 0.9738
Overfitting: 0.0802
Best model saved at epoch 2 with validation loss: 0.0802
[Epoch 3, Batch 100] loss: 0.044822305546840656
[Epoch 3, Batch 200] loss: 0.05257462008798029
[Epoch 3, Batch 300] loss: 0.04647032632041373
[Epoch 3, Batch 400] loss: 0.059308107321849095
[Epoch 3, Batch 500] loss: 0.05715028818929568
[Epoch 3, Batch 600] loss: 0.0645718715590192
[Epoch 3, Batch 700] loss: 0.04796855652588419
[Epoch 3, Batch 800] loss: 0.05047233435325325
[Epoch 3, Batch 900] loss: 0.05666390803351533
[Epoch 3, Batch 1000] loss: 0.04529164638865041
[Epoch 3, Batch 1100] loss: 0.04576126206142362
[Epoch 3, Batch 1200] loss: 0.048763725828030145
[Epoch 3, Batch 1300] loss: 0.05268567077662738
[Epoch 3, Batch 1400] loss: 0.05024865036655683
[Epoch 3, Batch 1500] loss: 0.051825802050007044
[Epoch 3, Batch 1600] loss: 0.0510839812438644
[Epoch 3, Batch 1700] loss: 0.04218383735686075
[Epoch 3, Batch 1800] loss: 0.04224076354788849
[Epoch 3, Batch 1900] loss: 0.03798325229872716
[Epoch 3, Batch 2000] loss: 0.04296717117460503
[Epoch 3, Batch 2100] loss: 0.0621935998115805
[Epoch 3, Batch 2200] loss: 0.05733025174995419
[Epoch 3, Batch 2300] loss: 0.06459233016095822
[Epoch 3, Batch 2400] loss: 0.0656428389751818
[Epoch 3, Batch 2500] loss: 0.06689452569989954
[Epoch 3, Batch 2600] loss: 0.05008040260698181
[Epoch 3, Batch 2700] loss: 0.05083128457888961
[Epoch 3, Batch 2800] loss: 0.047216392722912136
[Epoch 3, Batch 2900] loss: 0.04106554853991838
[Epoch 3, Batch 3000] loss: 0.06364346424001269
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0624
Validation Accuracy: 0.9802
Overfitting: 0.0624
Best model saved at epoch 3 with validation loss: 0.0624
[Epoch 4, Batch 100] loss: 0.03406073127494892
[Epoch 4, Batch 200] loss: 0.02288630174654827
[Epoch 4, Batch 300] loss: 0.046844763862754914
[Epoch 4, Batch 400] loss: 0.0341298044785799
[Epoch 4, Batch 500] loss: 0.04760335428029066
[Epoch 4, Batch 600] loss: 0.038560034153051675
[Epoch 4, Batch 700] loss: 0.03907728692749515
[Epoch 4, Batch 800] loss: 0.05456262146515655
[Epoch 4, Batch 900] loss: 0.03143137661463698
[Epoch 4, Batch 1000] loss: 0.032268647619494
[Epoch 4, Batch 1100] loss: 0.046630660951632305
[Epoch 4, Batch 1200] loss: 0.029993167056527454
[Epoch 4, Batch 1300] loss: 0.03192752340750303
[Epoch 4, Batch 1400] loss: 0.04356642803235445
[Epoch 4, Batch 1500] loss: 0.03699447572143981
[Epoch 4, Batch 1600] loss: 0.05249513840099098
[Epoch 4, Batch 1700] loss: 0.04188327344192658
[Epoch 4, Batch 1800] loss: 0.04086645532224793
[Epoch 4, Batch 1900] loss: 0.040405696122106746
[Epoch 4, Batch 2000] loss: 0.023618721722741612
[Epoch 4, Batch 2100] loss: 0.04811743550664687
[Epoch 4, Batch 2200] loss: 0.05273788814622094
[Epoch 4, Batch 2300] loss: 0.04225157769171346
[Epoch 4, Batch 2400] loss: 0.030517790708690883
[Epoch 4, Batch 2500] loss: 0.04328391775954515
[Epoch 4, Batch 2600] loss: 0.029869692611682694
[Epoch 4, Batch 2700] loss: 0.03226311723337858
[Epoch 4, Batch 2800] loss: 0.04156049083103426
[Epoch 4, Batch 2900] loss: 0.031039817526834667
[Epoch 4, Batch 3000] loss: 0.03425949110805959
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0555
Validation Accuracy: 0.9844
Overfitting: 0.0555
Best model saved at epoch 4 with validation loss: 0.0555
[Epoch 5, Batch 100] loss: 0.02970737145678868
[Epoch 5, Batch 200] loss: 0.03615820058257668
[Epoch 5, Batch 300] loss: 0.045861444783804474
[Epoch 5, Batch 400] loss: 0.03959935940525611
[Epoch 5, Batch 500] loss: 0.025593671542883386
[Epoch 5, Batch 600] loss: 0.04077342703953036
[Epoch 5, Batch 700] loss: 0.023126510019792476
[Epoch 5, Batch 800] loss: 0.04155865812812408
[Epoch 5, Batch 900] loss: 0.031140160409340752
[Epoch 5, Batch 1000] loss: 0.040559328557210395
[Epoch 5, Batch 1100] loss: 0.038228740362828834
[Epoch 5, Batch 1200] loss: 0.0278378055709436
[Epoch 5, Batch 1300] loss: 0.037235659308207686
[Epoch 5, Batch 1400] loss: 0.026094806733017322
[Epoch 5, Batch 1500] loss: 0.027706055487578853
[Epoch 5, Batch 1600] loss: 0.028227191270052573
[Epoch 5, Batch 1700] loss: 0.034246326552856775
[Epoch 5, Batch 1800] loss: 0.02601986265501182
[Epoch 5, Batch 1900] loss: 0.031270518624914985
[Epoch 5, Batch 2000] loss: 0.049183443784713746
[Epoch 5, Batch 2100] loss: 0.02760709354563005
[Epoch 5, Batch 2200] loss: 0.046428239194938214
[Epoch 5, Batch 2300] loss: 0.031969916383677625
[Epoch 5, Batch 2400] loss: 0.028658093708945672
[Epoch 5, Batch 2500] loss: 0.022111148739968486
[Epoch 5, Batch 2600] loss: 0.04801562015694799
[Epoch 5, Batch 2700] loss: 0.030704429781762882
[Epoch 5, Batch 2800] loss: 0.03167550386984658
[Epoch 5, Batch 2900] loss: 0.035754415058909216
[Epoch 5, Batch 3000] loss: 0.023041500479885145
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9848
Overfitting: 0.0522
Best model saved at epoch 5 with validation loss: 0.0522
[Epoch 6, Batch 100] loss: 0.025784765258140396
[Epoch 6, Batch 200] loss: 0.02930754175366019
[Epoch 6, Batch 300] loss: 0.020494649691609083
[Epoch 6, Batch 400] loss: 0.03145397662217874
[Epoch 6, Batch 500] loss: 0.033642980754812014
[Epoch 6, Batch 600] loss: 0.024176484667914337
[Epoch 6, Batch 700] loss: 0.027055932043640495
[Epoch 6, Batch 800] loss: 0.01993833132539294
[Epoch 6, Batch 900] loss: 0.029978510963592272
[Epoch 6, Batch 1000] loss: 0.04132997861623153
[Epoch 6, Batch 1100] loss: 0.026695134951805814
[Epoch 6, Batch 1200] loss: 0.03616139198638848
[Epoch 6, Batch 1300] loss: 0.02080666298941651
[Epoch 6, Batch 1400] loss: 0.02090312294603791
[Epoch 6, Batch 1500] loss: 0.026699035250767337
[Epoch 6, Batch 1600] loss: 0.038173795852781044
[Epoch 6, Batch 1700] loss: 0.03161173179127218
[Epoch 6, Batch 1800] loss: 0.030890677381976275
[Epoch 6, Batch 1900] loss: 0.022759368301958603
[Epoch 6, Batch 2000] loss: 0.025164982155729376
[Epoch 6, Batch 2100] loss: 0.03433554809638736
[Epoch 6, Batch 2200] loss: 0.030379423027770826
[Epoch 6, Batch 2300] loss: 0.02454333111469168
[Epoch 6, Batch 2400] loss: 0.026266714973171474
[Epoch 6, Batch 2500] loss: 0.017368129300557485
[Epoch 6, Batch 2600] loss: 0.027049293790005324
[Epoch 6, Batch 2700] loss: 0.027002373315517615
[Epoch 6, Batch 2800] loss: 0.03444048020712216
[Epoch 6, Batch 2900] loss: 0.031514216828363716
[Epoch 6, Batch 3000] loss: 0.017633155653165887
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9869
Overfitting: 0.0485
Best model saved at epoch 6 with validation loss: 0.0485
[Epoch 7, Batch 100] loss: 0.020342134552283824
[Epoch 7, Batch 200] loss: 0.023013871693874536
[Epoch 7, Batch 300] loss: 0.02931473508457202
[Epoch 7, Batch 400] loss: 0.013428868928167503
[Epoch 7, Batch 500] loss: 0.018819188947200017
[Epoch 7, Batch 600] loss: 0.01945867754946448
[Epoch 7, Batch 700] loss: 0.015939479569060496
[Epoch 7, Batch 800] loss: 0.015827809478869314
[Epoch 7, Batch 900] loss: 0.02713156471865659
[Epoch 7, Batch 1000] loss: 0.01918284592939017
[Epoch 7, Batch 1100] loss: 0.020276901784018263
[Epoch 7, Batch 1200] loss: 0.030492553530348233
[Epoch 7, Batch 1300] loss: 0.018930357033987093
[Epoch 7, Batch 1400] loss: 0.02023694879404502
[Epoch 7, Batch 1500] loss: 0.020737191269290633
[Epoch 7, Batch 1600] loss: 0.01998206305333042
[Epoch 7, Batch 1700] loss: 0.029761090533356765
[Epoch 7, Batch 1800] loss: 0.03460660973491031
[Epoch 7, Batch 1900] loss: 0.02538326657770085
[Epoch 7, Batch 2000] loss: 0.015893855662397982
[Epoch 7, Batch 2100] loss: 0.024057844193011987
[Epoch 7, Batch 2200] loss: 0.02333829289469577
[Epoch 7, Batch 2300] loss: 0.017638682946153495
[Epoch 7, Batch 2400] loss: 0.017155106680361312
[Epoch 7, Batch 2500] loss: 0.03165540407503613
[Epoch 7, Batch 2600] loss: 0.019401496365571803
[Epoch 7, Batch 2700] loss: 0.036261211535456826
[Epoch 7, Batch 2800] loss: 0.03435275584266492
[Epoch 7, Batch 2900] loss: 0.03240736947285768
[Epoch 7, Batch 3000] loss: 0.02652687825502653
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9828
Overfitting: 0.0586
[Epoch 8, Batch 100] loss: 0.015144592316610216
[Epoch 8, Batch 200] loss: 0.015618819933915801
[Epoch 8, Batch 300] loss: 0.03207857835837785
[Epoch 8, Batch 400] loss: 0.022682859816632116
[Epoch 8, Batch 500] loss: 0.016273272892394743
[Epoch 8, Batch 600] loss: 0.00728522380522918
[Epoch 8, Batch 700] loss: 0.015867317176735014
[Epoch 8, Batch 800] loss: 0.02085612349525036
[Epoch 8, Batch 900] loss: 0.013212598506688664
[Epoch 8, Batch 1000] loss: 0.01068284156775917
[Epoch 8, Batch 1100] loss: 0.028081744097489716
[Epoch 8, Batch 1200] loss: 0.01701918206183109
[Epoch 8, Batch 1300] loss: 0.019946545298626005
[Epoch 8, Batch 1400] loss: 0.013945928128214291
[Epoch 8, Batch 1500] loss: 0.02055048276361049
[Epoch 8, Batch 1600] loss: 0.01713292996408654
[Epoch 8, Batch 1700] loss: 0.023399167632410355
[Epoch 8, Batch 1800] loss: 0.01499560278487479
[Epoch 8, Batch 1900] loss: 0.021329171100078384
[Epoch 8, Batch 2000] loss: 0.014877667465871127
[Epoch 8, Batch 2100] loss: 0.01557794028077069
[Epoch 8, Batch 2200] loss: 0.03181222913925012
[Epoch 8, Batch 2300] loss: 0.03150001385194628
[Epoch 8, Batch 2400] loss: 0.02014538941462888
[Epoch 8, Batch 2500] loss: 0.024899520519047657
[Epoch 8, Batch 2600] loss: 0.02392069784418709
[Epoch 8, Batch 2700] loss: 0.023003514960400935
[Epoch 8, Batch 2800] loss: 0.00912160060253882
[Epoch 8, Batch 2900] loss: 0.019669870666893984
[Epoch 8, Batch 3000] loss: 0.027543263979644052
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9859
Overfitting: 0.0516
[Epoch 9, Batch 100] loss: 0.01598441383719546
[Epoch 9, Batch 200] loss: 0.00835009814053592
[Epoch 9, Batch 300] loss: 0.01862893563336911
[Epoch 9, Batch 400] loss: 0.02388622140966618
[Epoch 9, Batch 500] loss: 0.019637864615660874
[Epoch 9, Batch 600] loss: 0.01248290495407673
[Epoch 9, Batch 700] loss: 0.014308895078502247
[Epoch 9, Batch 800] loss: 0.012728140654817253
[Epoch 9, Batch 900] loss: 0.013366144861338398
[Epoch 9, Batch 1000] loss: 0.009910326441040524
[Epoch 9, Batch 1100] loss: 0.008976007802020831
[Epoch 9, Batch 1200] loss: 0.01714010600165693
[Epoch 9, Batch 1300] loss: 0.01380516586656995
[Epoch 9, Batch 1400] loss: 0.023487324587549666
[Epoch 9, Batch 1500] loss: 0.01843074786721445
[Epoch 9, Batch 1600] loss: 0.012307568697692658
[Epoch 9, Batch 1700] loss: 0.025902332312743966
[Epoch 9, Batch 1800] loss: 0.023209652174555232
[Epoch 9, Batch 1900] loss: 0.01097576880827546
[Epoch 9, Batch 2000] loss: 0.02119385783361395
[Epoch 9, Batch 2100] loss: 0.023372771379526966
[Epoch 9, Batch 2200] loss: 0.025469482884982426
[Epoch 9, Batch 2300] loss: 0.011848458893800852
[Epoch 9, Batch 2400] loss: 0.01771384858107922
[Epoch 9, Batch 2500] loss: 0.02334315081978275
[Epoch 9, Batch 2600] loss: 0.007082903336959134
[Epoch 9, Batch 2700] loss: 0.021369217775863945
[Epoch 9, Batch 2800] loss: 0.027456119546459375
[Epoch 9, Batch 2900] loss: 0.014770538769280393
[Epoch 9, Batch 3000] loss: 0.02395672220403867
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9850
Overfitting: 0.0522
[Epoch 10, Batch 100] loss: 0.006823385842108109
[Epoch 10, Batch 200] loss: 0.01558792418029043
[Epoch 10, Batch 300] loss: 0.008262546207652122
[Epoch 10, Batch 400] loss: 0.024526862547272685
[Epoch 10, Batch 500] loss: 0.013103832365286507
[Epoch 10, Batch 600] loss: 0.017433549055022014
[Epoch 10, Batch 700] loss: 0.0218515383734848
[Epoch 10, Batch 800] loss: 0.012842815048161356
[Epoch 10, Batch 900] loss: 0.0098872199707057
[Epoch 10, Batch 1000] loss: 0.009770664219345235
[Epoch 10, Batch 1100] loss: 0.010035744785327552
[Epoch 10, Batch 1200] loss: 0.009631959190624002
[Epoch 10, Batch 1300] loss: 0.00395787682230548
[Epoch 10, Batch 1400] loss: 0.017740841972527052
[Epoch 10, Batch 1500] loss: 0.015184346182695662
[Epoch 10, Batch 1600] loss: 0.011101712285186522
[Epoch 10, Batch 1700] loss: 0.02961755441366222
[Epoch 10, Batch 1800] loss: 0.017914634270273382
[Epoch 10, Batch 1900] loss: 0.008893790246256686
[Epoch 10, Batch 2000] loss: 0.01229615414269574
[Epoch 10, Batch 2100] loss: 0.005978192804850551
[Epoch 10, Batch 2200] loss: 0.008871396918266328
[Epoch 10, Batch 2300] loss: 0.008196444407831223
[Epoch 10, Batch 2400] loss: 0.02039391183162479
[Epoch 10, Batch 2500] loss: 0.01787277453506249
[Epoch 10, Batch 2600] loss: 0.006509765774882794
[Epoch 10, Batch 2700] loss: 0.01711348079435993
[Epoch 10, Batch 2800] loss: 0.0214626237497032
[Epoch 10, Batch 2900] loss: 0.006598935810761759
[Epoch 10, Batch 3000] loss: 0.009609539031580426
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0541
Validation Accuracy: 0.9865
Overfitting: 0.0541
[Epoch 11, Batch 100] loss: 0.011739517745336343
[Epoch 11, Batch 200] loss: 0.00894192505143792
[Epoch 11, Batch 300] loss: 0.008625477176714184
[Epoch 11, Batch 400] loss: 0.011778504047119895
[Epoch 11, Batch 500] loss: 0.004927837279691403
[Epoch 11, Batch 600] loss: 0.020402480998781128
[Epoch 11, Batch 700] loss: 0.007789004809346807
[Epoch 11, Batch 800] loss: 0.016606055494451086
[Epoch 11, Batch 900] loss: 0.018530383116008124
[Epoch 11, Batch 1000] loss: 0.018347633388311805
[Epoch 11, Batch 1100] loss: 0.019958086685774104
[Epoch 11, Batch 1200] loss: 0.015905445804669398
[Epoch 11, Batch 1300] loss: 0.007649950549016467
[Epoch 11, Batch 1400] loss: 0.005146562526001617
[Epoch 11, Batch 1500] loss: 0.0054101169330124325
[Epoch 11, Batch 1600] loss: 0.012354937627164872
[Epoch 11, Batch 1700] loss: 0.014679060742291767
[Epoch 11, Batch 1800] loss: 0.011490692842426143
[Epoch 11, Batch 1900] loss: 0.020805923141347195
[Epoch 11, Batch 2000] loss: 0.018995583296018595
[Epoch 11, Batch 2100] loss: 0.012762798684852895
[Epoch 11, Batch 2200] loss: 0.010790474300457618
[Epoch 11, Batch 2300] loss: 0.01616747236404535
[Epoch 11, Batch 2400] loss: 0.024767835412349087
[Epoch 11, Batch 2500] loss: 0.013963268946617972
[Epoch 11, Batch 2600] loss: 0.009782771503510049
[Epoch 11, Batch 2700] loss: 0.010401232143185552
[Epoch 11, Batch 2800] loss: 0.00467064214297352
[Epoch 11, Batch 2900] loss: 0.010895022924078148
[Epoch 11, Batch 3000] loss: 0.016277415215027985
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9858
Overfitting: 0.0559
[Epoch 12, Batch 100] loss: 0.005869987080754982
[Epoch 12, Batch 200] loss: 0.009302037331867723
[Epoch 12, Batch 300] loss: 0.013402857983719514
[Epoch 12, Batch 400] loss: 0.010334071685424533
[Epoch 12, Batch 500] loss: 0.011269343119456038
[Epoch 12, Batch 600] loss: 0.004969945075126816
[Epoch 12, Batch 700] loss: 0.007813214488105586
[Epoch 12, Batch 800] loss: 0.010486882686060427
[Epoch 12, Batch 900] loss: 0.004633549533518817
[Epoch 12, Batch 1000] loss: 0.014009805832481561
[Epoch 12, Batch 1100] loss: 0.010788339513046594
[Epoch 12, Batch 1200] loss: 0.0165611226263718
[Epoch 12, Batch 1300] loss: 0.012102328490318542
[Epoch 12, Batch 1400] loss: 0.009311619583427274
[Epoch 12, Batch 1500] loss: 0.020281424564257123
[Epoch 12, Batch 1600] loss: 0.010093057167732695
[Epoch 12, Batch 1700] loss: 0.006209220655844092
[Epoch 12, Batch 1800] loss: 0.01021430554088397
[Epoch 12, Batch 1900] loss: 0.011309242151050967
[Epoch 12, Batch 2000] loss: 0.011770080081914784
[Epoch 12, Batch 2100] loss: 0.009626294372355914
[Epoch 12, Batch 2200] loss: 0.014983326387297212
[Epoch 12, Batch 2300] loss: 0.00932323128383814
[Epoch 12, Batch 2400] loss: 0.013018063681583954
[Epoch 12, Batch 2500] loss: 0.01710836220304145
[Epoch 12, Batch 2600] loss: 0.0065237302841205744
[Epoch 12, Batch 2700] loss: 0.012857382996146497
[Epoch 12, Batch 2800] loss: 0.010971286176923058
[Epoch 12, Batch 2900] loss: 0.009253098763117577
[Epoch 12, Batch 3000] loss: 0.0054542621361486
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0648
Validation Accuracy: 0.9845
Overfitting: 0.0648
[Epoch 13, Batch 100] loss: 0.006115130645150941
[Epoch 13, Batch 200] loss: 0.008025839316690053
[Epoch 13, Batch 300] loss: 0.013081465307918734
[Epoch 13, Batch 400] loss: 0.015466712847170357
[Epoch 13, Batch 500] loss: 0.00881560499610373
[Epoch 13, Batch 600] loss: 0.0035775531161220896
[Epoch 13, Batch 700] loss: 0.013589059535797787
[Epoch 13, Batch 800] loss: 0.016256961994090487
[Epoch 13, Batch 900] loss: 0.012250433116387285
[Epoch 13, Batch 1000] loss: 0.00940061607063285
[Epoch 13, Batch 1100] loss: 0.005201236315115238
[Epoch 13, Batch 1200] loss: 0.02217128932690457
[Epoch 13, Batch 1300] loss: 0.022047867721660168
[Epoch 13, Batch 1400] loss: 0.008044363125760583
[Epoch 13, Batch 1500] loss: 0.010158842478035694
[Epoch 13, Batch 1600] loss: 0.008488800054772127
[Epoch 13, Batch 1700] loss: 0.013829631258488462
[Epoch 13, Batch 1800] loss: 0.005819700570116026
[Epoch 13, Batch 1900] loss: 0.007674730013100088
[Epoch 13, Batch 2000] loss: 0.010671097238773655
[Epoch 13, Batch 2100] loss: 0.016278738853012554
[Epoch 13, Batch 2200] loss: 0.023388879423706613
[Epoch 13, Batch 2300] loss: 0.012514067770316615
[Epoch 13, Batch 2400] loss: 0.009090680305507703
[Epoch 13, Batch 2500] loss: 0.004367573226775221
[Epoch 13, Batch 2600] loss: 0.008358000036362228
[Epoch 13, Batch 2700] loss: 0.0032323824318291373
[Epoch 13, Batch 2800] loss: 0.014496907560783256
[Epoch 13, Batch 2900] loss: 0.005183146614132284
[Epoch 13, Batch 3000] loss: 0.005548582040992187
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9872
Overfitting: 0.0526
[Epoch 14, Batch 100] loss: 0.006305154375494908
[Epoch 14, Batch 200] loss: 0.01065153281439791
[Epoch 14, Batch 300] loss: 0.008323115549912927
[Epoch 14, Batch 400] loss: 0.00676068830451527
[Epoch 14, Batch 500] loss: 0.005781128856272062
[Epoch 14, Batch 600] loss: 0.003802757724112098
[Epoch 14, Batch 700] loss: 0.009648304405946249
[Epoch 14, Batch 800] loss: 0.00488816340327503
[Epoch 14, Batch 900] loss: 0.003411590669308282
[Epoch 14, Batch 1000] loss: 0.008190349171654817
[Epoch 14, Batch 1100] loss: 0.0071955840039322535
[Epoch 14, Batch 1200] loss: 0.0019287907136879311
[Epoch 14, Batch 1300] loss: 0.01683033760177068
[Epoch 14, Batch 1400] loss: 0.012319961003270237
[Epoch 14, Batch 1500] loss: 0.010485470208991501
[Epoch 14, Batch 1600] loss: 0.01867398805866742
[Epoch 14, Batch 1700] loss: 0.007466544518633782
[Epoch 14, Batch 1800] loss: 0.0172640577808221
[Epoch 14, Batch 1900] loss: 0.0075412665616698855
[Epoch 14, Batch 2000] loss: 0.009482687699918415
[Epoch 14, Batch 2100] loss: 0.010892799338386964
[Epoch 14, Batch 2200] loss: 0.01774214300640324
[Epoch 14, Batch 2300] loss: 0.00826351991930096
[Epoch 14, Batch 2400] loss: 0.005371267651967173
[Epoch 14, Batch 2500] loss: 0.016511958148753364
[Epoch 14, Batch 2600] loss: 0.005645934654319262
[Epoch 14, Batch 2700] loss: 0.01564447173335111
[Epoch 14, Batch 2800] loss: 0.005512580527984028
[Epoch 14, Batch 2900] loss: 0.017458223880306604
[Epoch 14, Batch 3000] loss: 0.010182030543638233
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0648
Validation Accuracy: 0.9851
Overfitting: 0.0648
[Epoch 15, Batch 100] loss: 0.008645036471518779
[Epoch 15, Batch 200] loss: 0.009703941421083755
[Epoch 15, Batch 300] loss: 0.007310562232561892
[Epoch 15, Batch 400] loss: 0.014336278526292857
[Epoch 15, Batch 500] loss: 0.00869874893595437
[Epoch 15, Batch 600] loss: 0.00407790756576162
[Epoch 15, Batch 700] loss: 0.005859347384713658
[Epoch 15, Batch 800] loss: 0.01324313112726486
[Epoch 15, Batch 900] loss: 0.010866157666108621
[Epoch 15, Batch 1000] loss: 0.011083860282702744
[Epoch 15, Batch 1100] loss: 0.009755209283831619
[Epoch 15, Batch 1200] loss: 0.007504032255678794
[Epoch 15, Batch 1300] loss: 0.008085820793483548
[Epoch 15, Batch 1400] loss: 0.013420425351021094
[Epoch 15, Batch 1500] loss: 0.004999301355222059
[Epoch 15, Batch 1600] loss: 0.008429187084548744
[Epoch 15, Batch 1700] loss: 0.016333578852432994
[Epoch 15, Batch 1800] loss: 0.007379323407901666
[Epoch 15, Batch 1900] loss: 0.017732029793338596
[Epoch 15, Batch 2000] loss: 0.008510625092279725
[Epoch 15, Batch 2100] loss: 0.00503372437373315
[Epoch 15, Batch 2200] loss: 0.003114595138169989
[Epoch 15, Batch 2300] loss: 0.008413190424940922
[Epoch 15, Batch 2400] loss: 0.004209354761608211
[Epoch 15, Batch 2500] loss: 0.012908127937964906
[Epoch 15, Batch 2600] loss: 0.008597180472961555
[Epoch 15, Batch 2700] loss: 0.007528361350432533
[Epoch 15, Batch 2800] loss: 0.010445667657606919
[Epoch 15, Batch 2900] loss: 0.01401979173969039
[Epoch 15, Batch 3000] loss: 0.013791976754964708
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9873
Overfitting: 0.0550
[Epoch 16, Batch 100] loss: 0.007772234731901335
[Epoch 16, Batch 200] loss: 0.007381630561667407
[Epoch 16, Batch 300] loss: 0.007986286103099118
[Epoch 16, Batch 400] loss: 0.007822188624402315
[Epoch 16, Batch 500] loss: 0.001906130047369743
[Epoch 16, Batch 600] loss: 0.002283307675844526
[Epoch 16, Batch 700] loss: 0.006973445151758426
[Epoch 16, Batch 800] loss: 0.005916299020947804
[Epoch 16, Batch 900] loss: 0.0033800062659702233
[Epoch 16, Batch 1000] loss: 0.005361700970183847
[Epoch 16, Batch 1100] loss: 0.0059760200808072735
[Epoch 16, Batch 1200] loss: 0.005434787441770368
[Epoch 16, Batch 1300] loss: 0.006246709681802258
[Epoch 16, Batch 1400] loss: 0.0032794385320221407
[Epoch 16, Batch 1500] loss: 0.007147725935851668
[Epoch 16, Batch 1600] loss: 0.00989223052309697
[Epoch 16, Batch 1700] loss: 0.0061739908014388336
[Epoch 16, Batch 1800] loss: 0.0048970152942723645
[Epoch 16, Batch 1900] loss: 0.008635150237972766
[Epoch 16, Batch 2000] loss: 0.008751426637878125
[Epoch 16, Batch 2100] loss: 0.01170110422799837
[Epoch 16, Batch 2200] loss: 0.00459173558983963
[Epoch 16, Batch 2300] loss: 0.005198693728219723
[Epoch 16, Batch 2400] loss: 0.007405630267861056
[Epoch 16, Batch 2500] loss: 0.005714671770303994
[Epoch 16, Batch 2600] loss: 0.005845196025754831
[Epoch 16, Batch 2700] loss: 0.004756059355145226
[Epoch 16, Batch 2800] loss: 0.0032408098603204393
[Epoch 16, Batch 2900] loss: 0.007128921852450958
[Epoch 16, Batch 3000] loss: 0.0060710460757671565
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9875
Overfitting: 0.0505
[Epoch 17, Batch 100] loss: 0.005210046278359073
[Epoch 17, Batch 200] loss: 0.0016840235145912175
[Epoch 17, Batch 300] loss: 0.0023108887708974636
[Epoch 17, Batch 400] loss: 0.0015969264214743361
[Epoch 17, Batch 500] loss: 0.004239083378819828
[Epoch 17, Batch 600] loss: 0.001773708933255307
[Epoch 17, Batch 700] loss: 0.0018666816436933686
[Epoch 17, Batch 800] loss: 0.004897795122958542
[Epoch 17, Batch 900] loss: 0.002810669541036077
[Epoch 17, Batch 1000] loss: 0.003976225548280183
[Epoch 17, Batch 1100] loss: 0.004503700544773324
[Epoch 17, Batch 1200] loss: 0.0015124533644929271
[Epoch 17, Batch 1300] loss: 0.001232006444027718
[Epoch 17, Batch 1400] loss: 0.0034092616964777277
[Epoch 17, Batch 1500] loss: 0.005738193721916787
[Epoch 17, Batch 1600] loss: 0.003650117635501999
[Epoch 17, Batch 1700] loss: 0.0064116587915196985
[Epoch 17, Batch 1800] loss: 0.009151521846932695
[Epoch 17, Batch 1900] loss: 0.007168725100242881
[Epoch 17, Batch 2000] loss: 0.002447974589146753
[Epoch 17, Batch 2100] loss: 0.007299880011630222
[Epoch 17, Batch 2200] loss: 0.004753791858732468
[Epoch 17, Batch 2300] loss: 0.0013373767692282713
[Epoch 17, Batch 2400] loss: 0.005745169297345285
[Epoch 17, Batch 2500] loss: 0.003766298676754616
[Epoch 17, Batch 2600] loss: 0.00789425519790015
[Epoch 17, Batch 2700] loss: 0.008143404600726996
[Epoch 17, Batch 2800] loss: 0.014206646511710233
[Epoch 17, Batch 2900] loss: 0.0038526483171563088
[Epoch 17, Batch 3000] loss: 0.004821896744249443
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9878
Overfitting: 0.0519
[Epoch 18, Batch 100] loss: 0.007646594300711058
[Epoch 18, Batch 200] loss: 0.0034276406655135362
[Epoch 18, Batch 300] loss: 0.008955576460229224
[Epoch 18, Batch 400] loss: 0.003694486807090698
[Epoch 18, Batch 500] loss: 0.0015274337686987849
[Epoch 18, Batch 600] loss: 0.001432434985290456
[Epoch 18, Batch 700] loss: 0.0022400142867087425
[Epoch 18, Batch 800] loss: 0.004136300101154333
[Epoch 18, Batch 900] loss: 0.0026136846297333703
[Epoch 18, Batch 1000] loss: 0.006830124537197655
[Epoch 18, Batch 1100] loss: 0.005385281874705683
[Epoch 18, Batch 1200] loss: 0.0012947313961981877
[Epoch 18, Batch 1300] loss: 0.008783011096364533
[Epoch 18, Batch 1400] loss: 0.011279441227929397
[Epoch 18, Batch 1500] loss: 0.004224103957028831
[Epoch 18, Batch 1600] loss: 0.007192305442030929
[Epoch 18, Batch 1700] loss: 0.005362309496097026
[Epoch 18, Batch 1800] loss: 0.005573793037042023
[Epoch 18, Batch 1900] loss: 0.006553038296516718
[Epoch 18, Batch 2000] loss: 0.008279810305443789
[Epoch 18, Batch 2100] loss: 0.005048186463348543
[Epoch 18, Batch 2200] loss: 0.007243901908006762
[Epoch 18, Batch 2300] loss: 0.002850662982546055
[Epoch 18, Batch 2400] loss: 0.0030705408317558635
[Epoch 18, Batch 2500] loss: 0.0033044798176827326
[Epoch 18, Batch 2600] loss: 0.005189205985282399
[Epoch 18, Batch 2700] loss: 0.013798515209473124
[Epoch 18, Batch 2800] loss: 0.018811055557310396
[Epoch 18, Batch 2900] loss: 0.005189488906910071
[Epoch 18, Batch 3000] loss: 0.002601155149030774
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9867
Overfitting: 0.0551
[Epoch 19, Batch 100] loss: 0.0036245182342588577
[Epoch 19, Batch 200] loss: 0.005470032637007023
[Epoch 19, Batch 300] loss: 0.008751112769119232
[Epoch 19, Batch 400] loss: 0.0055193355690479964
[Epoch 19, Batch 500] loss: 0.01265315742854824
[Epoch 19, Batch 600] loss: 0.01173884473229208
[Epoch 19, Batch 700] loss: 0.0013491799921996517
[Epoch 19, Batch 800] loss: 0.00733732751111333
[Epoch 19, Batch 900] loss: 0.0025922563498306773
[Epoch 19, Batch 1000] loss: 0.0014799276131747874
[Epoch 19, Batch 1100] loss: 0.005684450818502
[Epoch 19, Batch 1200] loss: 0.002696977834385237
[Epoch 19, Batch 1300] loss: 0.008565843968598158
[Epoch 19, Batch 1400] loss: 0.00452185123593722
[Epoch 19, Batch 1500] loss: 0.004178902204823771
[Epoch 19, Batch 1600] loss: 0.0008719802276857536
[Epoch 19, Batch 1700] loss: 0.004582664439720361
[Epoch 19, Batch 1800] loss: 0.0020373724196639386
[Epoch 19, Batch 1900] loss: 0.0024248622472452298
[Epoch 19, Batch 2000] loss: 0.002529131126755857
[Epoch 19, Batch 2100] loss: 0.008442024597698286
[Epoch 19, Batch 2200] loss: 0.003991824335263523
[Epoch 19, Batch 2300] loss: 0.004575238747178432
[Epoch 19, Batch 2400] loss: 0.0016003382159406954
[Epoch 19, Batch 2500] loss: 0.0029319481789287847
[Epoch 19, Batch 2600] loss: 0.009369206175657467
[Epoch 19, Batch 2700] loss: 0.0027890646600317835
[Epoch 19, Batch 2800] loss: 0.008119929942100574
[Epoch 19, Batch 2900] loss: 0.0024085703812852443
[Epoch 19, Batch 3000] loss: 0.0018291933867621956
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9883
Overfitting: 0.0548
[Epoch 20, Batch 100] loss: 0.0007806666257459894
[Epoch 20, Batch 200] loss: 0.006553861078568133
[Epoch 20, Batch 300] loss: 0.004364737885774161
[Epoch 20, Batch 400] loss: 0.0053475655559942934
[Epoch 20, Batch 500] loss: 0.006592693199346939
[Epoch 20, Batch 600] loss: 0.003451849487580887
[Epoch 20, Batch 700] loss: 0.002161909853679305
[Epoch 20, Batch 800] loss: 0.003304392673693428
[Epoch 20, Batch 900] loss: 0.0006920747285718631
[Epoch 20, Batch 1000] loss: 0.008136102705550008
[Epoch 20, Batch 1100] loss: 0.0007814003690175042
[Epoch 20, Batch 1200] loss: 0.001400974363290608
[Epoch 20, Batch 1300] loss: 0.0011892477438124871
[Epoch 20, Batch 1400] loss: 0.0009552229327550776
[Epoch 20, Batch 1500] loss: 0.004861387826792334
[Epoch 20, Batch 1600] loss: 0.0009307506704174706
[Epoch 20, Batch 1700] loss: 0.003825798009293484
[Epoch 20, Batch 1800] loss: 0.017942422824041983
[Epoch 20, Batch 1900] loss: 0.019970840219419087
[Epoch 20, Batch 2000] loss: 0.005570649975595927
[Epoch 20, Batch 2100] loss: 0.0020128862825563943
[Epoch 20, Batch 2200] loss: 0.0016692719726669302
[Epoch 20, Batch 2300] loss: 0.004660886531520347
[Epoch 20, Batch 2400] loss: 0.005411081987844977
[Epoch 20, Batch 2500] loss: 0.006392023669024098
[Epoch 20, Batch 2600] loss: 0.0037172386586510698
[Epoch 20, Batch 2700] loss: 0.004578711105349953
[Epoch 20, Batch 2800] loss: 0.0019201164420331906
[Epoch 20, Batch 2900] loss: 0.012429140314796073
[Epoch 20, Batch 3000] loss: 0.004163699003272328
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0594
Validation Accuracy: 0.9867
Overfitting: 0.0594
[Epoch 21, Batch 100] loss: 0.005091864353858071
[Epoch 21, Batch 200] loss: 0.007545662064405007
[Epoch 21, Batch 300] loss: 0.007541494954935537
[Epoch 21, Batch 400] loss: 0.012074343141271697
[Epoch 21, Batch 500] loss: 0.0026823383352856567
[Epoch 21, Batch 600] loss: 0.004314597235485564
[Epoch 21, Batch 700] loss: 0.006561040268079665
[Epoch 21, Batch 800] loss: 0.00489683781537451
[Epoch 21, Batch 900] loss: 0.0036403185756398626
[Epoch 21, Batch 1000] loss: 0.0033216015129945474
[Epoch 21, Batch 1100] loss: 0.004161660335261104
[Epoch 21, Batch 1200] loss: 0.0035075535478983743
[Epoch 21, Batch 1300] loss: 0.006754605079228923
[Epoch 21, Batch 1400] loss: 0.00939864696612748
[Epoch 21, Batch 1500] loss: 0.001231982027599372
[Epoch 21, Batch 1600] loss: 0.003157225150183427
[Epoch 21, Batch 1700] loss: 0.006888845306437617
[Epoch 21, Batch 1800] loss: 0.0028904945450466003
[Epoch 21, Batch 1900] loss: 0.005230588545452264
[Epoch 21, Batch 2000] loss: 0.0029345463790431837
[Epoch 21, Batch 2100] loss: 0.0012872046896436728
[Epoch 21, Batch 2200] loss: 0.0007541338991458346
[Epoch 21, Batch 2300] loss: 0.002864253346030168
[Epoch 21, Batch 2400] loss: 0.006315627930291683
[Epoch 21, Batch 2500] loss: 0.0023734842357523434
[Epoch 21, Batch 2600] loss: 0.0023222974577938515
[Epoch 21, Batch 2700] loss: 0.002674566054243428
[Epoch 21, Batch 2800] loss: 0.010218953747702812
[Epoch 21, Batch 2900] loss: 0.006753498435583687
[Epoch 21, Batch 3000] loss: 0.0022995419132025496
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9883
Overfitting: 0.0543
[Epoch 22, Batch 100] loss: 0.004124626655489436
[Epoch 22, Batch 200] loss: 0.005740891388712974
[Epoch 22, Batch 300] loss: 0.002352791629024544
[Epoch 22, Batch 400] loss: 0.0017229711049943574
[Epoch 22, Batch 500] loss: 0.0038166050644561976
[Epoch 22, Batch 600] loss: 0.0007308946320185683
[Epoch 22, Batch 700] loss: 0.002330589594647314
[Epoch 22, Batch 800] loss: 0.000915511732694867
[Epoch 22, Batch 900] loss: 0.003926613379269028
[Epoch 22, Batch 1000] loss: 0.009980852505304082
[Epoch 22, Batch 1100] loss: 0.001193256363942723
[Epoch 22, Batch 1200] loss: 0.0007193946963170106
[Epoch 22, Batch 1300] loss: 0.0007090943432492302
[Epoch 22, Batch 1400] loss: 0.0032404486855218194
[Epoch 22, Batch 1500] loss: 0.0006200662041905592
[Epoch 22, Batch 1600] loss: 0.000514558263894429
[Epoch 22, Batch 1700] loss: 0.0009320117360408986
[Epoch 22, Batch 1800] loss: 0.0017722625518071266
[Epoch 22, Batch 1900] loss: 0.0007024438623991358
[Epoch 22, Batch 2000] loss: 0.001429323954225694
[Epoch 22, Batch 2100] loss: 0.0033886046561291527
[Epoch 22, Batch 2200] loss: 0.005358859562032982
[Epoch 22, Batch 2300] loss: 0.008135709170098546
[Epoch 22, Batch 2400] loss: 0.014681230661828764
[Epoch 22, Batch 2500] loss: 0.005421954962171043
[Epoch 22, Batch 2600] loss: 0.0063133385149802025
[Epoch 22, Batch 2700] loss: 0.004787910897600334
[Epoch 22, Batch 2800] loss: 0.010148849382662277
[Epoch 22, Batch 2900] loss: 0.002304436021586298
[Epoch 22, Batch 3000] loss: 0.0027221321818515064
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0588
Validation Accuracy: 0.9878
Overfitting: 0.0588
[Epoch 23, Batch 100] loss: 0.004543968838105577
[Epoch 23, Batch 200] loss: 0.0007806433586551975
[Epoch 23, Batch 300] loss: 0.0008157565295445579
[Epoch 23, Batch 400] loss: 0.0008419393143217402
[Epoch 23, Batch 500] loss: 0.0011880362965311876
[Epoch 23, Batch 600] loss: 0.001741366860290725
[Epoch 23, Batch 700] loss: 0.00813070801005903
[Epoch 23, Batch 800] loss: 0.002105952581075741
[Epoch 23, Batch 900] loss: 0.0017081728675655582
[Epoch 23, Batch 1000] loss: 0.0029208463859646374
[Epoch 23, Batch 1100] loss: 0.0005281255208682367
[Epoch 23, Batch 1200] loss: 0.0008265168539545442
[Epoch 23, Batch 1300] loss: 0.00605829199137208
[Epoch 23, Batch 1400] loss: 0.001640750568539886
[Epoch 23, Batch 1500] loss: 0.0009500867419461656
[Epoch 23, Batch 1600] loss: 0.0008944291131675896
[Epoch 23, Batch 1700] loss: 0.0022073550811969865
[Epoch 23, Batch 1800] loss: 0.0014740308972364601
[Epoch 23, Batch 1900] loss: 0.0006639552905195512
[Epoch 23, Batch 2000] loss: 0.0024778414658358015
[Epoch 23, Batch 2100] loss: 0.0027191259004471567
[Epoch 23, Batch 2200] loss: 0.0014536052771108832
[Epoch 23, Batch 2300] loss: 0.0012185604355245782
[Epoch 23, Batch 2400] loss: 0.00041728994023826794
[Epoch 23, Batch 2500] loss: 0.0019611588168455896
[Epoch 23, Batch 2600] loss: 0.000997877642717775
[Epoch 23, Batch 2700] loss: 0.0013868896916234296
[Epoch 23, Batch 2800] loss: 0.0009624459623860071
[Epoch 23, Batch 2900] loss: 0.0005482823309063889
[Epoch 23, Batch 3000] loss: 0.004282203428048188
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0585
Validation Accuracy: 0.9879
Overfitting: 0.0585
[Epoch 24, Batch 100] loss: 0.0008323838436837772
[Epoch 24, Batch 200] loss: 0.0005778845693630608
[Epoch 24, Batch 300] loss: 0.0002771638408367805
[Epoch 24, Batch 400] loss: 0.00021566584846348656
[Epoch 24, Batch 500] loss: 0.0002871658231666885
[Epoch 24, Batch 600] loss: 0.0007375958502209911
[Epoch 24, Batch 700] loss: 0.00036399363132119336
[Epoch 24, Batch 800] loss: 0.00284802607884044
[Epoch 24, Batch 900] loss: 0.00027752825890742016
[Epoch 24, Batch 1000] loss: 0.001983202630743768
[Epoch 24, Batch 1100] loss: 0.0012577423689252277
[Epoch 24, Batch 1200] loss: 0.00037562168212280423
[Epoch 24, Batch 1300] loss: 0.00054629409858721
[Epoch 24, Batch 1400] loss: 0.0008628580808495157
[Epoch 24, Batch 1500] loss: 0.0017842301871794054
[Epoch 24, Batch 1600] loss: 0.0003128230181388503
[Epoch 24, Batch 1700] loss: 0.0002725776744787645
[Epoch 24, Batch 1800] loss: 0.0015429932637686682
[Epoch 24, Batch 1900] loss: 0.0002456932133229017
[Epoch 24, Batch 2000] loss: 0.0008244734722953596
[Epoch 24, Batch 2100] loss: 0.0003373034825709853
[Epoch 24, Batch 2200] loss: 0.0011188081980641185
[Epoch 24, Batch 2300] loss: 0.0002761368077472515
[Epoch 24, Batch 2400] loss: 0.00044931598039019247
[Epoch 24, Batch 2500] loss: 0.0005276054245744133
[Epoch 24, Batch 2600] loss: 0.0007529519610454915
[Epoch 24, Batch 2700] loss: 0.0002639742933521072
[Epoch 24, Batch 2800] loss: 0.0003789071520065024
[Epoch 24, Batch 2900] loss: 0.0002445039778867919
[Epoch 24, Batch 3000] loss: 0.0003178423768710914
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0571
Validation Accuracy: 0.9891
Overfitting: 0.0571
Fold 2 validation loss: 0.0571
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.291132709980011
[Epoch 1, Batch 200] loss: 2.17737740278244
[Epoch 1, Batch 300] loss: 1.0890150040388107
[Epoch 1, Batch 400] loss: 0.5997337736189365
[Epoch 1, Batch 500] loss: 0.40351312041282655
[Epoch 1, Batch 600] loss: 0.3743669914454222
[Epoch 1, Batch 700] loss: 0.28488081257790326
[Epoch 1, Batch 800] loss: 0.2583611216209829
[Epoch 1, Batch 900] loss: 0.22836702208966017
[Epoch 1, Batch 1000] loss: 0.18689418787136675
[Epoch 1, Batch 1100] loss: 0.16301306495442985
[Epoch 1, Batch 1200] loss: 0.18162759508937598
[Epoch 1, Batch 1300] loss: 0.15686350179836153
[Epoch 1, Batch 1400] loss: 0.18300203218124808
[Epoch 1, Batch 1500] loss: 0.1565390445617959
[Epoch 1, Batch 1600] loss: 0.14308461679145693
[Epoch 1, Batch 1700] loss: 0.14982822470366955
[Epoch 1, Batch 1800] loss: 0.12116651092888787
[Epoch 1, Batch 1900] loss: 0.15007633427158
[Epoch 1, Batch 2000] loss: 0.13440778305288403
[Epoch 1, Batch 2100] loss: 0.14893044454976917
[Epoch 1, Batch 2200] loss: 0.1255411076254677
[Epoch 1, Batch 2300] loss: 0.10272105182753875
[Epoch 1, Batch 2400] loss: 0.12666939244605602
[Epoch 1, Batch 2500] loss: 0.11491522333817557
[Epoch 1, Batch 2600] loss: 0.0984486404096242
[Epoch 1, Batch 2700] loss: 0.08938466335996054
[Epoch 1, Batch 2800] loss: 0.09655795546947048
[Epoch 1, Batch 2900] loss: 0.07626143378787674
[Epoch 1, Batch 3000] loss: 0.1002168434264604
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0989
Validation Accuracy: 0.9704
Overfitting: 0.0989
Best model saved at epoch 1 with validation loss: 0.0989
[Epoch 2, Batch 100] loss: 0.10708645623642951
[Epoch 2, Batch 200] loss: 0.08003491033334285
[Epoch 2, Batch 300] loss: 0.06865752678015269
[Epoch 2, Batch 400] loss: 0.10237615093850763
[Epoch 2, Batch 500] loss: 0.07565203254809603
[Epoch 2, Batch 600] loss: 0.1011806339037139
[Epoch 2, Batch 700] loss: 0.09727808254188858
[Epoch 2, Batch 800] loss: 0.08074910013587214
[Epoch 2, Batch 900] loss: 0.06604074713133741
[Epoch 2, Batch 1000] loss: 0.08379033036588225
[Epoch 2, Batch 1100] loss: 0.07301132976834196
[Epoch 2, Batch 1200] loss: 0.054751595054694915
[Epoch 2, Batch 1300] loss: 0.07539081785362214
[Epoch 2, Batch 1400] loss: 0.07052319018635898
[Epoch 2, Batch 1500] loss: 0.0708371570770396
[Epoch 2, Batch 1600] loss: 0.07486530517810025
[Epoch 2, Batch 1700] loss: 0.0701687897107331
[Epoch 2, Batch 1800] loss: 0.08664192549476865
[Epoch 2, Batch 1900] loss: 0.0916958518064348
[Epoch 2, Batch 2000] loss: 0.09200021117052529
[Epoch 2, Batch 2100] loss: 0.08052274534362368
[Epoch 2, Batch 2200] loss: 0.08410295641166159
[Epoch 2, Batch 2300] loss: 0.0599634288426023
[Epoch 2, Batch 2400] loss: 0.055907347812317314
[Epoch 2, Batch 2500] loss: 0.06087512455036631
[Epoch 2, Batch 2600] loss: 0.07607645611802581
[Epoch 2, Batch 2700] loss: 0.08297460135596339
[Epoch 2, Batch 2800] loss: 0.06935817045276053
[Epoch 2, Batch 2900] loss: 0.059048532301094386
[Epoch 2, Batch 3000] loss: 0.050125085811887404
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0759
Validation Accuracy: 0.9762
Overfitting: 0.0759
Best model saved at epoch 2 with validation loss: 0.0759
[Epoch 3, Batch 100] loss: 0.04666309360138257
[Epoch 3, Batch 200] loss: 0.059236397692002354
[Epoch 3, Batch 300] loss: 0.05596669567225035
[Epoch 3, Batch 400] loss: 0.050690378803701606
[Epoch 3, Batch 500] loss: 0.05685872152607772
[Epoch 3, Batch 600] loss: 0.04546063272311585
[Epoch 3, Batch 700] loss: 0.056441422397620046
[Epoch 3, Batch 800] loss: 0.046365853360039185
[Epoch 3, Batch 900] loss: 0.06224999099154957
[Epoch 3, Batch 1000] loss: 0.05766682503090124
[Epoch 3, Batch 1100] loss: 0.05495982534077484
[Epoch 3, Batch 1200] loss: 0.06906163987267064
[Epoch 3, Batch 1300] loss: 0.044357023262418804
[Epoch 3, Batch 1400] loss: 0.04727330952708144
[Epoch 3, Batch 1500] loss: 0.06262921167741296
[Epoch 3, Batch 1600] loss: 0.04204683846823173
[Epoch 3, Batch 1700] loss: 0.060155400579387786
[Epoch 3, Batch 1800] loss: 0.05506543311785208
[Epoch 3, Batch 1900] loss: 0.0704405250880518
[Epoch 3, Batch 2000] loss: 0.047611689109471625
[Epoch 3, Batch 2100] loss: 0.06566654438938713
[Epoch 3, Batch 2200] loss: 0.05758529905302567
[Epoch 3, Batch 2300] loss: 0.04775900338710926
[Epoch 3, Batch 2400] loss: 0.06240660929615842
[Epoch 3, Batch 2500] loss: 0.06004099878598936
[Epoch 3, Batch 2600] loss: 0.048025366951769684
[Epoch 3, Batch 2700] loss: 0.05181430974218529
[Epoch 3, Batch 2800] loss: 0.04752421969053103
[Epoch 3, Batch 2900] loss: 0.041106891587842254
[Epoch 3, Batch 3000] loss: 0.0393918789998861
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0618
Validation Accuracy: 0.9810
Overfitting: 0.0618
Best model saved at epoch 3 with validation loss: 0.0618
[Epoch 4, Batch 100] loss: 0.04195326092201867
[Epoch 4, Batch 200] loss: 0.033580784619844053
[Epoch 4, Batch 300] loss: 0.042027250359824395
[Epoch 4, Batch 400] loss: 0.06104604763357201
[Epoch 4, Batch 500] loss: 0.03685056209273171
[Epoch 4, Batch 600] loss: 0.0363423401597538
[Epoch 4, Batch 700] loss: 0.04556762873296975
[Epoch 4, Batch 800] loss: 0.05126109638425987
[Epoch 4, Batch 900] loss: 0.041697753166954496
[Epoch 4, Batch 1000] loss: 0.03019998195071821
[Epoch 4, Batch 1100] loss: 0.04168090712555568
[Epoch 4, Batch 1200] loss: 0.03692383388231974
[Epoch 4, Batch 1300] loss: 0.04467273116793877
[Epoch 4, Batch 1400] loss: 0.033314721292845205
[Epoch 4, Batch 1500] loss: 0.05075739056468592
[Epoch 4, Batch 1600] loss: 0.04309297035357304
[Epoch 4, Batch 1700] loss: 0.049086198120494376
[Epoch 4, Batch 1800] loss: 0.05658149436028907
[Epoch 4, Batch 1900] loss: 0.029861292323912495
[Epoch 4, Batch 2000] loss: 0.039488093736581506
[Epoch 4, Batch 2100] loss: 0.038783297482004854
[Epoch 4, Batch 2200] loss: 0.03751683666232566
[Epoch 4, Batch 2300] loss: 0.03165585152361018
[Epoch 4, Batch 2400] loss: 0.0481529633977334
[Epoch 4, Batch 2500] loss: 0.029880601144686807
[Epoch 4, Batch 2600] loss: 0.04370586122589884
[Epoch 4, Batch 2700] loss: 0.05813262071176723
[Epoch 4, Batch 2800] loss: 0.04465223828185117
[Epoch 4, Batch 2900] loss: 0.04059245306707453
[Epoch 4, Batch 3000] loss: 0.04693020932376385
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9836
Overfitting: 0.0540
Best model saved at epoch 4 with validation loss: 0.0540
[Epoch 5, Batch 100] loss: 0.026669282030779867
[Epoch 5, Batch 200] loss: 0.035013114453104205
[Epoch 5, Batch 300] loss: 0.029347707418492065
[Epoch 5, Batch 400] loss: 0.025159819458767742
[Epoch 5, Batch 500] loss: 0.03251184232296509
[Epoch 5, Batch 600] loss: 0.0647459273856657
[Epoch 5, Batch 700] loss: 0.03682024640860618
[Epoch 5, Batch 800] loss: 0.020072188244957944
[Epoch 5, Batch 900] loss: 0.03460179226363835
[Epoch 5, Batch 1000] loss: 0.03341527980130195
[Epoch 5, Batch 1100] loss: 0.026048532608547247
[Epoch 5, Batch 1200] loss: 0.044555496676839536
[Epoch 5, Batch 1300] loss: 0.0409534416117458
[Epoch 5, Batch 1400] loss: 0.02947779058224114
[Epoch 5, Batch 1500] loss: 0.036872486138890964
[Epoch 5, Batch 1600] loss: 0.028318844951863865
[Epoch 5, Batch 1700] loss: 0.03823331222811248
[Epoch 5, Batch 1800] loss: 0.02212051824753871
[Epoch 5, Batch 1900] loss: 0.04013413922919426
[Epoch 5, Batch 2000] loss: 0.04350599334964499
[Epoch 5, Batch 2100] loss: 0.03912583862707834
[Epoch 5, Batch 2200] loss: 0.036591839591565076
[Epoch 5, Batch 2300] loss: 0.03129402574413689
[Epoch 5, Batch 2400] loss: 0.023431225410313346
[Epoch 5, Batch 2500] loss: 0.050864697702527335
[Epoch 5, Batch 2600] loss: 0.030922413496882656
[Epoch 5, Batch 2700] loss: 0.02213256798695511
[Epoch 5, Batch 2800] loss: 0.043234651851962555
[Epoch 5, Batch 2900] loss: 0.04433400631722179
[Epoch 5, Batch 3000] loss: 0.028667510488667176
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0609
Validation Accuracy: 0.9820
Overfitting: 0.0609
[Epoch 6, Batch 100] loss: 0.030613389111022116
[Epoch 6, Batch 200] loss: 0.029573350657738046
[Epoch 6, Batch 300] loss: 0.028199154587782688
[Epoch 6, Batch 400] loss: 0.021362793332664297
[Epoch 6, Batch 500] loss: 0.023251351754806818
[Epoch 6, Batch 600] loss: 0.033593688987421044
[Epoch 6, Batch 700] loss: 0.03106073524841122
[Epoch 6, Batch 800] loss: 0.03198766138983047
[Epoch 6, Batch 900] loss: 0.011588361442063615
[Epoch 6, Batch 1000] loss: 0.03416268819695688
[Epoch 6, Batch 1100] loss: 0.031318487634162014
[Epoch 6, Batch 1200] loss: 0.024771382780545536
[Epoch 6, Batch 1300] loss: 0.03207709789050568
[Epoch 6, Batch 1400] loss: 0.024298737438875832
[Epoch 6, Batch 1500] loss: 0.025832561718925718
[Epoch 6, Batch 1600] loss: 0.03511996622153674
[Epoch 6, Batch 1700] loss: 0.0326243150508526
[Epoch 6, Batch 1800] loss: 0.03382245600791066
[Epoch 6, Batch 1900] loss: 0.035909835186757846
[Epoch 6, Batch 2000] loss: 0.03168179620653973
[Epoch 6, Batch 2100] loss: 0.020781385245136334
[Epoch 6, Batch 2200] loss: 0.03280288539837784
[Epoch 6, Batch 2300] loss: 0.032952100407037506
[Epoch 6, Batch 2400] loss: 0.024310614222195
[Epoch 6, Batch 2500] loss: 0.0315964709799664
[Epoch 6, Batch 2600] loss: 0.03458522246837674
[Epoch 6, Batch 2700] loss: 0.02806263285494424
[Epoch 6, Batch 2800] loss: 0.04755576473718975
[Epoch 6, Batch 2900] loss: 0.033495143222389744
[Epoch 6, Batch 3000] loss: 0.03745348256550642
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9851
Overfitting: 0.0492
Best model saved at epoch 6 with validation loss: 0.0492
[Epoch 7, Batch 100] loss: 0.0216001016512746
[Epoch 7, Batch 200] loss: 0.011898426978896169
[Epoch 7, Batch 300] loss: 0.012582553821130205
[Epoch 7, Batch 400] loss: 0.019095758744515478
[Epoch 7, Batch 500] loss: 0.022784467593664884
[Epoch 7, Batch 600] loss: 0.013117361645636266
[Epoch 7, Batch 700] loss: 0.020918913550867727
[Epoch 7, Batch 800] loss: 0.01589403876592769
[Epoch 7, Batch 900] loss: 0.02508076913316472
[Epoch 7, Batch 1000] loss: 0.02009055036616701
[Epoch 7, Batch 1100] loss: 0.04926679766273082
[Epoch 7, Batch 1200] loss: 0.013655910392708392
[Epoch 7, Batch 1300] loss: 0.020596723780035974
[Epoch 7, Batch 1400] loss: 0.023271740595610026
[Epoch 7, Batch 1500] loss: 0.02518060815411445
[Epoch 7, Batch 1600] loss: 0.019116979800510307
[Epoch 7, Batch 1700] loss: 0.01750690740189384
[Epoch 7, Batch 1800] loss: 0.023961312674273358
[Epoch 7, Batch 1900] loss: 0.03999973741561007
[Epoch 7, Batch 2000] loss: 0.03493072305131136
[Epoch 7, Batch 2100] loss: 0.029614175874849026
[Epoch 7, Batch 2200] loss: 0.030037422488803714
[Epoch 7, Batch 2300] loss: 0.03191850297684141
[Epoch 7, Batch 2400] loss: 0.03237551776705004
[Epoch 7, Batch 2500] loss: 0.03028149967907666
[Epoch 7, Batch 2600] loss: 0.010868966716661816
[Epoch 7, Batch 2700] loss: 0.038959750137728406
[Epoch 7, Batch 2800] loss: 0.03219171535740315
[Epoch 7, Batch 2900] loss: 0.024601689190203616
[Epoch 7, Batch 3000] loss: 0.024353721528241293
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9828
Overfitting: 0.0567
[Epoch 8, Batch 100] loss: 0.014046020367622987
[Epoch 8, Batch 200] loss: 0.01366342448613068
[Epoch 8, Batch 300] loss: 0.017377113447892042
[Epoch 8, Batch 400] loss: 0.01881614571851969
[Epoch 8, Batch 500] loss: 0.021944441619998544
[Epoch 8, Batch 600] loss: 0.027717984127398267
[Epoch 8, Batch 700] loss: 0.014218032533863152
[Epoch 8, Batch 800] loss: 0.017047334345024864
[Epoch 8, Batch 900] loss: 0.017578665845603608
[Epoch 8, Batch 1000] loss: 0.019704954515764258
[Epoch 8, Batch 1100] loss: 0.019965482563457045
[Epoch 8, Batch 1200] loss: 0.02601886843565808
[Epoch 8, Batch 1300] loss: 0.020317918700748124
[Epoch 8, Batch 1400] loss: 0.02599415527893143
[Epoch 8, Batch 1500] loss: 0.02474531336929431
[Epoch 8, Batch 1600] loss: 0.015150745369537618
[Epoch 8, Batch 1700] loss: 0.01327471428345234
[Epoch 8, Batch 1800] loss: 0.017356006776635693
[Epoch 8, Batch 1900] loss: 0.03136811422437859
[Epoch 8, Batch 2000] loss: 0.02078506474274036
[Epoch 8, Batch 2100] loss: 0.02313580574908883
[Epoch 8, Batch 2200] loss: 0.038099519720744865
[Epoch 8, Batch 2300] loss: 0.019826211772724492
[Epoch 8, Batch 2400] loss: 0.031532103459076095
[Epoch 8, Batch 2500] loss: 0.03334470410113681
[Epoch 8, Batch 2600] loss: 0.0420581300192498
[Epoch 8, Batch 2700] loss: 0.023076878335268704
[Epoch 8, Batch 2800] loss: 0.026845001248730113
[Epoch 8, Batch 2900] loss: 0.017862922793731285
[Epoch 8, Batch 3000] loss: 0.02404387292584943
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9868
Overfitting: 0.0497
[Epoch 9, Batch 100] loss: 0.011524117361823301
[Epoch 9, Batch 200] loss: 0.012747090063357972
[Epoch 9, Batch 300] loss: 0.010257443222981237
[Epoch 9, Batch 400] loss: 0.010983527747675907
[Epoch 9, Batch 500] loss: 0.019643769144067846
[Epoch 9, Batch 600] loss: 0.009307765593603108
[Epoch 9, Batch 700] loss: 0.022767257016098483
[Epoch 9, Batch 800] loss: 0.016513121202356162
[Epoch 9, Batch 900] loss: 0.012188101072462132
[Epoch 9, Batch 1000] loss: 0.02464018695638515
[Epoch 9, Batch 1100] loss: 0.02102130955069697
[Epoch 9, Batch 1200] loss: 0.017512904810573673
[Epoch 9, Batch 1300] loss: 0.015522497723723064
[Epoch 9, Batch 1400] loss: 0.019587310165129566
[Epoch 9, Batch 1500] loss: 0.016440226354934567
[Epoch 9, Batch 1600] loss: 0.01679178971724468
[Epoch 9, Batch 1700] loss: 0.014604980989370233
[Epoch 9, Batch 1800] loss: 0.02048905929063949
[Epoch 9, Batch 1900] loss: 0.02175596774218775
[Epoch 9, Batch 2000] loss: 0.006666525451196321
[Epoch 9, Batch 2100] loss: 0.00809896418560129
[Epoch 9, Batch 2200] loss: 0.012273282315554752
[Epoch 9, Batch 2300] loss: 0.010893818492277205
[Epoch 9, Batch 2400] loss: 0.014210005028571686
[Epoch 9, Batch 2500] loss: 0.014803930091384246
[Epoch 9, Batch 2600] loss: 0.008100522493315339
[Epoch 9, Batch 2700] loss: 0.01245634636591376
[Epoch 9, Batch 2800] loss: 0.03428243952009552
[Epoch 9, Batch 2900] loss: 0.01883664005415085
[Epoch 9, Batch 3000] loss: 0.02252016973701984
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9832
Overfitting: 0.0619
[Epoch 10, Batch 100] loss: 0.014015905415678844
[Epoch 10, Batch 200] loss: 0.030327830443411585
[Epoch 10, Batch 300] loss: 0.013075890025029367
[Epoch 10, Batch 400] loss: 0.018610785253022188
[Epoch 10, Batch 500] loss: 0.012498135764517429
[Epoch 10, Batch 600] loss: 0.009871275492505447
[Epoch 10, Batch 700] loss: 0.012902408761096922
[Epoch 10, Batch 800] loss: 0.00975759681063778
[Epoch 10, Batch 900] loss: 0.011986941948400727
[Epoch 10, Batch 1000] loss: 0.01887901617405987
[Epoch 10, Batch 1100] loss: 0.0085564615523532
[Epoch 10, Batch 1200] loss: 0.008760711104632718
[Epoch 10, Batch 1300] loss: 0.006522952019586228
[Epoch 10, Batch 1400] loss: 0.022688853877766632
[Epoch 10, Batch 1500] loss: 0.008632820794919099
[Epoch 10, Batch 1600] loss: 0.020575929373549115
[Epoch 10, Batch 1700] loss: 0.01787167070372561
[Epoch 10, Batch 1800] loss: 0.01456892974518496
[Epoch 10, Batch 1900] loss: 0.015003526973381441
[Epoch 10, Batch 2000] loss: 0.013782465133870119
[Epoch 10, Batch 2100] loss: 0.008867784864548867
[Epoch 10, Batch 2200] loss: 0.01224490366590544
[Epoch 10, Batch 2300] loss: 0.02168431241774414
[Epoch 10, Batch 2400] loss: 0.011856503726489791
[Epoch 10, Batch 2500] loss: 0.009783611153484344
[Epoch 10, Batch 2600] loss: 0.013947777282194238
[Epoch 10, Batch 2700] loss: 0.018085961735097272
[Epoch 10, Batch 2800] loss: 0.018099727507787974
[Epoch 10, Batch 2900] loss: 0.02162055659067846
[Epoch 10, Batch 3000] loss: 0.01827885835469715
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0594
Validation Accuracy: 0.9852
Overfitting: 0.0594
[Epoch 11, Batch 100] loss: 0.01269293547412417
[Epoch 11, Batch 200] loss: 0.018679025397849502
[Epoch 11, Batch 300] loss: 0.023580948781027473
[Epoch 11, Batch 400] loss: 0.021634931328444507
[Epoch 11, Batch 500] loss: 0.016621540479245595
[Epoch 11, Batch 600] loss: 0.0063310308171639915
[Epoch 11, Batch 700] loss: 0.004959952467933135
[Epoch 11, Batch 800] loss: 0.011869472500661686
[Epoch 11, Batch 900] loss: 0.007434907594656579
[Epoch 11, Batch 1000] loss: 0.014889873346985496
[Epoch 11, Batch 1100] loss: 0.007460826810302024
[Epoch 11, Batch 1200] loss: 0.011373882121515634
[Epoch 11, Batch 1300] loss: 0.008178316785358675
[Epoch 11, Batch 1400] loss: 0.01465230988787198
[Epoch 11, Batch 1500] loss: 0.012263653938121025
[Epoch 11, Batch 1600] loss: 0.0251747932164335
[Epoch 11, Batch 1700] loss: 0.016341490348600017
[Epoch 11, Batch 1800] loss: 0.013485244525882081
[Epoch 11, Batch 1900] loss: 0.020179738005758736
[Epoch 11, Batch 2000] loss: 0.013655028197272259
[Epoch 11, Batch 2100] loss: 0.014229328403178556
[Epoch 11, Batch 2200] loss: 0.017705268796628388
[Epoch 11, Batch 2300] loss: 0.021322546215014882
[Epoch 11, Batch 2400] loss: 0.006903961278317184
[Epoch 11, Batch 2500] loss: 0.010528990237822881
[Epoch 11, Batch 2600] loss: 0.0134796351694456
[Epoch 11, Batch 2700] loss: 0.02101949924438031
[Epoch 11, Batch 2800] loss: 0.01389625866800543
[Epoch 11, Batch 2900] loss: 0.008008436901541245
[Epoch 11, Batch 3000] loss: 0.008310094207977271
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9872
Overfitting: 0.0509
[Epoch 12, Batch 100] loss: 0.007483056411438156
[Epoch 12, Batch 200] loss: 0.006112547280273475
[Epoch 12, Batch 300] loss: 0.0049371912919446
[Epoch 12, Batch 400] loss: 0.010507607878107592
[Epoch 12, Batch 500] loss: 0.007817703911587159
[Epoch 12, Batch 600] loss: 0.009455724263503953
[Epoch 12, Batch 700] loss: 0.008524251023970919
[Epoch 12, Batch 800] loss: 0.009667604040985225
[Epoch 12, Batch 900] loss: 0.009069273588853548
[Epoch 12, Batch 1000] loss: 0.004510704723632273
[Epoch 12, Batch 1100] loss: 0.004312311115054684
[Epoch 12, Batch 1200] loss: 0.0022309070838592506
[Epoch 12, Batch 1300] loss: 0.008064338225975264
[Epoch 12, Batch 1400] loss: 0.006750449709525128
[Epoch 12, Batch 1500] loss: 0.016491939509484153
[Epoch 12, Batch 1600] loss: 0.008981547191087316
[Epoch 12, Batch 1700] loss: 0.02455136584393813
[Epoch 12, Batch 1800] loss: 0.010566799970770263
[Epoch 12, Batch 1900] loss: 0.009814303692469366
[Epoch 12, Batch 2000] loss: 0.017852859425481142
[Epoch 12, Batch 2100] loss: 0.00935374851151039
[Epoch 12, Batch 2200] loss: 0.005536552811704496
[Epoch 12, Batch 2300] loss: 0.005626907197144533
[Epoch 12, Batch 2400] loss: 0.007647473954923498
[Epoch 12, Batch 2500] loss: 0.008472920289097914
[Epoch 12, Batch 2600] loss: 0.024149629210005515
[Epoch 12, Batch 2700] loss: 0.01589228521773009
[Epoch 12, Batch 2800] loss: 0.012867223755139818
[Epoch 12, Batch 2900] loss: 0.012824637270705352
[Epoch 12, Batch 3000] loss: 0.012145352394452403
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9864
Overfitting: 0.0564
[Epoch 13, Batch 100] loss: 0.008061808669589254
[Epoch 13, Batch 200] loss: 0.00509880046480248
[Epoch 13, Batch 300] loss: 0.004855376719729065
[Epoch 13, Batch 400] loss: 0.004224392765238321
[Epoch 13, Batch 500] loss: 0.009535738266160365
[Epoch 13, Batch 600] loss: 0.008502912692482595
[Epoch 13, Batch 700] loss: 0.008556783353599258
[Epoch 13, Batch 800] loss: 0.010851608747045702
[Epoch 13, Batch 900] loss: 0.006166096498475326
[Epoch 13, Batch 1000] loss: 0.010961159006994877
[Epoch 13, Batch 1100] loss: 0.015243226408788217
[Epoch 13, Batch 1200] loss: 0.00668021116893307
[Epoch 13, Batch 1300] loss: 0.006533619076192281
[Epoch 13, Batch 1400] loss: 0.009856291384358541
[Epoch 13, Batch 1500] loss: 0.013037208798784831
[Epoch 13, Batch 1600] loss: 0.0022491488445385245
[Epoch 13, Batch 1700] loss: 0.003980124215432852
[Epoch 13, Batch 1800] loss: 0.007026457318414714
[Epoch 13, Batch 1900] loss: 0.02302533799937123
[Epoch 13, Batch 2000] loss: 0.016952842372421627
[Epoch 13, Batch 2100] loss: 0.01830456964577479
[Epoch 13, Batch 2200] loss: 0.014087196562493319
[Epoch 13, Batch 2300] loss: 0.004670285838585642
[Epoch 13, Batch 2400] loss: 0.004636137061861518
[Epoch 13, Batch 2500] loss: 0.015194867955906376
[Epoch 13, Batch 2600] loss: 0.017150235803201783
[Epoch 13, Batch 2700] loss: 0.007500031766194865
[Epoch 13, Batch 2800] loss: 0.005572374529932062
[Epoch 13, Batch 2900] loss: 0.01068009676107522
[Epoch 13, Batch 3000] loss: 0.00645180380896818
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9853
Overfitting: 0.0592
[Epoch 14, Batch 100] loss: 0.007385830377491516
[Epoch 14, Batch 200] loss: 0.02317909171542581
[Epoch 14, Batch 300] loss: 0.0064316075007042174
[Epoch 14, Batch 400] loss: 0.004463863135438189
[Epoch 14, Batch 500] loss: 0.002824537258066613
[Epoch 14, Batch 600] loss: 0.003379511348259712
[Epoch 14, Batch 700] loss: 0.00608420958614996
[Epoch 14, Batch 800] loss: 0.00995584499084572
[Epoch 14, Batch 900] loss: 0.0064711891097587685
[Epoch 14, Batch 1000] loss: 0.0061688365938353225
[Epoch 14, Batch 1100] loss: 0.0035062726011508972
[Epoch 14, Batch 1200] loss: 0.003175350203433709
[Epoch 14, Batch 1300] loss: 0.0040720807115104665
[Epoch 14, Batch 1400] loss: 0.031681909901166705
[Epoch 14, Batch 1500] loss: 0.02240404534842128
[Epoch 14, Batch 1600] loss: 0.010823594951318682
[Epoch 14, Batch 1700] loss: 0.0059028562402519925
[Epoch 14, Batch 1800] loss: 0.007439118612321351
[Epoch 14, Batch 1900] loss: 0.021577247568855852
[Epoch 14, Batch 2000] loss: 0.014662583572583116
[Epoch 14, Batch 2100] loss: 0.010223129945629808
[Epoch 14, Batch 2200] loss: 0.008733555344587102
[Epoch 14, Batch 2300] loss: 0.010318303455854903
[Epoch 14, Batch 2400] loss: 0.01119434322216165
[Epoch 14, Batch 2500] loss: 0.018924888829135966
[Epoch 14, Batch 2600] loss: 0.0032020675393391682
[Epoch 14, Batch 2700] loss: 0.007806998272292489
[Epoch 14, Batch 2800] loss: 0.023923888761802913
[Epoch 14, Batch 2900] loss: 0.006412446899824502
[Epoch 14, Batch 3000] loss: 0.022387822873524765
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0713
Validation Accuracy: 0.9842
Overfitting: 0.0713
[Epoch 15, Batch 100] loss: 0.006770833152693711
[Epoch 15, Batch 200] loss: 0.0025123887413769806
[Epoch 15, Batch 300] loss: 0.005087303832644636
[Epoch 15, Batch 400] loss: 0.004920820926396913
[Epoch 15, Batch 500] loss: 0.010310770882570637
[Epoch 15, Batch 600] loss: 0.008899526916634955
[Epoch 15, Batch 700] loss: 0.004748055011647807
[Epoch 15, Batch 800] loss: 0.004824040636427753
[Epoch 15, Batch 900] loss: 0.007149135479512836
[Epoch 15, Batch 1000] loss: 0.003329495056952112
[Epoch 15, Batch 1100] loss: 0.0038458851156940453
[Epoch 15, Batch 1200] loss: 0.007726352002224246
[Epoch 15, Batch 1300] loss: 0.0033412380473009764
[Epoch 15, Batch 1400] loss: 0.002035165952036948
[Epoch 15, Batch 1500] loss: 0.0042605202947379435
[Epoch 15, Batch 1600] loss: 0.008491232978788262
[Epoch 15, Batch 1700] loss: 0.009069496634516411
[Epoch 15, Batch 1800] loss: 0.016680913877573856
[Epoch 15, Batch 1900] loss: 0.012902835102624976
[Epoch 15, Batch 2000] loss: 0.0058144605735094505
[Epoch 15, Batch 2100] loss: 0.0028865077201351143
[Epoch 15, Batch 2200] loss: 0.0062451607693208185
[Epoch 15, Batch 2300] loss: 0.011714801867739055
[Epoch 15, Batch 2400] loss: 0.012533271230774972
[Epoch 15, Batch 2500] loss: 0.013650609476276826
[Epoch 15, Batch 2600] loss: 0.04011175679498308
[Epoch 15, Batch 2700] loss: 0.009329954646123042
[Epoch 15, Batch 2800] loss: 0.00599916707779471
[Epoch 15, Batch 2900] loss: 0.006762365288894898
[Epoch 15, Batch 3000] loss: 0.01397312477557989
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0686
Validation Accuracy: 0.9842
Overfitting: 0.0686
[Epoch 16, Batch 100] loss: 0.0062676058315639695
[Epoch 16, Batch 200] loss: 0.008531745968120959
[Epoch 16, Batch 300] loss: 0.003916510761487118
[Epoch 16, Batch 400] loss: 0.0026633458629822825
[Epoch 16, Batch 500] loss: 0.0035503181957432517
[Epoch 16, Batch 600] loss: 0.012962191266751119
[Epoch 16, Batch 700] loss: 0.006099067549232871
[Epoch 16, Batch 800] loss: 0.010764724388515674
[Epoch 16, Batch 900] loss: 0.009400643871397846
[Epoch 16, Batch 1000] loss: 0.01523699963762283
[Epoch 16, Batch 1100] loss: 0.014868421796057305
[Epoch 16, Batch 1200] loss: 0.013923692795631411
[Epoch 16, Batch 1300] loss: 0.003904053854218894
[Epoch 16, Batch 1400] loss: 0.009801453760866252
[Epoch 16, Batch 1500] loss: 0.010696139069121386
[Epoch 16, Batch 1600] loss: 0.00508602429154251
[Epoch 16, Batch 1700] loss: 0.0066866503529496414
[Epoch 16, Batch 1800] loss: 0.0038971114382268723
[Epoch 16, Batch 1900] loss: 0.010261577583145538
[Epoch 16, Batch 2000] loss: 0.006871301680745318
[Epoch 16, Batch 2100] loss: 0.00599959805749819
[Epoch 16, Batch 2200] loss: 0.00512163547398302
[Epoch 16, Batch 2300] loss: 0.0074443332467630085
[Epoch 16, Batch 2400] loss: 0.0042425357640411224
[Epoch 16, Batch 2500] loss: 0.008511064798480562
[Epoch 16, Batch 2600] loss: 0.0024783625377470743
[Epoch 16, Batch 2700] loss: 0.0075468608055768984
[Epoch 16, Batch 2800] loss: 0.006959292736984537
[Epoch 16, Batch 2900] loss: 0.012481968614774814
[Epoch 16, Batch 3000] loss: 0.006948913352498352
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9885
Overfitting: 0.0554
[Epoch 17, Batch 100] loss: 0.006305413227328245
[Epoch 17, Batch 200] loss: 0.004751971299654656
[Epoch 17, Batch 300] loss: 0.003159162039554815
[Epoch 17, Batch 400] loss: 0.011105665766775701
[Epoch 17, Batch 500] loss: 0.006189652167782356
[Epoch 17, Batch 600] loss: 0.005509999464017597
[Epoch 17, Batch 700] loss: 0.0020552122425465313
[Epoch 17, Batch 800] loss: 0.004155864006316463
[Epoch 17, Batch 900] loss: 0.004949106290475243
[Epoch 17, Batch 1000] loss: 0.007400933241614425
[Epoch 17, Batch 1100] loss: 0.007119553246126032
[Epoch 17, Batch 1200] loss: 0.002757289332625987
[Epoch 17, Batch 1300] loss: 0.00625859102151793
[Epoch 17, Batch 1400] loss: 0.006476820307233595
[Epoch 17, Batch 1500] loss: 0.005248703056888218
[Epoch 17, Batch 1600] loss: 0.0014104635746948447
[Epoch 17, Batch 1700] loss: 0.012666000500048256
[Epoch 17, Batch 1800] loss: 0.00830363792622343
[Epoch 17, Batch 1900] loss: 0.004058145385315015
[Epoch 17, Batch 2000] loss: 0.0029624212029989395
[Epoch 17, Batch 2100] loss: 0.002359569203718905
[Epoch 17, Batch 2200] loss: 0.0026825407741979746
[Epoch 17, Batch 2300] loss: 0.004473438560421599
[Epoch 17, Batch 2400] loss: 0.005453142371162016
[Epoch 17, Batch 2500] loss: 0.0021865515584656237
[Epoch 17, Batch 2600] loss: 0.001486207720499948
[Epoch 17, Batch 2700] loss: 0.00796521548230313
[Epoch 17, Batch 2800] loss: 0.0044844899287636505
[Epoch 17, Batch 2900] loss: 0.0030432521246596877
[Epoch 17, Batch 3000] loss: 0.008357722449958232
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0588
Validation Accuracy: 0.9882
Overfitting: 0.0588
[Epoch 18, Batch 100] loss: 0.005547068929959944
[Epoch 18, Batch 200] loss: 0.009436499278241826
[Epoch 18, Batch 300] loss: 0.008533611743053466
[Epoch 18, Batch 400] loss: 0.004442928919843183
[Epoch 18, Batch 500] loss: 0.003933215556181011
[Epoch 18, Batch 600] loss: 0.006681772927409133
[Epoch 18, Batch 700] loss: 0.0025334423303058884
[Epoch 18, Batch 800] loss: 0.002279998566493866
[Epoch 18, Batch 900] loss: 0.0008212948009399179
[Epoch 18, Batch 1000] loss: 0.0014984937372835105
[Epoch 18, Batch 1100] loss: 0.002831983151421582
[Epoch 18, Batch 1200] loss: 0.003912544357448482
[Epoch 18, Batch 1300] loss: 0.0027864049284384153
[Epoch 18, Batch 1400] loss: 0.0050123663624603056
[Epoch 18, Batch 1500] loss: 0.0005609344193818266
[Epoch 18, Batch 1600] loss: 0.0015282485400106792
[Epoch 18, Batch 1700] loss: 0.008024144730774481
[Epoch 18, Batch 1800] loss: 0.014208522265320055
[Epoch 18, Batch 1900] loss: 0.003265202993175933
[Epoch 18, Batch 2000] loss: 0.0013860069149197152
[Epoch 18, Batch 2100] loss: 0.0024027569146426943
[Epoch 18, Batch 2200] loss: 0.0011250985312696526
[Epoch 18, Batch 2300] loss: 0.0007848014861310836
[Epoch 18, Batch 2400] loss: 0.005293291430322422
[Epoch 18, Batch 2500] loss: 0.0023006806897162414
[Epoch 18, Batch 2600] loss: 0.0014642795887428006
[Epoch 18, Batch 2700] loss: 0.006637361406867073
[Epoch 18, Batch 2800] loss: 0.007146878574300643
[Epoch 18, Batch 2900] loss: 0.005086893637207952
[Epoch 18, Batch 3000] loss: 0.009135151997220347
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0601
Validation Accuracy: 0.9878
Overfitting: 0.0601
[Epoch 19, Batch 100] loss: 0.0032591940399315433
[Epoch 19, Batch 200] loss: 0.002834221841398339
[Epoch 19, Batch 300] loss: 0.0005682491952099156
[Epoch 19, Batch 400] loss: 0.0015244574551894453
[Epoch 19, Batch 500] loss: 0.008769881633608777
[Epoch 19, Batch 600] loss: 0.0064170910444910235
[Epoch 19, Batch 700] loss: 0.0031488486733797895
[Epoch 19, Batch 800] loss: 0.0016527144708684994
[Epoch 19, Batch 900] loss: 0.0028390041898334138
[Epoch 19, Batch 1000] loss: 0.0014160781692722324
[Epoch 19, Batch 1100] loss: 0.000727972098944889
[Epoch 19, Batch 1200] loss: 0.005173058946997799
[Epoch 19, Batch 1300] loss: 0.00322324911362164
[Epoch 19, Batch 1400] loss: 0.0015042287375221885
[Epoch 19, Batch 1500] loss: 0.0014091534786653882
[Epoch 19, Batch 1600] loss: 0.0015548654337815293
[Epoch 19, Batch 1700] loss: 0.0019384766318204427
[Epoch 19, Batch 1800] loss: 0.0014035508557921795
[Epoch 19, Batch 1900] loss: 0.0009036304286760099
[Epoch 19, Batch 2000] loss: 0.0019140548074217634
[Epoch 19, Batch 2100] loss: 0.0032941441322519084
[Epoch 19, Batch 2200] loss: 0.006771780474487046
[Epoch 19, Batch 2300] loss: 0.004637857070386318
[Epoch 19, Batch 2400] loss: 0.007991533514064795
[Epoch 19, Batch 2500] loss: 0.009538881624758347
[Epoch 19, Batch 2600] loss: 0.0057568440914010565
[Epoch 19, Batch 2700] loss: 0.010414494708098547
[Epoch 19, Batch 2800] loss: 0.011663675349971507
[Epoch 19, Batch 2900] loss: 0.0038367694737556192
[Epoch 19, Batch 3000] loss: 0.004828082581932441
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9882
Overfitting: 0.0533
[Epoch 20, Batch 100] loss: 0.0017834501916784884
[Epoch 20, Batch 200] loss: 0.0011227939717383605
[Epoch 20, Batch 300] loss: 0.007219967474494275
[Epoch 20, Batch 400] loss: 0.00657782256112057
[Epoch 20, Batch 500] loss: 0.003220509271097498
[Epoch 20, Batch 600] loss: 0.0020362042928469748
[Epoch 20, Batch 700] loss: 0.0036133151911787566
[Epoch 20, Batch 800] loss: 0.004437060084736686
[Epoch 20, Batch 900] loss: 0.0033554954948844173
[Epoch 20, Batch 1000] loss: 0.007495395451666899
[Epoch 20, Batch 1100] loss: 0.007416863138784891
[Epoch 20, Batch 1200] loss: 0.005025518512491227
[Epoch 20, Batch 1300] loss: 0.002172161948341147
[Epoch 20, Batch 1400] loss: 0.004411306502839274
[Epoch 20, Batch 1500] loss: 0.0014669989116945104
[Epoch 20, Batch 1600] loss: 0.0022772665396701797
[Epoch 20, Batch 1700] loss: 0.016007209573115265
[Epoch 20, Batch 1800] loss: 0.009861380673854826
[Epoch 20, Batch 1900] loss: 0.005764821108177176
[Epoch 20, Batch 2000] loss: 0.013949519563551718
[Epoch 20, Batch 2100] loss: 0.007861326834956177
[Epoch 20, Batch 2200] loss: 0.004929060048011133
[Epoch 20, Batch 2300] loss: 0.00978372977360205
[Epoch 20, Batch 2400] loss: 0.014583100772301192
[Epoch 20, Batch 2500] loss: 0.01025750604878958
[Epoch 20, Batch 2600] loss: 0.01468609468715954
[Epoch 20, Batch 2700] loss: 0.007637696794242004
[Epoch 20, Batch 2800] loss: 0.00921104840531374
[Epoch 20, Batch 2900] loss: 0.002853624239951813
[Epoch 20, Batch 3000] loss: 0.006629469044498109
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0716
Validation Accuracy: 0.9849
Overfitting: 0.0716
[Epoch 21, Batch 100] loss: 0.014916459562052732
[Epoch 21, Batch 200] loss: 0.013860440291870368
[Epoch 21, Batch 300] loss: 0.004633660204870011
[Epoch 21, Batch 400] loss: 0.004617283931243281
[Epoch 21, Batch 500] loss: 0.00274024589469303
[Epoch 21, Batch 600] loss: 0.008620171069393017
[Epoch 21, Batch 700] loss: 0.002990011862690203
[Epoch 21, Batch 800] loss: 0.003922301305488603
[Epoch 21, Batch 900] loss: 0.006601776429862962
[Epoch 21, Batch 1000] loss: 0.00440156278425138
[Epoch 21, Batch 1100] loss: 0.0032420951080922578
[Epoch 21, Batch 1200] loss: 0.0031989762445388337
[Epoch 21, Batch 1300] loss: 0.004512409177537702
[Epoch 21, Batch 1400] loss: 0.0018656699277747445
[Epoch 21, Batch 1500] loss: 0.0021235728666445654
[Epoch 21, Batch 1600] loss: 0.0024262846231439595
[Epoch 21, Batch 1700] loss: 0.02134481022529371
[Epoch 21, Batch 1800] loss: 0.006842351640757087
[Epoch 21, Batch 1900] loss: 0.004615830287805096
[Epoch 21, Batch 2000] loss: 0.0030312478141149768
[Epoch 21, Batch 2100] loss: 0.009967648212645765
[Epoch 21, Batch 2200] loss: 0.007737466531684092
[Epoch 21, Batch 2300] loss: 0.012016417815410279
[Epoch 21, Batch 2400] loss: 0.003995336533398159
[Epoch 21, Batch 2500] loss: 0.005709736863645807
[Epoch 21, Batch 2600] loss: 0.0008087779309118215
[Epoch 21, Batch 2700] loss: 0.009868582286574484
[Epoch 21, Batch 2800] loss: 0.007348086146267363
[Epoch 21, Batch 2900] loss: 0.007096722030575489
[Epoch 21, Batch 3000] loss: 0.008232907119392223
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9868
Overfitting: 0.0632
[Epoch 22, Batch 100] loss: 0.0044452670684406795
[Epoch 22, Batch 200] loss: 0.0053210789453374385
[Epoch 22, Batch 300] loss: 0.002048796199277909
[Epoch 22, Batch 400] loss: 0.002102105064078472
[Epoch 22, Batch 500] loss: 0.0009647672696646125
[Epoch 22, Batch 600] loss: 0.0043187849929054774
[Epoch 22, Batch 700] loss: 0.006085398613319462
[Epoch 22, Batch 800] loss: 0.007734461881595536
[Epoch 22, Batch 900] loss: 0.004277616360429804
[Epoch 22, Batch 1000] loss: 0.00405067480020147
[Epoch 22, Batch 1100] loss: 0.006547877953842125
[Epoch 22, Batch 1200] loss: 0.0019262541442306258
[Epoch 22, Batch 1300] loss: 0.010000378666359904
[Epoch 22, Batch 1400] loss: 0.006624751037577817
[Epoch 22, Batch 1500] loss: 0.0033671338786182047
[Epoch 22, Batch 1600] loss: 0.009561629804801828
[Epoch 22, Batch 1700] loss: 0.007959622848303524
[Epoch 22, Batch 1800] loss: 0.006576444117514022
[Epoch 22, Batch 1900] loss: 0.005689470957706524
[Epoch 22, Batch 2000] loss: 0.004344339228040255
[Epoch 22, Batch 2100] loss: 0.0070181004217027
[Epoch 22, Batch 2200] loss: 0.002213241218805706
[Epoch 22, Batch 2300] loss: 0.0046363486460197475
[Epoch 22, Batch 2400] loss: 0.009043100457935082
[Epoch 22, Batch 2500] loss: 0.01175058141121049
[Epoch 22, Batch 2600] loss: 0.006738790039296774
[Epoch 22, Batch 2700] loss: 0.013147477951476744
[Epoch 22, Batch 2800] loss: 0.007762332427871712
[Epoch 22, Batch 2900] loss: 0.01109998804610825
[Epoch 22, Batch 3000] loss: 0.001967401163245679
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0682
Validation Accuracy: 0.9873
Overfitting: 0.0682
[Epoch 23, Batch 100] loss: 0.0019125226777700988
[Epoch 23, Batch 200] loss: 0.009048125209653363
[Epoch 23, Batch 300] loss: 0.0028220962734323506
[Epoch 23, Batch 400] loss: 0.004845432264457799
[Epoch 23, Batch 500] loss: 0.0046937058193390335
[Epoch 23, Batch 600] loss: 0.0011985799774896443
[Epoch 23, Batch 700] loss: 0.004065710613423672
[Epoch 23, Batch 800] loss: 0.0019955054571308304
[Epoch 23, Batch 900] loss: 0.001614537589869003
[Epoch 23, Batch 1000] loss: 0.005759992681740567
[Epoch 23, Batch 1100] loss: 0.01174998225011894
[Epoch 23, Batch 1200] loss: 0.0180856492052762
[Epoch 23, Batch 1300] loss: 0.009311668729188826
[Epoch 23, Batch 1400] loss: 0.0031597507438072725
[Epoch 23, Batch 1500] loss: 0.0036404562885390666
[Epoch 23, Batch 1600] loss: 0.012410690045823927
[Epoch 23, Batch 1700] loss: 0.00726651595998399
[Epoch 23, Batch 1800] loss: 0.0019553748708248976
[Epoch 23, Batch 1900] loss: 0.009730084778785493
[Epoch 23, Batch 2000] loss: 0.004211252518796691
[Epoch 23, Batch 2100] loss: 0.004117956963349312
[Epoch 23, Batch 2200] loss: 0.006249410886165508
[Epoch 23, Batch 2300] loss: 0.0029125467493229308
[Epoch 23, Batch 2400] loss: 0.0029536804735619524
[Epoch 23, Batch 2500] loss: 0.0023641102785128074
[Epoch 23, Batch 2600] loss: 0.0014378543757884899
[Epoch 23, Batch 2700] loss: 0.0022030033770688772
[Epoch 23, Batch 2800] loss: 0.013581598362340835
[Epoch 23, Batch 2900] loss: 0.0039162987579340535
[Epoch 23, Batch 3000] loss: 0.003626139856567079
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0657
Validation Accuracy: 0.9874
Overfitting: 0.0657
[Epoch 24, Batch 100] loss: 0.007196285231490723
[Epoch 24, Batch 200] loss: 0.0032706142756121536
[Epoch 24, Batch 300] loss: 0.01456938169797798
[Epoch 24, Batch 400] loss: 0.002594720712459875
[Epoch 24, Batch 500] loss: 0.008465017668793812
[Epoch 24, Batch 600] loss: 0.0010422740982962342
[Epoch 24, Batch 700] loss: 0.002368134012025873
[Epoch 24, Batch 800] loss: 0.0021146502200643626
[Epoch 24, Batch 900] loss: 0.0024076541136938447
[Epoch 24, Batch 1000] loss: 0.003991957411648892
[Epoch 24, Batch 1100] loss: 0.0015346976605520712
[Epoch 24, Batch 1200] loss: 0.014083949512333951
[Epoch 24, Batch 1300] loss: 0.0046059074930117384
[Epoch 24, Batch 1400] loss: 0.0037059892792919726
[Epoch 24, Batch 1500] loss: 0.0018567440718786443
[Epoch 24, Batch 1600] loss: 0.003189308174584804
[Epoch 24, Batch 1700] loss: 0.015063434321341442
[Epoch 24, Batch 1800] loss: 0.00884143101171622
[Epoch 24, Batch 1900] loss: 0.01132941112554576
[Epoch 24, Batch 2000] loss: 0.006090397118799888
[Epoch 24, Batch 2100] loss: 0.0010765282679758936
[Epoch 24, Batch 2200] loss: 0.006674281307769236
[Epoch 24, Batch 2300] loss: 0.013276265600559748
[Epoch 24, Batch 2400] loss: 0.011285212851774987
[Epoch 24, Batch 2500] loss: 0.011394054058793656
[Epoch 24, Batch 2600] loss: 0.0015448909371219345
[Epoch 24, Batch 2700] loss: 0.007668371589974168
[Epoch 24, Batch 2800] loss: 0.005266227565817872
[Epoch 24, Batch 2900] loss: 0.005477024898255998
[Epoch 24, Batch 3000] loss: 0.00482021590475767
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0771
Validation Accuracy: 0.9856
Overfitting: 0.0771
Fold 3 validation loss: 0.0771
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.296807577610016
[Epoch 1, Batch 200] loss: 2.190083280801773
[Epoch 1, Batch 300] loss: 1.1306234818696976
[Epoch 1, Batch 400] loss: 0.5949130301922559
[Epoch 1, Batch 500] loss: 0.4318536496534944
[Epoch 1, Batch 600] loss: 0.3649614930152893
[Epoch 1, Batch 700] loss: 0.2592141167074442
[Epoch 1, Batch 800] loss: 0.25946084707975386
[Epoch 1, Batch 900] loss: 0.2177805887721479
[Epoch 1, Batch 1000] loss: 0.23332497974857688
[Epoch 1, Batch 1100] loss: 0.20013815820682793
[Epoch 1, Batch 1200] loss: 0.16187363347038627
[Epoch 1, Batch 1300] loss: 0.1441233788547106
[Epoch 1, Batch 1400] loss: 0.14286697819363325
[Epoch 1, Batch 1500] loss: 0.11571510351030156
[Epoch 1, Batch 1600] loss: 0.12015310841496102
[Epoch 1, Batch 1700] loss: 0.15534829180687665
[Epoch 1, Batch 1800] loss: 0.13625047356355935
[Epoch 1, Batch 1900] loss: 0.14446708776522427
[Epoch 1, Batch 2000] loss: 0.11490695204585791
[Epoch 1, Batch 2100] loss: 0.12248760655173101
[Epoch 1, Batch 2200] loss: 0.12094022715464234
[Epoch 1, Batch 2300] loss: 0.13087316791759804
[Epoch 1, Batch 2400] loss: 0.12814325389219447
[Epoch 1, Batch 2500] loss: 0.11488149282289668
[Epoch 1, Batch 2600] loss: 0.0867557274363935
[Epoch 1, Batch 2700] loss: 0.08620183604070916
[Epoch 1, Batch 2800] loss: 0.09521947804605588
[Epoch 1, Batch 2900] loss: 0.10577743079978973
[Epoch 1, Batch 3000] loss: 0.07988190232310444
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0892
Validation Accuracy: 0.9715
Overfitting: 0.0892
Best model saved at epoch 1 with validation loss: 0.0892
[Epoch 2, Batch 100] loss: 0.0879520037653856
[Epoch 2, Batch 200] loss: 0.0777107470826013
[Epoch 2, Batch 300] loss: 0.08760400757368188
[Epoch 2, Batch 400] loss: 0.08601143183885142
[Epoch 2, Batch 500] loss: 0.07517750126542523
[Epoch 2, Batch 600] loss: 0.08128284777980298
[Epoch 2, Batch 700] loss: 0.06554951723839622
[Epoch 2, Batch 800] loss: 0.07740680596674793
[Epoch 2, Batch 900] loss: 0.07426729155238718
[Epoch 2, Batch 1000] loss: 0.08177687572664581
[Epoch 2, Batch 1100] loss: 0.06937376445974223
[Epoch 2, Batch 1200] loss: 0.09354685970582068
[Epoch 2, Batch 1300] loss: 0.060797496935410894
[Epoch 2, Batch 1400] loss: 0.07053066998545546
[Epoch 2, Batch 1500] loss: 0.06303686053608544
[Epoch 2, Batch 1600] loss: 0.07375266673974692
[Epoch 2, Batch 1700] loss: 0.08144738238537684
[Epoch 2, Batch 1800] loss: 0.06870673436671496
[Epoch 2, Batch 1900] loss: 0.08829245115164668
[Epoch 2, Batch 2000] loss: 0.07037825565959793
[Epoch 2, Batch 2100] loss: 0.08104114781250246
[Epoch 2, Batch 2200] loss: 0.06433535768534057
[Epoch 2, Batch 2300] loss: 0.06569470111920964
[Epoch 2, Batch 2400] loss: 0.05630951951141469
[Epoch 2, Batch 2500] loss: 0.07086430460069096
[Epoch 2, Batch 2600] loss: 0.07417385852197185
[Epoch 2, Batch 2700] loss: 0.05839758336398518
[Epoch 2, Batch 2800] loss: 0.056178727588267065
[Epoch 2, Batch 2900] loss: 0.06291158980049659
[Epoch 2, Batch 3000] loss: 0.06480520930665079
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0622
Validation Accuracy: 0.9804
Overfitting: 0.0622
Best model saved at epoch 2 with validation loss: 0.0622
[Epoch 3, Batch 100] loss: 0.08029049328062683
[Epoch 3, Batch 200] loss: 0.050814151973463596
[Epoch 3, Batch 300] loss: 0.04548271124571329
[Epoch 3, Batch 400] loss: 0.07245949390053283
[Epoch 3, Batch 500] loss: 0.06798783757723868
[Epoch 3, Batch 600] loss: 0.04001526694220956
[Epoch 3, Batch 700] loss: 0.046840114475926384
[Epoch 3, Batch 800] loss: 0.05339745851757471
[Epoch 3, Batch 900] loss: 0.045564493903657424
[Epoch 3, Batch 1000] loss: 0.06403367714898195
[Epoch 3, Batch 1100] loss: 0.03890321411687182
[Epoch 3, Batch 1200] loss: 0.04068291508272523
[Epoch 3, Batch 1300] loss: 0.06101344125869218
[Epoch 3, Batch 1400] loss: 0.0387205124303
[Epoch 3, Batch 1500] loss: 0.0594528865328175
[Epoch 3, Batch 1600] loss: 0.0470829350411077
[Epoch 3, Batch 1700] loss: 0.04957744905434083
[Epoch 3, Batch 1800] loss: 0.04950914212866337
[Epoch 3, Batch 1900] loss: 0.03752062254352495
[Epoch 3, Batch 2000] loss: 0.060393862441706005
[Epoch 3, Batch 2100] loss: 0.07350279311300255
[Epoch 3, Batch 2200] loss: 0.061052156404766716
[Epoch 3, Batch 2300] loss: 0.07224459525663406
[Epoch 3, Batch 2400] loss: 0.046156067947013074
[Epoch 3, Batch 2500] loss: 0.04849974315118743
[Epoch 3, Batch 2600] loss: 0.06425096427206882
[Epoch 3, Batch 2700] loss: 0.05754843260801863
[Epoch 3, Batch 2800] loss: 0.04338182961510029
[Epoch 3, Batch 2900] loss: 0.03828786686208332
[Epoch 3, Batch 3000] loss: 0.04105474021853297
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9852
Overfitting: 0.0489
Best model saved at epoch 3 with validation loss: 0.0489
[Epoch 4, Batch 100] loss: 0.04394277049752418
[Epoch 4, Batch 200] loss: 0.04397434937760408
[Epoch 4, Batch 300] loss: 0.0401274866584572
[Epoch 4, Batch 400] loss: 0.04447169032340753
[Epoch 4, Batch 500] loss: 0.036469183932058516
[Epoch 4, Batch 600] loss: 0.040812947341473775
[Epoch 4, Batch 700] loss: 0.050291496867430396
[Epoch 4, Batch 800] loss: 0.04828812093757733
[Epoch 4, Batch 900] loss: 0.035822374312847384
[Epoch 4, Batch 1000] loss: 0.024915918293845606
[Epoch 4, Batch 1100] loss: 0.03623309574904852
[Epoch 4, Batch 1200] loss: 0.032505470979085654
[Epoch 4, Batch 1300] loss: 0.03636276749733952
[Epoch 4, Batch 1400] loss: 0.04332977762176597
[Epoch 4, Batch 1500] loss: 0.049409728587634164
[Epoch 4, Batch 1600] loss: 0.055188154645438775
[Epoch 4, Batch 1700] loss: 0.04628608486498706
[Epoch 4, Batch 1800] loss: 0.04442612957878737
[Epoch 4, Batch 1900] loss: 0.03696892072606715
[Epoch 4, Batch 2000] loss: 0.0310018394261715
[Epoch 4, Batch 2100] loss: 0.0383091947343928
[Epoch 4, Batch 2200] loss: 0.05038962404069025
[Epoch 4, Batch 2300] loss: 0.04639225632461603
[Epoch 4, Batch 2400] loss: 0.040743009671568874
[Epoch 4, Batch 2500] loss: 0.04257440625064191
[Epoch 4, Batch 2600] loss: 0.05753817218734184
[Epoch 4, Batch 2700] loss: 0.026566577620178576
[Epoch 4, Batch 2800] loss: 0.03553819958870008
[Epoch 4, Batch 2900] loss: 0.04469131975463824
[Epoch 4, Batch 3000] loss: 0.024537733958422906
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9839
Overfitting: 0.0509
[Epoch 5, Batch 100] loss: 0.030214610562143206
[Epoch 5, Batch 200] loss: 0.03744709702834371
[Epoch 5, Batch 300] loss: 0.033796253049222284
[Epoch 5, Batch 400] loss: 0.017955806748359462
[Epoch 5, Batch 500] loss: 0.04120633653095865
[Epoch 5, Batch 600] loss: 0.03358249644978059
[Epoch 5, Batch 700] loss: 0.03569325154188846
[Epoch 5, Batch 800] loss: 0.03407287476620695
[Epoch 5, Batch 900] loss: 0.027278219677464223
[Epoch 5, Batch 1000] loss: 0.03085682273747807
[Epoch 5, Batch 1100] loss: 0.03336427709204145
[Epoch 5, Batch 1200] loss: 0.02674408834078349
[Epoch 5, Batch 1300] loss: 0.027942892585051594
[Epoch 5, Batch 1400] loss: 0.034732983483481805
[Epoch 5, Batch 1500] loss: 0.03576210609491682
[Epoch 5, Batch 1600] loss: 0.030212986998449196
[Epoch 5, Batch 1700] loss: 0.03137579329013533
[Epoch 5, Batch 1800] loss: 0.028184950424401903
[Epoch 5, Batch 1900] loss: 0.04369591363582003
[Epoch 5, Batch 2000] loss: 0.03467303615627316
[Epoch 5, Batch 2100] loss: 0.027939715107931987
[Epoch 5, Batch 2200] loss: 0.034520286124534325
[Epoch 5, Batch 2300] loss: 0.06366248449208797
[Epoch 5, Batch 2400] loss: 0.026926530056662158
[Epoch 5, Batch 2500] loss: 0.030941160222027975
[Epoch 5, Batch 2600] loss: 0.038969543243001684
[Epoch 5, Batch 2700] loss: 0.030250057406374254
[Epoch 5, Batch 2800] loss: 0.04424367649386113
[Epoch 5, Batch 2900] loss: 0.051824369823516465
[Epoch 5, Batch 3000] loss: 0.04476327860538731
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9864
Overfitting: 0.0457
Best model saved at epoch 5 with validation loss: 0.0457
[Epoch 6, Batch 100] loss: 0.03128838303106022
[Epoch 6, Batch 200] loss: 0.024134341369572213
[Epoch 6, Batch 300] loss: 0.018815088263982035
[Epoch 6, Batch 400] loss: 0.03690578863968767
[Epoch 6, Batch 500] loss: 0.02088106151088141
[Epoch 6, Batch 600] loss: 0.03774790402661893
[Epoch 6, Batch 700] loss: 0.01512830190549721
[Epoch 6, Batch 800] loss: 0.027086125551359145
[Epoch 6, Batch 900] loss: 0.019706538255122724
[Epoch 6, Batch 1000] loss: 0.036138759424175076
[Epoch 6, Batch 1100] loss: 0.022644925850909204
[Epoch 6, Batch 1200] loss: 0.0241761255838901
[Epoch 6, Batch 1300] loss: 0.01825349749509769
[Epoch 6, Batch 1400] loss: 0.019235529539437267
[Epoch 6, Batch 1500] loss: 0.030642998366420215
[Epoch 6, Batch 1600] loss: 0.03977253875316819
[Epoch 6, Batch 1700] loss: 0.03367629945649241
[Epoch 6, Batch 1800] loss: 0.03892944311985048
[Epoch 6, Batch 1900] loss: 0.029410477430792524
[Epoch 6, Batch 2000] loss: 0.028723883763013873
[Epoch 6, Batch 2100] loss: 0.023526203224246273
[Epoch 6, Batch 2200] loss: 0.036612735262751814
[Epoch 6, Batch 2300] loss: 0.025886666864462313
[Epoch 6, Batch 2400] loss: 0.025784987143197213
[Epoch 6, Batch 2500] loss: 0.03796208233310608
[Epoch 6, Batch 2600] loss: 0.027566108174760302
[Epoch 6, Batch 2700] loss: 0.028942923447757493
[Epoch 6, Batch 2800] loss: 0.028186764032943755
[Epoch 6, Batch 2900] loss: 0.038289910430539746
[Epoch 6, Batch 3000] loss: 0.027626492136841988
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0444
Validation Accuracy: 0.9868
Overfitting: 0.0444
Best model saved at epoch 6 with validation loss: 0.0444
[Epoch 7, Batch 100] loss: 0.02566699683746265
[Epoch 7, Batch 200] loss: 0.023477158062123634
[Epoch 7, Batch 300] loss: 0.02041801177907473
[Epoch 7, Batch 400] loss: 0.016976414894998015
[Epoch 7, Batch 500] loss: 0.013655684561454108
[Epoch 7, Batch 600] loss: 0.018041120764319202
[Epoch 7, Batch 700] loss: 0.01337704703260897
[Epoch 7, Batch 800] loss: 0.029522354547298166
[Epoch 7, Batch 900] loss: 0.025412372995633634
[Epoch 7, Batch 1000] loss: 0.03253008674855664
[Epoch 7, Batch 1100] loss: 0.025892641851451115
[Epoch 7, Batch 1200] loss: 0.021130292578782246
[Epoch 7, Batch 1300] loss: 0.020065317410226272
[Epoch 7, Batch 1400] loss: 0.020597996572560076
[Epoch 7, Batch 1500] loss: 0.02550050841243319
[Epoch 7, Batch 1600] loss: 0.01740927457545695
[Epoch 7, Batch 1700] loss: 0.03081262624183182
[Epoch 7, Batch 1800] loss: 0.02139666746711555
[Epoch 7, Batch 1900] loss: 0.0329238976868055
[Epoch 7, Batch 2000] loss: 0.0261370341993279
[Epoch 7, Batch 2100] loss: 0.01618670764181843
[Epoch 7, Batch 2200] loss: 0.022109972507450948
[Epoch 7, Batch 2300] loss: 0.02992610755290116
[Epoch 7, Batch 2400] loss: 0.04175891431168566
[Epoch 7, Batch 2500] loss: 0.03418751804514614
[Epoch 7, Batch 2600] loss: 0.01760006987458837
[Epoch 7, Batch 2700] loss: 0.028347904645852396
[Epoch 7, Batch 2800] loss: 0.019495039315770554
[Epoch 7, Batch 2900] loss: 0.02375008375860489
[Epoch 7, Batch 3000] loss: 0.02763290842533024
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0410
Validation Accuracy: 0.9882
Overfitting: 0.0410
Best model saved at epoch 7 with validation loss: 0.0410
[Epoch 8, Batch 100] loss: 0.02424375543891074
[Epoch 8, Batch 200] loss: 0.014244835927815985
[Epoch 8, Batch 300] loss: 0.01687528700411349
[Epoch 8, Batch 400] loss: 0.02374328776226321
[Epoch 8, Batch 500] loss: 0.02233901133775362
[Epoch 8, Batch 600] loss: 0.019439206716442642
[Epoch 8, Batch 700] loss: 0.015913897123255083
[Epoch 8, Batch 800] loss: 0.01655558344792553
[Epoch 8, Batch 900] loss: 0.013835637076426792
[Epoch 8, Batch 1000] loss: 0.01929446743995868
[Epoch 8, Batch 1100] loss: 0.010693572711788875
[Epoch 8, Batch 1200] loss: 0.019194040411084645
[Epoch 8, Batch 1300] loss: 0.01675468354057102
[Epoch 8, Batch 1400] loss: 0.021757470878505956
[Epoch 8, Batch 1500] loss: 0.02103966785562079
[Epoch 8, Batch 1600] loss: 0.020301353672748518
[Epoch 8, Batch 1700] loss: 0.020567845877849322
[Epoch 8, Batch 1800] loss: 0.03505190223677346
[Epoch 8, Batch 1900] loss: 0.03158448522222898
[Epoch 8, Batch 2000] loss: 0.013089975978655275
[Epoch 8, Batch 2100] loss: 0.021106569829571528
[Epoch 8, Batch 2200] loss: 0.010727356607676484
[Epoch 8, Batch 2300] loss: 0.013272682090801027
[Epoch 8, Batch 2400] loss: 0.03044591239323836
[Epoch 8, Batch 2500] loss: 0.03339166808790651
[Epoch 8, Batch 2600] loss: 0.028034119558542445
[Epoch 8, Batch 2700] loss: 0.020674155108345076
[Epoch 8, Batch 2800] loss: 0.021177891845254634
[Epoch 8, Batch 2900] loss: 0.020572489349397073
[Epoch 8, Batch 3000] loss: 0.015787492414929147
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9835
Overfitting: 0.0507
[Epoch 9, Batch 100] loss: 0.008312436591659207
[Epoch 9, Batch 200] loss: 0.01028026090871208
[Epoch 9, Batch 300] loss: 0.02497226082259658
[Epoch 9, Batch 400] loss: 0.0166087490850623
[Epoch 9, Batch 500] loss: 0.008487493159373116
[Epoch 9, Batch 600] loss: 0.013700936056420688
[Epoch 9, Batch 700] loss: 0.014169622632243773
[Epoch 9, Batch 800] loss: 0.008760349031799706
[Epoch 9, Batch 900] loss: 0.014245924661445315
[Epoch 9, Batch 1000] loss: 0.016216055960960603
[Epoch 9, Batch 1100] loss: 0.017253137690358925
[Epoch 9, Batch 1200] loss: 0.016194635687852496
[Epoch 9, Batch 1300] loss: 0.018017673904655567
[Epoch 9, Batch 1400] loss: 0.008048959270765862
[Epoch 9, Batch 1500] loss: 0.01293722401348532
[Epoch 9, Batch 1600] loss: 0.013598172140781344
[Epoch 9, Batch 1700] loss: 0.014603354521241271
[Epoch 9, Batch 1800] loss: 0.037599318089633016
[Epoch 9, Batch 1900] loss: 0.012107632288702916
[Epoch 9, Batch 2000] loss: 0.026097622721608787
[Epoch 9, Batch 2100] loss: 0.018997369093922314
[Epoch 9, Batch 2200] loss: 0.016984757749505662
[Epoch 9, Batch 2300] loss: 0.015702325553909303
[Epoch 9, Batch 2400] loss: 0.027652027927688325
[Epoch 9, Batch 2500] loss: 0.018009865105141215
[Epoch 9, Batch 2600] loss: 0.025487106322798353
[Epoch 9, Batch 2700] loss: 0.01945345619571526
[Epoch 9, Batch 2800] loss: 0.033079954539098254
[Epoch 9, Batch 2900] loss: 0.010998830209705374
[Epoch 9, Batch 3000] loss: 0.03535191251585275
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0402
Validation Accuracy: 0.9880
Overfitting: 0.0402
Best model saved at epoch 9 with validation loss: 0.0402
[Epoch 10, Batch 100] loss: 0.010317463717283317
[Epoch 10, Batch 200] loss: 0.010950745387935968
[Epoch 10, Batch 300] loss: 0.006737959345914532
[Epoch 10, Batch 400] loss: 0.014475844981448063
[Epoch 10, Batch 500] loss: 0.01184596430426609
[Epoch 10, Batch 600] loss: 0.013564402189090288
[Epoch 10, Batch 700] loss: 0.017907662076893302
[Epoch 10, Batch 800] loss: 0.01913217064196033
[Epoch 10, Batch 900] loss: 0.021169995967329668
[Epoch 10, Batch 1000] loss: 0.0075878003414300114
[Epoch 10, Batch 1100] loss: 0.012211707188662331
[Epoch 10, Batch 1200] loss: 0.021540532563037687
[Epoch 10, Batch 1300] loss: 0.007939099778382116
[Epoch 10, Batch 1400] loss: 0.015236933525454788
[Epoch 10, Batch 1500] loss: 0.01856185870302852
[Epoch 10, Batch 1600] loss: 0.012646561423493949
[Epoch 10, Batch 1700] loss: 0.0159595253363932
[Epoch 10, Batch 1800] loss: 0.014703652816526755
[Epoch 10, Batch 1900] loss: 0.023538983190283035
[Epoch 10, Batch 2000] loss: 0.010689275103609362
[Epoch 10, Batch 2100] loss: 0.018794039406757293
[Epoch 10, Batch 2200] loss: 0.014832822459557065
[Epoch 10, Batch 2300] loss: 0.009501669933533775
[Epoch 10, Batch 2400] loss: 0.022358392342698607
[Epoch 10, Batch 2500] loss: 0.009112594847647416
[Epoch 10, Batch 2600] loss: 0.01349719286356958
[Epoch 10, Batch 2700] loss: 0.00828835832722234
[Epoch 10, Batch 2800] loss: 0.01912144596895814
[Epoch 10, Batch 2900] loss: 0.01819766759923368
[Epoch 10, Batch 3000] loss: 0.012340726126017216
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9878
Overfitting: 0.0452
[Epoch 11, Batch 100] loss: 0.005450266307802849
[Epoch 11, Batch 200] loss: 0.005444569178575875
[Epoch 11, Batch 300] loss: 0.011999305927984096
[Epoch 11, Batch 400] loss: 0.01725906729157032
[Epoch 11, Batch 500] loss: 0.012783532368525813
[Epoch 11, Batch 600] loss: 0.00971155062935395
[Epoch 11, Batch 700] loss: 0.010219841433986403
[Epoch 11, Batch 800] loss: 0.012547427725228317
[Epoch 11, Batch 900] loss: 0.010751874201978352
[Epoch 11, Batch 1000] loss: 0.004877645453261721
[Epoch 11, Batch 1100] loss: 0.009852895714784609
[Epoch 11, Batch 1200] loss: 0.012510444127749452
[Epoch 11, Batch 1300] loss: 0.028698930556761298
[Epoch 11, Batch 1400] loss: 0.014582964503333642
[Epoch 11, Batch 1500] loss: 0.00983995927417709
[Epoch 11, Batch 1600] loss: 0.012318995031760096
[Epoch 11, Batch 1700] loss: 0.012923484125615232
[Epoch 11, Batch 1800] loss: 0.009495245799889744
[Epoch 11, Batch 1900] loss: 0.008026810118609546
[Epoch 11, Batch 2000] loss: 0.010134808747786793
[Epoch 11, Batch 2100] loss: 0.022839048231962807
[Epoch 11, Batch 2200] loss: 0.009364335631667019
[Epoch 11, Batch 2300] loss: 0.008814432669776124
[Epoch 11, Batch 2400] loss: 0.020357125025261668
[Epoch 11, Batch 2500] loss: 0.017465870615853873
[Epoch 11, Batch 2600] loss: 0.028032379487117395
[Epoch 11, Batch 2700] loss: 0.006596357617193007
[Epoch 11, Batch 2800] loss: 0.02086738436176688
[Epoch 11, Batch 2900] loss: 0.011991194517390795
[Epoch 11, Batch 3000] loss: 0.012568337575821716
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9852
Overfitting: 0.0539
[Epoch 12, Batch 100] loss: 0.005130724320597437
[Epoch 12, Batch 200] loss: 0.005650569863013289
[Epoch 12, Batch 300] loss: 0.021725165141931485
[Epoch 12, Batch 400] loss: 0.0049726693123807305
[Epoch 12, Batch 500] loss: 0.0054595054043556955
[Epoch 12, Batch 600] loss: 0.006744375743689659
[Epoch 12, Batch 700] loss: 0.00597081211926934
[Epoch 12, Batch 800] loss: 0.004919191807883294
[Epoch 12, Batch 900] loss: 0.010150289770890027
[Epoch 12, Batch 1000] loss: 0.007906241201940247
[Epoch 12, Batch 1100] loss: 0.024240533061606583
[Epoch 12, Batch 1200] loss: 0.014610591948239745
[Epoch 12, Batch 1300] loss: 0.006955734694033708
[Epoch 12, Batch 1400] loss: 0.007853470616923914
[Epoch 12, Batch 1500] loss: 0.004713365422213655
[Epoch 12, Batch 1600] loss: 0.004557879085582499
[Epoch 12, Batch 1700] loss: 0.00553112949565957
[Epoch 12, Batch 1800] loss: 0.014705107517768283
[Epoch 12, Batch 1900] loss: 0.01380171782887885
[Epoch 12, Batch 2000] loss: 0.014569961406148196
[Epoch 12, Batch 2100] loss: 0.009832137482421217
[Epoch 12, Batch 2200] loss: 0.015064469005751561
[Epoch 12, Batch 2300] loss: 0.012100040349250775
[Epoch 12, Batch 2400] loss: 0.007564389126225706
[Epoch 12, Batch 2500] loss: 0.011961982668109385
[Epoch 12, Batch 2600] loss: 0.010026896588573208
[Epoch 12, Batch 2700] loss: 0.012593067952080901
[Epoch 12, Batch 2800] loss: 0.013181211109894094
[Epoch 12, Batch 2900] loss: 0.00841759619600225
[Epoch 12, Batch 3000] loss: 0.011161173199329823
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0448
Validation Accuracy: 0.9879
Overfitting: 0.0448
[Epoch 13, Batch 100] loss: 0.006550814067234114
[Epoch 13, Batch 200] loss: 0.007879491416836117
[Epoch 13, Batch 300] loss: 0.00835261034311941
[Epoch 13, Batch 400] loss: 0.009371790241060864
[Epoch 13, Batch 500] loss: 0.011284898672591623
[Epoch 13, Batch 600] loss: 0.011563294958071992
[Epoch 13, Batch 700] loss: 0.0052563357584915595
[Epoch 13, Batch 800] loss: 0.018290650370734057
[Epoch 13, Batch 900] loss: 0.013557379864937501
[Epoch 13, Batch 1000] loss: 0.005586774984247995
[Epoch 13, Batch 1100] loss: 0.013131561997260234
[Epoch 13, Batch 1200] loss: 0.011602370539592358
[Epoch 13, Batch 1300] loss: 0.004644713101149591
[Epoch 13, Batch 1400] loss: 0.016411947311382846
[Epoch 13, Batch 1500] loss: 0.0066873145765930534
[Epoch 13, Batch 1600] loss: 0.0062755943541606025
[Epoch 13, Batch 1700] loss: 0.007764824909709773
[Epoch 13, Batch 1800] loss: 0.009506066059902878
[Epoch 13, Batch 1900] loss: 0.014796205861317873
[Epoch 13, Batch 2000] loss: 0.006652388826069
[Epoch 13, Batch 2100] loss: 0.005421767435305469
[Epoch 13, Batch 2200] loss: 0.005222657530711956
[Epoch 13, Batch 2300] loss: 0.004652635563341505
[Epoch 13, Batch 2400] loss: 0.012447148984729779
[Epoch 13, Batch 2500] loss: 0.008683044851897819
[Epoch 13, Batch 2600] loss: 0.016393198873122402
[Epoch 13, Batch 2700] loss: 0.012878502194735688
[Epoch 13, Batch 2800] loss: 0.0197222122084554
[Epoch 13, Batch 2900] loss: 0.009582577084806872
[Epoch 13, Batch 3000] loss: 0.01186941922519054
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0442
Validation Accuracy: 0.9872
Overfitting: 0.0442
[Epoch 14, Batch 100] loss: 0.013001248521127308
[Epoch 14, Batch 200] loss: 0.004616376002732067
[Epoch 14, Batch 300] loss: 0.0043768072091617686
[Epoch 14, Batch 400] loss: 0.007264389069509605
[Epoch 14, Batch 500] loss: 0.00363572438786008
[Epoch 14, Batch 600] loss: 0.010862097530283563
[Epoch 14, Batch 700] loss: 0.005934996908815719
[Epoch 14, Batch 800] loss: 0.0029024978641780308
[Epoch 14, Batch 900] loss: 0.0025686945786225126
[Epoch 14, Batch 1000] loss: 0.006222426647129069
[Epoch 14, Batch 1100] loss: 0.005011252334170422
[Epoch 14, Batch 1200] loss: 0.014928124982724285
[Epoch 14, Batch 1300] loss: 0.008941703526264746
[Epoch 14, Batch 1400] loss: 0.017560186647776845
[Epoch 14, Batch 1500] loss: 0.005297762142890861
[Epoch 14, Batch 1600] loss: 0.0089091133058038
[Epoch 14, Batch 1700] loss: 0.0191682579646249
[Epoch 14, Batch 1800] loss: 0.011710289488723902
[Epoch 14, Batch 1900] loss: 0.009112170057392177
[Epoch 14, Batch 2000] loss: 0.005212070701779794
[Epoch 14, Batch 2100] loss: 0.00510991631192951
[Epoch 14, Batch 2200] loss: 0.010323968044295952
[Epoch 14, Batch 2300] loss: 0.004323862749632781
[Epoch 14, Batch 2400] loss: 0.013040889838115674
[Epoch 14, Batch 2500] loss: 0.012923453071337007
[Epoch 14, Batch 2600] loss: 0.006777215136277128
[Epoch 14, Batch 2700] loss: 0.0038222690669442727
[Epoch 14, Batch 2800] loss: 0.003593873748537817
[Epoch 14, Batch 2900] loss: 0.01295354437643482
[Epoch 14, Batch 3000] loss: 0.01046422209351249
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9882
Overfitting: 0.0516
[Epoch 15, Batch 100] loss: 0.007254693416400073
[Epoch 15, Batch 200] loss: 0.005861224859222318
[Epoch 15, Batch 300] loss: 0.007793022289569649
[Epoch 15, Batch 400] loss: 0.002447471080377852
[Epoch 15, Batch 500] loss: 0.0031990275786114354
[Epoch 15, Batch 600] loss: 0.003376733622571777
[Epoch 15, Batch 700] loss: 0.004771010877447566
[Epoch 15, Batch 800] loss: 0.0033262068585315774
[Epoch 15, Batch 900] loss: 0.00356824530904305
[Epoch 15, Batch 1000] loss: 0.01378977745322331
[Epoch 15, Batch 1100] loss: 0.011399173397844607
[Epoch 15, Batch 1200] loss: 0.004561721460818262
[Epoch 15, Batch 1300] loss: 0.004337711640575889
[Epoch 15, Batch 1400] loss: 0.007379502167526084
[Epoch 15, Batch 1500] loss: 0.005584813692608535
[Epoch 15, Batch 1600] loss: 0.0031700463574588864
[Epoch 15, Batch 1700] loss: 0.008090161304336476
[Epoch 15, Batch 1800] loss: 0.004338259289567077
[Epoch 15, Batch 1900] loss: 0.0087711432679545
[Epoch 15, Batch 2000] loss: 0.005127699883971957
[Epoch 15, Batch 2100] loss: 0.007732103099746155
[Epoch 15, Batch 2200] loss: 0.0016394679083678908
[Epoch 15, Batch 2300] loss: 0.009315442252494534
[Epoch 15, Batch 2400] loss: 0.010413996611217726
[Epoch 15, Batch 2500] loss: 0.015576112732406671
[Epoch 15, Batch 2600] loss: 0.005494038142073805
[Epoch 15, Batch 2700] loss: 0.007873597263697433
[Epoch 15, Batch 2800] loss: 0.023631933565638263
[Epoch 15, Batch 2900] loss: 0.016802503294879898
[Epoch 15, Batch 3000] loss: 0.004443392853180797
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9895
Overfitting: 0.0492
[Epoch 16, Batch 100] loss: 0.006293023311511661
[Epoch 16, Batch 200] loss: 0.0020340335447355073
[Epoch 16, Batch 300] loss: 0.0010129948926012845
[Epoch 16, Batch 400] loss: 0.0006753797949555462
[Epoch 16, Batch 500] loss: 0.002998497452286699
[Epoch 16, Batch 600] loss: 0.0011174793240070358
[Epoch 16, Batch 700] loss: 0.004126663958734014
[Epoch 16, Batch 800] loss: 0.003042049998904197
[Epoch 16, Batch 900] loss: 0.006345205064671404
[Epoch 16, Batch 1000] loss: 0.006408143301357469
[Epoch 16, Batch 1100] loss: 0.00260654976028718
[Epoch 16, Batch 1200] loss: 0.011186410938970432
[Epoch 16, Batch 1300] loss: 0.006829326073633695
[Epoch 16, Batch 1400] loss: 0.004547011607288595
[Epoch 16, Batch 1500] loss: 0.005439819144631244
[Epoch 16, Batch 1600] loss: 0.002653587493370253
[Epoch 16, Batch 1700] loss: 0.007833979309523328
[Epoch 16, Batch 1800] loss: 0.0055535817511828435
[Epoch 16, Batch 1900] loss: 0.008616743741572463
[Epoch 16, Batch 2000] loss: 0.006993581375343183
[Epoch 16, Batch 2100] loss: 0.007778379745149806
[Epoch 16, Batch 2200] loss: 0.01882047014861918
[Epoch 16, Batch 2300] loss: 0.007712388061279398
[Epoch 16, Batch 2400] loss: 0.008991536544745032
[Epoch 16, Batch 2500] loss: 0.01809898563351112
[Epoch 16, Batch 2600] loss: 0.010535893896280868
[Epoch 16, Batch 2700] loss: 0.0062772184133709176
[Epoch 16, Batch 2800] loss: 0.015594933895480381
[Epoch 16, Batch 2900] loss: 0.012498455083131148
[Epoch 16, Batch 3000] loss: 0.007526439523463751
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0435
Validation Accuracy: 0.9878
Overfitting: 0.0435
[Epoch 17, Batch 100] loss: 0.01311366766655965
[Epoch 17, Batch 200] loss: 0.0037057122252272734
[Epoch 17, Batch 300] loss: 0.0031206635891202696
[Epoch 17, Batch 400] loss: 0.007001888191923627
[Epoch 17, Batch 500] loss: 0.005942032718387189
[Epoch 17, Batch 600] loss: 0.0033515351165303285
[Epoch 17, Batch 700] loss: 0.002693160638170582
[Epoch 17, Batch 800] loss: 0.006593321153903489
[Epoch 17, Batch 900] loss: 0.009078206076493416
[Epoch 17, Batch 1000] loss: 0.003108949005776367
[Epoch 17, Batch 1100] loss: 0.0049892947475569825
[Epoch 17, Batch 1200] loss: 0.006586717830725774
[Epoch 17, Batch 1300] loss: 0.0035260104842552665
[Epoch 17, Batch 1400] loss: 0.0016497467349125827
[Epoch 17, Batch 1500] loss: 0.009365532277734942
[Epoch 17, Batch 1600] loss: 0.00864634318336556
[Epoch 17, Batch 1700] loss: 0.007327539346865563
[Epoch 17, Batch 1800] loss: 0.01923964921505103
[Epoch 17, Batch 1900] loss: 0.005515922006076721
[Epoch 17, Batch 2000] loss: 0.007384558222059354
[Epoch 17, Batch 2100] loss: 0.012747225154904528
[Epoch 17, Batch 2200] loss: 0.013166743860679979
[Epoch 17, Batch 2300] loss: 0.016522201726664888
[Epoch 17, Batch 2400] loss: 0.009948822497156585
[Epoch 17, Batch 2500] loss: 0.005817359679279548
[Epoch 17, Batch 2600] loss: 0.002495974361071234
[Epoch 17, Batch 2700] loss: 0.012692441212302584
[Epoch 17, Batch 2800] loss: 0.0074789744164093005
[Epoch 17, Batch 2900] loss: 0.009189443484863204
[Epoch 17, Batch 3000] loss: 0.0022346689742732905
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0448
Validation Accuracy: 0.9893
Overfitting: 0.0448
[Epoch 18, Batch 100] loss: 0.0037954747963755155
[Epoch 18, Batch 200] loss: 0.003074875588587247
[Epoch 18, Batch 300] loss: 0.0013154130738666937
[Epoch 18, Batch 400] loss: 0.0015794236837132303
[Epoch 18, Batch 500] loss: 0.004355419904649267
[Epoch 18, Batch 600] loss: 0.0024625118092941813
[Epoch 18, Batch 700] loss: 0.005511394791972499
[Epoch 18, Batch 800] loss: 0.0021482068418200127
[Epoch 18, Batch 900] loss: 0.0023625494896587895
[Epoch 18, Batch 1000] loss: 0.0036831615801038707
[Epoch 18, Batch 1100] loss: 0.005032369364415956
[Epoch 18, Batch 1200] loss: 0.001370448447603394
[Epoch 18, Batch 1300] loss: 0.003577580164972289
[Epoch 18, Batch 1400] loss: 0.0008222729962024289
[Epoch 18, Batch 1500] loss: 0.0007465941230909578
[Epoch 18, Batch 1600] loss: 0.004259257648102448
[Epoch 18, Batch 1700] loss: 0.001356322943176451
[Epoch 18, Batch 1800] loss: 0.0008981505829854087
[Epoch 18, Batch 1900] loss: 0.005071613208930899
[Epoch 18, Batch 2000] loss: 0.002785668659584246
[Epoch 18, Batch 2100] loss: 0.004197879816761372
[Epoch 18, Batch 2200] loss: 0.0010227614164257616
[Epoch 18, Batch 2300] loss: 0.0010765162032250685
[Epoch 18, Batch 2400] loss: 0.0043766395600177786
[Epoch 18, Batch 2500] loss: 0.00727548154873574
[Epoch 18, Batch 2600] loss: 0.005567743645569152
[Epoch 18, Batch 2700] loss: 0.011643868304072243
[Epoch 18, Batch 2800] loss: 0.011125055823216243
[Epoch 18, Batch 2900] loss: 0.008137860656605654
[Epoch 18, Batch 3000] loss: 0.0022375086023617287
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9892
Overfitting: 0.0514
[Epoch 19, Batch 100] loss: 0.0030855827564725048
[Epoch 19, Batch 200] loss: 0.002020319852567738
[Epoch 19, Batch 300] loss: 0.0017728330451528152
[Epoch 19, Batch 400] loss: 0.0007142380418657268
[Epoch 19, Batch 500] loss: 0.0007971866976549258
[Epoch 19, Batch 600] loss: 0.0027627366531667264
[Epoch 19, Batch 700] loss: 0.0023645447175984556
[Epoch 19, Batch 800] loss: 0.003516711087795521
[Epoch 19, Batch 900] loss: 0.0012693958710982933
[Epoch 19, Batch 1000] loss: 0.0019584474070537894
[Epoch 19, Batch 1100] loss: 0.0028129226180415756
[Epoch 19, Batch 1200] loss: 0.0037058396542167314
[Epoch 19, Batch 1300] loss: 0.004935209828824316
[Epoch 19, Batch 1400] loss: 0.004948039790842742
[Epoch 19, Batch 1500] loss: 0.003918508582696205
[Epoch 19, Batch 1600] loss: 0.00618242288759987
[Epoch 19, Batch 1700] loss: 0.009089269691186175
[Epoch 19, Batch 1800] loss: 0.003852155374047719
[Epoch 19, Batch 1900] loss: 0.0019964459370099517
[Epoch 19, Batch 2000] loss: 0.002801175443705537
[Epoch 19, Batch 2100] loss: 0.005617083856755869
[Epoch 19, Batch 2200] loss: 0.008273424936809945
[Epoch 19, Batch 2300] loss: 0.003996050783841412
[Epoch 19, Batch 2400] loss: 0.00537098048767092
[Epoch 19, Batch 2500] loss: 0.004995893994396425
[Epoch 19, Batch 2600] loss: 0.0041815416964126936
[Epoch 19, Batch 2700] loss: 0.013229376757859512
[Epoch 19, Batch 2800] loss: 0.0049986208684278215
[Epoch 19, Batch 2900] loss: 0.005503361702923684
[Epoch 19, Batch 3000] loss: 0.002398675723033037
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9898
Overfitting: 0.0457
[Epoch 20, Batch 100] loss: 0.002226464149293985
[Epoch 20, Batch 200] loss: 0.005384469316366988
[Epoch 20, Batch 300] loss: 0.0070262636435872135
[Epoch 20, Batch 400] loss: 0.002794383389079158
[Epoch 20, Batch 500] loss: 0.0017097980542923707
[Epoch 20, Batch 600] loss: 0.00133230801846004
[Epoch 20, Batch 700] loss: 0.0015752456913407542
[Epoch 20, Batch 800] loss: 0.0024410124962847756
[Epoch 20, Batch 900] loss: 0.002700384036911743
[Epoch 20, Batch 1000] loss: 0.004913201178678008
[Epoch 20, Batch 1100] loss: 0.002282973895705176
[Epoch 20, Batch 1200] loss: 0.002344740521534874
[Epoch 20, Batch 1300] loss: 0.004153636311179154
[Epoch 20, Batch 1400] loss: 0.007074073110391908
[Epoch 20, Batch 1500] loss: 0.0007898979600276945
[Epoch 20, Batch 1600] loss: 0.0016291653593009236
[Epoch 20, Batch 1700] loss: 0.0035710528373865103
[Epoch 20, Batch 1800] loss: 0.0006795592349848035
[Epoch 20, Batch 1900] loss: 0.007434104531574111
[Epoch 20, Batch 2000] loss: 0.0025806284060179508
[Epoch 20, Batch 2100] loss: 0.0026711161814850916
[Epoch 20, Batch 2200] loss: 0.0013664087497741839
[Epoch 20, Batch 2300] loss: 0.008402612012135222
[Epoch 20, Batch 2400] loss: 0.017400134292806423
[Epoch 20, Batch 2500] loss: 0.0028124814410562847
[Epoch 20, Batch 2600] loss: 0.008948616154983853
[Epoch 20, Batch 2700] loss: 0.006645741701619556
[Epoch 20, Batch 2800] loss: 0.008226073612130663
[Epoch 20, Batch 2900] loss: 0.0036804264035103173
[Epoch 20, Batch 3000] loss: 0.010646119996697756
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9886
Overfitting: 0.0482
[Epoch 21, Batch 100] loss: 0.001249526329113415
[Epoch 21, Batch 200] loss: 0.002485529273923248
[Epoch 21, Batch 300] loss: 0.002082168441202512
[Epoch 21, Batch 400] loss: 0.0016507758752845624
[Epoch 21, Batch 500] loss: 0.0014959567627669656
[Epoch 21, Batch 600] loss: 0.0015094564965238532
[Epoch 21, Batch 700] loss: 0.0044354744465400844
[Epoch 21, Batch 800] loss: 0.0020511327576629235
[Epoch 21, Batch 900] loss: 0.0033697708547290616
[Epoch 21, Batch 1000] loss: 0.0031752409778875545
[Epoch 21, Batch 1100] loss: 0.004965610050048763
[Epoch 21, Batch 1200] loss: 0.0011191613737799244
[Epoch 21, Batch 1300] loss: 0.0036348071167213725
[Epoch 21, Batch 1400] loss: 0.002412983429604747
[Epoch 21, Batch 1500] loss: 0.0008788673990935214
[Epoch 21, Batch 1600] loss: 0.00158235646239433
[Epoch 21, Batch 1700] loss: 0.0013378403096215407
[Epoch 21, Batch 1800] loss: 0.0024498845327432005
[Epoch 21, Batch 1900] loss: 0.002830991733674657
[Epoch 21, Batch 2000] loss: 0.005609216683367322
[Epoch 21, Batch 2100] loss: 0.004177295296743608
[Epoch 21, Batch 2200] loss: 0.000898555539239183
[Epoch 21, Batch 2300] loss: 0.0009502468780349283
[Epoch 21, Batch 2400] loss: 0.0025942211424231764
[Epoch 21, Batch 2500] loss: 0.00048032917403118436
[Epoch 21, Batch 2600] loss: 0.001955821980810302
[Epoch 21, Batch 2700] loss: 0.001113044437930739
[Epoch 21, Batch 2800] loss: 0.0017137719709539034
[Epoch 21, Batch 2900] loss: 0.0018024955762988171
[Epoch 21, Batch 3000] loss: 0.004107931858588891
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0638
Validation Accuracy: 0.9877
Overfitting: 0.0638
[Epoch 22, Batch 100] loss: 0.0031208500721561627
[Epoch 22, Batch 200] loss: 0.0009352844925429871
[Epoch 22, Batch 300] loss: 0.0024259133776122965
[Epoch 22, Batch 400] loss: 0.006922230509908971
[Epoch 22, Batch 500] loss: 0.002500481964058063
[Epoch 22, Batch 600] loss: 0.0017317617198203195
[Epoch 22, Batch 700] loss: 0.005414248767088168
[Epoch 22, Batch 800] loss: 0.0027966997926877025
[Epoch 22, Batch 900] loss: 0.00210982519469006
[Epoch 22, Batch 1000] loss: 0.0019308804560379355
[Epoch 22, Batch 1100] loss: 0.0002896256594453517
[Epoch 22, Batch 1200] loss: 0.006825855922185138
[Epoch 22, Batch 1300] loss: 0.007010255071902307
[Epoch 22, Batch 1400] loss: 0.005636768479433556
[Epoch 22, Batch 1500] loss: 0.0017156939310650722
[Epoch 22, Batch 1600] loss: 0.004726517467862999
[Epoch 22, Batch 1700] loss: 0.0017799430894324076
[Epoch 22, Batch 1800] loss: 0.0030679449534487
[Epoch 22, Batch 1900] loss: 0.006998926522990394
[Epoch 22, Batch 2000] loss: 0.008424928849230984
[Epoch 22, Batch 2100] loss: 0.004320651986528006
[Epoch 22, Batch 2200] loss: 0.007819242332992716
[Epoch 22, Batch 2300] loss: 0.008318034468478697
[Epoch 22, Batch 2400] loss: 0.017006941629146562
[Epoch 22, Batch 2500] loss: 0.005298787562523444
[Epoch 22, Batch 2600] loss: 0.00440095538859321
[Epoch 22, Batch 2700] loss: 0.0017387101305394025
[Epoch 22, Batch 2800] loss: 0.006709906295735895
[Epoch 22, Batch 2900] loss: 0.011991665073232283
[Epoch 22, Batch 3000] loss: 0.004328406459849106
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0612
Validation Accuracy: 0.9882
Overfitting: 0.0612
[Epoch 23, Batch 100] loss: 0.003407122442347017
[Epoch 23, Batch 200] loss: 0.012275223194651054
[Epoch 23, Batch 300] loss: 0.0014994511376922048
[Epoch 23, Batch 400] loss: 0.0024718819446111606
[Epoch 23, Batch 500] loss: 0.001993365649885845
[Epoch 23, Batch 600] loss: 0.002158009890500767
[Epoch 23, Batch 700] loss: 0.0024184254929444293
[Epoch 23, Batch 800] loss: 0.00414357678803218
[Epoch 23, Batch 900] loss: 0.009044790910647152
[Epoch 23, Batch 1000] loss: 0.0010960954310057502
[Epoch 23, Batch 1100] loss: 0.012738651538110357
[Epoch 23, Batch 1200] loss: 0.0022970139075306406
[Epoch 23, Batch 1300] loss: 0.0008840889281408693
[Epoch 23, Batch 1400] loss: 0.0004917430187534455
[Epoch 23, Batch 1500] loss: 0.0009193862660135644
[Epoch 23, Batch 1600] loss: 0.0013291708229458932
[Epoch 23, Batch 1700] loss: 0.0013426877599898202
[Epoch 23, Batch 1800] loss: 0.0010273768010318118
[Epoch 23, Batch 1900] loss: 0.001418142441534389
[Epoch 23, Batch 2000] loss: 0.0009109517043063776
[Epoch 23, Batch 2100] loss: 0.0066870668856154935
[Epoch 23, Batch 2200] loss: 0.0065088782565490885
[Epoch 23, Batch 2300] loss: 0.00433712090747294
[Epoch 23, Batch 2400] loss: 0.014338140257674027
[Epoch 23, Batch 2500] loss: 0.006632586582646027
[Epoch 23, Batch 2600] loss: 0.011913740699295232
[Epoch 23, Batch 2700] loss: 0.010657220639150972
[Epoch 23, Batch 2800] loss: 0.002711548802010064
[Epoch 23, Batch 2900] loss: 0.007743458965067438
[Epoch 23, Batch 3000] loss: 0.009967985661907904
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9874
Overfitting: 0.0593
[Epoch 24, Batch 100] loss: 0.003547974878658513
[Epoch 24, Batch 200] loss: 0.001496913332405967
[Epoch 24, Batch 300] loss: 0.002268807306319327
[Epoch 24, Batch 400] loss: 0.0034892896558031293
[Epoch 24, Batch 500] loss: 0.0065334889322785725
[Epoch 24, Batch 600] loss: 0.01080511324088043
[Epoch 24, Batch 700] loss: 0.015484681052512333
[Epoch 24, Batch 800] loss: 0.01459899798166441
[Epoch 24, Batch 900] loss: 0.008615848941212327
[Epoch 24, Batch 1000] loss: 0.016280233264245058
[Epoch 24, Batch 1100] loss: 0.003922235899525503
[Epoch 24, Batch 1200] loss: 0.01496646822764653
[Epoch 24, Batch 1300] loss: 0.018748818114016217
[Epoch 24, Batch 1400] loss: 0.007320983619881289
[Epoch 24, Batch 1500] loss: 0.007242614576492517
[Epoch 24, Batch 1600] loss: 0.008532286607435147
[Epoch 24, Batch 1700] loss: 0.009679767383914921
[Epoch 24, Batch 1800] loss: 0.004183342783598363
[Epoch 24, Batch 1900] loss: 0.011532973837790053
[Epoch 24, Batch 2000] loss: 0.0076950577585893805
[Epoch 24, Batch 2100] loss: 0.006320586650485995
[Epoch 24, Batch 2200] loss: 0.01150054371925918
[Epoch 24, Batch 2300] loss: 0.004342295928570037
[Epoch 24, Batch 2400] loss: 0.024227681308000487
[Epoch 24, Batch 2500] loss: 0.02753584528325632
[Epoch 24, Batch 2600] loss: 0.008602831035208354
[Epoch 24, Batch 2700] loss: 0.0032340635586849942
[Epoch 24, Batch 2800] loss: 0.0030855693280387973
[Epoch 24, Batch 2900] loss: 0.006068044651170972
[Epoch 24, Batch 3000] loss: 0.006519880072206377
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0778
Validation Accuracy: 0.9858
Overfitting: 0.0778
Fold 4 validation loss: 0.0778
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2930503153800963
[Epoch 1, Batch 200] loss: 2.2172742605209352
[Epoch 1, Batch 300] loss: 1.3574700981378556
[Epoch 1, Batch 400] loss: 0.640933232307434
[Epoch 1, Batch 500] loss: 0.4420708452165127
[Epoch 1, Batch 600] loss: 0.35783937864005566
[Epoch 1, Batch 700] loss: 0.3125412575155497
[Epoch 1, Batch 800] loss: 0.2747445610538125
[Epoch 1, Batch 900] loss: 0.21077051104977726
[Epoch 1, Batch 1000] loss: 0.20709197640419005
[Epoch 1, Batch 1100] loss: 0.2054985705576837
[Epoch 1, Batch 1200] loss: 0.20449200049974026
[Epoch 1, Batch 1300] loss: 0.1579277970874682
[Epoch 1, Batch 1400] loss: 0.16723447910510003
[Epoch 1, Batch 1500] loss: 0.14739328539930285
[Epoch 1, Batch 1600] loss: 0.11788844216149301
[Epoch 1, Batch 1700] loss: 0.1616872850432992
[Epoch 1, Batch 1800] loss: 0.14468117939308286
[Epoch 1, Batch 1900] loss: 0.1428046901221387
[Epoch 1, Batch 2000] loss: 0.11008174099959434
[Epoch 1, Batch 2100] loss: 0.1140197180886753
[Epoch 1, Batch 2200] loss: 0.10711058922344818
[Epoch 1, Batch 2300] loss: 0.10098765715374611
[Epoch 1, Batch 2400] loss: 0.12603595231892542
[Epoch 1, Batch 2500] loss: 0.10228258600924164
[Epoch 1, Batch 2600] loss: 0.14053829765180126
[Epoch 1, Batch 2700] loss: 0.10919501812197269
[Epoch 1, Batch 2800] loss: 0.11495808383682743
[Epoch 1, Batch 2900] loss: 0.11425237470306455
[Epoch 1, Batch 3000] loss: 0.08944203449646011
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1287
Validation Accuracy: 0.9587
Overfitting: 0.1287
Best model saved at epoch 1 with validation loss: 0.1287
[Epoch 2, Batch 100] loss: 0.10092577486648224
[Epoch 2, Batch 200] loss: 0.130208690892905
[Epoch 2, Batch 300] loss: 0.07087195268832147
[Epoch 2, Batch 400] loss: 0.08347180170821958
[Epoch 2, Batch 500] loss: 0.0783222619019216
[Epoch 2, Batch 600] loss: 0.08746194792212919
[Epoch 2, Batch 700] loss: 0.09594275847775861
[Epoch 2, Batch 800] loss: 0.09032846146263182
[Epoch 2, Batch 900] loss: 0.048515861601335926
[Epoch 2, Batch 1000] loss: 0.085304345296463
[Epoch 2, Batch 1100] loss: 0.09068945941049605
[Epoch 2, Batch 1200] loss: 0.0822492011752911
[Epoch 2, Batch 1300] loss: 0.07511283287662081
[Epoch 2, Batch 1400] loss: 0.06886660054151435
[Epoch 2, Batch 1500] loss: 0.07734267860418186
[Epoch 2, Batch 1600] loss: 0.061936112213879825
[Epoch 2, Batch 1700] loss: 0.08860145475715399
[Epoch 2, Batch 1800] loss: 0.059315084122354166
[Epoch 2, Batch 1900] loss: 0.06477217780076899
[Epoch 2, Batch 2000] loss: 0.08428737927926705
[Epoch 2, Batch 2100] loss: 0.06402144582825713
[Epoch 2, Batch 2200] loss: 0.05617874695308274
[Epoch 2, Batch 2300] loss: 0.053127678217715586
[Epoch 2, Batch 2400] loss: 0.0768580351799028
[Epoch 2, Batch 2500] loss: 0.0700058958871523
[Epoch 2, Batch 2600] loss: 0.09455939821666107
[Epoch 2, Batch 2700] loss: 0.07276943485019728
[Epoch 2, Batch 2800] loss: 0.06563184398401063
[Epoch 2, Batch 2900] loss: 0.06731020837294636
[Epoch 2, Batch 3000] loss: 0.0664829734765226
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0753
Validation Accuracy: 0.9769
Overfitting: 0.0753
Best model saved at epoch 2 with validation loss: 0.0753
[Epoch 3, Batch 100] loss: 0.05592684200819349
[Epoch 3, Batch 200] loss: 0.057190473665250464
[Epoch 3, Batch 300] loss: 0.05276710763515439
[Epoch 3, Batch 400] loss: 0.061248250204953364
[Epoch 3, Batch 500] loss: 0.05399271118978504
[Epoch 3, Batch 600] loss: 0.07102025916043203
[Epoch 3, Batch 700] loss: 0.052419686905341226
[Epoch 3, Batch 800] loss: 0.05612551503523719
[Epoch 3, Batch 900] loss: 0.04426545681519201
[Epoch 3, Batch 1000] loss: 0.0488647446106188
[Epoch 3, Batch 1100] loss: 0.05310007824620697
[Epoch 3, Batch 1200] loss: 0.04129568217540509
[Epoch 3, Batch 1300] loss: 0.052007639367657246
[Epoch 3, Batch 1400] loss: 0.0605423963512294
[Epoch 3, Batch 1500] loss: 0.036033221621473786
[Epoch 3, Batch 1600] loss: 0.05782622563419863
[Epoch 3, Batch 1700] loss: 0.0660631973843556
[Epoch 3, Batch 1800] loss: 0.06028357155271806
[Epoch 3, Batch 1900] loss: 0.04963603958545718
[Epoch 3, Batch 2000] loss: 0.056408952198689806
[Epoch 3, Batch 2100] loss: 0.05740769424621248
[Epoch 3, Batch 2200] loss: 0.04479627408800298
[Epoch 3, Batch 2300] loss: 0.06045634909081855
[Epoch 3, Batch 2400] loss: 0.03712774859712226
[Epoch 3, Batch 2500] loss: 0.06945520457215025
[Epoch 3, Batch 2600] loss: 0.06716670992420404
[Epoch 3, Batch 2700] loss: 0.04532396804715973
[Epoch 3, Batch 2800] loss: 0.05779417667727103
[Epoch 3, Batch 2900] loss: 0.049787221071892415
[Epoch 3, Batch 3000] loss: 0.044708094282541425
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9832
Overfitting: 0.0564
Best model saved at epoch 3 with validation loss: 0.0564
[Epoch 4, Batch 100] loss: 0.0404899686598219
[Epoch 4, Batch 200] loss: 0.046602199964981994
[Epoch 4, Batch 300] loss: 0.032821293540037
[Epoch 4, Batch 400] loss: 0.04395941509385011
[Epoch 4, Batch 500] loss: 0.03888950220003608
[Epoch 4, Batch 600] loss: 0.04425163851759862
[Epoch 4, Batch 700] loss: 0.04192910414116341
[Epoch 4, Batch 800] loss: 0.042210613585994
[Epoch 4, Batch 900] loss: 0.03576496750560182
[Epoch 4, Batch 1000] loss: 0.04679192162628169
[Epoch 4, Batch 1100] loss: 0.05050729811177007
[Epoch 4, Batch 1200] loss: 0.03953156641495298
[Epoch 4, Batch 1300] loss: 0.04830379118327983
[Epoch 4, Batch 1400] loss: 0.05272034964873455
[Epoch 4, Batch 1500] loss: 0.04745771958259866
[Epoch 4, Batch 1600] loss: 0.046970409174537056
[Epoch 4, Batch 1700] loss: 0.04611924061799073
[Epoch 4, Batch 1800] loss: 0.034858242965419776
[Epoch 4, Batch 1900] loss: 0.05573265241728222
[Epoch 4, Batch 2000] loss: 0.04927323561016237
[Epoch 4, Batch 2100] loss: 0.04813885900075547
[Epoch 4, Batch 2200] loss: 0.03678036626733956
[Epoch 4, Batch 2300] loss: 0.04146486251920578
[Epoch 4, Batch 2400] loss: 0.030867622222431237
[Epoch 4, Batch 2500] loss: 0.04316453174513299
[Epoch 4, Batch 2600] loss: 0.03934312589408364
[Epoch 4, Batch 2700] loss: 0.04087201301910682
[Epoch 4, Batch 2800] loss: 0.0522730610621511
[Epoch 4, Batch 2900] loss: 0.04344060929113766
[Epoch 4, Batch 3000] loss: 0.038383162350510244
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9847
Overfitting: 0.0469
Best model saved at epoch 4 with validation loss: 0.0469
[Epoch 5, Batch 100] loss: 0.02717672720871633
[Epoch 5, Batch 200] loss: 0.036142793333128795
[Epoch 5, Batch 300] loss: 0.04009867651009699
[Epoch 5, Batch 400] loss: 0.02746313151095819
[Epoch 5, Batch 500] loss: 0.03691234762733075
[Epoch 5, Batch 600] loss: 0.03260078686929774
[Epoch 5, Batch 700] loss: 0.02365248573754798
[Epoch 5, Batch 800] loss: 0.039578530922735805
[Epoch 5, Batch 900] loss: 0.021920059535914332
[Epoch 5, Batch 1000] loss: 0.03551545026974054
[Epoch 5, Batch 1100] loss: 0.02906453446645173
[Epoch 5, Batch 1200] loss: 0.035581792008815685
[Epoch 5, Batch 1300] loss: 0.03398079125734512
[Epoch 5, Batch 1400] loss: 0.042311227699829035
[Epoch 5, Batch 1500] loss: 0.04263147732795915
[Epoch 5, Batch 1600] loss: 0.023414648325706368
[Epoch 5, Batch 1700] loss: 0.04328804530050547
[Epoch 5, Batch 1800] loss: 0.032398624746856515
[Epoch 5, Batch 1900] loss: 0.029450496665704123
[Epoch 5, Batch 2000] loss: 0.057547917382908056
[Epoch 5, Batch 2100] loss: 0.026423093795856403
[Epoch 5, Batch 2200] loss: 0.041054420028958705
[Epoch 5, Batch 2300] loss: 0.03714308766910108
[Epoch 5, Batch 2400] loss: 0.07630650356935803
[Epoch 5, Batch 2500] loss: 0.03444958206178853
[Epoch 5, Batch 2600] loss: 0.024850082413649943
[Epoch 5, Batch 2700] loss: 0.042864252878935076
[Epoch 5, Batch 2800] loss: 0.02271277417850797
[Epoch 5, Batch 2900] loss: 0.019886961895754212
[Epoch 5, Batch 3000] loss: 0.02883006878393644
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9857
Overfitting: 0.0512
[Epoch 6, Batch 100] loss: 0.0372914802089872
[Epoch 6, Batch 200] loss: 0.024102374029898784
[Epoch 6, Batch 300] loss: 0.021561121694976464
[Epoch 6, Batch 400] loss: 0.031370713047435855
[Epoch 6, Batch 500] loss: 0.022913351743154634
[Epoch 6, Batch 600] loss: 0.02095757959265029
[Epoch 6, Batch 700] loss: 0.040134682275383964
[Epoch 6, Batch 800] loss: 0.03686371333154966
[Epoch 6, Batch 900] loss: 0.020896909640759985
[Epoch 6, Batch 1000] loss: 0.0338276342498284
[Epoch 6, Batch 1100] loss: 0.02939765273258672
[Epoch 6, Batch 1200] loss: 0.04292307306663133
[Epoch 6, Batch 1300] loss: 0.03916470663272776
[Epoch 6, Batch 1400] loss: 0.019429270238106255
[Epoch 6, Batch 1500] loss: 0.0230248609015689
[Epoch 6, Batch 1600] loss: 0.03147172098804731
[Epoch 6, Batch 1700] loss: 0.024649803742286168
[Epoch 6, Batch 1800] loss: 0.02735059170081513
[Epoch 6, Batch 1900] loss: 0.02239291108751786
[Epoch 6, Batch 2000] loss: 0.037367531957352186
[Epoch 6, Batch 2100] loss: 0.026658440912233346
[Epoch 6, Batch 2200] loss: 0.028539133112644777
[Epoch 6, Batch 2300] loss: 0.03409987542509043
[Epoch 6, Batch 2400] loss: 0.017194673658377724
[Epoch 6, Batch 2500] loss: 0.035237253489904106
[Epoch 6, Batch 2600] loss: 0.01760022753438534
[Epoch 6, Batch 2700] loss: 0.021632890211658377
[Epoch 6, Batch 2800] loss: 0.029276307962063583
[Epoch 6, Batch 2900] loss: 0.037515288267222786
[Epoch 6, Batch 3000] loss: 0.027638807936455123
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9859
Overfitting: 0.0495
[Epoch 7, Batch 100] loss: 0.022617636271752416
[Epoch 7, Batch 200] loss: 0.011047523253437249
[Epoch 7, Batch 300] loss: 0.02746886095636455
[Epoch 7, Batch 400] loss: 0.01231659104823848
[Epoch 7, Batch 500] loss: 0.029685876991607074
[Epoch 7, Batch 600] loss: 0.0268840411500787
[Epoch 7, Batch 700] loss: 0.01851819125629845
[Epoch 7, Batch 800] loss: 0.028008598565775172
[Epoch 7, Batch 900] loss: 0.024720645629204226
[Epoch 7, Batch 1000] loss: 0.017121585802269693
[Epoch 7, Batch 1100] loss: 0.03539589834843355
[Epoch 7, Batch 1200] loss: 0.03047320648773166
[Epoch 7, Batch 1300] loss: 0.030060129062840134
[Epoch 7, Batch 1400] loss: 0.0191053641380131
[Epoch 7, Batch 1500] loss: 0.02393268506899403
[Epoch 7, Batch 1600] loss: 0.046786837241743345
[Epoch 7, Batch 1700] loss: 0.018010435369651533
[Epoch 7, Batch 1800] loss: 0.015734225005180635
[Epoch 7, Batch 1900] loss: 0.034850768033938946
[Epoch 7, Batch 2000] loss: 0.020276968084363033
[Epoch 7, Batch 2100] loss: 0.03253804136234976
[Epoch 7, Batch 2200] loss: 0.015879535693020443
[Epoch 7, Batch 2300] loss: 0.04008668597898577
[Epoch 7, Batch 2400] loss: 0.015453590525612525
[Epoch 7, Batch 2500] loss: 0.03357752095267642
[Epoch 7, Batch 2600] loss: 0.026228411408465036
[Epoch 7, Batch 2700] loss: 0.017452729229480612
[Epoch 7, Batch 2800] loss: 0.018389666023667813
[Epoch 7, Batch 2900] loss: 0.019600484957954904
[Epoch 7, Batch 3000] loss: 0.019958492797304644
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0429
Validation Accuracy: 0.9878
Overfitting: 0.0429
Best model saved at epoch 7 with validation loss: 0.0429
[Epoch 8, Batch 100] loss: 0.013738500952349568
[Epoch 8, Batch 200] loss: 0.015315967432861725
[Epoch 8, Batch 300] loss: 0.026763586495962954
[Epoch 8, Batch 400] loss: 0.032400416600758035
[Epoch 8, Batch 500] loss: 0.028903465001458243
[Epoch 8, Batch 600] loss: 0.018697489807746024
[Epoch 8, Batch 700] loss: 0.023826776755850005
[Epoch 8, Batch 800] loss: 0.028690565161195992
[Epoch 8, Batch 900] loss: 0.02831980208044115
[Epoch 8, Batch 1000] loss: 0.013529441734353895
[Epoch 8, Batch 1100] loss: 0.016222910560509264
[Epoch 8, Batch 1200] loss: 0.018488607897234034
[Epoch 8, Batch 1300] loss: 0.014357549878332066
[Epoch 8, Batch 1400] loss: 0.010811311290508456
[Epoch 8, Batch 1500] loss: 0.018169761101225958
[Epoch 8, Batch 1600] loss: 0.02266866814475179
[Epoch 8, Batch 1700] loss: 0.021874367019627243
[Epoch 8, Batch 1800] loss: 0.020900892631289025
[Epoch 8, Batch 1900] loss: 0.012922503097079242
[Epoch 8, Batch 2000] loss: 0.00811868111091826
[Epoch 8, Batch 2100] loss: 0.02442978267408762
[Epoch 8, Batch 2200] loss: 0.01978441555023892
[Epoch 8, Batch 2300] loss: 0.016030466096090094
[Epoch 8, Batch 2400] loss: 0.018408400451407944
[Epoch 8, Batch 2500] loss: 0.020582529793900902
[Epoch 8, Batch 2600] loss: 0.016095284316152175
[Epoch 8, Batch 2700] loss: 0.02576350477700544
[Epoch 8, Batch 2800] loss: 0.014728325740106811
[Epoch 8, Batch 2900] loss: 0.03367924117850635
[Epoch 8, Batch 3000] loss: 0.03342749863602876
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9858
Overfitting: 0.0479
[Epoch 9, Batch 100] loss: 0.009462413822548114
[Epoch 9, Batch 200] loss: 0.005515129746991079
[Epoch 9, Batch 300] loss: 0.022623444396836022
[Epoch 9, Batch 400] loss: 0.01811470779483443
[Epoch 9, Batch 500] loss: 0.015210538985265885
[Epoch 9, Batch 600] loss: 0.023879618520750226
[Epoch 9, Batch 700] loss: 0.013901562624851068
[Epoch 9, Batch 800] loss: 0.025958842279414966
[Epoch 9, Batch 900] loss: 0.012037508117136895
[Epoch 9, Batch 1000] loss: 0.013064541332828411
[Epoch 9, Batch 1100] loss: 0.009743283989701012
[Epoch 9, Batch 1200] loss: 0.031743046843093904
[Epoch 9, Batch 1300] loss: 0.015776146921889448
[Epoch 9, Batch 1400] loss: 0.0182710280720039
[Epoch 9, Batch 1500] loss: 0.01645227055545547
[Epoch 9, Batch 1600] loss: 0.026268139240187338
[Epoch 9, Batch 1700] loss: 0.01404910127095718
[Epoch 9, Batch 1800] loss: 0.0277538142999947
[Epoch 9, Batch 1900] loss: 0.020016536431103304
[Epoch 9, Batch 2000] loss: 0.013469853138340114
[Epoch 9, Batch 2100] loss: 0.0287269220824237
[Epoch 9, Batch 2200] loss: 0.01556521892960518
[Epoch 9, Batch 2300] loss: 0.02662635856881934
[Epoch 9, Batch 2400] loss: 0.017887399940282194
[Epoch 9, Batch 2500] loss: 0.005994980121267872
[Epoch 9, Batch 2600] loss: 0.012039651096129091
[Epoch 9, Batch 2700] loss: 0.020278849389897005
[Epoch 9, Batch 2800] loss: 0.020125828941836517
[Epoch 9, Batch 2900] loss: 0.017765822596684303
[Epoch 9, Batch 3000] loss: 0.016227828257747205
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9865
Overfitting: 0.0470
[Epoch 10, Batch 100] loss: 0.011006937716879293
[Epoch 10, Batch 200] loss: 0.014013502825100659
[Epoch 10, Batch 300] loss: 0.015186388042811813
[Epoch 10, Batch 400] loss: 0.011983990728931531
[Epoch 10, Batch 500] loss: 0.009383231807250923
[Epoch 10, Batch 600] loss: 0.015698748925660765
[Epoch 10, Batch 700] loss: 0.0194466115459727
[Epoch 10, Batch 800] loss: 0.020735964957502802
[Epoch 10, Batch 900] loss: 0.019181042366599284
[Epoch 10, Batch 1000] loss: 0.012133748290352742
[Epoch 10, Batch 1100] loss: 0.014755652538751747
[Epoch 10, Batch 1200] loss: 0.01451109147367788
[Epoch 10, Batch 1300] loss: 0.009544269340021855
[Epoch 10, Batch 1400] loss: 0.010453452295641909
[Epoch 10, Batch 1500] loss: 0.006815461277956274
[Epoch 10, Batch 1600] loss: 0.008722129784782737
[Epoch 10, Batch 1700] loss: 0.013674600994831962
[Epoch 10, Batch 1800] loss: 0.02160140685888109
[Epoch 10, Batch 1900] loss: 0.011014690598553898
[Epoch 10, Batch 2000] loss: 0.01638538132080839
[Epoch 10, Batch 2100] loss: 0.020823502233115507
[Epoch 10, Batch 2200] loss: 0.015164239253567757
[Epoch 10, Batch 2300] loss: 0.008431152325711082
[Epoch 10, Batch 2400] loss: 0.015236335988247448
[Epoch 10, Batch 2500] loss: 0.02037589860585058
[Epoch 10, Batch 2600] loss: 0.016947910369954116
[Epoch 10, Batch 2700] loss: 0.0163927166133908
[Epoch 10, Batch 2800] loss: 0.027164038968292063
[Epoch 10, Batch 2900] loss: 0.0167091104493511
[Epoch 10, Batch 3000] loss: 0.02334000938084955
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9872
Overfitting: 0.0484
[Epoch 11, Batch 100] loss: 0.010129089443371413
[Epoch 11, Batch 200] loss: 0.012590985881588494
[Epoch 11, Batch 300] loss: 0.007218682717980301
[Epoch 11, Batch 400] loss: 0.010329354228097144
[Epoch 11, Batch 500] loss: 0.009486606530585959
[Epoch 11, Batch 600] loss: 0.006938463526548731
[Epoch 11, Batch 700] loss: 0.009335423184572846
[Epoch 11, Batch 800] loss: 0.015342322681754013
[Epoch 11, Batch 900] loss: 0.009473357821261743
[Epoch 11, Batch 1000] loss: 0.011500219425865908
[Epoch 11, Batch 1100] loss: 0.013356168115683431
[Epoch 11, Batch 1200] loss: 0.014652765994610491
[Epoch 11, Batch 1300] loss: 0.009238349969309638
[Epoch 11, Batch 1400] loss: 0.009750610084985283
[Epoch 11, Batch 1500] loss: 0.016430035488908458
[Epoch 11, Batch 1600] loss: 0.018854703133345082
[Epoch 11, Batch 1700] loss: 0.020374684543389775
[Epoch 11, Batch 1800] loss: 0.010780484443373553
[Epoch 11, Batch 1900] loss: 0.010636326420244585
[Epoch 11, Batch 2000] loss: 0.025368297484574212
[Epoch 11, Batch 2100] loss: 0.007591617325563221
[Epoch 11, Batch 2200] loss: 0.0142291394766562
[Epoch 11, Batch 2300] loss: 0.020359891418322604
[Epoch 11, Batch 2400] loss: 0.02334097042112262
[Epoch 11, Batch 2500] loss: 0.011176072732623651
[Epoch 11, Batch 2600] loss: 0.018127098162817674
[Epoch 11, Batch 2700] loss: 0.008485719967488876
[Epoch 11, Batch 2800] loss: 0.014652008983132419
[Epoch 11, Batch 2900] loss: 0.021389489833854896
[Epoch 11, Batch 3000] loss: 0.01648706090021733
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9867
Overfitting: 0.0512
[Epoch 12, Batch 100] loss: 0.01013509866322238
[Epoch 12, Batch 200] loss: 0.012369004192769352
[Epoch 12, Batch 300] loss: 0.013579563286334632
[Epoch 12, Batch 400] loss: 0.010126668497223363
[Epoch 12, Batch 500] loss: 0.00938834576402769
[Epoch 12, Batch 600] loss: 0.009122676737504207
[Epoch 12, Batch 700] loss: 0.008717578793048233
[Epoch 12, Batch 800] loss: 0.014392646171581874
[Epoch 12, Batch 900] loss: 0.002620903154079315
[Epoch 12, Batch 1000] loss: 0.005634384148390836
[Epoch 12, Batch 1100] loss: 0.006457077815794037
[Epoch 12, Batch 1200] loss: 0.012273897211230178
[Epoch 12, Batch 1300] loss: 0.012640503457009799
[Epoch 12, Batch 1400] loss: 0.007480667152123601
[Epoch 12, Batch 1500] loss: 0.016746300549366423
[Epoch 12, Batch 1600] loss: 0.017345440152248558
[Epoch 12, Batch 1700] loss: 0.005971778708221791
[Epoch 12, Batch 1800] loss: 0.021610643581143448
[Epoch 12, Batch 1900] loss: 0.010867947250092129
[Epoch 12, Batch 2000] loss: 0.01603067614396423
[Epoch 12, Batch 2100] loss: 0.020008398341133216
[Epoch 12, Batch 2200] loss: 0.014794971227174755
[Epoch 12, Batch 2300] loss: 0.03204371972025229
[Epoch 12, Batch 2400] loss: 0.016315516722846722
[Epoch 12, Batch 2500] loss: 0.006080475333167214
[Epoch 12, Batch 2600] loss: 0.023092380949451582
[Epoch 12, Batch 2700] loss: 0.009806328784458173
[Epoch 12, Batch 2800] loss: 0.008280549598312063
[Epoch 12, Batch 2900] loss: 0.011164621216767045
[Epoch 12, Batch 3000] loss: 0.010064505895463753
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9873
Overfitting: 0.0487
[Epoch 13, Batch 100] loss: 0.005695409334051647
[Epoch 13, Batch 200] loss: 0.006657650697129611
[Epoch 13, Batch 300] loss: 0.009287509633750232
[Epoch 13, Batch 400] loss: 0.006201559034651609
[Epoch 13, Batch 500] loss: 0.010897408628736685
[Epoch 13, Batch 600] loss: 0.012944286367085738
[Epoch 13, Batch 700] loss: 0.012386930376774217
[Epoch 13, Batch 800] loss: 0.011540573715778919
[Epoch 13, Batch 900] loss: 0.006109680345997503
[Epoch 13, Batch 1000] loss: 0.009601424758727717
[Epoch 13, Batch 1100] loss: 0.005618274224352717
[Epoch 13, Batch 1200] loss: 0.0050488863013470105
[Epoch 13, Batch 1300] loss: 0.0043468570256527525
[Epoch 13, Batch 1400] loss: 0.012258173317654268
[Epoch 13, Batch 1500] loss: 0.014150964860250496
[Epoch 13, Batch 1600] loss: 0.008409627434892854
[Epoch 13, Batch 1700] loss: 0.010290398638074976
[Epoch 13, Batch 1800] loss: 0.010456601748895764
[Epoch 13, Batch 1900] loss: 0.019817452140759997
[Epoch 13, Batch 2000] loss: 0.008144656603476505
[Epoch 13, Batch 2100] loss: 0.007418920703155436
[Epoch 13, Batch 2200] loss: 0.005827701823702683
[Epoch 13, Batch 2300] loss: 0.008138557635885491
[Epoch 13, Batch 2400] loss: 0.015037608194247695
[Epoch 13, Batch 2500] loss: 0.010650446062994092
[Epoch 13, Batch 2600] loss: 0.02141974771116111
[Epoch 13, Batch 2700] loss: 0.01702371043925268
[Epoch 13, Batch 2800] loss: 0.012056475690387742
[Epoch 13, Batch 2900] loss: 0.008526166396623012
[Epoch 13, Batch 3000] loss: 0.00925567667865323
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9873
Overfitting: 0.0490
[Epoch 14, Batch 100] loss: 0.013875558996337531
[Epoch 14, Batch 200] loss: 0.010406858232528293
[Epoch 14, Batch 300] loss: 0.004117003822991592
[Epoch 14, Batch 400] loss: 0.007237430742615061
[Epoch 14, Batch 500] loss: 0.0030193561136269407
[Epoch 14, Batch 600] loss: 0.0068001131354003515
[Epoch 14, Batch 700] loss: 0.011664863395997144
[Epoch 14, Batch 800] loss: 0.011596051822598952
[Epoch 14, Batch 900] loss: 0.012188676931325517
[Epoch 14, Batch 1000] loss: 0.005789290633809969
[Epoch 14, Batch 1100] loss: 0.003235974293837671
[Epoch 14, Batch 1200] loss: 0.009497260947256336
[Epoch 14, Batch 1300] loss: 0.004229564930779333
[Epoch 14, Batch 1400] loss: 0.0035118812163938175
[Epoch 14, Batch 1500] loss: 0.010486062451400357
[Epoch 14, Batch 1600] loss: 0.004827158039508958
[Epoch 14, Batch 1700] loss: 0.008824661451159272
[Epoch 14, Batch 1800] loss: 0.017080548355104242
[Epoch 14, Batch 1900] loss: 0.007275397067229505
[Epoch 14, Batch 2000] loss: 0.010202521702150308
[Epoch 14, Batch 2100] loss: 0.008167610205418896
[Epoch 14, Batch 2200] loss: 0.008054787113580915
[Epoch 14, Batch 2300] loss: 0.004046597455622134
[Epoch 14, Batch 2400] loss: 0.007196859370797597
[Epoch 14, Batch 2500] loss: 0.007265873620326602
[Epoch 14, Batch 2600] loss: 0.006967523500869249
[Epoch 14, Batch 2700] loss: 0.016745198542120077
[Epoch 14, Batch 2800] loss: 0.011235302325493137
[Epoch 14, Batch 2900] loss: 0.005154801981088895
[Epoch 14, Batch 3000] loss: 0.016145659786196233
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0589
Validation Accuracy: 0.9847
Overfitting: 0.0589
[Epoch 15, Batch 100] loss: 0.013877235268544154
[Epoch 15, Batch 200] loss: 0.003303264772550847
[Epoch 15, Batch 300] loss: 0.002955105540098657
[Epoch 15, Batch 400] loss: 0.002224381122180148
[Epoch 15, Batch 500] loss: 0.005749585765098288
[Epoch 15, Batch 600] loss: 0.0015057708890017806
[Epoch 15, Batch 700] loss: 0.004721639365367878
[Epoch 15, Batch 800] loss: 0.0046997233351783055
[Epoch 15, Batch 900] loss: 0.0038551856520280124
[Epoch 15, Batch 1000] loss: 0.004277532077997251
[Epoch 15, Batch 1100] loss: 0.007458024744616978
[Epoch 15, Batch 1200] loss: 0.0042109064119176766
[Epoch 15, Batch 1300] loss: 0.005959143964733329
[Epoch 15, Batch 1400] loss: 0.0043395109636975345
[Epoch 15, Batch 1500] loss: 0.0030644487483871786
[Epoch 15, Batch 1600] loss: 0.002161900536663666
[Epoch 15, Batch 1700] loss: 0.0108316998308635
[Epoch 15, Batch 1800] loss: 0.006252985801293604
[Epoch 15, Batch 1900] loss: 0.006568243407396039
[Epoch 15, Batch 2000] loss: 0.004109073146917552
[Epoch 15, Batch 2100] loss: 0.0022911555978998876
[Epoch 15, Batch 2200] loss: 0.004782507467585262
[Epoch 15, Batch 2300] loss: 0.014336896749694574
[Epoch 15, Batch 2400] loss: 0.008994698147612326
[Epoch 15, Batch 2500] loss: 0.008261281015414852
[Epoch 15, Batch 2600] loss: 0.004521312025142947
[Epoch 15, Batch 2700] loss: 0.007749459918144055
[Epoch 15, Batch 2800] loss: 0.00832514405065382
[Epoch 15, Batch 2900] loss: 0.012813776561849864
[Epoch 15, Batch 3000] loss: 0.014728065362779716
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9879
Overfitting: 0.0513
[Epoch 16, Batch 100] loss: 0.007126575401908752
[Epoch 16, Batch 200] loss: 0.001550317436764601
[Epoch 16, Batch 300] loss: 0.0032663132820206896
[Epoch 16, Batch 400] loss: 0.006264579066085201
[Epoch 16, Batch 500] loss: 0.013370040565831829
[Epoch 16, Batch 600] loss: 0.011383937568558053
[Epoch 16, Batch 700] loss: 0.010310899952128168
[Epoch 16, Batch 800] loss: 0.004643287650291086
[Epoch 16, Batch 900] loss: 0.008317393618315095
[Epoch 16, Batch 1000] loss: 0.00872425515386226
[Epoch 16, Batch 1100] loss: 0.007418844331314176
[Epoch 16, Batch 1200] loss: 0.009684283997206649
[Epoch 16, Batch 1300] loss: 0.006512520440468279
[Epoch 16, Batch 1400] loss: 0.005833853629896737
[Epoch 16, Batch 1500] loss: 0.005783714237558044
[Epoch 16, Batch 1600] loss: 0.012983602213654138
[Epoch 16, Batch 1700] loss: 0.018256279941928143
[Epoch 16, Batch 1800] loss: 0.009512538894090311
[Epoch 16, Batch 1900] loss: 0.005286959094216286
[Epoch 16, Batch 2000] loss: 0.00265617312083684
[Epoch 16, Batch 2100] loss: 0.004774985961674858
[Epoch 16, Batch 2200] loss: 0.006932484583795712
[Epoch 16, Batch 2300] loss: 0.01922821824604398
[Epoch 16, Batch 2400] loss: 0.01118176083989738
[Epoch 16, Batch 2500] loss: 0.0053195811361433695
[Epoch 16, Batch 2600] loss: 0.007671903788588566
[Epoch 16, Batch 2700] loss: 0.002815544213890604
[Epoch 16, Batch 2800] loss: 0.01479771374050074
[Epoch 16, Batch 2900] loss: 0.004409838835381379
[Epoch 16, Batch 3000] loss: 0.004483656016394377
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9887
Overfitting: 0.0514
[Epoch 17, Batch 100] loss: 0.004580351266362755
[Epoch 17, Batch 200] loss: 0.006008346269274938
[Epoch 17, Batch 300] loss: 0.004442528204860849
[Epoch 17, Batch 400] loss: 0.0036335933682914855
[Epoch 17, Batch 500] loss: 0.007264953347175513
[Epoch 17, Batch 600] loss: 0.005182574656592891
[Epoch 17, Batch 700] loss: 0.00270320751700865
[Epoch 17, Batch 800] loss: 0.0055075535234635
[Epoch 17, Batch 900] loss: 0.005756783033241959
[Epoch 17, Batch 1000] loss: 0.002205831140426664
[Epoch 17, Batch 1100] loss: 0.0063316649346723515
[Epoch 17, Batch 1200] loss: 0.013383662942366072
[Epoch 17, Batch 1300] loss: 0.011414117280678511
[Epoch 17, Batch 1400] loss: 0.0025413013770614157
[Epoch 17, Batch 1500] loss: 0.003820868456459223
[Epoch 17, Batch 1600] loss: 0.008035800535427028
[Epoch 17, Batch 1700] loss: 0.006552631062727982
[Epoch 17, Batch 1800] loss: 0.005435955500024931
[Epoch 17, Batch 1900] loss: 0.004947180853287563
[Epoch 17, Batch 2000] loss: 0.00578591425570778
[Epoch 17, Batch 2100] loss: 0.008499055202324683
[Epoch 17, Batch 2200] loss: 0.0019703091577019903
[Epoch 17, Batch 2300] loss: 0.0029467979869433236
[Epoch 17, Batch 2400] loss: 0.005248422267636385
[Epoch 17, Batch 2500] loss: 0.0071624432228224325
[Epoch 17, Batch 2600] loss: 0.006111745708565195
[Epoch 17, Batch 2700] loss: 0.01674523114521392
[Epoch 17, Batch 2800] loss: 0.011126079332472614
[Epoch 17, Batch 2900] loss: 0.002526784108156335
[Epoch 17, Batch 3000] loss: 0.004450833651902855
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9878
Overfitting: 0.0496
[Epoch 18, Batch 100] loss: 0.0022825662663660752
[Epoch 18, Batch 200] loss: 0.0014922852302197498
[Epoch 18, Batch 300] loss: 0.0011080714575025753
[Epoch 18, Batch 400] loss: 0.0033715265900650594
[Epoch 18, Batch 500] loss: 0.0013564924835462477
[Epoch 18, Batch 600] loss: 0.004343047913350233
[Epoch 18, Batch 700] loss: 0.0007801583305108295
[Epoch 18, Batch 800] loss: 0.0014786252607795801
[Epoch 18, Batch 900] loss: 0.0008453439796750217
[Epoch 18, Batch 1000] loss: 0.0005618614470832028
[Epoch 18, Batch 1100] loss: 0.0016442056856791965
[Epoch 18, Batch 1200] loss: 0.0006304212459417569
[Epoch 18, Batch 1300] loss: 0.0010620399238749022
[Epoch 18, Batch 1400] loss: 0.000921427018908787
[Epoch 18, Batch 1500] loss: 0.005867019561020328
[Epoch 18, Batch 1600] loss: 0.013091611284182392
[Epoch 18, Batch 1700] loss: 0.008334487772824133
[Epoch 18, Batch 1800] loss: 0.003315710912973344
[Epoch 18, Batch 1900] loss: 0.00553317143924005
[Epoch 18, Batch 2000] loss: 0.0041580839765867775
[Epoch 18, Batch 2100] loss: 0.004500251960375757
[Epoch 18, Batch 2200] loss: 0.0065671841674018695
[Epoch 18, Batch 2300] loss: 0.0033559486183531817
[Epoch 18, Batch 2400] loss: 0.014738496023399392
[Epoch 18, Batch 2500] loss: 0.012173192602931522
[Epoch 18, Batch 2600] loss: 0.005231803533274615
[Epoch 18, Batch 2700] loss: 0.009711738054916168
[Epoch 18, Batch 2800] loss: 0.0028629981472596457
[Epoch 18, Batch 2900] loss: 0.005184123446497324
[Epoch 18, Batch 3000] loss: 0.0068236357420279605
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0631
Validation Accuracy: 0.9862
Overfitting: 0.0631
[Epoch 19, Batch 100] loss: 0.012326840452735723
[Epoch 19, Batch 200] loss: 0.004916725691379043
[Epoch 19, Batch 300] loss: 0.0040526522489272975
[Epoch 19, Batch 400] loss: 0.006487815690490493
[Epoch 19, Batch 500] loss: 0.0018157117008752177
[Epoch 19, Batch 600] loss: 0.0017979479813217836
[Epoch 19, Batch 700] loss: 0.004216182387679979
[Epoch 19, Batch 800] loss: 0.006954246208310409
[Epoch 19, Batch 900] loss: 0.004153685412447885
[Epoch 19, Batch 1000] loss: 0.0035040491533209206
[Epoch 19, Batch 1100] loss: 0.004459935447694043
[Epoch 19, Batch 1200] loss: 0.006970703400343154
[Epoch 19, Batch 1300] loss: 0.003705858389241712
[Epoch 19, Batch 1400] loss: 0.005887899749130838
[Epoch 19, Batch 1500] loss: 0.006829104815793983
[Epoch 19, Batch 1600] loss: 0.007541217818568242
[Epoch 19, Batch 1700] loss: 0.00884683710802534
[Epoch 19, Batch 1800] loss: 0.008739913941377608
[Epoch 19, Batch 1900] loss: 0.01113284869013512
[Epoch 19, Batch 2000] loss: 0.004478768985838428
[Epoch 19, Batch 2100] loss: 0.0028124944305103127
[Epoch 19, Batch 2200] loss: 0.0027747684913552464
[Epoch 19, Batch 2300] loss: 0.0017387197788667663
[Epoch 19, Batch 2400] loss: 0.005168366816691332
[Epoch 19, Batch 2500] loss: 0.004408789096850469
[Epoch 19, Batch 2600] loss: 0.003442705328276183
[Epoch 19, Batch 2700] loss: 0.0026038434068507144
[Epoch 19, Batch 2800] loss: 0.0027847298539975893
[Epoch 19, Batch 2900] loss: 0.003871054203704176
[Epoch 19, Batch 3000] loss: 0.010036074505378058
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9868
Overfitting: 0.0636
[Epoch 20, Batch 100] loss: 0.0074932178302557825
[Epoch 20, Batch 200] loss: 0.004867829389443443
[Epoch 20, Batch 300] loss: 0.0024393551891780875
[Epoch 20, Batch 400] loss: 0.0057450787928907945
[Epoch 20, Batch 500] loss: 0.004359386203243006
[Epoch 20, Batch 600] loss: 0.003306762312456044
[Epoch 20, Batch 700] loss: 0.001587553214768711
[Epoch 20, Batch 800] loss: 0.001618731248246803
[Epoch 20, Batch 900] loss: 0.0020602811084616947
[Epoch 20, Batch 1000] loss: 0.0017132325521744462
[Epoch 20, Batch 1100] loss: 0.0006936042954362165
[Epoch 20, Batch 1200] loss: 0.0019778850911477265
[Epoch 20, Batch 1300] loss: 0.003955007497698198
[Epoch 20, Batch 1400] loss: 0.0016568668081041339
[Epoch 20, Batch 1500] loss: 0.0011559577003490062
[Epoch 20, Batch 1600] loss: 0.0013877513526415442
[Epoch 20, Batch 1700] loss: 0.0011279797916555624
[Epoch 20, Batch 1800] loss: 0.002735793799316255
[Epoch 20, Batch 1900] loss: 0.011929229914568164
[Epoch 20, Batch 2000] loss: 0.006713974428645848
[Epoch 20, Batch 2100] loss: 0.013665146117859593
[Epoch 20, Batch 2200] loss: 0.0028134244949329455
[Epoch 20, Batch 2300] loss: 0.0027943421192401273
[Epoch 20, Batch 2400] loss: 0.0018112373870690756
[Epoch 20, Batch 2500] loss: 0.0034480167921886597
[Epoch 20, Batch 2600] loss: 0.0010298468843992837
[Epoch 20, Batch 2700] loss: 0.0061170273041699155
[Epoch 20, Batch 2800] loss: 0.010796618327537626
[Epoch 20, Batch 2900] loss: 0.008335474835838746
[Epoch 20, Batch 3000] loss: 0.02008041545798392
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0676
Validation Accuracy: 0.9867
Overfitting: 0.0676
[Epoch 21, Batch 100] loss: 0.0036921231668481623
[Epoch 21, Batch 200] loss: 0.004588779555397018
[Epoch 21, Batch 300] loss: 0.005127707104844461
[Epoch 21, Batch 400] loss: 0.001866949507392377
[Epoch 21, Batch 500] loss: 0.0014483028538897712
[Epoch 21, Batch 600] loss: 0.002622882191375773
[Epoch 21, Batch 700] loss: 0.0005245323904897959
[Epoch 21, Batch 800] loss: 0.007054855903030699
[Epoch 21, Batch 900] loss: 0.008103380410271371
[Epoch 21, Batch 1000] loss: 0.0077093232585880855
[Epoch 21, Batch 1100] loss: 0.016466119137021167
[Epoch 21, Batch 1200] loss: 0.008562587722085482
[Epoch 21, Batch 1300] loss: 0.005793554578413307
[Epoch 21, Batch 1400] loss: 0.019182829884461513
[Epoch 21, Batch 1500] loss: 0.0073326147683772545
[Epoch 21, Batch 1600] loss: 0.0014542283336051297
[Epoch 21, Batch 1700] loss: 0.01377955279528205
[Epoch 21, Batch 1800] loss: 0.00930575838674832
[Epoch 21, Batch 1900] loss: 0.01840837281225518
[Epoch 21, Batch 2000] loss: 0.014923428541458748
[Epoch 21, Batch 2100] loss: 0.011698635088664915
[Epoch 21, Batch 2200] loss: 0.006398423976522878
[Epoch 21, Batch 2300] loss: 0.003811706886169475
[Epoch 21, Batch 2400] loss: 0.010511264257462738
[Epoch 21, Batch 2500] loss: 0.0060465573574177214
[Epoch 21, Batch 2600] loss: 0.002181836632757053
[Epoch 21, Batch 2700] loss: 0.007275841398731764
[Epoch 21, Batch 2800] loss: 0.008340452855650255
[Epoch 21, Batch 2900] loss: 0.016678591915535782
[Epoch 21, Batch 3000] loss: 0.011775618998212263
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9859
Overfitting: 0.0632
[Epoch 22, Batch 100] loss: 0.0074729937930975154
[Epoch 22, Batch 200] loss: 0.002154931596456455
[Epoch 22, Batch 300] loss: 0.0033308597151246034
[Epoch 22, Batch 400] loss: 0.0012265436758328717
[Epoch 22, Batch 500] loss: 0.006011076662081649
[Epoch 22, Batch 600] loss: 0.009301170338284521
[Epoch 22, Batch 700] loss: 0.010791628061304976
[Epoch 22, Batch 800] loss: 0.008233342558457188
[Epoch 22, Batch 900] loss: 0.003383515687014267
[Epoch 22, Batch 1000] loss: 0.006833892778180477
[Epoch 22, Batch 1100] loss: 0.005971471839461122
[Epoch 22, Batch 1200] loss: 0.00468991039568806
[Epoch 22, Batch 1300] loss: 0.011582516916188865
[Epoch 22, Batch 1400] loss: 0.0035123284730173053
[Epoch 22, Batch 1500] loss: 0.0055617811849634794
[Epoch 22, Batch 1600] loss: 0.0031369807011708416
[Epoch 22, Batch 1700] loss: 0.00107739131248195
[Epoch 22, Batch 1800] loss: 0.0030760546429645787
[Epoch 22, Batch 1900] loss: 0.0012197410156255728
[Epoch 22, Batch 2000] loss: 0.0024490687974382296
[Epoch 22, Batch 2100] loss: 0.005064945262669731
[Epoch 22, Batch 2200] loss: 0.0040714374801802174
[Epoch 22, Batch 2300] loss: 0.005152338950780972
[Epoch 22, Batch 2400] loss: 0.00290407438073629
[Epoch 22, Batch 2500] loss: 0.003335899263277966
[Epoch 22, Batch 2600] loss: 0.0065808316764675735
[Epoch 22, Batch 2700] loss: 0.0075605930631780895
[Epoch 22, Batch 2800] loss: 0.007033979326538109
[Epoch 22, Batch 2900] loss: 0.009102062959950655
[Epoch 22, Batch 3000] loss: 0.007958323966950403
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9886
Overfitting: 0.0570
[Epoch 23, Batch 100] loss: 0.00808573238152441
[Epoch 23, Batch 200] loss: 0.0033687651976008937
[Epoch 23, Batch 300] loss: 0.0026069204400161537
[Epoch 23, Batch 400] loss: 0.0011092848038698122
[Epoch 23, Batch 500] loss: 0.0016573394545441999
[Epoch 23, Batch 600] loss: 0.0014555703437049772
[Epoch 23, Batch 700] loss: 0.004371464956106586
[Epoch 23, Batch 800] loss: 0.0020349149341456043
[Epoch 23, Batch 900] loss: 0.005798353260646021
[Epoch 23, Batch 1000] loss: 0.0026307733237165023
[Epoch 23, Batch 1100] loss: 0.003959019683681077
[Epoch 23, Batch 1200] loss: 0.002030936485197259
[Epoch 23, Batch 1300] loss: 0.004049721301218589
[Epoch 23, Batch 1400] loss: 0.002030697030194375
[Epoch 23, Batch 1500] loss: 0.001103601751814658
[Epoch 23, Batch 1600] loss: 0.005076635424360419
[Epoch 23, Batch 1700] loss: 0.0019336934953447127
[Epoch 23, Batch 1800] loss: 0.0023697414239407344
[Epoch 23, Batch 1900] loss: 0.003411589766529346
[Epoch 23, Batch 2000] loss: 0.0005334728176398329
[Epoch 23, Batch 2100] loss: 0.0024339770999880273
[Epoch 23, Batch 2200] loss: 0.0036485644082761403
[Epoch 23, Batch 2300] loss: 0.0010410624990575279
[Epoch 23, Batch 2400] loss: 0.004926197139058237
[Epoch 23, Batch 2500] loss: 0.011733705455518901
[Epoch 23, Batch 2600] loss: 0.00672410426274837
[Epoch 23, Batch 2700] loss: 0.006119852568133126
[Epoch 23, Batch 2800] loss: 0.007429234262690372
[Epoch 23, Batch 2900] loss: 0.008016148068618976
[Epoch 23, Batch 3000] loss: 0.011783416125323472
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9881
Overfitting: 0.0573
[Epoch 24, Batch 100] loss: 0.0033645837052822002
[Epoch 24, Batch 200] loss: 0.004606974353664128
[Epoch 24, Batch 300] loss: 0.003273722686833036
[Epoch 24, Batch 400] loss: 0.0020595536640732348
[Epoch 24, Batch 500] loss: 0.017851234592565674
[Epoch 24, Batch 600] loss: 0.005996121643215915
[Epoch 24, Batch 700] loss: 0.0014473486388139277
[Epoch 24, Batch 800] loss: 0.005954357720609344
[Epoch 24, Batch 900] loss: 0.014257455228938199
[Epoch 24, Batch 1000] loss: 0.00440964976728365
[Epoch 24, Batch 1100] loss: 0.004526592042970634
[Epoch 24, Batch 1200] loss: 0.009437515297986749
[Epoch 24, Batch 1300] loss: 0.0025569865008067084
[Epoch 24, Batch 1400] loss: 0.004310470408494034
[Epoch 24, Batch 1500] loss: 0.0018009847576492888
[Epoch 24, Batch 1600] loss: 0.0027062643748993055
[Epoch 24, Batch 1700] loss: 0.008272459010067297
[Epoch 24, Batch 1800] loss: 0.009721644675651503
[Epoch 24, Batch 1900] loss: 0.007677468776030878
[Epoch 24, Batch 2000] loss: 0.007504523608841112
[Epoch 24, Batch 2100] loss: 0.0028707122095921987
[Epoch 24, Batch 2200] loss: 0.002803656670705834
[Epoch 24, Batch 2300] loss: 0.0059251727591302485
[Epoch 24, Batch 2400] loss: 0.008846652840878839
[Epoch 24, Batch 2500] loss: 0.008051493825071244
[Epoch 24, Batch 2600] loss: 0.005491773426950033
[Epoch 24, Batch 2700] loss: 0.004093911916808421
[Epoch 24, Batch 2800] loss: 0.004637950924018241
[Epoch 24, Batch 2900] loss: 0.007171790123116879
[Epoch 24, Batch 3000] loss: 0.0019055246124096347
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9892
Overfitting: 0.0550
Fold 5 validation loss: 0.0550
Mean validation loss across all folds for Trial 13 is 0.0623 with trial config:  l1: 128, l2: 64, lr: 0.0021608588039666666, batch_size: 16
[I 2024-12-11 05:26:42,325] Trial 12 finished with value: 0.06232857476354632 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.0021608588039666666, 'batch_size': 16}. Best is trial 4 with value: 0.04724671796616846.

Selected Hyperparameters for Trial 14:
  l1: 256, l2: 128, lr: 0.000662925560873599, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3014672136306764
[Epoch 1, Batch 200] loss: 2.2950204610824585
[Epoch 1, Batch 300] loss: 2.2843963956832884
[Epoch 1, Batch 400] loss: 2.271519145965576
[Epoch 1, Batch 500] loss: 2.2497730922698973
[Epoch 1, Batch 600] loss: 2.1960756969451904
[Epoch 1, Batch 700] loss: 2.038461529016495
[Epoch 1, Batch 800] loss: 1.4644202196598053
[Epoch 1, Batch 900] loss: 0.8237239049375057
[Epoch 1, Batch 1000] loss: 0.5829697185754776
[Epoch 1, Batch 1100] loss: 0.43906094439327714
[Epoch 1, Batch 1200] loss: 0.47186998799443247
[Epoch 1, Batch 1300] loss: 0.3987534936517477
[Epoch 1, Batch 1400] loss: 0.39683725524693725
[Epoch 1, Batch 1500] loss: 0.3016836041212082
[Epoch 1, Batch 1600] loss: 0.31679581917822364
[Epoch 1, Batch 1700] loss: 0.3080321568623185
[Epoch 1, Batch 1800] loss: 0.2535690670274198
[Epoch 1, Batch 1900] loss: 0.24868486316874625
[Epoch 1, Batch 2000] loss: 0.1912275498919189
[Epoch 1, Batch 2100] loss: 0.2089123569522053
[Epoch 1, Batch 2200] loss: 0.20941662391647697
[Epoch 1, Batch 2300] loss: 0.20731318072415889
[Epoch 1, Batch 2400] loss: 0.18468335799872876
[Epoch 1, Batch 2500] loss: 0.17591242264956236
[Epoch 1, Batch 2600] loss: 0.19022175701335073
[Epoch 1, Batch 2700] loss: 0.19433758657425643
[Epoch 1, Batch 2800] loss: 0.16911469545215368
[Epoch 1, Batch 2900] loss: 0.17894547509495168
[Epoch 1, Batch 3000] loss: 0.1503247360745445
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1426
Validation Accuracy: 0.9559
Overfitting: 0.1426
Best model saved at epoch 1 with validation loss: 0.1426
[Epoch 2, Batch 100] loss: 0.14863774147816003
[Epoch 2, Batch 200] loss: 0.14153903179802
[Epoch 2, Batch 300] loss: 0.1501208386477083
[Epoch 2, Batch 400] loss: 0.14992331431247294
[Epoch 2, Batch 500] loss: 0.14215885156299918
[Epoch 2, Batch 600] loss: 0.1273919710610062
[Epoch 2, Batch 700] loss: 0.1480101620685309
[Epoch 2, Batch 800] loss: 0.12463861745782197
[Epoch 2, Batch 900] loss: 0.1606460111355409
[Epoch 2, Batch 1000] loss: 0.15983157362788916
[Epoch 2, Batch 1100] loss: 0.1204985498636961
[Epoch 2, Batch 1200] loss: 0.12246607289183885
[Epoch 2, Batch 1300] loss: 0.10713891426566988
[Epoch 2, Batch 1400] loss: 0.10984347919467836
[Epoch 2, Batch 1500] loss: 0.10284948544576764
[Epoch 2, Batch 1600] loss: 0.12317486093379557
[Epoch 2, Batch 1700] loss: 0.1355195428756997
[Epoch 2, Batch 1800] loss: 0.12265525537542998
[Epoch 2, Batch 1900] loss: 0.09870602277107537
[Epoch 2, Batch 2000] loss: 0.11774998879060149
[Epoch 2, Batch 2100] loss: 0.13152821031864734
[Epoch 2, Batch 2200] loss: 0.10090431939577683
[Epoch 2, Batch 2300] loss: 0.10941666073864326
[Epoch 2, Batch 2400] loss: 0.09199298304272815
[Epoch 2, Batch 2500] loss: 0.0970420283661224
[Epoch 2, Batch 2600] loss: 0.08529262433294207
[Epoch 2, Batch 2700] loss: 0.08934239364345559
[Epoch 2, Batch 2800] loss: 0.09851052926620468
[Epoch 2, Batch 2900] loss: 0.10893250660563353
[Epoch 2, Batch 3000] loss: 0.09049979199888185
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1004
Validation Accuracy: 0.9673
Overfitting: 0.1004
Best model saved at epoch 2 with validation loss: 0.1004
[Epoch 3, Batch 100] loss: 0.07550333519349806
[Epoch 3, Batch 200] loss: 0.08997340635862201
[Epoch 3, Batch 300] loss: 0.10406541485572234
[Epoch 3, Batch 400] loss: 0.09839981950121
[Epoch 3, Batch 500] loss: 0.09314715228276327
[Epoch 3, Batch 600] loss: 0.09383031171746552
[Epoch 3, Batch 700] loss: 0.08974672849057243
[Epoch 3, Batch 800] loss: 0.09402715436881408
[Epoch 3, Batch 900] loss: 0.09934033381869085
[Epoch 3, Batch 1000] loss: 0.08845521921757608
[Epoch 3, Batch 1100] loss: 0.09997905834577978
[Epoch 3, Batch 1200] loss: 0.08046678588259965
[Epoch 3, Batch 1300] loss: 0.08776372313383035
[Epoch 3, Batch 1400] loss: 0.08063980447012
[Epoch 3, Batch 1500] loss: 0.09037654855521396
[Epoch 3, Batch 1600] loss: 0.09104700859636068
[Epoch 3, Batch 1700] loss: 0.09104053089744411
[Epoch 3, Batch 1800] loss: 0.09652086041867733
[Epoch 3, Batch 1900] loss: 0.07999264555051923
[Epoch 3, Batch 2000] loss: 0.07080485688056797
[Epoch 3, Batch 2100] loss: 0.06837024307344108
[Epoch 3, Batch 2200] loss: 0.061790713557275015
[Epoch 3, Batch 2300] loss: 0.07912208355730399
[Epoch 3, Batch 2400] loss: 0.07298572217405308
[Epoch 3, Batch 2500] loss: 0.06673905433970503
[Epoch 3, Batch 2600] loss: 0.0686734279221855
[Epoch 3, Batch 2700] loss: 0.09483094194438309
[Epoch 3, Batch 2800] loss: 0.05632440134417266
[Epoch 3, Batch 2900] loss: 0.07416597361734603
[Epoch 3, Batch 3000] loss: 0.07531289092963561
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0770
Validation Accuracy: 0.9751
Overfitting: 0.0770
Best model saved at epoch 3 with validation loss: 0.0770
[Epoch 4, Batch 100] loss: 0.06830778761184775
[Epoch 4, Batch 200] loss: 0.08767094778944738
[Epoch 4, Batch 300] loss: 0.0707191063684877
[Epoch 4, Batch 400] loss: 0.0680474331381265
[Epoch 4, Batch 500] loss: 0.06883290345082059
[Epoch 4, Batch 600] loss: 0.04636631620815024
[Epoch 4, Batch 700] loss: 0.06676250050892123
[Epoch 4, Batch 800] loss: 0.07784281816799193
[Epoch 4, Batch 900] loss: 0.07157660069235135
[Epoch 4, Batch 1000] loss: 0.06841805456206203
[Epoch 4, Batch 1100] loss: 0.06182168272440322
[Epoch 4, Batch 1200] loss: 0.08370295943226665
[Epoch 4, Batch 1300] loss: 0.06891534017166123
[Epoch 4, Batch 1400] loss: 0.05670502095599659
[Epoch 4, Batch 1500] loss: 0.0836685928911902
[Epoch 4, Batch 1600] loss: 0.0809040828444995
[Epoch 4, Batch 1700] loss: 0.06622314335196279
[Epoch 4, Batch 1800] loss: 0.06401445965864695
[Epoch 4, Batch 1900] loss: 0.05832061845751014
[Epoch 4, Batch 2000] loss: 0.06878061030234676
[Epoch 4, Batch 2100] loss: 0.04744430006481707
[Epoch 4, Batch 2200] loss: 0.05911428052466363
[Epoch 4, Batch 2300] loss: 0.07536660252721049
[Epoch 4, Batch 2400] loss: 0.0531377511122264
[Epoch 4, Batch 2500] loss: 0.043647187746246346
[Epoch 4, Batch 2600] loss: 0.08141389908036217
[Epoch 4, Batch 2700] loss: 0.05905494933016598
[Epoch 4, Batch 2800] loss: 0.0689568115468137
[Epoch 4, Batch 2900] loss: 0.05469176667451393
[Epoch 4, Batch 3000] loss: 0.05205170865636319
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0597
Validation Accuracy: 0.9809
Overfitting: 0.0597
Best model saved at epoch 4 with validation loss: 0.0597
[Epoch 5, Batch 100] loss: 0.05248384380480275
[Epoch 5, Batch 200] loss: 0.048595590327167884
[Epoch 5, Batch 300] loss: 0.0419780802045716
[Epoch 5, Batch 400] loss: 0.07310015582566848
[Epoch 5, Batch 500] loss: 0.05413101161364466
[Epoch 5, Batch 600] loss: 0.047057830475096124
[Epoch 5, Batch 700] loss: 0.06530841601546854
[Epoch 5, Batch 800] loss: 0.0643307765678037
[Epoch 5, Batch 900] loss: 0.051324327934125905
[Epoch 5, Batch 1000] loss: 0.05504759020637721
[Epoch 5, Batch 1100] loss: 0.05790964724204969
[Epoch 5, Batch 1200] loss: 0.05710995259461924
[Epoch 5, Batch 1300] loss: 0.0459256336290855
[Epoch 5, Batch 1400] loss: 0.06735721098433714
[Epoch 5, Batch 1500] loss: 0.04953577884240076
[Epoch 5, Batch 1600] loss: 0.04953554471139796
[Epoch 5, Batch 1700] loss: 0.05057715528586414
[Epoch 5, Batch 1800] loss: 0.033105620423302756
[Epoch 5, Batch 1900] loss: 0.06397304620273644
[Epoch 5, Batch 2000] loss: 0.06299760641821195
[Epoch 5, Batch 2100] loss: 0.05048043822374893
[Epoch 5, Batch 2200] loss: 0.05389064869785216
[Epoch 5, Batch 2300] loss: 0.046475540733081286
[Epoch 5, Batch 2400] loss: 0.04545773623045534
[Epoch 5, Batch 2500] loss: 0.06478637410444207
[Epoch 5, Batch 2600] loss: 0.039085636396921475
[Epoch 5, Batch 2700] loss: 0.0442219635512447
[Epoch 5, Batch 2800] loss: 0.06922153593186522
[Epoch 5, Batch 2900] loss: 0.062249769812915474
[Epoch 5, Batch 3000] loss: 0.05552655129344203
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9846
Overfitting: 0.0531
Best model saved at epoch 5 with validation loss: 0.0531
[Epoch 6, Batch 100] loss: 0.0473414261318976
[Epoch 6, Batch 200] loss: 0.05665843883616617
[Epoch 6, Batch 300] loss: 0.04584577780915424
[Epoch 6, Batch 400] loss: 0.045119952316745184
[Epoch 6, Batch 500] loss: 0.04473838874138892
[Epoch 6, Batch 600] loss: 0.04101194125294569
[Epoch 6, Batch 700] loss: 0.0411269314600213
[Epoch 6, Batch 800] loss: 0.02959224138758145
[Epoch 6, Batch 900] loss: 0.03399368456739467
[Epoch 6, Batch 1000] loss: 0.05198435721467831
[Epoch 6, Batch 1100] loss: 0.046213251870649404
[Epoch 6, Batch 1200] loss: 0.06173971540367347
[Epoch 6, Batch 1300] loss: 0.04414671583595919
[Epoch 6, Batch 1400] loss: 0.05378600934986025
[Epoch 6, Batch 1500] loss: 0.04368690160627011
[Epoch 6, Batch 1600] loss: 0.06154166197680752
[Epoch 6, Batch 1700] loss: 0.04290137061005225
[Epoch 6, Batch 1800] loss: 0.04291021536511835
[Epoch 6, Batch 1900] loss: 0.036935096577944936
[Epoch 6, Batch 2000] loss: 0.038457854266744106
[Epoch 6, Batch 2100] loss: 0.06608608076086966
[Epoch 6, Batch 2200] loss: 0.04467991194047499
[Epoch 6, Batch 2300] loss: 0.03460759614506969
[Epoch 6, Batch 2400] loss: 0.043293914533860514
[Epoch 6, Batch 2500] loss: 0.038950244084117
[Epoch 6, Batch 2600] loss: 0.040368440941019795
[Epoch 6, Batch 2700] loss: 0.04687463852198562
[Epoch 6, Batch 2800] loss: 0.05884173709200695
[Epoch 6, Batch 2900] loss: 0.0306926866316644
[Epoch 6, Batch 3000] loss: 0.048883324190537675
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9841
Overfitting: 0.0497
Best model saved at epoch 6 with validation loss: 0.0497
[Epoch 7, Batch 100] loss: 0.03479039559199009
[Epoch 7, Batch 200] loss: 0.024834409258328378
[Epoch 7, Batch 300] loss: 0.03896753910084953
[Epoch 7, Batch 400] loss: 0.040519816873420496
[Epoch 7, Batch 500] loss: 0.02557852354570059
[Epoch 7, Batch 600] loss: 0.039864940032421144
[Epoch 7, Batch 700] loss: 0.03937755359656876
[Epoch 7, Batch 800] loss: 0.02926190514175687
[Epoch 7, Batch 900] loss: 0.03359714246820658
[Epoch 7, Batch 1000] loss: 0.04468837705469923
[Epoch 7, Batch 1100] loss: 0.05358995534072165
[Epoch 7, Batch 1200] loss: 0.038078456239891235
[Epoch 7, Batch 1300] loss: 0.033847864022973226
[Epoch 7, Batch 1400] loss: 0.03504234176740283
[Epoch 7, Batch 1500] loss: 0.05374128185416339
[Epoch 7, Batch 1600] loss: 0.032471596246323314
[Epoch 7, Batch 1700] loss: 0.04274291782887303
[Epoch 7, Batch 1800] loss: 0.05011651808265014
[Epoch 7, Batch 1900] loss: 0.029663819193374366
[Epoch 7, Batch 2000] loss: 0.043446805904532086
[Epoch 7, Batch 2100] loss: 0.04998543614157825
[Epoch 7, Batch 2200] loss: 0.0406867863619118
[Epoch 7, Batch 2300] loss: 0.05206537777688936
[Epoch 7, Batch 2400] loss: 0.04882937146234326
[Epoch 7, Batch 2500] loss: 0.03369713408348616
[Epoch 7, Batch 2600] loss: 0.0390745303282165
[Epoch 7, Batch 2700] loss: 0.03890097386800335
[Epoch 7, Batch 2800] loss: 0.03134997999601183
[Epoch 7, Batch 2900] loss: 0.04155121860079816
[Epoch 7, Batch 3000] loss: 0.041652509515115524
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9836
Overfitting: 0.0535
[Epoch 8, Batch 100] loss: 0.025031281698175006
[Epoch 8, Batch 200] loss: 0.033445033003226855
[Epoch 8, Batch 300] loss: 0.04455464415324968
[Epoch 8, Batch 400] loss: 0.03150157693802612
[Epoch 8, Batch 500] loss: 0.03295501431231969
[Epoch 8, Batch 600] loss: 0.045167950881732394
[Epoch 8, Batch 700] loss: 0.04100917154923081
[Epoch 8, Batch 800] loss: 0.045489976149110586
[Epoch 8, Batch 900] loss: 0.036570696223061534
[Epoch 8, Batch 1000] loss: 0.03202003730315482
[Epoch 8, Batch 1100] loss: 0.04375529842509422
[Epoch 8, Batch 1200] loss: 0.02607721031847177
[Epoch 8, Batch 1300] loss: 0.03487457964598434
[Epoch 8, Batch 1400] loss: 0.041110529586585474
[Epoch 8, Batch 1500] loss: 0.03063078012666665
[Epoch 8, Batch 1600] loss: 0.03999740301369457
[Epoch 8, Batch 1700] loss: 0.028693403680226767
[Epoch 8, Batch 1800] loss: 0.023351181313337292
[Epoch 8, Batch 1900] loss: 0.028700915130903015
[Epoch 8, Batch 2000] loss: 0.03139486127984128
[Epoch 8, Batch 2100] loss: 0.02992511167867633
[Epoch 8, Batch 2200] loss: 0.023433127879688983
[Epoch 8, Batch 2300] loss: 0.03459063121234067
[Epoch 8, Batch 2400] loss: 0.040898585171962626
[Epoch 8, Batch 2500] loss: 0.035260648146795574
[Epoch 8, Batch 2600] loss: 0.04453299097898707
[Epoch 8, Batch 2700] loss: 0.03175107211849536
[Epoch 8, Batch 2800] loss: 0.03845644123415695
[Epoch 8, Batch 2900] loss: 0.03083506647089962
[Epoch 8, Batch 3000] loss: 0.03859417604573537
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9839
Overfitting: 0.0489
Best model saved at epoch 8 with validation loss: 0.0489
[Epoch 9, Batch 100] loss: 0.03749258746902342
[Epoch 9, Batch 200] loss: 0.047831325976439985
[Epoch 9, Batch 300] loss: 0.02762894928411697
[Epoch 9, Batch 400] loss: 0.03971732455902384
[Epoch 9, Batch 500] loss: 0.026159584462002384
[Epoch 9, Batch 600] loss: 0.04622061136426055
[Epoch 9, Batch 700] loss: 0.02690552519459743
[Epoch 9, Batch 800] loss: 0.03011795669066487
[Epoch 9, Batch 900] loss: 0.029938722853112266
[Epoch 9, Batch 1000] loss: 0.01685980118585576
[Epoch 9, Batch 1100] loss: 0.024075539695622865
[Epoch 9, Batch 1200] loss: 0.02321960231056437
[Epoch 9, Batch 1300] loss: 0.0418854768377787
[Epoch 9, Batch 1400] loss: 0.033353872391890034
[Epoch 9, Batch 1500] loss: 0.024546233565197327
[Epoch 9, Batch 1600] loss: 0.021999401063512777
[Epoch 9, Batch 1700] loss: 0.022206620098550046
[Epoch 9, Batch 1800] loss: 0.029670642304554348
[Epoch 9, Batch 1900] loss: 0.027435067552141847
[Epoch 9, Batch 2000] loss: 0.034747101486063914
[Epoch 9, Batch 2100] loss: 0.025119729982980062
[Epoch 9, Batch 2200] loss: 0.032327192862649096
[Epoch 9, Batch 2300] loss: 0.03159725659395917
[Epoch 9, Batch 2400] loss: 0.024883063205343205
[Epoch 9, Batch 2500] loss: 0.040240162177360615
[Epoch 9, Batch 2600] loss: 0.026149219920189353
[Epoch 9, Batch 2700] loss: 0.024992614747170593
[Epoch 9, Batch 2800] loss: 0.017701709544417098
[Epoch 9, Batch 2900] loss: 0.03512424598302459
[Epoch 9, Batch 3000] loss: 0.030485362502222415
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9825
Overfitting: 0.0560
[Epoch 10, Batch 100] loss: 0.021041345776320667
[Epoch 10, Batch 200] loss: 0.025290558380547737
[Epoch 10, Batch 300] loss: 0.019405774535625822
[Epoch 10, Batch 400] loss: 0.017788806133830805
[Epoch 10, Batch 500] loss: 0.028712597686353546
[Epoch 10, Batch 600] loss: 0.033907507965050175
[Epoch 10, Batch 700] loss: 0.02023927609818202
[Epoch 10, Batch 800] loss: 0.03210219250289811
[Epoch 10, Batch 900] loss: 0.015889527271938278
[Epoch 10, Batch 1000] loss: 0.02907439659029478
[Epoch 10, Batch 1100] loss: 0.01938964757369831
[Epoch 10, Batch 1200] loss: 0.03322449839291949
[Epoch 10, Batch 1300] loss: 0.029205376285863168
[Epoch 10, Batch 1400] loss: 0.013081752130165113
[Epoch 10, Batch 1500] loss: 0.026391051625614635
[Epoch 10, Batch 1600] loss: 0.02993829873681534
[Epoch 10, Batch 1700] loss: 0.027057983113336376
[Epoch 10, Batch 1800] loss: 0.024241099163155012
[Epoch 10, Batch 1900] loss: 0.020197679513148614
[Epoch 10, Batch 2000] loss: 0.03703851311089238
[Epoch 10, Batch 2100] loss: 0.04116298125438334
[Epoch 10, Batch 2200] loss: 0.030944818980060518
[Epoch 10, Batch 2300] loss: 0.02736879394069547
[Epoch 10, Batch 2400] loss: 0.03645289875377784
[Epoch 10, Batch 2500] loss: 0.031204933178742067
[Epoch 10, Batch 2600] loss: 0.02084386686619837
[Epoch 10, Batch 2700] loss: 0.02352204403883661
[Epoch 10, Batch 2800] loss: 0.021029871629871195
[Epoch 10, Batch 2900] loss: 0.02475493312085746
[Epoch 10, Batch 3000] loss: 0.03224956183421455
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0416
Validation Accuracy: 0.9875
Overfitting: 0.0416
Best model saved at epoch 10 with validation loss: 0.0416
[Epoch 11, Batch 100] loss: 0.034423308778059436
[Epoch 11, Batch 200] loss: 0.026158926427888217
[Epoch 11, Batch 300] loss: 0.021606553385208827
[Epoch 11, Batch 400] loss: 0.02915526712873543
[Epoch 11, Batch 500] loss: 0.023441749075136614
[Epoch 11, Batch 600] loss: 0.021890032136507215
[Epoch 11, Batch 700] loss: 0.02209119974864734
[Epoch 11, Batch 800] loss: 0.01709103929446428
[Epoch 11, Batch 900] loss: 0.021244216140294158
[Epoch 11, Batch 1000] loss: 0.02221319250338638
[Epoch 11, Batch 1100] loss: 0.022361444455309538
[Epoch 11, Batch 1200] loss: 0.023958121265968656
[Epoch 11, Batch 1300] loss: 0.020908889936254126
[Epoch 11, Batch 1400] loss: 0.027624045459051557
[Epoch 11, Batch 1500] loss: 0.029186981201746676
[Epoch 11, Batch 1600] loss: 0.021589622543360748
[Epoch 11, Batch 1700] loss: 0.01838519913217169
[Epoch 11, Batch 1800] loss: 0.02439035019961011
[Epoch 11, Batch 1900] loss: 0.024712721920732292
[Epoch 11, Batch 2000] loss: 0.02571615112341533
[Epoch 11, Batch 2100] loss: 0.027223236553763856
[Epoch 11, Batch 2200] loss: 0.031852633811795386
[Epoch 11, Batch 2300] loss: 0.02259167471267574
[Epoch 11, Batch 2400] loss: 0.01947839577687773
[Epoch 11, Batch 2500] loss: 0.0306253895721602
[Epoch 11, Batch 2600] loss: 0.015262124172077165
[Epoch 11, Batch 2700] loss: 0.014357261538607417
[Epoch 11, Batch 2800] loss: 0.028090758891121368
[Epoch 11, Batch 2900] loss: 0.027927859862447803
[Epoch 11, Batch 3000] loss: 0.014778543209286
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9845
Overfitting: 0.0492
[Epoch 12, Batch 100] loss: 0.015267683206548099
[Epoch 12, Batch 200] loss: 0.01196958532447752
[Epoch 12, Batch 300] loss: 0.011514151557894365
[Epoch 12, Batch 400] loss: 0.02337810238794191
[Epoch 12, Batch 500] loss: 0.014733230108540739
[Epoch 12, Batch 600] loss: 0.016134056948067153
[Epoch 12, Batch 700] loss: 0.019075904505480138
[Epoch 12, Batch 800] loss: 0.03734846007526357
[Epoch 12, Batch 900] loss: 0.027004730792705232
[Epoch 12, Batch 1000] loss: 0.023785659819623106
[Epoch 12, Batch 1100] loss: 0.02384105565659411
[Epoch 12, Batch 1200] loss: 0.018083922095065645
[Epoch 12, Batch 1300] loss: 0.025374217339885943
[Epoch 12, Batch 1400] loss: 0.023895148436931777
[Epoch 12, Batch 1500] loss: 0.022841276498111254
[Epoch 12, Batch 1600] loss: 0.02519827082174743
[Epoch 12, Batch 1700] loss: 0.023309286156727466
[Epoch 12, Batch 1800] loss: 0.014317991759453435
[Epoch 12, Batch 1900] loss: 0.019254868200805506
[Epoch 12, Batch 2000] loss: 0.01837056012105677
[Epoch 12, Batch 2100] loss: 0.02672790428659937
[Epoch 12, Batch 2200] loss: 0.02907126527017681
[Epoch 12, Batch 2300] loss: 0.022372445267974397
[Epoch 12, Batch 2400] loss: 0.020607065610529388
[Epoch 12, Batch 2500] loss: 0.025158798327775
[Epoch 12, Batch 2600] loss: 0.025679058364985394
[Epoch 12, Batch 2700] loss: 0.02131761108415958
[Epoch 12, Batch 2800] loss: 0.02226600597747165
[Epoch 12, Batch 2900] loss: 0.01780993360618595
[Epoch 12, Batch 3000] loss: 0.015505992077305564
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0407
Validation Accuracy: 0.9888
Overfitting: 0.0407
Best model saved at epoch 12 with validation loss: 0.0407
[Epoch 13, Batch 100] loss: 0.012854707172245981
[Epoch 13, Batch 200] loss: 0.01603831584852742
[Epoch 13, Batch 300] loss: 0.01841494758682529
[Epoch 13, Batch 400] loss: 0.01890687764811446
[Epoch 13, Batch 500] loss: 0.028822543849200882
[Epoch 13, Batch 600] loss: 0.01396293586200045
[Epoch 13, Batch 700] loss: 0.020625093220769487
[Epoch 13, Batch 800] loss: 0.01833334975570324
[Epoch 13, Batch 900] loss: 0.01820260258522467
[Epoch 13, Batch 1000] loss: 0.014674956850867601
[Epoch 13, Batch 1100] loss: 0.012117973317363067
[Epoch 13, Batch 1200] loss: 0.014308099697809667
[Epoch 13, Batch 1300] loss: 0.010806798955381964
[Epoch 13, Batch 1400] loss: 0.025431119495660823
[Epoch 13, Batch 1500] loss: 0.02050189209938253
[Epoch 13, Batch 1600] loss: 0.03128096561747953
[Epoch 13, Batch 1700] loss: 0.02226379704923602
[Epoch 13, Batch 1800] loss: 0.015776956113022607
[Epoch 13, Batch 1900] loss: 0.009651350480162364
[Epoch 13, Batch 2000] loss: 0.026316272960793866
[Epoch 13, Batch 2100] loss: 0.020592890399530005
[Epoch 13, Batch 2200] loss: 0.014462480119054816
[Epoch 13, Batch 2300] loss: 0.014737396435521077
[Epoch 13, Batch 2400] loss: 0.013909187338904304
[Epoch 13, Batch 2500] loss: 0.026414953389648874
[Epoch 13, Batch 2600] loss: 0.011658468270106824
[Epoch 13, Batch 2700] loss: 0.021397529879286593
[Epoch 13, Batch 2800] loss: 0.022767777697736163
[Epoch 13, Batch 2900] loss: 0.017015326382497732
[Epoch 13, Batch 3000] loss: 0.02159308047797822
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9866
Overfitting: 0.0446
[Epoch 14, Batch 100] loss: 0.022910244143640738
[Epoch 14, Batch 200] loss: 0.012854792203033866
[Epoch 14, Batch 300] loss: 0.021000031833264075
[Epoch 14, Batch 400] loss: 0.014570600192782876
[Epoch 14, Batch 500] loss: 0.006166073265967497
[Epoch 14, Batch 600] loss: 0.01659031359693472
[Epoch 14, Batch 700] loss: 0.0073267027813926685
[Epoch 14, Batch 800] loss: 0.012087568604511035
[Epoch 14, Batch 900] loss: 0.014323431541124592
[Epoch 14, Batch 1000] loss: 0.034680876995153084
[Epoch 14, Batch 1100] loss: 0.015646457165130415
[Epoch 14, Batch 1200] loss: 0.015437467862102493
[Epoch 14, Batch 1300] loss: 0.029653568149369675
[Epoch 14, Batch 1400] loss: 0.021390352199668995
[Epoch 14, Batch 1500] loss: 0.010362276975865826
[Epoch 14, Batch 1600] loss: 0.026270636728368116
[Epoch 14, Batch 1700] loss: 0.022102168597157287
[Epoch 14, Batch 1800] loss: 0.016283099089532696
[Epoch 14, Batch 1900] loss: 0.019885869790159633
[Epoch 14, Batch 2000] loss: 0.010519254056926003
[Epoch 14, Batch 2100] loss: 0.022730096170998876
[Epoch 14, Batch 2200] loss: 0.01355733754222456
[Epoch 14, Batch 2300] loss: 0.013009308007276559
[Epoch 14, Batch 2400] loss: 0.01937558478430219
[Epoch 14, Batch 2500] loss: 0.013212840779378893
[Epoch 14, Batch 2600] loss: 0.020015336011474573
[Epoch 14, Batch 2700] loss: 0.01213519034637102
[Epoch 14, Batch 2800] loss: 0.019388953145826237
[Epoch 14, Batch 2900] loss: 0.011896795083812322
[Epoch 14, Batch 3000] loss: 0.009012061135449586
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9854
Overfitting: 0.0507
[Epoch 15, Batch 100] loss: 0.018650180370186717
[Epoch 15, Batch 200] loss: 0.014198477872250806
[Epoch 15, Batch 300] loss: 0.01580290683923522
[Epoch 15, Batch 400] loss: 0.01325171625296207
[Epoch 15, Batch 500] loss: 0.013872122450347888
[Epoch 15, Batch 600] loss: 0.019251901017705676
[Epoch 15, Batch 700] loss: 0.016662278515541404
[Epoch 15, Batch 800] loss: 0.014333324799245019
[Epoch 15, Batch 900] loss: 0.011753421270905165
[Epoch 15, Batch 1000] loss: 0.015974448493288947
[Epoch 15, Batch 1100] loss: 0.012440703438251148
[Epoch 15, Batch 1200] loss: 0.014146244189896606
[Epoch 15, Batch 1300] loss: 0.011667031619108457
[Epoch 15, Batch 1400] loss: 0.01652026132847823
[Epoch 15, Batch 1500] loss: 0.012750786100878032
[Epoch 15, Batch 1600] loss: 0.019445933825609246
[Epoch 15, Batch 1700] loss: 0.01437829997839799
[Epoch 15, Batch 1800] loss: 0.010327314107744314
[Epoch 15, Batch 1900] loss: 0.01402276005010208
[Epoch 15, Batch 2000] loss: 0.016260303924495928
[Epoch 15, Batch 2100] loss: 0.018164133363497967
[Epoch 15, Batch 2200] loss: 0.018422806635499
[Epoch 15, Batch 2300] loss: 0.005585755905685801
[Epoch 15, Batch 2400] loss: 0.013185785989517172
[Epoch 15, Batch 2500] loss: 0.015880983595307045
[Epoch 15, Batch 2600] loss: 0.016108764044545296
[Epoch 15, Batch 2700] loss: 0.02907901499853324
[Epoch 15, Batch 2800] loss: 0.013135581269252725
[Epoch 15, Batch 2900] loss: 0.013809786015390273
[Epoch 15, Batch 3000] loss: 0.027041265462285084
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9870
Overfitting: 0.0472
[Epoch 16, Batch 100] loss: 0.01231853680430504
[Epoch 16, Batch 200] loss: 0.009202590979821252
[Epoch 16, Batch 300] loss: 0.004670550954779173
[Epoch 16, Batch 400] loss: 0.012417672716492235
[Epoch 16, Batch 500] loss: 0.016148505203536844
[Epoch 16, Batch 600] loss: 0.007211948984131595
[Epoch 16, Batch 700] loss: 0.012510182428036387
[Epoch 16, Batch 800] loss: 0.010892053353181837
[Epoch 16, Batch 900] loss: 0.014207158005447126
[Epoch 16, Batch 1000] loss: 0.010000277731614915
[Epoch 16, Batch 1100] loss: 0.011159777598186338
[Epoch 16, Batch 1200] loss: 0.014051873967455322
[Epoch 16, Batch 1300] loss: 0.010242163875100232
[Epoch 16, Batch 1400] loss: 0.0059733335140708735
[Epoch 16, Batch 1500] loss: 0.004719322676028242
[Epoch 16, Batch 1600] loss: 0.02158156175520162
[Epoch 16, Batch 1700] loss: 0.020934553390125076
[Epoch 16, Batch 1800] loss: 0.01859305480144485
[Epoch 16, Batch 1900] loss: 0.005432823302808174
[Epoch 16, Batch 2000] loss: 0.01422633315265557
[Epoch 16, Batch 2100] loss: 0.007618153736639215
[Epoch 16, Batch 2200] loss: 0.012670676873003685
[Epoch 16, Batch 2300] loss: 0.016044478737339888
[Epoch 16, Batch 2400] loss: 0.010857691536766651
[Epoch 16, Batch 2500] loss: 0.02375273563079645
[Epoch 16, Batch 2600] loss: 0.016529765438062897
[Epoch 16, Batch 2700] loss: 0.012625050723599998
[Epoch 16, Batch 2800] loss: 0.015354162536923469
[Epoch 16, Batch 2900] loss: 0.01973233314090976
[Epoch 16, Batch 3000] loss: 0.015315010066142349
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9870
Overfitting: 0.0453
[Epoch 17, Batch 100] loss: 0.005849005021791527
[Epoch 17, Batch 200] loss: 0.008217758590928952
[Epoch 17, Batch 300] loss: 0.007507541720433437
[Epoch 17, Batch 400] loss: 0.010607195149868858
[Epoch 17, Batch 500] loss: 0.0077954539471647875
[Epoch 17, Batch 600] loss: 0.01742386652132154
[Epoch 17, Batch 700] loss: 0.014953420505285066
[Epoch 17, Batch 800] loss: 0.008522107033923022
[Epoch 17, Batch 900] loss: 0.012324493724481727
[Epoch 17, Batch 1000] loss: 0.0120055395857662
[Epoch 17, Batch 1100] loss: 0.008524050623018411
[Epoch 17, Batch 1200] loss: 0.0062698146157254084
[Epoch 17, Batch 1300] loss: 0.017183943852414812
[Epoch 17, Batch 1400] loss: 0.016960181783633742
[Epoch 17, Batch 1500] loss: 0.022271832348596945
[Epoch 17, Batch 1600] loss: 0.005886603913700128
[Epoch 17, Batch 1700] loss: 0.017510094613908223
[Epoch 17, Batch 1800] loss: 0.0050992068964933425
[Epoch 17, Batch 1900] loss: 0.013906741590690217
[Epoch 17, Batch 2000] loss: 0.014000496697335621
[Epoch 17, Batch 2100] loss: 0.018923149042634577
[Epoch 17, Batch 2200] loss: 0.010970196304970158
[Epoch 17, Batch 2300] loss: 0.005458249404509843
[Epoch 17, Batch 2400] loss: 0.004836912955744311
[Epoch 17, Batch 2500] loss: 0.008392333590650196
[Epoch 17, Batch 2600] loss: 0.011662658924651624
[Epoch 17, Batch 2700] loss: 0.013810444776731856
[Epoch 17, Batch 2800] loss: 0.00844994345257419
[Epoch 17, Batch 2900] loss: 0.012388106573689583
[Epoch 17, Batch 3000] loss: 0.006984035063851479
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9883
Overfitting: 0.0437
[Epoch 18, Batch 100] loss: 0.01457591768783459
[Epoch 18, Batch 200] loss: 0.011373141100248176
[Epoch 18, Batch 300] loss: 0.012609630093202213
[Epoch 18, Batch 400] loss: 0.016228987071426674
[Epoch 18, Batch 500] loss: 0.01215575906668164
[Epoch 18, Batch 600] loss: 0.008395107154592551
[Epoch 18, Batch 700] loss: 0.007379693492921433
[Epoch 18, Batch 800] loss: 0.010141765586431574
[Epoch 18, Batch 900] loss: 0.005983249446780974
[Epoch 18, Batch 1000] loss: 0.014416783118849707
[Epoch 18, Batch 1100] loss: 0.010462919707169931
[Epoch 18, Batch 1200] loss: 0.009951700730075572
[Epoch 18, Batch 1300] loss: 0.010009717842967803
[Epoch 18, Batch 1400] loss: 0.006822447931590432
[Epoch 18, Batch 1500] loss: 0.009072510242383487
[Epoch 18, Batch 1600] loss: 0.008205627086351797
[Epoch 18, Batch 1700] loss: 0.013108199219468588
[Epoch 18, Batch 1800] loss: 0.008655852665860948
[Epoch 18, Batch 1900] loss: 0.00813180966701566
[Epoch 18, Batch 2000] loss: 0.008382012952247352
[Epoch 18, Batch 2100] loss: 0.009127899134791733
[Epoch 18, Batch 2200] loss: 0.005754419374106874
[Epoch 18, Batch 2300] loss: 0.022636416853256378
[Epoch 18, Batch 2400] loss: 0.010270291485549024
[Epoch 18, Batch 2500] loss: 0.017305825774155893
[Epoch 18, Batch 2600] loss: 0.009187622221834318
[Epoch 18, Batch 2700] loss: 0.0184195355789052
[Epoch 18, Batch 2800] loss: 0.014313257890216846
[Epoch 18, Batch 2900] loss: 0.010630386543634813
[Epoch 18, Batch 3000] loss: 0.00798693490878577
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0423
Validation Accuracy: 0.9887
Overfitting: 0.0423
[Epoch 19, Batch 100] loss: 0.008508967465750174
[Epoch 19, Batch 200] loss: 0.013260184914622641
[Epoch 19, Batch 300] loss: 0.009995214572700205
[Epoch 19, Batch 400] loss: 0.0036227142948973778
[Epoch 19, Batch 500] loss: 0.0075640253932351695
[Epoch 19, Batch 600] loss: 0.007187085816158287
[Epoch 19, Batch 700] loss: 0.005024716119444292
[Epoch 19, Batch 800] loss: 0.014467080924687252
[Epoch 19, Batch 900] loss: 0.008054676653873685
[Epoch 19, Batch 1000] loss: 0.01346211370772835
[Epoch 19, Batch 1100] loss: 0.0064926990990079505
[Epoch 19, Batch 1200] loss: 0.006583307349965253
[Epoch 19, Batch 1300] loss: 0.007093483631033451
[Epoch 19, Batch 1400] loss: 0.008329506436521115
[Epoch 19, Batch 1500] loss: 0.009339147366645192
[Epoch 19, Batch 1600] loss: 0.013611207106469009
[Epoch 19, Batch 1700] loss: 0.0080881017712818
[Epoch 19, Batch 1800] loss: 0.012273751377115331
[Epoch 19, Batch 1900] loss: 0.007070459740752995
[Epoch 19, Batch 2000] loss: 0.006236221935344019
[Epoch 19, Batch 2100] loss: 0.006271966416143186
[Epoch 19, Batch 2200] loss: 0.008092589153511654
[Epoch 19, Batch 2300] loss: 0.007126429801883205
[Epoch 19, Batch 2400] loss: 0.011093904810177264
[Epoch 19, Batch 2500] loss: 0.009321741231451597
[Epoch 19, Batch 2600] loss: 0.00725123073044415
[Epoch 19, Batch 2700] loss: 0.00923532564719153
[Epoch 19, Batch 2800] loss: 0.01213751778101141
[Epoch 19, Batch 2900] loss: 0.013319778517773101
[Epoch 19, Batch 3000] loss: 0.012328327654145141
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0413
Validation Accuracy: 0.9888
Overfitting: 0.0413
[Epoch 20, Batch 100] loss: 0.004973628164214006
[Epoch 20, Batch 200] loss: 0.006793293667788021
[Epoch 20, Batch 300] loss: 0.015084400629984885
[Epoch 20, Batch 400] loss: 0.00728107370557268
[Epoch 20, Batch 500] loss: 0.00723683619828762
[Epoch 20, Batch 600] loss: 0.007579498903849072
[Epoch 20, Batch 700] loss: 0.0047071645573225854
[Epoch 20, Batch 800] loss: 0.018230725543971857
[Epoch 20, Batch 900] loss: 0.016657562632215104
[Epoch 20, Batch 1000] loss: 0.006423271685684994
[Epoch 20, Batch 1100] loss: 0.00515253701839356
[Epoch 20, Batch 1200] loss: 0.004089855395890254
[Epoch 20, Batch 1300] loss: 0.008133256760711447
[Epoch 20, Batch 1400] loss: 0.007962419618397689
[Epoch 20, Batch 1500] loss: 0.007225396254425504
[Epoch 20, Batch 1600] loss: 0.005851807870312769
[Epoch 20, Batch 1700] loss: 0.003302245177204668
[Epoch 20, Batch 1800] loss: 0.011775818624037128
[Epoch 20, Batch 1900] loss: 0.006942533531278059
[Epoch 20, Batch 2000] loss: 0.0077235964268311365
[Epoch 20, Batch 2100] loss: 0.004330516555824033
[Epoch 20, Batch 2200] loss: 0.006933092029503314
[Epoch 20, Batch 2300] loss: 0.008909622094140559
[Epoch 20, Batch 2400] loss: 0.012328753797100944
[Epoch 20, Batch 2500] loss: 0.016844824899599188
[Epoch 20, Batch 2600] loss: 0.00925739665227411
[Epoch 20, Batch 2700] loss: 0.015156818364084756
[Epoch 20, Batch 2800] loss: 0.007725683560270227
[Epoch 20, Batch 2900] loss: 0.014146587706090941
[Epoch 20, Batch 3000] loss: 0.006151465140665096
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0433
Validation Accuracy: 0.9887
Overfitting: 0.0433
[Epoch 21, Batch 100] loss: 0.0030253885929187162
[Epoch 21, Batch 200] loss: 0.0044070687626845025
[Epoch 21, Batch 300] loss: 0.002732855049023044
[Epoch 21, Batch 400] loss: 0.0047477186576293205
[Epoch 21, Batch 500] loss: 0.0076646997972193275
[Epoch 21, Batch 600] loss: 0.004736344041994016
[Epoch 21, Batch 700] loss: 0.008178004441738267
[Epoch 21, Batch 800] loss: 0.0036934139111417606
[Epoch 21, Batch 900] loss: 0.0055154468886007635
[Epoch 21, Batch 1000] loss: 0.014347022979636677
[Epoch 21, Batch 1100] loss: 0.0065240715625350275
[Epoch 21, Batch 1200] loss: 0.006532248876860649
[Epoch 21, Batch 1300] loss: 0.007165635754968207
[Epoch 21, Batch 1400] loss: 0.007832527807777297
[Epoch 21, Batch 1500] loss: 0.01090221297520202
[Epoch 21, Batch 1600] loss: 0.005476147666759062
[Epoch 21, Batch 1700] loss: 0.006788562079045732
[Epoch 21, Batch 1800] loss: 0.005840189934376099
[Epoch 21, Batch 1900] loss: 0.004689483191723412
[Epoch 21, Batch 2000] loss: 0.0059589459083736075
[Epoch 21, Batch 2100] loss: 0.006808028411923033
[Epoch 21, Batch 2200] loss: 0.006967357175585676
[Epoch 21, Batch 2300] loss: 0.006576463421756671
[Epoch 21, Batch 2400] loss: 0.0066227270450985995
[Epoch 21, Batch 2500] loss: 0.004824486744162186
[Epoch 21, Batch 2600] loss: 0.00860138266492868
[Epoch 21, Batch 2700] loss: 0.007354202737642482
[Epoch 21, Batch 2800] loss: 0.008111656693006352
[Epoch 21, Batch 2900] loss: 0.021684030797714512
[Epoch 21, Batch 3000] loss: 0.0037349614559525433
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0424
Validation Accuracy: 0.9892
Overfitting: 0.0424
[Epoch 22, Batch 100] loss: 0.002108552587417307
[Epoch 22, Batch 200] loss: 0.0035070354058461817
[Epoch 22, Batch 300] loss: 0.00609117127008858
[Epoch 22, Batch 400] loss: 0.004888849852904969
[Epoch 22, Batch 500] loss: 0.006980772707206598
[Epoch 22, Batch 600] loss: 0.0054482931004258715
[Epoch 22, Batch 700] loss: 0.006552241777631025
[Epoch 22, Batch 800] loss: 0.005412679586387412
[Epoch 22, Batch 900] loss: 0.0031354099061036323
[Epoch 22, Batch 1000] loss: 0.003911158439233304
[Epoch 22, Batch 1100] loss: 0.00632465288940466
[Epoch 22, Batch 1200] loss: 0.007341589298021063
[Epoch 22, Batch 1300] loss: 0.00544737184929545
[Epoch 22, Batch 1400] loss: 0.008378055124953505
[Epoch 22, Batch 1500] loss: 0.009263666845488388
[Epoch 22, Batch 1600] loss: 0.016337471233282486
[Epoch 22, Batch 1700] loss: 0.010399033214382599
[Epoch 22, Batch 1800] loss: 0.00804053980248966
[Epoch 22, Batch 1900] loss: 0.013132279162265377
[Epoch 22, Batch 2000] loss: 0.007001609412855032
[Epoch 22, Batch 2100] loss: 0.007954703149750912
[Epoch 22, Batch 2200] loss: 0.0026234804871569394
[Epoch 22, Batch 2300] loss: 0.011508542252474854
[Epoch 22, Batch 2400] loss: 0.012681412448937408
[Epoch 22, Batch 2500] loss: 0.006837038286441839
[Epoch 22, Batch 2600] loss: 0.00420623104410879
[Epoch 22, Batch 2700] loss: 0.008826776962318945
[Epoch 22, Batch 2800] loss: 0.00903496064741205
[Epoch 22, Batch 2900] loss: 0.006719324140242407
[Epoch 22, Batch 3000] loss: 0.0057913147082854265
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0411
Validation Accuracy: 0.9894
Overfitting: 0.0411
[Epoch 23, Batch 100] loss: 0.003237694568138636
[Epoch 23, Batch 200] loss: 0.002938248134432797
[Epoch 23, Batch 300] loss: 0.006670796151122431
[Epoch 23, Batch 400] loss: 0.00940935915476416
[Epoch 23, Batch 500] loss: 0.002195427366871172
[Epoch 23, Batch 600] loss: 0.0026189745630153995
[Epoch 23, Batch 700] loss: 0.004575298970170252
[Epoch 23, Batch 800] loss: 0.0027637577585591087
[Epoch 23, Batch 900] loss: 0.0044097178725900224
[Epoch 23, Batch 1000] loss: 0.007378579210044336
[Epoch 23, Batch 1100] loss: 0.009978020396188185
[Epoch 23, Batch 1200] loss: 0.013205987042611299
[Epoch 23, Batch 1300] loss: 0.0059272686088047526
[Epoch 23, Batch 1400] loss: 0.00419647365882156
[Epoch 23, Batch 1500] loss: 0.007951557407562291
[Epoch 23, Batch 1600] loss: 0.004710376865464241
[Epoch 23, Batch 1700] loss: 0.0025070564181828557
[Epoch 23, Batch 1800] loss: 0.011929540688638553
[Epoch 23, Batch 1900] loss: 0.006793663083999491
[Epoch 23, Batch 2000] loss: 0.004333973435841472
[Epoch 23, Batch 2100] loss: 0.007071309077641672
[Epoch 23, Batch 2200] loss: 0.0035450314238596545
[Epoch 23, Batch 2300] loss: 0.0031931848971476027
[Epoch 23, Batch 2400] loss: 0.002383019934491131
[Epoch 23, Batch 2500] loss: 0.006900536088567151
[Epoch 23, Batch 2600] loss: 0.005803502338874295
[Epoch 23, Batch 2700] loss: 0.005004569315660774
[Epoch 23, Batch 2800] loss: 0.007022700912907567
[Epoch 23, Batch 2900] loss: 0.016899952659418887
[Epoch 23, Batch 3000] loss: 0.004400402115743418
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9891
Overfitting: 0.0430
[Epoch 24, Batch 100] loss: 0.0024291323393026685
[Epoch 24, Batch 200] loss: 0.005530360381931132
[Epoch 24, Batch 300] loss: 0.004562136642718997
[Epoch 24, Batch 400] loss: 0.0033421896575345045
[Epoch 24, Batch 500] loss: 0.0022442037555811113
[Epoch 24, Batch 600] loss: 0.004396371867288735
[Epoch 24, Batch 700] loss: 0.0014939492804387556
[Epoch 24, Batch 800] loss: 0.005280198920904695
[Epoch 24, Batch 900] loss: 0.006371450556957825
[Epoch 24, Batch 1000] loss: 0.007327819405832088
[Epoch 24, Batch 1100] loss: 0.0017836718108264905
[Epoch 24, Batch 1200] loss: 0.0066845455354132355
[Epoch 24, Batch 1300] loss: 0.009242270165389073
[Epoch 24, Batch 1400] loss: 0.014503560512457625
[Epoch 24, Batch 1500] loss: 0.0026628557028163867
[Epoch 24, Batch 1600] loss: 0.003352802181568677
[Epoch 24, Batch 1700] loss: 0.009108462854110258
[Epoch 24, Batch 1800] loss: 0.00976568912670814
[Epoch 24, Batch 1900] loss: 0.0017806234494622687
[Epoch 24, Batch 2000] loss: 0.006147652535828456
[Epoch 24, Batch 2100] loss: 0.0037436934948823363
[Epoch 24, Batch 2200] loss: 0.0011302868234088236
[Epoch 24, Batch 2300] loss: 0.004337953610835541
[Epoch 24, Batch 2400] loss: 0.002009192431229394
[Epoch 24, Batch 2500] loss: 0.0036670803920367235
[Epoch 24, Batch 2600] loss: 0.004972343887848183
[Epoch 24, Batch 2700] loss: 0.010386156166980527
[Epoch 24, Batch 2800] loss: 0.0054880488138064724
[Epoch 24, Batch 2900] loss: 0.005433722818058868
[Epoch 24, Batch 3000] loss: 0.004033276072273111
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0432
Validation Accuracy: 0.9892
Overfitting: 0.0432
Fold 1 validation loss: 0.0432
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2975046253204345
[Epoch 1, Batch 200] loss: 2.2779022312164305
[Epoch 1, Batch 300] loss: 2.2265634989738463
[Epoch 1, Batch 400] loss: 2.0684363794326783
[Epoch 1, Batch 500] loss: 1.4076319950819016
[Epoch 1, Batch 600] loss: 0.7532255220413208
[Epoch 1, Batch 700] loss: 0.5668592573702336
[Epoch 1, Batch 800] loss: 0.46749437317252157
[Epoch 1, Batch 900] loss: 0.4193054204434156
[Epoch 1, Batch 1000] loss: 0.3946586837619543
[Epoch 1, Batch 1100] loss: 0.3736849947273731
[Epoch 1, Batch 1200] loss: 0.3055669427663088
[Epoch 1, Batch 1300] loss: 0.3244581761583686
[Epoch 1, Batch 1400] loss: 0.3435165483877063
[Epoch 1, Batch 1500] loss: 0.28637415524572135
[Epoch 1, Batch 1600] loss: 0.24955938735976815
[Epoch 1, Batch 1700] loss: 0.2898248649388552
[Epoch 1, Batch 1800] loss: 0.22859658582136036
[Epoch 1, Batch 1900] loss: 0.2204738909751177
[Epoch 1, Batch 2000] loss: 0.20458509595133365
[Epoch 1, Batch 2100] loss: 0.20833668721839785
[Epoch 1, Batch 2200] loss: 0.20571658845990895
[Epoch 1, Batch 2300] loss: 0.23201798532158135
[Epoch 1, Batch 2400] loss: 0.17314878346398474
[Epoch 1, Batch 2500] loss: 0.20276636976748705
[Epoch 1, Batch 2600] loss: 0.20603107884526253
[Epoch 1, Batch 2700] loss: 0.20056290521286427
[Epoch 1, Batch 2800] loss: 0.19474104775115847
[Epoch 1, Batch 2900] loss: 0.18442400109022855
[Epoch 1, Batch 3000] loss: 0.1822066090069711
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1738
Validation Accuracy: 0.9469
Overfitting: 0.1738
Best model saved at epoch 1 with validation loss: 0.1738
[Epoch 2, Batch 100] loss: 0.1763693144917488
[Epoch 2, Batch 200] loss: 0.17667402987368405
[Epoch 2, Batch 300] loss: 0.16436042455025018
[Epoch 2, Batch 400] loss: 0.13606745937373488
[Epoch 2, Batch 500] loss: 0.15866225872421638
[Epoch 2, Batch 600] loss: 0.14097749690525233
[Epoch 2, Batch 700] loss: 0.14494611757807432
[Epoch 2, Batch 800] loss: 0.1189802273036912
[Epoch 2, Batch 900] loss: 0.1260047466121614
[Epoch 2, Batch 1000] loss: 0.12329057646449655
[Epoch 2, Batch 1100] loss: 0.11564093425287865
[Epoch 2, Batch 1200] loss: 0.1586514027323574
[Epoch 2, Batch 1300] loss: 0.1345915417186916
[Epoch 2, Batch 1400] loss: 0.1410707018803805
[Epoch 2, Batch 1500] loss: 0.12084335574880242
[Epoch 2, Batch 1600] loss: 0.11914606828708202
[Epoch 2, Batch 1700] loss: 0.13836929359007627
[Epoch 2, Batch 1800] loss: 0.14137157367542386
[Epoch 2, Batch 1900] loss: 0.09730374841485173
[Epoch 2, Batch 2000] loss: 0.10812389533501118
[Epoch 2, Batch 2100] loss: 0.11541179566644132
[Epoch 2, Batch 2200] loss: 0.10788954413030297
[Epoch 2, Batch 2300] loss: 0.11058638462331145
[Epoch 2, Batch 2400] loss: 0.1030853124242276
[Epoch 2, Batch 2500] loss: 0.07897632808424532
[Epoch 2, Batch 2600] loss: 0.08264747213339434
[Epoch 2, Batch 2700] loss: 0.1033407569117844
[Epoch 2, Batch 2800] loss: 0.0978789390809834
[Epoch 2, Batch 2900] loss: 0.10871112361550331
[Epoch 2, Batch 3000] loss: 0.10980605165939777
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1102
Validation Accuracy: 0.9657
Overfitting: 0.1102
Best model saved at epoch 2 with validation loss: 0.1102
[Epoch 3, Batch 100] loss: 0.08049365606158972
[Epoch 3, Batch 200] loss: 0.09847580879926682
[Epoch 3, Batch 300] loss: 0.11201106937136501
[Epoch 3, Batch 400] loss: 0.08676499839522876
[Epoch 3, Batch 500] loss: 0.0785543313366361
[Epoch 3, Batch 600] loss: 0.09933841638732702
[Epoch 3, Batch 700] loss: 0.10778018137207254
[Epoch 3, Batch 800] loss: 0.08332428154302761
[Epoch 3, Batch 900] loss: 0.083636101098964
[Epoch 3, Batch 1000] loss: 0.06883166566141881
[Epoch 3, Batch 1100] loss: 0.0916568406787701
[Epoch 3, Batch 1200] loss: 0.0704207692365162
[Epoch 3, Batch 1300] loss: 0.08009983535390347
[Epoch 3, Batch 1400] loss: 0.11349933415069245
[Epoch 3, Batch 1500] loss: 0.07130980093963445
[Epoch 3, Batch 1600] loss: 0.08508229109691456
[Epoch 3, Batch 1700] loss: 0.06838550901506096
[Epoch 3, Batch 1800] loss: 0.0783485970494803
[Epoch 3, Batch 1900] loss: 0.08398515939014033
[Epoch 3, Batch 2000] loss: 0.08740671944105997
[Epoch 3, Batch 2100] loss: 0.09014751821989193
[Epoch 3, Batch 2200] loss: 0.090411368093919
[Epoch 3, Batch 2300] loss: 0.07179231024230831
[Epoch 3, Batch 2400] loss: 0.09597168229985982
[Epoch 3, Batch 2500] loss: 0.06934217065223493
[Epoch 3, Batch 2600] loss: 0.07762624508934096
[Epoch 3, Batch 2700] loss: 0.06668222629174124
[Epoch 3, Batch 2800] loss: 0.06888524691690691
[Epoch 3, Batch 2900] loss: 0.08940294247004203
[Epoch 3, Batch 3000] loss: 0.08831668217666447
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0799
Validation Accuracy: 0.9758
Overfitting: 0.0799
Best model saved at epoch 3 with validation loss: 0.0799
[Epoch 4, Batch 100] loss: 0.0695735592104029
[Epoch 4, Batch 200] loss: 0.05461971651238855
[Epoch 4, Batch 300] loss: 0.05161770968756173
[Epoch 4, Batch 400] loss: 0.054853304567805024
[Epoch 4, Batch 500] loss: 0.08718567315896507
[Epoch 4, Batch 600] loss: 0.07917550070560538
[Epoch 4, Batch 700] loss: 0.059330334566766396
[Epoch 4, Batch 800] loss: 0.07763740349560976
[Epoch 4, Batch 900] loss: 0.08317664775648154
[Epoch 4, Batch 1000] loss: 0.06351535035064444
[Epoch 4, Batch 1100] loss: 0.06474088581744582
[Epoch 4, Batch 1200] loss: 0.06333250787924044
[Epoch 4, Batch 1300] loss: 0.05919477836927399
[Epoch 4, Batch 1400] loss: 0.07745006056968123
[Epoch 4, Batch 1500] loss: 0.05711915561580099
[Epoch 4, Batch 1600] loss: 0.06988592339679599
[Epoch 4, Batch 1700] loss: 0.0724933286709711
[Epoch 4, Batch 1800] loss: 0.05238338737486629
[Epoch 4, Batch 1900] loss: 0.08120425516273827
[Epoch 4, Batch 2000] loss: 0.0878645652544219
[Epoch 4, Batch 2100] loss: 0.0548259635141585
[Epoch 4, Batch 2200] loss: 0.05662494171556318
[Epoch 4, Batch 2300] loss: 0.06911497852706816
[Epoch 4, Batch 2400] loss: 0.052299666455946865
[Epoch 4, Batch 2500] loss: 0.05788472282409202
[Epoch 4, Batch 2600] loss: 0.057751821003621445
[Epoch 4, Batch 2700] loss: 0.05996744952572044
[Epoch 4, Batch 2800] loss: 0.07484903678763657
[Epoch 4, Batch 2900] loss: 0.06066993505053688
[Epoch 4, Batch 3000] loss: 0.05646991201298079
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0759
Validation Accuracy: 0.9765
Overfitting: 0.0759
Best model saved at epoch 4 with validation loss: 0.0759
[Epoch 5, Batch 100] loss: 0.05728183923638426
[Epoch 5, Batch 200] loss: 0.04887422291794792
[Epoch 5, Batch 300] loss: 0.059307528004283086
[Epoch 5, Batch 400] loss: 0.0567880858015269
[Epoch 5, Batch 500] loss: 0.04695168259670027
[Epoch 5, Batch 600] loss: 0.06599867080745753
[Epoch 5, Batch 700] loss: 0.06717339083144908
[Epoch 5, Batch 800] loss: 0.04847264961048495
[Epoch 5, Batch 900] loss: 0.04280671038723085
[Epoch 5, Batch 1000] loss: 0.049855380588560365
[Epoch 5, Batch 1100] loss: 0.050872553685621824
[Epoch 5, Batch 1200] loss: 0.05261622704856563
[Epoch 5, Batch 1300] loss: 0.06246843168803025
[Epoch 5, Batch 1400] loss: 0.06774108180019539
[Epoch 5, Batch 1500] loss: 0.06045114547305275
[Epoch 5, Batch 1600] loss: 0.061531649326789194
[Epoch 5, Batch 1700] loss: 0.05495591715793125
[Epoch 5, Batch 1800] loss: 0.04457844016025774
[Epoch 5, Batch 1900] loss: 0.05752410902001429
[Epoch 5, Batch 2000] loss: 0.04582436537835747
[Epoch 5, Batch 2100] loss: 0.05072432789602317
[Epoch 5, Batch 2200] loss: 0.0584488747199066
[Epoch 5, Batch 2300] loss: 0.051636389548657464
[Epoch 5, Batch 2400] loss: 0.054134785189526156
[Epoch 5, Batch 2500] loss: 0.05351170792535413
[Epoch 5, Batch 2600] loss: 0.039047265168919695
[Epoch 5, Batch 2700] loss: 0.06540271227480844
[Epoch 5, Batch 2800] loss: 0.05657485038071172
[Epoch 5, Batch 2900] loss: 0.04671890022640582
[Epoch 5, Batch 3000] loss: 0.051652166920830495
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0644
Validation Accuracy: 0.9797
Overfitting: 0.0644
Best model saved at epoch 5 with validation loss: 0.0644
[Epoch 6, Batch 100] loss: 0.03983470945531735
[Epoch 6, Batch 200] loss: 0.051474409970396665
[Epoch 6, Batch 300] loss: 0.04911308847280452
[Epoch 6, Batch 400] loss: 0.056887055399129166
[Epoch 6, Batch 500] loss: 0.03674706423553289
[Epoch 6, Batch 600] loss: 0.05257367808721028
[Epoch 6, Batch 700] loss: 0.03983109112654347
[Epoch 6, Batch 800] loss: 0.056406078955042176
[Epoch 6, Batch 900] loss: 0.030550251866225155
[Epoch 6, Batch 1000] loss: 0.04886843194632093
[Epoch 6, Batch 1100] loss: 0.042717174362915104
[Epoch 6, Batch 1200] loss: 0.04484244475563173
[Epoch 6, Batch 1300] loss: 0.053081141608272445
[Epoch 6, Batch 1400] loss: 0.041842786372144475
[Epoch 6, Batch 1500] loss: 0.03746214199782116
[Epoch 6, Batch 1600] loss: 0.05370356379804434
[Epoch 6, Batch 1700] loss: 0.0458272847844637
[Epoch 6, Batch 1800] loss: 0.042409928697452415
[Epoch 6, Batch 1900] loss: 0.04966358447738457
[Epoch 6, Batch 2000] loss: 0.04948122527595842
[Epoch 6, Batch 2100] loss: 0.052471936603251376
[Epoch 6, Batch 2200] loss: 0.03927223852922907
[Epoch 6, Batch 2300] loss: 0.04086532897083089
[Epoch 6, Batch 2400] loss: 0.06595245772681664
[Epoch 6, Batch 2500] loss: 0.04001372643368086
[Epoch 6, Batch 2600] loss: 0.034101835213659795
[Epoch 6, Batch 2700] loss: 0.034825971614045555
[Epoch 6, Batch 2800] loss: 0.03147669266560115
[Epoch 6, Batch 2900] loss: 0.045550613672967304
[Epoch 6, Batch 3000] loss: 0.06765333997638663
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0660
Validation Accuracy: 0.9797
Overfitting: 0.0660
[Epoch 7, Batch 100] loss: 0.03835561440791935
[Epoch 7, Batch 200] loss: 0.0365228399031912
[Epoch 7, Batch 300] loss: 0.02743710411567008
[Epoch 7, Batch 400] loss: 0.042972350003838075
[Epoch 7, Batch 500] loss: 0.05044580183122889
[Epoch 7, Batch 600] loss: 0.034956495888473
[Epoch 7, Batch 700] loss: 0.04915977320750244
[Epoch 7, Batch 800] loss: 0.030250352648145053
[Epoch 7, Batch 900] loss: 0.050992028527834916
[Epoch 7, Batch 1000] loss: 0.04148712400579825
[Epoch 7, Batch 1100] loss: 0.039046110993949695
[Epoch 7, Batch 1200] loss: 0.03810661456634989
[Epoch 7, Batch 1300] loss: 0.04279495935377781
[Epoch 7, Batch 1400] loss: 0.03976764115694095
[Epoch 7, Batch 1500] loss: 0.05490841980790719
[Epoch 7, Batch 1600] loss: 0.029092709060641937
[Epoch 7, Batch 1700] loss: 0.03964773785526631
[Epoch 7, Batch 1800] loss: 0.02471949772007065
[Epoch 7, Batch 1900] loss: 0.033740642036136706
[Epoch 7, Batch 2000] loss: 0.04947911282361019
[Epoch 7, Batch 2100] loss: 0.03947632179275388
[Epoch 7, Batch 2200] loss: 0.03198512918112101
[Epoch 7, Batch 2300] loss: 0.03688464690785622
[Epoch 7, Batch 2400] loss: 0.036410006126243386
[Epoch 7, Batch 2500] loss: 0.04282850429895916
[Epoch 7, Batch 2600] loss: 0.05415041082334938
[Epoch 7, Batch 2700] loss: 0.03437977804656839
[Epoch 7, Batch 2800] loss: 0.04118807494625799
[Epoch 7, Batch 2900] loss: 0.04714109853404807
[Epoch 7, Batch 3000] loss: 0.043429929280246145
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0577
Validation Accuracy: 0.9832
Overfitting: 0.0577
Best model saved at epoch 7 with validation loss: 0.0577
[Epoch 8, Batch 100] loss: 0.04238182254266576
[Epoch 8, Batch 200] loss: 0.03967276146926452
[Epoch 8, Batch 300] loss: 0.040287512114155107
[Epoch 8, Batch 400] loss: 0.029384432623555768
[Epoch 8, Batch 500] loss: 0.030897568873333513
[Epoch 8, Batch 600] loss: 0.03599579715970322
[Epoch 8, Batch 700] loss: 0.0434236429669545
[Epoch 8, Batch 800] loss: 0.026420744174683933
[Epoch 8, Batch 900] loss: 0.030404797883966238
[Epoch 8, Batch 1000] loss: 0.029354572948504937
[Epoch 8, Batch 1100] loss: 0.03489016921303119
[Epoch 8, Batch 1200] loss: 0.03628214699150703
[Epoch 8, Batch 1300] loss: 0.058854182599752676
[Epoch 8, Batch 1400] loss: 0.0217881867523829
[Epoch 8, Batch 1500] loss: 0.04416015246475581
[Epoch 8, Batch 1600] loss: 0.02369264085587929
[Epoch 8, Batch 1700] loss: 0.0283922525691014
[Epoch 8, Batch 1800] loss: 0.04742034653623705
[Epoch 8, Batch 1900] loss: 0.03305227270677278
[Epoch 8, Batch 2000] loss: 0.02470805502962321
[Epoch 8, Batch 2100] loss: 0.03382268488072441
[Epoch 8, Batch 2200] loss: 0.04387584453172167
[Epoch 8, Batch 2300] loss: 0.03528015131305438
[Epoch 8, Batch 2400] loss: 0.022585029312758707
[Epoch 8, Batch 2500] loss: 0.04510661763582902
[Epoch 8, Batch 2600] loss: 0.04089745279030467
[Epoch 8, Batch 2700] loss: 0.021371321972110308
[Epoch 8, Batch 2800] loss: 0.04525467323648627
[Epoch 8, Batch 2900] loss: 0.02392612720199395
[Epoch 8, Batch 3000] loss: 0.04472811650950462
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9818
Overfitting: 0.0550
Best model saved at epoch 8 with validation loss: 0.0550
[Epoch 9, Batch 100] loss: 0.03593017495491949
[Epoch 9, Batch 200] loss: 0.028516047848243034
[Epoch 9, Batch 300] loss: 0.02457338212596369
[Epoch 9, Batch 400] loss: 0.022674948170315474
[Epoch 9, Batch 500] loss: 0.026312091950967443
[Epoch 9, Batch 600] loss: 0.03230653267877642
[Epoch 9, Batch 700] loss: 0.03356932844370022
[Epoch 9, Batch 800] loss: 0.04084304384479765
[Epoch 9, Batch 900] loss: 0.023675027210847476
[Epoch 9, Batch 1000] loss: 0.0371607257771393
[Epoch 9, Batch 1100] loss: 0.02718480378316599
[Epoch 9, Batch 1200] loss: 0.02165534929779824
[Epoch 9, Batch 1300] loss: 0.02902330492477631
[Epoch 9, Batch 1400] loss: 0.03744588131638011
[Epoch 9, Batch 1500] loss: 0.0275601219793316
[Epoch 9, Batch 1600] loss: 0.04520786392487935
[Epoch 9, Batch 1700] loss: 0.02585207008232828
[Epoch 9, Batch 1800] loss: 0.03407784652314149
[Epoch 9, Batch 1900] loss: 0.02122621030983282
[Epoch 9, Batch 2000] loss: 0.03228856590023497
[Epoch 9, Batch 2100] loss: 0.028450228827132377
[Epoch 9, Batch 2200] loss: 0.023498219478642567
[Epoch 9, Batch 2300] loss: 0.0475318132215034
[Epoch 9, Batch 2400] loss: 0.03324196797708282
[Epoch 9, Batch 2500] loss: 0.016064546519628492
[Epoch 9, Batch 2600] loss: 0.019843232452003576
[Epoch 9, Batch 2700] loss: 0.03413256000065303
[Epoch 9, Batch 2800] loss: 0.046125446838268545
[Epoch 9, Batch 2900] loss: 0.041361386552889595
[Epoch 9, Batch 3000] loss: 0.02902799509567558
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9848
Overfitting: 0.0527
Best model saved at epoch 9 with validation loss: 0.0527
[Epoch 10, Batch 100] loss: 0.03142573799326783
[Epoch 10, Batch 200] loss: 0.02549769125849707
[Epoch 10, Batch 300] loss: 0.022329911810156772
[Epoch 10, Batch 400] loss: 0.024259567709450494
[Epoch 10, Batch 500] loss: 0.035041994541388705
[Epoch 10, Batch 600] loss: 0.031204796698875725
[Epoch 10, Batch 700] loss: 0.022157455925116663
[Epoch 10, Batch 800] loss: 0.02166685827047331
[Epoch 10, Batch 900] loss: 0.025231268016541436
[Epoch 10, Batch 1000] loss: 0.02877004075970035
[Epoch 10, Batch 1100] loss: 0.028320526987226913
[Epoch 10, Batch 1200] loss: 0.033928625593252944
[Epoch 10, Batch 1300] loss: 0.047635903026894084
[Epoch 10, Batch 1400] loss: 0.016898681341699556
[Epoch 10, Batch 1500] loss: 0.037517116928502216
[Epoch 10, Batch 1600] loss: 0.028163685972685926
[Epoch 10, Batch 1700] loss: 0.027630671515944415
[Epoch 10, Batch 1800] loss: 0.020805628643647652
[Epoch 10, Batch 1900] loss: 0.029718798918256652
[Epoch 10, Batch 2000] loss: 0.022833777593477864
[Epoch 10, Batch 2100] loss: 0.024892559371801327
[Epoch 10, Batch 2200] loss: 0.02647498254358652
[Epoch 10, Batch 2300] loss: 0.021009902536752632
[Epoch 10, Batch 2400] loss: 0.02755503826039785
[Epoch 10, Batch 2500] loss: 0.031823005992118854
[Epoch 10, Batch 2600] loss: 0.02142302661362919
[Epoch 10, Batch 2700] loss: 0.030699264428549214
[Epoch 10, Batch 2800] loss: 0.03753951834860345
[Epoch 10, Batch 2900] loss: 0.029389817085757386
[Epoch 10, Batch 3000] loss: 0.029201277754764304
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0553
Validation Accuracy: 0.9839
Overfitting: 0.0553
[Epoch 11, Batch 100] loss: 0.023360112955997464
[Epoch 11, Batch 200] loss: 0.017176313767995454
[Epoch 11, Batch 300] loss: 0.016628796829390922
[Epoch 11, Batch 400] loss: 0.020973208305804292
[Epoch 11, Batch 500] loss: 0.01502508667163056
[Epoch 11, Batch 600] loss: 0.03359729805277311
[Epoch 11, Batch 700] loss: 0.028062291060523423
[Epoch 11, Batch 800] loss: 0.03691380046911945
[Epoch 11, Batch 900] loss: 0.02132099491835106
[Epoch 11, Batch 1000] loss: 0.020845446732273558
[Epoch 11, Batch 1100] loss: 0.016909606813278515
[Epoch 11, Batch 1200] loss: 0.02709605744737928
[Epoch 11, Batch 1300] loss: 0.026408375277242158
[Epoch 11, Batch 1400] loss: 0.029245581170980587
[Epoch 11, Batch 1500] loss: 0.028967824738210766
[Epoch 11, Batch 1600] loss: 0.024768643947609234
[Epoch 11, Batch 1700] loss: 0.02744952658904367
[Epoch 11, Batch 1800] loss: 0.029572215323714773
[Epoch 11, Batch 1900] loss: 0.0213576020221808
[Epoch 11, Batch 2000] loss: 0.029785684919261257
[Epoch 11, Batch 2100] loss: 0.02435737761305063
[Epoch 11, Batch 2200] loss: 0.019226445655076533
[Epoch 11, Batch 2300] loss: 0.03264971942862758
[Epoch 11, Batch 2400] loss: 0.01725674306304427
[Epoch 11, Batch 2500] loss: 0.02346164306552964
[Epoch 11, Batch 2600] loss: 0.013837660922545182
[Epoch 11, Batch 2700] loss: 0.029764220942379325
[Epoch 11, Batch 2800] loss: 0.01927202425271389
[Epoch 11, Batch 2900] loss: 0.03314736979809822
[Epoch 11, Batch 3000] loss: 0.029211688563445932
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9833
Overfitting: 0.0561
[Epoch 12, Batch 100] loss: 0.02508210415035137
[Epoch 12, Batch 200] loss: 0.01784558264673251
[Epoch 12, Batch 300] loss: 0.013522972790324274
[Epoch 12, Batch 400] loss: 0.020784472542945878
[Epoch 12, Batch 500] loss: 0.021946352314043908
[Epoch 12, Batch 600] loss: 0.010923500514181797
[Epoch 12, Batch 700] loss: 0.026864612296558333
[Epoch 12, Batch 800] loss: 0.013678228130511344
[Epoch 12, Batch 900] loss: 0.013650749505868589
[Epoch 12, Batch 1000] loss: 0.02047511519587715
[Epoch 12, Batch 1100] loss: 0.025362279228211264
[Epoch 12, Batch 1200] loss: 0.02961735875942395
[Epoch 12, Batch 1300] loss: 0.01878690142184496
[Epoch 12, Batch 1400] loss: 0.031016031504332204
[Epoch 12, Batch 1500] loss: 0.021428487019293244
[Epoch 12, Batch 1600] loss: 0.023448523529150406
[Epoch 12, Batch 1700] loss: 0.020381918032016985
[Epoch 12, Batch 1800] loss: 0.011778466925461544
[Epoch 12, Batch 1900] loss: 0.02748681401852082
[Epoch 12, Batch 2000] loss: 0.024124785869717016
[Epoch 12, Batch 2100] loss: 0.0391965321819589
[Epoch 12, Batch 2200] loss: 0.021108278016909024
[Epoch 12, Batch 2300] loss: 0.013035869008963346
[Epoch 12, Batch 2400] loss: 0.023204352912143802
[Epoch 12, Batch 2500] loss: 0.025231041030419874
[Epoch 12, Batch 2600] loss: 0.02157402823211669
[Epoch 12, Batch 2700] loss: 0.03665376645531069
[Epoch 12, Batch 2800] loss: 0.022031505966806433
[Epoch 12, Batch 2900] loss: 0.020895467482350796
[Epoch 12, Batch 3000] loss: 0.023298886459233472
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0618
Validation Accuracy: 0.9825
Overfitting: 0.0618
[Epoch 13, Batch 100] loss: 0.017047293223913584
[Epoch 13, Batch 200] loss: 0.01389927312193322
[Epoch 13, Batch 300] loss: 0.011787370686579379
[Epoch 13, Batch 400] loss: 0.012542772967681231
[Epoch 13, Batch 500] loss: 0.011291315129383292
[Epoch 13, Batch 600] loss: 0.02541778399638133
[Epoch 13, Batch 700] loss: 0.0190532480010188
[Epoch 13, Batch 800] loss: 0.020349896121642813
[Epoch 13, Batch 900] loss: 0.01573224160609243
[Epoch 13, Batch 1000] loss: 0.015950604553218
[Epoch 13, Batch 1100] loss: 0.022728465461768793
[Epoch 13, Batch 1200] loss: 0.029970619472660474
[Epoch 13, Batch 1300] loss: 0.01566179333058244
[Epoch 13, Batch 1400] loss: 0.02169951439696888
[Epoch 13, Batch 1500] loss: 0.017428657427280995
[Epoch 13, Batch 1600] loss: 0.024348578959634323
[Epoch 13, Batch 1700] loss: 0.023440512824709003
[Epoch 13, Batch 1800] loss: 0.013515100988843187
[Epoch 13, Batch 1900] loss: 0.02742907866351743
[Epoch 13, Batch 2000] loss: 0.017647322187513054
[Epoch 13, Batch 2100] loss: 0.027155231003453083
[Epoch 13, Batch 2200] loss: 0.01864430935442215
[Epoch 13, Batch 2300] loss: 0.016884790396707105
[Epoch 13, Batch 2400] loss: 0.019379151115572313
[Epoch 13, Batch 2500] loss: 0.03244935082511802
[Epoch 13, Batch 2600] loss: 0.015420016151074379
[Epoch 13, Batch 2700] loss: 0.018353967339098744
[Epoch 13, Batch 2800] loss: 0.023240304525115787
[Epoch 13, Batch 2900] loss: 0.022273321908141953
[Epoch 13, Batch 3000] loss: 0.032665438238182104
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9844
Overfitting: 0.0522
Best model saved at epoch 13 with validation loss: 0.0522
[Epoch 14, Batch 100] loss: 0.019729069966851965
[Epoch 14, Batch 200] loss: 0.01316658157051279
[Epoch 14, Batch 300] loss: 0.012437135732652678
[Epoch 14, Batch 400] loss: 0.018966410606808495
[Epoch 14, Batch 500] loss: 0.01849669285125856
[Epoch 14, Batch 600] loss: 0.019414066121134964
[Epoch 14, Batch 700] loss: 0.007989694541247445
[Epoch 14, Batch 800] loss: 0.023810471663746283
[Epoch 14, Batch 900] loss: 0.0210048680285945
[Epoch 14, Batch 1000] loss: 0.016939221116899716
[Epoch 14, Batch 1100] loss: 0.015808553387796565
[Epoch 14, Batch 1200] loss: 0.01365652160195168
[Epoch 14, Batch 1300] loss: 0.01578893944630181
[Epoch 14, Batch 1400] loss: 0.015648871711709943
[Epoch 14, Batch 1500] loss: 0.011869675469388313
[Epoch 14, Batch 1600] loss: 0.013251323919685093
[Epoch 14, Batch 1700] loss: 0.027950324342527894
[Epoch 14, Batch 1800] loss: 0.017934859266042623
[Epoch 14, Batch 1900] loss: 0.01186535155711681
[Epoch 14, Batch 2000] loss: 0.01412216257333057
[Epoch 14, Batch 2100] loss: 0.01716238437784341
[Epoch 14, Batch 2200] loss: 0.019131805793622333
[Epoch 14, Batch 2300] loss: 0.010970188216979294
[Epoch 14, Batch 2400] loss: 0.011500067447323091
[Epoch 14, Batch 2500] loss: 0.01962085345164269
[Epoch 14, Batch 2600] loss: 0.015156685778492829
[Epoch 14, Batch 2700] loss: 0.019056325567344174
[Epoch 14, Batch 2800] loss: 0.020117787564995524
[Epoch 14, Batch 2900] loss: 0.02114922489676246
[Epoch 14, Batch 3000] loss: 0.014136377646732399
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9857
Overfitting: 0.0508
Best model saved at epoch 14 with validation loss: 0.0508
[Epoch 15, Batch 100] loss: 0.008665457539937051
[Epoch 15, Batch 200] loss: 0.010749438891361934
[Epoch 15, Batch 300] loss: 0.012442403903123704
[Epoch 15, Batch 400] loss: 0.008894332149388902
[Epoch 15, Batch 500] loss: 0.012301732492342126
[Epoch 15, Batch 600] loss: 0.01302745172431969
[Epoch 15, Batch 700] loss: 0.01580527534830253
[Epoch 15, Batch 800] loss: 0.01093420404686185
[Epoch 15, Batch 900] loss: 0.012248564544788678
[Epoch 15, Batch 1000] loss: 0.021641923175957346
[Epoch 15, Batch 1100] loss: 0.016494378043607868
[Epoch 15, Batch 1200] loss: 0.019084114003821925
[Epoch 15, Batch 1300] loss: 0.013989578931523283
[Epoch 15, Batch 1400] loss: 0.009446091747631726
[Epoch 15, Batch 1500] loss: 0.017372180542624845
[Epoch 15, Batch 1600] loss: 0.022952999141016336
[Epoch 15, Batch 1700] loss: 0.012614614653066382
[Epoch 15, Batch 1800] loss: 0.012625971286634013
[Epoch 15, Batch 1900] loss: 0.020738188091545453
[Epoch 15, Batch 2000] loss: 0.021939940897909765
[Epoch 15, Batch 2100] loss: 0.02034868598300818
[Epoch 15, Batch 2200] loss: 0.025677736519191967
[Epoch 15, Batch 2300] loss: 0.01664440123098757
[Epoch 15, Batch 2400] loss: 0.01199301535703853
[Epoch 15, Batch 2500] loss: 0.019008480430263718
[Epoch 15, Batch 2600] loss: 0.005977753425750052
[Epoch 15, Batch 2700] loss: 0.018610673315706663
[Epoch 15, Batch 2800] loss: 0.015367747059254953
[Epoch 15, Batch 2900] loss: 0.028482636438202463
[Epoch 15, Batch 3000] loss: 0.015597477405226528
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9835
Overfitting: 0.0593
[Epoch 16, Batch 100] loss: 0.013436745775288727
[Epoch 16, Batch 200] loss: 0.012809913910405157
[Epoch 16, Batch 300] loss: 0.006508775313450315
[Epoch 16, Batch 400] loss: 0.006678591189802319
[Epoch 16, Batch 500] loss: 0.02112352957465191
[Epoch 16, Batch 600] loss: 0.011468177886490594
[Epoch 16, Batch 700] loss: 0.01599117012716306
[Epoch 16, Batch 800] loss: 0.01727183411028818
[Epoch 16, Batch 900] loss: 0.00975348960428164
[Epoch 16, Batch 1000] loss: 0.007897518719510117
[Epoch 16, Batch 1100] loss: 0.014062438380151435
[Epoch 16, Batch 1200] loss: 0.007213221805363901
[Epoch 16, Batch 1300] loss: 0.01794805100749727
[Epoch 16, Batch 1400] loss: 0.016734797570607043
[Epoch 16, Batch 1500] loss: 0.019536391120564076
[Epoch 16, Batch 1600] loss: 0.01588063909293851
[Epoch 16, Batch 1700] loss: 0.02059969909105348
[Epoch 16, Batch 1800] loss: 0.012692273249012943
[Epoch 16, Batch 1900] loss: 0.009935980984382696
[Epoch 16, Batch 2000] loss: 0.01182195998113457
[Epoch 16, Batch 2100] loss: 0.02756638192385708
[Epoch 16, Batch 2200] loss: 0.011539208040330777
[Epoch 16, Batch 2300] loss: 0.011941557201062096
[Epoch 16, Batch 2400] loss: 0.01671132685856719
[Epoch 16, Batch 2500] loss: 0.013937137370348865
[Epoch 16, Batch 2600] loss: 0.011628454244983004
[Epoch 16, Batch 2700] loss: 0.013011459052977443
[Epoch 16, Batch 2800] loss: 0.018534730725077678
[Epoch 16, Batch 2900] loss: 0.009068630988804217
[Epoch 16, Batch 3000] loss: 0.02040054417308056
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9852
Overfitting: 0.0534
[Epoch 17, Batch 100] loss: 0.011492591614533011
[Epoch 17, Batch 200] loss: 0.00712508762426296
[Epoch 17, Batch 300] loss: 0.017868863089770457
[Epoch 17, Batch 400] loss: 0.006489311284731229
[Epoch 17, Batch 500] loss: 0.015430631262588576
[Epoch 17, Batch 600] loss: 0.009956874365543626
[Epoch 17, Batch 700] loss: 0.009114760948132244
[Epoch 17, Batch 800] loss: 0.008156109705450944
[Epoch 17, Batch 900] loss: 0.0085384288313071
[Epoch 17, Batch 1000] loss: 0.00951632907412204
[Epoch 17, Batch 1100] loss: 0.016921910307191864
[Epoch 17, Batch 1200] loss: 0.004402517595108293
[Epoch 17, Batch 1300] loss: 0.008474800659082576
[Epoch 17, Batch 1400] loss: 0.013769121469713354
[Epoch 17, Batch 1500] loss: 0.00893661369872916
[Epoch 17, Batch 1600] loss: 0.01778722777889925
[Epoch 17, Batch 1700] loss: 0.013756560612446265
[Epoch 17, Batch 1800] loss: 0.005103534177469555
[Epoch 17, Batch 1900] loss: 0.0164965179574574
[Epoch 17, Batch 2000] loss: 0.02095808031677734
[Epoch 17, Batch 2100] loss: 0.00660475261413012
[Epoch 17, Batch 2200] loss: 0.008514073942196774
[Epoch 17, Batch 2300] loss: 0.015733658841718352
[Epoch 17, Batch 2400] loss: 0.01134175837587918
[Epoch 17, Batch 2500] loss: 0.020369847430870322
[Epoch 17, Batch 2600] loss: 0.010109960668796703
[Epoch 17, Batch 2700] loss: 0.02002795430237711
[Epoch 17, Batch 2800] loss: 0.010749958297592456
[Epoch 17, Batch 2900] loss: 0.007692223540179839
[Epoch 17, Batch 3000] loss: 0.019321581939066163
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0545
Validation Accuracy: 0.9853
Overfitting: 0.0545
[Epoch 18, Batch 100] loss: 0.009054548899348447
[Epoch 18, Batch 200] loss: 0.009364953160829827
[Epoch 18, Batch 300] loss: 0.015448905132875551
[Epoch 18, Batch 400] loss: 0.012098011018188116
[Epoch 18, Batch 500] loss: 0.006784245205826664
[Epoch 18, Batch 600] loss: 0.009948504231997503
[Epoch 18, Batch 700] loss: 0.00899827677605117
[Epoch 18, Batch 800] loss: 0.006768183613685324
[Epoch 18, Batch 900] loss: 0.008172650176834394
[Epoch 18, Batch 1000] loss: 0.008903618550111786
[Epoch 18, Batch 1100] loss: 0.010972661981631972
[Epoch 18, Batch 1200] loss: 0.007148354901437415
[Epoch 18, Batch 1300] loss: 0.004584511875059434
[Epoch 18, Batch 1400] loss: 0.008877190661876285
[Epoch 18, Batch 1500] loss: 0.013726180866374307
[Epoch 18, Batch 1600] loss: 0.024218659387202024
[Epoch 18, Batch 1700] loss: 0.006483093989522785
[Epoch 18, Batch 1800] loss: 0.0047693655758848765
[Epoch 18, Batch 1900] loss: 0.017165721132409998
[Epoch 18, Batch 2000] loss: 0.00811011292124931
[Epoch 18, Batch 2100] loss: 0.008952587431281245
[Epoch 18, Batch 2200] loss: 0.005151827295776457
[Epoch 18, Batch 2300] loss: 0.026077494686451246
[Epoch 18, Batch 2400] loss: 0.019058990344601626
[Epoch 18, Batch 2500] loss: 0.00987807298437474
[Epoch 18, Batch 2600] loss: 0.010590875946345477
[Epoch 18, Batch 2700] loss: 0.015044214854005986
[Epoch 18, Batch 2800] loss: 0.011095575693161663
[Epoch 18, Batch 2900] loss: 0.006511462773376025
[Epoch 18, Batch 3000] loss: 0.01361320950627487
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9853
Overfitting: 0.0548
[Epoch 19, Batch 100] loss: 0.01149278869452246
[Epoch 19, Batch 200] loss: 0.0044360410756075904
[Epoch 19, Batch 300] loss: 0.0059175931689071605
[Epoch 19, Batch 400] loss: 0.007550073403463102
[Epoch 19, Batch 500] loss: 0.012375861837654156
[Epoch 19, Batch 600] loss: 0.010436079758351298
[Epoch 19, Batch 700] loss: 0.014879766391732118
[Epoch 19, Batch 800] loss: 0.011875725489121578
[Epoch 19, Batch 900] loss: 0.01251728009215185
[Epoch 19, Batch 1000] loss: 0.01932651569311474
[Epoch 19, Batch 1100] loss: 0.014055948849681954
[Epoch 19, Batch 1200] loss: 0.022160588575916337
[Epoch 19, Batch 1300] loss: 0.010772033047969672
[Epoch 19, Batch 1400] loss: 0.006914132429315032
[Epoch 19, Batch 1500] loss: 0.009982548597581626
[Epoch 19, Batch 1600] loss: 0.007531007533634693
[Epoch 19, Batch 1700] loss: 0.015435552201156498
[Epoch 19, Batch 1800] loss: 0.01829628721062363
[Epoch 19, Batch 1900] loss: 0.013098338195472934
[Epoch 19, Batch 2000] loss: 0.007618418253750861
[Epoch 19, Batch 2100] loss: 0.009662204494234175
[Epoch 19, Batch 2200] loss: 0.009646210477803834
[Epoch 19, Batch 2300] loss: 0.010398579176489875
[Epoch 19, Batch 2400] loss: 0.0063726494218281
[Epoch 19, Batch 2500] loss: 0.004634826368619543
[Epoch 19, Batch 2600] loss: 0.01249565232599707
[Epoch 19, Batch 2700] loss: 0.006234361087972502
[Epoch 19, Batch 2800] loss: 0.0064049843035491
[Epoch 19, Batch 2900] loss: 0.00896712340416343
[Epoch 19, Batch 3000] loss: 0.010258912346362194
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9871
Overfitting: 0.0507
Best model saved at epoch 19 with validation loss: 0.0507
[Epoch 20, Batch 100] loss: 0.0038321061706164984
[Epoch 20, Batch 200] loss: 0.006109276626921769
[Epoch 20, Batch 300] loss: 0.014873506146220733
[Epoch 20, Batch 400] loss: 0.010814527658183123
[Epoch 20, Batch 500] loss: 0.006683962763477211
[Epoch 20, Batch 600] loss: 0.010687022548345339
[Epoch 20, Batch 700] loss: 0.0067520128737760384
[Epoch 20, Batch 800] loss: 0.01601600381690332
[Epoch 20, Batch 900] loss: 0.006578231126472929
[Epoch 20, Batch 1000] loss: 0.009135374560937635
[Epoch 20, Batch 1100] loss: 0.005305990166698393
[Epoch 20, Batch 1200] loss: 0.0075890572467096715
[Epoch 20, Batch 1300] loss: 0.007160361296046176
[Epoch 20, Batch 1400] loss: 0.004915076777788272
[Epoch 20, Batch 1500] loss: 0.009395567750507325
[Epoch 20, Batch 1600] loss: 0.004469635922141606
[Epoch 20, Batch 1700] loss: 0.008308690926628514
[Epoch 20, Batch 1800] loss: 0.005333731391210676
[Epoch 20, Batch 1900] loss: 0.01052106055756667
[Epoch 20, Batch 2000] loss: 0.005765768807032145
[Epoch 20, Batch 2100] loss: 0.0053823019232186195
[Epoch 20, Batch 2200] loss: 0.009242304824506392
[Epoch 20, Batch 2300] loss: 0.008600461026367157
[Epoch 20, Batch 2400] loss: 0.0087930225597961
[Epoch 20, Batch 2500] loss: 0.018317565348706922
[Epoch 20, Batch 2600] loss: 0.008887335041081315
[Epoch 20, Batch 2700] loss: 0.009285288121841404
[Epoch 20, Batch 2800] loss: 0.005481662709735246
[Epoch 20, Batch 2900] loss: 0.008258119844306293
[Epoch 20, Batch 3000] loss: 0.014619353797394296
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9859
Overfitting: 0.0564
[Epoch 21, Batch 100] loss: 0.003946723363387718
[Epoch 21, Batch 200] loss: 0.003609344809524373
[Epoch 21, Batch 300] loss: 0.0070293385398440475
[Epoch 21, Batch 400] loss: 0.009543395338275503
[Epoch 21, Batch 500] loss: 0.011155585135702495
[Epoch 21, Batch 600] loss: 0.004119657982168973
[Epoch 21, Batch 700] loss: 0.0021427565675980987
[Epoch 21, Batch 800] loss: 0.004071197432167537
[Epoch 21, Batch 900] loss: 0.0034344714867779657
[Epoch 21, Batch 1000] loss: 0.015218448685791372
[Epoch 21, Batch 1100] loss: 0.003109277594012383
[Epoch 21, Batch 1200] loss: 0.005641991703015492
[Epoch 21, Batch 1300] loss: 0.0050068533369244505
[Epoch 21, Batch 1400] loss: 0.0058757125522683395
[Epoch 21, Batch 1500] loss: 0.006710002547411022
[Epoch 21, Batch 1600] loss: 0.0041181875159895754
[Epoch 21, Batch 1700] loss: 0.005857269555556286
[Epoch 21, Batch 1800] loss: 0.014682740205519167
[Epoch 21, Batch 1900] loss: 0.008027404492806908
[Epoch 21, Batch 2000] loss: 0.0034261414222146415
[Epoch 21, Batch 2100] loss: 0.008397074787435486
[Epoch 21, Batch 2200] loss: 0.009149564160902629
[Epoch 21, Batch 2300] loss: 0.008804859993715582
[Epoch 21, Batch 2400] loss: 0.00809420377850074
[Epoch 21, Batch 2500] loss: 0.007055999660506132
[Epoch 21, Batch 2600] loss: 0.007091427015413956
[Epoch 21, Batch 2700] loss: 0.013558007670267215
[Epoch 21, Batch 2800] loss: 0.01796032869773853
[Epoch 21, Batch 2900] loss: 0.015274108327175781
[Epoch 21, Batch 3000] loss: 0.00749849382643788
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9863
Overfitting: 0.0546
[Epoch 22, Batch 100] loss: 0.0036462520331770067
[Epoch 22, Batch 200] loss: 0.010635488971101949
[Epoch 22, Batch 300] loss: 0.008866457485846696
[Epoch 22, Batch 400] loss: 0.002882951873145885
[Epoch 22, Batch 500] loss: 0.011217926360686761
[Epoch 22, Batch 600] loss: 0.0044989054591087554
[Epoch 22, Batch 700] loss: 0.006732101407592382
[Epoch 22, Batch 800] loss: 0.005293430569229258
[Epoch 22, Batch 900] loss: 0.008063210490420261
[Epoch 22, Batch 1000] loss: 0.008553222932814606
[Epoch 22, Batch 1100] loss: 0.004948158337942914
[Epoch 22, Batch 1200] loss: 0.006701766777659941
[Epoch 22, Batch 1300] loss: 0.004035758166487539
[Epoch 22, Batch 1400] loss: 0.008022257893694587
[Epoch 22, Batch 1500] loss: 0.0034772175694797623
[Epoch 22, Batch 1600] loss: 0.007885260364439546
[Epoch 22, Batch 1700] loss: 0.01147867277914429
[Epoch 22, Batch 1800] loss: 0.006540213244516053
[Epoch 22, Batch 1900] loss: 0.0054813312947953816
[Epoch 22, Batch 2000] loss: 0.005954250072857121
[Epoch 22, Batch 2100] loss: 0.006802452862774544
[Epoch 22, Batch 2200] loss: 0.005606426264848779
[Epoch 22, Batch 2300] loss: 0.005484585738649912
[Epoch 22, Batch 2400] loss: 0.005273963472273522
[Epoch 22, Batch 2500] loss: 0.009816385510250712
[Epoch 22, Batch 2600] loss: 0.004195877283568734
[Epoch 22, Batch 2700] loss: 0.0052282120822769685
[Epoch 22, Batch 2800] loss: 0.003707838768165459
[Epoch 22, Batch 2900] loss: 0.0064030679007464645
[Epoch 22, Batch 3000] loss: 0.005520889928955625
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9870
Overfitting: 0.0549
[Epoch 23, Batch 100] loss: 0.00462934297627271
[Epoch 23, Batch 200] loss: 0.008636639431256867
[Epoch 23, Batch 300] loss: 0.002727017854691667
[Epoch 23, Batch 400] loss: 0.004368862940766576
[Epoch 23, Batch 500] loss: 0.008351780821158172
[Epoch 23, Batch 600] loss: 0.005005253095683884
[Epoch 23, Batch 700] loss: 0.007723884014199029
[Epoch 23, Batch 800] loss: 0.002622224897442038
[Epoch 23, Batch 900] loss: 0.002932606623294305
[Epoch 23, Batch 1000] loss: 0.0025957496883984277
[Epoch 23, Batch 1100] loss: 0.004725738046993229
[Epoch 23, Batch 1200] loss: 0.0029232111622377486
[Epoch 23, Batch 1300] loss: 0.0029236359784067644
[Epoch 23, Batch 1400] loss: 0.0069177874242950564
[Epoch 23, Batch 1500] loss: 0.003986003111344871
[Epoch 23, Batch 1600] loss: 0.004589973848368345
[Epoch 23, Batch 1700] loss: 0.005939640521570482
[Epoch 23, Batch 1800] loss: 0.00841256749098676
[Epoch 23, Batch 1900] loss: 0.007138521992680182
[Epoch 23, Batch 2000] loss: 0.008187539589846438
[Epoch 23, Batch 2100] loss: 0.0052225960177565865
[Epoch 23, Batch 2200] loss: 0.0063410616616556585
[Epoch 23, Batch 2300] loss: 0.0051221947855901815
[Epoch 23, Batch 2400] loss: 0.008360301278612496
[Epoch 23, Batch 2500] loss: 0.005214092447389475
[Epoch 23, Batch 2600] loss: 0.0071865132442349025
[Epoch 23, Batch 2700] loss: 0.00296032245460367
[Epoch 23, Batch 2800] loss: 0.008259750237946263
[Epoch 23, Batch 2900] loss: 0.006887782094187856
[Epoch 23, Batch 3000] loss: 0.01144629867665003
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9848
Overfitting: 0.0586
[Epoch 24, Batch 100] loss: 0.007893441228379743
[Epoch 24, Batch 200] loss: 0.0033545911891815195
[Epoch 24, Batch 300] loss: 0.002155925840754662
[Epoch 24, Batch 400] loss: 0.002914873120490711
[Epoch 24, Batch 500] loss: 0.0054315182265224846
[Epoch 24, Batch 600] loss: 0.0035660178653733965
[Epoch 24, Batch 700] loss: 0.004764563083533631
[Epoch 24, Batch 800] loss: 0.0017819479397212135
[Epoch 24, Batch 900] loss: 0.004333770912457453
[Epoch 24, Batch 1000] loss: 0.003975742203891741
[Epoch 24, Batch 1100] loss: 0.005266909152144308
[Epoch 24, Batch 1200] loss: 0.004497525753904484
[Epoch 24, Batch 1300] loss: 0.005991767845521281
[Epoch 24, Batch 1400] loss: 0.005202622187449606
[Epoch 24, Batch 1500] loss: 0.0038844196222157733
[Epoch 24, Batch 1600] loss: 0.003411905964712787
[Epoch 24, Batch 1700] loss: 0.008131746729079624
[Epoch 24, Batch 1800] loss: 0.00215674863189804
[Epoch 24, Batch 1900] loss: 0.011037567792337768
[Epoch 24, Batch 2000] loss: 0.004212964951112781
[Epoch 24, Batch 2100] loss: 0.0048436226211742905
[Epoch 24, Batch 2200] loss: 0.004046560484556494
[Epoch 24, Batch 2300] loss: 0.005760538878607804
[Epoch 24, Batch 2400] loss: 0.011316006184893581
[Epoch 24, Batch 2500] loss: 0.005307460430535116
[Epoch 24, Batch 2600] loss: 0.012806895447972123
[Epoch 24, Batch 2700] loss: 0.008291340426567756
[Epoch 24, Batch 2800] loss: 0.008206073412967498
[Epoch 24, Batch 2900] loss: 0.012869306448681072
[Epoch 24, Batch 3000] loss: 0.0038254274217763397
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9862
Overfitting: 0.0586
Fold 2 validation loss: 0.0586
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3030791020393373
[Epoch 1, Batch 200] loss: 2.2907163977622984
[Epoch 1, Batch 300] loss: 2.2784499287605287
[Epoch 1, Batch 400] loss: 2.245927276611328
[Epoch 1, Batch 500] loss: 2.156151920557022
[Epoch 1, Batch 600] loss: 1.8258972597122192
[Epoch 1, Batch 700] loss: 1.1898266226053238
[Epoch 1, Batch 800] loss: 0.8045261424779891
[Epoch 1, Batch 900] loss: 0.5907818232476711
[Epoch 1, Batch 1000] loss: 0.5054128960520029
[Epoch 1, Batch 1100] loss: 0.44848142385482787
[Epoch 1, Batch 1200] loss: 0.43756139278411865
[Epoch 1, Batch 1300] loss: 0.3746868983656168
[Epoch 1, Batch 1400] loss: 0.33615603810176253
[Epoch 1, Batch 1500] loss: 0.3356770592927933
[Epoch 1, Batch 1600] loss: 0.33866765327751636
[Epoch 1, Batch 1700] loss: 0.28456949338316917
[Epoch 1, Batch 1800] loss: 0.29289151292294263
[Epoch 1, Batch 1900] loss: 0.2350030841678381
[Epoch 1, Batch 2000] loss: 0.22429194025695323
[Epoch 1, Batch 2100] loss: 0.21209762319922448
[Epoch 1, Batch 2200] loss: 0.25014306919649243
[Epoch 1, Batch 2300] loss: 0.2067310074903071
[Epoch 1, Batch 2400] loss: 0.17647347711026667
[Epoch 1, Batch 2500] loss: 0.18573568486608566
[Epoch 1, Batch 2600] loss: 0.18790936628356575
[Epoch 1, Batch 2700] loss: 0.21885315233841537
[Epoch 1, Batch 2800] loss: 0.18324684604071081
[Epoch 1, Batch 2900] loss: 0.1861548496130854
[Epoch 1, Batch 3000] loss: 0.15213954254984854
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1644
Validation Accuracy: 0.9511
Overfitting: 0.1644
Best model saved at epoch 1 with validation loss: 0.1644
[Epoch 2, Batch 100] loss: 0.13905051458626985
[Epoch 2, Batch 200] loss: 0.12267561639193446
[Epoch 2, Batch 300] loss: 0.16407747205346823
[Epoch 2, Batch 400] loss: 0.1395617295987904
[Epoch 2, Batch 500] loss: 0.13691699449904263
[Epoch 2, Batch 600] loss: 0.12835655496921392
[Epoch 2, Batch 700] loss: 0.11970734604168683
[Epoch 2, Batch 800] loss: 0.12415836058091373
[Epoch 2, Batch 900] loss: 0.12183260583784432
[Epoch 2, Batch 1000] loss: 0.13652831305749713
[Epoch 2, Batch 1100] loss: 0.13199720251839608
[Epoch 2, Batch 1200] loss: 0.11304265540558844
[Epoch 2, Batch 1300] loss: 0.1302493384387344
[Epoch 2, Batch 1400] loss: 0.11132160280365497
[Epoch 2, Batch 1500] loss: 0.12705335099250079
[Epoch 2, Batch 1600] loss: 0.11610485215205699
[Epoch 2, Batch 1700] loss: 0.11928604118991643
[Epoch 2, Batch 1800] loss: 0.1395091449143365
[Epoch 2, Batch 1900] loss: 0.10085239940788597
[Epoch 2, Batch 2000] loss: 0.08858349892310798
[Epoch 2, Batch 2100] loss: 0.09418892490677536
[Epoch 2, Batch 2200] loss: 0.10128128831507638
[Epoch 2, Batch 2300] loss: 0.12921725699910894
[Epoch 2, Batch 2400] loss: 0.08067715839482843
[Epoch 2, Batch 2500] loss: 0.12232612018589861
[Epoch 2, Batch 2600] loss: 0.09281057934975251
[Epoch 2, Batch 2700] loss: 0.09020065405638888
[Epoch 2, Batch 2800] loss: 0.10089126246050001
[Epoch 2, Batch 2900] loss: 0.07907139863586053
[Epoch 2, Batch 3000] loss: 0.11003028441569768
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1015
Validation Accuracy: 0.9688
Overfitting: 0.1015
Best model saved at epoch 2 with validation loss: 0.1015
[Epoch 3, Batch 100] loss: 0.09764854929409922
[Epoch 3, Batch 200] loss: 0.07747368180658669
[Epoch 3, Batch 300] loss: 0.08475729128113016
[Epoch 3, Batch 400] loss: 0.10429766502580605
[Epoch 3, Batch 500] loss: 0.06424755693413317
[Epoch 3, Batch 600] loss: 0.07307125923689455
[Epoch 3, Batch 700] loss: 0.08860478612128646
[Epoch 3, Batch 800] loss: 0.0894395285914652
[Epoch 3, Batch 900] loss: 0.08342280780896544
[Epoch 3, Batch 1000] loss: 0.06974402838386595
[Epoch 3, Batch 1100] loss: 0.07691825649468229
[Epoch 3, Batch 1200] loss: 0.08450243186438457
[Epoch 3, Batch 1300] loss: 0.08716485682292842
[Epoch 3, Batch 1400] loss: 0.09004718919983133
[Epoch 3, Batch 1500] loss: 0.0715596245159395
[Epoch 3, Batch 1600] loss: 0.08196594563254621
[Epoch 3, Batch 1700] loss: 0.0663679757504724
[Epoch 3, Batch 1800] loss: 0.07307379591162316
[Epoch 3, Batch 1900] loss: 0.0995722491433844
[Epoch 3, Batch 2000] loss: 0.05790430498425849
[Epoch 3, Batch 2100] loss: 0.08066413977649063
[Epoch 3, Batch 2200] loss: 0.07724032003781758
[Epoch 3, Batch 2300] loss: 0.06362898965599015
[Epoch 3, Batch 2400] loss: 0.059000026100547984
[Epoch 3, Batch 2500] loss: 0.057630643638549375
[Epoch 3, Batch 2600] loss: 0.06928216283093207
[Epoch 3, Batch 2700] loss: 0.06184246844612062
[Epoch 3, Batch 2800] loss: 0.09015407644328662
[Epoch 3, Batch 2900] loss: 0.06626990614633542
[Epoch 3, Batch 3000] loss: 0.08015661975776311
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0759
Validation Accuracy: 0.9768
Overfitting: 0.0759
Best model saved at epoch 3 with validation loss: 0.0759
[Epoch 4, Batch 100] loss: 0.05993080312095117
[Epoch 4, Batch 200] loss: 0.06318329074769281
[Epoch 4, Batch 300] loss: 0.05988306366256438
[Epoch 4, Batch 400] loss: 0.062307007321505806
[Epoch 4, Batch 500] loss: 0.0650140230054967
[Epoch 4, Batch 600] loss: 0.07324126804829575
[Epoch 4, Batch 700] loss: 0.07287166766589508
[Epoch 4, Batch 800] loss: 0.06952883811289212
[Epoch 4, Batch 900] loss: 0.06170374716690276
[Epoch 4, Batch 1000] loss: 0.058825871003209615
[Epoch 4, Batch 1100] loss: 0.05438595937972423
[Epoch 4, Batch 1200] loss: 0.04700616455753334
[Epoch 4, Batch 1300] loss: 0.0715268584061414
[Epoch 4, Batch 1400] loss: 0.08516728491464164
[Epoch 4, Batch 1500] loss: 0.04837115550559247
[Epoch 4, Batch 1600] loss: 0.05461506431078306
[Epoch 4, Batch 1700] loss: 0.07441969535197131
[Epoch 4, Batch 1800] loss: 0.03958253611635883
[Epoch 4, Batch 1900] loss: 0.07239397910714615
[Epoch 4, Batch 2000] loss: 0.07239849584468175
[Epoch 4, Batch 2100] loss: 0.05269759425427765
[Epoch 4, Batch 2200] loss: 0.05333678694383707
[Epoch 4, Batch 2300] loss: 0.0641418348409934
[Epoch 4, Batch 2400] loss: 0.051082895470317455
[Epoch 4, Batch 2500] loss: 0.0810976413229946
[Epoch 4, Batch 2600] loss: 0.04928386789164506
[Epoch 4, Batch 2700] loss: 0.06650232368265278
[Epoch 4, Batch 2800] loss: 0.05636978026042925
[Epoch 4, Batch 2900] loss: 0.0478933719813358
[Epoch 4, Batch 3000] loss: 0.06262585784657858
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0574
Validation Accuracy: 0.9827
Overfitting: 0.0574
Best model saved at epoch 4 with validation loss: 0.0574
[Epoch 5, Batch 100] loss: 0.048312521637999456
[Epoch 5, Batch 200] loss: 0.044132561014266686
[Epoch 5, Batch 300] loss: 0.053029580093570984
[Epoch 5, Batch 400] loss: 0.06947213806852233
[Epoch 5, Batch 500] loss: 0.06430202148039825
[Epoch 5, Batch 600] loss: 0.049094942485680804
[Epoch 5, Batch 700] loss: 0.05962847806687933
[Epoch 5, Batch 800] loss: 0.04788433973008068
[Epoch 5, Batch 900] loss: 0.05465920460526832
[Epoch 5, Batch 1000] loss: 0.04644330201175762
[Epoch 5, Batch 1100] loss: 0.056991791118634866
[Epoch 5, Batch 1200] loss: 0.04345464670594083
[Epoch 5, Batch 1300] loss: 0.043265764175448564
[Epoch 5, Batch 1400] loss: 0.03846043500408996
[Epoch 5, Batch 1500] loss: 0.05918293541268213
[Epoch 5, Batch 1600] loss: 0.054102268944261594
[Epoch 5, Batch 1700] loss: 0.05136249986098847
[Epoch 5, Batch 1800] loss: 0.048643422623426885
[Epoch 5, Batch 1900] loss: 0.05289505403576186
[Epoch 5, Batch 2000] loss: 0.048568365455721504
[Epoch 5, Batch 2100] loss: 0.049730109322990754
[Epoch 5, Batch 2200] loss: 0.045409372469293885
[Epoch 5, Batch 2300] loss: 0.04799871188180987
[Epoch 5, Batch 2400] loss: 0.04320344838313758
[Epoch 5, Batch 2500] loss: 0.04819570361665683
[Epoch 5, Batch 2600] loss: 0.04240136131993495
[Epoch 5, Batch 2700] loss: 0.05064598012948409
[Epoch 5, Batch 2800] loss: 0.048489374038472303
[Epoch 5, Batch 2900] loss: 0.055816167336888614
[Epoch 5, Batch 3000] loss: 0.05584729144786252
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9826
Overfitting: 0.0552
Best model saved at epoch 5 with validation loss: 0.0552
[Epoch 6, Batch 100] loss: 0.03754626861831639
[Epoch 6, Batch 200] loss: 0.03375529998069396
[Epoch 6, Batch 300] loss: 0.04517133145709522
[Epoch 6, Batch 400] loss: 0.040052992183191236
[Epoch 6, Batch 500] loss: 0.03842787623929325
[Epoch 6, Batch 600] loss: 0.054314766434108604
[Epoch 6, Batch 700] loss: 0.04418949716957286
[Epoch 6, Batch 800] loss: 0.03634416750981472
[Epoch 6, Batch 900] loss: 0.0428692161134677
[Epoch 6, Batch 1000] loss: 0.05079451635538135
[Epoch 6, Batch 1100] loss: 0.04478182642866159
[Epoch 6, Batch 1200] loss: 0.046594334430992604
[Epoch 6, Batch 1300] loss: 0.040846546299871986
[Epoch 6, Batch 1400] loss: 0.030291204937093426
[Epoch 6, Batch 1500] loss: 0.055294640396896286
[Epoch 6, Batch 1600] loss: 0.04448305594181875
[Epoch 6, Batch 1700] loss: 0.050459047900803855
[Epoch 6, Batch 1800] loss: 0.04803264199552359
[Epoch 6, Batch 1900] loss: 0.04670442213770002
[Epoch 6, Batch 2000] loss: 0.048156359952845375
[Epoch 6, Batch 2100] loss: 0.03858067584020319
[Epoch 6, Batch 2200] loss: 0.04666428965632804
[Epoch 6, Batch 2300] loss: 0.0416399693407584
[Epoch 6, Batch 2400] loss: 0.04742976822308265
[Epoch 6, Batch 2500] loss: 0.04293816721852636
[Epoch 6, Batch 2600] loss: 0.042240163507231046
[Epoch 6, Batch 2700] loss: 0.0378057382607949
[Epoch 6, Batch 2800] loss: 0.05557523711875547
[Epoch 6, Batch 2900] loss: 0.03692620000452734
[Epoch 6, Batch 3000] loss: 0.05287633376196027
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0547
Validation Accuracy: 0.9822
Overfitting: 0.0547
Best model saved at epoch 6 with validation loss: 0.0547
[Epoch 7, Batch 100] loss: 0.04018605964112794
[Epoch 7, Batch 200] loss: 0.02272147930547362
[Epoch 7, Batch 300] loss: 0.04213673762482358
[Epoch 7, Batch 400] loss: 0.04432742340199183
[Epoch 7, Batch 500] loss: 0.04217439604602987
[Epoch 7, Batch 600] loss: 0.025646872065990464
[Epoch 7, Batch 700] loss: 0.03625820507571916
[Epoch 7, Batch 800] loss: 0.02581925030623097
[Epoch 7, Batch 900] loss: 0.039021284305636075
[Epoch 7, Batch 1000] loss: 0.035610238503140865
[Epoch 7, Batch 1100] loss: 0.03643032107007457
[Epoch 7, Batch 1200] loss: 0.04922237535618478
[Epoch 7, Batch 1300] loss: 0.046072643448715096
[Epoch 7, Batch 1400] loss: 0.05737300504464656
[Epoch 7, Batch 1500] loss: 0.03559360207305872
[Epoch 7, Batch 1600] loss: 0.039556880354066376
[Epoch 7, Batch 1700] loss: 0.038768422806460874
[Epoch 7, Batch 1800] loss: 0.030884426087868632
[Epoch 7, Batch 1900] loss: 0.032398648463131396
[Epoch 7, Batch 2000] loss: 0.03421882098016795
[Epoch 7, Batch 2100] loss: 0.03288350168368197
[Epoch 7, Batch 2200] loss: 0.03292286993440939
[Epoch 7, Batch 2300] loss: 0.04596267922199331
[Epoch 7, Batch 2400] loss: 0.029161744653683853
[Epoch 7, Batch 2500] loss: 0.030824723117111718
[Epoch 7, Batch 2600] loss: 0.03096855596115347
[Epoch 7, Batch 2700] loss: 0.037416748525865844
[Epoch 7, Batch 2800] loss: 0.040845168610394465
[Epoch 7, Batch 2900] loss: 0.030962050032248955
[Epoch 7, Batch 3000] loss: 0.051212182134040635
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9846
Overfitting: 0.0486
Best model saved at epoch 7 with validation loss: 0.0486
[Epoch 8, Batch 100] loss: 0.028758606091723777
[Epoch 8, Batch 200] loss: 0.030631073165568522
[Epoch 8, Batch 300] loss: 0.03239280186680844
[Epoch 8, Batch 400] loss: 0.03459295994805871
[Epoch 8, Batch 500] loss: 0.037822620954248126
[Epoch 8, Batch 600] loss: 0.024235854939324782
[Epoch 8, Batch 700] loss: 0.04155233725949074
[Epoch 8, Batch 800] loss: 0.060831409592501585
[Epoch 8, Batch 900] loss: 0.027742238032078603
[Epoch 8, Batch 1000] loss: 0.025865786777067114
[Epoch 8, Batch 1100] loss: 0.04000095946263173
[Epoch 8, Batch 1200] loss: 0.031203217892471
[Epoch 8, Batch 1300] loss: 0.028796170365567378
[Epoch 8, Batch 1400] loss: 0.029770231959264492
[Epoch 8, Batch 1500] loss: 0.028912282526725903
[Epoch 8, Batch 1600] loss: 0.03030168940560543
[Epoch 8, Batch 1700] loss: 0.030103926846786633
[Epoch 8, Batch 1800] loss: 0.029655704788456205
[Epoch 8, Batch 1900] loss: 0.0370257465603936
[Epoch 8, Batch 2000] loss: 0.03622112719625875
[Epoch 8, Batch 2100] loss: 0.03168625635014905
[Epoch 8, Batch 2200] loss: 0.02599338821397396
[Epoch 8, Batch 2300] loss: 0.019856681498349644
[Epoch 8, Batch 2400] loss: 0.03519685613420734
[Epoch 8, Batch 2500] loss: 0.032010174364259
[Epoch 8, Batch 2600] loss: 0.04248496910709946
[Epoch 8, Batch 2700] loss: 0.03773011692625005
[Epoch 8, Batch 2800] loss: 0.03132511721320043
[Epoch 8, Batch 2900] loss: 0.027096670340179117
[Epoch 8, Batch 3000] loss: 0.022900489002204268
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0425
Validation Accuracy: 0.9861
Overfitting: 0.0425
Best model saved at epoch 8 with validation loss: 0.0425
[Epoch 9, Batch 100] loss: 0.03355182050727308
[Epoch 9, Batch 200] loss: 0.03729463873998611
[Epoch 9, Batch 300] loss: 0.03707604767390876
[Epoch 9, Batch 400] loss: 0.02458520679094363
[Epoch 9, Batch 500] loss: 0.019538197087094887
[Epoch 9, Batch 600] loss: 0.02750090115237981
[Epoch 9, Batch 700] loss: 0.022502186723977503
[Epoch 9, Batch 800] loss: 0.03475183103662857
[Epoch 9, Batch 900] loss: 0.014466158565046499
[Epoch 9, Batch 1000] loss: 0.036692965762158566
[Epoch 9, Batch 1100] loss: 0.04094724267924903
[Epoch 9, Batch 1200] loss: 0.0328477162267518
[Epoch 9, Batch 1300] loss: 0.026585650349152275
[Epoch 9, Batch 1400] loss: 0.01777790137100965
[Epoch 9, Batch 1500] loss: 0.03139881063834764
[Epoch 9, Batch 1600] loss: 0.027060129386500195
[Epoch 9, Batch 1700] loss: 0.023035580542345998
[Epoch 9, Batch 1800] loss: 0.031420929063169754
[Epoch 9, Batch 1900] loss: 0.015496306571076274
[Epoch 9, Batch 2000] loss: 0.024609821431804447
[Epoch 9, Batch 2100] loss: 0.02457644390669884
[Epoch 9, Batch 2200] loss: 0.03505674665328115
[Epoch 9, Batch 2300] loss: 0.021830212511340506
[Epoch 9, Batch 2400] loss: 0.028015523818066868
[Epoch 9, Batch 2500] loss: 0.015549764697316277
[Epoch 9, Batch 2600] loss: 0.04325753622410957
[Epoch 9, Batch 2700] loss: 0.03080684779211879
[Epoch 9, Batch 2800] loss: 0.04034931959133246
[Epoch 9, Batch 2900] loss: 0.029127442501339827
[Epoch 9, Batch 3000] loss: 0.029382710867139394
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9836
Overfitting: 0.0506
[Epoch 10, Batch 100] loss: 0.0282929293543566
[Epoch 10, Batch 200] loss: 0.022117016828487976
[Epoch 10, Batch 300] loss: 0.028050241528762853
[Epoch 10, Batch 400] loss: 0.01846754044898262
[Epoch 10, Batch 500] loss: 0.027867778098443523
[Epoch 10, Batch 600] loss: 0.01880571633024374
[Epoch 10, Batch 700] loss: 0.023523012341975118
[Epoch 10, Batch 800] loss: 0.02993683724580478
[Epoch 10, Batch 900] loss: 0.03196740692561434
[Epoch 10, Batch 1000] loss: 0.01942151726965676
[Epoch 10, Batch 1100] loss: 0.020176319612073713
[Epoch 10, Batch 1200] loss: 0.030346287675492932
[Epoch 10, Batch 1300] loss: 0.03171605864510638
[Epoch 10, Batch 1400] loss: 0.026900482792116237
[Epoch 10, Batch 1500] loss: 0.031567931102763395
[Epoch 10, Batch 1600] loss: 0.01854623093327973
[Epoch 10, Batch 1700] loss: 0.03730777189230139
[Epoch 10, Batch 1800] loss: 0.0266232388264325
[Epoch 10, Batch 1900] loss: 0.028914055403656675
[Epoch 10, Batch 2000] loss: 0.0199189123751421
[Epoch 10, Batch 2100] loss: 0.03193919653058401
[Epoch 10, Batch 2200] loss: 0.024061676994751906
[Epoch 10, Batch 2300] loss: 0.025644450662912276
[Epoch 10, Batch 2400] loss: 0.01766437951930129
[Epoch 10, Batch 2500] loss: 0.02600424671793007
[Epoch 10, Batch 2600] loss: 0.03610622030835657
[Epoch 10, Batch 2700] loss: 0.029677800499994193
[Epoch 10, Batch 2800] loss: 0.015669742467580364
[Epoch 10, Batch 2900] loss: 0.0256181147128882
[Epoch 10, Batch 3000] loss: 0.03115206633985508
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0421
Validation Accuracy: 0.9872
Overfitting: 0.0421
Best model saved at epoch 10 with validation loss: 0.0421
[Epoch 11, Batch 100] loss: 0.01985104140767362
[Epoch 11, Batch 200] loss: 0.02418599170316156
[Epoch 11, Batch 300] loss: 0.01595734399619687
[Epoch 11, Batch 400] loss: 0.02635451855720021
[Epoch 11, Batch 500] loss: 0.021851136469631455
[Epoch 11, Batch 600] loss: 0.015419138518846012
[Epoch 11, Batch 700] loss: 0.020078024952163105
[Epoch 11, Batch 800] loss: 0.014590539219116181
[Epoch 11, Batch 900] loss: 0.02034803779617505
[Epoch 11, Batch 1000] loss: 0.02261571552422538
[Epoch 11, Batch 1100] loss: 0.017513914948067394
[Epoch 11, Batch 1200] loss: 0.025746520937027527
[Epoch 11, Batch 1300] loss: 0.023854051240450643
[Epoch 11, Batch 1400] loss: 0.016105826915518266
[Epoch 11, Batch 1500] loss: 0.008547793340048883
[Epoch 11, Batch 1600] loss: 0.019984833242288006
[Epoch 11, Batch 1700] loss: 0.029199266660016293
[Epoch 11, Batch 1800] loss: 0.019552737446792888
[Epoch 11, Batch 1900] loss: 0.03460504767323073
[Epoch 11, Batch 2000] loss: 0.02596549780537316
[Epoch 11, Batch 2100] loss: 0.017840770541661187
[Epoch 11, Batch 2200] loss: 0.01993554308435705
[Epoch 11, Batch 2300] loss: 0.021085886445089273
[Epoch 11, Batch 2400] loss: 0.025568401170967262
[Epoch 11, Batch 2500] loss: 0.030855456338322255
[Epoch 11, Batch 2600] loss: 0.028431965204435982
[Epoch 11, Batch 2700] loss: 0.01668808469308715
[Epoch 11, Batch 2800] loss: 0.025850975420180475
[Epoch 11, Batch 2900] loss: 0.02547298232173489
[Epoch 11, Batch 3000] loss: 0.029188223721139366
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9864
Overfitting: 0.0465
[Epoch 12, Batch 100] loss: 0.014891588797254371
[Epoch 12, Batch 200] loss: 0.021388257828220958
[Epoch 12, Batch 300] loss: 0.02291759069172258
[Epoch 12, Batch 400] loss: 0.014994820745341713
[Epoch 12, Batch 500] loss: 0.022311402872001052
[Epoch 12, Batch 600] loss: 0.01651147688605306
[Epoch 12, Batch 700] loss: 0.02090196708952135
[Epoch 12, Batch 800] loss: 0.01910485689280904
[Epoch 12, Batch 900] loss: 0.02440915661132749
[Epoch 12, Batch 1000] loss: 0.015728282533600577
[Epoch 12, Batch 1100] loss: 0.019902890123266844
[Epoch 12, Batch 1200] loss: 0.024888300139282366
[Epoch 12, Batch 1300] loss: 0.02243755488707393
[Epoch 12, Batch 1400] loss: 0.02210296317716711
[Epoch 12, Batch 1500] loss: 0.02111437427924102
[Epoch 12, Batch 1600] loss: 0.022297214564459863
[Epoch 12, Batch 1700] loss: 0.015039984344857657
[Epoch 12, Batch 1800] loss: 0.024683242251121555
[Epoch 12, Batch 1900] loss: 0.016867452084679827
[Epoch 12, Batch 2000] loss: 0.027463198143977935
[Epoch 12, Batch 2100] loss: 0.01682361884117199
[Epoch 12, Batch 2200] loss: 0.024930442259355912
[Epoch 12, Batch 2300] loss: 0.015111996963605634
[Epoch 12, Batch 2400] loss: 0.0160681887429746
[Epoch 12, Batch 2500] loss: 0.019044566258999113
[Epoch 12, Batch 2600] loss: 0.019805057729245165
[Epoch 12, Batch 2700] loss: 0.02234779674008678
[Epoch 12, Batch 2800] loss: 0.024834904240306058
[Epoch 12, Batch 2900] loss: 0.01958527227237937
[Epoch 12, Batch 3000] loss: 0.030151237610771205
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0433
Validation Accuracy: 0.9870
Overfitting: 0.0433
[Epoch 13, Batch 100] loss: 0.017165017121878918
[Epoch 13, Batch 200] loss: 0.016247734158641832
[Epoch 13, Batch 300] loss: 0.02267977270286792
[Epoch 13, Batch 400] loss: 0.021589404572805507
[Epoch 13, Batch 500] loss: 0.014032966610629955
[Epoch 13, Batch 600] loss: 0.019036605267974665
[Epoch 13, Batch 700] loss: 0.011666324106336105
[Epoch 13, Batch 800] loss: 0.008897833505070594
[Epoch 13, Batch 900] loss: 0.011390619483690897
[Epoch 13, Batch 1000] loss: 0.018674091122338723
[Epoch 13, Batch 1100] loss: 0.019374231687179416
[Epoch 13, Batch 1200] loss: 0.02025629257524997
[Epoch 13, Batch 1300] loss: 0.020007254011870826
[Epoch 13, Batch 1400] loss: 0.02032913196941081
[Epoch 13, Batch 1500] loss: 0.02792445689010492
[Epoch 13, Batch 1600] loss: 0.024747559365423513
[Epoch 13, Batch 1700] loss: 0.025293704357900425
[Epoch 13, Batch 1800] loss: 0.01718816547439019
[Epoch 13, Batch 1900] loss: 0.02134522168949843
[Epoch 13, Batch 2000] loss: 0.01647947461655349
[Epoch 13, Batch 2100] loss: 0.015610601039588801
[Epoch 13, Batch 2200] loss: 0.014367088963772402
[Epoch 13, Batch 2300] loss: 0.019077559059587655
[Epoch 13, Batch 2400] loss: 0.013710398669809365
[Epoch 13, Batch 2500] loss: 0.028818180624839443
[Epoch 13, Batch 2600] loss: 0.012236727359922952
[Epoch 13, Batch 2700] loss: 0.0221078469324857
[Epoch 13, Batch 2800] loss: 0.0194276049517066
[Epoch 13, Batch 2900] loss: 0.017264612713261157
[Epoch 13, Batch 3000] loss: 0.021638359899807256
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0398
Validation Accuracy: 0.9878
Overfitting: 0.0398
Best model saved at epoch 13 with validation loss: 0.0398
[Epoch 14, Batch 100] loss: 0.0074250950875284615
[Epoch 14, Batch 200] loss: 0.011295827828125765
[Epoch 14, Batch 300] loss: 0.010616109874699759
[Epoch 14, Batch 400] loss: 0.01713599682867425
[Epoch 14, Batch 500] loss: 0.011205442084683454
[Epoch 14, Batch 600] loss: 0.014829928133385692
[Epoch 14, Batch 700] loss: 0.011929902220181247
[Epoch 14, Batch 800] loss: 0.02406755005238665
[Epoch 14, Batch 900] loss: 0.013420215632904728
[Epoch 14, Batch 1000] loss: 0.020155324547995405
[Epoch 14, Batch 1100] loss: 0.01798819358642504
[Epoch 14, Batch 1200] loss: 0.015592249352712315
[Epoch 14, Batch 1300] loss: 0.018481219008463085
[Epoch 14, Batch 1400] loss: 0.019710304115214967
[Epoch 14, Batch 1500] loss: 0.015942919523931776
[Epoch 14, Batch 1600] loss: 0.010979565326088049
[Epoch 14, Batch 1700] loss: 0.009456628869775158
[Epoch 14, Batch 1800] loss: 0.01667498713337409
[Epoch 14, Batch 1900] loss: 0.017622486911459418
[Epoch 14, Batch 2000] loss: 0.014259042767062056
[Epoch 14, Batch 2100] loss: 0.014092627913923935
[Epoch 14, Batch 2200] loss: 0.023578482415978215
[Epoch 14, Batch 2300] loss: 0.018369753149090683
[Epoch 14, Batch 2400] loss: 0.016508585301389756
[Epoch 14, Batch 2500] loss: 0.024780556119694666
[Epoch 14, Batch 2600] loss: 0.016482176432637063
[Epoch 14, Batch 2700] loss: 0.013341787458284671
[Epoch 14, Batch 2800] loss: 0.01775706834219818
[Epoch 14, Batch 2900] loss: 0.019512883545885415
[Epoch 14, Batch 3000] loss: 0.025786229768855265
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0390
Validation Accuracy: 0.9882
Overfitting: 0.0390
Best model saved at epoch 14 with validation loss: 0.0390
[Epoch 15, Batch 100] loss: 0.01687687564360658
[Epoch 15, Batch 200] loss: 0.01219073695341649
[Epoch 15, Batch 300] loss: 0.01058575951750754
[Epoch 15, Batch 400] loss: 0.014208617125514139
[Epoch 15, Batch 500] loss: 0.03841310021854952
[Epoch 15, Batch 600] loss: 0.015217978882137686
[Epoch 15, Batch 700] loss: 0.012270317147595052
[Epoch 15, Batch 800] loss: 0.01162920500672044
[Epoch 15, Batch 900] loss: 0.017717500692178874
[Epoch 15, Batch 1000] loss: 0.02093085788197641
[Epoch 15, Batch 1100] loss: 0.017477753747916724
[Epoch 15, Batch 1200] loss: 0.017541317167278976
[Epoch 15, Batch 1300] loss: 0.0030432417126121437
[Epoch 15, Batch 1400] loss: 0.01646960713218505
[Epoch 15, Batch 1500] loss: 0.016179355929853045
[Epoch 15, Batch 1600] loss: 0.01566554292928231
[Epoch 15, Batch 1700] loss: 0.01966252078746038
[Epoch 15, Batch 1800] loss: 0.015255012193629227
[Epoch 15, Batch 1900] loss: 0.009695552871880864
[Epoch 15, Batch 2000] loss: 0.01423004902077082
[Epoch 15, Batch 2100] loss: 0.012897915118746823
[Epoch 15, Batch 2200] loss: 0.01229983036797421
[Epoch 15, Batch 2300] loss: 0.010527452218248072
[Epoch 15, Batch 2400] loss: 0.013688059931173484
[Epoch 15, Batch 2500] loss: 0.00628145412529193
[Epoch 15, Batch 2600] loss: 0.019709653090339996
[Epoch 15, Batch 2700] loss: 0.011637244023149832
[Epoch 15, Batch 2800] loss: 0.012975681605494173
[Epoch 15, Batch 2900] loss: 0.015294280562666246
[Epoch 15, Batch 3000] loss: 0.007605526339280005
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9859
Overfitting: 0.0478
[Epoch 16, Batch 100] loss: 0.014344058610477077
[Epoch 16, Batch 200] loss: 0.014585116310208833
[Epoch 16, Batch 300] loss: 0.01224130833664276
[Epoch 16, Batch 400] loss: 0.015325519656471442
[Epoch 16, Batch 500] loss: 0.014489847606755575
[Epoch 16, Batch 600] loss: 0.013350124822136423
[Epoch 16, Batch 700] loss: 0.01216418549656737
[Epoch 16, Batch 800] loss: 0.007619164017387448
[Epoch 16, Batch 900] loss: 0.010136481561776236
[Epoch 16, Batch 1000] loss: 0.012289639204359446
[Epoch 16, Batch 1100] loss: 0.021789847326817834
[Epoch 16, Batch 1200] loss: 0.011731331501523527
[Epoch 16, Batch 1300] loss: 0.013020993000136514
[Epoch 16, Batch 1400] loss: 0.008362839887959127
[Epoch 16, Batch 1500] loss: 0.01868041782244518
[Epoch 16, Batch 1600] loss: 0.012275398742985999
[Epoch 16, Batch 1700] loss: 0.009189184454216957
[Epoch 16, Batch 1800] loss: 0.012161696654711705
[Epoch 16, Batch 1900] loss: 0.021253709616685226
[Epoch 16, Batch 2000] loss: 0.008803757979812872
[Epoch 16, Batch 2100] loss: 0.007483045238877821
[Epoch 16, Batch 2200] loss: 0.007050702007013569
[Epoch 16, Batch 2300] loss: 0.013491961105301016
[Epoch 16, Batch 2400] loss: 0.00855459713109667
[Epoch 16, Batch 2500] loss: 0.010862295485387675
[Epoch 16, Batch 2600] loss: 0.020122517192671694
[Epoch 16, Batch 2700] loss: 0.021459695952917173
[Epoch 16, Batch 2800] loss: 0.01964563973258919
[Epoch 16, Batch 2900] loss: 0.00910336934960469
[Epoch 16, Batch 3000] loss: 0.011289032515396685
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9883
Overfitting: 0.0457
[Epoch 17, Batch 100] loss: 0.013496713480781181
[Epoch 17, Batch 200] loss: 0.0089897937526257
[Epoch 17, Batch 300] loss: 0.011606118137169687
[Epoch 17, Batch 400] loss: 0.008578569506180429
[Epoch 17, Batch 500] loss: 0.00952929122746582
[Epoch 17, Batch 600] loss: 0.005487570939567377
[Epoch 17, Batch 700] loss: 0.006619517585331778
[Epoch 17, Batch 800] loss: 0.01142166676020679
[Epoch 17, Batch 900] loss: 0.008923771792574371
[Epoch 17, Batch 1000] loss: 0.008882998622966624
[Epoch 17, Batch 1100] loss: 0.006658716606279995
[Epoch 17, Batch 1200] loss: 0.012428492889484914
[Epoch 17, Batch 1300] loss: 0.01833574294254504
[Epoch 17, Batch 1400] loss: 0.013637088042751202
[Epoch 17, Batch 1500] loss: 0.010337993337641365
[Epoch 17, Batch 1600] loss: 0.010110484974138672
[Epoch 17, Batch 1700] loss: 0.010143700358512434
[Epoch 17, Batch 1800] loss: 0.006645344769026451
[Epoch 17, Batch 1900] loss: 0.015770527211439
[Epoch 17, Batch 2000] loss: 0.01684631021261339
[Epoch 17, Batch 2100] loss: 0.007069993283926124
[Epoch 17, Batch 2200] loss: 0.012625593732791459
[Epoch 17, Batch 2300] loss: 0.008863220082544103
[Epoch 17, Batch 2400] loss: 0.009992388255132028
[Epoch 17, Batch 2500] loss: 0.011259600341491023
[Epoch 17, Batch 2600] loss: 0.016737452865145316
[Epoch 17, Batch 2700] loss: 0.017060347094702593
[Epoch 17, Batch 2800] loss: 0.00922205258599206
[Epoch 17, Batch 2900] loss: 0.021682277070849524
[Epoch 17, Batch 3000] loss: 0.015412902832968029
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0397
Validation Accuracy: 0.9889
Overfitting: 0.0397
[Epoch 18, Batch 100] loss: 0.006131777084542591
[Epoch 18, Batch 200] loss: 0.019744103362036185
[Epoch 18, Batch 300] loss: 0.006767103722785351
[Epoch 18, Batch 400] loss: 0.010221466995699303
[Epoch 18, Batch 500] loss: 0.008330873712882863
[Epoch 18, Batch 600] loss: 0.005521128750697244
[Epoch 18, Batch 700] loss: 0.007271744053878137
[Epoch 18, Batch 800] loss: 0.00903723185700983
[Epoch 18, Batch 900] loss: 0.011318575208342736
[Epoch 18, Batch 1000] loss: 0.011421444886136669
[Epoch 18, Batch 1100] loss: 0.010385781013292216
[Epoch 18, Batch 1200] loss: 0.010774336185045285
[Epoch 18, Batch 1300] loss: 0.010915002265464864
[Epoch 18, Batch 1400] loss: 0.011455376255544252
[Epoch 18, Batch 1500] loss: 0.005486017392331633
[Epoch 18, Batch 1600] loss: 0.010347670422806914
[Epoch 18, Batch 1700] loss: 0.0059245193271090105
[Epoch 18, Batch 1800] loss: 0.0073189099005276145
[Epoch 18, Batch 1900] loss: 0.017119357685928663
[Epoch 18, Batch 2000] loss: 0.009486954285564479
[Epoch 18, Batch 2100] loss: 0.009297046597721419
[Epoch 18, Batch 2200] loss: 0.01354277400670071
[Epoch 18, Batch 2300] loss: 0.013528864699997029
[Epoch 18, Batch 2400] loss: 0.009524852544664099
[Epoch 18, Batch 2500] loss: 0.01700328162812184
[Epoch 18, Batch 2600] loss: 0.009552132005828752
[Epoch 18, Batch 2700] loss: 0.014244616248606689
[Epoch 18, Batch 2800] loss: 0.009811153799596468
[Epoch 18, Batch 2900] loss: 0.01609841291925477
[Epoch 18, Batch 3000] loss: 0.007133675924246745
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0396
Validation Accuracy: 0.9902
Overfitting: 0.0396
[Epoch 19, Batch 100] loss: 0.005258067900131209
[Epoch 19, Batch 200] loss: 0.009178262965446039
[Epoch 19, Batch 300] loss: 0.00905821522964061
[Epoch 19, Batch 400] loss: 0.011111279396855024
[Epoch 19, Batch 500] loss: 0.006900921469541572
[Epoch 19, Batch 600] loss: 0.008261824632304524
[Epoch 19, Batch 700] loss: 0.005335794698221434
[Epoch 19, Batch 800] loss: 0.007916742372390217
[Epoch 19, Batch 900] loss: 0.011731552996855044
[Epoch 19, Batch 1000] loss: 0.014611349891731606
[Epoch 19, Batch 1100] loss: 0.015002041766520051
[Epoch 19, Batch 1200] loss: 0.004218548911740072
[Epoch 19, Batch 1300] loss: 0.006228258520732197
[Epoch 19, Batch 1400] loss: 0.0076767806039583775
[Epoch 19, Batch 1500] loss: 0.01043434814298962
[Epoch 19, Batch 1600] loss: 0.012023881951333805
[Epoch 19, Batch 1700] loss: 0.011176624630625156
[Epoch 19, Batch 1800] loss: 0.011513723495518206
[Epoch 19, Batch 1900] loss: 0.0034789302929084443
[Epoch 19, Batch 2000] loss: 0.006320088812326503
[Epoch 19, Batch 2100] loss: 0.012369003823723688
[Epoch 19, Batch 2200] loss: 0.009191970911756471
[Epoch 19, Batch 2300] loss: 0.013524105779606544
[Epoch 19, Batch 2400] loss: 0.012805538349764447
[Epoch 19, Batch 2500] loss: 0.011258894675875127
[Epoch 19, Batch 2600] loss: 0.011507569671257442
[Epoch 19, Batch 2700] loss: 0.004875938453133131
[Epoch 19, Batch 2800] loss: 0.010628203136616322
[Epoch 19, Batch 2900] loss: 0.009704727567327608
[Epoch 19, Batch 3000] loss: 0.020859431876924645
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9888
Overfitting: 0.0447
[Epoch 20, Batch 100] loss: 0.005636390194042633
[Epoch 20, Batch 200] loss: 0.010634631544326112
[Epoch 20, Batch 300] loss: 0.004500531666353709
[Epoch 20, Batch 400] loss: 0.009864526169794772
[Epoch 20, Batch 500] loss: 0.010206908157374527
[Epoch 20, Batch 600] loss: 0.004646369076069732
[Epoch 20, Batch 700] loss: 0.0046728369456855035
[Epoch 20, Batch 800] loss: 0.00877955769590244
[Epoch 20, Batch 900] loss: 0.008539004099363865
[Epoch 20, Batch 1000] loss: 0.022496359759704775
[Epoch 20, Batch 1100] loss: 0.007566539462172841
[Epoch 20, Batch 1200] loss: 0.004527529494234841
[Epoch 20, Batch 1300] loss: 0.008418168113000774
[Epoch 20, Batch 1400] loss: 0.009477059345299495
[Epoch 20, Batch 1500] loss: 0.0065938159050938335
[Epoch 20, Batch 1600] loss: 0.007821889586875842
[Epoch 20, Batch 1700] loss: 0.009033697683685204
[Epoch 20, Batch 1800] loss: 0.009833690686641604
[Epoch 20, Batch 1900] loss: 0.007810937472258956
[Epoch 20, Batch 2000] loss: 0.007727608052416599
[Epoch 20, Batch 2100] loss: 0.008522265169697221
[Epoch 20, Batch 2200] loss: 0.017524777114224434
[Epoch 20, Batch 2300] loss: 0.008224945127703904
[Epoch 20, Batch 2400] loss: 0.009706767758034402
[Epoch 20, Batch 2500] loss: 0.009111268229751203
[Epoch 20, Batch 2600] loss: 0.013319437840518731
[Epoch 20, Batch 2700] loss: 0.005159871319974627
[Epoch 20, Batch 2800] loss: 0.00554969656943058
[Epoch 20, Batch 2900] loss: 0.004613932619868137
[Epoch 20, Batch 3000] loss: 0.014693321456416015
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0620
Validation Accuracy: 0.9843
Overfitting: 0.0620
[Epoch 21, Batch 100] loss: 0.008801247320789116
[Epoch 21, Batch 200] loss: 0.010018994158356236
[Epoch 21, Batch 300] loss: 0.0052330624448813975
[Epoch 21, Batch 400] loss: 0.004381149901769276
[Epoch 21, Batch 500] loss: 0.004495509525449961
[Epoch 21, Batch 600] loss: 0.004138786968178465
[Epoch 21, Batch 700] loss: 0.010149677145332135
[Epoch 21, Batch 800] loss: 0.009590272992586506
[Epoch 21, Batch 900] loss: 0.007502168049456941
[Epoch 21, Batch 1000] loss: 0.0069136311698639475
[Epoch 21, Batch 1100] loss: 0.0063438464131058935
[Epoch 21, Batch 1200] loss: 0.003422213634014497
[Epoch 21, Batch 1300] loss: 0.009544549190341058
[Epoch 21, Batch 1400] loss: 0.007376705059007236
[Epoch 21, Batch 1500] loss: 0.012315795021113445
[Epoch 21, Batch 1600] loss: 0.0033846571900289744
[Epoch 21, Batch 1700] loss: 0.006047734891549226
[Epoch 21, Batch 1800] loss: 0.008578476034164168
[Epoch 21, Batch 1900] loss: 0.006799873196760018
[Epoch 21, Batch 2000] loss: 0.0076119346849873185
[Epoch 21, Batch 2100] loss: 0.0067293702526581
[Epoch 21, Batch 2200] loss: 0.013443572599244362
[Epoch 21, Batch 2300] loss: 0.0059233472798194955
[Epoch 21, Batch 2400] loss: 0.005274257164259666
[Epoch 21, Batch 2500] loss: 0.0066457256071018374
[Epoch 21, Batch 2600] loss: 0.011309346594964608
[Epoch 21, Batch 2700] loss: 0.008255717912995807
[Epoch 21, Batch 2800] loss: 0.006296229442468757
[Epoch 21, Batch 2900] loss: 0.015613487360824366
[Epoch 21, Batch 3000] loss: 0.003258075069852566
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0394
Validation Accuracy: 0.9902
Overfitting: 0.0394
[Epoch 22, Batch 100] loss: 0.008002268936625114
[Epoch 22, Batch 200] loss: 0.005299298978405887
[Epoch 22, Batch 300] loss: 0.0031351532769076586
[Epoch 22, Batch 400] loss: 0.004216072324189781
[Epoch 22, Batch 500] loss: 0.004796440824125056
[Epoch 22, Batch 600] loss: 0.0027319270117141057
[Epoch 22, Batch 700] loss: 0.005675883963755268
[Epoch 22, Batch 800] loss: 0.005023912440894947
[Epoch 22, Batch 900] loss: 0.007899250828382378
[Epoch 22, Batch 1000] loss: 0.005195543401432587
[Epoch 22, Batch 1100] loss: 0.0025836530370531817
[Epoch 22, Batch 1200] loss: 0.004320393705488641
[Epoch 22, Batch 1300] loss: 0.004981654758171317
[Epoch 22, Batch 1400] loss: 0.0024912808391673023
[Epoch 22, Batch 1500] loss: 0.0016500819339074725
[Epoch 22, Batch 1600] loss: 0.00395950248865006
[Epoch 22, Batch 1700] loss: 0.010837102727460888
[Epoch 22, Batch 1800] loss: 0.009987360704773778
[Epoch 22, Batch 1900] loss: 0.0055076964446152486
[Epoch 22, Batch 2000] loss: 0.001726039844594993
[Epoch 22, Batch 2100] loss: 0.0071590079559587134
[Epoch 22, Batch 2200] loss: 0.005171459022453746
[Epoch 22, Batch 2300] loss: 0.00907720529085509
[Epoch 22, Batch 2400] loss: 0.00558335701588021
[Epoch 22, Batch 2500] loss: 0.010315729861467275
[Epoch 22, Batch 2600] loss: 0.006767862153174065
[Epoch 22, Batch 2700] loss: 0.010300256050705912
[Epoch 22, Batch 2800] loss: 0.004310255505283749
[Epoch 22, Batch 2900] loss: 0.004053181141257767
[Epoch 22, Batch 3000] loss: 0.007500456753482467
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0405
Validation Accuracy: 0.9902
Overfitting: 0.0405
[Epoch 23, Batch 100] loss: 0.008757579244397675
[Epoch 23, Batch 200] loss: 0.004891966994578069
[Epoch 23, Batch 300] loss: 0.0032822146893988703
[Epoch 23, Batch 400] loss: 0.0018702726172114125
[Epoch 23, Batch 500] loss: 0.0034476574577536213
[Epoch 23, Batch 600] loss: 0.0056374451535543815
[Epoch 23, Batch 700] loss: 0.005138237726573607
[Epoch 23, Batch 800] loss: 0.003267059119575606
[Epoch 23, Batch 900] loss: 0.0045770048203633
[Epoch 23, Batch 1000] loss: 0.005941403253264071
[Epoch 23, Batch 1100] loss: 0.0026137194466451775
[Epoch 23, Batch 1200] loss: 0.003145325494451754
[Epoch 23, Batch 1300] loss: 0.0039343721724026184
[Epoch 23, Batch 1400] loss: 0.003542452937132339
[Epoch 23, Batch 1500] loss: 0.001988731424283969
[Epoch 23, Batch 1600] loss: 0.006600755377096448
[Epoch 23, Batch 1700] loss: 0.003288580644359058
[Epoch 23, Batch 1800] loss: 0.0056946606542572905
[Epoch 23, Batch 1900] loss: 0.004608982712013585
[Epoch 23, Batch 2000] loss: 0.002182659599614567
[Epoch 23, Batch 2100] loss: 0.004886786206053557
[Epoch 23, Batch 2200] loss: 0.010009630494425891
[Epoch 23, Batch 2300] loss: 0.0044009824753726435
[Epoch 23, Batch 2400] loss: 0.0027996781039507823
[Epoch 23, Batch 2500] loss: 0.006903067912101619
[Epoch 23, Batch 2600] loss: 0.004615152404938954
[Epoch 23, Batch 2700] loss: 0.009888330551657987
[Epoch 23, Batch 2800] loss: 0.007849184408070187
[Epoch 23, Batch 2900] loss: 0.013853440094076177
[Epoch 23, Batch 3000] loss: 0.005856223363032313
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9886
Overfitting: 0.0466
[Epoch 24, Batch 100] loss: 0.0036443906650458755
[Epoch 24, Batch 200] loss: 0.002243843911132899
[Epoch 24, Batch 300] loss: 0.0019837968948201025
[Epoch 24, Batch 400] loss: 0.0021519903671588735
[Epoch 24, Batch 500] loss: 0.0023630974119032543
[Epoch 24, Batch 600] loss: 0.004927645296440915
[Epoch 24, Batch 700] loss: 0.002303441117563807
[Epoch 24, Batch 800] loss: 0.002135128929617167
[Epoch 24, Batch 900] loss: 0.009117739210229275
[Epoch 24, Batch 1000] loss: 0.01028812663705935
[Epoch 24, Batch 1100] loss: 0.006562640500674206
[Epoch 24, Batch 1200] loss: 0.006124438747019667
[Epoch 24, Batch 1300] loss: 0.00977139089870434
[Epoch 24, Batch 1400] loss: 0.002727953539674104
[Epoch 24, Batch 1500] loss: 0.0016721006953423511
[Epoch 24, Batch 1600] loss: 0.007400083009874834
[Epoch 24, Batch 1700] loss: 0.005542970332184325
[Epoch 24, Batch 1800] loss: 0.00245495962280188
[Epoch 24, Batch 1900] loss: 0.0042994310402434625
[Epoch 24, Batch 2000] loss: 0.007729877117538138
[Epoch 24, Batch 2100] loss: 0.002790617539035338
[Epoch 24, Batch 2200] loss: 0.004506881928632111
[Epoch 24, Batch 2300] loss: 0.0034972263063650644
[Epoch 24, Batch 2400] loss: 0.004876557535011443
[Epoch 24, Batch 2500] loss: 0.006449114677186571
[Epoch 24, Batch 2600] loss: 0.003204055017045562
[Epoch 24, Batch 2700] loss: 0.0039896385361407735
[Epoch 24, Batch 2800] loss: 0.008264050460327325
[Epoch 24, Batch 2900] loss: 0.0057396739376872575
[Epoch 24, Batch 3000] loss: 0.003014825814746018
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0435
Validation Accuracy: 0.9901
Overfitting: 0.0435
Fold 3 validation loss: 0.0435
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.284945487976074
[Epoch 1, Batch 200] loss: 2.236404654979706
[Epoch 1, Batch 300] loss: 2.087363938093185
[Epoch 1, Batch 400] loss: 1.5180125886201858
[Epoch 1, Batch 500] loss: 0.7676040586829186
[Epoch 1, Batch 600] loss: 0.6033942534029484
[Epoch 1, Batch 700] loss: 0.5283991840481758
[Epoch 1, Batch 800] loss: 0.4529984986037016
[Epoch 1, Batch 900] loss: 0.46273119643330574
[Epoch 1, Batch 1000] loss: 0.38079964585602283
[Epoch 1, Batch 1100] loss: 0.34396955125033857
[Epoch 1, Batch 1200] loss: 0.3455599895119667
[Epoch 1, Batch 1300] loss: 0.3276001764088869
[Epoch 1, Batch 1400] loss: 0.3119803545437753
[Epoch 1, Batch 1500] loss: 0.27640626452863215
[Epoch 1, Batch 1600] loss: 0.280838714055717
[Epoch 1, Batch 1700] loss: 0.27835752015467735
[Epoch 1, Batch 1800] loss: 0.2363159603998065
[Epoch 1, Batch 1900] loss: 0.22725444139912723
[Epoch 1, Batch 2000] loss: 0.21810179321095347
[Epoch 1, Batch 2100] loss: 0.22617034548893572
[Epoch 1, Batch 2200] loss: 0.17999005874618887
[Epoch 1, Batch 2300] loss: 0.1924065363407135
[Epoch 1, Batch 2400] loss: 0.18623113080859185
[Epoch 1, Batch 2500] loss: 0.2145917271822691
[Epoch 1, Batch 2600] loss: 0.18189852714538574
[Epoch 1, Batch 2700] loss: 0.20227490545250476
[Epoch 1, Batch 2800] loss: 0.19643759303726255
[Epoch 1, Batch 2900] loss: 0.15457993521820754
[Epoch 1, Batch 3000] loss: 0.14220462971366943
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1541
Validation Accuracy: 0.9525
Overfitting: 0.1541
Best model saved at epoch 1 with validation loss: 0.1541
[Epoch 2, Batch 100] loss: 0.127394488863647
[Epoch 2, Batch 200] loss: 0.16772090214770288
[Epoch 2, Batch 300] loss: 0.15268869571387766
[Epoch 2, Batch 400] loss: 0.1480048295482993
[Epoch 2, Batch 500] loss: 0.12451997430296614
[Epoch 2, Batch 600] loss: 0.12181054204003885
[Epoch 2, Batch 700] loss: 0.13328021022956818
[Epoch 2, Batch 800] loss: 0.11825198889710009
[Epoch 2, Batch 900] loss: 0.11547862230800092
[Epoch 2, Batch 1000] loss: 0.1385324931750074
[Epoch 2, Batch 1100] loss: 0.12537829583510757
[Epoch 2, Batch 1200] loss: 0.13356832090299575
[Epoch 2, Batch 1300] loss: 0.13071009239181877
[Epoch 2, Batch 1400] loss: 0.1473227777471766
[Epoch 2, Batch 1500] loss: 0.12480392700061202
[Epoch 2, Batch 1600] loss: 0.14874344313517213
[Epoch 2, Batch 1700] loss: 0.11811598491389304
[Epoch 2, Batch 1800] loss: 0.13352476517204195
[Epoch 2, Batch 1900] loss: 0.11584004586795345
[Epoch 2, Batch 2000] loss: 0.13132293870672584
[Epoch 2, Batch 2100] loss: 0.12335537782870233
[Epoch 2, Batch 2200] loss: 0.13088284739525988
[Epoch 2, Batch 2300] loss: 0.09627928039990366
[Epoch 2, Batch 2400] loss: 0.10596745641203598
[Epoch 2, Batch 2500] loss: 0.09614269482437521
[Epoch 2, Batch 2600] loss: 0.08618582588154823
[Epoch 2, Batch 2700] loss: 0.10262925621238538
[Epoch 2, Batch 2800] loss: 0.09354561520158314
[Epoch 2, Batch 2900] loss: 0.10012738025281578
[Epoch 2, Batch 3000] loss: 0.09636218573665246
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0957
Validation Accuracy: 0.9707
Overfitting: 0.0957
Best model saved at epoch 2 with validation loss: 0.0957
[Epoch 3, Batch 100] loss: 0.0932723865355365
[Epoch 3, Batch 200] loss: 0.0960875721310731
[Epoch 3, Batch 300] loss: 0.08558926444500685
[Epoch 3, Batch 400] loss: 0.11024332856293767
[Epoch 3, Batch 500] loss: 0.08541902847238816
[Epoch 3, Batch 600] loss: 0.08447874096687884
[Epoch 3, Batch 700] loss: 0.09735741943120957
[Epoch 3, Batch 800] loss: 0.11021317662205547
[Epoch 3, Batch 900] loss: 0.08787773250369355
[Epoch 3, Batch 1000] loss: 0.06556624666322022
[Epoch 3, Batch 1100] loss: 0.08632633971050381
[Epoch 3, Batch 1200] loss: 0.11452854240313172
[Epoch 3, Batch 1300] loss: 0.0776844119594898
[Epoch 3, Batch 1400] loss: 0.08401017716038041
[Epoch 3, Batch 1500] loss: 0.10368125724606216
[Epoch 3, Batch 1600] loss: 0.0798215629835613
[Epoch 3, Batch 1700] loss: 0.07001874714391305
[Epoch 3, Batch 1800] loss: 0.09127089626621455
[Epoch 3, Batch 1900] loss: 0.09130670286365784
[Epoch 3, Batch 2000] loss: 0.09932707037776708
[Epoch 3, Batch 2100] loss: 0.08609805084997788
[Epoch 3, Batch 2200] loss: 0.08783210403460544
[Epoch 3, Batch 2300] loss: 0.0657320196996443
[Epoch 3, Batch 2400] loss: 0.0935493580705952
[Epoch 3, Batch 2500] loss: 0.08307722709665541
[Epoch 3, Batch 2600] loss: 0.05936640355852432
[Epoch 3, Batch 2700] loss: 0.07623386862222105
[Epoch 3, Batch 2800] loss: 0.0539660602400545
[Epoch 3, Batch 2900] loss: 0.09998513922677375
[Epoch 3, Batch 3000] loss: 0.07413732735672966
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9797
Overfitting: 0.0665
Best model saved at epoch 3 with validation loss: 0.0665
[Epoch 4, Batch 100] loss: 0.06560645011253655
[Epoch 4, Batch 200] loss: 0.0783301915647462
[Epoch 4, Batch 300] loss: 0.07483670936926501
[Epoch 4, Batch 400] loss: 0.07991780902724713
[Epoch 4, Batch 500] loss: 0.06358472946914845
[Epoch 4, Batch 600] loss: 0.056540794899920005
[Epoch 4, Batch 700] loss: 0.06727376233204269
[Epoch 4, Batch 800] loss: 0.06762076416634955
[Epoch 4, Batch 900] loss: 0.08405975387198851
[Epoch 4, Batch 1000] loss: 0.06772581802448258
[Epoch 4, Batch 1100] loss: 0.039731723009608685
[Epoch 4, Batch 1200] loss: 0.06739410788984969
[Epoch 4, Batch 1300] loss: 0.07623841471155174
[Epoch 4, Batch 1400] loss: 0.07601406903238966
[Epoch 4, Batch 1500] loss: 0.0758447695709765
[Epoch 4, Batch 1600] loss: 0.06080270133679733
[Epoch 4, Batch 1700] loss: 0.05849998197401874
[Epoch 4, Batch 1800] loss: 0.0772302546503488
[Epoch 4, Batch 1900] loss: 0.06475739651476033
[Epoch 4, Batch 2000] loss: 0.0647704255633289
[Epoch 4, Batch 2100] loss: 0.05598747274721973
[Epoch 4, Batch 2200] loss: 0.06834774963383097
[Epoch 4, Batch 2300] loss: 0.05726121405547019
[Epoch 4, Batch 2400] loss: 0.06011248216847889
[Epoch 4, Batch 2500] loss: 0.05389014933985891
[Epoch 4, Batch 2600] loss: 0.0676202723843744
[Epoch 4, Batch 2700] loss: 0.05448642531875521
[Epoch 4, Batch 2800] loss: 0.06673419659491628
[Epoch 4, Batch 2900] loss: 0.05313590226403903
[Epoch 4, Batch 3000] loss: 0.05717420552740805
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0688
Validation Accuracy: 0.9775
Overfitting: 0.0688
[Epoch 5, Batch 100] loss: 0.06095290049765026
[Epoch 5, Batch 200] loss: 0.046160303009673956
[Epoch 5, Batch 300] loss: 0.048575261143269016
[Epoch 5, Batch 400] loss: 0.05045555398421129
[Epoch 5, Batch 500] loss: 0.07465440115047386
[Epoch 5, Batch 600] loss: 0.07082424191292375
[Epoch 5, Batch 700] loss: 0.06430265256378334
[Epoch 5, Batch 800] loss: 0.0648362691127113
[Epoch 5, Batch 900] loss: 0.060157948849955574
[Epoch 5, Batch 1000] loss: 0.06102386576356366
[Epoch 5, Batch 1100] loss: 0.03900232292537112
[Epoch 5, Batch 1200] loss: 0.0394003932364285
[Epoch 5, Batch 1300] loss: 0.052987355195218695
[Epoch 5, Batch 1400] loss: 0.04801163017284125
[Epoch 5, Batch 1500] loss: 0.06292243154195604
[Epoch 5, Batch 1600] loss: 0.06616305766336154
[Epoch 5, Batch 1700] loss: 0.062182022779597904
[Epoch 5, Batch 1800] loss: 0.053639657044550405
[Epoch 5, Batch 1900] loss: 0.05407933885056991
[Epoch 5, Batch 2000] loss: 0.06300493671180447
[Epoch 5, Batch 2100] loss: 0.05878539826720953
[Epoch 5, Batch 2200] loss: 0.05796832052117679
[Epoch 5, Batch 2300] loss: 0.05138597949699033
[Epoch 5, Batch 2400] loss: 0.06790059051534626
[Epoch 5, Batch 2500] loss: 0.0534405975745176
[Epoch 5, Batch 2600] loss: 0.06299748930498027
[Epoch 5, Batch 2700] loss: 0.060915343201486394
[Epoch 5, Batch 2800] loss: 0.053694726340763735
[Epoch 5, Batch 2900] loss: 0.03942511892702896
[Epoch 5, Batch 3000] loss: 0.03295691839943174
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9828
Overfitting: 0.0573
Best model saved at epoch 5 with validation loss: 0.0573
[Epoch 6, Batch 100] loss: 0.04717743660105043
[Epoch 6, Batch 200] loss: 0.04309772955661174
[Epoch 6, Batch 300] loss: 0.049773833185317924
[Epoch 6, Batch 400] loss: 0.03736819039913826
[Epoch 6, Batch 500] loss: 0.04768237551819766
[Epoch 6, Batch 600] loss: 0.04715687684773002
[Epoch 6, Batch 700] loss: 0.041308237191406076
[Epoch 6, Batch 800] loss: 0.041553715330082924
[Epoch 6, Batch 900] loss: 0.056202720254368614
[Epoch 6, Batch 1000] loss: 0.05174699331866577
[Epoch 6, Batch 1100] loss: 0.06304390564910137
[Epoch 6, Batch 1200] loss: 0.0510971580966725
[Epoch 6, Batch 1300] loss: 0.04155969214683864
[Epoch 6, Batch 1400] loss: 0.046014776496740524
[Epoch 6, Batch 1500] loss: 0.03940787589206593
[Epoch 6, Batch 1600] loss: 0.03382676724693738
[Epoch 6, Batch 1700] loss: 0.05337641336707748
[Epoch 6, Batch 1800] loss: 0.035558228743902874
[Epoch 6, Batch 1900] loss: 0.04466070217749803
[Epoch 6, Batch 2000] loss: 0.04266752948344219
[Epoch 6, Batch 2100] loss: 0.0350962172835716
[Epoch 6, Batch 2200] loss: 0.06351368696472491
[Epoch 6, Batch 2300] loss: 0.05132591521192808
[Epoch 6, Batch 2400] loss: 0.04033099094827776
[Epoch 6, Batch 2500] loss: 0.04038083132938482
[Epoch 6, Batch 2600] loss: 0.04373645226994995
[Epoch 6, Batch 2700] loss: 0.06376264092948986
[Epoch 6, Batch 2800] loss: 0.05643275141890627
[Epoch 6, Batch 2900] loss: 0.05230717047059443
[Epoch 6, Batch 3000] loss: 0.04473506839829497
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0690
Validation Accuracy: 0.9785
Overfitting: 0.0690
[Epoch 7, Batch 100] loss: 0.042693787044263444
[Epoch 7, Batch 200] loss: 0.03725832190306391
[Epoch 7, Batch 300] loss: 0.0454200632168795
[Epoch 7, Batch 400] loss: 0.03409860190775362
[Epoch 7, Batch 500] loss: 0.04466028127848404
[Epoch 7, Batch 600] loss: 0.023113781940191983
[Epoch 7, Batch 700] loss: 0.04733102090685861
[Epoch 7, Batch 800] loss: 0.030568161742121448
[Epoch 7, Batch 900] loss: 0.03204692349798279
[Epoch 7, Batch 1000] loss: 0.0518859151104698
[Epoch 7, Batch 1100] loss: 0.05149368408485316
[Epoch 7, Batch 1200] loss: 0.0429207921307534
[Epoch 7, Batch 1300] loss: 0.047842522434075364
[Epoch 7, Batch 1400] loss: 0.03202344254881609
[Epoch 7, Batch 1500] loss: 0.033935071070154664
[Epoch 7, Batch 1600] loss: 0.035013742848241235
[Epoch 7, Batch 1700] loss: 0.04212832109391457
[Epoch 7, Batch 1800] loss: 0.046559110519883685
[Epoch 7, Batch 1900] loss: 0.03414645610959269
[Epoch 7, Batch 2000] loss: 0.04458258037368069
[Epoch 7, Batch 2100] loss: 0.034759193938953103
[Epoch 7, Batch 2200] loss: 0.02061966040360858
[Epoch 7, Batch 2300] loss: 0.04063675687822979
[Epoch 7, Batch 2400] loss: 0.04057296059268992
[Epoch 7, Batch 2500] loss: 0.04560975520551438
[Epoch 7, Batch 2600] loss: 0.05184562597220065
[Epoch 7, Batch 2700] loss: 0.03885527779319091
[Epoch 7, Batch 2800] loss: 0.05193021542654606
[Epoch 7, Batch 2900] loss: 0.045223501507425684
[Epoch 7, Batch 3000] loss: 0.03512312837847276
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0578
Validation Accuracy: 0.9818
Overfitting: 0.0578
[Epoch 8, Batch 100] loss: 0.03786115205963142
[Epoch 8, Batch 200] loss: 0.025748764010568265
[Epoch 8, Batch 300] loss: 0.040647644264390694
[Epoch 8, Batch 400] loss: 0.035178136166359765
[Epoch 8, Batch 500] loss: 0.033594777404068736
[Epoch 8, Batch 600] loss: 0.022975743911520113
[Epoch 8, Batch 700] loss: 0.04282432981432066
[Epoch 8, Batch 800] loss: 0.027935538046076545
[Epoch 8, Batch 900] loss: 0.031124177043966483
[Epoch 8, Batch 1000] loss: 0.03928775174892508
[Epoch 8, Batch 1100] loss: 0.035506828751240394
[Epoch 8, Batch 1200] loss: 0.03422271215793444
[Epoch 8, Batch 1300] loss: 0.028662602680415147
[Epoch 8, Batch 1400] loss: 0.05221549741014314
[Epoch 8, Batch 1500] loss: 0.04066123827687988
[Epoch 8, Batch 1600] loss: 0.03756706762113026
[Epoch 8, Batch 1700] loss: 0.038316835619625636
[Epoch 8, Batch 1800] loss: 0.028567199058888947
[Epoch 8, Batch 1900] loss: 0.044693511494115226
[Epoch 8, Batch 2000] loss: 0.036288716885464964
[Epoch 8, Batch 2100] loss: 0.03558914370689308
[Epoch 8, Batch 2200] loss: 0.02688561009868863
[Epoch 8, Batch 2300] loss: 0.026970001369700184
[Epoch 8, Batch 2400] loss: 0.04752580802734883
[Epoch 8, Batch 2500] loss: 0.0427874433650868
[Epoch 8, Batch 2600] loss: 0.025342592435044935
[Epoch 8, Batch 2700] loss: 0.03663890572905075
[Epoch 8, Batch 2800] loss: 0.027198756551515543
[Epoch 8, Batch 2900] loss: 0.02950052109983517
[Epoch 8, Batch 3000] loss: 0.0348409624103806
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0488
Validation Accuracy: 0.9856
Overfitting: 0.0488
Best model saved at epoch 8 with validation loss: 0.0488
[Epoch 9, Batch 100] loss: 0.033830743488215374
[Epoch 9, Batch 200] loss: 0.025344435892475304
[Epoch 9, Batch 300] loss: 0.034205311228288335
[Epoch 9, Batch 400] loss: 0.031968034498786435
[Epoch 9, Batch 500] loss: 0.013284748960722936
[Epoch 9, Batch 600] loss: 0.021254912651784252
[Epoch 9, Batch 700] loss: 0.031501881248841526
[Epoch 9, Batch 800] loss: 0.026726683556771606
[Epoch 9, Batch 900] loss: 0.04223036632029107
[Epoch 9, Batch 1000] loss: 0.03150171684363159
[Epoch 9, Batch 1100] loss: 0.018417458246876777
[Epoch 9, Batch 1200] loss: 0.03573914728622185
[Epoch 9, Batch 1300] loss: 0.030960974005574828
[Epoch 9, Batch 1400] loss: 0.031770083202281967
[Epoch 9, Batch 1500] loss: 0.022204814189244644
[Epoch 9, Batch 1600] loss: 0.03294793956185458
[Epoch 9, Batch 1700] loss: 0.03106263113222667
[Epoch 9, Batch 1800] loss: 0.036954566178028475
[Epoch 9, Batch 1900] loss: 0.03781316111737396
[Epoch 9, Batch 2000] loss: 0.03320895988297707
[Epoch 9, Batch 2100] loss: 0.019131494993926027
[Epoch 9, Batch 2200] loss: 0.034914764311870385
[Epoch 9, Batch 2300] loss: 0.040675278100388824
[Epoch 9, Batch 2400] loss: 0.022475987158395584
[Epoch 9, Batch 2500] loss: 0.028791271166992375
[Epoch 9, Batch 2600] loss: 0.029959276231165857
[Epoch 9, Batch 2700] loss: 0.038703489448016624
[Epoch 9, Batch 2800] loss: 0.022748647764747148
[Epoch 9, Batch 2900] loss: 0.02530233027297072
[Epoch 9, Batch 3000] loss: 0.03618039375272929
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0461
Validation Accuracy: 0.9857
Overfitting: 0.0461
Best model saved at epoch 9 with validation loss: 0.0461
[Epoch 10, Batch 100] loss: 0.021200889394967816
[Epoch 10, Batch 200] loss: 0.026810368083461072
[Epoch 10, Batch 300] loss: 0.02290496822035493
[Epoch 10, Batch 400] loss: 0.023485140805860283
[Epoch 10, Batch 500] loss: 0.01835609195928555
[Epoch 10, Batch 600] loss: 0.044758860620931956
[Epoch 10, Batch 700] loss: 0.023630854894945513
[Epoch 10, Batch 800] loss: 0.02943809172571491
[Epoch 10, Batch 900] loss: 0.019668728806063882
[Epoch 10, Batch 1000] loss: 0.02791832737319055
[Epoch 10, Batch 1100] loss: 0.0198770397658609
[Epoch 10, Batch 1200] loss: 0.028152142092221766
[Epoch 10, Batch 1300] loss: 0.013615334682835965
[Epoch 10, Batch 1400] loss: 0.028987340491294162
[Epoch 10, Batch 1500] loss: 0.039595426737760134
[Epoch 10, Batch 1600] loss: 0.02035595344568719
[Epoch 10, Batch 1700] loss: 0.01656215631242958
[Epoch 10, Batch 1800] loss: 0.0367164544771731
[Epoch 10, Batch 1900] loss: 0.03459564216333092
[Epoch 10, Batch 2000] loss: 0.031244617573174763
[Epoch 10, Batch 2100] loss: 0.026316450442100178
[Epoch 10, Batch 2200] loss: 0.02399629764338897
[Epoch 10, Batch 2300] loss: 0.03521842560323421
[Epoch 10, Batch 2400] loss: 0.023877523842529627
[Epoch 10, Batch 2500] loss: 0.03801877091027563
[Epoch 10, Batch 2600] loss: 0.03519533875391062
[Epoch 10, Batch 2700] loss: 0.022091700544042397
[Epoch 10, Batch 2800] loss: 0.027610560142275063
[Epoch 10, Batch 2900] loss: 0.023487619755760535
[Epoch 10, Batch 3000] loss: 0.025660809054388663
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9855
Overfitting: 0.0500
[Epoch 11, Batch 100] loss: 0.023091759054514115
[Epoch 11, Batch 200] loss: 0.02152990651433356
[Epoch 11, Batch 300] loss: 0.020311335345541012
[Epoch 11, Batch 400] loss: 0.021064909153501503
[Epoch 11, Batch 500] loss: 0.012445550643715251
[Epoch 11, Batch 600] loss: 0.02045131038183172
[Epoch 11, Batch 700] loss: 0.03223628646454017
[Epoch 11, Batch 800] loss: 0.025756652165728155
[Epoch 11, Batch 900] loss: 0.020764072225501876
[Epoch 11, Batch 1000] loss: 0.026480802231999404
[Epoch 11, Batch 1100] loss: 0.04262835960333177
[Epoch 11, Batch 1200] loss: 0.020397612325177762
[Epoch 11, Batch 1300] loss: 0.024615361267024127
[Epoch 11, Batch 1400] loss: 0.026707164356921567
[Epoch 11, Batch 1500] loss: 0.024437137293134584
[Epoch 11, Batch 1600] loss: 0.017291175255959388
[Epoch 11, Batch 1700] loss: 0.019344185732043117
[Epoch 11, Batch 1800] loss: 0.030052659298889922
[Epoch 11, Batch 1900] loss: 0.024350339917036765
[Epoch 11, Batch 2000] loss: 0.01949161905773508
[Epoch 11, Batch 2100] loss: 0.02201612283311988
[Epoch 11, Batch 2200] loss: 0.02972773282386697
[Epoch 11, Batch 2300] loss: 0.011656583082731231
[Epoch 11, Batch 2400] loss: 0.025149743599176873
[Epoch 11, Batch 2500] loss: 0.03134531797728414
[Epoch 11, Batch 2600] loss: 0.01708990164734132
[Epoch 11, Batch 2700] loss: 0.03090264152193413
[Epoch 11, Batch 2800] loss: 0.0349493066080322
[Epoch 11, Batch 2900] loss: 0.021203818416106513
[Epoch 11, Batch 3000] loss: 0.019942600628019135
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9835
Overfitting: 0.0518
[Epoch 12, Batch 100] loss: 0.020617009658071766
[Epoch 12, Batch 200] loss: 0.019113701129499533
[Epoch 12, Batch 300] loss: 0.01446786483278629
[Epoch 12, Batch 400] loss: 0.01659816825294911
[Epoch 12, Batch 500] loss: 0.016768372782134975
[Epoch 12, Batch 600] loss: 0.026935526768429554
[Epoch 12, Batch 700] loss: 0.021575212827010547
[Epoch 12, Batch 800] loss: 0.01722814766126248
[Epoch 12, Batch 900] loss: 0.018494543436663662
[Epoch 12, Batch 1000] loss: 0.022987272552054492
[Epoch 12, Batch 1100] loss: 0.01782299448987942
[Epoch 12, Batch 1200] loss: 0.019492671728803545
[Epoch 12, Batch 1300] loss: 0.013637812665510864
[Epoch 12, Batch 1400] loss: 0.026294216821188456
[Epoch 12, Batch 1500] loss: 0.023608541550820518
[Epoch 12, Batch 1600] loss: 0.026052240728240576
[Epoch 12, Batch 1700] loss: 0.02591980143723049
[Epoch 12, Batch 1800] loss: 0.028055355485266772
[Epoch 12, Batch 1900] loss: 0.0258173879764945
[Epoch 12, Batch 2000] loss: 0.023782957141738736
[Epoch 12, Batch 2100] loss: 0.021094607880950206
[Epoch 12, Batch 2200] loss: 0.02568108281986497
[Epoch 12, Batch 2300] loss: 0.02411840071559709
[Epoch 12, Batch 2400] loss: 0.017373932515547495
[Epoch 12, Batch 2500] loss: 0.021873885119439364
[Epoch 12, Batch 2600] loss: 0.020381199536350324
[Epoch 12, Batch 2700] loss: 0.01677013112577697
[Epoch 12, Batch 2800] loss: 0.016076013767269616
[Epoch 12, Batch 2900] loss: 0.014042031876051624
[Epoch 12, Batch 3000] loss: 0.012592227695131441
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9862
Overfitting: 0.0477
[Epoch 13, Batch 100] loss: 0.013711400499587398
[Epoch 13, Batch 200] loss: 0.008931785483291606
[Epoch 13, Batch 300] loss: 0.01211613490460877
[Epoch 13, Batch 400] loss: 0.020048521188891756
[Epoch 13, Batch 500] loss: 0.03163567848541789
[Epoch 13, Batch 600] loss: 0.019263043870942055
[Epoch 13, Batch 700] loss: 0.014296064787122304
[Epoch 13, Batch 800] loss: 0.026860609096097506
[Epoch 13, Batch 900] loss: 0.014793128288301887
[Epoch 13, Batch 1000] loss: 0.015101326735584735
[Epoch 13, Batch 1100] loss: 0.027294568890720256
[Epoch 13, Batch 1200] loss: 0.016652348605193764
[Epoch 13, Batch 1300] loss: 0.020656843863744143
[Epoch 13, Batch 1400] loss: 0.01681913389438705
[Epoch 13, Batch 1500] loss: 0.031443452099083516
[Epoch 13, Batch 1600] loss: 0.022192490539237043
[Epoch 13, Batch 1700] loss: 0.018789822038670537
[Epoch 13, Batch 1800] loss: 0.015994111075724505
[Epoch 13, Batch 1900] loss: 0.013017738899143295
[Epoch 13, Batch 2000] loss: 0.014954413967998334
[Epoch 13, Batch 2100] loss: 0.01323355146603717
[Epoch 13, Batch 2200] loss: 0.021371978528441103
[Epoch 13, Batch 2300] loss: 0.014588023987530506
[Epoch 13, Batch 2400] loss: 0.007305771411611203
[Epoch 13, Batch 2500] loss: 0.026313922184381226
[Epoch 13, Batch 2600] loss: 0.03531730862468976
[Epoch 13, Batch 2700] loss: 0.013227020999802335
[Epoch 13, Batch 2800] loss: 0.011233907392488618
[Epoch 13, Batch 2900] loss: 0.01655961264810685
[Epoch 13, Batch 3000] loss: 0.014284855834612245
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0563
Validation Accuracy: 0.9830
Overfitting: 0.0563
[Epoch 14, Batch 100] loss: 0.012955618021715054
[Epoch 14, Batch 200] loss: 0.019093399334287824
[Epoch 14, Batch 300] loss: 0.014186124986035793
[Epoch 14, Batch 400] loss: 0.01826795054541435
[Epoch 14, Batch 500] loss: 0.007508244933960668
[Epoch 14, Batch 600] loss: 0.010091028127535538
[Epoch 14, Batch 700] loss: 0.012166332963097375
[Epoch 14, Batch 800] loss: 0.01512775711278664
[Epoch 14, Batch 900] loss: 0.016149452801237203
[Epoch 14, Batch 1000] loss: 0.031425959844928
[Epoch 14, Batch 1100] loss: 0.008265727850666735
[Epoch 14, Batch 1200] loss: 0.024647885907179444
[Epoch 14, Batch 1300] loss: 0.019924945169550484
[Epoch 14, Batch 1400] loss: 0.013985006142102066
[Epoch 14, Batch 1500] loss: 0.017107138062347076
[Epoch 14, Batch 1600] loss: 0.012599688634109043
[Epoch 14, Batch 1700] loss: 0.01559875046936213
[Epoch 14, Batch 1800] loss: 0.012639920913552488
[Epoch 14, Batch 1900] loss: 0.015756591570147974
[Epoch 14, Batch 2000] loss: 0.020722186437051277
[Epoch 14, Batch 2100] loss: 0.020308113268965824
[Epoch 14, Batch 2200] loss: 0.012383328949413226
[Epoch 14, Batch 2300] loss: 0.026320381240193456
[Epoch 14, Batch 2400] loss: 0.016276178721655016
[Epoch 14, Batch 2500] loss: 0.012709089236750515
[Epoch 14, Batch 2600] loss: 0.014310463148021882
[Epoch 14, Batch 2700] loss: 0.019549655202072243
[Epoch 14, Batch 2800] loss: 0.012016653355294693
[Epoch 14, Batch 2900] loss: 0.015714649444853422
[Epoch 14, Batch 3000] loss: 0.016177860538775804
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9865
Overfitting: 0.0501
[Epoch 15, Batch 100] loss: 0.009898125827476179
[Epoch 15, Batch 200] loss: 0.015869046883726697
[Epoch 15, Batch 300] loss: 0.01436792193679139
[Epoch 15, Batch 400] loss: 0.01649244205411378
[Epoch 15, Batch 500] loss: 0.017888889492114687
[Epoch 15, Batch 600] loss: 0.017333271246789083
[Epoch 15, Batch 700] loss: 0.01757386765544652
[Epoch 15, Batch 800] loss: 0.014376556125534989
[Epoch 15, Batch 900] loss: 0.012181559185155493
[Epoch 15, Batch 1000] loss: 0.015500047115624511
[Epoch 15, Batch 1100] loss: 0.01369868788399799
[Epoch 15, Batch 1200] loss: 0.011273525363358204
[Epoch 15, Batch 1300] loss: 0.017582899844455824
[Epoch 15, Batch 1400] loss: 0.005664789672846382
[Epoch 15, Batch 1500] loss: 0.011548923397949693
[Epoch 15, Batch 1600] loss: 0.029974089791912774
[Epoch 15, Batch 1700] loss: 0.011267608088855923
[Epoch 15, Batch 1800] loss: 0.017117605706689572
[Epoch 15, Batch 1900] loss: 0.013691853188502136
[Epoch 15, Batch 2000] loss: 0.015000012498167053
[Epoch 15, Batch 2100] loss: 0.0161965603351382
[Epoch 15, Batch 2200] loss: 0.01068286361896753
[Epoch 15, Batch 2300] loss: 0.015235235840482347
[Epoch 15, Batch 2400] loss: 0.02169186520497533
[Epoch 15, Batch 2500] loss: 0.020758409932959694
[Epoch 15, Batch 2600] loss: 0.012512384977444526
[Epoch 15, Batch 2700] loss: 0.013708358349194896
[Epoch 15, Batch 2800] loss: 0.019984737108934496
[Epoch 15, Batch 2900] loss: 0.015445921489808825
[Epoch 15, Batch 3000] loss: 0.012441406522084435
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9869
Overfitting: 0.0453
Best model saved at epoch 15 with validation loss: 0.0453
[Epoch 16, Batch 100] loss: 0.016971226210825988
[Epoch 16, Batch 200] loss: 0.008679344574247808
[Epoch 16, Batch 300] loss: 0.00891184735573006
[Epoch 16, Batch 400] loss: 0.010728919386037887
[Epoch 16, Batch 500] loss: 0.019910966427760288
[Epoch 16, Batch 600] loss: 0.012809911012941483
[Epoch 16, Batch 700] loss: 0.010187870510908397
[Epoch 16, Batch 800] loss: 0.007908141498510303
[Epoch 16, Batch 900] loss: 0.011098338550018525
[Epoch 16, Batch 1000] loss: 0.007959935759708969
[Epoch 16, Batch 1100] loss: 0.014750362474683244
[Epoch 16, Batch 1200] loss: 0.009134424565290828
[Epoch 16, Batch 1300] loss: 0.015241369934896056
[Epoch 16, Batch 1400] loss: 0.010585200473326496
[Epoch 16, Batch 1500] loss: 0.012558023343590321
[Epoch 16, Batch 1600] loss: 0.02321215384795778
[Epoch 16, Batch 1700] loss: 0.008769302378204884
[Epoch 16, Batch 1800] loss: 0.014164813761444748
[Epoch 16, Batch 1900] loss: 0.01894605463234484
[Epoch 16, Batch 2000] loss: 0.021385956845729196
[Epoch 16, Batch 2100] loss: 0.011886511121383591
[Epoch 16, Batch 2200] loss: 0.016180513465205878
[Epoch 16, Batch 2300] loss: 0.013449847757437966
[Epoch 16, Batch 2400] loss: 0.006743470480951146
[Epoch 16, Batch 2500] loss: 0.00964458686117723
[Epoch 16, Batch 2600] loss: 0.011499574911146055
[Epoch 16, Batch 2700] loss: 0.016869840830895554
[Epoch 16, Batch 2800] loss: 0.016309871976072827
[Epoch 16, Batch 2900] loss: 0.015701196340751268
[Epoch 16, Batch 3000] loss: 0.020536907743098708
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9880
Overfitting: 0.0445
Best model saved at epoch 16 with validation loss: 0.0445
[Epoch 17, Batch 100] loss: 0.007146754343211797
[Epoch 17, Batch 200] loss: 0.017608581747881543
[Epoch 17, Batch 300] loss: 0.008171243022559338
[Epoch 17, Batch 400] loss: 0.0077749041837159895
[Epoch 17, Batch 500] loss: 0.011755887995441298
[Epoch 17, Batch 600] loss: 0.007518236006389998
[Epoch 17, Batch 700] loss: 0.007179364538787922
[Epoch 17, Batch 800] loss: 0.009113184550578808
[Epoch 17, Batch 900] loss: 0.011739657819159675
[Epoch 17, Batch 1000] loss: 0.008329144010540404
[Epoch 17, Batch 1100] loss: 0.015367321826329317
[Epoch 17, Batch 1200] loss: 0.006233557897921856
[Epoch 17, Batch 1300] loss: 0.01621945284225603
[Epoch 17, Batch 1400] loss: 0.010854773886367184
[Epoch 17, Batch 1500] loss: 0.020775220894702216
[Epoch 17, Batch 1600] loss: 0.007688819253644397
[Epoch 17, Batch 1700] loss: 0.009874003310346779
[Epoch 17, Batch 1800] loss: 0.012579887176725606
[Epoch 17, Batch 1900] loss: 0.012081517932547286
[Epoch 17, Batch 2000] loss: 0.013338791874483604
[Epoch 17, Batch 2100] loss: 0.008994523583232876
[Epoch 17, Batch 2200] loss: 0.014983679487922928
[Epoch 17, Batch 2300] loss: 0.007727028226772745
[Epoch 17, Batch 2400] loss: 0.014955124133616665
[Epoch 17, Batch 2500] loss: 0.00932270085761047
[Epoch 17, Batch 2600] loss: 0.02864692298157479
[Epoch 17, Batch 2700] loss: 0.00628951595149374
[Epoch 17, Batch 2800] loss: 0.016118415873615958
[Epoch 17, Batch 2900] loss: 0.014896077523244457
[Epoch 17, Batch 3000] loss: 0.014053634564493222
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0565
Validation Accuracy: 0.9849
Overfitting: 0.0565
[Epoch 18, Batch 100] loss: 0.01049189381134056
[Epoch 18, Batch 200] loss: 0.0051852942435561995
[Epoch 18, Batch 300] loss: 0.003826340989937762
[Epoch 18, Batch 400] loss: 0.0077873264264690075
[Epoch 18, Batch 500] loss: 0.012648403296961987
[Epoch 18, Batch 600] loss: 0.007217383420797887
[Epoch 18, Batch 700] loss: 0.008445090853019793
[Epoch 18, Batch 800] loss: 0.021614788795804998
[Epoch 18, Batch 900] loss: 0.011313816899792073
[Epoch 18, Batch 1000] loss: 0.005480157530803354
[Epoch 18, Batch 1100] loss: 0.007311474859784539
[Epoch 18, Batch 1200] loss: 0.006921873410747139
[Epoch 18, Batch 1300] loss: 0.015883416821343418
[Epoch 18, Batch 1400] loss: 0.00850241939640796
[Epoch 18, Batch 1500] loss: 0.006286379234716151
[Epoch 18, Batch 1600] loss: 0.011003873732242937
[Epoch 18, Batch 1700] loss: 0.0065397513074003655
[Epoch 18, Batch 1800] loss: 0.013811445357309821
[Epoch 18, Batch 1900] loss: 0.008828647941504642
[Epoch 18, Batch 2000] loss: 0.008009473826928116
[Epoch 18, Batch 2100] loss: 0.006627811213274981
[Epoch 18, Batch 2200] loss: 0.009652828864000184
[Epoch 18, Batch 2300] loss: 0.004262803753481421
[Epoch 18, Batch 2400] loss: 0.010700237636456222
[Epoch 18, Batch 2500] loss: 0.008238143954945371
[Epoch 18, Batch 2600] loss: 0.009654826251863823
[Epoch 18, Batch 2700] loss: 0.012635098435853252
[Epoch 18, Batch 2800] loss: 0.016325332445931054
[Epoch 18, Batch 2900] loss: 0.010218140049519207
[Epoch 18, Batch 3000] loss: 0.016382721069917353
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9860
Overfitting: 0.0500
[Epoch 19, Batch 100] loss: 0.015276494399413422
[Epoch 19, Batch 200] loss: 0.007842844230981427
[Epoch 19, Batch 300] loss: 0.006517002753980705
[Epoch 19, Batch 400] loss: 0.007367717109174237
[Epoch 19, Batch 500] loss: 0.008734787560379119
[Epoch 19, Batch 600] loss: 0.014991026710604274
[Epoch 19, Batch 700] loss: 0.008811965341869836
[Epoch 19, Batch 800] loss: 0.003770523028874777
[Epoch 19, Batch 900] loss: 0.0050620923468500225
[Epoch 19, Batch 1000] loss: 0.008108753964659172
[Epoch 19, Batch 1100] loss: 0.004546614329328804
[Epoch 19, Batch 1200] loss: 0.011296787706396572
[Epoch 19, Batch 1300] loss: 0.0067149616060441985
[Epoch 19, Batch 1400] loss: 0.004557863629270287
[Epoch 19, Batch 1500] loss: 0.006329415054601668
[Epoch 19, Batch 1600] loss: 0.013244257143931008
[Epoch 19, Batch 1700] loss: 0.009256613285870116
[Epoch 19, Batch 1800] loss: 0.009049184834964308
[Epoch 19, Batch 1900] loss: 0.020274457789523696
[Epoch 19, Batch 2000] loss: 0.013264658247653643
[Epoch 19, Batch 2100] loss: 0.008708510164528888
[Epoch 19, Batch 2200] loss: 0.009089495514247118
[Epoch 19, Batch 2300] loss: 0.011155817421663414
[Epoch 19, Batch 2400] loss: 0.007386583842198888
[Epoch 19, Batch 2500] loss: 0.005771286518111083
[Epoch 19, Batch 2600] loss: 0.01032959022101295
[Epoch 19, Batch 2700] loss: 0.00598671579378788
[Epoch 19, Batch 2800] loss: 0.01305160007955692
[Epoch 19, Batch 2900] loss: 0.01128679830184865
[Epoch 19, Batch 3000] loss: 0.004437234237477696
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9868
Overfitting: 0.0499
[Epoch 20, Batch 100] loss: 0.004520814396137211
[Epoch 20, Batch 200] loss: 0.0066654348729912275
[Epoch 20, Batch 300] loss: 0.006624337379219014
[Epoch 20, Batch 400] loss: 0.005212914908204311
[Epoch 20, Batch 500] loss: 0.0050140265768530414
[Epoch 20, Batch 600] loss: 0.006463277394002489
[Epoch 20, Batch 700] loss: 0.012648561152525417
[Epoch 20, Batch 800] loss: 0.0075619572955201875
[Epoch 20, Batch 900] loss: 0.0028422851807135886
[Epoch 20, Batch 1000] loss: 0.003512742230792014
[Epoch 20, Batch 1100] loss: 0.004129490488649026
[Epoch 20, Batch 1200] loss: 0.010872142213806911
[Epoch 20, Batch 1300] loss: 0.0036419418303012207
[Epoch 20, Batch 1400] loss: 0.004131763305579171
[Epoch 20, Batch 1500] loss: 0.006117650855978809
[Epoch 20, Batch 1600] loss: 0.0053481002052149056
[Epoch 20, Batch 1700] loss: 0.007383787184658104
[Epoch 20, Batch 1800] loss: 0.01626413660160779
[Epoch 20, Batch 1900] loss: 0.0206144575565213
[Epoch 20, Batch 2000] loss: 0.013546822510661513
[Epoch 20, Batch 2100] loss: 0.011956552739095514
[Epoch 20, Batch 2200] loss: 0.006963045843255031
[Epoch 20, Batch 2300] loss: 0.015431401673545224
[Epoch 20, Batch 2400] loss: 0.005379717260100278
[Epoch 20, Batch 2500] loss: 0.007531320685166066
[Epoch 20, Batch 2600] loss: 0.010432205577394597
[Epoch 20, Batch 2700] loss: 0.008628232316043523
[Epoch 20, Batch 2800] loss: 0.009587413047661357
[Epoch 20, Batch 2900] loss: 0.010223617269039096
[Epoch 20, Batch 3000] loss: 0.0071548775471310935
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9872
Overfitting: 0.0468
[Epoch 21, Batch 100] loss: 0.005659830636591323
[Epoch 21, Batch 200] loss: 0.004967837721583237
[Epoch 21, Batch 300] loss: 0.0025801150376037183
[Epoch 21, Batch 400] loss: 0.005809115738056789
[Epoch 21, Batch 500] loss: 0.006118296620870751
[Epoch 21, Batch 600] loss: 0.004938431627629143
[Epoch 21, Batch 700] loss: 0.006410292688051413
[Epoch 21, Batch 800] loss: 0.004127937683119853
[Epoch 21, Batch 900] loss: 0.004612499935446977
[Epoch 21, Batch 1000] loss: 0.0067391047324531425
[Epoch 21, Batch 1100] loss: 0.010911135546184596
[Epoch 21, Batch 1200] loss: 0.004358779283070362
[Epoch 21, Batch 1300] loss: 0.006477902710262242
[Epoch 21, Batch 1400] loss: 0.005028780361783447
[Epoch 21, Batch 1500] loss: 0.010425348464336822
[Epoch 21, Batch 1600] loss: 0.012236692349977147
[Epoch 21, Batch 1700] loss: 0.005786583058338692
[Epoch 21, Batch 1800] loss: 0.006562465475146837
[Epoch 21, Batch 1900] loss: 0.008757303422065661
[Epoch 21, Batch 2000] loss: 0.01590257236096022
[Epoch 21, Batch 2100] loss: 0.011555213470712715
[Epoch 21, Batch 2200] loss: 0.005949472569193403
[Epoch 21, Batch 2300] loss: 0.008894219349049876
[Epoch 21, Batch 2400] loss: 0.00997861850651816
[Epoch 21, Batch 2500] loss: 0.010436044197863339
[Epoch 21, Batch 2600] loss: 0.009059935484551716
[Epoch 21, Batch 2700] loss: 0.010028853844119112
[Epoch 21, Batch 2800] loss: 0.0049070565823876675
[Epoch 21, Batch 2900] loss: 0.011316432576977604
[Epoch 21, Batch 3000] loss: 0.006711050360524951
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9878
Overfitting: 0.0491
[Epoch 22, Batch 100] loss: 0.007123272850972171
[Epoch 22, Batch 200] loss: 0.00813913639094892
[Epoch 22, Batch 300] loss: 0.0073594035868086395
[Epoch 22, Batch 400] loss: 0.006582122072569518
[Epoch 22, Batch 500] loss: 0.003748012939103944
[Epoch 22, Batch 600] loss: 0.005318398611168504
[Epoch 22, Batch 700] loss: 0.007495538770508006
[Epoch 22, Batch 800] loss: 0.003032577212595129
[Epoch 22, Batch 900] loss: 0.0040079937966106625
[Epoch 22, Batch 1000] loss: 0.010242150887805793
[Epoch 22, Batch 1100] loss: 0.003178267189557573
[Epoch 22, Batch 1200] loss: 0.007979649393749923
[Epoch 22, Batch 1300] loss: 0.005503607958298744
[Epoch 22, Batch 1400] loss: 0.003511912017409031
[Epoch 22, Batch 1500] loss: 0.004891460294811622
[Epoch 22, Batch 1600] loss: 0.007222885719369287
[Epoch 22, Batch 1700] loss: 0.010168721809571934
[Epoch 22, Batch 1800] loss: 0.009376127528364578
[Epoch 22, Batch 1900] loss: 0.012499073810322442
[Epoch 22, Batch 2000] loss: 0.015520974706012112
[Epoch 22, Batch 2100] loss: 0.006955591571206696
[Epoch 22, Batch 2200] loss: 0.0027872834240906742
[Epoch 22, Batch 2300] loss: 0.006839641419660438
[Epoch 22, Batch 2400] loss: 0.008302365675998544
[Epoch 22, Batch 2500] loss: 0.0030005753754386434
[Epoch 22, Batch 2600] loss: 0.0049157827560645725
[Epoch 22, Batch 2700] loss: 0.004638963622103347
[Epoch 22, Batch 2800] loss: 0.0051432495218500665
[Epoch 22, Batch 2900] loss: 0.004547551678199397
[Epoch 22, Batch 3000] loss: 0.010175798844425116
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0555
Validation Accuracy: 0.9865
Overfitting: 0.0555
[Epoch 23, Batch 100] loss: 0.009268582051488465
[Epoch 23, Batch 200] loss: 0.003221949811894547
[Epoch 23, Batch 300] loss: 0.004987485997494332
[Epoch 23, Batch 400] loss: 0.00668198764072713
[Epoch 23, Batch 500] loss: 0.004835604510135454
[Epoch 23, Batch 600] loss: 0.0046338202672041
[Epoch 23, Batch 700] loss: 0.0036820812443522756
[Epoch 23, Batch 800] loss: 0.004867073358350353
[Epoch 23, Batch 900] loss: 0.008234527890526805
[Epoch 23, Batch 1000] loss: 0.0028332059137892427
[Epoch 23, Batch 1100] loss: 0.0032763874160423256
[Epoch 23, Batch 1200] loss: 0.00509576056117794
[Epoch 23, Batch 1300] loss: 0.0056132443064313975
[Epoch 23, Batch 1400] loss: 0.0074090541858959115
[Epoch 23, Batch 1500] loss: 0.004309419737263624
[Epoch 23, Batch 1600] loss: 0.004176201122083967
[Epoch 23, Batch 1700] loss: 0.004118493608178824
[Epoch 23, Batch 1800] loss: 0.0026973119821252565
[Epoch 23, Batch 1900] loss: 0.006788203164725246
[Epoch 23, Batch 2000] loss: 0.006812266221239156
[Epoch 23, Batch 2100] loss: 0.008745068329422434
[Epoch 23, Batch 2200] loss: 0.006296750942540257
[Epoch 23, Batch 2300] loss: 0.006781062659412669
[Epoch 23, Batch 2400] loss: 0.005249712181575887
[Epoch 23, Batch 2500] loss: 0.0072753516928742105
[Epoch 23, Batch 2600] loss: 0.005064614219692771
[Epoch 23, Batch 2700] loss: 0.0028550314803521813
[Epoch 23, Batch 2800] loss: 0.0036831250180091504
[Epoch 23, Batch 2900] loss: 0.006509584338592447
[Epoch 23, Batch 3000] loss: 0.007180777739786208
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9875
Overfitting: 0.0490
[Epoch 24, Batch 100] loss: 0.004732819153236889
[Epoch 24, Batch 200] loss: 0.007062847246615718
[Epoch 24, Batch 300] loss: 0.00391805628291877
[Epoch 24, Batch 400] loss: 0.0056838851208431155
[Epoch 24, Batch 500] loss: 0.005736887679315714
[Epoch 24, Batch 600] loss: 0.004352681194384331
[Epoch 24, Batch 700] loss: 0.006186475936310672
[Epoch 24, Batch 800] loss: 0.002951392531050203
[Epoch 24, Batch 900] loss: 0.0026100137556858273
[Epoch 24, Batch 1000] loss: 0.008475954568727956
[Epoch 24, Batch 1100] loss: 0.0020518910670330117
[Epoch 24, Batch 1200] loss: 0.0026270833883722845
[Epoch 24, Batch 1300] loss: 0.0009487163156248357
[Epoch 24, Batch 1400] loss: 0.002235479968967411
[Epoch 24, Batch 1500] loss: 0.0029442403442652676
[Epoch 24, Batch 1600] loss: 0.0024182039189906846
[Epoch 24, Batch 1700] loss: 0.00125353968874947
[Epoch 24, Batch 1800] loss: 0.0032599913787771584
[Epoch 24, Batch 1900] loss: 0.001986447636797948
[Epoch 24, Batch 2000] loss: 0.001656746778067486
[Epoch 24, Batch 2100] loss: 0.003466072898632717
[Epoch 24, Batch 2200] loss: 0.0031957554513843433
[Epoch 24, Batch 2300] loss: 0.005525237374428116
[Epoch 24, Batch 2400] loss: 0.00885271788969078
[Epoch 24, Batch 2500] loss: 0.005280225210813114
[Epoch 24, Batch 2600] loss: 0.0037276128711982892
[Epoch 24, Batch 2700] loss: 0.01252789634018427
[Epoch 24, Batch 2800] loss: 0.008126112944693772
[Epoch 24, Batch 2900] loss: 0.0050917085360856615
[Epoch 24, Batch 3000] loss: 0.003199365934083289
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0574
Validation Accuracy: 0.9858
Overfitting: 0.0574
Fold 4 validation loss: 0.0574
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.3013132858276366
[Epoch 1, Batch 200] loss: 2.2928406977653504
[Epoch 1, Batch 300] loss: 2.284957025051117
[Epoch 1, Batch 400] loss: 2.271627991199493
[Epoch 1, Batch 500] loss: 2.246473934650421
[Epoch 1, Batch 600] loss: 2.169286663532257
[Epoch 1, Batch 700] loss: 1.886587029695511
[Epoch 1, Batch 800] loss: 1.1415828508138657
[Epoch 1, Batch 900] loss: 0.6817091792821884
[Epoch 1, Batch 1000] loss: 0.5496531274914741
[Epoch 1, Batch 1100] loss: 0.4815120207518339
[Epoch 1, Batch 1200] loss: 0.4506025401502848
[Epoch 1, Batch 1300] loss: 0.43107338089495895
[Epoch 1, Batch 1400] loss: 0.3624010246247053
[Epoch 1, Batch 1500] loss: 0.33713282495737074
[Epoch 1, Batch 1600] loss: 0.33139546800404784
[Epoch 1, Batch 1700] loss: 0.3281766937300563
[Epoch 1, Batch 1800] loss: 0.3132566884532571
[Epoch 1, Batch 1900] loss: 0.2556447350233793
[Epoch 1, Batch 2000] loss: 0.261620603762567
[Epoch 1, Batch 2100] loss: 0.25867103818804027
[Epoch 1, Batch 2200] loss: 0.23393363615497947
[Epoch 1, Batch 2300] loss: 0.2610376372002065
[Epoch 1, Batch 2400] loss: 0.24182353688403965
[Epoch 1, Batch 2500] loss: 0.1817719276435673
[Epoch 1, Batch 2600] loss: 0.17366399489343165
[Epoch 1, Batch 2700] loss: 0.19915127078071237
[Epoch 1, Batch 2800] loss: 0.209186170687899
[Epoch 1, Batch 2900] loss: 0.20209212544374167
[Epoch 1, Batch 3000] loss: 0.184552107360214
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1785
Validation Accuracy: 0.9457
Overfitting: 0.1785
Best model saved at epoch 1 with validation loss: 0.1785
[Epoch 2, Batch 100] loss: 0.18042913406156003
[Epoch 2, Batch 200] loss: 0.17691191483289004
[Epoch 2, Batch 300] loss: 0.15406515130773188
[Epoch 2, Batch 400] loss: 0.16848464662209153
[Epoch 2, Batch 500] loss: 0.16094550972804428
[Epoch 2, Batch 600] loss: 0.14787338219583035
[Epoch 2, Batch 700] loss: 0.12956424562260507
[Epoch 2, Batch 800] loss: 0.13932051348499955
[Epoch 2, Batch 900] loss: 0.15833744250936432
[Epoch 2, Batch 1000] loss: 0.1414832701580599
[Epoch 2, Batch 1100] loss: 0.12663257033564151
[Epoch 2, Batch 1200] loss: 0.13789566195104272
[Epoch 2, Batch 1300] loss: 0.13000899096950888
[Epoch 2, Batch 1400] loss: 0.1114251236570999
[Epoch 2, Batch 1500] loss: 0.13111120431683956
[Epoch 2, Batch 1600] loss: 0.12951343270018698
[Epoch 2, Batch 1700] loss: 0.12404694525524974
[Epoch 2, Batch 1800] loss: 0.10965045660035684
[Epoch 2, Batch 1900] loss: 0.08929198146797716
[Epoch 2, Batch 2000] loss: 0.13203947627916932
[Epoch 2, Batch 2100] loss: 0.13121974227717145
[Epoch 2, Batch 2200] loss: 0.12380516719538719
[Epoch 2, Batch 2300] loss: 0.11762169237714261
[Epoch 2, Batch 2400] loss: 0.10644526856020092
[Epoch 2, Batch 2500] loss: 0.10865149848163128
[Epoch 2, Batch 2600] loss: 0.1119942440604791
[Epoch 2, Batch 2700] loss: 0.1104277548007667
[Epoch 2, Batch 2800] loss: 0.13269785298034548
[Epoch 2, Batch 2900] loss: 0.10914990806719288
[Epoch 2, Batch 3000] loss: 0.08683434109669179
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0931
Validation Accuracy: 0.9732
Overfitting: 0.0931
Best model saved at epoch 2 with validation loss: 0.0931
[Epoch 3, Batch 100] loss: 0.1130037855450064
[Epoch 3, Batch 200] loss: 0.10369515736587345
[Epoch 3, Batch 300] loss: 0.07789809043402783
[Epoch 3, Batch 400] loss: 0.07957968197064474
[Epoch 3, Batch 500] loss: 0.09217758183833212
[Epoch 3, Batch 600] loss: 0.09404977506375872
[Epoch 3, Batch 700] loss: 0.08565927995834499
[Epoch 3, Batch 800] loss: 0.09887319170753471
[Epoch 3, Batch 900] loss: 0.08708768399781547
[Epoch 3, Batch 1000] loss: 0.09128540633595549
[Epoch 3, Batch 1100] loss: 0.08658569650957361
[Epoch 3, Batch 1200] loss: 0.05742826472269371
[Epoch 3, Batch 1300] loss: 0.08220591613557189
[Epoch 3, Batch 1400] loss: 0.09625119404634461
[Epoch 3, Batch 1500] loss: 0.07212237337953412
[Epoch 3, Batch 1600] loss: 0.09237563173053787
[Epoch 3, Batch 1700] loss: 0.07633619761560112
[Epoch 3, Batch 1800] loss: 0.07082349504635203
[Epoch 3, Batch 1900] loss: 0.08384808889997658
[Epoch 3, Batch 2000] loss: 0.08793692989856935
[Epoch 3, Batch 2100] loss: 0.08258413827861659
[Epoch 3, Batch 2200] loss: 0.07541360015282407
[Epoch 3, Batch 2300] loss: 0.09893357906723395
[Epoch 3, Batch 2400] loss: 0.0868078576948028
[Epoch 3, Batch 2500] loss: 0.08802694784710184
[Epoch 3, Batch 2600] loss: 0.09870871381019242
[Epoch 3, Batch 2700] loss: 0.07553755268454551
[Epoch 3, Batch 2800] loss: 0.07353539554867894
[Epoch 3, Batch 2900] loss: 0.0824008471367415
[Epoch 3, Batch 3000] loss: 0.07646780811017378
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0766
Validation Accuracy: 0.9762
Overfitting: 0.0766
Best model saved at epoch 3 with validation loss: 0.0766
[Epoch 4, Batch 100] loss: 0.0573171644913964
[Epoch 4, Batch 200] loss: 0.07076153870264534
[Epoch 4, Batch 300] loss: 0.06483297902857885
[Epoch 4, Batch 400] loss: 0.07251779286365491
[Epoch 4, Batch 500] loss: 0.05610182299336884
[Epoch 4, Batch 600] loss: 0.05750882562075276
[Epoch 4, Batch 700] loss: 0.0655263752466999
[Epoch 4, Batch 800] loss: 0.06772166407550685
[Epoch 4, Batch 900] loss: 0.06851923825743142
[Epoch 4, Batch 1000] loss: 0.0670593387610279
[Epoch 4, Batch 1100] loss: 0.05962610800925176
[Epoch 4, Batch 1200] loss: 0.05349502629367635
[Epoch 4, Batch 1300] loss: 0.06560245210421271
[Epoch 4, Batch 1400] loss: 0.08547827963018789
[Epoch 4, Batch 1500] loss: 0.07371845492743886
[Epoch 4, Batch 1600] loss: 0.058915286990813914
[Epoch 4, Batch 1700] loss: 0.0687913086649496
[Epoch 4, Batch 1800] loss: 0.050740419874200596
[Epoch 4, Batch 1900] loss: 0.07381456081027864
[Epoch 4, Batch 2000] loss: 0.08044905046874191
[Epoch 4, Batch 2100] loss: 0.07343689442030155
[Epoch 4, Batch 2200] loss: 0.0700186789102736
[Epoch 4, Batch 2300] loss: 0.05613008424465079
[Epoch 4, Batch 2400] loss: 0.062340289881685745
[Epoch 4, Batch 2500] loss: 0.07159994462679606
[Epoch 4, Batch 2600] loss: 0.06500175248744199
[Epoch 4, Batch 2700] loss: 0.04821641798713244
[Epoch 4, Batch 2800] loss: 0.057935077967122196
[Epoch 4, Batch 2900] loss: 0.07582313141145278
[Epoch 4, Batch 3000] loss: 0.06364813803113066
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0654
Validation Accuracy: 0.9805
Overfitting: 0.0654
Best model saved at epoch 4 with validation loss: 0.0654
[Epoch 5, Batch 100] loss: 0.04142584968678421
[Epoch 5, Batch 200] loss: 0.06695684267033357
[Epoch 5, Batch 300] loss: 0.04197240238427184
[Epoch 5, Batch 400] loss: 0.03763510044955183
[Epoch 5, Batch 500] loss: 0.044594080103124725
[Epoch 5, Batch 600] loss: 0.04983993645757437
[Epoch 5, Batch 700] loss: 0.0757270090514794
[Epoch 5, Batch 800] loss: 0.04577990853693336
[Epoch 5, Batch 900] loss: 0.04984149789554067
[Epoch 5, Batch 1000] loss: 0.07722136097378098
[Epoch 5, Batch 1100] loss: 0.05350073156063445
[Epoch 5, Batch 1200] loss: 0.05455696512421127
[Epoch 5, Batch 1300] loss: 0.06638228376861662
[Epoch 5, Batch 1400] loss: 0.04347582666028757
[Epoch 5, Batch 1500] loss: 0.052693900604353985
[Epoch 5, Batch 1600] loss: 0.06413934656593483
[Epoch 5, Batch 1700] loss: 0.04895247362321243
[Epoch 5, Batch 1800] loss: 0.0489445308415452
[Epoch 5, Batch 1900] loss: 0.04835830401571002
[Epoch 5, Batch 2000] loss: 0.055019721548305825
[Epoch 5, Batch 2100] loss: 0.04593925828958163
[Epoch 5, Batch 2200] loss: 0.03614958852733253
[Epoch 5, Batch 2300] loss: 0.06914766621834133
[Epoch 5, Batch 2400] loss: 0.061468155260081404
[Epoch 5, Batch 2500] loss: 0.05982051848550327
[Epoch 5, Batch 2600] loss: 0.045184072050033136
[Epoch 5, Batch 2700] loss: 0.07044311501987977
[Epoch 5, Batch 2800] loss: 0.05958498926018365
[Epoch 5, Batch 2900] loss: 0.06913330862182193
[Epoch 5, Batch 3000] loss: 0.05480915879830718
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0584
Validation Accuracy: 0.9841
Overfitting: 0.0584
Best model saved at epoch 5 with validation loss: 0.0584
[Epoch 6, Batch 100] loss: 0.041606947085238065
[Epoch 6, Batch 200] loss: 0.03672149682766758
[Epoch 6, Batch 300] loss: 0.05199557373533025
[Epoch 6, Batch 400] loss: 0.04086975172904204
[Epoch 6, Batch 500] loss: 0.048042044713365616
[Epoch 6, Batch 600] loss: 0.0397950336462236
[Epoch 6, Batch 700] loss: 0.05348479001753731
[Epoch 6, Batch 800] loss: 0.04870882883813465
[Epoch 6, Batch 900] loss: 0.03956377012946177
[Epoch 6, Batch 1000] loss: 0.054218854474602264
[Epoch 6, Batch 1100] loss: 0.04022605067701079
[Epoch 6, Batch 1200] loss: 0.06507173091580626
[Epoch 6, Batch 1300] loss: 0.04399373769585509
[Epoch 6, Batch 1400] loss: 0.04779328091419302
[Epoch 6, Batch 1500] loss: 0.049586069499491715
[Epoch 6, Batch 1600] loss: 0.046726023818628164
[Epoch 6, Batch 1700] loss: 0.03175912655860884
[Epoch 6, Batch 1800] loss: 0.04446668423639494
[Epoch 6, Batch 1900] loss: 0.054215470825438386
[Epoch 6, Batch 2000] loss: 0.041007142548041886
[Epoch 6, Batch 2100] loss: 0.0622770792292431
[Epoch 6, Batch 2200] loss: 0.05033521074568853
[Epoch 6, Batch 2300] loss: 0.05016357503802283
[Epoch 6, Batch 2400] loss: 0.047678524462680796
[Epoch 6, Batch 2500] loss: 0.03129635671168216
[Epoch 6, Batch 2600] loss: 0.03424354302769643
[Epoch 6, Batch 2700] loss: 0.052278825652319935
[Epoch 6, Batch 2800] loss: 0.052918009263812564
[Epoch 6, Batch 2900] loss: 0.046025030571618115
[Epoch 6, Batch 3000] loss: 0.030780615175754065
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0631
Validation Accuracy: 0.9807
Overfitting: 0.0631
[Epoch 7, Batch 100] loss: 0.029570720262563556
[Epoch 7, Batch 200] loss: 0.03540325313791982
[Epoch 7, Batch 300] loss: 0.033727974072971845
[Epoch 7, Batch 400] loss: 0.046790360728628
[Epoch 7, Batch 500] loss: 0.030714314747601747
[Epoch 7, Batch 600] loss: 0.025195499877154363
[Epoch 7, Batch 700] loss: 0.04218858373023977
[Epoch 7, Batch 800] loss: 0.05469153052312322
[Epoch 7, Batch 900] loss: 0.04416359764203662
[Epoch 7, Batch 1000] loss: 0.03155870218732162
[Epoch 7, Batch 1100] loss: 0.02752933364943601
[Epoch 7, Batch 1200] loss: 0.03050175037016743
[Epoch 7, Batch 1300] loss: 0.03527078728409833
[Epoch 7, Batch 1400] loss: 0.04224008404518827
[Epoch 7, Batch 1500] loss: 0.04612377908255439
[Epoch 7, Batch 1600] loss: 0.037782542048516915
[Epoch 7, Batch 1700] loss: 0.06599680369137786
[Epoch 7, Batch 1800] loss: 0.0311897234134085
[Epoch 7, Batch 1900] loss: 0.03683196818630677
[Epoch 7, Batch 2000] loss: 0.04291780658022617
[Epoch 7, Batch 2100] loss: 0.05457773486472434
[Epoch 7, Batch 2200] loss: 0.03375879382627318
[Epoch 7, Batch 2300] loss: 0.04150814596461714
[Epoch 7, Batch 2400] loss: 0.04344348790727963
[Epoch 7, Batch 2500] loss: 0.025708645698032342
[Epoch 7, Batch 2600] loss: 0.04991447683045408
[Epoch 7, Batch 2700] loss: 0.036656601497961676
[Epoch 7, Batch 2800] loss: 0.04021830329089426
[Epoch 7, Batch 2900] loss: 0.057148513233696574
[Epoch 7, Batch 3000] loss: 0.034005024537909774
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9853
Overfitting: 0.0490
Best model saved at epoch 7 with validation loss: 0.0490
[Epoch 8, Batch 100] loss: 0.044378043462929784
[Epoch 8, Batch 200] loss: 0.03737812680948991
[Epoch 8, Batch 300] loss: 0.02966601410196745
[Epoch 8, Batch 400] loss: 0.03106508861135808
[Epoch 8, Batch 500] loss: 0.03332481647725217
[Epoch 8, Batch 600] loss: 0.032619505885522815
[Epoch 8, Batch 700] loss: 0.03757039112220809
[Epoch 8, Batch 800] loss: 0.03363103033916559
[Epoch 8, Batch 900] loss: 0.0341911799308582
[Epoch 8, Batch 1000] loss: 0.026293661982781488
[Epoch 8, Batch 1100] loss: 0.04281926556635881
[Epoch 8, Batch 1200] loss: 0.03147603335724852
[Epoch 8, Batch 1300] loss: 0.041757198655977844
[Epoch 8, Batch 1400] loss: 0.030009487981442363
[Epoch 8, Batch 1500] loss: 0.03739729758555768
[Epoch 8, Batch 1600] loss: 0.02781387534312671
[Epoch 8, Batch 1700] loss: 0.027556870804692154
[Epoch 8, Batch 1800] loss: 0.03384468189018662
[Epoch 8, Batch 1900] loss: 0.02985117539355997
[Epoch 8, Batch 2000] loss: 0.02353969487216091
[Epoch 8, Batch 2100] loss: 0.03626785264845239
[Epoch 8, Batch 2200] loss: 0.03869300226258929
[Epoch 8, Batch 2300] loss: 0.03897020574178896
[Epoch 8, Batch 2400] loss: 0.029610628151713173
[Epoch 8, Batch 2500] loss: 0.03380992632417474
[Epoch 8, Batch 2600] loss: 0.02970547904566047
[Epoch 8, Batch 2700] loss: 0.05438539623079123
[Epoch 8, Batch 2800] loss: 0.03526742286514491
[Epoch 8, Batch 2900] loss: 0.029793983139679767
[Epoch 8, Batch 3000] loss: 0.029787519134988543
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9858
Overfitting: 0.0475
Best model saved at epoch 8 with validation loss: 0.0475
[Epoch 9, Batch 100] loss: 0.0371378829117748
[Epoch 9, Batch 200] loss: 0.01749854987509025
[Epoch 9, Batch 300] loss: 0.030083766714669766
[Epoch 9, Batch 400] loss: 0.02640740400762297
[Epoch 9, Batch 500] loss: 0.023918411399645265
[Epoch 9, Batch 600] loss: 0.03420286173408385
[Epoch 9, Batch 700] loss: 0.03503986491785326
[Epoch 9, Batch 800] loss: 0.03613040739757707
[Epoch 9, Batch 900] loss: 0.031127438735420582
[Epoch 9, Batch 1000] loss: 0.023873065808766115
[Epoch 9, Batch 1100] loss: 0.039192616614018336
[Epoch 9, Batch 1200] loss: 0.02017039142156136
[Epoch 9, Batch 1300] loss: 0.0325991574456566
[Epoch 9, Batch 1400] loss: 0.03309305788709025
[Epoch 9, Batch 1500] loss: 0.023840343081901666
[Epoch 9, Batch 1600] loss: 0.028304337786248652
[Epoch 9, Batch 1700] loss: 0.03420683469405048
[Epoch 9, Batch 1800] loss: 0.03339479170710547
[Epoch 9, Batch 1900] loss: 0.02675615369953448
[Epoch 9, Batch 2000] loss: 0.0315533137616876
[Epoch 9, Batch 2100] loss: 0.02768900968207163
[Epoch 9, Batch 2200] loss: 0.025201314737205393
[Epoch 9, Batch 2300] loss: 0.030170153762956033
[Epoch 9, Batch 2400] loss: 0.0365240629442269
[Epoch 9, Batch 2500] loss: 0.026408588462436454
[Epoch 9, Batch 2600] loss: 0.03382800559149473
[Epoch 9, Batch 2700] loss: 0.04325731328466645
[Epoch 9, Batch 2800] loss: 0.036987158159026874
[Epoch 9, Batch 2900] loss: 0.02633324040860316
[Epoch 9, Batch 3000] loss: 0.03534073837508913
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9829
Overfitting: 0.0534
[Epoch 10, Batch 100] loss: 0.016397507433030114
[Epoch 10, Batch 200] loss: 0.0177124008021201
[Epoch 10, Batch 300] loss: 0.035584443179541264
[Epoch 10, Batch 400] loss: 0.027065746372827562
[Epoch 10, Batch 500] loss: 0.025581397186251707
[Epoch 10, Batch 600] loss: 0.02316864227388578
[Epoch 10, Batch 700] loss: 0.020874560317170106
[Epoch 10, Batch 800] loss: 0.0254795343013393
[Epoch 10, Batch 900] loss: 0.01618902675309073
[Epoch 10, Batch 1000] loss: 0.0340234439807682
[Epoch 10, Batch 1100] loss: 0.02025297447980847
[Epoch 10, Batch 1200] loss: 0.0277193529716169
[Epoch 10, Batch 1300] loss: 0.031424897380493345
[Epoch 10, Batch 1400] loss: 0.02493768791515322
[Epoch 10, Batch 1500] loss: 0.03364863880105986
[Epoch 10, Batch 1600] loss: 0.02539980703833862
[Epoch 10, Batch 1700] loss: 0.022877630476868943
[Epoch 10, Batch 1800] loss: 0.03583835743833333
[Epoch 10, Batch 1900] loss: 0.02745680379401165
[Epoch 10, Batch 2000] loss: 0.020593068939779188
[Epoch 10, Batch 2100] loss: 0.02797620684854337
[Epoch 10, Batch 2200] loss: 0.029993667932139943
[Epoch 10, Batch 2300] loss: 0.02125824317408842
[Epoch 10, Batch 2400] loss: 0.024571507178261526
[Epoch 10, Batch 2500] loss: 0.019775268199737184
[Epoch 10, Batch 2600] loss: 0.03713830461703765
[Epoch 10, Batch 2700] loss: 0.028453617466875584
[Epoch 10, Batch 2800] loss: 0.04320619929181703
[Epoch 10, Batch 2900] loss: 0.021463983701905817
[Epoch 10, Batch 3000] loss: 0.03154745916239335
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9875
Overfitting: 0.0437
Best model saved at epoch 10 with validation loss: 0.0437
[Epoch 11, Batch 100] loss: 0.028846793393895495
[Epoch 11, Batch 200] loss: 0.026096082097210455
[Epoch 11, Batch 300] loss: 0.02086530266722548
[Epoch 11, Batch 400] loss: 0.030986856876552338
[Epoch 11, Batch 500] loss: 0.024999552625668
[Epoch 11, Batch 600] loss: 0.012234706612580339
[Epoch 11, Batch 700] loss: 0.03206833441223353
[Epoch 11, Batch 800] loss: 0.020368070718177478
[Epoch 11, Batch 900] loss: 0.02607183045729471
[Epoch 11, Batch 1000] loss: 0.030832258378868573
[Epoch 11, Batch 1100] loss: 0.010744072695597424
[Epoch 11, Batch 1200] loss: 0.028190480731573188
[Epoch 11, Batch 1300] loss: 0.011456573415525782
[Epoch 11, Batch 1400] loss: 0.01630362179923395
[Epoch 11, Batch 1500] loss: 0.02529805193276843
[Epoch 11, Batch 1600] loss: 0.012100790818622045
[Epoch 11, Batch 1700] loss: 0.020347632059529133
[Epoch 11, Batch 1800] loss: 0.023499572762357274
[Epoch 11, Batch 1900] loss: 0.024279254076609504
[Epoch 11, Batch 2000] loss: 0.019692344667637373
[Epoch 11, Batch 2100] loss: 0.019122222716687245
[Epoch 11, Batch 2200] loss: 0.02602310296620999
[Epoch 11, Batch 2300] loss: 0.03081213746147114
[Epoch 11, Batch 2400] loss: 0.028592946980643318
[Epoch 11, Batch 2500] loss: 0.029341469955834327
[Epoch 11, Batch 2600] loss: 0.03139271453375841
[Epoch 11, Batch 2700] loss: 0.027042547980818198
[Epoch 11, Batch 2800] loss: 0.023311142392485634
[Epoch 11, Batch 2900] loss: 0.020180784027743356
[Epoch 11, Batch 3000] loss: 0.02405620482586528
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9882
Overfitting: 0.0436
Best model saved at epoch 11 with validation loss: 0.0436
[Epoch 12, Batch 100] loss: 0.012305041589206667
[Epoch 12, Batch 200] loss: 0.02320159855633392
[Epoch 12, Batch 300] loss: 0.01601442373052123
[Epoch 12, Batch 400] loss: 0.015553788855286257
[Epoch 12, Batch 500] loss: 0.01983441110689455
[Epoch 12, Batch 600] loss: 0.023839627473607836
[Epoch 12, Batch 700] loss: 0.02393610070879731
[Epoch 12, Batch 800] loss: 0.01734621099945798
[Epoch 12, Batch 900] loss: 0.02175272943080927
[Epoch 12, Batch 1000] loss: 0.014174205864110263
[Epoch 12, Batch 1100] loss: 0.02562213528435677
[Epoch 12, Batch 1200] loss: 0.02487603192741517
[Epoch 12, Batch 1300] loss: 0.01430036188376107
[Epoch 12, Batch 1400] loss: 0.023472080898172862
[Epoch 12, Batch 1500] loss: 0.026454038795673113
[Epoch 12, Batch 1600] loss: 0.014003176471596816
[Epoch 12, Batch 1700] loss: 0.02843789974154788
[Epoch 12, Batch 1800] loss: 0.01882831405098841
[Epoch 12, Batch 1900] loss: 0.020897747905692085
[Epoch 12, Batch 2000] loss: 0.016797985563498513
[Epoch 12, Batch 2100] loss: 0.021541267982865975
[Epoch 12, Batch 2200] loss: 0.0182123455760302
[Epoch 12, Batch 2300] loss: 0.02390528858632024
[Epoch 12, Batch 2400] loss: 0.036308933908803735
[Epoch 12, Batch 2500] loss: 0.017603717471538403
[Epoch 12, Batch 2600] loss: 0.030684109634457855
[Epoch 12, Batch 2700] loss: 0.03106187900295481
[Epoch 12, Batch 2800] loss: 0.015378743794499314
[Epoch 12, Batch 2900] loss: 0.01643434677982441
[Epoch 12, Batch 3000] loss: 0.017230773845731163
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0421
Validation Accuracy: 0.9881
Overfitting: 0.0421
Best model saved at epoch 12 with validation loss: 0.0421
[Epoch 13, Batch 100] loss: 0.017606453094213066
[Epoch 13, Batch 200] loss: 0.009231496642460115
[Epoch 13, Batch 300] loss: 0.014120564256500075
[Epoch 13, Batch 400] loss: 0.013729243760844839
[Epoch 13, Batch 500] loss: 0.009350233481600299
[Epoch 13, Batch 600] loss: 0.013433667544286437
[Epoch 13, Batch 700] loss: 0.02201768943990828
[Epoch 13, Batch 800] loss: 0.015138396538495726
[Epoch 13, Batch 900] loss: 0.012423805532744154
[Epoch 13, Batch 1000] loss: 0.019453771921862425
[Epoch 13, Batch 1100] loss: 0.017255228667181655
[Epoch 13, Batch 1200] loss: 0.015739847782679135
[Epoch 13, Batch 1300] loss: 0.007594061912641337
[Epoch 13, Batch 1400] loss: 0.021524882052544853
[Epoch 13, Batch 1500] loss: 0.015507943218399305
[Epoch 13, Batch 1600] loss: 0.016755566348219873
[Epoch 13, Batch 1700] loss: 0.022308748896466567
[Epoch 13, Batch 1800] loss: 0.01562853244759026
[Epoch 13, Batch 1900] loss: 0.017093847352334705
[Epoch 13, Batch 2000] loss: 0.021663397168213125
[Epoch 13, Batch 2100] loss: 0.012764557778373273
[Epoch 13, Batch 2200] loss: 0.017782212279471424
[Epoch 13, Batch 2300] loss: 0.032163897829777854
[Epoch 13, Batch 2400] loss: 0.027918557826487812
[Epoch 13, Batch 2500] loss: 0.012742595817835536
[Epoch 13, Batch 2600] loss: 0.02779127677473298
[Epoch 13, Batch 2700] loss: 0.027612754476031114
[Epoch 13, Batch 2800] loss: 0.015020701487337647
[Epoch 13, Batch 2900] loss: 0.020849659176401473
[Epoch 13, Batch 3000] loss: 0.019515796604373463
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0405
Validation Accuracy: 0.9890
Overfitting: 0.0405
Best model saved at epoch 13 with validation loss: 0.0405
[Epoch 14, Batch 100] loss: 0.01842972363047011
[Epoch 14, Batch 200] loss: 0.021546349075433683
[Epoch 14, Batch 300] loss: 0.010757923462806502
[Epoch 14, Batch 400] loss: 0.011803073922292242
[Epoch 14, Batch 500] loss: 0.02562878240354621
[Epoch 14, Batch 600] loss: 0.022296246470014013
[Epoch 14, Batch 700] loss: 0.012049776420644776
[Epoch 14, Batch 800] loss: 0.01610575556398544
[Epoch 14, Batch 900] loss: 0.009623231436708011
[Epoch 14, Batch 1000] loss: 0.014202429402557755
[Epoch 14, Batch 1100] loss: 0.016099178948607004
[Epoch 14, Batch 1200] loss: 0.0192774423029914
[Epoch 14, Batch 1300] loss: 0.01133673100550368
[Epoch 14, Batch 1400] loss: 0.014947606989862834
[Epoch 14, Batch 1500] loss: 0.013312806176836603
[Epoch 14, Batch 1600] loss: 0.017237820298541918
[Epoch 14, Batch 1700] loss: 0.010489145191495481
[Epoch 14, Batch 1800] loss: 0.018151301968973712
[Epoch 14, Batch 1900] loss: 0.018946920417984073
[Epoch 14, Batch 2000] loss: 0.010707149670361104
[Epoch 14, Batch 2100] loss: 0.007500616017387074
[Epoch 14, Batch 2200] loss: 0.015254577502346364
[Epoch 14, Batch 2300] loss: 0.01059154564288292
[Epoch 14, Batch 2400] loss: 0.008720501703319315
[Epoch 14, Batch 2500] loss: 0.02040720442089878
[Epoch 14, Batch 2600] loss: 0.027114259954523733
[Epoch 14, Batch 2700] loss: 0.016944524650709808
[Epoch 14, Batch 2800] loss: 0.012048879300891713
[Epoch 14, Batch 2900] loss: 0.021075263406273734
[Epoch 14, Batch 3000] loss: 0.019236513031723915
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0414
Validation Accuracy: 0.9887
Overfitting: 0.0414
[Epoch 15, Batch 100] loss: 0.008698405662653386
[Epoch 15, Batch 200] loss: 0.009966094945957594
[Epoch 15, Batch 300] loss: 0.016810929136645426
[Epoch 15, Batch 400] loss: 0.009863912981886642
[Epoch 15, Batch 500] loss: 0.016440802048882687
[Epoch 15, Batch 600] loss: 0.0081771597945135
[Epoch 15, Batch 700] loss: 0.007254427079496964
[Epoch 15, Batch 800] loss: 0.012655751842612518
[Epoch 15, Batch 900] loss: 0.01862403014192296
[Epoch 15, Batch 1000] loss: 0.015520946255473973
[Epoch 15, Batch 1100] loss: 0.021650201849442965
[Epoch 15, Batch 1200] loss: 0.01375461117222585
[Epoch 15, Batch 1300] loss: 0.02901485308460906
[Epoch 15, Batch 1400] loss: 0.011971076165264095
[Epoch 15, Batch 1500] loss: 0.009021741692322394
[Epoch 15, Batch 1600] loss: 0.012713366534480883
[Epoch 15, Batch 1700] loss: 0.014741382325901213
[Epoch 15, Batch 1800] loss: 0.009806804012514476
[Epoch 15, Batch 1900] loss: 0.024657223361791693
[Epoch 15, Batch 2000] loss: 0.0178493273726599
[Epoch 15, Batch 2100] loss: 0.01715213299219613
[Epoch 15, Batch 2200] loss: 0.01757876076400862
[Epoch 15, Batch 2300] loss: 0.015617031551646504
[Epoch 15, Batch 2400] loss: 0.020469755104240903
[Epoch 15, Batch 2500] loss: 0.012707071698278014
[Epoch 15, Batch 2600] loss: 0.00692607111102916
[Epoch 15, Batch 2700] loss: 0.023198979381995742
[Epoch 15, Batch 2800] loss: 0.007435224512482819
[Epoch 15, Batch 2900] loss: 0.010977996882902517
[Epoch 15, Batch 3000] loss: 0.01651234170278258
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0423
Validation Accuracy: 0.9885
Overfitting: 0.0423
[Epoch 16, Batch 100] loss: 0.012655886774164174
[Epoch 16, Batch 200] loss: 0.008802926246589777
[Epoch 16, Batch 300] loss: 0.006108897706408243
[Epoch 16, Batch 400] loss: 0.011146842184361959
[Epoch 16, Batch 500] loss: 0.009887377474433379
[Epoch 16, Batch 600] loss: 0.009588921125650813
[Epoch 16, Batch 700] loss: 0.03270519027788396
[Epoch 16, Batch 800] loss: 0.012279747902721284
[Epoch 16, Batch 900] loss: 0.02220700010235305
[Epoch 16, Batch 1000] loss: 0.009459883944382455
[Epoch 16, Batch 1100] loss: 0.014456012754708354
[Epoch 16, Batch 1200] loss: 0.016772333013359456
[Epoch 16, Batch 1300] loss: 0.0127177199734615
[Epoch 16, Batch 1400] loss: 0.01352780919455654
[Epoch 16, Batch 1500] loss: 0.004134002343944303
[Epoch 16, Batch 1600] loss: 0.01320560059671152
[Epoch 16, Batch 1700] loss: 0.00826876224597072
[Epoch 16, Batch 1800] loss: 0.015301439579216094
[Epoch 16, Batch 1900] loss: 0.01465293755316452
[Epoch 16, Batch 2000] loss: 0.013626827106745622
[Epoch 16, Batch 2100] loss: 0.009163634676606308
[Epoch 16, Batch 2200] loss: 0.009043997770877468
[Epoch 16, Batch 2300] loss: 0.00917441289373528
[Epoch 16, Batch 2400] loss: 0.01458115190582248
[Epoch 16, Batch 2500] loss: 0.013107122025103309
[Epoch 16, Batch 2600] loss: 0.017083647464442037
[Epoch 16, Batch 2700] loss: 0.010378848451855447
[Epoch 16, Batch 2800] loss: 0.006495179216726683
[Epoch 16, Batch 2900] loss: 0.019194115926652558
[Epoch 16, Batch 3000] loss: 0.01837223136884859
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9887
Overfitting: 0.0456
[Epoch 17, Batch 100] loss: 0.009236396104170127
[Epoch 17, Batch 200] loss: 0.011372920551839343
[Epoch 17, Batch 300] loss: 0.007561597670355695
[Epoch 17, Batch 400] loss: 0.013778317587530182
[Epoch 17, Batch 500] loss: 0.009948943093631897
[Epoch 17, Batch 600] loss: 0.006425606750090082
[Epoch 17, Batch 700] loss: 0.007702092196441299
[Epoch 17, Batch 800] loss: 0.007016047853248893
[Epoch 17, Batch 900] loss: 0.0073365558770944975
[Epoch 17, Batch 1000] loss: 0.010572136443406634
[Epoch 17, Batch 1100] loss: 0.009156585720957082
[Epoch 17, Batch 1200] loss: 0.007076873563664776
[Epoch 17, Batch 1300] loss: 0.004567216150344393
[Epoch 17, Batch 1400] loss: 0.006119694006665668
[Epoch 17, Batch 1500] loss: 0.021018068953353577
[Epoch 17, Batch 1600] loss: 0.013822521485108154
[Epoch 17, Batch 1700] loss: 0.0100609143077736
[Epoch 17, Batch 1800] loss: 0.01599545997491532
[Epoch 17, Batch 1900] loss: 0.01327764463329686
[Epoch 17, Batch 2000] loss: 0.01290429053206026
[Epoch 17, Batch 2100] loss: 0.013795833350086469
[Epoch 17, Batch 2200] loss: 0.013327617534196179
[Epoch 17, Batch 2300] loss: 0.0072492602244801675
[Epoch 17, Batch 2400] loss: 0.01683188782479192
[Epoch 17, Batch 2500] loss: 0.006902791929569503
[Epoch 17, Batch 2600] loss: 0.009514946621475246
[Epoch 17, Batch 2700] loss: 0.00883387910754209
[Epoch 17, Batch 2800] loss: 0.014050160061183306
[Epoch 17, Batch 2900] loss: 0.008399267177537695
[Epoch 17, Batch 3000] loss: 0.01074059686079636
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0420
Validation Accuracy: 0.9888
Overfitting: 0.0420
[Epoch 18, Batch 100] loss: 0.006405930002620153
[Epoch 18, Batch 200] loss: 0.004932702397345565
[Epoch 18, Batch 300] loss: 0.008141541816471545
[Epoch 18, Batch 400] loss: 0.004631171081123284
[Epoch 18, Batch 500] loss: 0.010307577387388847
[Epoch 18, Batch 600] loss: 0.005485229166320096
[Epoch 18, Batch 700] loss: 0.007623347373946671
[Epoch 18, Batch 800] loss: 0.008051862758993594
[Epoch 18, Batch 900] loss: 0.014494682646841284
[Epoch 18, Batch 1000] loss: 0.01315159403279722
[Epoch 18, Batch 1100] loss: 0.011170423761293478
[Epoch 18, Batch 1200] loss: 0.009070678369785128
[Epoch 18, Batch 1300] loss: 0.011594653681850104
[Epoch 18, Batch 1400] loss: 0.006639519731343171
[Epoch 18, Batch 1500] loss: 0.015215997449413408
[Epoch 18, Batch 1600] loss: 0.008670081864693202
[Epoch 18, Batch 1700] loss: 0.010130455843782329
[Epoch 18, Batch 1800] loss: 0.005099785315399004
[Epoch 18, Batch 1900] loss: 0.009997590587354353
[Epoch 18, Batch 2000] loss: 0.0049722292713272505
[Epoch 18, Batch 2100] loss: 0.008258908395432626
[Epoch 18, Batch 2200] loss: 0.009015548058196146
[Epoch 18, Batch 2300] loss: 0.012624969957146277
[Epoch 18, Batch 2400] loss: 0.010661363323551996
[Epoch 18, Batch 2500] loss: 0.02189405249999254
[Epoch 18, Batch 2600] loss: 0.009947439624229447
[Epoch 18, Batch 2700] loss: 0.0045503703731901626
[Epoch 18, Batch 2800] loss: 0.01431562157238659
[Epoch 18, Batch 2900] loss: 0.012836810568078363
[Epoch 18, Batch 3000] loss: 0.006069133197979681
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0427
Validation Accuracy: 0.9891
Overfitting: 0.0427
[Epoch 19, Batch 100] loss: 0.0036659346317992458
[Epoch 19, Batch 200] loss: 0.007952288135970775
[Epoch 19, Batch 300] loss: 0.006531904784164908
[Epoch 19, Batch 400] loss: 0.011590944343279262
[Epoch 19, Batch 500] loss: 0.00631676522953967
[Epoch 19, Batch 600] loss: 0.021019261716128314
[Epoch 19, Batch 700] loss: 0.009248664448641648
[Epoch 19, Batch 800] loss: 0.006430570645288753
[Epoch 19, Batch 900] loss: 0.002984707923624228
[Epoch 19, Batch 1000] loss: 0.009613412692297062
[Epoch 19, Batch 1100] loss: 0.0070615676637953585
[Epoch 19, Batch 1200] loss: 0.007965032310748939
[Epoch 19, Batch 1300] loss: 0.013485634301537175
[Epoch 19, Batch 1400] loss: 0.01211892203019488
[Epoch 19, Batch 1500] loss: 0.006848462291254691
[Epoch 19, Batch 1600] loss: 0.011074680031324533
[Epoch 19, Batch 1700] loss: 0.007911043410258571
[Epoch 19, Batch 1800] loss: 0.006145892651838949
[Epoch 19, Batch 1900] loss: 0.005487900116659148
[Epoch 19, Batch 2000] loss: 0.010597941830787931
[Epoch 19, Batch 2100] loss: 0.004243814073220165
[Epoch 19, Batch 2200] loss: 0.01380965694983388
[Epoch 19, Batch 2300] loss: 0.005403960875796656
[Epoch 19, Batch 2400] loss: 0.006232171142669358
[Epoch 19, Batch 2500] loss: 0.006846555025995258
[Epoch 19, Batch 2600] loss: 0.008486741646196378
[Epoch 19, Batch 2700] loss: 0.006490316321473983
[Epoch 19, Batch 2800] loss: 0.0058307888718718455
[Epoch 19, Batch 2900] loss: 0.009082418224697903
[Epoch 19, Batch 3000] loss: 0.006774867687249752
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0413
Validation Accuracy: 0.9898
Overfitting: 0.0413
[Epoch 20, Batch 100] loss: 0.003867495795143441
[Epoch 20, Batch 200] loss: 0.004547573382460542
[Epoch 20, Batch 300] loss: 0.0074548438823376275
[Epoch 20, Batch 400] loss: 0.008361162042347133
[Epoch 20, Batch 500] loss: 0.0067196160680714455
[Epoch 20, Batch 600] loss: 0.005828211619054855
[Epoch 20, Batch 700] loss: 0.00893924038683508
[Epoch 20, Batch 800] loss: 0.004667933235179476
[Epoch 20, Batch 900] loss: 0.0034075885718448263
[Epoch 20, Batch 1000] loss: 0.002616040266203754
[Epoch 20, Batch 1100] loss: 0.0031912465202185557
[Epoch 20, Batch 1200] loss: 0.007484636234969457
[Epoch 20, Batch 1300] loss: 0.0035386839146667624
[Epoch 20, Batch 1400] loss: 0.0036494028922197685
[Epoch 20, Batch 1500] loss: 0.004268080277360014
[Epoch 20, Batch 1600] loss: 0.0030413411216864005
[Epoch 20, Batch 1700] loss: 0.006981727275579033
[Epoch 20, Batch 1800] loss: 0.006480687551955953
[Epoch 20, Batch 1900] loss: 0.006783545717415791
[Epoch 20, Batch 2000] loss: 0.006708770134622455
[Epoch 20, Batch 2100] loss: 0.006880883122544219
[Epoch 20, Batch 2200] loss: 0.007862307976015472
[Epoch 20, Batch 2300] loss: 0.009303582415982418
[Epoch 20, Batch 2400] loss: 0.020047630564258723
[Epoch 20, Batch 2500] loss: 0.006709733404354665
[Epoch 20, Batch 2600] loss: 0.0050539743666195135
[Epoch 20, Batch 2700] loss: 0.005452219549313213
[Epoch 20, Batch 2800] loss: 0.013801079713484796
[Epoch 20, Batch 2900] loss: 0.008551185790769012
[Epoch 20, Batch 3000] loss: 0.00554815866708168
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0429
Validation Accuracy: 0.9897
Overfitting: 0.0429
[Epoch 21, Batch 100] loss: 0.0031988976383536282
[Epoch 21, Batch 200] loss: 0.0037054948750210315
[Epoch 21, Batch 300] loss: 0.00631924991172582
[Epoch 21, Batch 400] loss: 0.002809337024218621
[Epoch 21, Batch 500] loss: 0.004489251724567112
[Epoch 21, Batch 600] loss: 0.007418282016587909
[Epoch 21, Batch 700] loss: 0.003761631567139148
[Epoch 21, Batch 800] loss: 0.003889314213175226
[Epoch 21, Batch 900] loss: 0.005609711320863653
[Epoch 21, Batch 1000] loss: 0.0042681384216325564
[Epoch 21, Batch 1100] loss: 0.002320657932746144
[Epoch 21, Batch 1200] loss: 0.00789345294933355
[Epoch 21, Batch 1300] loss: 0.009261580799061449
[Epoch 21, Batch 1400] loss: 0.007684769372878009
[Epoch 21, Batch 1500] loss: 0.009727590369268456
[Epoch 21, Batch 1600] loss: 0.006101758404327029
[Epoch 21, Batch 1700] loss: 0.006149078847553824
[Epoch 21, Batch 1800] loss: 0.01149547269901177
[Epoch 21, Batch 1900] loss: 0.00703304586269951
[Epoch 21, Batch 2000] loss: 0.016751767514197127
[Epoch 21, Batch 2100] loss: 0.00847093850979718
[Epoch 21, Batch 2200] loss: 0.006048859294135127
[Epoch 21, Batch 2300] loss: 0.005077798144220651
[Epoch 21, Batch 2400] loss: 0.0047072996869701456
[Epoch 21, Batch 2500] loss: 0.013483255051320385
[Epoch 21, Batch 2600] loss: 0.01388651542779371
[Epoch 21, Batch 2700] loss: 0.0069823499571873525
[Epoch 21, Batch 2800] loss: 0.007574900228527213
[Epoch 21, Batch 2900] loss: 0.004227876906782058
[Epoch 21, Batch 3000] loss: 0.00352972975342027
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0426
Validation Accuracy: 0.9898
Overfitting: 0.0426
[Epoch 22, Batch 100] loss: 0.005305815187717826
[Epoch 22, Batch 200] loss: 0.00893575419636818
[Epoch 22, Batch 300] loss: 0.008396525852805325
[Epoch 22, Batch 400] loss: 0.007695406066591204
[Epoch 22, Batch 500] loss: 0.004590445585358793
[Epoch 22, Batch 600] loss: 0.002864341991087258
[Epoch 22, Batch 700] loss: 0.003319496377705491
[Epoch 22, Batch 800] loss: 0.0034670715455808934
[Epoch 22, Batch 900] loss: 0.01132324337187356
[Epoch 22, Batch 1000] loss: 0.0026552998225554346
[Epoch 22, Batch 1100] loss: 0.004921580782538512
[Epoch 22, Batch 1200] loss: 0.005079080593654908
[Epoch 22, Batch 1300] loss: 0.0071053461403369055
[Epoch 22, Batch 1400] loss: 0.0021252839510628972
[Epoch 22, Batch 1500] loss: 0.0063348826753843925
[Epoch 22, Batch 1600] loss: 0.002980223018683432
[Epoch 22, Batch 1700] loss: 0.006635906348039952
[Epoch 22, Batch 1800] loss: 0.009055763753003702
[Epoch 22, Batch 1900] loss: 0.0046743832211313925
[Epoch 22, Batch 2000] loss: 0.01639791231170875
[Epoch 22, Batch 2100] loss: 0.0071533853439041195
[Epoch 22, Batch 2200] loss: 0.006052600541336233
[Epoch 22, Batch 2300] loss: 0.007491027184219092
[Epoch 22, Batch 2400] loss: 0.0029958960911505984
[Epoch 22, Batch 2500] loss: 0.005553444454728833
[Epoch 22, Batch 2600] loss: 0.005032005294700354
[Epoch 22, Batch 2700] loss: 0.009777630651585696
[Epoch 22, Batch 2800] loss: 0.007248944490917211
[Epoch 22, Batch 2900] loss: 0.008367090940910203
[Epoch 22, Batch 3000] loss: 0.006468985295614402
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9901
Overfitting: 0.0422
[Epoch 23, Batch 100] loss: 0.0070110283379040085
[Epoch 23, Batch 200] loss: 0.006345564665198253
[Epoch 23, Batch 300] loss: 0.004573396895793848
[Epoch 23, Batch 400] loss: 0.0036636835941590107
[Epoch 23, Batch 500] loss: 0.0047378951870769015
[Epoch 23, Batch 600] loss: 0.0024941433521348698
[Epoch 23, Batch 700] loss: 0.0031418896472109738
[Epoch 23, Batch 800] loss: 0.0049982130947478255
[Epoch 23, Batch 900] loss: 0.0026394654311479825
[Epoch 23, Batch 1000] loss: 0.0018585333868009002
[Epoch 23, Batch 1100] loss: 0.012671814840787192
[Epoch 23, Batch 1200] loss: 0.0046820401088325525
[Epoch 23, Batch 1300] loss: 0.0038708340356021155
[Epoch 23, Batch 1400] loss: 0.0024777018758118173
[Epoch 23, Batch 1500] loss: 0.004777553838342783
[Epoch 23, Batch 1600] loss: 0.003954799024463114
[Epoch 23, Batch 1700] loss: 0.004167459140999199
[Epoch 23, Batch 1800] loss: 0.0027081922638649302
[Epoch 23, Batch 1900] loss: 0.008396983313078863
[Epoch 23, Batch 2000] loss: 0.0026832620461141234
[Epoch 23, Batch 2100] loss: 0.00697828074874792
[Epoch 23, Batch 2200] loss: 0.0034827280085073654
[Epoch 23, Batch 2300] loss: 0.006663575556295313
[Epoch 23, Batch 2400] loss: 0.006692614700288573
[Epoch 23, Batch 2500] loss: 0.005174956204523368
[Epoch 23, Batch 2600] loss: 0.0021742008238834387
[Epoch 23, Batch 2700] loss: 0.0038210426480668504
[Epoch 23, Batch 2800] loss: 0.011695822210169808
[Epoch 23, Batch 2900] loss: 0.005027316043042447
[Epoch 23, Batch 3000] loss: 0.007616265082463087
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9901
Overfitting: 0.0437
[Epoch 24, Batch 100] loss: 0.002388762162664193
[Epoch 24, Batch 200] loss: 0.005131440101881708
[Epoch 24, Batch 300] loss: 0.004128370450303009
[Epoch 24, Batch 400] loss: 0.002226618054494338
[Epoch 24, Batch 500] loss: 0.003046617951192161
[Epoch 24, Batch 600] loss: 0.0042961874255638575
[Epoch 24, Batch 700] loss: 0.0034771713994410903
[Epoch 24, Batch 800] loss: 0.0019496719029348242
[Epoch 24, Batch 900] loss: 0.00785561035384262
[Epoch 24, Batch 1000] loss: 0.0010686388154272208
[Epoch 24, Batch 1100] loss: 0.002890525262034771
[Epoch 24, Batch 1200] loss: 0.008089201644766035
[Epoch 24, Batch 1300] loss: 0.005696038541486814
[Epoch 24, Batch 1400] loss: 0.002182001939503948
[Epoch 24, Batch 1500] loss: 0.009541302053291645
[Epoch 24, Batch 1600] loss: 0.0063389674104200825
[Epoch 24, Batch 1700] loss: 0.0036003246048380787
[Epoch 24, Batch 1800] loss: 0.004897361051750977
[Epoch 24, Batch 1900] loss: 0.004274390088796736
[Epoch 24, Batch 2000] loss: 0.0038596998523090066
[Epoch 24, Batch 2100] loss: 0.00275780583426922
[Epoch 24, Batch 2200] loss: 0.0023100207452557697
[Epoch 24, Batch 2300] loss: 0.0024047468694300277
[Epoch 24, Batch 2400] loss: 0.002780429134370479
[Epoch 24, Batch 2500] loss: 0.008750789615807832
[Epoch 24, Batch 2600] loss: 0.009527487400355313
[Epoch 24, Batch 2700] loss: 0.0055977399472004665
[Epoch 24, Batch 2800] loss: 0.009982484957094613
[Epoch 24, Batch 2900] loss: 0.007318352829852017
[Epoch 24, Batch 3000] loss: 0.00560995104452445
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9899
Overfitting: 0.0467
Fold 5 validation loss: 0.0467
Mean validation loss across all folds for Trial 14 is 0.0499 with trial config:  l1: 256, l2: 128, lr: 0.000662925560873599, batch_size: 16
[I 2024-12-11 05:54:27,622] Trial 13 finished with value: 0.04989075523890983 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.000662925560873599, 'batch_size': 16}. Best is trial 4 with value: 0.04724671796616846.

Selected Hyperparameters for Trial 15:
  l1: 256, l2: 128, lr: 0.0007002216379001282, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2965310287475584
[Epoch 1, Batch 200] loss: 2.2823860931396482
[Epoch 1, Batch 300] loss: 2.257879147529602
[Epoch 1, Batch 400] loss: 2.199910538196564
[Epoch 1, Batch 500] loss: 2.000455378293991
[Epoch 1, Batch 600] loss: 1.2496072351932526
[Epoch 1, Batch 700] loss: 0.7474452650547028
[Epoch 1, Batch 800] loss: 0.5668847024440765
[Epoch 1, Batch 900] loss: 0.5080174724757671
[Epoch 1, Batch 1000] loss: 0.4506113107502461
[Epoch 1, Batch 1100] loss: 0.3465138519182801
[Epoch 1, Batch 1200] loss: 0.3630825056135654
[Epoch 1, Batch 1300] loss: 0.3549921686947346
[Epoch 1, Batch 1400] loss: 0.3234318153560162
[Epoch 1, Batch 1500] loss: 0.3343457045778632
[Epoch 1, Batch 1600] loss: 0.2719622586108744
[Epoch 1, Batch 1700] loss: 0.3070024559274316
[Epoch 1, Batch 1800] loss: 0.22378312593325972
[Epoch 1, Batch 1900] loss: 0.21961725275963545
[Epoch 1, Batch 2000] loss: 0.24128002734854817
[Epoch 1, Batch 2100] loss: 0.23588269628584385
[Epoch 1, Batch 2200] loss: 0.19711508685722948
[Epoch 1, Batch 2300] loss: 0.17048711461480706
[Epoch 1, Batch 2400] loss: 0.2229773113736883
[Epoch 1, Batch 2500] loss: 0.18461735403165222
[Epoch 1, Batch 2600] loss: 0.18034916650503874
[Epoch 1, Batch 2700] loss: 0.21320342208258808
[Epoch 1, Batch 2800] loss: 0.18034089306369425
[Epoch 1, Batch 2900] loss: 0.15738947062753142
[Epoch 1, Batch 3000] loss: 0.16612436824245377
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2045
Validation Accuracy: 0.9347
Overfitting: 0.2045
Best model saved at epoch 1 with validation loss: 0.2045
[Epoch 2, Batch 100] loss: 0.15101306647993623
[Epoch 2, Batch 200] loss: 0.1527001763600856
[Epoch 2, Batch 300] loss: 0.12289863171987235
[Epoch 2, Batch 400] loss: 0.13263046141248197
[Epoch 2, Batch 500] loss: 0.12982817065436392
[Epoch 2, Batch 600] loss: 0.16245853956788778
[Epoch 2, Batch 700] loss: 0.12397042327560484
[Epoch 2, Batch 800] loss: 0.14650867536198348
[Epoch 2, Batch 900] loss: 0.1344026347482577
[Epoch 2, Batch 1000] loss: 0.12361573235131801
[Epoch 2, Batch 1100] loss: 0.14579918229952454
[Epoch 2, Batch 1200] loss: 0.11830607796786353
[Epoch 2, Batch 1300] loss: 0.13480748059693723
[Epoch 2, Batch 1400] loss: 0.1303663915162906
[Epoch 2, Batch 1500] loss: 0.12281093704514205
[Epoch 2, Batch 1600] loss: 0.09735497435322031
[Epoch 2, Batch 1700] loss: 0.14504065786022693
[Epoch 2, Batch 1800] loss: 0.10830291365273297
[Epoch 2, Batch 1900] loss: 0.10439984711818397
[Epoch 2, Batch 2000] loss: 0.10694501563673839
[Epoch 2, Batch 2100] loss: 0.09838257391005754
[Epoch 2, Batch 2200] loss: 0.10140653887647204
[Epoch 2, Batch 2300] loss: 0.11195092612644658
[Epoch 2, Batch 2400] loss: 0.088856952956412
[Epoch 2, Batch 2500] loss: 0.09918244465254247
[Epoch 2, Batch 2600] loss: 0.11610739018535242
[Epoch 2, Batch 2700] loss: 0.09451535643078386
[Epoch 2, Batch 2800] loss: 0.10952558616758325
[Epoch 2, Batch 2900] loss: 0.10482045748271047
[Epoch 2, Batch 3000] loss: 0.08370561661664397
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0878
Validation Accuracy: 0.9722
Overfitting: 0.0878
Best model saved at epoch 2 with validation loss: 0.0878
[Epoch 3, Batch 100] loss: 0.07969221333041787
[Epoch 3, Batch 200] loss: 0.10072769364807754
[Epoch 3, Batch 300] loss: 0.07850325533887371
[Epoch 3, Batch 400] loss: 0.08947680949233472
[Epoch 3, Batch 500] loss: 0.10427079224085901
[Epoch 3, Batch 600] loss: 0.07434677666518837
[Epoch 3, Batch 700] loss: 0.07760654377983883
[Epoch 3, Batch 800] loss: 0.09571630587102846
[Epoch 3, Batch 900] loss: 0.08316997504094616
[Epoch 3, Batch 1000] loss: 0.07324454883811995
[Epoch 3, Batch 1100] loss: 0.09368206745944917
[Epoch 3, Batch 1200] loss: 0.07708475201041437
[Epoch 3, Batch 1300] loss: 0.10253469595802017
[Epoch 3, Batch 1400] loss: 0.08193019750993699
[Epoch 3, Batch 1500] loss: 0.10743625565432012
[Epoch 3, Batch 1600] loss: 0.08824715983937495
[Epoch 3, Batch 1700] loss: 0.08401470307027921
[Epoch 3, Batch 1800] loss: 0.1001066467165947
[Epoch 3, Batch 1900] loss: 0.07621960630873219
[Epoch 3, Batch 2000] loss: 0.08024996290798299
[Epoch 3, Batch 2100] loss: 0.07032491606310941
[Epoch 3, Batch 2200] loss: 0.09009797115926631
[Epoch 3, Batch 2300] loss: 0.06754262555157765
[Epoch 3, Batch 2400] loss: 0.07607848525512964
[Epoch 3, Batch 2500] loss: 0.0815825065644458
[Epoch 3, Batch 2600] loss: 0.0903652378503466
[Epoch 3, Batch 2700] loss: 0.06340773204690776
[Epoch 3, Batch 2800] loss: 0.049147098402027044
[Epoch 3, Batch 2900] loss: 0.0734695596207166
[Epoch 3, Batch 3000] loss: 0.08174538354447577
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0689
Validation Accuracy: 0.9785
Overfitting: 0.0689
Best model saved at epoch 3 with validation loss: 0.0689
[Epoch 4, Batch 100] loss: 0.058637276836670936
[Epoch 4, Batch 200] loss: 0.06961829181527719
[Epoch 4, Batch 300] loss: 0.05772277051524725
[Epoch 4, Batch 400] loss: 0.059230163744068705
[Epoch 4, Batch 500] loss: 0.07870030500693247
[Epoch 4, Batch 600] loss: 0.0597517296182923
[Epoch 4, Batch 700] loss: 0.058341201938455926
[Epoch 4, Batch 800] loss: 0.07044968517613598
[Epoch 4, Batch 900] loss: 0.06855590484454296
[Epoch 4, Batch 1000] loss: 0.07359305867634248
[Epoch 4, Batch 1100] loss: 0.0527801853348501
[Epoch 4, Batch 1200] loss: 0.055823515079682695
[Epoch 4, Batch 1300] loss: 0.05459605055104475
[Epoch 4, Batch 1400] loss: 0.0792164853704162
[Epoch 4, Batch 1500] loss: 0.06624025050667115
[Epoch 4, Batch 1600] loss: 0.07501976359286346
[Epoch 4, Batch 1700] loss: 0.050123393909307194
[Epoch 4, Batch 1800] loss: 0.06751066488213837
[Epoch 4, Batch 1900] loss: 0.07223343549587298
[Epoch 4, Batch 2000] loss: 0.06145624577417039
[Epoch 4, Batch 2100] loss: 0.04678546563081909
[Epoch 4, Batch 2200] loss: 0.0743779394638841
[Epoch 4, Batch 2300] loss: 0.07940105470945127
[Epoch 4, Batch 2400] loss: 0.06163542222871911
[Epoch 4, Batch 2500] loss: 0.05360985075240023
[Epoch 4, Batch 2600] loss: 0.05606299771694467
[Epoch 4, Batch 2700] loss: 0.06138810170115903
[Epoch 4, Batch 2800] loss: 0.06654125064087565
[Epoch 4, Batch 2900] loss: 0.05662414161430206
[Epoch 4, Batch 3000] loss: 0.06263055501156486
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0656
Validation Accuracy: 0.9796
Overfitting: 0.0656
Best model saved at epoch 4 with validation loss: 0.0656
[Epoch 5, Batch 100] loss: 0.041970006367773746
[Epoch 5, Batch 200] loss: 0.0364491482230369
[Epoch 5, Batch 300] loss: 0.06177810667140875
[Epoch 5, Batch 400] loss: 0.046688341012923046
[Epoch 5, Batch 500] loss: 0.05000036186364014
[Epoch 5, Batch 600] loss: 0.06611864002654329
[Epoch 5, Batch 700] loss: 0.07609381936024874
[Epoch 5, Batch 800] loss: 0.04685290854627965
[Epoch 5, Batch 900] loss: 0.044292571567348206
[Epoch 5, Batch 1000] loss: 0.05549486416275613
[Epoch 5, Batch 1100] loss: 0.05961761524144094
[Epoch 5, Batch 1200] loss: 0.042885989689966666
[Epoch 5, Batch 1300] loss: 0.04776073436369188
[Epoch 5, Batch 1400] loss: 0.06352018151432276
[Epoch 5, Batch 1500] loss: 0.06368326474330388
[Epoch 5, Batch 1600] loss: 0.0388616389996605
[Epoch 5, Batch 1700] loss: 0.056395766961213664
[Epoch 5, Batch 1800] loss: 0.04490737539570546
[Epoch 5, Batch 1900] loss: 0.04936397727753501
[Epoch 5, Batch 2000] loss: 0.03333291485352675
[Epoch 5, Batch 2100] loss: 0.0639991353021469
[Epoch 5, Batch 2200] loss: 0.07831751422490925
[Epoch 5, Batch 2300] loss: 0.04147825262567494
[Epoch 5, Batch 2400] loss: 0.048700057767564434
[Epoch 5, Batch 2500] loss: 0.052408396221580916
[Epoch 5, Batch 2600] loss: 0.05114949948794674
[Epoch 5, Batch 2700] loss: 0.05672819540486671
[Epoch 5, Batch 2800] loss: 0.04709657228901051
[Epoch 5, Batch 2900] loss: 0.03903076524322387
[Epoch 5, Batch 3000] loss: 0.045210387113511386
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9848
Overfitting: 0.0499
Best model saved at epoch 5 with validation loss: 0.0499
[Epoch 6, Batch 100] loss: 0.041653922829282236
[Epoch 6, Batch 200] loss: 0.030443821985682008
[Epoch 6, Batch 300] loss: 0.046516807409061584
[Epoch 6, Batch 400] loss: 0.0379869935347233
[Epoch 6, Batch 500] loss: 0.04647137805237435
[Epoch 6, Batch 600] loss: 0.03836201808764599
[Epoch 6, Batch 700] loss: 0.0277546552172862
[Epoch 6, Batch 800] loss: 0.03397381471237168
[Epoch 6, Batch 900] loss: 0.039826602898101554
[Epoch 6, Batch 1000] loss: 0.045598168906290086
[Epoch 6, Batch 1100] loss: 0.06171540608600481
[Epoch 6, Batch 1200] loss: 0.061303041109495096
[Epoch 6, Batch 1300] loss: 0.03611635475681396
[Epoch 6, Batch 1400] loss: 0.04919970183371333
[Epoch 6, Batch 1500] loss: 0.03792442111007403
[Epoch 6, Batch 1600] loss: 0.03587771156628151
[Epoch 6, Batch 1700] loss: 0.05537143648834899
[Epoch 6, Batch 1800] loss: 0.058700040950789116
[Epoch 6, Batch 1900] loss: 0.04447686695726588
[Epoch 6, Batch 2000] loss: 0.04485457438582671
[Epoch 6, Batch 2100] loss: 0.048242845150234644
[Epoch 6, Batch 2200] loss: 0.04335001012557768
[Epoch 6, Batch 2300] loss: 0.034937998763925865
[Epoch 6, Batch 2400] loss: 0.05136234006844461
[Epoch 6, Batch 2500] loss: 0.04183010039589135
[Epoch 6, Batch 2600] loss: 0.046317445257591315
[Epoch 6, Batch 2700] loss: 0.04047103924618568
[Epoch 6, Batch 2800] loss: 0.03978052152728196
[Epoch 6, Batch 2900] loss: 0.05533343713381328
[Epoch 6, Batch 3000] loss: 0.05331575616757618
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9844
Overfitting: 0.0480
Best model saved at epoch 6 with validation loss: 0.0480
[Epoch 7, Batch 100] loss: 0.03696259033647948
[Epoch 7, Batch 200] loss: 0.04614895637700101
[Epoch 7, Batch 300] loss: 0.049898293082951566
[Epoch 7, Batch 400] loss: 0.04117194020189345
[Epoch 7, Batch 500] loss: 0.03033761670580134
[Epoch 7, Batch 600] loss: 0.03685702927497914
[Epoch 7, Batch 700] loss: 0.042966824723698664
[Epoch 7, Batch 800] loss: 0.04259086528851185
[Epoch 7, Batch 900] loss: 0.02646215474407654
[Epoch 7, Batch 1000] loss: 0.03573826924766763
[Epoch 7, Batch 1100] loss: 0.03426778549561277
[Epoch 7, Batch 1200] loss: 0.045778447998091
[Epoch 7, Batch 1300] loss: 0.04036388298743986
[Epoch 7, Batch 1400] loss: 0.042421703764703125
[Epoch 7, Batch 1500] loss: 0.04923316142463591
[Epoch 7, Batch 1600] loss: 0.0430975414038403
[Epoch 7, Batch 1700] loss: 0.04332947192975553
[Epoch 7, Batch 1800] loss: 0.030437119652342515
[Epoch 7, Batch 1900] loss: 0.038716148229577814
[Epoch 7, Batch 2000] loss: 0.04119956508773612
[Epoch 7, Batch 2100] loss: 0.030204940054682085
[Epoch 7, Batch 2200] loss: 0.04127581986133009
[Epoch 7, Batch 2300] loss: 0.06204240223538363
[Epoch 7, Batch 2400] loss: 0.03848473910969915
[Epoch 7, Batch 2500] loss: 0.04858647246350301
[Epoch 7, Batch 2600] loss: 0.03480470480993972
[Epoch 7, Batch 2700] loss: 0.03084501151650329
[Epoch 7, Batch 2800] loss: 0.029634769999684066
[Epoch 7, Batch 2900] loss: 0.02666907830600394
[Epoch 7, Batch 3000] loss: 0.027038970967114436
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9852
Overfitting: 0.0484
[Epoch 8, Batch 100] loss: 0.019297264096312574
[Epoch 8, Batch 200] loss: 0.025488119488727534
[Epoch 8, Batch 300] loss: 0.028867791979646427
[Epoch 8, Batch 400] loss: 0.03465252327092458
[Epoch 8, Batch 500] loss: 0.028045991942781255
[Epoch 8, Batch 600] loss: 0.032557678680313985
[Epoch 8, Batch 700] loss: 0.043581730484147554
[Epoch 8, Batch 800] loss: 0.028165340463347094
[Epoch 8, Batch 900] loss: 0.0216155463582254
[Epoch 8, Batch 1000] loss: 0.029116661290318008
[Epoch 8, Batch 1100] loss: 0.03743147306435276
[Epoch 8, Batch 1200] loss: 0.04340810858586337
[Epoch 8, Batch 1300] loss: 0.05037734474492026
[Epoch 8, Batch 1400] loss: 0.03818029646703508
[Epoch 8, Batch 1500] loss: 0.036980575459601824
[Epoch 8, Batch 1600] loss: 0.03422016032935062
[Epoch 8, Batch 1700] loss: 0.030831947007172858
[Epoch 8, Batch 1800] loss: 0.03930682744277874
[Epoch 8, Batch 1900] loss: 0.034428050148708284
[Epoch 8, Batch 2000] loss: 0.020880094177118735
[Epoch 8, Batch 2100] loss: 0.032905128373822666
[Epoch 8, Batch 2200] loss: 0.031008464358601485
[Epoch 8, Batch 2300] loss: 0.045064239922503475
[Epoch 8, Batch 2400] loss: 0.028998148222162855
[Epoch 8, Batch 2500] loss: 0.034522195944737176
[Epoch 8, Batch 2600] loss: 0.03976653864971013
[Epoch 8, Batch 2700] loss: 0.02898373616131721
[Epoch 8, Batch 2800] loss: 0.031381060888525096
[Epoch 8, Batch 2900] loss: 0.039547765725001224
[Epoch 8, Batch 3000] loss: 0.02922277097379265
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9840
Overfitting: 0.0514
[Epoch 9, Batch 100] loss: 0.0368730741131003
[Epoch 9, Batch 200] loss: 0.02845005225048226
[Epoch 9, Batch 300] loss: 0.04335271103656851
[Epoch 9, Batch 400] loss: 0.030334568548059906
[Epoch 9, Batch 500] loss: 0.0326408522996644
[Epoch 9, Batch 600] loss: 0.02003678626002511
[Epoch 9, Batch 700] loss: 0.026333588909183164
[Epoch 9, Batch 800] loss: 0.032757946993551744
[Epoch 9, Batch 900] loss: 0.03275203497003531
[Epoch 9, Batch 1000] loss: 0.027469826162050594
[Epoch 9, Batch 1100] loss: 0.025016591605854045
[Epoch 9, Batch 1200] loss: 0.026607268505904356
[Epoch 9, Batch 1300] loss: 0.02423378808198322
[Epoch 9, Batch 1400] loss: 0.02766224363202127
[Epoch 9, Batch 1500] loss: 0.01864085551522294
[Epoch 9, Batch 1600] loss: 0.03605044789866952
[Epoch 9, Batch 1700] loss: 0.017514099032850936
[Epoch 9, Batch 1800] loss: 0.025748531993467622
[Epoch 9, Batch 1900] loss: 0.04476946356007829
[Epoch 9, Batch 2000] loss: 0.02118453396622499
[Epoch 9, Batch 2100] loss: 0.029440717660472727
[Epoch 9, Batch 2200] loss: 0.023677693736899527
[Epoch 9, Batch 2300] loss: 0.030664037236419972
[Epoch 9, Batch 2400] loss: 0.03731753123131057
[Epoch 9, Batch 2500] loss: 0.040422749932986335
[Epoch 9, Batch 2600] loss: 0.024037289685220457
[Epoch 9, Batch 2700] loss: 0.020898984121158717
[Epoch 9, Batch 2800] loss: 0.025755730301389123
[Epoch 9, Batch 2900] loss: 0.022958339288998104
[Epoch 9, Batch 3000] loss: 0.0239906915938991
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9855
Overfitting: 0.0474
Best model saved at epoch 9 with validation loss: 0.0474
[Epoch 10, Batch 100] loss: 0.01587648603519483
[Epoch 10, Batch 200] loss: 0.019471871209243544
[Epoch 10, Batch 300] loss: 0.03285763309286267
[Epoch 10, Batch 400] loss: 0.01568013470234291
[Epoch 10, Batch 500] loss: 0.025485982794489246
[Epoch 10, Batch 600] loss: 0.025926146560086637
[Epoch 10, Batch 700] loss: 0.036844362033625656
[Epoch 10, Batch 800] loss: 0.032163669299698085
[Epoch 10, Batch 900] loss: 0.027988278289121808
[Epoch 10, Batch 1000] loss: 0.02656945106049534
[Epoch 10, Batch 1100] loss: 0.024799445042153822
[Epoch 10, Batch 1200] loss: 0.02276609388725774
[Epoch 10, Batch 1300] loss: 0.03031204329505272
[Epoch 10, Batch 1400] loss: 0.019664202622661834
[Epoch 10, Batch 1500] loss: 0.03000509923291247
[Epoch 10, Batch 1600] loss: 0.04321536524235853
[Epoch 10, Batch 1700] loss: 0.02987088097142987
[Epoch 10, Batch 1800] loss: 0.02953334428719245
[Epoch 10, Batch 1900] loss: 0.035861368174519154
[Epoch 10, Batch 2000] loss: 0.027043370120227336
[Epoch 10, Batch 2100] loss: 0.028044576593019885
[Epoch 10, Batch 2200] loss: 0.01870013799489243
[Epoch 10, Batch 2300] loss: 0.03174957028270001
[Epoch 10, Batch 2400] loss: 0.019261547413043444
[Epoch 10, Batch 2500] loss: 0.02090856288006762
[Epoch 10, Batch 2600] loss: 0.017337175253633177
[Epoch 10, Batch 2700] loss: 0.036486249896479424
[Epoch 10, Batch 2800] loss: 0.036148966573891814
[Epoch 10, Batch 2900] loss: 0.017197815990894014
[Epoch 10, Batch 3000] loss: 0.021534294143348235
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9849
Overfitting: 0.0535
[Epoch 11, Batch 100] loss: 0.016485166576076155
[Epoch 11, Batch 200] loss: 0.014383714350988158
[Epoch 11, Batch 300] loss: 0.01590574513500542
[Epoch 11, Batch 400] loss: 0.020370440437327487
[Epoch 11, Batch 500] loss: 0.017159765015967422
[Epoch 11, Batch 600] loss: 0.016916057269227167
[Epoch 11, Batch 700] loss: 0.014610996039036763
[Epoch 11, Batch 800] loss: 0.0191369398230745
[Epoch 11, Batch 900] loss: 0.023355258256269735
[Epoch 11, Batch 1000] loss: 0.033731531197627194
[Epoch 11, Batch 1100] loss: 0.027133918098043067
[Epoch 11, Batch 1200] loss: 0.02777745640327339
[Epoch 11, Batch 1300] loss: 0.02315787646904937
[Epoch 11, Batch 1400] loss: 0.02432271524277894
[Epoch 11, Batch 1500] loss: 0.018675171961513116
[Epoch 11, Batch 1600] loss: 0.02589871611824492
[Epoch 11, Batch 1700] loss: 0.02716395484218083
[Epoch 11, Batch 1800] loss: 0.028353182249338714
[Epoch 11, Batch 1900] loss: 0.019847480207681657
[Epoch 11, Batch 2000] loss: 0.01726296531382104
[Epoch 11, Batch 2100] loss: 0.01951802165058325
[Epoch 11, Batch 2200] loss: 0.028396286251991115
[Epoch 11, Batch 2300] loss: 0.02316301560102147
[Epoch 11, Batch 2400] loss: 0.01691366684368404
[Epoch 11, Batch 2500] loss: 0.02458452618411684
[Epoch 11, Batch 2600] loss: 0.03168462328496389
[Epoch 11, Batch 2700] loss: 0.024899074313725577
[Epoch 11, Batch 2800] loss: 0.017879943995903886
[Epoch 11, Batch 2900] loss: 0.03356632957875263
[Epoch 11, Batch 3000] loss: 0.01632432414968207
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9842
Overfitting: 0.0533
[Epoch 12, Batch 100] loss: 0.02165089474248816
[Epoch 12, Batch 200] loss: 0.021094435359846102
[Epoch 12, Batch 300] loss: 0.014129621669853805
[Epoch 12, Batch 400] loss: 0.015594510088521928
[Epoch 12, Batch 500] loss: 0.0185085178763984
[Epoch 12, Batch 600] loss: 0.016502787451609036
[Epoch 12, Batch 700] loss: 0.009906511696826784
[Epoch 12, Batch 800] loss: 0.01598145742875204
[Epoch 12, Batch 900] loss: 0.024287035028464743
[Epoch 12, Batch 1000] loss: 0.02860581441429531
[Epoch 12, Batch 1100] loss: 0.03392544935668411
[Epoch 12, Batch 1200] loss: 0.01064096857491677
[Epoch 12, Batch 1300] loss: 0.012071307891364996
[Epoch 12, Batch 1400] loss: 0.011712640055029623
[Epoch 12, Batch 1500] loss: 0.0247377621670239
[Epoch 12, Batch 1600] loss: 0.015882310866873015
[Epoch 12, Batch 1700] loss: 0.019073872102671884
[Epoch 12, Batch 1800] loss: 0.029188963026954298
[Epoch 12, Batch 1900] loss: 0.01585932640689862
[Epoch 12, Batch 2000] loss: 0.021934555727493716
[Epoch 12, Batch 2100] loss: 0.021956647792758303
[Epoch 12, Batch 2200] loss: 0.0298949572721358
[Epoch 12, Batch 2300] loss: 0.02507826234024833
[Epoch 12, Batch 2400] loss: 0.029507925835059724
[Epoch 12, Batch 2500] loss: 0.01494189213433856
[Epoch 12, Batch 2600] loss: 0.024999323158299377
[Epoch 12, Batch 2700] loss: 0.03650898678108206
[Epoch 12, Batch 2800] loss: 0.019183672949693573
[Epoch 12, Batch 2900] loss: 0.014759178815584164
[Epoch 12, Batch 3000] loss: 0.02011273812067884
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0460
Validation Accuracy: 0.9869
Overfitting: 0.0460
Best model saved at epoch 12 with validation loss: 0.0460
[Epoch 13, Batch 100] loss: 0.033892662942089376
[Epoch 13, Batch 200] loss: 0.01635371833868703
[Epoch 13, Batch 300] loss: 0.016721242936600902
[Epoch 13, Batch 400] loss: 0.011593127466076112
[Epoch 13, Batch 500] loss: 0.012518459962338966
[Epoch 13, Batch 600] loss: 0.020767507507298433
[Epoch 13, Batch 700] loss: 0.014744228627860139
[Epoch 13, Batch 800] loss: 0.01929350717437046
[Epoch 13, Batch 900] loss: 0.014456366946615163
[Epoch 13, Batch 1000] loss: 0.021957285835014773
[Epoch 13, Batch 1100] loss: 0.021648683474122663
[Epoch 13, Batch 1200] loss: 0.022114979100369966
[Epoch 13, Batch 1300] loss: 0.01752511324700208
[Epoch 13, Batch 1400] loss: 0.025108267437517498
[Epoch 13, Batch 1500] loss: 0.02067724092944445
[Epoch 13, Batch 1600] loss: 0.019589046881937976
[Epoch 13, Batch 1700] loss: 0.02210023795814777
[Epoch 13, Batch 1800] loss: 0.009451285822406135
[Epoch 13, Batch 1900] loss: 0.021664707721483864
[Epoch 13, Batch 2000] loss: 0.01247098375582027
[Epoch 13, Batch 2100] loss: 0.020568208145668905
[Epoch 13, Batch 2200] loss: 0.02435619439344009
[Epoch 13, Batch 2300] loss: 0.014897063325770432
[Epoch 13, Batch 2400] loss: 0.017944155611185123
[Epoch 13, Batch 2500] loss: 0.015375644573905447
[Epoch 13, Batch 2600] loss: 0.014428841706103413
[Epoch 13, Batch 2700] loss: 0.018556891903244832
[Epoch 13, Batch 2800] loss: 0.010904570976344985
[Epoch 13, Batch 2900] loss: 0.013931128352887755
[Epoch 13, Batch 3000] loss: 0.024852512221077632
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9852
Overfitting: 0.0522
[Epoch 14, Batch 100] loss: 0.01791079729523517
[Epoch 14, Batch 200] loss: 0.010031786769677637
[Epoch 14, Batch 300] loss: 0.013778655169262492
[Epoch 14, Batch 400] loss: 0.01080967331271495
[Epoch 14, Batch 500] loss: 0.013648943520211105
[Epoch 14, Batch 600] loss: 0.009141961449959126
[Epoch 14, Batch 700] loss: 0.020186167417159596
[Epoch 14, Batch 800] loss: 0.015049006845110853
[Epoch 14, Batch 900] loss: 0.014014118945378868
[Epoch 14, Batch 1000] loss: 0.01755254085510387
[Epoch 14, Batch 1100] loss: 0.0204182092829069
[Epoch 14, Batch 1200] loss: 0.019108829814354068
[Epoch 14, Batch 1300] loss: 0.009446022986890058
[Epoch 14, Batch 1400] loss: 0.010628543713955878
[Epoch 14, Batch 1500] loss: 0.015340021922820597
[Epoch 14, Batch 1600] loss: 0.017357079479279492
[Epoch 14, Batch 1700] loss: 0.018983953288366138
[Epoch 14, Batch 1800] loss: 0.01691077246241548
[Epoch 14, Batch 1900] loss: 0.01730930759787043
[Epoch 14, Batch 2000] loss: 0.01872116219739837
[Epoch 14, Batch 2100] loss: 0.015243592954120685
[Epoch 14, Batch 2200] loss: 0.023421608259113783
[Epoch 14, Batch 2300] loss: 0.017674143336116686
[Epoch 14, Batch 2400] loss: 0.014755963652060018
[Epoch 14, Batch 2500] loss: 0.01191431769364499
[Epoch 14, Batch 2600] loss: 0.012508407811128563
[Epoch 14, Batch 2700] loss: 0.03366688477583011
[Epoch 14, Batch 2800] loss: 0.012892411784887372
[Epoch 14, Batch 2900] loss: 0.02063245181750972
[Epoch 14, Batch 3000] loss: 0.01589129571280864
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0448
Validation Accuracy: 0.9866
Overfitting: 0.0448
Best model saved at epoch 14 with validation loss: 0.0448
[Epoch 15, Batch 100] loss: 0.011921553484571632
[Epoch 15, Batch 200] loss: 0.008152857650711666
[Epoch 15, Batch 300] loss: 0.013723801123305748
[Epoch 15, Batch 400] loss: 0.00859589249957935
[Epoch 15, Batch 500] loss: 0.007098967214697041
[Epoch 15, Batch 600] loss: 0.00957661984986771
[Epoch 15, Batch 700] loss: 0.010271298668794771
[Epoch 15, Batch 800] loss: 0.013332281435577898
[Epoch 15, Batch 900] loss: 0.012352536323091953
[Epoch 15, Batch 1000] loss: 0.007191937123316165
[Epoch 15, Batch 1100] loss: 0.01211343813489293
[Epoch 15, Batch 1200] loss: 0.014478501344456163
[Epoch 15, Batch 1300] loss: 0.006538987274370811
[Epoch 15, Batch 1400] loss: 0.018510585604908557
[Epoch 15, Batch 1500] loss: 0.025149588410777142
[Epoch 15, Batch 1600] loss: 0.010455275296644686
[Epoch 15, Batch 1700] loss: 0.017798229801119305
[Epoch 15, Batch 1800] loss: 0.015205208113784466
[Epoch 15, Batch 1900] loss: 0.02393140304429835
[Epoch 15, Batch 2000] loss: 0.013684120899888512
[Epoch 15, Batch 2100] loss: 0.008129953804946126
[Epoch 15, Batch 2200] loss: 0.007882187849681942
[Epoch 15, Batch 2300] loss: 0.023172623406157982
[Epoch 15, Batch 2400] loss: 0.020007271094600584
[Epoch 15, Batch 2500] loss: 0.019518203814723165
[Epoch 15, Batch 2600] loss: 0.018666049065268454
[Epoch 15, Batch 2700] loss: 0.014870168679599373
[Epoch 15, Batch 2800] loss: 0.01290030833117271
[Epoch 15, Batch 2900] loss: 0.0070404361899636565
[Epoch 15, Batch 3000] loss: 0.01719941455668959
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0417
Validation Accuracy: 0.9888
Overfitting: 0.0417
Best model saved at epoch 15 with validation loss: 0.0417
[Epoch 16, Batch 100] loss: 0.011934683966987904
[Epoch 16, Batch 200] loss: 0.012424703193291862
[Epoch 16, Batch 300] loss: 0.017714222268061804
[Epoch 16, Batch 400] loss: 0.011861784249267657
[Epoch 16, Batch 500] loss: 0.010025936751708287
[Epoch 16, Batch 600] loss: 0.011432282637315438
[Epoch 16, Batch 700] loss: 0.013038337237558153
[Epoch 16, Batch 800] loss: 0.019652638701318212
[Epoch 16, Batch 900] loss: 0.018830808309194254
[Epoch 16, Batch 1000] loss: 0.014426726217625401
[Epoch 16, Batch 1100] loss: 0.013641642742695694
[Epoch 16, Batch 1200] loss: 0.012906718666672532
[Epoch 16, Batch 1300] loss: 0.00831451729559376
[Epoch 16, Batch 1400] loss: 0.01839064182859147
[Epoch 16, Batch 1500] loss: 0.01358490491486009
[Epoch 16, Batch 1600] loss: 0.008928995744390704
[Epoch 16, Batch 1700] loss: 0.008286523670249154
[Epoch 16, Batch 1800] loss: 0.014180597123950065
[Epoch 16, Batch 1900] loss: 0.011090724998693987
[Epoch 16, Batch 2000] loss: 0.008898591899323946
[Epoch 16, Batch 2100] loss: 0.00752866410814022
[Epoch 16, Batch 2200] loss: 0.013751849377204053
[Epoch 16, Batch 2300] loss: 0.01325288264592018
[Epoch 16, Batch 2400] loss: 0.026957099008523073
[Epoch 16, Batch 2500] loss: 0.013340051910690818
[Epoch 16, Batch 2600] loss: 0.01585747351565715
[Epoch 16, Batch 2700] loss: 0.017057057543843256
[Epoch 16, Batch 2800] loss: 0.007864914671126827
[Epoch 16, Batch 2900] loss: 0.011492174927170709
[Epoch 16, Batch 3000] loss: 0.007780208545264031
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0438
Validation Accuracy: 0.9877
Overfitting: 0.0438
[Epoch 17, Batch 100] loss: 0.0058939077028890095
[Epoch 17, Batch 200] loss: 0.007693283542521385
[Epoch 17, Batch 300] loss: 0.0074653532397678645
[Epoch 17, Batch 400] loss: 0.01198322778292095
[Epoch 17, Batch 500] loss: 0.012618829546800043
[Epoch 17, Batch 600] loss: 0.007574585241682144
[Epoch 17, Batch 700] loss: 0.004193103305483419
[Epoch 17, Batch 800] loss: 0.008073576095957833
[Epoch 17, Batch 900] loss: 0.007231117512747005
[Epoch 17, Batch 1000] loss: 0.014056703304397615
[Epoch 17, Batch 1100] loss: 0.012548238979070448
[Epoch 17, Batch 1200] loss: 0.010448503891966538
[Epoch 17, Batch 1300] loss: 0.012565258916092717
[Epoch 17, Batch 1400] loss: 0.01511194039154816
[Epoch 17, Batch 1500] loss: 0.010680802251617933
[Epoch 17, Batch 1600] loss: 0.02015981373676368
[Epoch 17, Batch 1700] loss: 0.018282070219192974
[Epoch 17, Batch 1800] loss: 0.012046636847280752
[Epoch 17, Batch 1900] loss: 0.007808588429325028
[Epoch 17, Batch 2000] loss: 0.0086150925120819
[Epoch 17, Batch 2100] loss: 0.013499048567609861
[Epoch 17, Batch 2200] loss: 0.007524859607462986
[Epoch 17, Batch 2300] loss: 0.005653454154962673
[Epoch 17, Batch 2400] loss: 0.010745714152121763
[Epoch 17, Batch 2500] loss: 0.00836139966112114
[Epoch 17, Batch 2600] loss: 0.018991776865887003
[Epoch 17, Batch 2700] loss: 0.02252276410632476
[Epoch 17, Batch 2800] loss: 0.009742734573173949
[Epoch 17, Batch 2900] loss: 0.007738696794870065
[Epoch 17, Batch 3000] loss: 0.011409052548956425
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9876
Overfitting: 0.0455
[Epoch 18, Batch 100] loss: 0.01735408921127714
[Epoch 18, Batch 200] loss: 0.009378829055076494
[Epoch 18, Batch 300] loss: 0.005521246251237244
[Epoch 18, Batch 400] loss: 0.010359537684739734
[Epoch 18, Batch 500] loss: 0.006754110710389795
[Epoch 18, Batch 600] loss: 0.007034760913888931
[Epoch 18, Batch 700] loss: 0.008401515068389926
[Epoch 18, Batch 800] loss: 0.007703922067926214
[Epoch 18, Batch 900] loss: 0.007908073964044889
[Epoch 18, Batch 1000] loss: 0.015490070905166249
[Epoch 18, Batch 1100] loss: 0.0051706063439814895
[Epoch 18, Batch 1200] loss: 0.007369382929500717
[Epoch 18, Batch 1300] loss: 0.013051497104852388
[Epoch 18, Batch 1400] loss: 0.011113095636637808
[Epoch 18, Batch 1500] loss: 0.00881021116071679
[Epoch 18, Batch 1600] loss: 0.014851630228331487
[Epoch 18, Batch 1700] loss: 0.009756015639052294
[Epoch 18, Batch 1800] loss: 0.01243297313381845
[Epoch 18, Batch 1900] loss: 0.010963083957321942
[Epoch 18, Batch 2000] loss: 0.028507734474351308
[Epoch 18, Batch 2100] loss: 0.009457843217360278
[Epoch 18, Batch 2200] loss: 0.00719234244200834
[Epoch 18, Batch 2300] loss: 0.007766669044206083
[Epoch 18, Batch 2400] loss: 0.017727527567449216
[Epoch 18, Batch 2500] loss: 0.011559612728027559
[Epoch 18, Batch 2600] loss: 0.012043257409109174
[Epoch 18, Batch 2700] loss: 0.009205911032649965
[Epoch 18, Batch 2800] loss: 0.009914158454612333
[Epoch 18, Batch 2900] loss: 0.00884027348669406
[Epoch 18, Batch 3000] loss: 0.00896582277267953
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9871
Overfitting: 0.0483
[Epoch 19, Batch 100] loss: 0.005274968639705549
[Epoch 19, Batch 200] loss: 0.006052799413710091
[Epoch 19, Batch 300] loss: 0.003044896480648731
[Epoch 19, Batch 400] loss: 0.00956192252733672
[Epoch 19, Batch 500] loss: 0.005978817949307995
[Epoch 19, Batch 600] loss: 0.009496882803473454
[Epoch 19, Batch 700] loss: 0.008930802023442083
[Epoch 19, Batch 800] loss: 0.0049822484515902946
[Epoch 19, Batch 900] loss: 0.004597849616984604
[Epoch 19, Batch 1000] loss: 0.005927038850563804
[Epoch 19, Batch 1100] loss: 0.010259704408401831
[Epoch 19, Batch 1200] loss: 0.022915441953609842
[Epoch 19, Batch 1300] loss: 0.006513535902331569
[Epoch 19, Batch 1400] loss: 0.008436223894950672
[Epoch 19, Batch 1500] loss: 0.009531090623186174
[Epoch 19, Batch 1600] loss: 0.0070945171858704725
[Epoch 19, Batch 1700] loss: 0.0090081689293811
[Epoch 19, Batch 1800] loss: 0.00818009763671853
[Epoch 19, Batch 1900] loss: 0.01333886759213783
[Epoch 19, Batch 2000] loss: 0.009732004134471027
[Epoch 19, Batch 2100] loss: 0.015887138500238505
[Epoch 19, Batch 2200] loss: 0.01001384282680192
[Epoch 19, Batch 2300] loss: 0.009724373949889014
[Epoch 19, Batch 2400] loss: 0.006686922309854708
[Epoch 19, Batch 2500] loss: 0.006470150360610205
[Epoch 19, Batch 2600] loss: 0.007546078659888735
[Epoch 19, Batch 2700] loss: 0.00736989221555632
[Epoch 19, Batch 2800] loss: 0.004538621904183629
[Epoch 19, Batch 2900] loss: 0.014422305657233778
[Epoch 19, Batch 3000] loss: 0.006141257961960491
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9872
Overfitting: 0.0471
[Epoch 20, Batch 100] loss: 0.003157312883577106
[Epoch 20, Batch 200] loss: 0.007363012534037807
[Epoch 20, Batch 300] loss: 0.008653382413809823
[Epoch 20, Batch 400] loss: 0.0034999980733391566
[Epoch 20, Batch 500] loss: 0.0032986619444454845
[Epoch 20, Batch 600] loss: 0.004743318780651862
[Epoch 20, Batch 700] loss: 0.0064209441712773695
[Epoch 20, Batch 800] loss: 0.006741065761457321
[Epoch 20, Batch 900] loss: 0.004861484619287921
[Epoch 20, Batch 1000] loss: 0.005409691947202191
[Epoch 20, Batch 1100] loss: 0.0060408511635559135
[Epoch 20, Batch 1200] loss: 0.003026647554090687
[Epoch 20, Batch 1300] loss: 0.00886782857970502
[Epoch 20, Batch 1400] loss: 0.007731173822053279
[Epoch 20, Batch 1500] loss: 0.011098183694066392
[Epoch 20, Batch 1600] loss: 0.012034135829037496
[Epoch 20, Batch 1700] loss: 0.0056682802831801386
[Epoch 20, Batch 1800] loss: 0.008845794179076166
[Epoch 20, Batch 1900] loss: 0.008237437244474677
[Epoch 20, Batch 2000] loss: 0.004732908782386858
[Epoch 20, Batch 2100] loss: 0.012041033789726043
[Epoch 20, Batch 2200] loss: 0.011316230643874405
[Epoch 20, Batch 2300] loss: 0.012288672803388181
[Epoch 20, Batch 2400] loss: 0.011515865105286594
[Epoch 20, Batch 2500] loss: 0.007332693973985442
[Epoch 20, Batch 2600] loss: 0.01250488717701046
[Epoch 20, Batch 2700] loss: 0.008333045762037727
[Epoch 20, Batch 2800] loss: 0.015723850909489558
[Epoch 20, Batch 2900] loss: 0.005706624201552586
[Epoch 20, Batch 3000] loss: 0.003821672776630294
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9877
Overfitting: 0.0474
[Epoch 21, Batch 100] loss: 0.0060330003097078585
[Epoch 21, Batch 200] loss: 0.006825908150376563
[Epoch 21, Batch 300] loss: 0.012783100263131928
[Epoch 21, Batch 400] loss: 0.003913812943001176
[Epoch 21, Batch 500] loss: 0.01395797827590684
[Epoch 21, Batch 600] loss: 0.009342136266996022
[Epoch 21, Batch 700] loss: 0.005732746040157508
[Epoch 21, Batch 800] loss: 0.004507850041391066
[Epoch 21, Batch 900] loss: 0.004751719846376545
[Epoch 21, Batch 1000] loss: 0.00504605677843756
[Epoch 21, Batch 1100] loss: 0.006977707798996562
[Epoch 21, Batch 1200] loss: 0.0019527072047299044
[Epoch 21, Batch 1300] loss: 0.0033453818094045574
[Epoch 21, Batch 1400] loss: 0.009799031193554129
[Epoch 21, Batch 1500] loss: 0.0032165497389155463
[Epoch 21, Batch 1600] loss: 0.003650444850549661
[Epoch 21, Batch 1700] loss: 0.003634305154763524
[Epoch 21, Batch 1800] loss: 0.006233981727201581
[Epoch 21, Batch 1900] loss: 0.004553030493262895
[Epoch 21, Batch 2000] loss: 0.006947361551497124
[Epoch 21, Batch 2100] loss: 0.007117397031445307
[Epoch 21, Batch 2200] loss: 0.0071628382456083274
[Epoch 21, Batch 2300] loss: 0.009574661822198323
[Epoch 21, Batch 2400] loss: 0.009800783619816684
[Epoch 21, Batch 2500] loss: 0.006872179861388759
[Epoch 21, Batch 2600] loss: 0.008928557023255053
[Epoch 21, Batch 2700] loss: 0.006481910034804059
[Epoch 21, Batch 2800] loss: 0.010583496227991986
[Epoch 21, Batch 2900] loss: 0.006598065998164202
[Epoch 21, Batch 3000] loss: 0.007629836561086449
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9888
Overfitting: 0.0445
[Epoch 22, Batch 100] loss: 0.0052957184329977735
[Epoch 22, Batch 200] loss: 0.005744740740398129
[Epoch 22, Batch 300] loss: 0.005041489338047143
[Epoch 22, Batch 400] loss: 0.0017284904668008493
[Epoch 22, Batch 500] loss: 0.002921013305916631
[Epoch 22, Batch 600] loss: 0.003971315373023572
[Epoch 22, Batch 700] loss: 0.00437352940481901
[Epoch 22, Batch 800] loss: 0.001564335071577716
[Epoch 22, Batch 900] loss: 0.00814858916246635
[Epoch 22, Batch 1000] loss: 0.00472975797802178
[Epoch 22, Batch 1100] loss: 0.007471805556081961
[Epoch 22, Batch 1200] loss: 0.012022466116129636
[Epoch 22, Batch 1300] loss: 0.008311650047528474
[Epoch 22, Batch 1400] loss: 0.005448255717810753
[Epoch 22, Batch 1500] loss: 0.012620093296725372
[Epoch 22, Batch 1600] loss: 0.01234900706035205
[Epoch 22, Batch 1700] loss: 0.002059571750211262
[Epoch 22, Batch 1800] loss: 0.008064397182215544
[Epoch 22, Batch 1900] loss: 0.006948926067402681
[Epoch 22, Batch 2000] loss: 0.007874704600221777
[Epoch 22, Batch 2100] loss: 0.004761517627919147
[Epoch 22, Batch 2200] loss: 0.0024927966686675517
[Epoch 22, Batch 2300] loss: 0.0029600691845968895
[Epoch 22, Batch 2400] loss: 0.0030314538334209828
[Epoch 22, Batch 2500] loss: 0.0041847232993171704
[Epoch 22, Batch 2600] loss: 0.0032779451985248897
[Epoch 22, Batch 2700] loss: 0.0039272152938186625
[Epoch 22, Batch 2800] loss: 0.004215934735188966
[Epoch 22, Batch 2900] loss: 0.0109993343988981
[Epoch 22, Batch 3000] loss: 0.007393699076577605
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9882
Overfitting: 0.0491
[Epoch 23, Batch 100] loss: 0.012854766481675597
[Epoch 23, Batch 200] loss: 0.005436454403779862
[Epoch 23, Batch 300] loss: 0.007031788860363691
[Epoch 23, Batch 400] loss: 0.0029746436265895683
[Epoch 23, Batch 500] loss: 0.006360029367677385
[Epoch 23, Batch 600] loss: 0.0044734483549666495
[Epoch 23, Batch 700] loss: 0.002727925126016544
[Epoch 23, Batch 800] loss: 0.0023720734638766317
[Epoch 23, Batch 900] loss: 0.00251260636316033
[Epoch 23, Batch 1000] loss: 0.00278455618892508
[Epoch 23, Batch 1100] loss: 0.0033355302630937445
[Epoch 23, Batch 1200] loss: 0.004137040639554499
[Epoch 23, Batch 1300] loss: 0.009998737458563483
[Epoch 23, Batch 1400] loss: 0.01241996071309586
[Epoch 23, Batch 1500] loss: 0.008671970252753453
[Epoch 23, Batch 1600] loss: 0.006190574140474609
[Epoch 23, Batch 1700] loss: 0.0062064826821114135
[Epoch 23, Batch 1800] loss: 0.0057442577343954325
[Epoch 23, Batch 1900] loss: 0.0029704818307391178
[Epoch 23, Batch 2000] loss: 0.003059318447735677
[Epoch 23, Batch 2100] loss: 0.002128021854236408
[Epoch 23, Batch 2200] loss: 0.0023018590643232527
[Epoch 23, Batch 2300] loss: 0.00906713986343334
[Epoch 23, Batch 2400] loss: 0.008375118868550545
[Epoch 23, Batch 2500] loss: 0.0038251088630818233
[Epoch 23, Batch 2600] loss: 0.00506330630140269
[Epoch 23, Batch 2700] loss: 0.00613498344509992
[Epoch 23, Batch 2800] loss: 0.00642466065171675
[Epoch 23, Batch 2900] loss: 0.0027638054390376966
[Epoch 23, Batch 3000] loss: 0.008234098114661493
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9887
Overfitting: 0.0457
[Epoch 24, Batch 100] loss: 0.008515092755238811
[Epoch 24, Batch 200] loss: 0.011519924498081195
[Epoch 24, Batch 300] loss: 0.003203142722366579
[Epoch 24, Batch 400] loss: 0.007117431770363964
[Epoch 24, Batch 500] loss: 0.0032969570041279893
[Epoch 24, Batch 600] loss: 0.0063256868720304735
[Epoch 24, Batch 700] loss: 0.012080391849897865
[Epoch 24, Batch 800] loss: 0.002444235663937491
[Epoch 24, Batch 900] loss: 0.0022989750516001096
[Epoch 24, Batch 1000] loss: 0.0012328613864178806
[Epoch 24, Batch 1100] loss: 0.001129936855518281
[Epoch 24, Batch 1200] loss: 0.003176462352485032
[Epoch 24, Batch 1300] loss: 0.004552414281333767
[Epoch 24, Batch 1400] loss: 0.009413332285801062
[Epoch 24, Batch 1500] loss: 0.0014543609944325908
[Epoch 24, Batch 1600] loss: 0.0038207824081928268
[Epoch 24, Batch 1700] loss: 0.003351088493368479
[Epoch 24, Batch 1800] loss: 0.0048827620885685975
[Epoch 24, Batch 1900] loss: 0.0015012342136827782
[Epoch 24, Batch 2000] loss: 0.00478764410099302
[Epoch 24, Batch 2100] loss: 0.003908179741331424
[Epoch 24, Batch 2200] loss: 0.00607678344500755
[Epoch 24, Batch 2300] loss: 0.004422366551412153
[Epoch 24, Batch 2400] loss: 0.00678393054687831
[Epoch 24, Batch 2500] loss: 0.004843961547830417
[Epoch 24, Batch 2600] loss: 0.0060727335870092245
[Epoch 24, Batch 2700] loss: 0.009320553586564416
[Epoch 24, Batch 2800] loss: 0.0034531185384980745
[Epoch 24, Batch 2900] loss: 0.009316188745545446
[Epoch 24, Batch 3000] loss: 0.003587361588554927
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9884
Overfitting: 0.0469
Fold 1 validation loss: 0.0469
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.302995026111603
[Epoch 1, Batch 200] loss: 2.2960890984535216
[Epoch 1, Batch 300] loss: 2.2857416129112242
[Epoch 1, Batch 400] loss: 2.2737267804145813
[Epoch 1, Batch 500] loss: 2.2439433455467226
[Epoch 1, Batch 600] loss: 2.174088702201843
[Epoch 1, Batch 700] loss: 1.8666088020801543
[Epoch 1, Batch 800] loss: 1.0482038366794586
[Epoch 1, Batch 900] loss: 0.6230127316713333
[Epoch 1, Batch 1000] loss: 0.5842268911004066
[Epoch 1, Batch 1100] loss: 0.4741083371639252
[Epoch 1, Batch 1200] loss: 0.49206767953932284
[Epoch 1, Batch 1300] loss: 0.36852006413042543
[Epoch 1, Batch 1400] loss: 0.34640440221875907
[Epoch 1, Batch 1500] loss: 0.3286847909912467
[Epoch 1, Batch 1600] loss: 0.2847058545425534
[Epoch 1, Batch 1700] loss: 0.24694604324176908
[Epoch 1, Batch 1800] loss: 0.2648057940322906
[Epoch 1, Batch 1900] loss: 0.2674972529709339
[Epoch 1, Batch 2000] loss: 0.23318649042397738
[Epoch 1, Batch 2100] loss: 0.24111369268037378
[Epoch 1, Batch 2200] loss: 0.24243728211149573
[Epoch 1, Batch 2300] loss: 0.22139738192781805
[Epoch 1, Batch 2400] loss: 0.19745112132281065
[Epoch 1, Batch 2500] loss: 0.1905256661772728
[Epoch 1, Batch 2600] loss: 0.1871617039386183
[Epoch 1, Batch 2700] loss: 0.21074037422426045
[Epoch 1, Batch 2800] loss: 0.16801181120797992
[Epoch 1, Batch 2900] loss: 0.18603555565699936
[Epoch 1, Batch 3000] loss: 0.1665654062340036
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1584
Validation Accuracy: 0.9509
Overfitting: 0.1584
Best model saved at epoch 1 with validation loss: 0.1584
[Epoch 2, Batch 100] loss: 0.16067618112079798
[Epoch 2, Batch 200] loss: 0.1548971025738865
[Epoch 2, Batch 300] loss: 0.14632706958800554
[Epoch 2, Batch 400] loss: 0.17578340300126002
[Epoch 2, Batch 500] loss: 0.1294308512378484
[Epoch 2, Batch 600] loss: 0.1250378759438172
[Epoch 2, Batch 700] loss: 0.12490401141345502
[Epoch 2, Batch 800] loss: 0.11323420645669102
[Epoch 2, Batch 900] loss: 0.11708090842003002
[Epoch 2, Batch 1000] loss: 0.12849171055946498
[Epoch 2, Batch 1100] loss: 0.122573561379686
[Epoch 2, Batch 1200] loss: 0.1369765526941046
[Epoch 2, Batch 1300] loss: 0.09586604709737002
[Epoch 2, Batch 1400] loss: 0.11439719254616648
[Epoch 2, Batch 1500] loss: 0.11969182278960944
[Epoch 2, Batch 1600] loss: 0.10263146003475412
[Epoch 2, Batch 1700] loss: 0.13512284971307964
[Epoch 2, Batch 1800] loss: 0.10582859464455396
[Epoch 2, Batch 1900] loss: 0.10989287531934679
[Epoch 2, Batch 2000] loss: 0.09242312053451314
[Epoch 2, Batch 2100] loss: 0.09594908422324806
[Epoch 2, Batch 2200] loss: 0.10139677464845591
[Epoch 2, Batch 2300] loss: 0.08765711387852207
[Epoch 2, Batch 2400] loss: 0.082354857835453
[Epoch 2, Batch 2500] loss: 0.09958168364944868
[Epoch 2, Batch 2600] loss: 0.12185628049308433
[Epoch 2, Batch 2700] loss: 0.09863111949758605
[Epoch 2, Batch 2800] loss: 0.10603315282147378
[Epoch 2, Batch 2900] loss: 0.08877409772016108
[Epoch 2, Batch 3000] loss: 0.08832076254067943
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1024
Validation Accuracy: 0.9674
Overfitting: 0.1024
Best model saved at epoch 2 with validation loss: 0.1024
[Epoch 3, Batch 100] loss: 0.09073263122001662
[Epoch 3, Batch 200] loss: 0.07066706916433758
[Epoch 3, Batch 300] loss: 0.09527565299300476
[Epoch 3, Batch 400] loss: 0.08539320077514276
[Epoch 3, Batch 500] loss: 0.08568452691310086
[Epoch 3, Batch 600] loss: 0.07041402475442737
[Epoch 3, Batch 700] loss: 0.0557757011288777
[Epoch 3, Batch 800] loss: 0.08196047992212697
[Epoch 3, Batch 900] loss: 0.10823840124066919
[Epoch 3, Batch 1000] loss: 0.07363644723547623
[Epoch 3, Batch 1100] loss: 0.06402816951507702
[Epoch 3, Batch 1200] loss: 0.09315798620460555
[Epoch 3, Batch 1300] loss: 0.09984246260952205
[Epoch 3, Batch 1400] loss: 0.06488246325403452
[Epoch 3, Batch 1500] loss: 0.07121467013668735
[Epoch 3, Batch 1600] loss: 0.06899985128606204
[Epoch 3, Batch 1700] loss: 0.07742230873933295
[Epoch 3, Batch 1800] loss: 0.06054414941754658
[Epoch 3, Batch 1900] loss: 0.07512163002393209
[Epoch 3, Batch 2000] loss: 0.05763359288801439
[Epoch 3, Batch 2100] loss: 0.09102452400373295
[Epoch 3, Batch 2200] loss: 0.07539393893210217
[Epoch 3, Batch 2300] loss: 0.08355374534614385
[Epoch 3, Batch 2400] loss: 0.07426347815431654
[Epoch 3, Batch 2500] loss: 0.06795672854292206
[Epoch 3, Batch 2600] loss: 0.0767333341226913
[Epoch 3, Batch 2700] loss: 0.0713231087080203
[Epoch 3, Batch 2800] loss: 0.07235500464623329
[Epoch 3, Batch 2900] loss: 0.08648182786069811
[Epoch 3, Batch 3000] loss: 0.0784026564960368
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0757
Validation Accuracy: 0.9772
Overfitting: 0.0757
Best model saved at epoch 3 with validation loss: 0.0757
[Epoch 4, Batch 100] loss: 0.07121088541345671
[Epoch 4, Batch 200] loss: 0.06189558624872007
[Epoch 4, Batch 300] loss: 0.04826654131291434
[Epoch 4, Batch 400] loss: 0.06056279367068782
[Epoch 4, Batch 500] loss: 0.06547721999580972
[Epoch 4, Batch 600] loss: 0.04469258080411237
[Epoch 4, Batch 700] loss: 0.07176458449976053
[Epoch 4, Batch 800] loss: 0.0701031304273056
[Epoch 4, Batch 900] loss: 0.05037390525045339
[Epoch 4, Batch 1000] loss: 0.06903880379046314
[Epoch 4, Batch 1100] loss: 0.05548959653649945
[Epoch 4, Batch 1200] loss: 0.06904528374318034
[Epoch 4, Batch 1300] loss: 0.0551294699270511
[Epoch 4, Batch 1400] loss: 0.0461660570136155
[Epoch 4, Batch 1500] loss: 0.05741621829103678
[Epoch 4, Batch 1600] loss: 0.06292454035195988
[Epoch 4, Batch 1700] loss: 0.0594839226451586
[Epoch 4, Batch 1800] loss: 0.04952263777493499
[Epoch 4, Batch 1900] loss: 0.07168779183062725
[Epoch 4, Batch 2000] loss: 0.056903191274032
[Epoch 4, Batch 2100] loss: 0.045997658402775414
[Epoch 4, Batch 2200] loss: 0.06721031795081217
[Epoch 4, Batch 2300] loss: 0.060461005882243624
[Epoch 4, Batch 2400] loss: 0.060653160517686044
[Epoch 4, Batch 2500] loss: 0.054088642889983024
[Epoch 4, Batch 2600] loss: 0.05256852449150756
[Epoch 4, Batch 2700] loss: 0.07070632316463162
[Epoch 4, Batch 2800] loss: 0.06146101813239511
[Epoch 4, Batch 2900] loss: 0.04760533803899307
[Epoch 4, Batch 3000] loss: 0.07877883936453145
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0708
Validation Accuracy: 0.9789
Overfitting: 0.0708
Best model saved at epoch 4 with validation loss: 0.0708
[Epoch 5, Batch 100] loss: 0.04574315984849818
[Epoch 5, Batch 200] loss: 0.046259087937360166
[Epoch 5, Batch 300] loss: 0.058793882535246665
[Epoch 5, Batch 400] loss: 0.046301044531865045
[Epoch 5, Batch 500] loss: 0.05844567886990262
[Epoch 5, Batch 600] loss: 0.04373903206287651
[Epoch 5, Batch 700] loss: 0.03962883138738107
[Epoch 5, Batch 800] loss: 0.04806676680978853
[Epoch 5, Batch 900] loss: 0.046842612161999565
[Epoch 5, Batch 1000] loss: 0.04506945387707674
[Epoch 5, Batch 1100] loss: 0.06447063136700308
[Epoch 5, Batch 1200] loss: 0.04997477376135066
[Epoch 5, Batch 1300] loss: 0.05045349616266322
[Epoch 5, Batch 1400] loss: 0.05109381041373126
[Epoch 5, Batch 1500] loss: 0.05056259859993588
[Epoch 5, Batch 1600] loss: 0.06210951393237338
[Epoch 5, Batch 1700] loss: 0.04851114842284005
[Epoch 5, Batch 1800] loss: 0.05458445279757143
[Epoch 5, Batch 1900] loss: 0.0536064026679378
[Epoch 5, Batch 2000] loss: 0.052091437303461136
[Epoch 5, Batch 2100] loss: 0.05655917506781407
[Epoch 5, Batch 2200] loss: 0.06350019020552282
[Epoch 5, Batch 2300] loss: 0.042862175266782286
[Epoch 5, Batch 2400] loss: 0.04084618626831798
[Epoch 5, Batch 2500] loss: 0.05118316706793848
[Epoch 5, Batch 2600] loss: 0.0413567534822505
[Epoch 5, Batch 2700] loss: 0.06384040821692906
[Epoch 5, Batch 2800] loss: 0.049068434087676
[Epoch 5, Batch 2900] loss: 0.03511575319760595
[Epoch 5, Batch 3000] loss: 0.03645850292261457
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0614
Validation Accuracy: 0.9816
Overfitting: 0.0614
Best model saved at epoch 5 with validation loss: 0.0614
[Epoch 6, Batch 100] loss: 0.03968692652197205
[Epoch 6, Batch 200] loss: 0.05425983544468181
[Epoch 6, Batch 300] loss: 0.033989704601699484
[Epoch 6, Batch 400] loss: 0.03759817811602261
[Epoch 6, Batch 500] loss: 0.031707046582159816
[Epoch 6, Batch 600] loss: 0.048056162983994
[Epoch 6, Batch 700] loss: 0.044905005987966436
[Epoch 6, Batch 800] loss: 0.03164520751379314
[Epoch 6, Batch 900] loss: 0.031295622288307644
[Epoch 6, Batch 1000] loss: 0.03892395162518369
[Epoch 6, Batch 1100] loss: 0.044662569733045526
[Epoch 6, Batch 1200] loss: 0.04594779634906445
[Epoch 6, Batch 1300] loss: 0.05585645431419835
[Epoch 6, Batch 1400] loss: 0.03872324901734828
[Epoch 6, Batch 1500] loss: 0.03304422476416221
[Epoch 6, Batch 1600] loss: 0.042344852250244
[Epoch 6, Batch 1700] loss: 0.03561987243680051
[Epoch 6, Batch 1800] loss: 0.03811533925399999
[Epoch 6, Batch 1900] loss: 0.032614125249674546
[Epoch 6, Batch 2000] loss: 0.03349220391181006
[Epoch 6, Batch 2100] loss: 0.04744064559155959
[Epoch 6, Batch 2200] loss: 0.05992369563435204
[Epoch 6, Batch 2300] loss: 0.04279674736346351
[Epoch 6, Batch 2400] loss: 0.04596435473067686
[Epoch 6, Batch 2500] loss: 0.04440894319850486
[Epoch 6, Batch 2600] loss: 0.04355420075386064
[Epoch 6, Batch 2700] loss: 0.05096943682525307
[Epoch 6, Batch 2800] loss: 0.05572965775296325
[Epoch 6, Batch 2900] loss: 0.046457996069220825
[Epoch 6, Batch 3000] loss: 0.03749905018834397
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0638
Validation Accuracy: 0.9816
Overfitting: 0.0638
[Epoch 7, Batch 100] loss: 0.02970990449626697
[Epoch 7, Batch 200] loss: 0.04140377566131065
[Epoch 7, Batch 300] loss: 0.032226526440063026
[Epoch 7, Batch 400] loss: 0.034809431318135464
[Epoch 7, Batch 500] loss: 0.029515422846452567
[Epoch 7, Batch 600] loss: 0.041093378602527084
[Epoch 7, Batch 700] loss: 0.05283713560813339
[Epoch 7, Batch 800] loss: 0.04123328572721221
[Epoch 7, Batch 900] loss: 0.044470842925366016
[Epoch 7, Batch 1000] loss: 0.022773394374817145
[Epoch 7, Batch 1100] loss: 0.03665585078502773
[Epoch 7, Batch 1200] loss: 0.04043001816920878
[Epoch 7, Batch 1300] loss: 0.033039061298477466
[Epoch 7, Batch 1400] loss: 0.03191822521359427
[Epoch 7, Batch 1500] loss: 0.03436642998502066
[Epoch 7, Batch 1600] loss: 0.025509024648636115
[Epoch 7, Batch 1700] loss: 0.02539989335091377
[Epoch 7, Batch 1800] loss: 0.04885117758494743
[Epoch 7, Batch 1900] loss: 0.034988456496794246
[Epoch 7, Batch 2000] loss: 0.03943222650632379
[Epoch 7, Batch 2100] loss: 0.03295530770978075
[Epoch 7, Batch 2200] loss: 0.04136597971184528
[Epoch 7, Batch 2300] loss: 0.04306298458279343
[Epoch 7, Batch 2400] loss: 0.039113895075715846
[Epoch 7, Batch 2500] loss: 0.03463217516124132
[Epoch 7, Batch 2600] loss: 0.050837757703848185
[Epoch 7, Batch 2700] loss: 0.04198468550981488
[Epoch 7, Batch 2800] loss: 0.030811245753720868
[Epoch 7, Batch 2900] loss: 0.03391214879553445
[Epoch 7, Batch 3000] loss: 0.03202886843297165
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0578
Validation Accuracy: 0.9817
Overfitting: 0.0578
Best model saved at epoch 7 with validation loss: 0.0578
[Epoch 8, Batch 100] loss: 0.03159155179775553
[Epoch 8, Batch 200] loss: 0.02953893534722738
[Epoch 8, Batch 300] loss: 0.03635482071636943
[Epoch 8, Batch 400] loss: 0.023626602491858648
[Epoch 8, Batch 500] loss: 0.030766826110339027
[Epoch 8, Batch 600] loss: 0.040481504845956806
[Epoch 8, Batch 700] loss: 0.03140249909614795
[Epoch 8, Batch 800] loss: 0.03309447806008393
[Epoch 8, Batch 900] loss: 0.030044584678980756
[Epoch 8, Batch 1000] loss: 0.031758141765749315
[Epoch 8, Batch 1100] loss: 0.036596259267971616
[Epoch 8, Batch 1200] loss: 0.03386624003444012
[Epoch 8, Batch 1300] loss: 0.052759901156823615
[Epoch 8, Batch 1400] loss: 0.02698606546036899
[Epoch 8, Batch 1500] loss: 0.02543127231503604
[Epoch 8, Batch 1600] loss: 0.018710836380778348
[Epoch 8, Batch 1700] loss: 0.0371561209900392
[Epoch 8, Batch 1800] loss: 0.030417723691280117
[Epoch 8, Batch 1900] loss: 0.02888565962493885
[Epoch 8, Batch 2000] loss: 0.029018410256976494
[Epoch 8, Batch 2100] loss: 0.02387807564056857
[Epoch 8, Batch 2200] loss: 0.033195321110542866
[Epoch 8, Batch 2300] loss: 0.03389689885167172
[Epoch 8, Batch 2400] loss: 0.034903194400540086
[Epoch 8, Batch 2500] loss: 0.025896005115646402
[Epoch 8, Batch 2600] loss: 0.03486382851900999
[Epoch 8, Batch 2700] loss: 0.024075335498928326
[Epoch 8, Batch 2800] loss: 0.02540670728776604
[Epoch 8, Batch 2900] loss: 0.05770470708230278
[Epoch 8, Batch 3000] loss: 0.02052255722985137
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9846
Overfitting: 0.0533
Best model saved at epoch 8 with validation loss: 0.0533
[Epoch 9, Batch 100] loss: 0.03196158188671688
[Epoch 9, Batch 200] loss: 0.023595554506173358
[Epoch 9, Batch 300] loss: 0.02421515811714926
[Epoch 9, Batch 400] loss: 0.027044161065623483
[Epoch 9, Batch 500] loss: 0.027298836330373888
[Epoch 9, Batch 600] loss: 0.02936368602408038
[Epoch 9, Batch 700] loss: 0.031175367219984765
[Epoch 9, Batch 800] loss: 0.019624882721400352
[Epoch 9, Batch 900] loss: 0.020673132608499144
[Epoch 9, Batch 1000] loss: 0.02165187372782384
[Epoch 9, Batch 1100] loss: 0.029116782074706863
[Epoch 9, Batch 1200] loss: 0.03177402310837351
[Epoch 9, Batch 1300] loss: 0.03255219937520451
[Epoch 9, Batch 1400] loss: 0.020141224372928264
[Epoch 9, Batch 1500] loss: 0.026747376052371694
[Epoch 9, Batch 1600] loss: 0.029987058347614948
[Epoch 9, Batch 1700] loss: 0.01874834766751519
[Epoch 9, Batch 1800] loss: 0.03283358140230121
[Epoch 9, Batch 1900] loss: 0.04104847960545158
[Epoch 9, Batch 2000] loss: 0.033002212245046396
[Epoch 9, Batch 2100] loss: 0.038746816553466484
[Epoch 9, Batch 2200] loss: 0.025589350136324355
[Epoch 9, Batch 2300] loss: 0.023935798820020865
[Epoch 9, Batch 2400] loss: 0.02027242940494034
[Epoch 9, Batch 2500] loss: 0.02530796050305071
[Epoch 9, Batch 2600] loss: 0.020027914920028707
[Epoch 9, Batch 2700] loss: 0.023396978235177814
[Epoch 9, Batch 2800] loss: 0.02979680327633105
[Epoch 9, Batch 2900] loss: 0.02890175101609202
[Epoch 9, Batch 3000] loss: 0.035349676839759925
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9838
Overfitting: 0.0561
[Epoch 10, Batch 100] loss: 0.020948223570958362
[Epoch 10, Batch 200] loss: 0.016301032197734457
[Epoch 10, Batch 300] loss: 0.02018366884571151
[Epoch 10, Batch 400] loss: 0.0211312012597773
[Epoch 10, Batch 500] loss: 0.015239236571760557
[Epoch 10, Batch 600] loss: 0.041155616964533695
[Epoch 10, Batch 700] loss: 0.031120624056529777
[Epoch 10, Batch 800] loss: 0.023104169358994113
[Epoch 10, Batch 900] loss: 0.023236284834856635
[Epoch 10, Batch 1000] loss: 0.03381475161004346
[Epoch 10, Batch 1100] loss: 0.016093076120596378
[Epoch 10, Batch 1200] loss: 0.018120695690013237
[Epoch 10, Batch 1300] loss: 0.03143965350122016
[Epoch 10, Batch 1400] loss: 0.028987631799391237
[Epoch 10, Batch 1500] loss: 0.03045948916958878
[Epoch 10, Batch 1600] loss: 0.02840797270193434
[Epoch 10, Batch 1700] loss: 0.019354881211693282
[Epoch 10, Batch 1800] loss: 0.01994188888336794
[Epoch 10, Batch 1900] loss: 0.02744977214089886
[Epoch 10, Batch 2000] loss: 0.03220114018986351
[Epoch 10, Batch 2100] loss: 0.03500726877973648
[Epoch 10, Batch 2200] loss: 0.028337933376842556
[Epoch 10, Batch 2300] loss: 0.03694328806144767
[Epoch 10, Batch 2400] loss: 0.022324211636369
[Epoch 10, Batch 2500] loss: 0.024071005686237185
[Epoch 10, Batch 2600] loss: 0.020674678193936414
[Epoch 10, Batch 2700] loss: 0.017416925338984583
[Epoch 10, Batch 2800] loss: 0.02740473136116634
[Epoch 10, Batch 2900] loss: 0.02632659463051823
[Epoch 10, Batch 3000] loss: 0.018321075096610004
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9847
Overfitting: 0.0548
[Epoch 11, Batch 100] loss: 0.01994307557863067
[Epoch 11, Batch 200] loss: 0.01149838863624609
[Epoch 11, Batch 300] loss: 0.023112244827498216
[Epoch 11, Batch 400] loss: 0.034865468845746365
[Epoch 11, Batch 500] loss: 0.021383658347949676
[Epoch 11, Batch 600] loss: 0.01673288884514477
[Epoch 11, Batch 700] loss: 0.018002424709011394
[Epoch 11, Batch 800] loss: 0.021943421323521763
[Epoch 11, Batch 900] loss: 0.012382616607719683
[Epoch 11, Batch 1000] loss: 0.007792043210938573
[Epoch 11, Batch 1100] loss: 0.008996996014957404
[Epoch 11, Batch 1200] loss: 0.02120843617179162
[Epoch 11, Batch 1300] loss: 0.0268524514782257
[Epoch 11, Batch 1400] loss: 0.01969842614074878
[Epoch 11, Batch 1500] loss: 0.02038651319056953
[Epoch 11, Batch 1600] loss: 0.011405303668998385
[Epoch 11, Batch 1700] loss: 0.01642685700686343
[Epoch 11, Batch 1800] loss: 0.04249079153782077
[Epoch 11, Batch 1900] loss: 0.017419474408670796
[Epoch 11, Batch 2000] loss: 0.01720592711280915
[Epoch 11, Batch 2100] loss: 0.03418993486971886
[Epoch 11, Batch 2200] loss: 0.020133530327075277
[Epoch 11, Batch 2300] loss: 0.02066289459777181
[Epoch 11, Batch 2400] loss: 0.02176910038528149
[Epoch 11, Batch 2500] loss: 0.017046141021710357
[Epoch 11, Batch 2600] loss: 0.02022847141834063
[Epoch 11, Batch 2700] loss: 0.02122538037281629
[Epoch 11, Batch 2800] loss: 0.014848930954613024
[Epoch 11, Batch 2900] loss: 0.03428269120166078
[Epoch 11, Batch 3000] loss: 0.03391371868947317
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9858
Overfitting: 0.0520
Best model saved at epoch 11 with validation loss: 0.0520
[Epoch 12, Batch 100] loss: 0.014167921756088617
[Epoch 12, Batch 200] loss: 0.019397460349064203
[Epoch 12, Batch 300] loss: 0.01650634761324909
[Epoch 12, Batch 400] loss: 0.016120322049828245
[Epoch 12, Batch 500] loss: 0.00970912231314287
[Epoch 12, Batch 600] loss: 0.017652059164902312
[Epoch 12, Batch 700] loss: 0.014243689712293417
[Epoch 12, Batch 800] loss: 0.02135368044677307
[Epoch 12, Batch 900] loss: 0.021203322382812074
[Epoch 12, Batch 1000] loss: 0.012710730176731886
[Epoch 12, Batch 1100] loss: 0.01853187841579711
[Epoch 12, Batch 1200] loss: 0.02101485342302112
[Epoch 12, Batch 1300] loss: 0.00840941853577533
[Epoch 12, Batch 1400] loss: 0.01822866619851993
[Epoch 12, Batch 1500] loss: 0.016980347437420277
[Epoch 12, Batch 1600] loss: 0.018210166060562187
[Epoch 12, Batch 1700] loss: 0.020803458987193154
[Epoch 12, Batch 1800] loss: 0.01739614910653472
[Epoch 12, Batch 1900] loss: 0.02799279218301308
[Epoch 12, Batch 2000] loss: 0.018977669160813095
[Epoch 12, Batch 2100] loss: 0.031112670091024485
[Epoch 12, Batch 2200] loss: 0.017902772613670095
[Epoch 12, Batch 2300] loss: 0.016118628744352465
[Epoch 12, Batch 2400] loss: 0.029478257717346423
[Epoch 12, Batch 2500] loss: 0.01384232681702997
[Epoch 12, Batch 2600] loss: 0.01976917164945917
[Epoch 12, Batch 2700] loss: 0.023232860740499746
[Epoch 12, Batch 2800] loss: 0.03175275485577003
[Epoch 12, Batch 2900] loss: 0.015901943975295582
[Epoch 12, Batch 3000] loss: 0.022312152534141205
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9855
Overfitting: 0.0532
[Epoch 13, Batch 100] loss: 0.015499460249702678
[Epoch 13, Batch 200] loss: 0.011049252726370468
[Epoch 13, Batch 300] loss: 0.010320831846711372
[Epoch 13, Batch 400] loss: 0.015016098468677228
[Epoch 13, Batch 500] loss: 0.016984592433545914
[Epoch 13, Batch 600] loss: 0.01069134016503085
[Epoch 13, Batch 700] loss: 0.019763104927696985
[Epoch 13, Batch 800] loss: 0.020602520722823103
[Epoch 13, Batch 900] loss: 0.029171299996596643
[Epoch 13, Batch 1000] loss: 0.015946208429377294
[Epoch 13, Batch 1100] loss: 0.014677283015043941
[Epoch 13, Batch 1200] loss: 0.014026599949684169
[Epoch 13, Batch 1300] loss: 0.01612011020013597
[Epoch 13, Batch 1400] loss: 0.017641329798098012
[Epoch 13, Batch 1500] loss: 0.013454193058387319
[Epoch 13, Batch 1600] loss: 0.016006266598742512
[Epoch 13, Batch 1700] loss: 0.013584091258135231
[Epoch 13, Batch 1800] loss: 0.01629472248703678
[Epoch 13, Batch 1900] loss: 0.024890243267891493
[Epoch 13, Batch 2000] loss: 0.022061171579580333
[Epoch 13, Batch 2100] loss: 0.014201475156150991
[Epoch 13, Batch 2200] loss: 0.018706637314971887
[Epoch 13, Batch 2300] loss: 0.013330156977735897
[Epoch 13, Batch 2400] loss: 0.008271738923176598
[Epoch 13, Batch 2500] loss: 0.020993780763747055
[Epoch 13, Batch 2600] loss: 0.013084308603920363
[Epoch 13, Batch 2700] loss: 0.0213807244157033
[Epoch 13, Batch 2800] loss: 0.015202003532413072
[Epoch 13, Batch 2900] loss: 0.020593960215574043
[Epoch 13, Batch 3000] loss: 0.015097410910493636
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9865
Overfitting: 0.0496
Best model saved at epoch 13 with validation loss: 0.0496
[Epoch 14, Batch 100] loss: 0.008334786473010353
[Epoch 14, Batch 200] loss: 0.01665045086099781
[Epoch 14, Batch 300] loss: 0.025420197868043032
[Epoch 14, Batch 400] loss: 0.016914123737478803
[Epoch 14, Batch 500] loss: 0.013686310875418712
[Epoch 14, Batch 600] loss: 0.023613838615601707
[Epoch 14, Batch 700] loss: 0.015993938063020324
[Epoch 14, Batch 800] loss: 0.01815434980157079
[Epoch 14, Batch 900] loss: 0.01479129339029896
[Epoch 14, Batch 1000] loss: 0.01115808216174628
[Epoch 14, Batch 1100] loss: 0.010271608057773846
[Epoch 14, Batch 1200] loss: 0.010196673701721011
[Epoch 14, Batch 1300] loss: 0.02146505067947146
[Epoch 14, Batch 1400] loss: 0.012239598117448623
[Epoch 14, Batch 1500] loss: 0.011711918559281003
[Epoch 14, Batch 1600] loss: 0.011938942729066183
[Epoch 14, Batch 1700] loss: 0.010217808157949548
[Epoch 14, Batch 1800] loss: 0.01152575906166021
[Epoch 14, Batch 1900] loss: 0.021263652764755534
[Epoch 14, Batch 2000] loss: 0.015159346058426308
[Epoch 14, Batch 2100] loss: 0.012234123734288005
[Epoch 14, Batch 2200] loss: 0.015229674829729447
[Epoch 14, Batch 2300] loss: 0.01650055476480702
[Epoch 14, Batch 2400] loss: 0.012750600318368015
[Epoch 14, Batch 2500] loss: 0.012701835418374685
[Epoch 14, Batch 2600] loss: 0.014622688209055924
[Epoch 14, Batch 2700] loss: 0.025267693852138107
[Epoch 14, Batch 2800] loss: 0.012517171990439238
[Epoch 14, Batch 2900] loss: 0.01605829940865078
[Epoch 14, Batch 3000] loss: 0.01279703172049267
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9862
Overfitting: 0.0509
[Epoch 15, Batch 100] loss: 0.010957164810297399
[Epoch 15, Batch 200] loss: 0.011721858559340034
[Epoch 15, Batch 300] loss: 0.009067900865538832
[Epoch 15, Batch 400] loss: 0.005979695627133879
[Epoch 15, Batch 500] loss: 0.008404921698383987
[Epoch 15, Batch 600] loss: 0.01259646586675899
[Epoch 15, Batch 700] loss: 0.004576183286717423
[Epoch 15, Batch 800] loss: 0.018822270758355443
[Epoch 15, Batch 900] loss: 0.012674689379873599
[Epoch 15, Batch 1000] loss: 0.014897426961069868
[Epoch 15, Batch 1100] loss: 0.009694026459173983
[Epoch 15, Batch 1200] loss: 0.011388173576933695
[Epoch 15, Batch 1300] loss: 0.02099268083678908
[Epoch 15, Batch 1400] loss: 0.01619399059964053
[Epoch 15, Batch 1500] loss: 0.02635184704216954
[Epoch 15, Batch 1600] loss: 0.01670841544813811
[Epoch 15, Batch 1700] loss: 0.010997386073431698
[Epoch 15, Batch 1800] loss: 0.011581896304123802
[Epoch 15, Batch 1900] loss: 0.009075047722762974
[Epoch 15, Batch 2000] loss: 0.013498162006203528
[Epoch 15, Batch 2100] loss: 0.016263799495459353
[Epoch 15, Batch 2200] loss: 0.009651443324710272
[Epoch 15, Batch 2300] loss: 0.017896692350168452
[Epoch 15, Batch 2400] loss: 0.015539326808957412
[Epoch 15, Batch 2500] loss: 0.012512610151025
[Epoch 15, Batch 2600] loss: 0.014326461564814963
[Epoch 15, Batch 2700] loss: 0.005639352742964548
[Epoch 15, Batch 2800] loss: 0.006250814882355371
[Epoch 15, Batch 2900] loss: 0.014608267493567837
[Epoch 15, Batch 3000] loss: 0.01653932046173395
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9864
Overfitting: 0.0496
[Epoch 16, Batch 100] loss: 0.0048870981923937505
[Epoch 16, Batch 200] loss: 0.004800250096996024
[Epoch 16, Batch 300] loss: 0.007730688904398448
[Epoch 16, Batch 400] loss: 0.011248621831609852
[Epoch 16, Batch 500] loss: 0.01701943017875692
[Epoch 16, Batch 600] loss: 0.013731371393832887
[Epoch 16, Batch 700] loss: 0.007990782215279069
[Epoch 16, Batch 800] loss: 0.0064560706006068355
[Epoch 16, Batch 900] loss: 0.007990559542661231
[Epoch 16, Batch 1000] loss: 0.011129390034129756
[Epoch 16, Batch 1100] loss: 0.012421895611596482
[Epoch 16, Batch 1200] loss: 0.017622572988557295
[Epoch 16, Batch 1300] loss: 0.011878816189337157
[Epoch 16, Batch 1400] loss: 0.015978740766431656
[Epoch 16, Batch 1500] loss: 0.017011855418313643
[Epoch 16, Batch 1600] loss: 0.006863862245209021
[Epoch 16, Batch 1700] loss: 0.016694900451491322
[Epoch 16, Batch 1800] loss: 0.008700567640407825
[Epoch 16, Batch 1900] loss: 0.008465798128086136
[Epoch 16, Batch 2000] loss: 0.007249338897945563
[Epoch 16, Batch 2100] loss: 0.020991904400239035
[Epoch 16, Batch 2200] loss: 0.012181697339383391
[Epoch 16, Batch 2300] loss: 0.014019700879425728
[Epoch 16, Batch 2400] loss: 0.011005647629933718
[Epoch 16, Batch 2500] loss: 0.0200662557443502
[Epoch 16, Batch 2600] loss: 0.012648736630389977
[Epoch 16, Batch 2700] loss: 0.01820511587652163
[Epoch 16, Batch 2800] loss: 0.007531894064313747
[Epoch 16, Batch 2900] loss: 0.01353530401770513
[Epoch 16, Batch 3000] loss: 0.006234961898380789
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9868
Overfitting: 0.0538
[Epoch 17, Batch 100] loss: 0.008091550633935185
[Epoch 17, Batch 200] loss: 0.007693369655680726
[Epoch 17, Batch 300] loss: 0.015275670583614556
[Epoch 17, Batch 400] loss: 0.007387163298167252
[Epoch 17, Batch 500] loss: 0.008576948625391196
[Epoch 17, Batch 600] loss: 0.008095561069467294
[Epoch 17, Batch 700] loss: 0.014450080245615027
[Epoch 17, Batch 800] loss: 0.009120564894674317
[Epoch 17, Batch 900] loss: 0.013589686378018086
[Epoch 17, Batch 1000] loss: 0.01419523879696044
[Epoch 17, Batch 1100] loss: 0.008971577009174326
[Epoch 17, Batch 1200] loss: 0.011040219929309387
[Epoch 17, Batch 1300] loss: 0.01702305743259785
[Epoch 17, Batch 1400] loss: 0.010270793080867407
[Epoch 17, Batch 1500] loss: 0.00964753606551767
[Epoch 17, Batch 1600] loss: 0.012150120145711298
[Epoch 17, Batch 1700] loss: 0.009555980726090638
[Epoch 17, Batch 1800] loss: 0.009357293342502545
[Epoch 17, Batch 1900] loss: 0.009155724150937204
[Epoch 17, Batch 2000] loss: 0.00648264107326213
[Epoch 17, Batch 2100] loss: 0.00912834450964965
[Epoch 17, Batch 2200] loss: 0.011963387485657222
[Epoch 17, Batch 2300] loss: 0.01040898530090999
[Epoch 17, Batch 2400] loss: 0.010385135711403563
[Epoch 17, Batch 2500] loss: 0.014328892418270699
[Epoch 17, Batch 2600] loss: 0.010332500160302516
[Epoch 17, Batch 2700] loss: 0.015687030676926953
[Epoch 17, Batch 2800] loss: 0.0070464359403013075
[Epoch 17, Batch 2900] loss: 0.005331519895971724
[Epoch 17, Batch 3000] loss: 0.016765403645641185
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9855
Overfitting: 0.0552
[Epoch 18, Batch 100] loss: 0.010997986939137262
[Epoch 18, Batch 200] loss: 0.009194425119533207
[Epoch 18, Batch 300] loss: 0.007778006608200485
[Epoch 18, Batch 400] loss: 0.006778097323867769
[Epoch 18, Batch 500] loss: 0.00489227968295836
[Epoch 18, Batch 600] loss: 0.022222722823062212
[Epoch 18, Batch 700] loss: 0.008109461903172814
[Epoch 18, Batch 800] loss: 0.013157945788625511
[Epoch 18, Batch 900] loss: 0.00999656920525922
[Epoch 18, Batch 1000] loss: 0.003372670118574206
[Epoch 18, Batch 1100] loss: 0.006562001871998291
[Epoch 18, Batch 1200] loss: 0.0046505767972053035
[Epoch 18, Batch 1300] loss: 0.005333022110607999
[Epoch 18, Batch 1400] loss: 0.00939510261687019
[Epoch 18, Batch 1500] loss: 0.00585256031629342
[Epoch 18, Batch 1600] loss: 0.006248946822197467
[Epoch 18, Batch 1700] loss: 0.007391744711183037
[Epoch 18, Batch 1800] loss: 0.004530685213285324
[Epoch 18, Batch 1900] loss: 0.009476252548144543
[Epoch 18, Batch 2000] loss: 0.017312433309268727
[Epoch 18, Batch 2100] loss: 0.0106604156429853
[Epoch 18, Batch 2200] loss: 0.0072164626560743276
[Epoch 18, Batch 2300] loss: 0.010822845592756494
[Epoch 18, Batch 2400] loss: 0.009266697424516223
[Epoch 18, Batch 2500] loss: 0.011864118162802697
[Epoch 18, Batch 2600] loss: 0.010229840377101028
[Epoch 18, Batch 2700] loss: 0.005423177891218529
[Epoch 18, Batch 2800] loss: 0.006951341623494045
[Epoch 18, Batch 2900] loss: 0.011998742941432283
[Epoch 18, Batch 3000] loss: 0.005134991263360576
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0627
Validation Accuracy: 0.9854
Overfitting: 0.0627
[Epoch 19, Batch 100] loss: 0.0062718475569090515
[Epoch 19, Batch 200] loss: 0.006717829586723383
[Epoch 19, Batch 300] loss: 0.0067202462921000005
[Epoch 19, Batch 400] loss: 0.004806308657302907
[Epoch 19, Batch 500] loss: 0.004109330915534884
[Epoch 19, Batch 600] loss: 0.007093482048578608
[Epoch 19, Batch 700] loss: 0.005102660664978203
[Epoch 19, Batch 800] loss: 0.014336458021014097
[Epoch 19, Batch 900] loss: 0.008688808779684223
[Epoch 19, Batch 1000] loss: 0.006673100916004842
[Epoch 19, Batch 1100] loss: 0.008696859008377942
[Epoch 19, Batch 1200] loss: 0.010641039833096784
[Epoch 19, Batch 1300] loss: 0.0072543854855757674
[Epoch 19, Batch 1400] loss: 0.012745202729579432
[Epoch 19, Batch 1500] loss: 0.004636999233296706
[Epoch 19, Batch 1600] loss: 0.006743730761518236
[Epoch 19, Batch 1700] loss: 0.007187535146988467
[Epoch 19, Batch 1800] loss: 0.0065363999490455175
[Epoch 19, Batch 1900] loss: 0.015116547674599587
[Epoch 19, Batch 2000] loss: 0.004254478985849346
[Epoch 19, Batch 2100] loss: 0.010645039408881302
[Epoch 19, Batch 2200] loss: 0.007501911011506763
[Epoch 19, Batch 2300] loss: 0.006739256577511696
[Epoch 19, Batch 2400] loss: 0.0056276873299384534
[Epoch 19, Batch 2500] loss: 0.006372812726999655
[Epoch 19, Batch 2600] loss: 0.008631594947828489
[Epoch 19, Batch 2700] loss: 0.01783824321263637
[Epoch 19, Batch 2800] loss: 0.013571182659034094
[Epoch 19, Batch 2900] loss: 0.00874405188230412
[Epoch 19, Batch 3000] loss: 0.01523045160233778
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0604
Validation Accuracy: 0.9849
Overfitting: 0.0604
[Epoch 20, Batch 100] loss: 0.005791361351784871
[Epoch 20, Batch 200] loss: 0.010939476691805793
[Epoch 20, Batch 300] loss: 0.007769243540378739
[Epoch 20, Batch 400] loss: 0.011670970253724135
[Epoch 20, Batch 500] loss: 0.007256718622047628
[Epoch 20, Batch 600] loss: 0.011829596574855258
[Epoch 20, Batch 700] loss: 0.00780932080269622
[Epoch 20, Batch 800] loss: 0.006261088028004451
[Epoch 20, Batch 900] loss: 0.006577253057992038
[Epoch 20, Batch 1000] loss: 0.0050575779289010825
[Epoch 20, Batch 1100] loss: 0.00337936764515689
[Epoch 20, Batch 1200] loss: 0.005114578318052736
[Epoch 20, Batch 1300] loss: 0.010229876595712995
[Epoch 20, Batch 1400] loss: 0.0075668155045104865
[Epoch 20, Batch 1500] loss: 0.013976329137107087
[Epoch 20, Batch 1600] loss: 0.004327744259155679
[Epoch 20, Batch 1700] loss: 0.005755392443935534
[Epoch 20, Batch 1800] loss: 0.005294777066044389
[Epoch 20, Batch 1900] loss: 0.0032378596940088756
[Epoch 20, Batch 2000] loss: 0.004767276561892686
[Epoch 20, Batch 2100] loss: 0.004503157290025683
[Epoch 20, Batch 2200] loss: 0.00512272249558805
[Epoch 20, Batch 2300] loss: 0.004843722678757558
[Epoch 20, Batch 2400] loss: 0.007985760028657297
[Epoch 20, Batch 2500] loss: 0.009767062111313863
[Epoch 20, Batch 2600] loss: 0.007199540278543281
[Epoch 20, Batch 2700] loss: 0.011426034331082064
[Epoch 20, Batch 2800] loss: 0.0057748449768428144
[Epoch 20, Batch 2900] loss: 0.00935321327217025
[Epoch 20, Batch 3000] loss: 0.004712477380389828
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9872
Overfitting: 0.0502
[Epoch 21, Batch 100] loss: 0.0039020055755281647
[Epoch 21, Batch 200] loss: 0.006922209839599418
[Epoch 21, Batch 300] loss: 0.006041332657644034
[Epoch 21, Batch 400] loss: 0.004300287817140997
[Epoch 21, Batch 500] loss: 0.005222210126811433
[Epoch 21, Batch 600] loss: 0.010198145602143995
[Epoch 21, Batch 700] loss: 0.00619838682576983
[Epoch 21, Batch 800] loss: 0.005250873385955401
[Epoch 21, Batch 900] loss: 0.004327648576705769
[Epoch 21, Batch 1000] loss: 0.007239126363443802
[Epoch 21, Batch 1100] loss: 0.009808892046712571
[Epoch 21, Batch 1200] loss: 0.006445088302918975
[Epoch 21, Batch 1300] loss: 0.008398832143867593
[Epoch 21, Batch 1400] loss: 0.00435116496797491
[Epoch 21, Batch 1500] loss: 0.008430064181109174
[Epoch 21, Batch 1600] loss: 0.00941087121154851
[Epoch 21, Batch 1700] loss: 0.008133916165916162
[Epoch 21, Batch 1800] loss: 0.0026052914558067643
[Epoch 21, Batch 1900] loss: 0.007389046163840476
[Epoch 21, Batch 2000] loss: 0.00903963662690785
[Epoch 21, Batch 2100] loss: 0.004240371439379942
[Epoch 21, Batch 2200] loss: 0.0081932893994599
[Epoch 21, Batch 2300] loss: 0.007441671717456302
[Epoch 21, Batch 2400] loss: 0.00789184880216908
[Epoch 21, Batch 2500] loss: 0.005333604989268679
[Epoch 21, Batch 2600] loss: 0.002294065068779787
[Epoch 21, Batch 2700] loss: 0.01729470127743298
[Epoch 21, Batch 2800] loss: 0.006976873056962063
[Epoch 21, Batch 2900] loss: 0.005644432530532413
[Epoch 21, Batch 3000] loss: 0.015304610707974007
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0571
Validation Accuracy: 0.9858
Overfitting: 0.0571
[Epoch 22, Batch 100] loss: 0.004569676942930982
[Epoch 22, Batch 200] loss: 0.013304534167384646
[Epoch 22, Batch 300] loss: 0.010896884058388423
[Epoch 22, Batch 400] loss: 0.007609597772950565
[Epoch 22, Batch 500] loss: 0.003015298297859772
[Epoch 22, Batch 600] loss: 0.0031186671225486864
[Epoch 22, Batch 700] loss: 0.0060101295595427475
[Epoch 22, Batch 800] loss: 0.0022904048822374535
[Epoch 22, Batch 900] loss: 0.0043171495210572175
[Epoch 22, Batch 1000] loss: 0.0026758393360137235
[Epoch 22, Batch 1100] loss: 0.007726565232887879
[Epoch 22, Batch 1200] loss: 0.00609190467483927
[Epoch 22, Batch 1300] loss: 0.008499215819043116
[Epoch 22, Batch 1400] loss: 0.007272962656968502
[Epoch 22, Batch 1500] loss: 0.013022343099356135
[Epoch 22, Batch 1600] loss: 0.005762763101140536
[Epoch 22, Batch 1700] loss: 0.002854734486816142
[Epoch 22, Batch 1800] loss: 0.008049968163252857
[Epoch 22, Batch 1900] loss: 0.006181801838287413
[Epoch 22, Batch 2000] loss: 0.007214007299194236
[Epoch 22, Batch 2100] loss: 0.006963724239015505
[Epoch 22, Batch 2200] loss: 0.007819102833711894
[Epoch 22, Batch 2300] loss: 0.003389472052269866
[Epoch 22, Batch 2400] loss: 0.0027810507388903714
[Epoch 22, Batch 2500] loss: 0.005114460406531407
[Epoch 22, Batch 2600] loss: 0.016907932028634606
[Epoch 22, Batch 2700] loss: 0.01296672462303377
[Epoch 22, Batch 2800] loss: 0.00486431153794399
[Epoch 22, Batch 2900] loss: 0.00537537760160717
[Epoch 22, Batch 3000] loss: 0.0033166532708764863
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9866
Overfitting: 0.0561
[Epoch 23, Batch 100] loss: 0.005978871283464287
[Epoch 23, Batch 200] loss: 0.004989780685764345
[Epoch 23, Batch 300] loss: 0.007992507901587374
[Epoch 23, Batch 400] loss: 0.0090282414249873
[Epoch 23, Batch 500] loss: 0.005566628143593561
[Epoch 23, Batch 600] loss: 0.0035727124371737772
[Epoch 23, Batch 700] loss: 0.006487418779713039
[Epoch 23, Batch 800] loss: 0.005116251672026237
[Epoch 23, Batch 900] loss: 0.0016508164158497607
[Epoch 23, Batch 1000] loss: 0.005237145300084194
[Epoch 23, Batch 1100] loss: 0.0022970340700237558
[Epoch 23, Batch 1200] loss: 0.002235931375200835
[Epoch 23, Batch 1300] loss: 0.005471949245334145
[Epoch 23, Batch 1400] loss: 0.005906801361725229
[Epoch 23, Batch 1500] loss: 0.0073048134191094505
[Epoch 23, Batch 1600] loss: 0.00319119327738008
[Epoch 23, Batch 1700] loss: 0.0025390420242024448
[Epoch 23, Batch 1800] loss: 0.004444501743417959
[Epoch 23, Batch 1900] loss: 0.00180884950851123
[Epoch 23, Batch 2000] loss: 0.005303383385004849
[Epoch 23, Batch 2100] loss: 0.0028413330460318777
[Epoch 23, Batch 2200] loss: 0.0014264068547325337
[Epoch 23, Batch 2300] loss: 0.003371239579852272
[Epoch 23, Batch 2400] loss: 0.004421840591929822
[Epoch 23, Batch 2500] loss: 0.0020352099789101886
[Epoch 23, Batch 2600] loss: 0.0040331455444834316
[Epoch 23, Batch 2700] loss: 0.0020351347868779613
[Epoch 23, Batch 2800] loss: 0.006096634743796585
[Epoch 23, Batch 2900] loss: 0.0029814255627798047
[Epoch 23, Batch 3000] loss: 0.006264389799690875
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0580
Validation Accuracy: 0.9868
Overfitting: 0.0580
[Epoch 24, Batch 100] loss: 0.005125749044274386
[Epoch 24, Batch 200] loss: 0.002041106689622438
[Epoch 24, Batch 300] loss: 0.0036077851174611906
[Epoch 24, Batch 400] loss: 0.002845584045871874
[Epoch 24, Batch 500] loss: 0.0014978688300789145
[Epoch 24, Batch 600] loss: 0.0010441083061357404
[Epoch 24, Batch 700] loss: 0.0043586017102455795
[Epoch 24, Batch 800] loss: 0.0014528854673828563
[Epoch 24, Batch 900] loss: 0.0017502801983387429
[Epoch 24, Batch 1000] loss: 0.004388014050229003
[Epoch 24, Batch 1100] loss: 0.00623199237623453
[Epoch 24, Batch 1200] loss: 0.0023805753257840935
[Epoch 24, Batch 1300] loss: 0.001613571529986757
[Epoch 24, Batch 1400] loss: 0.0016301153058600449
[Epoch 24, Batch 1500] loss: 0.002932131388287189
[Epoch 24, Batch 1600] loss: 0.0022880459788325426
[Epoch 24, Batch 1700] loss: 0.003521135019361452
[Epoch 24, Batch 1800] loss: 0.004108854226768699
[Epoch 24, Batch 1900] loss: 0.001974673480655156
[Epoch 24, Batch 2000] loss: 0.0024421245055083318
[Epoch 24, Batch 2100] loss: 0.003795902000465645
[Epoch 24, Batch 2200] loss: 0.006094045818381843
[Epoch 24, Batch 2300] loss: 0.002679343092439694
[Epoch 24, Batch 2400] loss: 0.0020151270830911015
[Epoch 24, Batch 2500] loss: 0.012001120349331415
[Epoch 24, Batch 2600] loss: 0.0025390009043888993
[Epoch 24, Batch 2700] loss: 0.010880441519412897
[Epoch 24, Batch 2800] loss: 0.005107262947380473
[Epoch 24, Batch 2900] loss: 0.007024548049173518
[Epoch 24, Batch 3000] loss: 0.0030264411266375645
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9878
Overfitting: 0.0531
Fold 2 validation loss: 0.0531
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.297692391872406
[Epoch 1, Batch 200] loss: 2.2843156361579897
[Epoch 1, Batch 300] loss: 2.2589488530159
[Epoch 1, Batch 400] loss: 2.1987122631073
[Epoch 1, Batch 500] loss: 1.9813607382774352
[Epoch 1, Batch 600] loss: 1.2005665343999863
[Epoch 1, Batch 700] loss: 0.7223112079501152
[Epoch 1, Batch 800] loss: 0.5469370575249195
[Epoch 1, Batch 900] loss: 0.43854086987674235
[Epoch 1, Batch 1000] loss: 0.36740753188729286
[Epoch 1, Batch 1100] loss: 0.3672649110481143
[Epoch 1, Batch 1200] loss: 0.3330159658938646
[Epoch 1, Batch 1300] loss: 0.33350384317338466
[Epoch 1, Batch 1400] loss: 0.27311596848070624
[Epoch 1, Batch 1500] loss: 0.25207382716238497
[Epoch 1, Batch 1600] loss: 0.2558821333013475
[Epoch 1, Batch 1700] loss: 0.23802923008799554
[Epoch 1, Batch 1800] loss: 0.2152992380037904
[Epoch 1, Batch 1900] loss: 0.2312624335102737
[Epoch 1, Batch 2000] loss: 0.21852939480915665
[Epoch 1, Batch 2100] loss: 0.20335039957426487
[Epoch 1, Batch 2200] loss: 0.18351192696020008
[Epoch 1, Batch 2300] loss: 0.16753985456191003
[Epoch 1, Batch 2400] loss: 0.1843926315754652
[Epoch 1, Batch 2500] loss: 0.16553559402003884
[Epoch 1, Batch 2600] loss: 0.18094216137193142
[Epoch 1, Batch 2700] loss: 0.17217270869761706
[Epoch 1, Batch 2800] loss: 0.1479722926672548
[Epoch 1, Batch 2900] loss: 0.1470314699690789
[Epoch 1, Batch 3000] loss: 0.138460374455899
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1450
Validation Accuracy: 0.9559
Overfitting: 0.1450
Best model saved at epoch 1 with validation loss: 0.1450
[Epoch 2, Batch 100] loss: 0.11898301440756769
[Epoch 2, Batch 200] loss: 0.1267240179516375
[Epoch 2, Batch 300] loss: 0.14735439759213478
[Epoch 2, Batch 400] loss: 0.11136932675726711
[Epoch 2, Batch 500] loss: 0.12680683578830212
[Epoch 2, Batch 600] loss: 0.12671506275888533
[Epoch 2, Batch 700] loss: 0.1437572292704135
[Epoch 2, Batch 800] loss: 0.13357375752180814
[Epoch 2, Batch 900] loss: 0.10434882418718189
[Epoch 2, Batch 1000] loss: 0.13899664202705025
[Epoch 2, Batch 1100] loss: 0.10009154381696135
[Epoch 2, Batch 1200] loss: 0.12369888873770833
[Epoch 2, Batch 1300] loss: 0.11354144796030596
[Epoch 2, Batch 1400] loss: 0.10666645448189228
[Epoch 2, Batch 1500] loss: 0.10268659021006897
[Epoch 2, Batch 1600] loss: 0.0988859593681991
[Epoch 2, Batch 1700] loss: 0.10013108246494085
[Epoch 2, Batch 1800] loss: 0.12733378651901148
[Epoch 2, Batch 1900] loss: 0.08751223359256982
[Epoch 2, Batch 2000] loss: 0.1206165426177904
[Epoch 2, Batch 2100] loss: 0.087746387651423
[Epoch 2, Batch 2200] loss: 0.08746798340696842
[Epoch 2, Batch 2300] loss: 0.0988701034814585
[Epoch 2, Batch 2400] loss: 0.10419125400716439
[Epoch 2, Batch 2500] loss: 0.1024486644170247
[Epoch 2, Batch 2600] loss: 0.08092450141673907
[Epoch 2, Batch 2700] loss: 0.07608525364426896
[Epoch 2, Batch 2800] loss: 0.09446661831112578
[Epoch 2, Batch 2900] loss: 0.11388283172505907
[Epoch 2, Batch 3000] loss: 0.09935987671255134
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1090
Validation Accuracy: 0.9671
Overfitting: 0.1090
Best model saved at epoch 2 with validation loss: 0.1090
[Epoch 3, Batch 100] loss: 0.08262012829771265
[Epoch 3, Batch 200] loss: 0.08621279226965271
[Epoch 3, Batch 300] loss: 0.07759153402526862
[Epoch 3, Batch 400] loss: 0.08751996186561882
[Epoch 3, Batch 500] loss: 0.10482195394812152
[Epoch 3, Batch 600] loss: 0.08174065426923334
[Epoch 3, Batch 700] loss: 0.07603925798553973
[Epoch 3, Batch 800] loss: 0.08009288898436352
[Epoch 3, Batch 900] loss: 0.0886471818696009
[Epoch 3, Batch 1000] loss: 0.08436807038495317
[Epoch 3, Batch 1100] loss: 0.0656590366945602
[Epoch 3, Batch 1200] loss: 0.08330668642185629
[Epoch 3, Batch 1300] loss: 0.09453683764673769
[Epoch 3, Batch 1400] loss: 0.08726165691274218
[Epoch 3, Batch 1500] loss: 0.08309029652155005
[Epoch 3, Batch 1600] loss: 0.07570084621605928
[Epoch 3, Batch 1700] loss: 0.08609752783901058
[Epoch 3, Batch 1800] loss: 0.08150672056945041
[Epoch 3, Batch 1900] loss: 0.08759298656106694
[Epoch 3, Batch 2000] loss: 0.07677443682681769
[Epoch 3, Batch 2100] loss: 0.08971353498985991
[Epoch 3, Batch 2200] loss: 0.07655809997813776
[Epoch 3, Batch 2300] loss: 0.06231035331846215
[Epoch 3, Batch 2400] loss: 0.05299753691768274
[Epoch 3, Batch 2500] loss: 0.06898993920825887
[Epoch 3, Batch 2600] loss: 0.07027559921552892
[Epoch 3, Batch 2700] loss: 0.06874132541415748
[Epoch 3, Batch 2800] loss: 0.0751649694563821
[Epoch 3, Batch 2900] loss: 0.06418674282263964
[Epoch 3, Batch 3000] loss: 0.06359853626752737
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0744
Validation Accuracy: 0.9765
Overfitting: 0.0744
Best model saved at epoch 3 with validation loss: 0.0744
[Epoch 4, Batch 100] loss: 0.04676888544927351
[Epoch 4, Batch 200] loss: 0.052679336076253094
[Epoch 4, Batch 300] loss: 0.06712976602138951
[Epoch 4, Batch 400] loss: 0.05258215739857405
[Epoch 4, Batch 500] loss: 0.07024321220233105
[Epoch 4, Batch 600] loss: 0.06885916520259343
[Epoch 4, Batch 700] loss: 0.07000110153923743
[Epoch 4, Batch 800] loss: 0.06300051374244503
[Epoch 4, Batch 900] loss: 0.08838698172359727
[Epoch 4, Batch 1000] loss: 0.06002819034387358
[Epoch 4, Batch 1100] loss: 0.05423690385185182
[Epoch 4, Batch 1200] loss: 0.07093725781975081
[Epoch 4, Batch 1300] loss: 0.05082445813226513
[Epoch 4, Batch 1400] loss: 0.06769053127558436
[Epoch 4, Batch 1500] loss: 0.05972504585981369
[Epoch 4, Batch 1600] loss: 0.05182973655697424
[Epoch 4, Batch 1700] loss: 0.06903758525062585
[Epoch 4, Batch 1800] loss: 0.05853098212479381
[Epoch 4, Batch 1900] loss: 0.057358033421915026
[Epoch 4, Batch 2000] loss: 0.05343617233098485
[Epoch 4, Batch 2100] loss: 0.05526164897135459
[Epoch 4, Batch 2200] loss: 0.055526779384817926
[Epoch 4, Batch 2300] loss: 0.0679328878247179
[Epoch 4, Batch 2400] loss: 0.07667905370297376
[Epoch 4, Batch 2500] loss: 0.06835426373698283
[Epoch 4, Batch 2600] loss: 0.06243497741466854
[Epoch 4, Batch 2700] loss: 0.05547809203329962
[Epoch 4, Batch 2800] loss: 0.057757209338014946
[Epoch 4, Batch 2900] loss: 0.08207171039597597
[Epoch 4, Batch 3000] loss: 0.05925774747331161
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0653
Validation Accuracy: 0.9801
Overfitting: 0.0653
Best model saved at epoch 4 with validation loss: 0.0653
[Epoch 5, Batch 100] loss: 0.056782920029363596
[Epoch 5, Batch 200] loss: 0.05665982096688822
[Epoch 5, Batch 300] loss: 0.052877385785686785
[Epoch 5, Batch 400] loss: 0.05822551890276372
[Epoch 5, Batch 500] loss: 0.05479348358290736
[Epoch 5, Batch 600] loss: 0.0568577404867392
[Epoch 5, Batch 700] loss: 0.0473415559186833
[Epoch 5, Batch 800] loss: 0.048249217038101054
[Epoch 5, Batch 900] loss: 0.05137671892705839
[Epoch 5, Batch 1000] loss: 0.041680400191398806
[Epoch 5, Batch 1100] loss: 0.041199650549388026
[Epoch 5, Batch 1200] loss: 0.034324893046286886
[Epoch 5, Batch 1300] loss: 0.08172516910883132
[Epoch 5, Batch 1400] loss: 0.04452755965729011
[Epoch 5, Batch 1500] loss: 0.050018354001513214
[Epoch 5, Batch 1600] loss: 0.047041447783412876
[Epoch 5, Batch 1700] loss: 0.05412759755679872
[Epoch 5, Batch 1800] loss: 0.06150969020964112
[Epoch 5, Batch 1900] loss: 0.04896131741057616
[Epoch 5, Batch 2000] loss: 0.04773525877360953
[Epoch 5, Batch 2100] loss: 0.06012643929105252
[Epoch 5, Batch 2200] loss: 0.04835924907034496
[Epoch 5, Batch 2300] loss: 0.036590736911748536
[Epoch 5, Batch 2400] loss: 0.0539549244090449
[Epoch 5, Batch 2500] loss: 0.05750863355351612
[Epoch 5, Batch 2600] loss: 0.039332195682509334
[Epoch 5, Batch 2700] loss: 0.036073376130079854
[Epoch 5, Batch 2800] loss: 0.04518036977213342
[Epoch 5, Batch 2900] loss: 0.043160597862151914
[Epoch 5, Batch 3000] loss: 0.054313393787742824
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0695
Validation Accuracy: 0.9792
Overfitting: 0.0695
[Epoch 6, Batch 100] loss: 0.053948749867849984
[Epoch 6, Batch 200] loss: 0.05055087671120418
[Epoch 6, Batch 300] loss: 0.03497946041374234
[Epoch 6, Batch 400] loss: 0.043798552154912615
[Epoch 6, Batch 500] loss: 0.02731469174468657
[Epoch 6, Batch 600] loss: 0.037283003858319716
[Epoch 6, Batch 700] loss: 0.04871410017396556
[Epoch 6, Batch 800] loss: 0.04237103742227191
[Epoch 6, Batch 900] loss: 0.04289392090198817
[Epoch 6, Batch 1000] loss: 0.040388307701941815
[Epoch 6, Batch 1100] loss: 0.04832528043989441
[Epoch 6, Batch 1200] loss: 0.04027218996969168
[Epoch 6, Batch 1300] loss: 0.03500978447293164
[Epoch 6, Batch 1400] loss: 0.03976204482722096
[Epoch 6, Batch 1500] loss: 0.049739018687978385
[Epoch 6, Batch 1600] loss: 0.05285883488075342
[Epoch 6, Batch 1700] loss: 0.043054453592339996
[Epoch 6, Batch 1800] loss: 0.05406308167031966
[Epoch 6, Batch 1900] loss: 0.036351663783134425
[Epoch 6, Batch 2000] loss: 0.04100198109954363
[Epoch 6, Batch 2100] loss: 0.04882610360378749
[Epoch 6, Batch 2200] loss: 0.0496130110239028
[Epoch 6, Batch 2300] loss: 0.04560360789706465
[Epoch 6, Batch 2400] loss: 0.04600783309346298
[Epoch 6, Batch 2500] loss: 0.03362326427915832
[Epoch 6, Batch 2600] loss: 0.046396494464424905
[Epoch 6, Batch 2700] loss: 0.04222637254337314
[Epoch 6, Batch 2800] loss: 0.04039143279835116
[Epoch 6, Batch 2900] loss: 0.04116209678177256
[Epoch 6, Batch 3000] loss: 0.044998230867786336
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0595
Validation Accuracy: 0.9811
Overfitting: 0.0595
Best model saved at epoch 6 with validation loss: 0.0595
[Epoch 7, Batch 100] loss: 0.03559994062496116
[Epoch 7, Batch 200] loss: 0.03409034567244817
[Epoch 7, Batch 300] loss: 0.04157750038793893
[Epoch 7, Batch 400] loss: 0.03632301027493668
[Epoch 7, Batch 500] loss: 0.037203854131512344
[Epoch 7, Batch 600] loss: 0.042610567515948786
[Epoch 7, Batch 700] loss: 0.04316630259374506
[Epoch 7, Batch 800] loss: 0.02512075585196726
[Epoch 7, Batch 900] loss: 0.026134842949104495
[Epoch 7, Batch 1000] loss: 0.040859981704998063
[Epoch 7, Batch 1100] loss: 0.03228676213795552
[Epoch 7, Batch 1200] loss: 0.031262476290175985
[Epoch 7, Batch 1300] loss: 0.0423370107304072
[Epoch 7, Batch 1400] loss: 0.040184982171922456
[Epoch 7, Batch 1500] loss: 0.02644060873266426
[Epoch 7, Batch 1600] loss: 0.049199894618068354
[Epoch 7, Batch 1700] loss: 0.049510277015069735
[Epoch 7, Batch 1800] loss: 0.03301960304495879
[Epoch 7, Batch 1900] loss: 0.03777220331889111
[Epoch 7, Batch 2000] loss: 0.05126137552666478
[Epoch 7, Batch 2100] loss: 0.045958511419012214
[Epoch 7, Batch 2200] loss: 0.028237923661872628
[Epoch 7, Batch 2300] loss: 0.02737048382681678
[Epoch 7, Batch 2400] loss: 0.037131957893871005
[Epoch 7, Batch 2500] loss: 0.03387269248312805
[Epoch 7, Batch 2600] loss: 0.040076094245450805
[Epoch 7, Batch 2700] loss: 0.0505909671948757
[Epoch 7, Batch 2800] loss: 0.03406174372881651
[Epoch 7, Batch 2900] loss: 0.027220116042735755
[Epoch 7, Batch 3000] loss: 0.039238671569983126
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0571
Validation Accuracy: 0.9821
Overfitting: 0.0571
Best model saved at epoch 7 with validation loss: 0.0571
[Epoch 8, Batch 100] loss: 0.028050536125520012
[Epoch 8, Batch 200] loss: 0.027335264460416512
[Epoch 8, Batch 300] loss: 0.03548208913642156
[Epoch 8, Batch 400] loss: 0.040227766065945615
[Epoch 8, Batch 500] loss: 0.02986969648161903
[Epoch 8, Batch 600] loss: 0.03432213999229134
[Epoch 8, Batch 700] loss: 0.030469397215638308
[Epoch 8, Batch 800] loss: 0.03075497158235521
[Epoch 8, Batch 900] loss: 0.02480906879209215
[Epoch 8, Batch 1000] loss: 0.026613600301207043
[Epoch 8, Batch 1100] loss: 0.04495627249889367
[Epoch 8, Batch 1200] loss: 0.033029520483833036
[Epoch 8, Batch 1300] loss: 0.03739887680625543
[Epoch 8, Batch 1400] loss: 0.040362112403527134
[Epoch 8, Batch 1500] loss: 0.027257003379854722
[Epoch 8, Batch 1600] loss: 0.03259906591440085
[Epoch 8, Batch 1700] loss: 0.028297667007354903
[Epoch 8, Batch 1800] loss: 0.04402276837092359
[Epoch 8, Batch 1900] loss: 0.04478941125242272
[Epoch 8, Batch 2000] loss: 0.02666214140906959
[Epoch 8, Batch 2100] loss: 0.04206088342951261
[Epoch 8, Batch 2200] loss: 0.024946808169333964
[Epoch 8, Batch 2300] loss: 0.030789083035342626
[Epoch 8, Batch 2400] loss: 0.046194979258580134
[Epoch 8, Batch 2500] loss: 0.028150004569615705
[Epoch 8, Batch 2600] loss: 0.038111015617032534
[Epoch 8, Batch 2700] loss: 0.0333721571067872
[Epoch 8, Batch 2800] loss: 0.043532445228192954
[Epoch 8, Batch 2900] loss: 0.0339468571775069
[Epoch 8, Batch 3000] loss: 0.03016674761165632
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9842
Overfitting: 0.0522
Best model saved at epoch 8 with validation loss: 0.0522
[Epoch 9, Batch 100] loss: 0.031027418608573498
[Epoch 9, Batch 200] loss: 0.03001102601992898
[Epoch 9, Batch 300] loss: 0.02601709042697621
[Epoch 9, Batch 400] loss: 0.025126406304189004
[Epoch 9, Batch 500] loss: 0.018981220542227676
[Epoch 9, Batch 600] loss: 0.026775012388825417
[Epoch 9, Batch 700] loss: 0.01869848748203367
[Epoch 9, Batch 800] loss: 0.025872742974170252
[Epoch 9, Batch 900] loss: 0.02340103945985902
[Epoch 9, Batch 1000] loss: 0.026115735912135278
[Epoch 9, Batch 1100] loss: 0.02277743660215492
[Epoch 9, Batch 1200] loss: 0.03217478761624079
[Epoch 9, Batch 1300] loss: 0.03670073079876602
[Epoch 9, Batch 1400] loss: 0.03553134449452045
[Epoch 9, Batch 1500] loss: 0.0336925519547367
[Epoch 9, Batch 1600] loss: 0.029717258681121166
[Epoch 9, Batch 1700] loss: 0.022441877944984298
[Epoch 9, Batch 1800] loss: 0.03033728075453837
[Epoch 9, Batch 1900] loss: 0.02157687512692064
[Epoch 9, Batch 2000] loss: 0.024219556206589915
[Epoch 9, Batch 2100] loss: 0.0361110109299625
[Epoch 9, Batch 2200] loss: 0.03145593802728399
[Epoch 9, Batch 2300] loss: 0.03273408778695739
[Epoch 9, Batch 2400] loss: 0.025914270763241803
[Epoch 9, Batch 2500] loss: 0.03373615757416701
[Epoch 9, Batch 2600] loss: 0.03888940876706329
[Epoch 9, Batch 2700] loss: 0.03136883336861501
[Epoch 9, Batch 2800] loss: 0.0369473529572133
[Epoch 9, Batch 2900] loss: 0.028907959933653728
[Epoch 9, Batch 3000] loss: 0.02692383234942099
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9817
Overfitting: 0.0593
[Epoch 10, Batch 100] loss: 0.02401365448422439
[Epoch 10, Batch 200] loss: 0.02659383690002869
[Epoch 10, Batch 300] loss: 0.03424434265209129
[Epoch 10, Batch 400] loss: 0.031474525760568216
[Epoch 10, Batch 500] loss: 0.028511081751148595
[Epoch 10, Batch 600] loss: 0.026444232500653017
[Epoch 10, Batch 700] loss: 0.0262539157095307
[Epoch 10, Batch 800] loss: 0.032493133937859964
[Epoch 10, Batch 900] loss: 0.023715118676191197
[Epoch 10, Batch 1000] loss: 0.015550885604025098
[Epoch 10, Batch 1100] loss: 0.01761685886187479
[Epoch 10, Batch 1200] loss: 0.03791637183341663
[Epoch 10, Batch 1300] loss: 0.025368723285646412
[Epoch 10, Batch 1400] loss: 0.02353559687406232
[Epoch 10, Batch 1500] loss: 0.0262914631951935
[Epoch 10, Batch 1600] loss: 0.021667323799556472
[Epoch 10, Batch 1700] loss: 0.018403332635571132
[Epoch 10, Batch 1800] loss: 0.03759287797569413
[Epoch 10, Batch 1900] loss: 0.010053952907728671
[Epoch 10, Batch 2000] loss: 0.022850199504523515
[Epoch 10, Batch 2100] loss: 0.03056622059088113
[Epoch 10, Batch 2200] loss: 0.019294074510835344
[Epoch 10, Batch 2300] loss: 0.03021531811089517
[Epoch 10, Batch 2400] loss: 0.021962188231718756
[Epoch 10, Batch 2500] loss: 0.0204453747628213
[Epoch 10, Batch 2600] loss: 0.0171224581570641
[Epoch 10, Batch 2700] loss: 0.025222072771903185
[Epoch 10, Batch 2800] loss: 0.034466128988569836
[Epoch 10, Batch 2900] loss: 0.02885389106490038
[Epoch 10, Batch 3000] loss: 0.02465130849273919
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9859
Overfitting: 0.0468
Best model saved at epoch 10 with validation loss: 0.0468
[Epoch 11, Batch 100] loss: 0.023483480074100952
[Epoch 11, Batch 200] loss: 0.027781201988982502
[Epoch 11, Batch 300] loss: 0.018815826782447403
[Epoch 11, Batch 400] loss: 0.02384373188171594
[Epoch 11, Batch 500] loss: 0.01568637790507637
[Epoch 11, Batch 600] loss: 0.020686887530464448
[Epoch 11, Batch 700] loss: 0.028329473833873634
[Epoch 11, Batch 800] loss: 0.023438286708114903
[Epoch 11, Batch 900] loss: 0.015419326479131997
[Epoch 11, Batch 1000] loss: 0.020350668338360266
[Epoch 11, Batch 1100] loss: 0.028054092695601867
[Epoch 11, Batch 1200] loss: 0.016213893287058453
[Epoch 11, Batch 1300] loss: 0.02709444572163193
[Epoch 11, Batch 1400] loss: 0.01754946520575686
[Epoch 11, Batch 1500] loss: 0.03483349089852709
[Epoch 11, Batch 1600] loss: 0.02028549708233186
[Epoch 11, Batch 1700] loss: 0.015254143658639805
[Epoch 11, Batch 1800] loss: 0.017917347802067524
[Epoch 11, Batch 1900] loss: 0.021763265427507575
[Epoch 11, Batch 2000] loss: 0.014313787148566917
[Epoch 11, Batch 2100] loss: 0.03499544429934758
[Epoch 11, Batch 2200] loss: 0.029415235811720775
[Epoch 11, Batch 2300] loss: 0.019629892263255896
[Epoch 11, Batch 2400] loss: 0.021001675786274064
[Epoch 11, Batch 2500] loss: 0.02390395034562971
[Epoch 11, Batch 2600] loss: 0.019337112907523987
[Epoch 11, Batch 2700] loss: 0.021768705809772654
[Epoch 11, Batch 2800] loss: 0.012818360827150172
[Epoch 11, Batch 2900] loss: 0.027347429478654702
[Epoch 11, Batch 3000] loss: 0.033310487342932904
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0438
Validation Accuracy: 0.9872
Overfitting: 0.0438
Best model saved at epoch 11 with validation loss: 0.0438
[Epoch 12, Batch 100] loss: 0.0157660511683207
[Epoch 12, Batch 200] loss: 0.018672208545613102
[Epoch 12, Batch 300] loss: 0.022864047132170526
[Epoch 12, Batch 400] loss: 0.016275940974555852
[Epoch 12, Batch 500] loss: 0.015291392688268388
[Epoch 12, Batch 600] loss: 0.014411882711910948
[Epoch 12, Batch 700] loss: 0.03353092802062747
[Epoch 12, Batch 800] loss: 0.012535766859764408
[Epoch 12, Batch 900] loss: 0.014193323073486681
[Epoch 12, Batch 1000] loss: 0.01562556460967244
[Epoch 12, Batch 1100] loss: 0.022925911956554045
[Epoch 12, Batch 1200] loss: 0.019148149648426625
[Epoch 12, Batch 1300] loss: 0.0347462335565433
[Epoch 12, Batch 1400] loss: 0.020111999653672684
[Epoch 12, Batch 1500] loss: 0.012814511035430768
[Epoch 12, Batch 1600] loss: 0.024806792244926327
[Epoch 12, Batch 1700] loss: 0.017418309664453773
[Epoch 12, Batch 1800] loss: 0.015019367707245691
[Epoch 12, Batch 1900] loss: 0.02951775342570727
[Epoch 12, Batch 2000] loss: 0.015505661411116306
[Epoch 12, Batch 2100] loss: 0.02250575134257815
[Epoch 12, Batch 2200] loss: 0.03373146230680504
[Epoch 12, Batch 2300] loss: 0.010916637747359346
[Epoch 12, Batch 2400] loss: 0.018171161455684343
[Epoch 12, Batch 2500] loss: 0.02421957662967543
[Epoch 12, Batch 2600] loss: 0.03093507435914944
[Epoch 12, Batch 2700] loss: 0.017921897421583708
[Epoch 12, Batch 2800] loss: 0.02959896206011763
[Epoch 12, Batch 2900] loss: 0.02201247806668107
[Epoch 12, Batch 3000] loss: 0.015051867198926629
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9858
Overfitting: 0.0478
[Epoch 13, Batch 100] loss: 0.01565334660570443
[Epoch 13, Batch 200] loss: 0.020572378474180367
[Epoch 13, Batch 300] loss: 0.011533165197324707
[Epoch 13, Batch 400] loss: 0.007145239128976755
[Epoch 13, Batch 500] loss: 0.013960121864438407
[Epoch 13, Batch 600] loss: 0.01796304163581226
[Epoch 13, Batch 700] loss: 0.020613952109533783
[Epoch 13, Batch 800] loss: 0.01900894952177623
[Epoch 13, Batch 900] loss: 0.02041409880410356
[Epoch 13, Batch 1000] loss: 0.02720793466505711
[Epoch 13, Batch 1100] loss: 0.0203570507340919
[Epoch 13, Batch 1200] loss: 0.00885577926033875
[Epoch 13, Batch 1300] loss: 0.01719480540312361
[Epoch 13, Batch 1400] loss: 0.02763472495124006
[Epoch 13, Batch 1500] loss: 0.019403996795117565
[Epoch 13, Batch 1600] loss: 0.012062033285619691
[Epoch 13, Batch 1700] loss: 0.009399183900286516
[Epoch 13, Batch 1800] loss: 0.01987501095533844
[Epoch 13, Batch 1900] loss: 0.02412740689684142
[Epoch 13, Batch 2000] loss: 0.01137942540961376
[Epoch 13, Batch 2100] loss: 0.026281124537235884
[Epoch 13, Batch 2200] loss: 0.028977480726080102
[Epoch 13, Batch 2300] loss: 0.015524672343417478
[Epoch 13, Batch 2400] loss: 0.017276898246782368
[Epoch 13, Batch 2500] loss: 0.02072575151136334
[Epoch 13, Batch 2600] loss: 0.014990225200908753
[Epoch 13, Batch 2700] loss: 0.01967766665020463
[Epoch 13, Batch 2800] loss: 0.021426303319622093
[Epoch 13, Batch 2900] loss: 0.028988831185997696
[Epoch 13, Batch 3000] loss: 0.009057819792215014
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9863
Overfitting: 0.0477
[Epoch 14, Batch 100] loss: 0.023441703632161078
[Epoch 14, Batch 200] loss: 0.01695488027022293
[Epoch 14, Batch 300] loss: 0.012083833572366984
[Epoch 14, Batch 400] loss: 0.007758714743267774
[Epoch 14, Batch 500] loss: 0.014024125115674906
[Epoch 14, Batch 600] loss: 0.012923384644909674
[Epoch 14, Batch 700] loss: 0.013038041969266487
[Epoch 14, Batch 800] loss: 0.011569033441046485
[Epoch 14, Batch 900] loss: 0.010816707378307911
[Epoch 14, Batch 1000] loss: 0.015036947001053704
[Epoch 14, Batch 1100] loss: 0.010826899247231268
[Epoch 14, Batch 1200] loss: 0.020158611860269956
[Epoch 14, Batch 1300] loss: 0.019219143978734792
[Epoch 14, Batch 1400] loss: 0.017003861271696223
[Epoch 14, Batch 1500] loss: 0.01349455450223104
[Epoch 14, Batch 1600] loss: 0.013482753729285833
[Epoch 14, Batch 1700] loss: 0.021514124961977358
[Epoch 14, Batch 1800] loss: 0.01762818803490518
[Epoch 14, Batch 1900] loss: 0.01554295695023029
[Epoch 14, Batch 2000] loss: 0.00895548108791445
[Epoch 14, Batch 2100] loss: 0.016604077627016524
[Epoch 14, Batch 2200] loss: 0.014590452023167017
[Epoch 14, Batch 2300] loss: 0.013759301000618507
[Epoch 14, Batch 2400] loss: 0.0075657866302208275
[Epoch 14, Batch 2500] loss: 0.022296381841561016
[Epoch 14, Batch 2600] loss: 0.01245540261219503
[Epoch 14, Batch 2700] loss: 0.014500990905771687
[Epoch 14, Batch 2800] loss: 0.030223085055699813
[Epoch 14, Batch 2900] loss: 0.02120024874137016
[Epoch 14, Batch 3000] loss: 0.016346447073919988
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0428
Validation Accuracy: 0.9870
Overfitting: 0.0428
Best model saved at epoch 14 with validation loss: 0.0428
[Epoch 15, Batch 100] loss: 0.008792929850824294
[Epoch 15, Batch 200] loss: 0.00931487463603844
[Epoch 15, Batch 300] loss: 0.009896469345403603
[Epoch 15, Batch 400] loss: 0.015861975173170322
[Epoch 15, Batch 500] loss: 0.0125664240144215
[Epoch 15, Batch 600] loss: 0.01346239436084943
[Epoch 15, Batch 700] loss: 0.009934689981810152
[Epoch 15, Batch 800] loss: 0.00995673035416985
[Epoch 15, Batch 900] loss: 0.010354081061698252
[Epoch 15, Batch 1000] loss: 0.020525181149878335
[Epoch 15, Batch 1100] loss: 0.01127837225823896
[Epoch 15, Batch 1200] loss: 0.01073675030060258
[Epoch 15, Batch 1300] loss: 0.014094452795688994
[Epoch 15, Batch 1400] loss: 0.006678981263175956
[Epoch 15, Batch 1500] loss: 0.01142749561531673
[Epoch 15, Batch 1600] loss: 0.0070365266182261625
[Epoch 15, Batch 1700] loss: 0.012798633838820024
[Epoch 15, Batch 1800] loss: 0.018417396780782837
[Epoch 15, Batch 1900] loss: 0.016368031998608784
[Epoch 15, Batch 2000] loss: 0.019972251589715596
[Epoch 15, Batch 2100] loss: 0.022144898104274943
[Epoch 15, Batch 2200] loss: 0.015468649014824223
[Epoch 15, Batch 2300] loss: 0.014031648734862756
[Epoch 15, Batch 2400] loss: 0.012620948281228266
[Epoch 15, Batch 2500] loss: 0.01501411689865563
[Epoch 15, Batch 2600] loss: 0.008557042748634558
[Epoch 15, Batch 2700] loss: 0.025846331788179668
[Epoch 15, Batch 2800] loss: 0.012724193429639853
[Epoch 15, Batch 2900] loss: 0.01616380902014498
[Epoch 15, Batch 3000] loss: 0.014406545932206426
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9856
Overfitting: 0.0505
[Epoch 16, Batch 100] loss: 0.00956513978948351
[Epoch 16, Batch 200] loss: 0.011206117569372509
[Epoch 16, Batch 300] loss: 0.009539850137443864
[Epoch 16, Batch 400] loss: 0.02197349786265477
[Epoch 16, Batch 500] loss: 0.010747564777893785
[Epoch 16, Batch 600] loss: 0.009592908137246923
[Epoch 16, Batch 700] loss: 0.01501511450766884
[Epoch 16, Batch 800] loss: 0.008588226864453645
[Epoch 16, Batch 900] loss: 0.008975250409512227
[Epoch 16, Batch 1000] loss: 0.004707183861473823
[Epoch 16, Batch 1100] loss: 0.01158939478676075
[Epoch 16, Batch 1200] loss: 0.009880019221823204
[Epoch 16, Batch 1300] loss: 0.014159097555566404
[Epoch 16, Batch 1400] loss: 0.01533568610731436
[Epoch 16, Batch 1500] loss: 0.011040649652072717
[Epoch 16, Batch 1600] loss: 0.008683878498800368
[Epoch 16, Batch 1700] loss: 0.008519010603376955
[Epoch 16, Batch 1800] loss: 0.010558948719808541
[Epoch 16, Batch 1900] loss: 0.01088394463304212
[Epoch 16, Batch 2000] loss: 0.017291876857439093
[Epoch 16, Batch 2100] loss: 0.009361292527971727
[Epoch 16, Batch 2200] loss: 0.017414636769390198
[Epoch 16, Batch 2300] loss: 0.017304003465997083
[Epoch 16, Batch 2400] loss: 0.01531779526229002
[Epoch 16, Batch 2500] loss: 0.013378070446988204
[Epoch 16, Batch 2600] loss: 0.009901370659367786
[Epoch 16, Batch 2700] loss: 0.012908706765183525
[Epoch 16, Batch 2800] loss: 0.024022380113565306
[Epoch 16, Batch 2900] loss: 0.021323384558418184
[Epoch 16, Batch 3000] loss: 0.0133961487065244
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9868
Overfitting: 0.0457
[Epoch 17, Batch 100] loss: 0.007432464294788587
[Epoch 17, Batch 200] loss: 0.00847636036678523
[Epoch 17, Batch 300] loss: 0.00985047263159231
[Epoch 17, Batch 400] loss: 0.005363791090198902
[Epoch 17, Batch 500] loss: 0.015758757098856224
[Epoch 17, Batch 600] loss: 0.008632521459794588
[Epoch 17, Batch 700] loss: 0.0045707517556411404
[Epoch 17, Batch 800] loss: 0.010458641517434444
[Epoch 17, Batch 900] loss: 0.008099082810904292
[Epoch 17, Batch 1000] loss: 0.017938407567108926
[Epoch 17, Batch 1100] loss: 0.009216537889069515
[Epoch 17, Batch 1200] loss: 0.019398483640943594
[Epoch 17, Batch 1300] loss: 0.007941465644908021
[Epoch 17, Batch 1400] loss: 0.007408164866508287
[Epoch 17, Batch 1500] loss: 0.0040372298183274325
[Epoch 17, Batch 1600] loss: 0.009403915606753799
[Epoch 17, Batch 1700] loss: 0.012144240937673204
[Epoch 17, Batch 1800] loss: 0.009464541135639593
[Epoch 17, Batch 1900] loss: 0.010242232697037253
[Epoch 17, Batch 2000] loss: 0.022419926435959497
[Epoch 17, Batch 2100] loss: 0.0065904625447331
[Epoch 17, Batch 2200] loss: 0.014407926505955402
[Epoch 17, Batch 2300] loss: 0.00981615130287082
[Epoch 17, Batch 2400] loss: 0.014493422094483321
[Epoch 17, Batch 2500] loss: 0.010292675340169808
[Epoch 17, Batch 2600] loss: 0.010875847832783165
[Epoch 17, Batch 2700] loss: 0.004223626073708147
[Epoch 17, Batch 2800] loss: 0.01623289480847234
[Epoch 17, Batch 2900] loss: 0.014872614470141344
[Epoch 17, Batch 3000] loss: 0.012617593502100136
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9861
Overfitting: 0.0515
[Epoch 18, Batch 100] loss: 0.007963042318478983
[Epoch 18, Batch 200] loss: 0.011717301048724949
[Epoch 18, Batch 300] loss: 0.008025048091906229
[Epoch 18, Batch 400] loss: 0.005332239290819416
[Epoch 18, Batch 500] loss: 0.005871478201745503
[Epoch 18, Batch 600] loss: 0.01089875899744584
[Epoch 18, Batch 700] loss: 0.005798848108911443
[Epoch 18, Batch 800] loss: 0.007086702469441661
[Epoch 18, Batch 900] loss: 0.008746476176174838
[Epoch 18, Batch 1000] loss: 0.010493180784214929
[Epoch 18, Batch 1100] loss: 0.011359545120435542
[Epoch 18, Batch 1200] loss: 0.013938452875104304
[Epoch 18, Batch 1300] loss: 0.011032073391543235
[Epoch 18, Batch 1400] loss: 0.008506045298317985
[Epoch 18, Batch 1500] loss: 0.004489053286248463
[Epoch 18, Batch 1600] loss: 0.007765373278809875
[Epoch 18, Batch 1700] loss: 0.006382299944234547
[Epoch 18, Batch 1800] loss: 0.007323317331986346
[Epoch 18, Batch 1900] loss: 0.018942251824832966
[Epoch 18, Batch 2000] loss: 0.013454088455937381
[Epoch 18, Batch 2100] loss: 0.003930535056211965
[Epoch 18, Batch 2200] loss: 0.005873925999439962
[Epoch 18, Batch 2300] loss: 0.0128334500659264
[Epoch 18, Batch 2400] loss: 0.011039434373178664
[Epoch 18, Batch 2500] loss: 0.017709996642997793
[Epoch 18, Batch 2600] loss: 0.011113744941631011
[Epoch 18, Batch 2700] loss: 0.011884994556630772
[Epoch 18, Batch 2800] loss: 0.008846301577548274
[Epoch 18, Batch 2900] loss: 0.006786463484431806
[Epoch 18, Batch 3000] loss: 0.00821561475691169
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9872
Overfitting: 0.0473
[Epoch 19, Batch 100] loss: 0.006594805733489011
[Epoch 19, Batch 200] loss: 0.003030212043636311
[Epoch 19, Batch 300] loss: 0.006595085870485491
[Epoch 19, Batch 400] loss: 0.004891599189920726
[Epoch 19, Batch 500] loss: 0.007640333212950736
[Epoch 19, Batch 600] loss: 0.006260661096257536
[Epoch 19, Batch 700] loss: 0.006498978529940587
[Epoch 19, Batch 800] loss: 0.005105916655675173
[Epoch 19, Batch 900] loss: 0.0056862199734996465
[Epoch 19, Batch 1000] loss: 0.00821140101952551
[Epoch 19, Batch 1100] loss: 0.008506809581233484
[Epoch 19, Batch 1200] loss: 0.010645002783917334
[Epoch 19, Batch 1300] loss: 0.011090632992541032
[Epoch 19, Batch 1400] loss: 0.00961074611780532
[Epoch 19, Batch 1500] loss: 0.007687625509265672
[Epoch 19, Batch 1600] loss: 0.003596385643386384
[Epoch 19, Batch 1700] loss: 0.011316581129749466
[Epoch 19, Batch 1800] loss: 0.006764470841658294
[Epoch 19, Batch 1900] loss: 0.009694915645509354
[Epoch 19, Batch 2000] loss: 0.004238616445406933
[Epoch 19, Batch 2100] loss: 0.00837897959976999
[Epoch 19, Batch 2200] loss: 0.005754571462296099
[Epoch 19, Batch 2300] loss: 0.008440095877804197
[Epoch 19, Batch 2400] loss: 0.006157237902618818
[Epoch 19, Batch 2500] loss: 0.012307706972428605
[Epoch 19, Batch 2600] loss: 0.008918810966579259
[Epoch 19, Batch 2700] loss: 0.006373069075887088
[Epoch 19, Batch 2800] loss: 0.013534784956973453
[Epoch 19, Batch 2900] loss: 0.01572311484601414
[Epoch 19, Batch 3000] loss: 0.008440445632838873
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9869
Overfitting: 0.0499
[Epoch 20, Batch 100] loss: 0.008562295822206351
[Epoch 20, Batch 200] loss: 0.005082836503219426
[Epoch 20, Batch 300] loss: 0.010050125711269403
[Epoch 20, Batch 400] loss: 0.004365524027611229
[Epoch 20, Batch 500] loss: 0.004435913051152056
[Epoch 20, Batch 600] loss: 0.007629504673664087
[Epoch 20, Batch 700] loss: 0.009475961874220501
[Epoch 20, Batch 800] loss: 0.007885651362053069
[Epoch 20, Batch 900] loss: 0.010795524564533707
[Epoch 20, Batch 1000] loss: 0.0080788536099044
[Epoch 20, Batch 1100] loss: 0.009460665777301074
[Epoch 20, Batch 1200] loss: 0.004892673462129551
[Epoch 20, Batch 1300] loss: 0.003537152325415036
[Epoch 20, Batch 1400] loss: 0.005814835919427424
[Epoch 20, Batch 1500] loss: 0.005143003550722938
[Epoch 20, Batch 1600] loss: 0.009529771459244784
[Epoch 20, Batch 1700] loss: 0.003815512683063389
[Epoch 20, Batch 1800] loss: 0.004913417997379384
[Epoch 20, Batch 1900] loss: 0.008329367582912256
[Epoch 20, Batch 2000] loss: 0.011627315379281527
[Epoch 20, Batch 2100] loss: 0.003558150011233465
[Epoch 20, Batch 2200] loss: 0.004142204129964284
[Epoch 20, Batch 2300] loss: 0.0025750858675621657
[Epoch 20, Batch 2400] loss: 0.004350026458720322
[Epoch 20, Batch 2500] loss: 0.009944451078797555
[Epoch 20, Batch 2600] loss: 0.007396831235814716
[Epoch 20, Batch 2700] loss: 0.005499319469364537
[Epoch 20, Batch 2800] loss: 0.007123044229304014
[Epoch 20, Batch 2900] loss: 0.008015498229747208
[Epoch 20, Batch 3000] loss: 0.006950795900283992
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9868
Overfitting: 0.0537
[Epoch 21, Batch 100] loss: 0.013211919361590958
[Epoch 21, Batch 200] loss: 0.012436084156636298
[Epoch 21, Batch 300] loss: 0.0031335773079081263
[Epoch 21, Batch 400] loss: 0.006100811895441894
[Epoch 21, Batch 500] loss: 0.0056245319638679805
[Epoch 21, Batch 600] loss: 0.005664162948567082
[Epoch 21, Batch 700] loss: 0.006349782397621766
[Epoch 21, Batch 800] loss: 0.0031858912037023403
[Epoch 21, Batch 900] loss: 0.011019436720516751
[Epoch 21, Batch 1000] loss: 0.0040913723402104555
[Epoch 21, Batch 1100] loss: 0.00878283718718194
[Epoch 21, Batch 1200] loss: 0.005708057319518503
[Epoch 21, Batch 1300] loss: 0.002143811024875504
[Epoch 21, Batch 1400] loss: 0.004136248472879061
[Epoch 21, Batch 1500] loss: 0.0033017442808710483
[Epoch 21, Batch 1600] loss: 0.009719049271360802
[Epoch 21, Batch 1700] loss: 0.0050967134660689336
[Epoch 21, Batch 1800] loss: 0.0025290418248636115
[Epoch 21, Batch 1900] loss: 0.00403946529021141
[Epoch 21, Batch 2000] loss: 0.010118687488124748
[Epoch 21, Batch 2100] loss: 0.004160189551789699
[Epoch 21, Batch 2200] loss: 0.003610767678811726
[Epoch 21, Batch 2300] loss: 0.007874242923173824
[Epoch 21, Batch 2400] loss: 0.014728602580632924
[Epoch 21, Batch 2500] loss: 0.007203308658815217
[Epoch 21, Batch 2600] loss: 0.008160479964813021
[Epoch 21, Batch 2700] loss: 0.008408069104225433
[Epoch 21, Batch 2800] loss: 0.00521948540766175
[Epoch 21, Batch 2900] loss: 0.006527594467236213
[Epoch 21, Batch 3000] loss: 0.006241832879548497
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9879
Overfitting: 0.0472
[Epoch 22, Batch 100] loss: 0.0032173067875133654
[Epoch 22, Batch 200] loss: 0.004872527860902096
[Epoch 22, Batch 300] loss: 0.004631760847545365
[Epoch 22, Batch 400] loss: 0.005408039716897974
[Epoch 22, Batch 500] loss: 0.004820723900389794
[Epoch 22, Batch 600] loss: 0.004245369235725889
[Epoch 22, Batch 700] loss: 0.008003990374973
[Epoch 22, Batch 800] loss: 0.008100526250946132
[Epoch 22, Batch 900] loss: 0.007488701767727264
[Epoch 22, Batch 1000] loss: 0.0019856565608859
[Epoch 22, Batch 1100] loss: 0.002895367315695694
[Epoch 22, Batch 1200] loss: 0.004957608003995802
[Epoch 22, Batch 1300] loss: 0.012536939641240395
[Epoch 22, Batch 1400] loss: 0.012858679497367121
[Epoch 22, Batch 1500] loss: 0.005372355298006824
[Epoch 22, Batch 1600] loss: 0.009209746653327784
[Epoch 22, Batch 1700] loss: 0.007126705035173018
[Epoch 22, Batch 1800] loss: 0.009003411802959818
[Epoch 22, Batch 1900] loss: 0.009949338813873965
[Epoch 22, Batch 2000] loss: 0.003310145355653731
[Epoch 22, Batch 2100] loss: 0.013087957920226927
[Epoch 22, Batch 2200] loss: 0.004007736724976212
[Epoch 22, Batch 2300] loss: 0.005593724960752411
[Epoch 22, Batch 2400] loss: 0.004724691879367811
[Epoch 22, Batch 2500] loss: 0.007987468464937137
[Epoch 22, Batch 2600] loss: 0.010283250233091507
[Epoch 22, Batch 2700] loss: 0.010818792956897597
[Epoch 22, Batch 2800] loss: 0.014841126856701407
[Epoch 22, Batch 2900] loss: 0.009189637205690816
[Epoch 22, Batch 3000] loss: 0.004879270964457874
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9890
Overfitting: 0.0471
[Epoch 23, Batch 100] loss: 0.005785105745587771
[Epoch 23, Batch 200] loss: 0.003443121244069971
[Epoch 23, Batch 300] loss: 0.0032911206626891954
[Epoch 23, Batch 400] loss: 0.006278117217608497
[Epoch 23, Batch 500] loss: 0.0028697185356793397
[Epoch 23, Batch 600] loss: 0.0046357721468120875
[Epoch 23, Batch 700] loss: 0.004474274398614852
[Epoch 23, Batch 800] loss: 0.0031688452900971243
[Epoch 23, Batch 900] loss: 0.005220688183790258
[Epoch 23, Batch 1000] loss: 0.004759959159441678
[Epoch 23, Batch 1100] loss: 0.006564410929976248
[Epoch 23, Batch 1200] loss: 0.00977048891374011
[Epoch 23, Batch 1300] loss: 0.004819841112677636
[Epoch 23, Batch 1400] loss: 0.005212065301507209
[Epoch 23, Batch 1500] loss: 0.0053467722540733575
[Epoch 23, Batch 1600] loss: 0.0030407148810252236
[Epoch 23, Batch 1700] loss: 0.004520491657092691
[Epoch 23, Batch 1800] loss: 0.008943884451448128
[Epoch 23, Batch 1900] loss: 0.005052836881270082
[Epoch 23, Batch 2000] loss: 0.004120324946570691
[Epoch 23, Batch 2100] loss: 0.002758428359716163
[Epoch 23, Batch 2200] loss: 0.013857284696563853
[Epoch 23, Batch 2300] loss: 0.005373764276605471
[Epoch 23, Batch 2400] loss: 0.005942897087264924
[Epoch 23, Batch 2500] loss: 0.008573885578147155
[Epoch 23, Batch 2600] loss: 0.004040411628620859
[Epoch 23, Batch 2700] loss: 0.007046593652060409
[Epoch 23, Batch 2800] loss: 0.004178574445423919
[Epoch 23, Batch 2900] loss: 0.006934173331281954
[Epoch 23, Batch 3000] loss: 0.0017198096542028907
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9896
Overfitting: 0.0459
[Epoch 24, Batch 100] loss: 0.0014880060616815171
[Epoch 24, Batch 200] loss: 0.0029381296100251574
[Epoch 24, Batch 300] loss: 0.00607332297276713
[Epoch 24, Batch 400] loss: 0.007327906647237228
[Epoch 24, Batch 500] loss: 0.0030687153911932797
[Epoch 24, Batch 600] loss: 0.0065393213195625325
[Epoch 24, Batch 700] loss: 0.002457830949315394
[Epoch 24, Batch 800] loss: 0.004459022389514189
[Epoch 24, Batch 900] loss: 0.01212187831200481
[Epoch 24, Batch 1000] loss: 0.002560395808490057
[Epoch 24, Batch 1100] loss: 0.0020413295347708527
[Epoch 24, Batch 1200] loss: 0.0037640170452448276
[Epoch 24, Batch 1300] loss: 0.005186968842446049
[Epoch 24, Batch 1400] loss: 0.0037772759175708614
[Epoch 24, Batch 1500] loss: 0.005002263292815314
[Epoch 24, Batch 1600] loss: 0.0034678995450228454
[Epoch 24, Batch 1700] loss: 0.0015074057117850969
[Epoch 24, Batch 1800] loss: 0.002332061656178439
[Epoch 24, Batch 1900] loss: 0.00265043182277509
[Epoch 24, Batch 2000] loss: 0.003105662763020973
[Epoch 24, Batch 2100] loss: 0.0042550356602390595
[Epoch 24, Batch 2200] loss: 0.0025482832356817655
[Epoch 24, Batch 2300] loss: 0.005678984242574642
[Epoch 24, Batch 2400] loss: 0.003773588759184747
[Epoch 24, Batch 2500] loss: 0.009346378767646683
[Epoch 24, Batch 2600] loss: 0.009062202261846437
[Epoch 24, Batch 2700] loss: 0.005890097100586047
[Epoch 24, Batch 2800] loss: 0.007488720149431742
[Epoch 24, Batch 2900] loss: 0.0028006882767209616
[Epoch 24, Batch 3000] loss: 0.005609384823559935
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9892
Overfitting: 0.0501
Fold 3 validation loss: 0.0501
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2929220962524415
[Epoch 1, Batch 200] loss: 2.265199236869812
[Epoch 1, Batch 300] loss: 2.1976637661457064
[Epoch 1, Batch 400] loss: 1.9207909178733826
[Epoch 1, Batch 500] loss: 1.107752605676651
[Epoch 1, Batch 600] loss: 0.725073199570179
[Epoch 1, Batch 700] loss: 0.5557199117541313
[Epoch 1, Batch 800] loss: 0.5320783367753029
[Epoch 1, Batch 900] loss: 0.4740805678069592
[Epoch 1, Batch 1000] loss: 0.43179258078336713
[Epoch 1, Batch 1100] loss: 0.41353887610137463
[Epoch 1, Batch 1200] loss: 0.37668669030070306
[Epoch 1, Batch 1300] loss: 0.3036902390047908
[Epoch 1, Batch 1400] loss: 0.3296534181758761
[Epoch 1, Batch 1500] loss: 0.2764280361309648
[Epoch 1, Batch 1600] loss: 0.2546314707584679
[Epoch 1, Batch 1700] loss: 0.27019018076360224
[Epoch 1, Batch 1800] loss: 0.20426373353227972
[Epoch 1, Batch 1900] loss: 0.23774346989579498
[Epoch 1, Batch 2000] loss: 0.2162129838578403
[Epoch 1, Batch 2100] loss: 0.20140409513376653
[Epoch 1, Batch 2200] loss: 0.18961891195736824
[Epoch 1, Batch 2300] loss: 0.1799056527018547
[Epoch 1, Batch 2400] loss: 0.18906106465496123
[Epoch 1, Batch 2500] loss: 0.17980336900800467
[Epoch 1, Batch 2600] loss: 0.16719470315612853
[Epoch 1, Batch 2700] loss: 0.1490575086977333
[Epoch 1, Batch 2800] loss: 0.15097484027966857
[Epoch 1, Batch 2900] loss: 0.16280772997066378
[Epoch 1, Batch 3000] loss: 0.16168986706063151
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1331
Validation Accuracy: 0.9577
Overfitting: 0.1331
Best model saved at epoch 1 with validation loss: 0.1331
[Epoch 2, Batch 100] loss: 0.1632316729426384
[Epoch 2, Batch 200] loss: 0.13085772264748813
[Epoch 2, Batch 300] loss: 0.12522216856479645
[Epoch 2, Batch 400] loss: 0.1364864035276696
[Epoch 2, Batch 500] loss: 0.15290774330496787
[Epoch 2, Batch 600] loss: 0.11889043564442545
[Epoch 2, Batch 700] loss: 0.14016396068036557
[Epoch 2, Batch 800] loss: 0.11095767684280872
[Epoch 2, Batch 900] loss: 0.1296012602234259
[Epoch 2, Batch 1000] loss: 0.11913901256164536
[Epoch 2, Batch 1100] loss: 0.14300703505985438
[Epoch 2, Batch 1200] loss: 0.11985905035864562
[Epoch 2, Batch 1300] loss: 0.11395048946375028
[Epoch 2, Batch 1400] loss: 0.11628368668723851
[Epoch 2, Batch 1500] loss: 0.10792378385318444
[Epoch 2, Batch 1600] loss: 0.10536297147395089
[Epoch 2, Batch 1700] loss: 0.1343357977247797
[Epoch 2, Batch 1800] loss: 0.11082421835046262
[Epoch 2, Batch 1900] loss: 0.0961158765759319
[Epoch 2, Batch 2000] loss: 0.10379804796539246
[Epoch 2, Batch 2100] loss: 0.11970176922855899
[Epoch 2, Batch 2200] loss: 0.09514534594025463
[Epoch 2, Batch 2300] loss: 0.09243075549486093
[Epoch 2, Batch 2400] loss: 0.09155015085823834
[Epoch 2, Batch 2500] loss: 0.09126515765907244
[Epoch 2, Batch 2600] loss: 0.08383691941853613
[Epoch 2, Batch 2700] loss: 0.10472801754018292
[Epoch 2, Batch 2800] loss: 0.11291775578050874
[Epoch 2, Batch 2900] loss: 0.08731923652114347
[Epoch 2, Batch 3000] loss: 0.09454765212954953
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1003
Validation Accuracy: 0.9687
Overfitting: 0.1003
Best model saved at epoch 2 with validation loss: 0.1003
[Epoch 3, Batch 100] loss: 0.0934964049467817
[Epoch 3, Batch 200] loss: 0.09074159701005556
[Epoch 3, Batch 300] loss: 0.0791211511171423
[Epoch 3, Batch 400] loss: 0.08814335266361013
[Epoch 3, Batch 500] loss: 0.08142625199165195
[Epoch 3, Batch 600] loss: 0.06223583893966861
[Epoch 3, Batch 700] loss: 0.08510875978972762
[Epoch 3, Batch 800] loss: 0.09185828022134956
[Epoch 3, Batch 900] loss: 0.07631762573029846
[Epoch 3, Batch 1000] loss: 0.1039784657547716
[Epoch 3, Batch 1100] loss: 0.07275877130450681
[Epoch 3, Batch 1200] loss: 0.10595151641406118
[Epoch 3, Batch 1300] loss: 0.0930084415175952
[Epoch 3, Batch 1400] loss: 0.07469028356019408
[Epoch 3, Batch 1500] loss: 0.08364927949965932
[Epoch 3, Batch 1600] loss: 0.08170473541365936
[Epoch 3, Batch 1700] loss: 0.08053399371914566
[Epoch 3, Batch 1800] loss: 0.08356982658733614
[Epoch 3, Batch 1900] loss: 0.07804872105130926
[Epoch 3, Batch 2000] loss: 0.07555575757520273
[Epoch 3, Batch 2100] loss: 0.08669123645464424
[Epoch 3, Batch 2200] loss: 0.06477104572753888
[Epoch 3, Batch 2300] loss: 0.07926419820170849
[Epoch 3, Batch 2400] loss: 0.07621209453674965
[Epoch 3, Batch 2500] loss: 0.08217655238579027
[Epoch 3, Batch 2600] loss: 0.06091961356461979
[Epoch 3, Batch 2700] loss: 0.0623203625890892
[Epoch 3, Batch 2800] loss: 0.07342435962404124
[Epoch 3, Batch 2900] loss: 0.08697245544753969
[Epoch 3, Batch 3000] loss: 0.07540078109595924
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0812
Validation Accuracy: 0.9743
Overfitting: 0.0812
Best model saved at epoch 3 with validation loss: 0.0812
[Epoch 4, Batch 100] loss: 0.06827521661762148
[Epoch 4, Batch 200] loss: 0.052777134750504044
[Epoch 4, Batch 300] loss: 0.0748576395388227
[Epoch 4, Batch 400] loss: 0.07212738387752324
[Epoch 4, Batch 500] loss: 0.08596990782767534
[Epoch 4, Batch 600] loss: 0.05241103650303557
[Epoch 4, Batch 700] loss: 0.07592748584982473
[Epoch 4, Batch 800] loss: 0.07246517191641033
[Epoch 4, Batch 900] loss: 0.056152870596270076
[Epoch 4, Batch 1000] loss: 0.07066723563650157
[Epoch 4, Batch 1100] loss: 0.06282464733230882
[Epoch 4, Batch 1200] loss: 0.0658698176627513
[Epoch 4, Batch 1300] loss: 0.06361000056611374
[Epoch 4, Batch 1400] loss: 0.07482269396190531
[Epoch 4, Batch 1500] loss: 0.057727881263708695
[Epoch 4, Batch 1600] loss: 0.06934112100978382
[Epoch 4, Batch 1700] loss: 0.06620549169369042
[Epoch 4, Batch 1800] loss: 0.07169001198839396
[Epoch 4, Batch 1900] loss: 0.08656294439919293
[Epoch 4, Batch 2000] loss: 0.055756734265014526
[Epoch 4, Batch 2100] loss: 0.05630257097014692
[Epoch 4, Batch 2200] loss: 0.0552963994408492
[Epoch 4, Batch 2300] loss: 0.04428705782542238
[Epoch 4, Batch 2400] loss: 0.06786076603457332
[Epoch 4, Batch 2500] loss: 0.07782564969791565
[Epoch 4, Batch 2600] loss: 0.06890785325842444
[Epoch 4, Batch 2700] loss: 0.06262171790935099
[Epoch 4, Batch 2800] loss: 0.06059280802961439
[Epoch 4, Batch 2900] loss: 0.05819176763296127
[Epoch 4, Batch 3000] loss: 0.0609974280820461
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0634
Validation Accuracy: 0.9795
Overfitting: 0.0634
Best model saved at epoch 4 with validation loss: 0.0634
[Epoch 5, Batch 100] loss: 0.058052787058404644
[Epoch 5, Batch 200] loss: 0.05960832553493674
[Epoch 5, Batch 300] loss: 0.062314932174631396
[Epoch 5, Batch 400] loss: 0.043602984685567205
[Epoch 5, Batch 500] loss: 0.04060954709246289
[Epoch 5, Batch 600] loss: 0.05019401916011702
[Epoch 5, Batch 700] loss: 0.04508029018848902
[Epoch 5, Batch 800] loss: 0.07487507555255433
[Epoch 5, Batch 900] loss: 0.05707829888095148
[Epoch 5, Batch 1000] loss: 0.06025462292949669
[Epoch 5, Batch 1100] loss: 0.05278926790459081
[Epoch 5, Batch 1200] loss: 0.0540725048611057
[Epoch 5, Batch 1300] loss: 0.067404241488548
[Epoch 5, Batch 1400] loss: 0.054261425032746044
[Epoch 5, Batch 1500] loss: 0.039699612318072466
[Epoch 5, Batch 1600] loss: 0.05898064341425197
[Epoch 5, Batch 1700] loss: 0.052679503329854924
[Epoch 5, Batch 1800] loss: 0.06894167844904586
[Epoch 5, Batch 1900] loss: 0.060512673545163126
[Epoch 5, Batch 2000] loss: 0.05765578336664476
[Epoch 5, Batch 2100] loss: 0.04988821019011084
[Epoch 5, Batch 2200] loss: 0.05197500527719967
[Epoch 5, Batch 2300] loss: 0.057337310070870444
[Epoch 5, Batch 2400] loss: 0.06262987001391593
[Epoch 5, Batch 2500] loss: 0.05837073104310548
[Epoch 5, Batch 2600] loss: 0.035694873855100014
[Epoch 5, Batch 2700] loss: 0.04806798569567036
[Epoch 5, Batch 2800] loss: 0.04162434018973727
[Epoch 5, Batch 2900] loss: 0.054456206551403735
[Epoch 5, Batch 3000] loss: 0.042274543053645176
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0611
Validation Accuracy: 0.9808
Overfitting: 0.0611
Best model saved at epoch 5 with validation loss: 0.0611
[Epoch 6, Batch 100] loss: 0.03273218248039484
[Epoch 6, Batch 200] loss: 0.04636696300032781
[Epoch 6, Batch 300] loss: 0.04516312405845383
[Epoch 6, Batch 400] loss: 0.0363206891680602
[Epoch 6, Batch 500] loss: 0.04084629951074021
[Epoch 6, Batch 600] loss: 0.05467321093310602
[Epoch 6, Batch 700] loss: 0.04900877642794512
[Epoch 6, Batch 800] loss: 0.044395208399510014
[Epoch 6, Batch 900] loss: 0.053852938802738205
[Epoch 6, Batch 1000] loss: 0.04581119116104673
[Epoch 6, Batch 1100] loss: 0.043110007726354524
[Epoch 6, Batch 1200] loss: 0.0324277325568255
[Epoch 6, Batch 1300] loss: 0.04422463300448726
[Epoch 6, Batch 1400] loss: 0.0351315085891838
[Epoch 6, Batch 1500] loss: 0.04178338719153544
[Epoch 6, Batch 1600] loss: 0.042496543707966336
[Epoch 6, Batch 1700] loss: 0.054045397102599965
[Epoch 6, Batch 1800] loss: 0.04240885029168567
[Epoch 6, Batch 1900] loss: 0.05028933424575371
[Epoch 6, Batch 2000] loss: 0.04989216728921747
[Epoch 6, Batch 2100] loss: 0.03380462431669003
[Epoch 6, Batch 2200] loss: 0.06650217826521838
[Epoch 6, Batch 2300] loss: 0.049748258978361264
[Epoch 6, Batch 2400] loss: 0.0529662969041965
[Epoch 6, Batch 2500] loss: 0.041466029892471855
[Epoch 6, Batch 2600] loss: 0.06311620998079888
[Epoch 6, Batch 2700] loss: 0.05193733537918888
[Epoch 6, Batch 2800] loss: 0.055434828032448424
[Epoch 6, Batch 2900] loss: 0.04356177964407834
[Epoch 6, Batch 3000] loss: 0.042289640010276346
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9800
Overfitting: 0.0608
Best model saved at epoch 6 with validation loss: 0.0608
[Epoch 7, Batch 100] loss: 0.029123777400527615
[Epoch 7, Batch 200] loss: 0.025412107726733666
[Epoch 7, Batch 300] loss: 0.026524579769466074
[Epoch 7, Batch 400] loss: 0.05813596572610549
[Epoch 7, Batch 500] loss: 0.03507365928424406
[Epoch 7, Batch 600] loss: 0.03476427101049921
[Epoch 7, Batch 700] loss: 0.03435550154943485
[Epoch 7, Batch 800] loss: 0.0541446033937973
[Epoch 7, Batch 900] loss: 0.03167934434080962
[Epoch 7, Batch 1000] loss: 0.04997520744589565
[Epoch 7, Batch 1100] loss: 0.04346301752491854
[Epoch 7, Batch 1200] loss: 0.043291018164309206
[Epoch 7, Batch 1300] loss: 0.03221134013918345
[Epoch 7, Batch 1400] loss: 0.03326184236721019
[Epoch 7, Batch 1500] loss: 0.042959984488552434
[Epoch 7, Batch 1600] loss: 0.04133980850878288
[Epoch 7, Batch 1700] loss: 0.03956750095851021
[Epoch 7, Batch 1800] loss: 0.042098615643189986
[Epoch 7, Batch 1900] loss: 0.033135855748259925
[Epoch 7, Batch 2000] loss: 0.03989468382264022
[Epoch 7, Batch 2100] loss: 0.02168317949588527
[Epoch 7, Batch 2200] loss: 0.04379760206131323
[Epoch 7, Batch 2300] loss: 0.04495153142735944
[Epoch 7, Batch 2400] loss: 0.029717910947510973
[Epoch 7, Batch 2500] loss: 0.055214595961952
[Epoch 7, Batch 2600] loss: 0.049913710292021275
[Epoch 7, Batch 2700] loss: 0.04362404451792827
[Epoch 7, Batch 2800] loss: 0.0512730102284695
[Epoch 7, Batch 2900] loss: 0.04196125568385469
[Epoch 7, Batch 3000] loss: 0.04139380924054421
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9832
Overfitting: 0.0537
Best model saved at epoch 7 with validation loss: 0.0537
[Epoch 8, Batch 100] loss: 0.05536858519568341
[Epoch 8, Batch 200] loss: 0.037533722129301166
[Epoch 8, Batch 300] loss: 0.027532127945451065
[Epoch 8, Batch 400] loss: 0.028555822953931057
[Epoch 8, Batch 500] loss: 0.03247410341893556
[Epoch 8, Batch 600] loss: 0.045091471265186554
[Epoch 8, Batch 700] loss: 0.028906703827524326
[Epoch 8, Batch 800] loss: 0.026523746135499095
[Epoch 8, Batch 900] loss: 0.026535942812042777
[Epoch 8, Batch 1000] loss: 0.04203821458024322
[Epoch 8, Batch 1100] loss: 0.0418378854788898
[Epoch 8, Batch 1200] loss: 0.03002846841540304
[Epoch 8, Batch 1300] loss: 0.04594048788741929
[Epoch 8, Batch 1400] loss: 0.033954825798864476
[Epoch 8, Batch 1500] loss: 0.035037449538940564
[Epoch 8, Batch 1600] loss: 0.025646337574144126
[Epoch 8, Batch 1700] loss: 0.04326971873117145
[Epoch 8, Batch 1800] loss: 0.04133715174357348
[Epoch 8, Batch 1900] loss: 0.03186121880979045
[Epoch 8, Batch 2000] loss: 0.0414393375031068
[Epoch 8, Batch 2100] loss: 0.0385137754092284
[Epoch 8, Batch 2200] loss: 0.03183159850566881
[Epoch 8, Batch 2300] loss: 0.03375305031891912
[Epoch 8, Batch 2400] loss: 0.03463143249799032
[Epoch 8, Batch 2500] loss: 0.031123309867107308
[Epoch 8, Batch 2600] loss: 0.0351848817469363
[Epoch 8, Batch 2700] loss: 0.029504786502657226
[Epoch 8, Batch 2800] loss: 0.030933104582072702
[Epoch 8, Batch 2900] loss: 0.045813906451585354
[Epoch 8, Batch 3000] loss: 0.03436909972151625
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9847
Overfitting: 0.0522
Best model saved at epoch 8 with validation loss: 0.0522
[Epoch 9, Batch 100] loss: 0.026985440560092683
[Epoch 9, Batch 200] loss: 0.03676297742145834
[Epoch 9, Batch 300] loss: 0.022656631170102626
[Epoch 9, Batch 400] loss: 0.026416536877222827
[Epoch 9, Batch 500] loss: 0.03755928087848588
[Epoch 9, Batch 600] loss: 0.03295640468146303
[Epoch 9, Batch 700] loss: 0.026122252475688584
[Epoch 9, Batch 800] loss: 0.023832350970915284
[Epoch 9, Batch 900] loss: 0.025327865418221338
[Epoch 9, Batch 1000] loss: 0.03134386915793584
[Epoch 9, Batch 1100] loss: 0.034307344717381054
[Epoch 9, Batch 1200] loss: 0.026789307280268987
[Epoch 9, Batch 1300] loss: 0.022872292322099384
[Epoch 9, Batch 1400] loss: 0.030375981651523033
[Epoch 9, Batch 1500] loss: 0.03386905433115316
[Epoch 9, Batch 1600] loss: 0.045361145244824
[Epoch 9, Batch 1700] loss: 0.02556445009438903
[Epoch 9, Batch 1800] loss: 0.020107117558691243
[Epoch 9, Batch 1900] loss: 0.032896959622012216
[Epoch 9, Batch 2000] loss: 0.0333476609144418
[Epoch 9, Batch 2100] loss: 0.02861900753880036
[Epoch 9, Batch 2200] loss: 0.039236369015052334
[Epoch 9, Batch 2300] loss: 0.025246723453383312
[Epoch 9, Batch 2400] loss: 0.02522036194241082
[Epoch 9, Batch 2500] loss: 0.03993981670879293
[Epoch 9, Batch 2600] loss: 0.035586797204960025
[Epoch 9, Batch 2700] loss: 0.03698512023111107
[Epoch 9, Batch 2800] loss: 0.03173290162565536
[Epoch 9, Batch 2900] loss: 0.034078488026279954
[Epoch 9, Batch 3000] loss: 0.02779800796924974
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9823
Overfitting: 0.0540
[Epoch 10, Batch 100] loss: 0.022602832466582186
[Epoch 10, Batch 200] loss: 0.03359382354647096
[Epoch 10, Batch 300] loss: 0.038409303348889805
[Epoch 10, Batch 400] loss: 0.01981404314210522
[Epoch 10, Batch 500] loss: 0.03211407339604193
[Epoch 10, Batch 600] loss: 0.023661106902818575
[Epoch 10, Batch 700] loss: 0.026231635753647425
[Epoch 10, Batch 800] loss: 0.0165382362465607
[Epoch 10, Batch 900] loss: 0.021083188629345388
[Epoch 10, Batch 1000] loss: 0.023656218455034832
[Epoch 10, Batch 1100] loss: 0.022210790831995838
[Epoch 10, Batch 1200] loss: 0.01593090170645155
[Epoch 10, Batch 1300] loss: 0.0385065518349802
[Epoch 10, Batch 1400] loss: 0.0256619092047913
[Epoch 10, Batch 1500] loss: 0.031166492879056023
[Epoch 10, Batch 1600] loss: 0.019568947973730245
[Epoch 10, Batch 1700] loss: 0.027641710092102586
[Epoch 10, Batch 1800] loss: 0.025908189031815708
[Epoch 10, Batch 1900] loss: 0.014106910525952117
[Epoch 10, Batch 2000] loss: 0.03216801462964213
[Epoch 10, Batch 2100] loss: 0.030136837273385026
[Epoch 10, Batch 2200] loss: 0.0427951909773401
[Epoch 10, Batch 2300] loss: 0.023316243832960028
[Epoch 10, Batch 2400] loss: 0.02753947333942051
[Epoch 10, Batch 2500] loss: 0.05475150850921637
[Epoch 10, Batch 2600] loss: 0.026581520654726774
[Epoch 10, Batch 2700] loss: 0.016370799290307332
[Epoch 10, Batch 2800] loss: 0.03999566444974335
[Epoch 10, Batch 2900] loss: 0.02693310996175569
[Epoch 10, Batch 3000] loss: 0.02036850429387414
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9836
Overfitting: 0.0514
Best model saved at epoch 10 with validation loss: 0.0514
[Epoch 11, Batch 100] loss: 0.02284796427076799
[Epoch 11, Batch 200] loss: 0.012887488985252276
[Epoch 11, Batch 300] loss: 0.018482203311141348
[Epoch 11, Batch 400] loss: 0.015643620332266437
[Epoch 11, Batch 500] loss: 0.022916864887738485
[Epoch 11, Batch 600] loss: 0.027103498794749614
[Epoch 11, Batch 700] loss: 0.021627282502959134
[Epoch 11, Batch 800] loss: 0.02205092305201106
[Epoch 11, Batch 900] loss: 0.016508425908214122
[Epoch 11, Batch 1000] loss: 0.01840330134398755
[Epoch 11, Batch 1100] loss: 0.03991228572449472
[Epoch 11, Batch 1200] loss: 0.027383156604337273
[Epoch 11, Batch 1300] loss: 0.020160818187796394
[Epoch 11, Batch 1400] loss: 0.021153039179189363
[Epoch 11, Batch 1500] loss: 0.016481225789939345
[Epoch 11, Batch 1600] loss: 0.02759846929970081
[Epoch 11, Batch 1700] loss: 0.02291597308927521
[Epoch 11, Batch 1800] loss: 0.02740257028437554
[Epoch 11, Batch 1900] loss: 0.03286980286859034
[Epoch 11, Batch 2000] loss: 0.02991836206318112
[Epoch 11, Batch 2100] loss: 0.03437139875059074
[Epoch 11, Batch 2200] loss: 0.018929017975351597
[Epoch 11, Batch 2300] loss: 0.019999419413798025
[Epoch 11, Batch 2400] loss: 0.019128480551444227
[Epoch 11, Batch 2500] loss: 0.017523096751356205
[Epoch 11, Batch 2600] loss: 0.02994706604076782
[Epoch 11, Batch 2700] loss: 0.030494681829150067
[Epoch 11, Batch 2800] loss: 0.02311938022285176
[Epoch 11, Batch 2900] loss: 0.024694705080328276
[Epoch 11, Batch 3000] loss: 0.02625330539922288
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9828
Overfitting: 0.0510
Best model saved at epoch 11 with validation loss: 0.0510
[Epoch 12, Batch 100] loss: 0.02145597313199687
[Epoch 12, Batch 200] loss: 0.01841460286097572
[Epoch 12, Batch 300] loss: 0.01617405913451876
[Epoch 12, Batch 400] loss: 0.014565005074728106
[Epoch 12, Batch 500] loss: 0.020678849643154536
[Epoch 12, Batch 600] loss: 0.018767327870409644
[Epoch 12, Batch 700] loss: 0.013973864327854245
[Epoch 12, Batch 800] loss: 0.020234399811906768
[Epoch 12, Batch 900] loss: 0.023682862119167113
[Epoch 12, Batch 1000] loss: 0.02664982734597288
[Epoch 12, Batch 1100] loss: 0.02405203552181774
[Epoch 12, Batch 1200] loss: 0.024612203931392285
[Epoch 12, Batch 1300] loss: 0.01956930809876212
[Epoch 12, Batch 1400] loss: 0.024566397120161128
[Epoch 12, Batch 1500] loss: 0.011057621064246632
[Epoch 12, Batch 1600] loss: 0.025243278072885005
[Epoch 12, Batch 1700] loss: 0.017854740596740158
[Epoch 12, Batch 1800] loss: 0.030238664329044696
[Epoch 12, Batch 1900] loss: 0.0143617691738109
[Epoch 12, Batch 2000] loss: 0.019189245149354973
[Epoch 12, Batch 2100] loss: 0.01737946752416974
[Epoch 12, Batch 2200] loss: 0.023317999384926225
[Epoch 12, Batch 2300] loss: 0.0220183261465354
[Epoch 12, Batch 2400] loss: 0.02228144772230735
[Epoch 12, Batch 2500] loss: 0.025707331528537908
[Epoch 12, Batch 2600] loss: 0.02291270406123658
[Epoch 12, Batch 2700] loss: 0.014961301597486454
[Epoch 12, Batch 2800] loss: 0.018917318640501436
[Epoch 12, Batch 2900] loss: 0.017122988681785502
[Epoch 12, Batch 3000] loss: 0.03713574043569679
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9849
Overfitting: 0.0483
Best model saved at epoch 12 with validation loss: 0.0483
[Epoch 13, Batch 100] loss: 0.014736057180562057
[Epoch 13, Batch 200] loss: 0.013158254168283747
[Epoch 13, Batch 300] loss: 0.020172984110249672
[Epoch 13, Batch 400] loss: 0.01640643113380065
[Epoch 13, Batch 500] loss: 0.018017601858118723
[Epoch 13, Batch 600] loss: 0.01578993656552484
[Epoch 13, Batch 700] loss: 0.0289001720275337
[Epoch 13, Batch 800] loss: 0.015190946289330896
[Epoch 13, Batch 900] loss: 0.013909636288954062
[Epoch 13, Batch 1000] loss: 0.025239033640755224
[Epoch 13, Batch 1100] loss: 0.016273269233679458
[Epoch 13, Batch 1200] loss: 0.017170949669816762
[Epoch 13, Batch 1300] loss: 0.018814068215706355
[Epoch 13, Batch 1400] loss: 0.011592760796065704
[Epoch 13, Batch 1500] loss: 0.02667923094566504
[Epoch 13, Batch 1600] loss: 0.020875697281735484
[Epoch 13, Batch 1700] loss: 0.01911896888341289
[Epoch 13, Batch 1800] loss: 0.011582467684784206
[Epoch 13, Batch 1900] loss: 0.018363725867093308
[Epoch 13, Batch 2000] loss: 0.025964510635021726
[Epoch 13, Batch 2100] loss: 0.017174167958801265
[Epoch 13, Batch 2200] loss: 0.02048683179273212
[Epoch 13, Batch 2300] loss: 0.023918801827958306
[Epoch 13, Batch 2400] loss: 0.015929176011704838
[Epoch 13, Batch 2500] loss: 0.018562001042519115
[Epoch 13, Batch 2600] loss: 0.01619804911671963
[Epoch 13, Batch 2700] loss: 0.013652150640500621
[Epoch 13, Batch 2800] loss: 0.03158779160810809
[Epoch 13, Batch 2900] loss: 0.015962372928725016
[Epoch 13, Batch 3000] loss: 0.01577290375301345
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9862
Overfitting: 0.0475
Best model saved at epoch 13 with validation loss: 0.0475
[Epoch 14, Batch 100] loss: 0.014838290926854824
[Epoch 14, Batch 200] loss: 0.021868499033516856
[Epoch 14, Batch 300] loss: 0.014637018097619147
[Epoch 14, Batch 400] loss: 0.01701617097354756
[Epoch 14, Batch 500] loss: 0.015793812121701195
[Epoch 14, Batch 600] loss: 0.026476614147632062
[Epoch 14, Batch 700] loss: 0.009463122033739637
[Epoch 14, Batch 800] loss: 0.0108895158391897
[Epoch 14, Batch 900] loss: 0.013534758283931296
[Epoch 14, Batch 1000] loss: 0.025102669015941503
[Epoch 14, Batch 1100] loss: 0.01603392709637774
[Epoch 14, Batch 1200] loss: 0.022187907785441895
[Epoch 14, Batch 1300] loss: 0.02627597296052045
[Epoch 14, Batch 1400] loss: 0.01772235964812353
[Epoch 14, Batch 1500] loss: 0.017828256543853057
[Epoch 14, Batch 1600] loss: 0.012238207052278086
[Epoch 14, Batch 1700] loss: 0.02227956802053086
[Epoch 14, Batch 1800] loss: 0.014796279712381875
[Epoch 14, Batch 1900] loss: 0.011230758688168408
[Epoch 14, Batch 2000] loss: 0.012286544151829731
[Epoch 14, Batch 2100] loss: 0.017713081883985068
[Epoch 14, Batch 2200] loss: 0.01551681409620869
[Epoch 14, Batch 2300] loss: 0.016054827335137814
[Epoch 14, Batch 2400] loss: 0.013182323273613293
[Epoch 14, Batch 2500] loss: 0.01445671457609933
[Epoch 14, Batch 2600] loss: 0.013063829138254733
[Epoch 14, Batch 2700] loss: 0.016822667018059293
[Epoch 14, Batch 2800] loss: 0.023511815130259493
[Epoch 14, Batch 2900] loss: 0.020743720113005112
[Epoch 14, Batch 3000] loss: 0.016224539427130365
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9872
Overfitting: 0.0462
Best model saved at epoch 14 with validation loss: 0.0462
[Epoch 15, Batch 100] loss: 0.010033291235777142
[Epoch 15, Batch 200] loss: 0.016506171217263273
[Epoch 15, Batch 300] loss: 0.011871062539503327
[Epoch 15, Batch 400] loss: 0.0065050317006671325
[Epoch 15, Batch 500] loss: 0.019018542466765213
[Epoch 15, Batch 600] loss: 0.012761772239373385
[Epoch 15, Batch 700] loss: 0.022374519321710976
[Epoch 15, Batch 800] loss: 0.015157110754735185
[Epoch 15, Batch 900] loss: 0.010754158300187555
[Epoch 15, Batch 1000] loss: 0.013400664298023912
[Epoch 15, Batch 1100] loss: 0.013369696020581613
[Epoch 15, Batch 1200] loss: 0.016272060414339647
[Epoch 15, Batch 1300] loss: 0.019496815119996427
[Epoch 15, Batch 1400] loss: 0.010114889962478628
[Epoch 15, Batch 1500] loss: 0.011783477019644124
[Epoch 15, Batch 1600] loss: 0.01262859288141044
[Epoch 15, Batch 1700] loss: 0.017632708184755756
[Epoch 15, Batch 1800] loss: 0.007568243701489337
[Epoch 15, Batch 1900] loss: 0.016856803846876572
[Epoch 15, Batch 2000] loss: 0.021999858173412577
[Epoch 15, Batch 2100] loss: 0.010911767543093446
[Epoch 15, Batch 2200] loss: 0.017251373768067423
[Epoch 15, Batch 2300] loss: 0.014966680941643062
[Epoch 15, Batch 2400] loss: 0.019659885069249868
[Epoch 15, Batch 2500] loss: 0.024023158947111368
[Epoch 15, Batch 2600] loss: 0.019182463567267403
[Epoch 15, Batch 2700] loss: 0.017537222157952784
[Epoch 15, Batch 2800] loss: 0.03461740505816124
[Epoch 15, Batch 2900] loss: 0.010267870710140414
[Epoch 15, Batch 3000] loss: 0.014869265011939206
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9845
Overfitting: 0.0500
[Epoch 16, Batch 100] loss: 0.006431764014032524
[Epoch 16, Batch 200] loss: 0.007896930585666269
[Epoch 16, Batch 300] loss: 0.018908593561745873
[Epoch 16, Batch 400] loss: 0.00792106553526537
[Epoch 16, Batch 500] loss: 0.017773600295467987
[Epoch 16, Batch 600] loss: 0.009377995825680045
[Epoch 16, Batch 700] loss: 0.011158407786278985
[Epoch 16, Batch 800] loss: 0.010637052402125846
[Epoch 16, Batch 900] loss: 0.010342402554597356
[Epoch 16, Batch 1000] loss: 0.00928369147773992
[Epoch 16, Batch 1100] loss: 0.009162208675843431
[Epoch 16, Batch 1200] loss: 0.010090961591727137
[Epoch 16, Batch 1300] loss: 0.009978320213999723
[Epoch 16, Batch 1400] loss: 0.006831497391222002
[Epoch 16, Batch 1500] loss: 0.01641546987744732
[Epoch 16, Batch 1600] loss: 0.011805873779703688
[Epoch 16, Batch 1700] loss: 0.010385235321846266
[Epoch 16, Batch 1800] loss: 0.011762593895573445
[Epoch 16, Batch 1900] loss: 0.028410413439942203
[Epoch 16, Batch 2000] loss: 0.009188954801593353
[Epoch 16, Batch 2100] loss: 0.011514886464606206
[Epoch 16, Batch 2200] loss: 0.023790308968400495
[Epoch 16, Batch 2300] loss: 0.01771119145283592
[Epoch 16, Batch 2400] loss: 0.008888964946308989
[Epoch 16, Batch 2500] loss: 0.020275977327273723
[Epoch 16, Batch 2600] loss: 0.01003314824136396
[Epoch 16, Batch 2700] loss: 0.007576130291199661
[Epoch 16, Batch 2800] loss: 0.009158305745750113
[Epoch 16, Batch 2900] loss: 0.01127216467717517
[Epoch 16, Batch 3000] loss: 0.023208420812061377
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0588
Validation Accuracy: 0.9837
Overfitting: 0.0588
[Epoch 17, Batch 100] loss: 0.008686260141566891
[Epoch 17, Batch 200] loss: 0.005531849994385993
[Epoch 17, Batch 300] loss: 0.009968818621296123
[Epoch 17, Batch 400] loss: 0.004836868896654778
[Epoch 17, Batch 500] loss: 0.010286059888021554
[Epoch 17, Batch 600] loss: 0.008034046502132242
[Epoch 17, Batch 700] loss: 0.011532965528599561
[Epoch 17, Batch 800] loss: 0.012154792473493216
[Epoch 17, Batch 900] loss: 0.01753300362072878
[Epoch 17, Batch 1000] loss: 0.01195264884039716
[Epoch 17, Batch 1100] loss: 0.009406083798694453
[Epoch 17, Batch 1200] loss: 0.007185136096813949
[Epoch 17, Batch 1300] loss: 0.008296435799265964
[Epoch 17, Batch 1400] loss: 0.018172092404029172
[Epoch 17, Batch 1500] loss: 0.012441420472196114
[Epoch 17, Batch 1600] loss: 0.0075295050290969815
[Epoch 17, Batch 1700] loss: 0.009109966500295741
[Epoch 17, Batch 1800] loss: 0.03118717488895527
[Epoch 17, Batch 1900] loss: 0.011289077679832645
[Epoch 17, Batch 2000] loss: 0.016812350401969524
[Epoch 17, Batch 2100] loss: 0.012381791192692617
[Epoch 17, Batch 2200] loss: 0.010920326374371143
[Epoch 17, Batch 2300] loss: 0.012747198147903873
[Epoch 17, Batch 2400] loss: 0.01209233188464168
[Epoch 17, Batch 2500] loss: 0.015226021438134013
[Epoch 17, Batch 2600] loss: 0.011468866564719064
[Epoch 17, Batch 2700] loss: 0.012420103449094312
[Epoch 17, Batch 2800] loss: 0.0133895704562201
[Epoch 17, Batch 2900] loss: 0.010866502982325983
[Epoch 17, Batch 3000] loss: 0.030422646819533838
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9835
Overfitting: 0.0523
[Epoch 18, Batch 100] loss: 0.012517180052800541
[Epoch 18, Batch 200] loss: 0.013315982878502837
[Epoch 18, Batch 300] loss: 0.01058426416155271
[Epoch 18, Batch 400] loss: 0.003498591683619452
[Epoch 18, Batch 500] loss: 0.008364037521932915
[Epoch 18, Batch 600] loss: 0.00866535251007008
[Epoch 18, Batch 700] loss: 0.0068252481282786446
[Epoch 18, Batch 800] loss: 0.011649265336824328
[Epoch 18, Batch 900] loss: 0.014556256683517859
[Epoch 18, Batch 1000] loss: 0.012368468607719478
[Epoch 18, Batch 1100] loss: 0.00664779923831702
[Epoch 18, Batch 1200] loss: 0.010807758005562391
[Epoch 18, Batch 1300] loss: 0.010887234030848276
[Epoch 18, Batch 1400] loss: 0.010232246143932571
[Epoch 18, Batch 1500] loss: 0.012021605138475024
[Epoch 18, Batch 1600] loss: 0.015763961806956103
[Epoch 18, Batch 1700] loss: 0.01471958393291061
[Epoch 18, Batch 1800] loss: 0.01652429886805294
[Epoch 18, Batch 1900] loss: 0.006438130301835372
[Epoch 18, Batch 2000] loss: 0.009995087105362472
[Epoch 18, Batch 2100] loss: 0.012017062732634259
[Epoch 18, Batch 2200] loss: 0.005599832345992582
[Epoch 18, Batch 2300] loss: 0.008502475748223333
[Epoch 18, Batch 2400] loss: 0.011755974773136587
[Epoch 18, Batch 2500] loss: 0.012639364350688994
[Epoch 18, Batch 2600] loss: 0.00932519766859059
[Epoch 18, Batch 2700] loss: 0.013112997651751357
[Epoch 18, Batch 2800] loss: 0.012023069615970598
[Epoch 18, Batch 2900] loss: 0.009977622111745178
[Epoch 18, Batch 3000] loss: 0.01706955739768091
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0609
Validation Accuracy: 0.9818
Overfitting: 0.0609
[Epoch 19, Batch 100] loss: 0.0071443391627826714
[Epoch 19, Batch 200] loss: 0.01680947848895812
[Epoch 19, Batch 300] loss: 0.008643421312126521
[Epoch 19, Batch 400] loss: 0.006892815543669713
[Epoch 19, Batch 500] loss: 0.01199672599562291
[Epoch 19, Batch 600] loss: 0.00952707195012863
[Epoch 19, Batch 700] loss: 0.007089530645357627
[Epoch 19, Batch 800] loss: 0.005356114238684313
[Epoch 19, Batch 900] loss: 0.004243665070157476
[Epoch 19, Batch 1000] loss: 0.006292516001471995
[Epoch 19, Batch 1100] loss: 0.014203700593773192
[Epoch 19, Batch 1200] loss: 0.0064305720452193784
[Epoch 19, Batch 1300] loss: 0.010604184915055158
[Epoch 19, Batch 1400] loss: 0.010985222527028781
[Epoch 19, Batch 1500] loss: 0.008592137231025844
[Epoch 19, Batch 1600] loss: 0.012891113713035338
[Epoch 19, Batch 1700] loss: 0.016005989244595186
[Epoch 19, Batch 1800] loss: 0.012057123822633003
[Epoch 19, Batch 1900] loss: 0.013019994113856228
[Epoch 19, Batch 2000] loss: 0.00735817141892312
[Epoch 19, Batch 2100] loss: 0.01135069413531255
[Epoch 19, Batch 2200] loss: 0.006830290865882489
[Epoch 19, Batch 2300] loss: 0.004137038040084917
[Epoch 19, Batch 2400] loss: 0.010936354539867353
[Epoch 19, Batch 2500] loss: 0.01288020736926228
[Epoch 19, Batch 2600] loss: 0.006223889523507751
[Epoch 19, Batch 2700] loss: 0.0055544044636098985
[Epoch 19, Batch 2800] loss: 0.009841107634156288
[Epoch 19, Batch 2900] loss: 0.007443753360425944
[Epoch 19, Batch 3000] loss: 0.010121033316972899
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9864
Overfitting: 0.0489
[Epoch 20, Batch 100] loss: 0.0062023700142981395
[Epoch 20, Batch 200] loss: 0.008114830563322357
[Epoch 20, Batch 300] loss: 0.0035407115809044853
[Epoch 20, Batch 400] loss: 0.006159420471039994
[Epoch 20, Batch 500] loss: 0.010727965027165283
[Epoch 20, Batch 600] loss: 0.007270758592785569
[Epoch 20, Batch 700] loss: 0.007182256040405264
[Epoch 20, Batch 800] loss: 0.006709012812457331
[Epoch 20, Batch 900] loss: 0.005931117254258425
[Epoch 20, Batch 1000] loss: 0.012586963834648942
[Epoch 20, Batch 1100] loss: 0.007445729886467234
[Epoch 20, Batch 1200] loss: 0.004382043088746741
[Epoch 20, Batch 1300] loss: 0.0037574332950043752
[Epoch 20, Batch 1400] loss: 0.005656739897261787
[Epoch 20, Batch 1500] loss: 0.006710887597764667
[Epoch 20, Batch 1600] loss: 0.0049425304210762985
[Epoch 20, Batch 1700] loss: 0.004772942182710267
[Epoch 20, Batch 1800] loss: 0.010582233493800004
[Epoch 20, Batch 1900] loss: 0.0063741265675616885
[Epoch 20, Batch 2000] loss: 0.005328096216583162
[Epoch 20, Batch 2100] loss: 0.005080295707327878
[Epoch 20, Batch 2200] loss: 0.011960065120425724
[Epoch 20, Batch 2300] loss: 0.012206849802996658
[Epoch 20, Batch 2400] loss: 0.010954812370447087
[Epoch 20, Batch 2500] loss: 0.008739227430307892
[Epoch 20, Batch 2600] loss: 0.010609607994585985
[Epoch 20, Batch 2700] loss: 0.012176633623889757
[Epoch 20, Batch 2800] loss: 0.008040036880020125
[Epoch 20, Batch 2900] loss: 0.011207105873477303
[Epoch 20, Batch 3000] loss: 0.017370938452263545
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0530
Validation Accuracy: 0.9856
Overfitting: 0.0530
[Epoch 21, Batch 100] loss: 0.009096087824225378
[Epoch 21, Batch 200] loss: 0.00789106925222768
[Epoch 21, Batch 300] loss: 0.004745849398013888
[Epoch 21, Batch 400] loss: 0.0036860037259839372
[Epoch 21, Batch 500] loss: 0.0023711992507378455
[Epoch 21, Batch 600] loss: 0.012159002826153368
[Epoch 21, Batch 700] loss: 0.0033972342851393477
[Epoch 21, Batch 800] loss: 0.0057546299242903845
[Epoch 21, Batch 900] loss: 0.005929838259755797
[Epoch 21, Batch 1000] loss: 0.006144011408941878
[Epoch 21, Batch 1100] loss: 0.005104828476470402
[Epoch 21, Batch 1200] loss: 0.00739468763505215
[Epoch 21, Batch 1300] loss: 0.009041488252781846
[Epoch 21, Batch 1400] loss: 0.005193310602003294
[Epoch 21, Batch 1500] loss: 0.005291082573081667
[Epoch 21, Batch 1600] loss: 0.006978920786857543
[Epoch 21, Batch 1700] loss: 0.009605367593769643
[Epoch 21, Batch 1800] loss: 0.003907561507464834
[Epoch 21, Batch 1900] loss: 0.007411058861216588
[Epoch 21, Batch 2000] loss: 0.008373532146692923
[Epoch 21, Batch 2100] loss: 0.010057669135107972
[Epoch 21, Batch 2200] loss: 0.013515357571995991
[Epoch 21, Batch 2300] loss: 0.007441642344920183
[Epoch 21, Batch 2400] loss: 0.005227546696050922
[Epoch 21, Batch 2500] loss: 0.01215911155462436
[Epoch 21, Batch 2600] loss: 0.009796469685217062
[Epoch 21, Batch 2700] loss: 0.007041003731760611
[Epoch 21, Batch 2800] loss: 0.005849263009301922
[Epoch 21, Batch 2900] loss: 0.009619297043250298
[Epoch 21, Batch 3000] loss: 0.009280904464989135
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9871
Overfitting: 0.0474
[Epoch 22, Batch 100] loss: 0.0034158180440044816
[Epoch 22, Batch 200] loss: 0.004224296648101244
[Epoch 22, Batch 300] loss: 0.007689143925299504
[Epoch 22, Batch 400] loss: 0.005715334906140015
[Epoch 22, Batch 500] loss: 0.0075509723679761005
[Epoch 22, Batch 600] loss: 0.003742679141030294
[Epoch 22, Batch 700] loss: 0.004642830734492236
[Epoch 22, Batch 800] loss: 0.0033406354268680615
[Epoch 22, Batch 900] loss: 0.003048649778285153
[Epoch 22, Batch 1000] loss: 0.008634439245760177
[Epoch 22, Batch 1100] loss: 0.005608967584533957
[Epoch 22, Batch 1200] loss: 0.0055480190250409575
[Epoch 22, Batch 1300] loss: 0.00253910197406924
[Epoch 22, Batch 1400] loss: 0.015675156127017545
[Epoch 22, Batch 1500] loss: 0.0062146455718766445
[Epoch 22, Batch 1600] loss: 0.004430078752667441
[Epoch 22, Batch 1700] loss: 0.005887595022711026
[Epoch 22, Batch 1800] loss: 0.009725461073013548
[Epoch 22, Batch 1900] loss: 0.0052490866132416155
[Epoch 22, Batch 2000] loss: 0.010213284041385577
[Epoch 22, Batch 2100] loss: 0.003614798906201031
[Epoch 22, Batch 2200] loss: 0.003620150122177961
[Epoch 22, Batch 2300] loss: 0.0047632529023871936
[Epoch 22, Batch 2400] loss: 0.006292277553088752
[Epoch 22, Batch 2500] loss: 0.00583803357351826
[Epoch 22, Batch 2600] loss: 0.004214129610112423
[Epoch 22, Batch 2700] loss: 0.003736386424666307
[Epoch 22, Batch 2800] loss: 0.0067520584362898714
[Epoch 22, Batch 2900] loss: 0.011688561792051928
[Epoch 22, Batch 3000] loss: 0.009572987228758621
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0613
Validation Accuracy: 0.9842
Overfitting: 0.0613
[Epoch 23, Batch 100] loss: 0.005037610029821735
[Epoch 23, Batch 200] loss: 0.009132419890636356
[Epoch 23, Batch 300] loss: 0.0024482387882551393
[Epoch 23, Batch 400] loss: 0.0044451657788278
[Epoch 23, Batch 500] loss: 0.004976027995619461
[Epoch 23, Batch 600] loss: 0.010144951937695624
[Epoch 23, Batch 700] loss: 0.0087958081395891
[Epoch 23, Batch 800] loss: 0.0065887481088464026
[Epoch 23, Batch 900] loss: 0.0030488349036136243
[Epoch 23, Batch 1000] loss: 0.004668917217314288
[Epoch 23, Batch 1100] loss: 0.003620328522043792
[Epoch 23, Batch 1200] loss: 0.004041834120450858
[Epoch 23, Batch 1300] loss: 0.0065115172587718465
[Epoch 23, Batch 1400] loss: 0.009819825250028771
[Epoch 23, Batch 1500] loss: 0.00808997705914635
[Epoch 23, Batch 1600] loss: 0.0038851034401795916
[Epoch 23, Batch 1700] loss: 0.002652537868419813
[Epoch 23, Batch 1800] loss: 0.0034984187528266375
[Epoch 23, Batch 1900] loss: 0.006395784342348634
[Epoch 23, Batch 2000] loss: 0.007468861066167847
[Epoch 23, Batch 2100] loss: 0.013665380077661667
[Epoch 23, Batch 2200] loss: 0.00508614256344174
[Epoch 23, Batch 2300] loss: 0.008045785595730309
[Epoch 23, Batch 2400] loss: 0.003832022783630009
[Epoch 23, Batch 2500] loss: 0.0041166422901784475
[Epoch 23, Batch 2600] loss: 0.007325688984456065
[Epoch 23, Batch 2700] loss: 0.0029297274317787014
[Epoch 23, Batch 2800] loss: 0.006709081995629731
[Epoch 23, Batch 2900] loss: 0.004072430738161757
[Epoch 23, Batch 3000] loss: 0.004250498955990452
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9872
Overfitting: 0.0509
[Epoch 24, Batch 100] loss: 0.005730541105072007
[Epoch 24, Batch 200] loss: 0.0043316102284632054
[Epoch 24, Batch 300] loss: 0.0016025825916548798
[Epoch 24, Batch 400] loss: 0.008050621071267371
[Epoch 24, Batch 500] loss: 0.0019398828948152414
[Epoch 24, Batch 600] loss: 0.002642257415295717
[Epoch 24, Batch 700] loss: 0.0018682268590396235
[Epoch 24, Batch 800] loss: 0.001394495406441365
[Epoch 24, Batch 900] loss: 0.0016269553013765403
[Epoch 24, Batch 1000] loss: 0.0035980989488091806
[Epoch 24, Batch 1100] loss: 0.0012661145156977226
[Epoch 24, Batch 1200] loss: 0.004976242957386603
[Epoch 24, Batch 1300] loss: 0.005059228409955381
[Epoch 24, Batch 1400] loss: 0.004199119907630404
[Epoch 24, Batch 1500] loss: 0.002132583580633991
[Epoch 24, Batch 1600] loss: 0.0037578793262616726
[Epoch 24, Batch 1700] loss: 0.005080355916027202
[Epoch 24, Batch 1800] loss: 0.005312438654430878
[Epoch 24, Batch 1900] loss: 0.0036002372620846756
[Epoch 24, Batch 2000] loss: 0.0045738012382091145
[Epoch 24, Batch 2100] loss: 0.002046534053624782
[Epoch 24, Batch 2200] loss: 0.0022980348936329164
[Epoch 24, Batch 2300] loss: 0.002670966914720907
[Epoch 24, Batch 2400] loss: 0.00639549243585094
[Epoch 24, Batch 2500] loss: 0.00393258171335674
[Epoch 24, Batch 2600] loss: 0.004352592162368012
[Epoch 24, Batch 2700] loss: 0.004212412115999484
[Epoch 24, Batch 2800] loss: 0.004905890085134956
[Epoch 24, Batch 2900] loss: 0.004678302169307927
[Epoch 24, Batch 3000] loss: 0.009283881352151297
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9868
Overfitting: 0.0531
Fold 4 validation loss: 0.0531
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.295035300254822
[Epoch 1, Batch 200] loss: 2.271361448764801
[Epoch 1, Batch 300] loss: 2.217609624862671
[Epoch 1, Batch 400] loss: 2.064679045677185
[Epoch 1, Batch 500] loss: 1.436112823486328
[Epoch 1, Batch 600] loss: 0.7133932557702064
[Epoch 1, Batch 700] loss: 0.5386881271004677
[Epoch 1, Batch 800] loss: 0.4839316039532423
[Epoch 1, Batch 900] loss: 0.41477274589240554
[Epoch 1, Batch 1000] loss: 0.35077477104961874
[Epoch 1, Batch 1100] loss: 0.3243129939585924
[Epoch 1, Batch 1200] loss: 0.2836159659549594
[Epoch 1, Batch 1300] loss: 0.2383471168205142
[Epoch 1, Batch 1400] loss: 0.2596272310987115
[Epoch 1, Batch 1500] loss: 0.24295877628028392
[Epoch 1, Batch 1600] loss: 0.19414327010512353
[Epoch 1, Batch 1700] loss: 0.24230843614786862
[Epoch 1, Batch 1800] loss: 0.25047459077090023
[Epoch 1, Batch 1900] loss: 0.22860589571297169
[Epoch 1, Batch 2000] loss: 0.20814975161571056
[Epoch 1, Batch 2100] loss: 0.2062515968363732
[Epoch 1, Batch 2200] loss: 0.157620701296255
[Epoch 1, Batch 2300] loss: 0.1666682418063283
[Epoch 1, Batch 2400] loss: 0.22415086561813952
[Epoch 1, Batch 2500] loss: 0.1676220598258078
[Epoch 1, Batch 2600] loss: 0.13831501153763384
[Epoch 1, Batch 2700] loss: 0.1489745825342834
[Epoch 1, Batch 2800] loss: 0.16934272344224155
[Epoch 1, Batch 2900] loss: 0.1336290730535984
[Epoch 1, Batch 3000] loss: 0.14204953123349695
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1323
Validation Accuracy: 0.9603
Overfitting: 0.1323
Best model saved at epoch 1 with validation loss: 0.1323
[Epoch 2, Batch 100] loss: 0.1203075186535716
[Epoch 2, Batch 200] loss: 0.1391888873768039
[Epoch 2, Batch 300] loss: 0.11940021487884224
[Epoch 2, Batch 400] loss: 0.12383457336574794
[Epoch 2, Batch 500] loss: 0.11741235967259854
[Epoch 2, Batch 600] loss: 0.12337697744369507
[Epoch 2, Batch 700] loss: 0.14079461334040388
[Epoch 2, Batch 800] loss: 0.13361186110414563
[Epoch 2, Batch 900] loss: 0.1263113397033885
[Epoch 2, Batch 1000] loss: 0.11998985190875829
[Epoch 2, Batch 1100] loss: 0.12245481391670182
[Epoch 2, Batch 1200] loss: 0.12384733139537275
[Epoch 2, Batch 1300] loss: 0.1164688174566254
[Epoch 2, Batch 1400] loss: 0.11870813488028943
[Epoch 2, Batch 1500] loss: 0.12914043005905115
[Epoch 2, Batch 1600] loss: 0.09214848523959518
[Epoch 2, Batch 1700] loss: 0.0917622436734382
[Epoch 2, Batch 1800] loss: 0.10468964548781515
[Epoch 2, Batch 1900] loss: 0.09196632766164839
[Epoch 2, Batch 2000] loss: 0.11254163444507867
[Epoch 2, Batch 2100] loss: 0.07145484882872552
[Epoch 2, Batch 2200] loss: 0.1073447307094466
[Epoch 2, Batch 2300] loss: 0.10335839483654126
[Epoch 2, Batch 2400] loss: 0.0936857028491795
[Epoch 2, Batch 2500] loss: 0.10173121046274901
[Epoch 2, Batch 2600] loss: 0.10106675485614687
[Epoch 2, Batch 2700] loss: 0.09342144891852514
[Epoch 2, Batch 2800] loss: 0.09822771723149344
[Epoch 2, Batch 2900] loss: 0.10113955358043313
[Epoch 2, Batch 3000] loss: 0.09253334510140121
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0970
Validation Accuracy: 0.9717
Overfitting: 0.0970
Best model saved at epoch 2 with validation loss: 0.0970
[Epoch 3, Batch 100] loss: 0.07654065419221297
[Epoch 3, Batch 200] loss: 0.09916019801516086
[Epoch 3, Batch 300] loss: 0.07688387444242835
[Epoch 3, Batch 400] loss: 0.07606956038624048
[Epoch 3, Batch 500] loss: 0.08040718695847318
[Epoch 3, Batch 600] loss: 0.08136298588244245
[Epoch 3, Batch 700] loss: 0.08686451265006326
[Epoch 3, Batch 800] loss: 0.08439783146139235
[Epoch 3, Batch 900] loss: 0.087867715456523
[Epoch 3, Batch 1000] loss: 0.06708318125456572
[Epoch 3, Batch 1100] loss: 0.07125693213194609
[Epoch 3, Batch 1200] loss: 0.09627641977742314
[Epoch 3, Batch 1300] loss: 0.08823225893545895
[Epoch 3, Batch 1400] loss: 0.06383177615120075
[Epoch 3, Batch 1500] loss: 0.07939965959289111
[Epoch 3, Batch 1600] loss: 0.07939481984591111
[Epoch 3, Batch 1700] loss: 0.0932555803284049
[Epoch 3, Batch 1800] loss: 0.061236667309422045
[Epoch 3, Batch 1900] loss: 0.0731682767777238
[Epoch 3, Batch 2000] loss: 0.07747075468185358
[Epoch 3, Batch 2100] loss: 0.05860177672235295
[Epoch 3, Batch 2200] loss: 0.058041849259170705
[Epoch 3, Batch 2300] loss: 0.07724347047042102
[Epoch 3, Batch 2400] loss: 0.08032114176487085
[Epoch 3, Batch 2500] loss: 0.07581582735176198
[Epoch 3, Batch 2600] loss: 0.0633851839909039
[Epoch 3, Batch 2700] loss: 0.07761326419771648
[Epoch 3, Batch 2800] loss: 0.07190093503915705
[Epoch 3, Batch 2900] loss: 0.06803755689936225
[Epoch 3, Batch 3000] loss: 0.08399241320672444
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0712
Validation Accuracy: 0.9777
Overfitting: 0.0712
Best model saved at epoch 3 with validation loss: 0.0712
[Epoch 4, Batch 100] loss: 0.05524240520375315
[Epoch 4, Batch 200] loss: 0.06629749718005769
[Epoch 4, Batch 300] loss: 0.06082742899772711
[Epoch 4, Batch 400] loss: 0.0674160074867541
[Epoch 4, Batch 500] loss: 0.06565462649217807
[Epoch 4, Batch 600] loss: 0.06609916134097148
[Epoch 4, Batch 700] loss: 0.07238904666446615
[Epoch 4, Batch 800] loss: 0.05535656982508954
[Epoch 4, Batch 900] loss: 0.06515003432781669
[Epoch 4, Batch 1000] loss: 0.07509071669483092
[Epoch 4, Batch 1100] loss: 0.062101821828982794
[Epoch 4, Batch 1200] loss: 0.056617652379209175
[Epoch 4, Batch 1300] loss: 0.05928389625041745
[Epoch 4, Batch 1400] loss: 0.04370020835689502
[Epoch 4, Batch 1500] loss: 0.0920133476020419
[Epoch 4, Batch 1600] loss: 0.0726520519470796
[Epoch 4, Batch 1700] loss: 0.06712793037877418
[Epoch 4, Batch 1800] loss: 0.06641548003419302
[Epoch 4, Batch 1900] loss: 0.05364506863057614
[Epoch 4, Batch 2000] loss: 0.055711236889474096
[Epoch 4, Batch 2100] loss: 0.05018258953321492
[Epoch 4, Batch 2200] loss: 0.04731350906542502
[Epoch 4, Batch 2300] loss: 0.06549248004099355
[Epoch 4, Batch 2400] loss: 0.05885747506050393
[Epoch 4, Batch 2500] loss: 0.0517074560886249
[Epoch 4, Batch 2600] loss: 0.055109919500828254
[Epoch 4, Batch 2700] loss: 0.08160537497897166
[Epoch 4, Batch 2800] loss: 0.053458135897526515
[Epoch 4, Batch 2900] loss: 0.06369063432095573
[Epoch 4, Batch 3000] loss: 0.048364505973877384
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0692
Validation Accuracy: 0.9800
Overfitting: 0.0692
Best model saved at epoch 4 with validation loss: 0.0692
[Epoch 5, Batch 100] loss: 0.0607067546757753
[Epoch 5, Batch 200] loss: 0.044190558613627216
[Epoch 5, Batch 300] loss: 0.052496958631963936
[Epoch 5, Batch 400] loss: 0.05103541192947887
[Epoch 5, Batch 500] loss: 0.06559202271833783
[Epoch 5, Batch 600] loss: 0.06239080463303253
[Epoch 5, Batch 700] loss: 0.03854951078479644
[Epoch 5, Batch 800] loss: 0.056114151324145496
[Epoch 5, Batch 900] loss: 0.05892321665451163
[Epoch 5, Batch 1000] loss: 0.046035822306002956
[Epoch 5, Batch 1100] loss: 0.050223162760376
[Epoch 5, Batch 1200] loss: 0.047721137242624535
[Epoch 5, Batch 1300] loss: 0.038091015252284706
[Epoch 5, Batch 1400] loss: 0.054199527302989735
[Epoch 5, Batch 1500] loss: 0.04570715298235882
[Epoch 5, Batch 1600] loss: 0.050704340012889586
[Epoch 5, Batch 1700] loss: 0.04137296775938012
[Epoch 5, Batch 1800] loss: 0.05106738854636205
[Epoch 5, Batch 1900] loss: 0.06133322209236212
[Epoch 5, Batch 2000] loss: 0.04184159116237424
[Epoch 5, Batch 2100] loss: 0.05688734502822626
[Epoch 5, Batch 2200] loss: 0.03869939174503088
[Epoch 5, Batch 2300] loss: 0.060153455579420555
[Epoch 5, Batch 2400] loss: 0.05664990481192945
[Epoch 5, Batch 2500] loss: 0.04633576134976465
[Epoch 5, Batch 2600] loss: 0.034417385068809384
[Epoch 5, Batch 2700] loss: 0.049183143713889876
[Epoch 5, Batch 2800] loss: 0.05300945978000527
[Epoch 5, Batch 2900] loss: 0.05965068434423301
[Epoch 5, Batch 3000] loss: 0.046727690818952394
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0718
Validation Accuracy: 0.9768
Overfitting: 0.0718
[Epoch 6, Batch 100] loss: 0.04505731284996727
[Epoch 6, Batch 200] loss: 0.034674048692395446
[Epoch 6, Batch 300] loss: 0.050172159243375064
[Epoch 6, Batch 400] loss: 0.028163352133124136
[Epoch 6, Batch 500] loss: 0.03764610384707339
[Epoch 6, Batch 600] loss: 0.03804543333069887
[Epoch 6, Batch 700] loss: 0.04241015305175097
[Epoch 6, Batch 800] loss: 0.0445864458088181
[Epoch 6, Batch 900] loss: 0.038655559056787754
[Epoch 6, Batch 1000] loss: 0.03707082090331824
[Epoch 6, Batch 1100] loss: 0.0454543977137655
[Epoch 6, Batch 1200] loss: 0.0331565572960244
[Epoch 6, Batch 1300] loss: 0.046123840140062385
[Epoch 6, Batch 1400] loss: 0.050703156690869944
[Epoch 6, Batch 1500] loss: 0.03269191425992176
[Epoch 6, Batch 1600] loss: 0.03445784691153676
[Epoch 6, Batch 1700] loss: 0.040936838107008953
[Epoch 6, Batch 1800] loss: 0.040157554174074905
[Epoch 6, Batch 1900] loss: 0.054502539634122514
[Epoch 6, Batch 2000] loss: 0.0530242184526287
[Epoch 6, Batch 2100] loss: 0.07325312307395507
[Epoch 6, Batch 2200] loss: 0.03937214670528192
[Epoch 6, Batch 2300] loss: 0.045933877862116786
[Epoch 6, Batch 2400] loss: 0.042586960395274216
[Epoch 6, Batch 2500] loss: 0.04530462753289612
[Epoch 6, Batch 2600] loss: 0.04531435942393727
[Epoch 6, Batch 2700] loss: 0.03157164742398891
[Epoch 6, Batch 2800] loss: 0.035288777749519794
[Epoch 6, Batch 2900] loss: 0.042541578043746996
[Epoch 6, Batch 3000] loss: 0.04323159538500477
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9836
Overfitting: 0.0538
Best model saved at epoch 6 with validation loss: 0.0538
[Epoch 7, Batch 100] loss: 0.02365963872827706
[Epoch 7, Batch 200] loss: 0.03381051967764506
[Epoch 7, Batch 300] loss: 0.04061871629644884
[Epoch 7, Batch 400] loss: 0.04090693951962748
[Epoch 7, Batch 500] loss: 0.027654126256966265
[Epoch 7, Batch 600] loss: 0.036498233799211445
[Epoch 7, Batch 700] loss: 0.03933844302446232
[Epoch 7, Batch 800] loss: 0.031420835994940714
[Epoch 7, Batch 900] loss: 0.04242698537462274
[Epoch 7, Batch 1000] loss: 0.029478329723133356
[Epoch 7, Batch 1100] loss: 0.03675429384566087
[Epoch 7, Batch 1200] loss: 0.04191435222572181
[Epoch 7, Batch 1300] loss: 0.04737985108033172
[Epoch 7, Batch 1400] loss: 0.03325887376384344
[Epoch 7, Batch 1500] loss: 0.034412676945794377
[Epoch 7, Batch 1600] loss: 0.03542000181711046
[Epoch 7, Batch 1700] loss: 0.02799510014243424
[Epoch 7, Batch 1800] loss: 0.04127274472877616
[Epoch 7, Batch 1900] loss: 0.042573797150253084
[Epoch 7, Batch 2000] loss: 0.02960834488796536
[Epoch 7, Batch 2100] loss: 0.04300759890902554
[Epoch 7, Batch 2200] loss: 0.03324815105945163
[Epoch 7, Batch 2300] loss: 0.04091536561842077
[Epoch 7, Batch 2400] loss: 0.059427759180543945
[Epoch 7, Batch 2500] loss: 0.03150220268114936
[Epoch 7, Batch 2600] loss: 0.043603514569986145
[Epoch 7, Batch 2700] loss: 0.03667146335727011
[Epoch 7, Batch 2800] loss: 0.02669953220174648
[Epoch 7, Batch 2900] loss: 0.03727001394574472
[Epoch 7, Batch 3000] loss: 0.039598904410668184
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9828
Overfitting: 0.0593
[Epoch 8, Batch 100] loss: 0.014298787611623993
[Epoch 8, Batch 200] loss: 0.04132249586313264
[Epoch 8, Batch 300] loss: 0.037609131628851176
[Epoch 8, Batch 400] loss: 0.02508349088660907
[Epoch 8, Batch 500] loss: 0.033566588898975167
[Epoch 8, Batch 600] loss: 0.029436444879029296
[Epoch 8, Batch 700] loss: 0.028093386958935297
[Epoch 8, Batch 800] loss: 0.027509971198596758
[Epoch 8, Batch 900] loss: 0.027781954385136486
[Epoch 8, Batch 1000] loss: 0.04112370939474204
[Epoch 8, Batch 1100] loss: 0.0510568457255431
[Epoch 8, Batch 1200] loss: 0.031929985828828646
[Epoch 8, Batch 1300] loss: 0.03463259536583792
[Epoch 8, Batch 1400] loss: 0.029169780001830077
[Epoch 8, Batch 1500] loss: 0.031152686058776455
[Epoch 8, Batch 1600] loss: 0.03411280869899201
[Epoch 8, Batch 1700] loss: 0.024577936364803463
[Epoch 8, Batch 1800] loss: 0.03825716002524132
[Epoch 8, Batch 1900] loss: 0.03588340861533652
[Epoch 8, Batch 2000] loss: 0.04321942744943954
[Epoch 8, Batch 2100] loss: 0.03908272269967711
[Epoch 8, Batch 2200] loss: 0.03418960387571133
[Epoch 8, Batch 2300] loss: 0.0422823442259687
[Epoch 8, Batch 2400] loss: 0.04442983933025971
[Epoch 8, Batch 2500] loss: 0.02659800351189915
[Epoch 8, Batch 2600] loss: 0.02691486658237409
[Epoch 8, Batch 2700] loss: 0.03635348680756579
[Epoch 8, Batch 2800] loss: 0.035087423972727266
[Epoch 8, Batch 2900] loss: 0.04251340382972558
[Epoch 8, Batch 3000] loss: 0.03378914549772162
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9837
Overfitting: 0.0567
[Epoch 9, Batch 100] loss: 0.027960292726493207
[Epoch 9, Batch 200] loss: 0.03024434957864287
[Epoch 9, Batch 300] loss: 0.02540743868230493
[Epoch 9, Batch 400] loss: 0.024355047671924694
[Epoch 9, Batch 500] loss: 0.03265370932160295
[Epoch 9, Batch 600] loss: 0.02340726856411493
[Epoch 9, Batch 700] loss: 0.03287389711309516
[Epoch 9, Batch 800] loss: 0.03222273159579345
[Epoch 9, Batch 900] loss: 0.02267364600629662
[Epoch 9, Batch 1000] loss: 0.03954099501483142
[Epoch 9, Batch 1100] loss: 0.03616245888129924
[Epoch 9, Batch 1200] loss: 0.012889960270840675
[Epoch 9, Batch 1300] loss: 0.0329622769675916
[Epoch 9, Batch 1400] loss: 0.029104982196877245
[Epoch 9, Batch 1500] loss: 0.021434856547275557
[Epoch 9, Batch 1600] loss: 0.014297019122896017
[Epoch 9, Batch 1700] loss: 0.027072767581630616
[Epoch 9, Batch 1800] loss: 0.03439721944749181
[Epoch 9, Batch 1900] loss: 0.028189388398532175
[Epoch 9, Batch 2000] loss: 0.034215790761445534
[Epoch 9, Batch 2100] loss: 0.028977401459196698
[Epoch 9, Batch 2200] loss: 0.03492359549287358
[Epoch 9, Batch 2300] loss: 0.029132036972332572
[Epoch 9, Batch 2400] loss: 0.03901659150607884
[Epoch 9, Batch 2500] loss: 0.026230178626719863
[Epoch 9, Batch 2600] loss: 0.019122988487943075
[Epoch 9, Batch 2700] loss: 0.02931206348075648
[Epoch 9, Batch 2800] loss: 0.03672764214832568
[Epoch 9, Batch 2900] loss: 0.02162399857174023
[Epoch 9, Batch 3000] loss: 0.03891350593083189
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9858
Overfitting: 0.0473
Best model saved at epoch 9 with validation loss: 0.0473
[Epoch 10, Batch 100] loss: 0.024613949005361065
[Epoch 10, Batch 200] loss: 0.018993779996817464
[Epoch 10, Batch 300] loss: 0.021515708500082838
[Epoch 10, Batch 400] loss: 0.022381239106180145
[Epoch 10, Batch 500] loss: 0.02942178071520175
[Epoch 10, Batch 600] loss: 0.012978034250045312
[Epoch 10, Batch 700] loss: 0.013306049190159683
[Epoch 10, Batch 800] loss: 0.025621301018727536
[Epoch 10, Batch 900] loss: 0.027858015268939197
[Epoch 10, Batch 1000] loss: 0.03432712029847607
[Epoch 10, Batch 1100] loss: 0.029698885291800252
[Epoch 10, Batch 1200] loss: 0.028459905128984248
[Epoch 10, Batch 1300] loss: 0.028927888638663718
[Epoch 10, Batch 1400] loss: 0.03207763183134375
[Epoch 10, Batch 1500] loss: 0.021121775050451107
[Epoch 10, Batch 1600] loss: 0.025420291334594367
[Epoch 10, Batch 1700] loss: 0.019534924608633444
[Epoch 10, Batch 1800] loss: 0.025547268335940315
[Epoch 10, Batch 1900] loss: 0.03201733265996154
[Epoch 10, Batch 2000] loss: 0.01893529464949097
[Epoch 10, Batch 2100] loss: 0.029520246625979782
[Epoch 10, Batch 2200] loss: 0.022110629552335014
[Epoch 10, Batch 2300] loss: 0.025697499688139943
[Epoch 10, Batch 2400] loss: 0.01862554266157531
[Epoch 10, Batch 2500] loss: 0.022719727209332633
[Epoch 10, Batch 2600] loss: 0.026699793206225876
[Epoch 10, Batch 2700] loss: 0.031941852896452474
[Epoch 10, Batch 2800] loss: 0.03949894332963595
[Epoch 10, Batch 2900] loss: 0.03281642058354919
[Epoch 10, Batch 3000] loss: 0.027874855831032618
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9865
Overfitting: 0.0453
Best model saved at epoch 10 with validation loss: 0.0453
[Epoch 11, Batch 100] loss: 0.02766438263686723
[Epoch 11, Batch 200] loss: 0.02549126373734907
[Epoch 11, Batch 300] loss: 0.02405806259761448
[Epoch 11, Batch 400] loss: 0.01754667911445722
[Epoch 11, Batch 500] loss: 0.03751435317273717
[Epoch 11, Batch 600] loss: 0.016249606386118103
[Epoch 11, Batch 700] loss: 0.02609963500901358
[Epoch 11, Batch 800] loss: 0.01771944371950667
[Epoch 11, Batch 900] loss: 0.012290617788094095
[Epoch 11, Batch 1000] loss: 0.015293693973835615
[Epoch 11, Batch 1100] loss: 0.024721577775544575
[Epoch 11, Batch 1200] loss: 0.015806464466804754
[Epoch 11, Batch 1300] loss: 0.03236138499276422
[Epoch 11, Batch 1400] loss: 0.031498213724371456
[Epoch 11, Batch 1500] loss: 0.021176403786303127
[Epoch 11, Batch 1600] loss: 0.013079133176142932
[Epoch 11, Batch 1700] loss: 0.017328988236386067
[Epoch 11, Batch 1800] loss: 0.019945989077277772
[Epoch 11, Batch 1900] loss: 0.016117786635913945
[Epoch 11, Batch 2000] loss: 0.020275018014144733
[Epoch 11, Batch 2100] loss: 0.017053778848367073
[Epoch 11, Batch 2200] loss: 0.027302501746562485
[Epoch 11, Batch 2300] loss: 0.015332248041922868
[Epoch 11, Batch 2400] loss: 0.014881693963543512
[Epoch 11, Batch 2500] loss: 0.02849172746638942
[Epoch 11, Batch 2600] loss: 0.024049435049528257
[Epoch 11, Batch 2700] loss: 0.026071231607065783
[Epoch 11, Batch 2800] loss: 0.0378147893325513
[Epoch 11, Batch 2900] loss: 0.03182305228699988
[Epoch 11, Batch 3000] loss: 0.02162370888327132
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9866
Overfitting: 0.0455
[Epoch 12, Batch 100] loss: 0.022272264103685303
[Epoch 12, Batch 200] loss: 0.019317590033897433
[Epoch 12, Batch 300] loss: 0.016268120797976734
[Epoch 12, Batch 400] loss: 0.020464580240404758
[Epoch 12, Batch 500] loss: 0.019622093860816675
[Epoch 12, Batch 600] loss: 0.01399575062931035
[Epoch 12, Batch 700] loss: 0.02295433302573656
[Epoch 12, Batch 800] loss: 0.02834908606022509
[Epoch 12, Batch 900] loss: 0.017012665864240262
[Epoch 12, Batch 1000] loss: 0.019737892542070767
[Epoch 12, Batch 1100] loss: 0.024547970458879718
[Epoch 12, Batch 1200] loss: 0.018749793797360324
[Epoch 12, Batch 1300] loss: 0.016176422197386273
[Epoch 12, Batch 1400] loss: 0.00763625537034386
[Epoch 12, Batch 1500] loss: 0.014766152688243892
[Epoch 12, Batch 1600] loss: 0.030839716775153646
[Epoch 12, Batch 1700] loss: 0.023883175045884854
[Epoch 12, Batch 1800] loss: 0.01737132845213637
[Epoch 12, Batch 1900] loss: 0.014204257737892476
[Epoch 12, Batch 2000] loss: 0.02016915377740588
[Epoch 12, Batch 2100] loss: 0.02303106892879441
[Epoch 12, Batch 2200] loss: 0.017134684422180725
[Epoch 12, Batch 2300] loss: 0.01749603946262141
[Epoch 12, Batch 2400] loss: 0.02797597741458958
[Epoch 12, Batch 2500] loss: 0.02058235003685695
[Epoch 12, Batch 2600] loss: 0.020792819749913177
[Epoch 12, Batch 2700] loss: 0.018727520210159127
[Epoch 12, Batch 2800] loss: 0.01971035400132678
[Epoch 12, Batch 2900] loss: 0.0318306167523042
[Epoch 12, Batch 3000] loss: 0.022116373865537754
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9871
Overfitting: 0.0456
[Epoch 13, Batch 100] loss: 0.013692685673240702
[Epoch 13, Batch 200] loss: 0.017067028720121016
[Epoch 13, Batch 300] loss: 0.009649914480396546
[Epoch 13, Batch 400] loss: 0.011449010557626024
[Epoch 13, Batch 500] loss: 0.01518583250582651
[Epoch 13, Batch 600] loss: 0.015284329945116042
[Epoch 13, Batch 700] loss: 0.010787295939771867
[Epoch 13, Batch 800] loss: 0.012199431731387449
[Epoch 13, Batch 900] loss: 0.013416453201743934
[Epoch 13, Batch 1000] loss: 0.018307179455769075
[Epoch 13, Batch 1100] loss: 0.01597571272384812
[Epoch 13, Batch 1200] loss: 0.022640649477725674
[Epoch 13, Batch 1300] loss: 0.011831944166751783
[Epoch 13, Batch 1400] loss: 0.027001995793507375
[Epoch 13, Batch 1500] loss: 0.03509472114788878
[Epoch 13, Batch 1600] loss: 0.014450480397608772
[Epoch 13, Batch 1700] loss: 0.024922305979125668
[Epoch 13, Batch 1800] loss: 0.015090605926197896
[Epoch 13, Batch 1900] loss: 0.021760797178903887
[Epoch 13, Batch 2000] loss: 0.021814869274385272
[Epoch 13, Batch 2100] loss: 0.017065611535508653
[Epoch 13, Batch 2200] loss: 0.014696408275813155
[Epoch 13, Batch 2300] loss: 0.02043053562958448
[Epoch 13, Batch 2400] loss: 0.023257360706684268
[Epoch 13, Batch 2500] loss: 0.02456911915593082
[Epoch 13, Batch 2600] loss: 0.018886243595661652
[Epoch 13, Batch 2700] loss: 0.011354734885317156
[Epoch 13, Batch 2800] loss: 0.021613107163648237
[Epoch 13, Batch 2900] loss: 0.022629539034187473
[Epoch 13, Batch 3000] loss: 0.015400256981956772
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9868
Overfitting: 0.0463
[Epoch 14, Batch 100] loss: 0.009215220189980755
[Epoch 14, Batch 200] loss: 0.018445723688364522
[Epoch 14, Batch 300] loss: 0.01794597974570934
[Epoch 14, Batch 400] loss: 0.019185083207084973
[Epoch 14, Batch 500] loss: 0.013229481637536082
[Epoch 14, Batch 600] loss: 0.011161825365779804
[Epoch 14, Batch 700] loss: 0.010461745712091216
[Epoch 14, Batch 800] loss: 0.013049656025868899
[Epoch 14, Batch 900] loss: 0.012022146678864374
[Epoch 14, Batch 1000] loss: 0.012002374478470301
[Epoch 14, Batch 1100] loss: 0.016220290027158624
[Epoch 14, Batch 1200] loss: 0.010850182628510084
[Epoch 14, Batch 1300] loss: 0.01903618375057704
[Epoch 14, Batch 1400] loss: 0.018693967135604908
[Epoch 14, Batch 1500] loss: 0.022332092569295126
[Epoch 14, Batch 1600] loss: 0.016248795092633373
[Epoch 14, Batch 1700] loss: 0.01866429044152028
[Epoch 14, Batch 1800] loss: 0.014915810577804223
[Epoch 14, Batch 1900] loss: 0.01367634701597126
[Epoch 14, Batch 2000] loss: 0.02193020895781956
[Epoch 14, Batch 2100] loss: 0.02077516794440271
[Epoch 14, Batch 2200] loss: 0.012689227167702483
[Epoch 14, Batch 2300] loss: 0.01919071065245589
[Epoch 14, Batch 2400] loss: 0.01767706536084006
[Epoch 14, Batch 2500] loss: 0.01722388790856712
[Epoch 14, Batch 2600] loss: 0.022228662410852848
[Epoch 14, Batch 2700] loss: 0.013987241249687941
[Epoch 14, Batch 2800] loss: 0.0176734670958831
[Epoch 14, Batch 2900] loss: 0.012239775881098466
[Epoch 14, Batch 3000] loss: 0.014662856306281356
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0545
Validation Accuracy: 0.9846
Overfitting: 0.0545
[Epoch 15, Batch 100] loss: 0.0160185477842424
[Epoch 15, Batch 200] loss: 0.013801400898300927
[Epoch 15, Batch 300] loss: 0.00682116557083873
[Epoch 15, Batch 400] loss: 0.023481376364634342
[Epoch 15, Batch 500] loss: 0.010278110205481425
[Epoch 15, Batch 600] loss: 0.01290822386923992
[Epoch 15, Batch 700] loss: 0.01913685121156959
[Epoch 15, Batch 800] loss: 0.008212367334790542
[Epoch 15, Batch 900] loss: 0.010964416030883512
[Epoch 15, Batch 1000] loss: 0.010959894134066417
[Epoch 15, Batch 1100] loss: 0.014073373998626267
[Epoch 15, Batch 1200] loss: 0.015711359425022237
[Epoch 15, Batch 1300] loss: 0.02009977644997889
[Epoch 15, Batch 1400] loss: 0.007902226350961428
[Epoch 15, Batch 1500] loss: 0.01824660017791757
[Epoch 15, Batch 1600] loss: 0.017090058361181947
[Epoch 15, Batch 1700] loss: 0.017321629090474744
[Epoch 15, Batch 1800] loss: 0.026534757918634567
[Epoch 15, Batch 1900] loss: 0.018123983736063564
[Epoch 15, Batch 2000] loss: 0.01602643603836441
[Epoch 15, Batch 2100] loss: 0.008908110147112893
[Epoch 15, Batch 2200] loss: 0.014763392104659942
[Epoch 15, Batch 2300] loss: 0.008518499811762012
[Epoch 15, Batch 2400] loss: 0.019810468673126705
[Epoch 15, Batch 2500] loss: 0.022441358495652822
[Epoch 15, Batch 2600] loss: 0.019055723715873683
[Epoch 15, Batch 2700] loss: 0.010669410969258023
[Epoch 15, Batch 2800] loss: 0.017369716887951654
[Epoch 15, Batch 2900] loss: 0.012820753293490271
[Epoch 15, Batch 3000] loss: 0.011944233230533428
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9855
Overfitting: 0.0496
[Epoch 16, Batch 100] loss: 0.014899977862978631
[Epoch 16, Batch 200] loss: 0.014342982793586999
[Epoch 16, Batch 300] loss: 0.02795243019851114
[Epoch 16, Batch 400] loss: 0.006555608879853026
[Epoch 16, Batch 500] loss: 0.009961115594255715
[Epoch 16, Batch 600] loss: 0.006722601816809401
[Epoch 16, Batch 700] loss: 0.010187848019695593
[Epoch 16, Batch 800] loss: 0.008217939964979451
[Epoch 16, Batch 900] loss: 0.010112229141027456
[Epoch 16, Batch 1000] loss: 0.011407403786961368
[Epoch 16, Batch 1100] loss: 0.009068748939371289
[Epoch 16, Batch 1200] loss: 0.011714575724072347
[Epoch 16, Batch 1300] loss: 0.015652195711959395
[Epoch 16, Batch 1400] loss: 0.015887362952762486
[Epoch 16, Batch 1500] loss: 0.02010849231950715
[Epoch 16, Batch 1600] loss: 0.016367239888763832
[Epoch 16, Batch 1700] loss: 0.013726334133280034
[Epoch 16, Batch 1800] loss: 0.00545377290367469
[Epoch 16, Batch 1900] loss: 0.018041020573609786
[Epoch 16, Batch 2000] loss: 0.008194921342387716
[Epoch 16, Batch 2100] loss: 0.00853023039564505
[Epoch 16, Batch 2200] loss: 0.007444921791911838
[Epoch 16, Batch 2300] loss: 0.015731420314721162
[Epoch 16, Batch 2400] loss: 0.014658259849866226
[Epoch 16, Batch 2500] loss: 0.011835002224470372
[Epoch 16, Batch 2600] loss: 0.009103580646437877
[Epoch 16, Batch 2700] loss: 0.009309958950716464
[Epoch 16, Batch 2800] loss: 0.006735305285603772
[Epoch 16, Batch 2900] loss: 0.010929894747719118
[Epoch 16, Batch 3000] loss: 0.033072798612911354
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0503
Validation Accuracy: 0.9864
Overfitting: 0.0503
[Epoch 17, Batch 100] loss: 0.011451609029336396
[Epoch 17, Batch 200] loss: 0.009470910373856896
[Epoch 17, Batch 300] loss: 0.011931359587088082
[Epoch 17, Batch 400] loss: 0.008971568871756971
[Epoch 17, Batch 500] loss: 0.009978930028464674
[Epoch 17, Batch 600] loss: 0.013833063024208059
[Epoch 17, Batch 700] loss: 0.01284284595133613
[Epoch 17, Batch 800] loss: 0.009635867154775041
[Epoch 17, Batch 900] loss: 0.009104963235179184
[Epoch 17, Batch 1000] loss: 0.01033456733890489
[Epoch 17, Batch 1100] loss: 0.0052486733333989835
[Epoch 17, Batch 1200] loss: 0.0159683788740017
[Epoch 17, Batch 1300] loss: 0.020038914333090362
[Epoch 17, Batch 1400] loss: 0.011033375912147677
[Epoch 17, Batch 1500] loss: 0.007559851351065845
[Epoch 17, Batch 1600] loss: 0.007742221482303648
[Epoch 17, Batch 1700] loss: 0.012361648755613715
[Epoch 17, Batch 1800] loss: 0.006032388028952482
[Epoch 17, Batch 1900] loss: 0.01686881486110906
[Epoch 17, Batch 2000] loss: 0.022609839686328997
[Epoch 17, Batch 2100] loss: 0.009645719134864521
[Epoch 17, Batch 2200] loss: 0.012810878316172421
[Epoch 17, Batch 2300] loss: 0.01320182714868679
[Epoch 17, Batch 2400] loss: 0.012693977919534518
[Epoch 17, Batch 2500] loss: 0.009271544543044002
[Epoch 17, Batch 2600] loss: 0.011999474595186257
[Epoch 17, Batch 2700] loss: 0.008363120896074178
[Epoch 17, Batch 2800] loss: 0.011894871535714628
[Epoch 17, Batch 2900] loss: 0.014683419283855983
[Epoch 17, Batch 3000] loss: 0.010714175390278342
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9873
Overfitting: 0.0456
[Epoch 18, Batch 100] loss: 0.007777489135041833
[Epoch 18, Batch 200] loss: 0.009041610689291702
[Epoch 18, Batch 300] loss: 0.007309381050972661
[Epoch 18, Batch 400] loss: 0.007484073594814618
[Epoch 18, Batch 500] loss: 0.01263031813072871
[Epoch 18, Batch 600] loss: 0.01255483916434514
[Epoch 18, Batch 700] loss: 0.012604224906749551
[Epoch 18, Batch 800] loss: 0.009006163554101648
[Epoch 18, Batch 900] loss: 0.0057323177710441086
[Epoch 18, Batch 1000] loss: 0.014654374794376963
[Epoch 18, Batch 1100] loss: 0.003668849915666215
[Epoch 18, Batch 1200] loss: 0.009788785569294306
[Epoch 18, Batch 1300] loss: 0.005825332489157517
[Epoch 18, Batch 1400] loss: 0.007576315410233292
[Epoch 18, Batch 1500] loss: 0.004293912221257869
[Epoch 18, Batch 1600] loss: 0.007544675269676873
[Epoch 18, Batch 1700] loss: 0.006788620658169293
[Epoch 18, Batch 1800] loss: 0.009829106980155301
[Epoch 18, Batch 1900] loss: 0.008403969535274882
[Epoch 18, Batch 2000] loss: 0.010648161319384144
[Epoch 18, Batch 2100] loss: 0.005869272377983634
[Epoch 18, Batch 2200] loss: 0.005455328015641498
[Epoch 18, Batch 2300] loss: 0.011279679544903729
[Epoch 18, Batch 2400] loss: 0.010801388207995614
[Epoch 18, Batch 2500] loss: 0.011625632672773918
[Epoch 18, Batch 2600] loss: 0.013770480748660248
[Epoch 18, Batch 2700] loss: 0.010267499315559689
[Epoch 18, Batch 2800] loss: 0.014946621895396674
[Epoch 18, Batch 2900] loss: 0.011673897327627856
[Epoch 18, Batch 3000] loss: 0.014261384088690647
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9878
Overfitting: 0.0436
Best model saved at epoch 18 with validation loss: 0.0436
[Epoch 19, Batch 100] loss: 0.006338872379355962
[Epoch 19, Batch 200] loss: 0.011576996896158107
[Epoch 19, Batch 300] loss: 0.0055672325062960226
[Epoch 19, Batch 400] loss: 0.008818222119984967
[Epoch 19, Batch 500] loss: 0.00911208045152307
[Epoch 19, Batch 600] loss: 0.01302865732680175
[Epoch 19, Batch 700] loss: 0.007167889939810265
[Epoch 19, Batch 800] loss: 0.005674858467025956
[Epoch 19, Batch 900] loss: 0.005373215657754144
[Epoch 19, Batch 1000] loss: 0.006822082564028733
[Epoch 19, Batch 1100] loss: 0.005293474771074216
[Epoch 19, Batch 1200] loss: 0.009626639130783588
[Epoch 19, Batch 1300] loss: 0.0057223141318831945
[Epoch 19, Batch 1400] loss: 0.01452487008195476
[Epoch 19, Batch 1500] loss: 0.010449015759991197
[Epoch 19, Batch 1600] loss: 0.012814412634209021
[Epoch 19, Batch 1700] loss: 0.017150539986569128
[Epoch 19, Batch 1800] loss: 0.008719710215329997
[Epoch 19, Batch 1900] loss: 0.007748060279723177
[Epoch 19, Batch 2000] loss: 0.006312008593795326
[Epoch 19, Batch 2100] loss: 0.00971538418565956
[Epoch 19, Batch 2200] loss: 0.007841274476568287
[Epoch 19, Batch 2300] loss: 0.008461756648057418
[Epoch 19, Batch 2400] loss: 0.006796404334413637
[Epoch 19, Batch 2500] loss: 0.0051696921971961275
[Epoch 19, Batch 2600] loss: 0.013411870493055176
[Epoch 19, Batch 2700] loss: 0.007113875875955955
[Epoch 19, Batch 2800] loss: 0.006729670724089374
[Epoch 19, Batch 2900] loss: 0.006485997856843824
[Epoch 19, Batch 3000] loss: 0.007864537539426238
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0428
Validation Accuracy: 0.9885
Overfitting: 0.0428
Best model saved at epoch 19 with validation loss: 0.0428
[Epoch 20, Batch 100] loss: 0.006920401195420709
[Epoch 20, Batch 200] loss: 0.008605947445248603
[Epoch 20, Batch 300] loss: 0.006477771622248838
[Epoch 20, Batch 400] loss: 0.006510528108319705
[Epoch 20, Batch 500] loss: 0.006742910663328985
[Epoch 20, Batch 600] loss: 0.002315289822481645
[Epoch 20, Batch 700] loss: 0.008989255185204001
[Epoch 20, Batch 800] loss: 0.007212057600909248
[Epoch 20, Batch 900] loss: 0.005814693770114445
[Epoch 20, Batch 1000] loss: 0.004155742767537731
[Epoch 20, Batch 1100] loss: 0.004552867805336973
[Epoch 20, Batch 1200] loss: 0.012385258058984619
[Epoch 20, Batch 1300] loss: 0.0033104084638125642
[Epoch 20, Batch 1400] loss: 0.0063649019312811105
[Epoch 20, Batch 1500] loss: 0.009174336735813995
[Epoch 20, Batch 1600] loss: 0.008689094755914084
[Epoch 20, Batch 1700] loss: 0.005456067082683376
[Epoch 20, Batch 1800] loss: 0.004444989915011775
[Epoch 20, Batch 1900] loss: 0.006069224235818638
[Epoch 20, Batch 2000] loss: 0.0075797597979226335
[Epoch 20, Batch 2100] loss: 0.013812978729285988
[Epoch 20, Batch 2200] loss: 0.00648526325623834
[Epoch 20, Batch 2300] loss: 0.01270841938299327
[Epoch 20, Batch 2400] loss: 0.006844855183485379
[Epoch 20, Batch 2500] loss: 0.007533588231871136
[Epoch 20, Batch 2600] loss: 0.00485775472881528
[Epoch 20, Batch 2700] loss: 0.00734591580724441
[Epoch 20, Batch 2800] loss: 0.00531831223033123
[Epoch 20, Batch 2900] loss: 0.014405595310441867
[Epoch 20, Batch 3000] loss: 0.006560267288596151
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0451
Validation Accuracy: 0.9887
Overfitting: 0.0451
[Epoch 21, Batch 100] loss: 0.006433024705702337
[Epoch 21, Batch 200] loss: 0.003722966965443675
[Epoch 21, Batch 300] loss: 0.0047200336315972894
[Epoch 21, Batch 400] loss: 0.012149497373866325
[Epoch 21, Batch 500] loss: 0.0037518678771471057
[Epoch 21, Batch 600] loss: 0.0074516950317701
[Epoch 21, Batch 700] loss: 0.007561464213738418
[Epoch 21, Batch 800] loss: 0.004813449970877173
[Epoch 21, Batch 900] loss: 0.004099900933870231
[Epoch 21, Batch 1000] loss: 0.005006096534116295
[Epoch 21, Batch 1100] loss: 0.006954413999530971
[Epoch 21, Batch 1200] loss: 0.003071812816937154
[Epoch 21, Batch 1300] loss: 0.005819878134298051
[Epoch 21, Batch 1400] loss: 0.0036825573092914964
[Epoch 21, Batch 1500] loss: 0.002990336596456018
[Epoch 21, Batch 1600] loss: 0.004587725061533092
[Epoch 21, Batch 1700] loss: 0.002545486206054193
[Epoch 21, Batch 1800] loss: 0.004987934383937045
[Epoch 21, Batch 1900] loss: 0.007520451601376408
[Epoch 21, Batch 2000] loss: 0.004820292344697918
[Epoch 21, Batch 2100] loss: 0.0037118646619171613
[Epoch 21, Batch 2200] loss: 0.01030913496474966
[Epoch 21, Batch 2300] loss: 0.00405044932826172
[Epoch 21, Batch 2400] loss: 0.01685008060392647
[Epoch 21, Batch 2500] loss: 0.01277925028265372
[Epoch 21, Batch 2600] loss: 0.005618516310409518
[Epoch 21, Batch 2700] loss: 0.007670959177704617
[Epoch 21, Batch 2800] loss: 0.015699840945399047
[Epoch 21, Batch 2900] loss: 0.015416181488035363
[Epoch 21, Batch 3000] loss: 0.0051155112494708985
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9889
Overfitting: 0.0464
[Epoch 22, Batch 100] loss: 0.004518110970771261
[Epoch 22, Batch 200] loss: 0.005810301458279809
[Epoch 22, Batch 300] loss: 0.0026454977595233233
[Epoch 22, Batch 400] loss: 0.008366297126419795
[Epoch 22, Batch 500] loss: 0.008809698651232267
[Epoch 22, Batch 600] loss: 0.002823918727084447
[Epoch 22, Batch 700] loss: 0.00668064134360975
[Epoch 22, Batch 800] loss: 0.00494412426113513
[Epoch 22, Batch 900] loss: 0.008708924888278489
[Epoch 22, Batch 1000] loss: 0.002394449711746347
[Epoch 22, Batch 1100] loss: 0.007268061612580823
[Epoch 22, Batch 1200] loss: 0.0062688760685796294
[Epoch 22, Batch 1300] loss: 0.0060601852400805
[Epoch 22, Batch 1400] loss: 0.008586207501700187
[Epoch 22, Batch 1500] loss: 0.008164041295078733
[Epoch 22, Batch 1600] loss: 0.005918204224104784
[Epoch 22, Batch 1700] loss: 0.008415073753722026
[Epoch 22, Batch 1800] loss: 0.003200508130058779
[Epoch 22, Batch 1900] loss: 0.006375492820971544
[Epoch 22, Batch 2000] loss: 0.002904802320204567
[Epoch 22, Batch 2100] loss: 0.006335072234849122
[Epoch 22, Batch 2200] loss: 0.0020925360416288188
[Epoch 22, Batch 2300] loss: 0.004127523632355405
[Epoch 22, Batch 2400] loss: 0.0038104411817016627
[Epoch 22, Batch 2500] loss: 0.004343554517936355
[Epoch 22, Batch 2600] loss: 0.002483389413862369
[Epoch 22, Batch 2700] loss: 0.01062507846746712
[Epoch 22, Batch 2800] loss: 0.008212491330037892
[Epoch 22, Batch 2900] loss: 0.015167657390326212
[Epoch 22, Batch 3000] loss: 0.007971466459931662
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0577
Validation Accuracy: 0.9869
Overfitting: 0.0577
[Epoch 23, Batch 100] loss: 0.003975631460956492
[Epoch 23, Batch 200] loss: 0.004001379594058108
[Epoch 23, Batch 300] loss: 0.003419737576297166
[Epoch 23, Batch 400] loss: 0.0027562285817350585
[Epoch 23, Batch 500] loss: 0.002588912908850034
[Epoch 23, Batch 600] loss: 0.0019065781083625667
[Epoch 23, Batch 700] loss: 0.0057822015085810105
[Epoch 23, Batch 800] loss: 0.003064878954708092
[Epoch 23, Batch 900] loss: 0.005195671360696679
[Epoch 23, Batch 1000] loss: 0.003013327729551065
[Epoch 23, Batch 1100] loss: 0.007831227562792833
[Epoch 23, Batch 1200] loss: 0.003788055215599115
[Epoch 23, Batch 1300] loss: 0.0024446631164028077
[Epoch 23, Batch 1400] loss: 0.003601898866963893
[Epoch 23, Batch 1500] loss: 0.0034815062960520038
[Epoch 23, Batch 1600] loss: 0.004791861077923159
[Epoch 23, Batch 1700] loss: 0.007357729474717871
[Epoch 23, Batch 1800] loss: 0.0031585233234585532
[Epoch 23, Batch 1900] loss: 0.002270175233434486
[Epoch 23, Batch 2000] loss: 0.0022457915593179223
[Epoch 23, Batch 2100] loss: 0.002599716499443332
[Epoch 23, Batch 2200] loss: 0.0037324891812800585
[Epoch 23, Batch 2300] loss: 0.001988476362337792
[Epoch 23, Batch 2400] loss: 0.007893667908202815
[Epoch 23, Batch 2500] loss: 0.015276889560536801
[Epoch 23, Batch 2600] loss: 0.010242516963373874
[Epoch 23, Batch 2700] loss: 0.007006179429470762
[Epoch 23, Batch 2800] loss: 0.02061549787904198
[Epoch 23, Batch 2900] loss: 0.007510855678332291
[Epoch 23, Batch 3000] loss: 0.004886012919175755
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9882
Overfitting: 0.0474
[Epoch 24, Batch 100] loss: 0.004004831154115322
[Epoch 24, Batch 200] loss: 0.0018088617814947837
[Epoch 24, Batch 300] loss: 0.0023427699279554306
[Epoch 24, Batch 400] loss: 0.006180678055675344
[Epoch 24, Batch 500] loss: 0.0060649795789845485
[Epoch 24, Batch 600] loss: 0.0029749245230038922
[Epoch 24, Batch 700] loss: 0.0038151907527850426
[Epoch 24, Batch 800] loss: 0.005106946760528217
[Epoch 24, Batch 900] loss: 0.003891386878304388
[Epoch 24, Batch 1000] loss: 0.005253283783288225
[Epoch 24, Batch 1100] loss: 0.005921869403043729
[Epoch 24, Batch 1200] loss: 0.007973864682670069
[Epoch 24, Batch 1300] loss: 0.002879371727659077
[Epoch 24, Batch 1400] loss: 0.004004982381414379
[Epoch 24, Batch 1500] loss: 0.007200472235731468
[Epoch 24, Batch 1600] loss: 0.004427754242626634
[Epoch 24, Batch 1700] loss: 0.004610310776936331
[Epoch 24, Batch 1800] loss: 0.011261357130730404
[Epoch 24, Batch 1900] loss: 0.005313810511182737
[Epoch 24, Batch 2000] loss: 0.004626140697392884
[Epoch 24, Batch 2100] loss: 0.004643142454079339
[Epoch 24, Batch 2200] loss: 0.00565255118460982
[Epoch 24, Batch 2300] loss: 0.006041019066857345
[Epoch 24, Batch 2400] loss: 0.00424277216909843
[Epoch 24, Batch 2500] loss: 0.003496865073808948
[Epoch 24, Batch 2600] loss: 0.0034679902723507893
[Epoch 24, Batch 2700] loss: 0.010072784053131728
[Epoch 24, Batch 2800] loss: 0.006840793717200313
[Epoch 24, Batch 2900] loss: 0.006812164268335432
[Epoch 24, Batch 3000] loss: 0.007099719081793694
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9890
Overfitting: 0.0457
Fold 5 validation loss: 0.0457
Mean validation loss across all folds for Trial 15 is 0.0498 with trial config:  l1: 256, l2: 128, lr: 0.0007002216379001282, batch_size: 16
[I 2024-12-11 06:21:46,939] Trial 14 finished with value: 0.049803163864671145 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0007002216379001282, 'batch_size': 16}. Best is trial 4 with value: 0.04724671796616846.

Selected Hyperparameters for Trial 16:
  l1: 256, l2: 128, lr: 0.0032490609166865216, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.235648959875107
[Epoch 1, Batch 200] loss: 0.9740550568699837
[Epoch 1, Batch 300] loss: 0.3924755074083805
[Epoch 1, Batch 400] loss: 0.29247234426438806
[Epoch 1, Batch 500] loss: 0.23465389613062143
[Epoch 1, Batch 600] loss: 0.21694839671254157
[Epoch 1, Batch 700] loss: 0.168369483910501
**STATS for Epoch 1** : 
Average training loss: 0.0100
Average validation loss: 0.1251
Validation Accuracy: 0.9637
Overfitting: 0.1151
Best model saved at epoch 1 with validation loss: 0.1251
[Epoch 2, Batch 100] loss: 0.1442000951617956
[Epoch 2, Batch 200] loss: 0.13292368169873953
[Epoch 2, Batch 300] loss: 0.10781897071748972
[Epoch 2, Batch 400] loss: 0.10006616227328777
[Epoch 2, Batch 500] loss: 0.08527082149870693
[Epoch 2, Batch 600] loss: 0.11688660554587842
[Epoch 2, Batch 700] loss: 0.09123714670538902
**STATS for Epoch 2** : 
Average training loss: 0.0060
Average validation loss: 0.0912
Validation Accuracy: 0.9700
Overfitting: 0.0853
Best model saved at epoch 2 with validation loss: 0.0912
[Epoch 3, Batch 100] loss: 0.08213117457460611
[Epoch 3, Batch 200] loss: 0.07132957178167999
[Epoch 3, Batch 300] loss: 0.07370997600723057
[Epoch 3, Batch 400] loss: 0.07680815719533712
[Epoch 3, Batch 500] loss: 0.08591765322722494
[Epoch 3, Batch 600] loss: 0.06075052958447486
[Epoch 3, Batch 700] loss: 0.06386465964838862
**STATS for Epoch 3** : 
Average training loss: 0.0052
Average validation loss: 0.0628
Validation Accuracy: 0.9801
Overfitting: 0.0577
Best model saved at epoch 3 with validation loss: 0.0628
[Epoch 4, Batch 100] loss: 0.056349957501515745
[Epoch 4, Batch 200] loss: 0.05525328476447612
[Epoch 4, Batch 300] loss: 0.05677982998546213
[Epoch 4, Batch 400] loss: 0.06809776952024549
[Epoch 4, Batch 500] loss: 0.06047569685149938
[Epoch 4, Batch 600] loss: 0.0549593492783606
[Epoch 4, Batch 700] loss: 0.04848121661227196
**STATS for Epoch 4** : 
Average training loss: 0.0029
Average validation loss: 0.0745
Validation Accuracy: 0.9774
Overfitting: 0.0716
[Epoch 5, Batch 100] loss: 0.053647312759421764
[Epoch 5, Batch 200] loss: 0.04409395049558953
[Epoch 5, Batch 300] loss: 0.057353608906269074
[Epoch 5, Batch 400] loss: 0.0421880898042582
[Epoch 5, Batch 500] loss: 0.046016376696061345
[Epoch 5, Batch 600] loss: 0.04690329438541085
[Epoch 5, Batch 700] loss: 0.04982039203401655
**STATS for Epoch 5** : 
Average training loss: 0.0031
Average validation loss: 0.0511
Validation Accuracy: 0.9839
Overfitting: 0.0480
Best model saved at epoch 5 with validation loss: 0.0511
[Epoch 6, Batch 100] loss: 0.03675686514819972
[Epoch 6, Batch 200] loss: 0.03022209917253349
[Epoch 6, Batch 300] loss: 0.04802224884508178
[Epoch 6, Batch 400] loss: 0.04433866672217846
[Epoch 6, Batch 500] loss: 0.03607568302191794
[Epoch 6, Batch 600] loss: 0.04361937965499237
[Epoch 6, Batch 700] loss: 0.032704920020187274
**STATS for Epoch 6** : 
Average training loss: 0.0025
Average validation loss: 0.0472
Validation Accuracy: 0.9847
Overfitting: 0.0447
Best model saved at epoch 6 with validation loss: 0.0472
[Epoch 7, Batch 100] loss: 0.02988302422920242
[Epoch 7, Batch 200] loss: 0.04249735334073193
[Epoch 7, Batch 300] loss: 0.03341418192954734
[Epoch 7, Batch 400] loss: 0.02892642040620558
[Epoch 7, Batch 500] loss: 0.02847015658975579
[Epoch 7, Batch 600] loss: 0.03075190695235506
[Epoch 7, Batch 700] loss: 0.026304773533775007
**STATS for Epoch 7** : 
Average training loss: 0.0024
Average validation loss: 0.0475
Validation Accuracy: 0.9841
Overfitting: 0.0451
[Epoch 8, Batch 100] loss: 0.02881021726236213
[Epoch 8, Batch 200] loss: 0.028947659641271457
[Epoch 8, Batch 300] loss: 0.020105729358037935
[Epoch 8, Batch 400] loss: 0.025690074223675766
[Epoch 8, Batch 500] loss: 0.027013577158795668
[Epoch 8, Batch 600] loss: 0.03075303481600713
[Epoch 8, Batch 700] loss: 0.022918374998262152
**STATS for Epoch 8** : 
Average training loss: 0.0029
Average validation loss: 0.0443
Validation Accuracy: 0.9862
Overfitting: 0.0414
Best model saved at epoch 8 with validation loss: 0.0443
[Epoch 9, Batch 100] loss: 0.024981006419402547
[Epoch 9, Batch 200] loss: 0.022954410532547626
[Epoch 9, Batch 300] loss: 0.02661621177219786
[Epoch 9, Batch 400] loss: 0.025359325995086692
[Epoch 9, Batch 500] loss: 0.02948701256304048
[Epoch 9, Batch 600] loss: 0.023159148656995966
[Epoch 9, Batch 700] loss: 0.026553582655615172
**STATS for Epoch 9** : 
Average training loss: 0.0013
Average validation loss: 0.0452
Validation Accuracy: 0.9857
Overfitting: 0.0439
[Epoch 10, Batch 100] loss: 0.017016164521337487
[Epoch 10, Batch 200] loss: 0.0229696978937136
[Epoch 10, Batch 300] loss: 0.023526510071533266
[Epoch 10, Batch 400] loss: 0.019717980588320642
[Epoch 10, Batch 500] loss: 0.02321647707169177
[Epoch 10, Batch 600] loss: 0.017112712279777044
[Epoch 10, Batch 700] loss: 0.02407115212699864
**STATS for Epoch 10** : 
Average training loss: 0.0015
Average validation loss: 0.0488
Validation Accuracy: 0.9852
Overfitting: 0.0473
[Epoch 11, Batch 100] loss: 0.023077275561809073
[Epoch 11, Batch 200] loss: 0.01899723997572437
[Epoch 11, Batch 300] loss: 0.01444076621599379
[Epoch 11, Batch 400] loss: 0.018687149428442355
[Epoch 11, Batch 500] loss: 0.017879508240148424
[Epoch 11, Batch 600] loss: 0.01874715688842116
[Epoch 11, Batch 700] loss: 0.018029256948502735
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0478
Validation Accuracy: 0.9860
Overfitting: 0.0466
[Epoch 12, Batch 100] loss: 0.012459014680352994
[Epoch 12, Batch 200] loss: 0.017080738481017762
[Epoch 12, Batch 300] loss: 0.01687683611176908
[Epoch 12, Batch 400] loss: 0.01820065927298856
[Epoch 12, Batch 500] loss: 0.017735270916600713
[Epoch 12, Batch 600] loss: 0.017073459041130265
[Epoch 12, Batch 700] loss: 0.014100988752616103
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0394
Validation Accuracy: 0.9888
Overfitting: 0.0384
Best model saved at epoch 12 with validation loss: 0.0394
[Epoch 13, Batch 100] loss: 0.011280849577742629
[Epoch 13, Batch 200] loss: 0.012688567038130713
[Epoch 13, Batch 300] loss: 0.010575671012338717
[Epoch 13, Batch 400] loss: 0.01706322825019015
[Epoch 13, Batch 500] loss: 0.01339898683145293
[Epoch 13, Batch 600] loss: 0.013881525387405417
[Epoch 13, Batch 700] loss: 0.014782948490028503
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0380
Validation Accuracy: 0.9890
Overfitting: 0.0373
Best model saved at epoch 13 with validation loss: 0.0380
[Epoch 14, Batch 100] loss: 0.008848906370985787
[Epoch 14, Batch 200] loss: 0.009627995692426339
[Epoch 14, Batch 300] loss: 0.01085866224966594
[Epoch 14, Batch 400] loss: 0.011109629259735812
[Epoch 14, Batch 500] loss: 0.009334621346351924
[Epoch 14, Batch 600] loss: 0.015493057110579684
[Epoch 14, Batch 700] loss: 0.017680352496245177
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0439
Validation Accuracy: 0.9872
Overfitting: 0.0427
[Epoch 15, Batch 100] loss: 0.01093479904695414
[Epoch 15, Batch 200] loss: 0.010177821595934802
[Epoch 15, Batch 300] loss: 0.012139370853838045
[Epoch 15, Batch 400] loss: 0.009113493580516661
[Epoch 15, Batch 500] loss: 0.013389237653318559
[Epoch 15, Batch 600] loss: 0.009148720890079858
[Epoch 15, Batch 700] loss: 0.008834625675226561
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0439
Validation Accuracy: 0.9872
Overfitting: 0.0432
[Epoch 16, Batch 100] loss: 0.011222984354317305
[Epoch 16, Batch 200] loss: 0.006334005514509045
[Epoch 16, Batch 300] loss: 0.007148402688617352
[Epoch 16, Batch 400] loss: 0.010407712687010644
[Epoch 16, Batch 500] loss: 0.00890717474874691
[Epoch 16, Batch 600] loss: 0.008999805093699251
[Epoch 16, Batch 700] loss: 0.012488791752402903
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0397
Validation Accuracy: 0.9888
Overfitting: 0.0393
[Epoch 17, Batch 100] loss: 0.007374073790051625
[Epoch 17, Batch 200] loss: 0.011587373388465494
[Epoch 17, Batch 300] loss: 0.007370642351379502
[Epoch 17, Batch 400] loss: 0.005241742258549493
[Epoch 17, Batch 500] loss: 0.012616172715934227
[Epoch 17, Batch 600] loss: 0.010352210778510198
[Epoch 17, Batch 700] loss: 0.009175644921597267
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0421
Validation Accuracy: 0.9882
Overfitting: 0.0415
[Epoch 18, Batch 100] loss: 0.006093164695703308
[Epoch 18, Batch 200] loss: 0.005496309966674744
[Epoch 18, Batch 300] loss: 0.005758579202956753
[Epoch 18, Batch 400] loss: 0.006308475519654166
[Epoch 18, Batch 500] loss: 0.009714899945320212
[Epoch 18, Batch 600] loss: 0.01209052703808993
[Epoch 18, Batch 700] loss: 0.007098940326177399
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0437
Validation Accuracy: 0.9880
Overfitting: 0.0430
[Epoch 19, Batch 100] loss: 0.008328992326860317
[Epoch 19, Batch 200] loss: 0.004713461562496377
[Epoch 19, Batch 300] loss: 0.004259397304813319
[Epoch 19, Batch 400] loss: 0.007333627468979103
[Epoch 19, Batch 500] loss: 0.007705458859491045
[Epoch 19, Batch 600] loss: 0.005113433379265188
[Epoch 19, Batch 700] loss: 0.006445679761964129
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0434
Validation Accuracy: 0.9882
Overfitting: 0.0430
[Epoch 20, Batch 100] loss: 0.005163455517122202
[Epoch 20, Batch 200] loss: 0.0037655598577839553
[Epoch 20, Batch 300] loss: 0.004214244643480925
[Epoch 20, Batch 400] loss: 0.0040025772985063665
[Epoch 20, Batch 500] loss: 0.004892750689468812
[Epoch 20, Batch 600] loss: 0.004479352037615172
[Epoch 20, Batch 700] loss: 0.007541956743843912
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0479
Validation Accuracy: 0.9875
Overfitting: 0.0474
[Epoch 21, Batch 100] loss: 0.005214407110615866
[Epoch 21, Batch 200] loss: 0.004562135921260051
[Epoch 21, Batch 300] loss: 0.00393357017186645
[Epoch 21, Batch 400] loss: 0.008713787489632523
[Epoch 21, Batch 500] loss: 0.008782144010801858
[Epoch 21, Batch 600] loss: 0.003982809233275475
[Epoch 21, Batch 700] loss: 0.008175628081953618
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0454
Validation Accuracy: 0.9879
Overfitting: 0.0450
[Epoch 22, Batch 100] loss: 0.005084693104072358
[Epoch 22, Batch 200] loss: 0.0033020184887573123
[Epoch 22, Batch 300] loss: 0.0034131253260784433
[Epoch 22, Batch 400] loss: 0.004220159772485204
[Epoch 22, Batch 500] loss: 0.0040612631480689745
[Epoch 22, Batch 600] loss: 0.005895752781434567
[Epoch 22, Batch 700] loss: 0.004175970715332369
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0453
Validation Accuracy: 0.9892
Overfitting: 0.0450
[Epoch 23, Batch 100] loss: 0.0015810392603771107
[Epoch 23, Batch 200] loss: 0.004949157453984299
[Epoch 23, Batch 300] loss: 0.0036031915939202007
[Epoch 23, Batch 400] loss: 0.005068809653075732
[Epoch 23, Batch 500] loss: 0.006253491159131954
[Epoch 23, Batch 600] loss: 0.004316697561953333
[Epoch 23, Batch 700] loss: 0.003016229141048825
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0422
Validation Accuracy: 0.9894
Overfitting: 0.0422
[Epoch 24, Batch 100] loss: 0.0032955968622263754
[Epoch 24, Batch 200] loss: 0.0021906933214268067
[Epoch 24, Batch 300] loss: 0.0020651558052031758
[Epoch 24, Batch 400] loss: 0.005184953509560728
[Epoch 24, Batch 500] loss: 0.0028475949781932284
[Epoch 24, Batch 600] loss: 0.002539005112666928
[Epoch 24, Batch 700] loss: 0.002695063998908154
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0458
Validation Accuracy: 0.9899
Overfitting: 0.0456
Fold 1 validation loss: 0.0458
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2329654932022094
[Epoch 1, Batch 200] loss: 0.9273758736252785
[Epoch 1, Batch 300] loss: 0.3852815563976765
[Epoch 1, Batch 400] loss: 0.2754586275666952
[Epoch 1, Batch 500] loss: 0.21519401647150516
[Epoch 1, Batch 600] loss: 0.19307852521538735
[Epoch 1, Batch 700] loss: 0.14779149984940887
**STATS for Epoch 1** : 
Average training loss: 0.0090
Average validation loss: 0.1531
Validation Accuracy: 0.9525
Overfitting: 0.1442
Best model saved at epoch 1 with validation loss: 0.1531
[Epoch 2, Batch 100] loss: 0.13916245855391027
[Epoch 2, Batch 200] loss: 0.12939520804211496
[Epoch 2, Batch 300] loss: 0.11716169340535998
[Epoch 2, Batch 400] loss: 0.10711446452885866
[Epoch 2, Batch 500] loss: 0.08721586328931152
[Epoch 2, Batch 600] loss: 0.0980641037132591
[Epoch 2, Batch 700] loss: 0.07946096287108957
**STATS for Epoch 2** : 
Average training loss: 0.0052
Average validation loss: 0.0878
Validation Accuracy: 0.9728
Overfitting: 0.0827
Best model saved at epoch 2 with validation loss: 0.0878
[Epoch 3, Batch 100] loss: 0.0677703346312046
[Epoch 3, Batch 200] loss: 0.0753505152463913
[Epoch 3, Batch 300] loss: 0.074127361853607
[Epoch 3, Batch 400] loss: 0.07343170572537928
[Epoch 3, Batch 500] loss: 0.06744057009462268
[Epoch 3, Batch 600] loss: 0.07258603311143816
[Epoch 3, Batch 700] loss: 0.07830905586481095
**STATS for Epoch 3** : 
Average training loss: 0.0042
Average validation loss: 0.0749
Validation Accuracy: 0.9761
Overfitting: 0.0708
Best model saved at epoch 3 with validation loss: 0.0749
[Epoch 4, Batch 100] loss: 0.05918261666316539
[Epoch 4, Batch 200] loss: 0.06356747250072659
[Epoch 4, Batch 300] loss: 0.05725501987617463
[Epoch 4, Batch 400] loss: 0.05470418391749263
[Epoch 4, Batch 500] loss: 0.05935847575776279
[Epoch 4, Batch 600] loss: 0.048421602337621154
[Epoch 4, Batch 700] loss: 0.05138231102144346
**STATS for Epoch 4** : 
Average training loss: 0.0035
Average validation loss: 0.0671
Validation Accuracy: 0.9807
Overfitting: 0.0637
Best model saved at epoch 4 with validation loss: 0.0671
[Epoch 5, Batch 100] loss: 0.04632911926601082
[Epoch 5, Batch 200] loss: 0.0483321120031178
[Epoch 5, Batch 300] loss: 0.045774293630383905
[Epoch 5, Batch 400] loss: 0.04853318698238582
[Epoch 5, Batch 500] loss: 0.04491002270719036
[Epoch 5, Batch 600] loss: 0.0417675491666887
[Epoch 5, Batch 700] loss: 0.04278541112085804
**STATS for Epoch 5** : 
Average training loss: 0.0034
Average validation loss: 0.0567
Validation Accuracy: 0.9828
Overfitting: 0.0533
Best model saved at epoch 5 with validation loss: 0.0567
[Epoch 6, Batch 100] loss: 0.03800460647558793
[Epoch 6, Batch 200] loss: 0.03290485445410013
[Epoch 6, Batch 300] loss: 0.04696920045418665
[Epoch 6, Batch 400] loss: 0.03629103686893359
[Epoch 6, Batch 500] loss: 0.036472446254920216
[Epoch 6, Batch 600] loss: 0.03698896246030927
[Epoch 6, Batch 700] loss: 0.04223580693127588
**STATS for Epoch 6** : 
Average training loss: 0.0023
Average validation loss: 0.0583
Validation Accuracy: 0.9819
Overfitting: 0.0560
[Epoch 7, Batch 100] loss: 0.027830753229791297
[Epoch 7, Batch 200] loss: 0.03597599789616652
[Epoch 7, Batch 300] loss: 0.03286815150291659
[Epoch 7, Batch 400] loss: 0.035830656248144806
[Epoch 7, Batch 500] loss: 0.026733742508804427
[Epoch 7, Batch 600] loss: 0.03300475737371016
[Epoch 7, Batch 700] loss: 0.04273724063765258
**STATS for Epoch 7** : 
Average training loss: 0.0025
Average validation loss: 0.0533
Validation Accuracy: 0.9842
Overfitting: 0.0508
Best model saved at epoch 7 with validation loss: 0.0533
[Epoch 8, Batch 100] loss: 0.027836732915602624
[Epoch 8, Batch 200] loss: 0.03143616265850142
[Epoch 8, Batch 300] loss: 0.022047856640419923
[Epoch 8, Batch 400] loss: 0.035225591716589406
[Epoch 8, Batch 500] loss: 0.025315388973685914
[Epoch 8, Batch 600] loss: 0.03249186440021731
[Epoch 8, Batch 700] loss: 0.02869173993181903
**STATS for Epoch 8** : 
Average training loss: 0.0022
Average validation loss: 0.0604
Validation Accuracy: 0.9816
Overfitting: 0.0582
[Epoch 9, Batch 100] loss: 0.024255305169499478
[Epoch 9, Batch 200] loss: 0.023729195911437274
[Epoch 9, Batch 300] loss: 0.025953079617756884
[Epoch 9, Batch 400] loss: 0.03394368906505406
[Epoch 9, Batch 500] loss: 0.02335657277610153
[Epoch 9, Batch 600] loss: 0.028388709840364755
[Epoch 9, Batch 700] loss: 0.025809188600978816
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0525
Validation Accuracy: 0.9848
Overfitting: 0.0509
Best model saved at epoch 9 with validation loss: 0.0525
[Epoch 10, Batch 100] loss: 0.020111639902170284
[Epoch 10, Batch 200] loss: 0.025146562714944594
[Epoch 10, Batch 300] loss: 0.01825661490613129
[Epoch 10, Batch 400] loss: 0.023277809369028547
[Epoch 10, Batch 500] loss: 0.020951732922112568
[Epoch 10, Batch 600] loss: 0.025917910835996736
[Epoch 10, Batch 700] loss: 0.023699114564806223
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0507
Validation Accuracy: 0.9862
Overfitting: 0.0495
Best model saved at epoch 10 with validation loss: 0.0507
[Epoch 11, Batch 100] loss: 0.014633540518698283
[Epoch 11, Batch 200] loss: 0.016372563861950767
[Epoch 11, Batch 300] loss: 0.017475988019141367
[Epoch 11, Batch 400] loss: 0.015141799129778519
[Epoch 11, Batch 500] loss: 0.025881094827491326
[Epoch 11, Batch 600] loss: 0.02409354251110926
[Epoch 11, Batch 700] loss: 0.02320203935727477
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0492
Validation Accuracy: 0.9858
Overfitting: 0.0480
Best model saved at epoch 11 with validation loss: 0.0492
[Epoch 12, Batch 100] loss: 0.021822747085534503
[Epoch 12, Batch 200] loss: 0.014334556419635191
[Epoch 12, Batch 300] loss: 0.01941986859892495
[Epoch 12, Batch 400] loss: 0.016858655760224793
[Epoch 12, Batch 500] loss: 0.013619557079073275
[Epoch 12, Batch 600] loss: 0.022511282904015387
[Epoch 12, Batch 700] loss: 0.02204047374369111
**STATS for Epoch 12** : 
Average training loss: 0.0011
Average validation loss: 0.0459
Validation Accuracy: 0.9870
Overfitting: 0.0447
Best model saved at epoch 12 with validation loss: 0.0459
[Epoch 13, Batch 100] loss: 0.015518167682166677
[Epoch 13, Batch 200] loss: 0.014492544705135516
[Epoch 13, Batch 300] loss: 0.017081714768137315
[Epoch 13, Batch 400] loss: 0.01466096909774933
[Epoch 13, Batch 500] loss: 0.014807256745989435
[Epoch 13, Batch 600] loss: 0.01718987207830651
[Epoch 13, Batch 700] loss: 0.017855744709813735
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0455
Validation Accuracy: 0.9870
Overfitting: 0.0446
Best model saved at epoch 13 with validation loss: 0.0455
[Epoch 14, Batch 100] loss: 0.01287636790468241
[Epoch 14, Batch 200] loss: 0.015494850020331796
[Epoch 14, Batch 300] loss: 0.012879408632143168
[Epoch 14, Batch 400] loss: 0.00872843283446855
[Epoch 14, Batch 500] loss: 0.012953586432995507
[Epoch 14, Batch 600] loss: 0.020481664329126945
[Epoch 14, Batch 700] loss: 0.013640017984434961
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0457
Validation Accuracy: 0.9878
Overfitting: 0.0449
[Epoch 15, Batch 100] loss: 0.009828568788943812
[Epoch 15, Batch 200] loss: 0.009032633948809234
[Epoch 15, Batch 300] loss: 0.008723663118871627
[Epoch 15, Batch 400] loss: 0.013777854507352458
[Epoch 15, Batch 500] loss: 0.01249410861360957
[Epoch 15, Batch 600] loss: 0.008634276652592233
[Epoch 15, Batch 700] loss: 0.01039693445112789
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0520
Validation Accuracy: 0.9857
Overfitting: 0.0511
[Epoch 16, Batch 100] loss: 0.007519189678132534
[Epoch 16, Batch 200] loss: 0.009568406001344556
[Epoch 16, Batch 300] loss: 0.006481232946607633
[Epoch 16, Batch 400] loss: 0.010378674771582155
[Epoch 16, Batch 500] loss: 0.00952325655875029
[Epoch 16, Batch 600] loss: 0.010361380740141613
[Epoch 16, Batch 700] loss: 0.013680833369726315
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0484
Validation Accuracy: 0.9872
Overfitting: 0.0477
[Epoch 17, Batch 100] loss: 0.006377938102814369
[Epoch 17, Batch 200] loss: 0.00650046107963135
[Epoch 17, Batch 300] loss: 0.006279472381193045
[Epoch 17, Batch 400] loss: 0.011210179869449348
[Epoch 17, Batch 500] loss: 0.008497895651089493
[Epoch 17, Batch 600] loss: 0.008521103065722855
[Epoch 17, Batch 700] loss: 0.012990706761920592
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0509
Validation Accuracy: 0.9862
Overfitting: 0.0502
[Epoch 18, Batch 100] loss: 0.009024876455005142
[Epoch 18, Batch 200] loss: 0.00684621938111377
[Epoch 18, Batch 300] loss: 0.006022253757182625
[Epoch 18, Batch 400] loss: 0.009039589470194186
[Epoch 18, Batch 500] loss: 0.00743835190020036
[Epoch 18, Batch 600] loss: 0.005459158716403181
[Epoch 18, Batch 700] loss: 0.008796962613123469
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0566
Validation Accuracy: 0.9862
Overfitting: 0.0557
[Epoch 19, Batch 100] loss: 0.012460759555615368
[Epoch 19, Batch 200] loss: 0.004987364218432049
[Epoch 19, Batch 300] loss: 0.007171200920893171
[Epoch 19, Batch 400] loss: 0.0065210236034181435
[Epoch 19, Batch 500] loss: 0.0073907066212996145
[Epoch 19, Batch 600] loss: 0.007053373602684587
[Epoch 19, Batch 700] loss: 0.012276533762560575
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0522
Validation Accuracy: 0.9866
Overfitting: 0.0517
[Epoch 20, Batch 100] loss: 0.003444011649198728
[Epoch 20, Batch 200] loss: 0.003865881946767331
[Epoch 20, Batch 300] loss: 0.00618732008668303
[Epoch 20, Batch 400] loss: 0.009180730761836458
[Epoch 20, Batch 500] loss: 0.006349549962033052
[Epoch 20, Batch 600] loss: 0.008356897284829756
[Epoch 20, Batch 700] loss: 0.008852974026522133
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0466
Validation Accuracy: 0.9879
Overfitting: 0.0461
[Epoch 21, Batch 100] loss: 0.005074681068217615
[Epoch 21, Batch 200] loss: 0.0035544945066430956
[Epoch 21, Batch 300] loss: 0.004973405580549297
[Epoch 21, Batch 400] loss: 0.005820972485053062
[Epoch 21, Batch 500] loss: 0.0040629195769724905
[Epoch 21, Batch 600] loss: 0.007001673501745245
[Epoch 21, Batch 700] loss: 0.007817288541300513
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0547
Validation Accuracy: 0.9864
Overfitting: 0.0541
[Epoch 22, Batch 100] loss: 0.008493765750681632
[Epoch 22, Batch 200] loss: 0.006008538313690224
[Epoch 22, Batch 300] loss: 0.0050991676560079215
[Epoch 22, Batch 400] loss: 0.005942457290784659
[Epoch 22, Batch 500] loss: 0.005656622721508029
[Epoch 22, Batch 600] loss: 0.005103645856706862
[Epoch 22, Batch 700] loss: 0.005228942588873906
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0667
Validation Accuracy: 0.9840
Overfitting: 0.0661
[Epoch 23, Batch 100] loss: 0.0052917513524698735
[Epoch 23, Batch 200] loss: 0.003414616896247935
[Epoch 23, Batch 300] loss: 0.006215631740124081
[Epoch 23, Batch 400] loss: 0.005249116265931661
[Epoch 23, Batch 500] loss: 0.0029502348500864174
[Epoch 23, Batch 600] loss: 0.004132353606437391
[Epoch 23, Batch 700] loss: 0.007582667268825389
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0527
Validation Accuracy: 0.9882
Overfitting: 0.0523
[Epoch 24, Batch 100] loss: 0.003058794087046408
[Epoch 24, Batch 200] loss: 0.0019602375959948404
[Epoch 24, Batch 300] loss: 0.0023039420895293004
[Epoch 24, Batch 400] loss: 0.004355072095809192
[Epoch 24, Batch 500] loss: 0.004624548296942521
[Epoch 24, Batch 600] loss: 0.004681454811707226
[Epoch 24, Batch 700] loss: 0.002394515251817211
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0503
Validation Accuracy: 0.9893
Overfitting: 0.0500
Fold 2 validation loss: 0.0503
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2696733236312867
[Epoch 1, Batch 200] loss: 1.1846397665143014
[Epoch 1, Batch 300] loss: 0.4004956339299679
[Epoch 1, Batch 400] loss: 0.30332373149693015
[Epoch 1, Batch 500] loss: 0.2267579349130392
[Epoch 1, Batch 600] loss: 0.19401487078517676
[Epoch 1, Batch 700] loss: 0.15316968934610486
**STATS for Epoch 1** : 
Average training loss: 0.0101
Average validation loss: 0.1566
Validation Accuracy: 0.9504
Overfitting: 0.1466
Best model saved at epoch 1 with validation loss: 0.1566
[Epoch 2, Batch 100] loss: 0.1450435079447925
[Epoch 2, Batch 200] loss: 0.10955979950726032
[Epoch 2, Batch 300] loss: 0.1324372649937868
[Epoch 2, Batch 400] loss: 0.11245459702797234
[Epoch 2, Batch 500] loss: 0.10692385461181403
[Epoch 2, Batch 600] loss: 0.10286166179925203
[Epoch 2, Batch 700] loss: 0.09907196569256485
**STATS for Epoch 2** : 
Average training loss: 0.0061
Average validation loss: 0.0994
Validation Accuracy: 0.9698
Overfitting: 0.0934
Best model saved at epoch 2 with validation loss: 0.0994
[Epoch 3, Batch 100] loss: 0.10310487630777061
[Epoch 3, Batch 200] loss: 0.07327611639164389
[Epoch 3, Batch 300] loss: 0.0887179579026997
[Epoch 3, Batch 400] loss: 0.07941726106684655
[Epoch 3, Batch 500] loss: 0.07570393823087215
[Epoch 3, Batch 600] loss: 0.0747477194457315
[Epoch 3, Batch 700] loss: 0.07794606070034206
**STATS for Epoch 3** : 
Average training loss: 0.0051
Average validation loss: 0.0838
Validation Accuracy: 0.9742
Overfitting: 0.0788
Best model saved at epoch 3 with validation loss: 0.0838
[Epoch 4, Batch 100] loss: 0.0750507912132889
[Epoch 4, Batch 200] loss: 0.06277858369983733
[Epoch 4, Batch 300] loss: 0.07662341435439884
[Epoch 4, Batch 400] loss: 0.05756919545819983
[Epoch 4, Batch 500] loss: 0.05160634235711768
[Epoch 4, Batch 600] loss: 0.06646611674223095
[Epoch 4, Batch 700] loss: 0.06743839330971241
**STATS for Epoch 4** : 
Average training loss: 0.0043
Average validation loss: 0.0693
Validation Accuracy: 0.9782
Overfitting: 0.0650
Best model saved at epoch 4 with validation loss: 0.0693
[Epoch 5, Batch 100] loss: 0.048990798811428246
[Epoch 5, Batch 200] loss: 0.055346488999202845
[Epoch 5, Batch 300] loss: 0.04864813354099169
[Epoch 5, Batch 400] loss: 0.059058187752962114
[Epoch 5, Batch 500] loss: 0.05663634151220322
[Epoch 5, Batch 600] loss: 0.05072698197560385
[Epoch 5, Batch 700] loss: 0.05310382763389498
**STATS for Epoch 5** : 
Average training loss: 0.0036
Average validation loss: 0.0606
Validation Accuracy: 0.9807
Overfitting: 0.0570
Best model saved at epoch 5 with validation loss: 0.0606
[Epoch 6, Batch 100] loss: 0.03866751549532637
[Epoch 6, Batch 200] loss: 0.04254402006743476
[Epoch 6, Batch 300] loss: 0.04382662521675229
[Epoch 6, Batch 400] loss: 0.04201542912167497
[Epoch 6, Batch 500] loss: 0.04014178587123752
[Epoch 6, Batch 600] loss: 0.05082302643219009
[Epoch 6, Batch 700] loss: 0.04255386439384892
**STATS for Epoch 6** : 
Average training loss: 0.0028
Average validation loss: 0.0653
Validation Accuracy: 0.9789
Overfitting: 0.0625
[Epoch 7, Batch 100] loss: 0.03505909126601182
[Epoch 7, Batch 200] loss: 0.030976909608580173
[Epoch 7, Batch 300] loss: 0.04217750428244472
[Epoch 7, Batch 400] loss: 0.042140065466519445
[Epoch 7, Batch 500] loss: 0.03230758552788757
[Epoch 7, Batch 600] loss: 0.044869536228943616
[Epoch 7, Batch 700] loss: 0.030380346871679648
**STATS for Epoch 7** : 
Average training loss: 0.0027
Average validation loss: 0.0557
Validation Accuracy: 0.9830
Overfitting: 0.0530
Best model saved at epoch 7 with validation loss: 0.0557
[Epoch 8, Batch 100] loss: 0.031717301252065226
[Epoch 8, Batch 200] loss: 0.026588921846123412
[Epoch 8, Batch 300] loss: 0.031210285602428486
[Epoch 8, Batch 400] loss: 0.030582831288920715
[Epoch 8, Batch 500] loss: 0.038022498160135004
[Epoch 8, Batch 600] loss: 0.042939865600783375
[Epoch 8, Batch 700] loss: 0.037276565600186586
**STATS for Epoch 8** : 
Average training loss: 0.0029
Average validation loss: 0.0464
Validation Accuracy: 0.9853
Overfitting: 0.0435
Best model saved at epoch 8 with validation loss: 0.0464
[Epoch 9, Batch 100] loss: 0.021748620509169994
[Epoch 9, Batch 200] loss: 0.022281420763465575
[Epoch 9, Batch 300] loss: 0.03521551971323788
[Epoch 9, Batch 400] loss: 0.03604859034181573
[Epoch 9, Batch 500] loss: 0.03303390007989947
[Epoch 9, Batch 600] loss: 0.027929784243460744
[Epoch 9, Batch 700] loss: 0.0284633651713375
**STATS for Epoch 9** : 
Average training loss: 0.0024
Average validation loss: 0.0529
Validation Accuracy: 0.9832
Overfitting: 0.0504
[Epoch 10, Batch 100] loss: 0.025232186038629152
[Epoch 10, Batch 200] loss: 0.026743056485429406
[Epoch 10, Batch 300] loss: 0.02234583780053072
[Epoch 10, Batch 400] loss: 0.021802599260990974
[Epoch 10, Batch 500] loss: 0.02879728468193207
[Epoch 10, Batch 600] loss: 0.025464284773916004
[Epoch 10, Batch 700] loss: 0.027088831432629377
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0481
Validation Accuracy: 0.9866
Overfitting: 0.0468
[Epoch 11, Batch 100] loss: 0.016422946986858734
[Epoch 11, Batch 200] loss: 0.015825823439226953
[Epoch 11, Batch 300] loss: 0.025022291028872132
[Epoch 11, Batch 400] loss: 0.020195330478891264
[Epoch 11, Batch 500] loss: 0.017872838639304972
[Epoch 11, Batch 600] loss: 0.023482885428820738
[Epoch 11, Batch 700] loss: 0.02138480104622431
**STATS for Epoch 11** : 
Average training loss: 0.0018
Average validation loss: 0.0538
Validation Accuracy: 0.9843
Overfitting: 0.0520
[Epoch 12, Batch 100] loss: 0.017965150176896715
[Epoch 12, Batch 200] loss: 0.019630593306501395
[Epoch 12, Batch 300] loss: 0.017306101438298357
[Epoch 12, Batch 400] loss: 0.01848161880116095
[Epoch 12, Batch 500] loss: 0.018108833369333298
[Epoch 12, Batch 600] loss: 0.017154598605411592
[Epoch 12, Batch 700] loss: 0.021063811786589212
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0533
Validation Accuracy: 0.9848
Overfitting: 0.0521
[Epoch 13, Batch 100] loss: 0.010641074070736067
[Epoch 13, Batch 200] loss: 0.016109373508079443
[Epoch 13, Batch 300] loss: 0.01798232063098112
[Epoch 13, Batch 400] loss: 0.02228695575380698
[Epoch 13, Batch 500] loss: 0.016869829158677022
[Epoch 13, Batch 600] loss: 0.013083767170028295
[Epoch 13, Batch 700] loss: 0.013786293491721153
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0507
Validation Accuracy: 0.9859
Overfitting: 0.0497
[Epoch 14, Batch 100] loss: 0.010904054833154077
[Epoch 14, Batch 200] loss: 0.014898060659324983
[Epoch 14, Batch 300] loss: 0.01272016381524736
[Epoch 14, Batch 400] loss: 0.010095499734889017
[Epoch 14, Batch 500] loss: 0.019428639346151612
[Epoch 14, Batch 600] loss: 0.016219764512206893
[Epoch 14, Batch 700] loss: 0.01711440274542838
**STATS for Epoch 14** : 
Average training loss: 0.0014
Average validation loss: 0.0549
Validation Accuracy: 0.9846
Overfitting: 0.0534
[Epoch 15, Batch 100] loss: 0.011812794617726467
[Epoch 15, Batch 200] loss: 0.013430135930539109
[Epoch 15, Batch 300] loss: 0.010840941404894692
[Epoch 15, Batch 400] loss: 0.012934042323613539
[Epoch 15, Batch 500] loss: 0.013705338642175775
[Epoch 15, Batch 600] loss: 0.013971364280878333
[Epoch 15, Batch 700] loss: 0.012198237205884652
**STATS for Epoch 15** : 
Average training loss: 0.0014
Average validation loss: 0.0703
Validation Accuracy: 0.9818
Overfitting: 0.0689
[Epoch 16, Batch 100] loss: 0.009683296351431636
[Epoch 16, Batch 200] loss: 0.00968727284536726
[Epoch 16, Batch 300] loss: 0.007949854843245703
[Epoch 16, Batch 400] loss: 0.008426814802878652
[Epoch 16, Batch 500] loss: 0.00989054606492573
[Epoch 16, Batch 600] loss: 0.011946011611362337
[Epoch 16, Batch 700] loss: 0.00938932106269931
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0549
Validation Accuracy: 0.9861
Overfitting: 0.0543
[Epoch 17, Batch 100] loss: 0.007293303728874889
[Epoch 17, Batch 200] loss: 0.005963151936302893
[Epoch 17, Batch 300] loss: 0.012042911520693452
[Epoch 17, Batch 400] loss: 0.008483047866611741
[Epoch 17, Batch 500] loss: 0.007534177893830929
[Epoch 17, Batch 600] loss: 0.010955491387212532
[Epoch 17, Batch 700] loss: 0.00910124123132846
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0510
Validation Accuracy: 0.9868
Overfitting: 0.0505
[Epoch 18, Batch 100] loss: 0.007162631552491802
[Epoch 18, Batch 200] loss: 0.007418963331365376
[Epoch 18, Batch 300] loss: 0.0068316452639192
[Epoch 18, Batch 400] loss: 0.0063602681514748835
[Epoch 18, Batch 500] loss: 0.005272624316057772
[Epoch 18, Batch 600] loss: 0.008382378037058515
[Epoch 18, Batch 700] loss: 0.0077407176554334
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0460
Validation Accuracy: 0.9882
Overfitting: 0.0454
Best model saved at epoch 18 with validation loss: 0.0460
[Epoch 19, Batch 100] loss: 0.004610856078215875
[Epoch 19, Batch 200] loss: 0.0036097413197421703
[Epoch 19, Batch 300] loss: 0.01456242867589026
[Epoch 19, Batch 400] loss: 0.009401708260775195
[Epoch 19, Batch 500] loss: 0.008378580158678232
[Epoch 19, Batch 600] loss: 0.008234191258616193
[Epoch 19, Batch 700] loss: 0.006194812712965359
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0521
Validation Accuracy: 0.9872
Overfitting: 0.0516
[Epoch 20, Batch 100] loss: 0.004856295511817734
[Epoch 20, Batch 200] loss: 0.005212211240941542
[Epoch 20, Batch 300] loss: 0.0035915987845874043
[Epoch 20, Batch 400] loss: 0.005180421438963094
[Epoch 20, Batch 500] loss: 0.0042871178681889435
[Epoch 20, Batch 600] loss: 0.005892652479888056
[Epoch 20, Batch 700] loss: 0.00983434661130559
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0624
Validation Accuracy: 0.9838
Overfitting: 0.0621
[Epoch 21, Batch 100] loss: 0.005974523088007118
[Epoch 21, Batch 200] loss: 0.006222777012662845
[Epoch 21, Batch 300] loss: 0.005332804624595155
[Epoch 21, Batch 400] loss: 0.004275222641563232
[Epoch 21, Batch 500] loss: 0.006713731188228849
[Epoch 21, Batch 600] loss: 0.005016312636944349
[Epoch 21, Batch 700] loss: 0.0034091386363888886
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0518
Validation Accuracy: 0.9877
Overfitting: 0.0515
[Epoch 22, Batch 100] loss: 0.0024961377761428595
[Epoch 22, Batch 200] loss: 0.0022644902815591194
[Epoch 22, Batch 300] loss: 0.0024369589354319033
[Epoch 22, Batch 400] loss: 0.0025678041477294757
[Epoch 22, Batch 500] loss: 0.005454337844330439
[Epoch 22, Batch 600] loss: 0.0027263550124553147
[Epoch 22, Batch 700] loss: 0.005089188876900153
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0570
Validation Accuracy: 0.9867
Overfitting: 0.0566
[Epoch 23, Batch 100] loss: 0.0032729371990717483
[Epoch 23, Batch 200] loss: 0.001431888194365456
[Epoch 23, Batch 300] loss: 0.001980112124738298
[Epoch 23, Batch 400] loss: 0.002232598004047759
[Epoch 23, Batch 500] loss: 0.0025567981102540215
[Epoch 23, Batch 600] loss: 0.002973521107310262
[Epoch 23, Batch 700] loss: 0.0023232286978782215
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0648
Validation Accuracy: 0.9866
Overfitting: 0.0644
[Epoch 24, Batch 100] loss: 0.0035297343047659526
[Epoch 24, Batch 200] loss: 0.002353251179192739
[Epoch 24, Batch 300] loss: 0.001600903048984037
[Epoch 24, Batch 400] loss: 0.001334142232699378
[Epoch 24, Batch 500] loss: 0.0022370705467437803
[Epoch 24, Batch 600] loss: 0.0013500978866522928
[Epoch 24, Batch 700] loss: 0.0021791672162930808
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0567
Validation Accuracy: 0.9884
Overfitting: 0.0566
Fold 3 validation loss: 0.0567
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.1610187602043154
[Epoch 1, Batch 200] loss: 0.7639690068364143
[Epoch 1, Batch 300] loss: 0.41178362518548967
[Epoch 1, Batch 400] loss: 0.2873039084672928
[Epoch 1, Batch 500] loss: 0.23520561527460815
[Epoch 1, Batch 600] loss: 0.18810168709605932
[Epoch 1, Batch 700] loss: 0.16678506046533584
**STATS for Epoch 1** : 
Average training loss: 0.0099
Average validation loss: 0.1314
Validation Accuracy: 0.9589
Overfitting: 0.1214
Best model saved at epoch 1 with validation loss: 0.1314
[Epoch 2, Batch 100] loss: 0.12067392218858003
[Epoch 2, Batch 200] loss: 0.1285151555761695
[Epoch 2, Batch 300] loss: 0.11074454791843891
[Epoch 2, Batch 400] loss: 0.10327933792024852
[Epoch 2, Batch 500] loss: 0.10972959980368614
[Epoch 2, Batch 600] loss: 0.0940386270172894
[Epoch 2, Batch 700] loss: 0.0893501657154411
**STATS for Epoch 2** : 
Average training loss: 0.0056
Average validation loss: 0.0877
Validation Accuracy: 0.9704
Overfitting: 0.0821
Best model saved at epoch 2 with validation loss: 0.0877
[Epoch 3, Batch 100] loss: 0.08318794026970863
[Epoch 3, Batch 200] loss: 0.07752166281454265
[Epoch 3, Batch 300] loss: 0.08182276238221675
[Epoch 3, Batch 400] loss: 0.07418225693982095
[Epoch 3, Batch 500] loss: 0.06568501106463373
[Epoch 3, Batch 600] loss: 0.07067287550773471
[Epoch 3, Batch 700] loss: 0.07293092263396829
**STATS for Epoch 3** : 
Average training loss: 0.0040
Average validation loss: 0.0653
Validation Accuracy: 0.9789
Overfitting: 0.0613
Best model saved at epoch 3 with validation loss: 0.0653
[Epoch 4, Batch 100] loss: 0.05118299458175898
[Epoch 4, Batch 200] loss: 0.05946456213016063
[Epoch 4, Batch 300] loss: 0.0628719428111799
[Epoch 4, Batch 400] loss: 0.056359018464572724
[Epoch 4, Batch 500] loss: 0.05537521168356761
[Epoch 4, Batch 600] loss: 0.04602020996622741
[Epoch 4, Batch 700] loss: 0.061298777947667984
**STATS for Epoch 4** : 
Average training loss: 0.0039
Average validation loss: 0.0537
Validation Accuracy: 0.9837
Overfitting: 0.0498
Best model saved at epoch 4 with validation loss: 0.0537
[Epoch 5, Batch 100] loss: 0.05057586664799601
[Epoch 5, Batch 200] loss: 0.04114396317163482
[Epoch 5, Batch 300] loss: 0.037083624463994054
[Epoch 5, Batch 400] loss: 0.04939745927229524
[Epoch 5, Batch 500] loss: 0.04537769247894175
[Epoch 5, Batch 600] loss: 0.053057959019206465
[Epoch 5, Batch 700] loss: 0.04804403420188464
**STATS for Epoch 5** : 
Average training loss: 0.0027
Average validation loss: 0.0510
Validation Accuracy: 0.9847
Overfitting: 0.0483
Best model saved at epoch 5 with validation loss: 0.0510
[Epoch 6, Batch 100] loss: 0.038792424376588315
[Epoch 6, Batch 200] loss: 0.037999473428353664
[Epoch 6, Batch 300] loss: 0.02988493314362131
[Epoch 6, Batch 400] loss: 0.03999126101029105
[Epoch 6, Batch 500] loss: 0.0402231553895399
[Epoch 6, Batch 600] loss: 0.03885691790375859
[Epoch 6, Batch 700] loss: 0.036533605804434044
**STATS for Epoch 6** : 
Average training loss: 0.0029
Average validation loss: 0.0496
Validation Accuracy: 0.9843
Overfitting: 0.0467
Best model saved at epoch 6 with validation loss: 0.0496
[Epoch 7, Batch 100] loss: 0.030791732693905942
[Epoch 7, Batch 200] loss: 0.029458670269232243
[Epoch 7, Batch 300] loss: 0.03456878836965188
[Epoch 7, Batch 400] loss: 0.027227927716448903
[Epoch 7, Batch 500] loss: 0.03409777679480612
[Epoch 7, Batch 600] loss: 0.02770628852653317
[Epoch 7, Batch 700] loss: 0.038043116122134964
**STATS for Epoch 7** : 
Average training loss: 0.0027
Average validation loss: 0.0444
Validation Accuracy: 0.9858
Overfitting: 0.0417
Best model saved at epoch 7 with validation loss: 0.0444
[Epoch 8, Batch 100] loss: 0.024167171604931356
[Epoch 8, Batch 200] loss: 0.027418818990699947
[Epoch 8, Batch 300] loss: 0.0254445334430784
[Epoch 8, Batch 400] loss: 0.029479430911596865
[Epoch 8, Batch 500] loss: 0.02723959774011746
[Epoch 8, Batch 600] loss: 0.02133882257854566
[Epoch 8, Batch 700] loss: 0.027501833795104177
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0452
Validation Accuracy: 0.9852
Overfitting: 0.0433
[Epoch 9, Batch 100] loss: 0.018729516893508845
[Epoch 9, Batch 200] loss: 0.024317380855209195
[Epoch 9, Batch 300] loss: 0.01997601435694378
[Epoch 9, Batch 400] loss: 0.022153333374881186
[Epoch 9, Batch 500] loss: 0.026316824124660344
[Epoch 9, Batch 600] loss: 0.02452236235199962
[Epoch 9, Batch 700] loss: 0.02787416369013954
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0491
Validation Accuracy: 0.9848
Overfitting: 0.0475
[Epoch 10, Batch 100] loss: 0.017571463768254036
[Epoch 10, Batch 200] loss: 0.01897031625674572
[Epoch 10, Batch 300] loss: 0.021770996307313908
[Epoch 10, Batch 400] loss: 0.020781558876042255
[Epoch 10, Batch 500] loss: 0.026401661221752873
[Epoch 10, Batch 600] loss: 0.01788391245645471
[Epoch 10, Batch 700] loss: 0.022697355214040725
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0399
Validation Accuracy: 0.9878
Overfitting: 0.0383
Best model saved at epoch 10 with validation loss: 0.0399
[Epoch 11, Batch 100] loss: 0.015267063359497115
[Epoch 11, Batch 200] loss: 0.01756321997352643
[Epoch 11, Batch 300] loss: 0.014972918776911683
[Epoch 11, Batch 400] loss: 0.01931032355860225
[Epoch 11, Batch 500] loss: 0.02114222439849982
[Epoch 11, Batch 600] loss: 0.02149450933560729
[Epoch 11, Batch 700] loss: 0.016460151677165413
**STATS for Epoch 11** : 
Average training loss: 0.0014
Average validation loss: 0.0407
Validation Accuracy: 0.9888
Overfitting: 0.0393
[Epoch 12, Batch 100] loss: 0.016676604487292933
[Epoch 12, Batch 200] loss: 0.013513071338093142
[Epoch 12, Batch 300] loss: 0.012727473245759029
[Epoch 12, Batch 400] loss: 0.018272752483317164
[Epoch 12, Batch 500] loss: 0.017791959840105846
[Epoch 12, Batch 600] loss: 0.017702732375619236
[Epoch 12, Batch 700] loss: 0.014756854826409836
**STATS for Epoch 12** : 
Average training loss: 0.0011
Average validation loss: 0.0426
Validation Accuracy: 0.9872
Overfitting: 0.0415
[Epoch 13, Batch 100] loss: 0.012337210540426895
[Epoch 13, Batch 200] loss: 0.015710025111111463
[Epoch 13, Batch 300] loss: 0.01919095896242652
[Epoch 13, Batch 400] loss: 0.01275354003882967
[Epoch 13, Batch 500] loss: 0.013182298558240291
[Epoch 13, Batch 600] loss: 0.00999487018067157
[Epoch 13, Batch 700] loss: 0.01581801733802422
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0381
Validation Accuracy: 0.9890
Overfitting: 0.0373
Best model saved at epoch 13 with validation loss: 0.0381
[Epoch 14, Batch 100] loss: 0.009671872283215635
[Epoch 14, Batch 200] loss: 0.008926554387362557
[Epoch 14, Batch 300] loss: 0.013845937918376875
[Epoch 14, Batch 400] loss: 0.012835262790613342
[Epoch 14, Batch 500] loss: 0.009079693826570291
[Epoch 14, Batch 600] loss: 0.011407578665966867
[Epoch 14, Batch 700] loss: 0.01714787147269817
**STATS for Epoch 14** : 
Average training loss: 0.0014
Average validation loss: 0.0477
Validation Accuracy: 0.9874
Overfitting: 0.0463
[Epoch 15, Batch 100] loss: 0.011127170595573261
[Epoch 15, Batch 200] loss: 0.007883068541705143
[Epoch 15, Batch 300] loss: 0.011958627346684807
[Epoch 15, Batch 400] loss: 0.008611830519803333
[Epoch 15, Batch 500] loss: 0.0077185374762484575
[Epoch 15, Batch 600] loss: 0.011414721727342113
[Epoch 15, Batch 700] loss: 0.009864239656744758
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0439
Validation Accuracy: 0.9872
Overfitting: 0.0432
[Epoch 16, Batch 100] loss: 0.008703823390860635
[Epoch 16, Batch 200] loss: 0.006178249074364431
[Epoch 16, Batch 300] loss: 0.007655278716993052
[Epoch 16, Batch 400] loss: 0.009679033591746702
[Epoch 16, Batch 500] loss: 0.010348822135256341
[Epoch 16, Batch 600] loss: 0.009110170052954345
[Epoch 16, Batch 700] loss: 0.012345904975227313
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0485
Validation Accuracy: 0.9867
Overfitting: 0.0477
[Epoch 17, Batch 100] loss: 0.006384429100507987
[Epoch 17, Batch 200] loss: 0.00792913465651509
[Epoch 17, Batch 300] loss: 0.004522014635513188
[Epoch 17, Batch 400] loss: 0.005936591841164045
[Epoch 17, Batch 500] loss: 0.00724860474039815
[Epoch 17, Batch 600] loss: 0.01191441917551856
[Epoch 17, Batch 700] loss: 0.00964072388382192
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0457
Validation Accuracy: 0.9880
Overfitting: 0.0451
[Epoch 18, Batch 100] loss: 0.004932070273825957
[Epoch 18, Batch 200] loss: 0.003423135516386537
[Epoch 18, Batch 300] loss: 0.00873645193008997
[Epoch 18, Batch 400] loss: 0.0066921616360195915
[Epoch 18, Batch 500] loss: 0.005510847462719539
[Epoch 18, Batch 600] loss: 0.007427695484948344
[Epoch 18, Batch 700] loss: 0.010837468900208478
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0473
Validation Accuracy: 0.9877
Overfitting: 0.0467
[Epoch 19, Batch 100] loss: 0.005704168445026881
[Epoch 19, Batch 200] loss: 0.00491147382876079
[Epoch 19, Batch 300] loss: 0.007009765397233423
[Epoch 19, Batch 400] loss: 0.0046838197041506645
[Epoch 19, Batch 500] loss: 0.006510006524149503
[Epoch 19, Batch 600] loss: 0.008046303245573655
[Epoch 19, Batch 700] loss: 0.0058058330012772785
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0466
Validation Accuracy: 0.9880
Overfitting: 0.0462
[Epoch 20, Batch 100] loss: 0.0035125540629087483
[Epoch 20, Batch 200] loss: 0.004529952198863612
[Epoch 20, Batch 300] loss: 0.0035287912077910733
[Epoch 20, Batch 400] loss: 0.0024256671319380983
[Epoch 20, Batch 500] loss: 0.007732108593288558
[Epoch 20, Batch 600] loss: 0.007425138581456849
[Epoch 20, Batch 700] loss: 0.0070833676667098186
**STATS for Epoch 20** : 
Average training loss: 0.0008
Average validation loss: 0.0512
Validation Accuracy: 0.9877
Overfitting: 0.0504
[Epoch 21, Batch 100] loss: 0.007770230787537002
[Epoch 21, Batch 200] loss: 0.0055755139696339025
[Epoch 21, Batch 300] loss: 0.003989307156552968
[Epoch 21, Batch 400] loss: 0.004607481929815549
[Epoch 21, Batch 500] loss: 0.003642546010942169
[Epoch 21, Batch 600] loss: 0.005220499252354785
[Epoch 21, Batch 700] loss: 0.0052793533051954
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0489
Validation Accuracy: 0.9869
Overfitting: 0.0484
[Epoch 22, Batch 100] loss: 0.002849725959931675
[Epoch 22, Batch 200] loss: 0.004134285612162785
[Epoch 22, Batch 300] loss: 0.0019252904465793107
[Epoch 22, Batch 400] loss: 0.003543186615097511
[Epoch 22, Batch 500] loss: 0.003727288931604562
[Epoch 22, Batch 600] loss: 0.0060776349590923925
[Epoch 22, Batch 700] loss: 0.0036221183726229357
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0483
Validation Accuracy: 0.9891
Overfitting: 0.0481
[Epoch 23, Batch 100] loss: 0.0023835455020162046
[Epoch 23, Batch 200] loss: 0.0021990634244957617
[Epoch 23, Batch 300] loss: 0.0032888599890611657
[Epoch 23, Batch 400] loss: 0.002803923444962493
[Epoch 23, Batch 500] loss: 0.004114699068522896
[Epoch 23, Batch 600] loss: 0.0032994360922384658
[Epoch 23, Batch 700] loss: 0.004706906074216022
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0484
Validation Accuracy: 0.9889
Overfitting: 0.0483
[Epoch 24, Batch 100] loss: 0.0032628986360487035
[Epoch 24, Batch 200] loss: 0.0015476855491942843
[Epoch 24, Batch 300] loss: 0.0022897523282517794
[Epoch 24, Batch 400] loss: 0.0025510800993379236
[Epoch 24, Batch 500] loss: 0.0015489651881853206
[Epoch 24, Batch 600] loss: 0.002027863927129374
[Epoch 24, Batch 700] loss: 0.0013412501800030441
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0487
Validation Accuracy: 0.9887
Overfitting: 0.0484
Fold 4 validation loss: 0.0487
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2911426067352294
[Epoch 1, Batch 200] loss: 2.0554199159145354
[Epoch 1, Batch 300] loss: 0.671565887182951
[Epoch 1, Batch 400] loss: 0.34571438021957873
[Epoch 1, Batch 500] loss: 0.22768509574234486
[Epoch 1, Batch 600] loss: 0.19184568364173174
[Epoch 1, Batch 700] loss: 0.14609786098822952
**STATS for Epoch 1** : 
Average training loss: 0.0101
Average validation loss: 0.1391
Validation Accuracy: 0.9560
Overfitting: 0.1289
Best model saved at epoch 1 with validation loss: 0.1391
[Epoch 2, Batch 100] loss: 0.12689823027700187
[Epoch 2, Batch 200] loss: 0.1178711692802608
[Epoch 2, Batch 300] loss: 0.10701383203268051
[Epoch 2, Batch 400] loss: 0.09994825214147568
[Epoch 2, Batch 500] loss: 0.10021955638192594
[Epoch 2, Batch 600] loss: 0.09169895995873958
[Epoch 2, Batch 700] loss: 0.08824316374026239
**STATS for Epoch 2** : 
Average training loss: 0.0057
Average validation loss: 0.0810
Validation Accuracy: 0.9738
Overfitting: 0.0754
Best model saved at epoch 2 with validation loss: 0.0810
[Epoch 3, Batch 100] loss: 0.076026939637959
[Epoch 3, Batch 200] loss: 0.08174463911913335
[Epoch 3, Batch 300] loss: 0.07080008808989077
[Epoch 3, Batch 400] loss: 0.06702310923021287
[Epoch 3, Batch 500] loss: 0.06223570630419999
[Epoch 3, Batch 600] loss: 0.06503924882039427
[Epoch 3, Batch 700] loss: 0.07115064019337297
**STATS for Epoch 3** : 
Average training loss: 0.0044
Average validation loss: 0.0768
Validation Accuracy: 0.9760
Overfitting: 0.0723
Best model saved at epoch 3 with validation loss: 0.0768
[Epoch 4, Batch 100] loss: 0.05514777241274715
[Epoch 4, Batch 200] loss: 0.057613948676735166
[Epoch 4, Batch 300] loss: 0.06241955609759316
[Epoch 4, Batch 400] loss: 0.049537781975232065
[Epoch 4, Batch 500] loss: 0.06475772432051599
[Epoch 4, Batch 600] loss: 0.06153849953785539
[Epoch 4, Batch 700] loss: 0.05221361578674987
**STATS for Epoch 4** : 
Average training loss: 0.0027
Average validation loss: 0.0606
Validation Accuracy: 0.9809
Overfitting: 0.0580
Best model saved at epoch 4 with validation loss: 0.0606
[Epoch 5, Batch 100] loss: 0.0438666611420922
[Epoch 5, Batch 200] loss: 0.045584480727557095
[Epoch 5, Batch 300] loss: 0.046018499368801716
[Epoch 5, Batch 400] loss: 0.05138550751376897
[Epoch 5, Batch 500] loss: 0.04662895767716691
[Epoch 5, Batch 600] loss: 0.0484951281035319
[Epoch 5, Batch 700] loss: 0.04348390308674425
**STATS for Epoch 5** : 
Average training loss: 0.0033
Average validation loss: 0.0512
Validation Accuracy: 0.9847
Overfitting: 0.0478
Best model saved at epoch 5 with validation loss: 0.0512
[Epoch 6, Batch 100] loss: 0.040249131920281796
[Epoch 6, Batch 200] loss: 0.03376698415726423
[Epoch 6, Batch 300] loss: 0.043193837937433276
[Epoch 6, Batch 400] loss: 0.04456937313778326
[Epoch 6, Batch 500] loss: 0.042673488438595086
[Epoch 6, Batch 600] loss: 0.03547212818870321
[Epoch 6, Batch 700] loss: 0.0409532054211013
**STATS for Epoch 6** : 
Average training loss: 0.0025
Average validation loss: 0.0503
Validation Accuracy: 0.9845
Overfitting: 0.0478
Best model saved at epoch 6 with validation loss: 0.0503
[Epoch 7, Batch 100] loss: 0.03297370059764944
[Epoch 7, Batch 200] loss: 0.033682659451151266
[Epoch 7, Batch 300] loss: 0.03578058300307021
[Epoch 7, Batch 400] loss: 0.03266551304142922
[Epoch 7, Batch 500] loss: 0.035884814207674934
[Epoch 7, Batch 600] loss: 0.03444367389252875
[Epoch 7, Batch 700] loss: 0.030649448393378406
**STATS for Epoch 7** : 
Average training loss: 0.0028
Average validation loss: 0.0471
Validation Accuracy: 0.9855
Overfitting: 0.0444
Best model saved at epoch 7 with validation loss: 0.0471
[Epoch 8, Batch 100] loss: 0.02248029468173627
[Epoch 8, Batch 200] loss: 0.03381853739032522
[Epoch 8, Batch 300] loss: 0.029801146021927707
[Epoch 8, Batch 400] loss: 0.03214360724319704
[Epoch 8, Batch 500] loss: 0.030273376074619593
[Epoch 8, Batch 600] loss: 0.03320012388401665
[Epoch 8, Batch 700] loss: 0.03207406073343009
**STATS for Epoch 8** : 
Average training loss: 0.0016
Average validation loss: 0.0452
Validation Accuracy: 0.9868
Overfitting: 0.0436
Best model saved at epoch 8 with validation loss: 0.0452
[Epoch 9, Batch 100] loss: 0.02564328633074183
[Epoch 9, Batch 200] loss: 0.027058938586851582
[Epoch 9, Batch 300] loss: 0.027591963348677383
[Epoch 9, Batch 400] loss: 0.026057437981362456
[Epoch 9, Batch 500] loss: 0.030029327666270547
[Epoch 9, Batch 600] loss: 0.02121280995197594
[Epoch 9, Batch 700] loss: 0.028437215889571234
**STATS for Epoch 9** : 
Average training loss: 0.0017
Average validation loss: 0.0565
Validation Accuracy: 0.9842
Overfitting: 0.0548
[Epoch 10, Batch 100] loss: 0.025910310139588544
[Epoch 10, Batch 200] loss: 0.023466088082641362
[Epoch 10, Batch 300] loss: 0.027258956529549322
[Epoch 10, Batch 400] loss: 0.021850108099461068
[Epoch 10, Batch 500] loss: 0.02337294025113806
[Epoch 10, Batch 600] loss: 0.027224260283401237
[Epoch 10, Batch 700] loss: 0.025580045633541885
**STATS for Epoch 10** : 
Average training loss: 0.0013
Average validation loss: 0.0450
Validation Accuracy: 0.9872
Overfitting: 0.0438
Best model saved at epoch 10 with validation loss: 0.0450
[Epoch 11, Batch 100] loss: 0.01864018910215236
[Epoch 11, Batch 200] loss: 0.021619122929114384
[Epoch 11, Batch 300] loss: 0.018024578583426775
[Epoch 11, Batch 400] loss: 0.02546021912188735
[Epoch 11, Batch 500] loss: 0.01855952878453536
[Epoch 11, Batch 600] loss: 0.0207422378793126
[Epoch 11, Batch 700] loss: 0.026641746122622864
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0397
Validation Accuracy: 0.9884
Overfitting: 0.0385
Best model saved at epoch 11 with validation loss: 0.0397
[Epoch 12, Batch 100] loss: 0.01775574232364306
[Epoch 12, Batch 200] loss: 0.020247889067977667
[Epoch 12, Batch 300] loss: 0.017421321708679896
[Epoch 12, Batch 400] loss: 0.016526394541870104
[Epoch 12, Batch 500] loss: 0.01569540285869152
[Epoch 12, Batch 600] loss: 0.019749181131192017
[Epoch 12, Batch 700] loss: 0.021641445417189972
**STATS for Epoch 12** : 
Average training loss: 0.0020
Average validation loss: 0.0423
Validation Accuracy: 0.9872
Overfitting: 0.0404
[Epoch 13, Batch 100] loss: 0.016141942049725914
[Epoch 13, Batch 200] loss: 0.012728088275762274
[Epoch 13, Batch 300] loss: 0.01798533182707615
[Epoch 13, Batch 400] loss: 0.015510631480719895
[Epoch 13, Batch 500] loss: 0.012191684231438557
[Epoch 13, Batch 600] loss: 0.014511165240110131
[Epoch 13, Batch 700] loss: 0.02184086827212013
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0407
Validation Accuracy: 0.9890
Overfitting: 0.0396
[Epoch 14, Batch 100] loss: 0.013219412966864184
[Epoch 14, Batch 200] loss: 0.014384335053327958
[Epoch 14, Batch 300] loss: 0.010958743045630399
[Epoch 14, Batch 400] loss: 0.018262709056143647
[Epoch 14, Batch 500] loss: 0.01556961680209497
[Epoch 14, Batch 600] loss: 0.012313732039765456
[Epoch 14, Batch 700] loss: 0.01425906416901853
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0468
Validation Accuracy: 0.9878
Overfitting: 0.0457
[Epoch 15, Batch 100] loss: 0.013195055290998426
[Epoch 15, Batch 200] loss: 0.013261308332439513
[Epoch 15, Batch 300] loss: 0.017448799318954114
[Epoch 15, Batch 400] loss: 0.010867574861185858
[Epoch 15, Batch 500] loss: 0.013870647352014202
[Epoch 15, Batch 600] loss: 0.010824816186941462
[Epoch 15, Batch 700] loss: 0.012874735969235189
**STATS for Epoch 15** : 
Average training loss: 0.0016
Average validation loss: 0.0420
Validation Accuracy: 0.9889
Overfitting: 0.0404
[Epoch 16, Batch 100] loss: 0.012762776005110936
[Epoch 16, Batch 200] loss: 0.013054810187604744
[Epoch 16, Batch 300] loss: 0.011825702704372816
[Epoch 16, Batch 400] loss: 0.009386351300126989
[Epoch 16, Batch 500] loss: 0.009185173894511536
[Epoch 16, Batch 600] loss: 0.013906721384410048
[Epoch 16, Batch 700] loss: 0.013613477712497116
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0397
Validation Accuracy: 0.9899
Overfitting: 0.0390
Best model saved at epoch 16 with validation loss: 0.0397
[Epoch 17, Batch 100] loss: 0.006711952062687487
[Epoch 17, Batch 200] loss: 0.009053463687450858
[Epoch 17, Batch 300] loss: 0.01144843845431751
[Epoch 17, Batch 400] loss: 0.010501886644633487
[Epoch 17, Batch 500] loss: 0.00977528008108493
[Epoch 17, Batch 600] loss: 0.007361835479532602
[Epoch 17, Batch 700] loss: 0.012370672242614091
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0450
Validation Accuracy: 0.9884
Overfitting: 0.0439
[Epoch 18, Batch 100] loss: 0.007113948060869006
[Epoch 18, Batch 200] loss: 0.009850765467854216
[Epoch 18, Batch 300] loss: 0.009361997580999742
[Epoch 18, Batch 400] loss: 0.009525832949075266
[Epoch 18, Batch 500] loss: 0.010116207172104623
[Epoch 18, Batch 600] loss: 0.009301098900177749
[Epoch 18, Batch 700] loss: 0.0072374683107773305
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0384
Validation Accuracy: 0.9900
Overfitting: 0.0378
Best model saved at epoch 18 with validation loss: 0.0384
[Epoch 19, Batch 100] loss: 0.008307745680504013
[Epoch 19, Batch 200] loss: 0.0041707522187789435
[Epoch 19, Batch 300] loss: 0.007143348064928432
[Epoch 19, Batch 400] loss: 0.009638084442995022
[Epoch 19, Batch 500] loss: 0.0066900988798079195
[Epoch 19, Batch 600] loss: 0.007846182625362417
[Epoch 19, Batch 700] loss: 0.007851671294920379
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0394
Validation Accuracy: 0.9899
Overfitting: 0.0387
[Epoch 20, Batch 100] loss: 0.00482318156704423
[Epoch 20, Batch 200] loss: 0.004490823150190408
[Epoch 20, Batch 300] loss: 0.006185246582135733
[Epoch 20, Batch 400] loss: 0.005827836866374127
[Epoch 20, Batch 500] loss: 0.00982735797064379
[Epoch 20, Batch 600] loss: 0.01113705561740062
[Epoch 20, Batch 700] loss: 0.0075254532177496
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0416
Validation Accuracy: 0.9898
Overfitting: 0.0411
[Epoch 21, Batch 100] loss: 0.005393406599869195
[Epoch 21, Batch 200] loss: 0.005109149244008222
[Epoch 21, Batch 300] loss: 0.00433522874949631
[Epoch 21, Batch 400] loss: 0.007142971792454773
[Epoch 21, Batch 500] loss: 0.006970814335327305
[Epoch 21, Batch 600] loss: 0.009245069937569496
[Epoch 21, Batch 700] loss: 0.007159823474157747
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0422
Validation Accuracy: 0.9898
Overfitting: 0.0419
[Epoch 22, Batch 100] loss: 0.004986270396984765
[Epoch 22, Batch 200] loss: 0.0056173444679370734
[Epoch 22, Batch 300] loss: 0.006400310999160865
[Epoch 22, Batch 400] loss: 0.005012231554428581
[Epoch 22, Batch 500] loss: 0.005535314912085596
[Epoch 22, Batch 600] loss: 0.004381149849359644
[Epoch 22, Batch 700] loss: 0.008546771583296505
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0492
Validation Accuracy: 0.9882
Overfitting: 0.0486
[Epoch 23, Batch 100] loss: 0.00745561510535481
[Epoch 23, Batch 200] loss: 0.006460682345905297
[Epoch 23, Batch 300] loss: 0.005921859694153681
[Epoch 23, Batch 400] loss: 0.0074500715467365804
[Epoch 23, Batch 500] loss: 0.007461236659946735
[Epoch 23, Batch 600] loss: 0.005720017210624064
[Epoch 23, Batch 700] loss: 0.005374580237967166
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0464
Validation Accuracy: 0.9888
Overfitting: 0.0461
[Epoch 24, Batch 100] loss: 0.0029819545669306537
[Epoch 24, Batch 200] loss: 0.0026445013318152633
[Epoch 24, Batch 300] loss: 0.008407584819342446
[Epoch 24, Batch 400] loss: 0.006572387580163195
[Epoch 24, Batch 500] loss: 0.004130759482250141
[Epoch 24, Batch 600] loss: 0.004789816589363909
[Epoch 24, Batch 700] loss: 0.005701059867988079
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0449
Validation Accuracy: 0.9889
Overfitting: 0.0446
Fold 5 validation loss: 0.0449
Mean validation loss across all folds for Trial 16 is 0.0493 with trial config:  l1: 256, l2: 128, lr: 0.0032490609166865216, batch_size: 64
[I 2024-12-11 06:40:58,119] Trial 15 finished with value: 0.04928000235355149 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0032490609166865216, 'batch_size': 64}. Best is trial 4 with value: 0.04724671796616846.

Selected Hyperparameters for Trial 17:
  l1: 256, l2: 128, lr: 0.004571883955625129, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2047653865814207
[Epoch 1, Batch 200] loss: 0.6737115831673145
[Epoch 1, Batch 300] loss: 0.3317308470606804
[Epoch 1, Batch 400] loss: 0.23714018914848567
[Epoch 1, Batch 500] loss: 0.2100779278576374
[Epoch 1, Batch 600] loss: 0.17155625443905592
[Epoch 1, Batch 700] loss: 0.14018674340099097
**STATS for Epoch 1** : 
Average training loss: 0.0093
Average validation loss: 0.1002
Validation Accuracy: 0.9671
Overfitting: 0.0908
Best model saved at epoch 1 with validation loss: 0.1002
[Epoch 2, Batch 100] loss: 0.10679013308137655
[Epoch 2, Batch 200] loss: 0.10724220735020935
[Epoch 2, Batch 300] loss: 0.10870100785978139
[Epoch 2, Batch 400] loss: 0.10253071824088693
[Epoch 2, Batch 500] loss: 0.09131225928664208
[Epoch 2, Batch 600] loss: 0.0860486073512584
[Epoch 2, Batch 700] loss: 0.08155750386416911
**STATS for Epoch 2** : 
Average training loss: 0.0057
Average validation loss: 0.0849
Validation Accuracy: 0.9722
Overfitting: 0.0793
Best model saved at epoch 2 with validation loss: 0.0849
[Epoch 3, Batch 100] loss: 0.06893647505901754
[Epoch 3, Batch 200] loss: 0.07218099313322454
[Epoch 3, Batch 300] loss: 0.07105250053107738
[Epoch 3, Batch 400] loss: 0.06897708136588335
[Epoch 3, Batch 500] loss: 0.06526052728295326
[Epoch 3, Batch 600] loss: 0.06557861128123477
[Epoch 3, Batch 700] loss: 0.057313872368540617
**STATS for Epoch 3** : 
Average training loss: 0.0045
Average validation loss: 0.0584
Validation Accuracy: 0.9818
Overfitting: 0.0539
Best model saved at epoch 3 with validation loss: 0.0584
[Epoch 4, Batch 100] loss: 0.05528984680771828
[Epoch 4, Batch 200] loss: 0.049584121063817294
[Epoch 4, Batch 300] loss: 0.053210232560522853
[Epoch 4, Batch 400] loss: 0.05391995687037707
[Epoch 4, Batch 500] loss: 0.051402859687805176
[Epoch 4, Batch 600] loss: 0.056166706308722496
[Epoch 4, Batch 700] loss: 0.04828508265549317
**STATS for Epoch 4** : 
Average training loss: 0.0039
Average validation loss: 0.0580
Validation Accuracy: 0.9808
Overfitting: 0.0541
Best model saved at epoch 4 with validation loss: 0.0580
[Epoch 5, Batch 100] loss: 0.04014946370851249
[Epoch 5, Batch 200] loss: 0.03853463564417325
[Epoch 5, Batch 300] loss: 0.043704727413132784
[Epoch 5, Batch 400] loss: 0.04583595611504279
[Epoch 5, Batch 500] loss: 0.04443396048387513
[Epoch 5, Batch 600] loss: 0.040421103620901705
[Epoch 5, Batch 700] loss: 0.035701762305106965
**STATS for Epoch 5** : 
Average training loss: 0.0034
Average validation loss: 0.0555
Validation Accuracy: 0.9832
Overfitting: 0.0521
Best model saved at epoch 5 with validation loss: 0.0555
[Epoch 6, Batch 100] loss: 0.034793260823935274
[Epoch 6, Batch 200] loss: 0.031433633022243154
[Epoch 6, Batch 300] loss: 0.03648319359344896
[Epoch 6, Batch 400] loss: 0.04235087029519491
[Epoch 6, Batch 500] loss: 0.039576852982863786
[Epoch 6, Batch 600] loss: 0.043139222520403565
[Epoch 6, Batch 700] loss: 0.04089265721733682
**STATS for Epoch 6** : 
Average training loss: 0.0026
Average validation loss: 0.0451
Validation Accuracy: 0.9861
Overfitting: 0.0426
Best model saved at epoch 6 with validation loss: 0.0451
[Epoch 7, Batch 100] loss: 0.029876901044044644
[Epoch 7, Batch 200] loss: 0.0342264339630492
[Epoch 7, Batch 300] loss: 0.02969601029762998
[Epoch 7, Batch 400] loss: 0.02049374132126104
[Epoch 7, Batch 500] loss: 0.03285255440918263
[Epoch 7, Batch 600] loss: 0.03070054736570455
[Epoch 7, Batch 700] loss: 0.029088862878852526
**STATS for Epoch 7** : 
Average training loss: 0.0021
Average validation loss: 0.0641
Validation Accuracy: 0.9806
Overfitting: 0.0620
[Epoch 8, Batch 100] loss: 0.02449942382168956
[Epoch 8, Batch 200] loss: 0.020647866617073306
[Epoch 8, Batch 300] loss: 0.0255708388669882
[Epoch 8, Batch 400] loss: 0.027355606992496177
[Epoch 8, Batch 500] loss: 0.02393849804531783
[Epoch 8, Batch 600] loss: 0.026898767900420353
[Epoch 8, Batch 700] loss: 0.028572313131880946
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0459
Validation Accuracy: 0.9853
Overfitting: 0.0440
[Epoch 9, Batch 100] loss: 0.016880528863403015
[Epoch 9, Batch 200] loss: 0.017710775177984032
[Epoch 9, Batch 300] loss: 0.022512376079685054
[Epoch 9, Batch 400] loss: 0.024871777011430823
[Epoch 9, Batch 500] loss: 0.021062996421242132
[Epoch 9, Batch 600] loss: 0.025068669591564684
[Epoch 9, Batch 700] loss: 0.022622208425309508
**STATS for Epoch 9** : 
Average training loss: 0.0014
Average validation loss: 0.0405
Validation Accuracy: 0.9875
Overfitting: 0.0391
Best model saved at epoch 9 with validation loss: 0.0405
[Epoch 10, Batch 100] loss: 0.011876294469693675
[Epoch 10, Batch 200] loss: 0.021462794534745627
[Epoch 10, Batch 300] loss: 0.023812972072628325
[Epoch 10, Batch 400] loss: 0.017134053318877705
[Epoch 10, Batch 500] loss: 0.02159400788892526
[Epoch 10, Batch 600] loss: 0.0172784233110724
[Epoch 10, Batch 700] loss: 0.02193049616762437
**STATS for Epoch 10** : 
Average training loss: 0.0018
Average validation loss: 0.0533
Validation Accuracy: 0.9834
Overfitting: 0.0515
[Epoch 11, Batch 100] loss: 0.0182023095972545
[Epoch 11, Batch 200] loss: 0.011961095192527865
[Epoch 11, Batch 300] loss: 0.01592228052642895
[Epoch 11, Batch 400] loss: 0.013815024570649257
[Epoch 11, Batch 500] loss: 0.013882242941035657
[Epoch 11, Batch 600] loss: 0.019411116676492382
[Epoch 11, Batch 700] loss: 0.017401559314748738
**STATS for Epoch 11** : 
Average training loss: 0.0011
Average validation loss: 0.0612
Validation Accuracy: 0.9822
Overfitting: 0.0601
[Epoch 12, Batch 100] loss: 0.008261314404080622
[Epoch 12, Batch 200] loss: 0.014891723191831262
[Epoch 12, Batch 300] loss: 0.014819842390134
[Epoch 12, Batch 400] loss: 0.01326549342375074
[Epoch 12, Batch 500] loss: 0.014313872273778543
[Epoch 12, Batch 600] loss: 0.01165746880855295
[Epoch 12, Batch 700] loss: 0.015159857116814238
**STATS for Epoch 12** : 
Average training loss: 0.0009
Average validation loss: 0.0487
Validation Accuracy: 0.9856
Overfitting: 0.0478
[Epoch 13, Batch 100] loss: 0.01295825548353605
[Epoch 13, Batch 200] loss: 0.012239341569656972
[Epoch 13, Batch 300] loss: 0.009882371059502475
[Epoch 13, Batch 400] loss: 0.008676370214307099
[Epoch 13, Batch 500] loss: 0.023680430399253966
[Epoch 13, Batch 600] loss: 0.013678455140470759
[Epoch 13, Batch 700] loss: 0.013675869310682175
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0485
Validation Accuracy: 0.9868
Overfitting: 0.0477
[Epoch 14, Batch 100] loss: 0.0055044401527266015
[Epoch 14, Batch 200] loss: 0.010097323706249882
[Epoch 14, Batch 300] loss: 0.006825678581226385
[Epoch 14, Batch 400] loss: 0.011424814396959845
[Epoch 14, Batch 500] loss: 0.0073459369848569624
[Epoch 14, Batch 600] loss: 0.012281731021794258
[Epoch 14, Batch 700] loss: 0.01328968706067826
**STATS for Epoch 14** : 
Average training loss: 0.0011
Average validation loss: 0.0492
Validation Accuracy: 0.9866
Overfitting: 0.0481
[Epoch 15, Batch 100] loss: 0.004775497364462354
[Epoch 15, Batch 200] loss: 0.006149751623815973
[Epoch 15, Batch 300] loss: 0.007232182957195619
[Epoch 15, Batch 400] loss: 0.012128938881214708
[Epoch 15, Batch 500] loss: 0.006621266954898602
[Epoch 15, Batch 600] loss: 0.008239165949780726
[Epoch 15, Batch 700] loss: 0.00769603710170486
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0567
Validation Accuracy: 0.9857
Overfitting: 0.0561
[Epoch 16, Batch 100] loss: 0.011388214806866017
[Epoch 16, Batch 200] loss: 0.005373704709563753
[Epoch 16, Batch 300] loss: 0.006796503931836923
[Epoch 16, Batch 400] loss: 0.009117473903024802
[Epoch 16, Batch 500] loss: 0.007115476445687818
[Epoch 16, Batch 600] loss: 0.011847759659722214
[Epoch 16, Batch 700] loss: 0.008109041430579965
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0477
Validation Accuracy: 0.9890
Overfitting: 0.0472
[Epoch 17, Batch 100] loss: 0.007233882253312913
[Epoch 17, Batch 200] loss: 0.004211077130239573
[Epoch 17, Batch 300] loss: 0.0031502371639908233
[Epoch 17, Batch 400] loss: 0.004199806536998949
[Epoch 17, Batch 500] loss: 0.007782351962305256
[Epoch 17, Batch 600] loss: 0.008839734271386988
[Epoch 17, Batch 700] loss: 0.00510020458172221
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0506
Validation Accuracy: 0.9884
Overfitting: 0.0501
[Epoch 18, Batch 100] loss: 0.0024962127385515487
[Epoch 18, Batch 200] loss: 0.006162856777827983
[Epoch 18, Batch 300] loss: 0.005826864716073033
[Epoch 18, Batch 400] loss: 0.006112895692203892
[Epoch 18, Batch 500] loss: 0.004381674870337519
[Epoch 18, Batch 600] loss: 0.004836845851114049
[Epoch 18, Batch 700] loss: 0.006130289733332575
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0481
Validation Accuracy: 0.9884
Overfitting: 0.0477
[Epoch 19, Batch 100] loss: 0.002577734402975693
[Epoch 19, Batch 200] loss: 0.0029909476991451813
[Epoch 19, Batch 300] loss: 0.004321656234624243
[Epoch 19, Batch 400] loss: 0.005501680639354163
[Epoch 19, Batch 500] loss: 0.006067582407831651
[Epoch 19, Batch 600] loss: 0.00796124959590088
[Epoch 19, Batch 700] loss: 0.004943191663010112
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0579
Validation Accuracy: 0.9868
Overfitting: 0.0576
[Epoch 20, Batch 100] loss: 0.003197110587534553
[Epoch 20, Batch 200] loss: 0.006531622111197066
[Epoch 20, Batch 300] loss: 0.004092462041462568
[Epoch 20, Batch 400] loss: 0.005852817212817172
[Epoch 20, Batch 500] loss: 0.005192191732257925
[Epoch 20, Batch 600] loss: 0.004718966261334572
[Epoch 20, Batch 700] loss: 0.0028759271870876547
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0484
Validation Accuracy: 0.9889
Overfitting: 0.0480
[Epoch 21, Batch 100] loss: 0.003696745532561181
[Epoch 21, Batch 200] loss: 0.0028389721595340235
[Epoch 21, Batch 300] loss: 0.004803832746620174
[Epoch 21, Batch 400] loss: 0.0035755920678548136
[Epoch 21, Batch 500] loss: 0.0024765135419420404
[Epoch 21, Batch 600] loss: 0.0016567113289602275
[Epoch 21, Batch 700] loss: 0.003984259511926211
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0616
Validation Accuracy: 0.9860
Overfitting: 0.0613
[Epoch 22, Batch 100] loss: 0.004303269680276571
[Epoch 22, Batch 200] loss: 0.0036216388738830574
[Epoch 22, Batch 300] loss: 0.0033844852396669014
[Epoch 22, Batch 400] loss: 0.0030460589302310835
[Epoch 22, Batch 500] loss: 0.0026376488218636494
[Epoch 22, Batch 600] loss: 0.00222002737742514
[Epoch 22, Batch 700] loss: 0.0019012843598375183
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0558
Validation Accuracy: 0.9879
Overfitting: 0.0557
[Epoch 23, Batch 100] loss: 0.0007602758661141707
[Epoch 23, Batch 200] loss: 0.00126494965648817
[Epoch 23, Batch 300] loss: 0.0031911320030030767
[Epoch 23, Batch 400] loss: 0.0011399416490348812
[Epoch 23, Batch 500] loss: 0.002826468034586469
[Epoch 23, Batch 600] loss: 0.001990732173244396
[Epoch 23, Batch 700] loss: 0.002147738254379874
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0523
Validation Accuracy: 0.9889
Overfitting: 0.0522
[Epoch 24, Batch 100] loss: 0.0016929062222516222
[Epoch 24, Batch 200] loss: 0.0005840785052225783
[Epoch 24, Batch 300] loss: 0.0010134979586200643
[Epoch 24, Batch 400] loss: 0.0008915185895784816
[Epoch 24, Batch 500] loss: 0.00122973408343114
[Epoch 24, Batch 600] loss: 0.0007328291890189575
[Epoch 24, Batch 700] loss: 0.0017105408588895443
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0530
Validation Accuracy: 0.9892
Overfitting: 0.0530
Fold 1 validation loss: 0.0530
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2533811640739443
[Epoch 1, Batch 200] loss: 0.8353175227344036
[Epoch 1, Batch 300] loss: 0.2989299667626619
[Epoch 1, Batch 400] loss: 0.1960469163581729
[Epoch 1, Batch 500] loss: 0.17290936328470707
[Epoch 1, Batch 600] loss: 0.14764595977962017
[Epoch 1, Batch 700] loss: 0.12719404084607958
**STATS for Epoch 1** : 
Average training loss: 0.0090
Average validation loss: 0.1314
Validation Accuracy: 0.9600
Overfitting: 0.1224
Best model saved at epoch 1 with validation loss: 0.1314
[Epoch 2, Batch 100] loss: 0.10908044662326574
[Epoch 2, Batch 200] loss: 0.1018615873530507
[Epoch 2, Batch 300] loss: 0.08871371311601252
[Epoch 2, Batch 400] loss: 0.08492555909790099
[Epoch 2, Batch 500] loss: 0.09496360013261437
[Epoch 2, Batch 600] loss: 0.08279162069782614
[Epoch 2, Batch 700] loss: 0.08142265947535635
**STATS for Epoch 2** : 
Average training loss: 0.0046
Average validation loss: 0.0863
Validation Accuracy: 0.9738
Overfitting: 0.0817
Best model saved at epoch 2 with validation loss: 0.0863
[Epoch 3, Batch 100] loss: 0.07012083570938557
[Epoch 3, Batch 200] loss: 0.06444020519033074
[Epoch 3, Batch 300] loss: 0.0743058102671057
[Epoch 3, Batch 400] loss: 0.05473397983703762
[Epoch 3, Batch 500] loss: 0.05661978010553867
[Epoch 3, Batch 600] loss: 0.06165749803418294
[Epoch 3, Batch 700] loss: 0.06208080861251801
**STATS for Epoch 3** : 
Average training loss: 0.0039
Average validation loss: 0.0649
Validation Accuracy: 0.9810
Overfitting: 0.0610
Best model saved at epoch 3 with validation loss: 0.0649
[Epoch 4, Batch 100] loss: 0.05589997259899974
[Epoch 4, Batch 200] loss: 0.0462062169262208
[Epoch 4, Batch 300] loss: 0.049522664351388815
[Epoch 4, Batch 400] loss: 0.046873269313946364
[Epoch 4, Batch 500] loss: 0.04804473845520988
[Epoch 4, Batch 600] loss: 0.04769546810071915
[Epoch 4, Batch 700] loss: 0.05913496712688357
**STATS for Epoch 4** : 
Average training loss: 0.0031
Average validation loss: 0.0573
Validation Accuracy: 0.9810
Overfitting: 0.0542
Best model saved at epoch 4 with validation loss: 0.0573
[Epoch 5, Batch 100] loss: 0.03198035935638473
[Epoch 5, Batch 200] loss: 0.04098942163866013
[Epoch 5, Batch 300] loss: 0.043860067401546986
[Epoch 5, Batch 400] loss: 0.0350890247663483
[Epoch 5, Batch 500] loss: 0.044760190877132115
[Epoch 5, Batch 600] loss: 0.04136566357687116
[Epoch 5, Batch 700] loss: 0.04342736896360293
**STATS for Epoch 5** : 
Average training loss: 0.0025
Average validation loss: 0.0677
Validation Accuracy: 0.9797
Overfitting: 0.0652
[Epoch 6, Batch 100] loss: 0.03246013961615972
[Epoch 6, Batch 200] loss: 0.029283068067161366
[Epoch 6, Batch 300] loss: 0.03195530675468035
[Epoch 6, Batch 400] loss: 0.02790715612936765
[Epoch 6, Batch 500] loss: 0.03440237584640272
[Epoch 6, Batch 600] loss: 0.04381382218096405
[Epoch 6, Batch 700] loss: 0.03481538804713637
**STATS for Epoch 6** : 
Average training loss: 0.0020
Average validation loss: 0.0488
Validation Accuracy: 0.9849
Overfitting: 0.0468
Best model saved at epoch 6 with validation loss: 0.0488
[Epoch 7, Batch 100] loss: 0.02676728167105466
[Epoch 7, Batch 200] loss: 0.02124330145830754
[Epoch 7, Batch 300] loss: 0.030514275737223217
[Epoch 7, Batch 400] loss: 0.027972296039224603
[Epoch 7, Batch 500] loss: 0.031810846859589216
[Epoch 7, Batch 600] loss: 0.03130666525219567
[Epoch 7, Batch 700] loss: 0.030531086323899215
**STATS for Epoch 7** : 
Average training loss: 0.0022
Average validation loss: 0.0491
Validation Accuracy: 0.9853
Overfitting: 0.0468
[Epoch 8, Batch 100] loss: 0.020678737760172226
[Epoch 8, Batch 200] loss: 0.02408661667344859
[Epoch 8, Batch 300] loss: 0.020998016719240696
[Epoch 8, Batch 400] loss: 0.027177727709640748
[Epoch 8, Batch 500] loss: 0.02871306915592868
[Epoch 8, Batch 600] loss: 0.02206287025939673
[Epoch 8, Batch 700] loss: 0.025367198408348487
**STATS for Epoch 8** : 
Average training loss: 0.0012
Average validation loss: 0.0455
Validation Accuracy: 0.9872
Overfitting: 0.0444
Best model saved at epoch 8 with validation loss: 0.0455
[Epoch 9, Batch 100] loss: 0.016479188859811984
[Epoch 9, Batch 200] loss: 0.018806126119452527
[Epoch 9, Batch 300] loss: 0.019541333641973323
[Epoch 9, Batch 400] loss: 0.024129269272671082
[Epoch 9, Batch 500] loss: 0.018990717519191094
[Epoch 9, Batch 600] loss: 0.022505605674232355
[Epoch 9, Batch 700] loss: 0.017391001233045246
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0487
Validation Accuracy: 0.9870
Overfitting: 0.0471
[Epoch 10, Batch 100] loss: 0.013194764538202435
[Epoch 10, Batch 200] loss: 0.016120875935303047
[Epoch 10, Batch 300] loss: 0.026149486084323145
[Epoch 10, Batch 400] loss: 0.02025783709512325
[Epoch 10, Batch 500] loss: 0.019603717685677112
[Epoch 10, Batch 600] loss: 0.018576044983346945
[Epoch 10, Batch 700] loss: 0.022111270680325104
**STATS for Epoch 10** : 
Average training loss: 0.0011
Average validation loss: 0.0473
Validation Accuracy: 0.9869
Overfitting: 0.0462
[Epoch 11, Batch 100] loss: 0.010469249153829878
[Epoch 11, Batch 200] loss: 0.01601702182815643
[Epoch 11, Batch 300] loss: 0.013341281965258531
[Epoch 11, Batch 400] loss: 0.014617682413663714
[Epoch 11, Batch 500] loss: 0.020706501998356542
[Epoch 11, Batch 600] loss: 0.026551204930874518
[Epoch 11, Batch 700] loss: 0.02013578091922682
**STATS for Epoch 11** : 
Average training loss: 0.0010
Average validation loss: 0.0477
Validation Accuracy: 0.9875
Overfitting: 0.0467
[Epoch 12, Batch 100] loss: 0.013179381202207878
[Epoch 12, Batch 200] loss: 0.010883912452773075
[Epoch 12, Batch 300] loss: 0.01669068114759284
[Epoch 12, Batch 400] loss: 0.014208407992700813
[Epoch 12, Batch 500] loss: 0.014915046620881185
[Epoch 12, Batch 600] loss: 0.01154357717372477
[Epoch 12, Batch 700] loss: 0.009834406352456426
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0534
Validation Accuracy: 0.9855
Overfitting: 0.0521
[Epoch 13, Batch 100] loss: 0.011676703290941077
[Epoch 13, Batch 200] loss: 0.011498780670081032
[Epoch 13, Batch 300] loss: 0.011703898908308474
[Epoch 13, Batch 400] loss: 0.009379879192201769
[Epoch 13, Batch 500] loss: 0.010020144256159255
[Epoch 13, Batch 600] loss: 0.012435759869404137
[Epoch 13, Batch 700] loss: 0.014172417044028407
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0432
Validation Accuracy: 0.9884
Overfitting: 0.0426
Best model saved at epoch 13 with validation loss: 0.0432
[Epoch 14, Batch 100] loss: 0.005679246908475761
[Epoch 14, Batch 200] loss: 0.007699442002922297
[Epoch 14, Batch 300] loss: 0.00802777834214794
[Epoch 14, Batch 400] loss: 0.010017509782846901
[Epoch 14, Batch 500] loss: 0.01071949033808778
[Epoch 14, Batch 600] loss: 0.009309547914308497
[Epoch 14, Batch 700] loss: 0.01235256520594703
**STATS for Epoch 14** : 
Average training loss: 0.0010
Average validation loss: 0.0482
Validation Accuracy: 0.9875
Overfitting: 0.0472
[Epoch 15, Batch 100] loss: 0.005504375657546916
[Epoch 15, Batch 200] loss: 0.008827995943411224
[Epoch 15, Batch 300] loss: 0.005743695513301645
[Epoch 15, Batch 400] loss: 0.0034790707818683586
[Epoch 15, Batch 500] loss: 0.009269864291782141
[Epoch 15, Batch 600] loss: 0.008470511057785188
[Epoch 15, Batch 700] loss: 0.007035062900140474
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0489
Validation Accuracy: 0.9878
Overfitting: 0.0485
[Epoch 16, Batch 100] loss: 0.0057499553915840804
[Epoch 16, Batch 200] loss: 0.0033105190167225375
[Epoch 16, Batch 300] loss: 0.0053240621937584364
[Epoch 16, Batch 400] loss: 0.009304584287310718
[Epoch 16, Batch 500] loss: 0.008085104452184168
[Epoch 16, Batch 600] loss: 0.010916836728647468
[Epoch 16, Batch 700] loss: 0.017064259685867
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0548
Validation Accuracy: 0.9872
Overfitting: 0.0544
[Epoch 17, Batch 100] loss: 0.006622215941461036
[Epoch 17, Batch 200] loss: 0.005797293971554609
[Epoch 17, Batch 300] loss: 0.004678984387246601
[Epoch 17, Batch 400] loss: 0.00790098869940266
[Epoch 17, Batch 500] loss: 0.007926769146833976
[Epoch 17, Batch 600] loss: 0.010053576709178742
[Epoch 17, Batch 700] loss: 0.006748434670444112
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0514
Validation Accuracy: 0.9877
Overfitting: 0.0507
[Epoch 18, Batch 100] loss: 0.004899558196702855
[Epoch 18, Batch 200] loss: 0.0023990058807248716
[Epoch 18, Batch 300] loss: 0.0044188934880367015
[Epoch 18, Batch 400] loss: 0.00563359241503349
[Epoch 18, Batch 500] loss: 0.008995001232833602
[Epoch 18, Batch 600] loss: 0.008572102291072952
[Epoch 18, Batch 700] loss: 0.00580133902214584
**STATS for Epoch 18** : 
Average training loss: 0.0005
Average validation loss: 0.0504
Validation Accuracy: 0.9881
Overfitting: 0.0498
[Epoch 19, Batch 100] loss: 0.0060266268708801364
[Epoch 19, Batch 200] loss: 0.005799234644982789
[Epoch 19, Batch 300] loss: 0.007635486751728422
[Epoch 19, Batch 400] loss: 0.005950756017773529
[Epoch 19, Batch 500] loss: 0.002715814795337792
[Epoch 19, Batch 600] loss: 0.005289040059369654
[Epoch 19, Batch 700] loss: 0.004747307801890202
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0538
Validation Accuracy: 0.9889
Overfitting: 0.0536
[Epoch 20, Batch 100] loss: 0.005072350832160737
[Epoch 20, Batch 200] loss: 0.002841515771524428
[Epoch 20, Batch 300] loss: 0.0027542207363512716
[Epoch 20, Batch 400] loss: 0.003986001656558074
[Epoch 20, Batch 500] loss: 0.0025879299775078833
[Epoch 20, Batch 600] loss: 0.003473438100409112
[Epoch 20, Batch 700] loss: 0.002986634666276586
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0575
Validation Accuracy: 0.9873
Overfitting: 0.0574
[Epoch 21, Batch 100] loss: 0.004385234544533887
[Epoch 21, Batch 200] loss: 0.00490063239384881
[Epoch 21, Batch 300] loss: 0.0023348783017354434
[Epoch 21, Batch 400] loss: 0.0020006073192553233
[Epoch 21, Batch 500] loss: 0.001434571953041086
[Epoch 21, Batch 600] loss: 0.0034047386865233877
[Epoch 21, Batch 700] loss: 0.003850674514033017
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0558
Validation Accuracy: 0.9892
Overfitting: 0.0557
[Epoch 22, Batch 100] loss: 0.0023023363647371297
[Epoch 22, Batch 200] loss: 0.0037866151567868657
[Epoch 22, Batch 300] loss: 0.003965398028149139
[Epoch 22, Batch 400] loss: 0.002118716605114059
[Epoch 22, Batch 500] loss: 0.003605013910200796
[Epoch 22, Batch 600] loss: 0.0035307286565785033
[Epoch 22, Batch 700] loss: 0.004448930072503572
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0533
Validation Accuracy: 0.9889
Overfitting: 0.0531
[Epoch 23, Batch 100] loss: 0.004115553088086017
[Epoch 23, Batch 200] loss: 0.00568459751923001
[Epoch 23, Batch 300] loss: 0.005271974545839839
[Epoch 23, Batch 400] loss: 0.0036434789482404995
[Epoch 23, Batch 500] loss: 0.0035943806583782134
[Epoch 23, Batch 600] loss: 0.002649534881729778
[Epoch 23, Batch 700] loss: 0.0012050520461161795
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0560
Validation Accuracy: 0.9882
Overfitting: 0.0559
[Epoch 24, Batch 100] loss: 0.0010069552114600811
[Epoch 24, Batch 200] loss: 0.0007625542023583876
[Epoch 24, Batch 300] loss: 0.00156735766255224
[Epoch 24, Batch 400] loss: 0.002531424168923877
[Epoch 24, Batch 500] loss: 0.0038677490890268017
[Epoch 24, Batch 600] loss: 0.001802245658816446
[Epoch 24, Batch 700] loss: 0.0017499866994307922
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0543
Validation Accuracy: 0.9888
Overfitting: 0.0542
Fold 2 validation loss: 0.0543
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2470273566246033
[Epoch 1, Batch 200] loss: 0.8254038515686989
[Epoch 1, Batch 300] loss: 0.30729359209537505
[Epoch 1, Batch 400] loss: 0.2390137577801943
[Epoch 1, Batch 500] loss: 0.17496270220726728
[Epoch 1, Batch 600] loss: 0.14758263099938632
[Epoch 1, Batch 700] loss: 0.13533620301634072
**STATS for Epoch 1** : 
Average training loss: 0.0080
Average validation loss: 0.1276
Validation Accuracy: 0.9595
Overfitting: 0.1196
Best model saved at epoch 1 with validation loss: 0.1276
[Epoch 2, Batch 100] loss: 0.10524235182441771
[Epoch 2, Batch 200] loss: 0.10047021327540279
[Epoch 2, Batch 300] loss: 0.08690081425011158
[Epoch 2, Batch 400] loss: 0.08166412104386836
[Epoch 2, Batch 500] loss: 0.0868186719622463
[Epoch 2, Batch 600] loss: 0.07394791123457253
[Epoch 2, Batch 700] loss: 0.07806578516960144
**STATS for Epoch 2** : 
Average training loss: 0.0054
Average validation loss: 0.0942
Validation Accuracy: 0.9699
Overfitting: 0.0888
Best model saved at epoch 2 with validation loss: 0.0942
[Epoch 3, Batch 100] loss: 0.05789329566061497
[Epoch 3, Batch 200] loss: 0.06378620230592787
[Epoch 3, Batch 300] loss: 0.06448532957583666
[Epoch 3, Batch 400] loss: 0.06172454337123781
[Epoch 3, Batch 500] loss: 0.06942554736277089
[Epoch 3, Batch 600] loss: 0.05466476931003854
[Epoch 3, Batch 700] loss: 0.053871454065665604
**STATS for Epoch 3** : 
Average training loss: 0.0049
Average validation loss: 0.0588
Validation Accuracy: 0.9828
Overfitting: 0.0539
Best model saved at epoch 3 with validation loss: 0.0588
[Epoch 4, Batch 100] loss: 0.04881779911927879
[Epoch 4, Batch 200] loss: 0.046482218930032106
[Epoch 4, Batch 300] loss: 0.046395426881499585
[Epoch 4, Batch 400] loss: 0.04985569193726405
[Epoch 4, Batch 500] loss: 0.04112636758596636
[Epoch 4, Batch 600] loss: 0.049843438628595325
[Epoch 4, Batch 700] loss: 0.05073147871065885
**STATS for Epoch 4** : 
Average training loss: 0.0024
Average validation loss: 0.0551
Validation Accuracy: 0.9830
Overfitting: 0.0527
Best model saved at epoch 4 with validation loss: 0.0551
[Epoch 5, Batch 100] loss: 0.03566295088618063
[Epoch 5, Batch 200] loss: 0.03543303697137162
[Epoch 5, Batch 300] loss: 0.039870060547254976
[Epoch 5, Batch 400] loss: 0.04020806858432479
[Epoch 5, Batch 500] loss: 0.032884232019423504
[Epoch 5, Batch 600] loss: 0.046579402883071455
[Epoch 5, Batch 700] loss: 0.03878100582980551
**STATS for Epoch 5** : 
Average training loss: 0.0030
Average validation loss: 0.0572
Validation Accuracy: 0.9832
Overfitting: 0.0542
[Epoch 6, Batch 100] loss: 0.025221163795795292
[Epoch 6, Batch 200] loss: 0.037760162856429816
[Epoch 6, Batch 300] loss: 0.033365865088999275
[Epoch 6, Batch 400] loss: 0.033313776551513
[Epoch 6, Batch 500] loss: 0.03128338824957609
[Epoch 6, Batch 600] loss: 0.028178065901156516
[Epoch 6, Batch 700] loss: 0.03228166538407095
**STATS for Epoch 6** : 
Average training loss: 0.0018
Average validation loss: 0.0463
Validation Accuracy: 0.9856
Overfitting: 0.0445
Best model saved at epoch 6 with validation loss: 0.0463
[Epoch 7, Batch 100] loss: 0.021863946074736306
[Epoch 7, Batch 200] loss: 0.028522067149169744
[Epoch 7, Batch 300] loss: 0.024718263866961934
[Epoch 7, Batch 400] loss: 0.025690462385537103
[Epoch 7, Batch 500] loss: 0.025547448093420827
[Epoch 7, Batch 600] loss: 0.02495342240552418
[Epoch 7, Batch 700] loss: 0.036290468295337636
**STATS for Epoch 7** : 
Average training loss: 0.0016
Average validation loss: 0.0445
Validation Accuracy: 0.9875
Overfitting: 0.0428
Best model saved at epoch 7 with validation loss: 0.0445
[Epoch 8, Batch 100] loss: 0.024271678101504223
[Epoch 8, Batch 200] loss: 0.019975467652548106
[Epoch 8, Batch 300] loss: 0.0226567631989019
[Epoch 8, Batch 400] loss: 0.02354779721586965
[Epoch 8, Batch 500] loss: 0.0231531301108771
[Epoch 8, Batch 600] loss: 0.022540932877454907
[Epoch 8, Batch 700] loss: 0.020151287582702935
**STATS for Epoch 8** : 
Average training loss: 0.0017
Average validation loss: 0.0501
Validation Accuracy: 0.9859
Overfitting: 0.0484
[Epoch 9, Batch 100] loss: 0.020158139817940537
[Epoch 9, Batch 200] loss: 0.023501817796495742
[Epoch 9, Batch 300] loss: 0.017444039124529808
[Epoch 9, Batch 400] loss: 0.01805750788698788
[Epoch 9, Batch 500] loss: 0.019854217125102876
[Epoch 9, Batch 600] loss: 0.02045363463490503
[Epoch 9, Batch 700] loss: 0.01993344453512691
**STATS for Epoch 9** : 
Average training loss: 0.0008
Average validation loss: 0.0485
Validation Accuracy: 0.9867
Overfitting: 0.0477
[Epoch 10, Batch 100] loss: 0.015776544057007413
[Epoch 10, Batch 200] loss: 0.016717614615918138
[Epoch 10, Batch 300] loss: 0.016869310743932147
[Epoch 10, Batch 400] loss: 0.01855699267180171
[Epoch 10, Batch 500] loss: 0.015271207488694927
[Epoch 10, Batch 600] loss: 0.017310236752673517
[Epoch 10, Batch 700] loss: 0.015434101498394739
**STATS for Epoch 10** : 
Average training loss: 0.0014
Average validation loss: 0.0479
Validation Accuracy: 0.9875
Overfitting: 0.0465
[Epoch 11, Batch 100] loss: 0.01471092632826185
[Epoch 11, Batch 200] loss: 0.011697464254539228
[Epoch 11, Batch 300] loss: 0.016794516027439386
[Epoch 11, Batch 400] loss: 0.01370378923806129
[Epoch 11, Batch 500] loss: 0.01693832549935905
[Epoch 11, Batch 600] loss: 0.01761562632789719
[Epoch 11, Batch 700] loss: 0.01179702981506125
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0475
Validation Accuracy: 0.9866
Overfitting: 0.0466
[Epoch 12, Batch 100] loss: 0.010063657702121418
[Epoch 12, Batch 200] loss: 0.00899002259495319
[Epoch 12, Batch 300] loss: 0.00995700085110002
[Epoch 12, Batch 400] loss: 0.010513397729082498
[Epoch 12, Batch 500] loss: 0.011065138269696035
[Epoch 12, Batch 600] loss: 0.015158041965332814
[Epoch 12, Batch 700] loss: 0.014623067271459149
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0436
Validation Accuracy: 0.9875
Overfitting: 0.0423
Best model saved at epoch 12 with validation loss: 0.0436
[Epoch 13, Batch 100] loss: 0.008477736719432869
[Epoch 13, Batch 200] loss: 0.010814688312602811
[Epoch 13, Batch 300] loss: 0.010673395572739537
[Epoch 13, Batch 400] loss: 0.007315108289622003
[Epoch 13, Batch 500] loss: 0.007756274932617089
[Epoch 13, Batch 600] loss: 0.010381330931777484
[Epoch 13, Batch 700] loss: 0.012171695799042936
**STATS for Epoch 13** : 
Average training loss: 0.0007
Average validation loss: 0.0441
Validation Accuracy: 0.9886
Overfitting: 0.0434
[Epoch 14, Batch 100] loss: 0.005585568754031556
[Epoch 14, Batch 200] loss: 0.004586604198375426
[Epoch 14, Batch 300] loss: 0.007320402228360763
[Epoch 14, Batch 400] loss: 0.011593932188698091
[Epoch 14, Batch 500] loss: 0.013592318790979335
[Epoch 14, Batch 600] loss: 0.009512505050515756
[Epoch 14, Batch 700] loss: 0.01021496761139133
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0447
Validation Accuracy: 0.9894
Overfitting: 0.0439
[Epoch 15, Batch 100] loss: 0.00598102376818133
[Epoch 15, Batch 200] loss: 0.00919396592733392
[Epoch 15, Batch 300] loss: 0.00786753770438736
[Epoch 15, Batch 400] loss: 0.010895557137446303
[Epoch 15, Batch 500] loss: 0.007144278282212326
[Epoch 15, Batch 600] loss: 0.006845504901939421
[Epoch 15, Batch 700] loss: 0.006554430016140031
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0448
Validation Accuracy: 0.9896
Overfitting: 0.0444
[Epoch 16, Batch 100] loss: 0.006732895330169413
[Epoch 16, Batch 200] loss: 0.009392017236896208
[Epoch 16, Batch 300] loss: 0.007891469307469378
[Epoch 16, Batch 400] loss: 0.0060466776951943755
[Epoch 16, Batch 500] loss: 0.006549528705400007
[Epoch 16, Batch 600] loss: 0.005885174084869505
[Epoch 16, Batch 700] loss: 0.009343655418269918
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0480
Validation Accuracy: 0.9886
Overfitting: 0.0475
[Epoch 17, Batch 100] loss: 0.005227861764215049
[Epoch 17, Batch 200] loss: 0.004767039885482518
[Epoch 17, Batch 300] loss: 0.0036101639877233536
[Epoch 17, Batch 400] loss: 0.006063427711760596
[Epoch 17, Batch 500] loss: 0.008210727197038067
[Epoch 17, Batch 600] loss: 0.006173263433629473
[Epoch 17, Batch 700] loss: 0.006321884357566887
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0492
Validation Accuracy: 0.9882
Overfitting: 0.0486
[Epoch 18, Batch 100] loss: 0.005089780589805741
[Epoch 18, Batch 200] loss: 0.00480796208990796
[Epoch 18, Batch 300] loss: 0.0029699008893112476
[Epoch 18, Batch 400] loss: 0.002321214011490156
[Epoch 18, Batch 500] loss: 0.0049763575610086265
[Epoch 18, Batch 600] loss: 0.004199825813229836
[Epoch 18, Batch 700] loss: 0.005194248808620614
**STATS for Epoch 18** : 
Average training loss: 0.0005
Average validation loss: 0.0531
Validation Accuracy: 0.9879
Overfitting: 0.0526
[Epoch 19, Batch 100] loss: 0.0036525178926240186
[Epoch 19, Batch 200] loss: 0.0034455076837548405
[Epoch 19, Batch 300] loss: 0.0021448577136470703
[Epoch 19, Batch 400] loss: 0.002475979999608171
[Epoch 19, Batch 500] loss: 0.0033162922179872114
[Epoch 19, Batch 600] loss: 0.004724650631396798
[Epoch 19, Batch 700] loss: 0.0034597893773207033
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0539
Validation Accuracy: 0.9882
Overfitting: 0.0535
[Epoch 20, Batch 100] loss: 0.0034420719627451034
[Epoch 20, Batch 200] loss: 0.001487154127357826
[Epoch 20, Batch 300] loss: 0.0016005093983767439
[Epoch 20, Batch 400] loss: 0.0030416825088468613
[Epoch 20, Batch 500] loss: 0.002519952101938543
[Epoch 20, Batch 600] loss: 0.0018011868674875585
[Epoch 20, Batch 700] loss: 0.002928460636667296
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0479
Validation Accuracy: 0.9912
Overfitting: 0.0477
[Epoch 21, Batch 100] loss: 0.0014128772781441513
[Epoch 21, Batch 200] loss: 0.004139587874078643
[Epoch 21, Batch 300] loss: 0.002526571235875963
[Epoch 21, Batch 400] loss: 0.0012761463582864963
[Epoch 21, Batch 500] loss: 0.0017943218983691622
[Epoch 21, Batch 600] loss: 0.001868492580574639
[Epoch 21, Batch 700] loss: 0.0026692842249394742
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0548
Validation Accuracy: 0.9884
Overfitting: 0.0546
[Epoch 22, Batch 100] loss: 0.0028705106662619074
[Epoch 22, Batch 200] loss: 0.002881470660595369
[Epoch 22, Batch 300] loss: 0.002429750601509113
[Epoch 22, Batch 400] loss: 0.004738962644714775
[Epoch 22, Batch 500] loss: 0.002158986339900366
[Epoch 22, Batch 600] loss: 0.0019050787142396075
[Epoch 22, Batch 700] loss: 0.0016115804607863993
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0502
Validation Accuracy: 0.9900
Overfitting: 0.0500
[Epoch 23, Batch 100] loss: 0.00320234722825262
[Epoch 23, Batch 200] loss: 0.0017366857087108656
[Epoch 23, Batch 300] loss: 0.0008824821038251685
[Epoch 23, Batch 400] loss: 0.00114376547066513
[Epoch 23, Batch 500] loss: 0.0007617275479969976
[Epoch 23, Batch 600] loss: 0.0023075953780426063
[Epoch 23, Batch 700] loss: 0.002332479979886557
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0526
Validation Accuracy: 0.9894
Overfitting: 0.0524
[Epoch 24, Batch 100] loss: 0.0016426490587127774
[Epoch 24, Batch 200] loss: 0.0016331241440775558
[Epoch 24, Batch 300] loss: 0.0013427057604803849
[Epoch 24, Batch 400] loss: 0.0017353823933217427
[Epoch 24, Batch 500] loss: 0.0011918283642171445
[Epoch 24, Batch 600] loss: 0.00167604445177858
[Epoch 24, Batch 700] loss: 0.0007734953266299271
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9890
Overfitting: 0.0524
Fold 3 validation loss: 0.0524
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2519870865345
[Epoch 1, Batch 200] loss: 0.9065078073740005
[Epoch 1, Batch 300] loss: 0.344345168620348
[Epoch 1, Batch 400] loss: 0.25739212073385714
[Epoch 1, Batch 500] loss: 0.18486905224621297
[Epoch 1, Batch 600] loss: 0.1523033567890525
[Epoch 1, Batch 700] loss: 0.13623231356963517
**STATS for Epoch 1** : 
Average training loss: 0.0081
Average validation loss: 0.1395
Validation Accuracy: 0.9570
Overfitting: 0.1314
Best model saved at epoch 1 with validation loss: 0.1395
[Epoch 2, Batch 100] loss: 0.11207211218774318
[Epoch 2, Batch 200] loss: 0.09400098146870732
[Epoch 2, Batch 300] loss: 0.09990033010952175
[Epoch 2, Batch 400] loss: 0.08523891394026578
[Epoch 2, Batch 500] loss: 0.08235510907135904
[Epoch 2, Batch 600] loss: 0.09082655573263765
[Epoch 2, Batch 700] loss: 0.07909411100670695
**STATS for Epoch 2** : 
Average training loss: 0.0049
Average validation loss: 0.0689
Validation Accuracy: 0.9782
Overfitting: 0.0640
Best model saved at epoch 2 with validation loss: 0.0689
[Epoch 3, Batch 100] loss: 0.06457214849069715
[Epoch 3, Batch 200] loss: 0.05778725780779496
[Epoch 3, Batch 300] loss: 0.062322352454066275
[Epoch 3, Batch 400] loss: 0.06284194088540972
[Epoch 3, Batch 500] loss: 0.058433607425540685
[Epoch 3, Batch 600] loss: 0.06882846455089747
[Epoch 3, Batch 700] loss: 0.0652728900918737
**STATS for Epoch 3** : 
Average training loss: 0.0037
Average validation loss: 0.0545
Validation Accuracy: 0.9822
Overfitting: 0.0509
Best model saved at epoch 3 with validation loss: 0.0545
[Epoch 4, Batch 100] loss: 0.038178051643772054
[Epoch 4, Batch 200] loss: 0.043943875504191966
[Epoch 4, Batch 300] loss: 0.04820445902412757
[Epoch 4, Batch 400] loss: 0.052235053330659864
[Epoch 4, Batch 500] loss: 0.050647634617052975
[Epoch 4, Batch 600] loss: 0.046611569225788116
[Epoch 4, Batch 700] loss: 0.04250706368591636
**STATS for Epoch 4** : 
Average training loss: 0.0037
Average validation loss: 0.0470
Validation Accuracy: 0.9859
Overfitting: 0.0433
Best model saved at epoch 4 with validation loss: 0.0470
[Epoch 5, Batch 100] loss: 0.04056563380174339
[Epoch 5, Batch 200] loss: 0.042693338515236975
[Epoch 5, Batch 300] loss: 0.043146649393020195
[Epoch 5, Batch 400] loss: 0.03967841716832481
[Epoch 5, Batch 500] loss: 0.03833078072872013
[Epoch 5, Batch 600] loss: 0.04005134708364494
[Epoch 5, Batch 700] loss: 0.032771477611968296
**STATS for Epoch 5** : 
Average training loss: 0.0029
Average validation loss: 0.0551
Validation Accuracy: 0.9824
Overfitting: 0.0523
[Epoch 6, Batch 100] loss: 0.03454142399365082
[Epoch 6, Batch 200] loss: 0.02985013520810753
[Epoch 6, Batch 300] loss: 0.02456369717954658
[Epoch 6, Batch 400] loss: 0.031235353203956037
[Epoch 6, Batch 500] loss: 0.032832074459875
[Epoch 6, Batch 600] loss: 0.036827728799544275
[Epoch 6, Batch 700] loss: 0.039230454735225066
**STATS for Epoch 6** : 
Average training loss: 0.0018
Average validation loss: 0.0450
Validation Accuracy: 0.9863
Overfitting: 0.0432
Best model saved at epoch 6 with validation loss: 0.0450
[Epoch 7, Batch 100] loss: 0.03321035597240552
[Epoch 7, Batch 200] loss: 0.026490296664414926
[Epoch 7, Batch 300] loss: 0.02782828846713528
[Epoch 7, Batch 400] loss: 0.028592775407014416
[Epoch 7, Batch 500] loss: 0.02836909965320956
[Epoch 7, Batch 600] loss: 0.028741900984896346
[Epoch 7, Batch 700] loss: 0.026126440704101698
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0474
Validation Accuracy: 0.9858
Overfitting: 0.0455
[Epoch 8, Batch 100] loss: 0.020911095402552746
[Epoch 8, Batch 200] loss: 0.025234103665570728
[Epoch 8, Batch 300] loss: 0.02518540129007306
[Epoch 8, Batch 400] loss: 0.023579144526738673
[Epoch 8, Batch 500] loss: 0.020645170374191366
[Epoch 8, Batch 600] loss: 0.024659075398813003
[Epoch 8, Batch 700] loss: 0.02221689543745015
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0427
Validation Accuracy: 0.9869
Overfitting: 0.0408
Best model saved at epoch 8 with validation loss: 0.0427
[Epoch 9, Batch 100] loss: 0.018356782248592936
[Epoch 9, Batch 200] loss: 0.01607197920879116
[Epoch 9, Batch 300] loss: 0.020214980489108712
[Epoch 9, Batch 400] loss: 0.022601169402623782
[Epoch 9, Batch 500] loss: 0.022366126402048395
[Epoch 9, Batch 600] loss: 0.018373370469198562
[Epoch 9, Batch 700] loss: 0.022925417247606675
**STATS for Epoch 9** : 
Average training loss: 0.0017
Average validation loss: 0.0442
Validation Accuracy: 0.9880
Overfitting: 0.0425
[Epoch 10, Batch 100] loss: 0.02027051822951762
[Epoch 10, Batch 200] loss: 0.011826720707613276
[Epoch 10, Batch 300] loss: 0.016279783201171086
[Epoch 10, Batch 400] loss: 0.01806621271214681
[Epoch 10, Batch 500] loss: 0.015963463666848837
[Epoch 10, Batch 600] loss: 0.02599028173543047
[Epoch 10, Batch 700] loss: 0.016340415055747144
**STATS for Epoch 10** : 
Average training loss: 0.0017
Average validation loss: 0.0422
Validation Accuracy: 0.9872
Overfitting: 0.0405
Best model saved at epoch 10 with validation loss: 0.0422
[Epoch 11, Batch 100] loss: 0.015157184488198255
[Epoch 11, Batch 200] loss: 0.016459863502750523
[Epoch 11, Batch 300] loss: 0.013802298530645202
[Epoch 11, Batch 400] loss: 0.01637210481814691
[Epoch 11, Batch 500] loss: 0.012754255776235368
[Epoch 11, Batch 600] loss: 0.012108545643568504
[Epoch 11, Batch 700] loss: 0.014138419291484752
**STATS for Epoch 11** : 
Average training loss: 0.0014
Average validation loss: 0.0474
Validation Accuracy: 0.9858
Overfitting: 0.0460
[Epoch 12, Batch 100] loss: 0.012336155264492846
[Epoch 12, Batch 200] loss: 0.009718770735198633
[Epoch 12, Batch 300] loss: 0.007895401790447067
[Epoch 12, Batch 400] loss: 0.014096679443609901
[Epoch 12, Batch 500] loss: 0.013684029993455624
[Epoch 12, Batch 600] loss: 0.014243588851677487
[Epoch 12, Batch 700] loss: 0.0184922598295816
**STATS for Epoch 12** : 
Average training loss: 0.0009
Average validation loss: 0.0469
Validation Accuracy: 0.9866
Overfitting: 0.0460
[Epoch 13, Batch 100] loss: 0.014277306006697472
[Epoch 13, Batch 200] loss: 0.012300190073692647
[Epoch 13, Batch 300] loss: 0.007769959486431617
[Epoch 13, Batch 400] loss: 0.008847809307844727
[Epoch 13, Batch 500] loss: 0.00940072667257482
[Epoch 13, Batch 600] loss: 0.009039161640685052
[Epoch 13, Batch 700] loss: 0.01274794076995022
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0534
Validation Accuracy: 0.9855
Overfitting: 0.0528
[Epoch 14, Batch 100] loss: 0.008491586238815216
[Epoch 14, Batch 200] loss: 0.008315657489874865
[Epoch 14, Batch 300] loss: 0.007112179538962664
[Epoch 14, Batch 400] loss: 0.012006389457965269
[Epoch 14, Batch 500] loss: 0.009602713415042673
[Epoch 14, Batch 600] loss: 0.00956128090096172
[Epoch 14, Batch 700] loss: 0.008368746716114402
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0434
Validation Accuracy: 0.9886
Overfitting: 0.0425
[Epoch 15, Batch 100] loss: 0.005664513765041192
[Epoch 15, Batch 200] loss: 0.010176821370532708
[Epoch 15, Batch 300] loss: 0.006284095973387594
[Epoch 15, Batch 400] loss: 0.009483570054726442
[Epoch 15, Batch 500] loss: 0.008491555753280408
[Epoch 15, Batch 600] loss: 0.006932047622976825
[Epoch 15, Batch 700] loss: 0.010315800158277853
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0381
Validation Accuracy: 0.9898
Overfitting: 0.0377
Best model saved at epoch 15 with validation loss: 0.0381
[Epoch 16, Batch 100] loss: 0.00541543353592715
[Epoch 16, Batch 200] loss: 0.004676515716701033
[Epoch 16, Batch 300] loss: 0.01141836619201058
[Epoch 16, Batch 400] loss: 0.0065231594760189185
[Epoch 16, Batch 500] loss: 0.004848949861043366
[Epoch 16, Batch 600] loss: 0.005081554873213463
[Epoch 16, Batch 700] loss: 0.01075283657075488
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0499
Validation Accuracy: 0.9868
Overfitting: 0.0490
[Epoch 17, Batch 100] loss: 0.004778722295477564
[Epoch 17, Batch 200] loss: 0.009398019843210932
[Epoch 17, Batch 300] loss: 0.00609594313929847
[Epoch 17, Batch 400] loss: 0.008885470853274456
[Epoch 17, Batch 500] loss: 0.004286599648548872
[Epoch 17, Batch 600] loss: 0.006791255064181314
[Epoch 17, Batch 700] loss: 0.0075366784747166096
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0446
Validation Accuracy: 0.9888
Overfitting: 0.0442
[Epoch 18, Batch 100] loss: 0.005563369373849127
[Epoch 18, Batch 200] loss: 0.007205260773316695
[Epoch 18, Batch 300] loss: 0.005638385742749961
[Epoch 18, Batch 400] loss: 0.005049615529496804
[Epoch 18, Batch 500] loss: 0.004574649189999036
[Epoch 18, Batch 600] loss: 0.004918641887306876
[Epoch 18, Batch 700] loss: 0.004479883569219964
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0488
Validation Accuracy: 0.9882
Overfitting: 0.0485
[Epoch 19, Batch 100] loss: 0.009865389503720507
[Epoch 19, Batch 200] loss: 0.005619189450153499
[Epoch 19, Batch 300] loss: 0.00454594839789479
[Epoch 19, Batch 400] loss: 0.004708142907202273
[Epoch 19, Batch 500] loss: 0.003369251225831249
[Epoch 19, Batch 600] loss: 0.0036996522248500694
[Epoch 19, Batch 700] loss: 0.008187465561713908
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0463
Validation Accuracy: 0.9885
Overfitting: 0.0460
[Epoch 20, Batch 100] loss: 0.006617708300036611
[Epoch 20, Batch 200] loss: 0.005566161592469143
[Epoch 20, Batch 300] loss: 0.00652063444524174
[Epoch 20, Batch 400] loss: 0.005378640976650786
[Epoch 20, Batch 500] loss: 0.0037045859355112043
[Epoch 20, Batch 600] loss: 0.004552262991783209
[Epoch 20, Batch 700] loss: 0.0030117646525650342
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0515
Validation Accuracy: 0.9878
Overfitting: 0.0512
[Epoch 21, Batch 100] loss: 0.006495878957812238
[Epoch 21, Batch 200] loss: 0.0030685871030982524
[Epoch 21, Batch 300] loss: 0.004450675260004573
[Epoch 21, Batch 400] loss: 0.0024211980814197887
[Epoch 21, Batch 500] loss: 0.0023346784636760274
[Epoch 21, Batch 600] loss: 0.0018839253263013235
[Epoch 21, Batch 700] loss: 0.006252063037832159
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0550
Validation Accuracy: 0.9866
Overfitting: 0.0544
[Epoch 22, Batch 100] loss: 0.007686894555008621
[Epoch 22, Batch 200] loss: 0.0040759203296238415
[Epoch 22, Batch 300] loss: 0.001557921068288124
[Epoch 22, Batch 400] loss: 0.0035680500951707473
[Epoch 22, Batch 500] loss: 0.0020088871442669643
[Epoch 22, Batch 600] loss: 0.002436266844307511
[Epoch 22, Batch 700] loss: 0.004538676538722939
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0560
Validation Accuracy: 0.9873
Overfitting: 0.0555
[Epoch 23, Batch 100] loss: 0.002014711958518092
[Epoch 23, Batch 200] loss: 0.0011303799096276635
[Epoch 23, Batch 300] loss: 0.0021070495812091396
[Epoch 23, Batch 400] loss: 0.0008943534083300619
[Epoch 23, Batch 500] loss: 0.002794216991387657
[Epoch 23, Batch 600] loss: 0.0028954164953483995
[Epoch 23, Batch 700] loss: 0.006273478731309297
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0549
Validation Accuracy: 0.9889
Overfitting: 0.0544
[Epoch 24, Batch 100] loss: 0.006511367331004294
[Epoch 24, Batch 200] loss: 0.0033672728403143994
[Epoch 24, Batch 300] loss: 0.004664291514718571
[Epoch 24, Batch 400] loss: 0.003834037542210353
[Epoch 24, Batch 500] loss: 0.00661633096757214
[Epoch 24, Batch 600] loss: 0.004253797422211392
[Epoch 24, Batch 700] loss: 0.005677862288812321
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0632
Validation Accuracy: 0.9850
Overfitting: 0.0628
Fold 4 validation loss: 0.0632
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.0988465094566346
[Epoch 1, Batch 200] loss: 0.5493531577289105
[Epoch 1, Batch 300] loss: 0.3217610077559948
[Epoch 1, Batch 400] loss: 0.242783592492342
[Epoch 1, Batch 500] loss: 0.18662877641618253
[Epoch 1, Batch 600] loss: 0.17296326879411936
[Epoch 1, Batch 700] loss: 0.1431482818350196
**STATS for Epoch 1** : 
Average training loss: 0.0078
Average validation loss: 0.1144
Validation Accuracy: 0.9647
Overfitting: 0.1066
Best model saved at epoch 1 with validation loss: 0.1144
[Epoch 2, Batch 100] loss: 0.12238495944067836
[Epoch 2, Batch 200] loss: 0.09478403771296144
[Epoch 2, Batch 300] loss: 0.09682816221378744
[Epoch 2, Batch 400] loss: 0.09782632952556014
[Epoch 2, Batch 500] loss: 0.09544446349143981
[Epoch 2, Batch 600] loss: 0.08446812119334936
[Epoch 2, Batch 700] loss: 0.094082549973391
**STATS for Epoch 2** : 
Average training loss: 0.0051
Average validation loss: 0.0811
Validation Accuracy: 0.9738
Overfitting: 0.0760
Best model saved at epoch 2 with validation loss: 0.0811
[Epoch 3, Batch 100] loss: 0.08250478096306324
[Epoch 3, Batch 200] loss: 0.07386929274071008
[Epoch 3, Batch 300] loss: 0.07039327771868557
[Epoch 3, Batch 400] loss: 0.054803560147993265
[Epoch 3, Batch 500] loss: 0.058744767922908066
[Epoch 3, Batch 600] loss: 0.07255560679361224
[Epoch 3, Batch 700] loss: 0.057782868002541364
**STATS for Epoch 3** : 
Average training loss: 0.0030
Average validation loss: 0.0687
Validation Accuracy: 0.9799
Overfitting: 0.0657
Best model saved at epoch 3 with validation loss: 0.0687
[Epoch 4, Batch 100] loss: 0.051482855412177744
[Epoch 4, Batch 200] loss: 0.0522721408540383
[Epoch 4, Batch 300] loss: 0.04634561592480168
[Epoch 4, Batch 400] loss: 0.049595638976898046
[Epoch 4, Batch 500] loss: 0.05265390558401123
[Epoch 4, Batch 600] loss: 0.052091581393033264
[Epoch 4, Batch 700] loss: 0.048824564467649906
**STATS for Epoch 4** : 
Average training loss: 0.0039
Average validation loss: 0.0626
Validation Accuracy: 0.9796
Overfitting: 0.0587
Best model saved at epoch 4 with validation loss: 0.0626
[Epoch 5, Batch 100] loss: 0.04441734946798533
[Epoch 5, Batch 200] loss: 0.03808659894973971
[Epoch 5, Batch 300] loss: 0.041825350425206125
[Epoch 5, Batch 400] loss: 0.04429702332359739
[Epoch 5, Batch 500] loss: 0.035895462112966924
[Epoch 5, Batch 600] loss: 0.03794377588666976
[Epoch 5, Batch 700] loss: 0.04864691556198522
**STATS for Epoch 5** : 
Average training loss: 0.0032
Average validation loss: 0.0495
Validation Accuracy: 0.9842
Overfitting: 0.0464
Best model saved at epoch 5 with validation loss: 0.0495
[Epoch 6, Batch 100] loss: 0.031230760989710688
[Epoch 6, Batch 200] loss: 0.029879494987544605
[Epoch 6, Batch 300] loss: 0.0346502244961448
[Epoch 6, Batch 400] loss: 0.034255911589134484
[Epoch 6, Batch 500] loss: 0.03049864273169078
[Epoch 6, Batch 600] loss: 0.03234286304272246
[Epoch 6, Batch 700] loss: 0.0365513487404678
**STATS for Epoch 6** : 
Average training loss: 0.0025
Average validation loss: 0.0498
Validation Accuracy: 0.9849
Overfitting: 0.0472
[Epoch 7, Batch 100] loss: 0.02270540500176139
[Epoch 7, Batch 200] loss: 0.026451912466436623
[Epoch 7, Batch 300] loss: 0.032253560033859686
[Epoch 7, Batch 400] loss: 0.02835855611367151
[Epoch 7, Batch 500] loss: 0.029315072256722488
[Epoch 7, Batch 600] loss: 0.02884671134292148
[Epoch 7, Batch 700] loss: 0.028378728711395525
**STATS for Epoch 7** : 
Average training loss: 0.0025
Average validation loss: 0.0508
Validation Accuracy: 0.9843
Overfitting: 0.0483
[Epoch 8, Batch 100] loss: 0.020897214072174392
[Epoch 8, Batch 200] loss: 0.019972735935007223
[Epoch 8, Batch 300] loss: 0.02331154413346667
[Epoch 8, Batch 400] loss: 0.024734626631834546
[Epoch 8, Batch 500] loss: 0.02752221696136985
[Epoch 8, Batch 600] loss: 0.030445503921364435
[Epoch 8, Batch 700] loss: 0.030086420088773592
**STATS for Epoch 8** : 
Average training loss: 0.0021
Average validation loss: 0.0548
Validation Accuracy: 0.9848
Overfitting: 0.0527
[Epoch 9, Batch 100] loss: 0.01750876227917615
[Epoch 9, Batch 200] loss: 0.018042715548945126
[Epoch 9, Batch 300] loss: 0.018947845716029407
[Epoch 9, Batch 400] loss: 0.027539293636800723
[Epoch 9, Batch 500] loss: 0.021226160559454
[Epoch 9, Batch 600] loss: 0.020529677711892874
[Epoch 9, Batch 700] loss: 0.02305409705310012
**STATS for Epoch 9** : 
Average training loss: 0.0013
Average validation loss: 0.0429
Validation Accuracy: 0.9869
Overfitting: 0.0417
Best model saved at epoch 9 with validation loss: 0.0429
[Epoch 10, Batch 100] loss: 0.01752665752253961
[Epoch 10, Batch 200] loss: 0.013128470850060693
[Epoch 10, Batch 300] loss: 0.01873234013648471
[Epoch 10, Batch 400] loss: 0.016276494968915357
[Epoch 10, Batch 500] loss: 0.022222928969131316
[Epoch 10, Batch 600] loss: 0.01827008717751596
[Epoch 10, Batch 700] loss: 0.01875563200941542
**STATS for Epoch 10** : 
Average training loss: 0.0014
Average validation loss: 0.0576
Validation Accuracy: 0.9820
Overfitting: 0.0562
[Epoch 11, Batch 100] loss: 0.01457143677311251
[Epoch 11, Batch 200] loss: 0.012240583102538949
[Epoch 11, Batch 300] loss: 0.014830315127037466
[Epoch 11, Batch 400] loss: 0.0200356423080666
[Epoch 11, Batch 500] loss: 0.016834014974301682
[Epoch 11, Batch 600] loss: 0.01329739249922568
[Epoch 11, Batch 700] loss: 0.019161505356169072
**STATS for Epoch 11** : 
Average training loss: 0.0013
Average validation loss: 0.0480
Validation Accuracy: 0.9861
Overfitting: 0.0467
[Epoch 12, Batch 100] loss: 0.013076560099871131
[Epoch 12, Batch 200] loss: 0.016993967712624
[Epoch 12, Batch 300] loss: 0.014452321580974967
[Epoch 12, Batch 400] loss: 0.015053844514186494
[Epoch 12, Batch 500] loss: 0.014589242475194624
[Epoch 12, Batch 600] loss: 0.010517563123721629
[Epoch 12, Batch 700] loss: 0.01583494772348786
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0485
Validation Accuracy: 0.9862
Overfitting: 0.0476
[Epoch 13, Batch 100] loss: 0.012659715960326138
[Epoch 13, Batch 200] loss: 0.007676794328581309
[Epoch 13, Batch 300] loss: 0.009700375813117716
[Epoch 13, Batch 400] loss: 0.011337528501317138
[Epoch 13, Batch 500] loss: 0.012533951317163883
[Epoch 13, Batch 600] loss: 0.012683383070398123
[Epoch 13, Batch 700] loss: 0.008036498894143733
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0471
Validation Accuracy: 0.9875
Overfitting: 0.0464
[Epoch 14, Batch 100] loss: 0.007427725846137037
[Epoch 14, Batch 200] loss: 0.010040656985511305
[Epoch 14, Batch 300] loss: 0.009584080364111286
[Epoch 14, Batch 400] loss: 0.006618954197510902
[Epoch 14, Batch 500] loss: 0.008404486372292012
[Epoch 14, Batch 600] loss: 0.011193681392433064
[Epoch 14, Batch 700] loss: 0.01052726553989487
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0509
Validation Accuracy: 0.9868
Overfitting: 0.0501
[Epoch 15, Batch 100] loss: 0.007368632191210054
[Epoch 15, Batch 200] loss: 0.0051203686358348936
[Epoch 15, Batch 300] loss: 0.010349543462143628
[Epoch 15, Batch 400] loss: 0.008755968628156552
[Epoch 15, Batch 500] loss: 0.011302680479566334
[Epoch 15, Batch 600] loss: 0.012429275752510875
[Epoch 15, Batch 700] loss: 0.0097096342605073
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0490
Validation Accuracy: 0.9879
Overfitting: 0.0486
[Epoch 16, Batch 100] loss: 0.008260698721423978
[Epoch 16, Batch 200] loss: 0.007031789293578185
[Epoch 16, Batch 300] loss: 0.008226585276788682
[Epoch 16, Batch 400] loss: 0.007499888016900514
[Epoch 16, Batch 500] loss: 0.005604210049423273
[Epoch 16, Batch 600] loss: 0.006521967840235447
[Epoch 16, Batch 700] loss: 0.010213174234922916
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0458
Validation Accuracy: 0.9885
Overfitting: 0.0452
[Epoch 17, Batch 100] loss: 0.006810481182656076
[Epoch 17, Batch 200] loss: 0.008837567789814784
[Epoch 17, Batch 300] loss: 0.008076862445450387
[Epoch 17, Batch 400] loss: 0.005093021119755577
[Epoch 17, Batch 500] loss: 0.0033390616178166966
[Epoch 17, Batch 600] loss: 0.00533123310211522
[Epoch 17, Batch 700] loss: 0.007391870532046596
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0479
Validation Accuracy: 0.9884
Overfitting: 0.0474
[Epoch 18, Batch 100] loss: 0.0056605015556488066
[Epoch 18, Batch 200] loss: 0.00493371861275591
[Epoch 18, Batch 300] loss: 0.0043381616826809475
[Epoch 18, Batch 400] loss: 0.005607328628866526
[Epoch 18, Batch 500] loss: 0.006105845191150365
[Epoch 18, Batch 600] loss: 0.005981331109578605
[Epoch 18, Batch 700] loss: 0.005239324891736032
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0484
Validation Accuracy: 0.9872
Overfitting: 0.0479
[Epoch 19, Batch 100] loss: 0.004776140973008296
[Epoch 19, Batch 200] loss: 0.006019286007121991
[Epoch 19, Batch 300] loss: 0.0063105100947723255
[Epoch 19, Batch 400] loss: 0.0038211278669768945
[Epoch 19, Batch 500] loss: 0.0044210432042200406
[Epoch 19, Batch 600] loss: 0.008398687976905421
[Epoch 19, Batch 700] loss: 0.0044885614428858385
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0485
Validation Accuracy: 0.9878
Overfitting: 0.0483
[Epoch 20, Batch 100] loss: 0.003396614670677991
[Epoch 20, Batch 200] loss: 0.0034090164353438013
[Epoch 20, Batch 300] loss: 0.0031292941252286256
[Epoch 20, Batch 400] loss: 0.0042590691693749246
[Epoch 20, Batch 500] loss: 0.006250450418656328
[Epoch 20, Batch 600] loss: 0.003789453564941141
[Epoch 20, Batch 700] loss: 0.007183494673372479
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0501
Validation Accuracy: 0.9880
Overfitting: 0.0499
[Epoch 21, Batch 100] loss: 0.005902977276327874
[Epoch 21, Batch 200] loss: 0.004201969782188826
[Epoch 21, Batch 300] loss: 0.00564644768425751
[Epoch 21, Batch 400] loss: 0.0032276500239095183
[Epoch 21, Batch 500] loss: 0.004087794801243945
[Epoch 21, Batch 600] loss: 0.00459301904993481
[Epoch 21, Batch 700] loss: 0.004975989764334372
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0528
Validation Accuracy: 0.9875
Overfitting: 0.0525
[Epoch 22, Batch 100] loss: 0.010594023604062386
[Epoch 22, Batch 200] loss: 0.0064202595945425855
[Epoch 22, Batch 300] loss: 0.0028990298819553573
[Epoch 22, Batch 400] loss: 0.0032364896955596125
[Epoch 22, Batch 500] loss: 0.010934847359203559
[Epoch 22, Batch 600] loss: 0.004905813278264759
[Epoch 22, Batch 700] loss: 0.0030715454854043857
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0553
Validation Accuracy: 0.9882
Overfitting: 0.0549
[Epoch 23, Batch 100] loss: 0.002215358010316777
[Epoch 23, Batch 200] loss: 0.00420685824670727
[Epoch 23, Batch 300] loss: 0.00401950564550134
[Epoch 23, Batch 400] loss: 0.0034847163696667847
[Epoch 23, Batch 500] loss: 0.004462709671770426
[Epoch 23, Batch 600] loss: 0.001759964997509087
[Epoch 23, Batch 700] loss: 0.006303677255291404
**STATS for Epoch 23** : 
Average training loss: 0.0009
Average validation loss: 0.0612
Validation Accuracy: 0.9863
Overfitting: 0.0603
[Epoch 24, Batch 100] loss: 0.006920046705263303
[Epoch 24, Batch 200] loss: 0.007474376224672596
[Epoch 24, Batch 300] loss: 0.00343283440968662
[Epoch 24, Batch 400] loss: 0.004300177694904051
[Epoch 24, Batch 500] loss: 0.0028278283975214434
[Epoch 24, Batch 600] loss: 0.0029283496980315247
[Epoch 24, Batch 700] loss: 0.00423661224519492
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0549
Validation Accuracy: 0.9884
Overfitting: 0.0547
Fold 5 validation loss: 0.0549
Mean validation loss across all folds for Trial 17 is 0.0556 with trial config:  l1: 256, l2: 128, lr: 0.004571883955625129, batch_size: 64
[I 2024-12-11 07:00:09,684] Trial 16 finished with value: 0.05556671151106266 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.004571883955625129, 'batch_size': 64}. Best is trial 4 with value: 0.04724671796616846.

Selected Hyperparameters for Trial 18:
  l1: 256, l2: 128, lr: 0.004248530903342542, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.281401298046112
**STATS for Epoch 1** : 
Average training loss: 0.7119
Average validation loss: 0.4999
Validation Accuracy: 0.8377
Overfitting: -0.2121
Best model saved at epoch 1 with validation loss: 0.4999
[Epoch 2, Batch 100] loss: 0.3781122244894505
**STATS for Epoch 2** : 
Average training loss: 0.1071
Average validation loss: 0.1793
Validation Accuracy: 0.9460
Overfitting: 0.0721
Best model saved at epoch 2 with validation loss: 0.1793
[Epoch 3, Batch 100] loss: 0.1690707116574049
**STATS for Epoch 3** : 
Average training loss: 0.0696
Average validation loss: 0.1186
Validation Accuracy: 0.9631
Overfitting: 0.0490
Best model saved at epoch 3 with validation loss: 0.1186
[Epoch 4, Batch 100] loss: 0.11984840422868728
**STATS for Epoch 4** : 
Average training loss: 0.0528
Average validation loss: 0.0936
Validation Accuracy: 0.9728
Overfitting: 0.0409
Best model saved at epoch 4 with validation loss: 0.0936
[Epoch 5, Batch 100] loss: 0.10292373599484562
**STATS for Epoch 5** : 
Average training loss: 0.0421
Average validation loss: 0.0825
Validation Accuracy: 0.9742
Overfitting: 0.0404
Best model saved at epoch 5 with validation loss: 0.0825
[Epoch 6, Batch 100] loss: 0.084883421510458
**STATS for Epoch 6** : 
Average training loss: 0.0377
Average validation loss: 0.0786
Validation Accuracy: 0.9753
Overfitting: 0.0409
Best model saved at epoch 6 with validation loss: 0.0786
[Epoch 7, Batch 100] loss: 0.07501572746783496
**STATS for Epoch 7** : 
Average training loss: 0.0317
Average validation loss: 0.0663
Validation Accuracy: 0.9795
Overfitting: 0.0345
Best model saved at epoch 7 with validation loss: 0.0663
[Epoch 8, Batch 100] loss: 0.06343796269968152
**STATS for Epoch 8** : 
Average training loss: 0.0316
Average validation loss: 0.0666
Validation Accuracy: 0.9793
Overfitting: 0.0350
[Epoch 9, Batch 100] loss: 0.059919106233865024
**STATS for Epoch 9** : 
Average training loss: 0.0268
Average validation loss: 0.0611
Validation Accuracy: 0.9821
Overfitting: 0.0342
[I 2024-12-11 07:01:27,912] Trial 17 pruned. 

Selected Hyperparameters for Trial 19:
  l1: 256, l2: 128, lr: 0.0007732936101162838, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3012877535820007
[Epoch 1, Batch 200] loss: 2.2797309875488283
[Epoch 1, Batch 300] loss: 2.2352412295341493
[Epoch 1, Batch 400] loss: 2.084468883275986
[Epoch 1, Batch 500] loss: 1.3758505636453628
[Epoch 1, Batch 600] loss: 0.6922127526998519
[Epoch 1, Batch 700] loss: 0.49005929082632066
**STATS for Epoch 1** : 
Average training loss: 0.0274
Average validation loss: 0.4306
Validation Accuracy: 0.8750
Overfitting: 0.4032
Best model saved at epoch 1 with validation loss: 0.4306
[Epoch 2, Batch 100] loss: 0.40288346603512765
[Epoch 2, Batch 200] loss: 0.3346502912044525
[Epoch 2, Batch 300] loss: 0.3254950360953808
[Epoch 2, Batch 400] loss: 0.2902081387490034
[Epoch 2, Batch 500] loss: 0.2732950337231159
[Epoch 2, Batch 600] loss: 0.25566180862486365
[Epoch 2, Batch 700] loss: 0.23338406190276145
**STATS for Epoch 2** : 
Average training loss: 0.0146
Average validation loss: 0.2186
Validation Accuracy: 0.9300
Overfitting: 0.2040
Best model saved at epoch 2 with validation loss: 0.2186
[Epoch 3, Batch 100] loss: 0.20756287287920713
[Epoch 3, Batch 200] loss: 0.21531925708055497
[Epoch 3, Batch 300] loss: 0.19249697007238864
[Epoch 3, Batch 400] loss: 0.17865412898361682
[Epoch 3, Batch 500] loss: 0.16784515149891377
[Epoch 3, Batch 600] loss: 0.1712604070827365
[Epoch 3, Batch 700] loss: 0.16044724371284247
**STATS for Epoch 3** : 
Average training loss: 0.0101
Average validation loss: 0.1489
Validation Accuracy: 0.9544
Overfitting: 0.1388
Best model saved at epoch 3 with validation loss: 0.1489
[Epoch 4, Batch 100] loss: 0.15684152442961932
[Epoch 4, Batch 200] loss: 0.142885701097548
[Epoch 4, Batch 300] loss: 0.1318026599660516
[Epoch 4, Batch 400] loss: 0.14344222211278976
[Epoch 4, Batch 500] loss: 0.13762847786769272
[Epoch 4, Batch 600] loss: 0.1397505014576018
[Epoch 4, Batch 700] loss: 0.11791231768205762
**STATS for Epoch 4** : 
Average training loss: 0.0075
Average validation loss: 0.1133
Validation Accuracy: 0.9657
Overfitting: 0.1058
Best model saved at epoch 4 with validation loss: 0.1133
[Epoch 5, Batch 100] loss: 0.11587066508829594
[Epoch 5, Batch 200] loss: 0.10967784155160189
[Epoch 5, Batch 300] loss: 0.11637171071022749
[Epoch 5, Batch 400] loss: 0.12354598062112927
[Epoch 5, Batch 500] loss: 0.10439379874616861
[Epoch 5, Batch 600] loss: 0.1178652117215097
[Epoch 5, Batch 700] loss: 0.1108392346650362
**STATS for Epoch 5** : 
Average training loss: 0.0069
Average validation loss: 0.1023
Validation Accuracy: 0.9682
Overfitting: 0.0955
Best model saved at epoch 5 with validation loss: 0.1023
[Epoch 6, Batch 100] loss: 0.09590811332687736
[Epoch 6, Batch 200] loss: 0.09271950302645564
[Epoch 6, Batch 300] loss: 0.09963386217132211
[Epoch 6, Batch 400] loss: 0.1048498306144029
[Epoch 6, Batch 500] loss: 0.09477409470826387
[Epoch 6, Batch 600] loss: 0.09450789736583828
[Epoch 6, Batch 700] loss: 0.09460453433915973
**STATS for Epoch 6** : 
Average training loss: 0.0069
Average validation loss: 0.0974
Validation Accuracy: 0.9702
Overfitting: 0.0905
Best model saved at epoch 6 with validation loss: 0.0974
[Epoch 7, Batch 100] loss: 0.0906090277992189
[Epoch 7, Batch 200] loss: 0.09135710312053562
[Epoch 7, Batch 300] loss: 0.07870562731288373
[Epoch 7, Batch 400] loss: 0.08356359648518265
[Epoch 7, Batch 500] loss: 0.08727212060242891
[Epoch 7, Batch 600] loss: 0.09228865838609636
[Epoch 7, Batch 700] loss: 0.08078418568242342
**STATS for Epoch 7** : 
Average training loss: 0.0052
Average validation loss: 0.0772
Validation Accuracy: 0.9750
Overfitting: 0.0720
Best model saved at epoch 7 with validation loss: 0.0772
[Epoch 8, Batch 100] loss: 0.08558870149776339
[Epoch 8, Batch 200] loss: 0.07428851252421736
[Epoch 8, Batch 300] loss: 0.07885902750305832
[Epoch 8, Batch 400] loss: 0.09133401260711253
[Epoch 8, Batch 500] loss: 0.07052272443659603
[Epoch 8, Batch 600] loss: 0.07430111108347774
[Epoch 8, Batch 700] loss: 0.07171128302812577
**STATS for Epoch 8** : 
Average training loss: 0.0051
Average validation loss: 0.0740
Validation Accuracy: 0.9766
Overfitting: 0.0689
Best model saved at epoch 8 with validation loss: 0.0740
[Epoch 9, Batch 100] loss: 0.06992682722397149
[Epoch 9, Batch 200] loss: 0.07634747236035765
[Epoch 9, Batch 300] loss: 0.06472869300283492
[Epoch 9, Batch 400] loss: 0.07157344580162317
[Epoch 9, Batch 500] loss: 0.07620178980752826
[Epoch 9, Batch 600] loss: 0.07556047992315143
[Epoch 9, Batch 700] loss: 0.06424786127870902
**STATS for Epoch 9** : 
Average training loss: 0.0051
Average validation loss: 0.0791
Validation Accuracy: 0.9745
Overfitting: 0.0739
[I 2024-12-11 07:02:55,090] Trial 18 pruned. 

Selected Hyperparameters for Trial 20:
  l1: 256, l2: 64, lr: 0.009505026151444827, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.6643511644005775
[Epoch 1, Batch 200] loss: 0.35932175159454344
[Epoch 1, Batch 300] loss: 0.20493186384439468
[Epoch 1, Batch 400] loss: 0.1731258411332965
[Epoch 1, Batch 500] loss: 0.11717901634052395
[Epoch 1, Batch 600] loss: 0.1110056502185762
[Epoch 1, Batch 700] loss: 0.09802277525886893
**STATS for Epoch 1** : 
Average training loss: 0.0081
Average validation loss: 0.0866
Validation Accuracy: 0.9732
Overfitting: 0.0785
Best model saved at epoch 1 with validation loss: 0.0866
[Epoch 2, Batch 100] loss: 0.09800992978736758
[Epoch 2, Batch 200] loss: 0.08440158727578818
[Epoch 2, Batch 300] loss: 0.07333975308574736
[Epoch 2, Batch 400] loss: 0.07486062055453659
[Epoch 2, Batch 500] loss: 0.0657748318463564
[Epoch 2, Batch 600] loss: 0.07298367748502642
[Epoch 2, Batch 700] loss: 0.0685574966436252
**STATS for Epoch 2** : 
Average training loss: 0.0047
Average validation loss: 0.0565
Validation Accuracy: 0.9822
Overfitting: 0.0518
Best model saved at epoch 2 with validation loss: 0.0565
[Epoch 3, Batch 100] loss: 0.051840387729462235
[Epoch 3, Batch 200] loss: 0.0527833389386069
[Epoch 3, Batch 300] loss: 0.049137242033611986
[Epoch 3, Batch 400] loss: 0.04563328010495752
[Epoch 3, Batch 500] loss: 0.046532408290077
[Epoch 3, Batch 600] loss: 0.055570279613602905
[Epoch 3, Batch 700] loss: 0.052474260661983865
**STATS for Epoch 3** : 
Average training loss: 0.0038
Average validation loss: 0.0496
Validation Accuracy: 0.9862
Overfitting: 0.0458
Best model saved at epoch 3 with validation loss: 0.0496
[Epoch 4, Batch 100] loss: 0.03927694270503707
[Epoch 4, Batch 200] loss: 0.034986030536238104
[Epoch 4, Batch 300] loss: 0.04197185512748547
[Epoch 4, Batch 400] loss: 0.037064961546566334
[Epoch 4, Batch 500] loss: 0.04508759121643379
[Epoch 4, Batch 600] loss: 0.038856017888174395
[Epoch 4, Batch 700] loss: 0.039905194106395356
**STATS for Epoch 4** : 
Average training loss: 0.0019
Average validation loss: 0.0460
Validation Accuracy: 0.9863
Overfitting: 0.0441
Best model saved at epoch 4 with validation loss: 0.0460
[Epoch 5, Batch 100] loss: 0.027222385014756583
[Epoch 5, Batch 200] loss: 0.03985795496439096
[Epoch 5, Batch 300] loss: 0.03225002335268073
[Epoch 5, Batch 400] loss: 0.02759969463571906
[Epoch 5, Batch 500] loss: 0.037336904982221315
[Epoch 5, Batch 600] loss: 0.03285617379122414
[Epoch 5, Batch 700] loss: 0.03398018400650472
**STATS for Epoch 5** : 
Average training loss: 0.0022
Average validation loss: 0.0456
Validation Accuracy: 0.9859
Overfitting: 0.0434
Best model saved at epoch 5 with validation loss: 0.0456
[Epoch 6, Batch 100] loss: 0.02703677978250198
[Epoch 6, Batch 200] loss: 0.022020309925428593
[Epoch 6, Batch 300] loss: 0.018677516355528497
[Epoch 6, Batch 400] loss: 0.026131004723283696
[Epoch 6, Batch 500] loss: 0.022365173158468678
[Epoch 6, Batch 600] loss: 0.027261872366070746
[Epoch 6, Batch 700] loss: 0.02553590233117575
**STATS for Epoch 6** : 
Average training loss: 0.0019
Average validation loss: 0.0546
Validation Accuracy: 0.9846
Overfitting: 0.0527
[Epoch 7, Batch 100] loss: 0.018376896835397928
[Epoch 7, Batch 200] loss: 0.01674096693954198
[Epoch 7, Batch 300] loss: 0.020357562450808473
[Epoch 7, Batch 400] loss: 0.018808824365114562
[Epoch 7, Batch 500] loss: 0.0257924180815462
[Epoch 7, Batch 600] loss: 0.02008779984593275
[Epoch 7, Batch 700] loss: 0.02618264823657228
**STATS for Epoch 7** : 
Average training loss: 0.0016
Average validation loss: 0.0420
Validation Accuracy: 0.9882
Overfitting: 0.0404
Best model saved at epoch 7 with validation loss: 0.0420
[Epoch 8, Batch 100] loss: 0.01215561756893294
[Epoch 8, Batch 200] loss: 0.013828725091007072
[Epoch 8, Batch 300] loss: 0.020074614771001507
[Epoch 8, Batch 400] loss: 0.01814029913482955
[Epoch 8, Batch 500] loss: 0.016414377374312606
[Epoch 8, Batch 600] loss: 0.02071004184166668
[Epoch 8, Batch 700] loss: 0.01511639523349004
**STATS for Epoch 8** : 
Average training loss: 0.0010
Average validation loss: 0.0435
Validation Accuracy: 0.9875
Overfitting: 0.0425
[Epoch 9, Batch 100] loss: 0.009092225655331276
[Epoch 9, Batch 200] loss: 0.010884605734609067
[Epoch 9, Batch 300] loss: 0.014834509142892784
[Epoch 9, Batch 400] loss: 0.019760829099250258
[Epoch 9, Batch 500] loss: 0.012534855181875172
[Epoch 9, Batch 600] loss: 0.016426728363439905
[Epoch 9, Batch 700] loss: 0.02278784470003302
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0413
Validation Accuracy: 0.9886
Overfitting: 0.0397
Best model saved at epoch 9 with validation loss: 0.0413
[Epoch 10, Batch 100] loss: 0.009490588009321073
[Epoch 10, Batch 200] loss: 0.010905312109025544
[Epoch 10, Batch 300] loss: 0.012410016392386751
[Epoch 10, Batch 400] loss: 0.015571254275018874
[Epoch 10, Batch 500] loss: 0.010063040960376383
[Epoch 10, Batch 600] loss: 0.014748554885736667
[Epoch 10, Batch 700] loss: 0.01049881336359249
**STATS for Epoch 10** : 
Average training loss: 0.0006
Average validation loss: 0.0494
Validation Accuracy: 0.9865
Overfitting: 0.0488
[Epoch 11, Batch 100] loss: 0.013158525931794429
[Epoch 11, Batch 200] loss: 0.005794226609432371
[Epoch 11, Batch 300] loss: 0.008425254184548975
[Epoch 11, Batch 400] loss: 0.010609021541495168
[Epoch 11, Batch 500] loss: 0.008309034762896772
[Epoch 11, Batch 600] loss: 0.007306892364449595
[Epoch 11, Batch 700] loss: 0.011621822894285287
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0463
Validation Accuracy: 0.9880
Overfitting: 0.0450
[Epoch 12, Batch 100] loss: 0.01224972456832802
[Epoch 12, Batch 200] loss: 0.007723080072646553
[Epoch 12, Batch 300] loss: 0.012103667051924276
[Epoch 12, Batch 400] loss: 0.009707559639628017
[Epoch 12, Batch 500] loss: 0.011699908080336172
[Epoch 12, Batch 600] loss: 0.011834929423239373
[Epoch 12, Batch 700] loss: 0.006495029269717634
**STATS for Epoch 12** : 
Average training loss: 0.0005
Average validation loss: 0.0434
Validation Accuracy: 0.9892
Overfitting: 0.0430
[Epoch 13, Batch 100] loss: 0.00474113925749407
[Epoch 13, Batch 200] loss: 0.008581475442297233
[Epoch 13, Batch 300] loss: 0.009750028974449378
[Epoch 13, Batch 400] loss: 0.005023285298511837
[Epoch 13, Batch 500] loss: 0.005458449941124854
[Epoch 13, Batch 600] loss: 0.006423211847304628
[Epoch 13, Batch 700] loss: 0.01163095927957329
**STATS for Epoch 13** : 
Average training loss: 0.0013
Average validation loss: 0.0575
Validation Accuracy: 0.9857
Overfitting: 0.0563
[Epoch 14, Batch 100] loss: 0.011540577345949715
[Epoch 14, Batch 200] loss: 0.01000837962317746
[Epoch 14, Batch 300] loss: 0.008225168438475521
[Epoch 14, Batch 400] loss: 0.007033182155209943
[Epoch 14, Batch 500] loss: 0.003764188192290021
[Epoch 14, Batch 600] loss: 0.007068219598004362
[Epoch 14, Batch 700] loss: 0.006280023863582756
**STATS for Epoch 14** : 
Average training loss: 0.0003
Average validation loss: 0.0418
Validation Accuracy: 0.9907
Overfitting: 0.0416
[Epoch 15, Batch 100] loss: 0.0049239007606070116
[Epoch 15, Batch 200] loss: 0.006271911815438216
[Epoch 15, Batch 300] loss: 0.004745647374802502
[Epoch 15, Batch 400] loss: 0.003667839420504606
[Epoch 15, Batch 500] loss: 0.004433148863640781
[Epoch 15, Batch 600] loss: 0.005383060601016041
[Epoch 15, Batch 700] loss: 0.00440982634215743
**STATS for Epoch 15** : 
Average training loss: 0.0003
Average validation loss: 0.0427
Validation Accuracy: 0.9908
Overfitting: 0.0424
[Epoch 16, Batch 100] loss: 0.0022822324618482527
[Epoch 16, Batch 200] loss: 0.005123486340708041
[Epoch 16, Batch 300] loss: 0.004227925507502732
[Epoch 16, Batch 400] loss: 0.007220390888878683
[Epoch 16, Batch 500] loss: 0.01143914264814157
[Epoch 16, Batch 600] loss: 0.008276600306162436
[Epoch 16, Batch 700] loss: 0.0026690522298088125
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0513
Validation Accuracy: 0.9888
Overfitting: 0.0509
[Epoch 17, Batch 100] loss: 0.0034176653570466443
[Epoch 17, Batch 200] loss: 0.004017068976509108
[Epoch 17, Batch 300] loss: 0.004780182297463398
[Epoch 17, Batch 400] loss: 0.00518569744082015
[Epoch 17, Batch 500] loss: 0.007800635180310564
[Epoch 17, Batch 600] loss: 0.0027746382982968497
[Epoch 17, Batch 700] loss: 0.006188609005257604
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0494
Validation Accuracy: 0.9891
Overfitting: 0.0490
[Epoch 18, Batch 100] loss: 0.005033859605209728
[Epoch 18, Batch 200] loss: 0.003502605547641906
[Epoch 18, Batch 300] loss: 0.006260933890898741
[Epoch 18, Batch 400] loss: 0.010494224044996371
[Epoch 18, Batch 500] loss: 0.010266852873510288
[Epoch 18, Batch 600] loss: 0.004119768559594377
[Epoch 18, Batch 700] loss: 0.0037871314670883294
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0468
Validation Accuracy: 0.9895
Overfitting: 0.0465
[Epoch 19, Batch 100] loss: 0.003927660577796814
[Epoch 19, Batch 200] loss: 0.0026739900091570235
[Epoch 19, Batch 300] loss: 0.001851824334344201
[Epoch 19, Batch 400] loss: 0.0058781671502976
[Epoch 19, Batch 500] loss: 0.007025966821993279
[Epoch 19, Batch 600] loss: 0.007455198045763609
[Epoch 19, Batch 700] loss: 0.004192216459314295
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0454
Validation Accuracy: 0.9894
Overfitting: 0.0453
[Epoch 20, Batch 100] loss: 0.0009889184273197316
[Epoch 20, Batch 200] loss: 0.0022685744901968976
[Epoch 20, Batch 300] loss: 0.002193793436940723
[Epoch 20, Batch 400] loss: 0.0027148120062656742
[Epoch 20, Batch 500] loss: 0.001270141096508155
[Epoch 20, Batch 600] loss: 0.0027086417885419677
[Epoch 20, Batch 700] loss: 0.0008447883831075842
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0443
Validation Accuracy: 0.9902
Overfitting: 0.0442
[Epoch 21, Batch 100] loss: 0.0015437396488130163
[Epoch 21, Batch 200] loss: 0.00042678872154283453
[Epoch 21, Batch 300] loss: 0.0014016563619736644
[Epoch 21, Batch 400] loss: 0.0004877628379983889
[Epoch 21, Batch 500] loss: 0.0005545677681664074
[Epoch 21, Batch 600] loss: 0.00046014277404651696
[Epoch 21, Batch 700] loss: 0.0013886050203154809
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0485
Validation Accuracy: 0.9902
Overfitting: 0.0484
[Epoch 22, Batch 100] loss: 0.0011686134635999679
[Epoch 22, Batch 200] loss: 0.00024312012530970152
[Epoch 22, Batch 300] loss: 0.0004193884858136698
[Epoch 22, Batch 400] loss: 0.00058850703561518
[Epoch 22, Batch 500] loss: 0.0002957417389154671
[Epoch 22, Batch 600] loss: 0.00037970069648963546
[Epoch 22, Batch 700] loss: 0.000513530540672491
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0503
Validation Accuracy: 0.9901
Overfitting: 0.0503
[Epoch 23, Batch 100] loss: 0.0004572537349918093
[Epoch 23, Batch 200] loss: 0.00013686398808943068
[Epoch 23, Batch 300] loss: 0.0001679958930034786
[Epoch 23, Batch 400] loss: 0.000255947662986955
[Epoch 23, Batch 500] loss: 0.0002788323262018366
[Epoch 23, Batch 600] loss: 0.00024153009742221342
[Epoch 23, Batch 700] loss: 0.0004225867564781538
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9908
Overfitting: 0.0499
[Epoch 24, Batch 100] loss: 0.0005572391336920645
[Epoch 24, Batch 200] loss: 0.00015457730412009595
[Epoch 24, Batch 300] loss: 0.0002246459334386941
[Epoch 24, Batch 400] loss: 0.0001023908786771699
[Epoch 24, Batch 500] loss: 0.00012581118474997766
[Epoch 24, Batch 600] loss: 0.00015306612988467806
[Epoch 24, Batch 700] loss: 0.0002629449044792409
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9908
Overfitting: 0.0491
Fold 1 validation loss: 0.0491
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.6716541555523872
[Epoch 1, Batch 200] loss: 0.3422226679325104
[Epoch 1, Batch 300] loss: 0.20971685126423836
[Epoch 1, Batch 400] loss: 0.13844352697953582
[Epoch 1, Batch 500] loss: 0.13487250300124287
[Epoch 1, Batch 600] loss: 0.12456550341099501
[Epoch 1, Batch 700] loss: 0.08834381344728172
**STATS for Epoch 1** : 
Average training loss: 0.0068
Average validation loss: 0.0992
Validation Accuracy: 0.9688
Overfitting: 0.0924
Best model saved at epoch 1 with validation loss: 0.0992
[Epoch 2, Batch 100] loss: 0.082852772930637
[Epoch 2, Batch 200] loss: 0.0687660566624254
[Epoch 2, Batch 300] loss: 0.07811398601159453
[Epoch 2, Batch 400] loss: 0.07511571233160794
[Epoch 2, Batch 500] loss: 0.08032532181590796
[Epoch 2, Batch 600] loss: 0.0657804920594208
[Epoch 2, Batch 700] loss: 0.06978517354698852
**STATS for Epoch 2** : 
Average training loss: 0.0042
Average validation loss: 0.1123
Validation Accuracy: 0.9655
Overfitting: 0.1081
[Epoch 3, Batch 100] loss: 0.056360902281012384
[Epoch 3, Batch 200] loss: 0.05496914885938167
[Epoch 3, Batch 300] loss: 0.04706103606964462
[Epoch 3, Batch 400] loss: 0.050630901174154135
[Epoch 3, Batch 500] loss: 0.05863973269239068
[Epoch 3, Batch 600] loss: 0.04962745117605664
[Epoch 3, Batch 700] loss: 0.04850285205524415
**STATS for Epoch 3** : 
Average training loss: 0.0030
Average validation loss: 0.0551
Validation Accuracy: 0.9828
Overfitting: 0.0521
Best model saved at epoch 3 with validation loss: 0.0551
[Epoch 4, Batch 100] loss: 0.04041237798053771
[Epoch 4, Batch 200] loss: 0.04395465088775381
[Epoch 4, Batch 300] loss: 0.03226600000518374
[Epoch 4, Batch 400] loss: 0.043089058506302534
[Epoch 4, Batch 500] loss: 0.03345917467959225
[Epoch 4, Batch 600] loss: 0.03347073803422972
[Epoch 4, Batch 700] loss: 0.04115148734650575
**STATS for Epoch 4** : 
Average training loss: 0.0025
Average validation loss: 0.0507
Validation Accuracy: 0.9841
Overfitting: 0.0481
Best model saved at epoch 4 with validation loss: 0.0507
[Epoch 5, Batch 100] loss: 0.028451667927438393
[Epoch 5, Batch 200] loss: 0.030642611284274607
[Epoch 5, Batch 300] loss: 0.028479305617220233
[Epoch 5, Batch 400] loss: 0.028655645770195404
[Epoch 5, Batch 500] loss: 0.03514911609352566
[Epoch 5, Batch 600] loss: 0.028292631605872885
[Epoch 5, Batch 700] loss: 0.03710619188699638
**STATS for Epoch 5** : 
Average training loss: 0.0023
Average validation loss: 0.0551
Validation Accuracy: 0.9840
Overfitting: 0.0527
[Epoch 6, Batch 100] loss: 0.0241345326625742
[Epoch 6, Batch 200] loss: 0.020489032214973123
[Epoch 6, Batch 300] loss: 0.028092564019025303
[Epoch 6, Batch 400] loss: 0.02762354076723568
[Epoch 6, Batch 500] loss: 0.028277108571783175
[Epoch 6, Batch 600] loss: 0.03004740557866171
[Epoch 6, Batch 700] loss: 0.01913024016917916
**STATS for Epoch 6** : 
Average training loss: 0.0018
Average validation loss: 0.0531
Validation Accuracy: 0.9855
Overfitting: 0.0513
[Epoch 7, Batch 100] loss: 0.01959545712947147
[Epoch 7, Batch 200] loss: 0.02641343407420209
[Epoch 7, Batch 300] loss: 0.01688497853319859
[Epoch 7, Batch 400] loss: 0.01867008739762241
[Epoch 7, Batch 500] loss: 0.01742491404671455
[Epoch 7, Batch 600] loss: 0.023308152971731035
[Epoch 7, Batch 700] loss: 0.030049005970795406
**STATS for Epoch 7** : 
Average training loss: 0.0020
Average validation loss: 0.0517
Validation Accuracy: 0.9853
Overfitting: 0.0497
[Epoch 8, Batch 100] loss: 0.012264535684080329
[Epoch 8, Batch 200] loss: 0.012593220250564627
[Epoch 8, Batch 300] loss: 0.014808990601013648
[Epoch 8, Batch 400] loss: 0.023486885511520086
[Epoch 8, Batch 500] loss: 0.01908048868208425
[Epoch 8, Batch 600] loss: 0.01794457782249083
[Epoch 8, Batch 700] loss: 0.020090560376120267
**STATS for Epoch 8** : 
Average training loss: 0.0011
Average validation loss: 0.0465
Validation Accuracy: 0.9876
Overfitting: 0.0454
Best model saved at epoch 8 with validation loss: 0.0465
[Epoch 9, Batch 100] loss: 0.011235236954962601
[Epoch 9, Batch 200] loss: 0.009413687582273268
[Epoch 9, Batch 300] loss: 0.02086050355064799
[Epoch 9, Batch 400] loss: 0.01717400876703323
[Epoch 9, Batch 500] loss: 0.015996333885195783
[Epoch 9, Batch 600] loss: 0.01636907956606592
[Epoch 9, Batch 700] loss: 0.012746949318898259
**STATS for Epoch 9** : 
Average training loss: 0.0015
Average validation loss: 0.0499
Validation Accuracy: 0.9862
Overfitting: 0.0484
[Epoch 10, Batch 100] loss: 0.010148703029262834
[Epoch 10, Batch 200] loss: 0.010727706867037341
[Epoch 10, Batch 300] loss: 0.008107474638563872
[Epoch 10, Batch 400] loss: 0.011050877089364803
[Epoch 10, Batch 500] loss: 0.024279009489437158
[Epoch 10, Batch 600] loss: 0.009145548207307001
[Epoch 10, Batch 700] loss: 0.007518060279435304
**STATS for Epoch 10** : 
Average training loss: 0.0008
Average validation loss: 0.0538
Validation Accuracy: 0.9862
Overfitting: 0.0530
[Epoch 11, Batch 100] loss: 0.013214086305852106
[Epoch 11, Batch 200] loss: 0.01112429066983168
[Epoch 11, Batch 300] loss: 0.00669544540814968
[Epoch 11, Batch 400] loss: 0.012445084573046187
[Epoch 11, Batch 500] loss: 0.014339384163267823
[Epoch 11, Batch 600] loss: 0.01407274740813591
[Epoch 11, Batch 700] loss: 0.016732034843480504
**STATS for Epoch 11** : 
Average training loss: 0.0008
Average validation loss: 0.0523
Validation Accuracy: 0.9866
Overfitting: 0.0515
[Epoch 12, Batch 100] loss: 0.007011293527593807
[Epoch 12, Batch 200] loss: 0.006709913365684769
[Epoch 12, Batch 300] loss: 0.008595372884556127
[Epoch 12, Batch 400] loss: 0.010888042818514805
[Epoch 12, Batch 500] loss: 0.01107778543004315
[Epoch 12, Batch 600] loss: 0.006478828005238029
[Epoch 12, Batch 700] loss: 0.00711256828821206
**STATS for Epoch 12** : 
Average training loss: 0.0006
Average validation loss: 0.0522
Validation Accuracy: 0.9873
Overfitting: 0.0516
[Epoch 13, Batch 100] loss: 0.0047258893722028
[Epoch 13, Batch 200] loss: 0.006505090914433822
[Epoch 13, Batch 300] loss: 0.0040725814682809865
[Epoch 13, Batch 400] loss: 0.004892646725820669
[Epoch 13, Batch 500] loss: 0.004713807796663332
[Epoch 13, Batch 600] loss: 0.013287242053647787
[Epoch 13, Batch 700] loss: 0.009156946330058417
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0509
Validation Accuracy: 0.9865
Overfitting: 0.0502
[Epoch 14, Batch 100] loss: 0.007264517533767503
[Epoch 14, Batch 200] loss: 0.00967227059416473
[Epoch 14, Batch 300] loss: 0.007799468976409116
[Epoch 14, Batch 400] loss: 0.005028030134053551
[Epoch 14, Batch 500] loss: 0.00421332691272255
[Epoch 14, Batch 600] loss: 0.006669751002850717
[Epoch 14, Batch 700] loss: 0.009309690942754969
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0550
Validation Accuracy: 0.9876
Overfitting: 0.0546
[Epoch 15, Batch 100] loss: 0.010232675078968896
[Epoch 15, Batch 200] loss: 0.0064723093782231445
[Epoch 15, Batch 300] loss: 0.007763568088701049
[Epoch 15, Batch 400] loss: 0.013638290657454491
[Epoch 15, Batch 500] loss: 0.01903642156690694
[Epoch 15, Batch 600] loss: 0.010777414808762842
[Epoch 15, Batch 700] loss: 0.010114353980288798
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0535
Validation Accuracy: 0.9871
Overfitting: 0.0531
[Epoch 16, Batch 100] loss: 0.002714426981710858
[Epoch 16, Batch 200] loss: 0.004572228781817103
[Epoch 16, Batch 300] loss: 0.004846336172586234
[Epoch 16, Batch 400] loss: 0.006630013369813241
[Epoch 16, Batch 500] loss: 0.002979118749144618
[Epoch 16, Batch 600] loss: 0.0060149214970806495
[Epoch 16, Batch 700] loss: 0.007302422248185394
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0701
Validation Accuracy: 0.9838
Overfitting: 0.0692
[Epoch 17, Batch 100] loss: 0.007012823741024477
[Epoch 17, Batch 200] loss: 0.0051609977812586295
[Epoch 17, Batch 300] loss: 0.0041037520147119725
[Epoch 17, Batch 400] loss: 0.007358984332986438
[Epoch 17, Batch 500] loss: 0.006264895979220455
[Epoch 17, Batch 600] loss: 0.004570222599595581
[Epoch 17, Batch 700] loss: 0.005279652667340997
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0642
Validation Accuracy: 0.9862
Overfitting: 0.0638
[Epoch 18, Batch 100] loss: 0.004068008606263902
[Epoch 18, Batch 200] loss: 0.0028973143464372697
[Epoch 18, Batch 300] loss: 0.01242967230031354
[Epoch 18, Batch 400] loss: 0.007160841215718392
[Epoch 18, Batch 500] loss: 0.014131070731139062
[Epoch 18, Batch 600] loss: 0.011174090438780695
[Epoch 18, Batch 700] loss: 0.008937186379625928
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0593
Validation Accuracy: 0.9860
Overfitting: 0.0589
[Epoch 19, Batch 100] loss: 0.004652511211315868
[Epoch 19, Batch 200] loss: 0.005388046882208073
[Epoch 19, Batch 300] loss: 0.005212402900106099
[Epoch 19, Batch 400] loss: 0.004489772949905273
[Epoch 19, Batch 500] loss: 0.0035128109490779025
[Epoch 19, Batch 600] loss: 0.00790384720505699
[Epoch 19, Batch 700] loss: 0.004953517657968405
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0572
Validation Accuracy: 0.9876
Overfitting: 0.0568
[Epoch 20, Batch 100] loss: 0.0029206936521131866
[Epoch 20, Batch 200] loss: 0.0035218330923470374
[Epoch 20, Batch 300] loss: 0.003307131559431582
[Epoch 20, Batch 400] loss: 0.0018699601760613404
[Epoch 20, Batch 500] loss: 0.004464939574290838
[Epoch 20, Batch 600] loss: 0.002807386909948946
[Epoch 20, Batch 700] loss: 0.006710596249572518
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0598
Validation Accuracy: 0.9866
Overfitting: 0.0595
[Epoch 21, Batch 100] loss: 0.004398014761754894
[Epoch 21, Batch 200] loss: 0.0029028759958464436
[Epoch 21, Batch 300] loss: 0.0005882751472518066
[Epoch 21, Batch 400] loss: 0.006228141570156822
[Epoch 21, Batch 500] loss: 0.0029269966143283454
[Epoch 21, Batch 600] loss: 0.0038156116159166233
[Epoch 21, Batch 700] loss: 0.003108347596269141
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0657
Validation Accuracy: 0.9869
Overfitting: 0.0654
[Epoch 22, Batch 100] loss: 0.003273366531529973
[Epoch 22, Batch 200] loss: 0.003693615450561083
[Epoch 22, Batch 300] loss: 0.0026697366599182713
[Epoch 22, Batch 400] loss: 0.00336735890000341
[Epoch 22, Batch 500] loss: 0.004682633619755734
[Epoch 22, Batch 600] loss: 0.005485548566294938
[Epoch 22, Batch 700] loss: 0.0027986094383140882
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0574
Validation Accuracy: 0.9886
Overfitting: 0.0572
[Epoch 23, Batch 100] loss: 0.0012947749913030293
[Epoch 23, Batch 200] loss: 0.002096726522958079
[Epoch 23, Batch 300] loss: 0.0009512718804614906
[Epoch 23, Batch 400] loss: 0.0009718322322191852
[Epoch 23, Batch 500] loss: 0.000808890079504181
[Epoch 23, Batch 600] loss: 0.003198416073586259
[Epoch 23, Batch 700] loss: 0.0013400255029728215
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0517
Validation Accuracy: 0.9897
Overfitting: 0.0517
[Epoch 24, Batch 100] loss: 0.0003624760060426979
[Epoch 24, Batch 200] loss: 0.00022773882865976703
[Epoch 24, Batch 300] loss: 0.0003162545820694618
[Epoch 24, Batch 400] loss: 0.00022291249142085688
[Epoch 24, Batch 500] loss: 0.00013482887283885247
[Epoch 24, Batch 600] loss: 0.0005350739369515623
[Epoch 24, Batch 700] loss: 0.00037408552680403775
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9895
Overfitting: 0.0548
Fold 2 validation loss: 0.0549
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 1.8273754960298538
[Epoch 1, Batch 200] loss: 0.3375250433385372
[Epoch 1, Batch 300] loss: 0.17865458231419326
[Epoch 1, Batch 400] loss: 0.1514768012613058
[Epoch 1, Batch 500] loss: 0.11553607676178217
[Epoch 1, Batch 600] loss: 0.12052632773295045
[Epoch 1, Batch 700] loss: 0.10713998466730118
**STATS for Epoch 1** : 
Average training loss: 0.0069
Average validation loss: 0.0973
Validation Accuracy: 0.9706
Overfitting: 0.0904
Best model saved at epoch 1 with validation loss: 0.0973
[Epoch 2, Batch 100] loss: 0.08165865065064282
[Epoch 2, Batch 200] loss: 0.0804243344720453
[Epoch 2, Batch 300] loss: 0.08458198085892946
[Epoch 2, Batch 400] loss: 0.06842008546926082
[Epoch 2, Batch 500] loss: 0.07323512247297913
[Epoch 2, Batch 600] loss: 0.06648764053359628
[Epoch 2, Batch 700] loss: 0.058993628812022504
**STATS for Epoch 2** : 
Average training loss: 0.0038
Average validation loss: 0.0719
Validation Accuracy: 0.9777
Overfitting: 0.0681
Best model saved at epoch 2 with validation loss: 0.0719
[Epoch 3, Batch 100] loss: 0.048222736886236815
[Epoch 3, Batch 200] loss: 0.055056385229108856
[Epoch 3, Batch 300] loss: 0.040878168211784215
[Epoch 3, Batch 400] loss: 0.05482538473908789
[Epoch 3, Batch 500] loss: 0.04514619219233282
[Epoch 3, Batch 600] loss: 0.05187241916311905
[Epoch 3, Batch 700] loss: 0.05232975762570277
**STATS for Epoch 3** : 
Average training loss: 0.0042
Average validation loss: 0.0546
Validation Accuracy: 0.9830
Overfitting: 0.0504
Best model saved at epoch 3 with validation loss: 0.0546
[Epoch 4, Batch 100] loss: 0.03825905158795649
[Epoch 4, Batch 200] loss: 0.03600984166143462
[Epoch 4, Batch 300] loss: 0.04139379609609023
[Epoch 4, Batch 400] loss: 0.04412212744355202
[Epoch 4, Batch 500] loss: 0.03600778503227048
[Epoch 4, Batch 600] loss: 0.036670015163253994
[Epoch 4, Batch 700] loss: 0.029560652768122964
**STATS for Epoch 4** : 
Average training loss: 0.0022
Average validation loss: 0.0608
Validation Accuracy: 0.9815
Overfitting: 0.0586
[Epoch 5, Batch 100] loss: 0.030265277152648196
[Epoch 5, Batch 200] loss: 0.031712725854013114
[Epoch 5, Batch 300] loss: 0.03500700158532709
[Epoch 5, Batch 400] loss: 0.03051522350724554
[Epoch 5, Batch 500] loss: 0.037231549976277166
[Epoch 5, Batch 600] loss: 0.031275973038282244
[Epoch 5, Batch 700] loss: 0.02967309584550094
**STATS for Epoch 5** : 
Average training loss: 0.0025
Average validation loss: 0.0519
Validation Accuracy: 0.9850
Overfitting: 0.0494
Best model saved at epoch 5 with validation loss: 0.0519
[Epoch 6, Batch 100] loss: 0.02305480335635366
[Epoch 6, Batch 200] loss: 0.02467576757480856
[Epoch 6, Batch 300] loss: 0.02436578671913594
[Epoch 6, Batch 400] loss: 0.02799125983437989
[Epoch 6, Batch 500] loss: 0.02934278043161612
[Epoch 6, Batch 600] loss: 0.02974243737757206
[Epoch 6, Batch 700] loss: 0.02772156262479257
**STATS for Epoch 6** : 
Average training loss: 0.0017
Average validation loss: 0.0483
Validation Accuracy: 0.9868
Overfitting: 0.0467
Best model saved at epoch 6 with validation loss: 0.0483
[Epoch 7, Batch 100] loss: 0.020184147054096685
[Epoch 7, Batch 200] loss: 0.015828855806030332
[Epoch 7, Batch 300] loss: 0.0187770374835236
[Epoch 7, Batch 400] loss: 0.024952054487075655
[Epoch 7, Batch 500] loss: 0.02135797113645822
[Epoch 7, Batch 600] loss: 0.023884168291988316
[Epoch 7, Batch 700] loss: 0.02318418009323068
**STATS for Epoch 7** : 
Average training loss: 0.0011
Average validation loss: 0.0503
Validation Accuracy: 0.9865
Overfitting: 0.0492
[Epoch 8, Batch 100] loss: 0.017334075817489067
[Epoch 8, Batch 200] loss: 0.015083673731278396
[Epoch 8, Batch 300] loss: 0.019667186079605017
[Epoch 8, Batch 400] loss: 0.015071592067542952
[Epoch 8, Batch 500] loss: 0.01769551164325094
[Epoch 8, Batch 600] loss: 0.013815222163684667
[Epoch 8, Batch 700] loss: 0.01985820770729333
**STATS for Epoch 8** : 
Average training loss: 0.0018
Average validation loss: 0.0473
Validation Accuracy: 0.9872
Overfitting: 0.0455
Best model saved at epoch 8 with validation loss: 0.0473
[Epoch 9, Batch 100] loss: 0.009701537259388715
[Epoch 9, Batch 200] loss: 0.013842267634609016
[Epoch 9, Batch 300] loss: 0.014792061994885444
[Epoch 9, Batch 400] loss: 0.009808401945010701
[Epoch 9, Batch 500] loss: 0.01586384699548944
[Epoch 9, Batch 600] loss: 0.017152275240950986
[Epoch 9, Batch 700] loss: 0.015637618429900614
**STATS for Epoch 9** : 
Average training loss: 0.0015
Average validation loss: 0.0509
Validation Accuracy: 0.9863
Overfitting: 0.0495
[Epoch 10, Batch 100] loss: 0.01073119707769365
[Epoch 10, Batch 200] loss: 0.007012349221040495
[Epoch 10, Batch 300] loss: 0.012792319086875068
[Epoch 10, Batch 400] loss: 0.011791846364794766
[Epoch 10, Batch 500] loss: 0.013673269391074428
[Epoch 10, Batch 600] loss: 0.014980973531055496
[Epoch 10, Batch 700] loss: 0.014926170515536796
**STATS for Epoch 10** : 
Average training loss: 0.0011
Average validation loss: 0.0569
Validation Accuracy: 0.9851
Overfitting: 0.0557
[Epoch 11, Batch 100] loss: 0.010320411971624708
[Epoch 11, Batch 200] loss: 0.010821925284253665
[Epoch 11, Batch 300] loss: 0.011531876776134596
[Epoch 11, Batch 400] loss: 0.010499098466534634
[Epoch 11, Batch 500] loss: 0.011962716955204088
[Epoch 11, Batch 600] loss: 0.013454641047574115
[Epoch 11, Batch 700] loss: 0.015464665538274858
**STATS for Epoch 11** : 
Average training loss: 0.0006
Average validation loss: 0.0509
Validation Accuracy: 0.9878
Overfitting: 0.0502
[Epoch 12, Batch 100] loss: 0.009444477207161982
[Epoch 12, Batch 200] loss: 0.006689478109983611
[Epoch 12, Batch 300] loss: 0.016478040518486524
[Epoch 12, Batch 400] loss: 0.01487470852487604
[Epoch 12, Batch 500] loss: 0.014714143958899513
[Epoch 12, Batch 600] loss: 0.006982429902054718
[Epoch 12, Batch 700] loss: 0.010877656513330294
**STATS for Epoch 12** : 
Average training loss: 0.0005
Average validation loss: 0.0460
Validation Accuracy: 0.9887
Overfitting: 0.0455
Best model saved at epoch 12 with validation loss: 0.0460
[Epoch 13, Batch 100] loss: 0.00710610660527891
[Epoch 13, Batch 200] loss: 0.007754961224636645
[Epoch 13, Batch 300] loss: 0.0029888543402375946
[Epoch 13, Batch 400] loss: 0.007484408087766497
[Epoch 13, Batch 500] loss: 0.007583971407239005
[Epoch 13, Batch 600] loss: 0.0060347208432540355
[Epoch 13, Batch 700] loss: 0.006715194575390342
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0606
Validation Accuracy: 0.9860
Overfitting: 0.0596
[Epoch 14, Batch 100] loss: 0.0067617663187957075
[Epoch 14, Batch 200] loss: 0.007257752277437249
[Epoch 14, Batch 300] loss: 0.005408354752944433
[Epoch 14, Batch 400] loss: 0.007225597491342341
[Epoch 14, Batch 500] loss: 0.006218687904265607
[Epoch 14, Batch 600] loss: 0.007104763913775969
[Epoch 14, Batch 700] loss: 0.01032396304156009
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0870
Validation Accuracy: 0.9814
Overfitting: 0.0861
[Epoch 15, Batch 100] loss: 0.01045719125395408
[Epoch 15, Batch 200] loss: 0.004500954335489951
[Epoch 15, Batch 300] loss: 0.004773347724931227
[Epoch 15, Batch 400] loss: 0.006993756022102389
[Epoch 15, Batch 500] loss: 0.006484654090691037
[Epoch 15, Batch 600] loss: 0.00906562214693622
[Epoch 15, Batch 700] loss: 0.0067884512355794865
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0637
Validation Accuracy: 0.9865
Overfitting: 0.0628
[Epoch 16, Batch 100] loss: 0.010675161571411991
[Epoch 16, Batch 200] loss: 0.007294719980286572
[Epoch 16, Batch 300] loss: 0.00645214074622345
[Epoch 16, Batch 400] loss: 0.013321118030144135
[Epoch 16, Batch 500] loss: 0.006122416554389929
[Epoch 16, Batch 600] loss: 0.006297152464617284
[Epoch 16, Batch 700] loss: 0.009286259384789447
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0630
Validation Accuracy: 0.9863
Overfitting: 0.0622
[Epoch 17, Batch 100] loss: 0.007769515687291459
[Epoch 17, Batch 200] loss: 0.00405274357511189
[Epoch 17, Batch 300] loss: 0.0023643231328651384
[Epoch 17, Batch 400] loss: 0.009822415722796905
[Epoch 17, Batch 500] loss: 0.00757319682189518
[Epoch 17, Batch 600] loss: 0.004760927722072665
[Epoch 17, Batch 700] loss: 0.004652675977672516
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0501
Validation Accuracy: 0.9893
Overfitting: 0.0498
[Epoch 18, Batch 100] loss: 0.003830068671918525
[Epoch 18, Batch 200] loss: 0.003399308252060109
[Epoch 18, Batch 300] loss: 0.0027200873226775
[Epoch 18, Batch 400] loss: 0.0030637616368699126
[Epoch 18, Batch 500] loss: 0.006419767459333343
[Epoch 18, Batch 600] loss: 0.005957487125988337
[Epoch 18, Batch 700] loss: 0.006742478278601994
**STATS for Epoch 18** : 
Average training loss: 0.0017
Average validation loss: 0.0884
Validation Accuracy: 0.9795
Overfitting: 0.0867
[Epoch 19, Batch 100] loss: 0.008997407384849793
[Epoch 19, Batch 200] loss: 0.0075421654245383255
[Epoch 19, Batch 300] loss: 0.004069238728689016
[Epoch 19, Batch 400] loss: 0.004839533291196858
[Epoch 19, Batch 500] loss: 0.00429022232281568
[Epoch 19, Batch 600] loss: 0.004016420043614062
[Epoch 19, Batch 700] loss: 0.0032823149068099155
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0544
Validation Accuracy: 0.9897
Overfitting: 0.0542
[Epoch 20, Batch 100] loss: 0.0005849582471626035
[Epoch 20, Batch 200] loss: 0.0009474793166737072
[Epoch 20, Batch 300] loss: 0.001324735166770097
[Epoch 20, Batch 400] loss: 0.001321493398563689
[Epoch 20, Batch 500] loss: 0.0032325786813999003
[Epoch 20, Batch 600] loss: 0.0015719669577526929
[Epoch 20, Batch 700] loss: 0.0016610537728411145
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9892
Overfitting: 0.0541
[Epoch 21, Batch 100] loss: 0.0013759980664440263
[Epoch 21, Batch 200] loss: 0.0006094417167793153
[Epoch 21, Batch 300] loss: 0.0005660421652089553
[Epoch 21, Batch 400] loss: 0.00028737706970275665
[Epoch 21, Batch 500] loss: 0.0007868305146126886
[Epoch 21, Batch 600] loss: 0.000525821196388705
[Epoch 21, Batch 700] loss: 0.0007735201039258755
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0607
Validation Accuracy: 0.9888
Overfitting: 0.0604
[Epoch 22, Batch 100] loss: 0.005447248114971898
[Epoch 22, Batch 200] loss: 0.002078728674032391
[Epoch 22, Batch 300] loss: 0.00064042618822441
[Epoch 22, Batch 400] loss: 0.0003670938699306703
[Epoch 22, Batch 500] loss: 0.0002971599336532904
[Epoch 22, Batch 600] loss: 0.0006347868943001344
[Epoch 22, Batch 700] loss: 0.000664818453353746
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0566
Validation Accuracy: 0.9898
Overfitting: 0.0566
[Epoch 23, Batch 100] loss: 0.0003518045048679141
[Epoch 23, Batch 200] loss: 0.0005175156550558313
[Epoch 23, Batch 300] loss: 0.00020247064966952166
[Epoch 23, Batch 400] loss: 0.00014634503220577243
[Epoch 23, Batch 500] loss: 0.00011659063249680913
[Epoch 23, Batch 600] loss: 0.0004649272064526144
[Epoch 23, Batch 700] loss: 0.000111077206225616
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9898
Overfitting: 0.0551
[Epoch 24, Batch 100] loss: 0.00012437448428158858
[Epoch 24, Batch 200] loss: 0.00024737596120587567
[Epoch 24, Batch 300] loss: 0.00024077668808445197
[Epoch 24, Batch 400] loss: 0.00014860100516912668
[Epoch 24, Batch 500] loss: 0.0001299593601859783
[Epoch 24, Batch 600] loss: 0.0001406941961352004
[Epoch 24, Batch 700] loss: 7.966574753268674e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0572
Validation Accuracy: 0.9898
Overfitting: 0.0572
Fold 3 validation loss: 0.0572
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.505132275223732
[Epoch 1, Batch 200] loss: 0.3045608455687761
[Epoch 1, Batch 300] loss: 0.20848378363996745
[Epoch 1, Batch 400] loss: 0.1529938670992851
[Epoch 1, Batch 500] loss: 0.12588527778163552
[Epoch 1, Batch 600] loss: 0.11458382246084511
[Epoch 1, Batch 700] loss: 0.09628062078729271
**STATS for Epoch 1** : 
Average training loss: 0.0059
Average validation loss: 0.1093
Validation Accuracy: 0.9673
Overfitting: 0.1034
Best model saved at epoch 1 with validation loss: 0.1093
[Epoch 2, Batch 100] loss: 0.0896829621726647
[Epoch 2, Batch 200] loss: 0.0712386635504663
[Epoch 2, Batch 300] loss: 0.07089382287114859
[Epoch 2, Batch 400] loss: 0.07569706676527858
[Epoch 2, Batch 500] loss: 0.06981271835044027
[Epoch 2, Batch 600] loss: 0.07075351936277002
[Epoch 2, Batch 700] loss: 0.05231225337134674
**STATS for Epoch 2** : 
Average training loss: 0.0042
Average validation loss: 0.0642
Validation Accuracy: 0.9802
Overfitting: 0.0599
Best model saved at epoch 2 with validation loss: 0.0642
[Epoch 3, Batch 100] loss: 0.05073986315634102
[Epoch 3, Batch 200] loss: 0.04540512611856684
[Epoch 3, Batch 300] loss: 0.05521402426995337
[Epoch 3, Batch 400] loss: 0.0471456007193774
[Epoch 3, Batch 500] loss: 0.0480064047803171
[Epoch 3, Batch 600] loss: 0.04296804629964754
[Epoch 3, Batch 700] loss: 0.05548300732392818
**STATS for Epoch 3** : 
Average training loss: 0.0032
Average validation loss: 0.0542
Validation Accuracy: 0.9829
Overfitting: 0.0511
Best model saved at epoch 3 with validation loss: 0.0542
[Epoch 4, Batch 100] loss: 0.03051224275492132
[Epoch 4, Batch 200] loss: 0.036124795110663396
[Epoch 4, Batch 300] loss: 0.04146512887557037
[Epoch 4, Batch 400] loss: 0.04096182439127006
[Epoch 4, Batch 500] loss: 0.03277663748740452
[Epoch 4, Batch 600] loss: 0.03856677420902997
[Epoch 4, Batch 700] loss: 0.041157101058633995
**STATS for Epoch 4** : 
Average training loss: 0.0027
Average validation loss: 0.0509
Validation Accuracy: 0.9856
Overfitting: 0.0482
Best model saved at epoch 4 with validation loss: 0.0509
[Epoch 5, Batch 100] loss: 0.02338144065171946
[Epoch 5, Batch 200] loss: 0.03393558797542937
[Epoch 5, Batch 300] loss: 0.026704691281192936
[Epoch 5, Batch 400] loss: 0.028817453209776432
[Epoch 5, Batch 500] loss: 0.031251247496984436
[Epoch 5, Batch 600] loss: 0.03478375772596337
[Epoch 5, Batch 700] loss: 0.03707396077108569
**STATS for Epoch 5** : 
Average training loss: 0.0024
Average validation loss: 0.0409
Validation Accuracy: 0.9869
Overfitting: 0.0385
Best model saved at epoch 5 with validation loss: 0.0409
[Epoch 6, Batch 100] loss: 0.026654575076536277
[Epoch 6, Batch 200] loss: 0.02190219148003962
[Epoch 6, Batch 300] loss: 0.027125074946670793
[Epoch 6, Batch 400] loss: 0.019852062587742695
[Epoch 6, Batch 500] loss: 0.03115942960313987
[Epoch 6, Batch 600] loss: 0.024258465913007968
[Epoch 6, Batch 700] loss: 0.025832819295465013
**STATS for Epoch 6** : 
Average training loss: 0.0019
Average validation loss: 0.0433
Validation Accuracy: 0.9874
Overfitting: 0.0414
[Epoch 7, Batch 100] loss: 0.016138300511665874
[Epoch 7, Batch 200] loss: 0.01642679274744296
[Epoch 7, Batch 300] loss: 0.019075935685687
[Epoch 7, Batch 400] loss: 0.02493814443703741
[Epoch 7, Batch 500] loss: 0.0175234236754477
[Epoch 7, Batch 600] loss: 0.020369752091137342
[Epoch 7, Batch 700] loss: 0.0193959491464193
**STATS for Epoch 7** : 
Average training loss: 0.0015
Average validation loss: 0.0449
Validation Accuracy: 0.9842
Overfitting: 0.0434
[Epoch 8, Batch 100] loss: 0.015209417105797911
[Epoch 8, Batch 200] loss: 0.017650726157153258
[Epoch 8, Batch 300] loss: 0.020635271980572724
[Epoch 8, Batch 400] loss: 0.013554811079520732
[Epoch 8, Batch 500] loss: 0.02677725190689671
[Epoch 8, Batch 600] loss: 0.013615249654394574
[Epoch 8, Batch 700] loss: 0.014799910167057532
**STATS for Epoch 8** : 
Average training loss: 0.0011
Average validation loss: 0.0406
Validation Accuracy: 0.9887
Overfitting: 0.0395
Best model saved at epoch 8 with validation loss: 0.0406
[Epoch 9, Batch 100] loss: 0.013440065233735367
[Epoch 9, Batch 200] loss: 0.01099841781957366
[Epoch 9, Batch 300] loss: 0.007672919410833856
[Epoch 9, Batch 400] loss: 0.016147068019927248
[Epoch 9, Batch 500] loss: 0.014192955074977363
[Epoch 9, Batch 600] loss: 0.014863469984011318
[Epoch 9, Batch 700] loss: 0.01880132725535077
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0519
Validation Accuracy: 0.9852
Overfitting: 0.0504
[Epoch 10, Batch 100] loss: 0.016377491611638106
[Epoch 10, Batch 200] loss: 0.00960215077153407
[Epoch 10, Batch 300] loss: 0.005665068727685138
[Epoch 10, Batch 400] loss: 0.008762557550035126
[Epoch 10, Batch 500] loss: 0.010154163486076869
[Epoch 10, Batch 600] loss: 0.00874098332329595
[Epoch 10, Batch 700] loss: 0.01327068232552847
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0619
Validation Accuracy: 0.9852
Overfitting: 0.0607
[Epoch 11, Batch 100] loss: 0.0069791884817095706
[Epoch 11, Batch 200] loss: 0.005899015090108151
[Epoch 11, Batch 300] loss: 0.007726544280521921
[Epoch 11, Batch 400] loss: 0.011193057349155424
[Epoch 11, Batch 500] loss: 0.011892495033025625
[Epoch 11, Batch 600] loss: 0.011425247842344105
[Epoch 11, Batch 700] loss: 0.014559342542124796
**STATS for Epoch 11** : 
Average training loss: 0.0007
Average validation loss: 0.0485
Validation Accuracy: 0.9885
Overfitting: 0.0478
[Epoch 12, Batch 100] loss: 0.006244125837511092
[Epoch 12, Batch 200] loss: 0.006609975873252552
[Epoch 12, Batch 300] loss: 0.011131927350397745
[Epoch 12, Batch 400] loss: 0.008853163833337022
[Epoch 12, Batch 500] loss: 0.007545435855572578
[Epoch 12, Batch 600] loss: 0.003967133481855853
[Epoch 12, Batch 700] loss: 0.00484116300358437
**STATS for Epoch 12** : 
Average training loss: 0.0004
Average validation loss: 0.0414
Validation Accuracy: 0.9897
Overfitting: 0.0410
[Epoch 13, Batch 100] loss: 0.00593414855949959
[Epoch 13, Batch 200] loss: 0.005845470188814943
[Epoch 13, Batch 300] loss: 0.007767699444825666
[Epoch 13, Batch 400] loss: 0.00772972731563641
[Epoch 13, Batch 500] loss: 0.006900392467587153
[Epoch 13, Batch 600] loss: 0.007278408880993083
[Epoch 13, Batch 700] loss: 0.010562751373254287
**STATS for Epoch 13** : 
Average training loss: 0.0003
Average validation loss: 0.0401
Validation Accuracy: 0.9903
Overfitting: 0.0398
Best model saved at epoch 13 with validation loss: 0.0401
[Epoch 14, Batch 100] loss: 0.006073520165455193
[Epoch 14, Batch 200] loss: 0.004909763645464409
[Epoch 14, Batch 300] loss: 0.006941591308029729
[Epoch 14, Batch 400] loss: 0.006605088579985932
[Epoch 14, Batch 500] loss: 0.00873129863630311
[Epoch 14, Batch 600] loss: 0.010603016384584408
[Epoch 14, Batch 700] loss: 0.01231325633081724
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0507
Validation Accuracy: 0.9874
Overfitting: 0.0500
[Epoch 15, Batch 100] loss: 0.007008762957266299
[Epoch 15, Batch 200] loss: 0.0030131886236267748
[Epoch 15, Batch 300] loss: 0.008740995990165175
[Epoch 15, Batch 400] loss: 0.004926667230429302
[Epoch 15, Batch 500] loss: 0.012701352191352272
[Epoch 15, Batch 600] loss: 0.007758314667407831
[Epoch 15, Batch 700] loss: 0.006760042576970591
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0467
Validation Accuracy: 0.9897
Overfitting: 0.0463
[Epoch 16, Batch 100] loss: 0.003250062305155552
[Epoch 16, Batch 200] loss: 0.005330956914112903
[Epoch 16, Batch 300] loss: 0.004310155901512189
[Epoch 16, Batch 400] loss: 0.004191390532632795
[Epoch 16, Batch 500] loss: 0.0037305104624647356
[Epoch 16, Batch 600] loss: 0.006356176228491677
[Epoch 16, Batch 700] loss: 0.004158256921314205
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0485
Validation Accuracy: 0.9879
Overfitting: 0.0481
[Epoch 17, Batch 100] loss: 0.003446746648305634
[Epoch 17, Batch 200] loss: 0.0026550409969649993
[Epoch 17, Batch 300] loss: 0.002357943643510225
[Epoch 17, Batch 400] loss: 0.004391413880962318
[Epoch 17, Batch 500] loss: 0.0018448236396943684
[Epoch 17, Batch 600] loss: 0.003219430945619024
[Epoch 17, Batch 700] loss: 0.002849542836938781
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0486
Validation Accuracy: 0.9888
Overfitting: 0.0482
[Epoch 18, Batch 100] loss: 0.0019448722350989555
[Epoch 18, Batch 200] loss: 0.0015478579197019827
[Epoch 18, Batch 300] loss: 0.002947154178253868
[Epoch 18, Batch 400] loss: 0.002093310261716397
[Epoch 18, Batch 500] loss: 0.0033765387658615965
[Epoch 18, Batch 600] loss: 0.0038658309172842566
[Epoch 18, Batch 700] loss: 0.001313937909174001
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0448
Validation Accuracy: 0.9899
Overfitting: 0.0446
[Epoch 19, Batch 100] loss: 0.0035601179286902608
[Epoch 19, Batch 200] loss: 0.0019278970301365916
[Epoch 19, Batch 300] loss: 0.00392617466439333
[Epoch 19, Batch 400] loss: 0.00459978908013909
[Epoch 19, Batch 500] loss: 0.002469658026006982
[Epoch 19, Batch 600] loss: 0.008245563498093134
[Epoch 19, Batch 700] loss: 0.00417945977470481
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0519
Validation Accuracy: 0.9881
Overfitting: 0.0517
[Epoch 20, Batch 100] loss: 0.0045922838434853475
[Epoch 20, Batch 200] loss: 0.0038117520369814885
[Epoch 20, Batch 300] loss: 0.007176368352811551
[Epoch 20, Batch 400] loss: 0.006437755946826655
[Epoch 20, Batch 500] loss: 0.008190721851442505
[Epoch 20, Batch 600] loss: 0.009028727534187056
[Epoch 20, Batch 700] loss: 0.010932382456057894
**STATS for Epoch 20** : 
Average training loss: 0.0007
Average validation loss: 0.0584
Validation Accuracy: 0.9876
Overfitting: 0.0576
[Epoch 21, Batch 100] loss: 0.006287373644322542
[Epoch 21, Batch 200] loss: 0.0043960411941316125
[Epoch 21, Batch 300] loss: 0.0017621848002909246
[Epoch 21, Batch 400] loss: 0.005427142983614885
[Epoch 21, Batch 500] loss: 0.008626228011819422
[Epoch 21, Batch 600] loss: 0.004004554160817406
[Epoch 21, Batch 700] loss: 0.0023087733004831536
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0511
Validation Accuracy: 0.9888
Overfitting: 0.0508
[Epoch 22, Batch 100] loss: 0.0014431447308106725
[Epoch 22, Batch 200] loss: 0.0027679622727919194
[Epoch 22, Batch 300] loss: 0.0013679282003451476
[Epoch 22, Batch 400] loss: 0.0006348748490131584
[Epoch 22, Batch 500] loss: 0.0011953752376007286
[Epoch 22, Batch 600] loss: 0.001868678264903565
[Epoch 22, Batch 700] loss: 0.0038219716718867858
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0501
Validation Accuracy: 0.9900
Overfitting: 0.0500
[Epoch 23, Batch 100] loss: 0.00041355277361816435
[Epoch 23, Batch 200] loss: 0.001257913215785038
[Epoch 23, Batch 300] loss: 0.0009958488013353417
[Epoch 23, Batch 400] loss: 0.00030882209349414325
[Epoch 23, Batch 500] loss: 0.0003399700925552907
[Epoch 23, Batch 600] loss: 0.000651354881491244
[Epoch 23, Batch 700] loss: 0.0003040290037785098
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9901
Overfitting: 0.0473
[Epoch 24, Batch 100] loss: 0.00019131392363561873
[Epoch 24, Batch 200] loss: 0.00018258101831349904
[Epoch 24, Batch 300] loss: 0.0002432347757080322
[Epoch 24, Batch 400] loss: 0.0003014448528324465
[Epoch 24, Batch 500] loss: 0.000218744167073055
[Epoch 24, Batch 600] loss: 0.00015906619001498256
[Epoch 24, Batch 700] loss: 0.00012455952699838235
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9906
Overfitting: 0.0484
Fold 4 validation loss: 0.0484
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 1.615527682006359
[Epoch 1, Batch 200] loss: 0.3240661347657442
[Epoch 1, Batch 300] loss: 0.21746679348871112
[Epoch 1, Batch 400] loss: 0.15127695713192224
[Epoch 1, Batch 500] loss: 0.1243666224181652
[Epoch 1, Batch 600] loss: 0.12698756989091634
[Epoch 1, Batch 700] loss: 0.10278817830607295
**STATS for Epoch 1** : 
Average training loss: 0.0054
Average validation loss: 0.0958
Validation Accuracy: 0.9701
Overfitting: 0.0904
Best model saved at epoch 1 with validation loss: 0.0958
[Epoch 2, Batch 100] loss: 0.07476762239821255
[Epoch 2, Batch 200] loss: 0.08506443774327636
[Epoch 2, Batch 300] loss: 0.07329919580137358
[Epoch 2, Batch 400] loss: 0.06772522161714732
[Epoch 2, Batch 500] loss: 0.06463442984619178
[Epoch 2, Batch 600] loss: 0.053124076556414365
[Epoch 2, Batch 700] loss: 0.0685375309502706
**STATS for Epoch 2** : 
Average training loss: 0.0040
Average validation loss: 0.0733
Validation Accuracy: 0.9774
Overfitting: 0.0693
Best model saved at epoch 2 with validation loss: 0.0733
[Epoch 3, Batch 100] loss: 0.0490495531167835
[Epoch 3, Batch 200] loss: 0.05025286499410868
[Epoch 3, Batch 300] loss: 0.03866031493875198
[Epoch 3, Batch 400] loss: 0.04244623300619423
[Epoch 3, Batch 500] loss: 0.050511298319324854
[Epoch 3, Batch 600] loss: 0.05912997301435098
[Epoch 3, Batch 700] loss: 0.04287830209825188
**STATS for Epoch 3** : 
Average training loss: 0.0037
Average validation loss: 0.0584
Validation Accuracy: 0.9825
Overfitting: 0.0546
Best model saved at epoch 3 with validation loss: 0.0584
[Epoch 4, Batch 100] loss: 0.036452564273495226
[Epoch 4, Batch 200] loss: 0.0358173516811803
[Epoch 4, Batch 300] loss: 0.03771456909889821
[Epoch 4, Batch 400] loss: 0.03380536483076867
[Epoch 4, Batch 500] loss: 0.04198905844939873
[Epoch 4, Batch 600] loss: 0.037880590913118795
[Epoch 4, Batch 700] loss: 0.039431180706014854
**STATS for Epoch 4** : 
Average training loss: 0.0025
Average validation loss: 0.0428
Validation Accuracy: 0.9868
Overfitting: 0.0403
Best model saved at epoch 4 with validation loss: 0.0428
[Epoch 5, Batch 100] loss: 0.032481751751620325
[Epoch 5, Batch 200] loss: 0.027943142637377606
[Epoch 5, Batch 300] loss: 0.03878612739033997
[Epoch 5, Batch 400] loss: 0.03295438259257935
[Epoch 5, Batch 500] loss: 0.026969888111052567
[Epoch 5, Batch 600] loss: 0.03164293268520851
[Epoch 5, Batch 700] loss: 0.023167552464874463
**STATS for Epoch 5** : 
Average training loss: 0.0026
Average validation loss: 0.0452
Validation Accuracy: 0.9865
Overfitting: 0.0426
[Epoch 6, Batch 100] loss: 0.026008986130473203
[Epoch 6, Batch 200] loss: 0.020996416328125635
[Epoch 6, Batch 300] loss: 0.02425190767593449
[Epoch 6, Batch 400] loss: 0.02763858074657037
[Epoch 6, Batch 500] loss: 0.027805319683393462
[Epoch 6, Batch 600] loss: 0.024910668600932696
[Epoch 6, Batch 700] loss: 0.02695963993843179
**STATS for Epoch 6** : 
Average training loss: 0.0015
Average validation loss: 0.0401
Validation Accuracy: 0.9883
Overfitting: 0.0386
Best model saved at epoch 6 with validation loss: 0.0401
[Epoch 7, Batch 100] loss: 0.017597712335700635
[Epoch 7, Batch 200] loss: 0.012610358165838989
[Epoch 7, Batch 300] loss: 0.022321059329260606
[Epoch 7, Batch 400] loss: 0.014383222459291573
[Epoch 7, Batch 500] loss: 0.02694390150223626
[Epoch 7, Batch 600] loss: 0.022449407130188774
[Epoch 7, Batch 700] loss: 0.018105280648596817
**STATS for Epoch 7** : 
Average training loss: 0.0013
Average validation loss: 0.0429
Validation Accuracy: 0.9875
Overfitting: 0.0416
[Epoch 8, Batch 100] loss: 0.013459555845583964
[Epoch 8, Batch 200] loss: 0.016102292466530343
[Epoch 8, Batch 300] loss: 0.018885097508027682
[Epoch 8, Batch 400] loss: 0.020423192689777353
[Epoch 8, Batch 500] loss: 0.015704324528924188
[Epoch 8, Batch 600] loss: 0.01696629970218055
[Epoch 8, Batch 700] loss: 0.014905644807731733
**STATS for Epoch 8** : 
Average training loss: 0.0015
Average validation loss: 0.0514
Validation Accuracy: 0.9848
Overfitting: 0.0499
[Epoch 9, Batch 100] loss: 0.010615204238856677
[Epoch 9, Batch 200] loss: 0.013415625983689096
[Epoch 9, Batch 300] loss: 0.011418819508544403
[Epoch 9, Batch 400] loss: 0.014942385061367532
[Epoch 9, Batch 500] loss: 0.013088729411829264
[Epoch 9, Batch 600] loss: 0.011406547617370961
[Epoch 9, Batch 700] loss: 0.015412383382790723
**STATS for Epoch 9** : 
Average training loss: 0.0010
Average validation loss: 0.0459
Validation Accuracy: 0.9871
Overfitting: 0.0448
[Epoch 10, Batch 100] loss: 0.014093686820488074
[Epoch 10, Batch 200] loss: 0.011566022305196384
[Epoch 10, Batch 300] loss: 0.016364141752346767
[Epoch 10, Batch 400] loss: 0.011703428441396681
[Epoch 10, Batch 500] loss: 0.011462238420390349
[Epoch 10, Batch 600] loss: 0.01268706723831201
[Epoch 10, Batch 700] loss: 0.013421911381010431
**STATS for Epoch 10** : 
Average training loss: 0.0013
Average validation loss: 0.0472
Validation Accuracy: 0.9872
Overfitting: 0.0459
[Epoch 11, Batch 100] loss: 0.009205925188507536
[Epoch 11, Batch 200] loss: 0.006428667234140448
[Epoch 11, Batch 300] loss: 0.012554465937500935
[Epoch 11, Batch 400] loss: 0.010620249625353607
[Epoch 11, Batch 500] loss: 0.009914512817304058
[Epoch 11, Batch 600] loss: 0.008573210372437643
[Epoch 11, Batch 700] loss: 0.012653542268380988
**STATS for Epoch 11** : 
Average training loss: 0.0008
Average validation loss: 0.0416
Validation Accuracy: 0.9894
Overfitting: 0.0408
[Epoch 12, Batch 100] loss: 0.008214057205950667
[Epoch 12, Batch 200] loss: 0.006524465738511936
[Epoch 12, Batch 300] loss: 0.008444560600510157
[Epoch 12, Batch 400] loss: 0.007466888973176537
[Epoch 12, Batch 500] loss: 0.00985756655318255
[Epoch 12, Batch 600] loss: 0.00803523937916907
[Epoch 12, Batch 700] loss: 0.00948273965151202
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0457
Validation Accuracy: 0.9886
Overfitting: 0.0448
[Epoch 13, Batch 100] loss: 0.004465979414890171
[Epoch 13, Batch 200] loss: 0.0036974381271284076
[Epoch 13, Batch 300] loss: 0.00493751911477375
[Epoch 13, Batch 400] loss: 0.004158217974118088
[Epoch 13, Batch 500] loss: 0.005611133065358444
[Epoch 13, Batch 600] loss: 0.006951393089220801
[Epoch 13, Batch 700] loss: 0.007128072444174904
**STATS for Epoch 13** : 
Average training loss: 0.0003
Average validation loss: 0.0394
Validation Accuracy: 0.9900
Overfitting: 0.0391
Best model saved at epoch 13 with validation loss: 0.0394
[Epoch 14, Batch 100] loss: 0.0024091930324811983
[Epoch 14, Batch 200] loss: 0.003830593582115398
[Epoch 14, Batch 300] loss: 0.0020540931981167885
[Epoch 14, Batch 400] loss: 0.0048566231200675245
[Epoch 14, Batch 500] loss: 0.0070538934768592295
[Epoch 14, Batch 600] loss: 0.007620820073279902
[Epoch 14, Batch 700] loss: 0.004669647875962255
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0499
Validation Accuracy: 0.9891
Overfitting: 0.0495
[Epoch 15, Batch 100] loss: 0.0026628325768842842
[Epoch 15, Batch 200] loss: 0.005552017294226061
[Epoch 15, Batch 300] loss: 0.007134096018935452
[Epoch 15, Batch 400] loss: 0.005544596915387956
[Epoch 15, Batch 500] loss: 0.005960918819664584
[Epoch 15, Batch 600] loss: 0.004316492304753865
[Epoch 15, Batch 700] loss: 0.004331737061966124
**STATS for Epoch 15** : 
Average training loss: 0.0001
Average validation loss: 0.0449
Validation Accuracy: 0.9898
Overfitting: 0.0448
[Epoch 16, Batch 100] loss: 0.004275307453026471
[Epoch 16, Batch 200] loss: 0.007184453989084432
[Epoch 16, Batch 300] loss: 0.003267353493693008
[Epoch 16, Batch 400] loss: 0.004133891646728216
[Epoch 16, Batch 500] loss: 0.004882033922367555
[Epoch 16, Batch 600] loss: 0.006755669563772244
[Epoch 16, Batch 700] loss: 0.007860092772098141
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0486
Validation Accuracy: 0.9888
Overfitting: 0.0482
[Epoch 17, Batch 100] loss: 0.003138075277606731
[Epoch 17, Batch 200] loss: 0.002876456191256693
[Epoch 17, Batch 300] loss: 0.0037766270685824564
[Epoch 17, Batch 400] loss: 0.004869792600570691
[Epoch 17, Batch 500] loss: 0.0035209288238547743
[Epoch 17, Batch 600] loss: 0.008788328627283591
[Epoch 17, Batch 700] loss: 0.003133681891208653
**STATS for Epoch 17** : 
Average training loss: 0.0002
Average validation loss: 0.0468
Validation Accuracy: 0.9899
Overfitting: 0.0466
[Epoch 18, Batch 100] loss: 0.002722139447232621
[Epoch 18, Batch 200] loss: 0.0027418911453969486
[Epoch 18, Batch 300] loss: 0.0022991285139664797
[Epoch 18, Batch 400] loss: 0.001576701240260263
[Epoch 18, Batch 500] loss: 0.0018216355251070126
[Epoch 18, Batch 600] loss: 0.0030282707922356165
[Epoch 18, Batch 700] loss: 0.0029656832405044044
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0514
Validation Accuracy: 0.9892
Overfitting: 0.0511
[Epoch 19, Batch 100] loss: 0.005503854967596453
[Epoch 19, Batch 200] loss: 0.005895545991561449
[Epoch 19, Batch 300] loss: 0.005494663676890923
[Epoch 19, Batch 400] loss: 0.006042556761940432
[Epoch 19, Batch 500] loss: 0.004790055703895177
[Epoch 19, Batch 600] loss: 0.004121412317981594
[Epoch 19, Batch 700] loss: 0.002745399422283299
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0459
Validation Accuracy: 0.9902
Overfitting: 0.0457
[Epoch 20, Batch 100] loss: 0.002326284626974484
[Epoch 20, Batch 200] loss: 0.0007637711015263448
[Epoch 20, Batch 300] loss: 0.0011410555702946112
[Epoch 20, Batch 400] loss: 0.002761552737614181
[Epoch 20, Batch 500] loss: 0.0015194472183793551
[Epoch 20, Batch 600] loss: 0.003490171171131351
[Epoch 20, Batch 700] loss: 0.0008422466067781897
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0465
Validation Accuracy: 0.9898
Overfitting: 0.0464
[Epoch 21, Batch 100] loss: 0.0027869865557261166
[Epoch 21, Batch 200] loss: 0.0006774997814170547
[Epoch 21, Batch 300] loss: 0.0007398002722220553
[Epoch 21, Batch 400] loss: 0.0005341277222078133
[Epoch 21, Batch 500] loss: 0.0003801095848878333
[Epoch 21, Batch 600] loss: 0.001043136323858107
[Epoch 21, Batch 700] loss: 0.002859574846827968
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0470
Validation Accuracy: 0.9902
Overfitting: 0.0470
[Epoch 22, Batch 100] loss: 0.0009927906215534677
[Epoch 22, Batch 200] loss: 0.0003732281907332435
[Epoch 22, Batch 300] loss: 0.00032794147847198474
[Epoch 22, Batch 400] loss: 0.002965768611963995
[Epoch 22, Batch 500] loss: 0.0012933884522817608
[Epoch 22, Batch 600] loss: 0.0008127777085798016
[Epoch 22, Batch 700] loss: 0.005866128389129699
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0495
Validation Accuracy: 0.9908
Overfitting: 0.0493
[Epoch 23, Batch 100] loss: 0.006830548474095508
[Epoch 23, Batch 200] loss: 0.005669415825532269
[Epoch 23, Batch 300] loss: 0.004879254040145042
[Epoch 23, Batch 400] loss: 0.004903505152792604
[Epoch 23, Batch 500] loss: 0.004488152259559683
[Epoch 23, Batch 600] loss: 0.005261294750183652
[Epoch 23, Batch 700] loss: 0.005877531483987753
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0497
Validation Accuracy: 0.9896
Overfitting: 0.0495
[Epoch 24, Batch 100] loss: 0.006553272230039511
[Epoch 24, Batch 200] loss: 0.006072603447155416
[Epoch 24, Batch 300] loss: 0.006673064448179957
[Epoch 24, Batch 400] loss: 0.008308287063119906
[Epoch 24, Batch 500] loss: 0.014122232477573106
[Epoch 24, Batch 600] loss: 0.008844775333818689
[Epoch 24, Batch 700] loss: 0.00926212556429732
**STATS for Epoch 24** : 
Average training loss: 0.0012
Average validation loss: 0.0548
Validation Accuracy: 0.9878
Overfitting: 0.0536
Fold 5 validation loss: 0.0548
Mean validation loss across all folds for Trial 20 is 0.0529 with trial config:  l1: 256, l2: 64, lr: 0.009505026151444827, batch_size: 64
[I 2024-12-11 07:21:51,700] Trial 19 finished with value: 0.05287410927065409 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.009505026151444827, 'batch_size': 64}. Best is trial 4 with value: 0.04724671796616846.

Selected Hyperparameters for Trial 21:
  l1: 256, l2: 128, lr: 0.003538174401688524, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.1014023458957674
[Epoch 1, Batch 200] loss: 0.5715619297325611
[Epoch 1, Batch 300] loss: 0.31320526629686357
**STATS for Epoch 1** : 
Average training loss: 0.0461
Average validation loss: 0.1961
Validation Accuracy: 0.9414
Overfitting: 0.1500
Best model saved at epoch 1 with validation loss: 0.1961
[Epoch 2, Batch 100] loss: 0.1879802605882287
[Epoch 2, Batch 200] loss: 0.16260450907051563
[Epoch 2, Batch 300] loss: 0.14792095988988876
**STATS for Epoch 2** : 
Average training loss: 0.0279
Average validation loss: 0.1290
Validation Accuracy: 0.9613
Overfitting: 0.1011
Best model saved at epoch 2 with validation loss: 0.1290
[Epoch 3, Batch 100] loss: 0.12030179489403964
[Epoch 3, Batch 200] loss: 0.1095173442363739
[Epoch 3, Batch 300] loss: 0.09926737103611231
**STATS for Epoch 3** : 
Average training loss: 0.0212
Average validation loss: 0.0950
Validation Accuracy: 0.9692
Overfitting: 0.0738
Best model saved at epoch 3 with validation loss: 0.0950
[Epoch 4, Batch 100] loss: 0.09795665174722672
[Epoch 4, Batch 200] loss: 0.07840473502874375
[Epoch 4, Batch 300] loss: 0.08426267920061946
**STATS for Epoch 4** : 
Average training loss: 0.0152
Average validation loss: 0.0911
Validation Accuracy: 0.9731
Overfitting: 0.0759
Best model saved at epoch 4 with validation loss: 0.0911
[Epoch 5, Batch 100] loss: 0.0707857421040535
[Epoch 5, Batch 200] loss: 0.0634690878726542
[Epoch 5, Batch 300] loss: 0.07492424935102462
**STATS for Epoch 5** : 
Average training loss: 0.0151
Average validation loss: 0.0669
Validation Accuracy: 0.9794
Overfitting: 0.0518
Best model saved at epoch 5 with validation loss: 0.0669
[Epoch 6, Batch 100] loss: 0.05644453665241599
[Epoch 6, Batch 200] loss: 0.05714537965133786
[Epoch 6, Batch 300] loss: 0.06590357228182256
**STATS for Epoch 6** : 
Average training loss: 0.0124
Average validation loss: 0.0575
Validation Accuracy: 0.9813
Overfitting: 0.0451
Best model saved at epoch 6 with validation loss: 0.0575
[Epoch 7, Batch 100] loss: 0.05270340947899967
[Epoch 7, Batch 200] loss: 0.055294688660651445
[Epoch 7, Batch 300] loss: 0.053464935831725596
**STATS for Epoch 7** : 
Average training loss: 0.0095
Average validation loss: 0.0559
Validation Accuracy: 0.9828
Overfitting: 0.0465
Best model saved at epoch 7 with validation loss: 0.0559
[Epoch 8, Batch 100] loss: 0.044729594490490854
[Epoch 8, Batch 200] loss: 0.04497213358059526
[Epoch 8, Batch 300] loss: 0.04859435893595219
**STATS for Epoch 8** : 
Average training loss: 0.0098
Average validation loss: 0.0538
Validation Accuracy: 0.9835
Overfitting: 0.0440
Best model saved at epoch 8 with validation loss: 0.0538
[Epoch 9, Batch 100] loss: 0.04163471003063023
[Epoch 9, Batch 200] loss: 0.04350908800493926
[Epoch 9, Batch 300] loss: 0.03993670897558332
**STATS for Epoch 9** : 
Average training loss: 0.0088
Average validation loss: 0.0538
Validation Accuracy: 0.9838
Overfitting: 0.0450
[Epoch 10, Batch 100] loss: 0.03749051915016025
[Epoch 10, Batch 200] loss: 0.037758204475976526
[Epoch 10, Batch 300] loss: 0.037118137115612626
**STATS for Epoch 10** : 
Average training loss: 0.0070
Average validation loss: 0.0483
Validation Accuracy: 0.9845
Overfitting: 0.0413
Best model saved at epoch 10 with validation loss: 0.0483
[Epoch 11, Batch 100] loss: 0.031072981476318092
[Epoch 11, Batch 200] loss: 0.032334164762869474
[Epoch 11, Batch 300] loss: 0.036910048946738244
**STATS for Epoch 11** : 
Average training loss: 0.0072
Average validation loss: 0.0472
Validation Accuracy: 0.9845
Overfitting: 0.0400
Best model saved at epoch 11 with validation loss: 0.0472
[Epoch 12, Batch 100] loss: 0.030046878543216735
[Epoch 12, Batch 200] loss: 0.03118516867980361
[Epoch 12, Batch 300] loss: 0.02966993585927412
**STATS for Epoch 12** : 
Average training loss: 0.0068
Average validation loss: 0.0485
Validation Accuracy: 0.9844
Overfitting: 0.0417
[Epoch 13, Batch 100] loss: 0.024898005451541395
[Epoch 13, Batch 200] loss: 0.031245065643452107
[Epoch 13, Batch 300] loss: 0.03023202886339277
**STATS for Epoch 13** : 
Average training loss: 0.0051
Average validation loss: 0.0459
Validation Accuracy: 0.9863
Overfitting: 0.0408
Best model saved at epoch 13 with validation loss: 0.0459
[Epoch 14, Batch 100] loss: 0.021741444929502904
[Epoch 14, Batch 200] loss: 0.024102406559977682
[Epoch 14, Batch 300] loss: 0.030334025411866604
**STATS for Epoch 14** : 
Average training loss: 0.0048
Average validation loss: 0.0471
Validation Accuracy: 0.9851
Overfitting: 0.0423
[Epoch 15, Batch 100] loss: 0.02469974781619385
[Epoch 15, Batch 200] loss: 0.02449194237589836
[Epoch 15, Batch 300] loss: 0.024974577005486935
**STATS for Epoch 15** : 
Average training loss: 0.0047
Average validation loss: 0.0434
Validation Accuracy: 0.9861
Overfitting: 0.0387
Best model saved at epoch 15 with validation loss: 0.0434
[Epoch 16, Batch 100] loss: 0.01836991551099345
[Epoch 16, Batch 200] loss: 0.022533341584494337
[Epoch 16, Batch 300] loss: 0.02000960684614256
**STATS for Epoch 16** : 
Average training loss: 0.0043
Average validation loss: 0.0474
Validation Accuracy: 0.9858
Overfitting: 0.0431
[Epoch 17, Batch 100] loss: 0.01724424328538589
[Epoch 17, Batch 200] loss: 0.018176161982119084
[Epoch 17, Batch 300] loss: 0.018355484792846256
**STATS for Epoch 17** : 
Average training loss: 0.0041
Average validation loss: 0.0453
Validation Accuracy: 0.9864
Overfitting: 0.0412
[Epoch 18, Batch 100] loss: 0.01563689161208458
[Epoch 18, Batch 200] loss: 0.017482050613034518
[Epoch 18, Batch 300] loss: 0.020432618972845377
**STATS for Epoch 18** : 
Average training loss: 0.0038
Average validation loss: 0.0461
Validation Accuracy: 0.9865
Overfitting: 0.0424
[Epoch 19, Batch 100] loss: 0.013840649870689958
[Epoch 19, Batch 200] loss: 0.014738498162478209
[Epoch 19, Batch 300] loss: 0.016476417070953174
**STATS for Epoch 19** : 
Average training loss: 0.0036
Average validation loss: 0.0448
Validation Accuracy: 0.9867
Overfitting: 0.0412
[Epoch 20, Batch 100] loss: 0.014590561597724445
[Epoch 20, Batch 200] loss: 0.013424509065807798
[Epoch 20, Batch 300] loss: 0.013220376478275285
**STATS for Epoch 20** : 
Average training loss: 0.0031
Average validation loss: 0.0465
Validation Accuracy: 0.9863
Overfitting: 0.0435
[Epoch 21, Batch 100] loss: 0.01121806590759661
[Epoch 21, Batch 200] loss: 0.00984942652285099
[Epoch 21, Batch 300] loss: 0.013135071481810883
**STATS for Epoch 21** : 
Average training loss: 0.0023
Average validation loss: 0.0441
Validation Accuracy: 0.9878
Overfitting: 0.0418
[Epoch 22, Batch 100] loss: 0.00973607108608121
[Epoch 22, Batch 200] loss: 0.01138414230401395
[Epoch 22, Batch 300] loss: 0.013645283002988435
**STATS for Epoch 22** : 
Average training loss: 0.0023
Average validation loss: 0.0453
Validation Accuracy: 0.9872
Overfitting: 0.0430
[Epoch 23, Batch 100] loss: 0.00824252932012314
[Epoch 23, Batch 200] loss: 0.011177518046170008
[Epoch 23, Batch 300] loss: 0.012384907063096761
**STATS for Epoch 23** : 
Average training loss: 0.0023
Average validation loss: 0.0448
Validation Accuracy: 0.9867
Overfitting: 0.0424
[Epoch 24, Batch 100] loss: 0.008637558555346914
[Epoch 24, Batch 200] loss: 0.008544094294193201
[Epoch 24, Batch 300] loss: 0.01064566869463306
**STATS for Epoch 24** : 
Average training loss: 0.0021
Average validation loss: 0.0488
Validation Accuracy: 0.9869
Overfitting: 0.0468
Fold 1 validation loss: 0.0488
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2430193328857424
[Epoch 1, Batch 200] loss: 0.8641489350795746
[Epoch 1, Batch 300] loss: 0.3301906529068947
**STATS for Epoch 1** : 
Average training loss: 0.0466
Average validation loss: 0.2328
Validation Accuracy: 0.9311
Overfitting: 0.1863
Best model saved at epoch 1 with validation loss: 0.2328
[Epoch 2, Batch 100] loss: 0.20466338634490966
[Epoch 2, Batch 200] loss: 0.17474079929292202
[Epoch 2, Batch 300] loss: 0.14127063501626252
**STATS for Epoch 2** : 
Average training loss: 0.0252
Average validation loss: 0.1347
Validation Accuracy: 0.9570
Overfitting: 0.1095
Best model saved at epoch 2 with validation loss: 0.1347
[Epoch 3, Batch 100] loss: 0.11490710005164147
[Epoch 3, Batch 200] loss: 0.11358042748644948
[Epoch 3, Batch 300] loss: 0.10595254538580776
**STATS for Epoch 3** : 
Average training loss: 0.0191
Average validation loss: 0.1098
Validation Accuracy: 0.9665
Overfitting: 0.0907
Best model saved at epoch 3 with validation loss: 0.1098
[Epoch 4, Batch 100] loss: 0.08701292525976896
[Epoch 4, Batch 200] loss: 0.08348676696419716
[Epoch 4, Batch 300] loss: 0.0941662074252963
**STATS for Epoch 4** : 
Average training loss: 0.0154
Average validation loss: 0.1100
Validation Accuracy: 0.9650
Overfitting: 0.0946
[Epoch 5, Batch 100] loss: 0.07580147651955485
[Epoch 5, Batch 200] loss: 0.0746719234250486
[Epoch 5, Batch 300] loss: 0.06971053726971149
**STATS for Epoch 5** : 
Average training loss: 0.0132
Average validation loss: 0.0912
Validation Accuracy: 0.9726
Overfitting: 0.0781
Best model saved at epoch 5 with validation loss: 0.0912
[Epoch 6, Batch 100] loss: 0.06568257777951658
[Epoch 6, Batch 200] loss: 0.060267149209976195
[Epoch 6, Batch 300] loss: 0.056683051139116286
**STATS for Epoch 6** : 
Average training loss: 0.0113
Average validation loss: 0.0728
Validation Accuracy: 0.9783
Overfitting: 0.0615
Best model saved at epoch 6 with validation loss: 0.0728
[Epoch 7, Batch 100] loss: 0.057444819984957575
[Epoch 7, Batch 200] loss: 0.04861022983212024
[Epoch 7, Batch 300] loss: 0.05032422941178084
**STATS for Epoch 7** : 
Average training loss: 0.0110
Average validation loss: 0.0714
Validation Accuracy: 0.9782
Overfitting: 0.0603
Best model saved at epoch 7 with validation loss: 0.0714
[Epoch 8, Batch 100] loss: 0.04615714400075376
[Epoch 8, Batch 200] loss: 0.04614040046930313
[Epoch 8, Batch 300] loss: 0.04669785190373659
**STATS for Epoch 8** : 
Average training loss: 0.0120
Average validation loss: 0.0679
Validation Accuracy: 0.9797
Overfitting: 0.0559
Best model saved at epoch 8 with validation loss: 0.0679
[Epoch 9, Batch 100] loss: 0.04115572705399245
[Epoch 9, Batch 200] loss: 0.04085554649122059
[Epoch 9, Batch 300] loss: 0.04597753150621429
**STATS for Epoch 9** : 
Average training loss: 0.0086
Average validation loss: 0.0667
Validation Accuracy: 0.9795
Overfitting: 0.0581
Best model saved at epoch 9 with validation loss: 0.0667
[Epoch 10, Batch 100] loss: 0.03726078071631491
[Epoch 10, Batch 200] loss: 0.03736293214606121
[Epoch 10, Batch 300] loss: 0.038294703005813065
**STATS for Epoch 10** : 
Average training loss: 0.0080
Average validation loss: 0.0626
Validation Accuracy: 0.9818
Overfitting: 0.0546
Best model saved at epoch 10 with validation loss: 0.0626
[Epoch 11, Batch 100] loss: 0.0336450380878523
[Epoch 11, Batch 200] loss: 0.03425739341881126
[Epoch 11, Batch 300] loss: 0.03949702913407236
**STATS for Epoch 11** : 
Average training loss: 0.0072
Average validation loss: 0.0651
Validation Accuracy: 0.9814
Overfitting: 0.0579
[Epoch 12, Batch 100] loss: 0.030370452678762375
[Epoch 12, Batch 200] loss: 0.03185977716464549
[Epoch 12, Batch 300] loss: 0.03136135025415569
**STATS for Epoch 12** : 
Average training loss: 0.0063
Average validation loss: 0.0553
Validation Accuracy: 0.9839
Overfitting: 0.0490
Best model saved at epoch 12 with validation loss: 0.0553
[Epoch 13, Batch 100] loss: 0.023156641088426112
[Epoch 13, Batch 200] loss: 0.028855470099952072
[Epoch 13, Batch 300] loss: 0.03288213652791455
**STATS for Epoch 13** : 
Average training loss: 0.0057
Average validation loss: 0.0551
Validation Accuracy: 0.9843
Overfitting: 0.0495
Best model saved at epoch 13 with validation loss: 0.0551
[Epoch 14, Batch 100] loss: 0.02504724672762677
[Epoch 14, Batch 200] loss: 0.02347025173599832
[Epoch 14, Batch 300] loss: 0.031317326771095395
**STATS for Epoch 14** : 
Average training loss: 0.0053
Average validation loss: 0.0610
Validation Accuracy: 0.9834
Overfitting: 0.0557
[Epoch 15, Batch 100] loss: 0.019603208273765632
[Epoch 15, Batch 200] loss: 0.02587341399397701
[Epoch 15, Batch 300] loss: 0.022854980267584323
**STATS for Epoch 15** : 
Average training loss: 0.0051
Average validation loss: 0.0544
Validation Accuracy: 0.9843
Overfitting: 0.0493
Best model saved at epoch 15 with validation loss: 0.0544
[Epoch 16, Batch 100] loss: 0.017932651463197544
[Epoch 16, Batch 200] loss: 0.023195421134587377
[Epoch 16, Batch 300] loss: 0.023480185044463725
**STATS for Epoch 16** : 
Average training loss: 0.0057
Average validation loss: 0.0610
Validation Accuracy: 0.9832
Overfitting: 0.0553
[Epoch 17, Batch 100] loss: 0.015177625648211688
[Epoch 17, Batch 200] loss: 0.023951468570157886
[Epoch 17, Batch 300] loss: 0.021172171875368805
**STATS for Epoch 17** : 
Average training loss: 0.0043
Average validation loss: 0.0593
Validation Accuracy: 0.9832
Overfitting: 0.0550
[Epoch 18, Batch 100] loss: 0.016664101460482927
[Epoch 18, Batch 200] loss: 0.01952516694436781
[Epoch 18, Batch 300] loss: 0.02272892531938851
**STATS for Epoch 18** : 
Average training loss: 0.0032
Average validation loss: 0.0597
Validation Accuracy: 0.9844
Overfitting: 0.0565
[Epoch 19, Batch 100] loss: 0.013902136930264533
[Epoch 19, Batch 200] loss: 0.01198491241200827
[Epoch 19, Batch 300] loss: 0.025759225744986906
**STATS for Epoch 19** : 
Average training loss: 0.0034
Average validation loss: 0.0543
Validation Accuracy: 0.9848
Overfitting: 0.0509
Best model saved at epoch 19 with validation loss: 0.0543
[Epoch 20, Batch 100] loss: 0.01418460553541081
[Epoch 20, Batch 200] loss: 0.01402665073692333
[Epoch 20, Batch 300] loss: 0.016978956489474513
**STATS for Epoch 20** : 
Average training loss: 0.0033
Average validation loss: 0.0655
Validation Accuracy: 0.9812
Overfitting: 0.0622
[Epoch 21, Batch 100] loss: 0.014156738754827529
[Epoch 21, Batch 200] loss: 0.013148981042322703
[Epoch 21, Batch 300] loss: 0.016213439659331925
**STATS for Epoch 21** : 
Average training loss: 0.0030
Average validation loss: 0.0575
Validation Accuracy: 0.9837
Overfitting: 0.0544
[Epoch 22, Batch 100] loss: 0.00954457807703875
[Epoch 22, Batch 200] loss: 0.014039916070178151
[Epoch 22, Batch 300] loss: 0.011419984181993642
**STATS for Epoch 22** : 
Average training loss: 0.0034
Average validation loss: 0.0685
Validation Accuracy: 0.9829
Overfitting: 0.0651
[Epoch 23, Batch 100] loss: 0.012019934321870096
[Epoch 23, Batch 200] loss: 0.010526286324602552
[Epoch 23, Batch 300] loss: 0.011041224566870369
**STATS for Epoch 23** : 
Average training loss: 0.0036
Average validation loss: 0.0598
Validation Accuracy: 0.9847
Overfitting: 0.0561
[Epoch 24, Batch 100] loss: 0.008794122178805992
[Epoch 24, Batch 200] loss: 0.01778939612355316
[Epoch 24, Batch 300] loss: 0.010439126398705412
**STATS for Epoch 24** : 
Average training loss: 0.0018
Average validation loss: 0.0618
Validation Accuracy: 0.9847
Overfitting: 0.0600
Fold 2 validation loss: 0.0618
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.1915532672405242
[Epoch 1, Batch 200] loss: 0.7172843036055565
[Epoch 1, Batch 300] loss: 0.3200880815088749
**STATS for Epoch 1** : 
Average training loss: 0.0515
Average validation loss: 0.2310
Validation Accuracy: 0.9329
Overfitting: 0.1795
Best model saved at epoch 1 with validation loss: 0.2310
[Epoch 2, Batch 100] loss: 0.19345486901700495
[Epoch 2, Batch 200] loss: 0.15826358452439307
[Epoch 2, Batch 300] loss: 0.1615052059851587
**STATS for Epoch 2** : 
Average training loss: 0.0270
Average validation loss: 0.1296
Validation Accuracy: 0.9606
Overfitting: 0.1025
Best model saved at epoch 2 with validation loss: 0.1296
[Epoch 3, Batch 100] loss: 0.12249675221741199
[Epoch 3, Batch 200] loss: 0.1109195064008236
[Epoch 3, Batch 300] loss: 0.1063629450649023
**STATS for Epoch 3** : 
Average training loss: 0.0203
Average validation loss: 0.1083
Validation Accuracy: 0.9679
Overfitting: 0.0880
Best model saved at epoch 3 with validation loss: 0.1083
[Epoch 4, Batch 100] loss: 0.08982254717499018
[Epoch 4, Batch 200] loss: 0.09384757181629538
[Epoch 4, Batch 300] loss: 0.08782920215278864
**STATS for Epoch 4** : 
Average training loss: 0.0161
Average validation loss: 0.0840
Validation Accuracy: 0.9745
Overfitting: 0.0679
Best model saved at epoch 4 with validation loss: 0.0840
[Epoch 5, Batch 100] loss: 0.07159222472459077
[Epoch 5, Batch 200] loss: 0.07410421095788479
[Epoch 5, Batch 300] loss: 0.07191021361388267
**STATS for Epoch 5** : 
Average training loss: 0.0141
Average validation loss: 0.0835
Validation Accuracy: 0.9736
Overfitting: 0.0694
Best model saved at epoch 5 with validation loss: 0.0835
[Epoch 6, Batch 100] loss: 0.06765635047107935
[Epoch 6, Batch 200] loss: 0.06960336808115244
[Epoch 6, Batch 300] loss: 0.056405632207170125
**STATS for Epoch 6** : 
Average training loss: 0.0139
Average validation loss: 0.0781
Validation Accuracy: 0.9741
Overfitting: 0.0642
Best model saved at epoch 6 with validation loss: 0.0781
[Epoch 7, Batch 100] loss: 0.05431025988422334
[Epoch 7, Batch 200] loss: 0.060490600988268854
[Epoch 7, Batch 300] loss: 0.05704795395024121
**STATS for Epoch 7** : 
Average training loss: 0.0122
Average validation loss: 0.0673
Validation Accuracy: 0.9793
Overfitting: 0.0551
Best model saved at epoch 7 with validation loss: 0.0673
[Epoch 8, Batch 100] loss: 0.0488653764128685
[Epoch 8, Batch 200] loss: 0.05117506781592965
[Epoch 8, Batch 300] loss: 0.04761051293462515
**STATS for Epoch 8** : 
Average training loss: 0.0101
Average validation loss: 0.0610
Validation Accuracy: 0.9813
Overfitting: 0.0509
Best model saved at epoch 8 with validation loss: 0.0610
[Epoch 9, Batch 100] loss: 0.04933400545269251
[Epoch 9, Batch 200] loss: 0.044370574858039614
[Epoch 9, Batch 300] loss: 0.04139818150550127
**STATS for Epoch 9** : 
Average training loss: 0.0096
Average validation loss: 0.0638
Validation Accuracy: 0.9808
Overfitting: 0.0543
[Epoch 10, Batch 100] loss: 0.03457581001566723
[Epoch 10, Batch 200] loss: 0.04208322460297495
[Epoch 10, Batch 300] loss: 0.04498910592403263
**STATS for Epoch 10** : 
Average training loss: 0.0082
Average validation loss: 0.0582
Validation Accuracy: 0.9825
Overfitting: 0.0500
Best model saved at epoch 10 with validation loss: 0.0582
[Epoch 11, Batch 100] loss: 0.04069974669255316
[Epoch 11, Batch 200] loss: 0.035038835061714055
[Epoch 11, Batch 300] loss: 0.035415256787091495
**STATS for Epoch 11** : 
Average training loss: 0.0075
Average validation loss: 0.0532
Validation Accuracy: 0.9832
Overfitting: 0.0457
Best model saved at epoch 11 with validation loss: 0.0532
[Epoch 12, Batch 100] loss: 0.028666256470605733
[Epoch 12, Batch 200] loss: 0.03391394466627389
[Epoch 12, Batch 300] loss: 0.03403207784052938
**STATS for Epoch 12** : 
Average training loss: 0.0073
Average validation loss: 0.0556
Validation Accuracy: 0.9824
Overfitting: 0.0483
[Epoch 13, Batch 100] loss: 0.023328999346122144
[Epoch 13, Batch 200] loss: 0.033915813593193886
[Epoch 13, Batch 300] loss: 0.036617997153662145
**STATS for Epoch 13** : 
Average training loss: 0.0063
Average validation loss: 0.0492
Validation Accuracy: 0.9861
Overfitting: 0.0429
Best model saved at epoch 13 with validation loss: 0.0492
[Epoch 14, Batch 100] loss: 0.02836096648592502
[Epoch 14, Batch 200] loss: 0.025774866300635038
[Epoch 14, Batch 300] loss: 0.032096448231022805
**STATS for Epoch 14** : 
Average training loss: 0.0055
Average validation loss: 0.0517
Validation Accuracy: 0.9850
Overfitting: 0.0463
[Epoch 15, Batch 100] loss: 0.025278620412573217
[Epoch 15, Batch 200] loss: 0.030482835217844693
[Epoch 15, Batch 300] loss: 0.023103987153153868
**STATS for Epoch 15** : 
Average training loss: 0.0055
Average validation loss: 0.0451
Validation Accuracy: 0.9873
Overfitting: 0.0396
Best model saved at epoch 15 with validation loss: 0.0451
[Epoch 16, Batch 100] loss: 0.01879116760217585
[Epoch 16, Batch 200] loss: 0.023673091773525813
[Epoch 16, Batch 300] loss: 0.0249225828028284
**STATS for Epoch 16** : 
Average training loss: 0.0050
Average validation loss: 0.0509
Validation Accuracy: 0.9851
Overfitting: 0.0459
[Epoch 17, Batch 100] loss: 0.022001870231470093
[Epoch 17, Batch 200] loss: 0.02640039549674839
[Epoch 17, Batch 300] loss: 0.020858105532824994
**STATS for Epoch 17** : 
Average training loss: 0.0037
Average validation loss: 0.0533
Validation Accuracy: 0.9844
Overfitting: 0.0496
[Epoch 18, Batch 100] loss: 0.018222863879054786
[Epoch 18, Batch 200] loss: 0.020225432722363622
[Epoch 18, Batch 300] loss: 0.02142536542378366
**STATS for Epoch 18** : 
Average training loss: 0.0042
Average validation loss: 0.0497
Validation Accuracy: 0.9861
Overfitting: 0.0454
[Epoch 19, Batch 100] loss: 0.019275620420230552
[Epoch 19, Batch 200] loss: 0.01748226528754458
[Epoch 19, Batch 300] loss: 0.01770720924716443
**STATS for Epoch 19** : 
Average training loss: 0.0034
Average validation loss: 0.0468
Validation Accuracy: 0.9872
Overfitting: 0.0434
[Epoch 20, Batch 100] loss: 0.01416715867992025
[Epoch 20, Batch 200] loss: 0.014751110065844841
[Epoch 20, Batch 300] loss: 0.01613627699203789
**STATS for Epoch 20** : 
Average training loss: 0.0037
Average validation loss: 0.0511
Validation Accuracy: 0.9856
Overfitting: 0.0475
[Epoch 21, Batch 100] loss: 0.014591939885285683
[Epoch 21, Batch 200] loss: 0.014601938835112379
[Epoch 21, Batch 300] loss: 0.014334031346952542
**STATS for Epoch 21** : 
Average training loss: 0.0027
Average validation loss: 0.0489
Validation Accuracy: 0.9867
Overfitting: 0.0462
[Epoch 22, Batch 100] loss: 0.011500019410741516
[Epoch 22, Batch 200] loss: 0.014100893955910578
[Epoch 22, Batch 300] loss: 0.015411032539559529
**STATS for Epoch 22** : 
Average training loss: 0.0028
Average validation loss: 0.0464
Validation Accuracy: 0.9873
Overfitting: 0.0435
[Epoch 23, Batch 100] loss: 0.010810451142024249
[Epoch 23, Batch 200] loss: 0.01143706273054704
[Epoch 23, Batch 300] loss: 0.012460401309654116
**STATS for Epoch 23** : 
Average training loss: 0.0025
Average validation loss: 0.0475
Validation Accuracy: 0.9871
Overfitting: 0.0450
[Epoch 24, Batch 100] loss: 0.01052951974532334
[Epoch 24, Batch 200] loss: 0.010355061555164866
[Epoch 24, Batch 300] loss: 0.013441195320920087
**STATS for Epoch 24** : 
Average training loss: 0.0025
Average validation loss: 0.0492
Validation Accuracy: 0.9869
Overfitting: 0.0467
Fold 3 validation loss: 0.0492
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.8857820731401445
[Epoch 1, Batch 200] loss: 0.5325722602009774
[Epoch 1, Batch 300] loss: 0.32875391498208045
**STATS for Epoch 1** : 
Average training loss: 0.0478
Average validation loss: 0.2424
Validation Accuracy: 0.9251
Overfitting: 0.1946
Best model saved at epoch 1 with validation loss: 0.2424
[Epoch 2, Batch 100] loss: 0.20281948521733284
[Epoch 2, Batch 200] loss: 0.1664449942857027
[Epoch 2, Batch 300] loss: 0.13389685370028018
**STATS for Epoch 2** : 
Average training loss: 0.0259
Average validation loss: 0.1147
Validation Accuracy: 0.9651
Overfitting: 0.0888
Best model saved at epoch 2 with validation loss: 0.1147
[Epoch 3, Batch 100] loss: 0.11294812399894
[Epoch 3, Batch 200] loss: 0.10863493874669075
[Epoch 3, Batch 300] loss: 0.09434700842946768
**STATS for Epoch 3** : 
Average training loss: 0.0170
Average validation loss: 0.0859
Validation Accuracy: 0.9728
Overfitting: 0.0689
Best model saved at epoch 3 with validation loss: 0.0859
[Epoch 4, Batch 100] loss: 0.08066474080085755
[Epoch 4, Batch 200] loss: 0.07874899223446846
[Epoch 4, Batch 300] loss: 0.07667140044271946
**STATS for Epoch 4** : 
Average training loss: 0.0158
Average validation loss: 0.0757
Validation Accuracy: 0.9748
Overfitting: 0.0599
Best model saved at epoch 4 with validation loss: 0.0757
[Epoch 5, Batch 100] loss: 0.06091458884067833
[Epoch 5, Batch 200] loss: 0.06954681159928441
[Epoch 5, Batch 300] loss: 0.06582494024187327
**STATS for Epoch 5** : 
Average training loss: 0.0128
Average validation loss: 0.0660
Validation Accuracy: 0.9805
Overfitting: 0.0532
Best model saved at epoch 5 with validation loss: 0.0660
[Epoch 6, Batch 100] loss: 0.05743465521372855
[Epoch 6, Batch 200] loss: 0.05695268857292831
[Epoch 6, Batch 300] loss: 0.047447578068822625
**STATS for Epoch 6** : 
Average training loss: 0.0124
Average validation loss: 0.0621
Validation Accuracy: 0.9805
Overfitting: 0.0497
Best model saved at epoch 6 with validation loss: 0.0621
[Epoch 7, Batch 100] loss: 0.04686035603750497
[Epoch 7, Batch 200] loss: 0.04495748633053154
[Epoch 7, Batch 300] loss: 0.04861704891081899
**STATS for Epoch 7** : 
Average training loss: 0.0093
Average validation loss: 0.0537
Validation Accuracy: 0.9838
Overfitting: 0.0444
Best model saved at epoch 7 with validation loss: 0.0537
[Epoch 8, Batch 100] loss: 0.039260995499789716
[Epoch 8, Batch 200] loss: 0.04237664455082268
[Epoch 8, Batch 300] loss: 0.04550821846816689
**STATS for Epoch 8** : 
Average training loss: 0.0083
Average validation loss: 0.0550
Validation Accuracy: 0.9828
Overfitting: 0.0467
[Epoch 9, Batch 100] loss: 0.041023017102852465
[Epoch 9, Batch 200] loss: 0.036656083390116695
[Epoch 9, Batch 300] loss: 0.03850200792774558
**STATS for Epoch 9** : 
Average training loss: 0.0074
Average validation loss: 0.0528
Validation Accuracy: 0.9838
Overfitting: 0.0454
Best model saved at epoch 9 with validation loss: 0.0528
[Epoch 10, Batch 100] loss: 0.036629095277749005
[Epoch 10, Batch 200] loss: 0.03634612430119887
[Epoch 10, Batch 300] loss: 0.03949533731210977
**STATS for Epoch 10** : 
Average training loss: 0.0062
Average validation loss: 0.0523
Validation Accuracy: 0.9834
Overfitting: 0.0461
Best model saved at epoch 10 with validation loss: 0.0523
[Epoch 11, Batch 100] loss: 0.0328582465974614
[Epoch 11, Batch 200] loss: 0.029983897982165216
[Epoch 11, Batch 300] loss: 0.028735718980897218
**STATS for Epoch 11** : 
Average training loss: 0.0078
Average validation loss: 0.0536
Validation Accuracy: 0.9834
Overfitting: 0.0458
[Epoch 12, Batch 100] loss: 0.024980486198328437
[Epoch 12, Batch 200] loss: 0.03268966345232911
[Epoch 12, Batch 300] loss: 0.02726468945387751
**STATS for Epoch 12** : 
Average training loss: 0.0055
Average validation loss: 0.0458
Validation Accuracy: 0.9860
Overfitting: 0.0403
Best model saved at epoch 12 with validation loss: 0.0458
[Epoch 13, Batch 100] loss: 0.02486171808792278
[Epoch 13, Batch 200] loss: 0.02609467436093837
[Epoch 13, Batch 300] loss: 0.028326605395413935
**STATS for Epoch 13** : 
Average training loss: 0.0047
Average validation loss: 0.0483
Validation Accuracy: 0.9852
Overfitting: 0.0436
[Epoch 14, Batch 100] loss: 0.023452710653655232
[Epoch 14, Batch 200] loss: 0.02147804502863437
[Epoch 14, Batch 300] loss: 0.023172996728681027
**STATS for Epoch 14** : 
Average training loss: 0.0052
Average validation loss: 0.0451
Validation Accuracy: 0.9876
Overfitting: 0.0399
Best model saved at epoch 14 with validation loss: 0.0451
[Epoch 15, Batch 100] loss: 0.016683566813590005
[Epoch 15, Batch 200] loss: 0.018764950977638365
[Epoch 15, Batch 300] loss: 0.023098505632951856
**STATS for Epoch 15** : 
Average training loss: 0.0052
Average validation loss: 0.0454
Validation Accuracy: 0.9877
Overfitting: 0.0402
[Epoch 16, Batch 100] loss: 0.016610350731061773
[Epoch 16, Batch 200] loss: 0.016981143156299366
[Epoch 16, Batch 300] loss: 0.02044015116756782
**STATS for Epoch 16** : 
Average training loss: 0.0042
Average validation loss: 0.0454
Validation Accuracy: 0.9858
Overfitting: 0.0411
[Epoch 17, Batch 100] loss: 0.017011487234849482
[Epoch 17, Batch 200] loss: 0.016706352952169254
[Epoch 17, Batch 300] loss: 0.020558082514908163
**STATS for Epoch 17** : 
Average training loss: 0.0038
Average validation loss: 0.0467
Validation Accuracy: 0.9859
Overfitting: 0.0430
[Epoch 18, Batch 100] loss: 0.014222779116826132
[Epoch 18, Batch 200] loss: 0.01602454889100045
[Epoch 18, Batch 300] loss: 0.018428366183070467
**STATS for Epoch 18** : 
Average training loss: 0.0029
Average validation loss: 0.0476
Validation Accuracy: 0.9854
Overfitting: 0.0446
[Epoch 19, Batch 100] loss: 0.014304350727470591
[Epoch 19, Batch 200] loss: 0.017745678809005766
[Epoch 19, Batch 300] loss: 0.01258898664615117
**STATS for Epoch 19** : 
Average training loss: 0.0033
Average validation loss: 0.0459
Validation Accuracy: 0.9868
Overfitting: 0.0426
[Epoch 20, Batch 100] loss: 0.011802011644467711
[Epoch 20, Batch 200] loss: 0.011981152041407768
[Epoch 20, Batch 300] loss: 0.012684749068866949
**STATS for Epoch 20** : 
Average training loss: 0.0030
Average validation loss: 0.0459
Validation Accuracy: 0.9879
Overfitting: 0.0429
[Epoch 21, Batch 100] loss: 0.010047509971773252
[Epoch 21, Batch 200] loss: 0.013838294058223255
[Epoch 21, Batch 300] loss: 0.012392541654407977
**STATS for Epoch 21** : 
Average training loss: 0.0031
Average validation loss: 0.0459
Validation Accuracy: 0.9888
Overfitting: 0.0428
[Epoch 22, Batch 100] loss: 0.008571409006835893
[Epoch 22, Batch 200] loss: 0.009509033877402545
[Epoch 22, Batch 300] loss: 0.013553559467836748
**STATS for Epoch 22** : 
Average training loss: 0.0031
Average validation loss: 0.0479
Validation Accuracy: 0.9871
Overfitting: 0.0448
[Epoch 23, Batch 100] loss: 0.011318185258423909
[Epoch 23, Batch 200] loss: 0.009739032594952733
[Epoch 23, Batch 300] loss: 0.011470055662794038
**STATS for Epoch 23** : 
Average training loss: 0.0016
Average validation loss: 0.0482
Validation Accuracy: 0.9871
Overfitting: 0.0465
[Epoch 24, Batch 100] loss: 0.009375927385408432
[Epoch 24, Batch 200] loss: 0.008343735171074514
[Epoch 24, Batch 300] loss: 0.009032040574820712
**STATS for Epoch 24** : 
Average training loss: 0.0017
Average validation loss: 0.0501
Validation Accuracy: 0.9861
Overfitting: 0.0484
Fold 4 validation loss: 0.0501
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.220871478319168
[Epoch 1, Batch 200] loss: 0.7970377057790756
[Epoch 1, Batch 300] loss: 0.33783506482839587
**STATS for Epoch 1** : 
Average training loss: 0.0532
Average validation loss: 0.2673
Validation Accuracy: 0.9203
Overfitting: 0.2141
Best model saved at epoch 1 with validation loss: 0.2673
[Epoch 2, Batch 100] loss: 0.21308319747447968
[Epoch 2, Batch 200] loss: 0.1775431013852358
[Epoch 2, Batch 300] loss: 0.14801658142358065
**STATS for Epoch 2** : 
Average training loss: 0.0274
Average validation loss: 0.1265
Validation Accuracy: 0.9631
Overfitting: 0.0991
Best model saved at epoch 2 with validation loss: 0.1265
[Epoch 3, Batch 100] loss: 0.11251134309917689
[Epoch 3, Batch 200] loss: 0.11517941307276487
[Epoch 3, Batch 300] loss: 0.09844472536817193
**STATS for Epoch 3** : 
Average training loss: 0.0197
Average validation loss: 0.0925
Validation Accuracy: 0.9723
Overfitting: 0.0728
Best model saved at epoch 3 with validation loss: 0.0925
[Epoch 4, Batch 100] loss: 0.09322255278006196
[Epoch 4, Batch 200] loss: 0.08808589031919838
[Epoch 4, Batch 300] loss: 0.08166646439582109
**STATS for Epoch 4** : 
Average training loss: 0.0145
Average validation loss: 0.0745
Validation Accuracy: 0.9785
Overfitting: 0.0601
Best model saved at epoch 4 with validation loss: 0.0745
[Epoch 5, Batch 100] loss: 0.0656811913009733
[Epoch 5, Batch 200] loss: 0.06953546917997301
[Epoch 5, Batch 300] loss: 0.07178563193418086
**STATS for Epoch 5** : 
Average training loss: 0.0122
Average validation loss: 0.0728
Validation Accuracy: 0.9770
Overfitting: 0.0606
Best model saved at epoch 5 with validation loss: 0.0728
[Epoch 6, Batch 100] loss: 0.058287422340363264
[Epoch 6, Batch 200] loss: 0.058703748788684604
[Epoch 6, Batch 300] loss: 0.0651636379957199
**STATS for Epoch 6** : 
Average training loss: 0.0109
Average validation loss: 0.0650
Validation Accuracy: 0.9802
Overfitting: 0.0541
Best model saved at epoch 6 with validation loss: 0.0650
[Epoch 7, Batch 100] loss: 0.055869674682617186
[Epoch 7, Batch 200] loss: 0.04642183139920235
[Epoch 7, Batch 300] loss: 0.0518308580480516
**STATS for Epoch 7** : 
Average training loss: 0.0108
Average validation loss: 0.0595
Validation Accuracy: 0.9819
Overfitting: 0.0488
Best model saved at epoch 7 with validation loss: 0.0595
[Epoch 8, Batch 100] loss: 0.049082933231256905
[Epoch 8, Batch 200] loss: 0.04287914692424238
[Epoch 8, Batch 300] loss: 0.043905670498497786
**STATS for Epoch 8** : 
Average training loss: 0.0098
Average validation loss: 0.0639
Validation Accuracy: 0.9800
Overfitting: 0.0540
[Epoch 9, Batch 100] loss: 0.0416281127743423
[Epoch 9, Batch 200] loss: 0.03859391047153622
[Epoch 9, Batch 300] loss: 0.04215283327735961
**STATS for Epoch 9** : 
Average training loss: 0.0075
Average validation loss: 0.0509
Validation Accuracy: 0.9846
Overfitting: 0.0435
Best model saved at epoch 9 with validation loss: 0.0509
[Epoch 10, Batch 100] loss: 0.032854252010583875
[Epoch 10, Batch 200] loss: 0.03994665550068021
[Epoch 10, Batch 300] loss: 0.03646512577775866
**STATS for Epoch 10** : 
Average training loss: 0.0076
Average validation loss: 0.0509
Validation Accuracy: 0.9846
Overfitting: 0.0433
Best model saved at epoch 10 with validation loss: 0.0509
[Epoch 11, Batch 100] loss: 0.03221417585620657
[Epoch 11, Batch 200] loss: 0.03219829717418179
[Epoch 11, Batch 300] loss: 0.04006535463966429
**STATS for Epoch 11** : 
Average training loss: 0.0063
Average validation loss: 0.0512
Validation Accuracy: 0.9832
Overfitting: 0.0449
[Epoch 12, Batch 100] loss: 0.031767705135280266
[Epoch 12, Batch 200] loss: 0.031974892508005726
[Epoch 12, Batch 300] loss: 0.0271232734574005
**STATS for Epoch 12** : 
Average training loss: 0.0058
Average validation loss: 0.0447
Validation Accuracy: 0.9862
Overfitting: 0.0389
Best model saved at epoch 12 with validation loss: 0.0447
[Epoch 13, Batch 100] loss: 0.027436073822900652
[Epoch 13, Batch 200] loss: 0.029477812419645488
[Epoch 13, Batch 300] loss: 0.027231497609755025
**STATS for Epoch 13** : 
Average training loss: 0.0061
Average validation loss: 0.0475
Validation Accuracy: 0.9852
Overfitting: 0.0414
[Epoch 14, Batch 100] loss: 0.02426629405701533
[Epoch 14, Batch 200] loss: 0.024343403152888642
[Epoch 14, Batch 300] loss: 0.02888045446947217
**STATS for Epoch 14** : 
Average training loss: 0.0051
Average validation loss: 0.0431
Validation Accuracy: 0.9872
Overfitting: 0.0380
Best model saved at epoch 14 with validation loss: 0.0431
[Epoch 15, Batch 100] loss: 0.023843107833527027
[Epoch 15, Batch 200] loss: 0.020159323336556553
[Epoch 15, Batch 300] loss: 0.022875733245164155
**STATS for Epoch 15** : 
Average training loss: 0.0051
Average validation loss: 0.0432
Validation Accuracy: 0.9878
Overfitting: 0.0381
[Epoch 16, Batch 100] loss: 0.020387711082585157
[Epoch 16, Batch 200] loss: 0.025801648501073943
[Epoch 16, Batch 300] loss: 0.02369323913473636
**STATS for Epoch 16** : 
Average training loss: 0.0039
Average validation loss: 0.0574
Validation Accuracy: 0.9835
Overfitting: 0.0535
[Epoch 17, Batch 100] loss: 0.020818019724683837
[Epoch 17, Batch 200] loss: 0.015916089718230067
[Epoch 17, Batch 300] loss: 0.018429272569483145
**STATS for Epoch 17** : 
Average training loss: 0.0048
Average validation loss: 0.0419
Validation Accuracy: 0.9878
Overfitting: 0.0371
Best model saved at epoch 17 with validation loss: 0.0419
[Epoch 18, Batch 100] loss: 0.01754370986309368
[Epoch 18, Batch 200] loss: 0.01765263192879502
[Epoch 18, Batch 300] loss: 0.01949641788494773
**STATS for Epoch 18** : 
Average training loss: 0.0039
Average validation loss: 0.0412
Validation Accuracy: 0.9879
Overfitting: 0.0373
Best model saved at epoch 18 with validation loss: 0.0412
[Epoch 19, Batch 100] loss: 0.01325606953818351
[Epoch 19, Batch 200] loss: 0.016528531726216898
[Epoch 19, Batch 300] loss: 0.017914675675565376
**STATS for Epoch 19** : 
Average training loss: 0.0034
Average validation loss: 0.0487
Validation Accuracy: 0.9856
Overfitting: 0.0453
[Epoch 20, Batch 100] loss: 0.013959394501289352
[Epoch 20, Batch 200] loss: 0.01232493539340794
[Epoch 20, Batch 300] loss: 0.01588721216772683
**STATS for Epoch 20** : 
Average training loss: 0.0034
Average validation loss: 0.0459
Validation Accuracy: 0.9868
Overfitting: 0.0425
[Epoch 21, Batch 100] loss: 0.014412138501938898
[Epoch 21, Batch 200] loss: 0.013367636142647825
[Epoch 21, Batch 300] loss: 0.011374633539817295
**STATS for Epoch 21** : 
Average training loss: 0.0035
Average validation loss: 0.0501
Validation Accuracy: 0.9858
Overfitting: 0.0465
[Epoch 22, Batch 100] loss: 0.010724816199508496
[Epoch 22, Batch 200] loss: 0.01253685446223244
[Epoch 22, Batch 300] loss: 0.013083452278515324
**STATS for Epoch 22** : 
Average training loss: 0.0028
Average validation loss: 0.0547
Validation Accuracy: 0.9838
Overfitting: 0.0520
[Epoch 23, Batch 100] loss: 0.011429551535402425
[Epoch 23, Batch 200] loss: 0.011156797474250198
[Epoch 23, Batch 300] loss: 0.012915002384688705
**STATS for Epoch 23** : 
Average training loss: 0.0021
Average validation loss: 0.0438
Validation Accuracy: 0.9878
Overfitting: 0.0417
[Epoch 24, Batch 100] loss: 0.010108682105201296
[Epoch 24, Batch 200] loss: 0.008450188573915511
[Epoch 24, Batch 300] loss: 0.009616120180580764
**STATS for Epoch 24** : 
Average training loss: 0.0022
Average validation loss: 0.0462
Validation Accuracy: 0.9878
Overfitting: 0.0440
Fold 5 validation loss: 0.0462
Mean validation loss across all folds for Trial 21 is 0.0512 with trial config:  l1: 256, l2: 128, lr: 0.003538174401688524, batch_size: 128
[I 2024-12-11 07:39:21,278] Trial 20 finished with value: 0.05122830617836642 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.003538174401688524, 'batch_size': 128}. Best is trial 4 with value: 0.04724671796616846.

Selected Hyperparameters for Trial 22:
  l1: 256, l2: 128, lr: 0.0003663693715248452, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.297969045639038
**STATS for Epoch 1** : 
Average training loss: 1.0695
Average validation loss: 2.2777
Validation Accuracy: 0.1238
Overfitting: 1.2082
Best model saved at epoch 1 with validation loss: 2.2777
[Epoch 2, Batch 100] loss: 2.267684054374695
**STATS for Epoch 2** : 
Average training loss: 1.0495
Average validation loss: 2.2237
Validation Accuracy: 0.3509
Overfitting: 1.1741
Best model saved at epoch 2 with validation loss: 2.2237
[Epoch 3, Batch 100] loss: 2.1953790593147278
**STATS for Epoch 3** : 
Average training loss: 0.9797
Average validation loss: 2.0101
Validation Accuracy: 0.5022
Overfitting: 1.0304
Best model saved at epoch 3 with validation loss: 2.0101
[Epoch 4, Batch 100] loss: 1.859952142238617
**STATS for Epoch 4** : 
Average training loss: 0.6747
Average validation loss: 1.1932
Validation Accuracy: 0.7134
Overfitting: 0.5185
Best model saved at epoch 4 with validation loss: 1.1932
[Epoch 5, Batch 100] loss: 0.9739035493135453
**STATS for Epoch 5** : 
Average training loss: 0.3248
Average validation loss: 0.6011
Validation Accuracy: 0.8293
Overfitting: 0.2764
Best model saved at epoch 5 with validation loss: 0.6011
[Epoch 6, Batch 100] loss: 0.5544852340221404
**STATS for Epoch 6** : 
Average training loss: 0.2296
Average validation loss: 0.4376
Validation Accuracy: 0.8754
Overfitting: 0.2080
Best model saved at epoch 6 with validation loss: 0.4376
[Epoch 7, Batch 100] loss: 0.4343841254711151
**STATS for Epoch 7** : 
Average training loss: 0.1854
Average validation loss: 0.3654
Validation Accuracy: 0.8931
Overfitting: 0.1800
Best model saved at epoch 7 with validation loss: 0.3654
[Epoch 8, Batch 100] loss: 0.37178681790828705
**STATS for Epoch 8** : 
Average training loss: 0.1593
Average validation loss: 0.3157
Validation Accuracy: 0.9083
Overfitting: 0.1564
Best model saved at epoch 8 with validation loss: 0.3157
[Epoch 9, Batch 100] loss: 0.3230114993453026
**STATS for Epoch 9** : 
Average training loss: 0.1440
Average validation loss: 0.2846
Validation Accuracy: 0.9157
Overfitting: 0.1406
[I 2024-12-11 07:40:37,206] Trial 21 pruned. 

Selected Hyperparameters for Trial 23:
  l1: 256, l2: 64, lr: 0.0004964872560604052, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3050552082061766
[Epoch 1, Batch 200] loss: 2.2919908380508422
[Epoch 1, Batch 300] loss: 2.273975176811218
[Epoch 1, Batch 400] loss: 2.2506527876853943
[Epoch 1, Batch 500] loss: 2.186361575126648
[Epoch 1, Batch 600] loss: 2.0122344267368315
[Epoch 1, Batch 700] loss: 1.5595695668458938
[Epoch 1, Batch 800] loss: 1.006385860145092
[Epoch 1, Batch 900] loss: 0.7903857588768005
[Epoch 1, Batch 1000] loss: 0.6514421102404594
[Epoch 1, Batch 1100] loss: 0.584122793674469
[Epoch 1, Batch 1200] loss: 0.5029674699902534
[Epoch 1, Batch 1300] loss: 0.5019348414242267
[Epoch 1, Batch 1400] loss: 0.4920877695083618
[Epoch 1, Batch 1500] loss: 0.44342993311583995
[Epoch 1, Batch 1600] loss: 0.40187196716666224
[Epoch 1, Batch 1700] loss: 0.36679422851651905
[Epoch 1, Batch 1800] loss: 0.3503910145163536
[Epoch 1, Batch 1900] loss: 0.40192484337836504
[Epoch 1, Batch 2000] loss: 0.393950045928359
[Epoch 1, Batch 2100] loss: 0.36173262968659403
[Epoch 1, Batch 2200] loss: 0.30959130607545376
[Epoch 1, Batch 2300] loss: 0.29445700280368325
[Epoch 1, Batch 2400] loss: 0.29132512740790845
[Epoch 1, Batch 2500] loss: 0.3065283941850066
[Epoch 1, Batch 2600] loss: 0.2770108508318663
[Epoch 1, Batch 2700] loss: 0.25642319029197097
[Epoch 1, Batch 2800] loss: 0.2799635493755341
[Epoch 1, Batch 2900] loss: 0.23012071304023266
[Epoch 1, Batch 3000] loss: 0.22113471042364835
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2100
Validation Accuracy: 0.9364
Overfitting: 0.2100
Best model saved at epoch 1 with validation loss: 0.2100
[Epoch 2, Batch 100] loss: 0.2233193777874112
[Epoch 2, Batch 200] loss: 0.24085807077586652
[Epoch 2, Batch 300] loss: 0.238711899202317
[Epoch 2, Batch 400] loss: 0.2161983696417883
[Epoch 2, Batch 500] loss: 0.18195958753116429
[Epoch 2, Batch 600] loss: 0.19609825246036053
[Epoch 2, Batch 700] loss: 0.1788163542933762
[Epoch 2, Batch 800] loss: 0.21017647827044128
[Epoch 2, Batch 900] loss: 0.1925112633034587
[Epoch 2, Batch 1000] loss: 0.1872475824598223
[Epoch 2, Batch 1100] loss: 0.17535337899811565
[Epoch 2, Batch 1200] loss: 0.16976391398347915
[Epoch 2, Batch 1300] loss: 0.16812341038137674
[Epoch 2, Batch 1400] loss: 0.1774721088912338
[Epoch 2, Batch 1500] loss: 0.15737117839977144
[Epoch 2, Batch 1600] loss: 0.14973870291374625
[Epoch 2, Batch 1700] loss: 0.16591737806797027
[Epoch 2, Batch 1800] loss: 0.16046006709337235
[Epoch 2, Batch 1900] loss: 0.1350269810995087
[Epoch 2, Batch 2000] loss: 0.16288399898447095
[Epoch 2, Batch 2100] loss: 0.18171618934720754
[Epoch 2, Batch 2200] loss: 0.14613133354578167
[Epoch 2, Batch 2300] loss: 0.13927814921364187
[Epoch 2, Batch 2400] loss: 0.12054226165637374
[Epoch 2, Batch 2500] loss: 0.12347400275059045
[Epoch 2, Batch 2600] loss: 0.14115417490014806
[Epoch 2, Batch 2700] loss: 0.12045143183786422
[Epoch 2, Batch 2800] loss: 0.13573259100783616
[Epoch 2, Batch 2900] loss: 0.10207654251717031
[Epoch 2, Batch 3000] loss: 0.11061446213861928
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1199
Validation Accuracy: 0.9645
Overfitting: 0.1199
Best model saved at epoch 2 with validation loss: 0.1199
[Epoch 3, Batch 100] loss: 0.12065799800213427
[Epoch 3, Batch 200] loss: 0.13470912859309464
[Epoch 3, Batch 300] loss: 0.11548253700369969
[Epoch 3, Batch 400] loss: 0.11302646761760116
[Epoch 3, Batch 500] loss: 0.10138668246101588
[Epoch 3, Batch 600] loss: 0.09965225119842216
[Epoch 3, Batch 700] loss: 0.11645129785872996
[Epoch 3, Batch 800] loss: 0.14461663415073417
[Epoch 3, Batch 900] loss: 0.15169372713193296
[Epoch 3, Batch 1000] loss: 0.12017858852166682
[Epoch 3, Batch 1100] loss: 0.11115518335020169
[Epoch 3, Batch 1200] loss: 0.09537083282135426
[Epoch 3, Batch 1300] loss: 0.08934857395477593
[Epoch 3, Batch 1400] loss: 0.1028578769811429
[Epoch 3, Batch 1500] loss: 0.11000441413139925
[Epoch 3, Batch 1600] loss: 0.11673325846204534
[Epoch 3, Batch 1700] loss: 0.08650827047647908
[Epoch 3, Batch 1800] loss: 0.0929841356142424
[Epoch 3, Batch 1900] loss: 0.07834795489208773
[Epoch 3, Batch 2000] loss: 0.10349736746633426
[Epoch 3, Batch 2100] loss: 0.12299733789172024
[Epoch 3, Batch 2200] loss: 0.10474924376932904
[Epoch 3, Batch 2300] loss: 0.11022895691683515
[Epoch 3, Batch 2400] loss: 0.10445107551757246
[Epoch 3, Batch 2500] loss: 0.08154529499355703
[Epoch 3, Batch 2600] loss: 0.09800658317981288
[Epoch 3, Batch 2700] loss: 0.0813092634268105
[Epoch 3, Batch 2800] loss: 0.09596516164019704
[Epoch 3, Batch 2900] loss: 0.0999905204004608
[Epoch 3, Batch 3000] loss: 0.10466442885342986
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0863
Validation Accuracy: 0.9723
Overfitting: 0.0863
Best model saved at epoch 3 with validation loss: 0.0863
[Epoch 4, Batch 100] loss: 0.11410932111321018
[Epoch 4, Batch 200] loss: 0.07852226132294163
[Epoch 4, Batch 300] loss: 0.08217309263534844
[Epoch 4, Batch 400] loss: 0.06617637953488156
[Epoch 4, Batch 500] loss: 0.10695516015519388
[Epoch 4, Batch 600] loss: 0.08657233079196885
[Epoch 4, Batch 700] loss: 0.06691432875115425
[Epoch 4, Batch 800] loss: 0.08235807517310605
[Epoch 4, Batch 900] loss: 0.07403066461207346
[Epoch 4, Batch 1000] loss: 0.0746044481912395
[Epoch 4, Batch 1100] loss: 0.08332521782023833
[Epoch 4, Batch 1200] loss: 0.0766669721994549
[Epoch 4, Batch 1300] loss: 0.07625528021249921
[Epoch 4, Batch 1400] loss: 0.0729586598300375
[Epoch 4, Batch 1500] loss: 0.06863938783062622
[Epoch 4, Batch 1600] loss: 0.10273146485560573
[Epoch 4, Batch 1700] loss: 0.07506955505930818
[Epoch 4, Batch 1800] loss: 0.05759283589432016
[Epoch 4, Batch 1900] loss: 0.06770754887140357
[Epoch 4, Batch 2000] loss: 0.08512505322578363
[Epoch 4, Batch 2100] loss: 0.08233886170317418
[Epoch 4, Batch 2200] loss: 0.08280840106774122
[Epoch 4, Batch 2300] loss: 0.08039373192121274
[Epoch 4, Batch 2400] loss: 0.0720185752393445
[Epoch 4, Batch 2500] loss: 0.07934615053178277
[Epoch 4, Batch 2600] loss: 0.062211510026827455
[Epoch 4, Batch 2700] loss: 0.06372567596263252
[Epoch 4, Batch 2800] loss: 0.09148861207184382
[Epoch 4, Batch 2900] loss: 0.0989890532568097
[Epoch 4, Batch 3000] loss: 0.09767910784983541
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0757
Validation Accuracy: 0.9767
Overfitting: 0.0757
Best model saved at epoch 4 with validation loss: 0.0757
[Epoch 5, Batch 100] loss: 0.08180893186014146
[Epoch 5, Batch 200] loss: 0.05400487894425168
[Epoch 5, Batch 300] loss: 0.07795304010971449
[Epoch 5, Batch 400] loss: 0.060028551125433295
[Epoch 5, Batch 500] loss: 0.07688616996398195
[Epoch 5, Batch 600] loss: 0.06563233904715161
[Epoch 5, Batch 700] loss: 0.06105157043668442
[Epoch 5, Batch 800] loss: 0.06099266647943295
[Epoch 5, Batch 900] loss: 0.06416037620394491
[Epoch 5, Batch 1000] loss: 0.05782002199965063
[Epoch 5, Batch 1100] loss: 0.05823972788406536
[Epoch 5, Batch 1200] loss: 0.07296428497531451
[Epoch 5, Batch 1300] loss: 0.062012360808439554
[Epoch 5, Batch 1400] loss: 0.06192904149298556
[Epoch 5, Batch 1500] loss: 0.07628507374203763
[Epoch 5, Batch 1600] loss: 0.05101683506392874
[Epoch 5, Batch 1700] loss: 0.0745888817065861
[Epoch 5, Batch 1800] loss: 0.07187431047204881
[Epoch 5, Batch 1900] loss: 0.06097472396708326
[Epoch 5, Batch 2000] loss: 0.060394210947561075
[Epoch 5, Batch 2100] loss: 0.057784520222630816
[Epoch 5, Batch 2200] loss: 0.06764460601378232
[Epoch 5, Batch 2300] loss: 0.10006429708970245
[Epoch 5, Batch 2400] loss: 0.0827294623455964
[Epoch 5, Batch 2500] loss: 0.06046513911220245
[Epoch 5, Batch 2600] loss: 0.06164017601346131
[Epoch 5, Batch 2700] loss: 0.05803128457744606
[Epoch 5, Batch 2800] loss: 0.05354670706437901
[Epoch 5, Batch 2900] loss: 0.07941223547270056
[Epoch 5, Batch 3000] loss: 0.04862827353703324
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0734
Validation Accuracy: 0.9779
Overfitting: 0.0734
Best model saved at epoch 5 with validation loss: 0.0734
[Epoch 6, Batch 100] loss: 0.06880647281825077
[Epoch 6, Batch 200] loss: 0.05480988098133821
[Epoch 6, Batch 300] loss: 0.06162060862261569
[Epoch 6, Batch 400] loss: 0.058734862382989375
[Epoch 6, Batch 500] loss: 0.048493760869896506
[Epoch 6, Batch 600] loss: 0.06391186187101994
[Epoch 6, Batch 700] loss: 0.04910780320118647
[Epoch 6, Batch 800] loss: 0.05857781919068657
[Epoch 6, Batch 900] loss: 0.0348167273690342
[Epoch 6, Batch 1000] loss: 0.07646696751908166
[Epoch 6, Batch 1100] loss: 0.07772748346382287
[Epoch 6, Batch 1200] loss: 0.06520889584440738
[Epoch 6, Batch 1300] loss: 0.05432527355325874
[Epoch 6, Batch 1400] loss: 0.046742435173364356
[Epoch 6, Batch 1500] loss: 0.06260910157114268
[Epoch 6, Batch 1600] loss: 0.04820206407282967
[Epoch 6, Batch 1700] loss: 0.06870883745141328
[Epoch 6, Batch 1800] loss: 0.037136015910073185
[Epoch 6, Batch 1900] loss: 0.06917371683521197
[Epoch 6, Batch 2000] loss: 0.07013594849675428
[Epoch 6, Batch 2100] loss: 0.042447875239595305
[Epoch 6, Batch 2200] loss: 0.0652778151939856
[Epoch 6, Batch 2300] loss: 0.0420579876069678
[Epoch 6, Batch 2400] loss: 0.060953618961502795
[Epoch 6, Batch 2500] loss: 0.0713120548822917
[Epoch 6, Batch 2600] loss: 0.04794920328829903
[Epoch 6, Batch 2700] loss: 0.05065365673799534
[Epoch 6, Batch 2800] loss: 0.036150412372662685
[Epoch 6, Batch 2900] loss: 0.07309817616944202
[Epoch 6, Batch 3000] loss: 0.051244373812223784
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0653
Validation Accuracy: 0.9798
Overfitting: 0.0653
Best model saved at epoch 6 with validation loss: 0.0653
[Epoch 7, Batch 100] loss: 0.05986565487575717
[Epoch 7, Batch 200] loss: 0.05586090037366375
[Epoch 7, Batch 300] loss: 0.05331198968051467
[Epoch 7, Batch 400] loss: 0.050742136545595715
[Epoch 7, Batch 500] loss: 0.04609607090300415
[Epoch 7, Batch 600] loss: 0.061290638344944456
[Epoch 7, Batch 700] loss: 0.07986281188990688
[Epoch 7, Batch 800] loss: 0.04199309966061264
[Epoch 7, Batch 900] loss: 0.0516993698925944
[Epoch 7, Batch 1000] loss: 0.046686151754111054
[Epoch 7, Batch 1100] loss: 0.030013268328330015
[Epoch 7, Batch 1200] loss: 0.0463629393116571
[Epoch 7, Batch 1300] loss: 0.05067214797250927
[Epoch 7, Batch 1400] loss: 0.05328328662610147
[Epoch 7, Batch 1500] loss: 0.04484225851425436
[Epoch 7, Batch 1600] loss: 0.05030174036801327
[Epoch 7, Batch 1700] loss: 0.043617435695487074
[Epoch 7, Batch 1800] loss: 0.05863194544886938
[Epoch 7, Batch 1900] loss: 0.04918198029423365
[Epoch 7, Batch 2000] loss: 0.04641885818069568
[Epoch 7, Batch 2100] loss: 0.04182465661055176
[Epoch 7, Batch 2200] loss: 0.05597877326479647
[Epoch 7, Batch 2300] loss: 0.045708912335685456
[Epoch 7, Batch 2400] loss: 0.0426727047827444
[Epoch 7, Batch 2500] loss: 0.048184073566808365
[Epoch 7, Batch 2600] loss: 0.04015554480138235
[Epoch 7, Batch 2700] loss: 0.0437020138616208
[Epoch 7, Batch 2800] loss: 0.05908242870966205
[Epoch 7, Batch 2900] loss: 0.041022202710737476
[Epoch 7, Batch 3000] loss: 0.04381365389854182
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9821
Overfitting: 0.0586
Best model saved at epoch 7 with validation loss: 0.0586
[Epoch 8, Batch 100] loss: 0.040843432602414395
[Epoch 8, Batch 200] loss: 0.05162496442557313
[Epoch 8, Batch 300] loss: 0.03692940013745101
[Epoch 8, Batch 400] loss: 0.036535412745724895
[Epoch 8, Batch 500] loss: 0.0317764326557517
[Epoch 8, Batch 600] loss: 0.03979596656601643
[Epoch 8, Batch 700] loss: 0.03945530912809772
[Epoch 8, Batch 800] loss: 0.04319378390558995
[Epoch 8, Batch 900] loss: 0.04497585142933531
[Epoch 8, Batch 1000] loss: 0.055472530604165515
[Epoch 8, Batch 1100] loss: 0.039565997849131236
[Epoch 8, Batch 1200] loss: 0.03802695880411193
[Epoch 8, Batch 1300] loss: 0.04901138494140469
[Epoch 8, Batch 1400] loss: 0.047906908614968415
[Epoch 8, Batch 1500] loss: 0.03150482603494311
[Epoch 8, Batch 1600] loss: 0.05541862624522764
[Epoch 8, Batch 1700] loss: 0.03909802377718734
[Epoch 8, Batch 1800] loss: 0.03024603694328107
[Epoch 8, Batch 1900] loss: 0.04443238868610933
[Epoch 8, Batch 2000] loss: 0.034870736733282684
[Epoch 8, Batch 2100] loss: 0.03929224751860602
[Epoch 8, Batch 2200] loss: 0.03840945653748349
[Epoch 8, Batch 2300] loss: 0.0504864554211963
[Epoch 8, Batch 2400] loss: 0.04695353674265789
[Epoch 8, Batch 2500] loss: 0.036302588953403755
[Epoch 8, Batch 2600] loss: 0.059854703726305164
[Epoch 8, Batch 2700] loss: 0.049617052282847
[Epoch 8, Batch 2800] loss: 0.037916185573558324
[Epoch 8, Batch 2900] loss: 0.05079449651297182
[Epoch 8, Batch 3000] loss: 0.037347528643149414
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9842
Overfitting: 0.0501
Best model saved at epoch 8 with validation loss: 0.0501
[Epoch 9, Batch 100] loss: 0.0176767301390646
[Epoch 9, Batch 200] loss: 0.037837175875029064
[Epoch 9, Batch 300] loss: 0.0383829218352912
[Epoch 9, Batch 400] loss: 0.03871864623128204
[Epoch 9, Batch 500] loss: 0.044936612510937265
[Epoch 9, Batch 600] loss: 0.02388521085405955
[Epoch 9, Batch 700] loss: 0.04540567004631157
[Epoch 9, Batch 800] loss: 0.03994835893710842
[Epoch 9, Batch 900] loss: 0.05141779359502834
[Epoch 9, Batch 1000] loss: 0.02789379583497066
[Epoch 9, Batch 1100] loss: 0.03324751618347364
[Epoch 9, Batch 1200] loss: 0.051655465764197286
[Epoch 9, Batch 1300] loss: 0.03866609669712488
[Epoch 9, Batch 1400] loss: 0.0418630816222867
[Epoch 9, Batch 1500] loss: 0.047521219669433776
[Epoch 9, Batch 1600] loss: 0.030138232447498012
[Epoch 9, Batch 1700] loss: 0.04528651886343141
[Epoch 9, Batch 1800] loss: 0.02760522874450544
[Epoch 9, Batch 1900] loss: 0.03946465674292995
[Epoch 9, Batch 2000] loss: 0.03738458220701432
[Epoch 9, Batch 2100] loss: 0.03673833653127076
[Epoch 9, Batch 2200] loss: 0.035339120949502104
[Epoch 9, Batch 2300] loss: 0.04389818104245933
[Epoch 9, Batch 2400] loss: 0.038912930391379635
[Epoch 9, Batch 2500] loss: 0.03555541990863276
[Epoch 9, Batch 2600] loss: 0.0352095500746509
[Epoch 9, Batch 2700] loss: 0.03220661093837407
[Epoch 9, Batch 2800] loss: 0.03997050660691457
[Epoch 9, Batch 2900] loss: 0.04440027530159568
[Epoch 9, Batch 3000] loss: 0.02952187685557874
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9842
Overfitting: 0.0531
[Epoch 10, Batch 100] loss: 0.03924201166766579
[Epoch 10, Batch 200] loss: 0.03657227977804723
[Epoch 10, Batch 300] loss: 0.034198459916515274
[Epoch 10, Batch 400] loss: 0.025123009858943987
[Epoch 10, Batch 500] loss: 0.03750061429804191
[Epoch 10, Batch 600] loss: 0.03043193104909733
[Epoch 10, Batch 700] loss: 0.023195652025169693
[Epoch 10, Batch 800] loss: 0.029693052512520808
[Epoch 10, Batch 900] loss: 0.042171580843714765
[Epoch 10, Batch 1000] loss: 0.030324946832843126
[Epoch 10, Batch 1100] loss: 0.038414230835260244
[Epoch 10, Batch 1200] loss: 0.0248806355157285
[Epoch 10, Batch 1300] loss: 0.03895727193317725
[Epoch 10, Batch 1400] loss: 0.02910537743679015
[Epoch 10, Batch 1500] loss: 0.034983769186655994
[Epoch 10, Batch 1600] loss: 0.02908585037694138
[Epoch 10, Batch 1700] loss: 0.061180297673490716
[Epoch 10, Batch 1800] loss: 0.03659429258579621
[Epoch 10, Batch 1900] loss: 0.04072754750115564
[Epoch 10, Batch 2000] loss: 0.02728474378352985
[Epoch 10, Batch 2100] loss: 0.029451764433761126
[Epoch 10, Batch 2200] loss: 0.022530538221762982
[Epoch 10, Batch 2300] loss: 0.035451889025134735
[Epoch 10, Batch 2400] loss: 0.02577548189161462
[Epoch 10, Batch 2500] loss: 0.03275178656855132
[Epoch 10, Batch 2600] loss: 0.027938235912151867
[Epoch 10, Batch 2700] loss: 0.039239744899387
[Epoch 10, Batch 2800] loss: 0.0496207122252963
[Epoch 10, Batch 2900] loss: 0.02620386325288564
[Epoch 10, Batch 3000] loss: 0.02654390982919722
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9852
Overfitting: 0.0506
[I 2024-12-11 07:42:49,679] Trial 22 pruned. 

Selected Hyperparameters for Trial 24:
  l1: 256, l2: 128, lr: 0.0006513347638669589, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2934376335144044
[Epoch 1, Batch 200] loss: 2.26305255651474
[Epoch 1, Batch 300] loss: 2.1989296507835387
[Epoch 1, Batch 400] loss: 1.9694344866275788
[Epoch 1, Batch 500] loss: 1.3000809943675995
[Epoch 1, Batch 600] loss: 0.70625721514225
[Epoch 1, Batch 700] loss: 0.5455731429159641
[Epoch 1, Batch 800] loss: 0.46817065492272375
[Epoch 1, Batch 900] loss: 0.40752850234508514
[Epoch 1, Batch 1000] loss: 0.3632767947018147
[Epoch 1, Batch 1100] loss: 0.3167433454096317
[Epoch 1, Batch 1200] loss: 0.29076597213745115
[Epoch 1, Batch 1300] loss: 0.33047848209738734
[Epoch 1, Batch 1400] loss: 0.32838651828467846
[Epoch 1, Batch 1500] loss: 0.27840921651571987
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2404
Validation Accuracy: 0.9273
Overfitting: 0.2404
Best model saved at epoch 1 with validation loss: 0.2404
[Epoch 2, Batch 100] loss: 0.26569692984223364
[Epoch 2, Batch 200] loss: 0.23896108664572238
[Epoch 2, Batch 300] loss: 0.2381779717281461
[Epoch 2, Batch 400] loss: 0.24784351943060756
[Epoch 2, Batch 500] loss: 0.22688569083809854
[Epoch 2, Batch 600] loss: 0.21888026274740696
[Epoch 2, Batch 700] loss: 0.17956581519916653
[Epoch 2, Batch 800] loss: 0.19719363583251834
[Epoch 2, Batch 900] loss: 0.17714127467945218
[Epoch 2, Batch 1000] loss: 0.1726950993016362
[Epoch 2, Batch 1100] loss: 0.18193403599783778
[Epoch 2, Batch 1200] loss: 0.18959502797573805
[Epoch 2, Batch 1300] loss: 0.16436446186155082
[Epoch 2, Batch 1400] loss: 0.14514566332101822
[Epoch 2, Batch 1500] loss: 0.16770943669602276
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1385
Validation Accuracy: 0.9591
Overfitting: 0.1385
Best model saved at epoch 2 with validation loss: 0.1385
[Epoch 3, Batch 100] loss: 0.15638064068742097
[Epoch 3, Batch 200] loss: 0.15413372801616787
[Epoch 3, Batch 300] loss: 0.15214017616584896
[Epoch 3, Batch 400] loss: 0.14038881294429303
[Epoch 3, Batch 500] loss: 0.12443501165136694
[Epoch 3, Batch 600] loss: 0.11697570099495351
[Epoch 3, Batch 700] loss: 0.1296781135164201
[Epoch 3, Batch 800] loss: 0.14818443179596216
[Epoch 3, Batch 900] loss: 0.13026057495735585
[Epoch 3, Batch 1000] loss: 0.11697519895620644
[Epoch 3, Batch 1100] loss: 0.11890777919907122
[Epoch 3, Batch 1200] loss: 0.11020349765196442
[Epoch 3, Batch 1300] loss: 0.12368469797074795
[Epoch 3, Batch 1400] loss: 0.10992917629890143
[Epoch 3, Batch 1500] loss: 0.11306723887100815
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1067
Validation Accuracy: 0.9672
Overfitting: 0.1067
Best model saved at epoch 3 with validation loss: 0.1067
[Epoch 4, Batch 100] loss: 0.12800455594435334
[Epoch 4, Batch 200] loss: 0.10607884404249489
[Epoch 4, Batch 300] loss: 0.12196694862563164
[Epoch 4, Batch 400] loss: 0.12463795815594494
[Epoch 4, Batch 500] loss: 0.09970740299671889
[Epoch 4, Batch 600] loss: 0.1024796085851267
[Epoch 4, Batch 700] loss: 0.10192297525703907
[Epoch 4, Batch 800] loss: 0.09669978386722505
[Epoch 4, Batch 900] loss: 0.08372788070701062
[Epoch 4, Batch 1000] loss: 0.09306014716625213
[Epoch 4, Batch 1100] loss: 0.09719937220215798
[Epoch 4, Batch 1200] loss: 0.08185140036512166
[Epoch 4, Batch 1300] loss: 0.09588505405001342
[Epoch 4, Batch 1400] loss: 0.0968265145085752
[Epoch 4, Batch 1500] loss: 0.10544217275455595
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0902
Validation Accuracy: 0.9722
Overfitting: 0.0902
Best model saved at epoch 4 with validation loss: 0.0902
[Epoch 5, Batch 100] loss: 0.08753491842653602
[Epoch 5, Batch 200] loss: 0.09581904137972742
[Epoch 5, Batch 300] loss: 0.10153139892267063
[Epoch 5, Batch 400] loss: 0.07579057562630624
[Epoch 5, Batch 500] loss: 0.08616188977845013
[Epoch 5, Batch 600] loss: 0.07396069207694382
[Epoch 5, Batch 700] loss: 0.07814187714830041
[Epoch 5, Batch 800] loss: 0.07286640864331276
[Epoch 5, Batch 900] loss: 0.0928311239881441
[Epoch 5, Batch 1000] loss: 0.08265421280171723
[Epoch 5, Batch 1100] loss: 0.07612196156289429
[Epoch 5, Batch 1200] loss: 0.08831245731562376
[Epoch 5, Batch 1300] loss: 0.08082858494017273
[Epoch 5, Batch 1400] loss: 0.07518151987809688
[Epoch 5, Batch 1500] loss: 0.08738806165289134
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0772
Validation Accuracy: 0.9756
Overfitting: 0.0772
Best model saved at epoch 5 with validation loss: 0.0772
[Epoch 6, Batch 100] loss: 0.06998038013232871
[Epoch 6, Batch 200] loss: 0.07342864529462531
[Epoch 6, Batch 300] loss: 0.06497249684529378
[Epoch 6, Batch 400] loss: 0.06653233997058124
[Epoch 6, Batch 500] loss: 0.07157973689725622
[Epoch 6, Batch 600] loss: 0.07864094375167043
[Epoch 6, Batch 700] loss: 0.07387197529431433
[Epoch 6, Batch 800] loss: 0.07154684354783968
[Epoch 6, Batch 900] loss: 0.07548114228062332
[Epoch 6, Batch 1000] loss: 0.09242038488388062
[Epoch 6, Batch 1100] loss: 0.07215042546391487
[Epoch 6, Batch 1200] loss: 0.07196443958207965
[Epoch 6, Batch 1300] loss: 0.07164591810433193
[Epoch 6, Batch 1400] loss: 0.06248769951052964
[Epoch 6, Batch 1500] loss: 0.06096701007802039
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9782
Overfitting: 0.0665
Best model saved at epoch 6 with validation loss: 0.0665
[Epoch 7, Batch 100] loss: 0.05938699051039294
[Epoch 7, Batch 200] loss: 0.06899880309822037
[Epoch 7, Batch 300] loss: 0.05910156348953024
[Epoch 7, Batch 400] loss: 0.06479047036264092
[Epoch 7, Batch 500] loss: 0.06208739758934825
[Epoch 7, Batch 600] loss: 0.059534114233683794
[Epoch 7, Batch 700] loss: 0.06783130756579339
[Epoch 7, Batch 800] loss: 0.0559877939755097
[Epoch 7, Batch 900] loss: 0.05683390872436576
[Epoch 7, Batch 1000] loss: 0.057597137526609006
[Epoch 7, Batch 1100] loss: 0.06705998263321816
[Epoch 7, Batch 1200] loss: 0.06059035499347374
[Epoch 7, Batch 1300] loss: 0.0727093749330379
[Epoch 7, Batch 1400] loss: 0.0613306282274425
[Epoch 7, Batch 1500] loss: 0.0711654204572551
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9812
Overfitting: 0.0632
Best model saved at epoch 7 with validation loss: 0.0632
[Epoch 8, Batch 100] loss: 0.06376260414719581
[Epoch 8, Batch 200] loss: 0.062186514399945735
[Epoch 8, Batch 300] loss: 0.061767848572926595
[Epoch 8, Batch 400] loss: 0.05584597387118265
[Epoch 8, Batch 500] loss: 0.05157042938517407
[Epoch 8, Batch 600] loss: 0.0647318913298659
[Epoch 8, Batch 700] loss: 0.05681511253584176
[Epoch 8, Batch 800] loss: 0.06081840849481523
[Epoch 8, Batch 900] loss: 0.05965225010062568
[Epoch 8, Batch 1000] loss: 0.050252626488218086
[Epoch 8, Batch 1100] loss: 0.06337509350152687
[Epoch 8, Batch 1200] loss: 0.043292151001514866
[Epoch 8, Batch 1300] loss: 0.06292062705440912
[Epoch 8, Batch 1400] loss: 0.044576943267602476
[Epoch 8, Batch 1500] loss: 0.051654559687012803
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0591
Validation Accuracy: 0.9822
Overfitting: 0.0591
Best model saved at epoch 8 with validation loss: 0.0591
[Epoch 9, Batch 100] loss: 0.06020180676248856
[Epoch 9, Batch 200] loss: 0.03841549227712676
[Epoch 9, Batch 300] loss: 0.05209741364233196
[Epoch 9, Batch 400] loss: 0.052339771547121924
[Epoch 9, Batch 500] loss: 0.04485281322267838
[Epoch 9, Batch 600] loss: 0.05032631814072374
[Epoch 9, Batch 700] loss: 0.05253953472594731
[Epoch 9, Batch 800] loss: 0.04504527795128524
[Epoch 9, Batch 900] loss: 0.05838398688007146
[Epoch 9, Batch 1000] loss: 0.0704145997040905
[Epoch 9, Batch 1100] loss: 0.06039828151697293
[Epoch 9, Batch 1200] loss: 0.04292954093310982
[Epoch 9, Batch 1300] loss: 0.04270917679532431
[Epoch 9, Batch 1400] loss: 0.05079853747272864
[Epoch 9, Batch 1500] loss: 0.05108248682343401
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9810
Overfitting: 0.0559
[I 2024-12-11 07:44:24,991] Trial 23 pruned. 
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  8
  Number of complete trials:  16
Best hyperparameters found:
{'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16}
Best trial:
  Value:  0.04724671796616846
Loaded best model checkpoint from: instances/1446212_20241211/best_checkpoint_trial_4/model.pth
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 2.3027933645248413
[Epoch 1, Batch 200] loss: 2.2965991473197938
[Epoch 1, Batch 300] loss: 2.2911933565139773
[Epoch 1, Batch 400] loss: 2.2882435011863707
[Epoch 1, Batch 500] loss: 2.2787498021125794
[Epoch 1, Batch 600] loss: 2.2691717767715454
[Epoch 1, Batch 700] loss: 2.252761323451996
[Epoch 1, Batch 800] loss: 2.2320742917060854
[Epoch 1, Batch 900] loss: 2.190848789215088
[Epoch 1, Batch 1000] loss: 2.1237340533733366
[Epoch 1, Batch 1100] loss: 1.9831229543685913
[Epoch 1, Batch 1200] loss: 1.6947961914539338
[Epoch 1, Batch 1300] loss: 1.3126873588562011
[Epoch 1, Batch 1400] loss: 0.9581756192445755
[Epoch 1, Batch 1500] loss: 0.7068910992145538
[Epoch 1, Batch 1600] loss: 0.5795837652683258
[Epoch 1, Batch 1700] loss: 0.5087812003493309
[Epoch 1, Batch 1800] loss: 0.4800807400047779
[Epoch 1, Batch 1900] loss: 0.4565256907045841
[Epoch 1, Batch 2000] loss: 0.4038353978842497
[Epoch 1, Batch 2100] loss: 0.38073265485465524
[Epoch 1, Batch 2200] loss: 0.3973597340285778
[Epoch 1, Batch 2300] loss: 0.3781958092004061
[Epoch 1, Batch 2400] loss: 0.32295022435486315
[Epoch 1, Batch 2500] loss: 0.3654125944711268
[Epoch 1, Batch 2600] loss: 0.2975814003124833
[Epoch 1, Batch 2700] loss: 0.31989508982747794
[Epoch 1, Batch 2800] loss: 0.3012567678466439
[Epoch 1, Batch 2900] loss: 0.2920526897534728
[Epoch 1, Batch 3000] loss: 0.2761969684250653
[Epoch 1, Batch 3100] loss: 0.2805673491954803
[Epoch 1, Batch 3200] loss: 0.2677773539349437
[Epoch 1, Batch 3300] loss: 0.2771021429821849
[Epoch 1, Batch 3400] loss: 0.24912597282789647
[Epoch 1, Batch 3500] loss: 0.27474005818367003
[Epoch 1, Batch 3600] loss: 0.2441883970052004
[Epoch 1, Batch 3700] loss: 0.20933076787739993
**STATS for Epoch 1** : 
Average training loss: 0.0026
Average validation loss: 0.2009
Overfitting: 0.1983
Best model saved at epoch 1 with training loss: 0.0026
[Epoch 2, Batch 100] loss: 0.21662845935672523
[Epoch 2, Batch 200] loss: 0.239745330568403
[Epoch 2, Batch 300] loss: 0.22205121248960494
[Epoch 2, Batch 400] loss: 0.20824366653338075
[Epoch 2, Batch 500] loss: 0.18403097216039896
[Epoch 2, Batch 600] loss: 0.1920833432674408
[Epoch 2, Batch 700] loss: 0.2020039787236601
[Epoch 2, Batch 800] loss: 0.21279629783704876
[Epoch 2, Batch 900] loss: 0.20508186237886547
[Epoch 2, Batch 1000] loss: 0.1707489047385752
[Epoch 2, Batch 1100] loss: 0.1769360014051199
[Epoch 2, Batch 1200] loss: 0.16902484066784382
[Epoch 2, Batch 1300] loss: 0.16111530873924493
[Epoch 2, Batch 1400] loss: 0.15485834213905036
[Epoch 2, Batch 1500] loss: 0.16330336133018136
[Epoch 2, Batch 1600] loss: 0.16959980106912553
[Epoch 2, Batch 1700] loss: 0.15091820720583202
[Epoch 2, Batch 1800] loss: 0.1238054747134447
[Epoch 2, Batch 1900] loss: 0.1826455988828093
[Epoch 2, Batch 2000] loss: 0.13560430292971432
[Epoch 2, Batch 2100] loss: 0.13365870213136077
[Epoch 2, Batch 2200] loss: 0.16029663302469999
[Epoch 2, Batch 2300] loss: 0.15471133621409536
[Epoch 2, Batch 2400] loss: 0.12442778053693473
[Epoch 2, Batch 2500] loss: 0.12673698948696255
[Epoch 2, Batch 2600] loss: 0.12636718999827282
[Epoch 2, Batch 2700] loss: 0.13563114262651652
[Epoch 2, Batch 2800] loss: 0.13721507304348052
[Epoch 2, Batch 2900] loss: 0.13224543043412268
[Epoch 2, Batch 3000] loss: 0.13161052305717022
[Epoch 2, Batch 3100] loss: 0.11735440184362232
[Epoch 2, Batch 3200] loss: 0.14155388123355805
[Epoch 2, Batch 3300] loss: 0.13501656617503613
[Epoch 2, Batch 3400] loss: 0.1489299027621746
[Epoch 2, Batch 3500] loss: 0.12379073278745636
[Epoch 2, Batch 3600] loss: 0.1247952735517174
[Epoch 2, Batch 3700] loss: 0.12697336342418566
**STATS for Epoch 2** : 
Average training loss: 0.0017
Average validation loss: 0.1042
Overfitting: 0.1026
Best model saved at epoch 2 with training loss: 0.0017
[Epoch 3, Batch 100] loss: 0.11076781023759395
[Epoch 3, Batch 200] loss: 0.1387463064584881
[Epoch 3, Batch 300] loss: 0.11449377388693392
[Epoch 3, Batch 400] loss: 0.09444491097470746
[Epoch 3, Batch 500] loss: 0.11328594179823995
[Epoch 3, Batch 600] loss: 0.12301553698838688
[Epoch 3, Batch 700] loss: 0.08421905629802495
[Epoch 3, Batch 800] loss: 0.12001862231642008
[Epoch 3, Batch 900] loss: 0.09876518263015896
[Epoch 3, Batch 1000] loss: 0.10837052395101637
[Epoch 3, Batch 1100] loss: 0.09365226798690855
[Epoch 3, Batch 1200] loss: 0.12457740309182555
[Epoch 3, Batch 1300] loss: 0.09268682142952457
[Epoch 3, Batch 1400] loss: 0.0970898942486383
[Epoch 3, Batch 1500] loss: 0.10331249308539554
[Epoch 3, Batch 1600] loss: 0.09770957213360816
[Epoch 3, Batch 1700] loss: 0.10908512188121676
[Epoch 3, Batch 1800] loss: 0.09240769230993465
[Epoch 3, Batch 1900] loss: 0.10264111187774688
[Epoch 3, Batch 2000] loss: 0.1216315543197561
[Epoch 3, Batch 2100] loss: 0.10778959332266823
[Epoch 3, Batch 2200] loss: 0.09467679663561285
[Epoch 3, Batch 2300] loss: 0.10659398617222905
[Epoch 3, Batch 2400] loss: 0.10343891921569594
[Epoch 3, Batch 2500] loss: 0.1095639524422586
[Epoch 3, Batch 2600] loss: 0.10373213249957189
[Epoch 3, Batch 2700] loss: 0.08390937458956614
[Epoch 3, Batch 2800] loss: 0.10491664173547179
[Epoch 3, Batch 2900] loss: 0.09953514254884795
[Epoch 3, Batch 3000] loss: 0.08670118060545065
[Epoch 3, Batch 3100] loss: 0.1085089416243136
[Epoch 3, Batch 3200] loss: 0.1030359403102193
[Epoch 3, Batch 3300] loss: 0.09886138526489958
[Epoch 3, Batch 3400] loss: 0.09686854980420322
[Epoch 3, Batch 3500] loss: 0.09780307930661365
[Epoch 3, Batch 3600] loss: 0.0993561264546588
[Epoch 3, Batch 3700] loss: 0.11357053077314049
**STATS for Epoch 3** : 
Average training loss: 0.0014
Average validation loss: 0.0758
Overfitting: 0.0744
Best model saved at epoch 3 with training loss: 0.0014
[Epoch 4, Batch 100] loss: 0.09206688376609236
[Epoch 4, Batch 200] loss: 0.08080440989695489
[Epoch 4, Batch 300] loss: 0.07453415917465463
[Epoch 4, Batch 400] loss: 0.09578087738715112
[Epoch 4, Batch 500] loss: 0.07980491263791918
[Epoch 4, Batch 600] loss: 0.08369728949735872
[Epoch 4, Batch 700] loss: 0.0736971538932994
[Epoch 4, Batch 800] loss: 0.08362451287801377
[Epoch 4, Batch 900] loss: 0.08247252239496447
[Epoch 4, Batch 1000] loss: 0.0807835057482589
[Epoch 4, Batch 1100] loss: 0.07766550366999582
[Epoch 4, Batch 1200] loss: 0.0883323994895909
[Epoch 4, Batch 1300] loss: 0.07779437351389788
[Epoch 4, Batch 1400] loss: 0.08886073891888373
[Epoch 4, Batch 1500] loss: 0.08333416806475726
[Epoch 4, Batch 1600] loss: 0.06604083779384382
[Epoch 4, Batch 1700] loss: 0.09227436768240295
[Epoch 4, Batch 1800] loss: 0.07349749644461553
[Epoch 4, Batch 1900] loss: 0.07834830457519275
[Epoch 4, Batch 2000] loss: 0.05628002688521519
[Epoch 4, Batch 2100] loss: 0.10129183563869447
[Epoch 4, Batch 2200] loss: 0.058262429197784515
[Epoch 4, Batch 2300] loss: 0.06117729141958989
[Epoch 4, Batch 2400] loss: 0.06857664324576035
[Epoch 4, Batch 2500] loss: 0.07640288012335077
[Epoch 4, Batch 2600] loss: 0.06795774570200593
[Epoch 4, Batch 2700] loss: 0.07872317045694217
[Epoch 4, Batch 2800] loss: 0.08656523525016382
[Epoch 4, Batch 2900] loss: 0.07352103432873264
[Epoch 4, Batch 3000] loss: 0.0850585246027913
[Epoch 4, Batch 3100] loss: 0.09296702261315659
[Epoch 4, Batch 3200] loss: 0.07369242864719126
[Epoch 4, Batch 3300] loss: 0.07189403342199512
[Epoch 4, Batch 3400] loss: 0.09882441982161254
[Epoch 4, Batch 3500] loss: 0.09103525619022548
[Epoch 4, Batch 3600] loss: 0.08127347923815251
[Epoch 4, Batch 3700] loss: 0.0854052607039921
**STATS for Epoch 4** : 
Average training loss: 0.0013
Average validation loss: 0.0619
Overfitting: 0.0607
Best model saved at epoch 4 with training loss: 0.0013
[Epoch 5, Batch 100] loss: 0.075688002074603
[Epoch 5, Batch 200] loss: 0.07026068785460665
[Epoch 5, Batch 300] loss: 0.056259603969519956
[Epoch 5, Batch 400] loss: 0.0634546014177613
[Epoch 5, Batch 500] loss: 0.06339956467039883
[Epoch 5, Batch 600] loss: 0.07362939156184439
[Epoch 5, Batch 700] loss: 0.06767469727434218
[Epoch 5, Batch 800] loss: 0.06280242826091126
[Epoch 5, Batch 900] loss: 0.07250135875074193
[Epoch 5, Batch 1000] loss: 0.06298318809480406
[Epoch 5, Batch 1100] loss: 0.07453267565462739
[Epoch 5, Batch 1200] loss: 0.07536905011744238
[Epoch 5, Batch 1300] loss: 0.060633484933059666
[Epoch 5, Batch 1400] loss: 0.081829193738522
[Epoch 5, Batch 1500] loss: 0.06886820549494586
[Epoch 5, Batch 1600] loss: 0.0538499447342474
[Epoch 5, Batch 1700] loss: 0.07642321844701655
[Epoch 5, Batch 1800] loss: 0.07386974583147093
[Epoch 5, Batch 1900] loss: 0.07201015548082068
[Epoch 5, Batch 2000] loss: 0.06656016270339023
[Epoch 5, Batch 2100] loss: 0.07511866809916683
[Epoch 5, Batch 2200] loss: 0.062437144862487914
[Epoch 5, Batch 2300] loss: 0.08371967802639119
[Epoch 5, Batch 2400] loss: 0.06235267210635356
[Epoch 5, Batch 2500] loss: 0.0871592090849299
[Epoch 5, Batch 2600] loss: 0.057188738651457245
[Epoch 5, Batch 2700] loss: 0.057096441756002606
[Epoch 5, Batch 2800] loss: 0.07773955294280313
[Epoch 5, Batch 2900] loss: 0.06461183576262557
[Epoch 5, Batch 3000] loss: 0.057359178458573294
[Epoch 5, Batch 3100] loss: 0.05878520252910675
[Epoch 5, Batch 3200] loss: 0.09311409596994054
[Epoch 5, Batch 3300] loss: 0.06010885352734476
[Epoch 5, Batch 3400] loss: 0.06091687992797233
[Epoch 5, Batch 3500] loss: 0.07318809000309556
[Epoch 5, Batch 3600] loss: 0.05166604644153267
[Epoch 5, Batch 3700] loss: 0.06414597791270353
**STATS for Epoch 5** : 
Average training loss: 0.0007
Average validation loss: 0.0563
Overfitting: 0.0556
Best model saved at epoch 5 with training loss: 0.0007
[Epoch 6, Batch 100] loss: 0.06777822713367641
[Epoch 6, Batch 200] loss: 0.078421253481647
[Epoch 6, Batch 300] loss: 0.07912366514152382
[Epoch 6, Batch 400] loss: 0.05366923784022219
[Epoch 6, Batch 500] loss: 0.04811710706795566
[Epoch 6, Batch 600] loss: 0.06371663460391573
[Epoch 6, Batch 700] loss: 0.05724388376809657
[Epoch 6, Batch 800] loss: 0.06550400241627358
[Epoch 6, Batch 900] loss: 0.037613839462865145
[Epoch 6, Batch 1000] loss: 0.05206986009783577
[Epoch 6, Batch 1100] loss: 0.06414445360074751
[Epoch 6, Batch 1200] loss: 0.05900936650694348
[Epoch 6, Batch 1300] loss: 0.054786237417720256
[Epoch 6, Batch 1400] loss: 0.052859433324774725
[Epoch 6, Batch 1500] loss: 0.040552542068180625
[Epoch 6, Batch 1600] loss: 0.059509260466438715
[Epoch 6, Batch 1700] loss: 0.05636599771678448
[Epoch 6, Batch 1800] loss: 0.05529310175508726
[Epoch 6, Batch 1900] loss: 0.061907050560112115
[Epoch 6, Batch 2000] loss: 0.037901002008002255
[Epoch 6, Batch 2100] loss: 0.05999487085384317
[Epoch 6, Batch 2200] loss: 0.06220811439474346
[Epoch 6, Batch 2300] loss: 0.06450478509650566
[Epoch 6, Batch 2400] loss: 0.06036978643154725
[Epoch 6, Batch 2500] loss: 0.0675506660778774
[Epoch 6, Batch 2600] loss: 0.058722962688189
[Epoch 6, Batch 2700] loss: 0.07180120177741628
[Epoch 6, Batch 2800] loss: 0.04334156980970874
[Epoch 6, Batch 2900] loss: 0.05938549514510669
[Epoch 6, Batch 3000] loss: 0.04364973737450782
[Epoch 6, Batch 3100] loss: 0.05253802609426202
[Epoch 6, Batch 3200] loss: 0.053011788805015385
[Epoch 6, Batch 3300] loss: 0.057941538034938275
[Epoch 6, Batch 3400] loss: 0.05960615819494706
[Epoch 6, Batch 3500] loss: 0.06775992382725235
[Epoch 6, Batch 3600] loss: 0.06067515213449951
[Epoch 6, Batch 3700] loss: 0.07019382157013751
**STATS for Epoch 6** : 
Average training loss: 0.0008
Average validation loss: 0.0532
Overfitting: 0.0524
[Epoch 7, Batch 100] loss: 0.05080460664234124
[Epoch 7, Batch 200] loss: 0.046544960146711674
[Epoch 7, Batch 300] loss: 0.0627202006871812
[Epoch 7, Batch 400] loss: 0.04405548771610483
[Epoch 7, Batch 500] loss: 0.03675255669339094
[Epoch 7, Batch 600] loss: 0.05196053889405448
[Epoch 7, Batch 700] loss: 0.05770332580781542
[Epoch 7, Batch 800] loss: 0.06172668374318164
[Epoch 7, Batch 900] loss: 0.06134940792864654
[Epoch 7, Batch 1000] loss: 0.062387883802875875
[Epoch 7, Batch 1100] loss: 0.036598446919233536
[Epoch 7, Batch 1200] loss: 0.04863433805294335
[Epoch 7, Batch 1300] loss: 0.0498993870295817
[Epoch 7, Batch 1400] loss: 0.059432053178315986
[Epoch 7, Batch 1500] loss: 0.05814694084576331
[Epoch 7, Batch 1600] loss: 0.042947763709235004
[Epoch 7, Batch 1700] loss: 0.04838197434495669
[Epoch 7, Batch 1800] loss: 0.04087124959594803
[Epoch 7, Batch 1900] loss: 0.03969166298862547
[Epoch 7, Batch 2000] loss: 0.03936508200393291
[Epoch 7, Batch 2100] loss: 0.04641104445065139
[Epoch 7, Batch 2200] loss: 0.03956799164472614
[Epoch 7, Batch 2300] loss: 0.04202850716013927
[Epoch 7, Batch 2400] loss: 0.08976178030861774
[Epoch 7, Batch 2500] loss: 0.03241327959811315
[Epoch 7, Batch 2600] loss: 0.06541963410447352
[Epoch 7, Batch 2700] loss: 0.04561339613981545
[Epoch 7, Batch 2800] loss: 0.048982944848248736
[Epoch 7, Batch 2900] loss: 0.046485736381728204
[Epoch 7, Batch 3000] loss: 0.05234510364942253
[Epoch 7, Batch 3100] loss: 0.0693609202382504
[Epoch 7, Batch 3200] loss: 0.06549254152225331
[Epoch 7, Batch 3300] loss: 0.051298730248818175
[Epoch 7, Batch 3400] loss: 0.04626095135405194
[Epoch 7, Batch 3500] loss: 0.04783236665069126
[Epoch 7, Batch 3600] loss: 0.041667151996516626
[Epoch 7, Batch 3700] loss: 0.04792851001984673
**STATS for Epoch 7** : 
Average training loss: 0.0008
Average validation loss: 0.0539
Overfitting: 0.0530
[Epoch 8, Batch 100] loss: 0.046964448739017825
[Epoch 8, Batch 200] loss: 0.04434709023626056
[Epoch 8, Batch 300] loss: 0.043688607641961426
[Epoch 8, Batch 400] loss: 0.03487038623250555
[Epoch 8, Batch 500] loss: 0.029866050737327895
[Epoch 8, Batch 600] loss: 0.04850417629437288
[Epoch 8, Batch 700] loss: 0.05386270216375124
[Epoch 8, Batch 800] loss: 0.03853190913097933
[Epoch 8, Batch 900] loss: 0.031682745136786254
[Epoch 8, Batch 1000] loss: 0.04009350588225061
[Epoch 8, Batch 1100] loss: 0.04640169310558122
[Epoch 8, Batch 1200] loss: 0.053704951287363654
[Epoch 8, Batch 1300] loss: 0.04484112119942438
[Epoch 8, Batch 1400] loss: 0.0547713927726727
[Epoch 8, Batch 1500] loss: 0.034407233585370706
[Epoch 8, Batch 1600] loss: 0.03824678724631667
[Epoch 8, Batch 1700] loss: 0.051407446903176605
[Epoch 8, Batch 1800] loss: 0.05078030811360804
[Epoch 8, Batch 1900] loss: 0.05186101713916287
[Epoch 8, Batch 2000] loss: 0.056290317187667825
[Epoch 8, Batch 2100] loss: 0.04599141913204221
[Epoch 8, Batch 2200] loss: 0.05604760767222615
[Epoch 8, Batch 2300] loss: 0.04317556933587184
[Epoch 8, Batch 2400] loss: 0.04346569694112987
[Epoch 8, Batch 2500] loss: 0.04382062122924253
[Epoch 8, Batch 2600] loss: 0.04814546453068033
[Epoch 8, Batch 2700] loss: 0.06287377450964414
[Epoch 8, Batch 2800] loss: 0.05985372252180241
[Epoch 8, Batch 2900] loss: 0.04481448303267825
[Epoch 8, Batch 3000] loss: 0.036778201149427335
[Epoch 8, Batch 3100] loss: 0.048273338738654276
[Epoch 8, Batch 3200] loss: 0.042483242367452476
[Epoch 8, Batch 3300] loss: 0.027218125328654422
[Epoch 8, Batch 3400] loss: 0.051047108053171544
[Epoch 8, Batch 3500] loss: 0.050086230258602885
[Epoch 8, Batch 3600] loss: 0.05743240914947819
[Epoch 8, Batch 3700] loss: 0.037236507043708116
**STATS for Epoch 8** : 
Average training loss: 0.0004
Average validation loss: 0.0430
Overfitting: 0.0426
Best model saved at epoch 8 with training loss: 0.0004
[Epoch 9, Batch 100] loss: 0.04239989114488708
[Epoch 9, Batch 200] loss: 0.045363148606847974
[Epoch 9, Batch 300] loss: 0.05038291097647743
[Epoch 9, Batch 400] loss: 0.03677273191686254
[Epoch 9, Batch 500] loss: 0.039648341579595583
[Epoch 9, Batch 600] loss: 0.052914406732306817
[Epoch 9, Batch 700] loss: 0.03028983831172809
[Epoch 9, Batch 800] loss: 0.04743468137050513
[Epoch 9, Batch 900] loss: 0.044805636634700934
[Epoch 9, Batch 1000] loss: 0.0426208104705438
[Epoch 9, Batch 1100] loss: 0.032153302333317695
[Epoch 9, Batch 1200] loss: 0.03377099813325913
[Epoch 9, Batch 1300] loss: 0.03584959538624389
[Epoch 9, Batch 1400] loss: 0.037548103528097274
[Epoch 9, Batch 1500] loss: 0.034250755210523495
[Epoch 9, Batch 1600] loss: 0.03410317305533681
[Epoch 9, Batch 1700] loss: 0.04569864251388935
[Epoch 9, Batch 1800] loss: 0.061470071682997514
[Epoch 9, Batch 1900] loss: 0.05256942571868421
[Epoch 9, Batch 2000] loss: 0.04291193751094397
[Epoch 9, Batch 2100] loss: 0.05554352460661903
[Epoch 9, Batch 2200] loss: 0.03524459485721309
[Epoch 9, Batch 2300] loss: 0.0524267138162395
[Epoch 9, Batch 2400] loss: 0.04793532908777706
[Epoch 9, Batch 2500] loss: 0.03288636933779344
[Epoch 9, Batch 2600] loss: 0.04094748048781185
[Epoch 9, Batch 2700] loss: 0.05520408975018654
[Epoch 9, Batch 2800] loss: 0.04817659659835044
[Epoch 9, Batch 2900] loss: 0.027769618202582932
[Epoch 9, Batch 3000] loss: 0.042561576831212734
[Epoch 9, Batch 3100] loss: 0.03747806849220069
[Epoch 9, Batch 3200] loss: 0.03431760291918181
[Epoch 9, Batch 3300] loss: 0.04203885138675105
[Epoch 9, Batch 3400] loss: 0.03514857068745186
[Epoch 9, Batch 3500] loss: 0.025745982260268648
[Epoch 9, Batch 3600] loss: 0.04080892298348772
[Epoch 9, Batch 3700] loss: 0.04220162241123035
**STATS for Epoch 9** : 
Average training loss: 0.0007
Average validation loss: 0.0384
Overfitting: 0.0377
[Epoch 10, Batch 100] loss: 0.04036266700728447
[Epoch 10, Batch 200] loss: 0.0471660483040614
[Epoch 10, Batch 300] loss: 0.021966085504100192
[Epoch 10, Batch 400] loss: 0.03477127683785511
[Epoch 10, Batch 500] loss: 0.03546811208681902
[Epoch 10, Batch 600] loss: 0.03194529650529148
[Epoch 10, Batch 700] loss: 0.030164099396351958
[Epoch 10, Batch 800] loss: 0.029238086910627317
[Epoch 10, Batch 900] loss: 0.04109672094818961
[Epoch 10, Batch 1000] loss: 0.025791634635388618
[Epoch 10, Batch 1100] loss: 0.02482800179393962
[Epoch 10, Batch 1200] loss: 0.029863819039601367
[Epoch 10, Batch 1300] loss: 0.03591875201862422
[Epoch 10, Batch 1400] loss: 0.03756246689328691
[Epoch 10, Batch 1500] loss: 0.033915203539072535
[Epoch 10, Batch 1600] loss: 0.03507179728272604
[Epoch 10, Batch 1700] loss: 0.028112420009856576
[Epoch 10, Batch 1800] loss: 0.02998680887525552
[Epoch 10, Batch 1900] loss: 0.04706999342975905
[Epoch 10, Batch 2000] loss: 0.041297549977025484
[Epoch 10, Batch 2100] loss: 0.04911262603840441
[Epoch 10, Batch 2200] loss: 0.03645054762775544
[Epoch 10, Batch 2300] loss: 0.03629892550816294
[Epoch 10, Batch 2400] loss: 0.04120899623725563
[Epoch 10, Batch 2500] loss: 0.04761449226614786
[Epoch 10, Batch 2600] loss: 0.03817658493382623
[Epoch 10, Batch 2700] loss: 0.030759052283829077
[Epoch 10, Batch 2800] loss: 0.04414635535998968
[Epoch 10, Batch 2900] loss: 0.03622891261155019
[Epoch 10, Batch 3000] loss: 0.04457739058721927
[Epoch 10, Batch 3100] loss: 0.03739409281872213
[Epoch 10, Batch 3200] loss: 0.04587778398708906
[Epoch 10, Batch 3300] loss: 0.03956486657145433
[Epoch 10, Batch 3400] loss: 0.03334337811858859
[Epoch 10, Batch 3500] loss: 0.04316202596237417
[Epoch 10, Batch 3600] loss: 0.03968924438231625
[Epoch 10, Batch 3700] loss: 0.04858265915114316
**STATS for Epoch 10** : 
Average training loss: 0.0007
Average validation loss: 0.0415
Overfitting: 0.0407
[Epoch 11, Batch 100] loss: 0.027040988592780195
[Epoch 11, Batch 200] loss: 0.02030121528689051
[Epoch 11, Batch 300] loss: 0.03523244330543093
[Epoch 11, Batch 400] loss: 0.044666177565522956
[Epoch 11, Batch 500] loss: 0.03635602861875668
[Epoch 11, Batch 600] loss: 0.04297648445644882
[Epoch 11, Batch 700] loss: 0.03957970299408771
[Epoch 11, Batch 800] loss: 0.036787262468133124
[Epoch 11, Batch 900] loss: 0.03346898975330987
[Epoch 11, Batch 1000] loss: 0.03648711483809166
[Epoch 11, Batch 1100] loss: 0.03204634374647867
[Epoch 11, Batch 1200] loss: 0.02534187567915069
[Epoch 11, Batch 1300] loss: 0.027050636968342586
[Epoch 11, Batch 1400] loss: 0.032877331749186854
[Epoch 11, Batch 1500] loss: 0.031096850595786235
[Epoch 11, Batch 1600] loss: 0.025797005059866932
[Epoch 11, Batch 1700] loss: 0.033518634238062076
[Epoch 11, Batch 1800] loss: 0.02648306094459258
[Epoch 11, Batch 1900] loss: 0.04192468837980414
[Epoch 11, Batch 2000] loss: 0.03740916357026435
[Epoch 11, Batch 2100] loss: 0.04252847830211977
[Epoch 11, Batch 2200] loss: 0.036028089436440494
[Epoch 11, Batch 2300] loss: 0.03268570922635263
[Epoch 11, Batch 2400] loss: 0.04065995530429063
[Epoch 11, Batch 2500] loss: 0.02074688804350444
[Epoch 11, Batch 2600] loss: 0.03392784405004932
[Epoch 11, Batch 2700] loss: 0.03864286922194879
[Epoch 11, Batch 2800] loss: 0.024795526441157564
[Epoch 11, Batch 2900] loss: 0.03843640585328103
[Epoch 11, Batch 3000] loss: 0.027734535000345204
[Epoch 11, Batch 3100] loss: 0.03240865184256109
[Epoch 11, Batch 3200] loss: 0.0279609027980041
[Epoch 11, Batch 3300] loss: 0.03299916327989195
[Epoch 11, Batch 3400] loss: 0.05278749095421517
[Epoch 11, Batch 3500] loss: 0.0422917276804219
[Epoch 11, Batch 3600] loss: 0.03446443860491854
[Epoch 11, Batch 3700] loss: 0.03586035168904345
**STATS for Epoch 11** : 
Average training loss: 0.0003
Average validation loss: 0.0357
Overfitting: 0.0354
Best model saved at epoch 11 with training loss: 0.0003
[Epoch 12, Batch 100] loss: 0.03254089727153769
[Epoch 12, Batch 200] loss: 0.021829982723720606
[Epoch 12, Batch 300] loss: 0.03329921590397134
[Epoch 12, Batch 400] loss: 0.04618991644791095
[Epoch 12, Batch 500] loss: 0.03566612037131563
[Epoch 12, Batch 600] loss: 0.035635123562533406
[Epoch 12, Batch 700] loss: 0.02767266979557462
[Epoch 12, Batch 800] loss: 0.0251127446081955
[Epoch 12, Batch 900] loss: 0.027042607059702278
[Epoch 12, Batch 1000] loss: 0.03013336438452825
[Epoch 12, Batch 1100] loss: 0.030456605946092168
[Epoch 12, Batch 1200] loss: 0.020792424293758813
[Epoch 12, Batch 1300] loss: 0.04002673412731383
[Epoch 12, Batch 1400] loss: 0.031879116730269746
[Epoch 12, Batch 1500] loss: 0.028632672596286282
[Epoch 12, Batch 1600] loss: 0.027347045723581688
[Epoch 12, Batch 1700] loss: 0.03473959787472267
[Epoch 12, Batch 1800] loss: 0.039322539744898674
[Epoch 12, Batch 1900] loss: 0.030647914953297006
[Epoch 12, Batch 2000] loss: 0.03367116817389615
[Epoch 12, Batch 2100] loss: 0.026341974327951902
[Epoch 12, Batch 2200] loss: 0.019857360869573314
[Epoch 12, Batch 2300] loss: 0.026147700023357173
[Epoch 12, Batch 2400] loss: 0.026257298626660486
[Epoch 12, Batch 2500] loss: 0.037184569335659036
[Epoch 12, Batch 2600] loss: 0.03274036624876317
[Epoch 12, Batch 2700] loss: 0.04069473842697335
[Epoch 12, Batch 2800] loss: 0.021163886481517694
[Epoch 12, Batch 2900] loss: 0.04820136679569259
[Epoch 12, Batch 3000] loss: 0.02307331987278303
[Epoch 12, Batch 3100] loss: 0.036396182102034796
[Epoch 12, Batch 3200] loss: 0.027801122442033376
[Epoch 12, Batch 3300] loss: 0.03261215038000955
[Epoch 12, Batch 3400] loss: 0.03633649846276967
[Epoch 12, Batch 3500] loss: 0.025092261968093225
[Epoch 12, Batch 3600] loss: 0.026271672275906894
[Epoch 12, Batch 3700] loss: 0.017996909034409328
**STATS for Epoch 12** : 
Average training loss: 0.0007
Average validation loss: 0.0351
Overfitting: 0.0344
[Epoch 13, Batch 100] loss: 0.023075031352054794
[Epoch 13, Batch 200] loss: 0.02824131981771643
[Epoch 13, Batch 300] loss: 0.02607825874001719
[Epoch 13, Batch 400] loss: 0.023121430217724993
[Epoch 13, Batch 500] loss: 0.02049100810487289
[Epoch 13, Batch 600] loss: 0.031430361736856864
[Epoch 13, Batch 700] loss: 0.027663726569735446
[Epoch 13, Batch 800] loss: 0.024363167795818298
[Epoch 13, Batch 900] loss: 0.03784099811426131
[Epoch 13, Batch 1000] loss: 0.021152870722144144
[Epoch 13, Batch 1100] loss: 0.029951861431181896
[Epoch 13, Batch 1200] loss: 0.027001477985322708
[Epoch 13, Batch 1300] loss: 0.03415265635761898
[Epoch 13, Batch 1400] loss: 0.02230329421159695
[Epoch 13, Batch 1500] loss: 0.026248008561087773
[Epoch 13, Batch 1600] loss: 0.024687314971379236
[Epoch 13, Batch 1700] loss: 0.026454839882062514
[Epoch 13, Batch 1800] loss: 0.030544915305144967
[Epoch 13, Batch 1900] loss: 0.03573949759134848
[Epoch 13, Batch 2000] loss: 0.020323754726196058
[Epoch 13, Batch 2100] loss: 0.03196389447330148
[Epoch 13, Batch 2200] loss: 0.023138186358955863
[Epoch 13, Batch 2300] loss: 0.03577464484420489
[Epoch 13, Batch 2400] loss: 0.02735184101125924
[Epoch 13, Batch 2500] loss: 0.022992280909384134
[Epoch 13, Batch 2600] loss: 0.028564350275846664
[Epoch 13, Batch 2700] loss: 0.02719334152629017
[Epoch 13, Batch 2800] loss: 0.03139142236293992
[Epoch 13, Batch 2900] loss: 0.025617893152375473
[Epoch 13, Batch 3000] loss: 0.0319516700837994
[Epoch 13, Batch 3100] loss: 0.03617593144401326
[Epoch 13, Batch 3200] loss: 0.03724369921859761
[Epoch 13, Batch 3300] loss: 0.024906003462383523
[Epoch 13, Batch 3400] loss: 0.025639101392298472
[Epoch 13, Batch 3500] loss: 0.04267269316216698
[Epoch 13, Batch 3600] loss: 0.023542492218402912
[Epoch 13, Batch 3700] loss: 0.03338315051994869
**STATS for Epoch 13** : 
Average training loss: 0.0005
Average validation loss: 0.0354
Overfitting: 0.0349
[Epoch 14, Batch 100] loss: 0.022407176700944546
[Epoch 14, Batch 200] loss: 0.021701833806582728
[Epoch 14, Batch 300] loss: 0.01642860432039015
[Epoch 14, Batch 400] loss: 0.029828757793584373
[Epoch 14, Batch 500] loss: 0.0269976864970522
[Epoch 14, Batch 600] loss: 0.020705492352717556
[Epoch 14, Batch 700] loss: 0.026066397189497367
[Epoch 14, Batch 800] loss: 0.025075697473366746
[Epoch 14, Batch 900] loss: 0.03759579937992385
[Epoch 14, Batch 1000] loss: 0.02801250091575639
[Epoch 14, Batch 1100] loss: 0.023348602746264078
[Epoch 14, Batch 1200] loss: 0.03712879713624716
[Epoch 14, Batch 1300] loss: 0.02619928479907685
[Epoch 14, Batch 1400] loss: 0.02111218099234975
[Epoch 14, Batch 1500] loss: 0.04064332777204981
[Epoch 14, Batch 1600] loss: 0.028829789270239416
[Epoch 14, Batch 1700] loss: 0.029899395451211605
[Epoch 14, Batch 1800] loss: 0.025592912736537982
[Epoch 14, Batch 1900] loss: 0.031365288149536354
[Epoch 14, Batch 2000] loss: 0.029669008363343893
[Epoch 14, Batch 2100] loss: 0.03098635612470389
[Epoch 14, Batch 2200] loss: 0.022549765971270973
[Epoch 14, Batch 2300] loss: 0.02020877945557004
[Epoch 14, Batch 2400] loss: 0.023471725041454193
[Epoch 14, Batch 2500] loss: 0.021681093185397914
[Epoch 14, Batch 2600] loss: 0.036050216876901686
[Epoch 14, Batch 2700] loss: 0.0206186468629312
[Epoch 14, Batch 2800] loss: 0.027185965363642026
[Epoch 14, Batch 2900] loss: 0.027034689770662226
[Epoch 14, Batch 3000] loss: 0.03271953361458145
[Epoch 14, Batch 3100] loss: 0.022236567326399382
[Epoch 14, Batch 3200] loss: 0.029825483864333365
[Epoch 14, Batch 3300] loss: 0.01567961931039463
[Epoch 14, Batch 3400] loss: 0.01995107446957263
[Epoch 14, Batch 3500] loss: 0.024498408638683033
[Epoch 14, Batch 3600] loss: 0.03780449239311565
[Epoch 14, Batch 3700] loss: 0.024411638546152973
**STATS for Epoch 14** : 
Average training loss: 0.0002
Average validation loss: 0.0319
Overfitting: 0.0317
Best model saved at epoch 14 with training loss: 0.0002
[Epoch 15, Batch 100] loss: 0.021220979912759504
[Epoch 15, Batch 200] loss: 0.022436649626397413
[Epoch 15, Batch 300] loss: 0.021902698690391843
[Epoch 15, Batch 400] loss: 0.029511226072645513
[Epoch 15, Batch 500] loss: 0.03082177548742038
[Epoch 15, Batch 600] loss: 0.03170707088997005
[Epoch 15, Batch 700] loss: 0.03095082185645879
[Epoch 15, Batch 800] loss: 0.017853973701858195
[Epoch 15, Batch 900] loss: 0.024131546369753776
[Epoch 15, Batch 1000] loss: 0.02467704543902073
[Epoch 15, Batch 1100] loss: 0.019593132392910776
[Epoch 15, Batch 1200] loss: 0.015137347339477856
[Epoch 15, Batch 1300] loss: 0.02540300831071363
[Epoch 15, Batch 1400] loss: 0.020948320769457497
[Epoch 15, Batch 1500] loss: 0.02460262375683669
[Epoch 15, Batch 1600] loss: 0.027746304636239075
[Epoch 15, Batch 1700] loss: 0.01761283444468063
[Epoch 15, Batch 1800] loss: 0.016998774858075195
[Epoch 15, Batch 1900] loss: 0.022166938695299905
[Epoch 15, Batch 2000] loss: 0.024389828870480416
[Epoch 15, Batch 2100] loss: 0.029672121076728217
[Epoch 15, Batch 2200] loss: 0.026261399568611524
[Epoch 15, Batch 2300] loss: 0.016618796880793527
[Epoch 15, Batch 2400] loss: 0.025892389693171935
[Epoch 15, Batch 2500] loss: 0.02665282902042236
[Epoch 15, Batch 2600] loss: 0.022451562037240365
[Epoch 15, Batch 2700] loss: 0.03948647158802487
[Epoch 15, Batch 2800] loss: 0.02167723736514745
[Epoch 15, Batch 2900] loss: 0.029508836489985698
[Epoch 15, Batch 3000] loss: 0.023000738423797885
[Epoch 15, Batch 3100] loss: 0.018078751476023173
[Epoch 15, Batch 3200] loss: 0.025374457571160747
[Epoch 15, Batch 3300] loss: 0.024230483008141165
[Epoch 15, Batch 3400] loss: 0.026873317520366983
[Epoch 15, Batch 3500] loss: 0.024384729565717862
[Epoch 15, Batch 3600] loss: 0.0234672566669542
[Epoch 15, Batch 3700] loss: 0.02863332477165386
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0376
Overfitting: 0.0371
[Epoch 16, Batch 100] loss: 0.02008019271052035
[Epoch 16, Batch 200] loss: 0.013352133484440856
[Epoch 16, Batch 300] loss: 0.016428747048339572
[Epoch 16, Batch 400] loss: 0.027873748696729306
[Epoch 16, Batch 500] loss: 0.02630876161609194
[Epoch 16, Batch 600] loss: 0.029867821960069704
[Epoch 16, Batch 700] loss: 0.017090756671605048
[Epoch 16, Batch 800] loss: 0.014678521899386397
[Epoch 16, Batch 900] loss: 0.02182706560837687
[Epoch 16, Batch 1000] loss: 0.020110691807130935
[Epoch 16, Batch 1100] loss: 0.017534671351695577
[Epoch 16, Batch 1200] loss: 0.02221705877469503
[Epoch 16, Batch 1300] loss: 0.024635668093833375
[Epoch 16, Batch 1400] loss: 0.015453807914673235
[Epoch 16, Batch 1500] loss: 0.017556285063674296
[Epoch 16, Batch 1600] loss: 0.018050157316247352
[Epoch 16, Batch 1700] loss: 0.026421538085814975
[Epoch 16, Batch 1800] loss: 0.026905438949979724
[Epoch 16, Batch 1900] loss: 0.03090528231330609
[Epoch 16, Batch 2000] loss: 0.02295151248734328
[Epoch 16, Batch 2100] loss: 0.0199674614525793
[Epoch 16, Batch 2200] loss: 0.03147730841985322
[Epoch 16, Batch 2300] loss: 0.026791812624596786
[Epoch 16, Batch 2400] loss: 0.028447173062741058
[Epoch 16, Batch 2500] loss: 0.030100865738495484
[Epoch 16, Batch 2600] loss: 0.018706878550801775
[Epoch 16, Batch 2700] loss: 0.02427263345787651
[Epoch 16, Batch 2800] loss: 0.04303828767253435
[Epoch 16, Batch 2900] loss: 0.017287041343042802
[Epoch 16, Batch 3000] loss: 0.02145928955505951
[Epoch 16, Batch 3100] loss: 0.017809189514773605
[Epoch 16, Batch 3200] loss: 0.01826739814689063
[Epoch 16, Batch 3300] loss: 0.02057479883922497
[Epoch 16, Batch 3400] loss: 0.020850679840514204
[Epoch 16, Batch 3500] loss: 0.017073215576747316
[Epoch 16, Batch 3600] loss: 0.016894240532928963
[Epoch 16, Batch 3700] loss: 0.027091578483086777
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0347
Overfitting: 0.0343
[Epoch 17, Batch 100] loss: 0.02159589877956023
[Epoch 17, Batch 200] loss: 0.012957808142455179
[Epoch 17, Batch 300] loss: 0.017038552267404156
[Epoch 17, Batch 400] loss: 0.032603158569472726
[Epoch 17, Batch 500] loss: 0.016665904558904
[Epoch 17, Batch 600] loss: 0.024350842438179823
[Epoch 17, Batch 700] loss: 0.026446814699811513
[Epoch 17, Batch 800] loss: 0.017114438329444967
[Epoch 17, Batch 900] loss: 0.018487669174173788
[Epoch 17, Batch 1000] loss: 0.020090666050600704
[Epoch 17, Batch 1100] loss: 0.03751419786731276
[Epoch 17, Batch 1200] loss: 0.01726340764631459
[Epoch 17, Batch 1300] loss: 0.02040578405416454
[Epoch 17, Batch 1400] loss: 0.01293816938821692
[Epoch 17, Batch 1500] loss: 0.018529601732152515
[Epoch 17, Batch 1600] loss: 0.01596885240964184
[Epoch 17, Batch 1700] loss: 0.013684186011669226
[Epoch 17, Batch 1800] loss: 0.027269379426397792
[Epoch 17, Batch 1900] loss: 0.019583428856276442
[Epoch 17, Batch 2000] loss: 0.020900598913867724
[Epoch 17, Batch 2100] loss: 0.01827466310009186
[Epoch 17, Batch 2200] loss: 0.02141274255080134
[Epoch 17, Batch 2300] loss: 0.026509968231548556
[Epoch 17, Batch 2400] loss: 0.016069442851367056
[Epoch 17, Batch 2500] loss: 0.025923955713660688
[Epoch 17, Batch 2600] loss: 0.020006144538529044
[Epoch 17, Batch 2700] loss: 0.018636712515799445
[Epoch 17, Batch 2800] loss: 0.012823704945622011
[Epoch 17, Batch 2900] loss: 0.03279232584771307
[Epoch 17, Batch 3000] loss: 0.01237203402302839
[Epoch 17, Batch 3100] loss: 0.025278302831356996
[Epoch 17, Batch 3200] loss: 0.023795518639235524
[Epoch 17, Batch 3300] loss: 0.008404230939486296
[Epoch 17, Batch 3400] loss: 0.020232660745168687
[Epoch 17, Batch 3500] loss: 0.02042846964985074
[Epoch 17, Batch 3600] loss: 0.02980184993655712
[Epoch 17, Batch 3700] loss: 0.022783373669808496
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0492
Overfitting: 0.0488
[Epoch 18, Batch 100] loss: 0.012274482455541146
[Epoch 18, Batch 200] loss: 0.017405947021834435
[Epoch 18, Batch 300] loss: 0.014067717573998379
[Epoch 18, Batch 400] loss: 0.026616477174829924
[Epoch 18, Batch 500] loss: 0.01864864355620739
[Epoch 18, Batch 600] loss: 0.018931061578914523
[Epoch 18, Batch 700] loss: 0.030339325574750546
[Epoch 18, Batch 800] loss: 0.01214128535370037
[Epoch 18, Batch 900] loss: 0.022856386616949748
[Epoch 18, Batch 1000] loss: 0.014256272509883275
[Epoch 18, Batch 1100] loss: 0.012974737719014228
[Epoch 18, Batch 1200] loss: 0.020095055122765187
[Epoch 18, Batch 1300] loss: 0.023052896066510585
[Epoch 18, Batch 1400] loss: 0.019050980906285986
[Epoch 18, Batch 1500] loss: 0.014056640079361386
[Epoch 18, Batch 1600] loss: 0.02254124227909415
[Epoch 18, Batch 1700] loss: 0.011333723808274954
[Epoch 18, Batch 1800] loss: 0.01740649725881667
[Epoch 18, Batch 1900] loss: 0.015436581716603542
[Epoch 18, Batch 2000] loss: 0.021067492814036085
[Epoch 18, Batch 2100] loss: 0.032537975797240506
[Epoch 18, Batch 2200] loss: 0.006431847204148653
[Epoch 18, Batch 2300] loss: 0.010144895231132978
[Epoch 18, Batch 2400] loss: 0.028349773383451973
[Epoch 18, Batch 2500] loss: 0.014163534673862159
[Epoch 18, Batch 2600] loss: 0.018901079826318893
[Epoch 18, Batch 2700] loss: 0.021343574787169927
[Epoch 18, Batch 2800] loss: 0.03293197666091146
[Epoch 18, Batch 2900] loss: 0.016215971920173614
[Epoch 18, Batch 3000] loss: 0.01689978509886714
[Epoch 18, Batch 3100] loss: 0.02054889912280487
[Epoch 18, Batch 3200] loss: 0.015631548835717695
[Epoch 18, Batch 3300] loss: 0.01708017430775726
[Epoch 18, Batch 3400] loss: 0.03577329118081252
[Epoch 18, Batch 3500] loss: 0.02548390403389931
[Epoch 18, Batch 3600] loss: 0.020402483073812618
[Epoch 18, Batch 3700] loss: 0.01689853312986088
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0331
Overfitting: 0.0329
Best model saved at epoch 18 with training loss: 0.0002
[Epoch 19, Batch 100] loss: 0.02431084307569108
[Epoch 19, Batch 200] loss: 0.010797861067840132
[Epoch 19, Batch 300] loss: 0.011168266673439575
[Epoch 19, Batch 400] loss: 0.014125956780917477
[Epoch 19, Batch 500] loss: 0.01463710114310743
[Epoch 19, Batch 600] loss: 0.02580767327650392
[Epoch 19, Batch 700] loss: 0.023160335812572156
[Epoch 19, Batch 800] loss: 0.010970276863554318
[Epoch 19, Batch 900] loss: 0.009082659130217507
[Epoch 19, Batch 1000] loss: 0.014824484272648987
[Epoch 19, Batch 1100] loss: 0.015139683652623716
[Epoch 19, Batch 1200] loss: 0.013119340433258913
[Epoch 19, Batch 1300] loss: 0.01895639428124923
[Epoch 19, Batch 1400] loss: 0.019062754279875662
[Epoch 19, Batch 1500] loss: 0.009739356712525477
[Epoch 19, Batch 1600] loss: 0.01644071081202128
[Epoch 19, Batch 1700] loss: 0.01756404645875591
[Epoch 19, Batch 1800] loss: 0.018344523322193707
[Epoch 19, Batch 1900] loss: 0.03517251783734537
[Epoch 19, Batch 2000] loss: 0.01491869857069105
[Epoch 19, Batch 2100] loss: 0.017110305559945117
[Epoch 19, Batch 2200] loss: 0.015712143537857628
[Epoch 19, Batch 2300] loss: 0.00880925554632995
[Epoch 19, Batch 2400] loss: 0.013462671142779072
[Epoch 19, Batch 2500] loss: 0.017455994327319785
[Epoch 19, Batch 2600] loss: 0.01202261676065973
[Epoch 19, Batch 2700] loss: 0.019120059710912754
[Epoch 19, Batch 2800] loss: 0.028123952588430257
[Epoch 19, Batch 2900] loss: 0.01922676375901574
[Epoch 19, Batch 3000] loss: 0.028349232413274875
[Epoch 19, Batch 3100] loss: 0.014397169531584951
[Epoch 19, Batch 3200] loss: 0.014578004246614
[Epoch 19, Batch 3300] loss: 0.023047629016164136
[Epoch 19, Batch 3400] loss: 0.0185951856312613
[Epoch 19, Batch 3500] loss: 0.01731653496302897
[Epoch 19, Batch 3600] loss: 0.02109567100607819
[Epoch 19, Batch 3700] loss: 0.022705589285360473
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0379
Overfitting: 0.0376
[Epoch 20, Batch 100] loss: 0.01387268148819203
[Epoch 20, Batch 200] loss: 0.01577932378062542
[Epoch 20, Batch 300] loss: 0.02055932239336471
[Epoch 20, Batch 400] loss: 0.016629272603804566
[Epoch 20, Batch 500] loss: 0.009416684502693897
[Epoch 20, Batch 600] loss: 0.01071663245678792
[Epoch 20, Batch 700] loss: 0.012889190967034664
[Epoch 20, Batch 800] loss: 0.015739722045364033
[Epoch 20, Batch 900] loss: 0.020794318923835816
[Epoch 20, Batch 1000] loss: 0.012876555390939758
[Epoch 20, Batch 1100] loss: 0.017765107816667295
[Epoch 20, Batch 1200] loss: 0.016540145440631024
[Epoch 20, Batch 1300] loss: 0.01574280459773945
[Epoch 20, Batch 1400] loss: 0.010419093185046222
[Epoch 20, Batch 1500] loss: 0.016555987731426285
[Epoch 20, Batch 1600] loss: 0.013411726624726726
[Epoch 20, Batch 1700] loss: 0.017962740070688595
[Epoch 20, Batch 1800] loss: 0.011267915635362441
[Epoch 20, Batch 1900] loss: 0.013542793411252205
[Epoch 20, Batch 2000] loss: 0.021866955535151646
[Epoch 20, Batch 2100] loss: 0.016067421963489325
[Epoch 20, Batch 2200] loss: 0.012690029955333557
[Epoch 20, Batch 2300] loss: 0.016235732237419143
[Epoch 20, Batch 2400] loss: 0.018544458083124483
[Epoch 20, Batch 2500] loss: 0.014893008401340922
[Epoch 20, Batch 2600] loss: 0.022686900156113552
[Epoch 20, Batch 2700] loss: 0.016385076026563184
[Epoch 20, Batch 2800] loss: 0.020839508236895198
[Epoch 20, Batch 2900] loss: 0.0065666170646363755
[Epoch 20, Batch 3000] loss: 0.014335880638100207
[Epoch 20, Batch 3100] loss: 0.01743413532842169
[Epoch 20, Batch 3200] loss: 0.01548337146441554
[Epoch 20, Batch 3300] loss: 0.015950479986713617
[Epoch 20, Batch 3400] loss: 0.014001983441703487
[Epoch 20, Batch 3500] loss: 0.021529105768768205
[Epoch 20, Batch 3600] loss: 0.02352036209385915
[Epoch 20, Batch 3700] loss: 0.02527725423376978
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0384
Overfitting: 0.0381
[Epoch 21, Batch 100] loss: 0.0163761327436805
[Epoch 21, Batch 200] loss: 0.016304923607603997
[Epoch 21, Batch 300] loss: 0.012786682022306196
[Epoch 21, Batch 400] loss: 0.01121000699022261
[Epoch 21, Batch 500] loss: 0.022245635982853854
[Epoch 21, Batch 600] loss: 0.01201068596847108
[Epoch 21, Batch 700] loss: 0.022590368308237886
[Epoch 21, Batch 800] loss: 0.016851909491178957
[Epoch 21, Batch 900] loss: 0.013177173299227433
[Epoch 21, Batch 1000] loss: 0.018359811070477006
[Epoch 21, Batch 1100] loss: 0.013411997273324231
[Epoch 21, Batch 1200] loss: 0.01273684967562076
[Epoch 21, Batch 1300] loss: 0.009112813873634877
[Epoch 21, Batch 1400] loss: 0.010445842881963471
[Epoch 21, Batch 1500] loss: 0.01060274164292423
[Epoch 21, Batch 1600] loss: 0.01706460423181852
[Epoch 21, Batch 1700] loss: 0.009047968232698623
[Epoch 21, Batch 1800] loss: 0.016666202225751478
[Epoch 21, Batch 1900] loss: 0.015544470255899796
[Epoch 21, Batch 2000] loss: 0.012522813764953754
[Epoch 21, Batch 2100] loss: 0.018486864575970686
[Epoch 21, Batch 2200] loss: 0.01433601693774108
[Epoch 21, Batch 2300] loss: 0.024512332547565165
[Epoch 21, Batch 2400] loss: 0.015502648650908668
[Epoch 21, Batch 2500] loss: 0.01578158908207115
[Epoch 21, Batch 2600] loss: 0.01564305032545235
[Epoch 21, Batch 2700] loss: 0.01981921869544749
[Epoch 21, Batch 2800] loss: 0.012187845326498064
[Epoch 21, Batch 2900] loss: 0.01418443092770758
[Epoch 21, Batch 3000] loss: 0.015494216640472586
[Epoch 21, Batch 3100] loss: 0.009503768308641157
[Epoch 21, Batch 3200] loss: 0.010780278474849183
[Epoch 21, Batch 3300] loss: 0.017344638505965123
[Epoch 21, Batch 3400] loss: 0.01637347593154118
[Epoch 21, Batch 3500] loss: 0.014090434278691645
[Epoch 21, Batch 3600] loss: 0.02267026094148605
[Epoch 21, Batch 3700] loss: 0.024119330980611267
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0388
Overfitting: 0.0385
[Epoch 22, Batch 100] loss: 0.009873761545131856
[Epoch 22, Batch 200] loss: 0.009796038559488806
[Epoch 22, Batch 300] loss: 0.017462940370169235
[Epoch 22, Batch 400] loss: 0.013098479490836326
[Epoch 22, Batch 500] loss: 0.014506481797998277
[Epoch 22, Batch 600] loss: 0.013688296062064183
[Epoch 22, Batch 700] loss: 0.013409822393477953
[Epoch 22, Batch 800] loss: 0.02178809611061297
[Epoch 22, Batch 900] loss: 0.02329045868540561
[Epoch 22, Batch 1000] loss: 0.013888836992628058
[Epoch 22, Batch 1100] loss: 0.017084367863117223
[Epoch 22, Batch 1200] loss: 0.012521731821616413
[Epoch 22, Batch 1300] loss: 0.007482631084476452
[Epoch 22, Batch 1400] loss: 0.013255148179814569
[Epoch 22, Batch 1500] loss: 0.009653787425213523
[Epoch 22, Batch 1600] loss: 0.013252567742965767
[Epoch 22, Batch 1700] loss: 0.010693688795236085
[Epoch 22, Batch 1800] loss: 0.020606719642591996
[Epoch 22, Batch 1900] loss: 0.012358779934966152
[Epoch 22, Batch 2000] loss: 0.013035292069725984
[Epoch 22, Batch 2100] loss: 0.01299948564314036
[Epoch 22, Batch 2200] loss: 0.011566342826026811
[Epoch 22, Batch 2300] loss: 0.015233865342261198
[Epoch 22, Batch 2400] loss: 0.023582047516010788
[Epoch 22, Batch 2500] loss: 0.009811880163247223
[Epoch 22, Batch 2600] loss: 0.0068644307868089526
[Epoch 22, Batch 2700] loss: 0.01357793150492398
[Epoch 22, Batch 2800] loss: 0.02860466530166377
[Epoch 22, Batch 2900] loss: 0.020435583174776183
[Epoch 22, Batch 3000] loss: 0.010322075498897902
[Epoch 22, Batch 3100] loss: 0.018721850193542194
[Epoch 22, Batch 3200] loss: 0.02337706649941538
[Epoch 22, Batch 3300] loss: 0.020123720426781802
[Epoch 22, Batch 3400] loss: 0.011621918814562378
[Epoch 22, Batch 3500] loss: 0.00911734052160682
[Epoch 22, Batch 3600] loss: 0.010790788855019854
[Epoch 22, Batch 3700] loss: 0.008465411592096643
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0339
Overfitting: 0.0335
[Epoch 23, Batch 100] loss: 0.010234934549116588
[Epoch 23, Batch 200] loss: 0.007749847689956369
[Epoch 23, Batch 300] loss: 0.009770993132315197
[Epoch 23, Batch 400] loss: 0.007441431695824576
[Epoch 23, Batch 500] loss: 0.01686142629816459
[Epoch 23, Batch 600] loss: 0.008583484112950828
[Epoch 23, Batch 700] loss: 0.014189749983879665
[Epoch 23, Batch 800] loss: 0.010297789970627491
[Epoch 23, Batch 900] loss: 0.00994191128451348
[Epoch 23, Batch 1000] loss: 0.010577573965274496
[Epoch 23, Batch 1100] loss: 0.005295642866117305
[Epoch 23, Batch 1200] loss: 0.015577281693313126
[Epoch 23, Batch 1300] loss: 0.010661867121661998
[Epoch 23, Batch 1400] loss: 0.0065391897921654165
[Epoch 23, Batch 1500] loss: 0.010257814077831426
[Epoch 23, Batch 1600] loss: 0.011593405341809557
[Epoch 23, Batch 1700] loss: 0.011988251700422552
[Epoch 23, Batch 1800] loss: 0.015208870453427607
[Epoch 23, Batch 1900] loss: 0.016956326071958756
[Epoch 23, Batch 2000] loss: 0.016079794574852712
[Epoch 23, Batch 2100] loss: 0.013002558209300331
[Epoch 23, Batch 2200] loss: 0.013220589114580435
[Epoch 23, Batch 2300] loss: 0.010956031486712163
[Epoch 23, Batch 2400] loss: 0.012282608552341116
[Epoch 23, Batch 2500] loss: 0.010361967997359898
[Epoch 23, Batch 2600] loss: 0.017267434795048758
[Epoch 23, Batch 2700] loss: 0.011797815362779147
[Epoch 23, Batch 2800] loss: 0.00776253654694301
[Epoch 23, Batch 2900] loss: 0.021277582719540077
[Epoch 23, Batch 3000] loss: 0.01022046600912745
[Epoch 23, Batch 3100] loss: 0.01693353472805029
[Epoch 23, Batch 3200] loss: 0.011675757327966494
[Epoch 23, Batch 3300] loss: 0.018333016416149803
[Epoch 23, Batch 3400] loss: 0.014485997195442905
[Epoch 23, Batch 3500] loss: 0.009282868704467546
[Epoch 23, Batch 3600] loss: 0.009456511571752344
[Epoch 23, Batch 3700] loss: 0.02401088523583894
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0382
Overfitting: 0.0378
[Epoch 24, Batch 100] loss: 0.016077687512151898
[Epoch 24, Batch 200] loss: 0.010955531137160506
[Epoch 24, Batch 300] loss: 0.012681970453559187
[Epoch 24, Batch 400] loss: 0.015468487166599517
[Epoch 24, Batch 500] loss: 0.010316122576641646
[Epoch 24, Batch 600] loss: 0.00701433933352746
[Epoch 24, Batch 700] loss: 0.007666467991930404
[Epoch 24, Batch 800] loss: 0.007165709636392421
[Epoch 24, Batch 900] loss: 0.009711425033829072
[Epoch 24, Batch 1000] loss: 0.00741661099272278
[Epoch 24, Batch 1100] loss: 0.00779094192550474
[Epoch 24, Batch 1200] loss: 0.008990762208586602
[Epoch 24, Batch 1300] loss: 0.009613491340296605
[Epoch 24, Batch 1400] loss: 0.022585155026217763
[Epoch 24, Batch 1500] loss: 0.015857142681961704
[Epoch 24, Batch 1600] loss: 0.009449136725897915
[Epoch 24, Batch 1700] loss: 0.012197772131321472
[Epoch 24, Batch 1800] loss: 0.012040682367933186
[Epoch 24, Batch 1900] loss: 0.016846668738717197
[Epoch 24, Batch 2000] loss: 0.01030187134814696
[Epoch 24, Batch 2100] loss: 0.0069124363996525065
[Epoch 24, Batch 2200] loss: 0.01440122075870022
[Epoch 24, Batch 2300] loss: 0.022930805741125368
[Epoch 24, Batch 2400] loss: 0.021752319701881788
[Epoch 24, Batch 2500] loss: 0.012476305178734038
[Epoch 24, Batch 2600] loss: 0.014481508441940604
[Epoch 24, Batch 2700] loss: 0.00844365008031673
[Epoch 24, Batch 2800] loss: 0.007851328080687382
[Epoch 24, Batch 2900] loss: 0.009792929064151395
[Epoch 24, Batch 3000] loss: 0.017236846347586834
[Epoch 24, Batch 3100] loss: 0.007556981458910741
[Epoch 24, Batch 3200] loss: 0.009413166149461177
[Epoch 24, Batch 3300] loss: 0.018690274837272227
[Epoch 24, Batch 3400] loss: 0.013506248619032704
[Epoch 24, Batch 3500] loss: 0.008834030321158934
[Epoch 24, Batch 3600] loss: 0.016748376443115377
[Epoch 24, Batch 3700] loss: 0.011756083227223825
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0334
Overfitting: 0.0332
Best model saved at epoch 24 with training loss: 0.0001
qt.qpa.xcb: X server does not support XInput 2
+++FINAL STATS++++
Training Loss 0.00013528062254724015
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Test set to find Test loss for overfitting
 Testing loss : 0.0334
Calculated Overfitting : 0.0332
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9888
Total time taken for hyperparameter tuning and evaluation: 6:46:6
/home/ahussain/PycharmProjects/optunaNew/Median_pruner_Testing.py:493: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.


Process finished with exit code 0

