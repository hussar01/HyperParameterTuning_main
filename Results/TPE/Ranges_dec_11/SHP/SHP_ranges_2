04
[Epoch 19, Batch 2200] loss: 0.007173405417615868
[Epoch 19, Batch 2300] loss: 0.0075301451672817165
[Epoch 19, Batch 2400] loss: 0.00849095591539026
[Epoch 19, Batch 2500] loss: 0.005747693088098913
[Epoch 19, Batch 2600] loss: 0.006792013426220365
[Epoch 19, Batch 2700] loss: 0.017329459691650298
[Epoch 19, Batch 2800] loss: 0.014637982464072365
[Epoch 19, Batch 2900] loss: 0.012084941344501204
[Epoch 19, Batch 3000] loss: 0.011949100654201175
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9868
Overfitting: 0.0465
[Epoch 20, Batch 100] loss: 0.010541143146176636
[Epoch 20, Batch 200] loss: 0.005254696828480974
[Epoch 20, Batch 300] loss: 0.005294473390549683
[Epoch 20, Batch 400] loss: 0.005718670960443433
[Epoch 20, Batch 500] loss: 0.005142977886705467
[Epoch 20, Batch 600] loss: 0.0038339613899552203
[Epoch 20, Batch 700] loss: 0.01152641488257359
[Epoch 20, Batch 800] loss: 0.006248739606569416
[Epoch 20, Batch 900] loss: 0.007590758812280001
[Epoch 20, Batch 1000] loss: 0.005927268915766035
[Epoch 20, Batch 1100] loss: 0.00655762287265702
[Epoch 20, Batch 1200] loss: 0.009131464162327347
[Epoch 20, Batch 1300] loss: 0.0044690603840774655
[Epoch 20, Batch 1400] loss: 0.009253441588020906
[Epoch 20, Batch 1500] loss: 0.009769404566334287
[Epoch 20, Batch 1600] loss: 0.008388847346748208
[Epoch 20, Batch 1700] loss: 0.00923374069635429
[Epoch 20, Batch 1800] loss: 0.011277391532034926
[Epoch 20, Batch 1900] loss: 0.006479908646078911
[Epoch 20, Batch 2000] loss: 0.007831111926034282
[Epoch 20, Batch 2100] loss: 0.010423909142187994
[Epoch 20, Batch 2200] loss: 0.008796693506615156
[Epoch 20, Batch 2300] loss: 0.014562811988143949
[Epoch 20, Batch 2400] loss: 0.014354360701117912
[Epoch 20, Batch 2500] loss: 0.008204244510798162
[Epoch 20, Batch 2600] loss: 0.005738555802981864
[Epoch 20, Batch 2700] loss: 0.014262441322491668
[Epoch 20, Batch 2800] loss: 0.007561490551138377
[Epoch 20, Batch 2900] loss: 0.008878049328352518
[Epoch 20, Batch 3000] loss: 0.006580711001568033
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0541
Validation Accuracy: 0.9866
Overfitting: 0.0541
[Epoch 21, Batch 100] loss: 0.0048404021338569695
[Epoch 21, Batch 200] loss: 0.010368575158458952
[Epoch 21, Batch 300] loss: 0.0067037365524601
[Epoch 21, Batch 400] loss: 0.009491547586208071
[Epoch 21, Batch 500] loss: 0.004720431060875398
[Epoch 21, Batch 600] loss: 0.010588896426672817
[Epoch 21, Batch 700] loss: 0.008307873353714967
[Epoch 21, Batch 800] loss: 0.0023344286567811424
[Epoch 21, Batch 900] loss: 0.00793794098007197
[Epoch 21, Batch 1000] loss: 0.00307233900431811
[Epoch 21, Batch 1100] loss: 0.001912022377928224
[Epoch 21, Batch 1200] loss: 0.005516696527832324
[Epoch 21, Batch 1300] loss: 0.0037705457365530036
[Epoch 21, Batch 1400] loss: 0.002866585670838049
[Epoch 21, Batch 1500] loss: 0.003926620359522986
[Epoch 21, Batch 1600] loss: 0.0042081641606023365
[Epoch 21, Batch 1700] loss: 0.00772737461760471
[Epoch 21, Batch 1800] loss: 0.008089261412748102
[Epoch 21, Batch 1900] loss: 0.008260428579851577
[Epoch 21, Batch 2000] loss: 0.008634698075672987
[Epoch 21, Batch 2100] loss: 0.016085272671339225
[Epoch 21, Batch 2200] loss: 0.008758681169060764
[Epoch 21, Batch 2300] loss: 0.009614964384613813
[Epoch 21, Batch 2400] loss: 0.005703175352891776
[Epoch 21, Batch 2500] loss: 0.011178521026451449
[Epoch 21, Batch 2600] loss: 0.013351042524759578
[Epoch 21, Batch 2700] loss: 0.009184577539215297
[Epoch 21, Batch 2800] loss: 0.0069270419845884135
[Epoch 21, Batch 2900] loss: 0.0082953518067211
[Epoch 21, Batch 3000] loss: 0.005714113372469001
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9883
Overfitting: 0.0471
[Epoch 22, Batch 100] loss: 0.0049073519480884896
[Epoch 22, Batch 200] loss: 0.008061088569270396
[Epoch 22, Batch 300] loss: 0.00292975035980362
[Epoch 22, Batch 400] loss: 0.005008810560182156
[Epoch 22, Batch 500] loss: 0.0032856956228749824
[Epoch 22, Batch 600] loss: 0.001989844675800896
[Epoch 22, Batch 700] loss: 0.0015917718156197224
[Epoch 22, Batch 800] loss: 0.00507954188730082
[Epoch 22, Batch 900] loss: 0.0033204773443924296
[Epoch 22, Batch 1000] loss: 0.0034152995889371596
[Epoch 22, Batch 1100] loss: 0.013834955075914195
[Epoch 22, Batch 1200] loss: 0.009768621582388164
[Epoch 22, Batch 1300] loss: 0.0104262728770874
[Epoch 22, Batch 1400] loss: 0.006290002365544751
[Epoch 22, Batch 1500] loss: 0.0034435575256065933
[Epoch 22, Batch 1600] loss: 0.010082586670354204
[Epoch 22, Batch 1700] loss: 0.003677494541541364
[Epoch 22, Batch 1800] loss: 0.004980456696683291
[Epoch 22, Batch 1900] loss: 0.004594002018887124
[Epoch 22, Batch 2000] loss: 0.0021317088876071466
[Epoch 22, Batch 2100] loss: 0.006730619961749653
[Epoch 22, Batch 2200] loss: 0.004551317327344578
[Epoch 22, Batch 2300] loss: 0.005519126286421852
[Epoch 22, Batch 2400] loss: 0.006814661013677324
[Epoch 22, Batch 2500] loss: 0.00615333383692807
[Epoch 22, Batch 2600] loss: 0.005452215709860297
[Epoch 22, Batch 2700] loss: 0.013327673855492321
[Epoch 22, Batch 2800] loss: 0.015830256226250866
[Epoch 22, Batch 2900] loss: 0.009382565337526785
[Epoch 22, Batch 3000] loss: 0.011536296467518792
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9876
Overfitting: 0.0486
[Epoch 23, Batch 100] loss: 0.012556559410979844
[Epoch 23, Batch 200] loss: 0.006607628685005409
[Epoch 23, Batch 300] loss: 0.0092764098668124
[Epoch 23, Batch 400] loss: 0.002872119613860491
[Epoch 23, Batch 500] loss: 0.003141183659523676
[Epoch 23, Batch 600] loss: 0.0033190962330525054
[Epoch 23, Batch 700] loss: 0.0033899736492804776
[Epoch 23, Batch 800] loss: 0.005523899919465975
[Epoch 23, Batch 900] loss: 0.0024524201251222167
[Epoch 23, Batch 1000] loss: 0.00436002002520695
[Epoch 23, Batch 1100] loss: 0.005395972732920882
[Epoch 23, Batch 1200] loss: 0.004720046971417844
[Epoch 23, Batch 1300] loss: 0.01257585242643927
[Epoch 23, Batch 1400] loss: 0.003873484830486973
[Epoch 23, Batch 1500] loss: 0.004540192598105932
[Epoch 23, Batch 1600] loss: 0.00262296237418866
[Epoch 23, Batch 1700] loss: 0.0037624476987537037
[Epoch 23, Batch 1800] loss: 0.006900372754359978
[Epoch 23, Batch 1900] loss: 0.007402244098720985
[Epoch 23, Batch 2000] loss: 0.010529913726920768
[Epoch 23, Batch 2100] loss: 0.004924405935578306
[Epoch 23, Batch 2200] loss: 0.001667481569679694
[Epoch 23, Batch 2300] loss: 0.002395855081656464
[Epoch 23, Batch 2400] loss: 0.0034693688981727176
[Epoch 23, Batch 2500] loss: 0.00957121790451083
[Epoch 23, Batch 2600] loss: 0.005627560484648484
[Epoch 23, Batch 2700] loss: 0.0035330994687842576
[Epoch 23, Batch 2800] loss: 0.0044984534377908855
[Epoch 23, Batch 2900] loss: 0.00521830388448052
[Epoch 23, Batch 3000] loss: 0.004077320912083451
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9886
Overfitting: 0.0486
[Epoch 24, Batch 100] loss: 0.0028141283048968547
[Epoch 24, Batch 200] loss: 0.0047999988985452545
[Epoch 24, Batch 300] loss: 0.004575428429309341
[Epoch 24, Batch 400] loss: 0.004901104830425993
[Epoch 24, Batch 500] loss: 0.0039795774955905475
[Epoch 24, Batch 600] loss: 0.0028367361903674747
[Epoch 24, Batch 700] loss: 0.002342141008593899
[Epoch 24, Batch 800] loss: 0.004152485026755528
[Epoch 24, Batch 900] loss: 0.006035393338471806
[Epoch 24, Batch 1000] loss: 0.0030168028073784114
[Epoch 24, Batch 1100] loss: 0.006645792107994453
[Epoch 24, Batch 1200] loss: 0.004761265449835151
[Epoch 24, Batch 1300] loss: 0.01641819630586724
[Epoch 24, Batch 1400] loss: 0.006609909263913778
[Epoch 24, Batch 1500] loss: 0.0050154295791531925
[Epoch 24, Batch 1600] loss: 0.0032832368009746917
[Epoch 24, Batch 1700] loss: 0.0022254288020957347
[Epoch 24, Batch 1800] loss: 0.0034141766150548847
[Epoch 24, Batch 1900] loss: 0.00334026788922813
[Epoch 24, Batch 2000] loss: 0.0024084600454179397
[Epoch 24, Batch 2100] loss: 0.003256875497969176
[Epoch 24, Batch 2200] loss: 0.011324247396439944
[Epoch 24, Batch 2300] loss: 0.003249302202830222
[Epoch 24, Batch 2400] loss: 0.0033407766407992767
[Epoch 24, Batch 2500] loss: 0.004187959919520665
[Epoch 24, Batch 2600] loss: 0.0017875204330831806
[Epoch 24, Batch 2700] loss: 0.005943082537969531
[Epoch 24, Batch 2800] loss: 0.0058238905844484636
[Epoch 24, Batch 2900] loss: 0.001871263155750853
[Epoch 24, Batch 3000] loss: 0.010606785028934383
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0579
Validation Accuracy: 0.9868
Overfitting: 0.0579
Fold 4 validation loss: 0.0579
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2902444887161253
[Epoch 1, Batch 200] loss: 2.256407902240753
[Epoch 1, Batch 300] loss: 2.1386126899719238
[Epoch 1, Batch 400] loss: 1.64232681453228
[Epoch 1, Batch 500] loss: 0.8857857215404511
[Epoch 1, Batch 600] loss: 0.7212371335923672
[Epoch 1, Batch 700] loss: 0.5590639126300812
[Epoch 1, Batch 800] loss: 0.4269014728069305
[Epoch 1, Batch 900] loss: 0.43393990851938724
[Epoch 1, Batch 1000] loss: 0.36323784694075584
[Epoch 1, Batch 1100] loss: 0.3765468838810921
[Epoch 1, Batch 1200] loss: 0.39241319470107555
[Epoch 1, Batch 1300] loss: 0.29238413404673336
[Epoch 1, Batch 1400] loss: 0.3019522591866553
[Epoch 1, Batch 1500] loss: 0.3014621380344033
[Epoch 1, Batch 1600] loss: 0.28881427718326447
[Epoch 1, Batch 1700] loss: 0.2660641594976187
[Epoch 1, Batch 1800] loss: 0.24606473809108137
[Epoch 1, Batch 1900] loss: 0.25252388121560215
[Epoch 1, Batch 2000] loss: 0.2297683317773044
[Epoch 1, Batch 2100] loss: 0.23080562883988023
[Epoch 1, Batch 2200] loss: 0.20932143939658998
[Epoch 1, Batch 2300] loss: 0.21470979627221823
[Epoch 1, Batch 2400] loss: 0.21647071614861488
[Epoch 1, Batch 2500] loss: 0.1875595063250512
[Epoch 1, Batch 2600] loss: 0.18201945441775025
[Epoch 1, Batch 2700] loss: 0.16243277626112104
[Epoch 1, Batch 2800] loss: 0.18270583558827638
[Epoch 1, Batch 2900] loss: 0.15487012962345034
[Epoch 1, Batch 3000] loss: 0.14317140370607376
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1595
Validation Accuracy: 0.9530
Overfitting: 0.1595
Best model saved at epoch 1 with validation loss: 0.1595
[Epoch 2, Batch 100] loss: 0.15366779066622258
[Epoch 2, Batch 200] loss: 0.14279551102779806
[Epoch 2, Batch 300] loss: 0.1698609755281359
[Epoch 2, Batch 400] loss: 0.15768814330920577
[Epoch 2, Batch 500] loss: 0.1520686764549464
[Epoch 2, Batch 600] loss: 0.15108519108965993
[Epoch 2, Batch 700] loss: 0.13904794136062265
[Epoch 2, Batch 800] loss: 0.12793817168567329
[Epoch 2, Batch 900] loss: 0.13240341939497738
[Epoch 2, Batch 1000] loss: 0.11959804161451756
[Epoch 2, Batch 1100] loss: 0.12201679441612213
[Epoch 2, Batch 1200] loss: 0.12450563791207969
[Epoch 2, Batch 1300] loss: 0.11744035874027758
[Epoch 2, Batch 1400] loss: 0.12547632251866161
[Epoch 2, Batch 1500] loss: 0.1281079818494618
[Epoch 2, Batch 1600] loss: 0.09634473115438595
[Epoch 2, Batch 1700] loss: 0.09536108387401328
[Epoch 2, Batch 1800] loss: 0.12085731451865285
[Epoch 2, Batch 1900] loss: 0.10766685286536813
[Epoch 2, Batch 2000] loss: 0.10622786473482847
[Epoch 2, Batch 2100] loss: 0.1150615860580001
[Epoch 2, Batch 2200] loss: 0.12516470273025335
[Epoch 2, Batch 2300] loss: 0.11650775877758861
[Epoch 2, Batch 2400] loss: 0.10636280878446996
[Epoch 2, Batch 2500] loss: 0.13100279203848914
[Epoch 2, Batch 2600] loss: 0.10200608012266457
[Epoch 2, Batch 2700] loss: 0.09195508792065084
[Epoch 2, Batch 2800] loss: 0.09311351845040917
[Epoch 2, Batch 2900] loss: 0.07828825621167197
[Epoch 2, Batch 3000] loss: 0.10736666492419317
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1120
Validation Accuracy: 0.9668
Overfitting: 0.1120
Best model saved at epoch 2 with validation loss: 0.1120
[Epoch 3, Batch 100] loss: 0.09754468018654734
[Epoch 3, Batch 200] loss: 0.07193439533933997
[Epoch 3, Batch 300] loss: 0.09757490811636671
[Epoch 3, Batch 400] loss: 0.1074829760286957
[Epoch 3, Batch 500] loss: 0.09072322253021411
[Epoch 3, Batch 600] loss: 0.11859781485982239
[Epoch 3, Batch 700] loss: 0.09827739620581269
[Epoch 3, Batch 800] loss: 0.09727712430641987
[Epoch 3, Batch 900] loss: 0.08441832650452852
[Epoch 3, Batch 1000] loss: 0.08539486213121564
[Epoch 3, Batch 1100] loss: 0.08735650102375075
[Epoch 3, Batch 1200] loss: 0.09168695896863938
[Epoch 3, Batch 1300] loss: 0.09273402584716678
[Epoch 3, Batch 1400] loss: 0.12137061098590493
[Epoch 3, Batch 1500] loss: 0.08616830141399986
[Epoch 3, Batch 1600] loss: 0.09130598163232208
[Epoch 3, Batch 1700] loss: 0.04582845102238935
[Epoch 3, Batch 1800] loss: 0.07911447001737543
[Epoch 3, Batch 1900] loss: 0.10080501361517236
[Epoch 3, Batch 2000] loss: 0.0699323747260496
[Epoch 3, Batch 2100] loss: 0.07219068536651321
[Epoch 3, Batch 2200] loss: 0.08668161906767637
[Epoch 3, Batch 2300] loss: 0.07036191070219502
[Epoch 3, Batch 2400] loss: 0.07809026275470388
[Epoch 3, Batch 2500] loss: 0.081127803894924
[Epoch 3, Batch 2600] loss: 0.07084078002837486
[Epoch 3, Batch 2700] loss: 0.08229957346920855
[Epoch 3, Batch 2800] loss: 0.048600039936718534
[Epoch 3, Batch 2900] loss: 0.07005674602929503
[Epoch 3, Batch 3000] loss: 0.06949479405477177
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0764
Validation Accuracy: 0.9761
Overfitting: 0.0764
Best model saved at epoch 3 with validation loss: 0.0764
[Epoch 4, Batch 100] loss: 0.08075909876497463
[Epoch 4, Batch 200] loss: 0.053169987326255067
[Epoch 4, Batch 300] loss: 0.08001283312099985
[Epoch 4, Batch 400] loss: 0.0737624278414296
[Epoch 4, Batch 500] loss: 0.06811347973183729
[Epoch 4, Batch 600] loss: 0.07044920180225744
[Epoch 4, Batch 700] loss: 0.06727473187085707
[Epoch 4, Batch 800] loss: 0.061603058342589063
[Epoch 4, Batch 900] loss: 0.06641285366029478
[Epoch 4, Batch 1000] loss: 0.06198507995693944
[Epoch 4, Batch 1100] loss: 0.04615061489283107
[Epoch 4, Batch 1200] loss: 0.055062032917194303
[Epoch 4, Batch 1300] loss: 0.046753882942721245
[Epoch 4, Batch 1400] loss: 0.07969676998560317
[Epoch 4, Batch 1500] loss: 0.07066078037954866
[Epoch 4, Batch 1600] loss: 0.0646512152365176
[Epoch 4, Batch 1700] loss: 0.049337008802685885
[Epoch 4, Batch 1800] loss: 0.05622978080122266
[Epoch 4, Batch 1900] loss: 0.0702547828524257
[Epoch 4, Batch 2000] loss: 0.059828927367925645
[Epoch 4, Batch 2100] loss: 0.07940253990585916
[Epoch 4, Batch 2200] loss: 0.05491072789649479
[Epoch 4, Batch 2300] loss: 0.07261055550625314
[Epoch 4, Batch 2400] loss: 0.07882259185251314
[Epoch 4, Batch 2500] loss: 0.07359044233104214
[Epoch 4, Batch 2600] loss: 0.06598057429539039
[Epoch 4, Batch 2700] loss: 0.06453862606431357
[Epoch 4, Batch 2800] loss: 0.07066985641082284
[Epoch 4, Batch 2900] loss: 0.05201901702792384
[Epoch 4, Batch 3000] loss: 0.04758339370862814
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0611
Validation Accuracy: 0.9826
Overfitting: 0.0611
Best model saved at epoch 4 with validation loss: 0.0611
[Epoch 5, Batch 100] loss: 0.0522649828257272
[Epoch 5, Batch 200] loss: 0.05503149181226036
[Epoch 5, Batch 300] loss: 0.05584951647295384
[Epoch 5, Batch 400] loss: 0.055152363897650505
[Epoch 5, Batch 500] loss: 0.058787092082784514
[Epoch 5, Batch 600] loss: 0.04356622357270681
[Epoch 5, Batch 700] loss: 0.05786798857850954
[Epoch 5, Batch 800] loss: 0.05919247387035284
[Epoch 5, Batch 900] loss: 0.05664980587782338
[Epoch 5, Batch 1000] loss: 0.03750636850309093
[Epoch 5, Batch 1100] loss: 0.05657613674091408
[Epoch 5, Batch 1200] loss: 0.08978825036276249
[Epoch 5, Batch 1300] loss: 0.056116737406700846
[Epoch 5, Batch 1400] loss: 0.044690949419746176
[Epoch 5, Batch 1500] loss: 0.05663182510819752
[Epoch 5, Batch 1600] loss: 0.040114079132617914
[Epoch 5, Batch 1700] loss: 0.04654114178010786
[Epoch 5, Batch 1800] loss: 0.06555458545335568
[Epoch 5, Batch 1900] loss: 0.08313745617633686
[Epoch 5, Batch 2000] loss: 0.04232626247656299
[Epoch 5, Batch 2100] loss: 0.062087487855751536
[Epoch 5, Batch 2200] loss: 0.04706776100501884
[Epoch 5, Batch 2300] loss: 0.0690109488053713
[Epoch 5, Batch 2400] loss: 0.05847097170888446
[Epoch 5, Batch 2500] loss: 0.06994610599591397
[Epoch 5, Batch 2600] loss: 0.04028623288613744
[Epoch 5, Batch 2700] loss: 0.06661364425148349
[Epoch 5, Batch 2800] loss: 0.05143530069559347
[Epoch 5, Batch 2900] loss: 0.047374888182384896
[Epoch 5, Batch 3000] loss: 0.0395361443515867
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0579
Validation Accuracy: 0.9818
Overfitting: 0.0579
Best model saved at epoch 5 with validation loss: 0.0579
[Epoch 6, Batch 100] loss: 0.05652433721028501
[Epoch 6, Batch 200] loss: 0.03544988162248046
[Epoch 6, Batch 300] loss: 0.0685168635082664
[Epoch 6, Batch 400] loss: 0.04439656533126254
[Epoch 6, Batch 500] loss: 0.03662079534376971
[Epoch 6, Batch 600] loss: 0.05282189137389651
[Epoch 6, Batch 700] loss: 0.035491645440342834
[Epoch 6, Batch 800] loss: 0.04123079016964766
[Epoch 6, Batch 900] loss: 0.04971694484702312
[Epoch 6, Batch 1000] loss: 0.04927503147511743
[Epoch 6, Batch 1100] loss: 0.0571753545361571
[Epoch 6, Batch 1200] loss: 0.03910845917678671
[Epoch 6, Batch 1300] loss: 0.03447045537541271
[Epoch 6, Batch 1400] loss: 0.03152409066839027
[Epoch 6, Batch 1500] loss: 0.049405714465247004
[Epoch 6, Batch 1600] loss: 0.04352517681778409
[Epoch 6, Batch 1700] loss: 0.05555744423327269
[Epoch 6, Batch 1800] loss: 0.04164761650492437
[Epoch 6, Batch 1900] loss: 0.048773725043283776
[Epoch 6, Batch 2000] loss: 0.06280607347085607
[Epoch 6, Batch 2100] loss: 0.04897176368656801
[Epoch 6, Batch 2200] loss: 0.05878987090633018
[Epoch 6, Batch 2300] loss: 0.04577932885556948
[Epoch 6, Batch 2400] loss: 0.04923346637922805
[Epoch 6, Batch 2500] loss: 0.043994123512529765
[Epoch 6, Batch 2600] loss: 0.05134144069466856
[Epoch 6, Batch 2700] loss: 0.03611837676115101
[Epoch 6, Batch 2800] loss: 0.04112902603810653
[Epoch 6, Batch 2900] loss: 0.04378297847433714
[Epoch 6, Batch 3000] loss: 0.06077228454465512
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0553
Validation Accuracy: 0.9826
Overfitting: 0.0553
Best model saved at epoch 6 with validation loss: 0.0553
[Epoch 7, Batch 100] loss: 0.03688656214304501
[Epoch 7, Batch 200] loss: 0.04573968555050669
[Epoch 7, Batch 300] loss: 0.04479944397084182
[Epoch 7, Batch 400] loss: 0.038862300821929235
[Epoch 7, Batch 500] loss: 0.031133955476107075
[Epoch 7, Batch 600] loss: 0.05026318430042011
[Epoch 7, Batch 700] loss: 0.057819220943783875
[Epoch 7, Batch 800] loss: 0.034629506870842305
[Epoch 7, Batch 900] loss: 0.04638514909762307
[Epoch 7, Batch 1000] loss: 0.0303300515000592
[Epoch 7, Batch 1100] loss: 0.03935678927780827
[Epoch 7, Batch 1200] loss: 0.04263365581049584
[Epoch 7, Batch 1300] loss: 0.03694305523400544
[Epoch 7, Batch 1400] loss: 0.04929491420873092
[Epoch 7, Batch 1500] loss: 0.028183172716089756
[Epoch 7, Batch 1600] loss: 0.0442397263168823
[Epoch 7, Batch 1700] loss: 0.038089345120824875
[Epoch 7, Batch 1800] loss: 0.038956200390530285
[Epoch 7, Batch 1900] loss: 0.03815003543277271
[Epoch 7, Batch 2000] loss: 0.03126868826278951
[Epoch 7, Batch 2100] loss: 0.05399828634515871
[Epoch 7, Batch 2200] loss: 0.04810375101020327
[Epoch 7, Batch 2300] loss: 0.04942562727315817
[Epoch 7, Batch 2400] loss: 0.045453295240004084
[Epoch 7, Batch 2500] loss: 0.041474546618410386
[Epoch 7, Batch 2600] loss: 0.03404938857886009
[Epoch 7, Batch 2700] loss: 0.03021860506036319
[Epoch 7, Batch 2800] loss: 0.03362474943103735
[Epoch 7, Batch 2900] loss: 0.03317520817945478
[Epoch 7, Batch 3000] loss: 0.04540518417947169
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9831
Overfitting: 0.0550
Best model saved at epoch 7 with validation loss: 0.0550
[Epoch 8, Batch 100] loss: 0.04163027099566534
[Epoch 8, Batch 200] loss: 0.034808372832485474
[Epoch 8, Batch 300] loss: 0.04296145406668075
[Epoch 8, Batch 400] loss: 0.03068098554715107
[Epoch 8, Batch 500] loss: 0.02955057371080329
[Epoch 8, Batch 600] loss: 0.035294829978083725
[Epoch 8, Batch 700] loss: 0.03616947850539873
[Epoch 8, Batch 800] loss: 0.0232002286426723
[Epoch 8, Batch 900] loss: 0.03168660757582984
[Epoch 8, Batch 1000] loss: 0.02887541778589366
[Epoch 8, Batch 1100] loss: 0.053976719889760716
[Epoch 8, Batch 1200] loss: 0.0402793407154968
[Epoch 8, Batch 1300] loss: 0.031152643997702397
[Epoch 8, Batch 1400] loss: 0.038691290837159616
[Epoch 8, Batch 1500] loss: 0.037310533753188796
[Epoch 8, Batch 1600] loss: 0.03208995970780961
[Epoch 8, Batch 1700] loss: 0.02727200638357317
[Epoch 8, Batch 1800] loss: 0.028979354039329337
[Epoch 8, Batch 1900] loss: 0.03239929916031542
[Epoch 8, Batch 2000] loss: 0.02463373079197481
[Epoch 8, Batch 2100] loss: 0.041422802543238504
[Epoch 8, Batch 2200] loss: 0.04195428963488666
[Epoch 8, Batch 2300] loss: 0.03897881796961883
[Epoch 8, Batch 2400] loss: 0.02721463245456107
[Epoch 8, Batch 2500] loss: 0.04667691414506407
[Epoch 8, Batch 2600] loss: 0.053623497428779955
[Epoch 8, Batch 2700] loss: 0.03148325171619945
[Epoch 8, Batch 2800] loss: 0.028602518633415456
[Epoch 8, Batch 2900] loss: 0.034940630729252006
[Epoch 8, Batch 3000] loss: 0.05346751330052939
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9835
Overfitting: 0.0535
Best model saved at epoch 8 with validation loss: 0.0535
[Epoch 9, Batch 100] loss: 0.02780772875987168
[Epoch 9, Batch 200] loss: 0.03738271822148818
[Epoch 9, Batch 300] loss: 0.028138730279169976
[Epoch 9, Batch 400] loss: 0.02894774456632149
[Epoch 9, Batch 500] loss: 0.025039208551679622
[Epoch 9, Batch 600] loss: 0.03447812760976376
[Epoch 9, Batch 700] loss: 0.021465713996512932
[Epoch 9, Batch 800] loss: 0.024455071534030138
[Epoch 9, Batch 900] loss: 0.03537023098055215
[Epoch 9, Batch 1000] loss: 0.037679386796662585
[Epoch 9, Batch 1100] loss: 0.03641624894255074
[Epoch 9, Batch 1200] loss: 0.02422689892409835
[Epoch 9, Batch 1300] loss: 0.020930929896858286
[Epoch 9, Batch 1400] loss: 0.03869116831214342
[Epoch 9, Batch 1500] loss: 0.05510549189115409
[Epoch 9, Batch 1600] loss: 0.04011371299042366
[Epoch 9, Batch 1700] loss: 0.029648481228214223
[Epoch 9, Batch 1800] loss: 0.03605148034821468
[Epoch 9, Batch 1900] loss: 0.029020166817681457
[Epoch 9, Batch 2000] loss: 0.026629052377829796
[Epoch 9, Batch 2100] loss: 0.044883246774115836
[Epoch 9, Batch 2200] loss: 0.029537666305259336
[Epoch 9, Batch 2300] loss: 0.03477212459576549
[Epoch 9, Batch 2400] loss: 0.02254482471558731
[Epoch 9, Batch 2500] loss: 0.04213396034363541
[Epoch 9, Batch 2600] loss: 0.02431573678884888
[Epoch 9, Batch 2700] loss: 0.0333631644397974
[Epoch 9, Batch 2800] loss: 0.025756025419686922
[Epoch 9, Batch 2900] loss: 0.022962219290238863
[Epoch 9, Batch 3000] loss: 0.05943557571241399
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0461
Validation Accuracy: 0.9852
Overfitting: 0.0461
Best model saved at epoch 9 with validation loss: 0.0461
[Epoch 10, Batch 100] loss: 0.03320264571957523
[Epoch 10, Batch 200] loss: 0.028222427621803946
[Epoch 10, Batch 300] loss: 0.035744987532743834
[Epoch 10, Batch 400] loss: 0.02050189837354992
[Epoch 10, Batch 500] loss: 0.0297542894291837
[Epoch 10, Batch 600] loss: 0.045343010419310305
[Epoch 10, Batch 700] loss: 0.028053414093737957
[Epoch 10, Batch 800] loss: 0.02390994289627997
[Epoch 10, Batch 900] loss: 0.019672843012522208
[Epoch 10, Batch 1000] loss: 0.022048614913292113
[Epoch 10, Batch 1100] loss: 0.027333200727880466
[Epoch 10, Batch 1200] loss: 0.04367831042196485
[Epoch 10, Batch 1300] loss: 0.01927516673327773
[Epoch 10, Batch 1400] loss: 0.03358207580327871
[Epoch 10, Batch 1500] loss: 0.03388161918694095
[Epoch 10, Batch 1600] loss: 0.03379004964328487
[Epoch 10, Batch 1700] loss: 0.021574636885343352
[Epoch 10, Batch 1800] loss: 0.022873730701976454
[Epoch 10, Batch 1900] loss: 0.02687854665215127
[Epoch 10, Batch 2000] loss: 0.03822525760391727
[Epoch 10, Batch 2100] loss: 0.035677007849008076
[Epoch 10, Batch 2200] loss: 0.03600500164029654
[Epoch 10, Batch 2300] loss: 0.01964780106456601
[Epoch 10, Batch 2400] loss: 0.026371319132413192
[Epoch 10, Batch 2500] loss: 0.02027481356784847
[Epoch 10, Batch 2600] loss: 0.015211790750709043
[Epoch 10, Batch 2700] loss: 0.04093149800966785
[Epoch 10, Batch 2800] loss: 0.02663774595108407
[Epoch 10, Batch 2900] loss: 0.03606159239570843
[Epoch 10, Batch 3000] loss: 0.023651087450489286
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9854
Overfitting: 0.0462
[Epoch 11, Batch 100] loss: 0.02163759898758144
[Epoch 11, Batch 200] loss: 0.030807045488472795
[Epoch 11, Batch 300] loss: 0.021067914248560554
[Epoch 11, Batch 400] loss: 0.02407747418663348
[Epoch 11, Batch 500] loss: 0.025156723818799947
[Epoch 11, Batch 600] loss: 0.023585826705602813
[Epoch 11, Batch 700] loss: 0.01637363700880087
[Epoch 11, Batch 800] loss: 0.02506129969780886
[Epoch 11, Batch 900] loss: 0.01641554327616177
[Epoch 11, Batch 1000] loss: 0.021219625780686327
[Epoch 11, Batch 1100] loss: 0.02411499382375041
[Epoch 11, Batch 1200] loss: 0.02338266046215722
[Epoch 11, Batch 1300] loss: 0.03445271609110932
[Epoch 11, Batch 1400] loss: 0.025674738685338525
[Epoch 11, Batch 1500] loss: 0.025502845120354323
[Epoch 11, Batch 1600] loss: 0.025236473526165357
[Epoch 11, Batch 1700] loss: 0.02939230221614707
[Epoch 11, Batch 1800] loss: 0.026371793550351866
[Epoch 11, Batch 1900] loss: 0.03237469360028626
[Epoch 11, Batch 2000] loss: 0.02132091066629073
[Epoch 11, Batch 2100] loss: 0.027506679561483907
[Epoch 11, Batch 2200] loss: 0.019968845709609013
[Epoch 11, Batch 2300] loss: 0.045161882230095214
[Epoch 11, Batch 2400] loss: 0.03403225785434188
[Epoch 11, Batch 2500] loss: 0.026756561743459317
[Epoch 11, Batch 2600] loss: 0.021569781993384822
[Epoch 11, Batch 2700] loss: 0.03255152219739102
[Epoch 11, Batch 2800] loss: 0.027075601593678583
[Epoch 11, Batch 2900] loss: 0.024443543694251276
[Epoch 11, Batch 3000] loss: 0.033321236375631995
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9834
Overfitting: 0.0508
[Epoch 12, Batch 100] loss: 0.018825648563943104
[Epoch 12, Batch 200] loss: 0.02378932411505957
[Epoch 12, Batch 300] loss: 0.018504753947636347
[Epoch 12, Batch 400] loss: 0.014818604306783527
[Epoch 12, Batch 500] loss: 0.016636059362863307
[Epoch 12, Batch 600] loss: 0.019732326867670055
[Epoch 12, Batch 700] loss: 0.017534500044976083
[Epoch 12, Batch 800] loss: 0.018270127917348875
[Epoch 12, Batch 900] loss: 0.03483251952096907
[Epoch 12, Batch 1000] loss: 0.02966397865275212
[Epoch 12, Batch 1100] loss: 0.01965943747320125
[Epoch 12, Batch 1200] loss: 0.027727029844973005
[Epoch 12, Batch 1300] loss: 0.027221583877180818
[Epoch 12, Batch 1400] loss: 0.027308503209787886
[Epoch 12, Batch 1500] loss: 0.030542626450187526
[Epoch 12, Batch 1600] loss: 0.019671051909099332
[Epoch 12, Batch 1700] loss: 0.02337243918853346
[Epoch 12, Batch 1800] loss: 0.024497990856471006
[Epoch 12, Batch 1900] loss: 0.0147171460111349
[Epoch 12, Batch 2000] loss: 0.01935808644790086
[Epoch 12, Batch 2100] loss: 0.030461303196934752
[Epoch 12, Batch 2200] loss: 0.015607043840791448
[Epoch 12, Batch 2300] loss: 0.03300715288653009
[Epoch 12, Batch 2400] loss: 0.0226602499782166
[Epoch 12, Batch 2500] loss: 0.02249518227061344
[Epoch 12, Batch 2600] loss: 0.015223541834675416
[Epoch 12, Batch 2700] loss: 0.01441935765229573
[Epoch 12, Batch 2800] loss: 0.01971040677060955
[Epoch 12, Batch 2900] loss: 0.033665769265317065
[Epoch 12, Batch 3000] loss: 0.02383124299656629
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9865
Overfitting: 0.0462
[Epoch 13, Batch 100] loss: 0.012581786924238258
[Epoch 13, Batch 200] loss: 0.017883640003747134
[Epoch 13, Batch 300] loss: 0.020447386587420624
[Epoch 13, Batch 400] loss: 0.012291945557863074
[Epoch 13, Batch 500] loss: 0.027984816857579062
[Epoch 13, Batch 600] loss: 0.021003379828580363
[Epoch 13, Batch 700] loss: 0.030350520565953047
[Epoch 13, Batch 800] loss: 0.015339463140135194
[Epoch 13, Batch 900] loss: 0.017560907989081897
[Epoch 13, Batch 1000] loss: 0.018533816752023993
[Epoch 13, Batch 1100] loss: 0.01747895338718081
[Epoch 13, Batch 1200] loss: 0.018046371806194658
[Epoch 13, Batch 1300] loss: 0.03397063329568482
[Epoch 13, Batch 1400] loss: 0.023914763347129338
[Epoch 13, Batch 1500] loss: 0.02110672084687394
[Epoch 13, Batch 1600] loss: 0.015642402702105755
[Epoch 13, Batch 1700] loss: 0.013176241688306618
[Epoch 13, Batch 1800] loss: 0.016959740053134737
[Epoch 13, Batch 1900] loss: 0.023470206959027563
[Epoch 13, Batch 2000] loss: 0.03011157366599946
[Epoch 13, Batch 2100] loss: 0.02826813477968244
[Epoch 13, Batch 2200] loss: 0.019132088090282197
[Epoch 13, Batch 2300] loss: 0.028752660286027094
[Epoch 13, Batch 2400] loss: 0.01797003344188852
[Epoch 13, Batch 2500] loss: 0.02280631073501354
[Epoch 13, Batch 2600] loss: 0.015316996564033616
[Epoch 13, Batch 2700] loss: 0.020292685170461483
[Epoch 13, Batch 2800] loss: 0.02103904897252505
[Epoch 13, Batch 2900] loss: 0.017051989156752826
[Epoch 13, Batch 3000] loss: 0.0297789768659095
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0402
Validation Accuracy: 0.9888
Overfitting: 0.0402
Best model saved at epoch 13 with validation loss: 0.0402
[Epoch 14, Batch 100] loss: 0.006995389156199963
[Epoch 14, Batch 200] loss: 0.025588784373885575
[Epoch 14, Batch 300] loss: 0.018181107152195182
[Epoch 14, Batch 400] loss: 0.01857428493660336
[Epoch 14, Batch 500] loss: 0.01261702293095368
[Epoch 14, Batch 600] loss: 0.014187839191990861
[Epoch 14, Batch 700] loss: 0.01650023584759765
[Epoch 14, Batch 800] loss: 0.023780918438205845
[Epoch 14, Batch 900] loss: 0.01932204912904126
[Epoch 14, Batch 1000] loss: 0.01934237699610094
[Epoch 14, Batch 1100] loss: 0.02055680950255919
[Epoch 14, Batch 1200] loss: 0.01623251910044928
[Epoch 14, Batch 1300] loss: 0.012563905284841893
[Epoch 14, Batch 1400] loss: 0.01453513905973523
[Epoch 14, Batch 1500] loss: 0.01540335447562029
[Epoch 14, Batch 1600] loss: 0.022847534774300585
[Epoch 14, Batch 1700] loss: 0.02758398790825595
[Epoch 14, Batch 1800] loss: 0.024801972589484647
[Epoch 14, Batch 1900] loss: 0.02421292104469103
[Epoch 14, Batch 2000] loss: 0.012735637909845537
[Epoch 14, Batch 2100] loss: 0.01470255600179371
[Epoch 14, Batch 2200] loss: 0.01825233864345137
[Epoch 14, Batch 2300] loss: 0.023396622143773128
[Epoch 14, Batch 2400] loss: 0.010244709198814235
[Epoch 14, Batch 2500] loss: 0.0151553988788055
[Epoch 14, Batch 2600] loss: 0.02351318986385195
[Epoch 14, Batch 2700] loss: 0.01896009408370446
[Epoch 14, Batch 2800] loss: 0.04168432312686491
[Epoch 14, Batch 2900] loss: 0.02892789655696106
[Epoch 14, Batch 3000] loss: 0.012423169793146371
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0405
Validation Accuracy: 0.9892
Overfitting: 0.0405
[Epoch 15, Batch 100] loss: 0.016041316399614515
[Epoch 15, Batch 200] loss: 0.014626218561497808
[Epoch 15, Batch 300] loss: 0.015706179572298425
[Epoch 15, Batch 400] loss: 0.023785824735241476
[Epoch 15, Batch 500] loss: 0.018885984783737514
[Epoch 15, Batch 600] loss: 0.0190988132658822
[Epoch 15, Batch 700] loss: 0.022341864317058934
[Epoch 15, Batch 800] loss: 0.014742056627023886
[Epoch 15, Batch 900] loss: 0.012184187316820498
[Epoch 15, Batch 1000] loss: 0.01558631860450987
[Epoch 15, Batch 1100] loss: 0.027181118026419426
[Epoch 15, Batch 1200] loss: 0.013676991568709128
[Epoch 15, Batch 1300] loss: 0.017689267279383785
[Epoch 15, Batch 1400] loss: 0.010385642525216099
[Epoch 15, Batch 1500] loss: 0.01441521086384455
[Epoch 15, Batch 1600] loss: 0.016345491023676006
[Epoch 15, Batch 1700] loss: 0.015929788348421424
[Epoch 15, Batch 1800] loss: 0.014870191656709721
[Epoch 15, Batch 1900] loss: 0.01917892993260466
[Epoch 15, Batch 2000] loss: 0.020117635256319773
[Epoch 15, Batch 2100] loss: 0.01100891354119085
[Epoch 15, Batch 2200] loss: 0.012306740814601654
[Epoch 15, Batch 2300] loss: 0.013727720703273008
[Epoch 15, Batch 2400] loss: 0.03335962916022254
[Epoch 15, Batch 2500] loss: 0.010965825467969807
[Epoch 15, Batch 2600] loss: 0.011505962784485745
[Epoch 15, Batch 2700] loss: 0.018522246310985792
[Epoch 15, Batch 2800] loss: 0.011713361360571072
[Epoch 15, Batch 2900] loss: 0.017037952042501275
[Epoch 15, Batch 3000] loss: 0.012115354957386444
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9868
Overfitting: 0.0478
[Epoch 16, Batch 100] loss: 0.008473910321299627
[Epoch 16, Batch 200] loss: 0.009064157107977734
[Epoch 16, Batch 300] loss: 0.011522287714460617
[Epoch 16, Batch 400] loss: 0.02495110143360762
[Epoch 16, Batch 500] loss: 0.010587071794707298
[Epoch 16, Batch 600] loss: 0.010591851222770857
[Epoch 16, Batch 700] loss: 0.013008859364781529
[Epoch 16, Batch 800] loss: 0.018878764793507797
[Epoch 16, Batch 900] loss: 0.013704200085830962
[Epoch 16, Batch 1000] loss: 0.017240830968203228
[Epoch 16, Batch 1100] loss: 0.020310374839364157
[Epoch 16, Batch 1200] loss: 0.00821699110478221
[Epoch 16, Batch 1300] loss: 0.016630706920805097
[Epoch 16, Batch 1400] loss: 0.023632373493419435
[Epoch 16, Batch 1500] loss: 0.00634327186828159
[Epoch 16, Batch 1600] loss: 0.009606118581759802
[Epoch 16, Batch 1700] loss: 0.003684249257148622
[Epoch 16, Batch 1800] loss: 0.014537982026540703
[Epoch 16, Batch 1900] loss: 0.01336876939090871
[Epoch 16, Batch 2000] loss: 0.013623717383638904
[Epoch 16, Batch 2100] loss: 0.02209965417296189
[Epoch 16, Batch 2200] loss: 0.02036127456540271
[Epoch 16, Batch 2300] loss: 0.022575921726634078
[Epoch 16, Batch 2400] loss: 0.028124585271452816
[Epoch 16, Batch 2500] loss: 0.01891211282558288
[Epoch 16, Batch 2600] loss: 0.017640518914558926
[Epoch 16, Batch 2700] loss: 0.01765437757867403
[Epoch 16, Batch 2800] loss: 0.009711671138384191
[Epoch 16, Batch 2900] loss: 0.02171170254379831
[Epoch 16, Batch 3000] loss: 0.018359170726603223
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9878
Overfitting: 0.0452
[Epoch 17, Batch 100] loss: 0.010604672125937213
[Epoch 17, Batch 200] loss: 0.009584364083457331
[Epoch 17, Batch 300] loss: 0.018161183775528115
[Epoch 17, Batch 400] loss: 0.007404912746878835
[Epoch 17, Batch 500] loss: 0.009503698336097842
[Epoch 17, Batch 600] loss: 0.014374636831707904
[Epoch 17, Batch 700] loss: 0.01225933589747001
[Epoch 17, Batch 800] loss: 0.01642205149915753
[Epoch 17, Batch 900] loss: 0.010392038994741597
[Epoch 17, Batch 1000] loss: 0.013634573816780175
[Epoch 17, Batch 1100] loss: 0.008890541428613688
[Epoch 17, Batch 1200] loss: 0.007500143039974319
[Epoch 17, Batch 1300] loss: 0.017015656468975068
[Epoch 17, Batch 1400] loss: 0.026159506055719248
[Epoch 17, Batch 1500] loss: 0.01810091234096035
[Epoch 17, Batch 1600] loss: 0.013676530341072066
[Epoch 17, Batch 1700] loss: 0.017025270868598456
[Epoch 17, Batch 1800] loss: 0.022948836270934407
[Epoch 17, Batch 1900] loss: 0.013139562642081729
[Epoch 17, Batch 2000] loss: 0.00895338589435596
[Epoch 17, Batch 2100] loss: 0.015358532781365284
[Epoch 17, Batch 2200] loss: 0.01678964012900906
[Epoch 17, Batch 2300] loss: 0.01040572871468612
[Epoch 17, Batch 2400] loss: 0.016081498117509908
[Epoch 17, Batch 2500] loss: 0.01885464394117662
[Epoch 17, Batch 2600] loss: 0.006280586063721785
[Epoch 17, Batch 2700] loss: 0.009202299828448304
[Epoch 17, Batch 2800] loss: 0.027248391534171787
[Epoch 17, Batch 2900] loss: 0.00979320841099252
[Epoch 17, Batch 3000] loss: 0.016331381839390816
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0420
Validation Accuracy: 0.9878
Overfitting: 0.0420
[Epoch 18, Batch 100] loss: 0.00908122631407423
[Epoch 18, Batch 200] loss: 0.00976211051714472
[Epoch 18, Batch 300] loss: 0.009685807546336491
[Epoch 18, Batch 400] loss: 0.00410237222336491
[Epoch 18, Batch 500] loss: 0.008434368612788602
[Epoch 18, Batch 600] loss: 0.007563223713134448
[Epoch 18, Batch 700] loss: 0.006000966189199062
[Epoch 18, Batch 800] loss: 0.012695616587725453
[Epoch 18, Batch 900] loss: 0.00895194819245262
[Epoch 18, Batch 1000] loss: 0.012761641606421108
[Epoch 18, Batch 1100] loss: 0.024825830959653104
[Epoch 18, Batch 1200] loss: 0.020540921781548604
[Epoch 18, Batch 1300] loss: 0.009040614144450955
[Epoch 18, Batch 1400] loss: 0.014612818172008702
[Epoch 18, Batch 1500] loss: 0.013548790912363985
[Epoch 18, Batch 1600] loss: 0.01086613705054333
[Epoch 18, Batch 1700] loss: 0.01523184327652416
[Epoch 18, Batch 1800] loss: 0.009997255955724996
[Epoch 18, Batch 1900] loss: 0.008674638576349026
[Epoch 18, Batch 2000] loss: 0.010637075540507794
[Epoch 18, Batch 2100] loss: 0.01602534665944404
[Epoch 18, Batch 2200] loss: 0.02042284192203624
[Epoch 18, Batch 2300] loss: 0.02908247442501306
[Epoch 18, Batch 2400] loss: 0.013065392517128203
[Epoch 18, Batch 2500] loss: 0.012725430785658319
[Epoch 18, Batch 2600] loss: 0.010008506219587616
[Epoch 18, Batch 2700] loss: 0.01926977035609525
[Epoch 18, Batch 2800] loss: 0.017219474469907254
[Epoch 18, Batch 2900] loss: 0.005751791433776816
[Epoch 18, Batch 3000] loss: 0.018657983273124047
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0442
Validation Accuracy: 0.9879
Overfitting: 0.0442
[Epoch 19, Batch 100] loss: 0.006543292406895489
[Epoch 19, Batch 200] loss: 0.009534280820312234
[Epoch 19, Batch 300] loss: 0.01163714781258932
[Epoch 19, Batch 400] loss: 0.011989944581237068
[Epoch 19, Batch 500] loss: 0.008454438792707037
[Epoch 19, Batch 600] loss: 0.014193716160561962
[Epoch 19, Batch 700] loss: 0.01669824027411323
[Epoch 19, Batch 800] loss: 0.01594972867571869
[Epoch 19, Batch 900] loss: 0.011914920999988681
[Epoch 19, Batch 1000] loss: 0.007939383185785118
[Epoch 19, Batch 1100] loss: 0.008178191431570668
[Epoch 19, Batch 1200] loss: 0.009608884914173358
[Epoch 19, Batch 1300] loss: 0.013577912939672388
[Epoch 19, Batch 1400] loss: 0.010647604456294176
[Epoch 19, Batch 1500] loss: 0.012963108647136323
[Epoch 19, Batch 1600] loss: 0.012958431123429363
[Epoch 19, Batch 1700] loss: 0.01004293889602195
[Epoch 19, Batch 1800] loss: 0.014176432890849355
[Epoch 19, Batch 1900] loss: 0.008568116424885374
[Epoch 19, Batch 2000] loss: 0.01750616945468664
[Epoch 19, Batch 2100] loss: 0.009156526503379609
[Epoch 19, Batch 2200] loss: 0.017693665850451908
[Epoch 19, Batch 2300] loss: 0.02777176726818652
[Epoch 19, Batch 2400] loss: 0.011704262535431553
[Epoch 19, Batch 2500] loss: 0.022967971391999527
[Epoch 19, Batch 2600] loss: 0.013178824219703528
[Epoch 19, Batch 2700] loss: 0.01122477073423852
[Epoch 19, Batch 2800] loss: 0.011147543081569893
[Epoch 19, Batch 2900] loss: 0.01178701247413187
[Epoch 19, Batch 3000] loss: 0.00485828430913898
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0416
Validation Accuracy: 0.9892
Overfitting: 0.0416
[Epoch 20, Batch 100] loss: 0.006729601284368982
[Epoch 20, Batch 200] loss: 0.013478732413686885
[Epoch 20, Batch 300] loss: 0.017181303117868082
[Epoch 20, Batch 400] loss: 0.009149533437121136
[Epoch 20, Batch 500] loss: 0.00806750197198312
[Epoch 20, Batch 600] loss: 0.004065486459380736
[Epoch 20, Batch 700] loss: 0.004661804439135722
[Epoch 20, Batch 800] loss: 0.014413272161946225
[Epoch 20, Batch 900] loss: 0.010061838681615427
[Epoch 20, Batch 1000] loss: 0.004574670767588032
[Epoch 20, Batch 1100] loss: 0.0069296011965525395
[Epoch 20, Batch 1200] loss: 0.006067202845192696
[Epoch 20, Batch 1300] loss: 0.00786839478147158
[Epoch 20, Batch 1400] loss: 0.008557734640658055
[Epoch 20, Batch 1500] loss: 0.01236215894097768
[Epoch 20, Batch 1600] loss: 0.007477220815230794
[Epoch 20, Batch 1700] loss: 0.010584726934846458
[Epoch 20, Batch 1800] loss: 0.009757679209981234
[Epoch 20, Batch 1900] loss: 0.011340664680519695
[Epoch 20, Batch 2000] loss: 0.013302012519961864
[Epoch 20, Batch 2100] loss: 0.004894845862941111
[Epoch 20, Batch 2200] loss: 0.011645330861929324
[Epoch 20, Batch 2300] loss: 0.009890706969836174
[Epoch 20, Batch 2400] loss: 0.01481375968518023
[Epoch 20, Batch 2500] loss: 0.008504308903320634
[Epoch 20, Batch 2600] loss: 0.006613465170175914
[Epoch 20, Batch 2700] loss: 0.004798223830753159
[Epoch 20, Batch 2800] loss: 0.014430830812523254
[Epoch 20, Batch 2900] loss: 0.005593322576360151
[Epoch 20, Batch 3000] loss: 0.009353859008392647
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0421
Validation Accuracy: 0.9890
Overfitting: 0.0421
[Epoch 21, Batch 100] loss: 0.0026897121591514406
[Epoch 21, Batch 200] loss: 0.00664927899636723
[Epoch 21, Batch 300] loss: 0.007182172310294845
[Epoch 21, Batch 400] loss: 0.005554834014847074
[Epoch 21, Batch 500] loss: 0.006079374745661425
[Epoch 21, Batch 600] loss: 0.005328900530753344
[Epoch 21, Batch 700] loss: 0.006616155546873869
[Epoch 21, Batch 800] loss: 0.006320334239233034
[Epoch 21, Batch 900] loss: 0.007383088830977158
[Epoch 21, Batch 1000] loss: 0.01654531249349702
[Epoch 21, Batch 1100] loss: 0.006356637904559648
[Epoch 21, Batch 1200] loss: 0.0034531950595408033
[Epoch 21, Batch 1300] loss: 0.0035270821325434553
[Epoch 21, Batch 1400] loss: 0.009477331614950799
[Epoch 21, Batch 1500] loss: 0.007124279713061696
[Epoch 21, Batch 1600] loss: 0.013311499222247676
[Epoch 21, Batch 1700] loss: 0.009371098967080797
[Epoch 21, Batch 1800] loss: 0.007499784022777476
[Epoch 21, Batch 1900] loss: 0.010673590687470097
[Epoch 21, Batch 2000] loss: 0.005647169115512725
[Epoch 21, Batch 2100] loss: 0.009631406301205061
[Epoch 21, Batch 2200] loss: 0.0065830096576974025
[Epoch 21, Batch 2300] loss: 0.004912233807683606
[Epoch 21, Batch 2400] loss: 0.007516689302505597
[Epoch 21, Batch 2500] loss: 0.007217229604925705
[Epoch 21, Batch 2600] loss: 0.014032767192145882
[Epoch 21, Batch 2700] loss: 0.01114068381768334
[Epoch 21, Batch 2800] loss: 0.0073653003526908374
[Epoch 21, Batch 2900] loss: 0.011150099553092332
[Epoch 21, Batch 3000] loss: 0.016356750916205556
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9865
Overfitting: 0.0513
[Epoch 22, Batch 100] loss: 0.011774929757575592
[Epoch 22, Batch 200] loss: 0.007078422985289308
[Epoch 22, Batch 300] loss: 0.01015833854014886
[Epoch 22, Batch 400] loss: 0.0037000527065868026
[Epoch 22, Batch 500] loss: 0.005558019739754627
[Epoch 22, Batch 600] loss: 0.003922794302116017
[Epoch 22, Batch 700] loss: 0.004901816120891454
[Epoch 22, Batch 800] loss: 0.008729571272410794
[Epoch 22, Batch 900] loss: 0.006052477835946774
[Epoch 22, Batch 1000] loss: 0.006161961833182659
[Epoch 22, Batch 1100] loss: 0.008527312066940027
[Epoch 22, Batch 1200] loss: 0.014430720376911949
[Epoch 22, Batch 1300] loss: 0.008895261850709631
[Epoch 22, Batch 1400] loss: 0.007835349801255234
[Epoch 22, Batch 1500] loss: 0.010505990654773995
[Epoch 22, Batch 1600] loss: 0.012480054488717087
[Epoch 22, Batch 1700] loss: 0.013088000951111099
[Epoch 22, Batch 1800] loss: 0.007240270703210854
[Epoch 22, Batch 1900] loss: 0.01074443867591981
[Epoch 22, Batch 2000] loss: 0.01166998030365221
[Epoch 22, Batch 2100] loss: 0.011982463118067698
[Epoch 22, Batch 2200] loss: 0.009753047191513814
[Epoch 22, Batch 2300] loss: 0.009545720544923739
[Epoch 22, Batch 2400] loss: 0.004068635689000075
[Epoch 22, Batch 2500] loss: 0.011519237879410867
[Epoch 22, Batch 2600] loss: 0.009939859137463146
[Epoch 22, Batch 2700] loss: 0.007111336096804735
[Epoch 22, Batch 2800] loss: 0.01066382084296265
[Epoch 22, Batch 2900] loss: 0.00979942300444236
[Epoch 22, Batch 3000] loss: 0.007324219648323833
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0414
Validation Accuracy: 0.9897
Overfitting: 0.0414
[Epoch 23, Batch 100] loss: 0.006064466815541891
[Epoch 23, Batch 200] loss: 0.00871445742212245
[Epoch 23, Batch 300] loss: 0.004539541078002003
[Epoch 23, Batch 400] loss: 0.006318722738951692
[Epoch 23, Batch 500] loss: 0.0064472745808870965
[Epoch 23, Batch 600] loss: 0.004892684857616132
[Epoch 23, Batch 700] loss: 0.008835420262925027
[Epoch 23, Batch 800] loss: 0.004795268030570696
[Epoch 23, Batch 900] loss: 0.004057791794523382
[Epoch 23, Batch 1000] loss: 0.007495408729112114
[Epoch 23, Batch 1100] loss: 0.009098709990757925
[Epoch 23, Batch 1200] loss: 0.006985866597756285
[Epoch 23, Batch 1300] loss: 0.00742851639243554
[Epoch 23, Batch 1400] loss: 0.006888986185654176
[Epoch 23, Batch 1500] loss: 0.00859575446781946
[Epoch 23, Batch 1600] loss: 0.0061468149665802226
[Epoch 23, Batch 1700] loss: 0.01695413162641444
[Epoch 23, Batch 1800] loss: 0.00717639535937451
[Epoch 23, Batch 1900] loss: 0.010048416748807085
[Epoch 23, Batch 2000] loss: 0.009295178007608911
[Epoch 23, Batch 2100] loss: 0.004404760308683535
[Epoch 23, Batch 2200] loss: 0.006236834504886701
[Epoch 23, Batch 2300] loss: 0.006440435753688689
[Epoch 23, Batch 2400] loss: 0.006116906340162131
[Epoch 23, Batch 2500] loss: 0.004185148739541091
[Epoch 23, Batch 2600] loss: 0.0027312883239801523
[Epoch 23, Batch 2700] loss: 0.004962983789316695
[Epoch 23, Batch 2800] loss: 0.008901727597304045
[Epoch 23, Batch 2900] loss: 0.008227220486255647
[Epoch 23, Batch 3000] loss: 0.008287377615231436
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9881
Overfitting: 0.0467
[Epoch 24, Batch 100] loss: 0.005533144691580674
[Epoch 24, Batch 200] loss: 0.005598719838371835
[Epoch 24, Batch 300] loss: 0.005341621750228569
[Epoch 24, Batch 400] loss: 0.011935723993610736
[Epoch 24, Batch 500] loss: 0.0038414043203010804
[Epoch 24, Batch 600] loss: 0.006976513874269586
[Epoch 24, Batch 700] loss: 0.0029016152561064244
[Epoch 24, Batch 800] loss: 0.002587585965304129
[Epoch 24, Batch 900] loss: 0.008786988310998823
[Epoch 24, Batch 1000] loss: 0.007387525427271839
[Epoch 24, Batch 1100] loss: 0.008511501448150511
[Epoch 24, Batch 1200] loss: 0.0020310506767825132
[Epoch 24, Batch 1300] loss: 0.0046030707230329425
[Epoch 24, Batch 1400] loss: 0.0016622629806573742
[Epoch 24, Batch 1500] loss: 0.006214867013255798
[Epoch 24, Batch 1600] loss: 0.008380727361533218
[Epoch 24, Batch 1700] loss: 0.004513819739273117
[Epoch 24, Batch 1800] loss: 0.0056796966033834904
[Epoch 24, Batch 1900] loss: 0.004181275186792846
[Epoch 24, Batch 2000] loss: 0.005061937646530623
[Epoch 24, Batch 2100] loss: 0.006415082090237547
[Epoch 24, Batch 2200] loss: 0.00701521210000152
[Epoch 24, Batch 2300] loss: 0.0078006326273202834
[Epoch 24, Batch 2400] loss: 0.016132585874440792
[Epoch 24, Batch 2500] loss: 0.005283834303475033
[Epoch 24, Batch 2600] loss: 0.011019994755442894
[Epoch 24, Batch 2700] loss: 0.013781819152418393
[Epoch 24, Batch 2800] loss: 0.009521662408224075
[Epoch 24, Batch 2900] loss: 0.008808434708348613
[Epoch 24, Batch 3000] loss: 0.009098976307723206
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9888
Overfitting: 0.0462
Fold 5 validation loss: 0.0462
Mean validation loss across all folds for Trial 3 is 0.0505 with trial config:  l1: 128, l2: 128, lr: 0.000816845589476017, batch_size: 16
[I 2024-12-11 01:46:58,273] Trial 2 finished with value: 0.05047263894358398 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.000816845589476017, 'batch_size': 16}. Best is trial 2 with value: 0.05047263894358398.

Selected Hyperparameters for Trial 4:
  l1: 128, l2: 128, lr: 0.00853618986286683, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.8327856373786926
[Epoch 1, Batch 200] loss: 0.6788862511515618
[Epoch 1, Batch 300] loss: 0.3227658441290259
[Epoch 1, Batch 400] loss: 0.2406549156457186
[Epoch 1, Batch 500] loss: 0.20777010075282307
[Epoch 1, Batch 600] loss: 0.21808755013160408
[Epoch 1, Batch 700] loss: 0.16851236088899896
[Epoch 1, Batch 800] loss: 0.1389417336427141
[Epoch 1, Batch 900] loss: 0.11611386943899561
[Epoch 1, Batch 1000] loss: 0.15434226313838736
[Epoch 1, Batch 1100] loss: 0.13918237032950856
[Epoch 1, Batch 1200] loss: 0.13920168020413257
[Epoch 1, Batch 1300] loss: 0.1110582528001396
[Epoch 1, Batch 1400] loss: 0.11730050984420813
[Epoch 1, Batch 1500] loss: 0.11394744116347283
[Epoch 1, Batch 1600] loss: 0.11861655446118675
[Epoch 1, Batch 1700] loss: 0.11373952616704627
[Epoch 1, Batch 1800] loss: 0.09285682259534951
[Epoch 1, Batch 1900] loss: 0.10927211644651834
[Epoch 1, Batch 2000] loss: 0.10307443402009085
[Epoch 1, Batch 2100] loss: 0.09395622323383578
[Epoch 1, Batch 2200] loss: 0.08655735377338715
[Epoch 1, Batch 2300] loss: 0.11626784751191735
[Epoch 1, Batch 2400] loss: 0.07076408827444539
[Epoch 1, Batch 2500] loss: 0.06956232662996627
[Epoch 1, Batch 2600] loss: 0.10085961535107345
[Epoch 1, Batch 2700] loss: 0.05838922121416545
[Epoch 1, Batch 2800] loss: 0.09665794360422296
[Epoch 1, Batch 2900] loss: 0.06398548295774162
[Epoch 1, Batch 3000] loss: 0.10089335914468393
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0845
Validation Accuracy: 0.9752
Overfitting: 0.0845
Best model saved at epoch 1 with validation loss: 0.0845
[Epoch 2, Batch 100] loss: 0.0811362933885539
[Epoch 2, Batch 200] loss: 0.07741254936699989
[Epoch 2, Batch 300] loss: 0.059523892028373666
[Epoch 2, Batch 400] loss: 0.05949113067341386
[Epoch 2, Batch 500] loss: 0.040990741542045725
[Epoch 2, Batch 600] loss: 0.07894610353047028
[Epoch 2, Batch 700] loss: 0.08217180776497117
[Epoch 2, Batch 800] loss: 0.059810665476543366
[Epoch 2, Batch 900] loss: 0.05640855297540839
[Epoch 2, Batch 1000] loss: 0.06312703623363632
[Epoch 2, Batch 1100] loss: 0.0911396022439294
[Epoch 2, Batch 1200] loss: 0.0592867532762466
[Epoch 2, Batch 1300] loss: 0.039830178865031485
[Epoch 2, Batch 1400] loss: 0.06201048293885833
[Epoch 2, Batch 1500] loss: 0.059829986088443546
[Epoch 2, Batch 1600] loss: 0.07723674196618958
[Epoch 2, Batch 1700] loss: 0.08471149454679107
[Epoch 2, Batch 1800] loss: 0.058246306361979805
[Epoch 2, Batch 1900] loss: 0.07676064011393464
[Epoch 2, Batch 2000] loss: 0.062390883117332124
[Epoch 2, Batch 2100] loss: 0.07728444069565739
[Epoch 2, Batch 2200] loss: 0.05757224288143334
[Epoch 2, Batch 2300] loss: 0.07235708766806055
[Epoch 2, Batch 2400] loss: 0.030712312192263197
[Epoch 2, Batch 2500] loss: 0.06694972186611267
[Epoch 2, Batch 2600] loss: 0.06255843317238031
[Epoch 2, Batch 2700] loss: 0.06709711631090613
[Epoch 2, Batch 2800] loss: 0.056086871123116
[Epoch 2, Batch 2900] loss: 0.059879631142903234
[Epoch 2, Batch 3000] loss: 0.0641848581164959
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0872
Validation Accuracy: 0.9749
Overfitting: 0.0872
[Epoch 3, Batch 100] loss: 0.05780896217402187
[Epoch 3, Batch 200] loss: 0.04923889271847656
[Epoch 3, Batch 300] loss: 0.055709569411483244
[Epoch 3, Batch 400] loss: 0.056377973675989776
[Epoch 3, Batch 500] loss: 0.04979146819721791
[Epoch 3, Batch 600] loss: 0.028104301518142166
[Epoch 3, Batch 700] loss: 0.0480089311134725
[Epoch 3, Batch 800] loss: 0.050804222005735936
[Epoch 3, Batch 900] loss: 0.056705368934490255
[Epoch 3, Batch 1000] loss: 0.05133010308360099
[Epoch 3, Batch 1100] loss: 0.07156092608624022
[Epoch 3, Batch 1200] loss: 0.0538146353521006
[Epoch 3, Batch 1300] loss: 0.04669554459731444
[Epoch 3, Batch 1400] loss: 0.03838227138759976
[Epoch 3, Batch 1500] loss: 0.027340752005693504
[Epoch 3, Batch 1600] loss: 0.04118998771323277
[Epoch 3, Batch 1700] loss: 0.07008643739158288
[Epoch 3, Batch 1800] loss: 0.05405528715080436
[Epoch 3, Batch 1900] loss: 0.04578068928647554
[Epoch 3, Batch 2000] loss: 0.03824349613129016
[Epoch 3, Batch 2100] loss: 0.041651762358887935
[Epoch 3, Batch 2200] loss: 0.04608979394957714
[Epoch 3, Batch 2300] loss: 0.05787231130660075
[Epoch 3, Batch 2400] loss: 0.05795024661194475
[Epoch 3, Batch 2500] loss: 0.05301573422599176
[Epoch 3, Batch 2600] loss: 0.03948678930200913
[Epoch 3, Batch 2700] loss: 0.058364064662673625
[Epoch 3, Batch 2800] loss: 0.051276683697906264
[Epoch 3, Batch 2900] loss: 0.0428120705047877
[Epoch 3, Batch 3000] loss: 0.06821804847846578
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9833
Overfitting: 0.0549
Best model saved at epoch 3 with validation loss: 0.0549
[Epoch 4, Batch 100] loss: 0.030076357335310604
[Epoch 4, Batch 200] loss: 0.02103490893765411
[Epoch 4, Batch 300] loss: 0.029489473714911583
[Epoch 4, Batch 400] loss: 0.04606974621869995
[Epoch 4, Batch 500] loss: 0.04388568132490036
[Epoch 4, Batch 600] loss: 0.039267256655439266
[Epoch 4, Batch 700] loss: 0.051805881886575665
[Epoch 4, Batch 800] loss: 0.04724934224670505
[Epoch 4, Batch 900] loss: 0.031372638995890156
[Epoch 4, Batch 1000] loss: 0.03235826750961678
[Epoch 4, Batch 1100] loss: 0.0224831683820139
[Epoch 4, Batch 1200] loss: 0.04587426799208515
[Epoch 4, Batch 1300] loss: 0.03371577412410261
[Epoch 4, Batch 1400] loss: 0.04321410248947359
[Epoch 4, Batch 1500] loss: 0.04434793100110255
[Epoch 4, Batch 1600] loss: 0.03566169491754408
[Epoch 4, Batch 1700] loss: 0.034098047339648475
[Epoch 4, Batch 1800] loss: 0.032561357298855
[Epoch 4, Batch 1900] loss: 0.04648502506064915
[Epoch 4, Batch 2000] loss: 0.04065290074671793
[Epoch 4, Batch 2100] loss: 0.057844265493840794
[Epoch 4, Batch 2200] loss: 0.0337558370208717
[Epoch 4, Batch 2300] loss: 0.045844398358067334
[Epoch 4, Batch 2400] loss: 0.047179101864239785
[Epoch 4, Batch 2500] loss: 0.03863570498495392
[Epoch 4, Batch 2600] loss: 0.03575506918288738
[Epoch 4, Batch 2700] loss: 0.03853532240562345
[Epoch 4, Batch 2800] loss: 0.027341226825938064
[Epoch 4, Batch 2900] loss: 0.04173274192744429
[Epoch 4, Batch 3000] loss: 0.027420866574966566
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9858
Overfitting: 0.0491
Best model saved at epoch 4 with validation loss: 0.0491
[Epoch 5, Batch 100] loss: 0.03728574659491187
[Epoch 5, Batch 200] loss: 0.021649237298470327
[Epoch 5, Batch 300] loss: 0.042212212587646715
[Epoch 5, Batch 400] loss: 0.04677978678497311
[Epoch 5, Batch 500] loss: 0.031102583314595905
[Epoch 5, Batch 600] loss: 0.027834990794031
[Epoch 5, Batch 700] loss: 0.0316264062355549
[Epoch 5, Batch 800] loss: 0.023208395225265122
[Epoch 5, Batch 900] loss: 0.03668100466506985
[Epoch 5, Batch 1000] loss: 0.025468502456650412
[Epoch 5, Batch 1100] loss: 0.028601386723548786
[Epoch 5, Batch 1200] loss: 0.05691926765015523
[Epoch 5, Batch 1300] loss: 0.04310183695435626
[Epoch 5, Batch 1400] loss: 0.01700984436984072
[Epoch 5, Batch 1500] loss: 0.02837681442899793
[Epoch 5, Batch 1600] loss: 0.03322245029930855
[Epoch 5, Batch 1700] loss: 0.027857526296356808
[Epoch 5, Batch 1800] loss: 0.043014088868885664
[Epoch 5, Batch 1900] loss: 0.04040952698901265
[Epoch 5, Batch 2000] loss: 0.03744991558668062
[Epoch 5, Batch 2100] loss: 0.03395154125289992
[Epoch 5, Batch 2200] loss: 0.03438382834386175
[Epoch 5, Batch 2300] loss: 0.026070460434639245
[Epoch 5, Batch 2400] loss: 0.03440752120111938
[Epoch 5, Batch 2500] loss: 0.025185763301974477
[Epoch 5, Batch 2600] loss: 0.03413588703554524
[Epoch 5, Batch 2700] loss: 0.03583175553301771
[Epoch 5, Batch 2800] loss: 0.032040177616963775
[Epoch 5, Batch 2900] loss: 0.06264273993093411
[Epoch 5, Batch 3000] loss: 0.028435253343395743
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0557
Validation Accuracy: 0.9851
Overfitting: 0.0557
[Epoch 6, Batch 100] loss: 0.034057114186689434
[Epoch 6, Batch 200] loss: 0.02726381620312168
[Epoch 6, Batch 300] loss: 0.02331395034576417
[Epoch 6, Batch 400] loss: 0.025053748293303216
[Epoch 6, Batch 500] loss: 0.018165769047793105
[Epoch 6, Batch 600] loss: 0.02770223892710419
[Epoch 6, Batch 700] loss: 0.020625646887203856
[Epoch 6, Batch 800] loss: 0.020572403154581025
[Epoch 6, Batch 900] loss: 0.036676597042282995
[Epoch 6, Batch 1000] loss: 0.039363768515408994
[Epoch 6, Batch 1100] loss: 0.0378802911724415
[Epoch 6, Batch 1200] loss: 0.024997551262868
[Epoch 6, Batch 1300] loss: 0.017647035398872503
[Epoch 6, Batch 1400] loss: 0.030037601032763633
[Epoch 6, Batch 1500] loss: 0.052619464130766576
[Epoch 6, Batch 1600] loss: 0.0334449871722245
[Epoch 6, Batch 1700] loss: 0.02302089402102865
[Epoch 6, Batch 1800] loss: 0.029154132332046175
[Epoch 6, Batch 1900] loss: 0.03413919017415537
[Epoch 6, Batch 2000] loss: 0.021827193790993533
[Epoch 6, Batch 2100] loss: 0.015016261711753031
[Epoch 6, Batch 2200] loss: 0.021643963379706293
[Epoch 6, Batch 2300] loss: 0.037429708739384185
[Epoch 6, Batch 2400] loss: 0.04403135949389252
[Epoch 6, Batch 2500] loss: 0.02805491928995252
[Epoch 6, Batch 2600] loss: 0.033851815773796264
[Epoch 6, Batch 2700] loss: 0.016512306599765908
[Epoch 6, Batch 2800] loss: 0.03832269796190303
[Epoch 6, Batch 2900] loss: 0.03764841655640339
[Epoch 6, Batch 3000] loss: 0.021218248941631827
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0609
Validation Accuracy: 0.9845
Overfitting: 0.0609
[Epoch 7, Batch 100] loss: 0.03286480425822447
[Epoch 7, Batch 200] loss: 0.027146134140530194
[Epoch 7, Batch 300] loss: 0.015167437697009518
[Epoch 7, Batch 400] loss: 0.028750518731740157
[Epoch 7, Batch 500] loss: 0.019002446290501213
[Epoch 7, Batch 600] loss: 0.02193126054455888
[Epoch 7, Batch 700] loss: 0.03396281680090766
[Epoch 7, Batch 800] loss: 0.02822134072976951
[Epoch 7, Batch 900] loss: 0.02292974780424629
[Epoch 7, Batch 1000] loss: 0.022853290614275466
[Epoch 7, Batch 1100] loss: 0.021525745764479326
[Epoch 7, Batch 1200] loss: 0.032499077900902194
[Epoch 7, Batch 1300] loss: 0.02619012047786896
[Epoch 7, Batch 1400] loss: 0.01867689268669892
[Epoch 7, Batch 1500] loss: 0.0236619626522679
[Epoch 7, Batch 1600] loss: 0.017986156761644452
[Epoch 7, Batch 1700] loss: 0.037711435891374094
[Epoch 7, Batch 1800] loss: 0.03731706521692899
[Epoch 7, Batch 1900] loss: 0.012064040809545986
[Epoch 7, Batch 2000] loss: 0.009171944677043343
[Epoch 7, Batch 2100] loss: 0.022493093673595012
[Epoch 7, Batch 2200] loss: 0.035099458784145554
[Epoch 7, Batch 2300] loss: 0.028675962957141792
[Epoch 7, Batch 2400] loss: 0.014180771760302378
[Epoch 7, Batch 2500] loss: 0.038258489548934446
[Epoch 7, Batch 2600] loss: 0.0143380378444283
[Epoch 7, Batch 2700] loss: 0.022473194702424308
[Epoch 7, Batch 2800] loss: 0.01906332678045601
[Epoch 7, Batch 2900] loss: 0.024463837058772243
[Epoch 7, Batch 3000] loss: 0.03334078658022918
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9868
Overfitting: 0.0514
[Epoch 8, Batch 100] loss: 0.016153720114318162
[Epoch 8, Batch 200] loss: 0.016574236635426585
[Epoch 8, Batch 300] loss: 0.022318287471966868
[Epoch 8, Batch 400] loss: 0.02966860975174427
[Epoch 8, Batch 500] loss: 0.014233696256414987
[Epoch 8, Batch 600] loss: 0.010784352247450996
[Epoch 8, Batch 700] loss: 0.03472389762128841
[Epoch 8, Batch 800] loss: 0.022690190687101222
[Epoch 8, Batch 900] loss: 0.026792973748938492
[Epoch 8, Batch 1000] loss: 0.025505875998666737
[Epoch 8, Batch 1100] loss: 0.03331007001923922
[Epoch 8, Batch 1200] loss: 0.01506611512410558
[Epoch 8, Batch 1300] loss: 0.018252570688932934
[Epoch 8, Batch 1400] loss: 0.032736011265006935
[Epoch 8, Batch 1500] loss: 0.013798401074574258
[Epoch 8, Batch 1600] loss: 0.027498636053930454
[Epoch 8, Batch 1700] loss: 0.02218368380809352
[Epoch 8, Batch 1800] loss: 0.02618766597947399
[Epoch 8, Batch 1900] loss: 0.021347208855494272
[Epoch 8, Batch 2000] loss: 0.026591083326233046
[Epoch 8, Batch 2100] loss: 0.02480235820167536
[Epoch 8, Batch 2200] loss: 0.026114745953673264
[Epoch 8, Batch 2300] loss: 0.011122934066413279
[Epoch 8, Batch 2400] loss: 0.014574625936373877
[Epoch 8, Batch 2500] loss: 0.02597721731863885
[Epoch 8, Batch 2600] loss: 0.02154394736431499
[Epoch 8, Batch 2700] loss: 0.018011037042192583
[Epoch 8, Batch 2800] loss: 0.02876354798886041
[Epoch 8, Batch 2900] loss: 0.035930211550466995
[Epoch 8, Batch 3000] loss: 0.03920456972405191
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0566
Validation Accuracy: 0.9853
Overfitting: 0.0566
[Epoch 9, Batch 100] loss: 0.014329607749484694
[Epoch 9, Batch 200] loss: 0.015807337027390532
[Epoch 9, Batch 300] loss: 0.017341851294299885
[Epoch 9, Batch 400] loss: 0.03515785565127061
[Epoch 9, Batch 500] loss: 0.01718737192991284
[Epoch 9, Batch 600] loss: 0.015140689049669618
[Epoch 9, Batch 700] loss: 0.013511888377253171
[Epoch 9, Batch 800] loss: 0.011436081872896011
[Epoch 9, Batch 900] loss: 0.013932366362108723
[Epoch 9, Batch 1000] loss: 0.00981167584128002
[Epoch 9, Batch 1100] loss: 0.016525761892678473
[Epoch 9, Batch 1200] loss: 0.018436530370508707
[Epoch 9, Batch 1300] loss: 0.019385856876423305
[Epoch 9, Batch 1400] loss: 0.02618123967957672
[Epoch 9, Batch 1500] loss: 0.020075613135376785
[Epoch 9, Batch 1600] loss: 0.02704140393211489
[Epoch 9, Batch 1700] loss: 0.02053891063784107
[Epoch 9, Batch 1800] loss: 0.02712870062308241
[Epoch 9, Batch 1900] loss: 0.02397693280178487
[Epoch 9, Batch 2000] loss: 0.029825781215695315
[Epoch 9, Batch 2100] loss: 0.02866678442356033
[Epoch 9, Batch 2200] loss: 0.016214985352407892
[Epoch 9, Batch 2300] loss: 0.022227757141608323
[Epoch 9, Batch 2400] loss: 0.046168940916127214
[Epoch 9, Batch 2500] loss: 0.012536328220984388
[Epoch 9, Batch 2600] loss: 0.02994431051245229
[Epoch 9, Batch 2700] loss: 0.0362229100667264
[Epoch 9, Batch 2800] loss: 0.02534287807018245
[Epoch 9, Batch 2900] loss: 0.026990856543470727
[Epoch 9, Batch 3000] loss: 0.022031546005769086
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0545
Validation Accuracy: 0.9853
Overfitting: 0.0545
[Epoch 10, Batch 100] loss: 0.012546289232499248
[Epoch 10, Batch 200] loss: 0.008967571859755098
[Epoch 10, Batch 300] loss: 0.007962857655699054
[Epoch 10, Batch 400] loss: 0.01692700631738326
[Epoch 10, Batch 500] loss: 0.009422079145177804
[Epoch 10, Batch 600] loss: 0.009930661846504733
[Epoch 10, Batch 700] loss: 0.008478167572376946
[Epoch 10, Batch 800] loss: 0.01755959121182684
[Epoch 10, Batch 900] loss: 0.015457512885130314
[Epoch 10, Batch 1000] loss: 0.013639350626624492
[Epoch 10, Batch 1100] loss: 0.026174450449767617
[Epoch 10, Batch 1200] loss: 0.025145169696161034
[Epoch 10, Batch 1300] loss: 0.024611421766904867
[Epoch 10, Batch 1400] loss: 0.03674789975917975
[Epoch 10, Batch 1500] loss: 0.023876938149269337
[Epoch 10, Batch 1600] loss: 0.010481149217398525
[Epoch 10, Batch 1700] loss: 0.03322716452520467
[Epoch 10, Batch 1800] loss: 0.019499660533924726
[Epoch 10, Batch 1900] loss: 0.01675338213461487
[Epoch 10, Batch 2000] loss: 0.015540406205970428
[Epoch 10, Batch 2100] loss: 0.031865429257081815
[Epoch 10, Batch 2200] loss: 0.02136776310152527
[Epoch 10, Batch 2300] loss: 0.004368795124680674
[Epoch 10, Batch 2400] loss: 0.018168697096416508
[Epoch 10, Batch 2500] loss: 0.02227170206685969
[Epoch 10, Batch 2600] loss: 0.01685485744268476
[Epoch 10, Batch 2700] loss: 0.01608351960716675
[Epoch 10, Batch 2800] loss: 0.02334772691320062
[Epoch 10, Batch 2900] loss: 0.031122957319339548
[Epoch 10, Batch 3000] loss: 0.018998065579708054
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0558
Validation Accuracy: 0.9867
Overfitting: 0.0558
[Epoch 11, Batch 100] loss: 0.017777484600161417
[Epoch 11, Batch 200] loss: 0.005330556290433037
[Epoch 11, Batch 300] loss: 0.010417686511491482
[Epoch 11, Batch 400] loss: 0.008827203467270693
[Epoch 11, Batch 500] loss: 0.009839315875061167
[Epoch 11, Batch 600] loss: 0.01764425579874981
[Epoch 11, Batch 700] loss: 0.028637404096219825
[Epoch 11, Batch 800] loss: 0.020428444787121407
[Epoch 11, Batch 900] loss: 0.01091279575740316
[Epoch 11, Batch 1000] loss: 0.006615124967477613
[Epoch 11, Batch 1100] loss: 0.01365267899065266
[Epoch 11, Batch 1200] loss: 0.012219506128468218
[Epoch 11, Batch 1300] loss: 0.027140035975567117
[Epoch 11, Batch 1400] loss: 0.019130777770746975
[Epoch 11, Batch 1500] loss: 0.013597625019036705
[Epoch 11, Batch 1600] loss: 0.021372663716757074
[Epoch 11, Batch 1700] loss: 0.011957628725510504
[Epoch 11, Batch 1800] loss: 0.01271946147236914
[Epoch 11, Batch 1900] loss: 0.015642900835098884
[Epoch 11, Batch 2000] loss: 0.034012045952100146
[Epoch 11, Batch 2100] loss: 0.03043606282243644
[Epoch 11, Batch 2200] loss: 0.0069515600794220235
[Epoch 11, Batch 2300] loss: 0.03481231332561107
[Epoch 11, Batch 2400] loss: 0.023121814840259276
[Epoch 11, Batch 2500] loss: 0.02437085296750638
[Epoch 11, Batch 2600] loss: 0.03254283436137882
[Epoch 11, Batch 2700] loss: 0.02256879066229061
[Epoch 11, Batch 2800] loss: 0.033784712090006226
[Epoch 11, Batch 2900] loss: 0.02984818627995594
[Epoch 11, Batch 3000] loss: 0.026942718934146796
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0594
Validation Accuracy: 0.9860
Overfitting: 0.0594
[Epoch 12, Batch 100] loss: 0.01876828890628417
[Epoch 12, Batch 200] loss: 0.015526222676197677
[Epoch 12, Batch 300] loss: 0.00902313116482162
[Epoch 12, Batch 400] loss: 0.012287332430716589
[Epoch 12, Batch 500] loss: 0.015574624210045442
[Epoch 12, Batch 600] loss: 0.023541754752936014
[Epoch 12, Batch 700] loss: 0.019626256013780433
[Epoch 12, Batch 800] loss: 0.009816092775073955
[Epoch 12, Batch 900] loss: 0.02160386897999075
[Epoch 12, Batch 1000] loss: 0.010904727979908699
[Epoch 12, Batch 1100] loss: 0.012866316301350444
[Epoch 12, Batch 1200] loss: 0.014164409446632024
[Epoch 12, Batch 1300] loss: 0.013381921912154269
[Epoch 12, Batch 1400] loss: 0.01859878620916362
[Epoch 12, Batch 1500] loss: 0.03538453323432421
[Epoch 12, Batch 1600] loss: 0.045843074790692245
[Epoch 12, Batch 1700] loss: 0.022262288226241083
[Epoch 12, Batch 1800] loss: 0.027294385662993505
[Epoch 12, Batch 1900] loss: 0.02126934365917634
[Epoch 12, Batch 2000] loss: 0.02137404509113196
[Epoch 12, Batch 2100] loss: 0.04671528374309446
[Epoch 12, Batch 2200] loss: 0.032942716244830306
[Epoch 12, Batch 2300] loss: 0.026378154104131114
[Epoch 12, Batch 2400] loss: 0.03118028809760858
[Epoch 12, Batch 2500] loss: 0.02284214154079052
[Epoch 12, Batch 2600] loss: 0.02013822841276152
[Epoch 12, Batch 2700] loss: 0.04216139448205411
[Epoch 12, Batch 2800] loss: 0.01780219213034172
[Epoch 12, Batch 2900] loss: 0.026810274156699735
[Epoch 12, Batch 3000] loss: 0.017350694739161555
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0530
Validation Accuracy: 0.9877
Overfitting: 0.0530
[Epoch 13, Batch 100] loss: 0.016444685062099184
[Epoch 13, Batch 200] loss: 0.022227166986127714
[Epoch 13, Batch 300] loss: 0.0019175466037700773
[Epoch 13, Batch 400] loss: 0.03427212496778338
[Epoch 13, Batch 500] loss: 0.012528294558527194
[Epoch 13, Batch 600] loss: 0.0238648000255165
[Epoch 13, Batch 700] loss: 0.01758495079070542
[Epoch 13, Batch 800] loss: 0.018063000758736507
[Epoch 13, Batch 900] loss: 0.008155138712493227
[Epoch 13, Batch 1000] loss: 0.015347906685923719
[Epoch 13, Batch 1100] loss: 0.007515946013452037
[Epoch 13, Batch 1200] loss: 0.005509751711604167
[Epoch 13, Batch 1300] loss: 0.007531938522006101
[Epoch 13, Batch 1400] loss: 0.02622620715948841
[Epoch 13, Batch 1500] loss: 0.005515330983326119
[Epoch 13, Batch 1600] loss: 0.01822660476293791
[Epoch 13, Batch 1700] loss: 0.01271471199068671
[Epoch 13, Batch 1800] loss: 0.013461076917025921
[Epoch 13, Batch 1900] loss: 0.011242727068630245
[Epoch 13, Batch 2000] loss: 0.01514525762173779
[Epoch 13, Batch 2100] loss: 0.017151262981504368
[Epoch 13, Batch 2200] loss: 0.027671595657292727
[Epoch 13, Batch 2300] loss: 0.017443813229658645
[Epoch 13, Batch 2400] loss: 0.014865833022466858
[Epoch 13, Batch 2500] loss: 0.01593360082528818
[Epoch 13, Batch 2600] loss: 0.02551449067930065
[Epoch 13, Batch 2700] loss: 0.018847519680609822
[Epoch 13, Batch 2800] loss: 0.019137770805847297
[Epoch 13, Batch 2900] loss: 0.030928316658690704
[Epoch 13, Batch 3000] loss: 0.01864805089318452
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9868
Overfitting: 0.0632
[Epoch 14, Batch 100] loss: 0.017434394988165316
[Epoch 14, Batch 200] loss: 0.004944101809386509
[Epoch 14, Batch 300] loss: 0.03954584338989889
[Epoch 14, Batch 400] loss: 0.032173912127000215
[Epoch 14, Batch 500] loss: 0.0215758767735565
[Epoch 14, Batch 600] loss: 0.010035427372935146
[Epoch 14, Batch 700] loss: 0.005098900966121391
[Epoch 14, Batch 800] loss: 0.006819282885185345
[Epoch 14, Batch 900] loss: 0.010942401911662004
[Epoch 14, Batch 1000] loss: 0.022637941644272245
[Epoch 14, Batch 1100] loss: 0.0107507167239622
[Epoch 14, Batch 1200] loss: 0.011542289604577647
[Epoch 14, Batch 1300] loss: 0.009460287615563062
[Epoch 14, Batch 1400] loss: 0.018489680819745617
[Epoch 14, Batch 1500] loss: 0.013027733405063486
[Epoch 14, Batch 1600] loss: 0.03626732254522949
[Epoch 14, Batch 1700] loss: 0.019219258653249086
[Epoch 14, Batch 1800] loss: 0.011310325089041555
[Epoch 14, Batch 1900] loss: 0.009622997428562598
[Epoch 14, Batch 2000] loss: 0.01211051534376253
[Epoch 14, Batch 2100] loss: 0.013729072954239
[Epoch 14, Batch 2200] loss: 0.021657440384613973
[Epoch 14, Batch 2300] loss: 0.014724482329525444
[Epoch 14, Batch 2400] loss: 0.006107677807397352
[Epoch 14, Batch 2500] loss: 0.00700101878915703
[Epoch 14, Batch 2600] loss: 0.0111736339841584
[Epoch 14, Batch 2700] loss: 0.013725292065363411
[Epoch 14, Batch 2800] loss: 0.01932986028020167
[Epoch 14, Batch 2900] loss: 0.021276879006946244
[Epoch 14, Batch 3000] loss: 0.023468291581211817
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0583
Validation Accuracy: 0.9862
Overfitting: 0.0583
[Epoch 15, Batch 100] loss: 0.013003335687869252
[Epoch 15, Batch 200] loss: 0.018486498621807988
[Epoch 15, Batch 300] loss: 0.019418951156985963
[Epoch 15, Batch 400] loss: 0.016842841413829177
[Epoch 15, Batch 500] loss: 0.004837098183212958
[Epoch 15, Batch 600] loss: 0.008235266016306877
[Epoch 15, Batch 700] loss: 0.025349397024217454
[Epoch 15, Batch 800] loss: 0.013068440901860186
[Epoch 15, Batch 900] loss: 0.019346715097590988
[Epoch 15, Batch 1000] loss: 0.006356061916316129
[Epoch 15, Batch 1100] loss: 0.017559096886382318
[Epoch 15, Batch 1200] loss: 0.024355158947325463
[Epoch 15, Batch 1300] loss: 0.019877580225336543
[Epoch 15, Batch 1400] loss: 0.02502019368420747
[Epoch 15, Batch 1500] loss: 0.021442088330147158
[Epoch 15, Batch 1600] loss: 0.03219247217732402
[Epoch 15, Batch 1700] loss: 0.01776054521558166
[Epoch 15, Batch 1800] loss: 0.03147410112698253
[Epoch 15, Batch 1900] loss: 0.0160695263877718
[Epoch 15, Batch 2000] loss: 0.016955177084830596
[Epoch 15, Batch 2100] loss: 0.024948919284842646
[Epoch 15, Batch 2200] loss: 0.02269925309868104
[Epoch 15, Batch 2300] loss: 0.01442960700529099
[Epoch 15, Batch 2400] loss: 0.00474584492322137
[Epoch 15, Batch 2500] loss: 0.006809001625341118
[Epoch 15, Batch 2600] loss: 0.015712880252532476
[Epoch 15, Batch 2700] loss: 0.025911575073382168
[Epoch 15, Batch 2800] loss: 0.010503308315384804
[Epoch 15, Batch 2900] loss: 0.01961677738639806
[Epoch 15, Batch 3000] loss: 0.01376362351243742
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0728
Validation Accuracy: 0.9854
Overfitting: 0.0728
[Epoch 16, Batch 100] loss: 0.005867057221758265
[Epoch 16, Batch 200] loss: 0.010100475983643059
[Epoch 16, Batch 300] loss: 0.013581693383404314
[Epoch 16, Batch 400] loss: 0.015417138210565468
[Epoch 16, Batch 500] loss: 0.0032529169731242468
[Epoch 16, Batch 600] loss: 0.0028002804217231157
[Epoch 16, Batch 700] loss: 0.006714868161184246
[Epoch 16, Batch 800] loss: 0.011290185980208686
[Epoch 16, Batch 900] loss: 0.026483949662947218
[Epoch 16, Batch 1000] loss: 0.02513026301993275
[Epoch 16, Batch 1100] loss: 0.01660924495297749
[Epoch 16, Batch 1200] loss: 0.023874484644671838
[Epoch 16, Batch 1300] loss: 0.019678024334696717
[Epoch 16, Batch 1400] loss: 0.01679278863911506
[Epoch 16, Batch 1500] loss: 0.013956487328166052
[Epoch 16, Batch 1600] loss: 0.007979236033002728
[Epoch 16, Batch 1700] loss: 0.013141348796316628
[Epoch 16, Batch 1800] loss: 0.010418350303888132
[Epoch 16, Batch 1900] loss: 0.01019163492327408
[Epoch 16, Batch 2000] loss: 0.00999740345709149
[Epoch 16, Batch 2100] loss: 0.018052291336745192
[Epoch 16, Batch 2200] loss: 0.00533208013597811
[Epoch 16, Batch 2300] loss: 0.01475722189642132
[Epoch 16, Batch 2400] loss: 0.008557573490649242
[Epoch 16, Batch 2500] loss: 0.02131311023850145
[Epoch 16, Batch 2600] loss: 0.008125841786130223
[Epoch 16, Batch 2700] loss: 0.0131887473140323
[Epoch 16, Batch 2800] loss: 0.01304001230196965
[Epoch 16, Batch 2900] loss: 0.011630362352192272
[Epoch 16, Batch 3000] loss: 0.011863601858473039
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0724
Validation Accuracy: 0.9860
Overfitting: 0.0724
[Epoch 17, Batch 100] loss: 0.011742963925683511
[Epoch 17, Batch 200] loss: 0.020218023701891918
[Epoch 17, Batch 300] loss: 0.016155620443075235
[Epoch 17, Batch 400] loss: 0.017237318229289995
[Epoch 17, Batch 500] loss: 0.022650478522729212
[Epoch 17, Batch 600] loss: 0.026623382125445298
[Epoch 17, Batch 700] loss: 0.0070828950273006
[Epoch 17, Batch 800] loss: 0.0031133651591315117
[Epoch 17, Batch 900] loss: 0.007193252489577096
[Epoch 17, Batch 1000] loss: 0.0017778387410949349
[Epoch 17, Batch 1100] loss: 0.012591686997811316
[Epoch 17, Batch 1200] loss: 0.06886902584277303
[Epoch 17, Batch 1300] loss: 0.044738021625397834
[Epoch 17, Batch 1400] loss: 0.01954984037774984
[Epoch 17, Batch 1500] loss: 0.011239792669008786
[Epoch 17, Batch 1600] loss: 0.028374278247748047
[Epoch 17, Batch 1700] loss: 0.01843020417203796
[Epoch 17, Batch 1800] loss: 0.024976117236114072
[Epoch 17, Batch 1900] loss: 0.01548995683125435
[Epoch 17, Batch 2000] loss: 0.04257319559501667
[Epoch 17, Batch 2100] loss: 0.04377357541955917
[Epoch 17, Batch 2200] loss: 0.033751086207113305
[Epoch 17, Batch 2300] loss: 0.022240040110844746
[Epoch 17, Batch 2400] loss: 0.024686701168625404
[Epoch 17, Batch 2500] loss: 0.017621086488726973
[Epoch 17, Batch 2600] loss: 0.015993569155358767
[Epoch 17, Batch 2700] loss: 0.008668705132923882
[Epoch 17, Batch 2800] loss: 0.006704227343280875
[Epoch 17, Batch 2900] loss: 0.015608950982275207
[Epoch 17, Batch 3000] loss: 0.017968715815040878
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0808
Validation Accuracy: 0.9864
Overfitting: 0.0808
[Epoch 18, Batch 100] loss: 0.019178537835214546
[Epoch 18, Batch 200] loss: 0.011619683784090853
[Epoch 18, Batch 300] loss: 0.022152633154599775
[Epoch 18, Batch 400] loss: 0.014252821357037244
[Epoch 18, Batch 500] loss: 0.01728547436302103
[Epoch 18, Batch 600] loss: 0.03337938248581693
[Epoch 18, Batch 700] loss: 0.01680485282438708
[Epoch 18, Batch 800] loss: 0.03008435658478226
[Epoch 18, Batch 900] loss: 0.032340428992396614
[Epoch 18, Batch 1000] loss: 0.012647530656967625
[Epoch 18, Batch 1100] loss: 0.009096825250139915
[Epoch 18, Batch 1200] loss: 0.04316967299248283
[Epoch 18, Batch 1300] loss: 0.011329868492875192
[Epoch 18, Batch 1400] loss: 0.019400368583813683
[Epoch 18, Batch 1500] loss: 0.023916275400103045
[Epoch 18, Batch 1600] loss: 0.009668858082496285
[Epoch 18, Batch 1700] loss: 0.004250393209896615
[Epoch 18, Batch 1800] loss: 0.008025705652125362
[Epoch 18, Batch 1900] loss: 0.03689661908892198
[Epoch 18, Batch 2000] loss: 0.046204136645080475
[Epoch 18, Batch 2100] loss: 0.035420955957828244
[Epoch 18, Batch 2200] loss: 0.040381226604777394
[Epoch 18, Batch 2300] loss: 0.029256767064588303
[Epoch 18, Batch 2400] loss: 0.01483862614752411
[Epoch 18, Batch 2500] loss: 0.012200022042890382
[Epoch 18, Batch 2600] loss: 0.026091009829592587
[Epoch 18, Batch 2700] loss: 0.0317474732202292
[Epoch 18, Batch 2800] loss: 0.011784452445191494
[Epoch 18, Batch 2900] loss: 0.025491227720533582
[Epoch 18, Batch 3000] loss: 0.014381450464623101
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0572
Validation Accuracy: 0.9878
Overfitting: 0.0572
[Epoch 19, Batch 100] loss: 0.009133298726825388
[Epoch 19, Batch 200] loss: 0.008324139207737984
[Epoch 19, Batch 300] loss: 0.0054322691273742275
[Epoch 19, Batch 400] loss: 0.018304852079780637
[Epoch 19, Batch 500] loss: 0.016520887264759098
[Epoch 19, Batch 600] loss: 0.011521558874622749
[Epoch 19, Batch 700] loss: 0.0055783407444749454
[Epoch 19, Batch 800] loss: 0.003144455041821126
[Epoch 19, Batch 900] loss: 0.024618304873877155
[Epoch 19, Batch 1000] loss: 0.029249294642308746
[Epoch 19, Batch 1100] loss: 0.015365375702907046
[Epoch 19, Batch 1200] loss: 0.00507347349368958
[Epoch 19, Batch 1300] loss: 0.014431576746593962
[Epoch 19, Batch 1400] loss: 0.013152631884048156
[Epoch 19, Batch 1500] loss: 0.00739012950544911
[Epoch 19, Batch 1600] loss: 0.006281896767114543
[Epoch 19, Batch 1700] loss: 0.018681339775396776
[Epoch 19, Batch 1800] loss: 0.012300916320719626
[Epoch 19, Batch 1900] loss: 0.0038117353382077467
[Epoch 19, Batch 2000] loss: 0.008911269417754658
[Epoch 19, Batch 2100] loss: 0.015281842745422795
[Epoch 19, Batch 2200] loss: 0.02681914239147396
[Epoch 19, Batch 2300] loss: 0.03499471972561054
[Epoch 19, Batch 2400] loss: 0.01653128150031131
[Epoch 19, Batch 2500] loss: 0.012257596641970988
[Epoch 19, Batch 2600] loss: 0.01445871357300888
[Epoch 19, Batch 2700] loss: 0.014246492256874107
[Epoch 19, Batch 2800] loss: 0.02127201805710797
[Epoch 19, Batch 2900] loss: 0.02839707577552167
[Epoch 19, Batch 3000] loss: 0.01516570701892178
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0797
Validation Accuracy: 0.9828
Overfitting: 0.0797
[Epoch 20, Batch 100] loss: 0.01470123358930369
[Epoch 20, Batch 200] loss: 0.01727782305274598
[Epoch 20, Batch 300] loss: 0.011182101522595422
[Epoch 20, Batch 400] loss: 0.013449986809633501
[Epoch 20, Batch 500] loss: 0.003519347503580419
[Epoch 20, Batch 600] loss: 0.0016312999370923587
[Epoch 20, Batch 700] loss: 0.027406945483638437
[Epoch 20, Batch 800] loss: 0.015459960649985614
[Epoch 20, Batch 900] loss: 0.015252955965762639
[Epoch 20, Batch 1000] loss: 0.027273070505169947
[Epoch 20, Batch 1100] loss: 0.023763376210570834
[Epoch 20, Batch 1200] loss: 0.011934916114443644
[Epoch 20, Batch 1300] loss: 0.024474285835053386
[Epoch 20, Batch 1400] loss: 0.019276693283385306
[Epoch 20, Batch 1500] loss: 0.003570395537757132
[Epoch 20, Batch 1600] loss: 0.038869888797046295
[Epoch 20, Batch 1700] loss: 0.006383846947351231
[Epoch 20, Batch 1800] loss: 0.016772013497892563
[Epoch 20, Batch 1900] loss: 0.009815898868944233
[Epoch 20, Batch 2000] loss: 0.006155102941822803
[Epoch 20, Batch 2100] loss: 0.007909465678375112
[Epoch 20, Batch 2200] loss: 0.007098899688503031
[Epoch 20, Batch 2300] loss: 0.005661459865499898
[Epoch 20, Batch 2400] loss: 0.004763701708087926
[Epoch 20, Batch 2500] loss: 0.011460922327808376
[Epoch 20, Batch 2600] loss: 0.010634779889298764
[Epoch 20, Batch 2700] loss: 0.007967940883478878
[Epoch 20, Batch 2800] loss: 0.019115278844198887
[Epoch 20, Batch 2900] loss: 0.020994376827425457
[Epoch 20, Batch 3000] loss: 0.020286156009227056
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0616
Validation Accuracy: 0.9882
Overfitting: 0.0616
[Epoch 21, Batch 100] loss: 0.011926061034235502
[Epoch 21, Batch 200] loss: 0.004002685487352973
[Epoch 21, Batch 300] loss: 0.007570383436405752
[Epoch 21, Batch 400] loss: 0.015593496802078298
[Epoch 21, Batch 500] loss: 0.009924071179682551
[Epoch 21, Batch 600] loss: 0.011514574898575086
[Epoch 21, Batch 700] loss: 0.011678671340894514
[Epoch 21, Batch 800] loss: 0.012791469807629489
[Epoch 21, Batch 900] loss: 0.012262272689097653
[Epoch 21, Batch 1000] loss: 0.018909980615525276
[Epoch 21, Batch 1100] loss: 0.012780390485546538
[Epoch 21, Batch 1200] loss: 0.009576300725905575
[Epoch 21, Batch 1300] loss: 0.019201381719719843
[Epoch 21, Batch 1400] loss: 0.03789298993837356
[Epoch 21, Batch 1500] loss: 0.06807929767460731
[Epoch 21, Batch 1600] loss: 0.044806130194302796
[Epoch 21, Batch 1700] loss: 0.030617079425645635
[Epoch 21, Batch 1800] loss: 0.026587377477476283
[Epoch 21, Batch 1900] loss: 0.018776988381925843
[Epoch 21, Batch 2000] loss: 0.0257658621042005
[Epoch 21, Batch 2100] loss: 0.05675620223186925
[Epoch 21, Batch 2200] loss: 0.028551115356528954
[Epoch 21, Batch 2300] loss: 0.013225571265224403
[Epoch 21, Batch 2400] loss: 0.024063705800920588
[Epoch 21, Batch 2500] loss: 0.03929535639398633
[Epoch 21, Batch 2600] loss: 0.016141201729556513
[Epoch 21, Batch 2700] loss: 0.010433506601160759
[Epoch 21, Batch 2800] loss: 0.015904970485811135
[Epoch 21, Batch 2900] loss: 0.0162279315178872
[Epoch 21, Batch 3000] loss: 0.02593992440017738
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0861
Validation Accuracy: 0.9831
Overfitting: 0.0861
[Epoch 22, Batch 100] loss: 0.02992486834337754
[Epoch 22, Batch 200] loss: 0.0098460027962647
[Epoch 22, Batch 300] loss: 0.009036659415501181
[Epoch 22, Batch 400] loss: 0.006453008142475607
[Epoch 22, Batch 500] loss: 0.020525315667920783
[Epoch 22, Batch 600] loss: 0.013649355804576829
[Epoch 22, Batch 700] loss: 0.008377034063449376
[Epoch 22, Batch 800] loss: 0.005028040300220962
[Epoch 22, Batch 900] loss: 0.007952446467193383
[Epoch 22, Batch 1000] loss: 0.0016628401981030017
[Epoch 22, Batch 1100] loss: 0.004475853783575126
[Epoch 22, Batch 1200] loss: 0.007523902740607942
[Epoch 22, Batch 1300] loss: 0.019597466910968767
[Epoch 22, Batch 1400] loss: 0.002019526083090173
[Epoch 22, Batch 1500] loss: 0.004181078830874703
[Epoch 22, Batch 1600] loss: 0.008740412719460649
[Epoch 22, Batch 1700] loss: 0.017035556158871968
[Epoch 22, Batch 1800] loss: 0.006462416841472627
[Epoch 22, Batch 1900] loss: 0.021762838737780656
[Epoch 22, Batch 2000] loss: 0.006306865145311753
[Epoch 22, Batch 2100] loss: 0.03286930380165517
[Epoch 22, Batch 2200] loss: 0.016195230878951587
[Epoch 22, Batch 2300] loss: 0.0217571295537704
[Epoch 22, Batch 2400] loss: 0.01901567749353074
[Epoch 22, Batch 2500] loss: 0.030841186379668813
[Epoch 22, Batch 2600] loss: 0.027922440625922487
[Epoch 22, Batch 2700] loss: 0.029031749094080704
[Epoch 22, Batch 2800] loss: 0.04070607868842638
[Epoch 22, Batch 2900] loss: 0.028202543617362005
[Epoch 22, Batch 3000] loss: 0.03389618120602769
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0796
Validation Accuracy: 0.9852
Overfitting: 0.0796
[Epoch 23, Batch 100] loss: 0.014834864704750466
[Epoch 23, Batch 200] loss: 0.010633527021889
[Epoch 23, Batch 300] loss: 0.013824989000900621
[Epoch 23, Batch 400] loss: 0.005824421311032601
[Epoch 23, Batch 500] loss: 0.013382616550909545
[Epoch 23, Batch 600] loss: 0.016263876989994784
[Epoch 23, Batch 700] loss: 0.023161770652649606
[Epoch 23, Batch 800] loss: 0.04385618310735926
[Epoch 23, Batch 900] loss: 0.025834529611516163
[Epoch 23, Batch 1000] loss: 0.020762831888798416
[Epoch 23, Batch 1100] loss: 0.0335415013270091
[Epoch 23, Batch 1200] loss: 0.040716567127280626
[Epoch 23, Batch 1300] loss: 0.017079247651587113
[Epoch 23, Batch 1400] loss: 0.036536910364405345
[Epoch 23, Batch 1500] loss: 0.012759792075387
[Epoch 23, Batch 1600] loss: 0.01855746435115587
[Epoch 23, Batch 1700] loss: 0.012434827273088232
[Epoch 23, Batch 1800] loss: 0.019607250197857532
[Epoch 23, Batch 1900] loss: 0.05192835868633422
[Epoch 23, Batch 2000] loss: 0.03737404195388166
[Epoch 23, Batch 2100] loss: 0.00608449994248498
[Epoch 23, Batch 2200] loss: 0.02616019726455981
[Epoch 23, Batch 2300] loss: 0.01960473030327812
[Epoch 23, Batch 2400] loss: 0.028388181418666888
[Epoch 23, Batch 2500] loss: 0.00671189381249885
[Epoch 23, Batch 2600] loss: 0.031895016951373166
[Epoch 23, Batch 2700] loss: 0.019813819220485626
[Epoch 23, Batch 2800] loss: 0.01981937119565572
[Epoch 23, Batch 2900] loss: 0.016638135547541566
[Epoch 23, Batch 3000] loss: 0.018041828210944216
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0733
Validation Accuracy: 0.9863
Overfitting: 0.0733
[Epoch 24, Batch 100] loss: 0.01616025236414515
[Epoch 24, Batch 200] loss: 0.00914017293396824
[Epoch 24, Batch 300] loss: 0.012523993379446843
[Epoch 24, Batch 400] loss: 0.0035299914837452827
[Epoch 24, Batch 500] loss: 0.007346015285774117
[Epoch 24, Batch 600] loss: 0.016811589485227287
[Epoch 24, Batch 700] loss: 0.007579774403151238
[Epoch 24, Batch 800] loss: 0.009664490916970076
[Epoch 24, Batch 900] loss: 0.012577813666080325
[Epoch 24, Batch 1000] loss: 0.011375907246935135
[Epoch 24, Batch 1100] loss: 0.01135028963858943
[Epoch 24, Batch 1200] loss: 0.0076682165865391205
[Epoch 24, Batch 1300] loss: 0.004873823562265503
[Epoch 24, Batch 1400] loss: 0.01491156393731957
[Epoch 24, Batch 1500] loss: 0.015185162737101158
[Epoch 24, Batch 1600] loss: 0.0113059812543908
[Epoch 24, Batch 1700] loss: 0.017887857210334913
[Epoch 24, Batch 1800] loss: 0.00914047647435726
[Epoch 24, Batch 1900] loss: 0.006357853642558573
[Epoch 24, Batch 2000] loss: 0.007707733930001845
[Epoch 24, Batch 2100] loss: 0.01560421418226567
[Epoch 24, Batch 2200] loss: 0.026938268372598665
[Epoch 24, Batch 2300] loss: 0.003998347961516373
[Epoch 24, Batch 2400] loss: 0.013171360610423611
[Epoch 24, Batch 2500] loss: 0.04931538586929852
[Epoch 24, Batch 2600] loss: 0.01818134502942172
[Epoch 24, Batch 2700] loss: 0.021101119611012464
[Epoch 24, Batch 2800] loss: 0.009615537011078637
[Epoch 24, Batch 2900] loss: 0.02258727558579711
[Epoch 24, Batch 3000] loss: 0.01940946355155322
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0731
Validation Accuracy: 0.9861
Overfitting: 0.0731
Fold 1 validation loss: 0.0731
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.9889569461345673
[Epoch 1, Batch 200] loss: 0.5786652210354805
[Epoch 1, Batch 300] loss: 0.4005629650503397
[Epoch 1, Batch 400] loss: 0.29469691216014327
[Epoch 1, Batch 500] loss: 0.18309286340605468
[Epoch 1, Batch 600] loss: 0.17451667800545692
[Epoch 1, Batch 700] loss: 0.19061145742191002
[Epoch 1, Batch 800] loss: 0.17704619495430962
[Epoch 1, Batch 900] loss: 0.1328727211584919
[Epoch 1, Batch 1000] loss: 0.12794793192762882
[Epoch 1, Batch 1100] loss: 0.1356094683415722
[Epoch 1, Batch 1200] loss: 0.14382903404097305
[Epoch 1, Batch 1300] loss: 0.11374752628980786
[Epoch 1, Batch 1400] loss: 0.12861088116304017
[Epoch 1, Batch 1500] loss: 0.1275037022936158
[Epoch 1, Batch 1600] loss: 0.11535244978498667
[Epoch 1, Batch 1700] loss: 0.07723729795659892
[Epoch 1, Batch 1800] loss: 0.13310253060335525
[Epoch 1, Batch 1900] loss: 0.10490161084686406
[Epoch 1, Batch 2000] loss: 0.11317446135508362
[Epoch 1, Batch 2100] loss: 0.10737119886733126
[Epoch 1, Batch 2200] loss: 0.10706664219382218
[Epoch 1, Batch 2300] loss: 0.10165296689257958
[Epoch 1, Batch 2400] loss: 0.09603038865825511
[Epoch 1, Batch 2500] loss: 0.09698006442398764
[Epoch 1, Batch 2600] loss: 0.08065573625273828
[Epoch 1, Batch 2700] loss: 0.08897368215897586
[Epoch 1, Batch 2800] loss: 0.08025757082708879
[Epoch 1, Batch 2900] loss: 0.07841538556560408
[Epoch 1, Batch 3000] loss: 0.06423147988170967
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0845
Validation Accuracy: 0.9749
Overfitting: 0.0845
Best model saved at epoch 1 with validation loss: 0.0845
[Epoch 2, Batch 100] loss: 0.04882398989640933
[Epoch 2, Batch 200] loss: 0.07746839382278267
[Epoch 2, Batch 300] loss: 0.06327389132929966
[Epoch 2, Batch 400] loss: 0.07410960193112259
[Epoch 2, Batch 500] loss: 0.06859884858946316
[Epoch 2, Batch 600] loss: 0.07129475967813051
[Epoch 2, Batch 700] loss: 0.06477531301032285
[Epoch 2, Batch 800] loss: 0.07701468399842269
[Epoch 2, Batch 900] loss: 0.06420100169896614
[Epoch 2, Batch 1000] loss: 0.06142951118068595
[Epoch 2, Batch 1100] loss: 0.08185748093717848
[Epoch 2, Batch 1200] loss: 0.07301106401660945
[Epoch 2, Batch 1300] loss: 0.08195254026606563
[Epoch 2, Batch 1400] loss: 0.0493885589299316
[Epoch 2, Batch 1500] loss: 0.06857832478599449
[Epoch 2, Batch 1600] loss: 0.06314208516392682
[Epoch 2, Batch 1700] loss: 0.07389074674632866
[Epoch 2, Batch 1800] loss: 0.07485426267914591
[Epoch 2, Batch 1900] loss: 0.05230238223244669
[Epoch 2, Batch 2000] loss: 0.06630717359061236
[Epoch 2, Batch 2100] loss: 0.0592599937619525
[Epoch 2, Batch 2200] loss: 0.07548273147840519
[Epoch 2, Batch 2300] loss: 0.05450864541606279
[Epoch 2, Batch 2400] loss: 0.06105848193707061
[Epoch 2, Batch 2500] loss: 0.05518511939502787
[Epoch 2, Batch 2600] loss: 0.035771567995470835
[Epoch 2, Batch 2700] loss: 0.06278055486269295
[Epoch 2, Batch 2800] loss: 0.04273749849806336
[Epoch 2, Batch 2900] loss: 0.07935388209225494
[Epoch 2, Batch 3000] loss: 0.051600698970942174
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0742
Validation Accuracy: 0.9798
Overfitting: 0.0742
Best model saved at epoch 2 with validation loss: 0.0742
[Epoch 3, Batch 100] loss: 0.04539836213858507
[Epoch 3, Batch 200] loss: 0.029175523610210804
[Epoch 3, Batch 300] loss: 0.04127589631360024
[Epoch 3, Batch 400] loss: 0.03793302153571858
[Epoch 3, Batch 500] loss: 0.04480139978171792
[Epoch 3, Batch 600] loss: 0.06415369316877331
[Epoch 3, Batch 700] loss: 0.05497734625882003
[Epoch 3, Batch 800] loss: 0.05301705115394725
[Epoch 3, Batch 900] loss: 0.03707823050574916
[Epoch 3, Batch 1000] loss: 0.04301076159994409
[Epoch 3, Batch 1100] loss: 0.054858992623012456
[Epoch 3, Batch 1200] loss: 0.05405846454606945
[Epoch 3, Batch 1300] loss: 0.04679652977905789
[Epoch 3, Batch 1400] loss: 0.07407872853607841
[Epoch 3, Batch 1500] loss: 0.05246633710581591
[Epoch 3, Batch 1600] loss: 0.060522647421894366
[Epoch 3, Batch 1700] loss: 0.045526033861606266
[Epoch 3, Batch 1800] loss: 0.039799246434122325
[Epoch 3, Batch 1900] loss: 0.050354259549239944
[Epoch 3, Batch 2000] loss: 0.04085483980903518
[Epoch 3, Batch 2100] loss: 0.04245236106438824
[Epoch 3, Batch 2200] loss: 0.06100690347579075
[Epoch 3, Batch 2300] loss: 0.05609241499128984
[Epoch 3, Batch 2400] loss: 0.04145484641026997
[Epoch 3, Batch 2500] loss: 0.04272399451831006
[Epoch 3, Batch 2600] loss: 0.04526312415156099
[Epoch 3, Batch 2700] loss: 0.04524483162460001
[Epoch 3, Batch 2800] loss: 0.04472162652782572
[Epoch 3, Batch 2900] loss: 0.06325327083875891
[Epoch 3, Batch 3000] loss: 0.052076909102588616
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0579
Validation Accuracy: 0.9853
Overfitting: 0.0579
Best model saved at epoch 3 with validation loss: 0.0579
[Epoch 4, Batch 100] loss: 0.024214790407295367
[Epoch 4, Batch 200] loss: 0.022590289822746853
[Epoch 4, Batch 300] loss: 0.035043906092832915
[Epoch 4, Batch 400] loss: 0.03713231190133229
[Epoch 4, Batch 500] loss: 0.027338181206760057
[Epoch 4, Batch 600] loss: 0.02190370205176805
[Epoch 4, Batch 700] loss: 0.02091701075872038
[Epoch 4, Batch 800] loss: 0.049427364249668246
[Epoch 4, Batch 900] loss: 0.024854040454520145
[Epoch 4, Batch 1000] loss: 0.03699619346791223
[Epoch 4, Batch 1100] loss: 0.029892526626099425
[Epoch 4, Batch 1200] loss: 0.0458540301397079
[Epoch 4, Batch 1300] loss: 0.04466124476180994
[Epoch 4, Batch 1400] loss: 0.028163904113171156
[Epoch 4, Batch 1500] loss: 0.0356945276947954
[Epoch 4, Batch 1600] loss: 0.05622736835302931
[Epoch 4, Batch 1700] loss: 0.037228835909991174
[Epoch 4, Batch 1800] loss: 0.05933741253822518
[Epoch 4, Batch 1900] loss: 0.02618356747332655
[Epoch 4, Batch 2000] loss: 0.028530773816951297
[Epoch 4, Batch 2100] loss: 0.04785371541554923
[Epoch 4, Batch 2200] loss: 0.03976854057105811
[Epoch 4, Batch 2300] loss: 0.04532574257237684
[Epoch 4, Batch 2400] loss: 0.04303146690937865
[Epoch 4, Batch 2500] loss: 0.03849379243925796
[Epoch 4, Batch 2600] loss: 0.03717817181241116
[Epoch 4, Batch 2700] loss: 0.026049940091907045
[Epoch 4, Batch 2800] loss: 0.04438240524237699
[Epoch 4, Batch 2900] loss: 0.04698430277458101
[Epoch 4, Batch 3000] loss: 0.04251759471586411
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9832
Overfitting: 0.0606
[Epoch 5, Batch 100] loss: 0.029592330904561096
[Epoch 5, Batch 200] loss: 0.019069321954784755
[Epoch 5, Batch 300] loss: 0.023313354084821186
[Epoch 5, Batch 400] loss: 0.04003649243195469
[Epoch 5, Batch 500] loss: 0.023911832150067768
[Epoch 5, Batch 600] loss: 0.020799522690492723
[Epoch 5, Batch 700] loss: 0.031714226059289106
[Epoch 5, Batch 800] loss: 0.0354321104795963
[Epoch 5, Batch 900] loss: 0.020652183328202227
[Epoch 5, Batch 1000] loss: 0.03781212351055729
[Epoch 5, Batch 1100] loss: 0.01981069115219725
[Epoch 5, Batch 1200] loss: 0.035588928335318994
[Epoch 5, Batch 1300] loss: 0.025504426436837094
[Epoch 5, Batch 1400] loss: 0.023947354563533738
[Epoch 5, Batch 1500] loss: 0.037635954295337795
[Epoch 5, Batch 1600] loss: 0.02607396270083882
[Epoch 5, Batch 1700] loss: 0.014463696049024293
[Epoch 5, Batch 1800] loss: 0.023342007170690522
[Epoch 5, Batch 1900] loss: 0.03243351112349046
[Epoch 5, Batch 2000] loss: 0.026501165251720523
[Epoch 5, Batch 2100] loss: 0.020856911327074387
[Epoch 5, Batch 2200] loss: 0.034698120502605435
[Epoch 5, Batch 2300] loss: 0.04542784015318944
[Epoch 5, Batch 2400] loss: 0.017076714561744664
[Epoch 5, Batch 2500] loss: 0.024782773425470167
[Epoch 5, Batch 2600] loss: 0.03021238354023808
[Epoch 5, Batch 2700] loss: 0.04607015312445583
[Epoch 5, Batch 2800] loss: 0.02681423306292345
[Epoch 5, Batch 2900] loss: 0.03682882884379069
[Epoch 5, Batch 3000] loss: 0.028625759467922764
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9862
Overfitting: 0.0485
Best model saved at epoch 5 with validation loss: 0.0485
[Epoch 6, Batch 100] loss: 0.01524131274308047
[Epoch 6, Batch 200] loss: 0.021232869080242835
[Epoch 6, Batch 300] loss: 0.01974055065971811
[Epoch 6, Batch 400] loss: 0.022810697229874676
[Epoch 6, Batch 500] loss: 0.02322645564530944
[Epoch 6, Batch 600] loss: 0.0293894439806337
[Epoch 6, Batch 700] loss: 0.03205713175908386
[Epoch 6, Batch 800] loss: 0.024138029676996665
[Epoch 6, Batch 900] loss: 0.01920377594376305
[Epoch 6, Batch 1000] loss: 0.016125669865855344
[Epoch 6, Batch 1100] loss: 0.02519475128236337
[Epoch 6, Batch 1200] loss: 0.020201830397604682
[Epoch 6, Batch 1300] loss: 0.031614167562802324
[Epoch 6, Batch 1400] loss: 0.023864987199215194
[Epoch 6, Batch 1500] loss: 0.03240741706094468
[Epoch 6, Batch 1600] loss: 0.01748206630423681
[Epoch 6, Batch 1700] loss: 0.04578646070585819
[Epoch 6, Batch 1800] loss: 0.013918890315089812
[Epoch 6, Batch 1900] loss: 0.02006154220770668
[Epoch 6, Batch 2000] loss: 0.043207050125774915
[Epoch 6, Batch 2100] loss: 0.03894364058965948
[Epoch 6, Batch 2200] loss: 0.016090609206457884
[Epoch 6, Batch 2300] loss: 0.036927717786511494
[Epoch 6, Batch 2400] loss: 0.03342693922277249
[Epoch 6, Batch 2500] loss: 0.02795595758569334
[Epoch 6, Batch 2600] loss: 0.0395468826273077
[Epoch 6, Batch 2700] loss: 0.03102140256247367
[Epoch 6, Batch 2800] loss: 0.03882150750987421
[Epoch 6, Batch 2900] loss: 0.02795815373370715
[Epoch 6, Batch 3000] loss: 0.02596406497703356
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0823
Validation Accuracy: 0.9800
Overfitting: 0.0823
[Epoch 7, Batch 100] loss: 0.015788741742403543
[Epoch 7, Batch 200] loss: 0.020105149735647386
[Epoch 7, Batch 300] loss: 0.012665562397426128
[Epoch 7, Batch 400] loss: 0.03034770371266177
[Epoch 7, Batch 500] loss: 0.019968524552405144
[Epoch 7, Batch 600] loss: 0.008721417661544707
[Epoch 7, Batch 700] loss: 0.022050400667117175
[Epoch 7, Batch 800] loss: 0.026455424343348
[Epoch 7, Batch 900] loss: 0.030949645007517575
[Epoch 7, Batch 1000] loss: 0.033505248611035085
[Epoch 7, Batch 1100] loss: 0.028946768383655126
[Epoch 7, Batch 1200] loss: 0.03008188465526473
[Epoch 7, Batch 1300] loss: 0.01699433856953874
[Epoch 7, Batch 1400] loss: 0.012873140962440174
[Epoch 7, Batch 1500] loss: 0.0354183936042773
[Epoch 7, Batch 1600] loss: 0.022767372991254434
[Epoch 7, Batch 1700] loss: 0.022647210291713123
[Epoch 7, Batch 1800] loss: 0.0438706517241144
[Epoch 7, Batch 1900] loss: 0.011466388828036998
[Epoch 7, Batch 2000] loss: 0.022512341328703087
[Epoch 7, Batch 2100] loss: 0.016728875363613723
[Epoch 7, Batch 2200] loss: 0.049419778057408624
[Epoch 7, Batch 2300] loss: 0.014424758837661785
[Epoch 7, Batch 2400] loss: 0.038499290515387655
[Epoch 7, Batch 2500] loss: 0.02829687767590258
[Epoch 7, Batch 2600] loss: 0.023576092509394755
[Epoch 7, Batch 2700] loss: 0.024837734461411857
[Epoch 7, Batch 2800] loss: 0.028327805893370625
[Epoch 7, Batch 2900] loss: 0.027771163922455457
[Epoch 7, Batch 3000] loss: 0.022187510662699878
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0595
Validation Accuracy: 0.9850
Overfitting: 0.0595
[Epoch 8, Batch 100] loss: 0.02959386848355052
[Epoch 8, Batch 200] loss: 0.006899896059144908
[Epoch 8, Batch 300] loss: 0.01842400919136594
[Epoch 8, Batch 400] loss: 0.01888289963804965
[Epoch 8, Batch 500] loss: 0.025087589821175697
[Epoch 8, Batch 600] loss: 0.020382847975942014
[Epoch 8, Batch 700] loss: 0.015291643219354683
[Epoch 8, Batch 800] loss: 0.023339073191464194
[Epoch 8, Batch 900] loss: 0.03218938008963732
[Epoch 8, Batch 1000] loss: 0.017127523071569613
[Epoch 8, Batch 1100] loss: 0.018421832820265535
[Epoch 8, Batch 1200] loss: 0.0213461315786094
[Epoch 8, Batch 1300] loss: 0.0338747804569789
[Epoch 8, Batch 1400] loss: 0.025486717938122183
[Epoch 8, Batch 1500] loss: 0.026242218871358317
[Epoch 8, Batch 1600] loss: 0.02464045282408506
[Epoch 8, Batch 1700] loss: 0.02661359301642733
[Epoch 8, Batch 1800] loss: 0.026776804073188033
[Epoch 8, Batch 1900] loss: 0.021388260920986682
[Epoch 8, Batch 2000] loss: 0.03181060834426489
[Epoch 8, Batch 2100] loss: 0.0277994652276675
[Epoch 8, Batch 2200] loss: 0.015615238616887836
[Epoch 8, Batch 2300] loss: 0.03489391731984256
[Epoch 8, Batch 2400] loss: 0.01570697559538985
[Epoch 8, Batch 2500] loss: 0.019132252080537312
[Epoch 8, Batch 2600] loss: 0.014563659558969846
[Epoch 8, Batch 2700] loss: 0.020933567766094258
[Epoch 8, Batch 2800] loss: 0.016562783764267123
[Epoch 8, Batch 2900] loss: 0.015452342997950268
[Epoch 8, Batch 3000] loss: 0.019511145769810126
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9872
Overfitting: 0.0527
[Epoch 9, Batch 100] loss: 0.010509511572421104
[Epoch 9, Batch 200] loss: 0.026379585869726725
[Epoch 9, Batch 300] loss: 0.02880802889679444
[Epoch 9, Batch 400] loss: 0.02408736010192115
[Epoch 9, Batch 500] loss: 0.026614026519907553
[Epoch 9, Batch 600] loss: 0.009765079990406775
[Epoch 9, Batch 700] loss: 0.00954819298721759
[Epoch 9, Batch 800] loss: 0.012597969613607348
[Epoch 9, Batch 900] loss: 0.00782442168283069
[Epoch 9, Batch 1000] loss: 0.00845443599297255
[Epoch 9, Batch 1100] loss: 0.02321949888426161
[Epoch 9, Batch 1200] loss: 0.016765363899885984
[Epoch 9, Batch 1300] loss: 0.015180669700814633
[Epoch 9, Batch 1400] loss: 0.01783091608780069
[Epoch 9, Batch 1500] loss: 0.014032220963088093
[Epoch 9, Batch 1600] loss: 0.014470086796440568
[Epoch 9, Batch 1700] loss: 0.02825670687465701
[Epoch 9, Batch 1800] loss: 0.04136005145584477
[Epoch 9, Batch 1900] loss: 0.015567498859641092
[Epoch 9, Batch 2000] loss: 0.025869678436282583
[Epoch 9, Batch 2100] loss: 0.015911644557784255
[Epoch 9, Batch 2200] loss: 0.0238614613334647
[Epoch 9, Batch 2300] loss: 0.03719322016805364
[Epoch 9, Batch 2400] loss: 0.023302902927935066
[Epoch 9, Batch 2500] loss: 0.01574109654139889
[Epoch 9, Batch 2600] loss: 0.018723741988356437
[Epoch 9, Batch 2700] loss: 0.018045044653433706
[Epoch 9, Batch 2800] loss: 0.0227094317822457
[Epoch 9, Batch 2900] loss: 0.023506308355445073
[Epoch 9, Batch 3000] loss: 0.02098255381747663
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0647
Validation Accuracy: 0.9866
Overfitting: 0.0647
[Epoch 10, Batch 100] loss: 0.014759085013741924
[Epoch 10, Batch 200] loss: 0.02106687067138182
[Epoch 10, Batch 300] loss: 0.012499047485111986
[Epoch 10, Batch 400] loss: 0.008204892133048957
[Epoch 10, Batch 500] loss: 0.03744284297953684
[Epoch 10, Batch 600] loss: 0.02202431427391673
[Epoch 10, Batch 700] loss: 0.020005177093028122
[Epoch 10, Batch 800] loss: 0.025680031906152864
[Epoch 10, Batch 900] loss: 0.010451644912582197
[Epoch 10, Batch 1000] loss: 0.023483811232686086
[Epoch 10, Batch 1100] loss: 0.0362789162633203
[Epoch 10, Batch 1200] loss: 0.01225728624149184
[Epoch 10, Batch 1300] loss: 0.0040765417263864375
[Epoch 10, Batch 1400] loss: 0.010559765618732796
[Epoch 10, Batch 1500] loss: 0.030491747750724586
[Epoch 10, Batch 1600] loss: 0.030709869859728373
[Epoch 10, Batch 1700] loss: 0.026860755272724645
[Epoch 10, Batch 1800] loss: 0.029610883751183793
[Epoch 10, Batch 1900] loss: 0.01015448565211635
[Epoch 10, Batch 2000] loss: 0.018402406111165562
[Epoch 10, Batch 2100] loss: 0.018355524663966206
[Epoch 10, Batch 2200] loss: 0.017356356773947965
[Epoch 10, Batch 2300] loss: 0.04052398547136818
[Epoch 10, Batch 2400] loss: 0.01465682634265022
[Epoch 10, Batch 2500] loss: 0.02897799886299623
[Epoch 10, Batch 2600] loss: 0.019892082804212237
[Epoch 10, Batch 2700] loss: 0.012282416489662183
[Epoch 10, Batch 2800] loss: 0.018092860556938036
[Epoch 10, Batch 2900] loss: 0.01998624613966058
[Epoch 10, Batch 3000] loss: 0.024709178471518954
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9845
Overfitting: 0.0630
[Epoch 11, Batch 100] loss: 0.02165737508825373
[Epoch 11, Batch 200] loss: 0.01695771019566678
[Epoch 11, Batch 300] loss: 0.00893862739766277
[Epoch 11, Batch 400] loss: 0.01391080743081222
[Epoch 11, Batch 500] loss: 0.021296822741219613
[Epoch 11, Batch 600] loss: 0.01381371228493208
[Epoch 11, Batch 700] loss: 0.024915963259652472
[Epoch 11, Batch 800] loss: 0.01896399790158451
[Epoch 11, Batch 900] loss: 0.020253913387168154
[Epoch 11, Batch 1000] loss: 0.02128482248928094
[Epoch 11, Batch 1100] loss: 0.010864207546476337
[Epoch 11, Batch 1200] loss: 0.013826116619307988
[Epoch 11, Batch 1300] loss: 0.012864047158882386
[Epoch 11, Batch 1400] loss: 0.008494638664796241
[Epoch 11, Batch 1500] loss: 0.015355170644916143
[Epoch 11, Batch 1600] loss: 0.010062423250947177
[Epoch 11, Batch 1700] loss: 0.029666503637368464
[Epoch 11, Batch 1800] loss: 0.017818790741128795
[Epoch 11, Batch 1900] loss: 0.01570382785753507
[Epoch 11, Batch 2000] loss: 0.016863096054839488
[Epoch 11, Batch 2100] loss: 0.009588299278644002
[Epoch 11, Batch 2200] loss: 0.02555606844021568
[Epoch 11, Batch 2300] loss: 0.023507985618154523
[Epoch 11, Batch 2400] loss: 0.028426531367240954
[Epoch 11, Batch 2500] loss: 0.015041726932008146
[Epoch 11, Batch 2600] loss: 0.0062536052707889665
[Epoch 11, Batch 2700] loss: 0.015255155690337148
[Epoch 11, Batch 2800] loss: 0.008219210194812447
[Epoch 11, Batch 2900] loss: 0.030080059216011392
[Epoch 11, Batch 3000] loss: 0.01730479122049701
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0663
Validation Accuracy: 0.9854
Overfitting: 0.0663
[Epoch 12, Batch 100] loss: 0.011418733932496821
[Epoch 12, Batch 200] loss: 0.0056386927240759735
[Epoch 12, Batch 300] loss: 0.005217383605274964
[Epoch 12, Batch 400] loss: 0.008918933485138397
[Epoch 12, Batch 500] loss: 0.013186085283996207
[Epoch 12, Batch 600] loss: 0.014915302689785394
[Epoch 12, Batch 700] loss: 0.01456667451647284
[Epoch 12, Batch 800] loss: 0.014481693375383867
[Epoch 12, Batch 900] loss: 0.02357412651231151
[Epoch 12, Batch 1000] loss: 0.015462751183431997
[Epoch 12, Batch 1100] loss: 0.012364149964571674
[Epoch 12, Batch 1200] loss: 0.010244185812423581
[Epoch 12, Batch 1300] loss: 0.019671539802683283
[Epoch 12, Batch 1400] loss: 0.013162615945121558
[Epoch 12, Batch 1500] loss: 0.012533638849360961
[Epoch 12, Batch 1600] loss: 0.010348321039923749
[Epoch 12, Batch 1700] loss: 0.005591492621772307
[Epoch 12, Batch 1800] loss: 0.013238641258745147
[Epoch 12, Batch 1900] loss: 0.018625617619500386
[Epoch 12, Batch 2000] loss: 0.011693808691409053
[Epoch 12, Batch 2100] loss: 0.01708701342439497
[Epoch 12, Batch 2200] loss: 0.028337745391657166
[Epoch 12, Batch 2300] loss: 0.014112314410165094
[Epoch 12, Batch 2400] loss: 0.03603598197914817
[Epoch 12, Batch 2500] loss: 0.011171438216116485
[Epoch 12, Batch 2600] loss: 0.024300519244534087
[Epoch 12, Batch 2700] loss: 0.026525665580162176
[Epoch 12, Batch 2800] loss: 0.004463707148648268
[Epoch 12, Batch 2900] loss: 0.013668262313573081
[Epoch 12, Batch 3000] loss: 0.02541265876669911
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0687
Validation Accuracy: 0.9833
Overfitting: 0.0687
[Epoch 13, Batch 100] loss: 0.009759945069035715
[Epoch 13, Batch 200] loss: 0.0044414321420512696
[Epoch 13, Batch 300] loss: 0.015159431308364963
[Epoch 13, Batch 400] loss: 0.005799824800163442
[Epoch 13, Batch 500] loss: 0.011891575718794112
[Epoch 13, Batch 600] loss: 0.012036953600299344
[Epoch 13, Batch 700] loss: 0.010411457483329799
[Epoch 13, Batch 800] loss: 0.006030255683810637
[Epoch 13, Batch 900] loss: 0.008107473825827683
[Epoch 13, Batch 1000] loss: 0.00964214030473542
[Epoch 13, Batch 1100] loss: 0.013681367753140989
[Epoch 13, Batch 1200] loss: 0.016104001510942254
[Epoch 13, Batch 1300] loss: 0.02013804681460272
[Epoch 13, Batch 1400] loss: 0.012647575319489733
[Epoch 13, Batch 1500] loss: 0.003726578421836262
[Epoch 13, Batch 1600] loss: 0.010855556212960566
[Epoch 13, Batch 1700] loss: 0.018114409007960006
[Epoch 13, Batch 1800] loss: 0.023787900921655555
[Epoch 13, Batch 1900] loss: 0.03837185572980017
[Epoch 13, Batch 2000] loss: 0.013836787048879771
[Epoch 13, Batch 2100] loss: 0.015516049856493196
[Epoch 13, Batch 2200] loss: 0.004604343723349871
[Epoch 13, Batch 2300] loss: 0.010428638346182168
[Epoch 13, Batch 2400] loss: 0.021823816447006407
[Epoch 13, Batch 2500] loss: 0.012512066603848808
[Epoch 13, Batch 2600] loss: 0.017778098852309156
[Epoch 13, Batch 2700] loss: 0.018206730913076816
[Epoch 13, Batch 2800] loss: 0.03407735217548748
[Epoch 13, Batch 2900] loss: 0.013520600338515862
[Epoch 13, Batch 3000] loss: 0.014364880728434067
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0734
Validation Accuracy: 0.9854
Overfitting: 0.0734
[Epoch 14, Batch 100] loss: 0.015121149810653165
[Epoch 14, Batch 200] loss: 0.01864437891933079
[Epoch 14, Batch 300] loss: 0.015008344170884626
[Epoch 14, Batch 400] loss: 0.013086797151712445
[Epoch 14, Batch 500] loss: 0.0068472370116741035
[Epoch 14, Batch 600] loss: 0.016651597755770773
[Epoch 14, Batch 700] loss: 0.009979251715517154
[Epoch 14, Batch 800] loss: 0.019803434367533724
[Epoch 14, Batch 900] loss: 0.016033568881597376
[Epoch 14, Batch 1000] loss: 0.009220095239656202
[Epoch 14, Batch 1100] loss: 0.012999897431565235
[Epoch 14, Batch 1200] loss: 0.008546059593651947
[Epoch 14, Batch 1300] loss: 0.02446796036647409
[Epoch 14, Batch 1400] loss: 0.04388404731098881
[Epoch 14, Batch 1500] loss: 0.01638960420273932
[Epoch 14, Batch 1600] loss: 0.024902124491968606
[Epoch 14, Batch 1700] loss: 0.0412347202333801
[Epoch 14, Batch 1800] loss: 0.010551089888214661
[Epoch 14, Batch 1900] loss: 0.01189730495494742
[Epoch 14, Batch 2000] loss: 0.025837394659006384
[Epoch 14, Batch 2100] loss: 0.034070814565917575
[Epoch 14, Batch 2200] loss: 0.022093287165590992
[Epoch 14, Batch 2300] loss: 0.013947058961575252
[Epoch 14, Batch 2400] loss: 0.019982494133832917
[Epoch 14, Batch 2500] loss: 0.025419046226960517
[Epoch 14, Batch 2600] loss: 0.028972372012399317
[Epoch 14, Batch 2700] loss: 0.024353839565029175
[Epoch 14, Batch 2800] loss: 0.0071229245308215994
[Epoch 14, Batch 2900] loss: 0.01957825536695953
[Epoch 14, Batch 3000] loss: 0.009975823378376561
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0724
Validation Accuracy: 0.9853
Overfitting: 0.0724
[Epoch 15, Batch 100] loss: 0.038371848591812634
[Epoch 15, Batch 200] loss: 0.012938918588681646
[Epoch 15, Batch 300] loss: 0.009406742605549426
[Epoch 15, Batch 400] loss: 0.007318772813430883
[Epoch 15, Batch 500] loss: 0.01772210097496071
[Epoch 15, Batch 600] loss: 0.013147271093595663
[Epoch 15, Batch 700] loss: 0.007550414124809776
[Epoch 15, Batch 800] loss: 0.011447825291704699
[Epoch 15, Batch 900] loss: 0.005406037202582468
[Epoch 15, Batch 1000] loss: 0.010764896963818056
[Epoch 15, Batch 1100] loss: 0.026115544770180108
[Epoch 15, Batch 1200] loss: 0.02111375013135099
[Epoch 15, Batch 1300] loss: 0.02175725880218265
[Epoch 15, Batch 1400] loss: 0.013231093598082283
[Epoch 15, Batch 1500] loss: 0.010901319296554988
[Epoch 15, Batch 1600] loss: 0.015979897134954263
[Epoch 15, Batch 1700] loss: 0.015663115219522298
[Epoch 15, Batch 1800] loss: 0.013838986506311244
[Epoch 15, Batch 1900] loss: 0.02383406124130942
[Epoch 15, Batch 2000] loss: 0.024910689909864912
[Epoch 15, Batch 2100] loss: 0.012083464278579186
[Epoch 15, Batch 2200] loss: 0.010836549922021774
[Epoch 15, Batch 2300] loss: 0.03262211518597951
[Epoch 15, Batch 2400] loss: 0.014847037290450924
[Epoch 15, Batch 2500] loss: 0.01708696135056293
[Epoch 15, Batch 2600] loss: 0.004658268255483544
[Epoch 15, Batch 2700] loss: 0.009885872708293698
[Epoch 15, Batch 2800] loss: 0.021213404504017173
[Epoch 15, Batch 2900] loss: 0.019181330522823784
[Epoch 15, Batch 3000] loss: 0.03153329928260337
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0748
Validation Accuracy: 0.9868
Overfitting: 0.0748
[Epoch 16, Batch 100] loss: 0.02546699864625076
[Epoch 16, Batch 200] loss: 0.004718008450304576
[Epoch 16, Batch 300] loss: 0.00781516647529542
[Epoch 16, Batch 400] loss: 0.017384116211967036
[Epoch 16, Batch 500] loss: 0.012856013684536531
[Epoch 16, Batch 600] loss: 0.009794367106033163
[Epoch 16, Batch 700] loss: 0.01681225246486697
[Epoch 16, Batch 800] loss: 0.019384247058007703
[Epoch 16, Batch 900] loss: 0.04203692582483667
[Epoch 16, Batch 1000] loss: 0.022054679833065888
[Epoch 16, Batch 1100] loss: 0.01908736679253236
[Epoch 16, Batch 1200] loss: 0.011103127618248436
[Epoch 16, Batch 1300] loss: 0.01296913587308154
[Epoch 16, Batch 1400] loss: 0.020395466037063978
[Epoch 16, Batch 1500] loss: 0.017608006974908972
[Epoch 16, Batch 1600] loss: 0.008915270247709573
[Epoch 16, Batch 1700] loss: 0.012472634594064119
[Epoch 16, Batch 1800] loss: 0.018429387557850126
[Epoch 16, Batch 1900] loss: 0.023880273740771684
[Epoch 16, Batch 2000] loss: 0.021859383107775764
[Epoch 16, Batch 2100] loss: 0.02588273152325705
[Epoch 16, Batch 2200] loss: 0.013753746338087467
[Epoch 16, Batch 2300] loss: 0.00958826035297839
[Epoch 16, Batch 2400] loss: 0.014159032209450854
[Epoch 16, Batch 2500] loss: 0.013087351951441945
[Epoch 16, Batch 2600] loss: 0.005206960185932452
[Epoch 16, Batch 2700] loss: 0.015106274644377925
[Epoch 16, Batch 2800] loss: 0.008615669969938108
[Epoch 16, Batch 2900] loss: 0.009187862549147038
[Epoch 16, Batch 3000] loss: 0.011244859772651257
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0653
Validation Accuracy: 0.9866
Overfitting: 0.0653
[Epoch 17, Batch 100] loss: 0.0031158009174131296
[Epoch 17, Batch 200] loss: 0.010721436344173467
[Epoch 17, Batch 300] loss: 0.006998620167464509
[Epoch 17, Batch 400] loss: 0.01728658089017541
[Epoch 17, Batch 500] loss: 0.015182778240645631
[Epoch 17, Batch 600] loss: 0.008144520523417605
[Epoch 17, Batch 700] loss: 0.011061941149212138
[Epoch 17, Batch 800] loss: 0.010051856343301387
[Epoch 17, Batch 900] loss: 0.013457123944929976
[Epoch 17, Batch 1000] loss: 0.007383600428339432
[Epoch 17, Batch 1100] loss: 0.010113474474950111
[Epoch 17, Batch 1200] loss: 0.01274835874337425
[Epoch 17, Batch 1300] loss: 0.01331021536290951
[Epoch 17, Batch 1400] loss: 0.013057839656636703
[Epoch 17, Batch 1500] loss: 0.017972369643687366
[Epoch 17, Batch 1600] loss: 0.02315569940839012
[Epoch 17, Batch 1700] loss: 0.007917954666723959
[Epoch 17, Batch 1800] loss: 0.011819243863677897
[Epoch 17, Batch 1900] loss: 0.017631709761219843
[Epoch 17, Batch 2000] loss: 0.008854661955464423
[Epoch 17, Batch 2100] loss: 0.004559943743898045
[Epoch 17, Batch 2200] loss: 0.008522763567364193
[Epoch 17, Batch 2300] loss: 0.013125960858451009
[Epoch 17, Batch 2400] loss: 0.01501111490165815
[Epoch 17, Batch 2500] loss: 0.013005649606250991
[Epoch 17, Batch 2600] loss: 0.0261223079529072
[Epoch 17, Batch 2700] loss: 0.02686082891831923
[Epoch 17, Batch 2800] loss: 0.03239605147263507
[Epoch 17, Batch 2900] loss: 0.024302223616136657
[Epoch 17, Batch 3000] loss: 0.019183695042419034
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0793
Validation Accuracy: 0.9833
Overfitting: 0.0793
[Epoch 18, Batch 100] loss: 0.007460527356404043
[Epoch 18, Batch 200] loss: 0.0036494532804513735
[Epoch 18, Batch 300] loss: 0.008173735948943559
[Epoch 18, Batch 400] loss: 0.018161077181515477
[Epoch 18, Batch 500] loss: 0.003700483045394449
[Epoch 18, Batch 600] loss: 0.0019298127204176964
[Epoch 18, Batch 700] loss: 0.004041136502034788
[Epoch 18, Batch 800] loss: 0.019722898282517456
[Epoch 18, Batch 900] loss: 0.013241302711394738
[Epoch 18, Batch 1000] loss: 0.014457774427754937
[Epoch 18, Batch 1100] loss: 0.026311133814876455
[Epoch 18, Batch 1200] loss: 0.008775739192212102
[Epoch 18, Batch 1300] loss: 0.010898509303438643
[Epoch 18, Batch 1400] loss: 0.022106168229470452
[Epoch 18, Batch 1500] loss: 0.012734184852285564
[Epoch 18, Batch 1600] loss: 0.009695901480196474
[Epoch 18, Batch 1700] loss: 0.0342898460112713
[Epoch 18, Batch 1800] loss: 0.014621241429571797
[Epoch 18, Batch 1900] loss: 0.006220956513383942
[Epoch 18, Batch 2000] loss: 0.017774599459851284
[Epoch 18, Batch 2100] loss: 0.01192198720553339
[Epoch 18, Batch 2200] loss: 0.01582079497473229
[Epoch 18, Batch 2300] loss: 0.012472880317576181
[Epoch 18, Batch 2400] loss: 0.008127144357507072
[Epoch 18, Batch 2500] loss: 0.008829707282302599
[Epoch 18, Batch 2600] loss: 0.01894214880708475
[Epoch 18, Batch 2700] loss: 0.006188483398771379
[Epoch 18, Batch 2800] loss: 0.003727151777767661
[Epoch 18, Batch 2900] loss: 0.0023669278477727353
[Epoch 18, Batch 3000] loss: 0.006344552851985927
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0649
Validation Accuracy: 0.9879
Overfitting: 0.0649
[Epoch 19, Batch 100] loss: 0.007503979237503206
[Epoch 19, Batch 200] loss: 0.004902446156524842
[Epoch 19, Batch 300] loss: 0.008862778723762803
[Epoch 19, Batch 400] loss: 0.01063870689963776
[Epoch 19, Batch 500] loss: 0.007455298403383401
[Epoch 19, Batch 600] loss: 0.004877419483953478
[Epoch 19, Batch 700] loss: 0.005826100150716336
[Epoch 19, Batch 800] loss: 0.00983984332463876
[Epoch 19, Batch 900] loss: 0.01831589666096105
[Epoch 19, Batch 1000] loss: 0.008510760791770195
[Epoch 19, Batch 1100] loss: 0.009077594287690767
[Epoch 19, Batch 1200] loss: 0.0009660085349764414
[Epoch 19, Batch 1300] loss: 0.003130895997760752
[Epoch 19, Batch 1400] loss: 0.005623932364220203
[Epoch 19, Batch 1500] loss: 0.028961296432697178
[Epoch 19, Batch 1600] loss: 0.027852567430215233
[Epoch 19, Batch 1700] loss: 0.013023161297803041
[Epoch 19, Batch 1800] loss: 0.0062469937851820844
[Epoch 19, Batch 1900] loss: 0.008656316552911755
[Epoch 19, Batch 2000] loss: 0.019920618186300195
[Epoch 19, Batch 2100] loss: 0.013176709687202531
[Epoch 19, Batch 2200] loss: 0.020871790349929854
[Epoch 19, Batch 2300] loss: 0.02260298811757707
[Epoch 19, Batch 2400] loss: 0.014233998274727959
[Epoch 19, Batch 2500] loss: 0.00868166681986068
[Epoch 19, Batch 2600] loss: 0.0036678119538302314
[Epoch 19, Batch 2700] loss: 0.00819305055173294
[Epoch 19, Batch 2800] loss: 0.020951944995879258
[Epoch 19, Batch 2900] loss: 0.01782138217280192
[Epoch 19, Batch 3000] loss: 0.010223369059244685
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0745
Validation Accuracy: 0.9860
Overfitting: 0.0745
[Epoch 20, Batch 100] loss: 0.006413952948118302
[Epoch 20, Batch 200] loss: 0.007502879297724921
[Epoch 20, Batch 300] loss: 0.01212858302691616
[Epoch 20, Batch 400] loss: 0.015453985151837747
[Epoch 20, Batch 500] loss: 0.009009787762199215
[Epoch 20, Batch 600] loss: 0.006224868410593807
[Epoch 20, Batch 700] loss: 0.01787282390286874
[Epoch 20, Batch 800] loss: 0.012582404174597946
[Epoch 20, Batch 900] loss: 0.01722820253353438
[Epoch 20, Batch 1000] loss: 0.005011727020926036
[Epoch 20, Batch 1100] loss: 0.0059884089086730975
[Epoch 20, Batch 1200] loss: 0.01604544971324802
[Epoch 20, Batch 1300] loss: 0.022290547546124015
[Epoch 20, Batch 1400] loss: 0.018850612467072984
[Epoch 20, Batch 1500] loss: 0.006721218493799386
[Epoch 20, Batch 1600] loss: 0.013077574910855492
[Epoch 20, Batch 1700] loss: 0.01723501553987597
[Epoch 20, Batch 1800] loss: 0.029440551526756766
[Epoch 20, Batch 1900] loss: 0.027156259266052772
[Epoch 20, Batch 2000] loss: 0.013444709063667943
[Epoch 20, Batch 2100] loss: 0.01555282466647185
[Epoch 20, Batch 2200] loss: 0.012257472670765246
[Epoch 20, Batch 2300] loss: 0.02229087747982966
[Epoch 20, Batch 2400] loss: 0.01255326050026511
[Epoch 20, Batch 2500] loss: 0.011320836872965496
[Epoch 20, Batch 2600] loss: 0.016891339339580595
[Epoch 20, Batch 2700] loss: 0.02840997738715209
[Epoch 20, Batch 2800] loss: 0.020592873664268287
[Epoch 20, Batch 2900] loss: 0.01917741786003546
[Epoch 20, Batch 3000] loss: 0.02366148631704075
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.1134
Validation Accuracy: 0.9804
Overfitting: 0.1134
[Epoch 21, Batch 100] loss: 0.013616027158169635
[Epoch 21, Batch 200] loss: 0.009731180228531318
[Epoch 21, Batch 300] loss: 0.01602398799404197
[Epoch 21, Batch 400] loss: 0.017189901284081693
[Epoch 21, Batch 500] loss: 0.005552084414759389
[Epoch 21, Batch 600] loss: 0.005320941702021163
[Epoch 21, Batch 700] loss: 0.013513166478183646
[Epoch 21, Batch 800] loss: 0.01738611782419264
[Epoch 21, Batch 900] loss: 0.01223992095013585
[Epoch 21, Batch 1000] loss: 0.01489544224861077
[Epoch 21, Batch 1100] loss: 0.007838004718497861
[Epoch 21, Batch 1200] loss: 0.008371591914205721
[Epoch 21, Batch 1300] loss: 0.019417503232864036
[Epoch 21, Batch 1400] loss: 0.004881923343496659
[Epoch 21, Batch 1500] loss: 0.004522887617725546
[Epoch 21, Batch 1600] loss: 0.006243674368470607
[Epoch 21, Batch 1700] loss: 0.03689812132088931
[Epoch 21, Batch 1800] loss: 0.01102679021669601
[Epoch 21, Batch 1900] loss: 0.009116620877720107
[Epoch 21, Batch 2000] loss: 0.011990908174447465
[Epoch 21, Batch 2100] loss: 0.0047696925968744395
[Epoch 21, Batch 2200] loss: 0.0033085635171828586
[Epoch 21, Batch 2300] loss: 0.004929349398924701
[Epoch 21, Batch 2400] loss: 0.006330850246181332
[Epoch 21, Batch 2500] loss: 0.010843776636792271
[Epoch 21, Batch 2600] loss: 0.024715642361183912
[Epoch 21, Batch 2700] loss: 0.012334446486344249
[Epoch 21, Batch 2800] loss: 0.06617126940248072
[Epoch 21, Batch 2900] loss: 0.006883508631049082
[Epoch 21, Batch 3000] loss: 0.017387364671964375
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0862
Validation Accuracy: 0.9827
Overfitting: 0.0862
[Epoch 22, Batch 100] loss: 0.012207142387001943
[Epoch 22, Batch 200] loss: 0.007671084923595073
[Epoch 22, Batch 300] loss: 0.014780600064370217
[Epoch 22, Batch 400] loss: 0.0065797126741140265
[Epoch 22, Batch 500] loss: 0.008538795638400841
[Epoch 22, Batch 600] loss: 0.01744755681720203
[Epoch 22, Batch 700] loss: 0.021930141533447443
[Epoch 22, Batch 800] loss: 0.004498993916175302
[Epoch 22, Batch 900] loss: 0.007202426870477546
[Epoch 22, Batch 1000] loss: 0.001699789282521027
[Epoch 22, Batch 1100] loss: 0.0038410223992259196
[Epoch 22, Batch 1200] loss: 0.0037447199383600347
[Epoch 22, Batch 1300] loss: 0.00894582690580103
[Epoch 22, Batch 1400] loss: 0.020527273614889693
[Epoch 22, Batch 1500] loss: 0.002395728875335288
[Epoch 22, Batch 1600] loss: 0.004401510133478572
[Epoch 22, Batch 1700] loss: 0.004084679658386876
[Epoch 22, Batch 1800] loss: 0.007722839368358594
[Epoch 22, Batch 1900] loss: 0.0018439417161099003
[Epoch 22, Batch 2000] loss: 0.017168869458814896
[Epoch 22, Batch 2100] loss: 0.02197780016958068
[Epoch 22, Batch 2200] loss: 0.031672207680417015
[Epoch 22, Batch 2300] loss: 0.009610589009550452
[Epoch 22, Batch 2400] loss: 0.01670817189756143
[Epoch 22, Batch 2500] loss: 0.019739140252310907
[Epoch 22, Batch 2600] loss: 0.024165380968367005
[Epoch 22, Batch 2700] loss: 0.018618287861156567
[Epoch 22, Batch 2800] loss: 0.01363558932438849
[Epoch 22, Batch 2900] loss: 0.006233625483080401
[Epoch 22, Batch 3000] loss: 0.03724108435459543
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0919
Validation Accuracy: 0.9841
Overfitting: 0.0919
[Epoch 23, Batch 100] loss: 0.019177451448007067
[Epoch 23, Batch 200] loss: 0.008883533445854162
[Epoch 23, Batch 300] loss: 0.02060278995348023
[Epoch 23, Batch 400] loss: 0.013321722083865745
[Epoch 23, Batch 500] loss: 0.003262429241322313
[Epoch 23, Batch 600] loss: 0.007299381868716863
[Epoch 23, Batch 700] loss: 0.003454112502265172
[Epoch 23, Batch 800] loss: 0.014306246438622447
[Epoch 23, Batch 900] loss: 0.024853581284183263
[Epoch 23, Batch 1000] loss: 0.019601470326249183
[Epoch 23, Batch 1100] loss: 0.017782278688871243
[Epoch 23, Batch 1200] loss: 0.011756992029997306
[Epoch 23, Batch 1300] loss: 0.007460192855955205
[Epoch 23, Batch 1400] loss: 0.017413519761239546
[Epoch 23, Batch 1500] loss: 0.012990159045411285
[Epoch 23, Batch 1600] loss: 0.02300384136409063
[Epoch 23, Batch 1700] loss: 0.016706648879848417
[Epoch 23, Batch 1800] loss: 0.0294724660919813
[Epoch 23, Batch 1900] loss: 0.007070105601128552
[Epoch 23, Batch 2000] loss: 0.006336431388938859
[Epoch 23, Batch 2100] loss: 0.006700366994940508
[Epoch 23, Batch 2200] loss: 0.012001273032333431
[Epoch 23, Batch 2300] loss: 0.03640639423955646
[Epoch 23, Batch 2400] loss: 0.010605832597759069
[Epoch 23, Batch 2500] loss: 0.007898708262155996
[Epoch 23, Batch 2600] loss: 0.014678892158524373
[Epoch 23, Batch 2700] loss: 0.017326184076835914
[Epoch 23, Batch 2800] loss: 0.006911056528127046
[Epoch 23, Batch 2900] loss: 0.004394825210289563
[Epoch 23, Batch 3000] loss: 0.013796027604381122
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0762
Validation Accuracy: 0.9848
Overfitting: 0.0762
[Epoch 24, Batch 100] loss: 0.012308148063539352
[Epoch 24, Batch 200] loss: 0.021255908397766053
[Epoch 24, Batch 300] loss: 0.0133264550881202
[Epoch 24, Batch 400] loss: 0.014758331395845356
[Epoch 24, Batch 500] loss: 0.008765901808584537
[Epoch 24, Batch 600] loss: 0.014588078191267435
[Epoch 24, Batch 700] loss: 0.04033136404590522
[Epoch 24, Batch 800] loss: 0.010264155386102232
[Epoch 24, Batch 900] loss: 0.009304268514150303
[Epoch 24, Batch 1000] loss: 0.011546693145745053
[Epoch 24, Batch 1100] loss: 0.017689925813142153
[Epoch 24, Batch 1200] loss: 0.0037580544476382726
[Epoch 24, Batch 1300] loss: 0.0034802810937342877
[Epoch 24, Batch 1400] loss: 0.005687002925207323
[Epoch 24, Batch 1500] loss: 0.004801963618939511
[Epoch 24, Batch 1600] loss: 0.005207016613150475
[Epoch 24, Batch 1700] loss: 0.004246074560917381
[Epoch 24, Batch 1800] loss: 0.002850437523651177
[Epoch 24, Batch 1900] loss: 0.004510549566797253
[Epoch 24, Batch 2000] loss: 0.00043354685433825144
[Epoch 24, Batch 2100] loss: 0.004799824550187281
[Epoch 24, Batch 2200] loss: 0.0013881361081338373
[Epoch 24, Batch 2300] loss: 0.004915884380805875
[Epoch 24, Batch 2400] loss: 0.009987893869048551
[Epoch 24, Batch 2500] loss: 0.006065796355237803
[Epoch 24, Batch 2600] loss: 0.009841037356470617
[Epoch 24, Batch 2700] loss: 0.022295906740063237
[Epoch 24, Batch 2800] loss: 0.006045458977051501
[Epoch 24, Batch 2900] loss: 0.010794008288247002
[Epoch 24, Batch 3000] loss: 0.010415042564766757
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0749
Validation Accuracy: 0.9878
Overfitting: 0.0749
Fold 2 validation loss: 0.0749
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 1.7794576415419578
[Epoch 1, Batch 200] loss: 0.5043187794834375
[Epoch 1, Batch 300] loss: 0.30385804910212755
[Epoch 1, Batch 400] loss: 0.2341103147994727
[Epoch 1, Batch 500] loss: 0.2203825661726296
[Epoch 1, Batch 600] loss: 0.14860512701794504
[Epoch 1, Batch 700] loss: 0.18208228607545607
[Epoch 1, Batch 800] loss: 0.165097978010308
[Epoch 1, Batch 900] loss: 0.14396936098346486
[Epoch 1, Batch 1000] loss: 0.13445100424985867
[Epoch 1, Batch 1100] loss: 0.1320300643297378
[Epoch 1, Batch 1200] loss: 0.12944947118405253
[Epoch 1, Batch 1300] loss: 0.11615760641521775
[Epoch 1, Batch 1400] loss: 0.11688418440942769
[Epoch 1, Batch 1500] loss: 0.1568184925802052
[Epoch 1, Batch 1600] loss: 0.10779069206560962
[Epoch 1, Batch 1700] loss: 0.06959232405191869
[Epoch 1, Batch 1800] loss: 0.09849498450814281
[Epoch 1, Batch 1900] loss: 0.0849063211606699
[Epoch 1, Batch 2000] loss: 0.10210868977941573
[Epoch 1, Batch 2100] loss: 0.06794750874396413
[Epoch 1, Batch 2200] loss: 0.10354281984968111
[Epoch 1, Batch 2300] loss: 0.08171750874666031
[Epoch 1, Batch 2400] loss: 0.07448140174208674
[Epoch 1, Batch 2500] loss: 0.09734059335314668
[Epoch 1, Batch 2600] loss: 0.08837562774686375
[Epoch 1, Batch 2700] loss: 0.10594584703911096
[Epoch 1, Batch 2800] loss: 0.10286508401564788
[Epoch 1, Batch 2900] loss: 0.08776261051592883
[Epoch 1, Batch 3000] loss: 0.07810956394816458
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0740
Validation Accuracy: 0.9769
Overfitting: 0.0740
Best model saved at epoch 1 with validation loss: 0.0740
[Epoch 2, Batch 100] loss: 0.048028480986540674
[Epoch 2, Batch 200] loss: 0.05827124805051426
[Epoch 2, Batch 300] loss: 0.06879039007799292
[Epoch 2, Batch 400] loss: 0.06948560578202886
[Epoch 2, Batch 500] loss: 0.07221530429218546
[Epoch 2, Batch 600] loss: 0.07148592774858116
[Epoch 2, Batch 700] loss: 0.07378887440165272
[Epoch 2, Batch 800] loss: 0.07184319809792214
[Epoch 2, Batch 900] loss: 0.056488473022254765
[Epoch 2, Batch 1000] loss: 0.06050464385334635
[Epoch 2, Batch 1100] loss: 0.06104092215820856
[Epoch 2, Batch 1200] loss: 0.07578177390125347
[Epoch 2, Batch 1300] loss: 0.05823602110423962
[Epoch 2, Batch 1400] loss: 0.06450522143539274
[Epoch 2, Batch 1500] loss: 0.04438025141003891
[Epoch 2, Batch 1600] loss: 0.057002934123156594
[Epoch 2, Batch 1700] loss: 0.07770398132073751
[Epoch 2, Batch 1800] loss: 0.05162477264355402
[Epoch 2, Batch 1900] loss: 0.06761039396660636
[Epoch 2, Batch 2000] loss: 0.07736019089701586
[Epoch 2, Batch 2100] loss: 0.06888338130236661
[Epoch 2, Batch 2200] loss: 0.07325690718891564
[Epoch 2, Batch 2300] loss: 0.06505618998751743
[Epoch 2, Batch 2400] loss: 0.09845043605630054
[Epoch 2, Batch 2500] loss: 0.045444990406758735
[Epoch 2, Batch 2600] loss: 0.03770045551471412
[Epoch 2, Batch 2700] loss: 0.03662831180268768
[Epoch 2, Batch 2800] loss: 0.048944651181591324
[Epoch 2, Batch 2900] loss: 0.05525884179754939
[Epoch 2, Batch 3000] loss: 0.05541916090936866
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0690
Validation Accuracy: 0.9803
Overfitting: 0.0690
Best model saved at epoch 2 with validation loss: 0.0690
[Epoch 3, Batch 100] loss: 0.052689772151206855
[Epoch 3, Batch 200] loss: 0.04619089519357658
[Epoch 3, Batch 300] loss: 0.05193538012012141
[Epoch 3, Batch 400] loss: 0.028205317630672654
[Epoch 3, Batch 500] loss: 0.06199851697507256
[Epoch 3, Batch 600] loss: 0.045746420559171386
[Epoch 3, Batch 700] loss: 0.047983852225443116
[Epoch 3, Batch 800] loss: 0.03851451770460699
[Epoch 3, Batch 900] loss: 0.0368081718742178
[Epoch 3, Batch 1000] loss: 0.052193117860624624
[Epoch 3, Batch 1100] loss: 0.039871974320340085
[Epoch 3, Batch 1200] loss: 0.06560860005607537
[Epoch 3, Batch 1300] loss: 0.057983170757233894
[Epoch 3, Batch 1400] loss: 0.06034538382467872
[Epoch 3, Batch 1500] loss: 0.026127889063282055
[Epoch 3, Batch 1600] loss: 0.057226303762581664
[Epoch 3, Batch 1700] loss: 0.03900578812201275
[Epoch 3, Batch 1800] loss: 0.05545808035087248
[Epoch 3, Batch 1900] loss: 0.03638615876867334
[Epoch 3, Batch 2000] loss: 0.038871060369765474
[Epoch 3, Batch 2100] loss: 0.0430395813161158
[Epoch 3, Batch 2200] loss: 0.04814453102848347
[Epoch 3, Batch 2300] loss: 0.06483551291225012
[Epoch 3, Batch 2400] loss: 0.027734376404641808
[Epoch 3, Batch 2500] loss: 0.06466819805180421
[Epoch 3, Batch 2600] loss: 0.04688863386945741
[Epoch 3, Batch 2700] loss: 0.04431350843206019
[Epoch 3, Batch 2800] loss: 0.0677314957157796
[Epoch 3, Batch 2900] loss: 0.04790822282491718
[Epoch 3, Batch 3000] loss: 0.035027429475012466
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9843
Overfitting: 0.0546
Best model saved at epoch 3 with validation loss: 0.0546
[Epoch 4, Batch 100] loss: 0.022439363008415966
[Epoch 4, Batch 200] loss: 0.034967723017616664
[Epoch 4, Batch 300] loss: 0.023710304411342805
[Epoch 4, Batch 400] loss: 0.04781400137995206
[Epoch 4, Batch 500] loss: 0.036137824549878135
[Epoch 4, Batch 600] loss: 0.03699231391179637
[Epoch 4, Batch 700] loss: 0.025521248334589474
[Epoch 4, Batch 800] loss: 0.0462658067763914
[Epoch 4, Batch 900] loss: 0.045470939452497985
[Epoch 4, Batch 1000] loss: 0.02799815388782008
[Epoch 4, Batch 1100] loss: 0.02384424396121176
[Epoch 4, Batch 1200] loss: 0.01892650764910286
[Epoch 4, Batch 1300] loss: 0.0392306830238158
[Epoch 4, Batch 1400] loss: 0.027901503889434024
[Epoch 4, Batch 1500] loss: 0.039109546806794245
[Epoch 4, Batch 1600] loss: 0.040965813539419284
[Epoch 4, Batch 1700] loss: 0.04620488129163278
[Epoch 4, Batch 1800] loss: 0.03312487766183039
[Epoch 4, Batch 1900] loss: 0.04587519254160725
[Epoch 4, Batch 2000] loss: 0.037299257231752564
[Epoch 4, Batch 2100] loss: 0.04417001090561826
[Epoch 4, Batch 2200] loss: 0.04659110607277398
[Epoch 4, Batch 2300] loss: 0.039836960719403576
[Epoch 4, Batch 2400] loss: 0.04152820995012007
[Epoch 4, Batch 2500] loss: 0.04860181636637208
[Epoch 4, Batch 2600] loss: 0.05215117661857221
[Epoch 4, Batch 2700] loss: 0.04967438675375888
[Epoch 4, Batch 2800] loss: 0.022245850125491417
[Epoch 4, Batch 2900] loss: 0.03489233177144342
[Epoch 4, Batch 3000] loss: 0.042345372788786334
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0591
Validation Accuracy: 0.9838
Overfitting: 0.0591
[Epoch 5, Batch 100] loss: 0.0397119522394496
[Epoch 5, Batch 200] loss: 0.026159825145332435
[Epoch 5, Batch 300] loss: 0.020443857064437906
[Epoch 5, Batch 400] loss: 0.026813302409864265
[Epoch 5, Batch 500] loss: 0.01729797553314029
[Epoch 5, Batch 600] loss: 0.030491027994421528
[Epoch 5, Batch 700] loss: 0.02964296093788107
[Epoch 5, Batch 800] loss: 0.03040587893621705
[Epoch 5, Batch 900] loss: 0.014807813338011329
[Epoch 5, Batch 1000] loss: 0.033963838595998365
[Epoch 5, Batch 1100] loss: 0.02349726431661111
[Epoch 5, Batch 1200] loss: 0.029437821271021677
[Epoch 5, Batch 1300] loss: 0.04476103961892463
[Epoch 5, Batch 1400] loss: 0.032367677523889145
[Epoch 5, Batch 1500] loss: 0.03541603012778069
[Epoch 5, Batch 1600] loss: 0.03344715103074122
[Epoch 5, Batch 1700] loss: 0.032969701703736976
[Epoch 5, Batch 1800] loss: 0.035600461893000104
[Epoch 5, Batch 1900] loss: 0.026375748182672396
[Epoch 5, Batch 2000] loss: 0.01613855355628175
[Epoch 5, Batch 2100] loss: 0.034104388936229954
[Epoch 5, Batch 2200] loss: 0.028199561591204656
[Epoch 5, Batch 2300] loss: 0.026881613859886785
[Epoch 5, Batch 2400] loss: 0.03901017763271284
[Epoch 5, Batch 2500] loss: 0.04451048852008171
[Epoch 5, Batch 2600] loss: 0.025012630840683413
[Epoch 5, Batch 2700] loss: 0.01917354799592431
[Epoch 5, Batch 2800] loss: 0.025769895097132577
[Epoch 5, Batch 2900] loss: 0.029893484371023078
[Epoch 5, Batch 3000] loss: 0.02784401512095428
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9865
Overfitting: 0.0519
Best model saved at epoch 5 with validation loss: 0.0519
[Epoch 6, Batch 100] loss: 0.02652211046307457
[Epoch 6, Batch 200] loss: 0.02962361127429176
[Epoch 6, Batch 300] loss: 0.02425383354708174
[Epoch 6, Batch 400] loss: 0.02682041246273002
[Epoch 6, Batch 500] loss: 0.02267233132006538
[Epoch 6, Batch 600] loss: 0.036283364474611515
[Epoch 6, Batch 700] loss: 0.027260385732151917
[Epoch 6, Batch 800] loss: 0.02198122228046486
[Epoch 6, Batch 900] loss: 0.02939355797642861
[Epoch 6, Batch 1000] loss: 0.04377530489475248
[Epoch 6, Batch 1100] loss: 0.03447153540160798
[Epoch 6, Batch 1200] loss: 0.026152181233783267
[Epoch 6, Batch 1300] loss: 0.026982670392890214
[Epoch 6, Batch 1400] loss: 0.024158427473157645
[Epoch 6, Batch 1500] loss: 0.023161241666514343
[Epoch 6, Batch 1600] loss: 0.020490171381170513
[Epoch 6, Batch 1700] loss: 0.03252032834568126
[Epoch 6, Batch 1800] loss: 0.018713235320965395
[Epoch 6, Batch 1900] loss: 0.039618002880320094
[Epoch 6, Batch 2000] loss: 0.036811217847389346
[Epoch 6, Batch 2100] loss: 0.03337495358191518
[Epoch 6, Batch 2200] loss: 0.036010325388251656
[Epoch 6, Batch 2300] loss: 0.014913770587377258
[Epoch 6, Batch 2400] loss: 0.036787433910120626
[Epoch 6, Batch 2500] loss: 0.026698117409127916
[Epoch 6, Batch 2600] loss: 0.035294717669903546
[Epoch 6, Batch 2700] loss: 0.016608143819589714
[Epoch 6, Batch 2800] loss: 0.03802155861510301
[Epoch 6, Batch 2900] loss: 0.0347331582827519
[Epoch 6, Batch 3000] loss: 0.026342607963993032
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0708
Validation Accuracy: 0.9819
Overfitting: 0.0708
[Epoch 7, Batch 100] loss: 0.04151045794023503
[Epoch 7, Batch 200] loss: 0.016566112727268774
[Epoch 7, Batch 300] loss: 0.0319645809977078
[Epoch 7, Batch 400] loss: 0.023909466907271054
[Epoch 7, Batch 500] loss: 0.016955429688059666
[Epoch 7, Batch 600] loss: 0.008067790353848067
[Epoch 7, Batch 700] loss: 0.025045812516817704
[Epoch 7, Batch 800] loss: 0.022632939512772055
[Epoch 7, Batch 900] loss: 0.0245193916664806
[Epoch 7, Batch 1000] loss: 0.008162133235052806
[Epoch 7, Batch 1100] loss: 0.02266482921246791
[Epoch 7, Batch 1200] loss: 0.011121268124011294
[Epoch 7, Batch 1300] loss: 0.018407399679636
[Epoch 7, Batch 1400] loss: 0.015036514433268167
[Epoch 7, Batch 1500] loss: 0.012082852196008388
[Epoch 7, Batch 1600] loss: 0.0229011193617589
[Epoch 7, Batch 1700] loss: 0.031525962470068405
[Epoch 7, Batch 1800] loss: 0.016728080009020232
[Epoch 7, Batch 1900] loss: 0.03241312835360532
[Epoch 7, Batch 2000] loss: 0.02448953960254357
[Epoch 7, Batch 2100] loss: 0.034788044753563556
[Epoch 7, Batch 2200] loss: 0.03438469291981164
[Epoch 7, Batch 2300] loss: 0.01480601151841597
[Epoch 7, Batch 2400] loss: 0.029704961673714933
[Epoch 7, Batch 2500] loss: 0.018187577659221008
[Epoch 7, Batch 2600] loss: 0.02382305773484177
[Epoch 7, Batch 2700] loss: 0.01622238230363564
[Epoch 7, Batch 2800] loss: 0.020214275278931382
[Epoch 7, Batch 2900] loss: 0.038101100183646396
[Epoch 7, Batch 3000] loss: 0.02494031235210514
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0587
Validation Accuracy: 0.9861
Overfitting: 0.0587
[Epoch 8, Batch 100] loss: 0.012273670259785376
[Epoch 8, Batch 200] loss: 0.038505567732520375
[Epoch 8, Batch 300] loss: 0.03077858565446604
[Epoch 8, Batch 400] loss: 0.023050635690033232
[Epoch 8, Batch 500] loss: 0.01757824924960687
[Epoch 8, Batch 600] loss: 0.0127690034252646
[Epoch 8, Batch 700] loss: 0.01278216706511813
[Epoch 8, Batch 800] loss: 0.011354667286885842
[Epoch 8, Batch 900] loss: 0.016908997729860858
[Epoch 8, Batch 1000] loss: 0.03182799373271223
[Epoch 8, Batch 1100] loss: 0.02545342935375629
[Epoch 8, Batch 1200] loss: 0.028092176317415465
[Epoch 8, Batch 1300] loss: 0.017506715638364766
[Epoch 8, Batch 1400] loss: 0.024060238400281833
[Epoch 8, Batch 1500] loss: 0.022048545948241554
[Epoch 8, Batch 1600] loss: 0.008200528030154147
[Epoch 8, Batch 1700] loss: 0.011328267590911309
[Epoch 8, Batch 1800] loss: 0.030093732137754615
[Epoch 8, Batch 1900] loss: 0.018138590501163208
[Epoch 8, Batch 2000] loss: 0.01008082752743519
[Epoch 8, Batch 2100] loss: 0.014758900215611562
[Epoch 8, Batch 2200] loss: 0.029585288720427913
[Epoch 8, Batch 2300] loss: 0.021841121805570064
[Epoch 8, Batch 2400] loss: 0.018530079034292157
[Epoch 8, Batch 2500] loss: 0.025354683366858807
[Epoch 8, Batch 2600] loss: 0.020196570719580222
[Epoch 8, Batch 2700] loss: 0.01640234151474715
[Epoch 8, Batch 2800] loss: 0.030966648799672286
[Epoch 8, Batch 2900] loss: 0.037860076400668276
[Epoch 8, Batch 3000] loss: 0.0287213000391057
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9871
Overfitting: 0.0529
[Epoch 9, Batch 100] loss: 0.016460600398013413
[Epoch 9, Batch 200] loss: 0.01145741727286122
[Epoch 9, Batch 300] loss: 0.02740140210071786
[Epoch 9, Batch 400] loss: 0.014247929722178015
[Epoch 9, Batch 500] loss: 0.015560786354362578
[Epoch 9, Batch 600] loss: 0.006542752133962608
[Epoch 9, Batch 700] loss: 0.020516465353275636
[Epoch 9, Batch 800] loss: 0.011306077790675176
[Epoch 9, Batch 900] loss: 0.011552416056432691
[Epoch 9, Batch 1000] loss: 0.018365635808583535
[Epoch 9, Batch 1100] loss: 0.010765327808891811
[Epoch 9, Batch 1200] loss: 0.024887569654566236
[Epoch 9, Batch 1300] loss: 0.021081412784863005
[Epoch 9, Batch 1400] loss: 0.03503148012041948
[Epoch 9, Batch 1500] loss: 0.03007772849910907
[Epoch 9, Batch 1600] loss: 0.022795692850197894
[Epoch 9, Batch 1700] loss: 0.01790922607382342
[Epoch 9, Batch 1800] loss: 0.016263137145401174
[Epoch 9, Batch 1900] loss: 0.013326872745236926
[Epoch 9, Batch 2000] loss: 0.023977769417084006
[Epoch 9, Batch 2100] loss: 0.012215975737196913
[Epoch 9, Batch 2200] loss: 0.028107769682334832
[Epoch 9, Batch 2300] loss: 0.02054550070883977
[Epoch 9, Batch 2400] loss: 0.016361018344184686
[Epoch 9, Batch 2500] loss: 0.02332576173848338
[Epoch 9, Batch 2600] loss: 0.017534530352838827
[Epoch 9, Batch 2700] loss: 0.013748064863909804
[Epoch 9, Batch 2800] loss: 0.029748111752492434
[Epoch 9, Batch 2900] loss: 0.011956173098803901
[Epoch 9, Batch 3000] loss: 0.022330061337880805
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0821
Validation Accuracy: 0.9805
Overfitting: 0.0821
[Epoch 10, Batch 100] loss: 0.023471020945565045
[Epoch 10, Batch 200] loss: 0.014190440235183814
[Epoch 10, Batch 300] loss: 0.026591273530324314
[Epoch 10, Batch 400] loss: 0.020919172329257663
[Epoch 10, Batch 500] loss: 0.025553151858059665
[Epoch 10, Batch 600] loss: 0.012064159713017943
[Epoch 10, Batch 700] loss: 0.02248941454036867
[Epoch 10, Batch 800] loss: 0.01657908631650571
[Epoch 10, Batch 900] loss: 0.02320536056318808
[Epoch 10, Batch 1000] loss: 0.02730926604860855
[Epoch 10, Batch 1100] loss: 0.023267857749393387
[Epoch 10, Batch 1200] loss: 0.02137277054813694
[Epoch 10, Batch 1300] loss: 0.013844820862198617
[Epoch 10, Batch 1400] loss: 0.019150381166218155
[Epoch 10, Batch 1500] loss: 0.015731665593896053
[Epoch 10, Batch 1600] loss: 0.010910517632194684
[Epoch 10, Batch 1700] loss: 0.02211026211271715
[Epoch 10, Batch 1800] loss: 0.028832973933339757
[Epoch 10, Batch 1900] loss: 0.015421774540852766
[Epoch 10, Batch 2000] loss: 0.02243607064811499
[Epoch 10, Batch 2100] loss: 0.013488216531649755
[Epoch 10, Batch 2200] loss: 0.02220483589562946
[Epoch 10, Batch 2300] loss: 0.00910197496074062
[Epoch 10, Batch 2400] loss: 0.023341988949439382
[Epoch 10, Batch 2500] loss: 0.010484357013126555
[Epoch 10, Batch 2600] loss: 0.009441013410024582
[Epoch 10, Batch 2700] loss: 0.01786616658956234
[Epoch 10, Batch 2800] loss: 0.02631450587110635
[Epoch 10, Batch 2900] loss: 0.010683877823510102
[Epoch 10, Batch 3000] loss: 0.014578410727185086
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0563
Validation Accuracy: 0.9864
Overfitting: 0.0563
[Epoch 11, Batch 100] loss: 0.0135201830389218
[Epoch 11, Batch 200] loss: 0.008888138959682408
[Epoch 11, Batch 300] loss: 0.00786972094890075
[Epoch 11, Batch 400] loss: 0.008116028320109762
[Epoch 11, Batch 500] loss: 0.016387901458379588
[Epoch 11, Batch 600] loss: 0.02377488905100563
[Epoch 11, Batch 700] loss: 0.01627163071805171
[Epoch 11, Batch 800] loss: 0.007125338322824745
[Epoch 11, Batch 900] loss: 0.008312463165300982
[Epoch 11, Batch 1000] loss: 0.00517782603679052
[Epoch 11, Batch 1100] loss: 0.008400036239753526
[Epoch 11, Batch 1200] loss: 0.00994063019812458
[Epoch 11, Batch 1300] loss: 0.011539024673444871
[Epoch 11, Batch 1400] loss: 0.021933771780371102
[Epoch 11, Batch 1500] loss: 0.006762158973736518
[Epoch 11, Batch 1600] loss: 0.003937109226011443
[Epoch 11, Batch 1700] loss: 0.01597504881218896
[Epoch 11, Batch 1800] loss: 0.01948737242432003
[Epoch 11, Batch 1900] loss: 0.01353868596755987
[Epoch 11, Batch 2000] loss: 0.00828761348875048
[Epoch 11, Batch 2100] loss: 0.0320127233189109
[Epoch 11, Batch 2200] loss: 0.023981312770221166
[Epoch 11, Batch 2300] loss: 0.010978188641169737
[Epoch 11, Batch 2400] loss: 0.014722619235915531
[Epoch 11, Batch 2500] loss: 0.017663367534013617
[Epoch 11, Batch 2600] loss: 0.004419204998511077
[Epoch 11, Batch 2700] loss: 0.016535957928017878
[Epoch 11, Batch 2800] loss: 0.009080096543673886
[Epoch 11, Batch 2900] loss: 0.03563763840985497
[Epoch 11, Batch 3000] loss: 0.024624085704940058
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9878
Overfitting: 0.0619
[Epoch 12, Batch 100] loss: 0.037559130107385104
[Epoch 12, Batch 200] loss: 0.012558258354344645
[Epoch 12, Batch 300] loss: 0.004841235341399113
[Epoch 12, Batch 400] loss: 0.01486718968587283
[Epoch 12, Batch 500] loss: 0.007797890335177868
[Epoch 12, Batch 600] loss: 0.0068355373325383086
[Epoch 12, Batch 700] loss: 0.004934522348478758
[Epoch 12, Batch 800] loss: 0.007416484445054641
[Epoch 12, Batch 900] loss: 0.019530433786246134
[Epoch 12, Batch 1000] loss: 0.024366384607398997
[Epoch 12, Batch 1100] loss: 0.005512098491915935
[Epoch 12, Batch 1200] loss: 0.006183029653944488
[Epoch 12, Batch 1300] loss: 0.0081140755110615
[Epoch 12, Batch 1400] loss: 0.010969546227954652
[Epoch 12, Batch 1500] loss: 0.021995914643382547
[Epoch 12, Batch 1600] loss: 0.014817387521102603
[Epoch 12, Batch 1700] loss: 0.00810214112504184
[Epoch 12, Batch 1800] loss: 0.00569951721259228
[Epoch 12, Batch 1900] loss: 0.003959905451931572
[Epoch 12, Batch 2000] loss: 0.026994561076873532
[Epoch 12, Batch 2100] loss: 0.009481318049627502
[Epoch 12, Batch 2200] loss: 0.014022464593005051
[Epoch 12, Batch 2300] loss: 0.007848764619206179
[Epoch 12, Batch 2400] loss: 0.018775264460738263
[Epoch 12, Batch 2500] loss: 0.016319323769860006
[Epoch 12, Batch 2600] loss: 0.013399490774587549
[Epoch 12, Batch 2700] loss: 0.025289824080125242
[Epoch 12, Batch 2800] loss: 0.02107536943874152
[Epoch 12, Batch 2900] loss: 0.019982968786368627
[Epoch 12, Batch 3000] loss: 0.02656641398871102
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0640
Validation Accuracy: 0.9853
Overfitting: 0.0640
[Epoch 13, Batch 100] loss: 0.016743064747909066
[Epoch 13, Batch 200] loss: 0.013092457096313405
[Epoch 13, Batch 300] loss: 0.014844817141221114
[Epoch 13, Batch 400] loss: 0.00493133630599686
[Epoch 13, Batch 500] loss: 0.016627666835896802
[Epoch 13, Batch 600] loss: 0.021138215347418454
[Epoch 13, Batch 700] loss: 0.029897700066969204
[Epoch 13, Batch 800] loss: 0.012179526123689754
[Epoch 13, Batch 900] loss: 0.0025497162416543515
[Epoch 13, Batch 1000] loss: 0.01154161265009007
[Epoch 13, Batch 1100] loss: 0.022421880971156424
[Epoch 13, Batch 1200] loss: 0.01330303809302471
[Epoch 13, Batch 1300] loss: 0.004252550101526511
[Epoch 13, Batch 1400] loss: 0.005299477898886593
[Epoch 13, Batch 1500] loss: 0.011601566248250173
[Epoch 13, Batch 1600] loss: 0.004596962822635362
[Epoch 13, Batch 1700] loss: 0.003639243719750871
[Epoch 13, Batch 1800] loss: 0.013285240969230365
[Epoch 13, Batch 1900] loss: 0.012405002469910293
[Epoch 13, Batch 2000] loss: 0.013379811950362743
[Epoch 13, Batch 2100] loss: 0.020963659686083384
[Epoch 13, Batch 2200] loss: 0.01924974933056177
[Epoch 13, Batch 2300] loss: 0.03086367614905077
[Epoch 13, Batch 2400] loss: 0.017169877438114226
[Epoch 13, Batch 2500] loss: 0.02568516121060455
[Epoch 13, Batch 2600] loss: 0.03797415737536881
[Epoch 13, Batch 2700] loss: 0.06799562916503646
[Epoch 13, Batch 2800] loss: 0.024206089928409256
[Epoch 13, Batch 2900] loss: 0.010228452261179655
[Epoch 13, Batch 3000] loss: 0.016803691032788066
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9881
Overfitting: 0.0450
Best model saved at epoch 13 with validation loss: 0.0450
[Epoch 14, Batch 100] loss: 0.009365014726638492
[Epoch 14, Batch 200] loss: 0.008465816152979358
[Epoch 14, Batch 300] loss: 0.007437166928644104
[Epoch 14, Batch 400] loss: 0.006889423549885691
[Epoch 14, Batch 500] loss: 0.003485403538131777
[Epoch 14, Batch 600] loss: 0.010646145723831052
[Epoch 14, Batch 700] loss: 0.014088046795976653
[Epoch 14, Batch 800] loss: 0.019348556907227702
[Epoch 14, Batch 900] loss: 0.01011515617958942
[Epoch 14, Batch 1000] loss: 0.00490419126280667
[Epoch 14, Batch 1100] loss: 0.010448539143617496
[Epoch 14, Batch 1200] loss: 0.017489563066428494
[Epoch 14, Batch 1300] loss: 0.009752780186598465
[Epoch 14, Batch 1400] loss: 0.010824578064903499
[Epoch 14, Batch 1500] loss: 0.006671705805528521
[Epoch 14, Batch 1600] loss: 0.015543470146825587
[Epoch 14, Batch 1700] loss: 0.017454162457576246
[Epoch 14, Batch 1800] loss: 0.008409849710621912
[Epoch 14, Batch 1900] loss: 0.017773787115416276
[Epoch 14, Batch 2000] loss: 0.021201513180641594
[Epoch 14, Batch 2100] loss: 0.010709211942161971
[Epoch 14, Batch 2200] loss: 0.019724798786691124
[Epoch 14, Batch 2300] loss: 0.014805828229990539
[Epoch 14, Batch 2400] loss: 0.02422495541229317
[Epoch 14, Batch 2500] loss: 0.006827645562214832
[Epoch 14, Batch 2600] loss: 0.023538293414362598
[Epoch 14, Batch 2700] loss: 0.021612272947695237
[Epoch 14, Batch 2800] loss: 0.01326332539743472
[Epoch 14, Batch 2900] loss: 0.02695287253113189
[Epoch 14, Batch 3000] loss: 0.02121417529846248
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0661
Validation Accuracy: 0.9855
Overfitting: 0.0661
[Epoch 15, Batch 100] loss: 0.018877799311922346
[Epoch 15, Batch 200] loss: 0.011371650080570101
[Epoch 15, Batch 300] loss: 0.014077332934338535
[Epoch 15, Batch 400] loss: 0.007863746416769879
[Epoch 15, Batch 500] loss: 0.007425887475054518
[Epoch 15, Batch 600] loss: 0.01295950513685428
[Epoch 15, Batch 700] loss: 0.012627152655752143
[Epoch 15, Batch 800] loss: 0.009100993029393045
[Epoch 15, Batch 900] loss: 0.006061158223754495
[Epoch 15, Batch 1000] loss: 0.00782942878873726
[Epoch 15, Batch 1100] loss: 0.007999313849843625
[Epoch 15, Batch 1200] loss: 0.00790972478937547
[Epoch 15, Batch 1300] loss: 0.0448710923732497
[Epoch 15, Batch 1400] loss: 0.010998295217406006
[Epoch 15, Batch 1500] loss: 0.0035344738030141797
[Epoch 15, Batch 1600] loss: 0.026087393936715834
[Epoch 15, Batch 1700] loss: 0.01642651778443904
[Epoch 15, Batch 1800] loss: 0.0029960938781301927
[Epoch 15, Batch 1900] loss: 0.009651280043894985
[Epoch 15, Batch 2000] loss: 0.024038941804715237
[Epoch 15, Batch 2100] loss: 0.01703887848386667
[Epoch 15, Batch 2200] loss: 0.008259729765967162
[Epoch 15, Batch 2300] loss: 0.027147366848643006
[Epoch 15, Batch 2400] loss: 0.009795002006168403
[Epoch 15, Batch 2500] loss: 0.007813315830508287
[Epoch 15, Batch 2600] loss: 0.007905667796510567
[Epoch 15, Batch 2700] loss: 0.01996745623845916
[Epoch 15, Batch 2800] loss: 0.015241676033374603
[Epoch 15, Batch 2900] loss: 0.013469456037489315
[Epoch 15, Batch 3000] loss: 0.02371351301984166
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0735
Validation Accuracy: 0.9855
Overfitting: 0.0735
[Epoch 16, Batch 100] loss: 0.011148760511524554
[Epoch 16, Batch 200] loss: 0.006027820128058003
[Epoch 16, Batch 300] loss: 0.012743847158287842
[Epoch 16, Batch 400] loss: 0.0056632220104652475
[Epoch 16, Batch 500] loss: 0.0024617102840411454
[Epoch 16, Batch 600] loss: 0.010805455794175413
[Epoch 16, Batch 700] loss: 0.013466168717723472
[Epoch 16, Batch 800] loss: 0.0032200022432069407
[Epoch 16, Batch 900] loss: 0.008509777431649112
[Epoch 16, Batch 1000] loss: 0.027352975524709326
[Epoch 16, Batch 1100] loss: 0.03002883285312094
[Epoch 16, Batch 1200] loss: 0.01804477470268466
[Epoch 16, Batch 1300] loss: 0.012333962243248493
[Epoch 16, Batch 1400] loss: 0.01931812583703374
[Epoch 16, Batch 1500] loss: 0.009187904158850024
[Epoch 16, Batch 1600] loss: 0.020728076853335317
[Epoch 16, Batch 1700] loss: 0.014332802838413698
[Epoch 16, Batch 1800] loss: 0.02915776008013184
[Epoch 16, Batch 1900] loss: 0.04515585777349215
[Epoch 16, Batch 2000] loss: 0.027458115689778424
[Epoch 16, Batch 2100] loss: 0.01847694856834279
[Epoch 16, Batch 2200] loss: 0.02713926271839455
[Epoch 16, Batch 2300] loss: 0.015900844134806108
[Epoch 16, Batch 2400] loss: 0.007444448850263718
[Epoch 16, Batch 2500] loss: 0.024337549271486902
[Epoch 16, Batch 2600] loss: 0.016499277811430804
[Epoch 16, Batch 2700] loss: 0.0116460558911335
[Epoch 16, Batch 2800] loss: 0.010477184040943398
[Epoch 16, Batch 2900] loss: 0.030211243023846066
[Epoch 16, Batch 3000] loss: 0.03443507434713254
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9871
Overfitting: 0.0630
[Epoch 17, Batch 100] loss: 0.009185550629327537
[Epoch 17, Batch 200] loss: 0.012800674500637967
[Epoch 17, Batch 300] loss: 0.007087158648894127
[Epoch 17, Batch 400] loss: 0.01537128109176407
[Epoch 17, Batch 500] loss: 0.016421749720427384
[Epoch 17, Batch 600] loss: 0.006362341237344232
[Epoch 17, Batch 700] loss: 0.00298068003054496
[Epoch 17, Batch 800] loss: 0.007503560658058941
[Epoch 17, Batch 900] loss: 0.008591362088766683
[Epoch 17, Batch 1000] loss: 0.013982804432342632
[Epoch 17, Batch 1100] loss: 0.009190163251109267
[Epoch 17, Batch 1200] loss: 0.01711777066648764
[Epoch 17, Batch 1300] loss: 0.008967939325456057
[Epoch 17, Batch 1400] loss: 0.011787883726778468
[Epoch 17, Batch 1500] loss: 0.0084301532945747
[Epoch 17, Batch 1600] loss: 0.008100861727671998
[Epoch 17, Batch 1700] loss: 0.005861944816426252
[Epoch 17, Batch 1800] loss: 0.005631578182349646
[Epoch 17, Batch 1900] loss: 0.00799470148944907
[Epoch 17, Batch 2000] loss: 0.011216917237622158
[Epoch 17, Batch 2100] loss: 0.005581895841616813
[Epoch 17, Batch 2200] loss: 0.010399796281253546
[Epoch 17, Batch 2300] loss: 0.018049478482110217
[Epoch 17, Batch 2400] loss: 0.009829738485310347
[Epoch 17, Batch 2500] loss: 0.027844720538763478
[Epoch 17, Batch 2600] loss: 0.006612996671817335
[Epoch 17, Batch 2700] loss: 0.012686616167166789
[Epoch 17, Batch 2800] loss: 0.01896031030311688
[Epoch 17, Batch 2900] loss: 0.006434184802602725
[Epoch 17, Batch 3000] loss: 0.004921462419568026
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0703
Validation Accuracy: 0.9881
Overfitting: 0.0703
[Epoch 18, Batch 100] loss: 0.0022471706048834373
[Epoch 18, Batch 200] loss: 0.012673122895601035
[Epoch 18, Batch 300] loss: 0.00512913053062185
[Epoch 18, Batch 400] loss: 0.01004067134673833
[Epoch 18, Batch 500] loss: 0.007697407099083793
[Epoch 18, Batch 600] loss: 0.030293082155907848
[Epoch 18, Batch 700] loss: 0.038742744284611705
[Epoch 18, Batch 800] loss: 0.00956670469754453
[Epoch 18, Batch 900] loss: 0.006834082820097436
[Epoch 18, Batch 1000] loss: 0.0034616928867500364
[Epoch 18, Batch 1100] loss: 0.0078370126963067
[Epoch 18, Batch 1200] loss: 0.0045148732911624865
[Epoch 18, Batch 1300] loss: 0.010319621567073787
[Epoch 18, Batch 1400] loss: 0.010992754007682164
[Epoch 18, Batch 1500] loss: 0.014946131756657542
[Epoch 18, Batch 1600] loss: 0.02160387709951791
[Epoch 18, Batch 1700] loss: 0.024848457682158768
[Epoch 18, Batch 1800] loss: 0.014608838519895286
[Epoch 18, Batch 1900] loss: 0.005355991691817135
[Epoch 18, Batch 2000] loss: 0.007993506688987581
[Epoch 18, Batch 2100] loss: 0.0032283173190070613
[Epoch 18, Batch 2200] loss: 0.009224690994839744
[Epoch 18, Batch 2300] loss: 0.006704010773032487
[Epoch 18, Batch 2400] loss: 0.008235211005905416
[Epoch 18, Batch 2500] loss: 0.0035087209820891018
[Epoch 18, Batch 2600] loss: 0.010703653509423976
[Epoch 18, Batch 2700] loss: 0.006435391022176873
[Epoch 18, Batch 2800] loss: 0.007088896461056713
[Epoch 18, Batch 2900] loss: 0.017594382997009106
[Epoch 18, Batch 3000] loss: 0.008480292034202783
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0583
Validation Accuracy: 0.9887
Overfitting: 0.0583
[Epoch 19, Batch 100] loss: 0.0075449811967176926
[Epoch 19, Batch 200] loss: 0.0037352632158413044
[Epoch 19, Batch 300] loss: 0.0027871748334970994
[Epoch 19, Batch 400] loss: 0.0049997244117085905
[Epoch 19, Batch 500] loss: 0.0059611729100366335
[Epoch 19, Batch 600] loss: 0.009663677016906855
[Epoch 19, Batch 700] loss: 0.0020409740039292012
[Epoch 19, Batch 800] loss: 0.002834287360944261
[Epoch 19, Batch 900] loss: 0.014000478766105781
[Epoch 19, Batch 1000] loss: 0.006396555642509885
[Epoch 19, Batch 1100] loss: 0.003197550360933512
[Epoch 19, Batch 1200] loss: 0.0008096804170037064
[Epoch 19, Batch 1300] loss: 0.003757826937541524
[Epoch 19, Batch 1400] loss: 0.002126246756379455
[Epoch 19, Batch 1500] loss: 0.0008122594840881759
[Epoch 19, Batch 1600] loss: 0.0010324778736006035
[Epoch 19, Batch 1700] loss: 0.013273234877637057
[Epoch 19, Batch 1800] loss: 0.002790721356605883
[Epoch 19, Batch 1900] loss: 0.001626544073260132
[Epoch 19, Batch 2000] loss: 0.002336394321727955
[Epoch 19, Batch 2100] loss: 0.00967751282988925
[Epoch 19, Batch 2200] loss: 0.018915910905044676
[Epoch 19, Batch 2300] loss: 0.010494813195546989
[Epoch 19, Batch 2400] loss: 0.008447101943022872
[Epoch 19, Batch 2500] loss: 0.008118915585159661
[Epoch 19, Batch 2600] loss: 0.03292677231678938
[Epoch 19, Batch 2700] loss: 0.016255838528858882
[Epoch 19, Batch 2800] loss: 0.02418506755255855
[Epoch 19, Batch 2900] loss: 0.011673860882425667
[Epoch 19, Batch 3000] loss: 0.013284140393735332
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0801
Validation Accuracy: 0.9851
Overfitting: 0.0801
[Epoch 20, Batch 100] loss: 0.017162963554006243
[Epoch 20, Batch 200] loss: 0.0041709053693707076
[Epoch 20, Batch 300] loss: 0.010573454891643807
[Epoch 20, Batch 400] loss: 0.00963085275338821
[Epoch 20, Batch 500] loss: 0.010717476575714988
[Epoch 20, Batch 600] loss: 0.010909317325891817
[Epoch 20, Batch 700] loss: 0.014655723262824055
[Epoch 20, Batch 800] loss: 0.011785308254538265
[Epoch 20, Batch 900] loss: 0.006334902681931491
[Epoch 20, Batch 1000] loss: 0.024338621492750363
[Epoch 20, Batch 1100] loss: 0.017132481041253467
[Epoch 20, Batch 1200] loss: 0.019731692790574854
[Epoch 20, Batch 1300] loss: 0.032323470258870224
[Epoch 20, Batch 1400] loss: 0.023078383346826267
[Epoch 20, Batch 1500] loss: 0.011081716681493515
[Epoch 20, Batch 1600] loss: 0.013371016634802686
[Epoch 20, Batch 1700] loss: 0.02275864162831545
[Epoch 20, Batch 1800] loss: 0.022726120948961478
[Epoch 20, Batch 1900] loss: 0.01411935391203337
[Epoch 20, Batch 2000] loss: 0.013763561761236285
[Epoch 20, Batch 2100] loss: 0.006560415579777903
[Epoch 20, Batch 2200] loss: 0.014969186493467693
[Epoch 20, Batch 2300] loss: 0.003545115315254743
[Epoch 20, Batch 2400] loss: 0.011146107253200657
[Epoch 20, Batch 2500] loss: 0.020660525004360105
[Epoch 20, Batch 2600] loss: 0.02070588557293618
[Epoch 20, Batch 2700] loss: 0.01735053790449983
[Epoch 20, Batch 2800] loss: 0.027639630871347944
[Epoch 20, Batch 2900] loss: 0.02003629780918665
[Epoch 20, Batch 3000] loss: 0.012583240324630545
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0788
Validation Accuracy: 0.9835
Overfitting: 0.0788
[Epoch 21, Batch 100] loss: 0.01381919601904361
[Epoch 21, Batch 200] loss: 0.014116785549148218
[Epoch 21, Batch 300] loss: 0.01732371615398612
[Epoch 21, Batch 400] loss: 0.012391922974438372
[Epoch 21, Batch 500] loss: 0.01030522609386352
[Epoch 21, Batch 600] loss: 0.013246271813765871
[Epoch 21, Batch 700] loss: 0.01660977794849226
[Epoch 21, Batch 800] loss: 0.012884414882558128
[Epoch 21, Batch 900] loss: 0.017667736389583806
[Epoch 21, Batch 1000] loss: 0.019008955452179076
[Epoch 21, Batch 1100] loss: 0.02812121682620017
[Epoch 21, Batch 1200] loss: 0.005730439421863025
[Epoch 21, Batch 1300] loss: 0.005840887376570198
[Epoch 21, Batch 1400] loss: 0.004401594496276946
[Epoch 21, Batch 1500] loss: 0.013288416034268731
[Epoch 21, Batch 1600] loss: 0.00984465937990715
[Epoch 21, Batch 1700] loss: 0.007808289000074429
[Epoch 21, Batch 1800] loss: 0.02030390631911508
[Epoch 21, Batch 1900] loss: 0.00979875664830427
[Epoch 21, Batch 2000] loss: 0.006578505157052819
[Epoch 21, Batch 2100] loss: 0.03070327225338976
[Epoch 21, Batch 2200] loss: 0.015961437287765848
[Epoch 21, Batch 2300] loss: 0.008344361671493501
[Epoch 21, Batch 2400] loss: 0.010110314507134809
[Epoch 21, Batch 2500] loss: 0.0066749530184279406
[Epoch 21, Batch 2600] loss: 0.008894039522305852
[Epoch 21, Batch 2700] loss: 0.01342220784327374
[Epoch 21, Batch 2800] loss: 0.017703680745486786
[Epoch 21, Batch 2900] loss: 0.021831952512474526
[Epoch 21, Batch 3000] loss: 0.01581176651919428
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0631
Validation Accuracy: 0.9878
Overfitting: 0.0631
[Epoch 22, Batch 100] loss: 0.008036907386751899
[Epoch 22, Batch 200] loss: 0.00454674734564049
[Epoch 22, Batch 300] loss: 0.007128237277532463
[Epoch 22, Batch 400] loss: 0.0016723748928665883
[Epoch 22, Batch 500] loss: 0.01370090000858863
[Epoch 22, Batch 600] loss: 0.002059312693573876
[Epoch 22, Batch 700] loss: 0.003828054611007534
[Epoch 22, Batch 800] loss: 0.02967646074155394
[Epoch 22, Batch 900] loss: 0.03798786000347739
[Epoch 22, Batch 1000] loss: 0.014574017606528268
[Epoch 22, Batch 1100] loss: 0.02487527967593693
[Epoch 22, Batch 1200] loss: 0.01536314619382626
[Epoch 22, Batch 1300] loss: 0.027107401818000906
[Epoch 22, Batch 1400] loss: 0.009040788431828374
[Epoch 22, Batch 1500] loss: 0.020056297694866027
[Epoch 22, Batch 1600] loss: 0.006136275751264275
[Epoch 22, Batch 1700] loss: 0.005181095841256438
[Epoch 22, Batch 1800] loss: 0.007068570091565593
[Epoch 22, Batch 1900] loss: 0.017760084198608132
[Epoch 22, Batch 2000] loss: 0.021348084872244016
[Epoch 22, Batch 2100] loss: 0.018371521916874935
[Epoch 22, Batch 2200] loss: 0.009646008676837056
[Epoch 22, Batch 2300] loss: 0.01316805838366832
[Epoch 22, Batch 2400] loss: 0.010576660228216874
[Epoch 22, Batch 2500] loss: 0.006906936241071158
[Epoch 22, Batch 2600] loss: 0.003461150423865531
[Epoch 22, Batch 2700] loss: 0.010739142627586969
[Epoch 22, Batch 2800] loss: 0.029647186703047133
[Epoch 22, Batch 2900] loss: 0.01867484939440274
[Epoch 22, Batch 3000] loss: 0.028792063883097078
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0600
Validation Accuracy: 0.9882
Overfitting: 0.0600
[Epoch 23, Batch 100] loss: 0.00952255944194107
[Epoch 23, Batch 200] loss: 0.017212569154653457
[Epoch 23, Batch 300] loss: 0.004005848653908948
[Epoch 23, Batch 400] loss: 0.01337989305484212
[Epoch 23, Batch 500] loss: 0.0500234426265818
[Epoch 23, Batch 600] loss: 0.024174753385076624
[Epoch 23, Batch 700] loss: 0.010054924649260904
[Epoch 23, Batch 800] loss: 0.006902799274409967
[Epoch 23, Batch 900] loss: 0.007273874467035477
[Epoch 23, Batch 1000] loss: 0.011931522507987622
[Epoch 23, Batch 1100] loss: 0.010782441830256112
[Epoch 23, Batch 1200] loss: 0.011187656417036175
[Epoch 23, Batch 1300] loss: 0.023797114741926216
[Epoch 23, Batch 1400] loss: 0.009250951958109196
[Epoch 23, Batch 1500] loss: 0.004009170197521712
[Epoch 23, Batch 1600] loss: 0.007876704561536196
[Epoch 23, Batch 1700] loss: 0.0013603214989088475
[Epoch 23, Batch 1800] loss: 0.012458737267723978
[Epoch 23, Batch 1900] loss: 0.025871713313998575
[Epoch 23, Batch 2000] loss: 0.01088036624664479
[Epoch 23, Batch 2100] loss: 0.01512908111522572
[Epoch 23, Batch 2200] loss: 0.015037341851081515
[Epoch 23, Batch 2300] loss: 0.023698991171173845
[Epoch 23, Batch 2400] loss: 0.003869833423937319
[Epoch 23, Batch 2500] loss: 0.006671779066966046
[Epoch 23, Batch 2600] loss: 0.004905916168641804
[Epoch 23, Batch 2700] loss: 0.0034926066116111798
[Epoch 23, Batch 2800] loss: 0.02048620173549888
[Epoch 23, Batch 2900] loss: 0.01515451290824693
[Epoch 23, Batch 3000] loss: 0.013607889182041645
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0695
Validation Accuracy: 0.9872
Overfitting: 0.0695
[Epoch 24, Batch 100] loss: 0.0022856939528471633
[Epoch 24, Batch 200] loss: 0.00941020166740076
[Epoch 24, Batch 300] loss: 0.009695864118932352
[Epoch 24, Batch 400] loss: 0.010621924987430819
[Epoch 24, Batch 500] loss: 0.006012512909504828
[Epoch 24, Batch 600] loss: 0.004179026707468414
[Epoch 24, Batch 700] loss: 0.005921885555447242
[Epoch 24, Batch 800] loss: 0.008302369687360525
[Epoch 24, Batch 900] loss: 0.008100155770382757
[Epoch 24, Batch 1000] loss: 0.007550408459215645
[Epoch 24, Batch 1100] loss: 0.014331937726089553
[Epoch 24, Batch 1200] loss: 0.01096958359739662
[Epoch 24, Batch 1300] loss: 0.008420875338401643
[Epoch 24, Batch 1400] loss: 0.00786497299466494
[Epoch 24, Batch 1500] loss: 0.011421081122596256
[Epoch 24, Batch 1600] loss: 0.030468861610111784
[Epoch 24, Batch 1700] loss: 0.0118321843922419
[Epoch 24, Batch 1800] loss: 0.05470630216497705
[Epoch 24, Batch 1900] loss: 0.017359317461995035
[Epoch 24, Batch 2000] loss: 0.041230332298597024
[Epoch 24, Batch 2100] loss: 0.0023823125014847644
[Epoch 24, Batch 2200] loss: 0.04178829157439589
[Epoch 24, Batch 2300] loss: 0.02479225653656619
[Epoch 24, Batch 2400] loss: 0.016380034386176762
[Epoch 24, Batch 2500] loss: 0.029514403587090454
[Epoch 24, Batch 2600] loss: 0.015372971284344228
[Epoch 24, Batch 2700] loss: 0.00782994458831504
[Epoch 24, Batch 2800] loss: 0.030921295068344026
[Epoch 24, Batch 2900] loss: 0.023965706986340363
[Epoch 24, Batch 3000] loss: 0.008277781696808014
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0589
Validation Accuracy: 0.9888
Overfitting: 0.0589
Fold 3 validation loss: 0.0589
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.9929125213623047
[Epoch 1, Batch 200] loss: 0.6538251432776451
[Epoch 1, Batch 300] loss: 0.3838993274047971
[Epoch 1, Batch 400] loss: 0.27243328146636486
[Epoch 1, Batch 500] loss: 0.24398934273049236
[Epoch 1, Batch 600] loss: 0.1814376145543065
[Epoch 1, Batch 700] loss: 0.16828812557738274
[Epoch 1, Batch 800] loss: 0.18634444890194574
[Epoch 1, Batch 900] loss: 0.16712510717334225
[Epoch 1, Batch 1000] loss: 0.18035020161652937
[Epoch 1, Batch 1100] loss: 0.15054553842172028
[Epoch 1, Batch 1200] loss: 0.11549359775963239
[Epoch 1, Batch 1300] loss: 0.09002859212545446
[Epoch 1, Batch 1400] loss: 0.1302896738986601
[Epoch 1, Batch 1500] loss: 0.11102309271227569
[Epoch 1, Batch 1600] loss: 0.12829475505976007
[Epoch 1, Batch 1700] loss: 0.12184923757828074
[Epoch 1, Batch 1800] loss: 0.11485047578142257
[Epoch 1, Batch 1900] loss: 0.11149099056143313
[Epoch 1, Batch 2000] loss: 0.10416712631355039
[Epoch 1, Batch 2100] loss: 0.12492425856995397
[Epoch 1, Batch 2200] loss: 0.09826337814563885
[Epoch 1, Batch 2300] loss: 0.10989150828914716
[Epoch 1, Batch 2400] loss: 0.1029927155590849
[Epoch 1, Batch 2500] loss: 0.10129873004567344
[Epoch 1, Batch 2600] loss: 0.10753850083652651
[Epoch 1, Batch 2700] loss: 0.10596213712822646
[Epoch 1, Batch 2800] loss: 0.09966186772682704
[Epoch 1, Batch 2900] loss: 0.0881618023046758
[Epoch 1, Batch 3000] loss: 0.1262127514136955
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0670
Validation Accuracy: 0.9794
Overfitting: 0.0670
Best model saved at epoch 1 with validation loss: 0.0670
[Epoch 2, Batch 100] loss: 0.06873626244341721
[Epoch 2, Batch 200] loss: 0.09879402406397275
[Epoch 2, Batch 300] loss: 0.062367781975190155
[Epoch 2, Batch 400] loss: 0.0784006923015113
[Epoch 2, Batch 500] loss: 0.08180803512703277
[Epoch 2, Batch 600] loss: 0.10026750647637528
[Epoch 2, Batch 700] loss: 0.05922290181923017
[Epoch 2, Batch 800] loss: 0.06264965182112064
[Epoch 2, Batch 900] loss: 0.06869527863374969
[Epoch 2, Batch 1000] loss: 0.07567966621660162
[Epoch 2, Batch 1100] loss: 0.07158817202842328
[Epoch 2, Batch 1200] loss: 0.08451442756617325
[Epoch 2, Batch 1300] loss: 0.06509213880417519
[Epoch 2, Batch 1400] loss: 0.10787131438381038
[Epoch 2, Batch 1500] loss: 0.06613443662230566
[Epoch 2, Batch 1600] loss: 0.06983259299915517
[Epoch 2, Batch 1700] loss: 0.08086380307780928
[Epoch 2, Batch 1800] loss: 0.06204584183578845
[Epoch 2, Batch 1900] loss: 0.06642738121277944
[Epoch 2, Batch 2000] loss: 0.05546885355128325
[Epoch 2, Batch 2100] loss: 0.04864442871330539
[Epoch 2, Batch 2200] loss: 0.06118914630525978
[Epoch 2, Batch 2300] loss: 0.050430733687499014
[Epoch 2, Batch 2400] loss: 0.05482484231557464
[Epoch 2, Batch 2500] loss: 0.041926321716800885
[Epoch 2, Batch 2600] loss: 0.07957569898717338
[Epoch 2, Batch 2700] loss: 0.07890088240557816
[Epoch 2, Batch 2800] loss: 0.08825499954517
[Epoch 2, Batch 2900] loss: 0.05361117022606777
[Epoch 2, Batch 3000] loss: 0.06730260767159052
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9818
Overfitting: 0.0593
Best model saved at epoch 2 with validation loss: 0.0593
[Epoch 3, Batch 100] loss: 0.029342038545892138
[Epoch 3, Batch 200] loss: 0.050584947833376644
[Epoch 3, Batch 300] loss: 0.04491001096834225
[Epoch 3, Batch 400] loss: 0.03010757414609543
[Epoch 3, Batch 500] loss: 0.06988054793655465
[Epoch 3, Batch 600] loss: 0.051329062955337575
[Epoch 3, Batch 700] loss: 0.05997169245991245
[Epoch 3, Batch 800] loss: 0.06731373786540644
[Epoch 3, Batch 900] loss: 0.08607221177328028
[Epoch 3, Batch 1000] loss: 0.05973849038913613
[Epoch 3, Batch 1100] loss: 0.05437319692089659
[Epoch 3, Batch 1200] loss: 0.03979581433661224
[Epoch 3, Batch 1300] loss: 0.04526653456479835
[Epoch 3, Batch 1400] loss: 0.06332258809476116
[Epoch 3, Batch 1500] loss: 0.03391528576747078
[Epoch 3, Batch 1600] loss: 0.04695519152344787
[Epoch 3, Batch 1700] loss: 0.04135375582283814
[Epoch 3, Batch 1800] loss: 0.06226461111913523
[Epoch 3, Batch 1900] loss: 0.04617966149307904
[Epoch 3, Batch 2000] loss: 0.05130065647303127
[Epoch 3, Batch 2100] loss: 0.039284157390284236
[Epoch 3, Batch 2200] loss: 0.035489629473831885
[Epoch 3, Batch 2300] loss: 0.05969226701636217
[Epoch 3, Batch 2400] loss: 0.04497032628938541
[Epoch 3, Batch 2500] loss: 0.06757920919044409
[Epoch 3, Batch 2600] loss: 0.06189027153333882
[Epoch 3, Batch 2700] loss: 0.04639146862822599
[Epoch 3, Batch 2800] loss: 0.050193729757229445
[Epoch 3, Batch 2900] loss: 0.046135448876666485
[Epoch 3, Batch 3000] loss: 0.053659664064471146
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9848
Overfitting: 0.0485
Best model saved at epoch 3 with validation loss: 0.0485
[Epoch 4, Batch 100] loss: 0.040683567495798344
[Epoch 4, Batch 200] loss: 0.04077266308973776
[Epoch 4, Batch 300] loss: 0.03608471702798852
[Epoch 4, Batch 400] loss: 0.03907484860275872
[Epoch 4, Batch 500] loss: 0.03524134054387105
[Epoch 4, Batch 600] loss: 0.015014294013967628
[Epoch 4, Batch 700] loss: 0.04753178138934345
[Epoch 4, Batch 800] loss: 0.042368548275417195
[Epoch 4, Batch 900] loss: 0.04313258945156122
[Epoch 4, Batch 1000] loss: 0.02414531143990814
[Epoch 4, Batch 1100] loss: 0.06635604628027067
[Epoch 4, Batch 1200] loss: 0.02435545615772753
[Epoch 4, Batch 1300] loss: 0.037005095235581396
[Epoch 4, Batch 1400] loss: 0.04736182498978451
[Epoch 4, Batch 1500] loss: 0.035833764530580084
[Epoch 4, Batch 1600] loss: 0.03658669431584713
[Epoch 4, Batch 1700] loss: 0.03555626819474128
[Epoch 4, Batch 1800] loss: 0.0352109675645761
[Epoch 4, Batch 1900] loss: 0.035909186785283966
[Epoch 4, Batch 2000] loss: 0.05032795820581668
[Epoch 4, Batch 2100] loss: 0.03238455213797351
[Epoch 4, Batch 2200] loss: 0.055383823313786704
[Epoch 4, Batch 2300] loss: 0.032020951714730475
[Epoch 4, Batch 2400] loss: 0.041535784614416114
[Epoch 4, Batch 2500] loss: 0.03535314654850481
[Epoch 4, Batch 2600] loss: 0.03552531094496317
[Epoch 4, Batch 2700] loss: 0.03655242566986999
[Epoch 4, Batch 2800] loss: 0.05000395389435653
[Epoch 4, Batch 2900] loss: 0.04366085719941111
[Epoch 4, Batch 3000] loss: 0.05805020155225066
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0568
Validation Accuracy: 0.9843
Overfitting: 0.0568
[Epoch 5, Batch 100] loss: 0.040403435991465814
[Epoch 5, Batch 200] loss: 0.02830390210447149
[Epoch 5, Batch 300] loss: 0.022203634507895913
[Epoch 5, Batch 400] loss: 0.017948864413283444
[Epoch 5, Batch 500] loss: 0.013888108563282913
[Epoch 5, Batch 600] loss: 0.04510393217897217
[Epoch 5, Batch 700] loss: 0.04337103065776318
[Epoch 5, Batch 800] loss: 0.01663682123027229
[Epoch 5, Batch 900] loss: 0.03548268236683725
[Epoch 5, Batch 1000] loss: 0.05059576943389402
[Epoch 5, Batch 1100] loss: 0.04435115232770613
[Epoch 5, Batch 1200] loss: 0.024034941323780003
[Epoch 5, Batch 1300] loss: 0.03088895496994155
[Epoch 5, Batch 1400] loss: 0.050859482399991975
[Epoch 5, Batch 1500] loss: 0.031844930768602356
[Epoch 5, Batch 1600] loss: 0.039494823576933416
[Epoch 5, Batch 1700] loss: 0.03575308651350497
[Epoch 5, Batch 1800] loss: 0.031205007664375443
[Epoch 5, Batch 1900] loss: 0.03833492996055611
[Epoch 5, Batch 2000] loss: 0.039850383253678956
[Epoch 5, Batch 2100] loss: 0.03834807290513709
[Epoch 5, Batch 2200] loss: 0.023925139347957158
[Epoch 5, Batch 2300] loss: 0.04878848881380691
[Epoch 5, Batch 2400] loss: 0.040125978368778306
[Epoch 5, Batch 2500] loss: 0.04135408299101982
[Epoch 5, Batch 2600] loss: 0.03792407291533891
[Epoch 5, Batch 2700] loss: 0.03948247561369101
[Epoch 5, Batch 2800] loss: 0.03621318778195018
[Epoch 5, Batch 2900] loss: 0.03711688310828322
[Epoch 5, Batch 3000] loss: 0.04343919493883732
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9842
Overfitting: 0.0606
[Epoch 6, Batch 100] loss: 0.028054130024456753
[Epoch 6, Batch 200] loss: 0.03409637753858988
[Epoch 6, Batch 300] loss: 0.02053169997750956
[Epoch 6, Batch 400] loss: 0.02466564370510241
[Epoch 6, Batch 500] loss: 0.026139963364912547
[Epoch 6, Batch 600] loss: 0.0245520966998356
[Epoch 6, Batch 700] loss: 0.03590333934524097
[Epoch 6, Batch 800] loss: 0.016785512774895324
[Epoch 6, Batch 900] loss: 0.02387983607292881
[Epoch 6, Batch 1000] loss: 0.019676718704197356
[Epoch 6, Batch 1100] loss: 0.025767458487930526
[Epoch 6, Batch 1200] loss: 0.007966512234321498
[Epoch 6, Batch 1300] loss: 0.020815842866202274
[Epoch 6, Batch 1400] loss: 0.02515773818263085
[Epoch 6, Batch 1500] loss: 0.01999451534635682
[Epoch 6, Batch 1600] loss: 0.023887718398382277
[Epoch 6, Batch 1700] loss: 0.039169284399067694
[Epoch 6, Batch 1800] loss: 0.05681712222221904
[Epoch 6, Batch 1900] loss: 0.021627187634453548
[Epoch 6, Batch 2000] loss: 0.01712652734857784
[Epoch 6, Batch 2100] loss: 0.017427048956515135
[Epoch 6, Batch 2200] loss: 0.042591081898040103
[Epoch 6, Batch 2300] loss: 0.03994621698102719
[Epoch 6, Batch 2400] loss: 0.03880720912691686
[Epoch 6, Batch 2500] loss: 0.009059343832141166
[Epoch 6, Batch 2600] loss: 0.02637606111475861
[Epoch 6, Batch 2700] loss: 0.029518997862962807
[Epoch 6, Batch 2800] loss: 0.026392818462218203
[Epoch 6, Batch 2900] loss: 0.03601490325038071
[Epoch 6, Batch 3000] loss: 0.039010378280327135
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9834
Overfitting: 0.0581
[Epoch 7, Batch 100] loss: 0.025502145633217878
[Epoch 7, Batch 200] loss: 0.020464964378447803
[Epoch 7, Batch 300] loss: 0.02995716184021603
[Epoch 7, Batch 400] loss: 0.020753604427957272
[Epoch 7, Batch 500] loss: 0.022224301612714045
[Epoch 7, Batch 600] loss: 0.020311951119128934
[Epoch 7, Batch 700] loss: 0.016237012369051628
[Epoch 7, Batch 800] loss: 0.02443099741649348
[Epoch 7, Batch 900] loss: 0.021614401265608763
[Epoch 7, Batch 1000] loss: 0.04487893515245105
[Epoch 7, Batch 1100] loss: 0.026689722176065515
[Epoch 7, Batch 1200] loss: 0.01585018730394495
[Epoch 7, Batch 1300] loss: 0.029235720178821794
[Epoch 7, Batch 1400] loss: 0.030133194572927097
[Epoch 7, Batch 1500] loss: 0.02607306867039348
[Epoch 7, Batch 1600] loss: 0.017260667688985053
[Epoch 7, Batch 1700] loss: 0.04628311172904318
[Epoch 7, Batch 1800] loss: 0.025100287282293722
[Epoch 7, Batch 1900] loss: 0.04168596149356176
[Epoch 7, Batch 2000] loss: 0.016594674937728086
[Epoch 7, Batch 2100] loss: 0.036749196663076876
[Epoch 7, Batch 2200] loss: 0.014029057878751701
[Epoch 7, Batch 2300] loss: 0.030930179894742196
[Epoch 7, Batch 2400] loss: 0.028928544811164726
[Epoch 7, Batch 2500] loss: 0.021333673601561715
[Epoch 7, Batch 2600] loss: 0.03325798198768098
[Epoch 7, Batch 2700] loss: 0.029963271782155517
[Epoch 7, Batch 2800] loss: 0.018170646112605483
[Epoch 7, Batch 2900] loss: 0.03502955866200864
[Epoch 7, Batch 3000] loss: 0.050542782982893185
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9843
Overfitting: 0.0608
[Epoch 8, Batch 100] loss: 0.02494198412045762
[Epoch 8, Batch 200] loss: 0.030640959578149704
[Epoch 8, Batch 300] loss: 0.01032362540137001
[Epoch 8, Batch 400] loss: 0.01714073798974141
[Epoch 8, Batch 500] loss: 0.015004877294466042
[Epoch 8, Batch 600] loss: 0.014483131513302964
[Epoch 8, Batch 700] loss: 0.019636912258380334
[Epoch 8, Batch 800] loss: 0.018698838796436235
[Epoch 8, Batch 900] loss: 0.02896852845331068
[Epoch 8, Batch 1000] loss: 0.01334286938311152
[Epoch 8, Batch 1100] loss: 0.01811879775665396
[Epoch 8, Batch 1200] loss: 0.023501593368426086
[Epoch 8, Batch 1300] loss: 0.012027391418166077
[Epoch 8, Batch 1400] loss: 0.022080823077067747
[Epoch 8, Batch 1500] loss: 0.0368460917974744
[Epoch 8, Batch 1600] loss: 0.0267218996170271
[Epoch 8, Batch 1700] loss: 0.023759215934298937
[Epoch 8, Batch 1800] loss: 0.034303078164184625
[Epoch 8, Batch 1900] loss: 0.028142236014526815
[Epoch 8, Batch 2000] loss: 0.022209757694264455
[Epoch 8, Batch 2100] loss: 0.02750625224531177
[Epoch 8, Batch 2200] loss: 0.017828725477575063
[Epoch 8, Batch 2300] loss: 0.01187185587555632
[Epoch 8, Batch 2400] loss: 0.02334553046216797
[Epoch 8, Batch 2500] loss: 0.020710062959458354
[Epoch 8, Batch 2600] loss: 0.022496096347894935
[Epoch 8, Batch 2700] loss: 0.03499386875507412
[Epoch 8, Batch 2800] loss: 0.017932102534167597
[Epoch 8, Batch 2900] loss: 0.017510314945106985
[Epoch 8, Batch 3000] loss: 0.03803688588265459
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9850
Overfitting: 0.0548
[Epoch 9, Batch 100] loss: 0.016844138126025428
[Epoch 9, Batch 200] loss: 0.023383206873413654
[Epoch 9, Batch 300] loss: 0.025168981277687977
[Epoch 9, Batch 400] loss: 0.010437055187057922
[Epoch 9, Batch 500] loss: 0.012533800842636538
[Epoch 9, Batch 600] loss: 0.029772452812983373
[Epoch 9, Batch 700] loss: 0.04873671573388265
[Epoch 9, Batch 800] loss: 0.021368069092326893
[Epoch 9, Batch 900] loss: 0.03437047804882013
[Epoch 9, Batch 1000] loss: 0.03357949075223587
[Epoch 9, Batch 1100] loss: 0.017798481933155016
[Epoch 9, Batch 1200] loss: 0.016499686888580528
[Epoch 9, Batch 1300] loss: 0.008846826361445893
[Epoch 9, Batch 1400] loss: 0.015487174477898406
[Epoch 9, Batch 1500] loss: 0.018769080289185922
[Epoch 9, Batch 1600] loss: 0.03686684863418122
[Epoch 9, Batch 1700] loss: 0.01128412268806187
[Epoch 9, Batch 1800] loss: 0.01676092926735265
[Epoch 9, Batch 1900] loss: 0.01840022705726824
[Epoch 9, Batch 2000] loss: 0.0319161792724617
[Epoch 9, Batch 2100] loss: 0.020360722623801734
[Epoch 9, Batch 2200] loss: 0.021347657336264092
[Epoch 9, Batch 2300] loss: 0.03607777314964096
[Epoch 9, Batch 2400] loss: 0.03046046702738863
[Epoch 9, Batch 2500] loss: 0.022866880047058658
[Epoch 9, Batch 2600] loss: 0.01548309785321635
[Epoch 9, Batch 2700] loss: 0.018634337181453305
[Epoch 9, Batch 2800] loss: 0.039498199321437825
[Epoch 9, Batch 2900] loss: 0.022104601009098133
[Epoch 9, Batch 3000] loss: 0.021190025734672418
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9874
Overfitting: 0.0491
[Epoch 10, Batch 100] loss: 0.014798403277097805
[Epoch 10, Batch 200] loss: 0.02891612249838829
[Epoch 10, Batch 300] loss: 0.02724820022159065
[Epoch 10, Batch 400] loss: 0.021053772481889155
[Epoch 10, Batch 500] loss: 0.01581429530479369
[Epoch 10, Batch 600] loss: 0.02270166285784626
[Epoch 10, Batch 700] loss: 0.015452730713270739
[Epoch 10, Batch 800] loss: 0.012032554343907122
[Epoch 10, Batch 900] loss: 0.012193081633594999
[Epoch 10, Batch 1000] loss: 0.012957819474011317
[Epoch 10, Batch 1100] loss: 0.017046878390921307
[Epoch 10, Batch 1200] loss: 0.02355917418703008
[Epoch 10, Batch 1300] loss: 0.03655648521536051
[Epoch 10, Batch 1400] loss: 0.04822981612845595
[Epoch 10, Batch 1500] loss: 0.017823069541310018
[Epoch 10, Batch 1600] loss: 0.03427274010785368
[Epoch 10, Batch 1700] loss: 0.02162008529949787
[Epoch 10, Batch 1800] loss: 0.025101177176039755
[Epoch 10, Batch 1900] loss: 0.01892693958856512
[Epoch 10, Batch 2000] loss: 0.011507692223636354
[Epoch 10, Batch 2100] loss: 0.012597556703790645
[Epoch 10, Batch 2200] loss: 0.028848898779373258
[Epoch 10, Batch 2300] loss: 0.01512687649213234
[Epoch 10, Batch 2400] loss: 0.0491098380962103
[Epoch 10, Batch 2500] loss: 0.01878984754528176
[Epoch 10, Batch 2600] loss: 0.016636810542956085
[Epoch 10, Batch 2700] loss: 0.024405653401438486
[Epoch 10, Batch 2800] loss: 0.019693082926237348
[Epoch 10, Batch 2900] loss: 0.021933131715050676
[Epoch 10, Batch 3000] loss: 0.016441557425411587
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9844
Overfitting: 0.0592
[Epoch 11, Batch 100] loss: 0.029644255491061103
[Epoch 11, Batch 200] loss: 0.026271884679254072
[Epoch 11, Batch 300] loss: 0.007068218959744854
[Epoch 11, Batch 400] loss: 0.013399435646280083
[Epoch 11, Batch 500] loss: 0.009297235445926333
[Epoch 11, Batch 600] loss: 0.022485018563540963
[Epoch 11, Batch 700] loss: 0.01798306970037288
[Epoch 11, Batch 800] loss: 0.021998621289249058
[Epoch 11, Batch 900] loss: 0.012798995081559496
[Epoch 11, Batch 1000] loss: 0.007287228763913198
[Epoch 11, Batch 1100] loss: 0.01563107374102543
[Epoch 11, Batch 1200] loss: 0.02468479986106189
[Epoch 11, Batch 1300] loss: 0.014990609047901771
[Epoch 11, Batch 1400] loss: 0.0177202217002079
[Epoch 11, Batch 1500] loss: 0.021498509575993693
[Epoch 11, Batch 1600] loss: 0.02389201806628062
[Epoch 11, Batch 1700] loss: 0.025877833840439665
[Epoch 11, Batch 1800] loss: 0.030113327529166158
[Epoch 11, Batch 1900] loss: 0.017721412079802122
[Epoch 11, Batch 2000] loss: 0.014908839876164847
[Epoch 11, Batch 2100] loss: 0.0292913510689705
[Epoch 11, Batch 2200] loss: 0.02169476213575166
[Epoch 11, Batch 2300] loss: 0.05404144276745325
[Epoch 11, Batch 2400] loss: 0.03532458947853911
[Epoch 11, Batch 2500] loss: 0.023631022125132402
[Epoch 11, Batch 2600] loss: 0.011283760600860403
[Epoch 11, Batch 2700] loss: 0.017905736746910178
[Epoch 11, Batch 2800] loss: 0.02055673411814894
[Epoch 11, Batch 2900] loss: 0.012943576925025227
[Epoch 11, Batch 3000] loss: 0.00612027473714221
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0591
Validation Accuracy: 0.9885
Overfitting: 0.0591
[Epoch 12, Batch 100] loss: 0.009673968297922641
[Epoch 12, Batch 200] loss: 0.005015338185916036
[Epoch 12, Batch 300] loss: 0.004630024518839893
[Epoch 12, Batch 400] loss: 0.008869720105580198
[Epoch 12, Batch 500] loss: 0.009631768448200488
[Epoch 12, Batch 600] loss: 0.02097106892967801
[Epoch 12, Batch 700] loss: 0.012668174242951408
[Epoch 12, Batch 800] loss: 0.03472273153980907
[Epoch 12, Batch 900] loss: 0.01159716536439177
[Epoch 12, Batch 1000] loss: 0.01123527255287712
[Epoch 12, Batch 1100] loss: 0.038609781992530824
[Epoch 12, Batch 1200] loss: 0.03404169561108347
[Epoch 12, Batch 1300] loss: 0.024336596000958933
[Epoch 12, Batch 1400] loss: 0.022949385543193444
[Epoch 12, Batch 1500] loss: 0.012346367862307943
[Epoch 12, Batch 1600] loss: 0.01910352355979455
[Epoch 12, Batch 1700] loss: 0.016434788316688577
[Epoch 12, Batch 1800] loss: 0.020313729288888
[Epoch 12, Batch 1900] loss: 0.013340261642715312
[Epoch 12, Batch 2000] loss: 0.018149538293475057
[Epoch 12, Batch 2100] loss: 0.009354631305914154
[Epoch 12, Batch 2200] loss: 0.0108803925362816
[Epoch 12, Batch 2300] loss: 0.025626448745373266
[Epoch 12, Batch 2400] loss: 0.025844297571137674
[Epoch 12, Batch 2500] loss: 0.007884753229918644
[Epoch 12, Batch 2600] loss: 0.021762587478321792
[Epoch 12, Batch 2700] loss: 0.019166959079652556
[Epoch 12, Batch 2800] loss: 0.026797998752600735
[Epoch 12, Batch 2900] loss: 0.014921230857670498
[Epoch 12, Batch 3000] loss: 0.011255557154197647
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0627
Validation Accuracy: 0.9889
Overfitting: 0.0627
[Epoch 13, Batch 100] loss: 0.0082629975902438
[Epoch 13, Batch 200] loss: 0.010821844761955544
[Epoch 13, Batch 300] loss: 0.014025953702402769
[Epoch 13, Batch 400] loss: 0.010827096413619498
[Epoch 13, Batch 500] loss: 0.034123686674368645
[Epoch 13, Batch 600] loss: 0.03157875912752104
[Epoch 13, Batch 700] loss: 0.024607628125306178
[Epoch 13, Batch 800] loss: 0.030841221695774267
[Epoch 13, Batch 900] loss: 0.04132876813362287
[Epoch 13, Batch 1000] loss: 0.015381411130400124
[Epoch 13, Batch 1100] loss: 0.01552144829349686
[Epoch 13, Batch 1200] loss: 0.01523167705282873
[Epoch 13, Batch 1300] loss: 0.006240207737652881
[Epoch 13, Batch 1400] loss: 0.008652826531061742
[Epoch 13, Batch 1500] loss: 0.008878895176343916
[Epoch 13, Batch 1600] loss: 0.004957647184123175
[Epoch 13, Batch 1700] loss: 0.03505637174704081
[Epoch 13, Batch 1800] loss: 0.01770029624174498
[Epoch 13, Batch 1900] loss: 0.022875412527818214
[Epoch 13, Batch 2000] loss: 0.014011175711139287
[Epoch 13, Batch 2100] loss: 0.020035455824532988
[Epoch 13, Batch 2200] loss: 0.00834840855552656
[Epoch 13, Batch 2300] loss: 0.02004049051368021
[Epoch 13, Batch 2400] loss: 0.0174911549565293
[Epoch 13, Batch 2500] loss: 0.00458279740989262
[Epoch 13, Batch 2600] loss: 0.02142497041854611
[Epoch 13, Batch 2700] loss: 0.010884097005587137
[Epoch 13, Batch 2800] loss: 0.017402402239901846
[Epoch 13, Batch 2900] loss: 0.014090699554513142
[Epoch 13, Batch 3000] loss: 0.017175744987904907
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0609
Validation Accuracy: 0.9877
Overfitting: 0.0609
[Epoch 14, Batch 100] loss: 0.013416298277714987
[Epoch 14, Batch 200] loss: 0.004125370307760079
[Epoch 14, Batch 300] loss: 0.007215789846878305
[Epoch 14, Batch 400] loss: 0.005197181870528556
[Epoch 14, Batch 500] loss: 0.008824104970424003
[Epoch 14, Batch 600] loss: 0.009193781092929197
[Epoch 14, Batch 700] loss: 0.010597031754590062
[Epoch 14, Batch 800] loss: 0.008306904864366799
[Epoch 14, Batch 900] loss: 0.012197467388543685
[Epoch 14, Batch 1000] loss: 0.016180627262290886
[Epoch 14, Batch 1100] loss: 0.010713575619205783
[Epoch 14, Batch 1200] loss: 0.01583057757692222
[Epoch 14, Batch 1300] loss: 0.01928549507900273
[Epoch 14, Batch 1400] loss: 0.016463063582725593
[Epoch 14, Batch 1500] loss: 0.014371897938138428
[Epoch 14, Batch 1600] loss: 0.022625089042078307
[Epoch 14, Batch 1700] loss: 0.032580199527395735
[Epoch 14, Batch 1800] loss: 0.02520062924032814
[Epoch 14, Batch 1900] loss: 0.023227502799857972
[Epoch 14, Batch 2000] loss: 0.0075095488170445176
[Epoch 14, Batch 2100] loss: 0.037771033968953774
[Epoch 14, Batch 2200] loss: 0.0166876432885158
[Epoch 14, Batch 2300] loss: 0.019235152285161945
[Epoch 14, Batch 2400] loss: 0.021360671778300002
[Epoch 14, Batch 2500] loss: 0.021280492288911147
[Epoch 14, Batch 2600] loss: 0.014701968187471265
[Epoch 14, Batch 2700] loss: 0.011272852547473917
[Epoch 14, Batch 2800] loss: 0.0118773463575863
[Epoch 14, Batch 2900] loss: 0.010916150037363934
[Epoch 14, Batch 3000] loss: 0.008702923428858754
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9892
Overfitting: 0.0538
[Epoch 15, Batch 100] loss: 0.004342828788509179
[Epoch 15, Batch 200] loss: 0.007685655101535503
[Epoch 15, Batch 300] loss: 0.011278668792997451
[Epoch 15, Batch 400] loss: 0.0058814598874900705
[Epoch 15, Batch 500] loss: 0.014657493947468047
[Epoch 15, Batch 600] loss: 0.009431261916070053
[Epoch 15, Batch 700] loss: 0.0173022533464154
[Epoch 15, Batch 800] loss: 0.01753846878569032
[Epoch 15, Batch 900] loss: 0.009819756626659504
[Epoch 15, Batch 1000] loss: 0.006221285219187887
[Epoch 15, Batch 1100] loss: 0.009893886629361836
[Epoch 15, Batch 1200] loss: 0.005086155978374185
[Epoch 15, Batch 1300] loss: 0.004476671254692053
[Epoch 15, Batch 1400] loss: 0.018453587438894855
[Epoch 15, Batch 1500] loss: 0.017370620153446127
[Epoch 15, Batch 1600] loss: 0.031785661715440554
[Epoch 15, Batch 1700] loss: 0.010410161199647518
[Epoch 15, Batch 1800] loss: 0.018314897387487844
[Epoch 15, Batch 1900] loss: 0.01597003123159606
[Epoch 15, Batch 2000] loss: 0.017147698875816728
[Epoch 15, Batch 2100] loss: 0.00997404884455456
[Epoch 15, Batch 2200] loss: 0.007656035859417151
[Epoch 15, Batch 2300] loss: 0.013218267952509329
[Epoch 15, Batch 2400] loss: 0.019619853398427357
[Epoch 15, Batch 2500] loss: 0.03221307940824164
[Epoch 15, Batch 2600] loss: 0.012293376912800502
[Epoch 15, Batch 2700] loss: 0.015732024410913256
[Epoch 15, Batch 2800] loss: 0.03552753299420828
[Epoch 15, Batch 2900] loss: 0.011601937118523437
[Epoch 15, Batch 3000] loss: 0.010705259030246949
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0558
Validation Accuracy: 0.9886
Overfitting: 0.0558
[Epoch 16, Batch 100] loss: 0.004079468180296999
[Epoch 16, Batch 200] loss: 0.0049788639219910235
[Epoch 16, Batch 300] loss: 0.002535054379122865
[Epoch 16, Batch 400] loss: 0.0211536431195006
[Epoch 16, Batch 500] loss: 0.019879119460001905
[Epoch 16, Batch 600] loss: 0.006447536588431899
[Epoch 16, Batch 700] loss: 0.011980019982408528
[Epoch 16, Batch 800] loss: 0.015916288576182037
[Epoch 16, Batch 900] loss: 0.005425390632998552
[Epoch 16, Batch 1000] loss: 0.005602779979189942
[Epoch 16, Batch 1100] loss: 0.02273222269761401
[Epoch 16, Batch 1200] loss: 0.028746854459286625
[Epoch 16, Batch 1300] loss: 0.012649784533678297
[Epoch 16, Batch 1400] loss: 0.0071718960753669545
[Epoch 16, Batch 1500] loss: 0.015732798381699525
[Epoch 16, Batch 1600] loss: 0.00976841115721129
[Epoch 16, Batch 1700] loss: 0.005580904959785569
[Epoch 16, Batch 1800] loss: 0.013496627730233968
[Epoch 16, Batch 1900] loss: 0.005315513028476513
[Epoch 16, Batch 2000] loss: 0.003472105888154711
[Epoch 16, Batch 2100] loss: 0.014561933583408316
[Epoch 16, Batch 2200] loss: 0.011719079877086641
[Epoch 16, Batch 2300] loss: 0.017703882017085823
[Epoch 16, Batch 2400] loss: 0.02017478436952195
[Epoch 16, Batch 2500] loss: 0.020634059062179518
[Epoch 16, Batch 2600] loss: 0.006715045992470223
[Epoch 16, Batch 2700] loss: 0.004523201285388865
[Epoch 16, Batch 2800] loss: 0.008375541093988255
[Epoch 16, Batch 2900] loss: 0.021211983613224943
[Epoch 16, Batch 3000] loss: 0.007829891953619574
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0582
Validation Accuracy: 0.9885
Overfitting: 0.0582
[Epoch 17, Batch 100] loss: 0.0009431384858374159
[Epoch 17, Batch 200] loss: 0.00938960813832333
[Epoch 17, Batch 300] loss: 0.003765728073727241
[Epoch 17, Batch 400] loss: 0.010848347026886924
[Epoch 17, Batch 500] loss: 0.025991899390722894
[Epoch 17, Batch 600] loss: 0.010095468766765557
[Epoch 17, Batch 700] loss: 0.01263772249714548
[Epoch 17, Batch 800] loss: 0.01872468730848432
[Epoch 17, Batch 900] loss: 0.010738042295525822
[Epoch 17, Batch 1000] loss: 0.003888326347494222
[Epoch 17, Batch 1100] loss: 0.026909846483338665
[Epoch 17, Batch 1200] loss: 0.011806845270749537
[Epoch 17, Batch 1300] loss: 0.007483485500044855
[Epoch 17, Batch 1400] loss: 0.006185071268770339
[Epoch 17, Batch 1500] loss: 0.013065726192063348
[Epoch 17, Batch 1600] loss: 0.011771351922192976
[Epoch 17, Batch 1700] loss: 0.0218092419269751
[Epoch 17, Batch 1800] loss: 0.030230688875454347
[Epoch 17, Batch 1900] loss: 0.016531678326949083
[Epoch 17, Batch 2000] loss: 0.016793652071287787
[Epoch 17, Batch 2100] loss: 0.024214505637134457
[Epoch 17, Batch 2200] loss: 0.015597844502344386
[Epoch 17, Batch 2300] loss: 0.0051942297564095295
[Epoch 17, Batch 2400] loss: 0.017580704600239992
[Epoch 17, Batch 2500] loss: 0.022845728259294765
[Epoch 17, Batch 2600] loss: 0.014540402843420744
[Epoch 17, Batch 2700] loss: 0.0318806833820247
[Epoch 17, Batch 2800] loss: 0.04215660242143413
[Epoch 17, Batch 2900] loss: 0.012691811432506004
[Epoch 17, Batch 3000] loss: 0.01696210296820706
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0824
Validation Accuracy: 0.9857
Overfitting: 0.0824
[Epoch 18, Batch 100] loss: 0.03408728979485907
[Epoch 18, Batch 200] loss: 0.008032782086860877
[Epoch 18, Batch 300] loss: 0.006103229698012314
[Epoch 18, Batch 400] loss: 0.010767921175088265
[Epoch 18, Batch 500] loss: 0.010504808013836388
[Epoch 18, Batch 600] loss: 0.02103567636111391
[Epoch 18, Batch 700] loss: 0.01619103742642537
[Epoch 18, Batch 800] loss: 0.015919144090492027
[Epoch 18, Batch 900] loss: 0.011152905792505692
[Epoch 18, Batch 1000] loss: 0.03930004674462772
[Epoch 18, Batch 1100] loss: 0.01167285025870512
[Epoch 18, Batch 1200] loss: 0.01077672245257423
[Epoch 18, Batch 1300] loss: 0.012816663386935784
[Epoch 18, Batch 1400] loss: 0.032433541472629425
[Epoch 18, Batch 1500] loss: 0.02694017982426809
[Epoch 18, Batch 1600] loss: 0.04715481246794724
[Epoch 18, Batch 1700] loss: 0.018365031973996686
[Epoch 18, Batch 1800] loss: 0.011877474856067955
[Epoch 18, Batch 1900] loss: 0.02540411612030375
[Epoch 18, Batch 2000] loss: 0.02553656420134198
[Epoch 18, Batch 2100] loss: 0.048543650146402086
[Epoch 18, Batch 2200] loss: 0.043119487667289604
[Epoch 18, Batch 2300] loss: 0.010788399444143941
[Epoch 18, Batch 2400] loss: 0.012217958074693551
[Epoch 18, Batch 2500] loss: 0.016140446706015298
[Epoch 18, Batch 2600] loss: 0.01734678073745897
[Epoch 18, Batch 2700] loss: 0.017442799094271492
[Epoch 18, Batch 2800] loss: 0.034931889034569966
[Epoch 18, Batch 2900] loss: 0.012646402493267015
[Epoch 18, Batch 3000] loss: 0.01508533870177855
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0711
Validation Accuracy: 0.9868
Overfitting: 0.0711
[Epoch 19, Batch 100] loss: 0.003591625995478345
[Epoch 19, Batch 200] loss: 0.009591598519671925
[Epoch 19, Batch 300] loss: 0.0070527022906226745
[Epoch 19, Batch 400] loss: 0.010803329465117306
[Epoch 19, Batch 500] loss: 0.00821586876991935
[Epoch 19, Batch 600] loss: 0.009149395627927532
[Epoch 19, Batch 700] loss: 0.02190555651398139
[Epoch 19, Batch 800] loss: 0.005090198623688588
[Epoch 19, Batch 900] loss: 0.010677499768044614
[Epoch 19, Batch 1000] loss: 0.00374832688497869
[Epoch 19, Batch 1100] loss: 0.0017192942162308977
[Epoch 19, Batch 1200] loss: 0.0038133626503137298
[Epoch 19, Batch 1300] loss: 0.0037372013195414635
[Epoch 19, Batch 1400] loss: 0.035451419064348046
[Epoch 19, Batch 1500] loss: 0.013461977646354976
[Epoch 19, Batch 1600] loss: 0.024339546373975778
[Epoch 19, Batch 1700] loss: 0.014320037934497858
[Epoch 19, Batch 1800] loss: 0.02405127657673381
[Epoch 19, Batch 1900] loss: 0.03272993745076048
[Epoch 19, Batch 2000] loss: 0.01887640833059757
[Epoch 19, Batch 2100] loss: 0.013550900141255297
[Epoch 19, Batch 2200] loss: 0.011340327478245626
[Epoch 19, Batch 2300] loss: 0.007502116057274524
[Epoch 19, Batch 2400] loss: 0.008616668755134347
[Epoch 19, Batch 2500] loss: 0.02618289753884999
[Epoch 19, Batch 2600] loss: 0.02655949171505652
[Epoch 19, Batch 2700] loss: 0.021687718024880363
[Epoch 19, Batch 2800] loss: 0.012045486341816965
[Epoch 19, Batch 2900] loss: 0.01886279924337675
[Epoch 19, Batch 3000] loss: 0.02601830260549036
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0788
Validation Accuracy: 0.9834
Overfitting: 0.0788
[Epoch 20, Batch 100] loss: 0.010277783465097019
[Epoch 20, Batch 200] loss: 0.014881776321048434
[Epoch 20, Batch 300] loss: 0.025336738482886645
[Epoch 20, Batch 400] loss: 0.016652937150630973
[Epoch 20, Batch 500] loss: 0.006865794513953141
[Epoch 20, Batch 600] loss: 0.009003550964588625
[Epoch 20, Batch 700] loss: 0.007776430825845653
[Epoch 20, Batch 800] loss: 0.005233166298878667
[Epoch 20, Batch 900] loss: 0.008056998087915348
[Epoch 20, Batch 1000] loss: 0.02478252640767149
[Epoch 20, Batch 1100] loss: 0.018323026193182622
[Epoch 20, Batch 1200] loss: 0.009344821976121298
[Epoch 20, Batch 1300] loss: 0.015611243768621086
[Epoch 20, Batch 1400] loss: 0.008633478367951523
[Epoch 20, Batch 1500] loss: 0.0028766583240995747
[Epoch 20, Batch 1600] loss: 0.010628283556932714
[Epoch 20, Batch 1700] loss: 0.003298098952402153
[Epoch 20, Batch 1800] loss: 0.0028169578262495954
[Epoch 20, Batch 1900] loss: 0.010974383163181094
[Epoch 20, Batch 2000] loss: 0.012109860474621871
[Epoch 20, Batch 2100] loss: 0.010388982267933508
[Epoch 20, Batch 2200] loss: 0.0076576452811515415
[Epoch 20, Batch 2300] loss: 0.0015592436111046392
[Epoch 20, Batch 2400] loss: 0.024226924863134686
[Epoch 20, Batch 2500] loss: 0.011796466200853076
[Epoch 20, Batch 2600] loss: 0.013744022516665923
[Epoch 20, Batch 2700] loss: 0.013649714158389661
[Epoch 20, Batch 2800] loss: 0.018998283533758167
[Epoch 20, Batch 2900] loss: 0.027180370789174794
[Epoch 20, Batch 3000] loss: 0.028764401484358545
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0907
Validation Accuracy: 0.9862
Overfitting: 0.0907
[Epoch 21, Batch 100] loss: 0.005603042244665141
[Epoch 21, Batch 200] loss: 0.02532985897004396
[Epoch 21, Batch 300] loss: 0.01381631286261948
[Epoch 21, Batch 400] loss: 0.01243205805792388
[Epoch 21, Batch 500] loss: 0.011310101965659123
[Epoch 21, Batch 600] loss: 0.005033120647667944
[Epoch 21, Batch 700] loss: 0.014420054934227027
[Epoch 21, Batch 800] loss: 0.01729671912695116
[Epoch 21, Batch 900] loss: 0.006148219768721144
[Epoch 21, Batch 1000] loss: 0.015078370676304687
[Epoch 21, Batch 1100] loss: 0.006266411488048482
[Epoch 21, Batch 1200] loss: 0.008216523893749645
[Epoch 21, Batch 1300] loss: 0.02272480015757354
[Epoch 21, Batch 1400] loss: 0.046228805497445506
[Epoch 21, Batch 1500] loss: 0.018169487395704315
[Epoch 21, Batch 1600] loss: 0.0205184779696361
[Epoch 21, Batch 1700] loss: 0.02350744971394971
[Epoch 21, Batch 1800] loss: 0.016328155518848128
[Epoch 21, Batch 1900] loss: 0.0235297128839656
[Epoch 21, Batch 2000] loss: 0.04465663826293845
[Epoch 21, Batch 2100] loss: 0.00600396378888334
[Epoch 21, Batch 2200] loss: 0.009419204801551971
[Epoch 21, Batch 2300] loss: 0.0071597967761520345
[Epoch 21, Batch 2400] loss: 0.02275386262276121
[Epoch 21, Batch 2500] loss: 0.009846143092098166
[Epoch 21, Batch 2600] loss: 0.03666764965479104
[Epoch 21, Batch 2700] loss: 0.006763657295943398
[Epoch 21, Batch 2800] loss: 0.013841260416098802
[Epoch 21, Batch 2900] loss: 0.008476514907062511
[Epoch 21, Batch 3000] loss: 0.01142472590382741
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0575
Validation Accuracy: 0.9883
Overfitting: 0.0575
[Epoch 22, Batch 100] loss: 0.009145718773224716
[Epoch 22, Batch 200] loss: 0.018077295063111322
[Epoch 22, Batch 300] loss: 0.010513468137540354
[Epoch 22, Batch 400] loss: 0.009501168556353629
[Epoch 22, Batch 500] loss: 0.008679536272322994
[Epoch 22, Batch 600] loss: 0.005489541890254293
[Epoch 22, Batch 700] loss: 0.002540228816099086
[Epoch 22, Batch 800] loss: 0.01458784794461558
[Epoch 22, Batch 900] loss: 0.01520041650414143
[Epoch 22, Batch 1000] loss: 0.005829365873042818
[Epoch 22, Batch 1100] loss: 0.010632125361815646
[Epoch 22, Batch 1200] loss: 0.011810176397811576
[Epoch 22, Batch 1300] loss: 0.009114786171341378
[Epoch 22, Batch 1400] loss: 0.013926156201812385
[Epoch 22, Batch 1500] loss: 0.011248963381515532
[Epoch 22, Batch 1600] loss: 0.01709914834416107
[Epoch 22, Batch 1700] loss: 0.006316737835906547
[Epoch 22, Batch 1800] loss: 0.012097937508284527
[Epoch 22, Batch 1900] loss: 0.0028462501651341033
[Epoch 22, Batch 2000] loss: 0.009204193980706203
[Epoch 22, Batch 2100] loss: 0.01020872195176787
[Epoch 22, Batch 2200] loss: 0.007742595313025924
[Epoch 22, Batch 2300] loss: 0.011088475038041574
[Epoch 22, Batch 2400] loss: 0.007800647028181302
[Epoch 22, Batch 2500] loss: 0.0024707096491605983
[Epoch 22, Batch 2600] loss: 0.00903771720701986
[Epoch 22, Batch 2700] loss: 0.012917599370545653
[Epoch 22, Batch 2800] loss: 0.012827476464854142
[Epoch 22, Batch 2900] loss: 0.016908894986679125
[Epoch 22, Batch 3000] loss: 0.004957455788318974
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0782
Validation Accuracy: 0.9875
Overfitting: 0.0782
[Epoch 23, Batch 100] loss: 0.014180203180128829
[Epoch 23, Batch 200] loss: 0.01081527317203313
[Epoch 23, Batch 300] loss: 0.008310703169064158
[Epoch 23, Batch 400] loss: 0.0034697334955023475
[Epoch 23, Batch 500] loss: 0.01490310081806213
[Epoch 23, Batch 600] loss: 0.009292038452987837
[Epoch 23, Batch 700] loss: 0.010298476409275469
[Epoch 23, Batch 800] loss: 0.0072528557632192394
[Epoch 23, Batch 900] loss: 0.020254123741361787
[Epoch 23, Batch 1000] loss: 0.022740234076627636
[Epoch 23, Batch 1100] loss: 0.013626497019922872
[Epoch 23, Batch 1200] loss: 0.0032667109080787692
[Epoch 23, Batch 1300] loss: 0.012978050402985261
[Epoch 23, Batch 1400] loss: 0.008682513597415502
[Epoch 23, Batch 1500] loss: 0.0038522344378940907
[Epoch 23, Batch 1600] loss: 0.004810532938739378
[Epoch 23, Batch 1700] loss: 0.006944632465923571
[Epoch 23, Batch 1800] loss: 0.010633145577741034
[Epoch 23, Batch 1900] loss: 0.007344610756840631
[Epoch 23, Batch 2000] loss: 0.005347415297712268
[Epoch 23, Batch 2100] loss: 0.013458462223756582
[Epoch 23, Batch 2200] loss: 0.012801792844176485
[Epoch 23, Batch 2300] loss: 0.006875596879746015
[Epoch 23, Batch 2400] loss: 0.006706133880904046
[Epoch 23, Batch 2500] loss: 0.006903941640850158
[Epoch 23, Batch 2600] loss: 0.00518461819456411
[Epoch 23, Batch 2700] loss: 0.010790263532945281
[Epoch 23, Batch 2800] loss: 0.012546690673924377
[Epoch 23, Batch 2900] loss: 0.0050787285839431155
[Epoch 23, Batch 3000] loss: 0.015760451318805345
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0865
Validation Accuracy: 0.9850
Overfitting: 0.0865
[Epoch 24, Batch 100] loss: 0.005186329251672514
[Epoch 24, Batch 200] loss: 0.0007806124357612853
[Epoch 24, Batch 300] loss: 0.003175588217711125
[Epoch 24, Batch 400] loss: 0.0017695173078143922
[Epoch 24, Batch 500] loss: 0.0017879016215998967
[Epoch 24, Batch 600] loss: 0.006104408982180649
[Epoch 24, Batch 700] loss: 0.0029383702308043835
[Epoch 24, Batch 800] loss: 0.0023438515531104985
[Epoch 24, Batch 900] loss: 0.002290357878250209
[Epoch 24, Batch 1000] loss: 0.015856873883338167
[Epoch 24, Batch 1100] loss: 0.005494691877938917
[Epoch 24, Batch 1200] loss: 0.006701240937166233
[Epoch 24, Batch 1300] loss: 0.01864692989061575
[Epoch 24, Batch 1400] loss: 0.0097572024605335
[Epoch 24, Batch 1500] loss: 0.005170450993052622
[Epoch 24, Batch 1600] loss: 0.034310502795367265
[Epoch 24, Batch 1700] loss: 0.010295564341490758
[Epoch 24, Batch 1800] loss: 0.006616185058317558
[Epoch 24, Batch 1900] loss: 0.014897876272145614
[Epoch 24, Batch 2000] loss: 0.01446032303659341
[Epoch 24, Batch 2100] loss: 0.001984306405590357
[Epoch 24, Batch 2200] loss: 0.003461213094026312
[Epoch 24, Batch 2300] loss: 0.009154196382221058
[Epoch 24, Batch 2400] loss: 0.029611305421853477
[Epoch 24, Batch 2500] loss: 0.018779807660847494
[Epoch 24, Batch 2600] loss: 0.012820997865597454
[Epoch 24, Batch 2700] loss: 0.03621140356237761
[Epoch 24, Batch 2800] loss: 0.018512970379108356
[Epoch 24, Batch 2900] loss: 0.010493585156793857
[Epoch 24, Batch 3000] loss: 0.010765259898282866
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0759
Validation Accuracy: 0.9880
Overfitting: 0.0759
Fold 4 validation loss: 0.0759
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 1.9312906596064567
[Epoch 1, Batch 200] loss: 0.5528556161373853
[Epoch 1, Batch 300] loss: 0.3544895138218999
[Epoch 1, Batch 400] loss: 0.2576365396939218
[Epoch 1, Batch 500] loss: 0.23230093057267368
[Epoch 1, Batch 600] loss: 0.18079918185831048
[Epoch 1, Batch 700] loss: 0.15473295639269055
[Epoch 1, Batch 800] loss: 0.1911075503891334
[Epoch 1, Batch 900] loss: 0.14009580625686793
[Epoch 1, Batch 1000] loss: 0.15038246919983067
[Epoch 1, Batch 1100] loss: 0.13210834203287958
[Epoch 1, Batch 1200] loss: 0.15457031730329618
[Epoch 1, Batch 1300] loss: 0.1343997824273538
[Epoch 1, Batch 1400] loss: 0.11343669424997643
[Epoch 1, Batch 1500] loss: 0.15588374146493153
[Epoch 1, Batch 1600] loss: 0.12325039455834486
[Epoch 1, Batch 1700] loss: 0.13122497047879733
[Epoch 1, Batch 1800] loss: 0.12396898384671658
[Epoch 1, Batch 1900] loss: 0.0918175894212618
[Epoch 1, Batch 2000] loss: 0.12508816264977213
[Epoch 1, Batch 2100] loss: 0.09773320559761486
[Epoch 1, Batch 2200] loss: 0.06568452461666312
[Epoch 1, Batch 2300] loss: 0.09524993298749905
[Epoch 1, Batch 2400] loss: 0.08608931518043392
[Epoch 1, Batch 2500] loss: 0.08670363207405898
[Epoch 1, Batch 2600] loss: 0.07681712960416917
[Epoch 1, Batch 2700] loss: 0.07652645981012028
[Epoch 1, Batch 2800] loss: 0.07766853825567523
[Epoch 1, Batch 2900] loss: 0.08521827602475242
[Epoch 1, Batch 3000] loss: 0.08656588568119332
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0664
Validation Accuracy: 0.9804
Overfitting: 0.0664
Best model saved at epoch 1 with validation loss: 0.0664
[Epoch 2, Batch 100] loss: 0.07954768695752136
[Epoch 2, Batch 200] loss: 0.09256016386934789
[Epoch 2, Batch 300] loss: 0.05218657728379185
[Epoch 2, Batch 400] loss: 0.08985851721030486
[Epoch 2, Batch 500] loss: 0.09413120554701891
[Epoch 2, Batch 600] loss: 0.0628477968199877
[Epoch 2, Batch 700] loss: 0.06760171404050197
[Epoch 2, Batch 800] loss: 0.054727464436582524
[Epoch 2, Batch 900] loss: 0.08180733090965077
[Epoch 2, Batch 1000] loss: 0.07284143008087994
[Epoch 2, Batch 1100] loss: 0.06463275397836696
[Epoch 2, Batch 1200] loss: 0.07643364190589637
[Epoch 2, Batch 1300] loss: 0.061275339385611007
[Epoch 2, Batch 1400] loss: 0.059721742996043756
[Epoch 2, Batch 1500] loss: 0.056391074587882034
[Epoch 2, Batch 1600] loss: 0.0566557070192357
[Epoch 2, Batch 1700] loss: 0.07148561898153276
[Epoch 2, Batch 1800] loss: 0.048969415556057355
[Epoch 2, Batch 1900] loss: 0.04699331167270429
[Epoch 2, Batch 2000] loss: 0.07084503009173204
[Epoch 2, Batch 2100] loss: 0.06609773698786739
[Epoch 2, Batch 2200] loss: 0.07308139152737567
[Epoch 2, Batch 2300] loss: 0.07217454548110254
[Epoch 2, Batch 2400] loss: 0.05875216576037928
[Epoch 2, Batch 2500] loss: 0.05018945123229059
[Epoch 2, Batch 2600] loss: 0.045423253841509
[Epoch 2, Batch 2700] loss: 0.06331922418044997
[Epoch 2, Batch 2800] loss: 0.06022443582449341
[Epoch 2, Batch 2900] loss: 0.0703370023224852
[Epoch 2, Batch 3000] loss: 0.06484367776298314
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0762
Validation Accuracy: 0.9788
Overfitting: 0.0762
[Epoch 3, Batch 100] loss: 0.060296135751123074
[Epoch 3, Batch 200] loss: 0.05889788050699281
[Epoch 3, Batch 300] loss: 0.04453590494653326
[Epoch 3, Batch 400] loss: 0.050944803568418136
[Epoch 3, Batch 500] loss: 0.04092431763696368
[Epoch 3, Batch 600] loss: 0.038151843443301914
[Epoch 3, Batch 700] loss: 0.0617190560463132
[Epoch 3, Batch 800] loss: 0.05853531607419427
[Epoch 3, Batch 900] loss: 0.06140843372180825
[Epoch 3, Batch 1000] loss: 0.02242090460706095
[Epoch 3, Batch 1100] loss: 0.05838067547927494
[Epoch 3, Batch 1200] loss: 0.03776096311175934
[Epoch 3, Batch 1300] loss: 0.06176735564137743
[Epoch 3, Batch 1400] loss: 0.04366081274834869
[Epoch 3, Batch 1500] loss: 0.05302849284114927
[Epoch 3, Batch 1600] loss: 0.07065368714989745
[Epoch 3, Batch 1700] loss: 0.03926218065280409
[Epoch 3, Batch 1800] loss: 0.049207472946836785
[Epoch 3, Batch 1900] loss: 0.08319868803693681
[Epoch 3, Batch 2000] loss: 0.03825435106904479
[Epoch 3, Batch 2100] loss: 0.056483559377957133
[Epoch 3, Batch 2200] loss: 0.052339579599192804
[Epoch 3, Batch 2300] loss: 0.061224180982972026
[Epoch 3, Batch 2400] loss: 0.03199346744317154
[Epoch 3, Batch 2500] loss: 0.06156268647217075
[Epoch 3, Batch 2600] loss: 0.05497569817271142
[Epoch 3, Batch 2700] loss: 0.05128911049992894
[Epoch 3, Batch 2800] loss: 0.05786443830395001
[Epoch 3, Batch 2900] loss: 0.02693855883233482
[Epoch 3, Batch 3000] loss: 0.04140958358990701
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0614
Validation Accuracy: 0.9814
Overfitting: 0.0614
Best model saved at epoch 3 with validation loss: 0.0614
[Epoch 4, Batch 100] loss: 0.03636675519468554
[Epoch 4, Batch 200] loss: 0.0429203163891998
[Epoch 4, Batch 300] loss: 0.033905087327839284
[Epoch 4, Batch 400] loss: 0.026249175966877373
[Epoch 4, Batch 500] loss: 0.03420258678472237
[Epoch 4, Batch 600] loss: 0.054387963262743144
[Epoch 4, Batch 700] loss: 0.03897570607383386
[Epoch 4, Batch 800] loss: 0.02999597362890199
[Epoch 4, Batch 900] loss: 0.04316672127579295
[Epoch 4, Batch 1000] loss: 0.028212601888972132
[Epoch 4, Batch 1100] loss: 0.027264784245880948
[Epoch 4, Batch 1200] loss: 0.032814822472655575
[Epoch 4, Batch 1300] loss: 0.043956550575894655
[Epoch 4, Batch 1400] loss: 0.06742693406162288
[Epoch 4, Batch 1500] loss: 0.03601314301486127
[Epoch 4, Batch 1600] loss: 0.04978631697187666
[Epoch 4, Batch 1700] loss: 0.03688713564217323
[Epoch 4, Batch 1800] loss: 0.03844007767634139
[Epoch 4, Batch 1900] loss: 0.03143343051902775
[Epoch 4, Batch 2000] loss: 0.04872374973489059
[Epoch 4, Batch 2100] loss: 0.03940405194318373
[Epoch 4, Batch 2200] loss: 0.031119020515689044
[Epoch 4, Batch 2300] loss: 0.04909950018092786
[Epoch 4, Batch 2400] loss: 0.04174882299019373
[Epoch 4, Batch 2500] loss: 0.04665876227474655
[Epoch 4, Batch 2600] loss: 0.04936593440419529
[Epoch 4, Batch 2700] loss: 0.05135902430869464
[Epoch 4, Batch 2800] loss: 0.03601608365329412
[Epoch 4, Batch 2900] loss: 0.044910789739187745
[Epoch 4, Batch 3000] loss: 0.04313077928214625
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0375
Validation Accuracy: 0.9878
Overfitting: 0.0375
Best model saved at epoch 4 with validation loss: 0.0375
[Epoch 5, Batch 100] loss: 0.02400176127168379
[Epoch 5, Batch 200] loss: 0.02689663197070331
[Epoch 5, Batch 300] loss: 0.036992188139192875
[Epoch 5, Batch 400] loss: 0.02280517475292072
[Epoch 5, Batch 500] loss: 0.0457980111935467
[Epoch 5, Batch 600] loss: 0.039333840505387345
[Epoch 5, Batch 700] loss: 0.04179728946623072
[Epoch 5, Batch 800] loss: 0.045441795276274205
[Epoch 5, Batch 900] loss: 0.044756932062009584
[Epoch 5, Batch 1000] loss: 0.02359360861886216
[Epoch 5, Batch 1100] loss: 0.035823917299821914
[Epoch 5, Batch 1200] loss: 0.027112569969431205
[Epoch 5, Batch 1300] loss: 0.017183287817651945
[Epoch 5, Batch 1400] loss: 0.03455908054831525
[Epoch 5, Batch 1500] loss: 0.042200746560274636
[Epoch 5, Batch 1600] loss: 0.025980214527280623
[Epoch 5, Batch 1700] loss: 0.012226082724218941
[Epoch 5, Batch 1800] loss: 0.04092100668020066
[Epoch 5, Batch 1900] loss: 0.023138383859741225
[Epoch 5, Batch 2000] loss: 0.02132144267001422
[Epoch 5, Batch 2100] loss: 0.04176247763605716
[Epoch 5, Batch 2200] loss: 0.04417306000861572
[Epoch 5, Batch 2300] loss: 0.02062320744194949
[Epoch 5, Batch 2400] loss: 0.03268824983939339
[Epoch 5, Batch 2500] loss: 0.024954022687504674
[Epoch 5, Batch 2600] loss: 0.051602054329889596
[Epoch 5, Batch 2700] loss: 0.04566591673057701
[Epoch 5, Batch 2800] loss: 0.0460178138075571
[Epoch 5, Batch 2900] loss: 0.03926049872265139
[Epoch 5, Batch 3000] loss: 0.03784310186976654
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0365
Validation Accuracy: 0.9894
Overfitting: 0.0365
Best model saved at epoch 5 with validation loss: 0.0365
[Epoch 6, Batch 100] loss: 0.012365589911623828
[Epoch 6, Batch 200] loss: 0.02101396921550986
[Epoch 6, Batch 300] loss: 0.02811017767791782
[Epoch 6, Batch 400] loss: 0.013646069109463498
[Epoch 6, Batch 500] loss: 0.026149133208427884
[Epoch 6, Batch 600] loss: 0.01495472604684437
[Epoch 6, Batch 700] loss: 0.03298309322542082
[Epoch 6, Batch 800] loss: 0.02546324111781473
[Epoch 6, Batch 900] loss: 0.027633037109008
[Epoch 6, Batch 1000] loss: 0.029316360256379993
[Epoch 6, Batch 1100] loss: 0.01451364574643776
[Epoch 6, Batch 1200] loss: 0.024843145139625447
[Epoch 6, Batch 1300] loss: 0.031065078765495854
[Epoch 6, Batch 1400] loss: 0.040818270104100524
[Epoch 6, Batch 1500] loss: 0.028595961471764894
[Epoch 6, Batch 1600] loss: 0.025362894740419507
[Epoch 6, Batch 1700] loss: 0.0374055681588186
[Epoch 6, Batch 1800] loss: 0.06243445368368157
[Epoch 6, Batch 1900] loss: 0.02184669688613212
[Epoch 6, Batch 2000] loss: 0.026321393790603907
[Epoch 6, Batch 2100] loss: 0.01495231860969625
[Epoch 6, Batch 2200] loss: 0.03810081447158154
[Epoch 6, Batch 2300] loss: 0.04432814895668344
[Epoch 6, Batch 2400] loss: 0.013797874063875497
[Epoch 6, Batch 2500] loss: 0.01242352207830038
[Epoch 6, Batch 2600] loss: 0.05695392333715972
[Epoch 6, Batch 2700] loss: 0.032280414360566285
[Epoch 6, Batch 2800] loss: 0.03612609799945858
[Epoch 6, Batch 2900] loss: 0.030282177591470828
[Epoch 6, Batch 3000] loss: 0.042389977045231717
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0646
Validation Accuracy: 0.9837
Overfitting: 0.0646
[Epoch 7, Batch 100] loss: 0.02337160222267812
[Epoch 7, Batch 200] loss: 0.04452479396995841
[Epoch 7, Batch 300] loss: 0.023547044987426487
[Epoch 7, Batch 400] loss: 0.019592181882976546
[Epoch 7, Batch 500] loss: 0.027056317496223982
[Epoch 7, Batch 600] loss: 0.01935262060517971
[Epoch 7, Batch 700] loss: 0.012861256792193672
[Epoch 7, Batch 800] loss: 0.02959704127790701
[Epoch 7, Batch 900] loss: 0.024454664357895128
[Epoch 7, Batch 1000] loss: 0.033420176721222106
[Epoch 7, Batch 1100] loss: 0.033601924926997526
[Epoch 7, Batch 1200] loss: 0.03170428577458551
[Epoch 7, Batch 1300] loss: 0.02865641147102906
[Epoch 7, Batch 1400] loss: 0.02379981268102114
[Epoch 7, Batch 1500] loss: 0.026558543281586255
[Epoch 7, Batch 1600] loss: 0.02387553043947264
[Epoch 7, Batch 1700] loss: 0.020749062830602724
[Epoch 7, Batch 1800] loss: 0.02115752862387069
[Epoch 7, Batch 1900] loss: 0.027768857685359336
[Epoch 7, Batch 2000] loss: 0.022448797999863927
[Epoch 7, Batch 2100] loss: 0.03522298521500943
[Epoch 7, Batch 2200] loss: 0.024892411754626663
[Epoch 7, Batch 2300] loss: 0.021126796500343516
[Epoch 7, Batch 2400] loss: 0.028415563737016782
[Epoch 7, Batch 2500] loss: 0.04158961690889555
[Epoch 7, Batch 2600] loss: 0.021098015765028323
[Epoch 7, Batch 2700] loss: 0.028335165602720737
[Epoch 7, Batch 2800] loss: 0.026947546839592176
[Epoch 7, Batch 2900] loss: 0.015413233576555285
[Epoch 7, Batch 3000] loss: 0.023355020921162577
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0460
Validation Accuracy: 0.9882
Overfitting: 0.0460
[Epoch 8, Batch 100] loss: 0.021004226202876453
[Epoch 8, Batch 200] loss: 0.008479757794175384
[Epoch 8, Batch 300] loss: 0.026939422883405086
[Epoch 8, Batch 400] loss: 0.009363227589299186
[Epoch 8, Batch 500] loss: 0.009219747163493252
[Epoch 8, Batch 600] loss: 0.016863168857065604
[Epoch 8, Batch 700] loss: 0.02090608688992063
[Epoch 8, Batch 800] loss: 0.035273237631040504
[Epoch 8, Batch 900] loss: 0.014650738128841568
[Epoch 8, Batch 1000] loss: 0.012200736508605132
[Epoch 8, Batch 1100] loss: 0.019454197413797374
[Epoch 8, Batch 1200] loss: 0.04965600636045508
[Epoch 8, Batch 1300] loss: 0.03722155938110063
[Epoch 8, Batch 1400] loss: 0.028772878126333126
[Epoch 8, Batch 1500] loss: 0.05097436954652949
[Epoch 8, Batch 1600] loss: 0.03682595263187977
[Epoch 8, Batch 1700] loss: 0.013740798830690437
[Epoch 8, Batch 1800] loss: 0.03814997606796169
[Epoch 8, Batch 1900] loss: 0.011243034148949392
[Epoch 8, Batch 2000] loss: 0.02525266277112223
[Epoch 8, Batch 2100] loss: 0.015967533754648572
[Epoch 8, Batch 2200] loss: 0.030856143173327837
[Epoch 8, Batch 2300] loss: 0.02362879572182919
[Epoch 8, Batch 2400] loss: 0.014716493362536767
[Epoch 8, Batch 2500] loss: 0.014524436220095395
[Epoch 8, Batch 2600] loss: 0.033300148338666985
[Epoch 8, Batch 2700] loss: 0.03457214791332035
[Epoch 8, Batch 2800] loss: 0.020429111508960887
[Epoch 8, Batch 2900] loss: 0.031203714866860535
[Epoch 8, Batch 3000] loss: 0.022096426628911557
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0503
Validation Accuracy: 0.9877
Overfitting: 0.0503
[Epoch 9, Batch 100] loss: 0.009052727341362185
[Epoch 9, Batch 200] loss: 0.018861328217563766
[Epoch 9, Batch 300] loss: 0.014288117783728467
[Epoch 9, Batch 400] loss: 0.011880912875740961
[Epoch 9, Batch 500] loss: 0.02543350329701127
[Epoch 9, Batch 600] loss: 0.015080672541112108
[Epoch 9, Batch 700] loss: 0.023527643383004032
[Epoch 9, Batch 800] loss: 0.021453380013115295
[Epoch 9, Batch 900] loss: 0.026375565699236176
[Epoch 9, Batch 1000] loss: 0.014391553147581816
[Epoch 9, Batch 1100] loss: 0.013856998407682113
[Epoch 9, Batch 1200] loss: 0.02653766403483587
[Epoch 9, Batch 1300] loss: 0.022686750622727913
[Epoch 9, Batch 1400] loss: 0.016259334832891454
[Epoch 9, Batch 1500] loss: 0.03303483172911001
[Epoch 9, Batch 1600] loss: 0.023345931170941584
[Epoch 9, Batch 1700] loss: 0.025107799792592686
[Epoch 9, Batch 1800] loss: 0.01717234069564995
[Epoch 9, Batch 1900] loss: 0.028716157177411647
[Epoch 9, Batch 2000] loss: 0.027475576181485585
[Epoch 9, Batch 2100] loss: 0.011949645907547221
[Epoch 9, Batch 2200] loss: 0.03502486902388227
[Epoch 9, Batch 2300] loss: 0.016959135145893926
[Epoch 9, Batch 2400] loss: 0.025190102937233404
[Epoch 9, Batch 2500] loss: 0.024135900871565353
[Epoch 9, Batch 2600] loss: 0.011259442951222809
[Epoch 9, Batch 2700] loss: 0.030763855975505974
[Epoch 9, Batch 2800] loss: 0.015085424329880652
[Epoch 9, Batch 2900] loss: 0.024254876199642013
[Epoch 9, Batch 3000] loss: 0.024619517944534552
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0582
Validation Accuracy: 0.9852
Overfitting: 0.0582
[Epoch 10, Batch 100] loss: 0.020749072045254734
[Epoch 10, Batch 200] loss: 0.02634945046174664
[Epoch 10, Batch 300] loss: 0.01837222449673959
[Epoch 10, Batch 400] loss: 0.010290098690543346
[Epoch 10, Batch 500] loss: 0.029636169006628278
[Epoch 10, Batch 600] loss: 0.03147122625419115
[Epoch 10, Batch 700] loss: 0.021005735469091746
[Epoch 10, Batch 800] loss: 0.01712783159967785
[Epoch 10, Batch 900] loss: 0.017050862204197017
[Epoch 10, Batch 1000] loss: 0.03789998720766448
[Epoch 10, Batch 1100] loss: 0.024659422069830725
[Epoch 10, Batch 1200] loss: 0.02145281834725438
[Epoch 10, Batch 1300] loss: 0.03001437995437982
[Epoch 10, Batch 1400] loss: 0.0270079457008228
[Epoch 10, Batch 1500] loss: 0.020107829858020523
[Epoch 10, Batch 1600] loss: 0.01478713040203047
[Epoch 10, Batch 1700] loss: 0.03779199931787844
[Epoch 10, Batch 1800] loss: 0.03208733572042547
[Epoch 10, Batch 1900] loss: 0.029460815391623783
[Epoch 10, Batch 2000] loss: 0.02527702704865078
[Epoch 10, Batch 2100] loss: 0.02014146551700833
[Epoch 10, Batch 2200] loss: 0.014537224471582703
[Epoch 10, Batch 2300] loss: 0.020629681243563028
[Epoch 10, Batch 2400] loss: 0.010865995660137741
[Epoch 10, Batch 2500] loss: 0.010692847224047454
[Epoch 10, Batch 2600] loss: 0.00792099000950742
[Epoch 10, Batch 2700] loss: 0.0052016172261011165
[Epoch 10, Batch 2800] loss: 0.02779911850683497
[Epoch 10, Batch 2900] loss: 0.015000760943330818
[Epoch 10, Batch 3000] loss: 0.0227703630693847
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0621
Validation Accuracy: 0.9824
Overfitting: 0.0621
[Epoch 11, Batch 100] loss: 0.013271025441360962
[Epoch 11, Batch 200] loss: 0.013969688267945628
[Epoch 11, Batch 300] loss: 0.006165558948556509
[Epoch 11, Batch 400] loss: 0.005532863240412098
[Epoch 11, Batch 500] loss: 0.008776720527231134
[Epoch 11, Batch 600] loss: 0.027256579720218495
[Epoch 11, Batch 700] loss: 0.011462564052512505
[Epoch 11, Batch 800] loss: 0.008887798604146156
[Epoch 11, Batch 900] loss: 0.007785811883824038
[Epoch 11, Batch 1000] loss: 0.015645708753716007
[Epoch 11, Batch 1100] loss: 0.007256003042144243
[Epoch 11, Batch 1200] loss: 0.008981310932540225
[Epoch 11, Batch 1300] loss: 0.015257654757340049
[Epoch 11, Batch 1400] loss: 0.004754649875910317
[Epoch 11, Batch 1500] loss: 0.013468156830082876
[Epoch 11, Batch 1600] loss: 0.010015126397847851
[Epoch 11, Batch 1700] loss: 0.013054745703535674
[Epoch 11, Batch 1800] loss: 0.007849607047032947
[Epoch 11, Batch 1900] loss: 0.011040292555275921
[Epoch 11, Batch 2000] loss: 0.010628583046273406
[Epoch 11, Batch 2100] loss: 0.010298397185953396
[Epoch 11, Batch 2200] loss: 0.011119404309363787
[Epoch 11, Batch 2300] loss: 0.014891968144600441
[Epoch 11, Batch 2400] loss: 0.012510826591905548
[Epoch 11, Batch 2500] loss: 0.018965148059002176
[Epoch 11, Batch 2600] loss: 0.021152852220808427
[Epoch 11, Batch 2700] loss: 0.011076694123088373
[Epoch 11, Batch 2800] loss: 0.024277058716109537
[Epoch 11, Batch 2900] loss: 0.019900205033343353
[Epoch 11, Batch 3000] loss: 0.009885479691477598
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9879
Overfitting: 0.0511
[Epoch 12, Batch 100] loss: 0.00541358922297718
[Epoch 12, Batch 200] loss: 0.009203271737925718
[Epoch 12, Batch 300] loss: 0.008391384895526812
[Epoch 12, Batch 400] loss: 0.010059990258590825
[Epoch 12, Batch 500] loss: 0.034494497712106026
[Epoch 12, Batch 600] loss: 0.006344673758878799
[Epoch 12, Batch 700] loss: 0.013327595741860704
[Epoch 12, Batch 800] loss: 0.015937083152242338
[Epoch 12, Batch 900] loss: 0.007522528886295063
[Epoch 12, Batch 1000] loss: 0.007568833566872666
[Epoch 12, Batch 1100] loss: 0.012041572926423338
[Epoch 12, Batch 1200] loss: 0.02616919084858452
[Epoch 12, Batch 1300] loss: 0.026965643597539356
[Epoch 12, Batch 1400] loss: 0.013544545426564697
[Epoch 12, Batch 1500] loss: 0.010125047029758711
[Epoch 12, Batch 1600] loss: 0.010772972492137427
[Epoch 12, Batch 1700] loss: 0.034547760346956696
[Epoch 12, Batch 1800] loss: 0.005503877553864527
[Epoch 12, Batch 1900] loss: 0.005446519959571105
[Epoch 12, Batch 2000] loss: 0.011096141843800105
[Epoch 12, Batch 2100] loss: 0.009782206548726045
[Epoch 12, Batch 2200] loss: 0.04396938782615322
[Epoch 12, Batch 2300] loss: 0.018005519159366087
[Epoch 12, Batch 2400] loss: 0.026338028911716264
[Epoch 12, Batch 2500] loss: 0.016998230045209367
[Epoch 12, Batch 2600] loss: 0.009405871812951716
[Epoch 12, Batch 2700] loss: 0.00818991989670451
[Epoch 12, Batch 2800] loss: 0.011754917059937498
[Epoch 12, Batch 2900] loss: 0.008691575805175872
[Epoch 12, Batch 3000] loss: 0.006492087861134612
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9888
Overfitting: 0.0534
[Epoch 13, Batch 100] loss: 0.008154663602488767
[Epoch 13, Batch 200] loss: 0.01634964184798036
[Epoch 13, Batch 300] loss: 0.003965431242415285
[Epoch 13, Batch 400] loss: 0.0077895410363410635
[Epoch 13, Batch 500] loss: 0.011713004211340187
[Epoch 13, Batch 600] loss: 0.008436805793583772
[Epoch 13, Batch 700] loss: 0.0054313778491049906
[Epoch 13, Batch 800] loss: 0.005697394612703874
[Epoch 13, Batch 900] loss: 0.01048235130467745
[Epoch 13, Batch 1000] loss: 0.016595159882441646
[Epoch 13, Batch 1100] loss: 0.008799258406627644
[Epoch 13, Batch 1200] loss: 0.01909108930321814
[Epoch 13, Batch 1300] loss: 0.03128939746687706
[Epoch 13, Batch 1400] loss: 0.021273923726814133
[Epoch 13, Batch 1500] loss: 0.02782342475979533
[Epoch 13, Batch 1600] loss: 0.012735878751886389
[Epoch 13, Batch 1700] loss: 0.013571369544927875
[Epoch 13, Batch 1800] loss: 0.017691039376119874
[Epoch 13, Batch 1900] loss: 0.022497154716544402
[Epoch 13, Batch 2000] loss: 0.018710219846028053
[Epoch 13, Batch 2100] loss: 0.03071480382417164
[Epoch 13, Batch 2200] loss: 0.017042876108087624
[Epoch 13, Batch 2300] loss: 0.017396449125007506
[Epoch 13, Batch 2400] loss: 0.018990568206366448
[Epoch 13, Batch 2500] loss: 0.01323743666203967
[Epoch 13, Batch 2600] loss: 0.026182010215534318
[Epoch 13, Batch 2700] loss: 0.00871362172919362
[Epoch 13, Batch 2800] loss: 0.0092881111293201
[Epoch 13, Batch 2900] loss: 0.012739257822756932
[Epoch 13, Batch 3000] loss: 0.007880502775891212
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0547
Validation Accuracy: 0.9881
Overfitting: 0.0547
[Epoch 14, Batch 100] loss: 0.010306987271931689
[Epoch 14, Batch 200] loss: 0.0022918256453649376
[Epoch 14, Batch 300] loss: 0.015402058400657488
[Epoch 14, Batch 400] loss: 0.010112792434780502
[Epoch 14, Batch 500] loss: 0.01651207834215164
[Epoch 14, Batch 600] loss: 0.007344230631828168
[Epoch 14, Batch 700] loss: 0.01264334499868383
[Epoch 14, Batch 800] loss: 0.020354278196960673
[Epoch 14, Batch 900] loss: 0.03244428312741036
[Epoch 14, Batch 1000] loss: 0.021762626745061766
[Epoch 14, Batch 1100] loss: 0.009048438163291053
[Epoch 14, Batch 1200] loss: 0.010749197052362333
[Epoch 14, Batch 1300] loss: 0.006033303149455653
[Epoch 14, Batch 1400] loss: 0.010780013801506873
[Epoch 14, Batch 1500] loss: 0.023774835825636272
[Epoch 14, Batch 1600] loss: 0.02437755149730336
[Epoch 14, Batch 1700] loss: 0.024166760733153866
[Epoch 14, Batch 1800] loss: 0.015849900873145657
[Epoch 14, Batch 1900] loss: 0.025883371324439394
[Epoch 14, Batch 2000] loss: 0.013155482284809637
[Epoch 14, Batch 2100] loss: 0.024424303411349227
[Epoch 14, Batch 2200] loss: 0.020067055520186727
[Epoch 14, Batch 2300] loss: 0.019020989633590377
[Epoch 14, Batch 2400] loss: 0.016069157971893445
[Epoch 14, Batch 2500] loss: 0.016724536684727696
[Epoch 14, Batch 2600] loss: 0.013168674797336376
[Epoch 14, Batch 2700] loss: 0.011954575466707099
[Epoch 14, Batch 2800] loss: 0.01941798963573717
[Epoch 14, Batch 2900] loss: 0.01765571896781999
[Epoch 14, Batch 3000] loss: 0.01953792148623748
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9868
Overfitting: 0.0528
[Epoch 15, Batch 100] loss: 0.006044931972522107
[Epoch 15, Batch 200] loss: 0.02057144511804225
[Epoch 15, Batch 300] loss: 0.013650276902276054
[Epoch 15, Batch 400] loss: 0.01856942627713514
[Epoch 15, Batch 500] loss: 0.018408519552992716
[Epoch 15, Batch 600] loss: 0.005219527013067591
[Epoch 15, Batch 700] loss: 0.0026247769175251887
[Epoch 15, Batch 800] loss: 0.005218252863050093
[Epoch 15, Batch 900] loss: 0.010250118716621204
[Epoch 15, Batch 1000] loss: 0.017365110895700583
[Epoch 15, Batch 1100] loss: 0.015506770269954017
[Epoch 15, Batch 1200] loss: 0.023532942029790293
[Epoch 15, Batch 1300] loss: 0.015798644784579638
[Epoch 15, Batch 1400] loss: 0.02015853305373511
[Epoch 15, Batch 1500] loss: 0.04420971301620995
[Epoch 15, Batch 1600] loss: 0.018052418606946504
[Epoch 15, Batch 1700] loss: 0.009783393439809914
[Epoch 15, Batch 1800] loss: 0.020260397185065955
[Epoch 15, Batch 1900] loss: 0.01802365770014063
[Epoch 15, Batch 2000] loss: 0.016863914015237062
[Epoch 15, Batch 2100] loss: 0.009737975304652053
[Epoch 15, Batch 2200] loss: 0.013933936153010204
[Epoch 15, Batch 2300] loss: 0.02312733336108977
[Epoch 15, Batch 2400] loss: 0.02107979164041865
[Epoch 15, Batch 2500] loss: 0.00861613956990709
[Epoch 15, Batch 2600] loss: 0.006748225486452011
[Epoch 15, Batch 2700] loss: 0.025490631879749658
[Epoch 15, Batch 2800] loss: 0.017377901949994338
[Epoch 15, Batch 2900] loss: 0.0075739731346756226
[Epoch 15, Batch 3000] loss: 0.005388350287572621
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9888
Overfitting: 0.0560
[Epoch 16, Batch 100] loss: 0.007091790505837743
[Epoch 16, Batch 200] loss: 0.008577162651351982
[Epoch 16, Batch 300] loss: 0.0037240557588278022
[Epoch 16, Batch 400] loss: 0.012045825625001862
[Epoch 16, Batch 500] loss: 0.011185666095148292
[Epoch 16, Batch 600] loss: 0.014893871355011199
[Epoch 16, Batch 700] loss: 0.010239080778508871
[Epoch 16, Batch 800] loss: 0.012447432181054268
[Epoch 16, Batch 900] loss: 0.003283891631154461
[Epoch 16, Batch 1000] loss: 0.0034735671551288008
[Epoch 16, Batch 1100] loss: 0.009110054950994973
[Epoch 16, Batch 1200] loss: 0.017407231741222294
[Epoch 16, Batch 1300] loss: 0.013460691906867241
[Epoch 16, Batch 1400] loss: 0.025944071630163615
[Epoch 16, Batch 1500] loss: 0.01925642247989387
[Epoch 16, Batch 1600] loss: 0.012867745201476585
[Epoch 16, Batch 1700] loss: 0.00810695898597963
[Epoch 16, Batch 1800] loss: 0.005550237185210261
[Epoch 16, Batch 1900] loss: 0.0022185655234916624
[Epoch 16, Batch 2000] loss: 0.0020256811900128736
[Epoch 16, Batch 2100] loss: 0.014579682298569646
[Epoch 16, Batch 2200] loss: 0.01626187465829524
[Epoch 16, Batch 2300] loss: 0.007927677660075148
[Epoch 16, Batch 2400] loss: 0.009257166687745517
[Epoch 16, Batch 2500] loss: 0.006103074717270686
[Epoch 16, Batch 2600] loss: 0.007872097142584807
[Epoch 16, Batch 2700] loss: 0.0048829398540546935
[Epoch 16, Batch 2800] loss: 0.007760408098303695
[Epoch 16, Batch 2900] loss: 0.012581895413758483
[Epoch 16, Batch 3000] loss: 0.015780003483293132
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9888
Overfitting: 0.0606
[Epoch 17, Batch 100] loss: 0.017148987484611508
[Epoch 17, Batch 200] loss: 0.01552224244845945
[Epoch 17, Batch 300] loss: 0.03512691400201945
[Epoch 17, Batch 400] loss: 0.022696323989274278
[Epoch 17, Batch 500] loss: 0.005621298227525884
[Epoch 17, Batch 600] loss: 0.009802423235004624
[Epoch 17, Batch 700] loss: 0.020678150708581332
[Epoch 17, Batch 800] loss: 0.016163520921085136
[Epoch 17, Batch 900] loss: 0.01445765076624589
[Epoch 17, Batch 1000] loss: 0.009861694351569628
[Epoch 17, Batch 1100] loss: 0.022484961228429155
[Epoch 17, Batch 1200] loss: 0.014805274073133066
[Epoch 17, Batch 1300] loss: 0.016933306919674304
[Epoch 17, Batch 1400] loss: 0.021235500333421555
[Epoch 17, Batch 1500] loss: 0.009367663032755668
[Epoch 17, Batch 1600] loss: 0.03556473055068718
[Epoch 17, Batch 1700] loss: 0.013189628294827003
[Epoch 17, Batch 1800] loss: 0.013982088795028887
[Epoch 17, Batch 1900] loss: 0.03098215635681754
[Epoch 17, Batch 2000] loss: 0.020214052369216445
[Epoch 17, Batch 2100] loss: 0.02626472062499545
[Epoch 17, Batch 2200] loss: 0.012382863894816864
[Epoch 17, Batch 2300] loss: 0.009408158979979361
[Epoch 17, Batch 2400] loss: 0.012632361203291325
[Epoch 17, Batch 2500] loss: 0.009864488711225193
[Epoch 17, Batch 2600] loss: 0.009463928330526712
[Epoch 17, Batch 2700] loss: 0.007841753502173674
[Epoch 17, Batch 2800] loss: 0.01143481354276651
[Epoch 17, Batch 2900] loss: 0.0043026733970974096
[Epoch 17, Batch 3000] loss: 0.01596098233186259
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0598
Validation Accuracy: 0.9871
Overfitting: 0.0598
[Epoch 18, Batch 100] loss: 0.00842069540328673
[Epoch 18, Batch 200] loss: 0.006816803545029853
[Epoch 18, Batch 300] loss: 0.006770764024683959
[Epoch 18, Batch 400] loss: 0.007230885056074641
[Epoch 18, Batch 500] loss: 0.00897258799635531
[Epoch 18, Batch 600] loss: 0.01389662429607526
[Epoch 18, Batch 700] loss: 0.0045156869859422025
[Epoch 18, Batch 800] loss: 0.010067465636456335
[Epoch 18, Batch 900] loss: 0.0030792184024136214
[Epoch 18, Batch 1000] loss: 0.042498529769298854
[Epoch 18, Batch 1100] loss: 0.006824768596916275
[Epoch 18, Batch 1200] loss: 0.010696968582870295
[Epoch 18, Batch 1300] loss: 0.023219557641803234
[Epoch 18, Batch 1400] loss: 0.00579412210088492
[Epoch 18, Batch 1500] loss: 0.0014739565982250724
[Epoch 18, Batch 1600] loss: 0.016593205804376537
[Epoch 18, Batch 1700] loss: 0.03639998705422837
[Epoch 18, Batch 1800] loss: 0.023618313201177514
[Epoch 18, Batch 1900] loss: 0.013982783804445162
[Epoch 18, Batch 2000] loss: 0.03410437984815416
[Epoch 18, Batch 2100] loss: 0.037928550361062886
[Epoch 18, Batch 2200] loss: 0.039000364888662736
[Epoch 18, Batch 2300] loss: 0.018143239675429256
[Epoch 18, Batch 2400] loss: 0.00988545515643267
[Epoch 18, Batch 2500] loss: 0.01388313197540679
[Epoch 18, Batch 2600] loss: 0.01971448862524998
[Epoch 18, Batch 2700] loss: 0.023055447882730232
[Epoch 18, Batch 2800] loss: 0.013703040531073327
[Epoch 18, Batch 2900] loss: 0.010667151945356248
[Epoch 18, Batch 3000] loss: 0.021470768923712632
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0598
Validation Accuracy: 0.9876
Overfitting: 0.0598
[Epoch 19, Batch 100] loss: 0.013696144233861104
[Epoch 19, Batch 200] loss: 0.011285174095986289
[Epoch 19, Batch 300] loss: 0.004215006262543564
[Epoch 19, Batch 400] loss: 0.008624121462437264
[Epoch 19, Batch 500] loss: 0.00911749767874635
[Epoch 19, Batch 600] loss: 0.008255017597491374
[Epoch 19, Batch 700] loss: 0.018286630975919246
[Epoch 19, Batch 800] loss: 0.008863377229980708
[Epoch 19, Batch 900] loss: 0.02962251301675223
[Epoch 19, Batch 1000] loss: 0.00974967655340924
[Epoch 19, Batch 1100] loss: 0.00527676019658386
[Epoch 19, Batch 1200] loss: 0.010151797577078448
[Epoch 19, Batch 1300] loss: 0.0036955273934642817
[Epoch 19, Batch 1400] loss: 0.006030054039780879
[Epoch 19, Batch 1500] loss: 0.026397030756072522
[Epoch 19, Batch 1600] loss: 0.011384332193640887
[Epoch 19, Batch 1700] loss: 0.01582750637023494
[Epoch 19, Batch 1800] loss: 0.005261453744119722
[Epoch 19, Batch 1900] loss: 0.0036273214565490488
[Epoch 19, Batch 2000] loss: 0.010200250068265748
[Epoch 19, Batch 2100] loss: 0.005211986257174095
[Epoch 19, Batch 2200] loss: 0.013222997076166965
[Epoch 19, Batch 2300] loss: 0.010885569495782113
[Epoch 19, Batch 2400] loss: 0.007244840454827126
[Epoch 19, Batch 2500] loss: 0.009518106825872077
[Epoch 19, Batch 2600] loss: 0.019622627842566458
[Epoch 19, Batch 2700] loss: 0.012193912386780154
[Epoch 19, Batch 2800] loss: 0.017675554858486882
[Epoch 19, Batch 2900] loss: 0.015174148879183473
[Epoch 19, Batch 3000] loss: 0.007304381433896596
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0746
Validation Accuracy: 0.9869
Overfitting: 0.0746
[Epoch 20, Batch 100] loss: 0.014796249684868954
[Epoch 20, Batch 200] loss: 0.002018569243325152
[Epoch 20, Batch 300] loss: 0.0026895953304700584
[Epoch 20, Batch 400] loss: 0.003547896879768673
[Epoch 20, Batch 500] loss: 0.00473873878370966
[Epoch 20, Batch 600] loss: 0.0036476957491508744
[Epoch 20, Batch 700] loss: 0.009895867353820118
[Epoch 20, Batch 800] loss: 0.0234043811946091
[Epoch 20, Batch 900] loss: 0.00560501707207
[Epoch 20, Batch 1000] loss: 0.008173944510237287
[Epoch 20, Batch 1100] loss: 0.004073448988178416
[Epoch 20, Batch 1200] loss: 0.0014270531485132798
[Epoch 20, Batch 1300] loss: 0.002367201807248058
[Epoch 20, Batch 1400] loss: 0.006092867596248514
[Epoch 20, Batch 1500] loss: 0.0056461366936406375
[Epoch 20, Batch 1600] loss: 0.022753598320862232
[Epoch 20, Batch 1700] loss: 0.0070399864901934265
[Epoch 20, Batch 1800] loss: 0.021971359470178017
[Epoch 20, Batch 1900] loss: 0.010564521523177777
[Epoch 20, Batch 2000] loss: 0.01195015729102909
[Epoch 20, Batch 2100] loss: 0.004963446903635216
[Epoch 20, Batch 2200] loss: 0.014269577874038956
[Epoch 20, Batch 2300] loss: 0.007815437996645174
[Epoch 20, Batch 2400] loss: 0.008541722869950722
[Epoch 20, Batch 2500] loss: 0.010430236983059338
[Epoch 20, Batch 2600] loss: 0.014909798167063624
[Epoch 20, Batch 2700] loss: 0.005840213353784418
[Epoch 20, Batch 2800] loss: 0.01852629326797427
[Epoch 20, Batch 2900] loss: 0.02670992965266663
[Epoch 20, Batch 3000] loss: 0.029463637960725642
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0648
Validation Accuracy: 0.9872
Overfitting: 0.0648
[Epoch 21, Batch 100] loss: 0.0105934970124133
[Epoch 21, Batch 200] loss: 0.003966733026925482
[Epoch 21, Batch 300] loss: 0.012470454473741342
[Epoch 21, Batch 400] loss: 0.005553286387004377
[Epoch 21, Batch 500] loss: 0.005905869193197808
[Epoch 21, Batch 600] loss: 0.027384422347290424
[Epoch 21, Batch 700] loss: 0.02394656997030111
[Epoch 21, Batch 800] loss: 0.012078996258202891
[Epoch 21, Batch 900] loss: 0.002526449325452269
[Epoch 21, Batch 1000] loss: 0.024660886267989
[Epoch 21, Batch 1100] loss: 0.019750550852876626
[Epoch 21, Batch 1200] loss: 0.031092642922397006
[Epoch 21, Batch 1300] loss: 0.011984348590229814
[Epoch 21, Batch 1400] loss: 0.004372102948594545
[Epoch 21, Batch 1500] loss: 0.00468429702259622
[Epoch 21, Batch 1600] loss: 0.014496570145655596
[Epoch 21, Batch 1700] loss: 0.018988835432906616
[Epoch 21, Batch 1800] loss: 0.011185511064992574
[Epoch 21, Batch 1900] loss: 0.013202979459552169
[Epoch 21, Batch 2000] loss: 0.0042528014510484135
[Epoch 21, Batch 2100] loss: 0.009399414753343445
[Epoch 21, Batch 2200] loss: 0.010559449193511945
[Epoch 21, Batch 2300] loss: 0.010565448774347414
[Epoch 21, Batch 2400] loss: 0.023705019931199656
[Epoch 21, Batch 2500] loss: 0.043632370352297445
[Epoch 21, Batch 2600] loss: 0.012978397116099742
[Epoch 21, Batch 2700] loss: 0.0062026330693050365
[Epoch 21, Batch 2800] loss: 0.0019309126712590441
[Epoch 21, Batch 2900] loss: 0.005192889403326193
[Epoch 21, Batch 3000] loss: 0.001776454834589405
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0641
Validation Accuracy: 0.9889
Overfitting: 0.0641
[Epoch 22, Batch 100] loss: 0.008349504351899295
[Epoch 22, Batch 200] loss: 0.003330984805660089
[Epoch 22, Batch 300] loss: 0.01129241421356315
[Epoch 22, Batch 400] loss: 0.03507413463293353
[Epoch 22, Batch 500] loss: 0.007892467533980745
[Epoch 22, Batch 600] loss: 0.018794188758277982
[Epoch 22, Batch 700] loss: 0.012793177934693603
[Epoch 22, Batch 800] loss: 0.01662448394786192
[Epoch 22, Batch 900] loss: 0.008327840963414448
[Epoch 22, Batch 1000] loss: 0.010465866793143515
[Epoch 22, Batch 1100] loss: 0.005494687094721011
[Epoch 22, Batch 1200] loss: 0.010188229292351032
[Epoch 22, Batch 1300] loss: 0.013192855083363314
[Epoch 22, Batch 1400] loss: 0.01962485081743921
[Epoch 22, Batch 1500] loss: 0.011934315493171161
[Epoch 22, Batch 1600] loss: 0.039068585970496554
[Epoch 22, Batch 1700] loss: 0.011403812805231155
[Epoch 22, Batch 1800] loss: 0.0057695105360063255
[Epoch 22, Batch 1900] loss: 0.013135382494119198
[Epoch 22, Batch 2000] loss: 0.012660792177674835
[Epoch 22, Batch 2100] loss: 0.004838699516135545
[Epoch 22, Batch 2200] loss: 0.0061956531264423685
[Epoch 22, Batch 2300] loss: 0.01044287484489423
[Epoch 22, Batch 2400] loss: 0.01700069718241756
[Epoch 22, Batch 2500] loss: 0.0097061843788414
[Epoch 22, Batch 2600] loss: 0.006566422112133159
[Epoch 22, Batch 2700] loss: 0.0042936520982776024
[Epoch 22, Batch 2800] loss: 0.008347849987033027
[Epoch 22, Batch 2900] loss: 0.02046264713816196
[Epoch 22, Batch 3000] loss: 0.014372041884873737
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0772
Validation Accuracy: 0.9868
Overfitting: 0.0772
[Epoch 23, Batch 100] loss: 0.009242736648005562
[Epoch 23, Batch 200] loss: 0.026554052110757165
[Epoch 23, Batch 300] loss: 0.019112903601961634
[Epoch 23, Batch 400] loss: 0.008500467554061242
[Epoch 23, Batch 500] loss: 0.010678422375949102
[Epoch 23, Batch 600] loss: 0.0109063651971162
[Epoch 23, Batch 700] loss: 0.024976693588681088
[Epoch 23, Batch 800] loss: 0.009320832682214722
[Epoch 23, Batch 900] loss: 0.0009889211058353186
[Epoch 23, Batch 1000] loss: 0.004737027082569832
[Epoch 23, Batch 1100] loss: 0.009583640503027801
[Epoch 23, Batch 1200] loss: 0.020613882487425194
[Epoch 23, Batch 1300] loss: 0.024478520613797728
[Epoch 23, Batch 1400] loss: 0.030947766388937495
[Epoch 23, Batch 1500] loss: 0.03571986575334364
[Epoch 23, Batch 1600] loss: 0.02817219079121311
[Epoch 23, Batch 1700] loss: 0.021607677737941876
[Epoch 23, Batch 1800] loss: 0.008270693511533408
[Epoch 23, Batch 1900] loss: 0.009166927126157597
[Epoch 23, Batch 2000] loss: 0.011694683626104001
[Epoch 23, Batch 2100] loss: 0.011320326278268645
[Epoch 23, Batch 2200] loss: 0.015436116214372846
[Epoch 23, Batch 2300] loss: 0.0028403349004912436
[Epoch 23, Batch 2400] loss: 0.015135635717667623
[Epoch 23, Batch 2500] loss: 0.00978720422534023
[Epoch 23, Batch 2600] loss: 0.015331264238402621
[Epoch 23, Batch 2700] loss: 0.005863804597489555
[Epoch 23, Batch 2800] loss: 0.010409546774115114
[Epoch 23, Batch 2900] loss: 0.00792338527692836
[Epoch 23, Batch 3000] loss: 0.004062011344711496
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0738
Validation Accuracy: 0.9883
Overfitting: 0.0738
[Epoch 24, Batch 100] loss: 0.008287749873853535
[Epoch 24, Batch 200] loss: 0.011253020354457277
[Epoch 24, Batch 300] loss: 0.01685803182172555
[Epoch 24, Batch 400] loss: 0.018175458886719655
[Epoch 24, Batch 500] loss: 0.007308173577159205
[Epoch 24, Batch 600] loss: 0.014641380220328997
[Epoch 24, Batch 700] loss: 0.018387633899703538
[Epoch 24, Batch 800] loss: 0.007685545229995321
[Epoch 24, Batch 900] loss: 0.004921321721698386
[Epoch 24, Batch 1000] loss: 0.012897075250509347
[Epoch 24, Batch 1100] loss: 0.012636542538384612
[Epoch 24, Batch 1200] loss: 0.019698170231250395
[Epoch 24, Batch 1300] loss: 0.016733003846690745
[Epoch 24, Batch 1400] loss: 0.006915346221070844
[Epoch 24, Batch 1500] loss: 0.005513039092956604
[Epoch 24, Batch 1600] loss: 0.003520375907298927
[Epoch 24, Batch 1700] loss: 0.011058985717682388
[Epoch 24, Batch 1800] loss: 0.018152833051649147
[Epoch 24, Batch 1900] loss: 0.0038065925884553133
[Epoch 24, Batch 2000] loss: 0.0055272043208474874
[Epoch 24, Batch 2100] loss: 0.015230198277780094
[Epoch 24, Batch 2200] loss: 0.014743934323409275
[Epoch 24, Batch 2300] loss: 0.009232273427517814
[Epoch 24, Batch 2400] loss: 0.004963500461820174
[Epoch 24, Batch 2500] loss: 0.004037195666752718
[Epoch 24, Batch 2600] loss: 0.017676241301842893
[Epoch 24, Batch 2700] loss: 0.008990333466184781
[Epoch 24, Batch 2800] loss: 0.006897459377230408
[Epoch 24, Batch 2900] loss: 0.0016960127513629697
[Epoch 24, Batch 3000] loss: 0.0051929400301874385
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0653
Validation Accuracy: 0.9903
Overfitting: 0.0653
Fold 5 validation loss: 0.0653
Mean validation loss across all folds for Trial 4 is 0.0696 with trial config:  l1: 128, l2: 128, lr: 0.00853618986286683, batch_size: 16
[I 2024-12-11 02:17:05,242] Trial 3 finished with value: 0.06964804603608349 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.00853618986286683, 'batch_size': 16}. Best is trial 2 with value: 0.05047263894358398.

Selected Hyperparameters for Trial 5:
  l1: 256, l2: 128, lr: 0.00032927591344236165, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3008579277992247
[Epoch 1, Batch 200] loss: 2.292464337348938
[Epoch 1, Batch 300] loss: 2.2835876631736753
[Epoch 1, Batch 400] loss: 2.2689082527160647
[Epoch 1, Batch 500] loss: 2.2500671553611755
[Epoch 1, Batch 600] loss: 2.21469269990921
[Epoch 1, Batch 700] loss: 2.157820816040039
[Epoch 1, Batch 800] loss: 2.050366622209549
[Epoch 1, Batch 900] loss: 1.7786394679546356
[Epoch 1, Batch 1000] loss: 1.3999048173427582
[Epoch 1, Batch 1100] loss: 1.04222886800766
[Epoch 1, Batch 1200] loss: 0.8020177307724953
[Epoch 1, Batch 1300] loss: 0.6743045495450497
[Epoch 1, Batch 1400] loss: 0.6014492975175381
[Epoch 1, Batch 1500] loss: 0.5361012160778046
[Epoch 1, Batch 1600] loss: 0.4697624298930168
[Epoch 1, Batch 1700] loss: 0.5059336822479963
[Epoch 1, Batch 1800] loss: 0.4487528744339943
[Epoch 1, Batch 1900] loss: 0.4288059847056866
[Epoch 1, Batch 2000] loss: 0.416909219622612
[Epoch 1, Batch 2100] loss: 0.3974358706176281
[Epoch 1, Batch 2200] loss: 0.40780826907604933
[Epoch 1, Batch 2300] loss: 0.3406853458657861
[Epoch 1, Batch 2400] loss: 0.3436951997131109
[Epoch 1, Batch 2500] loss: 0.3027581181004643
[Epoch 1, Batch 2600] loss: 0.34491751484572886
[Epoch 1, Batch 2700] loss: 0.32508776552975177
[Epoch 1, Batch 2800] loss: 0.32087368950247763
[Epoch 1, Batch 2900] loss: 0.28538612136617303
[Epoch 1, Batch 3000] loss: 0.287980837225914
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2652
Validation Accuracy: 0.9203
Overfitting: 0.2652
Best model saved at epoch 1 with validation loss: 0.2652
[Epoch 2, Batch 100] loss: 0.25343131087720394
[Epoch 2, Batch 200] loss: 0.2535745274601504
[Epoch 2, Batch 300] loss: 0.25815064188092945
[Epoch 2, Batch 400] loss: 0.2212495608627796
[Epoch 2, Batch 500] loss: 0.21411240469664336
[Epoch 2, Batch 600] loss: 0.22409726545214653
[Epoch 2, Batch 700] loss: 0.22696594761684538
[Epoch 2, Batch 800] loss: 0.2382886249665171
[Epoch 2, Batch 900] loss: 0.23723909714259206
[Epoch 2, Batch 1000] loss: 0.2270245986059308
[Epoch 2, Batch 1100] loss: 0.19967289151623846
[Epoch 2, Batch 1200] loss: 0.22427329760044812
[Epoch 2, Batch 1300] loss: 0.2203902719542384
[Epoch 2, Batch 1400] loss: 0.18491846395656467
[Epoch 2, Batch 1500] loss: 0.2141003317013383
[Epoch 2, Batch 1600] loss: 0.18183094888925552
[Epoch 2, Batch 1700] loss: 0.20743513157591223
[Epoch 2, Batch 1800] loss: 0.17578016088344156
[Epoch 2, Batch 1900] loss: 0.1702832291647792
[Epoch 2, Batch 2000] loss: 0.19497438455466182
[Epoch 2, Batch 2100] loss: 0.16287467579357326
[Epoch 2, Batch 2200] loss: 0.19261722943745554
[Epoch 2, Batch 2300] loss: 0.1684220492374152
[Epoch 2, Batch 2400] loss: 0.22298760017380118
[Epoch 2, Batch 2500] loss: 0.1835635132621974
[Epoch 2, Batch 2600] loss: 0.16949874131008982
[Epoch 2, Batch 2700] loss: 0.16749217670876532
[Epoch 2, Batch 2800] loss: 0.1685775182209909
[Epoch 2, Batch 2900] loss: 0.15110999560914934
[Epoch 2, Batch 3000] loss: 0.1493994283862412
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1377
Validation Accuracy: 0.9578
Overfitting: 0.1377
Best model saved at epoch 2 with validation loss: 0.1377
[Epoch 3, Batch 100] loss: 0.14880393211729825
[Epoch 3, Batch 200] loss: 0.12288369468413293
[Epoch 3, Batch 300] loss: 0.12573818827979266
[Epoch 3, Batch 400] loss: 0.15537103787530213
[Epoch 3, Batch 500] loss: 0.1273367277602665
[Epoch 3, Batch 600] loss: 0.1805075727775693
[Epoch 3, Batch 700] loss: 0.14486984312534332
[Epoch 3, Batch 800] loss: 0.15199402417521923
[Epoch 3, Batch 900] loss: 0.11790351842995733
[Epoch 3, Batch 1000] loss: 0.13033417991362511
[Epoch 3, Batch 1100] loss: 0.13491210827138275
[Epoch 3, Batch 1200] loss: 0.13859259648248554
[Epoch 3, Batch 1300] loss: 0.09165557956323028
[Epoch 3, Batch 1400] loss: 0.14018440475687385
[Epoch 3, Batch 1500] loss: 0.12091144350357354
[Epoch 3, Batch 1600] loss: 0.11904486573301255
[Epoch 3, Batch 1700] loss: 0.1276495612319559
[Epoch 3, Batch 1800] loss: 0.11093913291115313
[Epoch 3, Batch 1900] loss: 0.13796014280524105
[Epoch 3, Batch 2000] loss: 0.11902938577346504
[Epoch 3, Batch 2100] loss: 0.12713789247907697
[Epoch 3, Batch 2200] loss: 0.09982986151240766
[Epoch 3, Batch 2300] loss: 0.1736327427299693
[Epoch 3, Batch 2400] loss: 0.12498060706770048
[Epoch 3, Batch 2500] loss: 0.11280679772607982
[Epoch 3, Batch 2600] loss: 0.13036752249579878
[Epoch 3, Batch 2700] loss: 0.13316370092332364
[Epoch 3, Batch 2800] loss: 0.11373881067149341
[Epoch 3, Batch 2900] loss: 0.12516972805839033
[Epoch 3, Batch 3000] loss: 0.10717964942101389
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1061
Validation Accuracy: 0.9677
Overfitting: 0.1061
Best model saved at epoch 3 with validation loss: 0.1061
[Epoch 4, Batch 100] loss: 0.09917669233167543
[Epoch 4, Batch 200] loss: 0.10049221911933273
[Epoch 4, Batch 300] loss: 0.0890700545348227
[Epoch 4, Batch 400] loss: 0.0845471009798348
[Epoch 4, Batch 500] loss: 0.11808491293806583
[Epoch 4, Batch 600] loss: 0.09566902257502079
[Epoch 4, Batch 700] loss: 0.10081260441802442
[Epoch 4, Batch 800] loss: 0.12760049504227935
[Epoch 4, Batch 900] loss: 0.1305718307523057
[Epoch 4, Batch 1000] loss: 0.09427553432062269
[Epoch 4, Batch 1100] loss: 0.10553581262007355
[Epoch 4, Batch 1200] loss: 0.10276697683148087
[Epoch 4, Batch 1300] loss: 0.10544496637769044
[Epoch 4, Batch 1400] loss: 0.0879222318995744
[Epoch 4, Batch 1500] loss: 0.0814702862733975
[Epoch 4, Batch 1600] loss: 0.09490975214168429
[Epoch 4, Batch 1700] loss: 0.09875205857912078
[Epoch 4, Batch 1800] loss: 0.10661941927624867
[Epoch 4, Batch 1900] loss: 0.12104633336886764
[Epoch 4, Batch 2000] loss: 0.08452888957224786
[Epoch 4, Batch 2100] loss: 0.1281452728714794
[Epoch 4, Batch 2200] loss: 0.09004237002925947
[Epoch 4, Batch 2300] loss: 0.08636953181121498
[Epoch 4, Batch 2400] loss: 0.0982283107494004
[Epoch 4, Batch 2500] loss: 0.08408087133197113
[Epoch 4, Batch 2600] loss: 0.09669732959009707
[Epoch 4, Batch 2700] loss: 0.09147365758195519
[Epoch 4, Batch 2800] loss: 0.0951996850525029
[Epoch 4, Batch 2900] loss: 0.10084281442686915
[Epoch 4, Batch 3000] loss: 0.08878378203138709
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0862
Validation Accuracy: 0.9732
Overfitting: 0.0862
Best model saved at epoch 4 with validation loss: 0.0862
[Epoch 5, Batch 100] loss: 0.08078788923099638
[Epoch 5, Batch 200] loss: 0.07754257401451468
[Epoch 5, Batch 300] loss: 0.10053533053142019
[Epoch 5, Batch 400] loss: 0.08094076455337927
[Epoch 5, Batch 500] loss: 0.07491279595065863
[Epoch 5, Batch 600] loss: 0.09320164041826501
[Epoch 5, Batch 700] loss: 0.10732584460754879
[Epoch 5, Batch 800] loss: 0.06643476512166671
[Epoch 5, Batch 900] loss: 0.07195487761404365
[Epoch 5, Batch 1000] loss: 0.06391775603871792
[Epoch 5, Batch 1100] loss: 0.09048447655222844
[Epoch 5, Batch 1200] loss: 0.06761670449399389
[Epoch 5, Batch 1300] loss: 0.09265581972664222
[Epoch 5, Batch 1400] loss: 0.08279545889468863
[Epoch 5, Batch 1500] loss: 0.10698085476527922
[Epoch 5, Batch 1600] loss: 0.07448706407565624
[Epoch 5, Batch 1700] loss: 0.09529132456285878
[Epoch 5, Batch 1800] loss: 0.07513855247525499
[Epoch 5, Batch 1900] loss: 0.07038372745504602
[Epoch 5, Batch 2000] loss: 0.0763330541504547
[Epoch 5, Batch 2100] loss: 0.0739005538332276
[Epoch 5, Batch 2200] loss: 0.08541441231733188
[Epoch 5, Batch 2300] loss: 0.06524198191182222
[Epoch 5, Batch 2400] loss: 0.06300185532774777
[Epoch 5, Batch 2500] loss: 0.0926924441952724
[Epoch 5, Batch 2600] loss: 0.09849534665117972
[Epoch 5, Batch 2700] loss: 0.08280106400954537
[Epoch 5, Batch 2800] loss: 0.07422209776239469
[Epoch 5, Batch 2900] loss: 0.0819462264550384
[Epoch 5, Batch 3000] loss: 0.0681352817080915
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0724
Validation Accuracy: 0.9768
Overfitting: 0.0724
Best model saved at epoch 5 with validation loss: 0.0724
[Epoch 6, Batch 100] loss: 0.06166960249887779
[Epoch 6, Batch 200] loss: 0.0783392746312893
[Epoch 6, Batch 300] loss: 0.08211098992265761
[Epoch 6, Batch 400] loss: 0.08640741257811896
[Epoch 6, Batch 500] loss: 0.0649886074126698
[Epoch 6, Batch 600] loss: 0.06416023672092706
[Epoch 6, Batch 700] loss: 0.07212008822243661
[Epoch 6, Batch 800] loss: 0.061690230204258116
[Epoch 6, Batch 900] loss: 0.08060981334187091
[Epoch 6, Batch 1000] loss: 0.07009173828992062
[Epoch 6, Batch 1100] loss: 0.07105903375922935
[Epoch 6, Batch 1200] loss: 0.056088974478188905
[Epoch 6, Batch 1300] loss: 0.05949590444215573
[Epoch 6, Batch 1400] loss: 0.06265787859854755
[Epoch 6, Batch 1500] loss: 0.06098003672785126
[Epoch 6, Batch 1600] loss: 0.061627304975991136
[Epoch 6, Batch 1700] loss: 0.07379067679052241
[Epoch 6, Batch 1800] loss: 0.05992691904131789
[Epoch 6, Batch 1900] loss: 0.08538772554136813
[Epoch 6, Batch 2000] loss: 0.08214902582578361
[Epoch 6, Batch 2100] loss: 0.07867891701636837
[Epoch 6, Batch 2200] loss: 0.052555574774742125
[Epoch 6, Batch 2300] loss: 0.06870863031828776
[Epoch 6, Batch 2400] loss: 0.06616882393020206
[Epoch 6, Batch 2500] loss: 0.0668434870429337
[Epoch 6, Batch 2600] loss: 0.06034413481364027
[Epoch 6, Batch 2700] loss: 0.07111169248179067
[Epoch 6, Batch 2800] loss: 0.06754270649864338
[Epoch 6, Batch 2900] loss: 0.06785382220288738
[Epoch 6, Batch 3000] loss: 0.05730687334784307
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0703
Validation Accuracy: 0.9782
Overfitting: 0.0703
Best model saved at epoch 6 with validation loss: 0.0703
[Epoch 7, Batch 100] loss: 0.058404833080712704
[Epoch 7, Batch 200] loss: 0.06402088023431134
[Epoch 7, Batch 300] loss: 0.06926612943061627
[Epoch 7, Batch 400] loss: 0.046274608185049144
[Epoch 7, Batch 500] loss: 0.061986538626952095
[Epoch 7, Batch 600] loss: 0.04103718575323
[Epoch 7, Batch 700] loss: 0.05075048818311188
[Epoch 7, Batch 800] loss: 0.0393895211306517
[Epoch 7, Batch 900] loss: 0.045973167314077724
[Epoch 7, Batch 1000] loss: 0.06832138877594844
[Epoch 7, Batch 1100] loss: 0.04842626876779832
[Epoch 7, Batch 1200] loss: 0.0684578759373835
[Epoch 7, Batch 1300] loss: 0.05746301829232834
[Epoch 7, Batch 1400] loss: 0.05232968357508071
[Epoch 7, Batch 1500] loss: 0.06184865723946132
[Epoch 7, Batch 1600] loss: 0.05993271617160644
[Epoch 7, Batch 1700] loss: 0.05651854514959268
[Epoch 7, Batch 1800] loss: 0.04902586613141466
[Epoch 7, Batch 1900] loss: 0.07458108088583686
[Epoch 7, Batch 2000] loss: 0.07779887635959312
[Epoch 7, Batch 2100] loss: 0.0618836506002117
[Epoch 7, Batch 2200] loss: 0.05665734127163887
[Epoch 7, Batch 2300] loss: 0.06665044657245744
[Epoch 7, Batch 2400] loss: 0.05388713458494749
[Epoch 7, Batch 2500] loss: 0.057650054937112144
[Epoch 7, Batch 2600] loss: 0.06800844404147938
[Epoch 7, Batch 2700] loss: 0.044098625057959
[Epoch 7, Batch 2800] loss: 0.06232005149591714
[Epoch 7, Batch 2900] loss: 0.06281419039005413
[Epoch 7, Batch 3000] loss: 0.07404574408952612
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0687
Validation Accuracy: 0.9778
Overfitting: 0.0687
Best model saved at epoch 7 with validation loss: 0.0687
[Epoch 8, Batch 100] loss: 0.05290567521005869
[Epoch 8, Batch 200] loss: 0.0445558500327752
[Epoch 8, Batch 300] loss: 0.05910823464539135
[Epoch 8, Batch 400] loss: 0.04965333277359605
[Epoch 8, Batch 500] loss: 0.0705432697525248
[Epoch 8, Batch 600] loss: 0.054721605823142457
[Epoch 8, Batch 700] loss: 0.06155888128618244
[Epoch 8, Batch 800] loss: 0.04976543018477969
[Epoch 8, Batch 900] loss: 0.0628281889623031
[Epoch 8, Batch 1000] loss: 0.04524328296538442
[Epoch 8, Batch 1100] loss: 0.040989065815520004
[Epoch 8, Batch 1200] loss: 0.03772286313818768
[Epoch 8, Batch 1300] loss: 0.05012860273767728
[Epoch 8, Batch 1400] loss: 0.047806392450002025
[Epoch 8, Batch 1500] loss: 0.042656049184734
[Epoch 8, Batch 1600] loss: 0.07622075770195806
[Epoch 8, Batch 1700] loss: 0.04478459641628433
[Epoch 8, Batch 1800] loss: 0.03597090256866067
[Epoch 8, Batch 1900] loss: 0.07644030538853258
[Epoch 8, Batch 2000] loss: 0.053911563702276906
[Epoch 8, Batch 2100] loss: 0.03912600252195261
[Epoch 8, Batch 2200] loss: 0.06842607114347629
[Epoch 8, Batch 2300] loss: 0.049550891693797894
[Epoch 8, Batch 2400] loss: 0.04273094409843907
[Epoch 8, Batch 2500] loss: 0.044679392459802326
[Epoch 8, Batch 2600] loss: 0.05890475336491363
[Epoch 8, Batch 2700] loss: 0.04364604894130025
[Epoch 8, Batch 2800] loss: 0.058542109326808714
[Epoch 8, Batch 2900] loss: 0.06189961785683409
[Epoch 8, Batch 3000] loss: 0.05269536825391697
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0578
Validation Accuracy: 0.9812
Overfitting: 0.0578
Best model saved at epoch 8 with validation loss: 0.0578
[Epoch 9, Batch 100] loss: 0.04372452939365758
[Epoch 9, Batch 200] loss: 0.05237905123271048
[Epoch 9, Batch 300] loss: 0.05316120564879384
[Epoch 9, Batch 400] loss: 0.03956199745822232
[Epoch 9, Batch 500] loss: 0.05629952509800205
[Epoch 9, Batch 600] loss: 0.048446882694261145
[Epoch 9, Batch 700] loss: 0.04050714406883344
[Epoch 9, Batch 800] loss: 0.06893461935105734
[Epoch 9, Batch 900] loss: 0.04642010159790516
[Epoch 9, Batch 1000] loss: 0.04278711149672745
[Epoch 9, Batch 1100] loss: 0.04152973711199593
[Epoch 9, Batch 1200] loss: 0.046649553668685256
[Epoch 9, Batch 1300] loss: 0.05589484691969119
[Epoch 9, Batch 1400] loss: 0.04027679133287165
[Epoch 9, Batch 1500] loss: 0.028754575134371407
[Epoch 9, Batch 1600] loss: 0.04031793337708223
[Epoch 9, Batch 1700] loss: 0.05560756269231206
[Epoch 9, Batch 1800] loss: 0.04110787911718944
[Epoch 9, Batch 1900] loss: 0.054084837347618306
[Epoch 9, Batch 2000] loss: 0.06093261720030568
[Epoch 9, Batch 2100] loss: 0.03969978923312738
[Epoch 9, Batch 2200] loss: 0.03802394878643099
[Epoch 9, Batch 2300] loss: 0.05273263833223609
[Epoch 9, Batch 2400] loss: 0.03633533996384358
[Epoch 9, Batch 2500] loss: 0.0237046551896492
[Epoch 9, Batch 2600] loss: 0.0427019620250212
[Epoch 9, Batch 2700] loss: 0.04325184592511505
[Epoch 9, Batch 2800] loss: 0.0518479928909801
[Epoch 9, Batch 2900] loss: 0.05440589091333095
[Epoch 9, Batch 3000] loss: 0.05616198697767686
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9828
Overfitting: 0.0554
[I 2024-12-11 02:19:19,930] Trial 4 pruned. 

Selected Hyperparameters for Trial 6:
  l1: 128, l2: 64, lr: 0.0015696396388661157, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.286041171550751
[Epoch 1, Batch 200] loss: 2.1418050122261048
[Epoch 1, Batch 300] loss: 1.1319414332509041
[Epoch 1, Batch 400] loss: 0.6089723283052444
[Epoch 1, Batch 500] loss: 0.488574607744813
[Epoch 1, Batch 600] loss: 0.425347193479538
[Epoch 1, Batch 700] loss: 0.3652117356285453
[Epoch 1, Batch 800] loss: 0.26218201231211424
[Epoch 1, Batch 900] loss: 0.28708152497187256
[Epoch 1, Batch 1000] loss: 0.25090358113870026
[Epoch 1, Batch 1100] loss: 0.24549294590950013
[Epoch 1, Batch 1200] loss: 0.20963311672210694
[Epoch 1, Batch 1300] loss: 0.19872179115191102
[Epoch 1, Batch 1400] loss: 0.22195699848234654
[Epoch 1, Batch 1500] loss: 0.2156467070663348
[Epoch 1, Batch 1600] loss: 0.1732300179125741
[Epoch 1, Batch 1700] loss: 0.15895360284484922
[Epoch 1, Batch 1800] loss: 0.15402260507456958
[Epoch 1, Batch 1900] loss: 0.1671336881350726
[Epoch 1, Batch 2000] loss: 0.15087337536737322
[Epoch 1, Batch 2100] loss: 0.15232595543842764
[Epoch 1, Batch 2200] loss: 0.12428540871245787
[Epoch 1, Batch 2300] loss: 0.12280114405788481
[Epoch 1, Batch 2400] loss: 0.14381419090321287
[Epoch 1, Batch 2500] loss: 0.12231901486869902
[Epoch 1, Batch 2600] loss: 0.11792887612245977
[Epoch 1, Batch 2700] loss: 0.10510774123482407
[Epoch 1, Batch 2800] loss: 0.1317213242035359
[Epoch 1, Batch 2900] loss: 0.13092357656918466
[Epoch 1, Batch 3000] loss: 0.10059130372246727
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1062
Validation Accuracy: 0.9659
Overfitting: 0.1062
Best model saved at epoch 1 with validation loss: 0.1062
[Epoch 2, Batch 100] loss: 0.1267080605099909
[Epoch 2, Batch 200] loss: 0.08196445556590333
[Epoch 2, Batch 300] loss: 0.08401746655348688
[Epoch 2, Batch 400] loss: 0.11062870347639546
[Epoch 2, Batch 500] loss: 0.09016407128539868
[Epoch 2, Batch 600] loss: 0.0969502529304009
[Epoch 2, Batch 700] loss: 0.07737466474762186
[Epoch 2, Batch 800] loss: 0.07793517241021618
[Epoch 2, Batch 900] loss: 0.11482986403745599
[Epoch 2, Batch 1000] loss: 0.10277677009580657
[Epoch 2, Batch 1100] loss: 0.09230471346643754
[Epoch 2, Batch 1200] loss: 0.08336160930339247
[Epoch 2, Batch 1300] loss: 0.08980065096868202
[Epoch 2, Batch 1400] loss: 0.09547306963882875
[Epoch 2, Batch 1500] loss: 0.10348034238908439
[Epoch 2, Batch 1600] loss: 0.0985399732668884
[Epoch 2, Batch 1700] loss: 0.08026680957060307
[Epoch 2, Batch 1800] loss: 0.09492079781426582
[Epoch 2, Batch 1900] loss: 0.08205754389055073
[Epoch 2, Batch 2000] loss: 0.11512755392934196
[Epoch 2, Batch 2100] loss: 0.10329942623502575
[Epoch 2, Batch 2200] loss: 0.07989649692783132
[Epoch 2, Batch 2300] loss: 0.07276814439566806
[Epoch 2, Batch 2400] loss: 0.09691985977697186
[Epoch 2, Batch 2500] loss: 0.06056036189431325
[Epoch 2, Batch 2600] loss: 0.0705205214698799
[Epoch 2, Batch 2700] loss: 0.065049201589718
[Epoch 2, Batch 2800] loss: 0.0958115725684911
[Epoch 2, Batch 2900] loss: 0.06111437531420961
[Epoch 2, Batch 3000] loss: 0.08307321431289892
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0685
Validation Accuracy: 0.9778
Overfitting: 0.0685
Best model saved at epoch 2 with validation loss: 0.0685
[Epoch 3, Batch 100] loss: 0.06740008112275973
[Epoch 3, Batch 200] loss: 0.07483538744738326
[Epoch 3, Batch 300] loss: 0.05883254777058028
[Epoch 3, Batch 400] loss: 0.06279412078205496
[Epoch 3, Batch 500] loss: 0.05700701214489527
[Epoch 3, Batch 600] loss: 0.06671145474887454
[Epoch 3, Batch 700] loss: 0.062469071485102175
[Epoch 3, Batch 800] loss: 0.07661928653076756
[Epoch 3, Batch 900] loss: 0.05519076418335317
[Epoch 3, Batch 1000] loss: 0.04669464817212429
[Epoch 3, Batch 1100] loss: 0.07417424250976183
[Epoch 3, Batch 1200] loss: 0.0729124697583029
[Epoch 3, Batch 1300] loss: 0.05306503867206629
[Epoch 3, Batch 1400] loss: 0.08116078273509629
[Epoch 3, Batch 1500] loss: 0.05655868322297465
[Epoch 3, Batch 1600] loss: 0.05911189965030644
[Epoch 3, Batch 1700] loss: 0.06772949412203161
[Epoch 3, Batch 1800] loss: 0.06419585900148377
[Epoch 3, Batch 1900] loss: 0.05378088323166594
[Epoch 3, Batch 2000] loss: 0.07190330198907759
[Epoch 3, Batch 2100] loss: 0.06057959379570093
[Epoch 3, Batch 2200] loss: 0.06406059173459652
[Epoch 3, Batch 2300] loss: 0.08166018672578503
[Epoch 3, Batch 2400] loss: 0.06306465682107955
[Epoch 3, Batch 2500] loss: 0.0723990489647258
[Epoch 3, Batch 2600] loss: 0.0711371598248661
[Epoch 3, Batch 2700] loss: 0.05688469360698946
[Epoch 3, Batch 2800] loss: 0.043592110365862025
[Epoch 3, Batch 2900] loss: 0.04794265744887525
[Epoch 3, Batch 3000] loss: 0.062207481625227955
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0545
Validation Accuracy: 0.9829
Overfitting: 0.0545
Best model saved at epoch 3 with validation loss: 0.0545
[Epoch 4, Batch 100] loss: 0.03873710414278321
[Epoch 4, Batch 200] loss: 0.0677501683367882
[Epoch 4, Batch 300] loss: 0.0619683697813889
[Epoch 4, Batch 400] loss: 0.048476392131560714
[Epoch 4, Batch 500] loss: 0.05198047484271228
[Epoch 4, Batch 600] loss: 0.053475025482475756
[Epoch 4, Batch 700] loss: 0.0574815561863943
[Epoch 4, Batch 800] loss: 0.03953867601871025
[Epoch 4, Batch 900] loss: 0.04835333651106339
[Epoch 4, Batch 1000] loss: 0.041777037223801015
[Epoch 4, Batch 1100] loss: 0.04538126383384224
[Epoch 4, Batch 1200] loss: 0.04416255708958488
[Epoch 4, Batch 1300] loss: 0.03563871277612634
[Epoch 4, Batch 1400] loss: 0.059678488908248256
[Epoch 4, Batch 1500] loss: 0.04818972956374637
[Epoch 4, Batch 1600] loss: 0.03673428091482492
[Epoch 4, Batch 1700] loss: 0.05385400623461464
[Epoch 4, Batch 1800] loss: 0.035597558192821455
[Epoch 4, Batch 1900] loss: 0.06206637954266626
[Epoch 4, Batch 2000] loss: 0.053261157931992785
[Epoch 4, Batch 2100] loss: 0.06525646694499301
[Epoch 4, Batch 2200] loss: 0.04763432239269605
[Epoch 4, Batch 2300] loss: 0.0621906831569504
[Epoch 4, Batch 2400] loss: 0.07183272344147554
[Epoch 4, Batch 2500] loss: 0.04712175017688423
[Epoch 4, Batch 2600] loss: 0.039007870976347475
[Epoch 4, Batch 2700] loss: 0.03871353790142166
[Epoch 4, Batch 2800] loss: 0.036573851726570863
[Epoch 4, Batch 2900] loss: 0.048259644382051194
[Epoch 4, Batch 3000] loss: 0.04795045213424601
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9839
Overfitting: 0.0494
Best model saved at epoch 4 with validation loss: 0.0494
[Epoch 5, Batch 100] loss: 0.05136551865216461
[Epoch 5, Batch 200] loss: 0.03798700880302931
[Epoch 5, Batch 300] loss: 0.040842897016264035
[Epoch 5, Batch 400] loss: 0.04196664440547465
[Epoch 5, Batch 500] loss: 0.029710359801647428
[Epoch 5, Batch 600] loss: 0.044968392311566276
[Epoch 5, Batch 700] loss: 0.034972944814071524
[Epoch 5, Batch 800] loss: 0.05328960182057926
[Epoch 5, Batch 900] loss: 0.03752178934402764
[Epoch 5, Batch 1000] loss: 0.031034878705977462
[Epoch 5, Batch 1100] loss: 0.046999117287341505
[Epoch 5, Batch 1200] loss: 0.03324401833102456
[Epoch 5, Batch 1300] loss: 0.050423246641512376
[Epoch 5, Batch 1400] loss: 0.04588020924391458
[Epoch 5, Batch 1500] loss: 0.039035931626713136
[Epoch 5, Batch 1600] loss: 0.029673651365592378
[Epoch 5, Batch 1700] loss: 0.0427405775868101
[Epoch 5, Batch 1800] loss: 0.03219142716108763
[Epoch 5, Batch 1900] loss: 0.04383058220053499
[Epoch 5, Batch 2000] loss: 0.022329764085297937
[Epoch 5, Batch 2100] loss: 0.052910738443024456
[Epoch 5, Batch 2200] loss: 0.04914484003209509
[Epoch 5, Batch 2300] loss: 0.04197757885660394
[Epoch 5, Batch 2400] loss: 0.048030869187932694
[Epoch 5, Batch 2500] loss: 0.056651397993264255
[Epoch 5, Batch 2600] loss: 0.0371186847233912
[Epoch 5, Batch 2700] loss: 0.0426595406117849
[Epoch 5, Batch 2800] loss: 0.03503293103771284
[Epoch 5, Batch 2900] loss: 0.029916319343901706
[Epoch 5, Batch 3000] loss: 0.040135345160815634
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9867
Overfitting: 0.0459
Best model saved at epoch 5 with validation loss: 0.0459
[Epoch 6, Batch 100] loss: 0.023691509147174657
[Epoch 6, Batch 200] loss: 0.02045390569317533
[Epoch 6, Batch 300] loss: 0.034218118097414846
[Epoch 6, Batch 400] loss: 0.030111913871514843
[Epoch 6, Batch 500] loss: 0.021675504258637374
[Epoch 6, Batch 600] loss: 0.04210249340336304
[Epoch 6, Batch 700] loss: 0.03629719155098428
[Epoch 6, Batch 800] loss: 0.02869232855955488
[Epoch 6, Batch 900] loss: 0.022903789022384446
[Epoch 6, Batch 1000] loss: 0.03481563941564673
[Epoch 6, Batch 1100] loss: 0.0385913480164163
[Epoch 6, Batch 1200] loss: 0.026447972560417837
[Epoch 6, Batch 1300] loss: 0.04521617204587528
[Epoch 6, Batch 1400] loss: 0.04261673394285026
[Epoch 6, Batch 1500] loss: 0.032242602862570496
[Epoch 6, Batch 1600] loss: 0.04060808411362814
[Epoch 6, Batch 1700] loss: 0.03749150447925786
[Epoch 6, Batch 1800] loss: 0.036109008606581484
[Epoch 6, Batch 1900] loss: 0.03215250531997299
[Epoch 6, Batch 2000] loss: 0.04122252456407296
[Epoch 6, Batch 2100] loss: 0.026417735119539428
[Epoch 6, Batch 2200] loss: 0.045506011378820405
[Epoch 6, Batch 2300] loss: 0.027072041831270325
[Epoch 6, Batch 2400] loss: 0.03434889844727877
[Epoch 6, Batch 2500] loss: 0.040603098210922325
[Epoch 6, Batch 2600] loss: 0.037624776863449366
[Epoch 6, Batch 2700] loss: 0.030993114602606512
[Epoch 6, Batch 2800] loss: 0.034193171407750925
[Epoch 6, Batch 2900] loss: 0.03294757136522094
[Epoch 6, Batch 3000] loss: 0.027740016570169244
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9847
Overfitting: 0.0520
[Epoch 7, Batch 100] loss: 0.025209666550072143
[Epoch 7, Batch 200] loss: 0.028340453948912908
[Epoch 7, Batch 300] loss: 0.03239116305092466
[Epoch 7, Batch 400] loss: 0.03817880484988564
[Epoch 7, Batch 500] loss: 0.031207640253051068
[Epoch 7, Batch 600] loss: 0.017788571508026506
[Epoch 7, Batch 700] loss: 0.01872545960410207
[Epoch 7, Batch 800] loss: 0.031611656952718475
[Epoch 7, Batch 900] loss: 0.028900142377497103
[Epoch 7, Batch 1000] loss: 0.02038956570417213
[Epoch 7, Batch 1100] loss: 0.03469200220250059
[Epoch 7, Batch 1200] loss: 0.022242681293937493
[Epoch 7, Batch 1300] loss: 0.026299883376414073
[Epoch 7, Batch 1400] loss: 0.02935315886297758
[Epoch 7, Batch 1500] loss: 0.03154968446411658
[Epoch 7, Batch 1600] loss: 0.02078988313463924
[Epoch 7, Batch 1700] loss: 0.02771871957942494
[Epoch 7, Batch 1800] loss: 0.02349623118308955
[Epoch 7, Batch 1900] loss: 0.021508928374132666
[Epoch 7, Batch 2000] loss: 0.02415208750982856
[Epoch 7, Batch 2100] loss: 0.03660400366647082
[Epoch 7, Batch 2200] loss: 0.030548890269892583
[Epoch 7, Batch 2300] loss: 0.021008906677088816
[Epoch 7, Batch 2400] loss: 0.027231370067929674
[Epoch 7, Batch 2500] loss: 0.026790274326904184
[Epoch 7, Batch 2600] loss: 0.04236499931081198
[Epoch 7, Batch 2700] loss: 0.03318779317709414
[Epoch 7, Batch 2800] loss: 0.038621856252939325
[Epoch 7, Batch 2900] loss: 0.037694262186414564
[Epoch 7, Batch 3000] loss: 0.023676197652275733
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0587
Validation Accuracy: 0.9849
Overfitting: 0.0587
[Epoch 8, Batch 100] loss: 0.023223979583781328
[Epoch 8, Batch 200] loss: 0.018358451510430314
[Epoch 8, Batch 300] loss: 0.0187643456868318
[Epoch 8, Batch 400] loss: 0.03601868595589622
[Epoch 8, Batch 500] loss: 0.022134920919343132
[Epoch 8, Batch 600] loss: 0.03154040705449006
[Epoch 8, Batch 700] loss: 0.022205492136527026
[Epoch 8, Batch 800] loss: 0.019586837893784834
[Epoch 8, Batch 900] loss: 0.023118179488228634
[Epoch 8, Batch 1000] loss: 0.01424819656946056
[Epoch 8, Batch 1100] loss: 0.02240215788489877
[Epoch 8, Batch 1200] loss: 0.03094961613597661
[Epoch 8, Batch 1300] loss: 0.023739820440059702
[Epoch 8, Batch 1400] loss: 0.01556566182000097
[Epoch 8, Batch 1500] loss: 0.024050896765256766
[Epoch 8, Batch 1600] loss: 0.0242500705600105
[Epoch 8, Batch 1700] loss: 0.0330382216331418
[Epoch 8, Batch 1800] loss: 0.01968554288452651
[Epoch 8, Batch 1900] loss: 0.016539492099509515
[Epoch 8, Batch 2000] loss: 0.02558420665889571
[Epoch 8, Batch 2100] loss: 0.043036309261688076
[Epoch 8, Batch 2200] loss: 0.02776361695447122
[Epoch 8, Batch 2300] loss: 0.026849547041856568
[Epoch 8, Batch 2400] loss: 0.03929725983129174
[Epoch 8, Batch 2500] loss: 0.03389755772666831
[Epoch 8, Batch 2600] loss: 0.027407302240026184
[Epoch 8, Batch 2700] loss: 0.019542341757223768
[Epoch 8, Batch 2800] loss: 0.030182044750545173
[Epoch 8, Batch 2900] loss: 0.025543197116385273
[Epoch 8, Batch 3000] loss: 0.020113692482700573
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0405
Validation Accuracy: 0.9882
Overfitting: 0.0405
Best model saved at epoch 8 with validation loss: 0.0405
[Epoch 9, Batch 100] loss: 0.030880605966831353
[Epoch 9, Batch 200] loss: 0.021775284960167483
[Epoch 9, Batch 300] loss: 0.01600401066262748
[Epoch 9, Batch 400] loss: 0.013854963113462872
[Epoch 9, Batch 500] loss: 0.015377018496637902
[Epoch 9, Batch 600] loss: 0.01469326400974751
[Epoch 9, Batch 700] loss: 0.014085103491815971
[Epoch 9, Batch 800] loss: 0.020786994790601056
[Epoch 9, Batch 900] loss: 0.025405686084050104
[Epoch 9, Batch 1000] loss: 0.022433190672782075
[Epoch 9, Batch 1100] loss: 0.02915797380497679
[Epoch 9, Batch 1200] loss: 0.01781212513051287
[Epoch 9, Batch 1300] loss: 0.025698116045296048
[Epoch 9, Batch 1400] loss: 0.03432018646653887
[Epoch 9, Batch 1500] loss: 0.024794633387518843
[Epoch 9, Batch 1600] loss: 0.016918986800646962
[Epoch 9, Batch 1700] loss: 0.015719716317307758
[Epoch 9, Batch 1800] loss: 0.023966616881589287
[Epoch 9, Batch 1900] loss: 0.017275148442786305
[Epoch 9, Batch 2000] loss: 0.0386950101833645
[Epoch 9, Batch 2100] loss: 0.02240348347728286
[Epoch 9, Batch 2200] loss: 0.015000679724762449
[Epoch 9, Batch 2300] loss: 0.015072082581318681
[Epoch 9, Batch 2400] loss: 0.012512207980353195
[Epoch 9, Batch 2500] loss: 0.017801813369012508
[Epoch 9, Batch 2600] loss: 0.01468441972079745
[Epoch 9, Batch 2700] loss: 0.017753433763424482
[Epoch 9, Batch 2800] loss: 0.030119916369772
[Epoch 9, Batch 2900] loss: 0.01541355920742717
[Epoch 9, Batch 3000] loss: 0.024353885559339688
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0418
Validation Accuracy: 0.9879
Overfitting: 0.0418
[Epoch 10, Batch 100] loss: 0.011671973537904706
[Epoch 10, Batch 200] loss: 0.015208027425401269
[Epoch 10, Batch 300] loss: 0.006062492017572367
[Epoch 10, Batch 400] loss: 0.01386256268606303
[Epoch 10, Batch 500] loss: 0.012224063407429639
[Epoch 10, Batch 600] loss: 0.02429144170549989
[Epoch 10, Batch 700] loss: 0.01621165502239819
[Epoch 10, Batch 800] loss: 0.012883114663973174
[Epoch 10, Batch 900] loss: 0.014821063497474824
[Epoch 10, Batch 1000] loss: 0.022441192208925712
[Epoch 10, Batch 1100] loss: 0.021831774949432656
[Epoch 10, Batch 1200] loss: 0.021462341057049344
[Epoch 10, Batch 1300] loss: 0.024327638133800063
[Epoch 10, Batch 1400] loss: 0.011500246539144427
[Epoch 10, Batch 1500] loss: 0.028979674996153334
[Epoch 10, Batch 1600] loss: 0.016326910743810003
[Epoch 10, Batch 1700] loss: 0.019378505727327137
[Epoch 10, Batch 1800] loss: 0.0241041540612423
[Epoch 10, Batch 1900] loss: 0.017599996528761038
[Epoch 10, Batch 2000] loss: 0.011168300628560246
[Epoch 10, Batch 2100] loss: 0.02420446491400071
[Epoch 10, Batch 2200] loss: 0.014956221458887739
[Epoch 10, Batch 2300] loss: 0.025833239138573844
[Epoch 10, Batch 2400] loss: 0.011843676504468022
[Epoch 10, Batch 2500] loss: 0.016428665367639043
[Epoch 10, Batch 2600] loss: 0.025908246002054512
[Epoch 10, Batch 2700] loss: 0.01686976613200386
[Epoch 10, Batch 2800] loss: 0.01504308816988214
[Epoch 10, Batch 2900] loss: 0.012308729414253322
[Epoch 10, Batch 3000] loss: 0.015078795169874865
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9874
Overfitting: 0.0449
[Epoch 11, Batch 100] loss: 0.014593019984295097
[Epoch 11, Batch 200] loss: 0.01905331609705172
[Epoch 11, Batch 300] loss: 0.00801022640796873
[Epoch 11, Batch 400] loss: 0.01467913101364843
[Epoch 11, Batch 500] loss: 0.01967781118181847
[Epoch 11, Batch 600] loss: 0.015624633553188686
[Epoch 11, Batch 700] loss: 0.01541525552850544
[Epoch 11, Batch 800] loss: 0.0053198995179081976
[Epoch 11, Batch 900] loss: 0.018936674869137277
[Epoch 11, Batch 1000] loss: 0.009296072106176325
[Epoch 11, Batch 1100] loss: 0.033192643111833606
[Epoch 11, Batch 1200] loss: 0.012259965516313968
[Epoch 11, Batch 1300] loss: 0.012861979974904897
[Epoch 11, Batch 1400] loss: 0.01707572781187082
[Epoch 11, Batch 1500] loss: 0.012742234053785068
[Epoch 11, Batch 1600] loss: 0.012745193019945873
[Epoch 11, Batch 1700] loss: 0.03410168072819943
[Epoch 11, Batch 1800] loss: 0.020821388652584573
[Epoch 11, Batch 1900] loss: 0.015972390322494902
[Epoch 11, Batch 2000] loss: 0.0160517912729847
[Epoch 11, Batch 2100] loss: 0.021717850748027557
[Epoch 11, Batch 2200] loss: 0.014612587770461687
[Epoch 11, Batch 2300] loss: 0.024389056762688596
[Epoch 11, Batch 2400] loss: 0.012590863775922117
[Epoch 11, Batch 2500] loss: 0.007540354229026889
[Epoch 11, Batch 2600] loss: 0.016602867946448895
[Epoch 11, Batch 2700] loss: 0.01157816549495692
[Epoch 11, Batch 2800] loss: 0.029305404452461516
[Epoch 11, Batch 2900] loss: 0.01774399262460065
[Epoch 11, Batch 3000] loss: 0.022431705520211835
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9872
Overfitting: 0.0471
[Epoch 12, Batch 100] loss: 0.01003188064955566
[Epoch 12, Batch 200] loss: 0.008053525125733358
[Epoch 12, Batch 300] loss: 0.011012178779485566
[Epoch 12, Batch 400] loss: 0.007329595068554227
[Epoch 12, Batch 500] loss: 0.005539702319422304
[Epoch 12, Batch 600] loss: 0.009265977425027359
[Epoch 12, Batch 700] loss: 0.015155451835926214
[Epoch 12, Batch 800] loss: 0.02808382418108067
[Epoch 12, Batch 900] loss: 0.01473000601597505
[Epoch 12, Batch 1000] loss: 0.016191557322799782
[Epoch 12, Batch 1100] loss: 0.013125154299409587
[Epoch 12, Batch 1200] loss: 0.014994090521212939
[Epoch 12, Batch 1300] loss: 0.01375821831210942
[Epoch 12, Batch 1400] loss: 0.02133415808802056
[Epoch 12, Batch 1500] loss: 0.017951055555495258
[Epoch 12, Batch 1600] loss: 0.010544281376846812
[Epoch 12, Batch 1700] loss: 0.01204578038345062
[Epoch 12, Batch 1800] loss: 0.029968310836691218
[Epoch 12, Batch 1900] loss: 0.011739514985711139
[Epoch 12, Batch 2000] loss: 0.013391918973311476
[Epoch 12, Batch 2100] loss: 0.015990235306644535
[Epoch 12, Batch 2200] loss: 0.012840719989469562
[Epoch 12, Batch 2300] loss: 0.014127855261813238
[Epoch 12, Batch 2400] loss: 0.013713958734515473
[Epoch 12, Batch 2500] loss: 0.011141937982697527
[Epoch 12, Batch 2600] loss: 0.011242006047837094
[Epoch 12, Batch 2700] loss: 0.013003554662855094
[Epoch 12, Batch 2800] loss: 0.01625571097303691
[Epoch 12, Batch 2900] loss: 0.010039932573931765
[Epoch 12, Batch 3000] loss: 0.01912301877540813
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9868
Overfitting: 0.0524
[Epoch 13, Batch 100] loss: 0.006634895059826249
[Epoch 13, Batch 200] loss: 0.006817648480603111
[Epoch 13, Batch 300] loss: 0.01198060792963588
[Epoch 13, Batch 400] loss: 0.007134242791935321
[Epoch 13, Batch 500] loss: 0.013237786555964703
[Epoch 13, Batch 600] loss: 0.021166698329743668
[Epoch 13, Batch 700] loss: 0.01528462993258472
[Epoch 13, Batch 800] loss: 0.019194507119136686
[Epoch 13, Batch 900] loss: 0.007179399418864705
[Epoch 13, Batch 1000] loss: 0.014271774933358756
[Epoch 13, Batch 1100] loss: 0.007704605395779254
[Epoch 13, Batch 1200] loss: 0.023876329221548077
[Epoch 13, Batch 1300] loss: 0.01433017780022965
[Epoch 13, Batch 1400] loss: 0.00826925631454742
[Epoch 13, Batch 1500] loss: 0.009266884512149999
[Epoch 13, Batch 1600] loss: 0.013642146398299247
[Epoch 13, Batch 1700] loss: 0.005584472451149622
[Epoch 13, Batch 1800] loss: 0.01463519527641438
[Epoch 13, Batch 1900] loss: 0.019022574748566966
[Epoch 13, Batch 2000] loss: 0.009331762887236437
[Epoch 13, Batch 2100] loss: 0.011655333723019794
[Epoch 13, Batch 2200] loss: 0.010110725879590063
[Epoch 13, Batch 2300] loss: 0.010710903982828767
[Epoch 13, Batch 2400] loss: 0.01649591706449769
[Epoch 13, Batch 2500] loss: 0.005368978082051399
[Epoch 13, Batch 2600] loss: 0.009344558198381491
[Epoch 13, Batch 2700] loss: 0.012171991915993203
[Epoch 13, Batch 2800] loss: 0.022462574143787606
[Epoch 13, Batch 2900] loss: 0.014213433138859272
[Epoch 13, Batch 3000] loss: 0.02004467094060601
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9858
Overfitting: 0.0506
[Epoch 14, Batch 100] loss: 0.004490694752624904
[Epoch 14, Batch 200] loss: 0.005274135466421513
[Epoch 14, Batch 300] loss: 0.005064685710156027
[Epoch 14, Batch 400] loss: 0.00463286057071457
[Epoch 14, Batch 500] loss: 0.006683499460789335
[Epoch 14, Batch 600] loss: 0.0034481636166492535
[Epoch 14, Batch 700] loss: 0.008354345148591165
[Epoch 14, Batch 800] loss: 0.0068691821747195545
[Epoch 14, Batch 900] loss: 0.010527228877201651
[Epoch 14, Batch 1000] loss: 0.015042903567439226
[Epoch 14, Batch 1100] loss: 0.010919530732976454
[Epoch 14, Batch 1200] loss: 0.005320531508210706
[Epoch 14, Batch 1300] loss: 0.00451032901895644
[Epoch 14, Batch 1400] loss: 0.008982291975621592
[Epoch 14, Batch 1500] loss: 0.00462500632343108
[Epoch 14, Batch 1600] loss: 0.00507752841299407
[Epoch 14, Batch 1700] loss: 0.003218810558919358
[Epoch 14, Batch 1800] loss: 0.013013111030004439
[Epoch 14, Batch 1900] loss: 0.011931317977655453
[Epoch 14, Batch 2000] loss: 0.00898766977023115
[Epoch 14, Batch 2100] loss: 0.00789992656291588
[Epoch 14, Batch 2200] loss: 0.013455448739118765
[Epoch 14, Batch 2300] loss: 0.008601530208743498
[Epoch 14, Batch 2400] loss: 0.009256892514899846
[Epoch 14, Batch 2500] loss: 0.016846294148433572
[Epoch 14, Batch 2600] loss: 0.008678217022782065
[Epoch 14, Batch 2700] loss: 0.023703269973478314
[Epoch 14, Batch 2800] loss: 0.01439003654548287
[Epoch 14, Batch 2900] loss: 0.03588469933916258
[Epoch 14, Batch 3000] loss: 0.01362393341756615
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9885
Overfitting: 0.0501
[Epoch 15, Batch 100] loss: 0.005174700614015819
[Epoch 15, Batch 200] loss: 0.012882666921991586
[Epoch 15, Batch 300] loss: 0.011699944509723536
[Epoch 15, Batch 400] loss: 0.008318453011384008
[Epoch 15, Batch 500] loss: 0.012926767244244956
[Epoch 15, Batch 600] loss: 0.01870435314146107
[Epoch 15, Batch 700] loss: 0.006956429457300146
[Epoch 15, Batch 800] loss: 0.0056615097385838455
[Epoch 15, Batch 900] loss: 0.006624016269229287
[Epoch 15, Batch 1000] loss: 0.005359020245770694
[Epoch 15, Batch 1100] loss: 0.005660153399226146
[Epoch 15, Batch 1200] loss: 0.007957354049926835
[Epoch 15, Batch 1300] loss: 0.009843036284553932
[Epoch 15, Batch 1400] loss: 0.012464925996505371
[Epoch 15, Batch 1500] loss: 0.013480908453241227
[Epoch 15, Batch 1600] loss: 0.009779757706537566
[Epoch 15, Batch 1700] loss: 0.011518006400565354
[Epoch 15, Batch 1800] loss: 0.004355280978541032
[Epoch 15, Batch 1900] loss: 0.002959246554408992
[Epoch 15, Batch 2000] loss: 0.007137642384632273
[Epoch 15, Batch 2100] loss: 0.0078098976589274114
[Epoch 15, Batch 2200] loss: 0.003943734169547497
[Epoch 15, Batch 2300] loss: 0.008506195118366122
[Epoch 15, Batch 2400] loss: 0.015483365102077186
[Epoch 15, Batch 2500] loss: 0.007507289612995009
[Epoch 15, Batch 2600] loss: 0.016473072477980397
[Epoch 15, Batch 2700] loss: 0.010319017323494108
[Epoch 15, Batch 2800] loss: 0.011863718880171063
[Epoch 15, Batch 2900] loss: 0.015169207581325282
[Epoch 15, Batch 3000] loss: 0.009038738775147976
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9882
Overfitting: 0.0463
[Epoch 16, Batch 100] loss: 0.007933448342213864
[Epoch 16, Batch 200] loss: 0.00877478264176716
[Epoch 16, Batch 300] loss: 0.006563321845372911
[Epoch 16, Batch 400] loss: 0.016292655952142923
[Epoch 16, Batch 500] loss: 0.016288420767466505
[Epoch 16, Batch 600] loss: 0.014723369252797056
[Epoch 16, Batch 700] loss: 0.006969250678944263
[Epoch 16, Batch 800] loss: 0.00365516589156897
[Epoch 16, Batch 900] loss: 0.009016853321141412
[Epoch 16, Batch 1000] loss: 0.007177876633113556
[Epoch 16, Batch 1100] loss: 0.008915111336606855
[Epoch 16, Batch 1200] loss: 0.005829268184241982
[Epoch 16, Batch 1300] loss: 0.008032112906432758
[Epoch 16, Batch 1400] loss: 0.003135417994264458
[Epoch 16, Batch 1500] loss: 0.010304531641099289
[Epoch 16, Batch 1600] loss: 0.008493531315932614
[Epoch 16, Batch 1700] loss: 0.008218797609606554
[Epoch 16, Batch 1800] loss: 0.006428714156069191
[Epoch 16, Batch 1900] loss: 0.008925749691154578
[Epoch 16, Batch 2000] loss: 0.001965497994059433
[Epoch 16, Batch 2100] loss: 0.014240129338695482
[Epoch 16, Batch 2200] loss: 0.0024710319468925946
[Epoch 16, Batch 2300] loss: 0.008126768338641881
[Epoch 16, Batch 2400] loss: 0.01828011506525172
[Epoch 16, Batch 2500] loss: 0.01342927055152586
[Epoch 16, Batch 2600] loss: 0.009156354352919607
[Epoch 16, Batch 2700] loss: 0.0026571401181683997
[Epoch 16, Batch 2800] loss: 0.008091454958268969
[Epoch 16, Batch 2900] loss: 0.005972247777195037
[Epoch 16, Batch 3000] loss: 0.0036237383238201916
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9891
Overfitting: 0.0437
[Epoch 17, Batch 100] loss: 0.006454576287902966
[Epoch 17, Batch 200] loss: 0.0034389761196740665
[Epoch 17, Batch 300] loss: 0.007905043566014456
[Epoch 17, Batch 400] loss: 0.0021003496813651167
[Epoch 17, Batch 500] loss: 0.005233456058738284
[Epoch 17, Batch 600] loss: 0.011069968408431805
[Epoch 17, Batch 700] loss: 0.013315231273404607
[Epoch 17, Batch 800] loss: 0.01447525833722608
[Epoch 17, Batch 900] loss: 0.01953933292275906
[Epoch 17, Batch 1000] loss: 0.019271737899116487
[Epoch 17, Batch 1100] loss: 0.007701921897059947
[Epoch 17, Batch 1200] loss: 0.004396050568410601
[Epoch 17, Batch 1300] loss: 0.004098429829082306
[Epoch 17, Batch 1400] loss: 0.006744019533053916
[Epoch 17, Batch 1500] loss: 0.00420535513542859
[Epoch 17, Batch 1600] loss: 0.006132231666688312
[Epoch 17, Batch 1700] loss: 0.004164129253310876
[Epoch 17, Batch 1800] loss: 0.01195192480001623
[Epoch 17, Batch 1900] loss: 0.005097353580779327
[Epoch 17, Batch 2000] loss: 0.006019329854705404
[Epoch 17, Batch 2100] loss: 0.009645341216412646
[Epoch 17, Batch 2200] loss: 0.007358708625866655
[Epoch 17, Batch 2300] loss: 0.010260409890643132
[Epoch 17, Batch 2400] loss: 0.009179718678001905
[Epoch 17, Batch 2500] loss: 0.004780474312374281
[Epoch 17, Batch 2600] loss: 0.01048424763458172
[Epoch 17, Batch 2700] loss: 0.003757496613479745
[Epoch 17, Batch 2800] loss: 0.003419060892397283
[Epoch 17, Batch 2900] loss: 0.006710951524412394
[Epoch 17, Batch 3000] loss: 0.014762145890407509
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9888
Overfitting: 0.0478
[Epoch 18, Batch 100] loss: 0.009182462876619581
[Epoch 18, Batch 200] loss: 0.0029869975158385385
[Epoch 18, Batch 300] loss: 0.002588407240491506
[Epoch 18, Batch 400] loss: 0.004953609631295564
[Epoch 18, Batch 500] loss: 0.0045474854184340075
[Epoch 18, Batch 600] loss: 0.010572309215880154
[Epoch 18, Batch 700] loss: 0.006501141593485827
[Epoch 18, Batch 800] loss: 0.009872822012553115
[Epoch 18, Batch 900] loss: 0.01374533313571419
[Epoch 18, Batch 1000] loss: 0.00748949696849337
[Epoch 18, Batch 1100] loss: 0.00964237191583038
[Epoch 18, Batch 1200] loss: 0.017704563450712953
[Epoch 18, Batch 1300] loss: 0.012821132334721597
[Epoch 18, Batch 1400] loss: 0.012190150133393444
[Epoch 18, Batch 1500] loss: 0.009292454815738437
[Epoch 18, Batch 1600] loss: 0.01236106554329126
[Epoch 18, Batch 1700] loss: 0.005230033677287338
[Epoch 18, Batch 1800] loss: 0.004734222354059057
[Epoch 18, Batch 1900] loss: 0.0053509251120192405
[Epoch 18, Batch 2000] loss: 0.005730704351581153
[Epoch 18, Batch 2100] loss: 0.009560288665146572
[Epoch 18, Batch 2200] loss: 0.005983298969503892
[Epoch 18, Batch 2300] loss: 0.005117507154745908
[Epoch 18, Batch 2400] loss: 0.0063461839749316875
[Epoch 18, Batch 2500] loss: 0.00400100678456738
[Epoch 18, Batch 2600] loss: 0.0067362695702401255
[Epoch 18, Batch 2700] loss: 0.006206270520163457
[Epoch 18, Batch 2800] loss: 0.0074734002323390315
[Epoch 18, Batch 2900] loss: 0.011197852396960285
[Epoch 18, Batch 3000] loss: 0.01227055103267503
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0618
Validation Accuracy: 0.9852
Overfitting: 0.0618
[Epoch 19, Batch 100] loss: 0.011266205577752259
[Epoch 19, Batch 200] loss: 0.005598670670029833
[Epoch 19, Batch 300] loss: 0.010793465635323685
[Epoch 19, Batch 400] loss: 0.003963726071643236
[Epoch 19, Batch 500] loss: 0.0022151341315600347
[Epoch 19, Batch 600] loss: 0.004223695538256606
[Epoch 19, Batch 700] loss: 0.009761263060595412
[Epoch 19, Batch 800] loss: 0.0015271144550770544
[Epoch 19, Batch 900] loss: 0.0036746917293351087
[Epoch 19, Batch 1000] loss: 0.004700929859452003
[Epoch 19, Batch 1100] loss: 0.003717368052589265
[Epoch 19, Batch 1200] loss: 0.004165843708146894
[Epoch 19, Batch 1300] loss: 0.006057973555581952
[Epoch 19, Batch 1400] loss: 0.007843531226920959
[Epoch 19, Batch 1500] loss: 0.01148933009353641
[Epoch 19, Batch 1600] loss: 0.007231696450205476
[Epoch 19, Batch 1700] loss: 0.00469112479585732
[Epoch 19, Batch 1800] loss: 0.00508252827934399
[Epoch 19, Batch 1900] loss: 0.004017037037245359
[Epoch 19, Batch 2000] loss: 0.004751389433728112
[Epoch 19, Batch 2100] loss: 0.0010645933044053635
[Epoch 19, Batch 2200] loss: 0.006256979751681513
[Epoch 19, Batch 2300] loss: 0.006341514394205205
[Epoch 19, Batch 2400] loss: 0.003348055783642394
[Epoch 19, Batch 2500] loss: 0.006254694110175478
[Epoch 19, Batch 2600] loss: 0.0022390792819246743
[Epoch 19, Batch 2700] loss: 0.006729548791508932
[Epoch 19, Batch 2800] loss: 0.007582952359101682
[Epoch 19, Batch 2900] loss: 0.010604977559219152
[Epoch 19, Batch 3000] loss: 0.01114551068245987
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9894
Overfitting: 0.0462
[Epoch 20, Batch 100] loss: 0.007126774595778897
[Epoch 20, Batch 200] loss: 0.0018058622340343788
[Epoch 20, Batch 300] loss: 0.003548537577493107
[Epoch 20, Batch 400] loss: 0.0017911343009036074
[Epoch 20, Batch 500] loss: 0.0014581271059790524
[Epoch 20, Batch 600] loss: 0.001529936065417843
[Epoch 20, Batch 700] loss: 0.008135219273549196
[Epoch 20, Batch 800] loss: 0.007852392695366178
[Epoch 20, Batch 900] loss: 0.02789608137803839
[Epoch 20, Batch 1000] loss: 0.010830356000122379
[Epoch 20, Batch 1100] loss: 0.007521952993513419
[Epoch 20, Batch 1200] loss: 0.0026345994118821634
[Epoch 20, Batch 1300] loss: 0.005842770778626942
[Epoch 20, Batch 1400] loss: 0.006889322476326356
[Epoch 20, Batch 1500] loss: 0.0012946089800590244
[Epoch 20, Batch 1600] loss: 0.0029554779622005256
[Epoch 20, Batch 1700] loss: 0.007740353393193118
[Epoch 20, Batch 1800] loss: 0.00825063921978881
[Epoch 20, Batch 1900] loss: 0.0032759756219523694
[Epoch 20, Batch 2000] loss: 0.00312952837402797
[Epoch 20, Batch 2100] loss: 0.0020366796311373035
[Epoch 20, Batch 2200] loss: 0.004904396865658995
[Epoch 20, Batch 2300] loss: 0.003289950583742538
[Epoch 20, Batch 2400] loss: 0.009896528641599218
[Epoch 20, Batch 2500] loss: 0.0071551647356272955
[Epoch 20, Batch 2600] loss: 0.012888666769073041
[Epoch 20, Batch 2700] loss: 0.005720120761257004
[Epoch 20, Batch 2800] loss: 0.01282293451218834
[Epoch 20, Batch 2900] loss: 0.0047441858779373545
[Epoch 20, Batch 3000] loss: 0.00578790283418499
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9891
Overfitting: 0.0477
[Epoch 21, Batch 100] loss: 0.002207992585140346
[Epoch 21, Batch 200] loss: 0.0012984964061416803
[Epoch 21, Batch 300] loss: 0.003883527996429734
[Epoch 21, Batch 400] loss: 0.0045698516021922585
[Epoch 21, Batch 500] loss: 0.0024127380848507586
[Epoch 21, Batch 600] loss: 0.0041906794478760645
[Epoch 21, Batch 700] loss: 0.0037171965351572565
[Epoch 21, Batch 800] loss: 0.005009135179406314
[Epoch 21, Batch 900] loss: 0.010535944684940332
[Epoch 21, Batch 1000] loss: 0.008896852178828567
[Epoch 21, Batch 1100] loss: 0.006140444266195573
[Epoch 21, Batch 1200] loss: 0.0054028386290723065
[Epoch 21, Batch 1300] loss: 0.006311178751470834
[Epoch 21, Batch 1400] loss: 0.0022949035122290695
[Epoch 21, Batch 1500] loss: 0.003598009722699089
[Epoch 21, Batch 1600] loss: 0.014639583541725187
[Epoch 21, Batch 1700] loss: 0.005420034509251081
[Epoch 21, Batch 1800] loss: 0.009566630598911843
[Epoch 21, Batch 1900] loss: 0.010092446168168435
[Epoch 21, Batch 2000] loss: 0.0020916945039967773
[Epoch 21, Batch 2100] loss: 0.0015315021206112078
[Epoch 21, Batch 2200] loss: 0.002653463590528418
[Epoch 21, Batch 2300] loss: 0.007157990419412812
[Epoch 21, Batch 2400] loss: 0.004057917801459325
[Epoch 21, Batch 2500] loss: 0.004574432762744039
[Epoch 21, Batch 2600] loss: 0.0023968409848760786
[Epoch 21, Batch 2700] loss: 0.004564397589449527
[Epoch 21, Batch 2800] loss: 0.00490549044067933
[Epoch 21, Batch 2900] loss: 0.006861250003252621
[Epoch 21, Batch 3000] loss: 0.012612517647509662
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9886
Overfitting: 0.0487
[Epoch 22, Batch 100] loss: 0.008928559418223757
[Epoch 22, Batch 200] loss: 0.0032817195349500138
[Epoch 22, Batch 300] loss: 0.0026001134862045916
[Epoch 22, Batch 400] loss: 0.0026510748743175582
[Epoch 22, Batch 500] loss: 0.0013920100379501577
[Epoch 22, Batch 600] loss: 0.0016864565601244718
[Epoch 22, Batch 700] loss: 0.0009665662271088138
[Epoch 22, Batch 800] loss: 0.0020131757428946883
[Epoch 22, Batch 900] loss: 0.0008120144352878178
[Epoch 22, Batch 1000] loss: 0.003465396561761054
[Epoch 22, Batch 1100] loss: 0.0014401078603878048
[Epoch 22, Batch 1200] loss: 0.004207260397982004
[Epoch 22, Batch 1300] loss: 0.0008349394293624801
[Epoch 22, Batch 1400] loss: 0.0005479474703706799
[Epoch 22, Batch 1500] loss: 0.0011509651536204047
[Epoch 22, Batch 1600] loss: 0.0034499723446000984
[Epoch 22, Batch 1700] loss: 0.00222208740122948
[Epoch 22, Batch 1800] loss: 0.0010269805827137146
[Epoch 22, Batch 1900] loss: 0.0024348708645458217
[Epoch 22, Batch 2000] loss: 0.0019529713725690457
[Epoch 22, Batch 2100] loss: 0.0012890334185084384
[Epoch 22, Batch 2200] loss: 0.0013301313175945494
[Epoch 22, Batch 2300] loss: 0.0020943710264547553
[Epoch 22, Batch 2400] loss: 0.0004988333802861434
[Epoch 22, Batch 2500] loss: 0.0004762756420870984
[Epoch 22, Batch 2600] loss: 0.0008773049157898027
[Epoch 22, Batch 2700] loss: 0.0012292649067484262
[Epoch 22, Batch 2800] loss: 0.0007313572952891434
[Epoch 22, Batch 2900] loss: 0.0019136417178482646
[Epoch 22, Batch 3000] loss: 0.0010249883536278404
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9912
Overfitting: 0.0436
[Epoch 23, Batch 100] loss: 0.0006734557145797737
[Epoch 23, Batch 200] loss: 0.0003830979057492989
[Epoch 23, Batch 300] loss: 0.0008159209166118764
[Epoch 23, Batch 400] loss: 0.0026154513693695948
[Epoch 23, Batch 500] loss: 0.0004932209171152246
[Epoch 23, Batch 600] loss: 0.0011543342667117784
[Epoch 23, Batch 700] loss: 0.0020242105242154907
[Epoch 23, Batch 800] loss: 0.0034017557985069934
[Epoch 23, Batch 900] loss: 0.002504660731022401
[Epoch 23, Batch 1000] loss: 0.0006150171302952722
[Epoch 23, Batch 1100] loss: 0.0009699602274117281
[Epoch 23, Batch 1200] loss: 0.0010413468805610827
[Epoch 23, Batch 1300] loss: 0.0010969357484313092
[Epoch 23, Batch 1400] loss: 0.0014463419465462124
[Epoch 23, Batch 1500] loss: 0.005440203485055619
[Epoch 23, Batch 1600] loss: 0.0012619965671490263
[Epoch 23, Batch 1700] loss: 0.0008613500725121525
[Epoch 23, Batch 1800] loss: 0.0018364546533302928
[Epoch 23, Batch 1900] loss: 0.0026452989031422545
[Epoch 23, Batch 2000] loss: 0.003455251436601756
[Epoch 23, Batch 2100] loss: 0.0015994222829762705
[Epoch 23, Batch 2200] loss: 0.0007158528436774247
[Epoch 23, Batch 2300] loss: 0.00046275127462791943
[Epoch 23, Batch 2400] loss: 0.004763827329764893
[Epoch 23, Batch 2500] loss: 0.0006146046131184768
[Epoch 23, Batch 2600] loss: 0.0006150119629538154
[Epoch 23, Batch 2700] loss: 0.0006490827665576937
[Epoch 23, Batch 2800] loss: 0.0010269935427485422
[Epoch 23, Batch 2900] loss: 0.0026570956701511862
[Epoch 23, Batch 3000] loss: 0.0009095172226221803
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9903
Overfitting: 0.0459
[Epoch 24, Batch 100] loss: 0.0005573394565518708
[Epoch 24, Batch 200] loss: 0.00025224538969212065
[Epoch 24, Batch 300] loss: 0.000697733861494001
[Epoch 24, Batch 400] loss: 0.0007583471263350772
[Epoch 24, Batch 500] loss: 0.00042128383180710215
[Epoch 24, Batch 600] loss: 0.0006855226182467567
[Epoch 24, Batch 700] loss: 0.00044234422567264177
[Epoch 24, Batch 800] loss: 0.0003586189583055699
[Epoch 24, Batch 900] loss: 0.0016388309716356276
[Epoch 24, Batch 1000] loss: 0.0006966891218027982
[Epoch 24, Batch 1100] loss: 0.0003720110569882529
[Epoch 24, Batch 1200] loss: 0.0004106304359342161
[Epoch 24, Batch 1300] loss: 0.0003079359252706082
[Epoch 24, Batch 1400] loss: 0.00030865641704178157
[Epoch 24, Batch 1500] loss: 0.0014399792914112908
[Epoch 24, Batch 1600] loss: 0.0035291412099569186
[Epoch 24, Batch 1700] loss: 0.0007545767644757007
[Epoch 24, Batch 1800] loss: 0.0006389476906444536
[Epoch 24, Batch 1900] loss: 0.0037816662126341784
[Epoch 24, Batch 2000] loss: 0.0009673679544579272
[Epoch 24, Batch 2100] loss: 0.0005693817103482246
[Epoch 24, Batch 2200] loss: 0.0016451913587779688
[Epoch 24, Batch 2300] loss: 0.0011349951761795917
[Epoch 24, Batch 2400] loss: 0.0006987788427870889
[Epoch 24, Batch 2500] loss: 0.0003738219527714648
[Epoch 24, Batch 2600] loss: 0.0005247507728108225
[Epoch 24, Batch 2700] loss: 0.0002116187314989304
[Epoch 24, Batch 2800] loss: 0.0006380162189957117
[Epoch 24, Batch 2900] loss: 0.005206134234560245
[Epoch 24, Batch 3000] loss: 0.0028061078822348407
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9902
Overfitting: 0.0510
Fold 1 validation loss: 0.0510
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.291490547657013
[Epoch 1, Batch 200] loss: 2.2070088148117066
[Epoch 1, Batch 300] loss: 1.5295209085941315
[Epoch 1, Batch 400] loss: 0.7454650597274304
[Epoch 1, Batch 500] loss: 0.6007429949939251
[Epoch 1, Batch 600] loss: 0.44097429171204566
[Epoch 1, Batch 700] loss: 0.3615418941900134
[Epoch 1, Batch 800] loss: 0.30507363451644776
[Epoch 1, Batch 900] loss: 0.33024022649973633
[Epoch 1, Batch 1000] loss: 0.2760313472058624
[Epoch 1, Batch 1100] loss: 0.2349691955372691
[Epoch 1, Batch 1200] loss: 0.23303380372002722
[Epoch 1, Batch 1300] loss: 0.20708977341651916
[Epoch 1, Batch 1400] loss: 0.17917159060947596
[Epoch 1, Batch 1500] loss: 0.1896968781016767
[Epoch 1, Batch 1600] loss: 0.18342726809903978
[Epoch 1, Batch 1700] loss: 0.15147470873314886
[Epoch 1, Batch 1800] loss: 0.1845992987602949
[Epoch 1, Batch 1900] loss: 0.18331405125558375
[Epoch 1, Batch 2000] loss: 0.17696625443175434
[Epoch 1, Batch 2100] loss: 0.1213401133962907
[Epoch 1, Batch 2200] loss: 0.13193474993342533
[Epoch 1, Batch 2300] loss: 0.1266398737486452
[Epoch 1, Batch 2400] loss: 0.14237383508123458
[Epoch 1, Batch 2500] loss: 0.12513604366220535
[Epoch 1, Batch 2600] loss: 0.1359801983786747
[Epoch 1, Batch 2700] loss: 0.1280053586838767
[Epoch 1, Batch 2800] loss: 0.12135482899611816
[Epoch 1, Batch 2900] loss: 0.12181884108111263
[Epoch 1, Batch 3000] loss: 0.1348753856215626
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1237
Validation Accuracy: 0.9617
Overfitting: 0.1237
Best model saved at epoch 1 with validation loss: 0.1237
[Epoch 2, Batch 100] loss: 0.11961752788629383
[Epoch 2, Batch 200] loss: 0.1122713778121397
[Epoch 2, Batch 300] loss: 0.12454887542175129
[Epoch 2, Batch 400] loss: 0.11100209818570875
[Epoch 2, Batch 500] loss: 0.10281378238461912
[Epoch 2, Batch 600] loss: 0.09602362458943389
[Epoch 2, Batch 700] loss: 0.07249333449872211
[Epoch 2, Batch 800] loss: 0.10788116397336125
[Epoch 2, Batch 900] loss: 0.11902587810414843
[Epoch 2, Batch 1000] loss: 0.09276451771351275
[Epoch 2, Batch 1100] loss: 0.09196939884219318
[Epoch 2, Batch 1200] loss: 0.11639123415108771
[Epoch 2, Batch 1300] loss: 0.0968016026262194
[Epoch 2, Batch 1400] loss: 0.09073725927912164
[Epoch 2, Batch 1500] loss: 0.08356413331348449
[Epoch 2, Batch 1600] loss: 0.0961012798617594
[Epoch 2, Batch 1700] loss: 0.08982488029752858
[Epoch 2, Batch 1800] loss: 0.10181620512041263
[Epoch 2, Batch 1900] loss: 0.07843201055424288
[Epoch 2, Batch 2000] loss: 0.08916191017546225
[Epoch 2, Batch 2100] loss: 0.10264736323850229
[Epoch 2, Batch 2200] loss: 0.08135764379636384
[Epoch 2, Batch 2300] loss: 0.11525583133334294
[Epoch 2, Batch 2400] loss: 0.092171590924263
[Epoch 2, Batch 2500] loss: 0.05634463246562518
[Epoch 2, Batch 2600] loss: 0.07838860644027591
[Epoch 2, Batch 2700] loss: 0.09228744722669945
[Epoch 2, Batch 2800] loss: 0.08176842812914402
[Epoch 2, Batch 2900] loss: 0.09086244781385176
[Epoch 2, Batch 3000] loss: 0.08571247659274377
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0879
Validation Accuracy: 0.9741
Overfitting: 0.0879
Best model saved at epoch 2 with validation loss: 0.0879
[Epoch 3, Batch 100] loss: 0.06697131251683458
[Epoch 3, Batch 200] loss: 0.06277724694984499
[Epoch 3, Batch 300] loss: 0.08491239026654512
[Epoch 3, Batch 400] loss: 0.06863633925735485
[Epoch 3, Batch 500] loss: 0.08481332997442223
[Epoch 3, Batch 600] loss: 0.0793592764425557
[Epoch 3, Batch 700] loss: 0.07604015456628986
[Epoch 3, Batch 800] loss: 0.0737137785469531
[Epoch 3, Batch 900] loss: 0.08629125287756324
[Epoch 3, Batch 1000] loss: 0.0733518695604289
[Epoch 3, Batch 1100] loss: 0.07526646108715795
[Epoch 3, Batch 1200] loss: 0.05764168625115417
[Epoch 3, Batch 1300] loss: 0.05182995603536256
[Epoch 3, Batch 1400] loss: 0.061461908366181886
[Epoch 3, Batch 1500] loss: 0.09897542160761078
[Epoch 3, Batch 1600] loss: 0.051310876365751025
[Epoch 3, Batch 1700] loss: 0.05205590565252351
[Epoch 3, Batch 1800] loss: 0.0655715811176924
[Epoch 3, Batch 1900] loss: 0.06275321364053525
[Epoch 3, Batch 2000] loss: 0.06532524595735595
[Epoch 3, Batch 2100] loss: 0.064985180987278
[Epoch 3, Batch 2200] loss: 0.07194923426490277
[Epoch 3, Batch 2300] loss: 0.062074656865443105
[Epoch 3, Batch 2400] loss: 0.06251575406524353
[Epoch 3, Batch 2500] loss: 0.058195744507247585
[Epoch 3, Batch 2600] loss: 0.08074028281727806
[Epoch 3, Batch 2700] loss: 0.06780002776940819
[Epoch 3, Batch 2800] loss: 0.059067797161987984
[Epoch 3, Batch 2900] loss: 0.03983103019592818
[Epoch 3, Batch 3000] loss: 0.06890659190888983
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0711
Validation Accuracy: 0.9784
Overfitting: 0.0711
Best model saved at epoch 3 with validation loss: 0.0711
[Epoch 4, Batch 100] loss: 0.04740695450571366
[Epoch 4, Batch 200] loss: 0.05560991742822807
[Epoch 4, Batch 300] loss: 0.04765823609486688
[Epoch 4, Batch 400] loss: 0.05256074372795411
[Epoch 4, Batch 500] loss: 0.05967494126030942
[Epoch 4, Batch 600] loss: 0.06158197464479599
[Epoch 4, Batch 700] loss: 0.054648960314225406
[Epoch 4, Batch 800] loss: 0.03597818108682986
[Epoch 4, Batch 900] loss: 0.045142324102052954
[Epoch 4, Batch 1000] loss: 0.045487425468454606
[Epoch 4, Batch 1100] loss: 0.05897875054244651
[Epoch 4, Batch 1200] loss: 0.042375185683486055
[Epoch 4, Batch 1300] loss: 0.04552621331415139
[Epoch 4, Batch 1400] loss: 0.06415463007127982
[Epoch 4, Batch 1500] loss: 0.04594305944396183
[Epoch 4, Batch 1600] loss: 0.049032567353278864
[Epoch 4, Batch 1700] loss: 0.05252336734876735
[Epoch 4, Batch 1800] loss: 0.04440590604557656
[Epoch 4, Batch 1900] loss: 0.07293236168974544
[Epoch 4, Batch 2000] loss: 0.04133782645629253
[Epoch 4, Batch 2100] loss: 0.05369727243174566
[Epoch 4, Batch 2200] loss: 0.040525102606770814
[Epoch 4, Batch 2300] loss: 0.056492342660640134
[Epoch 4, Batch 2400] loss: 0.04555050651892088
[Epoch 4, Batch 2500] loss: 0.0561555343773216
[Epoch 4, Batch 2600] loss: 0.05075784206128446
[Epoch 4, Batch 2700] loss: 0.04922725596203236
[Epoch 4, Batch 2800] loss: 0.06346610592503567
[Epoch 4, Batch 2900] loss: 0.04260604605660774
[Epoch 4, Batch 3000] loss: 0.054650829425081614
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9822
Overfitting: 0.0603
Best model saved at epoch 4 with validation loss: 0.0603
[Epoch 5, Batch 100] loss: 0.0313603701358079
[Epoch 5, Batch 200] loss: 0.04178394048591144
[Epoch 5, Batch 300] loss: 0.03016857629932929
[Epoch 5, Batch 400] loss: 0.03299862179061165
[Epoch 5, Batch 500] loss: 0.03553463260643184
[Epoch 5, Batch 600] loss: 0.025146216143020865
[Epoch 5, Batch 700] loss: 0.029663489598533488
[Epoch 5, Batch 800] loss: 0.03911484986558207
[Epoch 5, Batch 900] loss: 0.04117487256247841
[Epoch 5, Batch 1000] loss: 0.042445601063082
[Epoch 5, Batch 1100] loss: 0.0661404769247747
[Epoch 5, Batch 1200] loss: 0.03528705163436825
[Epoch 5, Batch 1300] loss: 0.0317385272984393
[Epoch 5, Batch 1400] loss: 0.048632506560534236
[Epoch 5, Batch 1500] loss: 0.03343762585587683
[Epoch 5, Batch 1600] loss: 0.05252944368119643
[Epoch 5, Batch 1700] loss: 0.03322369369867374
[Epoch 5, Batch 1800] loss: 0.049348564796091524
[Epoch 5, Batch 1900] loss: 0.05668030255823396
[Epoch 5, Batch 2000] loss: 0.035608912023744776
[Epoch 5, Batch 2100] loss: 0.03538394333940232
[Epoch 5, Batch 2200] loss: 0.04994792524856166
[Epoch 5, Batch 2300] loss: 0.044428843730711376
[Epoch 5, Batch 2400] loss: 0.04360433618508978
[Epoch 5, Batch 2500] loss: 0.03950167478018557
[Epoch 5, Batch 2600] loss: 0.04210578923928551
[Epoch 5, Batch 2700] loss: 0.05439075016445713
[Epoch 5, Batch 2800] loss: 0.039827496484358564
[Epoch 5, Batch 2900] loss: 0.06195204733579885
[Epoch 5, Batch 3000] loss: 0.042607614910812115
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0616
Validation Accuracy: 0.9828
Overfitting: 0.0616
[Epoch 6, Batch 100] loss: 0.02639958310770453
[Epoch 6, Batch 200] loss: 0.026977154159103522
[Epoch 6, Batch 300] loss: 0.03250020882522222
[Epoch 6, Batch 400] loss: 0.04573936351487646
[Epoch 6, Batch 500] loss: 0.02509193412872264
[Epoch 6, Batch 600] loss: 0.04043300395802362
[Epoch 6, Batch 700] loss: 0.040646279015636534
[Epoch 6, Batch 800] loss: 0.024231703671248397
[Epoch 6, Batch 900] loss: 0.029108021338324762
[Epoch 6, Batch 1000] loss: 0.0367276667652186
[Epoch 6, Batch 1100] loss: 0.03938634332997026
[Epoch 6, Batch 1200] loss: 0.03606202479728381
[Epoch 6, Batch 1300] loss: 0.04045352751054452
[Epoch 6, Batch 1400] loss: 0.028078881629517126
[Epoch 6, Batch 1500] loss: 0.01611952938030299
[Epoch 6, Batch 1600] loss: 0.032533874933378684
[Epoch 6, Batch 1700] loss: 0.0371021913117147
[Epoch 6, Batch 1800] loss: 0.031708337796735576
[Epoch 6, Batch 1900] loss: 0.033064888716326096
[Epoch 6, Batch 2000] loss: 0.023206191890712945
[Epoch 6, Batch 2100] loss: 0.03414393685503456
[Epoch 6, Batch 2200] loss: 0.03791019169424544
[Epoch 6, Batch 2300] loss: 0.054615051800719815
[Epoch 6, Batch 2400] loss: 0.06699667485041573
[Epoch 6, Batch 2500] loss: 0.037800499388977185
[Epoch 6, Batch 2600] loss: 0.04050831561893574
[Epoch 6, Batch 2700] loss: 0.04233484094627784
[Epoch 6, Batch 2800] loss: 0.03932009261465282
[Epoch 6, Batch 2900] loss: 0.023940886107739062
[Epoch 6, Batch 3000] loss: 0.029827601864017197
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9835
Overfitting: 0.0556
Best model saved at epoch 6 with validation loss: 0.0556
[Epoch 7, Batch 100] loss: 0.03071676854036923
[Epoch 7, Batch 200] loss: 0.023609162345092045
[Epoch 7, Batch 300] loss: 0.020994439152418637
[Epoch 7, Batch 400] loss: 0.025956477049403473
[Epoch 7, Batch 500] loss: 0.02457953787434235
[Epoch 7, Batch 600] loss: 0.013468248576282349
[Epoch 7, Batch 700] loss: 0.03470561761780118
[Epoch 7, Batch 800] loss: 0.027030991606270618
[Epoch 7, Batch 900] loss: 0.025963053286395733
[Epoch 7, Batch 1000] loss: 0.02262964581619599
[Epoch 7, Batch 1100] loss: 0.03561482270979468
[Epoch 7, Batch 1200] loss: 0.03376478453181335
[Epoch 7, Batch 1300] loss: 0.025215107295953203
[Epoch 7, Batch 1400] loss: 0.020351082556444453
[Epoch 7, Batch 1500] loss: 0.025347818833615747
[Epoch 7, Batch 1600] loss: 0.02977384208876174
[Epoch 7, Batch 1700] loss: 0.03293215340519964
[Epoch 7, Batch 1800] loss: 0.034438627626986996
[Epoch 7, Batch 1900] loss: 0.050911759363407326
[Epoch 7, Batch 2000] loss: 0.035510510113454075
[Epoch 7, Batch 2100] loss: 0.0287482761470892
[Epoch 7, Batch 2200] loss: 0.03140499584464124
[Epoch 7, Batch 2300] loss: 0.04131791134612286
[Epoch 7, Batch 2400] loss: 0.030164714084385195
[Epoch 7, Batch 2500] loss: 0.02688876878391966
[Epoch 7, Batch 2600] loss: 0.03032785051091196
[Epoch 7, Batch 2700] loss: 0.03676642010224896
[Epoch 7, Batch 2800] loss: 0.02183471329186432
[Epoch 7, Batch 2900] loss: 0.02041777694266784
[Epoch 7, Batch 3000] loss: 0.052109762278705604
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0640
Validation Accuracy: 0.9832
Overfitting: 0.0640
[Epoch 8, Batch 100] loss: 0.01967907293445023
[Epoch 8, Batch 200] loss: 0.01806192122727225
[Epoch 8, Batch 300] loss: 0.017138393785135122
[Epoch 8, Batch 400] loss: 0.030328062625267195
[Epoch 8, Batch 500] loss: 0.02083705985103734
[Epoch 8, Batch 600] loss: 0.02254268183218301
[Epoch 8, Batch 700] loss: 0.027171496472910804
[Epoch 8, Batch 800] loss: 0.024289489504863013
[Epoch 8, Batch 900] loss: 0.030678842182460357
[Epoch 8, Batch 1000] loss: 0.02320830910497534
[Epoch 8, Batch 1100] loss: 0.016926313016183483
[Epoch 8, Batch 1200] loss: 0.022722648264789314
[Epoch 8, Batch 1300] loss: 0.035009571506125214
[Epoch 8, Batch 1400] loss: 0.026336530794797
[Epoch 8, Batch 1500] loss: 0.03844699717708863
[Epoch 8, Batch 1600] loss: 0.025382619932715896
[Epoch 8, Batch 1700] loss: 0.018603050467754657
[Epoch 8, Batch 1800] loss: 0.02368345457383384
[Epoch 8, Batch 1900] loss: 0.01557096306758467
[Epoch 8, Batch 2000] loss: 0.04009043411966559
[Epoch 8, Batch 2100] loss: 0.031081184953072806
[Epoch 8, Batch 2200] loss: 0.025375075393749284
[Epoch 8, Batch 2300] loss: 0.03197062944167556
[Epoch 8, Batch 2400] loss: 0.026044959390710574
[Epoch 8, Batch 2500] loss: 0.02047343076155812
[Epoch 8, Batch 2600] loss: 0.023910440327636024
[Epoch 8, Batch 2700] loss: 0.0300050604948774
[Epoch 8, Batch 2800] loss: 0.019819560253272358
[Epoch 8, Batch 2900] loss: 0.01716909892256808
[Epoch 8, Batch 3000] loss: 0.02810589921235078
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9851
Overfitting: 0.0546
Best model saved at epoch 8 with validation loss: 0.0546
[Epoch 9, Batch 100] loss: 0.015711388693744083
[Epoch 9, Batch 200] loss: 0.006945988628631312
[Epoch 9, Batch 300] loss: 0.027514406906093428
[Epoch 9, Batch 400] loss: 0.019530875605296386
[Epoch 9, Batch 500] loss: 0.02168172500187211
[Epoch 9, Batch 600] loss: 0.01909418792820361
[Epoch 9, Batch 700] loss: 0.018557032584867558
[Epoch 9, Batch 800] loss: 0.01762623442265067
[Epoch 9, Batch 900] loss: 0.01788294556818073
[Epoch 9, Batch 1000] loss: 0.020396736660095484
[Epoch 9, Batch 1100] loss: 0.016041945130691602
[Epoch 9, Batch 1200] loss: 0.023100212653262134
[Epoch 9, Batch 1300] loss: 0.025490175943596115
[Epoch 9, Batch 1400] loss: 0.02275103094707447
[Epoch 9, Batch 1500] loss: 0.01861293102399941
[Epoch 9, Batch 1600] loss: 0.016838052187376887
[Epoch 9, Batch 1700] loss: 0.030464733797780353
[Epoch 9, Batch 1800] loss: 0.025464805054216413
[Epoch 9, Batch 1900] loss: 0.02535239621933215
[Epoch 9, Batch 2000] loss: 0.028242535991521437
[Epoch 9, Batch 2100] loss: 0.01752536719367072
[Epoch 9, Batch 2200] loss: 0.025331511304611923
[Epoch 9, Batch 2300] loss: 0.03327765475900378
[Epoch 9, Batch 2400] loss: 0.027919579518384127
[Epoch 9, Batch 2500] loss: 0.023185268684646872
[Epoch 9, Batch 2600] loss: 0.026677834406145847
[Epoch 9, Batch 2700] loss: 0.022773667717465286
[Epoch 9, Batch 2800] loss: 0.025332115338605944
[Epoch 9, Batch 2900] loss: 0.017066847362948466
[Epoch 9, Batch 3000] loss: 0.024722524252501897
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0783
Validation Accuracy: 0.9789
Overfitting: 0.0783
[Epoch 10, Batch 100] loss: 0.032410521866477214
[Epoch 10, Batch 200] loss: 0.008821981359988058
[Epoch 10, Batch 300] loss: 0.006977725795441075
[Epoch 10, Batch 400] loss: 0.02035619198344648
[Epoch 10, Batch 500] loss: 0.010930986342209507
[Epoch 10, Batch 600] loss: 0.014960047805525392
[Epoch 10, Batch 700] loss: 0.02516859354576809
[Epoch 10, Batch 800] loss: 0.016413818569599243
[Epoch 10, Batch 900] loss: 0.025929699296339096
[Epoch 10, Batch 1000] loss: 0.014101975472931372
[Epoch 10, Batch 1100] loss: 0.016884416661159776
[Epoch 10, Batch 1200] loss: 0.009234231882592212
[Epoch 10, Batch 1300] loss: 0.010828841929587725
[Epoch 10, Batch 1400] loss: 0.019822155886395194
[Epoch 10, Batch 1500] loss: 0.014027212501760004
[Epoch 10, Batch 1600] loss: 0.011223018658620276
[Epoch 10, Batch 1700] loss: 0.01182535039398772
[Epoch 10, Batch 1800] loss: 0.019382124622566152
[Epoch 10, Batch 1900] loss: 0.01842927877031798
[Epoch 10, Batch 2000] loss: 0.02979044711941242
[Epoch 10, Batch 2100] loss: 0.013244004316352403
[Epoch 10, Batch 2200] loss: 0.013070317632082152
[Epoch 10, Batch 2300] loss: 0.034917956502577
[Epoch 10, Batch 2400] loss: 0.015237560802743246
[Epoch 10, Batch 2500] loss: 0.011030803959693003
[Epoch 10, Batch 2600] loss: 0.012048191180024332
[Epoch 10, Batch 2700] loss: 0.02064609469662173
[Epoch 10, Batch 2800] loss: 0.027084915192917832
[Epoch 10, Batch 2900] loss: 0.0295656400263033
[Epoch 10, Batch 3000] loss: 0.017295087596266967
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9860
Overfitting: 0.0525
Best model saved at epoch 10 with validation loss: 0.0525
[Epoch 11, Batch 100] loss: 0.009250842106193886
[Epoch 11, Batch 200] loss: 0.01115011065913677
[Epoch 11, Batch 300] loss: 0.01022863706667522
[Epoch 11, Batch 400] loss: 0.006154934867199699
[Epoch 11, Batch 500] loss: 0.010336555805656645
[Epoch 11, Batch 600] loss: 0.017787883064002016
[Epoch 11, Batch 700] loss: 0.011291380390039194
[Epoch 11, Batch 800] loss: 0.0107191296318706
[Epoch 11, Batch 900] loss: 0.016168092723025895
[Epoch 11, Batch 1000] loss: 0.009826244691339525
[Epoch 11, Batch 1100] loss: 0.015126346493530037
[Epoch 11, Batch 1200] loss: 0.011605811192466717
[Epoch 11, Batch 1300] loss: 0.016216456221941372
[Epoch 11, Batch 1400] loss: 0.009209735413946873
[Epoch 11, Batch 1500] loss: 0.0162313128683445
[Epoch 11, Batch 1600] loss: 0.020200028248600576
[Epoch 11, Batch 1700] loss: 0.028861815665254652
[Epoch 11, Batch 1800] loss: 0.01587908663465896
[Epoch 11, Batch 1900] loss: 0.013819098381190997
[Epoch 11, Batch 2000] loss: 0.015128409552326048
[Epoch 11, Batch 2100] loss: 0.026759158350278086
[Epoch 11, Batch 2200] loss: 0.016817029327739874
[Epoch 11, Batch 2300] loss: 0.014450373154213594
[Epoch 11, Batch 2400] loss: 0.01651926311159514
[Epoch 11, Batch 2500] loss: 0.015162619375496433
[Epoch 11, Batch 2600] loss: 0.013355436692263538
[Epoch 11, Batch 2700] loss: 0.009793664107274936
[Epoch 11, Batch 2800] loss: 0.020266847571028847
[Epoch 11, Batch 2900] loss: 0.008151758350841191
[Epoch 11, Batch 3000] loss: 0.022195879951059396
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0720
Validation Accuracy: 0.9815
Overfitting: 0.0720
[Epoch 12, Batch 100] loss: 0.016245431929364715
[Epoch 12, Batch 200] loss: 0.014847947912949166
[Epoch 12, Batch 300] loss: 0.013238224402130072
[Epoch 12, Batch 400] loss: 0.008152828492138725
[Epoch 12, Batch 500] loss: 0.02533295770024779
[Epoch 12, Batch 600] loss: 0.014889972260843933
[Epoch 12, Batch 700] loss: 0.009321036317724065
[Epoch 12, Batch 800] loss: 0.010123460424183576
[Epoch 12, Batch 900] loss: 0.008187958630996946
[Epoch 12, Batch 1000] loss: 0.006489827251389215
[Epoch 12, Batch 1100] loss: 0.007841039013237605
[Epoch 12, Batch 1200] loss: 0.021109168619641423
[Epoch 12, Batch 1300] loss: 0.010926688119354822
[Epoch 12, Batch 1400] loss: 0.01604384186061452
[Epoch 12, Batch 1500] loss: 0.01459756378016209
[Epoch 12, Batch 1600] loss: 0.012799011322772457
[Epoch 12, Batch 1700] loss: 0.009209493220719196
[Epoch 12, Batch 1800] loss: 0.02094809285630163
[Epoch 12, Batch 1900] loss: 0.013285686163208084
[Epoch 12, Batch 2000] loss: 0.012711938495472168
[Epoch 12, Batch 2100] loss: 0.019309515139423184
[Epoch 12, Batch 2200] loss: 0.009877019374475821
[Epoch 12, Batch 2300] loss: 0.011863066205924042
[Epoch 12, Batch 2400] loss: 0.011677609379244131
[Epoch 12, Batch 2500] loss: 0.015453464680720118
[Epoch 12, Batch 2600] loss: 0.01920102962488727
[Epoch 12, Batch 2700] loss: 0.018527629076720585
[Epoch 12, Batch 2800] loss: 0.01250227129441555
[Epoch 12, Batch 2900] loss: 0.02377190082609559
[Epoch 12, Batch 3000] loss: 0.01487622480392929
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0668
Validation Accuracy: 0.9828
Overfitting: 0.0668
[Epoch 13, Batch 100] loss: 0.012417305228973418
[Epoch 13, Batch 200] loss: 0.015234925739578102
[Epoch 13, Batch 300] loss: 0.023136870097496286
[Epoch 13, Batch 400] loss: 0.010835334995472295
[Epoch 13, Batch 500] loss: 0.009392678565764073
[Epoch 13, Batch 600] loss: 0.009388012611611884
[Epoch 13, Batch 700] loss: 0.013429554979350087
[Epoch 13, Batch 800] loss: 0.022761958666333158
[Epoch 13, Batch 900] loss: 0.013219528303707193
[Epoch 13, Batch 1000] loss: 0.009766437986863821
[Epoch 13, Batch 1100] loss: 0.009595281650738342
[Epoch 13, Batch 1200] loss: 0.009454612562813054
[Epoch 13, Batch 1300] loss: 0.013174457206287116
[Epoch 13, Batch 1400] loss: 0.017032003390895625
[Epoch 13, Batch 1500] loss: 0.006953775206611681
[Epoch 13, Batch 1600] loss: 0.01777485434655773
[Epoch 13, Batch 1700] loss: 0.009475909615030104
[Epoch 13, Batch 1800] loss: 0.00555155883593784
[Epoch 13, Batch 1900] loss: 0.007006221687211109
[Epoch 13, Batch 2000] loss: 0.0058852971192209225
[Epoch 13, Batch 2100] loss: 0.010786302251369761
[Epoch 13, Batch 2200] loss: 0.011143902706053269
[Epoch 13, Batch 2300] loss: 0.016357338362756765
[Epoch 13, Batch 2400] loss: 0.011462547151586478
[Epoch 13, Batch 2500] loss: 0.016774573654204233
[Epoch 13, Batch 2600] loss: 0.016343815793813974
[Epoch 13, Batch 2700] loss: 0.013814479972206755
[Epoch 13, Batch 2800] loss: 0.011889647335947303
[Epoch 13, Batch 2900] loss: 0.026285620861723372
[Epoch 13, Batch 3000] loss: 0.01293769287429086
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9846
Overfitting: 0.0592
[Epoch 14, Batch 100] loss: 0.01109488393065476
[Epoch 14, Batch 200] loss: 0.0070539135401895695
[Epoch 14, Batch 300] loss: 0.006614110635237012
[Epoch 14, Batch 400] loss: 0.007403997962212543
[Epoch 14, Batch 500] loss: 0.006144049330419534
[Epoch 14, Batch 600] loss: 0.010285201914634855
[Epoch 14, Batch 700] loss: 0.013995794176082654
[Epoch 14, Batch 800] loss: 0.00674299073462862
[Epoch 14, Batch 900] loss: 0.00820066462986233
[Epoch 14, Batch 1000] loss: 0.0061222224365656075
[Epoch 14, Batch 1100] loss: 0.017831270016790766
[Epoch 14, Batch 1200] loss: 0.010122541181101497
[Epoch 14, Batch 1300] loss: 0.0059041599181648505
[Epoch 14, Batch 1400] loss: 0.005722053883400804
[Epoch 14, Batch 1500] loss: 0.009753071691418426
[Epoch 14, Batch 1600] loss: 0.007246504405966334
[Epoch 14, Batch 1700] loss: 0.008226659481286163
[Epoch 14, Batch 1800] loss: 0.012905242561585055
[Epoch 14, Batch 1900] loss: 0.018763082796365325
[Epoch 14, Batch 2000] loss: 0.004495233886316328
[Epoch 14, Batch 2100] loss: 0.015192270226420987
[Epoch 14, Batch 2200] loss: 0.005217673050906342
[Epoch 14, Batch 2300] loss: 0.02291658537713829
[Epoch 14, Batch 2400] loss: 0.016348347736179675
[Epoch 14, Batch 2500] loss: 0.019422960380866244
[Epoch 14, Batch 2600] loss: 0.014651974021481919
[Epoch 14, Batch 2700] loss: 0.009942646694867677
[Epoch 14, Batch 2800] loss: 0.011832765272929464
[Epoch 14, Batch 2900] loss: 0.012536174360152473
[Epoch 14, Batch 3000] loss: 0.014875235257542273
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0753
Validation Accuracy: 0.9833
Overfitting: 0.0753
[Epoch 15, Batch 100] loss: 0.012520113830646551
[Epoch 15, Batch 200] loss: 0.0037733487930267985
[Epoch 15, Batch 300] loss: 0.00835438764299795
[Epoch 15, Batch 400] loss: 0.007483584138865354
[Epoch 15, Batch 500] loss: 0.01681463545754809
[Epoch 15, Batch 600] loss: 0.0044944222829468574
[Epoch 15, Batch 700] loss: 0.011253983781537046
[Epoch 15, Batch 800] loss: 0.0076517196556244475
[Epoch 15, Batch 900] loss: 0.008719014513800402
[Epoch 15, Batch 1000] loss: 0.0036342754391671408
[Epoch 15, Batch 1100] loss: 0.005283327822008346
[Epoch 15, Batch 1200] loss: 0.010103301561383518
[Epoch 15, Batch 1300] loss: 0.011308986883010448
[Epoch 15, Batch 1400] loss: 0.017101809013752814
[Epoch 15, Batch 1500] loss: 0.002215488313900096
[Epoch 15, Batch 1600] loss: 0.007032182769244173
[Epoch 15, Batch 1700] loss: 0.003967916100846196
[Epoch 15, Batch 1800] loss: 0.006412261578898324
[Epoch 15, Batch 1900] loss: 0.010646041425475232
[Epoch 15, Batch 2000] loss: 0.004690755326330418
[Epoch 15, Batch 2100] loss: 0.014064851633165745
[Epoch 15, Batch 2200] loss: 0.006976652207465577
[Epoch 15, Batch 2300] loss: 0.007730485415120256
[Epoch 15, Batch 2400] loss: 0.021022741987167137
[Epoch 15, Batch 2500] loss: 0.02186821367015227
[Epoch 15, Batch 2600] loss: 0.012609089494417277
[Epoch 15, Batch 2700] loss: 0.010886822388893052
[Epoch 15, Batch 2800] loss: 0.017420258062779793
[Epoch 15, Batch 2900] loss: 0.012342188902421185
[Epoch 15, Batch 3000] loss: 0.005739668386349876
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0571
Validation Accuracy: 0.9866
Overfitting: 0.0571
[Epoch 16, Batch 100] loss: 0.0030060308099382383
[Epoch 16, Batch 200] loss: 0.006635550693838468
[Epoch 16, Batch 300] loss: 0.005256629066483925
[Epoch 16, Batch 400] loss: 0.006170159548911083
[Epoch 16, Batch 500] loss: 0.00563323291092729
[Epoch 16, Batch 600] loss: 0.009113985716224989
[Epoch 16, Batch 700] loss: 0.007200142801968923
[Epoch 16, Batch 800] loss: 0.004267915339826231
[Epoch 16, Batch 900] loss: 0.0070205224385216525
[Epoch 16, Batch 1000] loss: 0.008196069462750302
[Epoch 16, Batch 1100] loss: 0.027360191013848408
[Epoch 16, Batch 1200] loss: 0.010292551328971057
[Epoch 16, Batch 1300] loss: 0.007583725821934308
[Epoch 16, Batch 1400] loss: 0.00774140502000023
[Epoch 16, Batch 1500] loss: 0.010244398806464687
[Epoch 16, Batch 1600] loss: 0.016582868149932893
[Epoch 16, Batch 1700] loss: 0.0034699912313681126
[Epoch 16, Batch 1800] loss: 0.004431817687543571
[Epoch 16, Batch 1900] loss: 0.008308942303277717
[Epoch 16, Batch 2000] loss: 0.008718752791367024
[Epoch 16, Batch 2100] loss: 0.005774385425623905
[Epoch 16, Batch 2200] loss: 0.011854263488526157
[Epoch 16, Batch 2300] loss: 0.015143745733660126
[Epoch 16, Batch 2400] loss: 0.008240431905985588
[Epoch 16, Batch 2500] loss: 0.013405742717916383
[Epoch 16, Batch 2600] loss: 0.020662612436872223
[Epoch 16, Batch 2700] loss: 0.017177797460659575
[Epoch 16, Batch 2800] loss: 0.020290843253421828
[Epoch 16, Batch 2900] loss: 0.009519451174780898
[Epoch 16, Batch 3000] loss: 0.017508247360524365
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0817
Validation Accuracy: 0.9805
Overfitting: 0.0817
[Epoch 17, Batch 100] loss: 0.007263939603426479
[Epoch 17, Batch 200] loss: 0.00520833276625126
[Epoch 17, Batch 300] loss: 0.006580673223933502
[Epoch 17, Batch 400] loss: 0.011560419478779522
[Epoch 17, Batch 500] loss: 0.00489082777692829
[Epoch 17, Batch 600] loss: 0.013409667830911331
[Epoch 17, Batch 700] loss: 0.00804744616957521
[Epoch 17, Batch 800] loss: 0.008034595805834216
[Epoch 17, Batch 900] loss: 0.005189130302690614
[Epoch 17, Batch 1000] loss: 0.005182901284746606
[Epoch 17, Batch 1100] loss: 0.015003934198792592
[Epoch 17, Batch 1200] loss: 0.007268257882201396
[Epoch 17, Batch 1300] loss: 0.011964537083136407
[Epoch 17, Batch 1400] loss: 0.008814963841383588
[Epoch 17, Batch 1500] loss: 0.005606548798800759
[Epoch 17, Batch 1600] loss: 0.013635011540362712
[Epoch 17, Batch 1700] loss: 0.0109904269009877
[Epoch 17, Batch 1800] loss: 0.004496561526011646
[Epoch 17, Batch 1900] loss: 0.010148650230178618
[Epoch 17, Batch 2000] loss: 0.006536638703171321
[Epoch 17, Batch 2100] loss: 0.00928125439415659
[Epoch 17, Batch 2200] loss: 0.011801988289746532
[Epoch 17, Batch 2300] loss: 0.007516437067924926
[Epoch 17, Batch 2400] loss: 0.011323785401934287
[Epoch 17, Batch 2500] loss: 0.006026392584437872
[Epoch 17, Batch 2600] loss: 0.0044288812266536585
[Epoch 17, Batch 2700] loss: 0.006310463669395574
[Epoch 17, Batch 2800] loss: 0.005215526428830799
[Epoch 17, Batch 2900] loss: 0.006871881012048391
[Epoch 17, Batch 3000] loss: 0.013533962077935939
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0682
Validation Accuracy: 0.9850
Overfitting: 0.0682
[Epoch 18, Batch 100] loss: 0.006512988912688798
[Epoch 18, Batch 200] loss: 0.005354272635996011
[Epoch 18, Batch 300] loss: 0.006393182342881118
[Epoch 18, Batch 400] loss: 0.00508010103458318
[Epoch 18, Batch 500] loss: 0.010575364962721778
[Epoch 18, Batch 600] loss: 0.005247625747407483
[Epoch 18, Batch 700] loss: 0.00936324259830478
[Epoch 18, Batch 800] loss: 0.00522179916409641
[Epoch 18, Batch 900] loss: 0.01014978692002927
[Epoch 18, Batch 1000] loss: 0.0029241909199049588
[Epoch 18, Batch 1100] loss: 0.0021489082964569663
[Epoch 18, Batch 1200] loss: 0.0033660357392087505
[Epoch 18, Batch 1300] loss: 0.0049240844001082
[Epoch 18, Batch 1400] loss: 0.004782034769129666
[Epoch 18, Batch 1500] loss: 0.008690331231928212
[Epoch 18, Batch 1600] loss: 0.007684129232909526
[Epoch 18, Batch 1700] loss: 0.006234408093566231
[Epoch 18, Batch 1800] loss: 0.009159490837075169
[Epoch 18, Batch 1900] loss: 0.008222087132208173
[Epoch 18, Batch 2000] loss: 0.002186237961526558
[Epoch 18, Batch 2100] loss: 0.0029704282296120254
[Epoch 18, Batch 2200] loss: 0.004901606938400676
[Epoch 18, Batch 2300] loss: 0.0040340272202729465
[Epoch 18, Batch 2400] loss: 0.010486064829765667
[Epoch 18, Batch 2500] loss: 0.004648886255935168
[Epoch 18, Batch 2600] loss: 0.013513560600228515
[Epoch 18, Batch 2700] loss: 0.012412861674848159
[Epoch 18, Batch 2800] loss: 0.009772456716145825
[Epoch 18, Batch 2900] loss: 0.002854458899940937
[Epoch 18, Batch 3000] loss: 0.012768762228319873
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0652
Validation Accuracy: 0.9859
Overfitting: 0.0652
[Epoch 19, Batch 100] loss: 0.01322987551321944
[Epoch 19, Batch 200] loss: 0.005848782271854418
[Epoch 19, Batch 300] loss: 0.004400963260654862
[Epoch 19, Batch 400] loss: 0.003210130446175583
[Epoch 19, Batch 500] loss: 0.008776465922425132
[Epoch 19, Batch 600] loss: 0.0039965113666221444
[Epoch 19, Batch 700] loss: 0.003667217984349662
[Epoch 19, Batch 800] loss: 0.004177411974394545
[Epoch 19, Batch 900] loss: 0.0064540458541870295
[Epoch 19, Batch 1000] loss: 0.006104530179871404
[Epoch 19, Batch 1100] loss: 0.0037670284823536804
[Epoch 19, Batch 1200] loss: 0.007771590352440398
[Epoch 19, Batch 1300] loss: 0.0020394112708515878
[Epoch 19, Batch 1400] loss: 0.009556769009540958
[Epoch 19, Batch 1500] loss: 0.00958379062546726
[Epoch 19, Batch 1600] loss: 0.005646246488281293
[Epoch 19, Batch 1700] loss: 0.004664493633280742
[Epoch 19, Batch 1800] loss: 0.014559996727917905
[Epoch 19, Batch 1900] loss: 0.005281813168565179
[Epoch 19, Batch 2000] loss: 0.003219953613493303
[Epoch 19, Batch 2100] loss: 0.009287247852595755
[Epoch 19, Batch 2200] loss: 0.007616772363925293
[Epoch 19, Batch 2300] loss: 0.004315066493807933
[Epoch 19, Batch 2400] loss: 0.002499181983025558
[Epoch 19, Batch 2500] loss: 0.0031944779685190382
[Epoch 19, Batch 2600] loss: 0.0043027731578591496
[Epoch 19, Batch 2700] loss: 0.007877787273354642
[Epoch 19, Batch 2800] loss: 0.001804337379758323
[Epoch 19, Batch 2900] loss: 0.007618064926425627
[Epoch 19, Batch 3000] loss: 0.007883737744683685
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0767
Validation Accuracy: 0.9852
Overfitting: 0.0767
[Epoch 20, Batch 100] loss: 0.0039640703804272445
[Epoch 20, Batch 200] loss: 0.0030714207908567916
[Epoch 20, Batch 300] loss: 0.0019002783095302788
[Epoch 20, Batch 400] loss: 0.00199354697578201
[Epoch 20, Batch 500] loss: 0.0037808039498249714
[Epoch 20, Batch 600] loss: 0.002046250026709231
[Epoch 20, Batch 700] loss: 0.005302824085697111
[Epoch 20, Batch 800] loss: 0.0072554066480023495
[Epoch 20, Batch 900] loss: 0.00339396832930845
[Epoch 20, Batch 1000] loss: 0.005357507694593764
[Epoch 20, Batch 1100] loss: 0.007768044864489525
[Epoch 20, Batch 1200] loss: 0.008238995811162511
[Epoch 20, Batch 1300] loss: 0.004133184484137047
[Epoch 20, Batch 1400] loss: 0.0035265734084677547
[Epoch 20, Batch 1500] loss: 0.006332627701201821
[Epoch 20, Batch 1600] loss: 0.006388019584522766
[Epoch 20, Batch 1700] loss: 0.001900055358433974
[Epoch 20, Batch 1800] loss: 0.0018941442819313892
[Epoch 20, Batch 1900] loss: 0.0009022910983321708
[Epoch 20, Batch 2000] loss: 0.0013463692594057974
[Epoch 20, Batch 2100] loss: 0.009748624786921027
[Epoch 20, Batch 2200] loss: 0.007854865230783546
[Epoch 20, Batch 2300] loss: 0.0024529921611292594
[Epoch 20, Batch 2400] loss: 0.0022656117201549364
[Epoch 20, Batch 2500] loss: 0.006321143238500042
[Epoch 20, Batch 2600] loss: 0.00312015202319742
[Epoch 20, Batch 2700] loss: 0.01630489280689928
[Epoch 20, Batch 2800] loss: 0.010630291081930067
[Epoch 20, Batch 2900] loss: 0.0057064126899399525
[Epoch 20, Batch 3000] loss: 0.003828173467031206
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0725
Validation Accuracy: 0.9869
Overfitting: 0.0725
[Epoch 21, Batch 100] loss: 0.009640047862766891
[Epoch 21, Batch 200] loss: 0.001229154302649249
[Epoch 21, Batch 300] loss: 0.002908190344202524
[Epoch 21, Batch 400] loss: 0.004298259036106203
[Epoch 21, Batch 500] loss: 0.0015943435384730264
[Epoch 21, Batch 600] loss: 0.004074666442053427
[Epoch 21, Batch 700] loss: 0.011169715766970966
[Epoch 21, Batch 800] loss: 0.0036593705371839747
[Epoch 21, Batch 900] loss: 0.0028869279620752763
[Epoch 21, Batch 1000] loss: 0.002869793415472941
[Epoch 21, Batch 1100] loss: 0.00806073969981192
[Epoch 21, Batch 1200] loss: 0.004309290027463533
[Epoch 21, Batch 1300] loss: 0.00785564765770598
[Epoch 21, Batch 1400] loss: 0.00970533826902539
[Epoch 21, Batch 1500] loss: 0.004882600366287875
[Epoch 21, Batch 1600] loss: 0.007506392619656594
[Epoch 21, Batch 1700] loss: 0.008137866544732902
[Epoch 21, Batch 1800] loss: 0.002820812815655245
[Epoch 21, Batch 1900] loss: 0.006143488121549012
[Epoch 21, Batch 2000] loss: 0.006256093219182759
[Epoch 21, Batch 2100] loss: 0.007463983133113743
[Epoch 21, Batch 2200] loss: 0.0027719363485728186
[Epoch 21, Batch 2300] loss: 0.009295565766146008
[Epoch 21, Batch 2400] loss: 0.004026635833599812
[Epoch 21, Batch 2500] loss: 0.0041947900349472884
[Epoch 21, Batch 2600] loss: 0.006584497935511564
[Epoch 21, Batch 2700] loss: 0.006523753144788032
[Epoch 21, Batch 2800] loss: 0.003465384681958277
[Epoch 21, Batch 2900] loss: 0.008007037947227645
[Epoch 21, Batch 3000] loss: 0.009045650834229093
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0777
Validation Accuracy: 0.9858
Overfitting: 0.0777
[Epoch 22, Batch 100] loss: 0.003394772945437268
[Epoch 22, Batch 200] loss: 0.0022085815940292262
[Epoch 22, Batch 300] loss: 0.0043940256366173
[Epoch 22, Batch 400] loss: 0.011986553398353124
[Epoch 22, Batch 500] loss: 0.0025793005905474153
[Epoch 22, Batch 600] loss: 0.003843625853147863
[Epoch 22, Batch 700] loss: 0.0018023655544149619
[Epoch 22, Batch 800] loss: 0.00564161557569129
[Epoch 22, Batch 900] loss: 0.0062233411796557905
[Epoch 22, Batch 1000] loss: 0.0020954680587813622
[Epoch 22, Batch 1100] loss: 0.001576417073646388
[Epoch 22, Batch 1200] loss: 0.0013383363126465043
[Epoch 22, Batch 1300] loss: 0.0022704027333876374
[Epoch 22, Batch 1400] loss: 0.0036997429045476336
[Epoch 22, Batch 1500] loss: 0.001077179897766314
[Epoch 22, Batch 1600] loss: 0.004062444312297009
[Epoch 22, Batch 1700] loss: 0.004497298583251368
[Epoch 22, Batch 1800] loss: 0.0035720701741341187
[Epoch 22, Batch 1900] loss: 0.0027881854555274897
[Epoch 22, Batch 2000] loss: 0.0018308440929743952
[Epoch 22, Batch 2100] loss: 0.0025480524020969142
[Epoch 22, Batch 2200] loss: 0.002409259552436538
[Epoch 22, Batch 2300] loss: 0.005841997464390189
[Epoch 22, Batch 2400] loss: 0.0026717428366984566
[Epoch 22, Batch 2500] loss: 0.0013541989177818258
[Epoch 22, Batch 2600] loss: 0.0025872492796317204
[Epoch 22, Batch 2700] loss: 0.0012167957343479684
[Epoch 22, Batch 2800] loss: 0.0011087224532997553
[Epoch 22, Batch 2900] loss: 0.0034517463342338094
[Epoch 22, Batch 3000] loss: 0.0016939985738983053
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0685
Validation Accuracy: 0.9871
Overfitting: 0.0685
[Epoch 23, Batch 100] loss: 0.0008216489691562812
[Epoch 23, Batch 200] loss: 0.0009757873363249026
[Epoch 23, Batch 300] loss: 0.002124275943771465
[Epoch 23, Batch 400] loss: 0.0024593167994906517
[Epoch 23, Batch 500] loss: 0.002929667954716093
[Epoch 23, Batch 600] loss: 0.0034627964468474204
[Epoch 23, Batch 700] loss: 0.003178968886762572
[Epoch 23, Batch 800] loss: 0.0004926512275132877
[Epoch 23, Batch 900] loss: 0.0018054957749235356
[Epoch 23, Batch 1000] loss: 0.0014999016627970008
[Epoch 23, Batch 1100] loss: 0.0012668467758846801
[Epoch 23, Batch 1200] loss: 0.0011255693779430942
[Epoch 23, Batch 1300] loss: 0.0005617775146551018
[Epoch 23, Batch 1400] loss: 0.0020812156231685064
[Epoch 23, Batch 1500] loss: 0.001004775187216147
[Epoch 23, Batch 1600] loss: 0.000896773761776899
[Epoch 23, Batch 1700] loss: 0.0007568925157382012
[Epoch 23, Batch 1800] loss: 0.0006908483467261339
[Epoch 23, Batch 1900] loss: 0.0008271822249917982
[Epoch 23, Batch 2000] loss: 0.006349617529330374
[Epoch 23, Batch 2100] loss: 0.0016599914220571143
[Epoch 23, Batch 2200] loss: 0.003991985436676729
[Epoch 23, Batch 2300] loss: 0.00039957384489213154
[Epoch 23, Batch 2400] loss: 0.0007729054230920696
[Epoch 23, Batch 2500] loss: 0.0009395826018125142
[Epoch 23, Batch 2600] loss: 0.00034845017121594603
[Epoch 23, Batch 2700] loss: 0.0003006856339441555
[Epoch 23, Batch 2800] loss: 0.002990384348731352
[Epoch 23, Batch 2900] loss: 0.0046451205331277026
[Epoch 23, Batch 3000] loss: 0.0012858316294727956
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0735
Validation Accuracy: 0.9873
Overfitting: 0.0735
[Epoch 24, Batch 100] loss: 0.0005881249048680104
[Epoch 24, Batch 200] loss: 0.0008071917598848399
[Epoch 24, Batch 300] loss: 0.0011466575004691394
[Epoch 24, Batch 400] loss: 0.0009281617661407893
[Epoch 24, Batch 500] loss: 0.00045026130413130974
[Epoch 24, Batch 600] loss: 0.0004409062012080511
[Epoch 24, Batch 700] loss: 0.000712306833511711
[Epoch 24, Batch 800] loss: 0.0005756646280355681
[Epoch 24, Batch 900] loss: 0.0007079768602527192
[Epoch 24, Batch 1000] loss: 0.0006084684546745222
[Epoch 24, Batch 1100] loss: 0.00034684874571262015
[Epoch 24, Batch 1200] loss: 0.0003719767942353469
[Epoch 24, Batch 1300] loss: 0.00046150057559182225
[Epoch 24, Batch 1400] loss: 0.0007836553799257384
[Epoch 24, Batch 1500] loss: 0.0005950072126996275
[Epoch 24, Batch 1600] loss: 0.0007590323510742536
[Epoch 24, Batch 1700] loss: 0.0012285551045665554
[Epoch 24, Batch 1800] loss: 0.003099913350478589
[Epoch 24, Batch 1900] loss: 0.0007596827908888316
[Epoch 24, Batch 2000] loss: 0.0016685028460521423
[Epoch 24, Batch 2100] loss: 0.0006301292819325787
[Epoch 24, Batch 2200] loss: 0.0006610564349237791
[Epoch 24, Batch 2300] loss: 0.000310230771552531
[Epoch 24, Batch 2400] loss: 0.0003522765397265415
[Epoch 24, Batch 2500] loss: 0.0005005954452297301
[Epoch 24, Batch 2600] loss: 0.0005835158771955928
[Epoch 24, Batch 2700] loss: 0.005404264659850413
[Epoch 24, Batch 2800] loss: 0.0014268271493008244
[Epoch 24, Batch 2900] loss: 0.0006360084359663132
[Epoch 24, Batch 3000] loss: 0.0007734418630526419
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0741
Validation Accuracy: 0.9875
Overfitting: 0.0741
Fold 2 validation loss: 0.0741
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.300427982807159
[Epoch 1, Batch 200] loss: 2.2810012745857238
[Epoch 1, Batch 300] loss: 2.185127531290054
[Epoch 1, Batch 400] loss: 1.3284338986873627
[Epoch 1, Batch 500] loss: 0.6050147531926632
[Epoch 1, Batch 600] loss: 0.5100350746512413
[Epoch 1, Batch 700] loss: 0.3948883153498173
[Epoch 1, Batch 800] loss: 0.36422316141426564
[Epoch 1, Batch 900] loss: 0.29301677552983163
[Epoch 1, Batch 1000] loss: 0.2629598187096417
[Epoch 1, Batch 1100] loss: 0.27631224067881704
[Epoch 1, Batch 1200] loss: 0.21777117889374495
[Epoch 1, Batch 1300] loss: 0.19463733456097543
[Epoch 1, Batch 1400] loss: 0.17921966400463135
[Epoch 1, Batch 1500] loss: 0.17732758911326527
[Epoch 1, Batch 1600] loss: 0.17652802740223705
[Epoch 1, Batch 1700] loss: 0.1788286126870662
[Epoch 1, Batch 1800] loss: 0.14653517057187856
[Epoch 1, Batch 1900] loss: 0.1581149213248864
[Epoch 1, Batch 2000] loss: 0.15864402547013015
[Epoch 1, Batch 2100] loss: 0.13542054355842992
[Epoch 1, Batch 2200] loss: 0.12341925313696266
[Epoch 1, Batch 2300] loss: 0.13699862600304186
[Epoch 1, Batch 2400] loss: 0.14893010072410107
[Epoch 1, Batch 2500] loss: 0.10119672656059266
[Epoch 1, Batch 2600] loss: 0.13885873451363295
[Epoch 1, Batch 2700] loss: 0.11076104343868792
[Epoch 1, Batch 2800] loss: 0.09330380619270727
[Epoch 1, Batch 2900] loss: 0.10946589825674892
[Epoch 1, Batch 3000] loss: 0.11341675631469116
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1087
Validation Accuracy: 0.9655
Overfitting: 0.1087
Best model saved at epoch 1 with validation loss: 0.1087
[Epoch 2, Batch 100] loss: 0.10366883833426982
[Epoch 2, Batch 200] loss: 0.11457746416563168
[Epoch 2, Batch 300] loss: 0.11319579590810463
[Epoch 2, Batch 400] loss: 0.07885601624380797
[Epoch 2, Batch 500] loss: 0.08512494683032855
[Epoch 2, Batch 600] loss: 0.09515091736917385
[Epoch 2, Batch 700] loss: 0.08330582018126734
[Epoch 2, Batch 800] loss: 0.0692256811237894
[Epoch 2, Batch 900] loss: 0.11790990758920089
[Epoch 2, Batch 1000] loss: 0.10999233803479001
[Epoch 2, Batch 1100] loss: 0.09310529312351719
[Epoch 2, Batch 1200] loss: 0.08810501971165649
[Epoch 2, Batch 1300] loss: 0.07363645781064405
[Epoch 2, Batch 1400] loss: 0.08592001093900763
[Epoch 2, Batch 1500] loss: 0.07479265625588596
[Epoch 2, Batch 1600] loss: 0.08702068959944881
[Epoch 2, Batch 1700] loss: 0.08307061500512646
[Epoch 2, Batch 1800] loss: 0.09248155170935206
[Epoch 2, Batch 1900] loss: 0.0889407743839547
[Epoch 2, Batch 2000] loss: 0.05087018057238311
[Epoch 2, Batch 2100] loss: 0.06358924181258771
[Epoch 2, Batch 2200] loss: 0.06627607217873446
[Epoch 2, Batch 2300] loss: 0.07362832247454207
[Epoch 2, Batch 2400] loss: 0.07103769226989243
[Epoch 2, Batch 2500] loss: 0.05642292335629463
[Epoch 2, Batch 2600] loss: 0.06781378913903609
[Epoch 2, Batch 2700] loss: 0.07669960905070183
[Epoch 2, Batch 2800] loss: 0.08049086201936007
[Epoch 2, Batch 2900] loss: 0.05976416533463635
[Epoch 2, Batch 3000] loss: 0.07529103952634614
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0644
Validation Accuracy: 0.9808
Overfitting: 0.0644
Best model saved at epoch 2 with validation loss: 0.0644
[Epoch 3, Batch 100] loss: 0.06510988446185366
[Epoch 3, Batch 200] loss: 0.052946273167617616
[Epoch 3, Batch 300] loss: 0.06276858864352107
[Epoch 3, Batch 400] loss: 0.06724488393185311
[Epoch 3, Batch 500] loss: 0.08347246228018776
[Epoch 3, Batch 600] loss: 0.06465561699558747
[Epoch 3, Batch 700] loss: 0.0556699752015993
[Epoch 3, Batch 800] loss: 0.0732234655204229
[Epoch 3, Batch 900] loss: 0.06994333739508875
[Epoch 3, Batch 1000] loss: 0.06264313097286504
[Epoch 3, Batch 1100] loss: 0.0659839731262764
[Epoch 3, Batch 1200] loss: 0.038428298614162484
[Epoch 3, Batch 1300] loss: 0.06877766691963189
[Epoch 3, Batch 1400] loss: 0.0815126681199763
[Epoch 3, Batch 1500] loss: 0.05768006422847975
[Epoch 3, Batch 1600] loss: 0.05329003392544109
[Epoch 3, Batch 1700] loss: 0.06091892864962574
[Epoch 3, Batch 1800] loss: 0.07094952026178362
[Epoch 3, Batch 1900] loss: 0.04136229656025534
[Epoch 3, Batch 2000] loss: 0.04869287250447087
[Epoch 3, Batch 2100] loss: 0.0564868389791809
[Epoch 3, Batch 2200] loss: 0.039750884706736545
[Epoch 3, Batch 2300] loss: 0.04408661261142697
[Epoch 3, Batch 2400] loss: 0.05991273823863594
[Epoch 3, Batch 2500] loss: 0.06748689813073724
[Epoch 3, Batch 2600] loss: 0.05245277733367402
[Epoch 3, Batch 2700] loss: 0.05708140839065891
[Epoch 3, Batch 2800] loss: 0.05152782915130956
[Epoch 3, Batch 2900] loss: 0.0646659955760697
[Epoch 3, Batch 3000] loss: 0.06763459853886161
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0622
Validation Accuracy: 0.9805
Overfitting: 0.0622
Best model saved at epoch 3 with validation loss: 0.0622
[Epoch 4, Batch 100] loss: 0.05806487236171961
[Epoch 4, Batch 200] loss: 0.02619989811180858
[Epoch 4, Batch 300] loss: 0.04637351004610537
[Epoch 4, Batch 400] loss: 0.05019094545801636
[Epoch 4, Batch 500] loss: 0.057850252697535326
[Epoch 4, Batch 600] loss: 0.0530170216341503
[Epoch 4, Batch 700] loss: 0.04444141490530455
[Epoch 4, Batch 800] loss: 0.03248592593095964
[Epoch 4, Batch 900] loss: 0.03948470334697049
[Epoch 4, Batch 1000] loss: 0.03016332654398866
[Epoch 4, Batch 1100] loss: 0.05827902991673909
[Epoch 4, Batch 1200] loss: 0.05295368131286523
[Epoch 4, Batch 1300] loss: 0.05079613470879849
[Epoch 4, Batch 1400] loss: 0.05085535105172312
[Epoch 4, Batch 1500] loss: 0.03473400312825106
[Epoch 4, Batch 1600] loss: 0.040266517840063895
[Epoch 4, Batch 1700] loss: 0.03807210963423131
[Epoch 4, Batch 1800] loss: 0.08256115948126536
[Epoch 4, Batch 1900] loss: 0.03840708456118591
[Epoch 4, Batch 2000] loss: 0.043156968074617906
[Epoch 4, Batch 2100] loss: 0.04994482710477314
[Epoch 4, Batch 2200] loss: 0.04801384734455496
[Epoch 4, Batch 2300] loss: 0.050381584075803405
[Epoch 4, Batch 2400] loss: 0.053303429315128596
[Epoch 4, Batch 2500] loss: 0.057516472336137665
[Epoch 4, Batch 2600] loss: 0.04709981747553684
[Epoch 4, Batch 2700] loss: 0.04515974289155565
[Epoch 4, Batch 2800] loss: 0.047440842179057655
[Epoch 4, Batch 2900] loss: 0.052823298920993696
[Epoch 4, Batch 3000] loss: 0.041231573684199246
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9852
Overfitting: 0.0508
Best model saved at epoch 4 with validation loss: 0.0508
[Epoch 5, Batch 100] loss: 0.04109695910621667
[Epoch 5, Batch 200] loss: 0.03542117689648876
[Epoch 5, Batch 300] loss: 0.04767724383098539
[Epoch 5, Batch 400] loss: 0.033465054979315026
[Epoch 5, Batch 500] loss: 0.04571229426772334
[Epoch 5, Batch 600] loss: 0.03286841732959147
[Epoch 5, Batch 700] loss: 0.03169948809649213
[Epoch 5, Batch 800] loss: 0.04194332642597146
[Epoch 5, Batch 900] loss: 0.049803772379964355
[Epoch 5, Batch 1000] loss: 0.04084497645060765
[Epoch 5, Batch 1100] loss: 0.03313861000191537
[Epoch 5, Batch 1200] loss: 0.040142519779146825
[Epoch 5, Batch 1300] loss: 0.031356589097413234
[Epoch 5, Batch 1400] loss: 0.04053122269222513
[Epoch 5, Batch 1500] loss: 0.046400657595222584
[Epoch 5, Batch 1600] loss: 0.03441268276801566
[Epoch 5, Batch 1700] loss: 0.02353483429906191
[Epoch 5, Batch 1800] loss: 0.038282022763523854
[Epoch 5, Batch 1900] loss: 0.03485397214029945
[Epoch 5, Batch 2000] loss: 0.03755471913071233
[Epoch 5, Batch 2100] loss: 0.04612292963720392
[Epoch 5, Batch 2200] loss: 0.0331863406602497
[Epoch 5, Batch 2300] loss: 0.0462639474937896
[Epoch 5, Batch 2400] loss: 0.041555066511646144
[Epoch 5, Batch 2500] loss: 0.04255560573277762
[Epoch 5, Batch 2600] loss: 0.033828535963984906
[Epoch 5, Batch 2700] loss: 0.04622324520343682
[Epoch 5, Batch 2800] loss: 0.04327343197655864
[Epoch 5, Batch 2900] loss: 0.0401129201965523
[Epoch 5, Batch 3000] loss: 0.04586584713455522
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9862
Overfitting: 0.0468
Best model saved at epoch 5 with validation loss: 0.0468
[Epoch 6, Batch 100] loss: 0.03237804936798057
[Epoch 6, Batch 200] loss: 0.019829364926627024
[Epoch 6, Batch 300] loss: 0.03428770455728227
[Epoch 6, Batch 400] loss: 0.037416758807230506
[Epoch 6, Batch 500] loss: 0.031138371140114033
[Epoch 6, Batch 600] loss: 0.017157878370489925
[Epoch 6, Batch 700] loss: 0.0288633170896901
[Epoch 6, Batch 800] loss: 0.024282793989987114
[Epoch 6, Batch 900] loss: 0.03655662167100673
[Epoch 6, Batch 1000] loss: 0.03436130770838645
[Epoch 6, Batch 1100] loss: 0.028947329208240263
[Epoch 6, Batch 1200] loss: 0.02564936820916046
[Epoch 6, Batch 1300] loss: 0.0408582467904489
[Epoch 6, Batch 1400] loss: 0.02358642668055836
[Epoch 6, Batch 1500] loss: 0.035306499826074283
[Epoch 6, Batch 1600] loss: 0.028353366528099288
[Epoch 6, Batch 1700] loss: 0.04006503955988592
[Epoch 6, Batch 1800] loss: 0.03508192350913305
[Epoch 6, Batch 1900] loss: 0.02037316424874007
[Epoch 6, Batch 2000] loss: 0.029973300632918837
[Epoch 6, Batch 2100] loss: 0.03518152324988478
[Epoch 6, Batch 2200] loss: 0.041337871686737346
[Epoch 6, Batch 2300] loss: 0.03954887066767696
[Epoch 6, Batch 2400] loss: 0.028237019865009642
[Epoch 6, Batch 2500] loss: 0.03117266687579104
[Epoch 6, Batch 2600] loss: 0.042513444839278235
[Epoch 6, Batch 2700] loss: 0.023870097721228375
[Epoch 6, Batch 2800] loss: 0.03286652407565271
[Epoch 6, Batch 2900] loss: 0.06301242103989352
[Epoch 6, Batch 3000] loss: 0.037229796316823924
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0424
Validation Accuracy: 0.9869
Overfitting: 0.0424
Best model saved at epoch 6 with validation loss: 0.0424
[Epoch 7, Batch 100] loss: 0.016052709451905685
[Epoch 7, Batch 200] loss: 0.029344281806734217
[Epoch 7, Batch 300] loss: 0.03233375300806074
[Epoch 7, Batch 400] loss: 0.03025550924212439
[Epoch 7, Batch 500] loss: 0.030530037683056434
[Epoch 7, Batch 600] loss: 0.013093081793522287
[Epoch 7, Batch 700] loss: 0.022559469002062543
[Epoch 7, Batch 800] loss: 0.027076055651305067
[Epoch 7, Batch 900] loss: 0.024378473486285655
[Epoch 7, Batch 1000] loss: 0.025997799981159916
[Epoch 7, Batch 1100] loss: 0.027658704551358822
[Epoch 7, Batch 1200] loss: 0.028408853417495265
[Epoch 7, Batch 1300] loss: 0.026338978776475414
[Epoch 7, Batch 1400] loss: 0.017018353335297432
[Epoch 7, Batch 1500] loss: 0.018296647398892675
[Epoch 7, Batch 1600] loss: 0.022256296120758634
[Epoch 7, Batch 1700] loss: 0.03186515588069597
[Epoch 7, Batch 1800] loss: 0.023036280728556447
[Epoch 7, Batch 1900] loss: 0.01684798593239975
[Epoch 7, Batch 2000] loss: 0.03383736981308175
[Epoch 7, Batch 2100] loss: 0.02806248171320476
[Epoch 7, Batch 2200] loss: 0.0387453772853587
[Epoch 7, Batch 2300] loss: 0.027370635564911937
[Epoch 7, Batch 2400] loss: 0.023296458246259134
[Epoch 7, Batch 2500] loss: 0.02752209667499301
[Epoch 7, Batch 2600] loss: 0.03119477829655807
[Epoch 7, Batch 2700] loss: 0.02882178232604929
[Epoch 7, Batch 2800] loss: 0.034822751928368235
[Epoch 7, Batch 2900] loss: 0.04816551363568578
[Epoch 7, Batch 3000] loss: 0.036078315131962885
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0438
Validation Accuracy: 0.9874
Overfitting: 0.0438
[Epoch 8, Batch 100] loss: 0.023303755003144033
[Epoch 8, Batch 200] loss: 0.03347783219709527
[Epoch 8, Batch 300] loss: 0.030159380814802718
[Epoch 8, Batch 400] loss: 0.017359142506829812
[Epoch 8, Batch 500] loss: 0.018294676505975077
[Epoch 8, Batch 600] loss: 0.019153993529871512
[Epoch 8, Batch 700] loss: 0.02176410576223134
[Epoch 8, Batch 800] loss: 0.021743875216670858
[Epoch 8, Batch 900] loss: 0.02125668573218718
[Epoch 8, Batch 1000] loss: 0.021105687513609153
[Epoch 8, Batch 1100] loss: 0.01970745572472879
[Epoch 8, Batch 1200] loss: 0.017492811686825007
[Epoch 8, Batch 1300] loss: 0.018982644055104175
[Epoch 8, Batch 1400] loss: 0.018277475033464725
[Epoch 8, Batch 1500] loss: 0.025216495958266024
[Epoch 8, Batch 1600] loss: 0.018095610328018666
[Epoch 8, Batch 1700] loss: 0.016332120656006737
[Epoch 8, Batch 1800] loss: 0.019502242476737593
[Epoch 8, Batch 1900] loss: 0.02087701903470588
[Epoch 8, Batch 2000] loss: 0.01766357492891984
[Epoch 8, Batch 2100] loss: 0.03379831580272366
[Epoch 8, Batch 2200] loss: 0.015344803413427144
[Epoch 8, Batch 2300] loss: 0.025650520388926453
[Epoch 8, Batch 2400] loss: 0.029306109285971615
[Epoch 8, Batch 2500] loss: 0.01955995016884117
[Epoch 8, Batch 2600] loss: 0.027428595066958224
[Epoch 8, Batch 2700] loss: 0.03740245531505934
[Epoch 8, Batch 2800] loss: 0.02324913048376402
[Epoch 8, Batch 2900] loss: 0.020659223111251776
[Epoch 8, Batch 3000] loss: 0.019245305366421234
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0414
Validation Accuracy: 0.9875
Overfitting: 0.0414
Best model saved at epoch 8 with validation loss: 0.0414
[Epoch 9, Batch 100] loss: 0.020676303660366102
[Epoch 9, Batch 200] loss: 0.018969161738059483
[Epoch 9, Batch 300] loss: 0.014682612390952272
[Epoch 9, Batch 400] loss: 0.018528514425197498
[Epoch 9, Batch 500] loss: 0.017203744433791145
[Epoch 9, Batch 600] loss: 0.012996723696160188
[Epoch 9, Batch 700] loss: 0.009849884274717623
[Epoch 9, Batch 800] loss: 0.018940495857932546
[Epoch 9, Batch 900] loss: 0.026437645258920384
[Epoch 9, Batch 1000] loss: 0.016389938709871786
[Epoch 9, Batch 1100] loss: 0.016140256945618603
[Epoch 9, Batch 1200] loss: 0.010088388331778332
[Epoch 9, Batch 1300] loss: 0.015124188866684563
[Epoch 9, Batch 1400] loss: 0.01627229638172139
[Epoch 9, Batch 1500] loss: 0.02434732927558798
[Epoch 9, Batch 1600] loss: 0.01637048935384428
[Epoch 9, Batch 1700] loss: 0.03076689885543601
[Epoch 9, Batch 1800] loss: 0.034941915031704414
[Epoch 9, Batch 1900] loss: 0.02070305766254023
[Epoch 9, Batch 2000] loss: 0.012990749261098245
[Epoch 9, Batch 2100] loss: 0.025334812935725495
[Epoch 9, Batch 2200] loss: 0.019081768200321675
[Epoch 9, Batch 2300] loss: 0.028010891137382712
[Epoch 9, Batch 2400] loss: 0.023219019827974988
[Epoch 9, Batch 2500] loss: 0.022194382753677928
[Epoch 9, Batch 2600] loss: 0.024031660846376326
[Epoch 9, Batch 2700] loss: 0.020577979829577087
[Epoch 9, Batch 2800] loss: 0.03246397326289298
[Epoch 9, Batch 2900] loss: 0.024172050069555553
[Epoch 9, Batch 3000] loss: 0.025392795432999264
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9855
Overfitting: 0.0480
[Epoch 10, Batch 100] loss: 0.016989865408977494
[Epoch 10, Batch 200] loss: 0.009602452916005859
[Epoch 10, Batch 300] loss: 0.010790527934696002
[Epoch 10, Batch 400] loss: 0.026159950096352986
[Epoch 10, Batch 500] loss: 0.020125251266035774
[Epoch 10, Batch 600] loss: 0.01948525641026208
[Epoch 10, Batch 700] loss: 0.008525705744395963
[Epoch 10, Batch 800] loss: 0.02079120076441541
[Epoch 10, Batch 900] loss: 0.009371580169445224
[Epoch 10, Batch 1000] loss: 0.024097777680631226
[Epoch 10, Batch 1100] loss: 0.019567424408814985
[Epoch 10, Batch 1200] loss: 0.012683426868052265
[Epoch 10, Batch 1300] loss: 0.02193434521135714
[Epoch 10, Batch 1400] loss: 0.0159212950716028
[Epoch 10, Batch 1500] loss: 0.016518776649559187
[Epoch 10, Batch 1600] loss: 0.023725694211934753
[Epoch 10, Batch 1700] loss: 0.01316505079090348
[Epoch 10, Batch 1800] loss: 0.013719505687467971
[Epoch 10, Batch 1900] loss: 0.019036513834907964
[Epoch 10, Batch 2000] loss: 0.024004506232868154
[Epoch 10, Batch 2100] loss: 0.012416830999245575
[Epoch 10, Batch 2200] loss: 0.013093092657018133
[Epoch 10, Batch 2300] loss: 0.030506010076969688
[Epoch 10, Batch 2400] loss: 0.021792109950820305
[Epoch 10, Batch 2500] loss: 0.01906471705831791
[Epoch 10, Batch 2600] loss: 0.018593217681382158
[Epoch 10, Batch 2700] loss: 0.018325111777694473
[Epoch 10, Batch 2800] loss: 0.015464959115274724
[Epoch 10, Batch 2900] loss: 0.010017065968222596
[Epoch 10, Batch 3000] loss: 0.031175808813659386
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0419
Validation Accuracy: 0.9888
Overfitting: 0.0419
[Epoch 11, Batch 100] loss: 0.00999651411598279
[Epoch 11, Batch 200] loss: 0.009707822523832874
[Epoch 11, Batch 300] loss: 0.011998464922999118
[Epoch 11, Batch 400] loss: 0.020394951027801655
[Epoch 11, Batch 500] loss: 0.0109121063631801
[Epoch 11, Batch 600] loss: 0.014166853287242702
[Epoch 11, Batch 700] loss: 0.013342197254914936
[Epoch 11, Batch 800] loss: 0.006755056481615611
[Epoch 11, Batch 900] loss: 0.008986081223692963
[Epoch 11, Batch 1000] loss: 0.010355617181849084
[Epoch 11, Batch 1100] loss: 0.013323721605465834
[Epoch 11, Batch 1200] loss: 0.014984767196001485
[Epoch 11, Batch 1300] loss: 0.01432443090767265
[Epoch 11, Batch 1400] loss: 0.009394856527860611
[Epoch 11, Batch 1500] loss: 0.015280473335863007
[Epoch 11, Batch 1600] loss: 0.023420489447912588
[Epoch 11, Batch 1700] loss: 0.029977647495143173
[Epoch 11, Batch 1800] loss: 0.014612149081658572
[Epoch 11, Batch 1900] loss: 0.030313910883596692
[Epoch 11, Batch 2000] loss: 0.020771526051212276
[Epoch 11, Batch 2100] loss: 0.019575378531608293
[Epoch 11, Batch 2200] loss: 0.018067997495754752
[Epoch 11, Batch 2300] loss: 0.010696102227466326
[Epoch 11, Batch 2400] loss: 0.015622202851245675
[Epoch 11, Batch 2500] loss: 0.006448387250393353
[Epoch 11, Batch 2600] loss: 0.034538988410454295
[Epoch 11, Batch 2700] loss: 0.008277808723451017
[Epoch 11, Batch 2800] loss: 0.012223628421616013
[Epoch 11, Batch 2900] loss: 0.015013557891841174
[Epoch 11, Batch 3000] loss: 0.016506445343420637
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9882
Overfitting: 0.0467
[Epoch 12, Batch 100] loss: 0.007386207349582037
[Epoch 12, Batch 200] loss: 0.006485959122378517
[Epoch 12, Batch 300] loss: 0.009659739033061214
[Epoch 12, Batch 400] loss: 0.017304211964269598
[Epoch 12, Batch 500] loss: 0.014020033384322233
[Epoch 12, Batch 600] loss: 0.012052628775704762
[Epoch 12, Batch 700] loss: 0.015958671400439925
[Epoch 12, Batch 800] loss: 0.007514206514852049
[Epoch 12, Batch 900] loss: 0.012566140597459707
[Epoch 12, Batch 1000] loss: 0.010937637558699862
[Epoch 12, Batch 1100] loss: 0.015555479424156146
[Epoch 12, Batch 1200] loss: 0.009087515318051374
[Epoch 12, Batch 1300] loss: 0.00813681091471608
[Epoch 12, Batch 1400] loss: 0.007917242281137079
[Epoch 12, Batch 1500] loss: 0.02009926403216923
[Epoch 12, Batch 1600] loss: 0.012224815132522054
[Epoch 12, Batch 1700] loss: 0.013656522723156286
[Epoch 12, Batch 1800] loss: 0.012615105383324589
[Epoch 12, Batch 1900] loss: 0.018144547077326934
[Epoch 12, Batch 2000] loss: 0.011301699189625652
[Epoch 12, Batch 2100] loss: 0.023056951135804412
[Epoch 12, Batch 2200] loss: 0.012380510170423804
[Epoch 12, Batch 2300] loss: 0.005657404085250164
[Epoch 12, Batch 2400] loss: 0.013156564201358379
[Epoch 12, Batch 2500] loss: 0.019315187165275347
[Epoch 12, Batch 2600] loss: 0.012730956208051793
[Epoch 12, Batch 2700] loss: 0.013665847758365999
[Epoch 12, Batch 2800] loss: 0.015986693599209047
[Epoch 12, Batch 2900] loss: 0.00870757464374492
[Epoch 12, Batch 3000] loss: 0.01605515395835937
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9880
Overfitting: 0.0441
[Epoch 13, Batch 100] loss: 0.0048590300894284155
[Epoch 13, Batch 200] loss: 0.008700203495072856
[Epoch 13, Batch 300] loss: 0.01052099440920756
[Epoch 13, Batch 400] loss: 0.008263312903982295
[Epoch 13, Batch 500] loss: 0.007917960183697233
[Epoch 13, Batch 600] loss: 0.017820359145780458
[Epoch 13, Batch 700] loss: 0.011175054425875715
[Epoch 13, Batch 800] loss: 0.008804350993777917
[Epoch 13, Batch 900] loss: 0.013207559981058239
[Epoch 13, Batch 1000] loss: 0.014660902653431548
[Epoch 13, Batch 1100] loss: 0.01600823857638261
[Epoch 13, Batch 1200] loss: 0.014469705965557295
[Epoch 13, Batch 1300] loss: 0.01854251187656473
[Epoch 13, Batch 1400] loss: 0.013468342748283249
[Epoch 13, Batch 1500] loss: 0.010932972607952252
[Epoch 13, Batch 1600] loss: 0.010823020639305696
[Epoch 13, Batch 1700] loss: 0.006408580541719857
[Epoch 13, Batch 1800] loss: 0.005886172860921306
[Epoch 13, Batch 1900] loss: 0.013188463116772482
[Epoch 13, Batch 2000] loss: 0.002138415143331258
[Epoch 13, Batch 2100] loss: 0.018015303825640105
[Epoch 13, Batch 2200] loss: 0.014880922497318351
[Epoch 13, Batch 2300] loss: 0.007411592930455981
[Epoch 13, Batch 2400] loss: 0.006402950597780546
[Epoch 13, Batch 2500] loss: 0.00969388386859464
[Epoch 13, Batch 2600] loss: 0.01705266554006812
[Epoch 13, Batch 2700] loss: 0.010094116058216968
[Epoch 13, Batch 2800] loss: 0.02650814535120844
[Epoch 13, Batch 2900] loss: 0.0152613829862662
[Epoch 13, Batch 3000] loss: 0.020371792034834472
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9874
Overfitting: 0.0457
[Epoch 14, Batch 100] loss: 0.006133066039778896
[Epoch 14, Batch 200] loss: 0.005117836338762345
[Epoch 14, Batch 300] loss: 0.008540064923699901
[Epoch 14, Batch 400] loss: 0.009991198478164733
[Epoch 14, Batch 500] loss: 0.012419466078965798
[Epoch 14, Batch 600] loss: 0.0049741250949819
[Epoch 14, Batch 700] loss: 0.00507347128130732
[Epoch 14, Batch 800] loss: 0.008644595270591821
[Epoch 14, Batch 900] loss: 0.011485865344275226
[Epoch 14, Batch 1000] loss: 0.004093209383229351
[Epoch 14, Batch 1100] loss: 0.00470206744511529
[Epoch 14, Batch 1200] loss: 0.008529642351288658
[Epoch 14, Batch 1300] loss: 0.0076750211085027335
[Epoch 14, Batch 1400] loss: 0.007819761626742548
[Epoch 14, Batch 1500] loss: 0.008474620972415324
[Epoch 14, Batch 1600] loss: 0.004017825839835041
[Epoch 14, Batch 1700] loss: 0.009587545776244042
[Epoch 14, Batch 1800] loss: 0.014748403606627108
[Epoch 14, Batch 1900] loss: 0.0074713547987010995
[Epoch 14, Batch 2000] loss: 0.0061588830481684904
[Epoch 14, Batch 2100] loss: 0.005296274349536816
[Epoch 14, Batch 2200] loss: 0.008658625053785443
[Epoch 14, Batch 2300] loss: 0.016069824035660076
[Epoch 14, Batch 2400] loss: 0.012446085757005676
[Epoch 14, Batch 2500] loss: 0.012766140428716426
[Epoch 14, Batch 2600] loss: 0.01589631855178368
[Epoch 14, Batch 2700] loss: 0.0064234156902148246
[Epoch 14, Batch 2800] loss: 0.02087810783056284
[Epoch 14, Batch 2900] loss: 0.011547462242278926
[Epoch 14, Batch 3000] loss: 0.007106560128697766
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0563
Validation Accuracy: 0.9856
Overfitting: 0.0563
[Epoch 15, Batch 100] loss: 0.011159365598742851
[Epoch 15, Batch 200] loss: 0.00910251723104011
[Epoch 15, Batch 300] loss: 0.007675199861994315
[Epoch 15, Batch 400] loss: 0.0050461708638351865
[Epoch 15, Batch 500] loss: 0.010508369152396994
[Epoch 15, Batch 600] loss: 0.007373497272178611
[Epoch 15, Batch 700] loss: 0.013654678658022022
[Epoch 15, Batch 800] loss: 0.004738055618379349
[Epoch 15, Batch 900] loss: 0.0073620488021651906
[Epoch 15, Batch 1000] loss: 0.010022121269039418
[Epoch 15, Batch 1100] loss: 0.014147170030046254
[Epoch 15, Batch 1200] loss: 0.005164428492159914
[Epoch 15, Batch 1300] loss: 0.0051689444191697475
[Epoch 15, Batch 1400] loss: 0.0016058027676297115
[Epoch 15, Batch 1500] loss: 0.013134377805235999
[Epoch 15, Batch 1600] loss: 0.009079812106251665
[Epoch 15, Batch 1700] loss: 0.01040203874740655
[Epoch 15, Batch 1800] loss: 0.010816210469697581
[Epoch 15, Batch 1900] loss: 0.008374325383695123
[Epoch 15, Batch 2000] loss: 0.008806419307351234
[Epoch 15, Batch 2100] loss: 0.014859707505816005
[Epoch 15, Batch 2200] loss: 0.025207782516389443
[Epoch 15, Batch 2300] loss: 0.014182393968010274
[Epoch 15, Batch 2400] loss: 0.011888253597376205
[Epoch 15, Batch 2500] loss: 0.010792931765880098
[Epoch 15, Batch 2600] loss: 0.005312234872169483
[Epoch 15, Batch 2700] loss: 0.009852698089091519
[Epoch 15, Batch 2800] loss: 0.01848810401588395
[Epoch 15, Batch 2900] loss: 0.020667275638289198
[Epoch 15, Batch 3000] loss: 0.012604396347180682
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0498
Validation Accuracy: 0.9875
Overfitting: 0.0498
[Epoch 16, Batch 100] loss: 0.004984997496685537
[Epoch 16, Batch 200] loss: 0.005158421790983425
[Epoch 16, Batch 300] loss: 0.007655702910222999
[Epoch 16, Batch 400] loss: 0.014818616622739
[Epoch 16, Batch 500] loss: 0.009258846815882862
[Epoch 16, Batch 600] loss: 0.006542008387480109
[Epoch 16, Batch 700] loss: 0.005359432656600802
[Epoch 16, Batch 800] loss: 0.006378103385064975
[Epoch 16, Batch 900] loss: 0.011218031044962232
[Epoch 16, Batch 1000] loss: 0.005197307418853825
[Epoch 16, Batch 1100] loss: 0.013356650238140446
[Epoch 16, Batch 1200] loss: 0.010697850902772643
[Epoch 16, Batch 1300] loss: 0.006023633747074086
[Epoch 16, Batch 1400] loss: 0.0048223983504328775
[Epoch 16, Batch 1500] loss: 0.0034914195691953865
[Epoch 16, Batch 1600] loss: 0.005696208284341538
[Epoch 16, Batch 1700] loss: 0.01396040079170234
[Epoch 16, Batch 1800] loss: 0.0032387048388670793
[Epoch 16, Batch 1900] loss: 0.013001536247870718
[Epoch 16, Batch 2000] loss: 0.01988303971082587
[Epoch 16, Batch 2100] loss: 0.019983990488294693
[Epoch 16, Batch 2200] loss: 0.007615825332299267
[Epoch 16, Batch 2300] loss: 0.007967328965552838
[Epoch 16, Batch 2400] loss: 0.004515483076402233
[Epoch 16, Batch 2500] loss: 0.008213126631849263
[Epoch 16, Batch 2600] loss: 0.006842505397616918
[Epoch 16, Batch 2700] loss: 0.005434268902533858
[Epoch 16, Batch 2800] loss: 0.013494141150677024
[Epoch 16, Batch 2900] loss: 0.0048566867395965115
[Epoch 16, Batch 3000] loss: 0.004467527947189183
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9889
Overfitting: 0.0463
[Epoch 17, Batch 100] loss: 0.009341610332903656
[Epoch 17, Batch 200] loss: 0.0035987214345090026
[Epoch 17, Batch 300] loss: 0.00249308679740011
[Epoch 17, Batch 400] loss: 0.00686418778684299
[Epoch 17, Batch 500] loss: 0.0068536232262999515
[Epoch 17, Batch 600] loss: 0.007420537616596192
[Epoch 17, Batch 700] loss: 0.00217491095098012
[Epoch 17, Batch 800] loss: 0.004413996724809977
[Epoch 17, Batch 900] loss: 0.0029090653442892743
[Epoch 17, Batch 1000] loss: 0.008049778143420384
[Epoch 17, Batch 1100] loss: 0.00405651766025386
[Epoch 17, Batch 1200] loss: 0.012288997682138075
[Epoch 17, Batch 1300] loss: 0.0028259327222360754
[Epoch 17, Batch 1400] loss: 0.0033611439912147032
[Epoch 17, Batch 1500] loss: 0.015445294042944795
[Epoch 17, Batch 1600] loss: 0.006731402141163016
[Epoch 17, Batch 1700] loss: 0.003349573456416266
[Epoch 17, Batch 1800] loss: 0.0028472133314497226
[Epoch 17, Batch 1900] loss: 0.0064531031777130465
[Epoch 17, Batch 2000] loss: 0.008323904817416974
[Epoch 17, Batch 2100] loss: 0.005360114461009857
[Epoch 17, Batch 2200] loss: 0.00493035568076067
[Epoch 17, Batch 2300] loss: 0.002713990608422705
[Epoch 17, Batch 2400] loss: 0.01121727054238363
[Epoch 17, Batch 2500] loss: 0.007497076406382348
[Epoch 17, Batch 2600] loss: 0.00466055025708414
[Epoch 17, Batch 2700] loss: 0.003747953903838379
[Epoch 17, Batch 2800] loss: 0.007322738389169672
[Epoch 17, Batch 2900] loss: 0.007248476932800258
[Epoch 17, Batch 3000] loss: 0.010905533210328713
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9876
Overfitting: 0.0536
[Epoch 18, Batch 100] loss: 0.0057764843800521245
[Epoch 18, Batch 200] loss: 0.006205626632721533
[Epoch 18, Batch 300] loss: 0.007680799754356116
[Epoch 18, Batch 400] loss: 0.0019923391359526477
[Epoch 18, Batch 500] loss: 0.008757332552226344
[Epoch 18, Batch 600] loss: 0.005729391668000972
[Epoch 18, Batch 700] loss: 0.002891902795452097
[Epoch 18, Batch 800] loss: 0.0022650729361878776
[Epoch 18, Batch 900] loss: 0.0025459578184279506
[Epoch 18, Batch 1000] loss: 0.00331125446898497
[Epoch 18, Batch 1100] loss: 0.002678014116089571
[Epoch 18, Batch 1200] loss: 0.005020529911503786
[Epoch 18, Batch 1300] loss: 0.01025768101593485
[Epoch 18, Batch 1400] loss: 0.00806141742239987
[Epoch 18, Batch 1500] loss: 0.0034908738734250734
[Epoch 18, Batch 1600] loss: 0.004049426427015135
[Epoch 18, Batch 1700] loss: 0.005729354164870983
[Epoch 18, Batch 1800] loss: 0.00176730137303295
[Epoch 18, Batch 1900] loss: 0.00348565847757925
[Epoch 18, Batch 2000] loss: 0.0019372227720052138
[Epoch 18, Batch 2100] loss: 0.0011952976913210023
[Epoch 18, Batch 2200] loss: 0.002232761848225948
[Epoch 18, Batch 2300] loss: 0.006610805913130662
[Epoch 18, Batch 2400] loss: 0.0044289863825977705
[Epoch 18, Batch 2500] loss: 0.0031427909983838733
[Epoch 18, Batch 2600] loss: 0.0033864569130531664
[Epoch 18, Batch 2700] loss: 0.004155023074813471
[Epoch 18, Batch 2800] loss: 0.0070927161168987144
[Epoch 18, Batch 2900] loss: 0.005973464450747769
[Epoch 18, Batch 3000] loss: 0.004291967127588157
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9894
Overfitting: 0.0463
[Epoch 19, Batch 100] loss: 0.002728415908581425
[Epoch 19, Batch 200] loss: 0.004444642403150425
[Epoch 19, Batch 300] loss: 0.004432483006761742
[Epoch 19, Batch 400] loss: 0.007042199267469868
[Epoch 19, Batch 500] loss: 0.0017457041185230083
[Epoch 19, Batch 600] loss: 0.006739936463703629
[Epoch 19, Batch 700] loss: 0.0024024604102928036
[Epoch 19, Batch 800] loss: 0.003182336144413398
[Epoch 19, Batch 900] loss: 0.0014979462386655485
[Epoch 19, Batch 1000] loss: 0.004073211892661988
[Epoch 19, Batch 1100] loss: 0.011883294265585391
[Epoch 19, Batch 1200] loss: 0.005121988997865401
[Epoch 19, Batch 1300] loss: 0.008151990745606668
[Epoch 19, Batch 1400] loss: 0.006495618406657116
[Epoch 19, Batch 1500] loss: 0.011058146531028825
[Epoch 19, Batch 1600] loss: 0.003514722902889815
[Epoch 19, Batch 1700] loss: 0.002108031415548055
[Epoch 19, Batch 1800] loss: 0.007752937464439356
[Epoch 19, Batch 1900] loss: 0.020332755854168313
[Epoch 19, Batch 2000] loss: 0.009046610349918183
[Epoch 19, Batch 2100] loss: 0.00860203998041925
[Epoch 19, Batch 2200] loss: 0.008360195058712777
[Epoch 19, Batch 2300] loss: 0.012737926620139027
[Epoch 19, Batch 2400] loss: 0.006814506421316082
[Epoch 19, Batch 2500] loss: 0.014587332996289462
[Epoch 19, Batch 2600] loss: 0.018390676330046176
[Epoch 19, Batch 2700] loss: 0.00849913409484607
[Epoch 19, Batch 2800] loss: 0.006891540514582175
[Epoch 19, Batch 2900] loss: 0.0038602933633565327
[Epoch 19, Batch 3000] loss: 0.009925727123224704
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9880
Overfitting: 0.0501
[Epoch 20, Batch 100] loss: 0.005785921032500312
[Epoch 20, Batch 200] loss: 0.007513218230839414
[Epoch 20, Batch 300] loss: 0.0016318281231983177
[Epoch 20, Batch 400] loss: 0.0036066812594523867
[Epoch 20, Batch 500] loss: 0.001113061079165405
[Epoch 20, Batch 600] loss: 0.011952452850244696
[Epoch 20, Batch 700] loss: 0.004974088284196796
[Epoch 20, Batch 800] loss: 0.007795942744938884
[Epoch 20, Batch 900] loss: 0.002348891089411609
[Epoch 20, Batch 1000] loss: 0.004874835011262775
[Epoch 20, Batch 1100] loss: 0.0036535682357555286
[Epoch 20, Batch 1200] loss: 0.00931020844191238
[Epoch 20, Batch 1300] loss: 0.015208235480706947
[Epoch 20, Batch 1400] loss: 0.014159173284749613
[Epoch 20, Batch 1500] loss: 0.007407009118278438
[Epoch 20, Batch 1600] loss: 0.006719012746875137
[Epoch 20, Batch 1700] loss: 0.001928030826596796
[Epoch 20, Batch 1800] loss: 0.00372114086534566
[Epoch 20, Batch 1900] loss: 0.0020393837691949556
[Epoch 20, Batch 2000] loss: 0.010943422489481804
[Epoch 20, Batch 2100] loss: 0.002769003480657091
[Epoch 20, Batch 2200] loss: 0.001677866250090858
[Epoch 20, Batch 2300] loss: 0.002934444856497862
[Epoch 20, Batch 2400] loss: 0.0035554733578709373
[Epoch 20, Batch 2500] loss: 0.004614385794954785
[Epoch 20, Batch 2600] loss: 0.0029449452702300506
[Epoch 20, Batch 2700] loss: 0.0031243907557135307
[Epoch 20, Batch 2800] loss: 0.0071608639392283634
[Epoch 20, Batch 2900] loss: 0.002456429745987805
[Epoch 20, Batch 3000] loss: 0.0026353891468906456
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9881
Overfitting: 0.0523
[Epoch 21, Batch 100] loss: 0.004948177176081572
[Epoch 21, Batch 200] loss: 0.00282520120264536
[Epoch 21, Batch 300] loss: 0.0015981170949366686
[Epoch 21, Batch 400] loss: 0.0016072345746562888
[Epoch 21, Batch 500] loss: 0.0008093112194205787
[Epoch 21, Batch 600] loss: 0.0011298946073264914
[Epoch 21, Batch 700] loss: 0.004938559875458495
[Epoch 21, Batch 800] loss: 0.0025421510493942633
[Epoch 21, Batch 900] loss: 0.003757006777835272
[Epoch 21, Batch 1000] loss: 0.007174076468547792
[Epoch 21, Batch 1100] loss: 0.008086149255095449
[Epoch 21, Batch 1200] loss: 0.003130436289158354
[Epoch 21, Batch 1300] loss: 0.0036221478243989224
[Epoch 21, Batch 1400] loss: 0.0033435503730856906
[Epoch 21, Batch 1500] loss: 0.0009518334545855112
[Epoch 21, Batch 1600] loss: 0.0007356046328852272
[Epoch 21, Batch 1700] loss: 0.0009712405018337656
[Epoch 21, Batch 1800] loss: 0.0011322957662164112
[Epoch 21, Batch 1900] loss: 0.009321327415890862
[Epoch 21, Batch 2000] loss: 0.0045714816325028804
[Epoch 21, Batch 2100] loss: 0.001325698944170739
[Epoch 21, Batch 2200] loss: 0.0018419752590051353
[Epoch 21, Batch 2300] loss: 0.0017608244720603138
[Epoch 21, Batch 2400] loss: 0.004923284196293878
[Epoch 21, Batch 2500] loss: 0.002288551808435777
[Epoch 21, Batch 2600] loss: 0.0022652275924717057
[Epoch 21, Batch 2700] loss: 0.002161600859929038
[Epoch 21, Batch 2800] loss: 0.0051510562976179305
[Epoch 21, Batch 2900] loss: 0.0021809123775688023
[Epoch 21, Batch 3000] loss: 0.004076092445723525
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9874
Overfitting: 0.0551
[Epoch 22, Batch 100] loss: 0.0020303835863417774
[Epoch 22, Batch 200] loss: 0.000866961326005935
[Epoch 22, Batch 300] loss: 0.002031117620985916
[Epoch 22, Batch 400] loss: 0.0031022782777110082
[Epoch 22, Batch 500] loss: 0.0011187956102840602
[Epoch 22, Batch 600] loss: 0.001491955853629694
[Epoch 22, Batch 700] loss: 0.0007447678777814515
[Epoch 22, Batch 800] loss: 0.0009727138669265756
[Epoch 22, Batch 900] loss: 0.004802711809362421
[Epoch 22, Batch 1000] loss: 0.002463230889266015
[Epoch 22, Batch 1100] loss: 0.004071519541526501
[Epoch 22, Batch 1200] loss: 0.002121860035401593
[Epoch 22, Batch 1300] loss: 0.0016431763938777521
[Epoch 22, Batch 1400] loss: 0.0006395068571978868
[Epoch 22, Batch 1500] loss: 0.0014550439735844288
[Epoch 22, Batch 1600] loss: 0.003848429452098934
[Epoch 22, Batch 1700] loss: 0.0007846917990403313
[Epoch 22, Batch 1800] loss: 0.0016577332759108287
[Epoch 22, Batch 1900] loss: 0.0014764375846233512
[Epoch 22, Batch 2000] loss: 0.0038110905815712925
[Epoch 22, Batch 2100] loss: 0.00445938589460864
[Epoch 22, Batch 2200] loss: 0.002585940174403287
[Epoch 22, Batch 2300] loss: 0.004725809481365379
[Epoch 22, Batch 2400] loss: 0.004304963851570847
[Epoch 22, Batch 2500] loss: 0.005207759301632962
[Epoch 22, Batch 2600] loss: 0.003212437965952759
[Epoch 22, Batch 2700] loss: 0.0017636118243702548
[Epoch 22, Batch 2800] loss: 0.0013726502594962576
[Epoch 22, Batch 2900] loss: 0.00045073252524421294
[Epoch 22, Batch 3000] loss: 0.001217437248649107
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0547
Validation Accuracy: 0.9896
Overfitting: 0.0547
[Epoch 23, Batch 100] loss: 0.0005974296155138958
[Epoch 23, Batch 200] loss: 0.0004590717650950893
[Epoch 23, Batch 300] loss: 0.001227142982311058
[Epoch 23, Batch 400] loss: 0.0015579655990051221
[Epoch 23, Batch 500] loss: 0.0024454847017761905
[Epoch 23, Batch 600] loss: 0.0022903362809549633
[Epoch 23, Batch 700] loss: 0.0013828881319854246
[Epoch 23, Batch 800] loss: 0.0018557041520498396
[Epoch 23, Batch 900] loss: 0.0025137929913727143
[Epoch 23, Batch 1000] loss: 0.001670038927716533
[Epoch 23, Batch 1100] loss: 0.0007624700934977113
[Epoch 23, Batch 1200] loss: 0.002838930216050386
[Epoch 23, Batch 1300] loss: 0.0007527698728588028
[Epoch 23, Batch 1400] loss: 0.0019299075123139177
[Epoch 23, Batch 1500] loss: 0.0024808881443066787
[Epoch 23, Batch 1600] loss: 0.002845252670159346
[Epoch 23, Batch 1700] loss: 0.001331395937543176
[Epoch 23, Batch 1800] loss: 0.000902085413137712
[Epoch 23, Batch 1900] loss: 0.0009808783497794328
[Epoch 23, Batch 2000] loss: 0.000651874501400318
[Epoch 23, Batch 2100] loss: 0.0004456025366735616
[Epoch 23, Batch 2200] loss: 0.0012483854236207037
[Epoch 23, Batch 2300] loss: 0.0017356607787095157
[Epoch 23, Batch 2400] loss: 0.0007550298757791607
[Epoch 23, Batch 2500] loss: 0.0009959443470567697
[Epoch 23, Batch 2600] loss: 0.0011996679866924564
[Epoch 23, Batch 2700] loss: 0.0012439841096965676
[Epoch 23, Batch 2800] loss: 0.002442871288286259
[Epoch 23, Batch 2900] loss: 0.0012577430327164053
[Epoch 23, Batch 3000] loss: 0.0016969979793686819
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9900
Overfitting: 0.0522
[Epoch 24, Batch 100] loss: 0.0038286182848750227
[Epoch 24, Batch 200] loss: 0.000650947096448693
[Epoch 24, Batch 300] loss: 0.0002721105995950701
[Epoch 24, Batch 400] loss: 0.0010431567082157223
[Epoch 24, Batch 500] loss: 0.0008999105732621527
[Epoch 24, Batch 600] loss: 0.00042363487818608103
[Epoch 24, Batch 700] loss: 0.000273476796740546
[Epoch 24, Batch 800] loss: 0.002218666128917626
[Epoch 24, Batch 900] loss: 0.0005898778142493199
[Epoch 24, Batch 1000] loss: 0.0002086975554019421
[Epoch 24, Batch 1100] loss: 0.000221205738130017
[Epoch 24, Batch 1200] loss: 0.0003503148930416344
[Epoch 24, Batch 1300] loss: 0.0010346010135078255
[Epoch 24, Batch 1400] loss: 0.0011459281263834775
[Epoch 24, Batch 1500] loss: 0.0006919266701727267
[Epoch 24, Batch 1600] loss: 0.0009584166897024104
[Epoch 24, Batch 1700] loss: 0.0002387359481027529
[Epoch 24, Batch 1800] loss: 0.0002832441366453686
[Epoch 24, Batch 1900] loss: 0.0003043004824627493
[Epoch 24, Batch 2000] loss: 0.00031569480895170975
[Epoch 24, Batch 2100] loss: 0.0006773348122593248
[Epoch 24, Batch 2200] loss: 0.0003044261847455765
[Epoch 24, Batch 2300] loss: 0.0005561625691773609
[Epoch 24, Batch 2400] loss: 0.0008480448274794439
[Epoch 24, Batch 2500] loss: 0.0036689560759051963
[Epoch 24, Batch 2600] loss: 0.003326061656089703
[Epoch 24, Batch 2700] loss: 0.0007866525891831033
[Epoch 24, Batch 2800] loss: 0.0008359690125443242
[Epoch 24, Batch 2900] loss: 0.0013734542223115343
[Epoch 24, Batch 3000] loss: 0.0010517885579055264
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9890
Overfitting: 0.0561
Fold 3 validation loss: 0.0561
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.269441697597504
[Epoch 1, Batch 200] loss: 1.9090638387203216
[Epoch 1, Batch 300] loss: 0.7880259126424789
[Epoch 1, Batch 400] loss: 0.6360378643870354
[Epoch 1, Batch 500] loss: 0.4754243946820498
[Epoch 1, Batch 600] loss: 0.4406172323971987
[Epoch 1, Batch 700] loss: 0.4016988658159971
[Epoch 1, Batch 800] loss: 0.3441286626458168
[Epoch 1, Batch 900] loss: 0.2724532038904727
[Epoch 1, Batch 1000] loss: 0.24583764653652906
[Epoch 1, Batch 1100] loss: 0.294571068957448
[Epoch 1, Batch 1200] loss: 0.21244455387815833
[Epoch 1, Batch 1300] loss: 0.20935224065557123
[Epoch 1, Batch 1400] loss: 0.19180975571274758
[Epoch 1, Batch 1500] loss: 0.19714945101179182
[Epoch 1, Batch 1600] loss: 0.16453490636777132
[Epoch 1, Batch 1700] loss: 0.17101783507037907
[Epoch 1, Batch 1800] loss: 0.16355100562330335
[Epoch 1, Batch 1900] loss: 0.12113180968444795
[Epoch 1, Batch 2000] loss: 0.16111838747281582
[Epoch 1, Batch 2100] loss: 0.1291701969783753
[Epoch 1, Batch 2200] loss: 0.1499936715932563
[Epoch 1, Batch 2300] loss: 0.13544937574770302
[Epoch 1, Batch 2400] loss: 0.12225026667350904
[Epoch 1, Batch 2500] loss: 0.12974050327436998
[Epoch 1, Batch 2600] loss: 0.10664131765021011
[Epoch 1, Batch 2700] loss: 0.11901423769071698
[Epoch 1, Batch 2800] loss: 0.12091319853439927
[Epoch 1, Batch 2900] loss: 0.13250857775099575
[Epoch 1, Batch 3000] loss: 0.09604010900249704
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1103
Validation Accuracy: 0.9647
Overfitting: 0.1103
Best model saved at epoch 1 with validation loss: 0.1103
[Epoch 2, Batch 100] loss: 0.12575573418522254
[Epoch 2, Batch 200] loss: 0.09363093460560776
[Epoch 2, Batch 300] loss: 0.10778569297748618
[Epoch 2, Batch 400] loss: 0.1017840327823069
[Epoch 2, Batch 500] loss: 0.0978348157927394
[Epoch 2, Batch 600] loss: 0.09105498425662517
[Epoch 2, Batch 700] loss: 0.07852361845900305
[Epoch 2, Batch 800] loss: 0.08552040136011783
[Epoch 2, Batch 900] loss: 0.09994034296250902
[Epoch 2, Batch 1000] loss: 0.08533634633990005
[Epoch 2, Batch 1100] loss: 0.06249995606893208
[Epoch 2, Batch 1200] loss: 0.08956114486907608
[Epoch 2, Batch 1300] loss: 0.0883812485501403
[Epoch 2, Batch 1400] loss: 0.10375286878785119
[Epoch 2, Batch 1500] loss: 0.09161494656931608
[Epoch 2, Batch 1600] loss: 0.08839893511030823
[Epoch 2, Batch 1700] loss: 0.09051989038242027
[Epoch 2, Batch 1800] loss: 0.07878502050414682
[Epoch 2, Batch 1900] loss: 0.07656593140243785
[Epoch 2, Batch 2000] loss: 0.0867585836953367
[Epoch 2, Batch 2100] loss: 0.0780692772846669
[Epoch 2, Batch 2200] loss: 0.07498722397140227
[Epoch 2, Batch 2300] loss: 0.07656387020309921
[Epoch 2, Batch 2400] loss: 0.07320757651701569
[Epoch 2, Batch 2500] loss: 0.07955233376473188
[Epoch 2, Batch 2600] loss: 0.08068678325391375
[Epoch 2, Batch 2700] loss: 0.0748169325888739
[Epoch 2, Batch 2800] loss: 0.0868814185843803
[Epoch 2, Batch 2900] loss: 0.08365268922876566
[Epoch 2, Batch 3000] loss: 0.06390433405525982
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0821
Validation Accuracy: 0.9751
Overfitting: 0.0821
Best model saved at epoch 2 with validation loss: 0.0821
[Epoch 3, Batch 100] loss: 0.042193643032806
[Epoch 3, Batch 200] loss: 0.08426190847982071
[Epoch 3, Batch 300] loss: 0.06678237908519805
[Epoch 3, Batch 400] loss: 0.07813471279339865
[Epoch 3, Batch 500] loss: 0.06812045217782725
[Epoch 3, Batch 600] loss: 0.04947587784437928
[Epoch 3, Batch 700] loss: 0.06045297952485271
[Epoch 3, Batch 800] loss: 0.07733866698574275
[Epoch 3, Batch 900] loss: 0.059071404384740164
[Epoch 3, Batch 1000] loss: 0.06078315890452359
[Epoch 3, Batch 1100] loss: 0.052167638620594516
[Epoch 3, Batch 1200] loss: 0.07347341613261961
[Epoch 3, Batch 1300] loss: 0.06043452971149236
[Epoch 3, Batch 1400] loss: 0.06438855794360279
[Epoch 3, Batch 1500] loss: 0.0511490327451611
[Epoch 3, Batch 1600] loss: 0.09963535261689685
[Epoch 3, Batch 1700] loss: 0.051600805467460306
[Epoch 3, Batch 1800] loss: 0.06826313677767758
[Epoch 3, Batch 1900] loss: 0.06507480181113351
[Epoch 3, Batch 2000] loss: 0.05423694010823965
[Epoch 3, Batch 2100] loss: 0.06650026421324583
[Epoch 3, Batch 2200] loss: 0.06540835393127054
[Epoch 3, Batch 2300] loss: 0.05093234961852431
[Epoch 3, Batch 2400] loss: 0.054590588411665524
[Epoch 3, Batch 2500] loss: 0.044585398624258234
[Epoch 3, Batch 2600] loss: 0.0560771525214659
[Epoch 3, Batch 2700] loss: 0.061325349887192716
[Epoch 3, Batch 2800] loss: 0.06218372221803293
[Epoch 3, Batch 2900] loss: 0.050447996811126355
[Epoch 3, Batch 3000] loss: 0.03938790240776143
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9835
Overfitting: 0.0532
Best model saved at epoch 3 with validation loss: 0.0532
[Epoch 4, Batch 100] loss: 0.030011045421124437
[Epoch 4, Batch 200] loss: 0.03982597030699253
[Epoch 4, Batch 300] loss: 0.0406057053458062
[Epoch 4, Batch 400] loss: 0.060968301240063735
[Epoch 4, Batch 500] loss: 0.05329885295563144
[Epoch 4, Batch 600] loss: 0.05386031317349989
[Epoch 4, Batch 700] loss: 0.04252041554893367
[Epoch 4, Batch 800] loss: 0.04379731356399134
[Epoch 4, Batch 900] loss: 0.031217226872686295
[Epoch 4, Batch 1000] loss: 0.042227892662485826
[Epoch 4, Batch 1100] loss: 0.06165348787239054
[Epoch 4, Batch 1200] loss: 0.055561848018842286
[Epoch 4, Batch 1300] loss: 0.061209547650505555
[Epoch 4, Batch 1400] loss: 0.04097982255741954
[Epoch 4, Batch 1500] loss: 0.03681244598155899
[Epoch 4, Batch 1600] loss: 0.043100463220034725
[Epoch 4, Batch 1700] loss: 0.04982871050902759
[Epoch 4, Batch 1800] loss: 0.04853242747660261
[Epoch 4, Batch 1900] loss: 0.055974413536387144
[Epoch 4, Batch 2000] loss: 0.04840380487527
[Epoch 4, Batch 2100] loss: 0.04233933524708846
[Epoch 4, Batch 2200] loss: 0.038317374013204245
[Epoch 4, Batch 2300] loss: 0.050358663786319084
[Epoch 4, Batch 2400] loss: 0.05087681076794979
[Epoch 4, Batch 2500] loss: 0.04988080385694047
[Epoch 4, Batch 2600] loss: 0.03716038556056447
[Epoch 4, Batch 2700] loss: 0.039067078001680786
[Epoch 4, Batch 2800] loss: 0.05144243753966293
[Epoch 4, Batch 2900] loss: 0.045798699357546865
[Epoch 4, Batch 3000] loss: 0.056527248415804934
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0692
Validation Accuracy: 0.9802
Overfitting: 0.0692
[Epoch 5, Batch 100] loss: 0.05090097871841863
[Epoch 5, Batch 200] loss: 0.03441253928438528
[Epoch 5, Batch 300] loss: 0.051710707076272226
[Epoch 5, Batch 400] loss: 0.04173849519109354
[Epoch 5, Batch 500] loss: 0.024762518145143984
[Epoch 5, Batch 600] loss: 0.034468360021419356
[Epoch 5, Batch 700] loss: 0.026420025733241346
[Epoch 5, Batch 800] loss: 0.042346080366660314
[Epoch 5, Batch 900] loss: 0.03152795357978903
[Epoch 5, Batch 1000] loss: 0.03665045631285466
[Epoch 5, Batch 1100] loss: 0.03622393748031755
[Epoch 5, Batch 1200] loss: 0.041992989165883045
[Epoch 5, Batch 1300] loss: 0.052325115667481444
[Epoch 5, Batch 1400] loss: 0.021772788078233133
[Epoch 5, Batch 1500] loss: 0.03232654316991102
[Epoch 5, Batch 1600] loss: 0.039804184354143214
[Epoch 5, Batch 1700] loss: 0.0537805316860613
[Epoch 5, Batch 1800] loss: 0.029572527927739428
[Epoch 5, Batch 1900] loss: 0.03315270240200334
[Epoch 5, Batch 2000] loss: 0.04950368283709395
[Epoch 5, Batch 2100] loss: 0.03092862006771611
[Epoch 5, Batch 2200] loss: 0.042936358265433225
[Epoch 5, Batch 2300] loss: 0.023792900297848973
[Epoch 5, Batch 2400] loss: 0.047926710885803914
[Epoch 5, Batch 2500] loss: 0.034459306962962725
[Epoch 5, Batch 2600] loss: 0.03896477307425812
[Epoch 5, Batch 2700] loss: 0.023808125631985602
[Epoch 5, Batch 2800] loss: 0.0513519847925636
[Epoch 5, Batch 2900] loss: 0.04213750778402755
[Epoch 5, Batch 3000] loss: 0.03456593608498224
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9840
Overfitting: 0.0490
Best model saved at epoch 5 with validation loss: 0.0490
[Epoch 6, Batch 100] loss: 0.04583429150632583
[Epoch 6, Batch 200] loss: 0.044081629686988894
[Epoch 6, Batch 300] loss: 0.04402900197535928
[Epoch 6, Batch 400] loss: 0.02855748891066469
[Epoch 6, Batch 500] loss: 0.02484630840590398
[Epoch 6, Batch 600] loss: 0.04089819559681928
[Epoch 6, Batch 700] loss: 0.02968424655813578
[Epoch 6, Batch 800] loss: 0.034722340230582634
[Epoch 6, Batch 900] loss: 0.039329546357766955
[Epoch 6, Batch 1000] loss: 0.018478448971145554
[Epoch 6, Batch 1100] loss: 0.019154763877922962
[Epoch 6, Batch 1200] loss: 0.03162904385677393
[Epoch 6, Batch 1300] loss: 0.034323862275050486
[Epoch 6, Batch 1400] loss: 0.028587770729500334
[Epoch 6, Batch 1500] loss: 0.030309505394834558
[Epoch 6, Batch 1600] loss: 0.039371814605401595
[Epoch 6, Batch 1700] loss: 0.02500582649889111
[Epoch 6, Batch 1800] loss: 0.04071675912549835
[Epoch 6, Batch 1900] loss: 0.03462188544403034
[Epoch 6, Batch 2000] loss: 0.019896481524992852
[Epoch 6, Batch 2100] loss: 0.021876344287848043
[Epoch 6, Batch 2200] loss: 0.04444992295073462
[Epoch 6, Batch 2300] loss: 0.027607554539517878
[Epoch 6, Batch 2400] loss: 0.0427829513886536
[Epoch 6, Batch 2500] loss: 0.04716467425736482
[Epoch 6, Batch 2600] loss: 0.02906489247448917
[Epoch 6, Batch 2700] loss: 0.029688804779434575
[Epoch 6, Batch 2800] loss: 0.015206644026184222
[Epoch 6, Batch 2900] loss: 0.04237978487260989
[Epoch 6, Batch 3000] loss: 0.03657302678351698
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9848
Overfitting: 0.0529
[Epoch 7, Batch 100] loss: 0.028964887825204642
[Epoch 7, Batch 200] loss: 0.03204844675216009
[Epoch 7, Batch 300] loss: 0.025020084023999516
[Epoch 7, Batch 400] loss: 0.016137126246612753
[Epoch 7, Batch 500] loss: 0.029708759432505758
[Epoch 7, Batch 600] loss: 0.026830275629181416
[Epoch 7, Batch 700] loss: 0.042785060412279564
[Epoch 7, Batch 800] loss: 0.024494003811341827
[Epoch 7, Batch 900] loss: 0.031736729290059884
[Epoch 7, Batch 1000] loss: 0.04573320835988852
[Epoch 7, Batch 1100] loss: 0.0354315948540534
[Epoch 7, Batch 1200] loss: 0.02491915799000708
[Epoch 7, Batch 1300] loss: 0.019966910553484922
[Epoch 7, Batch 1400] loss: 0.03490576851034348
[Epoch 7, Batch 1500] loss: 0.04039284612699703
[Epoch 7, Batch 1600] loss: 0.029585581041974365
[Epoch 7, Batch 1700] loss: 0.023447746001911584
[Epoch 7, Batch 1800] loss: 0.02726725516709848
[Epoch 7, Batch 1900] loss: 0.01976159157413349
[Epoch 7, Batch 2000] loss: 0.02882952160005516
[Epoch 7, Batch 2100] loss: 0.03026640895077435
[Epoch 7, Batch 2200] loss: 0.04156333980521595
[Epoch 7, Batch 2300] loss: 0.02822934126634209
[Epoch 7, Batch 2400] loss: 0.03315310771846271
[Epoch 7, Batch 2500] loss: 0.010750860922489664
[Epoch 7, Batch 2600] loss: 0.022035549010061006
[Epoch 7, Batch 2700] loss: 0.02596511732765066
[Epoch 7, Batch 2800] loss: 0.03110907412161396
[Epoch 7, Batch 2900] loss: 0.021951962495513726
[Epoch 7, Batch 3000] loss: 0.02463889043494419
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9853
Overfitting: 0.0513
[Epoch 8, Batch 100] loss: 0.01688825517663645
[Epoch 8, Batch 200] loss: 0.028823905128192565
[Epoch 8, Batch 300] loss: 0.031075129237324292
[Epoch 8, Batch 400] loss: 0.030353123566164868
[Epoch 8, Batch 500] loss: 0.021261335587114447
[Epoch 8, Batch 600] loss: 0.015365408616999048
[Epoch 8, Batch 700] loss: 0.02381319859847281
[Epoch 8, Batch 800] loss: 0.011604746742887074
[Epoch 8, Batch 900] loss: 0.018588530933338916
[Epoch 8, Batch 1000] loss: 0.0240571944554722
[Epoch 8, Batch 1100] loss: 0.012183122420738072
[Epoch 8, Batch 1200] loss: 0.031796361405376956
[Epoch 8, Batch 1300] loss: 0.018106594291093642
[Epoch 8, Batch 1400] loss: 0.01974106582688364
[Epoch 8, Batch 1500] loss: 0.02755162618832401
[Epoch 8, Batch 1600] loss: 0.024448596179518063
[Epoch 8, Batch 1700] loss: 0.022524711627957005
[Epoch 8, Batch 1800] loss: 0.015026438287095515
[Epoch 8, Batch 1900] loss: 0.0332733983469916
[Epoch 8, Batch 2000] loss: 0.02030157851142576
[Epoch 8, Batch 2100] loss: 0.04585317900364316
[Epoch 8, Batch 2200] loss: 0.017507061520664138
[Epoch 8, Batch 2300] loss: 0.022008043157493374
[Epoch 8, Batch 2400] loss: 0.02277903524411158
[Epoch 8, Batch 2500] loss: 0.026573574493268096
[Epoch 8, Batch 2600] loss: 0.02622743304668802
[Epoch 8, Batch 2700] loss: 0.02819614863348761
[Epoch 8, Batch 2800] loss: 0.012945768022182164
[Epoch 8, Batch 2900] loss: 0.027883957257254222
[Epoch 8, Batch 3000] loss: 0.021636379262945413
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9851
Overfitting: 0.0507
[Epoch 9, Batch 100] loss: 0.013106923174527765
[Epoch 9, Batch 200] loss: 0.016432755834139244
[Epoch 9, Batch 300] loss: 0.030736596426959296
[Epoch 9, Batch 400] loss: 0.022171725483804038
[Epoch 9, Batch 500] loss: 0.017874236902107443
[Epoch 9, Batch 600] loss: 0.02180691549208859
[Epoch 9, Batch 700] loss: 0.020371070847431838
[Epoch 9, Batch 800] loss: 0.01312708538640436
[Epoch 9, Batch 900] loss: 0.021292342858705526
[Epoch 9, Batch 1000] loss: 0.011930766800267065
[Epoch 9, Batch 1100] loss: 0.013816120561168646
[Epoch 9, Batch 1200] loss: 0.014857163901142485
[Epoch 9, Batch 1300] loss: 0.016588453150598072
[Epoch 9, Batch 1400] loss: 0.02591338110882134
[Epoch 9, Batch 1500] loss: 0.025201354014625393
[Epoch 9, Batch 1600] loss: 0.032501128300864365
[Epoch 9, Batch 1700] loss: 0.021928584884590235
[Epoch 9, Batch 1800] loss: 0.024939756897183543
[Epoch 9, Batch 1900] loss: 0.00858204436784945
[Epoch 9, Batch 2000] loss: 0.017300413095308612
[Epoch 9, Batch 2100] loss: 0.01793988850849928
[Epoch 9, Batch 2200] loss: 0.028434887536386667
[Epoch 9, Batch 2300] loss: 0.0387038156244671
[Epoch 9, Batch 2400] loss: 0.025060201374108148
[Epoch 9, Batch 2500] loss: 0.023642613517404244
[Epoch 9, Batch 2600] loss: 0.022199206134519044
[Epoch 9, Batch 2700] loss: 0.020899387148783716
[Epoch 9, Batch 2800] loss: 0.016057512100451275
[Epoch 9, Batch 2900] loss: 0.023219076659079293
[Epoch 9, Batch 3000] loss: 0.016181218958745375
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0410
Validation Accuracy: 0.9882
Overfitting: 0.0410
Best model saved at epoch 9 with validation loss: 0.0410
[Epoch 10, Batch 100] loss: 0.013837706781305314
[Epoch 10, Batch 200] loss: 0.018357852867738986
[Epoch 10, Batch 300] loss: 0.013813951200304472
[Epoch 10, Batch 400] loss: 0.010305541202515088
[Epoch 10, Batch 500] loss: 0.009753812800320248
[Epoch 10, Batch 600] loss: 0.008039585536229197
[Epoch 10, Batch 700] loss: 0.025177396057024452
[Epoch 10, Batch 800] loss: 0.02255523535686734
[Epoch 10, Batch 900] loss: 0.019655864882261086
[Epoch 10, Batch 1000] loss: 0.017847723866161687
[Epoch 10, Batch 1100] loss: 0.015069494750869127
[Epoch 10, Batch 1200] loss: 0.015258011096912015
[Epoch 10, Batch 1300] loss: 0.03162963972669786
[Epoch 10, Batch 1400] loss: 0.012521387388196671
[Epoch 10, Batch 1500] loss: 0.013334143693896294
[Epoch 10, Batch 1600] loss: 0.026090929734837117
[Epoch 10, Batch 1700] loss: 0.01217721959537812
[Epoch 10, Batch 1800] loss: 0.023143906223540397
[Epoch 10, Batch 1900] loss: 0.009919315578204078
[Epoch 10, Batch 2000] loss: 0.012182363268238986
[Epoch 10, Batch 2100] loss: 0.015022652073521386
[Epoch 10, Batch 2200] loss: 0.028232677273554146
[Epoch 10, Batch 2300] loss: 0.01781527980710962
[Epoch 10, Batch 2400] loss: 0.01419435075522415
[Epoch 10, Batch 2500] loss: 0.02585113741530222
[Epoch 10, Batch 2600] loss: 0.01891849459356308
[Epoch 10, Batch 2700] loss: 0.020575388155202746
[Epoch 10, Batch 2800] loss: 0.017251145422696935
[Epoch 10, Batch 2900] loss: 0.017963056491435054
[Epoch 10, Batch 3000] loss: 0.013755229141470409
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0396
Validation Accuracy: 0.9895
Overfitting: 0.0396
Best model saved at epoch 10 with validation loss: 0.0396
[Epoch 11, Batch 100] loss: 0.008892649876252108
[Epoch 11, Batch 200] loss: 0.01024044615613093
[Epoch 11, Batch 300] loss: 0.008412277035340594
[Epoch 11, Batch 400] loss: 0.011120189206139912
[Epoch 11, Batch 500] loss: 0.01530183114546162
[Epoch 11, Batch 600] loss: 0.009377718087771427
[Epoch 11, Batch 700] loss: 0.012987267485482335
[Epoch 11, Batch 800] loss: 0.013446464949793154
[Epoch 11, Batch 900] loss: 0.030143558868312537
[Epoch 11, Batch 1000] loss: 0.023932209409122152
[Epoch 11, Batch 1100] loss: 0.014403865206604678
[Epoch 11, Batch 1200] loss: 0.015320957280318908
[Epoch 11, Batch 1300] loss: 0.009159409409198816
[Epoch 11, Batch 1400] loss: 0.01446437921013512
[Epoch 11, Batch 1500] loss: 0.012449266869734856
[Epoch 11, Batch 1600] loss: 0.013012496247720265
[Epoch 11, Batch 1700] loss: 0.01878924699015897
[Epoch 11, Batch 1800] loss: 0.020648337784805335
[Epoch 11, Batch 1900] loss: 0.013373311625919086
[Epoch 11, Batch 2000] loss: 0.009721582252645931
[Epoch 11, Batch 2100] loss: 0.006472430817220811
[Epoch 11, Batch 2200] loss: 0.017607429956433406
[Epoch 11, Batch 2300] loss: 0.01454420004871281
[Epoch 11, Batch 2400] loss: 0.01237900899682245
[Epoch 11, Batch 2500] loss: 0.022598185745205227
[Epoch 11, Batch 2600] loss: 0.015099868457000412
[Epoch 11, Batch 2700] loss: 0.021235706563729764
[Epoch 11, Batch 2800] loss: 0.023806730901233097
[Epoch 11, Batch 2900] loss: 0.028868114874148885
[Epoch 11, Batch 3000] loss: 0.0198632780554226
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0415
Validation Accuracy: 0.9884
Overfitting: 0.0415
[Epoch 12, Batch 100] loss: 0.007844682267332245
[Epoch 12, Batch 200] loss: 0.012019022322983802
[Epoch 12, Batch 300] loss: 0.029988559114999588
[Epoch 12, Batch 400] loss: 0.008897623432130786
[Epoch 12, Batch 500] loss: 0.03206922856592882
[Epoch 12, Batch 600] loss: 0.020297384432078614
[Epoch 12, Batch 700] loss: 0.012246297739638977
[Epoch 12, Batch 800] loss: 0.024193778787830526
[Epoch 12, Batch 900] loss: 0.018361209985841925
[Epoch 12, Batch 1000] loss: 0.01175456527973779
[Epoch 12, Batch 1100] loss: 0.007882745874453576
[Epoch 12, Batch 1200] loss: 0.007958743920985398
[Epoch 12, Batch 1300] loss: 0.018104641874501795
[Epoch 12, Batch 1400] loss: 0.011009752173067681
[Epoch 12, Batch 1500] loss: 0.016177420044919018
[Epoch 12, Batch 1600] loss: 0.010848981825020018
[Epoch 12, Batch 1700] loss: 0.020539757417436702
[Epoch 12, Batch 1800] loss: 0.022829048096446057
[Epoch 12, Batch 1900] loss: 0.020559990044957885
[Epoch 12, Batch 2000] loss: 0.011057087037424935
[Epoch 12, Batch 2100] loss: 0.01697807055474641
[Epoch 12, Batch 2200] loss: 0.016799970349425167
[Epoch 12, Batch 2300] loss: 0.008564213751894272
[Epoch 12, Batch 2400] loss: 0.01937837299356488
[Epoch 12, Batch 2500] loss: 0.005211787196692512
[Epoch 12, Batch 2600] loss: 0.00588085155871056
[Epoch 12, Batch 2700] loss: 0.02237746895109012
[Epoch 12, Batch 2800] loss: 0.012405942739390526
[Epoch 12, Batch 2900] loss: 0.012107244369872205
[Epoch 12, Batch 3000] loss: 0.018959282609157527
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9873
Overfitting: 0.0463
[Epoch 13, Batch 100] loss: 0.015561941580613166
[Epoch 13, Batch 200] loss: 0.017322968287821823
[Epoch 13, Batch 300] loss: 0.0058911450258403875
[Epoch 13, Batch 400] loss: 0.008294014491302732
[Epoch 13, Batch 500] loss: 0.006637303738456382
[Epoch 13, Batch 600] loss: 0.013886988851419346
[Epoch 13, Batch 700] loss: 0.006926044445481239
[Epoch 13, Batch 800] loss: 0.00995437294753401
[Epoch 13, Batch 900] loss: 0.017415135657608972
[Epoch 13, Batch 1000] loss: 0.008933504349674876
[Epoch 13, Batch 1100] loss: 0.021073982080026782
[Epoch 13, Batch 1200] loss: 0.016357252027983122
[Epoch 13, Batch 1300] loss: 0.019727130025862606
[Epoch 13, Batch 1400] loss: 0.015599920105355523
[Epoch 13, Batch 1500] loss: 0.019512332718868493
[Epoch 13, Batch 1600] loss: 0.017857846953857007
[Epoch 13, Batch 1700] loss: 0.009064954501779994
[Epoch 13, Batch 1800] loss: 0.008546304781090157
[Epoch 13, Batch 1900] loss: 0.01166252398145616
[Epoch 13, Batch 2000] loss: 0.01562437070992928
[Epoch 13, Batch 2100] loss: 0.011924999398952424
[Epoch 13, Batch 2200] loss: 0.01090166026739098
[Epoch 13, Batch 2300] loss: 0.00992663999295587
[Epoch 13, Batch 2400] loss: 0.01423147215658446
[Epoch 13, Batch 2500] loss: 0.01115603337275843
[Epoch 13, Batch 2600] loss: 0.02121682229873386
[Epoch 13, Batch 2700] loss: 0.015294791387623264
[Epoch 13, Batch 2800] loss: 0.02232225549410714
[Epoch 13, Batch 2900] loss: 0.0042155298847126235
[Epoch 13, Batch 3000] loss: 0.014907849562068804
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9863
Overfitting: 0.0467
[Epoch 14, Batch 100] loss: 0.010805906049093893
[Epoch 14, Batch 200] loss: 0.005357260407113245
[Epoch 14, Batch 300] loss: 0.008708112748206532
[Epoch 14, Batch 400] loss: 0.02167743648267333
[Epoch 14, Batch 500] loss: 0.003455530583564723
[Epoch 14, Batch 600] loss: 0.007151438936729164
[Epoch 14, Batch 700] loss: 0.0095295116023442
[Epoch 14, Batch 800] loss: 0.00754646166724342
[Epoch 14, Batch 900] loss: 0.010874887943332396
[Epoch 14, Batch 1000] loss: 0.012104706535235437
[Epoch 14, Batch 1100] loss: 0.008976365237473374
[Epoch 14, Batch 1200] loss: 0.0034683691878444733
[Epoch 14, Batch 1300] loss: 0.006004619198458841
[Epoch 14, Batch 1400] loss: 0.005656702066809203
[Epoch 14, Batch 1500] loss: 0.013517292479420746
[Epoch 14, Batch 1600] loss: 0.018768756014563907
[Epoch 14, Batch 1700] loss: 0.012140850136495374
[Epoch 14, Batch 1800] loss: 0.013539005411603284
[Epoch 14, Batch 1900] loss: 0.014713589296709415
[Epoch 14, Batch 2000] loss: 0.020733894742569987
[Epoch 14, Batch 2100] loss: 0.007365482732184319
[Epoch 14, Batch 2200] loss: 0.024954967175176535
[Epoch 14, Batch 2300] loss: 0.015083714546203737
[Epoch 14, Batch 2400] loss: 0.013201681525538333
[Epoch 14, Batch 2500] loss: 0.006148175793236987
[Epoch 14, Batch 2600] loss: 0.016160397434523476
[Epoch 14, Batch 2700] loss: 0.011007353214837394
[Epoch 14, Batch 2800] loss: 0.014645395401331598
[Epoch 14, Batch 2900] loss: 0.012593809283030168
[Epoch 14, Batch 3000] loss: 0.013451308514599986
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9885
Overfitting: 0.0456
[Epoch 15, Batch 100] loss: 0.004422397064302004
[Epoch 15, Batch 200] loss: 0.005908876526103768
[Epoch 15, Batch 300] loss: 0.011969429253293811
[Epoch 15, Batch 400] loss: 0.009408278036886486
[Epoch 15, Batch 500] loss: 0.003793105274436357
[Epoch 15, Batch 600] loss: 0.008274136221888852
[Epoch 15, Batch 700] loss: 0.006390032787375048
[Epoch 15, Batch 800] loss: 0.00829572509887612
[Epoch 15, Batch 900] loss: 0.005793927180521905
[Epoch 15, Batch 1000] loss: 0.004099138128869981
[Epoch 15, Batch 1100] loss: 0.008647753855912014
[Epoch 15, Batch 1200] loss: 0.006765994741264194
[Epoch 15, Batch 1300] loss: 0.01236263263890308
[Epoch 15, Batch 1400] loss: 0.01098002507087358
[Epoch 15, Batch 1500] loss: 0.0107518639147861
[Epoch 15, Batch 1600] loss: 0.0044000452561977
[Epoch 15, Batch 1700] loss: 0.00410309050157025
[Epoch 15, Batch 1800] loss: 0.00929271135847216
[Epoch 15, Batch 1900] loss: 0.020994722906007724
[Epoch 15, Batch 2000] loss: 0.012054266150601052
[Epoch 15, Batch 2100] loss: 0.008403496242201526
[Epoch 15, Batch 2200] loss: 0.013036124136368699
[Epoch 15, Batch 2300] loss: 0.005365040780450272
[Epoch 15, Batch 2400] loss: 0.011459826240844677
[Epoch 15, Batch 2500] loss: 0.01045491756809838
[Epoch 15, Batch 2600] loss: 0.022825439579914928
[Epoch 15, Batch 2700] loss: 0.01902959891854607
[Epoch 15, Batch 2800] loss: 0.010246388231330457
[Epoch 15, Batch 2900] loss: 0.022722756305780082
[Epoch 15, Batch 3000] loss: 0.013996771973979775
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9872
Overfitting: 0.0472
[Epoch 16, Batch 100] loss: 0.003292659146800361
[Epoch 16, Batch 200] loss: 0.005815774092006905
[Epoch 16, Batch 300] loss: 0.006351777062287738
[Epoch 16, Batch 400] loss: 0.004798666900780688
[Epoch 16, Batch 500] loss: 0.010230270134547937
[Epoch 16, Batch 600] loss: 0.006124586346759315
[Epoch 16, Batch 700] loss: 0.010889572877214277
[Epoch 16, Batch 800] loss: 0.003510442205860045
[Epoch 16, Batch 900] loss: 0.003612076794809127
[Epoch 16, Batch 1000] loss: 0.003880607978402395
[Epoch 16, Batch 1100] loss: 0.009881715397381753
[Epoch 16, Batch 1200] loss: 0.008933153754589397
[Epoch 16, Batch 1300] loss: 0.007462907822890656
[Epoch 16, Batch 1400] loss: 0.01519928546486426
[Epoch 16, Batch 1500] loss: 0.008161814100578226
[Epoch 16, Batch 1600] loss: 0.006605061412237774
[Epoch 16, Batch 1700] loss: 0.010789303936269335
[Epoch 16, Batch 1800] loss: 0.007815151023709176
[Epoch 16, Batch 1900] loss: 0.014597041023736778
[Epoch 16, Batch 2000] loss: 0.01585707604535969
[Epoch 16, Batch 2100] loss: 0.01318350357155822
[Epoch 16, Batch 2200] loss: 0.013950457085101675
[Epoch 16, Batch 2300] loss: 0.015568274654687287
[Epoch 16, Batch 2400] loss: 0.0070664849286367825
[Epoch 16, Batch 2500] loss: 0.01704100803865682
[Epoch 16, Batch 2600] loss: 0.008218699393153202
[Epoch 16, Batch 2700] loss: 0.014142254395692362
[Epoch 16, Batch 2800] loss: 0.021964053134117877
[Epoch 16, Batch 2900] loss: 0.011812825801520148
[Epoch 16, Batch 3000] loss: 0.013467777053665485
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0421
Validation Accuracy: 0.9878
Overfitting: 0.0421
[Epoch 17, Batch 100] loss: 0.009568271905066013
[Epoch 17, Batch 200] loss: 0.0038755718781180804
[Epoch 17, Batch 300] loss: 0.0059255644810639295
[Epoch 17, Batch 400] loss: 0.003561882803298886
[Epoch 17, Batch 500] loss: 0.006695509302792288
[Epoch 17, Batch 600] loss: 0.005613603774226022
[Epoch 17, Batch 700] loss: 0.003050695722332648
[Epoch 17, Batch 800] loss: 0.0019503706775708452
[Epoch 17, Batch 900] loss: 0.005576280166056797
[Epoch 17, Batch 1000] loss: 0.0057791210281556
[Epoch 17, Batch 1100] loss: 0.012301566711814047
[Epoch 17, Batch 1200] loss: 0.013072708591749915
[Epoch 17, Batch 1300] loss: 0.005012809308310579
[Epoch 17, Batch 1400] loss: 0.00422718645957275
[Epoch 17, Batch 1500] loss: 0.004192397514663071
[Epoch 17, Batch 1600] loss: 0.006662404421132351
[Epoch 17, Batch 1700] loss: 0.012873893482301356
[Epoch 17, Batch 1800] loss: 0.008296599634762742
[Epoch 17, Batch 1900] loss: 0.009093887246452824
[Epoch 17, Batch 2000] loss: 0.011163449630339528
[Epoch 17, Batch 2100] loss: 0.012129696686695866
[Epoch 17, Batch 2200] loss: 0.0035555753129460754
[Epoch 17, Batch 2300] loss: 0.0055532385980358616
[Epoch 17, Batch 2400] loss: 0.005557567148873659
[Epoch 17, Batch 2500] loss: 0.004343191844629075
[Epoch 17, Batch 2600] loss: 0.00916910403045449
[Epoch 17, Batch 2700] loss: 0.01091171427452192
[Epoch 17, Batch 2800] loss: 0.013915144618048316
[Epoch 17, Batch 2900] loss: 0.016727577849004548
[Epoch 17, Batch 3000] loss: 0.012093417137656388
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9887
Overfitting: 0.0436
[Epoch 18, Batch 100] loss: 0.003467517703154499
[Epoch 18, Batch 200] loss: 0.00633169537223722
[Epoch 18, Batch 300] loss: 0.006186451662911168
[Epoch 18, Batch 400] loss: 0.0016741533225935257
[Epoch 18, Batch 500] loss: 0.0034133013203208407
[Epoch 18, Batch 600] loss: 0.004644642201697025
[Epoch 18, Batch 700] loss: 0.0033633151390449713
[Epoch 18, Batch 800] loss: 0.0025362485978016026
[Epoch 18, Batch 900] loss: 0.0013055180013361678
[Epoch 18, Batch 1000] loss: 0.0022452151160585743
[Epoch 18, Batch 1100] loss: 0.01184230342364458
[Epoch 18, Batch 1200] loss: 0.011111246709683087
[Epoch 18, Batch 1300] loss: 0.004218409383002779
[Epoch 18, Batch 1400] loss: 0.005687329828785437
[Epoch 18, Batch 1500] loss: 0.0043881593328232785
[Epoch 18, Batch 1600] loss: 0.002932903209791391
[Epoch 18, Batch 1700] loss: 0.003738300480378882
[Epoch 18, Batch 1800] loss: 0.006465736336322152
[Epoch 18, Batch 1900] loss: 0.009914360368941288
[Epoch 18, Batch 2000] loss: 0.00281305135034728
[Epoch 18, Batch 2100] loss: 0.011068086466457317
[Epoch 18, Batch 2200] loss: 0.006672268385431153
[Epoch 18, Batch 2300] loss: 0.014377684637878474
[Epoch 18, Batch 2400] loss: 0.003095347160261781
[Epoch 18, Batch 2500] loss: 0.004306797219676497
[Epoch 18, Batch 2600] loss: 0.007822022542477498
[Epoch 18, Batch 2700] loss: 0.007864218955257912
[Epoch 18, Batch 2800] loss: 0.0074003713770652265
[Epoch 18, Batch 2900] loss: 0.006566817462436347
[Epoch 18, Batch 3000] loss: 0.013882828254735777
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0577
Validation Accuracy: 0.9867
Overfitting: 0.0577
[Epoch 19, Batch 100] loss: 0.01101226761685325
[Epoch 19, Batch 200] loss: 0.004412544088362438
[Epoch 19, Batch 300] loss: 0.013927813700748573
[Epoch 19, Batch 400] loss: 0.007785522097931406
[Epoch 19, Batch 500] loss: 0.0021652682724923977
[Epoch 19, Batch 600] loss: 0.0028611886849674306
[Epoch 19, Batch 700] loss: 0.007150163704104671
[Epoch 19, Batch 800] loss: 0.0035278698850358127
[Epoch 19, Batch 900] loss: 0.008230565323976152
[Epoch 19, Batch 1000] loss: 0.006846112668646071
[Epoch 19, Batch 1100] loss: 0.008154498801090853
[Epoch 19, Batch 1200] loss: 0.007086472279226114
[Epoch 19, Batch 1300] loss: 0.010217956094610372
[Epoch 19, Batch 1400] loss: 0.008944617002893552
[Epoch 19, Batch 1500] loss: 0.011392395009862355
[Epoch 19, Batch 1600] loss: 0.00696044927959349
[Epoch 19, Batch 1700] loss: 0.006361144290255396
[Epoch 19, Batch 1800] loss: 0.003413021247031622
[Epoch 19, Batch 1900] loss: 0.0019336514675916306
[Epoch 19, Batch 2000] loss: 0.00395439569244953
[Epoch 19, Batch 2100] loss: 0.010632134161041336
[Epoch 19, Batch 2200] loss: 0.0048034789486791855
[Epoch 19, Batch 2300] loss: 0.006248268344612029
[Epoch 19, Batch 2400] loss: 0.009753617484424488
[Epoch 19, Batch 2500] loss: 0.006253538614194549
[Epoch 19, Batch 2600] loss: 0.0029149063595172464
[Epoch 19, Batch 2700] loss: 0.013347725374096626
[Epoch 19, Batch 2800] loss: 0.008000496210399319
[Epoch 19, Batch 2900] loss: 0.004891277376248127
[Epoch 19, Batch 3000] loss: 0.002929581649635078
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9895
Overfitting: 0.0459
[Epoch 20, Batch 100] loss: 0.001786212541437635
[Epoch 20, Batch 200] loss: 0.004551693938766448
[Epoch 20, Batch 300] loss: 0.0022112179171816138
[Epoch 20, Batch 400] loss: 0.0038132922785753466
[Epoch 20, Batch 500] loss: 0.008922113519282106
[Epoch 20, Batch 600] loss: 0.005584799824081017
[Epoch 20, Batch 700] loss: 0.006516724547203481
[Epoch 20, Batch 800] loss: 0.004593135937859927
[Epoch 20, Batch 900] loss: 0.005154181824895545
[Epoch 20, Batch 1000] loss: 0.0024294579909017954
[Epoch 20, Batch 1100] loss: 0.0028378086416646787
[Epoch 20, Batch 1200] loss: 0.002319716196836548
[Epoch 20, Batch 1300] loss: 0.004867410124899721
[Epoch 20, Batch 1400] loss: 0.0024602166088339315
[Epoch 20, Batch 1500] loss: 0.003467866589389521
[Epoch 20, Batch 1600] loss: 0.0030299079680007777
[Epoch 20, Batch 1700] loss: 0.0018690254528881667
[Epoch 20, Batch 1800] loss: 0.008855834538738137
[Epoch 20, Batch 1900] loss: 0.007279156056450659
[Epoch 20, Batch 2000] loss: 0.0034789120804008178
[Epoch 20, Batch 2100] loss: 0.003453005884607574
[Epoch 20, Batch 2200] loss: 0.00992381918329329
[Epoch 20, Batch 2300] loss: 0.00704596108211831
[Epoch 20, Batch 2400] loss: 0.009745032823148847
[Epoch 20, Batch 2500] loss: 0.005777407293329481
[Epoch 20, Batch 2600] loss: 0.006875562832161108
[Epoch 20, Batch 2700] loss: 0.003203048712027865
[Epoch 20, Batch 2800] loss: 0.005269112909032785
[Epoch 20, Batch 2900] loss: 0.0032906250608949962
[Epoch 20, Batch 3000] loss: 0.005480893889364893
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9893
Overfitting: 0.0484
[Epoch 21, Batch 100] loss: 0.006200614295227638
[Epoch 21, Batch 200] loss: 0.005353299298972729
[Epoch 21, Batch 300] loss: 0.005498613985772351
[Epoch 21, Batch 400] loss: 0.004572775586256057
[Epoch 21, Batch 500] loss: 0.0056356781857991225
[Epoch 21, Batch 600] loss: 0.0025263153413176377
[Epoch 21, Batch 700] loss: 0.006332852507995312
[Epoch 21, Batch 800] loss: 0.005380186113684431
[Epoch 21, Batch 900] loss: 0.003560902389811815
[Epoch 21, Batch 1000] loss: 0.002139821884807702
[Epoch 21, Batch 1100] loss: 0.0014495965995369176
[Epoch 21, Batch 1200] loss: 0.015234121026791456
[Epoch 21, Batch 1300] loss: 0.0038462052197604634
[Epoch 21, Batch 1400] loss: 0.003605283863514899
[Epoch 21, Batch 1500] loss: 0.001978880429387786
[Epoch 21, Batch 1600] loss: 0.006516536486694804
[Epoch 21, Batch 1700] loss: 0.006968663067676726
[Epoch 21, Batch 1800] loss: 0.004165601971587876
[Epoch 21, Batch 1900] loss: 0.00230676436248487
[Epoch 21, Batch 2000] loss: 0.0024774458073524384
[Epoch 21, Batch 2100] loss: 0.012360557863989072
[Epoch 21, Batch 2200] loss: 0.00944492822432963
[Epoch 21, Batch 2300] loss: 0.0036540185378803967
[Epoch 21, Batch 2400] loss: 0.003638362572146434
[Epoch 21, Batch 2500] loss: 0.008422351459057752
[Epoch 21, Batch 2600] loss: 0.014395370771616385
[Epoch 21, Batch 2700] loss: 0.01885301394161928
[Epoch 21, Batch 2800] loss: 0.013441095792003352
[Epoch 21, Batch 2900] loss: 0.010736641692037665
[Epoch 21, Batch 3000] loss: 0.009193997873842364
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0584
Validation Accuracy: 0.9874
Overfitting: 0.0584
[Epoch 22, Batch 100] loss: 0.004906793363964184
[Epoch 22, Batch 200] loss: 0.006379077969920317
[Epoch 22, Batch 300] loss: 0.0024134994300059986
[Epoch 22, Batch 400] loss: 0.002590190971741535
[Epoch 22, Batch 500] loss: 0.0018469618032761303
[Epoch 22, Batch 600] loss: 0.004849424102730335
[Epoch 22, Batch 700] loss: 0.005500291806367405
[Epoch 22, Batch 800] loss: 0.00730428113047239
[Epoch 22, Batch 900] loss: 0.002888598010869998
[Epoch 22, Batch 1000] loss: 0.0014326233604531069
[Epoch 22, Batch 1100] loss: 0.0034048806129902687
[Epoch 22, Batch 1200] loss: 0.004047673112766006
[Epoch 22, Batch 1300] loss: 0.002799167143219279
[Epoch 22, Batch 1400] loss: 0.0024280276408813963
[Epoch 22, Batch 1500] loss: 0.0021414380349713724
[Epoch 22, Batch 1600] loss: 0.0010824721263623927
[Epoch 22, Batch 1700] loss: 0.006268517831412623
[Epoch 22, Batch 1800] loss: 0.00411120666138828
[Epoch 22, Batch 1900] loss: 0.0038807779768425376
[Epoch 22, Batch 2000] loss: 0.010069229341871804
[Epoch 22, Batch 2100] loss: 0.001532721361751328
[Epoch 22, Batch 2200] loss: 0.0004239822609786614
[Epoch 22, Batch 2300] loss: 0.0025806824858266
[Epoch 22, Batch 2400] loss: 0.008037514335992873
[Epoch 22, Batch 2500] loss: 0.0024180841003956033
[Epoch 22, Batch 2600] loss: 0.0010216794172307076
[Epoch 22, Batch 2700] loss: 0.002929690452022271
[Epoch 22, Batch 2800] loss: 0.0013905631701824417
[Epoch 22, Batch 2900] loss: 0.004998765574414996
[Epoch 22, Batch 3000] loss: 0.004487118219184278
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9887
Overfitting: 0.0504
[Epoch 23, Batch 100] loss: 0.0018910150873769594
[Epoch 23, Batch 200] loss: 0.0014011336446472101
[Epoch 23, Batch 300] loss: 0.0026691776652001133
[Epoch 23, Batch 400] loss: 0.0022025738518563066
[Epoch 23, Batch 500] loss: 0.005566496085337729
[Epoch 23, Batch 600] loss: 0.0042032485137417554
[Epoch 23, Batch 700] loss: 0.006327915143189529
[Epoch 23, Batch 800] loss: 0.005867293000079705
[Epoch 23, Batch 900] loss: 0.0037038909301163867
[Epoch 23, Batch 1000] loss: 0.0015359951084577927
[Epoch 23, Batch 1100] loss: 0.0017908082677417524
[Epoch 23, Batch 1200] loss: 0.0023337471587710824
[Epoch 23, Batch 1300] loss: 0.0017588883635718134
[Epoch 23, Batch 1400] loss: 0.008736810048719974
[Epoch 23, Batch 1500] loss: 0.005762866580243227
[Epoch 23, Batch 1600] loss: 0.004190837418781754
[Epoch 23, Batch 1700] loss: 0.006793355822246379
[Epoch 23, Batch 1800] loss: 0.008804869149589214
[Epoch 23, Batch 1900] loss: 0.007726331962379618
[Epoch 23, Batch 2000] loss: 0.010605709308175015
[Epoch 23, Batch 2100] loss: 0.005681054268039816
[Epoch 23, Batch 2200] loss: 0.0058756200634595855
[Epoch 23, Batch 2300] loss: 0.006710418319445637
[Epoch 23, Batch 2400] loss: 0.00955106125058819
[Epoch 23, Batch 2500] loss: 0.0035579492347794428
[Epoch 23, Batch 2600] loss: 0.0028762961745511005
[Epoch 23, Batch 2700] loss: 0.003391886080354709
[Epoch 23, Batch 2800] loss: 0.008440747865657792
[Epoch 23, Batch 2900] loss: 0.014505012391761198
[Epoch 23, Batch 3000] loss: 0.015117259170206765
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0648
Validation Accuracy: 0.9855
Overfitting: 0.0648
[Epoch 24, Batch 100] loss: 0.0030613817259819596
[Epoch 24, Batch 200] loss: 0.004020809788216582
[Epoch 24, Batch 300] loss: 0.004451772766031823
[Epoch 24, Batch 400] loss: 0.003954559389585946
[Epoch 24, Batch 500] loss: 0.001881195815423382
[Epoch 24, Batch 600] loss: 0.0018130775054587644
[Epoch 24, Batch 700] loss: 0.0027311539204371016
[Epoch 24, Batch 800] loss: 0.002906309365413069
[Epoch 24, Batch 900] loss: 0.0013308971071424392
[Epoch 24, Batch 1000] loss: 0.001510328392983027
[Epoch 24, Batch 1100] loss: 0.0009376740374866754
[Epoch 24, Batch 1200] loss: 0.0013015729306537294
[Epoch 24, Batch 1300] loss: 0.0026747135381491116
[Epoch 24, Batch 1400] loss: 0.006836574822926025
[Epoch 24, Batch 1500] loss: 0.002691244917296416
[Epoch 24, Batch 1600] loss: 0.003053092379051918
[Epoch 24, Batch 1700] loss: 0.006590298921237245
[Epoch 24, Batch 1800] loss: 0.0027713230340828776
[Epoch 24, Batch 1900] loss: 0.004911443982318602
[Epoch 24, Batch 2000] loss: 0.004525346829021118
[Epoch 24, Batch 2100] loss: 0.005784879033741386
[Epoch 24, Batch 2200] loss: 0.0033744773419985743
[Epoch 24, Batch 2300] loss: 0.002907526164963996
[Epoch 24, Batch 2400] loss: 0.008077518405576817
[Epoch 24, Batch 2500] loss: 0.010360226409012853
[Epoch 24, Batch 2600] loss: 0.004294668797053589
[Epoch 24, Batch 2700] loss: 0.0032127624522585306
[Epoch 24, Batch 2800] loss: 0.009262977162627735
[Epoch 24, Batch 2900] loss: 0.007591298837357021
[Epoch 24, Batch 3000] loss: 0.0033894233976430586
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9892
Overfitting: 0.0532
Fold 4 validation loss: 0.0532
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.293266453742981
[Epoch 1, Batch 200] loss: 2.2107925987243653
[Epoch 1, Batch 300] loss: 1.5179798990488051
[Epoch 1, Batch 400] loss: 0.6978413960337639
[Epoch 1, Batch 500] loss: 0.5381736280024052
[Epoch 1, Batch 600] loss: 0.3688437977433205
[Epoch 1, Batch 700] loss: 0.3409267359226942
[Epoch 1, Batch 800] loss: 0.2826300809904933
[Epoch 1, Batch 900] loss: 0.2520865081436932
[Epoch 1, Batch 1000] loss: 0.2802138058654964
[Epoch 1, Batch 1100] loss: 0.20491795087233186
[Epoch 1, Batch 1200] loss: 0.19691418696194887
[Epoch 1, Batch 1300] loss: 0.2383388752117753
[Epoch 1, Batch 1400] loss: 0.18607567068189382
[Epoch 1, Batch 1500] loss: 0.18039723896421492
[Epoch 1, Batch 1600] loss: 0.15243527435231954
[Epoch 1, Batch 1700] loss: 0.15829498891718685
[Epoch 1, Batch 1800] loss: 0.13977987407008186
[Epoch 1, Batch 1900] loss: 0.13255635102745145
[Epoch 1, Batch 2000] loss: 0.1429532492067665
[Epoch 1, Batch 2100] loss: 0.10626859296113253
[Epoch 1, Batch 2200] loss: 0.12391397584229707
[Epoch 1, Batch 2300] loss: 0.13464680210920052
[Epoch 1, Batch 2400] loss: 0.10456573870149441
[Epoch 1, Batch 2500] loss: 0.11231059266487137
[Epoch 1, Batch 2600] loss: 0.11816990717081353
[Epoch 1, Batch 2700] loss: 0.11915822080569342
[Epoch 1, Batch 2800] loss: 0.08741531703621148
[Epoch 1, Batch 2900] loss: 0.10107033428968862
[Epoch 1, Batch 3000] loss: 0.09563614801038056
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0957
Validation Accuracy: 0.9720
Overfitting: 0.0957
Best model saved at epoch 1 with validation loss: 0.0957
[Epoch 2, Batch 100] loss: 0.08540315236663445
[Epoch 2, Batch 200] loss: 0.10158008113852703
[Epoch 2, Batch 300] loss: 0.10093946853652597
[Epoch 2, Batch 400] loss: 0.09849735241266899
[Epoch 2, Batch 500] loss: 0.0743936213827692
[Epoch 2, Batch 600] loss: 0.06826229832367972
[Epoch 2, Batch 700] loss: 0.11811393818701617
[Epoch 2, Batch 800] loss: 0.09029520174022763
[Epoch 2, Batch 900] loss: 0.08158825909602456
[Epoch 2, Batch 1000] loss: 0.0670313728461042
[Epoch 2, Batch 1100] loss: 0.06410351415339392
[Epoch 2, Batch 1200] loss: 0.08249755058204755
[Epoch 2, Batch 1300] loss: 0.0779873505886644
[Epoch 2, Batch 1400] loss: 0.08512477422395022
[Epoch 2, Batch 1500] loss: 0.0905073139333399
[Epoch 2, Batch 1600] loss: 0.09579979750211351
[Epoch 2, Batch 1700] loss: 0.0698319372232072
[Epoch 2, Batch 1800] loss: 0.07735908692004159
[Epoch 2, Batch 1900] loss: 0.0653507105272729
[Epoch 2, Batch 2000] loss: 0.07285130440839566
[Epoch 2, Batch 2100] loss: 0.09532012731884607
[Epoch 2, Batch 2200] loss: 0.08274430315941572
[Epoch 2, Batch 2300] loss: 0.0813175349595258
[Epoch 2, Batch 2400] loss: 0.06688430272683035
[Epoch 2, Batch 2500] loss: 0.08721210137649905
[Epoch 2, Batch 2600] loss: 0.07385441907332278
[Epoch 2, Batch 2700] loss: 0.07070579379331321
[Epoch 2, Batch 2800] loss: 0.056680287712952124
[Epoch 2, Batch 2900] loss: 0.06875441638170741
[Epoch 2, Batch 3000] loss: 0.10419959962135181
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0644
Validation Accuracy: 0.9810
Overfitting: 0.0644
Best model saved at epoch 2 with validation loss: 0.0644
[Epoch 3, Batch 100] loss: 0.05055637229816057
[Epoch 3, Batch 200] loss: 0.044823015015863346
[Epoch 3, Batch 300] loss: 0.07900653855424025
[Epoch 3, Batch 400] loss: 0.06380123111885042
[Epoch 3, Batch 500] loss: 0.04935745999508072
[Epoch 3, Batch 600] loss: 0.060281911545607726
[Epoch 3, Batch 700] loss: 0.05939726048090961
[Epoch 3, Batch 800] loss: 0.05906600464251824
[Epoch 3, Batch 900] loss: 0.06003252891357988
[Epoch 3, Batch 1000] loss: 0.05808002970006783
[Epoch 3, Batch 1100] loss: 0.05981286795635242
[Epoch 3, Batch 1200] loss: 0.05746872957097367
[Epoch 3, Batch 1300] loss: 0.07114487673883559
[Epoch 3, Batch 1400] loss: 0.07201547974022106
[Epoch 3, Batch 1500] loss: 0.060482700263382864
[Epoch 3, Batch 1600] loss: 0.05232336748798844
[Epoch 3, Batch 1700] loss: 0.054168323875928764
[Epoch 3, Batch 1800] loss: 0.07074762040792848
[Epoch 3, Batch 1900] loss: 0.06880457128369016
[Epoch 3, Batch 2000] loss: 0.05726683225686429
[Epoch 3, Batch 2100] loss: 0.05552542260440532
[Epoch 3, Batch 2200] loss: 0.0616489456925774
[Epoch 3, Batch 2300] loss: 0.05017991428641835
[Epoch 3, Batch 2400] loss: 0.031893566444050524
[Epoch 3, Batch 2500] loss: 0.05099627644493012
[Epoch 3, Batch 2600] loss: 0.053408866801764814
[Epoch 3, Batch 2700] loss: 0.05082577212713659
[Epoch 3, Batch 2800] loss: 0.061842817036958875
[Epoch 3, Batch 2900] loss: 0.0491870920493966
[Epoch 3, Batch 3000] loss: 0.057415178473456764
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9837
Overfitting: 0.0560
Best model saved at epoch 3 with validation loss: 0.0560
[Epoch 4, Batch 100] loss: 0.03735784617732861
[Epoch 4, Batch 200] loss: 0.036802675206708955
[Epoch 4, Batch 300] loss: 0.03777572089275054
[Epoch 4, Batch 400] loss: 0.040802063809242096
[Epoch 4, Batch 500] loss: 0.060277186181047
[Epoch 4, Batch 600] loss: 0.046614454473892696
[Epoch 4, Batch 700] loss: 0.058142889916052806
[Epoch 4, Batch 800] loss: 0.05289876522088889
[Epoch 4, Batch 900] loss: 0.06189754507970065
[Epoch 4, Batch 1000] loss: 0.032734820058976766
[Epoch 4, Batch 1100] loss: 0.03918385297234636
[Epoch 4, Batch 1200] loss: 0.06106521851397702
[Epoch 4, Batch 1300] loss: 0.05518440105777699
[Epoch 4, Batch 1400] loss: 0.060125392357294916
[Epoch 4, Batch 1500] loss: 0.043355997589242176
[Epoch 4, Batch 1600] loss: 0.03408763636987715
[Epoch 4, Batch 1700] loss: 0.025235592787503265
[Epoch 4, Batch 1800] loss: 0.05045195602644526
[Epoch 4, Batch 1900] loss: 0.05382263591571245
[Epoch 4, Batch 2000] loss: 0.03646078330908495
[Epoch 4, Batch 2100] loss: 0.04548585972486762
[Epoch 4, Batch 2200] loss: 0.05239485040074214
[Epoch 4, Batch 2300] loss: 0.05393209866335383
[Epoch 4, Batch 2400] loss: 0.031899107668577925
[Epoch 4, Batch 2500] loss: 0.0388954891305184
[Epoch 4, Batch 2600] loss: 0.03898109961737646
[Epoch 4, Batch 2700] loss: 0.04899993292929139
[Epoch 4, Batch 2800] loss: 0.03707592452861718
[Epoch 4, Batch 2900] loss: 0.05578439347911626
[Epoch 4, Batch 3000] loss: 0.03498571760559571
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9847
Overfitting: 0.0487
Best model saved at epoch 4 with validation loss: 0.0487
[Epoch 5, Batch 100] loss: 0.039036211744241885
[Epoch 5, Batch 200] loss: 0.06684508897014893
[Epoch 5, Batch 300] loss: 0.04166224088476156
[Epoch 5, Batch 400] loss: 0.047269978121621536
[Epoch 5, Batch 500] loss: 0.03296727900364203
[Epoch 5, Batch 600] loss: 0.028315939330204855
[Epoch 5, Batch 700] loss: 0.031001450407638912
[Epoch 5, Batch 800] loss: 0.03506537642126204
[Epoch 5, Batch 900] loss: 0.033364746005827325
[Epoch 5, Batch 1000] loss: 0.039060194906560354
[Epoch 5, Batch 1100] loss: 0.048666646900528576
[Epoch 5, Batch 1200] loss: 0.04618049800494191
[Epoch 5, Batch 1300] loss: 0.04439746179021313
[Epoch 5, Batch 1400] loss: 0.03880178305938898
[Epoch 5, Batch 1500] loss: 0.04690666491427692
[Epoch 5, Batch 1600] loss: 0.03864981119229924
[Epoch 5, Batch 1700] loss: 0.039719216285448056
[Epoch 5, Batch 1800] loss: 0.033076525522919835
[Epoch 5, Batch 1900] loss: 0.03336654012768122
[Epoch 5, Batch 2000] loss: 0.05119995384156937
[Epoch 5, Batch 2100] loss: 0.04861404823081102
[Epoch 5, Batch 2200] loss: 0.02776364443823695
[Epoch 5, Batch 2300] loss: 0.021905011689232198
[Epoch 5, Batch 2400] loss: 0.03311616087043148
[Epoch 5, Batch 2500] loss: 0.03987077045057959
[Epoch 5, Batch 2600] loss: 0.048214726268488446
[Epoch 5, Batch 2700] loss: 0.04031296934466809
[Epoch 5, Batch 2800] loss: 0.029958406687801472
[Epoch 5, Batch 2900] loss: 0.03412321990006603
[Epoch 5, Batch 3000] loss: 0.033839947692758866
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9842
Overfitting: 0.0514
[Epoch 6, Batch 100] loss: 0.03938872042097501
[Epoch 6, Batch 200] loss: 0.02767191505932715
[Epoch 6, Batch 300] loss: 0.014660389323325944
[Epoch 6, Batch 400] loss: 0.03330370517927804
[Epoch 6, Batch 500] loss: 0.0182377929953509
[Epoch 6, Batch 600] loss: 0.030225377207352723
[Epoch 6, Batch 700] loss: 0.02030133389700495
[Epoch 6, Batch 800] loss: 0.032413832075399114
[Epoch 6, Batch 900] loss: 0.036794038829721105
[Epoch 6, Batch 1000] loss: 0.04306502403110244
[Epoch 6, Batch 1100] loss: 0.031968972618342376
[Epoch 6, Batch 1200] loss: 0.03325780824787216
[Epoch 6, Batch 1300] loss: 0.04426614676893223
[Epoch 6, Batch 1400] loss: 0.039530767736578126
[Epoch 6, Batch 1500] loss: 0.020130799241887872
[Epoch 6, Batch 1600] loss: 0.01768758209727821
[Epoch 6, Batch 1700] loss: 0.0279557623780056
[Epoch 6, Batch 1800] loss: 0.027001423922847607
[Epoch 6, Batch 1900] loss: 0.02887964365823791
[Epoch 6, Batch 2000] loss: 0.0496832875162363
[Epoch 6, Batch 2100] loss: 0.024517963370526558
[Epoch 6, Batch 2200] loss: 0.03326774965236837
[Epoch 6, Batch 2300] loss: 0.023497267538841696
[Epoch 6, Batch 2400] loss: 0.02882745146573143
[Epoch 6, Batch 2500] loss: 0.02864625611113297
[Epoch 6, Batch 2600] loss: 0.03446543598169228
[Epoch 6, Batch 2700] loss: 0.024686174564267277
[Epoch 6, Batch 2800] loss: 0.04092310136547894
[Epoch 6, Batch 2900] loss: 0.03162075485306559
[Epoch 6, Batch 3000] loss: 0.024105705918191233
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0417
Validation Accuracy: 0.9873
Overfitting: 0.0417
Best model saved at epoch 6 with validation loss: 0.0417
[Epoch 7, Batch 100] loss: 0.01961305491384337
[Epoch 7, Batch 200] loss: 0.022035166357818527
[Epoch 7, Batch 300] loss: 0.03341786406785104
[Epoch 7, Batch 400] loss: 0.03473238333492191
[Epoch 7, Batch 500] loss: 0.023497995192956297
[Epoch 7, Batch 600] loss: 0.02116547653142334
[Epoch 7, Batch 700] loss: 0.025889807710300375
[Epoch 7, Batch 800] loss: 0.01689885487108768
[Epoch 7, Batch 900] loss: 0.03168439882811981
[Epoch 7, Batch 1000] loss: 0.016307267521842733
[Epoch 7, Batch 1100] loss: 0.022595281886497107
[Epoch 7, Batch 1200] loss: 0.039798177893535465
[Epoch 7, Batch 1300] loss: 0.030683496831843512
[Epoch 7, Batch 1400] loss: 0.024434844382558368
[Epoch 7, Batch 1500] loss: 0.03156316279535531
[Epoch 7, Batch 1600] loss: 0.02470716128609638
[Epoch 7, Batch 1700] loss: 0.03882826121467588
[Epoch 7, Batch 1800] loss: 0.024816474987164838
[Epoch 7, Batch 1900] loss: 0.03726642209712736
[Epoch 7, Batch 2000] loss: 0.03856606084795203
[Epoch 7, Batch 2100] loss: 0.02719845938816434
[Epoch 7, Batch 2200] loss: 0.016221129337063756
[Epoch 7, Batch 2300] loss: 0.03121623519276909
[Epoch 7, Batch 2400] loss: 0.019734932209430553
[Epoch 7, Batch 2500] loss: 0.0301583217530424
[Epoch 7, Batch 2600] loss: 0.02534411374080264
[Epoch 7, Batch 2700] loss: 0.03271789996244479
[Epoch 7, Batch 2800] loss: 0.030208020075006062
[Epoch 7, Batch 2900] loss: 0.027970185189369657
[Epoch 7, Batch 3000] loss: 0.02605269166015205
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9873
Overfitting: 0.0431
[Epoch 8, Batch 100] loss: 0.02084515160175215
[Epoch 8, Batch 200] loss: 0.0307228163095715
[Epoch 8, Batch 300] loss: 0.018279375932688708
[Epoch 8, Batch 400] loss: 0.021123553700745104
[Epoch 8, Batch 500] loss: 0.018045269432113854
[Epoch 8, Batch 600] loss: 0.028618440393474883
[Epoch 8, Batch 700] loss: 0.025090503156934573
[Epoch 8, Batch 800] loss: 0.02339587505838608
[Epoch 8, Batch 900] loss: 0.02558064886252396
[Epoch 8, Batch 1000] loss: 0.02997885022967239
[Epoch 8, Batch 1100] loss: 0.014032746249031334
[Epoch 8, Batch 1200] loss: 0.025972328814896174
[Epoch 8, Batch 1300] loss: 0.017355722061802227
[Epoch 8, Batch 1400] loss: 0.022815659162251905
[Epoch 8, Batch 1500] loss: 0.01077743994213961
[Epoch 8, Batch 1600] loss: 0.020964324417909665
[Epoch 8, Batch 1700] loss: 0.01468816868849899
[Epoch 8, Batch 1800] loss: 0.035601161903032336
[Epoch 8, Batch 1900] loss: 0.03193212223255614
[Epoch 8, Batch 2000] loss: 0.018055566530929355
[Epoch 8, Batch 2100] loss: 0.023144779453805314
[Epoch 8, Batch 2200] loss: 0.015931965922936796
[Epoch 8, Batch 2300] loss: 0.022162551418205112
[Epoch 8, Batch 2400] loss: 0.025004026568167317
[Epoch 8, Batch 2500] loss: 0.014862159157237329
[Epoch 8, Batch 2600] loss: 0.02416274061672084
[Epoch 8, Batch 2700] loss: 0.03293351033120416
[Epoch 8, Batch 2800] loss: 0.02112344509725517
[Epoch 8, Batch 2900] loss: 0.03205217412218189
[Epoch 8, Batch 3000] loss: 0.025121424685603414
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9866
Overfitting: 0.0462
[Epoch 9, Batch 100] loss: 0.018417461906938114
[Epoch 9, Batch 200] loss: 0.016079297050237074
[Epoch 9, Batch 300] loss: 0.010817710962728598
[Epoch 9, Batch 400] loss: 0.016141943057045863
[Epoch 9, Batch 500] loss: 0.01982167829314676
[Epoch 9, Batch 600] loss: 0.02227673817435061
[Epoch 9, Batch 700] loss: 0.02153893302893266
[Epoch 9, Batch 800] loss: 0.011947652106946406
[Epoch 9, Batch 900] loss: 0.008631027600786182
[Epoch 9, Batch 1000] loss: 0.010638938645406597
[Epoch 9, Batch 1100] loss: 0.02918961745668639
[Epoch 9, Batch 1200] loss: 0.018960367271902215
[Epoch 9, Batch 1300] loss: 0.014927166641027724
[Epoch 9, Batch 1400] loss: 0.013794435835407057
[Epoch 9, Batch 1500] loss: 0.012023423832315529
[Epoch 9, Batch 1600] loss: 0.023847943961745843
[Epoch 9, Batch 1700] loss: 0.020880924547454924
[Epoch 9, Batch 1800] loss: 0.013716563143480015
[Epoch 9, Batch 1900] loss: 0.014903863424497104
[Epoch 9, Batch 2000] loss: 0.032295140472347154
[Epoch 9, Batch 2100] loss: 0.023730403445788396
[Epoch 9, Batch 2200] loss: 0.020842810152316815
[Epoch 9, Batch 2300] loss: 0.013718328863287752
[Epoch 9, Batch 2400] loss: 0.03683570811044774
[Epoch 9, Batch 2500] loss: 0.02079515121600707
[Epoch 9, Batch 2600] loss: 0.02745681259148114
[Epoch 9, Batch 2700] loss: 0.026945411764045274
[Epoch 9, Batch 2800] loss: 0.020512711796036455
[Epoch 9, Batch 2900] loss: 0.022987154124639347
[Epoch 9, Batch 3000] loss: 0.018194372146322167
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0398
Validation Accuracy: 0.9892
Overfitting: 0.0398
Best model saved at epoch 9 with validation loss: 0.0398
[Epoch 10, Batch 100] loss: 0.024336398200321126
[Epoch 10, Batch 200] loss: 0.014304498441906616
[Epoch 10, Batch 300] loss: 0.023307814891049928
[Epoch 10, Batch 400] loss: 0.015057198249273825
[Epoch 10, Batch 500] loss: 0.0158762448683774
[Epoch 10, Batch 600] loss: 0.02313138124733996
[Epoch 10, Batch 700] loss: 0.017728640671011816
[Epoch 10, Batch 800] loss: 0.008729799251304939
[Epoch 10, Batch 900] loss: 0.024309864616061532
[Epoch 10, Batch 1000] loss: 0.008251823889513616
[Epoch 10, Batch 1100] loss: 0.018845262703216577
[Epoch 10, Batch 1200] loss: 0.015222324630310596
[Epoch 10, Batch 1300] loss: 0.005807726457712761
[Epoch 10, Batch 1400] loss: 0.010591899734336038
[Epoch 10, Batch 1500] loss: 0.010401447202102645
[Epoch 10, Batch 1600] loss: 0.010221314270238509
[Epoch 10, Batch 1700] loss: 0.03266545028037399
[Epoch 10, Batch 1800] loss: 0.014728539544048545
[Epoch 10, Batch 1900] loss: 0.02107202797786158
[Epoch 10, Batch 2000] loss: 0.011942677580454983
[Epoch 10, Batch 2100] loss: 0.016034623073119293
[Epoch 10, Batch 2200] loss: 0.010856326867738061
[Epoch 10, Batch 2300] loss: 0.027660141403503077
[Epoch 10, Batch 2400] loss: 0.009110069858902534
[Epoch 10, Batch 2500] loss: 0.018223692071305777
[Epoch 10, Batch 2600] loss: 0.022367043116837522
[Epoch 10, Batch 2700] loss: 0.01711339773657528
[Epoch 10, Batch 2800] loss: 0.025690856846485987
[Epoch 10, Batch 2900] loss: 0.013724775197879353
[Epoch 10, Batch 3000] loss: 0.016943785171056335
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0582
Validation Accuracy: 0.9843
Overfitting: 0.0582
[Epoch 11, Batch 100] loss: 0.014114091961419035
[Epoch 11, Batch 200] loss: 0.007787386066484032
[Epoch 11, Batch 300] loss: 0.01525752074949196
[Epoch 11, Batch 400] loss: 0.01864781986376329
[Epoch 11, Batch 500] loss: 0.01625586863702665
[Epoch 11, Batch 600] loss: 0.016265646270312573
[Epoch 11, Batch 700] loss: 0.019346204222747476
[Epoch 11, Batch 800] loss: 0.01466957703250955
[Epoch 11, Batch 900] loss: 0.012097249927801385
[Epoch 11, Batch 1000] loss: 0.012352262255317327
[Epoch 11, Batch 1100] loss: 0.006804026842874009
[Epoch 11, Batch 1200] loss: 0.011835317110646884
[Epoch 11, Batch 1300] loss: 0.02278097583995532
[Epoch 11, Batch 1400] loss: 0.025710256280781323
[Epoch 11, Batch 1500] loss: 0.011333140297610953
[Epoch 11, Batch 1600] loss: 0.013614644814961139
[Epoch 11, Batch 1700] loss: 0.010829060282085266
[Epoch 11, Batch 1800] loss: 0.00673575515954326
[Epoch 11, Batch 1900] loss: 0.011124428948614878
[Epoch 11, Batch 2000] loss: 0.01816582182336333
[Epoch 11, Batch 2100] loss: 0.013103908711600524
[Epoch 11, Batch 2200] loss: 0.027043193138615605
[Epoch 11, Batch 2300] loss: 0.018488173198675212
[Epoch 11, Batch 2400] loss: 0.010546916518514991
[Epoch 11, Batch 2500] loss: 0.015052699632224175
[Epoch 11, Batch 2600] loss: 0.015043663229171216
[Epoch 11, Batch 2700] loss: 0.015229741119310348
[Epoch 11, Batch 2800] loss: 0.01488247665220115
[Epoch 11, Batch 2900] loss: 0.023178976689996487
[Epoch 11, Batch 3000] loss: 0.017735998641580864
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9877
Overfitting: 0.0469
[Epoch 12, Batch 100] loss: 0.013429610040429907
[Epoch 12, Batch 200] loss: 0.015992419028484618
[Epoch 12, Batch 300] loss: 0.006072268658460871
[Epoch 12, Batch 400] loss: 0.00959104889473565
[Epoch 12, Batch 500] loss: 0.013375998711921966
[Epoch 12, Batch 600] loss: 0.008677573011718778
[Epoch 12, Batch 700] loss: 0.009662531996559665
[Epoch 12, Batch 800] loss: 0.014902446127209715
[Epoch 12, Batch 900] loss: 0.012401971723020324
[Epoch 12, Batch 1000] loss: 0.011611691605749002
[Epoch 12, Batch 1100] loss: 0.008311609582056007
[Epoch 12, Batch 1200] loss: 0.01576755301630783
[Epoch 12, Batch 1300] loss: 0.009538051586278016
[Epoch 12, Batch 1400] loss: 0.014112038099387974
[Epoch 12, Batch 1500] loss: 0.01733723180144352
[Epoch 12, Batch 1600] loss: 0.013952090491432045
[Epoch 12, Batch 1700] loss: 0.01908894112823873
[Epoch 12, Batch 1800] loss: 0.018157828925341166
[Epoch 12, Batch 1900] loss: 0.015051182585866628
[Epoch 12, Batch 2000] loss: 0.00449916142636539
[Epoch 12, Batch 2100] loss: 0.013908440358025019
[Epoch 12, Batch 2200] loss: 0.01944081126009678
[Epoch 12, Batch 2300] loss: 0.010395356121453005
[Epoch 12, Batch 2400] loss: 0.021494104059252096
[Epoch 12, Batch 2500] loss: 0.013261013450955943
[Epoch 12, Batch 2600] loss: 0.019798399249411888
[Epoch 12, Batch 2700] loss: 0.01686933165356095
[Epoch 12, Batch 2800] loss: 0.00948953594719569
[Epoch 12, Batch 2900] loss: 0.015040004112995576
[Epoch 12, Batch 3000] loss: 0.013541220858996894
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9880
Overfitting: 0.0458
[Epoch 13, Batch 100] loss: 0.010001912312027343
[Epoch 13, Batch 200] loss: 0.007850713840998651
[Epoch 13, Batch 300] loss: 0.0056925215843057235
[Epoch 13, Batch 400] loss: 0.005861462631460199
[Epoch 13, Batch 500] loss: 0.003808575356010806
[Epoch 13, Batch 600] loss: 0.01886259568677815
[Epoch 13, Batch 700] loss: 0.016601340348133816
[Epoch 13, Batch 800] loss: 0.013163756121709867
[Epoch 13, Batch 900] loss: 0.005974470526261939
[Epoch 13, Batch 1000] loss: 0.013653212105573402
[Epoch 13, Batch 1100] loss: 0.006692749175781501
[Epoch 13, Batch 1200] loss: 0.01842592574205696
[Epoch 13, Batch 1300] loss: 0.008461713085355599
[Epoch 13, Batch 1400] loss: 0.011780342927131641
[Epoch 13, Batch 1500] loss: 0.016626330570798018
[Epoch 13, Batch 1600] loss: 0.005312019489838349
[Epoch 13, Batch 1700] loss: 0.005897049656680337
[Epoch 13, Batch 1800] loss: 0.007975856133707566
[Epoch 13, Batch 1900] loss: 0.011349625095444935
[Epoch 13, Batch 2000] loss: 0.01125537355385859
[Epoch 13, Batch 2100] loss: 0.018663666286383888
[Epoch 13, Batch 2200] loss: 0.014926596935583802
[Epoch 13, Batch 2300] loss: 0.022484234749299503
[Epoch 13, Batch 2400] loss: 0.008295221366611259
[Epoch 13, Batch 2500] loss: 0.0070147481811090985
[Epoch 13, Batch 2600] loss: 0.012929842266532886
[Epoch 13, Batch 2700] loss: 0.005375188141442777
[Epoch 13, Batch 2800] loss: 0.014805121922138368
[Epoch 13, Batch 2900] loss: 0.007100960880659386
[Epoch 13, Batch 3000] loss: 0.009428245000112839
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9870
Overfitting: 0.0493
[Epoch 14, Batch 100] loss: 0.008841864568157689
[Epoch 14, Batch 200] loss: 0.008580355723674984
[Epoch 14, Batch 300] loss: 0.007508267843064118
[Epoch 14, Batch 400] loss: 0.010618629410403741
[Epoch 14, Batch 500] loss: 0.0078750030147512
[Epoch 14, Batch 600] loss: 0.015060572218994822
[Epoch 14, Batch 700] loss: 0.0075566080283351765
[Epoch 14, Batch 800] loss: 0.010863307462882403
[Epoch 14, Batch 900] loss: 0.006648957800325661
[Epoch 14, Batch 1000] loss: 0.011284123637833545
[Epoch 14, Batch 1100] loss: 0.010268517833237638
[Epoch 14, Batch 1200] loss: 0.007988963023349243
[Epoch 14, Batch 1300] loss: 0.006532078871642853
[Epoch 14, Batch 1400] loss: 0.005921141825965605
[Epoch 14, Batch 1500] loss: 0.008022468616522928
[Epoch 14, Batch 1600] loss: 0.009351198792201103
[Epoch 14, Batch 1700] loss: 0.009072042676790489
[Epoch 14, Batch 1800] loss: 0.0038464789342522467
[Epoch 14, Batch 1900] loss: 0.0064668788116250655
[Epoch 14, Batch 2000] loss: 0.0035671268484088613
[Epoch 14, Batch 2100] loss: 0.004593124191462721
[Epoch 14, Batch 2200] loss: 0.008493798178940325
[Epoch 14, Batch 2300] loss: 0.008951629776242953
[Epoch 14, Batch 2400] loss: 0.015520023832596052
[Epoch 14, Batch 2500] loss: 0.012254335502555024
[Epoch 14, Batch 2600] loss: 0.01047793509945791
[Epoch 14, Batch 2700] loss: 0.025867606882784458
[Epoch 14, Batch 2800] loss: 0.012302608733978104
[Epoch 14, Batch 2900] loss: 0.010300474103883062
[Epoch 14, Batch 3000] loss: 0.009315477450500112
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9860
Overfitting: 0.0537
[Epoch 15, Batch 100] loss: 0.014983624198935104
[Epoch 15, Batch 200] loss: 0.005964580866584583
[Epoch 15, Batch 300] loss: 0.0074637197349147755
[Epoch 15, Batch 400] loss: 0.0052456370369554865
[Epoch 15, Batch 500] loss: 0.011324358722863508
[Epoch 15, Batch 600] loss: 0.01116192747991704
[Epoch 15, Batch 700] loss: 0.013287378519582943
[Epoch 15, Batch 800] loss: 0.007832281539273254
[Epoch 15, Batch 900] loss: 0.01157603276022428
[Epoch 15, Batch 1000] loss: 0.0053941832380792224
[Epoch 15, Batch 1100] loss: 0.018039974364885438
[Epoch 15, Batch 1200] loss: 0.010797813519602642
[Epoch 15, Batch 1300] loss: 0.006267919205479302
[Epoch 15, Batch 1400] loss: 0.005196800083490416
[Epoch 15, Batch 1500] loss: 0.0045034376354237795
[Epoch 15, Batch 1600] loss: 0.010962576544202421
[Epoch 15, Batch 1700] loss: 0.006220628886864006
[Epoch 15, Batch 1800] loss: 0.012773270342381692
[Epoch 15, Batch 1900] loss: 0.010130898682173211
[Epoch 15, Batch 2000] loss: 0.01122992766893276
[Epoch 15, Batch 2100] loss: 0.013366327427157786
[Epoch 15, Batch 2200] loss: 0.008536388357174473
[Epoch 15, Batch 2300] loss: 0.013721397403523952
[Epoch 15, Batch 2400] loss: 0.005980675090618206
[Epoch 15, Batch 2500] loss: 0.015802250288033975
[Epoch 15, Batch 2600] loss: 0.014600590050386018
[Epoch 15, Batch 2700] loss: 0.009692615076712627
[Epoch 15, Batch 2800] loss: 0.013132495507534259
[Epoch 15, Batch 2900] loss: 0.014612345147579617
[Epoch 15, Batch 3000] loss: 0.01749987671496001
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9892
Overfitting: 0.0462
[Epoch 16, Batch 100] loss: 0.010883664786215377
[Epoch 16, Batch 200] loss: 0.008981842775358472
[Epoch 16, Batch 300] loss: 0.011686720627662907
[Epoch 16, Batch 400] loss: 0.007254503321933043
[Epoch 16, Batch 500] loss: 0.007970211705390966
[Epoch 16, Batch 600] loss: 0.010691716417818497
[Epoch 16, Batch 700] loss: 0.008881230690976736
[Epoch 16, Batch 800] loss: 0.007146426314689052
[Epoch 16, Batch 900] loss: 0.0026282286064315485
[Epoch 16, Batch 1000] loss: 0.0054472080081761475
[Epoch 16, Batch 1100] loss: 0.0026946117898933152
[Epoch 16, Batch 1200] loss: 0.003977959171981809
[Epoch 16, Batch 1300] loss: 0.007246435257008557
[Epoch 16, Batch 1400] loss: 0.0014625649999214828
[Epoch 16, Batch 1500] loss: 0.0031870940287672058
[Epoch 16, Batch 1600] loss: 0.003662926567067757
[Epoch 16, Batch 1700] loss: 0.012160609320282702
[Epoch 16, Batch 1800] loss: 0.01737784705144918
[Epoch 16, Batch 1900] loss: 0.01213661874280433
[Epoch 16, Batch 2000] loss: 0.003754805392612752
[Epoch 16, Batch 2100] loss: 0.00715469973594054
[Epoch 16, Batch 2200] loss: 0.007630650602727655
[Epoch 16, Batch 2300] loss: 0.006304262806235101
[Epoch 16, Batch 2400] loss: 0.0038421351717749987
[Epoch 16, Batch 2500] loss: 0.010893868371387611
[Epoch 16, Batch 2600] loss: 0.0033605152555253428
[Epoch 16, Batch 2700] loss: 0.0045799101126306144
[Epoch 16, Batch 2800] loss: 0.007859708767152824
[Epoch 16, Batch 2900] loss: 0.006099454360489745
[Epoch 16, Batch 3000] loss: 0.01118649190426936
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9862
Overfitting: 0.0567
[Epoch 17, Batch 100] loss: 0.0071835096615586735
[Epoch 17, Batch 200] loss: 0.005840685278062665
[Epoch 17, Batch 300] loss: 0.0031194774108109866
[Epoch 17, Batch 400] loss: 0.00523497782816321
[Epoch 17, Batch 500] loss: 0.0038051186829417814
[Epoch 17, Batch 600] loss: 0.003124628695506999
[Epoch 17, Batch 700] loss: 0.0037232319847545626
[Epoch 17, Batch 800] loss: 0.0027896295863331488
[Epoch 17, Batch 900] loss: 0.0033283914206589317
[Epoch 17, Batch 1000] loss: 0.003825631884895415
[Epoch 17, Batch 1100] loss: 0.006441731718762184
[Epoch 17, Batch 1200] loss: 0.007729491985442678
[Epoch 17, Batch 1300] loss: 0.008694012497996936
[Epoch 17, Batch 1400] loss: 0.0034690617510625544
[Epoch 17, Batch 1500] loss: 0.0029165524767913098
[Epoch 17, Batch 1600] loss: 0.010088928954704243
[Epoch 17, Batch 1700] loss: 0.00729126172422923
[Epoch 17, Batch 1800] loss: 0.007391850361711363
[Epoch 17, Batch 1900] loss: 0.005006213628697651
[Epoch 17, Batch 2000] loss: 0.0034548499050163174
[Epoch 17, Batch 2100] loss: 0.006567820956309447
[Epoch 17, Batch 2200] loss: 0.01120047858733102
[Epoch 17, Batch 2300] loss: 0.012379292659913688
[Epoch 17, Batch 2400] loss: 0.01025765442563852
[Epoch 17, Batch 2500] loss: 0.008691459358158227
[Epoch 17, Batch 2600] loss: 0.005244376112535747
[Epoch 17, Batch 2700] loss: 0.015009175897278055
[Epoch 17, Batch 2800] loss: 0.01675978055555845
[Epoch 17, Batch 2900] loss: 0.012768110661445462
[Epoch 17, Batch 3000] loss: 0.01664250840388945
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9889
Overfitting: 0.0527
[Epoch 18, Batch 100] loss: 0.005119299243324349
[Epoch 18, Batch 200] loss: 0.004382105411975772
[Epoch 18, Batch 300] loss: 0.009535911152345306
[Epoch 18, Batch 400] loss: 0.004223363085659457
[Epoch 18, Batch 500] loss: 0.001435739690310811
[Epoch 18, Batch 600] loss: 0.0018952203634262333
[Epoch 18, Batch 700] loss: 0.004849277924257365
[Epoch 18, Batch 800] loss: 0.008828654179968112
[Epoch 18, Batch 900] loss: 0.0021204063551124364
[Epoch 18, Batch 1000] loss: 0.0034181019243214907
[Epoch 18, Batch 1100] loss: 0.006684618880903485
[Epoch 18, Batch 1200] loss: 0.008931986949230008
[Epoch 18, Batch 1300] loss: 0.004752848573152164
[Epoch 18, Batch 1400] loss: 0.004622752618058712
[Epoch 18, Batch 1500] loss: 0.003153402484217622
[Epoch 18, Batch 1600] loss: 0.005083648700277194
[Epoch 18, Batch 1700] loss: 0.0012736529083747427
[Epoch 18, Batch 1800] loss: 0.0014340886780760797
[Epoch 18, Batch 1900] loss: 0.01010594597880754
[Epoch 18, Batch 2000] loss: 0.005592146869707904
[Epoch 18, Batch 2100] loss: 0.002518508673762199
[Epoch 18, Batch 2200] loss: 0.0034286376213444212
[Epoch 18, Batch 2300] loss: 0.0026903154554975117
[Epoch 18, Batch 2400] loss: 0.00615347318821307
[Epoch 18, Batch 2500] loss: 0.01048074102251384
[Epoch 18, Batch 2600] loss: 0.006296260630043662
[Epoch 18, Batch 2700] loss: 0.015579505011934884
[Epoch 18, Batch 2800] loss: 0.01645667812555189
[Epoch 18, Batch 2900] loss: 0.011243108990493909
[Epoch 18, Batch 3000] loss: 0.02235845653072886
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0580
Validation Accuracy: 0.9876
Overfitting: 0.0580
[Epoch 19, Batch 100] loss: 0.014559636293209905
[Epoch 19, Batch 200] loss: 0.0033804868369554696
[Epoch 19, Batch 300] loss: 0.0071599108870441346
[Epoch 19, Batch 400] loss: 0.0014494023032119686
[Epoch 19, Batch 500] loss: 0.006297549208314876
[Epoch 19, Batch 600] loss: 0.00516501945414916
[Epoch 19, Batch 700] loss: 0.0015082562107201624
[Epoch 19, Batch 800] loss: 0.001645499848659142
[Epoch 19, Batch 900] loss: 0.0024802419802517762
[Epoch 19, Batch 1000] loss: 0.005227929098189179
[Epoch 19, Batch 1100] loss: 0.002011334343660849
[Epoch 19, Batch 1200] loss: 0.0033301211555306054
[Epoch 19, Batch 1300] loss: 0.0056147958959191155
[Epoch 19, Batch 1400] loss: 0.010461239371493888
[Epoch 19, Batch 1500] loss: 0.005649334064861478
[Epoch 19, Batch 1600] loss: 0.004530464925314277
[Epoch 19, Batch 1700] loss: 0.005569611393455886
[Epoch 19, Batch 1800] loss: 0.005278588392665071
[Epoch 19, Batch 1900] loss: 0.0018561245038139873
[Epoch 19, Batch 2000] loss: 0.005994787331331679
[Epoch 19, Batch 2100] loss: 0.0028835722422127217
[Epoch 19, Batch 2200] loss: 0.00374123843826613
[Epoch 19, Batch 2300] loss: 0.006078535705090076
[Epoch 19, Batch 2400] loss: 0.003999245616027807
[Epoch 19, Batch 2500] loss: 0.004686857980609034
[Epoch 19, Batch 2600] loss: 0.0007753381857791907
[Epoch 19, Batch 2700] loss: 0.0025669516224641597
[Epoch 19, Batch 2800] loss: 0.010662110630228198
[Epoch 19, Batch 2900] loss: 0.018348502893229722
[Epoch 19, Batch 3000] loss: 0.010055658848898474
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9885
Overfitting: 0.0548
[Epoch 20, Batch 100] loss: 0.0018181715846552037
[Epoch 20, Batch 200] loss: 0.0019655531751845957
[Epoch 20, Batch 300] loss: 0.005379374297741606
[Epoch 20, Batch 400] loss: 0.016717482464697044
[Epoch 20, Batch 500] loss: 0.0025281847832764014
[Epoch 20, Batch 600] loss: 0.0026840278325067856
[Epoch 20, Batch 700] loss: 0.0026179036383410905
[Epoch 20, Batch 800] loss: 0.008707595262023844
[Epoch 20, Batch 900] loss: 0.0042328498650658734
[Epoch 20, Batch 1000] loss: 0.003094717839503005
[Epoch 20, Batch 1100] loss: 0.0029529041781722752
[Epoch 20, Batch 1200] loss: 0.0063358230917120294
[Epoch 20, Batch 1300] loss: 0.005029122259589798
[Epoch 20, Batch 1400] loss: 0.003009996827854593
[Epoch 20, Batch 1500] loss: 0.004060654179667154
[Epoch 20, Batch 1600] loss: 0.0038107919839461602
[Epoch 20, Batch 1700] loss: 0.006089195239970877
[Epoch 20, Batch 1800] loss: 0.0013485824425378823
[Epoch 20, Batch 1900] loss: 0.001809976054668132
[Epoch 20, Batch 2000] loss: 0.0008123760424808424
[Epoch 20, Batch 2100] loss: 0.00450766834296914
[Epoch 20, Batch 2200] loss: 0.012575267920044552
[Epoch 20, Batch 2300] loss: 0.0036962071380770567
[Epoch 20, Batch 2400] loss: 0.0032997967624478976
[Epoch 20, Batch 2500] loss: 0.0045806705145867
[Epoch 20, Batch 2600] loss: 0.004984650676290379
[Epoch 20, Batch 2700] loss: 0.004566653265027583
[Epoch 20, Batch 2800] loss: 0.005636141865541333
[Epoch 20, Batch 2900] loss: 0.005428138022414402
[Epoch 20, Batch 3000] loss: 0.014002060259938104
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0695
Validation Accuracy: 0.9849
Overfitting: 0.0695
[Epoch 21, Batch 100] loss: 0.004899334104104583
[Epoch 21, Batch 200] loss: 0.006928685013156155
[Epoch 21, Batch 300] loss: 0.0018533517019045575
[Epoch 21, Batch 400] loss: 0.003061247722121152
[Epoch 21, Batch 500] loss: 0.0014663763461302893
[Epoch 21, Batch 600] loss: 0.0015771662156644605
[Epoch 21, Batch 700] loss: 0.007504220222680971
[Epoch 21, Batch 800] loss: 0.006037844756082365
[Epoch 21, Batch 900] loss: 0.0027404962912839894
[Epoch 21, Batch 1000] loss: 0.006832738189281144
[Epoch 21, Batch 1100] loss: 0.004018217545296636
[Epoch 21, Batch 1200] loss: 0.005597022291653388
[Epoch 21, Batch 1300] loss: 0.0015258863692594105
[Epoch 21, Batch 1400] loss: 0.011722087846439138
[Epoch 21, Batch 1500] loss: 0.012237207657319117
[Epoch 21, Batch 1600] loss: 0.006900532483460964
[Epoch 21, Batch 1700] loss: 0.005404295536953896
[Epoch 21, Batch 1800] loss: 0.0038075048591970527
[Epoch 21, Batch 1900] loss: 0.00320924244541402
[Epoch 21, Batch 2000] loss: 0.0016485916489992292
[Epoch 21, Batch 2100] loss: 0.005990834028392272
[Epoch 21, Batch 2200] loss: 0.0029693871401926942
[Epoch 21, Batch 2300] loss: 0.005595196962061522
[Epoch 21, Batch 2400] loss: 0.007243128830641012
[Epoch 21, Batch 2500] loss: 0.015825965978289672
[Epoch 21, Batch 2600] loss: 0.021192230972936415
[Epoch 21, Batch 2700] loss: 0.012525798044753138
[Epoch 21, Batch 2800] loss: 0.004197556040639796
[Epoch 21, Batch 2900] loss: 0.009512293290802845
[Epoch 21, Batch 3000] loss: 0.008093845275028854
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9876
Overfitting: 0.0586
[Epoch 22, Batch 100] loss: 0.0028195843112152376
[Epoch 22, Batch 200] loss: 0.0029011386763398406
[Epoch 22, Batch 300] loss: 0.0020299120854859565
[Epoch 22, Batch 400] loss: 0.0009876458258759157
[Epoch 22, Batch 500] loss: 0.0022647100238458416
[Epoch 22, Batch 600] loss: 0.00417724039716024
[Epoch 22, Batch 700] loss: 0.005169648103553115
[Epoch 22, Batch 800] loss: 0.002473286304685427
[Epoch 22, Batch 900] loss: 0.0019338055733164339
[Epoch 22, Batch 1000] loss: 0.0038245750788037467
[Epoch 22, Batch 1100] loss: 0.002727801849385898
[Epoch 22, Batch 1200] loss: 0.001691723631155284
[Epoch 22, Batch 1300] loss: 0.0015613401304759122
[Epoch 22, Batch 1400] loss: 0.008350631900087642
[Epoch 22, Batch 1500] loss: 0.008490885070775667
[Epoch 22, Batch 1600] loss: 0.003107357302640992
[Epoch 22, Batch 1700] loss: 0.0048000060172911675
[Epoch 22, Batch 1800] loss: 0.00446961881545036
[Epoch 22, Batch 1900] loss: 0.006683048026318516
[Epoch 22, Batch 2000] loss: 0.016209032504153172
[Epoch 22, Batch 2100] loss: 0.00402167804897104
[Epoch 22, Batch 2200] loss: 0.007567954502318273
[Epoch 22, Batch 2300] loss: 0.011640972223520406
[Epoch 22, Batch 2400] loss: 0.01083498965321155
[Epoch 22, Batch 2500] loss: 0.014975040975907064
[Epoch 22, Batch 2600] loss: 0.0038422697707390795
[Epoch 22, Batch 2700] loss: 0.005166136755728808
[Epoch 22, Batch 2800] loss: 0.00833741682807542
[Epoch 22, Batch 2900] loss: 0.01698125091650802
[Epoch 22, Batch 3000] loss: 0.010074852291701148
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9878
Overfitting: 0.0546
[Epoch 23, Batch 100] loss: 0.005460968044197756
[Epoch 23, Batch 200] loss: 0.014268361114906156
[Epoch 23, Batch 300] loss: 0.004103261505152318
[Epoch 23, Batch 400] loss: 0.005433470321667926
[Epoch 23, Batch 500] loss: 0.0023684491348753057
[Epoch 23, Batch 600] loss: 0.0019312282532853687
[Epoch 23, Batch 700] loss: 0.001286686755143478
[Epoch 23, Batch 800] loss: 0.009558001756705039
[Epoch 23, Batch 900] loss: 0.005090519547040628
[Epoch 23, Batch 1000] loss: 0.0014812404689433832
[Epoch 23, Batch 1100] loss: 0.0019275533381944855
[Epoch 23, Batch 1200] loss: 0.0012602447324176857
[Epoch 23, Batch 1300] loss: 0.0007171455351507916
[Epoch 23, Batch 1400] loss: 0.0011694861847892746
[Epoch 23, Batch 1500] loss: 0.0019265916081845802
[Epoch 23, Batch 1600] loss: 0.0039750901660562474
[Epoch 23, Batch 1700] loss: 0.002607719307735845
[Epoch 23, Batch 1800] loss: 0.0027856704350995186
[Epoch 23, Batch 1900] loss: 0.01158839170078423
[Epoch 23, Batch 2000] loss: 0.004305388326515551
[Epoch 23, Batch 2100] loss: 0.0031539176222332797
[Epoch 23, Batch 2200] loss: 0.0035801209718735547
[Epoch 23, Batch 2300] loss: 0.007412709335573595
[Epoch 23, Batch 2400] loss: 0.008787690145706684
[Epoch 23, Batch 2500] loss: 0.003960528044557705
[Epoch 23, Batch 2600] loss: 0.004689655335312035
[Epoch 23, Batch 2700] loss: 0.007027571943738202
[Epoch 23, Batch 2800] loss: 0.0016590762469467534
[Epoch 23, Batch 2900] loss: 0.006559801626643633
[Epoch 23, Batch 3000] loss: 0.006672348037083964
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0646
Validation Accuracy: 0.9869
Overfitting: 0.0646
[Epoch 24, Batch 100] loss: 0.0058048179304989135
[Epoch 24, Batch 200] loss: 0.0017673983969933714
[Epoch 24, Batch 300] loss: 0.003283349613276414
[Epoch 24, Batch 400] loss: 0.0024902036915651136
[Epoch 24, Batch 500] loss: 0.001706983551278789
[Epoch 24, Batch 600] loss: 0.0020172477830868196
[Epoch 24, Batch 700] loss: 0.003263996736704584
[Epoch 24, Batch 800] loss: 0.0021568552964672614
[Epoch 24, Batch 900] loss: 0.00633914717022737
[Epoch 24, Batch 1000] loss: 0.001962424683593995
[Epoch 24, Batch 1100] loss: 0.0019885309179027287
[Epoch 24, Batch 1200] loss: 0.0009001832521123188
[Epoch 24, Batch 1300] loss: 0.0007372736117722844
[Epoch 24, Batch 1400] loss: 0.0008048085375187508
[Epoch 24, Batch 1500] loss: 0.0024076386264479588
[Epoch 24, Batch 1600] loss: 0.0036084980848644977
[Epoch 24, Batch 1700] loss: 0.0026087760223101465
[Epoch 24, Batch 1800] loss: 0.0010361224129404835
[Epoch 24, Batch 1900] loss: 0.002282912381075968
[Epoch 24, Batch 2000] loss: 0.0026662719933520716
[Epoch 24, Batch 2100] loss: 0.0033143919169658885
[Epoch 24, Batch 2200] loss: 0.001258772110995383
[Epoch 24, Batch 2300] loss: 0.0032415079331090226
[Epoch 24, Batch 2400] loss: 0.001055334840258322
[Epoch 24, Batch 2500] loss: 0.003707131274666793
[Epoch 24, Batch 2600] loss: 0.0027945640252050818
[Epoch 24, Batch 2700] loss: 0.0011758568532987202
[Epoch 24, Batch 2800] loss: 0.0013794719310860114
[Epoch 24, Batch 2900] loss: 0.002953942742769935
[Epoch 24, Batch 3000] loss: 0.007079227103064052
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9885
Overfitting: 0.0592
Fold 5 validation loss: 0.0592
Mean validation loss across all folds for Trial 6 is 0.0587 with trial config:  l1: 128, l2: 64, lr: 0.0015696396388661157, batch_size: 16
[I 2024-12-11 02:49:13,236] Trial 5 finished with value: 0.058733755402784936 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.0015696396388661157, 'batch_size': 16}. Best is trial 2 with value: 0.05047263894358398.

Selected Hyperparameters for Trial 7:
  l1: 128, l2: 64, lr: 0.0003646439558980723, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.299387652873993
**STATS for Epoch 1** : 
Average training loss: 1.0740
Average validation loss: 2.2914
Validation Accuracy: 0.0993
Overfitting: 1.2175
Best model saved at epoch 1 with validation loss: 2.2914
[Epoch 2, Batch 100] loss: 2.2888409066200257
**STATS for Epoch 2** : 
Average training loss: 1.0681
Average validation loss: 2.2771
Validation Accuracy: 0.0995
Overfitting: 1.2089
Best model saved at epoch 2 with validation loss: 2.2771
[Epoch 3, Batch 100] loss: 2.273236436843872
**STATS for Epoch 3** : 
Average training loss: 1.0574
Average validation loss: 2.2507
Validation Accuracy: 0.2510
Overfitting: 1.1933
Best model saved at epoch 3 with validation loss: 2.2507
[Epoch 4, Batch 100] loss: 2.240892629623413
**STATS for Epoch 4** : 
Average training loss: 1.0342
Average validation loss: 2.1860
Validation Accuracy: 0.3417
Overfitting: 1.1518
Best model saved at epoch 4 with validation loss: 2.1860
[Epoch 5, Batch 100] loss: 2.1518056654930113
**STATS for Epoch 5** : 
Average training loss: 0.9536
Average validation loss: 1.9457
Validation Accuracy: 0.4330
Overfitting: 0.9922
Best model saved at epoch 5 with validation loss: 1.9457
[Epoch 6, Batch 100] loss: 1.8098422825336455
**STATS for Epoch 6** : 
Average training loss: 0.6810
Average validation loss: 1.2589
Validation Accuracy: 0.6746
Overfitting: 0.5778
Best model saved at epoch 6 with validation loss: 1.2589
[Epoch 7, Batch 100] loss: 1.0786174649000169
**STATS for Epoch 7** : 
Average training loss: 0.3767
Average validation loss: 0.6955
Validation Accuracy: 0.8145
Overfitting: 0.3188
Best model saved at epoch 7 with validation loss: 0.6955
[Epoch 8, Batch 100] loss: 0.6439641696214676
**STATS for Epoch 8** : 
Average training loss: 0.2573
Average validation loss: 0.4989
Validation Accuracy: 0.8608
Overfitting: 0.2416
Best model saved at epoch 8 with validation loss: 0.4989
[Epoch 9, Batch 100] loss: 0.4888473501801491
**STATS for Epoch 9** : 
Average training loss: 0.2110
Average validation loss: 0.4075
Validation Accuracy: 0.8843
Overfitting: 0.1965
[I 2024-12-11 02:50:33,096] Trial 6 pruned. 

Selected Hyperparameters for Trial 8:
  l1: 128, l2: 128, lr: 0.002592475660475161, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2743207907676695
[Epoch 1, Batch 200] loss: 1.6190033119916916
[Epoch 1, Batch 300] loss: 0.6401871535181999
[Epoch 1, Batch 400] loss: 0.4321716134250164
[Epoch 1, Batch 500] loss: 0.3464596658945084
[Epoch 1, Batch 600] loss: 0.25565119352191684
[Epoch 1, Batch 700] loss: 0.220733424089849
[Epoch 1, Batch 800] loss: 0.192556921094656
[Epoch 1, Batch 900] loss: 0.19199062380939722
[Epoch 1, Batch 1000] loss: 0.16492551216855644
[Epoch 1, Batch 1100] loss: 0.1487617121450603
[Epoch 1, Batch 1200] loss: 0.1691112898848951
[Epoch 1, Batch 1300] loss: 0.12767748438753188
[Epoch 1, Batch 1400] loss: 0.16155583452899008
[Epoch 1, Batch 1500] loss: 0.10086112137883901
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0971
Validation Accuracy: 0.9695
Overfitting: 0.0971
Best model saved at epoch 1 with validation loss: 0.0971
[Epoch 2, Batch 100] loss: 0.11596184710040688
[Epoch 2, Batch 200] loss: 0.09563419565791265
[Epoch 2, Batch 300] loss: 0.11645394396036864
[Epoch 2, Batch 400] loss: 0.10022331518121064
[Epoch 2, Batch 500] loss: 0.1085827378463
[Epoch 2, Batch 600] loss: 0.10275553425773978
[Epoch 2, Batch 700] loss: 0.09825614163652062
[Epoch 2, Batch 800] loss: 0.08779499490745366
[Epoch 2, Batch 900] loss: 0.08212525662500411
[Epoch 2, Batch 1000] loss: 0.09059444165788591
[Epoch 2, Batch 1100] loss: 0.0972559831943363
[Epoch 2, Batch 1200] loss: 0.07260602692142129
[Epoch 2, Batch 1300] loss: 0.09665493889129721
[Epoch 2, Batch 1400] loss: 0.07977191773243249
[Epoch 2, Batch 1500] loss: 0.09147296668961644
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0773
Validation Accuracy: 0.9760
Overfitting: 0.0773
Best model saved at epoch 2 with validation loss: 0.0773
[Epoch 3, Batch 100] loss: 0.05862226601340808
[Epoch 3, Batch 200] loss: 0.0800337846763432
[Epoch 3, Batch 300] loss: 0.06628597378497943
[Epoch 3, Batch 400] loss: 0.07537100108573214
[Epoch 3, Batch 500] loss: 0.07859931643819436
[Epoch 3, Batch 600] loss: 0.06103452578536235
[Epoch 3, Batch 700] loss: 0.06240489442134276
[Epoch 3, Batch 800] loss: 0.05370477402582765
[Epoch 3, Batch 900] loss: 0.07530517871258781
[Epoch 3, Batch 1000] loss: 0.07854506709380076
[Epoch 3, Batch 1100] loss: 0.06631885381182656
[Epoch 3, Batch 1200] loss: 0.0667728891572915
[Epoch 3, Batch 1300] loss: 0.06585737739223987
[Epoch 3, Batch 1400] loss: 0.07097561681293882
[Epoch 3, Batch 1500] loss: 0.050120988559210676
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0596
Validation Accuracy: 0.9816
Overfitting: 0.0596
Best model saved at epoch 3 with validation loss: 0.0596
[Epoch 4, Batch 100] loss: 0.05445102054974996
[Epoch 4, Batch 200] loss: 0.050206886550877246
[Epoch 4, Batch 300] loss: 0.05830617970088497
[Epoch 4, Batch 400] loss: 0.04409341373306233
[Epoch 4, Batch 500] loss: 0.0547040088661015
[Epoch 4, Batch 600] loss: 0.048456736049847675
[Epoch 4, Batch 700] loss: 0.047932514315471055
[Epoch 4, Batch 800] loss: 0.056897276876261456
[Epoch 4, Batch 900] loss: 0.046986614731140436
[Epoch 4, Batch 1000] loss: 0.05852275469573215
[Epoch 4, Batch 1100] loss: 0.05899958354711998
[Epoch 4, Batch 1200] loss: 0.0494662316411268
[Epoch 4, Batch 1300] loss: 0.04674230310483836
[Epoch 4, Batch 1400] loss: 0.04728468648274429
[Epoch 4, Batch 1500] loss: 0.05499604918528348
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9845
Overfitting: 0.0490
Best model saved at epoch 4 with validation loss: 0.0490
[Epoch 5, Batch 100] loss: 0.04100453336723149
[Epoch 5, Batch 200] loss: 0.03909577423386509
[Epoch 5, Batch 300] loss: 0.03243333821126725
[Epoch 5, Batch 400] loss: 0.04631125211308244
[Epoch 5, Batch 500] loss: 0.04136791766795796
[Epoch 5, Batch 600] loss: 0.036211075982428155
[Epoch 5, Batch 700] loss: 0.044250122180092145
[Epoch 5, Batch 800] loss: 0.04421357886516489
[Epoch 5, Batch 900] loss: 0.039744348454405554
[Epoch 5, Batch 1000] loss: 0.04378516686731018
[Epoch 5, Batch 1100] loss: 0.05511909241933608
[Epoch 5, Batch 1200] loss: 0.039953019713284445
[Epoch 5, Batch 1300] loss: 0.04054368030745536
[Epoch 5, Batch 1400] loss: 0.04807401480822591
[Epoch 5, Batch 1500] loss: 0.046883638973231424
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9842
Overfitting: 0.0489
Best model saved at epoch 5 with validation loss: 0.0489
[Epoch 6, Batch 100] loss: 0.032592608983395624
[Epoch 6, Batch 200] loss: 0.03262551431398606
[Epoch 6, Batch 300] loss: 0.030634425391763215
[Epoch 6, Batch 400] loss: 0.04883570372010581
[Epoch 6, Batch 500] loss: 0.034575994415790776
[Epoch 6, Batch 600] loss: 0.03618056851119036
[Epoch 6, Batch 700] loss: 0.040768530205241404
[Epoch 6, Batch 800] loss: 0.04155410511739319
[Epoch 6, Batch 900] loss: 0.03523433588605258
[Epoch 6, Batch 1000] loss: 0.033640524598013144
[Epoch 6, Batch 1100] loss: 0.03724071502801962
[Epoch 6, Batch 1200] loss: 0.03260586436983431
[Epoch 6, Batch 1300] loss: 0.03711893950414378
[Epoch 6, Batch 1400] loss: 0.0395481954870047
[Epoch 6, Batch 1500] loss: 0.031017674935283138
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9844
Overfitting: 0.0474
Best model saved at epoch 6 with validation loss: 0.0474
[Epoch 7, Batch 100] loss: 0.024358098350348883
[Epoch 7, Batch 200] loss: 0.024607877550588454
[Epoch 7, Batch 300] loss: 0.03191544088942464
[Epoch 7, Batch 400] loss: 0.024531818857358303
[Epoch 7, Batch 500] loss: 0.03661033134965692
[Epoch 7, Batch 600] loss: 0.026511893843417057
[Epoch 7, Batch 700] loss: 0.026640280484061803
[Epoch 7, Batch 800] loss: 0.03287556624331046
[Epoch 7, Batch 900] loss: 0.03713627599616302
[Epoch 7, Batch 1000] loss: 0.027687059218587818
[Epoch 7, Batch 1100] loss: 0.03330416002208949
[Epoch 7, Batch 1200] loss: 0.03055672443850199
[Epoch 7, Batch 1300] loss: 0.02812630855914904
[Epoch 7, Batch 1400] loss: 0.022937470476317685
[Epoch 7, Batch 1500] loss: 0.035842323396209394
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9870
Overfitting: 0.0436
Best model saved at epoch 7 with validation loss: 0.0436
[Epoch 8, Batch 100] loss: 0.014939529105249675
[Epoch 8, Batch 200] loss: 0.02596149274366326
[Epoch 8, Batch 300] loss: 0.03311858970992034
[Epoch 8, Batch 400] loss: 0.027625634860960417
[Epoch 8, Batch 500] loss: 0.02709363574307645
[Epoch 8, Batch 600] loss: 0.024396869861739105
[Epoch 8, Batch 700] loss: 0.020906594822299666
[Epoch 8, Batch 800] loss: 0.0341200101719005
[Epoch 8, Batch 900] loss: 0.021198925171047447
[Epoch 8, Batch 1000] loss: 0.0286698044588411
[Epoch 8, Batch 1100] loss: 0.022533124648034572
[Epoch 8, Batch 1200] loss: 0.026406723770342068
[Epoch 8, Batch 1300] loss: 0.026279139360412956
[Epoch 8, Batch 1400] loss: 0.03515026087814476
[Epoch 8, Batch 1500] loss: 0.025777823268435897
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9831
Overfitting: 0.0531
[Epoch 9, Batch 100] loss: 0.018792215633002343
[Epoch 9, Batch 200] loss: 0.028178202997369225
[Epoch 9, Batch 300] loss: 0.018625865270441865
[Epoch 9, Batch 400] loss: 0.015031471008260269
[Epoch 9, Batch 500] loss: 0.021916395934822502
[Epoch 9, Batch 600] loss: 0.029445033990123194
[Epoch 9, Batch 700] loss: 0.02105684038993786
[Epoch 9, Batch 800] loss: 0.022368681042426033
[Epoch 9, Batch 900] loss: 0.02744036355885328
[Epoch 9, Batch 1000] loss: 0.0222072155821661
[Epoch 9, Batch 1100] loss: 0.0233246057938959
[Epoch 9, Batch 1200] loss: 0.020714910640963355
[Epoch 9, Batch 1300] loss: 0.02019335129745741
[Epoch 9, Batch 1400] loss: 0.02347909381853242
[Epoch 9, Batch 1500] loss: 0.034110767339298034
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9868
Overfitting: 0.0436
Best model saved at epoch 9 with validation loss: 0.0436
[Epoch 10, Batch 100] loss: 0.01625888704744284
[Epoch 10, Batch 200] loss: 0.024648259337045602
[Epoch 10, Batch 300] loss: 0.012456035105278715
[Epoch 10, Batch 400] loss: 0.023277771489083533
[Epoch 10, Batch 500] loss: 0.025545954561093823
[Epoch 10, Batch 600] loss: 0.019396168719176786
[Epoch 10, Batch 700] loss: 0.02020441731197934
[Epoch 10, Batch 800] loss: 0.015733070184542158
[Epoch 10, Batch 900] loss: 0.019991852585662856
[Epoch 10, Batch 1000] loss: 0.02129630656723748
[Epoch 10, Batch 1100] loss: 0.026783726752873917
[Epoch 10, Batch 1200] loss: 0.010493327171716374
[Epoch 10, Batch 1300] loss: 0.024390516995263168
[Epoch 10, Batch 1400] loss: 0.018972828408295755
[Epoch 10, Batch 1500] loss: 0.01850707624631468
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0521
Validation Accuracy: 0.9847
Overfitting: 0.0521
[Epoch 11, Batch 100] loss: 0.023257978829424247
[Epoch 11, Batch 200] loss: 0.017285712193115615
[Epoch 11, Batch 300] loss: 0.020267207380857143
[Epoch 11, Batch 400] loss: 0.013003491795316222
[Epoch 11, Batch 500] loss: 0.014746616560805705
[Epoch 11, Batch 600] loss: 0.015658465182277724
[Epoch 11, Batch 700] loss: 0.017462280459731118
[Epoch 11, Batch 800] loss: 0.020862503195312455
[Epoch 11, Batch 900] loss: 0.016590536934672856
[Epoch 11, Batch 1000] loss: 0.01677078374530538
[Epoch 11, Batch 1100] loss: 0.015295858462050092
[Epoch 11, Batch 1200] loss: 0.015612277253821957
[Epoch 11, Batch 1300] loss: 0.013920503789850045
[Epoch 11, Batch 1400] loss: 0.022687362437682167
[Epoch 11, Batch 1500] loss: 0.01864073262866441
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9852
Overfitting: 0.0504
[Epoch 12, Batch 100] loss: 0.01737831391983491
[Epoch 12, Batch 200] loss: 0.012616406680099317
[Epoch 12, Batch 300] loss: 0.018337479446199723
[Epoch 12, Batch 400] loss: 0.008894123361424136
[Epoch 12, Batch 500] loss: 0.01003796900731686
[Epoch 12, Batch 600] loss: 0.013914572672256327
[Epoch 12, Batch 700] loss: 0.0175099660592241
[Epoch 12, Batch 800] loss: 0.017083406627643852
[Epoch 12, Batch 900] loss: 0.019746765206000418
[Epoch 12, Batch 1000] loss: 0.013643415116312098
[Epoch 12, Batch 1100] loss: 0.021298290123959306
[Epoch 12, Batch 1200] loss: 0.011887977196383872
[Epoch 12, Batch 1300] loss: 0.01979693126242637
[Epoch 12, Batch 1400] loss: 0.0288177812867616
[Epoch 12, Batch 1500] loss: 0.01609990775876213
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9868
Overfitting: 0.0447
[Epoch 13, Batch 100] loss: 0.016073449447503663
[Epoch 13, Batch 200] loss: 0.011008090357609034
[Epoch 13, Batch 300] loss: 0.007610427170602634
[Epoch 13, Batch 400] loss: 0.015581360323458283
[Epoch 13, Batch 500] loss: 0.016301554317687986
[Epoch 13, Batch 600] loss: 0.012930566679497133
[Epoch 13, Batch 700] loss: 0.016434166343283322
[Epoch 13, Batch 800] loss: 0.018077260103818844
[Epoch 13, Batch 900] loss: 0.01307172746379365
[Epoch 13, Batch 1000] loss: 0.008156240492671713
[Epoch 13, Batch 1100] loss: 0.015455061171505803
[Epoch 13, Batch 1200] loss: 0.01829262248459145
[Epoch 13, Batch 1300] loss: 0.013593734162859618
[Epoch 13, Batch 1400] loss: 0.009554290907799442
[Epoch 13, Batch 1500] loss: 0.008423101469397808
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0397
Validation Accuracy: 0.9898
Overfitting: 0.0397
Best model saved at epoch 13 with validation loss: 0.0397
[Epoch 14, Batch 100] loss: 0.009767607129292628
[Epoch 14, Batch 200] loss: 0.003424163288291311
[Epoch 14, Batch 300] loss: 0.005345025749666093
[Epoch 14, Batch 400] loss: 0.009249387716408819
[Epoch 14, Batch 500] loss: 0.010399205686753702
[Epoch 14, Batch 600] loss: 0.00941863502286651
[Epoch 14, Batch 700] loss: 0.013363646977868484
[Epoch 14, Batch 800] loss: 0.009837368161242921
[Epoch 14, Batch 900] loss: 0.005674742840037652
[Epoch 14, Batch 1000] loss: 0.00950133739017474
[Epoch 14, Batch 1100] loss: 0.01427971161881942
[Epoch 14, Batch 1200] loss: 0.015936223119117587
[Epoch 14, Batch 1300] loss: 0.018179838337009643
[Epoch 14, Batch 1400] loss: 0.014583984365635842
[Epoch 14, Batch 1500] loss: 0.011357288335020713
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9877
Overfitting: 0.0455
[Epoch 15, Batch 100] loss: 0.009330649846342567
[Epoch 15, Batch 200] loss: 0.007759792150754947
[Epoch 15, Batch 300] loss: 0.009294856189808343
[Epoch 15, Batch 400] loss: 0.010741990433289175
[Epoch 15, Batch 500] loss: 0.006785406210001383
[Epoch 15, Batch 600] loss: 0.006247559739022108
[Epoch 15, Batch 700] loss: 0.010490688847330603
[Epoch 15, Batch 800] loss: 0.013854897246583278
[Epoch 15, Batch 900] loss: 0.011520824735689529
[Epoch 15, Batch 1000] loss: 0.007539054996354935
[Epoch 15, Batch 1100] loss: 0.003976850616736556
[Epoch 15, Batch 1200] loss: 0.0090118024851472
[Epoch 15, Batch 1300] loss: 0.008676708385710299
[Epoch 15, Batch 1400] loss: 0.009410210401856602
[Epoch 15, Batch 1500] loss: 0.013295946286968957
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9868
Overfitting: 0.0467
[Epoch 16, Batch 100] loss: 0.01599392378488119
[Epoch 16, Batch 200] loss: 0.01012659853351579
[Epoch 16, Batch 300] loss: 0.008138872753361283
[Epoch 16, Batch 400] loss: 0.010514714727723912
[Epoch 16, Batch 500] loss: 0.006688691693416331
[Epoch 16, Batch 600] loss: 0.007883352435874258
[Epoch 16, Batch 700] loss: 0.008425639557740396
[Epoch 16, Batch 800] loss: 0.008875436372486547
[Epoch 16, Batch 900] loss: 0.008527023082988307
[Epoch 16, Batch 1000] loss: 0.014050721230541968
[Epoch 16, Batch 1100] loss: 0.017832375504704033
[Epoch 16, Batch 1200] loss: 0.008175156346787844
[Epoch 16, Batch 1300] loss: 0.009951850710094731
[Epoch 16, Batch 1400] loss: 0.01075200025967206
[Epoch 16, Batch 1500] loss: 0.007964201626573414
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9897
Overfitting: 0.0422
[Epoch 17, Batch 100] loss: 0.0056212774159757825
[Epoch 17, Batch 200] loss: 0.003938154422939988
[Epoch 17, Batch 300] loss: 0.004910469594105962
[Epoch 17, Batch 400] loss: 0.007274763810773948
[Epoch 17, Batch 500] loss: 0.0055121639139770195
[Epoch 17, Batch 600] loss: 0.00995970297557733
[Epoch 17, Batch 700] loss: 0.011713592791656992
[Epoch 17, Batch 800] loss: 0.004714756022576694
[Epoch 17, Batch 900] loss: 0.003153097303811592
[Epoch 17, Batch 1000] loss: 0.007326328984474912
[Epoch 17, Batch 1100] loss: 0.007704150192193992
[Epoch 17, Batch 1200] loss: 0.0076906206639500855
[Epoch 17, Batch 1300] loss: 0.012949038164260856
[Epoch 17, Batch 1400] loss: 0.009149534219359339
[Epoch 17, Batch 1500] loss: 0.014492083974164415
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0562
Validation Accuracy: 0.9858
Overfitting: 0.0562
[Epoch 18, Batch 100] loss: 0.013631968487406993
[Epoch 18, Batch 200] loss: 0.011095487764159771
[Epoch 18, Batch 300] loss: 0.005465975925867497
[Epoch 18, Batch 400] loss: 0.00840132619285214
[Epoch 18, Batch 500] loss: 0.00347969797263886
[Epoch 18, Batch 600] loss: 0.005180766708519968
[Epoch 18, Batch 700] loss: 0.004652938468643697
[Epoch 18, Batch 800] loss: 0.009482940687557857
[Epoch 18, Batch 900] loss: 0.007846730996461701
[Epoch 18, Batch 1000] loss: 0.008825069910581079
[Epoch 18, Batch 1100] loss: 0.006777824511198105
[Epoch 18, Batch 1200] loss: 0.00413823899590625
[Epoch 18, Batch 1300] loss: 0.005876560984206663
[Epoch 18, Batch 1400] loss: 0.008928486425693336
[Epoch 18, Batch 1500] loss: 0.009631941910174645
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9875
Overfitting: 0.0475
[Epoch 19, Batch 100] loss: 0.0032864726046500435
[Epoch 19, Batch 200] loss: 0.0094985249939009
[Epoch 19, Batch 300] loss: 0.006092235665602175
[Epoch 19, Batch 400] loss: 0.005321659900355371
[Epoch 19, Batch 500] loss: 0.005464738471655437
[Epoch 19, Batch 600] loss: 0.006121555134359369
[Epoch 19, Batch 700] loss: 0.0031853986588134832
[Epoch 19, Batch 800] loss: 0.009232163842759745
[Epoch 19, Batch 900] loss: 0.008349131140912505
[Epoch 19, Batch 1000] loss: 0.008188928379609025
[Epoch 19, Batch 1100] loss: 0.010014173654153637
[Epoch 19, Batch 1200] loss: 0.007274093089595226
[Epoch 19, Batch 1300] loss: 0.006390712514812549
[Epoch 19, Batch 1400] loss: 0.004815047487056745
[Epoch 19, Batch 1500] loss: 0.011019144081305967
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0420
Validation Accuracy: 0.9895
Overfitting: 0.0420
[Epoch 20, Batch 100] loss: 0.005833077253121246
[Epoch 20, Batch 200] loss: 0.006084001225767679
[Epoch 20, Batch 300] loss: 0.00516530973284489
[Epoch 20, Batch 400] loss: 0.0051298358881012975
[Epoch 20, Batch 500] loss: 0.003675496445873705
[Epoch 20, Batch 600] loss: 0.006624835318350506
[Epoch 20, Batch 700] loss: 0.0038500369755593055
[Epoch 20, Batch 800] loss: 0.0030803447110974956
[Epoch 20, Batch 900] loss: 0.0080160519647211
[Epoch 20, Batch 1000] loss: 0.0062261392589425665
[Epoch 20, Batch 1100] loss: 0.005062147944069011
[Epoch 20, Batch 1200] loss: 0.007573475291276281
[Epoch 20, Batch 1300] loss: 0.005168481991345289
[Epoch 20, Batch 1400] loss: 0.004112748005654794
[Epoch 20, Batch 1500] loss: 0.001515492600547077
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0404
Validation Accuracy: 0.9899
Overfitting: 0.0404
[Epoch 21, Batch 100] loss: 0.002121497352441679
[Epoch 21, Batch 200] loss: 0.004050137016466806
[Epoch 21, Batch 300] loss: 0.004654168170607136
[Epoch 21, Batch 400] loss: 0.002161119067443451
[Epoch 21, Batch 500] loss: 0.0027210905008269036
[Epoch 21, Batch 600] loss: 0.003713657435628193
[Epoch 21, Batch 700] loss: 0.008421571594482771
[Epoch 21, Batch 800] loss: 0.0035882620829852385
[Epoch 21, Batch 900] loss: 0.0032322689675379477
[Epoch 21, Batch 1000] loss: 0.0086596092400805
[Epoch 21, Batch 1100] loss: 0.0057986952701162406
[Epoch 21, Batch 1200] loss: 0.007644570675684009
[Epoch 21, Batch 1300] loss: 0.008404026764353034
[Epoch 21, Batch 1400] loss: 0.004551445897279791
[Epoch 21, Batch 1500] loss: 0.005718675774638768
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9879
Overfitting: 0.0504
[Epoch 22, Batch 100] loss: 0.00485438386765054
[Epoch 22, Batch 200] loss: 0.002047208163480718
[Epoch 22, Batch 300] loss: 0.0030608036180342422
[Epoch 22, Batch 400] loss: 0.004467280740045681
[Epoch 22, Batch 500] loss: 0.005508366334373705
[Epoch 22, Batch 600] loss: 0.001286527513591409
[Epoch 22, Batch 700] loss: 0.002176634207483232
[Epoch 22, Batch 800] loss: 0.003395331673292503
[Epoch 22, Batch 900] loss: 0.004581812081087264
[Epoch 22, Batch 1000] loss: 0.002873499935806194
[Epoch 22, Batch 1100] loss: 0.004073308797732125
[Epoch 22, Batch 1200] loss: 0.003074276427829545
[Epoch 22, Batch 1300] loss: 0.006152050713145627
[Epoch 22, Batch 1400] loss: 0.0037805904233709953
[Epoch 22, Batch 1500] loss: 0.005687067213145696
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9885
Overfitting: 0.0478
[Epoch 23, Batch 100] loss: 0.0018186609440408574
[Epoch 23, Batch 200] loss: 0.003858632344479247
[Epoch 23, Batch 300] loss: 0.0023635260783885313
[Epoch 23, Batch 400] loss: 0.0018153327953970688
[Epoch 23, Batch 500] loss: 0.0007559774723881673
[Epoch 23, Batch 600] loss: 0.0024451976904282446
[Epoch 23, Batch 700] loss: 0.0027190025200805935
[Epoch 23, Batch 800] loss: 0.0070657777771089055
[Epoch 23, Batch 900] loss: 0.0025889254620301474
[Epoch 23, Batch 1000] loss: 0.0027407411421802408
[Epoch 23, Batch 1100] loss: 0.003590674277278936
[Epoch 23, Batch 1200] loss: 0.00983775443570721
[Epoch 23, Batch 1300] loss: 0.01689554268146594
[Epoch 23, Batch 1400] loss: 0.01784622751986717
[Epoch 23, Batch 1500] loss: 0.00467694756910987
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0444
Validation Accuracy: 0.9883
Overfitting: 0.0444
[Epoch 24, Batch 100] loss: 0.004129238971947871
[Epoch 24, Batch 200] loss: 0.0019321158262425797
[Epoch 24, Batch 300] loss: 0.0014739677473039592
[Epoch 24, Batch 400] loss: 0.001660111398770141
[Epoch 24, Batch 500] loss: 0.002275740001986151
[Epoch 24, Batch 600] loss: 0.0012887668924560104
[Epoch 24, Batch 700] loss: 0.0028027346042381394
[Epoch 24, Batch 800] loss: 0.0065825643091443455
[Epoch 24, Batch 900] loss: 0.0022553243909442244
[Epoch 24, Batch 1000] loss: 0.0016385256391049552
[Epoch 24, Batch 1100] loss: 0.005043216005912541
[Epoch 24, Batch 1200] loss: 0.004079176534783073
[Epoch 24, Batch 1300] loss: 0.004478084237589428
[Epoch 24, Batch 1400] loss: 0.00306297609879266
[Epoch 24, Batch 1500] loss: 0.003511835761213433
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0424
Validation Accuracy: 0.9899
Overfitting: 0.0424
Fold 1 validation loss: 0.0424
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.290717568397522
[Epoch 1, Batch 200] loss: 2.0622945964336394
[Epoch 1, Batch 300] loss: 0.6195196333527565
[Epoch 1, Batch 400] loss: 0.335576356574893
[Epoch 1, Batch 500] loss: 0.28596736062318084
[Epoch 1, Batch 600] loss: 0.2416502285376191
[Epoch 1, Batch 700] loss: 0.186609445232898
[Epoch 1, Batch 800] loss: 0.1828929753601551
[Epoch 1, Batch 900] loss: 0.1731836842186749
[Epoch 1, Batch 1000] loss: 0.16159003788605333
[Epoch 1, Batch 1100] loss: 0.16241755994036794
[Epoch 1, Batch 1200] loss: 0.14233093399554492
[Epoch 1, Batch 1300] loss: 0.14501184018328786
[Epoch 1, Batch 1400] loss: 0.13032256392762065
[Epoch 1, Batch 1500] loss: 0.11233043347485364
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1113
Validation Accuracy: 0.9670
Overfitting: 0.1113
Best model saved at epoch 1 with validation loss: 0.1113
[Epoch 2, Batch 100] loss: 0.10407319394405931
[Epoch 2, Batch 200] loss: 0.08735467458842322
[Epoch 2, Batch 300] loss: 0.10256953747477382
[Epoch 2, Batch 400] loss: 0.09838239524047822
[Epoch 2, Batch 500] loss: 0.08959316059248522
[Epoch 2, Batch 600] loss: 0.09556442661909387
[Epoch 2, Batch 700] loss: 0.08879991269670427
[Epoch 2, Batch 800] loss: 0.10273603415815159
[Epoch 2, Batch 900] loss: 0.0869297962798737
[Epoch 2, Batch 1000] loss: 0.07521021841908805
[Epoch 2, Batch 1100] loss: 0.08023748538224026
[Epoch 2, Batch 1200] loss: 0.08523168610525317
[Epoch 2, Batch 1300] loss: 0.0842271834006533
[Epoch 2, Batch 1400] loss: 0.07844507270958274
[Epoch 2, Batch 1500] loss: 0.08135369304101914
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0783
Validation Accuracy: 0.9764
Overfitting: 0.0783
Best model saved at epoch 2 with validation loss: 0.0783
[Epoch 3, Batch 100] loss: 0.061502106608822944
[Epoch 3, Batch 200] loss: 0.051230818810872734
[Epoch 3, Batch 300] loss: 0.07963805010076612
[Epoch 3, Batch 400] loss: 0.05834026168566197
[Epoch 3, Batch 500] loss: 0.08523947400506586
[Epoch 3, Batch 600] loss: 0.05902247790014371
[Epoch 3, Batch 700] loss: 0.06147570943576284
[Epoch 3, Batch 800] loss: 0.058776861161459235
[Epoch 3, Batch 900] loss: 0.06264239502139389
[Epoch 3, Batch 1000] loss: 0.06276742364163511
[Epoch 3, Batch 1100] loss: 0.05936853435472585
[Epoch 3, Batch 1200] loss: 0.05683789937291294
[Epoch 3, Batch 1300] loss: 0.0573780279874336
[Epoch 3, Batch 1400] loss: 0.0721032122685574
[Epoch 3, Batch 1500] loss: 0.054467984228394925
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9795
Overfitting: 0.0665
Best model saved at epoch 3 with validation loss: 0.0665
[Epoch 4, Batch 100] loss: 0.04709464429877699
[Epoch 4, Batch 200] loss: 0.048631264354335145
[Epoch 4, Batch 300] loss: 0.040486620531883094
[Epoch 4, Batch 400] loss: 0.0492223515958176
[Epoch 4, Batch 500] loss: 0.04409253066638485
[Epoch 4, Batch 600] loss: 0.047300251066917556
[Epoch 4, Batch 700] loss: 0.06658822876866907
[Epoch 4, Batch 800] loss: 0.04659122403594665
[Epoch 4, Batch 900] loss: 0.04567580806324258
[Epoch 4, Batch 1000] loss: 0.050888316194759683
[Epoch 4, Batch 1100] loss: 0.05247963299858384
[Epoch 4, Batch 1200] loss: 0.04313906486670021
[Epoch 4, Batch 1300] loss: 0.04281933957070578
[Epoch 4, Batch 1400] loss: 0.05297700564726256
[Epoch 4, Batch 1500] loss: 0.05183271944610169
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0655
Validation Accuracy: 0.9798
Overfitting: 0.0655
Best model saved at epoch 4 with validation loss: 0.0655
[Epoch 5, Batch 100] loss: 0.028609176396857946
[Epoch 5, Batch 200] loss: 0.045652632759884
[Epoch 5, Batch 300] loss: 0.0450255464023212
[Epoch 5, Batch 400] loss: 0.050004628649330696
[Epoch 5, Batch 500] loss: 0.03140078578260727
[Epoch 5, Batch 600] loss: 0.04022427846386563
[Epoch 5, Batch 700] loss: 0.03259020863479236
[Epoch 5, Batch 800] loss: 0.042178994616260755
[Epoch 5, Batch 900] loss: 0.04819182479288429
[Epoch 5, Batch 1000] loss: 0.038699574615457095
[Epoch 5, Batch 1100] loss: 0.03539933036838192
[Epoch 5, Batch 1200] loss: 0.03995772190552088
[Epoch 5, Batch 1300] loss: 0.03611264799488709
[Epoch 5, Batch 1400] loss: 0.047918446341063826
[Epoch 5, Batch 1500] loss: 0.03728639138280414
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9848
Overfitting: 0.0537
Best model saved at epoch 5 with validation loss: 0.0537
[Epoch 6, Batch 100] loss: 0.03256098422803916
[Epoch 6, Batch 200] loss: 0.02896530083089601
[Epoch 6, Batch 300] loss: 0.03460614281837479
[Epoch 6, Batch 400] loss: 0.03445071265799925
[Epoch 6, Batch 500] loss: 0.03569209437584504
[Epoch 6, Batch 600] loss: 0.04420951574924402
[Epoch 6, Batch 700] loss: 0.03315608036500635
[Epoch 6, Batch 800] loss: 0.03944068946875632
[Epoch 6, Batch 900] loss: 0.02708065826096572
[Epoch 6, Batch 1000] loss: 0.028060734565369786
[Epoch 6, Batch 1100] loss: 0.04515438213391462
[Epoch 6, Batch 1200] loss: 0.0424112272443017
[Epoch 6, Batch 1300] loss: 0.03089934553048806
[Epoch 6, Batch 1400] loss: 0.033707311539328655
[Epoch 6, Batch 1500] loss: 0.04437907449027989
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9869
Overfitting: 0.0479
Best model saved at epoch 6 with validation loss: 0.0479
[Epoch 7, Batch 100] loss: 0.03435936899099033
[Epoch 7, Batch 200] loss: 0.02738521695835516
[Epoch 7, Batch 300] loss: 0.027602306580811274
[Epoch 7, Batch 400] loss: 0.032904477578704246
[Epoch 7, Batch 500] loss: 0.031890139982861
[Epoch 7, Batch 600] loss: 0.02489679022328346
[Epoch 7, Batch 700] loss: 0.025245298396330326
[Epoch 7, Batch 800] loss: 0.02188838748028502
[Epoch 7, Batch 900] loss: 0.03155922897043638
[Epoch 7, Batch 1000] loss: 0.02964545277049183
[Epoch 7, Batch 1100] loss: 0.027497636262633022
[Epoch 7, Batch 1200] loss: 0.027945919131889242
[Epoch 7, Batch 1300] loss: 0.030255517462501304
[Epoch 7, Batch 1400] loss: 0.02835449652047828
[Epoch 7, Batch 1500] loss: 0.02934842859627679
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9860
Overfitting: 0.0518
[Epoch 8, Batch 100] loss: 0.021801049285859336
[Epoch 8, Batch 200] loss: 0.02536318380822195
[Epoch 8, Batch 300] loss: 0.02120617210963246
[Epoch 8, Batch 400] loss: 0.025058270342706235
[Epoch 8, Batch 500] loss: 0.025188132624316496
[Epoch 8, Batch 600] loss: 0.02640442484494997
[Epoch 8, Batch 700] loss: 0.027346539630088956
[Epoch 8, Batch 800] loss: 0.021883678451558808
[Epoch 8, Batch 900] loss: 0.024858329959606636
[Epoch 8, Batch 1000] loss: 0.02570888978021685
[Epoch 8, Batch 1100] loss: 0.018852173083287196
[Epoch 8, Batch 1200] loss: 0.02057724398422579
[Epoch 8, Batch 1300] loss: 0.0334951506087964
[Epoch 8, Batch 1400] loss: 0.03134452307625907
[Epoch 8, Batch 1500] loss: 0.018929733996774303
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9849
Overfitting: 0.0509
[Epoch 9, Batch 100] loss: 0.01528731836253428
[Epoch 9, Batch 200] loss: 0.021829460874832875
[Epoch 9, Batch 300] loss: 0.01658083211390476
[Epoch 9, Batch 400] loss: 0.018860943180479806
[Epoch 9, Batch 500] loss: 0.019235665669184526
[Epoch 9, Batch 600] loss: 0.02344514107477153
[Epoch 9, Batch 700] loss: 0.022885513880464715
[Epoch 9, Batch 800] loss: 0.021282875329343368
[Epoch 9, Batch 900] loss: 0.025808636270812712
[Epoch 9, Batch 1000] loss: 0.02494368894447689
[Epoch 9, Batch 1100] loss: 0.021922775948478374
[Epoch 9, Batch 1200] loss: 0.01943993857537862
[Epoch 9, Batch 1300] loss: 0.02077727821073495
[Epoch 9, Batch 1400] loss: 0.03572599594233907
[Epoch 9, Batch 1500] loss: 0.024484967499302002
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0545
Validation Accuracy: 0.9840
Overfitting: 0.0545
[Epoch 10, Batch 100] loss: 0.0161343928759743
[Epoch 10, Batch 200] loss: 0.015214734657529334
[Epoch 10, Batch 300] loss: 0.017120177846954902
[Epoch 10, Batch 400] loss: 0.017117234390971136
[Epoch 10, Batch 500] loss: 0.014252144785859854
[Epoch 10, Batch 600] loss: 0.021756120974823715
[Epoch 10, Batch 700] loss: 0.017282092325913254
[Epoch 10, Batch 800] loss: 0.018965979582280853
[Epoch 10, Batch 900] loss: 0.030872076381128863
[Epoch 10, Batch 1000] loss: 0.0238717468669347
[Epoch 10, Batch 1100] loss: 0.020619850301009136
[Epoch 10, Batch 1200] loss: 0.017780634828814073
[Epoch 10, Batch 1300] loss: 0.02712551148244529
[Epoch 10, Batch 1400] loss: 0.017136212896875804
[Epoch 10, Batch 1500] loss: 0.020255655281143845
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9856
Overfitting: 0.0524
[Epoch 11, Batch 100] loss: 0.017600613980321214
[Epoch 11, Batch 200] loss: 0.013985958272314747
[Epoch 11, Batch 300] loss: 0.018133489783358527
[Epoch 11, Batch 400] loss: 0.01679845116166689
[Epoch 11, Batch 500] loss: 0.018201191602129255
[Epoch 11, Batch 600] loss: 0.012492471877922072
[Epoch 11, Batch 700] loss: 0.016358559241780313
[Epoch 11, Batch 800] loss: 0.01476407598282094
[Epoch 11, Batch 900] loss: 0.018131516602988996
[Epoch 11, Batch 1000] loss: 0.008055057218625735
[Epoch 11, Batch 1100] loss: 0.01636162397277076
[Epoch 11, Batch 1200] loss: 0.015857167025460514
[Epoch 11, Batch 1300] loss: 0.02189728647877928
[Epoch 11, Batch 1400] loss: 0.018836480911777472
[Epoch 11, Batch 1500] loss: 0.015665013925445236
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9858
Overfitting: 0.0546
[Epoch 12, Batch 100] loss: 0.008980757109820842
[Epoch 12, Batch 200] loss: 0.01919514559322124
[Epoch 12, Batch 300] loss: 0.015576125722291181
[Epoch 12, Batch 400] loss: 0.008734381069880328
[Epoch 12, Batch 500] loss: 0.014752213805004431
[Epoch 12, Batch 600] loss: 0.015498180490794766
[Epoch 12, Batch 700] loss: 0.014377002918590733
[Epoch 12, Batch 800] loss: 0.015837744746131647
[Epoch 12, Batch 900] loss: 0.011542126455751714
[Epoch 12, Batch 1000] loss: 0.01577066316820492
[Epoch 12, Batch 1100] loss: 0.012140438732967596
[Epoch 12, Batch 1200] loss: 0.015177408957533771
[Epoch 12, Batch 1300] loss: 0.017157489656165127
[Epoch 12, Batch 1400] loss: 0.015346492417775153
[Epoch 12, Batch 1500] loss: 0.013225176030537113
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9842
Overfitting: 0.0608
[Epoch 13, Batch 100] loss: 0.010069310283652157
[Epoch 13, Batch 200] loss: 0.010573390204845054
[Epoch 13, Batch 300] loss: 0.014229454054002418
[Epoch 13, Batch 400] loss: 0.010429484790292917
[Epoch 13, Batch 500] loss: 0.014419040466891601
[Epoch 13, Batch 600] loss: 0.016748247105570043
[Epoch 13, Batch 700] loss: 0.010652627778872556
[Epoch 13, Batch 800] loss: 0.015853900228648854
[Epoch 13, Batch 900] loss: 0.00772791603438236
[Epoch 13, Batch 1000] loss: 0.012563151977483358
[Epoch 13, Batch 1100] loss: 0.011511407369398511
[Epoch 13, Batch 1200] loss: 0.018123680864882773
[Epoch 13, Batch 1300] loss: 0.013356591119518271
[Epoch 13, Batch 1400] loss: 0.013348670111299725
[Epoch 13, Batch 1500] loss: 0.009716100742061827
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9875
Overfitting: 0.0535
[Epoch 14, Batch 100] loss: 0.012977704923014245
[Epoch 14, Batch 200] loss: 0.012443743276053283
[Epoch 14, Batch 300] loss: 0.010788097843815195
[Epoch 14, Batch 400] loss: 0.009422700998238725
[Epoch 14, Batch 500] loss: 0.008296272678035167
[Epoch 14, Batch 600] loss: 0.006485187115649751
[Epoch 14, Batch 700] loss: 0.010833419519294694
[Epoch 14, Batch 800] loss: 0.011737708468281198
[Epoch 14, Batch 900] loss: 0.015277514570489075
[Epoch 14, Batch 1000] loss: 0.014484273558518907
[Epoch 14, Batch 1100] loss: 0.012119952579159871
[Epoch 14, Batch 1200] loss: 0.013844877518276916
[Epoch 14, Batch 1300] loss: 0.013753826727661362
[Epoch 14, Batch 1400] loss: 0.010609840124689072
[Epoch 14, Batch 1500] loss: 0.012745325151936413
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9886
Overfitting: 0.0481
[Epoch 15, Batch 100] loss: 0.007868100031946596
[Epoch 15, Batch 200] loss: 0.007956164950446692
[Epoch 15, Batch 300] loss: 0.008037286688777385
[Epoch 15, Batch 400] loss: 0.0061648220256756755
[Epoch 15, Batch 500] loss: 0.011656999260812881
[Epoch 15, Batch 600] loss: 0.010574510435035336
[Epoch 15, Batch 700] loss: 0.015030666322199977
[Epoch 15, Batch 800] loss: 0.011884281313577959
[Epoch 15, Batch 900] loss: 0.00673441938436099
[Epoch 15, Batch 1000] loss: 0.005375348747620592
[Epoch 15, Batch 1100] loss: 0.014625408345127653
[Epoch 15, Batch 1200] loss: 0.009990830083006585
[Epoch 15, Batch 1300] loss: 0.006154482989259123
[Epoch 15, Batch 1400] loss: 0.011298374680391134
[Epoch 15, Batch 1500] loss: 0.014804495797898198
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9865
Overfitting: 0.0576
[Epoch 16, Batch 100] loss: 0.008545908845007943
[Epoch 16, Batch 200] loss: 0.004042958691898093
[Epoch 16, Batch 300] loss: 0.005162057616161064
[Epoch 16, Batch 400] loss: 0.006980674591086426
[Epoch 16, Batch 500] loss: 0.0038480800918273416
[Epoch 16, Batch 600] loss: 0.009304165267703866
[Epoch 16, Batch 700] loss: 0.005077401036533047
[Epoch 16, Batch 800] loss: 0.010090249009863328
[Epoch 16, Batch 900] loss: 0.011029947139231808
[Epoch 16, Batch 1000] loss: 0.012119676770016668
[Epoch 16, Batch 1100] loss: 0.0055913202515876035
[Epoch 16, Batch 1200] loss: 0.011687275054346174
[Epoch 16, Batch 1300] loss: 0.011624177175563091
[Epoch 16, Batch 1400] loss: 0.007619182199605347
[Epoch 16, Batch 1500] loss: 0.014278118914025981
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9876
Overfitting: 0.0523
[Epoch 17, Batch 100] loss: 0.009653858587844297
[Epoch 17, Batch 200] loss: 0.004914317698621744
[Epoch 17, Batch 300] loss: 0.015257466190946615
[Epoch 17, Batch 400] loss: 0.010505242601357167
[Epoch 17, Batch 500] loss: 0.008623520333640045
[Epoch 17, Batch 600] loss: 0.007710783429993171
[Epoch 17, Batch 700] loss: 0.010408823367706646
[Epoch 17, Batch 800] loss: 0.012966619584803994
[Epoch 17, Batch 900] loss: 0.006053071830174304
[Epoch 17, Batch 1000] loss: 0.007414905067162181
[Epoch 17, Batch 1100] loss: 0.00668021451403547
[Epoch 17, Batch 1200] loss: 0.007312887346306525
[Epoch 17, Batch 1300] loss: 0.005470201010948586
[Epoch 17, Batch 1400] loss: 0.004743007400843453
[Epoch 17, Batch 1500] loss: 0.007403107243699196
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9892
Overfitting: 0.0500
[Epoch 18, Batch 100] loss: 0.006083300248328669
[Epoch 18, Batch 200] loss: 0.0023295072638620695
[Epoch 18, Batch 300] loss: 0.005449814702496951
[Epoch 18, Batch 400] loss: 0.0029369406749674455
[Epoch 18, Batch 500] loss: 0.003030947250608733
[Epoch 18, Batch 600] loss: 0.005455443974688024
[Epoch 18, Batch 700] loss: 0.0036461703802888224
[Epoch 18, Batch 800] loss: 0.009418552329498198
[Epoch 18, Batch 900] loss: 0.008736216772299486
[Epoch 18, Batch 1000] loss: 0.005854727021214785
[Epoch 18, Batch 1100] loss: 0.010192243047104057
[Epoch 18, Batch 1200] loss: 0.0039412703575249
[Epoch 18, Batch 1300] loss: 0.0033412339017468186
[Epoch 18, Batch 1400] loss: 0.004580624884702047
[Epoch 18, Batch 1500] loss: 0.013601407638307137
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0596
Validation Accuracy: 0.9868
Overfitting: 0.0596
[Epoch 19, Batch 100] loss: 0.009198864513423359
[Epoch 19, Batch 200] loss: 0.004928315834686146
[Epoch 19, Batch 300] loss: 0.004074799920435908
[Epoch 19, Batch 400] loss: 0.0043531056302072105
[Epoch 19, Batch 500] loss: 0.0038255880626070393
[Epoch 19, Batch 600] loss: 0.011345390713199777
[Epoch 19, Batch 700] loss: 0.011406836472942813
[Epoch 19, Batch 800] loss: 0.005435647499250535
[Epoch 19, Batch 900] loss: 0.004292689892909038
[Epoch 19, Batch 1000] loss: 0.004616103491216563
[Epoch 19, Batch 1100] loss: 0.004052701682126098
[Epoch 19, Batch 1200] loss: 0.006886628090992417
[Epoch 19, Batch 1300] loss: 0.01726270739366555
[Epoch 19, Batch 1400] loss: 0.014907674910823517
[Epoch 19, Batch 1500] loss: 0.003390719398898909
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9892
Overfitting: 0.0481
[Epoch 20, Batch 100] loss: 0.0031961531332672165
[Epoch 20, Batch 200] loss: 0.002274541637088987
[Epoch 20, Batch 300] loss: 0.0063044158273805806
[Epoch 20, Batch 400] loss: 0.0036141171650342584
[Epoch 20, Batch 500] loss: 0.003142567751376646
[Epoch 20, Batch 600] loss: 0.0053282642819931425
[Epoch 20, Batch 700] loss: 0.007235054864813719
[Epoch 20, Batch 800] loss: 0.00660464490357299
[Epoch 20, Batch 900] loss: 0.0032390203982606636
[Epoch 20, Batch 1000] loss: 0.004181187977624176
[Epoch 20, Batch 1100] loss: 0.002506440299539463
[Epoch 20, Batch 1200] loss: 0.012159717659478701
[Epoch 20, Batch 1300] loss: 0.006170501592514484
[Epoch 20, Batch 1400] loss: 0.007553121059549995
[Epoch 20, Batch 1500] loss: 0.0038577039761196375
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9886
Overfitting: 0.0556
[Epoch 21, Batch 100] loss: 0.00294427550193177
[Epoch 21, Batch 200] loss: 0.007122331642231075
[Epoch 21, Batch 300] loss: 0.003966199302230962
[Epoch 21, Batch 400] loss: 0.016356269007483205
[Epoch 21, Batch 500] loss: 0.003542490749023273
[Epoch 21, Batch 600] loss: 0.005401712298735219
[Epoch 21, Batch 700] loss: 0.0069188330452811895
[Epoch 21, Batch 800] loss: 0.007435958091714383
[Epoch 21, Batch 900] loss: 0.00429517849095646
[Epoch 21, Batch 1000] loss: 0.006222610636123136
[Epoch 21, Batch 1100] loss: 0.006554981162853437
[Epoch 21, Batch 1200] loss: 0.003919605115702893
[Epoch 21, Batch 1300] loss: 0.007523812330236979
[Epoch 21, Batch 1400] loss: 0.0029148022734898403
[Epoch 21, Batch 1500] loss: 0.005426855655866802
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0597
Validation Accuracy: 0.9868
Overfitting: 0.0597
[Epoch 22, Batch 100] loss: 0.010153701106080461
[Epoch 22, Batch 200] loss: 0.002295730125058526
[Epoch 22, Batch 300] loss: 0.003943607741346114
[Epoch 22, Batch 400] loss: 0.009177798608425292
[Epoch 22, Batch 500] loss: 0.0029904602635940592
[Epoch 22, Batch 600] loss: 0.003300590940489201
[Epoch 22, Batch 700] loss: 0.0030988063972290547
[Epoch 22, Batch 800] loss: 0.0043422664230843115
[Epoch 22, Batch 900] loss: 0.009161983168492044
[Epoch 22, Batch 1000] loss: 0.0020657848898099473
[Epoch 22, Batch 1100] loss: 0.005627078510940464
[Epoch 22, Batch 1200] loss: 0.006089066682632165
[Epoch 22, Batch 1300] loss: 0.006229550533739712
[Epoch 22, Batch 1400] loss: 0.004455584661336616
[Epoch 22, Batch 1500] loss: 0.004849620877764665
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0563
Validation Accuracy: 0.9882
Overfitting: 0.0563
[Epoch 23, Batch 100] loss: 0.003709394969869209
[Epoch 23, Batch 200] loss: 0.0024530693473218436
[Epoch 23, Batch 300] loss: 0.0015008923698178478
[Epoch 23, Batch 400] loss: 0.0025066954438602808
[Epoch 23, Batch 500] loss: 0.001883339970599991
[Epoch 23, Batch 600] loss: 0.005127226852191597
[Epoch 23, Batch 700] loss: 0.0038388931209465227
[Epoch 23, Batch 800] loss: 0.001760130311380408
[Epoch 23, Batch 900] loss: 0.0018661910562832419
[Epoch 23, Batch 1000] loss: 0.001605227142763397
[Epoch 23, Batch 1100] loss: 0.00544117436943111
[Epoch 23, Batch 1200] loss: 0.0019965039883277315
[Epoch 23, Batch 1300] loss: 0.00130273874480622
[Epoch 23, Batch 1400] loss: 0.0046158355950638
[Epoch 23, Batch 1500] loss: 0.0026022859412182697
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9884
Overfitting: 0.0561
[Epoch 24, Batch 100] loss: 0.0013277525938741519
[Epoch 24, Batch 200] loss: 0.0006499150769684548
[Epoch 24, Batch 300] loss: 0.0014549431959369485
[Epoch 24, Batch 400] loss: 0.005500174437174792
[Epoch 24, Batch 500] loss: 0.0038113250134230725
[Epoch 24, Batch 600] loss: 0.0026511055391620175
[Epoch 24, Batch 700] loss: 0.002544155384853184
[Epoch 24, Batch 800] loss: 0.003703655790263838
[Epoch 24, Batch 900] loss: 0.0015794489432505543
[Epoch 24, Batch 1000] loss: 0.02064373049797723
[Epoch 24, Batch 1100] loss: 0.009189302613857536
[Epoch 24, Batch 1200] loss: 0.005753973750208843
[Epoch 24, Batch 1300] loss: 0.005188960548060777
[Epoch 24, Batch 1400] loss: 0.0057621272199526175
[Epoch 24, Batch 1500] loss: 0.004669140406082874
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0675
Validation Accuracy: 0.9874
Overfitting: 0.0675
Fold 2 validation loss: 0.0675
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2822315454483033
[Epoch 1, Batch 200] loss: 1.7335435166954993
[Epoch 1, Batch 300] loss: 0.5604339139163494
[Epoch 1, Batch 400] loss: 0.40158294066786765
[Epoch 1, Batch 500] loss: 0.2869478579983115
[Epoch 1, Batch 600] loss: 0.2221701630577445
[Epoch 1, Batch 700] loss: 0.21384205821901558
[Epoch 1, Batch 800] loss: 0.19646263659000396
[Epoch 1, Batch 900] loss: 0.18066708521917463
[Epoch 1, Batch 1000] loss: 0.16148397695273162
[Epoch 1, Batch 1100] loss: 0.18577115868218244
[Epoch 1, Batch 1200] loss: 0.137664128318429
[Epoch 1, Batch 1300] loss: 0.12816146415658294
[Epoch 1, Batch 1400] loss: 0.12524699917063117
[Epoch 1, Batch 1500] loss: 0.10525086775887757
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1322
Validation Accuracy: 0.9601
Overfitting: 0.1322
Best model saved at epoch 1 with validation loss: 0.1322
[Epoch 2, Batch 100] loss: 0.0937661703210324
[Epoch 2, Batch 200] loss: 0.11020018271170556
[Epoch 2, Batch 300] loss: 0.10052678738720715
[Epoch 2, Batch 400] loss: 0.0940203816536814
[Epoch 2, Batch 500] loss: 0.08891811190638692
[Epoch 2, Batch 600] loss: 0.09110593811608851
[Epoch 2, Batch 700] loss: 0.08233898151200264
[Epoch 2, Batch 800] loss: 0.09159554663579911
[Epoch 2, Batch 900] loss: 0.10033902801107615
[Epoch 2, Batch 1000] loss: 0.07159645047038793
[Epoch 2, Batch 1100] loss: 0.08336497121956199
[Epoch 2, Batch 1200] loss: 0.09156940252985805
[Epoch 2, Batch 1300] loss: 0.060660484072286636
[Epoch 2, Batch 1400] loss: 0.07797319105360657
[Epoch 2, Batch 1500] loss: 0.07013756022555753
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0777
Validation Accuracy: 0.9768
Overfitting: 0.0777
Best model saved at epoch 2 with validation loss: 0.0777
[Epoch 3, Batch 100] loss: 0.059741595519008116
[Epoch 3, Batch 200] loss: 0.07143321224488318
[Epoch 3, Batch 300] loss: 0.06782513815443963
[Epoch 3, Batch 400] loss: 0.06444361037109048
[Epoch 3, Batch 500] loss: 0.0607265672669746
[Epoch 3, Batch 600] loss: 0.0581524149235338
[Epoch 3, Batch 700] loss: 0.06690361674642191
[Epoch 3, Batch 800] loss: 0.052990197602193805
[Epoch 3, Batch 900] loss: 0.06075654293876141
[Epoch 3, Batch 1000] loss: 0.06603897945722564
[Epoch 3, Batch 1100] loss: 0.0617455607233569
[Epoch 3, Batch 1200] loss: 0.05853795398841612
[Epoch 3, Batch 1300] loss: 0.04108866430586204
[Epoch 3, Batch 1400] loss: 0.0762996104703052
[Epoch 3, Batch 1500] loss: 0.0542754082987085
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0590
Validation Accuracy: 0.9820
Overfitting: 0.0590
Best model saved at epoch 3 with validation loss: 0.0590
[Epoch 4, Batch 100] loss: 0.05020152577315457
[Epoch 4, Batch 200] loss: 0.039826843293849376
[Epoch 4, Batch 300] loss: 0.05154799072770402
[Epoch 4, Batch 400] loss: 0.051646347219357264
[Epoch 4, Batch 500] loss: 0.058286908997688444
[Epoch 4, Batch 600] loss: 0.05010754055692814
[Epoch 4, Batch 700] loss: 0.046069512300891804
[Epoch 4, Batch 800] loss: 0.04429523568949662
[Epoch 4, Batch 900] loss: 0.051586071815690956
[Epoch 4, Batch 1000] loss: 0.0520110120184836
[Epoch 4, Batch 1100] loss: 0.047736128558171914
[Epoch 4, Batch 1200] loss: 0.040732496525743046
[Epoch 4, Batch 1300] loss: 0.04597645917383488
[Epoch 4, Batch 1400] loss: 0.0388936486991588
[Epoch 4, Batch 1500] loss: 0.04738641189876944
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9813
Overfitting: 0.0606
[Epoch 5, Batch 100] loss: 0.033643440396990625
[Epoch 5, Batch 200] loss: 0.04448217681550887
[Epoch 5, Batch 300] loss: 0.030409854459867346
[Epoch 5, Batch 400] loss: 0.03076313183817547
[Epoch 5, Batch 500] loss: 0.04250530747114681
[Epoch 5, Batch 600] loss: 0.03573902570205974
[Epoch 5, Batch 700] loss: 0.035551059070858176
[Epoch 5, Batch 800] loss: 0.04768121934495866
[Epoch 5, Batch 900] loss: 0.0370053778111469
[Epoch 5, Batch 1000] loss: 0.04616097567719407
[Epoch 5, Batch 1100] loss: 0.03522365485550836
[Epoch 5, Batch 1200] loss: 0.036337498948560094
[Epoch 5, Batch 1300] loss: 0.04606503770512063
[Epoch 5, Batch 1400] loss: 0.037851398577331566
[Epoch 5, Batch 1500] loss: 0.04243157400691416
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9843
Overfitting: 0.0518
Best model saved at epoch 5 with validation loss: 0.0518
[Epoch 6, Batch 100] loss: 0.03168318637282937
[Epoch 6, Batch 200] loss: 0.03415760753676295
[Epoch 6, Batch 300] loss: 0.02451473713386804
[Epoch 6, Batch 400] loss: 0.03739434117334895
[Epoch 6, Batch 500] loss: 0.030676407522987573
[Epoch 6, Batch 600] loss: 0.02874068223463837
[Epoch 6, Batch 700] loss: 0.03852223913825583
[Epoch 6, Batch 800] loss: 0.034573475582001266
[Epoch 6, Batch 900] loss: 0.02560422969472711
[Epoch 6, Batch 1000] loss: 0.03245320772693958
[Epoch 6, Batch 1100] loss: 0.03132557237637229
[Epoch 6, Batch 1200] loss: 0.02938805155135924
[Epoch 6, Batch 1300] loss: 0.04049096155562438
[Epoch 6, Batch 1400] loss: 0.03223343014602506
[Epoch 6, Batch 1500] loss: 0.036940878381137736
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9848
Overfitting: 0.0515
Best model saved at epoch 6 with validation loss: 0.0515
[Epoch 7, Batch 100] loss: 0.01818322026680107
[Epoch 7, Batch 200] loss: 0.024096949321392457
[Epoch 7, Batch 300] loss: 0.025064342274999943
[Epoch 7, Batch 400] loss: 0.031003408194956138
[Epoch 7, Batch 500] loss: 0.02407536646380322
[Epoch 7, Batch 600] loss: 0.02538131782785058
[Epoch 7, Batch 700] loss: 0.029574369574256708
[Epoch 7, Batch 800] loss: 0.021600810778763843
[Epoch 7, Batch 900] loss: 0.029969391292106594
[Epoch 7, Batch 1000] loss: 0.034450433941092345
[Epoch 7, Batch 1100] loss: 0.029238328285864555
[Epoch 7, Batch 1200] loss: 0.02562906160688726
[Epoch 7, Batch 1300] loss: 0.03268089747492922
[Epoch 7, Batch 1400] loss: 0.02618986787558242
[Epoch 7, Batch 1500] loss: 0.03180660348851234
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9818
Overfitting: 0.0605
[Epoch 8, Batch 100] loss: 0.027706646932056173
[Epoch 8, Batch 200] loss: 0.018823401842382737
[Epoch 8, Batch 300] loss: 0.020769176298126694
[Epoch 8, Batch 400] loss: 0.01881964454529225
[Epoch 8, Batch 500] loss: 0.023329497314116453
[Epoch 8, Batch 600] loss: 0.022500905443739613
[Epoch 8, Batch 700] loss: 0.019932319514919073
[Epoch 8, Batch 800] loss: 0.028899225533095887
[Epoch 8, Batch 900] loss: 0.019686524712160463
[Epoch 8, Batch 1000] loss: 0.02078605128117488
[Epoch 8, Batch 1100] loss: 0.02896310226264177
[Epoch 8, Batch 1200] loss: 0.02204584730498027
[Epoch 8, Batch 1300] loss: 0.02029711920855334
[Epoch 8, Batch 1400] loss: 0.026725812587828843
[Epoch 8, Batch 1500] loss: 0.02735794388478098
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9862
Overfitting: 0.0490
Best model saved at epoch 8 with validation loss: 0.0490
[Epoch 9, Batch 100] loss: 0.013250195966975298
[Epoch 9, Batch 200] loss: 0.01950455711918039
[Epoch 9, Batch 300] loss: 0.022156889000652883
[Epoch 9, Batch 400] loss: 0.023190518739793334
[Epoch 9, Batch 500] loss: 0.02162362211398431
[Epoch 9, Batch 600] loss: 0.014193675504429848
[Epoch 9, Batch 700] loss: 0.022284165732417024
[Epoch 9, Batch 800] loss: 0.013486629296967294
[Epoch 9, Batch 900] loss: 0.02109643500429229
[Epoch 9, Batch 1000] loss: 0.017447075541640517
[Epoch 9, Batch 1100] loss: 0.019768164380075177
[Epoch 9, Batch 1200] loss: 0.02648321153654251
[Epoch 9, Batch 1300] loss: 0.02252619299804792
[Epoch 9, Batch 1400] loss: 0.01991069282616081
[Epoch 9, Batch 1500] loss: 0.024455923494751914
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0596
Validation Accuracy: 0.9841
Overfitting: 0.0596
[Epoch 10, Batch 100] loss: 0.01139868855010718
[Epoch 10, Batch 200] loss: 0.016974618115491467
[Epoch 10, Batch 300] loss: 0.013017286009962846
[Epoch 10, Batch 400] loss: 0.015218463656819949
[Epoch 10, Batch 500] loss: 0.017992102728385362
[Epoch 10, Batch 600] loss: 0.01938878578810545
[Epoch 10, Batch 700] loss: 0.012716440887052158
[Epoch 10, Batch 800] loss: 0.013453589873788587
[Epoch 10, Batch 900] loss: 0.02696294319910521
[Epoch 10, Batch 1000] loss: 0.014487053575830942
[Epoch 10, Batch 1100] loss: 0.03842540732315683
[Epoch 10, Batch 1200] loss: 0.025752755340072327
[Epoch 10, Batch 1300] loss: 0.019652702520688764
[Epoch 10, Batch 1400] loss: 0.01731318735081004
[Epoch 10, Batch 1500] loss: 0.01432550511264708
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9885
Overfitting: 0.0437
Best model saved at epoch 10 with validation loss: 0.0437
[Epoch 11, Batch 100] loss: 0.01667522094474407
[Epoch 11, Batch 200] loss: 0.016782522936555324
[Epoch 11, Batch 300] loss: 0.013574601968393836
[Epoch 11, Batch 400] loss: 0.01353100148277008
[Epoch 11, Batch 500] loss: 0.013823768376278167
[Epoch 11, Batch 600] loss: 0.01843283382797381
[Epoch 11, Batch 700] loss: 0.02129998143125704
[Epoch 11, Batch 800] loss: 0.022348201834465727
[Epoch 11, Batch 900] loss: 0.019828947470814456
[Epoch 11, Batch 1000] loss: 0.014796079620427918
[Epoch 11, Batch 1100] loss: 0.01250375560943212
[Epoch 11, Batch 1200] loss: 0.013915136662526494
[Epoch 11, Batch 1300] loss: 0.00944346345066151
[Epoch 11, Batch 1400] loss: 0.01470303095282361
[Epoch 11, Batch 1500] loss: 0.02287150054223275
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9853
Overfitting: 0.0570
[Epoch 12, Batch 100] loss: 0.014471796137331693
[Epoch 12, Batch 200] loss: 0.014921553546219001
[Epoch 12, Batch 300] loss: 0.009872643269818581
[Epoch 12, Batch 400] loss: 0.007611822446760925
[Epoch 12, Batch 500] loss: 0.010624707712850068
[Epoch 12, Batch 600] loss: 0.01652161148518644
[Epoch 12, Batch 700] loss: 0.012477791426954354
[Epoch 12, Batch 800] loss: 0.01815881862121387
[Epoch 12, Batch 900] loss: 0.012221649925668316
[Epoch 12, Batch 1000] loss: 0.021411205843915013
[Epoch 12, Batch 1100] loss: 0.012257215291629108
[Epoch 12, Batch 1200] loss: 0.01197734928009595
[Epoch 12, Batch 1300] loss: 0.014198854259011568
[Epoch 12, Batch 1400] loss: 0.020090153747914882
[Epoch 12, Batch 1500] loss: 0.012760154119387152
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9863
Overfitting: 0.0512
[Epoch 13, Batch 100] loss: 0.006464027816837188
[Epoch 13, Batch 200] loss: 0.008680626150635362
[Epoch 13, Batch 300] loss: 0.00529863711732105
[Epoch 13, Batch 400] loss: 0.006979171026905533
[Epoch 13, Batch 500] loss: 0.014792688744819316
[Epoch 13, Batch 600] loss: 0.008231089458131464
[Epoch 13, Batch 700] loss: 0.012005442904173833
[Epoch 13, Batch 800] loss: 0.016711599632799334
[Epoch 13, Batch 900] loss: 0.009068291047719867
[Epoch 13, Batch 1000] loss: 0.01479015436755617
[Epoch 13, Batch 1100] loss: 0.017711975807360433
[Epoch 13, Batch 1200] loss: 0.01003780595237913
[Epoch 13, Batch 1300] loss: 0.010473581480500798
[Epoch 13, Batch 1400] loss: 0.008698658870889631
[Epoch 13, Batch 1500] loss: 0.01422371089392982
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9874
Overfitting: 0.0492
[Epoch 14, Batch 100] loss: 0.004897030852125681
[Epoch 14, Batch 200] loss: 0.007727148961839703
[Epoch 14, Batch 300] loss: 0.00874570952335489
[Epoch 14, Batch 400] loss: 0.006409961398949235
[Epoch 14, Batch 500] loss: 0.007167085933706403
[Epoch 14, Batch 600] loss: 0.009385072938912345
[Epoch 14, Batch 700] loss: 0.009242570259630156
[Epoch 14, Batch 800] loss: 0.006146386914797404
[Epoch 14, Batch 900] loss: 0.007751784648235116
[Epoch 14, Batch 1000] loss: 0.006917655120378186
[Epoch 14, Batch 1100] loss: 0.016507679500828088
[Epoch 14, Batch 1200] loss: 0.008285303498378199
[Epoch 14, Batch 1300] loss: 0.011338598271263435
[Epoch 14, Batch 1400] loss: 0.017069454242609937
[Epoch 14, Batch 1500] loss: 0.014984196677160071
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9881
Overfitting: 0.0468
[Epoch 15, Batch 100] loss: 0.010010402373300167
[Epoch 15, Batch 200] loss: 0.008075003729254604
[Epoch 15, Batch 300] loss: 0.006175271991178306
[Epoch 15, Batch 400] loss: 0.006913240300636971
[Epoch 15, Batch 500] loss: 0.004787462609256181
[Epoch 15, Batch 600] loss: 0.011018579965766549
[Epoch 15, Batch 700] loss: 0.017753529247765982
[Epoch 15, Batch 800] loss: 0.012776272578375937
[Epoch 15, Batch 900] loss: 0.009897727225879862
[Epoch 15, Batch 1000] loss: 0.008103421263804193
[Epoch 15, Batch 1100] loss: 0.005246275520676136
[Epoch 15, Batch 1200] loss: 0.012856979079188022
[Epoch 15, Batch 1300] loss: 0.004247408521177931
[Epoch 15, Batch 1400] loss: 0.010227863783575231
[Epoch 15, Batch 1500] loss: 0.006482659286043599
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9879
Overfitting: 0.0508
[Epoch 16, Batch 100] loss: 0.010299117919530545
[Epoch 16, Batch 200] loss: 0.006809520485621761
[Epoch 16, Batch 300] loss: 0.0040939003687935835
[Epoch 16, Batch 400] loss: 0.0030872246166472905
[Epoch 16, Batch 500] loss: 0.0053530526481563355
[Epoch 16, Batch 600] loss: 0.009759979805348849
[Epoch 16, Batch 700] loss: 0.002622603673607955
[Epoch 16, Batch 800] loss: 0.004236531792685128
[Epoch 16, Batch 900] loss: 0.005203969961567054
[Epoch 16, Batch 1000] loss: 0.0054074081098258375
[Epoch 16, Batch 1100] loss: 0.007914924776509907
[Epoch 16, Batch 1200] loss: 0.0028175352709376967
[Epoch 16, Batch 1300] loss: 0.013414365981581682
[Epoch 16, Batch 1400] loss: 0.012000918628955333
[Epoch 16, Batch 1500] loss: 0.008610936619006679
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9878
Overfitting: 0.0511
[Epoch 17, Batch 100] loss: 0.008711906991095475
[Epoch 17, Batch 200] loss: 0.0032694394312784425
[Epoch 17, Batch 300] loss: 0.0036484321284160613
[Epoch 17, Batch 400] loss: 0.00667932083219057
[Epoch 17, Batch 500] loss: 0.0057423807684881464
[Epoch 17, Batch 600] loss: 0.00969540635624071
[Epoch 17, Batch 700] loss: 0.009859283701252934
[Epoch 17, Batch 800] loss: 0.011097810831815878
[Epoch 17, Batch 900] loss: 0.01253262882420131
[Epoch 17, Batch 1000] loss: 0.015470715055780602
[Epoch 17, Batch 1100] loss: 0.01493681791961535
[Epoch 17, Batch 1200] loss: 0.00975031881265977
[Epoch 17, Batch 1300] loss: 0.004813465265915511
[Epoch 17, Batch 1400] loss: 0.011871650627736017
[Epoch 17, Batch 1500] loss: 0.0042263610505051475
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9878
Overfitting: 0.0546
[Epoch 18, Batch 100] loss: 0.005114489524569308
[Epoch 18, Batch 200] loss: 0.011393148571446545
[Epoch 18, Batch 300] loss: 0.008817951424316562
[Epoch 18, Batch 400] loss: 0.006600424396883682
[Epoch 18, Batch 500] loss: 0.00602178436846998
[Epoch 18, Batch 600] loss: 0.006337713383645678
[Epoch 18, Batch 700] loss: 0.0027666183137353075
[Epoch 18, Batch 800] loss: 0.009304590715462382
[Epoch 18, Batch 900] loss: 0.005506990380727075
[Epoch 18, Batch 1000] loss: 0.007115029161479924
[Epoch 18, Batch 1100] loss: 0.006694117231527344
[Epoch 18, Batch 1200] loss: 0.007301020855320531
[Epoch 18, Batch 1300] loss: 0.006228738088277623
[Epoch 18, Batch 1400] loss: 0.0037522948834748603
[Epoch 18, Batch 1500] loss: 0.008260571643343156
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9879
Overfitting: 0.0549
[Epoch 19, Batch 100] loss: 0.008357179036656816
[Epoch 19, Batch 200] loss: 0.005962285627908841
[Epoch 19, Batch 300] loss: 0.003522068097349802
[Epoch 19, Batch 400] loss: 0.00482325061160509
[Epoch 19, Batch 500] loss: 0.00800431584862963
[Epoch 19, Batch 600] loss: 0.007763057109750662
[Epoch 19, Batch 700] loss: 0.006848298702061583
[Epoch 19, Batch 800] loss: 0.007499299896830962
[Epoch 19, Batch 900] loss: 0.002084208819323976
[Epoch 19, Batch 1000] loss: 0.0019043466479013204
[Epoch 19, Batch 1100] loss: 0.003349013609063718
[Epoch 19, Batch 1200] loss: 0.004831409052281685
[Epoch 19, Batch 1300] loss: 0.006249884645253587
[Epoch 19, Batch 1400] loss: 0.007305564928501553
[Epoch 19, Batch 1500] loss: 0.00466862051201133
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0729
Validation Accuracy: 0.9852
Overfitting: 0.0729
[Epoch 20, Batch 100] loss: 0.003585174350125726
[Epoch 20, Batch 200] loss: 0.0022919447548383686
[Epoch 20, Batch 300] loss: 0.002477037507201203
[Epoch 20, Batch 400] loss: 0.004207276890372214
[Epoch 20, Batch 500] loss: 0.002954958607319895
[Epoch 20, Batch 600] loss: 0.0016683644780380292
[Epoch 20, Batch 700] loss: 0.003088283913881469
[Epoch 20, Batch 800] loss: 0.0035017049105363187
[Epoch 20, Batch 900] loss: 0.008562842793707545
[Epoch 20, Batch 1000] loss: 0.004868473574244945
[Epoch 20, Batch 1100] loss: 0.0058887948229039465
[Epoch 20, Batch 1200] loss: 0.006367878177355806
[Epoch 20, Batch 1300] loss: 0.004269000575545761
[Epoch 20, Batch 1400] loss: 0.006992390566561539
[Epoch 20, Batch 1500] loss: 0.007246575773833684
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0631
Validation Accuracy: 0.9869
Overfitting: 0.0631
[Epoch 21, Batch 100] loss: 0.00533599449506255
[Epoch 21, Batch 200] loss: 0.0015260235034588732
[Epoch 21, Batch 300] loss: 0.0010906377875005546
[Epoch 21, Batch 400] loss: 0.0017656481546737268
[Epoch 21, Batch 500] loss: 0.0024825014320887817
[Epoch 21, Batch 600] loss: 0.004577434887937954
[Epoch 21, Batch 700] loss: 0.0028878809041452767
[Epoch 21, Batch 800] loss: 0.002706378332654822
[Epoch 21, Batch 900] loss: 0.0015092517530274562
[Epoch 21, Batch 1000] loss: 0.003059778818181655
[Epoch 21, Batch 1100] loss: 0.00713646586146183
[Epoch 21, Batch 1200] loss: 0.0023180436168968297
[Epoch 21, Batch 1300] loss: 0.0020194027618271803
[Epoch 21, Batch 1400] loss: 0.009568701967953074
[Epoch 21, Batch 1500] loss: 0.004010551941354379
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0575
Validation Accuracy: 0.9882
Overfitting: 0.0575
[Epoch 22, Batch 100] loss: 0.0017193637948616925
[Epoch 22, Batch 200] loss: 0.0019442192237352175
[Epoch 22, Batch 300] loss: 0.0008581254305147467
[Epoch 22, Batch 400] loss: 0.0016706251239557446
[Epoch 22, Batch 500] loss: 0.00140669927988597
[Epoch 22, Batch 600] loss: 0.0021582622076311963
[Epoch 22, Batch 700] loss: 0.0009274915015248553
[Epoch 22, Batch 800] loss: 0.0016275140002761646
[Epoch 22, Batch 900] loss: 0.0026570158762316966
[Epoch 22, Batch 1000] loss: 0.0026246417002425914
[Epoch 22, Batch 1100] loss: 0.001927801334367132
[Epoch 22, Batch 1200] loss: 0.0011111244185440228
[Epoch 22, Batch 1300] loss: 0.0007197591681887161
[Epoch 22, Batch 1400] loss: 0.0015020233919517522
[Epoch 22, Batch 1500] loss: 0.002499049028882325
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0664
Validation Accuracy: 0.9869
Overfitting: 0.0664
[Epoch 23, Batch 100] loss: 0.004260770281533723
[Epoch 23, Batch 200] loss: 0.0027999209197423626
[Epoch 23, Batch 300] loss: 0.0015165612744635836
[Epoch 23, Batch 400] loss: 0.004902234951430273
[Epoch 23, Batch 500] loss: 0.002749072695853556
[Epoch 23, Batch 600] loss: 0.0014739045860896027
[Epoch 23, Batch 700] loss: 0.0006624186865929005
[Epoch 23, Batch 800] loss: 0.0013811328160301174
[Epoch 23, Batch 900] loss: 0.0007601358095209321
[Epoch 23, Batch 1000] loss: 0.001067594147380575
[Epoch 23, Batch 1100] loss: 0.0009721803998814949
[Epoch 23, Batch 1200] loss: 0.0009923502479303181
[Epoch 23, Batch 1300] loss: 0.0022313091332725322
[Epoch 23, Batch 1400] loss: 0.0008300174449308883
[Epoch 23, Batch 1500] loss: 0.0005530508970697667
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0572
Validation Accuracy: 0.9888
Overfitting: 0.0572
[Epoch 24, Batch 100] loss: 0.0017404672245550047
[Epoch 24, Batch 200] loss: 0.0006652745521665793
[Epoch 24, Batch 300] loss: 0.0008260042165659342
[Epoch 24, Batch 400] loss: 0.0005219074777618004
[Epoch 24, Batch 500] loss: 0.0005119069372780415
[Epoch 24, Batch 600] loss: 0.0015816384044103416
[Epoch 24, Batch 700] loss: 0.0004396306780196824
[Epoch 24, Batch 800] loss: 0.0005343253049989017
[Epoch 24, Batch 900] loss: 0.0006988719852890312
[Epoch 24, Batch 1000] loss: 0.00043946532790442914
[Epoch 24, Batch 1100] loss: 0.0008178193008590462
[Epoch 24, Batch 1200] loss: 0.0007999684658767592
[Epoch 24, Batch 1300] loss: 0.001095972884372074
[Epoch 24, Batch 1400] loss: 0.0009605332035081915
[Epoch 24, Batch 1500] loss: 0.0015328956387983795
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9884
Overfitting: 0.0608
Fold 3 validation loss: 0.0608
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2068653881549833
[Epoch 1, Batch 200] loss: 0.940120306611061
[Epoch 1, Batch 300] loss: 0.4156643357127905
[Epoch 1, Batch 400] loss: 0.2915075031667948
[Epoch 1, Batch 500] loss: 0.2266617242246866
[Epoch 1, Batch 600] loss: 0.21394027229398488
[Epoch 1, Batch 700] loss: 0.219081080108881
[Epoch 1, Batch 800] loss: 0.1609109698422253
[Epoch 1, Batch 900] loss: 0.15004825042560696
[Epoch 1, Batch 1000] loss: 0.1582539498806
[Epoch 1, Batch 1100] loss: 0.1412104741577059
[Epoch 1, Batch 1200] loss: 0.1293772784434259
[Epoch 1, Batch 1300] loss: 0.11780440440401435
[Epoch 1, Batch 1400] loss: 0.1193063515610993
[Epoch 1, Batch 1500] loss: 0.10622046680189669
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1072
Validation Accuracy: 0.9666
Overfitting: 0.1072
Best model saved at epoch 1 with validation loss: 0.1072
[Epoch 2, Batch 100] loss: 0.10562002618797123
[Epoch 2, Batch 200] loss: 0.10330342413391919
[Epoch 2, Batch 300] loss: 0.09837787197204306
[Epoch 2, Batch 400] loss: 0.08591989209875464
[Epoch 2, Batch 500] loss: 0.12282168087549508
[Epoch 2, Batch 600] loss: 0.09996903016464785
[Epoch 2, Batch 700] loss: 0.09252499785507098
[Epoch 2, Batch 800] loss: 0.10178524938877671
[Epoch 2, Batch 900] loss: 0.07977255670120939
[Epoch 2, Batch 1000] loss: 0.0638720313529484
[Epoch 2, Batch 1100] loss: 0.08227514610742219
[Epoch 2, Batch 1200] loss: 0.06967600943986327
[Epoch 2, Batch 1300] loss: 0.07801104083890095
[Epoch 2, Batch 1400] loss: 0.08178199661895633
[Epoch 2, Batch 1500] loss: 0.08113219257444143
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0671
Validation Accuracy: 0.9797
Overfitting: 0.0671
Best model saved at epoch 2 with validation loss: 0.0671
[Epoch 3, Batch 100] loss: 0.05714680999459233
[Epoch 3, Batch 200] loss: 0.06191000056220219
[Epoch 3, Batch 300] loss: 0.07199726997525431
[Epoch 3, Batch 400] loss: 0.06480394012876786
[Epoch 3, Batch 500] loss: 0.07322708221152424
[Epoch 3, Batch 600] loss: 0.06316233279881998
[Epoch 3, Batch 700] loss: 0.06587289112154394
[Epoch 3, Batch 800] loss: 0.0609075114375446
[Epoch 3, Batch 900] loss: 0.0729624836758012
[Epoch 3, Batch 1000] loss: 0.051914558944990856
[Epoch 3, Batch 1100] loss: 0.07232611055253074
[Epoch 3, Batch 1200] loss: 0.056874833290930835
[Epoch 3, Batch 1300] loss: 0.06450869465072173
[Epoch 3, Batch 1400] loss: 0.06312686057062819
[Epoch 3, Batch 1500] loss: 0.056727994475513695
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0655
Validation Accuracy: 0.9799
Overfitting: 0.0655
Best model saved at epoch 3 with validation loss: 0.0655
[Epoch 4, Batch 100] loss: 0.04981960764504038
[Epoch 4, Batch 200] loss: 0.05043976412853226
[Epoch 4, Batch 300] loss: 0.04698349566257093
[Epoch 4, Batch 400] loss: 0.04413990700384602
[Epoch 4, Batch 500] loss: 0.057911956619354894
[Epoch 4, Batch 600] loss: 0.04575542281614617
[Epoch 4, Batch 700] loss: 0.06252414616988972
[Epoch 4, Batch 800] loss: 0.05475395276327617
[Epoch 4, Batch 900] loss: 0.04193114430061542
[Epoch 4, Batch 1000] loss: 0.06261821327148936
[Epoch 4, Batch 1100] loss: 0.05097480495576747
[Epoch 4, Batch 1200] loss: 0.04171373677556403
[Epoch 4, Batch 1300] loss: 0.04948518323944882
[Epoch 4, Batch 1400] loss: 0.034437911596032794
[Epoch 4, Batch 1500] loss: 0.050979592215153385
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0607
Validation Accuracy: 0.9812
Overfitting: 0.0607
Best model saved at epoch 4 with validation loss: 0.0607
[Epoch 5, Batch 100] loss: 0.045601024159695955
[Epoch 5, Batch 200] loss: 0.039273774399189276
[Epoch 5, Batch 300] loss: 0.04533285717538092
[Epoch 5, Batch 400] loss: 0.04431167689734138
[Epoch 5, Batch 500] loss: 0.032912052136089186
[Epoch 5, Batch 600] loss: 0.038377915322780606
[Epoch 5, Batch 700] loss: 0.041130012795329095
[Epoch 5, Batch 800] loss: 0.043741707371082156
[Epoch 5, Batch 900] loss: 0.05845173978828825
[Epoch 5, Batch 1000] loss: 0.03793441964080557
[Epoch 5, Batch 1100] loss: 0.04137672822398599
[Epoch 5, Batch 1200] loss: 0.04184879939886741
[Epoch 5, Batch 1300] loss: 0.03376220190461027
[Epoch 5, Batch 1400] loss: 0.03713695558719337
[Epoch 5, Batch 1500] loss: 0.029542321305780207
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0442
Validation Accuracy: 0.9865
Overfitting: 0.0442
Best model saved at epoch 5 with validation loss: 0.0442
[Epoch 6, Batch 100] loss: 0.02594112492603017
[Epoch 6, Batch 200] loss: 0.03434219855436822
[Epoch 6, Batch 300] loss: 0.03359770678711357
[Epoch 6, Batch 400] loss: 0.03601301416987553
[Epoch 6, Batch 500] loss: 0.03060043412959203
[Epoch 6, Batch 600] loss: 0.03331511465454241
[Epoch 6, Batch 700] loss: 0.036648163542558905
[Epoch 6, Batch 800] loss: 0.03567848741993657
[Epoch 6, Batch 900] loss: 0.034766290752158965
[Epoch 6, Batch 1000] loss: 0.033164415652281606
[Epoch 6, Batch 1100] loss: 0.037446437823819
[Epoch 6, Batch 1200] loss: 0.029601246418897064
[Epoch 6, Batch 1300] loss: 0.035975161144742744
[Epoch 6, Batch 1400] loss: 0.03219879254611442
[Epoch 6, Batch 1500] loss: 0.03769647546752822
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9863
Overfitting: 0.0463
[Epoch 7, Batch 100] loss: 0.03577792507421691
[Epoch 7, Batch 200] loss: 0.025796992296236568
[Epoch 7, Batch 300] loss: 0.029793246429471766
[Epoch 7, Batch 400] loss: 0.02804800425510621
[Epoch 7, Batch 500] loss: 0.02850112800413626
[Epoch 7, Batch 600] loss: 0.02793694501684513
[Epoch 7, Batch 700] loss: 0.029599459288001527
[Epoch 7, Batch 800] loss: 0.02167159221586189
[Epoch 7, Batch 900] loss: 0.0220494114595931
[Epoch 7, Batch 1000] loss: 0.028788138222298584
[Epoch 7, Batch 1100] loss: 0.03571246503473958
[Epoch 7, Batch 1200] loss: 0.04256349480128847
[Epoch 7, Batch 1300] loss: 0.03570248604257358
[Epoch 7, Batch 1400] loss: 0.026143482070910978
[Epoch 7, Batch 1500] loss: 0.019171387725073145
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0387
Validation Accuracy: 0.9885
Overfitting: 0.0387
Best model saved at epoch 7 with validation loss: 0.0387
[Epoch 8, Batch 100] loss: 0.021687572085356807
[Epoch 8, Batch 200] loss: 0.0183531383376976
[Epoch 8, Batch 300] loss: 0.018003986739786343
[Epoch 8, Batch 400] loss: 0.018848125694785268
[Epoch 8, Batch 500] loss: 0.02984103530354332
[Epoch 8, Batch 600] loss: 0.018142655500269028
[Epoch 8, Batch 700] loss: 0.019564570778456983
[Epoch 8, Batch 800] loss: 0.03934573834572802
[Epoch 8, Batch 900] loss: 0.022009758303756826
[Epoch 8, Batch 1000] loss: 0.028658222579106222
[Epoch 8, Batch 1100] loss: 0.028088980181637455
[Epoch 8, Batch 1200] loss: 0.02698553805690608
[Epoch 8, Batch 1300] loss: 0.02585631544046919
[Epoch 8, Batch 1400] loss: 0.029783555607064045
[Epoch 8, Batch 1500] loss: 0.022009421113107237
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9874
Overfitting: 0.0430
[Epoch 9, Batch 100] loss: 0.023351981421437813
[Epoch 9, Batch 200] loss: 0.01717043774682679
[Epoch 9, Batch 300] loss: 0.018703380166261923
[Epoch 9, Batch 400] loss: 0.017844980851004947
[Epoch 9, Batch 500] loss: 0.017864041067223297
[Epoch 9, Batch 600] loss: 0.016774872360838345
[Epoch 9, Batch 700] loss: 0.029138780894718365
[Epoch 9, Batch 800] loss: 0.013418200437445193
[Epoch 9, Batch 900] loss: 0.015500281584318145
[Epoch 9, Batch 1000] loss: 0.016996885428670793
[Epoch 9, Batch 1100] loss: 0.02301852150631021
[Epoch 9, Batch 1200] loss: 0.02783007402642397
[Epoch 9, Batch 1300] loss: 0.02407650869135978
[Epoch 9, Batch 1400] loss: 0.03492749234908842
[Epoch 9, Batch 1500] loss: 0.020525550158490658
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9851
Overfitting: 0.0458
[Epoch 10, Batch 100] loss: 0.01276457294181455
[Epoch 10, Batch 200] loss: 0.014995025096031895
[Epoch 10, Batch 300] loss: 0.021523997276453884
[Epoch 10, Batch 400] loss: 0.023334879588801413
[Epoch 10, Batch 500] loss: 0.019911106856743573
[Epoch 10, Batch 600] loss: 0.022390481691691094
[Epoch 10, Batch 700] loss: 0.017464213589119027
[Epoch 10, Batch 800] loss: 0.01628259485703893
[Epoch 10, Batch 900] loss: 0.015483890973628149
[Epoch 10, Batch 1000] loss: 0.01953441352576192
[Epoch 10, Batch 1100] loss: 0.017491639328982275
[Epoch 10, Batch 1200] loss: 0.016640119397634406
[Epoch 10, Batch 1300] loss: 0.01787783768180816
[Epoch 10, Batch 1400] loss: 0.022529334056016523
[Epoch 10, Batch 1500] loss: 0.02050793981165043
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9848
Overfitting: 0.0539
[Epoch 11, Batch 100] loss: 0.013341075890202773
[Epoch 11, Batch 200] loss: 0.025031528189065285
[Epoch 11, Batch 300] loss: 0.010806025101337581
[Epoch 11, Batch 400] loss: 0.0154307752524619
[Epoch 11, Batch 500] loss: 0.020682616650738055
[Epoch 11, Batch 600] loss: 0.012671430061236605
[Epoch 11, Batch 700] loss: 0.008811826338423999
[Epoch 11, Batch 800] loss: 0.013603339469664206
[Epoch 11, Batch 900] loss: 0.023626140049600508
[Epoch 11, Batch 1000] loss: 0.012754734713162179
[Epoch 11, Batch 1100] loss: 0.014127707643419854
[Epoch 11, Batch 1200] loss: 0.015872346663200004
[Epoch 11, Batch 1300] loss: 0.010812618696145365
[Epoch 11, Batch 1400] loss: 0.02538917214355024
[Epoch 11, Batch 1500] loss: 0.014185685232878314
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0401
Validation Accuracy: 0.9889
Overfitting: 0.0401
[Epoch 12, Batch 100] loss: 0.009581566611013842
[Epoch 12, Batch 200] loss: 0.012432918838749174
[Epoch 12, Batch 300] loss: 0.018824773049018403
[Epoch 12, Batch 400] loss: 0.012442034371397313
[Epoch 12, Batch 500] loss: 0.016373872783296974
[Epoch 12, Batch 600] loss: 0.014729546267153637
[Epoch 12, Batch 700] loss: 0.014982491208356805
[Epoch 12, Batch 800] loss: 0.011655329301283927
[Epoch 12, Batch 900] loss: 0.022689432037841472
[Epoch 12, Batch 1000] loss: 0.013194868369773759
[Epoch 12, Batch 1100] loss: 0.010805097658121668
[Epoch 12, Batch 1200] loss: 0.015358801759357448
[Epoch 12, Batch 1300] loss: 0.011932331866810274
[Epoch 12, Batch 1400] loss: 0.012722647996561136
[Epoch 12, Batch 1500] loss: 0.014076246673539572
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0397
Validation Accuracy: 0.9891
Overfitting: 0.0397
[Epoch 13, Batch 100] loss: 0.006920635034912265
[Epoch 13, Batch 200] loss: 0.013498878791833703
[Epoch 13, Batch 300] loss: 0.011896066052104288
[Epoch 13, Batch 400] loss: 0.010871094889771483
[Epoch 13, Batch 500] loss: 0.01430960914311072
[Epoch 13, Batch 600] loss: 0.006580971881876394
[Epoch 13, Batch 700] loss: 0.013876231137874128
[Epoch 13, Batch 800] loss: 0.01429025130066293
[Epoch 13, Batch 900] loss: 0.009273629765375517
[Epoch 13, Batch 1000] loss: 0.00972924447252808
[Epoch 13, Batch 1100] loss: 0.014779605877265567
[Epoch 13, Batch 1200] loss: 0.009563534072367475
[Epoch 13, Batch 1300] loss: 0.01338232225360116
[Epoch 13, Batch 1400] loss: 0.015089465430137353
[Epoch 13, Batch 1500] loss: 0.008769528474213075
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9876
Overfitting: 0.0450
[Epoch 14, Batch 100] loss: 0.006408182513805514
[Epoch 14, Batch 200] loss: 0.007054694129674317
[Epoch 14, Batch 300] loss: 0.0071267512160784465
[Epoch 14, Batch 400] loss: 0.014342148618870851
[Epoch 14, Batch 500] loss: 0.010747122799039062
[Epoch 14, Batch 600] loss: 0.011622254449030152
[Epoch 14, Batch 700] loss: 0.010816301192808169
[Epoch 14, Batch 800] loss: 0.005644208484363844
[Epoch 14, Batch 900] loss: 0.009631717396105159
[Epoch 14, Batch 1000] loss: 0.011853249408950432
[Epoch 14, Batch 1100] loss: 0.01072215992810925
[Epoch 14, Batch 1200] loss: 0.009176270156031023
[Epoch 14, Batch 1300] loss: 0.009532391033853855
[Epoch 14, Batch 1400] loss: 0.009744071293280285
[Epoch 14, Batch 1500] loss: 0.011714526210707845
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9882
Overfitting: 0.0470
[Epoch 15, Batch 100] loss: 0.007892364886165524
[Epoch 15, Batch 200] loss: 0.007723252191135543
[Epoch 15, Batch 300] loss: 0.012220667005203722
[Epoch 15, Batch 400] loss: 0.012094382339018921
[Epoch 15, Batch 500] loss: 0.007674818415589471
[Epoch 15, Batch 600] loss: 0.010431078285901094
[Epoch 15, Batch 700] loss: 0.01395055093898918
[Epoch 15, Batch 800] loss: 0.007159603028349011
[Epoch 15, Batch 900] loss: 0.004992066416903072
[Epoch 15, Batch 1000] loss: 0.011049148680885992
[Epoch 15, Batch 1100] loss: 0.008373701285377138
[Epoch 15, Batch 1200] loss: 0.008240633763412006
[Epoch 15, Batch 1300] loss: 0.0139201609509837
[Epoch 15, Batch 1400] loss: 0.011867465405166512
[Epoch 15, Batch 1500] loss: 0.012430177527503474
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9857
Overfitting: 0.0540
[Epoch 16, Batch 100] loss: 0.008716914323922537
[Epoch 16, Batch 200] loss: 0.004704777351835218
[Epoch 16, Batch 300] loss: 0.007099378577186144
[Epoch 16, Batch 400] loss: 0.0064687623725876615
[Epoch 16, Batch 500] loss: 0.004537986831765011
[Epoch 16, Batch 600] loss: 0.004885331801365283
[Epoch 16, Batch 700] loss: 0.0127693173589887
[Epoch 16, Batch 800] loss: 0.00605009713981417
[Epoch 16, Batch 900] loss: 0.010200876477711063
[Epoch 16, Batch 1000] loss: 0.00805489582017799
[Epoch 16, Batch 1100] loss: 0.008804467735035359
[Epoch 16, Batch 1200] loss: 0.012325088756279001
[Epoch 16, Batch 1300] loss: 0.006339059049196294
[Epoch 16, Batch 1400] loss: 0.0117608100646612
[Epoch 16, Batch 1500] loss: 0.008563277405619374
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9874
Overfitting: 0.0470
[Epoch 17, Batch 100] loss: 0.0050927404587855565
[Epoch 17, Batch 200] loss: 0.00448077805056073
[Epoch 17, Batch 300] loss: 0.003930762211334695
[Epoch 17, Batch 400] loss: 0.004429696620954928
[Epoch 17, Batch 500] loss: 0.0029364183827692613
[Epoch 17, Batch 600] loss: 0.008134597743219275
[Epoch 17, Batch 700] loss: 0.00412190445341821
[Epoch 17, Batch 800] loss: 0.0034393821691628547
[Epoch 17, Batch 900] loss: 0.005563974576218698
[Epoch 17, Batch 1000] loss: 0.006645518690747849
[Epoch 17, Batch 1100] loss: 0.005173447664996047
[Epoch 17, Batch 1200] loss: 0.005959148511187777
[Epoch 17, Batch 1300] loss: 0.013643613095960063
[Epoch 17, Batch 1400] loss: 0.006108918508907664
[Epoch 17, Batch 1500] loss: 0.01688808865303827
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9892
Overfitting: 0.0482
[Epoch 18, Batch 100] loss: 0.009010834884816177
[Epoch 18, Batch 200] loss: 0.006302509720449052
[Epoch 18, Batch 300] loss: 0.004198739518365073
[Epoch 18, Batch 400] loss: 0.007293735784796809
[Epoch 18, Batch 500] loss: 0.004244174932309761
[Epoch 18, Batch 600] loss: 0.002542860366511377
[Epoch 18, Batch 700] loss: 0.0025727741389073343
[Epoch 18, Batch 800] loss: 0.007659478493619645
[Epoch 18, Batch 900] loss: 0.007034572911366012
[Epoch 18, Batch 1000] loss: 0.004173658744421118
[Epoch 18, Batch 1100] loss: 0.00801147636814676
[Epoch 18, Batch 1200] loss: 0.003803865960130679
[Epoch 18, Batch 1300] loss: 0.0056205901761927635
[Epoch 18, Batch 1400] loss: 0.006161136039727353
[Epoch 18, Batch 1500] loss: 0.003262263670003449
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9892
Overfitting: 0.0446
[Epoch 19, Batch 100] loss: 0.0021971874798811086
[Epoch 19, Batch 200] loss: 0.0032103539558647753
[Epoch 19, Batch 300] loss: 0.0009616318338419205
[Epoch 19, Batch 400] loss: 0.001482031805940096
[Epoch 19, Batch 500] loss: 0.001391043941330281
[Epoch 19, Batch 600] loss: 0.001728689910688459
[Epoch 19, Batch 700] loss: 0.0021760699711217057
[Epoch 19, Batch 800] loss: 0.003402664149054999
[Epoch 19, Batch 900] loss: 0.0030058115839392487
[Epoch 19, Batch 1000] loss: 0.00778949228608326
[Epoch 19, Batch 1100] loss: 0.005699703006033019
[Epoch 19, Batch 1200] loss: 0.003899744348548211
[Epoch 19, Batch 1300] loss: 0.0038422647172774303
[Epoch 19, Batch 1400] loss: 0.004469220646109306
[Epoch 19, Batch 1500] loss: 0.008172593418689757
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9870
Overfitting: 0.0593
[Epoch 20, Batch 100] loss: 0.009408314024117317
[Epoch 20, Batch 200] loss: 0.005540722212542732
[Epoch 20, Batch 300] loss: 0.0043208382436648665
[Epoch 20, Batch 400] loss: 0.005400897689401063
[Epoch 20, Batch 500] loss: 0.004829520679239749
[Epoch 20, Batch 600] loss: 0.007906935842411257
[Epoch 20, Batch 700] loss: 0.0035456379242123147
[Epoch 20, Batch 800] loss: 0.0048154221220011095
[Epoch 20, Batch 900] loss: 0.0022491347992507826
[Epoch 20, Batch 1000] loss: 0.007951571147104914
[Epoch 20, Batch 1100] loss: 0.006460286852147874
[Epoch 20, Batch 1200] loss: 0.007141106047582752
[Epoch 20, Batch 1300] loss: 0.003383064790605772
[Epoch 20, Batch 1400] loss: 0.006141365991135786
[Epoch 20, Batch 1500] loss: 0.009997992191420052
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0572
Validation Accuracy: 0.9867
Overfitting: 0.0572
[Epoch 21, Batch 100] loss: 0.004538036418115326
[Epoch 21, Batch 200] loss: 0.0014727146269763124
[Epoch 21, Batch 300] loss: 0.0025221226489327364
[Epoch 21, Batch 400] loss: 0.002520317482992596
[Epoch 21, Batch 500] loss: 0.008619415769376247
[Epoch 21, Batch 600] loss: 0.00755618152099828
[Epoch 21, Batch 700] loss: 0.007148114659471503
[Epoch 21, Batch 800] loss: 0.0025390427607271705
[Epoch 21, Batch 900] loss: 0.01376638643355136
[Epoch 21, Batch 1000] loss: 0.006444170832226064
[Epoch 21, Batch 1100] loss: 0.002630170094666937
[Epoch 21, Batch 1200] loss: 0.004535868701561867
[Epoch 21, Batch 1300] loss: 0.002599582757613348
[Epoch 21, Batch 1400] loss: 0.0020573710568032766
[Epoch 21, Batch 1500] loss: 0.002423650196099061
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9886
Overfitting: 0.0478
[Epoch 22, Batch 100] loss: 0.003127829056055589
[Epoch 22, Batch 200] loss: 0.004709843231582908
[Epoch 22, Batch 300] loss: 0.0018324035052933142
[Epoch 22, Batch 400] loss: 0.002966889385842251
[Epoch 22, Batch 500] loss: 0.0024980271564221824
[Epoch 22, Batch 600] loss: 0.0016585792140381272
[Epoch 22, Batch 700] loss: 0.0017082236632666081
[Epoch 22, Batch 800] loss: 0.00210106646404995
[Epoch 22, Batch 900] loss: 0.001612545539098278
[Epoch 22, Batch 1000] loss: 0.0016968375500323418
[Epoch 22, Batch 1100] loss: 0.005279540779077933
[Epoch 22, Batch 1200] loss: 0.009319572810311457
[Epoch 22, Batch 1300] loss: 0.0043444902430064755
[Epoch 22, Batch 1400] loss: 0.006868525880797734
[Epoch 22, Batch 1500] loss: 0.0022185052229099257
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9888
Overfitting: 0.0499
[Epoch 23, Batch 100] loss: 0.003550987388427984
[Epoch 23, Batch 200] loss: 0.004628189799477695
[Epoch 23, Batch 300] loss: 0.0015517376899600777
[Epoch 23, Batch 400] loss: 0.0020579806512887443
[Epoch 23, Batch 500] loss: 0.005699599120707717
[Epoch 23, Batch 600] loss: 0.004287178546601211
[Epoch 23, Batch 700] loss: 0.004657567430157315
[Epoch 23, Batch 800] loss: 0.0031116053158041267
[Epoch 23, Batch 900] loss: 0.00400755176215057
[Epoch 23, Batch 1000] loss: 0.004339878896491669
[Epoch 23, Batch 1100] loss: 0.002908023351672
[Epoch 23, Batch 1200] loss: 0.0022156990053963455
[Epoch 23, Batch 1300] loss: 0.0022252877925822644
[Epoch 23, Batch 1400] loss: 0.005393064918784489
[Epoch 23, Batch 1500] loss: 0.014817257411700667
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0679
Validation Accuracy: 0.9833
Overfitting: 0.0679
[Epoch 24, Batch 100] loss: 0.0037425965630291103
[Epoch 24, Batch 200] loss: 0.006022201948717339
[Epoch 24, Batch 300] loss: 0.004231424932977461
[Epoch 24, Batch 400] loss: 0.0033932024165937947
[Epoch 24, Batch 500] loss: 0.0018659406259644129
[Epoch 24, Batch 600] loss: 0.001507711260657345
[Epoch 24, Batch 700] loss: 0.0022715563137732887
[Epoch 24, Batch 800] loss: 0.0020211822866468766
[Epoch 24, Batch 900] loss: 0.001105527360563201
[Epoch 24, Batch 1000] loss: 0.0026376210755694983
[Epoch 24, Batch 1100] loss: 0.0023400225213754313
[Epoch 24, Batch 1200] loss: 0.0036619762116572472
[Epoch 24, Batch 1300] loss: 0.009631072878557917
[Epoch 24, Batch 1400] loss: 0.008144703120294708
[Epoch 24, Batch 1500] loss: 0.00626404300378681
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9887
Overfitting: 0.0492
Fold 4 validation loss: 0.0492
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2758981370925904
[Epoch 1, Batch 200] loss: 1.5055054047703742
[Epoch 1, Batch 300] loss: 0.5433056050539017
[Epoch 1, Batch 400] loss: 0.3714405372738838
[Epoch 1, Batch 500] loss: 0.3123107672482729
[Epoch 1, Batch 600] loss: 0.24574722338467836
[Epoch 1, Batch 700] loss: 0.23594749614596366
[Epoch 1, Batch 800] loss: 0.2034024193510413
[Epoch 1, Batch 900] loss: 0.16088767250999808
[Epoch 1, Batch 1000] loss: 0.1550614928267896
[Epoch 1, Batch 1100] loss: 0.13771845430135726
[Epoch 1, Batch 1200] loss: 0.16018478277139367
[Epoch 1, Batch 1300] loss: 0.12382876826450229
[Epoch 1, Batch 1400] loss: 0.14182433303445577
[Epoch 1, Batch 1500] loss: 0.1365134050231427
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1320
Validation Accuracy: 0.9614
Overfitting: 0.1320
Best model saved at epoch 1 with validation loss: 0.1320
[Epoch 2, Batch 100] loss: 0.11085574623662979
[Epoch 2, Batch 200] loss: 0.10195887139998376
[Epoch 2, Batch 300] loss: 0.10202734743244946
[Epoch 2, Batch 400] loss: 0.0861422212049365
[Epoch 2, Batch 500] loss: 0.09912760300212539
[Epoch 2, Batch 600] loss: 0.08666275203227997
[Epoch 2, Batch 700] loss: 0.09826795440167188
[Epoch 2, Batch 800] loss: 0.0983519883453846
[Epoch 2, Batch 900] loss: 0.09539722051937133
[Epoch 2, Batch 1000] loss: 0.09930510236648843
[Epoch 2, Batch 1100] loss: 0.09790154447313398
[Epoch 2, Batch 1200] loss: 0.07196715510624926
[Epoch 2, Batch 1300] loss: 0.07986783281667158
[Epoch 2, Batch 1400] loss: 0.08137950663571246
[Epoch 2, Batch 1500] loss: 0.07830529794329777
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9797
Overfitting: 0.0665
Best model saved at epoch 2 with validation loss: 0.0665
[Epoch 3, Batch 100] loss: 0.06653337867930531
[Epoch 3, Batch 200] loss: 0.08338542947312817
[Epoch 3, Batch 300] loss: 0.06627989046275616
[Epoch 3, Batch 400] loss: 0.06190436337376013
[Epoch 3, Batch 500] loss: 0.06370583006180823
[Epoch 3, Batch 600] loss: 0.051380728804506365
[Epoch 3, Batch 700] loss: 0.0678638050891459
[Epoch 3, Batch 800] loss: 0.05211065139155835
[Epoch 3, Batch 900] loss: 0.05068333218048792
[Epoch 3, Batch 1000] loss: 0.06508272722596303
[Epoch 3, Batch 1100] loss: 0.07953399919904769
[Epoch 3, Batch 1200] loss: 0.060200996149796994
[Epoch 3, Batch 1300] loss: 0.0699242969241459
[Epoch 3, Batch 1400] loss: 0.06283009535167366
[Epoch 3, Batch 1500] loss: 0.07557169896317646
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0671
Validation Accuracy: 0.9802
Overfitting: 0.0671
[Epoch 4, Batch 100] loss: 0.047754414548398925
[Epoch 4, Batch 200] loss: 0.04676329384557903
[Epoch 4, Batch 300] loss: 0.03550968902185559
[Epoch 4, Batch 400] loss: 0.06823489990201778
[Epoch 4, Batch 500] loss: 0.05165494700486306
[Epoch 4, Batch 600] loss: 0.04915172166307457
[Epoch 4, Batch 700] loss: 0.053101096831960605
[Epoch 4, Batch 800] loss: 0.06040408698609099
[Epoch 4, Batch 900] loss: 0.043123446116806005
[Epoch 4, Batch 1000] loss: 0.0533894955489086
[Epoch 4, Batch 1100] loss: 0.054919611536315645
[Epoch 4, Batch 1200] loss: 0.05653374620247632
[Epoch 4, Batch 1300] loss: 0.056581054717535155
[Epoch 4, Batch 1400] loss: 0.04075170308642555
[Epoch 4, Batch 1500] loss: 0.05436542499170173
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9840
Overfitting: 0.0504
Best model saved at epoch 4 with validation loss: 0.0504
[Epoch 5, Batch 100] loss: 0.0330411280982662
[Epoch 5, Batch 200] loss: 0.043884375074412674
[Epoch 5, Batch 300] loss: 0.03703630620555486
[Epoch 5, Batch 400] loss: 0.04138605032698251
[Epoch 5, Batch 500] loss: 0.0479966947203502
[Epoch 5, Batch 600] loss: 0.04760894919978455
[Epoch 5, Batch 700] loss: 0.04011494510341436
[Epoch 5, Batch 800] loss: 0.04434015431674197
[Epoch 5, Batch 900] loss: 0.0469445501093287
[Epoch 5, Batch 1000] loss: 0.036407063305669
[Epoch 5, Batch 1100] loss: 0.04066178835579194
[Epoch 5, Batch 1200] loss: 0.04302281951881014
[Epoch 5, Batch 1300] loss: 0.036028338162868746
[Epoch 5, Batch 1400] loss: 0.04709335325402208
[Epoch 5, Batch 1500] loss: 0.0398271966422908
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9835
Overfitting: 0.0534
[Epoch 6, Batch 100] loss: 0.027956765571434516
[Epoch 6, Batch 200] loss: 0.03439151449623751
[Epoch 6, Batch 300] loss: 0.033686581720830874
[Epoch 6, Batch 400] loss: 0.03903693105618004
[Epoch 6, Batch 500] loss: 0.035200673263752834
[Epoch 6, Batch 600] loss: 0.030196878786955494
[Epoch 6, Batch 700] loss: 0.03239564173942199
[Epoch 6, Batch 800] loss: 0.0438296441762941
[Epoch 6, Batch 900] loss: 0.026680514676263554
[Epoch 6, Batch 1000] loss: 0.03485425707302056
[Epoch 6, Batch 1100] loss: 0.03572769623657223
[Epoch 6, Batch 1200] loss: 0.03777648540446535
[Epoch 6, Batch 1300] loss: 0.03166031293978449
[Epoch 6, Batch 1400] loss: 0.029103843250486535
[Epoch 6, Batch 1500] loss: 0.04790542812261265
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0553
Validation Accuracy: 0.9832
Overfitting: 0.0553
[Epoch 7, Batch 100] loss: 0.029162804378429427
[Epoch 7, Batch 200] loss: 0.023635485284903553
[Epoch 7, Batch 300] loss: 0.02349500578493462
[Epoch 7, Batch 400] loss: 0.035575450508040375
[Epoch 7, Batch 500] loss: 0.031130212879215833
[Epoch 7, Batch 600] loss: 0.032370400213549144
[Epoch 7, Batch 700] loss: 0.02457363456982421
[Epoch 7, Batch 800] loss: 0.03929927543009398
[Epoch 7, Batch 900] loss: 0.03550267048703972
[Epoch 7, Batch 1000] loss: 0.020009753578779054
[Epoch 7, Batch 1100] loss: 0.03216288709343644
[Epoch 7, Batch 1200] loss: 0.03002380983234616
[Epoch 7, Batch 1300] loss: 0.03807184035482351
[Epoch 7, Batch 1400] loss: 0.040793266523978675
[Epoch 7, Batch 1500] loss: 0.04161875268793665
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9845
Overfitting: 0.0523
[Epoch 8, Batch 100] loss: 0.02104387780454999
[Epoch 8, Batch 200] loss: 0.020411792221275392
[Epoch 8, Batch 300] loss: 0.01866683618653042
[Epoch 8, Batch 400] loss: 0.02851147666668112
[Epoch 8, Batch 500] loss: 0.031986556970805394
[Epoch 8, Batch 600] loss: 0.02400075900310185
[Epoch 8, Batch 700] loss: 0.01731878876904375
[Epoch 8, Batch 800] loss: 0.026710145885299425
[Epoch 8, Batch 900] loss: 0.023333222085784654
[Epoch 8, Batch 1000] loss: 0.018961308520374587
[Epoch 8, Batch 1100] loss: 0.024323771797207884
[Epoch 8, Batch 1200] loss: 0.03621320436010137
[Epoch 8, Batch 1300] loss: 0.031778081704396756
[Epoch 8, Batch 1400] loss: 0.027767031180264894
[Epoch 8, Batch 1500] loss: 0.03147669195488561
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9847
Overfitting: 0.0510
[Epoch 9, Batch 100] loss: 0.025312797786755256
[Epoch 9, Batch 200] loss: 0.020315229725965764
[Epoch 9, Batch 300] loss: 0.02010229263047222
[Epoch 9, Batch 400] loss: 0.015443858964863466
[Epoch 9, Batch 500] loss: 0.017624700853411925
[Epoch 9, Batch 600] loss: 0.01979152640502434
[Epoch 9, Batch 700] loss: 0.013017139446310467
[Epoch 9, Batch 800] loss: 0.018032209418088314
[Epoch 9, Batch 900] loss: 0.027172978731468903
[Epoch 9, Batch 1000] loss: 0.025587745905068005
[Epoch 9, Batch 1100] loss: 0.023910674684593687
[Epoch 9, Batch 1200] loss: 0.024283780410260077
[Epoch 9, Batch 1300] loss: 0.021935617364069914
[Epoch 9, Batch 1400] loss: 0.02434458762218128
[Epoch 9, Batch 1500] loss: 0.017621589404952828
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0400
Validation Accuracy: 0.9886
Overfitting: 0.0400
Best model saved at epoch 9 with validation loss: 0.0400
[Epoch 10, Batch 100] loss: 0.010714427587226965
[Epoch 10, Batch 200] loss: 0.020144558075771785
[Epoch 10, Batch 300] loss: 0.012270853811569395
[Epoch 10, Batch 400] loss: 0.021497513347494532
[Epoch 10, Batch 500] loss: 0.013217578328331002
[Epoch 10, Batch 600] loss: 0.02428874503226325
[Epoch 10, Batch 700] loss: 0.027465830661221845
[Epoch 10, Batch 800] loss: 0.025427538699841535
[Epoch 10, Batch 900] loss: 0.019416304174956166
[Epoch 10, Batch 1000] loss: 0.017178421375283505
[Epoch 10, Batch 1100] loss: 0.025607133945886745
[Epoch 10, Batch 1200] loss: 0.019742301020596643
[Epoch 10, Batch 1300] loss: 0.022512902023445348
[Epoch 10, Batch 1400] loss: 0.01699846005460131
[Epoch 10, Batch 1500] loss: 0.021446463499814855
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9858
Overfitting: 0.0515
[Epoch 11, Batch 100] loss: 0.01389945866078051
[Epoch 11, Batch 200] loss: 0.01897048467908462
[Epoch 11, Batch 300] loss: 0.018084219161864895
[Epoch 11, Batch 400] loss: 0.01709894200474082
[Epoch 11, Batch 500] loss: 0.015076188067469047
[Epoch 11, Batch 600] loss: 0.013693437752808678
[Epoch 11, Batch 700] loss: 0.010586455380180269
[Epoch 11, Batch 800] loss: 0.015284763131348881
[Epoch 11, Batch 900] loss: 0.02010924009155133
[Epoch 11, Batch 1000] loss: 0.021883357131519007
[Epoch 11, Batch 1100] loss: 0.016330836884953896
[Epoch 11, Batch 1200] loss: 0.02056707696763624
[Epoch 11, Batch 1300] loss: 0.018109146077767944
[Epoch 11, Batch 1400] loss: 0.013999952823651256
[Epoch 11, Batch 1500] loss: 0.01837552807497559
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0517
Validation Accuracy: 0.9858
Overfitting: 0.0517
[Epoch 12, Batch 100] loss: 0.01480197385630163
[Epoch 12, Batch 200] loss: 0.008317159719626942
[Epoch 12, Batch 300] loss: 0.01180815649779106
[Epoch 12, Batch 400] loss: 0.013507975796383107
[Epoch 12, Batch 500] loss: 0.017240581387577548
[Epoch 12, Batch 600] loss: 0.0137001500984843
[Epoch 12, Batch 700] loss: 0.015031219644279191
[Epoch 12, Batch 800] loss: 0.014369326102678315
[Epoch 12, Batch 900] loss: 0.013994727609606343
[Epoch 12, Batch 1000] loss: 0.010802649930283223
[Epoch 12, Batch 1100] loss: 0.024392630337388255
[Epoch 12, Batch 1200] loss: 0.018781040762914928
[Epoch 12, Batch 1300] loss: 0.026827561817226522
[Epoch 12, Batch 1400] loss: 0.029882626032922417
[Epoch 12, Batch 1500] loss: 0.017451894774858374
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9872
Overfitting: 0.0470
[Epoch 13, Batch 100] loss: 0.012114085758712463
[Epoch 13, Batch 200] loss: 0.009830438150875125
[Epoch 13, Batch 300] loss: 0.011724176933639682
[Epoch 13, Batch 400] loss: 0.01431283608872036
[Epoch 13, Batch 500] loss: 0.011256362828844431
[Epoch 13, Batch 600] loss: 0.012309198872262641
[Epoch 13, Batch 700] loss: 0.006788024416109693
[Epoch 13, Batch 800] loss: 0.014305546950927237
[Epoch 13, Batch 900] loss: 0.013536745798301126
[Epoch 13, Batch 1000] loss: 0.017656761005819133
[Epoch 13, Batch 1100] loss: 0.01745419845734432
[Epoch 13, Batch 1200] loss: 0.008783718133254298
[Epoch 13, Batch 1300] loss: 0.013433487867732765
[Epoch 13, Batch 1400] loss: 0.013288456564114313
[Epoch 13, Batch 1500] loss: 0.01782563108157774
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0411
Validation Accuracy: 0.9888
Overfitting: 0.0411
[Epoch 14, Batch 100] loss: 0.007002034012475633
[Epoch 14, Batch 200] loss: 0.005216705671555247
[Epoch 14, Batch 300] loss: 0.007903799816585889
[Epoch 14, Batch 400] loss: 0.01115800403204048
[Epoch 14, Batch 500] loss: 0.016019410446515395
[Epoch 14, Batch 600] loss: 0.010620763547949537
[Epoch 14, Batch 700] loss: 0.010878234158208216
[Epoch 14, Batch 800] loss: 0.013356841593113131
[Epoch 14, Batch 900] loss: 0.022967401629957748
[Epoch 14, Batch 1000] loss: 0.010317353640689362
[Epoch 14, Batch 1100] loss: 0.010264762893020815
[Epoch 14, Batch 1200] loss: 0.014803573699027765
[Epoch 14, Batch 1300] loss: 0.012544707338456647
[Epoch 14, Batch 1400] loss: 0.012526512666445342
[Epoch 14, Batch 1500] loss: 0.0105544043430109
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9887
Overfitting: 0.0422
[Epoch 15, Batch 100] loss: 0.011353668731189828
[Epoch 15, Batch 200] loss: 0.009765586471130518
[Epoch 15, Batch 300] loss: 0.007734450645675679
[Epoch 15, Batch 400] loss: 0.01698881105403416
[Epoch 15, Batch 500] loss: 0.009333554667282442
[Epoch 15, Batch 600] loss: 0.010826948759895458
[Epoch 15, Batch 700] loss: 0.00950273778398696
[Epoch 15, Batch 800] loss: 0.010282314176693034
[Epoch 15, Batch 900] loss: 0.010359131681425424
[Epoch 15, Batch 1000] loss: 0.011420673895054278
[Epoch 15, Batch 1100] loss: 0.00804809094463053
[Epoch 15, Batch 1200] loss: 0.011499442925805852
[Epoch 15, Batch 1300] loss: 0.009342606874124613
[Epoch 15, Batch 1400] loss: 0.008482654938525229
[Epoch 15, Batch 1500] loss: 0.010248432336320548
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9871
Overfitting: 0.0477
[Epoch 16, Batch 100] loss: 0.004237723948835992
[Epoch 16, Batch 200] loss: 0.005241247041442421
[Epoch 16, Batch 300] loss: 0.005774954786647868
[Epoch 16, Batch 400] loss: 0.00471342114385152
[Epoch 16, Batch 500] loss: 0.004565880024238141
[Epoch 16, Batch 600] loss: 0.006792039302554258
[Epoch 16, Batch 700] loss: 0.010731799249424512
[Epoch 16, Batch 800] loss: 0.008122418005641521
[Epoch 16, Batch 900] loss: 0.004899777334903774
[Epoch 16, Batch 1000] loss: 0.009833529720799561
[Epoch 16, Batch 1100] loss: 0.005459993387830764
[Epoch 16, Batch 1200] loss: 0.0118912138221458
[Epoch 16, Batch 1300] loss: 0.007052591321626096
[Epoch 16, Batch 1400] loss: 0.013421074167681582
[Epoch 16, Batch 1500] loss: 0.014503168800729327
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9852
Overfitting: 0.0534
[Epoch 17, Batch 100] loss: 0.008871113740351575
[Epoch 17, Batch 200] loss: 0.004342133739482961
[Epoch 17, Batch 300] loss: 0.0059178381315541624
[Epoch 17, Batch 400] loss: 0.005814007847511675
[Epoch 17, Batch 500] loss: 0.003015788648608577
[Epoch 17, Batch 600] loss: 0.004330051168039972
[Epoch 17, Batch 700] loss: 0.004143113366214948
[Epoch 17, Batch 800] loss: 0.005502314316831871
[Epoch 17, Batch 900] loss: 0.007595161894869307
[Epoch 17, Batch 1000] loss: 0.008696510458275953
[Epoch 17, Batch 1100] loss: 0.008949229914733223
[Epoch 17, Batch 1200] loss: 0.01161848364123216
[Epoch 17, Batch 1300] loss: 0.007699221662314812
[Epoch 17, Batch 1400] loss: 0.005556900247953535
[Epoch 17, Batch 1500] loss: 0.009893780389588755
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9879
Overfitting: 0.0505
[Epoch 18, Batch 100] loss: 0.006043358846195588
[Epoch 18, Batch 200] loss: 0.006497252971648777
[Epoch 18, Batch 300] loss: 0.00566159219471956
[Epoch 18, Batch 400] loss: 0.004122048260076099
[Epoch 18, Batch 500] loss: 0.005624418480892928
[Epoch 18, Batch 600] loss: 0.00793671735802036
[Epoch 18, Batch 700] loss: 0.0038247284567864883
[Epoch 18, Batch 800] loss: 0.007331330519587027
[Epoch 18, Batch 900] loss: 0.004529478520189514
[Epoch 18, Batch 1000] loss: 0.0026248867185518065
[Epoch 18, Batch 1100] loss: 0.005330923524535364
[Epoch 18, Batch 1200] loss: 0.006663816964214675
[Epoch 18, Batch 1300] loss: 0.015520926553435857
[Epoch 18, Batch 1400] loss: 0.008249353078344939
[Epoch 18, Batch 1500] loss: 0.00617283491436865
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9888
Overfitting: 0.0509
[Epoch 19, Batch 100] loss: 0.003926086372403006
[Epoch 19, Batch 200] loss: 0.00550722854037133
[Epoch 19, Batch 300] loss: 0.013988572973348141
[Epoch 19, Batch 400] loss: 0.007776239449185596
[Epoch 19, Batch 500] loss: 0.007040221978350018
[Epoch 19, Batch 600] loss: 0.011703135113289137
[Epoch 19, Batch 700] loss: 0.009507423280801959
[Epoch 19, Batch 800] loss: 0.008739207500220801
[Epoch 19, Batch 900] loss: 0.007631047989962099
[Epoch 19, Batch 1000] loss: 0.004729374543710491
[Epoch 19, Batch 1100] loss: 0.010372636942420285
[Epoch 19, Batch 1200] loss: 0.007253233937681216
[Epoch 19, Batch 1300] loss: 0.007278771654955563
[Epoch 19, Batch 1400] loss: 0.008838301536270592
[Epoch 19, Batch 1500] loss: 0.004166228967089864
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9881
Overfitting: 0.0496
[Epoch 20, Batch 100] loss: 0.0024425221705223522
[Epoch 20, Batch 200] loss: 0.0033368377035185403
[Epoch 20, Batch 300] loss: 0.009723983507838057
[Epoch 20, Batch 400] loss: 0.006235545383902945
[Epoch 20, Batch 500] loss: 0.007254362917956314
[Epoch 20, Batch 600] loss: 0.004521269954798299
[Epoch 20, Batch 700] loss: 0.002372906538312236
[Epoch 20, Batch 800] loss: 0.008658044625417461
[Epoch 20, Batch 900] loss: 0.002134446550674056
[Epoch 20, Batch 1000] loss: 0.0030052967748088123
[Epoch 20, Batch 1100] loss: 0.0035293589029515714
[Epoch 20, Batch 1200] loss: 0.00272047374024055
[Epoch 20, Batch 1300] loss: 0.008822538415423652
[Epoch 20, Batch 1400] loss: 0.002691687237365841
[Epoch 20, Batch 1500] loss: 0.005402613151859441
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9883
Overfitting: 0.0485
[Epoch 21, Batch 100] loss: 0.002851234209890663
[Epoch 21, Batch 200] loss: 0.003394139162660963
[Epoch 21, Batch 300] loss: 0.0019135735974828093
[Epoch 21, Batch 400] loss: 0.0025865746379918164
[Epoch 21, Batch 500] loss: 0.001888832397258966
[Epoch 21, Batch 600] loss: 0.001334816311182294
[Epoch 21, Batch 700] loss: 0.0027365401099280007
[Epoch 21, Batch 800] loss: 0.005793314198596704
[Epoch 21, Batch 900] loss: 0.00491444641572798
[Epoch 21, Batch 1000] loss: 0.008485011142947769
[Epoch 21, Batch 1100] loss: 0.006731452819985861
[Epoch 21, Batch 1200] loss: 0.006567839819779237
[Epoch 21, Batch 1300] loss: 0.012024352961921067
[Epoch 21, Batch 1400] loss: 0.012516544505522233
[Epoch 21, Batch 1500] loss: 0.005934182166647588
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9887
Overfitting: 0.0483
[Epoch 22, Batch 100] loss: 0.002217680831005282
[Epoch 22, Batch 200] loss: 0.001172270273700633
[Epoch 22, Batch 300] loss: 0.004741057237923769
[Epoch 22, Batch 400] loss: 0.011548138456801098
[Epoch 22, Batch 500] loss: 0.006127030132906839
[Epoch 22, Batch 600] loss: 0.005124324013195292
[Epoch 22, Batch 700] loss: 0.004434064233610115
[Epoch 22, Batch 800] loss: 0.004509172477031598
[Epoch 22, Batch 900] loss: 0.0035058923962878906
[Epoch 22, Batch 1000] loss: 0.0026640650792455743
[Epoch 22, Batch 1100] loss: 0.0016121407404881439
[Epoch 22, Batch 1200] loss: 0.004001421111745458
[Epoch 22, Batch 1300] loss: 0.001963217206129002
[Epoch 22, Batch 1400] loss: 0.001777011754885507
[Epoch 22, Batch 1500] loss: 0.004866168454246918
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9884
Overfitting: 0.0533
[Epoch 23, Batch 100] loss: 0.005946234934012864
[Epoch 23, Batch 200] loss: 0.0029312917082734203
[Epoch 23, Batch 300] loss: 0.002661437734014953
[Epoch 23, Batch 400] loss: 0.004393404012929523
[Epoch 23, Batch 500] loss: 0.005731791604905539
[Epoch 23, Batch 600] loss: 0.0033743850238624872
[Epoch 23, Batch 700] loss: 0.0029886617593501796
[Epoch 23, Batch 800] loss: 0.007360621526447631
[Epoch 23, Batch 900] loss: 0.003011018354318935
[Epoch 23, Batch 1000] loss: 0.0028291828710200664
[Epoch 23, Batch 1100] loss: 0.0023238308804877763
[Epoch 23, Batch 1200] loss: 0.002510734402280832
[Epoch 23, Batch 1300] loss: 0.005666168826102762
[Epoch 23, Batch 1400] loss: 0.00440635327913185
[Epoch 23, Batch 1500] loss: 0.001565737260800688
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9896
Overfitting: 0.0472
[Epoch 24, Batch 100] loss: 0.0019416616688420164
[Epoch 24, Batch 200] loss: 0.002017539654848406
[Epoch 24, Batch 300] loss: 0.004972798304758044
[Epoch 24, Batch 400] loss: 0.003602398887159097
[Epoch 24, Batch 500] loss: 0.003114513259032492
[Epoch 24, Batch 600] loss: 0.0025065933227710955
[Epoch 24, Batch 700] loss: 0.002262180113305021
[Epoch 24, Batch 800] loss: 0.0018328815871706183
[Epoch 24, Batch 900] loss: 0.0008781864180491539
[Epoch 24, Batch 1000] loss: 0.0019390096841320314
[Epoch 24, Batch 1100] loss: 0.0008297146161606861
[Epoch 24, Batch 1200] loss: 0.0007941434343968013
[Epoch 24, Batch 1300] loss: 0.0009089307135650415
[Epoch 24, Batch 1400] loss: 0.0011636714696331297
[Epoch 24, Batch 1500] loss: 0.00155638745935903
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9893
Overfitting: 0.0492
Fold 5 validation loss: 0.0492
Mean validation loss across all folds for Trial 8 is 0.0538 with trial config:  l1: 128, l2: 128, lr: 0.002592475660475161, batch_size: 32
[I 2024-12-11 03:13:52,017] Trial 7 finished with value: 0.05382610358479013 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.002592475660475161, 'batch_size': 32}. Best is trial 2 with value: 0.05047263894358398.

Selected Hyperparameters for Trial 9:
  l1: 128, l2: 128, lr: 0.00016867164929354415, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.307184247970581
[Epoch 1, Batch 200] loss: 2.3039202642440797
[Epoch 1, Batch 300] loss: 2.302542276382446
[Epoch 1, Batch 400] loss: 2.300139172077179
[Epoch 1, Batch 500] loss: 2.2983613848686217
[Epoch 1, Batch 600] loss: 2.2955234098434447
[Epoch 1, Batch 700] loss: 2.2916200160980225
[Epoch 1, Batch 800] loss: 2.2900181436538696
[Epoch 1, Batch 900] loss: 2.2857821083068846
[Epoch 1, Batch 1000] loss: 2.2824955558776856
[Epoch 1, Batch 1100] loss: 2.2778461837768553
[Epoch 1, Batch 1200] loss: 2.273092362880707
[Epoch 1, Batch 1300] loss: 2.267263238430023
[Epoch 1, Batch 1400] loss: 2.259238123893738
[Epoch 1, Batch 1500] loss: 2.2490758657455445
[Epoch 1, Batch 1600] loss: 2.233925232887268
[Epoch 1, Batch 1700] loss: 2.218578245639801
[Epoch 1, Batch 1800] loss: 2.1965703701972963
[Epoch 1, Batch 1900] loss: 2.165500421524048
[Epoch 1, Batch 2000] loss: 2.1295851182937624
[Epoch 1, Batch 2100] loss: 2.0629113495349882
[Epoch 1, Batch 2200] loss: 1.9523285806179047
[Epoch 1, Batch 2300] loss: 1.7855584251880645
[Epoch 1, Batch 2400] loss: 1.5590897500514984
[Epoch 1, Batch 2500] loss: 1.3113797503709792
[Epoch 1, Batch 2600] loss: 1.0686966168880463
[Epoch 1, Batch 2700] loss: 0.8821965366601944
[Epoch 1, Batch 2800] loss: 0.8007059359550476
[Epoch 1, Batch 2900] loss: 0.7238749146461487
[Epoch 1, Batch 3000] loss: 0.6307079768180848
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.6032
Validation Accuracy: 0.8153
Overfitting: 0.6032
Best model saved at epoch 1 with validation loss: 0.6032
[Epoch 2, Batch 100] loss: 0.6017520043253899
[Epoch 2, Batch 200] loss: 0.5582507391273975
[Epoch 2, Batch 300] loss: 0.5154469066858292
[Epoch 2, Batch 400] loss: 0.5337991589307785
[Epoch 2, Batch 500] loss: 0.4742327965795994
[Epoch 2, Batch 600] loss: 0.4991830837726593
[Epoch 2, Batch 700] loss: 0.4878574785590172
[Epoch 2, Batch 800] loss: 0.4748428896814585
[Epoch 2, Batch 900] loss: 0.4259560546278954
[Epoch 2, Batch 1000] loss: 0.45159062288701535
[Epoch 2, Batch 1100] loss: 0.41745859511196615
[Epoch 2, Batch 1200] loss: 0.41821032878011466
[Epoch 2, Batch 1300] loss: 0.4164666188508272
[Epoch 2, Batch 1400] loss: 0.40505019553005694
[Epoch 2, Batch 1500] loss: 0.4262571785598993
[Epoch 2, Batch 1600] loss: 0.35103389851748945
[Epoch 2, Batch 1700] loss: 0.39267552696168423
[Epoch 2, Batch 1800] loss: 0.3669641952961683
[Epoch 2, Batch 1900] loss: 0.3490144819766283
[Epoch 2, Batch 2000] loss: 0.36443947851657865
[Epoch 2, Batch 2100] loss: 0.3297793589532375
[Epoch 2, Batch 2200] loss: 0.3698052693158388
[Epoch 2, Batch 2300] loss: 0.34655577935278414
[Epoch 2, Batch 2400] loss: 0.31963392429053783
[Epoch 2, Batch 2500] loss: 0.31058778423815964
[Epoch 2, Batch 2600] loss: 0.3243618937395513
[Epoch 2, Batch 2700] loss: 0.31020719489082693
[Epoch 2, Batch 2800] loss: 0.32079499308019876
[Epoch 2, Batch 2900] loss: 0.3184188230335712
[Epoch 2, Batch 3000] loss: 0.3214023239910603
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2771
Validation Accuracy: 0.9167
Overfitting: 0.2771
Best model saved at epoch 2 with validation loss: 0.2771
[Epoch 3, Batch 100] loss: 0.27919057942926884
[Epoch 3, Batch 200] loss: 0.2690791791304946
[Epoch 3, Batch 300] loss: 0.30012174289673565
[Epoch 3, Batch 400] loss: 0.278681402169168
[Epoch 3, Batch 500] loss: 0.2965554579719901
[Epoch 3, Batch 600] loss: 0.2579607406631112
[Epoch 3, Batch 700] loss: 0.30523532029241324
[Epoch 3, Batch 800] loss: 0.2592717702314258
[Epoch 3, Batch 900] loss: 0.26961996994912624
[Epoch 3, Batch 1000] loss: 0.243269054973498
[Epoch 3, Batch 1100] loss: 0.272430558539927
[Epoch 3, Batch 1200] loss: 0.26063967499881985
[Epoch 3, Batch 1300] loss: 0.2423648745752871
[Epoch 3, Batch 1400] loss: 0.23049098256975412
[Epoch 3, Batch 1500] loss: 0.25572462363168597
[Epoch 3, Batch 1600] loss: 0.2335603727772832
[Epoch 3, Batch 1700] loss: 0.2511389217525721
[Epoch 3, Batch 1800] loss: 0.2385394672676921
[Epoch 3, Batch 1900] loss: 0.21425018401816487
[Epoch 3, Batch 2000] loss: 0.2331850482337177
[Epoch 3, Batch 2100] loss: 0.2251804692670703
[Epoch 3, Batch 2200] loss: 0.22478917023167014
[Epoch 3, Batch 2300] loss: 0.2267342709004879
[Epoch 3, Batch 2400] loss: 0.23904131092131137
[Epoch 3, Batch 2500] loss: 0.23517022781074048
[Epoch 3, Batch 2600] loss: 0.21364661168307067
[Epoch 3, Batch 2700] loss: 0.20847894695587457
[Epoch 3, Batch 2800] loss: 0.19890021787956358
[Epoch 3, Batch 2900] loss: 0.2107666529645212
[Epoch 3, Batch 3000] loss: 0.22275135190226136
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1860
Validation Accuracy: 0.9443
Overfitting: 0.1860
Best model saved at epoch 3 with validation loss: 0.1860
[Epoch 4, Batch 100] loss: 0.206863727401942
[Epoch 4, Batch 200] loss: 0.18344832165166736
[Epoch 4, Batch 300] loss: 0.2109135168697685
[Epoch 4, Batch 400] loss: 0.20299391951411963
[Epoch 4, Batch 500] loss: 0.16191196464002133
[Epoch 4, Batch 600] loss: 0.209278073515743
[Epoch 4, Batch 700] loss: 0.163870137501508
[Epoch 4, Batch 800] loss: 0.20641621954739095
[Epoch 4, Batch 900] loss: 0.19809175649657845
[Epoch 4, Batch 1000] loss: 0.19138603226281703
[Epoch 4, Batch 1100] loss: 0.16849586060270666
[Epoch 4, Batch 1200] loss: 0.17886018920689822
[Epoch 4, Batch 1300] loss: 0.17663256896659732
[Epoch 4, Batch 1400] loss: 0.17969808688387276
[Epoch 4, Batch 1500] loss: 0.1622644679900259
[Epoch 4, Batch 1600] loss: 0.15617630301043392
[Epoch 4, Batch 1700] loss: 0.19014974309131502
[Epoch 4, Batch 1800] loss: 0.17530921031720936
[Epoch 4, Batch 1900] loss: 0.1618856222741306
[Epoch 4, Batch 2000] loss: 0.18267347948625684
[Epoch 4, Batch 2100] loss: 0.14706591778434813
[Epoch 4, Batch 2200] loss: 0.16958786477334797
[Epoch 4, Batch 2300] loss: 0.14780521586537362
[Epoch 4, Batch 2400] loss: 0.1497395573463291
[Epoch 4, Batch 2500] loss: 0.16240680737420918
[Epoch 4, Batch 2600] loss: 0.16887729784939437
[Epoch 4, Batch 2700] loss: 0.17000421072356403
[Epoch 4, Batch 2800] loss: 0.14885920596309007
[Epoch 4, Batch 2900] loss: 0.1651834305981174
[Epoch 4, Batch 3000] loss: 0.1744168414385058
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1429
Validation Accuracy: 0.9567
Overfitting: 0.1429
Best model saved at epoch 4 with validation loss: 0.1429
[Epoch 5, Batch 100] loss: 0.1379047289863229
[Epoch 5, Batch 200] loss: 0.1536194765428081
[Epoch 5, Batch 300] loss: 0.13369414410553873
[Epoch 5, Batch 400] loss: 0.15515939197503031
[Epoch 5, Batch 500] loss: 0.12711489268578588
[Epoch 5, Batch 600] loss: 0.14752779105678201
[Epoch 5, Batch 700] loss: 0.13076336447149514
[Epoch 5, Batch 800] loss: 0.1545044731674716
[Epoch 5, Batch 900] loss: 0.13899676832836122
[Epoch 5, Batch 1000] loss: 0.16333670911379158
[Epoch 5, Batch 1100] loss: 0.1412807785347104
[Epoch 5, Batch 1200] loss: 0.15733219629619272
[Epoch 5, Batch 1300] loss: 0.1365808429615572
[Epoch 5, Batch 1400] loss: 0.13074861551634967
[Epoch 5, Batch 1500] loss: 0.15044609528034925
[Epoch 5, Batch 1600] loss: 0.13883450925350188
[Epoch 5, Batch 1700] loss: 0.1413640096783638
[Epoch 5, Batch 1800] loss: 0.14957459623459726
[Epoch 5, Batch 1900] loss: 0.13558501912280918
[Epoch 5, Batch 2000] loss: 0.13022556441370398
[Epoch 5, Batch 2100] loss: 0.140660810531117
[Epoch 5, Batch 2200] loss: 0.1527802237402648
[Epoch 5, Batch 2300] loss: 0.12937890756409615
[Epoch 5, Batch 2400] loss: 0.1071601236378774
[Epoch 5, Batch 2500] loss: 0.13213139456231146
[Epoch 5, Batch 2600] loss: 0.12463398136664182
[Epoch 5, Batch 2700] loss: 0.11868094467092305
[Epoch 5, Batch 2800] loss: 0.14376966434298083
[Epoch 5, Batch 2900] loss: 0.11679399577435107
[Epoch 5, Batch 3000] loss: 0.1108967053424567
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1279
Validation Accuracy: 0.9611
Overfitting: 0.1279
Best model saved at epoch 5 with validation loss: 0.1279
[Epoch 6, Batch 100] loss: 0.12560971005819738
[Epoch 6, Batch 200] loss: 0.13206290914677082
[Epoch 6, Batch 300] loss: 0.11389163038693369
[Epoch 6, Batch 400] loss: 0.11804756588768214
[Epoch 6, Batch 500] loss: 0.1183005723147653
[Epoch 6, Batch 600] loss: 0.12005596483126282
[Epoch 6, Batch 700] loss: 0.13033143679844217
[Epoch 6, Batch 800] loss: 0.09703194408211857
[Epoch 6, Batch 900] loss: 0.12702294872608036
[Epoch 6, Batch 1000] loss: 0.11758503660559655
[Epoch 6, Batch 1100] loss: 0.10490735133877024
[Epoch 6, Batch 1200] loss: 0.11789058449212461
[Epoch 6, Batch 1300] loss: 0.12040611557196826
[Epoch 6, Batch 1400] loss: 0.11178480621427297
[Epoch 6, Batch 1500] loss: 0.1321310181892477
[Epoch 6, Batch 1600] loss: 0.1211292675510049
[Epoch 6, Batch 1700] loss: 0.11189423603471368
[Epoch 6, Batch 1800] loss: 0.10448741128202528
[Epoch 6, Batch 1900] loss: 0.09392295108176768
[Epoch 6, Batch 2000] loss: 0.09586490290239454
[Epoch 6, Batch 2100] loss: 0.11325749667361379
[Epoch 6, Batch 2200] loss: 0.12534424155950546
[Epoch 6, Batch 2300] loss: 0.10111032389104366
[Epoch 6, Batch 2400] loss: 0.1155177640169859
[Epoch 6, Batch 2500] loss: 0.11294780829688535
[Epoch 6, Batch 2600] loss: 0.14613386529497802
[Epoch 6, Batch 2700] loss: 0.11531878740992398
[Epoch 6, Batch 2800] loss: 0.10199252248276025
[Epoch 6, Batch 2900] loss: 0.09491190491244197
[Epoch 6, Batch 3000] loss: 0.10909012012300082
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.1022
Validation Accuracy: 0.9674
Overfitting: 0.1022
Best model saved at epoch 6 with validation loss: 0.1022
[Epoch 7, Batch 100] loss: 0.0861176306323614
[Epoch 7, Batch 200] loss: 0.10220564956311136
[Epoch 7, Batch 300] loss: 0.09916769091738388
[Epoch 7, Batch 400] loss: 0.10514776132302359
[Epoch 7, Batch 500] loss: 0.11082161298487335
[Epoch 7, Batch 600] loss: 0.12124110424891114
[Epoch 7, Batch 700] loss: 0.10164996330160647
[Epoch 7, Batch 800] loss: 0.10134985024109483
[Epoch 7, Batch 900] loss: 0.08916907798731699
[Epoch 7, Batch 1000] loss: 0.08651493026642129
[Epoch 7, Batch 1100] loss: 0.09897159293759614
[Epoch 7, Batch 1200] loss: 0.08459628512151539
[Epoch 7, Batch 1300] loss: 0.09916017286013812
[Epoch 7, Batch 1400] loss: 0.105739001466427
[Epoch 7, Batch 1500] loss: 0.10781629235949368
[Epoch 7, Batch 1600] loss: 0.08768977836472913
[Epoch 7, Batch 1700] loss: 0.09447532426798716
[Epoch 7, Batch 1800] loss: 0.09255546743050218
[Epoch 7, Batch 1900] loss: 0.1099966775951907
[Epoch 7, Batch 2000] loss: 0.10054659474175423
[Epoch 7, Batch 2100] loss: 0.10258756075054407
[Epoch 7, Batch 2200] loss: 0.10949574988801032
[Epoch 7, Batch 2300] loss: 0.0931929701124318
[Epoch 7, Batch 2400] loss: 0.10414657399058341
[Epoch 7, Batch 2500] loss: 0.11725097409449518
[Epoch 7, Batch 2600] loss: 0.09525702796410769
[Epoch 7, Batch 2700] loss: 0.09466930858790874
[Epoch 7, Batch 2800] loss: 0.08598306093597785
[Epoch 7, Batch 2900] loss: 0.1073606251226738
[Epoch 7, Batch 3000] loss: 0.08991456714458763
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0924
Validation Accuracy: 0.9719
Overfitting: 0.0924
Best model saved at epoch 7 with validation loss: 0.0924
[Epoch 8, Batch 100] loss: 0.08473984739277513
[Epoch 8, Batch 200] loss: 0.09989428179105744
[Epoch 8, Batch 300] loss: 0.08802041548071429
[Epoch 8, Batch 400] loss: 0.08356632583308965
[Epoch 8, Batch 500] loss: 0.06576128468383104
[Epoch 8, Batch 600] loss: 0.10513618333032354
[Epoch 8, Batch 700] loss: 0.11147798617079388
[Epoch 8, Batch 800] loss: 0.09136821764870547
[Epoch 8, Batch 900] loss: 0.0799720854870975
[Epoch 8, Batch 1000] loss: 0.08961104675894603
[Epoch 8, Batch 1100] loss: 0.08718902304884978
[Epoch 8, Batch 1200] loss: 0.0789455366996117
[Epoch 8, Batch 1300] loss: 0.09751816159114242
[Epoch 8, Batch 1400] loss: 0.09502823831629939
[Epoch 8, Batch 1500] loss: 0.09206311603542418
[Epoch 8, Batch 1600] loss: 0.07074504812480882
[Epoch 8, Batch 1700] loss: 0.05941860859049484
[Epoch 8, Batch 1800] loss: 0.07671773162204772
[Epoch 8, Batch 1900] loss: 0.07677712537231855
[Epoch 8, Batch 2000] loss: 0.10049594991607591
[Epoch 8, Batch 2100] loss: 0.075433969887672
[Epoch 8, Batch 2200] loss: 0.10681644603144377
[Epoch 8, Batch 2300] loss: 0.09485900118714198
[Epoch 8, Batch 2400] loss: 0.10820754742366262
[Epoch 8, Batch 2500] loss: 0.08295835299650207
[Epoch 8, Batch 2600] loss: 0.09405823442153632
[Epoch 8, Batch 2700] loss: 0.08800124841509387
[Epoch 8, Batch 2800] loss: 0.08403399398317561
[Epoch 8, Batch 2900] loss: 0.10483159539871849
[Epoch 8, Batch 3000] loss: 0.07916270303539932
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0832
Validation Accuracy: 0.9728
Overfitting: 0.0832
Best model saved at epoch 8 with validation loss: 0.0832
[Epoch 9, Batch 100] loss: 0.07546408978465478
[Epoch 9, Batch 200] loss: 0.10943296652985737
[Epoch 9, Batch 300] loss: 0.07222937142476439
[Epoch 9, Batch 400] loss: 0.08132465733448044
[Epoch 9, Batch 500] loss: 0.09890444028191268
[Epoch 9, Batch 600] loss: 0.07597423607483506
[Epoch 9, Batch 700] loss: 0.06323908988619223
[Epoch 9, Batch 800] loss: 0.1081070211797487
[Epoch 9, Batch 900] loss: 0.09899068997707218
[Epoch 9, Batch 1000] loss: 0.07037334689754061
[Epoch 9, Batch 1100] loss: 0.08449838310480118
[Epoch 9, Batch 1200] loss: 0.07843409407418221
[Epoch 9, Batch 1300] loss: 0.06635770686902105
[Epoch 9, Batch 1400] loss: 0.07224512420129031
[Epoch 9, Batch 1500] loss: 0.07198188519687392
[Epoch 9, Batch 1600] loss: 0.07563507119659335
[Epoch 9, Batch 1700] loss: 0.079812352869194
[Epoch 9, Batch 1800] loss: 0.07560857383767143
[Epoch 9, Batch 1900] loss: 0.0879576959775295
[Epoch 9, Batch 2000] loss: 0.09322793319821358
[Epoch 9, Batch 2100] loss: 0.07953196892049164
[Epoch 9, Batch 2200] loss: 0.08064678374445065
[Epoch 9, Batch 2300] loss: 0.06291192724602297
[Epoch 9, Batch 2400] loss: 0.08120562408003025
[Epoch 9, Batch 2500] loss: 0.08075487638881895
[Epoch 9, Batch 2600] loss: 0.07853449966059997
[Epoch 9, Batch 2700] loss: 0.06207715880242176
[Epoch 9, Batch 2800] loss: 0.06295441470108926
[Epoch 9, Batch 2900] loss: 0.09036851075012237
[Epoch 9, Batch 3000] loss: 0.07746392418048345
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0753
Validation Accuracy: 0.9752
Overfitting: 0.0753
[I 2024-12-11 03:16:05,814] Trial 8 pruned. 

Selected Hyperparameters for Trial 10:
  l1: 256, l2: 128, lr: 0.0026936379642822942, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.274156575202942
[Epoch 1, Batch 200] loss: 1.521995124220848
[Epoch 1, Batch 300] loss: 0.49728654757142066
[Epoch 1, Batch 400] loss: 0.33840545736253264
[Epoch 1, Batch 500] loss: 0.2552618955820799
[Epoch 1, Batch 600] loss: 0.22203684881329536
[Epoch 1, Batch 700] loss: 0.17394447967410087
**STATS for Epoch 1** : 
Average training loss: 0.0109
Average validation loss: 0.1444
Validation Accuracy: 0.9538
Overfitting: 0.1335
Best model saved at epoch 1 with validation loss: 0.1444
[Epoch 2, Batch 100] loss: 0.1468864978477359
[Epoch 2, Batch 200] loss: 0.15609400294721126
[Epoch 2, Batch 300] loss: 0.11784350227564573
[Epoch 2, Batch 400] loss: 0.12768421726301313
[Epoch 2, Batch 500] loss: 0.10999887829646468
[Epoch 2, Batch 600] loss: 0.10633950466290117
[Epoch 2, Batch 700] loss: 0.09822555616497994
**STATS for Epoch 2** : 
Average training loss: 0.0063
Average validation loss: 0.0889
Validation Accuracy: 0.9715
Overfitting: 0.0826
Best model saved at epoch 2 with validation loss: 0.0889
[Epoch 3, Batch 100] loss: 0.09641118654981255
[Epoch 3, Batch 200] loss: 0.09095300477929413
[Epoch 3, Batch 300] loss: 0.08896888686344027
[Epoch 3, Batch 400] loss: 0.07611534513533115
[Epoch 3, Batch 500] loss: 0.08322287414688617
[Epoch 3, Batch 600] loss: 0.07205601756460965
[Epoch 3, Batch 700] loss: 0.07025925188791007
**STATS for Epoch 3** : 
Average training loss: 0.0059
Average validation loss: 0.0654
Validation Accuracy: 0.9789
Overfitting: 0.0595
Best model saved at epoch 3 with validation loss: 0.0654
[Epoch 4, Batch 100] loss: 0.06721197438426316
[Epoch 4, Batch 200] loss: 0.0770804162370041
[Epoch 4, Batch 300] loss: 0.07202012526569888
[Epoch 4, Batch 400] loss: 0.0662253673421219
[Epoch 4, Batch 500] loss: 0.06131812974344939
[Epoch 4, Batch 600] loss: 0.057859993553720415
[Epoch 4, Batch 700] loss: 0.06609382821246981
**STATS for Epoch 4** : 
Average training loss: 0.0037
Average validation loss: 0.0632
Validation Accuracy: 0.9792
Overfitting: 0.0595
Best model saved at epoch 4 with validation loss: 0.0632
[Epoch 5, Batch 100] loss: 0.05711254408117384
[Epoch 5, Batch 200] loss: 0.04606703512836248
[Epoch 5, Batch 300] loss: 0.05923274541273713
[Epoch 5, Batch 400] loss: 0.05866915283026174
[Epoch 5, Batch 500] loss: 0.051596415194217114
[Epoch 5, Batch 600] loss: 0.05198386517353356
[Epoch 5, Batch 700] loss: 0.050211560321040453
**STATS for Epoch 5** : 
Average training loss: 0.0033
Average validation loss: 0.0526
Validation Accuracy: 0.9840
Overfitting: 0.0492
Best model saved at epoch 5 with validation loss: 0.0526
[Epoch 6, Batch 100] loss: 0.04480117926839739
[Epoch 6, Batch 200] loss: 0.04562539303675294
[Epoch 6, Batch 300] loss: 0.05154256641864777
[Epoch 6, Batch 400] loss: 0.034396179229952396
[Epoch 6, Batch 500] loss: 0.04161795462481677
[Epoch 6, Batch 600] loss: 0.05622749697766267
[Epoch 6, Batch 700] loss: 0.0371736200642772
**STATS for Epoch 6** : 
Average training loss: 0.0032
Average validation loss: 0.0705
Validation Accuracy: 0.9777
Overfitting: 0.0673
[Epoch 7, Batch 100] loss: 0.042565839590970427
[Epoch 7, Batch 200] loss: 0.036652371590025726
[Epoch 7, Batch 300] loss: 0.0455417911708355
[Epoch 7, Batch 400] loss: 0.037895768175367266
[Epoch 7, Batch 500] loss: 0.040850821207277475
[Epoch 7, Batch 600] loss: 0.038888626056723295
[Epoch 7, Batch 700] loss: 0.04473856123629957
**STATS for Epoch 7** : 
Average training loss: 0.0027
Average validation loss: 0.0463
Validation Accuracy: 0.9854
Overfitting: 0.0436
Best model saved at epoch 7 with validation loss: 0.0463
[Epoch 8, Batch 100] loss: 0.033342219380429014
[Epoch 8, Batch 200] loss: 0.03128411647747271
[Epoch 8, Batch 300] loss: 0.03218005109811202
[Epoch 8, Batch 400] loss: 0.03470615293132141
[Epoch 8, Batch 500] loss: 0.03544517086353153
[Epoch 8, Batch 600] loss: 0.03192611732170917
[Epoch 8, Batch 700] loss: 0.032984740434912965
**STATS for Epoch 8** : 
Average training loss: 0.0022
Average validation loss: 0.0442
Validation Accuracy: 0.9873
Overfitting: 0.0419
Best model saved at epoch 8 with validation loss: 0.0442
[Epoch 9, Batch 100] loss: 0.025747329099103808
[Epoch 9, Batch 200] loss: 0.02912654163490515
[Epoch 9, Batch 300] loss: 0.029771623048582115
[Epoch 9, Batch 400] loss: 0.026037749013630672
[Epoch 9, Batch 500] loss: 0.035262287573423236
[Epoch 9, Batch 600] loss: 0.028134226421825587
[Epoch 9, Batch 700] loss: 0.025453640648629518
**STATS for Epoch 9** : 
Average training loss: 0.0019
Average validation loss: 0.0420
Validation Accuracy: 0.9873
Overfitting: 0.0401
Best model saved at epoch 9 with validation loss: 0.0420
[Epoch 10, Batch 100] loss: 0.02366063411347568
[Epoch 10, Batch 200] loss: 0.01525862237875117
[Epoch 10, Batch 300] loss: 0.025676508019678294
[Epoch 10, Batch 400] loss: 0.024778382943477482
[Epoch 10, Batch 500] loss: 0.03318174873362295
[Epoch 10, Batch 600] loss: 0.03447333990945481
[Epoch 10, Batch 700] loss: 0.028797923049423843
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0448
Validation Accuracy: 0.9870
Overfitting: 0.0432
[Epoch 11, Batch 100] loss: 0.025655692785512656
[Epoch 11, Batch 200] loss: 0.022489889573771505
[Epoch 11, Batch 300] loss: 0.02241016708605457
[Epoch 11, Batch 400] loss: 0.022351867993129416
[Epoch 11, Batch 500] loss: 0.022593192147323863
[Epoch 11, Batch 600] loss: 0.01901623132522218
[Epoch 11, Batch 700] loss: 0.022022880588192493
**STATS for Epoch 11** : 
Average training loss: 0.0020
Average validation loss: 0.0503
Validation Accuracy: 0.9837
Overfitting: 0.0483
[Epoch 12, Batch 100] loss: 0.019265114834997803
[Epoch 12, Batch 200] loss: 0.014311778774717822
[Epoch 12, Batch 300] loss: 0.02094986418436747
[Epoch 12, Batch 400] loss: 0.02134347229031846
[Epoch 12, Batch 500] loss: 0.025651968648307957
[Epoch 12, Batch 600] loss: 0.022888681972399353
[Epoch 12, Batch 700] loss: 0.024055837168125437
**STATS for Epoch 12** : 
Average training loss: 0.0016
Average validation loss: 0.0419
Validation Accuracy: 0.9884
Overfitting: 0.0403
Best model saved at epoch 12 with validation loss: 0.0419
[Epoch 13, Batch 100] loss: 0.019539234906551427
[Epoch 13, Batch 200] loss: 0.0174566844778019
[Epoch 13, Batch 300] loss: 0.019216704387799835
[Epoch 13, Batch 400] loss: 0.020323833865695633
[Epoch 13, Batch 500] loss: 0.02052858883253066
[Epoch 13, Batch 600] loss: 0.0197369981938391
[Epoch 13, Batch 700] loss: 0.01677426909795031
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0415
Validation Accuracy: 0.9882
Overfitting: 0.0405
Best model saved at epoch 13 with validation loss: 0.0415
[Epoch 14, Batch 100] loss: 0.01571386270748917
[Epoch 14, Batch 200] loss: 0.016335890744812787
[Epoch 14, Batch 300] loss: 0.015364190212858375
[Epoch 14, Batch 400] loss: 0.01739932994154515
[Epoch 14, Batch 500] loss: 0.018208974297740498
[Epoch 14, Batch 600] loss: 0.011969465741130988
[Epoch 14, Batch 700] loss: 0.02115045212674886
**STATS for Epoch 14** : 
Average training loss: 0.0013
Average validation loss: 0.0439
Validation Accuracy: 0.9874
Overfitting: 0.0426
[Epoch 15, Batch 100] loss: 0.014442848965409212
[Epoch 15, Batch 200] loss: 0.014975280010839925
[Epoch 15, Batch 300] loss: 0.011319008872960694
[Epoch 15, Batch 400] loss: 0.00965211195696611
[Epoch 15, Batch 500] loss: 0.012471184911410091
[Epoch 15, Batch 600] loss: 0.013382190391421318
[Epoch 15, Batch 700] loss: 0.02472505793091841
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0441
Validation Accuracy: 0.9855
Overfitting: 0.0431
[Epoch 16, Batch 100] loss: 0.018164614245324628
[Epoch 16, Batch 200] loss: 0.01078913668578025
[Epoch 16, Batch 300] loss: 0.014972265898541082
[Epoch 16, Batch 400] loss: 0.012467633851920255
[Epoch 16, Batch 500] loss: 0.011210101143078646
[Epoch 16, Batch 600] loss: 0.012684766464662971
[Epoch 16, Batch 700] loss: 0.01180698935611872
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0482
Validation Accuracy: 0.9860
Overfitting: 0.0472
[Epoch 17, Batch 100] loss: 0.01450249910732964
[Epoch 17, Batch 200] loss: 0.012259617540548788
[Epoch 17, Batch 300] loss: 0.00744157279128558
[Epoch 17, Batch 400] loss: 0.013050384084999677
[Epoch 17, Batch 500] loss: 0.007843042659078491
[Epoch 17, Batch 600] loss: 0.010206724237214075
[Epoch 17, Batch 700] loss: 0.011850787508737994
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0434
Validation Accuracy: 0.9881
Overfitting: 0.0429
[Epoch 18, Batch 100] loss: 0.008553943455481203
[Epoch 18, Batch 200] loss: 0.007193603480554884
[Epoch 18, Batch 300] loss: 0.007061611188582902
[Epoch 18, Batch 400] loss: 0.014574860107022686
[Epoch 18, Batch 500] loss: 0.00971256962737243
[Epoch 18, Batch 600] loss: 0.008461608973084367
[Epoch 18, Batch 700] loss: 0.011773405026178806
**STATS for Epoch 18** : 
Average training loss: 0.0011
Average validation loss: 0.0638
Validation Accuracy: 0.9829
Overfitting: 0.0628
[Epoch 19, Batch 100] loss: 0.009823240011101006
[Epoch 19, Batch 200] loss: 0.009624029160331702
[Epoch 19, Batch 300] loss: 0.009225907127183746
[Epoch 19, Batch 400] loss: 0.008822945379361045
[Epoch 19, Batch 500] loss: 0.016094064539502143
[Epoch 19, Batch 600] loss: 0.009563271926963353
[Epoch 19, Batch 700] loss: 0.010660909765865654
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0533
Validation Accuracy: 0.9852
Overfitting: 0.0529
[Epoch 20, Batch 100] loss: 0.0068538856472878254
[Epoch 20, Batch 200] loss: 0.00565617961146927
[Epoch 20, Batch 300] loss: 0.0076836360763991255
[Epoch 20, Batch 400] loss: 0.011403091466781916
[Epoch 20, Batch 500] loss: 0.008350443558010739
[Epoch 20, Batch 600] loss: 0.00762249918661837
[Epoch 20, Batch 700] loss: 0.008279379266368778
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0458
Validation Accuracy: 0.9872
Overfitting: 0.0453
[Epoch 21, Batch 100] loss: 0.007333537377853645
[Epoch 21, Batch 200] loss: 0.006666620766118285
[Epoch 21, Batch 300] loss: 0.007256395760268788
[Epoch 21, Batch 400] loss: 0.004935670884224237
[Epoch 21, Batch 500] loss: 0.005750447145437647
[Epoch 21, Batch 600] loss: 0.009073786956741969
[Epoch 21, Batch 700] loss: 0.007929706705181162
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0451
Validation Accuracy: 0.9882
Overfitting: 0.0448
[Epoch 22, Batch 100] loss: 0.009344411467482132
[Epoch 22, Batch 200] loss: 0.005275370055533131
[Epoch 22, Batch 300] loss: 0.0057016486831344085
[Epoch 22, Batch 400] loss: 0.004750606773159234
[Epoch 22, Batch 500] loss: 0.00499510607765842
[Epoch 22, Batch 600] loss: 0.007160737311205594
[Epoch 22, Batch 700] loss: 0.005597313966718503
**STATS for Epoch 22** : 
Average training loss: 0.0007
Average validation loss: 0.0510
Validation Accuracy: 0.9867
Overfitting: 0.0504
[Epoch 23, Batch 100] loss: 0.006259091733591049
[Epoch 23, Batch 200] loss: 0.004783861154619444
[Epoch 23, Batch 300] loss: 0.0054854343073748165
[Epoch 23, Batch 400] loss: 0.003430118847027188
[Epoch 23, Batch 500] loss: 0.003980117099672498
[Epoch 23, Batch 600] loss: 0.00728707135462173
[Epoch 23, Batch 700] loss: 0.006211117076672963
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0458
Validation Accuracy: 0.9877
Overfitting: 0.0455
[Epoch 24, Batch 100] loss: 0.0038912040175455333
[Epoch 24, Batch 200] loss: 0.007039413327729563
[Epoch 24, Batch 300] loss: 0.004470098607271211
[Epoch 24, Batch 400] loss: 0.005330587955722876
[Epoch 24, Batch 500] loss: 0.004566565750337759
[Epoch 24, Batch 600] loss: 0.004401244419204886
[Epoch 24, Batch 700] loss: 0.008178335716929724
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0472
Validation Accuracy: 0.9886
Overfitting: 0.0469
Fold 1 validation loss: 0.0472
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.166140135526657
[Epoch 1, Batch 200] loss: 0.7096806693077088
[Epoch 1, Batch 300] loss: 0.3528262710571289
[Epoch 1, Batch 400] loss: 0.26704397425055504
[Epoch 1, Batch 500] loss: 0.21133362054824828
[Epoch 1, Batch 600] loss: 0.18772040713578464
[Epoch 1, Batch 700] loss: 0.1537873975560069
**STATS for Epoch 1** : 
Average training loss: 0.0089
Average validation loss: 0.1645
Validation Accuracy: 0.9488
Overfitting: 0.1556
Best model saved at epoch 1 with validation loss: 0.1645
[Epoch 2, Batch 100] loss: 0.12613673916086554
[Epoch 2, Batch 200] loss: 0.12276436949148774
[Epoch 2, Batch 300] loss: 0.10824898893944919
[Epoch 2, Batch 400] loss: 0.11904446076601743
[Epoch 2, Batch 500] loss: 0.11648891229182481
[Epoch 2, Batch 600] loss: 0.09529807034879922
[Epoch 2, Batch 700] loss: 0.10276755955070258
**STATS for Epoch 2** : 
Average training loss: 0.0061
Average validation loss: 0.0950
Validation Accuracy: 0.9722
Overfitting: 0.0889
Best model saved at epoch 2 with validation loss: 0.0950
[Epoch 3, Batch 100] loss: 0.07081841008272022
[Epoch 3, Batch 200] loss: 0.0875757443299517
[Epoch 3, Batch 300] loss: 0.09189285769127309
[Epoch 3, Batch 400] loss: 0.0723292405065149
[Epoch 3, Batch 500] loss: 0.07499515847768634
[Epoch 3, Batch 600] loss: 0.06902475190348924
[Epoch 3, Batch 700] loss: 0.06993765973020345
**STATS for Epoch 3** : 
Average training loss: 0.0057
Average validation loss: 0.0925
Validation Accuracy: 0.9712
Overfitting: 0.0868
Best model saved at epoch 3 with validation loss: 0.0925
[Epoch 4, Batch 100] loss: 0.06141059429850429
[Epoch 4, Batch 200] loss: 0.05889235387556255
[Epoch 4, Batch 300] loss: 0.06139886075165123
[Epoch 4, Batch 400] loss: 0.07000679666176439
[Epoch 4, Batch 500] loss: 0.059044311470352114
[Epoch 4, Batch 600] loss: 0.07052405535709112
[Epoch 4, Batch 700] loss: 0.05198018169263378
**STATS for Epoch 4** : 
Average training loss: 0.0038
Average validation loss: 0.0826
Validation Accuracy: 0.9753
Overfitting: 0.0788
Best model saved at epoch 4 with validation loss: 0.0826
[Epoch 5, Batch 100] loss: 0.05153038064017892
[Epoch 5, Batch 200] loss: 0.05448268645908683
[Epoch 5, Batch 300] loss: 0.05393926113320049
[Epoch 5, Batch 400] loss: 0.052406855258159336
[Epoch 5, Batch 500] loss: 0.04915505728218705
[Epoch 5, Batch 600] loss: 0.04614332969300449
[Epoch 5, Batch 700] loss: 0.04176110047847033
**STATS for Epoch 5** : 
Average training loss: 0.0043
Average validation loss: 0.0653
Validation Accuracy: 0.9803
Overfitting: 0.0610
Best model saved at epoch 5 with validation loss: 0.0653
[Epoch 6, Batch 100] loss: 0.039790632794611154
[Epoch 6, Batch 200] loss: 0.042980692572891714
[Epoch 6, Batch 300] loss: 0.04524381614057347
[Epoch 6, Batch 400] loss: 0.0501181153440848
[Epoch 6, Batch 500] loss: 0.04114863448310643
[Epoch 6, Batch 600] loss: 0.041165691160131246
[Epoch 6, Batch 700] loss: 0.04087758950772695
**STATS for Epoch 6** : 
Average training loss: 0.0034
Average validation loss: 0.0628
Validation Accuracy: 0.9817
Overfitting: 0.0593
Best model saved at epoch 6 with validation loss: 0.0628
[Epoch 7, Batch 100] loss: 0.038970474109519274
[Epoch 7, Batch 200] loss: 0.03579848370049149
[Epoch 7, Batch 300] loss: 0.03778775529004633
[Epoch 7, Batch 400] loss: 0.03731219915905967
[Epoch 7, Batch 500] loss: 0.033743805268313734
[Epoch 7, Batch 600] loss: 0.035360910565941595
[Epoch 7, Batch 700] loss: 0.04129680170910433
**STATS for Epoch 7** : 
Average training loss: 0.0031
Average validation loss: 0.0623
Validation Accuracy: 0.9802
Overfitting: 0.0592
Best model saved at epoch 7 with validation loss: 0.0623
[Epoch 8, Batch 100] loss: 0.031035934063838796
[Epoch 8, Batch 200] loss: 0.029364319930318742
[Epoch 8, Batch 300] loss: 0.03336035543994512
[Epoch 8, Batch 400] loss: 0.034236275161383674
[Epoch 8, Batch 500] loss: 0.033496080291224646
[Epoch 8, Batch 600] loss: 0.032111647974234075
[Epoch 8, Batch 700] loss: 0.03894112635636702
**STATS for Epoch 8** : 
Average training loss: 0.0023
Average validation loss: 0.0568
Validation Accuracy: 0.9823
Overfitting: 0.0545
Best model saved at epoch 8 with validation loss: 0.0568
[Epoch 9, Batch 100] loss: 0.020723645405960268
[Epoch 9, Batch 200] loss: 0.026757160862907768
[Epoch 9, Batch 300] loss: 0.033492238659528085
[Epoch 9, Batch 400] loss: 0.030970427066786214
[Epoch 9, Batch 500] loss: 0.03078471771092154
[Epoch 9, Batch 600] loss: 0.031825217391597105
[Epoch 9, Batch 700] loss: 0.030212776318658142
**STATS for Epoch 9** : 
Average training loss: 0.0018
Average validation loss: 0.0500
Validation Accuracy: 0.9860
Overfitting: 0.0482
Best model saved at epoch 9 with validation loss: 0.0500
[Epoch 10, Batch 100] loss: 0.020445292182266712
[Epoch 10, Batch 200] loss: 0.019041383562143892
[Epoch 10, Batch 300] loss: 0.02352969506988302
[Epoch 10, Batch 400] loss: 0.023463565252022818
[Epoch 10, Batch 500] loss: 0.028020032337517476
[Epoch 10, Batch 600] loss: 0.02812162120360881
[Epoch 10, Batch 700] loss: 0.026407296222168954
**STATS for Epoch 10** : 
Average training loss: 0.0017
Average validation loss: 0.0662
Validation Accuracy: 0.9808
Overfitting: 0.0646
[Epoch 11, Batch 100] loss: 0.022548775782343
[Epoch 11, Batch 200] loss: 0.01827127917727921
[Epoch 11, Batch 300] loss: 0.023829970427323134
[Epoch 11, Batch 400] loss: 0.022631507511250676
[Epoch 11, Batch 500] loss: 0.02109858811600134
[Epoch 11, Batch 600] loss: 0.021470110901573206
[Epoch 11, Batch 700] loss: 0.021726826012600214
**STATS for Epoch 11** : 
Average training loss: 0.0020
Average validation loss: 0.0572
Validation Accuracy: 0.9847
Overfitting: 0.0552
[Epoch 12, Batch 100] loss: 0.01887126676389016
[Epoch 12, Batch 200] loss: 0.01655819458712358
[Epoch 12, Batch 300] loss: 0.01756357342324918
[Epoch 12, Batch 400] loss: 0.02321624293545028
[Epoch 12, Batch 500] loss: 0.022296059875516222
[Epoch 12, Batch 600] loss: 0.01930877029080875
[Epoch 12, Batch 700] loss: 0.022547615528455935
**STATS for Epoch 12** : 
Average training loss: 0.0011
Average validation loss: 0.0486
Validation Accuracy: 0.9875
Overfitting: 0.0476
Best model saved at epoch 12 with validation loss: 0.0486
[Epoch 13, Batch 100] loss: 0.01645805540436413
[Epoch 13, Batch 200] loss: 0.016226136004843284
[Epoch 13, Batch 300] loss: 0.021266587865538894
[Epoch 13, Batch 400] loss: 0.017109858521725984
[Epoch 13, Batch 500] loss: 0.01773266301548574
[Epoch 13, Batch 600] loss: 0.01944242597121047
[Epoch 13, Batch 700] loss: 0.01967430100106867
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0534
Validation Accuracy: 0.9851
Overfitting: 0.0524
[Epoch 14, Batch 100] loss: 0.015065901403868338
[Epoch 14, Batch 200] loss: 0.01148119770892663
[Epoch 14, Batch 300] loss: 0.015878800544742264
[Epoch 14, Batch 400] loss: 0.013301401428179815
[Epoch 14, Batch 500] loss: 0.013376676477491856
[Epoch 14, Batch 600] loss: 0.02056432346376823
[Epoch 14, Batch 700] loss: 0.01567070479679387
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0506
Validation Accuracy: 0.9862
Overfitting: 0.0494
[Epoch 15, Batch 100] loss: 0.009530761843780055
[Epoch 15, Batch 200] loss: 0.015307710389315617
[Epoch 15, Batch 300] loss: 0.013178037357283756
[Epoch 15, Batch 400] loss: 0.013455986851040507
[Epoch 15, Batch 500] loss: 0.00901827511144802
[Epoch 15, Batch 600] loss: 0.01794011605612468
[Epoch 15, Batch 700] loss: 0.01762822525197407
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0509
Validation Accuracy: 0.9866
Overfitting: 0.0501
[Epoch 16, Batch 100] loss: 0.010895092693681363
[Epoch 16, Batch 200] loss: 0.008258353079436348
[Epoch 16, Batch 300] loss: 0.01132766598428134
[Epoch 16, Batch 400] loss: 0.011053172234969679
[Epoch 16, Batch 500] loss: 0.016895022870012325
[Epoch 16, Batch 600] loss: 0.018097486680781004
[Epoch 16, Batch 700] loss: 0.009539025549893268
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0515
Validation Accuracy: 0.9853
Overfitting: 0.0505
[Epoch 17, Batch 100] loss: 0.00777710282105545
[Epoch 17, Batch 200] loss: 0.010463234118142282
[Epoch 17, Batch 300] loss: 0.009316680123883998
[Epoch 17, Batch 400] loss: 0.009451331402960932
[Epoch 17, Batch 500] loss: 0.01396449111867696
[Epoch 17, Batch 600] loss: 0.01200443255045684
[Epoch 17, Batch 700] loss: 0.01569657531530538
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0510
Validation Accuracy: 0.9868
Overfitting: 0.0505
[Epoch 18, Batch 100] loss: 0.00806583242781926
[Epoch 18, Batch 200] loss: 0.011942955890699523
[Epoch 18, Batch 300] loss: 0.006553795607178472
[Epoch 18, Batch 400] loss: 0.009702644387580221
[Epoch 18, Batch 500] loss: 0.009223308960645226
[Epoch 18, Batch 600] loss: 0.012881495645342512
[Epoch 18, Batch 700] loss: 0.008717813317707624
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0538
Validation Accuracy: 0.9868
Overfitting: 0.0529
[Epoch 19, Batch 100] loss: 0.005804267164567136
[Epoch 19, Batch 200] loss: 0.005403412941850547
[Epoch 19, Batch 300] loss: 0.009490216376252646
[Epoch 19, Batch 400] loss: 0.012118820029136258
[Epoch 19, Batch 500] loss: 0.010077213565673447
[Epoch 19, Batch 600] loss: 0.010246686435712036
[Epoch 19, Batch 700] loss: 0.013920888098800788
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0523
Validation Accuracy: 0.9877
Overfitting: 0.0516
[Epoch 20, Batch 100] loss: 0.004408548002138559
[Epoch 20, Batch 200] loss: 0.006729556360660353
[Epoch 20, Batch 300] loss: 0.00470034080419282
[Epoch 20, Batch 400] loss: 0.005987262459311751
[Epoch 20, Batch 500] loss: 0.006701922636493691
[Epoch 20, Batch 600] loss: 0.008543100577953737
[Epoch 20, Batch 700] loss: 0.009440920864435612
**STATS for Epoch 20** : 
Average training loss: 0.0008
Average validation loss: 0.0526
Validation Accuracy: 0.9872
Overfitting: 0.0518
[Epoch 21, Batch 100] loss: 0.004338594590808498
[Epoch 21, Batch 200] loss: 0.00419721027072228
[Epoch 21, Batch 300] loss: 0.004375053637304518
[Epoch 21, Batch 400] loss: 0.007060938465292566
[Epoch 21, Batch 500] loss: 0.0076131635251658735
[Epoch 21, Batch 600] loss: 0.005318641475168988
[Epoch 21, Batch 700] loss: 0.008335601349390345
**STATS for Epoch 21** : 
Average training loss: 0.0007
Average validation loss: 0.0601
Validation Accuracy: 0.9863
Overfitting: 0.0593
[Epoch 22, Batch 100] loss: 0.00729655915274634
[Epoch 22, Batch 200] loss: 0.005495724577704095
[Epoch 22, Batch 300] loss: 0.004679436857622931
[Epoch 22, Batch 400] loss: 0.004540109214940457
[Epoch 22, Batch 500] loss: 0.005506390299779014
[Epoch 22, Batch 600] loss: 0.011876835312068578
[Epoch 22, Batch 700] loss: 0.006531046938325744
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0564
Validation Accuracy: 0.9867
Overfitting: 0.0561
[Epoch 23, Batch 100] loss: 0.00438103380954999
[Epoch 23, Batch 200] loss: 0.009607621019949875
[Epoch 23, Batch 300] loss: 0.0057645297436829425
[Epoch 23, Batch 400] loss: 0.003926945044586318
[Epoch 23, Batch 500] loss: 0.008160481274044286
[Epoch 23, Batch 600] loss: 0.004367856636872602
[Epoch 23, Batch 700] loss: 0.004839610720937344
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0616
Validation Accuracy: 0.9858
Overfitting: 0.0612
[Epoch 24, Batch 100] loss: 0.005142588448634342
[Epoch 24, Batch 200] loss: 0.0065961115472782696
[Epoch 24, Batch 300] loss: 0.003762880096292065
[Epoch 24, Batch 400] loss: 0.006009777283125004
[Epoch 24, Batch 500] loss: 0.004973121456350782
[Epoch 24, Batch 600] loss: 0.00443957192799644
[Epoch 24, Batch 700] loss: 0.004005478352682985
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0568
Validation Accuracy: 0.9872
Overfitting: 0.0564
Fold 2 validation loss: 0.0568
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2825796961784364
[Epoch 1, Batch 200] loss: 1.6827835685014725
[Epoch 1, Batch 300] loss: 0.5044700346887112
[Epoch 1, Batch 400] loss: 0.3298997500538826
[Epoch 1, Batch 500] loss: 0.25308403991162776
[Epoch 1, Batch 600] loss: 0.22301108397543432
[Epoch 1, Batch 700] loss: 0.19361965391784908
**STATS for Epoch 1** : 
Average training loss: 0.0109
Average validation loss: 0.1745
Validation Accuracy: 0.9480
Overfitting: 0.1635
Best model saved at epoch 1 with validation loss: 0.1745
[Epoch 2, Batch 100] loss: 0.15639036145061255
[Epoch 2, Batch 200] loss: 0.14143437260761857
[Epoch 2, Batch 300] loss: 0.13274757854640484
[Epoch 2, Batch 400] loss: 0.1328983161598444
[Epoch 2, Batch 500] loss: 0.10994750984013081
[Epoch 2, Batch 600] loss: 0.11303738905116915
[Epoch 2, Batch 700] loss: 0.09779754501767457
**STATS for Epoch 2** : 
Average training loss: 0.0064
Average validation loss: 0.1033
Validation Accuracy: 0.9692
Overfitting: 0.0968
Best model saved at epoch 2 with validation loss: 0.1033
[Epoch 3, Batch 100] loss: 0.08474026373587548
[Epoch 3, Batch 200] loss: 0.08122714951634408
[Epoch 3, Batch 300] loss: 0.08187452888116241
[Epoch 3, Batch 400] loss: 0.08489711835049092
[Epoch 3, Batch 500] loss: 0.09051031870767474
[Epoch 3, Batch 600] loss: 0.08121966348495334
[Epoch 3, Batch 700] loss: 0.08391030536964536
**STATS for Epoch 3** : 
Average training loss: 0.0059
Average validation loss: 0.0849
Validation Accuracy: 0.9732
Overfitting: 0.0790
Best model saved at epoch 3 with validation loss: 0.0849
[Epoch 4, Batch 100] loss: 0.07354822740424424
[Epoch 4, Batch 200] loss: 0.06105223590973765
[Epoch 4, Batch 300] loss: 0.06078870426863432
[Epoch 4, Batch 400] loss: 0.06428605819586665
[Epoch 4, Batch 500] loss: 0.05454779882915318
[Epoch 4, Batch 600] loss: 0.07312043696176261
[Epoch 4, Batch 700] loss: 0.07416719235945493
**STATS for Epoch 4** : 
Average training loss: 0.0052
Average validation loss: 0.0714
Validation Accuracy: 0.9773
Overfitting: 0.0662
Best model saved at epoch 4 with validation loss: 0.0714
[Epoch 5, Batch 100] loss: 0.05749305005185306
[Epoch 5, Batch 200] loss: 0.04934909041039646
[Epoch 5, Batch 300] loss: 0.051244880526792255
[Epoch 5, Batch 400] loss: 0.05481605796841905
[Epoch 5, Batch 500] loss: 0.056029709526337686
[Epoch 5, Batch 600] loss: 0.057062012115493416
[Epoch 5, Batch 700] loss: 0.06099811759777367
**STATS for Epoch 5** : 
Average training loss: 0.0044
Average validation loss: 0.0625
Validation Accuracy: 0.9798
Overfitting: 0.0582
Best model saved at epoch 5 with validation loss: 0.0625
[Epoch 6, Batch 100] loss: 0.054836820578202605
[Epoch 6, Batch 200] loss: 0.04973840587073937
[Epoch 6, Batch 300] loss: 0.044878559411736206
[Epoch 6, Batch 400] loss: 0.03655467655044049
[Epoch 6, Batch 500] loss: 0.0461345137632452
[Epoch 6, Batch 600] loss: 0.04619942189194262
[Epoch 6, Batch 700] loss: 0.04972752300091088
**STATS for Epoch 6** : 
Average training loss: 0.0029
Average validation loss: 0.0623
Validation Accuracy: 0.9803
Overfitting: 0.0594
Best model saved at epoch 6 with validation loss: 0.0623
[Epoch 7, Batch 100] loss: 0.03976698259823024
[Epoch 7, Batch 200] loss: 0.0381555237644352
[Epoch 7, Batch 300] loss: 0.04349253026302904
[Epoch 7, Batch 400] loss: 0.034064111970365046
[Epoch 7, Batch 500] loss: 0.045903928845655174
[Epoch 7, Batch 600] loss: 0.04452870898647234
[Epoch 7, Batch 700] loss: 0.03730522063095123
**STATS for Epoch 7** : 
Average training loss: 0.0029
Average validation loss: 0.0593
Validation Accuracy: 0.9811
Overfitting: 0.0565
Best model saved at epoch 7 with validation loss: 0.0593
[Epoch 8, Batch 100] loss: 0.030731459652306514
[Epoch 8, Batch 200] loss: 0.03531643628724851
[Epoch 8, Batch 300] loss: 0.03079178953776136
[Epoch 8, Batch 400] loss: 0.03746698043425568
[Epoch 8, Batch 500] loss: 0.03228299686568789
[Epoch 8, Batch 600] loss: 0.044292167774401606
[Epoch 8, Batch 700] loss: 0.03286722762975842
**STATS for Epoch 8** : 
Average training loss: 0.0026
Average validation loss: 0.0611
Validation Accuracy: 0.9812
Overfitting: 0.0585
[Epoch 9, Batch 100] loss: 0.025034034192212857
[Epoch 9, Batch 200] loss: 0.03312534544500522
[Epoch 9, Batch 300] loss: 0.04035479204263538
[Epoch 9, Batch 400] loss: 0.03006300599547103
[Epoch 9, Batch 500] loss: 0.027777315735584125
[Epoch 9, Batch 600] loss: 0.03465644317213446
[Epoch 9, Batch 700] loss: 0.03365314022463281
**STATS for Epoch 9** : 
Average training loss: 0.0020
Average validation loss: 0.0525
Validation Accuracy: 0.9849
Overfitting: 0.0505
Best model saved at epoch 9 with validation loss: 0.0525
[Epoch 10, Batch 100] loss: 0.024695202286820858
[Epoch 10, Batch 200] loss: 0.025567298997193576
[Epoch 10, Batch 300] loss: 0.024015708542137873
[Epoch 10, Batch 400] loss: 0.03024567934044171
[Epoch 10, Batch 500] loss: 0.024521901519037784
[Epoch 10, Batch 600] loss: 0.03382137011620216
[Epoch 10, Batch 700] loss: 0.025947958066826687
**STATS for Epoch 10** : 
Average training loss: 0.0018
Average validation loss: 0.0495
Validation Accuracy: 0.9852
Overfitting: 0.0477
Best model saved at epoch 10 with validation loss: 0.0495
[Epoch 11, Batch 100] loss: 0.018651982011506335
[Epoch 11, Batch 200] loss: 0.021156722091254777
[Epoch 11, Batch 300] loss: 0.02332226055848878
[Epoch 11, Batch 400] loss: 0.023707156786113046
[Epoch 11, Batch 500] loss: 0.022015638418379238
[Epoch 11, Batch 600] loss: 0.0251711215855903
[Epoch 11, Batch 700] loss: 0.024587213957565836
**STATS for Epoch 11** : 
Average training loss: 0.0019
Average validation loss: 0.0497
Validation Accuracy: 0.9856
Overfitting: 0.0478
[Epoch 12, Batch 100] loss: 0.019833620039280506
[Epoch 12, Batch 200] loss: 0.020500980821088886
[Epoch 12, Batch 300] loss: 0.02117637403920526
[Epoch 12, Batch 400] loss: 0.01935519733146066
[Epoch 12, Batch 500] loss: 0.02058800042839721
[Epoch 12, Batch 600] loss: 0.024534257955965585
[Epoch 12, Batch 700] loss: 0.023724501290125773
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0557
Validation Accuracy: 0.9842
Overfitting: 0.0545
[Epoch 13, Batch 100] loss: 0.019090683171525596
[Epoch 13, Batch 200] loss: 0.015232798488577828
[Epoch 13, Batch 300] loss: 0.018652761251432823
[Epoch 13, Batch 400] loss: 0.019942022864124737
[Epoch 13, Batch 500] loss: 0.016091298017272493
[Epoch 13, Batch 600] loss: 0.017942713433294556
[Epoch 13, Batch 700] loss: 0.01596540044149151
**STATS for Epoch 13** : 
Average training loss: 0.0015
Average validation loss: 0.0498
Validation Accuracy: 0.9870
Overfitting: 0.0483
[Epoch 14, Batch 100] loss: 0.013078114435775206
[Epoch 14, Batch 200] loss: 0.01372482790146023
[Epoch 14, Batch 300] loss: 0.014469210792594823
[Epoch 14, Batch 400] loss: 0.018450128113036045
[Epoch 14, Batch 500] loss: 0.017247834065346978
[Epoch 14, Batch 600] loss: 0.0162958976480877
[Epoch 14, Batch 700] loss: 0.013252689279615879
**STATS for Epoch 14** : 
Average training loss: 0.0017
Average validation loss: 0.0654
Validation Accuracy: 0.9798
Overfitting: 0.0637
[Epoch 15, Batch 100] loss: 0.009000041901599616
[Epoch 15, Batch 200] loss: 0.010994146108278074
[Epoch 15, Batch 300] loss: 0.014980177745746915
[Epoch 15, Batch 400] loss: 0.016917127577617066
[Epoch 15, Batch 500] loss: 0.016006652409269007
[Epoch 15, Batch 600] loss: 0.016828662781626917
[Epoch 15, Batch 700] loss: 0.016861856682226062
**STATS for Epoch 15** : 
Average training loss: 0.0011
Average validation loss: 0.0495
Validation Accuracy: 0.9872
Overfitting: 0.0484
[Epoch 16, Batch 100] loss: 0.008645954745297786
[Epoch 16, Batch 200] loss: 0.010638948088453616
[Epoch 16, Batch 300] loss: 0.008775867156509775
[Epoch 16, Batch 400] loss: 0.012468714013812133
[Epoch 16, Batch 500] loss: 0.013269897686550394
[Epoch 16, Batch 600] loss: 0.008583632758090971
[Epoch 16, Batch 700] loss: 0.012258864868344972
**STATS for Epoch 16** : 
Average training loss: 0.0012
Average validation loss: 0.0491
Validation Accuracy: 0.9871
Overfitting: 0.0479
Best model saved at epoch 16 with validation loss: 0.0491
[Epoch 17, Batch 100] loss: 0.00861554273593356
[Epoch 17, Batch 200] loss: 0.008227744951000204
[Epoch 17, Batch 300] loss: 0.00988055413326947
[Epoch 17, Batch 400] loss: 0.011348945638528675
[Epoch 17, Batch 500] loss: 0.013860138354939409
[Epoch 17, Batch 600] loss: 0.008802926214848412
[Epoch 17, Batch 700] loss: 0.013876408425567206
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0522
Validation Accuracy: 0.9857
Overfitting: 0.0515
[Epoch 18, Batch 100] loss: 0.00796133854673826
[Epoch 18, Batch 200] loss: 0.007559601722168736
[Epoch 18, Batch 300] loss: 0.007922684466539067
[Epoch 18, Batch 400] loss: 0.007114464452970423
[Epoch 18, Batch 500] loss: 0.012178908102287096
[Epoch 18, Batch 600] loss: 0.0071312163585389495
[Epoch 18, Batch 700] loss: 0.008013084219564917
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0552
Validation Accuracy: 0.9855
Overfitting: 0.0545
[Epoch 19, Batch 100] loss: 0.009110924015476484
[Epoch 19, Batch 200] loss: 0.00651968359365128
[Epoch 19, Batch 300] loss: 0.007651335331465816
[Epoch 19, Batch 400] loss: 0.011070429190076538
[Epoch 19, Batch 500] loss: 0.009498227399235474
[Epoch 19, Batch 600] loss: 0.010252841850524419
[Epoch 19, Batch 700] loss: 0.010708213532725495
**STATS for Epoch 19** : 
Average training loss: 0.0011
Average validation loss: 0.0505
Validation Accuracy: 0.9872
Overfitting: 0.0494
[Epoch 20, Batch 100] loss: 0.006497159707068931
[Epoch 20, Batch 200] loss: 0.003998987806771766
[Epoch 20, Batch 300] loss: 0.005317128545830201
[Epoch 20, Batch 400] loss: 0.009015630029316525
[Epoch 20, Batch 500] loss: 0.008860023021552478
[Epoch 20, Batch 600] loss: 0.008549886275504832
[Epoch 20, Batch 700] loss: 0.010208557861333248
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0541
Validation Accuracy: 0.9868
Overfitting: 0.0535
[Epoch 21, Batch 100] loss: 0.004492556604964193
[Epoch 21, Batch 200] loss: 0.005711827530576557
[Epoch 21, Batch 300] loss: 0.0044789089858386436
[Epoch 21, Batch 400] loss: 0.006124614185100654
[Epoch 21, Batch 500] loss: 0.003957369233721693
[Epoch 21, Batch 600] loss: 0.011122791961606709
[Epoch 21, Batch 700] loss: 0.008518783474355586
**STATS for Epoch 21** : 
Average training loss: 0.0008
Average validation loss: 0.0577
Validation Accuracy: 0.9872
Overfitting: 0.0568
[Epoch 22, Batch 100] loss: 0.0037951327228984157
[Epoch 22, Batch 200] loss: 0.006414481360843638
[Epoch 22, Batch 300] loss: 0.005472357478938647
[Epoch 22, Batch 400] loss: 0.006622797362724669
[Epoch 22, Batch 500] loss: 0.004424252423796134
[Epoch 22, Batch 600] loss: 0.003460663511395978
[Epoch 22, Batch 700] loss: 0.00453698674125917
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0604
Validation Accuracy: 0.9862
Overfitting: 0.0599
[Epoch 23, Batch 100] loss: 0.005669256781511649
[Epoch 23, Batch 200] loss: 0.0028078569445278844
[Epoch 23, Batch 300] loss: 0.0027976027816475836
[Epoch 23, Batch 400] loss: 0.0036962847531685837
[Epoch 23, Batch 500] loss: 0.00653689520804619
[Epoch 23, Batch 600] loss: 0.004946603641255934
[Epoch 23, Batch 700] loss: 0.00313093964021391
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0534
Validation Accuracy: 0.9872
Overfitting: 0.0531
[Epoch 24, Batch 100] loss: 0.0020829769612828388
[Epoch 24, Batch 200] loss: 0.003688921635484803
[Epoch 24, Batch 300] loss: 0.004435466146460385
[Epoch 24, Batch 400] loss: 0.003546458657015137
[Epoch 24, Batch 500] loss: 0.0038683311441400294
[Epoch 24, Batch 600] loss: 0.002727778599874
[Epoch 24, Batch 700] loss: 0.002722885106340982
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0523
Validation Accuracy: 0.9884
Overfitting: 0.0521
Fold 3 validation loss: 0.0523
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.231111605167389
[Epoch 1, Batch 200] loss: 1.0236362624168396
[Epoch 1, Batch 300] loss: 0.4413202004134655
[Epoch 1, Batch 400] loss: 0.2919801387935877
[Epoch 1, Batch 500] loss: 0.2522029796987772
[Epoch 1, Batch 600] loss: 0.20133375376462936
[Epoch 1, Batch 700] loss: 0.1781038893200457
**STATS for Epoch 1** : 
Average training loss: 0.0117
Average validation loss: 0.1459
Validation Accuracy: 0.9557
Overfitting: 0.1342
Best model saved at epoch 1 with validation loss: 0.1459
[Epoch 2, Batch 100] loss: 0.1530661553516984
[Epoch 2, Batch 200] loss: 0.13699945917353035
[Epoch 2, Batch 300] loss: 0.11874053874984383
[Epoch 2, Batch 400] loss: 0.11600698433816432
[Epoch 2, Batch 500] loss: 0.10493529926985502
[Epoch 2, Batch 600] loss: 0.10803525740280748
[Epoch 2, Batch 700] loss: 0.09543434051796794
**STATS for Epoch 2** : 
Average training loss: 0.0058
Average validation loss: 0.0829
Validation Accuracy: 0.9735
Overfitting: 0.0771
Best model saved at epoch 2 with validation loss: 0.0829
[Epoch 3, Batch 100] loss: 0.09267488315701485
[Epoch 3, Batch 200] loss: 0.08264617531560361
[Epoch 3, Batch 300] loss: 0.07299071505665779
[Epoch 3, Batch 400] loss: 0.08417115881107748
[Epoch 3, Batch 500] loss: 0.07343390913680196
[Epoch 3, Batch 600] loss: 0.07614103986881673
[Epoch 3, Batch 700] loss: 0.07702624022495001
**STATS for Epoch 3** : 
Average training loss: 0.0062
Average validation loss: 0.0968
Validation Accuracy: 0.9680
Overfitting: 0.0906
[Epoch 4, Batch 100] loss: 0.06747959600761533
[Epoch 4, Batch 200] loss: 0.07025791818276048
[Epoch 4, Batch 300] loss: 0.060736469295807186
[Epoch 4, Batch 400] loss: 0.05923122182488441
[Epoch 4, Batch 500] loss: 0.06758381298743188
[Epoch 4, Batch 600] loss: 0.061810746146366
[Epoch 4, Batch 700] loss: 0.07186582553200424
**STATS for Epoch 4** : 
Average training loss: 0.0035
Average validation loss: 0.0558
Validation Accuracy: 0.9838
Overfitting: 0.0523
Best model saved at epoch 4 with validation loss: 0.0558
[Epoch 5, Batch 100] loss: 0.051869289986789226
[Epoch 5, Batch 200] loss: 0.04575390466954559
[Epoch 5, Batch 300] loss: 0.057061932939104734
[Epoch 5, Batch 400] loss: 0.05283515722025186
[Epoch 5, Batch 500] loss: 0.05194762433413416
[Epoch 5, Batch 600] loss: 0.05448675649706274
[Epoch 5, Batch 700] loss: 0.054781356824096294
**STATS for Epoch 5** : 
Average training loss: 0.0035
Average validation loss: 0.0545
Validation Accuracy: 0.9825
Overfitting: 0.0510
Best model saved at epoch 5 with validation loss: 0.0545
[Epoch 6, Batch 100] loss: 0.04588150712894276
[Epoch 6, Batch 200] loss: 0.04544696202268824
[Epoch 6, Batch 300] loss: 0.03692827379563823
[Epoch 6, Batch 400] loss: 0.045983669513370844
[Epoch 6, Batch 500] loss: 0.0434634250914678
[Epoch 6, Batch 600] loss: 0.04611726704868488
[Epoch 6, Batch 700] loss: 0.0558907425403595
**STATS for Epoch 6** : 
Average training loss: 0.0032
Average validation loss: 0.0489
Validation Accuracy: 0.9849
Overfitting: 0.0457
Best model saved at epoch 6 with validation loss: 0.0489
[Epoch 7, Batch 100] loss: 0.038773455751361326
[Epoch 7, Batch 200] loss: 0.03558308012550697
[Epoch 7, Batch 300] loss: 0.03801175224361941
[Epoch 7, Batch 400] loss: 0.037311530322767794
[Epoch 7, Batch 500] loss: 0.0313029273878783
[Epoch 7, Batch 600] loss: 0.039935622045304625
[Epoch 7, Batch 700] loss: 0.04092570293229073
**STATS for Epoch 7** : 
Average training loss: 0.0024
Average validation loss: 0.0489
Validation Accuracy: 0.9847
Overfitting: 0.0465
Best model saved at epoch 7 with validation loss: 0.0489
[Epoch 8, Batch 100] loss: 0.02564747785567306
[Epoch 8, Batch 200] loss: 0.03311827769095544
[Epoch 8, Batch 300] loss: 0.027146335698198527
[Epoch 8, Batch 400] loss: 0.041218872382305566
[Epoch 8, Batch 500] loss: 0.03646536277374253
[Epoch 8, Batch 600] loss: 0.030852154882159085
[Epoch 8, Batch 700] loss: 0.03539228765293956
**STATS for Epoch 8** : 
Average training loss: 0.0022
Average validation loss: 0.0465
Validation Accuracy: 0.9857
Overfitting: 0.0443
Best model saved at epoch 8 with validation loss: 0.0465
[Epoch 9, Batch 100] loss: 0.02465084640891291
[Epoch 9, Batch 200] loss: 0.033040500107454136
[Epoch 9, Batch 300] loss: 0.03217783597763628
[Epoch 9, Batch 400] loss: 0.026019492654595525
[Epoch 9, Batch 500] loss: 0.026925896413158627
[Epoch 9, Batch 600] loss: 0.025664989021606743
[Epoch 9, Batch 700] loss: 0.028977582703810185
**STATS for Epoch 9** : 
Average training loss: 0.0019
Average validation loss: 0.0454
Validation Accuracy: 0.9861
Overfitting: 0.0434
Best model saved at epoch 9 with validation loss: 0.0454
[Epoch 10, Batch 100] loss: 0.021792510586674325
[Epoch 10, Batch 200] loss: 0.027767556102480738
[Epoch 10, Batch 300] loss: 0.02494414009503089
[Epoch 10, Batch 400] loss: 0.026559569999808446
[Epoch 10, Batch 500] loss: 0.022040703002130613
[Epoch 10, Batch 600] loss: 0.025382922918652184
[Epoch 10, Batch 700] loss: 0.02675868302816525
**STATS for Epoch 10** : 
Average training loss: 0.0018
Average validation loss: 0.0403
Validation Accuracy: 0.9878
Overfitting: 0.0385
Best model saved at epoch 10 with validation loss: 0.0403
[Epoch 11, Batch 100] loss: 0.02030192257137969
[Epoch 11, Batch 200] loss: 0.019852434446220285
[Epoch 11, Batch 300] loss: 0.024945573374279776
[Epoch 11, Batch 400] loss: 0.023875071150250733
[Epoch 11, Batch 500] loss: 0.028694346632109954
[Epoch 11, Batch 600] loss: 0.01945540603410336
[Epoch 11, Batch 700] loss: 0.024821337764442432
**STATS for Epoch 11** : 
Average training loss: 0.0020
Average validation loss: 0.0457
Validation Accuracy: 0.9845
Overfitting: 0.0437
[Epoch 12, Batch 100] loss: 0.02140545076574199
[Epoch 12, Batch 200] loss: 0.018671018935565373
[Epoch 12, Batch 300] loss: 0.0216121062845923
[Epoch 12, Batch 400] loss: 0.02239342748274794
[Epoch 12, Batch 500] loss: 0.01940135987009853
[Epoch 12, Batch 600] loss: 0.01850680178584298
[Epoch 12, Batch 700] loss: 0.017436750269844196
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0389
Validation Accuracy: 0.9884
Overfitting: 0.0379
Best model saved at epoch 12 with validation loss: 0.0389
[Epoch 13, Batch 100] loss: 0.016047182822367178
[Epoch 13, Batch 200] loss: 0.014497786867432296
[Epoch 13, Batch 300] loss: 0.018702809303067624
[Epoch 13, Batch 400] loss: 0.015352078034775332
[Epoch 13, Batch 500] loss: 0.017929204041720367
[Epoch 13, Batch 600] loss: 0.016679444366600363
[Epoch 13, Batch 700] loss: 0.017111318224924617
**STATS for Epoch 13** : 
Average training loss: 0.0013
Average validation loss: 0.0442
Validation Accuracy: 0.9880
Overfitting: 0.0429
[Epoch 14, Batch 100] loss: 0.013704569248802726
[Epoch 14, Batch 200] loss: 0.010135597784537822
[Epoch 14, Batch 300] loss: 0.013570876279263757
[Epoch 14, Batch 400] loss: 0.019537310423620512
[Epoch 14, Batch 500] loss: 0.017964406591199803
[Epoch 14, Batch 600] loss: 0.014202127546741394
[Epoch 14, Batch 700] loss: 0.015594187632377726
**STATS for Epoch 14** : 
Average training loss: 0.0011
Average validation loss: 0.0417
Validation Accuracy: 0.9872
Overfitting: 0.0406
[Epoch 15, Batch 100] loss: 0.01265775134350406
[Epoch 15, Batch 200] loss: 0.016970018511638044
[Epoch 15, Batch 300] loss: 0.015366691369272302
[Epoch 15, Batch 400] loss: 0.010462187270022696
[Epoch 15, Batch 500] loss: 0.012805605229950744
[Epoch 15, Batch 600] loss: 0.01277363354252884
[Epoch 15, Batch 700] loss: 0.01184835871172254
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0378
Validation Accuracy: 0.9882
Overfitting: 0.0370
Best model saved at epoch 15 with validation loss: 0.0378
[Epoch 16, Batch 100] loss: 0.01207042996014934
[Epoch 16, Batch 200] loss: 0.00998044067498995
[Epoch 16, Batch 300] loss: 0.010442868951067795
[Epoch 16, Batch 400] loss: 0.013600866767665138
[Epoch 16, Batch 500] loss: 0.010314176435640547
[Epoch 16, Batch 600] loss: 0.015083635677874553
[Epoch 16, Batch 700] loss: 0.012423987957154168
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0456
Validation Accuracy: 0.9860
Overfitting: 0.0450
[Epoch 17, Batch 100] loss: 0.009963071998063242
[Epoch 17, Batch 200] loss: 0.008435937190297409
[Epoch 17, Batch 300] loss: 0.008535798325174255
[Epoch 17, Batch 400] loss: 0.014101638487773016
[Epoch 17, Batch 500] loss: 0.012325926921475912
[Epoch 17, Batch 600] loss: 0.012293951915344223
[Epoch 17, Batch 700] loss: 0.01109949788893573
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0437
Validation Accuracy: 0.9873
Overfitting: 0.0431
[Epoch 18, Batch 100] loss: 0.007013203216629336
[Epoch 18, Batch 200] loss: 0.007525635646597948
[Epoch 18, Batch 300] loss: 0.0067934758054616394
[Epoch 18, Batch 400] loss: 0.008954150544450385
[Epoch 18, Batch 500] loss: 0.008594249003435835
[Epoch 18, Batch 600] loss: 0.014779146771761589
[Epoch 18, Batch 700] loss: 0.011029833237553249
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0400
Validation Accuracy: 0.9893
Overfitting: 0.0395
[Epoch 19, Batch 100] loss: 0.00812371456740948
[Epoch 19, Batch 200] loss: 0.006074225764969014
[Epoch 19, Batch 300] loss: 0.006489818388290587
[Epoch 19, Batch 400] loss: 0.007612830466459854
[Epoch 19, Batch 500] loss: 0.013835612994080293
[Epoch 19, Batch 600] loss: 0.008955959886225173
[Epoch 19, Batch 700] loss: 0.008863958326910506
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0421
Validation Accuracy: 0.9878
Overfitting: 0.0417
[Epoch 20, Batch 100] loss: 0.007224904136965051
[Epoch 20, Batch 200] loss: 0.0036691697750939056
[Epoch 20, Batch 300] loss: 0.006237283863447374
[Epoch 20, Batch 400] loss: 0.008517675264265563
[Epoch 20, Batch 500] loss: 0.008049233523306611
[Epoch 20, Batch 600] loss: 0.010559910520678386
[Epoch 20, Batch 700] loss: 0.00863795607976499
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0412
Validation Accuracy: 0.9885
Overfitting: 0.0408
[Epoch 21, Batch 100] loss: 0.005016752224837546
[Epoch 21, Batch 200] loss: 0.005149979116104078
[Epoch 21, Batch 300] loss: 0.007954550087742974
[Epoch 21, Batch 400] loss: 0.007535786409353023
[Epoch 21, Batch 500] loss: 0.008103734977121349
[Epoch 21, Batch 600] loss: 0.006740421270806109
[Epoch 21, Batch 700] loss: 0.006127184143988416
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0408
Validation Accuracy: 0.9888
Overfitting: 0.0404
[Epoch 22, Batch 100] loss: 0.0037229341400689007
[Epoch 22, Batch 200] loss: 0.006678096205068869
[Epoch 22, Batch 300] loss: 0.002989556444263144
[Epoch 22, Batch 400] loss: 0.005412047838453873
[Epoch 22, Batch 500] loss: 0.007351971336756833
[Epoch 22, Batch 600] loss: 0.005283548867300852
[Epoch 22, Batch 700] loss: 0.0037889866501791404
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0421
Validation Accuracy: 0.9888
Overfitting: 0.0416
[Epoch 23, Batch 100] loss: 0.002810100150127255
[Epoch 23, Batch 200] loss: 0.003959067941650574
[Epoch 23, Batch 300] loss: 0.0037684096710654557
[Epoch 23, Batch 400] loss: 0.003484357805009495
[Epoch 23, Batch 500] loss: 0.005000477925359519
[Epoch 23, Batch 600] loss: 0.004413173843240656
[Epoch 23, Batch 700] loss: 0.004400713924114825
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0437
Validation Accuracy: 0.9886
Overfitting: 0.0430
[Epoch 24, Batch 100] loss: 0.0023284319932099606
[Epoch 24, Batch 200] loss: 0.0037640445082433873
[Epoch 24, Batch 300] loss: 0.0028315753833157943
[Epoch 24, Batch 400] loss: 0.002678173970671196
[Epoch 24, Batch 500] loss: 0.0030809056357247754
[Epoch 24, Batch 600] loss: 0.002562703947251066
[Epoch 24, Batch 700] loss: 0.003743307393451687
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0583
Validation Accuracy: 0.9862
Overfitting: 0.0578
Fold 4 validation loss: 0.0583
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.1809253132343294
[Epoch 1, Batch 200] loss: 0.8147230839729309
[Epoch 1, Batch 300] loss: 0.39542604103684426
[Epoch 1, Batch 400] loss: 0.2982786974310875
[Epoch 1, Batch 500] loss: 0.24432772904634475
[Epoch 1, Batch 600] loss: 0.2056425443291664
[Epoch 1, Batch 700] loss: 0.18388071991503238
**STATS for Epoch 1** : 
Average training loss: 0.0104
Average validation loss: 0.1614
Validation Accuracy: 0.9525
Overfitting: 0.1509
Best model saved at epoch 1 with validation loss: 0.1614
[Epoch 2, Batch 100] loss: 0.158793462254107
[Epoch 2, Batch 200] loss: 0.14505558244884015
[Epoch 2, Batch 300] loss: 0.13365808675065638
[Epoch 2, Batch 400] loss: 0.1197331060282886
[Epoch 2, Batch 500] loss: 0.11586475064978004
[Epoch 2, Batch 600] loss: 0.10225021734833717
[Epoch 2, Batch 700] loss: 0.10021711261011661
**STATS for Epoch 2** : 
Average training loss: 0.0074
Average validation loss: 0.0905
Validation Accuracy: 0.9738
Overfitting: 0.0831
Best model saved at epoch 2 with validation loss: 0.0905
[Epoch 3, Batch 100] loss: 0.08693540565669537
[Epoch 3, Batch 200] loss: 0.09751784233376384
[Epoch 3, Batch 300] loss: 0.08223685434088111
[Epoch 3, Batch 400] loss: 0.08412479008547961
[Epoch 3, Batch 500] loss: 0.08123948351480066
[Epoch 3, Batch 600] loss: 0.07868563213385642
[Epoch 3, Batch 700] loss: 0.07350482070818544
**STATS for Epoch 3** : 
Average training loss: 0.0056
Average validation loss: 0.0786
Validation Accuracy: 0.9781
Overfitting: 0.0730
Best model saved at epoch 3 with validation loss: 0.0786
[Epoch 4, Batch 100] loss: 0.06283967352937907
[Epoch 4, Batch 200] loss: 0.07441385794430971
[Epoch 4, Batch 300] loss: 0.06883541817776859
[Epoch 4, Batch 400] loss: 0.06340745450928807
[Epoch 4, Batch 500] loss: 0.0711440524738282
[Epoch 4, Batch 600] loss: 0.06133757782168686
[Epoch 4, Batch 700] loss: 0.07250111604575067
**STATS for Epoch 4** : 
Average training loss: 0.0036
Average validation loss: 0.0648
Validation Accuracy: 0.9819
Overfitting: 0.0612
Best model saved at epoch 4 with validation loss: 0.0648
[Epoch 5, Batch 100] loss: 0.0501664050645195
[Epoch 5, Batch 200] loss: 0.06163596793543547
[Epoch 5, Batch 300] loss: 0.05992918224772439
[Epoch 5, Batch 400] loss: 0.05386695145862177
[Epoch 5, Batch 500] loss: 0.0514069809904322
[Epoch 5, Batch 600] loss: 0.05876158973202109
[Epoch 5, Batch 700] loss: 0.05880465604364872
**STATS for Epoch 5** : 
Average training loss: 0.0037
Average validation loss: 0.0615
Validation Accuracy: 0.9819
Overfitting: 0.0578
Best model saved at epoch 5 with validation loss: 0.0615
[Epoch 6, Batch 100] loss: 0.05630861017620191
[Epoch 6, Batch 200] loss: 0.048454299778677525
[Epoch 6, Batch 300] loss: 0.053509360402822496
[Epoch 6, Batch 400] loss: 0.045630993973463777
[Epoch 6, Batch 500] loss: 0.04811728967353702
[Epoch 6, Batch 600] loss: 0.04889068549033254
[Epoch 6, Batch 700] loss: 0.051057882830500605
**STATS for Epoch 6** : 
Average training loss: 0.0027
Average validation loss: 0.0536
Validation Accuracy: 0.9845
Overfitting: 0.0509
Best model saved at epoch 6 with validation loss: 0.0536
[Epoch 7, Batch 100] loss: 0.04594565131701529
[Epoch 7, Batch 200] loss: 0.04298670579912141
[Epoch 7, Batch 300] loss: 0.040933081819675865
[Epoch 7, Batch 400] loss: 0.04541154976468533
[Epoch 7, Batch 500] loss: 0.04353475618874654
[Epoch 7, Batch 600] loss: 0.04048116055782884
[Epoch 7, Batch 700] loss: 0.04714008514827583
**STATS for Epoch 7** : 
Average training loss: 0.0030
Average validation loss: 0.0716
Validation Accuracy: 0.9787
Overfitting: 0.0686
[Epoch 8, Batch 100] loss: 0.03512598040746525
[Epoch 8, Batch 200] loss: 0.04217366269906051
[Epoch 8, Batch 300] loss: 0.03593778526643291
[Epoch 8, Batch 400] loss: 0.03956392277032137
[Epoch 8, Batch 500] loss: 0.037754958102013916
[Epoch 8, Batch 600] loss: 0.04053860756917857
[Epoch 8, Batch 700] loss: 0.03778987069497816
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0472
Validation Accuracy: 0.9865
Overfitting: 0.0448
Best model saved at epoch 8 with validation loss: 0.0472
[Epoch 9, Batch 100] loss: 0.030207707201479934
[Epoch 9, Batch 200] loss: 0.026173590758698993
[Epoch 9, Batch 300] loss: 0.03295260526181664
[Epoch 9, Batch 400] loss: 0.033656740131555125
[Epoch 9, Batch 500] loss: 0.03145881876873318
[Epoch 9, Batch 600] loss: 0.03915736724156886
[Epoch 9, Batch 700] loss: 0.032767671432811764
**STATS for Epoch 9** : 
Average training loss: 0.0023
Average validation loss: 0.0471
Validation Accuracy: 0.9867
Overfitting: 0.0448
Best model saved at epoch 9 with validation loss: 0.0471
[Epoch 10, Batch 100] loss: 0.030525966191198677
[Epoch 10, Batch 200] loss: 0.028664343581185678
[Epoch 10, Batch 300] loss: 0.026742675189161673
[Epoch 10, Batch 400] loss: 0.03214844270027242
[Epoch 10, Batch 500] loss: 0.025986730000004173
[Epoch 10, Batch 600] loss: 0.026603021355695092
[Epoch 10, Batch 700] loss: 0.03467134950333275
**STATS for Epoch 10** : 
Average training loss: 0.0017
Average validation loss: 0.0531
Validation Accuracy: 0.9848
Overfitting: 0.0514
[Epoch 11, Batch 100] loss: 0.030678030789131297
[Epoch 11, Batch 200] loss: 0.026944221710728015
[Epoch 11, Batch 300] loss: 0.026466140423435716
[Epoch 11, Batch 400] loss: 0.030382012304035016
[Epoch 11, Batch 500] loss: 0.02951060719205998
[Epoch 11, Batch 600] loss: 0.020420239779050463
[Epoch 11, Batch 700] loss: 0.02505211966112256
**STATS for Epoch 11** : 
Average training loss: 0.0021
Average validation loss: 0.0487
Validation Accuracy: 0.9857
Overfitting: 0.0466
[Epoch 12, Batch 100] loss: 0.02093593079072889
[Epoch 12, Batch 200] loss: 0.020974344626301898
[Epoch 12, Batch 300] loss: 0.024522802281426268
[Epoch 12, Batch 400] loss: 0.023968159942887722
[Epoch 12, Batch 500] loss: 0.025544549259357154
[Epoch 12, Batch 600] loss: 0.02795007571694441
[Epoch 12, Batch 700] loss: 0.01680909653601702
**STATS for Epoch 12** : 
Average training loss: 0.0020
Average validation loss: 0.0464
Validation Accuracy: 0.9860
Overfitting: 0.0444
Best model saved at epoch 12 with validation loss: 0.0464
[Epoch 13, Batch 100] loss: 0.01510352197510656
[Epoch 13, Batch 200] loss: 0.019665569647331724
[Epoch 13, Batch 300] loss: 0.019908937225700356
[Epoch 13, Batch 400] loss: 0.01915459974348778
[Epoch 13, Batch 500] loss: 0.02350401389878243
[Epoch 13, Batch 600] loss: 0.020461103340494446
[Epoch 13, Batch 700] loss: 0.021422149263089524
**STATS for Epoch 13** : 
Average training loss: 0.0015
Average validation loss: 0.0454
Validation Accuracy: 0.9875
Overfitting: 0.0439
Best model saved at epoch 13 with validation loss: 0.0454
[Epoch 14, Batch 100] loss: 0.01809156241361052
[Epoch 14, Batch 200] loss: 0.018982222039776387
[Epoch 14, Batch 300] loss: 0.019879655287077184
[Epoch 14, Batch 400] loss: 0.016276756843726616
[Epoch 14, Batch 500] loss: 0.01582392471987987
[Epoch 14, Batch 600] loss: 0.020463267670857023
[Epoch 14, Batch 700] loss: 0.014397048964165151
**STATS for Epoch 14** : 
Average training loss: 0.0014
Average validation loss: 0.0449
Validation Accuracy: 0.9882
Overfitting: 0.0436
Best model saved at epoch 14 with validation loss: 0.0449
[Epoch 15, Batch 100] loss: 0.015939285501081032
[Epoch 15, Batch 200] loss: 0.01485841251560487
[Epoch 15, Batch 300] loss: 0.013743284725060222
[Epoch 15, Batch 400] loss: 0.01745514685782837
[Epoch 15, Batch 500] loss: 0.020105647235614015
[Epoch 15, Batch 600] loss: 0.015997487490676577
[Epoch 15, Batch 700] loss: 0.016578336591192056
**STATS for Epoch 15** : 
Average training loss: 0.0014
Average validation loss: 0.0408
Validation Accuracy: 0.9888
Overfitting: 0.0395
Best model saved at epoch 15 with validation loss: 0.0408
[Epoch 16, Batch 100] loss: 0.010947949709225214
[Epoch 16, Batch 200] loss: 0.01581092560023535
[Epoch 16, Batch 300] loss: 0.011756717231473885
[Epoch 16, Batch 400] loss: 0.013644496868073475
[Epoch 16, Batch 500] loss: 0.011182934330354328
[Epoch 16, Batch 600] loss: 0.010049132417625515
[Epoch 16, Batch 700] loss: 0.021786844490270595
**STATS for Epoch 16** : 
Average training loss: 0.0015
Average validation loss: 0.0455
Validation Accuracy: 0.9884
Overfitting: 0.0440
[Epoch 17, Batch 100] loss: 0.011195085858198582
[Epoch 17, Batch 200] loss: 0.01156996572681237
[Epoch 17, Batch 300] loss: 0.011296769162581767
[Epoch 17, Batch 400] loss: 0.009791108689678368
[Epoch 17, Batch 500] loss: 0.015053781941533088
[Epoch 17, Batch 600] loss: 0.01690419156715507
[Epoch 17, Batch 700] loss: 0.014201589988078921
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0406
Validation Accuracy: 0.9889
Overfitting: 0.0397
Best model saved at epoch 17 with validation loss: 0.0406
[Epoch 18, Batch 100] loss: 0.010914593234556378
[Epoch 18, Batch 200] loss: 0.011620758742792532
[Epoch 18, Batch 300] loss: 0.010038325146160787
[Epoch 18, Batch 400] loss: 0.00923844569173525
[Epoch 18, Batch 500] loss: 0.00964350119291339
[Epoch 18, Batch 600] loss: 0.010605315896173124
[Epoch 18, Batch 700] loss: 0.014873608400957892
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0424
Validation Accuracy: 0.9892
Overfitting: 0.0415
[Epoch 19, Batch 100] loss: 0.008003915333902115
[Epoch 19, Batch 200] loss: 0.008100700473005418
[Epoch 19, Batch 300] loss: 0.010204936962254578
[Epoch 19, Batch 400] loss: 0.010638290853457875
[Epoch 19, Batch 500] loss: 0.013730611063292599
[Epoch 19, Batch 600] loss: 0.009669874580577015
[Epoch 19, Batch 700] loss: 0.012458080049764248
**STATS for Epoch 19** : 
Average training loss: 0.0009
Average validation loss: 0.0504
Validation Accuracy: 0.9874
Overfitting: 0.0495
[Epoch 20, Batch 100] loss: 0.008025214708177374
[Epoch 20, Batch 200] loss: 0.007341250317767845
[Epoch 20, Batch 300] loss: 0.00967365968732338
[Epoch 20, Batch 400] loss: 0.006450749692121462
[Epoch 20, Batch 500] loss: 0.008742299212462968
[Epoch 20, Batch 600] loss: 0.008680363973653585
[Epoch 20, Batch 700] loss: 0.011422167704513413
**STATS for Epoch 20** : 
Average training loss: 0.0008
Average validation loss: 0.0492
Validation Accuracy: 0.9884
Overfitting: 0.0485
[Epoch 21, Batch 100] loss: 0.009591790530976141
[Epoch 21, Batch 200] loss: 0.0053967187861417186
[Epoch 21, Batch 300] loss: 0.007113417176515213
[Epoch 21, Batch 400] loss: 0.005707348451032886
[Epoch 21, Batch 500] loss: 0.008984480725775939
[Epoch 21, Batch 600] loss: 0.006465066018026846
[Epoch 21, Batch 700] loss: 0.007743491535620706
**STATS for Epoch 21** : 
Average training loss: 0.0008
Average validation loss: 0.0470
Validation Accuracy: 0.9896
Overfitting: 0.0462
[Epoch 22, Batch 100] loss: 0.00405447448243649
[Epoch 22, Batch 200] loss: 0.00553055246367876
[Epoch 22, Batch 300] loss: 0.007699108223459916
[Epoch 22, Batch 400] loss: 0.008040315402031411
[Epoch 22, Batch 500] loss: 0.007899615109909063
[Epoch 22, Batch 600] loss: 0.007211301825154805
[Epoch 22, Batch 700] loss: 0.008543732446196373
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0473
Validation Accuracy: 0.9891
Overfitting: 0.0468
[Epoch 23, Batch 100] loss: 0.006420074832640239
[Epoch 23, Batch 200] loss: 0.008454817215897492
[Epoch 23, Batch 300] loss: 0.00499966761268297
[Epoch 23, Batch 400] loss: 0.004581535481484025
[Epoch 23, Batch 500] loss: 0.007899987097334814
[Epoch 23, Batch 600] loss: 0.007387701130792266
[Epoch 23, Batch 700] loss: 0.005013535400030378
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0453
Validation Accuracy: 0.9894
Overfitting: 0.0447
[Epoch 24, Batch 100] loss: 0.002680461266063503
[Epoch 24, Batch 200] loss: 0.005865080693329219
[Epoch 24, Batch 300] loss: 0.006144093691837042
[Epoch 24, Batch 400] loss: 0.0068715479924139795
[Epoch 24, Batch 500] loss: 0.00512793266439985
[Epoch 24, Batch 600] loss: 0.006843698209486319
[Epoch 24, Batch 700] loss: 0.004932863315407304
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0463
Validation Accuracy: 0.9893
Overfitting: 0.0460
Fold 5 validation loss: 0.0463
Mean validation loss across all folds for Trial 10 is 0.0522 with trial config:  l1: 256, l2: 128, lr: 0.0026936379642822942, batch_size: 64
[I 2024-12-11 03:36:19,546] Trial 9 finished with value: 0.052157658089951854 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0026936379642822942, 'batch_size': 64}. Best is trial 2 with value: 0.05047263894358398.

Selected Hyperparameters for Trial 11:
  l1: 128, l2: 128, lr: 0.0008921058725659591, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3013237833976747
[Epoch 1, Batch 200] loss: 2.287520523071289
[Epoch 1, Batch 300] loss: 2.263249201774597
**STATS for Epoch 1** : 
Average training loss: 0.4415
Average validation loss: 2.1586
Validation Accuracy: 0.3758
Overfitting: 1.7171
Best model saved at epoch 1 with validation loss: 2.1586
[Epoch 2, Batch 100] loss: 1.96048548579216
[Epoch 2, Batch 200] loss: 1.0695360016822815
[Epoch 2, Batch 300] loss: 0.589290599822998
**STATS for Epoch 2** : 
Average training loss: 0.0946
Average validation loss: 0.4134
Validation Accuracy: 0.8808
Overfitting: 0.3188
Best model saved at epoch 2 with validation loss: 0.4134
[Epoch 3, Batch 100] loss: 0.4008313246071339
[Epoch 3, Batch 200] loss: 0.35564171940088274
[Epoch 3, Batch 300] loss: 0.31606500804424287
**STATS for Epoch 3** : 
Average training loss: 0.0582
Average validation loss: 0.2731
Validation Accuracy: 0.9177
Overfitting: 0.2149
Best model saved at epoch 3 with validation loss: 0.2731
[Epoch 4, Batch 100] loss: 0.26072785280644895
[Epoch 4, Batch 200] loss: 0.24598292872309685
[Epoch 4, Batch 300] loss: 0.22879948273301123
**STATS for Epoch 4** : 
Average training loss: 0.0470
Average validation loss: 0.1967
Validation Accuracy: 0.9418
Overfitting: 0.1497
Best model saved at epoch 4 with validation loss: 0.1967
[Epoch 5, Batch 100] loss: 0.20373470932245255
[Epoch 5, Batch 200] loss: 0.1891140142828226
[Epoch 5, Batch 300] loss: 0.18470830895006657
**STATS for Epoch 5** : 
Average training loss: 0.0367
Average validation loss: 0.1678
Validation Accuracy: 0.9498
Overfitting: 0.1311
Best model saved at epoch 5 with validation loss: 0.1678
[Epoch 6, Batch 100] loss: 0.1609655349701643
[Epoch 6, Batch 200] loss: 0.16696904808282853
[Epoch 6, Batch 300] loss: 0.15485592849552632
**STATS for Epoch 6** : 
Average training loss: 0.0308
Average validation loss: 0.1388
Validation Accuracy: 0.9574
Overfitting: 0.1079
Best model saved at epoch 6 with validation loss: 0.1388
[Epoch 7, Batch 100] loss: 0.14373946093022824
[Epoch 7, Batch 200] loss: 0.13277679782360793
[Epoch 7, Batch 300] loss: 0.14260778713971375
**STATS for Epoch 7** : 
Average training loss: 0.0246
Average validation loss: 0.1210
Validation Accuracy: 0.9614
Overfitting: 0.0964
Best model saved at epoch 7 with validation loss: 0.1210
[Epoch 8, Batch 100] loss: 0.1266649105772376
[Epoch 8, Batch 200] loss: 0.12521926879882814
[Epoch 8, Batch 300] loss: 0.11705656237900257
**STATS for Epoch 8** : 
Average training loss: 0.0236
Average validation loss: 0.1127
Validation Accuracy: 0.9637
Overfitting: 0.0891
Best model saved at epoch 8 with validation loss: 0.1127
[Epoch 9, Batch 100] loss: 0.11236794665455818
[Epoch 9, Batch 200] loss: 0.11204010745510459
[Epoch 9, Batch 300] loss: 0.11392875349149108
**STATS for Epoch 9** : 
Average training loss: 0.0200
Average validation loss: 0.0983
Validation Accuracy: 0.9686
Overfitting: 0.0783
[I 2024-12-11 03:37:41,934] Trial 10 pruned. 

Selected Hyperparameters for Trial 12:
  l1: 256, l2: 128, lr: 0.008332334231893158, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.9038424223661423
[Epoch 1, Batch 200] loss: 0.421608866751194
[Epoch 1, Batch 300] loss: 0.23160180039703845
[Epoch 1, Batch 400] loss: 0.16181250929832458
[Epoch 1, Batch 500] loss: 0.13561597920954227
[Epoch 1, Batch 600] loss: 0.11763378160074353
[Epoch 1, Batch 700] loss: 0.09615911860018969
**STATS for Epoch 1** : 
Average training loss: 0.0066
Average validation loss: 0.0845
Validation Accuracy: 0.9738
Overfitting: 0.0779
Best model saved at epoch 1 with validation loss: 0.0845
[Epoch 2, Batch 100] loss: 0.08748984662815928
[Epoch 2, Batch 200] loss: 0.08389297980815172
[Epoch 2, Batch 300] loss: 0.07453300956636667
[Epoch 2, Batch 400] loss: 0.07568662772886454
[Epoch 2, Batch 500] loss: 0.06676417366834357
[Epoch 2, Batch 600] loss: 0.07338956046849489
[Epoch 2, Batch 700] loss: 0.06863949562422932
**STATS for Epoch 2** : 
Average training loss: 0.0047
Average validation loss: 0.0721
Validation Accuracy: 0.9776
Overfitting: 0.0675
Best model saved at epoch 2 with validation loss: 0.0721
[Epoch 3, Batch 100] loss: 0.0496822720952332
[Epoch 3, Batch 200] loss: 0.049431782835163175
[Epoch 3, Batch 300] loss: 0.043743408182635904
[Epoch 3, Batch 400] loss: 0.05527480330783874
[Epoch 3, Batch 500] loss: 0.04928457223810256
[Epoch 3, Batch 600] loss: 0.04789939176524058
[Epoch 3, Batch 700] loss: 0.04823373728781007
**STATS for Epoch 3** : 
Average training loss: 0.0040
Average validation loss: 0.0560
Validation Accuracy: 0.9835
Overfitting: 0.0519
Best model saved at epoch 3 with validation loss: 0.0560
[Epoch 4, Batch 100] loss: 0.04223038564901799
[Epoch 4, Batch 200] loss: 0.03902320128516294
[Epoch 4, Batch 300] loss: 0.04375251199817285
[Epoch 4, Batch 400] loss: 0.03708876774064265
[Epoch 4, Batch 500] loss: 0.03785465619759634
[Epoch 4, Batch 600] loss: 0.03492344731290359
[Epoch 4, Batch 700] loss: 0.038495400749379766
**STATS for Epoch 4** : 
Average training loss: 0.0018
Average validation loss: 0.0440
Validation Accuracy: 0.9864
Overfitting: 0.0422
Best model saved at epoch 4 with validation loss: 0.0440
[Epoch 5, Batch 100] loss: 0.02835316155804321
[Epoch 5, Batch 200] loss: 0.0335966630501207
[Epoch 5, Batch 300] loss: 0.025909546181792392
[Epoch 5, Batch 400] loss: 0.0251088366744807
[Epoch 5, Batch 500] loss: 0.03785255560069345
[Epoch 5, Batch 600] loss: 0.0306309006200172
[Epoch 5, Batch 700] loss: 0.027795205462025477
**STATS for Epoch 5** : 
Average training loss: 0.0014
Average validation loss: 0.0529
Validation Accuracy: 0.9848
Overfitting: 0.0515
[Epoch 6, Batch 100] loss: 0.02430922581872437
[Epoch 6, Batch 200] loss: 0.018359766626381314
[Epoch 6, Batch 300] loss: 0.026209903792478145
[Epoch 6, Batch 400] loss: 0.02374827649007784
[Epoch 6, Batch 500] loss: 0.027327575670205988
[Epoch 6, Batch 600] loss: 0.025896280212618875
[Epoch 6, Batch 700] loss: 0.03213357022672426
**STATS for Epoch 6** : 
Average training loss: 0.0016
Average validation loss: 0.0552
Validation Accuracy: 0.9844
Overfitting: 0.0536
[Epoch 7, Batch 100] loss: 0.01739583964794292
[Epoch 7, Batch 200] loss: 0.01831291601731209
[Epoch 7, Batch 300] loss: 0.019745655280567008
[Epoch 7, Batch 400] loss: 0.018569346962322014
[Epoch 7, Batch 500] loss: 0.024487619443098085
[Epoch 7, Batch 600] loss: 0.022912668924545868
[Epoch 7, Batch 700] loss: 0.027145147258706856
**STATS for Epoch 7** : 
Average training loss: 0.0009
Average validation loss: 0.0364
Validation Accuracy: 0.9892
Overfitting: 0.0355
Best model saved at epoch 7 with validation loss: 0.0364
[Epoch 8, Batch 100] loss: 0.01161563098357874
[Epoch 8, Batch 200] loss: 0.011300269137282158
[Epoch 8, Batch 300] loss: 0.016126997642495554
[Epoch 8, Batch 400] loss: 0.018445617894176394
[Epoch 8, Batch 500] loss: 0.01793292398186168
[Epoch 8, Batch 600] loss: 0.01735187980288174
[Epoch 8, Batch 700] loss: 0.018589657211850862
**STATS for Epoch 8** : 
Average training loss: 0.0010
Average validation loss: 0.0430
Validation Accuracy: 0.9869
Overfitting: 0.0419
[Epoch 9, Batch 100] loss: 0.015394213208346628
[Epoch 9, Batch 200] loss: 0.009743424953194335
[Epoch 9, Batch 300] loss: 0.016721159952285233
[Epoch 9, Batch 400] loss: 0.011389743052277482
[Epoch 9, Batch 500] loss: 0.01717529500492674
[Epoch 9, Batch 600] loss: 0.01149174913065508
[Epoch 9, Batch 700] loss: 0.012618406372603204
**STATS for Epoch 9** : 
Average training loss: 0.0011
Average validation loss: 0.0410
Validation Accuracy: 0.9891
Overfitting: 0.0400
[Epoch 10, Batch 100] loss: 0.012826299359512633
[Epoch 10, Batch 200] loss: 0.0068083740981455775
[Epoch 10, Batch 300] loss: 0.013362287890049628
[Epoch 10, Batch 400] loss: 0.011793639902607537
[Epoch 10, Batch 500] loss: 0.011093429024258512
[Epoch 10, Batch 600] loss: 0.01100210989916377
[Epoch 10, Batch 700] loss: 0.012052777490462177
**STATS for Epoch 10** : 
Average training loss: 0.0010
Average validation loss: 0.0442
Validation Accuracy: 0.9882
Overfitting: 0.0433
[Epoch 11, Batch 100] loss: 0.007649636592977913
[Epoch 11, Batch 200] loss: 0.004833771244739183
[Epoch 11, Batch 300] loss: 0.007010756593344923
[Epoch 11, Batch 400] loss: 0.010766308074307744
[Epoch 11, Batch 500] loss: 0.00944320463197073
[Epoch 11, Batch 600] loss: 0.014569652468926506
[Epoch 11, Batch 700] loss: 0.013058233115225448
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0406
Validation Accuracy: 0.9889
Overfitting: 0.0398
[Epoch 12, Batch 100] loss: 0.006985561452893307
[Epoch 12, Batch 200] loss: 0.004867249654053012
[Epoch 12, Batch 300] loss: 0.006466429587107996
[Epoch 12, Batch 400] loss: 0.0039509367060964
[Epoch 12, Batch 500] loss: 0.0055513324095409185
[Epoch 12, Batch 600] loss: 0.005954712977654708
[Epoch 12, Batch 700] loss: 0.004492552119409084
**STATS for Epoch 12** : 
Average training loss: 0.0006
Average validation loss: 0.0516
Validation Accuracy: 0.9870
Overfitting: 0.0510
[Epoch 13, Batch 100] loss: 0.0042296898465428966
[Epoch 13, Batch 200] loss: 0.0031641689897151082
[Epoch 13, Batch 300] loss: 0.004023111597507523
[Epoch 13, Batch 400] loss: 0.008973530431903782
[Epoch 13, Batch 500] loss: 0.0050724484993588705
[Epoch 13, Batch 600] loss: 0.011304602024265477
[Epoch 13, Batch 700] loss: 0.01180164606685139
**STATS for Epoch 13** : 
Average training loss: 0.0004
Average validation loss: 0.0427
Validation Accuracy: 0.9898
Overfitting: 0.0423
[Epoch 14, Batch 100] loss: 0.005055537050211569
[Epoch 14, Batch 200] loss: 0.005392495803071142
[Epoch 14, Batch 300] loss: 0.004689074485722813
[Epoch 14, Batch 400] loss: 0.002507751682642265
[Epoch 14, Batch 500] loss: 0.0028883287792723423
[Epoch 14, Batch 600] loss: 0.0022482077894756002
[Epoch 14, Batch 700] loss: 0.008782485349966009
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0566
Validation Accuracy: 0.9872
Overfitting: 0.0561
[Epoch 15, Batch 100] loss: 0.008937603202803075
[Epoch 15, Batch 200] loss: 0.00541664710144687
[Epoch 15, Batch 300] loss: 0.0036136485809765873
[Epoch 15, Batch 400] loss: 0.0054346572552640285
[Epoch 15, Batch 500] loss: 0.007388631298399559
[Epoch 15, Batch 600] loss: 0.0049566172059257955
[Epoch 15, Batch 700] loss: 0.004168873766902834
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0565
Validation Accuracy: 0.9870
Overfitting: 0.0558
[Epoch 16, Batch 100] loss: 0.006315195018814847
[Epoch 16, Batch 200] loss: 0.005042471448305151
[Epoch 16, Batch 300] loss: 0.007127148601848603
[Epoch 16, Batch 400] loss: 0.0054333806061367795
[Epoch 16, Batch 500] loss: 0.009637022912647808
[Epoch 16, Batch 600] loss: 0.007339283047185745
[Epoch 16, Batch 700] loss: 0.004290837299922714
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0473
Validation Accuracy: 0.9889
Overfitting: 0.0470
[Epoch 17, Batch 100] loss: 0.004799088172421762
[Epoch 17, Batch 200] loss: 0.00492439011712122
[Epoch 17, Batch 300] loss: 0.0031178459606235266
[Epoch 17, Batch 400] loss: 0.0033308437175764995
[Epoch 17, Batch 500] loss: 0.0033339389433058387
[Epoch 17, Batch 600] loss: 0.002077015022332489
[Epoch 17, Batch 700] loss: 0.0015264150962161693
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0444
Validation Accuracy: 0.9910
Overfitting: 0.0443
[Epoch 18, Batch 100] loss: 0.0009349213289078762
[Epoch 18, Batch 200] loss: 0.0012740926397827935
[Epoch 18, Batch 300] loss: 0.0017526454065944109
[Epoch 18, Batch 400] loss: 0.0013624026893762674
[Epoch 18, Batch 500] loss: 0.0021723002680710123
[Epoch 18, Batch 600] loss: 0.001235796289092832
[Epoch 18, Batch 700] loss: 0.001536606105919418
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0482
Validation Accuracy: 0.9908
Overfitting: 0.0481
[Epoch 19, Batch 100] loss: 0.0009141459744955682
[Epoch 19, Batch 200] loss: 0.0005199677681343929
[Epoch 19, Batch 300] loss: 0.00035025793275963226
[Epoch 19, Batch 400] loss: 0.0006459903449899684
[Epoch 19, Batch 500] loss: 0.0005185488209872347
[Epoch 19, Batch 600] loss: 0.0006607930943005158
[Epoch 19, Batch 700] loss: 0.0009081856494412932
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0463
Validation Accuracy: 0.9910
Overfitting: 0.0462
[Epoch 20, Batch 100] loss: 0.0004021839870426902
[Epoch 20, Batch 200] loss: 0.0005886049183476416
[Epoch 20, Batch 300] loss: 0.000743006280681584
[Epoch 20, Batch 400] loss: 0.0005715291079374652
[Epoch 20, Batch 500] loss: 0.0007308499536588897
[Epoch 20, Batch 600] loss: 0.001563449109247017
[Epoch 20, Batch 700] loss: 0.0005592361749154406
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9903
Overfitting: 0.0488
[Epoch 21, Batch 100] loss: 0.00031645444300238524
[Epoch 21, Batch 200] loss: 0.0003209805982578473
[Epoch 21, Batch 300] loss: 0.0003378337808385368
[Epoch 21, Batch 400] loss: 0.00029825932199898373
[Epoch 21, Batch 500] loss: 0.0003129470130352274
[Epoch 21, Batch 600] loss: 0.0005766087262924202
[Epoch 21, Batch 700] loss: 0.0003763367735882639
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9907
Overfitting: 0.0486
[Epoch 22, Batch 100] loss: 0.0001311031789083472
[Epoch 22, Batch 200] loss: 0.0001611566974924017
[Epoch 22, Batch 300] loss: 0.000268961602263289
[Epoch 22, Batch 400] loss: 0.00030755799289011065
[Epoch 22, Batch 500] loss: 0.0005018843517224525
[Epoch 22, Batch 600] loss: 0.00036847237151960144
[Epoch 22, Batch 700] loss: 0.00036476327615616813
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0475
Validation Accuracy: 0.9904
Overfitting: 0.0474
[Epoch 23, Batch 100] loss: 0.000670611065830542
[Epoch 23, Batch 200] loss: 0.0016785403640432151
[Epoch 23, Batch 300] loss: 0.00020306326413106036
[Epoch 23, Batch 400] loss: 0.0002322544976416907
[Epoch 23, Batch 500] loss: 0.00017557004607425596
[Epoch 23, Batch 600] loss: 0.0003288262588409907
[Epoch 23, Batch 700] loss: 0.00014207511289839658
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9905
Overfitting: 0.0520
[Epoch 24, Batch 100] loss: 0.0003013166792783295
[Epoch 24, Batch 200] loss: 0.00013141607913610186
[Epoch 24, Batch 300] loss: 0.0002608219272349288
[Epoch 24, Batch 400] loss: 0.00025775286951102317
[Epoch 24, Batch 500] loss: 0.00035783654762411743
[Epoch 24, Batch 600] loss: 0.00033662999927855706
[Epoch 24, Batch 700] loss: 0.0004217373779249556
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9905
Overfitting: 0.0497
Fold 1 validation loss: 0.0497
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.9944888955354692
[Epoch 1, Batch 200] loss: 0.39552245050668716
[Epoch 1, Batch 300] loss: 0.2049376728758216
[Epoch 1, Batch 400] loss: 0.1571545422822237
[Epoch 1, Batch 500] loss: 0.13795606356114148
[Epoch 1, Batch 600] loss: 0.11640977039933205
[Epoch 1, Batch 700] loss: 0.1050366007257253
**STATS for Epoch 1** : 
Average training loss: 0.0059
Average validation loss: 0.1090
Validation Accuracy: 0.9673
Overfitting: 0.1031
Best model saved at epoch 1 with validation loss: 0.1090
[Epoch 2, Batch 100] loss: 0.08181842112913727
[Epoch 2, Batch 200] loss: 0.08165247392840684
[Epoch 2, Batch 300] loss: 0.07366891965735704
[Epoch 2, Batch 400] loss: 0.07998152075335384
[Epoch 2, Batch 500] loss: 0.06564198654610663
[Epoch 2, Batch 600] loss: 0.07333523167762905
[Epoch 2, Batch 700] loss: 0.06775833998806774
**STATS for Epoch 2** : 
Average training loss: 0.0039
Average validation loss: 0.0802
Validation Accuracy: 0.9735
Overfitting: 0.0763
Best model saved at epoch 2 with validation loss: 0.0802
[Epoch 3, Batch 100] loss: 0.05972833272768185
[Epoch 3, Batch 200] loss: 0.058955684182001276
[Epoch 3, Batch 300] loss: 0.042476566396653655
[Epoch 3, Batch 400] loss: 0.051062613239046185
[Epoch 3, Batch 500] loss: 0.04963630958576687
[Epoch 3, Batch 600] loss: 0.0445212800509762
[Epoch 3, Batch 700] loss: 0.054328342236112805
**STATS for Epoch 3** : 
Average training loss: 0.0028
Average validation loss: 0.0535
Validation Accuracy: 0.9827
Overfitting: 0.0507
Best model saved at epoch 3 with validation loss: 0.0535
[Epoch 4, Batch 100] loss: 0.03279131640214473
[Epoch 4, Batch 200] loss: 0.03619199363165535
[Epoch 4, Batch 300] loss: 0.031860092874849213
[Epoch 4, Batch 400] loss: 0.03851774309994653
[Epoch 4, Batch 500] loss: 0.03701647584792227
[Epoch 4, Batch 600] loss: 0.04557359434198588
[Epoch 4, Batch 700] loss: 0.03661959208548069
**STATS for Epoch 4** : 
Average training loss: 0.0029
Average validation loss: 0.0596
Validation Accuracy: 0.9817
Overfitting: 0.0567
[Epoch 5, Batch 100] loss: 0.03871361001336481
[Epoch 5, Batch 200] loss: 0.02660482479957864
[Epoch 5, Batch 300] loss: 0.03661252405145206
[Epoch 5, Batch 400] loss: 0.03205987313820515
[Epoch 5, Batch 500] loss: 0.03855357298918534
[Epoch 5, Batch 600] loss: 0.029143430295516737
[Epoch 5, Batch 700] loss: 0.028532047264743596
**STATS for Epoch 5** : 
Average training loss: 0.0021
Average validation loss: 0.0468
Validation Accuracy: 0.9852
Overfitting: 0.0448
Best model saved at epoch 5 with validation loss: 0.0468
[Epoch 6, Batch 100] loss: 0.026344236684963107
[Epoch 6, Batch 200] loss: 0.024462719101575204
[Epoch 6, Batch 300] loss: 0.022329489432304398
[Epoch 6, Batch 400] loss: 0.022979052579030393
[Epoch 6, Batch 500] loss: 0.03368202914600261
[Epoch 6, Batch 600] loss: 0.023652262608520686
[Epoch 6, Batch 700] loss: 0.022858173215281566
**STATS for Epoch 6** : 
Average training loss: 0.0016
Average validation loss: 0.0554
Validation Accuracy: 0.9828
Overfitting: 0.0539
[Epoch 7, Batch 100] loss: 0.01964532699144911
[Epoch 7, Batch 200] loss: 0.017020906284305966
[Epoch 7, Batch 300] loss: 0.023587015843659173
[Epoch 7, Batch 400] loss: 0.02046396082470892
[Epoch 7, Batch 500] loss: 0.02151172113924986
[Epoch 7, Batch 600] loss: 0.020163493208237925
[Epoch 7, Batch 700] loss: 0.026417607595794833
**STATS for Epoch 7** : 
Average training loss: 0.0020
Average validation loss: 0.0547
Validation Accuracy: 0.9838
Overfitting: 0.0527
[Epoch 8, Batch 100] loss: 0.015338880271156086
[Epoch 8, Batch 200] loss: 0.014067139591352315
[Epoch 8, Batch 300] loss: 0.01830289473218727
[Epoch 8, Batch 400] loss: 0.018328772191889584
[Epoch 8, Batch 500] loss: 0.0215671548989485
[Epoch 8, Batch 600] loss: 0.020898540466150736
[Epoch 8, Batch 700] loss: 0.015886125420074677
**STATS for Epoch 8** : 
Average training loss: 0.0013
Average validation loss: 0.0575
Validation Accuracy: 0.9847
Overfitting: 0.0562
[Epoch 9, Batch 100] loss: 0.008617413501197007
[Epoch 9, Batch 200] loss: 0.01040407059910649
[Epoch 9, Batch 300] loss: 0.01752133991525625
[Epoch 9, Batch 400] loss: 0.009125581007101573
[Epoch 9, Batch 500] loss: 0.008904698958795053
[Epoch 9, Batch 600] loss: 0.011080906331126244
[Epoch 9, Batch 700] loss: 0.017065210104010475
**STATS for Epoch 9** : 
Average training loss: 0.0011
Average validation loss: 0.0530
Validation Accuracy: 0.9850
Overfitting: 0.0520
[Epoch 10, Batch 100] loss: 0.012421417911064055
[Epoch 10, Batch 200] loss: 0.013444289470062359
[Epoch 10, Batch 300] loss: 0.010811340205764281
[Epoch 10, Batch 400] loss: 0.012130299830023433
[Epoch 10, Batch 500] loss: 0.010203114954565535
[Epoch 10, Batch 600] loss: 0.009274571167406976
[Epoch 10, Batch 700] loss: 0.009593357371068123
**STATS for Epoch 10** : 
Average training loss: 0.0008
Average validation loss: 0.0597
Validation Accuracy: 0.9846
Overfitting: 0.0589
[Epoch 11, Batch 100] loss: 0.005531361532812298
[Epoch 11, Batch 200] loss: 0.009241974988690345
[Epoch 11, Batch 300] loss: 0.011620924147428014
[Epoch 11, Batch 400] loss: 0.005789850678193034
[Epoch 11, Batch 500] loss: 0.012542359529370516
[Epoch 11, Batch 600] loss: 0.012077730607798003
[Epoch 11, Batch 700] loss: 0.010392725209730997
**STATS for Epoch 11** : 
Average training loss: 0.0007
Average validation loss: 0.0507
Validation Accuracy: 0.9873
Overfitting: 0.0500
[Epoch 12, Batch 100] loss: 0.007391477009732626
[Epoch 12, Batch 200] loss: 0.006881646757774433
[Epoch 12, Batch 300] loss: 0.004495499496097182
[Epoch 12, Batch 400] loss: 0.008395566156523274
[Epoch 12, Batch 500] loss: 0.00822349524456513
[Epoch 12, Batch 600] loss: 0.0074763031011752905
[Epoch 12, Batch 700] loss: 0.007803924433592329
**STATS for Epoch 12** : 
Average training loss: 0.0005
Average validation loss: 0.0566
Validation Accuracy: 0.9858
Overfitting: 0.0560
[Epoch 13, Batch 100] loss: 0.00879396215586894
[Epoch 13, Batch 200] loss: 0.011318274013756308
[Epoch 13, Batch 300] loss: 0.005992711062599482
[Epoch 13, Batch 400] loss: 0.00802997012355263
[Epoch 13, Batch 500] loss: 0.005891174476428205
[Epoch 13, Batch 600] loss: 0.012949045021437088
[Epoch 13, Batch 700] loss: 0.013439446112570294
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0576
Validation Accuracy: 0.9857
Overfitting: 0.0568
[Epoch 14, Batch 100] loss: 0.005660150183612132
[Epoch 14, Batch 200] loss: 0.0025252675231149622
[Epoch 14, Batch 300] loss: 0.00320845477362127
[Epoch 14, Batch 400] loss: 0.004888459606372635
[Epoch 14, Batch 500] loss: 0.010214173658905566
[Epoch 14, Batch 600] loss: 0.006016965098579022
[Epoch 14, Batch 700] loss: 0.007496809132881026
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0523
Validation Accuracy: 0.9871
Overfitting: 0.0519
[Epoch 15, Batch 100] loss: 0.0049695555869129745
[Epoch 15, Batch 200] loss: 0.006961956141003612
[Epoch 15, Batch 300] loss: 0.007541830833697531
[Epoch 15, Batch 400] loss: 0.005742096419799054
[Epoch 15, Batch 500] loss: 0.003036305421246652
[Epoch 15, Batch 600] loss: 0.00542848734465224
[Epoch 15, Batch 700] loss: 0.009169210229865712
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0590
Validation Accuracy: 0.9865
Overfitting: 0.0586
[Epoch 16, Batch 100] loss: 0.0021079791970623775
[Epoch 16, Batch 200] loss: 0.0015588019879078274
[Epoch 16, Batch 300] loss: 0.002538715245786989
[Epoch 16, Batch 400] loss: 0.00508746495246669
[Epoch 16, Batch 500] loss: 0.0048825398051167215
[Epoch 16, Batch 600] loss: 0.0028111986741987493
[Epoch 16, Batch 700] loss: 0.004838361103720672
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0595
Validation Accuracy: 0.9869
Overfitting: 0.0589
[Epoch 17, Batch 100] loss: 0.005131362302818161
[Epoch 17, Batch 200] loss: 0.0028211211525103865
[Epoch 17, Batch 300] loss: 0.0027893709490854233
[Epoch 17, Batch 400] loss: 0.0026605573971642117
[Epoch 17, Batch 500] loss: 0.0022911331991599584
[Epoch 17, Batch 600] loss: 0.0026257395522725348
[Epoch 17, Batch 700] loss: 0.0024729510355564342
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0521
Validation Accuracy: 0.9884
Overfitting: 0.0520
[Epoch 18, Batch 100] loss: 0.001094708252635428
[Epoch 18, Batch 200] loss: 0.001273291728480217
[Epoch 18, Batch 300] loss: 0.0005590566990086643
[Epoch 18, Batch 400] loss: 0.0008247223673038207
[Epoch 18, Batch 500] loss: 0.0027411758838036347
[Epoch 18, Batch 600] loss: 0.0012186024239986182
[Epoch 18, Batch 700] loss: 0.000749762229110047
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0548
Validation Accuracy: 0.9885
Overfitting: 0.0548
[Epoch 19, Batch 100] loss: 0.00044770344980406664
[Epoch 19, Batch 200] loss: 0.000575380048394436
[Epoch 19, Batch 300] loss: 0.0006762993215443202
[Epoch 19, Batch 400] loss: 0.0005617073572807385
[Epoch 19, Batch 500] loss: 0.0008985885195284027
[Epoch 19, Batch 600] loss: 0.0017100507147711141
[Epoch 19, Batch 700] loss: 0.0038291716100684425
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0728
Validation Accuracy: 0.9845
Overfitting: 0.0726
[Epoch 20, Batch 100] loss: 0.0025166194759412975
[Epoch 20, Batch 200] loss: 0.0015227663066428932
[Epoch 20, Batch 300] loss: 0.002232154877711707
[Epoch 20, Batch 400] loss: 0.002553685921162696
[Epoch 20, Batch 500] loss: 0.004894134822413889
[Epoch 20, Batch 600] loss: 0.006490271403238239
[Epoch 20, Batch 700] loss: 0.003133535201163795
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0612
Validation Accuracy: 0.9873
Overfitting: 0.0610
[Epoch 21, Batch 100] loss: 0.003027365002071747
[Epoch 21, Batch 200] loss: 0.001348407458158789
[Epoch 21, Batch 300] loss: 0.004223765236407644
[Epoch 21, Batch 400] loss: 0.007078110210584327
[Epoch 21, Batch 500] loss: 0.004223318509762066
[Epoch 21, Batch 600] loss: 0.013610617075746631
[Epoch 21, Batch 700] loss: 0.007058210832719851
**STATS for Epoch 21** : 
Average training loss: 0.0009
Average validation loss: 0.0722
Validation Accuracy: 0.9849
Overfitting: 0.0713
[Epoch 22, Batch 100] loss: 0.0044331955971529165
[Epoch 22, Batch 200] loss: 0.009006675782784442
[Epoch 22, Batch 300] loss: 0.008743229583974426
[Epoch 22, Batch 400] loss: 0.012977159230613324
[Epoch 22, Batch 500] loss: 0.007504891866283288
[Epoch 22, Batch 600] loss: 0.004309086887342346
[Epoch 22, Batch 700] loss: 0.006044453623617301
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0655
Validation Accuracy: 0.9876
Overfitting: 0.0653
[Epoch 23, Batch 100] loss: 0.003851419750906189
[Epoch 23, Batch 200] loss: 0.0028266052182254952
[Epoch 23, Batch 300] loss: 0.004155452757083821
[Epoch 23, Batch 400] loss: 0.004065746086514537
[Epoch 23, Batch 500] loss: 0.006081952241911495
[Epoch 23, Batch 600] loss: 0.0054205972115960325
[Epoch 23, Batch 700] loss: 0.00572969833133584
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0617
Validation Accuracy: 0.9879
Overfitting: 0.0615
[Epoch 24, Batch 100] loss: 0.001984986577309655
[Epoch 24, Batch 200] loss: 0.0012892879243008792
[Epoch 24, Batch 300] loss: 0.0021559673839806237
[Epoch 24, Batch 400] loss: 0.0020224495583261158
[Epoch 24, Batch 500] loss: 0.0021887901398486066
[Epoch 24, Batch 600] loss: 0.0025338041521376906
[Epoch 24, Batch 700] loss: 0.002378793883931962
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0691
Validation Accuracy: 0.9862
Overfitting: 0.0687
Fold 2 validation loss: 0.0691
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 1.7181217473745347
[Epoch 1, Batch 200] loss: 0.31612460732460024
[Epoch 1, Batch 300] loss: 0.1861595954746008
[Epoch 1, Batch 400] loss: 0.14864227924495935
[Epoch 1, Batch 500] loss: 0.13839385338127613
[Epoch 1, Batch 600] loss: 0.11184237206354737
[Epoch 1, Batch 700] loss: 0.09437320542521775
**STATS for Epoch 1** : 
Average training loss: 0.0072
Average validation loss: 0.0835
Validation Accuracy: 0.9742
Overfitting: 0.0762
Best model saved at epoch 1 with validation loss: 0.0835
[Epoch 2, Batch 100] loss: 0.07755317852832377
[Epoch 2, Batch 200] loss: 0.08311675237491727
[Epoch 2, Batch 300] loss: 0.07158486275468022
[Epoch 2, Batch 400] loss: 0.07206639925017953
[Epoch 2, Batch 500] loss: 0.06604303991422057
[Epoch 2, Batch 600] loss: 0.07040183833800256
[Epoch 2, Batch 700] loss: 0.06329933733213693
**STATS for Epoch 2** : 
Average training loss: 0.0041
Average validation loss: 0.0650
Validation Accuracy: 0.9795
Overfitting: 0.0609
Best model saved at epoch 2 with validation loss: 0.0650
[Epoch 3, Batch 100] loss: 0.0478378741000779
[Epoch 3, Batch 200] loss: 0.05190484474296682
[Epoch 3, Batch 300] loss: 0.04826182527234778
[Epoch 3, Batch 400] loss: 0.04926207041135058
[Epoch 3, Batch 500] loss: 0.04990034516202286
[Epoch 3, Batch 600] loss: 0.04995676852762699
[Epoch 3, Batch 700] loss: 0.05457966575864703
**STATS for Epoch 3** : 
Average training loss: 0.0032
Average validation loss: 0.0531
Validation Accuracy: 0.9832
Overfitting: 0.0499
Best model saved at epoch 3 with validation loss: 0.0531
[Epoch 4, Batch 100] loss: 0.04120483121951111
[Epoch 4, Batch 200] loss: 0.038179271332919595
[Epoch 4, Batch 300] loss: 0.03562284543178976
[Epoch 4, Batch 400] loss: 0.03923592831357382
[Epoch 4, Batch 500] loss: 0.049101242356700825
[Epoch 4, Batch 600] loss: 0.03897129855118692
[Epoch 4, Batch 700] loss: 0.03300755081465468
**STATS for Epoch 4** : 
Average training loss: 0.0030
Average validation loss: 0.0480
Validation Accuracy: 0.9852
Overfitting: 0.0450
Best model saved at epoch 4 with validation loss: 0.0480
[Epoch 5, Batch 100] loss: 0.024204236671212128
[Epoch 5, Batch 200] loss: 0.028885359772248195
[Epoch 5, Batch 300] loss: 0.04042783503886312
[Epoch 5, Batch 400] loss: 0.02995769030181691
[Epoch 5, Batch 500] loss: 0.027194165547261947
[Epoch 5, Batch 600] loss: 0.03334973104065284
[Epoch 5, Batch 700] loss: 0.036321360727306455
**STATS for Epoch 5** : 
Average training loss: 0.0020
Average validation loss: 0.0508
Validation Accuracy: 0.9842
Overfitting: 0.0488
[Epoch 6, Batch 100] loss: 0.019974441100639524
[Epoch 6, Batch 200] loss: 0.023684663647436537
[Epoch 6, Batch 300] loss: 0.020630095992819408
[Epoch 6, Batch 400] loss: 0.02812223868619185
[Epoch 6, Batch 500] loss: 0.029359327675192618
[Epoch 6, Batch 600] loss: 0.02808138068416156
[Epoch 6, Batch 700] loss: 0.03287955634819809
**STATS for Epoch 6** : 
Average training loss: 0.0013
Average validation loss: 0.0483
Validation Accuracy: 0.9857
Overfitting: 0.0471
[Epoch 7, Batch 100] loss: 0.016560934643348447
[Epoch 7, Batch 200] loss: 0.015402228788589127
[Epoch 7, Batch 300] loss: 0.024863757086568513
[Epoch 7, Batch 400] loss: 0.02031108257244341
[Epoch 7, Batch 500] loss: 0.022312966093886645
[Epoch 7, Batch 600] loss: 0.025630788302514702
[Epoch 7, Batch 700] loss: 0.02266453385411296
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0458
Validation Accuracy: 0.9878
Overfitting: 0.0438
Best model saved at epoch 7 with validation loss: 0.0458
[Epoch 8, Batch 100] loss: 0.016499292687512934
[Epoch 8, Batch 200] loss: 0.010985529510944616
[Epoch 8, Batch 300] loss: 0.015532299476180924
[Epoch 8, Batch 400] loss: 0.01581421600480098
[Epoch 8, Batch 500] loss: 0.018894615314275144
[Epoch 8, Batch 600] loss: 0.01754788878111867
[Epoch 8, Batch 700] loss: 0.018593836225627457
**STATS for Epoch 8** : 
Average training loss: 0.0012
Average validation loss: 0.0436
Validation Accuracy: 0.9870
Overfitting: 0.0424
Best model saved at epoch 8 with validation loss: 0.0436
[Epoch 9, Batch 100] loss: 0.013098523002990987
[Epoch 9, Batch 200] loss: 0.015335558123479132
[Epoch 9, Batch 300] loss: 0.010135309722681996
[Epoch 9, Batch 400] loss: 0.015140903094725218
[Epoch 9, Batch 500] loss: 0.016602987132937414
[Epoch 9, Batch 600] loss: 0.014643429609495797
[Epoch 9, Batch 700] loss: 0.016493979594888516
**STATS for Epoch 9** : 
Average training loss: 0.0015
Average validation loss: 0.0568
Validation Accuracy: 0.9847
Overfitting: 0.0553
[Epoch 10, Batch 100] loss: 0.012456977367619401
[Epoch 10, Batch 200] loss: 0.008288337160847732
[Epoch 10, Batch 300] loss: 0.011319637360065827
[Epoch 10, Batch 400] loss: 0.015370272406435105
[Epoch 10, Batch 500] loss: 0.009782643902144627
[Epoch 10, Batch 600] loss: 0.008149853397917468
[Epoch 10, Batch 700] loss: 0.00917108615671168
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0527
Validation Accuracy: 0.9868
Overfitting: 0.0512
[Epoch 11, Batch 100] loss: 0.007448064548952971
[Epoch 11, Batch 200] loss: 0.005404160431753553
[Epoch 11, Batch 300] loss: 0.006891904733201955
[Epoch 11, Batch 400] loss: 0.010721567891450831
[Epoch 11, Batch 500] loss: 0.011186784616002114
[Epoch 11, Batch 600] loss: 0.009337398278294131
[Epoch 11, Batch 700] loss: 0.015121302985353396
**STATS for Epoch 11** : 
Average training loss: 0.0006
Average validation loss: 0.0453
Validation Accuracy: 0.9878
Overfitting: 0.0447
[Epoch 12, Batch 100] loss: 0.00990421135818906
[Epoch 12, Batch 200] loss: 0.005717379097259254
[Epoch 12, Batch 300] loss: 0.004313421750557609
[Epoch 12, Batch 400] loss: 0.00940445615873159
[Epoch 12, Batch 500] loss: 0.005996430836112268
[Epoch 12, Batch 600] loss: 0.00958396722911857
[Epoch 12, Batch 700] loss: 0.0069105812615453035
**STATS for Epoch 12** : 
Average training loss: 0.0004
Average validation loss: 0.0498
Validation Accuracy: 0.9886
Overfitting: 0.0494
[Epoch 13, Batch 100] loss: 0.006933851230560322
[Epoch 13, Batch 200] loss: 0.007934699102625018
[Epoch 13, Batch 300] loss: 0.01763336739530132
[Epoch 13, Batch 400] loss: 0.01772746151640604
[Epoch 13, Batch 500] loss: 0.009375231863887166
[Epoch 13, Batch 600] loss: 0.00825062562007588
[Epoch 13, Batch 700] loss: 0.009655226622498958
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0622
Validation Accuracy: 0.9845
Overfitting: 0.0612
[Epoch 14, Batch 100] loss: 0.007998287586488004
[Epoch 14, Batch 200] loss: 0.00818163975137395
[Epoch 14, Batch 300] loss: 0.006758667445283208
[Epoch 14, Batch 400] loss: 0.005512288123136386
[Epoch 14, Batch 500] loss: 0.011936977369459782
[Epoch 14, Batch 600] loss: 0.01069066700845724
[Epoch 14, Batch 700] loss: 0.008483443084769534
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0501
Validation Accuracy: 0.9874
Overfitting: 0.0494
[Epoch 15, Batch 100] loss: 0.005482963491922419
[Epoch 15, Batch 200] loss: 0.004352559596554784
[Epoch 15, Batch 300] loss: 0.0033871930640634674
[Epoch 15, Batch 400] loss: 0.004024104374229865
[Epoch 15, Batch 500] loss: 0.006454661653669973
[Epoch 15, Batch 600] loss: 0.006698853762700309
[Epoch 15, Batch 700] loss: 0.009258248021433246
**STATS for Epoch 15** : 
Average training loss: 0.0002
Average validation loss: 0.0513
Validation Accuracy: 0.9893
Overfitting: 0.0511
[Epoch 16, Batch 100] loss: 0.004348837323723273
[Epoch 16, Batch 200] loss: 0.003399960170545455
[Epoch 16, Batch 300] loss: 0.0034589114166738
[Epoch 16, Batch 400] loss: 0.004536616502059587
[Epoch 16, Batch 500] loss: 0.0032792573987080686
[Epoch 16, Batch 600] loss: 0.0036088377960959406
[Epoch 16, Batch 700] loss: 0.0035637985892458344
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0539
Validation Accuracy: 0.9892
Overfitting: 0.0538
[Epoch 17, Batch 100] loss: 0.0009325776455739287
[Epoch 17, Batch 200] loss: 0.0008511602079397562
[Epoch 17, Batch 300] loss: 0.002609650170536497
[Epoch 17, Batch 400] loss: 0.003617391124215601
[Epoch 17, Batch 500] loss: 0.0024095062855576544
[Epoch 17, Batch 600] loss: 0.001682872945686995
[Epoch 17, Batch 700] loss: 0.0009113045171272916
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0532
Validation Accuracy: 0.9888
Overfitting: 0.0531
[Epoch 18, Batch 100] loss: 0.002028433778784802
[Epoch 18, Batch 200] loss: 0.0006677277380254054
[Epoch 18, Batch 300] loss: 0.0008713783551138476
[Epoch 18, Batch 400] loss: 0.0009029779360878365
[Epoch 18, Batch 500] loss: 0.0018743433800455023
[Epoch 18, Batch 600] loss: 0.0014497935963390773
[Epoch 18, Batch 700] loss: 0.000706485336534115
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9904
Overfitting: 0.0534
[Epoch 19, Batch 100] loss: 0.0007099587916309247
[Epoch 19, Batch 200] loss: 0.0006381963219087083
[Epoch 19, Batch 300] loss: 0.00044197408397053553
[Epoch 19, Batch 400] loss: 0.00033251110512651395
[Epoch 19, Batch 500] loss: 0.0004753714837704592
[Epoch 19, Batch 600] loss: 0.0003035551143784687
[Epoch 19, Batch 700] loss: 0.00040447036177170047
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9901
Overfitting: 0.0542
[Epoch 20, Batch 100] loss: 0.0001887541122454195
[Epoch 20, Batch 200] loss: 0.00011960877776335366
[Epoch 20, Batch 300] loss: 0.00014464918904991464
[Epoch 20, Batch 400] loss: 0.0006535381817951702
[Epoch 20, Batch 500] loss: 0.0002919699421306632
[Epoch 20, Batch 600] loss: 0.0002109152805451231
[Epoch 20, Batch 700] loss: 0.00013676103789407536
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9899
Overfitting: 0.0537
[Epoch 21, Batch 100] loss: 0.00015215355714076395
[Epoch 21, Batch 200] loss: 0.00014408346322312583
[Epoch 21, Batch 300] loss: 0.00013087425203309522
[Epoch 21, Batch 400] loss: 0.0001299082737932622
[Epoch 21, Batch 500] loss: 0.0001635965490312685
[Epoch 21, Batch 600] loss: 9.385887263633209e-05
[Epoch 21, Batch 700] loss: 0.00044411048005883915
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9909
Overfitting: 0.0548
[Epoch 22, Batch 100] loss: 0.00014835649562476406
[Epoch 22, Batch 200] loss: 0.00011288528632974248
[Epoch 22, Batch 300] loss: 9.881935406554021e-05
[Epoch 22, Batch 400] loss: 0.0001139347935236401
[Epoch 22, Batch 500] loss: 0.0001067247500319013
[Epoch 22, Batch 600] loss: 0.0001031266445829715
[Epoch 22, Batch 700] loss: 8.862201260114943e-05
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9908
Overfitting: 0.0559
[Epoch 23, Batch 100] loss: 9.164473992967715e-05
[Epoch 23, Batch 200] loss: 7.048176666899053e-05
[Epoch 23, Batch 300] loss: 0.00010734015493667925
[Epoch 23, Batch 400] loss: 8.689228236960389e-05
[Epoch 23, Batch 500] loss: 7.965351764966045e-05
[Epoch 23, Batch 600] loss: 7.651068053384336e-05
[Epoch 23, Batch 700] loss: 0.0001068001318452616
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9904
Overfitting: 0.0569
[Epoch 24, Batch 100] loss: 6.35083358216093e-05
[Epoch 24, Batch 200] loss: 7.275760286432841e-05
[Epoch 24, Batch 300] loss: 9.694987281363865e-05
[Epoch 24, Batch 400] loss: 6.477831796289024e-05
[Epoch 24, Batch 500] loss: 7.955935194736696e-05
[Epoch 24, Batch 600] loss: 8.193085975392477e-05
[Epoch 24, Batch 700] loss: 5.6604969957945176e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9902
Overfitting: 0.0576
Fold 3 validation loss: 0.0576
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.5534949684143067
[Epoch 1, Batch 200] loss: 0.343076304346323
[Epoch 1, Batch 300] loss: 0.20617323648184538
[Epoch 1, Batch 400] loss: 0.15179720740765335
[Epoch 1, Batch 500] loss: 0.14407062089070677
[Epoch 1, Batch 600] loss: 0.1266524242423475
[Epoch 1, Batch 700] loss: 0.1189856980741024
**STATS for Epoch 1** : 
Average training loss: 0.0066
Average validation loss: 0.0997
Validation Accuracy: 0.9692
Overfitting: 0.0930
Best model saved at epoch 1 with validation loss: 0.0997
[Epoch 2, Batch 100] loss: 0.08713131844066084
[Epoch 2, Batch 200] loss: 0.08474284010007978
[Epoch 2, Batch 300] loss: 0.08136058951262384
[Epoch 2, Batch 400] loss: 0.082472003265284
[Epoch 2, Batch 500] loss: 0.07064396633766591
[Epoch 2, Batch 600] loss: 0.07606831597629934
[Epoch 2, Batch 700] loss: 0.06419422149891034
**STATS for Epoch 2** : 
Average training loss: 0.0046
Average validation loss: 0.0634
Validation Accuracy: 0.9803
Overfitting: 0.0588
Best model saved at epoch 2 with validation loss: 0.0634
[Epoch 3, Batch 100] loss: 0.05745814267545939
[Epoch 3, Batch 200] loss: 0.05731218821136281
[Epoch 3, Batch 300] loss: 0.04742414195556194
[Epoch 3, Batch 400] loss: 0.05987711137160659
[Epoch 3, Batch 500] loss: 0.05679779366357252
[Epoch 3, Batch 600] loss: 0.050184283817652615
[Epoch 3, Batch 700] loss: 0.053336433434160425
**STATS for Epoch 3** : 
Average training loss: 0.0036
Average validation loss: 0.0577
Validation Accuracy: 0.9815
Overfitting: 0.0541
Best model saved at epoch 3 with validation loss: 0.0577
[Epoch 4, Batch 100] loss: 0.03480750367278233
[Epoch 4, Batch 200] loss: 0.03856688329484314
[Epoch 4, Batch 300] loss: 0.03639720675069839
[Epoch 4, Batch 400] loss: 0.04441398184513673
[Epoch 4, Batch 500] loss: 0.043661871543154124
[Epoch 4, Batch 600] loss: 0.04095086487592198
[Epoch 4, Batch 700] loss: 0.04226507172803395
**STATS for Epoch 4** : 
Average training loss: 0.0033
Average validation loss: 0.0587
Validation Accuracy: 0.9828
Overfitting: 0.0554
[Epoch 5, Batch 100] loss: 0.03004151118337177
[Epoch 5, Batch 200] loss: 0.031194043428986334
[Epoch 5, Batch 300] loss: 0.03138108037412166
[Epoch 5, Batch 400] loss: 0.03066973187844269
[Epoch 5, Batch 500] loss: 0.037700625036959534
[Epoch 5, Batch 600] loss: 0.026320369053864853
[Epoch 5, Batch 700] loss: 0.04212422069977038
**STATS for Epoch 5** : 
Average training loss: 0.0018
Average validation loss: 0.0597
Validation Accuracy: 0.9828
Overfitting: 0.0579
[Epoch 6, Batch 100] loss: 0.0290304970490979
[Epoch 6, Batch 200] loss: 0.026281591207371093
[Epoch 6, Batch 300] loss: 0.03255722221161705
[Epoch 6, Batch 400] loss: 0.027418944399105385
[Epoch 6, Batch 500] loss: 0.032828246669378135
[Epoch 6, Batch 600] loss: 0.022947721767413897
[Epoch 6, Batch 700] loss: 0.02052653257269412
**STATS for Epoch 6** : 
Average training loss: 0.0020
Average validation loss: 0.0709
Validation Accuracy: 0.9806
Overfitting: 0.0688
[Epoch 7, Batch 100] loss: 0.020368158129276708
[Epoch 7, Batch 200] loss: 0.02135755827242974
[Epoch 7, Batch 300] loss: 0.02212267198265181
[Epoch 7, Batch 400] loss: 0.02567944754875498
[Epoch 7, Batch 500] loss: 0.022802059667883443
[Epoch 7, Batch 600] loss: 0.023440185286162887
[Epoch 7, Batch 700] loss: 0.026393234029819725
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0649
Validation Accuracy: 0.9815
Overfitting: 0.0630
[Epoch 8, Batch 100] loss: 0.021473496656981297
[Epoch 8, Batch 200] loss: 0.02617391018808121
[Epoch 8, Batch 300] loss: 0.016155957899900385
[Epoch 8, Batch 400] loss: 0.013737638023303588
[Epoch 8, Batch 500] loss: 0.016361051945496002
[Epoch 8, Batch 600] loss: 0.02565692318341462
[Epoch 8, Batch 700] loss: 0.017484140739543363
**STATS for Epoch 8** : 
Average training loss: 0.0013
Average validation loss: 0.0509
Validation Accuracy: 0.9858
Overfitting: 0.0496
Best model saved at epoch 8 with validation loss: 0.0509
[Epoch 9, Batch 100] loss: 0.015162706482806243
[Epoch 9, Batch 200] loss: 0.009477454415755347
[Epoch 9, Batch 300] loss: 0.019851947817223846
[Epoch 9, Batch 400] loss: 0.013815349143806088
[Epoch 9, Batch 500] loss: 0.021841238252309266
[Epoch 9, Batch 600] loss: 0.017799621211379416
[Epoch 9, Batch 700] loss: 0.014148919852887047
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0529
Validation Accuracy: 0.9868
Overfitting: 0.0513
[Epoch 10, Batch 100] loss: 0.010086098045867402
[Epoch 10, Batch 200] loss: 0.01164947834360646
[Epoch 10, Batch 300] loss: 0.014118250021274434
[Epoch 10, Batch 400] loss: 0.015529508416948374
[Epoch 10, Batch 500] loss: 0.0135463100807101
[Epoch 10, Batch 600] loss: 0.018885854304389795
[Epoch 10, Batch 700] loss: 0.014594787234382239
**STATS for Epoch 10** : 
Average training loss: 0.0007
Average validation loss: 0.0477
Validation Accuracy: 0.9884
Overfitting: 0.0469
Best model saved at epoch 10 with validation loss: 0.0477
[Epoch 11, Batch 100] loss: 0.010213573714863741
[Epoch 11, Batch 200] loss: 0.007157339644836611
[Epoch 11, Batch 300] loss: 0.004976250066265493
[Epoch 11, Batch 400] loss: 0.012382313194284506
[Epoch 11, Batch 500] loss: 0.016072642123908736
[Epoch 11, Batch 600] loss: 0.013737695114105008
[Epoch 11, Batch 700] loss: 0.011291645794335637
**STATS for Epoch 11** : 
Average training loss: 0.0008
Average validation loss: 0.0451
Validation Accuracy: 0.9883
Overfitting: 0.0444
Best model saved at epoch 11 with validation loss: 0.0451
[Epoch 12, Batch 100] loss: 0.006642096526429668
[Epoch 12, Batch 200] loss: 0.006872830956817779
[Epoch 12, Batch 300] loss: 0.008438912432502547
[Epoch 12, Batch 400] loss: 0.00975807474937028
[Epoch 12, Batch 500] loss: 0.012654144805128453
[Epoch 12, Batch 600] loss: 0.01114591243567702
[Epoch 12, Batch 700] loss: 0.010599990229529795
**STATS for Epoch 12** : 
Average training loss: 0.0005
Average validation loss: 0.0559
Validation Accuracy: 0.9862
Overfitting: 0.0554
[Epoch 13, Batch 100] loss: 0.006306336500892939
[Epoch 13, Batch 200] loss: 0.007465544007900462
[Epoch 13, Batch 300] loss: 0.006820974586353259
[Epoch 13, Batch 400] loss: 0.005788920528739254
[Epoch 13, Batch 500] loss: 0.01201682575916493
[Epoch 13, Batch 600] loss: 0.011309374992324593
[Epoch 13, Batch 700] loss: 0.011211728220005171
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0474
Validation Accuracy: 0.9889
Overfitting: 0.0469
[Epoch 14, Batch 100] loss: 0.00499723613858805
[Epoch 14, Batch 200] loss: 0.005887989828843274
[Epoch 14, Batch 300] loss: 0.008527922383409532
[Epoch 14, Batch 400] loss: 0.006045690120026847
[Epoch 14, Batch 500] loss: 0.004498089433250243
[Epoch 14, Batch 600] loss: 0.008508178764977857
[Epoch 14, Batch 700] loss: 0.008154361628307925
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0560
Validation Accuracy: 0.9872
Overfitting: 0.0554
[Epoch 15, Batch 100] loss: 0.003058104348187953
[Epoch 15, Batch 200] loss: 0.006938195462716976
[Epoch 15, Batch 300] loss: 0.012792864885586824
[Epoch 15, Batch 400] loss: 0.006209059046691437
[Epoch 15, Batch 500] loss: 0.008014286024463217
[Epoch 15, Batch 600] loss: 0.007882730338569672
[Epoch 15, Batch 700] loss: 0.00925959836171387
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0495
Validation Accuracy: 0.9886
Overfitting: 0.0490
[Epoch 16, Batch 100] loss: 0.004068628168679425
[Epoch 16, Batch 200] loss: 0.003190783354402811
[Epoch 16, Batch 300] loss: 0.0028494381606105888
[Epoch 16, Batch 400] loss: 0.005597516884217839
[Epoch 16, Batch 500] loss: 0.006788227284569075
[Epoch 16, Batch 600] loss: 0.005684497356787688
[Epoch 16, Batch 700] loss: 0.00481709579519702
**STATS for Epoch 16** : 
Average training loss: 0.0008
Average validation loss: 0.0584
Validation Accuracy: 0.9878
Overfitting: 0.0577
[Epoch 17, Batch 100] loss: 0.0038160656932450365
[Epoch 17, Batch 200] loss: 0.003907640463912685
[Epoch 17, Batch 300] loss: 0.002857718688078421
[Epoch 17, Batch 400] loss: 0.00343198895408932
[Epoch 17, Batch 500] loss: 0.002405117331800284
[Epoch 17, Batch 600] loss: 0.005428551462382529
[Epoch 17, Batch 700] loss: 0.006179023465529098
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0709
Validation Accuracy: 0.9848
Overfitting: 0.0701
[Epoch 18, Batch 100] loss: 0.011298775093346194
[Epoch 18, Batch 200] loss: 0.005171567876250265
[Epoch 18, Batch 300] loss: 0.003810528616118063
[Epoch 18, Batch 400] loss: 0.005813384101554675
[Epoch 18, Batch 500] loss: 0.004450244520112392
[Epoch 18, Batch 600] loss: 0.008980647862072146
[Epoch 18, Batch 700] loss: 0.011263347783706195
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0619
Validation Accuracy: 0.9869
Overfitting: 0.0611
[Epoch 19, Batch 100] loss: 0.0029017264304502534
[Epoch 19, Batch 200] loss: 0.0032566630346900637
[Epoch 19, Batch 300] loss: 0.0026210904023810143
[Epoch 19, Batch 400] loss: 0.0030945379025251896
[Epoch 19, Batch 500] loss: 0.0017818315104659631
[Epoch 19, Batch 600] loss: 0.006490204942750779
[Epoch 19, Batch 700] loss: 0.003931528201010223
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0625
Validation Accuracy: 0.9862
Overfitting: 0.0623
[Epoch 20, Batch 100] loss: 0.0033939843042321625
[Epoch 20, Batch 200] loss: 0.0014251561025776028
[Epoch 20, Batch 300] loss: 0.0013146060645340186
[Epoch 20, Batch 400] loss: 0.0007440749951069847
[Epoch 20, Batch 500] loss: 0.0009844019928465287
[Epoch 20, Batch 600] loss: 0.0018137469592647904
[Epoch 20, Batch 700] loss: 0.00118809661242949
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0546
Validation Accuracy: 0.9886
Overfitting: 0.0545
[Epoch 21, Batch 100] loss: 0.0007704128574550851
[Epoch 21, Batch 200] loss: 0.002113867034769328
[Epoch 21, Batch 300] loss: 0.0017713793984165704
[Epoch 21, Batch 400] loss: 0.0011325682598345565
[Epoch 21, Batch 500] loss: 0.0029715849464651
[Epoch 21, Batch 600] loss: 0.0040740888926484335
[Epoch 21, Batch 700] loss: 0.004048289996999302
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0548
Validation Accuracy: 0.9892
Overfitting: 0.0546
[Epoch 22, Batch 100] loss: 0.0014734857778103106
[Epoch 22, Batch 200] loss: 0.0012853556288962408
[Epoch 22, Batch 300] loss: 0.0005893643891340617
[Epoch 22, Batch 400] loss: 0.0005199334897389462
[Epoch 22, Batch 500] loss: 0.00034386313203015105
[Epoch 22, Batch 600] loss: 0.00032463076845715475
[Epoch 22, Batch 700] loss: 0.00022766017228065038
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0546
Validation Accuracy: 0.9898
Overfitting: 0.0545
[Epoch 23, Batch 100] loss: 0.00038957392590020844
[Epoch 23, Batch 200] loss: 0.0002465053996604638
[Epoch 23, Batch 300] loss: 0.00020104228748465402
[Epoch 23, Batch 400] loss: 0.00024778409666396326
[Epoch 23, Batch 500] loss: 0.00017476120388721484
[Epoch 23, Batch 600] loss: 0.000750951860246687
[Epoch 23, Batch 700] loss: 0.0003237428211610904
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0562
Validation Accuracy: 0.9907
Overfitting: 0.0562
[Epoch 24, Batch 100] loss: 0.00012026509257204054
[Epoch 24, Batch 200] loss: 0.00018485393552621687
[Epoch 24, Batch 300] loss: 9.117325247057551e-05
[Epoch 24, Batch 400] loss: 0.0002534031389271263
[Epoch 24, Batch 500] loss: 0.00012106452764214737
[Epoch 24, Batch 600] loss: 0.00016855868236220317
[Epoch 24, Batch 700] loss: 0.00016754333171149937
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9904
Overfitting: 0.0569
Fold 4 validation loss: 0.0569
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 1.8246305987238884
[Epoch 1, Batch 200] loss: 0.35899022705852984
[Epoch 1, Batch 300] loss: 0.2180909502506256
[Epoch 1, Batch 400] loss: 0.14741747856140136
[Epoch 1, Batch 500] loss: 0.12289683992043138
[Epoch 1, Batch 600] loss: 0.13140661804005505
[Epoch 1, Batch 700] loss: 0.10203028302639723
**STATS for Epoch 1** : 
Average training loss: 0.0073
Average validation loss: 0.0986
Validation Accuracy: 0.9701
Overfitting: 0.0912
Best model saved at epoch 1 with validation loss: 0.0986
[Epoch 2, Batch 100] loss: 0.08173575258813798
[Epoch 2, Batch 200] loss: 0.07054539879318326
[Epoch 2, Batch 300] loss: 0.0738105493457988
[Epoch 2, Batch 400] loss: 0.07632987645687535
[Epoch 2, Batch 500] loss: 0.06965096822939813
[Epoch 2, Batch 600] loss: 0.07046707686968148
[Epoch 2, Batch 700] loss: 0.07496243566740304
**STATS for Epoch 2** : 
Average training loss: 0.0053
Average validation loss: 0.0649
Validation Accuracy: 0.9795
Overfitting: 0.0596
Best model saved at epoch 2 with validation loss: 0.0649
[Epoch 3, Batch 100] loss: 0.06244496453553438
[Epoch 3, Batch 200] loss: 0.04273782938718796
[Epoch 3, Batch 300] loss: 0.05673567867837846
[Epoch 3, Batch 400] loss: 0.04557486361358315
[Epoch 3, Batch 500] loss: 0.05816659854725003
[Epoch 3, Batch 600] loss: 0.0505200140690431
[Epoch 3, Batch 700] loss: 0.05707162089413032
**STATS for Epoch 3** : 
Average training loss: 0.0030
Average validation loss: 0.0631
Validation Accuracy: 0.9791
Overfitting: 0.0601
Best model saved at epoch 3 with validation loss: 0.0631
[Epoch 4, Batch 100] loss: 0.038040328486822546
[Epoch 4, Batch 200] loss: 0.0484526425274089
[Epoch 4, Batch 300] loss: 0.04451153646921739
[Epoch 4, Batch 400] loss: 0.04676413072622381
[Epoch 4, Batch 500] loss: 0.038437139362795275
[Epoch 4, Batch 600] loss: 0.038505885665072126
[Epoch 4, Batch 700] loss: 0.04673595465021208
**STATS for Epoch 4** : 
Average training loss: 0.0026
Average validation loss: 0.0542
Validation Accuracy: 0.9822
Overfitting: 0.0517
Best model saved at epoch 4 with validation loss: 0.0542
[Epoch 5, Batch 100] loss: 0.03542692884162534
[Epoch 5, Batch 200] loss: 0.03314302640035748
[Epoch 5, Batch 300] loss: 0.036285801524645646
[Epoch 5, Batch 400] loss: 0.029783434969140217
[Epoch 5, Batch 500] loss: 0.028708379584131763
[Epoch 5, Batch 600] loss: 0.039596621508244424
[Epoch 5, Batch 700] loss: 0.03214399230724666
**STATS for Epoch 5** : 
Average training loss: 0.0027
Average validation loss: 0.0544
Validation Accuracy: 0.9826
Overfitting: 0.0517
[Epoch 6, Batch 100] loss: 0.03556823034596164
[Epoch 6, Batch 200] loss: 0.02920608360262122
[Epoch 6, Batch 300] loss: 0.02411616963101551
[Epoch 6, Batch 400] loss: 0.03192499926430173
[Epoch 6, Batch 500] loss: 0.027232116567902268
[Epoch 6, Batch 600] loss: 0.024574102536425925
[Epoch 6, Batch 700] loss: 0.02809033799698227
**STATS for Epoch 6** : 
Average training loss: 0.0023
Average validation loss: 0.0449
Validation Accuracy: 0.9856
Overfitting: 0.0426
Best model saved at epoch 6 with validation loss: 0.0449
[Epoch 7, Batch 100] loss: 0.02170064174104482
[Epoch 7, Batch 200] loss: 0.0240975475977757
[Epoch 7, Batch 300] loss: 0.01921298985776957
[Epoch 7, Batch 400] loss: 0.021850259821512737
[Epoch 7, Batch 500] loss: 0.031188049816555576
[Epoch 7, Batch 600] loss: 0.025760475705028513
[Epoch 7, Batch 700] loss: 0.021118680504150687
**STATS for Epoch 7** : 
Average training loss: 0.0012
Average validation loss: 0.0467
Validation Accuracy: 0.9864
Overfitting: 0.0455
[Epoch 8, Batch 100] loss: 0.018078526900644647
[Epoch 8, Batch 200] loss: 0.015729637994081714
[Epoch 8, Batch 300] loss: 0.024339943470040454
[Epoch 8, Batch 400] loss: 0.02186152157315519
[Epoch 8, Batch 500] loss: 0.021481249384523834
[Epoch 8, Batch 600] loss: 0.021978023393894545
[Epoch 8, Batch 700] loss: 0.016618769952328874
**STATS for Epoch 8** : 
Average training loss: 0.0010
Average validation loss: 0.0357
Validation Accuracy: 0.9897
Overfitting: 0.0347
Best model saved at epoch 8 with validation loss: 0.0357
[Epoch 9, Batch 100] loss: 0.013674454700631031
[Epoch 9, Batch 200] loss: 0.015369153751671548
[Epoch 9, Batch 300] loss: 0.011742525403096806
[Epoch 9, Batch 400] loss: 0.012528017806689605
[Epoch 9, Batch 500] loss: 0.022769708681007614
[Epoch 9, Batch 600] loss: 0.02188723730178026
[Epoch 9, Batch 700] loss: 0.025763940574543086
**STATS for Epoch 9** : 
Average training loss: 0.0014
Average validation loss: 0.0426
Validation Accuracy: 0.9871
Overfitting: 0.0412
[Epoch 10, Batch 100] loss: 0.014157974930640194
[Epoch 10, Batch 200] loss: 0.015808392753460795
[Epoch 10, Batch 300] loss: 0.01651819272476132
[Epoch 10, Batch 400] loss: 0.019176158441696317
[Epoch 10, Batch 500] loss: 0.01762233710644068
[Epoch 10, Batch 600] loss: 0.01215026937374205
[Epoch 10, Batch 700] loss: 0.010600798205923639
**STATS for Epoch 10** : 
Average training loss: 0.0011
Average validation loss: 0.0416
Validation Accuracy: 0.9882
Overfitting: 0.0404
[Epoch 11, Batch 100] loss: 0.015499433779914397
[Epoch 11, Batch 200] loss: 0.011653983419892029
[Epoch 11, Batch 300] loss: 0.0076453059401683275
[Epoch 11, Batch 400] loss: 0.011965802633621934
[Epoch 11, Batch 500] loss: 0.016247723247579414
[Epoch 11, Batch 600] loss: 0.012018141155676858
[Epoch 11, Batch 700] loss: 0.012604627252512728
**STATS for Epoch 11** : 
Average training loss: 0.0011
Average validation loss: 0.0408
Validation Accuracy: 0.9884
Overfitting: 0.0397
[Epoch 12, Batch 100] loss: 0.007157819627682329
[Epoch 12, Batch 200] loss: 0.007559278645276208
[Epoch 12, Batch 300] loss: 0.007921135048491124
[Epoch 12, Batch 400] loss: 0.010897277938565821
[Epoch 12, Batch 500] loss: 0.007838015342131258
[Epoch 12, Batch 600] loss: 0.007508313165944855
[Epoch 12, Batch 700] loss: 0.016216689847206
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0443
Validation Accuracy: 0.9885
Overfitting: 0.0435
[Epoch 13, Batch 100] loss: 0.010400924671557732
[Epoch 13, Batch 200] loss: 0.010926780929439701
[Epoch 13, Batch 300] loss: 0.007287056534714793
[Epoch 13, Batch 400] loss: 0.013623748862519278
[Epoch 13, Batch 500] loss: 0.015985832916412618
[Epoch 13, Batch 600] loss: 0.012588728430855553
[Epoch 13, Batch 700] loss: 0.011090725304966327
**STATS for Epoch 13** : 
Average training loss: 0.0005
Average validation loss: 0.0435
Validation Accuracy: 0.9888
Overfitting: 0.0430
[Epoch 14, Batch 100] loss: 0.009055741752345057
[Epoch 14, Batch 200] loss: 0.010111630162082292
[Epoch 14, Batch 300] loss: 0.010057171343796655
[Epoch 14, Batch 400] loss: 0.004205637163840948
[Epoch 14, Batch 500] loss: 0.00999576379719656
[Epoch 14, Batch 600] loss: 0.005464026948982337
[Epoch 14, Batch 700] loss: 0.009723262046964009
**STATS for Epoch 14** : 
Average training loss: 0.0011
Average validation loss: 0.0457
Validation Accuracy: 0.9881
Overfitting: 0.0446
[Epoch 15, Batch 100] loss: 0.0044202422441594535
[Epoch 15, Batch 200] loss: 0.005028182593468955
[Epoch 15, Batch 300] loss: 0.00445040121621787
[Epoch 15, Batch 400] loss: 0.003975211406022936
[Epoch 15, Batch 500] loss: 0.009647256734115216
[Epoch 15, Batch 600] loss: 0.003687745171246206
[Epoch 15, Batch 700] loss: 0.00711125562147572
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0434
Validation Accuracy: 0.9882
Overfitting: 0.0430
[Epoch 16, Batch 100] loss: 0.004261524596258824
[Epoch 16, Batch 200] loss: 0.0036385854901891434
[Epoch 16, Batch 300] loss: 0.003969511973155022
[Epoch 16, Batch 400] loss: 0.005141084917431727
[Epoch 16, Batch 500] loss: 0.007500947098669712
[Epoch 16, Batch 600] loss: 0.004722120104152055
[Epoch 16, Batch 700] loss: 0.006683511531364274
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0440
Validation Accuracy: 0.9888
Overfitting: 0.0438
[Epoch 17, Batch 100] loss: 0.002989262030168902
[Epoch 17, Batch 200] loss: 0.003991387395626589
[Epoch 17, Batch 300] loss: 0.002851806384092015
[Epoch 17, Batch 400] loss: 0.0031155563794766296
[Epoch 17, Batch 500] loss: 0.0040983431982363075
[Epoch 17, Batch 600] loss: 0.0063934858195534615
[Epoch 17, Batch 700] loss: 0.006319409983857441
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0447
Validation Accuracy: 0.9890
Overfitting: 0.0443
[Epoch 18, Batch 100] loss: 0.0042705590549030606
[Epoch 18, Batch 200] loss: 0.0029592739949748648
[Epoch 18, Batch 300] loss: 0.0018876968727636267
[Epoch 18, Batch 400] loss: 0.003170229577854116
[Epoch 18, Batch 500] loss: 0.004096132092599874
[Epoch 18, Batch 600] loss: 0.00872004919506253
[Epoch 18, Batch 700] loss: 0.007042323603109253
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0433
Validation Accuracy: 0.9890
Overfitting: 0.0431
[Epoch 19, Batch 100] loss: 0.003953397035293165
[Epoch 19, Batch 200] loss: 0.002508164596633833
[Epoch 19, Batch 300] loss: 0.004611629000746689
[Epoch 19, Batch 400] loss: 0.004981716150707598
[Epoch 19, Batch 500] loss: 0.004926150264655007
[Epoch 19, Batch 600] loss: 0.008748198495504766
[Epoch 19, Batch 700] loss: 0.007361161401649952
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0450
Validation Accuracy: 0.9891
Overfitting: 0.0444
[Epoch 20, Batch 100] loss: 0.00644435998154222
[Epoch 20, Batch 200] loss: 0.0059888712247402505
[Epoch 20, Batch 300] loss: 0.008881614602678382
[Epoch 20, Batch 400] loss: 0.004526439238095464
[Epoch 20, Batch 500] loss: 0.003181616782408128
[Epoch 20, Batch 600] loss: 0.007839690305263502
[Epoch 20, Batch 700] loss: 0.0031355947577412736
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0452
Validation Accuracy: 0.9888
Overfitting: 0.0447
[Epoch 21, Batch 100] loss: 0.0027831019886889407
[Epoch 21, Batch 200] loss: 0.004547504462434518
[Epoch 21, Batch 300] loss: 0.005272289520166851
[Epoch 21, Batch 400] loss: 0.007050443640376897
[Epoch 21, Batch 500] loss: 0.00772215630237497
[Epoch 21, Batch 600] loss: 0.0042008726088238295
[Epoch 21, Batch 700] loss: 0.011564596194557453
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0512
Validation Accuracy: 0.9878
Overfitting: 0.0507
[Epoch 22, Batch 100] loss: 0.0024484556742027054
[Epoch 22, Batch 200] loss: 0.0011146934805412912
[Epoch 22, Batch 300] loss: 0.0015968876392616948
[Epoch 22, Batch 400] loss: 0.0021422418282008946
[Epoch 22, Batch 500] loss: 0.0029637396760563207
[Epoch 22, Batch 600] loss: 0.007938507409120348
[Epoch 22, Batch 700] loss: 0.008381602620399917
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0467
Validation Accuracy: 0.9882
Overfitting: 0.0462
[Epoch 23, Batch 100] loss: 0.004712733047672373
[Epoch 23, Batch 200] loss: 0.0017039616393458345
[Epoch 23, Batch 300] loss: 0.003022174029638336
[Epoch 23, Batch 400] loss: 0.0031045233068107336
[Epoch 23, Batch 500] loss: 0.0039425443256732254
[Epoch 23, Batch 600] loss: 0.001637417976935467
[Epoch 23, Batch 700] loss: 0.0018700601050477418
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0469
Validation Accuracy: 0.9897
Overfitting: 0.0468
[Epoch 24, Batch 100] loss: 0.002921050292007976
[Epoch 24, Batch 200] loss: 0.00336618461580656
[Epoch 24, Batch 300] loss: 0.005089927448862
[Epoch 24, Batch 400] loss: 0.014562013132899666
[Epoch 24, Batch 500] loss: 0.008541643968701464
[Epoch 24, Batch 600] loss: 0.01215495948471016
[Epoch 24, Batch 700] loss: 0.010359822846476163
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0570
Validation Accuracy: 0.9872
Overfitting: 0.0566
Fold 5 validation loss: 0.0570
Mean validation loss across all folds for Trial 12 is 0.0581 with trial config:  l1: 256, l2: 128, lr: 0.008332334231893158, batch_size: 64
[I 2024-12-11 03:57:56,566] Trial 11 finished with value: 0.05806303817105899 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.008332334231893158, 'batch_size': 64}. Best is trial 2 with value: 0.05047263894358398.

Selected Hyperparameters for Trial 13:
  l1: 256, l2: 128, lr: 0.0008591168444032908, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.294928629398346
[Epoch 1, Batch 200] loss: 2.2668704271316527
[Epoch 1, Batch 300] loss: 2.1846698999404905
[Epoch 1, Batch 400] loss: 1.6975471317768096
[Epoch 1, Batch 500] loss: 0.782675849199295
[Epoch 1, Batch 600] loss: 0.5524955099821091
[Epoch 1, Batch 700] loss: 0.44774759739637376
**STATS for Epoch 1** : 
Average training loss: 0.0270
Average validation loss: 0.3879
Validation Accuracy: 0.8815
Overfitting: 0.3609
Best model saved at epoch 1 with validation loss: 0.3879
[Epoch 2, Batch 100] loss: 0.3642183218896389
[Epoch 2, Batch 200] loss: 0.33543034076690675
[Epoch 2, Batch 300] loss: 0.33626249864697455
[Epoch 2, Batch 400] loss: 0.32481921032071115
[Epoch 2, Batch 500] loss: 0.29029716722667215
[Epoch 2, Batch 600] loss: 0.250501494333148
[Epoch 2, Batch 700] loss: 0.25485543042421344
**STATS for Epoch 2** : 
Average training loss: 0.0158
Average validation loss: 0.2210
Validation Accuracy: 0.9305
Overfitting: 0.2052
Best model saved at epoch 2 with validation loss: 0.2210
[Epoch 3, Batch 100] loss: 0.2181140488386154
[Epoch 3, Batch 200] loss: 0.213890816308558
[Epoch 3, Batch 300] loss: 0.19832857202738524
[Epoch 3, Batch 400] loss: 0.1844249638915062
[Epoch 3, Batch 500] loss: 0.18902474753558635
[Epoch 3, Batch 600] loss: 0.19956946890801192
[Epoch 3, Batch 700] loss: 0.17844598408788442
**STATS for Epoch 3** : 
Average training loss: 0.0109
Average validation loss: 0.1608
Validation Accuracy: 0.9498
Overfitting: 0.1499
Best model saved at epoch 3 with validation loss: 0.1608
[Epoch 4, Batch 100] loss: 0.1583234667032957
[Epoch 4, Batch 200] loss: 0.1528171557933092
[Epoch 4, Batch 300] loss: 0.1494578645005822
[Epoch 4, Batch 400] loss: 0.14374807454645633
[Epoch 4, Batch 500] loss: 0.16009675530716777
[Epoch 4, Batch 600] loss: 0.12777041213586926
[Epoch 4, Batch 700] loss: 0.12929059961810707
**STATS for Epoch 4** : 
Average training loss: 0.0091
Average validation loss: 0.1261
Validation Accuracy: 0.9611
Overfitting: 0.1170
Best model saved at epoch 4 with validation loss: 0.1261
[Epoch 5, Batch 100] loss: 0.1247606747597456
[Epoch 5, Batch 200] loss: 0.12007515670731664
[Epoch 5, Batch 300] loss: 0.11698015077039599
[Epoch 5, Batch 400] loss: 0.11420145638287067
[Epoch 5, Batch 500] loss: 0.11624767972156405
[Epoch 5, Batch 600] loss: 0.12234777439385652
[Epoch 5, Batch 700] loss: 0.11294344877824188
**STATS for Epoch 5** : 
Average training loss: 0.0074
Average validation loss: 0.1022
Validation Accuracy: 0.9679
Overfitting: 0.0949
Best model saved at epoch 5 with validation loss: 0.1022
[Epoch 6, Batch 100] loss: 0.10483078828081488
[Epoch 6, Batch 200] loss: 0.10351093221455812
[Epoch 6, Batch 300] loss: 0.09723688857629895
[Epoch 6, Batch 400] loss: 0.109249786157161
[Epoch 6, Batch 500] loss: 0.0995137283205986
[Epoch 6, Batch 600] loss: 0.08827964261174202
[Epoch 6, Batch 700] loss: 0.10900590794626623
**STATS for Epoch 6** : 
Average training loss: 0.0065
Average validation loss: 0.0942
Validation Accuracy: 0.9708
Overfitting: 0.0877
Best model saved at epoch 6 with validation loss: 0.0942
[Epoch 7, Batch 100] loss: 0.10669884528964758
[Epoch 7, Batch 200] loss: 0.0813127238675952
[Epoch 7, Batch 300] loss: 0.09007199319079519
[Epoch 7, Batch 400] loss: 0.08430298533290624
[Epoch 7, Batch 500] loss: 0.08401712220162154
[Epoch 7, Batch 600] loss: 0.09627886980772019
[Epoch 7, Batch 700] loss: 0.0845098555739969
**STATS for Epoch 7** : 
Average training loss: 0.0063
Average validation loss: 0.0827
Validation Accuracy: 0.9741
Overfitting: 0.0764
Best model saved at epoch 7 with validation loss: 0.0827
[Epoch 8, Batch 100] loss: 0.07047062404919416
[Epoch 8, Batch 200] loss: 0.08236159906722605
[Epoch 8, Batch 300] loss: 0.0807005463913083
[Epoch 8, Batch 400] loss: 0.08808154990896583
[Epoch 8, Batch 500] loss: 0.07772533971816302
[Epoch 8, Batch 600] loss: 0.08190142707899213
[Epoch 8, Batch 700] loss: 0.0843361733108759
**STATS for Epoch 8** : 
Average training loss: 0.0047
Average validation loss: 0.0766
Validation Accuracy: 0.9760
Overfitting: 0.0720
Best model saved at epoch 8 with validation loss: 0.0766
[Epoch 9, Batch 100] loss: 0.07133905889932066
[Epoch 9, Batch 200] loss: 0.07577735903672873
[Epoch 9, Batch 300] loss: 0.07384791516698896
[Epoch 9, Batch 400] loss: 0.07755144577473402
[Epoch 9, Batch 500] loss: 0.07007093103602528
[Epoch 9, Batch 600] loss: 0.07556780879385769
[Epoch 9, Batch 700] loss: 0.06535228665918112
**STATS for Epoch 9** : 
Average training loss: 0.0047
Average validation loss: 0.0751
Validation Accuracy: 0.9760
Overfitting: 0.0704
[I 2024-12-11 03:59:27,342] Trial 12 pruned. 

Selected Hyperparameters for Trial 14:
  l1: 128, l2: 128, lr: 0.0010518010537295668, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2988541293144227
[Epoch 1, Batch 200] loss: 2.2624769163131715
[Epoch 1, Batch 300] loss: 2.1537627947330473
[Epoch 1, Batch 400] loss: 1.4785497385263442
[Epoch 1, Batch 500] loss: 0.7088341461122036
[Epoch 1, Batch 600] loss: 0.5090486884117127
[Epoch 1, Batch 700] loss: 0.440649180971086
[Epoch 1, Batch 800] loss: 0.34514590244740245
[Epoch 1, Batch 900] loss: 0.2910929982550442
[Epoch 1, Batch 1000] loss: 0.3313880981877446
[Epoch 1, Batch 1100] loss: 0.2478529664129019
[Epoch 1, Batch 1200] loss: 0.2472023966163397
[Epoch 1, Batch 1300] loss: 0.23193569907918574
[Epoch 1, Batch 1400] loss: 0.1883355768211186
[Epoch 1, Batch 1500] loss: 0.204514948297292
[Epoch 1, Batch 1600] loss: 0.2096312659792602
[Epoch 1, Batch 1700] loss: 0.19284736389294266
[Epoch 1, Batch 1800] loss: 0.228561307862401
[Epoch 1, Batch 1900] loss: 0.15678095502778888
[Epoch 1, Batch 2000] loss: 0.1471828147303313
[Epoch 1, Batch 2100] loss: 0.16727049816865475
[Epoch 1, Batch 2200] loss: 0.15978433132637293
[Epoch 1, Batch 2300] loss: 0.1893894088175148
[Epoch 1, Batch 2400] loss: 0.16561876281164586
[Epoch 1, Batch 2500] loss: 0.15216216553002596
[Epoch 1, Batch 2600] loss: 0.14010770057793706
[Epoch 1, Batch 2700] loss: 0.15344606570899486
[Epoch 1, Batch 2800] loss: 0.14953133693896234
[Epoch 1, Batch 2900] loss: 0.10983903093729168
[Epoch 1, Batch 3000] loss: 0.14517904839478432
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1086
Validation Accuracy: 0.9666
Overfitting: 0.1086
Best model saved at epoch 1 with validation loss: 0.1086
[Epoch 2, Batch 100] loss: 0.11255314259557053
[Epoch 2, Batch 200] loss: 0.14214742449577897
[Epoch 2, Batch 300] loss: 0.1195219168253243
[Epoch 2, Batch 400] loss: 0.12042016008403152
[Epoch 2, Batch 500] loss: 0.11490707422839477
[Epoch 2, Batch 600] loss: 0.10277468690648675
[Epoch 2, Batch 700] loss: 0.09485045258887112
[Epoch 2, Batch 800] loss: 0.09482410550583154
[Epoch 2, Batch 900] loss: 0.07912293474655599
[Epoch 2, Batch 1000] loss: 0.1195056720660068
[Epoch 2, Batch 1100] loss: 0.11536468662088736
[Epoch 2, Batch 1200] loss: 0.10406356343533844
[Epoch 2, Batch 1300] loss: 0.10391094637103379
[Epoch 2, Batch 1400] loss: 0.09002199270762504
[Epoch 2, Batch 1500] loss: 0.09393372225575149
[Epoch 2, Batch 1600] loss: 0.10695045314962044
[Epoch 2, Batch 1700] loss: 0.09974067663308234
[Epoch 2, Batch 1800] loss: 0.10100075437687338
[Epoch 2, Batch 1900] loss: 0.09991597700922285
[Epoch 2, Batch 2000] loss: 0.09294539676164276
[Epoch 2, Batch 2100] loss: 0.10693888215231709
[Epoch 2, Batch 2200] loss: 0.09630354954628274
[Epoch 2, Batch 2300] loss: 0.10233170407358556
[Epoch 2, Batch 2400] loss: 0.0829486358910799
[Epoch 2, Batch 2500] loss: 0.10872559001029003
[Epoch 2, Batch 2600] loss: 0.08133949155919254
[Epoch 2, Batch 2700] loss: 0.09842832723399625
[Epoch 2, Batch 2800] loss: 0.07533063640468754
[Epoch 2, Batch 2900] loss: 0.11089385582483374
[Epoch 2, Batch 3000] loss: 0.07989080690749688
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0701
Validation Accuracy: 0.9779
Overfitting: 0.0701
Best model saved at epoch 2 with validation loss: 0.0701
[Epoch 3, Batch 100] loss: 0.059732422686065545
[Epoch 3, Batch 200] loss: 0.11070152146508917
[Epoch 3, Batch 300] loss: 0.07998762796632945
[Epoch 3, Batch 400] loss: 0.07985876754391938
[Epoch 3, Batch 500] loss: 0.048013022787636146
[Epoch 3, Batch 600] loss: 0.08627228491357528
[Epoch 3, Batch 700] loss: 0.06069351728307083
[Epoch 3, Batch 800] loss: 0.06317862449388485
[Epoch 3, Batch 900] loss: 0.07572170475585153
[Epoch 3, Batch 1000] loss: 0.07830278831883333
[Epoch 3, Batch 1100] loss: 0.0508958562114276
[Epoch 3, Batch 1200] loss: 0.09648510269180406
[Epoch 3, Batch 1300] loss: 0.06990373694105073
[Epoch 3, Batch 1400] loss: 0.09258797675604001
[Epoch 3, Batch 1500] loss: 0.07227155115455389
[Epoch 3, Batch 1600] loss: 0.07799343672348186
[Epoch 3, Batch 1700] loss: 0.06094303693040274
[Epoch 3, Batch 1800] loss: 0.07977318712859414
[Epoch 3, Batch 1900] loss: 0.06789217040641234
[Epoch 3, Batch 2000] loss: 0.05546228492457885
[Epoch 3, Batch 2100] loss: 0.0570246325811604
[Epoch 3, Batch 2200] loss: 0.04844677600718569
[Epoch 3, Batch 2300] loss: 0.054347794226778205
[Epoch 3, Batch 2400] loss: 0.05952251693815924
[Epoch 3, Batch 2500] loss: 0.056154530454077756
[Epoch 3, Batch 2600] loss: 0.07494367869454437
[Epoch 3, Batch 2700] loss: 0.08519350886053871
[Epoch 3, Batch 2800] loss: 0.059306513142073525
[Epoch 3, Batch 2900] loss: 0.07095476878457703
[Epoch 3, Batch 3000] loss: 0.06606836168852169
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9808
Overfitting: 0.0636
Best model saved at epoch 3 with validation loss: 0.0636
[Epoch 4, Batch 100] loss: 0.047790361433872025
[Epoch 4, Batch 200] loss: 0.05289501279825345
[Epoch 4, Batch 300] loss: 0.05079472577694105
[Epoch 4, Batch 400] loss: 0.06763790535536827
[Epoch 4, Batch 500] loss: 0.051406907292257525
[Epoch 4, Batch 600] loss: 0.06810490475327242
[Epoch 4, Batch 700] loss: 0.060315267510013655
[Epoch 4, Batch 800] loss: 0.04226713195152115
[Epoch 4, Batch 900] loss: 0.04736501306353603
[Epoch 4, Batch 1000] loss: 0.05654822806391167
[Epoch 4, Batch 1100] loss: 0.08550957891566213
[Epoch 4, Batch 1200] loss: 0.06459732237039134
[Epoch 4, Batch 1300] loss: 0.05846213052427629
[Epoch 4, Batch 1400] loss: 0.0448995545267826
[Epoch 4, Batch 1500] loss: 0.05440706480847439
[Epoch 4, Batch 1600] loss: 0.04676018804195337
[Epoch 4, Batch 1700] loss: 0.047859568342973946
[Epoch 4, Batch 1800] loss: 0.05129116593525396
[Epoch 4, Batch 1900] loss: 0.04285056063527008
[Epoch 4, Batch 2000] loss: 0.06790161411801819
[Epoch 4, Batch 2100] loss: 0.0499035310378531
[Epoch 4, Batch 2200] loss: 0.05183374441228807
[Epoch 4, Batch 2300] loss: 0.033421801639487964
[Epoch 4, Batch 2400] loss: 0.05419731235684594
[Epoch 4, Batch 2500] loss: 0.06950332546839491
[Epoch 4, Batch 2600] loss: 0.050157684991136195
[Epoch 4, Batch 2700] loss: 0.05025789805600653
[Epoch 4, Batch 2800] loss: 0.059426453477353786
[Epoch 4, Batch 2900] loss: 0.056026165957009655
[Epoch 4, Batch 3000] loss: 0.05929198194440687
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0671
Validation Accuracy: 0.9781
Overfitting: 0.0671
[Epoch 5, Batch 100] loss: 0.03989897844730876
[Epoch 5, Batch 200] loss: 0.03926451319013722
[Epoch 5, Batch 300] loss: 0.04634033686190378
[Epoch 5, Batch 400] loss: 0.05506611229880946
[Epoch 5, Batch 500] loss: 0.0471712697550538
[Epoch 5, Batch 600] loss: 0.05003289685642812
[Epoch 5, Batch 700] loss: 0.05368447712506168
[Epoch 5, Batch 800] loss: 0.04458906911037047
[Epoch 5, Batch 900] loss: 0.05154914311860921
[Epoch 5, Batch 1000] loss: 0.04589215945030446
[Epoch 5, Batch 1100] loss: 0.03919475663889898
[Epoch 5, Batch 1200] loss: 0.0425778410845669
[Epoch 5, Batch 1300] loss: 0.03848312703703414
[Epoch 5, Batch 1400] loss: 0.05054327939782524
[Epoch 5, Batch 1500] loss: 0.04989125150517793
[Epoch 5, Batch 1600] loss: 0.0553393468610011
[Epoch 5, Batch 1700] loss: 0.045303137513110416
[Epoch 5, Batch 1800] loss: 0.04649348702019779
[Epoch 5, Batch 1900] loss: 0.047704708685050716
[Epoch 5, Batch 2000] loss: 0.04041087492922088
[Epoch 5, Batch 2100] loss: 0.03125328539928887
[Epoch 5, Batch 2200] loss: 0.0386551599309314
[Epoch 5, Batch 2300] loss: 0.043269971668778454
[Epoch 5, Batch 2400] loss: 0.03188485188977211
[Epoch 5, Batch 2500] loss: 0.04106695011942065
[Epoch 5, Batch 2600] loss: 0.0474724975132267
[Epoch 5, Batch 2700] loss: 0.03668366856581997
[Epoch 5, Batch 2800] loss: 0.04578703502847929
[Epoch 5, Batch 2900] loss: 0.06311650080649997
[Epoch 5, Batch 3000] loss: 0.04253082142793573
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9818
Overfitting: 0.0592
Best model saved at epoch 5 with validation loss: 0.0592
[Epoch 6, Batch 100] loss: 0.031514079322951145
[Epoch 6, Batch 200] loss: 0.03492182971313014
[Epoch 6, Batch 300] loss: 0.03964772961480776
[Epoch 6, Batch 400] loss: 0.03607728393217258
[Epoch 6, Batch 500] loss: 0.06458459835135727
[Epoch 6, Batch 600] loss: 0.036565519889991266
[Epoch 6, Batch 700] loss: 0.029937983131749207
[Epoch 6, Batch 800] loss: 0.05065637398642139
[Epoch 6, Batch 900] loss: 0.04558426517680345
[Epoch 6, Batch 1000] loss: 0.03896302578228642
[Epoch 6, Batch 1100] loss: 0.032667192850785794
[Epoch 6, Batch 1200] loss: 0.029646737761067923
[Epoch 6, Batch 1300] loss: 0.03188166790314426
[Epoch 6, Batch 1400] loss: 0.048689664564444686
[Epoch 6, Batch 1500] loss: 0.04143925035692519
[Epoch 6, Batch 1600] loss: 0.033632923172372105
[Epoch 6, Batch 1700] loss: 0.04332395591249224
[Epoch 6, Batch 1800] loss: 0.04009435434985789
[Epoch 6, Batch 1900] loss: 0.03232172437863483
[Epoch 6, Batch 2000] loss: 0.028555700640426947
[Epoch 6, Batch 2100] loss: 0.03294206075654074
[Epoch 6, Batch 2200] loss: 0.04759995163607528
[Epoch 6, Batch 2300] loss: 0.03728860005016031
[Epoch 6, Batch 2400] loss: 0.0309074755088659
[Epoch 6, Batch 2500] loss: 0.035308506002184006
[Epoch 6, Batch 2600] loss: 0.037954435297069725
[Epoch 6, Batch 2700] loss: 0.03938184487980834
[Epoch 6, Batch 2800] loss: 0.04026750954639283
[Epoch 6, Batch 2900] loss: 0.0230464748913073
[Epoch 6, Batch 3000] loss: 0.0296984601431177
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9842
Overfitting: 0.0518
Best model saved at epoch 6 with validation loss: 0.0518
[Epoch 7, Batch 100] loss: 0.036678991765220416
[Epoch 7, Batch 200] loss: 0.024415393121853413
[Epoch 7, Batch 300] loss: 0.024259556198667268
[Epoch 7, Batch 400] loss: 0.03326552559454285
[Epoch 7, Batch 500] loss: 0.0390930013012985
[Epoch 7, Batch 600] loss: 0.03375877808226505
[Epoch 7, Batch 700] loss: 0.026690014718915335
[Epoch 7, Batch 800] loss: 0.03157310694485204
[Epoch 7, Batch 900] loss: 0.02304435710706457
[Epoch 7, Batch 1000] loss: 0.03295512657059589
[Epoch 7, Batch 1100] loss: 0.03422534730110783
[Epoch 7, Batch 1200] loss: 0.026077822815022956
[Epoch 7, Batch 1300] loss: 0.03413675064723066
[Epoch 7, Batch 1400] loss: 0.027632719288230873
[Epoch 7, Batch 1500] loss: 0.03523173048044555
[Epoch 7, Batch 1600] loss: 0.03420284403604455
[Epoch 7, Batch 1700] loss: 0.026383657752885484
[Epoch 7, Batch 1800] loss: 0.025493020436551887
[Epoch 7, Batch 1900] loss: 0.032268515803225456
[Epoch 7, Batch 2000] loss: 0.05226281014227425
[Epoch 7, Batch 2100] loss: 0.02452472423319705
[Epoch 7, Batch 2200] loss: 0.028491774302056003
[Epoch 7, Batch 2300] loss: 0.031471356830443255
[Epoch 7, Batch 2400] loss: 0.03682924435401219
[Epoch 7, Batch 2500] loss: 0.025112708458527776
[Epoch 7, Batch 2600] loss: 0.034037854749803954
[Epoch 7, Batch 2700] loss: 0.035439783582151
[Epoch 7, Batch 2800] loss: 0.038588714588040605
[Epoch 7, Batch 2900] loss: 0.037824895837657094
[Epoch 7, Batch 3000] loss: 0.04441993629341596
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9848
Overfitting: 0.0482
Best model saved at epoch 7 with validation loss: 0.0482
[Epoch 8, Batch 100] loss: 0.02740097895664803
[Epoch 8, Batch 200] loss: 0.022774646134130307
[Epoch 8, Batch 300] loss: 0.024785709292773392
[Epoch 8, Batch 400] loss: 0.02424026520118787
[Epoch 8, Batch 500] loss: 0.020032559304963796
[Epoch 8, Batch 600] loss: 0.0381916500033185
[Epoch 8, Batch 700] loss: 0.02154327100397495
[Epoch 8, Batch 800] loss: 0.03306478940343368
[Epoch 8, Batch 900] loss: 0.02837955849638092
[Epoch 8, Batch 1000] loss: 0.03629114684656088
[Epoch 8, Batch 1100] loss: 0.023662274489397533
[Epoch 8, Batch 1200] loss: 0.02666853654751321
[Epoch 8, Batch 1300] loss: 0.028181413322527077
[Epoch 8, Batch 1400] loss: 0.0280456273566233
[Epoch 8, Batch 1500] loss: 0.03080703768930107
[Epoch 8, Batch 1600] loss: 0.020362314898484328
[Epoch 8, Batch 1700] loss: 0.025700077111250722
[Epoch 8, Batch 1800] loss: 0.03391064677511167
[Epoch 8, Batch 1900] loss: 0.024008388456568355
[Epoch 8, Batch 2000] loss: 0.025346692001548946
[Epoch 8, Batch 2100] loss: 0.037435043160767234
[Epoch 8, Batch 2200] loss: 0.02159114889553166
[Epoch 8, Batch 2300] loss: 0.029691355464819935
[Epoch 8, Batch 2400] loss: 0.023235795078653608
[Epoch 8, Batch 2500] loss: 0.0275706144992364
[Epoch 8, Batch 2600] loss: 0.03398090325834346
[Epoch 8, Batch 2700] loss: 0.03916208547550923
[Epoch 8, Batch 2800] loss: 0.022073560901771996
[Epoch 8, Batch 2900] loss: 0.016385866957789402
[Epoch 8, Batch 3000] loss: 0.03075059216906084
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0461
Validation Accuracy: 0.9852
Overfitting: 0.0461
Best model saved at epoch 8 with validation loss: 0.0461
[Epoch 9, Batch 100] loss: 0.01526970788361723
[Epoch 9, Batch 200] loss: 0.020239400675927756
[Epoch 9, Batch 300] loss: 0.016008326989031048
[Epoch 9, Batch 400] loss: 0.01831469758049934
[Epoch 9, Batch 500] loss: 0.017605044311458186
[Epoch 9, Batch 600] loss: 0.01171901443391107
[Epoch 9, Batch 700] loss: 0.028740010704786982
[Epoch 9, Batch 800] loss: 0.02159583633994771
[Epoch 9, Batch 900] loss: 0.029236924988954343
[Epoch 9, Batch 1000] loss: 0.020091118395430384
[Epoch 9, Batch 1100] loss: 0.023275258989851864
[Epoch 9, Batch 1200] loss: 0.03388737296298132
[Epoch 9, Batch 1300] loss: 0.02196898607944604
[Epoch 9, Batch 1400] loss: 0.01521283488204972
[Epoch 9, Batch 1500] loss: 0.030072368365963484
[Epoch 9, Batch 1600] loss: 0.027996941166275064
[Epoch 9, Batch 1700] loss: 0.02520342236610304
[Epoch 9, Batch 1800] loss: 0.02099803109143977
[Epoch 9, Batch 1900] loss: 0.03078874629616621
[Epoch 9, Batch 2000] loss: 0.029528161898924737
[Epoch 9, Batch 2100] loss: 0.018742827306887193
[Epoch 9, Batch 2200] loss: 0.02077328858187684
[Epoch 9, Batch 2300] loss: 0.03939184204549747
[Epoch 9, Batch 2400] loss: 0.02951477108093968
[Epoch 9, Batch 2500] loss: 0.038036675841576655
[Epoch 9, Batch 2600] loss: 0.027349999523357836
[Epoch 9, Batch 2700] loss: 0.026297788460942682
[Epoch 9, Batch 2800] loss: 0.024841240519235724
[Epoch 9, Batch 2900] loss: 0.031091777981710037
[Epoch 9, Batch 3000] loss: 0.02397483293651021
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0402
Validation Accuracy: 0.9868
Overfitting: 0.0402
Best model saved at epoch 9 with validation loss: 0.0402
[Epoch 10, Batch 100] loss: 0.01689458087854291
[Epoch 10, Batch 200] loss: 0.03252902493011788
[Epoch 10, Batch 300] loss: 0.026375004186429577
[Epoch 10, Batch 400] loss: 0.02806984237409779
[Epoch 10, Batch 500] loss: 0.01777694947682903
[Epoch 10, Batch 600] loss: 0.017915200390780227
[Epoch 10, Batch 700] loss: 0.022727916923904558
[Epoch 10, Batch 800] loss: 0.022402855030759384
[Epoch 10, Batch 900] loss: 0.01837109306896309
[Epoch 10, Batch 1000] loss: 0.01099639543775993
[Epoch 10, Batch 1100] loss: 0.04121168996753113
[Epoch 10, Batch 1200] loss: 0.024691295592128883
[Epoch 10, Batch 1300] loss: 0.015385063148460176
[Epoch 10, Batch 1400] loss: 0.0338582509455955
[Epoch 10, Batch 1500] loss: 0.02119903553628319
[Epoch 10, Batch 1600] loss: 0.013615116367254813
[Epoch 10, Batch 1700] loss: 0.01593183554095958
[Epoch 10, Batch 1800] loss: 0.03296507198127074
[Epoch 10, Batch 1900] loss: 0.01367596300195146
[Epoch 10, Batch 2000] loss: 0.010515733185329737
[Epoch 10, Batch 2100] loss: 0.02433315554882938
[Epoch 10, Batch 2200] loss: 0.01650217766627975
[Epoch 10, Batch 2300] loss: 0.016360846554744058
[Epoch 10, Batch 2400] loss: 0.016101751974988473
[Epoch 10, Batch 2500] loss: 0.0200219089226448
[Epoch 10, Batch 2600] loss: 0.02177034845790331
[Epoch 10, Batch 2700] loss: 0.01830762223464262
[Epoch 10, Batch 2800] loss: 0.01494726700881074
[Epoch 10, Batch 2900] loss: 0.01655317503529659
[Epoch 10, Batch 3000] loss: 0.029272493212538393
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9852
Overfitting: 0.0478
[Epoch 11, Batch 100] loss: 0.02795679326316531
[Epoch 11, Batch 200] loss: 0.019715369792238563
[Epoch 11, Batch 300] loss: 0.012054898081696592
[Epoch 11, Batch 400] loss: 0.019197781751795446
[Epoch 11, Batch 500] loss: 0.02183107233931878
[Epoch 11, Batch 600] loss: 0.013463966759527466
[Epoch 11, Batch 700] loss: 0.012207337094496324
[Epoch 11, Batch 800] loss: 0.019562608336091216
[Epoch 11, Batch 900] loss: 0.027631648700071308
[Epoch 11, Batch 1000] loss: 0.01207814058452641
[Epoch 11, Batch 1100] loss: 0.016932307767765453
[Epoch 11, Batch 1200] loss: 0.016288682431058986
[Epoch 11, Batch 1300] loss: 0.020266928974288022
[Epoch 11, Batch 1400] loss: 0.01728769581644883
[Epoch 11, Batch 1500] loss: 0.011316276655379624
[Epoch 11, Batch 1600] loss: 0.01145740192678204
[Epoch 11, Batch 1700] loss: 0.030051503114345905
[Epoch 11, Batch 1800] loss: 0.023238321586286474
[Epoch 11, Batch 1900] loss: 0.022059903705994657
[Epoch 11, Batch 2000] loss: 0.009169072373915697
[Epoch 11, Batch 2100] loss: 0.013658267944592808
[Epoch 11, Batch 2200] loss: 0.015342896804468183
[Epoch 11, Batch 2300] loss: 0.012923294009724487
[Epoch 11, Batch 2400] loss: 0.0141250028270224
[Epoch 11, Batch 2500] loss: 0.011141970271573882
[Epoch 11, Batch 2600] loss: 0.015587076265526321
[Epoch 11, Batch 2700] loss: 0.010693356061165105
[Epoch 11, Batch 2800] loss: 0.024487474452180323
[Epoch 11, Batch 2900] loss: 0.026590490156913803
[Epoch 11, Batch 3000] loss: 0.04153541180276079
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9868
Overfitting: 0.0431
[Epoch 12, Batch 100] loss: 0.015070764028423582
[Epoch 12, Batch 200] loss: 0.013225711873492401
[Epoch 12, Batch 300] loss: 0.013042650483475882
[Epoch 12, Batch 400] loss: 0.008749346328113462
[Epoch 12, Batch 500] loss: 0.012020071164952241
[Epoch 12, Batch 600] loss: 0.013955479740816372
[Epoch 12, Batch 700] loss: 0.013780907067302905
[Epoch 12, Batch 800] loss: 0.02303393375043015
[Epoch 12, Batch 900] loss: 0.009695772591767309
[Epoch 12, Batch 1000] loss: 0.011058535677498184
[Epoch 12, Batch 1100] loss: 0.017060742539506464
[Epoch 12, Batch 1200] loss: 0.01114852063962644
[Epoch 12, Batch 1300] loss: 0.009580655324812141
[Epoch 12, Batch 1400] loss: 0.02172290855236497
[Epoch 12, Batch 1500] loss: 0.015000263491838268
[Epoch 12, Batch 1600] loss: 0.008641230519283455
[Epoch 12, Batch 1700] loss: 0.0164038104859992
[Epoch 12, Batch 1800] loss: 0.007198955209119049
[Epoch 12, Batch 1900] loss: 0.024117706867900778
[Epoch 12, Batch 2000] loss: 0.027148102628270863
[Epoch 12, Batch 2100] loss: 0.015023184070323624
[Epoch 12, Batch 2200] loss: 0.03286300744226537
[Epoch 12, Batch 2300] loss: 0.012157793276692246
[Epoch 12, Batch 2400] loss: 0.026012666561218794
[Epoch 12, Batch 2500] loss: 0.010638284377610035
[Epoch 12, Batch 2600] loss: 0.020569560608591927
[Epoch 12, Batch 2700] loss: 0.014406542783626719
[Epoch 12, Batch 2800] loss: 0.01798028122505457
[Epoch 12, Batch 2900] loss: 0.011644089192295724
[Epoch 12, Batch 3000] loss: 0.007521393713568613
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0388
Validation Accuracy: 0.9883
Overfitting: 0.0388
Best model saved at epoch 12 with validation loss: 0.0388
[Epoch 13, Batch 100] loss: 0.006189372837961855
[Epoch 13, Batch 200] loss: 0.012775513586275338
[Epoch 13, Batch 300] loss: 0.008414392556730946
[Epoch 13, Batch 400] loss: 0.01749361750038588
[Epoch 13, Batch 500] loss: 0.007947304487879591
[Epoch 13, Batch 600] loss: 0.00583193854989986
[Epoch 13, Batch 700] loss: 0.014208972216438269
[Epoch 13, Batch 800] loss: 0.012111351478888538
[Epoch 13, Batch 900] loss: 0.006189707030689533
[Epoch 13, Batch 1000] loss: 0.0090714989888329
[Epoch 13, Batch 1100] loss: 0.014351693978665026
[Epoch 13, Batch 1200] loss: 0.01759823907577811
[Epoch 13, Batch 1300] loss: 0.009840216000116015
[Epoch 13, Batch 1400] loss: 0.016836689757183193
[Epoch 13, Batch 1500] loss: 0.017226181190208082
[Epoch 13, Batch 1600] loss: 0.01226601917484004
[Epoch 13, Batch 1700] loss: 0.02338924736482113
[Epoch 13, Batch 1800] loss: 0.014387283338746783
[Epoch 13, Batch 1900] loss: 0.01321837666603642
[Epoch 13, Batch 2000] loss: 0.01508120064952891
[Epoch 13, Batch 2100] loss: 0.022797149413681838
[Epoch 13, Batch 2200] loss: 0.015619526663740543
[Epoch 13, Batch 2300] loss: 0.022510874608669837
[Epoch 13, Batch 2400] loss: 0.02663214819311179
[Epoch 13, Batch 2500] loss: 0.008502460598501784
[Epoch 13, Batch 2600] loss: 0.01868861525063039
[Epoch 13, Batch 2700] loss: 0.014472078468679683
[Epoch 13, Batch 2800] loss: 0.015288821869089588
[Epoch 13, Batch 2900] loss: 0.012086312999376786
[Epoch 13, Batch 3000] loss: 0.020591182699381535
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9861
Overfitting: 0.0468
[Epoch 14, Batch 100] loss: 0.016722122213304828
[Epoch 14, Batch 200] loss: 0.007403277060438996
[Epoch 14, Batch 300] loss: 0.007283273528237259
[Epoch 14, Batch 400] loss: 0.01155436186758834
[Epoch 14, Batch 500] loss: 0.01100007274350901
[Epoch 14, Batch 600] loss: 0.013294008557215875
[Epoch 14, Batch 700] loss: 0.007467467153792313
[Epoch 14, Batch 800] loss: 0.006728458624309042
[Epoch 14, Batch 900] loss: 0.0059397132442245495
[Epoch 14, Batch 1000] loss: 0.007792592734213031
[Epoch 14, Batch 1100] loss: 0.01921146637630045
[Epoch 14, Batch 1200] loss: 0.010934570765039097
[Epoch 14, Batch 1300] loss: 0.007784124440095183
[Epoch 14, Batch 1400] loss: 0.01279432888868996
[Epoch 14, Batch 1500] loss: 0.017748438737532977
[Epoch 14, Batch 1600] loss: 0.008530304046958008
[Epoch 14, Batch 1700] loss: 0.010707753265619431
[Epoch 14, Batch 1800] loss: 0.01374361126992426
[Epoch 14, Batch 1900] loss: 0.012261669207537124
[Epoch 14, Batch 2000] loss: 0.014156311041576828
[Epoch 14, Batch 2100] loss: 0.011911925959539075
[Epoch 14, Batch 2200] loss: 0.008093625154988331
[Epoch 14, Batch 2300] loss: 0.012742520657811838
[Epoch 14, Batch 2400] loss: 0.015347101131218323
[Epoch 14, Batch 2500] loss: 0.01984685103199695
[Epoch 14, Batch 2600] loss: 0.022575308512132325
[Epoch 14, Batch 2700] loss: 0.014627371942333411
[Epoch 14, Batch 2800] loss: 0.022619444073861815
[Epoch 14, Batch 2900] loss: 0.013457636765269853
[Epoch 14, Batch 3000] loss: 0.0079609910938143
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0498
Validation Accuracy: 0.9862
Overfitting: 0.0498
[Epoch 15, Batch 100] loss: 0.00828777628894386
[Epoch 15, Batch 200] loss: 0.005655272372409854
[Epoch 15, Batch 300] loss: 0.0037282925257204626
[Epoch 15, Batch 400] loss: 0.006346169070000087
[Epoch 15, Batch 500] loss: 0.010878347197444783
[Epoch 15, Batch 600] loss: 0.00831955659066807
[Epoch 15, Batch 700] loss: 0.01134212876115953
[Epoch 15, Batch 800] loss: 0.008943233039060488
[Epoch 15, Batch 900] loss: 0.012040788692488605
[Epoch 15, Batch 1000] loss: 0.0052710238439613024
[Epoch 15, Batch 1100] loss: 0.01403739260985276
[Epoch 15, Batch 1200] loss: 0.014254913772515466
[Epoch 15, Batch 1300] loss: 0.005597130863620805
[Epoch 15, Batch 1400] loss: 0.007454294897233922
[Epoch 15, Batch 1500] loss: 0.02145035529188135
[Epoch 15, Batch 1600] loss: 0.01451600262313832
[Epoch 15, Batch 1700] loss: 0.010210536843067075
[Epoch 15, Batch 1800] loss: 0.010132757503424728
[Epoch 15, Batch 1900] loss: 0.00932548618142505
[Epoch 15, Batch 2000] loss: 0.008951884281657385
[Epoch 15, Batch 2100] loss: 0.012050995718743707
[Epoch 15, Batch 2200] loss: 0.005663038824887962
[Epoch 15, Batch 2300] loss: 0.016258791284631115
[Epoch 15, Batch 2400] loss: 0.011629080399743544
[Epoch 15, Batch 2500] loss: 0.010162117561376362
[Epoch 15, Batch 2600] loss: 0.011826169564833434
[Epoch 15, Batch 2700] loss: 0.009253442991789597
[Epoch 15, Batch 2800] loss: 0.014238217785973575
[Epoch 15, Batch 2900] loss: 0.0182120414145038
[Epoch 15, Batch 3000] loss: 0.012015909958729481
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9878
Overfitting: 0.0455
[Epoch 16, Batch 100] loss: 0.006176367236494115
[Epoch 16, Batch 200] loss: 0.006164447857981941
[Epoch 16, Batch 300] loss: 0.006224334713452322
[Epoch 16, Batch 400] loss: 0.007406798836498751
[Epoch 16, Batch 500] loss: 0.014222740912807695
[Epoch 16, Batch 600] loss: 0.011492574309959308
[Epoch 16, Batch 700] loss: 0.013466335880475527
[Epoch 16, Batch 800] loss: 0.003685469825832115
[Epoch 16, Batch 900] loss: 0.005700942712787764
[Epoch 16, Batch 1000] loss: 0.00518225936284864
[Epoch 16, Batch 1100] loss: 0.004772695881129039
[Epoch 16, Batch 1200] loss: 0.006289379982249556
[Epoch 16, Batch 1300] loss: 0.010987081641087571
[Epoch 16, Batch 1400] loss: 0.006131980894508615
[Epoch 16, Batch 1500] loss: 0.007561409303852962
[Epoch 16, Batch 1600] loss: 0.007846026855315814
[Epoch 16, Batch 1700] loss: 0.010893709240540374
[Epoch 16, Batch 1800] loss: 0.006469238164790454
[Epoch 16, Batch 1900] loss: 0.0047213763496301905
[Epoch 16, Batch 2000] loss: 0.009951840537132455
[Epoch 16, Batch 2100] loss: 0.006953791711956683
[Epoch 16, Batch 2200] loss: 0.010821691845537771
[Epoch 16, Batch 2300] loss: 0.019993027622017507
[Epoch 16, Batch 2400] loss: 0.02464369551116306
[Epoch 16, Batch 2500] loss: 0.0064589776643583716
[Epoch 16, Batch 2600] loss: 0.008089683086877813
[Epoch 16, Batch 2700] loss: 0.019618790207309757
[Epoch 16, Batch 2800] loss: 0.0055803295789974075
[Epoch 16, Batch 2900] loss: 0.008422730092265738
[Epoch 16, Batch 3000] loss: 0.012328782282534121
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9877
Overfitting: 0.0468
[Epoch 17, Batch 100] loss: 0.005501774142510385
[Epoch 17, Batch 200] loss: 0.0037991946490842565
[Epoch 17, Batch 300] loss: 0.00362208967463971
[Epoch 17, Batch 400] loss: 0.011503699636704142
[Epoch 17, Batch 500] loss: 0.004297456472510248
[Epoch 17, Batch 600] loss: 0.007138855010128964
[Epoch 17, Batch 700] loss: 0.008430182324630095
[Epoch 17, Batch 800] loss: 0.005903180197304891
[Epoch 17, Batch 900] loss: 0.004514239622360492
[Epoch 17, Batch 1000] loss: 0.006321348033508229
[Epoch 17, Batch 1100] loss: 0.005636080980250427
[Epoch 17, Batch 1200] loss: 0.012100650732877511
[Epoch 17, Batch 1300] loss: 0.00417762272645632
[Epoch 17, Batch 1400] loss: 0.007063454833002538
[Epoch 17, Batch 1500] loss: 0.0055878061235421226
[Epoch 17, Batch 1600] loss: 0.004139871810689328
[Epoch 17, Batch 1700] loss: 0.0052947047048405695
[Epoch 17, Batch 1800] loss: 0.01197818570547554
[Epoch 17, Batch 1900] loss: 0.0106282446434966
[Epoch 17, Batch 2000] loss: 0.005383174538974558
[Epoch 17, Batch 2100] loss: 0.0055761899528528145
[Epoch 17, Batch 2200] loss: 0.005820396044983908
[Epoch 17, Batch 2300] loss: 0.016365673753043666
[Epoch 17, Batch 2400] loss: 0.008784459534533653
[Epoch 17, Batch 2500] loss: 0.005512424540556822
[Epoch 17, Batch 2600] loss: 0.008485161156133358
[Epoch 17, Batch 2700] loss: 0.009471366729108012
[Epoch 17, Batch 2800] loss: 0.01051558158571197
[Epoch 17, Batch 2900] loss: 0.008164398694441388
[Epoch 17, Batch 3000] loss: 0.0102236144865023
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9879
Overfitting: 0.0478
[I 2024-12-11 04:03:34,763] Trial 13 pruned. 

Selected Hyperparameters for Trial 15:
  l1: 256, l2: 128, lr: 0.00313624754642003, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.283521659374237
**STATS for Epoch 1** : 
Average training loss: 0.8030
Average validation loss: 0.7444
Validation Accuracy: 0.7648
Overfitting: -0.0586
Best model saved at epoch 1 with validation loss: 0.7444
[Epoch 2, Batch 100] loss: 0.48908681750297545
**STATS for Epoch 2** : 
Average training loss: 0.1460
Average validation loss: 0.2385
Validation Accuracy: 0.9273
Overfitting: 0.0925
Best model saved at epoch 2 with validation loss: 0.2385
[Epoch 3, Batch 100] loss: 0.2241202749311924
**STATS for Epoch 3** : 
Average training loss: 0.0895
Average validation loss: 0.1635
Validation Accuracy: 0.9488
Overfitting: 0.0740
Best model saved at epoch 3 with validation loss: 0.1635
[Epoch 4, Batch 100] loss: 0.1593943193554878
**STATS for Epoch 4** : 
Average training loss: 0.0641
Average validation loss: 0.1219
Validation Accuracy: 0.9613
Overfitting: 0.0579
Best model saved at epoch 4 with validation loss: 0.1219
[Epoch 5, Batch 100] loss: 0.12129660975188017
**STATS for Epoch 5** : 
Average training loss: 0.0546
Average validation loss: 0.0998
Validation Accuracy: 0.9693
Overfitting: 0.0453
Best model saved at epoch 5 with validation loss: 0.0998
[Epoch 6, Batch 100] loss: 0.10552821107208729
**STATS for Epoch 6** : 
Average training loss: 0.0438
Average validation loss: 0.0880
Validation Accuracy: 0.9734
Overfitting: 0.0442
Best model saved at epoch 6 with validation loss: 0.0880
[Epoch 7, Batch 100] loss: 0.08964142318814992
**STATS for Epoch 7** : 
Average training loss: 0.0397
Average validation loss: 0.0803
Validation Accuracy: 0.9749
Overfitting: 0.0406
Best model saved at epoch 7 with validation loss: 0.0803
[Epoch 8, Batch 100] loss: 0.07967538356781007
**STATS for Epoch 8** : 
Average training loss: 0.0359
Average validation loss: 0.0740
Validation Accuracy: 0.9775
Overfitting: 0.0382
Best model saved at epoch 8 with validation loss: 0.0740
[Epoch 9, Batch 100] loss: 0.07062418090179562
**STATS for Epoch 9** : 
Average training loss: 0.0327
Average validation loss: 0.0666
Validation Accuracy: 0.9791
Overfitting: 0.0340
[I 2024-12-11 04:04:54,501] Trial 14 pruned. 

Selected Hyperparameters for Trial 16:
  l1: 128, l2: 128, lr: 0.0029125540727754106, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2669703650474546
[Epoch 1, Batch 200] loss: 1.3019198831915855
[Epoch 1, Batch 300] loss: 0.48316257402300833
[Epoch 1, Batch 400] loss: 0.35278840199112893
[Epoch 1, Batch 500] loss: 0.3143686455488205
[Epoch 1, Batch 600] loss: 0.21792161628603934
[Epoch 1, Batch 700] loss: 0.19654556136578322
**STATS for Epoch 1** : 
Average training loss: 0.0121
Average validation loss: 0.1626
Validation Accuracy: 0.9503
Overfitting: 0.1504
Best model saved at epoch 1 with validation loss: 0.1626
[Epoch 2, Batch 100] loss: 0.16963376972824334
[Epoch 2, Batch 200] loss: 0.17189776040613652
[Epoch 2, Batch 300] loss: 0.1454143562167883
[Epoch 2, Batch 400] loss: 0.13770946564152836
[Epoch 2, Batch 500] loss: 0.11612263624556363
[Epoch 2, Batch 600] loss: 0.11483332999050617
[Epoch 2, Batch 700] loss: 0.09738437964580954
**STATS for Epoch 2** : 
Average training loss: 0.0078
Average validation loss: 0.0946
Validation Accuracy: 0.9686
Overfitting: 0.0869
Best model saved at epoch 2 with validation loss: 0.0946
[Epoch 3, Batch 100] loss: 0.09463098115287721
[Epoch 3, Batch 200] loss: 0.09478664113208651
[Epoch 3, Batch 300] loss: 0.08365936839953064
[Epoch 3, Batch 400] loss: 0.09158577600494028
[Epoch 3, Batch 500] loss: 0.0832046203315258
[Epoch 3, Batch 600] loss: 0.07788167659658939
[Epoch 3, Batch 700] loss: 0.08421223053708672
**STATS for Epoch 3** : 
Average training loss: 0.0053
Average validation loss: 0.0686
Validation Accuracy: 0.9784
Overfitting: 0.0634
Best model saved at epoch 3 with validation loss: 0.0686
[Epoch 4, Batch 100] loss: 0.06303696372080594
[Epoch 4, Batch 200] loss: 0.06326501099858434
[Epoch 4, Batch 300] loss: 0.0691278307698667
[Epoch 4, Batch 400] loss: 0.0703530494729057
[Epoch 4, Batch 500] loss: 0.05749301194678992
[Epoch 4, Batch 600] loss: 0.06929488184861839
[Epoch 4, Batch 700] loss: 0.06288337846053764
**STATS for Epoch 4** : 
Average training loss: 0.0045
Average validation loss: 0.0723
Validation Accuracy: 0.9773
Overfitting: 0.0678
[Epoch 5, Batch 100] loss: 0.056220596279017626
[Epoch 5, Batch 200] loss: 0.06612303799018264
[Epoch 5, Batch 300] loss: 0.0532760322932154
[Epoch 5, Batch 400] loss: 0.050111177565995604
[Epoch 5, Batch 500] loss: 0.05529573001433164
[Epoch 5, Batch 600] loss: 0.05172408750280738
[Epoch 5, Batch 700] loss: 0.053125919109443205
**STATS for Epoch 5** : 
Average training loss: 0.0036
Average validation loss: 0.0531
Validation Accuracy: 0.9825
Overfitting: 0.0495
Best model saved at epoch 5 with validation loss: 0.0531
[Epoch 6, Batch 100] loss: 0.042465599357383324
[Epoch 6, Batch 200] loss: 0.043573312277439984
[Epoch 6, Batch 300] loss: 0.04908602010691539
[Epoch 6, Batch 400] loss: 0.05204220220912248
[Epoch 6, Batch 500] loss: 0.04518132716650143
[Epoch 6, Batch 600] loss: 0.04819885793142021
[Epoch 6, Batch 700] loss: 0.04649901461787522
**STATS for Epoch 6** : 
Average training loss: 0.0024
Average validation loss: 0.0563
Validation Accuracy: 0.9820
Overfitting: 0.0539
[Epoch 7, Batch 100] loss: 0.029950309084961192
[Epoch 7, Batch 200] loss: 0.04423399166902527
[Epoch 7, Batch 300] loss: 0.04103284678189084
[Epoch 7, Batch 400] loss: 0.04142717284150422
[Epoch 7, Batch 500] loss: 0.04115591074456461
[Epoch 7, Batch 600] loss: 0.04439616489456966
[Epoch 7, Batch 700] loss: 0.04449191144201905
**STATS for Epoch 7** : 
Average training loss: 0.0034
Average validation loss: 0.0489
Validation Accuracy: 0.9837
Overfitting: 0.0454
Best model saved at epoch 7 with validation loss: 0.0489
[Epoch 8, Batch 100] loss: 0.03735809615114704
[Epoch 8, Batch 200] loss: 0.031984390228753906
[Epoch 8, Batch 300] loss: 0.03831434022868052
[Epoch 8, Batch 400] loss: 0.03392209605663084
[Epoch 8, Batch 500] loss: 0.039023866052739324
[Epoch 8, Batch 600] loss: 0.03122544168494642
[Epoch 8, Batch 700] loss: 0.037082047911826524
**STATS for Epoch 8** : 
Average training loss: 0.0021
Average validation loss: 0.0508
Validation Accuracy: 0.9841
Overfitting: 0.0487
[Epoch 9, Batch 100] loss: 0.034729734123684464
[Epoch 9, Batch 200] loss: 0.027750088448519818
[Epoch 9, Batch 300] loss: 0.030393377636210063
[Epoch 9, Batch 400] loss: 0.03395812228322029
[Epoch 9, Batch 500] loss: 0.029439332657493652
[Epoch 9, Batch 600] loss: 0.030033195989090017
[Epoch 9, Batch 700] loss: 0.03239486480713822
**STATS for Epoch 9** : 
Average training loss: 0.0020
Average validation loss: 0.0492
Validation Accuracy: 0.9836
Overfitting: 0.0472
[Epoch 10, Batch 100] loss: 0.026011905836639926
[Epoch 10, Batch 200] loss: 0.02437677693320438
[Epoch 10, Batch 300] loss: 0.02343784178432543
[Epoch 10, Batch 400] loss: 0.03274061414878816
[Epoch 10, Batch 500] loss: 0.031921988688700366
[Epoch 10, Batch 600] loss: 0.03277916516875848
[Epoch 10, Batch 700] loss: 0.023931952285347505
**STATS for Epoch 10** : 
Average training loss: 0.0018
Average validation loss: 0.0450
Validation Accuracy: 0.9852
Overfitting: 0.0432
Best model saved at epoch 10 with validation loss: 0.0450
[Epoch 11, Batch 100] loss: 0.02276656472502509
[Epoch 11, Batch 200] loss: 0.02472498554212507
[Epoch 11, Batch 300] loss: 0.020956650422886015
[Epoch 11, Batch 400] loss: 0.020809777788817884
[Epoch 11, Batch 500] loss: 0.033254868950461966
[Epoch 11, Batch 600] loss: 0.027715333871892654
[Epoch 11, Batch 700] loss: 0.022877566061215476
**STATS for Epoch 11** : 
Average training loss: 0.0018
Average validation loss: 0.0513
Validation Accuracy: 0.9840
Overfitting: 0.0496
[Epoch 12, Batch 100] loss: 0.022885001501999794
[Epoch 12, Batch 200] loss: 0.018901042625657283
[Epoch 12, Batch 300] loss: 0.019213359051791487
[Epoch 12, Batch 400] loss: 0.021805806335178205
[Epoch 12, Batch 500] loss: 0.026819182796170935
[Epoch 12, Batch 600] loss: 0.022963029237871524
[Epoch 12, Batch 700] loss: 0.019202372879371977
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0416
Validation Accuracy: 0.9868
Overfitting: 0.0406
Best model saved at epoch 12 with validation loss: 0.0416
[Epoch 13, Batch 100] loss: 0.017201246256008745
[Epoch 13, Batch 200] loss: 0.016787787447101438
[Epoch 13, Batch 300] loss: 0.019137689431227047
[Epoch 13, Batch 400] loss: 0.016812399374321104
[Epoch 13, Batch 500] loss: 0.0162058073625667
[Epoch 13, Batch 600] loss: 0.01947871305485023
[Epoch 13, Batch 700] loss: 0.020082547257188707
**STATS for Epoch 13** : 
Average training loss: 0.0021
Average validation loss: 0.0548
Validation Accuracy: 0.9817
Overfitting: 0.0528
[Epoch 14, Batch 100] loss: 0.01334933978272602
[Epoch 14, Batch 200] loss: 0.0225486163853202
[Epoch 14, Batch 300] loss: 0.015896080022212117
[Epoch 14, Batch 400] loss: 0.016128957626351623
[Epoch 14, Batch 500] loss: 0.014141565730387811
[Epoch 14, Batch 600] loss: 0.02244462879549246
[Epoch 14, Batch 700] loss: 0.018777871979254998
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0513
Validation Accuracy: 0.9854
Overfitting: 0.0501
[Epoch 15, Batch 100] loss: 0.013001024606928695
[Epoch 15, Batch 200] loss: 0.01641874293622095
[Epoch 15, Batch 300] loss: 0.015071556762850378
[Epoch 15, Batch 400] loss: 0.017928846649156185
[Epoch 15, Batch 500] loss: 0.024330187220475637
[Epoch 15, Batch 600] loss: 0.015453790980391204
[Epoch 15, Batch 700] loss: 0.01530265337205492
**STATS for Epoch 15** : 
Average training loss: 0.0016
Average validation loss: 0.0494
Validation Accuracy: 0.9858
Overfitting: 0.0478
[Epoch 16, Batch 100] loss: 0.012561768011946696
[Epoch 16, Batch 200] loss: 0.01241027467767708
[Epoch 16, Batch 300] loss: 0.018808999658504036
[Epoch 16, Batch 400] loss: 0.012824768051505089
[Epoch 16, Batch 500] loss: 0.014525245794211515
[Epoch 16, Batch 600] loss: 0.017291530134680214
[Epoch 16, Batch 700] loss: 0.015560031554268789
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0413
Validation Accuracy: 0.9876
Overfitting: 0.0405
Best model saved at epoch 16 with validation loss: 0.0413
[Epoch 17, Batch 100] loss: 0.008417339586740126
[Epoch 17, Batch 200] loss: 0.013540799011825583
[Epoch 17, Batch 300] loss: 0.012046023356961087
[Epoch 17, Batch 400] loss: 0.0184671776482719
[Epoch 17, Batch 500] loss: 0.009066940061748028
[Epoch 17, Batch 600] loss: 0.013695130511041497
[Epoch 17, Batch 700] loss: 0.013918806028086692
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0446
Validation Accuracy: 0.9873
Overfitting: 0.0437
[Epoch 18, Batch 100] loss: 0.015452945006545633
[Epoch 18, Batch 200] loss: 0.008361509854003088
[Epoch 18, Batch 300] loss: 0.012055642036466451
[Epoch 18, Batch 400] loss: 0.011479472778519266
[Epoch 18, Batch 500] loss: 0.010949495284294244
[Epoch 18, Batch 600] loss: 0.012489132710616104
[Epoch 18, Batch 700] loss: 0.00935531630690093
**STATS for Epoch 18** : 
Average training loss: 0.0005
Average validation loss: 0.0428
Validation Accuracy: 0.9878
Overfitting: 0.0423
[Epoch 19, Batch 100] loss: 0.008873837722785539
[Epoch 19, Batch 200] loss: 0.011364789166182164
[Epoch 19, Batch 300] loss: 0.008093968906905502
[Epoch 19, Batch 400] loss: 0.006349063352827216
[Epoch 19, Batch 500] loss: 0.008502442327298923
[Epoch 19, Batch 600] loss: 0.010067508506544982
[Epoch 19, Batch 700] loss: 0.014279960990170365
**STATS for Epoch 19** : 
Average training loss: 0.0011
Average validation loss: 0.0504
Validation Accuracy: 0.9862
Overfitting: 0.0494
[Epoch 20, Batch 100] loss: 0.007684093770003528
[Epoch 20, Batch 200] loss: 0.0071634683690353996
[Epoch 20, Batch 300] loss: 0.0067341975213093975
[Epoch 20, Batch 400] loss: 0.010906802287645406
[Epoch 20, Batch 500] loss: 0.009048597203072859
[Epoch 20, Batch 600] loss: 0.012200500889557589
[Epoch 20, Batch 700] loss: 0.013623553020952386
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0476
Validation Accuracy: 0.9877
Overfitting: 0.0470
[Epoch 21, Batch 100] loss: 0.0056279474374241545
[Epoch 21, Batch 200] loss: 0.00804165927660506
[Epoch 21, Batch 300] loss: 0.007443461660714092
[Epoch 21, Batch 400] loss: 0.01028393226210028
[Epoch 21, Batch 500] loss: 0.008707376446727722
[Epoch 21, Batch 600] loss: 0.008880073564432678
[Epoch 21, Batch 700] loss: 0.007038446750520962
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0503
Validation Accuracy: 0.9874
Overfitting: 0.0498
[Epoch 22, Batch 100] loss: 0.008345383319974644
[Epoch 22, Batch 200] loss: 0.012143411944125547
[Epoch 22, Batch 300] loss: 0.005036566953676811
[Epoch 22, Batch 400] loss: 0.007072582066793984
[Epoch 22, Batch 500] loss: 0.008181465330781066
[Epoch 22, Batch 600] loss: 0.013880644280434354
[Epoch 22, Batch 700] loss: 0.014800470988484448
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0483
Validation Accuracy: 0.9872
Overfitting: 0.0477
[Epoch 23, Batch 100] loss: 0.007578930291347205
[Epoch 23, Batch 200] loss: 0.008486396633888943
[Epoch 23, Batch 300] loss: 0.008758362763328477
[Epoch 23, Batch 400] loss: 0.008299794787890278
[Epoch 23, Batch 500] loss: 0.005343892077216878
[Epoch 23, Batch 600] loss: 0.00580236567540851
[Epoch 23, Batch 700] loss: 0.007966891319520074
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0467
Validation Accuracy: 0.9881
Overfitting: 0.0465
[Epoch 24, Batch 100] loss: 0.004265824217036425
[Epoch 24, Batch 200] loss: 0.004697396209430735
[Epoch 24, Batch 300] loss: 0.008986114742110658
[Epoch 24, Batch 400] loss: 0.0033610047408001264
[Epoch 24, Batch 500] loss: 0.004628450649288424
[Epoch 24, Batch 600] loss: 0.005857138070350629
[Epoch 24, Batch 700] loss: 0.004536702197838167
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0472
Validation Accuracy: 0.9881
Overfitting: 0.0469
Fold 1 validation loss: 0.0472
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.267725398540497
[Epoch 1, Batch 200] loss: 1.322588992714882
[Epoch 1, Batch 300] loss: 0.4856496262550354
[Epoch 1, Batch 400] loss: 0.36601894840598104
[Epoch 1, Batch 500] loss: 0.2836772382259369
[Epoch 1, Batch 600] loss: 0.23257096588611603
[Epoch 1, Batch 700] loss: 0.17885464556515218
**STATS for Epoch 1** : 
Average training loss: 0.0121
Average validation loss: 0.1809
Validation Accuracy: 0.9452
Overfitting: 0.1688
Best model saved at epoch 1 with validation loss: 0.1809
[Epoch 2, Batch 100] loss: 0.14641353726387024
[Epoch 2, Batch 200] loss: 0.14525622233748436
[Epoch 2, Batch 300] loss: 0.12735238524153827
[Epoch 2, Batch 400] loss: 0.13277075223624707
[Epoch 2, Batch 500] loss: 0.11631419640034438
[Epoch 2, Batch 600] loss: 0.11400509030558169
[Epoch 2, Batch 700] loss: 0.10922739869914949
**STATS for Epoch 2** : 
Average training loss: 0.0069
Average validation loss: 0.1102
Validation Accuracy: 0.9681
Overfitting: 0.1033
Best model saved at epoch 2 with validation loss: 0.1102
[Epoch 3, Batch 100] loss: 0.09378539471887053
[Epoch 3, Batch 200] loss: 0.08959895846433938
[Epoch 3, Batch 300] loss: 0.0928354456461966
[Epoch 3, Batch 400] loss: 0.08599205442704261
[Epoch 3, Batch 500] loss: 0.0796256193332374
[Epoch 3, Batch 600] loss: 0.08684713738039136
[Epoch 3, Batch 700] loss: 0.07410304728429765
**STATS for Epoch 3** : 
Average training loss: 0.0046
Average validation loss: 0.0847
Validation Accuracy: 0.9739
Overfitting: 0.0801
Best model saved at epoch 3 with validation loss: 0.0847
[Epoch 4, Batch 100] loss: 0.06831245553679764
[Epoch 4, Batch 200] loss: 0.07507541703060269
[Epoch 4, Batch 300] loss: 0.06259450253099202
[Epoch 4, Batch 400] loss: 0.05985016605583951
[Epoch 4, Batch 500] loss: 0.0727201183885336
[Epoch 4, Batch 600] loss: 0.06658181371167302
[Epoch 4, Batch 700] loss: 0.055931547242216766
**STATS for Epoch 4** : 
Average training loss: 0.0040
Average validation loss: 0.0800
Validation Accuracy: 0.9751
Overfitting: 0.0760
Best model saved at epoch 4 with validation loss: 0.0800
[Epoch 5, Batch 100] loss: 0.056144681209698316
[Epoch 5, Batch 200] loss: 0.06111784015316516
[Epoch 5, Batch 300] loss: 0.0487064854009077
[Epoch 5, Batch 400] loss: 0.05013747862307355
[Epoch 5, Batch 500] loss: 0.051492903872858736
[Epoch 5, Batch 600] loss: 0.05377507210476324
[Epoch 5, Batch 700] loss: 0.061558258747681976
**STATS for Epoch 5** : 
Average training loss: 0.0036
Average validation loss: 0.0699
Validation Accuracy: 0.9791
Overfitting: 0.0663
Best model saved at epoch 5 with validation loss: 0.0699
[Epoch 6, Batch 100] loss: 0.045385577760171145
[Epoch 6, Batch 200] loss: 0.042044135050382465
[Epoch 6, Batch 300] loss: 0.044393016796093435
[Epoch 6, Batch 400] loss: 0.04280907245120034
[Epoch 6, Batch 500] loss: 0.04653167273616418
[Epoch 6, Batch 600] loss: 0.04798687017057091
[Epoch 6, Batch 700] loss: 0.04574006700888276
**STATS for Epoch 6** : 
Average training loss: 0.0035
Average validation loss: 0.0682
Validation Accuracy: 0.9792
Overfitting: 0.0647
Best model saved at epoch 6 with validation loss: 0.0682
[Epoch 7, Batch 100] loss: 0.040064017217373474
[Epoch 7, Batch 200] loss: 0.04588761326158419
[Epoch 7, Batch 300] loss: 0.03560086486395449
[Epoch 7, Batch 400] loss: 0.040320542689878495
[Epoch 7, Batch 500] loss: 0.04172599334269762
[Epoch 7, Batch 600] loss: 0.03952002660604194
[Epoch 7, Batch 700] loss: 0.03779994932934642
**STATS for Epoch 7** : 
Average training loss: 0.0033
Average validation loss: 0.0684
Validation Accuracy: 0.9785
Overfitting: 0.0652
[Epoch 8, Batch 100] loss: 0.03386426805285737
[Epoch 8, Batch 200] loss: 0.04098715811152943
[Epoch 8, Batch 300] loss: 0.03954816105309874
[Epoch 8, Batch 400] loss: 0.03260243523342069
[Epoch 8, Batch 500] loss: 0.030846203878172673
[Epoch 8, Batch 600] loss: 0.039543086892226714
[Epoch 8, Batch 700] loss: 0.039642742686555724
**STATS for Epoch 8** : 
Average training loss: 0.0022
Average validation loss: 0.0603
Validation Accuracy: 0.9820
Overfitting: 0.0581
Best model saved at epoch 8 with validation loss: 0.0603
[Epoch 9, Batch 100] loss: 0.031213665314135143
[Epoch 9, Batch 200] loss: 0.03311798561830073
[Epoch 9, Batch 300] loss: 0.03244301665108651
[Epoch 9, Batch 400] loss: 0.035030001805280334
[Epoch 9, Batch 500] loss: 0.026574156456626953
[Epoch 9, Batch 600] loss: 0.02893452303716913
[Epoch 9, Batch 700] loss: 0.029791213605203665
**STATS for Epoch 9** : 
Average training loss: 0.0023
Average validation loss: 0.0585
Validation Accuracy: 0.9822
Overfitting: 0.0562
Best model saved at epoch 9 with validation loss: 0.0585
[Epoch 10, Batch 100] loss: 0.023892230842029676
[Epoch 10, Batch 200] loss: 0.02848677199683152
[Epoch 10, Batch 300] loss: 0.029082380515756085
[Epoch 10, Batch 400] loss: 0.03062661770556588
[Epoch 10, Batch 500] loss: 0.022547768434160387
[Epoch 10, Batch 600] loss: 0.027955038910149596
[Epoch 10, Batch 700] loss: 0.030004313151584937
**STATS for Epoch 10** : 
Average training loss: 0.0017
Average validation loss: 0.0597
Validation Accuracy: 0.9831
Overfitting: 0.0579
[Epoch 11, Batch 100] loss: 0.018954681916511618
[Epoch 11, Batch 200] loss: 0.027887064209207894
[Epoch 11, Batch 300] loss: 0.021792254466563462
[Epoch 11, Batch 400] loss: 0.024750184555887244
[Epoch 11, Batch 500] loss: 0.0254550960790948
[Epoch 11, Batch 600] loss: 0.023014052720973267
[Epoch 11, Batch 700] loss: 0.027320555479382166
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0567
Validation Accuracy: 0.9844
Overfitting: 0.0550
Best model saved at epoch 11 with validation loss: 0.0567
[Epoch 12, Batch 100] loss: 0.0165424092131434
[Epoch 12, Batch 200] loss: 0.021225421243580057
[Epoch 12, Batch 300] loss: 0.02247503561869962
[Epoch 12, Batch 400] loss: 0.021204543769708834
[Epoch 12, Batch 500] loss: 0.021263315357500687
[Epoch 12, Batch 600] loss: 0.02352043799299281
[Epoch 12, Batch 700] loss: 0.02913615993107669
**STATS for Epoch 12** : 
Average training loss: 0.0017
Average validation loss: 0.0570
Validation Accuracy: 0.9838
Overfitting: 0.0553
[Epoch 13, Batch 100] loss: 0.018614079872786533
[Epoch 13, Batch 200] loss: 0.020011816939222625
[Epoch 13, Batch 300] loss: 0.014995780465687858
[Epoch 13, Batch 400] loss: 0.020181494493153877
[Epoch 13, Batch 500] loss: 0.019642270322074183
[Epoch 13, Batch 600] loss: 0.020053251135977918
[Epoch 13, Batch 700] loss: 0.02166791648895014
**STATS for Epoch 13** : 
Average training loss: 0.0015
Average validation loss: 0.0586
Validation Accuracy: 0.9828
Overfitting: 0.0571
[Epoch 14, Batch 100] loss: 0.01342945696640527
[Epoch 14, Batch 200] loss: 0.017789555062481668
[Epoch 14, Batch 300] loss: 0.02056259064716869
[Epoch 14, Batch 400] loss: 0.017634888810862323
[Epoch 14, Batch 500] loss: 0.019806800871738233
[Epoch 14, Batch 600] loss: 0.018049696091911756
[Epoch 14, Batch 700] loss: 0.023372184356558138
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0539
Validation Accuracy: 0.9849
Overfitting: 0.0532
Best model saved at epoch 14 with validation loss: 0.0539
[Epoch 15, Batch 100] loss: 0.014093821518326877
[Epoch 15, Batch 200] loss: 0.013834091640892438
[Epoch 15, Batch 300] loss: 0.017685942204552704
[Epoch 15, Batch 400] loss: 0.01579213995813916
[Epoch 15, Batch 500] loss: 0.013722237814363325
[Epoch 15, Batch 600] loss: 0.016175102514825995
[Epoch 15, Batch 700] loss: 0.01513453823281452
**STATS for Epoch 15** : 
Average training loss: 0.0016
Average validation loss: 0.0674
Validation Accuracy: 0.9831
Overfitting: 0.0657
[Epoch 16, Batch 100] loss: 0.011809522182593355
[Epoch 16, Batch 200] loss: 0.016963448694586988
[Epoch 16, Batch 300] loss: 0.01166812756389845
[Epoch 16, Batch 400] loss: 0.013776160533016082
[Epoch 16, Batch 500] loss: 0.012200378396373708
[Epoch 16, Batch 600] loss: 0.014783573015010916
[Epoch 16, Batch 700] loss: 0.016784977160641576
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0632
Validation Accuracy: 0.9840
Overfitting: 0.0622
[Epoch 17, Batch 100] loss: 0.0141561820966308
[Epoch 17, Batch 200] loss: 0.012087531097204191
[Epoch 17, Batch 300] loss: 0.014689659430878237
[Epoch 17, Batch 400] loss: 0.015176498678629287
[Epoch 17, Batch 500] loss: 0.009931293987756362
[Epoch 17, Batch 600] loss: 0.02000406311984989
[Epoch 17, Batch 700] loss: 0.010855781275313347
**STATS for Epoch 17** : 
Average training loss: 0.0012
Average validation loss: 0.0561
Validation Accuracy: 0.9846
Overfitting: 0.0549
[Epoch 18, Batch 100] loss: 0.009712174447922734
[Epoch 18, Batch 200] loss: 0.010858472270920174
[Epoch 18, Batch 300] loss: 0.011748949934553821
[Epoch 18, Batch 400] loss: 0.01168646478188748
[Epoch 18, Batch 500] loss: 0.013740978082059882
[Epoch 18, Batch 600] loss: 0.014706787326213088
[Epoch 18, Batch 700] loss: 0.017434566492738668
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0578
Validation Accuracy: 0.9843
Overfitting: 0.0570
[Epoch 19, Batch 100] loss: 0.011161958334214432
[Epoch 19, Batch 200] loss: 0.011727914449584204
[Epoch 19, Batch 300] loss: 0.011817291880870471
[Epoch 19, Batch 400] loss: 0.011040988024469699
[Epoch 19, Batch 500] loss: 0.008510039450557087
[Epoch 19, Batch 600] loss: 0.008907269808623823
[Epoch 19, Batch 700] loss: 0.008645342577292468
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0588
Validation Accuracy: 0.9856
Overfitting: 0.0582
[Epoch 20, Batch 100] loss: 0.007516906365635805
[Epoch 20, Batch 200] loss: 0.011184119348035893
[Epoch 20, Batch 300] loss: 0.010606740834264201
[Epoch 20, Batch 400] loss: 0.007089353747214772
[Epoch 20, Batch 500] loss: 0.021218226668679563
[Epoch 20, Batch 600] loss: 0.010995208804743015
[Epoch 20, Batch 700] loss: 0.009681175426449045
**STATS for Epoch 20** : 
Average training loss: 0.0007
Average validation loss: 0.0595
Validation Accuracy: 0.9865
Overfitting: 0.0588
[Epoch 21, Batch 100] loss: 0.006776331538167142
[Epoch 21, Batch 200] loss: 0.010697585608795634
[Epoch 21, Batch 300] loss: 0.005742819512852293
[Epoch 21, Batch 400] loss: 0.007608597176713374
[Epoch 21, Batch 500] loss: 0.013944355684216134
[Epoch 21, Batch 600] loss: 0.009805783249430534
[Epoch 21, Batch 700] loss: 0.006004281537461793
**STATS for Epoch 21** : 
Average training loss: 0.0007
Average validation loss: 0.0590
Validation Accuracy: 0.9863
Overfitting: 0.0584
[Epoch 22, Batch 100] loss: 0.0075982216171541946
[Epoch 22, Batch 200] loss: 0.004555870492658869
[Epoch 22, Batch 300] loss: 0.006479447795427405
[Epoch 22, Batch 400] loss: 0.007921865702483046
[Epoch 22, Batch 500] loss: 0.01078451324672642
[Epoch 22, Batch 600] loss: 0.007140086501312908
[Epoch 22, Batch 700] loss: 0.005476716906196088
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0632
Validation Accuracy: 0.9850
Overfitting: 0.0626
[Epoch 23, Batch 100] loss: 0.007730048123485176
[Epoch 23, Batch 200] loss: 0.007734575941103685
[Epoch 23, Batch 300] loss: 0.008504060012928676
[Epoch 23, Batch 400] loss: 0.010301114176654665
[Epoch 23, Batch 500] loss: 0.004544211752290721
[Epoch 23, Batch 600] loss: 0.007639927916097804
[Epoch 23, Batch 700] loss: 0.005503331086438266
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0632
Validation Accuracy: 0.9860
Overfitting: 0.0628
[Epoch 24, Batch 100] loss: 0.004433028388730236
[Epoch 24, Batch 200] loss: 0.006347751402863651
[Epoch 24, Batch 300] loss: 0.007885507534083444
[Epoch 24, Batch 400] loss: 0.007171444129453448
[Epoch 24, Batch 500] loss: 0.007797522098298941
[Epoch 24, Batch 600] loss: 0.008980554608715465
[Epoch 24, Batch 700] loss: 0.008002178230417484
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0662
Validation Accuracy: 0.9862
Overfitting: 0.0659
Fold 2 validation loss: 0.0662
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.281720373630524
[Epoch 1, Batch 200] loss: 1.4573477026820183
[Epoch 1, Batch 300] loss: 0.4854963694512844
[Epoch 1, Batch 400] loss: 0.3425931339710951
[Epoch 1, Batch 500] loss: 0.26455149821937085
[Epoch 1, Batch 600] loss: 0.22738900426775216
[Epoch 1, Batch 700] loss: 0.18909951202571393
**STATS for Epoch 1** : 
Average training loss: 0.0107
Average validation loss: 0.1800
Validation Accuracy: 0.9453
Overfitting: 0.1693
Best model saved at epoch 1 with validation loss: 0.1800
[Epoch 2, Batch 100] loss: 0.1598680067062378
[Epoch 2, Batch 200] loss: 0.12810366349294783
[Epoch 2, Batch 300] loss: 0.12288947137072682
[Epoch 2, Batch 400] loss: 0.11291468663141131
[Epoch 2, Batch 500] loss: 0.11640427820384502
[Epoch 2, Batch 600] loss: 0.11886619787663222
[Epoch 2, Batch 700] loss: 0.09506660409271717
**STATS for Epoch 2** : 
Average training loss: 0.0071
Average validation loss: 0.1051
Validation Accuracy: 0.9682
Overfitting: 0.0980
Best model saved at epoch 2 with validation loss: 0.1051
[Epoch 3, Batch 100] loss: 0.09100183978676796
[Epoch 3, Batch 200] loss: 0.09584028529003262
[Epoch 3, Batch 300] loss: 0.0942530078208074
[Epoch 3, Batch 400] loss: 0.08251011363230645
[Epoch 3, Batch 500] loss: 0.08408591707237065
[Epoch 3, Batch 600] loss: 0.08224968527210877
[Epoch 3, Batch 700] loss: 0.07927134154364467
**STATS for Epoch 3** : 
Average training loss: 0.0046
Average validation loss: 0.0758
Validation Accuracy: 0.9758
Overfitting: 0.0712
Best model saved at epoch 3 with validation loss: 0.0758
[Epoch 4, Batch 100] loss: 0.064285732912831
[Epoch 4, Batch 200] loss: 0.06819445022381843
[Epoch 4, Batch 300] loss: 0.07023194515146315
[Epoch 4, Batch 400] loss: 0.06653564637992532
[Epoch 4, Batch 500] loss: 0.07306708637159318
[Epoch 4, Batch 600] loss: 0.06056521724909544
[Epoch 4, Batch 700] loss: 0.06863965881057084
**STATS for Epoch 4** : 
Average training loss: 0.0050
Average validation loss: 0.0740
Validation Accuracy: 0.9767
Overfitting: 0.0690
Best model saved at epoch 4 with validation loss: 0.0740
[Epoch 5, Batch 100] loss: 0.056025792448781433
[Epoch 5, Batch 200] loss: 0.060516201304271815
[Epoch 5, Batch 300] loss: 0.056714188392506915
[Epoch 5, Batch 400] loss: 0.06556532736402004
[Epoch 5, Batch 500] loss: 0.05272393783554435
[Epoch 5, Batch 600] loss: 0.05634870240930468
[Epoch 5, Batch 700] loss: 0.05629881647881121
**STATS for Epoch 5** : 
Average training loss: 0.0038
Average validation loss: 0.0609
Validation Accuracy: 0.9802
Overfitting: 0.0570
Best model saved at epoch 5 with validation loss: 0.0609
[Epoch 6, Batch 100] loss: 0.04390998288989067
[Epoch 6, Batch 200] loss: 0.05220134353497997
[Epoch 6, Batch 300] loss: 0.04756886876188218
[Epoch 6, Batch 400] loss: 0.047003821725957094
[Epoch 6, Batch 500] loss: 0.04785072678234428
[Epoch 6, Batch 600] loss: 0.05700281416065991
[Epoch 6, Batch 700] loss: 0.04740097293863073
**STATS for Epoch 6** : 
Average training loss: 0.0028
Average validation loss: 0.0609
Validation Accuracy: 0.9811
Overfitting: 0.0581
[Epoch 7, Batch 100] loss: 0.0445657313533593
[Epoch 7, Batch 200] loss: 0.04510867994395085
[Epoch 7, Batch 300] loss: 0.047843750077299775
[Epoch 7, Batch 400] loss: 0.03785498157376423
[Epoch 7, Batch 500] loss: 0.04349601079011336
[Epoch 7, Batch 600] loss: 0.04798218612326309
[Epoch 7, Batch 700] loss: 0.05330039504216984
**STATS for Epoch 7** : 
Average training loss: 0.0033
Average validation loss: 0.0523
Validation Accuracy: 0.9836
Overfitting: 0.0490
Best model saved at epoch 7 with validation loss: 0.0523
[Epoch 8, Batch 100] loss: 0.0346338622411713
[Epoch 8, Batch 200] loss: 0.035652702257502826
[Epoch 8, Batch 300] loss: 0.03267310673603788
[Epoch 8, Batch 400] loss: 0.051644784638192505
[Epoch 8, Batch 500] loss: 0.04000652973074466
[Epoch 8, Batch 600] loss: 0.03559166082879529
[Epoch 8, Batch 700] loss: 0.03269188079168089
**STATS for Epoch 8** : 
Average training loss: 0.0029
Average validation loss: 0.0521
Validation Accuracy: 0.9852
Overfitting: 0.0492
Best model saved at epoch 8 with validation loss: 0.0521
[Epoch 9, Batch 100] loss: 0.03296522605232895
[Epoch 9, Batch 200] loss: 0.03442647184361704
[Epoch 9, Batch 300] loss: 0.03236442291527055
[Epoch 9, Batch 400] loss: 0.03416503221204039
[Epoch 9, Batch 500] loss: 0.029336450170376338
[Epoch 9, Batch 600] loss: 0.03792874746839516
[Epoch 9, Batch 700] loss: 0.03135732877301052
**STATS for Epoch 9** : 
Average training loss: 0.0025
Average validation loss: 0.0529
Validation Accuracy: 0.9836
Overfitting: 0.0505
[Epoch 10, Batch 100] loss: 0.03095225528231822
[Epoch 10, Batch 200] loss: 0.03448576644994319
[Epoch 10, Batch 300] loss: 0.024819879395654425
[Epoch 10, Batch 400] loss: 0.02560113335028291
[Epoch 10, Batch 500] loss: 0.033218715945258735
[Epoch 10, Batch 600] loss: 0.029788473381195217
[Epoch 10, Batch 700] loss: 0.026952292826608756
**STATS for Epoch 10** : 
Average training loss: 0.0026
Average validation loss: 0.0572
Validation Accuracy: 0.9826
Overfitting: 0.0547
[Epoch 11, Batch 100] loss: 0.022392403138801455
[Epoch 11, Batch 200] loss: 0.027516790456429588
[Epoch 11, Batch 300] loss: 0.02433268554741517
[Epoch 11, Batch 400] loss: 0.031151076680398546
[Epoch 11, Batch 500] loss: 0.022900929168681614
[Epoch 11, Batch 600] loss: 0.025728233229601757
[Epoch 11, Batch 700] loss: 0.025702964851952857
**STATS for Epoch 11** : 
Average training loss: 0.0024
Average validation loss: 0.0426
Validation Accuracy: 0.9872
Overfitting: 0.0402
Best model saved at epoch 11 with validation loss: 0.0426
[Epoch 12, Batch 100] loss: 0.022260078500257807
[Epoch 12, Batch 200] loss: 0.021798086186754516
[Epoch 12, Batch 300] loss: 0.019614780705305746
[Epoch 12, Batch 400] loss: 0.016282997100788635
[Epoch 12, Batch 500] loss: 0.028943347539752723
[Epoch 12, Batch 600] loss: 0.031788571287179365
[Epoch 12, Batch 700] loss: 0.025438474748516456
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0468
Validation Accuracy: 0.9866
Overfitting: 0.0456
[Epoch 13, Batch 100] loss: 0.01785301532712765
[Epoch 13, Batch 200] loss: 0.020650788968196138
[Epoch 13, Batch 300] loss: 0.017514606261393055
[Epoch 13, Batch 400] loss: 0.01966981674922863
[Epoch 13, Batch 500] loss: 0.024662509555346334
[Epoch 13, Batch 600] loss: 0.0253738533006981
[Epoch 13, Batch 700] loss: 0.01913513635896379
**STATS for Epoch 13** : 
Average training loss: 0.0020
Average validation loss: 0.0599
Validation Accuracy: 0.9832
Overfitting: 0.0579
[Epoch 14, Batch 100] loss: 0.01918254773685476
[Epoch 14, Batch 200] loss: 0.017812947965576312
[Epoch 14, Batch 300] loss: 0.020095432364032603
[Epoch 14, Batch 400] loss: 0.02213755746895913
[Epoch 14, Batch 500] loss: 0.017421042994828894
[Epoch 14, Batch 600] loss: 0.020384241925785317
[Epoch 14, Batch 700] loss: 0.01702901991142426
**STATS for Epoch 14** : 
Average training loss: 0.0015
Average validation loss: 0.0516
Validation Accuracy: 0.9848
Overfitting: 0.0501
[Epoch 15, Batch 100] loss: 0.014461732508498243
[Epoch 15, Batch 200] loss: 0.02258406230219407
[Epoch 15, Batch 300] loss: 0.020149686445074623
[Epoch 15, Batch 400] loss: 0.017473849937086925
[Epoch 15, Batch 500] loss: 0.014494387361919507
[Epoch 15, Batch 600] loss: 0.01935712362799677
[Epoch 15, Batch 700] loss: 0.018708073489251548
**STATS for Epoch 15** : 
Average training loss: 0.0014
Average validation loss: 0.0532
Validation Accuracy: 0.9852
Overfitting: 0.0518
[Epoch 16, Batch 100] loss: 0.017666260797414
[Epoch 16, Batch 200] loss: 0.014165355798613746
[Epoch 16, Batch 300] loss: 0.015302870446175803
[Epoch 16, Batch 400] loss: 0.01468645342218224
[Epoch 16, Batch 500] loss: 0.016599692002346275
[Epoch 16, Batch 600] loss: 0.016261424736876508
[Epoch 16, Batch 700] loss: 0.014961469664995094
**STATS for Epoch 16** : 
Average training loss: 0.0012
Average validation loss: 0.0467
Validation Accuracy: 0.9867
Overfitting: 0.0456
[Epoch 17, Batch 100] loss: 0.013364241457893514
[Epoch 17, Batch 200] loss: 0.009135774424357805
[Epoch 17, Batch 300] loss: 0.011740927911596373
[Epoch 17, Batch 400] loss: 0.012803955365816364
[Epoch 17, Batch 500] loss: 0.015442902569338912
[Epoch 17, Batch 600] loss: 0.015794137429620606
[Epoch 17, Batch 700] loss: 0.0152853828764637
**STATS for Epoch 17** : 
Average training loss: 0.0014
Average validation loss: 0.0471
Validation Accuracy: 0.9863
Overfitting: 0.0457
[Epoch 18, Batch 100] loss: 0.010858396801559138
[Epoch 18, Batch 200] loss: 0.013323676863728906
[Epoch 18, Batch 300] loss: 0.015694521194091066
[Epoch 18, Batch 400] loss: 0.011753938820038456
[Epoch 18, Batch 500] loss: 0.013130193288816372
[Epoch 18, Batch 600] loss: 0.010831934148009169
[Epoch 18, Batch 700] loss: 0.01414419992826879
**STATS for Epoch 18** : 
Average training loss: 0.0013
Average validation loss: 0.0512
Validation Accuracy: 0.9867
Overfitting: 0.0499
[Epoch 19, Batch 100] loss: 0.009062151190737494
[Epoch 19, Batch 200] loss: 0.009932141505705658
[Epoch 19, Batch 300] loss: 0.010910266061509901
[Epoch 19, Batch 400] loss: 0.010578137046686607
[Epoch 19, Batch 500] loss: 0.013755646995268761
[Epoch 19, Batch 600] loss: 0.011787154808698687
[Epoch 19, Batch 700] loss: 0.01084841343923472
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0498
Validation Accuracy: 0.9867
Overfitting: 0.0490
[Epoch 20, Batch 100] loss: 0.013420388440936222
[Epoch 20, Batch 200] loss: 0.0080802682983267
[Epoch 20, Batch 300] loss: 0.007264718672595336
[Epoch 20, Batch 400] loss: 0.012730935808940557
[Epoch 20, Batch 500] loss: 0.0090586502419319
[Epoch 20, Batch 600] loss: 0.009677451744064456
[Epoch 20, Batch 700] loss: 0.011106648276363557
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0446
Validation Accuracy: 0.9882
Overfitting: 0.0440
[Epoch 21, Batch 100] loss: 0.010980673731683054
[Epoch 21, Batch 200] loss: 0.004848984933414613
[Epoch 21, Batch 300] loss: 0.0067039389157798725
[Epoch 21, Batch 400] loss: 0.008633852653620124
[Epoch 21, Batch 500] loss: 0.007620278770773438
[Epoch 21, Batch 600] loss: 0.007704621063021477
[Epoch 21, Batch 700] loss: 0.01100709722704778
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0495
Validation Accuracy: 0.9874
Overfitting: 0.0489
[Epoch 22, Batch 100] loss: 0.008317472306807759
[Epoch 22, Batch 200] loss: 0.008065240565038038
[Epoch 22, Batch 300] loss: 0.006356779397428909
[Epoch 22, Batch 400] loss: 0.007467220193175308
[Epoch 22, Batch 500] loss: 0.007706573750328971
[Epoch 22, Batch 600] loss: 0.011078198871400673
[Epoch 22, Batch 700] loss: 0.008265492763457586
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0497
Validation Accuracy: 0.9871
Overfitting: 0.0491
[Epoch 23, Batch 100] loss: 0.006397507852743729
[Epoch 23, Batch 200] loss: 0.006372667972573254
[Epoch 23, Batch 300] loss: 0.004690660585492878
[Epoch 23, Batch 400] loss: 0.004122326015667568
[Epoch 23, Batch 500] loss: 0.008622399561954808
[Epoch 23, Batch 600] loss: 0.010138213382815594
[Epoch 23, Batch 700] loss: 0.007231230596826208
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0575
Validation Accuracy: 0.9860
Overfitting: 0.0568
[Epoch 24, Batch 100] loss: 0.004451663696581818
[Epoch 24, Batch 200] loss: 0.004352709858958406
[Epoch 24, Batch 300] loss: 0.0033430858826613984
[Epoch 24, Batch 400] loss: 0.0035045626037117474
[Epoch 24, Batch 500] loss: 0.0064374436359867105
[Epoch 24, Batch 600] loss: 0.006394251190613431
[Epoch 24, Batch 700] loss: 0.005394014711318959
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0524
Validation Accuracy: 0.9872
Overfitting: 0.0521
Fold 3 validation loss: 0.0524
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.270281994342804
[Epoch 1, Batch 200] loss: 1.3474053770303727
[Epoch 1, Batch 300] loss: 0.4599717964231968
[Epoch 1, Batch 400] loss: 0.3424426645040512
[Epoch 1, Batch 500] loss: 0.2584247414395213
[Epoch 1, Batch 600] loss: 0.2318712876737118
[Epoch 1, Batch 700] loss: 0.1866018731892109
**STATS for Epoch 1** : 
Average training loss: 0.0110
Average validation loss: 0.1850
Validation Accuracy: 0.9398
Overfitting: 0.1740
Best model saved at epoch 1 with validation loss: 0.1850
[Epoch 2, Batch 100] loss: 0.15844059832394122
[Epoch 2, Batch 200] loss: 0.1429587423056364
[Epoch 2, Batch 300] loss: 0.13481296656653285
[Epoch 2, Batch 400] loss: 0.1208988705649972
[Epoch 2, Batch 500] loss: 0.12700330786406994
[Epoch 2, Batch 600] loss: 0.11081878042779864
[Epoch 2, Batch 700] loss: 0.11583166440017521
**STATS for Epoch 2** : 
Average training loss: 0.0066
Average validation loss: 0.0899
Validation Accuracy: 0.9723
Overfitting: 0.0832
Best model saved at epoch 2 with validation loss: 0.0899
[Epoch 3, Batch 100] loss: 0.0870141121186316
[Epoch 3, Batch 200] loss: 0.09324534486979247
[Epoch 3, Batch 300] loss: 0.09232914932072163
[Epoch 3, Batch 400] loss: 0.09006445741280913
[Epoch 3, Batch 500] loss: 0.09049827192910015
[Epoch 3, Batch 600] loss: 0.07909586031921208
[Epoch 3, Batch 700] loss: 0.07586041156202555
**STATS for Epoch 3** : 
Average training loss: 0.0063
Average validation loss: 0.0764
Validation Accuracy: 0.9760
Overfitting: 0.0701
Best model saved at epoch 3 with validation loss: 0.0764
[Epoch 4, Batch 100] loss: 0.07773202523123474
[Epoch 4, Batch 200] loss: 0.06725001835264266
[Epoch 4, Batch 300] loss: 0.0806918966025114
[Epoch 4, Batch 400] loss: 0.06115286230109632
[Epoch 4, Batch 500] loss: 0.06989286697935312
[Epoch 4, Batch 600] loss: 0.05914286933839321
[Epoch 4, Batch 700] loss: 0.05946475171484053
**STATS for Epoch 4** : 
Average training loss: 0.0044
Average validation loss: 0.0681
Validation Accuracy: 0.9781
Overfitting: 0.0637
Best model saved at epoch 4 with validation loss: 0.0681
[Epoch 5, Batch 100] loss: 0.05566414113622159
[Epoch 5, Batch 200] loss: 0.06866308764088899
[Epoch 5, Batch 300] loss: 0.05648632706841454
[Epoch 5, Batch 400] loss: 0.051602831683121624
[Epoch 5, Batch 500] loss: 0.05850987638346851
[Epoch 5, Batch 600] loss: 0.06210785734001547
[Epoch 5, Batch 700] loss: 0.0499619831983
**STATS for Epoch 5** : 
Average training loss: 0.0035
Average validation loss: 0.0605
Validation Accuracy: 0.9800
Overfitting: 0.0570
Best model saved at epoch 5 with validation loss: 0.0605
[Epoch 6, Batch 100] loss: 0.0456559380935505
[Epoch 6, Batch 200] loss: 0.053498474538791925
[Epoch 6, Batch 300] loss: 0.049727987237274646
[Epoch 6, Batch 400] loss: 0.05807238365756348
[Epoch 6, Batch 500] loss: 0.043277068671304736
[Epoch 6, Batch 600] loss: 0.04821049324702471
[Epoch 6, Batch 700] loss: 0.04871617150260135
**STATS for Epoch 6** : 
Average training loss: 0.0026
Average validation loss: 0.0565
Validation Accuracy: 0.9817
Overfitting: 0.0539
Best model saved at epoch 6 with validation loss: 0.0565
[Epoch 7, Batch 100] loss: 0.03413829421508126
[Epoch 7, Batch 200] loss: 0.042672829303191974
[Epoch 7, Batch 300] loss: 0.03818168442463502
[Epoch 7, Batch 400] loss: 0.04189490099903196
[Epoch 7, Batch 500] loss: 0.0449204873223789
[Epoch 7, Batch 600] loss: 0.05527261468814686
[Epoch 7, Batch 700] loss: 0.051153207388706504
**STATS for Epoch 7** : 
Average training loss: 0.0025
Average validation loss: 0.0581
Validation Accuracy: 0.9815
Overfitting: 0.0557
[Epoch 8, Batch 100] loss: 0.03809191980515607
[Epoch 8, Batch 200] loss: 0.042518157646991316
[Epoch 8, Batch 300] loss: 0.04162081100745127
[Epoch 8, Batch 400] loss: 0.036232063837815076
[Epoch 8, Batch 500] loss: 0.029524625074118377
[Epoch 8, Batch 600] loss: 0.036530672124354166
[Epoch 8, Batch 700] loss: 0.034825008674524725
**STATS for Epoch 8** : 
Average training loss: 0.0028
Average validation loss: 0.0553
Validation Accuracy: 0.9826
Overfitting: 0.0525
Best model saved at epoch 8 with validation loss: 0.0553
[Epoch 9, Batch 100] loss: 0.03166406035423279
[Epoch 9, Batch 200] loss: 0.034392487232107666
[Epoch 9, Batch 300] loss: 0.029545456415507942
[Epoch 9, Batch 400] loss: 0.03069935025589075
[Epoch 9, Batch 500] loss: 0.035292790898820384
[Epoch 9, Batch 600] loss: 0.03064121093135327
[Epoch 9, Batch 700] loss: 0.03209550460218452
**STATS for Epoch 9** : 
Average training loss: 0.0033
Average validation loss: 0.0509
Validation Accuracy: 0.9846
Overfitting: 0.0476
Best model saved at epoch 9 with validation loss: 0.0509
[Epoch 10, Batch 100] loss: 0.027667501633986832
[Epoch 10, Batch 200] loss: 0.024983563674613834
[Epoch 10, Batch 300] loss: 0.03216861639055423
[Epoch 10, Batch 400] loss: 0.0309641785081476
[Epoch 10, Batch 500] loss: 0.03213103109912481
[Epoch 10, Batch 600] loss: 0.030469661684473976
[Epoch 10, Batch 700] loss: 0.0350358604080975
**STATS for Epoch 10** : 
Average training loss: 0.0020
Average validation loss: 0.0498
Validation Accuracy: 0.9842
Overfitting: 0.0478
Best model saved at epoch 10 with validation loss: 0.0498
[Epoch 11, Batch 100] loss: 0.02360641437349841
[Epoch 11, Batch 200] loss: 0.02802621654700488
[Epoch 11, Batch 300] loss: 0.02101703319232911
[Epoch 11, Batch 400] loss: 0.022978254419285804
[Epoch 11, Batch 500] loss: 0.0285871260863496
[Epoch 11, Batch 600] loss: 0.030059134917974007
[Epoch 11, Batch 700] loss: 0.026806932410399897
**STATS for Epoch 11** : 
Average training loss: 0.0019
Average validation loss: 0.0472
Validation Accuracy: 0.9849
Overfitting: 0.0453
Best model saved at epoch 11 with validation loss: 0.0472
[Epoch 12, Batch 100] loss: 0.021691059094737283
[Epoch 12, Batch 200] loss: 0.02062918999348767
[Epoch 12, Batch 300] loss: 0.022401341050863267
[Epoch 12, Batch 400] loss: 0.02533110466436483
[Epoch 12, Batch 500] loss: 0.021928662644058933
[Epoch 12, Batch 600] loss: 0.02239310437173117
[Epoch 12, Batch 700] loss: 0.026102740484056995
**STATS for Epoch 12** : 
Average training loss: 0.0015
Average validation loss: 0.0454
Validation Accuracy: 0.9860
Overfitting: 0.0439
Best model saved at epoch 12 with validation loss: 0.0454
[Epoch 13, Batch 100] loss: 0.01599830348568503
[Epoch 13, Batch 200] loss: 0.018079249221191276
[Epoch 13, Batch 300] loss: 0.02598676067253109
[Epoch 13, Batch 400] loss: 0.026449110818793996
[Epoch 13, Batch 500] loss: 0.025089693682384676
[Epoch 13, Batch 600] loss: 0.02166716495761648
[Epoch 13, Batch 700] loss: 0.024407998177339324
**STATS for Epoch 13** : 
Average training loss: 0.0015
Average validation loss: 0.0499
Validation Accuracy: 0.9858
Overfitting: 0.0484
[Epoch 14, Batch 100] loss: 0.017060375661239958
[Epoch 14, Batch 200] loss: 0.014981411139306147
[Epoch 14, Batch 300] loss: 0.014632785190042342
[Epoch 14, Batch 400] loss: 0.021232631922030124
[Epoch 14, Batch 500] loss: 0.023364729142049328
[Epoch 14, Batch 600] loss: 0.017599302640301174
[Epoch 14, Batch 700] loss: 0.020744463365117552
**STATS for Epoch 14** : 
Average training loss: 0.0017
Average validation loss: 0.0449
Validation Accuracy: 0.9869
Overfitting: 0.0432
Best model saved at epoch 14 with validation loss: 0.0449
[Epoch 15, Batch 100] loss: 0.011465673774655443
[Epoch 15, Batch 200] loss: 0.012206698618538212
[Epoch 15, Batch 300] loss: 0.014841660147649236
[Epoch 15, Batch 400] loss: 0.01574076121323742
[Epoch 15, Batch 500] loss: 0.014908927099895664
[Epoch 15, Batch 600] loss: 0.022473917358438483
[Epoch 15, Batch 700] loss: 0.017617521066131302
**STATS for Epoch 15** : 
Average training loss: 0.0016
Average validation loss: 0.0522
Validation Accuracy: 0.9845
Overfitting: 0.0507
[Epoch 16, Batch 100] loss: 0.017544225208985152
[Epoch 16, Batch 200] loss: 0.017096371653315144
[Epoch 16, Batch 300] loss: 0.01114939099730691
[Epoch 16, Batch 400] loss: 0.014285750838171225
[Epoch 16, Batch 500] loss: 0.015184873973485082
[Epoch 16, Batch 600] loss: 0.015845578382140957
[Epoch 16, Batch 700] loss: 0.015124488061992451
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0453
Validation Accuracy: 0.9873
Overfitting: 0.0443
[Epoch 17, Batch 100] loss: 0.010920776546699927
[Epoch 17, Batch 200] loss: 0.01416259575955337
[Epoch 17, Batch 300] loss: 0.012298313629580662
[Epoch 17, Batch 400] loss: 0.014941204374699736
[Epoch 17, Batch 500] loss: 0.023176649514061863
[Epoch 17, Batch 600] loss: 0.01798035319050541
[Epoch 17, Batch 700] loss: 0.01893782824772643
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0494
Validation Accuracy: 0.9856
Overfitting: 0.0486
[Epoch 18, Batch 100] loss: 0.014561556502303574
[Epoch 18, Batch 200] loss: 0.00983920001614024
[Epoch 18, Batch 300] loss: 0.01232304036981077
[Epoch 18, Batch 400] loss: 0.01048520774478675
[Epoch 18, Batch 500] loss: 0.011241415427211904
[Epoch 18, Batch 600] loss: 0.010961511987188715
[Epoch 18, Batch 700] loss: 0.013950677238753997
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0450
Validation Accuracy: 0.9871
Overfitting: 0.0442
[Epoch 19, Batch 100] loss: 0.008109722779190634
[Epoch 19, Batch 200] loss: 0.008935491168376757
[Epoch 19, Batch 300] loss: 0.010410874205408618
[Epoch 19, Batch 400] loss: 0.01186139775589254
[Epoch 19, Batch 500] loss: 0.012272993644655799
[Epoch 19, Batch 600] loss: 0.010076912769582122
[Epoch 19, Batch 700] loss: 0.013125206622789846
**STATS for Epoch 19** : 
Average training loss: 0.0010
Average validation loss: 0.0564
Validation Accuracy: 0.9850
Overfitting: 0.0554
[Epoch 20, Batch 100] loss: 0.00854134991459432
[Epoch 20, Batch 200] loss: 0.011658934167571714
[Epoch 20, Batch 300] loss: 0.01050436920246284
[Epoch 20, Batch 400] loss: 0.007994046224921477
[Epoch 20, Batch 500] loss: 0.01127025603214861
[Epoch 20, Batch 600] loss: 0.010534184622338216
[Epoch 20, Batch 700] loss: 0.007650205953359546
**STATS for Epoch 20** : 
Average training loss: 0.0009
Average validation loss: 0.0590
Validation Accuracy: 0.9852
Overfitting: 0.0581
[Epoch 21, Batch 100] loss: 0.006680443399236537
[Epoch 21, Batch 200] loss: 0.011104817595914938
[Epoch 21, Batch 300] loss: 0.008099799299670848
[Epoch 21, Batch 400] loss: 0.007202402898365108
[Epoch 21, Batch 500] loss: 0.011679579124975135
[Epoch 21, Batch 600] loss: 0.006252667693261173
[Epoch 21, Batch 700] loss: 0.007638852120253432
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0509
Validation Accuracy: 0.9873
Overfitting: 0.0504
[Epoch 22, Batch 100] loss: 0.008195106258790474
[Epoch 22, Batch 200] loss: 0.005689501999549975
[Epoch 22, Batch 300] loss: 0.010022964063709878
[Epoch 22, Batch 400] loss: 0.00700975807820214
[Epoch 22, Batch 500] loss: 0.005662512558046728
[Epoch 22, Batch 600] loss: 0.008100953490065876
[Epoch 22, Batch 700] loss: 0.009122928476244851
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0543
Validation Accuracy: 0.9856
Overfitting: 0.0538
[Epoch 23, Batch 100] loss: 0.006193915596304578
[Epoch 23, Batch 200] loss: 0.004361107158292726
[Epoch 23, Batch 300] loss: 0.00694334618299763
[Epoch 23, Batch 400] loss: 0.005924518291458299
[Epoch 23, Batch 500] loss: 0.004792506230514846
[Epoch 23, Batch 600] loss: 0.0060774224240594775
[Epoch 23, Batch 700] loss: 0.009164251031597815
**STATS for Epoch 23** : 
Average training loss: 0.0011
Average validation loss: 0.0591
Validation Accuracy: 0.9841
Overfitting: 0.0580
[Epoch 24, Batch 100] loss: 0.004850045725725068
[Epoch 24, Batch 200] loss: 0.0055091408453881744
[Epoch 24, Batch 300] loss: 0.0044443976402726544
[Epoch 24, Batch 400] loss: 0.011865806114437874
[Epoch 24, Batch 500] loss: 0.012077962664043297
[Epoch 24, Batch 600] loss: 0.006417375859637104
[Epoch 24, Batch 700] loss: 0.007711086300187162
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0598
Validation Accuracy: 0.9856
Overfitting: 0.0593
Fold 4 validation loss: 0.0598
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.290866117477417
[Epoch 1, Batch 200] loss: 2.000750336647034
[Epoch 1, Batch 300] loss: 0.6475720730423927
[Epoch 1, Batch 400] loss: 0.4155165863037109
[Epoch 1, Batch 500] loss: 0.29352160193026067
[Epoch 1, Batch 600] loss: 0.25512724943459036
[Epoch 1, Batch 700] loss: 0.20873546227812767
**STATS for Epoch 1** : 
Average training loss: 0.0126
Average validation loss: 0.1604
Validation Accuracy: 0.9531
Overfitting: 0.1478
Best model saved at epoch 1 with validation loss: 0.1604
[Epoch 2, Batch 100] loss: 0.16480718214064838
[Epoch 2, Batch 200] loss: 0.15702529782429336
[Epoch 2, Batch 300] loss: 0.1517524858377874
[Epoch 2, Batch 400] loss: 0.11861276546493173
[Epoch 2, Batch 500] loss: 0.11887599078007043
[Epoch 2, Batch 600] loss: 0.10712836855091154
[Epoch 2, Batch 700] loss: 0.11139491545036435
**STATS for Epoch 2** : 
Average training loss: 0.0072
Average validation loss: 0.0933
Validation Accuracy: 0.9719
Overfitting: 0.0862
Best model saved at epoch 2 with validation loss: 0.0933
[Epoch 3, Batch 100] loss: 0.09087775409221649
[Epoch 3, Batch 200] loss: 0.10020367222838104
[Epoch 3, Batch 300] loss: 0.0842360203154385
[Epoch 3, Batch 400] loss: 0.0827156500192359
[Epoch 3, Batch 500] loss: 0.09046968504786491
[Epoch 3, Batch 600] loss: 0.07966911876574159
[Epoch 3, Batch 700] loss: 0.08444729981012643
**STATS for Epoch 3** : 
Average training loss: 0.0047
Average validation loss: 0.0779
Validation Accuracy: 0.9758
Overfitting: 0.0732
Best model saved at epoch 3 with validation loss: 0.0779
[Epoch 4, Batch 100] loss: 0.06890908394474536
[Epoch 4, Batch 200] loss: 0.06913004283793271
[Epoch 4, Batch 300] loss: 0.06789207622874528
[Epoch 4, Batch 400] loss: 0.06366105144377798
[Epoch 4, Batch 500] loss: 0.05991122224833816
[Epoch 4, Batch 600] loss: 0.07258349111769348
[Epoch 4, Batch 700] loss: 0.06918194220867008
**STATS for Epoch 4** : 
Average training loss: 0.0034
Average validation loss: 0.0672
Validation Accuracy: 0.9778
Overfitting: 0.0638
Best model saved at epoch 4 with validation loss: 0.0672
[Epoch 5, Batch 100] loss: 0.06510069445706904
[Epoch 5, Batch 200] loss: 0.05201917748898268
[Epoch 5, Batch 300] loss: 0.05630170707125217
[Epoch 5, Batch 400] loss: 0.05801702931057662
[Epoch 5, Batch 500] loss: 0.053861216423101724
[Epoch 5, Batch 600] loss: 0.06251635575434193
[Epoch 5, Batch 700] loss: 0.05002686393680051
**STATS for Epoch 5** : 
Average training loss: 0.0037
Average validation loss: 0.0618
Validation Accuracy: 0.9796
Overfitting: 0.0581
Best model saved at epoch 5 with validation loss: 0.0618
[Epoch 6, Batch 100] loss: 0.0496950213611126
[Epoch 6, Batch 200] loss: 0.04572557982057333
[Epoch 6, Batch 300] loss: 0.05194824626669288
[Epoch 6, Batch 400] loss: 0.04241344913141802
[Epoch 6, Batch 500] loss: 0.046359184868633746
[Epoch 6, Batch 600] loss: 0.048687933137407526
[Epoch 6, Batch 700] loss: 0.05000766243436374
**STATS for Epoch 6** : 
Average training loss: 0.0026
Average validation loss: 0.0500
Validation Accuracy: 0.9847
Overfitting: 0.0474
Best model saved at epoch 6 with validation loss: 0.0500
[Epoch 7, Batch 100] loss: 0.03526546282460913
[Epoch 7, Batch 200] loss: 0.042366296726977455
[Epoch 7, Batch 300] loss: 0.04752951451344416
[Epoch 7, Batch 400] loss: 0.038206864048261194
[Epoch 7, Batch 500] loss: 0.03651455409708433
[Epoch 7, Batch 600] loss: 0.04196444776374847
[Epoch 7, Batch 700] loss: 0.04197796339634806
**STATS for Epoch 7** : 
Average training loss: 0.0033
Average validation loss: 0.0522
Validation Accuracy: 0.9826
Overfitting: 0.0489
[Epoch 8, Batch 100] loss: 0.031770124344620856
[Epoch 8, Batch 200] loss: 0.033779075543861836
[Epoch 8, Batch 300] loss: 0.0327224543329794
[Epoch 8, Batch 400] loss: 0.038281293781474234
[Epoch 8, Batch 500] loss: 0.03239757496106904
[Epoch 8, Batch 600] loss: 0.03876205367268994
[Epoch 8, Batch 700] loss: 0.040528063573874534
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0483
Validation Accuracy: 0.9843
Overfitting: 0.0458
Best model saved at epoch 8 with validation loss: 0.0483
[Epoch 9, Batch 100] loss: 0.03241808877559379
[Epoch 9, Batch 200] loss: 0.029721499796723946
[Epoch 9, Batch 300] loss: 0.029680726390797645
[Epoch 9, Batch 400] loss: 0.03380618837603833
[Epoch 9, Batch 500] loss: 0.03317977850325406
[Epoch 9, Batch 600] loss: 0.028988461385597474
[Epoch 9, Batch 700] loss: 0.03154813933186233
**STATS for Epoch 9** : 
Average training loss: 0.0024
Average validation loss: 0.0581
Validation Accuracy: 0.9826
Overfitting: 0.0557
[Epoch 10, Batch 100] loss: 0.028836598536581732
[Epoch 10, Batch 200] loss: 0.034725014044088315
[Epoch 10, Batch 300] loss: 0.032370793221052734
[Epoch 10, Batch 400] loss: 0.022797492526005953
[Epoch 10, Batch 500] loss: 0.029621701210271568
[Epoch 10, Batch 600] loss: 0.02702066706609912
[Epoch 10, Batch 700] loss: 0.026805656980141066
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0466
Validation Accuracy: 0.9851
Overfitting: 0.0450
Best model saved at epoch 10 with validation loss: 0.0466
[Epoch 11, Batch 100] loss: 0.016297048277920112
[Epoch 11, Batch 200] loss: 0.025658753547468223
[Epoch 11, Batch 300] loss: 0.027153723805677144
[Epoch 11, Batch 400] loss: 0.02959831242565997
[Epoch 11, Batch 500] loss: 0.024315004781237805
[Epoch 11, Batch 600] loss: 0.02712607861845754
[Epoch 11, Batch 700] loss: 0.027092943285242654
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0617
Validation Accuracy: 0.9815
Overfitting: 0.0600
[Epoch 12, Batch 100] loss: 0.02421954476783867
[Epoch 12, Batch 200] loss: 0.022182602938264608
[Epoch 12, Batch 300] loss: 0.01840061625058297
[Epoch 12, Batch 400] loss: 0.022069878529873677
[Epoch 12, Batch 500] loss: 0.026301427241414786
[Epoch 12, Batch 600] loss: 0.024038093999261035
[Epoch 12, Batch 700] loss: 0.02551626787346322
**STATS for Epoch 12** : 
Average training loss: 0.0014
Average validation loss: 0.0450
Validation Accuracy: 0.9877
Overfitting: 0.0436
Best model saved at epoch 12 with validation loss: 0.0450
[Epoch 13, Batch 100] loss: 0.016770714450394734
[Epoch 13, Batch 200] loss: 0.01817916291183792
[Epoch 13, Batch 300] loss: 0.022403146044816823
[Epoch 13, Batch 400] loss: 0.018457988949667197
[Epoch 13, Batch 500] loss: 0.017606249903037677
[Epoch 13, Batch 600] loss: 0.022539444763679056
[Epoch 13, Batch 700] loss: 0.019652357572340406
**STATS for Epoch 13** : 
Average training loss: 0.0018
Average validation loss: 0.0475
Validation Accuracy: 0.9852
Overfitting: 0.0457
[Epoch 14, Batch 100] loss: 0.016949595054029487
[Epoch 14, Batch 200] loss: 0.015451146857813
[Epoch 14, Batch 300] loss: 0.01787734265322797
[Epoch 14, Batch 400] loss: 0.01950408292323118
[Epoch 14, Batch 500] loss: 0.02077339020295767
[Epoch 14, Batch 600] loss: 0.014255863347207196
[Epoch 14, Batch 700] loss: 0.021777907167270315
**STATS for Epoch 14** : 
Average training loss: 0.0020
Average validation loss: 0.0530
Validation Accuracy: 0.9835
Overfitting: 0.0510
[Epoch 15, Batch 100] loss: 0.017406874074367806
[Epoch 15, Batch 200] loss: 0.013978630417695967
[Epoch 15, Batch 300] loss: 0.015545590861001983
[Epoch 15, Batch 400] loss: 0.017580195125119644
[Epoch 15, Batch 500] loss: 0.018644857695908287
[Epoch 15, Batch 600] loss: 0.01611501626946847
[Epoch 15, Batch 700] loss: 0.017035281524586027
**STATS for Epoch 15** : 
Average training loss: 0.0015
Average validation loss: 0.0468
Validation Accuracy: 0.9857
Overfitting: 0.0454
[Epoch 16, Batch 100] loss: 0.01253805895568803
[Epoch 16, Batch 200] loss: 0.01429260947246803
[Epoch 16, Batch 300] loss: 0.014510121591592906
[Epoch 16, Batch 400] loss: 0.01654354840888118
[Epoch 16, Batch 500] loss: 0.01624850758453249
[Epoch 16, Batch 600] loss: 0.016292625092319213
[Epoch 16, Batch 700] loss: 0.019073365154326893
**STATS for Epoch 16** : 
Average training loss: 0.0011
Average validation loss: 0.0527
Validation Accuracy: 0.9848
Overfitting: 0.0516
[Epoch 17, Batch 100] loss: 0.01603123388122185
[Epoch 17, Batch 200] loss: 0.009521419485099613
[Epoch 17, Batch 300] loss: 0.013128214078533347
[Epoch 17, Batch 400] loss: 0.013718770967388992
[Epoch 17, Batch 500] loss: 0.013782329191162717
[Epoch 17, Batch 600] loss: 0.009839050909358776
[Epoch 17, Batch 700] loss: 0.01342501428196556
**STATS for Epoch 17** : 
Average training loss: 0.0013
Average validation loss: 0.0479
Validation Accuracy: 0.9864
Overfitting: 0.0466
[Epoch 18, Batch 100] loss: 0.009621612522460054
[Epoch 18, Batch 200] loss: 0.008066994075052207
[Epoch 18, Batch 300] loss: 0.01251261816440092
[Epoch 18, Batch 400] loss: 0.013939021834812593
[Epoch 18, Batch 500] loss: 0.012418618719384539
[Epoch 18, Batch 600] loss: 0.012397921956508072
[Epoch 18, Batch 700] loss: 0.013265029548674647
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0533
Validation Accuracy: 0.9852
Overfitting: 0.0527
[Epoch 19, Batch 100] loss: 0.010388924193975982
[Epoch 19, Batch 200] loss: 0.009430073184485082
[Epoch 19, Batch 300] loss: 0.008931008454674157
[Epoch 19, Batch 400] loss: 0.011723580020370718
[Epoch 19, Batch 500] loss: 0.014287408885429613
[Epoch 19, Batch 600] loss: 0.011023925861954921
[Epoch 19, Batch 700] loss: 0.010213422425367753
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0479
Validation Accuracy: 0.9869
Overfitting: 0.0472
[Epoch 20, Batch 100] loss: 0.006013101277130772
[Epoch 20, Batch 200] loss: 0.009557123925405904
[Epoch 20, Batch 300] loss: 0.009072258157975738
[Epoch 20, Batch 400] loss: 0.008128779310063693
[Epoch 20, Batch 500] loss: 0.007008133099152474
[Epoch 20, Batch 600] loss: 0.006201001319059287
[Epoch 20, Batch 700] loss: 0.015098092346161138
**STATS for Epoch 20** : 
Average training loss: 0.0014
Average validation loss: 0.0522
Validation Accuracy: 0.9864
Overfitting: 0.0507
[Epoch 21, Batch 100] loss: 0.006836928663033177
[Epoch 21, Batch 200] loss: 0.008152420711558079
[Epoch 21, Batch 300] loss: 0.008845747977175052
[Epoch 21, Batch 400] loss: 0.007203008498545387
[Epoch 21, Batch 500] loss: 0.008894317890153616
[Epoch 21, Batch 600] loss: 0.010667868767122855
[Epoch 21, Batch 700] loss: 0.007898310040254729
**STATS for Epoch 21** : 
Average training loss: 0.0008
Average validation loss: 0.0487
Validation Accuracy: 0.9872
Overfitting: 0.0479
[Epoch 22, Batch 100] loss: 0.005212229155149544
[Epoch 22, Batch 200] loss: 0.007035837706789607
[Epoch 22, Batch 300] loss: 0.006983988659303577
[Epoch 22, Batch 400] loss: 0.011483134606933162
[Epoch 22, Batch 500] loss: 0.008481999578943942
[Epoch 22, Batch 600] loss: 0.010019182632677258
[Epoch 22, Batch 700] loss: 0.009219616908958415
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0480
Validation Accuracy: 0.9877
Overfitting: 0.0476
[Epoch 23, Batch 100] loss: 0.006336029121303
[Epoch 23, Batch 200] loss: 0.007231436155389019
[Epoch 23, Batch 300] loss: 0.011019986541250547
[Epoch 23, Batch 400] loss: 0.007449201864146744
[Epoch 23, Batch 500] loss: 0.007360534545514383
[Epoch 23, Batch 600] loss: 0.007649957842659205
[Epoch 23, Batch 700] loss: 0.006452173229736218
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0484
Validation Accuracy: 0.9879
Overfitting: 0.0481
[Epoch 24, Batch 100] loss: 0.003315335151301042
[Epoch 24, Batch 200] loss: 0.004338493014402047
[Epoch 24, Batch 300] loss: 0.006021871992998058
[Epoch 24, Batch 400] loss: 0.005741483915262507
[Epoch 24, Batch 500] loss: 0.004728310585524014
[Epoch 24, Batch 600] loss: 0.006697602838394232
[Epoch 24, Batch 700] loss: 0.005921290929927636
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0526
Validation Accuracy: 0.9871
Overfitting: 0.0522
Fold 5 validation loss: 0.0526
Mean validation loss across all folds for Trial 16 is 0.0556 with trial config:  l1: 128, l2: 128, lr: 0.0029125540727754106, batch_size: 64
[I 2024-12-11 04:24:56,063] Trial 15 finished with value: 0.05563473855795661 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0029125540727754106, 'batch_size': 64}. Best is trial 2 with value: 0.05047263894358398.

Selected Hyperparameters for Trial 17:
  l1: 256, l2: 64, lr: 0.003317662028701678, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2887557125091553
[Epoch 1, Batch 200] loss: 1.7125045406818389
[Epoch 1, Batch 300] loss: 0.465435286462307
**STATS for Epoch 1** : 
Average training loss: 0.0634
Average validation loss: 0.3008
Validation Accuracy: 0.9058
Overfitting: 0.2374
Best model saved at epoch 1 with validation loss: 0.3008
[Epoch 2, Batch 100] loss: 0.2711779712885618
[Epoch 2, Batch 200] loss: 0.21479146473109723
[Epoch 2, Batch 300] loss: 0.1777547577023506
**STATS for Epoch 2** : 
Average training loss: 0.0285
Average validation loss: 0.1497
Validation Accuracy: 0.9550
Overfitting: 0.1212
Best model saved at epoch 2 with validation loss: 0.1497
[Epoch 3, Batch 100] loss: 0.14060406912118195
[Epoch 3, Batch 200] loss: 0.1294763405621052
[Epoch 3, Batch 300] loss: 0.1106093261949718
**STATS for Epoch 3** : 
Average training loss: 0.0238
Average validation loss: 0.0948
Validation Accuracy: 0.9687
Overfitting: 0.0710
Best model saved at epoch 3 with validation loss: 0.0948
[Epoch 4, Batch 100] loss: 0.09675837937742472
[Epoch 4, Batch 200] loss: 0.09758453190326691
[Epoch 4, Batch 300] loss: 0.08624321933835745
**STATS for Epoch 4** : 
Average training loss: 0.0187
Average validation loss: 0.0784
Validation Accuracy: 0.9746
Overfitting: 0.0597
Best model saved at epoch 4 with validation loss: 0.0784
[Epoch 5, Batch 100] loss: 0.08303552874363959
[Epoch 5, Batch 200] loss: 0.07525949224829674
[Epoch 5, Batch 300] loss: 0.07347906559705734
**STATS for Epoch 5** : 
Average training loss: 0.0145
Average validation loss: 0.1008
Validation Accuracy: 0.9658
Overfitting: 0.0864
[Epoch 6, Batch 100] loss: 0.07007735179737211
[Epoch 6, Batch 200] loss: 0.06324073537252843
[Epoch 6, Batch 300] loss: 0.06571522634476423
**STATS for Epoch 6** : 
Average training loss: 0.0127
Average validation loss: 0.0728
Validation Accuracy: 0.9767
Overfitting: 0.0601
Best model saved at epoch 6 with validation loss: 0.0728
[Epoch 7, Batch 100] loss: 0.0554742357134819
[Epoch 7, Batch 200] loss: 0.05868570690974593
[Epoch 7, Batch 300] loss: 0.05710011251270771
**STATS for Epoch 7** : 
Average training loss: 0.0101
Average validation loss: 0.0628
Validation Accuracy: 0.9789
Overfitting: 0.0528
Best model saved at epoch 7 with validation loss: 0.0628
[Epoch 8, Batch 100] loss: 0.04991380103863776
[Epoch 8, Batch 200] loss: 0.05127354359254241
[Epoch 8, Batch 300] loss: 0.05200037488713861
**STATS for Epoch 8** : 
Average training loss: 0.0113
Average validation loss: 0.0677
Validation Accuracy: 0.9792
Overfitting: 0.0564
[Epoch 9, Batch 100] loss: 0.04433757709339261
[Epoch 9, Batch 200] loss: 0.051778291435912255
[Epoch 9, Batch 300] loss: 0.044878585143014786
**STATS for Epoch 9** : 
Average training loss: 0.0089
Average validation loss: 0.0553
Validation Accuracy: 0.9826
Overfitting: 0.0464
[I 2024-12-11 04:26:21,245] Trial 16 pruned. 

Selected Hyperparameters for Trial 18:
  l1: 256, l2: 128, lr: 0.0030474599138996432, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2001811707019807
[Epoch 1, Batch 200] loss: 0.9870890054106712
[Epoch 1, Batch 300] loss: 0.46832660779356955
[Epoch 1, Batch 400] loss: 0.34986087765544654
[Epoch 1, Batch 500] loss: 0.2880673091765493
[Epoch 1, Batch 600] loss: 0.25427253025583924
[Epoch 1, Batch 700] loss: 0.23888082824647427
[Epoch 1, Batch 800] loss: 0.232576955948025
[Epoch 1, Batch 900] loss: 0.18941648060455918
[Epoch 1, Batch 1000] loss: 0.17218573952093721
[Epoch 1, Batch 1100] loss: 0.17363031866028905
[Epoch 1, Batch 1200] loss: 0.15988283537328243
[Epoch 1, Batch 1300] loss: 0.15542364851105958
[Epoch 1, Batch 1400] loss: 0.16276422563008963
[Epoch 1, Batch 1500] loss: 0.14640689205611124
[Epoch 1, Batch 1600] loss: 0.1419362448574975
[Epoch 1, Batch 1700] loss: 0.1225828144303523
[Epoch 1, Batch 1800] loss: 0.1196240927069448
[Epoch 1, Batch 1900] loss: 0.15921466323081404
[Epoch 1, Batch 2000] loss: 0.107144858664833
[Epoch 1, Batch 2100] loss: 0.1504626032616943
[Epoch 1, Batch 2200] loss: 0.12384207576396875
[Epoch 1, Batch 2300] loss: 0.12279156713397242
[Epoch 1, Batch 2400] loss: 0.12356522725662217
[Epoch 1, Batch 2500] loss: 0.09904351945384406
[Epoch 1, Batch 2600] loss: 0.11763468371587806
[Epoch 1, Batch 2700] loss: 0.08192166027380153
[Epoch 1, Batch 2800] loss: 0.08608378980425187
[Epoch 1, Batch 2900] loss: 0.08133537499525119
[Epoch 1, Batch 3000] loss: 0.09042606234608684
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0956
Validation Accuracy: 0.9699
Overfitting: 0.0956
Best model saved at epoch 1 with validation loss: 0.0956
[Epoch 2, Batch 100] loss: 0.07225002216408029
[Epoch 2, Batch 200] loss: 0.08409083006321452
[Epoch 2, Batch 300] loss: 0.08087421161239035
[Epoch 2, Batch 400] loss: 0.06934052613680251
[Epoch 2, Batch 500] loss: 0.07999750110582682
[Epoch 2, Batch 600] loss: 0.06698862629884389
[Epoch 2, Batch 700] loss: 0.08128661186114186
[Epoch 2, Batch 800] loss: 0.07913273145735729
[Epoch 2, Batch 900] loss: 0.06460879621445201
[Epoch 2, Batch 1000] loss: 0.06438324898888823
[Epoch 2, Batch 1100] loss: 0.07610685062129051
[Epoch 2, Batch 1200] loss: 0.0710054383741226
[Epoch 2, Batch 1300] loss: 0.07527415815246058
[Epoch 2, Batch 1400] loss: 0.06259146208001766
[Epoch 2, Batch 1500] loss: 0.07027262227260507
[Epoch 2, Batch 1600] loss: 0.07959798175783363
[Epoch 2, Batch 1700] loss: 0.07454489858893794
[Epoch 2, Batch 1800] loss: 0.07690474378992804
[Epoch 2, Batch 1900] loss: 0.08323142517125234
[Epoch 2, Batch 2000] loss: 0.0571846918220399
[Epoch 2, Batch 2100] loss: 0.07672874214476906
[Epoch 2, Batch 2200] loss: 0.08003211099188774
[Epoch 2, Batch 2300] loss: 0.06772710901743267
[Epoch 2, Batch 2400] loss: 0.07476319703739137
[Epoch 2, Batch 2500] loss: 0.07451966810855083
[Epoch 2, Batch 2600] loss: 0.07572930007023387
[Epoch 2, Batch 2700] loss: 0.08044986416643951
[Epoch 2, Batch 2800] loss: 0.059132457130181136
[Epoch 2, Batch 2900] loss: 0.06025180983357131
[Epoch 2, Batch 3000] loss: 0.07243760612909682
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0663
Validation Accuracy: 0.9788
Overfitting: 0.0663
Best model saved at epoch 2 with validation loss: 0.0663
[Epoch 3, Batch 100] loss: 0.04097352743614465
[Epoch 3, Batch 200] loss: 0.044936449956148865
[Epoch 3, Batch 300] loss: 0.04458668346167542
[Epoch 3, Batch 400] loss: 0.03649066490106634
[Epoch 3, Batch 500] loss: 0.041528396838475604
[Epoch 3, Batch 600] loss: 0.05237698041994008
[Epoch 3, Batch 700] loss: 0.04695367666776292
[Epoch 3, Batch 800] loss: 0.05908851303858682
[Epoch 3, Batch 900] loss: 0.07282392197055743
[Epoch 3, Batch 1000] loss: 0.035880087100013044
[Epoch 3, Batch 1100] loss: 0.038418173388636206
[Epoch 3, Batch 1200] loss: 0.0546854308390175
[Epoch 3, Batch 1300] loss: 0.07071571500069694
[Epoch 3, Batch 1400] loss: 0.04512274640612304
[Epoch 3, Batch 1500] loss: 0.05286810421894188
[Epoch 3, Batch 1600] loss: 0.041755710705474486
[Epoch 3, Batch 1700] loss: 0.04983704993755964
[Epoch 3, Batch 1800] loss: 0.051042051479089426
[Epoch 3, Batch 1900] loss: 0.049673148400033826
[Epoch 3, Batch 2000] loss: 0.06295518186707341
[Epoch 3, Batch 2100] loss: 0.043945371773734226
[Epoch 3, Batch 2200] loss: 0.04364237581667112
[Epoch 3, Batch 2300] loss: 0.032358928239991654
[Epoch 3, Batch 2400] loss: 0.04185812246432761
[Epoch 3, Batch 2500] loss: 0.051488705853698774
[Epoch 3, Batch 2600] loss: 0.030106137356233374
[Epoch 3, Batch 2700] loss: 0.049579025977873246
[Epoch 3, Batch 2800] loss: 0.057038594367040785
[Epoch 3, Batch 2900] loss: 0.06586517658055527
[Epoch 3, Batch 3000] loss: 0.08002540780813433
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9845
Overfitting: 0.0514
Best model saved at epoch 3 with validation loss: 0.0514
[Epoch 4, Batch 100] loss: 0.033698897598224
[Epoch 4, Batch 200] loss: 0.032938403314328756
[Epoch 4, Batch 300] loss: 0.03222967238922138
[Epoch 4, Batch 400] loss: 0.04687311743189639
[Epoch 4, Batch 500] loss: 0.0372984170759446
[Epoch 4, Batch 600] loss: 0.02028929921456438
[Epoch 4, Batch 700] loss: 0.023594611414591782
[Epoch 4, Batch 800] loss: 0.049598595905627006
[Epoch 4, Batch 900] loss: 0.03520619339629775
[Epoch 4, Batch 1000] loss: 0.04236000989920285
[Epoch 4, Batch 1100] loss: 0.03274685419193702
[Epoch 4, Batch 1200] loss: 0.03538767938225647
[Epoch 4, Batch 1300] loss: 0.04241854894135031
[Epoch 4, Batch 1400] loss: 0.050700743245324705
[Epoch 4, Batch 1500] loss: 0.03727350018103607
[Epoch 4, Batch 1600] loss: 0.026475821773055942
[Epoch 4, Batch 1700] loss: 0.026744315971591277
[Epoch 4, Batch 1800] loss: 0.027779602478003654
[Epoch 4, Batch 1900] loss: 0.03996841659316488
[Epoch 4, Batch 2000] loss: 0.047324449467632805
[Epoch 4, Batch 2100] loss: 0.027026364097910118
[Epoch 4, Batch 2200] loss: 0.048319621522095985
[Epoch 4, Batch 2300] loss: 0.03711686428461689
[Epoch 4, Batch 2400] loss: 0.038364008199132514
[Epoch 4, Batch 2500] loss: 0.03200886489603363
[Epoch 4, Batch 2600] loss: 0.047690818354203655
[Epoch 4, Batch 2700] loss: 0.03664223449006385
[Epoch 4, Batch 2800] loss: 0.03917316897015553
[Epoch 4, Batch 2900] loss: 0.04632181189423136
[Epoch 4, Batch 3000] loss: 0.05165091261980706
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9838
Overfitting: 0.0559
[Epoch 5, Batch 100] loss: 0.03290438268712023
[Epoch 5, Batch 200] loss: 0.0229427468686481
[Epoch 5, Batch 300] loss: 0.03206517388178327
[Epoch 5, Batch 400] loss: 0.03429866429663889
[Epoch 5, Batch 500] loss: 0.02747185581669328
[Epoch 5, Batch 600] loss: 0.02433026981074363
[Epoch 5, Batch 700] loss: 0.02751493582924013
[Epoch 5, Batch 800] loss: 0.04015136229176278
[Epoch 5, Batch 900] loss: 0.018141955041719483
[Epoch 5, Batch 1000] loss: 0.03709643746551592
[Epoch 5, Batch 1100] loss: 0.020803601483075907
[Epoch 5, Batch 1200] loss: 0.026295578161734737
[Epoch 5, Batch 1300] loss: 0.03889348796979902
[Epoch 5, Batch 1400] loss: 0.022078248655416247
[Epoch 5, Batch 1500] loss: 0.030446097215171903
[Epoch 5, Batch 1600] loss: 0.038582226802391234
[Epoch 5, Batch 1700] loss: 0.027295227343274747
[Epoch 5, Batch 1800] loss: 0.021548354264559748
[Epoch 5, Batch 1900] loss: 0.03207095489397034
[Epoch 5, Batch 2000] loss: 0.02643057929315546
[Epoch 5, Batch 2100] loss: 0.027403579708188772
[Epoch 5, Batch 2200] loss: 0.023102309077403335
[Epoch 5, Batch 2300] loss: 0.026496863096963353
[Epoch 5, Batch 2400] loss: 0.03324347171299451
[Epoch 5, Batch 2500] loss: 0.029737967456167098
[Epoch 5, Batch 2600] loss: 0.0390321748155111
[Epoch 5, Batch 2700] loss: 0.03880745503149228
[Epoch 5, Batch 2800] loss: 0.029635496921036973
[Epoch 5, Batch 2900] loss: 0.025324576462153345
[Epoch 5, Batch 3000] loss: 0.04865047120387317
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9848
Overfitting: 0.0522
[Epoch 6, Batch 100] loss: 0.023522878292424138
[Epoch 6, Batch 200] loss: 0.02105127129030734
[Epoch 6, Batch 300] loss: 0.01951366903966118
[Epoch 6, Batch 400] loss: 0.01571782754992455
[Epoch 6, Batch 500] loss: 0.029448376913423998
[Epoch 6, Batch 600] loss: 0.030978354491962817
[Epoch 6, Batch 700] loss: 0.009500504944298882
[Epoch 6, Batch 800] loss: 0.02090846119581329
[Epoch 6, Batch 900] loss: 0.011983723435864704
[Epoch 6, Batch 1000] loss: 0.028791504852870277
[Epoch 6, Batch 1100] loss: 0.02292959118649378
[Epoch 6, Batch 1200] loss: 0.026240062729575585
[Epoch 6, Batch 1300] loss: 0.033690167760378247
[Epoch 6, Batch 1400] loss: 0.024675493575568908
[Epoch 6, Batch 1500] loss: 0.01790425335913824
[Epoch 6, Batch 1600] loss: 0.021297267281224778
[Epoch 6, Batch 1700] loss: 0.029567174503972636
[Epoch 6, Batch 1800] loss: 0.030527761033081333
[Epoch 6, Batch 1900] loss: 0.011867517698483425
[Epoch 6, Batch 2000] loss: 0.02903601158157926
[Epoch 6, Batch 2100] loss: 0.015431619247829076
[Epoch 6, Batch 2200] loss: 0.017052094441460212
[Epoch 6, Batch 2300] loss: 0.030544601110505026
[Epoch 6, Batch 2400] loss: 0.03719136299703678
[Epoch 6, Batch 2500] loss: 0.025526550351478362
[Epoch 6, Batch 2600] loss: 0.018349090892861568
[Epoch 6, Batch 2700] loss: 0.02126873278556559
[Epoch 6, Batch 2800] loss: 0.03223512494610077
[Epoch 6, Batch 2900] loss: 0.03425199121209516
[Epoch 6, Batch 3000] loss: 0.028202765292371625
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0444
Validation Accuracy: 0.9864
Overfitting: 0.0444
Best model saved at epoch 6 with validation loss: 0.0444
[Epoch 7, Batch 100] loss: 0.014214629090602102
[Epoch 7, Batch 200] loss: 0.015167241872795785
[Epoch 7, Batch 300] loss: 0.019493329468914453
[Epoch 7, Batch 400] loss: 0.0379741164130246
[Epoch 7, Batch 500] loss: 0.01659340794913078
[Epoch 7, Batch 600] loss: 0.012597910726453847
[Epoch 7, Batch 700] loss: 0.01762438704422493
[Epoch 7, Batch 800] loss: 0.016725168995903913
[Epoch 7, Batch 900] loss: 0.012689570430775348
[Epoch 7, Batch 1000] loss: 0.014833310827489185
[Epoch 7, Batch 1100] loss: 0.01627245488393328
[Epoch 7, Batch 1200] loss: 0.019142668318972936
[Epoch 7, Batch 1300] loss: 0.017743422611615642
[Epoch 7, Batch 1400] loss: 0.011125062002333834
[Epoch 7, Batch 1500] loss: 0.027534278887635537
[Epoch 7, Batch 1600] loss: 0.026369295980948664
[Epoch 7, Batch 1700] loss: 0.020275150219731586
[Epoch 7, Batch 1800] loss: 0.014390710455445514
[Epoch 7, Batch 1900] loss: 0.027110208246904223
[Epoch 7, Batch 2000] loss: 0.02162826777257578
[Epoch 7, Batch 2100] loss: 0.01597653374294168
[Epoch 7, Batch 2200] loss: 0.01322998218777684
[Epoch 7, Batch 2300] loss: 0.02274540345704736
[Epoch 7, Batch 2400] loss: 0.039840150315612846
[Epoch 7, Batch 2500] loss: 0.025962014480464857
[Epoch 7, Batch 2600] loss: 0.021903821230898755
[Epoch 7, Batch 2700] loss: 0.024480931790139947
[Epoch 7, Batch 2800] loss: 0.027975192936391977
[Epoch 7, Batch 2900] loss: 0.020381137729768854
[Epoch 7, Batch 3000] loss: 0.02370223198779968
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9877
Overfitting: 0.0466
[Epoch 8, Batch 100] loss: 0.013712111526710941
[Epoch 8, Batch 200] loss: 0.01278422506786228
[Epoch 8, Batch 300] loss: 0.008724600824143636
[Epoch 8, Batch 400] loss: 0.015407734107384385
[Epoch 8, Batch 500] loss: 0.01617435855383519
[Epoch 8, Batch 600] loss: 0.0246000977784297
[Epoch 8, Batch 700] loss: 0.020897835441815005
[Epoch 8, Batch 800] loss: 0.016417884816364678
[Epoch 8, Batch 900] loss: 0.009484275141876424
[Epoch 8, Batch 1000] loss: 0.011569216908646922
[Epoch 8, Batch 1100] loss: 0.01441746547224284
[Epoch 8, Batch 1200] loss: 0.011541974910469434
[Epoch 8, Batch 1300] loss: 0.008034432503977769
[Epoch 8, Batch 1400] loss: 0.0230703957020296
[Epoch 8, Batch 1500] loss: 0.018109238853912756
[Epoch 8, Batch 1600] loss: 0.017992552515224816
[Epoch 8, Batch 1700] loss: 0.021014636494141994
[Epoch 8, Batch 1800] loss: 0.030489356250582203
[Epoch 8, Batch 1900] loss: 0.012417211802348902
[Epoch 8, Batch 2000] loss: 0.01730751611236883
[Epoch 8, Batch 2100] loss: 0.016035138372808434
[Epoch 8, Batch 2200] loss: 0.01740483887403343
[Epoch 8, Batch 2300] loss: 0.014811683064235694
[Epoch 8, Batch 2400] loss: 0.015377920916180302
[Epoch 8, Batch 2500] loss: 0.016692932140376798
[Epoch 8, Batch 2600] loss: 0.021341343393523858
[Epoch 8, Batch 2700] loss: 0.013647037904156605
[Epoch 8, Batch 2800] loss: 0.019083863570558607
[Epoch 8, Batch 2900] loss: 0.013166280006021224
[Epoch 8, Batch 3000] loss: 0.012187951426813014
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9879
Overfitting: 0.0452
[Epoch 9, Batch 100] loss: 0.0146667302846663
[Epoch 9, Batch 200] loss: 0.011660455996820928
[Epoch 9, Batch 300] loss: 0.009389167460758472
[Epoch 9, Batch 400] loss: 0.008538927233339565
[Epoch 9, Batch 500] loss: 0.009950733215819128
[Epoch 9, Batch 600] loss: 0.011035284666263578
[Epoch 9, Batch 700] loss: 0.0071995895420263875
[Epoch 9, Batch 800] loss: 0.010950766032807167
[Epoch 9, Batch 900] loss: 0.014210197155326796
[Epoch 9, Batch 1000] loss: 0.014765267290385964
[Epoch 9, Batch 1100] loss: 0.007963825072656618
[Epoch 9, Batch 1200] loss: 0.01047749678125001
[Epoch 9, Batch 1300] loss: 0.010054918699756854
[Epoch 9, Batch 1400] loss: 0.01733366082439943
[Epoch 9, Batch 1500] loss: 0.014079279933225735
[Epoch 9, Batch 1600] loss: 0.018382000682384502
[Epoch 9, Batch 1700] loss: 0.009802968731291913
[Epoch 9, Batch 1800] loss: 0.005836333655074668
[Epoch 9, Batch 1900] loss: 0.015136939890307986
[Epoch 9, Batch 2000] loss: 0.0172156729850758
[Epoch 9, Batch 2100] loss: 0.012668873870534298
[Epoch 9, Batch 2200] loss: 0.017754358630764955
[Epoch 9, Batch 2300] loss: 0.011213591561702287
[Epoch 9, Batch 2400] loss: 0.00877454626501958
[Epoch 9, Batch 2500] loss: 0.01297419326842487
[Epoch 9, Batch 2600] loss: 0.020656994578639568
[Epoch 9, Batch 2700] loss: 0.0219619354668248
[Epoch 9, Batch 2800] loss: 0.019683224877908287
[Epoch 9, Batch 2900] loss: 0.030960703791172363
[Epoch 9, Batch 3000] loss: 0.014353456701355754
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9864
Overfitting: 0.0515
[Epoch 10, Batch 100] loss: 0.012045215516150166
[Epoch 10, Batch 200] loss: 0.00785169564348962
[Epoch 10, Batch 300] loss: 0.003620576697796878
[Epoch 10, Batch 400] loss: 0.005132502816629696
[Epoch 10, Batch 500] loss: 0.019355722078310864
[Epoch 10, Batch 600] loss: 0.015948320969425823
[Epoch 10, Batch 700] loss: 0.006132184145120618
[Epoch 10, Batch 800] loss: 0.007125733197381408
[Epoch 10, Batch 900] loss: 0.01001982671163887
[Epoch 10, Batch 1000] loss: 0.01508334211974443
[Epoch 10, Batch 1100] loss: 0.011320250548851617
[Epoch 10, Batch 1200] loss: 0.009769006084459306
[Epoch 10, Batch 1300] loss: 0.0066406290446821
[Epoch 10, Batch 1400] loss: 0.015919254359844218
[Epoch 10, Batch 1500] loss: 0.011630476529404632
[Epoch 10, Batch 1600] loss: 0.006474806360770345
[Epoch 10, Batch 1700] loss: 0.007119183526378947
[Epoch 10, Batch 1800] loss: 0.004614882825587756
[Epoch 10, Batch 1900] loss: 0.009218351025010634
[Epoch 10, Batch 2000] loss: 0.014266047325982072
[Epoch 10, Batch 2100] loss: 0.011292857194425777
[Epoch 10, Batch 2200] loss: 0.01340237652912606
[Epoch 10, Batch 2300] loss: 0.01312492096101778
[Epoch 10, Batch 2400] loss: 0.008409799533746992
[Epoch 10, Batch 2500] loss: 0.008578972411706331
[Epoch 10, Batch 2600] loss: 0.01866482905047178
[Epoch 10, Batch 2700] loss: 0.02597895217157884
[Epoch 10, Batch 2800] loss: 0.012334189726234967
[Epoch 10, Batch 2900] loss: 0.0051258882282206744
[Epoch 10, Batch 3000] loss: 0.00552600804767053
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0454
Validation Accuracy: 0.9885
Overfitting: 0.0454
[Epoch 11, Batch 100] loss: 0.003951531617193495
[Epoch 11, Batch 200] loss: 0.003665072736313846
[Epoch 11, Batch 300] loss: 0.004420275084368655
[Epoch 11, Batch 400] loss: 0.00474597351568832
[Epoch 11, Batch 500] loss: 0.005239611438100838
[Epoch 11, Batch 600] loss: 0.003911264234704923
[Epoch 11, Batch 700] loss: 0.004980277724089746
[Epoch 11, Batch 800] loss: 0.007732029279851531
[Epoch 11, Batch 900] loss: 0.005535896304634207
[Epoch 11, Batch 1000] loss: 0.011892806799637582
[Epoch 11, Batch 1100] loss: 0.003074622826912332
[Epoch 11, Batch 1200] loss: 0.005929802216010103
[Epoch 11, Batch 1300] loss: 0.018311404440238446
[Epoch 11, Batch 1400] loss: 0.00401413097668069
[Epoch 11, Batch 1500] loss: 0.004569561402806244
[Epoch 11, Batch 1600] loss: 0.008031520812325254
[Epoch 11, Batch 1700] loss: 0.010893176387157553
[Epoch 11, Batch 1800] loss: 0.008465534005504196
[Epoch 11, Batch 1900] loss: 0.02139262250386963
[Epoch 11, Batch 2000] loss: 0.012619723976606566
[Epoch 11, Batch 2100] loss: 0.020753154629861114
[Epoch 11, Batch 2200] loss: 0.013253623394606394
[Epoch 11, Batch 2300] loss: 0.015813079443568655
[Epoch 11, Batch 2400] loss: 0.006977516355107695
[Epoch 11, Batch 2500] loss: 0.010636082422417986
[Epoch 11, Batch 2600] loss: 0.017997821549815853
[Epoch 11, Batch 2700] loss: 0.006460861333575849
[Epoch 11, Batch 2800] loss: 0.008973240374070884
[Epoch 11, Batch 2900] loss: 0.007171748704504637
[Epoch 11, Batch 3000] loss: 0.008867609690589688
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9881
Overfitting: 0.0535
[Epoch 12, Batch 100] loss: 0.003156053466405524
[Epoch 12, Batch 200] loss: 0.0025241536299267864
[Epoch 12, Batch 300] loss: 0.0038077787779400296
[Epoch 12, Batch 400] loss: 0.0038729431417459637
[Epoch 12, Batch 500] loss: 0.006959941749242304
[Epoch 12, Batch 600] loss: 0.008731678643564465
[Epoch 12, Batch 700] loss: 0.0030216896204873756
[Epoch 12, Batch 800] loss: 0.002363612946264766
[Epoch 12, Batch 900] loss: 0.00357111648690136
[Epoch 12, Batch 1000] loss: 0.007535212028616911
[Epoch 12, Batch 1100] loss: 0.0027892461683555326
[Epoch 12, Batch 1200] loss: 0.009631261530814754
[Epoch 12, Batch 1300] loss: 0.012078314140657085
[Epoch 12, Batch 1400] loss: 0.005918888585932791
[Epoch 12, Batch 1500] loss: 0.011882182539042673
[Epoch 12, Batch 1600] loss: 0.00846065851725129
[Epoch 12, Batch 1700] loss: 0.014084688408778447
[Epoch 12, Batch 1800] loss: 0.026968052180557152
[Epoch 12, Batch 1900] loss: 0.004044727161694937
[Epoch 12, Batch 2000] loss: 0.005734466500548478
[Epoch 12, Batch 2100] loss: 0.004991070551632788
[Epoch 12, Batch 2200] loss: 0.006938495622677578
[Epoch 12, Batch 2300] loss: 0.009253274447104332
[Epoch 12, Batch 2400] loss: 0.002039059525418452
[Epoch 12, Batch 2500] loss: 0.004429879739820706
[Epoch 12, Batch 2600] loss: 0.008218065174999083
[Epoch 12, Batch 2700] loss: 0.010186630334353453
[Epoch 12, Batch 2800] loss: 0.0037294466647048805
[Epoch 12, Batch 2900] loss: 0.004615906938838208
[Epoch 12, Batch 3000] loss: 0.007063909451540553
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9868
Overfitting: 0.0556
[Epoch 13, Batch 100] loss: 0.0041123598056339
[Epoch 13, Batch 200] loss: 0.0022324355919748485
[Epoch 13, Batch 300] loss: 0.001805046779704611
[Epoch 13, Batch 400] loss: 0.001625175448651106
[Epoch 13, Batch 500] loss: 0.005228666708119647
[Epoch 13, Batch 600] loss: 0.0012562590497620719
[Epoch 13, Batch 700] loss: 0.0007690598756207833
[Epoch 13, Batch 800] loss: 0.0025918861844472295
[Epoch 13, Batch 900] loss: 0.002034307086496483
[Epoch 13, Batch 1000] loss: 0.0014403604057011954
[Epoch 13, Batch 1100] loss: 0.0017035720767850115
[Epoch 13, Batch 1200] loss: 0.0010349230063688708
[Epoch 13, Batch 1300] loss: 0.00248645757606198
[Epoch 13, Batch 1400] loss: 0.003868096848130769
[Epoch 13, Batch 1500] loss: 0.008999527612486099
[Epoch 13, Batch 1600] loss: 0.01412047958682109
[Epoch 13, Batch 1700] loss: 0.0038707958237989715
[Epoch 13, Batch 1800] loss: 0.00781286932775174
[Epoch 13, Batch 1900] loss: 0.002006848462922051
[Epoch 13, Batch 2000] loss: 0.011950027590336844
[Epoch 13, Batch 2100] loss: 0.008606153141975027
[Epoch 13, Batch 2200] loss: 0.00678977653023253
[Epoch 13, Batch 2300] loss: 0.009959179698124813
[Epoch 13, Batch 2400] loss: 0.006004314874173247
[Epoch 13, Batch 2500] loss: 0.02027509704464819
[Epoch 13, Batch 2600] loss: 0.007785753139450406
[Epoch 13, Batch 2700] loss: 0.014290273614705598
[Epoch 13, Batch 2800] loss: 0.010790511476430993
[Epoch 13, Batch 2900] loss: 0.01043214972821545
[Epoch 13, Batch 3000] loss: 0.00772230547571219
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9886
Overfitting: 0.0511
[Epoch 14, Batch 100] loss: 0.006196890695971149
[Epoch 14, Batch 200] loss: 0.004649326163466156
[Epoch 14, Batch 300] loss: 0.007860573835939917
[Epoch 14, Batch 400] loss: 0.00837707350088749
[Epoch 14, Batch 500] loss: 0.00190581441855727
[Epoch 14, Batch 600] loss: 0.004619955295113272
[Epoch 14, Batch 700] loss: 0.004822724477708107
[Epoch 14, Batch 800] loss: 0.004272096128984497
[Epoch 14, Batch 900] loss: 0.004178156045878154
[Epoch 14, Batch 1000] loss: 0.006222764867448518
[Epoch 14, Batch 1100] loss: 0.0038838661747320202
[Epoch 14, Batch 1200] loss: 0.0076243517652062566
[Epoch 14, Batch 1300] loss: 0.005361688359259773
[Epoch 14, Batch 1400] loss: 0.004867458751571618
[Epoch 14, Batch 1500] loss: 0.006979888687535407
[Epoch 14, Batch 1600] loss: 0.011163900060049628
[Epoch 14, Batch 1700] loss: 0.0093610081857382
[Epoch 14, Batch 1800] loss: 0.006164464790467292
[Epoch 14, Batch 1900] loss: 0.007770948421049298
[Epoch 14, Batch 2000] loss: 0.008879515463068225
[Epoch 14, Batch 2100] loss: 0.009046327676645087
[Epoch 14, Batch 2200] loss: 0.012736876666904208
[Epoch 14, Batch 2300] loss: 0.006943963090806733
[Epoch 14, Batch 2400] loss: 0.005841660287900083
[Epoch 14, Batch 2500] loss: 0.011962797955222157
[Epoch 14, Batch 2600] loss: 0.004469837284570701
[Epoch 14, Batch 2700] loss: 0.010214792117822072
[Epoch 14, Batch 2800] loss: 0.0047703836190494545
[Epoch 14, Batch 2900] loss: 0.0048826196523174305
[Epoch 14, Batch 3000] loss: 0.005089289440409175
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9892
Overfitting: 0.0479
[Epoch 15, Batch 100] loss: 0.00378257072505221
[Epoch 15, Batch 200] loss: 0.0020765102749583163
[Epoch 15, Batch 300] loss: 0.0026990483884905634
[Epoch 15, Batch 400] loss: 0.0019536716895268568
[Epoch 15, Batch 500] loss: 0.00353212529785047
[Epoch 15, Batch 600] loss: 0.008824487841907001
[Epoch 15, Batch 700] loss: 0.0030883341875357928
[Epoch 15, Batch 800] loss: 0.0017948830702685114
[Epoch 15, Batch 900] loss: 0.0015974034390894998
[Epoch 15, Batch 1000] loss: 0.008137354154964384
[Epoch 15, Batch 1100] loss: 0.006561006709130908
[Epoch 15, Batch 1200] loss: 0.005968163418575614
[Epoch 15, Batch 1300] loss: 0.007462292433266455
[Epoch 15, Batch 1400] loss: 0.007237077179188134
[Epoch 15, Batch 1500] loss: 0.013752527984724235
[Epoch 15, Batch 1600] loss: 0.011843429215928437
[Epoch 15, Batch 1700] loss: 0.01579674752503479
[Epoch 15, Batch 1800] loss: 0.005692728943394058
[Epoch 15, Batch 1900] loss: 0.010367046050450739
[Epoch 15, Batch 2000] loss: 0.03347194907341077
[Epoch 15, Batch 2100] loss: 0.009328472481020072
[Epoch 15, Batch 2200] loss: 0.00975389908064784
[Epoch 15, Batch 2300] loss: 0.009370733823593014
[Epoch 15, Batch 2400] loss: 0.01055480478707139
[Epoch 15, Batch 2500] loss: 0.003009297336697969
[Epoch 15, Batch 2600] loss: 0.004811670357555329
[Epoch 15, Batch 2700] loss: 0.010019241266787162
[Epoch 15, Batch 2800] loss: 0.010674343539286327
[Epoch 15, Batch 2900] loss: 0.018037367536730357
[Epoch 15, Batch 3000] loss: 0.006094515997588701
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0717
Validation Accuracy: 0.9848
Overfitting: 0.0717
[Epoch 16, Batch 100] loss: 0.01380150868212226
[Epoch 16, Batch 200] loss: 0.008971490245601217
[Epoch 16, Batch 300] loss: 0.010869878256072526
[Epoch 16, Batch 400] loss: 0.004542075906753382
[Epoch 16, Batch 500] loss: 0.016319997245100807
[Epoch 16, Batch 600] loss: 0.010250645765641764
[Epoch 16, Batch 700] loss: 0.002961126939045897
[Epoch 16, Batch 800] loss: 0.0149958114676177
[Epoch 16, Batch 900] loss: 0.0060265789441533
[Epoch 16, Batch 1000] loss: 0.0050553338110677255
[Epoch 16, Batch 1100] loss: 0.008358013470394568
[Epoch 16, Batch 1200] loss: 0.011580813325448674
[Epoch 16, Batch 1300] loss: 0.0128727237820004
[Epoch 16, Batch 1400] loss: 0.00755746524181788
[Epoch 16, Batch 1500] loss: 0.0029825691657502772
[Epoch 16, Batch 1600] loss: 0.0034595861666872453
[Epoch 16, Batch 1700] loss: 0.0026267583969729457
[Epoch 16, Batch 1800] loss: 0.011277394595911403
[Epoch 16, Batch 1900] loss: 0.008668230253508664
[Epoch 16, Batch 2000] loss: 0.0027893417991492696
[Epoch 16, Batch 2100] loss: 0.003073598088058418
[Epoch 16, Batch 2200] loss: 0.007296678105226064
[Epoch 16, Batch 2300] loss: 0.00486284497278632
[Epoch 16, Batch 2400] loss: 0.005394831277600076
[Epoch 16, Batch 2500] loss: 0.0032155544911213595
[Epoch 16, Batch 2600] loss: 0.005529171878431072
[Epoch 16, Batch 2700] loss: 0.0045855162504913945
[Epoch 16, Batch 2800] loss: 0.0028498664913786343
[Epoch 16, Batch 2900] loss: 0.004458909901242408
[Epoch 16, Batch 3000] loss: 0.0020688267113172644
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9890
Overfitting: 0.0528
[Epoch 17, Batch 100] loss: 0.005349915573399002
[Epoch 17, Batch 200] loss: 0.008018492491845813
[Epoch 17, Batch 300] loss: 0.0026868011488178924
[Epoch 17, Batch 400] loss: 0.006768993608361456
[Epoch 17, Batch 500] loss: 0.002854764392537845
[Epoch 17, Batch 600] loss: 0.0031945962410452468
[Epoch 17, Batch 700] loss: 0.005448110898634582
[Epoch 17, Batch 800] loss: 0.004211506741108408
[Epoch 17, Batch 900] loss: 0.002366470047359144
[Epoch 17, Batch 1000] loss: 0.001184652202784804
[Epoch 17, Batch 1100] loss: 0.003728514408629842
[Epoch 17, Batch 1200] loss: 0.001482279872575134
[Epoch 17, Batch 1300] loss: 0.003172417558304792
[Epoch 17, Batch 1400] loss: 0.009823098909950527
[Epoch 17, Batch 1500] loss: 0.011973159070258817
[Epoch 17, Batch 1600] loss: 0.005579260421391439
[Epoch 17, Batch 1700] loss: 0.006676979501670246
[Epoch 17, Batch 1800] loss: 0.0015465032578785554
[Epoch 17, Batch 1900] loss: 0.004781555607535068
[Epoch 17, Batch 2000] loss: 0.006786222857227386
[Epoch 17, Batch 2100] loss: 0.006790817387111328
[Epoch 17, Batch 2200] loss: 0.01712966454783091
[Epoch 17, Batch 2300] loss: 0.011694557602174313
[Epoch 17, Batch 2400] loss: 0.015042400984153765
[Epoch 17, Batch 2500] loss: 0.003080209170079584
[Epoch 17, Batch 2600] loss: 0.007387610993058331
[Epoch 17, Batch 2700] loss: 0.006941989493012386
[Epoch 17, Batch 2800] loss: 0.00875005160693263
[Epoch 17, Batch 2900] loss: 0.004140040740634845
[Epoch 17, Batch 3000] loss: 0.013452827003976254
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0624
Validation Accuracy: 0.9870
Overfitting: 0.0624
[I 2024-12-11 04:30:30,053] Trial 17 pruned. 

Selected Hyperparameters for Trial 19:
  l1: 256, l2: 64, lr: 0.00492813613804113, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.8762941700220108
[Epoch 1, Batch 200] loss: 0.5484497967362404
[Epoch 1, Batch 300] loss: 0.31329684793949125
[Epoch 1, Batch 400] loss: 0.24022100627422333
[Epoch 1, Batch 500] loss: 0.1763568305596709
[Epoch 1, Batch 600] loss: 0.1547363100387156
[Epoch 1, Batch 700] loss: 0.13379014175385237
**STATS for Epoch 1** : 
Average training loss: 0.0087
Average validation loss: 0.1310
Validation Accuracy: 0.9608
Overfitting: 0.1223
Best model saved at epoch 1 with validation loss: 0.1310
[Epoch 2, Batch 100] loss: 0.11025123031809926
[Epoch 2, Batch 200] loss: 0.1099320909101516
[Epoch 2, Batch 300] loss: 0.09433521584607661
[Epoch 2, Batch 400] loss: 0.0973028619773686
[Epoch 2, Batch 500] loss: 0.09495768873021007
[Epoch 2, Batch 600] loss: 0.08091120063327253
[Epoch 2, Batch 700] loss: 0.08065490189008415
**STATS for Epoch 2** : 
Average training loss: 0.0057
Average validation loss: 0.0777
Validation Accuracy: 0.9755
Overfitting: 0.0720
Best model saved at epoch 2 with validation loss: 0.0777
[Epoch 3, Batch 100] loss: 0.06835595638956875
[Epoch 3, Batch 200] loss: 0.06201589345000684
[Epoch 3, Batch 300] loss: 0.07048496448434889
[Epoch 3, Batch 400] loss: 0.061164018944837154
[Epoch 3, Batch 500] loss: 0.07354557237122208
[Epoch 3, Batch 600] loss: 0.06363630395382643
[Epoch 3, Batch 700] loss: 0.057298412907402965
**STATS for Epoch 3** : 
Average training loss: 0.0045
Average validation loss: 0.0639
Validation Accuracy: 0.9801
Overfitting: 0.0594
Best model saved at epoch 3 with validation loss: 0.0639
[Epoch 4, Batch 100] loss: 0.0545414247084409
[Epoch 4, Batch 200] loss: 0.053282029731199144
[Epoch 4, Batch 300] loss: 0.04976518634939566
[Epoch 4, Batch 400] loss: 0.05038021561224013
[Epoch 4, Batch 500] loss: 0.054798032233957204
[Epoch 4, Batch 600] loss: 0.04174057834781706
[Epoch 4, Batch 700] loss: 0.05015213005710393
**STATS for Epoch 4** : 
Average training loss: 0.0033
Average validation loss: 0.0574
Validation Accuracy: 0.9820
Overfitting: 0.0542
Best model saved at epoch 4 with validation loss: 0.0574
[Epoch 5, Batch 100] loss: 0.04148234608699568
[Epoch 5, Batch 200] loss: 0.042319455666001884
[Epoch 5, Batch 300] loss: 0.03995760299032554
[Epoch 5, Batch 400] loss: 0.04079638470779173
[Epoch 5, Batch 500] loss: 0.04769675644580275
[Epoch 5, Batch 600] loss: 0.044361024982063096
[Epoch 5, Batch 700] loss: 0.03499509402317926
**STATS for Epoch 5** : 
Average training loss: 0.0027
Average validation loss: 0.0571
Validation Accuracy: 0.9822
Overfitting: 0.0545
Best model saved at epoch 5 with validation loss: 0.0571
[Epoch 6, Batch 100] loss: 0.03656239165109582
[Epoch 6, Batch 200] loss: 0.03333235942234751
[Epoch 6, Batch 300] loss: 0.03777749863918871
[Epoch 6, Batch 400] loss: 0.039694599299691616
[Epoch 6, Batch 500] loss: 0.035687797641148794
[Epoch 6, Batch 600] loss: 0.028992656834889205
[Epoch 6, Batch 700] loss: 0.03178208294906654
**STATS for Epoch 6** : 
Average training loss: 0.0013
Average validation loss: 0.0468
Validation Accuracy: 0.9855
Overfitting: 0.0454
Best model saved at epoch 6 with validation loss: 0.0468
[Epoch 7, Batch 100] loss: 0.025360333510907367
[Epoch 7, Batch 200] loss: 0.03358533063787036
[Epoch 7, Batch 300] loss: 0.03118850214232225
[Epoch 7, Batch 400] loss: 0.02902303707494866
[Epoch 7, Batch 500] loss: 0.024398357548052446
[Epoch 7, Batch 600] loss: 0.032454689912556206
[Epoch 7, Batch 700] loss: 0.025440242204931563
**STATS for Epoch 7** : 
Average training loss: 0.0015
Average validation loss: 0.0422
Validation Accuracy: 0.9863
Overfitting: 0.0406
Best model saved at epoch 7 with validation loss: 0.0422
[Epoch 8, Batch 100] loss: 0.0165777623699978
[Epoch 8, Batch 200] loss: 0.02630959286063444
[Epoch 8, Batch 300] loss: 0.01969687733799219
[Epoch 8, Batch 400] loss: 0.02097240874252748
[Epoch 8, Batch 500] loss: 0.02497522469377145
[Epoch 8, Batch 600] loss: 0.02922811088967137
[Epoch 8, Batch 700] loss: 0.028289952755440027
**STATS for Epoch 8** : 
Average training loss: 0.0021
Average validation loss: 0.0581
Validation Accuracy: 0.9832
Overfitting: 0.0559
[Epoch 9, Batch 100] loss: 0.01785577161470428
[Epoch 9, Batch 200] loss: 0.015308429328142666
[Epoch 9, Batch 300] loss: 0.02095691388443811
[Epoch 9, Batch 400] loss: 0.020604434911219868
[Epoch 9, Batch 500] loss: 0.019628569294000045
[Epoch 9, Batch 600] loss: 0.029461977525497788
[Epoch 9, Batch 700] loss: 0.02370919365872396
**STATS for Epoch 9** : 
Average training loss: 0.0014
Average validation loss: 0.0477
Validation Accuracy: 0.9857
Overfitting: 0.0463
[Epoch 10, Batch 100] loss: 0.017869286763016135
[Epoch 10, Batch 200] loss: 0.014422323377148131
[Epoch 10, Batch 300] loss: 0.01757979103771504
[Epoch 10, Batch 400] loss: 0.01972528009689995
[Epoch 10, Batch 500] loss: 0.01943850074603688
[Epoch 10, Batch 600] loss: 0.013919857890869025
[Epoch 10, Batch 700] loss: 0.018984626042074525
**STATS for Epoch 10** : 
Average training loss: 0.0014
Average validation loss: 0.0402
Validation Accuracy: 0.9872
Overfitting: 0.0388
Best model saved at epoch 10 with validation loss: 0.0402
[Epoch 11, Batch 100] loss: 0.01602917413634714
[Epoch 11, Batch 200] loss: 0.013718778339243726
[Epoch 11, Batch 300] loss: 0.011647538064426043
[Epoch 11, Batch 400] loss: 0.015601961123466027
[Epoch 11, Batch 500] loss: 0.01712756029141019
[Epoch 11, Batch 600] loss: 0.011067839704810466
[Epoch 11, Batch 700] loss: 0.016323118706350215
**STATS for Epoch 11** : 
Average training loss: 0.0011
Average validation loss: 0.0437
Validation Accuracy: 0.9875
Overfitting: 0.0426
[Epoch 12, Batch 100] loss: 0.008848309175373287
[Epoch 12, Batch 200] loss: 0.012461709090712248
[Epoch 12, Batch 300] loss: 0.012856758093403187
[Epoch 12, Batch 400] loss: 0.01016110313757963
[Epoch 12, Batch 500] loss: 0.011929257411684374
[Epoch 12, Batch 600] loss: 0.013248088133404962
[Epoch 12, Batch 700] loss: 0.010991925449561677
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0434
Validation Accuracy: 0.9880
Overfitting: 0.0421
[Epoch 13, Batch 100] loss: 0.009032299687387422
[Epoch 13, Batch 200] loss: 0.008318791170240728
[Epoch 13, Batch 300] loss: 0.004872159564256435
[Epoch 13, Batch 400] loss: 0.010464050602167844
[Epoch 13, Batch 500] loss: 0.010385374531506387
[Epoch 13, Batch 600] loss: 0.012382872572052292
[Epoch 13, Batch 700] loss: 0.012492168291209964
**STATS for Epoch 13** : 
Average training loss: 0.0007
Average validation loss: 0.0471
Validation Accuracy: 0.9882
Overfitting: 0.0464
[Epoch 14, Batch 100] loss: 0.009484655002015643
[Epoch 14, Batch 200] loss: 0.01615563762723468
[Epoch 14, Batch 300] loss: 0.009445939077995718
[Epoch 14, Batch 400] loss: 0.011175145208981122
[Epoch 14, Batch 500] loss: 0.01231288720315206
[Epoch 14, Batch 600] loss: 0.01374475463759154
[Epoch 14, Batch 700] loss: 0.010246890416165116
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0402
Validation Accuracy: 0.9886
Overfitting: 0.0394
[Epoch 15, Batch 100] loss: 0.008345663786822116
[Epoch 15, Batch 200] loss: 0.009694829725922317
[Epoch 15, Batch 300] loss: 0.007163599743416853
[Epoch 15, Batch 400] loss: 0.008207603669943638
[Epoch 15, Batch 500] loss: 0.009178977921401384
[Epoch 15, Batch 600] loss: 0.009071105032562627
[Epoch 15, Batch 700] loss: 0.006017288396669755
**STATS for Epoch 15** : 
Average training loss: 0.0003
Average validation loss: 0.0423
Validation Accuracy: 0.9886
Overfitting: 0.0421
[Epoch 16, Batch 100] loss: 0.0032311814916647563
[Epoch 16, Batch 200] loss: 0.0063470461867837
[Epoch 16, Batch 300] loss: 0.009254172047076282
[Epoch 16, Batch 400] loss: 0.007124861905977014
[Epoch 16, Batch 500] loss: 0.007832648303410678
[Epoch 16, Batch 600] loss: 0.00689263395517628
[Epoch 16, Batch 700] loss: 0.006538781490326074
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0425
Validation Accuracy: 0.9891
Overfitting: 0.0419
[Epoch 17, Batch 100] loss: 0.004869110226973134
[Epoch 17, Batch 200] loss: 0.0031845121330024997
[Epoch 17, Batch 300] loss: 0.0057776225528868965
[Epoch 17, Batch 400] loss: 0.0061341665339568864
[Epoch 17, Batch 500] loss: 0.010013656240698766
[Epoch 17, Batch 600] loss: 0.010070959155964374
[Epoch 17, Batch 700] loss: 0.007379985279185348
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0433
Validation Accuracy: 0.9884
Overfitting: 0.0428
[Epoch 18, Batch 100] loss: 0.004363888400184805
[Epoch 18, Batch 200] loss: 0.0030173965660651447
[Epoch 18, Batch 300] loss: 0.005656145753000601
[Epoch 18, Batch 400] loss: 0.00532409912582807
[Epoch 18, Batch 500] loss: 0.005838331527929768
[Epoch 18, Batch 600] loss: 0.005185479319179649
[Epoch 18, Batch 700] loss: 0.006376777230980224
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0583
Validation Accuracy: 0.9857
Overfitting: 0.0576
[Epoch 19, Batch 100] loss: 0.005486949207333964
[Epoch 19, Batch 200] loss: 0.007380005985414755
[Epoch 19, Batch 300] loss: 0.004659235648305184
[Epoch 19, Batch 400] loss: 0.004357435782512766
[Epoch 19, Batch 500] loss: 0.0021168769923133367
[Epoch 19, Batch 600] loss: 0.0049382306691586565
[Epoch 19, Batch 700] loss: 0.0048666061660696865
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0484
Validation Accuracy: 0.9877
Overfitting: 0.0481
[Epoch 20, Batch 100] loss: 0.003450987972355506
[Epoch 20, Batch 200] loss: 0.0020907924763196206
[Epoch 20, Batch 300] loss: 0.0012172523878280117
[Epoch 20, Batch 400] loss: 0.0020528762727826688
[Epoch 20, Batch 500] loss: 0.004984521795340697
[Epoch 20, Batch 600] loss: 0.003962839608411741
[Epoch 20, Batch 700] loss: 0.0034140969178997694
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0534
Validation Accuracy: 0.9868
Overfitting: 0.0531
[Epoch 21, Batch 100] loss: 0.0038110951581074915
[Epoch 21, Batch 200] loss: 0.0015864295004166707
[Epoch 21, Batch 300] loss: 0.002563390044515472
[Epoch 21, Batch 400] loss: 0.0018736109539804601
[Epoch 21, Batch 500] loss: 0.0014943778039014433
[Epoch 21, Batch 600] loss: 0.002148714237537206
[Epoch 21, Batch 700] loss: 0.0015821357499612532
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0469
Validation Accuracy: 0.9886
Overfitting: 0.0468
[Epoch 22, Batch 100] loss: 0.0009571205552924766
[Epoch 22, Batch 200] loss: 0.000997522106449651
[Epoch 22, Batch 300] loss: 0.0017650975317246775
[Epoch 22, Batch 400] loss: 0.0006896472923199326
[Epoch 22, Batch 500] loss: 0.0007426329808367882
[Epoch 22, Batch 600] loss: 0.0017432498124333052
[Epoch 22, Batch 700] loss: 0.001993436575432952
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0449
Validation Accuracy: 0.9894
Overfitting: 0.0448
[Epoch 23, Batch 100] loss: 0.0008448309533673637
[Epoch 23, Batch 200] loss: 0.0005632791324205755
[Epoch 23, Batch 300] loss: 0.002797960810667064
[Epoch 23, Batch 400] loss: 0.001867750503465686
[Epoch 23, Batch 500] loss: 0.0012157507484380403
[Epoch 23, Batch 600] loss: 0.0005239549781731512
[Epoch 23, Batch 700] loss: 0.0015564125734567824
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9899
Overfitting: 0.0464
[Epoch 24, Batch 100] loss: 0.002475873432053959
[Epoch 24, Batch 200] loss: 0.0019068123350916722
[Epoch 24, Batch 300] loss: 0.0006923456572098985
[Epoch 24, Batch 400] loss: 0.0009204703413934112
[Epoch 24, Batch 500] loss: 0.000862920910280991
[Epoch 24, Batch 600] loss: 0.0013251301817945205
[Epoch 24, Batch 700] loss: 0.0004789960522930414
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9897
Overfitting: 0.0458
Fold 1 validation loss: 0.0458
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.1988747096061707
[Epoch 1, Batch 200] loss: 0.7645810742676258
[Epoch 1, Batch 300] loss: 0.3273540457338095
[Epoch 1, Batch 400] loss: 0.23309147074818612
[Epoch 1, Batch 500] loss: 0.17473259072750807
[Epoch 1, Batch 600] loss: 0.16292361553758383
[Epoch 1, Batch 700] loss: 0.1334248991124332
**STATS for Epoch 1** : 
Average training loss: 0.0085
Average validation loss: 0.1568
Validation Accuracy: 0.9512
Overfitting: 0.1484
Best model saved at epoch 1 with validation loss: 0.1568
[Epoch 2, Batch 100] loss: 0.1272294104564935
[Epoch 2, Batch 200] loss: 0.10026865515857936
[Epoch 2, Batch 300] loss: 0.10124978963285684
[Epoch 2, Batch 400] loss: 0.10329649693332613
[Epoch 2, Batch 500] loss: 0.09377367506735027
[Epoch 2, Batch 600] loss: 0.1002257943712175
[Epoch 2, Batch 700] loss: 0.08117844825610518
**STATS for Epoch 2** : 
Average training loss: 0.0055
Average validation loss: 0.0885
Validation Accuracy: 0.9728
Overfitting: 0.0830
Best model saved at epoch 2 with validation loss: 0.0885
[Epoch 3, Batch 100] loss: 0.07498404047917574
[Epoch 3, Batch 200] loss: 0.06284157441463321
[Epoch 3, Batch 300] loss: 0.06900167375337332
[Epoch 3, Batch 400] loss: 0.0666210248786956
[Epoch 3, Batch 500] loss: 0.05764240201562643
[Epoch 3, Batch 600] loss: 0.057361712057609114
[Epoch 3, Batch 700] loss: 0.06343632738571614
**STATS for Epoch 3** : 
Average training loss: 0.0046
Average validation loss: 0.0912
Validation Accuracy: 0.9722
Overfitting: 0.0866
[Epoch 4, Batch 100] loss: 0.051711022527888416
[Epoch 4, Batch 200] loss: 0.05089651808841154
[Epoch 4, Batch 300] loss: 0.05486586125567555
[Epoch 4, Batch 400] loss: 0.05523843732196838
[Epoch 4, Batch 500] loss: 0.040875551778590306
[Epoch 4, Batch 600] loss: 0.05102900256053545
[Epoch 4, Batch 700] loss: 0.04639981820015237
**STATS for Epoch 4** : 
Average training loss: 0.0040
Average validation loss: 0.0719
Validation Accuracy: 0.9773
Overfitting: 0.0679
Best model saved at epoch 4 with validation loss: 0.0719
[Epoch 5, Batch 100] loss: 0.03790791741106659
[Epoch 5, Batch 200] loss: 0.042832434840966015
[Epoch 5, Batch 300] loss: 0.04668470269534737
[Epoch 5, Batch 400] loss: 0.0423923563270364
[Epoch 5, Batch 500] loss: 0.03917575215222314
[Epoch 5, Batch 600] loss: 0.04795265689026564
[Epoch 5, Batch 700] loss: 0.04094880808552261
**STATS for Epoch 5** : 
Average training loss: 0.0033
Average validation loss: 0.0632
Validation Accuracy: 0.9818
Overfitting: 0.0599
Best model saved at epoch 5 with validation loss: 0.0632
[Epoch 6, Batch 100] loss: 0.033227889471454546
[Epoch 6, Batch 200] loss: 0.030647389513906092
[Epoch 6, Batch 300] loss: 0.03446021969721187
[Epoch 6, Batch 400] loss: 0.03440720880869776
[Epoch 6, Batch 500] loss: 0.036059670218965036
[Epoch 6, Batch 600] loss: 0.03875031893607229
[Epoch 6, Batch 700] loss: 0.038203339856117964
**STATS for Epoch 6** : 
Average training loss: 0.0025
Average validation loss: 0.0567
Validation Accuracy: 0.9840
Overfitting: 0.0542
Best model saved at epoch 6 with validation loss: 0.0567
[Epoch 7, Batch 100] loss: 0.023772893224377187
[Epoch 7, Batch 200] loss: 0.027762196997646243
[Epoch 7, Batch 300] loss: 0.029009942000848242
[Epoch 7, Batch 400] loss: 0.030432486888603307
[Epoch 7, Batch 500] loss: 0.03167065936257132
[Epoch 7, Batch 600] loss: 0.027411266473936848
[Epoch 7, Batch 700] loss: 0.029380837264761796
**STATS for Epoch 7** : 
Average training loss: 0.0021
Average validation loss: 0.0592
Validation Accuracy: 0.9838
Overfitting: 0.0571
[Epoch 8, Batch 100] loss: 0.019564070080814417
[Epoch 8, Batch 200] loss: 0.02183585903432686
[Epoch 8, Batch 300] loss: 0.021593774802749977
[Epoch 8, Batch 400] loss: 0.027997142750828062
[Epoch 8, Batch 500] loss: 0.02130605054786429
[Epoch 8, Batch 600] loss: 0.0278949083032785
[Epoch 8, Batch 700] loss: 0.028709450247115454
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0598
Validation Accuracy: 0.9819
Overfitting: 0.0579
[Epoch 9, Batch 100] loss: 0.01807835967018036
[Epoch 9, Batch 200] loss: 0.015597671508439817
[Epoch 9, Batch 300] loss: 0.022758234700304456
[Epoch 9, Batch 400] loss: 0.027577675709617323
[Epoch 9, Batch 500] loss: 0.021397961108013987
[Epoch 9, Batch 600] loss: 0.01989076000987552
[Epoch 9, Batch 700] loss: 0.025798337458109017
**STATS for Epoch 9** : 
Average training loss: 0.0015
Average validation loss: 0.0542
Validation Accuracy: 0.9842
Overfitting: 0.0527
Best model saved at epoch 9 with validation loss: 0.0542
[Epoch 10, Batch 100] loss: 0.012176767546334304
[Epoch 10, Batch 200] loss: 0.016263563116663136
[Epoch 10, Batch 300] loss: 0.016875650724978188
[Epoch 10, Batch 400] loss: 0.01924726468321751
[Epoch 10, Batch 500] loss: 0.018174911093665286
[Epoch 10, Batch 600] loss: 0.02152615052065812
[Epoch 10, Batch 700] loss: 0.02248450728424359
**STATS for Epoch 10** : 
Average training loss: 0.0015
Average validation loss: 0.0584
Validation Accuracy: 0.9841
Overfitting: 0.0569
[Epoch 11, Batch 100] loss: 0.01750316741206916
[Epoch 11, Batch 200] loss: 0.012855118611769285
[Epoch 11, Batch 300] loss: 0.013076480978925246
[Epoch 11, Batch 400] loss: 0.017423269698338118
[Epoch 11, Batch 500] loss: 0.014470548091630918
[Epoch 11, Batch 600] loss: 0.01349921456159791
[Epoch 11, Batch 700] loss: 0.018017200086178492
**STATS for Epoch 11** : 
Average training loss: 0.0010
Average validation loss: 0.0653
Validation Accuracy: 0.9832
Overfitting: 0.0643
[Epoch 12, Batch 100] loss: 0.012408103393972851
[Epoch 12, Batch 200] loss: 0.01239312676290865
[Epoch 12, Batch 300] loss: 0.009860078583442374
[Epoch 12, Batch 400] loss: 0.014366031620738795
[Epoch 12, Batch 500] loss: 0.012140771333943121
[Epoch 12, Batch 600] loss: 0.012395328176062322
[Epoch 12, Batch 700] loss: 0.01011841929750517
**STATS for Epoch 12** : 
Average training loss: 0.0011
Average validation loss: 0.0562
Validation Accuracy: 0.9858
Overfitting: 0.0551
[Epoch 13, Batch 100] loss: 0.010719559471472167
[Epoch 13, Batch 200] loss: 0.014665733443544014
[Epoch 13, Batch 300] loss: 0.009290197793088737
[Epoch 13, Batch 400] loss: 0.008521092294686242
[Epoch 13, Batch 500] loss: 0.008269523558337823
[Epoch 13, Batch 600] loss: 0.014844145716924686
[Epoch 13, Batch 700] loss: 0.008678551060002064
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0600
Validation Accuracy: 0.9844
Overfitting: 0.0591
[Epoch 14, Batch 100] loss: 0.010103346596297342
[Epoch 14, Batch 200] loss: 0.010266416488593676
[Epoch 14, Batch 300] loss: 0.004914339652823401
[Epoch 14, Batch 400] loss: 0.007471930181127391
[Epoch 14, Batch 500] loss: 0.008473107049212558
[Epoch 14, Batch 600] loss: 0.010829172783232935
[Epoch 14, Batch 700] loss: 0.007473956736648688
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0636
Validation Accuracy: 0.9847
Overfitting: 0.0628
[Epoch 15, Batch 100] loss: 0.010223516820842634
[Epoch 15, Batch 200] loss: 0.009673182300975896
[Epoch 15, Batch 300] loss: 0.009063112536023255
[Epoch 15, Batch 400] loss: 0.008117011939248187
[Epoch 15, Batch 500] loss: 0.006261240976673434
[Epoch 15, Batch 600] loss: 0.016809249862781143
[Epoch 15, Batch 700] loss: 0.009507855954525439
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0639
Validation Accuracy: 0.9860
Overfitting: 0.0632
[Epoch 16, Batch 100] loss: 0.011205897858526442
[Epoch 16, Batch 200] loss: 0.007378797363053309
[Epoch 16, Batch 300] loss: 0.005714176247856813
[Epoch 16, Batch 400] loss: 0.0052081075051683004
[Epoch 16, Batch 500] loss: 0.006298307758279407
[Epoch 16, Batch 600] loss: 0.00765095889544682
[Epoch 16, Batch 700] loss: 0.0071157133601809615
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0662
Validation Accuracy: 0.9852
Overfitting: 0.0656
[Epoch 17, Batch 100] loss: 0.004812454650782456
[Epoch 17, Batch 200] loss: 0.004647046165046049
[Epoch 17, Batch 300] loss: 0.0032699991418849096
[Epoch 17, Batch 400] loss: 0.004525164470178425
[Epoch 17, Batch 500] loss: 0.0073017170892489955
[Epoch 17, Batch 600] loss: 0.004684979404137266
[Epoch 17, Batch 700] loss: 0.008561400204780512
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0720
Validation Accuracy: 0.9848
Overfitting: 0.0713
[Epoch 18, Batch 100] loss: 0.007200317637798434
[Epoch 18, Batch 200] loss: 0.009780470278456051
[Epoch 18, Batch 300] loss: 0.007974608056720171
[Epoch 18, Batch 400] loss: 0.007948583176039392
[Epoch 18, Batch 500] loss: 0.004215119924992905
[Epoch 18, Batch 600] loss: 0.004802209913959814
[Epoch 18, Batch 700] loss: 0.010073495084507158
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0604
Validation Accuracy: 0.9861
Overfitting: 0.0602
[Epoch 19, Batch 100] loss: 0.00237002766218211
[Epoch 19, Batch 200] loss: 0.005475216654258474
[Epoch 19, Batch 300] loss: 0.006000733435575967
[Epoch 19, Batch 400] loss: 0.004979860027833638
[Epoch 19, Batch 500] loss: 0.00510064552174299
[Epoch 19, Batch 600] loss: 0.003293316710387444
[Epoch 19, Batch 700] loss: 0.003573543638121919
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0647
Validation Accuracy: 0.9872
Overfitting: 0.0644
[Epoch 20, Batch 100] loss: 0.0024011007721674105
[Epoch 20, Batch 200] loss: 0.001510477257270395
[Epoch 20, Batch 300] loss: 0.0032615224437540745
[Epoch 20, Batch 400] loss: 0.002590897254867741
[Epoch 20, Batch 500] loss: 0.0026999962581339787
[Epoch 20, Batch 600] loss: 0.0021797769259450208
[Epoch 20, Batch 700] loss: 0.003396231859615
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0677
Validation Accuracy: 0.9875
Overfitting: 0.0675
[Epoch 21, Batch 100] loss: 0.0022836347409975134
[Epoch 21, Batch 200] loss: 0.0013638027546130616
[Epoch 21, Batch 300] loss: 0.002185478395501832
[Epoch 21, Batch 400] loss: 0.0013070282260832756
[Epoch 21, Batch 500] loss: 0.0036244193328229812
[Epoch 21, Batch 600] loss: 0.008552425053821935
[Epoch 21, Batch 700] loss: 0.004273105998800019
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0750
Validation Accuracy: 0.9857
Overfitting: 0.0746
[Epoch 22, Batch 100] loss: 0.0037293775861598987
[Epoch 22, Batch 200] loss: 0.0021976930638084014
[Epoch 22, Batch 300] loss: 0.001510039817121651
[Epoch 22, Batch 400] loss: 0.003006569212575414
[Epoch 22, Batch 500] loss: 0.0038835685971662314
[Epoch 22, Batch 600] loss: 0.003067330384556044
[Epoch 22, Batch 700] loss: 0.0024303321416300604
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0690
Validation Accuracy: 0.9872
Overfitting: 0.0689
[Epoch 23, Batch 100] loss: 0.0015495026084954588
[Epoch 23, Batch 200] loss: 0.0017109586527544708
[Epoch 23, Batch 300] loss: 0.0012562853646704752
[Epoch 23, Batch 400] loss: 0.001610544537138594
[Epoch 23, Batch 500] loss: 0.001701318150080624
[Epoch 23, Batch 600] loss: 0.0024379224621247884
[Epoch 23, Batch 700] loss: 0.0013854623863403504
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0690
Validation Accuracy: 0.9875
Overfitting: 0.0689
[Epoch 24, Batch 100] loss: 0.0011003694211854055
[Epoch 24, Batch 200] loss: 0.0006778213111942932
[Epoch 24, Batch 300] loss: 0.001308977304529435
[Epoch 24, Batch 400] loss: 0.000859041370677005
[Epoch 24, Batch 500] loss: 0.00048253195751158274
[Epoch 24, Batch 600] loss: 0.0005957938559959075
[Epoch 24, Batch 700] loss: 0.0010065983791582766
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0692
Validation Accuracy: 0.9876
Overfitting: 0.0691
Fold 2 validation loss: 0.0692
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.1029271864891053
[Epoch 1, Batch 200] loss: 0.5692304998636246
[Epoch 1, Batch 300] loss: 0.289993999004364
[Epoch 1, Batch 400] loss: 0.23379583522677422
[Epoch 1, Batch 500] loss: 0.17094205539673568
[Epoch 1, Batch 600] loss: 0.14599954329431056
[Epoch 1, Batch 700] loss: 0.15148940559476615
**STATS for Epoch 1** : 
Average training loss: 0.0092
Average validation loss: 0.1409
Validation Accuracy: 0.9568
Overfitting: 0.1317
Best model saved at epoch 1 with validation loss: 0.1409
[Epoch 2, Batch 100] loss: 0.12056542994454503
[Epoch 2, Batch 200] loss: 0.10161775073036551
[Epoch 2, Batch 300] loss: 0.10227535493671894
[Epoch 2, Batch 400] loss: 0.10762314377352596
[Epoch 2, Batch 500] loss: 0.09450172907672823
[Epoch 2, Batch 600] loss: 0.08437359620817006
[Epoch 2, Batch 700] loss: 0.077335811634548
**STATS for Epoch 2** : 
Average training loss: 0.0055
Average validation loss: 0.0893
Validation Accuracy: 0.9708
Overfitting: 0.0837
Best model saved at epoch 2 with validation loss: 0.0893
[Epoch 3, Batch 100] loss: 0.07899558184202761
[Epoch 3, Batch 200] loss: 0.06938889507669956
[Epoch 3, Batch 300] loss: 0.06687184086535126
[Epoch 3, Batch 400] loss: 0.06401628830470145
[Epoch 3, Batch 500] loss: 0.06789332867134362
[Epoch 3, Batch 600] loss: 0.06679036055924371
[Epoch 3, Batch 700] loss: 0.069148259004578
**STATS for Epoch 3** : 
Average training loss: 0.0044
Average validation loss: 0.0787
Validation Accuracy: 0.9748
Overfitting: 0.0743
Best model saved at epoch 3 with validation loss: 0.0787
[Epoch 4, Batch 100] loss: 0.05297354201553389
[Epoch 4, Batch 200] loss: 0.05981011586729437
[Epoch 4, Batch 300] loss: 0.05729217744199559
[Epoch 4, Batch 400] loss: 0.0503964577941224
[Epoch 4, Batch 500] loss: 0.044448102314490825
[Epoch 4, Batch 600] loss: 0.05739829483209178
[Epoch 4, Batch 700] loss: 0.05274283033795655
**STATS for Epoch 4** : 
Average training loss: 0.0036
Average validation loss: 0.0568
Validation Accuracy: 0.9818
Overfitting: 0.0532
Best model saved at epoch 4 with validation loss: 0.0568
[Epoch 5, Batch 100] loss: 0.043407973907887934
[Epoch 5, Batch 200] loss: 0.04479995234170928
[Epoch 5, Batch 300] loss: 0.0429091648501344
[Epoch 5, Batch 400] loss: 0.041649339467985554
[Epoch 5, Batch 500] loss: 0.047397978121880444
[Epoch 5, Batch 600] loss: 0.044818937048548835
[Epoch 5, Batch 700] loss: 0.04467521943850443
**STATS for Epoch 5** : 
Average training loss: 0.0033
Average validation loss: 0.0505
Validation Accuracy: 0.9854
Overfitting: 0.0472
Best model saved at epoch 5 with validation loss: 0.0505
[Epoch 6, Batch 100] loss: 0.0357826499606017
[Epoch 6, Batch 200] loss: 0.03976845542318188
[Epoch 6, Batch 300] loss: 0.03362273054663092
[Epoch 6, Batch 400] loss: 0.046670497658196836
[Epoch 6, Batch 500] loss: 0.03853440779959783
[Epoch 6, Batch 600] loss: 0.025834016867447643
[Epoch 6, Batch 700] loss: 0.04247018077527173
**STATS for Epoch 6** : 
Average training loss: 0.0028
Average validation loss: 0.0498
Validation Accuracy: 0.9852
Overfitting: 0.0470
Best model saved at epoch 6 with validation loss: 0.0498
[Epoch 7, Batch 100] loss: 0.029056245530955493
[Epoch 7, Batch 200] loss: 0.03346725848619826
[Epoch 7, Batch 300] loss: 0.026060664880205878
[Epoch 7, Batch 400] loss: 0.03252587824128568
[Epoch 7, Batch 500] loss: 0.02585168241726933
[Epoch 7, Batch 600] loss: 0.03363014208502136
[Epoch 7, Batch 700] loss: 0.040466666813008485
**STATS for Epoch 7** : 
Average training loss: 0.0025
Average validation loss: 0.0472
Validation Accuracy: 0.9858
Overfitting: 0.0447
Best model saved at epoch 7 with validation loss: 0.0472
[Epoch 8, Batch 100] loss: 0.02371140063740313
[Epoch 8, Batch 200] loss: 0.025724209748441352
[Epoch 8, Batch 300] loss: 0.02196274625035585
[Epoch 8, Batch 400] loss: 0.0246822066209279
[Epoch 8, Batch 500] loss: 0.02438951986579923
[Epoch 8, Batch 600] loss: 0.030045801158994436
[Epoch 8, Batch 700] loss: 0.027379590936470778
**STATS for Epoch 8** : 
Average training loss: 0.0026
Average validation loss: 0.0482
Validation Accuracy: 0.9863
Overfitting: 0.0456
[Epoch 9, Batch 100] loss: 0.018496700443793087
[Epoch 9, Batch 200] loss: 0.0249563942279201
[Epoch 9, Batch 300] loss: 0.02226374225516338
[Epoch 9, Batch 400] loss: 0.02284639005200006
[Epoch 9, Batch 500] loss: 0.026738195978687145
[Epoch 9, Batch 600] loss: 0.018117035417817534
[Epoch 9, Batch 700] loss: 0.022736599761701656
**STATS for Epoch 9** : 
Average training loss: 0.0014
Average validation loss: 0.0567
Validation Accuracy: 0.9824
Overfitting: 0.0552
[Epoch 10, Batch 100] loss: 0.015545004482555668
[Epoch 10, Batch 200] loss: 0.021765326360764448
[Epoch 10, Batch 300] loss: 0.016517711979977322
[Epoch 10, Batch 400] loss: 0.023558774415869267
[Epoch 10, Batch 500] loss: 0.02178605207009241
[Epoch 10, Batch 600] loss: 0.01768858667695895
[Epoch 10, Batch 700] loss: 0.023139964995789342
**STATS for Epoch 10** : 
Average training loss: 0.0013
Average validation loss: 0.0500
Validation Accuracy: 0.9863
Overfitting: 0.0487
[Epoch 11, Batch 100] loss: 0.01474606010102434
[Epoch 11, Batch 200] loss: 0.014611138262262102
[Epoch 11, Batch 300] loss: 0.02007391980543616
[Epoch 11, Batch 400] loss: 0.015241334957245271
[Epoch 11, Batch 500] loss: 0.016191058912954758
[Epoch 11, Batch 600] loss: 0.01575647280580597
[Epoch 11, Batch 700] loss: 0.01736495237564668
**STATS for Epoch 11** : 
Average training loss: 0.0014
Average validation loss: 0.0487
Validation Accuracy: 0.9860
Overfitting: 0.0473
[Epoch 12, Batch 100] loss: 0.009497484146995703
[Epoch 12, Batch 200] loss: 0.017497706476424357
[Epoch 12, Batch 300] loss: 0.017444420916144735
[Epoch 12, Batch 400] loss: 0.010664578824653291
[Epoch 12, Batch 500] loss: 0.014094595606584335
[Epoch 12, Batch 600] loss: 0.018757452370191458
[Epoch 12, Batch 700] loss: 0.013756742747791578
**STATS for Epoch 12** : 
Average training loss: 0.0009
Average validation loss: 0.0487
Validation Accuracy: 0.9867
Overfitting: 0.0478
[Epoch 13, Batch 100] loss: 0.011469422104128171
[Epoch 13, Batch 200] loss: 0.011170743208494968
[Epoch 13, Batch 300] loss: 0.01061263032752322
[Epoch 13, Batch 400] loss: 0.008277388983988204
[Epoch 13, Batch 500] loss: 0.013014535045513184
[Epoch 13, Batch 600] loss: 0.013334325519899722
[Epoch 13, Batch 700] loss: 0.010264212749461876
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0463
Validation Accuracy: 0.9879
Overfitting: 0.0457
Best model saved at epoch 13 with validation loss: 0.0463
[Epoch 14, Batch 100] loss: 0.0078626740816253
[Epoch 14, Batch 200] loss: 0.0083643707176725
[Epoch 14, Batch 300] loss: 0.014067022504823399
[Epoch 14, Batch 400] loss: 0.009684254923031403
[Epoch 14, Batch 500] loss: 0.0153258801503398
[Epoch 14, Batch 600] loss: 0.008920223277673358
[Epoch 14, Batch 700] loss: 0.016656671833479776
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0517
Validation Accuracy: 0.9864
Overfitting: 0.0507
[Epoch 15, Batch 100] loss: 0.008102324764113291
[Epoch 15, Batch 200] loss: 0.013074606406844396
[Epoch 15, Batch 300] loss: 0.01148552998976811
[Epoch 15, Batch 400] loss: 0.008642607327492441
[Epoch 15, Batch 500] loss: 0.009128319230294437
[Epoch 15, Batch 600] loss: 0.009443705771118402
[Epoch 15, Batch 700] loss: 0.009950848872977076
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0487
Validation Accuracy: 0.9873
Overfitting: 0.0479
[Epoch 16, Batch 100] loss: 0.007501794749587134
[Epoch 16, Batch 200] loss: 0.007273336527869105
[Epoch 16, Batch 300] loss: 0.0035758683035965076
[Epoch 16, Batch 400] loss: 0.006624198021090706
[Epoch 16, Batch 500] loss: 0.008299868413760124
[Epoch 16, Batch 600] loss: 0.012041290597808256
[Epoch 16, Batch 700] loss: 0.009591149574334849
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0535
Validation Accuracy: 0.9860
Overfitting: 0.0530
[Epoch 17, Batch 100] loss: 0.007894159300703904
[Epoch 17, Batch 200] loss: 0.005542509972619882
[Epoch 17, Batch 300] loss: 0.0075904326064119235
[Epoch 17, Batch 400] loss: 0.005318961031771323
[Epoch 17, Batch 500] loss: 0.005141975924925646
[Epoch 17, Batch 600] loss: 0.005184500358809601
[Epoch 17, Batch 700] loss: 0.008483169638639083
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0613
Validation Accuracy: 0.9857
Overfitting: 0.0607
[Epoch 18, Batch 100] loss: 0.0057778285511267315
[Epoch 18, Batch 200] loss: 0.006430186965189932
[Epoch 18, Batch 300] loss: 0.00705418383657161
[Epoch 18, Batch 400] loss: 0.006360503606283601
[Epoch 18, Batch 500] loss: 0.008254432926114531
[Epoch 18, Batch 600] loss: 0.0053498667390886115
[Epoch 18, Batch 700] loss: 0.006716878433653619
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0540
Validation Accuracy: 0.9878
Overfitting: 0.0533
[Epoch 19, Batch 100] loss: 0.0075407718298083634
[Epoch 19, Batch 200] loss: 0.005118348486266768
[Epoch 19, Batch 300] loss: 0.00685731283280802
[Epoch 19, Batch 400] loss: 0.006126074634394172
[Epoch 19, Batch 500] loss: 0.0066654449896304865
[Epoch 19, Batch 600] loss: 0.004902450387962744
[Epoch 19, Batch 700] loss: 0.004597745078508524
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0509
Validation Accuracy: 0.9883
Overfitting: 0.0505
[Epoch 20, Batch 100] loss: 0.0063582608991418965
[Epoch 20, Batch 200] loss: 0.00273074152013578
[Epoch 20, Batch 300] loss: 0.004044751456442555
[Epoch 20, Batch 400] loss: 0.0026945322790652426
[Epoch 20, Batch 500] loss: 0.0018969447730523825
[Epoch 20, Batch 600] loss: 0.0020785707394497875
[Epoch 20, Batch 700] loss: 0.003551714775903747
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0509
Validation Accuracy: 0.9886
Overfitting: 0.0507
[Epoch 21, Batch 100] loss: 0.002020264488019166
[Epoch 21, Batch 200] loss: 0.002581890061928789
[Epoch 21, Batch 300] loss: 0.0018641797705799944
[Epoch 21, Batch 400] loss: 0.0018076432944053521
[Epoch 21, Batch 500] loss: 0.0017244234138524917
[Epoch 21, Batch 600] loss: 0.001262696111700734
[Epoch 21, Batch 700] loss: 0.00249970625740616
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0496
Validation Accuracy: 0.9893
Overfitting: 0.0494
[Epoch 22, Batch 100] loss: 0.0006119624378425214
[Epoch 22, Batch 200] loss: 0.0009228324641185282
[Epoch 22, Batch 300] loss: 0.0018269431589123997
[Epoch 22, Batch 400] loss: 0.0017723063368339353
[Epoch 22, Batch 500] loss: 0.0018505136036640125
[Epoch 22, Batch 600] loss: 0.0015441789068813706
[Epoch 22, Batch 700] loss: 0.004285802026994361
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0507
Validation Accuracy: 0.9889
Overfitting: 0.0507
[Epoch 23, Batch 100] loss: 0.00062110289939028
[Epoch 23, Batch 200] loss: 0.0026492839214597554
[Epoch 23, Batch 300] loss: 0.002659494565050409
[Epoch 23, Batch 400] loss: 0.0026609871309710795
[Epoch 23, Batch 500] loss: 0.004125384581572007
[Epoch 23, Batch 600] loss: 0.004780796143113548
[Epoch 23, Batch 700] loss: 0.0015582856329206152
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0597
Validation Accuracy: 0.9873
Overfitting: 0.0595
[Epoch 24, Batch 100] loss: 0.004170281249416803
[Epoch 24, Batch 200] loss: 0.002358929507126959
[Epoch 24, Batch 300] loss: 0.001689221442688904
[Epoch 24, Batch 400] loss: 0.0013833694772483794
[Epoch 24, Batch 500] loss: 0.0014091629750646463
[Epoch 24, Batch 600] loss: 0.000876033031827319
[Epoch 24, Batch 700] loss: 0.0032614903556554965
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0528
Validation Accuracy: 0.9893
Overfitting: 0.0527
Fold 3 validation loss: 0.0528
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.7913964796066284
[Epoch 1, Batch 200] loss: 0.550857153236866
[Epoch 1, Batch 300] loss: 0.3396872141957283
[Epoch 1, Batch 400] loss: 0.22235987685620784
[Epoch 1, Batch 500] loss: 0.17844977788627148
[Epoch 1, Batch 600] loss: 0.13758305620402098
[Epoch 1, Batch 700] loss: 0.1440493713133037
**STATS for Epoch 1** : 
Average training loss: 0.0073
Average validation loss: 0.1112
Validation Accuracy: 0.9637
Overfitting: 0.1039
Best model saved at epoch 1 with validation loss: 0.1112
[Epoch 2, Batch 100] loss: 0.11624129049479962
[Epoch 2, Batch 200] loss: 0.10583728683181107
[Epoch 2, Batch 300] loss: 0.11366364269517362
[Epoch 2, Batch 400] loss: 0.08477700133807957
[Epoch 2, Batch 500] loss: 0.0861991622671485
[Epoch 2, Batch 600] loss: 0.08915327510796488
[Epoch 2, Batch 700] loss: 0.0834014075435698
**STATS for Epoch 2** : 
Average training loss: 0.0053
Average validation loss: 0.0756
Validation Accuracy: 0.9762
Overfitting: 0.0703
Best model saved at epoch 2 with validation loss: 0.0756
[Epoch 3, Batch 100] loss: 0.0728574634110555
[Epoch 3, Batch 200] loss: 0.07312818938400596
[Epoch 3, Batch 300] loss: 0.06797434443607926
[Epoch 3, Batch 400] loss: 0.07226040092296898
[Epoch 3, Batch 500] loss: 0.057476687892340124
[Epoch 3, Batch 600] loss: 0.058259480544365944
[Epoch 3, Batch 700] loss: 0.06515210437821224
**STATS for Epoch 3** : 
Average training loss: 0.0037
Average validation loss: 0.0809
Validation Accuracy: 0.9753
Overfitting: 0.0771
[Epoch 4, Batch 100] loss: 0.04869696271140128
[Epoch 4, Batch 200] loss: 0.055028048311360184
[Epoch 4, Batch 300] loss: 0.04868098930688575
[Epoch 4, Batch 400] loss: 0.045025412410032
[Epoch 4, Batch 500] loss: 0.05799243672052398
[Epoch 4, Batch 600] loss: 0.061605903678573666
[Epoch 4, Batch 700] loss: 0.04354215298080817
**STATS for Epoch 4** : 
Average training loss: 0.0036
Average validation loss: 0.0567
Validation Accuracy: 0.9826
Overfitting: 0.0531
Best model saved at epoch 4 with validation loss: 0.0567
[Epoch 5, Batch 100] loss: 0.03808440945576876
[Epoch 5, Batch 200] loss: 0.04543084856588393
[Epoch 5, Batch 300] loss: 0.04341018235078081
[Epoch 5, Batch 400] loss: 0.0427805440290831
[Epoch 5, Batch 500] loss: 0.03970300891203806
[Epoch 5, Batch 600] loss: 0.038093611479271205
[Epoch 5, Batch 700] loss: 0.04001983648748137
**STATS for Epoch 5** : 
Average training loss: 0.0032
Average validation loss: 0.0703
Validation Accuracy: 0.9788
Overfitting: 0.0671
[Epoch 6, Batch 100] loss: 0.036624595925677565
[Epoch 6, Batch 200] loss: 0.032090335545362905
[Epoch 6, Batch 300] loss: 0.04006644224864431
[Epoch 6, Batch 400] loss: 0.03746925815823488
[Epoch 6, Batch 500] loss: 0.03045614973991178
[Epoch 6, Batch 600] loss: 0.03532165326294489
[Epoch 6, Batch 700] loss: 0.03646978739416227
**STATS for Epoch 6** : 
Average training loss: 0.0027
Average validation loss: 0.0532
Validation Accuracy: 0.9853
Overfitting: 0.0505
Best model saved at epoch 6 with validation loss: 0.0532
[Epoch 7, Batch 100] loss: 0.028977324422448873
[Epoch 7, Batch 200] loss: 0.02561643533234019
[Epoch 7, Batch 300] loss: 0.031605675672763026
[Epoch 7, Batch 400] loss: 0.02370971093303524
[Epoch 7, Batch 500] loss: 0.032399197376216764
[Epoch 7, Batch 600] loss: 0.028987134763156064
[Epoch 7, Batch 700] loss: 0.02815289038582705
**STATS for Epoch 7** : 
Average training loss: 0.0031
Average validation loss: 0.0549
Validation Accuracy: 0.9822
Overfitting: 0.0518
[Epoch 8, Batch 100] loss: 0.021820381075958722
[Epoch 8, Batch 200] loss: 0.027916325704427435
[Epoch 8, Batch 300] loss: 0.026276887258281933
[Epoch 8, Batch 400] loss: 0.020703096570796335
[Epoch 8, Batch 500] loss: 0.02880484281835379
[Epoch 8, Batch 600] loss: 0.027754374970681964
[Epoch 8, Batch 700] loss: 0.03013907118845964
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0430
Validation Accuracy: 0.9862
Overfitting: 0.0411
Best model saved at epoch 8 with validation loss: 0.0430
[Epoch 9, Batch 100] loss: 0.02244810231786687
[Epoch 9, Batch 200] loss: 0.015073913131200243
[Epoch 9, Batch 300] loss: 0.017669264897122047
[Epoch 9, Batch 400] loss: 0.019314112588763237
[Epoch 9, Batch 500] loss: 0.025459152976982296
[Epoch 9, Batch 600] loss: 0.019151907578052487
[Epoch 9, Batch 700] loss: 0.02735409395332681
**STATS for Epoch 9** : 
Average training loss: 0.0018
Average validation loss: 0.0449
Validation Accuracy: 0.9868
Overfitting: 0.0431
[Epoch 10, Batch 100] loss: 0.01536678929172922
[Epoch 10, Batch 200] loss: 0.021129760537587573
[Epoch 10, Batch 300] loss: 0.017246780581772328
[Epoch 10, Batch 400] loss: 0.022794644620153123
[Epoch 10, Batch 500] loss: 0.018044696400975228
[Epoch 10, Batch 600] loss: 0.023452538300189188
[Epoch 10, Batch 700] loss: 0.02269281927496195
**STATS for Epoch 10** : 
Average training loss: 0.0015
Average validation loss: 0.0476
Validation Accuracy: 0.9864
Overfitting: 0.0461
[Epoch 11, Batch 100] loss: 0.015429870580264833
[Epoch 11, Batch 200] loss: 0.015712991434556896
[Epoch 11, Batch 300] loss: 0.013664962037073564
[Epoch 11, Batch 400] loss: 0.0153850141869043
[Epoch 11, Batch 500] loss: 0.013504479517432628
[Epoch 11, Batch 600] loss: 0.016740413513034583
[Epoch 11, Batch 700] loss: 0.020810585811850614
**STATS for Epoch 11** : 
Average training loss: 0.0018
Average validation loss: 0.0462
Validation Accuracy: 0.9868
Overfitting: 0.0444
[Epoch 12, Batch 100] loss: 0.01230930626988993
[Epoch 12, Batch 200] loss: 0.01082822447817307
[Epoch 12, Batch 300] loss: 0.009512561064766487
[Epoch 12, Batch 400] loss: 0.008034304619941394
[Epoch 12, Batch 500] loss: 0.019191787093295717
[Epoch 12, Batch 600] loss: 0.019712011307128706
[Epoch 12, Batch 700] loss: 0.017819320593844168
**STATS for Epoch 12** : 
Average training loss: 0.0017
Average validation loss: 0.0521
Validation Accuracy: 0.9858
Overfitting: 0.0504
[Epoch 13, Batch 100] loss: 0.010947712812194367
[Epoch 13, Batch 200] loss: 0.009182054025222897
[Epoch 13, Batch 300] loss: 0.017477440617221875
[Epoch 13, Batch 400] loss: 0.010993282451236154
[Epoch 13, Batch 500] loss: 0.013211107642964634
[Epoch 13, Batch 600] loss: 0.013559688163950341
[Epoch 13, Batch 700] loss: 0.009230215388379292
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0501
Validation Accuracy: 0.9884
Overfitting: 0.0491
[Epoch 14, Batch 100] loss: 0.00951551103615202
[Epoch 14, Batch 200] loss: 0.010899955274344392
[Epoch 14, Batch 300] loss: 0.011600300524951307
[Epoch 14, Batch 400] loss: 0.0077869817696046085
[Epoch 14, Batch 500] loss: 0.012396756823800387
[Epoch 14, Batch 600] loss: 0.012545949543819006
[Epoch 14, Batch 700] loss: 0.011012705037865089
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0461
Validation Accuracy: 0.9886
Overfitting: 0.0454
[Epoch 15, Batch 100] loss: 0.006223800371226389
[Epoch 15, Batch 200] loss: 0.008863717730127974
[Epoch 15, Batch 300] loss: 0.008943891644812539
[Epoch 15, Batch 400] loss: 0.006044745034014341
[Epoch 15, Batch 500] loss: 0.006956519220620976
[Epoch 15, Batch 600] loss: 0.0066464681205616214
[Epoch 15, Batch 700] loss: 0.010398658883714234
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0490
Validation Accuracy: 0.9878
Overfitting: 0.0486
[Epoch 16, Batch 100] loss: 0.006908000811345119
[Epoch 16, Batch 200] loss: 0.0066378701760913825
[Epoch 16, Batch 300] loss: 0.00731478208432236
[Epoch 16, Batch 400] loss: 0.007080972568655852
[Epoch 16, Batch 500] loss: 0.004011394560184272
[Epoch 16, Batch 600] loss: 0.013569472803210374
[Epoch 16, Batch 700] loss: 0.015463217057758811
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0481
Validation Accuracy: 0.9880
Overfitting: 0.0472
[Epoch 17, Batch 100] loss: 0.008372377921350562
[Epoch 17, Batch 200] loss: 0.009238446988547366
[Epoch 17, Batch 300] loss: 0.005104980133692152
[Epoch 17, Batch 400] loss: 0.005717366558874346
[Epoch 17, Batch 500] loss: 0.005978737612531404
[Epoch 17, Batch 600] loss: 0.005802708815062943
[Epoch 17, Batch 700] loss: 0.00966678972930822
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0506
Validation Accuracy: 0.9865
Overfitting: 0.0496
[Epoch 18, Batch 100] loss: 0.004072129777232476
[Epoch 18, Batch 200] loss: 0.006088413371453498
[Epoch 18, Batch 300] loss: 0.0058337274864970826
[Epoch 18, Batch 400] loss: 0.0063941750795493135
[Epoch 18, Batch 500] loss: 0.005044480077212938
[Epoch 18, Batch 600] loss: 0.004904431142349495
[Epoch 18, Batch 700] loss: 0.01063623421603097
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0575
Validation Accuracy: 0.9863
Overfitting: 0.0568
[Epoch 19, Batch 100] loss: 0.005891128379080329
[Epoch 19, Batch 200] loss: 0.0028808653545456765
[Epoch 19, Batch 300] loss: 0.006889091424927756
[Epoch 19, Batch 400] loss: 0.011255239183956291
[Epoch 19, Batch 500] loss: 0.00646522897257455
[Epoch 19, Batch 600] loss: 0.006762866677199782
[Epoch 19, Batch 700] loss: 0.004827147025134764
**STATS for Epoch 19** : 
Average training loss: 0.0009
Average validation loss: 0.0537
Validation Accuracy: 0.9878
Overfitting: 0.0528
[Epoch 20, Batch 100] loss: 0.0069105321947427
[Epoch 20, Batch 200] loss: 0.005765690584503318
[Epoch 20, Batch 300] loss: 0.0038096276016221964
[Epoch 20, Batch 400] loss: 0.0059192494019771405
[Epoch 20, Batch 500] loss: 0.0050936753122186925
[Epoch 20, Batch 600] loss: 0.0024311723663413432
[Epoch 20, Batch 700] loss: 0.004495287373874817
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0553
Validation Accuracy: 0.9882
Overfitting: 0.0552
[Epoch 21, Batch 100] loss: 0.002313322243253424
[Epoch 21, Batch 200] loss: 0.0028460020350939887
[Epoch 21, Batch 300] loss: 0.0016437038384810876
[Epoch 21, Batch 400] loss: 0.0032246982848027983
[Epoch 21, Batch 500] loss: 0.002992146203559969
[Epoch 21, Batch 600] loss: 0.00217908204575906
[Epoch 21, Batch 700] loss: 0.00308130782749231
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0488
Validation Accuracy: 0.9896
Overfitting: 0.0485
[Epoch 22, Batch 100] loss: 0.0007327691198679531
[Epoch 22, Batch 200] loss: 0.0006780860458275128
[Epoch 22, Batch 300] loss: 0.0027779007336584984
[Epoch 22, Batch 400] loss: 0.002509864679934708
[Epoch 22, Batch 500] loss: 0.0010559214500585768
[Epoch 22, Batch 600] loss: 0.0025981323957785206
[Epoch 22, Batch 700] loss: 0.0037522104666822998
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0515
Validation Accuracy: 0.9888
Overfitting: 0.0514
[Epoch 23, Batch 100] loss: 0.0010812477067634063
[Epoch 23, Batch 200] loss: 0.0014894121554107187
[Epoch 23, Batch 300] loss: 0.0017181163273971834
[Epoch 23, Batch 400] loss: 0.0008890946577548675
[Epoch 23, Batch 500] loss: 0.00043761731212271115
[Epoch 23, Batch 600] loss: 0.0010618901301450024
[Epoch 23, Batch 700] loss: 0.0006992109095875776
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0504
Validation Accuracy: 0.9898
Overfitting: 0.0503
[Epoch 24, Batch 100] loss: 0.0005223297338591237
[Epoch 24, Batch 200] loss: 0.00037017031766140463
[Epoch 24, Batch 300] loss: 0.0007593687832650176
[Epoch 24, Batch 400] loss: 0.0003773658002762659
[Epoch 24, Batch 500] loss: 0.0005818641801306513
[Epoch 24, Batch 600] loss: 0.00037810211788610106
[Epoch 24, Batch 700] loss: 0.0006577463197140787
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0564
Validation Accuracy: 0.9892
Overfitting: 0.0563
Fold 4 validation loss: 0.0564
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2689944338798522
[Epoch 1, Batch 200] loss: 1.1315719172358514
[Epoch 1, Batch 300] loss: 0.3588919911533594
[Epoch 1, Batch 400] loss: 0.24050154320895673
[Epoch 1, Batch 500] loss: 0.1707208815589547
[Epoch 1, Batch 600] loss: 0.15896906428039073
[Epoch 1, Batch 700] loss: 0.13407737132161857
**STATS for Epoch 1** : 
Average training loss: 0.0083
Average validation loss: 0.1138
Validation Accuracy: 0.9654
Overfitting: 0.1056
Best model saved at epoch 1 with validation loss: 0.1138
[Epoch 2, Batch 100] loss: 0.09978163681924343
[Epoch 2, Batch 200] loss: 0.09994905830360949
[Epoch 2, Batch 300] loss: 0.09735986586660146
[Epoch 2, Batch 400] loss: 0.08552464079577476
[Epoch 2, Batch 500] loss: 0.09410531815141439
[Epoch 2, Batch 600] loss: 0.08278103270567953
[Epoch 2, Batch 700] loss: 0.08909954031929374
**STATS for Epoch 2** : 
Average training loss: 0.0058
Average validation loss: 0.0879
Validation Accuracy: 0.9739
Overfitting: 0.0821
Best model saved at epoch 2 with validation loss: 0.0879
[Epoch 3, Batch 100] loss: 0.06600364726036786
[Epoch 3, Batch 200] loss: 0.058567173578776416
[Epoch 3, Batch 300] loss: 0.06732035622000694
[Epoch 3, Batch 400] loss: 0.060097123810555785
[Epoch 3, Batch 500] loss: 0.06348658402916044
[Epoch 3, Batch 600] loss: 0.06184450683183968
[Epoch 3, Batch 700] loss: 0.06929612611187622
**STATS for Epoch 3** : 
Average training loss: 0.0029
Average validation loss: 0.0658
Validation Accuracy: 0.9816
Overfitting: 0.0628
Best model saved at epoch 3 with validation loss: 0.0658
[Epoch 4, Batch 100] loss: 0.05282346320571378
[Epoch 4, Batch 200] loss: 0.039260587077587845
[Epoch 4, Batch 300] loss: 0.05208847064059228
[Epoch 4, Batch 400] loss: 0.056784298138227315
[Epoch 4, Batch 500] loss: 0.04429351131664589
[Epoch 4, Batch 600] loss: 0.057459891778416934
[Epoch 4, Batch 700] loss: 0.037092248467961324
**STATS for Epoch 4** : 
Average training loss: 0.0031
Average validation loss: 0.0530
Validation Accuracy: 0.9844
Overfitting: 0.0498
Best model saved at epoch 4 with validation loss: 0.0530
[Epoch 5, Batch 100] loss: 0.03407143620541319
[Epoch 5, Batch 200] loss: 0.03468977573676966
[Epoch 5, Batch 300] loss: 0.037884042765945196
[Epoch 5, Batch 400] loss: 0.036935577340191234
[Epoch 5, Batch 500] loss: 0.04370301188668236
[Epoch 5, Batch 600] loss: 0.041064905448583884
[Epoch 5, Batch 700] loss: 0.03383263910422102
**STATS for Epoch 5** : 
Average training loss: 0.0023
Average validation loss: 0.0618
Validation Accuracy: 0.9827
Overfitting: 0.0595
[Epoch 6, Batch 100] loss: 0.03131362846004777
[Epoch 6, Batch 200] loss: 0.0265578638354782
[Epoch 6, Batch 300] loss: 0.0265523932070937
[Epoch 6, Batch 400] loss: 0.031188883796567098
[Epoch 6, Batch 500] loss: 0.03865187938208692
[Epoch 6, Batch 600] loss: 0.03572053327399772
[Epoch 6, Batch 700] loss: 0.03157284752232954
**STATS for Epoch 6** : 
Average training loss: 0.0018
Average validation loss: 0.0513
Validation Accuracy: 0.9844
Overfitting: 0.0495
Best model saved at epoch 6 with validation loss: 0.0513
[Epoch 7, Batch 100] loss: 0.022265579194645398
[Epoch 7, Batch 200] loss: 0.019752583965309895
[Epoch 7, Batch 300] loss: 0.03184057853010017
[Epoch 7, Batch 400] loss: 0.027069195075309836
[Epoch 7, Batch 500] loss: 0.02384093762579141
[Epoch 7, Batch 600] loss: 0.029432021753746086
[Epoch 7, Batch 700] loss: 0.030674617962213234
**STATS for Epoch 7** : 
Average training loss: 0.0017
Average validation loss: 0.0402
Validation Accuracy: 0.9879
Overfitting: 0.0386
Best model saved at epoch 7 with validation loss: 0.0402
[Epoch 8, Batch 100] loss: 0.018936985772597836
[Epoch 8, Batch 200] loss: 0.021653239162696993
[Epoch 8, Batch 300] loss: 0.020627000780659727
[Epoch 8, Batch 400] loss: 0.026769547976728064
[Epoch 8, Batch 500] loss: 0.021110314239631407
[Epoch 8, Batch 600] loss: 0.029844563917140476
[Epoch 8, Batch 700] loss: 0.026044256433087866
**STATS for Epoch 8** : 
Average training loss: 0.0014
Average validation loss: 0.0430
Validation Accuracy: 0.9878
Overfitting: 0.0415
[Epoch 9, Batch 100] loss: 0.01587001150328433
[Epoch 9, Batch 200] loss: 0.018607655107916798
[Epoch 9, Batch 300] loss: 0.015405551231960999
[Epoch 9, Batch 400] loss: 0.02029882710427046
[Epoch 9, Batch 500] loss: 0.021344104301533662
[Epoch 9, Batch 600] loss: 0.016342101699265185
[Epoch 9, Batch 700] loss: 0.022975505325885024
**STATS for Epoch 9** : 
Average training loss: 0.0013
Average validation loss: 0.0453
Validation Accuracy: 0.9871
Overfitting: 0.0441
[Epoch 10, Batch 100] loss: 0.015029938090156065
[Epoch 10, Batch 200] loss: 0.010563680559134809
[Epoch 10, Batch 300] loss: 0.013704123109491775
[Epoch 10, Batch 400] loss: 0.020513355387374758
[Epoch 10, Batch 500] loss: 0.01476065555936657
[Epoch 10, Batch 600] loss: 0.016920055849768686
[Epoch 10, Batch 700] loss: 0.019834095183759927
**STATS for Epoch 10** : 
Average training loss: 0.0011
Average validation loss: 0.0548
Validation Accuracy: 0.9847
Overfitting: 0.0537
[Epoch 11, Batch 100] loss: 0.014583169279794674
[Epoch 11, Batch 200] loss: 0.0104881869982637
[Epoch 11, Batch 300] loss: 0.01423407863258035
[Epoch 11, Batch 400] loss: 0.016263907758402637
[Epoch 11, Batch 500] loss: 0.016926943186845164
[Epoch 11, Batch 600] loss: 0.017757363464770606
[Epoch 11, Batch 700] loss: 0.0198650001414353
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0453
Validation Accuracy: 0.9882
Overfitting: 0.0443
[Epoch 12, Batch 100] loss: 0.009507171952427597
[Epoch 12, Batch 200] loss: 0.012619308557186742
[Epoch 12, Batch 300] loss: 0.008482862272066995
[Epoch 12, Batch 400] loss: 0.009291440146625973
[Epoch 12, Batch 500] loss: 0.01043804140532302
[Epoch 12, Batch 600] loss: 0.011066344492137432
[Epoch 12, Batch 700] loss: 0.014702928442857229
**STATS for Epoch 12** : 
Average training loss: 0.0009
Average validation loss: 0.0445
Validation Accuracy: 0.9882
Overfitting: 0.0436
[Epoch 13, Batch 100] loss: 0.009800916112581035
[Epoch 13, Batch 200] loss: 0.008233142891767783
[Epoch 13, Batch 300] loss: 0.010534342546488915
[Epoch 13, Batch 400] loss: 0.012030322415812407
[Epoch 13, Batch 500] loss: 0.011999597352842102
[Epoch 13, Batch 600] loss: 0.012514008253965585
[Epoch 13, Batch 700] loss: 0.013142220407899004
**STATS for Epoch 13** : 
Average training loss: 0.0004
Average validation loss: 0.0397
Validation Accuracy: 0.9894
Overfitting: 0.0393
Best model saved at epoch 13 with validation loss: 0.0397
[Epoch 14, Batch 100] loss: 0.005931506066517613
[Epoch 14, Batch 200] loss: 0.00511673429144139
[Epoch 14, Batch 300] loss: 0.007092932142986683
[Epoch 14, Batch 400] loss: 0.008346474347781623
[Epoch 14, Batch 500] loss: 0.008343970351997996
[Epoch 14, Batch 600] loss: 0.011417016064460767
[Epoch 14, Batch 700] loss: 0.012532291081151925
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0439
Validation Accuracy: 0.9886
Overfitting: 0.0432
[Epoch 15, Batch 100] loss: 0.006787123973626876
[Epoch 15, Batch 200] loss: 0.005347782962526253
[Epoch 15, Batch 300] loss: 0.010909443771015503
[Epoch 15, Batch 400] loss: 0.005692835159861715
[Epoch 15, Batch 500] loss: 0.006834467181979562
[Epoch 15, Batch 600] loss: 0.008980760795911919
[Epoch 15, Batch 700] loss: 0.009473905948507309
**STATS for Epoch 15** : 
Average training loss: 0.0003
Average validation loss: 0.0447
Validation Accuracy: 0.9882
Overfitting: 0.0444
[Epoch 16, Batch 100] loss: 0.004678818776956178
[Epoch 16, Batch 200] loss: 0.004367437936416536
[Epoch 16, Batch 300] loss: 0.006290995302770171
[Epoch 16, Batch 400] loss: 0.004280773856953602
[Epoch 16, Batch 500] loss: 0.00431634347378349
[Epoch 16, Batch 600] loss: 0.008536881230265863
[Epoch 16, Batch 700] loss: 0.0067091274937411075
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0478
Validation Accuracy: 0.9887
Overfitting: 0.0472
[Epoch 17, Batch 100] loss: 0.004509344750385935
[Epoch 17, Batch 200] loss: 0.004562920148200647
[Epoch 17, Batch 300] loss: 0.004043432965618194
[Epoch 17, Batch 400] loss: 0.004479312482581008
[Epoch 17, Batch 500] loss: 0.0037654061728153465
[Epoch 17, Batch 600] loss: 0.007414401039886798
[Epoch 17, Batch 700] loss: 0.009493579265545123
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0520
Validation Accuracy: 0.9882
Overfitting: 0.0512
[Epoch 18, Batch 100] loss: 0.006186615164533577
[Epoch 18, Batch 200] loss: 0.0039032910012610955
[Epoch 18, Batch 300] loss: 0.004362761119245988
[Epoch 18, Batch 400] loss: 0.004361840241526807
[Epoch 18, Batch 500] loss: 0.005828135133870091
[Epoch 18, Batch 600] loss: 0.00478096769140393
[Epoch 18, Batch 700] loss: 0.006137401613241309
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0518
Validation Accuracy: 0.9878
Overfitting: 0.0514
[Epoch 19, Batch 100] loss: 0.005137696800065896
[Epoch 19, Batch 200] loss: 0.004450634864351741
[Epoch 19, Batch 300] loss: 0.0019856346770939126
[Epoch 19, Batch 400] loss: 0.003995458611716458
[Epoch 19, Batch 500] loss: 0.004375740116702218
[Epoch 19, Batch 600] loss: 0.004500029566838748
[Epoch 19, Batch 700] loss: 0.002976621861334934
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0485
Validation Accuracy: 0.9883
Overfitting: 0.0484
[Epoch 20, Batch 100] loss: 0.0027938957462538385
[Epoch 20, Batch 200] loss: 0.0011463557419529025
[Epoch 20, Batch 300] loss: 0.002146599936736493
[Epoch 20, Batch 400] loss: 0.0015908828240571893
[Epoch 20, Batch 500] loss: 0.0031876267755478692
[Epoch 20, Batch 600] loss: 0.006463634046067455
[Epoch 20, Batch 700] loss: 0.0046849736778222
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0503
Validation Accuracy: 0.9884
Overfitting: 0.0500
[Epoch 21, Batch 100] loss: 0.002809188058613472
[Epoch 21, Batch 200] loss: 0.007200132152793231
[Epoch 21, Batch 300] loss: 0.006456760802248027
[Epoch 21, Batch 400] loss: 0.001640368971739008
[Epoch 21, Batch 500] loss: 0.0027375193831994694
[Epoch 21, Batch 600] loss: 0.00497406784128998
[Epoch 21, Batch 700] loss: 0.005281918269861308
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0479
Validation Accuracy: 0.9899
Overfitting: 0.0476
[Epoch 22, Batch 100] loss: 0.004152845814642206
[Epoch 22, Batch 200] loss: 0.0053121967351762575
[Epoch 22, Batch 300] loss: 0.0038701295698137985
[Epoch 22, Batch 400] loss: 0.002739037683479637
[Epoch 22, Batch 500] loss: 0.0034651738553748146
[Epoch 22, Batch 600] loss: 0.005466141033757595
[Epoch 22, Batch 700] loss: 0.01068202016750547
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0532
Validation Accuracy: 0.9890
Overfitting: 0.0529
[Epoch 23, Batch 100] loss: 0.005859818365415777
[Epoch 23, Batch 200] loss: 0.0022725899852866858
[Epoch 23, Batch 300] loss: 0.0026752659585145013
[Epoch 23, Batch 400] loss: 0.003973511956419315
[Epoch 23, Batch 500] loss: 0.002350021590827964
[Epoch 23, Batch 600] loss: 0.0026723839134774607
[Epoch 23, Batch 700] loss: 0.003051980865875521
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0527
Validation Accuracy: 0.9893
Overfitting: 0.0526
[Epoch 24, Batch 100] loss: 0.001990289799932725
[Epoch 24, Batch 200] loss: 0.0018435180540018338
[Epoch 24, Batch 300] loss: 0.0022202103126892324
[Epoch 24, Batch 400] loss: 0.00104247518334887
[Epoch 24, Batch 500] loss: 0.0012227385811581825
[Epoch 24, Batch 600] loss: 0.0011626051478879163
[Epoch 24, Batch 700] loss: 0.002360460061104277
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0495
Validation Accuracy: 0.9896
Overfitting: 0.0494
Fold 5 validation loss: 0.0495
Mean validation loss across all folds for Trial 19 is 0.0547 with trial config:  l1: 256, l2: 64, lr: 0.00492813613804113, batch_size: 64
[I 2024-12-11 04:50:44,590] Trial 18 finished with value: 0.05474166419906703 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.00492813613804113, 'batch_size': 64}. Best is trial 2 with value: 0.05047263894358398.

Selected Hyperparameters for Trial 20:
  l1: 256, l2: 64, lr: 0.0008094764402330428, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2981011486053466
[Epoch 1, Batch 200] loss: 2.2744020771980287
[Epoch 1, Batch 300] loss: 2.2238425612449646
[Epoch 1, Batch 400] loss: 2.042774068117142
[Epoch 1, Batch 500] loss: 1.303081402182579
[Epoch 1, Batch 600] loss: 0.6123950038850308
[Epoch 1, Batch 700] loss: 0.48623140588402747
[Epoch 1, Batch 800] loss: 0.382499952763319
[Epoch 1, Batch 900] loss: 0.3506800243258476
[Epoch 1, Batch 1000] loss: 0.3224202337861061
[Epoch 1, Batch 1100] loss: 0.3172642241418362
[Epoch 1, Batch 1200] loss: 0.2618363642692566
[Epoch 1, Batch 1300] loss: 0.2797888921946287
[Epoch 1, Batch 1400] loss: 0.28063235484063626
[Epoch 1, Batch 1500] loss: 0.22720890410244465
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2270
Validation Accuracy: 0.9320
Overfitting: 0.2270
Best model saved at epoch 1 with validation loss: 0.2270
[Epoch 2, Batch 100] loss: 0.2088407330028713
[Epoch 2, Batch 200] loss: 0.19059901339933277
[Epoch 2, Batch 300] loss: 0.18364708922803402
[Epoch 2, Batch 400] loss: 0.1897440021112561
[Epoch 2, Batch 500] loss: 0.177135591506958
[Epoch 2, Batch 600] loss: 0.18063563397154211
[Epoch 2, Batch 700] loss: 0.1805245342850685
[Epoch 2, Batch 800] loss: 0.145245973020792
[Epoch 2, Batch 900] loss: 0.15602207273244859
[Epoch 2, Batch 1000] loss: 0.16263011218979956
[Epoch 2, Batch 1100] loss: 0.1384061524644494
[Epoch 2, Batch 1200] loss: 0.13170463769230992
[Epoch 2, Batch 1300] loss: 0.12880366175435484
[Epoch 2, Batch 1400] loss: 0.13776584374718367
[Epoch 2, Batch 1500] loss: 0.12153675811365247
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1365
Validation Accuracy: 0.9567
Overfitting: 0.1365
Best model saved at epoch 2 with validation loss: 0.1365
[Epoch 3, Batch 100] loss: 0.11907107837498188
[Epoch 3, Batch 200] loss: 0.10950659902766346
[Epoch 3, Batch 300] loss: 0.12046811563894153
[Epoch 3, Batch 400] loss: 0.10213463540188968
[Epoch 3, Batch 500] loss: 0.12541026669554411
[Epoch 3, Batch 600] loss: 0.1074072974640876
[Epoch 3, Batch 700] loss: 0.105974883409217
[Epoch 3, Batch 800] loss: 0.1244710691832006
[Epoch 3, Batch 900] loss: 0.10183341960422694
[Epoch 3, Batch 1000] loss: 0.12173390292562544
[Epoch 3, Batch 1100] loss: 0.11233339714817703
[Epoch 3, Batch 1200] loss: 0.10219780695158988
[Epoch 3, Batch 1300] loss: 0.09520068695768714
[Epoch 3, Batch 1400] loss: 0.08136161791160702
[Epoch 3, Batch 1500] loss: 0.09702348542166873
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0942
Validation Accuracy: 0.9700
Overfitting: 0.0942
Best model saved at epoch 3 with validation loss: 0.0942
[Epoch 4, Batch 100] loss: 0.0797937102848664
[Epoch 4, Batch 200] loss: 0.08775205568876117
[Epoch 4, Batch 300] loss: 0.07516737415455282
[Epoch 4, Batch 400] loss: 0.09370629121549427
[Epoch 4, Batch 500] loss: 0.0928171201236546
[Epoch 4, Batch 600] loss: 0.09351706319022923
[Epoch 4, Batch 700] loss: 0.08800128036178649
[Epoch 4, Batch 800] loss: 0.0870896181743592
[Epoch 4, Batch 900] loss: 0.07771864627487958
[Epoch 4, Batch 1000] loss: 0.07560315639246255
[Epoch 4, Batch 1100] loss: 0.07318053595605306
[Epoch 4, Batch 1200] loss: 0.08880578178912402
[Epoch 4, Batch 1300] loss: 0.10084702637977898
[Epoch 4, Batch 1400] loss: 0.08020379453897476
[Epoch 4, Batch 1500] loss: 0.06605555278249085
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0756
Validation Accuracy: 0.9775
Overfitting: 0.0756
Best model saved at epoch 4 with validation loss: 0.0756
[Epoch 5, Batch 100] loss: 0.06963339701294899
[Epoch 5, Batch 200] loss: 0.07108142422512173
[Epoch 5, Batch 300] loss: 0.07356311948504299
[Epoch 5, Batch 400] loss: 0.07621335188858211
[Epoch 5, Batch 500] loss: 0.0730531330499798
[Epoch 5, Batch 600] loss: 0.057964979810640214
[Epoch 5, Batch 700] loss: 0.06463301703799516
[Epoch 5, Batch 800] loss: 0.06867977562127635
[Epoch 5, Batch 900] loss: 0.07339225043193437
[Epoch 5, Batch 1000] loss: 0.06467949640238657
[Epoch 5, Batch 1100] loss: 0.06725588153349235
[Epoch 5, Batch 1200] loss: 0.05731910637812689
[Epoch 5, Batch 1300] loss: 0.06652946734102443
[Epoch 5, Batch 1400] loss: 0.06968083533924073
[Epoch 5, Batch 1500] loss: 0.07365179531276227
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9794
Overfitting: 0.0630
Best model saved at epoch 5 with validation loss: 0.0630
[Epoch 6, Batch 100] loss: 0.07319700499530882
[Epoch 6, Batch 200] loss: 0.05755688549252227
[Epoch 6, Batch 300] loss: 0.06108553383150138
[Epoch 6, Batch 400] loss: 0.052434415293391795
[Epoch 6, Batch 500] loss: 0.05261296820943244
[Epoch 6, Batch 600] loss: 0.06621667062223423
[Epoch 6, Batch 700] loss: 0.0675548983970657
[Epoch 6, Batch 800] loss: 0.04806326456251554
[Epoch 6, Batch 900] loss: 0.06393057559849695
[Epoch 6, Batch 1000] loss: 0.05517027402180247
[Epoch 6, Batch 1100] loss: 0.05226110948249698
[Epoch 6, Batch 1200] loss: 0.05370799319120124
[Epoch 6, Batch 1300] loss: 0.045293653709813954
[Epoch 6, Batch 1400] loss: 0.06779304382158444
[Epoch 6, Batch 1500] loss: 0.062126568446401506
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0566
Validation Accuracy: 0.9822
Overfitting: 0.0566
Best model saved at epoch 6 with validation loss: 0.0566
[Epoch 7, Batch 100] loss: 0.05506613126490265
[Epoch 7, Batch 200] loss: 0.0416013594227843
[Epoch 7, Batch 300] loss: 0.05268814472714439
[Epoch 7, Batch 400] loss: 0.053905140217393635
[Epoch 7, Batch 500] loss: 0.05154077231884003
[Epoch 7, Batch 600] loss: 0.058849641317501665
[Epoch 7, Batch 700] loss: 0.039617490619421006
[Epoch 7, Batch 800] loss: 0.04573811848065816
[Epoch 7, Batch 900] loss: 0.041380741192260755
[Epoch 7, Batch 1000] loss: 0.05295018148783129
[Epoch 7, Batch 1100] loss: 0.06078087423462421
[Epoch 7, Batch 1200] loss: 0.06347389358328655
[Epoch 7, Batch 1300] loss: 0.050973973560612645
[Epoch 7, Batch 1400] loss: 0.056742978096590374
[Epoch 7, Batch 1500] loss: 0.056496532163000664
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0600
Validation Accuracy: 0.9812
Overfitting: 0.0600
[Epoch 8, Batch 100] loss: 0.035710737963672724
[Epoch 8, Batch 200] loss: 0.05353938172687776
[Epoch 8, Batch 300] loss: 0.046612536744214596
[Epoch 8, Batch 400] loss: 0.03594084474025294
[Epoch 8, Batch 500] loss: 0.04576173711218871
[Epoch 8, Batch 600] loss: 0.041478622738504785
[Epoch 8, Batch 700] loss: 0.054767862467560914
[Epoch 8, Batch 800] loss: 0.04643460520717781
[Epoch 8, Batch 900] loss: 0.04572373391245492
[Epoch 8, Batch 1000] loss: 0.053626000095391646
[Epoch 8, Batch 1100] loss: 0.04384682616218925
[Epoch 8, Batch 1200] loss: 0.047698103577131404
[Epoch 8, Batch 1300] loss: 0.04815493446192704
[Epoch 8, Batch 1400] loss: 0.0466074715659488
[Epoch 8, Batch 1500] loss: 0.0486554522253573
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0642
Validation Accuracy: 0.9796
Overfitting: 0.0642
[Epoch 9, Batch 100] loss: 0.04458836932783015
[Epoch 9, Batch 200] loss: 0.03750104867154733
[Epoch 9, Batch 300] loss: 0.04279279347800184
[Epoch 9, Batch 400] loss: 0.03512046466872562
[Epoch 9, Batch 500] loss: 0.04520043287891894
[Epoch 9, Batch 600] loss: 0.04398632786935195
[Epoch 9, Batch 700] loss: 0.034952405520598404
[Epoch 9, Batch 800] loss: 0.043918368353042754
[Epoch 9, Batch 900] loss: 0.046340811687987295
[Epoch 9, Batch 1000] loss: 0.0418312555848388
[Epoch 9, Batch 1100] loss: 0.04186931322328746
[Epoch 9, Batch 1200] loss: 0.03487916354846675
[Epoch 9, Batch 1300] loss: 0.05234363073832356
[Epoch 9, Batch 1400] loss: 0.04069963964924682
[Epoch 9, Batch 1500] loss: 0.0376732351211831
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9836
Overfitting: 0.0508
Best model saved at epoch 9 with validation loss: 0.0508
[Epoch 10, Batch 100] loss: 0.035285488156368956
[Epoch 10, Batch 200] loss: 0.037424505214439706
[Epoch 10, Batch 300] loss: 0.03789127705036663
[Epoch 10, Batch 400] loss: 0.029386008499423043
[Epoch 10, Batch 500] loss: 0.03787724766298197
[Epoch 10, Batch 600] loss: 0.039742404550197535
[Epoch 10, Batch 700] loss: 0.03144599028280936
[Epoch 10, Batch 800] loss: 0.037741610860684886
[Epoch 10, Batch 900] loss: 0.04949210255232174
[Epoch 10, Batch 1000] loss: 0.025665743689169174
[Epoch 10, Batch 1100] loss: 0.04967948958568741
[Epoch 10, Batch 1200] loss: 0.03536187549238093
[Epoch 10, Batch 1300] loss: 0.03448979881504784
[Epoch 10, Batch 1400] loss: 0.04229916150332429
[Epoch 10, Batch 1500] loss: 0.040367703173542394
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9846
Overfitting: 0.0497
Best model saved at epoch 10 with validation loss: 0.0497
[Epoch 11, Batch 100] loss: 0.03886336105584633
[Epoch 11, Batch 200] loss: 0.026568738564965316
[Epoch 11, Batch 300] loss: 0.03854869175644126
[Epoch 11, Batch 400] loss: 0.03535803397011478
[Epoch 11, Batch 500] loss: 0.039223678117850796
[Epoch 11, Batch 600] loss: 0.02951264919596724
[Epoch 11, Batch 700] loss: 0.024610966318286954
[Epoch 11, Batch 800] loss: 0.032363802054605914
[Epoch 11, Batch 900] loss: 0.033846691062208265
[Epoch 11, Batch 1000] loss: 0.038321661849622615
[Epoch 11, Batch 1100] loss: 0.03089996576862177
[Epoch 11, Batch 1200] loss: 0.03581074924208224
[Epoch 11, Batch 1300] loss: 0.03462439881870523
[Epoch 11, Batch 1400] loss: 0.032544193376088514
[Epoch 11, Batch 1500] loss: 0.03155295873439172
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9855
Overfitting: 0.0491
Best model saved at epoch 11 with validation loss: 0.0491
[Epoch 12, Batch 100] loss: 0.027902508780243807
[Epoch 12, Batch 200] loss: 0.03203957061923575
[Epoch 12, Batch 300] loss: 0.024316668667306657
[Epoch 12, Batch 400] loss: 0.03172023264982272
[Epoch 12, Batch 500] loss: 0.029371409057930578
[Epoch 12, Batch 600] loss: 0.029487298714084318
[Epoch 12, Batch 700] loss: 0.0276354991144035
[Epoch 12, Batch 800] loss: 0.027286202037357724
[Epoch 12, Batch 900] loss: 0.03223065589379985
[Epoch 12, Batch 1000] loss: 0.026237612058466767
[Epoch 12, Batch 1100] loss: 0.0320322995033348
[Epoch 12, Batch 1200] loss: 0.034170155237952714
[Epoch 12, Batch 1300] loss: 0.03574113558745012
[Epoch 12, Batch 1400] loss: 0.040336538277333606
[Epoch 12, Batch 1500] loss: 0.02785617743851617
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9864
Overfitting: 0.0445
Best model saved at epoch 12 with validation loss: 0.0445
[Epoch 13, Batch 100] loss: 0.021665633067314047
[Epoch 13, Batch 200] loss: 0.03105715832207352
[Epoch 13, Batch 300] loss: 0.03426520070293918
[Epoch 13, Batch 400] loss: 0.032882186210190414
[Epoch 13, Batch 500] loss: 0.022463551478867885
[Epoch 13, Batch 600] loss: 0.018141334330139217
[Epoch 13, Batch 700] loss: 0.02411247998912586
[Epoch 13, Batch 800] loss: 0.027513458891480696
[Epoch 13, Batch 900] loss: 0.028084331948775798
[Epoch 13, Batch 1000] loss: 0.03625387650979974
[Epoch 13, Batch 1100] loss: 0.031345138764590955
[Epoch 13, Batch 1200] loss: 0.0256442206617794
[Epoch 13, Batch 1300] loss: 0.02259325188730145
[Epoch 13, Batch 1400] loss: 0.032539474667573814
[Epoch 13, Batch 1500] loss: 0.041306269753549715
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9870
Overfitting: 0.0445
[Epoch 14, Batch 100] loss: 0.030121574090444483
[Epoch 14, Batch 200] loss: 0.02170341381948674
[Epoch 14, Batch 300] loss: 0.021884353639616164
[Epoch 14, Batch 400] loss: 0.02778890290821437
[Epoch 14, Batch 500] loss: 0.01876575053232955
[Epoch 14, Batch 600] loss: 0.02850209180091042
[Epoch 14, Batch 700] loss: 0.019447292268159798
[Epoch 14, Batch 800] loss: 0.029072079704492354
[Epoch 14, Batch 900] loss: 0.0343855021231866
[Epoch 14, Batch 1000] loss: 0.029103910256235394
[Epoch 14, Batch 1100] loss: 0.022800985069479793
[Epoch 14, Batch 1200] loss: 0.02296260422852356
[Epoch 14, Batch 1300] loss: 0.023589558608655352
[Epoch 14, Batch 1400] loss: 0.02782563102635322
[Epoch 14, Batch 1500] loss: 0.03131191428226884
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9865
Overfitting: 0.0441
Best model saved at epoch 14 with validation loss: 0.0441
[Epoch 15, Batch 100] loss: 0.02171208424377255
[Epoch 15, Batch 200] loss: 0.03068245087430114
[Epoch 15, Batch 300] loss: 0.023145092234772166
[Epoch 15, Batch 400] loss: 0.023253333030443173
[Epoch 15, Batch 500] loss: 0.019067700424639043
[Epoch 15, Batch 600] loss: 0.0207837798971741
[Epoch 15, Batch 700] loss: 0.028191282394400333
[Epoch 15, Batch 800] loss: 0.023724390739225783
[Epoch 15, Batch 900] loss: 0.0240673784558021
[Epoch 15, Batch 1000] loss: 0.018363143909955398
[Epoch 15, Batch 1100] loss: 0.023769563529931474
[Epoch 15, Batch 1200] loss: 0.03029714699194301
[Epoch 15, Batch 1300] loss: 0.022847412151604657
[Epoch 15, Batch 1400] loss: 0.019307810153695756
[Epoch 15, Batch 1500] loss: 0.02354338214179734
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9858
Overfitting: 0.0489
[Epoch 16, Batch 100] loss: 0.01837305652908981
[Epoch 16, Batch 200] loss: 0.0250556812393188
[Epoch 16, Batch 300] loss: 0.023075611523017868
[Epoch 16, Batch 400] loss: 0.020373533845122437
[Epoch 16, Batch 500] loss: 0.020963994457997615
[Epoch 16, Batch 600] loss: 0.027478246320970356
[Epoch 16, Batch 700] loss: 0.019502376496966463
[Epoch 16, Batch 800] loss: 0.024077341501179034
[Epoch 16, Batch 900] loss: 0.025988553829374723
[Epoch 16, Batch 1000] loss: 0.026934091582370458
[Epoch 16, Batch 1100] loss: 0.020924690799511154
[Epoch 16, Batch 1200] loss: 0.022648763974866596
[Epoch 16, Batch 1300] loss: 0.02171298398156068
[Epoch 16, Batch 1400] loss: 0.025362107419641688
[Epoch 16, Batch 1500] loss: 0.021668147831514942
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9847
Overfitting: 0.0502
[Epoch 17, Batch 100] loss: 0.015964878072118154
[Epoch 17, Batch 200] loss: 0.020150103381602093
[Epoch 17, Batch 300] loss: 0.019292742805555464
[Epoch 17, Batch 400] loss: 0.015984871238761116
[Epoch 17, Batch 500] loss: 0.02680056872573914
[Epoch 17, Batch 600] loss: 0.020068739173730137
[Epoch 17, Batch 700] loss: 0.021204184586240446
[Epoch 17, Batch 800] loss: 0.016998636451899075
[Epoch 17, Batch 900] loss: 0.022355780296202284
[Epoch 17, Batch 1000] loss: 0.014895404354610946
[Epoch 17, Batch 1100] loss: 0.022608162712713237
[Epoch 17, Batch 1200] loss: 0.014895801663951715
[Epoch 17, Batch 1300] loss: 0.027667164835438598
[Epoch 17, Batch 1400] loss: 0.02542580959838233
[Epoch 17, Batch 1500] loss: 0.01805812855105614
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0432
Validation Accuracy: 0.9872
Overfitting: 0.0432
Best model saved at epoch 17 with validation loss: 0.0432
[Epoch 18, Batch 100] loss: 0.01905907867665519
[Epoch 18, Batch 200] loss: 0.016152963143395028
[Epoch 18, Batch 300] loss: 0.01737915905781847
[Epoch 18, Batch 400] loss: 0.018155562995525544
[Epoch 18, Batch 500] loss: 0.024622040117246797
[Epoch 18, Batch 600] loss: 0.020667762085504363
[Epoch 18, Batch 700] loss: 0.017160974972066468
[Epoch 18, Batch 800] loss: 0.017595004085451366
[Epoch 18, Batch 900] loss: 0.01476569737009413
[Epoch 18, Batch 1000] loss: 0.013140479494468308
[Epoch 18, Batch 1100] loss: 0.020810263163875787
[Epoch 18, Batch 1200] loss: 0.016507489140785765
[Epoch 18, Batch 1300] loss: 0.017745754022616893
[Epoch 18, Batch 1400] loss: 0.019822597996535476
[Epoch 18, Batch 1500] loss: 0.023703073719516396
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0451
Validation Accuracy: 0.9870
Overfitting: 0.0451
[Epoch 19, Batch 100] loss: 0.018049602449900705
[Epoch 19, Batch 200] loss: 0.01755954783933703
[Epoch 19, Batch 300] loss: 0.015167493072221988
[Epoch 19, Batch 400] loss: 0.017758139398065396
[Epoch 19, Batch 500] loss: 0.01162756147881737
[Epoch 19, Batch 600] loss: 0.014654035912899417
[Epoch 19, Batch 700] loss: 0.013921761029341723
[Epoch 19, Batch 800] loss: 0.016438985155909903
[Epoch 19, Batch 900] loss: 0.01988502416133997
[Epoch 19, Batch 1000] loss: 0.020553690666492912
[Epoch 19, Batch 1100] loss: 0.020965027201164048
[Epoch 19, Batch 1200] loss: 0.018660430372692646
[Epoch 19, Batch 1300] loss: 0.01163437369883468
[Epoch 19, Batch 1400] loss: 0.018656921266010613
[Epoch 19, Batch 1500] loss: 0.01982352917766548
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9851
Overfitting: 0.0504
[Epoch 20, Batch 100] loss: 0.009754927307112667
[Epoch 20, Batch 200] loss: 0.015451132475936902
[Epoch 20, Batch 300] loss: 0.019546930548749515
[Epoch 20, Batch 400] loss: 0.01927973823105276
[Epoch 20, Batch 500] loss: 0.015063455239869654
[Epoch 20, Batch 600] loss: 0.009767831486606156
[Epoch 20, Batch 700] loss: 0.011289757771228323
[Epoch 20, Batch 800] loss: 0.017767405837257683
[Epoch 20, Batch 900] loss: 0.013616203177371063
[Epoch 20, Batch 1000] loss: 0.015788409339438658
[Epoch 20, Batch 1100] loss: 0.0205403603378727
[Epoch 20, Batch 1200] loss: 0.01567893672017817
[Epoch 20, Batch 1300] loss: 0.013044914013007655
[Epoch 20, Batch 1400] loss: 0.01355032912826573
[Epoch 20, Batch 1500] loss: 0.021811728255270283
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0448
Validation Accuracy: 0.9864
Overfitting: 0.0448
[Epoch 21, Batch 100] loss: 0.012314141923416172
[Epoch 21, Batch 200] loss: 0.014679377865395509
[Epoch 21, Batch 300] loss: 0.01054973395417619
[Epoch 21, Batch 400] loss: 0.01217623564953101
[Epoch 21, Batch 500] loss: 0.02071212325579836
[Epoch 21, Batch 600] loss: 0.01821950555102376
[Epoch 21, Batch 700] loss: 0.01104776661566575
[Epoch 21, Batch 800] loss: 0.011329593310874771
[Epoch 21, Batch 900] loss: 0.011033524516024044
[Epoch 21, Batch 1000] loss: 0.022848860506201163
[Epoch 21, Batch 1100] loss: 0.01749490852758754
[Epoch 21, Batch 1200] loss: 0.013936601076566149
[Epoch 21, Batch 1300] loss: 0.01057252177986811
[Epoch 21, Batch 1400] loss: 0.019435832790040877
[Epoch 21, Batch 1500] loss: 0.013075750008574687
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0405
Validation Accuracy: 0.9888
Overfitting: 0.0405
Best model saved at epoch 21 with validation loss: 0.0405
[Epoch 22, Batch 100] loss: 0.015905802145061897
[Epoch 22, Batch 200] loss: 0.010136795522121246
[Epoch 22, Batch 300] loss: 0.009797903217895509
[Epoch 22, Batch 400] loss: 0.007705315520033764
[Epoch 22, Batch 500] loss: 0.009039234931587998
[Epoch 22, Batch 600] loss: 0.013463950990044396
[Epoch 22, Batch 700] loss: 0.01616883298731409
[Epoch 22, Batch 800] loss: 0.013104397030037945
[Epoch 22, Batch 900] loss: 0.014300921205067424
[Epoch 22, Batch 1000] loss: 0.011859430329641327
[Epoch 22, Batch 1100] loss: 0.013813800252355577
[Epoch 22, Batch 1200] loss: 0.012420745297931716
[Epoch 22, Batch 1300] loss: 0.016384400208844453
[Epoch 22, Batch 1400] loss: 0.016195316663615813
[Epoch 22, Batch 1500] loss: 0.010353966613693047
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9868
Overfitting: 0.0464
[Epoch 23, Batch 100] loss: 0.016392192508938024
[Epoch 23, Batch 200] loss: 0.010151773201287143
[Epoch 23, Batch 300] loss: 0.009696177576188347
[Epoch 23, Batch 400] loss: 0.013841887778216915
[Epoch 23, Batch 500] loss: 0.01596771761389391
[Epoch 23, Batch 600] loss: 0.011826838859269629
[Epoch 23, Batch 700] loss: 0.015148388557427096
[Epoch 23, Batch 800] loss: 0.011667148300330155
[Epoch 23, Batch 900] loss: 0.01057380963495234
[Epoch 23, Batch 1000] loss: 0.010233956143711111
[Epoch 23, Batch 1100] loss: 0.01323149771647877
[Epoch 23, Batch 1200] loss: 0.011793369270817493
[Epoch 23, Batch 1300] loss: 0.008289330311090453
[Epoch 23, Batch 1400] loss: 0.016261919160315302
[Epoch 23, Batch 1500] loss: 0.008197005760303
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0406
Validation Accuracy: 0.9893
Overfitting: 0.0406
[Epoch 24, Batch 100] loss: 0.007754699850192992
[Epoch 24, Batch 200] loss: 0.01488445196468092
[Epoch 24, Batch 300] loss: 0.009628475591198367
[Epoch 24, Batch 400] loss: 0.006871676025948546
[Epoch 24, Batch 500] loss: 0.011671082597458735
[Epoch 24, Batch 600] loss: 0.005646436703391373
[Epoch 24, Batch 700] loss: 0.0075143889410537665
[Epoch 24, Batch 800] loss: 0.0062358428900188305
[Epoch 24, Batch 900] loss: 0.010282622121121677
[Epoch 24, Batch 1000] loss: 0.011389712603595399
[Epoch 24, Batch 1100] loss: 0.012407737035136961
[Epoch 24, Batch 1200] loss: 0.011949206128701918
[Epoch 24, Batch 1300] loss: 0.012291448839823716
[Epoch 24, Batch 1400] loss: 0.01655508423642459
[Epoch 24, Batch 1500] loss: 0.011151709677869803
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0442
Validation Accuracy: 0.9878
Overfitting: 0.0442
Fold 1 validation loss: 0.0442
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.297150294780731
[Epoch 1, Batch 200] loss: 2.2675544381141663
[Epoch 1, Batch 300] loss: 2.190287563800812
[Epoch 1, Batch 400] loss: 1.7984716594219208
[Epoch 1, Batch 500] loss: 0.848072469830513
[Epoch 1, Batch 600] loss: 0.5824563109874725
[Epoch 1, Batch 700] loss: 0.4544112838804722
[Epoch 1, Batch 800] loss: 0.3943205966055393
[Epoch 1, Batch 900] loss: 0.3473745568096638
[Epoch 1, Batch 1000] loss: 0.30540889464318755
[Epoch 1, Batch 1100] loss: 0.3136113730818033
[Epoch 1, Batch 1200] loss: 0.287766261100769
[Epoch 1, Batch 1300] loss: 0.23941531490534543
[Epoch 1, Batch 1400] loss: 0.22823110610246658
[Epoch 1, Batch 1500] loss: 0.22881933810189367
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2267
Validation Accuracy: 0.9317
Overfitting: 0.2267
Best model saved at epoch 1 with validation loss: 0.2267
[Epoch 2, Batch 100] loss: 0.19948576487600803
[Epoch 2, Batch 200] loss: 0.16955338727682828
[Epoch 2, Batch 300] loss: 0.19258357798680664
[Epoch 2, Batch 400] loss: 0.18780594140291215
[Epoch 2, Batch 500] loss: 0.19176656136289238
[Epoch 2, Batch 600] loss: 0.16814133126288652
[Epoch 2, Batch 700] loss: 0.14400861278176308
[Epoch 2, Batch 800] loss: 0.14658673224039376
[Epoch 2, Batch 900] loss: 0.14960667945444583
[Epoch 2, Batch 1000] loss: 0.15338855357840658
[Epoch 2, Batch 1100] loss: 0.14658305617049336
[Epoch 2, Batch 1200] loss: 0.12332676214165986
[Epoch 2, Batch 1300] loss: 0.1359060577303171
[Epoch 2, Batch 1400] loss: 0.1320983792375773
[Epoch 2, Batch 1500] loss: 0.11468778954818845
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1288
Validation Accuracy: 0.9603
Overfitting: 0.1288
Best model saved at epoch 2 with validation loss: 0.1288
[Epoch 3, Batch 100] loss: 0.10674435006454587
[Epoch 3, Batch 200] loss: 0.11437214137986303
[Epoch 3, Batch 300] loss: 0.1202665148768574
[Epoch 3, Batch 400] loss: 0.0964044869504869
[Epoch 3, Batch 500] loss: 0.10416028831154107
[Epoch 3, Batch 600] loss: 0.11759633883368224
[Epoch 3, Batch 700] loss: 0.1109224184602499
[Epoch 3, Batch 800] loss: 0.08757124604657292
[Epoch 3, Batch 900] loss: 0.1138076754193753
[Epoch 3, Batch 1000] loss: 0.08534496051026508
[Epoch 3, Batch 1100] loss: 0.09404128956608475
[Epoch 3, Batch 1200] loss: 0.0840610383497551
[Epoch 3, Batch 1300] loss: 0.0897070718370378
[Epoch 3, Batch 1400] loss: 0.09005488450173288
[Epoch 3, Batch 1500] loss: 0.09540089140180498
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1011
Validation Accuracy: 0.9685
Overfitting: 0.1011
Best model saved at epoch 3 with validation loss: 0.1011
[Epoch 4, Batch 100] loss: 0.08289087927900254
[Epoch 4, Batch 200] loss: 0.07675343804992735
[Epoch 4, Batch 300] loss: 0.06233719842741266
[Epoch 4, Batch 400] loss: 0.08027980044484138
[Epoch 4, Batch 500] loss: 0.09722898351959884
[Epoch 4, Batch 600] loss: 0.06543261199258268
[Epoch 4, Batch 700] loss: 0.07662205831147731
[Epoch 4, Batch 800] loss: 0.08313978351652622
[Epoch 4, Batch 900] loss: 0.07523957562167198
[Epoch 4, Batch 1000] loss: 0.07966515072621405
[Epoch 4, Batch 1100] loss: 0.08422169775003567
[Epoch 4, Batch 1200] loss: 0.07497883108910174
[Epoch 4, Batch 1300] loss: 0.07146713864756749
[Epoch 4, Batch 1400] loss: 0.08042578860651702
[Epoch 4, Batch 1500] loss: 0.07510577892884612
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0838
Validation Accuracy: 0.9732
Overfitting: 0.0838
Best model saved at epoch 4 with validation loss: 0.0838
[Epoch 5, Batch 100] loss: 0.07225870554801077
[Epoch 5, Batch 200] loss: 0.07392980432137847
[Epoch 5, Batch 300] loss: 0.05706749631557614
[Epoch 5, Batch 400] loss: 0.08259405331686138
[Epoch 5, Batch 500] loss: 0.05657237940467894
[Epoch 5, Batch 600] loss: 0.061933820305857805
[Epoch 5, Batch 700] loss: 0.06382268042885698
[Epoch 5, Batch 800] loss: 0.07983954578172416
[Epoch 5, Batch 900] loss: 0.058107047292869536
[Epoch 5, Batch 1000] loss: 0.07415824110154062
[Epoch 5, Batch 1100] loss: 0.06757303769234568
[Epoch 5, Batch 1200] loss: 0.06454154528444633
[Epoch 5, Batch 1300] loss: 0.05562367291422561
[Epoch 5, Batch 1400] loss: 0.07337547631235793
[Epoch 5, Batch 1500] loss: 0.05406467548338696
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0769
Validation Accuracy: 0.9767
Overfitting: 0.0769
Best model saved at epoch 5 with validation loss: 0.0769
[Epoch 6, Batch 100] loss: 0.05652526157442481
[Epoch 6, Batch 200] loss: 0.05003120115492493
[Epoch 6, Batch 300] loss: 0.06220587451010942
[Epoch 6, Batch 400] loss: 0.052502280362532475
[Epoch 6, Batch 500] loss: 0.04694471730967052
[Epoch 6, Batch 600] loss: 0.06613210651092231
[Epoch 6, Batch 700] loss: 0.059107479564845564
[Epoch 6, Batch 800] loss: 0.057531478587770836
[Epoch 6, Batch 900] loss: 0.06397403715876862
[Epoch 6, Batch 1000] loss: 0.05250575381680392
[Epoch 6, Batch 1100] loss: 0.0524527946440503
[Epoch 6, Batch 1200] loss: 0.06352665079990402
[Epoch 6, Batch 1300] loss: 0.06287457373808138
[Epoch 6, Batch 1400] loss: 0.06146130455192179
[Epoch 6, Batch 1500] loss: 0.04999349018326029
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0693
Validation Accuracy: 0.9792
Overfitting: 0.0693
Best model saved at epoch 6 with validation loss: 0.0693
[Epoch 7, Batch 100] loss: 0.04315631080651656
[Epoch 7, Batch 200] loss: 0.044434403677005324
[Epoch 7, Batch 300] loss: 0.05415038195089437
[Epoch 7, Batch 400] loss: 0.057399977589957414
[Epoch 7, Batch 500] loss: 0.04955824421835132
[Epoch 7, Batch 600] loss: 0.05473245741566643
[Epoch 7, Batch 700] loss: 0.050345756185706705
[Epoch 7, Batch 800] loss: 0.04840248610591516
[Epoch 7, Batch 900] loss: 0.04059087304980494
[Epoch 7, Batch 1000] loss: 0.0467682439845521
[Epoch 7, Batch 1100] loss: 0.05156915788538754
[Epoch 7, Batch 1200] loss: 0.06280919356853701
[Epoch 7, Batch 1300] loss: 0.05709680645493791
[Epoch 7, Batch 1400] loss: 0.04623827586416155
[Epoch 7, Batch 1500] loss: 0.036991855944506824
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0675
Validation Accuracy: 0.9785
Overfitting: 0.0675
Best model saved at epoch 7 with validation loss: 0.0675
[Epoch 8, Batch 100] loss: 0.05477974452078342
[Epoch 8, Batch 200] loss: 0.037859512701397764
[Epoch 8, Batch 300] loss: 0.05574749395716935
[Epoch 8, Batch 400] loss: 0.042395334262400865
[Epoch 8, Batch 500] loss: 0.04531653965241276
[Epoch 8, Batch 600] loss: 0.03362962009035982
[Epoch 8, Batch 700] loss: 0.034280443752068096
[Epoch 8, Batch 800] loss: 0.05484515199903399
[Epoch 8, Batch 900] loss: 0.0468564164894633
[Epoch 8, Batch 1000] loss: 0.03433056805632077
[Epoch 8, Batch 1100] loss: 0.0496820592856966
[Epoch 8, Batch 1200] loss: 0.05308756746642757
[Epoch 8, Batch 1300] loss: 0.04026256053184625
[Epoch 8, Batch 1400] loss: 0.04329352999222465
[Epoch 8, Batch 1500] loss: 0.04243212596978992
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0658
Validation Accuracy: 0.9799
Overfitting: 0.0658
Best model saved at epoch 8 with validation loss: 0.0658
[Epoch 9, Batch 100] loss: 0.04306141473061871
[Epoch 9, Batch 200] loss: 0.04513033109018579
[Epoch 9, Batch 300] loss: 0.039301467096665876
[Epoch 9, Batch 400] loss: 0.03804105604998767
[Epoch 9, Batch 500] loss: 0.03606528314063326
[Epoch 9, Batch 600] loss: 0.036934733274392784
[Epoch 9, Batch 700] loss: 0.046503494490170855
[Epoch 9, Batch 800] loss: 0.049948016931302845
[Epoch 9, Batch 900] loss: 0.03536401634628419
[Epoch 9, Batch 1000] loss: 0.03753031045547686
[Epoch 9, Batch 1100] loss: 0.04054628273297567
[Epoch 9, Batch 1200] loss: 0.04655868179746903
[Epoch 9, Batch 1300] loss: 0.027645876823808067
[Epoch 9, Batch 1400] loss: 0.03830795918009244
[Epoch 9, Batch 1500] loss: 0.052274367395439184
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0704
Validation Accuracy: 0.9795
Overfitting: 0.0704
[Epoch 10, Batch 100] loss: 0.04388378128525801
[Epoch 10, Batch 200] loss: 0.04575615178793669
[Epoch 10, Batch 300] loss: 0.032651446713716725
[Epoch 10, Batch 400] loss: 0.0365606015897356
[Epoch 10, Batch 500] loss: 0.03518380506488029
[Epoch 10, Batch 600] loss: 0.030562672030646353
[Epoch 10, Batch 700] loss: 0.0403792367974529
[Epoch 10, Batch 800] loss: 0.04124501978571061
[Epoch 10, Batch 900] loss: 0.04048709839291405
[Epoch 10, Batch 1000] loss: 0.03613266294589266
[Epoch 10, Batch 1100] loss: 0.042661936818185496
[Epoch 10, Batch 1200] loss: 0.04014098273939453
[Epoch 10, Batch 1300] loss: 0.039065115743433125
[Epoch 10, Batch 1400] loss: 0.02987980562960729
[Epoch 10, Batch 1500] loss: 0.03292735307943076
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0618
Validation Accuracy: 0.9808
Overfitting: 0.0618
Best model saved at epoch 10 with validation loss: 0.0618
[Epoch 11, Batch 100] loss: 0.032249114786973225
[Epoch 11, Batch 200] loss: 0.034833575596567246
[Epoch 11, Batch 300] loss: 0.034958103747339916
[Epoch 11, Batch 400] loss: 0.04487637546088081
[Epoch 11, Batch 500] loss: 0.028722892905352636
[Epoch 11, Batch 600] loss: 0.03660751328570768
[Epoch 11, Batch 700] loss: 0.029999346361728386
[Epoch 11, Batch 800] loss: 0.02925398343882989
[Epoch 11, Batch 900] loss: 0.03142312534590019
[Epoch 11, Batch 1000] loss: 0.03897608789673541
[Epoch 11, Batch 1100] loss: 0.036923402461688966
[Epoch 11, Batch 1200] loss: 0.02900039283093065
[Epoch 11, Batch 1300] loss: 0.03160343532421393
[Epoch 11, Batch 1400] loss: 0.031274020682612896
[Epoch 11, Batch 1500] loss: 0.03495661670458503
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9840
Overfitting: 0.0525
Best model saved at epoch 11 with validation loss: 0.0525
[Epoch 12, Batch 100] loss: 0.021487449852284044
[Epoch 12, Batch 200] loss: 0.026444172251212875
[Epoch 12, Batch 300] loss: 0.03397097159409895
[Epoch 12, Batch 400] loss: 0.02815922850277275
[Epoch 12, Batch 500] loss: 0.0377968385675922
[Epoch 12, Batch 600] loss: 0.0357683106593322
[Epoch 12, Batch 700] loss: 0.029424496567226014
[Epoch 12, Batch 800] loss: 0.03378421922127018
[Epoch 12, Batch 900] loss: 0.034781857664347625
[Epoch 12, Batch 1000] loss: 0.031018609245365952
[Epoch 12, Batch 1100] loss: 0.033338586448226126
[Epoch 12, Batch 1200] loss: 0.02606189964542864
[Epoch 12, Batch 1300] loss: 0.03266973893565592
[Epoch 12, Batch 1400] loss: 0.02968923535285285
[Epoch 12, Batch 1500] loss: 0.033894579768530095
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0595
Validation Accuracy: 0.9820
Overfitting: 0.0595
[Epoch 13, Batch 100] loss: 0.032472229493432675
[Epoch 13, Batch 200] loss: 0.026256733929621988
[Epoch 13, Batch 300] loss: 0.024600140410766472
[Epoch 13, Batch 400] loss: 0.02267729316983605
[Epoch 13, Batch 500] loss: 0.03152297148655634
[Epoch 13, Batch 600] loss: 0.028932373634306716
[Epoch 13, Batch 700] loss: 0.036264779071207155
[Epoch 13, Batch 800] loss: 0.03201350123985321
[Epoch 13, Batch 900] loss: 0.02445244960457785
[Epoch 13, Batch 1000] loss: 0.02440274717839202
[Epoch 13, Batch 1100] loss: 0.02561193797388114
[Epoch 13, Batch 1200] loss: 0.03755821473547258
[Epoch 13, Batch 1300] loss: 0.03218846609481261
[Epoch 13, Batch 1400] loss: 0.022427608933357986
[Epoch 13, Batch 1500] loss: 0.030940270759747365
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0566
Validation Accuracy: 0.9828
Overfitting: 0.0566
[Epoch 14, Batch 100] loss: 0.019907691717962736
[Epoch 14, Batch 200] loss: 0.023188578544941264
[Epoch 14, Batch 300] loss: 0.020946812442562076
[Epoch 14, Batch 400] loss: 0.03177181187667884
[Epoch 14, Batch 500] loss: 0.02338693400262855
[Epoch 14, Batch 600] loss: 0.030509968999540435
[Epoch 14, Batch 700] loss: 0.026248073686147108
[Epoch 14, Batch 800] loss: 0.02377378456410952
[Epoch 14, Batch 900] loss: 0.03142046011547791
[Epoch 14, Batch 1000] loss: 0.02078147303662263
[Epoch 14, Batch 1100] loss: 0.02364094792312244
[Epoch 14, Batch 1200] loss: 0.029228882213283215
[Epoch 14, Batch 1300] loss: 0.03733065896987682
[Epoch 14, Batch 1400] loss: 0.031591148989537035
[Epoch 14, Batch 1500] loss: 0.0220539520814782
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9850
Overfitting: 0.0475
Best model saved at epoch 14 with validation loss: 0.0475
[Epoch 15, Batch 100] loss: 0.028732800463330932
[Epoch 15, Batch 200] loss: 0.021455975353310352
[Epoch 15, Batch 300] loss: 0.025453395706717855
[Epoch 15, Batch 400] loss: 0.01743845931167016
[Epoch 15, Batch 500] loss: 0.02770010665524751
[Epoch 15, Batch 600] loss: 0.018846514131146252
[Epoch 15, Batch 700] loss: 0.02458333193746512
[Epoch 15, Batch 800] loss: 0.022184753274195827
[Epoch 15, Batch 900] loss: 0.01833495707309339
[Epoch 15, Batch 1000] loss: 0.02357873837798252
[Epoch 15, Batch 1100] loss: 0.02599817800684832
[Epoch 15, Batch 1200] loss: 0.029082553746702614
[Epoch 15, Batch 1300] loss: 0.018132674778462386
[Epoch 15, Batch 1400] loss: 0.023181976824889716
[Epoch 15, Batch 1500] loss: 0.030317395931924694
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9854
Overfitting: 0.0495
[Epoch 16, Batch 100] loss: 0.01946357872831868
[Epoch 16, Batch 200] loss: 0.01705344958070782
[Epoch 16, Batch 300] loss: 0.017451962435588938
[Epoch 16, Batch 400] loss: 0.017167693828378107
[Epoch 16, Batch 500] loss: 0.019088538634387076
[Epoch 16, Batch 600] loss: 0.03321020148607204
[Epoch 16, Batch 700] loss: 0.020955065762682353
[Epoch 16, Batch 800] loss: 0.021476355072227307
[Epoch 16, Batch 900] loss: 0.026226038740423972
[Epoch 16, Batch 1000] loss: 0.018965922053612302
[Epoch 16, Batch 1100] loss: 0.018853208473883568
[Epoch 16, Batch 1200] loss: 0.024396680002828363
[Epoch 16, Batch 1300] loss: 0.024327893759764265
[Epoch 16, Batch 1400] loss: 0.021730795729672535
[Epoch 16, Batch 1500] loss: 0.030311360901541774
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9839
Overfitting: 0.0538
[Epoch 17, Batch 100] loss: 0.01488951613791869
[Epoch 17, Batch 200] loss: 0.01697475666369428
[Epoch 17, Batch 300] loss: 0.017443506138661177
[Epoch 17, Batch 400] loss: 0.02664540986152133
[Epoch 17, Batch 500] loss: 0.021894238534296163
[Epoch 17, Batch 600] loss: 0.021594563478720373
[Epoch 17, Batch 700] loss: 0.01872587561025284
[Epoch 17, Batch 800] loss: 0.025146316445752746
[Epoch 17, Batch 900] loss: 0.021042987064865883
[Epoch 17, Batch 1000] loss: 0.015016653853235766
[Epoch 17, Batch 1100] loss: 0.01970715319534065
[Epoch 17, Batch 1200] loss: 0.02154761391982902
[Epoch 17, Batch 1300] loss: 0.019230842575561836
[Epoch 17, Batch 1400] loss: 0.022500896453057067
[Epoch 17, Batch 1500] loss: 0.020074261867121093
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9858
Overfitting: 0.0483
[Epoch 18, Batch 100] loss: 0.026987484186829534
[Epoch 18, Batch 200] loss: 0.01936621611355804
[Epoch 18, Batch 300] loss: 0.016117266187939093
[Epoch 18, Batch 400] loss: 0.01877008647978073
[Epoch 18, Batch 500] loss: 0.02640263387322193
[Epoch 18, Batch 600] loss: 0.019181517360848374
[Epoch 18, Batch 700] loss: 0.01940106881025713
[Epoch 18, Batch 800] loss: 0.023715643924224424
[Epoch 18, Batch 900] loss: 0.017221136126900093
[Epoch 18, Batch 1000] loss: 0.02143643802293809
[Epoch 18, Batch 1100] loss: 0.023203625450041728
[Epoch 18, Batch 1200] loss: 0.016895764402433996
[Epoch 18, Batch 1300] loss: 0.019455127442779486
[Epoch 18, Batch 1400] loss: 0.012196591054962482
[Epoch 18, Batch 1500] loss: 0.01277804299392301
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9843
Overfitting: 0.0544
[Epoch 19, Batch 100] loss: 0.018446349820442264
[Epoch 19, Batch 200] loss: 0.016120314078652883
[Epoch 19, Batch 300] loss: 0.014881958091136767
[Epoch 19, Batch 400] loss: 0.019122430736169916
[Epoch 19, Batch 500] loss: 0.014961165083223022
[Epoch 19, Batch 600] loss: 0.012007232233372633
[Epoch 19, Batch 700] loss: 0.020743093018390935
[Epoch 19, Batch 800] loss: 0.01640209491175483
[Epoch 19, Batch 900] loss: 0.021882669661281398
[Epoch 19, Batch 1000] loss: 0.015475681936804904
[Epoch 19, Batch 1100] loss: 0.014697345014647
[Epoch 19, Batch 1200] loss: 0.021604873040232633
[Epoch 19, Batch 1300] loss: 0.026361616955109638
[Epoch 19, Batch 1400] loss: 0.012720268387492979
[Epoch 19, Batch 1500] loss: 0.020379052986863825
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9842
Overfitting: 0.0551
[Epoch 20, Batch 100] loss: 0.014562196211190894
[Epoch 20, Batch 200] loss: 0.014669019202847267
[Epoch 20, Batch 300] loss: 0.01710138798880507
[Epoch 20, Batch 400] loss: 0.014578693014918827
[Epoch 20, Batch 500] loss: 0.02253868196516123
[Epoch 20, Batch 600] loss: 0.018113493141718208
[Epoch 20, Batch 700] loss: 0.016825341312505772
[Epoch 20, Batch 800] loss: 0.011040313683552086
[Epoch 20, Batch 900] loss: 0.012460592494753654
[Epoch 20, Batch 1000] loss: 0.012722220742725767
[Epoch 20, Batch 1100] loss: 0.018338792565991753
[Epoch 20, Batch 1200] loss: 0.01844680375448661
[Epoch 20, Batch 1300] loss: 0.011489622122026049
[Epoch 20, Batch 1400] loss: 0.02171909173102904
[Epoch 20, Batch 1500] loss: 0.019566369270178255
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9864
Overfitting: 0.0476
[Epoch 21, Batch 100] loss: 0.018581984811244182
[Epoch 21, Batch 200] loss: 0.02216606629473972
[Epoch 21, Batch 300] loss: 0.014141763575098594
[Epoch 21, Batch 400] loss: 0.013302272938526585
[Epoch 21, Batch 500] loss: 0.014740687774537947
[Epoch 21, Batch 600] loss: 0.01444897655317618
[Epoch 21, Batch 700] loss: 0.014500794002378825
[Epoch 21, Batch 800] loss: 0.01395333008025773
[Epoch 21, Batch 900] loss: 0.010370926066098036
[Epoch 21, Batch 1000] loss: 0.01576078878286353
[Epoch 21, Batch 1100] loss: 0.017383425918851572
[Epoch 21, Batch 1200] loss: 0.014287496544420719
[Epoch 21, Batch 1300] loss: 0.015660710618831217
[Epoch 21, Batch 1400] loss: 0.015449084714855416
[Epoch 21, Batch 1500] loss: 0.012816798746825953
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9859
Overfitting: 0.0481
[Epoch 22, Batch 100] loss: 0.009828475599242666
[Epoch 22, Batch 200] loss: 0.01082311698630292
[Epoch 22, Batch 300] loss: 0.01033936439343961
[Epoch 22, Batch 400] loss: 0.015087111237517093
[Epoch 22, Batch 500] loss: 0.014854352156908135
[Epoch 22, Batch 600] loss: 0.015615666557969234
[Epoch 22, Batch 700] loss: 0.019248665197337686
[Epoch 22, Batch 800] loss: 0.013868043044931255
[Epoch 22, Batch 900] loss: 0.01898991785630642
[Epoch 22, Batch 1000] loss: 0.012446850581254694
[Epoch 22, Batch 1100] loss: 0.009977240245279972
[Epoch 22, Batch 1200] loss: 0.018130690153375328
[Epoch 22, Batch 1300] loss: 0.012298081029020977
[Epoch 22, Batch 1400] loss: 0.016714701241799048
[Epoch 22, Batch 1500] loss: 0.020079195100697687
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9862
Overfitting: 0.0485
[Epoch 23, Batch 100] loss: 0.012047023292252561
[Epoch 23, Batch 200] loss: 0.00903551799194247
[Epoch 23, Batch 300] loss: 0.009554702830791939
[Epoch 23, Batch 400] loss: 0.009435729783435818
[Epoch 23, Batch 500] loss: 0.005930445706981118
[Epoch 23, Batch 600] loss: 0.016882722241043667
[Epoch 23, Batch 700] loss: 0.008412689403703552
[Epoch 23, Batch 800] loss: 0.01230911183396529
[Epoch 23, Batch 900] loss: 0.014040297168612596
[Epoch 23, Batch 1000] loss: 0.01697897790974821
[Epoch 23, Batch 1100] loss: 0.010689503055691602
[Epoch 23, Batch 1200] loss: 0.01542777707130881
[Epoch 23, Batch 1300] loss: 0.016179003007273422
[Epoch 23, Batch 1400] loss: 0.013372418000708422
[Epoch 23, Batch 1500] loss: 0.018377948029228718
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9846
Overfitting: 0.0535
[Epoch 24, Batch 100] loss: 0.009640200042267679
[Epoch 24, Batch 200] loss: 0.007165240510512376
[Epoch 24, Batch 300] loss: 0.014645160562722595
[Epoch 24, Batch 400] loss: 0.0070951716030322135
[Epoch 24, Batch 500] loss: 0.013835370781634992
[Epoch 24, Batch 600] loss: 0.011991111291063134
[Epoch 24, Batch 700] loss: 0.009728297558049236
[Epoch 24, Batch 800] loss: 0.00855097745108651
[Epoch 24, Batch 900] loss: 0.011342707400981453
[Epoch 24, Batch 1000] loss: 0.010369063702491986
[Epoch 24, Batch 1100] loss: 0.012731745537494135
[Epoch 24, Batch 1200] loss: 0.014381454555696109
[Epoch 24, Batch 1300] loss: 0.012779898421558755
[Epoch 24, Batch 1400] loss: 0.012795326003979425
[Epoch 24, Batch 1500] loss: 0.014195336412049073
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9878
Overfitting: 0.0473
Best model saved at epoch 24 with validation loss: 0.0473
Fold 2 validation loss: 0.0473
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2950833582878114
[Epoch 1, Batch 200] loss: 2.2644006299972532
[Epoch 1, Batch 300] loss: 2.174120798110962
[Epoch 1, Batch 400] loss: 1.7120648789405823
[Epoch 1, Batch 500] loss: 0.9455779027938843
[Epoch 1, Batch 600] loss: 0.6377612340450287
[Epoch 1, Batch 700] loss: 0.5509402666985989
[Epoch 1, Batch 800] loss: 0.47112853959202766
[Epoch 1, Batch 900] loss: 0.44612170264124873
[Epoch 1, Batch 1000] loss: 0.3986919628083706
[Epoch 1, Batch 1100] loss: 0.35396479710936546
[Epoch 1, Batch 1200] loss: 0.33790611326694486
[Epoch 1, Batch 1300] loss: 0.31491220332682135
[Epoch 1, Batch 1400] loss: 0.274981754347682
[Epoch 1, Batch 1500] loss: 0.29369480077177285
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2732
Validation Accuracy: 0.9174
Overfitting: 0.2732
Best model saved at epoch 1 with validation loss: 0.2732
[Epoch 2, Batch 100] loss: 0.26687582399696114
[Epoch 2, Batch 200] loss: 0.22997264828532935
[Epoch 2, Batch 300] loss: 0.21765598837286235
[Epoch 2, Batch 400] loss: 0.21069008018821478
[Epoch 2, Batch 500] loss: 0.20638004664331674
[Epoch 2, Batch 600] loss: 0.18518921073526143
[Epoch 2, Batch 700] loss: 0.19280407562851906
[Epoch 2, Batch 800] loss: 0.19523817997425794
[Epoch 2, Batch 900] loss: 0.19196012465283274
[Epoch 2, Batch 1000] loss: 0.1832578160241246
[Epoch 2, Batch 1100] loss: 0.18173522878438234
[Epoch 2, Batch 1200] loss: 0.17823782194405793
[Epoch 2, Batch 1300] loss: 0.17418400460854172
[Epoch 2, Batch 1400] loss: 0.17010378420352937
[Epoch 2, Batch 1500] loss: 0.15093463605269788
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1392
Validation Accuracy: 0.9565
Overfitting: 0.1392
Best model saved at epoch 2 with validation loss: 0.1392
[Epoch 3, Batch 100] loss: 0.14478844668716193
[Epoch 3, Batch 200] loss: 0.1477241780422628
[Epoch 3, Batch 300] loss: 0.1132885067909956
[Epoch 3, Batch 400] loss: 0.12964526016265154
[Epoch 3, Batch 500] loss: 0.1333882680442184
[Epoch 3, Batch 600] loss: 0.1378483334928751
[Epoch 3, Batch 700] loss: 0.1176841691788286
[Epoch 3, Batch 800] loss: 0.11940307350829243
[Epoch 3, Batch 900] loss: 0.11609310137107968
[Epoch 3, Batch 1000] loss: 0.09035898381844162
[Epoch 3, Batch 1100] loss: 0.1121306221652776
[Epoch 3, Batch 1200] loss: 0.10870001872070134
[Epoch 3, Batch 1300] loss: 0.09219401692505926
[Epoch 3, Batch 1400] loss: 0.10707165436819195
[Epoch 3, Batch 1500] loss: 0.11174890431575477
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1094
Validation Accuracy: 0.9667
Overfitting: 0.1094
Best model saved at epoch 3 with validation loss: 0.1094
[Epoch 4, Batch 100] loss: 0.09974553951527923
[Epoch 4, Batch 200] loss: 0.08547606134787201
[Epoch 4, Batch 300] loss: 0.09398144524544477
[Epoch 4, Batch 400] loss: 0.09237450727727264
[Epoch 4, Batch 500] loss: 0.10537458536680788
[Epoch 4, Batch 600] loss: 0.1056727900961414
[Epoch 4, Batch 700] loss: 0.09076799756847322
[Epoch 4, Batch 800] loss: 0.08557785526616499
[Epoch 4, Batch 900] loss: 0.09071507521905005
[Epoch 4, Batch 1000] loss: 0.07865352399647235
[Epoch 4, Batch 1100] loss: 0.06946647999342531
[Epoch 4, Batch 1200] loss: 0.0880015833908692
[Epoch 4, Batch 1300] loss: 0.08658466607099399
[Epoch 4, Batch 1400] loss: 0.08521137394476681
[Epoch 4, Batch 1500] loss: 0.09820528452517464
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0957
Validation Accuracy: 0.9714
Overfitting: 0.0957
Best model saved at epoch 4 with validation loss: 0.0957
[Epoch 5, Batch 100] loss: 0.09729614296928048
[Epoch 5, Batch 200] loss: 0.08826451070141048
[Epoch 5, Batch 300] loss: 0.07784286806825548
[Epoch 5, Batch 400] loss: 0.0770542185753584
[Epoch 5, Batch 500] loss: 0.07242721468675882
[Epoch 5, Batch 600] loss: 0.07016842102631926
[Epoch 5, Batch 700] loss: 0.0657604813342914
[Epoch 5, Batch 800] loss: 0.07189919798634946
[Epoch 5, Batch 900] loss: 0.06486865175422281
[Epoch 5, Batch 1000] loss: 0.0834767352277413
[Epoch 5, Batch 1100] loss: 0.06446209563408047
[Epoch 5, Batch 1200] loss: 0.07789876259863376
[Epoch 5, Batch 1300] loss: 0.07108912727213465
[Epoch 5, Batch 1400] loss: 0.06928416823968292
[Epoch 5, Batch 1500] loss: 0.06891706986818463
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0857
Validation Accuracy: 0.9736
Overfitting: 0.0857
Best model saved at epoch 5 with validation loss: 0.0857
[Epoch 6, Batch 100] loss: 0.06488064851844683
[Epoch 6, Batch 200] loss: 0.05306571542518213
[Epoch 6, Batch 300] loss: 0.07264565092045813
[Epoch 6, Batch 400] loss: 0.05962987716775388
[Epoch 6, Batch 500] loss: 0.07773628736147657
[Epoch 6, Batch 600] loss: 0.07321067459182813
[Epoch 6, Batch 700] loss: 0.0753826171392575
[Epoch 6, Batch 800] loss: 0.0642961236415431
[Epoch 6, Batch 900] loss: 0.06421488754451275
[Epoch 6, Batch 1000] loss: 0.058616826266516
[Epoch 6, Batch 1100] loss: 0.05689485426293686
[Epoch 6, Batch 1200] loss: 0.050021548580843955
[Epoch 6, Batch 1300] loss: 0.06038723743055016
[Epoch 6, Batch 1400] loss: 0.05267622882965952
[Epoch 6, Batch 1500] loss: 0.061153613867936656
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0683
Validation Accuracy: 0.9789
Overfitting: 0.0683
Best model saved at epoch 6 with validation loss: 0.0683
[Epoch 7, Batch 100] loss: 0.04261904971324839
[Epoch 7, Batch 200] loss: 0.04616555229527876
[Epoch 7, Batch 300] loss: 0.06372373543446884
[Epoch 7, Batch 400] loss: 0.059922722011106086
[Epoch 7, Batch 500] loss: 0.060404418215621265
[Epoch 7, Batch 600] loss: 0.05964499652851373
[Epoch 7, Batch 700] loss: 0.05439997684326954
[Epoch 7, Batch 800] loss: 0.04443522768793628
[Epoch 7, Batch 900] loss: 0.048614083210704845
[Epoch 7, Batch 1000] loss: 0.06031771765323356
[Epoch 7, Batch 1100] loss: 0.066112719894154
[Epoch 7, Batch 1200] loss: 0.05191993818269111
[Epoch 7, Batch 1300] loss: 0.05334919625194743
[Epoch 7, Batch 1400] loss: 0.05679055714397691
[Epoch 7, Batch 1500] loss: 0.052710648141801354
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0663
Validation Accuracy: 0.9810
Overfitting: 0.0663
Best model saved at epoch 7 with validation loss: 0.0663
[Epoch 8, Batch 100] loss: 0.04783256420865655
[Epoch 8, Batch 200] loss: 0.05227218660060316
[Epoch 8, Batch 300] loss: 0.045427735555567776
[Epoch 8, Batch 400] loss: 0.05275187820196152
[Epoch 8, Batch 500] loss: 0.057751541298348454
[Epoch 8, Batch 600] loss: 0.0503273298102431
[Epoch 8, Batch 700] loss: 0.04271691725007258
[Epoch 8, Batch 800] loss: 0.04616306267329492
[Epoch 8, Batch 900] loss: 0.048827192247845236
[Epoch 8, Batch 1000] loss: 0.05595365209388547
[Epoch 8, Batch 1100] loss: 0.04608926630113274
[Epoch 8, Batch 1200] loss: 0.05205431108828634
[Epoch 8, Batch 1300] loss: 0.05331575366202742
[Epoch 8, Batch 1400] loss: 0.04963657028507441
[Epoch 8, Batch 1500] loss: 0.050766369025222954
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0578
Validation Accuracy: 0.9812
Overfitting: 0.0578
Best model saved at epoch 8 with validation loss: 0.0578
[Epoch 9, Batch 100] loss: 0.034900690180948005
[Epoch 9, Batch 200] loss: 0.04374372476013377
[Epoch 9, Batch 300] loss: 0.03481652092421427
[Epoch 9, Batch 400] loss: 0.03734889792161994
[Epoch 9, Batch 500] loss: 0.05954567404813133
[Epoch 9, Batch 600] loss: 0.055483400968369095
[Epoch 9, Batch 700] loss: 0.04018077456508763
[Epoch 9, Batch 800] loss: 0.045852684975834564
[Epoch 9, Batch 900] loss: 0.039695156419766134
[Epoch 9, Batch 1000] loss: 0.0501720012241276
[Epoch 9, Batch 1100] loss: 0.040058660745853555
[Epoch 9, Batch 1200] loss: 0.04896090127353091
[Epoch 9, Batch 1300] loss: 0.03627440867130645
[Epoch 9, Batch 1400] loss: 0.04675310970924329
[Epoch 9, Batch 1500] loss: 0.044095419847290034
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0587
Validation Accuracy: 0.9824
Overfitting: 0.0587
[Epoch 10, Batch 100] loss: 0.035987376999109984
[Epoch 10, Batch 200] loss: 0.04366092788404785
[Epoch 10, Batch 300] loss: 0.03462633374205325
[Epoch 10, Batch 400] loss: 0.03936986129381694
[Epoch 10, Batch 500] loss: 0.03048315169347916
[Epoch 10, Batch 600] loss: 0.041758269391721115
[Epoch 10, Batch 700] loss: 0.041427637375309134
[Epoch 10, Batch 800] loss: 0.041407425196957774
[Epoch 10, Batch 900] loss: 0.04353018941241316
[Epoch 10, Batch 1000] loss: 0.04089218293956946
[Epoch 10, Batch 1100] loss: 0.04225856418139301
[Epoch 10, Batch 1200] loss: 0.040118663313915025
[Epoch 10, Batch 1300] loss: 0.04099000331654679
[Epoch 10, Batch 1400] loss: 0.03902177290932741
[Epoch 10, Batch 1500] loss: 0.043583226184127855
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0580
Validation Accuracy: 0.9824
Overfitting: 0.0580
[Epoch 11, Batch 100] loss: 0.03387282034615055
[Epoch 11, Batch 200] loss: 0.0292569393850863
[Epoch 11, Batch 300] loss: 0.034044339118991046
[Epoch 11, Batch 400] loss: 0.03649922439042712
[Epoch 11, Batch 500] loss: 0.04277209569117986
[Epoch 11, Batch 600] loss: 0.03354691386804916
[Epoch 11, Batch 700] loss: 0.03091773682652274
[Epoch 11, Batch 800] loss: 0.03518251458008308
[Epoch 11, Batch 900] loss: 0.04010319745342713
[Epoch 11, Batch 1000] loss: 0.04545579727855511
[Epoch 11, Batch 1100] loss: 0.03675514010246843
[Epoch 11, Batch 1200] loss: 0.027737500572111457
[Epoch 11, Batch 1300] loss: 0.03518104944902006
[Epoch 11, Batch 1400] loss: 0.03401377833331935
[Epoch 11, Batch 1500] loss: 0.04422420035873074
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9835
Overfitting: 0.0538
Best model saved at epoch 11 with validation loss: 0.0538
[Epoch 12, Batch 100] loss: 0.031369259803614116
[Epoch 12, Batch 200] loss: 0.03736684904084541
[Epoch 12, Batch 300] loss: 0.03098448703298345
[Epoch 12, Batch 400] loss: 0.0324055081041297
[Epoch 12, Batch 500] loss: 0.028610611406620592
[Epoch 12, Batch 600] loss: 0.03128565785475075
[Epoch 12, Batch 700] loss: 0.026883704664360266
[Epoch 12, Batch 800] loss: 0.024553767027100548
[Epoch 12, Batch 900] loss: 0.03308051634550793
[Epoch 12, Batch 1000] loss: 0.04686383912834571
[Epoch 12, Batch 1100] loss: 0.03103473167284392
[Epoch 12, Batch 1200] loss: 0.02195532009471208
[Epoch 12, Batch 1300] loss: 0.033647305877530016
[Epoch 12, Batch 1400] loss: 0.03346316937066149
[Epoch 12, Batch 1500] loss: 0.03940387656912207
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9851
Overfitting: 0.0493
Best model saved at epoch 12 with validation loss: 0.0493
[Epoch 13, Batch 100] loss: 0.029508409317350014
[Epoch 13, Batch 200] loss: 0.023848370949272068
[Epoch 13, Batch 300] loss: 0.02109859508898808
[Epoch 13, Batch 400] loss: 0.03042380929691717
[Epoch 13, Batch 500] loss: 0.03206613808462862
[Epoch 13, Batch 600] loss: 0.026929482988925883
[Epoch 13, Batch 700] loss: 0.04929765218810644
[Epoch 13, Batch 800] loss: 0.022829086582642048
[Epoch 13, Batch 900] loss: 0.027745043601607903
[Epoch 13, Batch 1000] loss: 0.02736113345832564
[Epoch 13, Batch 1100] loss: 0.03180836812214693
[Epoch 13, Batch 1200] loss: 0.0281892330487608
[Epoch 13, Batch 1300] loss: 0.0354973208141746
[Epoch 13, Batch 1400] loss: 0.024113207616028375
[Epoch 13, Batch 1500] loss: 0.02587695663503837
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9857
Overfitting: 0.0494
[Epoch 14, Batch 100] loss: 0.023370963819033932
[Epoch 14, Batch 200] loss: 0.023196291486383417
[Epoch 14, Batch 300] loss: 0.02409927696338855
[Epoch 14, Batch 400] loss: 0.02550976434533368
[Epoch 14, Batch 500] loss: 0.026061637277307453
[Epoch 14, Batch 600] loss: 0.029523665021406485
[Epoch 14, Batch 700] loss: 0.02623159784649033
[Epoch 14, Batch 800] loss: 0.025251894941029605
[Epoch 14, Batch 900] loss: 0.019336649085744284
[Epoch 14, Batch 1000] loss: 0.029377822626847773
[Epoch 14, Batch 1100] loss: 0.03254915335768601
[Epoch 14, Batch 1200] loss: 0.023782768533565105
[Epoch 14, Batch 1300] loss: 0.027072908902191557
[Epoch 14, Batch 1400] loss: 0.031544469977088735
[Epoch 14, Batch 1500] loss: 0.02359660371497739
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9858
Overfitting: 0.0467
Best model saved at epoch 14 with validation loss: 0.0467
[Epoch 15, Batch 100] loss: 0.020345718322787434
[Epoch 15, Batch 200] loss: 0.017900646945345215
[Epoch 15, Batch 300] loss: 0.025956557502795477
[Epoch 15, Batch 400] loss: 0.021033597019559237
[Epoch 15, Batch 500] loss: 0.02256107999724918
[Epoch 15, Batch 600] loss: 0.028400207914819474
[Epoch 15, Batch 700] loss: 0.017160073629347607
[Epoch 15, Batch 800] loss: 0.027821163371263537
[Epoch 15, Batch 900] loss: 0.03189860704485909
[Epoch 15, Batch 1000] loss: 0.021778585856955034
[Epoch 15, Batch 1100] loss: 0.018946516283176607
[Epoch 15, Batch 1200] loss: 0.02564716910594143
[Epoch 15, Batch 1300] loss: 0.028331739142304288
[Epoch 15, Batch 1400] loss: 0.022560129934572615
[Epoch 15, Batch 1500] loss: 0.027979053340968677
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9845
Overfitting: 0.0520
[Epoch 16, Batch 100] loss: 0.025801918059587477
[Epoch 16, Batch 200] loss: 0.01675852699117968
[Epoch 16, Batch 300] loss: 0.027372449152171612
[Epoch 16, Batch 400] loss: 0.024945987727260217
[Epoch 16, Batch 500] loss: 0.01646006388560636
[Epoch 16, Batch 600] loss: 0.025480158408463467
[Epoch 16, Batch 700] loss: 0.01940473672846565
[Epoch 16, Batch 800] loss: 0.020686014192469883
[Epoch 16, Batch 900] loss: 0.02195103468184243
[Epoch 16, Batch 1000] loss: 0.019805210451304445
[Epoch 16, Batch 1100] loss: 0.02355271729218657
[Epoch 16, Batch 1200] loss: 0.02971906553466397
[Epoch 16, Batch 1300] loss: 0.02606495193875162
[Epoch 16, Batch 1400] loss: 0.02069827015664487
[Epoch 16, Batch 1500] loss: 0.02130411199235823
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9871
Overfitting: 0.0470
[Epoch 17, Batch 100] loss: 0.019172533919045234
[Epoch 17, Batch 200] loss: 0.01905395853391383
[Epoch 17, Batch 300] loss: 0.018073520130710678
[Epoch 17, Batch 400] loss: 0.025761280607694063
[Epoch 17, Batch 500] loss: 0.01983325819601305
[Epoch 17, Batch 600] loss: 0.01712553914010641
[Epoch 17, Batch 700] loss: 0.021609586441190914
[Epoch 17, Batch 800] loss: 0.015168432293576188
[Epoch 17, Batch 900] loss: 0.020818600843776947
[Epoch 17, Batch 1000] loss: 0.01714931506488938
[Epoch 17, Batch 1100] loss: 0.016479551814700243
[Epoch 17, Batch 1200] loss: 0.02012032760787406
[Epoch 17, Batch 1300] loss: 0.025164615376561415
[Epoch 17, Batch 1400] loss: 0.021824855942686554
[Epoch 17, Batch 1500] loss: 0.019414679620167588
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0488
Validation Accuracy: 0.9867
Overfitting: 0.0488
[Epoch 18, Batch 100] loss: 0.013349445466010365
[Epoch 18, Batch 200] loss: 0.01714824494330969
[Epoch 18, Batch 300] loss: 0.01687330297609151
[Epoch 18, Batch 400] loss: 0.015729521389876027
[Epoch 18, Batch 500] loss: 0.015787668532138924
[Epoch 18, Batch 600] loss: 0.018377735854010098
[Epoch 18, Batch 700] loss: 0.017024831717426425
[Epoch 18, Batch 800] loss: 0.02064025993277028
[Epoch 18, Batch 900] loss: 0.018845036244165385
[Epoch 18, Batch 1000] loss: 0.012865397979185218
[Epoch 18, Batch 1100] loss: 0.018039317311631747
[Epoch 18, Batch 1200] loss: 0.0218761831887241
[Epoch 18, Batch 1300] loss: 0.019833790543925714
[Epoch 18, Batch 1400] loss: 0.02195928965898929
[Epoch 18, Batch 1500] loss: 0.029526813544798643
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9848
Overfitting: 0.0535
[Epoch 19, Batch 100] loss: 0.019798738862737083
[Epoch 19, Batch 200] loss: 0.013463864176883363
[Epoch 19, Batch 300] loss: 0.015997987540613393
[Epoch 19, Batch 400] loss: 0.01301606556357001
[Epoch 19, Batch 500] loss: 0.016632828139699997
[Epoch 19, Batch 600] loss: 0.017555409067426808
[Epoch 19, Batch 700] loss: 0.020086222260360956
[Epoch 19, Batch 800] loss: 0.02120006362456479
[Epoch 19, Batch 900] loss: 0.01567437375852023
[Epoch 19, Batch 1000] loss: 0.015208123617994715
[Epoch 19, Batch 1100] loss: 0.0174167911116092
[Epoch 19, Batch 1200] loss: 0.014653307938788203
[Epoch 19, Batch 1300] loss: 0.017534276620863237
[Epoch 19, Batch 1400] loss: 0.015462230940793234
[Epoch 19, Batch 1500] loss: 0.015125050031856517
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9863
Overfitting: 0.0490
[Epoch 20, Batch 100] loss: 0.013329695740831085
[Epoch 20, Batch 200] loss: 0.011890341222751885
[Epoch 20, Batch 300] loss: 0.011914085961252567
[Epoch 20, Batch 400] loss: 0.011318106782709947
[Epoch 20, Batch 500] loss: 0.01724477773081162
[Epoch 20, Batch 600] loss: 0.011492671939631691
[Epoch 20, Batch 700] loss: 0.016558470315212615
[Epoch 20, Batch 800] loss: 0.016847016632236773
[Epoch 20, Batch 900] loss: 0.010997150372131727
[Epoch 20, Batch 1000] loss: 0.014900725584120665
[Epoch 20, Batch 1100] loss: 0.018695249226148007
[Epoch 20, Batch 1200] loss: 0.02210803837457206
[Epoch 20, Batch 1300] loss: 0.014204217288424843
[Epoch 20, Batch 1400] loss: 0.01857954305683961
[Epoch 20, Batch 1500] loss: 0.016368946015863913
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9867
Overfitting: 0.0480
[Epoch 21, Batch 100] loss: 0.015765212512778817
[Epoch 21, Batch 200] loss: 0.013658446858316893
[Epoch 21, Batch 300] loss: 0.009230530939894378
[Epoch 21, Batch 400] loss: 0.015770312568638475
[Epoch 21, Batch 500] loss: 0.01517332939831249
[Epoch 21, Batch 600] loss: 0.00991790712083457
[Epoch 21, Batch 700] loss: 0.010431804177133018
[Epoch 21, Batch 800] loss: 0.014213686781149591
[Epoch 21, Batch 900] loss: 0.012852048775021102
[Epoch 21, Batch 1000] loss: 0.015257423823059071
[Epoch 21, Batch 1100] loss: 0.010574734010951943
[Epoch 21, Batch 1200] loss: 0.011675621160466108
[Epoch 21, Batch 1300] loss: 0.017251835351780754
[Epoch 21, Batch 1400] loss: 0.01543001700512832
[Epoch 21, Batch 1500] loss: 0.018499838792122317
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9875
Overfitting: 0.0492
[Epoch 22, Batch 100] loss: 0.010233570017953752
[Epoch 22, Batch 200] loss: 0.010297458363129407
[Epoch 22, Batch 300] loss: 0.010131580283632502
[Epoch 22, Batch 400] loss: 0.008237852468737402
[Epoch 22, Batch 500] loss: 0.014560643958830041
[Epoch 22, Batch 600] loss: 0.010329672404004668
[Epoch 22, Batch 700] loss: 0.008624903977906797
[Epoch 22, Batch 800] loss: 0.011646739802672527
[Epoch 22, Batch 900] loss: 0.011192095599253661
[Epoch 22, Batch 1000] loss: 0.018086497730982955
[Epoch 22, Batch 1100] loss: 0.012936330781994911
[Epoch 22, Batch 1200] loss: 0.016731231701996876
[Epoch 22, Batch 1300] loss: 0.010544837792913313
[Epoch 22, Batch 1400] loss: 0.01788143462690641
[Epoch 22, Batch 1500] loss: 0.013991601251036627
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9862
Overfitting: 0.0508
[Epoch 23, Batch 100] loss: 0.010077266212829273
[Epoch 23, Batch 200] loss: 0.007499206675274764
[Epoch 23, Batch 300] loss: 0.012671687807305716
[Epoch 23, Batch 400] loss: 0.011460346486855996
[Epoch 23, Batch 500] loss: 0.01404253090993734
[Epoch 23, Batch 600] loss: 0.012067813452558767
[Epoch 23, Batch 700] loss: 0.010866234307322885
[Epoch 23, Batch 800] loss: 0.012631375168421072
[Epoch 23, Batch 900] loss: 0.01254123251295823
[Epoch 23, Batch 1000] loss: 0.012282002718784497
[Epoch 23, Batch 1100] loss: 0.012628696097799548
[Epoch 23, Batch 1200] loss: 0.010023043534911267
[Epoch 23, Batch 1300] loss: 0.012469623204015078
[Epoch 23, Batch 1400] loss: 0.014070099580949317
[Epoch 23, Batch 1500] loss: 0.010592370807644328
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9882
Overfitting: 0.0462
Best model saved at epoch 23 with validation loss: 0.0462
[Epoch 24, Batch 100] loss: 0.007440156472002854
[Epoch 24, Batch 200] loss: 0.007696230776491575
[Epoch 24, Batch 300] loss: 0.005606807878793915
[Epoch 24, Batch 400] loss: 0.014339410231586953
[Epoch 24, Batch 500] loss: 0.011853545244375709
[Epoch 24, Batch 600] loss: 0.01013859355749446
[Epoch 24, Batch 700] loss: 0.012448238840879639
[Epoch 24, Batch 800] loss: 0.011402871189347933
[Epoch 24, Batch 900] loss: 0.011438168779786793
[Epoch 24, Batch 1000] loss: 0.008818371068991837
[Epoch 24, Batch 1100] loss: 0.011668485346308443
[Epoch 24, Batch 1200] loss: 0.00944052685619681
[Epoch 24, Batch 1300] loss: 0.010593535378793604
[Epoch 24, Batch 1400] loss: 0.009503343040996697
[Epoch 24, Batch 1500] loss: 0.011718538606219226
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9867
Overfitting: 0.0504
Fold 3 validation loss: 0.0504
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.3058638191223144
[Epoch 1, Batch 200] loss: 2.2894966530799867
[Epoch 1, Batch 300] loss: 2.264629476070404
[Epoch 1, Batch 400] loss: 2.2026992774009706
[Epoch 1, Batch 500] loss: 1.8880085504055024
[Epoch 1, Batch 600] loss: 0.9741430750489235
[Epoch 1, Batch 700] loss: 0.5953765946626663
[Epoch 1, Batch 800] loss: 0.5267807486653328
[Epoch 1, Batch 900] loss: 0.3950635112076998
[Epoch 1, Batch 1000] loss: 0.39499163754284383
[Epoch 1, Batch 1100] loss: 0.3395973901450634
[Epoch 1, Batch 1200] loss: 0.3335380393266678
[Epoch 1, Batch 1300] loss: 0.3014499832689762
[Epoch 1, Batch 1400] loss: 0.2850456625968218
[Epoch 1, Batch 1500] loss: 0.2805981807783246
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2701
Validation Accuracy: 0.9157
Overfitting: 0.2701
Best model saved at epoch 1 with validation loss: 0.2701
[Epoch 2, Batch 100] loss: 0.25293800510466097
[Epoch 2, Batch 200] loss: 0.2254241456091404
[Epoch 2, Batch 300] loss: 0.22957427855581045
[Epoch 2, Batch 400] loss: 0.21564365696161986
[Epoch 2, Batch 500] loss: 0.20918201863765717
[Epoch 2, Batch 600] loss: 0.18591905364766717
[Epoch 2, Batch 700] loss: 0.19327842408791185
[Epoch 2, Batch 800] loss: 0.18946500290185214
[Epoch 2, Batch 900] loss: 0.1911341997794807
[Epoch 2, Batch 1000] loss: 0.15126206303015352
[Epoch 2, Batch 1100] loss: 0.14959023039788008
[Epoch 2, Batch 1200] loss: 0.15249014243483544
[Epoch 2, Batch 1300] loss: 0.14679539355449378
[Epoch 2, Batch 1400] loss: 0.16357545960694553
[Epoch 2, Batch 1500] loss: 0.15189470602199434
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1492
Validation Accuracy: 0.9525
Overfitting: 0.1492
Best model saved at epoch 2 with validation loss: 0.1492
[Epoch 3, Batch 100] loss: 0.1240838679112494
[Epoch 3, Batch 200] loss: 0.1395096040330827
[Epoch 3, Batch 300] loss: 0.11918189929798245
[Epoch 3, Batch 400] loss: 0.12750277905724944
[Epoch 3, Batch 500] loss: 0.12856699207331984
[Epoch 3, Batch 600] loss: 0.1321345524676144
[Epoch 3, Batch 700] loss: 0.11052753176540137
[Epoch 3, Batch 800] loss: 0.13153590911068022
[Epoch 3, Batch 900] loss: 0.11003035777248442
[Epoch 3, Batch 1000] loss: 0.1246681932033971
[Epoch 3, Batch 1100] loss: 0.10180241607595235
[Epoch 3, Batch 1200] loss: 0.13478952527977525
[Epoch 3, Batch 1300] loss: 0.10243043858092278
[Epoch 3, Batch 1400] loss: 0.0916975567676127
[Epoch 3, Batch 1500] loss: 0.1177447699289769
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1068
Validation Accuracy: 0.9670
Overfitting: 0.1068
Best model saved at epoch 3 with validation loss: 0.1068
[Epoch 4, Batch 100] loss: 0.10488733707927167
[Epoch 4, Batch 200] loss: 0.10428840680979193
[Epoch 4, Batch 300] loss: 0.10028058569412679
[Epoch 4, Batch 400] loss: 0.08278307136148215
[Epoch 4, Batch 500] loss: 0.09720798015594483
[Epoch 4, Batch 600] loss: 0.0852642554952763
[Epoch 4, Batch 700] loss: 0.09302845316939055
[Epoch 4, Batch 800] loss: 0.09466888516675681
[Epoch 4, Batch 900] loss: 0.08388185651041567
[Epoch 4, Batch 1000] loss: 0.09150264152791351
[Epoch 4, Batch 1100] loss: 0.09189563151914626
[Epoch 4, Batch 1200] loss: 0.0923334159492515
[Epoch 4, Batch 1300] loss: 0.0859302237816155
[Epoch 4, Batch 1400] loss: 0.0864942762395367
[Epoch 4, Batch 1500] loss: 0.08385512981563807
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0906
Validation Accuracy: 0.9717
Overfitting: 0.0906
Best model saved at epoch 4 with validation loss: 0.0906
[Epoch 5, Batch 100] loss: 0.07311951150419191
[Epoch 5, Batch 200] loss: 0.08203650020528584
[Epoch 5, Batch 300] loss: 0.08948090507183223
[Epoch 5, Batch 400] loss: 0.07433455430902541
[Epoch 5, Batch 500] loss: 0.08388925391249359
[Epoch 5, Batch 600] loss: 0.08212925211992114
[Epoch 5, Batch 700] loss: 0.06869312352966517
[Epoch 5, Batch 800] loss: 0.06989966481225565
[Epoch 5, Batch 900] loss: 0.0758593640034087
[Epoch 5, Batch 1000] loss: 0.0769762050686404
[Epoch 5, Batch 1100] loss: 0.08019497928209603
[Epoch 5, Batch 1200] loss: 0.0781102415244095
[Epoch 5, Batch 1300] loss: 0.06997750354465097
[Epoch 5, Batch 1400] loss: 0.07557656357996166
[Epoch 5, Batch 1500] loss: 0.07575209422502667
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0705
Validation Accuracy: 0.9792
Overfitting: 0.0705
Best model saved at epoch 5 with validation loss: 0.0705
[Epoch 6, Batch 100] loss: 0.07766455885022878
[Epoch 6, Batch 200] loss: 0.06351105829933658
[Epoch 6, Batch 300] loss: 0.06193450751365162
[Epoch 6, Batch 400] loss: 0.05356946835643612
[Epoch 6, Batch 500] loss: 0.06659391476772726
[Epoch 6, Batch 600] loss: 0.06441566747264005
[Epoch 6, Batch 700] loss: 0.07933331637526862
[Epoch 6, Batch 800] loss: 0.06489404101623222
[Epoch 6, Batch 900] loss: 0.06403406872181222
[Epoch 6, Batch 1000] loss: 0.062077756368089466
[Epoch 6, Batch 1100] loss: 0.06026630006497726
[Epoch 6, Batch 1200] loss: 0.08235068460460752
[Epoch 6, Batch 1300] loss: 0.0668854960706085
[Epoch 6, Batch 1400] loss: 0.08311986218905076
[Epoch 6, Batch 1500] loss: 0.055926321130245926
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0653
Validation Accuracy: 0.9811
Overfitting: 0.0653
Best model saved at epoch 6 with validation loss: 0.0653
[Epoch 7, Batch 100] loss: 0.06264218323980458
[Epoch 7, Batch 200] loss: 0.05343561122892424
[Epoch 7, Batch 300] loss: 0.05023761621094309
[Epoch 7, Batch 400] loss: 0.0652366547944257
[Epoch 7, Batch 500] loss: 0.058688312120502815
[Epoch 7, Batch 600] loss: 0.05432335676741786
[Epoch 7, Batch 700] loss: 0.06274138570763171
[Epoch 7, Batch 800] loss: 0.04795277217170223
[Epoch 7, Batch 900] loss: 0.06124805014580488
[Epoch 7, Batch 1000] loss: 0.05716065328684636
[Epoch 7, Batch 1100] loss: 0.06835214055376128
[Epoch 7, Batch 1200] loss: 0.04926785510033369
[Epoch 7, Batch 1300] loss: 0.061695115092443305
[Epoch 7, Batch 1400] loss: 0.05349872008198872
[Epoch 7, Batch 1500] loss: 0.06932995221810416
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0659
Validation Accuracy: 0.9786
Overfitting: 0.0659
[Epoch 8, Batch 100] loss: 0.050749439999926836
[Epoch 8, Batch 200] loss: 0.04192963613662869
[Epoch 8, Batch 300] loss: 0.047285518418066205
[Epoch 8, Batch 400] loss: 0.04654813831206411
[Epoch 8, Batch 500] loss: 0.05813121663639322
[Epoch 8, Batch 600] loss: 0.06577707842923701
[Epoch 8, Batch 700] loss: 0.048224914122838525
[Epoch 8, Batch 800] loss: 0.0517089789477177
[Epoch 8, Batch 900] loss: 0.048812531746225435
[Epoch 8, Batch 1000] loss: 0.055902714754338376
[Epoch 8, Batch 1100] loss: 0.05255392594146542
[Epoch 8, Batch 1200] loss: 0.049071093405946155
[Epoch 8, Batch 1300] loss: 0.052783043587114664
[Epoch 8, Batch 1400] loss: 0.04350355655769818
[Epoch 8, Batch 1500] loss: 0.059070947640575466
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9812
Overfitting: 0.0605
Best model saved at epoch 8 with validation loss: 0.0605
[Epoch 9, Batch 100] loss: 0.04973481897613965
[Epoch 9, Batch 200] loss: 0.050897158762672916
[Epoch 9, Batch 300] loss: 0.04568791585508734
[Epoch 9, Batch 400] loss: 0.05409034897747915
[Epoch 9, Batch 500] loss: 0.051629159883596
[Epoch 9, Batch 600] loss: 0.04747459765028907
[Epoch 9, Batch 700] loss: 0.04286365112871863
[Epoch 9, Batch 800] loss: 0.04446964626549743
[Epoch 9, Batch 900] loss: 0.04743590535596013
[Epoch 9, Batch 1000] loss: 0.04804390101111494
[Epoch 9, Batch 1100] loss: 0.0442792948835995
[Epoch 9, Batch 1200] loss: 0.05121110422944184
[Epoch 9, Batch 1300] loss: 0.029090324975550176
[Epoch 9, Batch 1400] loss: 0.04749023216892965
[Epoch 9, Batch 1500] loss: 0.045024157565494535
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0757
Validation Accuracy: 0.9766
Overfitting: 0.0757
[Epoch 10, Batch 100] loss: 0.039009488261071965
[Epoch 10, Batch 200] loss: 0.029402295844629407
[Epoch 10, Batch 300] loss: 0.035941440136521126
[Epoch 10, Batch 400] loss: 0.03960160840069875
[Epoch 10, Batch 500] loss: 0.036810362985124814
[Epoch 10, Batch 600] loss: 0.03914192237600218
[Epoch 10, Batch 700] loss: 0.04450650334067177
[Epoch 10, Batch 800] loss: 0.04884943749057129
[Epoch 10, Batch 900] loss: 0.03733703356818296
[Epoch 10, Batch 1000] loss: 0.047551384438993406
[Epoch 10, Batch 1100] loss: 0.04110926379857119
[Epoch 10, Batch 1200] loss: 0.04181791609735228
[Epoch 10, Batch 1300] loss: 0.04301003581495024
[Epoch 10, Batch 1400] loss: 0.03901864843908697
[Epoch 10, Batch 1500] loss: 0.05240795267163776
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9836
Overfitting: 0.0538
Best model saved at epoch 10 with validation loss: 0.0538
[Epoch 11, Batch 100] loss: 0.03440449403249659
[Epoch 11, Batch 200] loss: 0.04129421942139743
[Epoch 11, Batch 300] loss: 0.04253330365289003
[Epoch 11, Batch 400] loss: 0.037481814419152215
[Epoch 11, Batch 500] loss: 0.03788480563787743
[Epoch 11, Batch 600] loss: 0.03489111890725326
[Epoch 11, Batch 700] loss: 0.03440135865937918
[Epoch 11, Batch 800] loss: 0.032571713365614416
[Epoch 11, Batch 900] loss: 0.03612101526523474
[Epoch 11, Batch 1000] loss: 0.03895561729208566
[Epoch 11, Batch 1100] loss: 0.031440360257402065
[Epoch 11, Batch 1200] loss: 0.03919575355626875
[Epoch 11, Batch 1300] loss: 0.049304371832404284
[Epoch 11, Batch 1400] loss: 0.0291023246748955
[Epoch 11, Batch 1500] loss: 0.04035556924296543
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9829
Overfitting: 0.0551
[Epoch 12, Batch 100] loss: 0.03198312494554557
[Epoch 12, Batch 200] loss: 0.028510917159728706
[Epoch 12, Batch 300] loss: 0.0393534096213989
[Epoch 12, Batch 400] loss: 0.03395000631950097
[Epoch 12, Batch 500] loss: 0.03592656538443407
[Epoch 12, Batch 600] loss: 0.04154267425183207
[Epoch 12, Batch 700] loss: 0.032900408752029764
[Epoch 12, Batch 800] loss: 0.039357346612378025
[Epoch 12, Batch 900] loss: 0.036254192907363175
[Epoch 12, Batch 1000] loss: 0.03840616933448473
[Epoch 12, Batch 1100] loss: 0.027882654922432266
[Epoch 12, Batch 1200] loss: 0.03849240642914083
[Epoch 12, Batch 1300] loss: 0.035805412768968384
[Epoch 12, Batch 1400] loss: 0.03339998364041094
[Epoch 12, Batch 1500] loss: 0.030418389724218287
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9838
Overfitting: 0.0522
Best model saved at epoch 12 with validation loss: 0.0522
[Epoch 13, Batch 100] loss: 0.03389297120738775
[Epoch 13, Batch 200] loss: 0.030974345620488748
[Epoch 13, Batch 300] loss: 0.0345308654155815
[Epoch 13, Batch 400] loss: 0.023600655810150785
[Epoch 13, Batch 500] loss: 0.03510536117479205
[Epoch 13, Batch 600] loss: 0.026264941160334274
[Epoch 13, Batch 700] loss: 0.027510301937290933
[Epoch 13, Batch 800] loss: 0.029400866489158944
[Epoch 13, Batch 900] loss: 0.029634712964762003
[Epoch 13, Batch 1000] loss: 0.026538393163937146
[Epoch 13, Batch 1100] loss: 0.029683920320821927
[Epoch 13, Batch 1200] loss: 0.03798055727456813
[Epoch 13, Batch 1300] loss: 0.04040854334685719
[Epoch 13, Batch 1400] loss: 0.02900105857377639
[Epoch 13, Batch 1500] loss: 0.03412280159740476
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9841
Overfitting: 0.0539
[Epoch 14, Batch 100] loss: 0.017209595325984994
[Epoch 14, Batch 200] loss: 0.03445065043284558
[Epoch 14, Batch 300] loss: 0.03157077866664622
[Epoch 14, Batch 400] loss: 0.024995218355907126
[Epoch 14, Batch 500] loss: 0.03300177618890302
[Epoch 14, Batch 600] loss: 0.03350486757903127
[Epoch 14, Batch 700] loss: 0.03030598372395616
[Epoch 14, Batch 800] loss: 0.02212960719829425
[Epoch 14, Batch 900] loss: 0.030696161860250867
[Epoch 14, Batch 1000] loss: 0.024647248846886214
[Epoch 14, Batch 1100] loss: 0.01859102605958469
[Epoch 14, Batch 1200] loss: 0.019888808616087772
[Epoch 14, Batch 1300] loss: 0.02512037270644214
[Epoch 14, Batch 1400] loss: 0.04008020254317671
[Epoch 14, Batch 1500] loss: 0.034884879470919256
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9848
Overfitting: 0.0527
[Epoch 15, Batch 100] loss: 0.022438453593058513
[Epoch 15, Batch 200] loss: 0.016827052088046912
[Epoch 15, Batch 300] loss: 0.02952913533197716
[Epoch 15, Batch 400] loss: 0.02383157207572367
[Epoch 15, Batch 500] loss: 0.019824808776029386
[Epoch 15, Batch 600] loss: 0.02969045274920063
[Epoch 15, Batch 700] loss: 0.02617758402659092
[Epoch 15, Batch 800] loss: 0.024879539113608188
[Epoch 15, Batch 900] loss: 0.031222844247095052
[Epoch 15, Batch 1000] loss: 0.02524289830122143
[Epoch 15, Batch 1100] loss: 0.0252434387752146
[Epoch 15, Batch 1200] loss: 0.027593378631281668
[Epoch 15, Batch 1300] loss: 0.030968889215728268
[Epoch 15, Batch 1400] loss: 0.02002774756998406
[Epoch 15, Batch 1500] loss: 0.024400984747335316
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9859
Overfitting: 0.0478
Best model saved at epoch 15 with validation loss: 0.0478
[Epoch 16, Batch 100] loss: 0.021861135563231073
[Epoch 16, Batch 200] loss: 0.023912050069775433
[Epoch 16, Batch 300] loss: 0.031228688708215487
[Epoch 16, Batch 400] loss: 0.019639196812640876
[Epoch 16, Batch 500] loss: 0.015851682496722787
[Epoch 16, Batch 600] loss: 0.01912402160705824
[Epoch 16, Batch 700] loss: 0.03140047301145387
[Epoch 16, Batch 800] loss: 0.02423763032973511
[Epoch 16, Batch 900] loss: 0.026118727084831334
[Epoch 16, Batch 1000] loss: 0.021013072807400023
[Epoch 16, Batch 1100] loss: 0.026775651678472057
[Epoch 16, Batch 1200] loss: 0.01731903252162738
[Epoch 16, Batch 1300] loss: 0.022180042817635696
[Epoch 16, Batch 1400] loss: 0.02103203468286665
[Epoch 16, Batch 1500] loss: 0.027572320404287892
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9844
Overfitting: 0.0526
[Epoch 17, Batch 100] loss: 0.02074039483923116
[Epoch 17, Batch 200] loss: 0.028354387572835548
[Epoch 17, Batch 300] loss: 0.018015843530010896
[Epoch 17, Batch 400] loss: 0.016531231621629557
[Epoch 17, Batch 500] loss: 0.01666610560991103
[Epoch 17, Batch 600] loss: 0.01705464204074815
[Epoch 17, Batch 700] loss: 0.021433883857753244
[Epoch 17, Batch 800] loss: 0.02572611403709743
[Epoch 17, Batch 900] loss: 0.01722318002473912
[Epoch 17, Batch 1000] loss: 0.023431528296350736
[Epoch 17, Batch 1100] loss: 0.023653629610780626
[Epoch 17, Batch 1200] loss: 0.022865922708369908
[Epoch 17, Batch 1300] loss: 0.019959808285930195
[Epoch 17, Batch 1400] loss: 0.022368056165869347
[Epoch 17, Batch 1500] loss: 0.017295195379119832
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0565
Validation Accuracy: 0.9838
Overfitting: 0.0565
[Epoch 18, Batch 100] loss: 0.020482227245229297
[Epoch 18, Batch 200] loss: 0.016722233552864053
[Epoch 18, Batch 300] loss: 0.022671022553695366
[Epoch 18, Batch 400] loss: 0.01596933647109836
[Epoch 18, Batch 500] loss: 0.017094553448841907
[Epoch 18, Batch 600] loss: 0.015051580539293355
[Epoch 18, Batch 700] loss: 0.022021288854739397
[Epoch 18, Batch 800] loss: 0.023271683100465453
[Epoch 18, Batch 900] loss: 0.01837112232329673
[Epoch 18, Batch 1000] loss: 0.018920645420148503
[Epoch 18, Batch 1100] loss: 0.011194646357726015
[Epoch 18, Batch 1200] loss: 0.02460562567866873
[Epoch 18, Batch 1300] loss: 0.022760276820044965
[Epoch 18, Batch 1400] loss: 0.024040995770483277
[Epoch 18, Batch 1500] loss: 0.015287464736538824
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9860
Overfitting: 0.0513
[Epoch 19, Batch 100] loss: 0.013967247766122454
[Epoch 19, Batch 200] loss: 0.014287081096335896
[Epoch 19, Batch 300] loss: 0.012736971401027404
[Epoch 19, Batch 400] loss: 0.018489354956691385
[Epoch 19, Batch 500] loss: 0.021001073507068212
[Epoch 19, Batch 600] loss: 0.016335632614718633
[Epoch 19, Batch 700] loss: 0.020377112214264345
[Epoch 19, Batch 800] loss: 0.014008215977446526
[Epoch 19, Batch 900] loss: 0.014949011358767165
[Epoch 19, Batch 1000] loss: 0.015596184177702525
[Epoch 19, Batch 1100] loss: 0.01818145892728353
[Epoch 19, Batch 1200] loss: 0.01519036006735405
[Epoch 19, Batch 1300] loss: 0.02742242835010984
[Epoch 19, Batch 1400] loss: 0.01567864138749428
[Epoch 19, Batch 1500] loss: 0.02456029831279011
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9858
Overfitting: 0.0496
[Epoch 20, Batch 100] loss: 0.009494907029293245
[Epoch 20, Batch 200] loss: 0.018565262560659903
[Epoch 20, Batch 300] loss: 0.01809214658176643
[Epoch 20, Batch 400] loss: 0.011234970129153225
[Epoch 20, Batch 500] loss: 0.01610329193768848
[Epoch 20, Batch 600] loss: 0.01067086082228343
[Epoch 20, Batch 700] loss: 0.013060548228095286
[Epoch 20, Batch 800] loss: 0.016541958538946345
[Epoch 20, Batch 900] loss: 0.013981013353113667
[Epoch 20, Batch 1000] loss: 0.018595207880280212
[Epoch 20, Batch 1100] loss: 0.015087489406432723
[Epoch 20, Batch 1200] loss: 0.01842945110081928
[Epoch 20, Batch 1300] loss: 0.01931063642652589
[Epoch 20, Batch 1400] loss: 0.021640601881954352
[Epoch 20, Batch 1500] loss: 0.01274869685221347
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9860
Overfitting: 0.0486
[Epoch 21, Batch 100] loss: 0.011453208093917056
[Epoch 21, Batch 200] loss: 0.010318164789496223
[Epoch 21, Batch 300] loss: 0.012047756070096512
[Epoch 21, Batch 400] loss: 0.014035314695211127
[Epoch 21, Batch 500] loss: 0.015162568418309092
[Epoch 21, Batch 600] loss: 0.017193326322740177
[Epoch 21, Batch 700] loss: 0.014432652319446787
[Epoch 21, Batch 800] loss: 0.010650604156180634
[Epoch 21, Batch 900] loss: 0.02087583397049457
[Epoch 21, Batch 1000] loss: 0.0165437655173082
[Epoch 21, Batch 1100] loss: 0.01002339565580769
[Epoch 21, Batch 1200] loss: 0.015770855515875155
[Epoch 21, Batch 1300] loss: 0.013431759602026432
[Epoch 21, Batch 1400] loss: 0.017071957906591707
[Epoch 21, Batch 1500] loss: 0.0184044331102632
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9868
Overfitting: 0.0501
[Epoch 22, Batch 100] loss: 0.01021110140492965
[Epoch 22, Batch 200] loss: 0.007339517822656489
[Epoch 22, Batch 300] loss: 0.017573115352242895
[Epoch 22, Batch 400] loss: 0.015702941521303727
[Epoch 22, Batch 500] loss: 0.012694598159250746
[Epoch 22, Batch 600] loss: 0.012372977068225736
[Epoch 22, Batch 700] loss: 0.016891578441500313
[Epoch 22, Batch 800] loss: 0.012836051413687528
[Epoch 22, Batch 900] loss: 0.013898872087156632
[Epoch 22, Batch 1000] loss: 0.016710051920854313
[Epoch 22, Batch 1100] loss: 0.023283877216163092
[Epoch 22, Batch 1200] loss: 0.01394095873536571
[Epoch 22, Batch 1300] loss: 0.010002006169561355
[Epoch 22, Batch 1400] loss: 0.01205432088499947
[Epoch 22, Batch 1500] loss: 0.0194687955466361
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9858
Overfitting: 0.0520
[Epoch 23, Batch 100] loss: 0.014432544256706023
[Epoch 23, Batch 200] loss: 0.011727264846413163
[Epoch 23, Batch 300] loss: 0.008126290819927818
[Epoch 23, Batch 400] loss: 0.009425655925915634
[Epoch 23, Batch 500] loss: 0.016773953472329593
[Epoch 23, Batch 600] loss: 0.009890502552443649
[Epoch 23, Batch 700] loss: 0.011832894765539094
[Epoch 23, Batch 800] loss: 0.009204884491336997
[Epoch 23, Batch 900] loss: 0.01365988250447117
[Epoch 23, Batch 1000] loss: 0.008457818532042439
[Epoch 23, Batch 1100] loss: 0.010845489333150908
[Epoch 23, Batch 1200] loss: 0.008141698543986421
[Epoch 23, Batch 1300] loss: 0.02163071342754847
[Epoch 23, Batch 1400] loss: 0.012783277446287685
[Epoch 23, Batch 1500] loss: 0.014260298080407664
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9871
Overfitting: 0.0466
Best model saved at epoch 23 with validation loss: 0.0466
[Epoch 24, Batch 100] loss: 0.00796643691486679
[Epoch 24, Batch 200] loss: 0.010823130956578098
[Epoch 24, Batch 300] loss: 0.007577901388285682
[Epoch 24, Batch 400] loss: 0.011584325605581399
[Epoch 24, Batch 500] loss: 0.014143258516778588
[Epoch 24, Batch 600] loss: 0.015265579604165396
[Epoch 24, Batch 700] loss: 0.008338555348091177
[Epoch 24, Batch 800] loss: 0.011086136744124815
[Epoch 24, Batch 900] loss: 0.01001650224417972
[Epoch 24, Batch 1000] loss: 0.009498029605765623
[Epoch 24, Batch 1100] loss: 0.01212993485170955
[Epoch 24, Batch 1200] loss: 0.01675259119583643
[Epoch 24, Batch 1300] loss: 0.011804764185926615
[Epoch 24, Batch 1400] loss: 0.013214047864348686
[Epoch 24, Batch 1500] loss: 0.008917887405696092
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0558
Validation Accuracy: 0.9849
Overfitting: 0.0558
Fold 4 validation loss: 0.0558
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2995192193984986
[Epoch 1, Batch 200] loss: 2.2881510710716246
[Epoch 1, Batch 300] loss: 2.2706405782699584
[Epoch 1, Batch 400] loss: 2.225521569252014
[Epoch 1, Batch 500] loss: 2.0275635063648223
[Epoch 1, Batch 600] loss: 1.2125890964269639
[Epoch 1, Batch 700] loss: 0.6950449720025063
[Epoch 1, Batch 800] loss: 0.5520950794219971
[Epoch 1, Batch 900] loss: 0.46734596997499467
[Epoch 1, Batch 1000] loss: 0.39905856594443323
[Epoch 1, Batch 1100] loss: 0.36365561820566655
[Epoch 1, Batch 1200] loss: 0.35316612891852855
[Epoch 1, Batch 1300] loss: 0.3195749557763338
[Epoch 1, Batch 1400] loss: 0.30300937354564667
[Epoch 1, Batch 1500] loss: 0.2782844127714634
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2986
Validation Accuracy: 0.9133
Overfitting: 0.2986
Best model saved at epoch 1 with validation loss: 0.2986
[Epoch 2, Batch 100] loss: 0.3029748698696494
[Epoch 2, Batch 200] loss: 0.23699721500277518
[Epoch 2, Batch 300] loss: 0.24746378250420092
[Epoch 2, Batch 400] loss: 0.24067324899137021
[Epoch 2, Batch 500] loss: 0.2017315094731748
[Epoch 2, Batch 600] loss: 0.22569827988743782
[Epoch 2, Batch 700] loss: 0.19954156380146743
[Epoch 2, Batch 800] loss: 0.18984746454283596
[Epoch 2, Batch 900] loss: 0.2035817443020642
[Epoch 2, Batch 1000] loss: 0.18902803130447865
[Epoch 2, Batch 1100] loss: 0.17742976982146502
[Epoch 2, Batch 1200] loss: 0.15769816670566797
[Epoch 2, Batch 1300] loss: 0.17986625880002977
[Epoch 2, Batch 1400] loss: 0.1482653759419918
[Epoch 2, Batch 1500] loss: 0.1408019951079041
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1373
Validation Accuracy: 0.9603
Overfitting: 0.1373
Best model saved at epoch 2 with validation loss: 0.1373
[Epoch 3, Batch 100] loss: 0.14400708957575262
[Epoch 3, Batch 200] loss: 0.13659062379039824
[Epoch 3, Batch 300] loss: 0.12727721109986306
[Epoch 3, Batch 400] loss: 0.11299953577108682
[Epoch 3, Batch 500] loss: 0.15408038329333068
[Epoch 3, Batch 600] loss: 0.11963052273262292
[Epoch 3, Batch 700] loss: 0.1146845771651715
[Epoch 3, Batch 800] loss: 0.12332472402602435
[Epoch 3, Batch 900] loss: 0.1241356992162764
[Epoch 3, Batch 1000] loss: 0.11061645197682082
[Epoch 3, Batch 1100] loss: 0.10857302433811128
[Epoch 3, Batch 1200] loss: 0.10956062902929262
[Epoch 3, Batch 1300] loss: 0.10193054425530136
[Epoch 3, Batch 1400] loss: 0.11823787803761661
[Epoch 3, Batch 1500] loss: 0.09791616548784077
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1059
Validation Accuracy: 0.9696
Overfitting: 0.1059
Best model saved at epoch 3 with validation loss: 0.1059
[Epoch 4, Batch 100] loss: 0.08872679668478668
[Epoch 4, Batch 200] loss: 0.08405439146794379
[Epoch 4, Batch 300] loss: 0.10352059736847878
[Epoch 4, Batch 400] loss: 0.08994063138961791
[Epoch 4, Batch 500] loss: 0.097647121893242
[Epoch 4, Batch 600] loss: 0.08606895656324923
[Epoch 4, Batch 700] loss: 0.08700925662647933
[Epoch 4, Batch 800] loss: 0.08392419495619834
[Epoch 4, Batch 900] loss: 0.1058123034145683
[Epoch 4, Batch 1000] loss: 0.09566290681716055
[Epoch 4, Batch 1100] loss: 0.08486408185679466
[Epoch 4, Batch 1200] loss: 0.09908776469528675
[Epoch 4, Batch 1300] loss: 0.074236941607669
[Epoch 4, Batch 1400] loss: 0.08629382468527183
[Epoch 4, Batch 1500] loss: 0.07316900809295475
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0847
Validation Accuracy: 0.9730
Overfitting: 0.0847
Best model saved at epoch 4 with validation loss: 0.0847
[Epoch 5, Batch 100] loss: 0.0849067620653659
[Epoch 5, Batch 200] loss: 0.08238840385340154
[Epoch 5, Batch 300] loss: 0.07907414120621979
[Epoch 5, Batch 400] loss: 0.0743613561638631
[Epoch 5, Batch 500] loss: 0.06489981286460533
[Epoch 5, Batch 600] loss: 0.07354586669243872
[Epoch 5, Batch 700] loss: 0.07731266312301159
[Epoch 5, Batch 800] loss: 0.07379414781928062
[Epoch 5, Batch 900] loss: 0.07362593142781407
[Epoch 5, Batch 1000] loss: 0.07743847724050283
[Epoch 5, Batch 1100] loss: 0.06643486075801774
[Epoch 5, Batch 1200] loss: 0.06947345634456724
[Epoch 5, Batch 1300] loss: 0.045497832513647155
[Epoch 5, Batch 1400] loss: 0.06941639883443713
[Epoch 5, Batch 1500] loss: 0.07582440595375374
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0685
Validation Accuracy: 0.9789
Overfitting: 0.0685
Best model saved at epoch 5 with validation loss: 0.0685
[Epoch 6, Batch 100] loss: 0.04804413013858721
[Epoch 6, Batch 200] loss: 0.06975429299520329
[Epoch 6, Batch 300] loss: 0.062184415655210615
[Epoch 6, Batch 400] loss: 0.06517396344337613
[Epoch 6, Batch 500] loss: 0.06320039775106125
[Epoch 6, Batch 600] loss: 0.060021787534933535
[Epoch 6, Batch 700] loss: 0.05249718208564445
[Epoch 6, Batch 800] loss: 0.0538973645796068
[Epoch 6, Batch 900] loss: 0.06461818963522091
[Epoch 6, Batch 1000] loss: 0.06705359009560198
[Epoch 6, Batch 1100] loss: 0.05961954967235215
[Epoch 6, Batch 1200] loss: 0.06095434911781922
[Epoch 6, Batch 1300] loss: 0.060513645802857355
[Epoch 6, Batch 1400] loss: 0.05985964606748894
[Epoch 6, Batch 1500] loss: 0.06730938523542136
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0648
Validation Accuracy: 0.9798
Overfitting: 0.0648
Best model saved at epoch 6 with validation loss: 0.0648
[Epoch 7, Batch 100] loss: 0.057956821362022314
[Epoch 7, Batch 200] loss: 0.051065646880306306
[Epoch 7, Batch 300] loss: 0.040166344571625816
[Epoch 7, Batch 400] loss: 0.04760107793728821
[Epoch 7, Batch 500] loss: 0.051988130763638764
[Epoch 7, Batch 600] loss: 0.04759518001461402
[Epoch 7, Batch 700] loss: 0.05815532051492482
[Epoch 7, Batch 800] loss: 0.04572291016229428
[Epoch 7, Batch 900] loss: 0.05158395503822248
[Epoch 7, Batch 1000] loss: 0.05477027099346742
[Epoch 7, Batch 1100] loss: 0.05370678309816867
[Epoch 7, Batch 1200] loss: 0.06512540150841233
[Epoch 7, Batch 1300] loss: 0.05819603365147486
[Epoch 7, Batch 1400] loss: 0.056037379449699075
[Epoch 7, Batch 1500] loss: 0.0476360215828754
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9816
Overfitting: 0.0586
Best model saved at epoch 7 with validation loss: 0.0586
[Epoch 8, Batch 100] loss: 0.03980545447673649
[Epoch 8, Batch 200] loss: 0.04219866388710216
[Epoch 8, Batch 300] loss: 0.04711702376720495
[Epoch 8, Batch 400] loss: 0.04293383854208514
[Epoch 8, Batch 500] loss: 0.04004329599672928
[Epoch 8, Batch 600] loss: 0.037955859258072454
[Epoch 8, Batch 700] loss: 0.0456056573416572
[Epoch 8, Batch 800] loss: 0.05282864314969629
[Epoch 8, Batch 900] loss: 0.04517046957858838
[Epoch 8, Batch 1000] loss: 0.040768608548678455
[Epoch 8, Batch 1100] loss: 0.038544354459736495
[Epoch 8, Batch 1200] loss: 0.05508329029195011
[Epoch 8, Batch 1300] loss: 0.05444241347373463
[Epoch 8, Batch 1400] loss: 0.05673929307959043
[Epoch 8, Batch 1500] loss: 0.052502548719057816
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0740
Validation Accuracy: 0.9765
Overfitting: 0.0740
[Epoch 9, Batch 100] loss: 0.04252290477510542
[Epoch 9, Batch 200] loss: 0.04238518739701249
[Epoch 9, Batch 300] loss: 0.03709801388817141
[Epoch 9, Batch 400] loss: 0.03749683929258026
[Epoch 9, Batch 500] loss: 0.034407165264710785
[Epoch 9, Batch 600] loss: 0.04486727522336878
[Epoch 9, Batch 700] loss: 0.05039043940603733
[Epoch 9, Batch 800] loss: 0.04712762025534176
[Epoch 9, Batch 900] loss: 0.04286577568564098
[Epoch 9, Batch 1000] loss: 0.04604544366011396
[Epoch 9, Batch 1100] loss: 0.03547354206210002
[Epoch 9, Batch 1200] loss: 0.038072775893379006
[Epoch 9, Batch 1300] loss: 0.032921480017830615
[Epoch 9, Batch 1400] loss: 0.050295129860169256
[Epoch 9, Batch 1500] loss: 0.04565056671039201
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0594
Validation Accuracy: 0.9821
Overfitting: 0.0594
[Epoch 10, Batch 100] loss: 0.03508525775745511
[Epoch 10, Batch 200] loss: 0.04062911232758779
[Epoch 10, Batch 300] loss: 0.05065779249649495
[Epoch 10, Batch 400] loss: 0.036615195443155245
[Epoch 10, Batch 500] loss: 0.044786716267699374
[Epoch 10, Batch 600] loss: 0.03936424272658769
[Epoch 10, Batch 700] loss: 0.049670289451023565
[Epoch 10, Batch 800] loss: 0.029211490579764358
[Epoch 10, Batch 900] loss: 0.04503680370631628
[Epoch 10, Batch 1000] loss: 0.03768826050800271
[Epoch 10, Batch 1100] loss: 0.031703893873491325
[Epoch 10, Batch 1200] loss: 0.026584434174001217
[Epoch 10, Batch 1300] loss: 0.02930246677424293
[Epoch 10, Batch 1400] loss: 0.03415302080393303
[Epoch 10, Batch 1500] loss: 0.03415877784718759
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9827
Overfitting: 0.0560
Best model saved at epoch 10 with validation loss: 0.0560
[Epoch 11, Batch 100] loss: 0.025408673628407995
[Epoch 11, Batch 200] loss: 0.029794562058668816
[Epoch 11, Batch 300] loss: 0.045980825336882844
[Epoch 11, Batch 400] loss: 0.03184155988390557
[Epoch 11, Batch 500] loss: 0.03105109997559339
[Epoch 11, Batch 600] loss: 0.027792257411638276
[Epoch 11, Batch 700] loss: 0.032784881135448814
[Epoch 11, Batch 800] loss: 0.03956348357372917
[Epoch 11, Batch 900] loss: 0.0302194223497645
[Epoch 11, Batch 1000] loss: 0.026591445078665857
[Epoch 11, Batch 1100] loss: 0.04140672732988605
[Epoch 11, Batch 1200] loss: 0.044861713348363995
[Epoch 11, Batch 1300] loss: 0.043496091880952006
[Epoch 11, Batch 1400] loss: 0.033976992745301686
[Epoch 11, Batch 1500] loss: 0.02787625879107509
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9858
Overfitting: 0.0463
Best model saved at epoch 11 with validation loss: 0.0463
[Epoch 12, Batch 100] loss: 0.04329410015430767
[Epoch 12, Batch 200] loss: 0.03089563458401244
[Epoch 12, Batch 300] loss: 0.03460951532586478
[Epoch 12, Batch 400] loss: 0.0348360926064197
[Epoch 12, Batch 500] loss: 0.036311492356471714
[Epoch 12, Batch 600] loss: 0.025438318655942566
[Epoch 12, Batch 700] loss: 0.023955563404015265
[Epoch 12, Batch 800] loss: 0.032678437232098075
[Epoch 12, Batch 900] loss: 0.02374933031765977
[Epoch 12, Batch 1000] loss: 0.03808258297853172
[Epoch 12, Batch 1100] loss: 0.036590022529126146
[Epoch 12, Batch 1200] loss: 0.031128904965589753
[Epoch 12, Batch 1300] loss: 0.024406164510000963
[Epoch 12, Batch 1400] loss: 0.028902610015356912
[Epoch 12, Batch 1500] loss: 0.031188116315752266
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9844
Overfitting: 0.0484
[Epoch 13, Batch 100] loss: 0.034565918126609176
[Epoch 13, Batch 200] loss: 0.027247984402347356
[Epoch 13, Batch 300] loss: 0.030979620989528486
[Epoch 13, Batch 400] loss: 0.023230493125738577
[Epoch 13, Batch 500] loss: 0.017906447963614482
[Epoch 13, Batch 600] loss: 0.03471444621507544
[Epoch 13, Batch 700] loss: 0.033577688796940494
[Epoch 13, Batch 800] loss: 0.03378312250250019
[Epoch 13, Batch 900] loss: 0.03248167373996694
[Epoch 13, Batch 1000] loss: 0.026473920417483896
[Epoch 13, Batch 1100] loss: 0.033112957585253754
[Epoch 13, Batch 1200] loss: 0.020707951673830393
[Epoch 13, Batch 1300] loss: 0.03870864316646475
[Epoch 13, Batch 1400] loss: 0.028397838444798252
[Epoch 13, Batch 1500] loss: 0.01951012507925043
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9853
Overfitting: 0.0437
Best model saved at epoch 13 with validation loss: 0.0437
[Epoch 14, Batch 100] loss: 0.02542833992774831
[Epoch 14, Batch 200] loss: 0.025443812906742094
[Epoch 14, Batch 300] loss: 0.03383004153787624
[Epoch 14, Batch 400] loss: 0.023426473404688297
[Epoch 14, Batch 500] loss: 0.03386934411755647
[Epoch 14, Batch 600] loss: 0.024516858538554516
[Epoch 14, Batch 700] loss: 0.02378390786674572
[Epoch 14, Batch 800] loss: 0.035035475499462336
[Epoch 14, Batch 900] loss: 0.024943932426394894
[Epoch 14, Batch 1000] loss: 0.018576957743789535
[Epoch 14, Batch 1100] loss: 0.028355220808298328
[Epoch 14, Batch 1200] loss: 0.024607853398338195
[Epoch 14, Batch 1300] loss: 0.025443628514476586
[Epoch 14, Batch 1400] loss: 0.023113538160541795
[Epoch 14, Batch 1500] loss: 0.028779139698599465
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0426
Validation Accuracy: 0.9865
Overfitting: 0.0426
Best model saved at epoch 14 with validation loss: 0.0426
[Epoch 15, Batch 100] loss: 0.023467955758969764
[Epoch 15, Batch 200] loss: 0.017328065124020214
[Epoch 15, Batch 300] loss: 0.03219377918634564
[Epoch 15, Batch 400] loss: 0.023838741895160637
[Epoch 15, Batch 500] loss: 0.02541957006615121
[Epoch 15, Batch 600] loss: 0.024585990542254875
[Epoch 15, Batch 700] loss: 0.026005265810235868
[Epoch 15, Batch 800] loss: 0.020205335037317126
[Epoch 15, Batch 900] loss: 0.021864912428427488
[Epoch 15, Batch 1000] loss: 0.020470287213101984
[Epoch 15, Batch 1100] loss: 0.023489133209805006
[Epoch 15, Batch 1200] loss: 0.01940285013988614
[Epoch 15, Batch 1300] loss: 0.023524881024786736
[Epoch 15, Batch 1400] loss: 0.02961781250909553
[Epoch 15, Batch 1500] loss: 0.02451792915140686
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9844
Overfitting: 0.0483
[Epoch 16, Batch 100] loss: 0.01715432359953411
[Epoch 16, Batch 200] loss: 0.02929547177947825
[Epoch 16, Batch 300] loss: 0.017117513067059918
[Epoch 16, Batch 400] loss: 0.027982946545380402
[Epoch 16, Batch 500] loss: 0.022118714706157335
[Epoch 16, Batch 600] loss: 0.01969642601921805
[Epoch 16, Batch 700] loss: 0.023222643101471475
[Epoch 16, Batch 800] loss: 0.03197088906468707
[Epoch 16, Batch 900] loss: 0.017301554070872954
[Epoch 16, Batch 1000] loss: 0.024902222363743932
[Epoch 16, Batch 1100] loss: 0.019288374899188058
[Epoch 16, Batch 1200] loss: 0.022236301829398144
[Epoch 16, Batch 1300] loss: 0.020182850945566315
[Epoch 16, Batch 1400] loss: 0.02112520350550767
[Epoch 16, Batch 1500] loss: 0.025083030611131107
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9854
Overfitting: 0.0480
[Epoch 17, Batch 100] loss: 0.021404658204264706
[Epoch 17, Batch 200] loss: 0.01464849123833119
[Epoch 17, Batch 300] loss: 0.018194682494940936
[Epoch 17, Batch 400] loss: 0.017167919735074973
[Epoch 17, Batch 500] loss: 0.018262170893867734
[Epoch 17, Batch 600] loss: 0.02317838669740013
[Epoch 17, Batch 700] loss: 0.014295784284622642
[Epoch 17, Batch 800] loss: 0.01659863983921241
[Epoch 17, Batch 900] loss: 0.024396423361613417
[Epoch 17, Batch 1000] loss: 0.02109656624175841
[Epoch 17, Batch 1100] loss: 0.02911533178499667
[Epoch 17, Batch 1200] loss: 0.023417494872555834
[Epoch 17, Batch 1300] loss: 0.016056128538184566
[Epoch 17, Batch 1400] loss: 0.02701868518764968
[Epoch 17, Batch 1500] loss: 0.022737537944922222
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0406
Validation Accuracy: 0.9870
Overfitting: 0.0406
Best model saved at epoch 17 with validation loss: 0.0406
[Epoch 18, Batch 100] loss: 0.011836257180839312
[Epoch 18, Batch 200] loss: 0.020617569325113435
[Epoch 18, Batch 300] loss: 0.019654618877102622
[Epoch 18, Batch 400] loss: 0.017528558357153088
[Epoch 18, Batch 500] loss: 0.015157749712379882
[Epoch 18, Batch 600] loss: 0.01743765333099873
[Epoch 18, Batch 700] loss: 0.021452766681904906
[Epoch 18, Batch 800] loss: 0.018683300350094214
[Epoch 18, Batch 900] loss: 0.017553052834991832
[Epoch 18, Batch 1000] loss: 0.027457503284676932
[Epoch 18, Batch 1100] loss: 0.021248002173088025
[Epoch 18, Batch 1200] loss: 0.0178844463108544
[Epoch 18, Batch 1300] loss: 0.011165357401987422
[Epoch 18, Batch 1400] loss: 0.01638987766018545
[Epoch 18, Batch 1500] loss: 0.014466358400604805
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0426
Validation Accuracy: 0.9872
Overfitting: 0.0426
[Epoch 19, Batch 100] loss: 0.009620137418824014
[Epoch 19, Batch 200] loss: 0.02014088677271502
[Epoch 19, Batch 300] loss: 0.013475207031078754
[Epoch 19, Batch 400] loss: 0.016883003559050848
[Epoch 19, Batch 500] loss: 0.015909915496449684
[Epoch 19, Batch 600] loss: 0.016997153251068084
[Epoch 19, Batch 700] loss: 0.01404978441685671
[Epoch 19, Batch 800] loss: 0.021582793998677515
[Epoch 19, Batch 900] loss: 0.021188669194525573
[Epoch 19, Batch 1000] loss: 0.02703635960831889
[Epoch 19, Batch 1100] loss: 0.018103972564276774
[Epoch 19, Batch 1200] loss: 0.0159746538548643
[Epoch 19, Batch 1300] loss: 0.017284570273623102
[Epoch 19, Batch 1400] loss: 0.013986213621246862
[Epoch 19, Batch 1500] loss: 0.01647680551497615
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0416
Validation Accuracy: 0.9873
Overfitting: 0.0416
[Epoch 20, Batch 100] loss: 0.014005967414705082
[Epoch 20, Batch 200] loss: 0.015562725823838264
[Epoch 20, Batch 300] loss: 0.019538928751353525
[Epoch 20, Batch 400] loss: 0.01829563574945496
[Epoch 20, Batch 500] loss: 0.010091529745222943
[Epoch 20, Batch 600] loss: 0.016916896806069417
[Epoch 20, Batch 700] loss: 0.010352649049818865
[Epoch 20, Batch 800] loss: 0.013644218585977797
[Epoch 20, Batch 900] loss: 0.013168737075757235
[Epoch 20, Batch 1000] loss: 0.019111862528661733
[Epoch 20, Batch 1100] loss: 0.024928296005382437
[Epoch 20, Batch 1200] loss: 0.01885532358493947
[Epoch 20, Batch 1300] loss: 0.010998568984687153
[Epoch 20, Batch 1400] loss: 0.018212585666042287
[Epoch 20, Batch 1500] loss: 0.024141848665312864
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0399
Validation Accuracy: 0.9876
Overfitting: 0.0399
Best model saved at epoch 20 with validation loss: 0.0399
[Epoch 21, Batch 100] loss: 0.01372071036901616
[Epoch 21, Batch 200] loss: 0.013533295745000942
[Epoch 21, Batch 300] loss: 0.011899383141280851
[Epoch 21, Batch 400] loss: 0.017273996014155274
[Epoch 21, Batch 500] loss: 0.014393924753385363
[Epoch 21, Batch 600] loss: 0.012644455677218502
[Epoch 21, Batch 700] loss: 0.020238341399963247
[Epoch 21, Batch 800] loss: 0.010824236421722162
[Epoch 21, Batch 900] loss: 0.017443357505835592
[Epoch 21, Batch 1000] loss: 0.009935772985736549
[Epoch 21, Batch 1100] loss: 0.011413840788882225
[Epoch 21, Batch 1200] loss: 0.011462230396136874
[Epoch 21, Batch 1300] loss: 0.014042546748896712
[Epoch 21, Batch 1400] loss: 0.0172465667664801
[Epoch 21, Batch 1500] loss: 0.01574570354867319
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0428
Validation Accuracy: 0.9884
Overfitting: 0.0428
[Epoch 22, Batch 100] loss: 0.01316394828769262
[Epoch 22, Batch 200] loss: 0.01148640599571081
[Epoch 22, Batch 300] loss: 0.0138437532428361
[Epoch 22, Batch 400] loss: 0.01158984113168117
[Epoch 22, Batch 500] loss: 0.012724458615339244
[Epoch 22, Batch 600] loss: 0.01185154439695907
[Epoch 22, Batch 700] loss: 0.011949251723272027
[Epoch 22, Batch 800] loss: 0.015623310338705778
[Epoch 22, Batch 900] loss: 0.0093742056562769
[Epoch 22, Batch 1000] loss: 0.017907894986565226
[Epoch 22, Batch 1100] loss: 0.01476782121382712
[Epoch 22, Batch 1200] loss: 0.012765137278329348
[Epoch 22, Batch 1300] loss: 0.016831485163638717
[Epoch 22, Batch 1400] loss: 0.010104384983424097
[Epoch 22, Batch 1500] loss: 0.01799722595296771
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0417
Validation Accuracy: 0.9878
Overfitting: 0.0417
[Epoch 23, Batch 100] loss: 0.007848682078292767
[Epoch 23, Batch 200] loss: 0.010013800912565785
[Epoch 23, Batch 300] loss: 0.009147114423758467
[Epoch 23, Batch 400] loss: 0.013597663537402695
[Epoch 23, Batch 500] loss: 0.01673151891111047
[Epoch 23, Batch 600] loss: 0.012125113256479381
[Epoch 23, Batch 700] loss: 0.013077531480084871
[Epoch 23, Batch 800] loss: 0.014413960072597548
[Epoch 23, Batch 900] loss: 0.01184350632582209
[Epoch 23, Batch 1000] loss: 0.015152620453900454
[Epoch 23, Batch 1100] loss: 0.01248421834607143
[Epoch 23, Batch 1200] loss: 0.007115918982653966
[Epoch 23, Batch 1300] loss: 0.017017105844497563
[Epoch 23, Batch 1400] loss: 0.012020881672942779
[Epoch 23, Batch 1500] loss: 0.01697836764757085
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9871
Overfitting: 0.0430
[Epoch 24, Batch 100] loss: 0.009465843479956675
[Epoch 24, Batch 200] loss: 0.010388661802535353
[Epoch 24, Batch 300] loss: 0.009687403522802925
[Epoch 24, Batch 400] loss: 0.00846910759795719
[Epoch 24, Batch 500] loss: 0.0070567059084714855
[Epoch 24, Batch 600] loss: 0.007897294518352282
[Epoch 24, Batch 700] loss: 0.0063309634343750075
[Epoch 24, Batch 800] loss: 0.013615616061779292
[Epoch 24, Batch 900] loss: 0.01030606015909143
[Epoch 24, Batch 1000] loss: 0.016319611486542273
[Epoch 24, Batch 1100] loss: 0.009835920185869327
[Epoch 24, Batch 1200] loss: 0.010840600705741964
[Epoch 24, Batch 1300] loss: 0.01750985634229437
[Epoch 24, Batch 1400] loss: 0.01260679320068448
[Epoch 24, Batch 1500] loss: 0.014004497784917476
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0397
Validation Accuracy: 0.9887
Overfitting: 0.0397
Best model saved at epoch 24 with validation loss: 0.0397
Fold 5 validation loss: 0.0397
Mean validation loss across all folds for Trial 20 is 0.0475 with trial config:  l1: 256, l2: 64, lr: 0.0008094764402330428, batch_size: 32
[I 2024-12-11 05:14:01,481] Trial 19 finished with value: 0.04748951513393477 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0008094764402330428, 'batch_size': 32}. Best is trial 19 with value: 0.04748951513393477.

Selected Hyperparameters for Trial 21:
  l1: 256, l2: 64, lr: 0.0008930494187397061, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.289018635749817
[Epoch 1, Batch 200] loss: 2.2545035886764526
[Epoch 1, Batch 300] loss: 2.124705150127411
[Epoch 1, Batch 400] loss: 1.4560514771938324
[Epoch 1, Batch 500] loss: 0.6819587400555611
[Epoch 1, Batch 600] loss: 0.4773038209974766
[Epoch 1, Batch 700] loss: 0.3680516820400953
[Epoch 1, Batch 800] loss: 0.371494237780571
[Epoch 1, Batch 900] loss: 0.3101400505006313
[Epoch 1, Batch 1000] loss: 0.3181534366309643
[Epoch 1, Batch 1100] loss: 0.2618070675060153
[Epoch 1, Batch 1200] loss: 0.24751924369484185
[Epoch 1, Batch 1300] loss: 0.2298422075808048
[Epoch 1, Batch 1400] loss: 0.24051939364522695
[Epoch 1, Batch 1500] loss: 0.2091473053768277
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1849
Validation Accuracy: 0.9440
Overfitting: 0.1849
Best model saved at epoch 1 with validation loss: 0.1849
[Epoch 2, Batch 100] loss: 0.17558955071493984
[Epoch 2, Batch 200] loss: 0.16674545601010324
[Epoch 2, Batch 300] loss: 0.1874489002954215
[Epoch 2, Batch 400] loss: 0.16593728320673107
[Epoch 2, Batch 500] loss: 0.15956349182873963
[Epoch 2, Batch 600] loss: 0.1371864016726613
[Epoch 2, Batch 700] loss: 0.15436323883011938
[Epoch 2, Batch 800] loss: 0.16937608354724942
[Epoch 2, Batch 900] loss: 0.1308769054338336
[Epoch 2, Batch 1000] loss: 0.12388614690862595
[Epoch 2, Batch 1100] loss: 0.13490042613819242
[Epoch 2, Batch 1200] loss: 0.13072506564669312
[Epoch 2, Batch 1300] loss: 0.11490761106833816
[Epoch 2, Batch 1400] loss: 0.12991757988929747
[Epoch 2, Batch 1500] loss: 0.1283838940411806
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1056
Validation Accuracy: 0.9680
Overfitting: 0.1056
Best model saved at epoch 2 with validation loss: 0.1056
[Epoch 3, Batch 100] loss: 0.11373487404547632
[Epoch 3, Batch 200] loss: 0.10132433193735778
[Epoch 3, Batch 300] loss: 0.11022556386888027
[Epoch 3, Batch 400] loss: 0.10065749272704125
[Epoch 3, Batch 500] loss: 0.09771525404881685
[Epoch 3, Batch 600] loss: 0.10701683414168656
[Epoch 3, Batch 700] loss: 0.09817147550638765
[Epoch 3, Batch 800] loss: 0.0835057097254321
[Epoch 3, Batch 900] loss: 0.09078361999709159
[Epoch 3, Batch 1000] loss: 0.0950814159680158
[Epoch 3, Batch 1100] loss: 0.09176814619451762
[Epoch 3, Batch 1200] loss: 0.08788302117958664
[Epoch 3, Batch 1300] loss: 0.10574173652566969
[Epoch 3, Batch 1400] loss: 0.09711361677385867
[Epoch 3, Batch 1500] loss: 0.08966101270169019
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0999
Validation Accuracy: 0.9687
Overfitting: 0.0999
Best model saved at epoch 3 with validation loss: 0.0999
[Epoch 4, Batch 100] loss: 0.08394402653444559
[Epoch 4, Batch 200] loss: 0.08700753506273032
[Epoch 4, Batch 300] loss: 0.08378075421787798
[Epoch 4, Batch 400] loss: 0.09114575957879424
[Epoch 4, Batch 500] loss: 0.07558335380163043
[Epoch 4, Batch 600] loss: 0.07298563552321866
[Epoch 4, Batch 700] loss: 0.07173245964804664
[Epoch 4, Batch 800] loss: 0.07967495237942784
[Epoch 4, Batch 900] loss: 0.0758228457160294
[Epoch 4, Batch 1000] loss: 0.0764063354791142
[Epoch 4, Batch 1100] loss: 0.08110368154011667
[Epoch 4, Batch 1200] loss: 0.0748790999641642
[Epoch 4, Batch 1300] loss: 0.06097925804788247
[Epoch 4, Batch 1400] loss: 0.07180019135586918
[Epoch 4, Batch 1500] loss: 0.07903212976641953
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0770
Validation Accuracy: 0.9756
Overfitting: 0.0770
Best model saved at epoch 4 with validation loss: 0.0770
[Epoch 5, Batch 100] loss: 0.06783620291855186
[Epoch 5, Batch 200] loss: 0.05370528156403452
[Epoch 5, Batch 300] loss: 0.057860182924196125
[Epoch 5, Batch 400] loss: 0.05738264415645972
[Epoch 5, Batch 500] loss: 0.06896751454216428
[Epoch 5, Batch 600] loss: 0.05728329962352291
[Epoch 5, Batch 700] loss: 0.06790466271457263
[Epoch 5, Batch 800] loss: 0.06620691472664475
[Epoch 5, Batch 900] loss: 0.06636680633760988
[Epoch 5, Batch 1000] loss: 0.06882665730081498
[Epoch 5, Batch 1100] loss: 0.062411744613200426
[Epoch 5, Batch 1200] loss: 0.06587772530969233
[Epoch 5, Batch 1300] loss: 0.05860337005229667
[Epoch 5, Batch 1400] loss: 0.08391764238942415
[Epoch 5, Batch 1500] loss: 0.07033865180332213
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9797
Overfitting: 0.0636
Best model saved at epoch 5 with validation loss: 0.0636
[Epoch 6, Batch 100] loss: 0.06761378885712474
[Epoch 6, Batch 200] loss: 0.061969109873753044
[Epoch 6, Batch 300] loss: 0.05356383317383006
[Epoch 6, Batch 400] loss: 0.06099449777975678
[Epoch 6, Batch 500] loss: 0.059422581719700246
[Epoch 6, Batch 600] loss: 0.054216574791353195
[Epoch 6, Batch 700] loss: 0.056679869752842935
[Epoch 6, Batch 800] loss: 0.05554137615952641
[Epoch 6, Batch 900] loss: 0.06628180508385412
[Epoch 6, Batch 1000] loss: 0.05292722235317342
[Epoch 6, Batch 1100] loss: 0.05318070523673669
[Epoch 6, Batch 1200] loss: 0.06931756594276521
[Epoch 6, Batch 1300] loss: 0.053692050017416476
[Epoch 6, Batch 1400] loss: 0.04331956925103441
[Epoch 6, Batch 1500] loss: 0.04968069694237784
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0647
Validation Accuracy: 0.9796
Overfitting: 0.0647
[Epoch 7, Batch 100] loss: 0.04698017849063035
[Epoch 7, Batch 200] loss: 0.05658411329612136
[Epoch 7, Batch 300] loss: 0.05024473857833073
[Epoch 7, Batch 400] loss: 0.05293273890274577
[Epoch 7, Batch 500] loss: 0.05132130783284083
[Epoch 7, Batch 600] loss: 0.039425181325059386
[Epoch 7, Batch 700] loss: 0.05017241690889932
[Epoch 7, Batch 800] loss: 0.04414018845302053
[Epoch 7, Batch 900] loss: 0.053045255208853635
[Epoch 7, Batch 1000] loss: 0.04257521171239205
[Epoch 7, Batch 1100] loss: 0.041134096440218856
[Epoch 7, Batch 1200] loss: 0.0524686820874922
[Epoch 7, Batch 1300] loss: 0.04303359777259175
[Epoch 7, Batch 1400] loss: 0.05909070242400048
[Epoch 7, Batch 1500] loss: 0.06266539546661079
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0815
Validation Accuracy: 0.9745
Overfitting: 0.0815
[Epoch 8, Batch 100] loss: 0.04976244628429413
[Epoch 8, Batch 200] loss: 0.042276430740021166
[Epoch 8, Batch 300] loss: 0.040647204220294955
[Epoch 8, Batch 400] loss: 0.04000027856323868
[Epoch 8, Batch 500] loss: 0.04387605753727257
[Epoch 8, Batch 600] loss: 0.04586283819109667
[Epoch 8, Batch 700] loss: 0.03441329702443909
[Epoch 8, Batch 800] loss: 0.03978165484732017
[Epoch 8, Batch 900] loss: 0.04952793197648134
[Epoch 8, Batch 1000] loss: 0.04637502017780207
[Epoch 8, Batch 1100] loss: 0.04738475582795218
[Epoch 8, Batch 1200] loss: 0.03995935462648049
[Epoch 8, Batch 1300] loss: 0.05032643183716573
[Epoch 8, Batch 1400] loss: 0.039571759011596444
[Epoch 8, Batch 1500] loss: 0.05622031622100621
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9805
Overfitting: 0.0608
Best model saved at epoch 8 with validation loss: 0.0608
[Epoch 9, Batch 100] loss: 0.04214398554817308
[Epoch 9, Batch 200] loss: 0.03871961780474521
[Epoch 9, Batch 300] loss: 0.03040479423769284
[Epoch 9, Batch 400] loss: 0.04298253384622512
[Epoch 9, Batch 500] loss: 0.03733215989544988
[Epoch 9, Batch 600] loss: 0.03773015659069642
[Epoch 9, Batch 700] loss: 0.039306338808382864
[Epoch 9, Batch 800] loss: 0.03697329521470238
[Epoch 9, Batch 900] loss: 0.03810478960396722
[Epoch 9, Batch 1000] loss: 0.03907053699134849
[Epoch 9, Batch 1100] loss: 0.033931170513387766
[Epoch 9, Batch 1200] loss: 0.035977255278266965
[Epoch 9, Batch 1300] loss: 0.04729032316477969
[Epoch 9, Batch 1400] loss: 0.04281790421286132
[Epoch 9, Batch 1500] loss: 0.03759643675526604
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9822
Overfitting: 0.0570
[I 2024-12-11 05:15:45,301] Trial 20 pruned. 

Selected Hyperparameters for Trial 22:
  l1: 256, l2: 64, lr: 0.0002821370658156816, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.297928042411804
[Epoch 1, Batch 200] loss: 2.2907169485092163
[Epoch 1, Batch 300] loss: 2.282719554901123
[Epoch 1, Batch 400] loss: 2.2708574461936952
[Epoch 1, Batch 500] loss: 2.255279586315155
[Epoch 1, Batch 600] loss: 2.230174329280853
[Epoch 1, Batch 700] loss: 2.1888418006896972
[Epoch 1, Batch 800] loss: 2.1187503933906555
[Epoch 1, Batch 900] loss: 1.9769047713279724
[Epoch 1, Batch 1000] loss: 1.6993115031719208
[Epoch 1, Batch 1100] loss: 1.2877745205163955
[Epoch 1, Batch 1200] loss: 0.8895911520719528
[Epoch 1, Batch 1300] loss: 0.6847353863716126
[Epoch 1, Batch 1400] loss: 0.5562460279464722
[Epoch 1, Batch 1500] loss: 0.489796177893877
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.4349
Validation Accuracy: 0.8802
Overfitting: 0.4349
Best model saved at epoch 1 with validation loss: 0.4349
[Epoch 2, Batch 100] loss: 0.44932767376303673
[Epoch 2, Batch 200] loss: 0.4197929082810879
[Epoch 2, Batch 300] loss: 0.39188559383153915
[Epoch 2, Batch 400] loss: 0.3849439664185047
[Epoch 2, Batch 500] loss: 0.3828191521763802
[Epoch 2, Batch 600] loss: 0.3430967700481415
[Epoch 2, Batch 700] loss: 0.32754345040768384
[Epoch 2, Batch 800] loss: 0.3448799039423466
[Epoch 2, Batch 900] loss: 0.2957624874264002
[Epoch 2, Batch 1000] loss: 0.29955621421337125
[Epoch 2, Batch 1100] loss: 0.29995698101818563
[Epoch 2, Batch 1200] loss: 0.27337809167802335
[Epoch 2, Batch 1300] loss: 0.2939552281051874
[Epoch 2, Batch 1400] loss: 0.2700570110976696
[Epoch 2, Batch 1500] loss: 0.27038033459335564
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2474
Validation Accuracy: 0.9277
Overfitting: 0.2474
Best model saved at epoch 2 with validation loss: 0.2474
[Epoch 3, Batch 100] loss: 0.26595736499875783
[Epoch 3, Batch 200] loss: 0.22746372949332
[Epoch 3, Batch 300] loss: 0.23561324022710323
[Epoch 3, Batch 400] loss: 0.2418311631679535
[Epoch 3, Batch 500] loss: 0.22755132433027028
[Epoch 3, Batch 600] loss: 0.24940851662307978
[Epoch 3, Batch 700] loss: 0.23045257646590472
[Epoch 3, Batch 800] loss: 0.24294407691806555
[Epoch 3, Batch 900] loss: 0.22400624673813582
[Epoch 3, Batch 1000] loss: 0.2100469495356083
[Epoch 3, Batch 1100] loss: 0.19351081766188144
[Epoch 3, Batch 1200] loss: 0.19693841233849527
[Epoch 3, Batch 1300] loss: 0.18840109910815955
[Epoch 3, Batch 1400] loss: 0.19862432703375815
[Epoch 3, Batch 1500] loss: 0.22513142243027687
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1770
Validation Accuracy: 0.9479
Overfitting: 0.1770
Best model saved at epoch 3 with validation loss: 0.1770
[Epoch 4, Batch 100] loss: 0.1943301136791706
[Epoch 4, Batch 200] loss: 0.1813209004700184
[Epoch 4, Batch 300] loss: 0.17679590452462435
[Epoch 4, Batch 400] loss: 0.19068039800971748
[Epoch 4, Batch 500] loss: 0.17199347345158458
[Epoch 4, Batch 600] loss: 0.16903980623930692
[Epoch 4, Batch 700] loss: 0.20802167125046253
[Epoch 4, Batch 800] loss: 0.16264847259968518
[Epoch 4, Batch 900] loss: 0.16955989649519324
[Epoch 4, Batch 1000] loss: 0.1610071044228971
[Epoch 4, Batch 1100] loss: 0.16545943278819322
[Epoch 4, Batch 1200] loss: 0.17523293990641833
[Epoch 4, Batch 1300] loss: 0.15876205939799548
[Epoch 4, Batch 1400] loss: 0.1551793039403856
[Epoch 4, Batch 1500] loss: 0.16038540471345186
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1475
Validation Accuracy: 0.9554
Overfitting: 0.1475
Best model saved at epoch 4 with validation loss: 0.1475
[Epoch 5, Batch 100] loss: 0.15219319317489863
[Epoch 5, Batch 200] loss: 0.15058185189962386
[Epoch 5, Batch 300] loss: 0.15850325159728526
[Epoch 5, Batch 400] loss: 0.16757984774187207
[Epoch 5, Batch 500] loss: 0.13625213917344808
[Epoch 5, Batch 600] loss: 0.13712114239111542
[Epoch 5, Batch 700] loss: 0.14836894045583904
[Epoch 5, Batch 800] loss: 0.1418264421634376
[Epoch 5, Batch 900] loss: 0.1595074887946248
[Epoch 5, Batch 1000] loss: 0.14331255735829473
[Epoch 5, Batch 1100] loss: 0.1501687441021204
[Epoch 5, Batch 1200] loss: 0.12994740003719926
[Epoch 5, Batch 1300] loss: 0.12232612259685993
[Epoch 5, Batch 1400] loss: 0.1190703183133155
[Epoch 5, Batch 1500] loss: 0.1384441221319139
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1200
Validation Accuracy: 0.9643
Overfitting: 0.1200
Best model saved at epoch 5 with validation loss: 0.1200
[Epoch 6, Batch 100] loss: 0.12694146001711487
[Epoch 6, Batch 200] loss: 0.12281571123749017
[Epoch 6, Batch 300] loss: 0.13444234736263752
[Epoch 6, Batch 400] loss: 0.11954521436244249
[Epoch 6, Batch 500] loss: 0.11119350924156607
[Epoch 6, Batch 600] loss: 0.12983916265890003
[Epoch 6, Batch 700] loss: 0.13533048992045224
[Epoch 6, Batch 800] loss: 0.14527264109812676
[Epoch 6, Batch 900] loss: 0.12355543470941484
[Epoch 6, Batch 1000] loss: 0.12210575427860021
[Epoch 6, Batch 1100] loss: 0.11845644732937216
[Epoch 6, Batch 1200] loss: 0.1074637665785849
[Epoch 6, Batch 1300] loss: 0.13448335173539816
[Epoch 6, Batch 1400] loss: 0.11297648324631154
[Epoch 6, Batch 1500] loss: 0.11609613695181906
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.1048
Validation Accuracy: 0.9665
Overfitting: 0.1048
Best model saved at epoch 6 with validation loss: 0.1048
[Epoch 7, Batch 100] loss: 0.12056445320136845
[Epoch 7, Batch 200] loss: 0.12406391794793308
[Epoch 7, Batch 300] loss: 0.10326755127869547
[Epoch 7, Batch 400] loss: 0.11372871725820005
[Epoch 7, Batch 500] loss: 0.12151981171220541
[Epoch 7, Batch 600] loss: 0.11500757383182644
[Epoch 7, Batch 700] loss: 0.11207840996794402
[Epoch 7, Batch 800] loss: 0.09566780459135771
[Epoch 7, Batch 900] loss: 0.10220663174055516
[Epoch 7, Batch 1000] loss: 0.09491806763224303
[Epoch 7, Batch 1100] loss: 0.11076227814890444
[Epoch 7, Batch 1200] loss: 0.09961003079079092
[Epoch 7, Batch 1300] loss: 0.10306481908075511
[Epoch 7, Batch 1400] loss: 0.10614648910239338
[Epoch 7, Batch 1500] loss: 0.10702542742714286
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.1048
Validation Accuracy: 0.9668
Overfitting: 0.1048
[Epoch 8, Batch 100] loss: 0.11610300054773688
[Epoch 8, Batch 200] loss: 0.09220556462183595
[Epoch 8, Batch 300] loss: 0.10444636947475373
[Epoch 8, Batch 400] loss: 0.09325968044344336
[Epoch 8, Batch 500] loss: 0.09834344306960702
[Epoch 8, Batch 600] loss: 0.09399117002263666
[Epoch 8, Batch 700] loss: 0.11019296387210488
[Epoch 8, Batch 800] loss: 0.10711257371585817
[Epoch 8, Batch 900] loss: 0.10157823737710714
[Epoch 8, Batch 1000] loss: 0.10078483828809112
[Epoch 8, Batch 1100] loss: 0.10714475621702149
[Epoch 8, Batch 1200] loss: 0.07859689335804433
[Epoch 8, Batch 1300] loss: 0.08405968646518885
[Epoch 8, Batch 1400] loss: 0.10577811215538531
[Epoch 8, Batch 1500] loss: 0.07825115821324288
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0839
Validation Accuracy: 0.9731
Overfitting: 0.0839
Best model saved at epoch 8 with validation loss: 0.0839
[Epoch 9, Batch 100] loss: 0.09649533804506064
[Epoch 9, Batch 200] loss: 0.08911008939146996
[Epoch 9, Batch 300] loss: 0.10650656819343567
[Epoch 9, Batch 400] loss: 0.07837110869586468
[Epoch 9, Batch 500] loss: 0.07916079954709858
[Epoch 9, Batch 600] loss: 0.08272913814987987
[Epoch 9, Batch 700] loss: 0.09060390106402337
[Epoch 9, Batch 800] loss: 0.09426522707333788
[Epoch 9, Batch 900] loss: 0.10208454680163413
[Epoch 9, Batch 1000] loss: 0.08836811936693266
[Epoch 9, Batch 1100] loss: 0.0757414298853837
[Epoch 9, Batch 1200] loss: 0.08098626906052232
[Epoch 9, Batch 1300] loss: 0.09385497519746423
[Epoch 9, Batch 1400] loss: 0.0888095680763945
[Epoch 9, Batch 1500] loss: 0.09897472346667201
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0844
Validation Accuracy: 0.9734
Overfitting: 0.0844
[I 2024-12-11 05:17:28,282] Trial 21 pruned. 

Selected Hyperparameters for Trial 23:
  l1: 256, l2: 64, lr: 0.0010633668427804854, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.302405605316162
**STATS for Epoch 1** : 
Average training loss: 1.0718
Average validation loss: 2.2826
Validation Accuracy: 0.1661
Overfitting: 1.2108
Best model saved at epoch 1 with validation loss: 2.2826
[Epoch 2, Batch 100] loss: 2.267006208896637
**STATS for Epoch 2** : 
Average training loss: 1.0241
Average validation loss: 2.0792
Validation Accuracy: 0.5570
Overfitting: 1.0551
Best model saved at epoch 2 with validation loss: 2.0792
[Epoch 3, Batch 100] loss: 1.6028113549947738
**STATS for Epoch 3** : 
Average training loss: 0.3208
Average validation loss: 0.5290
Validation Accuracy: 0.8458
Overfitting: 0.2083
Best model saved at epoch 3 with validation loss: 0.5290
[Epoch 4, Batch 100] loss: 0.477742041349411
**STATS for Epoch 4** : 
Average training loss: 0.1883
Average validation loss: 0.3530
Validation Accuracy: 0.8942
Overfitting: 0.1647
Best model saved at epoch 4 with validation loss: 0.3530
[Epoch 5, Batch 100] loss: 0.34756835997104646
**STATS for Epoch 5** : 
Average training loss: 0.1472
Average validation loss: 0.2821
Validation Accuracy: 0.9170
Overfitting: 0.1350
Best model saved at epoch 5 with validation loss: 0.2821
[Epoch 6, Batch 100] loss: 0.2794827018678188
**STATS for Epoch 6** : 
Average training loss: 0.1280
Average validation loss: 0.2479
Validation Accuracy: 0.9254
Overfitting: 0.1199
Best model saved at epoch 6 with validation loss: 0.2479
[Epoch 7, Batch 100] loss: 0.242954333871603
**STATS for Epoch 7** : 
Average training loss: 0.1064
Average validation loss: 0.2084
Validation Accuracy: 0.9387
Overfitting: 0.1020
Best model saved at epoch 7 with validation loss: 0.2084
[Epoch 8, Batch 100] loss: 0.21096751049160958
**STATS for Epoch 8** : 
Average training loss: 0.0919
Average validation loss: 0.1835
Validation Accuracy: 0.9440
Overfitting: 0.0916
Best model saved at epoch 8 with validation loss: 0.1835
[Epoch 9, Batch 100] loss: 0.18825634583830833
**STATS for Epoch 9** : 
Average training loss: 0.0812
Average validation loss: 0.1633
Validation Accuracy: 0.9513
Overfitting: 0.0821
[I 2024-12-11 05:18:48,686] Trial 22 pruned. 

Selected Hyperparameters for Trial 24:
  l1: 128, l2: 64, lr: 0.0007270312333840008, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3003463530540467
[Epoch 1, Batch 200] loss: 2.282081301212311
[Epoch 1, Batch 300] loss: 2.2540055203437803
[Epoch 1, Batch 400] loss: 2.181729989051819
[Epoch 1, Batch 500] loss: 1.8739074563980103
[Epoch 1, Batch 600] loss: 1.1001943498849869
[Epoch 1, Batch 700] loss: 0.7038594359159469
[Epoch 1, Batch 800] loss: 0.6360874408483506
[Epoch 1, Batch 900] loss: 0.5182147347927093
[Epoch 1, Batch 1000] loss: 0.4395746099948883
[Epoch 1, Batch 1100] loss: 0.3907649026811123
[Epoch 1, Batch 1200] loss: 0.36256580911576747
[Epoch 1, Batch 1300] loss: 0.3180106291919947
[Epoch 1, Batch 1400] loss: 0.3158928196132183
[Epoch 1, Batch 1500] loss: 0.2658649004623294
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2553
Validation Accuracy: 0.9225
Overfitting: 0.2553
Best model saved at epoch 1 with validation loss: 0.2553
[Epoch 2, Batch 100] loss: 0.2781302109360695
[Epoch 2, Batch 200] loss: 0.2652166520431638
[Epoch 2, Batch 300] loss: 0.24906226489692926
[Epoch 2, Batch 400] loss: 0.24564342807978393
[Epoch 2, Batch 500] loss: 0.21751332998275758
[Epoch 2, Batch 600] loss: 0.211524068005383
[Epoch 2, Batch 700] loss: 0.21493124876171352
[Epoch 2, Batch 800] loss: 0.18084449633955957
[Epoch 2, Batch 900] loss: 0.1751346020027995
[Epoch 2, Batch 1000] loss: 0.18166636370122433
[Epoch 2, Batch 1100] loss: 0.1609385134652257
[Epoch 2, Batch 1200] loss: 0.1905568821169436
[Epoch 2, Batch 1300] loss: 0.13232489983551204
[Epoch 2, Batch 1400] loss: 0.1521979112736881
[Epoch 2, Batch 1500] loss: 0.14767685854807497
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1397
Validation Accuracy: 0.9582
Overfitting: 0.1397
Best model saved at epoch 2 with validation loss: 0.1397
[Epoch 3, Batch 100] loss: 0.1494410640746355
[Epoch 3, Batch 200] loss: 0.1366672714613378
[Epoch 3, Batch 300] loss: 0.12731094658374786
[Epoch 3, Batch 400] loss: 0.1338290084991604
[Epoch 3, Batch 500] loss: 0.12754831320606172
[Epoch 3, Batch 600] loss: 0.13310828359797597
[Epoch 3, Batch 700] loss: 0.12128058354370296
[Epoch 3, Batch 800] loss: 0.10820114892907441
[Epoch 3, Batch 900] loss: 0.1060689014196396
[Epoch 3, Batch 1000] loss: 0.10831469568889589
[Epoch 3, Batch 1100] loss: 0.10703795409761369
[Epoch 3, Batch 1200] loss: 0.11220431949943305
[Epoch 3, Batch 1300] loss: 0.13323100828565657
[Epoch 3, Batch 1400] loss: 0.10458486580755562
[Epoch 3, Batch 1500] loss: 0.13620026181917638
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1039
Validation Accuracy: 0.9683
Overfitting: 0.1039
Best model saved at epoch 3 with validation loss: 0.1039
[Epoch 4, Batch 100] loss: 0.09021538643166423
[Epoch 4, Batch 200] loss: 0.0965141020482406
[Epoch 4, Batch 300] loss: 0.09972797740250826
[Epoch 4, Batch 400] loss: 0.10287289102561772
[Epoch 4, Batch 500] loss: 0.10908579778857529
[Epoch 4, Batch 600] loss: 0.09025835787411779
[Epoch 4, Batch 700] loss: 0.09948454251978546
[Epoch 4, Batch 800] loss: 0.09323065973352641
[Epoch 4, Batch 900] loss: 0.0922835896955803
[Epoch 4, Batch 1000] loss: 0.08686090507544578
[Epoch 4, Batch 1100] loss: 0.08993605718016624
[Epoch 4, Batch 1200] loss: 0.10771758889779448
[Epoch 4, Batch 1300] loss: 0.09942545230267569
[Epoch 4, Batch 1400] loss: 0.07494914195034653
[Epoch 4, Batch 1500] loss: 0.08941050467547029
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0911
Validation Accuracy: 0.9709
Overfitting: 0.0911
Best model saved at epoch 4 with validation loss: 0.0911
[Epoch 5, Batch 100] loss: 0.08903687927406281
[Epoch 5, Batch 200] loss: 0.07797373333480209
[Epoch 5, Batch 300] loss: 0.07825817589648068
[Epoch 5, Batch 400] loss: 0.08548395553138106
[Epoch 5, Batch 500] loss: 0.07693283416796476
[Epoch 5, Batch 600] loss: 0.08042723623104393
[Epoch 5, Batch 700] loss: 0.07629361409228295
[Epoch 5, Batch 800] loss: 0.07235433904686943
[Epoch 5, Batch 900] loss: 0.07731527586234734
[Epoch 5, Batch 1000] loss: 0.08373601989354938
[Epoch 5, Batch 1100] loss: 0.0816161800478585
[Epoch 5, Batch 1200] loss: 0.090916265535634
[Epoch 5, Batch 1300] loss: 0.0836483933031559
[Epoch 5, Batch 1400] loss: 0.0793890255363658
[Epoch 5, Batch 1500] loss: 0.079167929883115
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0718
Validation Accuracy: 0.9755
Overfitting: 0.0718
Best model saved at epoch 5 with validation loss: 0.0718
[Epoch 6, Batch 100] loss: 0.09121237920597196
[Epoch 6, Batch 200] loss: 0.0646149956760928
[Epoch 6, Batch 300] loss: 0.0674326703697443
[Epoch 6, Batch 400] loss: 0.06992168676108122
[Epoch 6, Batch 500] loss: 0.06515410526888445
[Epoch 6, Batch 600] loss: 0.0742117757233791
[Epoch 6, Batch 700] loss: 0.08300436669727787
[Epoch 6, Batch 800] loss: 0.063095659930259
[Epoch 6, Batch 900] loss: 0.06091227255528793
[Epoch 6, Batch 1000] loss: 0.0760723954695277
[Epoch 6, Batch 1100] loss: 0.06400063612964005
[Epoch 6, Batch 1200] loss: 0.07306403153808788
[Epoch 6, Batch 1300] loss: 0.07579986229538918
[Epoch 6, Batch 1400] loss: 0.06812605889048427
[Epoch 6, Batch 1500] loss: 0.06920362549251877
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0666
Validation Accuracy: 0.9781
Overfitting: 0.0666
Best model saved at epoch 6 with validation loss: 0.0666
[Epoch 7, Batch 100] loss: 0.0617057857720647
[Epoch 7, Batch 200] loss: 0.07689667745726184
[Epoch 7, Batch 300] loss: 0.06817936203442514
[Epoch 7, Batch 400] loss: 0.0511663228191901
[Epoch 7, Batch 500] loss: 0.06905348657397553
[Epoch 7, Batch 600] loss: 0.056971067336853594
[Epoch 7, Batch 700] loss: 0.0678457840019837
[Epoch 7, Batch 800] loss: 0.05654246459947899
[Epoch 7, Batch 900] loss: 0.06221776213962585
[Epoch 7, Batch 1000] loss: 0.054310105422046034
[Epoch 7, Batch 1100] loss: 0.05678271045908332
[Epoch 7, Batch 1200] loss: 0.06911577562335879
[Epoch 7, Batch 1300] loss: 0.05871002498664893
[Epoch 7, Batch 1400] loss: 0.06767171883955597
[Epoch 7, Batch 1500] loss: 0.06593376718694344
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0583
Validation Accuracy: 0.9809
Overfitting: 0.0583
Best model saved at epoch 7 with validation loss: 0.0583
[Epoch 8, Batch 100] loss: 0.051011414476670326
[Epoch 8, Batch 200] loss: 0.062413638255093246
[Epoch 8, Batch 300] loss: 0.050143922343850136
[Epoch 8, Batch 400] loss: 0.06717087827855721
[Epoch 8, Batch 500] loss: 0.053222983831074086
[Epoch 8, Batch 600] loss: 0.0615434738388285
[Epoch 8, Batch 700] loss: 0.057295878531876954
[Epoch 8, Batch 800] loss: 0.057877875352278355
[Epoch 8, Batch 900] loss: 0.05875898002181202
[Epoch 8, Batch 1000] loss: 0.06254603667533956
[Epoch 8, Batch 1100] loss: 0.04975926597835496
[Epoch 8, Batch 1200] loss: 0.05711077930405736
[Epoch 8, Batch 1300] loss: 0.057919052202487366
[Epoch 8, Batch 1400] loss: 0.055726629863493145
[Epoch 8, Batch 1500] loss: 0.049295552573166784
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0578
Validation Accuracy: 0.9802
Overfitting: 0.0578
Best model saved at epoch 8 with validation loss: 0.0578
[Epoch 9, Batch 100] loss: 0.06099150587106124
[Epoch 9, Batch 200] loss: 0.03706392920110375
[Epoch 9, Batch 300] loss: 0.048951074132928624
[Epoch 9, Batch 400] loss: 0.048897735332138835
[Epoch 9, Batch 500] loss: 0.05641861050971784
[Epoch 9, Batch 600] loss: 0.05199748981744051
[Epoch 9, Batch 700] loss: 0.0561010117107071
[Epoch 9, Batch 800] loss: 0.05406410380266607
[Epoch 9, Batch 900] loss: 0.06106161722913384
[Epoch 9, Batch 1000] loss: 0.05937018229626119
[Epoch 9, Batch 1100] loss: 0.04365631217835471
[Epoch 9, Batch 1200] loss: 0.050657976853544825
[Epoch 9, Batch 1300] loss: 0.049329970007529485
[Epoch 9, Batch 1400] loss: 0.0563424869638402
[Epoch 9, Batch 1500] loss: 0.05208148253150284
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0590
Validation Accuracy: 0.9811
Overfitting: 0.0590
[I 2024-12-11 05:20:34,236] Trial 23 pruned. 
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  13
  Number of complete trials:  11
Best hyperparameters found:
{'l1': 256, 'l2': 64, 'lr': 0.0008094764402330428, 'batch_size': 32}
Best trial:
  Value:  0.04748951513393477
Loaded best model checkpoint from: instances/1440183_20241211/best_checkpoint_trial_19/model.pth
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0008094764402330428, 'batch_size': 32} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 2.281884891986847
[Epoch 1, Batch 200] loss: 2.220323920249939
[Epoch 1, Batch 300] loss: 1.932937856912613
[Epoch 1, Batch 400] loss: 1.0482189774513244
[Epoch 1, Batch 500] loss: 0.6316860935091972
[Epoch 1, Batch 600] loss: 0.4943329805135727
[Epoch 1, Batch 700] loss: 0.41885285302996633
[Epoch 1, Batch 800] loss: 0.4057286877185106
[Epoch 1, Batch 900] loss: 0.35736833810806273
[Epoch 1, Batch 1000] loss: 0.35626749850809575
[Epoch 1, Batch 1100] loss: 0.2745582378655672
[Epoch 1, Batch 1200] loss: 0.2994629120081663
[Epoch 1, Batch 1300] loss: 0.28742585346102717
[Epoch 1, Batch 1400] loss: 0.2479478683695197
[Epoch 1, Batch 1500] loss: 0.25560135148465635
[Epoch 1, Batch 1600] loss: 0.2484385984018445
[Epoch 1, Batch 1700] loss: 0.21900893907994032
[Epoch 1, Batch 1800] loss: 0.21459772102534772
**STATS for Epoch 1** : 
Average training loss: 0.0074
Average validation loss: 0.1707
Overfitting: 0.1633
Best model saved at epoch 1 with training loss: 0.0074
[Epoch 2, Batch 100] loss: 0.19526069778949023
[Epoch 2, Batch 200] loss: 0.14942855846136807
[Epoch 2, Batch 300] loss: 0.16888255650177597
[Epoch 2, Batch 400] loss: 0.19481185544282198
[Epoch 2, Batch 500] loss: 0.14314911231398583
[Epoch 2, Batch 600] loss: 0.1506029582582414
[Epoch 2, Batch 700] loss: 0.15887303203344344
[Epoch 2, Batch 800] loss: 0.13742260542698204
[Epoch 2, Batch 900] loss: 0.16798984997905791
[Epoch 2, Batch 1000] loss: 0.14112614495679737
[Epoch 2, Batch 1100] loss: 0.13697498951107265
[Epoch 2, Batch 1200] loss: 0.1298329721018672
[Epoch 2, Batch 1300] loss: 0.12623908436857165
[Epoch 2, Batch 1400] loss: 0.12050294260494411
[Epoch 2, Batch 1500] loss: 0.135053363610059
[Epoch 2, Batch 1600] loss: 0.12267021655105054
[Epoch 2, Batch 1700] loss: 0.10545878161676228
[Epoch 2, Batch 1800] loss: 0.12646312047727407
**STATS for Epoch 2** : 
Average training loss: 0.0043
Average validation loss: 0.0948
Overfitting: 0.0905
Best model saved at epoch 2 with training loss: 0.0043
[Epoch 3, Batch 100] loss: 0.11683938911184669
[Epoch 3, Batch 200] loss: 0.08956035090610386
[Epoch 3, Batch 300] loss: 0.10773330501746387
[Epoch 3, Batch 400] loss: 0.08594633101951331
[Epoch 3, Batch 500] loss: 0.1285057368921116
[Epoch 3, Batch 600] loss: 0.09905860380269588
[Epoch 3, Batch 700] loss: 0.10432873063720763
[Epoch 3, Batch 800] loss: 0.10389241545461118
[Epoch 3, Batch 900] loss: 0.08609669215977192
[Epoch 3, Batch 1000] loss: 0.10252946584485471
[Epoch 3, Batch 1100] loss: 0.0845275697670877
[Epoch 3, Batch 1200] loss: 0.09546428116504103
[Epoch 3, Batch 1300] loss: 0.0939612482395023
[Epoch 3, Batch 1400] loss: 0.09098885575309396
[Epoch 3, Batch 1500] loss: 0.08931217789649963
[Epoch 3, Batch 1600] loss: 0.078745324825868
[Epoch 3, Batch 1700] loss: 0.08971175095066428
[Epoch 3, Batch 1800] loss: 0.08485847916919738
**STATS for Epoch 3** : 
Average training loss: 0.0033
Average validation loss: 0.0809
Overfitting: 0.0776
Best model saved at epoch 3 with training loss: 0.0033
[Epoch 4, Batch 100] loss: 0.09647459689993411
[Epoch 4, Batch 200] loss: 0.07787927573081106
[Epoch 4, Batch 300] loss: 0.07601992208277807
[Epoch 4, Batch 400] loss: 0.06426903217099607
[Epoch 4, Batch 500] loss: 0.07937319210264832
[Epoch 4, Batch 600] loss: 0.06197791818063706
[Epoch 4, Batch 700] loss: 0.07815197852673009
[Epoch 4, Batch 800] loss: 0.07336601716931909
[Epoch 4, Batch 900] loss: 0.07074630374438129
[Epoch 4, Batch 1000] loss: 0.0717655846546404
[Epoch 4, Batch 1100] loss: 0.07443774617044255
[Epoch 4, Batch 1200] loss: 0.08564369884552434
[Epoch 4, Batch 1300] loss: 0.07592614927096292
[Epoch 4, Batch 1400] loss: 0.07228140785126015
[Epoch 4, Batch 1500] loss: 0.06692873008083552
[Epoch 4, Batch 1600] loss: 0.08117334874346853
[Epoch 4, Batch 1700] loss: 0.07938180736731738
[Epoch 4, Batch 1800] loss: 0.06231723216711543
**STATS for Epoch 4** : 
Average training loss: 0.0029
Average validation loss: 0.0699
Overfitting: 0.0670
Best model saved at epoch 4 with training loss: 0.0029
[Epoch 5, Batch 100] loss: 0.0634977534553036
[Epoch 5, Batch 200] loss: 0.052536422361154106
[Epoch 5, Batch 300] loss: 0.06438311502803117
[Epoch 5, Batch 400] loss: 0.06307231981772929
[Epoch 5, Batch 500] loss: 0.06431561504025013
[Epoch 5, Batch 600] loss: 0.06653052872046829
[Epoch 5, Batch 700] loss: 0.06254484898177907
[Epoch 5, Batch 800] loss: 0.06133593351114541
[Epoch 5, Batch 900] loss: 0.05645484374137595
[Epoch 5, Batch 1000] loss: 0.06253731867531315
[Epoch 5, Batch 1100] loss: 0.06634875605115667
[Epoch 5, Batch 1200] loss: 0.06931847932748497
[Epoch 5, Batch 1300] loss: 0.07781058452092111
[Epoch 5, Batch 1400] loss: 0.0640953922085464
[Epoch 5, Batch 1500] loss: 0.0713907767191995
[Epoch 5, Batch 1600] loss: 0.050157903609797355
[Epoch 5, Batch 1700] loss: 0.0627940708422102
[Epoch 5, Batch 1800] loss: 0.06432115768780931
**STATS for Epoch 5** : 
Average training loss: 0.0025
Average validation loss: 0.0623
Overfitting: 0.0597
Best model saved at epoch 5 with training loss: 0.0025
[Epoch 6, Batch 100] loss: 0.06036110557615757
[Epoch 6, Batch 200] loss: 0.06217297606868669
[Epoch 6, Batch 300] loss: 0.05093129580724053
[Epoch 6, Batch 400] loss: 0.04726529029314406
[Epoch 6, Batch 500] loss: 0.05596288744360209
[Epoch 6, Batch 600] loss: 0.06086387597606517
[Epoch 6, Batch 700] loss: 0.051815661878790706
[Epoch 6, Batch 800] loss: 0.037309628701768814
[Epoch 6, Batch 900] loss: 0.05775094066513702
[Epoch 6, Batch 1000] loss: 0.059016589102102446
[Epoch 6, Batch 1100] loss: 0.05167736972915009
[Epoch 6, Batch 1200] loss: 0.06513954226160422
[Epoch 6, Batch 1300] loss: 0.05396331755444408
[Epoch 6, Batch 1400] loss: 0.05066086768056266
[Epoch 6, Batch 1500] loss: 0.05061804824799765
[Epoch 6, Batch 1600] loss: 0.0602945912029827
[Epoch 6, Batch 1700] loss: 0.05090611417312175
[Epoch 6, Batch 1800] loss: 0.06152247167890892
**STATS for Epoch 6** : 
Average training loss: 0.0014
Average validation loss: 0.0475
Overfitting: 0.0462
Best model saved at epoch 6 with training loss: 0.0014
[Epoch 7, Batch 100] loss: 0.049398797043832016
[Epoch 7, Batch 200] loss: 0.050338355308631434
[Epoch 7, Batch 300] loss: 0.03785391017096117
[Epoch 7, Batch 400] loss: 0.04325899665709585
[Epoch 7, Batch 500] loss: 0.05801910667854827
[Epoch 7, Batch 600] loss: 0.051791776430327445
[Epoch 7, Batch 700] loss: 0.038157552359625695
[Epoch 7, Batch 800] loss: 0.04538316313701216
[Epoch 7, Batch 900] loss: 0.04776897658477537
[Epoch 7, Batch 1000] loss: 0.04351561658608261
[Epoch 7, Batch 1100] loss: 0.04017981424694881
[Epoch 7, Batch 1200] loss: 0.04787234867690131
[Epoch 7, Batch 1300] loss: 0.0431513832102064
[Epoch 7, Batch 1400] loss: 0.0601720159035176
[Epoch 7, Batch 1500] loss: 0.054881859347224234
[Epoch 7, Batch 1600] loss: 0.05453749768901616
[Epoch 7, Batch 1700] loss: 0.045333482193527744
[Epoch 7, Batch 1800] loss: 0.04554527878994122
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0428
Overfitting: 0.0408
[Epoch 8, Batch 100] loss: 0.04263550262199715
[Epoch 8, Batch 200] loss: 0.057219381579197946
[Epoch 8, Batch 300] loss: 0.031901364871300755
[Epoch 8, Batch 400] loss: 0.04461857777263503
[Epoch 8, Batch 500] loss: 0.043418684843345545
[Epoch 8, Batch 600] loss: 0.04769808054552414
[Epoch 8, Batch 700] loss: 0.05049146836157888
[Epoch 8, Batch 800] loss: 0.045261256655212495
[Epoch 8, Batch 900] loss: 0.03183710922137834
[Epoch 8, Batch 1000] loss: 0.04832980119506829
[Epoch 8, Batch 1100] loss: 0.046417536025401204
[Epoch 8, Batch 1200] loss: 0.03785762830229942
[Epoch 8, Batch 1300] loss: 0.04580383269465529
[Epoch 8, Batch 1400] loss: 0.03918953443877399
[Epoch 8, Batch 1500] loss: 0.03679004322155379
[Epoch 8, Batch 1600] loss: 0.04340149474039208
[Epoch 8, Batch 1700] loss: 0.03053209800913464
[Epoch 8, Batch 1800] loss: 0.0424054158636136
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0411
Overfitting: 0.0392
[Epoch 9, Batch 100] loss: 0.04392024319153279
[Epoch 9, Batch 200] loss: 0.04558365982957184
[Epoch 9, Batch 300] loss: 0.03883310711709782
[Epoch 9, Batch 400] loss: 0.03228131846874021
[Epoch 9, Batch 500] loss: 0.04326640589628369
[Epoch 9, Batch 600] loss: 0.042009495280799454
[Epoch 9, Batch 700] loss: 0.042549483472830614
[Epoch 9, Batch 800] loss: 0.03973355275171343
[Epoch 9, Batch 900] loss: 0.04118154368828982
[Epoch 9, Batch 1000] loss: 0.03220370969094802
[Epoch 9, Batch 1100] loss: 0.03612485987599939
[Epoch 9, Batch 1200] loss: 0.041197575858095664
[Epoch 9, Batch 1300] loss: 0.04852030180161819
[Epoch 9, Batch 1400] loss: 0.040592899765470064
[Epoch 9, Batch 1500] loss: 0.03345144051359966
[Epoch 9, Batch 1600] loss: 0.02991454457689542
[Epoch 9, Batch 1700] loss: 0.034712263350083955
[Epoch 9, Batch 1800] loss: 0.02459817785420455
**STATS for Epoch 9** : 
Average training loss: 0.0013
Average validation loss: 0.0368
Overfitting: 0.0355
Best model saved at epoch 9 with training loss: 0.0013
[Epoch 10, Batch 100] loss: 0.03655554635741282
[Epoch 10, Batch 200] loss: 0.043387477608048355
[Epoch 10, Batch 300] loss: 0.028237439629156143
[Epoch 10, Batch 400] loss: 0.029918925716774538
[Epoch 10, Batch 500] loss: 0.033687657162663524
[Epoch 10, Batch 600] loss: 0.03562366363301408
[Epoch 10, Batch 700] loss: 0.02595979083504062
[Epoch 10, Batch 800] loss: 0.03702572410635185
[Epoch 10, Batch 900] loss: 0.038014019613328856
[Epoch 10, Batch 1000] loss: 0.02970637467922643
[Epoch 10, Batch 1100] loss: 0.03447507209406467
[Epoch 10, Batch 1200] loss: 0.02741637078288477
[Epoch 10, Batch 1300] loss: 0.03887379171996144
[Epoch 10, Batch 1400] loss: 0.037037462611915546
[Epoch 10, Batch 1500] loss: 0.036032422500720716
[Epoch 10, Batch 1600] loss: 0.03536115449533099
[Epoch 10, Batch 1700] loss: 0.03738380681781564
[Epoch 10, Batch 1800] loss: 0.03583146783203119
**STATS for Epoch 10** : 
Average training loss: 0.0010
Average validation loss: 0.0443
Overfitting: 0.0434
Best model saved at epoch 10 with training loss: 0.0010
[Epoch 11, Batch 100] loss: 0.029250901930499822
[Epoch 11, Batch 200] loss: 0.026602696769405156
[Epoch 11, Batch 300] loss: 0.027047191758756525
[Epoch 11, Batch 400] loss: 0.024460367448627948
[Epoch 11, Batch 500] loss: 0.029455802195006982
[Epoch 11, Batch 600] loss: 0.030821779451798648
[Epoch 11, Batch 700] loss: 0.025749610466882587
[Epoch 11, Batch 800] loss: 0.04083366001548711
[Epoch 11, Batch 900] loss: 0.03259453357342863
[Epoch 11, Batch 1000] loss: 0.02706604192382656
[Epoch 11, Batch 1100] loss: 0.03753850751614664
[Epoch 11, Batch 1200] loss: 0.027954568635323085
[Epoch 11, Batch 1300] loss: 0.025350495586753823
[Epoch 11, Batch 1400] loss: 0.042754203357035295
[Epoch 11, Batch 1500] loss: 0.033099801416974516
[Epoch 11, Batch 1600] loss: 0.03210244983813027
[Epoch 11, Batch 1700] loss: 0.034797340669465486
[Epoch 11, Batch 1800] loss: 0.028472589925222565
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0379
Overfitting: 0.0362
[Epoch 12, Batch 100] loss: 0.03295216503625852
[Epoch 12, Batch 200] loss: 0.031052372463891517
[Epoch 12, Batch 300] loss: 0.02629524554067757
[Epoch 12, Batch 400] loss: 0.035044128170702606
[Epoch 12, Batch 500] loss: 0.02177157951547997
[Epoch 12, Batch 600] loss: 0.027538864107918927
[Epoch 12, Batch 700] loss: 0.027397632997599432
[Epoch 12, Batch 800] loss: 0.025577933978347574
[Epoch 12, Batch 900] loss: 0.024925836922193412
[Epoch 12, Batch 1000] loss: 0.025319069885008504
[Epoch 12, Batch 1100] loss: 0.03798584685398964
[Epoch 12, Batch 1200] loss: 0.027047194338520056
[Epoch 12, Batch 1300] loss: 0.03280135200941004
[Epoch 12, Batch 1400] loss: 0.023875289181887638
[Epoch 12, Batch 1500] loss: 0.035225704896292884
[Epoch 12, Batch 1600] loss: 0.03650212105829269
[Epoch 12, Batch 1700] loss: 0.027849607993557582
[Epoch 12, Batch 1800] loss: 0.018715105556184428
**STATS for Epoch 12** : 
Average training loss: 0.0011
Average validation loss: 0.0380
Overfitting: 0.0369
[Epoch 13, Batch 100] loss: 0.02212582998443395
[Epoch 13, Batch 200] loss: 0.028191056071955246
[Epoch 13, Batch 300] loss: 0.027652989081689158
[Epoch 13, Batch 400] loss: 0.01603366889117751
[Epoch 13, Batch 500] loss: 0.025578182095778175
[Epoch 13, Batch 600] loss: 0.02331826375491801
[Epoch 13, Batch 700] loss: 0.02160212616305216
[Epoch 13, Batch 800] loss: 0.026425662897672737
[Epoch 13, Batch 900] loss: 0.02067566026322311
[Epoch 13, Batch 1000] loss: 0.022666165986593115
[Epoch 13, Batch 1100] loss: 0.022576287486735964
[Epoch 13, Batch 1200] loss: 0.027471586124738677
[Epoch 13, Batch 1300] loss: 0.024618357571889647
[Epoch 13, Batch 1400] loss: 0.03549522960238392
[Epoch 13, Batch 1500] loss: 0.022469880096323322
[Epoch 13, Batch 1600] loss: 0.028159280327672606
[Epoch 13, Batch 1700] loss: 0.027506412683578674
[Epoch 13, Batch 1800] loss: 0.02767245006747544
**STATS for Epoch 13** : 
Average training loss: 0.0012
Average validation loss: 0.0342
Overfitting: 0.0330
[Epoch 14, Batch 100] loss: 0.017312388115096836
[Epoch 14, Batch 200] loss: 0.022043208732793574
[Epoch 14, Batch 300] loss: 0.02251968880635104
[Epoch 14, Batch 400] loss: 0.024754733238733024
[Epoch 14, Batch 500] loss: 0.02111871235712897
[Epoch 14, Batch 600] loss: 0.02496885950997239
[Epoch 14, Batch 700] loss: 0.025675069352728314
[Epoch 14, Batch 800] loss: 0.01874337044049753
[Epoch 14, Batch 900] loss: 0.030194052593433298
[Epoch 14, Batch 1000] loss: 0.0258451228713966
[Epoch 14, Batch 1100] loss: 0.023230752611125352
[Epoch 14, Batch 1200] loss: 0.025156036522093927
[Epoch 14, Batch 1300] loss: 0.025440328998374753
[Epoch 14, Batch 1400] loss: 0.02567323378068977
[Epoch 14, Batch 1500] loss: 0.02597647819231497
[Epoch 14, Batch 1600] loss: 0.02831925379636232
[Epoch 14, Batch 1700] loss: 0.023549470874713735
[Epoch 14, Batch 1800] loss: 0.0214567972435907
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0345
Overfitting: 0.0338
Best model saved at epoch 14 with training loss: 0.0007
[Epoch 15, Batch 100] loss: 0.01572667118511163
[Epoch 15, Batch 200] loss: 0.017967479542130606
[Epoch 15, Batch 300] loss: 0.01816270366689423
[Epoch 15, Batch 400] loss: 0.017509178115433316
[Epoch 15, Batch 500] loss: 0.021011464507610073
[Epoch 15, Batch 600] loss: 0.01885810384032084
[Epoch 15, Batch 700] loss: 0.02248446175712161
[Epoch 15, Batch 800] loss: 0.017779698765079958
[Epoch 15, Batch 900] loss: 0.028794338704174152
[Epoch 15, Batch 1000] loss: 0.024026836066623217
[Epoch 15, Batch 1100] loss: 0.021629393256589538
[Epoch 15, Batch 1200] loss: 0.021309441986159073
[Epoch 15, Batch 1300] loss: 0.03792439907527296
[Epoch 15, Batch 1400] loss: 0.014979499555192888
[Epoch 15, Batch 1500] loss: 0.021501847101608292
[Epoch 15, Batch 1600] loss: 0.022630765193025582
[Epoch 15, Batch 1700] loss: 0.02566006893408485
[Epoch 15, Batch 1800] loss: 0.024369728730962378
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0329
Overfitting: 0.0319
[Epoch 16, Batch 100] loss: 0.01861615134344902
[Epoch 16, Batch 200] loss: 0.015339194417756517
[Epoch 16, Batch 300] loss: 0.016505649565806378
[Epoch 16, Batch 400] loss: 0.023703677444864298
[Epoch 16, Batch 500] loss: 0.0214380076204543
[Epoch 16, Batch 600] loss: 0.016251307430211456
[Epoch 16, Batch 700] loss: 0.016851243870551116
[Epoch 16, Batch 800] loss: 0.021216783849085916
[Epoch 16, Batch 900] loss: 0.02232733376979013
[Epoch 16, Batch 1000] loss: 0.024990580465528184
[Epoch 16, Batch 1100] loss: 0.023075716186576757
[Epoch 16, Batch 1200] loss: 0.024864968680922174
[Epoch 16, Batch 1300] loss: 0.020374670898163458
[Epoch 16, Batch 1400] loss: 0.01706599315220956
[Epoch 16, Batch 1500] loss: 0.02347881382513151
[Epoch 16, Batch 1600] loss: 0.021362551084312145
[Epoch 16, Batch 1700] loss: 0.018314414416381625
[Epoch 16, Batch 1800] loss: 0.018609499567974128
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0396
Overfitting: 0.0389
[Epoch 17, Batch 100] loss: 0.019828445607417963
[Epoch 17, Batch 200] loss: 0.018514943473855964
[Epoch 17, Batch 300] loss: 0.014231315945362439
[Epoch 17, Batch 400] loss: 0.016248707896156702
[Epoch 17, Batch 500] loss: 0.01130973014209303
[Epoch 17, Batch 600] loss: 0.021111712710699067
[Epoch 17, Batch 700] loss: 0.014745904460505698
[Epoch 17, Batch 800] loss: 0.023277142658480444
[Epoch 17, Batch 900] loss: 0.020943458342953816
[Epoch 17, Batch 1000] loss: 0.015721269008790843
[Epoch 17, Batch 1100] loss: 0.017799149916827448
[Epoch 17, Batch 1200] loss: 0.01805349366310111
[Epoch 17, Batch 1300] loss: 0.01975002053346543
[Epoch 17, Batch 1400] loss: 0.017965157697617543
[Epoch 17, Batch 1500] loss: 0.019081254135235214
[Epoch 17, Batch 1600] loss: 0.021657176985463593
[Epoch 17, Batch 1700] loss: 0.020657285729503202
[Epoch 17, Batch 1800] loss: 0.013559105487365742
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0333
Overfitting: 0.0324
[Epoch 18, Batch 100] loss: 0.014631428800566938
[Epoch 18, Batch 200] loss: 0.018752289309486515
[Epoch 18, Batch 300] loss: 0.015720164973608917
[Epoch 18, Batch 400] loss: 0.018815362367968193
[Epoch 18, Batch 500] loss: 0.01267743587050063
[Epoch 18, Batch 600] loss: 0.021632322420300623
[Epoch 18, Batch 700] loss: 0.017234044750075554
[Epoch 18, Batch 800] loss: 0.015813899544009472
[Epoch 18, Batch 900] loss: 0.015856000132043847
[Epoch 18, Batch 1000] loss: 0.018064448862787685
[Epoch 18, Batch 1100] loss: 0.019360073921852745
[Epoch 18, Batch 1200] loss: 0.017856460084876746
[Epoch 18, Batch 1300] loss: 0.01395973037055228
[Epoch 18, Batch 1400] loss: 0.01810371652361937
[Epoch 18, Batch 1500] loss: 0.014063764997918043
[Epoch 18, Batch 1600] loss: 0.015154540780713432
[Epoch 18, Batch 1700] loss: 0.019299487231182865
[Epoch 18, Batch 1800] loss: 0.016367461005647784
**STATS for Epoch 18** : 
Average training loss: 0.0011
Average validation loss: 0.0372
Overfitting: 0.0362
[Epoch 19, Batch 100] loss: 0.01197968558743014
[Epoch 19, Batch 200] loss: 0.016349335885533948
[Epoch 19, Batch 300] loss: 0.013816157648761873
[Epoch 19, Batch 400] loss: 0.016554142013192177
[Epoch 19, Batch 500] loss: 0.014940740019974329
[Epoch 19, Batch 600] loss: 0.013147500613486044
[Epoch 19, Batch 700] loss: 0.01461340490495786
[Epoch 19, Batch 800] loss: 0.020226745578547707
[Epoch 19, Batch 900] loss: 0.01770432572819118
[Epoch 19, Batch 1000] loss: 0.015606309940485516
[Epoch 19, Batch 1100] loss: 0.018673583303025224
[Epoch 19, Batch 1200] loss: 0.015237860430206638
[Epoch 19, Batch 1300] loss: 0.012245893754879944
[Epoch 19, Batch 1400] loss: 0.012536173357075313
[Epoch 19, Batch 1500] loss: 0.014864701828109901
[Epoch 19, Batch 1600] loss: 0.013207853282801807
[Epoch 19, Batch 1700] loss: 0.018398947351124663
[Epoch 19, Batch 1800] loss: 0.014329845549946185
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0303
Overfitting: 0.0296
Best model saved at epoch 19 with training loss: 0.0007
[Epoch 20, Batch 100] loss: 0.009050941995155881
[Epoch 20, Batch 200] loss: 0.0076013345003593715
[Epoch 20, Batch 300] loss: 0.010528362747863866
[Epoch 20, Batch 400] loss: 0.0162872454835815
[Epoch 20, Batch 500] loss: 0.015289150832322775
[Epoch 20, Batch 600] loss: 0.014111110736994305
[Epoch 20, Batch 700] loss: 0.015480610180020449
[Epoch 20, Batch 800] loss: 0.011943365832084964
[Epoch 20, Batch 900] loss: 0.010324618488521082
[Epoch 20, Batch 1000] loss: 0.022347634470497722
[Epoch 20, Batch 1100] loss: 0.013925852031825343
[Epoch 20, Batch 1200] loss: 0.014152941403299337
[Epoch 20, Batch 1300] loss: 0.016767475057422418
[Epoch 20, Batch 1400] loss: 0.009167100342529011
[Epoch 20, Batch 1500] loss: 0.010881736555747921
[Epoch 20, Batch 1600] loss: 0.01220344182147528
[Epoch 20, Batch 1700] loss: 0.013026457422784006
[Epoch 20, Batch 1800] loss: 0.011086723265761975
**STATS for Epoch 20** : 
Average training loss: 0.0007
Average validation loss: 0.0353
Overfitting: 0.0346
[Epoch 21, Batch 100] loss: 0.010099964770342923
[Epoch 21, Batch 200] loss: 0.014011412350591855
[Epoch 21, Batch 300] loss: 0.010804672741251124
[Epoch 21, Batch 400] loss: 0.012973978492373134
[Epoch 21, Batch 500] loss: 0.01143192293784523
[Epoch 21, Batch 600] loss: 0.010612300615939603
[Epoch 21, Batch 700] loss: 0.008525888190197293
[Epoch 21, Batch 800] loss: 0.010103947549068834
[Epoch 21, Batch 900] loss: 0.012378520017391566
[Epoch 21, Batch 1000] loss: 0.011225888897270124
[Epoch 21, Batch 1100] loss: 0.010168573818846198
[Epoch 21, Batch 1200] loss: 0.009929737879429013
[Epoch 21, Batch 1300] loss: 0.011441875813870865
[Epoch 21, Batch 1400] loss: 0.014041282625112218
[Epoch 21, Batch 1500] loss: 0.022744526068636334
[Epoch 21, Batch 1600] loss: 0.010749236518058751
[Epoch 21, Batch 1700] loss: 0.013307981043180917
[Epoch 21, Batch 1800] loss: 0.013536325620807475
**STATS for Epoch 21** : 
Average training loss: 0.0008
Average validation loss: 0.0323
Overfitting: 0.0316
[Epoch 22, Batch 100] loss: 0.014304110840166686
[Epoch 22, Batch 200] loss: 0.016154848885526006
[Epoch 22, Batch 300] loss: 0.009208572207571706
[Epoch 22, Batch 400] loss: 0.009634260917518987
[Epoch 22, Batch 500] loss: 0.015068149471553625
[Epoch 22, Batch 600] loss: 0.008010705346459873
[Epoch 22, Batch 700] loss: 0.011137453436895157
[Epoch 22, Batch 800] loss: 0.017252512537124856
[Epoch 22, Batch 900] loss: 0.012969859330623876
[Epoch 22, Batch 1000] loss: 0.016377475505323674
[Epoch 22, Batch 1100] loss: 0.013921429627807812
[Epoch 22, Batch 1200] loss: 0.011459402326618146
[Epoch 22, Batch 1300] loss: 0.010737755645332072
[Epoch 22, Batch 1400] loss: 0.013767390471402905
[Epoch 22, Batch 1500] loss: 0.011696927877419511
[Epoch 22, Batch 1600] loss: 0.010245080689746828
[Epoch 22, Batch 1700] loss: 0.012215435552134295
[Epoch 22, Batch 1800] loss: 0.006674295664379315
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0330
Overfitting: 0.0327
Best model saved at epoch 22 with training loss: 0.0003
[Epoch 23, Batch 100] loss: 0.0059008545831784436
[Epoch 23, Batch 200] loss: 0.011068823388468445
[Epoch 23, Batch 300] loss: 0.009364661884537781
[Epoch 23, Batch 400] loss: 0.008388882728231692
[Epoch 23, Batch 500] loss: 0.010608321699937733
[Epoch 23, Batch 600] loss: 0.006315499362171977
[Epoch 23, Batch 700] loss: 0.008574076841832722
[Epoch 23, Batch 800] loss: 0.008259056419119589
[Epoch 23, Batch 900] loss: 0.013493443974293768
[Epoch 23, Batch 1000] loss: 0.013969463738139893
[Epoch 23, Batch 1100] loss: 0.008939253077187459
[Epoch 23, Batch 1200] loss: 0.0123743248610117
[Epoch 23, Batch 1300] loss: 0.018046770808068685
[Epoch 23, Batch 1400] loss: 0.009515288920738385
[Epoch 23, Batch 1500] loss: 0.009731615388664067
[Epoch 23, Batch 1600] loss: 0.015030456143322227
[Epoch 23, Batch 1700] loss: 0.019905006779663382
[Epoch 23, Batch 1800] loss: 0.013416121960763121
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0339
Overfitting: 0.0335
[Epoch 24, Batch 100] loss: 0.007688372424308909
[Epoch 24, Batch 200] loss: 0.010191017508477672
[Epoch 24, Batch 300] loss: 0.00810165007816977
[Epoch 24, Batch 400] loss: 0.00711340383220886
[Epoch 24, Batch 500] loss: 0.00968695551273413
[Epoch 24, Batch 600] loss: 0.00926717147041927
[Epoch 24, Batch 700] loss: 0.009743231543925503
[Epoch 24, Batch 800] loss: 0.012496185592826805
[Epoch 24, Batch 900] loss: 0.007807456607442873
[Epoch 24, Batch 1000] loss: 0.013002970493635075
[Epoch 24, Batch 1100] loss: 0.0119846166536081
[Epoch 24, Batch 1200] loss: 0.010072532115591457
[Epoch 24, Batch 1300] loss: 0.010034484948264435
[Epoch 24, Batch 1400] loss: 0.009474634488888113
[Epoch 24, Batch 1500] loss: 0.011524561979931604
[Epoch 24, Batch 1600] loss: 0.020351857201749226
[Epoch 24, Batch 1700] loss: 0.01198847485713486
[Epoch 24, Batch 1800] loss: 0.01603380860418838
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0317
Overfitting: 0.0314
qt.qpa.xcb: X server does not support XInput 2
+++FINAL STATS++++
Training Loss 0.0003361559014612188
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0008094764402330428, 'batch_size': 32} on final Test set to find Test loss for overfitting
 Testing loss : 0.0317
Calculated Overfitting : 0.0314
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0008094764402330428, 'batch_size': 32} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9894
Total time taken for hyperparameter tuning and evaluation: 4:46:54
/home/ahussain/PycharmProjects/optunaNew/optuna_TrialPruner.py:515: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.


Process finished with exit code 0

