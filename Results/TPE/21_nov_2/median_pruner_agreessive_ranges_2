-----------------------------------------------------------
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  9
  Number of complete trials:  15
Best hyperparameters found:
{'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16}
Best trial:
  Value:  0.0616292772171084

------------------------------------------------------------
**STATS for Epoch 24** : 
Average training loss: 0.0001
Using best hyperparameters {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16} on final Test set to find Test loss for overfitting
Testing loss : 0.0472
Calculated Overfitting : 0.0471
Using best hyperparameters {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9866
Total time taken for hyperparameter tuning and evaluation: 2:51:36

-----------------------------------------------------------
EPOCHS = 24
CLASSES = 10
INNER_FOLD = 2
NUM_SAMPLES = 24
DIR = os.getcwd()

#---------PRUNER SETTINGS--------------
N_STARTUP_TRIALS_PRUNNER = 5 #The pruner will not prune any trials until n trials have been completed  unlike asha pruning start from 1 or 2 trials
N_WARMUP_STEPS = 5           #Each trial must reach at least n epochs before it becomes eligible for pruning.
INTERVAL_STEPS = 1           #The pruner will check for pruning opportunities after every epoch following the warm-up period

N_MIN_TRIALS = 5             #At least n trials must have reported intermediate results at the same step, but since n_start_up trial have this covered
                             #Ensures that the median is calculated from a minimum of n data points at each epoch.
#---------TPE SETTINGS-----------------
N_STARTUP_TRIALS = 8    #The random sampling is used instead of the TPE algorithm until the given number of trials finish in the same study.

-----------------------------------------------------------

[I 2024-11-21 22:00:05,839] A new study created in RDB with name: MedianPruner_ranges_21_2_nov

Selected Hyperparameters for Trial 1:
  l1: 256, l2: 64, lr: 4.207988669606632e-05, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.303935401439667
[Epoch 1, Batch 200] loss: 2.3021901130676268
[Epoch 1, Batch 300] loss: 2.301714975833893
[Epoch 1, Batch 400] loss: 2.3012550401687624
**STATS for Epoch 1** : 
Average training loss: 0.3381
Average validation loss: 2.2988
Validation Accuracy: 0.1417
Overfitting: 1.9607
Best model saved at epoch 1 with validation loss: 2.2988
[Epoch 2, Batch 100] loss: 2.2980636858940127
[Epoch 2, Batch 200] loss: 2.29657173871994
[Epoch 2, Batch 300] loss: 2.2940568709373474
[Epoch 2, Batch 400] loss: 2.292155909538269
**STATS for Epoch 2** : 
Average training loss: 0.3370
Average validation loss: 2.2915
Validation Accuracy: 0.1695
Overfitting: 1.9544
Best model saved at epoch 2 with validation loss: 2.2915
[Epoch 3, Batch 100] loss: 2.2903819918632506
[Epoch 3, Batch 200] loss: 2.2875904989242555
[Epoch 3, Batch 300] loss: 2.286614556312561
[Epoch 3, Batch 400] loss: 2.2858663153648378
**STATS for Epoch 3** : 
Average training loss: 0.3359
Average validation loss: 2.2833
Validation Accuracy: 0.2028
Overfitting: 1.9474
Best model saved at epoch 3 with validation loss: 2.2833
[Epoch 4, Batch 100] loss: 2.2818669414520265
[Epoch 4, Batch 200] loss: 2.279550943374634
[Epoch 4, Batch 300] loss: 2.278515374660492
[Epoch 4, Batch 400] loss: 2.274325466156006
**STATS for Epoch 4** : 
Average training loss: 0.3347
Average validation loss: 2.2733
Validation Accuracy: 0.2353
Overfitting: 1.9387
Best model saved at epoch 4 with validation loss: 2.2733
[Epoch 5, Batch 100] loss: 2.270380711555481
[Epoch 5, Batch 200] loss: 2.2682414937019346
[Epoch 5, Batch 300] loss: 2.268529815673828
[Epoch 5, Batch 400] loss: 2.262654814720154
**STATS for Epoch 5** : 
Average training loss: 0.3331
Average validation loss: 2.2607
Validation Accuracy: 0.2728
Overfitting: 1.9276
Best model saved at epoch 5 with validation loss: 2.2607
[Epoch 6, Batch 100] loss: 2.258898913860321
[Epoch 6, Batch 200] loss: 2.2550984120368955
[Epoch 6, Batch 300] loss: 2.252696433067322
[Epoch 6, Batch 400] loss: 2.247967338562012
**STATS for Epoch 6** : 
Average training loss: 0.3302
Average validation loss: 2.2436
Validation Accuracy: 0.3479
Overfitting: 1.9133
Best model saved at epoch 6 with validation loss: 2.2436
[Epoch 7, Batch 100] loss: 2.2411406683921813
[Epoch 7, Batch 200] loss: 2.2353138256073
[Epoch 7, Batch 300] loss: 2.2335375332832337
[Epoch 7, Batch 400] loss: 2.2258972239494326
**STATS for Epoch 7** : 
Average training loss: 0.3268
Average validation loss: 2.2196
Validation Accuracy: 0.4355
Overfitting: 1.8927
Best model saved at epoch 7 with validation loss: 2.2196
[Epoch 8, Batch 100] loss: 2.215717701911926
[Epoch 8, Batch 200] loss: 2.2096177101135255
[Epoch 8, Batch 300] loss: 2.203212685585022
[Epoch 8, Batch 400] loss: 2.1939072799682617
**STATS for Epoch 8** : 
Average training loss: 0.3220
Average validation loss: 2.1843
Validation Accuracy: 0.4979
Overfitting: 1.8623
Best model saved at epoch 8 with validation loss: 2.1843
[Epoch 9, Batch 100] loss: 2.179885060787201
[Epoch 9, Batch 200] loss: 2.1703153371810915
[Epoch 9, Batch 300] loss: 2.1559592604637148
[Epoch 9, Batch 400] loss: 2.1470467114448546
**STATS for Epoch 9** : 
Average training loss: 0.3145
Average validation loss: 2.1301
Validation Accuracy: 0.5149
Overfitting: 1.8156
Best model saved at epoch 9 with validation loss: 2.1301
[Epoch 10, Batch 100] loss: 2.126816132068634
[Epoch 10, Batch 200] loss: 2.1107252979278566
[Epoch 10, Batch 300] loss: 2.0889035487174987
[Epoch 10, Batch 400] loss: 2.0679924511909484
**STATS for Epoch 10** : 
Average training loss: 0.3008
Average validation loss: 2.0430
Validation Accuracy: 0.5274
Overfitting: 1.7422
Best model saved at epoch 10 with validation loss: 2.0430
[Epoch 11, Batch 100] loss: 2.0283281350135804
[Epoch 11, Batch 200] loss: 2.0091941714286805
[Epoch 11, Batch 300] loss: 1.9777893030643463
[Epoch 11, Batch 400] loss: 1.9434753346443177
**STATS for Epoch 11** : 
Average training loss: 0.2809
Average validation loss: 1.8986
Validation Accuracy: 0.5585
Overfitting: 1.6177
Best model saved at epoch 11 with validation loss: 1.8986
[Epoch 12, Batch 100] loss: 1.8769072461128236
[Epoch 12, Batch 200] loss: 1.8356492936611175
[Epoch 12, Batch 300] loss: 1.7873995113372803
[Epoch 12, Batch 400] loss: 1.7296829652786254
**STATS for Epoch 12** : 
Average training loss: 0.2495
Average validation loss: 1.6633
Validation Accuracy: 0.6081
Overfitting: 1.4138
Best model saved at epoch 12 with validation loss: 1.6633
[Epoch 13, Batch 100] loss: 1.6338262796401977
[Epoch 13, Batch 200] loss: 1.5756877446174622
[Epoch 13, Batch 300] loss: 1.4830332171916962
[Epoch 13, Batch 400] loss: 1.4126819229125978
**STATS for Epoch 13** : 
Average training loss: 0.2033
Average validation loss: 1.3344
Validation Accuracy: 0.7086
Overfitting: 1.1311
Best model saved at epoch 13 with validation loss: 1.3344
[Epoch 14, Batch 100] loss: 1.3017401123046874
[Epoch 14, Batch 200] loss: 1.2278934240341186
[Epoch 14, Batch 300] loss: 1.156680046916008
[Epoch 14, Batch 400] loss: 1.0958649390935897
**STATS for Epoch 14** : 
Average training loss: 0.1515
Average validation loss: 1.0201
Validation Accuracy: 0.7744
Overfitting: 0.8686
Best model saved at epoch 14 with validation loss: 1.0201
[Epoch 15, Batch 100] loss: 0.9859721660614014
[Epoch 15, Batch 200] loss: 0.9376795017719268
[Epoch 15, Batch 300] loss: 0.9027546179294587
[Epoch 15, Batch 400] loss: 0.869182670712471
**STATS for Epoch 15** : 
Average training loss: 0.1215
Average validation loss: 0.8149
Validation Accuracy: 0.7996
Overfitting: 0.6934
Best model saved at epoch 15 with validation loss: 0.8149
[Epoch 16, Batch 100] loss: 0.8068584316968918
[Epoch 16, Batch 200] loss: 0.7751777738332748
[Epoch 16, Batch 300] loss: 0.7321378296613693
[Epoch 16, Batch 400] loss: 0.722322569489479
**STATS for Epoch 16** : 
Average training loss: 0.1042
Average validation loss: 0.6952
Validation Accuracy: 0.8159
Overfitting: 0.5910
Best model saved at epoch 16 with validation loss: 0.6952
[Epoch 17, Batch 100] loss: 0.6998469796776772
[Epoch 17, Batch 200] loss: 0.6789437064528465
[Epoch 17, Batch 300] loss: 0.6430475652217865
[Epoch 17, Batch 400] loss: 0.6322846880555153
**STATS for Epoch 17** : 
Average training loss: 0.0909
Average validation loss: 0.6187
Validation Accuracy: 0.8317
Overfitting: 0.5279
Best model saved at epoch 17 with validation loss: 0.6187
[Epoch 18, Batch 100] loss: 0.5889787632226944
[Epoch 18, Batch 200] loss: 0.6003226017951966
[Epoch 18, Batch 300] loss: 0.6047685608267784
[Epoch 18, Batch 400] loss: 0.594507828950882
**STATS for Epoch 18** : 
Average training loss: 0.0855
Average validation loss: 0.5677
Validation Accuracy: 0.8413
Overfitting: 0.4823
Best model saved at epoch 18 with validation loss: 0.5677
[Epoch 19, Batch 100] loss: 0.5721751153469086
[Epoch 19, Batch 200] loss: 0.5559771341085434
[Epoch 19, Batch 300] loss: 0.5521097692847252
[Epoch 19, Batch 400] loss: 0.5359016728401184
**STATS for Epoch 19** : 
Average training loss: 0.0779
Average validation loss: 0.5284
Validation Accuracy: 0.8499
Overfitting: 0.4505
Best model saved at epoch 19 with validation loss: 0.5284
[Epoch 20, Batch 100] loss: 0.5306561809778213
[Epoch 20, Batch 200] loss: 0.5285176160931587
[Epoch 20, Batch 300] loss: 0.5186012440919876
[Epoch 20, Batch 400] loss: 0.5130911859869957
**STATS for Epoch 20** : 
Average training loss: 0.0701
Average validation loss: 0.4976
Validation Accuracy: 0.8592
Overfitting: 0.4275
Best model saved at epoch 20 with validation loss: 0.4976
[Epoch 21, Batch 100] loss: 0.5024034067988395
[Epoch 21, Batch 200] loss: 0.4803252297639847
[Epoch 21, Batch 300] loss: 0.48701002418994904
[Epoch 21, Batch 400] loss: 0.48485559582710264
**STATS for Epoch 21** : 
Average training loss: 0.0718
Average validation loss: 0.4749
Validation Accuracy: 0.8618
Overfitting: 0.4031
Best model saved at epoch 21 with validation loss: 0.4749
[Epoch 22, Batch 100] loss: 0.4760780072212219
[Epoch 22, Batch 200] loss: 0.4621532742679119
[Epoch 22, Batch 300] loss: 0.4570571705698967
[Epoch 22, Batch 400] loss: 0.47208438128232955
**STATS for Epoch 22** : 
Average training loss: 0.0665
Average validation loss: 0.4502
Validation Accuracy: 0.8703
Overfitting: 0.3837
Best model saved at epoch 22 with validation loss: 0.4502
[Epoch 23, Batch 100] loss: 0.4466338257491589
[Epoch 23, Batch 200] loss: 0.45161677539348605
[Epoch 23, Batch 300] loss: 0.44883410692214964
[Epoch 23, Batch 400] loss: 0.4328913915157318
**STATS for Epoch 23** : 
Average training loss: 0.0651
Average validation loss: 0.4326
Validation Accuracy: 0.8750
Overfitting: 0.3675
Best model saved at epoch 23 with validation loss: 0.4326
[Epoch 24, Batch 100] loss: 0.42686794251203536
[Epoch 24, Batch 200] loss: 0.4454483537375927
[Epoch 24, Batch 300] loss: 0.43606709226965906
[Epoch 24, Batch 400] loss: 0.4162988901138306
**STATS for Epoch 24** : 
Average training loss: 0.0599
Average validation loss: 0.4146
Validation Accuracy: 0.8807
Overfitting: 0.3547
Best model saved at epoch 24 with validation loss: 0.4146
Fold 1 validation loss: 0.4146
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.3040696358680726
[Epoch 1, Batch 200] loss: 2.3039174318313598
[Epoch 1, Batch 300] loss: 2.3035399675369264
[Epoch 1, Batch 400] loss: 2.302353091239929
**STATS for Epoch 1** : 
Average training loss: 0.3385
Average validation loss: 2.3010
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
Validation Accuracy: 0.1238
Overfitting: 1.9625
Best model saved at epoch 1 with validation loss: 2.3010
[Epoch 2, Batch 100] loss: 2.299441475868225
[Epoch 2, Batch 200] loss: 2.2995796370506287
[Epoch 2, Batch 300] loss: 2.29844580411911
[Epoch 2, Batch 400] loss: 2.297910792827606
**STATS for Epoch 2** : 
Average training loss: 0.3381
Average validation loss: 2.2966
Validation Accuracy: 0.1278
Overfitting: 1.9585
Best model saved at epoch 2 with validation loss: 2.2966
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 1 is already reported.
  warnings.warn(
[Epoch 3, Batch 100] loss: 2.295863914489746
[Epoch 3, Batch 200] loss: 2.29527801990509
[Epoch 3, Batch 300] loss: 2.293514814376831
[Epoch 3, Batch 400] loss: 2.2936793470382693
**STATS for Epoch 3** : 
Average training loss: 0.3373
Average validation loss: 2.2921
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 2 is already reported.
  warnings.warn(
Validation Accuracy: 0.1375
Overfitting: 1.9548
Best model saved at epoch 3 with validation loss: 2.2921
[Epoch 4, Batch 100] loss: 2.2913595843315124
[Epoch 4, Batch 200] loss: 2.2909378671646117
[Epoch 4, Batch 300] loss: 2.2892117166519164
[Epoch 4, Batch 400] loss: 2.2886446261405946
**STATS for Epoch 4** : 
Average training loss: 0.3365
Average validation loss: 2.2872
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 3 is already reported.
  warnings.warn(
Validation Accuracy: 0.1520
Overfitting: 1.9507
Best model saved at epoch 4 with validation loss: 2.2872
[Epoch 5, Batch 100] loss: 2.2867557263374327
[Epoch 5, Batch 200] loss: 2.2851545858383178
[Epoch 5, Batch 300] loss: 2.2846376156806945
[Epoch 5, Batch 400] loss: 2.2827545523643495
**STATS for Epoch 5** : 
Average training loss: 0.3358
Average validation loss: 2.2816
Validation Accuracy: 0.1682
Overfitting: 1.9459
Best model saved at epoch 5 with validation loss: 2.2816
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 4 is already reported.
  warnings.warn(
[Epoch 6, Batch 100] loss: 2.2798633408546447
[Epoch 6, Batch 200] loss: 2.2807485628128052
[Epoch 6, Batch 300] loss: 2.277610960006714
[Epoch 6, Batch 400] loss: 2.277466402053833
**STATS for Epoch 6** : 
Average training loss: 0.3348
Average validation loss: 2.2751
Validation Accuracy: 0.1873
Overfitting: 1.9403
Best model saved at epoch 6 with validation loss: 2.2751
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 5 is already reported.
  warnings.warn(
[Epoch 7, Batch 100] loss: 2.2754810070991516
[Epoch 7, Batch 200] loss: 2.2722133350372316
[Epoch 7, Batch 300] loss: 2.2718409729003906
[Epoch 7, Batch 400] loss: 2.2687245297431944
**STATS for Epoch 7** : 
Average training loss: 0.3335
Average validation loss: 2.2671
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 6 is already reported.
  warnings.warn(
Validation Accuracy: 0.2093
Overfitting: 1.9336
Best model saved at epoch 7 with validation loss: 2.2671
[Epoch 8, Batch 100] loss: 2.2671046662330627
[Epoch 8, Batch 200] loss: 2.2648126602172853
[Epoch 8, Batch 300] loss: 2.2614464354515076
[Epoch 8, Batch 400] loss: 2.2594928407669066
**STATS for Epoch 8** : 
Average training loss: 0.3321
Average validation loss: 2.2569
Validation Accuracy: 0.2400
Overfitting: 1.9248
Best model saved at epoch 8 with validation loss: 2.2569
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 7 is already reported.
  warnings.warn(
[Epoch 9, Batch 100] loss: 2.255540676116943
[Epoch 9, Batch 200] loss: 2.252187476158142
[Epoch 9, Batch 300] loss: 2.2512818121910096
[Epoch 9, Batch 400] loss: 2.249052243232727
**STATS for Epoch 9** : 
Average training loss: 0.3301
Average validation loss: 2.2435
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 8 is already reported.
  warnings.warn(
Validation Accuracy: 0.2860
Overfitting: 1.9135
Best model saved at epoch 9 with validation loss: 2.2435
[Epoch 10, Batch 100] loss: 2.2422474431991577
[Epoch 10, Batch 200] loss: 2.2377616596221923
[Epoch 10, Batch 300] loss: 2.235036995410919
[Epoch 10, Batch 400] loss: 2.230462205410004
**STATS for Epoch 10** : 
Average training loss: 0.3278
Average validation loss: 2.2253
Validation Accuracy: 0.3373
Overfitting: 1.8974
Best model saved at epoch 10 with validation loss: 2.2253
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 9 is already reported.
  warnings.warn(
[Epoch 11, Batch 100] loss: 2.223085792064667
[Epoch 11, Batch 200] loss: 2.2205376839637756
[Epoch 11, Batch 300] loss: 2.2123810839653015
[Epoch 11, Batch 400] loss: 2.205979468822479
**STATS for Epoch 11** : 
Average training loss: 0.3239
Average validation loss: 2.1993
Validation Accuracy: 0.3956
Overfitting: 1.8753
Best model saved at epoch 11 with validation loss: 2.1993
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 10 is already reported.
  warnings.warn(
[Epoch 12, Batch 100] loss: 2.1971085810661317
[Epoch 12, Batch 200] loss: 2.1886261439323427
[Epoch 12, Batch 300] loss: 2.1821199870109558
[Epoch 12, Batch 400] loss: 2.1718661761283875
**STATS for Epoch 12** : 
Average training loss: 0.3183
Average validation loss: 2.1604
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 11 is already reported.
  warnings.warn(
Validation Accuracy: 0.4649
Overfitting: 1.8421
Best model saved at epoch 12 with validation loss: 2.1604
[Epoch 13, Batch 100] loss: 2.1566050267219543
[Epoch 13, Batch 200] loss: 2.144530704021454
[Epoch 13, Batch 300] loss: 2.1315224075317385
[Epoch 13, Batch 400] loss: 2.119144625663757
**STATS for Epoch 13** : 
Average training loss: 0.3091
Average validation loss: 2.0980
Validation Accuracy: 0.5370
Overfitting: 1.7889
Best model saved at epoch 13 with validation loss: 2.0980
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 12 is already reported.
  warnings.warn(
[Epoch 14, Batch 100] loss: 2.0857639074325562
[Epoch 14, Batch 200] loss: 2.0684806287288664
[Epoch 14, Batch 300] loss: 2.054787274599075
[Epoch 14, Batch 400] loss: 2.031733914613724
**STATS for Epoch 14** : 
Average training loss: 0.2952
Average validation loss: 1.9963
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 13 is already reported.
  warnings.warn(
Validation Accuracy: 0.5893
Overfitting: 1.7012
Best model saved at epoch 14 with validation loss: 1.9963
[Epoch 15, Batch 100] loss: 1.9847554111480712
[Epoch 15, Batch 200] loss: 1.9513747429847716
[Epoch 15, Batch 300] loss: 1.9191715407371521
[Epoch 15, Batch 400] loss: 1.8774367249011994
**STATS for Epoch 15** : 
Average training loss: 0.2718
Average validation loss: 1.8293
Validation Accuracy: 0.6301
Overfitting: 1.5575
Best model saved at epoch 15 with validation loss: 1.8293
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 14 is already reported.
  warnings.warn(
[Epoch 16, Batch 100] loss: 1.8019095528125764
[Epoch 16, Batch 200] loss: 1.765695745944977
[Epoch 16, Batch 300] loss: 1.706519502401352
[Epoch 16, Batch 400] loss: 1.6530164313316345
**STATS for Epoch 16** : 
Average training loss: 0.2349
Average validation loss: 1.5781
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 15 is already reported.
  warnings.warn(
Validation Accuracy: 0.6660
Overfitting: 1.3432
Best model saved at epoch 16 with validation loss: 1.5781
[Epoch 17, Batch 100] loss: 1.5467458009719848
[Epoch 17, Batch 200] loss: 1.4854319369792939
[Epoch 17, Batch 300] loss: 1.412349373102188
[Epoch 17, Batch 400] loss: 1.3551613700389862
**STATS for Epoch 17** : 
Average training loss: 0.1921
Average validation loss: 1.2737
Validation Accuracy: 0.7184
Overfitting: 1.0816
Best model saved at epoch 17 with validation loss: 1.2737
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 16 is already reported.
  warnings.warn(
[Epoch 18, Batch 100] loss: 1.2398037838935851
[Epoch 18, Batch 200] loss: 1.1664016771316528
[Epoch 18, Batch 300] loss: 1.1191645097732543
[Epoch 18, Batch 400] loss: 1.0579979848861694
**STATS for Epoch 18** : 
Average training loss: 0.1516
Average validation loss: 0.9928
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 17 is already reported.
  warnings.warn(
Validation Accuracy: 0.7723
Overfitting: 0.8412
Best model saved at epoch 18 with validation loss: 0.9928
[Epoch 19, Batch 100] loss: 0.9717224478721619
[Epoch 19, Batch 200] loss: 0.9175454944372177
[Epoch 19, Batch 300] loss: 0.8619774663448334
[Epoch 19, Batch 400] loss: 0.8341723561286927
**STATS for Epoch 19** : 
Average training loss: 0.1202
Average validation loss: 0.7906
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 18 is already reported.
  warnings.warn(
Validation Accuracy: 0.8089
Overfitting: 0.6704
Best model saved at epoch 19 with validation loss: 0.7906
[Epoch 20, Batch 100] loss: 0.7660240739583969
[Epoch 20, Batch 200] loss: 0.7532393270730973
[Epoch 20, Batch 300] loss: 0.7144345787167549
[Epoch 20, Batch 400] loss: 0.6889811041951179
**STATS for Epoch 20** : 
Average training loss: 0.0968
Average validation loss: 0.6622
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 19 is already reported.
  warnings.warn(
Validation Accuracy: 0.8335
Overfitting: 0.5654
Best model saved at epoch 20 with validation loss: 0.6622
[Epoch 21, Batch 100] loss: 0.655306935608387
[Epoch 21, Batch 200] loss: 0.6303806033730507
[Epoch 21, Batch 300] loss: 0.6073691400885582
[Epoch 21, Batch 400] loss: 0.5901472383737564
**STATS for Epoch 21** : 
Average training loss: 0.0862
Average validation loss: 0.5809
Validation Accuracy: 0.8475
Overfitting: 0.4947
Best model saved at epoch 21 with validation loss: 0.5809
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 20 is already reported.
  warnings.warn(
[Epoch 22, Batch 100] loss: 0.5667541763186454
[Epoch 22, Batch 200] loss: 0.5480626478791237
[Epoch 22, Batch 300] loss: 0.5475792399048806
[Epoch 22, Batch 400] loss: 0.5410230034589767
**STATS for Epoch 22** : 
Average training loss: 0.0777
Average validation loss: 0.5257
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 21 is already reported.
  warnings.warn(
Validation Accuracy: 0.8575
Overfitting: 0.4480
Best model saved at epoch 22 with validation loss: 0.5257
[Epoch 23, Batch 100] loss: 0.5074818348884582
[Epoch 23, Batch 200] loss: 0.5024907064437866
[Epoch 23, Batch 300] loss: 0.5038489702343941
[Epoch 23, Batch 400] loss: 0.49061467111110685
**STATS for Epoch 23** : 
Average training loss: 0.0726
Average validation loss: 0.4865
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 22 is already reported.
  warnings.warn(
Validation Accuracy: 0.8657
Overfitting: 0.4139
Best model saved at epoch 23 with validation loss: 0.4865
[Epoch 24, Batch 100] loss: 0.4894196480512619
[Epoch 24, Batch 200] loss: 0.4782474237680435
[Epoch 24, Batch 300] loss: 0.4540176355838776
[Epoch 24, Batch 400] loss: 0.45135058507323267
**STATS for Epoch 24** : 
Average training loss: 0.0657
Average validation loss: 0.4547
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 23 is already reported.
  warnings.warn(
Validation Accuracy: 0.8720
Overfitting: 0.3890
Best model saved at epoch 24 with validation loss: 0.4547
Fold 2 validation loss: 0.4547
Mean validation loss across all folds for Trial 1 is 0.4346 with trial config:  l1: 256, l2: 64, lr: 4.207988669606632e-05, batch_size: 64
[I 2024-11-21 22:09:21,961] Trial 0 finished with value: 0.4346420783350971 and parameters: {'l1': 256, 'l2': 64, 'lr': 4.207988669606632e-05, 'batch_size': 64}. Best is trial 0 with value: 0.4346420783350971.

Selected Hyperparameters for Trial 2:
  l1: 256, l2: 64, lr: 5.3370327626039544e-05, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.306646988391876
[Epoch 1, Batch 200] loss: 2.304807605743408
[Epoch 1, Batch 300] loss: 2.3009824466705324
[Epoch 1, Batch 400] loss: 2.3005322194099427
**STATS for Epoch 1** : 
Average training loss: 0.3382
Average validation loss: 2.2995
Validation Accuracy: 0.1404
Overfitting: 1.9613
Best model saved at epoch 1 with validation loss: 2.2995
[Epoch 2, Batch 100] loss: 2.298422439098358
[Epoch 2, Batch 200] loss: 2.298455970287323
[Epoch 2, Batch 300] loss: 2.2957202625274657
[Epoch 2, Batch 400] loss: 2.2931949400901797
**STATS for Epoch 2** : 
Average training loss: 0.3374
Average validation loss: 2.2928
Validation Accuracy: 0.1779
Overfitting: 1.9554
Best model saved at epoch 2 with validation loss: 2.2928
[Epoch 3, Batch 100] loss: 2.2924512696266173
[Epoch 3, Batch 200] loss: 2.29080082654953
[Epoch 3, Batch 300] loss: 2.2884647274017333
[Epoch 3, Batch 400] loss: 2.28589572429657
**STATS for Epoch 3** : 
Average training loss: 0.3364
Average validation loss: 2.2855
Validation Accuracy: 0.2130
Overfitting: 1.9491
Best model saved at epoch 3 with validation loss: 2.2855
[Epoch 4, Batch 100] loss: 2.2847044467926025
[Epoch 4, Batch 200] loss: 2.2827365803718567
[Epoch 4, Batch 300] loss: 2.280898368358612
[Epoch 4, Batch 400] loss: 2.277777259349823
**STATS for Epoch 4** : 
Average training loss: 0.3351
Average validation loss: 2.2768
Validation Accuracy: 0.2125
Overfitting: 1.9417
Best model saved at epoch 4 with validation loss: 2.2768
[Epoch 5, Batch 100] loss: 2.275104558467865
[Epoch 5, Batch 200] loss: 2.2723017358779907
[Epoch 5, Batch 300] loss: 2.270704746246338
[Epoch 5, Batch 400] loss: 2.268824510574341
**STATS for Epoch 5** : 
Average training loss: 0.3336
Average validation loss: 2.2657
Validation Accuracy: 0.2104
Overfitting: 1.9321
Best model saved at epoch 5 with validation loss: 2.2657
[Epoch 6, Batch 100] loss: 2.263406524658203
[Epoch 6, Batch 200] loss: 2.2611024045944212
[Epoch 6, Batch 300] loss: 2.2578391814231873
[Epoch 6, Batch 400] loss: 2.253516147136688
**STATS for Epoch 6** : 
Average training loss: 0.3314
Average validation loss: 2.2504
Validation Accuracy: 0.2433
Overfitting: 1.9190
Best model saved at epoch 6 with validation loss: 2.2504
[Epoch 7, Batch 100] loss: 2.249052891731262
[Epoch 7, Batch 200] loss: 2.2434387254714965
[Epoch 7, Batch 300] loss: 2.2384387278556823
[Epoch 7, Batch 400] loss: 2.2343433332443237
**STATS for Epoch 7** : 
Average training loss: 0.3280
Average validation loss: 2.2283
Validation Accuracy: 0.3076
Overfitting: 1.9003
Best model saved at epoch 7 with validation loss: 2.2283
[Epoch 8, Batch 100] loss: 2.223324890136719
[Epoch 8, Batch 200] loss: 2.2183940601348877
[Epoch 8, Batch 300] loss: 2.2130067706108094
[Epoch 8, Batch 400] loss: 2.201531479358673
**STATS for Epoch 8** : 
Average training loss: 0.3233
Average validation loss: 2.1931
Validation Accuracy: 0.3825
Overfitting: 1.8698
Best model saved at epoch 8 with validation loss: 2.1931
[Epoch 9, Batch 100] loss: 2.1879734563827515
[Epoch 9, Batch 200] loss: 2.178724160194397
[Epoch 9, Batch 300] loss: 2.164329800605774
[Epoch 9, Batch 400] loss: 2.1482187247276308
**STATS for Epoch 9** : 
Average training loss: 0.3141
Average validation loss: 2.1324
Validation Accuracy: 0.4583
Overfitting: 1.8183
Best model saved at epoch 9 with validation loss: 2.1324
[Epoch 10, Batch 100] loss: 2.121531751155853
[Epoch 10, Batch 200] loss: 2.104844164848328
[Epoch 10, Batch 300] loss: 2.0803044557571413
[Epoch 10, Batch 400] loss: 2.0554142677783966
**STATS for Epoch 10** : 
Average training loss: 0.2989
Average validation loss: 2.0213
Validation Accuracy: 0.5793
Overfitting: 1.7225
Best model saved at epoch 10 with validation loss: 2.0213
[Epoch 11, Batch 100] loss: 2.0018411660194397
[Epoch 11, Batch 200] loss: 1.9651517343521119
[Epoch 11, Batch 300] loss: 1.9287548291683196
[Epoch 11, Batch 400] loss: 1.8683862590789795
**STATS for Epoch 11** : 
Average training loss: 0.2687
Average validation loss: 1.8059
Validation Accuracy: 0.6628
Overfitting: 1.5371
Best model saved at epoch 11 with validation loss: 1.8059
[Epoch 12, Batch 100] loss: 1.774258542060852
[Epoch 12, Batch 200] loss: 1.6959352946281434
[Epoch 12, Batch 300] loss: 1.6282498240470886
[Epoch 12, Batch 400] loss: 1.5444717967510224
**STATS for Epoch 12** : 
Average training loss: 0.2169
Average validation loss: 1.4425
Validation Accuracy: 0.7082
Overfitting: 1.2257
Best model saved at epoch 12 with validation loss: 1.4425
[Epoch 13, Batch 100] loss: 1.3893417823314667
[Epoch 13, Batch 200] loss: 1.3050505650043487
[Epoch 13, Batch 300] loss: 1.2276468825340272
[Epoch 13, Batch 400] loss: 1.1580779039859772
**STATS for Epoch 13** : 
Average training loss: 0.1589
Average validation loss: 1.0605
Validation Accuracy: 0.7432
Overfitting: 0.9016
Best model saved at epoch 13 with validation loss: 1.0605
[Epoch 14, Batch 100] loss: 1.02411315202713
[Epoch 14, Batch 200] loss: 0.9771323651075363
[Epoch 14, Batch 300] loss: 0.9041566693782807
[Epoch 14, Batch 400] loss: 0.8646915990114212
**STATS for Epoch 14** : 
Average training loss: 0.1229
Average validation loss: 0.8181
Validation Accuracy: 0.7810
Overfitting: 0.6952
Best model saved at epoch 14 with validation loss: 0.8181
[Epoch 15, Batch 100] loss: 0.7895273828506469
[Epoch 15, Batch 200] loss: 0.7653269433975219
[Epoch 15, Batch 300] loss: 0.7477093213796615
[Epoch 15, Batch 400] loss: 0.7120263341069222
**STATS for Epoch 15** : 
Average training loss: 0.1019
Average validation loss: 0.6820
Validation Accuracy: 0.8078
Overfitting: 0.5802
Best model saved at epoch 15 with validation loss: 0.6820
[Epoch 16, Batch 100] loss: 0.6870896673202515
[Epoch 16, Batch 200] loss: 0.658878185749054
[Epoch 16, Batch 300] loss: 0.6266033732891083
[Epoch 16, Batch 400] loss: 0.6079948881268501
**STATS for Epoch 16** : 
Average training loss: 0.0871
Average validation loss: 0.5943
Validation Accuracy: 0.8299
Overfitting: 0.5072
Best model saved at epoch 16 with validation loss: 0.5943
[Epoch 17, Batch 100] loss: 0.5945807269215584
[Epoch 17, Batch 200] loss: 0.5775168997049331
[Epoch 17, Batch 300] loss: 0.5525029128789902
[Epoch 17, Batch 400] loss: 0.5550011149048806
**STATS for Epoch 17** : 
Average training loss: 0.0791
Average validation loss: 0.5330
Validation Accuracy: 0.8459
Overfitting: 0.4539
Best model saved at epoch 17 with validation loss: 0.5330
[Epoch 18, Batch 100] loss: 0.5271107035875321
[Epoch 18, Batch 200] loss: 0.5303193727135658
[Epoch 18, Batch 300] loss: 0.5206607401371002
[Epoch 18, Batch 400] loss: 0.48320358276367187
**STATS for Epoch 18** : 
Average training loss: 0.0732
Average validation loss: 0.4873
Validation Accuracy: 0.8596
Overfitting: 0.4141
Best model saved at epoch 18 with validation loss: 0.4873
[Epoch 19, Batch 100] loss: 0.47228334307670594
[Epoch 19, Batch 200] loss: 0.4812900802493095
[Epoch 19, Batch 300] loss: 0.4586011528968811
[Epoch 19, Batch 400] loss: 0.4658371093869209
**STATS for Epoch 19** : 
Average training loss: 0.0711
Average validation loss: 0.4523
Validation Accuracy: 0.8681
Overfitting: 0.3813
Best model saved at epoch 19 with validation loss: 0.4523
[Epoch 20, Batch 100] loss: 0.47389647126197815
[Epoch 20, Batch 200] loss: 0.4439410439133644
[Epoch 20, Batch 300] loss: 0.42791902005672455
[Epoch 20, Batch 400] loss: 0.4210576546192169
**STATS for Epoch 20** : 
Average training loss: 0.0622
Average validation loss: 0.4219
Validation Accuracy: 0.8793
Overfitting: 0.3597
Best model saved at epoch 20 with validation loss: 0.4219
[Epoch 21, Batch 100] loss: 0.4115730419754982
[Epoch 21, Batch 200] loss: 0.4070195198059082
[Epoch 21, Batch 300] loss: 0.4129150778055191
[Epoch 21, Batch 400] loss: 0.4157432843744755
**STATS for Epoch 21** : 
Average training loss: 0.0606
Average validation loss: 0.3991
Validation Accuracy: 0.8860
Overfitting: 0.3386
Best model saved at epoch 21 with validation loss: 0.3991
[Epoch 22, Batch 100] loss: 0.40478831917047503
[Epoch 22, Batch 200] loss: 0.39560053452849386
[Epoch 22, Batch 300] loss: 0.38428632631897924
[Epoch 22, Batch 400] loss: 0.38106345385313034
**STATS for Epoch 22** : 
Average training loss: 0.0559
Average validation loss: 0.3774
Validation Accuracy: 0.8914
Overfitting: 0.3215
Best model saved at epoch 22 with validation loss: 0.3774
[Epoch 23, Batch 100] loss: 0.390069504827261
[Epoch 23, Batch 200] loss: 0.36179925374686717
[Epoch 23, Batch 300] loss: 0.35813148096203806
[Epoch 23, Batch 400] loss: 0.37919686213135717
**STATS for Epoch 23** : 
Average training loss: 0.0533
Average validation loss: 0.3599
Validation Accuracy: 0.8968
Overfitting: 0.3066
Best model saved at epoch 23 with validation loss: 0.3599
[Epoch 24, Batch 100] loss: 0.37596699222922325
[Epoch 24, Batch 200] loss: 0.3436916555464268
[Epoch 24, Batch 300] loss: 0.36671387061476707
[Epoch 24, Batch 400] loss: 0.34581456154584883
**STATS for Epoch 24** : 
Average training loss: 0.0494
Average validation loss: 0.3456
Validation Accuracy: 0.8994
Overfitting: 0.2962
Best model saved at epoch 24 with validation loss: 0.3456
Fold 1 validation loss: 0.3456
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.3025285053253173
[Epoch 1, Batch 200] loss: 2.3007080483436586
[Epoch 1, Batch 300] loss: 2.2997154235839843
[Epoch 1, Batch 400] loss: 2.298601393699646
**STATS for Epoch 1** : 
Average training loss: 0.3382
Average validation loss: 2.2969
Validation Accuracy: 0.1628
Overfitting: 1.9588
Best model saved at epoch 1 with validation loss: 2.2969
[Epoch 2, Batch 100] loss: 2.2972140550613402
[Epoch 2, Batch 200] loss: 2.296397705078125
[Epoch 2, Batch 300] loss: 2.293453783988953
[Epoch 2, Batch 400] loss: 2.2932217431068422
**STATS for Epoch 2** : 
Average training loss: 0.3373
Average validation loss: 2.2913
Validation Accuracy: 0.1786
Overfitting: 1.9541
Best model saved at epoch 2 with validation loss: 2.2913
[Epoch 3, Batch 100] loss: 2.291635663509369
[Epoch 3, Batch 200] loss: 2.2893188118934633
[Epoch 3, Batch 300] loss: 2.288299930095673
[Epoch 3, Batch 400] loss: 2.2862905406951906
**STATS for Epoch 3** : 
Average training loss: 0.3364
Average validation loss: 2.2847
Validation Accuracy: 0.1855
Overfitting: 1.9483
Best model saved at epoch 3 with validation loss: 2.2847
[Epoch 4, Batch 100] loss: 2.284782507419586
[Epoch 4, Batch 200] loss: 2.2820557379722595
[Epoch 4, Batch 300] loss: 2.2807317996025085
[Epoch 4, Batch 400] loss: 2.2776845788955686
**STATS for Epoch 4** : 
Average training loss: 0.3353
Average validation loss: 2.2763
Validation Accuracy: 0.1937
Overfitting: 1.9410
Best model saved at epoch 4 with validation loss: 2.2763
[Epoch 5, Batch 100] loss: 2.2738294506073
[Epoch 5, Batch 200] loss: 2.2742826890945436
[Epoch 5, Batch 300] loss: 2.2717628836631776
[Epoch 5, Batch 400] loss: 2.267530677318573
**STATS for Epoch 5** : 
Average training loss: 0.3334
Average validation loss: 2.2647
Validation Accuracy: 0.2474
Overfitting: 1.9313
Best model saved at epoch 5 with validation loss: 2.2647
[Epoch 6, Batch 100] loss: 2.2632673025131225
[Epoch 6, Batch 200] loss: 2.2601265859603883
[Epoch 6, Batch 300] loss: 2.2556542444229124
[Epoch 6, Batch 400] loss: 2.2541619396209716
**STATS for Epoch 6** : 
Average training loss: 0.3308
Average validation loss: 2.2479
Validation Accuracy: 0.3611
Overfitting: 1.9171
Best model saved at epoch 6 with validation loss: 2.2479
[Epoch 7, Batch 100] loss: 2.2466319823265075
[Epoch 7, Batch 200] loss: 2.2422377610206605
[Epoch 7, Batch 300] loss: 2.2346889424324035
[Epoch 7, Batch 400] loss: 2.23005686044693
**STATS for Epoch 7** : 
Average training loss: 0.3269
Average validation loss: 2.2227
Validation Accuracy: 0.4671
Overfitting: 1.8958
Best model saved at epoch 7 with validation loss: 2.2227
[Epoch 8, Batch 100] loss: 2.220785994529724
[Epoch 8, Batch 200] loss: 2.2106351399421693
[Epoch 8, Batch 300] loss: 2.2030834484100343
[Epoch 8, Batch 400] loss: 2.1937580275535584
**STATS for Epoch 8** : 
Average training loss: 0.3213
Average validation loss: 2.1822
Validation Accuracy: 0.5300
Overfitting: 1.8609
Best model saved at epoch 8 with validation loss: 2.1822
[Epoch 9, Batch 100] loss: 2.1751572275161744
[Epoch 9, Batch 200] loss: 2.159949245452881
[Epoch 9, Batch 300] loss: 2.1510652232170107
[Epoch 9, Batch 400] loss: 2.134968726634979
**STATS for Epoch 9** : 
Average training loss: 0.3114
Average validation loss: 2.1123
Validation Accuracy: 0.5360
Overfitting: 1.8008
Best model saved at epoch 9 with validation loss: 2.1123
[Epoch 10, Batch 100] loss: 2.1051946663856507
[Epoch 10, Batch 200] loss: 2.07512305021286
[Epoch 10, Batch 300] loss: 2.053919731378555
[Epoch 10, Batch 400] loss: 2.016921011209488
**STATS for Epoch 10** : 
Average training loss: 0.2939
Average validation loss: 1.9835
Validation Accuracy: 0.5549
Overfitting: 1.6896
Best model saved at epoch 10 with validation loss: 1.9835
[Epoch 11, Batch 100] loss: 1.9617249989509582
[Epoch 11, Batch 200] loss: 1.9178894782066345
[Epoch 11, Batch 300] loss: 1.872163599729538
[Epoch 11, Batch 400] loss: 1.8194475531578065
**STATS for Epoch 11** : 
Average training loss: 0.2596
Average validation loss: 1.7472
Validation Accuracy: 0.6205
Overfitting: 1.4876
Best model saved at epoch 11 with validation loss: 1.7472
[Epoch 12, Batch 100] loss: 1.7174318420886994
[Epoch 12, Batch 200] loss: 1.6383004343509675
[Epoch 12, Batch 300] loss: 1.5704915165901183
[Epoch 12, Batch 400] loss: 1.4919772779941558
**STATS for Epoch 12** : 
Average training loss: 0.2071
Average validation loss: 1.3957
Validation Accuracy: 0.6951
Overfitting: 1.1885
Best model saved at epoch 12 with validation loss: 1.3957
[Epoch 13, Batch 100] loss: 1.359970042705536
[Epoch 13, Batch 200] loss: 1.261899322271347
[Epoch 13, Batch 300] loss: 1.191185977458954
[Epoch 13, Batch 400] loss: 1.108795285820961
**STATS for Epoch 13** : 
Average training loss: 0.1529
Average validation loss: 1.0253
Validation Accuracy: 0.7667
Overfitting: 0.8724
Best model saved at epoch 13 with validation loss: 1.0253
[Epoch 14, Batch 100] loss: 0.9828533148765564
[Epoch 14, Batch 200] loss: 0.9181501495838166
[Epoch 14, Batch 300] loss: 0.8710833483934403
[Epoch 14, Batch 400] loss: 0.8162651872634887
**STATS for Epoch 14** : 
Average training loss: 0.1134
Average validation loss: 0.7637
Validation Accuracy: 0.8120
Overfitting: 0.6503
Best model saved at epoch 14 with validation loss: 0.7637
[Epoch 15, Batch 100] loss: 0.7431082826852798
[Epoch 15, Batch 200] loss: 0.7181339779496193
[Epoch 15, Batch 300] loss: 0.6668806588649749
[Epoch 15, Batch 400] loss: 0.6382213196158409
**STATS for Epoch 15** : 
Average training loss: 0.0897
Average validation loss: 0.6203
Validation Accuracy: 0.8378
Overfitting: 0.5306
Best model saved at epoch 15 with validation loss: 0.6203
[Epoch 16, Batch 100] loss: 0.5901705053448677
[Epoch 16, Batch 200] loss: 0.5981010150909424
[Epoch 16, Batch 300] loss: 0.5713355627655983
[Epoch 16, Batch 400] loss: 0.5565946015715599
**STATS for Epoch 16** : 
Average training loss: 0.0777
Average validation loss: 0.5420
Validation Accuracy: 0.8478
Overfitting: 0.4643
Best model saved at epoch 16 with validation loss: 0.5420
[Epoch 17, Batch 100] loss: 0.534275327026844
[Epoch 17, Batch 200] loss: 0.5147876000404358
[Epoch 17, Batch 300] loss: 0.49439764976501466
[Epoch 17, Batch 400] loss: 0.495955071747303
**STATS for Epoch 17** : 
Average training loss: 0.0722
Average validation loss: 0.4923
Validation Accuracy: 0.8591
Overfitting: 0.4200
Best model saved at epoch 17 with validation loss: 0.4923
[Epoch 18, Batch 100] loss: 0.484109573662281
[Epoch 18, Batch 200] loss: 0.4640380296111107
[Epoch 18, Batch 300] loss: 0.47486144602298735
[Epoch 18, Batch 400] loss: 0.4406625297665596
**STATS for Epoch 18** : 
Average training loss: 0.0671
Average validation loss: 0.4542
Validation Accuracy: 0.8689
Overfitting: 0.3871
Best model saved at epoch 18 with validation loss: 0.4542
[Epoch 19, Batch 100] loss: 0.4535639947652817
[Epoch 19, Batch 200] loss: 0.42802849531173703
[Epoch 19, Batch 300] loss: 0.4356678846478462
[Epoch 19, Batch 400] loss: 0.4225766763091087
**STATS for Epoch 19** : 
Average training loss: 0.0615
Average validation loss: 0.4262
Validation Accuracy: 0.8753
Overfitting: 0.3647
Best model saved at epoch 19 with validation loss: 0.4262
[Epoch 20, Batch 100] loss: 0.4025150050222874
[Epoch 20, Batch 200] loss: 0.41441224291920664
[Epoch 20, Batch 300] loss: 0.40990777894854546
[Epoch 20, Batch 400] loss: 0.40378699913620947
**STATS for Epoch 20** : 
Average training loss: 0.0594
Average validation loss: 0.4039
Validation Accuracy: 0.8813
Overfitting: 0.3445
Best model saved at epoch 20 with validation loss: 0.4039
[Epoch 21, Batch 100] loss: 0.3863281625509262
[Epoch 21, Batch 200] loss: 0.3919860996305943
[Epoch 21, Batch 300] loss: 0.38751479029655456
[Epoch 21, Batch 400] loss: 0.3917903234064579
**STATS for Epoch 21** : 
Average training loss: 0.0544
Average validation loss: 0.3856
Validation Accuracy: 0.8854
Overfitting: 0.3313
Best model saved at epoch 21 with validation loss: 0.3856
[Epoch 22, Batch 100] loss: 0.35360618129372595
[Epoch 22, Batch 200] loss: 0.3740249015390873
[Epoch 22, Batch 300] loss: 0.37961341127753256
[Epoch 22, Batch 400] loss: 0.37446717441082
**STATS for Epoch 22** : 
Average training loss: 0.0526
Average validation loss: 0.3684
Validation Accuracy: 0.8905
Overfitting: 0.3158
Best model saved at epoch 22 with validation loss: 0.3684
[Epoch 23, Batch 100] loss: 0.35701803877949717
[Epoch 23, Batch 200] loss: 0.35587071508169177
[Epoch 23, Batch 300] loss: 0.3568295754492283
[Epoch 23, Batch 400] loss: 0.35217240288853646
**STATS for Epoch 23** : 
Average training loss: 0.0501
Average validation loss: 0.3535
Validation Accuracy: 0.8954
Overfitting: 0.3034
Best model saved at epoch 23 with validation loss: 0.3535
[Epoch 24, Batch 100] loss: 0.3650453785061836
[Epoch 24, Batch 200] loss: 0.3438949748873711
[Epoch 24, Batch 300] loss: 0.32823401808738706
[Epoch 24, Batch 400] loss: 0.3271943025290966
**STATS for Epoch 24** : 
Average training loss: 0.0488
Average validation loss: 0.3406
Validation Accuracy: 0.8983
Overfitting: 0.2918
Best model saved at epoch 24 with validation loss: 0.3406
Fold 2 validation loss: 0.3406
Mean validation loss across all folds for Trial 2 is 0.3431 with trial config:  l1: 256, l2: 64, lr: 5.3370327626039544e-05, batch_size: 64
[I 2024-11-21 22:18:29,609] Trial 1 finished with value: 0.34308980319545723 and parameters: {'l1': 256, 'l2': 64, 'lr': 5.3370327626039544e-05, 'batch_size': 64}. Best is trial 1 with value: 0.34308980319545723.

Selected Hyperparameters for Trial 3:
  l1: 128, l2: 128, lr: 0.0006672367170464204, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2915175628662108
[Epoch 1, Batch 200] loss: 2.2495449113845827
[Epoch 1, Batch 300] loss: 2.153963892459869
[Epoch 1, Batch 400] loss: 1.7810814678668976
[Epoch 1, Batch 500] loss: 1.0363672667741775
[Epoch 1, Batch 600] loss: 0.7307840976119041
[Epoch 1, Batch 700] loss: 0.5247467240691185
[Epoch 1, Batch 800] loss: 0.5046655490994454
[Epoch 1, Batch 900] loss: 0.4767443013936281
[Epoch 1, Batch 1000] loss: 0.39015820737928153
[Epoch 1, Batch 1100] loss: 0.33800431333482267
[Epoch 1, Batch 1200] loss: 0.37110118098556993
[Epoch 1, Batch 1300] loss: 0.3577207139879465
[Epoch 1, Batch 1400] loss: 0.2984561996161938
[Epoch 1, Batch 1500] loss: 0.30120806079357865
[Epoch 1, Batch 1600] loss: 0.2814023544639349
[Epoch 1, Batch 1700] loss: 0.2693049693107605
[Epoch 1, Batch 1800] loss: 0.23804593309760094
**STATS for Epoch 1** : 
Average training loss: 0.0076
Average validation loss: 0.2310
Validation Accuracy: 0.9305
Overfitting: 0.2234
Best model saved at epoch 1 with validation loss: 0.2310
[Epoch 2, Batch 100] loss: 0.2183074014261365
[Epoch 2, Batch 200] loss: 0.2128203986864537
[Epoch 2, Batch 300] loss: 0.20465139399282634
[Epoch 2, Batch 400] loss: 0.20709091382101177
[Epoch 2, Batch 500] loss: 0.20915464347228407
[Epoch 2, Batch 600] loss: 0.17955074079334735
[Epoch 2, Batch 700] loss: 0.1781758208014071
[Epoch 2, Batch 800] loss: 0.19043231977149844
[Epoch 2, Batch 900] loss: 0.19409511608071625
[Epoch 2, Batch 1000] loss: 0.1852221351675689
[Epoch 2, Batch 1100] loss: 0.12590241856873036
[Epoch 2, Batch 1200] loss: 0.1665611432539299
[Epoch 2, Batch 1300] loss: 0.17365170806646346
[Epoch 2, Batch 1400] loss: 0.14635044655762613
[Epoch 2, Batch 1500] loss: 0.147928040237166
[Epoch 2, Batch 1600] loss: 0.16693250289652498
[Epoch 2, Batch 1700] loss: 0.15975483558839187
[Epoch 2, Batch 1800] loss: 0.11396108211949468
**STATS for Epoch 2** : 
Average training loss: 0.0054
Average validation loss: 0.1343
Validation Accuracy: 0.9578
Overfitting: 0.1289
Best model saved at epoch 2 with validation loss: 0.1343
[Epoch 3, Batch 100] loss: 0.1461377987358719
[Epoch 3, Batch 200] loss: 0.13529346167342737
[Epoch 3, Batch 300] loss: 0.11611963442992419
[Epoch 3, Batch 400] loss: 0.13843320437241347
[Epoch 3, Batch 500] loss: 0.13340732886921614
[Epoch 3, Batch 600] loss: 0.11017675213282928
[Epoch 3, Batch 700] loss: 0.11911454145330935
[Epoch 3, Batch 800] loss: 0.10266815562034026
[Epoch 3, Batch 900] loss: 0.11798485942650587
[Epoch 3, Batch 1000] loss: 0.12794177018571645
[Epoch 3, Batch 1100] loss: 0.11474685750668868
[Epoch 3, Batch 1200] loss: 0.10433185384375974
[Epoch 3, Batch 1300] loss: 0.09467919456772506
[Epoch 3, Batch 1400] loss: 0.11855762068997137
[Epoch 3, Batch 1500] loss: 0.09407358441734687
[Epoch 3, Batch 1600] loss: 0.09745089974952861
[Epoch 3, Batch 1700] loss: 0.11969101413153112
[Epoch 3, Batch 1800] loss: 0.10738005340099335
**STATS for Epoch 3** : 
Average training loss: 0.0029
Average validation loss: 0.0960
Validation Accuracy: 0.9694
Overfitting: 0.0932
Best model saved at epoch 3 with validation loss: 0.0960
[Epoch 4, Batch 100] loss: 0.0873691087437328
[Epoch 4, Batch 200] loss: 0.12060239014565013
[Epoch 4, Batch 300] loss: 0.08450121519388631
[Epoch 4, Batch 400] loss: 0.08397304048528895
[Epoch 4, Batch 500] loss: 0.1241724058194086
[Epoch 4, Batch 600] loss: 0.099795060493052
[Epoch 4, Batch 700] loss: 0.09779072773177176
[Epoch 4, Batch 800] loss: 0.10332430939422921
[Epoch 4, Batch 900] loss: 0.09549634343711659
[Epoch 4, Batch 1000] loss: 0.09736321741249412
[Epoch 4, Batch 1100] loss: 0.08424256669473834
[Epoch 4, Batch 1200] loss: 0.07473742812173441
[Epoch 4, Batch 1300] loss: 0.07204948976519518
[Epoch 4, Batch 1400] loss: 0.07926981589058414
[Epoch 4, Batch 1500] loss: 0.08910452821757645
[Epoch 4, Batch 1600] loss: 0.056133714050520214
[Epoch 4, Batch 1700] loss: 0.08393026471836493
[Epoch 4, Batch 1800] loss: 0.07762437853380107
**STATS for Epoch 4** : 
Average training loss: 0.0026
Average validation loss: 0.0835
Validation Accuracy: 0.9735
Overfitting: 0.0809
Best model saved at epoch 4 with validation loss: 0.0835
[Epoch 5, Batch 100] loss: 0.07518033502739854
[Epoch 5, Batch 200] loss: 0.08160040945338551
[Epoch 5, Batch 300] loss: 0.06913269464857877
[Epoch 5, Batch 400] loss: 0.09507249393500387
[Epoch 5, Batch 500] loss: 0.06074098422599491
[Epoch 5, Batch 600] loss: 0.07263683816883713
[Epoch 5, Batch 700] loss: 0.06485422870900948
[Epoch 5, Batch 800] loss: 0.07210007727495395
[Epoch 5, Batch 900] loss: 0.07139520499913488
[Epoch 5, Batch 1000] loss: 0.07136267321417109
[Epoch 5, Batch 1100] loss: 0.06893096508923918
[Epoch 5, Batch 1200] loss: 0.06439901480218396
[Epoch 5, Batch 1300] loss: 0.07316742241440806
[Epoch 5, Batch 1400] loss: 0.07842848104657606
[Epoch 5, Batch 1500] loss: 0.06646142895217054
[Epoch 5, Batch 1600] loss: 0.06814981743780663
[Epoch 5, Batch 1700] loss: 0.07818930249661207
[Epoch 5, Batch 1800] loss: 0.061154988532071
**STATS for Epoch 5** : 
Average training loss: 0.0033
Average validation loss: 0.0765
Validation Accuracy: 0.9766
Overfitting: 0.0732
Best model saved at epoch 5 with validation loss: 0.0765
[Epoch 6, Batch 100] loss: 0.07038896797108464
[Epoch 6, Batch 200] loss: 0.05991566583979875
[Epoch 6, Batch 300] loss: 0.06729082339326851
[Epoch 6, Batch 400] loss: 0.06274725414725253
[Epoch 6, Batch 500] loss: 0.051278193164034744
[Epoch 6, Batch 600] loss: 0.06341951350390446
[Epoch 6, Batch 700] loss: 0.0647793775680475
[Epoch 6, Batch 800] loss: 0.05592289825202897
[Epoch 6, Batch 900] loss: 0.0680804431863362
[Epoch 6, Batch 1000] loss: 0.0619217747222865
[Epoch 6, Batch 1100] loss: 0.08020639503956772
[Epoch 6, Batch 1200] loss: 0.05025534235930536
[Epoch 6, Batch 1300] loss: 0.06387263968703337
[Epoch 6, Batch 1400] loss: 0.05389799568336457
[Epoch 6, Batch 1500] loss: 0.05453350332332775
[Epoch 6, Batch 1600] loss: 0.06103406761772931
[Epoch 6, Batch 1700] loss: 0.06824000321736094
[Epoch 6, Batch 1800] loss: 0.040159768257290125
**STATS for Epoch 6** : 
Average training loss: 0.0029
Average validation loss: 0.0751
Validation Accuracy: 0.9774
Overfitting: 0.0723
Best model saved at epoch 6 with validation loss: 0.0751
[Epoch 7, Batch 100] loss: 0.0558343327709008
[Epoch 7, Batch 200] loss: 0.06960972517495975
[Epoch 7, Batch 300] loss: 0.056541634101886305
[Epoch 7, Batch 400] loss: 0.042353250460000706
[Epoch 7, Batch 500] loss: 0.07540156345057766
[Epoch 7, Batch 600] loss: 0.05511041858349927
[Epoch 7, Batch 700] loss: 0.06141322462004609
[Epoch 7, Batch 800] loss: 0.044180874586454595
[Epoch 7, Batch 900] loss: 0.06096495913021499
[Epoch 7, Batch 1000] loss: 0.05375290722935461
[Epoch 7, Batch 1100] loss: 0.04339658718905412
[Epoch 7, Batch 1200] loss: 0.04433450926153455
[Epoch 7, Batch 1300] loss: 0.046860618445207364
[Epoch 7, Batch 1400] loss: 0.06901050677901367
[Epoch 7, Batch 1500] loss: 0.0737017581181135
[Epoch 7, Batch 1600] loss: 0.04965854418987874
[Epoch 7, Batch 1700] loss: 0.05109808928973507
[Epoch 7, Batch 1800] loss: 0.05738958804722642
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0713
Validation Accuracy: 0.9777
Overfitting: 0.0695
Best model saved at epoch 7 with validation loss: 0.0713
[Epoch 8, Batch 100] loss: 0.02843932592018973
[Epoch 8, Batch 200] loss: 0.035163695155642924
[Epoch 8, Batch 300] loss: 0.05485384633866488
[Epoch 8, Batch 400] loss: 0.04959277730711619
[Epoch 8, Batch 500] loss: 0.053801441679243
[Epoch 8, Batch 600] loss: 0.04864089071692433
[Epoch 8, Batch 700] loss: 0.05866703993524425
[Epoch 8, Batch 800] loss: 0.053504740470671094
[Epoch 8, Batch 900] loss: 0.037288385100546294
[Epoch 8, Batch 1000] loss: 0.0324035890356754
[Epoch 8, Batch 1100] loss: 0.03672905901214108
[Epoch 8, Batch 1200] loss: 0.052687448701180986
[Epoch 8, Batch 1300] loss: 0.04209536644964828
[Epoch 8, Batch 1400] loss: 0.0517761203176633
[Epoch 8, Batch 1500] loss: 0.06600220958760473
[Epoch 8, Batch 1600] loss: 0.05297311267713667
[Epoch 8, Batch 1700] loss: 0.0503004937467631
[Epoch 8, Batch 1800] loss: 0.05453170814347686
**STATS for Epoch 8** : 
Average training loss: 0.0017
Average validation loss: 0.0760
Validation Accuracy: 0.9773
Overfitting: 0.0743
[Epoch 9, Batch 100] loss: 0.05225809458206641
[Epoch 9, Batch 200] loss: 0.045107358188543
[Epoch 9, Batch 300] loss: 0.038598212357319424
[Epoch 9, Batch 400] loss: 0.040435832259827297
[Epoch 9, Batch 500] loss: 0.04688806957186898
[Epoch 9, Batch 600] loss: 0.03860519413079601
[Epoch 9, Batch 700] loss: 0.03791622973309131
[Epoch 9, Batch 800] loss: 0.03692227312392788
[Epoch 9, Batch 900] loss: 0.03453460530930897
[Epoch 9, Batch 1000] loss: 0.03764639001208707
[Epoch 9, Batch 1100] loss: 0.032522285574377745
[Epoch 9, Batch 1200] loss: 0.03298484119397472
[Epoch 9, Batch 1300] loss: 0.06125305788329569
[Epoch 9, Batch 1400] loss: 0.04140405983780511
[Epoch 9, Batch 1500] loss: 0.040553265267517416
[Epoch 9, Batch 1600] loss: 0.04548696830519475
[Epoch 9, Batch 1700] loss: 0.06042818978778087
[Epoch 9, Batch 1800] loss: 0.03759839036705671
**STATS for Epoch 9** : 
Average training loss: 0.0017
Average validation loss: 0.0658
Validation Accuracy: 0.9801
Overfitting: 0.0641
Best model saved at epoch 9 with validation loss: 0.0658
[Epoch 10, Batch 100] loss: 0.03055085813757614
[Epoch 10, Batch 200] loss: 0.033800637421154536
[Epoch 10, Batch 300] loss: 0.03144991854671389
[Epoch 10, Batch 400] loss: 0.04330582292808685
[Epoch 10, Batch 500] loss: 0.03855312871630304
[Epoch 10, Batch 600] loss: 0.037666170611482815
[Epoch 10, Batch 700] loss: 0.04354248156312678
[Epoch 10, Batch 800] loss: 0.04294527740261401
[Epoch 10, Batch 900] loss: 0.02750580401450861
[Epoch 10, Batch 1000] loss: 0.025549098913616036
[Epoch 10, Batch 1100] loss: 0.030823918883397708
[Epoch 10, Batch 1200] loss: 0.04213813030553865
[Epoch 10, Batch 1300] loss: 0.03266526512248674
[Epoch 10, Batch 1400] loss: 0.04457858136229333
[Epoch 10, Batch 1500] loss: 0.0289106631706818
[Epoch 10, Batch 1600] loss: 0.06324316795013146
[Epoch 10, Batch 1700] loss: 0.03938328945252579
[Epoch 10, Batch 1800] loss: 0.04593724250342348
**STATS for Epoch 10** : 
Average training loss: 0.0014
Average validation loss: 0.0668
Validation Accuracy: 0.9799
Overfitting: 0.0654
[Epoch 11, Batch 100] loss: 0.03167812116065761
[Epoch 11, Batch 200] loss: 0.039450690789090005
[Epoch 11, Batch 300] loss: 0.03322366368272924
[Epoch 11, Batch 400] loss: 0.017546447923232334
[Epoch 11, Batch 500] loss: 0.026546597176711657
[Epoch 11, Batch 600] loss: 0.026850517403217963
[Epoch 11, Batch 700] loss: 0.03664658593443164
[Epoch 11, Batch 800] loss: 0.03168814852455398
[Epoch 11, Batch 900] loss: 0.048923174294468484
[Epoch 11, Batch 1000] loss: 0.042639770467503696
[Epoch 11, Batch 1100] loss: 0.037590243000922785
[Epoch 11, Batch 1200] loss: 0.03018283802754013
[Epoch 11, Batch 1300] loss: 0.034267779755755325
[Epoch 11, Batch 1400] loss: 0.03104280590006965
[Epoch 11, Batch 1500] loss: 0.029257272896720678
[Epoch 11, Batch 1600] loss: 0.023233186971774556
[Epoch 11, Batch 1700] loss: 0.02808135890729318
[Epoch 11, Batch 1800] loss: 0.03575273169844877
**STATS for Epoch 11** : 
Average training loss: 0.0025
Average validation loss: 0.0674
Validation Accuracy: 0.9793
Overfitting: 0.0649
[Epoch 12, Batch 100] loss: 0.025329766201466555
[Epoch 12, Batch 200] loss: 0.032772867743333337
[Epoch 12, Batch 300] loss: 0.022723965351142395
[Epoch 12, Batch 400] loss: 0.03929463212421979
[Epoch 12, Batch 500] loss: 0.0349375497631263
[Epoch 12, Batch 600] loss: 0.023651758559281005
[Epoch 12, Batch 700] loss: 0.024636027057422325
[Epoch 12, Batch 800] loss: 0.019709920152818087
[Epoch 12, Batch 900] loss: 0.0329631543206051
[Epoch 12, Batch 1000] loss: 0.03381450381522882
[Epoch 12, Batch 1100] loss: 0.03065125236433232
[Epoch 12, Batch 1200] loss: 0.03586702522377891
[Epoch 12, Batch 1300] loss: 0.03993504866826697
[Epoch 12, Batch 1400] loss: 0.032504882178473055
[Epoch 12, Batch 1500] loss: 0.033905326966923895
[Epoch 12, Batch 1600] loss: 0.023755719005712307
[Epoch 12, Batch 1700] loss: 0.028458750415011308
[Epoch 12, Batch 1800] loss: 0.03875087864580564
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0565
Validation Accuracy: 0.9830
Overfitting: 0.0552
Best model saved at epoch 12 with validation loss: 0.0565
[Epoch 13, Batch 100] loss: 0.01983357149911171
[Epoch 13, Batch 200] loss: 0.02786228093005775
[Epoch 13, Batch 300] loss: 0.03108461368305143
[Epoch 13, Batch 400] loss: 0.027961537292285357
[Epoch 13, Batch 500] loss: 0.028418748936601332
[Epoch 13, Batch 600] loss: 0.03118492276651523
[Epoch 13, Batch 700] loss: 0.020259492262648563
[Epoch 13, Batch 800] loss: 0.03159630045447557
[Epoch 13, Batch 900] loss: 0.026754213747990432
[Epoch 13, Batch 1000] loss: 0.029243439986603333
[Epoch 13, Batch 1100] loss: 0.029617210266951587
[Epoch 13, Batch 1200] loss: 0.02362416982919967
[Epoch 13, Batch 1300] loss: 0.035345644421540784
[Epoch 13, Batch 1400] loss: 0.031922233303193936
[Epoch 13, Batch 1500] loss: 0.02867984152660938
[Epoch 13, Batch 1600] loss: 0.016295258713580552
[Epoch 13, Batch 1700] loss: 0.02006786422633013
[Epoch 13, Batch 1800] loss: 0.029284513842430897
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0620
Validation Accuracy: 0.9828
Overfitting: 0.0612
[Epoch 14, Batch 100] loss: 0.031943804585826
[Epoch 14, Batch 200] loss: 0.02021433009973407
[Epoch 14, Batch 300] loss: 0.026382097969362802
[Epoch 14, Batch 400] loss: 0.019855392266508717
[Epoch 14, Batch 500] loss: 0.028945396300841822
[Epoch 14, Batch 600] loss: 0.019918692223145625
[Epoch 14, Batch 700] loss: 0.02304346661810996
[Epoch 14, Batch 800] loss: 0.023177043667819818
[Epoch 14, Batch 900] loss: 0.029784544274079963
[Epoch 14, Batch 1000] loss: 0.02273463140198146
[Epoch 14, Batch 1100] loss: 0.03124347868044424
[Epoch 14, Batch 1200] loss: 0.021164033945242407
[Epoch 14, Batch 1300] loss: 0.021473766455019357
[Epoch 14, Batch 1400] loss: 0.02222041676475783
[Epoch 14, Batch 1500] loss: 0.022291615619815276
[Epoch 14, Batch 1600] loss: 0.024510087136004586
[Epoch 14, Batch 1700] loss: 0.03213184748494314
[Epoch 14, Batch 1800] loss: 0.026285792317576124
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0656
Validation Accuracy: 0.9820
Overfitting: 0.0646
[Epoch 15, Batch 100] loss: 0.01484541807032656
[Epoch 15, Batch 200] loss: 0.010597920867330685
[Epoch 15, Batch 300] loss: 0.014345941423162003
[Epoch 15, Batch 400] loss: 0.019853020553146052
[Epoch 15, Batch 500] loss: 0.026334033365128563
[Epoch 15, Batch 600] loss: 0.023808740062449943
[Epoch 15, Batch 700] loss: 0.02683780537608982
[Epoch 15, Batch 800] loss: 0.02073484688246026
[Epoch 15, Batch 900] loss: 0.0299649911661254
[Epoch 15, Batch 1000] loss: 0.013819647926211473
[Epoch 15, Batch 1100] loss: 0.021683952810672053
[Epoch 15, Batch 1200] loss: 0.021373351901393108
[Epoch 15, Batch 1300] loss: 0.027317691243442823
[Epoch 15, Batch 1400] loss: 0.02972876713043661
[Epoch 15, Batch 1500] loss: 0.030163490029081003
[Epoch 15, Batch 1600] loss: 0.02759145905743935
[Epoch 15, Batch 1700] loss: 0.018608949165554806
[Epoch 15, Batch 1800] loss: 0.019320858366481845
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0639
Validation Accuracy: 0.9828
Overfitting: 0.0630
[Epoch 16, Batch 100] loss: 0.020726931210701877
[Epoch 16, Batch 200] loss: 0.01417774310837558
[Epoch 16, Batch 300] loss: 0.01584881762482837
[Epoch 16, Batch 400] loss: 0.011789168114046334
[Epoch 16, Batch 500] loss: 0.023241197076513346
[Epoch 16, Batch 600] loss: 0.01513704297482036
[Epoch 16, Batch 700] loss: 0.021486241234324552
[Epoch 16, Batch 800] loss: 0.01767511241927423
[Epoch 16, Batch 900] loss: 0.019429827025087432
[Epoch 16, Batch 1000] loss: 0.02798590594793495
[Epoch 16, Batch 1100] loss: 0.011804010023006413
[Epoch 16, Batch 1200] loss: 0.038035924233108746
[Epoch 16, Batch 1300] loss: 0.020684047950635432
[Epoch 16, Batch 1400] loss: 0.029785216254240368
[Epoch 16, Batch 1500] loss: 0.021798014576997957
[Epoch 16, Batch 1600] loss: 0.023586019752256108
[Epoch 16, Batch 1700] loss: 0.021946242852900467
[Epoch 16, Batch 1800] loss: 0.01836658028587408
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0625
Validation Accuracy: 0.9834
Overfitting: 0.0618
[Epoch 17, Batch 100] loss: 0.01089453464584949
[Epoch 17, Batch 200] loss: 0.018256215681285538
[Epoch 17, Batch 300] loss: 0.011111609021354526
[Epoch 17, Batch 400] loss: 0.02163809156842035
[Epoch 17, Batch 500] loss: 0.01894368364351976
[Epoch 17, Batch 600] loss: 0.0190813388517563
[Epoch 17, Batch 700] loss: 0.018524253402483738
[Epoch 17, Batch 800] loss: 0.019343880425913083
[Epoch 17, Batch 900] loss: 0.02114257537841695
[Epoch 17, Batch 1000] loss: 0.023138448392692225
[Epoch 17, Batch 1100] loss: 0.023451442828772998
[Epoch 17, Batch 1200] loss: 0.019483309803690646
[Epoch 17, Batch 1300] loss: 0.02078485025707778
[Epoch 17, Batch 1400] loss: 0.01567128249884263
[Epoch 17, Batch 1500] loss: 0.0205019329544848
[Epoch 17, Batch 1600] loss: 0.01349724876909022
[Epoch 17, Batch 1700] loss: 0.014617836704128423
[Epoch 17, Batch 1800] loss: 0.026226724590192135
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0645
Validation Accuracy: 0.9823
Overfitting: 0.0640
[Epoch 18, Batch 100] loss: 0.013282992165568431
[Epoch 18, Batch 200] loss: 0.014993006049953692
[Epoch 18, Batch 300] loss: 0.013360835991697968
[Epoch 18, Batch 400] loss: 0.010106330392009113
[Epoch 18, Batch 500] loss: 0.02377465232977556
[Epoch 18, Batch 600] loss: 0.014809465057114722
[Epoch 18, Batch 700] loss: 0.016489995893571176
[Epoch 18, Batch 800] loss: 0.007941115377288952
[Epoch 18, Batch 900] loss: 0.007969456703413015
[Epoch 18, Batch 1000] loss: 0.021456081878950498
[Epoch 18, Batch 1100] loss: 0.011208960399471835
[Epoch 18, Batch 1200] loss: 0.01790759580183476
[Epoch 18, Batch 1300] loss: 0.016727409165250718
[Epoch 18, Batch 1400] loss: 0.009629377862565888
[Epoch 18, Batch 1500] loss: 0.019459731530141654
[Epoch 18, Batch 1600] loss: 0.015534255834299984
[Epoch 18, Batch 1700] loss: 0.02513137904677933
[Epoch 18, Batch 1800] loss: 0.017105152149397326
**STATS for Epoch 18** : 
Average training loss: 0.0012
Average validation loss: 0.0741
Validation Accuracy: 0.9799
Overfitting: 0.0728
[Epoch 19, Batch 100] loss: 0.014786341890912809
[Epoch 19, Batch 200] loss: 0.018928832117435377
[Epoch 19, Batch 300] loss: 0.014255999585802783
[Epoch 19, Batch 400] loss: 0.013268986825223691
[Epoch 19, Batch 500] loss: 0.010767136692470558
[Epoch 19, Batch 600] loss: 0.01112931211778232
[Epoch 19, Batch 700] loss: 0.011818061938370192
[Epoch 19, Batch 800] loss: 0.01590965390256315
[Epoch 19, Batch 900] loss: 0.011003601930478907
[Epoch 19, Batch 1000] loss: 0.0076515452779131014
[Epoch 19, Batch 1100] loss: 0.02434549819881795
[Epoch 19, Batch 1200] loss: 0.016537340414943175
[Epoch 19, Batch 1300] loss: 0.01258277029815872
[Epoch 19, Batch 1400] loss: 0.021876809282093745
[Epoch 19, Batch 1500] loss: 0.020638598319974336
[Epoch 19, Batch 1600] loss: 0.012221794050783502
[Epoch 19, Batch 1700] loss: 0.01454902378618499
[Epoch 19, Batch 1800] loss: 0.024886959930154263
**STATS for Epoch 19** : 
Average training loss: 0.0009
Average validation loss: 0.0699
Validation Accuracy: 0.9807
Overfitting: 0.0690
[Epoch 20, Batch 100] loss: 0.01772533380299137
[Epoch 20, Batch 200] loss: 0.014657666170933226
[Epoch 20, Batch 300] loss: 0.012172372237823765
[Epoch 20, Batch 400] loss: 0.01428594892116962
[Epoch 20, Batch 500] loss: 0.00955749845263199
[Epoch 20, Batch 600] loss: 0.0065774491514639525
[Epoch 20, Batch 700] loss: 0.018140579818802963
[Epoch 20, Batch 800] loss: 0.01284591152610119
[Epoch 20, Batch 900] loss: 0.007481238253812989
[Epoch 20, Batch 1000] loss: 0.010148167450414575
[Epoch 20, Batch 1100] loss: 0.012971816578246944
[Epoch 20, Batch 1200] loss: 0.01253125444226498
[Epoch 20, Batch 1300] loss: 0.009933152657977189
[Epoch 20, Batch 1400] loss: 0.02430035774494172
[Epoch 20, Batch 1500] loss: 0.015947391323607008
[Epoch 20, Batch 1600] loss: 0.008699884188868055
[Epoch 20, Batch 1700] loss: 0.01077283199037538
[Epoch 20, Batch 1800] loss: 0.012503831138728857
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0618
Validation Accuracy: 0.9844
Overfitting: 0.0613
[Epoch 21, Batch 100] loss: 0.010368133196213875
[Epoch 21, Batch 200] loss: 0.009876188321522933
[Epoch 21, Batch 300] loss: 0.012321858519117086
[Epoch 21, Batch 400] loss: 0.010981998829920485
[Epoch 21, Batch 500] loss: 0.00848935650772546
[Epoch 21, Batch 600] loss: 0.018812113577623676
[Epoch 21, Batch 700] loss: 0.0070745291780758635
[Epoch 21, Batch 800] loss: 0.010799097320161764
[Epoch 21, Batch 900] loss: 0.016424932335448828
[Epoch 21, Batch 1000] loss: 0.009372883350333722
[Epoch 21, Batch 1100] loss: 0.01030304039695693
[Epoch 21, Batch 1200] loss: 0.013775719826808199
[Epoch 21, Batch 1300] loss: 0.022277346501741704
[Epoch 21, Batch 1400] loss: 0.009793584531180385
[Epoch 21, Batch 1500] loss: 0.008599165446321421
[Epoch 21, Batch 1600] loss: 0.020368544643797577
[Epoch 21, Batch 1700] loss: 0.013632095258335539
[Epoch 21, Batch 1800] loss: 0.0069532995437111824
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0682
Validation Accuracy: 0.9825
Overfitting: 0.0679
[Epoch 22, Batch 100] loss: 0.012408022068775608
[Epoch 22, Batch 200] loss: 0.007118180204356577
[Epoch 22, Batch 300] loss: 0.005788436404109234
[Epoch 22, Batch 400] loss: 0.015560485691030407
[Epoch 22, Batch 500] loss: 0.008238975688914251
[Epoch 22, Batch 600] loss: 0.010798479384559414
[Epoch 22, Batch 700] loss: 0.01579075622759774
[Epoch 22, Batch 800] loss: 0.016737334330123303
[Epoch 22, Batch 900] loss: 0.010639688293513245
[Epoch 22, Batch 1000] loss: 0.010675838237393692
[Epoch 22, Batch 1100] loss: 0.010830777965674087
[Epoch 22, Batch 1200] loss: 0.02066095104312808
[Epoch 22, Batch 1300] loss: 0.007936894927706818
[Epoch 22, Batch 1400] loss: 0.01030648610803837
[Epoch 22, Batch 1500] loss: 0.0067953877906211345
[Epoch 22, Batch 1600] loss: 0.008656170089270745
[Epoch 22, Batch 1700] loss: 0.012991276424982061
[Epoch 22, Batch 1800] loss: 0.011463153739811105
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0664
Validation Accuracy: 0.9837
Overfitting: 0.0659
[Epoch 23, Batch 100] loss: 0.007020843085356319
[Epoch 23, Batch 200] loss: 0.009509347963230538
[Epoch 23, Batch 300] loss: 0.015140184175247668
[Epoch 23, Batch 400] loss: 0.024400539211437717
[Epoch 23, Batch 500] loss: 0.010927253611453126
[Epoch 23, Batch 600] loss: 0.0065091431232576725
[Epoch 23, Batch 700] loss: 0.006470960418789673
[Epoch 23, Batch 800] loss: 0.006755083863254185
[Epoch 23, Batch 900] loss: 0.013127818138323165
[Epoch 23, Batch 1000] loss: 0.0055496072251298755
[Epoch 23, Batch 1100] loss: 0.010213644720774937
[Epoch 23, Batch 1200] loss: 0.00793366126732053
[Epoch 23, Batch 1300] loss: 0.005294076540881178
[Epoch 23, Batch 1400] loss: 0.008860390515983453
[Epoch 23, Batch 1500] loss: 0.008268915367902991
[Epoch 23, Batch 1600] loss: 0.010141054073992564
[Epoch 23, Batch 1700] loss: 0.0054860388791621514
[Epoch 23, Batch 1800] loss: 0.010485325066470067
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0651
Validation Accuracy: 0.9840
Overfitting: 0.0647
[Epoch 24, Batch 100] loss: 0.009074652839863119
[Epoch 24, Batch 200] loss: 0.014913322705228892
[Epoch 24, Batch 300] loss: 0.007083362514513283
[Epoch 24, Batch 400] loss: 0.0067619975482102745
[Epoch 24, Batch 500] loss: 0.005313900644828209
[Epoch 24, Batch 600] loss: 0.013794513730667859
[Epoch 24, Batch 700] loss: 0.008785988187291878
[Epoch 24, Batch 800] loss: 0.005007449465801983
[Epoch 24, Batch 900] loss: 0.00796800719128214
[Epoch 24, Batch 1000] loss: 0.004850944798790806
[Epoch 24, Batch 1100] loss: 0.009737298111249402
[Epoch 24, Batch 1200] loss: 0.004612719721123994
[Epoch 24, Batch 1300] loss: 0.0033814018883072095
[Epoch 24, Batch 1400] loss: 0.003969933927705825
[Epoch 24, Batch 1500] loss: 0.010545603254754496
[Epoch 24, Batch 1600] loss: 0.012849300665438932
[Epoch 24, Batch 1700] loss: 0.009315731933293136
[Epoch 24, Batch 1800] loss: 0.007867647556361134
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0632
Validation Accuracy: 0.9849
Overfitting: 0.0628
Fold 1 validation loss: 0.0632
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.302329807281494
[Epoch 1, Batch 200] loss: 2.2850922656059267
[Epoch 1, Batch 300] loss: 2.2593569421768187
[Epoch 1, Batch 400] loss: 2.190596480369568
[Epoch 1, Batch 500] loss: 1.9637251341342925
[Epoch 1, Batch 600] loss: 1.3011628252267837
[Epoch 1, Batch 700] loss: 0.7725584375858306
[Epoch 1, Batch 800] loss: 0.5380168119072914
[Epoch 1, Batch 900] loss: 0.47455229610204697
[Epoch 1, Batch 1000] loss: 0.47057590179145337
[Epoch 1, Batch 1100] loss: 0.4255402984470129
[Epoch 1, Batch 1200] loss: 0.3863593616336584
[Epoch 1, Batch 1300] loss: 0.33837923638522627
[Epoch 1, Batch 1400] loss: 0.31731951985508206
[Epoch 1, Batch 1500] loss: 0.29933949902653695
[Epoch 1, Batch 1600] loss: 0.2856755045801401
[Epoch 1, Batch 1700] loss: 0.26958279190585016
[Epoch 1, Batch 1800] loss: 0.29855998899787667
**STATS for Epoch 1** : 
Average training loss: 0.0096
Average validation loss: 0.2562
Validation Accuracy: 0.9215
Overfitting: 0.2465
Best model saved at epoch 1 with validation loss: 0.2562
[Epoch 2, Batch 100] loss: 0.23018035817891358
[Epoch 2, Batch 200] loss: 0.23331938553601503
[Epoch 2, Batch 300] loss: 0.20368573531508447
[Epoch 2, Batch 400] loss: 0.21402242302894592
[Epoch 2, Batch 500] loss: 0.21940002866089345
[Epoch 2, Batch 600] loss: 0.154051479306072
[Epoch 2, Batch 700] loss: 0.19394819802604615
[Epoch 2, Batch 800] loss: 0.16278223108500242
[Epoch 2, Batch 900] loss: 0.21894237734377384
[Epoch 2, Batch 1000] loss: 0.1396405918430537
[Epoch 2, Batch 1100] loss: 0.1567160979472101
[Epoch 2, Batch 1200] loss: 0.14274575212970375
[Epoch 2, Batch 1300] loss: 0.15932761807926
[Epoch 2, Batch 1400] loss: 0.15714654962532223
[Epoch 2, Batch 1500] loss: 0.14999484669882804
[Epoch 2, Batch 1600] loss: 0.15722923455759882
[Epoch 2, Batch 1700] loss: 0.13191448444500564
[Epoch 2, Batch 1800] loss: 0.136402574935928
**STATS for Epoch 2** : 
Average training loss: 0.0041
Average validation loss: 0.1321
Validation Accuracy: 0.9594
Overfitting: 0.1280
Best model saved at epoch 2 with validation loss: 0.1321
[Epoch 3, Batch 100] loss: 0.09728341384790838
[Epoch 3, Batch 200] loss: 0.12868648569565266
[Epoch 3, Batch 300] loss: 0.13967031352221965
[Epoch 3, Batch 400] loss: 0.14803844121750445
[Epoch 3, Batch 500] loss: 0.09480447672307492
[Epoch 3, Batch 600] loss: 0.12044805517420172
[Epoch 3, Batch 700] loss: 0.11404943494591863
[Epoch 3, Batch 800] loss: 0.14345836156513542
[Epoch 3, Batch 900] loss: 0.11634518312755972
[Epoch 3, Batch 1000] loss: 0.09040487896068954
[Epoch 3, Batch 1100] loss: 0.11128992666024715
[Epoch 3, Batch 1200] loss: 0.12237566999043338
[Epoch 3, Batch 1300] loss: 0.12016466627712362
[Epoch 3, Batch 1400] loss: 0.10558032269123942
[Epoch 3, Batch 1500] loss: 0.0886269927257672
[Epoch 3, Batch 1600] loss: 0.11550105582457036
[Epoch 3, Batch 1700] loss: 0.09331635506823659
[Epoch 3, Batch 1800] loss: 0.09480605331948028
**STATS for Epoch 3** : 
Average training loss: 0.0036
Average validation loss: 0.0953
Validation Accuracy: 0.9713
Overfitting: 0.0916
Best model saved at epoch 3 with validation loss: 0.0953
[Epoch 4, Batch 100] loss: 0.08584892629645764
[Epoch 4, Batch 200] loss: 0.09260511891450733
[Epoch 4, Batch 300] loss: 0.10341126919724047
[Epoch 4, Batch 400] loss: 0.07733283842913806
[Epoch 4, Batch 500] loss: 0.08348963813856244
[Epoch 4, Batch 600] loss: 0.0909063901414629
[Epoch 4, Batch 700] loss: 0.10045132115017623
[Epoch 4, Batch 800] loss: 0.08024242451705504
[Epoch 4, Batch 900] loss: 0.07593872230965644
[Epoch 4, Batch 1000] loss: 0.09361034836387262
[Epoch 4, Batch 1100] loss: 0.09853885599528439
[Epoch 4, Batch 1200] loss: 0.09325703094480559
[Epoch 4, Batch 1300] loss: 0.0753609297145158
[Epoch 4, Batch 1400] loss: 0.0952947669639252
[Epoch 4, Batch 1500] loss: 0.0825800625514239
[Epoch 4, Batch 1600] loss: 0.07310574488481507
[Epoch 4, Batch 1700] loss: 0.0883001387672266
[Epoch 4, Batch 1800] loss: 0.07529243072960526
**STATS for Epoch 4** : 
Average training loss: 0.0031
Average validation loss: 0.0978
Validation Accuracy: 0.9707
Overfitting: 0.0947
[Epoch 5, Batch 100] loss: 0.07158514236565679
[Epoch 5, Batch 200] loss: 0.08077022675541229
[Epoch 5, Batch 300] loss: 0.06913616099976934
[Epoch 5, Batch 400] loss: 0.05410047985846177
[Epoch 5, Batch 500] loss: 0.07309985607455019
[Epoch 5, Batch 600] loss: 0.07081219388230238
[Epoch 5, Batch 700] loss: 0.084152776109986
[Epoch 5, Batch 800] loss: 0.07024953137617558
[Epoch 5, Batch 900] loss: 0.06928629777976311
[Epoch 5, Batch 1000] loss: 0.06387469636742026
[Epoch 5, Batch 1100] loss: 0.05587867739261128
[Epoch 5, Batch 1200] loss: 0.07466319720435421
[Epoch 5, Batch 1300] loss: 0.09445717652095481
[Epoch 5, Batch 1400] loss: 0.07903438615554478
[Epoch 5, Batch 1500] loss: 0.054120270685525614
[Epoch 5, Batch 1600] loss: 0.08206774336053059
[Epoch 5, Batch 1700] loss: 0.06475751394580584
[Epoch 5, Batch 1800] loss: 0.08557779886148636
**STATS for Epoch 5** : 
Average training loss: 0.0037
Average validation loss: 0.0739
Validation Accuracy: 0.9776
Overfitting: 0.0702
Best model saved at epoch 5 with validation loss: 0.0739
[Epoch 6, Batch 100] loss: 0.05175419472390786
[Epoch 6, Batch 200] loss: 0.04745825273217633
[Epoch 6, Batch 300] loss: 0.08195397980802227
[Epoch 6, Batch 400] loss: 0.05736431404366158
[Epoch 6, Batch 500] loss: 0.06940596185391769
[Epoch 6, Batch 600] loss: 0.04487214175285772
[Epoch 6, Batch 700] loss: 0.07845530684804544
[Epoch 6, Batch 800] loss: 0.06590475158009212
[Epoch 6, Batch 900] loss: 0.06718853776343167
[Epoch 6, Batch 1000] loss: 0.050744394932407885
[Epoch 6, Batch 1100] loss: 0.05397379753121641
[Epoch 6, Batch 1200] loss: 0.06259431922866497
[Epoch 6, Batch 1300] loss: 0.08270293231238611
[Epoch 6, Batch 1400] loss: 0.07009015032672324
[Epoch 6, Batch 1500] loss: 0.04975019219797105
[Epoch 6, Batch 1600] loss: 0.06416094637825154
[Epoch 6, Batch 1700] loss: 0.05872614046093076
[Epoch 6, Batch 1800] loss: 0.060352784165297636
**STATS for Epoch 6** : 
Average training loss: 0.0016
Average validation loss: 0.0695
Validation Accuracy: 0.9791
Overfitting: 0.0679
Best model saved at epoch 6 with validation loss: 0.0695
[Epoch 7, Batch 100] loss: 0.062146865437971426
[Epoch 7, Batch 200] loss: 0.05940612046397291
[Epoch 7, Batch 300] loss: 0.0611478499165969
[Epoch 7, Batch 400] loss: 0.035910430784570055
[Epoch 7, Batch 500] loss: 0.048583964383869895
[Epoch 7, Batch 600] loss: 0.05439344561018515
[Epoch 7, Batch 700] loss: 0.05529653080098797
[Epoch 7, Batch 800] loss: 0.06352941044257022
[Epoch 7, Batch 900] loss: 0.05871980898606125
[Epoch 7, Batch 1000] loss: 0.055639481826801784
[Epoch 7, Batch 1100] loss: 0.058145439992658796
[Epoch 7, Batch 1200] loss: 0.062422054106136785
[Epoch 7, Batch 1300] loss: 0.03247627535718493
[Epoch 7, Batch 1400] loss: 0.04298931022174656
[Epoch 7, Batch 1500] loss: 0.051099147802451624
[Epoch 7, Batch 1600] loss: 0.05174425902281655
[Epoch 7, Batch 1700] loss: 0.06021678388817236
[Epoch 7, Batch 1800] loss: 0.07780569481896236
**STATS for Epoch 7** : 
Average training loss: 0.0017
Average validation loss: 0.0744
Validation Accuracy: 0.9774
Overfitting: 0.0727
[Epoch 8, Batch 100] loss: 0.05335896053293254
[Epoch 8, Batch 200] loss: 0.04968651829811279
[Epoch 8, Batch 300] loss: 0.05854922185011674
[Epoch 8, Batch 400] loss: 0.0511101164369029
[Epoch 8, Batch 500] loss: 0.041938247804355344
[Epoch 8, Batch 600] loss: 0.04265082664962392
[Epoch 8, Batch 700] loss: 0.03862471453787293
[Epoch 8, Batch 800] loss: 0.04913996554445475
[Epoch 8, Batch 900] loss: 0.053057369302841835
[Epoch 8, Batch 1000] loss: 0.042852545432688204
[Epoch 8, Batch 1100] loss: 0.05058572836045641
[Epoch 8, Batch 1200] loss: 0.04611129935801728
[Epoch 8, Batch 1300] loss: 0.04070116448448971
[Epoch 8, Batch 1400] loss: 0.04138653114292538
[Epoch 8, Batch 1500] loss: 0.05980511074361857
[Epoch 8, Batch 1600] loss: 0.04244885260763112
[Epoch 8, Batch 1700] loss: 0.05479226690309588
[Epoch 8, Batch 1800] loss: 0.05142571020231117
**STATS for Epoch 8** : 
Average training loss: 0.0014
Average validation loss: 0.0621
Validation Accuracy: 0.9810
Overfitting: 0.0606
Best model saved at epoch 8 with validation loss: 0.0621
[Epoch 9, Batch 100] loss: 0.058816391958098395
[Epoch 9, Batch 200] loss: 0.0560817994188983
[Epoch 9, Batch 300] loss: 0.03605758339777822
[Epoch 9, Batch 400] loss: 0.04660442617838271
[Epoch 9, Batch 500] loss: 0.039042942949017743
[Epoch 9, Batch 600] loss: 0.041061737694253676
[Epoch 9, Batch 700] loss: 0.041999559481919274
[Epoch 9, Batch 800] loss: 0.040962577413301914
[Epoch 9, Batch 900] loss: 0.03260782212833874
[Epoch 9, Batch 1000] loss: 0.04084578840789618
[Epoch 9, Batch 1100] loss: 0.036426093241752826
[Epoch 9, Batch 1200] loss: 0.03360436903545633
[Epoch 9, Batch 1300] loss: 0.05450715519284131
[Epoch 9, Batch 1400] loss: 0.042644375877280254
[Epoch 9, Batch 1500] loss: 0.037208526428294135
[Epoch 9, Batch 1600] loss: 0.06993307112017647
[Epoch 9, Batch 1700] loss: 0.046554917369503526
[Epoch 9, Batch 1800] loss: 0.0319591551173653
**STATS for Epoch 9** : 
Average training loss: 0.0010
Average validation loss: 0.0672
Validation Accuracy: 0.9809
Overfitting: 0.0662
[Epoch 10, Batch 100] loss: 0.039581771227531135
[Epoch 10, Batch 200] loss: 0.03794739768869476
[Epoch 10, Batch 300] loss: 0.03409580154620926
[Epoch 10, Batch 400] loss: 0.0378637530967535
[Epoch 10, Batch 500] loss: 0.05012460728139558
[Epoch 10, Batch 600] loss: 0.045537021217751314
[Epoch 10, Batch 700] loss: 0.036395331282983535
[Epoch 10, Batch 800] loss: 0.041954069378552956
[Epoch 10, Batch 900] loss: 0.03868485429455177
[Epoch 10, Batch 1000] loss: 0.05114734678762033
[Epoch 10, Batch 1100] loss: 0.03916715072351508
[Epoch 10, Batch 1200] loss: 0.035306379938629104
[Epoch 10, Batch 1300] loss: 0.031194886064331514
[Epoch 10, Batch 1400] loss: 0.03376398728301865
[Epoch 10, Batch 1500] loss: 0.041901284732448404
[Epoch 10, Batch 1600] loss: 0.03813433397270274
[Epoch 10, Batch 1700] loss: 0.04411886486050207
[Epoch 10, Batch 1800] loss: 0.020132964499352965
**STATS for Epoch 10** : 
Average training loss: 0.0015
Average validation loss: 0.0692
Validation Accuracy: 0.9786
Overfitting: 0.0677
[Epoch 11, Batch 100] loss: 0.01649301121258759
[Epoch 11, Batch 200] loss: 0.039015433890454004
[Epoch 11, Batch 300] loss: 0.04086962600697006
[Epoch 11, Batch 400] loss: 0.04072530718942289
[Epoch 11, Batch 500] loss: 0.03013370548724197
[Epoch 11, Batch 600] loss: 0.031106807066244073
[Epoch 11, Batch 700] loss: 0.024349332664278335
[Epoch 11, Batch 800] loss: 0.033962469557591246
[Epoch 11, Batch 900] loss: 0.03430721139797242
[Epoch 11, Batch 1000] loss: 0.03706163500377443
[Epoch 11, Batch 1100] loss: 0.036031019500806
[Epoch 11, Batch 1200] loss: 0.027623586838744815
[Epoch 11, Batch 1300] loss: 0.02633206841041101
[Epoch 11, Batch 1400] loss: 0.03654092910073814
[Epoch 11, Batch 1500] loss: 0.033785925813863284
[Epoch 11, Batch 1600] loss: 0.047770761144638525
[Epoch 11, Batch 1700] loss: 0.03557617110374849
[Epoch 11, Batch 1800] loss: 0.026964918959565695
**STATS for Epoch 11** : 
Average training loss: 0.0015
Average validation loss: 0.0589
Validation Accuracy: 0.9826
Overfitting: 0.0575
Best model saved at epoch 11 with validation loss: 0.0589
[Epoch 12, Batch 100] loss: 0.030473470254655695
[Epoch 12, Batch 200] loss: 0.0211048700104584
[Epoch 12, Batch 300] loss: 0.03859272082074312
[Epoch 12, Batch 400] loss: 0.018818568371061703
[Epoch 12, Batch 500] loss: 0.029025770286098124
[Epoch 12, Batch 600] loss: 0.028006772453009036
[Epoch 12, Batch 700] loss: 0.034128336683788806
[Epoch 12, Batch 800] loss: 0.03376348151829006
[Epoch 12, Batch 900] loss: 0.027079773598525207
[Epoch 12, Batch 1000] loss: 0.04373163526295684
[Epoch 12, Batch 1100] loss: 0.024645869702981146
[Epoch 12, Batch 1200] loss: 0.03017419991316274
[Epoch 12, Batch 1300] loss: 0.031536568702940714
[Epoch 12, Batch 1400] loss: 0.03128493248939776
[Epoch 12, Batch 1500] loss: 0.036407531282311535
[Epoch 12, Batch 1600] loss: 0.030652193801797692
[Epoch 12, Batch 1700] loss: 0.04566525785267004
[Epoch 12, Batch 1800] loss: 0.03445989675354213
**STATS for Epoch 12** : 
Average training loss: 0.0009
Average validation loss: 0.0611
Validation Accuracy: 0.9829
Overfitting: 0.0602
[Epoch 13, Batch 100] loss: 0.026770173652039375
[Epoch 13, Batch 200] loss: 0.040080117733959926
[Epoch 13, Batch 300] loss: 0.018939058773539727
[Epoch 13, Batch 400] loss: 0.0307327644227189
[Epoch 13, Batch 500] loss: 0.02624391731194919
[Epoch 13, Batch 600] loss: 0.030041840747289824
[Epoch 13, Batch 700] loss: 0.025360243062314113
[Epoch 13, Batch 800] loss: 0.038549883895611856
[Epoch 13, Batch 900] loss: 0.021011749126337236
[Epoch 13, Batch 1000] loss: 0.03294927969458513
[Epoch 13, Batch 1100] loss: 0.025862970288435462
[Epoch 13, Batch 1200] loss: 0.03363185352805886
[Epoch 13, Batch 1300] loss: 0.03475708709640458
[Epoch 13, Batch 1400] loss: 0.019567858290683943
[Epoch 13, Batch 1500] loss: 0.026051265180140035
[Epoch 13, Batch 1600] loss: 0.03831599202167126
[Epoch 13, Batch 1700] loss: 0.03082787946150347
[Epoch 13, Batch 1800] loss: 0.020386578023681066
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0609
Validation Accuracy: 0.9821
Overfitting: 0.0600
[Epoch 14, Batch 100] loss: 0.023464402697863988
[Epoch 14, Batch 200] loss: 0.035178987331892134
[Epoch 14, Batch 300] loss: 0.02010002024428104
[Epoch 14, Batch 400] loss: 0.03354523687070468
[Epoch 14, Batch 500] loss: 0.02283583585776796
[Epoch 14, Batch 600] loss: 0.020285933133054643
[Epoch 14, Batch 700] loss: 0.02524204560475482
[Epoch 14, Batch 800] loss: 0.0268336718154751
[Epoch 14, Batch 900] loss: 0.020718899144630997
[Epoch 14, Batch 1000] loss: 0.017582845785436802
[Epoch 14, Batch 1100] loss: 0.023768635272681422
[Epoch 14, Batch 1200] loss: 0.023804491367482115
[Epoch 14, Batch 1300] loss: 0.032385317808330004
[Epoch 14, Batch 1400] loss: 0.03776215079378744
[Epoch 14, Batch 1500] loss: 0.023128511318645906
[Epoch 14, Batch 1600] loss: 0.028552269438732764
[Epoch 14, Batch 1700] loss: 0.03158151519874082
[Epoch 14, Batch 1800] loss: 0.020722335166901758
**STATS for Epoch 14** : 
Average training loss: 0.0010
Average validation loss: 0.0555
Validation Accuracy: 0.9836
Overfitting: 0.0545
Best model saved at epoch 14 with validation loss: 0.0555
[Epoch 15, Batch 100] loss: 0.015836833918729098
[Epoch 15, Batch 200] loss: 0.022483974370115904
[Epoch 15, Batch 300] loss: 0.017064313291120924
[Epoch 15, Batch 400] loss: 0.01876934696927492
[Epoch 15, Batch 500] loss: 0.02369784097725642
[Epoch 15, Batch 600] loss: 0.026452764717614628
[Epoch 15, Batch 700] loss: 0.018304765781140306
[Epoch 15, Batch 800] loss: 0.01609731956003088
[Epoch 15, Batch 900] loss: 0.016516950025870756
[Epoch 15, Batch 1000] loss: 0.04192920659002994
[Epoch 15, Batch 1100] loss: 0.016887735242708004
[Epoch 15, Batch 1200] loss: 0.014079984812815383
[Epoch 15, Batch 1300] loss: 0.02398254986263055
[Epoch 15, Batch 1400] loss: 0.02911542147005093
[Epoch 15, Batch 1500] loss: 0.03144593182019889
[Epoch 15, Batch 1600] loss: 0.035988200237115964
[Epoch 15, Batch 1700] loss: 0.01653573039766343
[Epoch 15, Batch 1800] loss: 0.025337014297183488
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0552
Validation Accuracy: 0.9845
Overfitting: 0.0543
Best model saved at epoch 15 with validation loss: 0.0552
[Epoch 16, Batch 100] loss: 0.01906839220704569
[Epoch 16, Batch 200] loss: 0.019544196499628016
[Epoch 16, Batch 300] loss: 0.02225771840508969
[Epoch 16, Batch 400] loss: 0.019973618510048256
[Epoch 16, Batch 500] loss: 0.032187679761073014
[Epoch 16, Batch 600] loss: 0.01479158963809823
[Epoch 16, Batch 700] loss: 0.017236574089547502
[Epoch 16, Batch 800] loss: 0.017449869357806166
[Epoch 16, Batch 900] loss: 0.01167590272420057
[Epoch 16, Batch 1000] loss: 0.015800419861825503
[Epoch 16, Batch 1100] loss: 0.010514071446541493
[Epoch 16, Batch 1200] loss: 0.017994916078168898
[Epoch 16, Batch 1300] loss: 0.021884954041743187
[Epoch 16, Batch 1400] loss: 0.02108168610404391
[Epoch 16, Batch 1500] loss: 0.024103849721650476
[Epoch 16, Batch 1600] loss: 0.02437360513897147
[Epoch 16, Batch 1700] loss: 0.0179780360784207
[Epoch 16, Batch 1800] loss: 0.025887684975605226
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0607
Validation Accuracy: 0.9831
Overfitting: 0.0598
[Epoch 17, Batch 100] loss: 0.012389102089455263
[Epoch 17, Batch 200] loss: 0.017881941362211363
[Epoch 17, Batch 300] loss: 0.011072424158628564
[Epoch 17, Batch 400] loss: 0.010067412800599413
[Epoch 17, Batch 500] loss: 0.015389331488477183
[Epoch 17, Batch 600] loss: 0.014524699087746739
[Epoch 17, Batch 700] loss: 0.01315733596929931
[Epoch 17, Batch 800] loss: 0.021750780201709858
[Epoch 17, Batch 900] loss: 0.024280746212298254
[Epoch 17, Batch 1000] loss: 0.02003019669202331
[Epoch 17, Batch 1100] loss: 0.027919135620359158
[Epoch 17, Batch 1200] loss: 0.030400183625715727
[Epoch 17, Batch 1300] loss: 0.021680795226602642
[Epoch 17, Batch 1400] loss: 0.016626385609051796
[Epoch 17, Batch 1500] loss: 0.017513669981744896
[Epoch 17, Batch 1600] loss: 0.01952713067832519
[Epoch 17, Batch 1700] loss: 0.020354021708717484
[Epoch 17, Batch 1800] loss: 0.02118629967644665
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0580
Validation Accuracy: 0.9841
Overfitting: 0.0574
[Epoch 18, Batch 100] loss: 0.014413648680674669
[Epoch 18, Batch 200] loss: 0.030611755914142124
[Epoch 18, Batch 300] loss: 0.01718266265535931
[Epoch 18, Batch 400] loss: 0.01063313039503555
[Epoch 18, Batch 500] loss: 0.013868859141311987
[Epoch 18, Batch 600] loss: 0.01250206058171898
[Epoch 18, Batch 700] loss: 0.015054973593832984
[Epoch 18, Batch 800] loss: 0.01731464642044557
[Epoch 18, Batch 900] loss: 0.013991388719223324
[Epoch 18, Batch 1000] loss: 0.0144958281019899
[Epoch 18, Batch 1100] loss: 0.029239405594653364
[Epoch 18, Batch 1200] loss: 0.021224957884369358
[Epoch 18, Batch 1300] loss: 0.021887196006318846
[Epoch 18, Batch 1400] loss: 0.018083982800962985
[Epoch 18, Batch 1500] loss: 0.008306310516709346
[Epoch 18, Batch 1600] loss: 0.018423947815972497
[Epoch 18, Batch 1700] loss: 0.013073357830353415
[Epoch 18, Batch 1800] loss: 0.017104213715292645
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0551
Validation Accuracy: 0.9846
Overfitting: 0.0544
Best model saved at epoch 18 with validation loss: 0.0551
[Epoch 19, Batch 100] loss: 0.013403516335783934
[Epoch 19, Batch 200] loss: 0.007335615180327295
[Epoch 19, Batch 300] loss: 0.008925729797119857
[Epoch 19, Batch 400] loss: 0.015025921928317984
[Epoch 19, Batch 500] loss: 0.013475908918044297
[Epoch 19, Batch 600] loss: 0.015985642868454306
[Epoch 19, Batch 700] loss: 0.0097724013066545
[Epoch 19, Batch 800] loss: 0.014915868508214771
[Epoch 19, Batch 900] loss: 0.013778406518922566
[Epoch 19, Batch 1000] loss: 0.011203737481700955
[Epoch 19, Batch 1100] loss: 0.016758031111967286
[Epoch 19, Batch 1200] loss: 0.018917719001001386
[Epoch 19, Batch 1300] loss: 0.010908783897975808
[Epoch 19, Batch 1400] loss: 0.016502800601156196
[Epoch 19, Batch 1500] loss: 0.01369600141916635
[Epoch 19, Batch 1600] loss: 0.012279338382450078
[Epoch 19, Batch 1700] loss: 0.015855514653267164
[Epoch 19, Batch 1800] loss: 0.02907478631783306
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0613
Validation Accuracy: 0.9835
Overfitting: 0.0606
[Epoch 20, Batch 100] loss: 0.011016551237530621
[Epoch 20, Batch 200] loss: 0.010052438408692979
[Epoch 20, Batch 300] loss: 0.008890811764122191
[Epoch 20, Batch 400] loss: 0.016236825772830345
[Epoch 20, Batch 500] loss: 0.013296293044513732
[Epoch 20, Batch 600] loss: 0.008730979802567162
[Epoch 20, Batch 700] loss: 0.011946310084767901
[Epoch 20, Batch 800] loss: 0.00884385531641783
[Epoch 20, Batch 900] loss: 0.018683122835982433
[Epoch 20, Batch 1000] loss: 0.0181136414843877
[Epoch 20, Batch 1100] loss: 0.009797674666333477
[Epoch 20, Batch 1200] loss: 0.013124256836272252
[Epoch 20, Batch 1300] loss: 0.01819697472147709
[Epoch 20, Batch 1400] loss: 0.0199101883671392
[Epoch 20, Batch 1500] loss: 0.013129989001827198
[Epoch 20, Batch 1600] loss: 0.013665845493233065
[Epoch 20, Batch 1700] loss: 0.017861555425770347
[Epoch 20, Batch 1800] loss: 0.013146624586261169
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0672
Validation Accuracy: 0.9822
Overfitting: 0.0667
[Epoch 21, Batch 100] loss: 0.013248449296424951
[Epoch 21, Batch 200] loss: 0.012301812217338011
[Epoch 21, Batch 300] loss: 0.014068109762238237
[Epoch 21, Batch 400] loss: 0.012969827875949705
[Epoch 21, Batch 500] loss: 0.01322913550910016
[Epoch 21, Batch 600] loss: 0.013792219025281155
[Epoch 21, Batch 700] loss: 0.010902711796479708
[Epoch 21, Batch 800] loss: 0.005411286339476646
[Epoch 21, Batch 900] loss: 0.011972657120022632
[Epoch 21, Batch 1000] loss: 0.011882330092548727
[Epoch 21, Batch 1100] loss: 0.009349727914031974
[Epoch 21, Batch 1200] loss: 0.01083098425861408
[Epoch 21, Batch 1300] loss: 0.011771551693482252
[Epoch 21, Batch 1400] loss: 0.009000320720660966
[Epoch 21, Batch 1500] loss: 0.016417225414866152
[Epoch 21, Batch 1600] loss: 0.016253197462356185
[Epoch 21, Batch 1700] loss: 0.014805746279726008
[Epoch 21, Batch 1800] loss: 0.008213044520730364
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0545
Validation Accuracy: 0.9858
Overfitting: 0.0543
Best model saved at epoch 21 with validation loss: 0.0545
[Epoch 22, Batch 100] loss: 0.007127583897199656
[Epoch 22, Batch 200] loss: 0.0059685595674409345
[Epoch 22, Batch 300] loss: 0.010110872720088083
[Epoch 22, Batch 400] loss: 0.008981783636309047
[Epoch 22, Batch 500] loss: 0.011617986130704593
[Epoch 22, Batch 600] loss: 0.013653560890679728
[Epoch 22, Batch 700] loss: 0.009638089157497233
[Epoch 22, Batch 800] loss: 0.012877357505076362
[Epoch 22, Batch 900] loss: 0.007750065868704041
[Epoch 22, Batch 1000] loss: 0.003780703822844771
[Epoch 22, Batch 1100] loss: 0.007891235405031694
[Epoch 22, Batch 1200] loss: 0.01101829457847998
[Epoch 22, Batch 1300] loss: 0.010553691281966166
[Epoch 22, Batch 1400] loss: 0.013332912063324329
[Epoch 22, Batch 1500] loss: 0.015070013861850385
[Epoch 22, Batch 1600] loss: 0.00902258323141723
[Epoch 22, Batch 1700] loss: 0.01464470906290444
[Epoch 22, Batch 1800] loss: 0.01601143099168439
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0708
Validation Accuracy: 0.9812
Overfitting: 0.0702
[Epoch 23, Batch 100] loss: 0.008599022366615828
[Epoch 23, Batch 200] loss: 0.005600693088254048
[Epoch 23, Batch 300] loss: 0.020417593928541464
[Epoch 23, Batch 400] loss: 0.005972429344183183
[Epoch 23, Batch 500] loss: 0.006391682937742189
[Epoch 23, Batch 600] loss: 0.004844639090099463
[Epoch 23, Batch 700] loss: 0.011560901904031197
[Epoch 23, Batch 800] loss: 0.010885030067848902
[Epoch 23, Batch 900] loss: 0.011528122640283982
[Epoch 23, Batch 1000] loss: 0.012939855547510887
[Epoch 23, Batch 1100] loss: 0.006233303133976733
[Epoch 23, Batch 1200] loss: 0.007378417368336158
[Epoch 23, Batch 1300] loss: 0.006940483845828567
[Epoch 23, Batch 1400] loss: 0.012234641965624177
[Epoch 23, Batch 1500] loss: 0.013212606076331212
[Epoch 23, Batch 1600] loss: 0.004089395838367409
[Epoch 23, Batch 1700] loss: 0.007707562257346581
[Epoch 23, Batch 1800] loss: 0.007408475864049251
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0585
Validation Accuracy: 0.9857
Overfitting: 0.0581
[Epoch 24, Batch 100] loss: 0.010146346738433749
[Epoch 24, Batch 200] loss: 0.0078002247277595416
[Epoch 24, Batch 300] loss: 0.004513444928161334
[Epoch 24, Batch 400] loss: 0.0035079346650366008
[Epoch 24, Batch 500] loss: 0.0051426622268536445
[Epoch 24, Batch 600] loss: 0.005231609884015142
[Epoch 24, Batch 700] loss: 0.007644786281543929
[Epoch 24, Batch 800] loss: 0.006980533602238666
[Epoch 24, Batch 900] loss: 0.004729332489894204
[Epoch 24, Batch 1000] loss: 0.009440434125324373
[Epoch 24, Batch 1100] loss: 0.0040272113992296
[Epoch 24, Batch 1200] loss: 0.006020838132817516
[Epoch 24, Batch 1300] loss: 0.008262965466215064
[Epoch 24, Batch 1400] loss: 0.012835994258657592
[Epoch 24, Batch 1500] loss: 0.014735070254832863
[Epoch 24, Batch 1600] loss: 0.01068911866972485
[Epoch 24, Batch 1700] loss: 0.016866791154282055
[Epoch 24, Batch 1800] loss: 0.01081158668504031
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0600
Validation Accuracy: 0.9853
Overfitting: 0.0596
Fold 2 validation loss: 0.0600
Mean validation loss across all folds for Trial 3 is 0.0616 with trial config:  l1: 128, l2: 128, lr: 0.0006672367170464204, batch_size: 16
[I 2024-11-21 22:30:54,716] Trial 2 finished with value: 0.0616292772171084 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 4:
  l1: 128, l2: 128, lr: 0.07286653737491042, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.8412768921256066
[Epoch 1, Batch 200] loss: 1.8765472340583802
[Epoch 1, Batch 300] loss: 1.6970885801315307
[Epoch 1, Batch 400] loss: 1.438429833650589
[Epoch 1, Batch 500] loss: 1.4516312476992608
[Epoch 1, Batch 600] loss: 2.1046647846698763
[Epoch 1, Batch 700] loss: 2.0452835977077486
[Epoch 1, Batch 800] loss: 2.2180945229530336
[Epoch 1, Batch 900] loss: 2.306868562698364
[Epoch 1, Batch 1000] loss: 2.309653444290161
[Epoch 1, Batch 1100] loss: 2.3100182175636292
[Epoch 1, Batch 1200] loss: 2.3079299616813658
[Epoch 1, Batch 1300] loss: 2.3100058746337893
[Epoch 1, Batch 1400] loss: 2.312375314235687
[Epoch 1, Batch 1500] loss: 2.312666664123535
[Epoch 1, Batch 1600] loss: 2.311129651069641
[Epoch 1, Batch 1700] loss: 2.311086509227753
[Epoch 1, Batch 1800] loss: 2.3104438543319703
**STATS for Epoch 1** : 
Average training loss: 0.0927
Average validation loss: 2.3078
Validation Accuracy: 0.0991
Overfitting: 2.2151
Best model saved at epoch 1 with validation loss: 2.3078
[Epoch 2, Batch 100] loss: 2.312007474899292
[Epoch 2, Batch 200] loss: 2.310662705898285
[Epoch 2, Batch 300] loss: 2.3086862325668336
[Epoch 2, Batch 400] loss: 2.3116403436660766
[Epoch 2, Batch 500] loss: 2.311016843318939
[Epoch 2, Batch 600] loss: 2.3062957453727724
[Epoch 2, Batch 700] loss: 2.317657520771027
[Epoch 2, Batch 800] loss: 2.310521330833435
[Epoch 2, Batch 900] loss: 2.3124266123771666
[Epoch 2, Batch 1000] loss: 2.3061490082740783
[Epoch 2, Batch 1100] loss: 2.3126584553718565
[Epoch 2, Batch 1200] loss: 2.3109123492240906
[Epoch 2, Batch 1300] loss: 2.3124220108985902
[Epoch 2, Batch 1400] loss: 2.3118089127540586
[Epoch 2, Batch 1500] loss: 2.3115029740333557
[Epoch 2, Batch 1600] loss: 2.316809079647064
[Epoch 2, Batch 1700] loss: 2.3114177322387697
[Epoch 2, Batch 1800] loss: 2.3110733246803283
**STATS for Epoch 2** : 
Average training loss: 0.0926
Average validation loss: 2.3103
Validation Accuracy: 0.1007
Overfitting: 2.2177
[Epoch 3, Batch 100] loss: 2.312373342514038
[Epoch 3, Batch 200] loss: 2.3104015684127805
[Epoch 3, Batch 300] loss: 2.3116654992103576
[Epoch 3, Batch 400] loss: 2.3146784615516665
[Epoch 3, Batch 500] loss: 2.3094983553886412
[Epoch 3, Batch 600] loss: 2.309923686981201
[Epoch 3, Batch 700] loss: 2.313273365497589
[Epoch 3, Batch 800] loss: 2.307707624435425
[Epoch 3, Batch 900] loss: 2.312401831150055
[Epoch 3, Batch 1000] loss: 2.3088612294197084
[Epoch 3, Batch 1100] loss: 2.306955564022064
[Epoch 3, Batch 1200] loss: 2.3112125277519224
[Epoch 3, Batch 1300] loss: 2.317701337337494
[Epoch 3, Batch 1400] loss: 2.3104171466827395
[Epoch 3, Batch 1500] loss: 2.314969518184662
[Epoch 3, Batch 1600] loss: 2.304385814666748
[Epoch 3, Batch 1700] loss: 2.3092833805084227
[Epoch 3, Batch 1800] loss: 2.3146293783187866
**STATS for Epoch 3** : 
Average training loss: 0.0925
Average validation loss: 2.3093
Validation Accuracy: 0.1007
Overfitting: 2.2168
[Epoch 4, Batch 100] loss: 2.315366656780243
[Epoch 4, Batch 200] loss: 2.311608946323395
[Epoch 4, Batch 300] loss: 2.313274085521698
[Epoch 4, Batch 400] loss: 2.3148386883735657
[Epoch 4, Batch 500] loss: 2.3121798753738405
[Epoch 4, Batch 600] loss: 2.315996835231781
[Epoch 4, Batch 700] loss: 2.304112203121185
[Epoch 4, Batch 800] loss: 2.3058282375335692
[Epoch 4, Batch 900] loss: 2.304783844947815
[Epoch 4, Batch 1000] loss: 2.31372275352478
[Epoch 4, Batch 1100] loss: 2.311411507129669
[Epoch 4, Batch 1200] loss: 2.310920658111572
[Epoch 4, Batch 1300] loss: 2.317429311275482
[Epoch 4, Batch 1400] loss: 2.3145767498016356
[Epoch 4, Batch 1500] loss: 2.314967677593231
[Epoch 4, Batch 1600] loss: 2.308454396724701
[Epoch 4, Batch 1700] loss: 2.311092822551727
[Epoch 4, Batch 1800] loss: 2.3106616163253784
**STATS for Epoch 4** : 
Average training loss: 0.0925
Average validation loss: 2.3081
Validation Accuracy: 0.1122
Overfitting: 2.2155
[Epoch 5, Batch 100] loss: 2.309166169166565
[Epoch 5, Batch 200] loss: 2.3088358211517335
[Epoch 5, Batch 300] loss: 2.316955711841583
[Epoch 5, Batch 400] loss: 2.311652948856354
[Epoch 5, Batch 500] loss: 2.3076894783973696
[Epoch 5, Batch 600] loss: 2.309998559951782
[Epoch 5, Batch 700] loss: 2.3108391404151916
[Epoch 5, Batch 800] loss: 2.307368772029877
[Epoch 5, Batch 900] loss: 2.311975018978119
[Epoch 5, Batch 1000] loss: 2.315802037715912
[Epoch 5, Batch 1100] loss: 2.314607412815094
[Epoch 5, Batch 1200] loss: 2.312394440174103
[Epoch 5, Batch 1300] loss: 2.3126470708847044
[Epoch 5, Batch 1400] loss: 2.316349866390228
[Epoch 5, Batch 1500] loss: 2.3125414872169494
[Epoch 5, Batch 1600] loss: 2.3136589455604555
[Epoch 5, Batch 1700] loss: 2.3094802784919737
[Epoch 5, Batch 1800] loss: 2.314604306221008
**STATS for Epoch 5** : 
Average training loss: 0.0925
Average validation loss: 2.3047
Validation Accuracy: 0.1122
Overfitting: 2.2122
Best model saved at epoch 5 with validation loss: 2.3047
[Epoch 6, Batch 100] loss: 2.3091399264335633
[Epoch 6, Batch 200] loss: 2.3099175763130186
[Epoch 6, Batch 300] loss: 2.309492189884186
[Epoch 6, Batch 400] loss: 2.3092308163642885
[Epoch 6, Batch 500] loss: 2.307939214706421
[Epoch 6, Batch 600] loss: 2.3110628223419187
[Epoch 6, Batch 700] loss: 2.31404705286026
[Epoch 6, Batch 800] loss: 2.308159132003784
[Epoch 6, Batch 900] loss: 2.313705050945282
[Epoch 6, Batch 1000] loss: 2.307915723323822
[Epoch 6, Batch 1100] loss: 2.3090592360496522
[Epoch 6, Batch 1200] loss: 2.3159204435348513
[Epoch 6, Batch 1300] loss: 2.3128407621383666
[Epoch 6, Batch 1400] loss: 2.3130426001548767
[Epoch 6, Batch 1500] loss: 2.312375159263611
[Epoch 6, Batch 1600] loss: 2.314206337928772
[Epoch 6, Batch 1700] loss: 2.310226993560791
[Epoch 6, Batch 1800] loss: 2.3097062420845034
**STATS for Epoch 6** : 
Average training loss: 0.0926
Average validation loss: 2.3051
Validation Accuracy: 0.1122
Overfitting: 2.2125
[Epoch 7, Batch 100] loss: 2.31109450340271
[Epoch 7, Batch 200] loss: 2.306563491821289
[Epoch 7, Batch 300] loss: 2.3123671507835386
[Epoch 7, Batch 400] loss: 2.3106953048706056
[Epoch 7, Batch 500] loss: 2.3153794765472413
[Epoch 7, Batch 600] loss: 2.315773296356201
[Epoch 7, Batch 700] loss: 2.3136556434631346
[Epoch 7, Batch 800] loss: 2.313945167064667
[Epoch 7, Batch 900] loss: 2.3105546641349792
[Epoch 7, Batch 1000] loss: 2.3133493757247923
[Epoch 7, Batch 1100] loss: 2.308820388317108
[Epoch 7, Batch 1200] loss: 2.3117235040664674
[Epoch 7, Batch 1300] loss: 2.313032555580139
[Epoch 7, Batch 1400] loss: 2.3084586334228514
[Epoch 7, Batch 1500] loss: 2.3097379350662233
[Epoch 7, Batch 1600] loss: 2.308246490955353
[Epoch 7, Batch 1700] loss: 2.316640751361847
[Epoch 7, Batch 1800] loss: 2.308644812107086
**STATS for Epoch 7** : 
Average training loss: 0.0925
Average validation loss: 2.3091
Validation Accuracy: 0.1036
Overfitting: 2.2165
[Epoch 8, Batch 100] loss: 2.3122800993919372
[Epoch 8, Batch 200] loss: 2.3093621039390566
[Epoch 8, Batch 300] loss: 2.308743531703949
[Epoch 8, Batch 400] loss: 2.313037223815918
[Epoch 8, Batch 500] loss: 2.3125271344184877
[Epoch 8, Batch 600] loss: 2.3125982093811035
[Epoch 8, Batch 700] loss: 2.307760841846466
[Epoch 8, Batch 800] loss: 2.31015753030777
[Epoch 8, Batch 900] loss: 2.3122046613693237
[Epoch 8, Batch 1000] loss: 2.308930377960205
[Epoch 8, Batch 1100] loss: 2.312188093662262
[Epoch 8, Batch 1200] loss: 2.311678433418274
[Epoch 8, Batch 1300] loss: 2.3093554544448853
[Epoch 8, Batch 1400] loss: 2.3167524433135984
[Epoch 8, Batch 1500] loss: 2.3071632242202758
[Epoch 8, Batch 1600] loss: 2.3128836488723756
[Epoch 8, Batch 1700] loss: 2.312618761062622
[Epoch 8, Batch 1800] loss: 2.3098861956596375
**STATS for Epoch 8** : 
Average training loss: 0.0924
Average validation loss: 2.3090
Validation Accuracy: 0.0998
Overfitting: 2.2165
[Epoch 9, Batch 100] loss: 2.309964017868042
[Epoch 9, Batch 200] loss: 2.3074073696136477
[Epoch 9, Batch 300] loss: 2.3073031449317933
[Epoch 9, Batch 400] loss: 2.3136154341697694
[Epoch 9, Batch 500] loss: 2.3149475383758547
[Epoch 9, Batch 600] loss: 2.3110681200027465
[Epoch 9, Batch 700] loss: 2.312162435054779
[Epoch 9, Batch 800] loss: 2.3113805055618286
[Epoch 9, Batch 900] loss: 2.307057776451111
[Epoch 9, Batch 1000] loss: 2.3114441776275636
[Epoch 9, Batch 1100] loss: 2.31392450094223
[Epoch 9, Batch 1200] loss: 2.310878918170929
[Epoch 9, Batch 1300] loss: 2.308880889415741
[Epoch 9, Batch 1400] loss: 2.3094204688072204
[Epoch 9, Batch 1500] loss: 2.31377427816391
[Epoch 9, Batch 1600] loss: 2.3064347219467165
[Epoch 9, Batch 1700] loss: 2.315398771762848
[Epoch 9, Batch 1800] loss: 2.309568622112274
**STATS for Epoch 9** : 
Average training loss: 0.0925
Average validation loss: 2.3160
Validation Accuracy: 0.0904
Overfitting: 2.2235
[Epoch 10, Batch 100] loss: 2.3154600739479063
[Epoch 10, Batch 200] loss: 2.312436718940735
[Epoch 10, Batch 300] loss: 2.314930341243744
[Epoch 10, Batch 400] loss: 2.3107381868362427
[Epoch 10, Batch 500] loss: 2.3161521649360655
[Epoch 10, Batch 600] loss: 2.313302536010742
[Epoch 10, Batch 700] loss: 2.302794041633606
[Epoch 10, Batch 800] loss: 2.3084631824493407
[Epoch 10, Batch 900] loss: 2.313422267436981
[Epoch 10, Batch 1000] loss: 2.3072738575935365
[Epoch 10, Batch 1100] loss: 2.309944908618927
[Epoch 10, Batch 1200] loss: 2.31100994348526
[Epoch 10, Batch 1300] loss: 2.309741885662079
[Epoch 10, Batch 1400] loss: 2.308417387008667
[Epoch 10, Batch 1500] loss: 2.312156310081482
[Epoch 10, Batch 1600] loss: 2.311818459033966
[Epoch 10, Batch 1700] loss: 2.312186028957367
[Epoch 10, Batch 1800] loss: 2.31289155960083
**STATS for Epoch 10** : 
Average training loss: 0.0924
Average validation loss: 2.3088
Validation Accuracy: 0.0982
Overfitting: 2.2164
[Epoch 11, Batch 100] loss: 2.314464089870453
[Epoch 11, Batch 200] loss: 2.309205718040466
[Epoch 11, Batch 300] loss: 2.3088350462913514
[Epoch 11, Batch 400] loss: 2.3117037439346313
[Epoch 11, Batch 500] loss: 2.3114042472839356
[Epoch 11, Batch 600] loss: 2.3080504083633424
[Epoch 11, Batch 700] loss: 2.312154176235199
[Epoch 11, Batch 800] loss: 2.314659869670868
[Epoch 11, Batch 900] loss: 2.3099915099143984
[Epoch 11, Batch 1000] loss: 2.3057664442062378
[Epoch 11, Batch 1100] loss: 2.3095472121238707
[Epoch 11, Batch 1200] loss: 2.3133230805397034
[Epoch 11, Batch 1300] loss: 2.3089459705352784
[Epoch 11, Batch 1400] loss: 2.309975576400757
[Epoch 11, Batch 1500] loss: 2.309991543292999
[Epoch 11, Batch 1600] loss: 2.313993926048279
[Epoch 11, Batch 1700] loss: 2.3075030493736266
[Epoch 11, Batch 1800] loss: 2.3148536777496336
**STATS for Epoch 11** : 
Average training loss: 0.0926
Average validation loss: 2.3046
Validation Accuracy: 0.1122
Overfitting: 2.2120
Best model saved at epoch 11 with validation loss: 2.3046
[Epoch 12, Batch 100] loss: 2.3065923738479612
[Epoch 12, Batch 200] loss: 2.30816908121109
[Epoch 12, Batch 300] loss: 2.3088741064071656
[Epoch 12, Batch 400] loss: 2.3139806723594667
[Epoch 12, Batch 500] loss: 2.31015282869339
[Epoch 12, Batch 600] loss: 2.311984875202179
[Epoch 12, Batch 700] loss: 2.3153693675994873
[Epoch 12, Batch 800] loss: 2.3093328142166136
[Epoch 12, Batch 900] loss: 2.312528805732727
[Epoch 12, Batch 1000] loss: 2.309838261604309
[Epoch 12, Batch 1100] loss: 2.310503747463226
[Epoch 12, Batch 1200] loss: 2.311637761592865
[Epoch 12, Batch 1300] loss: 2.314634976387024
[Epoch 12, Batch 1400] loss: 2.3124037265777586
[Epoch 12, Batch 1500] loss: 2.313085057735443
[Epoch 12, Batch 1600] loss: 2.3115814995765684
[Epoch 12, Batch 1700] loss: 2.3113526797294615
[Epoch 12, Batch 1800] loss: 2.3102871870994566
**STATS for Epoch 12** : 
Average training loss: 0.0926
Average validation loss: 2.3088
Validation Accuracy: 0.1036
Overfitting: 2.2162
[Epoch 13, Batch 100] loss: 2.3090726256370546
[Epoch 13, Batch 200] loss: 2.316317799091339
[Epoch 13, Batch 300] loss: 2.308082377910614
[Epoch 13, Batch 400] loss: 2.312082509994507
[Epoch 13, Batch 500] loss: 2.3157887840270996
[Epoch 13, Batch 600] loss: 2.312348873615265
[Epoch 13, Batch 700] loss: 2.3103092813491823
[Epoch 13, Batch 800] loss: 2.3110804605484008
[Epoch 13, Batch 900] loss: 2.31715172290802
[Epoch 13, Batch 1000] loss: 2.308835606575012
[Epoch 13, Batch 1100] loss: 2.3121724772453307
[Epoch 13, Batch 1200] loss: 2.311995222568512
[Epoch 13, Batch 1300] loss: 2.312013418674469
[Epoch 13, Batch 1400] loss: 2.3127230286598204
[Epoch 13, Batch 1500] loss: 2.311371009349823
[Epoch 13, Batch 1600] loss: 2.3098897457122805
[Epoch 13, Batch 1700] loss: 2.3122396659851074
[Epoch 13, Batch 1800] loss: 2.3048801231384277
**STATS for Epoch 13** : 
Average training loss: 0.0927
Average validation loss: 2.3078
Validation Accuracy: 0.0998
Overfitting: 2.2151
[Epoch 14, Batch 100] loss: 2.3161322116851806
[Epoch 14, Batch 200] loss: 2.3119476652145385
[Epoch 14, Batch 300] loss: 2.309227900505066
[Epoch 14, Batch 400] loss: 2.3123043537139893
[Epoch 14, Batch 500] loss: 2.3156163334846496
[Epoch 14, Batch 600] loss: 2.310425214767456
[Epoch 14, Batch 700] loss: 2.3131262922286986
[Epoch 14, Batch 800] loss: 2.3140750885009767
[Epoch 14, Batch 900] loss: 2.31375746011734
[Epoch 14, Batch 1000] loss: 2.3116869807243345
[Epoch 14, Batch 1100] loss: 2.316483235359192
[Epoch 14, Batch 1200] loss: 2.3105767941474915
[Epoch 14, Batch 1300] loss: 2.3066283869743347
[Epoch 14, Batch 1400] loss: 2.3132356715202333
[Epoch 14, Batch 1500] loss: 2.3095673751831054
[Epoch 14, Batch 1600] loss: 2.310921325683594
[Epoch 14, Batch 1700] loss: 2.3057297897338866
[Epoch 14, Batch 1800] loss: 2.306569905281067
**STATS for Epoch 14** : 
Average training loss: 0.0921
Average validation loss: 2.3085
Validation Accuracy: 0.1122
Overfitting: 2.2164
[Epoch 15, Batch 100] loss: 2.315230543613434
[Epoch 15, Batch 200] loss: 2.3087243461608886
[Epoch 15, Batch 300] loss: 2.313109450340271
[Epoch 15, Batch 400] loss: 2.31284654378891
[Epoch 15, Batch 500] loss: 2.311846144199371
[Epoch 15, Batch 600] loss: 2.3091927933692933
[Epoch 15, Batch 700] loss: 2.315373730659485
[Epoch 15, Batch 800] loss: 2.3133397555351256
[Epoch 15, Batch 900] loss: 2.3083970189094543
[Epoch 15, Batch 1000] loss: 2.3092884516716
[Epoch 15, Batch 1100] loss: 2.3075328373909
[Epoch 15, Batch 1200] loss: 2.312641577720642
[Epoch 15, Batch 1300] loss: 2.3102794885635376
[Epoch 15, Batch 1400] loss: 2.3121954941749574
[Epoch 15, Batch 1500] loss: 2.310301871299744
[Epoch 15, Batch 1600] loss: 2.317412633895874
[Epoch 15, Batch 1700] loss: 2.308524105548859
[Epoch 15, Batch 1800] loss: 2.309915678501129
**STATS for Epoch 15** : 
Average training loss: 0.0924
Average validation loss: 2.3144
Validation Accuracy: 0.0991
Overfitting: 2.2220
[Epoch 16, Batch 100] loss: 2.310149517059326
[Epoch 16, Batch 200] loss: 2.315011444091797
[Epoch 16, Batch 300] loss: 2.3122243332862853
[Epoch 16, Batch 400] loss: 2.306634111404419
[Epoch 16, Batch 500] loss: 2.310785508155823
[Epoch 16, Batch 600] loss: 2.314130449295044
[Epoch 16, Batch 700] loss: 2.3130721378326418
[Epoch 16, Batch 800] loss: 2.3085295152664185
[Epoch 16, Batch 900] loss: 2.312030110359192
[Epoch 16, Batch 1000] loss: 2.3089680218696595
[Epoch 16, Batch 1100] loss: 2.312474083900452
[Epoch 16, Batch 1200] loss: 2.309304850101471
[Epoch 16, Batch 1300] loss: 2.3127423787117003
[Epoch 16, Batch 1400] loss: 2.310970575809479
[Epoch 16, Batch 1500] loss: 2.3101217484474184
[Epoch 16, Batch 1600] loss: 2.31440185546875
[Epoch 16, Batch 1700] loss: 2.3107064366340637
[Epoch 16, Batch 1800] loss: 2.3104303598403932
**STATS for Epoch 16** : 
Average training loss: 0.0924
Average validation loss: 2.3067
Validation Accuracy: 0.1036
Overfitting: 2.2142
[Epoch 17, Batch 100] loss: 2.309125392436981
[Epoch 17, Batch 200] loss: 2.3082485580444336
[Epoch 17, Batch 300] loss: 2.31106703042984
[Epoch 17, Batch 400] loss: 2.312885081768036
[Epoch 17, Batch 500] loss: 2.3068226766586304
[Epoch 17, Batch 600] loss: 2.3135480666160584
[Epoch 17, Batch 700] loss: 2.309803500175476
[Epoch 17, Batch 800] loss: 2.308057646751404
[Epoch 17, Batch 900] loss: 2.3141764283180235
[Epoch 17, Batch 1000] loss: 2.3136762976646423
[Epoch 17, Batch 1100] loss: 2.312349967956543
[Epoch 17, Batch 1200] loss: 2.308085582256317
[Epoch 17, Batch 1300] loss: 2.308728575706482
[Epoch 17, Batch 1400] loss: 2.311463725566864
[Epoch 17, Batch 1500] loss: 2.311101734638214
[Epoch 17, Batch 1600] loss: 2.3122612619400025
[Epoch 17, Batch 1700] loss: 2.3123308706283567
[Epoch 17, Batch 1800] loss: 2.3153353476524354
**STATS for Epoch 17** : 
Average training loss: 0.0924
Average validation loss: 2.3132
Validation Accuracy: 0.1122
Overfitting: 2.2207
[Epoch 18, Batch 100] loss: 2.3127962708473206
[Epoch 18, Batch 200] loss: 2.312666668891907
[Epoch 18, Batch 300] loss: 2.3144206833839416
[Epoch 18, Batch 400] loss: 2.3139955163002015
[Epoch 18, Batch 500] loss: 2.315032436847687
[Epoch 18, Batch 600] loss: 2.309496955871582
[Epoch 18, Batch 700] loss: 2.311435317993164
[Epoch 18, Batch 800] loss: 2.3077627491950987
[Epoch 18, Batch 900] loss: 2.308528473377228
[Epoch 18, Batch 1000] loss: 2.310226058959961
[Epoch 18, Batch 1100] loss: 2.3120936441421507
[Epoch 18, Batch 1200] loss: 2.311715371608734
[Epoch 18, Batch 1300] loss: 2.3079110026359557
[Epoch 18, Batch 1400] loss: 2.315045163631439
[Epoch 18, Batch 1500] loss: 2.3094837522506713
[Epoch 18, Batch 1600] loss: 2.3128416180610656
[Epoch 18, Batch 1700] loss: 2.312756998538971
[Epoch 18, Batch 1800] loss: 2.308145797252655
**STATS for Epoch 18** : 
Average training loss: 0.0925
Average validation loss: 2.3065
Validation Accuracy: 0.0991
Overfitting: 2.2140
[Epoch 19, Batch 100] loss: 2.3089790391921996
[Epoch 19, Batch 200] loss: 2.315424027442932
[Epoch 19, Batch 300] loss: 2.3109405708312987
[Epoch 19, Batch 400] loss: 2.3118931317329405
[Epoch 19, Batch 500] loss: 2.314621503353119
[Epoch 19, Batch 600] loss: 2.314854462146759
[Epoch 19, Batch 700] loss: 2.3134122562408446
[Epoch 19, Batch 800] loss: 2.3063376426696776
[Epoch 19, Batch 900] loss: 2.3078327536582948
[Epoch 19, Batch 1000] loss: 2.310017993450165
[Epoch 19, Batch 1100] loss: 2.3174705719947815
[Epoch 19, Batch 1200] loss: 2.3071846079826357
[Epoch 19, Batch 1300] loss: 2.3099906754493715
[Epoch 19, Batch 1400] loss: 2.3159009122848513
[Epoch 19, Batch 1500] loss: 2.312375612258911
[Epoch 19, Batch 1600] loss: 2.307585825920105
[Epoch 19, Batch 1700] loss: 2.309254477024078
[Epoch 19, Batch 1800] loss: 2.3079220819473267
**STATS for Epoch 19** : 
Average training loss: 0.0924
Average validation loss: 2.3123
Validation Accuracy: 0.1036
Overfitting: 2.2199
[Epoch 20, Batch 100] loss: 2.3100122928619387
[Epoch 20, Batch 200] loss: 2.3130356097221374
[Epoch 20, Batch 300] loss: 2.309900288581848
[Epoch 20, Batch 400] loss: 2.316371259689331
[Epoch 20, Batch 500] loss: 2.310637581348419
[Epoch 20, Batch 600] loss: 2.3118694639205932
[Epoch 20, Batch 700] loss: 2.311234736442566
[Epoch 20, Batch 800] loss: 2.3161932611465454
[Epoch 20, Batch 900] loss: 2.3081022763252257
[Epoch 20, Batch 1000] loss: 2.309897758960724
[Epoch 20, Batch 1100] loss: 2.3156308817863462
[Epoch 20, Batch 1200] loss: 2.3162478971481324
[Epoch 20, Batch 1300] loss: 2.313641414642334
[Epoch 20, Batch 1400] loss: 2.3054836416244506
[Epoch 20, Batch 1500] loss: 2.3095411467552185
[Epoch 20, Batch 1600] loss: 2.312108242511749
[Epoch 20, Batch 1700] loss: 2.3183272314071655
[Epoch 20, Batch 1800] loss: 2.3109243941307067
**STATS for Epoch 20** : 
Average training loss: 0.0926
Average validation loss: 2.3159
Validation Accuracy: 0.1007
Overfitting: 2.2233
[Epoch 21, Batch 100] loss: 2.3107157230377195
[Epoch 21, Batch 200] loss: 2.312458026409149
[Epoch 21, Batch 300] loss: 2.3040790271759035
[Epoch 21, Batch 400] loss: 2.30864981174469
[Epoch 21, Batch 500] loss: 2.311522567272186
[Epoch 21, Batch 600] loss: 2.3128007555007937
[Epoch 21, Batch 700] loss: 2.312419216632843
[Epoch 21, Batch 800] loss: 2.3144464802742006
[Epoch 21, Batch 900] loss: 2.312131700515747
[Epoch 21, Batch 1000] loss: 2.30872832775116
[Epoch 21, Batch 1100] loss: 2.315735466480255
[Epoch 21, Batch 1200] loss: 2.3120253324508666
[Epoch 21, Batch 1300] loss: 2.3106169176101683
[Epoch 21, Batch 1400] loss: 2.3116809368133544
[Epoch 21, Batch 1500] loss: 2.3115454745292663
[Epoch 21, Batch 1600] loss: 2.307459738254547
[Epoch 21, Batch 1700] loss: 2.3107820749282837
[Epoch 21, Batch 1800] loss: 2.3143500542640685
**STATS for Epoch 21** : 
Average training loss: 0.0925
Average validation loss: 2.3139
Validation Accuracy: 0.1007
Overfitting: 2.2213
[Epoch 22, Batch 100] loss: 2.310302023887634
[Epoch 22, Batch 200] loss: 2.3088386845588684
[Epoch 22, Batch 300] loss: 2.31506046295166
[Epoch 22, Batch 400] loss: 2.3086017322540284
[Epoch 22, Batch 500] loss: 2.3114967823028563
[Epoch 22, Batch 600] loss: 2.312392313480377
[Epoch 22, Batch 700] loss: 2.3136337542533876
[Epoch 22, Batch 800] loss: 2.307976598739624
[Epoch 22, Batch 900] loss: 2.3142781925201414
[Epoch 22, Batch 1000] loss: 2.3093906354904177
[Epoch 22, Batch 1100] loss: 2.309609830379486
[Epoch 22, Batch 1200] loss: 2.30880569934845
[Epoch 22, Batch 1300] loss: 2.3099841904640197
[Epoch 22, Batch 1400] loss: 2.3074838423728945
[Epoch 22, Batch 1500] loss: 2.3083406281471253
[Epoch 22, Batch 1600] loss: 2.3113693261146544
[Epoch 22, Batch 1700] loss: 2.3076687693595885
[Epoch 22, Batch 1800] loss: 2.3118104767799377
**STATS for Epoch 22** : 
Average training loss: 0.0925
Average validation loss: 2.3154
Validation Accuracy: 0.0998
Overfitting: 2.2230
[Epoch 23, Batch 100] loss: 2.3139017748832704
[Epoch 23, Batch 200] loss: 2.3113774156570432
[Epoch 23, Batch 300] loss: 2.307923173904419
[Epoch 23, Batch 400] loss: 2.3147151112556457
[Epoch 23, Batch 500] loss: 2.3078435134887694
[Epoch 23, Batch 600] loss: 2.3137416768074037
[Epoch 23, Batch 700] loss: 2.3109146976470947
[Epoch 23, Batch 800] loss: 2.313153738975525
[Epoch 23, Batch 900] loss: 2.3109371566772463
[Epoch 23, Batch 1000] loss: 2.3116718101501466
[Epoch 23, Batch 1100] loss: 2.3118899273872375
[Epoch 23, Batch 1200] loss: 2.307398507595062
[Epoch 23, Batch 1300] loss: 2.310120713710785
[Epoch 23, Batch 1400] loss: 2.3166704273223875
[Epoch 23, Batch 1500] loss: 2.310438334941864
[Epoch 23, Batch 1600] loss: 2.309457120895386
[Epoch 23, Batch 1700] loss: 2.3145955061912535
[Epoch 23, Batch 1800] loss: 2.3095605969429016
**STATS for Epoch 23** : 
Average training loss: 0.0926
Average validation loss: 2.3077
Validation Accuracy: 0.0987
Overfitting: 2.2151
[Epoch 24, Batch 100] loss: 2.30808881521225
[Epoch 24, Batch 200] loss: 2.315565640926361
[Epoch 24, Batch 300] loss: 2.308126890659332
[Epoch 24, Batch 400] loss: 2.3100330448150634
[Epoch 24, Batch 500] loss: 2.3136572265625
[Epoch 24, Batch 600] loss: 2.3125880360603333
[Epoch 24, Batch 700] loss: 2.314729399681091
[Epoch 24, Batch 800] loss: 2.3112219023704528
[Epoch 24, Batch 900] loss: 2.3137378025054933
[Epoch 24, Batch 1000] loss: 2.311212604045868
[Epoch 24, Batch 1100] loss: 2.3100748372077944
[Epoch 24, Batch 1200] loss: 2.3181589818000794
[Epoch 24, Batch 1300] loss: 2.3101949739456176
[Epoch 24, Batch 1400] loss: 2.3117934823036195
[Epoch 24, Batch 1500] loss: 2.309178342819214
[Epoch 24, Batch 1600] loss: 2.3141718697547913
[Epoch 24, Batch 1700] loss: 2.315654528141022
[Epoch 24, Batch 1800] loss: 2.3097151207923887
**STATS for Epoch 24** : 
Average training loss: 0.0926
Average validation loss: 2.3141
Validation Accuracy: 0.0986
Overfitting: 2.2215
Fold 1 validation loss: 2.3141
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.8141965597867966
[Epoch 1, Batch 200] loss: 1.8145170575380325
[Epoch 1, Batch 300] loss: 1.53100621342659
[Epoch 1, Batch 400] loss: 1.4129042577743531
[Epoch 1, Batch 500] loss: 2.02561225771904
[Epoch 1, Batch 600] loss: 2.148060458898544
[Epoch 1, Batch 700] loss: 1.9026984935998916
[Epoch 1, Batch 800] loss: 1.7278273546695708
[Epoch 1, Batch 900] loss: 1.6776765781641005
[Epoch 1, Batch 1000] loss: 2.38278085231781
[Epoch 1, Batch 1100] loss: 2.1949864840507507
[Epoch 1, Batch 1200] loss: 2.1572741878032686
[Epoch 1, Batch 1300] loss: 2.086737743616104
[Epoch 1, Batch 1400] loss: 2.2624226677417756
[Epoch 1, Batch 1500] loss: 2.316167290210724
[Epoch 1, Batch 1600] loss: 2.3095881843566897
[Epoch 1, Batch 1700] loss: 2.310890417098999
[Epoch 1, Batch 1800] loss: 2.313747408390045
**STATS for Epoch 1** : 
Average training loss: 0.0922
Average validation loss: 2.3092
Validation Accuracy: 0.0992
Overfitting: 2.2170
Best model saved at epoch 1 with validation loss: 2.3092
[Epoch 2, Batch 100] loss: 2.3138621854782104
[Epoch 2, Batch 200] loss: 2.3100597071647644
[Epoch 2, Batch 300] loss: 2.3096086239814757
[Epoch 2, Batch 400] loss: 2.313719398975372
[Epoch 2, Batch 500] loss: 2.307622165679932
[Epoch 2, Batch 600] loss: 2.314836187362671
[Epoch 2, Batch 700] loss: 2.310869994163513
[Epoch 2, Batch 800] loss: 2.314730956554413
[Epoch 2, Batch 900] loss: 2.3064762282371523
[Epoch 2, Batch 1000] loss: 2.312837688922882
[Epoch 2, Batch 1100] loss: 2.3145262598991394
[Epoch 2, Batch 1200] loss: 2.3116617012023926
[Epoch 2, Batch 1300] loss: 2.307832942008972
[Epoch 2, Batch 1400] loss: 2.314427578449249
[Epoch 2, Batch 1500] loss: 2.3101655721664427
[Epoch 2, Batch 1600] loss: 2.314934377670288
[Epoch 2, Batch 1700] loss: 2.3106729197502136
[Epoch 2, Batch 1800] loss: 2.3164060878753663
**STATS for Epoch 2** : 
Average training loss: 0.0925
Average validation loss: 2.3050
Validation Accuracy: 0.1126
Overfitting: 2.2124
Best model saved at epoch 2 with validation loss: 2.3050
[Epoch 3, Batch 100] loss: 2.3119097447395323
[Epoch 3, Batch 200] loss: 2.312601292133331
[Epoch 3, Batch 300] loss: 2.307566821575165
[Epoch 3, Batch 400] loss: 2.3143548917770387
[Epoch 3, Batch 500] loss: 2.309789986610413
[Epoch 3, Batch 600] loss: 2.3095974636077883
[Epoch 3, Batch 700] loss: 2.3060337233543398
[Epoch 3, Batch 800] loss: 2.309749803543091
[Epoch 3, Batch 900] loss: 2.313505618572235
[Epoch 3, Batch 1000] loss: 2.316681263446808
[Epoch 3, Batch 1100] loss: 2.3133587789535524
[Epoch 3, Batch 1200] loss: 2.3130097365379334
[Epoch 3, Batch 1300] loss: 2.3105127143859865
[Epoch 3, Batch 1400] loss: 2.3120613861083985
[Epoch 3, Batch 1500] loss: 2.309775824546814
[Epoch 3, Batch 1600] loss: 2.3122554326057436
[Epoch 3, Batch 1700] loss: 2.311359462738037
[Epoch 3, Batch 1800] loss: 2.307430000305176
**STATS for Epoch 3** : 
Average training loss: 0.0924
Average validation loss: 2.3103
Validation Accuracy: 0.1037
Overfitting: 2.2179
[Epoch 4, Batch 100] loss: 2.312511053085327
[Epoch 4, Batch 200] loss: 2.3144859361648558
[Epoch 4, Batch 300] loss: 2.3174801874160766
[Epoch 4, Batch 400] loss: 2.309611394405365
[Epoch 4, Batch 500] loss: 2.3097855472564697
[Epoch 4, Batch 600] loss: 2.3145890378952028
[Epoch 4, Batch 700] loss: 2.3091823196411134
[Epoch 4, Batch 800] loss: 2.3129798364639282
[Epoch 4, Batch 900] loss: 2.311280198097229
[Epoch 4, Batch 1000] loss: 2.3129520845413207
[Epoch 4, Batch 1100] loss: 2.310862948894501
[Epoch 4, Batch 1200] loss: 2.31209666967392
[Epoch 4, Batch 1300] loss: 2.3114853501319885
[Epoch 4, Batch 1400] loss: 2.3146501708030702
[Epoch 4, Batch 1500] loss: 2.3144826531410216
[Epoch 4, Batch 1600] loss: 2.3132835388183595
[Epoch 4, Batch 1700] loss: 2.3104642963409425
[Epoch 4, Batch 1800] loss: 2.3092530274391176
**STATS for Epoch 4** : 
Average training loss: 0.0925
Average validation loss: 2.3124
Validation Accuracy: 0.0976
Overfitting: 2.2200
[Epoch 5, Batch 100] loss: 2.311328341960907
[Epoch 5, Batch 200] loss: 2.3087385845184327
[Epoch 5, Batch 300] loss: 2.3144377136230467
[Epoch 5, Batch 400] loss: 2.3079969358444212
[Epoch 5, Batch 500] loss: 2.3111734914779665
[Epoch 5, Batch 600] loss: 2.312573080062866
[Epoch 5, Batch 700] loss: 2.31088919878006
[Epoch 5, Batch 800] loss: 2.3109648299217223
[Epoch 5, Batch 900] loss: 2.3120537543296815
[Epoch 5, Batch 1000] loss: 2.3113008451461794
[Epoch 5, Batch 1100] loss: 2.3102691864967344
[Epoch 5, Batch 1200] loss: 2.3090820336341857
[Epoch 5, Batch 1300] loss: 2.3187722992897033
[Epoch 5, Batch 1400] loss: 2.313777410984039
[Epoch 5, Batch 1500] loss: 2.3070275139808656
[Epoch 5, Batch 1600] loss: 2.3083890891075134
[Epoch 5, Batch 1700] loss: 2.313942563533783
[Epoch 5, Batch 1800] loss: 2.30976309299469
**STATS for Epoch 5** : 
Average training loss: 0.0925
Average validation loss: 2.3163
Validation Accuracy: 0.1126
Overfitting: 2.2239
[Epoch 6, Batch 100] loss: 2.3187266421318053
[Epoch 6, Batch 200] loss: 2.311847834587097
[Epoch 6, Batch 300] loss: 2.316801218986511
[Epoch 6, Batch 400] loss: 2.3129417657852174
[Epoch 6, Batch 500] loss: 2.309511110782623
[Epoch 6, Batch 600] loss: 2.318010013103485
[Epoch 6, Batch 700] loss: 2.313034257888794
[Epoch 6, Batch 800] loss: 2.3156442737579344
[Epoch 6, Batch 900] loss: 2.309710111618042
[Epoch 6, Batch 1000] loss: 2.3099299359321592
[Epoch 6, Batch 1100] loss: 2.317197155952454
[Epoch 6, Batch 1200] loss: 2.30404625415802
[Epoch 6, Batch 1300] loss: 2.3143122839927672
[Epoch 6, Batch 1400] loss: 2.312343854904175
[Epoch 6, Batch 1500] loss: 2.3099144196510313
[Epoch 6, Batch 1600] loss: 2.313347635269165
[Epoch 6, Batch 1700] loss: 2.310093712806702
[Epoch 6, Batch 1800] loss: 2.3057840061187744
**STATS for Epoch 6** : 
Average training loss: 0.0925
Average validation loss: 2.3147
Validation Accuracy: 0.0903
Overfitting: 2.2222
[Epoch 7, Batch 100] loss: 2.313594481945038
[Epoch 7, Batch 200] loss: 2.3123651194572448
[Epoch 7, Batch 300] loss: 2.312213559150696
[Epoch 7, Batch 400] loss: 2.312691662311554
[Epoch 7, Batch 500] loss: 2.315644769668579
[Epoch 7, Batch 600] loss: 2.307208442687988
[Epoch 7, Batch 700] loss: 2.3140121293067932
[Epoch 7, Batch 800] loss: 2.309578652381897
[Epoch 7, Batch 900] loss: 2.311036353111267
[Epoch 7, Batch 1000] loss: 2.315764443874359
[Epoch 7, Batch 1100] loss: 2.3092993307113647
[Epoch 7, Batch 1200] loss: 2.308868668079376
[Epoch 7, Batch 1300] loss: 2.3149819445610045
[Epoch 7, Batch 1400] loss: 2.3114527821540833
[Epoch 7, Batch 1500] loss: 2.311213912963867
[Epoch 7, Batch 1600] loss: 2.307157509326935
[Epoch 7, Batch 1700] loss: 2.311905612945557
[Epoch 7, Batch 1800] loss: 2.3114545726776123
**STATS for Epoch 7** : 
Average training loss: 0.0926
Average validation loss: 2.3058
Validation Accuracy: 0.1037
Overfitting: 2.2132
[Epoch 8, Batch 100] loss: 2.312852120399475
[Epoch 8, Batch 200] loss: 2.312011725902557
[Epoch 8, Batch 300] loss: 2.309457278251648
[Epoch 8, Batch 400] loss: 2.3091497898101805
[Epoch 8, Batch 500] loss: 2.309000639915466
[Epoch 8, Batch 600] loss: 2.3102583646774293
[Epoch 8, Batch 700] loss: 2.311022925376892
[Epoch 8, Batch 800] loss: 2.3150571322441102
[Epoch 8, Batch 900] loss: 2.307881453037262
[Epoch 8, Batch 1000] loss: 2.3143998908996584
[Epoch 8, Batch 1100] loss: 2.3122292137145997
[Epoch 8, Batch 1200] loss: 2.3135562634468076
[Epoch 8, Batch 1300] loss: 2.313046944141388
[Epoch 8, Batch 1400] loss: 2.310544807910919
[Epoch 8, Batch 1500] loss: 2.3109858679771422
[Epoch 8, Batch 1600] loss: 2.3159146428108217
[Epoch 8, Batch 1700] loss: 2.309034423828125
[Epoch 8, Batch 1800] loss: 2.3110064578056337
**STATS for Epoch 8** : 
Average training loss: 0.0925
Average validation loss: 2.3072
Validation Accuracy: 0.1052
Overfitting: 2.2147
[Epoch 9, Batch 100] loss: 2.313286690711975
[Epoch 9, Batch 200] loss: 2.3132125687599183
[Epoch 9, Batch 300] loss: 2.3139497089385985
[Epoch 9, Batch 400] loss: 2.309388611316681
[Epoch 9, Batch 500] loss: 2.312730755805969
[Epoch 9, Batch 600] loss: 2.310321235656738
[Epoch 9, Batch 700] loss: 2.3028743124008177
[Epoch 9, Batch 800] loss: 2.3112195706367493
[Epoch 9, Batch 900] loss: 2.314228537082672
[Epoch 9, Batch 1000] loss: 2.3126170873641967
[Epoch 9, Batch 1100] loss: 2.3089444780349733
[Epoch 9, Batch 1200] loss: 2.3156937885284425
[Epoch 9, Batch 1300] loss: 2.3129598808288576
[Epoch 9, Batch 1400] loss: 2.3072439074516295
[Epoch 9, Batch 1500] loss: 2.3145709896087645
[Epoch 9, Batch 1600] loss: 2.3123255348205567
[Epoch 9, Batch 1700] loss: 2.3107512331008913
[Epoch 9, Batch 1800] loss: 2.3070277976989746
**STATS for Epoch 9** : 
Average training loss: 0.0925
Average validation loss: 2.3121
Validation Accuracy: 0.0985
Overfitting: 2.2197
[Epoch 10, Batch 100] loss: 2.3154703760147095
[Epoch 10, Batch 200] loss: 2.3133552050590516
[Epoch 10, Batch 300] loss: 2.3110154175758364
[Epoch 10, Batch 400] loss: 2.3093285894393922
[Epoch 10, Batch 500] loss: 2.30976265668869
[Epoch 10, Batch 600] loss: 2.3107331585884094
[Epoch 10, Batch 700] loss: 2.3123836874961854
[Epoch 10, Batch 800] loss: 2.3125922751426695
[Epoch 10, Batch 900] loss: 2.3095605969429016
[Epoch 10, Batch 1000] loss: 2.3081810760498045
[Epoch 10, Batch 1100] loss: 2.315208795070648
[Epoch 10, Batch 1200] loss: 2.315433440208435
[Epoch 10, Batch 1300] loss: 2.317041072845459
[Epoch 10, Batch 1400] loss: 2.3132238388061523
[Epoch 10, Batch 1500] loss: 2.3130925607681276
[Epoch 10, Batch 1600] loss: 2.3142429304122927
[Epoch 10, Batch 1700] loss: 2.3131675910949707
[Epoch 10, Batch 1800] loss: 2.3078661441802977
**STATS for Epoch 10** : 
Average training loss: 0.0925
Average validation loss: 2.3092
Validation Accuracy: 0.0992
Overfitting: 2.2167
[Epoch 11, Batch 100] loss: 2.3112062072753905
[Epoch 11, Batch 200] loss: 2.3141704416275024
[Epoch 11, Batch 300] loss: 2.3121056365966797
[Epoch 11, Batch 400] loss: 2.3124393320083616
[Epoch 11, Batch 500] loss: 2.3108601069450376
[Epoch 11, Batch 600] loss: 2.3121017909049986
[Epoch 11, Batch 700] loss: 2.3116958928108216
[Epoch 11, Batch 800] loss: 2.3109660148620605
[Epoch 11, Batch 900] loss: 2.312035307884216
[Epoch 11, Batch 1000] loss: 2.3077812957763673
[Epoch 11, Batch 1100] loss: 2.310933611392975
[Epoch 11, Batch 1200] loss: 2.312581512928009
[Epoch 11, Batch 1300] loss: 2.3123713684082032
[Epoch 11, Batch 1400] loss: 2.31584178686142
[Epoch 11, Batch 1500] loss: 2.30753986120224
[Epoch 11, Batch 1600] loss: 2.309948039054871
[Epoch 11, Batch 1700] loss: 2.3119883823394773
[Epoch 11, Batch 1800] loss: 2.3161019611358644
**STATS for Epoch 11** : 
Average training loss: 0.0926
Average validation loss: 2.3042
Validation Accuracy: 0.1126
Overfitting: 2.2116
Best model saved at epoch 11 with validation loss: 2.3042
[Epoch 12, Batch 100] loss: 2.3115540981292724
[Epoch 12, Batch 200] loss: 2.312061197757721
[Epoch 12, Batch 300] loss: 2.3154861426353452
[Epoch 12, Batch 400] loss: 2.3088688492774962
[Epoch 12, Batch 500] loss: 2.3114921259880066
[Epoch 12, Batch 600] loss: 2.308368973731995
[Epoch 12, Batch 700] loss: 2.3105059838294983
[Epoch 12, Batch 800] loss: 2.3132815313339234
[Epoch 12, Batch 900] loss: 2.3167521071434023
[Epoch 12, Batch 1000] loss: 2.311182606220245
[Epoch 12, Batch 1100] loss: 2.311134071350098
[Epoch 12, Batch 1200] loss: 2.308206639289856
[Epoch 12, Batch 1300] loss: 2.307295379638672
[Epoch 12, Batch 1400] loss: 2.3090496397018434
[Epoch 12, Batch 1500] loss: 2.3130985426902773
[Epoch 12, Batch 1600] loss: 2.3118063974380494
[Epoch 12, Batch 1700] loss: 2.310432724952698
[Epoch 12, Batch 1800] loss: 2.3151162981987
**STATS for Epoch 12** : 
Average training loss: 0.0924
Average validation loss: 2.3119
Validation Accuracy: 0.1037
Overfitting: 2.2196
[Epoch 13, Batch 100] loss: 2.315069010257721
[Epoch 13, Batch 200] loss: 2.312752251625061
[Epoch 13, Batch 300] loss: 2.3094556522369385
[Epoch 13, Batch 400] loss: 2.3121592378616334
[Epoch 13, Batch 500] loss: 2.3165331578254698
[Epoch 13, Batch 600] loss: 2.3126444935798647
[Epoch 13, Batch 700] loss: 2.3135748314857483
[Epoch 13, Batch 800] loss: 2.3115503072738646
[Epoch 13, Batch 900] loss: 2.3101147747039796
[Epoch 13, Batch 1000] loss: 2.308516619205475
[Epoch 13, Batch 1100] loss: 2.3104873180389403
[Epoch 13, Batch 1200] loss: 2.3152779936790466
[Epoch 13, Batch 1300] loss: 2.312590184211731
[Epoch 13, Batch 1400] loss: 2.3133953046798705
[Epoch 13, Batch 1500] loss: 2.307794497013092
[Epoch 13, Batch 1600] loss: 2.310226848125458
[Epoch 13, Batch 1700] loss: 2.308680012226105
[Epoch 13, Batch 1800] loss: 2.3110714602470397
**STATS for Epoch 13** : 
Average training loss: 0.0923
Average validation loss: 2.3105
Validation Accuracy: 0.1126
Overfitting: 2.2182
[Epoch 14, Batch 100] loss: 2.3088369226455687
[Epoch 14, Batch 200] loss: 2.309986777305603
[Epoch 14, Batch 300] loss: 2.310722532272339
[Epoch 14, Batch 400] loss: 2.306927833557129
[Epoch 14, Batch 500] loss: 2.311727674007416
[Epoch 14, Batch 600] loss: 2.3199809885025022
[Epoch 14, Batch 700] loss: 2.307372794151306
[Epoch 14, Batch 800] loss: 2.3145446753501893
[Epoch 14, Batch 900] loss: 2.3100202965736387
[Epoch 14, Batch 1000] loss: 2.3063193416595458
[Epoch 14, Batch 1100] loss: 2.3089849615097044
[Epoch 14, Batch 1200] loss: 2.3067141819000243
[Epoch 14, Batch 1300] loss: 2.3185196495056153
[Epoch 14, Batch 1400] loss: 2.30554084777832
[Epoch 14, Batch 1500] loss: 2.3126835012435913
[Epoch 14, Batch 1600] loss: 2.3110026025772097
[Epoch 14, Batch 1700] loss: 2.31206139087677
[Epoch 14, Batch 1800] loss: 2.3119428873062136
**STATS for Epoch 14** : 
Average training loss: 0.0926
Average validation loss: 2.3097
Validation Accuracy: 0.0976
Overfitting: 2.2170
[Epoch 15, Batch 100] loss: 2.3136638164520265
[Epoch 15, Batch 200] loss: 2.3085884284973144
[Epoch 15, Batch 300] loss: 2.313416087627411
[Epoch 15, Batch 400] loss: 2.3106442856788636
[Epoch 15, Batch 500] loss: 2.3110597276687623
[Epoch 15, Batch 600] loss: 2.309431610107422
[Epoch 15, Batch 700] loss: 2.3154606294631956
[Epoch 15, Batch 800] loss: 2.310986034870148
[Epoch 15, Batch 900] loss: 2.3068682765960693
[Epoch 15, Batch 1000] loss: 2.312293219566345
[Epoch 15, Batch 1100] loss: 2.3118662810325623
[Epoch 15, Batch 1200] loss: 2.3170006561279295
[Epoch 15, Batch 1300] loss: 2.309492435455322
[Epoch 15, Batch 1400] loss: 2.3137473177909853
[Epoch 15, Batch 1500] loss: 2.309114832878113
[Epoch 15, Batch 1600] loss: 2.312607080936432
[Epoch 15, Batch 1700] loss: 2.30706773519516
[Epoch 15, Batch 1800] loss: 2.3123297834396364
**STATS for Epoch 15** : 
Average training loss: 0.0923
Average validation loss: 2.3158
Validation Accuracy: 0.0992
Overfitting: 2.2235
[Epoch 16, Batch 100] loss: 2.3146526551246644
[Epoch 16, Batch 200] loss: 2.3107681465148926
[Epoch 16, Batch 300] loss: 2.3116187334060667
[Epoch 16, Batch 400] loss: 2.305674216747284
[Epoch 16, Batch 500] loss: 2.312700822353363
[Epoch 16, Batch 600] loss: 2.3122908020019532
[Epoch 16, Batch 700] loss: 2.311538119316101
[Epoch 16, Batch 800] loss: 2.3104791617393494
[Epoch 16, Batch 900] loss: 2.309303333759308
[Epoch 16, Batch 1000] loss: 2.3062925720214844
[Epoch 16, Batch 1100] loss: 2.3117475438117983
[Epoch 16, Batch 1200] loss: 2.3127252006530763
[Epoch 16, Batch 1300] loss: 2.3126468110084533
[Epoch 16, Batch 1400] loss: 2.3111338067054747
[Epoch 16, Batch 1500] loss: 2.308316910266876
[Epoch 16, Batch 1600] loss: 2.314785804748535
[Epoch 16, Batch 1700] loss: 2.315667941570282
[Epoch 16, Batch 1800] loss: 2.313176329135895
**STATS for Epoch 16** : 
Average training loss: 0.0926
Average validation loss: 2.3106
Validation Accuracy: 0.1052
Overfitting: 2.2180
[Epoch 17, Batch 100] loss: 2.311298894882202
[Epoch 17, Batch 200] loss: 2.30957350730896
[Epoch 17, Batch 300] loss: 2.308624565601349
[Epoch 17, Batch 400] loss: 2.3138148617744445
[Epoch 17, Batch 500] loss: 2.3158514070510865
[Epoch 17, Batch 600] loss: 2.317186119556427
[Epoch 17, Batch 700] loss: 2.315661861896515
[Epoch 17, Batch 800] loss: 2.309862484931946
[Epoch 17, Batch 900] loss: 2.3113799691200256
[Epoch 17, Batch 1000] loss: 2.312660863399506
[Epoch 17, Batch 1100] loss: 2.31365665435791
[Epoch 17, Batch 1200] loss: 2.310271592140198
[Epoch 17, Batch 1300] loss: 2.308466475009918
[Epoch 17, Batch 1400] loss: 2.311391532421112
[Epoch 17, Batch 1500] loss: 2.30910587310791
[Epoch 17, Batch 1600] loss: 2.3098243188858034
[Epoch 17, Batch 1700] loss: 2.309804606437683
[Epoch 17, Batch 1800] loss: 2.311497304439545
**STATS for Epoch 17** : 
Average training loss: 0.0926
Average validation loss: 2.3119
Validation Accuracy: 0.0976
Overfitting: 2.2194
[Epoch 18, Batch 100] loss: 2.3071126103401185
[Epoch 18, Batch 200] loss: 2.310689446926117
[Epoch 18, Batch 300] loss: 2.3136247181892395
[Epoch 18, Batch 400] loss: 2.311140868663788
[Epoch 18, Batch 500] loss: 2.3135585951805115
[Epoch 18, Batch 600] loss: 2.3092306303977965
[Epoch 18, Batch 700] loss: 2.314276099205017
[Epoch 18, Batch 800] loss: 2.3131077122688293
[Epoch 18, Batch 900] loss: 2.315917055606842
[Epoch 18, Batch 1000] loss: 2.3083791971206664
[Epoch 18, Batch 1100] loss: 2.3130321216583254
[Epoch 18, Batch 1200] loss: 2.313689568042755
[Epoch 18, Batch 1300] loss: 2.3137750363349916
[Epoch 18, Batch 1400] loss: 2.309888460636139
[Epoch 18, Batch 1500] loss: 2.312470345497131
[Epoch 18, Batch 1600] loss: 2.3109047341346742
[Epoch 18, Batch 1700] loss: 2.3113608241081236
[Epoch 18, Batch 1800] loss: 2.3159861874580385
**STATS for Epoch 18** : 
Average training loss: 0.0924
Average validation loss: 2.3119
Validation Accuracy: 0.1126
Overfitting: 2.2195
[Epoch 19, Batch 100] loss: 2.3166573286056518
[Epoch 19, Batch 200] loss: 2.310651669502258
[Epoch 19, Batch 300] loss: 2.306483862400055
[Epoch 19, Batch 400] loss: 2.30929988861084
[Epoch 19, Batch 500] loss: 2.3127505564689637
[Epoch 19, Batch 600] loss: 2.3138888907432555
[Epoch 19, Batch 700] loss: 2.3129880809783936
[Epoch 19, Batch 800] loss: 2.3142802047729494
[Epoch 19, Batch 900] loss: 2.312475497722626
[Epoch 19, Batch 1000] loss: 2.312909300327301
[Epoch 19, Batch 1100] loss: 2.31134788274765
[Epoch 19, Batch 1200] loss: 2.3152069568634035
[Epoch 19, Batch 1300] loss: 2.3092116069793702
[Epoch 19, Batch 1400] loss: 2.3165360140800475
[Epoch 19, Batch 1500] loss: 2.3132979035377503
[Epoch 19, Batch 1600] loss: 2.309315755367279
[Epoch 19, Batch 1700] loss: 2.30917111158371
[Epoch 19, Batch 1800] loss: 2.30766606092453
**STATS for Epoch 19** : 
Average training loss: 0.0926
Average validation loss: 2.3042
Validation Accuracy: 0.1037
Overfitting: 2.2116
Best model saved at epoch 19 with validation loss: 2.3042
[Epoch 20, Batch 100] loss: 2.3040708541870116
[Epoch 20, Batch 200] loss: 2.3137185907363893
[Epoch 20, Batch 300] loss: 2.3107511591911316
[Epoch 20, Batch 400] loss: 2.3073420977592467
[Epoch 20, Batch 500] loss: 2.310098960399628
[Epoch 20, Batch 600] loss: 2.311612241268158
[Epoch 20, Batch 700] loss: 2.316177806854248
[Epoch 20, Batch 800] loss: 2.309050259590149
[Epoch 20, Batch 900] loss: 2.3130740404129027
[Epoch 20, Batch 1000] loss: 2.3088858485221864
[Epoch 20, Batch 1100] loss: 2.3139167284965514
[Epoch 20, Batch 1200] loss: 2.3104673767089845
[Epoch 20, Batch 1300] loss: 2.3108008980751036
[Epoch 20, Batch 1400] loss: 2.3126774978637696
[Epoch 20, Batch 1500] loss: 2.3127680611610413
[Epoch 20, Batch 1600] loss: 2.3128943991661073
[Epoch 20, Batch 1700] loss: 2.309615831375122
[Epoch 20, Batch 1800] loss: 2.310793499946594
**STATS for Epoch 20** : 
Average training loss: 0.0925
Average validation loss: 2.3139
Validation Accuracy: 0.1126
Overfitting: 2.2214
[Epoch 21, Batch 100] loss: 2.311083800792694
[Epoch 21, Batch 200] loss: 2.311151282787323
[Epoch 21, Batch 300] loss: 2.308341977596283
[Epoch 21, Batch 400] loss: 2.3149327301979064
[Epoch 21, Batch 500] loss: 2.316034972667694
[Epoch 21, Batch 600] loss: 2.3174142813682557
[Epoch 21, Batch 700] loss: 2.3143716287612914
[Epoch 21, Batch 800] loss: 2.3107833647727967
[Epoch 21, Batch 900] loss: 2.3120319843292236
[Epoch 21, Batch 1000] loss: 2.3137654304504394
[Epoch 21, Batch 1100] loss: 2.3089996147155762
[Epoch 21, Batch 1200] loss: 2.3112660384178163
[Epoch 21, Batch 1300] loss: 2.307961256504059
[Epoch 21, Batch 1400] loss: 2.3097527050971984
[Epoch 21, Batch 1500] loss: 2.3124981904029847
[Epoch 21, Batch 1600] loss: 2.3131336522102357
[Epoch 21, Batch 1700] loss: 2.310681324005127
[Epoch 21, Batch 1800] loss: 2.3114654922485354
**STATS for Epoch 21** : 
Average training loss: 0.0924
Average validation loss: 2.3090
Validation Accuracy: 0.0985
Overfitting: 2.2166
[Epoch 22, Batch 100] loss: 2.312098205089569
[Epoch 22, Batch 200] loss: 2.31438805103302
[Epoch 22, Batch 300] loss: 2.318729407787323
[Epoch 22, Batch 400] loss: 2.305497772693634
[Epoch 22, Batch 500] loss: 2.311960799694061
[Epoch 22, Batch 600] loss: 2.3100777411460878
[Epoch 22, Batch 700] loss: 2.3124409127235412
[Epoch 22, Batch 800] loss: 2.3195305633544923
[Epoch 22, Batch 900] loss: 2.314632580280304
[Epoch 22, Batch 1000] loss: 2.312910945415497
[Epoch 22, Batch 1100] loss: 2.314848310947418
[Epoch 22, Batch 1200] loss: 2.3151303362846374
[Epoch 22, Batch 1300] loss: 2.3060344529151915
[Epoch 22, Batch 1400] loss: 2.3104393243789674
[Epoch 22, Batch 1500] loss: 2.3160927367210387
[Epoch 22, Batch 1600] loss: 2.3075258708000184
[Epoch 22, Batch 1700] loss: 2.310446038246155
[Epoch 22, Batch 1800] loss: 2.3120539450645445
**STATS for Epoch 22** : 
Average training loss: 0.0925
Average validation loss: 2.3120
Validation Accuracy: 0.0965
Overfitting: 2.2195
[Epoch 23, Batch 100] loss: 2.3114483547210694
[Epoch 23, Batch 200] loss: 2.3083552360534667
[Epoch 23, Batch 300] loss: 2.313955240249634
[Epoch 23, Batch 400] loss: 2.3122362971305845
[Epoch 23, Batch 500] loss: 2.314794969558716
[Epoch 23, Batch 600] loss: 2.3118462109565736
[Epoch 23, Batch 700] loss: 2.3100637912750246
[Epoch 23, Batch 800] loss: 2.311418766975403
[Epoch 23, Batch 900] loss: 2.3102864718437193
[Epoch 23, Batch 1000] loss: 2.3160907196998597
[Epoch 23, Batch 1100] loss: 2.311813726425171
[Epoch 23, Batch 1200] loss: 2.313178656101227
[Epoch 23, Batch 1300] loss: 2.3150308322906494
[Epoch 23, Batch 1400] loss: 2.3091506433486937
[Epoch 23, Batch 1500] loss: 2.309899854660034
[Epoch 23, Batch 1600] loss: 2.3171201825141905
[Epoch 23, Batch 1700] loss: 2.309916923046112
[Epoch 23, Batch 1800] loss: 2.3131949663162232
**STATS for Epoch 23** : 
Average training loss: 0.0926
Average validation loss: 2.3121
Validation Accuracy: 0.1000
Overfitting: 2.2195
[Epoch 24, Batch 100] loss: 2.312268762588501
[Epoch 24, Batch 200] loss: 2.3116964292526245
[Epoch 24, Batch 300] loss: 2.3105959725379943
[Epoch 24, Batch 400] loss: 2.310952670574188
[Epoch 24, Batch 500] loss: 2.3093042945861817
[Epoch 24, Batch 600] loss: 2.311550209522247
[Epoch 24, Batch 700] loss: 2.310747904777527
[Epoch 24, Batch 800] loss: 2.314967062473297
[Epoch 24, Batch 900] loss: 2.310275595188141
[Epoch 24, Batch 1000] loss: 2.3099205350875853
[Epoch 24, Batch 1100] loss: 2.311135070323944
[Epoch 24, Batch 1200] loss: 2.304349992275238
[Epoch 24, Batch 1300] loss: 2.311929852962494
[Epoch 24, Batch 1400] loss: 2.3067730283737182
[Epoch 24, Batch 1500] loss: 2.3133735966682436
[Epoch 24, Batch 1600] loss: 2.311883487701416
[Epoch 24, Batch 1700] loss: 2.3069065237045288
[Epoch 24, Batch 1800] loss: 2.31375723361969
**STATS for Epoch 24** : 
Average training loss: 0.0924
Average validation loss: 2.3148
Validation Accuracy: 0.0965
Overfitting: 2.2224
Fold 2 validation loss: 2.3148
Mean validation loss across all folds for Trial 4 is 2.3144 with trial config:  l1: 128, l2: 128, lr: 0.07286653737491042, batch_size: 16
[I 2024-11-21 22:43:27,302] Trial 3 finished with value: 2.314410787328084 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.07286653737491042, 'batch_size': 16}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 5:
  l1: 256, l2: 128, lr: 0.00010842262717330161, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.299547710418701
[Epoch 1, Batch 200] loss: 2.2953344631195067
[Epoch 1, Batch 300] loss: 2.292609443664551
[Epoch 1, Batch 400] loss: 2.2906952691078186
[Epoch 1, Batch 500] loss: 2.2874476385116576
[Epoch 1, Batch 600] loss: 2.284089002609253
[Epoch 1, Batch 700] loss: 2.28022999048233
[Epoch 1, Batch 800] loss: 2.27860488653183
[Epoch 1, Batch 900] loss: 2.2739775586128235
[Epoch 1, Batch 1000] loss: 2.2696125507354736
[Epoch 1, Batch 1100] loss: 2.2652468919754027
[Epoch 1, Batch 1200] loss: 2.260319948196411
[Epoch 1, Batch 1300] loss: 2.2549615859985352
[Epoch 1, Batch 1400] loss: 2.246204707622528
[Epoch 1, Batch 1500] loss: 2.239718585014343
[Epoch 1, Batch 1600] loss: 2.2315793561935426
[Epoch 1, Batch 1700] loss: 2.2197923636436463
[Epoch 1, Batch 1800] loss: 2.203470478057861
**STATS for Epoch 1** : 
Average training loss: 0.0874
Average validation loss: 2.1838
Validation Accuracy: 0.4432
Overfitting: 2.0964
Best model saved at epoch 1 with validation loss: 2.1838
[Epoch 2, Batch 100] loss: 2.174050719738007
[Epoch 2, Batch 200] loss: 2.148216574192047
[Epoch 2, Batch 300] loss: 2.126978030204773
[Epoch 2, Batch 400] loss: 2.087007040977478
[Epoch 2, Batch 500] loss: 2.044432235956192
[Epoch 2, Batch 600] loss: 1.9775395035743712
[Epoch 2, Batch 700] loss: 1.8910849213600158
[Epoch 2, Batch 800] loss: 1.772213591337204
[Epoch 2, Batch 900] loss: 1.653136249780655
[Epoch 2, Batch 1000] loss: 1.4922963738441468
[Epoch 2, Batch 1100] loss: 1.3289782524108886
[Epoch 2, Batch 1200] loss: 1.2063769561052322
[Epoch 2, Batch 1300] loss: 1.0319078490138054
[Epoch 2, Batch 1400] loss: 0.9367808908224106
[Epoch 2, Batch 1500] loss: 0.8374969461560249
[Epoch 2, Batch 1600] loss: 0.7722690293192863
[Epoch 2, Batch 1700] loss: 0.7185593828558922
[Epoch 2, Batch 1800] loss: 0.6164608666300774
**STATS for Epoch 2** : 
Average training loss: 0.0246
Average validation loss: 0.6182
Validation Accuracy: 0.8295
Overfitting: 0.5936
Best model saved at epoch 2 with validation loss: 0.6182
[Epoch 3, Batch 100] loss: 0.6151261620223523
[Epoch 3, Batch 200] loss: 0.6111277908086776
[Epoch 3, Batch 300] loss: 0.5293332387506962
[Epoch 3, Batch 400] loss: 0.5595918865501881
[Epoch 3, Batch 500] loss: 0.4983250293135643
[Epoch 3, Batch 600] loss: 0.49297126829624177
[Epoch 3, Batch 700] loss: 0.46593006610870363
[Epoch 3, Batch 800] loss: 0.49413818299770357
[Epoch 3, Batch 900] loss: 0.4758197051286697
[Epoch 3, Batch 1000] loss: 0.4384261038899422
[Epoch 3, Batch 1100] loss: 0.4468485330045223
[Epoch 3, Batch 1200] loss: 0.4196884333342314
[Epoch 3, Batch 1300] loss: 0.4455242269486189
[Epoch 3, Batch 1400] loss: 0.3977750375121832
[Epoch 3, Batch 1500] loss: 0.41937185943126676
[Epoch 3, Batch 1600] loss: 0.39794205740094185
[Epoch 3, Batch 1700] loss: 0.3729295504838228
[Epoch 3, Batch 1800] loss: 0.382819237485528
**STATS for Epoch 3** : 
Average training loss: 0.0150
Average validation loss: 0.3739
Validation Accuracy: 0.8936
Overfitting: 0.3589
Best model saved at epoch 3 with validation loss: 0.3739
[Epoch 4, Batch 100] loss: 0.3925432465225458
[Epoch 4, Batch 200] loss: 0.3553934489935637
[Epoch 4, Batch 300] loss: 0.3120495454967022
[Epoch 4, Batch 400] loss: 0.34746669679880143
[Epoch 4, Batch 500] loss: 0.3047712350450456
[Epoch 4, Batch 600] loss: 0.33784640496596696
[Epoch 4, Batch 700] loss: 0.3183351305127144
[Epoch 4, Batch 800] loss: 0.35983353696763515
[Epoch 4, Batch 900] loss: 0.34422431521117686
[Epoch 4, Batch 1000] loss: 0.3589181534200907
[Epoch 4, Batch 1100] loss: 0.3108556762337685
[Epoch 4, Batch 1200] loss: 0.30019054368138315
[Epoch 4, Batch 1300] loss: 0.3169365892745554
[Epoch 4, Batch 1400] loss: 0.3352666565030813
[Epoch 4, Batch 1500] loss: 0.31966233760118484
[Epoch 4, Batch 1600] loss: 0.3038301429897547
[Epoch 4, Batch 1700] loss: 0.2797702020034194
[Epoch 4, Batch 1800] loss: 0.27606629364192486
**STATS for Epoch 4** : 
Average training loss: 0.0131
Average validation loss: 0.2843
Validation Accuracy: 0.9173
Overfitting: 0.2712
Best model saved at epoch 4 with validation loss: 0.2843
[Epoch 5, Batch 100] loss: 0.2643290238082409
[Epoch 5, Batch 200] loss: 0.2915081845596433
[Epoch 5, Batch 300] loss: 0.3169202633202076
[Epoch 5, Batch 400] loss: 0.2748305109143257
[Epoch 5, Batch 500] loss: 0.2709673027135432
[Epoch 5, Batch 600] loss: 0.27379113567993046
[Epoch 5, Batch 700] loss: 0.2581482032313943
[Epoch 5, Batch 800] loss: 0.2549285163730383
[Epoch 5, Batch 900] loss: 0.2862965311482549
[Epoch 5, Batch 1000] loss: 0.2576821284741163
[Epoch 5, Batch 1100] loss: 0.2558729871362448
[Epoch 5, Batch 1200] loss: 0.2381293212622404
[Epoch 5, Batch 1300] loss: 0.27092789866030215
[Epoch 5, Batch 1400] loss: 0.23529567351564765
[Epoch 5, Batch 1500] loss: 0.24263558983802797
[Epoch 5, Batch 1600] loss: 0.23744259342551233
[Epoch 5, Batch 1700] loss: 0.2249691042304039
[Epoch 5, Batch 1800] loss: 0.24175670869648458
**STATS for Epoch 5** : 
Average training loss: 0.0086
Average validation loss: 0.2328
Validation Accuracy: 0.9325
Overfitting: 0.2242
Best model saved at epoch 5 with validation loss: 0.2328
[Epoch 6, Batch 100] loss: 0.23492964209988712
[Epoch 6, Batch 200] loss: 0.22021828003227711
[Epoch 6, Batch 300] loss: 0.2501064002513885
[Epoch 6, Batch 400] loss: 0.22170761669054628
[Epoch 6, Batch 500] loss: 0.23252935361117125
[Epoch 6, Batch 600] loss: 0.20738768111914396
[Epoch 6, Batch 700] loss: 0.20447414759546517
[Epoch 6, Batch 800] loss: 0.24312330672517418
[Epoch 6, Batch 900] loss: 0.21160807939246296
[Epoch 6, Batch 1000] loss: 0.22183223580941558
[Epoch 6, Batch 1100] loss: 0.23211582751013338
[Epoch 6, Batch 1200] loss: 0.20017830416560173
[Epoch 6, Batch 1300] loss: 0.19099712658673526
[Epoch 6, Batch 1400] loss: 0.19721392778679728
[Epoch 6, Batch 1500] loss: 0.19901610125787556
[Epoch 6, Batch 1600] loss: 0.21106037098914385
[Epoch 6, Batch 1700] loss: 0.22004519574344159
[Epoch 6, Batch 1800] loss: 0.2071779641881585
**STATS for Epoch 6** : 
Average training loss: 0.0081
Average validation loss: 0.2007
Validation Accuracy: 0.9404
Overfitting: 0.1926
Best model saved at epoch 6 with validation loss: 0.2007
[Epoch 7, Batch 100] loss: 0.20571675255894661
[Epoch 7, Batch 200] loss: 0.20113561185076834
[Epoch 7, Batch 300] loss: 0.208823823928833
[Epoch 7, Batch 400] loss: 0.20000324526801705
[Epoch 7, Batch 500] loss: 0.204141285372898
[Epoch 7, Batch 600] loss: 0.20322503462433816
[Epoch 7, Batch 700] loss: 0.17867892381735145
[Epoch 7, Batch 800] loss: 0.17768690176308155
[Epoch 7, Batch 900] loss: 0.18152775620110334
[Epoch 7, Batch 1000] loss: 0.17793632371351123
[Epoch 7, Batch 1100] loss: 0.18798401351086796
[Epoch 7, Batch 1200] loss: 0.18183889834210276
[Epoch 7, Batch 1300] loss: 0.19100478576496244
[Epoch 7, Batch 1400] loss: 0.1660014525707811
[Epoch 7, Batch 1500] loss: 0.15589166549034417
[Epoch 7, Batch 1600] loss: 0.14798624942079186
[Epoch 7, Batch 1700] loss: 0.22079191397875547
[Epoch 7, Batch 1800] loss: 0.16329769978299738
**STATS for Epoch 7** : 
Average training loss: 0.0081
Average validation loss: 0.1845
Validation Accuracy: 0.9443
Overfitting: 0.1764
Best model saved at epoch 7 with validation loss: 0.1845
[Epoch 8, Batch 100] loss: 0.19472511764615774
[Epoch 8, Batch 200] loss: 0.17079225738998502
[Epoch 8, Batch 300] loss: 0.15693592271767556
[Epoch 8, Batch 400] loss: 0.1532763576693833
[Epoch 8, Batch 500] loss: 0.17441146627999843
[Epoch 8, Batch 600] loss: 0.17272705148905515
[Epoch 8, Batch 700] loss: 0.18204188188537956
[Epoch 8, Batch 800] loss: 0.15741768853738905
[Epoch 8, Batch 900] loss: 0.1642798983398825
[Epoch 8, Batch 1000] loss: 0.1726718051545322
[Epoch 8, Batch 1100] loss: 0.16715177659876645
[Epoch 8, Batch 1200] loss: 0.1757464216137305
[Epoch 8, Batch 1300] loss: 0.15661845296621324
[Epoch 8, Batch 1400] loss: 0.14857897345907986
[Epoch 8, Batch 1500] loss: 0.1904603316448629
[Epoch 8, Batch 1600] loss: 0.16582597559317946
[Epoch 8, Batch 1700] loss: 0.14692556016147137
[Epoch 8, Batch 1800] loss: 0.13584805177524686
**STATS for Epoch 8** : 
Average training loss: 0.0048
Average validation loss: 0.1569
Validation Accuracy: 0.9529
Overfitting: 0.1521
Best model saved at epoch 8 with validation loss: 0.1569
[Epoch 9, Batch 100] loss: 0.14107425276655705
[Epoch 9, Batch 200] loss: 0.14128527736291288
[Epoch 9, Batch 300] loss: 0.16062329621054233
[Epoch 9, Batch 400] loss: 0.16738476789090784
[Epoch 9, Batch 500] loss: 0.13657352081499993
[Epoch 9, Batch 600] loss: 0.13051919550169258
[Epoch 9, Batch 700] loss: 0.14541570545174182
[Epoch 9, Batch 800] loss: 0.15248904179316014
[Epoch 9, Batch 900] loss: 0.13445499862544238
[Epoch 9, Batch 1000] loss: 0.16022568362765013
[Epoch 9, Batch 1100] loss: 0.14729781527537852
[Epoch 9, Batch 1200] loss: 0.14572379608871416
[Epoch 9, Batch 1300] loss: 0.14221802219748497
[Epoch 9, Batch 1400] loss: 0.15990027301944792
[Epoch 9, Batch 1500] loss: 0.12741061764769257
[Epoch 9, Batch 1600] loss: 0.14951221859548242
[Epoch 9, Batch 1700] loss: 0.14058390733785928
[Epoch 9, Batch 1800] loss: 0.16840056341141463
**STATS for Epoch 9** : 
Average training loss: 0.0056
Average validation loss: 0.1387
Validation Accuracy: 0.9585
Overfitting: 0.1331
Best model saved at epoch 9 with validation loss: 0.1387
[Epoch 10, Batch 100] loss: 0.12252194942906498
[Epoch 10, Batch 200] loss: 0.14278773894533514
[Epoch 10, Batch 300] loss: 0.1679861142113805
[Epoch 10, Batch 400] loss: 0.1527020173566416
[Epoch 10, Batch 500] loss: 0.12934427157044412
[Epoch 10, Batch 600] loss: 0.13902940676081926
[Epoch 10, Batch 700] loss: 0.14248303603380919
[Epoch 10, Batch 800] loss: 0.1329087388049811
[Epoch 10, Batch 900] loss: 0.13862443588208406
[Epoch 10, Batch 1000] loss: 0.13022388376295566
[Epoch 10, Batch 1100] loss: 0.11871526932576672
[Epoch 10, Batch 1200] loss: 0.12502975266892463
[Epoch 10, Batch 1300] loss: 0.10157024116721004
[Epoch 10, Batch 1400] loss: 0.1477159544778988
[Epoch 10, Batch 1500] loss: 0.13087040381971746
[Epoch 10, Batch 1600] loss: 0.12169640254694969
[Epoch 10, Batch 1700] loss: 0.12446409052936361
[Epoch 10, Batch 1800] loss: 0.14071082149632275
**STATS for Epoch 10** : 
Average training loss: 0.0048
Average validation loss: 0.1352
Validation Accuracy: 0.9602
Overfitting: 0.1304
Best model saved at epoch 10 with validation loss: 0.1352
[Epoch 11, Batch 100] loss: 0.12054701049113646
[Epoch 11, Batch 200] loss: 0.13849763729143888
[Epoch 11, Batch 300] loss: 0.10666434886632487
[Epoch 11, Batch 400] loss: 0.12207739770412446
[Epoch 11, Batch 500] loss: 0.14517282356042416
[Epoch 11, Batch 600] loss: 0.12565214610658587
[Epoch 11, Batch 700] loss: 0.1163037375966087
[Epoch 11, Batch 800] loss: 0.11597892172634601
[Epoch 11, Batch 900] loss: 0.11313593889120967
[Epoch 11, Batch 1000] loss: 0.1217624799720943
[Epoch 11, Batch 1100] loss: 0.10832700940780342
[Epoch 11, Batch 1200] loss: 0.1508987459493801
[Epoch 11, Batch 1300] loss: 0.1254452648712322
[Epoch 11, Batch 1400] loss: 0.13613440881017597
[Epoch 11, Batch 1500] loss: 0.10237184929661453
[Epoch 11, Batch 1600] loss: 0.12325580873526633
[Epoch 11, Batch 1700] loss: 0.09836474538780748
[Epoch 11, Batch 1800] loss: 0.1352811037749052
**STATS for Epoch 11** : 
Average training loss: 0.0050
Average validation loss: 0.1242
Validation Accuracy: 0.9622
Overfitting: 0.1191
Best model saved at epoch 11 with validation loss: 0.1242
[Epoch 12, Batch 100] loss: 0.10853780707810073
[Epoch 12, Batch 200] loss: 0.11078875805251301
[Epoch 12, Batch 300] loss: 0.1105354978190735
[Epoch 12, Batch 400] loss: 0.1412316525168717
[Epoch 12, Batch 500] loss: 0.09922878934070468
[Epoch 12, Batch 600] loss: 0.13987014403101056
[Epoch 12, Batch 700] loss: 0.10598257711390033
[Epoch 12, Batch 800] loss: 0.12972068377770485
[Epoch 12, Batch 900] loss: 0.11125084333121776
[Epoch 12, Batch 1000] loss: 0.1035568540962413
[Epoch 12, Batch 1100] loss: 0.0892255522031337
[Epoch 12, Batch 1200] loss: 0.11137956830440089
[Epoch 12, Batch 1300] loss: 0.11207562857773155
[Epoch 12, Batch 1400] loss: 0.11975145381409674
[Epoch 12, Batch 1500] loss: 0.1227377310488373
[Epoch 12, Batch 1600] loss: 0.11128063386538997
[Epoch 12, Batch 1700] loss: 0.116390566136688
[Epoch 12, Batch 1800] loss: 0.0817307033482939
**STATS for Epoch 12** : 
Average training loss: 0.0059
Average validation loss: 0.1222
Validation Accuracy: 0.9645
Overfitting: 0.1162
Best model saved at epoch 12 with validation loss: 0.1222
[Epoch 13, Batch 100] loss: 0.09450902205426245
[Epoch 13, Batch 200] loss: 0.097372056923341
[Epoch 13, Batch 300] loss: 0.11890080760000274
[Epoch 13, Batch 400] loss: 0.10576730112195946
[Epoch 13, Batch 500] loss: 0.09961026013363153
[Epoch 13, Batch 600] loss: 0.11271223012823611
[Epoch 13, Batch 700] loss: 0.11867630238179118
[Epoch 13, Batch 800] loss: 0.12187334643444046
[Epoch 13, Batch 900] loss: 0.10799083448946475
[Epoch 13, Batch 1000] loss: 0.10161902501480653
[Epoch 13, Batch 1100] loss: 0.11762657624669373
[Epoch 13, Batch 1200] loss: 0.08661508631426841
[Epoch 13, Batch 1300] loss: 0.11128398207598365
[Epoch 13, Batch 1400] loss: 0.10060956161934882
[Epoch 13, Batch 1500] loss: 0.09809166254475712
[Epoch 13, Batch 1600] loss: 0.11693124593002721
[Epoch 13, Batch 1700] loss: 0.10863327675731853
[Epoch 13, Batch 1800] loss: 0.09555370151880198
**STATS for Epoch 13** : 
Average training loss: 0.0045
Average validation loss: 0.1183
Validation Accuracy: 0.9637
Overfitting: 0.1138
Best model saved at epoch 13 with validation loss: 0.1183
[Epoch 14, Batch 100] loss: 0.11930037228390575
[Epoch 14, Batch 200] loss: 0.08258981047198176
[Epoch 14, Batch 300] loss: 0.10817468664958142
[Epoch 14, Batch 400] loss: 0.10625239957123994
[Epoch 14, Batch 500] loss: 0.1159179072023835
[Epoch 14, Batch 600] loss: 0.10010565013159066
[Epoch 14, Batch 700] loss: 0.08571972559206188
[Epoch 14, Batch 800] loss: 0.09457017603330314
[Epoch 14, Batch 900] loss: 0.1129536639410071
[Epoch 14, Batch 1000] loss: 0.09244177788496018
[Epoch 14, Batch 1100] loss: 0.11603453734423966
[Epoch 14, Batch 1200] loss: 0.08485840044450015
[Epoch 14, Batch 1300] loss: 0.1026646878104657
[Epoch 14, Batch 1400] loss: 0.0856007726630196
[Epoch 14, Batch 1500] loss: 0.09573581641539931
[Epoch 14, Batch 1600] loss: 0.08877234364394099
[Epoch 14, Batch 1700] loss: 0.09462209814344533
[Epoch 14, Batch 1800] loss: 0.11636742160655558
**STATS for Epoch 14** : 
Average training loss: 0.0037
Average validation loss: 0.1080
Validation Accuracy: 0.9669
Overfitting: 0.1043
Best model saved at epoch 14 with validation loss: 0.1080
[Epoch 15, Batch 100] loss: 0.10869640077464282
[Epoch 15, Batch 200] loss: 0.08237869604956359
[Epoch 15, Batch 300] loss: 0.1081868061888963
[Epoch 15, Batch 400] loss: 0.09379467183025554
[Epoch 15, Batch 500] loss: 0.08584326937794685
[Epoch 15, Batch 600] loss: 0.08077798242913559
[Epoch 15, Batch 700] loss: 0.09424586175242439
[Epoch 15, Batch 800] loss: 0.09537383157759904
[Epoch 15, Batch 900] loss: 0.09387369371950627
[Epoch 15, Batch 1000] loss: 0.11106143382843583
[Epoch 15, Batch 1100] loss: 0.09763833084376529
[Epoch 15, Batch 1200] loss: 0.10673568631173111
[Epoch 15, Batch 1300] loss: 0.08532349301269278
[Epoch 15, Batch 1400] loss: 0.08045131058432162
[Epoch 15, Batch 1500] loss: 0.10473908713785932
[Epoch 15, Batch 1600] loss: 0.1046765437303111
[Epoch 15, Batch 1700] loss: 0.09716556516475976
[Epoch 15, Batch 1800] loss: 0.08073522514197976
**STATS for Epoch 15** : 
Average training loss: 0.0037
Average validation loss: 0.1042
Validation Accuracy: 0.9684
Overfitting: 0.1006
Best model saved at epoch 15 with validation loss: 0.1042
[Epoch 16, Batch 100] loss: 0.09402898145373911
[Epoch 16, Batch 200] loss: 0.08581003789324314
[Epoch 16, Batch 300] loss: 0.08813307650387286
[Epoch 16, Batch 400] loss: 0.08710256670368835
[Epoch 16, Batch 500] loss: 0.09959803720703349
[Epoch 16, Batch 600] loss: 0.08567372236866504
[Epoch 16, Batch 700] loss: 0.08812088691396638
[Epoch 16, Batch 800] loss: 0.08037084821844473
[Epoch 16, Batch 900] loss: 0.06628840934252367
[Epoch 16, Batch 1000] loss: 0.06295183835318312
[Epoch 16, Batch 1100] loss: 0.08026519983774051
[Epoch 16, Batch 1200] loss: 0.09209136915276758
[Epoch 16, Batch 1300] loss: 0.0940878635062836
[Epoch 16, Batch 1400] loss: 0.11904914833372458
[Epoch 16, Batch 1500] loss: 0.10973440454341471
[Epoch 16, Batch 1600] loss: 0.10865106246434152
[Epoch 16, Batch 1700] loss: 0.07459512468427419
[Epoch 16, Batch 1800] loss: 0.09201767277438194
**STATS for Epoch 16** : 
Average training loss: 0.0039
Average validation loss: 0.1040
Validation Accuracy: 0.9689
Overfitting: 0.1001
Best model saved at epoch 16 with validation loss: 0.1040
[Epoch 17, Batch 100] loss: 0.09308032657951117
[Epoch 17, Batch 200] loss: 0.09102776939864271
[Epoch 17, Batch 300] loss: 0.08840640197042376
[Epoch 17, Batch 400] loss: 0.07500541824032553
[Epoch 17, Batch 500] loss: 0.07694567881291732
[Epoch 17, Batch 600] loss: 0.08766388870659285
[Epoch 17, Batch 700] loss: 0.11731076955329627
[Epoch 17, Batch 800] loss: 0.07536562121938914
[Epoch 17, Batch 900] loss: 0.08682702233782039
[Epoch 17, Batch 1000] loss: 0.07906287353020161
[Epoch 17, Batch 1100] loss: 0.08055479902541265
[Epoch 17, Batch 1200] loss: 0.06987753577646799
[Epoch 17, Batch 1300] loss: 0.10194384682341479
[Epoch 17, Batch 1400] loss: 0.08935586503706873
[Epoch 17, Batch 1500] loss: 0.08043529239832424
[Epoch 17, Batch 1600] loss: 0.0993076445790939
[Epoch 17, Batch 1700] loss: 0.0766845955804456
[Epoch 17, Batch 1800] loss: 0.0808041632734239
**STATS for Epoch 17** : 
Average training loss: 0.0033
Average validation loss: 0.0951
Validation Accuracy: 0.9709
Overfitting: 0.0918
Best model saved at epoch 17 with validation loss: 0.0951
[Epoch 18, Batch 100] loss: 0.08562600927078165
[Epoch 18, Batch 200] loss: 0.07692381283617579
[Epoch 18, Batch 300] loss: 0.08298073321930133
[Epoch 18, Batch 400] loss: 0.07620563530130312
[Epoch 18, Batch 500] loss: 0.09539426328847185
[Epoch 18, Batch 600] loss: 0.065930592820514
[Epoch 18, Batch 700] loss: 0.07539957952802069
[Epoch 18, Batch 800] loss: 0.08394495308864862
[Epoch 18, Batch 900] loss: 0.0883923762338236
[Epoch 18, Batch 1000] loss: 0.07732082802569494
[Epoch 18, Batch 1100] loss: 0.09443683438352309
[Epoch 18, Batch 1200] loss: 0.09569484373903833
[Epoch 18, Batch 1300] loss: 0.08109410808770917
[Epoch 18, Batch 1400] loss: 0.0862224763352424
[Epoch 18, Batch 1500] loss: 0.0937909329868853
[Epoch 18, Batch 1600] loss: 0.06888184503884986
[Epoch 18, Batch 1700] loss: 0.07062709778896532
[Epoch 18, Batch 1800] loss: 0.0780309344502166
**STATS for Epoch 18** : 
Average training loss: 0.0034
Average validation loss: 0.0913
Validation Accuracy: 0.9718
Overfitting: 0.0878
Best model saved at epoch 18 with validation loss: 0.0913
[Epoch 19, Batch 100] loss: 0.06777596900006756
[Epoch 19, Batch 200] loss: 0.08269851107848808
[Epoch 19, Batch 300] loss: 0.06942066226736643
[Epoch 19, Batch 400] loss: 0.08467355533037335
[Epoch 19, Batch 500] loss: 0.0731404684484005
[Epoch 19, Batch 600] loss: 0.0766562724718824
[Epoch 19, Batch 700] loss: 0.08633831888204441
[Epoch 19, Batch 800] loss: 0.0757246043079067
[Epoch 19, Batch 900] loss: 0.08925631235935726
[Epoch 19, Batch 1000] loss: 0.07845552870305256
[Epoch 19, Batch 1100] loss: 0.07851959491032176
[Epoch 19, Batch 1200] loss: 0.07279141020961105
[Epoch 19, Batch 1300] loss: 0.08175483285798692
[Epoch 19, Batch 1400] loss: 0.08838316080276855
[Epoch 19, Batch 1500] loss: 0.0746260804333724
[Epoch 19, Batch 1600] loss: 0.08295148148899897
[Epoch 19, Batch 1700] loss: 0.07597300493274815
[Epoch 19, Batch 1800] loss: 0.08021192009793594
**STATS for Epoch 19** : 
Average training loss: 0.0035
Average validation loss: 0.0899
Validation Accuracy: 0.9721
Overfitting: 0.0863
Best model saved at epoch 19 with validation loss: 0.0899
[Epoch 20, Batch 100] loss: 0.07617130367550999
[Epoch 20, Batch 200] loss: 0.06288755420828238
[Epoch 20, Batch 300] loss: 0.10403825397486799
[Epoch 20, Batch 400] loss: 0.06552998869563453
[Epoch 20, Batch 500] loss: 0.06777192823821679
[Epoch 20, Batch 600] loss: 0.07718445481383242
[Epoch 20, Batch 700] loss: 0.06382635735208168
[Epoch 20, Batch 800] loss: 0.056785696838051083
[Epoch 20, Batch 900] loss: 0.09892761240829713
[Epoch 20, Batch 1000] loss: 0.07830723277991637
[Epoch 20, Batch 1100] loss: 0.06772567250067368
[Epoch 20, Batch 1200] loss: 0.08386492403107695
[Epoch 20, Batch 1300] loss: 0.0831434349855408
[Epoch 20, Batch 1400] loss: 0.0808287954586558
[Epoch 20, Batch 1500] loss: 0.06570078175631351
[Epoch 20, Batch 1600] loss: 0.06326136491610669
[Epoch 20, Batch 1700] loss: 0.07634152035694569
[Epoch 20, Batch 1800] loss: 0.07596016621217132
**STATS for Epoch 20** : 
Average training loss: 0.0038
Average validation loss: 0.0949
Validation Accuracy: 0.9707
Overfitting: 0.0911
[Epoch 21, Batch 100] loss: 0.0826078295847401
[Epoch 21, Batch 200] loss: 0.06624026934849098
[Epoch 21, Batch 300] loss: 0.07419708813133184
[Epoch 21, Batch 400] loss: 0.05605719840852544
[Epoch 21, Batch 500] loss: 0.08087936558644288
[Epoch 21, Batch 600] loss: 0.06224316013278439
[Epoch 21, Batch 700] loss: 0.09503569105640054
[Epoch 21, Batch 800] loss: 0.08100823089713231
[Epoch 21, Batch 900] loss: 0.08548470318783075
[Epoch 21, Batch 1000] loss: 0.07415596356266178
[Epoch 21, Batch 1100] loss: 0.07550841151794885
[Epoch 21, Batch 1200] loss: 0.06170990730053745
[Epoch 21, Batch 1300] loss: 0.08136286366352578
[Epoch 21, Batch 1400] loss: 0.06437806004425511
[Epoch 21, Batch 1500] loss: 0.07187206751666964
[Epoch 21, Batch 1600] loss: 0.07653749943245203
[Epoch 21, Batch 1700] loss: 0.06071295287227258
[Epoch 21, Batch 1800] loss: 0.051451249239617025
**STATS for Epoch 21** : 
Average training loss: 0.0029
Average validation loss: 0.0822
Validation Accuracy: 0.9751
Overfitting: 0.0793
Best model saved at epoch 21 with validation loss: 0.0822
[Epoch 22, Batch 100] loss: 0.08306293774367077
[Epoch 22, Batch 200] loss: 0.07370334021688904
[Epoch 22, Batch 300] loss: 0.06167623789224308
[Epoch 22, Batch 400] loss: 0.07651338754687459
[Epoch 22, Batch 500] loss: 0.0706179629813414
[Epoch 22, Batch 600] loss: 0.05624342588125728
[Epoch 22, Batch 700] loss: 0.0808793535688892
[Epoch 22, Batch 800] loss: 0.06734804201056249
[Epoch 22, Batch 900] loss: 0.06703352148819249
[Epoch 22, Batch 1000] loss: 0.08161909114744048
[Epoch 22, Batch 1100] loss: 0.05233999371470418
[Epoch 22, Batch 1200] loss: 0.08921483228972647
[Epoch 22, Batch 1300] loss: 0.07801497275824659
[Epoch 22, Batch 1400] loss: 0.06811533688334748
[Epoch 22, Batch 1500] loss: 0.06206131946062669
[Epoch 22, Batch 1600] loss: 0.06624240271630696
[Epoch 22, Batch 1700] loss: 0.05904601225978695
[Epoch 22, Batch 1800] loss: 0.06281935745500959
**STATS for Epoch 22** : 
Average training loss: 0.0024
Average validation loss: 0.0828
Validation Accuracy: 0.9749
Overfitting: 0.0805
[Epoch 23, Batch 100] loss: 0.0598309384228196
[Epoch 23, Batch 200] loss: 0.08803497409331612
[Epoch 23, Batch 300] loss: 0.0592834834344103
[Epoch 23, Batch 400] loss: 0.05551550175645389
[Epoch 23, Batch 500] loss: 0.06339621621882544
[Epoch 23, Batch 600] loss: 0.06850554451928474
[Epoch 23, Batch 700] loss: 0.07267970433924348
[Epoch 23, Batch 800] loss: 0.07521779060480185
[Epoch 23, Batch 900] loss: 0.06244532757904381
[Epoch 23, Batch 1000] loss: 0.060128489963244644
[Epoch 23, Batch 1100] loss: 0.07055802557093557
[Epoch 23, Batch 1200] loss: 0.06536294708785136
[Epoch 23, Batch 1300] loss: 0.052498569241724906
[Epoch 23, Batch 1400] loss: 0.08295424970856402
[Epoch 23, Batch 1500] loss: 0.0592720331880264
[Epoch 23, Batch 1600] loss: 0.07138646020786837
[Epoch 23, Batch 1700] loss: 0.05810456380946562
[Epoch 23, Batch 1800] loss: 0.07590850571636111
**STATS for Epoch 23** : 
Average training loss: 0.0026
Average validation loss: 0.0852
Validation Accuracy: 0.9743
Overfitting: 0.0826
[Epoch 24, Batch 100] loss: 0.08410119828797179
[Epoch 24, Batch 200] loss: 0.06193394614791032
[Epoch 24, Batch 300] loss: 0.06337026940775103
[Epoch 24, Batch 400] loss: 0.05151822520885616
[Epoch 24, Batch 500] loss: 0.054820276924874636
[Epoch 24, Batch 600] loss: 0.057590365044306965
[Epoch 24, Batch 700] loss: 0.052296315128915014
[Epoch 24, Batch 800] loss: 0.0570593752048444
[Epoch 24, Batch 900] loss: 0.06874169594375416
[Epoch 24, Batch 1000] loss: 0.04976683840854093
[Epoch 24, Batch 1100] loss: 0.07027943012537435
[Epoch 24, Batch 1200] loss: 0.059654965638765135
[Epoch 24, Batch 1300] loss: 0.074505872662412
[Epoch 24, Batch 1400] loss: 0.0612863918102812
[Epoch 24, Batch 1500] loss: 0.07402862464019563
[Epoch 24, Batch 1600] loss: 0.07481438890798017
[Epoch 24, Batch 1700] loss: 0.0690708090912085
[Epoch 24, Batch 1800] loss: 0.06227348921704106
**STATS for Epoch 24** : 
Average training loss: 0.0025
Average validation loss: 0.0774
Validation Accuracy: 0.9760
Overfitting: 0.0750
Best model saved at epoch 24 with validation loss: 0.0774
Fold 1 validation loss: 0.0774
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.301081395149231
[Epoch 1, Batch 200] loss: 2.3013360285758973
[Epoch 1, Batch 300] loss: 2.2979914474487306
[Epoch 1, Batch 400] loss: 2.296776149272919
[Epoch 1, Batch 500] loss: 2.293541030883789
[Epoch 1, Batch 600] loss: 2.2916916513442995
[Epoch 1, Batch 700] loss: 2.291037743091583
[Epoch 1, Batch 800] loss: 2.286930251121521
[Epoch 1, Batch 900] loss: 2.2834693241119384
[Epoch 1, Batch 1000] loss: 2.2822748255729675
[Epoch 1, Batch 1100] loss: 2.279162814617157
[Epoch 1, Batch 1200] loss: 2.2749064326286317
[Epoch 1, Batch 1300] loss: 2.270667233467102
[Epoch 1, Batch 1400] loss: 2.2645924639701844
[Epoch 1, Batch 1500] loss: 2.260933148860931
[Epoch 1, Batch 1600] loss: 2.2553881192207337
[Epoch 1, Batch 1700] loss: 2.2461462116241453
[Epoch 1, Batch 1800] loss: 2.2381498289108275
**STATS for Epoch 1** : 
Average training loss: 0.0891
Average validation loss: 2.2236
Validation Accuracy: 0.4486
Overfitting: 2.1345
Best model saved at epoch 1 with validation loss: 2.2236
[Epoch 2, Batch 100] loss: 2.2146280002593994
[Epoch 2, Batch 200] loss: 2.19989084482193
[Epoch 2, Batch 300] loss: 2.179150276184082
[Epoch 2, Batch 400] loss: 2.1560174894332884
[Epoch 2, Batch 500] loss: 2.1268871235847473
[Epoch 2, Batch 600] loss: 2.0837991070747375
[Epoch 2, Batch 700] loss: 2.0217566657066346
[Epoch 2, Batch 800] loss: 1.9421183466911316
[Epoch 2, Batch 900] loss: 1.8389241659641267
[Epoch 2, Batch 1000] loss: 1.702807070016861
[Epoch 2, Batch 1100] loss: 1.5628157591819762
[Epoch 2, Batch 1200] loss: 1.4064462298154832
[Epoch 2, Batch 1300] loss: 1.2174053746461868
[Epoch 2, Batch 1400] loss: 1.0669673472642898
[Epoch 2, Batch 1500] loss: 0.9516244775056839
[Epoch 2, Batch 1600] loss: 0.8715745258331299
[Epoch 2, Batch 1700] loss: 0.7829509767889976
[Epoch 2, Batch 1800] loss: 0.703862262070179
**STATS for Epoch 2** : 
Average training loss: 0.0245
Average validation loss: 0.6835
Validation Accuracy: 0.7818
Overfitting: 0.6590
Best model saved at epoch 2 with validation loss: 0.6835
[Epoch 3, Batch 100] loss: 0.6586479529738426
[Epoch 3, Batch 200] loss: 0.583616336286068
[Epoch 3, Batch 300] loss: 0.6283307030797005
[Epoch 3, Batch 400] loss: 0.5534267464280128
[Epoch 3, Batch 500] loss: 0.5297956232726574
[Epoch 3, Batch 600] loss: 0.5554484052956105
[Epoch 3, Batch 700] loss: 0.49932223573327067
[Epoch 3, Batch 800] loss: 0.5370372568070888
[Epoch 3, Batch 900] loss: 0.4928257999569178
[Epoch 3, Batch 1000] loss: 0.5103418403863906
[Epoch 3, Batch 1100] loss: 0.4859619806706905
[Epoch 3, Batch 1200] loss: 0.4863290560245514
[Epoch 3, Batch 1300] loss: 0.4275410771369934
[Epoch 3, Batch 1400] loss: 0.43148406751453877
[Epoch 3, Batch 1500] loss: 0.4517145304381847
[Epoch 3, Batch 1600] loss: 0.4561767477542162
[Epoch 3, Batch 1700] loss: 0.4392363270372152
[Epoch 3, Batch 1800] loss: 0.41317987322807315
**STATS for Epoch 3** : 
Average training loss: 0.0167
Average validation loss: 0.4160
Validation Accuracy: 0.8763
Overfitting: 0.3993
Best model saved at epoch 3 with validation loss: 0.4160
[Epoch 4, Batch 100] loss: 0.42854690294712783
[Epoch 4, Batch 200] loss: 0.39630131125450135
[Epoch 4, Batch 300] loss: 0.38139602676033973
[Epoch 4, Batch 400] loss: 0.39180261999368665
[Epoch 4, Batch 500] loss: 0.3959751281514764
[Epoch 4, Batch 600] loss: 0.37017175540328023
[Epoch 4, Batch 700] loss: 0.40341244384646413
[Epoch 4, Batch 800] loss: 0.36519547119736673
[Epoch 4, Batch 900] loss: 0.36161544803529977
[Epoch 4, Batch 1000] loss: 0.34254571299999953
[Epoch 4, Batch 1100] loss: 0.3551108767837286
[Epoch 4, Batch 1200] loss: 0.3313408243283629
[Epoch 4, Batch 1300] loss: 0.3474639219790697
[Epoch 4, Batch 1400] loss: 0.3138174634054303
[Epoch 4, Batch 1500] loss: 0.3297377375513315
[Epoch 4, Batch 1600] loss: 0.31920566644519566
[Epoch 4, Batch 1700] loss: 0.3074462235346436
[Epoch 4, Batch 1800] loss: 0.3312701477110386
**STATS for Epoch 4** : 
Average training loss: 0.0129
Average validation loss: 0.3191
Validation Accuracy: 0.9038
Overfitting: 0.3062
Best model saved at epoch 4 with validation loss: 0.3191
[Epoch 5, Batch 100] loss: 0.30456198774278165
[Epoch 5, Batch 200] loss: 0.3154395094513893
[Epoch 5, Batch 300] loss: 0.31736528750509024
[Epoch 5, Batch 400] loss: 0.2659425692632794
[Epoch 5, Batch 500] loss: 0.30066456910222766
[Epoch 5, Batch 600] loss: 0.29723448999226093
[Epoch 5, Batch 700] loss: 0.2734912179037929
[Epoch 5, Batch 800] loss: 0.29187612503767013
[Epoch 5, Batch 900] loss: 0.2588774510100484
[Epoch 5, Batch 1000] loss: 0.3064877681061626
[Epoch 5, Batch 1100] loss: 0.28439760226756333
[Epoch 5, Batch 1200] loss: 0.3017404306679964
[Epoch 5, Batch 1300] loss: 0.25690445471554996
[Epoch 5, Batch 1400] loss: 0.2803594083338976
[Epoch 5, Batch 1500] loss: 0.27142659448087214
[Epoch 5, Batch 1600] loss: 0.2955773961544037
[Epoch 5, Batch 1700] loss: 0.2656953821890056
[Epoch 5, Batch 1800] loss: 0.2666124807484448
**STATS for Epoch 5** : 
Average training loss: 0.0089
Average validation loss: 0.2662
Validation Accuracy: 0.9203
Overfitting: 0.2572
Best model saved at epoch 5 with validation loss: 0.2662
[Epoch 6, Batch 100] loss: 0.27379055332392455
[Epoch 6, Batch 200] loss: 0.2660806827247143
[Epoch 6, Batch 300] loss: 0.26336706332862375
[Epoch 6, Batch 400] loss: 0.22606230933219196
[Epoch 6, Batch 500] loss: 0.2655328080430627
[Epoch 6, Batch 600] loss: 0.2541269525606185
[Epoch 6, Batch 700] loss: 0.24054618015885354
[Epoch 6, Batch 800] loss: 0.20907709997147322
[Epoch 6, Batch 900] loss: 0.23442327607423066
[Epoch 6, Batch 1000] loss: 0.25454038171097637
[Epoch 6, Batch 1100] loss: 0.24447570268064736
[Epoch 6, Batch 1200] loss: 0.24204125298187137
[Epoch 6, Batch 1300] loss: 0.23959350802004337
[Epoch 6, Batch 1400] loss: 0.22297454629093408
[Epoch 6, Batch 1500] loss: 0.21456360064446925
[Epoch 6, Batch 1600] loss: 0.22001298860646784
[Epoch 6, Batch 1700] loss: 0.17882249012589455
[Epoch 6, Batch 1800] loss: 0.23042958175763487
**STATS for Epoch 6** : 
Average training loss: 0.0080
Average validation loss: 0.2248
Validation Accuracy: 0.9333
Overfitting: 0.2169
Best model saved at epoch 6 with validation loss: 0.2248
[Epoch 7, Batch 100] loss: 0.21672468606382608
[Epoch 7, Batch 200] loss: 0.22136214898899198
[Epoch 7, Batch 300] loss: 0.23832429207861425
[Epoch 7, Batch 400] loss: 0.21000578247010707
[Epoch 7, Batch 500] loss: 0.21687538161873818
[Epoch 7, Batch 600] loss: 0.21788616256788373
[Epoch 7, Batch 700] loss: 0.1863923084922135
[Epoch 7, Batch 800] loss: 0.18711475951597095
[Epoch 7, Batch 900] loss: 0.20560763912275434
[Epoch 7, Batch 1000] loss: 0.21709507839754225
[Epoch 7, Batch 1100] loss: 0.20027908079326154
[Epoch 7, Batch 1200] loss: 0.19528892673086376
[Epoch 7, Batch 1300] loss: 0.2009250712580979
[Epoch 7, Batch 1400] loss: 0.1674440973997116
[Epoch 7, Batch 1500] loss: 0.16742141166701913
[Epoch 7, Batch 1600] loss: 0.19423925258219243
[Epoch 7, Batch 1700] loss: 0.194150528954342
[Epoch 7, Batch 1800] loss: 0.18073695354163646
**STATS for Epoch 7** : 
Average training loss: 0.0083
Average validation loss: 0.1930
Validation Accuracy: 0.9423
Overfitting: 0.1847
Best model saved at epoch 7 with validation loss: 0.1930
[Epoch 8, Batch 100] loss: 0.1853327632881701
[Epoch 8, Batch 200] loss: 0.17803363139741124
[Epoch 8, Batch 300] loss: 0.17687456599436702
[Epoch 8, Batch 400] loss: 0.17799186517484486
[Epoch 8, Batch 500] loss: 0.19451332013122738
[Epoch 8, Batch 600] loss: 0.18048002345487477
[Epoch 8, Batch 700] loss: 0.15971520665101707
[Epoch 8, Batch 800] loss: 0.1541702617285773
[Epoch 8, Batch 900] loss: 0.17294027414172888
[Epoch 8, Batch 1000] loss: 0.1885929014906287
[Epoch 8, Batch 1100] loss: 0.164005235331133
[Epoch 8, Batch 1200] loss: 0.1904115584725514
[Epoch 8, Batch 1300] loss: 0.16580995673313736
[Epoch 8, Batch 1400] loss: 0.18012915299739687
[Epoch 8, Batch 1500] loss: 0.17085780575871468
[Epoch 8, Batch 1600] loss: 0.16951112736947835
[Epoch 8, Batch 1700] loss: 0.17259603682905436
[Epoch 8, Batch 1800] loss: 0.20306574092246593
**STATS for Epoch 8** : 
Average training loss: 0.0066
Average validation loss: 0.1832
Validation Accuracy: 0.9433
Overfitting: 0.1766
Best model saved at epoch 8 with validation loss: 0.1832
[Epoch 9, Batch 100] loss: 0.1729079055134207
[Epoch 9, Batch 200] loss: 0.1688559788186103
[Epoch 9, Batch 300] loss: 0.15767897255718707
[Epoch 9, Batch 400] loss: 0.1538022248726338
[Epoch 9, Batch 500] loss: 0.15545771688222884
[Epoch 9, Batch 600] loss: 0.13700890459120274
[Epoch 9, Batch 700] loss: 0.1576277246233076
[Epoch 9, Batch 800] loss: 0.16210924089886247
[Epoch 9, Batch 900] loss: 0.17026602433994412
[Epoch 9, Batch 1000] loss: 0.1497655209992081
[Epoch 9, Batch 1100] loss: 0.1477417213190347
[Epoch 9, Batch 1200] loss: 0.1556129658780992
[Epoch 9, Batch 1300] loss: 0.17755326324142515
[Epoch 9, Batch 1400] loss: 0.16631527512334288
[Epoch 9, Batch 1500] loss: 0.15429717175662516
[Epoch 9, Batch 1600] loss: 0.15781655767001213
[Epoch 9, Batch 1700] loss: 0.15280417019501327
[Epoch 9, Batch 1800] loss: 0.13472998730838298
**STATS for Epoch 9** : 
Average training loss: 0.0055
Average validation loss: 0.1643
Validation Accuracy: 0.9512
Overfitting: 0.1587
Best model saved at epoch 9 with validation loss: 0.1643
[Epoch 10, Batch 100] loss: 0.1401636956539005
[Epoch 10, Batch 200] loss: 0.1749217204283923
[Epoch 10, Batch 300] loss: 0.15080758079886436
[Epoch 10, Batch 400] loss: 0.16311677019111812
[Epoch 10, Batch 500] loss: 0.15044255937449635
[Epoch 10, Batch 600] loss: 0.16041664017364382
[Epoch 10, Batch 700] loss: 0.13888733011204749
[Epoch 10, Batch 800] loss: 0.1508466098085046
[Epoch 10, Batch 900] loss: 0.12575060710310937
[Epoch 10, Batch 1000] loss: 0.1278262076806277
[Epoch 10, Batch 1100] loss: 0.14488099521026016
[Epoch 10, Batch 1200] loss: 0.14785707048606128
[Epoch 10, Batch 1300] loss: 0.14228341078385712
[Epoch 10, Batch 1400] loss: 0.14087379563134164
[Epoch 10, Batch 1500] loss: 0.13222793301567434
[Epoch 10, Batch 1600] loss: 0.11735605573281646
[Epoch 10, Batch 1700] loss: 0.1274680340010673
[Epoch 10, Batch 1800] loss: 0.13260298194363712
**STATS for Epoch 10** : 
Average training loss: 0.0051
Average validation loss: 0.1449
Validation Accuracy: 0.9574
Overfitting: 0.1397
Best model saved at epoch 10 with validation loss: 0.1449
[Epoch 11, Batch 100] loss: 0.1405923425545916
[Epoch 11, Batch 200] loss: 0.126731650903821
[Epoch 11, Batch 300] loss: 0.15429439621511848
[Epoch 11, Batch 400] loss: 0.1407848228700459
[Epoch 11, Batch 500] loss: 0.15249943424249068
[Epoch 11, Batch 600] loss: 0.14812045740894975
[Epoch 11, Batch 700] loss: 0.13384660303127022
[Epoch 11, Batch 800] loss: 0.11156624146737158
[Epoch 11, Batch 900] loss: 0.12757965945638716
[Epoch 11, Batch 1000] loss: 0.10744751361198723
[Epoch 11, Batch 1100] loss: 0.13634287517517804
[Epoch 11, Batch 1200] loss: 0.12933049620129167
[Epoch 11, Batch 1300] loss: 0.1201151220407337
[Epoch 11, Batch 1400] loss: 0.13205293278675526
[Epoch 11, Batch 1500] loss: 0.11411861097440124
[Epoch 11, Batch 1600] loss: 0.11767335036303848
[Epoch 11, Batch 1700] loss: 0.1047188484040089
[Epoch 11, Batch 1800] loss: 0.13176609529647976
**STATS for Epoch 11** : 
Average training loss: 0.0051
Average validation loss: 0.1365
Validation Accuracy: 0.9591
Overfitting: 0.1315
Best model saved at epoch 11 with validation loss: 0.1365
[Epoch 12, Batch 100] loss: 0.11075110540725291
[Epoch 12, Batch 200] loss: 0.12689561801729723
[Epoch 12, Batch 300] loss: 0.12088849634863436
[Epoch 12, Batch 400] loss: 0.09781859731301665
[Epoch 12, Batch 500] loss: 0.12751972356811167
[Epoch 12, Batch 600] loss: 0.13918460716027767
[Epoch 12, Batch 700] loss: 0.10894372329115867
[Epoch 12, Batch 800] loss: 0.148153741620481
[Epoch 12, Batch 900] loss: 0.12943846092559397
[Epoch 12, Batch 1000] loss: 0.124399731811136
[Epoch 12, Batch 1100] loss: 0.11481626345776022
[Epoch 12, Batch 1200] loss: 0.1053912946442142
[Epoch 12, Batch 1300] loss: 0.1105727247800678
[Epoch 12, Batch 1400] loss: 0.12153698527254164
[Epoch 12, Batch 1500] loss: 0.1129565328778699
[Epoch 12, Batch 1600] loss: 0.11862573785707355
[Epoch 12, Batch 1700] loss: 0.12129248742479831
[Epoch 12, Batch 1800] loss: 0.11672687171259895
**STATS for Epoch 12** : 
Average training loss: 0.0039
Average validation loss: 0.1267
Validation Accuracy: 0.9611
Overfitting: 0.1228
Best model saved at epoch 12 with validation loss: 0.1267
[Epoch 13, Batch 100] loss: 0.09909055179450661
[Epoch 13, Batch 200] loss: 0.1095731911296025
[Epoch 13, Batch 300] loss: 0.11216687491629272
[Epoch 13, Batch 400] loss: 0.09005547657608987
[Epoch 13, Batch 500] loss: 0.09357105419272557
[Epoch 13, Batch 600] loss: 0.12411478190217168
[Epoch 13, Batch 700] loss: 0.1046651340345852
[Epoch 13, Batch 800] loss: 0.10704042253550142
[Epoch 13, Batch 900] loss: 0.13462559146573766
[Epoch 13, Batch 1000] loss: 0.1068891748553142
[Epoch 13, Batch 1100] loss: 0.11193325841333718
[Epoch 13, Batch 1200] loss: 0.10852811915567145
[Epoch 13, Batch 1300] loss: 0.11708854915574193
[Epoch 13, Batch 1400] loss: 0.10855983899906278
[Epoch 13, Batch 1500] loss: 0.1101223602052778
[Epoch 13, Batch 1600] loss: 0.11419528198428452
[Epoch 13, Batch 1700] loss: 0.10467635605949908
[Epoch 13, Batch 1800] loss: 0.12179523210972548
**STATS for Epoch 13** : 
Average training loss: 0.0053
Average validation loss: 0.1199
Validation Accuracy: 0.9649
Overfitting: 0.1145
Best model saved at epoch 13 with validation loss: 0.1199
[Epoch 14, Batch 100] loss: 0.11321592630818486
[Epoch 14, Batch 200] loss: 0.09791456463281065
[Epoch 14, Batch 300] loss: 0.11441827160073444
[Epoch 14, Batch 400] loss: 0.1157828129408881
[Epoch 14, Batch 500] loss: 0.10025226487312466
[Epoch 14, Batch 600] loss: 0.09875907827634364
[Epoch 14, Batch 700] loss: 0.11456549724098294
[Epoch 14, Batch 800] loss: 0.10340979608707129
[Epoch 14, Batch 900] loss: 0.08781253057532012
[Epoch 14, Batch 1000] loss: 0.09238433014135808
[Epoch 14, Batch 1100] loss: 0.11356149743776768
[Epoch 14, Batch 1200] loss: 0.11093982201535255
[Epoch 14, Batch 1300] loss: 0.12780582274775953
[Epoch 14, Batch 1400] loss: 0.09692937291227281
[Epoch 14, Batch 1500] loss: 0.09404228054219857
[Epoch 14, Batch 1600] loss: 0.08434561298694461
[Epoch 14, Batch 1700] loss: 0.106793231992051
[Epoch 14, Batch 1800] loss: 0.09586347540840506
**STATS for Epoch 14** : 
Average training loss: 0.0044
Average validation loss: 0.1157
Validation Accuracy: 0.9649
Overfitting: 0.1112
Best model saved at epoch 14 with validation loss: 0.1157
[Epoch 15, Batch 100] loss: 0.08256731512024999
[Epoch 15, Batch 200] loss: 0.0769435595755931
[Epoch 15, Batch 300] loss: 0.11448669450473972
[Epoch 15, Batch 400] loss: 0.10265979325398802
[Epoch 15, Batch 500] loss: 0.11009197881445289
[Epoch 15, Batch 600] loss: 0.10017876263475045
[Epoch 15, Batch 700] loss: 0.09295323493890464
[Epoch 15, Batch 800] loss: 0.10702138215769082
[Epoch 15, Batch 900] loss: 0.0840695575857535
[Epoch 15, Batch 1000] loss: 0.0878424797509797
[Epoch 15, Batch 1100] loss: 0.10540478146867827
[Epoch 15, Batch 1200] loss: 0.10570810622884892
[Epoch 15, Batch 1300] loss: 0.08325991053716279
[Epoch 15, Batch 1400] loss: 0.10758655724697747
[Epoch 15, Batch 1500] loss: 0.12524768961477092
[Epoch 15, Batch 1600] loss: 0.08422790896613151
[Epoch 15, Batch 1700] loss: 0.09661238132510334
[Epoch 15, Batch 1800] loss: 0.07873970019631088
**STATS for Epoch 15** : 
Average training loss: 0.0036
Average validation loss: 0.1074
Validation Accuracy: 0.9681
Overfitting: 0.1038
Best model saved at epoch 15 with validation loss: 0.1074
[Epoch 16, Batch 100] loss: 0.07973457716638223
[Epoch 16, Batch 200] loss: 0.1070425477065146
[Epoch 16, Batch 300] loss: 0.10296024003997445
[Epoch 16, Batch 400] loss: 0.1092811324703507
[Epoch 16, Batch 500] loss: 0.07120808808598668
[Epoch 16, Batch 600] loss: 0.09447326987283304
[Epoch 16, Batch 700] loss: 0.07499727293150499
[Epoch 16, Batch 800] loss: 0.09080042978748679
[Epoch 16, Batch 900] loss: 0.08627076415810735
[Epoch 16, Batch 1000] loss: 0.07110501471208408
[Epoch 16, Batch 1100] loss: 0.09463187767192721
[Epoch 16, Batch 1200] loss: 0.10283524684607982
[Epoch 16, Batch 1300] loss: 0.08889864927623421
[Epoch 16, Batch 1400] loss: 0.1034841419069562
[Epoch 16, Batch 1500] loss: 0.09703152525471523
[Epoch 16, Batch 1600] loss: 0.08672317053657025
[Epoch 16, Batch 1700] loss: 0.09745475827949121
[Epoch 16, Batch 1800] loss: 0.08782381906872615
**STATS for Epoch 16** : 
Average training loss: 0.0035
Average validation loss: 0.1041
Validation Accuracy: 0.9694
Overfitting: 0.1006
Best model saved at epoch 16 with validation loss: 0.1041
[Epoch 17, Batch 100] loss: 0.0971770882466808
[Epoch 17, Batch 200] loss: 0.07762611617101356
[Epoch 17, Batch 300] loss: 0.06562965143355541
[Epoch 17, Batch 400] loss: 0.0937028427910991
[Epoch 17, Batch 500] loss: 0.09955087054986507
[Epoch 17, Batch 600] loss: 0.09256811496801674
[Epoch 17, Batch 700] loss: 0.11594460646156221
[Epoch 17, Batch 800] loss: 0.09303934837924316
[Epoch 17, Batch 900] loss: 0.0805877574312035
[Epoch 17, Batch 1000] loss: 0.09845778868533671
[Epoch 17, Batch 1100] loss: 0.06442070824094116
[Epoch 17, Batch 1200] loss: 0.0927016465831548
[Epoch 17, Batch 1300] loss: 0.10119173451093957
[Epoch 17, Batch 1400] loss: 0.07242576173739508
[Epoch 17, Batch 1500] loss: 0.0812474474683404
[Epoch 17, Batch 1600] loss: 0.0723127130419016
[Epoch 17, Batch 1700] loss: 0.08516294351778925
[Epoch 17, Batch 1800] loss: 0.08181631593499333
**STATS for Epoch 17** : 
Average training loss: 0.0030
Average validation loss: 0.1007
Validation Accuracy: 0.9686
Overfitting: 0.0978
Best model saved at epoch 17 with validation loss: 0.1007
[Epoch 18, Batch 100] loss: 0.07570238372078165
[Epoch 18, Batch 200] loss: 0.08002202915027738
[Epoch 18, Batch 300] loss: 0.08886166793876328
[Epoch 18, Batch 400] loss: 0.08282783586881123
[Epoch 18, Batch 500] loss: 0.06836905365344137
[Epoch 18, Batch 600] loss: 0.07474914371268823
[Epoch 18, Batch 700] loss: 0.07395882021868601
[Epoch 18, Batch 800] loss: 0.09326061478117481
[Epoch 18, Batch 900] loss: 0.08191088417428545
[Epoch 18, Batch 1000] loss: 0.07058928543119691
[Epoch 18, Batch 1100] loss: 0.07538042051717639
[Epoch 18, Batch 1200] loss: 0.08494014431722462
[Epoch 18, Batch 1300] loss: 0.0722994768084027
[Epoch 18, Batch 1400] loss: 0.0769309757166775
[Epoch 18, Batch 1500] loss: 0.09288323102518917
[Epoch 18, Batch 1600] loss: 0.0963627729692962
[Epoch 18, Batch 1700] loss: 0.08910300374729559
[Epoch 18, Batch 1800] loss: 0.0855185461556539
**STATS for Epoch 18** : 
Average training loss: 0.0035
Average validation loss: 0.0973
Validation Accuracy: 0.9712
Overfitting: 0.0938
Best model saved at epoch 18 with validation loss: 0.0973
[Epoch 19, Batch 100] loss: 0.06639493512455374
[Epoch 19, Batch 200] loss: 0.07314966179896146
[Epoch 19, Batch 300] loss: 0.09461971170268953
[Epoch 19, Batch 400] loss: 0.0786258284910582
[Epoch 19, Batch 500] loss: 0.06726574722095392
[Epoch 19, Batch 600] loss: 0.07123947659216355
[Epoch 19, Batch 700] loss: 0.08477889372734353
[Epoch 19, Batch 800] loss: 0.07721701961476356
[Epoch 19, Batch 900] loss: 0.08990724574308842
[Epoch 19, Batch 1000] loss: 0.07899482421285939
[Epoch 19, Batch 1100] loss: 0.07685862353537232
[Epoch 19, Batch 1200] loss: 0.09193881350103766
[Epoch 19, Batch 1300] loss: 0.05754938581958413
[Epoch 19, Batch 1400] loss: 0.08136608881992288
[Epoch 19, Batch 1500] loss: 0.07788038473343477
[Epoch 19, Batch 1600] loss: 0.07950721152825281
[Epoch 19, Batch 1700] loss: 0.07652534632477909
[Epoch 19, Batch 1800] loss: 0.07615300546400249
**STATS for Epoch 19** : 
Average training loss: 0.0033
Average validation loss: 0.1009
Validation Accuracy: 0.9691
Overfitting: 0.0976
[Epoch 20, Batch 100] loss: 0.09534793943865225
[Epoch 20, Batch 200] loss: 0.0821714995673392
[Epoch 20, Batch 300] loss: 0.06797567903297022
[Epoch 20, Batch 400] loss: 0.07721345758647657
[Epoch 20, Batch 500] loss: 0.0707904867688194
[Epoch 20, Batch 600] loss: 0.07971264608204365
[Epoch 20, Batch 700] loss: 0.04773168490035459
[Epoch 20, Batch 800] loss: 0.087691639396362
[Epoch 20, Batch 900] loss: 0.07810486287227832
[Epoch 20, Batch 1000] loss: 0.07382050486921798
[Epoch 20, Batch 1100] loss: 0.07293491978663952
[Epoch 20, Batch 1200] loss: 0.07072690898086875
[Epoch 20, Batch 1300] loss: 0.06965093799866735
[Epoch 20, Batch 1400] loss: 0.06589019043953158
[Epoch 20, Batch 1500] loss: 0.08876242806436493
[Epoch 20, Batch 1600] loss: 0.059120798620861024
[Epoch 20, Batch 1700] loss: 0.07054274628404528
[Epoch 20, Batch 1800] loss: 0.09037357577006333
**STATS for Epoch 20** : 
Average training loss: 0.0029
Average validation loss: 0.0878
Validation Accuracy: 0.9732
Overfitting: 0.0849
Best model saved at epoch 20 with validation loss: 0.0878
[Epoch 21, Batch 100] loss: 0.06770186011097394
[Epoch 21, Batch 200] loss: 0.07385138924233615
[Epoch 21, Batch 300] loss: 0.05387622258800548
[Epoch 21, Batch 400] loss: 0.0709609722730238
[Epoch 21, Batch 500] loss: 0.05904369535273872
[Epoch 21, Batch 600] loss: 0.0733037679363042
[Epoch 21, Batch 700] loss: 0.06002303196815774
[Epoch 21, Batch 800] loss: 0.06662636266089976
[Epoch 21, Batch 900] loss: 0.07475544351967983
[Epoch 21, Batch 1000] loss: 0.06217035367153585
[Epoch 21, Batch 1100] loss: 0.07952023539924995
[Epoch 21, Batch 1200] loss: 0.07041357595589944
[Epoch 21, Batch 1300] loss: 0.07939585173560772
[Epoch 21, Batch 1400] loss: 0.06911868215946015
[Epoch 21, Batch 1500] loss: 0.0677087180223316
[Epoch 21, Batch 1600] loss: 0.07084140587598085
[Epoch 21, Batch 1700] loss: 0.09254762487486005
[Epoch 21, Batch 1800] loss: 0.08194978158688172
**STATS for Epoch 21** : 
Average training loss: 0.0028
Average validation loss: 0.0886
Validation Accuracy: 0.9739
Overfitting: 0.0858
[Epoch 22, Batch 100] loss: 0.07337326469831168
[Epoch 22, Batch 200] loss: 0.06276790278847329
[Epoch 22, Batch 300] loss: 0.06685649455757811
[Epoch 22, Batch 400] loss: 0.08210442709969357
[Epoch 22, Batch 500] loss: 0.06771384012885391
[Epoch 22, Batch 600] loss: 0.07489122186554596
[Epoch 22, Batch 700] loss: 0.062336909759324044
[Epoch 22, Batch 800] loss: 0.056644549214979634
[Epoch 22, Batch 900] loss: 0.06871802082867362
[Epoch 22, Batch 1000] loss: 0.0522692070924677
[Epoch 22, Batch 1100] loss: 0.08182367532746866
[Epoch 22, Batch 1200] loss: 0.06847802084987052
[Epoch 22, Batch 1300] loss: 0.0688428196113091
[Epoch 22, Batch 1400] loss: 0.08141888780752198
[Epoch 22, Batch 1500] loss: 0.06746457019704394
[Epoch 22, Batch 1600] loss: 0.0738001263816841
[Epoch 22, Batch 1700] loss: 0.0736286256252788
[Epoch 22, Batch 1800] loss: 0.05987821697373875
**STATS for Epoch 22** : 
Average training loss: 0.0032
Average validation loss: 0.0824
Validation Accuracy: 0.9758
Overfitting: 0.0792
Best model saved at epoch 22 with validation loss: 0.0824
[Epoch 23, Batch 100] loss: 0.07311982384475414
[Epoch 23, Batch 200] loss: 0.08862973106908612
[Epoch 23, Batch 300] loss: 0.05547238365164958
[Epoch 23, Batch 400] loss: 0.06437520184437745
[Epoch 23, Batch 500] loss: 0.04508863428141922
[Epoch 23, Batch 600] loss: 0.0699445964791812
[Epoch 23, Batch 700] loss: 0.05030441018519923
[Epoch 23, Batch 800] loss: 0.06778972258209251
[Epoch 23, Batch 900] loss: 0.05754043813445606
[Epoch 23, Batch 1000] loss: 0.0669403709738981
[Epoch 23, Batch 1100] loss: 0.0760767755098641
[Epoch 23, Batch 1200] loss: 0.07803370748413727
[Epoch 23, Batch 1300] loss: 0.06958849288523197
[Epoch 23, Batch 1400] loss: 0.07252286477130837
[Epoch 23, Batch 1500] loss: 0.06078077043930534
[Epoch 23, Batch 1600] loss: 0.05577421466587111
[Epoch 23, Batch 1700] loss: 0.07287174961762503
[Epoch 23, Batch 1800] loss: 0.0796773538098205
**STATS for Epoch 23** : 
Average training loss: 0.0019
Average validation loss: 0.0823
Validation Accuracy: 0.9758
Overfitting: 0.0804
Best model saved at epoch 23 with validation loss: 0.0823
[Epoch 24, Batch 100] loss: 0.05970898178173229
[Epoch 24, Batch 200] loss: 0.0701426501874812
[Epoch 24, Batch 300] loss: 0.0715090769098606
[Epoch 24, Batch 400] loss: 0.0606855167564936
[Epoch 24, Batch 500] loss: 0.056689351211534816
[Epoch 24, Batch 600] loss: 0.06415568692260422
[Epoch 24, Batch 700] loss: 0.05926154608372599
[Epoch 24, Batch 800] loss: 0.07327905391226523
[Epoch 24, Batch 900] loss: 0.061190413938020355
[Epoch 24, Batch 1000] loss: 0.05915060298400931
[Epoch 24, Batch 1100] loss: 0.055825921460054814
[Epoch 24, Batch 1200] loss: 0.05930099946563132
[Epoch 24, Batch 1300] loss: 0.06311221961746924
[Epoch 24, Batch 1400] loss: 0.07029536699177698
[Epoch 24, Batch 1500] loss: 0.05882337204180658
[Epoch 24, Batch 1600] loss: 0.05816501775290817
[Epoch 24, Batch 1700] loss: 0.06598308864457067
[Epoch 24, Batch 1800] loss: 0.061092872268054633
**STATS for Epoch 24** : 
Average training loss: 0.0026
Average validation loss: 0.0794
Validation Accuracy: 0.9761
Overfitting: 0.0768
Best model saved at epoch 24 with validation loss: 0.0794
Fold 2 validation loss: 0.0794
Mean validation loss across all folds for Trial 5 is 0.0784 with trial config:  l1: 256, l2: 128, lr: 0.00010842262717330161, batch_size: 16
[I 2024-11-21 22:55:58,347] Trial 4 finished with value: 0.07840000983725767 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.00010842262717330161, 'batch_size': 16}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 6:
  l1: 128, l2: 64, lr: 0.002463768595899745, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2918630933761595
[Epoch 1, Batch 200] loss: 2.1493664312362672
[Epoch 1, Batch 300] loss: 1.034379744529724
[Epoch 1, Batch 400] loss: 0.5676704382896424
[Epoch 1, Batch 500] loss: 0.3783095894753933
[Epoch 1, Batch 600] loss: 0.27187977951020004
[Epoch 1, Batch 700] loss: 0.2405311000905931
[Epoch 1, Batch 800] loss: 0.21726560838520526
[Epoch 1, Batch 900] loss: 0.19996944786980747
[Epoch 1, Batch 1000] loss: 0.18203468484804033
[Epoch 1, Batch 1100] loss: 0.1611314169783145
[Epoch 1, Batch 1200] loss: 0.18803557482548058
[Epoch 1, Batch 1300] loss: 0.1295781200006604
[Epoch 1, Batch 1400] loss: 0.14907566375564785
[Epoch 1, Batch 1500] loss: 0.13283121042186394
[Epoch 1, Batch 1600] loss: 0.13221820728853345
[Epoch 1, Batch 1700] loss: 0.1277520938566886
[Epoch 1, Batch 1800] loss: 0.12464105954859406
**STATS for Epoch 1** : 
Average training loss: 0.0055
Average validation loss: 0.1220
Validation Accuracy: 0.9625
Overfitting: 0.1166
Best model saved at epoch 1 with validation loss: 0.1220
[Epoch 2, Batch 100] loss: 0.09319606025354005
[Epoch 2, Batch 200] loss: 0.10701410009525716
[Epoch 2, Batch 300] loss: 0.09794659362873062
[Epoch 2, Batch 400] loss: 0.1020419420482358
[Epoch 2, Batch 500] loss: 0.09903421547845938
[Epoch 2, Batch 600] loss: 0.11986575411166996
[Epoch 2, Batch 700] loss: 0.1007808469212614
[Epoch 2, Batch 800] loss: 0.10923788472078741
[Epoch 2, Batch 900] loss: 0.08735593131859787
[Epoch 2, Batch 1000] loss: 0.08366700820624828
[Epoch 2, Batch 1100] loss: 0.073931415125262
[Epoch 2, Batch 1200] loss: 0.07803717674454674
[Epoch 2, Batch 1300] loss: 0.09410336636763532
[Epoch 2, Batch 1400] loss: 0.07440800042706541
[Epoch 2, Batch 1500] loss: 0.0745670209347736
[Epoch 2, Batch 1600] loss: 0.08149182939087041
[Epoch 2, Batch 1700] loss: 0.07227017142635304
[Epoch 2, Batch 1800] loss: 0.09508670702576637
**STATS for Epoch 2** : 
Average training loss: 0.0041
Average validation loss: 0.0999
Validation Accuracy: 0.9696
Overfitting: 0.0958
Best model saved at epoch 2 with validation loss: 0.0999
[Epoch 3, Batch 100] loss: 0.06758093382639345
[Epoch 3, Batch 200] loss: 0.07645366927725263
[Epoch 3, Batch 300] loss: 0.06658248586347326
[Epoch 3, Batch 400] loss: 0.06673221775272395
[Epoch 3, Batch 500] loss: 0.06793563337705563
[Epoch 3, Batch 600] loss: 0.047102051501860843
[Epoch 3, Batch 700] loss: 0.05889186213025823
[Epoch 3, Batch 800] loss: 0.05107226223568432
[Epoch 3, Batch 900] loss: 0.08505692063132302
[Epoch 3, Batch 1000] loss: 0.04929503956285771
[Epoch 3, Batch 1100] loss: 0.06663615028199274
[Epoch 3, Batch 1200] loss: 0.06205827576050069
[Epoch 3, Batch 1300] loss: 0.06703260033682454
[Epoch 3, Batch 1400] loss: 0.07011025039246306
[Epoch 3, Batch 1500] loss: 0.07067945878821774
[Epoch 3, Batch 1600] loss: 0.06834166106942575
[Epoch 3, Batch 1700] loss: 0.04726226645288989
[Epoch 3, Batch 1800] loss: 0.05942143210559152
**STATS for Epoch 3** : 
Average training loss: 0.0021
Average validation loss: 0.0684
Validation Accuracy: 0.9797
Overfitting: 0.0663
Best model saved at epoch 3 with validation loss: 0.0684
[Epoch 4, Batch 100] loss: 0.053028162701812105
[Epoch 4, Batch 200] loss: 0.040155483805283436
[Epoch 4, Batch 300] loss: 0.04956655488160323
[Epoch 4, Batch 400] loss: 0.04949362774612382
[Epoch 4, Batch 500] loss: 0.04118253980210284
[Epoch 4, Batch 600] loss: 0.06251770901173587
[Epoch 4, Batch 700] loss: 0.04772014842281351
[Epoch 4, Batch 800] loss: 0.04787064435731736
[Epoch 4, Batch 900] loss: 0.04745801679266151
[Epoch 4, Batch 1000] loss: 0.05268371605721768
[Epoch 4, Batch 1100] loss: 0.04537034947279608
[Epoch 4, Batch 1200] loss: 0.05384624957805499
[Epoch 4, Batch 1300] loss: 0.05219824880594388
[Epoch 4, Batch 1400] loss: 0.051678001639957075
[Epoch 4, Batch 1500] loss: 0.052440081500390076
[Epoch 4, Batch 1600] loss: 0.04467016629336285
[Epoch 4, Batch 1700] loss: 0.046031093857600354
[Epoch 4, Batch 1800] loss: 0.04378489226815873
**STATS for Epoch 4** : 
Average training loss: 0.0019
Average validation loss: 0.0787
Validation Accuracy: 0.9771
Overfitting: 0.0767
[Epoch 5, Batch 100] loss: 0.03481574365418055
[Epoch 5, Batch 200] loss: 0.029940564706630538
[Epoch 5, Batch 300] loss: 0.03916525009088218
[Epoch 5, Batch 400] loss: 0.03612775007393793
[Epoch 5, Batch 500] loss: 0.03300064577182638
[Epoch 5, Batch 600] loss: 0.0319761745363212
[Epoch 5, Batch 700] loss: 0.03112940889190213
[Epoch 5, Batch 800] loss: 0.04943798854321358
[Epoch 5, Batch 900] loss: 0.04760579367983155
[Epoch 5, Batch 1000] loss: 0.021486449222720694
[Epoch 5, Batch 1100] loss: 0.049774901643831984
[Epoch 5, Batch 1200] loss: 0.03587123197343317
[Epoch 5, Batch 1300] loss: 0.03309702901533455
[Epoch 5, Batch 1400] loss: 0.04425924526010931
[Epoch 5, Batch 1500] loss: 0.046214729381536014
[Epoch 5, Batch 1600] loss: 0.052423411760682936
[Epoch 5, Batch 1700] loss: 0.039140860621992034
[Epoch 5, Batch 1800] loss: 0.028566960829321034
**STATS for Epoch 5** : 
Average training loss: 0.0017
Average validation loss: 0.0640
Validation Accuracy: 0.9824
Overfitting: 0.0623
Best model saved at epoch 5 with validation loss: 0.0640
[Epoch 6, Batch 100] loss: 0.026170515357662225
[Epoch 6, Batch 200] loss: 0.02288566341590922
[Epoch 6, Batch 300] loss: 0.024364139653698658
[Epoch 6, Batch 400] loss: 0.03541474829282379
[Epoch 6, Batch 500] loss: 0.03162743249653431
[Epoch 6, Batch 600] loss: 0.04808412585989572
[Epoch 6, Batch 700] loss: 0.037854242582398
[Epoch 6, Batch 800] loss: 0.03080305767740356
[Epoch 6, Batch 900] loss: 0.03141242950834567
[Epoch 6, Batch 1000] loss: 0.029262967676550032
[Epoch 6, Batch 1100] loss: 0.03338048411191266
[Epoch 6, Batch 1200] loss: 0.04304486315981194
[Epoch 6, Batch 1300] loss: 0.0613797581653489
[Epoch 6, Batch 1400] loss: 0.03479969133652048
[Epoch 6, Batch 1500] loss: 0.029911450748550124
[Epoch 6, Batch 1600] loss: 0.03926600351187517
[Epoch 6, Batch 1700] loss: 0.03932372373503313
[Epoch 6, Batch 1800] loss: 0.03310108591627795
**STATS for Epoch 6** : 
Average training loss: 0.0009
Average validation loss: 0.0600
Validation Accuracy: 0.9828
Overfitting: 0.0591
Best model saved at epoch 6 with validation loss: 0.0600
[Epoch 7, Batch 100] loss: 0.035110660852806175
[Epoch 7, Batch 200] loss: 0.018234395824256355
[Epoch 7, Batch 300] loss: 0.020315517460912817
[Epoch 7, Batch 400] loss: 0.026627778970196234
[Epoch 7, Batch 500] loss: 0.02304487156770847
[Epoch 7, Batch 600] loss: 0.03625086390558863
[Epoch 7, Batch 700] loss: 0.029215397449443115
[Epoch 7, Batch 800] loss: 0.022789037075090165
[Epoch 7, Batch 900] loss: 0.024652049537908168
[Epoch 7, Batch 1000] loss: 0.034500449207698694
[Epoch 7, Batch 1100] loss: 0.02976638893414929
[Epoch 7, Batch 1200] loss: 0.02419080008403398
[Epoch 7, Batch 1300] loss: 0.019272501604536956
[Epoch 7, Batch 1400] loss: 0.023941686429789114
[Epoch 7, Batch 1500] loss: 0.030294112840711023
[Epoch 7, Batch 1600] loss: 0.015781140331964708
[Epoch 7, Batch 1700] loss: 0.04152974261298368
[Epoch 7, Batch 1800] loss: 0.029932883453639078
**STATS for Epoch 7** : 
Average training loss: 0.0010
Average validation loss: 0.0946
Validation Accuracy: 0.9734
Overfitting: 0.0936
[Epoch 8, Batch 100] loss: 0.027633645669811812
[Epoch 8, Batch 200] loss: 0.02233891355972446
[Epoch 8, Batch 300] loss: 0.021111622493499453
[Epoch 8, Batch 400] loss: 0.01634383970340423
[Epoch 8, Batch 500] loss: 0.01914694126422546
[Epoch 8, Batch 600] loss: 0.014141267825652903
[Epoch 8, Batch 700] loss: 0.01820817453127802
[Epoch 8, Batch 800] loss: 0.018351866682023682
[Epoch 8, Batch 900] loss: 0.0319537572878653
[Epoch 8, Batch 1000] loss: 0.029542665306544223
[Epoch 8, Batch 1100] loss: 0.017133582147525885
[Epoch 8, Batch 1200] loss: 0.034280478803011646
[Epoch 8, Batch 1300] loss: 0.02416358539572684
[Epoch 8, Batch 1400] loss: 0.029492347490086102
[Epoch 8, Batch 1500] loss: 0.016712214294602745
[Epoch 8, Batch 1600] loss: 0.016042153535418036
[Epoch 8, Batch 1700] loss: 0.03607679039485447
[Epoch 8, Batch 1800] loss: 0.025686226616526257
**STATS for Epoch 8** : 
Average training loss: 0.0015
Average validation loss: 0.0662
Validation Accuracy: 0.9815
Overfitting: 0.0646
[Epoch 9, Batch 100] loss: 0.008800935819776897
[Epoch 9, Batch 200] loss: 0.013614261193711173
[Epoch 9, Batch 300] loss: 0.013873568769804478
[Epoch 9, Batch 400] loss: 0.015911001303647934
[Epoch 9, Batch 500] loss: 0.023155687055223098
[Epoch 9, Batch 600] loss: 0.02417532432671578
[Epoch 9, Batch 700] loss: 0.019125437062502897
[Epoch 9, Batch 800] loss: 0.00985568286769194
[Epoch 9, Batch 900] loss: 0.0142978730856521
[Epoch 9, Batch 1000] loss: 0.024093068577640223
[Epoch 9, Batch 1100] loss: 0.006668962524290691
[Epoch 9, Batch 1200] loss: 0.018803745398927277
[Epoch 9, Batch 1300] loss: 0.01898252740422322
[Epoch 9, Batch 1400] loss: 0.010210977958486182
[Epoch 9, Batch 1500] loss: 0.029446736170684745
[Epoch 9, Batch 1600] loss: 0.01862161118835502
[Epoch 9, Batch 1700] loss: 0.014609010837757523
[Epoch 9, Batch 1800] loss: 0.025956363353670894
**STATS for Epoch 9** : 
Average training loss: 0.0005
Average validation loss: 0.0612
Validation Accuracy: 0.9838
Overfitting: 0.0607
[Epoch 10, Batch 100] loss: 0.014133779968560703
[Epoch 10, Batch 200] loss: 0.012441397454331309
[Epoch 10, Batch 300] loss: 0.013045873422372551
[Epoch 10, Batch 400] loss: 0.016087183573931726
[Epoch 10, Batch 500] loss: 0.012839072372262308
[Epoch 10, Batch 600] loss: 0.008163647585033686
[Epoch 10, Batch 700] loss: 0.011285307641865075
[Epoch 10, Batch 800] loss: 0.01834620215178802
[Epoch 10, Batch 900] loss: 0.023613051739266665
[Epoch 10, Batch 1000] loss: 0.025916157807696436
[Epoch 10, Batch 1100] loss: 0.014727157572524447
[Epoch 10, Batch 1200] loss: 0.020819925780142513
[Epoch 10, Batch 1300] loss: 0.012609493615582324
[Epoch 10, Batch 1400] loss: 0.02302923854040273
[Epoch 10, Batch 1500] loss: 0.011664976279244002
[Epoch 10, Batch 1600] loss: 0.018295586794247354
[Epoch 10, Batch 1700] loss: 0.020819303317235836
[Epoch 10, Batch 1800] loss: 0.023653237785665623
**STATS for Epoch 10** : 
Average training loss: 0.0006
Average validation loss: 0.0750
Validation Accuracy: 0.9817
Overfitting: 0.0744
[Epoch 11, Batch 100] loss: 0.014672475166842105
[Epoch 11, Batch 200] loss: 0.008408165270457174
[Epoch 11, Batch 300] loss: 0.012971595629096555
[Epoch 11, Batch 400] loss: 0.005815591238201705
[Epoch 11, Batch 500] loss: 0.006581103605199133
[Epoch 11, Batch 600] loss: 0.008540976027384205
[Epoch 11, Batch 700] loss: 0.014700485667326575
[Epoch 11, Batch 800] loss: 0.01889063061284105
[Epoch 11, Batch 900] loss: 0.010975573064793026
[Epoch 11, Batch 1000] loss: 0.013943583803868478
[Epoch 11, Batch 1100] loss: 0.010022364257756634
[Epoch 11, Batch 1200] loss: 0.013986835699167841
[Epoch 11, Batch 1300] loss: 0.014656087567054783
[Epoch 11, Batch 1400] loss: 0.01822740142657949
[Epoch 11, Batch 1500] loss: 0.013348645382648102
[Epoch 11, Batch 1600] loss: 0.02114976813877547
[Epoch 11, Batch 1700] loss: 0.016632225284959078
[Epoch 11, Batch 1800] loss: 0.023389980395204475
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0715
Validation Accuracy: 0.9822
Overfitting: 0.0705
[Epoch 12, Batch 100] loss: 0.016746188905090095
[Epoch 12, Batch 200] loss: 0.012079351355105246
[Epoch 12, Batch 300] loss: 0.008531065908994152
[Epoch 12, Batch 400] loss: 0.007450719323021531
[Epoch 12, Batch 500] loss: 0.007579926957182579
[Epoch 12, Batch 600] loss: 0.005157743609747385
[Epoch 12, Batch 700] loss: 0.01960852632692081
[Epoch 12, Batch 800] loss: 0.01145983250272593
[Epoch 12, Batch 900] loss: 0.014175350507399003
[Epoch 12, Batch 1000] loss: 0.01337652298156172
[Epoch 12, Batch 1100] loss: 0.01609322691762827
[Epoch 12, Batch 1200] loss: 0.021413440817268564
[Epoch 12, Batch 1300] loss: 0.010941082834156077
[Epoch 12, Batch 1400] loss: 0.015208178717130068
[Epoch 12, Batch 1500] loss: 0.01139340135946668
[Epoch 12, Batch 1600] loss: 0.010566566868109249
[Epoch 12, Batch 1700] loss: 0.005994112683176809
[Epoch 12, Batch 1800] loss: 0.006099464441286955
**STATS for Epoch 12** : 
Average training loss: 0.0005
Average validation loss: 0.0580
Validation Accuracy: 0.9861
Overfitting: 0.0574
Best model saved at epoch 12 with validation loss: 0.0580
[Epoch 13, Batch 100] loss: 0.005052893890519954
[Epoch 13, Batch 200] loss: 0.005571712166029101
[Epoch 13, Batch 300] loss: 0.0048711135482824375
[Epoch 13, Batch 400] loss: 0.007664250584820138
[Epoch 13, Batch 500] loss: 0.011646830369904534
[Epoch 13, Batch 600] loss: 0.017447936904359265
[Epoch 13, Batch 700] loss: 0.006355394805743799
[Epoch 13, Batch 800] loss: 0.004809478440835732
[Epoch 13, Batch 900] loss: 0.010036839263719628
[Epoch 13, Batch 1000] loss: 0.014084191102984391
[Epoch 13, Batch 1100] loss: 0.016350568611255768
[Epoch 13, Batch 1200] loss: 0.011447149224694612
[Epoch 13, Batch 1300] loss: 0.009385801972176182
[Epoch 13, Batch 1400] loss: 0.012593383795237969
[Epoch 13, Batch 1500] loss: 0.01073920691334024
[Epoch 13, Batch 1600] loss: 0.007969244361195251
[Epoch 13, Batch 1700] loss: 0.009929730707253838
[Epoch 13, Batch 1800] loss: 0.024360373036079182
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0809
Validation Accuracy: 0.9820
Overfitting: 0.0798
[Epoch 14, Batch 100] loss: 0.0194097171289377
[Epoch 14, Batch 200] loss: 0.010986394492392719
[Epoch 14, Batch 300] loss: 0.015274813533391125
[Epoch 14, Batch 400] loss: 0.021963905423458528
[Epoch 14, Batch 500] loss: 0.014345071736061072
[Epoch 14, Batch 600] loss: 0.00459612111621027
[Epoch 14, Batch 700] loss: 0.013642541712891613
[Epoch 14, Batch 800] loss: 0.010035185323833956
[Epoch 14, Batch 900] loss: 0.003780533017776406
[Epoch 14, Batch 1000] loss: 0.005992365396109847
[Epoch 14, Batch 1100] loss: 0.010116959293531664
[Epoch 14, Batch 1200] loss: 0.012412777746271786
[Epoch 14, Batch 1300] loss: 0.02056563590187352
[Epoch 14, Batch 1400] loss: 0.018715243215865485
[Epoch 14, Batch 1500] loss: 0.015077827264917118
[Epoch 14, Batch 1600] loss: 0.011353026426188535
[Epoch 14, Batch 1700] loss: 0.01149165968117245
[Epoch 14, Batch 1800] loss: 0.030404684501781958
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0840
Validation Accuracy: 0.9818
Overfitting: 0.0835
[Epoch 15, Batch 100] loss: 0.008076164661399616
[Epoch 15, Batch 200] loss: 0.01356355511078391
[Epoch 15, Batch 300] loss: 0.008029763663250833
[Epoch 15, Batch 400] loss: 0.006923608245055846
[Epoch 15, Batch 500] loss: 0.012506422542103338
[Epoch 15, Batch 600] loss: 0.006075372706686721
[Epoch 15, Batch 700] loss: 0.007964816635926582
[Epoch 15, Batch 800] loss: 0.008073136973157488
[Epoch 15, Batch 900] loss: 0.0063048159067903954
[Epoch 15, Batch 1000] loss: 0.01685811194614814
[Epoch 15, Batch 1100] loss: 0.020335339452100244
[Epoch 15, Batch 1200] loss: 0.008191190598784032
[Epoch 15, Batch 1300] loss: 0.011961685969396285
[Epoch 15, Batch 1400] loss: 0.004775681825979774
[Epoch 15, Batch 1500] loss: 0.003992567605142767
[Epoch 15, Batch 1600] loss: 0.011641529172059961
[Epoch 15, Batch 1700] loss: 0.007400707888934903
[Epoch 15, Batch 1800] loss: 0.008661700912671221
**STATS for Epoch 15** : 
Average training loss: 0.0003
Average validation loss: 0.0694
Validation Accuracy: 0.9846
Overfitting: 0.0691
[Epoch 16, Batch 100] loss: 0.005961420587925659
[Epoch 16, Batch 200] loss: 0.007681797199265361
[Epoch 16, Batch 300] loss: 0.006807025878021591
[Epoch 16, Batch 400] loss: 0.010031111259568775
[Epoch 16, Batch 500] loss: 0.006408109657910757
[Epoch 16, Batch 600] loss: 0.004315048102293986
[Epoch 16, Batch 700] loss: 0.004104517208754714
[Epoch 16, Batch 800] loss: 0.002309622203464308
[Epoch 16, Batch 900] loss: 0.0029269723532573265
[Epoch 16, Batch 1000] loss: 0.0024952775385735037
[Epoch 16, Batch 1100] loss: 0.0011627118185887752
[Epoch 16, Batch 1200] loss: 0.0011927235441046235
[Epoch 16, Batch 1300] loss: 0.008842484480630332
[Epoch 16, Batch 1400] loss: 0.007383235719756125
[Epoch 16, Batch 1500] loss: 0.005234742629353874
[Epoch 16, Batch 1600] loss: 0.008222635780750238
[Epoch 16, Batch 1700] loss: 0.004510911684894836
[Epoch 16, Batch 1800] loss: 0.002034199371027512
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0644
Validation Accuracy: 0.9868
Overfitting: 0.0643
[Epoch 17, Batch 100] loss: 0.001123141248476216
[Epoch 17, Batch 200] loss: 0.0006543756296439618
[Epoch 17, Batch 300] loss: 0.003525746125239486
[Epoch 17, Batch 400] loss: 0.009735833689122444
[Epoch 17, Batch 500] loss: 0.004263910286508121
[Epoch 17, Batch 600] loss: 0.007237787204783288
[Epoch 17, Batch 700] loss: 0.006088150500565064
[Epoch 17, Batch 800] loss: 0.003728014847677059
[Epoch 17, Batch 900] loss: 0.006788923652887462
[Epoch 17, Batch 1000] loss: 0.0023888989895988286
[Epoch 17, Batch 1100] loss: 0.0021766238171854633
[Epoch 17, Batch 1200] loss: 0.004794590213034269
[Epoch 17, Batch 1300] loss: 0.008132148182874025
[Epoch 17, Batch 1400] loss: 0.0028462640187683517
[Epoch 17, Batch 1500] loss: 0.003170977399688013
[Epoch 17, Batch 1600] loss: 0.011522927555013211
[Epoch 17, Batch 1700] loss: 0.0032473256795449855
[Epoch 17, Batch 1800] loss: 0.0018249197896111013
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0648
Validation Accuracy: 0.9873
Overfitting: 0.0647
[Epoch 18, Batch 100] loss: 0.003298046690036358
[Epoch 18, Batch 200] loss: 0.006306301967941863
[Epoch 18, Batch 300] loss: 0.008992891391924189
[Epoch 18, Batch 400] loss: 0.007389557648576783
[Epoch 18, Batch 500] loss: 0.009063439905532392
[Epoch 18, Batch 600] loss: 0.01707403917605916
[Epoch 18, Batch 700] loss: 0.017806129970126677
[Epoch 18, Batch 800] loss: 0.012515179935890046
[Epoch 18, Batch 900] loss: 0.00857491791786714
[Epoch 18, Batch 1000] loss: 0.005261417283291223
[Epoch 18, Batch 1100] loss: 0.004317305954456288
[Epoch 18, Batch 1200] loss: 0.005408181465315636
[Epoch 18, Batch 1300] loss: 0.003829862895772447
[Epoch 18, Batch 1400] loss: 0.0029008243763455257
[Epoch 18, Batch 1500] loss: 0.0071597502925989254
[Epoch 18, Batch 1600] loss: 0.0029648776325089444
[Epoch 18, Batch 1700] loss: 0.007119753344908091
[Epoch 18, Batch 1800] loss: 0.006186990519610731
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0711
Validation Accuracy: 0.9855
Overfitting: 0.0707
[Epoch 19, Batch 100] loss: 0.0031953437635820594
[Epoch 19, Batch 200] loss: 0.004553014241087538
[Epoch 19, Batch 300] loss: 0.0016612047535403108
[Epoch 19, Batch 400] loss: 0.0005974208591590013
[Epoch 19, Batch 500] loss: 0.001296745063262108
[Epoch 19, Batch 600] loss: 0.007204577149784263
[Epoch 19, Batch 700] loss: 0.004553631539563341
[Epoch 19, Batch 800] loss: 0.006484806879132066
[Epoch 19, Batch 900] loss: 0.008561584615420302
[Epoch 19, Batch 1000] loss: 0.006630270800986011
[Epoch 19, Batch 1100] loss: 0.01079623159356231
[Epoch 19, Batch 1200] loss: 0.011423405961438675
[Epoch 19, Batch 1300] loss: 0.011990696498458533
[Epoch 19, Batch 1400] loss: 0.011017131933008385
[Epoch 19, Batch 1500] loss: 0.011122214556913833
[Epoch 19, Batch 1600] loss: 0.01276510751073488
[Epoch 19, Batch 1700] loss: 0.006527294232254803
[Epoch 19, Batch 1800] loss: 0.0072712656111431784
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0694
Validation Accuracy: 0.9846
Overfitting: 0.0691
[Epoch 20, Batch 100] loss: 0.0045281065824099185
[Epoch 20, Batch 200] loss: 0.0018896215738257638
[Epoch 20, Batch 300] loss: 0.00496593203530665
[Epoch 20, Batch 400] loss: 0.0020298069130906525
[Epoch 20, Batch 500] loss: 0.004376612885944269
[Epoch 20, Batch 600] loss: 0.0017769616194333081
[Epoch 20, Batch 700] loss: 0.005649382009074202
[Epoch 20, Batch 800] loss: 0.0025000209632850103
[Epoch 20, Batch 900] loss: 0.0015090684891470119
[Epoch 20, Batch 1000] loss: 0.00070323739921065
[Epoch 20, Batch 1100] loss: 0.0003162816493247078
[Epoch 20, Batch 1200] loss: 0.0019353423510045785
[Epoch 20, Batch 1300] loss: 0.004434634778894235
[Epoch 20, Batch 1400] loss: 0.008659342974056159
[Epoch 20, Batch 1500] loss: 0.003254281688841587
[Epoch 20, Batch 1600] loss: 0.002493808304074321
[Epoch 20, Batch 1700] loss: 0.004669626348425026
[Epoch 20, Batch 1800] loss: 0.007028159021603387
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0708
Validation Accuracy: 0.9864
Overfitting: 0.0708
[Epoch 21, Batch 100] loss: 0.004200619512031878
[Epoch 21, Batch 200] loss: 0.0017418660851747348
[Epoch 21, Batch 300] loss: 0.0021939637661259324
[Epoch 21, Batch 400] loss: 0.0014797363079063076
[Epoch 21, Batch 500] loss: 0.00092053426368782
[Epoch 21, Batch 600] loss: 0.0006429776164865864
[Epoch 21, Batch 700] loss: 0.0007841707114802166
[Epoch 21, Batch 800] loss: 0.0007303352813475783
[Epoch 21, Batch 900] loss: 0.00046883035251741754
[Epoch 21, Batch 1000] loss: 0.0005096141447938152
[Epoch 21, Batch 1100] loss: 0.003158728170787413
[Epoch 21, Batch 1200] loss: 0.0008152005636080161
[Epoch 21, Batch 1300] loss: 0.001201700786656943
[Epoch 21, Batch 1400] loss: 0.004529929468109088
[Epoch 21, Batch 1500] loss: 0.003057487959371308
[Epoch 21, Batch 1600] loss: 0.0021790000907744656
[Epoch 21, Batch 1700] loss: 0.0007006655154452889
[Epoch 21, Batch 1800] loss: 0.0004594957805261313
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0800
Validation Accuracy: 0.9847
Overfitting: 0.0798
[Epoch 22, Batch 100] loss: 0.008151758930179916
[Epoch 22, Batch 200] loss: 0.005372394305829875
[Epoch 22, Batch 300] loss: 0.00697180544243448
[Epoch 22, Batch 400] loss: 0.011271395482291098
[Epoch 22, Batch 500] loss: 0.0069852577875668944
[Epoch 22, Batch 600] loss: 0.006095543340802827
[Epoch 22, Batch 700] loss: 0.002003199297238325
[Epoch 22, Batch 800] loss: 0.009997773941211357
[Epoch 22, Batch 900] loss: 0.009163210299836777
[Epoch 22, Batch 1000] loss: 0.007780732940231445
[Epoch 22, Batch 1100] loss: 0.003954790066719127
[Epoch 22, Batch 1200] loss: 0.0013450499631940714
[Epoch 22, Batch 1300] loss: 0.0016866233122396989
[Epoch 22, Batch 1400] loss: 0.011732983471623722
[Epoch 22, Batch 1500] loss: 0.00594884030772306
[Epoch 22, Batch 1600] loss: 0.013208742375325357
[Epoch 22, Batch 1700] loss: 0.00613870141728114
[Epoch 22, Batch 1800] loss: 0.0015110585241221797
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0804
Validation Accuracy: 0.9862
Overfitting: 0.0800
[Epoch 23, Batch 100] loss: 0.0019717941947999407
[Epoch 23, Batch 200] loss: 0.002604767975160911
[Epoch 23, Batch 300] loss: 0.003624074210250532
[Epoch 23, Batch 400] loss: 0.0019106322221385597
[Epoch 23, Batch 500] loss: 0.002987607258959599
[Epoch 23, Batch 600] loss: 0.006202204800220343
[Epoch 23, Batch 700] loss: 0.00801760774311603
[Epoch 23, Batch 800] loss: 0.0033482095610522576
[Epoch 23, Batch 900] loss: 0.00290647103834516
[Epoch 23, Batch 1000] loss: 0.0009673641217793216
[Epoch 23, Batch 1100] loss: 0.0007051423809883772
[Epoch 23, Batch 1200] loss: 0.0011262084435624332
[Epoch 23, Batch 1300] loss: 0.002162094691966594
[Epoch 23, Batch 1400] loss: 0.001445817043415758
[Epoch 23, Batch 1500] loss: 0.0029041939511969873
[Epoch 23, Batch 1600] loss: 0.00120018560123075
[Epoch 23, Batch 1700] loss: 0.0032773978199685415
[Epoch 23, Batch 1800] loss: 0.0010714651124174067
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0703
Validation Accuracy: 0.9872
Overfitting: 0.0703
[Epoch 24, Batch 100] loss: 0.0005434751080822497
[Epoch 24, Batch 200] loss: 0.0002392401019446311
[Epoch 24, Batch 300] loss: 0.00043480064059369994
[Epoch 24, Batch 400] loss: 0.000498827278506191
[Epoch 24, Batch 500] loss: 0.00028455229017831484
[Epoch 24, Batch 600] loss: 0.0003620043335234868
[Epoch 24, Batch 700] loss: 0.00043051523249264533
[Epoch 24, Batch 800] loss: 0.00032631763576693726
[Epoch 24, Batch 900] loss: 0.000259168215225003
[Epoch 24, Batch 1000] loss: 0.0005228779101073044
[Epoch 24, Batch 1100] loss: 0.00022598305680800125
[Epoch 24, Batch 1200] loss: 0.0004726973376236199
[Epoch 24, Batch 1300] loss: 0.0006645656730827332
[Epoch 24, Batch 1400] loss: 0.0003276153190591158
[Epoch 24, Batch 1500] loss: 0.00013024930996087924
[Epoch 24, Batch 1600] loss: 0.00049353873728335
[Epoch 24, Batch 1700] loss: 0.002042566145854021
[Epoch 24, Batch 1800] loss: 0.0030142920333241464
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0698
Validation Accuracy: 0.9882
Overfitting: 0.0698
Fold 1 validation loss: 0.0698
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.286011917591095
[Epoch 1, Batch 200] loss: 1.8867270630598068
[Epoch 1, Batch 300] loss: 0.774996392428875
[Epoch 1, Batch 400] loss: 0.47446260146796704
[Epoch 1, Batch 500] loss: 0.38294596657156943
[Epoch 1, Batch 600] loss: 0.3244990556687117
[Epoch 1, Batch 700] loss: 0.2483356472104788
[Epoch 1, Batch 800] loss: 0.27322351826820523
[Epoch 1, Batch 900] loss: 0.21102999568916858
[Epoch 1, Batch 1000] loss: 0.23027590660378336
[Epoch 1, Batch 1100] loss: 0.1970368980243802
[Epoch 1, Batch 1200] loss: 0.16701822869013994
[Epoch 1, Batch 1300] loss: 0.180915030981414
[Epoch 1, Batch 1400] loss: 0.15943553858902304
[Epoch 1, Batch 1500] loss: 0.15320166695863008
[Epoch 1, Batch 1600] loss: 0.14120350345969201
[Epoch 1, Batch 1700] loss: 0.11951063992921263
[Epoch 1, Batch 1800] loss: 0.16222500449977814
**STATS for Epoch 1** : 
Average training loss: 0.0052
Average validation loss: 0.1280
Validation Accuracy: 0.9601
Overfitting: 0.1228
Best model saved at epoch 1 with validation loss: 0.1280
[Epoch 2, Batch 100] loss: 0.11367408331483603
[Epoch 2, Batch 200] loss: 0.09578943283529952
[Epoch 2, Batch 300] loss: 0.12767551589640788
[Epoch 2, Batch 400] loss: 0.11418088648031699
[Epoch 2, Batch 500] loss: 0.11906714750744868
[Epoch 2, Batch 600] loss: 0.09787261571269483
[Epoch 2, Batch 700] loss: 0.11098169887438417
[Epoch 2, Batch 800] loss: 0.11688127925619483
[Epoch 2, Batch 900] loss: 0.10267266815062612
[Epoch 2, Batch 1000] loss: 0.11025148742017336
[Epoch 2, Batch 1100] loss: 0.09617310233879835
[Epoch 2, Batch 1200] loss: 0.09431654788786545
[Epoch 2, Batch 1300] loss: 0.0877283166628331
[Epoch 2, Batch 1400] loss: 0.09708377002738416
[Epoch 2, Batch 1500] loss: 0.11023533279774711
[Epoch 2, Batch 1600] loss: 0.09684421314159408
[Epoch 2, Batch 1700] loss: 0.09349906247924082
[Epoch 2, Batch 1800] loss: 0.07583532158692834
**STATS for Epoch 2** : 
Average training loss: 0.0042
Average validation loss: 0.0965
Validation Accuracy: 0.9693
Overfitting: 0.0923
Best model saved at epoch 2 with validation loss: 0.0965
[Epoch 3, Batch 100] loss: 0.0676609249622561
[Epoch 3, Batch 200] loss: 0.07474132955161622
[Epoch 3, Batch 300] loss: 0.0730717475200072
[Epoch 3, Batch 400] loss: 0.05566900431993418
[Epoch 3, Batch 500] loss: 0.08157615919131786
[Epoch 3, Batch 600] loss: 0.07542294402199332
[Epoch 3, Batch 700] loss: 0.06380018993921112
[Epoch 3, Batch 800] loss: 0.07455352056422271
[Epoch 3, Batch 900] loss: 0.08812482072389685
[Epoch 3, Batch 1000] loss: 0.07792219141963869
[Epoch 3, Batch 1100] loss: 0.06999815547431354
[Epoch 3, Batch 1200] loss: 0.0800487359345425
[Epoch 3, Batch 1300] loss: 0.06619194109924137
[Epoch 3, Batch 1400] loss: 0.06816261893545743
[Epoch 3, Batch 1500] loss: 0.05894920662161894
[Epoch 3, Batch 1600] loss: 0.06759448631259148
[Epoch 3, Batch 1700] loss: 0.08461727390415036
[Epoch 3, Batch 1800] loss: 0.05575565162464045
**STATS for Epoch 3** : 
Average training loss: 0.0031
Average validation loss: 0.0931
Validation Accuracy: 0.9710
Overfitting: 0.0899
Best model saved at epoch 3 with validation loss: 0.0931
[Epoch 4, Batch 100] loss: 0.03817306200042367
[Epoch 4, Batch 200] loss: 0.07066720681264997
[Epoch 4, Batch 300] loss: 0.042423602319031486
[Epoch 4, Batch 400] loss: 0.048062622700235806
[Epoch 4, Batch 500] loss: 0.06810730307915946
[Epoch 4, Batch 600] loss: 0.051002072802803014
[Epoch 4, Batch 700] loss: 0.05187536979094148
[Epoch 4, Batch 800] loss: 0.055237554861232635
[Epoch 4, Batch 900] loss: 0.06126878642644442
[Epoch 4, Batch 1000] loss: 0.049123757317429406
[Epoch 4, Batch 1100] loss: 0.04885393861186458
[Epoch 4, Batch 1200] loss: 0.060420796701218936
[Epoch 4, Batch 1300] loss: 0.05542558069020743
[Epoch 4, Batch 1400] loss: 0.05409980257587449
[Epoch 4, Batch 1500] loss: 0.05853952029516222
[Epoch 4, Batch 1600] loss: 0.0587630938080838
[Epoch 4, Batch 1700] loss: 0.05029971846597618
[Epoch 4, Batch 1800] loss: 0.03981174608699803
**STATS for Epoch 4** : 
Average training loss: 0.0030
Average validation loss: 0.0650
Validation Accuracy: 0.9798
Overfitting: 0.0620
Best model saved at epoch 4 with validation loss: 0.0650
[Epoch 5, Batch 100] loss: 0.046218707593798175
[Epoch 5, Batch 200] loss: 0.03369375461537857
[Epoch 5, Batch 300] loss: 0.03807855027902406
[Epoch 5, Batch 400] loss: 0.021143696822982748
[Epoch 5, Batch 500] loss: 0.05337686709681293
[Epoch 5, Batch 600] loss: 0.05187336347124074
[Epoch 5, Batch 700] loss: 0.04604152550338767
[Epoch 5, Batch 800] loss: 0.05683149620366748
[Epoch 5, Batch 900] loss: 0.045122332986211405
[Epoch 5, Batch 1000] loss: 0.03912739234903711
[Epoch 5, Batch 1100] loss: 0.02606311021721922
[Epoch 5, Batch 1200] loss: 0.04610775931127137
[Epoch 5, Batch 1300] loss: 0.036164201609935845
[Epoch 5, Batch 1400] loss: 0.04205528999940725
[Epoch 5, Batch 1500] loss: 0.052692225923237856
[Epoch 5, Batch 1600] loss: 0.03904844460921595
[Epoch 5, Batch 1700] loss: 0.04691511804558104
[Epoch 5, Batch 1800] loss: 0.049028900780540424
**STATS for Epoch 5** : 
Average training loss: 0.0016
Average validation loss: 0.0623
Validation Accuracy: 0.9813
Overfitting: 0.0607
Best model saved at epoch 5 with validation loss: 0.0623
[Epoch 6, Batch 100] loss: 0.02450930162129225
[Epoch 6, Batch 200] loss: 0.040495126038294985
[Epoch 6, Batch 300] loss: 0.03173860105438507
[Epoch 6, Batch 400] loss: 0.03373919831421517
[Epoch 6, Batch 500] loss: 0.04340177531732479
[Epoch 6, Batch 600] loss: 0.029637891323291116
[Epoch 6, Batch 700] loss: 0.04240227855916601
[Epoch 6, Batch 800] loss: 0.026885165192870774
[Epoch 6, Batch 900] loss: 0.028800447190151318
[Epoch 6, Batch 1000] loss: 0.034656570232400555
[Epoch 6, Batch 1100] loss: 0.048778245129033164
[Epoch 6, Batch 1200] loss: 0.034044639703497526
[Epoch 6, Batch 1300] loss: 0.021595701446785825
[Epoch 6, Batch 1400] loss: 0.04511132626023027
[Epoch 6, Batch 1500] loss: 0.022608431912703963
[Epoch 6, Batch 1600] loss: 0.040018918916357504
[Epoch 6, Batch 1700] loss: 0.0497770473624405
[Epoch 6, Batch 1800] loss: 0.04164926906101755
**STATS for Epoch 6** : 
Average training loss: 0.0013
Average validation loss: 0.0589
Validation Accuracy: 0.9816
Overfitting: 0.0575
Best model saved at epoch 6 with validation loss: 0.0589
[Epoch 7, Batch 100] loss: 0.019374121517976163
[Epoch 7, Batch 200] loss: 0.020819297728121456
[Epoch 7, Batch 300] loss: 0.02449714101938298
[Epoch 7, Batch 400] loss: 0.01565433423485956
[Epoch 7, Batch 500] loss: 0.010046675891626364
[Epoch 7, Batch 600] loss: 0.026607666896879892
[Epoch 7, Batch 700] loss: 0.04493965537001714
[Epoch 7, Batch 800] loss: 0.032141911577255086
[Epoch 7, Batch 900] loss: 0.03137756056348735
[Epoch 7, Batch 1000] loss: 0.04042226135788951
[Epoch 7, Batch 1100] loss: 0.025472434623879964
[Epoch 7, Batch 1200] loss: 0.0302945097709744
[Epoch 7, Batch 1300] loss: 0.035190799472547954
[Epoch 7, Batch 1400] loss: 0.02076446396356914
[Epoch 7, Batch 1500] loss: 0.032033366766645484
[Epoch 7, Batch 1600] loss: 0.029750101149656986
[Epoch 7, Batch 1700] loss: 0.026146755649970144
[Epoch 7, Batch 1800] loss: 0.0155603516453084
**STATS for Epoch 7** : 
Average training loss: 0.0015
Average validation loss: 0.0617
Validation Accuracy: 0.9825
Overfitting: 0.0602
[Epoch 8, Batch 100] loss: 0.011790656327439137
[Epoch 8, Batch 200] loss: 0.010841843483522098
[Epoch 8, Batch 300] loss: 0.04095077317752839
[Epoch 8, Batch 400] loss: 0.018473383274795196
[Epoch 8, Batch 500] loss: 0.016023267427444806
[Epoch 8, Batch 600] loss: 0.020623766225689906
[Epoch 8, Batch 700] loss: 0.02492055212816922
[Epoch 8, Batch 800] loss: 0.015368066887458554
[Epoch 8, Batch 900] loss: 0.01576186556378161
[Epoch 8, Batch 1000] loss: 0.030492397201269342
[Epoch 8, Batch 1100] loss: 0.025301733849337326
[Epoch 8, Batch 1200] loss: 0.014329043346915569
[Epoch 8, Batch 1300] loss: 0.02748625052110583
[Epoch 8, Batch 1400] loss: 0.021277169107597728
[Epoch 8, Batch 1500] loss: 0.01938818809867371
[Epoch 8, Batch 1600] loss: 0.028540677400887945
[Epoch 8, Batch 1700] loss: 0.021946347099510603
[Epoch 8, Batch 1800] loss: 0.024373749143342137
**STATS for Epoch 8** : 
Average training loss: 0.0010
Average validation loss: 0.0585
Validation Accuracy: 0.9820
Overfitting: 0.0575
Best model saved at epoch 8 with validation loss: 0.0585
[Epoch 9, Batch 100] loss: 0.017105214444191007
[Epoch 9, Batch 200] loss: 0.019165604580125548
[Epoch 9, Batch 300] loss: 0.018986839073277223
[Epoch 9, Batch 400] loss: 0.013092970782472547
[Epoch 9, Batch 500] loss: 0.025787370591897344
[Epoch 9, Batch 600] loss: 0.017666199218838302
[Epoch 9, Batch 700] loss: 0.015404030073368631
[Epoch 9, Batch 800] loss: 0.02027423101109889
[Epoch 9, Batch 900] loss: 0.01716609666500517
[Epoch 9, Batch 1000] loss: 0.013046871481210474
[Epoch 9, Batch 1100] loss: 0.022566298750152782
[Epoch 9, Batch 1200] loss: 0.024957031288740838
[Epoch 9, Batch 1300] loss: 0.01670977062200109
[Epoch 9, Batch 1400] loss: 0.031654066927512756
[Epoch 9, Batch 1500] loss: 0.01324701617930259
[Epoch 9, Batch 1600] loss: 0.02793724179662604
[Epoch 9, Batch 1700] loss: 0.030375310305771563
[Epoch 9, Batch 1800] loss: 0.009832644115958829
**STATS for Epoch 9** : 
Average training loss: 0.0008
Average validation loss: 0.0546
Validation Accuracy: 0.9838
Overfitting: 0.0538
Best model saved at epoch 9 with validation loss: 0.0546
[Epoch 10, Batch 100] loss: 0.02079262142823154
[Epoch 10, Batch 200] loss: 0.012688695132219437
[Epoch 10, Batch 300] loss: 0.015054434980902443
[Epoch 10, Batch 400] loss: 0.009043838773359313
[Epoch 10, Batch 500] loss: 0.020176118689614667
[Epoch 10, Batch 600] loss: 0.011260510015408726
[Epoch 10, Batch 700] loss: 0.02110691205880357
[Epoch 10, Batch 800] loss: 0.01757762155177261
[Epoch 10, Batch 900] loss: 0.017961419736761856
[Epoch 10, Batch 1000] loss: 0.025612524125695018
[Epoch 10, Batch 1100] loss: 0.01982905730670609
[Epoch 10, Batch 1200] loss: 0.01875908282009732
[Epoch 10, Batch 1300] loss: 0.020958810874708432
[Epoch 10, Batch 1400] loss: 0.01624945879002553
[Epoch 10, Batch 1500] loss: 0.014444287529058783
[Epoch 10, Batch 1600] loss: 0.011821173473063027
[Epoch 10, Batch 1700] loss: 0.013420732616077657
[Epoch 10, Batch 1800] loss: 0.01829586789448513
**STATS for Epoch 10** : 
Average training loss: 0.0003
Average validation loss: 0.0640
Validation Accuracy: 0.9827
Overfitting: 0.0636
[Epoch 11, Batch 100] loss: 0.01813762529906626
[Epoch 11, Batch 200] loss: 0.013793909202704527
[Epoch 11, Batch 300] loss: 0.011532547833485295
[Epoch 11, Batch 400] loss: 0.018721071341269636
[Epoch 11, Batch 500] loss: 0.010597161144196433
[Epoch 11, Batch 600] loss: 0.00790323018334675
[Epoch 11, Batch 700] loss: 0.016149455145859973
[Epoch 11, Batch 800] loss: 0.0128132039648699
[Epoch 11, Batch 900] loss: 0.011610330638341111
[Epoch 11, Batch 1000] loss: 0.023537219466015814
[Epoch 11, Batch 1100] loss: 0.01533140775949505
[Epoch 11, Batch 1200] loss: 0.008520423345828476
[Epoch 11, Batch 1300] loss: 0.008062875220477963
[Epoch 11, Batch 1400] loss: 0.007269727824409529
[Epoch 11, Batch 1500] loss: 0.005895154787253887
[Epoch 11, Batch 1600] loss: 0.011692516804860133
[Epoch 11, Batch 1700] loss: 0.018569227472835338
[Epoch 11, Batch 1800] loss: 0.024690392006432374
**STATS for Epoch 11** : 
Average training loss: 0.0006
Average validation loss: 0.0690
Validation Accuracy: 0.9809
Overfitting: 0.0684
[Epoch 12, Batch 100] loss: 0.017927159159512485
[Epoch 12, Batch 200] loss: 0.012905890835631907
[Epoch 12, Batch 300] loss: 0.010095651818173791
[Epoch 12, Batch 400] loss: 0.0064508013024124015
[Epoch 12, Batch 500] loss: 0.009022799820550063
[Epoch 12, Batch 600] loss: 0.01989224387257764
[Epoch 12, Batch 700] loss: 0.004289620361296329
[Epoch 12, Batch 800] loss: 0.008539819860100124
[Epoch 12, Batch 900] loss: 0.009862661770449676
[Epoch 12, Batch 1000] loss: 0.006755240229885544
[Epoch 12, Batch 1100] loss: 0.015602616873975421
[Epoch 12, Batch 1200] loss: 0.012339560372997766
[Epoch 12, Batch 1300] loss: 0.013885250681860271
[Epoch 12, Batch 1400] loss: 0.007140572622242871
[Epoch 12, Batch 1500] loss: 0.010759533384048154
[Epoch 12, Batch 1600] loss: 0.015280806054688583
[Epoch 12, Batch 1700] loss: 0.012411576079821317
[Epoch 12, Batch 1800] loss: 0.020709585290815083
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0610
Validation Accuracy: 0.9847
Overfitting: 0.0603
[Epoch 13, Batch 100] loss: 0.00890458074253729
[Epoch 13, Batch 200] loss: 0.007667764969837663
[Epoch 13, Batch 300] loss: 0.010354461633487516
[Epoch 13, Batch 400] loss: 0.008607335210051588
[Epoch 13, Batch 500] loss: 0.003015806705157047
[Epoch 13, Batch 600] loss: 0.0033033025651218397
[Epoch 13, Batch 700] loss: 0.002792266232438578
[Epoch 13, Batch 800] loss: 0.010625603310529641
[Epoch 13, Batch 900] loss: 0.004438413107324095
[Epoch 13, Batch 1000] loss: 0.0023668345273449632
[Epoch 13, Batch 1100] loss: 0.0073350189984876125
[Epoch 13, Batch 1200] loss: 0.006171644595351609
[Epoch 13, Batch 1300] loss: 0.00839967964475818
[Epoch 13, Batch 1400] loss: 0.014609481455092919
[Epoch 13, Batch 1500] loss: 0.009248082749994637
[Epoch 13, Batch 1600] loss: 0.013584576483718252
[Epoch 13, Batch 1700] loss: 0.01659569964291677
[Epoch 13, Batch 1800] loss: 0.010465536259480358
**STATS for Epoch 13** : 
Average training loss: 0.0004
Average validation loss: 0.0584
Validation Accuracy: 0.9857
Overfitting: 0.0580
[Epoch 14, Batch 100] loss: 0.00951034160497727
[Epoch 14, Batch 200] loss: 0.01219758843437603
[Epoch 14, Batch 300] loss: 0.007834670847086613
[Epoch 14, Batch 400] loss: 0.009606399451631659
[Epoch 14, Batch 500] loss: 0.004300093858898322
[Epoch 14, Batch 600] loss: 0.004574736744141319
[Epoch 14, Batch 700] loss: 0.008605637673050524
[Epoch 14, Batch 800] loss: 0.008696137611281643
[Epoch 14, Batch 900] loss: 0.0034149526758237413
[Epoch 14, Batch 1000] loss: 0.0036247047717165516
[Epoch 14, Batch 1100] loss: 0.0038626059260070634
[Epoch 14, Batch 1200] loss: 0.004359352010600333
[Epoch 14, Batch 1300] loss: 0.00974140813463066
[Epoch 14, Batch 1400] loss: 0.03357696983963507
[Epoch 14, Batch 1500] loss: 0.01036159625192795
[Epoch 14, Batch 1600] loss: 0.015789228341250235
[Epoch 14, Batch 1700] loss: 0.009521190616162585
[Epoch 14, Batch 1800] loss: 0.0066112345994326915
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0555
Validation Accuracy: 0.9854
Overfitting: 0.0548
[Epoch 15, Batch 100] loss: 0.014072112730073059
[Epoch 15, Batch 200] loss: 0.0028913712964056515
[Epoch 15, Batch 300] loss: 0.0040018029864268105
[Epoch 15, Batch 400] loss: 0.002497376352944798
[Epoch 15, Batch 500] loss: 0.009674129963265159
[Epoch 15, Batch 600] loss: 0.015147692003333475
[Epoch 15, Batch 700] loss: 0.013706717050492898
[Epoch 15, Batch 800] loss: 0.006516966481764257
[Epoch 15, Batch 900] loss: 0.003644367355128111
[Epoch 15, Batch 1000] loss: 0.0019790164629671383
[Epoch 15, Batch 1100] loss: 0.0021450452247177053
[Epoch 15, Batch 1200] loss: 0.0030034843377904964
[Epoch 15, Batch 1300] loss: 0.003370538472822773
[Epoch 15, Batch 1400] loss: 0.005209365724262512
[Epoch 15, Batch 1500] loss: 0.009593334817057837
[Epoch 15, Batch 1600] loss: 0.012316765711329367
[Epoch 15, Batch 1700] loss: 0.02003734928442185
[Epoch 15, Batch 1800] loss: 0.005274801915146554
**STATS for Epoch 15** : 
Average training loss: 0.0001
Average validation loss: 0.0521
Validation Accuracy: 0.9873
Overfitting: 0.0521
Best model saved at epoch 15 with validation loss: 0.0521
[Epoch 16, Batch 100] loss: 0.001944217130197785
[Epoch 16, Batch 200] loss: 0.005775942843807229
[Epoch 16, Batch 300] loss: 0.002209580368710817
[Epoch 16, Batch 400] loss: 0.0060818877657279205
[Epoch 16, Batch 500] loss: 0.0014792834038462389
[Epoch 16, Batch 600] loss: 0.004491817650768723
[Epoch 16, Batch 700] loss: 0.003154825885324044
[Epoch 16, Batch 800] loss: 0.003996459510065051
[Epoch 16, Batch 900] loss: 0.001615968194826536
[Epoch 16, Batch 1000] loss: 0.0030039817843936587
[Epoch 16, Batch 1100] loss: 0.00398123620759975
[Epoch 16, Batch 1200] loss: 0.013171961449328648
[Epoch 16, Batch 1300] loss: 0.004943843508933199
[Epoch 16, Batch 1400] loss: 0.005066414557591656
[Epoch 16, Batch 1500] loss: 0.013965461762139171
[Epoch 16, Batch 1600] loss: 0.0051720174224556105
[Epoch 16, Batch 1700] loss: 0.004636963159213359
[Epoch 16, Batch 1800] loss: 0.002037997122820059
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0584
Validation Accuracy: 0.9868
Overfitting: 0.0583
[Epoch 17, Batch 100] loss: 0.0025319429982673114
[Epoch 17, Batch 200] loss: 0.002513037581089037
[Epoch 17, Batch 300] loss: 0.0015614948340122935
[Epoch 17, Batch 400] loss: 0.015900263875482566
[Epoch 17, Batch 500] loss: 0.006859506221226166
[Epoch 17, Batch 600] loss: 0.0027043105331824436
[Epoch 17, Batch 700] loss: 0.0022346910870805915
[Epoch 17, Batch 800] loss: 0.0027466834468046386
[Epoch 17, Batch 900] loss: 0.006190585431061209
[Epoch 17, Batch 1000] loss: 0.004443017115481353
[Epoch 17, Batch 1100] loss: 0.004273371040368499
[Epoch 17, Batch 1200] loss: 0.0031714255948404003
[Epoch 17, Batch 1300] loss: 0.002347483984871843
[Epoch 17, Batch 1400] loss: 0.0037555159750587387
[Epoch 17, Batch 1500] loss: 0.003041842807188573
[Epoch 17, Batch 1600] loss: 0.008208171927728927
[Epoch 17, Batch 1700] loss: 0.0049189713712601705
[Epoch 17, Batch 1800] loss: 0.0020897143171575293
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0636
Validation Accuracy: 0.9859
Overfitting: 0.0634
[Epoch 18, Batch 100] loss: 0.002758126870070434
[Epoch 18, Batch 200] loss: 0.003074830208235113
[Epoch 18, Batch 300] loss: 0.013430705563238093
[Epoch 18, Batch 400] loss: 0.0017693883294060697
[Epoch 18, Batch 500] loss: 0.0011567769594850396
[Epoch 18, Batch 600] loss: 0.0022406184562875353
[Epoch 18, Batch 700] loss: 0.0030433920260423976
[Epoch 18, Batch 800] loss: 0.002108665750132275
[Epoch 18, Batch 900] loss: 0.0017702736338799242
[Epoch 18, Batch 1000] loss: 0.0013561078498967305
[Epoch 18, Batch 1100] loss: 0.0014598628035612648
[Epoch 18, Batch 1200] loss: 0.0013488317368466874
[Epoch 18, Batch 1300] loss: 0.0009580865480998923
[Epoch 18, Batch 1400] loss: 0.0007730847219122516
[Epoch 18, Batch 1500] loss: 0.002374628639919649
[Epoch 18, Batch 1600] loss: 0.0009053160505845836
[Epoch 18, Batch 1700] loss: 0.001897342616781419
[Epoch 18, Batch 1800] loss: 0.0012507573833627017
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0611
Validation Accuracy: 0.9873
Overfitting: 0.0609
[Epoch 19, Batch 100] loss: 0.00042486350959578087
[Epoch 19, Batch 200] loss: 0.0005877954339602809
[Epoch 19, Batch 300] loss: 0.0008177801033013132
[Epoch 19, Batch 400] loss: 0.002016940888257537
[Epoch 19, Batch 500] loss: 0.0007156802129329254
[Epoch 19, Batch 600] loss: 0.0009930613609041216
[Epoch 19, Batch 700] loss: 0.002343076652148972
[Epoch 19, Batch 800] loss: 0.010357187440101256
[Epoch 19, Batch 900] loss: 0.0007131394556972736
[Epoch 19, Batch 1000] loss: 0.0021368893941409706
[Epoch 19, Batch 1100] loss: 0.001639189980632305
[Epoch 19, Batch 1200] loss: 0.0010515207502751346
[Epoch 19, Batch 1300] loss: 0.004948619225144437
[Epoch 19, Batch 1400] loss: 0.007718948782738551
[Epoch 19, Batch 1500] loss: 0.004492649490503098
[Epoch 19, Batch 1600] loss: 0.0016233166110505514
[Epoch 19, Batch 1700] loss: 0.0016337548432471748
[Epoch 19, Batch 1800] loss: 0.0009455107762367732
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0625
Validation Accuracy: 0.9873
Overfitting: 0.0625
[Epoch 20, Batch 100] loss: 0.006863848345762733
[Epoch 20, Batch 200] loss: 0.0013188412974303532
[Epoch 20, Batch 300] loss: 0.0011427628159464832
[Epoch 20, Batch 400] loss: 0.0026939153589265173
[Epoch 20, Batch 500] loss: 0.0005690531077689797
[Epoch 20, Batch 600] loss: 0.0004828110468121238
[Epoch 20, Batch 700] loss: 0.0008357667290611915
[Epoch 20, Batch 800] loss: 0.0010894630508681757
[Epoch 20, Batch 900] loss: 0.0004929826416753436
[Epoch 20, Batch 1000] loss: 0.000467364840855895
[Epoch 20, Batch 1100] loss: 0.00039171145219614624
[Epoch 20, Batch 1200] loss: 0.00039712915087772413
[Epoch 20, Batch 1300] loss: 0.001032006564741539
[Epoch 20, Batch 1400] loss: 0.0008124084326641778
[Epoch 20, Batch 1500] loss: 0.00047410742455854303
[Epoch 20, Batch 1600] loss: 0.0004752405357460532
[Epoch 20, Batch 1700] loss: 0.0006318612164008908
[Epoch 20, Batch 1800] loss: 0.00046523898404950083
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0620
Validation Accuracy: 0.9873
Overfitting: 0.0620
[Epoch 21, Batch 100] loss: 0.00015510379162190003
[Epoch 21, Batch 200] loss: 0.0002611162600451422
[Epoch 21, Batch 300] loss: 0.00013487074180882798
[Epoch 21, Batch 400] loss: 0.0002045536841089479
[Epoch 21, Batch 500] loss: 0.00021042550542659465
[Epoch 21, Batch 600] loss: 0.0001786158347311284
[Epoch 21, Batch 700] loss: 0.00020731362615639793
[Epoch 21, Batch 800] loss: 0.000529679676945114
[Epoch 21, Batch 900] loss: 0.00022017018476105932
[Epoch 21, Batch 1000] loss: 0.0001800664937227836
[Epoch 21, Batch 1100] loss: 0.00012010043231757362
[Epoch 21, Batch 1200] loss: 0.00030219690395979717
[Epoch 21, Batch 1300] loss: 0.00018410433621138367
[Epoch 21, Batch 1400] loss: 0.00013086465192375664
[Epoch 21, Batch 1500] loss: 0.0002559595253940916
[Epoch 21, Batch 1600] loss: 0.0003113432873175359
[Epoch 21, Batch 1700] loss: 0.0004141862339294189
[Epoch 21, Batch 1800] loss: 0.00021366079947759964
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0633
Validation Accuracy: 0.9877
Overfitting: 0.0633
[Epoch 22, Batch 100] loss: 0.0005729390948503532
[Epoch 22, Batch 200] loss: 0.00033391344520362855
[Epoch 22, Batch 300] loss: 0.00016438553624140262
[Epoch 22, Batch 400] loss: 0.0005030117207522622
[Epoch 22, Batch 500] loss: 0.001037325456010052
[Epoch 22, Batch 600] loss: 0.00010096689367986578
[Epoch 22, Batch 700] loss: 0.00033311580971643104
[Epoch 22, Batch 800] loss: 0.0002649972458224781
[Epoch 22, Batch 900] loss: 0.0001237204848295992
[Epoch 22, Batch 1000] loss: 0.00010417022941181298
[Epoch 22, Batch 1100] loss: 0.00011145849285981501
[Epoch 22, Batch 1200] loss: 7.452633690369304e-05
[Epoch 22, Batch 1300] loss: 0.0001316357655700795
[Epoch 22, Batch 1400] loss: 0.00019945988607431798
[Epoch 22, Batch 1500] loss: 0.00011782871375253911
[Epoch 22, Batch 1600] loss: 0.00011909412970264821
[Epoch 22, Batch 1700] loss: 0.00015816357223852773
[Epoch 22, Batch 1800] loss: 9.665106165762438e-05
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9878
Overfitting: 0.0635
[Epoch 23, Batch 100] loss: 0.00015225179209012562
[Epoch 23, Batch 200] loss: 0.00012945310576370606
[Epoch 23, Batch 300] loss: 0.00018103428013329647
[Epoch 23, Batch 400] loss: 0.0001696402841786959
[Epoch 23, Batch 500] loss: 0.0001514953578580025
[Epoch 23, Batch 600] loss: 0.0001339558869837809
[Epoch 23, Batch 700] loss: 8.149164865374203e-05
[Epoch 23, Batch 800] loss: 0.0008155286015381514
[Epoch 23, Batch 900] loss: 6.880153978453762e-05
[Epoch 23, Batch 1000] loss: 0.0010009778302966365
[Epoch 23, Batch 1100] loss: 0.0001538666011964418
[Epoch 23, Batch 1200] loss: 8.084662387984665e-05
[Epoch 23, Batch 1300] loss: 0.00016167327928166665
[Epoch 23, Batch 1400] loss: 6.664232781138146e-05
[Epoch 23, Batch 1500] loss: 6.20431935899024e-05
[Epoch 23, Batch 1600] loss: 0.00012481715589460318
[Epoch 23, Batch 1700] loss: 0.00012605243386514252
[Epoch 23, Batch 1800] loss: 0.00014926146133277475
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0646
Validation Accuracy: 0.9875
Overfitting: 0.0646
[Epoch 24, Batch 100] loss: 8.371785490431272e-05
[Epoch 24, Batch 200] loss: 6.53402090565347e-05
[Epoch 24, Batch 300] loss: 0.0001506219319232116
[Epoch 24, Batch 400] loss: 0.0001292323980088872
[Epoch 24, Batch 500] loss: 9.131223494632135e-05
[Epoch 24, Batch 600] loss: 5.081636501326425e-05
[Epoch 24, Batch 700] loss: 0.00015066569791017949
[Epoch 24, Batch 800] loss: 6.461706076585472e-05
[Epoch 24, Batch 900] loss: 7.318118199883372e-05
[Epoch 24, Batch 1000] loss: 0.0007143314980669401
[Epoch 24, Batch 1100] loss: 0.0009206507582105194
[Epoch 24, Batch 1200] loss: 0.00016401490947203444
[Epoch 24, Batch 1300] loss: 0.00015504893161546462
[Epoch 24, Batch 1400] loss: 7.720757985426375e-05
[Epoch 24, Batch 1500] loss: 0.00011157213756677997
[Epoch 24, Batch 1600] loss: 0.00017894557376851416
[Epoch 24, Batch 1700] loss: 7.637042239105885e-05
[Epoch 24, Batch 1800] loss: 0.00010837626867928663
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0652
Validation Accuracy: 0.9879
Overfitting: 0.0652
Fold 2 validation loss: 0.0652
Mean validation loss across all folds for Trial 6 is 0.0675 with trial config:  l1: 128, l2: 64, lr: 0.002463768595899745, batch_size: 16
[I 2024-11-21 23:07:49,158] Trial 5 finished with value: 0.06753186186165229 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.002463768595899745, 'batch_size': 16}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 7:
  l1: 128, l2: 64, lr: 0.000132965214572995, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.305379686355591
**STATS for Epoch 1** : 
Average training loss: 0.3516
Average validation loss: 2.3040
Validation Accuracy: 0.0986
Overfitting: 1.9524
Best model saved at epoch 1 with validation loss: 2.3040
[Epoch 2, Batch 100] loss: 2.3037164568901063
**STATS for Epoch 2** : 
Average training loss: 0.3511
Average validation loss: 2.3023
Validation Accuracy: 0.0986
Overfitting: 1.9512
Best model saved at epoch 2 with validation loss: 2.3023
[Epoch 3, Batch 100] loss: 2.302045614719391
**STATS for Epoch 3** : 
Average training loss: 0.3509
Average validation loss: 2.3008
Validation Accuracy: 0.0987
Overfitting: 1.9499
Best model saved at epoch 3 with validation loss: 2.3008
[Epoch 4, Batch 100] loss: 2.300124132633209
**STATS for Epoch 4** : 
Average training loss: 0.3509
Average validation loss: 2.2991
Validation Accuracy: 0.0990
Overfitting: 1.9482
Best model saved at epoch 4 with validation loss: 2.2991
[Epoch 5, Batch 100] loss: 2.2985716366767885
**STATS for Epoch 5** : 
Average training loss: 0.3505
Average validation loss: 2.2975
Validation Accuracy: 0.1002
Overfitting: 1.9470
Best model saved at epoch 5 with validation loss: 2.2975
[Epoch 6, Batch 100] loss: 2.296904354095459
**STATS for Epoch 6** : 
Average training loss: 0.3503
Average validation loss: 2.2957
Validation Accuracy: 0.1022
Overfitting: 1.9454
[I 2024-11-21 23:08:53,445] Trial 6 pruned. 

Selected Hyperparameters for Trial 8:
  l1: 128, l2: 128, lr: 0.00672093005015611, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2118306386470796
[Epoch 1, Batch 200] loss: 0.8483897712826729
[Epoch 1, Batch 300] loss: 0.39675152994692325
[Epoch 1, Batch 400] loss: 0.26107460286468265
[Epoch 1, Batch 500] loss: 0.17727945743128656
[Epoch 1, Batch 600] loss: 0.17589328308589758
[Epoch 1, Batch 700] loss: 0.17032192152924835
[Epoch 1, Batch 800] loss: 0.15509877922013401
[Epoch 1, Batch 900] loss: 0.12024415521882474
**STATS for Epoch 1** : 
Average training loss: 0.0046
Average validation loss: 0.0994
Validation Accuracy: 0.9680
Overfitting: 0.0948
Best model saved at epoch 1 with validation loss: 0.0994
[Epoch 2, Batch 100] loss: 0.09761526968795806
[Epoch 2, Batch 200] loss: 0.09838303198106586
[Epoch 2, Batch 300] loss: 0.09391237811883911
[Epoch 2, Batch 400] loss: 0.08430521195754409
[Epoch 2, Batch 500] loss: 0.10832324317190796
[Epoch 2, Batch 600] loss: 0.08717083213152364
[Epoch 2, Batch 700] loss: 0.07522115148487502
[Epoch 2, Batch 800] loss: 0.08227527327951975
[Epoch 2, Batch 900] loss: 0.08174966534803389
**STATS for Epoch 2** : 
Average training loss: 0.0045
Average validation loss: 0.0904
Validation Accuracy: 0.9726
Overfitting: 0.0858
Best model saved at epoch 2 with validation loss: 0.0904
[Epoch 3, Batch 100] loss: 0.06400070513715037
[Epoch 3, Batch 200] loss: 0.051406031660153534
[Epoch 3, Batch 300] loss: 0.05504612141055986
[Epoch 3, Batch 400] loss: 0.06266339435242116
[Epoch 3, Batch 500] loss: 0.049115352448716294
[Epoch 3, Batch 600] loss: 0.05594892075227108
[Epoch 3, Batch 700] loss: 0.06972384135238827
[Epoch 3, Batch 800] loss: 0.04710969810839742
[Epoch 3, Batch 900] loss: 0.07085886190761811
**STATS for Epoch 3** : 
Average training loss: 0.0027
Average validation loss: 0.0729
Validation Accuracy: 0.9776
Overfitting: 0.0702
Best model saved at epoch 3 with validation loss: 0.0729
[Epoch 4, Batch 100] loss: 0.043765360788675024
[Epoch 4, Batch 200] loss: 0.05019092925125733
[Epoch 4, Batch 300] loss: 0.027719291821704246
[Epoch 4, Batch 400] loss: 0.05302896853536367
[Epoch 4, Batch 500] loss: 0.053432633000193165
[Epoch 4, Batch 600] loss: 0.0627347660594387
[Epoch 4, Batch 700] loss: 0.03539359502959996
[Epoch 4, Batch 800] loss: 0.0539877939633152
[Epoch 4, Batch 900] loss: 0.041767447597230785
**STATS for Epoch 4** : 
Average training loss: 0.0020
Average validation loss: 0.0695
Validation Accuracy: 0.9795
Overfitting: 0.0675
Best model saved at epoch 4 with validation loss: 0.0695
[Epoch 5, Batch 100] loss: 0.03176218025750131
[Epoch 5, Batch 200] loss: 0.027944474459509365
[Epoch 5, Batch 300] loss: 0.02829658037808258
[Epoch 5, Batch 400] loss: 0.040465382031106854
[Epoch 5, Batch 500] loss: 0.04855627063603606
[Epoch 5, Batch 600] loss: 0.03864667259971611
[Epoch 5, Batch 700] loss: 0.03372959406580776
[Epoch 5, Batch 800] loss: 0.02685824542029877
[Epoch 5, Batch 900] loss: 0.03785221255224314
**STATS for Epoch 5** : 
Average training loss: 0.0012
Average validation loss: 0.0669
Validation Accuracy: 0.9815
Overfitting: 0.0657
Best model saved at epoch 5 with validation loss: 0.0669
[Epoch 6, Batch 100] loss: 0.026783489664958325
[Epoch 6, Batch 200] loss: 0.02462086209867266
[Epoch 6, Batch 300] loss: 0.029384528671980662
[Epoch 6, Batch 400] loss: 0.035074237755907234
[Epoch 6, Batch 500] loss: 0.03306193853772129
[Epoch 6, Batch 600] loss: 0.022908748561749234
[Epoch 6, Batch 700] loss: 0.022152731642709114
[Epoch 6, Batch 800] loss: 0.02710368464315252
[Epoch 6, Batch 900] loss: 0.0359921844972996
**STATS for Epoch 6** : 
Average training loss: 0.0011
Average validation loss: 0.0674
Validation Accuracy: 0.9810
Overfitting: 0.0662
[Epoch 7, Batch 100] loss: 0.017491200177391874
[Epoch 7, Batch 200] loss: 0.015752652927658345
[Epoch 7, Batch 300] loss: 0.02520978357846616
[Epoch 7, Batch 400] loss: 0.02347333334535506
[Epoch 7, Batch 500] loss: 0.022026560317972326
[Epoch 7, Batch 600] loss: 0.02393915133085102
[Epoch 7, Batch 700] loss: 0.029226681428299345
[Epoch 7, Batch 800] loss: 0.023063156023490593
[Epoch 7, Batch 900] loss: 0.03449782918192795
**STATS for Epoch 7** : 
Average training loss: 0.0006
Average validation loss: 0.0545
Validation Accuracy: 0.9853
Overfitting: 0.0539
Best model saved at epoch 7 with validation loss: 0.0545
[Epoch 8, Batch 100] loss: 0.012807211250947147
[Epoch 8, Batch 200] loss: 0.018369158869463716
[Epoch 8, Batch 300] loss: 0.024519310970827064
[Epoch 8, Batch 400] loss: 0.021727912509959424
[Epoch 8, Batch 500] loss: 0.03048486801868421
[Epoch 8, Batch 600] loss: 0.021945091214438436
[Epoch 8, Batch 700] loss: 0.014231955813374952
[Epoch 8, Batch 800] loss: 0.030052346258744363
[Epoch 8, Batch 900] loss: 0.015106043681298616
**STATS for Epoch 8** : 
Average training loss: 0.0004
Average validation loss: 0.0544
Validation Accuracy: 0.9857
Overfitting: 0.0539
Best model saved at epoch 8 with validation loss: 0.0544
[Epoch 9, Batch 100] loss: 0.011933259802781322
[Epoch 9, Batch 200] loss: 0.012758586765630752
[Epoch 9, Batch 300] loss: 0.008438447603184613
[Epoch 9, Batch 400] loss: 0.02045648583312868
[Epoch 9, Batch 500] loss: 0.012198166700763978
[Epoch 9, Batch 600] loss: 0.015201853906110046
[Epoch 9, Batch 700] loss: 0.019995334533250572
[Epoch 9, Batch 800] loss: 0.022665590200704175
[Epoch 9, Batch 900] loss: 0.01715127302555629
**STATS for Epoch 9** : 
Average training loss: 0.0010
Average validation loss: 0.0580
Validation Accuracy: 0.9839
Overfitting: 0.0570
[Epoch 10, Batch 100] loss: 0.014963749390772137
[Epoch 10, Batch 200] loss: 0.006417044479148899
[Epoch 10, Batch 300] loss: 0.01773917389637063
[Epoch 10, Batch 400] loss: 0.01912012633321865
[Epoch 10, Batch 500] loss: 0.009797625812825572
[Epoch 10, Batch 600] loss: 0.015263266396032123
[Epoch 10, Batch 700] loss: 0.011733943998442554
[Epoch 10, Batch 800] loss: 0.019066412670290446
[Epoch 10, Batch 900] loss: 0.01653868811074062
**STATS for Epoch 10** : 
Average training loss: 0.0003
Average validation loss: 0.0597
Validation Accuracy: 0.9853
Overfitting: 0.0594
[Epoch 11, Batch 100] loss: 0.013327338065118965
[Epoch 11, Batch 200] loss: 0.00827346067907456
[Epoch 11, Batch 300] loss: 0.016952807321540603
[Epoch 11, Batch 400] loss: 0.009693916841606552
[Epoch 11, Batch 500] loss: 0.005132123361772756
[Epoch 11, Batch 600] loss: 0.010832390108607797
[Epoch 11, Batch 700] loss: 0.010303910560523946
[Epoch 11, Batch 800] loss: 0.017300361689776764
[Epoch 11, Batch 900] loss: 0.012358907746893237
**STATS for Epoch 11** : 
Average training loss: 0.0005
Average validation loss: 0.0687
Validation Accuracy: 0.9837
Overfitting: 0.0681
[Epoch 12, Batch 100] loss: 0.010628149244093948
[Epoch 12, Batch 200] loss: 0.013592057160385593
[Epoch 12, Batch 300] loss: 0.010310433402810303
[Epoch 12, Batch 400] loss: 0.011677411669388675
[Epoch 12, Batch 500] loss: 0.011791395073923922
[Epoch 12, Batch 600] loss: 0.015060899573036295
[Epoch 12, Batch 700] loss: 0.011099335581329797
[Epoch 12, Batch 800] loss: 0.01212163676675118
[Epoch 12, Batch 900] loss: 0.015543686695455108
**STATS for Epoch 12** : 
Average training loss: 0.0002
Average validation loss: 0.0606
Validation Accuracy: 0.9853
Overfitting: 0.0604
[Epoch 13, Batch 100] loss: 0.010204335245398398
[Epoch 13, Batch 200] loss: 0.006858177971516852
[Epoch 13, Batch 300] loss: 0.009160344122974493
[Epoch 13, Batch 400] loss: 0.007988401430657177
[Epoch 13, Batch 500] loss: 0.009205160445571892
[Epoch 13, Batch 600] loss: 0.008998749340541963
[Epoch 13, Batch 700] loss: 0.006697126609906263
[Epoch 13, Batch 800] loss: 0.009730470829890692
[Epoch 13, Batch 900] loss: 0.009252832598874647
**STATS for Epoch 13** : 
Average training loss: 0.0005
Average validation loss: 0.0628
Validation Accuracy: 0.9860
Overfitting: 0.0623
[Epoch 14, Batch 100] loss: 0.0058587384092925274
[Epoch 14, Batch 200] loss: 0.003358090606870974
[Epoch 14, Batch 300] loss: 0.002857430672322607
[Epoch 14, Batch 400] loss: 0.004514110761233496
[Epoch 14, Batch 500] loss: 0.003972804359860902
[Epoch 14, Batch 600] loss: 0.010469876179579956
[Epoch 14, Batch 700] loss: 0.010621491787782702
[Epoch 14, Batch 800] loss: 0.006231651673210763
[Epoch 14, Batch 900] loss: 0.0077749898246179325
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0774
Validation Accuracy: 0.9835
Overfitting: 0.0768
[Epoch 15, Batch 100] loss: 0.013152922259658908
[Epoch 15, Batch 200] loss: 0.012088870408265394
[Epoch 15, Batch 300] loss: 0.007643451029243806
[Epoch 15, Batch 400] loss: 0.0022355526617002398
[Epoch 15, Batch 500] loss: 0.009214094944404679
[Epoch 15, Batch 600] loss: 0.004768706676541115
[Epoch 15, Batch 700] loss: 0.01173232855495371
[Epoch 15, Batch 800] loss: 0.0049479127537301795
[Epoch 15, Batch 900] loss: 0.007223149996630127
**STATS for Epoch 15** : 
Average training loss: 0.0003
Average validation loss: 0.0715
Validation Accuracy: 0.9851
Overfitting: 0.0711
[Epoch 16, Batch 100] loss: 0.005534675296545401
[Epoch 16, Batch 200] loss: 0.0016447596476953663
[Epoch 16, Batch 300] loss: 0.002206777923368577
[Epoch 16, Batch 400] loss: 0.0020929264449171116
[Epoch 16, Batch 500] loss: 0.005428944128815374
[Epoch 16, Batch 600] loss: 0.010110119524251787
[Epoch 16, Batch 700] loss: 0.012447410003444475
[Epoch 16, Batch 800] loss: 0.005597698587765762
[Epoch 16, Batch 900] loss: 0.005093375797774797
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0703
Validation Accuracy: 0.9861
Overfitting: 0.0702
[Epoch 17, Batch 100] loss: 0.0046009515024502436
[Epoch 17, Batch 200] loss: 0.006489625718841125
[Epoch 17, Batch 300] loss: 0.008197585425773469
[Epoch 17, Batch 400] loss: 0.008714589915334726
[Epoch 17, Batch 500] loss: 0.003920171376623784
[Epoch 17, Batch 600] loss: 0.0031619623293727274
[Epoch 17, Batch 700] loss: 0.005751656292568441
[Epoch 17, Batch 800] loss: 0.004093878870717233
[Epoch 17, Batch 900] loss: 0.004343325084157641
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.1157
Validation Accuracy: 0.9780
Overfitting: 0.1153
[Epoch 18, Batch 100] loss: 0.006375441850834136
[Epoch 18, Batch 200] loss: 0.00350704974906094
[Epoch 18, Batch 300] loss: 0.012576100643429981
[Epoch 18, Batch 400] loss: 0.005761938707107106
[Epoch 18, Batch 500] loss: 0.0070759721023932794
[Epoch 18, Batch 600] loss: 0.005806426926701533
[Epoch 18, Batch 700] loss: 0.0024826481066239124
[Epoch 18, Batch 800] loss: 0.0038709183718674467
[Epoch 18, Batch 900] loss: 0.004641101084337081
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0676
Validation Accuracy: 0.9868
Overfitting: 0.0674
[Epoch 19, Batch 100] loss: 0.0022623667959021532
[Epoch 19, Batch 200] loss: 0.0016700976407406642
[Epoch 19, Batch 300] loss: 0.002819852945522996
[Epoch 19, Batch 400] loss: 0.005917845640408359
[Epoch 19, Batch 500] loss: 0.0021043030897487823
[Epoch 19, Batch 600] loss: 0.0021446896513765525
[Epoch 19, Batch 700] loss: 0.001296317463641401
[Epoch 19, Batch 800] loss: 0.0016193215704491592
[Epoch 19, Batch 900] loss: 0.005218227718610251
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0922
Validation Accuracy: 0.9831
Overfitting: 0.0919
[Epoch 20, Batch 100] loss: 0.005184220749028157
[Epoch 20, Batch 200] loss: 0.0016652539313112412
[Epoch 20, Batch 300] loss: 0.002445185711999045
[Epoch 20, Batch 400] loss: 0.0008798818557511367
[Epoch 20, Batch 500] loss: 0.004778419829100287
[Epoch 20, Batch 600] loss: 0.003019621733832025
[Epoch 20, Batch 700] loss: 0.0017570698903769256
[Epoch 20, Batch 800] loss: 0.005745037806514119
[Epoch 20, Batch 900] loss: 0.00900517961549724
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0660
Validation Accuracy: 0.9877
Overfitting: 0.0659
[Epoch 21, Batch 100] loss: 0.0011650577896210733
[Epoch 21, Batch 200] loss: 0.0008508741394632579
[Epoch 21, Batch 300] loss: 0.0007467741715211673
[Epoch 21, Batch 400] loss: 0.0006349796628449766
[Epoch 21, Batch 500] loss: 0.00027033435619912895
[Epoch 21, Batch 600] loss: 0.001382137552194429
[Epoch 21, Batch 700] loss: 0.0011393926824702304
[Epoch 21, Batch 800] loss: 0.000651781140708323
[Epoch 21, Batch 900] loss: 0.0013938294396911033
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0695
Validation Accuracy: 0.9877
Overfitting: 0.0695
[Epoch 22, Batch 100] loss: 0.00018354697671012942
[Epoch 22, Batch 200] loss: 0.0017021798026942746
[Epoch 22, Batch 300] loss: 0.0002515172564901391
[Epoch 22, Batch 400] loss: 0.0005728414703855123
[Epoch 22, Batch 500] loss: 0.000314643245452686
[Epoch 22, Batch 600] loss: 0.0001431510992568974
[Epoch 22, Batch 700] loss: 0.00013534451009709515
[Epoch 22, Batch 800] loss: 0.00042718811098531263
[Epoch 22, Batch 900] loss: 0.00029226486181542553
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0663
Validation Accuracy: 0.9886
Overfitting: 0.0663
[Epoch 23, Batch 100] loss: 0.0001193925139214258
[Epoch 23, Batch 200] loss: 0.0021078802457566324
[Epoch 23, Batch 300] loss: 0.00024222996234055216
[Epoch 23, Batch 400] loss: 0.00015334846213242769
[Epoch 23, Batch 500] loss: 0.00020006541595691375
[Epoch 23, Batch 600] loss: 9.061482934221488e-05
[Epoch 23, Batch 700] loss: 0.00013496188809853038
[Epoch 23, Batch 800] loss: 0.00010881035976098019
[Epoch 23, Batch 900] loss: 0.00010792016286675476
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0661
Validation Accuracy: 0.9892
Overfitting: 0.0661
[Epoch 24, Batch 100] loss: 0.00020070368855829913
[Epoch 24, Batch 200] loss: 7.859430329623996e-05
[Epoch 24, Batch 300] loss: 0.00017665584861638274
[Epoch 24, Batch 400] loss: 5.61473582701999e-05
[Epoch 24, Batch 500] loss: 9.53009687604478e-05
[Epoch 24, Batch 600] loss: 5.501807709264561e-05
[Epoch 24, Batch 700] loss: 6.535702899934881e-05
[Epoch 24, Batch 800] loss: 3.36468463376427e-05
[Epoch 24, Batch 900] loss: 8.66983499537355e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0674
Validation Accuracy: 0.9890
Overfitting: 0.0674
Fold 1 validation loss: 0.0674
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.1146967124938967
[Epoch 1, Batch 200] loss: 0.6258368302881717
[Epoch 1, Batch 300] loss: 0.3015146648138762
[Epoch 1, Batch 400] loss: 0.223286967985332
[Epoch 1, Batch 500] loss: 0.17919734733179213
[Epoch 1, Batch 600] loss: 0.1580231720674783
[Epoch 1, Batch 700] loss: 0.13305271322838963
[Epoch 1, Batch 800] loss: 0.09718092498369515
[Epoch 1, Batch 900] loss: 0.11748491898644715
**STATS for Epoch 1** : 
Average training loss: 0.0044
Average validation loss: 0.1023
Validation Accuracy: 0.9679
Overfitting: 0.0978
Best model saved at epoch 1 with validation loss: 0.1023
[Epoch 2, Batch 100] loss: 0.10599414463154971
[Epoch 2, Batch 200] loss: 0.08188563353847712
[Epoch 2, Batch 300] loss: 0.08738428795943037
[Epoch 2, Batch 400] loss: 0.07652179039316252
[Epoch 2, Batch 500] loss: 0.08158245214959607
[Epoch 2, Batch 600] loss: 0.07114537318702788
[Epoch 2, Batch 700] loss: 0.08210584154119716
[Epoch 2, Batch 800] loss: 0.06926425055717118
[Epoch 2, Batch 900] loss: 0.07957344981143251
**STATS for Epoch 2** : 
Average training loss: 0.0021
Average validation loss: 0.0679
Validation Accuracy: 0.9791
Overfitting: 0.0658
Best model saved at epoch 2 with validation loss: 0.0679
[Epoch 3, Batch 100] loss: 0.04820029183872975
[Epoch 3, Batch 200] loss: 0.0610000179882627
[Epoch 3, Batch 300] loss: 0.06974794953828678
[Epoch 3, Batch 400] loss: 0.05791387059725821
[Epoch 3, Batch 500] loss: 0.04794049283838831
[Epoch 3, Batch 600] loss: 0.04387655382364755
[Epoch 3, Batch 700] loss: 0.06851333937840537
[Epoch 3, Batch 800] loss: 0.05583471267600544
[Epoch 3, Batch 900] loss: 0.05478750861366279
**STATS for Epoch 3** : 
Average training loss: 0.0018
Average validation loss: 0.0592
Validation Accuracy: 0.9818
Overfitting: 0.0574
Best model saved at epoch 3 with validation loss: 0.0592
[Epoch 4, Batch 100] loss: 0.038988440320827066
[Epoch 4, Batch 200] loss: 0.049564024034771136
[Epoch 4, Batch 300] loss: 0.04023998663877137
[Epoch 4, Batch 400] loss: 0.05967776462959591
[Epoch 4, Batch 500] loss: 0.03836270089901518
[Epoch 4, Batch 600] loss: 0.041214428066159596
[Epoch 4, Batch 700] loss: 0.046633229698054494
[Epoch 4, Batch 800] loss: 0.04433597659866791
[Epoch 4, Batch 900] loss: 0.036882404437637885
**STATS for Epoch 4** : 
Average training loss: 0.0014
Average validation loss: 0.0583
Validation Accuracy: 0.9825
Overfitting: 0.0569
Best model saved at epoch 4 with validation loss: 0.0583
[Epoch 5, Batch 100] loss: 0.0319626051747764
[Epoch 5, Batch 200] loss: 0.03196600477327593
[Epoch 5, Batch 300] loss: 0.020538250448807957
[Epoch 5, Batch 400] loss: 0.049346250515809514
[Epoch 5, Batch 500] loss: 0.035024221819185186
[Epoch 5, Batch 600] loss: 0.02954054405548959
[Epoch 5, Batch 700] loss: 0.04780635407150839
[Epoch 5, Batch 800] loss: 0.03886084271740401
[Epoch 5, Batch 900] loss: 0.03202056413298124
**STATS for Epoch 5** : 
Average training loss: 0.0025
Average validation loss: 0.0522
Validation Accuracy: 0.9840
Overfitting: 0.0497
Best model saved at epoch 5 with validation loss: 0.0522
[Epoch 6, Batch 100] loss: 0.026541624483070337
[Epoch 6, Batch 200] loss: 0.027531250136671587
[Epoch 6, Batch 300] loss: 0.025267707897000946
[Epoch 6, Batch 400] loss: 0.023813492225162918
[Epoch 6, Batch 500] loss: 0.025233817180851475
[Epoch 6, Batch 600] loss: 0.022408061714377255
[Epoch 6, Batch 700] loss: 0.02570164497185033
[Epoch 6, Batch 800] loss: 0.038410208417044484
[Epoch 6, Batch 900] loss: 0.024854070505825804
**STATS for Epoch 6** : 
Average training loss: 0.0012
Average validation loss: 0.0594
Validation Accuracy: 0.9827
Overfitting: 0.0581
[Epoch 7, Batch 100] loss: 0.02512542838441732
[Epoch 7, Batch 200] loss: 0.01874828703890671
[Epoch 7, Batch 300] loss: 0.023636839680020786
[Epoch 7, Batch 400] loss: 0.01890770555692143
[Epoch 7, Batch 500] loss: 0.02967222775456321
[Epoch 7, Batch 600] loss: 0.021395531772759567
[Epoch 7, Batch 700] loss: 0.031408220143785
[Epoch 7, Batch 800] loss: 0.031003525991836797
[Epoch 7, Batch 900] loss: 0.029621391724795103
**STATS for Epoch 7** : 
Average training loss: 0.0010
Average validation loss: 0.0584
Validation Accuracy: 0.9844
Overfitting: 0.0574
[Epoch 8, Batch 100] loss: 0.02441257294922252
[Epoch 8, Batch 200] loss: 0.018307413164002355
[Epoch 8, Batch 300] loss: 0.014870998165206402
[Epoch 8, Batch 400] loss: 0.014182015660771867
[Epoch 8, Batch 500] loss: 0.0163509962986609
[Epoch 8, Batch 600] loss: 0.02211111050355612
[Epoch 8, Batch 700] loss: 0.022352451950828255
[Epoch 8, Batch 800] loss: 0.013117692435389471
[Epoch 8, Batch 900] loss: 0.013699986693682149
**STATS for Epoch 8** : 
Average training loss: 0.0007
Average validation loss: 0.0521
Validation Accuracy: 0.9867
Overfitting: 0.0514
Best model saved at epoch 8 with validation loss: 0.0521
[Epoch 9, Batch 100] loss: 0.01888254926801892
[Epoch 9, Batch 200] loss: 0.019523019976440993
[Epoch 9, Batch 300] loss: 0.02113346897109295
[Epoch 9, Batch 400] loss: 0.0168551180948225
[Epoch 9, Batch 500] loss: 0.018354339513789456
[Epoch 9, Batch 600] loss: 0.015237622248532716
[Epoch 9, Batch 700] loss: 0.021085807601230043
[Epoch 9, Batch 800] loss: 0.015203808299265802
[Epoch 9, Batch 900] loss: 0.01838308156612584
**STATS for Epoch 9** : 
Average training loss: 0.0010
Average validation loss: 0.0622
Validation Accuracy: 0.9837
Overfitting: 0.0612
[Epoch 10, Batch 100] loss: 0.016357413999940035
[Epoch 10, Batch 200] loss: 0.01510886899965044
[Epoch 10, Batch 300] loss: 0.011231079610042797
[Epoch 10, Batch 400] loss: 0.014886790079963248
[Epoch 10, Batch 500] loss: 0.01450516949206758
[Epoch 10, Batch 600] loss: 0.01410139971330409
[Epoch 10, Batch 700] loss: 0.01658488230492367
[Epoch 10, Batch 800] loss: 0.017459998508547868
[Epoch 10, Batch 900] loss: 0.016492558244663086
**STATS for Epoch 10** : 
Average training loss: 0.0005
Average validation loss: 0.0667
Validation Accuracy: 0.9820
Overfitting: 0.0663
[Epoch 11, Batch 100] loss: 0.010613237902953187
[Epoch 11, Batch 200] loss: 0.005852169813274486
[Epoch 11, Batch 300] loss: 0.012624686582348658
[Epoch 11, Batch 400] loss: 0.008683831914622716
[Epoch 11, Batch 500] loss: 0.009547109603445278
[Epoch 11, Batch 600] loss: 0.014608410141318019
[Epoch 11, Batch 700] loss: 0.016602322946928327
[Epoch 11, Batch 800] loss: 0.012404704271748414
[Epoch 11, Batch 900] loss: 0.02114811928938252
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0629
Validation Accuracy: 0.9844
Overfitting: 0.0620
[Epoch 12, Batch 100] loss: 0.009035536319188395
[Epoch 12, Batch 200] loss: 0.009774491919361026
[Epoch 12, Batch 300] loss: 0.009255993437318467
[Epoch 12, Batch 400] loss: 0.010370643163878413
[Epoch 12, Batch 500] loss: 0.010904560923672762
[Epoch 12, Batch 600] loss: 0.014074784399053897
[Epoch 12, Batch 700] loss: 0.009134336614220046
[Epoch 12, Batch 800] loss: 0.014743703207304861
[Epoch 12, Batch 900] loss: 0.020239582875365158
**STATS for Epoch 12** : 
Average training loss: 0.0009
Average validation loss: 0.0579
Validation Accuracy: 0.9855
Overfitting: 0.0570
[Epoch 13, Batch 100] loss: 0.012390221203431792
[Epoch 13, Batch 200] loss: 0.010176916363393502
[Epoch 13, Batch 300] loss: 0.007548391635946245
[Epoch 13, Batch 400] loss: 0.009010706327640037
[Epoch 13, Batch 500] loss: 0.0063508300236435385
[Epoch 13, Batch 600] loss: 0.007518779091396937
[Epoch 13, Batch 700] loss: 0.013194009676499262
[Epoch 13, Batch 800] loss: 0.008568819432430246
[Epoch 13, Batch 900] loss: 0.018427598497783037
**STATS for Epoch 13** : 
Average training loss: 0.0005
Average validation loss: 0.0585
Validation Accuracy: 0.9857
Overfitting: 0.0580
[Epoch 14, Batch 100] loss: 0.003038509872569648
[Epoch 14, Batch 200] loss: 0.0040655388280060835
[Epoch 14, Batch 300] loss: 0.007885608462297569
[Epoch 14, Batch 400] loss: 0.008245286971207405
[Epoch 14, Batch 500] loss: 0.011829003716461556
[Epoch 14, Batch 600] loss: 0.006535026824494707
[Epoch 14, Batch 700] loss: 0.008715482785419226
[Epoch 14, Batch 800] loss: 0.006159415829688442
[Epoch 14, Batch 900] loss: 0.013089066113939224
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0676
Validation Accuracy: 0.9839
Overfitting: 0.0671
[Epoch 15, Batch 100] loss: 0.01141483836050611
[Epoch 15, Batch 200] loss: 0.006739781349656368
[Epoch 15, Batch 300] loss: 0.006484552082652044
[Epoch 15, Batch 400] loss: 0.005222649458847286
[Epoch 15, Batch 500] loss: 0.012371037307311782
[Epoch 15, Batch 600] loss: 0.010390165516146226
[Epoch 15, Batch 700] loss: 0.010642995548278123
[Epoch 15, Batch 800] loss: 0.007762487676995988
[Epoch 15, Batch 900] loss: 0.017299297144936644
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0563
Validation Accuracy: 0.9875
Overfitting: 0.0558
[Epoch 16, Batch 100] loss: 0.0066175333713772485
[Epoch 16, Batch 200] loss: 0.004628489679627137
[Epoch 16, Batch 300] loss: 0.004439037196127629
[Epoch 16, Batch 400] loss: 0.005963081308818801
[Epoch 16, Batch 500] loss: 0.005814334864789998
[Epoch 16, Batch 600] loss: 0.006104437520098145
[Epoch 16, Batch 700] loss: 0.008286676631934142
[Epoch 16, Batch 800] loss: 0.006730839662102426
[Epoch 16, Batch 900] loss: 0.007003271174253314
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0722
Validation Accuracy: 0.9842
Overfitting: 0.0718
[Epoch 17, Batch 100] loss: 0.0017561553215375625
[Epoch 17, Batch 200] loss: 0.0028678453215434272
[Epoch 17, Batch 300] loss: 0.0041700282523343905
[Epoch 17, Batch 400] loss: 0.004105182729293233
[Epoch 17, Batch 500] loss: 0.006653121947138061
[Epoch 17, Batch 600] loss: 0.007776178006799199
[Epoch 17, Batch 700] loss: 0.011705405448572037
[Epoch 17, Batch 800] loss: 0.012653524415833317
[Epoch 17, Batch 900] loss: 0.010739653225746224
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0612
Validation Accuracy: 0.9872
Overfitting: 0.0609
[Epoch 18, Batch 100] loss: 0.0032561258064242793
[Epoch 18, Batch 200] loss: 0.0024211450102296795
[Epoch 18, Batch 300] loss: 0.004882360507724499
[Epoch 18, Batch 400] loss: 0.004718948921500896
[Epoch 18, Batch 500] loss: 0.002726310239880263
[Epoch 18, Batch 600] loss: 0.0012395962067517986
[Epoch 18, Batch 700] loss: 0.0030465845342228805
[Epoch 18, Batch 800] loss: 0.007640042423837486
[Epoch 18, Batch 900] loss: 0.009917962671909777
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0634
Validation Accuracy: 0.9872
Overfitting: 0.0633
[Epoch 19, Batch 100] loss: 0.0017912108453795384
[Epoch 19, Batch 200] loss: 0.0011211398563060015
[Epoch 19, Batch 300] loss: 0.0009477842568335859
[Epoch 19, Batch 400] loss: 0.000984379846504737
[Epoch 19, Batch 500] loss: 0.0005220932004215229
[Epoch 19, Batch 600] loss: 0.000800422641453622
[Epoch 19, Batch 700] loss: 0.0023782986021735654
[Epoch 19, Batch 800] loss: 0.0008366203798487959
[Epoch 19, Batch 900] loss: 0.0007862655747518943
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0802
Validation Accuracy: 0.9844
Overfitting: 0.0801
[Epoch 20, Batch 100] loss: 0.001086474564402522
[Epoch 20, Batch 200] loss: 0.000214089091236076
[Epoch 20, Batch 300] loss: 0.0020275221950426213
[Epoch 20, Batch 400] loss: 0.0031372422093868123
[Epoch 20, Batch 500] loss: 0.0001731826501828948
[Epoch 20, Batch 600] loss: 0.00035034158961224195
[Epoch 20, Batch 700] loss: 0.0005614517862879609
[Epoch 20, Batch 800] loss: 0.00045558540770969104
[Epoch 20, Batch 900] loss: 0.0009713295462358573
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0618
Validation Accuracy: 0.9884
Overfitting: 0.0618
[Epoch 21, Batch 100] loss: 0.0004726643790998253
[Epoch 21, Batch 200] loss: 0.00021854304857114924
[Epoch 21, Batch 300] loss: 0.00018805974306815187
[Epoch 21, Batch 400] loss: 0.00018971994502081202
[Epoch 21, Batch 500] loss: 0.00018771867255201969
[Epoch 21, Batch 600] loss: 0.0005065373524728756
[Epoch 21, Batch 700] loss: 0.00012494204101109573
[Epoch 21, Batch 800] loss: 0.0002928111700604319
[Epoch 21, Batch 900] loss: 0.00010637068639766767
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0629
Validation Accuracy: 0.9884
Overfitting: 0.0628
[Epoch 22, Batch 100] loss: 0.0001131414730326874
[Epoch 22, Batch 200] loss: 0.00013648441003361712
[Epoch 22, Batch 300] loss: 0.00019284252007713222
[Epoch 22, Batch 400] loss: 0.0001290975703705044
[Epoch 22, Batch 500] loss: 9.53226010839181e-05
[Epoch 22, Batch 600] loss: 0.00016618261050058925
[Epoch 22, Batch 700] loss: 0.0001591202622028387
[Epoch 22, Batch 800] loss: 6.64171397625779e-05
[Epoch 22, Batch 900] loss: 0.0001171725237280441
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0633
Validation Accuracy: 0.9889
Overfitting: 0.0633
[Epoch 23, Batch 100] loss: 4.739430799542532e-05
[Epoch 23, Batch 200] loss: 8.150804377724086e-05
[Epoch 23, Batch 300] loss: 7.076125411535016e-05
[Epoch 23, Batch 400] loss: 7.956235033126368e-05
[Epoch 23, Batch 500] loss: 0.00011177832293615353
[Epoch 23, Batch 600] loss: 8.101291912252507e-05
[Epoch 23, Batch 700] loss: 8.313674574573327e-05
[Epoch 23, Batch 800] loss: 0.00016549861256578424
[Epoch 23, Batch 900] loss: 0.00010931291418907917
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0647
Validation Accuracy: 0.9892
Overfitting: 0.0647
[Epoch 24, Batch 100] loss: 5.587409029196078e-05
[Epoch 24, Batch 200] loss: 4.8451851339272876e-05
[Epoch 24, Batch 300] loss: 0.00014995574436191817
[Epoch 24, Batch 400] loss: 5.410428376976029e-05
[Epoch 24, Batch 500] loss: 0.00011299893001815775
[Epoch 24, Batch 600] loss: 0.00010088583367303671
[Epoch 24, Batch 700] loss: 5.7809774488530866e-05
[Epoch 24, Batch 800] loss: 8.417504563389411e-05
[Epoch 24, Batch 900] loss: 5.653718829551124e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0656
Validation Accuracy: 0.9892
Overfitting: 0.0656
Fold 2 validation loss: 0.0656
Mean validation loss across all folds for Trial 8 is 0.0665 with trial config:  l1: 128, l2: 128, lr: 0.00672093005015611, batch_size: 32
[I 2024-11-21 23:18:50,747] Trial 7 finished with value: 0.06647006289337519 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.00672093005015611, 'batch_size': 32}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 9:
  l1: 128, l2: 128, lr: 2.8450125275404295e-05, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.30390230178833
[Epoch 1, Batch 200] loss: 2.3047967958450317
[Epoch 1, Batch 300] loss: 2.3053224992752077
[Epoch 1, Batch 400] loss: 2.304032804965973
[Epoch 1, Batch 500] loss: 2.302455339431763
[Epoch 1, Batch 600] loss: 2.3027037882804873
[Epoch 1, Batch 700] loss: 2.3023449778556824
[Epoch 1, Batch 800] loss: 2.3041405153274535
[Epoch 1, Batch 900] loss: 2.3030505681037905
[Epoch 1, Batch 1000] loss: 2.3036886405944825
[Epoch 1, Batch 1100] loss: 2.300893063545227
[Epoch 1, Batch 1200] loss: 2.3015994453430175
[Epoch 1, Batch 1300] loss: 2.3001483845710755
[Epoch 1, Batch 1400] loss: 2.304106984138489
[Epoch 1, Batch 1500] loss: 2.3008134841918944
[Epoch 1, Batch 1600] loss: 2.298779926300049
[Epoch 1, Batch 1700] loss: 2.2998457527160645
[Epoch 1, Batch 1800] loss: 2.2993971514701843
**STATS for Epoch 1** : 
Average training loss: 0.0920
Average validation loss: 2.2994
Validation Accuracy: 0.1605
Overfitting: 2.2074
Best model saved at epoch 1 with validation loss: 2.2994
[Epoch 2, Batch 100] loss: 2.296446614265442
[Epoch 2, Batch 200] loss: 2.2996888160705566
[Epoch 2, Batch 300] loss: 2.2998014211654665
[Epoch 2, Batch 400] loss: 2.29905953168869
[Epoch 2, Batch 500] loss: 2.2969057512283326
[Epoch 2, Batch 600] loss: 2.2967803382873537
[Epoch 2, Batch 700] loss: 2.2984184503555296
[Epoch 2, Batch 800] loss: 2.296261944770813
[Epoch 2, Batch 900] loss: 2.2964167261123656
[Epoch 2, Batch 1000] loss: 2.2951377916336058
[Epoch 2, Batch 1100] loss: 2.294586591720581
[Epoch 2, Batch 1200] loss: 2.2934172463417055
[Epoch 2, Batch 1300] loss: 2.2942074084281923
[Epoch 2, Batch 1400] loss: 2.2942700672149656
[Epoch 2, Batch 1500] loss: 2.2934912610054017
[Epoch 2, Batch 1600] loss: 2.2941179728507994
[Epoch 2, Batch 1700] loss: 2.292241768836975
[Epoch 2, Batch 1800] loss: 2.2932564043998718
**STATS for Epoch 2** : 
Average training loss: 0.0916
Average validation loss: 2.2920
Validation Accuracy: 0.2185
Overfitting: 2.2004
Best model saved at epoch 2 with validation loss: 2.2920
[Epoch 3, Batch 100] loss: 2.291944580078125
[Epoch 3, Batch 200] loss: 2.2912781643867492
[Epoch 3, Batch 300] loss: 2.290555124282837
[Epoch 3, Batch 400] loss: 2.2916136479377744
[Epoch 3, Batch 500] loss: 2.2907309627532957
[Epoch 3, Batch 600] loss: 2.2881685948371886
[Epoch 3, Batch 700] loss: 2.286976180076599
[Epoch 3, Batch 800] loss: 2.2865806674957274
[Epoch 3, Batch 900] loss: 2.2868393087387084
[Epoch 3, Batch 1000] loss: 2.2861957144737244
[Epoch 3, Batch 1100] loss: 2.28729900598526
[Epoch 3, Batch 1200] loss: 2.285591700077057
[Epoch 3, Batch 1300] loss: 2.286992030143738
[Epoch 3, Batch 1400] loss: 2.2852084612846375
[Epoch 3, Batch 1500] loss: 2.285113832950592
[Epoch 3, Batch 1600] loss: 2.2841037726402282
[Epoch 3, Batch 1700] loss: 2.281189751625061
[Epoch 3, Batch 1800] loss: 2.2809720730781553
**STATS for Epoch 3** : 
Average training loss: 0.0913
Average validation loss: 2.2816
Validation Accuracy: 0.2523
Overfitting: 2.1904
Best model saved at epoch 3 with validation loss: 2.2816
[Epoch 4, Batch 100] loss: 2.2815140438079835
[Epoch 4, Batch 200] loss: 2.2813080763816833
[Epoch 4, Batch 300] loss: 2.2782927417755126
[Epoch 4, Batch 400] loss: 2.278493685722351
[Epoch 4, Batch 500] loss: 2.2780565285682677
[Epoch 4, Batch 600] loss: 2.2771033525466917
[Epoch 4, Batch 700] loss: 2.278448646068573
[Epoch 4, Batch 800] loss: 2.2751719045639036
[Epoch 4, Batch 900] loss: 2.276007442474365
[Epoch 4, Batch 1000] loss: 2.275101215839386
[Epoch 4, Batch 1100] loss: 2.2720560240745544
[Epoch 4, Batch 1200] loss: 2.270531928539276
[Epoch 4, Batch 1300] loss: 2.2716617941856385
[Epoch 4, Batch 1400] loss: 2.2702484011650084
[Epoch 4, Batch 1500] loss: 2.2682767033576967
[Epoch 4, Batch 1600] loss: 2.2702638602256773
[Epoch 4, Batch 1700] loss: 2.2674392104148864
[Epoch 4, Batch 1800] loss: 2.265923137664795
**STATS for Epoch 4** : 
Average training loss: 0.0905
Average validation loss: 2.2648
Validation Accuracy: 0.2875
Overfitting: 2.1743
Best model saved at epoch 4 with validation loss: 2.2648
[Epoch 5, Batch 100] loss: 2.260574414730072
[Epoch 5, Batch 200] loss: 2.26001877784729
[Epoch 5, Batch 300] loss: 2.2618371438980103
[Epoch 5, Batch 400] loss: 2.2586567878723143
[Epoch 5, Batch 500] loss: 2.2597038316726685
[Epoch 5, Batch 600] loss: 2.256508855819702
[Epoch 5, Batch 700] loss: 2.2562632179260254
[Epoch 5, Batch 800] loss: 2.254537212848663
[Epoch 5, Batch 900] loss: 2.2525771117210387
[Epoch 5, Batch 1000] loss: 2.250995490550995
[Epoch 5, Batch 1100] loss: 2.249351432323456
[Epoch 5, Batch 1200] loss: 2.2471350049972534
[Epoch 5, Batch 1300] loss: 2.244653012752533
[Epoch 5, Batch 1400] loss: 2.24387903213501
[Epoch 5, Batch 1500] loss: 2.2411067366600035
[Epoch 5, Batch 1600] loss: 2.239536509513855
[Epoch 5, Batch 1700] loss: 2.236479468345642
[Epoch 5, Batch 1800] loss: 2.2338074707984923
**STATS for Epoch 5** : 
Average training loss: 0.0893
Average validation loss: 2.2303
Validation Accuracy: 0.4353
Overfitting: 2.1410
Best model saved at epoch 5 with validation loss: 2.2303
[Epoch 6, Batch 100] loss: 2.2302842140197754
[Epoch 6, Batch 200] loss: 2.230542171001434
[Epoch 6, Batch 300] loss: 2.2219865250587465
[Epoch 6, Batch 400] loss: 2.2203966784477234
[Epoch 6, Batch 500] loss: 2.213879826068878
[Epoch 6, Batch 600] loss: 2.2100513911247255
[Epoch 6, Batch 700] loss: 2.203559455871582
[Epoch 6, Batch 800] loss: 2.2034418058395384
[Epoch 6, Batch 900] loss: 2.1998200464248656
[Epoch 6, Batch 1000] loss: 2.195917947292328
[Epoch 6, Batch 1100] loss: 2.194213120937347
[Epoch 6, Batch 1200] loss: 2.1864277291297913
[Epoch 6, Batch 1300] loss: 2.1815345644950868
[Epoch 6, Batch 1400] loss: 2.1741407895088196
[Epoch 6, Batch 1500] loss: 2.1718292331695555
[Epoch 6, Batch 1600] loss: 2.1618075275421145
[Epoch 6, Batch 1700] loss: 2.1601124000549317
[Epoch 6, Batch 1800] loss: 2.148516833782196
**STATS for Epoch 6** : 
Average training loss: 0.0856
Average validation loss: 2.1378
Validation Accuracy: 0.4801
Overfitting: 2.0523
[I 2024-11-21 23:20:17,528] Trial 8 pruned. 

Selected Hyperparameters for Trial 10:
  l1: 256, l2: 128, lr: 0.007255685482622854, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.9605365705490112
[Epoch 1, Batch 200] loss: 0.40063891649246214
[Epoch 1, Batch 300] loss: 0.19725657686591147
[Epoch 1, Batch 400] loss: 0.17744366448372603
**STATS for Epoch 1** : 
Average training loss: 0.0213
Average validation loss: 0.1174
Validation Accuracy: 0.9634
Overfitting: 0.0961
Best model saved at epoch 1 with validation loss: 0.1174
[Epoch 2, Batch 100] loss: 0.11849918024614453
[Epoch 2, Batch 200] loss: 0.10099089933559298
[Epoch 2, Batch 300] loss: 0.09775262301787734
[Epoch 2, Batch 400] loss: 0.09241534155793488
**STATS for Epoch 2** : 
Average training loss: 0.0117
Average validation loss: 0.0814
Validation Accuracy: 0.9745
Overfitting: 0.0697
Best model saved at epoch 2 with validation loss: 0.0814
[Epoch 3, Batch 100] loss: 0.07118275090586394
[Epoch 3, Batch 200] loss: 0.0747171625494957
[Epoch 3, Batch 300] loss: 0.060793378041125834
[Epoch 3, Batch 400] loss: 0.06903555096127093
**STATS for Epoch 3** : 
Average training loss: 0.0099
Average validation loss: 0.0831
Validation Accuracy: 0.9739
Overfitting: 0.0732
[Epoch 4, Batch 100] loss: 0.05510073836194351
[Epoch 4, Batch 200] loss: 0.042712314850650725
[Epoch 4, Batch 300] loss: 0.06141719721490517
[Epoch 4, Batch 400] loss: 0.0496609044377692
**STATS for Epoch 4** : 
Average training loss: 0.0075
Average validation loss: 0.0716
Validation Accuracy: 0.9787
Overfitting: 0.0641
Best model saved at epoch 4 with validation loss: 0.0716
[Epoch 5, Batch 100] loss: 0.03756150506436825
[Epoch 5, Batch 200] loss: 0.04379228700883687
[Epoch 5, Batch 300] loss: 0.04533886531833559
[Epoch 5, Batch 400] loss: 0.04316079709911719
**STATS for Epoch 5** : 
Average training loss: 0.0056
Average validation loss: 0.0593
Validation Accuracy: 0.9814
Overfitting: 0.0536
Best model saved at epoch 5 with validation loss: 0.0593
[Epoch 6, Batch 100] loss: 0.030628685830160974
[Epoch 6, Batch 200] loss: 0.02999801202560775
[Epoch 6, Batch 300] loss: 0.03506237717054319
[Epoch 6, Batch 400] loss: 0.03285595217370428
**STATS for Epoch 6** : 
Average training loss: 0.0050
Average validation loss: 0.0588
Validation Accuracy: 0.9828
Overfitting: 0.0538
Best model saved at epoch 6 with validation loss: 0.0588
[Epoch 7, Batch 100] loss: 0.022117930331151
[Epoch 7, Batch 200] loss: 0.028920650955697055
[Epoch 7, Batch 300] loss: 0.03342422326968517
[Epoch 7, Batch 400] loss: 0.03464717554685194
**STATS for Epoch 7** : 
Average training loss: 0.0030
Average validation loss: 0.0649
Validation Accuracy: 0.9813
Overfitting: 0.0618
[Epoch 8, Batch 100] loss: 0.01767403928999556
[Epoch 8, Batch 200] loss: 0.0221591575385537
[Epoch 8, Batch 300] loss: 0.019705880102701485
[Epoch 8, Batch 400] loss: 0.026277714335301426
**STATS for Epoch 8** : 
Average training loss: 0.0053
Average validation loss: 0.0685
Validation Accuracy: 0.9812
Overfitting: 0.0632
[Epoch 9, Batch 100] loss: 0.023042135977884754
[Epoch 9, Batch 200] loss: 0.01665702034777496
[Epoch 9, Batch 300] loss: 0.01517975295020733
[Epoch 9, Batch 400] loss: 0.025038656731776427
**STATS for Epoch 9** : 
Average training loss: 0.0024
Average validation loss: 0.0694
Validation Accuracy: 0.9828
Overfitting: 0.0670
[Epoch 10, Batch 100] loss: 0.015680110834691733
[Epoch 10, Batch 200] loss: 0.01898541187576484
[Epoch 10, Batch 300] loss: 0.012343751797743607
[Epoch 10, Batch 400] loss: 0.016298602464521538
**STATS for Epoch 10** : 
Average training loss: 0.0031
Average validation loss: 0.0590
Validation Accuracy: 0.9848
Overfitting: 0.0559
[Epoch 11, Batch 100] loss: 0.00826849539167597
[Epoch 11, Batch 200] loss: 0.01107557408453431
[Epoch 11, Batch 300] loss: 0.015056083177041728
[Epoch 11, Batch 400] loss: 0.012627807468088576
**STATS for Epoch 11** : 
Average training loss: 0.0013
Average validation loss: 0.0626
Validation Accuracy: 0.9839
Overfitting: 0.0613
[Epoch 12, Batch 100] loss: 0.0077407551156647965
[Epoch 12, Batch 200] loss: 0.009945810158824316
[Epoch 12, Batch 300] loss: 0.0076339269781601615
[Epoch 12, Batch 400] loss: 0.014306974122009706
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0751
Validation Accuracy: 0.9827
Overfitting: 0.0740
[Epoch 13, Batch 100] loss: 0.012111206112313084
[Epoch 13, Batch 200] loss: 0.006283431565025239
[Epoch 13, Batch 300] loss: 0.009586257017072058
[Epoch 13, Batch 400] loss: 0.010765158587164479
**STATS for Epoch 13** : 
Average training loss: 0.0013
Average validation loss: 0.0647
Validation Accuracy: 0.9851
Overfitting: 0.0634
[Epoch 14, Batch 100] loss: 0.005454863154172926
[Epoch 14, Batch 200] loss: 0.007011340850804118
[Epoch 14, Batch 300] loss: 0.004385789810003189
[Epoch 14, Batch 400] loss: 0.0028234421740671676
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0707
Validation Accuracy: 0.9837
Overfitting: 0.0701
[Epoch 15, Batch 100] loss: 0.00775241151024602
[Epoch 15, Batch 200] loss: 0.009939575313910608
[Epoch 15, Batch 300] loss: 0.006495510514723719
[Epoch 15, Batch 400] loss: 0.007298341162932047
**STATS for Epoch 15** : 
Average training loss: 0.0019
Average validation loss: 0.0833
Validation Accuracy: 0.9822
Overfitting: 0.0814
[Epoch 16, Batch 100] loss: 0.010337343007558958
[Epoch 16, Batch 200] loss: 0.007755698484761524
[Epoch 16, Batch 300] loss: 0.003384718209199491
[Epoch 16, Batch 400] loss: 0.003999300393425074
**STATS for Epoch 16** : 
Average training loss: 0.0008
Average validation loss: 0.0671
Validation Accuracy: 0.9858
Overfitting: 0.0663
[Epoch 17, Batch 100] loss: 0.003725010705220484
[Epoch 17, Batch 200] loss: 0.002711232371148071
[Epoch 17, Batch 300] loss: 0.0021603093390876894
[Epoch 17, Batch 400] loss: 0.0033668624624351652
**STATS for Epoch 17** : 
Average training loss: 0.0012
Average validation loss: 0.0634
Validation Accuracy: 0.9862
Overfitting: 0.0623
[Epoch 18, Batch 100] loss: 0.00407773305988485
[Epoch 18, Batch 200] loss: 0.0038377451318865495
[Epoch 18, Batch 300] loss: 0.0012453134593488357
[Epoch 18, Batch 400] loss: 0.002210097246038458
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0581
Validation Accuracy: 0.9883
Overfitting: 0.0580
Best model saved at epoch 18 with validation loss: 0.0581
[Epoch 19, Batch 100] loss: 0.0004591523832505118
[Epoch 19, Batch 200] loss: 0.0008467779922102637
[Epoch 19, Batch 300] loss: 0.0008478725776058127
[Epoch 19, Batch 400] loss: 0.0016495489598128189
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0603
Validation Accuracy: 0.9877
Overfitting: 0.0598
[Epoch 20, Batch 100] loss: 0.0008695662367790647
[Epoch 20, Batch 200] loss: 0.0005828072665781292
[Epoch 20, Batch 300] loss: 0.00043376676097977906
[Epoch 20, Batch 400] loss: 0.0013319716104388136
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0633
Validation Accuracy: 0.9881
Overfitting: 0.0630
[Epoch 21, Batch 100] loss: 0.0006145481465046032
[Epoch 21, Batch 200] loss: 0.0005146645630725289
[Epoch 21, Batch 300] loss: 0.001120965782906751
[Epoch 21, Batch 400] loss: 0.0010850227023456683
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0636
Validation Accuracy: 0.9875
Overfitting: 0.0635
[Epoch 22, Batch 100] loss: 0.00043031257731854564
[Epoch 22, Batch 200] loss: 0.0007968641559455137
[Epoch 22, Batch 300] loss: 0.0005937245255836388
[Epoch 22, Batch 400] loss: 0.00023692554198760264
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0667
Validation Accuracy: 0.9878
Overfitting: 0.0666
[Epoch 23, Batch 100] loss: 0.00029780356313494847
[Epoch 23, Batch 200] loss: 0.0006455789527944944
[Epoch 23, Batch 300] loss: 0.0002947763395650327
[Epoch 23, Batch 400] loss: 0.0003771045930170658
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0660
Validation Accuracy: 0.9882
Overfitting: 0.0659
[Epoch 24, Batch 100] loss: 0.000262794698048765
[Epoch 24, Batch 200] loss: 0.0003461026909485554
[Epoch 24, Batch 300] loss: 0.0002128848027643926
[Epoch 24, Batch 400] loss: 0.00016855735186737774
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0661
Validation Accuracy: 0.9884
Overfitting: 0.0660
Fold 1 validation loss: 0.0661
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.8480440002679825
[Epoch 1, Batch 200] loss: 0.39745161421597003
[Epoch 1, Batch 300] loss: 0.21613419070839882
[Epoch 1, Batch 400] loss: 0.1753480600565672
**STATS for Epoch 1** : 
Average training loss: 0.0196
Average validation loss: 0.1313
Validation Accuracy: 0.9592
Overfitting: 0.1116
Best model saved at epoch 1 with validation loss: 0.1313
[Epoch 2, Batch 100] loss: 0.12011702271178365
[Epoch 2, Batch 200] loss: 0.10771892219781876
[Epoch 2, Batch 300] loss: 0.10364166047424078
[Epoch 2, Batch 400] loss: 0.08982107204385102
**STATS for Epoch 2** : 
Average training loss: 0.0118
Average validation loss: 0.0784
Validation Accuracy: 0.9757
Overfitting: 0.0666
Best model saved at epoch 2 with validation loss: 0.0784
[Epoch 3, Batch 100] loss: 0.07632003325037658
[Epoch 3, Batch 200] loss: 0.07364141777157783
[Epoch 3, Batch 300] loss: 0.0751299147401005
[Epoch 3, Batch 400] loss: 0.0556723810499534
**STATS for Epoch 3** : 
Average training loss: 0.0111
Average validation loss: 0.0661
Validation Accuracy: 0.9793
Overfitting: 0.0550
Best model saved at epoch 3 with validation loss: 0.0661
[Epoch 4, Batch 100] loss: 0.05325186723843217
[Epoch 4, Batch 200] loss: 0.053354835864156486
[Epoch 4, Batch 300] loss: 0.051617501685395833
[Epoch 4, Batch 400] loss: 0.04636273168493062
**STATS for Epoch 4** : 
Average training loss: 0.0074
Average validation loss: 0.0615
Validation Accuracy: 0.9816
Overfitting: 0.0541
Best model saved at epoch 4 with validation loss: 0.0615
[Epoch 5, Batch 100] loss: 0.03787476875120774
[Epoch 5, Batch 200] loss: 0.04472597117768601
[Epoch 5, Batch 300] loss: 0.05814866575412452
[Epoch 5, Batch 400] loss: 0.040346231549046936
**STATS for Epoch 5** : 
Average training loss: 0.0063
Average validation loss: 0.0554
Validation Accuracy: 0.9829
Overfitting: 0.0491
Best model saved at epoch 5 with validation loss: 0.0554
[Epoch 6, Batch 100] loss: 0.030571382213383912
[Epoch 6, Batch 200] loss: 0.03530744723044336
[Epoch 6, Batch 300] loss: 0.0315694212471135
[Epoch 6, Batch 400] loss: 0.035936568126780914
**STATS for Epoch 6** : 
Average training loss: 0.0050
Average validation loss: 0.0545
Validation Accuracy: 0.9839
Overfitting: 0.0495
Best model saved at epoch 6 with validation loss: 0.0545
[Epoch 7, Batch 100] loss: 0.02526920628210064
[Epoch 7, Batch 200] loss: 0.029349903503316455
[Epoch 7, Batch 300] loss: 0.029865830916096455
[Epoch 7, Batch 400] loss: 0.029773304687114432
**STATS for Epoch 7** : 
Average training loss: 0.0040
Average validation loss: 0.0547
Validation Accuracy: 0.9837
Overfitting: 0.0506
[Epoch 8, Batch 100] loss: 0.018043112717568876
[Epoch 8, Batch 200] loss: 0.019234962788177653
[Epoch 8, Batch 300] loss: 0.02793704835930839
[Epoch 8, Batch 400] loss: 0.03294334498263197
**STATS for Epoch 8** : 
Average training loss: 0.0049
Average validation loss: 0.0534
Validation Accuracy: 0.9841
Overfitting: 0.0485
Best model saved at epoch 8 with validation loss: 0.0534
[Epoch 9, Batch 100] loss: 0.020012073933321516
[Epoch 9, Batch 200] loss: 0.022140227213385516
[Epoch 9, Batch 300] loss: 0.027205137886921874
[Epoch 9, Batch 400] loss: 0.022475909438799135
**STATS for Epoch 9** : 
Average training loss: 0.0028
Average validation loss: 0.0581
Validation Accuracy: 0.9838
Overfitting: 0.0553
[Epoch 10, Batch 100] loss: 0.01573677735985257
[Epoch 10, Batch 200] loss: 0.02065945142385317
[Epoch 10, Batch 300] loss: 0.020101057721331018
[Epoch 10, Batch 400] loss: 0.02049389177118428
**STATS for Epoch 10** : 
Average training loss: 0.0027
Average validation loss: 0.0513
Validation Accuracy: 0.9855
Overfitting: 0.0487
Best model saved at epoch 10 with validation loss: 0.0513
[Epoch 11, Batch 100] loss: 0.01266678358631907
[Epoch 11, Batch 200] loss: 0.012157237719220575
[Epoch 11, Batch 300] loss: 0.012350914554699556
[Epoch 11, Batch 400] loss: 0.015035812892965622
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0567
Validation Accuracy: 0.9850
Overfitting: 0.0550
[Epoch 12, Batch 100] loss: 0.01133938584884163
[Epoch 12, Batch 200] loss: 0.009175753729541611
[Epoch 12, Batch 300] loss: 0.010458982314448804
[Epoch 12, Batch 400] loss: 0.02380272088747006
**STATS for Epoch 12** : 
Average training loss: 0.0021
Average validation loss: 0.0574
Validation Accuracy: 0.9840
Overfitting: 0.0553
[Epoch 13, Batch 100] loss: 0.013129028357216157
[Epoch 13, Batch 200] loss: 0.016251862567442002
[Epoch 13, Batch 300] loss: 0.010980582899210277
[Epoch 13, Batch 400] loss: 0.012511567521069083
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0561
Validation Accuracy: 0.9866
Overfitting: 0.0550
[Epoch 14, Batch 100] loss: 0.009495859473681777
[Epoch 14, Batch 200] loss: 0.006973292873808532
[Epoch 14, Batch 300] loss: 0.010116732770547969
[Epoch 14, Batch 400] loss: 0.010265999449766241
**STATS for Epoch 14** : 
Average training loss: 0.0021
Average validation loss: 0.0496
Validation Accuracy: 0.9873
Overfitting: 0.0476
Best model saved at epoch 14 with validation loss: 0.0496
[Epoch 15, Batch 100] loss: 0.00544706719876558
[Epoch 15, Batch 200] loss: 0.010300479044599343
[Epoch 15, Batch 300] loss: 0.005840967563199228
[Epoch 15, Batch 400] loss: 0.0064793378148169725
**STATS for Epoch 15** : 
Average training loss: 0.0013
Average validation loss: 0.0530
Validation Accuracy: 0.9871
Overfitting: 0.0518
[Epoch 16, Batch 100] loss: 0.0044223249485548875
[Epoch 16, Batch 200] loss: 0.006564796973761986
[Epoch 16, Batch 300] loss: 0.0032365626570208406
[Epoch 16, Batch 400] loss: 0.004583619425429788
**STATS for Epoch 16** : 
Average training loss: 0.0008
Average validation loss: 0.0561
Validation Accuracy: 0.9870
Overfitting: 0.0553
[Epoch 17, Batch 100] loss: 0.0036690137686309753
[Epoch 17, Batch 200] loss: 0.004506962467839912
[Epoch 17, Batch 300] loss: 0.006875745196775824
[Epoch 17, Batch 400] loss: 0.008651219191415293
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0527
Validation Accuracy: 0.9872
Overfitting: 0.0516
[Epoch 18, Batch 100] loss: 0.002795688465303101
[Epoch 18, Batch 200] loss: 0.0021246856928337364
[Epoch 18, Batch 300] loss: 0.003676585012844953
[Epoch 18, Batch 400] loss: 0.004201213399246626
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0601
Validation Accuracy: 0.9868
Overfitting: 0.0592
[Epoch 19, Batch 100] loss: 0.004119521715520023
[Epoch 19, Batch 200] loss: 0.0011158953003177884
[Epoch 19, Batch 300] loss: 0.001947674355124036
[Epoch 19, Batch 400] loss: 0.0015126145462909335
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0538
Validation Accuracy: 0.9875
Overfitting: 0.0534
[Epoch 20, Batch 100] loss: 0.001838408786279615
[Epoch 20, Batch 200] loss: 0.0012898658624635572
[Epoch 20, Batch 300] loss: 0.0007196637080232903
[Epoch 20, Batch 400] loss: 0.000985686997182711
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0560
Validation Accuracy: 0.9880
Overfitting: 0.0559
[Epoch 21, Batch 100] loss: 0.0008133139269557433
[Epoch 21, Batch 200] loss: 0.00041196179545408993
[Epoch 21, Batch 300] loss: 0.0006019096184650152
[Epoch 21, Batch 400] loss: 0.00039594803597310603
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0581
Validation Accuracy: 0.9879
Overfitting: 0.0579
[Epoch 22, Batch 100] loss: 0.00037157674296622645
[Epoch 22, Batch 200] loss: 0.00029814845114060516
[Epoch 22, Batch 300] loss: 0.0004426826079861712
[Epoch 22, Batch 400] loss: 0.00037131826491872746
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0568
Validation Accuracy: 0.9882
Overfitting: 0.0568
[Epoch 23, Batch 100] loss: 0.00028959237373328507
[Epoch 23, Batch 200] loss: 0.00022062627075797536
[Epoch 23, Batch 300] loss: 0.00025395053740226106
[Epoch 23, Batch 400] loss: 0.0002346735119249388
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0582
Validation Accuracy: 0.9882
Overfitting: 0.0581
[Epoch 24, Batch 100] loss: 0.0004198343219104572
[Epoch 24, Batch 200] loss: 0.00024095957074223405
[Epoch 24, Batch 300] loss: 0.00018048863254534807
[Epoch 24, Batch 400] loss: 0.00020570584932784187
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0588
Validation Accuracy: 0.9881
Overfitting: 0.0587
Fold 2 validation loss: 0.0588
Mean validation loss across all folds for Trial 10 is 0.0624 with trial config:  l1: 256, l2: 128, lr: 0.007255685482622854, batch_size: 64
[I 2024-11-21 23:29:25,186] Trial 9 finished with value: 0.062409205112072 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.007255685482622854, 'batch_size': 64}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 11:
  l1: 128, l2: 128, lr: 0.0007958528878666696, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2930343747138977
[Epoch 1, Batch 200] loss: 2.2609747362136843
**STATS for Epoch 1** : 
Average training loss: 0.3306
Average validation loss: 2.2009
Validation Accuracy: 0.4027
Overfitting: 1.8702
Best model saved at epoch 1 with validation loss: 2.2009
[Epoch 2, Batch 100] loss: 2.0874136328697204
[Epoch 2, Batch 200] loss: 1.376576750278473
**STATS for Epoch 2** : 
Average training loss: 0.1107
Average validation loss: 0.6497
Validation Accuracy: 0.8175
Overfitting: 0.5390
Best model saved at epoch 2 with validation loss: 0.6497
[Epoch 3, Batch 100] loss: 0.5410766568779946
[Epoch 3, Batch 200] loss: 0.43699094265699384
**STATS for Epoch 3** : 
Average training loss: 0.0618
Average validation loss: 0.3874
Validation Accuracy: 0.8844
Overfitting: 0.3256
Best model saved at epoch 3 with validation loss: 0.3874
[Epoch 4, Batch 100] loss: 0.3716098639369011
[Epoch 4, Batch 200] loss: 0.3502825817465782
**STATS for Epoch 4** : 
Average training loss: 0.0478
Average validation loss: 0.3168
Validation Accuracy: 0.9022
Overfitting: 0.2690
Best model saved at epoch 4 with validation loss: 0.3168
[Epoch 5, Batch 100] loss: 0.30695853032171727
[Epoch 5, Batch 200] loss: 0.28137687310576437
**STATS for Epoch 5** : 
Average training loss: 0.0385
Average validation loss: 0.2601
Validation Accuracy: 0.9205
Overfitting: 0.2215
Best model saved at epoch 5 with validation loss: 0.2601
[Epoch 6, Batch 100] loss: 0.26147392436861994
[Epoch 6, Batch 200] loss: 0.2330493760108948
**STATS for Epoch 6** : 
Average training loss: 0.0348
Average validation loss: 0.2187
Validation Accuracy: 0.9339
Overfitting: 0.1839
[I 2024-11-21 23:30:29,282] Trial 10 pruned. 

Selected Hyperparameters for Trial 12:
  l1: 256, l2: 128, lr: 0.06942779375197834, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.0085719615221023
[Epoch 1, Batch 200] loss: 0.2913383661210537
[Epoch 1, Batch 300] loss: 0.22772691078484059
[Epoch 1, Batch 400] loss: 0.18902562678791582
**STATS for Epoch 1** : 
Average training loss: 0.0233
Average validation loss: 0.1432
Validation Accuracy: 0.9604
Overfitting: 0.1199
Best model saved at epoch 1 with validation loss: 0.1432
[Epoch 2, Batch 100] loss: 0.15448416760191322
[Epoch 2, Batch 200] loss: 0.16030343810562045
[Epoch 2, Batch 300] loss: 0.12743516772752628
[Epoch 2, Batch 400] loss: 0.11706354376394301
**STATS for Epoch 2** : 
Average training loss: 0.0187
Average validation loss: 0.1127
Validation Accuracy: 0.9693
Overfitting: 0.0940
Best model saved at epoch 2 with validation loss: 0.1127
[Epoch 3, Batch 100] loss: 0.09838507648790255
[Epoch 3, Batch 200] loss: 0.0955589230300393
[Epoch 3, Batch 300] loss: 0.1380485425540246
[Epoch 3, Batch 400] loss: 0.13316124479286373
**STATS for Epoch 3** : 
Average training loss: 0.0162
Average validation loss: 0.2021
Validation Accuracy: 0.9482
Overfitting: 0.1859
[Epoch 4, Batch 100] loss: 0.11622899577021599
[Epoch 4, Batch 200] loss: 0.09809710445348173
[Epoch 4, Batch 300] loss: 0.11683027270250022
[Epoch 4, Batch 400] loss: 0.127272192313103
**STATS for Epoch 4** : 
Average training loss: 0.0171
Average validation loss: 0.1242
Validation Accuracy: 0.9697
Overfitting: 0.1071
[Epoch 5, Batch 100] loss: 0.09761182751972228
[Epoch 5, Batch 200] loss: 0.09723308219807222
[Epoch 5, Batch 300] loss: 0.10153993836604058
[Epoch 5, Batch 400] loss: 0.09272006341256202
**STATS for Epoch 5** : 
Average training loss: 0.0163
Average validation loss: 0.1442
Validation Accuracy: 0.9656
Overfitting: 0.1278
[Epoch 6, Batch 100] loss: 0.08658318081870675
[Epoch 6, Batch 200] loss: 0.0932872296590358
[Epoch 6, Batch 300] loss: 0.0913052478665486
[Epoch 6, Batch 400] loss: 0.11004651374532841
**STATS for Epoch 6** : 
Average training loss: 0.0131
Average validation loss: 0.1387
Validation Accuracy: 0.9704
Overfitting: 0.1256
[Epoch 7, Batch 100] loss: 0.07744922467216384
[Epoch 7, Batch 200] loss: 0.12478857060108567
[Epoch 7, Batch 300] loss: 0.08380437359257485
[Epoch 7, Batch 400] loss: 0.10795225525158457
**STATS for Epoch 7** : 
Average training loss: 0.0155
Average validation loss: 0.1464
Validation Accuracy: 0.9694
Overfitting: 0.1309
[Epoch 8, Batch 100] loss: 0.08115876990021206
[Epoch 8, Batch 200] loss: 0.08489516810514033
[Epoch 8, Batch 300] loss: 0.08197573863086291
[Epoch 8, Batch 400] loss: 0.06534384565879009
**STATS for Epoch 8** : 
Average training loss: 0.0145
Average validation loss: 0.1308
Validation Accuracy: 0.9699
Overfitting: 0.1164
[Epoch 9, Batch 100] loss: 0.0824560363063938
[Epoch 9, Batch 200] loss: 0.10120813922549132
[Epoch 9, Batch 300] loss: 0.16644534797233063
[Epoch 9, Batch 400] loss: 0.14751925693359225
**STATS for Epoch 9** : 
Average training loss: 0.0289
Average validation loss: 0.1960
Validation Accuracy: 0.9534
Overfitting: 0.1671
[I 2024-11-21 23:32:14,280] Trial 11 pruned. 

Selected Hyperparameters for Trial 13:
  l1: 256, l2: 128, lr: 0.0007380817523374673, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2931015872955323
[Epoch 1, Batch 200] loss: 2.270694861412048
[Epoch 1, Batch 300] loss: 2.2147050714492797
[Epoch 1, Batch 400] loss: 2.0046717619895933
**STATS for Epoch 1** : 
Average training loss: 0.2078
Average validation loss: 1.0849
Validation Accuracy: 0.6967
Overfitting: 0.8771
Best model saved at epoch 1 with validation loss: 1.0849
[Epoch 2, Batch 100] loss: 0.8112395280599594
[Epoch 2, Batch 200] loss: 0.5957587242126465
[Epoch 2, Batch 300] loss: 0.5030215160548687
[Epoch 2, Batch 400] loss: 0.43223164036870004
**STATS for Epoch 2** : 
Average training loss: 0.0533
Average validation loss: 0.3902
Validation Accuracy: 0.8819
Overfitting: 0.3369
Best model saved at epoch 2 with validation loss: 0.3902
[Epoch 3, Batch 100] loss: 0.38181984692811965
[Epoch 3, Batch 200] loss: 0.31530354395508764
[Epoch 3, Batch 300] loss: 0.32732298105955127
[Epoch 3, Batch 400] loss: 0.27893235176801684
**STATS for Epoch 3** : 
Average training loss: 0.0392
Average validation loss: 0.2576
Validation Accuracy: 0.9224
Overfitting: 0.2184
Best model saved at epoch 3 with validation loss: 0.2576
[Epoch 4, Batch 100] loss: 0.24933824457228185
[Epoch 4, Batch 200] loss: 0.2396806761622429
[Epoch 4, Batch 300] loss: 0.22721822261810304
[Epoch 4, Batch 400] loss: 0.21696748696267604
**STATS for Epoch 4** : 
Average training loss: 0.0275
Average validation loss: 0.2049
Validation Accuracy: 0.9369
Overfitting: 0.1775
Best model saved at epoch 4 with validation loss: 0.2049
[Epoch 5, Batch 100] loss: 0.1843824804574251
[Epoch 5, Batch 200] loss: 0.1957887974753976
[Epoch 5, Batch 300] loss: 0.1767923517152667
[Epoch 5, Batch 400] loss: 0.1726319008693099
**STATS for Epoch 5** : 
Average training loss: 0.0242
Average validation loss: 0.1646
Validation Accuracy: 0.9512
Overfitting: 0.1404
Best model saved at epoch 5 with validation loss: 0.1646
[Epoch 6, Batch 100] loss: 0.1544029639288783
[Epoch 6, Batch 200] loss: 0.14160886328667402
[Epoch 6, Batch 300] loss: 0.14865210969001055
[Epoch 6, Batch 400] loss: 0.14052829576656223
**STATS for Epoch 6** : 
Average training loss: 0.0210
Average validation loss: 0.1412
Validation Accuracy: 0.9585
Overfitting: 0.1202
[I 2024-11-21 23:33:21,389] Trial 12 pruned. 

Selected Hyperparameters for Trial 14:
  l1: 128, l2: 128, lr: 0.0011062854566266248, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2973323321342467
[Epoch 1, Batch 200] loss: 2.273925383090973
[Epoch 1, Batch 300] loss: 2.196260793209076
[Epoch 1, Batch 400] loss: 1.6425969570875167
[Epoch 1, Batch 500] loss: 0.756101167947054
[Epoch 1, Batch 600] loss: 0.5953621068596839
[Epoch 1, Batch 700] loss: 0.48506114855408666
[Epoch 1, Batch 800] loss: 0.3765275467932224
[Epoch 1, Batch 900] loss: 0.3713007785007358
[Epoch 1, Batch 1000] loss: 0.3301359039545059
[Epoch 1, Batch 1100] loss: 0.33227520931512117
[Epoch 1, Batch 1200] loss: 0.3257615245133638
[Epoch 1, Batch 1300] loss: 0.29302620474249125
[Epoch 1, Batch 1400] loss: 0.24118120178580285
[Epoch 1, Batch 1500] loss: 0.25510322213172915
[Epoch 1, Batch 1600] loss: 0.23465197660028936
[Epoch 1, Batch 1700] loss: 0.20965436665341258
[Epoch 1, Batch 1800] loss: 0.20273708869703114
**STATS for Epoch 1** : 
Average training loss: 0.0067
Average validation loss: 0.2045
Validation Accuracy: 0.9363
Overfitting: 0.1978
Best model saved at epoch 1 with validation loss: 0.2045
[Epoch 2, Batch 100] loss: 0.1705664160475135
[Epoch 2, Batch 200] loss: 0.20026925331447273
[Epoch 2, Batch 300] loss: 0.1745383281353861
[Epoch 2, Batch 400] loss: 0.15731304498855025
[Epoch 2, Batch 500] loss: 0.19013335471972823
[Epoch 2, Batch 600] loss: 0.16498389870859684
[Epoch 2, Batch 700] loss: 0.15421208321116864
[Epoch 2, Batch 800] loss: 0.12290974878240377
[Epoch 2, Batch 900] loss: 0.1393454235745594
[Epoch 2, Batch 1000] loss: 0.1624355338746682
[Epoch 2, Batch 1100] loss: 0.12799696961417795
[Epoch 2, Batch 1200] loss: 0.15347604263108225
[Epoch 2, Batch 1300] loss: 0.13361746467649938
[Epoch 2, Batch 1400] loss: 0.151994695821777
[Epoch 2, Batch 1500] loss: 0.11719388492172583
[Epoch 2, Batch 1600] loss: 0.1115550226753112
[Epoch 2, Batch 1700] loss: 0.11817891396232881
[Epoch 2, Batch 1800] loss: 0.13394383320352063
**STATS for Epoch 2** : 
Average training loss: 0.0046
Average validation loss: 0.1108
Validation Accuracy: 0.9644
Overfitting: 0.1062
Best model saved at epoch 2 with validation loss: 0.1108
[Epoch 3, Batch 100] loss: 0.09207728555658833
[Epoch 3, Batch 200] loss: 0.1190955391828902
[Epoch 3, Batch 300] loss: 0.107616315074265
[Epoch 3, Batch 400] loss: 0.09696811706293375
[Epoch 3, Batch 500] loss: 0.10738738585729152
[Epoch 3, Batch 600] loss: 0.08831027410225943
[Epoch 3, Batch 700] loss: 0.09026047943159937
[Epoch 3, Batch 800] loss: 0.10318663346813992
[Epoch 3, Batch 900] loss: 0.09167763969977387
[Epoch 3, Batch 1000] loss: 0.10249067929573358
[Epoch 3, Batch 1100] loss: 0.08903968788217753
[Epoch 3, Batch 1200] loss: 0.08144494534702972
[Epoch 3, Batch 1300] loss: 0.10563509859610348
[Epoch 3, Batch 1400] loss: 0.10539651338011026
[Epoch 3, Batch 1500] loss: 0.08890926474472508
[Epoch 3, Batch 1600] loss: 0.08825711652054452
[Epoch 3, Batch 1700] loss: 0.09196182844229042
[Epoch 3, Batch 1800] loss: 0.07000420751865022
**STATS for Epoch 3** : 
Average training loss: 0.0049
Average validation loss: 0.1008
Validation Accuracy: 0.9676
Overfitting: 0.0959
Best model saved at epoch 3 with validation loss: 0.1008
[Epoch 4, Batch 100] loss: 0.07748718411894515
[Epoch 4, Batch 200] loss: 0.08373117061331868
[Epoch 4, Batch 300] loss: 0.07200799140846356
[Epoch 4, Batch 400] loss: 0.07524455073056742
[Epoch 4, Batch 500] loss: 0.0799710115743801
[Epoch 4, Batch 600] loss: 0.09430781875620596
[Epoch 4, Batch 700] loss: 0.06700593209418003
[Epoch 4, Batch 800] loss: 0.06442770934605506
[Epoch 4, Batch 900] loss: 0.06558204281958752
[Epoch 4, Batch 1000] loss: 0.06872158369980752
[Epoch 4, Batch 1100] loss: 0.0775096835999284
[Epoch 4, Batch 1200] loss: 0.0686123579996638
[Epoch 4, Batch 1300] loss: 0.07309571392135694
[Epoch 4, Batch 1400] loss: 0.08849450354231521
[Epoch 4, Batch 1500] loss: 0.07475176871172153
[Epoch 4, Batch 1600] loss: 0.07198557796073146
[Epoch 4, Batch 1700] loss: 0.06636328177060932
[Epoch 4, Batch 1800] loss: 0.06266987163340673
**STATS for Epoch 4** : 
Average training loss: 0.0030
Average validation loss: 0.1113
Validation Accuracy: 0.9668
Overfitting: 0.1083
[Epoch 5, Batch 100] loss: 0.07420002492261119
[Epoch 5, Batch 200] loss: 0.05926307269546669
[Epoch 5, Batch 300] loss: 0.06984724422101862
[Epoch 5, Batch 400] loss: 0.07116535280132666
[Epoch 5, Batch 500] loss: 0.0541737768764142
[Epoch 5, Batch 600] loss: 0.05360769206832629
[Epoch 5, Batch 700] loss: 0.05666284981969511
[Epoch 5, Batch 800] loss: 0.06673521104967221
[Epoch 5, Batch 900] loss: 0.05029301570437383
[Epoch 5, Batch 1000] loss: 0.07432837499945891
[Epoch 5, Batch 1100] loss: 0.0711984876828501
[Epoch 5, Batch 1200] loss: 0.04605141236068448
[Epoch 5, Batch 1300] loss: 0.07123430233186809
[Epoch 5, Batch 1400] loss: 0.06360898445651401
[Epoch 5, Batch 1500] loss: 0.0539951026358176
[Epoch 5, Batch 1600] loss: 0.04583515593083575
[Epoch 5, Batch 1700] loss: 0.062027714684372764
[Epoch 5, Batch 1800] loss: 0.04562343002180569
**STATS for Epoch 5** : 
Average training loss: 0.0029
Average validation loss: 0.0721
Validation Accuracy: 0.9769
Overfitting: 0.0693
Best model saved at epoch 5 with validation loss: 0.0721
[Epoch 6, Batch 100] loss: 0.04802491028269287
[Epoch 6, Batch 200] loss: 0.04618159335426753
[Epoch 6, Batch 300] loss: 0.049219716464867815
[Epoch 6, Batch 400] loss: 0.041626983578316866
[Epoch 6, Batch 500] loss: 0.05357662147551309
[Epoch 6, Batch 600] loss: 0.04984101790440036
[Epoch 6, Batch 700] loss: 0.05904716963384999
[Epoch 6, Batch 800] loss: 0.05430779819871532
[Epoch 6, Batch 900] loss: 0.03971037752693519
[Epoch 6, Batch 1000] loss: 0.055457497386378236
[Epoch 6, Batch 1100] loss: 0.03997877313871868
[Epoch 6, Batch 1200] loss: 0.037524276640324386
[Epoch 6, Batch 1300] loss: 0.04630708587152185
[Epoch 6, Batch 1400] loss: 0.0500156999155297
[Epoch 6, Batch 1500] loss: 0.06435318020550768
[Epoch 6, Batch 1600] loss: 0.043979243892244994
[Epoch 6, Batch 1700] loss: 0.04557764018551097
[Epoch 6, Batch 1800] loss: 0.04858052635914646
**STATS for Epoch 6** : 
Average training loss: 0.0017
Average validation loss: 0.0605
Validation Accuracy: 0.9812
Overfitting: 0.0587
Best model saved at epoch 6 with validation loss: 0.0605
[Epoch 7, Batch 100] loss: 0.036977764242037664
[Epoch 7, Batch 200] loss: 0.03841878665632976
[Epoch 7, Batch 300] loss: 0.045670205717033244
[Epoch 7, Batch 400] loss: 0.028143529352673793
[Epoch 7, Batch 500] loss: 0.04029212720168289
[Epoch 7, Batch 600] loss: 0.03316836630037869
[Epoch 7, Batch 700] loss: 0.060463642355025514
[Epoch 7, Batch 800] loss: 0.036841233852610455
[Epoch 7, Batch 900] loss: 0.05170417194138281
[Epoch 7, Batch 1000] loss: 0.042849004581803456
[Epoch 7, Batch 1100] loss: 0.03605457644152921
[Epoch 7, Batch 1200] loss: 0.04577178924519103
[Epoch 7, Batch 1300] loss: 0.04277612883510301
[Epoch 7, Batch 1400] loss: 0.032074589310941516
[Epoch 7, Batch 1500] loss: 0.04778456326690503
[Epoch 7, Batch 1600] loss: 0.0362807373416581
[Epoch 7, Batch 1700] loss: 0.04882664349934203
[Epoch 7, Batch 1800] loss: 0.0509900646310416
**STATS for Epoch 7** : 
Average training loss: 0.0013
Average validation loss: 0.0666
Validation Accuracy: 0.9791
Overfitting: 0.0653
[Epoch 8, Batch 100] loss: 0.055104857650294436
[Epoch 8, Batch 200] loss: 0.03342283452351694
[Epoch 8, Batch 300] loss: 0.030910615357133794
[Epoch 8, Batch 400] loss: 0.03383212783111958
[Epoch 8, Batch 500] loss: 0.022610231190919875
[Epoch 8, Batch 600] loss: 0.022917519467737294
[Epoch 8, Batch 700] loss: 0.02562712938837649
[Epoch 8, Batch 800] loss: 0.04850064896316326
[Epoch 8, Batch 900] loss: 0.029712047475622966
[Epoch 8, Batch 1000] loss: 0.03177639060795627
[Epoch 8, Batch 1100] loss: 0.053061030790413494
[Epoch 8, Batch 1200] loss: 0.03185713300015777
[Epoch 8, Batch 1300] loss: 0.04413489574202686
[Epoch 8, Batch 1400] loss: 0.023929044509786765
[Epoch 8, Batch 1500] loss: 0.04166484542409307
[Epoch 8, Batch 1600] loss: 0.04945319126534741
[Epoch 8, Batch 1700] loss: 0.03758563472016249
[Epoch 8, Batch 1800] loss: 0.030261007791850716
**STATS for Epoch 8** : 
Average training loss: 0.0016
Average validation loss: 0.0574
Validation Accuracy: 0.9819
Overfitting: 0.0558
Best model saved at epoch 8 with validation loss: 0.0574
[Epoch 9, Batch 100] loss: 0.02830041651468491
[Epoch 9, Batch 200] loss: 0.02756294582170085
[Epoch 9, Batch 300] loss: 0.03527054731122917
[Epoch 9, Batch 400] loss: 0.022142896538425702
[Epoch 9, Batch 500] loss: 0.029492404340126087
[Epoch 9, Batch 600] loss: 0.02383601990157331
[Epoch 9, Batch 700] loss: 0.048711551523592786
[Epoch 9, Batch 800] loss: 0.03068603203049861
[Epoch 9, Batch 900] loss: 0.031073049883780186
[Epoch 9, Batch 1000] loss: 0.029625576712423937
[Epoch 9, Batch 1100] loss: 0.04929398625310569
[Epoch 9, Batch 1200] loss: 0.035660812027381326
[Epoch 9, Batch 1300] loss: 0.030063337638712256
[Epoch 9, Batch 1400] loss: 0.028532724052347476
[Epoch 9, Batch 1500] loss: 0.025718963302715565
[Epoch 9, Batch 1600] loss: 0.02239062115368142
[Epoch 9, Batch 1700] loss: 0.021231143943623465
[Epoch 9, Batch 1800] loss: 0.0360699486170779
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0706
Validation Accuracy: 0.9788
Overfitting: 0.0691
[Epoch 10, Batch 100] loss: 0.027364033107005525
[Epoch 10, Batch 200] loss: 0.02749315944252885
[Epoch 10, Batch 300] loss: 0.023937431780141197
[Epoch 10, Batch 400] loss: 0.019472258020105073
[Epoch 10, Batch 500] loss: 0.021527636633290968
[Epoch 10, Batch 600] loss: 0.03111600237094535
[Epoch 10, Batch 700] loss: 0.016353663082736603
[Epoch 10, Batch 800] loss: 0.030469447564901202
[Epoch 10, Batch 900] loss: 0.020143933771905723
[Epoch 10, Batch 1000] loss: 0.04803399296419229
[Epoch 10, Batch 1100] loss: 0.037213421993219524
[Epoch 10, Batch 1200] loss: 0.021708677777569393
[Epoch 10, Batch 1300] loss: 0.02243643431131204
[Epoch 10, Batch 1400] loss: 0.03819257879600627
[Epoch 10, Batch 1500] loss: 0.036170520071173086
[Epoch 10, Batch 1600] loss: 0.020379630740571884
[Epoch 10, Batch 1700] loss: 0.026527236122637986
[Epoch 10, Batch 1800] loss: 0.025156534124253085
**STATS for Epoch 10** : 
Average training loss: 0.0010
Average validation loss: 0.0614
Validation Accuracy: 0.9825
Overfitting: 0.0604
[Epoch 11, Batch 100] loss: 0.027906802048019017
[Epoch 11, Batch 200] loss: 0.01888655242160894
[Epoch 11, Batch 300] loss: 0.015308934107088135
[Epoch 11, Batch 400] loss: 0.021025075184988962
[Epoch 11, Batch 500] loss: 0.013862038728766492
[Epoch 11, Batch 600] loss: 0.015355480489906767
[Epoch 11, Batch 700] loss: 0.021153711583829136
[Epoch 11, Batch 800] loss: 0.020218200464478288
[Epoch 11, Batch 900] loss: 0.016129234791806085
[Epoch 11, Batch 1000] loss: 0.017078077708501952
[Epoch 11, Batch 1100] loss: 0.032376424242065695
[Epoch 11, Batch 1200] loss: 0.0333115267211906
[Epoch 11, Batch 1300] loss: 0.02905247380371293
[Epoch 11, Batch 1400] loss: 0.02094315690221265
[Epoch 11, Batch 1500] loss: 0.02510970472249028
[Epoch 11, Batch 1600] loss: 0.0222645624677898
[Epoch 11, Batch 1700] loss: 0.018813218308750948
[Epoch 11, Batch 1800] loss: 0.0287938631457655
**STATS for Epoch 11** : 
Average training loss: 0.0007
Average validation loss: 0.0561
Validation Accuracy: 0.9840
Overfitting: 0.0554
Best model saved at epoch 11 with validation loss: 0.0561
[Epoch 12, Batch 100] loss: 0.014049443125040853
[Epoch 12, Batch 200] loss: 0.01206568515467552
[Epoch 12, Batch 300] loss: 0.021174278382823104
[Epoch 12, Batch 400] loss: 0.01333061654218909
[Epoch 12, Batch 500] loss: 0.01499968788741171
[Epoch 12, Batch 600] loss: 0.017963765640452038
[Epoch 12, Batch 700] loss: 0.020508826460977615
[Epoch 12, Batch 800] loss: 0.018416120324109216
[Epoch 12, Batch 900] loss: 0.015451187044200197
[Epoch 12, Batch 1000] loss: 0.021470902279252187
[Epoch 12, Batch 1100] loss: 0.015192279581260664
[Epoch 12, Batch 1200] loss: 0.015278990769766097
[Epoch 12, Batch 1300] loss: 0.029892473967192926
[Epoch 12, Batch 1400] loss: 0.01356224693452532
[Epoch 12, Batch 1500] loss: 0.0241112693553805
[Epoch 12, Batch 1600] loss: 0.028668330913096726
[Epoch 12, Batch 1700] loss: 0.019247765256668572
[Epoch 12, Batch 1800] loss: 0.03559340846462874
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0622
Validation Accuracy: 0.9834
Overfitting: 0.0615
[Epoch 13, Batch 100] loss: 0.01632271413323906
[Epoch 13, Batch 200] loss: 0.013027670775172737
[Epoch 13, Batch 300] loss: 0.019434968670393574
[Epoch 13, Batch 400] loss: 0.018671491031382173
[Epoch 13, Batch 500] loss: 0.015426545232362514
[Epoch 13, Batch 600] loss: 0.0158545614007744
[Epoch 13, Batch 700] loss: 0.0257995433533506
[Epoch 13, Batch 800] loss: 0.014122474245559714
[Epoch 13, Batch 900] loss: 0.016698555629263864
[Epoch 13, Batch 1000] loss: 0.0311089201153527
[Epoch 13, Batch 1100] loss: 0.01862721995632455
[Epoch 13, Batch 1200] loss: 0.014502527294507673
[Epoch 13, Batch 1300] loss: 0.016230136128051527
[Epoch 13, Batch 1400] loss: 0.020104695435056785
[Epoch 13, Batch 1500] loss: 0.027324421566290766
[Epoch 13, Batch 1600] loss: 0.019089974595044624
[Epoch 13, Batch 1700] loss: 0.011729140313395874
[Epoch 13, Batch 1800] loss: 0.02078645582512763
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0597
Validation Accuracy: 0.9839
Overfitting: 0.0590
[Epoch 14, Batch 100] loss: 0.0071968962639493836
[Epoch 14, Batch 200] loss: 0.012412707300222791
[Epoch 14, Batch 300] loss: 0.008708613908456755
[Epoch 14, Batch 400] loss: 0.02649284785531563
[Epoch 14, Batch 500] loss: 0.012664911731044413
[Epoch 14, Batch 600] loss: 0.01058161353986179
[Epoch 14, Batch 700] loss: 0.016020198412643367
[Epoch 14, Batch 800] loss: 0.013054624146639071
[Epoch 14, Batch 900] loss: 0.01250999751407562
[Epoch 14, Batch 1000] loss: 0.011471539155736536
[Epoch 14, Batch 1100] loss: 0.02155935344660975
[Epoch 14, Batch 1200] loss: 0.021754076755032655
[Epoch 14, Batch 1300] loss: 0.013875954541108513
[Epoch 14, Batch 1400] loss: 0.010625538138665434
[Epoch 14, Batch 1500] loss: 0.023071354911089657
[Epoch 14, Batch 1600] loss: 0.015570370316108893
[Epoch 14, Batch 1700] loss: 0.020155312084370963
[Epoch 14, Batch 1800] loss: 0.013079019752108251
**STATS for Epoch 14** : 
Average training loss: 0.0003
Average validation loss: 0.0588
Validation Accuracy: 0.9842
Overfitting: 0.0585
[Epoch 15, Batch 100] loss: 0.00660081528628325
[Epoch 15, Batch 200] loss: 0.00767353987505885
[Epoch 15, Batch 300] loss: 0.008836229850826384
[Epoch 15, Batch 400] loss: 0.008685647173283541
[Epoch 15, Batch 500] loss: 0.007456274455194034
[Epoch 15, Batch 600] loss: 0.008307656515316921
[Epoch 15, Batch 700] loss: 0.016804477803484586
[Epoch 15, Batch 800] loss: 0.017304659834353517
[Epoch 15, Batch 900] loss: 0.01959378240682781
[Epoch 15, Batch 1000] loss: 0.010454092434056293
[Epoch 15, Batch 1100] loss: 0.010917675470846006
[Epoch 15, Batch 1200] loss: 0.010842471476726132
[Epoch 15, Batch 1300] loss: 0.012894788370508649
[Epoch 15, Batch 1400] loss: 0.022666144777904264
[Epoch 15, Batch 1500] loss: 0.005419006872434693
[Epoch 15, Batch 1600] loss: 0.014086257235696849
[Epoch 15, Batch 1700] loss: 0.008167573372370498
[Epoch 15, Batch 1800] loss: 0.011532112605427755
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0596
Validation Accuracy: 0.9844
Overfitting: 0.0591
[Epoch 16, Batch 100] loss: 0.016635168952384448
[Epoch 16, Batch 200] loss: 0.005419076154316827
[Epoch 16, Batch 300] loss: 0.00897038568836706
[Epoch 16, Batch 400] loss: 0.008109442155105171
[Epoch 16, Batch 500] loss: 0.0064760846813328495
[Epoch 16, Batch 600] loss: 0.017123378525116095
[Epoch 16, Batch 700] loss: 0.01256503593828711
[Epoch 16, Batch 800] loss: 0.01369523630128242
[Epoch 16, Batch 900] loss: 0.007943689397714025
[Epoch 16, Batch 1000] loss: 0.008416556055422006
[Epoch 16, Batch 1100] loss: 0.009347269608415445
[Epoch 16, Batch 1200] loss: 0.008295931772258881
[Epoch 16, Batch 1300] loss: 0.008910332995628777
[Epoch 16, Batch 1400] loss: 0.009179249312314824
[Epoch 16, Batch 1500] loss: 0.01177138126505497
[Epoch 16, Batch 1600] loss: 0.01833897740170414
[Epoch 16, Batch 1700] loss: 0.014918534300531973
[Epoch 16, Batch 1800] loss: 0.013299013222567737
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0717
Validation Accuracy: 0.9818
Overfitting: 0.0709
[Epoch 17, Batch 100] loss: 0.014388897763392378
[Epoch 17, Batch 200] loss: 0.012034716359794402
[Epoch 17, Batch 300] loss: 0.008888776497849448
[Epoch 17, Batch 400] loss: 0.01300044443539946
[Epoch 17, Batch 500] loss: 0.006510562566654698
[Epoch 17, Batch 600] loss: 0.011096713632095998
[Epoch 17, Batch 700] loss: 0.006462153828629198
[Epoch 17, Batch 800] loss: 0.02553224920653065
[Epoch 17, Batch 900] loss: 0.008073283934827487
[Epoch 17, Batch 1000] loss: 0.005731930335850848
[Epoch 17, Batch 1100] loss: 0.012494174302843249
[Epoch 17, Batch 1200] loss: 0.005623530670959553
[Epoch 17, Batch 1300] loss: 0.01177185180997185
[Epoch 17, Batch 1400] loss: 0.013662076769787746
[Epoch 17, Batch 1500] loss: 0.007614194945362556
[Epoch 17, Batch 1600] loss: 0.008139979691183043
[Epoch 17, Batch 1700] loss: 0.013732087383859835
[Epoch 17, Batch 1800] loss: 0.004992031804720227
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0618
Validation Accuracy: 0.9849
Overfitting: 0.0614
[Epoch 18, Batch 100] loss: 0.008052898013499999
[Epoch 18, Batch 200] loss: 0.0041957209827432965
[Epoch 18, Batch 300] loss: 0.004005042653726036
[Epoch 18, Batch 400] loss: 0.008721990321164412
[Epoch 18, Batch 500] loss: 0.011627967615752369
[Epoch 18, Batch 600] loss: 0.009729667340016021
[Epoch 18, Batch 700] loss: 0.012359984515996984
[Epoch 18, Batch 800] loss: 0.007518335852081464
[Epoch 18, Batch 900] loss: 0.006676718191433792
[Epoch 18, Batch 1000] loss: 0.008887172773220299
[Epoch 18, Batch 1100] loss: 0.005115119475379401
[Epoch 18, Batch 1200] loss: 0.009056468983237665
[Epoch 18, Batch 1300] loss: 0.01885656651339673
[Epoch 18, Batch 1400] loss: 0.00609867879693411
[Epoch 18, Batch 1500] loss: 0.003812890133592646
[Epoch 18, Batch 1600] loss: 0.0034476624436808835
[Epoch 18, Batch 1700] loss: 0.004202453883385715
[Epoch 18, Batch 1800] loss: 0.007542518173660255
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0727
Validation Accuracy: 0.9828
Overfitting: 0.0724
[Epoch 19, Batch 100] loss: 0.013750283134804704
[Epoch 19, Batch 200] loss: 0.0032881899296535264
[Epoch 19, Batch 300] loss: 0.008344598146387626
[Epoch 19, Batch 400] loss: 0.005014141051625529
[Epoch 19, Batch 500] loss: 0.00816666793793047
[Epoch 19, Batch 600] loss: 0.006144488416416607
[Epoch 19, Batch 700] loss: 0.0040399312488341365
[Epoch 19, Batch 800] loss: 0.005124606983154081
[Epoch 19, Batch 900] loss: 0.004763023969428559
[Epoch 19, Batch 1000] loss: 0.010261028188665478
[Epoch 19, Batch 1100] loss: 0.005616005732161398
[Epoch 19, Batch 1200] loss: 0.009836619076239686
[Epoch 19, Batch 1300] loss: 0.006293466513202475
[Epoch 19, Batch 1400] loss: 0.006469152946182249
[Epoch 19, Batch 1500] loss: 0.005946451011559475
[Epoch 19, Batch 1600] loss: 0.007114162472180397
[Epoch 19, Batch 1700] loss: 0.006233229531774214
[Epoch 19, Batch 1800] loss: 0.0049042137877444245
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0621
Validation Accuracy: 0.9863
Overfitting: 0.0621
[Epoch 20, Batch 100] loss: 0.0022213038913491802
[Epoch 20, Batch 200] loss: 0.004574845204837174
[Epoch 20, Batch 300] loss: 0.006217433594191562
[Epoch 20, Batch 400] loss: 0.00747569604418004
[Epoch 20, Batch 500] loss: 0.004131206329777797
[Epoch 20, Batch 600] loss: 0.006527020826637226
[Epoch 20, Batch 700] loss: 0.005798080712106639
[Epoch 20, Batch 800] loss: 0.0040349196621312445
[Epoch 20, Batch 900] loss: 0.009261161537853013
[Epoch 20, Batch 1000] loss: 0.0025652319517132584
[Epoch 20, Batch 1100] loss: 0.006647912187642078
[Epoch 20, Batch 1200] loss: 0.004495692592397518
[Epoch 20, Batch 1300] loss: 0.005605534361236551
[Epoch 20, Batch 1400] loss: 0.006038127324308107
[Epoch 20, Batch 1500] loss: 0.005684758747327124
[Epoch 20, Batch 1600] loss: 0.00366521686017677
[Epoch 20, Batch 1700] loss: 0.0031698423161628853
[Epoch 20, Batch 1800] loss: 0.009491304960908735
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0693
Validation Accuracy: 0.9843
Overfitting: 0.0688
[Epoch 21, Batch 100] loss: 0.0039283551385756255
[Epoch 21, Batch 200] loss: 0.002594985699508925
[Epoch 21, Batch 300] loss: 0.0019708999775377833
[Epoch 21, Batch 400] loss: 0.004031100135095187
[Epoch 21, Batch 500] loss: 0.005402659757864967
[Epoch 21, Batch 600] loss: 0.0059594465027254274
[Epoch 21, Batch 700] loss: 0.0032937253222075926
[Epoch 21, Batch 800] loss: 0.007620349003937008
[Epoch 21, Batch 900] loss: 0.0030538243975360047
[Epoch 21, Batch 1000] loss: 0.0014315888648002329
[Epoch 21, Batch 1100] loss: 0.002934316892451534
[Epoch 21, Batch 1200] loss: 0.007482626149550242
[Epoch 21, Batch 1300] loss: 0.0015844053626881305
[Epoch 21, Batch 1400] loss: 0.002914753469664504
[Epoch 21, Batch 1500] loss: 0.0034767456613690228
[Epoch 21, Batch 1600] loss: 0.00498669368438982
[Epoch 21, Batch 1700] loss: 0.007994724937234424
[Epoch 21, Batch 1800] loss: 0.008338617694908521
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0740
Validation Accuracy: 0.9843
Overfitting: 0.0736
[Epoch 22, Batch 100] loss: 0.013482714029146336
[Epoch 22, Batch 200] loss: 0.0016523133834122916
[Epoch 22, Batch 300] loss: 0.0034571552956219873
[Epoch 22, Batch 400] loss: 0.003873857721246168
[Epoch 22, Batch 500] loss: 0.006336565655063282
[Epoch 22, Batch 600] loss: 0.005183355564594194
[Epoch 22, Batch 700] loss: 0.0016489374076752482
[Epoch 22, Batch 800] loss: 0.003904617223944058
[Epoch 22, Batch 900] loss: 0.003845039354276878
[Epoch 22, Batch 1000] loss: 0.005172127759285558
[Epoch 22, Batch 1100] loss: 0.004009902073306648
[Epoch 22, Batch 1200] loss: 0.0014026636949432713
[Epoch 22, Batch 1300] loss: 0.001863662251089906
[Epoch 22, Batch 1400] loss: 0.0013967490851575803
[Epoch 22, Batch 1500] loss: 0.000976621036279539
[Epoch 22, Batch 1600] loss: 0.003278341876012405
[Epoch 22, Batch 1700] loss: 0.0038915216707550828
[Epoch 22, Batch 1800] loss: 0.005292719904742853
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0791
Validation Accuracy: 0.9831
Overfitting: 0.0788
[Epoch 23, Batch 100] loss: 0.007885803640554058
[Epoch 23, Batch 200] loss: 0.007980116070282008
[Epoch 23, Batch 300] loss: 0.005557058654721238
[Epoch 23, Batch 400] loss: 0.010410290610806214
[Epoch 23, Batch 500] loss: 0.003744665947203316
[Epoch 23, Batch 600] loss: 0.0028908841334394707
[Epoch 23, Batch 700] loss: 0.009481015737874259
[Epoch 23, Batch 800] loss: 0.0047867769734965294
[Epoch 23, Batch 900] loss: 0.005034785722685058
[Epoch 23, Batch 1000] loss: 0.0043915514539514785
[Epoch 23, Batch 1100] loss: 0.001936456632589767
[Epoch 23, Batch 1200] loss: 0.0018628092348018299
[Epoch 23, Batch 1300] loss: 0.0045958310890521405
[Epoch 23, Batch 1400] loss: 0.006348362651370536
[Epoch 23, Batch 1500] loss: 0.006255747051848175
[Epoch 23, Batch 1600] loss: 0.004308192078359241
[Epoch 23, Batch 1700] loss: 0.0037841032685022925
[Epoch 23, Batch 1800] loss: 0.0036922039170439545
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0695
Validation Accuracy: 0.9854
Overfitting: 0.0693
[Epoch 24, Batch 100] loss: 0.004054145238051206
[Epoch 24, Batch 200] loss: 0.0010910031016976517
[Epoch 24, Batch 300] loss: 0.005788098122604879
[Epoch 24, Batch 400] loss: 0.008366972102066939
[Epoch 24, Batch 500] loss: 0.0020445579270119653
[Epoch 24, Batch 600] loss: 0.0033924638814974628
[Epoch 24, Batch 700] loss: 0.0014138929853487526
[Epoch 24, Batch 800] loss: 0.0024570587243697164
[Epoch 24, Batch 900] loss: 0.0014315677318177222
[Epoch 24, Batch 1000] loss: 0.002383267407038545
[Epoch 24, Batch 1100] loss: 0.0017991732978728692
[Epoch 24, Batch 1200] loss: 0.0011113586725951309
[Epoch 24, Batch 1300] loss: 0.001705805537495735
[Epoch 24, Batch 1400] loss: 0.001111406811867539
[Epoch 24, Batch 1500] loss: 0.000937535046792135
[Epoch 24, Batch 1600] loss: 0.002133554176352277
[Epoch 24, Batch 1700] loss: 0.0016004867150849122
[Epoch 24, Batch 1800] loss: 0.0018953783219905773
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0690
Validation Accuracy: 0.9859
Overfitting: 0.0689
Fold 1 validation loss: 0.0690
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.286674199104309
[Epoch 1, Batch 200] loss: 2.235484445095062
[Epoch 1, Batch 300] loss: 1.894930213689804
[Epoch 1, Batch 400] loss: 0.9911673566699029
[Epoch 1, Batch 500] loss: 0.5734123255312443
[Epoch 1, Batch 600] loss: 0.5280249464511871
[Epoch 1, Batch 700] loss: 0.507797968685627
[Epoch 1, Batch 800] loss: 0.38769973583519457
[Epoch 1, Batch 900] loss: 0.36734023040160535
[Epoch 1, Batch 1000] loss: 0.36064255073666573
[Epoch 1, Batch 1100] loss: 0.3054339147359133
[Epoch 1, Batch 1200] loss: 0.30627627316862344
[Epoch 1, Batch 1300] loss: 0.3157646341621876
[Epoch 1, Batch 1400] loss: 0.24520912781357765
[Epoch 1, Batch 1500] loss: 0.23174403987824918
[Epoch 1, Batch 1600] loss: 0.19762453366070987
[Epoch 1, Batch 1700] loss: 0.20912197208032013
[Epoch 1, Batch 1800] loss: 0.2433167590200901
**STATS for Epoch 1** : 
Average training loss: 0.0080
Average validation loss: 0.1811
Validation Accuracy: 0.9435
Overfitting: 0.1731
Best model saved at epoch 1 with validation loss: 0.1811
[Epoch 2, Batch 100] loss: 0.16648400481790304
[Epoch 2, Batch 200] loss: 0.20526812278665602
[Epoch 2, Batch 300] loss: 0.17626177668571472
[Epoch 2, Batch 400] loss: 0.18000352847389878
[Epoch 2, Batch 500] loss: 0.1736145966593176
[Epoch 2, Batch 600] loss: 0.15352580865379423
[Epoch 2, Batch 700] loss: 0.1566680153273046
[Epoch 2, Batch 800] loss: 0.148719054388348
[Epoch 2, Batch 900] loss: 0.10365273669827729
[Epoch 2, Batch 1000] loss: 0.12950064790435134
[Epoch 2, Batch 1100] loss: 0.13036654388997704
[Epoch 2, Batch 1200] loss: 0.11413114940747619
[Epoch 2, Batch 1300] loss: 0.13421827646903695
[Epoch 2, Batch 1400] loss: 0.13087679096031934
[Epoch 2, Batch 1500] loss: 0.10212416366208345
[Epoch 2, Batch 1600] loss: 0.1007450970588252
[Epoch 2, Batch 1700] loss: 0.11568617927609011
[Epoch 2, Batch 1800] loss: 0.11023611878510564
**STATS for Epoch 2** : 
Average training loss: 0.0042
Average validation loss: 0.1137
Validation Accuracy: 0.9639
Overfitting: 0.1094
Best model saved at epoch 2 with validation loss: 0.1137
[Epoch 3, Batch 100] loss: 0.10108701407909393
[Epoch 3, Batch 200] loss: 0.11897240701364353
[Epoch 3, Batch 300] loss: 0.09142446966143325
[Epoch 3, Batch 400] loss: 0.09356359983677975
[Epoch 3, Batch 500] loss: 0.1277958243759349
[Epoch 3, Batch 600] loss: 0.09203034128062428
[Epoch 3, Batch 700] loss: 0.06379455695976503
[Epoch 3, Batch 800] loss: 0.09240122483111918
[Epoch 3, Batch 900] loss: 0.08784165798686444
[Epoch 3, Batch 1000] loss: 0.0854194968601223
[Epoch 3, Batch 1100] loss: 0.08523623342858627
[Epoch 3, Batch 1200] loss: 0.09857874794979579
[Epoch 3, Batch 1300] loss: 0.09235453414730728
[Epoch 3, Batch 1400] loss: 0.0728324365185108
[Epoch 3, Batch 1500] loss: 0.09628131734440103
[Epoch 3, Batch 1600] loss: 0.0821137789369095
[Epoch 3, Batch 1700] loss: 0.08616226967133116
[Epoch 3, Batch 1800] loss: 0.07310685260919854
**STATS for Epoch 3** : 
Average training loss: 0.0029
Average validation loss: 0.0887
Validation Accuracy: 0.9737
Overfitting: 0.0858
Best model saved at epoch 3 with validation loss: 0.0887
[Epoch 4, Batch 100] loss: 0.05481873370939866
[Epoch 4, Batch 200] loss: 0.07561499700881541
[Epoch 4, Batch 300] loss: 0.07678483548748773
[Epoch 4, Batch 400] loss: 0.06731155136832967
[Epoch 4, Batch 500] loss: 0.0664732542715501
[Epoch 4, Batch 600] loss: 0.06944335714215413
[Epoch 4, Batch 700] loss: 0.0806449715414783
[Epoch 4, Batch 800] loss: 0.06654669573850697
[Epoch 4, Batch 900] loss: 0.07157233407953754
[Epoch 4, Batch 1000] loss: 0.06960894670221024
[Epoch 4, Batch 1100] loss: 0.060984710149641616
[Epoch 4, Batch 1200] loss: 0.046743465122417546
[Epoch 4, Batch 1300] loss: 0.07187602497753687
[Epoch 4, Batch 1400] loss: 0.05767736249865266
[Epoch 4, Batch 1500] loss: 0.07365624556085094
[Epoch 4, Batch 1600] loss: 0.07536265058413846
[Epoch 4, Batch 1700] loss: 0.050129989123670386
[Epoch 4, Batch 1800] loss: 0.06511685883102473
**STATS for Epoch 4** : 
Average training loss: 0.0038
Average validation loss: 0.0868
Validation Accuracy: 0.9746
Overfitting: 0.0830
Best model saved at epoch 4 with validation loss: 0.0868
[Epoch 5, Batch 100] loss: 0.0706750443088822
[Epoch 5, Batch 200] loss: 0.04072490686608944
[Epoch 5, Batch 300] loss: 0.06274426571209915
[Epoch 5, Batch 400] loss: 0.04119990964056342
[Epoch 5, Batch 500] loss: 0.06934157317737118
[Epoch 5, Batch 600] loss: 0.05302233242779039
[Epoch 5, Batch 700] loss: 0.06521529422898312
[Epoch 5, Batch 800] loss: 0.07900305673945696
[Epoch 5, Batch 900] loss: 0.04216805575008038
[Epoch 5, Batch 1000] loss: 0.05324237742781406
[Epoch 5, Batch 1100] loss: 0.05988938945461996
[Epoch 5, Batch 1200] loss: 0.04662588619306916
[Epoch 5, Batch 1300] loss: 0.05872828780557029
[Epoch 5, Batch 1400] loss: 0.05074681832629722
[Epoch 5, Batch 1500] loss: 0.05971484274836257
[Epoch 5, Batch 1600] loss: 0.04614210683153942
[Epoch 5, Batch 1700] loss: 0.05630664522584993
[Epoch 5, Batch 1800] loss: 0.044928990947082637
**STATS for Epoch 5** : 
Average training loss: 0.0021
Average validation loss: 0.0728
Validation Accuracy: 0.9775
Overfitting: 0.0707
Best model saved at epoch 5 with validation loss: 0.0728
[Epoch 6, Batch 100] loss: 0.030914316487906036
[Epoch 6, Batch 200] loss: 0.04843462912162067
[Epoch 6, Batch 300] loss: 0.04724555005086586
[Epoch 6, Batch 400] loss: 0.03957594226943911
[Epoch 6, Batch 500] loss: 0.052498535478371196
[Epoch 6, Batch 600] loss: 0.06103505937120644
[Epoch 6, Batch 700] loss: 0.042697821817419025
[Epoch 6, Batch 800] loss: 0.04219180557483924
[Epoch 6, Batch 900] loss: 0.05557792887615506
[Epoch 6, Batch 1000] loss: 0.038986598118790426
[Epoch 6, Batch 1100] loss: 0.05428380555385957
[Epoch 6, Batch 1200] loss: 0.03934376518736826
[Epoch 6, Batch 1300] loss: 0.053845447909552605
[Epoch 6, Batch 1400] loss: 0.05176556284495746
[Epoch 6, Batch 1500] loss: 0.07353756963362684
[Epoch 6, Batch 1600] loss: 0.041567069935554174
[Epoch 6, Batch 1700] loss: 0.04825945880817017
[Epoch 6, Batch 1800] loss: 0.034978915682877414
**STATS for Epoch 6** : 
Average training loss: 0.0020
Average validation loss: 0.0756
Validation Accuracy: 0.9762
Overfitting: 0.0736
[Epoch 7, Batch 100] loss: 0.03061823873591493
[Epoch 7, Batch 200] loss: 0.028610261000503668
[Epoch 7, Batch 300] loss: 0.04677869885112159
[Epoch 7, Batch 400] loss: 0.05855856749403756
[Epoch 7, Batch 500] loss: 0.03641279194096569
[Epoch 7, Batch 600] loss: 0.03517673089147138
[Epoch 7, Batch 700] loss: 0.031755740968947066
[Epoch 7, Batch 800] loss: 0.04523148038177169
[Epoch 7, Batch 900] loss: 0.03610121936624637
[Epoch 7, Batch 1000] loss: 0.03226594211155316
[Epoch 7, Batch 1100] loss: 0.03807111632697342
[Epoch 7, Batch 1200] loss: 0.04029877065651817
[Epoch 7, Batch 1300] loss: 0.041463856874179326
[Epoch 7, Batch 1400] loss: 0.049014471456321186
[Epoch 7, Batch 1500] loss: 0.04483252373946016
[Epoch 7, Batch 1600] loss: 0.030516555324720685
[Epoch 7, Batch 1700] loss: 0.03572502858020016
[Epoch 7, Batch 1800] loss: 0.04348384303586499
**STATS for Epoch 7** : 
Average training loss: 0.0013
Average validation loss: 0.0606
Validation Accuracy: 0.9816
Overfitting: 0.0594
Best model saved at epoch 7 with validation loss: 0.0606
[Epoch 8, Batch 100] loss: 0.029239549991179958
[Epoch 8, Batch 200] loss: 0.0371868087209441
[Epoch 8, Batch 300] loss: 0.04245151988245197
[Epoch 8, Batch 400] loss: 0.01949761900206795
[Epoch 8, Batch 500] loss: 0.028858077892800794
[Epoch 8, Batch 600] loss: 0.04045786945573127
[Epoch 8, Batch 700] loss: 0.03010468395211319
[Epoch 8, Batch 800] loss: 0.033892653378279645
[Epoch 8, Batch 900] loss: 0.028300721664782032
[Epoch 8, Batch 1000] loss: 0.029458325216182857
[Epoch 8, Batch 1100] loss: 0.03647151699449751
[Epoch 8, Batch 1200] loss: 0.03936309407552471
[Epoch 8, Batch 1300] loss: 0.03959677601844305
[Epoch 8, Batch 1400] loss: 0.022103293137406582
[Epoch 8, Batch 1500] loss: 0.05154932110781374
[Epoch 8, Batch 1600] loss: 0.03421880434107152
[Epoch 8, Batch 1700] loss: 0.0331723996072833
[Epoch 8, Batch 1800] loss: 0.033446811767280454
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0639
Validation Accuracy: 0.9811
Overfitting: 0.0619
[Epoch 9, Batch 100] loss: 0.02747249994572485
[Epoch 9, Batch 200] loss: 0.023434139524142666
[Epoch 9, Batch 300] loss: 0.03965336725974339
[Epoch 9, Batch 400] loss: 0.023637908394957777
[Epoch 9, Batch 500] loss: 0.023974220735108246
[Epoch 9, Batch 600] loss: 0.031315850225582836
[Epoch 9, Batch 700] loss: 0.03501681638736045
[Epoch 9, Batch 800] loss: 0.020926774868166832
[Epoch 9, Batch 900] loss: 0.03363852034286538
[Epoch 9, Batch 1000] loss: 0.018598408343350456
[Epoch 9, Batch 1100] loss: 0.04965254236481997
[Epoch 9, Batch 1200] loss: 0.030850288418969286
[Epoch 9, Batch 1300] loss: 0.02296132454837789
[Epoch 9, Batch 1400] loss: 0.032498076831616346
[Epoch 9, Batch 1500] loss: 0.044917592290112225
[Epoch 9, Batch 1600] loss: 0.02853968382696621
[Epoch 9, Batch 1700] loss: 0.032946221680103915
[Epoch 9, Batch 1800] loss: 0.035211075002007416
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0563
Validation Accuracy: 0.9835
Overfitting: 0.0547
Best model saved at epoch 9 with validation loss: 0.0563
[Epoch 10, Batch 100] loss: 0.016168828411464345
[Epoch 10, Batch 200] loss: 0.015872868351116266
[Epoch 10, Batch 300] loss: 0.025462303640961182
[Epoch 10, Batch 400] loss: 0.02905586238899559
[Epoch 10, Batch 500] loss: 0.018419848081830423
[Epoch 10, Batch 600] loss: 0.012099377646181892
[Epoch 10, Batch 700] loss: 0.024287155842794162
[Epoch 10, Batch 800] loss: 0.02396939704172837
[Epoch 10, Batch 900] loss: 0.02640351830254076
[Epoch 10, Batch 1000] loss: 0.03564270721213689
[Epoch 10, Batch 1100] loss: 0.03160179019854695
[Epoch 10, Batch 1200] loss: 0.02589316464640433
[Epoch 10, Batch 1300] loss: 0.033995651621407885
[Epoch 10, Batch 1400] loss: 0.035568201890419
[Epoch 10, Batch 1500] loss: 0.03358658509117959
[Epoch 10, Batch 1600] loss: 0.03283989499876043
[Epoch 10, Batch 1700] loss: 0.03227771234323882
[Epoch 10, Batch 1800] loss: 0.025605950271401525
**STATS for Epoch 10** : 
Average training loss: 0.0009
Average validation loss: 0.0659
Validation Accuracy: 0.9813
Overfitting: 0.0651
[Epoch 11, Batch 100] loss: 0.02474208625153551
[Epoch 11, Batch 200] loss: 0.02288094297171483
[Epoch 11, Batch 300] loss: 0.02494555667937675
[Epoch 11, Batch 400] loss: 0.018656296980807383
[Epoch 11, Batch 500] loss: 0.026900705190091686
[Epoch 11, Batch 600] loss: 0.011816696848109131
[Epoch 11, Batch 700] loss: 0.03917577374995744
[Epoch 11, Batch 800] loss: 0.016943527597723006
[Epoch 11, Batch 900] loss: 0.028181339739458054
[Epoch 11, Batch 1000] loss: 0.022462605539658398
[Epoch 11, Batch 1100] loss: 0.027655246553895268
[Epoch 11, Batch 1200] loss: 0.015815613847807983
[Epoch 11, Batch 1300] loss: 0.021256531698709294
[Epoch 11, Batch 1400] loss: 0.017821526486695802
[Epoch 11, Batch 1500] loss: 0.03260221774598904
[Epoch 11, Batch 1600] loss: 0.020296550686634874
[Epoch 11, Batch 1700] loss: 0.038291573573296774
[Epoch 11, Batch 1800] loss: 0.017993814814763028
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0550
Validation Accuracy: 0.9840
Overfitting: 0.0542
Best model saved at epoch 11 with validation loss: 0.0550
[Epoch 12, Batch 100] loss: 0.01735476337458749
[Epoch 12, Batch 200] loss: 0.021443147050813422
[Epoch 12, Batch 300] loss: 0.009759173957700113
[Epoch 12, Batch 400] loss: 0.016630079401620604
[Epoch 12, Batch 500] loss: 0.015379799686925252
[Epoch 12, Batch 600] loss: 0.01752178301489039
[Epoch 12, Batch 700] loss: 0.013395816300035222
[Epoch 12, Batch 800] loss: 0.01300962057619472
[Epoch 12, Batch 900] loss: 0.01964980741708132
[Epoch 12, Batch 1000] loss: 0.021927253552421463
[Epoch 12, Batch 1100] loss: 0.022020599373609003
[Epoch 12, Batch 1200] loss: 0.02161213210543792
[Epoch 12, Batch 1300] loss: 0.03319566266220136
[Epoch 12, Batch 1400] loss: 0.01787280729642589
[Epoch 12, Batch 1500] loss: 0.024446846487880976
[Epoch 12, Batch 1600] loss: 0.023307097117613012
[Epoch 12, Batch 1700] loss: 0.02371591374738273
[Epoch 12, Batch 1800] loss: 0.02305050225222658
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0559
Validation Accuracy: 0.9839
Overfitting: 0.0552
[Epoch 13, Batch 100] loss: 0.019120352793397615
[Epoch 13, Batch 200] loss: 0.01798874391708523
[Epoch 13, Batch 300] loss: 0.019788352316445525
[Epoch 13, Batch 400] loss: 0.017237009710115672
[Epoch 13, Batch 500] loss: 0.023555101410638598
[Epoch 13, Batch 600] loss: 0.019835428234146094
[Epoch 13, Batch 700] loss: 0.02392307266149146
[Epoch 13, Batch 800] loss: 0.014975425873490166
[Epoch 13, Batch 900] loss: 0.011213215623392898
[Epoch 13, Batch 1000] loss: 0.011144039216360398
[Epoch 13, Batch 1100] loss: 0.02502634394872075
[Epoch 13, Batch 1200] loss: 0.023270106991349168
[Epoch 13, Batch 1300] loss: 0.021906581053845003
[Epoch 13, Batch 1400] loss: 0.017026876561048995
[Epoch 13, Batch 1500] loss: 0.009541100404521784
[Epoch 13, Batch 1600] loss: 0.008888558789562922
[Epoch 13, Batch 1700] loss: 0.007740569174220582
[Epoch 13, Batch 1800] loss: 0.012230460893370036
**STATS for Epoch 13** : 
Average training loss: 0.0005
Average validation loss: 0.0537
Validation Accuracy: 0.9854
Overfitting: 0.0532
Best model saved at epoch 13 with validation loss: 0.0537
[Epoch 14, Batch 100] loss: 0.013780678775874548
[Epoch 14, Batch 200] loss: 0.011469753950404993
[Epoch 14, Batch 300] loss: 0.01439437818357419
[Epoch 14, Batch 400] loss: 0.018888724298303714
[Epoch 14, Batch 500] loss: 0.01335627527041197
[Epoch 14, Batch 600] loss: 0.01841351769537141
[Epoch 14, Batch 700] loss: 0.016149753532044998
[Epoch 14, Batch 800] loss: 0.011531410248808242
[Epoch 14, Batch 900] loss: 0.010519465092911559
[Epoch 14, Batch 1000] loss: 0.015558231991035428
[Epoch 14, Batch 1100] loss: 0.012946055289930883
[Epoch 14, Batch 1200] loss: 0.014765533792042334
[Epoch 14, Batch 1300] loss: 0.012184528140196563
[Epoch 14, Batch 1400] loss: 0.008971686631748526
[Epoch 14, Batch 1500] loss: 0.01696556956248969
[Epoch 14, Batch 1600] loss: 0.020477040652549475
[Epoch 14, Batch 1700] loss: 0.025310079340924857
[Epoch 14, Batch 1800] loss: 0.018580339025520518
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0553
Validation Accuracy: 0.9851
Overfitting: 0.0549
[Epoch 15, Batch 100] loss: 0.01143076540117363
[Epoch 15, Batch 200] loss: 0.015965411050008243
[Epoch 15, Batch 300] loss: 0.015209055193763562
[Epoch 15, Batch 400] loss: 0.016574456951011597
[Epoch 15, Batch 500] loss: 0.006380275567441913
[Epoch 15, Batch 600] loss: 0.014242049415479414
[Epoch 15, Batch 700] loss: 0.012163674145208461
[Epoch 15, Batch 800] loss: 0.013736309830960636
[Epoch 15, Batch 900] loss: 0.008791031044027023
[Epoch 15, Batch 1000] loss: 0.023708630943590377
[Epoch 15, Batch 1100] loss: 0.017894105858781584
[Epoch 15, Batch 1200] loss: 0.005169803252701968
[Epoch 15, Batch 1300] loss: 0.030837328331354
[Epoch 15, Batch 1400] loss: 0.011167829718770008
[Epoch 15, Batch 1500] loss: 0.016110486178486098
[Epoch 15, Batch 1600] loss: 0.009689298980847525
[Epoch 15, Batch 1700] loss: 0.016525685346496174
[Epoch 15, Batch 1800] loss: 0.009359424490726269
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0590
Validation Accuracy: 0.9852
Overfitting: 0.0585
[Epoch 16, Batch 100] loss: 0.008274477737284087
[Epoch 16, Batch 200] loss: 0.0072921928738742285
[Epoch 16, Batch 300] loss: 0.013977470107988665
[Epoch 16, Batch 400] loss: 0.03200922664056634
[Epoch 16, Batch 500] loss: 0.01681736828103567
[Epoch 16, Batch 600] loss: 0.015503028049897694
[Epoch 16, Batch 700] loss: 0.013588036834594277
[Epoch 16, Batch 800] loss: 0.00915169949729716
[Epoch 16, Batch 900] loss: 0.011252104170343955
[Epoch 16, Batch 1000] loss: 0.017531158543433775
[Epoch 16, Batch 1100] loss: 0.005769346783449691
[Epoch 16, Batch 1200] loss: 0.006808586143060893
[Epoch 16, Batch 1300] loss: 0.010932961298310602
[Epoch 16, Batch 1400] loss: 0.005039307343449764
[Epoch 16, Batch 1500] loss: 0.013559385099633801
[Epoch 16, Batch 1600] loss: 0.008872450770500109
[Epoch 16, Batch 1700] loss: 0.014965934875187941
[Epoch 16, Batch 1800] loss: 0.03565183577749849
**STATS for Epoch 16** : 
Average training loss: 0.0002
Average validation loss: 0.0579
Validation Accuracy: 0.9848
Overfitting: 0.0577
[Epoch 17, Batch 100] loss: 0.006888849476235919
[Epoch 17, Batch 200] loss: 0.008579910884857328
[Epoch 17, Batch 300] loss: 0.008914551618322547
[Epoch 17, Batch 400] loss: 0.011711459264556651
[Epoch 17, Batch 500] loss: 0.008620977333875998
[Epoch 17, Batch 600] loss: 0.011310400042611945
[Epoch 17, Batch 700] loss: 0.009865523033272438
[Epoch 17, Batch 800] loss: 0.011961302756949408
[Epoch 17, Batch 900] loss: 0.01164738173893511
[Epoch 17, Batch 1000] loss: 0.017246795603903138
[Epoch 17, Batch 1100] loss: 0.010174684887149397
[Epoch 17, Batch 1200] loss: 0.01274129890459335
[Epoch 17, Batch 1300] loss: 0.022819463505957174
[Epoch 17, Batch 1400] loss: 0.0068970447144965875
[Epoch 17, Batch 1500] loss: 0.006383683978283443
[Epoch 17, Batch 1600] loss: 0.012710406940555004
[Epoch 17, Batch 1700] loss: 0.018581875098361705
[Epoch 17, Batch 1800] loss: 0.01929081131480871
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0607
Validation Accuracy: 0.9854
Overfitting: 0.0604
[Epoch 18, Batch 100] loss: 0.005625135679805453
[Epoch 18, Batch 200] loss: 0.01029595135594718
[Epoch 18, Batch 300] loss: 0.006153805278054278
[Epoch 18, Batch 400] loss: 0.004964202432229285
[Epoch 18, Batch 500] loss: 0.01098819423482837
[Epoch 18, Batch 600] loss: 0.009161942870741768
[Epoch 18, Batch 700] loss: 0.012743089191371838
[Epoch 18, Batch 800] loss: 0.012610223371339657
[Epoch 18, Batch 900] loss: 0.012862701779324652
[Epoch 18, Batch 1000] loss: 0.010758237614136306
[Epoch 18, Batch 1100] loss: 0.0106158632751567
[Epoch 18, Batch 1200] loss: 0.0075173365137379735
[Epoch 18, Batch 1300] loss: 0.006235223341384426
[Epoch 18, Batch 1400] loss: 0.01715687725701173
[Epoch 18, Batch 1500] loss: 0.011486751293127782
[Epoch 18, Batch 1600] loss: 0.007312125230998845
[Epoch 18, Batch 1700] loss: 0.010927854945551303
[Epoch 18, Batch 1800] loss: 0.005617354618050285
**STATS for Epoch 18** : 
Average training loss: 0.0005
Average validation loss: 0.0633
Validation Accuracy: 0.9847
Overfitting: 0.0628
[Epoch 19, Batch 100] loss: 0.004635956659772091
[Epoch 19, Batch 200] loss: 0.002801562053721227
[Epoch 19, Batch 300] loss: 0.003622367309293395
[Epoch 19, Batch 400] loss: 0.0025305109905150404
[Epoch 19, Batch 500] loss: 0.008595263031596688
[Epoch 19, Batch 600] loss: 0.015726206022703762
[Epoch 19, Batch 700] loss: 0.00750760111382533
[Epoch 19, Batch 800] loss: 0.004802893741784828
[Epoch 19, Batch 900] loss: 0.006953260786099235
[Epoch 19, Batch 1000] loss: 0.005546827260588998
[Epoch 19, Batch 1100] loss: 0.00868088883614405
[Epoch 19, Batch 1200] loss: 0.013581279974324616
[Epoch 19, Batch 1300] loss: 0.010572911738075846
[Epoch 19, Batch 1400] loss: 0.012225112839247458
[Epoch 19, Batch 1500] loss: 0.006351075898555223
[Epoch 19, Batch 1600] loss: 0.007775716622383015
[Epoch 19, Batch 1700] loss: 0.01834793835170785
[Epoch 19, Batch 1800] loss: 0.01202820260333283
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0682
Validation Accuracy: 0.9836
Overfitting: 0.0678
[Epoch 20, Batch 100] loss: 0.0072886158249514214
[Epoch 20, Batch 200] loss: 0.0055783454201900895
[Epoch 20, Batch 300] loss: 0.013057444152191238
[Epoch 20, Batch 400] loss: 0.007827445156117392
[Epoch 20, Batch 500] loss: 0.005409499577655765
[Epoch 20, Batch 600] loss: 0.004908594324730302
[Epoch 20, Batch 700] loss: 0.00917078154698288
[Epoch 20, Batch 800] loss: 0.004341628560362096
[Epoch 20, Batch 900] loss: 0.003213689111203166
[Epoch 20, Batch 1000] loss: 0.00389916990118536
[Epoch 20, Batch 1100] loss: 0.008742699487036133
[Epoch 20, Batch 1200] loss: 0.005935913426221759
[Epoch 20, Batch 1300] loss: 0.007716624125660019
[Epoch 20, Batch 1400] loss: 0.006707191621725741
[Epoch 20, Batch 1500] loss: 0.01452416123169769
[Epoch 20, Batch 1600] loss: 0.009249469459391549
[Epoch 20, Batch 1700] loss: 0.01214824765026151
[Epoch 20, Batch 1800] loss: 0.0075906626480878
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0572
Validation Accuracy: 0.9865
Overfitting: 0.0570
[Epoch 21, Batch 100] loss: 0.004635963229948175
[Epoch 21, Batch 200] loss: 0.01027123812298214
[Epoch 21, Batch 300] loss: 0.006377848476041663
[Epoch 21, Batch 400] loss: 0.004176273545929234
[Epoch 21, Batch 500] loss: 0.006798760674469975
[Epoch 21, Batch 600] loss: 0.00395959837604778
[Epoch 21, Batch 700] loss: 0.011039509195655342
[Epoch 21, Batch 800] loss: 0.005385564384442887
[Epoch 21, Batch 900] loss: 0.010443718957469343
[Epoch 21, Batch 1000] loss: 0.009037432221581411
[Epoch 21, Batch 1100] loss: 0.015941576367704328
[Epoch 21, Batch 1200] loss: 0.0034303204453532033
[Epoch 21, Batch 1300] loss: 0.004910069370159817
[Epoch 21, Batch 1400] loss: 0.0042319950868477466
[Epoch 21, Batch 1500] loss: 0.004050484413699564
[Epoch 21, Batch 1600] loss: 0.004211024316530257
[Epoch 21, Batch 1700] loss: 0.006799518512057717
[Epoch 21, Batch 1800] loss: 0.0034608488544768078
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0585
Validation Accuracy: 0.9866
Overfitting: 0.0584
[Epoch 22, Batch 100] loss: 0.001099308426386898
[Epoch 22, Batch 200] loss: 0.0041170330682871285
[Epoch 22, Batch 300] loss: 0.0066832724122696165
[Epoch 22, Batch 400] loss: 0.005381106380611982
[Epoch 22, Batch 500] loss: 0.008964705112780962
[Epoch 22, Batch 600] loss: 0.0027754750151220264
[Epoch 22, Batch 700] loss: 0.006964016982274188
[Epoch 22, Batch 800] loss: 0.005551404962800746
[Epoch 22, Batch 900] loss: 0.005567874029260907
[Epoch 22, Batch 1000] loss: 0.013437975740760492
[Epoch 22, Batch 1100] loss: 0.011828694176776367
[Epoch 22, Batch 1200] loss: 0.002847036793613995
[Epoch 22, Batch 1300] loss: 0.0029394144332195535
[Epoch 22, Batch 1400] loss: 0.0031249008498306806
[Epoch 22, Batch 1500] loss: 0.003301128537876252
[Epoch 22, Batch 1600] loss: 0.006321414842030606
[Epoch 22, Batch 1700] loss: 0.002408769870678498
[Epoch 22, Batch 1800] loss: 0.016993954050383307
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0645
Validation Accuracy: 0.9855
Overfitting: 0.0643
[Epoch 23, Batch 100] loss: 0.004216151180435191
[Epoch 23, Batch 200] loss: 0.005574224645667983
[Epoch 23, Batch 300] loss: 0.00605295376000413
[Epoch 23, Batch 400] loss: 0.0033380284423469675
[Epoch 23, Batch 500] loss: 0.005781205826272071
[Epoch 23, Batch 600] loss: 0.010922259027795462
[Epoch 23, Batch 700] loss: 0.003191595809623209
[Epoch 23, Batch 800] loss: 0.002523142159521683
[Epoch 23, Batch 900] loss: 0.00239535070969211
[Epoch 23, Batch 1000] loss: 0.004098439061139913
[Epoch 23, Batch 1100] loss: 0.0073191684616199385
[Epoch 23, Batch 1200] loss: 0.0055226447660385244
[Epoch 23, Batch 1300] loss: 0.006283234998865055
[Epoch 23, Batch 1400] loss: 0.0038331611635553033
[Epoch 23, Batch 1500] loss: 0.004676656066615976
[Epoch 23, Batch 1600] loss: 0.0048376223139922556
[Epoch 23, Batch 1700] loss: 0.007029501791554367
[Epoch 23, Batch 1800] loss: 0.006061754599411415
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0683
Validation Accuracy: 0.9849
Overfitting: 0.0681
[Epoch 24, Batch 100] loss: 0.008013398648095062
[Epoch 24, Batch 200] loss: 0.0039970816189870105
[Epoch 24, Batch 300] loss: 0.00595176951139365
[Epoch 24, Batch 400] loss: 0.010216665742144642
[Epoch 24, Batch 500] loss: 0.006916763439551658
[Epoch 24, Batch 600] loss: 0.00279106783769123
[Epoch 24, Batch 700] loss: 0.0024796945747573317
[Epoch 24, Batch 800] loss: 0.0017084496262626202
[Epoch 24, Batch 900] loss: 0.008896225895452758
[Epoch 24, Batch 1000] loss: 0.004175039055534739
[Epoch 24, Batch 1100] loss: 0.014763943557809397
[Epoch 24, Batch 1200] loss: 0.005184416349543426
[Epoch 24, Batch 1300] loss: 0.005618973970557022
[Epoch 24, Batch 1400] loss: 0.002887110876868313
[Epoch 24, Batch 1500] loss: 0.0037570884765580105
[Epoch 24, Batch 1600] loss: 0.0037891699440295665
[Epoch 24, Batch 1700] loss: 0.005705473163454826
[Epoch 24, Batch 1800] loss: 0.014523016637038495
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0635
Validation Accuracy: 0.9853
Overfitting: 0.0632
Fold 2 validation loss: 0.0635
Mean validation loss across all folds for Trial 14 is 0.0663 with trial config:  l1: 128, l2: 128, lr: 0.0011062854566266248, batch_size: 16
[I 2024-11-21 23:45:19,337] Trial 13 finished with value: 0.06625476726224519 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0011062854566266248, 'batch_size': 16}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 15:
  l1: 256, l2: 128, lr: 0.009836048672425646, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.701451849937439
**STATS for Epoch 1** : 
Average training loss: 0.0575
Average validation loss: 0.3340
Validation Accuracy: 0.8980
Overfitting: 0.2765
Best model saved at epoch 1 with validation loss: 0.3340
[Epoch 2, Batch 100] loss: 0.22724954515695572
**STATS for Epoch 2** : 
Average training loss: 0.0244
Average validation loss: 0.1816
Validation Accuracy: 0.9459
Overfitting: 0.1572
Best model saved at epoch 2 with validation loss: 0.1816
[Epoch 3, Batch 100] loss: 0.1327686044946313
**STATS for Epoch 3** : 
Average training loss: 0.0143
Average validation loss: 0.1063
Validation Accuracy: 0.9671
Overfitting: 0.0921
Best model saved at epoch 3 with validation loss: 0.1063
[Epoch 4, Batch 100] loss: 0.09710664432495833
**STATS for Epoch 4** : 
Average training loss: 0.0113
Average validation loss: 0.0976
Validation Accuracy: 0.9691
Overfitting: 0.0863
Best model saved at epoch 4 with validation loss: 0.0976
[Epoch 5, Batch 100] loss: 0.07493882913142443
**STATS for Epoch 5** : 
Average training loss: 0.0127
Average validation loss: 0.0907
Validation Accuracy: 0.9706
Overfitting: 0.0781
Best model saved at epoch 5 with validation loss: 0.0907
[Epoch 6, Batch 100] loss: 0.06791978294029832
**STATS for Epoch 6** : 
Average training loss: 0.0085
Average validation loss: 0.0754
Validation Accuracy: 0.9763
Overfitting: 0.0670
[I 2024-11-21 23:46:21,025] Trial 14 pruned. 

Selected Hyperparameters for Trial 16:
  l1: 128, l2: 128, lr: 0.008482971226840623, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.6075057831406594
[Epoch 1, Batch 200] loss: 0.38485861286520956
[Epoch 1, Batch 300] loss: 0.22371568478643894
[Epoch 1, Batch 400] loss: 0.14587286707013847
**STATS for Epoch 1** : 
Average training loss: 0.0206
Average validation loss: 0.1514
Validation Accuracy: 0.9540
Overfitting: 0.1308
Best model saved at epoch 1 with validation loss: 0.1514
[Epoch 2, Batch 100] loss: 0.11396338027901948
[Epoch 2, Batch 200] loss: 0.09820514019578695
[Epoch 2, Batch 300] loss: 0.09589155302383005
[Epoch 2, Batch 400] loss: 0.09165239008143544
**STATS for Epoch 2** : 
Average training loss: 0.0133
Average validation loss: 0.0891
Validation Accuracy: 0.9715
Overfitting: 0.0758
Best model saved at epoch 2 with validation loss: 0.0891
[Epoch 3, Batch 100] loss: 0.06822763916221447
[Epoch 3, Batch 200] loss: 0.07440922320820391
[Epoch 3, Batch 300] loss: 0.0677939704246819
[Epoch 3, Batch 400] loss: 0.06926358870696277
**STATS for Epoch 3** : 
Average training loss: 0.0093
Average validation loss: 0.0917
Validation Accuracy: 0.9709
Overfitting: 0.0824
[Epoch 4, Batch 100] loss: 0.057706730579957365
[Epoch 4, Batch 200] loss: 0.048631142657250166
[Epoch 4, Batch 300] loss: 0.05208129911450669
[Epoch 4, Batch 400] loss: 0.04840529774548486
**STATS for Epoch 4** : 
Average training loss: 0.0087
Average validation loss: 0.0698
Validation Accuracy: 0.9781
Overfitting: 0.0611
Best model saved at epoch 4 with validation loss: 0.0698
[Epoch 5, Batch 100] loss: 0.03934869160759263
[Epoch 5, Batch 200] loss: 0.03654327447526157
[Epoch 5, Batch 300] loss: 0.042855353138875216
[Epoch 5, Batch 400] loss: 0.05021604639478028
**STATS for Epoch 5** : 
Average training loss: 0.0070
Average validation loss: 0.0700
Validation Accuracy: 0.9787
Overfitting: 0.0630
[Epoch 6, Batch 100] loss: 0.025876081431633793
[Epoch 6, Batch 200] loss: 0.029265729924081826
[Epoch 6, Batch 300] loss: 0.033720641634427014
[Epoch 6, Batch 400] loss: 0.03727637780248187
**STATS for Epoch 6** : 
Average training loss: 0.0049
Average validation loss: 0.0654
Validation Accuracy: 0.9813
Overfitting: 0.0605
Best model saved at epoch 6 with validation loss: 0.0654
[Epoch 7, Batch 100] loss: 0.02393591264175484
[Epoch 7, Batch 200] loss: 0.02436848005920183
[Epoch 7, Batch 300] loss: 0.03008282362949103
[Epoch 7, Batch 400] loss: 0.030265718232258224
**STATS for Epoch 7** : 
Average training loss: 0.0047
Average validation loss: 0.0563
Validation Accuracy: 0.9835
Overfitting: 0.0517
Best model saved at epoch 7 with validation loss: 0.0563
[Epoch 8, Batch 100] loss: 0.019023608055431396
[Epoch 8, Batch 200] loss: 0.028258158055250532
[Epoch 8, Batch 300] loss: 0.019370094425685238
[Epoch 8, Batch 400] loss: 0.021664247551962036
**STATS for Epoch 8** : 
Average training loss: 0.0051
Average validation loss: 0.0631
Validation Accuracy: 0.9824
Overfitting: 0.0580
[Epoch 9, Batch 100] loss: 0.021068811599106993
[Epoch 9, Batch 200] loss: 0.022117526904621626
[Epoch 9, Batch 300] loss: 0.01820755252498202
[Epoch 9, Batch 400] loss: 0.025447482933814172
**STATS for Epoch 9** : 
Average training loss: 0.0029
Average validation loss: 0.0595
Validation Accuracy: 0.9840
Overfitting: 0.0566
[Epoch 10, Batch 100] loss: 0.016036910837428878
[Epoch 10, Batch 200] loss: 0.01436868498683907
[Epoch 10, Batch 300] loss: 0.016488448500749656
[Epoch 10, Batch 400] loss: 0.014468641188868788
**STATS for Epoch 10** : 
Average training loss: 0.0026
Average validation loss: 0.0573
Validation Accuracy: 0.9842
Overfitting: 0.0547
[Epoch 11, Batch 100] loss: 0.008868956256883394
[Epoch 11, Batch 200] loss: 0.0097614038206666
[Epoch 11, Batch 300] loss: 0.015341803106566658
[Epoch 11, Batch 400] loss: 0.017587372062844223
**STATS for Epoch 11** : 
Average training loss: 0.0020
Average validation loss: 0.0601
Validation Accuracy: 0.9846
Overfitting: 0.0581
[Epoch 12, Batch 100] loss: 0.014303535692233709
[Epoch 12, Batch 200] loss: 0.006505964946045424
[Epoch 12, Batch 300] loss: 0.009411092465816182
[Epoch 12, Batch 400] loss: 0.015112945008513633
**STATS for Epoch 12** : 
Average training loss: 0.0016
Average validation loss: 0.0606
Validation Accuracy: 0.9843
Overfitting: 0.0590
[Epoch 13, Batch 100] loss: 0.004882212317897938
[Epoch 13, Batch 200] loss: 0.00873598054258764
[Epoch 13, Batch 300] loss: 0.0062320834680576805
[Epoch 13, Batch 400] loss: 0.01774801959749311
**STATS for Epoch 13** : 
Average training loss: 0.0041
Average validation loss: 0.0698
Validation Accuracy: 0.9818
Overfitting: 0.0657
[Epoch 14, Batch 100] loss: 0.008888310301626916
[Epoch 14, Batch 200] loss: 0.011972463097481522
[Epoch 14, Batch 300] loss: 0.008901360717281932
[Epoch 14, Batch 400] loss: 0.008022941421659198
**STATS for Epoch 14** : 
Average training loss: 0.0025
Average validation loss: 0.0615
Validation Accuracy: 0.9842
Overfitting: 0.0590
[Epoch 15, Batch 100] loss: 0.00990812215655751
[Epoch 15, Batch 200] loss: 0.004821827154883067
[Epoch 15, Batch 300] loss: 0.004287058915324451
[Epoch 15, Batch 400] loss: 0.01344453495068592
**STATS for Epoch 15** : 
Average training loss: 0.0013
Average validation loss: 0.0712
Validation Accuracy: 0.9833
Overfitting: 0.0699
[Epoch 16, Batch 100] loss: 0.009714735515026406
[Epoch 16, Batch 200] loss: 0.0033348260087223023
[Epoch 16, Batch 300] loss: 0.003588955638151674
[Epoch 16, Batch 400] loss: 0.0031037549335815127
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0612
Validation Accuracy: 0.9861
Overfitting: 0.0606
[Epoch 17, Batch 100] loss: 0.0016036105426610447
[Epoch 17, Batch 200] loss: 0.0016841269063115761
[Epoch 17, Batch 300] loss: 0.0014652771632245277
[Epoch 17, Batch 400] loss: 0.0019197387715030345
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0683
Validation Accuracy: 0.9854
Overfitting: 0.0680
[Epoch 18, Batch 100] loss: 0.001962949272183323
[Epoch 18, Batch 200] loss: 0.0009657225639693933
[Epoch 18, Batch 300] loss: 0.001881513509333672
[Epoch 18, Batch 400] loss: 0.0008646213086649368
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0651
Validation Accuracy: 0.9865
Overfitting: 0.0651
[Epoch 19, Batch 100] loss: 0.0008674481339949125
[Epoch 19, Batch 200] loss: 0.0005572397450259814
[Epoch 19, Batch 300] loss: 0.00047714374592942475
[Epoch 19, Batch 400] loss: 0.0011760913387342954
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0691
Validation Accuracy: 0.9861
Overfitting: 0.0690
[Epoch 20, Batch 100] loss: 0.0007058598006165084
[Epoch 20, Batch 200] loss: 0.0012282676961444848
[Epoch 20, Batch 300] loss: 0.0003816099314508392
[Epoch 20, Batch 400] loss: 0.0008765300548805044
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0675
Validation Accuracy: 0.9867
Overfitting: 0.0674
[Epoch 21, Batch 100] loss: 0.0008611676519331013
[Epoch 21, Batch 200] loss: 0.00029790639910913795
[Epoch 21, Batch 300] loss: 0.00023242492179520013
[Epoch 21, Batch 400] loss: 0.0005413018656554413
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0681
Validation Accuracy: 0.9867
Overfitting: 0.0681
[Epoch 22, Batch 100] loss: 0.0003779967772352677
[Epoch 22, Batch 200] loss: 0.0002062017812207273
[Epoch 22, Batch 300] loss: 0.00018052191397146088
[Epoch 22, Batch 400] loss: 0.0001575638544770186
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0690
Validation Accuracy: 0.9867
Overfitting: 0.0689
[Epoch 23, Batch 100] loss: 0.00015515732437734186
[Epoch 23, Batch 200] loss: 0.00017073677394819243
[Epoch 23, Batch 300] loss: 0.00017848765938481394
[Epoch 23, Batch 400] loss: 0.00014048944176238366
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0697
Validation Accuracy: 0.9866
Overfitting: 0.0697
[Epoch 24, Batch 100] loss: 0.00013469421324771247
[Epoch 24, Batch 200] loss: 0.0001368130529613154
[Epoch 24, Batch 300] loss: 0.00011300063126157056
[Epoch 24, Batch 400] loss: 0.00014152335845210473
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0699
Validation Accuracy: 0.9868
Overfitting: 0.0698
Fold 1 validation loss: 0.0699
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.1354631090164187
[Epoch 1, Batch 200] loss: 0.4965329101681709
[Epoch 1, Batch 300] loss: 0.2247721588239074
[Epoch 1, Batch 400] loss: 0.1888707982003689
**STATS for Epoch 1** : 
Average training loss: 0.0209
Average validation loss: 0.1244
Validation Accuracy: 0.9629
Overfitting: 0.1035
Best model saved at epoch 1 with validation loss: 0.1244
[Epoch 2, Batch 100] loss: 0.131799209844321
[Epoch 2, Batch 200] loss: 0.1043970164656639
[Epoch 2, Batch 300] loss: 0.0976494850218296
[Epoch 2, Batch 400] loss: 0.09501813439652324
**STATS for Epoch 2** : 
Average training loss: 0.0141
Average validation loss: 0.0805
Validation Accuracy: 0.9747
Overfitting: 0.0664
Best model saved at epoch 2 with validation loss: 0.0805
[Epoch 3, Batch 100] loss: 0.06722655849996954
[Epoch 3, Batch 200] loss: 0.07695796445477754
[Epoch 3, Batch 300] loss: 0.06407357817050069
[Epoch 3, Batch 400] loss: 0.07759434952400625
**STATS for Epoch 3** : 
Average training loss: 0.0103
Average validation loss: 0.0689
Validation Accuracy: 0.9790
Overfitting: 0.0587
Best model saved at epoch 3 with validation loss: 0.0689
[Epoch 4, Batch 100] loss: 0.04450994377257302
[Epoch 4, Batch 200] loss: 0.05155542301479727
[Epoch 4, Batch 300] loss: 0.052957496573217216
[Epoch 4, Batch 400] loss: 0.06405283604748548
**STATS for Epoch 4** : 
Average training loss: 0.0074
Average validation loss: 0.0660
Validation Accuracy: 0.9789
Overfitting: 0.0586
Best model saved at epoch 4 with validation loss: 0.0660
[Epoch 5, Batch 100] loss: 0.03902213344816118
[Epoch 5, Batch 200] loss: 0.04219502836698666
[Epoch 5, Batch 300] loss: 0.04721605434082449
[Epoch 5, Batch 400] loss: 0.039477873134892434
**STATS for Epoch 5** : 
Average training loss: 0.0068
Average validation loss: 0.0652
Validation Accuracy: 0.9800
Overfitting: 0.0585
Best model saved at epoch 5 with validation loss: 0.0652
[Epoch 6, Batch 100] loss: 0.03760448342538439
[Epoch 6, Batch 200] loss: 0.035912381990347055
[Epoch 6, Batch 300] loss: 0.03580950279516401
[Epoch 6, Batch 400] loss: 0.036714883296517654
**STATS for Epoch 6** : 
Average training loss: 0.0052
Average validation loss: 0.0551
Validation Accuracy: 0.9835
Overfitting: 0.0500
Best model saved at epoch 6 with validation loss: 0.0551
[Epoch 7, Batch 100] loss: 0.023803064243984408
[Epoch 7, Batch 200] loss: 0.028633135015843435
[Epoch 7, Batch 300] loss: 0.032730035862186924
[Epoch 7, Batch 400] loss: 0.031305079381563704
**STATS for Epoch 7** : 
Average training loss: 0.0041
Average validation loss: 0.0562
Validation Accuracy: 0.9844
Overfitting: 0.0521
[Epoch 8, Batch 100] loss: 0.02434867683070479
[Epoch 8, Batch 200] loss: 0.02492509820382111
[Epoch 8, Batch 300] loss: 0.022259991501341572
[Epoch 8, Batch 400] loss: 0.023579278129618617
**STATS for Epoch 8** : 
Average training loss: 0.0040
Average validation loss: 0.0652
Validation Accuracy: 0.9818
Overfitting: 0.0611
[Epoch 9, Batch 100] loss: 0.024292313641635702
[Epoch 9, Batch 200] loss: 0.023769800690643023
[Epoch 9, Batch 300] loss: 0.018052023725176697
[Epoch 9, Batch 400] loss: 0.01968763101263903
**STATS for Epoch 9** : 
Average training loss: 0.0030
Average validation loss: 0.0526
Validation Accuracy: 0.9854
Overfitting: 0.0496
Best model saved at epoch 9 with validation loss: 0.0526
[Epoch 10, Batch 100] loss: 0.014473309616005282
[Epoch 10, Batch 200] loss: 0.011978315167070833
[Epoch 10, Batch 300] loss: 0.017115665010023803
[Epoch 10, Batch 400] loss: 0.018829016063245944
**STATS for Epoch 10** : 
Average training loss: 0.0036
Average validation loss: 0.0616
Validation Accuracy: 0.9835
Overfitting: 0.0580
[Epoch 11, Batch 100] loss: 0.015371167595876613
[Epoch 11, Batch 200] loss: 0.015686205695164972
[Epoch 11, Batch 300] loss: 0.013542729523032903
[Epoch 11, Batch 400] loss: 0.018112385487402207
**STATS for Epoch 11** : 
Average training loss: 0.0032
Average validation loss: 0.0558
Validation Accuracy: 0.9847
Overfitting: 0.0525
[Epoch 12, Batch 100] loss: 0.013613839957397431
[Epoch 12, Batch 200] loss: 0.013065158724348293
[Epoch 12, Batch 300] loss: 0.007430843136608019
[Epoch 12, Batch 400] loss: 0.01806059761016513
**STATS for Epoch 12** : 
Average training loss: 0.0022
Average validation loss: 0.0586
Validation Accuracy: 0.9848
Overfitting: 0.0564
[Epoch 13, Batch 100] loss: 0.007389316493608931
[Epoch 13, Batch 200] loss: 0.008643882946053054
[Epoch 13, Batch 300] loss: 0.00802410577503906
[Epoch 13, Batch 400] loss: 0.012526686849159887
**STATS for Epoch 13** : 
Average training loss: 0.0017
Average validation loss: 0.0557
Validation Accuracy: 0.9863
Overfitting: 0.0539
[Epoch 14, Batch 100] loss: 0.006807557589818316
[Epoch 14, Batch 200] loss: 0.007060881836659974
[Epoch 14, Batch 300] loss: 0.013177001239018864
[Epoch 14, Batch 400] loss: 0.012178927408604068
**STATS for Epoch 14** : 
Average training loss: 0.0013
Average validation loss: 0.0581
Validation Accuracy: 0.9861
Overfitting: 0.0568
[Epoch 15, Batch 100] loss: 0.006234026680995157
[Epoch 15, Batch 200] loss: 0.007684138916956727
[Epoch 15, Batch 300] loss: 0.008469160714139435
[Epoch 15, Batch 400] loss: 0.004262706850713584
**STATS for Epoch 15** : 
Average training loss: 0.0012
Average validation loss: 0.0639
Validation Accuracy: 0.9850
Overfitting: 0.0628
[Epoch 16, Batch 100] loss: 0.006641341600188752
[Epoch 16, Batch 200] loss: 0.0054566278570746364
[Epoch 16, Batch 300] loss: 0.006003654712985735
[Epoch 16, Batch 400] loss: 0.00729561878444656
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0690
Validation Accuracy: 0.9847
Overfitting: 0.0683
[Epoch 17, Batch 100] loss: 0.009319232502239174
[Epoch 17, Batch 200] loss: 0.0053416048707458684
[Epoch 17, Batch 300] loss: 0.004368844311693465
[Epoch 17, Batch 400] loss: 0.010932649375281472
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0546
Validation Accuracy: 0.9873
Overfitting: 0.0542
[Epoch 18, Batch 100] loss: 0.0017620250772233702
[Epoch 18, Batch 200] loss: 0.0024889734081466486
[Epoch 18, Batch 300] loss: 0.0050234517563512784
[Epoch 18, Batch 400] loss: 0.006558967294113245
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0576
Validation Accuracy: 0.9875
Overfitting: 0.0566
[Epoch 19, Batch 100] loss: 0.005357110612385441
[Epoch 19, Batch 200] loss: 0.0022500197009640032
[Epoch 19, Batch 300] loss: 0.0028770730645555887
[Epoch 19, Batch 400] loss: 0.00545511365899074
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0718
Validation Accuracy: 0.9841
Overfitting: 0.0712
[Epoch 20, Batch 100] loss: 0.0032250260973796683
[Epoch 20, Batch 200] loss: 0.0026061105659800888
[Epoch 20, Batch 300] loss: 0.008159100746670447
[Epoch 20, Batch 400] loss: 0.012272004411652233
**STATS for Epoch 20** : 
Average training loss: 0.0009
Average validation loss: 0.0666
Validation Accuracy: 0.9858
Overfitting: 0.0658
[Epoch 21, Batch 100] loss: 0.004274080297750516
[Epoch 21, Batch 200] loss: 0.005887509632977981
[Epoch 21, Batch 300] loss: 0.005767592867953226
[Epoch 21, Batch 400] loss: 0.006937988082945594
**STATS for Epoch 21** : 
Average training loss: 0.0014
Average validation loss: 0.0613
Validation Accuracy: 0.9866
Overfitting: 0.0598
[Epoch 22, Batch 100] loss: 0.003180111783440225
[Epoch 22, Batch 200] loss: 0.00294820443050412
[Epoch 22, Batch 300] loss: 0.0026570930616844637
[Epoch 22, Batch 400] loss: 0.004275038956213848
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0602
Validation Accuracy: 0.9878
Overfitting: 0.0599
[Epoch 23, Batch 100] loss: 0.0008818219631893953
[Epoch 23, Batch 200] loss: 0.005489822943422951
[Epoch 23, Batch 300] loss: 0.0032387966519581823
[Epoch 23, Batch 400] loss: 0.0026052623799614595
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0643
Validation Accuracy: 0.9870
Overfitting: 0.0637
[Epoch 24, Batch 100] loss: 0.011177740811081093
[Epoch 24, Batch 200] loss: 0.003512314521804001
[Epoch 24, Batch 300] loss: 0.004156700390167316
[Epoch 24, Batch 400] loss: 0.001626827854476005
**STATS for Epoch 24** : 
Average training loss: 0.0008
Average validation loss: 0.0702
Validation Accuracy: 0.9862
Overfitting: 0.0694
Fold 2 validation loss: 0.0702
Mean validation loss across all folds for Trial 16 is 0.0700 with trial config:  l1: 128, l2: 128, lr: 0.008482971226840623, batch_size: 64
[I 2024-11-21 23:55:43,769] Trial 15 finished with value: 0.07003246271494881 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.008482971226840623, 'batch_size': 64}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 17:
  l1: 256, l2: 64, lr: 0.011006881336688933, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.4831322768330575
[Epoch 1, Batch 200] loss: 0.29558251045644285
**STATS for Epoch 1** : 
Average training loss: 0.0284
Average validation loss: 0.2011
Validation Accuracy: 0.9368
Overfitting: 0.1727
Best model saved at epoch 1 with validation loss: 0.2011
[Epoch 2, Batch 100] loss: 0.14817571721971035
[Epoch 2, Batch 200] loss: 0.11609702657908201
**STATS for Epoch 2** : 
Average training loss: 0.0179
Average validation loss: 0.1111
Validation Accuracy: 0.9656
Overfitting: 0.0932
Best model saved at epoch 2 with validation loss: 0.1111
[Epoch 3, Batch 100] loss: 0.08478972807526589
[Epoch 3, Batch 200] loss: 0.0815828307531774
**STATS for Epoch 3** : 
Average training loss: 0.0134
Average validation loss: 0.1176
Validation Accuracy: 0.9642
Overfitting: 0.1042
[Epoch 4, Batch 100] loss: 0.06995437677949667
[Epoch 4, Batch 200] loss: 0.0640492139942944
**STATS for Epoch 4** : 
Average training loss: 0.0083
Average validation loss: 0.0784
Validation Accuracy: 0.9760
Overfitting: 0.0701
Best model saved at epoch 4 with validation loss: 0.0784
[Epoch 5, Batch 100] loss: 0.05430348358582705
[Epoch 5, Batch 200] loss: 0.05603577285073698
**STATS for Epoch 5** : 
Average training loss: 0.0066
Average validation loss: 0.0712
Validation Accuracy: 0.9780
Overfitting: 0.0647
Best model saved at epoch 5 with validation loss: 0.0712
[Epoch 6, Batch 100] loss: 0.040995940156281
[Epoch 6, Batch 200] loss: 0.04266375936800614
**STATS for Epoch 6** : 
Average training loss: 0.0067
Average validation loss: 0.0694
Validation Accuracy: 0.9786
Overfitting: 0.0626
Best model saved at epoch 6 with validation loss: 0.0694
[Epoch 7, Batch 100] loss: 0.029859258155338467
[Epoch 7, Batch 200] loss: 0.034421269865706566
**STATS for Epoch 7** : 
Average training loss: 0.0051
Average validation loss: 0.0653
Validation Accuracy: 0.9805
Overfitting: 0.0602
Best model saved at epoch 7 with validation loss: 0.0653
[Epoch 8, Batch 100] loss: 0.025820271163247525
[Epoch 8, Batch 200] loss: 0.030754815097898246
**STATS for Epoch 8** : 
Average training loss: 0.0042
Average validation loss: 0.0710
Validation Accuracy: 0.9788
Overfitting: 0.0668
[Epoch 9, Batch 100] loss: 0.024097846555523574
[Epoch 9, Batch 200] loss: 0.023828240006696432
**STATS for Epoch 9** : 
Average training loss: 0.0037
Average validation loss: 0.0673
Validation Accuracy: 0.9798
Overfitting: 0.0636
[Epoch 10, Batch 100] loss: 0.021396982844453304
[Epoch 10, Batch 200] loss: 0.02319244506652467
**STATS for Epoch 10** : 
Average training loss: 0.0036
Average validation loss: 0.0722
Validation Accuracy: 0.9804
Overfitting: 0.0686
[Epoch 11, Batch 100] loss: 0.01785090544843115
[Epoch 11, Batch 200] loss: 0.01180154231376946
**STATS for Epoch 11** : 
Average training loss: 0.0028
Average validation loss: 0.0575
Validation Accuracy: 0.9837
Overfitting: 0.0546
Best model saved at epoch 11 with validation loss: 0.0575
[Epoch 12, Batch 100] loss: 0.013550786532578058
[Epoch 12, Batch 200] loss: 0.015266522543970495
**STATS for Epoch 12** : 
Average training loss: 0.0015
Average validation loss: 0.0669
Validation Accuracy: 0.9833
Overfitting: 0.0654
[Epoch 13, Batch 100] loss: 0.0115223675215384
[Epoch 13, Batch 200] loss: 0.009301994659472257
**STATS for Epoch 13** : 
Average training loss: 0.0021
Average validation loss: 0.0660
Validation Accuracy: 0.9828
Overfitting: 0.0639
[Epoch 14, Batch 100] loss: 0.017284876401536167
[Epoch 14, Batch 200] loss: 0.010808995469124056
**STATS for Epoch 14** : 
Average training loss: 0.0022
Average validation loss: 0.0702
Validation Accuracy: 0.9814
Overfitting: 0.0681
[Epoch 15, Batch 100] loss: 0.00892250485776458
[Epoch 15, Batch 200] loss: 0.007982717770210002
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0703
Validation Accuracy: 0.9828
Overfitting: 0.0694
[Epoch 16, Batch 100] loss: 0.005264741840946953
[Epoch 16, Batch 200] loss: 0.009843819112575147
**STATS for Epoch 16** : 
Average training loss: 0.0012
Average validation loss: 0.0689
Validation Accuracy: 0.9829
Overfitting: 0.0677
[Epoch 17, Batch 100] loss: 0.007667485743149882
[Epoch 17, Batch 200] loss: 0.005506613376783207
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0657
Validation Accuracy: 0.9856
Overfitting: 0.0650
[Epoch 18, Batch 100] loss: 0.00612009225107613
[Epoch 18, Batch 200] loss: 0.004168272675160551
**STATS for Epoch 18** : 
Average training loss: 0.0020
Average validation loss: 0.0828
Validation Accuracy: 0.9812
Overfitting: 0.0807
[Epoch 19, Batch 100] loss: 0.012993434994423297
[Epoch 19, Batch 200] loss: 0.005813248029735405
**STATS for Epoch 19** : 
Average training loss: 0.0012
Average validation loss: 0.0774
Validation Accuracy: 0.9825
Overfitting: 0.0761
[Epoch 20, Batch 100] loss: 0.0032879559449793304
[Epoch 20, Batch 200] loss: 0.0022484310349682344
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0678
Validation Accuracy: 0.9854
Overfitting: 0.0674
[Epoch 21, Batch 100] loss: 0.002999800964462338
[Epoch 21, Batch 200] loss: 0.0015799168036028277
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0689
Validation Accuracy: 0.9855
Overfitting: 0.0686
[Epoch 22, Batch 100] loss: 0.0010223046813007386
[Epoch 22, Batch 200] loss: 0.003618830422165047
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0676
Validation Accuracy: 0.9857
Overfitting: 0.0675
[Epoch 23, Batch 100] loss: 0.0007501777657671482
[Epoch 23, Batch 200] loss: 0.0014344320440795855
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0677
Validation Accuracy: 0.9862
Overfitting: 0.0676
[Epoch 24, Batch 100] loss: 0.0009841854221303947
[Epoch 24, Batch 200] loss: 0.00042929547220410313
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0701
Validation Accuracy: 0.9862
Overfitting: 0.0701
Fold 1 validation loss: 0.0701
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.4787169578671455
[Epoch 1, Batch 200] loss: 0.3059752257913351
**STATS for Epoch 1** : 
Average training loss: 0.0276
Average validation loss: 0.1821
Validation Accuracy: 0.9466
Overfitting: 0.1545
Best model saved at epoch 1 with validation loss: 0.1821
[Epoch 2, Batch 100] loss: 0.14590279392898084
[Epoch 2, Batch 200] loss: 0.12219371618703008
**STATS for Epoch 2** : 
Average training loss: 0.0134
Average validation loss: 0.1150
Validation Accuracy: 0.9647
Overfitting: 0.1016
Best model saved at epoch 2 with validation loss: 0.1150
[Epoch 3, Batch 100] loss: 0.08570627143606543
[Epoch 3, Batch 200] loss: 0.07961308495141566
**STATS for Epoch 3** : 
Average training loss: 0.0116
Average validation loss: 0.0785
Validation Accuracy: 0.9754
Overfitting: 0.0670
Best model saved at epoch 3 with validation loss: 0.0785
[Epoch 4, Batch 100] loss: 0.05262160178273916
[Epoch 4, Batch 200] loss: 0.0657037325995043
**STATS for Epoch 4** : 
Average training loss: 0.0082
Average validation loss: 0.0672
Validation Accuracy: 0.9797
Overfitting: 0.0590
Best model saved at epoch 4 with validation loss: 0.0672
[Epoch 5, Batch 100] loss: 0.044750075465999545
[Epoch 5, Batch 200] loss: 0.04820426654536277
**STATS for Epoch 5** : 
Average training loss: 0.0060
Average validation loss: 0.0562
Validation Accuracy: 0.9830
Overfitting: 0.0502
Best model saved at epoch 5 with validation loss: 0.0562
[Epoch 6, Batch 100] loss: 0.03463804134633392
[Epoch 6, Batch 200] loss: 0.041876180979888884
**STATS for Epoch 6** : 
Average training loss: 0.0058
Average validation loss: 0.0554
Validation Accuracy: 0.9837
Overfitting: 0.0496
Best model saved at epoch 6 with validation loss: 0.0554
[Epoch 7, Batch 100] loss: 0.03420067228493281
[Epoch 7, Batch 200] loss: 0.036537112100049854
**STATS for Epoch 7** : 
Average training loss: 0.0043
Average validation loss: 0.0579
Validation Accuracy: 0.9837
Overfitting: 0.0536
[Epoch 8, Batch 100] loss: 0.027641722748521714
[Epoch 8, Batch 200] loss: 0.030133788042003288
**STATS for Epoch 8** : 
Average training loss: 0.0042
Average validation loss: 0.0499
Validation Accuracy: 0.9854
Overfitting: 0.0457
Best model saved at epoch 8 with validation loss: 0.0499
[Epoch 9, Batch 100] loss: 0.023917420719517395
[Epoch 9, Batch 200] loss: 0.02050659858621657
**STATS for Epoch 9** : 
Average training loss: 0.0037
Average validation loss: 0.0556
Validation Accuracy: 0.9834
Overfitting: 0.0518
[Epoch 10, Batch 100] loss: 0.017386607775697484
[Epoch 10, Batch 200] loss: 0.022936463875230403
**STATS for Epoch 10** : 
Average training loss: 0.0032
Average validation loss: 0.0530
Validation Accuracy: 0.9856
Overfitting: 0.0498
[Epoch 11, Batch 100] loss: 0.015836665489478038
[Epoch 11, Batch 200] loss: 0.01577852957881987
**STATS for Epoch 11** : 
Average training loss: 0.0027
Average validation loss: 0.0542
Validation Accuracy: 0.9845
Overfitting: 0.0515
[Epoch 12, Batch 100] loss: 0.01651267314562574
[Epoch 12, Batch 200] loss: 0.0154100366338389
**STATS for Epoch 12** : 
Average training loss: 0.0019
Average validation loss: 0.0519
Validation Accuracy: 0.9860
Overfitting: 0.0500
[Epoch 13, Batch 100] loss: 0.009526402507908642
[Epoch 13, Batch 200] loss: 0.014899646932608448
**STATS for Epoch 13** : 
Average training loss: 0.0024
Average validation loss: 0.0592
Validation Accuracy: 0.9844
Overfitting: 0.0568
[Epoch 14, Batch 100] loss: 0.00954046627652133
[Epoch 14, Batch 200] loss: 0.009349943149427418
**STATS for Epoch 14** : 
Average training loss: 0.0016
Average validation loss: 0.0579
Validation Accuracy: 0.9847
Overfitting: 0.0563
[Epoch 15, Batch 100] loss: 0.008463133749028202
[Epoch 15, Batch 200] loss: 0.008516253636917099
**STATS for Epoch 15** : 
Average training loss: 0.0015
Average validation loss: 0.0555
Validation Accuracy: 0.9864
Overfitting: 0.0540
[Epoch 16, Batch 100] loss: 0.007034559060848551
[Epoch 16, Batch 200] loss: 0.008882489548414014
**STATS for Epoch 16** : 
Average training loss: 0.0019
Average validation loss: 0.0587
Validation Accuracy: 0.9848
Overfitting: 0.0568
[Epoch 17, Batch 100] loss: 0.00984081483707996
[Epoch 17, Batch 200] loss: 0.005894792639301158
**STATS for Epoch 17** : 
Average training loss: 0.0012
Average validation loss: 0.0552
Validation Accuracy: 0.9867
Overfitting: 0.0540
[Epoch 18, Batch 100] loss: 0.002837718331211363
[Epoch 18, Batch 200] loss: 0.004962203174072783
**STATS for Epoch 18** : 
Average training loss: 0.0013
Average validation loss: 0.0640
Validation Accuracy: 0.9849
Overfitting: 0.0627
[Epoch 19, Batch 100] loss: 0.0064004999130702345
[Epoch 19, Batch 200] loss: 0.003856307855749037
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0578
Validation Accuracy: 0.9867
Overfitting: 0.0570
[Epoch 20, Batch 100] loss: 0.0024921868443198037
[Epoch 20, Batch 200] loss: 0.002230425553825626
**STATS for Epoch 20** : 
Average training loss: 0.0008
Average validation loss: 0.0576
Validation Accuracy: 0.9869
Overfitting: 0.0568
[Epoch 21, Batch 100] loss: 0.002986384773030295
[Epoch 21, Batch 200] loss: 0.0038707615235398407
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0589
Validation Accuracy: 0.9872
Overfitting: 0.0584
[Epoch 22, Batch 100] loss: 0.0019149307283078088
[Epoch 22, Batch 200] loss: 0.0014468872952784295
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0564
Validation Accuracy: 0.9880
Overfitting: 0.0562
[Epoch 23, Batch 100] loss: 0.0009072514498984674
[Epoch 23, Batch 200] loss: 0.001144865566129738
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0641
Validation Accuracy: 0.9863
Overfitting: 0.0638
[Epoch 24, Batch 100] loss: 0.0018325711368379417
[Epoch 24, Batch 200] loss: 0.0013171514029454556
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0597
Validation Accuracy: 0.9875
Overfitting: 0.0596
Fold 2 validation loss: 0.0597
Mean validation loss across all folds for Trial 17 is 0.0649 with trial config:  l1: 256, l2: 64, lr: 0.011006881336688933, batch_size: 128
[I 2024-11-22 00:04:23,866] Trial 16 finished with value: 0.06491296334077445 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.011006881336688933, 'batch_size': 128}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 18:
  l1: 256, l2: 128, lr: 0.009287011926825201, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.5869575087726115
[Epoch 1, Batch 200] loss: 0.44006168965250253
[Epoch 1, Batch 300] loss: 0.31483837856911123
[Epoch 1, Batch 400] loss: 0.21387448923662306
[Epoch 1, Batch 500] loss: 0.16758144060382618
[Epoch 1, Batch 600] loss: 0.18011974230408667
[Epoch 1, Batch 700] loss: 0.15429518614080734
[Epoch 1, Batch 800] loss: 0.21124574713408947
[Epoch 1, Batch 900] loss: 0.1409710151120089
[Epoch 1, Batch 1000] loss: 0.1575295205670409
[Epoch 1, Batch 1100] loss: 0.1673217788571492
[Epoch 1, Batch 1200] loss: 0.13690439803816845
[Epoch 1, Batch 1300] loss: 0.1618895942045492
[Epoch 1, Batch 1400] loss: 0.1354470565333031
[Epoch 1, Batch 1500] loss: 0.11125385448496672
[Epoch 1, Batch 1600] loss: 0.08583490325487218
[Epoch 1, Batch 1700] loss: 0.11406593720894306
[Epoch 1, Batch 1800] loss: 0.09554535426999791
**STATS for Epoch 1** : 
Average training loss: 0.0042
Average validation loss: 0.1133
Validation Accuracy: 0.9667
Overfitting: 0.1091
Best model saved at epoch 1 with validation loss: 0.1133
[Epoch 2, Batch 100] loss: 0.08941497066727606
[Epoch 2, Batch 200] loss: 0.07800035963882693
[Epoch 2, Batch 300] loss: 0.08589367210515775
[Epoch 2, Batch 400] loss: 0.09304113427351694
[Epoch 2, Batch 500] loss: 0.0877671597659355
[Epoch 2, Batch 600] loss: 0.08331670112238498
[Epoch 2, Batch 700] loss: 0.09720313621626701
[Epoch 2, Batch 800] loss: 0.08827363238775433
[Epoch 2, Batch 900] loss: 0.09363573857757729
[Epoch 2, Batch 1000] loss: 0.10113615773450874
[Epoch 2, Batch 1100] loss: 0.08693733976047952
[Epoch 2, Batch 1200] loss: 0.07078255193731821
[Epoch 2, Batch 1300] loss: 0.07172509087133222
[Epoch 2, Batch 1400] loss: 0.07463172079718788
[Epoch 2, Batch 1500] loss: 0.09015406311449624
[Epoch 2, Batch 1600] loss: 0.08288988875072391
[Epoch 2, Batch 1700] loss: 0.055740928431259815
[Epoch 2, Batch 1800] loss: 0.09497075675521045
**STATS for Epoch 2** : 
Average training loss: 0.0039
Average validation loss: 0.0951
Validation Accuracy: 0.9717
Overfitting: 0.0911
Best model saved at epoch 2 with validation loss: 0.0951
[Epoch 3, Batch 100] loss: 0.05901049650576169
[Epoch 3, Batch 200] loss: 0.045756571666943274
[Epoch 3, Batch 300] loss: 0.05810287122694717
[Epoch 3, Batch 400] loss: 0.08269429414365731
[Epoch 3, Batch 500] loss: 0.07005884523663554
[Epoch 3, Batch 600] loss: 0.08169701614649966
[Epoch 3, Batch 700] loss: 0.06989535342319869
[Epoch 3, Batch 800] loss: 0.04947759779650369
[Epoch 3, Batch 900] loss: 0.05771339633181924
[Epoch 3, Batch 1000] loss: 0.040019042587773584
[Epoch 3, Batch 1100] loss: 0.06076742157070839
[Epoch 3, Batch 1200] loss: 0.05463322183961281
[Epoch 3, Batch 1300] loss: 0.046977335079354816
[Epoch 3, Batch 1400] loss: 0.05968449905412854
[Epoch 3, Batch 1500] loss: 0.05923174836825638
[Epoch 3, Batch 1600] loss: 0.04796449171612039
[Epoch 3, Batch 1700] loss: 0.05244103157558129
[Epoch 3, Batch 1800] loss: 0.048524070205603495
**STATS for Epoch 3** : 
Average training loss: 0.0032
Average validation loss: 0.0844
Validation Accuracy: 0.9745
Overfitting: 0.0812
Best model saved at epoch 3 with validation loss: 0.0844
[Epoch 4, Batch 100] loss: 0.03243995609598642
[Epoch 4, Batch 200] loss: 0.03742665150770336
[Epoch 4, Batch 300] loss: 0.05440474686722155
[Epoch 4, Batch 400] loss: 0.03743266723911802
[Epoch 4, Batch 500] loss: 0.03761373414867194
[Epoch 4, Batch 600] loss: 0.0408226920751622
[Epoch 4, Batch 700] loss: 0.04955006690468508
[Epoch 4, Batch 800] loss: 0.06853414991754107
[Epoch 4, Batch 900] loss: 0.030281869175867088
[Epoch 4, Batch 1000] loss: 0.04274491761709214
[Epoch 4, Batch 1100] loss: 0.0175942835649289
[Epoch 4, Batch 1200] loss: 0.04248570046955138
[Epoch 4, Batch 1300] loss: 0.05462533567765604
[Epoch 4, Batch 1400] loss: 0.09113248581470543
[Epoch 4, Batch 1500] loss: 0.026521028902825493
[Epoch 4, Batch 1600] loss: 0.06033565797832125
[Epoch 4, Batch 1700] loss: 0.05422778897464013
[Epoch 4, Batch 1800] loss: 0.047667889538770394
**STATS for Epoch 4** : 
Average training loss: 0.0022
Average validation loss: 0.0609
Validation Accuracy: 0.9827
Overfitting: 0.0587
Best model saved at epoch 4 with validation loss: 0.0609
[Epoch 5, Batch 100] loss: 0.04359067208104534
[Epoch 5, Batch 200] loss: 0.0325074593973909
[Epoch 5, Batch 300] loss: 0.027178963631504304
[Epoch 5, Batch 400] loss: 0.022787681086047087
[Epoch 5, Batch 500] loss: 0.016037623635593263
[Epoch 5, Batch 600] loss: 0.030069706916142424
[Epoch 5, Batch 700] loss: 0.02491879206568228
[Epoch 5, Batch 800] loss: 0.03508723703729629
[Epoch 5, Batch 900] loss: 0.048334929739426116
[Epoch 5, Batch 1000] loss: 0.03803463852340428
[Epoch 5, Batch 1100] loss: 0.050842888224997294
[Epoch 5, Batch 1200] loss: 0.05030233181678341
[Epoch 5, Batch 1300] loss: 0.038891915933127165
[Epoch 5, Batch 1400] loss: 0.026582150130848275
[Epoch 5, Batch 1500] loss: 0.041294686351611744
[Epoch 5, Batch 1600] loss: 0.02990041807624948
[Epoch 5, Batch 1700] loss: 0.028187081362266327
[Epoch 5, Batch 1800] loss: 0.018999950474817524
**STATS for Epoch 5** : 
Average training loss: 0.0012
Average validation loss: 0.0613
Validation Accuracy: 0.9830
Overfitting: 0.0602
[Epoch 6, Batch 100] loss: 0.013451576860225032
[Epoch 6, Batch 200] loss: 0.02397850579099668
[Epoch 6, Batch 300] loss: 0.027057845399285727
[Epoch 6, Batch 400] loss: 0.03943276333935955
[Epoch 6, Batch 500] loss: 0.01845944106221282
[Epoch 6, Batch 600] loss: 0.034295857522383816
[Epoch 6, Batch 700] loss: 0.03348837955625641
[Epoch 6, Batch 800] loss: 0.02341004349545983
[Epoch 6, Batch 900] loss: 0.017145869326103878
[Epoch 6, Batch 1000] loss: 0.0216672372407038
[Epoch 6, Batch 1100] loss: 0.03788156989861477
[Epoch 6, Batch 1200] loss: 0.06793210928297412
[Epoch 6, Batch 1300] loss: 0.030609777497306822
[Epoch 6, Batch 1400] loss: 0.04593118692660255
[Epoch 6, Batch 1500] loss: 0.020737623466720832
[Epoch 6, Batch 1600] loss: 0.04617451587930191
[Epoch 6, Batch 1700] loss: 0.04492403087459934
[Epoch 6, Batch 1800] loss: 0.05093930830661293
**STATS for Epoch 6** : 
Average training loss: 0.0021
Average validation loss: 0.0625
Validation Accuracy: 0.9831
Overfitting: 0.0605
[Epoch 7, Batch 100] loss: 0.023478117916092743
[Epoch 7, Batch 200] loss: 0.03671571565968407
[Epoch 7, Batch 300] loss: 0.01395073923020277
[Epoch 7, Batch 400] loss: 0.0228916709889927
[Epoch 7, Batch 500] loss: 0.021648583354010924
[Epoch 7, Batch 600] loss: 0.01525085310417694
[Epoch 7, Batch 700] loss: 0.03468198448345589
[Epoch 7, Batch 800] loss: 0.01341698638644516
[Epoch 7, Batch 900] loss: 0.030840753749511975
[Epoch 7, Batch 1000] loss: 0.03669978305359109
[Epoch 7, Batch 1100] loss: 0.03997910783709471
[Epoch 7, Batch 1200] loss: 0.03428660869445593
[Epoch 7, Batch 1300] loss: 0.02105034784099189
[Epoch 7, Batch 1400] loss: 0.023032871513662484
[Epoch 7, Batch 1500] loss: 0.02386820023833934
[Epoch 7, Batch 1600] loss: 0.03574783866572034
[Epoch 7, Batch 1700] loss: 0.04382550859186267
[Epoch 7, Batch 1800] loss: 0.03619842865582768
**STATS for Epoch 7** : 
Average training loss: 0.0011
Average validation loss: 0.0608
Validation Accuracy: 0.9840
Overfitting: 0.0597
Best model saved at epoch 7 with validation loss: 0.0608
[Epoch 8, Batch 100] loss: 0.023599152630417848
[Epoch 8, Batch 200] loss: 0.015087462225114905
[Epoch 8, Batch 300] loss: 0.015092624829899677
[Epoch 8, Batch 400] loss: 0.026364994651247572
[Epoch 8, Batch 500] loss: 0.0042242822899629575
[Epoch 8, Batch 600] loss: 0.013249359780497799
[Epoch 8, Batch 700] loss: 0.007432188882448542
[Epoch 8, Batch 800] loss: 0.02247728079112221
[Epoch 8, Batch 900] loss: 0.028036407038100036
[Epoch 8, Batch 1000] loss: 0.04283512255724872
[Epoch 8, Batch 1100] loss: 0.014192368451426773
[Epoch 8, Batch 1200] loss: 0.021042594239293066
[Epoch 8, Batch 1300] loss: 0.031716456319911684
[Epoch 8, Batch 1400] loss: 0.029065159745456412
[Epoch 8, Batch 1500] loss: 0.025358329876093676
[Epoch 8, Batch 1600] loss: 0.03057277821108581
[Epoch 8, Batch 1700] loss: 0.03350204721545296
[Epoch 8, Batch 1800] loss: 0.02716555428675292
**STATS for Epoch 8** : 
Average training loss: 0.0005
Average validation loss: 0.0762
Validation Accuracy: 0.9837
Overfitting: 0.0757
[Epoch 9, Batch 100] loss: 0.014693524799261013
[Epoch 9, Batch 200] loss: 0.016986461149950075
[Epoch 9, Batch 300] loss: 0.031919782416402996
[Epoch 9, Batch 400] loss: 0.024628981705752152
[Epoch 9, Batch 500] loss: 0.0423921746459348
[Epoch 9, Batch 600] loss: 0.026167074395370946
[Epoch 9, Batch 700] loss: 0.02058020992746151
[Epoch 9, Batch 800] loss: 0.01879091901173851
[Epoch 9, Batch 900] loss: 0.0360568994953519
[Epoch 9, Batch 1000] loss: 0.04055110464747031
[Epoch 9, Batch 1100] loss: 0.01485867665839976
[Epoch 9, Batch 1200] loss: 0.03591576912781761
[Epoch 9, Batch 1300] loss: 0.03387694655703854
[Epoch 9, Batch 1400] loss: 0.061527253219228445
[Epoch 9, Batch 1500] loss: 0.024672804150845877
[Epoch 9, Batch 1600] loss: 0.013868967301265798
[Epoch 9, Batch 1700] loss: 0.0424824299935159
[Epoch 9, Batch 1800] loss: 0.033213607643574505
**STATS for Epoch 9** : 
Average training loss: 0.0020
Average validation loss: 0.0743
Validation Accuracy: 0.9826
Overfitting: 0.0722
[Epoch 10, Batch 100] loss: 0.013783535719171595
[Epoch 10, Batch 200] loss: 0.0038084790252796096
[Epoch 10, Batch 300] loss: 0.017144275572743766
[Epoch 10, Batch 400] loss: 0.018982118103414224
[Epoch 10, Batch 500] loss: 0.007083267742487749
[Epoch 10, Batch 600] loss: 0.020351502367178965
[Epoch 10, Batch 700] loss: 0.016593060520531253
[Epoch 10, Batch 800] loss: 0.016844673845369015
[Epoch 10, Batch 900] loss: 0.01528875717134099
[Epoch 10, Batch 1000] loss: 0.00667497622075814
[Epoch 10, Batch 1100] loss: 0.016878945145674003
[Epoch 10, Batch 1200] loss: 0.027845152551290654
[Epoch 10, Batch 1300] loss: 0.006715402551400586
[Epoch 10, Batch 1400] loss: 0.0032804287865697292
[Epoch 10, Batch 1500] loss: 0.004534490166401816
[Epoch 10, Batch 1600] loss: 0.023836255484871813
[Epoch 10, Batch 1700] loss: 0.017486763769450134
[Epoch 10, Batch 1800] loss: 0.012296799837290848
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0975
Validation Accuracy: 0.9809
Overfitting: 0.0963
[Epoch 11, Batch 100] loss: 0.023409509179239407
[Epoch 11, Batch 200] loss: 0.008963452390300688
[Epoch 11, Batch 300] loss: 0.011032735052413613
[Epoch 11, Batch 400] loss: 0.015801208193099967
[Epoch 11, Batch 500] loss: 0.0353429658900211
[Epoch 11, Batch 600] loss: 0.011547526926104865
[Epoch 11, Batch 700] loss: 0.018544104536766783
[Epoch 11, Batch 800] loss: 0.011252665501382353
[Epoch 11, Batch 900] loss: 0.008894154927110093
[Epoch 11, Batch 1000] loss: 0.002407644960642763
[Epoch 11, Batch 1100] loss: 0.007699846485842983
[Epoch 11, Batch 1200] loss: 0.01177189980479211
[Epoch 11, Batch 1300] loss: 0.006827335824843672
[Epoch 11, Batch 1400] loss: 0.03620536092704942
[Epoch 11, Batch 1500] loss: 0.02324906603066271
[Epoch 11, Batch 1600] loss: 0.04343338683433785
[Epoch 11, Batch 1700] loss: 0.06363421705390664
[Epoch 11, Batch 1800] loss: 0.03188648868785997
**STATS for Epoch 11** : 
Average training loss: 0.0003
Average validation loss: 0.0921
Validation Accuracy: 0.9814
Overfitting: 0.0917
[Epoch 12, Batch 100] loss: 0.024288924366026095
[Epoch 12, Batch 200] loss: 0.007834515930428837
[Epoch 12, Batch 300] loss: 0.015025048930294247
[Epoch 12, Batch 400] loss: 0.02692811609521314
[Epoch 12, Batch 500] loss: 0.017962061928158732
[Epoch 12, Batch 600] loss: 0.015191880494675285
[Epoch 12, Batch 700] loss: 0.028107728157514434
[Epoch 12, Batch 800] loss: 0.014670222144221014
[Epoch 12, Batch 900] loss: 0.022977998897593395
[Epoch 12, Batch 1000] loss: 0.005927634115362821
[Epoch 12, Batch 1100] loss: 0.022515622379427214
[Epoch 12, Batch 1200] loss: 0.03642376915471459
[Epoch 12, Batch 1300] loss: 0.023340167890560225
[Epoch 12, Batch 1400] loss: 0.014986257767626512
[Epoch 12, Batch 1500] loss: 0.03509919269655143
[Epoch 12, Batch 1600] loss: 0.016729860894998297
[Epoch 12, Batch 1700] loss: 0.012064921522389796
[Epoch 12, Batch 1800] loss: 0.018010822159957342
**STATS for Epoch 12** : 
Average training loss: 0.0003
Average validation loss: 0.0626
Validation Accuracy: 0.9861
Overfitting: 0.0622
[Epoch 13, Batch 100] loss: 0.004545624670985831
[Epoch 13, Batch 200] loss: 0.004175053015441393
[Epoch 13, Batch 300] loss: 0.003936877439975528
[Epoch 13, Batch 400] loss: 0.005905808945531113
[Epoch 13, Batch 500] loss: 0.00807679071896251
[Epoch 13, Batch 600] loss: 0.01902156613705806
[Epoch 13, Batch 700] loss: 0.012653491290121792
[Epoch 13, Batch 800] loss: 0.003516776579775249
[Epoch 13, Batch 900] loss: 0.010681764956130024
[Epoch 13, Batch 1000] loss: 0.0067971437462902885
[Epoch 13, Batch 1100] loss: 0.011768423426283432
[Epoch 13, Batch 1200] loss: 0.023175084504978544
[Epoch 13, Batch 1300] loss: 0.020936212298443006
[Epoch 13, Batch 1400] loss: 0.009520423617933602
[Epoch 13, Batch 1500] loss: 0.03108314747908757
[Epoch 13, Batch 1600] loss: 0.024180911468205293
[Epoch 13, Batch 1700] loss: 0.021684142597504938
[Epoch 13, Batch 1800] loss: 0.055096156934655624
**STATS for Epoch 13** : 
Average training loss: 0.0019
Average validation loss: 0.0805
Validation Accuracy: 0.9825
Overfitting: 0.0787
[Epoch 14, Batch 100] loss: 0.007919626038565185
[Epoch 14, Batch 200] loss: 0.016031822678006905
[Epoch 14, Batch 300] loss: 0.005817968510842419
[Epoch 14, Batch 400] loss: 0.033538175329244024
[Epoch 14, Batch 500] loss: 0.04456800569392073
[Epoch 14, Batch 600] loss: 0.022926208191553315
[Epoch 14, Batch 700] loss: 0.016657369819949964
[Epoch 14, Batch 800] loss: 0.008412989894309088
[Epoch 14, Batch 900] loss: 0.007856879994309623
[Epoch 14, Batch 1000] loss: 0.0062144552680159035
[Epoch 14, Batch 1100] loss: 0.028168293693108665
[Epoch 14, Batch 1200] loss: 0.025093549652016805
[Epoch 14, Batch 1300] loss: 0.029467978459821895
[Epoch 14, Batch 1400] loss: 0.03756389822286323
[Epoch 14, Batch 1500] loss: 0.008770425839166967
[Epoch 14, Batch 1600] loss: 0.02555756317087422
[Epoch 14, Batch 1700] loss: 0.01143173320875313
[Epoch 14, Batch 1800] loss: 0.007629454751925735
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0639
Validation Accuracy: 0.9869
Overfitting: 0.0635
[Epoch 15, Batch 100] loss: 0.007882185450029517
[Epoch 15, Batch 200] loss: 0.006490385723907863
[Epoch 15, Batch 300] loss: 0.0072589154884518696
[Epoch 15, Batch 400] loss: 0.009397815733902984
[Epoch 15, Batch 500] loss: 0.012315895883910457
[Epoch 15, Batch 600] loss: 0.005350807823804207
[Epoch 15, Batch 700] loss: 0.008694000535616411
[Epoch 15, Batch 800] loss: 0.00465629838588995
[Epoch 15, Batch 900] loss: 0.010782154185824382
[Epoch 15, Batch 1000] loss: 0.007888682956991229
[Epoch 15, Batch 1100] loss: 0.030094349299156272
[Epoch 15, Batch 1200] loss: 0.02836312337259585
[Epoch 15, Batch 1300] loss: 0.02640335183321973
[Epoch 15, Batch 1400] loss: 0.018552461434439137
[Epoch 15, Batch 1500] loss: 0.020228078397602118
[Epoch 15, Batch 1600] loss: 0.01683782055980906
[Epoch 15, Batch 1700] loss: 0.010039182256779635
[Epoch 15, Batch 1800] loss: 0.018646947475169248
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0825
Validation Accuracy: 0.9849
Overfitting: 0.0821
[Epoch 16, Batch 100] loss: 0.008035107067301546
[Epoch 16, Batch 200] loss: 0.017778608421912093
[Epoch 16, Batch 300] loss: 0.01683837979493706
[Epoch 16, Batch 400] loss: 0.009504383462260312
[Epoch 16, Batch 500] loss: 0.032683474358277335
[Epoch 16, Batch 600] loss: 0.025865004342615797
[Epoch 16, Batch 700] loss: 0.006390388224896526
[Epoch 16, Batch 800] loss: 0.018735702027743172
[Epoch 16, Batch 900] loss: 0.01761455802927692
[Epoch 16, Batch 1000] loss: 0.0038808102871855255
[Epoch 16, Batch 1100] loss: 0.0038963404139771996
[Epoch 16, Batch 1200] loss: 0.002935420540359712
[Epoch 16, Batch 1300] loss: 0.002443554534736876
[Epoch 16, Batch 1400] loss: 0.008289729579302492
[Epoch 16, Batch 1500] loss: 0.01056394739990477
[Epoch 16, Batch 1600] loss: 0.025077581104969646
[Epoch 16, Batch 1700] loss: 0.03283447202546113
[Epoch 16, Batch 1800] loss: 0.006422411331950925
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0755
Validation Accuracy: 0.9849
Overfitting: 0.0749
[Epoch 17, Batch 100] loss: 0.009351407155522464
[Epoch 17, Batch 200] loss: 0.005443887870120889
[Epoch 17, Batch 300] loss: 0.006541055157748996
[Epoch 17, Batch 400] loss: 0.004288687729281469
[Epoch 17, Batch 500] loss: 0.00437609898546687
[Epoch 17, Batch 600] loss: 0.0031785186525746223
[Epoch 17, Batch 700] loss: 0.0006347845218235771
[Epoch 17, Batch 800] loss: 0.0035453991774338435
[Epoch 17, Batch 900] loss: 0.006314985839976948
[Epoch 17, Batch 1000] loss: 0.0023685879885271266
[Epoch 17, Batch 1100] loss: 0.0014186209981361308
[Epoch 17, Batch 1200] loss: 0.0026899815679827022
[Epoch 17, Batch 1300] loss: 0.017792304460288188
[Epoch 17, Batch 1400] loss: 0.009370017372096267
[Epoch 17, Batch 1500] loss: 0.01242625481777003
[Epoch 17, Batch 1600] loss: 0.011757244894305878
[Epoch 17, Batch 1700] loss: 0.006040575121493346
[Epoch 17, Batch 1800] loss: 0.01620727957186162
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0718
Validation Accuracy: 0.9859
Overfitting: 0.0713
[Epoch 18, Batch 100] loss: 0.021527426491714467
[Epoch 18, Batch 200] loss: 0.01603566221224602
[Epoch 18, Batch 300] loss: 0.008162268383558303
[Epoch 18, Batch 400] loss: 0.02062423412417117
[Epoch 18, Batch 500] loss: 0.015834713910198785
[Epoch 18, Batch 600] loss: 0.005412569016354265
[Epoch 18, Batch 700] loss: 0.005426991776627679
[Epoch 18, Batch 800] loss: 0.005579620700571062
[Epoch 18, Batch 900] loss: 0.01347729165744898
[Epoch 18, Batch 1000] loss: 0.005863481811800084
[Epoch 18, Batch 1100] loss: 0.01078242034279226
[Epoch 18, Batch 1200] loss: 0.00921748297470801
[Epoch 18, Batch 1300] loss: 0.01802587572716133
[Epoch 18, Batch 1400] loss: 0.028047606863892783
[Epoch 18, Batch 1500] loss: 0.00808245092935237
[Epoch 18, Batch 1600] loss: 0.028414743177383385
[Epoch 18, Batch 1700] loss: 0.014766827077012578
[Epoch 18, Batch 1800] loss: 0.03192365710378498
**STATS for Epoch 18** : 
Average training loss: 0.0012
Average validation loss: 0.1513
Validation Accuracy: 0.9737
Overfitting: 0.1501
[Epoch 19, Batch 100] loss: 0.02039544356753936
[Epoch 19, Batch 200] loss: 0.009265015582427623
[Epoch 19, Batch 300] loss: 0.0029211319246249976
[Epoch 19, Batch 400] loss: 0.02258979303027557
[Epoch 19, Batch 500] loss: 0.022381155171967676
[Epoch 19, Batch 600] loss: 0.026852770468639795
[Epoch 19, Batch 700] loss: 0.027445239965285567
[Epoch 19, Batch 800] loss: 0.024482780450854
[Epoch 19, Batch 900] loss: 0.011573402642429186
[Epoch 19, Batch 1000] loss: 0.014538434167656681
[Epoch 19, Batch 1100] loss: 0.014997633483850796
[Epoch 19, Batch 1200] loss: 0.00973448565319698
[Epoch 19, Batch 1300] loss: 0.007604356150502376
[Epoch 19, Batch 1400] loss: 0.012992299080663962
[Epoch 19, Batch 1500] loss: 0.03416359822197104
[Epoch 19, Batch 1600] loss: 0.023125199976484646
[Epoch 19, Batch 1700] loss: 0.015785383297671773
[Epoch 19, Batch 1800] loss: 0.010255653871818354
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0738
Validation Accuracy: 0.9860
Overfitting: 0.0735
[Epoch 20, Batch 100] loss: 0.0069731088367053305
[Epoch 20, Batch 200] loss: 0.006986627912667611
[Epoch 20, Batch 300] loss: 0.0070271305827870065
[Epoch 20, Batch 400] loss: 0.01041689928361773
[Epoch 20, Batch 500] loss: 0.0072057969405805574
[Epoch 20, Batch 600] loss: 0.012934826411325208
[Epoch 20, Batch 700] loss: 0.00863792589675846
[Epoch 20, Batch 800] loss: 0.012167623801177441
[Epoch 20, Batch 900] loss: 0.006555211082820955
[Epoch 20, Batch 1000] loss: 0.007107064673845578
[Epoch 20, Batch 1100] loss: 0.008483769854212534
[Epoch 20, Batch 1200] loss: 0.004671082223956171
[Epoch 20, Batch 1300] loss: 0.007291128803477451
[Epoch 20, Batch 1400] loss: 0.0065060809709893384
[Epoch 20, Batch 1500] loss: 0.014216348088203948
[Epoch 20, Batch 1600] loss: 0.014100491715540855
[Epoch 20, Batch 1700] loss: 0.0028526632718652235
[Epoch 20, Batch 1800] loss: 0.0015336342927683689
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0883
Validation Accuracy: 0.9856
Overfitting: 0.0881
[Epoch 21, Batch 100] loss: 0.0011841804380635246
[Epoch 21, Batch 200] loss: 0.011687559909788123
[Epoch 21, Batch 300] loss: 0.004308746368083316
[Epoch 21, Batch 400] loss: 0.014521971696533137
[Epoch 21, Batch 500] loss: 0.007162935052925019
[Epoch 21, Batch 600] loss: 0.029205072418712983
[Epoch 21, Batch 700] loss: 0.003596798804983279
[Epoch 21, Batch 800] loss: 0.0016283577668693107
[Epoch 21, Batch 900] loss: 0.009630169060289507
[Epoch 21, Batch 1000] loss: 0.00566265604140538
[Epoch 21, Batch 1100] loss: 0.004661041403971584
[Epoch 21, Batch 1200] loss: 0.0045961935026901865
[Epoch 21, Batch 1300] loss: 0.00803420794778845
[Epoch 21, Batch 1400] loss: 0.00875281765930327
[Epoch 21, Batch 1500] loss: 0.0019149964875261904
[Epoch 21, Batch 1600] loss: 0.000979719021243124
[Epoch 21, Batch 1700] loss: 0.0068889260975109326
[Epoch 21, Batch 1800] loss: 0.004276328608846179
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0843
Validation Accuracy: 0.9861
Overfitting: 0.0840
[Epoch 22, Batch 100] loss: 0.0016037984449786568
[Epoch 22, Batch 200] loss: 0.0006026981667206588
[Epoch 22, Batch 300] loss: 0.0018488378693410513
[Epoch 22, Batch 400] loss: 0.0008528970991044682
[Epoch 22, Batch 500] loss: 0.00015487693873102336
[Epoch 22, Batch 600] loss: 0.0010839758442901814
[Epoch 22, Batch 700] loss: 0.012594454858698464
[Epoch 22, Batch 800] loss: 0.014452358113627311
[Epoch 22, Batch 900] loss: 0.003295359395319055
[Epoch 22, Batch 1000] loss: 0.013599121266125112
[Epoch 22, Batch 1100] loss: 0.009752380486039965
[Epoch 22, Batch 1200] loss: 0.01435416520506199
[Epoch 22, Batch 1300] loss: 0.008980312424866325
[Epoch 22, Batch 1400] loss: 0.007936723862458783
[Epoch 22, Batch 1500] loss: 0.004375908412077303
[Epoch 22, Batch 1600] loss: 0.004231292186512286
[Epoch 22, Batch 1700] loss: 0.0036300762093474724
[Epoch 22, Batch 1800] loss: 0.003909240616438328
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0883
Validation Accuracy: 0.9862
Overfitting: 0.0883
[Epoch 23, Batch 100] loss: 0.002093090727780296
[Epoch 23, Batch 200] loss: 0.00041916929686738327
[Epoch 23, Batch 300] loss: 0.002460109002256834
[Epoch 23, Batch 400] loss: 0.01227180752399502
[Epoch 23, Batch 500] loss: 0.01867274817064142
[Epoch 23, Batch 600] loss: 0.006337141404370814
[Epoch 23, Batch 700] loss: 0.004304844977199065
[Epoch 23, Batch 800] loss: 0.0012963379032975774
[Epoch 23, Batch 900] loss: 0.010177216850987181
[Epoch 23, Batch 1000] loss: 0.004243323841774882
[Epoch 23, Batch 1100] loss: 0.003799334503560994
[Epoch 23, Batch 1200] loss: 0.00783930751562337
[Epoch 23, Batch 1300] loss: 0.019239231765593483
[Epoch 23, Batch 1400] loss: 0.004418478193168607
[Epoch 23, Batch 1500] loss: 0.0059743229783227395
[Epoch 23, Batch 1600] loss: 0.005471634278126567
[Epoch 23, Batch 1700] loss: 0.01740057026867333
[Epoch 23, Batch 1800] loss: 0.041106452444125384
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.1111
Validation Accuracy: 0.9809
Overfitting: 0.1108
[Epoch 24, Batch 100] loss: 0.007410696137915558
[Epoch 24, Batch 200] loss: 0.019333993168587887
[Epoch 24, Batch 300] loss: 0.009399511160159796
[Epoch 24, Batch 400] loss: 0.010393416337897197
[Epoch 24, Batch 500] loss: 0.004105859614734486
[Epoch 24, Batch 600] loss: 0.020163682600480008
[Epoch 24, Batch 700] loss: 0.024272030693296736
[Epoch 24, Batch 800] loss: 0.08764063805901387
[Epoch 24, Batch 900] loss: 0.02021328232222096
[Epoch 24, Batch 1000] loss: 0.025546561036937053
[Epoch 24, Batch 1100] loss: 0.026068564678296758
[Epoch 24, Batch 1200] loss: 0.010651073287417016
[Epoch 24, Batch 1300] loss: 0.005313129967433699
[Epoch 24, Batch 1400] loss: 0.010672720802296594
[Epoch 24, Batch 1500] loss: 0.03299112227331521
[Epoch 24, Batch 1600] loss: 0.02486969070280365
[Epoch 24, Batch 1700] loss: 0.008301629369985694
[Epoch 24, Batch 1800] loss: 0.008632937456437855
**STATS for Epoch 24** : 
Average training loss: 0.0011
Average validation loss: 0.1202
Validation Accuracy: 0.9792
Overfitting: 0.1191
Fold 1 validation loss: 0.1202
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.7517067214846611
[Epoch 1, Batch 200] loss: 0.556074539348483
[Epoch 1, Batch 300] loss: 0.31952578369528056
[Epoch 1, Batch 400] loss: 0.27862329160794613
[Epoch 1, Batch 500] loss: 0.20840421894565225
[Epoch 1, Batch 600] loss: 0.18714485994074492
[Epoch 1, Batch 700] loss: 0.1598344216227997
[Epoch 1, Batch 800] loss: 0.19855894750449807
[Epoch 1, Batch 900] loss: 0.1769962380733341
[Epoch 1, Batch 1000] loss: 0.1797435442660935
[Epoch 1, Batch 1100] loss: 0.1271017215377651
[Epoch 1, Batch 1200] loss: 0.12527101808227598
[Epoch 1, Batch 1300] loss: 0.1491321033774875
[Epoch 1, Batch 1400] loss: 0.11750285780930426
[Epoch 1, Batch 1500] loss: 0.10656001449591714
[Epoch 1, Batch 1600] loss: 0.12247755212156335
[Epoch 1, Batch 1700] loss: 0.13366575469030068
[Epoch 1, Batch 1800] loss: 0.0979686700948514
**STATS for Epoch 1** : 
Average training loss: 0.0037
Average validation loss: 0.0928
Validation Accuracy: 0.9721
Overfitting: 0.0891
Best model saved at epoch 1 with validation loss: 0.0928
[Epoch 2, Batch 100] loss: 0.09692300678347238
[Epoch 2, Batch 200] loss: 0.10378663483075798
[Epoch 2, Batch 300] loss: 0.092080985205248
[Epoch 2, Batch 400] loss: 0.08589880969666411
[Epoch 2, Batch 500] loss: 0.07745200991485035
[Epoch 2, Batch 600] loss: 0.09673593973217066
[Epoch 2, Batch 700] loss: 0.0788857114026905
[Epoch 2, Batch 800] loss: 0.08247432074509561
[Epoch 2, Batch 900] loss: 0.07280624781007645
[Epoch 2, Batch 1000] loss: 0.05589688874460989
[Epoch 2, Batch 1100] loss: 0.06219373398285825
[Epoch 2, Batch 1200] loss: 0.10907977750321152
[Epoch 2, Batch 1300] loss: 0.06860237849701661
[Epoch 2, Batch 1400] loss: 0.09147747323149816
[Epoch 2, Batch 1500] loss: 0.057821682131179844
[Epoch 2, Batch 1600] loss: 0.08503916998182831
[Epoch 2, Batch 1700] loss: 0.11288101425132481
[Epoch 2, Batch 1800] loss: 0.07411916724959156
**STATS for Epoch 2** : 
Average training loss: 0.0022
Average validation loss: 0.0806
Validation Accuracy: 0.9779
Overfitting: 0.0784
Best model saved at epoch 2 with validation loss: 0.0806
[Epoch 3, Batch 100] loss: 0.035437911971530414
[Epoch 3, Batch 200] loss: 0.0776864567982193
[Epoch 3, Batch 300] loss: 0.06104929092602106
[Epoch 3, Batch 400] loss: 0.05097786880578496
[Epoch 3, Batch 500] loss: 0.05956266253675494
[Epoch 3, Batch 600] loss: 0.053247192780099796
[Epoch 3, Batch 700] loss: 0.08451875762257259
[Epoch 3, Batch 800] loss: 0.044526903767255134
[Epoch 3, Batch 900] loss: 0.04355215331193904
[Epoch 3, Batch 1000] loss: 0.08879593915147325
[Epoch 3, Batch 1100] loss: 0.05993562050105538
[Epoch 3, Batch 1200] loss: 0.07007353551620327
[Epoch 3, Batch 1300] loss: 0.06203671809009393
[Epoch 3, Batch 1400] loss: 0.05122857534391187
[Epoch 3, Batch 1500] loss: 0.056951077089725
[Epoch 3, Batch 1600] loss: 0.06085560382620315
[Epoch 3, Batch 1700] loss: 0.0667205650984397
[Epoch 3, Batch 1800] loss: 0.050472251745741235
**STATS for Epoch 3** : 
Average training loss: 0.0031
Average validation loss: 0.0686
Validation Accuracy: 0.9796
Overfitting: 0.0655
Best model saved at epoch 3 with validation loss: 0.0686
[Epoch 4, Batch 100] loss: 0.053442708157817834
[Epoch 4, Batch 200] loss: 0.04546287869226944
[Epoch 4, Batch 300] loss: 0.03427728316918888
[Epoch 4, Batch 400] loss: 0.046969195109577415
[Epoch 4, Batch 500] loss: 0.04291782611100643
[Epoch 4, Batch 600] loss: 0.04356350267524249
[Epoch 4, Batch 700] loss: 0.057647318381204966
[Epoch 4, Batch 800] loss: 0.04770656966102251
[Epoch 4, Batch 900] loss: 0.036825431531233334
[Epoch 4, Batch 1000] loss: 0.05585797451050894
[Epoch 4, Batch 1100] loss: 0.06468980652061873
[Epoch 4, Batch 1200] loss: 0.060187484111447705
[Epoch 4, Batch 1300] loss: 0.05580675313309257
[Epoch 4, Batch 1400] loss: 0.030760516298778386
[Epoch 4, Batch 1500] loss: 0.04077060542353138
[Epoch 4, Batch 1600] loss: 0.048382876693176514
[Epoch 4, Batch 1700] loss: 0.049996698249724435
[Epoch 4, Batch 1800] loss: 0.048905484199312926
**STATS for Epoch 4** : 
Average training loss: 0.0015
Average validation loss: 0.0516
Validation Accuracy: 0.9854
Overfitting: 0.0501
Best model saved at epoch 4 with validation loss: 0.0516
[Epoch 5, Batch 100] loss: 0.018845737623760215
[Epoch 5, Batch 200] loss: 0.015271072816194647
[Epoch 5, Batch 300] loss: 0.044812246805513496
[Epoch 5, Batch 400] loss: 0.050037716424531024
[Epoch 5, Batch 500] loss: 0.024097316179158952
[Epoch 5, Batch 600] loss: 0.026620481560257758
[Epoch 5, Batch 700] loss: 0.04589244711532956
[Epoch 5, Batch 800] loss: 0.028255379932179494
[Epoch 5, Batch 900] loss: 0.02999485057418269
[Epoch 5, Batch 1000] loss: 0.046595455718288575
[Epoch 5, Batch 1100] loss: 0.025064945566678033
[Epoch 5, Batch 1200] loss: 0.04775869218214211
[Epoch 5, Batch 1300] loss: 0.04166493129103401
[Epoch 5, Batch 1400] loss: 0.03784528812560893
[Epoch 5, Batch 1500] loss: 0.059218697045980664
[Epoch 5, Batch 1600] loss: 0.040125618125966864
[Epoch 5, Batch 1700] loss: 0.03563128567923286
[Epoch 5, Batch 1800] loss: 0.052764298900510764
**STATS for Epoch 5** : 
Average training loss: 0.0013
Average validation loss: 0.0557
Validation Accuracy: 0.9837
Overfitting: 0.0544
[Epoch 6, Batch 100] loss: 0.0217935542403211
[Epoch 6, Batch 200] loss: 0.020460535919301037
[Epoch 6, Batch 300] loss: 0.01837599640822191
[Epoch 6, Batch 400] loss: 0.02664155121794465
[Epoch 6, Batch 500] loss: 0.04008974353797384
[Epoch 6, Batch 600] loss: 0.03592218698600846
[Epoch 6, Batch 700] loss: 0.04049241874317886
[Epoch 6, Batch 800] loss: 0.0264182487855669
[Epoch 6, Batch 900] loss: 0.023366785696098305
[Epoch 6, Batch 1000] loss: 0.024570825227492606
[Epoch 6, Batch 1100] loss: 0.031177036063779723
[Epoch 6, Batch 1200] loss: 0.036446687774512154
[Epoch 6, Batch 1300] loss: 0.02431146624846292
[Epoch 6, Batch 1400] loss: 0.04731659102599451
[Epoch 6, Batch 1500] loss: 0.02734417791634769
[Epoch 6, Batch 1600] loss: 0.0527663869524622
[Epoch 6, Batch 1700] loss: 0.03745758018876586
[Epoch 6, Batch 1800] loss: 0.04253405266417758
**STATS for Epoch 6** : 
Average training loss: 0.0012
Average validation loss: 0.0605
Validation Accuracy: 0.9839
Overfitting: 0.0593
[Epoch 7, Batch 100] loss: 0.01373219004885641
[Epoch 7, Batch 200] loss: 0.01510427060847178
[Epoch 7, Batch 300] loss: 0.014899883564627316
[Epoch 7, Batch 400] loss: 0.025450868264374548
[Epoch 7, Batch 500] loss: 0.04188572910400581
[Epoch 7, Batch 600] loss: 0.037018705073478486
[Epoch 7, Batch 700] loss: 0.019373085263150642
[Epoch 7, Batch 800] loss: 0.020675357900678364
[Epoch 7, Batch 900] loss: 0.02070433951396808
[Epoch 7, Batch 1000] loss: 0.01307082707654331
[Epoch 7, Batch 1100] loss: 0.021183627948561254
[Epoch 7, Batch 1200] loss: 0.022881414051798856
[Epoch 7, Batch 1300] loss: 0.034895029852414154
[Epoch 7, Batch 1400] loss: 0.04071673736972116
[Epoch 7, Batch 1500] loss: 0.019768504199055313
[Epoch 7, Batch 1600] loss: 0.015699311095769417
[Epoch 7, Batch 1700] loss: 0.04565698217144018
[Epoch 7, Batch 1800] loss: 0.037589113887877376
**STATS for Epoch 7** : 
Average training loss: 0.0018
Average validation loss: 0.0639
Validation Accuracy: 0.9824
Overfitting: 0.0621
[Epoch 8, Batch 100] loss: 0.03027408666962401
[Epoch 8, Batch 200] loss: 0.01598724703761036
[Epoch 8, Batch 300] loss: 0.008368446585052425
[Epoch 8, Batch 400] loss: 0.014502140878605588
[Epoch 8, Batch 500] loss: 0.0038947136092406256
[Epoch 8, Batch 600] loss: 0.013715114065951184
[Epoch 8, Batch 700] loss: 0.01767167854296531
[Epoch 8, Batch 800] loss: 0.011176273575934204
[Epoch 8, Batch 900] loss: 0.03377347042545011
[Epoch 8, Batch 1000] loss: 0.04615966400985599
[Epoch 8, Batch 1100] loss: 0.03060579621796478
[Epoch 8, Batch 1200] loss: 0.03445783935832822
[Epoch 8, Batch 1300] loss: 0.03093648122317063
[Epoch 8, Batch 1400] loss: 0.0306822754055338
[Epoch 8, Batch 1500] loss: 0.020043312766815688
[Epoch 8, Batch 1600] loss: 0.015599404839006183
[Epoch 8, Batch 1700] loss: 0.04863910456817024
[Epoch 8, Batch 1800] loss: 0.01722512122158264
**STATS for Epoch 8** : 
Average training loss: 0.0008
Average validation loss: 0.0613
Validation Accuracy: 0.9868
Overfitting: 0.0605
[Epoch 9, Batch 100] loss: 0.010759336739355377
[Epoch 9, Batch 200] loss: 0.012407297961816539
[Epoch 9, Batch 300] loss: 0.01598907125334506
[Epoch 9, Batch 400] loss: 0.01591264274831701
[Epoch 9, Batch 500] loss: 0.024120592466836115
[Epoch 9, Batch 600] loss: 0.012038198667736423
[Epoch 9, Batch 700] loss: 0.02117373667394503
[Epoch 9, Batch 800] loss: 0.017319219038422488
[Epoch 9, Batch 900] loss: 0.006081965145745017
[Epoch 9, Batch 1000] loss: 0.014218999612060088
[Epoch 9, Batch 1100] loss: 0.030155973209441526
[Epoch 9, Batch 1200] loss: 0.020038990181133157
[Epoch 9, Batch 1300] loss: 0.023162654889526946
[Epoch 9, Batch 1400] loss: 0.02574615621709654
[Epoch 9, Batch 1500] loss: 0.01987653003272726
[Epoch 9, Batch 1600] loss: 0.008112464733240739
[Epoch 9, Batch 1700] loss: 0.006367099273133761
[Epoch 9, Batch 1800] loss: 0.022388953971755825
**STATS for Epoch 9** : 
Average training loss: 0.0012
Average validation loss: 0.0787
Validation Accuracy: 0.9820
Overfitting: 0.0775
[Epoch 10, Batch 100] loss: 0.023896046728623332
[Epoch 10, Batch 200] loss: 0.0067698142367179056
[Epoch 10, Batch 300] loss: 0.002629661842770008
[Epoch 10, Batch 400] loss: 0.007724108291815242
[Epoch 10, Batch 500] loss: 0.0059654534431222575
[Epoch 10, Batch 600] loss: 0.01268448294066939
[Epoch 10, Batch 700] loss: 0.03671245356894497
[Epoch 10, Batch 800] loss: 0.039609689434743134
[Epoch 10, Batch 900] loss: 0.025461092196238155
[Epoch 10, Batch 1000] loss: 0.04703384495518776
[Epoch 10, Batch 1100] loss: 0.03165412405853203
[Epoch 10, Batch 1200] loss: 0.04046349379013307
[Epoch 10, Batch 1300] loss: 0.015891878075329942
[Epoch 10, Batch 1400] loss: 0.02099833450836968
[Epoch 10, Batch 1500] loss: 0.015437932222019413
[Epoch 10, Batch 1600] loss: 0.020673378510683307
[Epoch 10, Batch 1700] loss: 0.016163903491705225
[Epoch 10, Batch 1800] loss: 0.02489815010097118
**STATS for Epoch 10** : 
Average training loss: 0.0009
Average validation loss: 0.0633
Validation Accuracy: 0.9863
Overfitting: 0.0624
[Epoch 11, Batch 100] loss: 0.006485177709860182
[Epoch 11, Batch 200] loss: 0.014979338369773866
[Epoch 11, Batch 300] loss: 0.011093245333261734
[Epoch 11, Batch 400] loss: 0.009139600286142269
[Epoch 11, Batch 500] loss: 0.013717189902082793
[Epoch 11, Batch 600] loss: 0.026687367746116877
[Epoch 11, Batch 700] loss: 0.022064124912800197
[Epoch 11, Batch 800] loss: 0.0441802311466688
[Epoch 11, Batch 900] loss: 0.022567518429772237
[Epoch 11, Batch 1000] loss: 0.02178038422203926
[Epoch 11, Batch 1100] loss: 0.009220713200396186
[Epoch 11, Batch 1200] loss: 0.01070642706210748
[Epoch 11, Batch 1300] loss: 0.027480194958619107
[Epoch 11, Batch 1400] loss: 0.007948342101349688
[Epoch 11, Batch 1500] loss: 0.0204983284129181
[Epoch 11, Batch 1600] loss: 0.03816293467507179
[Epoch 11, Batch 1700] loss: 0.017516436989083103
[Epoch 11, Batch 1800] loss: 0.026685777956757875
**STATS for Epoch 11** : 
Average training loss: 0.0019
Average validation loss: 0.0908
Validation Accuracy: 0.9778
Overfitting: 0.0889
[Epoch 12, Batch 100] loss: 0.024572353842893337
[Epoch 12, Batch 200] loss: 0.017120548403543125
[Epoch 12, Batch 300] loss: 0.01344095883447153
[Epoch 12, Batch 400] loss: 0.010650411268912379
[Epoch 12, Batch 500] loss: 0.01848062907817166
[Epoch 12, Batch 600] loss: 0.011442990501150803
[Epoch 12, Batch 700] loss: 0.006531984720560331
[Epoch 12, Batch 800] loss: 0.021001684548453456
[Epoch 12, Batch 900] loss: 0.02194551605223701
[Epoch 12, Batch 1000] loss: 0.012706278894551132
[Epoch 12, Batch 1100] loss: 0.024805236243295104
[Epoch 12, Batch 1200] loss: 0.04613707050097446
[Epoch 12, Batch 1300] loss: 0.01894930740076461
[Epoch 12, Batch 1400] loss: 0.023932405984824358
[Epoch 12, Batch 1500] loss: 0.026914696984929664
[Epoch 12, Batch 1600] loss: 0.01894724565106742
[Epoch 12, Batch 1700] loss: 0.016842977303888916
[Epoch 12, Batch 1800] loss: 0.010840722469160511
**STATS for Epoch 12** : 
Average training loss: 0.0009
Average validation loss: 0.0776
Validation Accuracy: 0.9837
Overfitting: 0.0767
[Epoch 13, Batch 100] loss: 0.006203624138067028
[Epoch 13, Batch 200] loss: 0.01931977368509024
[Epoch 13, Batch 300] loss: 0.013348538406919701
[Epoch 13, Batch 400] loss: 0.018163145287576798
[Epoch 13, Batch 500] loss: 0.015938272045694504
[Epoch 13, Batch 600] loss: 0.017777556757180832
[Epoch 13, Batch 700] loss: 0.01273863591841474
[Epoch 13, Batch 800] loss: 0.02998896111789456
[Epoch 13, Batch 900] loss: 0.04373058430503491
[Epoch 13, Batch 1000] loss: 0.02231635597159652
[Epoch 13, Batch 1100] loss: 0.02430883718097647
[Epoch 13, Batch 1200] loss: 0.013850038722377746
[Epoch 13, Batch 1300] loss: 0.008919814960506471
[Epoch 13, Batch 1400] loss: 0.023907251761602293
[Epoch 13, Batch 1500] loss: 0.00922318816480896
[Epoch 13, Batch 1600] loss: 0.025684840120822727
[Epoch 13, Batch 1700] loss: 0.011673432256075094
[Epoch 13, Batch 1800] loss: 0.05030347873217536
**STATS for Epoch 13** : 
Average training loss: 0.0012
Average validation loss: 0.0696
Validation Accuracy: 0.9845
Overfitting: 0.0684
[Epoch 14, Batch 100] loss: 0.009154921336094048
[Epoch 14, Batch 200] loss: 0.0077248239275117215
[Epoch 14, Batch 300] loss: 0.008115085395433824
[Epoch 14, Batch 400] loss: 0.004095742621745671
[Epoch 14, Batch 500] loss: 0.005735954785438615
[Epoch 14, Batch 600] loss: 0.01928061854652471
[Epoch 14, Batch 700] loss: 0.013907565219180356
[Epoch 14, Batch 800] loss: 0.006076770052173544
[Epoch 14, Batch 900] loss: 0.005462284087882931
[Epoch 14, Batch 1000] loss: 0.009847854886651209
[Epoch 14, Batch 1100] loss: 0.011922054278741214
[Epoch 14, Batch 1200] loss: 0.015871317964717947
[Epoch 14, Batch 1300] loss: 0.010076268363664482
[Epoch 14, Batch 1400] loss: 0.037852873202744455
[Epoch 14, Batch 1500] loss: 0.018609608589514718
[Epoch 14, Batch 1600] loss: 0.02070706956757384
[Epoch 14, Batch 1700] loss: 0.025840432429301907
[Epoch 14, Batch 1800] loss: 0.03176188572026333
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0770
Validation Accuracy: 0.9839
Overfitting: 0.0758
[Epoch 15, Batch 100] loss: 0.004552950271826717
[Epoch 15, Batch 200] loss: 0.02345363642793899
[Epoch 15, Batch 300] loss: 0.0067927670034855225
[Epoch 15, Batch 400] loss: 0.025128165349432754
[Epoch 15, Batch 500] loss: 0.02010131052506475
[Epoch 15, Batch 600] loss: 0.005796883364341099
[Epoch 15, Batch 700] loss: 0.002831099384177267
[Epoch 15, Batch 800] loss: 0.0027377272619846195
[Epoch 15, Batch 900] loss: 0.004697746440679107
[Epoch 15, Batch 1000] loss: 0.007731269449603166
[Epoch 15, Batch 1100] loss: 0.02570398955611381
[Epoch 15, Batch 1200] loss: 0.017984999344462765
[Epoch 15, Batch 1300] loss: 0.014086635723917596
[Epoch 15, Batch 1400] loss: 0.008367373374094877
[Epoch 15, Batch 1500] loss: 0.008677523962089562
[Epoch 15, Batch 1600] loss: 0.01368418007927791
[Epoch 15, Batch 1700] loss: 0.01549805463832513
[Epoch 15, Batch 1800] loss: 0.013784781239764995
**STATS for Epoch 15** : 
Average training loss: 0.0001
Average validation loss: 0.0732
Validation Accuracy: 0.9860
Overfitting: 0.0730
[Epoch 16, Batch 100] loss: 0.0032732119420131587
[Epoch 16, Batch 200] loss: 0.002076059127111214
[Epoch 16, Batch 300] loss: 0.0029752248148498016
[Epoch 16, Batch 400] loss: 0.003616043243109002
[Epoch 16, Batch 500] loss: 0.0028031183404014113
[Epoch 16, Batch 600] loss: 0.0036280283777574062
[Epoch 16, Batch 700] loss: 0.0013939885643017868
[Epoch 16, Batch 800] loss: 0.003814047168193624
[Epoch 16, Batch 900] loss: 0.0016148751912214898
[Epoch 16, Batch 1000] loss: 0.004617676932701831
[Epoch 16, Batch 1100] loss: 0.035538413322661604
[Epoch 16, Batch 1200] loss: 0.010624722010441148
[Epoch 16, Batch 1300] loss: 0.009441234611764137
[Epoch 16, Batch 1400] loss: 0.007794855956552835
[Epoch 16, Batch 1500] loss: 0.030923474347918433
[Epoch 16, Batch 1600] loss: 0.037257053570160396
[Epoch 16, Batch 1700] loss: 0.029678144354346188
[Epoch 16, Batch 1800] loss: 0.005612288005483208
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0731
Validation Accuracy: 0.9865
Overfitting: 0.0729
[Epoch 17, Batch 100] loss: 0.0031569803280949047
[Epoch 17, Batch 200] loss: 0.013031227085352377
[Epoch 17, Batch 300] loss: 0.01369386025783526
[Epoch 17, Batch 400] loss: 0.0065830122938809014
[Epoch 17, Batch 500] loss: 0.014092534625060504
[Epoch 17, Batch 600] loss: 0.016774456505025695
[Epoch 17, Batch 700] loss: 0.023988377130803647
[Epoch 17, Batch 800] loss: 0.013745164312458202
[Epoch 17, Batch 900] loss: 0.018561175370191484
[Epoch 17, Batch 1000] loss: 0.008699242970755883
[Epoch 17, Batch 1100] loss: 0.020929637649574295
[Epoch 17, Batch 1200] loss: 0.022226265345947988
[Epoch 17, Batch 1300] loss: 0.01822188003311382
[Epoch 17, Batch 1400] loss: 0.01330834021709265
[Epoch 17, Batch 1500] loss: 0.016781632976581237
[Epoch 17, Batch 1600] loss: 0.009651727078248983
[Epoch 17, Batch 1700] loss: 0.006909353033385041
[Epoch 17, Batch 1800] loss: 0.010882372976940285
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0933
Validation Accuracy: 0.9836
Overfitting: 0.0925
[Epoch 18, Batch 100] loss: 0.025414102739153534
[Epoch 18, Batch 200] loss: 0.011279269308715647
[Epoch 18, Batch 300] loss: 0.016817127669229635
[Epoch 18, Batch 400] loss: 0.010305257409524522
[Epoch 18, Batch 500] loss: 0.014115727196417254
[Epoch 18, Batch 600] loss: 0.008687400683172655
[Epoch 18, Batch 700] loss: 0.006059152385016091
[Epoch 18, Batch 800] loss: 0.021769808216329806
[Epoch 18, Batch 900] loss: 0.013164649164118601
[Epoch 18, Batch 1000] loss: 0.008896222410519367
[Epoch 18, Batch 1100] loss: 0.0055745376258559
[Epoch 18, Batch 1200] loss: 0.002489814135152364
[Epoch 18, Batch 1300] loss: 0.03112205067722754
[Epoch 18, Batch 1400] loss: 0.018238122766667003
[Epoch 18, Batch 1500] loss: 0.0172573803231743
[Epoch 18, Batch 1600] loss: 0.01019558932285868
[Epoch 18, Batch 1700] loss: 0.017065334148013624
[Epoch 18, Batch 1800] loss: 0.012533372447862217
**STATS for Epoch 18** : 
Average training loss: 0.0014
Average validation loss: 0.0828
Validation Accuracy: 0.9843
Overfitting: 0.0814
[Epoch 19, Batch 100] loss: 0.008307428581424095
[Epoch 19, Batch 200] loss: 0.006172931689860075
[Epoch 19, Batch 300] loss: 0.005594270705508526
[Epoch 19, Batch 400] loss: 0.0015795445881580284
[Epoch 19, Batch 500] loss: 0.0008300072132694813
[Epoch 19, Batch 600] loss: 0.0009677632477708454
[Epoch 19, Batch 700] loss: 0.00887479052970054
[Epoch 19, Batch 800] loss: 0.010875270243261
[Epoch 19, Batch 900] loss: 0.003202832498815855
[Epoch 19, Batch 1000] loss: 0.0010294978919559972
[Epoch 19, Batch 1100] loss: 0.00909482446259779
[Epoch 19, Batch 1200] loss: 0.02500265488926807
[Epoch 19, Batch 1300] loss: 0.01864270480483624
[Epoch 19, Batch 1400] loss: 0.008334583001478975
[Epoch 19, Batch 1500] loss: 0.0076392179647230265
[Epoch 19, Batch 1600] loss: 0.011527559489705292
[Epoch 19, Batch 1700] loss: 0.020964023858616353
[Epoch 19, Batch 1800] loss: 0.024134302314736397
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0810
Validation Accuracy: 0.9856
Overfitting: 0.0805
[Epoch 20, Batch 100] loss: 0.01641651172113276
[Epoch 20, Batch 200] loss: 0.017221553177623715
[Epoch 20, Batch 300] loss: 0.018951117051857907
[Epoch 20, Batch 400] loss: 0.018733697574898223
[Epoch 20, Batch 500] loss: 0.00861983129810496
[Epoch 20, Batch 600] loss: 0.023037172362547865
[Epoch 20, Batch 700] loss: 0.013903122486409316
[Epoch 20, Batch 800] loss: 0.0026631879925144374
[Epoch 20, Batch 900] loss: 0.010824077745815707
[Epoch 20, Batch 1000] loss: 0.012552440433868583
[Epoch 20, Batch 1100] loss: 0.004581389346069082
[Epoch 20, Batch 1200] loss: 0.00626975315227138
[Epoch 20, Batch 1300] loss: 0.008960654162703615
[Epoch 20, Batch 1400] loss: 0.03625158405895112
[Epoch 20, Batch 1500] loss: 0.006850318251042533
[Epoch 20, Batch 1600] loss: 0.010021406026141069
[Epoch 20, Batch 1700] loss: 0.009196982768778783
[Epoch 20, Batch 1800] loss: 0.014454817773769703
**STATS for Epoch 20** : 
Average training loss: 0.0009
Average validation loss: 0.0951
Validation Accuracy: 0.9836
Overfitting: 0.0943
[Epoch 21, Batch 100] loss: 0.021606687823928064
[Epoch 21, Batch 200] loss: 0.005918667081880642
[Epoch 21, Batch 300] loss: 0.003774820090166293
[Epoch 21, Batch 400] loss: 0.005390502034455072
[Epoch 21, Batch 500] loss: 0.0016723786214588897
[Epoch 21, Batch 600] loss: 0.002629861223927601
[Epoch 21, Batch 700] loss: 0.025783583853186545
[Epoch 21, Batch 800] loss: 0.013152091679965637
[Epoch 21, Batch 900] loss: 0.005169365472943475
[Epoch 21, Batch 1000] loss: 0.003641146279089975
[Epoch 21, Batch 1100] loss: 0.002408008809139677
[Epoch 21, Batch 1200] loss: 0.00323157918775264
[Epoch 21, Batch 1300] loss: 0.002414372141569605
[Epoch 21, Batch 1400] loss: 0.008908425144367587
[Epoch 21, Batch 1500] loss: 0.012082486079198746
[Epoch 21, Batch 1600] loss: 0.0054592815780930785
[Epoch 21, Batch 1700] loss: 0.005780082242538818
[Epoch 21, Batch 1800] loss: 0.014014113219878959
**STATS for Epoch 21** : 
Average training loss: 0.0010
Average validation loss: 0.0871
Validation Accuracy: 0.9850
Overfitting: 0.0861
[Epoch 22, Batch 100] loss: 0.0063844958336773065
[Epoch 22, Batch 200] loss: 0.0057734209101795875
[Epoch 22, Batch 300] loss: 0.00675755067391747
[Epoch 22, Batch 400] loss: 0.0178356643950925
[Epoch 22, Batch 500] loss: 0.007745071815826497
[Epoch 22, Batch 600] loss: 0.02541037604306094
[Epoch 22, Batch 700] loss: 0.020671260142951498
[Epoch 22, Batch 800] loss: 0.005314629537523468
[Epoch 22, Batch 900] loss: 0.009136532330912415
[Epoch 22, Batch 1000] loss: 0.019354211649604932
[Epoch 22, Batch 1100] loss: 0.0022533434358779124
[Epoch 22, Batch 1200] loss: 0.012899171922251984
[Epoch 22, Batch 1300] loss: 0.014796496437816695
[Epoch 22, Batch 1400] loss: 0.009243890640247466
[Epoch 22, Batch 1500] loss: 0.0156924334915087
[Epoch 22, Batch 1600] loss: 0.01074446853207199
[Epoch 22, Batch 1700] loss: 0.010536350391872631
[Epoch 22, Batch 1800] loss: 0.01624152129145827
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0917
Validation Accuracy: 0.9840
Overfitting: 0.0910
[Epoch 23, Batch 100] loss: 0.006988796686955059
[Epoch 23, Batch 200] loss: 0.005503490456503708
[Epoch 23, Batch 300] loss: 0.02519950257537573
[Epoch 23, Batch 400] loss: 0.005963575230722444
[Epoch 23, Batch 500] loss: 0.00638444363003948
[Epoch 23, Batch 600] loss: 0.010703133615066696
[Epoch 23, Batch 700] loss: 0.029465720197383173
[Epoch 23, Batch 800] loss: 0.008528021033787709
[Epoch 23, Batch 900] loss: 0.020809396620124234
[Epoch 23, Batch 1000] loss: 0.025064634092940512
[Epoch 23, Batch 1100] loss: 0.01774142244211676
[Epoch 23, Batch 1200] loss: 0.006827218680215022
[Epoch 23, Batch 1300] loss: 0.002228702925288513
[Epoch 23, Batch 1400] loss: 0.007015225836638037
[Epoch 23, Batch 1500] loss: 0.007282580129945564
[Epoch 23, Batch 1600] loss: 0.008864077528545925
[Epoch 23, Batch 1700] loss: 0.01035063720471264
[Epoch 23, Batch 1800] loss: 0.014272521289376935
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0781
Validation Accuracy: 0.9867
Overfitting: 0.0779
[Epoch 24, Batch 100] loss: 0.0025949373714293645
[Epoch 24, Batch 200] loss: 0.01563310910590343
[Epoch 24, Batch 300] loss: 0.029231868076237896
[Epoch 24, Batch 400] loss: 0.014811916441735526
[Epoch 24, Batch 500] loss: 0.021864749088891154
[Epoch 24, Batch 600] loss: 0.02222699262104284
[Epoch 24, Batch 700] loss: 0.009081260924604675
[Epoch 24, Batch 800] loss: 0.020827514002740192
[Epoch 24, Batch 900] loss: 0.024037231747781485
[Epoch 24, Batch 1000] loss: 0.04514429034340324
[Epoch 24, Batch 1100] loss: 0.009314888833559883
[Epoch 24, Batch 1200] loss: 0.008882202697232767
[Epoch 24, Batch 1300] loss: 0.008999579693158651
[Epoch 24, Batch 1400] loss: 0.010328257495741972
[Epoch 24, Batch 1500] loss: 0.021997067276837753
[Epoch 24, Batch 1600] loss: 0.022400201682051327
[Epoch 24, Batch 1700] loss: 0.00966841269894913
[Epoch 24, Batch 1800] loss: 0.023692059265087037
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.1036
Validation Accuracy: 0.9825
Overfitting: 0.1033
Fold 2 validation loss: 0.1036
Mean validation loss across all folds for Trial 18 is 0.1119 with trial config:  l1: 256, l2: 128, lr: 0.009287011926825201, batch_size: 16
[I 2024-11-22 00:16:40,125] Trial 17 finished with value: 0.11187524744773272 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.009287011926825201, 'batch_size': 16}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 19:
  l1: 256, l2: 64, lr: 0.024286525795066936, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.0358957524597645
[Epoch 1, Batch 200] loss: 0.20816604811698197
[Epoch 1, Batch 300] loss: 0.12515778809785844
[Epoch 1, Batch 400] loss: 0.12385849742218852
**STATS for Epoch 1** : 
Average training loss: 0.0151
Average validation loss: 0.1036
Validation Accuracy: 0.9671
Overfitting: 0.0885
Best model saved at epoch 1 with validation loss: 0.1036
[Epoch 2, Batch 100] loss: 0.07904847424477339
[Epoch 2, Batch 200] loss: 0.07838279715739191
[Epoch 2, Batch 300] loss: 0.08179381280206144
[Epoch 2, Batch 400] loss: 0.08459668391384184
**STATS for Epoch 2** : 
Average training loss: 0.0118
Average validation loss: 0.0964
Validation Accuracy: 0.9707
Overfitting: 0.0845
Best model saved at epoch 2 with validation loss: 0.0964
[Epoch 3, Batch 100] loss: 0.04936385025561321
[Epoch 3, Batch 200] loss: 0.05423059633933008
[Epoch 3, Batch 300] loss: 0.057264910764060914
[Epoch 3, Batch 400] loss: 0.048809132695896554
**STATS for Epoch 3** : 
Average training loss: 0.0090
Average validation loss: 0.0585
Validation Accuracy: 0.9826
Overfitting: 0.0495
Best model saved at epoch 3 with validation loss: 0.0585
[Epoch 4, Batch 100] loss: 0.03128192424890585
[Epoch 4, Batch 200] loss: 0.03651065354584716
[Epoch 4, Batch 300] loss: 0.03709573854401242
[Epoch 4, Batch 400] loss: 0.04615012451540679
**STATS for Epoch 4** : 
Average training loss: 0.0070
Average validation loss: 0.0552
Validation Accuracy: 0.9833
Overfitting: 0.0482
Best model saved at epoch 4 with validation loss: 0.0552
[Epoch 5, Batch 100] loss: 0.031807135876151735
[Epoch 5, Batch 200] loss: 0.033921325420378706
[Epoch 5, Batch 300] loss: 0.026545833981072065
[Epoch 5, Batch 400] loss: 0.0371892031369498
**STATS for Epoch 5** : 
Average training loss: 0.0050
Average validation loss: 0.0932
Validation Accuracy: 0.9753
Overfitting: 0.0883
[Epoch 6, Batch 100] loss: 0.0300820085714804
[Epoch 6, Batch 200] loss: 0.026095295835402793
[Epoch 6, Batch 300] loss: 0.02821674864127999
[Epoch 6, Batch 400] loss: 0.030207616878906263
**STATS for Epoch 6** : 
Average training loss: 0.0047
Average validation loss: 0.0638
Validation Accuracy: 0.9822
Overfitting: 0.0591
[Epoch 7, Batch 100] loss: 0.017130951824074144
[Epoch 7, Batch 200] loss: 0.023559997621778166
[Epoch 7, Batch 300] loss: 0.025592877269373274
[Epoch 7, Batch 400] loss: 0.02554516325559234
**STATS for Epoch 7** : 
Average training loss: 0.0039
Average validation loss: 0.0535
Validation Accuracy: 0.9853
Overfitting: 0.0496
Best model saved at epoch 7 with validation loss: 0.0535
[Epoch 8, Batch 100] loss: 0.012902362392487703
[Epoch 8, Batch 200] loss: 0.01497047327386099
[Epoch 8, Batch 300] loss: 0.014360664862142585
[Epoch 8, Batch 400] loss: 0.022556107695418177
**STATS for Epoch 8** : 
Average training loss: 0.0033
Average validation loss: 0.0640
Validation Accuracy: 0.9850
Overfitting: 0.0607
[Epoch 9, Batch 100] loss: 0.013951042918779421
[Epoch 9, Batch 200] loss: 0.013444967853283743
[Epoch 9, Batch 300] loss: 0.027451655789191134
[Epoch 9, Batch 400] loss: 0.023259890512781566
**STATS for Epoch 9** : 
Average training loss: 0.0033
Average validation loss: 0.0552
Validation Accuracy: 0.9851
Overfitting: 0.0519
[Epoch 10, Batch 100] loss: 0.008137154708238085
[Epoch 10, Batch 200] loss: 0.012152112669027701
[Epoch 10, Batch 300] loss: 0.012937923235804193
[Epoch 10, Batch 400] loss: 0.026835412300824826
**STATS for Epoch 10** : 
Average training loss: 0.0038
Average validation loss: 0.0700
Validation Accuracy: 0.9843
Overfitting: 0.0662
[Epoch 11, Batch 100] loss: 0.010518010584273724
[Epoch 11, Batch 200] loss: 0.006931444178376296
[Epoch 11, Batch 300] loss: 0.01577640513158258
[Epoch 11, Batch 400] loss: 0.01327578973461641
**STATS for Epoch 11** : 
Average training loss: 0.0025
Average validation loss: 0.0646
Validation Accuracy: 0.9856
Overfitting: 0.0621
[Epoch 12, Batch 100] loss: 0.008632440130386386
[Epoch 12, Batch 200] loss: 0.010393618065791088
[Epoch 12, Batch 300] loss: 0.008916931417970772
[Epoch 12, Batch 400] loss: 0.021641030108585254
**STATS for Epoch 12** : 
Average training loss: 0.0029
Average validation loss: 0.0691
Validation Accuracy: 0.9836
Overfitting: 0.0662
[Epoch 13, Batch 100] loss: 0.010606575351102947
[Epoch 13, Batch 200] loss: 0.0051918444690636535
[Epoch 13, Batch 300] loss: 0.004683595448500455
[Epoch 13, Batch 400] loss: 0.0061162237713597275
**STATS for Epoch 13** : 
Average training loss: 0.0021
Average validation loss: 0.0668
Validation Accuracy: 0.9849
Overfitting: 0.0647
[Epoch 14, Batch 100] loss: 0.008127321217507415
[Epoch 14, Batch 200] loss: 0.005953352276851547
[Epoch 14, Batch 300] loss: 0.0062972559553872995
[Epoch 14, Batch 400] loss: 0.005025652330705271
**STATS for Epoch 14** : 
Average training loss: 0.0015
Average validation loss: 0.0732
Validation Accuracy: 0.9868
Overfitting: 0.0717
[Epoch 15, Batch 100] loss: 0.0038887377085984553
[Epoch 15, Batch 200] loss: 0.013640281509549369
[Epoch 15, Batch 300] loss: 0.01502047417005997
[Epoch 15, Batch 400] loss: 0.011234288752339125
**STATS for Epoch 15** : 
Average training loss: 0.0035
Average validation loss: 0.0785
Validation Accuracy: 0.9834
Overfitting: 0.0749
[Epoch 16, Batch 100] loss: 0.017085985279536545
[Epoch 16, Batch 200] loss: 0.014515697251817982
[Epoch 16, Batch 300] loss: 0.020379932412233757
[Epoch 16, Batch 400] loss: 0.0075617384128599955
**STATS for Epoch 16** : 
Average training loss: 0.0012
Average validation loss: 0.0636
Validation Accuracy: 0.9865
Overfitting: 0.0625
[Epoch 17, Batch 100] loss: 0.007862126683758106
[Epoch 17, Batch 200] loss: 0.004112604620540878
[Epoch 17, Batch 300] loss: 0.01042330515598394
[Epoch 17, Batch 400] loss: 0.010248634124416185
**STATS for Epoch 17** : 
Average training loss: 0.0016
Average validation loss: 0.0648
Validation Accuracy: 0.9871
Overfitting: 0.0632
[Epoch 18, Batch 100] loss: 0.004233068108514999
[Epoch 18, Batch 200] loss: 0.005529383820867793
[Epoch 18, Batch 300] loss: 0.0023069858428470978
[Epoch 18, Batch 400] loss: 0.002996382520825591
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0659
Validation Accuracy: 0.9877
Overfitting: 0.0651
[Epoch 19, Batch 100] loss: 0.0009935088357872245
[Epoch 19, Batch 200] loss: 0.0010665046270719358
[Epoch 19, Batch 300] loss: 0.0037512455350406527
[Epoch 19, Batch 400] loss: 0.009023388748353227
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0641
Validation Accuracy: 0.9880
Overfitting: 0.0636
[Epoch 20, Batch 100] loss: 0.0033438036477460285
[Epoch 20, Batch 200] loss: 0.0017657117732579764
[Epoch 20, Batch 300] loss: 0.0006948261805871425
[Epoch 20, Batch 400] loss: 0.0011421821657989994
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0658
Validation Accuracy: 0.9885
Overfitting: 0.0653
[Epoch 21, Batch 100] loss: 0.004953853528632522
[Epoch 21, Batch 200] loss: 0.0016931330549698486
[Epoch 21, Batch 300] loss: 0.005197734100693197
[Epoch 21, Batch 400] loss: 0.0029482800688072075
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0652
Validation Accuracy: 0.9888
Overfitting: 0.0649
[Epoch 22, Batch 100] loss: 0.00028894006797088425
[Epoch 22, Batch 200] loss: 0.0003843886854862433
[Epoch 22, Batch 300] loss: 0.0001893735222893156
[Epoch 22, Batch 400] loss: 0.00020525371530226267
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0678
Validation Accuracy: 0.9890
Overfitting: 0.0675
[Epoch 23, Batch 100] loss: 0.000755290040645491
[Epoch 23, Batch 200] loss: 0.00020749153309024493
[Epoch 23, Batch 300] loss: 0.0006888509199474413
[Epoch 23, Batch 400] loss: 0.0004074990105972631
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0677
Validation Accuracy: 0.9889
Overfitting: 0.0676
[Epoch 24, Batch 100] loss: 9.490550110818674e-05
[Epoch 24, Batch 200] loss: 2.783527714953493e-05
[Epoch 24, Batch 300] loss: 7.113628002429095e-05
[Epoch 24, Batch 400] loss: 5.834768018843306e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0674
Validation Accuracy: 0.9892
Overfitting: 0.0673
Fold 1 validation loss: 0.0674
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 0.9953438967466355
[Epoch 1, Batch 200] loss: 0.1981743347644806
[Epoch 1, Batch 300] loss: 0.162993351444602
[Epoch 1, Batch 400] loss: 0.13151519311591983
**STATS for Epoch 1** : 
Average training loss: 0.0166
Average validation loss: 0.0953
Validation Accuracy: 0.9702
Overfitting: 0.0787
Best model saved at epoch 1 with validation loss: 0.0953
[Epoch 2, Batch 100] loss: 0.0890894881915301
[Epoch 2, Batch 200] loss: 0.08191432934720069
[Epoch 2, Batch 300] loss: 0.08590428544906899
[Epoch 2, Batch 400] loss: 0.07987119231373072
**STATS for Epoch 2** : 
Average training loss: 0.0112
Average validation loss: 0.0694
Validation Accuracy: 0.9786
Overfitting: 0.0582
Best model saved at epoch 2 with validation loss: 0.0694
[Epoch 3, Batch 100] loss: 0.04980253321584314
[Epoch 3, Batch 200] loss: 0.05220179147290764
[Epoch 3, Batch 300] loss: 0.05194721357023809
[Epoch 3, Batch 400] loss: 0.051207576706074176
**STATS for Epoch 3** : 
Average training loss: 0.0092
Average validation loss: 0.0621
Validation Accuracy: 0.9806
Overfitting: 0.0528
Best model saved at epoch 3 with validation loss: 0.0621
[Epoch 4, Batch 100] loss: 0.03666045099656912
[Epoch 4, Batch 200] loss: 0.045333483951399106
[Epoch 4, Batch 300] loss: 0.04150703653285746
[Epoch 4, Batch 400] loss: 0.04816703876655083
**STATS for Epoch 4** : 
Average training loss: 0.0069
Average validation loss: 0.0571
Validation Accuracy: 0.9830
Overfitting: 0.0502
Best model saved at epoch 4 with validation loss: 0.0571
[Epoch 5, Batch 100] loss: 0.035520282345823946
[Epoch 5, Batch 200] loss: 0.027692853058106266
[Epoch 5, Batch 300] loss: 0.035220530266524296
[Epoch 5, Batch 400] loss: 0.04234904918259417
**STATS for Epoch 5** : 
Average training loss: 0.0052
Average validation loss: 0.0731
Validation Accuracy: 0.9806
Overfitting: 0.0679
[Epoch 6, Batch 100] loss: 0.03397577242925763
[Epoch 6, Batch 200] loss: 0.030534115014888813
[Epoch 6, Batch 300] loss: 0.02575084703916218
[Epoch 6, Batch 400] loss: 0.033617255507560916
**STATS for Epoch 6** : 
Average training loss: 0.0044
Average validation loss: 0.0564
Validation Accuracy: 0.9842
Overfitting: 0.0520
Best model saved at epoch 6 with validation loss: 0.0564
[Epoch 7, Batch 100] loss: 0.022391427509282948
[Epoch 7, Batch 200] loss: 0.017672489615069936
[Epoch 7, Batch 300] loss: 0.02746153414158471
[Epoch 7, Batch 400] loss: 0.027659659385244596
**STATS for Epoch 7** : 
Average training loss: 0.0029
Average validation loss: 0.0631
Validation Accuracy: 0.9841
Overfitting: 0.0601
[Epoch 8, Batch 100] loss: 0.01950068717043905
[Epoch 8, Batch 200] loss: 0.01714712999179028
[Epoch 8, Batch 300] loss: 0.026159557289502117
[Epoch 8, Batch 400] loss: 0.033694711463249406
**STATS for Epoch 8** : 
Average training loss: 0.0048
Average validation loss: 0.0712
Validation Accuracy: 0.9815
Overfitting: 0.0664
[Epoch 9, Batch 100] loss: 0.019548600153502776
[Epoch 9, Batch 200] loss: 0.01994454628365929
[Epoch 9, Batch 300] loss: 0.02463502070575487
[Epoch 9, Batch 400] loss: 0.020206091324362206
**STATS for Epoch 9** : 
Average training loss: 0.0034
Average validation loss: 0.0622
Validation Accuracy: 0.9846
Overfitting: 0.0588
[Epoch 10, Batch 100] loss: 0.011822636648794287
[Epoch 10, Batch 200] loss: 0.007612305675179414
[Epoch 10, Batch 300] loss: 0.012164744960246025
[Epoch 10, Batch 400] loss: 0.019061606371760718
**STATS for Epoch 10** : 
Average training loss: 0.0038
Average validation loss: 0.0830
Validation Accuracy: 0.9817
Overfitting: 0.0792
[Epoch 11, Batch 100] loss: 0.013466593876946717
[Epoch 11, Batch 200] loss: 0.01610958398468938
[Epoch 11, Batch 300] loss: 0.021102445691740288
[Epoch 11, Batch 400] loss: 0.013171801633448013
**STATS for Epoch 11** : 
Average training loss: 0.0019
Average validation loss: 0.0638
Validation Accuracy: 0.9861
Overfitting: 0.0618
[Epoch 12, Batch 100] loss: 0.011845601832101238
[Epoch 12, Batch 200] loss: 0.00915363832186813
[Epoch 12, Batch 300] loss: 0.01576941507330048
[Epoch 12, Batch 400] loss: 0.01288096537877209
**STATS for Epoch 12** : 
Average training loss: 0.0029
Average validation loss: 0.0729
Validation Accuracy: 0.9840
Overfitting: 0.0700
[Epoch 13, Batch 100] loss: 0.011953345300480579
[Epoch 13, Batch 200] loss: 0.01240280011044888
[Epoch 13, Batch 300] loss: 0.013729333939663775
[Epoch 13, Batch 400] loss: 0.012518875590121752
**STATS for Epoch 13** : 
Average training loss: 0.0013
Average validation loss: 0.0619
Validation Accuracy: 0.9872
Overfitting: 0.0605
[Epoch 14, Batch 100] loss: 0.007285511859086
[Epoch 14, Batch 200] loss: 0.008212665855317026
[Epoch 14, Batch 300] loss: 0.009250856906764965
[Epoch 14, Batch 400] loss: 0.005980291458731699
**STATS for Epoch 14** : 
Average training loss: 0.0014
Average validation loss: 0.0732
Validation Accuracy: 0.9852
Overfitting: 0.0718
[Epoch 15, Batch 100] loss: 0.008749600714181724
[Epoch 15, Batch 200] loss: 0.004189427631638409
[Epoch 15, Batch 300] loss: 0.007907628876191666
[Epoch 15, Batch 400] loss: 0.014322009677725874
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0798
Validation Accuracy: 0.9848
Overfitting: 0.0789
[Epoch 16, Batch 100] loss: 0.01325860123282837
[Epoch 16, Batch 200] loss: 0.009362092464070883
[Epoch 16, Batch 300] loss: 0.010296985195989237
[Epoch 16, Batch 400] loss: 0.00347513043469462
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0661
Validation Accuracy: 0.9871
Overfitting: 0.0658
[Epoch 17, Batch 100] loss: 0.0027420885510707647
[Epoch 17, Batch 200] loss: 0.011117106059456318
[Epoch 17, Batch 300] loss: 0.021892231842175532
[Epoch 17, Batch 400] loss: 0.024313303691342297
**STATS for Epoch 17** : 
Average training loss: 0.0020
Average validation loss: 0.0752
Validation Accuracy: 0.9845
Overfitting: 0.0732
[Epoch 18, Batch 100] loss: 0.007926164138398235
[Epoch 18, Batch 200] loss: 0.014105326557328227
[Epoch 18, Batch 300] loss: 0.010482211151256707
[Epoch 18, Batch 400] loss: 0.006202100721948227
**STATS for Epoch 18** : 
Average training loss: 0.0024
Average validation loss: 0.0600
Validation Accuracy: 0.9872
Overfitting: 0.0576
[Epoch 19, Batch 100] loss: 0.009758678211892403
[Epoch 19, Batch 200] loss: 0.004604214561844629
[Epoch 19, Batch 300] loss: 0.0036460093784967283
[Epoch 19, Batch 400] loss: 0.006620353405796777
**STATS for Epoch 19** : 
Average training loss: 0.0014
Average validation loss: 0.0795
Validation Accuracy: 0.9866
Overfitting: 0.0782
[Epoch 20, Batch 100] loss: 0.008889985169587363
[Epoch 20, Batch 200] loss: 0.006767837686484199
[Epoch 20, Batch 300] loss: 0.0052885085880745916
[Epoch 20, Batch 400] loss: 0.006774102617719109
**STATS for Epoch 20** : 
Average training loss: 0.0018
Average validation loss: 0.0804
Validation Accuracy: 0.9857
Overfitting: 0.0786
[Epoch 21, Batch 100] loss: 0.009436887198196473
[Epoch 21, Batch 200] loss: 0.014053454353002053
[Epoch 21, Batch 300] loss: 0.008674700901749474
[Epoch 21, Batch 400] loss: 0.008825092831043548
**STATS for Epoch 21** : 
Average training loss: 0.0023
Average validation loss: 0.0732
Validation Accuracy: 0.9854
Overfitting: 0.0709
[Epoch 22, Batch 100] loss: 0.0016745091321854488
[Epoch 22, Batch 200] loss: 0.003013881622125609
[Epoch 22, Batch 300] loss: 0.009399143996895419
[Epoch 22, Batch 400] loss: 0.0036493294495892315
**STATS for Epoch 22** : 
Average training loss: 0.0015
Average validation loss: 0.0674
Validation Accuracy: 0.9872
Overfitting: 0.0659
[Epoch 23, Batch 100] loss: 0.009926248582345067
[Epoch 23, Batch 200] loss: 0.005694101163593359
[Epoch 23, Batch 300] loss: 0.00210238234153735
[Epoch 23, Batch 400] loss: 0.003450086159498369
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0672
Validation Accuracy: 0.9884
Overfitting: 0.0670
[Epoch 24, Batch 100] loss: 0.0034343244316509926
[Epoch 24, Batch 200] loss: 0.002796940757904309
[Epoch 24, Batch 300] loss: 0.0023611548519116353
[Epoch 24, Batch 400] loss: 0.0030154268561725316
**STATS for Epoch 24** : 
Average training loss: 0.0010
Average validation loss: 0.0907
Validation Accuracy: 0.9850
Overfitting: 0.0897
Fold 2 validation loss: 0.0907
Mean validation loss across all folds for Trial 19 is 0.0790 with trial config:  l1: 256, l2: 64, lr: 0.024286525795066936, batch_size: 64
[I 2024-11-22 00:25:41,907] Trial 18 finished with value: 0.07902740638496708 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.024286525795066936, 'batch_size': 64}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 20:
  l1: 256, l2: 64, lr: 0.0006552521072923581, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.302008147239685
[Epoch 1, Batch 200] loss: 2.293345584869385
[Epoch 1, Batch 300] loss: 2.283896417617798
[Epoch 1, Batch 400] loss: 2.2621197271347047
[Epoch 1, Batch 500] loss: 2.2225748229026796
[Epoch 1, Batch 600] loss: 2.102192124128342
[Epoch 1, Batch 700] loss: 1.6314502024650575
[Epoch 1, Batch 800] loss: 0.8691552546620369
[Epoch 1, Batch 900] loss: 0.5953162381052971
**STATS for Epoch 1** : 
Average training loss: 0.0217
Average validation loss: 0.4793
Validation Accuracy: 0.8629
Overfitting: 0.4576
Best model saved at epoch 1 with validation loss: 0.4793
[Epoch 2, Batch 100] loss: 0.45846242040395735
[Epoch 2, Batch 200] loss: 0.4212645466625691
[Epoch 2, Batch 300] loss: 0.3848137854784727
[Epoch 2, Batch 400] loss: 0.31596755117177966
[Epoch 2, Batch 500] loss: 0.3024251271039248
[Epoch 2, Batch 600] loss: 0.2941117982566357
[Epoch 2, Batch 700] loss: 0.2778524073958397
[Epoch 2, Batch 800] loss: 0.26974128108471634
[Epoch 2, Batch 900] loss: 0.21541135739535094
**STATS for Epoch 2** : 
Average training loss: 0.0096
Average validation loss: 0.2153
Validation Accuracy: 0.9351
Overfitting: 0.2057
Best model saved at epoch 2 with validation loss: 0.2153
[Epoch 3, Batch 100] loss: 0.22385981798171997
[Epoch 3, Batch 200] loss: 0.2197098627127707
[Epoch 3, Batch 300] loss: 0.18450914483517408
[Epoch 3, Batch 400] loss: 0.21365611769258977
[Epoch 3, Batch 500] loss: 0.17376649843528866
[Epoch 3, Batch 600] loss: 0.17110888477414846
[Epoch 3, Batch 700] loss: 0.18440102122724056
[Epoch 3, Batch 800] loss: 0.16763571389019488
[Epoch 3, Batch 900] loss: 0.16545784637331962
**STATS for Epoch 3** : 
Average training loss: 0.0058
Average validation loss: 0.1614
Validation Accuracy: 0.9529
Overfitting: 0.1556
Best model saved at epoch 3 with validation loss: 0.1614
[Epoch 4, Batch 100] loss: 0.14048003137111664
[Epoch 4, Batch 200] loss: 0.14704909890890122
[Epoch 4, Batch 300] loss: 0.13703796899877488
[Epoch 4, Batch 400] loss: 0.14993838645517826
[Epoch 4, Batch 500] loss: 0.13829631129279732
[Epoch 4, Batch 600] loss: 0.1315462628379464
[Epoch 4, Batch 700] loss: 0.13455479562282563
[Epoch 4, Batch 800] loss: 0.1202246148698032
[Epoch 4, Batch 900] loss: 0.11702999133616686
**STATS for Epoch 4** : 
Average training loss: 0.0051
Average validation loss: 0.1219
Validation Accuracy: 0.9630
Overfitting: 0.1168
Best model saved at epoch 4 with validation loss: 0.1219
[Epoch 5, Batch 100] loss: 0.10542383172549308
[Epoch 5, Batch 200] loss: 0.11286015367601067
[Epoch 5, Batch 300] loss: 0.1108329559257254
[Epoch 5, Batch 400] loss: 0.09940974538214505
[Epoch 5, Batch 500] loss: 0.11460962011478841
[Epoch 5, Batch 600] loss: 0.13140541456174104
[Epoch 5, Batch 700] loss: 0.10633901605382562
[Epoch 5, Batch 800] loss: 0.10510559945367276
[Epoch 5, Batch 900] loss: 0.09427612639032304
**STATS for Epoch 5** : 
Average training loss: 0.0038
Average validation loss: 0.1041
Validation Accuracy: 0.9682
Overfitting: 0.1003
Best model saved at epoch 5 with validation loss: 0.1041
[Epoch 6, Batch 100] loss: 0.09497538278345019
[Epoch 6, Batch 200] loss: 0.09236221862956881
[Epoch 6, Batch 300] loss: 0.0947819017386064
[Epoch 6, Batch 400] loss: 0.1036331417830661
[Epoch 6, Batch 500] loss: 0.08688569362740964
[Epoch 6, Batch 600] loss: 0.08279970498755575
[Epoch 6, Batch 700] loss: 0.08864322987152264
[Epoch 6, Batch 800] loss: 0.10708966645412148
[Epoch 6, Batch 900] loss: 0.08631197365932167
**STATS for Epoch 6** : 
Average training loss: 0.0031
Average validation loss: 0.0987
Validation Accuracy: 0.9684
Overfitting: 0.0956
[I 2024-11-22 00:26:58,850] Trial 19 pruned. 

Selected Hyperparameters for Trial 21:
  l1: 128, l2: 128, lr: 0.0001422055773698847, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.307727944850922
[Epoch 1, Batch 200] loss: 2.3065584087371827
[Epoch 1, Batch 300] loss: 2.3035455894470216
[Epoch 1, Batch 400] loss: 2.302376837730408
[Epoch 1, Batch 500] loss: 2.2985556888580323
[Epoch 1, Batch 600] loss: 2.296725251674652
[Epoch 1, Batch 700] loss: 2.2942455863952635
[Epoch 1, Batch 800] loss: 2.29224440574646
[Epoch 1, Batch 900] loss: 2.2882212090492247
**STATS for Epoch 1** : 
Average training loss: 0.0927
Average validation loss: 2.2865
Validation Accuracy: 0.1053
Overfitting: 2.1938
Best model saved at epoch 1 with validation loss: 2.2865
[Epoch 2, Batch 100] loss: 2.286028423309326
[Epoch 2, Batch 200] loss: 2.281841003894806
[Epoch 2, Batch 300] loss: 2.278326518535614
[Epoch 2, Batch 400] loss: 2.273029987812042
[Epoch 2, Batch 500] loss: 2.2700095272064207
[Epoch 2, Batch 600] loss: 2.2629218173027037
[Epoch 2, Batch 700] loss: 2.257748508453369
[Epoch 2, Batch 800] loss: 2.2496128511428832
[Epoch 2, Batch 900] loss: 2.239981460571289
**STATS for Epoch 2** : 
Average training loss: 0.0906
Average validation loss: 2.2306
Validation Accuracy: 0.3030
Overfitting: 2.1399
Best model saved at epoch 2 with validation loss: 2.2306
[Epoch 3, Batch 100] loss: 2.2226680445671083
[Epoch 3, Batch 200] loss: 2.2059845304489136
[Epoch 3, Batch 300] loss: 2.1823761820793153
[Epoch 3, Batch 400] loss: 2.151941766738892
[Epoch 3, Batch 500] loss: 2.120353126525879
[Epoch 3, Batch 600] loss: 2.0630683314800264
[Epoch 3, Batch 700] loss: 1.9783553767204285
[Epoch 3, Batch 800] loss: 1.8511657285690308
[Epoch 3, Batch 900] loss: 1.6810844600200654
**STATS for Epoch 3** : 
Average training loss: 0.0632
Average validation loss: 1.5123
Validation Accuracy: 0.6920
Overfitting: 1.4491
Best model saved at epoch 3 with validation loss: 1.5123
[Epoch 4, Batch 100] loss: 1.4054216313362122
[Epoch 4, Batch 200] loss: 1.1920788019895554
[Epoch 4, Batch 300] loss: 1.018505139350891
[Epoch 4, Batch 400] loss: 0.8896635228395462
[Epoch 4, Batch 500] loss: 0.8393005114793778
[Epoch 4, Batch 600] loss: 0.7447813600301743
[Epoch 4, Batch 700] loss: 0.6749493607878685
[Epoch 4, Batch 800] loss: 0.6077686697244644
[Epoch 4, Batch 900] loss: 0.5629901486635208
**STATS for Epoch 4** : 
Average training loss: 0.0234
Average validation loss: 0.5596
Validation Accuracy: 0.8346
Overfitting: 0.5362
Best model saved at epoch 4 with validation loss: 0.5596
[Epoch 5, Batch 100] loss: 0.542554073035717
[Epoch 5, Batch 200] loss: 0.5173341292142868
[Epoch 5, Batch 300] loss: 0.46100533500313756
[Epoch 5, Batch 400] loss: 0.49728405803442
[Epoch 5, Batch 500] loss: 0.4647666649520397
[Epoch 5, Batch 600] loss: 0.46516080632805823
[Epoch 5, Batch 700] loss: 0.4318365354835987
[Epoch 5, Batch 800] loss: 0.4308830714225769
[Epoch 5, Batch 900] loss: 0.4255546133965254
**STATS for Epoch 5** : 
Average training loss: 0.0157
Average validation loss: 0.4170
Validation Accuracy: 0.8744
Overfitting: 0.4013
Best model saved at epoch 5 with validation loss: 0.4170
[Epoch 6, Batch 100] loss: 0.40829426147043707
[Epoch 6, Batch 200] loss: 0.3844936026632786
[Epoch 6, Batch 300] loss: 0.3822904361784458
[Epoch 6, Batch 400] loss: 0.36878994897007944
[Epoch 6, Batch 500] loss: 0.35418946981430055
[Epoch 6, Batch 600] loss: 0.34166416473686695
[Epoch 6, Batch 700] loss: 0.3706895912438631
[Epoch 6, Batch 800] loss: 0.35561957478523254
[Epoch 6, Batch 900] loss: 0.3650647957623005
**STATS for Epoch 6** : 
Average training loss: 0.0142
Average validation loss: 0.3381
Validation Accuracy: 0.8997
Overfitting: 0.3238
[I 2024-11-22 00:28:15,481] Trial 20 pruned. 

Selected Hyperparameters for Trial 22:
  l1: 256, l2: 64, lr: 0.003550717188012259, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2546332454681397
[Epoch 1, Batch 200] loss: 0.9958856934309006
**STATS for Epoch 1** : 
Average training loss: 0.0613
Average validation loss: 0.3768
Validation Accuracy: 0.8873
Overfitting: 0.3155
Best model saved at epoch 1 with validation loss: 0.3768
[Epoch 2, Batch 100] loss: 0.30624838203191757
[Epoch 2, Batch 200] loss: 0.2508437106758356
**STATS for Epoch 2** : 
Average training loss: 0.0310
Average validation loss: 0.1914
Validation Accuracy: 0.9403
Overfitting: 0.1604
Best model saved at epoch 2 with validation loss: 0.1914
[Epoch 3, Batch 100] loss: 0.1773843264579773
[Epoch 3, Batch 200] loss: 0.1482835017517209
**STATS for Epoch 3** : 
Average training loss: 0.0205
Average validation loss: 0.1618
Validation Accuracy: 0.9516
Overfitting: 0.1412
Best model saved at epoch 3 with validation loss: 0.1618
[Epoch 4, Batch 100] loss: 0.12281284883618354
[Epoch 4, Batch 200] loss: 0.11206775076687336
**STATS for Epoch 4** : 
Average training loss: 0.0151
Average validation loss: 0.1119
Validation Accuracy: 0.9644
Overfitting: 0.0968
Best model saved at epoch 4 with validation loss: 0.1119
[Epoch 5, Batch 100] loss: 0.09331726517528295
[Epoch 5, Batch 200] loss: 0.09035494642332197
**STATS for Epoch 5** : 
Average training loss: 0.0145
Average validation loss: 0.0984
Validation Accuracy: 0.9686
Overfitting: 0.0839
Best model saved at epoch 5 with validation loss: 0.0984
[Epoch 6, Batch 100] loss: 0.0857761369086802
[Epoch 6, Batch 200] loss: 0.07976044164970517
**STATS for Epoch 6** : 
Average training loss: 0.0101
Average validation loss: 0.0858
Validation Accuracy: 0.9736
Overfitting: 0.0757
[I 2024-11-22 00:29:20,420] Trial 21 pruned. 

Selected Hyperparameters for Trial 23:
  l1: 128, l2: 64, lr: 0.03827235612723595, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.0335085189342499
[Epoch 1, Batch 200] loss: 0.15957554705441
**STATS for Epoch 1** : 
Average training loss: 0.0201
Average validation loss: 0.1543
Validation Accuracy: 0.9520
Overfitting: 0.1342
Best model saved at epoch 1 with validation loss: 0.1543
[Epoch 2, Batch 100] loss: 0.09901248385198415
[Epoch 2, Batch 200] loss: 0.09050289602950215
**STATS for Epoch 2** : 
Average training loss: 0.0130
Average validation loss: 0.1099
Validation Accuracy: 0.9668
Overfitting: 0.0969
Best model saved at epoch 2 with validation loss: 0.1099
[Epoch 3, Batch 100] loss: 0.06650046422146261
[Epoch 3, Batch 200] loss: 0.07092333449982106
**STATS for Epoch 3** : 
Average training loss: 0.0093
Average validation loss: 0.0784
Validation Accuracy: 0.9763
Overfitting: 0.0691
Best model saved at epoch 3 with validation loss: 0.0784
[Epoch 4, Batch 100] loss: 0.04257004075450823
[Epoch 4, Batch 200] loss: 0.054403217351064084
**STATS for Epoch 4** : 
Average training loss: 0.0071
Average validation loss: 0.0757
Validation Accuracy: 0.9792
Overfitting: 0.0686
Best model saved at epoch 4 with validation loss: 0.0757
[Epoch 5, Batch 100] loss: 0.03780284668551758
[Epoch 5, Batch 200] loss: 0.04268675216007978
**STATS for Epoch 5** : 
Average training loss: 0.0070
Average validation loss: 0.0644
Validation Accuracy: 0.9808
Overfitting: 0.0574
Best model saved at epoch 5 with validation loss: 0.0644
[Epoch 6, Batch 100] loss: 0.029342478229664265
[Epoch 6, Batch 200] loss: 0.032522654922795484
**STATS for Epoch 6** : 
Average training loss: 0.0048
Average validation loss: 0.0700
Validation Accuracy: 0.9808
Overfitting: 0.0652
[Epoch 7, Batch 100] loss: 0.030503187632421033
[Epoch 7, Batch 200] loss: 0.03583473060047254
**STATS for Epoch 7** : 
Average training loss: 0.0051
Average validation loss: 0.0687
Validation Accuracy: 0.9816
Overfitting: 0.0635
[Epoch 8, Batch 100] loss: 0.026418662559299266
[Epoch 8, Batch 200] loss: 0.026496170229511336
**STATS for Epoch 8** : 
Average training loss: 0.0038
Average validation loss: 0.0635
Validation Accuracy: 0.9841
Overfitting: 0.0597
Best model saved at epoch 8 with validation loss: 0.0635
[Epoch 9, Batch 100] loss: 0.02147980256762821
[Epoch 9, Batch 200] loss: 0.020170371489075477
**STATS for Epoch 9** : 
Average training loss: 0.0046
Average validation loss: 0.0735
Validation Accuracy: 0.9817
Overfitting: 0.0689
[Epoch 10, Batch 100] loss: 0.018591954509320205
[Epoch 10, Batch 200] loss: 0.02024759490712313
**STATS for Epoch 10** : 
Average training loss: 0.0025
Average validation loss: 0.0642
Validation Accuracy: 0.9846
Overfitting: 0.0617
[Epoch 11, Batch 100] loss: 0.016887265278492124
[Epoch 11, Batch 200] loss: 0.01870934902864974
**STATS for Epoch 11** : 
Average training loss: 0.0020
Average validation loss: 0.0737
Validation Accuracy: 0.9831
Overfitting: 0.0717
[Epoch 12, Batch 100] loss: 0.011919197378156242
[Epoch 12, Batch 200] loss: 0.014909102867968614
**STATS for Epoch 12** : 
Average training loss: 0.0028
Average validation loss: 0.0758
Validation Accuracy: 0.9825
Overfitting: 0.0730
[Epoch 13, Batch 100] loss: 0.014054902815405512
[Epoch 13, Batch 200] loss: 0.01761628270643996
**STATS for Epoch 13** : 
Average training loss: 0.0031
Average validation loss: 0.0756
Validation Accuracy: 0.9831
Overfitting: 0.0725
[Epoch 14, Batch 100] loss: 0.01007126103821065
[Epoch 14, Batch 200] loss: 0.01469354986329563
**STATS for Epoch 14** : 
Average training loss: 0.0020
Average validation loss: 0.0767
Validation Accuracy: 0.9845
Overfitting: 0.0747
[Epoch 15, Batch 100] loss: 0.010344188087619841
[Epoch 15, Batch 200] loss: 0.010038584563008044
**STATS for Epoch 15** : 
Average training loss: 0.0019
Average validation loss: 0.0873
Validation Accuracy: 0.9823
Overfitting: 0.0854
[Epoch 16, Batch 100] loss: 0.012744511411874555
[Epoch 16, Batch 200] loss: 0.011352288280177163
**STATS for Epoch 16** : 
Average training loss: 0.0025
Average validation loss: 0.0767
Validation Accuracy: 0.9836
Overfitting: 0.0743
[Epoch 17, Batch 100] loss: 0.009026319113909267
[Epoch 17, Batch 200] loss: 0.008539099778718083
**STATS for Epoch 17** : 
Average training loss: 0.0038
Average validation loss: 0.0956
Validation Accuracy: 0.9818
Overfitting: 0.0919
[Epoch 18, Batch 100] loss: 0.016753860697608616
[Epoch 18, Batch 200] loss: 0.015843048902097506
**STATS for Epoch 18** : 
Average training loss: 0.0026
Average validation loss: 0.1088
Validation Accuracy: 0.9771
Overfitting: 0.1062
[Epoch 19, Batch 100] loss: 0.015051779950626952
[Epoch 19, Batch 200] loss: 0.008425677854829701
**STATS for Epoch 19** : 
Average training loss: 0.0018
Average validation loss: 0.1011
Validation Accuracy: 0.9819
Overfitting: 0.0993
[Epoch 20, Batch 100] loss: 0.015180982531746849
[Epoch 20, Batch 200] loss: 0.009111981848036521
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0743
Validation Accuracy: 0.9859
Overfitting: 0.0733
[Epoch 21, Batch 100] loss: 0.004625577026235988
[Epoch 21, Batch 200] loss: 0.0035779243014985697
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0816
Validation Accuracy: 0.9857
Overfitting: 0.0813
[Epoch 22, Batch 100] loss: 0.002418649221360738
[Epoch 22, Batch 200] loss: 0.004914004026986731
**STATS for Epoch 22** : 
Average training loss: 0.0021
Average validation loss: 0.0894
Validation Accuracy: 0.9839
Overfitting: 0.0873
[Epoch 23, Batch 100] loss: 0.004388328125451153
[Epoch 23, Batch 200] loss: 0.002499573750565105
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0767
Validation Accuracy: 0.9867
Overfitting: 0.0763
[Epoch 24, Batch 100] loss: 0.004359108139688032
[Epoch 24, Batch 200] loss: 0.00167533360861853
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0887
Validation Accuracy: 0.9868
Overfitting: 0.0886
Fold 1 validation loss: 0.0887
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 0.9453996780514717
[Epoch 1, Batch 200] loss: 0.14806943152099847
**STATS for Epoch 1** : 
Average training loss: 0.0148
Average validation loss: 0.1189
Validation Accuracy: 0.9633
Overfitting: 0.1041
Best model saved at epoch 1 with validation loss: 0.1189
[Epoch 2, Batch 100] loss: 0.09248265033587813
[Epoch 2, Batch 200] loss: 0.08424774911254644
**STATS for Epoch 2** : 
Average training loss: 0.0130
Average validation loss: 0.1114
Validation Accuracy: 0.9653
Overfitting: 0.0983
Best model saved at epoch 2 with validation loss: 0.1114
[Epoch 3, Batch 100] loss: 0.0573934685671702
[Epoch 3, Batch 200] loss: 0.063181994240731
**STATS for Epoch 3** : 
Average training loss: 0.0085
Average validation loss: 0.0647
Validation Accuracy: 0.9801
Overfitting: 0.0561
Best model saved at epoch 3 with validation loss: 0.0647
[Epoch 4, Batch 100] loss: 0.04452750709373504
[Epoch 4, Batch 200] loss: 0.047052459500264376
**STATS for Epoch 4** : 
Average training loss: 0.0080
Average validation loss: 0.0641
Validation Accuracy: 0.9822
Overfitting: 0.0560
Best model saved at epoch 4 with validation loss: 0.0641
[Epoch 5, Batch 100] loss: 0.034649789209943264
[Epoch 5, Batch 200] loss: 0.03902457169955596
**STATS for Epoch 5** : 
Average training loss: 0.0047
Average validation loss: 0.0575
Validation Accuracy: 0.9847
Overfitting: 0.0528
Best model saved at epoch 5 with validation loss: 0.0575
[Epoch 6, Batch 100] loss: 0.025910128720570354
[Epoch 6, Batch 200] loss: 0.036541892262175676
**STATS for Epoch 6** : 
Average training loss: 0.0049
Average validation loss: 0.0560
Validation Accuracy: 0.9857
Overfitting: 0.0511
Best model saved at epoch 6 with validation loss: 0.0560
[Epoch 7, Batch 100] loss: 0.028837468007113783
[Epoch 7, Batch 200] loss: 0.030088292041327805
**STATS for Epoch 7** : 
Average training loss: 0.0032
Average validation loss: 0.0476
Validation Accuracy: 0.9874
Overfitting: 0.0444
Best model saved at epoch 7 with validation loss: 0.0476
[Epoch 8, Batch 100] loss: 0.02498321059101727
[Epoch 8, Batch 200] loss: 0.02834629961056635
**STATS for Epoch 8** : 
Average training loss: 0.0042
Average validation loss: 0.0493
Validation Accuracy: 0.9871
Overfitting: 0.0450
[Epoch 9, Batch 100] loss: 0.020579184345551768
[Epoch 9, Batch 200] loss: 0.018632490525924368
**STATS for Epoch 9** : 
Average training loss: 0.0043
Average validation loss: 0.0552
Validation Accuracy: 0.9858
Overfitting: 0.0509
[Epoch 10, Batch 100] loss: 0.016639804387523327
[Epoch 10, Batch 200] loss: 0.020322240319801496
**STATS for Epoch 10** : 
Average training loss: 0.0028
Average validation loss: 0.0576
Validation Accuracy: 0.9858
Overfitting: 0.0548
[Epoch 11, Batch 100] loss: 0.01173978558712406
[Epoch 11, Batch 200] loss: 0.010629477586990106
**STATS for Epoch 11** : 
Average training loss: 0.0026
Average validation loss: 0.0711
Validation Accuracy: 0.9840
Overfitting: 0.0685
[Epoch 12, Batch 100] loss: 0.013718445911072194
[Epoch 12, Batch 200] loss: 0.016699879996012898
**STATS for Epoch 12** : 
Average training loss: 0.0021
Average validation loss: 0.0648
Validation Accuracy: 0.9854
Overfitting: 0.0627
[Epoch 13, Batch 100] loss: 0.024138467934681104
[Epoch 13, Batch 200] loss: 0.020116467324260156
**STATS for Epoch 13** : 
Average training loss: 0.0024
Average validation loss: 0.0604
Validation Accuracy: 0.9865
Overfitting: 0.0580
[Epoch 14, Batch 100] loss: 0.012229627650376641
[Epoch 14, Batch 200] loss: 0.011726444952655584
**STATS for Epoch 14** : 
Average training loss: 0.0023
Average validation loss: 0.0644
Validation Accuracy: 0.9857
Overfitting: 0.0621
[Epoch 15, Batch 100] loss: 0.01021267038096994
[Epoch 15, Batch 200] loss: 0.01226314435749373
**STATS for Epoch 15** : 
Average training loss: 0.0026
Average validation loss: 0.0981
Validation Accuracy: 0.9805
Overfitting: 0.0955
[Epoch 16, Batch 100] loss: 0.00961633546576195
[Epoch 16, Batch 200] loss: 0.01335124978366366
**STATS for Epoch 16** : 
Average training loss: 0.0020
Average validation loss: 0.0632
Validation Accuracy: 0.9854
Overfitting: 0.0612
[Epoch 17, Batch 100] loss: 0.00418408223795268
[Epoch 17, Batch 200] loss: 0.008814857418328756
**STATS for Epoch 17** : 
Average training loss: 0.0016
Average validation loss: 0.0640
Validation Accuracy: 0.9867
Overfitting: 0.0624
[Epoch 18, Batch 100] loss: 0.0038765286366106012
[Epoch 18, Batch 200] loss: 0.0035905626257044785
**STATS for Epoch 18** : 
Average training loss: 0.0014
Average validation loss: 0.0799
Validation Accuracy: 0.9851
Overfitting: 0.0785
[Epoch 19, Batch 100] loss: 0.006337310346243612
[Epoch 19, Batch 200] loss: 0.009286488915604423
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0672
Validation Accuracy: 0.9872
Overfitting: 0.0666
[Epoch 20, Batch 100] loss: 0.00512635991195566
[Epoch 20, Batch 200] loss: 0.002734696911174979
**STATS for Epoch 20** : 
Average training loss: 0.0009
Average validation loss: 0.0825
Validation Accuracy: 0.9852
Overfitting: 0.0816
[Epoch 21, Batch 100] loss: 0.007297821079655478
[Epoch 21, Batch 200] loss: 0.006479939149003257
**STATS for Epoch 21** : 
Average training loss: 0.0012
Average validation loss: 0.0685
Validation Accuracy: 0.9870
Overfitting: 0.0674
[Epoch 22, Batch 100] loss: 0.003250387914822568
[Epoch 22, Batch 200] loss: 0.001201843408834975
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0701
Validation Accuracy: 0.9887
Overfitting: 0.0698
[Epoch 23, Batch 100] loss: 0.006043274861704049
[Epoch 23, Batch 200] loss: 0.007186512897851572
**STATS for Epoch 23** : 
Average training loss: 0.0020
Average validation loss: 0.0822
Validation Accuracy: 0.9853
Overfitting: 0.0802
[Epoch 24, Batch 100] loss: 0.011120922664449608
[Epoch 24, Batch 200] loss: 0.008732610231963917
**STATS for Epoch 24** : 
Average training loss: 0.0018
Average validation loss: 0.0735
Validation Accuracy: 0.9868
Overfitting: 0.0717
Fold 2 validation loss: 0.0735
Mean validation loss across all folds for Trial 23 is 0.0811 with trial config:  l1: 128, l2: 64, lr: 0.03827235612723595, batch_size: 128
[I 2024-11-22 00:38:15,211] Trial 22 finished with value: 0.08109275678509142 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.03827235612723595, 'batch_size': 128}. Best is trial 2 with value: 0.0616292772171084.

Selected Hyperparameters for Trial 24:
  l1: 256, l2: 64, lr: 0.07279297858004308, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 0.9219843852519989
[Epoch 1, Batch 200] loss: 0.14583753060549498
**STATS for Epoch 1** : 
Average training loss: 0.0191
Average validation loss: 0.1257
Validation Accuracy: 0.9647
Overfitting: 0.1066
Best model saved at epoch 1 with validation loss: 0.1257
[Epoch 2, Batch 100] loss: 0.09562090581282973
[Epoch 2, Batch 200] loss: 0.09588965971022845
**STATS for Epoch 2** : 
Average training loss: 0.0142
Average validation loss: 0.0895
Validation Accuracy: 0.9747
Overfitting: 0.0753
Best model saved at epoch 2 with validation loss: 0.0895
[Epoch 3, Batch 100] loss: 0.06761977861635388
[Epoch 3, Batch 200] loss: 0.05629872084595263
**STATS for Epoch 3** : 
Average training loss: 0.0083
Average validation loss: 0.0655
Validation Accuracy: 0.9830
Overfitting: 0.0572
Best model saved at epoch 3 with validation loss: 0.0655
[Epoch 4, Batch 100] loss: 0.042428424515528605
[Epoch 4, Batch 200] loss: 0.056024018642492596
**STATS for Epoch 4** : 
Average training loss: 0.0081
Average validation loss: 0.0634
Validation Accuracy: 0.9831
Overfitting: 0.0552
Best model saved at epoch 4 with validation loss: 0.0634
[Epoch 5, Batch 100] loss: 0.03468164582271129
[Epoch 5, Batch 200] loss: 0.043155530944932255
**STATS for Epoch 5** : 
Average training loss: 0.0058
Average validation loss: 0.0881
Validation Accuracy: 0.9752
Overfitting: 0.0822
[Epoch 6, Batch 100] loss: 0.03796494809444994
[Epoch 6, Batch 200] loss: 0.036429225633619354
**STATS for Epoch 6** : 
Average training loss: 0.0070
Average validation loss: 0.0891
Validation Accuracy: 0.9782
Overfitting: 0.0821
[Epoch 7, Batch 100] loss: 0.039413174469955264
[Epoch 7, Batch 200] loss: 0.04090872343746014
**STATS for Epoch 7** : 
Average training loss: 0.0056
Average validation loss: 0.0914
Validation Accuracy: 0.9764
Overfitting: 0.0857
[Epoch 8, Batch 100] loss: 0.032956033367663624
[Epoch 8, Batch 200] loss: 0.03059548006800469
**STATS for Epoch 8** : 
Average training loss: 0.0049
Average validation loss: 0.0703
Validation Accuracy: 0.9834
Overfitting: 0.0655
[Epoch 9, Batch 100] loss: 0.022867903864243998
[Epoch 9, Batch 200] loss: 0.020921755837334785
**STATS for Epoch 9** : 
Average training loss: 0.0046
Average validation loss: 0.0667
Validation Accuracy: 0.9840
Overfitting: 0.0622
[Epoch 10, Batch 100] loss: 0.01882812508440111
[Epoch 10, Batch 200] loss: 0.016524892949528292
**STATS for Epoch 10** : 
Average training loss: 0.0036
Average validation loss: 0.0831
Validation Accuracy: 0.9829
Overfitting: 0.0795
[Epoch 11, Batch 100] loss: 0.020455987141676815
[Epoch 11, Batch 200] loss: 0.03672911723828293
**STATS for Epoch 11** : 
Average training loss: 0.0041
Average validation loss: 0.0747
Validation Accuracy: 0.9824
Overfitting: 0.0707
[Epoch 12, Batch 100] loss: 0.019261311418085826
[Epoch 12, Batch 200] loss: 0.019874265026301144
**STATS for Epoch 12** : 
Average training loss: 0.0034
Average validation loss: 0.0703
Validation Accuracy: 0.9858
Overfitting: 0.0669
[Epoch 13, Batch 100] loss: 0.01651133770337765
[Epoch 13, Batch 200] loss: 0.015434139254284673
**STATS for Epoch 13** : 
Average training loss: 0.0019
Average validation loss: 0.0666
Validation Accuracy: 0.9871
Overfitting: 0.0647
[Epoch 14, Batch 100] loss: 0.015549015246215277
[Epoch 14, Batch 200] loss: 0.016073493472358678
**STATS for Epoch 14** : 
Average training loss: 0.0026
Average validation loss: 0.0791
Validation Accuracy: 0.9845
Overfitting: 0.0765
[Epoch 15, Batch 100] loss: 0.014526380261577288
[Epoch 15, Batch 200] loss: 0.027158703762688675
**STATS for Epoch 15** : 
Average training loss: 0.0028
Average validation loss: 0.0772
Validation Accuracy: 0.9841
Overfitting: 0.0744
[Epoch 16, Batch 100] loss: 0.02327955859072972
[Epoch 16, Batch 200] loss: 0.01440658844752761
**STATS for Epoch 16** : 
Average training loss: 0.0035
Average validation loss: 0.0809
Validation Accuracy: 0.9831
Overfitting: 0.0774
[Epoch 17, Batch 100] loss: 0.017350398133276032
[Epoch 17, Batch 200] loss: 0.021457334578481094
**STATS for Epoch 17** : 
Average training loss: 0.0049
Average validation loss: 0.1035
Validation Accuracy: 0.9815
Overfitting: 0.0986
[Epoch 18, Batch 100] loss: 0.0181752472876542
[Epoch 18, Batch 200] loss: 0.014458263254637132
**STATS for Epoch 18** : 
Average training loss: 0.0011
Average validation loss: 0.0875
Validation Accuracy: 0.9846
Overfitting: 0.0864
[Epoch 19, Batch 100] loss: 0.01027227933253016
[Epoch 19, Batch 200] loss: 0.014123724374921948
**STATS for Epoch 19** : 
Average training loss: 0.0036
Average validation loss: 0.0915
Validation Accuracy: 0.9827
Overfitting: 0.0878
[Epoch 20, Batch 100] loss: 0.015701225581142352
[Epoch 20, Batch 200] loss: 0.02019646784669021
**STATS for Epoch 20** : 
Average training loss: 0.0021
Average validation loss: 0.0770
Validation Accuracy: 0.9855
Overfitting: 0.0750
[Epoch 21, Batch 100] loss: 0.009941484933005996
[Epoch 21, Batch 200] loss: 0.019457875471598527
**STATS for Epoch 21** : 
Average training loss: 0.0025
Average validation loss: 0.0786
Validation Accuracy: 0.9841
Overfitting: 0.0761
[Epoch 22, Batch 100] loss: 0.010888200836634497
[Epoch 22, Batch 200] loss: 0.017762064268026734
**STATS for Epoch 22** : 
Average training loss: 0.0024
Average validation loss: 0.0859
Validation Accuracy: 0.9860
Overfitting: 0.0836
[Epoch 23, Batch 100] loss: 0.01710570993967849
[Epoch 23, Batch 200] loss: 0.0175686239101924
**STATS for Epoch 23** : 
Average training loss: 0.0020
Average validation loss: 0.0926
Validation Accuracy: 0.9832
Overfitting: 0.0906
[Epoch 24, Batch 100] loss: 0.010765403490258904
[Epoch 24, Batch 200] loss: 0.018640929765133478
**STATS for Epoch 24** : 
Average training loss: 0.0007
Average validation loss: 0.0869
Validation Accuracy: 0.9867
Overfitting: 0.0863
Fold 1 validation loss: 0.0869
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.0278900481015443
[Epoch 1, Batch 200] loss: 0.17877321207895874
**STATS for Epoch 1** : 
Average training loss: 0.0175
Average validation loss: 0.1344
Validation Accuracy: 0.9610
Overfitting: 0.1169
Best model saved at epoch 1 with validation loss: 0.1344
[Epoch 2, Batch 100] loss: 0.10812372349202633
[Epoch 2, Batch 200] loss: 0.09284508952870965
**STATS for Epoch 2** : 
Average training loss: 0.0147
Average validation loss: 0.0878
Validation Accuracy: 0.9741
Overfitting: 0.0731
Best model saved at epoch 2 with validation loss: 0.0878
[Epoch 3, Batch 100] loss: 0.06442111687734724
[Epoch 3, Batch 200] loss: 0.07202483513392507
**STATS for Epoch 3** : 
Average training loss: 0.0112
Average validation loss: 0.1119
Validation Accuracy: 0.9685
Overfitting: 0.1007
[Epoch 4, Batch 100] loss: 0.05829540097620338
[Epoch 4, Batch 200] loss: 0.05564652194036171
**STATS for Epoch 4** : 
Average training loss: 0.0113
Average validation loss: 0.0779
Validation Accuracy: 0.9798
Overfitting: 0.0666
Best model saved at epoch 4 with validation loss: 0.0779
[Epoch 5, Batch 100] loss: 0.04718457671348006
[Epoch 5, Batch 200] loss: 0.04979567207104992
**STATS for Epoch 5** : 
Average training loss: 0.0060
Average validation loss: 0.0617
Validation Accuracy: 0.9829
Overfitting: 0.0557
Best model saved at epoch 5 with validation loss: 0.0617
[Epoch 6, Batch 100] loss: 0.03530683472054079
[Epoch 6, Batch 200] loss: 0.040481414855457844
**STATS for Epoch 6** : 
Average training loss: 0.0073
Average validation loss: 0.0733
Validation Accuracy: 0.9811
Overfitting: 0.0660
[Epoch 7, Batch 100] loss: 0.031032282140804456
[Epoch 7, Batch 200] loss: 0.03623446838697419
**STATS for Epoch 7** : 
Average training loss: 0.0060
Average validation loss: 0.0738
Validation Accuracy: 0.9822
Overfitting: 0.0678
[Epoch 8, Batch 100] loss: 0.028316120869712903
[Epoch 8, Batch 200] loss: 0.030748006115318277
**STATS for Epoch 8** : 
Average training loss: 0.0049
Average validation loss: 0.0946
Validation Accuracy: 0.9773
Overfitting: 0.0898
[Epoch 9, Batch 100] loss: 0.030299433726468122
[Epoch 9, Batch 200] loss: 0.029626727014547213
**STATS for Epoch 9** : 
Average training loss: 0.0042
Average validation loss: 0.0700
Validation Accuracy: 0.9827
Overfitting: 0.0658
[Epoch 10, Batch 100] loss: 0.029359464979497717
[Epoch 10, Batch 200] loss: 0.033437796616162814
**STATS for Epoch 10** : 
Average training loss: 0.0031
Average validation loss: 0.0722
Validation Accuracy: 0.9850
Overfitting: 0.0690
[Epoch 11, Batch 100] loss: 0.02270866157574346
[Epoch 11, Batch 200] loss: 0.03150151468697004
**STATS for Epoch 11** : 
Average training loss: 0.0041
Average validation loss: 0.0690
Validation Accuracy: 0.9836
Overfitting: 0.0648
[Epoch 12, Batch 100] loss: 0.01712710445455741
[Epoch 12, Batch 200] loss: 0.024309786194353363
**STATS for Epoch 12** : 
Average training loss: 0.0032
Average validation loss: 0.0720
Validation Accuracy: 0.9846
Overfitting: 0.0688
[Epoch 13, Batch 100] loss: 0.01857124917762121
[Epoch 13, Batch 200] loss: 0.027842298118630423
**STATS for Epoch 13** : 
Average training loss: 0.0040
Average validation loss: 0.0892
Validation Accuracy: 0.9816
Overfitting: 0.0852
[Epoch 14, Batch 100] loss: 0.02103958713472821
[Epoch 14, Batch 200] loss: 0.01944083315305761
**STATS for Epoch 14** : 
Average training loss: 0.0021
Average validation loss: 0.0771
Validation Accuracy: 0.9840
Overfitting: 0.0750
[Epoch 15, Batch 100] loss: 0.019105032021398075
[Epoch 15, Batch 200] loss: 0.01581405309625552
**STATS for Epoch 15** : 
Average training loss: 0.0026
Average validation loss: 0.0912
Validation Accuracy: 0.9819
Overfitting: 0.0885
[Epoch 16, Batch 100] loss: 0.014545162424547016
[Epoch 16, Batch 200] loss: 0.02685826685614302
**STATS for Epoch 16** : 
Average training loss: 0.0031
Average validation loss: 0.0941
Validation Accuracy: 0.9817
Overfitting: 0.0910
[Epoch 17, Batch 100] loss: 0.022596539985242997
[Epoch 17, Batch 200] loss: 0.01815648144009174
**STATS for Epoch 17** : 
Average training loss: 0.0022
Average validation loss: 0.0983
Validation Accuracy: 0.9794
Overfitting: 0.0961
[Epoch 18, Batch 100] loss: 0.014266146597910846
[Epoch 18, Batch 200] loss: 0.018122388211922955
**STATS for Epoch 18** : 
Average training loss: 0.0036
Average validation loss: 0.0992
Validation Accuracy: 0.9824
Overfitting: 0.0955
[Epoch 19, Batch 100] loss: 0.018913711643526766
[Epoch 19, Batch 200] loss: 0.014104018149519107
**STATS for Epoch 19** : 
Average training loss: 0.0025
Average validation loss: 0.0813
Validation Accuracy: 0.9855
Overfitting: 0.0788
[Epoch 20, Batch 100] loss: 0.007342804158324725
[Epoch 20, Batch 200] loss: 0.004409580923399972
**STATS for Epoch 20** : 
Average training loss: 0.0029
Average validation loss: 0.1109
Validation Accuracy: 0.9823
Overfitting: 0.1080
[Epoch 21, Batch 100] loss: 0.026666316514847493
[Epoch 21, Batch 200] loss: 0.028897368079342414
**STATS for Epoch 21** : 
Average training loss: 0.0045
Average validation loss: 0.1236
Validation Accuracy: 0.9786
Overfitting: 0.1191
[Epoch 22, Batch 100] loss: 0.015993793437883142
[Epoch 22, Batch 200] loss: 0.021058760317391716
**STATS for Epoch 22** : 
Average training loss: 0.0035
Average validation loss: 0.1214
Validation Accuracy: 0.9815
Overfitting: 0.1179
[Epoch 23, Batch 100] loss: 0.016705615939063136
[Epoch 23, Batch 200] loss: 0.00952134754978033
**STATS for Epoch 23** : 
Average training loss: 0.0025
Average validation loss: 0.1058
Validation Accuracy: 0.9831
Overfitting: 0.1033
[Epoch 24, Batch 100] loss: 0.023015965859085556
[Epoch 24, Batch 200] loss: 0.02684955163136692
**STATS for Epoch 24** : 
Average training loss: 0.0053
Average validation loss: 0.1122
Validation Accuracy: 0.9812
Overfitting: 0.1069
Fold 2 validation loss: 0.1122
Mean validation loss across all folds for Trial 24 is 0.0996 with trial config:  l1: 256, l2: 64, lr: 0.07279297858004308, batch_size: 128
[I 2024-11-22 00:46:52,470] Trial 23 finished with value: 0.09956469652235218 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.07279297858004308, 'batch_size': 128}. Best is trial 2 with value: 0.0616292772171084.
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  9
  Number of complete trials:  15
Best hyperparameters found:
{'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16}
Best trial:
  Value:  0.0616292772171084
Loaded best model checkpoint from: best_checkpoint_trial_2/model.pth
Using best hyperparameters {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 2.301312370300293
[Epoch 1, Batch 200] loss: 2.287164525985718
[Epoch 1, Batch 300] loss: 2.2729778122901916
[Epoch 1, Batch 400] loss: 2.24452086687088
[Epoch 1, Batch 500] loss: 2.162892645597458
[Epoch 1, Batch 600] loss: 1.8612804305553436
[Epoch 1, Batch 700] loss: 1.0993528634309768
[Epoch 1, Batch 800] loss: 0.6933911189436912
[Epoch 1, Batch 900] loss: 0.5507035645842552
[Epoch 1, Batch 1000] loss: 0.489241319000721
[Epoch 1, Batch 1100] loss: 0.40850300550460816
[Epoch 1, Batch 1200] loss: 0.4171386194229126
[Epoch 1, Batch 1300] loss: 0.3882002280652523
[Epoch 1, Batch 1400] loss: 0.3358118009567261
[Epoch 1, Batch 1500] loss: 0.3414908127486706
[Epoch 1, Batch 1600] loss: 0.30062901102006434
[Epoch 1, Batch 1700] loss: 0.2669580369442701
[Epoch 1, Batch 1800] loss: 0.2577761637233198
[Epoch 1, Batch 1900] loss: 0.26826102532446383
[Epoch 1, Batch 2000] loss: 0.21418873546645045
[Epoch 1, Batch 2100] loss: 0.20400134842842818
[Epoch 1, Batch 2200] loss: 0.2310549881029874
[Epoch 1, Batch 2300] loss: 0.21956694721244274
[Epoch 1, Batch 2400] loss: 0.1927305217832327
[Epoch 1, Batch 2500] loss: 0.19790527273900807
[Epoch 1, Batch 2600] loss: 0.17903024794533848
[Epoch 1, Batch 2700] loss: 0.18142650972120464
[Epoch 1, Batch 2800] loss: 0.1920992934331298
[Epoch 1, Batch 2900] loss: 0.14019044455140828
[Epoch 1, Batch 3000] loss: 0.19950203728862106
[Epoch 1, Batch 3100] loss: 0.14810150322970003
[Epoch 1, Batch 3200] loss: 0.1622816753666848
[Epoch 1, Batch 3300] loss: 0.1403793473728001
[Epoch 1, Batch 3400] loss: 0.17246781651861964
[Epoch 1, Batch 3500] loss: 0.16167473963461818
[Epoch 1, Batch 3600] loss: 0.15393953677732497
[Epoch 1, Batch 3700] loss: 0.13229214664082975
**STATS for Epoch 1** : 
Average training loss: 0.0023
Best model saved at epoch 1 with training loss: 0.0023
[Epoch 2, Batch 100] loss: 0.12333635847549886
[Epoch 2, Batch 200] loss: 0.11963044371921569
[Epoch 2, Batch 300] loss: 0.09132100193295628
[Epoch 2, Batch 400] loss: 0.1420723736891523
[Epoch 2, Batch 500] loss: 0.1480838011414744
[Epoch 2, Batch 600] loss: 0.11213683918118476
[Epoch 2, Batch 700] loss: 0.14498174838721753
[Epoch 2, Batch 800] loss: 0.1275411324761808
[Epoch 2, Batch 900] loss: 0.1359898855048232
[Epoch 2, Batch 1000] loss: 0.124850934012793
[Epoch 2, Batch 1100] loss: 0.13610708116088063
[Epoch 2, Batch 1200] loss: 0.10872700406238436
[Epoch 2, Batch 1300] loss: 0.12982162569183855
[Epoch 2, Batch 1400] loss: 0.1416732373740524
[Epoch 2, Batch 1500] loss: 0.10510311757912859
[Epoch 2, Batch 1600] loss: 0.1164396649831906
[Epoch 2, Batch 1700] loss: 0.11062343057710677
[Epoch 2, Batch 1800] loss: 0.10246343322098256
[Epoch 2, Batch 1900] loss: 0.12412210415815934
[Epoch 2, Batch 2000] loss: 0.11579803800210357
[Epoch 2, Batch 2100] loss: 0.07883662151522003
[Epoch 2, Batch 2200] loss: 0.08789481884799898
[Epoch 2, Batch 2300] loss: 0.10858132829423994
[Epoch 2, Batch 2400] loss: 0.09626449448056519
[Epoch 2, Batch 2500] loss: 0.09563058376777916
[Epoch 2, Batch 2600] loss: 0.08330378910759464
[Epoch 2, Batch 2700] loss: 0.09470771245425567
[Epoch 2, Batch 2800] loss: 0.0940470988699235
[Epoch 2, Batch 2900] loss: 0.0959287531056907
[Epoch 2, Batch 3000] loss: 0.11493155415169895
[Epoch 2, Batch 3100] loss: 0.10711784595972858
[Epoch 2, Batch 3200] loss: 0.0881064439425245
[Epoch 2, Batch 3300] loss: 0.07667791315470822
[Epoch 2, Batch 3400] loss: 0.11389406009577215
[Epoch 2, Batch 3500] loss: 0.08415908809518441
[Epoch 2, Batch 3600] loss: 0.10151970834936946
[Epoch 2, Batch 3700] loss: 0.10782352345762775
**STATS for Epoch 2** : 
Average training loss: 0.0013
Best model saved at epoch 2 with training loss: 0.0013
[Epoch 3, Batch 100] loss: 0.07808714265236631
[Epoch 3, Batch 200] loss: 0.08610779967159032
[Epoch 3, Batch 300] loss: 0.09360967630462255
[Epoch 3, Batch 400] loss: 0.09467315483139828
[Epoch 3, Batch 500] loss: 0.08006970488233492
[Epoch 3, Batch 600] loss: 0.07292036100989208
[Epoch 3, Batch 700] loss: 0.08055096853990108
[Epoch 3, Batch 800] loss: 0.08541931058978662
[Epoch 3, Batch 900] loss: 0.06992740959802177
[Epoch 3, Batch 1000] loss: 0.12083902199985459
[Epoch 3, Batch 1100] loss: 0.08619945061858743
[Epoch 3, Batch 1200] loss: 0.08526227454247419
[Epoch 3, Batch 1300] loss: 0.09707010439829901
[Epoch 3, Batch 1400] loss: 0.06750605365494267
[Epoch 3, Batch 1500] loss: 0.08879748597508297
[Epoch 3, Batch 1600] loss: 0.06926660552970133
[Epoch 3, Batch 1700] loss: 0.08996906875516288
[Epoch 3, Batch 1800] loss: 0.07860753414104693
[Epoch 3, Batch 1900] loss: 0.065215789770009
[Epoch 3, Batch 2000] loss: 0.07666836739866995
[Epoch 3, Batch 2100] loss: 0.08595232604653574
[Epoch 3, Batch 2200] loss: 0.08461131582502275
[Epoch 3, Batch 2300] loss: 0.06903247971902601
[Epoch 3, Batch 2400] loss: 0.07721083509619348
[Epoch 3, Batch 2500] loss: 0.07381176255876198
[Epoch 3, Batch 2600] loss: 0.08866130051785148
[Epoch 3, Batch 2700] loss: 0.07749397345643956
[Epoch 3, Batch 2800] loss: 0.06685180345491971
[Epoch 3, Batch 2900] loss: 0.05976877066539601
[Epoch 3, Batch 3000] loss: 0.06356850074720569
[Epoch 3, Batch 3100] loss: 0.058850185371702536
[Epoch 3, Batch 3200] loss: 0.0796902477950789
[Epoch 3, Batch 3300] loss: 0.058681913907057605
[Epoch 3, Batch 3400] loss: 0.05547775870887563
[Epoch 3, Batch 3500] loss: 0.05454761766566662
[Epoch 3, Batch 3600] loss: 0.06834658909589052
[Epoch 3, Batch 3700] loss: 0.06441087872372009
**STATS for Epoch 3** : 
Average training loss: 0.0006
Best model saved at epoch 3 with training loss: 0.0006
[Epoch 4, Batch 100] loss: 0.061768577439361254
[Epoch 4, Batch 200] loss: 0.05578303124173544
[Epoch 4, Batch 300] loss: 0.06368842856842093
[Epoch 4, Batch 400] loss: 0.06626734769553877
[Epoch 4, Batch 500] loss: 0.046825186429778114
[Epoch 4, Batch 600] loss: 0.08524517165147699
[Epoch 4, Batch 700] loss: 0.05116370026371442
[Epoch 4, Batch 800] loss: 0.06411152827495244
[Epoch 4, Batch 900] loss: 0.0593718025094131
[Epoch 4, Batch 1000] loss: 0.06275311220204458
[Epoch 4, Batch 1100] loss: 0.05533125011468656
[Epoch 4, Batch 1200] loss: 0.08898761150310747
[Epoch 4, Batch 1300] loss: 0.06399686124641449
[Epoch 4, Batch 1400] loss: 0.07382733259466477
[Epoch 4, Batch 1500] loss: 0.060793315485934724
[Epoch 4, Batch 1600] loss: 0.04894975749775767
[Epoch 4, Batch 1700] loss: 0.04338638363056816
[Epoch 4, Batch 1800] loss: 0.06434511757513973
[Epoch 4, Batch 1900] loss: 0.06031859503942542
[Epoch 4, Batch 2000] loss: 0.06631297024257947
[Epoch 4, Batch 2100] loss: 0.05958576917182654
[Epoch 4, Batch 2200] loss: 0.06316671027278062
[Epoch 4, Batch 2300] loss: 0.0698016011377331
[Epoch 4, Batch 2400] loss: 0.04765926140680676
[Epoch 4, Batch 2500] loss: 0.04324108273547608
[Epoch 4, Batch 2600] loss: 0.06938479465286945
[Epoch 4, Batch 2700] loss: 0.04473921711003641
[Epoch 4, Batch 2800] loss: 0.05070742586656706
[Epoch 4, Batch 2900] loss: 0.06110527133452706
[Epoch 4, Batch 3000] loss: 0.0718299359761295
[Epoch 4, Batch 3100] loss: 0.06310451998695499
[Epoch 4, Batch 3200] loss: 0.06253272341069532
[Epoch 4, Batch 3300] loss: 0.05640867109643295
[Epoch 4, Batch 3400] loss: 0.09005664373078616
[Epoch 4, Batch 3500] loss: 0.06703074009536067
[Epoch 4, Batch 3600] loss: 0.057406997917569244
[Epoch 4, Batch 3700] loss: 0.051644988061743786
**STATS for Epoch 4** : 
Average training loss: 0.0007
[Epoch 5, Batch 100] loss: 0.04696961568493862
[Epoch 5, Batch 200] loss: 0.04608677954849554
[Epoch 5, Batch 300] loss: 0.04321798337681684
[Epoch 5, Batch 400] loss: 0.05903346647159197
[Epoch 5, Batch 500] loss: 0.04722577330627246
[Epoch 5, Batch 600] loss: 0.06585400622017915
[Epoch 5, Batch 700] loss: 0.053927988637587985
[Epoch 5, Batch 800] loss: 0.062104253713623624
[Epoch 5, Batch 900] loss: 0.04833498296269681
[Epoch 5, Batch 1000] loss: 0.06320472197025083
[Epoch 5, Batch 1100] loss: 0.06652709044632502
[Epoch 5, Batch 1200] loss: 0.05060034517548047
[Epoch 5, Batch 1300] loss: 0.05711246140068397
[Epoch 5, Batch 1400] loss: 0.06028746742755175
[Epoch 5, Batch 1500] loss: 0.046510558784357274
[Epoch 5, Batch 1600] loss: 0.03651759542699438
[Epoch 5, Batch 1700] loss: 0.04261156990833115
[Epoch 5, Batch 1800] loss: 0.03271369962894823
[Epoch 5, Batch 1900] loss: 0.0591787910219864
[Epoch 5, Batch 2000] loss: 0.04587779410925577
[Epoch 5, Batch 2100] loss: 0.039304737488055255
[Epoch 5, Batch 2200] loss: 0.03557051176860113
[Epoch 5, Batch 2300] loss: 0.05322295198406209
[Epoch 5, Batch 2400] loss: 0.0508126802611514
[Epoch 5, Batch 2500] loss: 0.050602034616167656
[Epoch 5, Batch 2600] loss: 0.05619176968029933
[Epoch 5, Batch 2700] loss: 0.04397166631038999
[Epoch 5, Batch 2800] loss: 0.050248249821161155
[Epoch 5, Batch 2900] loss: 0.048221376934379806
[Epoch 5, Batch 3000] loss: 0.04645595662746928
[Epoch 5, Batch 3100] loss: 0.04981878665974364
[Epoch 5, Batch 3200] loss: 0.07329139566863888
[Epoch 5, Batch 3300] loss: 0.051935165449394846
[Epoch 5, Batch 3400] loss: 0.045619062003097496
[Epoch 5, Batch 3500] loss: 0.03727860321188928
[Epoch 5, Batch 3600] loss: 0.06545994748536031
[Epoch 5, Batch 3700] loss: 0.048827229173912204
**STATS for Epoch 5** : 
Average training loss: 0.0007
[Epoch 6, Batch 100] loss: 0.03450903066637693
[Epoch 6, Batch 200] loss: 0.037857325974619015
[Epoch 6, Batch 300] loss: 0.05249425031535793
[Epoch 6, Batch 400] loss: 0.041959986976871734
[Epoch 6, Batch 500] loss: 0.03320240962639218
[Epoch 6, Batch 600] loss: 0.0317428536771331
[Epoch 6, Batch 700] loss: 0.04939172814338235
[Epoch 6, Batch 800] loss: 0.03762257557020348
[Epoch 6, Batch 900] loss: 0.05347309638425941
[Epoch 6, Batch 1000] loss: 0.044255148509691936
[Epoch 6, Batch 1100] loss: 0.03999284809920937
[Epoch 6, Batch 1200] loss: 0.04716257158812368
[Epoch 6, Batch 1300] loss: 0.048468580679182194
[Epoch 6, Batch 1400] loss: 0.04787194879783783
[Epoch 6, Batch 1500] loss: 0.04609963360402616
[Epoch 6, Batch 1600] loss: 0.04909700039803283
[Epoch 6, Batch 1700] loss: 0.052725242307351435
[Epoch 6, Batch 1800] loss: 0.03588975958962692
[Epoch 6, Batch 1900] loss: 0.03697130073807784
[Epoch 6, Batch 2000] loss: 0.05572062289051246
[Epoch 6, Batch 2100] loss: 0.030075877107010457
[Epoch 6, Batch 2200] loss: 0.04835851880692644
[Epoch 6, Batch 2300] loss: 0.03994712854910176
[Epoch 6, Batch 2400] loss: 0.04368437174663995
[Epoch 6, Batch 2500] loss: 0.042525553603481966
[Epoch 6, Batch 2600] loss: 0.03907738737725595
[Epoch 6, Batch 2700] loss: 0.02587810398224974
[Epoch 6, Batch 2800] loss: 0.0425284565804759
[Epoch 6, Batch 2900] loss: 0.040514082547451834
[Epoch 6, Batch 3000] loss: 0.038143384116119707
[Epoch 6, Batch 3100] loss: 0.0530849010910606
[Epoch 6, Batch 3200] loss: 0.053333207551040686
[Epoch 6, Batch 3300] loss: 0.04232540732831694
[Epoch 6, Batch 3400] loss: 0.04232881156131043
[Epoch 6, Batch 3500] loss: 0.047392504722811285
[Epoch 6, Batch 3600] loss: 0.060310577751079106
[Epoch 6, Batch 3700] loss: 0.04465867327176966
**STATS for Epoch 6** : 
Average training loss: 0.0004
Best model saved at epoch 6 with training loss: 0.0004
[Epoch 7, Batch 100] loss: 0.03810051232969272
[Epoch 7, Batch 200] loss: 0.029698853103618604
[Epoch 7, Batch 300] loss: 0.051619244365865596
[Epoch 7, Batch 400] loss: 0.040597058867570014
[Epoch 7, Batch 500] loss: 0.04956151320133358
[Epoch 7, Batch 600] loss: 0.045295573199400675
[Epoch 7, Batch 700] loss: 0.027812299439974594
[Epoch 7, Batch 800] loss: 0.034939507378003325
[Epoch 7, Batch 900] loss: 0.042809324583213314
[Epoch 7, Batch 1000] loss: 0.03493098692793865
[Epoch 7, Batch 1100] loss: 0.031792756960931
[Epoch 7, Batch 1200] loss: 0.04821448678165325
[Epoch 7, Batch 1300] loss: 0.0367323947197292
[Epoch 7, Batch 1400] loss: 0.03453397911252978
[Epoch 7, Batch 1500] loss: 0.032233267406991215
[Epoch 7, Batch 1600] loss: 0.04135701709150453
[Epoch 7, Batch 1700] loss: 0.04311479331547161
[Epoch 7, Batch 1800] loss: 0.051603390841191865
[Epoch 7, Batch 1900] loss: 0.03049598946905462
[Epoch 7, Batch 2000] loss: 0.030953676136705327
[Epoch 7, Batch 2100] loss: 0.02634826790090301
[Epoch 7, Batch 2200] loss: 0.0428423023528012
[Epoch 7, Batch 2300] loss: 0.04185706606309395
[Epoch 7, Batch 2400] loss: 0.03032635168376146
[Epoch 7, Batch 2500] loss: 0.03125133205045131
[Epoch 7, Batch 2600] loss: 0.032471605861355786
[Epoch 7, Batch 2700] loss: 0.033608266194496535
[Epoch 7, Batch 2800] loss: 0.038382519558945206
[Epoch 7, Batch 2900] loss: 0.020979639143624808
[Epoch 7, Batch 3000] loss: 0.03959513715359208
[Epoch 7, Batch 3100] loss: 0.03666843441242236
[Epoch 7, Batch 3200] loss: 0.023285261811543022
[Epoch 7, Batch 3300] loss: 0.043936412429829944
[Epoch 7, Batch 3400] loss: 0.03647085589604103
[Epoch 7, Batch 3500] loss: 0.045058242017403244
[Epoch 7, Batch 3600] loss: 0.04292115991745959
[Epoch 7, Batch 3700] loss: 0.041335444125070356
**STATS for Epoch 7** : 
Average training loss: 0.0005
[Epoch 8, Batch 100] loss: 0.03400722904072609
[Epoch 8, Batch 200] loss: 0.04937581847130787
[Epoch 8, Batch 300] loss: 0.020303830909833776
[Epoch 8, Batch 400] loss: 0.03381595887069125
[Epoch 8, Batch 500] loss: 0.02711643728718627
[Epoch 8, Batch 600] loss: 0.04045731723846984
[Epoch 8, Batch 700] loss: 0.03101423830521526
[Epoch 8, Batch 800] loss: 0.034308586813567674
[Epoch 8, Batch 900] loss: 0.028482213831375704
[Epoch 8, Batch 1000] loss: 0.03450440887696459
[Epoch 8, Batch 1100] loss: 0.035885754761402495
[Epoch 8, Batch 1200] loss: 0.033378980518900786
[Epoch 8, Batch 1300] loss: 0.03562043891783105
[Epoch 8, Batch 1400] loss: 0.048777700046193785
[Epoch 8, Batch 1500] loss: 0.04083642607962247
[Epoch 8, Batch 1600] loss: 0.02939639034186257
[Epoch 8, Batch 1700] loss: 0.02829083775461186
[Epoch 8, Batch 1800] loss: 0.027706112923915498
[Epoch 8, Batch 1900] loss: 0.03630228471578448
[Epoch 8, Batch 2000] loss: 0.03829954679182265
[Epoch 8, Batch 2100] loss: 0.03960637003590819
[Epoch 8, Batch 2200] loss: 0.029323838021373377
[Epoch 8, Batch 2300] loss: 0.023227743021489004
[Epoch 8, Batch 2400] loss: 0.030576556020496356
[Epoch 8, Batch 2500] loss: 0.0337849728364381
[Epoch 8, Batch 2600] loss: 0.03483837458959897
[Epoch 8, Batch 2700] loss: 0.029903475372047978
[Epoch 8, Batch 2800] loss: 0.025087022279330996
[Epoch 8, Batch 2900] loss: 0.033205487194572926
[Epoch 8, Batch 3000] loss: 0.029335171798884403
[Epoch 8, Batch 3100] loss: 0.02383108089756206
[Epoch 8, Batch 3200] loss: 0.02509221096028341
[Epoch 8, Batch 3300] loss: 0.031092423454101663
[Epoch 8, Batch 3400] loss: 0.054600836113168044
[Epoch 8, Batch 3500] loss: 0.035069519022654275
[Epoch 8, Batch 3600] loss: 0.036947614439413884
[Epoch 8, Batch 3700] loss: 0.028140616153250447
**STATS for Epoch 8** : 
Average training loss: 0.0005
[Epoch 9, Batch 100] loss: 0.037712406761565946
[Epoch 9, Batch 200] loss: 0.026623986240738303
[Epoch 9, Batch 300] loss: 0.039358921321836535
[Epoch 9, Batch 400] loss: 0.02607650351827033
[Epoch 9, Batch 500] loss: 0.03332123314656201
[Epoch 9, Batch 600] loss: 0.02584578232723288
[Epoch 9, Batch 700] loss: 0.03615952097490663
[Epoch 9, Batch 800] loss: 0.029496692384273045
[Epoch 9, Batch 900] loss: 0.03431152660778025
[Epoch 9, Batch 1000] loss: 0.03268418643361656
[Epoch 9, Batch 1100] loss: 0.027755295134629706
[Epoch 9, Batch 1200] loss: 0.02470945651490183
[Epoch 9, Batch 1300] loss: 0.028691072959409213
[Epoch 9, Batch 1400] loss: 0.020104087942017942
[Epoch 9, Batch 1500] loss: 0.02381594707883778
[Epoch 9, Batch 1600] loss: 0.026903312743088464
[Epoch 9, Batch 1700] loss: 0.02241127407116437
[Epoch 9, Batch 1800] loss: 0.03092012021050323
[Epoch 9, Batch 1900] loss: 0.05379149324780883
[Epoch 9, Batch 2000] loss: 0.029298017739565693
[Epoch 9, Batch 2100] loss: 0.036581861014128664
[Epoch 9, Batch 2200] loss: 0.03119407972044428
[Epoch 9, Batch 2300] loss: 0.027279755933850538
[Epoch 9, Batch 2400] loss: 0.019525348700699396
[Epoch 9, Batch 2500] loss: 0.033197736227011776
[Epoch 9, Batch 2600] loss: 0.042994272169453326
[Epoch 9, Batch 2700] loss: 0.03317451071285177
[Epoch 9, Batch 2800] loss: 0.029246522836911027
[Epoch 9, Batch 2900] loss: 0.023776290003806936
[Epoch 9, Batch 3000] loss: 0.026330188577558148
[Epoch 9, Batch 3100] loss: 0.027837339312391123
[Epoch 9, Batch 3200] loss: 0.023844342170632443
[Epoch 9, Batch 3300] loss: 0.023974065652000717
[Epoch 9, Batch 3400] loss: 0.025724781912067556
[Epoch 9, Batch 3500] loss: 0.035331943793135
[Epoch 9, Batch 3600] loss: 0.03571473811163742
[Epoch 9, Batch 3700] loss: 0.024609806107910116
**STATS for Epoch 9** : 
Average training loss: 0.0002
Best model saved at epoch 9 with training loss: 0.0002
[Epoch 10, Batch 100] loss: 0.011501291848981054
[Epoch 10, Batch 200] loss: 0.03857020650750201
[Epoch 10, Batch 300] loss: 0.013424135962850414
[Epoch 10, Batch 400] loss: 0.02583828751863621
[Epoch 10, Batch 500] loss: 0.029541995827698883
[Epoch 10, Batch 600] loss: 0.028525918038703822
[Epoch 10, Batch 700] loss: 0.027588528508276797
[Epoch 10, Batch 800] loss: 0.026817249756932143
[Epoch 10, Batch 900] loss: 0.025992990818776887
[Epoch 10, Batch 1000] loss: 0.025482242724283424
[Epoch 10, Batch 1100] loss: 0.02259904228929372
[Epoch 10, Batch 1200] loss: 0.026980971409357152
[Epoch 10, Batch 1300] loss: 0.027203753516587312
[Epoch 10, Batch 1400] loss: 0.03052712550270371
[Epoch 10, Batch 1500] loss: 0.016625099221564597
[Epoch 10, Batch 1600] loss: 0.024905241954002122
[Epoch 10, Batch 1700] loss: 0.03344596146271215
[Epoch 10, Batch 1800] loss: 0.028999904226729996
[Epoch 10, Batch 1900] loss: 0.024808002404097352
[Epoch 10, Batch 2000] loss: 0.034683514625467066
[Epoch 10, Batch 2100] loss: 0.028187620565804535
[Epoch 10, Batch 2200] loss: 0.02938745590094186
[Epoch 10, Batch 2300] loss: 0.023600577482829975
[Epoch 10, Batch 2400] loss: 0.028725551085008193
[Epoch 10, Batch 2500] loss: 0.02492406210207264
[Epoch 10, Batch 2600] loss: 0.03097084075518069
[Epoch 10, Batch 2700] loss: 0.02898874478734797
[Epoch 10, Batch 2800] loss: 0.0226852233678801
[Epoch 10, Batch 2900] loss: 0.01782047946631792
[Epoch 10, Batch 3000] loss: 0.028297198467553245
[Epoch 10, Batch 3100] loss: 0.035637152794879515
[Epoch 10, Batch 3200] loss: 0.02616861267859349
[Epoch 10, Batch 3300] loss: 0.02961318117493647
[Epoch 10, Batch 3400] loss: 0.01412307379199774
[Epoch 10, Batch 3500] loss: 0.036521202447038374
[Epoch 10, Batch 3600] loss: 0.026822753124361044
[Epoch 10, Batch 3700] loss: 0.02559586506053165
**STATS for Epoch 10** : 
Average training loss: 0.0003
[Epoch 11, Batch 100] loss: 0.02957149798319733
[Epoch 11, Batch 200] loss: 0.024906000323680927
[Epoch 11, Batch 300] loss: 0.020747534652073227
[Epoch 11, Batch 400] loss: 0.020401747689320474
[Epoch 11, Batch 500] loss: 0.022734985660063104
[Epoch 11, Batch 600] loss: 0.03427192195042153
[Epoch 11, Batch 700] loss: 0.03091555508428428
[Epoch 11, Batch 800] loss: 0.017326111596030386
[Epoch 11, Batch 900] loss: 0.021651974163250997
[Epoch 11, Batch 1000] loss: 0.023293826160006574
[Epoch 11, Batch 1100] loss: 0.04527623393958493
[Epoch 11, Batch 1200] loss: 0.026125272748322458
[Epoch 11, Batch 1300] loss: 0.0203077910342472
[Epoch 11, Batch 1400] loss: 0.014488806253102665
[Epoch 11, Batch 1500] loss: 0.021309870626173507
[Epoch 11, Batch 1600] loss: 0.01928614316297171
[Epoch 11, Batch 1700] loss: 0.021450025708309114
[Epoch 11, Batch 1800] loss: 0.021918159120468773
[Epoch 11, Batch 1900] loss: 0.02394481263880152
[Epoch 11, Batch 2000] loss: 0.02907176511709622
[Epoch 11, Batch 2100] loss: 0.023754563921393128
[Epoch 11, Batch 2200] loss: 0.021513446423050482
[Epoch 11, Batch 2300] loss: 0.019910735086668865
[Epoch 11, Batch 2400] loss: 0.023030015052772797
[Epoch 11, Batch 2500] loss: 0.023313868330951663
[Epoch 11, Batch 2600] loss: 0.02520669159901445
[Epoch 11, Batch 2700] loss: 0.024193267073278547
[Epoch 11, Batch 2800] loss: 0.021220775376677922
[Epoch 11, Batch 2900] loss: 0.024706497185616173
[Epoch 11, Batch 3000] loss: 0.020284089465603755
[Epoch 11, Batch 3100] loss: 0.014848767166804465
[Epoch 11, Batch 3200] loss: 0.03629085774820851
[Epoch 11, Batch 3300] loss: 0.014582619711654842
[Epoch 11, Batch 3400] loss: 0.031052442396976403
[Epoch 11, Batch 3500] loss: 0.013294271379527345
[Epoch 11, Batch 3600] loss: 0.02735475894442061
[Epoch 11, Batch 3700] loss: 0.02984670119571092
**STATS for Epoch 11** : 
Average training loss: 0.0003
[Epoch 12, Batch 100] loss: 0.022063395076947927
[Epoch 12, Batch 200] loss: 0.029270586988686773
[Epoch 12, Batch 300] loss: 0.012222768599713163
[Epoch 12, Batch 400] loss: 0.02604667422056082
[Epoch 12, Batch 500] loss: 0.023397280723511358
[Epoch 12, Batch 600] loss: 0.024117560073209462
[Epoch 12, Batch 700] loss: 0.031062484313515597
[Epoch 12, Batch 800] loss: 0.017449069960748603
[Epoch 12, Batch 900] loss: 0.014334776174837315
[Epoch 12, Batch 1000] loss: 0.015725699198883378
[Epoch 12, Batch 1100] loss: 0.022094027983039267
[Epoch 12, Batch 1200] loss: 0.01937939273016127
[Epoch 12, Batch 1300] loss: 0.017400608575444496
[Epoch 12, Batch 1400] loss: 0.013746528741430666
[Epoch 12, Batch 1500] loss: 0.021611853815138603
[Epoch 12, Batch 1600] loss: 0.0189857733441022
[Epoch 12, Batch 1700] loss: 0.017403500287364294
[Epoch 12, Batch 1800] loss: 0.021740622648267163
[Epoch 12, Batch 1900] loss: 0.017158916972894078
[Epoch 12, Batch 2000] loss: 0.04063676106001367
[Epoch 12, Batch 2100] loss: 0.0166858357741512
[Epoch 12, Batch 2200] loss: 0.015630589890570264
[Epoch 12, Batch 2300] loss: 0.01977088140549313
[Epoch 12, Batch 2400] loss: 0.01768827291794878
[Epoch 12, Batch 2500] loss: 0.014847455748131323
[Epoch 12, Batch 2600] loss: 0.03639129138122371
[Epoch 12, Batch 2700] loss: 0.02372728506263229
[Epoch 12, Batch 2800] loss: 0.04459295055408802
[Epoch 12, Batch 2900] loss: 0.02109599016428547
[Epoch 12, Batch 3000] loss: 0.036484784335480074
[Epoch 12, Batch 3100] loss: 0.03271984259275996
[Epoch 12, Batch 3200] loss: 0.012312700794100238
[Epoch 12, Batch 3300] loss: 0.015656903516446618
[Epoch 12, Batch 3400] loss: 0.023326474566747493
[Epoch 12, Batch 3500] loss: 0.021268841531054933
[Epoch 12, Batch 3600] loss: 0.021157463308627486
[Epoch 12, Batch 3700] loss: 0.0193115122296922
**STATS for Epoch 12** : 
Average training loss: 0.0003
[Epoch 13, Batch 100] loss: 0.011071924186835532
[Epoch 13, Batch 200] loss: 0.015621780870224028
[Epoch 13, Batch 300] loss: 0.017472726505402533
[Epoch 13, Batch 400] loss: 0.019434112268136232
[Epoch 13, Batch 500] loss: 0.02394113151716738
[Epoch 13, Batch 600] loss: 0.01444591949129972
[Epoch 13, Batch 700] loss: 0.012906893526524072
[Epoch 13, Batch 800] loss: 0.016959444304993666
[Epoch 13, Batch 900] loss: 0.021004625326022507
[Epoch 13, Batch 1000] loss: 0.029933824896797887
[Epoch 13, Batch 1100] loss: 0.012322646775755857
[Epoch 13, Batch 1200] loss: 0.03313020128931385
[Epoch 13, Batch 1300] loss: 0.016512708162190394
[Epoch 13, Batch 1400] loss: 0.012849513122419012
[Epoch 13, Batch 1500] loss: 0.026748440882693104
[Epoch 13, Batch 1600] loss: 0.01505060420018708
[Epoch 13, Batch 1700] loss: 0.01857645344603952
[Epoch 13, Batch 1800] loss: 0.017600173488008294
[Epoch 13, Batch 1900] loss: 0.02005341771644453
[Epoch 13, Batch 2000] loss: 0.020842110723351653
[Epoch 13, Batch 2100] loss: 0.020168707932989492
[Epoch 13, Batch 2200] loss: 0.012392513899394544
[Epoch 13, Batch 2300] loss: 0.022320474502930666
[Epoch 13, Batch 2400] loss: 0.026187376927609876
[Epoch 13, Batch 2500] loss: 0.019598831192888612
[Epoch 13, Batch 2600] loss: 0.01637501962886745
[Epoch 13, Batch 2700] loss: 0.02684793112170155
[Epoch 13, Batch 2800] loss: 0.0241636598862533
[Epoch 13, Batch 2900] loss: 0.011199561905996233
[Epoch 13, Batch 3000] loss: 0.019961032002474895
[Epoch 13, Batch 3100] loss: 0.014270000177266411
[Epoch 13, Batch 3200] loss: 0.01266779908245553
[Epoch 13, Batch 3300] loss: 0.01658735228844307
[Epoch 13, Batch 3400] loss: 0.026151660352734325
[Epoch 13, Batch 3500] loss: 0.019172555322302286
[Epoch 13, Batch 3600] loss: 0.025605796749350703
[Epoch 13, Batch 3700] loss: 0.017901872113106947
**STATS for Epoch 13** : 
Average training loss: 0.0003
[Epoch 14, Batch 100] loss: 0.010881734468839568
[Epoch 14, Batch 200] loss: 0.012642245923761947
[Epoch 14, Batch 300] loss: 0.010004353991489552
[Epoch 14, Batch 400] loss: 0.014942142819727451
[Epoch 14, Batch 500] loss: 0.012386166791720825
[Epoch 14, Batch 600] loss: 0.015714865804820875
[Epoch 14, Batch 700] loss: 0.016602315799527787
[Epoch 14, Batch 800] loss: 0.0201333197533404
[Epoch 14, Batch 900] loss: 0.013159790121135303
[Epoch 14, Batch 1000] loss: 0.017339894332135373
[Epoch 14, Batch 1100] loss: 0.018855792215999825
[Epoch 14, Batch 1200] loss: 0.0125031761806531
[Epoch 14, Batch 1300] loss: 0.015822114596267055
[Epoch 14, Batch 1400] loss: 0.018174374473510398
[Epoch 14, Batch 1500] loss: 0.01891527688547285
[Epoch 14, Batch 1600] loss: 0.016089589353673547
[Epoch 14, Batch 1700] loss: 0.010180771812174498
[Epoch 14, Batch 1800] loss: 0.01064173311653576
[Epoch 14, Batch 1900] loss: 0.014393096426729243
[Epoch 14, Batch 2000] loss: 0.021527053822173913
[Epoch 14, Batch 2100] loss: 0.025059621571417664
[Epoch 14, Batch 2200] loss: 0.029727629085755325
[Epoch 14, Batch 2300] loss: 0.016156468596509512
[Epoch 14, Batch 2400] loss: 0.023790587667317595
[Epoch 14, Batch 2500] loss: 0.011164698684842734
[Epoch 14, Batch 2600] loss: 0.01583877257307904
[Epoch 14, Batch 2700] loss: 0.013914041614370945
[Epoch 14, Batch 2800] loss: 0.03525167921443426
[Epoch 14, Batch 2900] loss: 0.022423047356387543
[Epoch 14, Batch 3000] loss: 0.019648967847060703
[Epoch 14, Batch 3100] loss: 0.017434690803074773
[Epoch 14, Batch 3200] loss: 0.025140833505938643
[Epoch 14, Batch 3300] loss: 0.025146987856642225
[Epoch 14, Batch 3400] loss: 0.03798142967527383
[Epoch 14, Batch 3500] loss: 0.016039032932167175
[Epoch 14, Batch 3600] loss: 0.019337197744362128
[Epoch 14, Batch 3700] loss: 0.016462496075037053
**STATS for Epoch 14** : 
Average training loss: 0.0002
[Epoch 15, Batch 100] loss: 0.010135881029891608
[Epoch 15, Batch 200] loss: 0.011260838893367691
[Epoch 15, Batch 300] loss: 0.011438065806287341
[Epoch 15, Batch 400] loss: 0.008219128999335225
[Epoch 15, Batch 500] loss: 0.012988800739558428
[Epoch 15, Batch 600] loss: 0.01126151673930508
[Epoch 15, Batch 700] loss: 0.010516456779241708
[Epoch 15, Batch 800] loss: 0.012189188605902927
[Epoch 15, Batch 900] loss: 0.01565694356851054
[Epoch 15, Batch 1000] loss: 0.011277463560309115
[Epoch 15, Batch 1100] loss: 0.015620987551073995
[Epoch 15, Batch 1200] loss: 0.017425117087759644
[Epoch 15, Batch 1300] loss: 0.031287998442749085
[Epoch 15, Batch 1400] loss: 0.016438944127512515
[Epoch 15, Batch 1500] loss: 0.008393380056513706
[Epoch 15, Batch 1600] loss: 0.01651065747033499
[Epoch 15, Batch 1700] loss: 0.016170289783631234
[Epoch 15, Batch 1800] loss: 0.017209216507108067
[Epoch 15, Batch 1900] loss: 0.014380996355448587
[Epoch 15, Batch 2000] loss: 0.01912170665196754
[Epoch 15, Batch 2100] loss: 0.01319715017551971
[Epoch 15, Batch 2200] loss: 0.022517518365275463
[Epoch 15, Batch 2300] loss: 0.014296460877230856
[Epoch 15, Batch 2400] loss: 0.02059343925542635
[Epoch 15, Batch 2500] loss: 0.009627676591771888
[Epoch 15, Batch 2600] loss: 0.029083796075301507
[Epoch 15, Batch 2700] loss: 0.015375506317323016
[Epoch 15, Batch 2800] loss: 0.014477895634445303
[Epoch 15, Batch 2900] loss: 0.0090466380383441
[Epoch 15, Batch 3000] loss: 0.013898723672145934
[Epoch 15, Batch 3100] loss: 0.01477971230852745
[Epoch 15, Batch 3200] loss: 0.02789567146683112
[Epoch 15, Batch 3300] loss: 0.01878605170663832
[Epoch 15, Batch 3400] loss: 0.03057040440104174
[Epoch 15, Batch 3500] loss: 0.007997496240059264
[Epoch 15, Batch 3600] loss: 0.009374383924832728
[Epoch 15, Batch 3700] loss: 0.013997977890930997
**STATS for Epoch 15** : 
Average training loss: 0.0001
Best model saved at epoch 15 with training loss: 0.0001
[Epoch 16, Batch 100] loss: 0.013829002709462657
[Epoch 16, Batch 200] loss: 0.008765224563412631
[Epoch 16, Batch 300] loss: 0.005891760505237471
[Epoch 16, Batch 400] loss: 0.008997195178139919
[Epoch 16, Batch 500] loss: 0.007320029492943831
[Epoch 16, Batch 600] loss: 0.010008424601178376
[Epoch 16, Batch 700] loss: 0.011084000008443127
[Epoch 16, Batch 800] loss: 0.005095255609589912
[Epoch 16, Batch 900] loss: 0.01043494211415691
[Epoch 16, Batch 1000] loss: 0.012377765277706202
[Epoch 16, Batch 1100] loss: 0.006280190695224519
[Epoch 16, Batch 1200] loss: 0.014073388411320593
[Epoch 16, Batch 1300] loss: 0.008212726656652194
[Epoch 16, Batch 1400] loss: 0.018245449703772464
[Epoch 16, Batch 1500] loss: 0.009215442693666774
[Epoch 16, Batch 1600] loss: 0.02585978076729134
[Epoch 16, Batch 1700] loss: 0.017831085276748128
[Epoch 16, Batch 1800] loss: 0.029374417428643936
[Epoch 16, Batch 1900] loss: 0.015614679569480358
[Epoch 16, Batch 2000] loss: 0.016797352760704598
[Epoch 16, Batch 2100] loss: 0.01642706362243189
[Epoch 16, Batch 2200] loss: 0.01250038320755266
[Epoch 16, Batch 2300] loss: 0.011180026944175551
[Epoch 16, Batch 2400] loss: 0.016858432584485855
[Epoch 16, Batch 2500] loss: 0.009591421063387316
[Epoch 16, Batch 2600] loss: 0.01235671845829529
[Epoch 16, Batch 2700] loss: 0.025102319971501856
[Epoch 16, Batch 2800] loss: 0.011359428904461311
[Epoch 16, Batch 2900] loss: 0.01538683524080625
[Epoch 16, Batch 3000] loss: 0.01973614458152042
[Epoch 16, Batch 3100] loss: 0.007703495921959984
[Epoch 16, Batch 3200] loss: 0.02315243042902239
[Epoch 16, Batch 3300] loss: 0.013768570192078187
[Epoch 16, Batch 3400] loss: 0.015601668349559077
[Epoch 16, Batch 3500] loss: 0.015946601182331505
[Epoch 16, Batch 3600] loss: 0.01283430235218475
[Epoch 16, Batch 3700] loss: 0.014460147124555078
**STATS for Epoch 16** : 
Average training loss: 0.0002
[Epoch 17, Batch 100] loss: 0.012923162295533076
[Epoch 17, Batch 200] loss: 0.004925088312993466
[Epoch 17, Batch 300] loss: 0.02232780782669579
[Epoch 17, Batch 400] loss: 0.016548120538973306
[Epoch 17, Batch 500] loss: 0.015756157849236844
[Epoch 17, Batch 600] loss: 0.01614726489153327
[Epoch 17, Batch 700] loss: 0.010954253842842264
[Epoch 17, Batch 800] loss: 0.011478909437382754
[Epoch 17, Batch 900] loss: 0.01464053904875982
[Epoch 17, Batch 1000] loss: 0.004795088431706063
[Epoch 17, Batch 1100] loss: 0.011498490978856352
[Epoch 17, Batch 1200] loss: 0.009145642147359467
[Epoch 17, Batch 1300] loss: 0.0121639635210704
[Epoch 17, Batch 1400] loss: 0.013313795532435507
[Epoch 17, Batch 1500] loss: 0.013078527368988943
[Epoch 17, Batch 1600] loss: 0.01030470384020191
[Epoch 17, Batch 1700] loss: 0.009209571507731197
[Epoch 17, Batch 1800] loss: 0.016143427086194605
[Epoch 17, Batch 1900] loss: 0.01610267302434295
[Epoch 17, Batch 2000] loss: 0.00835843168178144
[Epoch 17, Batch 2100] loss: 0.016085806897847305
[Epoch 17, Batch 2200] loss: 0.014670437959775882
[Epoch 17, Batch 2300] loss: 0.012662383487536318
[Epoch 17, Batch 2400] loss: 0.01718570861931312
[Epoch 17, Batch 2500] loss: 0.007609610911972595
[Epoch 17, Batch 2600] loss: 0.008233504191293832
[Epoch 17, Batch 2700] loss: 0.014744414780070656
[Epoch 17, Batch 2800] loss: 0.018691980021126254
[Epoch 17, Batch 2900] loss: 0.021828894166619647
[Epoch 17, Batch 3000] loss: 0.014099804345328266
[Epoch 17, Batch 3100] loss: 0.020369558689239967
[Epoch 17, Batch 3200] loss: 0.011685781473752287
[Epoch 17, Batch 3300] loss: 0.010653105708843213
[Epoch 17, Batch 3400] loss: 0.022662881994892813
[Epoch 17, Batch 3500] loss: 0.011651597414092975
[Epoch 17, Batch 3600] loss: 0.01288258085052803
[Epoch 17, Batch 3700] loss: 0.024124165305147473
**STATS for Epoch 17** : 
Average training loss: 0.0002
[Epoch 18, Batch 100] loss: 0.012002704493243073
[Epoch 18, Batch 200] loss: 0.005304280680975353
[Epoch 18, Batch 300] loss: 0.007477008707278401
[Epoch 18, Batch 400] loss: 0.0059190104195931785
[Epoch 18, Batch 500] loss: 0.006135887123773501
[Epoch 18, Batch 600] loss: 0.010068001069957972
[Epoch 18, Batch 700] loss: 0.011296359068079482
[Epoch 18, Batch 800] loss: 0.014019343653321812
[Epoch 18, Batch 900] loss: 0.008736565277313275
[Epoch 18, Batch 1000] loss: 0.01655822781601273
[Epoch 18, Batch 1100] loss: 0.009574908272354606
[Epoch 18, Batch 1200] loss: 0.016177965553206376
[Epoch 18, Batch 1300] loss: 0.02009882613344985
[Epoch 18, Batch 1400] loss: 0.008757208194865598
[Epoch 18, Batch 1500] loss: 0.013942202552939306
[Epoch 18, Batch 1600] loss: 0.018754668019064412
[Epoch 18, Batch 1700] loss: 0.015300173871842161
[Epoch 18, Batch 1800] loss: 0.010776306554439542
[Epoch 18, Batch 1900] loss: 0.01771882763285248
[Epoch 18, Batch 2000] loss: 0.012390716114495035
[Epoch 18, Batch 2100] loss: 0.008956444200821352
[Epoch 18, Batch 2200] loss: 0.009440804755238332
[Epoch 18, Batch 2300] loss: 0.0102869640005747
[Epoch 18, Batch 2400] loss: 0.008288059316664658
[Epoch 18, Batch 2500] loss: 0.014376731396337163
[Epoch 18, Batch 2600] loss: 0.005611552239670346
[Epoch 18, Batch 2700] loss: 0.010187034056339144
[Epoch 18, Batch 2800] loss: 0.005501690042801783
[Epoch 18, Batch 2900] loss: 0.011507043344972772
[Epoch 18, Batch 3000] loss: 0.009764740551376008
[Epoch 18, Batch 3100] loss: 0.00997077316258128
[Epoch 18, Batch 3200] loss: 0.017210144424525425
[Epoch 18, Batch 3300] loss: 0.025112923366934867
[Epoch 18, Batch 3400] loss: 0.014820212479985457
[Epoch 18, Batch 3500] loss: 0.009007618528880813
[Epoch 18, Batch 3600] loss: 0.009698027458816795
[Epoch 18, Batch 3700] loss: 0.015125272859795586
**STATS for Epoch 18** : 
Average training loss: 0.0001
Best model saved at epoch 18 with training loss: 0.0001
[Epoch 19, Batch 100] loss: 0.01077865364205536
[Epoch 19, Batch 200] loss: 0.010822248163044605
[Epoch 19, Batch 300] loss: 0.005317816889369169
[Epoch 19, Batch 400] loss: 0.011150524164727359
[Epoch 19, Batch 500] loss: 0.008401091967152751
[Epoch 19, Batch 600] loss: 0.009866480886703357
[Epoch 19, Batch 700] loss: 0.01176770126379779
[Epoch 19, Batch 800] loss: 0.016303558412610074
[Epoch 19, Batch 900] loss: 0.008033282505693932
[Epoch 19, Batch 1000] loss: 0.008007546695109795
[Epoch 19, Batch 1100] loss: 0.008071015256482496
[Epoch 19, Batch 1200] loss: 0.009195192928937104
[Epoch 19, Batch 1300] loss: 0.014843558177320233
[Epoch 19, Batch 1400] loss: 0.009189045711214022
[Epoch 19, Batch 1500] loss: 0.00976059989938051
[Epoch 19, Batch 1600] loss: 0.00799407627405344
[Epoch 19, Batch 1700] loss: 0.010539345721924746
[Epoch 19, Batch 1800] loss: 0.015428775368982316
[Epoch 19, Batch 1900] loss: 0.010103099504485727
[Epoch 19, Batch 2000] loss: 0.008948351604622075
[Epoch 19, Batch 2100] loss: 0.012829144230975089
[Epoch 19, Batch 2200] loss: 0.007095939810778873
[Epoch 19, Batch 2300] loss: 0.007640003486153546
[Epoch 19, Batch 2400] loss: 0.014374935655691843
[Epoch 19, Batch 2500] loss: 0.013024196863025281
[Epoch 19, Batch 2600] loss: 0.010802899523196175
[Epoch 19, Batch 2700] loss: 0.006991823411808582
[Epoch 19, Batch 2800] loss: 0.01046617400874311
[Epoch 19, Batch 2900] loss: 0.007246972558414199
[Epoch 19, Batch 3000] loss: 0.004965051550468616
[Epoch 19, Batch 3100] loss: 0.011030011707614449
[Epoch 19, Batch 3200] loss: 0.016957070233993364
[Epoch 19, Batch 3300] loss: 0.023020162164484645
[Epoch 19, Batch 3400] loss: 0.009505099817007477
[Epoch 19, Batch 3500] loss: 0.006899445973263027
[Epoch 19, Batch 3600] loss: 0.010327734636483683
[Epoch 19, Batch 3700] loss: 0.017801232731030722
**STATS for Epoch 19** : 
Average training loss: 0.0002
[Epoch 20, Batch 100] loss: 0.007298786161009048
[Epoch 20, Batch 200] loss: 0.004130018217531415
[Epoch 20, Batch 300] loss: 0.009326621677918184
[Epoch 20, Batch 400] loss: 0.006908092243966166
[Epoch 20, Batch 500] loss: 0.007621777586136886
[Epoch 20, Batch 600] loss: 0.009504321336264639
[Epoch 20, Batch 700] loss: 0.004057887406614782
[Epoch 20, Batch 800] loss: 0.009773411462008426
[Epoch 20, Batch 900] loss: 0.00521007595840274
[Epoch 20, Batch 1000] loss: 0.008461551051586866
[Epoch 20, Batch 1100] loss: 0.011987230775771423
[Epoch 20, Batch 1200] loss: 0.00951432845162799
[Epoch 20, Batch 1300] loss: 0.0088831534003657
[Epoch 20, Batch 1400] loss: 0.004591011233776499
[Epoch 20, Batch 1500] loss: 0.010990965268356377
[Epoch 20, Batch 1600] loss: 0.012089906016703934
[Epoch 20, Batch 1700] loss: 0.007303830956896035
[Epoch 20, Batch 1800] loss: 0.0071436325566537565
[Epoch 20, Batch 1900] loss: 0.010762256234124834
[Epoch 20, Batch 2000] loss: 0.005495501682729582
[Epoch 20, Batch 2100] loss: 0.004669052134897811
[Epoch 20, Batch 2200] loss: 0.01041732696155691
[Epoch 20, Batch 2300] loss: 0.005005788383084564
[Epoch 20, Batch 2400] loss: 0.01672159821227524
[Epoch 20, Batch 2500] loss: 0.012614423239187999
[Epoch 20, Batch 2600] loss: 0.02279616155949043
[Epoch 20, Batch 2700] loss: 0.013016004902401618
[Epoch 20, Batch 2800] loss: 0.01145996548738367
[Epoch 20, Batch 2900] loss: 0.015466714055419288
[Epoch 20, Batch 3000] loss: 0.0037199112731013885
[Epoch 20, Batch 3100] loss: 0.01239705720756774
[Epoch 20, Batch 3200] loss: 0.006975104426176131
[Epoch 20, Batch 3300] loss: 0.00998027538627639
[Epoch 20, Batch 3400] loss: 0.0050285940347635
[Epoch 20, Batch 3500] loss: 0.007015579622161567
[Epoch 20, Batch 3600] loss: 0.00933556372175417
[Epoch 20, Batch 3700] loss: 0.017296489509876663
**STATS for Epoch 20** : 
Average training loss: 0.0002
[Epoch 21, Batch 100] loss: 0.0084860000325898
[Epoch 21, Batch 200] loss: 0.006632829233064967
[Epoch 21, Batch 300] loss: 0.009375618454021151
[Epoch 21, Batch 400] loss: 0.007924989779221505
[Epoch 21, Batch 500] loss: 0.0062567303239848115
[Epoch 21, Batch 600] loss: 0.010839782011225907
[Epoch 21, Batch 700] loss: 0.0057860665880207305
[Epoch 21, Batch 800] loss: 0.008826588533183894
[Epoch 21, Batch 900] loss: 0.007740186583278046
[Epoch 21, Batch 1000] loss: 0.00370740798438419
[Epoch 21, Batch 1100] loss: 0.012125444525868261
[Epoch 21, Batch 1200] loss: 0.009539081240100132
[Epoch 21, Batch 1300] loss: 0.006285707750726033
[Epoch 21, Batch 1400] loss: 0.009680590382738502
[Epoch 21, Batch 1500] loss: 0.01931237333310719
[Epoch 21, Batch 1600] loss: 0.00992122600073003
[Epoch 21, Batch 1700] loss: 0.005642566686026385
[Epoch 21, Batch 1800] loss: 0.009131768228320992
[Epoch 21, Batch 1900] loss: 0.011035797306013818
[Epoch 21, Batch 2000] loss: 0.003001309793130531
[Epoch 21, Batch 2100] loss: 0.0073929508043960365
[Epoch 21, Batch 2200] loss: 0.0041682019875918285
[Epoch 21, Batch 2300] loss: 0.008205817515940907
[Epoch 21, Batch 2400] loss: 0.012268259030795434
[Epoch 21, Batch 2500] loss: 0.008152778257463354
[Epoch 21, Batch 2600] loss: 0.008119635662508244
[Epoch 21, Batch 2700] loss: 0.010539085012967462
[Epoch 21, Batch 2800] loss: 0.004727831477957807
[Epoch 21, Batch 2900] loss: 0.01376026099508863
[Epoch 21, Batch 3000] loss: 0.004796225181444243
[Epoch 21, Batch 3100] loss: 0.0035632917829229883
[Epoch 21, Batch 3200] loss: 0.0033111235279670837
[Epoch 21, Batch 3300] loss: 0.010943808668261567
[Epoch 21, Batch 3400] loss: 0.008460360400317769
[Epoch 21, Batch 3500] loss: 0.0085965158217806
[Epoch 21, Batch 3600] loss: 0.007927255943274788
[Epoch 21, Batch 3700] loss: 0.011451201825593671
**STATS for Epoch 21** : 
Average training loss: 0.0002
[Epoch 22, Batch 100] loss: 0.010864977664646176
[Epoch 22, Batch 200] loss: 0.006861361603591831
[Epoch 22, Batch 300] loss: 0.01852936349835545
[Epoch 22, Batch 400] loss: 0.007666013851908246
[Epoch 22, Batch 500] loss: 0.006455642187706872
[Epoch 22, Batch 600] loss: 0.008967803216492029
[Epoch 22, Batch 700] loss: 0.006835074169202926
[Epoch 22, Batch 800] loss: 0.005179483775132212
[Epoch 22, Batch 900] loss: 0.0032729003896974974
[Epoch 22, Batch 1000] loss: 0.004629493176754523
[Epoch 22, Batch 1100] loss: 0.0070055470449096905
[Epoch 22, Batch 1200] loss: 0.00256545111565174
[Epoch 22, Batch 1300] loss: 0.007865726840050229
[Epoch 22, Batch 1400] loss: 0.007468541328345282
[Epoch 22, Batch 1500] loss: 0.005117644452836316
[Epoch 22, Batch 1600] loss: 0.01438328342086379
[Epoch 22, Batch 1700] loss: 0.006502528194066031
[Epoch 22, Batch 1800] loss: 0.01012847618020146
[Epoch 22, Batch 1900] loss: 0.005682063258675498
[Epoch 22, Batch 2000] loss: 0.00456886653560332
[Epoch 22, Batch 2100] loss: 0.008136649892961714
[Epoch 22, Batch 2200] loss: 0.009944026898148195
[Epoch 22, Batch 2300] loss: 0.011645498996089146
[Epoch 22, Batch 2400] loss: 0.018333503603914777
[Epoch 22, Batch 2500] loss: 0.005005895649550212
[Epoch 22, Batch 2600] loss: 0.0033030240726793637
[Epoch 22, Batch 2700] loss: 0.004472690710640563
[Epoch 22, Batch 2800] loss: 0.012305650683069871
[Epoch 22, Batch 2900] loss: 0.003587411518196859
[Epoch 22, Batch 3000] loss: 0.008803336987311923
[Epoch 22, Batch 3100] loss: 0.005738244203685099
[Epoch 22, Batch 3200] loss: 0.006779721703051109
[Epoch 22, Batch 3300] loss: 0.008062512559687889
[Epoch 22, Batch 3400] loss: 0.011119435447965884
[Epoch 22, Batch 3500] loss: 0.011783223555859194
[Epoch 22, Batch 3600] loss: 0.008534552243992266
[Epoch 22, Batch 3700] loss: 0.01188602979020061
**STATS for Epoch 22** : 
Average training loss: 0.0001
[Epoch 23, Batch 100] loss: 0.007796779450983991
[Epoch 23, Batch 200] loss: 0.009322883366460246
[Epoch 23, Batch 300] loss: 0.006451996642952053
[Epoch 23, Batch 400] loss: 0.004511362470630616
[Epoch 23, Batch 500] loss: 0.002886814555033652
[Epoch 23, Batch 600] loss: 0.00525512193237887
[Epoch 23, Batch 700] loss: 0.005460079728557048
[Epoch 23, Batch 800] loss: 0.005281898358795729
[Epoch 23, Batch 900] loss: 0.012675787925451232
[Epoch 23, Batch 1000] loss: 0.007527179480453014
[Epoch 23, Batch 1100] loss: 0.007597044934044561
[Epoch 23, Batch 1200] loss: 0.004721616922679459
[Epoch 23, Batch 1300] loss: 0.004724106594181876
[Epoch 23, Batch 1400] loss: 0.009280908242101305
[Epoch 23, Batch 1500] loss: 0.006031824740848961
[Epoch 23, Batch 1600] loss: 0.007435179496295632
[Epoch 23, Batch 1700] loss: 0.012706295336126914
[Epoch 23, Batch 1800] loss: 0.00993591163529402
[Epoch 23, Batch 1900] loss: 0.005230760502889211
[Epoch 23, Batch 2000] loss: 0.012360229000832773
[Epoch 23, Batch 2100] loss: 0.006377015176141754
[Epoch 23, Batch 2200] loss: 0.0046916762913633645
[Epoch 23, Batch 2300] loss: 0.007701270758964256
[Epoch 23, Batch 2400] loss: 0.007526198313861414
[Epoch 23, Batch 2500] loss: 0.012406123883916962
[Epoch 23, Batch 2600] loss: 0.0029421948724807833
[Epoch 23, Batch 2700] loss: 0.008580232787707018
[Epoch 23, Batch 2800] loss: 0.004737461817242093
[Epoch 23, Batch 2900] loss: 0.006439353248531461
[Epoch 23, Batch 3000] loss: 0.011164641596092224
[Epoch 23, Batch 3100] loss: 0.0040551017571385725
[Epoch 23, Batch 3200] loss: 0.007722847410468603
[Epoch 23, Batch 3300] loss: 0.007798604258578621
[Epoch 23, Batch 3400] loss: 0.007049414970123564
[Epoch 23, Batch 3500] loss: 0.0040832819402203315
[Epoch 23, Batch 3600] loss: 0.004280463380785022
[Epoch 23, Batch 3700] loss: 0.013336137892783881
**STATS for Epoch 23** : 
Average training loss: 0.0000
Best model saved at epoch 23 with training loss: 0.0000
[Epoch 24, Batch 100] loss: 0.005280935662323145
[Epoch 24, Batch 200] loss: 0.004464902739787035
[Epoch 24, Batch 300] loss: 0.005275286774140114
[Epoch 24, Batch 400] loss: 0.002939746513908972
[Epoch 24, Batch 500] loss: 0.008123218380515879
[Epoch 24, Batch 600] loss: 0.004940444596113594
[Epoch 24, Batch 700] loss: 0.005785148759964613
[Epoch 24, Batch 800] loss: 0.009258662088362825
[Epoch 24, Batch 900] loss: 0.0064234895178231
[Epoch 24, Batch 1000] loss: 0.005079028378561361
[Epoch 24, Batch 1100] loss: 0.004074846970439694
[Epoch 24, Batch 1200] loss: 0.0037726022053908535
[Epoch 24, Batch 1300] loss: 0.008779605446559344
[Epoch 24, Batch 1400] loss: 0.003826631470742541
[Epoch 24, Batch 1500] loss: 0.009803405142828297
[Epoch 24, Batch 1600] loss: 0.008623861336061509
[Epoch 24, Batch 1700] loss: 0.005715427017294133
[Epoch 24, Batch 1800] loss: 0.013096523823180632
[Epoch 24, Batch 1900] loss: 0.008609943319011392
[Epoch 24, Batch 2000] loss: 0.008553095059663179
[Epoch 24, Batch 2100] loss: 0.007629985119297089
[Epoch 24, Batch 2200] loss: 0.002954899204630692
[Epoch 24, Batch 2300] loss: 0.003885664746755424
[Epoch 24, Batch 2400] loss: 0.0036405151556590455
[Epoch 24, Batch 2500] loss: 0.0038120558396883553
[Epoch 24, Batch 2600] loss: 0.00408056982577591
[Epoch 24, Batch 2700] loss: 0.004183958697963135
[Epoch 24, Batch 2800] loss: 0.005752463541058433
[Epoch 24, Batch 2900] loss: 0.005995205681688844
[Epoch 24, Batch 3000] loss: 0.007646828924750934
[Epoch 24, Batch 3100] loss: 0.009174087482615506
[Epoch 24, Batch 3200] loss: 0.01015941448548233
[Epoch 24, Batch 3300] loss: 0.00394049471598521
[Epoch 24, Batch 3400] loss: 0.020890075669371982
[Epoch 24, Batch 3500] loss: 0.004504077905926352
[Epoch 24, Batch 3600] loss: 0.0028598630715671904
[Epoch 24, Batch 3700] loss: 0.0030655564384073843
**STATS for Epoch 24** : 
Average training loss: 0.0001
Using best hyperparameters {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16} on final Test set to find Test loss for overfitting
Testing loss : 0.0472
Calculated Overfitting : 0.0471
Using best hyperparameters {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9866
Total time taken for hyperparameter tuning and evaluation: 2:51:36
/home/ahussain/PycharmProjects/optunaNew/optuna_MedianPruner.py:455: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.


Process finished with exit code 0

