s: 0.04269545357354218
[Epoch 11, Batch 2400] loss: 0.04041275655938079
[Epoch 11, Batch 2500] loss: 0.04388355034519918
[Epoch 11, Batch 2600] loss: 0.03635251431493089
[Epoch 11, Batch 2700] loss: 0.03536758515328984
[Epoch 11, Batch 2800] loss: 0.02521523529663682
[Epoch 11, Batch 2900] loss: 0.0397416318100295
[Epoch 11, Batch 3000] loss: 0.03502600027859444
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9825
Overfitting: 0.0586
Best model saved at epoch 11 with validation loss: 0.0586
[Epoch 12, Batch 100] loss: 0.03985957843047799
[Epoch 12, Batch 200] loss: 0.04130097127665067
[Epoch 12, Batch 300] loss: 0.03669899556582095
[Epoch 12, Batch 400] loss: 0.03448952645470854
[Epoch 12, Batch 500] loss: 0.029063032349804417
[Epoch 12, Batch 600] loss: 0.0444672986981459
[Epoch 12, Batch 700] loss: 0.053613605908467435
[Epoch 12, Batch 800] loss: 0.034916229936934544
[Epoch 12, Batch 900] loss: 0.02453812491381541
[Epoch 12, Batch 1000] loss: 0.02987114953168202
[Epoch 12, Batch 1100] loss: 0.03262074322308763
[Epoch 12, Batch 1200] loss: 0.03170050651999191
[Epoch 12, Batch 1300] loss: 0.03168549640424317
[Epoch 12, Batch 1400] loss: 0.037411287760769484
[Epoch 12, Batch 1500] loss: 0.03963533265137812
[Epoch 12, Batch 1600] loss: 0.036244267586444036
[Epoch 12, Batch 1700] loss: 0.04253937319735997
[Epoch 12, Batch 1800] loss: 0.02980377324129222
[Epoch 12, Batch 1900] loss: 0.03495301041577477
[Epoch 12, Batch 2000] loss: 0.03549242278560996
[Epoch 12, Batch 2100] loss: 0.043446101380104664
[Epoch 12, Batch 2200] loss: 0.03887076717706805
[Epoch 12, Batch 2300] loss: 0.04065399953775341
[Epoch 12, Batch 2400] loss: 0.039390025948814585
[Epoch 12, Batch 2500] loss: 0.06276822735526366
[Epoch 12, Batch 2600] loss: 0.035126876709691716
[Epoch 12, Batch 2700] loss: 0.036008516026340656
[Epoch 12, Batch 2800] loss: 0.03431645996759471
[Epoch 12, Batch 2900] loss: 0.0430252261942951
[Epoch 12, Batch 3000] loss: 0.026886829177528854
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9846
Overfitting: 0.0502
Best model saved at epoch 12 with validation loss: 0.0502
[Epoch 13, Batch 100] loss: 0.027467824997438585
[Epoch 13, Batch 200] loss: 0.03053243613168888
[Epoch 13, Batch 300] loss: 0.03573107612610329
[Epoch 13, Batch 400] loss: 0.0308310667295882
[Epoch 13, Batch 500] loss: 0.03296306839547469
[Epoch 13, Batch 600] loss: 0.033611022300610784
[Epoch 13, Batch 700] loss: 0.03599205833073938
[Epoch 13, Batch 800] loss: 0.0316905762735405
[Epoch 13, Batch 900] loss: 0.03125675296818372
[Epoch 13, Batch 1000] loss: 0.04405532401389792
[Epoch 13, Batch 1100] loss: 0.03477426258090418
[Epoch 13, Batch 1200] loss: 0.029247820634336678
[Epoch 13, Batch 1300] loss: 0.04031382026907522
[Epoch 13, Batch 1400] loss: 0.04293176497230888
[Epoch 13, Batch 1500] loss: 0.044438766349485376
[Epoch 13, Batch 1600] loss: 0.04378175507838023
[Epoch 13, Batch 1700] loss: 0.04231429632243817
[Epoch 13, Batch 1800] loss: 0.02858443718578201
[Epoch 13, Batch 1900] loss: 0.02946460453720647
[Epoch 13, Batch 2000] loss: 0.04032846729969606
[Epoch 13, Batch 2100] loss: 0.04263582893676357
[Epoch 13, Batch 2200] loss: 0.03270363636140246
[Epoch 13, Batch 2300] loss: 0.03093450326443417
[Epoch 13, Batch 2400] loss: 0.035328310641198186
[Epoch 13, Batch 2500] loss: 0.034737097248071225
[Epoch 13, Batch 2600] loss: 0.031967772302305096
[Epoch 13, Batch 2700] loss: 0.039536028962174896
[Epoch 13, Batch 2800] loss: 0.03295189865719294
[Epoch 13, Batch 2900] loss: 0.026134843337094937
[Epoch 13, Batch 3000] loss: 0.027432838255772366
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9848
Overfitting: 0.0529
[Epoch 14, Batch 100] loss: 0.021100737155793466
[Epoch 14, Batch 200] loss: 0.02480117591760063
[Epoch 14, Batch 300] loss: 0.028939803872272022
[Epoch 14, Batch 400] loss: 0.02806639041758899
[Epoch 14, Batch 500] loss: 0.04320417604474642
[Epoch 14, Batch 600] loss: 0.04074719863856444
[Epoch 14, Batch 700] loss: 0.027960298359394075
[Epoch 14, Batch 800] loss: 0.02802922049333574
[Epoch 14, Batch 900] loss: 0.03606568579183658
[Epoch 14, Batch 1000] loss: 0.03402253957930952
[Epoch 14, Batch 1100] loss: 0.04122291343948745
[Epoch 14, Batch 1200] loss: 0.032233062587329185
[Epoch 14, Batch 1300] loss: 0.025328009355362155
[Epoch 14, Batch 1400] loss: 0.0371774924541387
[Epoch 14, Batch 1500] loss: 0.028545163913513534
[Epoch 14, Batch 1600] loss: 0.03696674963954138
[Epoch 14, Batch 1700] loss: 0.032995008779689666
[Epoch 14, Batch 1800] loss: 0.0470184010900266
[Epoch 14, Batch 1900] loss: 0.030330843603442192
[Epoch 14, Batch 2000] loss: 0.033297349114582174
[Epoch 14, Batch 2100] loss: 0.03773309647469432
[Epoch 14, Batch 2200] loss: 0.026367819763399893
[Epoch 14, Batch 2300] loss: 0.025743769971595613
[Epoch 14, Batch 2400] loss: 0.028998564502471708
[Epoch 14, Batch 2500] loss: 0.03232364635085105
[Epoch 14, Batch 2600] loss: 0.03657863195883692
[Epoch 14, Batch 2700] loss: 0.03839704543031985
[Epoch 14, Batch 2800] loss: 0.019605822310768416
[Epoch 14, Batch 2900] loss: 0.020889159278049192
[Epoch 14, Batch 3000] loss: 0.030700667400451492
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9835
Overfitting: 0.0536
[Epoch 15, Batch 100] loss: 0.029701098653968073
[Epoch 15, Batch 200] loss: 0.02662714910140494
[Epoch 15, Batch 300] loss: 0.03199444389363634
[Epoch 15, Batch 400] loss: 0.024421779758558842
[Epoch 15, Batch 500] loss: 0.029929418684041594
[Epoch 15, Batch 600] loss: 0.022685573500639294
[Epoch 15, Batch 700] loss: 0.020157433268323074
[Epoch 15, Batch 800] loss: 0.03412019913041149
[Epoch 15, Batch 900] loss: 0.028273341081949184
[Epoch 15, Batch 1000] loss: 0.0387942379348533
[Epoch 15, Batch 1100] loss: 0.027617761213405173
[Epoch 15, Batch 1200] loss: 0.027913427346356913
[Epoch 15, Batch 1300] loss: 0.0227089790275204
[Epoch 15, Batch 1400] loss: 0.028046750400244493
[Epoch 15, Batch 1500] loss: 0.029590397246793146
[Epoch 15, Batch 1600] loss: 0.027780803272034974
[Epoch 15, Batch 1700] loss: 0.03605069548255415
[Epoch 15, Batch 1800] loss: 0.045737372970324944
[Epoch 15, Batch 1900] loss: 0.017483472465028172
[Epoch 15, Batch 2000] loss: 0.030410280811047415
[Epoch 15, Batch 2100] loss: 0.027703509632847272
[Epoch 15, Batch 2200] loss: 0.02915705515188165
[Epoch 15, Batch 2300] loss: 0.02689228571485728
[Epoch 15, Batch 2400] loss: 0.03401679218331992
[Epoch 15, Batch 2500] loss: 0.029099833819345805
[Epoch 15, Batch 2600] loss: 0.026651660229254047
[Epoch 15, Batch 2700] loss: 0.03255378595204093
[Epoch 15, Batch 2800] loss: 0.0321528313626186
[Epoch 15, Batch 2900] loss: 0.029847162780861254
[Epoch 15, Batch 3000] loss: 0.04684282372356392
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9861
Overfitting: 0.0510
[Epoch 16, Batch 100] loss: 0.030918777565384515
[Epoch 16, Batch 200] loss: 0.03279163801780669
[Epoch 16, Batch 300] loss: 0.02094600427473779
[Epoch 16, Batch 400] loss: 0.0265084984657733
[Epoch 16, Batch 500] loss: 0.029469131678633857
[Epoch 16, Batch 600] loss: 0.022074114929200733
[Epoch 16, Batch 700] loss: 0.02292815194479772
[Epoch 16, Batch 800] loss: 0.023037741540319984
[Epoch 16, Batch 900] loss: 0.02319338301116659
[Epoch 16, Batch 1000] loss: 0.031850921558216214
[Epoch 16, Batch 1100] loss: 0.02378195294048055
[Epoch 16, Batch 1200] loss: 0.02858949774868961
[Epoch 16, Batch 1300] loss: 0.02180336056091619
[Epoch 16, Batch 1400] loss: 0.027907678996416507
[Epoch 16, Batch 1500] loss: 0.028805398596305168
[Epoch 16, Batch 1600] loss: 0.028719352186089963
[Epoch 16, Batch 1700] loss: 0.031239502344433276
[Epoch 16, Batch 1800] loss: 0.03019443962359219
[Epoch 16, Batch 1900] loss: 0.03344574383867439
[Epoch 16, Batch 2000] loss: 0.035752756899019
[Epoch 16, Batch 2100] loss: 0.02866609731223434
[Epoch 16, Batch 2200] loss: 0.03149836366719683
[Epoch 16, Batch 2300] loss: 0.02997334943531314
[Epoch 16, Batch 2400] loss: 0.023888689789528142
[Epoch 16, Batch 2500] loss: 0.027684624234716466
[Epoch 16, Batch 2600] loss: 0.02713615754371858
[Epoch 16, Batch 2700] loss: 0.028405184778384863
[Epoch 16, Batch 2800] loss: 0.012719925388955744
[Epoch 16, Batch 2900] loss: 0.03119787067218567
[Epoch 16, Batch 3000] loss: 0.024122432062431472
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9853
Overfitting: 0.0496
Best model saved at epoch 16 with validation loss: 0.0496
[Epoch 17, Batch 100] loss: 0.02199507537749014
[Epoch 17, Batch 200] loss: 0.019458881859027315
[Epoch 17, Batch 300] loss: 0.016063647451810537
[Epoch 17, Batch 400] loss: 0.021824620587722166
[Epoch 17, Batch 500] loss: 0.024688293645667728
[Epoch 17, Batch 600] loss: 0.02338662945985561
[Epoch 17, Batch 700] loss: 0.01900054661615286
[Epoch 17, Batch 800] loss: 0.02102484671806451
[Epoch 17, Batch 900] loss: 0.025483592183300062
[Epoch 17, Batch 1000] loss: 0.02484376221169441
[Epoch 17, Batch 1100] loss: 0.02857966192816093
[Epoch 17, Batch 1200] loss: 0.027804058847650595
[Epoch 17, Batch 1300] loss: 0.01663175232533831
[Epoch 17, Batch 1400] loss: 0.02219386630848021
[Epoch 17, Batch 1500] loss: 0.03003476752739516
[Epoch 17, Batch 1600] loss: 0.029773524454813013
[Epoch 17, Batch 1700] loss: 0.035913329890536264
[Epoch 17, Batch 1800] loss: 0.026432495448170813
[Epoch 17, Batch 1900] loss: 0.032359419810236434
[Epoch 17, Batch 2000] loss: 0.04279122729349183
[Epoch 17, Batch 2100] loss: 0.025719783383392494
[Epoch 17, Batch 2200] loss: 0.03336276321373589
[Epoch 17, Batch 2300] loss: 0.02662244729915983
[Epoch 17, Batch 2400] loss: 0.03906203339058265
[Epoch 17, Batch 2500] loss: 0.027054343575582607
[Epoch 17, Batch 2600] loss: 0.022276301990277716
[Epoch 17, Batch 2700] loss: 0.03937620190961752
[Epoch 17, Batch 2800] loss: 0.015185802063497249
[Epoch 17, Batch 2900] loss: 0.01981255823178799
[Epoch 17, Batch 3000] loss: 0.01994881552986044
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9861
Overfitting: 0.0495
Best model saved at epoch 17 with validation loss: 0.0495
[Epoch 18, Batch 100] loss: 0.01715179625436576
[Epoch 18, Batch 200] loss: 0.021626981516528757
[Epoch 18, Batch 300] loss: 0.02016076551095466
[Epoch 18, Batch 400] loss: 0.03144667923566885
[Epoch 18, Batch 500] loss: 0.02267967944877455
[Epoch 18, Batch 600] loss: 0.021309189939129284
[Epoch 18, Batch 700] loss: 0.019678768094308907
[Epoch 18, Batch 800] loss: 0.026557159681397026
[Epoch 18, Batch 900] loss: 0.02022178302941029
[Epoch 18, Batch 1000] loss: 0.01982454920638702
[Epoch 18, Batch 1100] loss: 0.03777169038192369
[Epoch 18, Batch 1200] loss: 0.021904246251215228
[Epoch 18, Batch 1300] loss: 0.030626252498477696
[Epoch 18, Batch 1400] loss: 0.024248133816618066
[Epoch 18, Batch 1500] loss: 0.01943670109179948
[Epoch 18, Batch 1600] loss: 0.02525138265260466
[Epoch 18, Batch 1700] loss: 0.017699416870891584
[Epoch 18, Batch 1800] loss: 0.026131354017561535
[Epoch 18, Batch 1900] loss: 0.02555033862416167
[Epoch 18, Batch 2000] loss: 0.022053136832255404
[Epoch 18, Batch 2100] loss: 0.03119342023288482
[Epoch 18, Batch 2200] loss: 0.028469963299576195
[Epoch 18, Batch 2300] loss: 0.018920384578232186
[Epoch 18, Batch 2400] loss: 0.022834928744523496
[Epoch 18, Batch 2500] loss: 0.016310998595581622
[Epoch 18, Batch 2600] loss: 0.0190601271824562
[Epoch 18, Batch 2700] loss: 0.01707887033073348
[Epoch 18, Batch 2800] loss: 0.017998650109184382
[Epoch 18, Batch 2900] loss: 0.02401017795993539
[Epoch 18, Batch 3000] loss: 0.031140597860139677
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0646
Validation Accuracy: 0.9802
Overfitting: 0.0646
[Epoch 19, Batch 100] loss: 0.016419202466313437
[Epoch 19, Batch 200] loss: 0.018838954226594068
[Epoch 19, Batch 300] loss: 0.024329495930760458
[Epoch 19, Batch 400] loss: 0.02589480651935446
[Epoch 19, Batch 500] loss: 0.01476947677852877
[Epoch 19, Batch 600] loss: 0.016133318901993335
[Epoch 19, Batch 700] loss: 0.02608961849124171
[Epoch 19, Batch 800] loss: 0.01086924844297755
[Epoch 19, Batch 900] loss: 0.018526690553480874
[Epoch 19, Batch 1000] loss: 0.018264077664061917
[Epoch 19, Batch 1100] loss: 0.018088542315672383
[Epoch 19, Batch 1200] loss: 0.029010788556843182
[Epoch 19, Batch 1300] loss: 0.01718872220175399
[Epoch 19, Batch 1400] loss: 0.02252815605399519
[Epoch 19, Batch 1500] loss: 0.019122026855911828
[Epoch 19, Batch 1600] loss: 0.021997168130183126
[Epoch 19, Batch 1700] loss: 0.028451112189213746
[Epoch 19, Batch 1800] loss: 0.023380886378854483
[Epoch 19, Batch 1900] loss: 0.022193725684010134
[Epoch 19, Batch 2000] loss: 0.025989165474748006
[Epoch 19, Batch 2100] loss: 0.026753329777820908
[Epoch 19, Batch 2200] loss: 0.03304648409728543
[Epoch 19, Batch 2300] loss: 0.016174383212346585
[Epoch 19, Batch 2400] loss: 0.016382911905820946
[Epoch 19, Batch 2500] loss: 0.02691493971804448
[Epoch 19, Batch 2600] loss: 0.018631152522430056
[Epoch 19, Batch 2700] loss: 0.02459039390014368
[Epoch 19, Batch 2800] loss: 0.019517079366123652
[Epoch 19, Batch 2900] loss: 0.02006113435876614
[Epoch 19, Batch 3000] loss: 0.021374923958210276
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9858
Overfitting: 0.0483
Best model saved at epoch 19 with validation loss: 0.0483
[Epoch 20, Batch 100] loss: 0.018274476242659148
[Epoch 20, Batch 200] loss: 0.020633579278510297
[Epoch 20, Batch 300] loss: 0.025997732850082684
[Epoch 20, Batch 400] loss: 0.011423558405494987
[Epoch 20, Batch 500] loss: 0.018473649739753455
[Epoch 20, Batch 600] loss: 0.016512722536863294
[Epoch 20, Batch 700] loss: 0.02018579686700832
[Epoch 20, Batch 800] loss: 0.025467707057705413
[Epoch 20, Batch 900] loss: 0.02668315223792888
[Epoch 20, Batch 1000] loss: 0.020118544368197034
[Epoch 20, Batch 1100] loss: 0.011397152006757096
[Epoch 20, Batch 1200] loss: 0.028547133480933552
[Epoch 20, Batch 1300] loss: 0.016860056201039697
[Epoch 20, Batch 1400] loss: 0.019470871835001163
[Epoch 20, Batch 1500] loss: 0.022683550777073833
[Epoch 20, Batch 1600] loss: 0.029898898919927887
[Epoch 20, Batch 1700] loss: 0.020151504422610742
[Epoch 20, Batch 1800] loss: 0.01789944584494151
[Epoch 20, Batch 1900] loss: 0.01948069713620498
[Epoch 20, Batch 2000] loss: 0.016899837552336976
[Epoch 20, Batch 2100] loss: 0.026445182405186642
[Epoch 20, Batch 2200] loss: 0.016862159482079732
[Epoch 20, Batch 2300] loss: 0.0134287576000861
[Epoch 20, Batch 2400] loss: 0.015468832212936831
[Epoch 20, Batch 2500] loss: 0.023816259120067115
[Epoch 20, Batch 2600] loss: 0.01843108504646807
[Epoch 20, Batch 2700] loss: 0.012725641097840707
[Epoch 20, Batch 2800] loss: 0.024556758035196254
[Epoch 20, Batch 2900] loss: 0.018754569622706184
[Epoch 20, Batch 3000] loss: 0.028440100658172013
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9856
Overfitting: 0.0495
[Epoch 21, Batch 100] loss: 0.014062050559950877
[Epoch 21, Batch 200] loss: 0.020320704865516747
[Epoch 21, Batch 300] loss: 0.02477345924664405
[Epoch 21, Batch 400] loss: 0.01929139902746101
[Epoch 21, Batch 500] loss: 0.01587107813469629
[Epoch 21, Batch 600] loss: 0.021319119548861634
[Epoch 21, Batch 700] loss: 0.020359948453115066
[Epoch 21, Batch 800] loss: 0.018967983808688586
[Epoch 21, Batch 900] loss: 0.01984273139212746
[Epoch 21, Batch 1000] loss: 0.029874692318953747
[Epoch 21, Batch 1100] loss: 0.019641353635379347
[Epoch 21, Batch 1200] loss: 0.013467581659715505
[Epoch 21, Batch 1300] loss: 0.023210132528474786
[Epoch 21, Batch 1400] loss: 0.01791799871440162
[Epoch 21, Batch 1500] loss: 0.0270082186945001
[Epoch 21, Batch 1600] loss: 0.014235936930417666
[Epoch 21, Batch 1700] loss: 0.016099290135680348
[Epoch 21, Batch 1800] loss: 0.011992325833052746
[Epoch 21, Batch 1900] loss: 0.021290795969689497
[Epoch 21, Batch 2000] loss: 0.014491928094939795
[Epoch 21, Batch 2100] loss: 0.020468763986136763
[Epoch 21, Batch 2200] loss: 0.0196771819415153
[Epoch 21, Batch 2300] loss: 0.01532723580417951
[Epoch 21, Batch 2400] loss: 0.020348082014643297
[Epoch 21, Batch 2500] loss: 0.023370219264543267
[Epoch 21, Batch 2600] loss: 0.020632777543250994
[Epoch 21, Batch 2700] loss: 0.022266961584609817
[Epoch 21, Batch 2800] loss: 0.02494106518701301
[Epoch 21, Batch 2900] loss: 0.02042394115949719
[Epoch 21, Batch 3000] loss: 0.014221059010378668
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0541
Validation Accuracy: 0.9845
Overfitting: 0.0541
[Epoch 22, Batch 100] loss: 0.015248723549457282
[Epoch 22, Batch 200] loss: 0.024336445966746396
[Epoch 22, Batch 300] loss: 0.015335591364928404
[Epoch 22, Batch 400] loss: 0.020835066761210327
[Epoch 22, Batch 500] loss: 0.009681716473023698
[Epoch 22, Batch 600] loss: 0.011970481616554025
[Epoch 22, Batch 700] loss: 0.017999134207857422
[Epoch 22, Batch 800] loss: 0.020141465642564072
[Epoch 22, Batch 900] loss: 0.021997310393689986
[Epoch 22, Batch 1000] loss: 0.01644404370978009
[Epoch 22, Batch 1100] loss: 0.0198082145434455
[Epoch 22, Batch 1200] loss: 0.01908854413912195
[Epoch 22, Batch 1300] loss: 0.019202581311801623
[Epoch 22, Batch 1400] loss: 0.01359452320022683
[Epoch 22, Batch 1500] loss: 0.01349560637947434
[Epoch 22, Batch 1600] loss: 0.014984611804538871
[Epoch 22, Batch 1700] loss: 0.014132558432793303
[Epoch 22, Batch 1800] loss: 0.02053480797520024
[Epoch 22, Batch 1900] loss: 0.01786030876726727
[Epoch 22, Batch 2000] loss: 0.019282481453265065
[Epoch 22, Batch 2100] loss: 0.014444489132838498
[Epoch 22, Batch 2200] loss: 0.02581105440222018
[Epoch 22, Batch 2300] loss: 0.01400390855025762
[Epoch 22, Batch 2400] loss: 0.019390230151821015
[Epoch 22, Batch 2500] loss: 0.0150885701146035
[Epoch 22, Batch 2600] loss: 0.013076864895192558
[Epoch 22, Batch 2700] loss: 0.022813172050991853
[Epoch 22, Batch 2800] loss: 0.021927803149173995
[Epoch 22, Batch 2900] loss: 0.013162701636902056
[Epoch 22, Batch 3000] loss: 0.026541639738115918
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9865
Overfitting: 0.0463
Best model saved at epoch 22 with validation loss: 0.0463
[Epoch 23, Batch 100] loss: 0.012504742650562548
[Epoch 23, Batch 200] loss: 0.01731926383989048
[Epoch 23, Batch 300] loss: 0.009678071502639796
[Epoch 23, Batch 400] loss: 0.01216855397571635
[Epoch 23, Batch 500] loss: 0.010175309884789385
[Epoch 23, Batch 600] loss: 0.01572712416644208
[Epoch 23, Batch 700] loss: 0.01881866857824207
[Epoch 23, Batch 800] loss: 0.012533115376318165
[Epoch 23, Batch 900] loss: 0.021858651967149853
[Epoch 23, Batch 1000] loss: 0.025740959992544957
[Epoch 23, Batch 1100] loss: 0.014356912497278244
[Epoch 23, Batch 1200] loss: 0.01332952192362427
[Epoch 23, Batch 1300] loss: 0.012936625557995286
[Epoch 23, Batch 1400] loss: 0.014328328198971577
[Epoch 23, Batch 1500] loss: 0.014518002498007263
[Epoch 23, Batch 1600] loss: 0.015131339367035252
[Epoch 23, Batch 1700] loss: 0.014415666823588254
[Epoch 23, Batch 1800] loss: 0.019005456514132674
[Epoch 23, Batch 1900] loss: 0.016626149245166744
[Epoch 23, Batch 2000] loss: 0.021004460712756554
[Epoch 23, Batch 2100] loss: 0.017785001821321204
[Epoch 23, Batch 2200] loss: 0.01301034190091741
[Epoch 23, Batch 2300] loss: 0.014511579589561735
[Epoch 23, Batch 2400] loss: 0.014741154070306947
[Epoch 23, Batch 2500] loss: 0.021944648391217923
[Epoch 23, Batch 2600] loss: 0.013635951857431793
[Epoch 23, Batch 2700] loss: 0.01561639384199225
[Epoch 23, Batch 2800] loss: 0.021250926253942454
[Epoch 23, Batch 2900] loss: 0.012932370454873308
[Epoch 23, Batch 3000] loss: 0.013709319063345903
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9850
Overfitting: 0.0513
[Epoch 24, Batch 100] loss: 0.012172191587669658
[Epoch 24, Batch 200] loss: 0.012739086187357316
[Epoch 24, Batch 300] loss: 0.010658488462613604
[Epoch 24, Batch 400] loss: 0.0172644849871358
[Epoch 24, Batch 500] loss: 0.02367837192301522
[Epoch 24, Batch 600] loss: 0.010872728234862733
[Epoch 24, Batch 700] loss: 0.013605783546881866
[Epoch 24, Batch 800] loss: 0.009806481613341021
[Epoch 24, Batch 900] loss: 0.01481044527306949
[Epoch 24, Batch 1000] loss: 0.012235208439378767
[Epoch 24, Batch 1100] loss: 0.019943750413876842
[Epoch 24, Batch 1200] loss: 0.014174254378594923
[Epoch 24, Batch 1300] loss: 0.009050503925245722
[Epoch 24, Batch 1400] loss: 0.01311597442443599
[Epoch 24, Batch 1500] loss: 0.015729783176138882
[Epoch 24, Batch 1600] loss: 0.0160606494163585
[Epoch 24, Batch 1700] loss: 0.012897127656287921
[Epoch 24, Batch 1800] loss: 0.013166270873171015
[Epoch 24, Batch 1900] loss: 0.01780848892420181
[Epoch 24, Batch 2000] loss: 0.014470056499012571
[Epoch 24, Batch 2100] loss: 0.020774935125427874
[Epoch 24, Batch 2200] loss: 0.014824642526691604
[Epoch 24, Batch 2300] loss: 0.015352683695391533
[Epoch 24, Batch 2400] loss: 0.019426039534537268
[Epoch 24, Batch 2500] loss: 0.01902941266012931
[Epoch 24, Batch 2600] loss: 0.013478318217967172
[Epoch 24, Batch 2700] loss: 0.020418537163204745
[Epoch 24, Batch 2800] loss: 0.0068825924813245365
[Epoch 24, Batch 2900] loss: 0.008498964095097108
[Epoch 24, Batch 3000] loss: 0.016941937367409992
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9862
Overfitting: 0.0480
Fold 3 validation loss: 0.0480
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.298512933254242
[Epoch 1, Batch 200] loss: 2.279342863559723
[Epoch 1, Batch 300] loss: 2.2646020102500914
[Epoch 1, Batch 400] loss: 2.239674460887909
[Epoch 1, Batch 500] loss: 2.198304100036621
[Epoch 1, Batch 600] loss: 2.1277512133121492
[Epoch 1, Batch 700] loss: 1.9812964630126952
[Epoch 1, Batch 800] loss: 1.7106491005420685
[Epoch 1, Batch 900] loss: 1.313235529065132
[Epoch 1, Batch 1000] loss: 0.9552547720074653
[Epoch 1, Batch 1100] loss: 0.7214501237869263
[Epoch 1, Batch 1200] loss: 0.5584323851764202
[Epoch 1, Batch 1300] loss: 0.562127538472414
[Epoch 1, Batch 1400] loss: 0.47514621064066886
[Epoch 1, Batch 1500] loss: 0.46002217307686805
[Epoch 1, Batch 1600] loss: 0.4345152051746845
[Epoch 1, Batch 1700] loss: 0.4560802077874541
[Epoch 1, Batch 1800] loss: 0.42286445312201976
[Epoch 1, Batch 1900] loss: 0.3674142221361399
[Epoch 1, Batch 2000] loss: 0.35229310460388663
[Epoch 1, Batch 2100] loss: 0.38112316802144053
[Epoch 1, Batch 2200] loss: 0.32635286064818503
[Epoch 1, Batch 2300] loss: 0.29010670371353625
[Epoch 1, Batch 2400] loss: 0.28316277589648964
[Epoch 1, Batch 2500] loss: 0.3015305770561099
[Epoch 1, Batch 2600] loss: 0.2548596701025963
[Epoch 1, Batch 2700] loss: 0.22360595520585774
[Epoch 1, Batch 2800] loss: 0.24744370934553445
[Epoch 1, Batch 2900] loss: 0.24252111732959747
[Epoch 1, Batch 3000] loss: 0.2765945538133383
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2342
Validation Accuracy: 0.9285
Overfitting: 0.2342
Best model saved at epoch 1 with validation loss: 0.2342
[Epoch 2, Batch 100] loss: 0.23988976441323756
[Epoch 2, Batch 200] loss: 0.21305978303775192
[Epoch 2, Batch 300] loss: 0.20207445947453379
[Epoch 2, Batch 400] loss: 0.2064806287176907
[Epoch 2, Batch 500] loss: 0.20516464257612824
[Epoch 2, Batch 600] loss: 0.21776251764968038
[Epoch 2, Batch 700] loss: 0.17702924501150846
[Epoch 2, Batch 800] loss: 0.2007059234008193
[Epoch 2, Batch 900] loss: 0.18188688555732369
[Epoch 2, Batch 1000] loss: 0.21415964586660266
[Epoch 2, Batch 1100] loss: 0.16565576842054724
[Epoch 2, Batch 1200] loss: 0.20501265631057322
[Epoch 2, Batch 1300] loss: 0.1899610066972673
[Epoch 2, Batch 1400] loss: 0.21199404234066604
[Epoch 2, Batch 1500] loss: 0.18006264859810472
[Epoch 2, Batch 1600] loss: 0.15133690137416125
[Epoch 2, Batch 1700] loss: 0.16193276356905698
[Epoch 2, Batch 1800] loss: 0.18124929220881314
[Epoch 2, Batch 1900] loss: 0.14724406633526088
[Epoch 2, Batch 2000] loss: 0.13869438831694425
[Epoch 2, Batch 2100] loss: 0.13986584801692514
[Epoch 2, Batch 2200] loss: 0.14000357289798557
[Epoch 2, Batch 2300] loss: 0.1525944072380662
[Epoch 2, Batch 2400] loss: 0.12776311358436943
[Epoch 2, Batch 2500] loss: 0.13360140092205255
[Epoch 2, Batch 2600] loss: 0.12294493469875306
[Epoch 2, Batch 2700] loss: 0.12383670144714415
[Epoch 2, Batch 2800] loss: 0.13538161830976606
[Epoch 2, Batch 2900] loss: 0.13911221948917954
[Epoch 2, Batch 3000] loss: 0.13539990347344427
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1265
Validation Accuracy: 0.9600
Overfitting: 0.1265
Best model saved at epoch 2 with validation loss: 0.1265
[Epoch 3, Batch 100] loss: 0.11370032924227416
[Epoch 3, Batch 200] loss: 0.10352845893241465
[Epoch 3, Batch 300] loss: 0.13190131867304444
[Epoch 3, Batch 400] loss: 0.10184890519827604
[Epoch 3, Batch 500] loss: 0.14298988852649927
[Epoch 3, Batch 600] loss: 0.10438504809513688
[Epoch 3, Batch 700] loss: 0.1255198852205649
[Epoch 3, Batch 800] loss: 0.11316367882303893
[Epoch 3, Batch 900] loss: 0.1346212942665443
[Epoch 3, Batch 1000] loss: 0.14513444187119603
[Epoch 3, Batch 1100] loss: 0.13825304757338017
[Epoch 3, Batch 1200] loss: 0.11316938722971827
[Epoch 3, Batch 1300] loss: 0.12898344638291748
[Epoch 3, Batch 1400] loss: 0.12345681346952915
[Epoch 3, Batch 1500] loss: 0.095026177149266
[Epoch 3, Batch 1600] loss: 0.10544565784744918
[Epoch 3, Batch 1700] loss: 0.11159594729542732
[Epoch 3, Batch 1800] loss: 0.10083016113145277
[Epoch 3, Batch 1900] loss: 0.10752276574494317
[Epoch 3, Batch 2000] loss: 0.1158054293319583
[Epoch 3, Batch 2100] loss: 0.11444059153553099
[Epoch 3, Batch 2200] loss: 0.10352328145410866
[Epoch 3, Batch 2300] loss: 0.11311493396991863
[Epoch 3, Batch 2400] loss: 0.11722590581746772
[Epoch 3, Batch 2500] loss: 0.114488859558478
[Epoch 3, Batch 2600] loss: 0.07953554586041718
[Epoch 3, Batch 2700] loss: 0.08583219783380627
[Epoch 3, Batch 2800] loss: 0.09169498017407023
[Epoch 3, Batch 2900] loss: 0.10355855294503272
[Epoch 3, Batch 3000] loss: 0.10063933863304556
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1008
Validation Accuracy: 0.9701
Overfitting: 0.1008
Best model saved at epoch 3 with validation loss: 0.1008
[Epoch 4, Batch 100] loss: 0.08163035172736272
[Epoch 4, Batch 200] loss: 0.09476383529021405
[Epoch 4, Batch 300] loss: 0.10673471097135917
[Epoch 4, Batch 400] loss: 0.07438933013705537
[Epoch 4, Batch 500] loss: 0.0867518660495989
[Epoch 4, Batch 600] loss: 0.10942889524274506
[Epoch 4, Batch 700] loss: 0.11265042603947223
[Epoch 4, Batch 800] loss: 0.10530304176500067
[Epoch 4, Batch 900] loss: 0.11214470078470186
[Epoch 4, Batch 1000] loss: 0.10523952922550961
[Epoch 4, Batch 1100] loss: 0.08234330766834319
[Epoch 4, Batch 1200] loss: 0.09695773116662167
[Epoch 4, Batch 1300] loss: 0.07363883077865467
[Epoch 4, Batch 1400] loss: 0.08368472897622269
[Epoch 4, Batch 1500] loss: 0.08086282891454175
[Epoch 4, Batch 1600] loss: 0.07582249294500798
[Epoch 4, Batch 1700] loss: 0.08335269175004215
[Epoch 4, Batch 1800] loss: 0.0784236064599827
[Epoch 4, Batch 1900] loss: 0.05973112377920188
[Epoch 4, Batch 2000] loss: 0.07297726157936267
[Epoch 4, Batch 2100] loss: 0.09631917269784025
[Epoch 4, Batch 2200] loss: 0.07292536936933175
[Epoch 4, Batch 2300] loss: 0.08049891291419044
[Epoch 4, Batch 2400] loss: 0.09236153556499631
[Epoch 4, Batch 2500] loss: 0.08190805059857667
[Epoch 4, Batch 2600] loss: 0.08987285535549745
[Epoch 4, Batch 2700] loss: 0.09668328690342605
[Epoch 4, Batch 2800] loss: 0.07762162394355983
[Epoch 4, Batch 2900] loss: 0.07091687014326453
[Epoch 4, Batch 3000] loss: 0.11470435443916357
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0841
Validation Accuracy: 0.9738
Overfitting: 0.0841
Best model saved at epoch 4 with validation loss: 0.0841
[Epoch 5, Batch 100] loss: 0.082543260990642
[Epoch 5, Batch 200] loss: 0.07686073541059159
[Epoch 5, Batch 300] loss: 0.09742553922580555
[Epoch 5, Batch 400] loss: 0.0705445280537242
[Epoch 5, Batch 500] loss: 0.08299091965891421
[Epoch 5, Batch 600] loss: 0.07486401772941463
[Epoch 5, Batch 700] loss: 0.07210093736532144
[Epoch 5, Batch 800] loss: 0.11000244192779064
[Epoch 5, Batch 900] loss: 0.07315414829645306
[Epoch 5, Batch 1000] loss: 0.0778386892506387
[Epoch 5, Batch 1100] loss: 0.07154229091014713
[Epoch 5, Batch 1200] loss: 0.08092426217277535
[Epoch 5, Batch 1300] loss: 0.07310206723632291
[Epoch 5, Batch 1400] loss: 0.07845240443130023
[Epoch 5, Batch 1500] loss: 0.07410782236140222
[Epoch 5, Batch 1600] loss: 0.06375956369913183
[Epoch 5, Batch 1700] loss: 0.07498724336270243
[Epoch 5, Batch 1800] loss: 0.07813216166337952
[Epoch 5, Batch 1900] loss: 0.06492744565708562
[Epoch 5, Batch 2000] loss: 0.08706056939670816
[Epoch 5, Batch 2100] loss: 0.05928684900572989
[Epoch 5, Batch 2200] loss: 0.07018699046573601
[Epoch 5, Batch 2300] loss: 0.07650532634579577
[Epoch 5, Batch 2400] loss: 0.0635199321527034
[Epoch 5, Batch 2500] loss: 0.06784218255896121
[Epoch 5, Batch 2600] loss: 0.06735999640775844
[Epoch 5, Batch 2700] loss: 0.07166314728092402
[Epoch 5, Batch 2800] loss: 0.06632588702253997
[Epoch 5, Batch 2900] loss: 0.07396173495159018
[Epoch 5, Batch 3000] loss: 0.05245951451943256
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0697
Validation Accuracy: 0.9780
Overfitting: 0.0697
Best model saved at epoch 5 with validation loss: 0.0697
[Epoch 6, Batch 100] loss: 0.05614669046015479
[Epoch 6, Batch 200] loss: 0.05994767955620773
[Epoch 6, Batch 300] loss: 0.06499488432600628
[Epoch 6, Batch 400] loss: 0.0801675930674537
[Epoch 6, Batch 500] loss: 0.05255613158573397
[Epoch 6, Batch 600] loss: 0.05823589126113802
[Epoch 6, Batch 700] loss: 0.08989753674133681
[Epoch 6, Batch 800] loss: 0.07419956318452023
[Epoch 6, Batch 900] loss: 0.06112935031531379
[Epoch 6, Batch 1000] loss: 0.08264347943360917
[Epoch 6, Batch 1100] loss: 0.06206549603899475
[Epoch 6, Batch 1200] loss: 0.05351369923155289
[Epoch 6, Batch 1300] loss: 0.06312006893800572
[Epoch 6, Batch 1400] loss: 0.06740401814255165
[Epoch 6, Batch 1500] loss: 0.06503379067289643
[Epoch 6, Batch 1600] loss: 0.07159737331152428
[Epoch 6, Batch 1700] loss: 0.0679461686545983
[Epoch 6, Batch 1800] loss: 0.05957095813471824
[Epoch 6, Batch 1900] loss: 0.07294536212692038
[Epoch 6, Batch 2000] loss: 0.056289797666249794
[Epoch 6, Batch 2100] loss: 0.05793429409328382
[Epoch 6, Batch 2200] loss: 0.07573737071128563
[Epoch 6, Batch 2300] loss: 0.056322711671236904
[Epoch 6, Batch 2400] loss: 0.08743336655257736
[Epoch 6, Batch 2500] loss: 0.06597238984773866
[Epoch 6, Batch 2600] loss: 0.06766651501064189
[Epoch 6, Batch 2700] loss: 0.06381977576646022
[Epoch 6, Batch 2800] loss: 0.05817827165708877
[Epoch 6, Batch 2900] loss: 0.06801762251532636
[Epoch 6, Batch 3000] loss: 0.06651749255484901
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0614
Validation Accuracy: 0.9819
Overfitting: 0.0614
Best model saved at epoch 6 with validation loss: 0.0614
[Epoch 7, Batch 100] loss: 0.06751702454988845
[Epoch 7, Batch 200] loss: 0.05250925966072827
[Epoch 7, Batch 300] loss: 0.055840204855194316
[Epoch 7, Batch 400] loss: 0.05681664927338716
[Epoch 7, Batch 500] loss: 0.05691804251691792
[Epoch 7, Batch 600] loss: 0.03830578730267007
[Epoch 7, Batch 700] loss: 0.04791772271855734
[Epoch 7, Batch 800] loss: 0.06592761901789344
[Epoch 7, Batch 900] loss: 0.06508725352876354
[Epoch 7, Batch 1000] loss: 0.04737988041859353
[Epoch 7, Batch 1100] loss: 0.04126300352218095
[Epoch 7, Batch 1200] loss: 0.048570284928428006
[Epoch 7, Batch 1300] loss: 0.05378758999984711
[Epoch 7, Batch 1400] loss: 0.06205335715756519
[Epoch 7, Batch 1500] loss: 0.048238182486384173
[Epoch 7, Batch 1600] loss: 0.05877809304598486
[Epoch 7, Batch 1700] loss: 0.05966769878694322
[Epoch 7, Batch 1800] loss: 0.06588395156199113
[Epoch 7, Batch 1900] loss: 0.058114507708814926
[Epoch 7, Batch 2000] loss: 0.04116326491290238
[Epoch 7, Batch 2100] loss: 0.06296423217165284
[Epoch 7, Batch 2200] loss: 0.06024516567878891
[Epoch 7, Batch 2300] loss: 0.053554697500076145
[Epoch 7, Batch 2400] loss: 0.049633742165751754
[Epoch 7, Batch 2500] loss: 0.059450401159119794
[Epoch 7, Batch 2600] loss: 0.07281108496244997
[Epoch 7, Batch 2700] loss: 0.06894094339048024
[Epoch 7, Batch 2800] loss: 0.06243180109770037
[Epoch 7, Batch 2900] loss: 0.056649652289343065
[Epoch 7, Batch 3000] loss: 0.05004393340903334
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9815
Overfitting: 0.0630
[Epoch 8, Batch 100] loss: 0.05008908419113141
[Epoch 8, Batch 200] loss: 0.04135681944782846
[Epoch 8, Batch 300] loss: 0.05193516218336299
[Epoch 8, Batch 400] loss: 0.04593065277149435
[Epoch 8, Batch 500] loss: 0.05453068397502648
[Epoch 8, Batch 600] loss: 0.053077793151314834
[Epoch 8, Batch 700] loss: 0.0386133603748749
[Epoch 8, Batch 800] loss: 0.04880153121368494
[Epoch 8, Batch 900] loss: 0.06025715507566929
[Epoch 8, Batch 1000] loss: 0.039743297090753915
[Epoch 8, Batch 1100] loss: 0.06371056130912621
[Epoch 8, Batch 1200] loss: 0.05552787029009778
[Epoch 8, Batch 1300] loss: 0.05344143206835725
[Epoch 8, Batch 1400] loss: 0.04993886063341051
[Epoch 8, Batch 1500] loss: 0.06382513371470849
[Epoch 8, Batch 1600] loss: 0.058620240102754906
[Epoch 8, Batch 1700] loss: 0.05151730963552836
[Epoch 8, Batch 1800] loss: 0.059323147734394295
[Epoch 8, Batch 1900] loss: 0.04963328287354671
[Epoch 8, Batch 2000] loss: 0.049069129967829216
[Epoch 8, Batch 2100] loss: 0.044448684939416123
[Epoch 8, Batch 2200] loss: 0.05172575902834069
[Epoch 8, Batch 2300] loss: 0.055716151346277915
[Epoch 8, Batch 2400] loss: 0.04325712223420851
[Epoch 8, Batch 2500] loss: 0.04297531418502331
[Epoch 8, Batch 2600] loss: 0.062067126056645064
[Epoch 8, Batch 2700] loss: 0.05592074691754533
[Epoch 8, Batch 2800] loss: 0.04490279660851229
[Epoch 8, Batch 2900] loss: 0.051765338687691835
[Epoch 8, Batch 3000] loss: 0.05136036660725949
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9793
Overfitting: 0.0635
[Epoch 9, Batch 100] loss: 0.05398864124785177
[Epoch 9, Batch 200] loss: 0.04242492026474792
[Epoch 9, Batch 300] loss: 0.04697733798006084
[Epoch 9, Batch 400] loss: 0.03125146728416439
[Epoch 9, Batch 500] loss: 0.03769840023567667
[Epoch 9, Batch 600] loss: 0.062033138537371996
[Epoch 9, Batch 700] loss: 0.04521905047353357
[Epoch 9, Batch 800] loss: 0.03720788278908003
[Epoch 9, Batch 900] loss: 0.04876238282740815
[Epoch 9, Batch 1000] loss: 0.027263676534057594
[Epoch 9, Batch 1100] loss: 0.05758435306721367
[Epoch 9, Batch 1200] loss: 0.04746746116608847
[Epoch 9, Batch 1300] loss: 0.04802490059664706
[Epoch 9, Batch 1400] loss: 0.044736847193562426
[Epoch 9, Batch 1500] loss: 0.07042132575646974
[Epoch 9, Batch 1600] loss: 0.04270930217346176
[Epoch 9, Batch 1700] loss: 0.048201257273321974
[Epoch 9, Batch 1800] loss: 0.036755362350377255
[Epoch 9, Batch 1900] loss: 0.048423330615041775
[Epoch 9, Batch 2000] loss: 0.05310738233965821
[Epoch 9, Batch 2100] loss: 0.03959208713087719
[Epoch 9, Batch 2200] loss: 0.06828124284395017
[Epoch 9, Batch 2300] loss: 0.036521034513716584
[Epoch 9, Batch 2400] loss: 0.0456073881854536
[Epoch 9, Batch 2500] loss: 0.04158728419308318
[Epoch 9, Batch 2600] loss: 0.03653483848960604
[Epoch 9, Batch 2700] loss: 0.05819584650860634
[Epoch 9, Batch 2800] loss: 0.04702797480858863
[Epoch 9, Batch 2900] loss: 0.043173064881848404
[Epoch 9, Batch 3000] loss: 0.04282656392664649
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0585
Validation Accuracy: 0.9827
Overfitting: 0.0585
Best model saved at epoch 9 with validation loss: 0.0585
[Epoch 10, Batch 100] loss: 0.04634529983624816
[Epoch 10, Batch 200] loss: 0.04351814234803896
[Epoch 10, Batch 300] loss: 0.05341964342544088
[Epoch 10, Batch 400] loss: 0.03228935433900915
[Epoch 10, Batch 500] loss: 0.03916946110912249
[Epoch 10, Batch 600] loss: 0.05039429016876966
[Epoch 10, Batch 700] loss: 0.03997048572316999
[Epoch 10, Batch 800] loss: 0.03633887937990948
[Epoch 10, Batch 900] loss: 0.03320574219513219
[Epoch 10, Batch 1000] loss: 0.05151708353252616
[Epoch 10, Batch 1100] loss: 0.05500140835094498
[Epoch 10, Batch 1200] loss: 0.04594953872438055
[Epoch 10, Batch 1300] loss: 0.030951105776766782
[Epoch 10, Batch 1400] loss: 0.04471271440153941
[Epoch 10, Batch 1500] loss: 0.0391959365142975
[Epoch 10, Batch 1600] loss: 0.03369987088488415
[Epoch 10, Batch 1700] loss: 0.043319253862136975
[Epoch 10, Batch 1800] loss: 0.033606269848532974
[Epoch 10, Batch 1900] loss: 0.04507965490076458
[Epoch 10, Batch 2000] loss: 0.03950946502227452
[Epoch 10, Batch 2100] loss: 0.054378951705875804
[Epoch 10, Batch 2200] loss: 0.03507476495724404
[Epoch 10, Batch 2300] loss: 0.044441020915983245
[Epoch 10, Batch 2400] loss: 0.027685964441043324
[Epoch 10, Batch 2500] loss: 0.043801651133253475
[Epoch 10, Batch 2600] loss: 0.04838951456185896
[Epoch 10, Batch 2700] loss: 0.04885169202811085
[Epoch 10, Batch 2800] loss: 0.04375311071926262
[Epoch 10, Batch 2900] loss: 0.04245432370196795
[Epoch 10, Batch 3000] loss: 0.0268301057361532
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9842
Overfitting: 0.0512
Best model saved at epoch 10 with validation loss: 0.0512
[Epoch 11, Batch 100] loss: 0.03524389548692852
[Epoch 11, Batch 200] loss: 0.03142841926106485
[Epoch 11, Batch 300] loss: 0.029861738720501307
[Epoch 11, Batch 400] loss: 0.035821187653345986
[Epoch 11, Batch 500] loss: 0.04530861363949953
[Epoch 11, Batch 600] loss: 0.05024985039897729
[Epoch 11, Batch 700] loss: 0.03218060948333004
[Epoch 11, Batch 800] loss: 0.04164008469437249
[Epoch 11, Batch 900] loss: 0.04213860818068497
[Epoch 11, Batch 1000] loss: 0.042630685949116016
[Epoch 11, Batch 1100] loss: 0.04052683871705085
[Epoch 11, Batch 1200] loss: 0.03742487932831864
[Epoch 11, Batch 1300] loss: 0.026474090332631022
[Epoch 11, Batch 1400] loss: 0.05070079381010146
[Epoch 11, Batch 1500] loss: 0.032801244954171124
[Epoch 11, Batch 1600] loss: 0.050087009049020706
[Epoch 11, Batch 1700] loss: 0.02801445864373818
[Epoch 11, Batch 1800] loss: 0.036851618237269575
[Epoch 11, Batch 1900] loss: 0.030444144698267336
[Epoch 11, Batch 2000] loss: 0.047083630930501386
[Epoch 11, Batch 2100] loss: 0.04443872097122949
[Epoch 11, Batch 2200] loss: 0.03976490507629933
[Epoch 11, Batch 2300] loss: 0.030458711779792792
[Epoch 11, Batch 2400] loss: 0.028436769982072292
[Epoch 11, Batch 2500] loss: 0.04410702763183508
[Epoch 11, Batch 2600] loss: 0.036410939544002756
[Epoch 11, Batch 2700] loss: 0.050472407584748
[Epoch 11, Batch 2800] loss: 0.04551084280392388
[Epoch 11, Batch 2900] loss: 0.039038325443398206
[Epoch 11, Batch 3000] loss: 0.04094252830633195
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9849
Overfitting: 0.0497
Best model saved at epoch 11 with validation loss: 0.0497
[Epoch 12, Batch 100] loss: 0.030030010510527064
[Epoch 12, Batch 200] loss: 0.026839455201989038
[Epoch 12, Batch 300] loss: 0.028595754114503505
[Epoch 12, Batch 400] loss: 0.024424363935249858
[Epoch 12, Batch 500] loss: 0.05703777621325571
[Epoch 12, Batch 600] loss: 0.030050327230710536
[Epoch 12, Batch 700] loss: 0.03195847713839612
[Epoch 12, Batch 800] loss: 0.03509166418822133
[Epoch 12, Batch 900] loss: 0.037852385892474555
[Epoch 12, Batch 1000] loss: 0.04029691531584831
[Epoch 12, Batch 1100] loss: 0.04505155291655683
[Epoch 12, Batch 1200] loss: 0.03820625868218485
[Epoch 12, Batch 1300] loss: 0.04433434637147002
[Epoch 12, Batch 1400] loss: 0.031154387188289546
[Epoch 12, Batch 1500] loss: 0.04978346748452168
[Epoch 12, Batch 1600] loss: 0.02667673200747231
[Epoch 12, Batch 1700] loss: 0.03479476273743785
[Epoch 12, Batch 1800] loss: 0.037564194755468634
[Epoch 12, Batch 1900] loss: 0.025921407678397373
[Epoch 12, Batch 2000] loss: 0.04511446477117716
[Epoch 12, Batch 2100] loss: 0.034252049249771516
[Epoch 12, Batch 2200] loss: 0.032679775428550786
[Epoch 12, Batch 2300] loss: 0.03543133490078617
[Epoch 12, Batch 2400] loss: 0.02985702321471763
[Epoch 12, Batch 2500] loss: 0.028455230180406944
[Epoch 12, Batch 2600] loss: 0.040040435610862915
[Epoch 12, Batch 2700] loss: 0.03724861468072049
[Epoch 12, Batch 2800] loss: 0.036321003075572664
[Epoch 12, Batch 2900] loss: 0.02849850281403633
[Epoch 12, Batch 3000] loss: 0.03685789350085542
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0521
Validation Accuracy: 0.9831
Overfitting: 0.0521
[Epoch 13, Batch 100] loss: 0.02737185257705278
[Epoch 13, Batch 200] loss: 0.02908613550302107
[Epoch 13, Batch 300] loss: 0.028421294483414385
[Epoch 13, Batch 400] loss: 0.0240429759323888
[Epoch 13, Batch 500] loss: 0.026234891434796737
[Epoch 13, Batch 600] loss: 0.040135313697101084
[Epoch 13, Batch 700] loss: 0.026593096614524258
[Epoch 13, Batch 800] loss: 0.02033362860180205
[Epoch 13, Batch 900] loss: 0.024763518274849048
[Epoch 13, Batch 1000] loss: 0.042346018347598144
[Epoch 13, Batch 1100] loss: 0.031830368853115944
[Epoch 13, Batch 1200] loss: 0.028132289633213077
[Epoch 13, Batch 1300] loss: 0.046389705267793034
[Epoch 13, Batch 1400] loss: 0.030773669071204494
[Epoch 13, Batch 1500] loss: 0.03202383999363519
[Epoch 13, Batch 1600] loss: 0.046198526671505535
[Epoch 13, Batch 1700] loss: 0.03766971598874079
[Epoch 13, Batch 1800] loss: 0.037035993616009365
[Epoch 13, Batch 1900] loss: 0.02746231096680276
[Epoch 13, Batch 2000] loss: 0.05754701798723545
[Epoch 13, Batch 2100] loss: 0.025734425665577872
[Epoch 13, Batch 2200] loss: 0.02658595597575186
[Epoch 13, Batch 2300] loss: 0.03354704001860227
[Epoch 13, Batch 2400] loss: 0.03344967597789946
[Epoch 13, Batch 2500] loss: 0.03429023904871428
[Epoch 13, Batch 2600] loss: 0.031236551024921937
[Epoch 13, Batch 2700] loss: 0.028709079229665802
[Epoch 13, Batch 2800] loss: 0.024976842697360554
[Epoch 13, Batch 2900] loss: 0.04171335680199263
[Epoch 13, Batch 3000] loss: 0.02846437440268346
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9832
Overfitting: 0.0492
Best model saved at epoch 13 with validation loss: 0.0492
[Epoch 14, Batch 100] loss: 0.028606560753833037
[Epoch 14, Batch 200] loss: 0.04419308722106507
[Epoch 14, Batch 300] loss: 0.033438595616898964
[Epoch 14, Batch 400] loss: 0.03589952015950985
[Epoch 14, Batch 500] loss: 0.027416554552619345
[Epoch 14, Batch 600] loss: 0.022142718057875755
[Epoch 14, Batch 700] loss: 0.03783338270946843
[Epoch 14, Batch 800] loss: 0.029406624517432648
[Epoch 14, Batch 900] loss: 0.02620936783918296
[Epoch 14, Batch 1000] loss: 0.026131177198549266
[Epoch 14, Batch 1100] loss: 0.04273818878544262
[Epoch 14, Batch 1200] loss: 0.027679369501420296
[Epoch 14, Batch 1300] loss: 0.029612120658130153
[Epoch 14, Batch 1400] loss: 0.029842040793737395
[Epoch 14, Batch 1500] loss: 0.04899418560584309
[Epoch 14, Batch 1600] loss: 0.04773331544100074
[Epoch 14, Batch 1700] loss: 0.035120935486775126
[Epoch 14, Batch 1800] loss: 0.029593976876931265
[Epoch 14, Batch 1900] loss: 0.033691461676862676
[Epoch 14, Batch 2000] loss: 0.03538220282149268
[Epoch 14, Batch 2100] loss: 0.02672912282447214
[Epoch 14, Batch 2200] loss: 0.035641781184240245
[Epoch 14, Batch 2300] loss: 0.02406866596575128
[Epoch 14, Batch 2400] loss: 0.0209233716619201
[Epoch 14, Batch 2500] loss: 0.027194755961390912
[Epoch 14, Batch 2600] loss: 0.02011418048190535
[Epoch 14, Batch 2700] loss: 0.02271042440814199
[Epoch 14, Batch 2800] loss: 0.02769309578128741
[Epoch 14, Batch 2900] loss: 0.026707240205723792
[Epoch 14, Batch 3000] loss: 0.021540690096153413
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0426
Validation Accuracy: 0.9872
Overfitting: 0.0426
Best model saved at epoch 14 with validation loss: 0.0426
[Epoch 15, Batch 100] loss: 0.04129633536504116
[Epoch 15, Batch 200] loss: 0.03515140518618864
[Epoch 15, Batch 300] loss: 0.020364519803842997
[Epoch 15, Batch 400] loss: 0.02878932202409487
[Epoch 15, Batch 500] loss: 0.01652790341693617
[Epoch 15, Batch 600] loss: 0.029872940218556323
[Epoch 15, Batch 700] loss: 0.035264503549551594
[Epoch 15, Batch 800] loss: 0.02330058744053531
[Epoch 15, Batch 900] loss: 0.02183655883774918
[Epoch 15, Batch 1000] loss: 0.027226720385333466
[Epoch 15, Batch 1100] loss: 0.030216179315684714
[Epoch 15, Batch 1200] loss: 0.018152017025568058
[Epoch 15, Batch 1300] loss: 0.021167613008146874
[Epoch 15, Batch 1400] loss: 0.020492556817407602
[Epoch 15, Batch 1500] loss: 0.02471167427545879
[Epoch 15, Batch 1600] loss: 0.023815817950307974
[Epoch 15, Batch 1700] loss: 0.02122110129952489
[Epoch 15, Batch 1800] loss: 0.027485576031103846
[Epoch 15, Batch 1900] loss: 0.02866908901989518
[Epoch 15, Batch 2000] loss: 0.0306204063284531
[Epoch 15, Batch 2100] loss: 0.028242838416081214
[Epoch 15, Batch 2200] loss: 0.04873777233093279
[Epoch 15, Batch 2300] loss: 0.026312820700622977
[Epoch 15, Batch 2400] loss: 0.039345934728517024
[Epoch 15, Batch 2500] loss: 0.021994979185255944
[Epoch 15, Batch 2600] loss: 0.0336575809797796
[Epoch 15, Batch 2700] loss: 0.029210491041012573
[Epoch 15, Batch 2800] loss: 0.03240445571689634
[Epoch 15, Batch 2900] loss: 0.029958812720506104
[Epoch 15, Batch 3000] loss: 0.030473540157836397
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9853
Overfitting: 0.0495
[Epoch 16, Batch 100] loss: 0.02451183290235349
[Epoch 16, Batch 200] loss: 0.01733792571212689
[Epoch 16, Batch 300] loss: 0.022723772192766774
[Epoch 16, Batch 400] loss: 0.021258148767665262
[Epoch 16, Batch 500] loss: 0.0281238394707907
[Epoch 16, Batch 600] loss: 0.03890355112060206
[Epoch 16, Batch 700] loss: 0.02156018938643683
[Epoch 16, Batch 800] loss: 0.026624648931174305
[Epoch 16, Batch 900] loss: 0.016332337901767458
[Epoch 16, Batch 1000] loss: 0.02974763922931743
[Epoch 16, Batch 1100] loss: 0.02340251384077419
[Epoch 16, Batch 1200] loss: 0.028309179183379454
[Epoch 16, Batch 1300] loss: 0.02868217067065416
[Epoch 16, Batch 1400] loss: 0.038294322102883596
[Epoch 16, Batch 1500] loss: 0.029719035135785818
[Epoch 16, Batch 1600] loss: 0.03003348547346832
[Epoch 16, Batch 1700] loss: 0.024968629925715503
[Epoch 16, Batch 1800] loss: 0.014312501480308128
[Epoch 16, Batch 1900] loss: 0.01607958238979336
[Epoch 16, Batch 2000] loss: 0.023164014361973385
[Epoch 16, Batch 2100] loss: 0.03269352722578333
[Epoch 16, Batch 2200] loss: 0.029564065896265673
[Epoch 16, Batch 2300] loss: 0.027917264596180758
[Epoch 16, Batch 2400] loss: 0.03497836872236803
[Epoch 16, Batch 2500] loss: 0.02346020423567097
[Epoch 16, Batch 2600] loss: 0.024317637898348038
[Epoch 16, Batch 2700] loss: 0.029158266042541073
[Epoch 16, Batch 2800] loss: 0.038763579494698205
[Epoch 16, Batch 2900] loss: 0.025073173363198295
[Epoch 16, Batch 3000] loss: 0.03603871667179192
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9875
Overfitting: 0.0431
[Epoch 17, Batch 100] loss: 0.015016596810310147
[Epoch 17, Batch 200] loss: 0.02168346617021598
[Epoch 17, Batch 300] loss: 0.015542139553799643
[Epoch 17, Batch 400] loss: 0.024414384691626764
[Epoch 17, Batch 500] loss: 0.025610767472608133
[Epoch 17, Batch 600] loss: 0.028620072598205298
[Epoch 17, Batch 700] loss: 0.026301711227133637
[Epoch 17, Batch 800] loss: 0.026231639516990982
[Epoch 17, Batch 900] loss: 0.0389259509734984
[Epoch 17, Batch 1000] loss: 0.03002668707005796
[Epoch 17, Batch 1100] loss: 0.014664310074149398
[Epoch 17, Batch 1200] loss: 0.025684957213670714
[Epoch 17, Batch 1300] loss: 0.02892319032383966
[Epoch 17, Batch 1400] loss: 0.025795915539347333
[Epoch 17, Batch 1500] loss: 0.01896942216415482
[Epoch 17, Batch 1600] loss: 0.014524695865184185
[Epoch 17, Batch 1700] loss: 0.04563800466188695
[Epoch 17, Batch 1800] loss: 0.032373569307092114
[Epoch 17, Batch 1900] loss: 0.02242512893433741
[Epoch 17, Batch 2000] loss: 0.02866193471083534
[Epoch 17, Batch 2100] loss: 0.01780841279673041
[Epoch 17, Batch 2200] loss: 0.022342473641911057
[Epoch 17, Batch 2300] loss: 0.024214772627019557
[Epoch 17, Batch 2400] loss: 0.019751845039281762
[Epoch 17, Batch 2500] loss: 0.029077502748550615
[Epoch 17, Batch 2600] loss: 0.019949677324621006
[Epoch 17, Batch 2700] loss: 0.025983104659426316
[Epoch 17, Batch 2800] loss: 0.025566423318668968
[Epoch 17, Batch 2900] loss: 0.01871957499795826
[Epoch 17, Batch 3000] loss: 0.02075403410475701
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0399
Validation Accuracy: 0.9878
Overfitting: 0.0399
Best model saved at epoch 17 with validation loss: 0.0399
[Epoch 18, Batch 100] loss: 0.014222297506566974
[Epoch 18, Batch 200] loss: 0.026483688609077946
[Epoch 18, Batch 300] loss: 0.024751027017046
[Epoch 18, Batch 400] loss: 0.015102927441330394
[Epoch 18, Batch 500] loss: 0.023428637524557417
[Epoch 18, Batch 600] loss: 0.02540096222262946
[Epoch 18, Batch 700] loss: 0.023446007296734024
[Epoch 18, Batch 800] loss: 0.015026402106304886
[Epoch 18, Batch 900] loss: 0.016392111054155976
[Epoch 18, Batch 1000] loss: 0.028250744277756895
[Epoch 18, Batch 1100] loss: 0.018880455950275064
[Epoch 18, Batch 1200] loss: 0.018807747727405514
[Epoch 18, Batch 1300] loss: 0.02856756908702664
[Epoch 18, Batch 1400] loss: 0.029571216188633117
[Epoch 18, Batch 1500] loss: 0.023980758684920146
[Epoch 18, Batch 1600] loss: 0.034204913024877895
[Epoch 18, Batch 1700] loss: 0.019528614912705963
[Epoch 18, Batch 1800] loss: 0.02356820247412543
[Epoch 18, Batch 1900] loss: 0.026903005745589327
[Epoch 18, Batch 2000] loss: 0.02238428441400174
[Epoch 18, Batch 2100] loss: 0.027371498045831687
[Epoch 18, Batch 2200] loss: 0.018363078040565597
[Epoch 18, Batch 2300] loss: 0.022628240864141846
[Epoch 18, Batch 2400] loss: 0.02321515741969051
[Epoch 18, Batch 2500] loss: 0.02432812127764919
[Epoch 18, Batch 2600] loss: 0.020408340820413286
[Epoch 18, Batch 2700] loss: 0.019009830989234616
[Epoch 18, Batch 2800] loss: 0.020132352580767475
[Epoch 18, Batch 2900] loss: 0.031587537524465005
[Epoch 18, Batch 3000] loss: 0.018002376247022767
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0418
Validation Accuracy: 0.9878
Overfitting: 0.0418
[Epoch 19, Batch 100] loss: 0.022332389523871825
[Epoch 19, Batch 200] loss: 0.015600973947694002
[Epoch 19, Batch 300] loss: 0.020394741635682292
[Epoch 19, Batch 400] loss: 0.015934996919822877
[Epoch 19, Batch 500] loss: 0.017469077764544635
[Epoch 19, Batch 600] loss: 0.027298682833716156
[Epoch 19, Batch 700] loss: 0.023412484030995984
[Epoch 19, Batch 800] loss: 0.014233756630164861
[Epoch 19, Batch 900] loss: 0.020064659499548724
[Epoch 19, Batch 1000] loss: 0.021283709452982292
[Epoch 19, Batch 1100] loss: 0.02367168909557222
[Epoch 19, Batch 1200] loss: 0.01512397083628457
[Epoch 19, Batch 1300] loss: 0.022663420957760538
[Epoch 19, Batch 1400] loss: 0.020387507162377007
[Epoch 19, Batch 1500] loss: 0.02364936295482039
[Epoch 19, Batch 1600] loss: 0.01706901970665058
[Epoch 19, Batch 1700] loss: 0.026619094432899146
[Epoch 19, Batch 1800] loss: 0.02322060970196617
[Epoch 19, Batch 1900] loss: 0.0119251058500231
[Epoch 19, Batch 2000] loss: 0.02611650987826579
[Epoch 19, Batch 2100] loss: 0.012092943718052994
[Epoch 19, Batch 2200] loss: 0.01895922594463627
[Epoch 19, Batch 2300] loss: 0.012650799026960157
[Epoch 19, Batch 2400] loss: 0.02311312221478147
[Epoch 19, Batch 2500] loss: 0.03128182517375535
[Epoch 19, Batch 2600] loss: 0.023918181202825507
[Epoch 19, Batch 2700] loss: 0.01731061705522734
[Epoch 19, Batch 2800] loss: 0.014887465351857827
[Epoch 19, Batch 2900] loss: 0.022457590712256205
[Epoch 19, Batch 3000] loss: 0.030121093064663
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0432
Validation Accuracy: 0.9882
Overfitting: 0.0432
[Epoch 20, Batch 100] loss: 0.01670666887308471
[Epoch 20, Batch 200] loss: 0.010093489963182947
[Epoch 20, Batch 300] loss: 0.02326663014435326
[Epoch 20, Batch 400] loss: 0.023830916602528306
[Epoch 20, Batch 500] loss: 0.018604919078497914
[Epoch 20, Batch 600] loss: 0.017633475607435684
[Epoch 20, Batch 700] loss: 0.018638285740526044
[Epoch 20, Batch 800] loss: 0.018721405704691278
[Epoch 20, Batch 900] loss: 0.019822575023426908
[Epoch 20, Batch 1000] loss: 0.02515478720473766
[Epoch 20, Batch 1100] loss: 0.020519043631938984
[Epoch 20, Batch 1200] loss: 0.016919053265664844
[Epoch 20, Batch 1300] loss: 0.016793958495291007
[Epoch 20, Batch 1400] loss: 0.025353557955822906
[Epoch 20, Batch 1500] loss: 0.020236041479511187
[Epoch 20, Batch 1600] loss: 0.01394058537138335
[Epoch 20, Batch 1700] loss: 0.016754138064607106
[Epoch 20, Batch 1800] loss: 0.02837151873871335
[Epoch 20, Batch 1900] loss: 0.016424376886498067
[Epoch 20, Batch 2000] loss: 0.014183098460707698
[Epoch 20, Batch 2100] loss: 0.03914058118665707
[Epoch 20, Batch 2200] loss: 0.0325962804511073
[Epoch 20, Batch 2300] loss: 0.011174479088931549
[Epoch 20, Batch 2400] loss: 0.01696330619917717
[Epoch 20, Batch 2500] loss: 0.01723404080968976
[Epoch 20, Batch 2600] loss: 0.02548718192410888
[Epoch 20, Batch 2700] loss: 0.017823433514313366
[Epoch 20, Batch 2800] loss: 0.01605849529420084
[Epoch 20, Batch 2900] loss: 0.014051134180845111
[Epoch 20, Batch 3000] loss: 0.01928927211849441
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0411
Validation Accuracy: 0.9875
Overfitting: 0.0411
[Epoch 21, Batch 100] loss: 0.013440070759606897
[Epoch 21, Batch 200] loss: 0.015945391827954153
[Epoch 21, Batch 300] loss: 0.01727560660299787
[Epoch 21, Batch 400] loss: 0.02138818383871694
[Epoch 21, Batch 500] loss: 0.01068115305966785
[Epoch 21, Batch 600] loss: 0.02116523187527491
[Epoch 21, Batch 700] loss: 0.02102489042386878
[Epoch 21, Batch 800] loss: 0.018341800109483303
[Epoch 21, Batch 900] loss: 0.012118554758162646
[Epoch 21, Batch 1000] loss: 0.013079083838238147
[Epoch 21, Batch 1100] loss: 0.026488403304974782
[Epoch 21, Batch 1200] loss: 0.011273480989948438
[Epoch 21, Batch 1300] loss: 0.014335010509912536
[Epoch 21, Batch 1400] loss: 0.00923979525345203
[Epoch 21, Batch 1500] loss: 0.017880239154037553
[Epoch 21, Batch 1600] loss: 0.016716081527001735
[Epoch 21, Batch 1700] loss: 0.025687008838503972
[Epoch 21, Batch 1800] loss: 0.029681668827615793
[Epoch 21, Batch 1900] loss: 0.010710399300296557
[Epoch 21, Batch 2000] loss: 0.017071890054503457
[Epoch 21, Batch 2100] loss: 0.009518436429425492
[Epoch 21, Batch 2200] loss: 0.02944184338030027
[Epoch 21, Batch 2300] loss: 0.030598615622620853
[Epoch 21, Batch 2400] loss: 0.025506366531189997
[Epoch 21, Batch 2500] loss: 0.012547977123613236
[Epoch 21, Batch 2600] loss: 0.013929659246350638
[Epoch 21, Batch 2700] loss: 0.013279420963117445
[Epoch 21, Batch 2800] loss: 0.015140906574815744
[Epoch 21, Batch 2900] loss: 0.028876808108452678
[Epoch 21, Batch 3000] loss: 0.01871363106318313
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0394
Validation Accuracy: 0.9882
Overfitting: 0.0394
Best model saved at epoch 21 with validation loss: 0.0394
[Epoch 22, Batch 100] loss: 0.011700806217486388
[Epoch 22, Batch 200] loss: 0.01020407481748407
[Epoch 22, Batch 300] loss: 0.014669481821019872
[Epoch 22, Batch 400] loss: 0.020747355261992197
[Epoch 22, Batch 500] loss: 0.02320886449646423
[Epoch 22, Batch 600] loss: 0.011087529331598489
[Epoch 22, Batch 700] loss: 0.007099508839855844
[Epoch 22, Batch 800] loss: 0.010944145198554906
[Epoch 22, Batch 900] loss: 0.011957047440191673
[Epoch 22, Batch 1000] loss: 0.021336498519958697
[Epoch 22, Batch 1100] loss: 0.017872663556008774
[Epoch 22, Batch 1200] loss: 0.013735976786192624
[Epoch 22, Batch 1300] loss: 0.02485177818351076
[Epoch 22, Batch 1400] loss: 0.018913474433029476
[Epoch 22, Batch 1500] loss: 0.014991156070991565
[Epoch 22, Batch 1600] loss: 0.011422900389479764
[Epoch 22, Batch 1700] loss: 0.012164182981541672
[Epoch 22, Batch 1800] loss: 0.019228010920778617
[Epoch 22, Batch 1900] loss: 0.021900334377860417
[Epoch 22, Batch 2000] loss: 0.028461291320127202
[Epoch 22, Batch 2100] loss: 0.024437011843692746
[Epoch 22, Batch 2200] loss: 0.022414014761343425
[Epoch 22, Batch 2300] loss: 0.009928162810847425
[Epoch 22, Batch 2400] loss: 0.013442035412117548
[Epoch 22, Batch 2500] loss: 0.01739353221397323
[Epoch 22, Batch 2600] loss: 0.016071429215735407
[Epoch 22, Batch 2700] loss: 0.02373106227885728
[Epoch 22, Batch 2800] loss: 0.01764071123303438
[Epoch 22, Batch 2900] loss: 0.019462115579881357
[Epoch 22, Batch 3000] loss: 0.01210562450633006
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0415
Validation Accuracy: 0.9877
Overfitting: 0.0415
[Epoch 23, Batch 100] loss: 0.017232883275210043
[Epoch 23, Batch 200] loss: 0.010823732230455789
[Epoch 23, Batch 300] loss: 0.018753539499402904
[Epoch 23, Batch 400] loss: 0.010620373760611984
[Epoch 23, Batch 500] loss: 0.012476919404944055
[Epoch 23, Batch 600] loss: 0.017692716181936703
[Epoch 23, Batch 700] loss: 0.01866655636087671
[Epoch 23, Batch 800] loss: 0.012580520766205154
[Epoch 23, Batch 900] loss: 0.030657388264771726
[Epoch 23, Batch 1000] loss: 0.012490265991054912
[Epoch 23, Batch 1100] loss: 0.014350173849743441
[Epoch 23, Batch 1200] loss: 0.012124381617131802
[Epoch 23, Batch 1300] loss: 0.023258505481062456
[Epoch 23, Batch 1400] loss: 0.014133483394325595
[Epoch 23, Batch 1500] loss: 0.008372861113566615
[Epoch 23, Batch 1600] loss: 0.019703352267897573
[Epoch 23, Batch 1700] loss: 0.015020669962468673
[Epoch 23, Batch 1800] loss: 0.012546885292395019
[Epoch 23, Batch 1900] loss: 0.011529741110825853
[Epoch 23, Batch 2000] loss: 0.017324165301033645
[Epoch 23, Batch 2100] loss: 0.022956382817355916
[Epoch 23, Batch 2200] loss: 0.017656710997325718
[Epoch 23, Batch 2300] loss: 0.01240244269316463
[Epoch 23, Batch 2400] loss: 0.027071894360442456
[Epoch 23, Batch 2500] loss: 0.011428779323250638
[Epoch 23, Batch 2600] loss: 0.009803483650939597
[Epoch 23, Batch 2700] loss: 0.015096969107507902
[Epoch 23, Batch 2800] loss: 0.013968904008579556
[Epoch 23, Batch 2900] loss: 0.013661665675535915
[Epoch 23, Batch 3000] loss: 0.01153400315077306
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0401
Validation Accuracy: 0.9876
Overfitting: 0.0401
[Epoch 24, Batch 100] loss: 0.010741269562658999
[Epoch 24, Batch 200] loss: 0.013518306103615032
[Epoch 24, Batch 300] loss: 0.012750280518412182
[Epoch 24, Batch 400] loss: 0.013828705340856687
[Epoch 24, Batch 500] loss: 0.012589620500584715
[Epoch 24, Batch 600] loss: 0.013820532026866204
[Epoch 24, Batch 700] loss: 0.01018838704877453
[Epoch 24, Batch 800] loss: 0.014575460544192538
[Epoch 24, Batch 900] loss: 0.022619678058199498
[Epoch 24, Batch 1000] loss: 0.015291135409206617
[Epoch 24, Batch 1100] loss: 0.0123164678079047
[Epoch 24, Batch 1200] loss: 0.009946290990219495
[Epoch 24, Batch 1300] loss: 0.02017110249187681
[Epoch 24, Batch 1400] loss: 0.011518597787726322
[Epoch 24, Batch 1500] loss: 0.011005881405453692
[Epoch 24, Batch 1600] loss: 0.014265747714489407
[Epoch 24, Batch 1700] loss: 0.019877318177859708
[Epoch 24, Batch 1800] loss: 0.012614253602496319
[Epoch 24, Batch 1900] loss: 0.020220561200676456
[Epoch 24, Batch 2000] loss: 0.011034263513065525
[Epoch 24, Batch 2100] loss: 0.013413951522634306
[Epoch 24, Batch 2200] loss: 0.02034849257684982
[Epoch 24, Batch 2300] loss: 0.01481761229741096
[Epoch 24, Batch 2400] loss: 0.01811460295572033
[Epoch 24, Batch 2500] loss: 0.011226585966342099
[Epoch 24, Batch 2600] loss: 0.015353184576888453
[Epoch 24, Batch 2700] loss: 0.012116209919986432
[Epoch 24, Batch 2800] loss: 0.032355616332642965
[Epoch 24, Batch 2900] loss: 0.009897196745805558
[Epoch 24, Batch 3000] loss: 0.012373297249287134
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0403
Validation Accuracy: 0.9892
Overfitting: 0.0403
Fold 4 validation loss: 0.0403
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.300060062408447
[Epoch 1, Batch 200] loss: 2.287355029582977
[Epoch 1, Batch 300] loss: 2.274530727863312
[Epoch 1, Batch 400] loss: 2.2501729631423952
[Epoch 1, Batch 500] loss: 2.2167892408370973
[Epoch 1, Batch 600] loss: 2.1501486921310424
[Epoch 1, Batch 700] loss: 2.0160915672779085
[Epoch 1, Batch 800] loss: 1.7549753892421722
[Epoch 1, Batch 900] loss: 1.3345892763137817
[Epoch 1, Batch 1000] loss: 0.9338332372903824
[Epoch 1, Batch 1100] loss: 0.7337979599833488
[Epoch 1, Batch 1200] loss: 0.584508921802044
[Epoch 1, Batch 1300] loss: 0.5443593554198742
[Epoch 1, Batch 1400] loss: 0.478951246291399
[Epoch 1, Batch 1500] loss: 0.4590718189626932
[Epoch 1, Batch 1600] loss: 0.44425298884510994
[Epoch 1, Batch 1700] loss: 0.4152411194145679
[Epoch 1, Batch 1800] loss: 0.42171761676669123
[Epoch 1, Batch 1900] loss: 0.3585699292272329
[Epoch 1, Batch 2000] loss: 0.37801179580390454
[Epoch 1, Batch 2100] loss: 0.33408303651958704
[Epoch 1, Batch 2200] loss: 0.35241176176816225
[Epoch 1, Batch 2300] loss: 0.35083389103412627
[Epoch 1, Batch 2400] loss: 0.31653770312666896
[Epoch 1, Batch 2500] loss: 0.29785509726032616
[Epoch 1, Batch 2600] loss: 0.3011191892623901
[Epoch 1, Batch 2700] loss: 0.28263779655098914
[Epoch 1, Batch 2800] loss: 0.29413703640922906
[Epoch 1, Batch 2900] loss: 0.27016194045543673
[Epoch 1, Batch 3000] loss: 0.24629881948232651
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2630
Validation Accuracy: 0.9203
Overfitting: 0.2630
Best model saved at epoch 1 with validation loss: 0.2630
[Epoch 2, Batch 100] loss: 0.28725852988660333
[Epoch 2, Batch 200] loss: 0.2863909947127104
[Epoch 2, Batch 300] loss: 0.2798300114553422
[Epoch 2, Batch 400] loss: 0.2713062216341495
[Epoch 2, Batch 500] loss: 0.25270323384553195
[Epoch 2, Batch 600] loss: 0.22804486677981914
[Epoch 2, Batch 700] loss: 0.22932959489524365
[Epoch 2, Batch 800] loss: 0.20881854278966785
[Epoch 2, Batch 900] loss: 0.2163139413110912
[Epoch 2, Batch 1000] loss: 0.22197135485708713
[Epoch 2, Batch 1100] loss: 0.17808680228888987
[Epoch 2, Batch 1200] loss: 0.20547269217669964
[Epoch 2, Batch 1300] loss: 0.16198671474121512
[Epoch 2, Batch 1400] loss: 0.21943796213716268
[Epoch 2, Batch 1500] loss: 0.18316224308684467
[Epoch 2, Batch 1600] loss: 0.2068532607704401
[Epoch 2, Batch 1700] loss: 0.22871399814262985
[Epoch 2, Batch 1800] loss: 0.21423478918150068
[Epoch 2, Batch 1900] loss: 0.1721957007003948
[Epoch 2, Batch 2000] loss: 0.16700853707268834
[Epoch 2, Batch 2100] loss: 0.14224321154877542
[Epoch 2, Batch 2200] loss: 0.15570881513878704
[Epoch 2, Batch 2300] loss: 0.19748078215867282
[Epoch 2, Batch 2400] loss: 0.19093689122237265
[Epoch 2, Batch 2500] loss: 0.1784973034262657
[Epoch 2, Batch 2600] loss: 0.15695997207425536
[Epoch 2, Batch 2700] loss: 0.1544203479588032
[Epoch 2, Batch 2800] loss: 0.16289288516156375
[Epoch 2, Batch 2900] loss: 0.16223540052771568
[Epoch 2, Batch 3000] loss: 0.1274291161634028
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1549
Validation Accuracy: 0.9532
Overfitting: 0.1549
Best model saved at epoch 2 with validation loss: 0.1549
[Epoch 3, Batch 100] loss: 0.162742310911417
[Epoch 3, Batch 200] loss: 0.1316216206457466
[Epoch 3, Batch 300] loss: 0.1402129241451621
[Epoch 3, Batch 400] loss: 0.12701193377841263
[Epoch 3, Batch 500] loss: 0.14350375775247812
[Epoch 3, Batch 600] loss: 0.14973818661645055
[Epoch 3, Batch 700] loss: 0.14335016690194607
[Epoch 3, Batch 800] loss: 0.1389768039062619
[Epoch 3, Batch 900] loss: 0.13060672665014864
[Epoch 3, Batch 1000] loss: 0.1375304905651137
[Epoch 3, Batch 1100] loss: 0.12727190009318293
[Epoch 3, Batch 1200] loss: 0.12387926561757923
[Epoch 3, Batch 1300] loss: 0.11568745263386518
[Epoch 3, Batch 1400] loss: 0.12628546104766428
[Epoch 3, Batch 1500] loss: 0.12682733798399567
[Epoch 3, Batch 1600] loss: 0.13808940198272468
[Epoch 3, Batch 1700] loss: 0.1370979426195845
[Epoch 3, Batch 1800] loss: 0.13178010405041277
[Epoch 3, Batch 1900] loss: 0.12065962236607447
[Epoch 3, Batch 2000] loss: 0.1263953330507502
[Epoch 3, Batch 2100] loss: 0.10579897136893124
[Epoch 3, Batch 2200] loss: 0.13832532020285726
[Epoch 3, Batch 2300] loss: 0.09625010975636542
[Epoch 3, Batch 2400] loss: 0.11124881569296122
[Epoch 3, Batch 2500] loss: 0.11085760260233656
[Epoch 3, Batch 2600] loss: 0.13333817372098566
[Epoch 3, Batch 2700] loss: 0.08943443281343207
[Epoch 3, Batch 2800] loss: 0.10282345047686249
[Epoch 3, Batch 2900] loss: 0.126266244945582
[Epoch 3, Batch 3000] loss: 0.09918156914995052
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1173
Validation Accuracy: 0.9637
Overfitting: 0.1173
Best model saved at epoch 3 with validation loss: 0.1173
[Epoch 4, Batch 100] loss: 0.09722922598477453
[Epoch 4, Batch 200] loss: 0.1130453059496358
[Epoch 4, Batch 300] loss: 0.10096546264830977
[Epoch 4, Batch 400] loss: 0.11513565996661783
[Epoch 4, Batch 500] loss: 0.0845798248751089
[Epoch 4, Batch 600] loss: 0.10023277786094695
[Epoch 4, Batch 700] loss: 0.1188288712175563
[Epoch 4, Batch 800] loss: 0.10570459734881296
[Epoch 4, Batch 900] loss: 0.10123528617667034
[Epoch 4, Batch 1000] loss: 0.10411230036988854
[Epoch 4, Batch 1100] loss: 0.10070588904665784
[Epoch 4, Batch 1200] loss: 0.10389047223608941
[Epoch 4, Batch 1300] loss: 0.10594420472392813
[Epoch 4, Batch 1400] loss: 0.10783264786470681
[Epoch 4, Batch 1500] loss: 0.09105578945716843
[Epoch 4, Batch 1600] loss: 0.09389217122923582
[Epoch 4, Batch 1700] loss: 0.08373466317309067
[Epoch 4, Batch 1800] loss: 0.0886933826096356
[Epoch 4, Batch 1900] loss: 0.08545653047971427
[Epoch 4, Batch 2000] loss: 0.06590671984595246
[Epoch 4, Batch 2100] loss: 0.09558674487983808
[Epoch 4, Batch 2200] loss: 0.08250812305836007
[Epoch 4, Batch 2300] loss: 0.10340618497459218
[Epoch 4, Batch 2400] loss: 0.09608061684528366
[Epoch 4, Batch 2500] loss: 0.09471906297607348
[Epoch 4, Batch 2600] loss: 0.07935080269351602
[Epoch 4, Batch 2700] loss: 0.09925898483488708
[Epoch 4, Batch 2800] loss: 0.08301551745738835
[Epoch 4, Batch 2900] loss: 0.08480056031839922
[Epoch 4, Batch 3000] loss: 0.0905663252575323
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0874
Validation Accuracy: 0.9734
Overfitting: 0.0874
Best model saved at epoch 4 with validation loss: 0.0874
[Epoch 5, Batch 100] loss: 0.06336317916633562
[Epoch 5, Batch 200] loss: 0.07658307407982648
[Epoch 5, Batch 300] loss: 0.06578440253273583
[Epoch 5, Batch 400] loss: 0.062491320420522245
[Epoch 5, Batch 500] loss: 0.06362480426672847
[Epoch 5, Batch 600] loss: 0.07284972185268998
[Epoch 5, Batch 700] loss: 0.07084258235991
[Epoch 5, Batch 800] loss: 0.09143222034908831
[Epoch 5, Batch 900] loss: 0.08280164964962751
[Epoch 5, Batch 1000] loss: 0.07973357404465788
[Epoch 5, Batch 1100] loss: 0.09973003036458977
[Epoch 5, Batch 1200] loss: 0.11073863449040801
[Epoch 5, Batch 1300] loss: 0.07660478114848956
[Epoch 5, Batch 1400] loss: 0.08856628386303783
[Epoch 5, Batch 1500] loss: 0.08418830882292241
[Epoch 5, Batch 1600] loss: 0.09787220575031824
[Epoch 5, Batch 1700] loss: 0.07715384103939868
[Epoch 5, Batch 1800] loss: 0.07021610666997731
[Epoch 5, Batch 1900] loss: 0.07719985859002917
[Epoch 5, Batch 2000] loss: 0.07418142577633262
[Epoch 5, Batch 2100] loss: 0.09201448567793705
[Epoch 5, Batch 2200] loss: 0.06470762636570726
[Epoch 5, Batch 2300] loss: 0.06428012940450571
[Epoch 5, Batch 2400] loss: 0.0753593431878835
[Epoch 5, Batch 2500] loss: 0.08934377927449531
[Epoch 5, Batch 2600] loss: 0.07146438357536682
[Epoch 5, Batch 2700] loss: 0.06365010060952045
[Epoch 5, Batch 2800] loss: 0.053617250628303734
[Epoch 5, Batch 2900] loss: 0.060370999713777566
[Epoch 5, Batch 3000] loss: 0.08868965319124981
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0759
Validation Accuracy: 0.9763
Overfitting: 0.0759
Best model saved at epoch 5 with validation loss: 0.0759
[Epoch 6, Batch 100] loss: 0.08095498226117342
[Epoch 6, Batch 200] loss: 0.0508294753334485
[Epoch 6, Batch 300] loss: 0.08205232672975399
[Epoch 6, Batch 400] loss: 0.06144357612705789
[Epoch 6, Batch 500] loss: 0.07071621054667049
[Epoch 6, Batch 600] loss: 0.058592732690740376
[Epoch 6, Batch 700] loss: 0.06082759035169147
[Epoch 6, Batch 800] loss: 0.060318321379600096
[Epoch 6, Batch 900] loss: 0.06615981181850657
[Epoch 6, Batch 1000] loss: 0.08912216320401058
[Epoch 6, Batch 1100] loss: 0.0736288051289739
[Epoch 6, Batch 1200] loss: 0.06563819095259532
[Epoch 6, Batch 1300] loss: 0.053768363097915425
[Epoch 6, Batch 1400] loss: 0.08869450075202621
[Epoch 6, Batch 1500] loss: 0.08247235460847151
[Epoch 6, Batch 1600] loss: 0.06513598942547105
[Epoch 6, Batch 1700] loss: 0.06887881172355265
[Epoch 6, Batch 1800] loss: 0.0762489159987308
[Epoch 6, Batch 1900] loss: 0.0705122014239896
[Epoch 6, Batch 2000] loss: 0.08474506479629781
[Epoch 6, Batch 2100] loss: 0.06576993878814391
[Epoch 6, Batch 2200] loss: 0.05833225014037453
[Epoch 6, Batch 2300] loss: 0.06651974359294399
[Epoch 6, Batch 2400] loss: 0.05593590370932361
[Epoch 6, Batch 2500] loss: 0.058530908724060283
[Epoch 6, Batch 2600] loss: 0.06612671562586911
[Epoch 6, Batch 2700] loss: 0.05739383822423406
[Epoch 6, Batch 2800] loss: 0.05261890923604369
[Epoch 6, Batch 2900] loss: 0.07221763835405
[Epoch 6, Batch 3000] loss: 0.058052431308897215
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0741
Validation Accuracy: 0.9762
Overfitting: 0.0741
Best model saved at epoch 6 with validation loss: 0.0741
[Epoch 7, Batch 100] loss: 0.06419273258768954
[Epoch 7, Batch 200] loss: 0.05938453397480771
[Epoch 7, Batch 300] loss: 0.056974556561326606
[Epoch 7, Batch 400] loss: 0.06019471176550724
[Epoch 7, Batch 500] loss: 0.06609630796767306
[Epoch 7, Batch 600] loss: 0.056300044057425114
[Epoch 7, Batch 700] loss: 0.04770208173547871
[Epoch 7, Batch 800] loss: 0.06672976208443288
[Epoch 7, Batch 900] loss: 0.055356814463157204
[Epoch 7, Batch 1000] loss: 0.055249921255744995
[Epoch 7, Batch 1100] loss: 0.03840169164701365
[Epoch 7, Batch 1200] loss: 0.062325416890671476
[Epoch 7, Batch 1300] loss: 0.06864206118392759
[Epoch 7, Batch 1400] loss: 0.07791267206892372
[Epoch 7, Batch 1500] loss: 0.05003615294292103
[Epoch 7, Batch 1600] loss: 0.06332283146621194
[Epoch 7, Batch 1700] loss: 0.05719550217036158
[Epoch 7, Batch 1800] loss: 0.07820673167705536
[Epoch 7, Batch 1900] loss: 0.055392121879849585
[Epoch 7, Batch 2000] loss: 0.04968729763466399
[Epoch 7, Batch 2100] loss: 0.031235077508026735
[Epoch 7, Batch 2200] loss: 0.05368431599868927
[Epoch 7, Batch 2300] loss: 0.04874316315283068
[Epoch 7, Batch 2400] loss: 0.05409816615167074
[Epoch 7, Batch 2500] loss: 0.05899778832215816
[Epoch 7, Batch 2600] loss: 0.05094833202136215
[Epoch 7, Batch 2700] loss: 0.06774705777294003
[Epoch 7, Batch 2800] loss: 0.07466998838703148
[Epoch 7, Batch 2900] loss: 0.06730182598053944
[Epoch 7, Batch 3000] loss: 0.05963240391400177
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0783
Validation Accuracy: 0.9752
Overfitting: 0.0783
[Epoch 8, Batch 100] loss: 0.049649434863822534
[Epoch 8, Batch 200] loss: 0.06777134878851938
[Epoch 8, Batch 300] loss: 0.0683095579611836
[Epoch 8, Batch 400] loss: 0.051877814908511934
[Epoch 8, Batch 500] loss: 0.058119738970999604
[Epoch 8, Batch 600] loss: 0.05786415795097127
[Epoch 8, Batch 700] loss: 0.05771179984556511
[Epoch 8, Batch 800] loss: 0.04913377626275178
[Epoch 8, Batch 900] loss: 0.04948296800866956
[Epoch 8, Batch 1000] loss: 0.05802590328210499
[Epoch 8, Batch 1100] loss: 0.04520966107433196
[Epoch 8, Batch 1200] loss: 0.051412663556402546
[Epoch 8, Batch 1300] loss: 0.03745730935333995
[Epoch 8, Batch 1400] loss: 0.06057048930000747
[Epoch 8, Batch 1500] loss: 0.05102276714780601
[Epoch 8, Batch 1600] loss: 0.05197976208641194
[Epoch 8, Batch 1700] loss: 0.04849133786774473
[Epoch 8, Batch 1800] loss: 0.045438025472685696
[Epoch 8, Batch 1900] loss: 0.06536459451541304
[Epoch 8, Batch 2000] loss: 0.06023085047781933
[Epoch 8, Batch 2100] loss: 0.049806436736835165
[Epoch 8, Batch 2200] loss: 0.03968447360777645
[Epoch 8, Batch 2300] loss: 0.06165940589387901
[Epoch 8, Batch 2400] loss: 0.04864461723947897
[Epoch 8, Batch 2500] loss: 0.041773501303978264
[Epoch 8, Batch 2600] loss: 0.050812991808052176
[Epoch 8, Batch 2700] loss: 0.043338934522762426
[Epoch 8, Batch 2800] loss: 0.04649195989506552
[Epoch 8, Batch 2900] loss: 0.05978119365638122
[Epoch 8, Batch 3000] loss: 0.057182678403332826
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0760
Validation Accuracy: 0.9746
Overfitting: 0.0760
[Epoch 9, Batch 100] loss: 0.06283508839609567
[Epoch 9, Batch 200] loss: 0.04783863824093714
[Epoch 9, Batch 300] loss: 0.039576984890154564
[Epoch 9, Batch 400] loss: 0.04311255617823918
[Epoch 9, Batch 500] loss: 0.03614407053973991
[Epoch 9, Batch 600] loss: 0.03370290835388005
[Epoch 9, Batch 700] loss: 0.05170128237572499
[Epoch 9, Batch 800] loss: 0.0455545090616215
[Epoch 9, Batch 900] loss: 0.044603415678138844
[Epoch 9, Batch 1000] loss: 0.05869106899248436
[Epoch 9, Batch 1100] loss: 0.04628903253527824
[Epoch 9, Batch 1200] loss: 0.05232014190754853
[Epoch 9, Batch 1300] loss: 0.059335094167036
[Epoch 9, Batch 1400] loss: 0.041281885037897155
[Epoch 9, Batch 1500] loss: 0.05028970359067898
[Epoch 9, Batch 1600] loss: 0.03728204642306082
[Epoch 9, Batch 1700] loss: 0.05934473233763129
[Epoch 9, Batch 1800] loss: 0.04751249153865501
[Epoch 9, Batch 1900] loss: 0.038391992344404574
[Epoch 9, Batch 2000] loss: 0.05769261088571511
[Epoch 9, Batch 2100] loss: 0.05617076632741373
[Epoch 9, Batch 2200] loss: 0.050775081187603065
[Epoch 9, Batch 2300] loss: 0.046396583724417725
[Epoch 9, Batch 2400] loss: 0.04325374162144726
[Epoch 9, Batch 2500] loss: 0.042232382091751786
[Epoch 9, Batch 2600] loss: 0.048883861763169986
[Epoch 9, Batch 2700] loss: 0.06674833536613732
[Epoch 9, Batch 2800] loss: 0.033458628872176634
[Epoch 9, Batch 2900] loss: 0.04409394518181216
[Epoch 9, Batch 3000] loss: 0.053514155757729893
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9825
Overfitting: 0.0576
Best model saved at epoch 9 with validation loss: 0.0576
[Epoch 10, Batch 100] loss: 0.04502493511303328
[Epoch 10, Batch 200] loss: 0.05237239807640435
[Epoch 10, Batch 300] loss: 0.05138995391665958
[Epoch 10, Batch 400] loss: 0.039627623728010805
[Epoch 10, Batch 500] loss: 0.05871469125850126
[Epoch 10, Batch 600] loss: 0.040768263812060467
[Epoch 10, Batch 700] loss: 0.03829258281562943
[Epoch 10, Batch 800] loss: 0.026820798794506117
[Epoch 10, Batch 900] loss: 0.043469134530459995
[Epoch 10, Batch 1000] loss: 0.0341438346443465
[Epoch 10, Batch 1100] loss: 0.04556289112311788
[Epoch 10, Batch 1200] loss: 0.03978551004227484
[Epoch 10, Batch 1300] loss: 0.05480824033904355
[Epoch 10, Batch 1400] loss: 0.040852756386157124
[Epoch 10, Batch 1500] loss: 0.03519146135775372
[Epoch 10, Batch 1600] loss: 0.04083570954971947
[Epoch 10, Batch 1700] loss: 0.03911514631894533
[Epoch 10, Batch 1800] loss: 0.028523343534034212
[Epoch 10, Batch 1900] loss: 0.05635174656374147
[Epoch 10, Batch 2000] loss: 0.04892077814351069
[Epoch 10, Batch 2100] loss: 0.06160672704107128
[Epoch 10, Batch 2200] loss: 0.035500864939531314
[Epoch 10, Batch 2300] loss: 0.050530529175011905
[Epoch 10, Batch 2400] loss: 0.043632678282738195
[Epoch 10, Batch 2500] loss: 0.03633774176094448
[Epoch 10, Batch 2600] loss: 0.042156510816130324
[Epoch 10, Batch 2700] loss: 0.05367239138111472
[Epoch 10, Batch 2800] loss: 0.030356574633624404
[Epoch 10, Batch 2900] loss: 0.04365892461675685
[Epoch 10, Batch 3000] loss: 0.04819410154566867
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9812
Overfitting: 0.0586
[Epoch 11, Batch 100] loss: 0.05060421533358749
[Epoch 11, Batch 200] loss: 0.0562834265253332
[Epoch 11, Batch 300] loss: 0.037391494161565786
[Epoch 11, Batch 400] loss: 0.03490295154042542
[Epoch 11, Batch 500] loss: 0.033824225263670085
[Epoch 11, Batch 600] loss: 0.03851840983290458
[Epoch 11, Batch 700] loss: 0.040631720854435116
[Epoch 11, Batch 800] loss: 0.043449574562546334
[Epoch 11, Batch 900] loss: 0.042196768219873775
[Epoch 11, Batch 1000] loss: 0.03294757247233065
[Epoch 11, Batch 1100] loss: 0.04493844841927057
[Epoch 11, Batch 1200] loss: 0.041369466453325
[Epoch 11, Batch 1300] loss: 0.03171399842074606
[Epoch 11, Batch 1400] loss: 0.04540879204228986
[Epoch 11, Batch 1500] loss: 0.040177095294639004
[Epoch 11, Batch 1600] loss: 0.0324914416577667
[Epoch 11, Batch 1700] loss: 0.04346977357781725
[Epoch 11, Batch 1800] loss: 0.03879684842875577
[Epoch 11, Batch 1900] loss: 0.03428376886615297
[Epoch 11, Batch 2000] loss: 0.035522456784092354
[Epoch 11, Batch 2100] loss: 0.04198015923728235
[Epoch 11, Batch 2200] loss: 0.046355360971938354
[Epoch 11, Batch 2300] loss: 0.02812320452198037
[Epoch 11, Batch 2400] loss: 0.05627788238984067
[Epoch 11, Batch 2500] loss: 0.03536195249616867
[Epoch 11, Batch 2600] loss: 0.0331634158533052
[Epoch 11, Batch 2700] loss: 0.05495101049775258
[Epoch 11, Batch 2800] loss: 0.06032489130593603
[Epoch 11, Batch 2900] loss: 0.03497814436617773
[Epoch 11, Batch 3000] loss: 0.028459820313728415
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9822
Overfitting: 0.0554
Best model saved at epoch 11 with validation loss: 0.0554
[Epoch 12, Batch 100] loss: 0.03712230378645472
[Epoch 12, Batch 200] loss: 0.03373780292458832
[Epoch 12, Batch 300] loss: 0.036429882605880266
[Epoch 12, Batch 400] loss: 0.05189409985061502
[Epoch 12, Batch 500] loss: 0.04422594337025657
[Epoch 12, Batch 600] loss: 0.02379746102145873
[Epoch 12, Batch 700] loss: 0.03261532635748154
[Epoch 12, Batch 800] loss: 0.03416879493859597
[Epoch 12, Batch 900] loss: 0.038653427370009014
[Epoch 12, Batch 1000] loss: 0.03534234164937516
[Epoch 12, Batch 1100] loss: 0.04107286198763177
[Epoch 12, Batch 1200] loss: 0.040421926896815424
[Epoch 12, Batch 1300] loss: 0.04360511716571636
[Epoch 12, Batch 1400] loss: 0.03129576783147058
[Epoch 12, Batch 1500] loss: 0.03850483142145095
[Epoch 12, Batch 1600] loss: 0.02812507280992577
[Epoch 12, Batch 1700] loss: 0.05066105304809753
[Epoch 12, Batch 1800] loss: 0.03648149570450187
[Epoch 12, Batch 1900] loss: 0.054722564269613944
[Epoch 12, Batch 2000] loss: 0.03126197941135615
[Epoch 12, Batch 2100] loss: 0.053359090365702286
[Epoch 12, Batch 2200] loss: 0.036524940274539404
[Epoch 12, Batch 2300] loss: 0.03909541314002127
[Epoch 12, Batch 2400] loss: 0.030473634041700278
[Epoch 12, Batch 2500] loss: 0.030044463184021878
[Epoch 12, Batch 2600] loss: 0.03730997679696884
[Epoch 12, Batch 2700] loss: 0.03026113679690752
[Epoch 12, Batch 2800] loss: 0.02850834909171681
[Epoch 12, Batch 2900] loss: 0.030474728912013235
[Epoch 12, Batch 3000] loss: 0.030378295693080874
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9841
Overfitting: 0.0500
Best model saved at epoch 12 with validation loss: 0.0500
[Epoch 13, Batch 100] loss: 0.04015443186319317
[Epoch 13, Batch 200] loss: 0.03245583359937882
[Epoch 13, Batch 300] loss: 0.026751806648098862
[Epoch 13, Batch 400] loss: 0.04032833694916917
[Epoch 13, Batch 500] loss: 0.03946096223720815
[Epoch 13, Batch 600] loss: 0.02821886857593199
[Epoch 13, Batch 700] loss: 0.025954003553197255
[Epoch 13, Batch 800] loss: 0.033592730703239794
[Epoch 13, Batch 900] loss: 0.04844004540194874
[Epoch 13, Batch 1000] loss: 0.02012779588025296
[Epoch 13, Batch 1100] loss: 0.03791646967758425
[Epoch 13, Batch 1200] loss: 0.029815835661720483
[Epoch 13, Batch 1300] loss: 0.03050863062686403
[Epoch 13, Batch 1400] loss: 0.04362539941335854
[Epoch 13, Batch 1500] loss: 0.03388776542720734
[Epoch 13, Batch 1600] loss: 0.04168603906960925
[Epoch 13, Batch 1700] loss: 0.02211700855361414
[Epoch 13, Batch 1800] loss: 0.059621428162790834
[Epoch 13, Batch 1900] loss: 0.036837038680096156
[Epoch 13, Batch 2000] loss: 0.025808227145826094
[Epoch 13, Batch 2100] loss: 0.0466813526932674
[Epoch 13, Batch 2200] loss: 0.03112308103358373
[Epoch 13, Batch 2300] loss: 0.03683243400664651
[Epoch 13, Batch 2400] loss: 0.03096784474895685
[Epoch 13, Batch 2500] loss: 0.023076742063858548
[Epoch 13, Batch 2600] loss: 0.02998116291113547
[Epoch 13, Batch 2700] loss: 0.02947313819255214
[Epoch 13, Batch 2800] loss: 0.025828918671031716
[Epoch 13, Batch 2900] loss: 0.030893745974390187
[Epoch 13, Batch 3000] loss: 0.04121741304537863
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9838
Overfitting: 0.0499
Best model saved at epoch 13 with validation loss: 0.0499
[Epoch 14, Batch 100] loss: 0.025249276951362844
[Epoch 14, Batch 200] loss: 0.02765566306086839
[Epoch 14, Batch 300] loss: 0.0505170345120132
[Epoch 14, Batch 400] loss: 0.022893328811915126
[Epoch 14, Batch 500] loss: 0.02960694127890747
[Epoch 14, Batch 600] loss: 0.032807562087473346
[Epoch 14, Batch 700] loss: 0.0392959906932083
[Epoch 14, Batch 800] loss: 0.022722769980027806
[Epoch 14, Batch 900] loss: 0.04620553549772012
[Epoch 14, Batch 1000] loss: 0.029558386664866702
[Epoch 14, Batch 1100] loss: 0.02646470669991686
[Epoch 14, Batch 1200] loss: 0.03355345934643992
[Epoch 14, Batch 1300] loss: 0.031190356946899554
[Epoch 14, Batch 1400] loss: 0.03445850358577445
[Epoch 14, Batch 1500] loss: 0.03281260729083442
[Epoch 14, Batch 1600] loss: 0.025020470331364775
[Epoch 14, Batch 1700] loss: 0.02401584514474962
[Epoch 14, Batch 1800] loss: 0.029220292068494018
[Epoch 14, Batch 1900] loss: 0.025029280266098793
[Epoch 14, Batch 2000] loss: 0.03806957915148814
[Epoch 14, Batch 2100] loss: 0.023962284446315606
[Epoch 14, Batch 2200] loss: 0.028826355301353034
[Epoch 14, Batch 2300] loss: 0.03484145781767438
[Epoch 14, Batch 2400] loss: 0.05416683592949994
[Epoch 14, Batch 2500] loss: 0.030743344741058536
[Epoch 14, Batch 2600] loss: 0.03787991247634636
[Epoch 14, Batch 2700] loss: 0.029406462449987885
[Epoch 14, Batch 2800] loss: 0.026285821563506034
[Epoch 14, Batch 2900] loss: 0.0370782517734915
[Epoch 14, Batch 3000] loss: 0.029464287266309837
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9828
Overfitting: 0.0534
[Epoch 15, Batch 100] loss: 0.01975138620386133
[Epoch 15, Batch 200] loss: 0.022375400611490476
[Epoch 15, Batch 300] loss: 0.026791124620795016
[Epoch 15, Batch 400] loss: 0.02407783538219519
[Epoch 15, Batch 500] loss: 0.025116738724627795
[Epoch 15, Batch 600] loss: 0.02244646387931425
[Epoch 15, Batch 700] loss: 0.02070415234542452
[Epoch 15, Batch 800] loss: 0.024754615908896084
[Epoch 15, Batch 900] loss: 0.03151269022433553
[Epoch 15, Batch 1000] loss: 0.043809427150554255
[Epoch 15, Batch 1100] loss: 0.029892643705388765
[Epoch 15, Batch 1200] loss: 0.027123365743318573
[Epoch 15, Batch 1300] loss: 0.02948898162416299
[Epoch 15, Batch 1400] loss: 0.02261611953494139
[Epoch 15, Batch 1500] loss: 0.03239569567522267
[Epoch 15, Batch 1600] loss: 0.03336056665633805
[Epoch 15, Batch 1700] loss: 0.028351483063961496
[Epoch 15, Batch 1800] loss: 0.03435206260764971
[Epoch 15, Batch 1900] loss: 0.026506837372871815
[Epoch 15, Batch 2000] loss: 0.023690163317660336
[Epoch 15, Batch 2100] loss: 0.022924787117590315
[Epoch 15, Batch 2200] loss: 0.029259884437051367
[Epoch 15, Batch 2300] loss: 0.023785843333025695
[Epoch 15, Batch 2400] loss: 0.040611224691165265
[Epoch 15, Batch 2500] loss: 0.02896659862017259
[Epoch 15, Batch 2600] loss: 0.0481280691504071
[Epoch 15, Batch 2700] loss: 0.04550566906240419
[Epoch 15, Batch 2800] loss: 0.034480066469404845
[Epoch 15, Batch 2900] loss: 0.031697672616282944
[Epoch 15, Batch 3000] loss: 0.040181824041937944
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9828
Overfitting: 0.0569
[Epoch 16, Batch 100] loss: 0.027886485752096634
[Epoch 16, Batch 200] loss: 0.02218552311314852
[Epoch 16, Batch 300] loss: 0.021055950904701602
[Epoch 16, Batch 400] loss: 0.021415537321008742
[Epoch 16, Batch 500] loss: 0.02374464757158421
[Epoch 16, Batch 600] loss: 0.029089389007131105
[Epoch 16, Batch 700] loss: 0.029506160974269734
[Epoch 16, Batch 800] loss: 0.01868635068385629
[Epoch 16, Batch 900] loss: 0.02582464078957855
[Epoch 16, Batch 1000] loss: 0.01743574599007843
[Epoch 16, Batch 1100] loss: 0.037471411480655664
[Epoch 16, Batch 1200] loss: 0.025297156881861155
[Epoch 16, Batch 1300] loss: 0.024837436701345722
[Epoch 16, Batch 1400] loss: 0.045394521677226296
[Epoch 16, Batch 1500] loss: 0.018136951062333536
[Epoch 16, Batch 1600] loss: 0.031846807524561885
[Epoch 16, Batch 1700] loss: 0.04178943482118484
[Epoch 16, Batch 1800] loss: 0.03201461508557259
[Epoch 16, Batch 1900] loss: 0.02977479858760489
[Epoch 16, Batch 2000] loss: 0.01663791418628534
[Epoch 16, Batch 2100] loss: 0.023692528836982092
[Epoch 16, Batch 2200] loss: 0.023435856993019116
[Epoch 16, Batch 2300] loss: 0.015875321383282424
[Epoch 16, Batch 2400] loss: 0.023723945859092054
[Epoch 16, Batch 2500] loss: 0.035194435530502235
[Epoch 16, Batch 2600] loss: 0.032762378640181854
[Epoch 16, Batch 2700] loss: 0.04347531799234275
[Epoch 16, Batch 2800] loss: 0.03875970686778601
[Epoch 16, Batch 2900] loss: 0.032817315826541744
[Epoch 16, Batch 3000] loss: 0.021534357790733337
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9849
Overfitting: 0.0452
Best model saved at epoch 16 with validation loss: 0.0452
[Epoch 17, Batch 100] loss: 0.012647995857405477
[Epoch 17, Batch 200] loss: 0.022262568156293128
[Epoch 17, Batch 300] loss: 0.017705427737237187
[Epoch 17, Batch 400] loss: 0.029051080920908134
[Epoch 17, Batch 500] loss: 0.031606176169298124
[Epoch 17, Batch 600] loss: 0.019269840698107145
[Epoch 17, Batch 700] loss: 0.019420290509588087
[Epoch 17, Batch 800] loss: 0.014830351596901891
[Epoch 17, Batch 900] loss: 0.026686568896511744
[Epoch 17, Batch 1000] loss: 0.02715456316844211
[Epoch 17, Batch 1100] loss: 0.03414730718286592
[Epoch 17, Batch 1200] loss: 0.023557921642641304
[Epoch 17, Batch 1300] loss: 0.023437471723300404
[Epoch 17, Batch 1400] loss: 0.02974266967357835
[Epoch 17, Batch 1500] loss: 0.05458109294595488
[Epoch 17, Batch 1600] loss: 0.021065433518961073
[Epoch 17, Batch 1700] loss: 0.01921069798310782
[Epoch 17, Batch 1800] loss: 0.020988303119447663
[Epoch 17, Batch 1900] loss: 0.027889466936176176
[Epoch 17, Batch 2000] loss: 0.024558612447654015
[Epoch 17, Batch 2100] loss: 0.025149265405343613
[Epoch 17, Batch 2200] loss: 0.013534225116745801
[Epoch 17, Batch 2300] loss: 0.022546724486383028
[Epoch 17, Batch 2400] loss: 0.035634572347007634
[Epoch 17, Batch 2500] loss: 0.025243310748628574
[Epoch 17, Batch 2600] loss: 0.026355392373880022
[Epoch 17, Batch 2700] loss: 0.03445164951743209
[Epoch 17, Batch 2800] loss: 0.033628961048307246
[Epoch 17, Batch 2900] loss: 0.02829810320676188
[Epoch 17, Batch 3000] loss: 0.02156267934216885
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9849
Overfitting: 0.0447
Best model saved at epoch 17 with validation loss: 0.0447
[Epoch 18, Batch 100] loss: 0.015284792802121956
[Epoch 18, Batch 200] loss: 0.019744219731437626
[Epoch 18, Batch 300] loss: 0.01984634746229858
[Epoch 18, Batch 400] loss: 0.026475404547236393
[Epoch 18, Batch 500] loss: 0.024370151126859127
[Epoch 18, Batch 600] loss: 0.01730427675116516
[Epoch 18, Batch 700] loss: 0.018044856791675556
[Epoch 18, Batch 800] loss: 0.02399992738475703
[Epoch 18, Batch 900] loss: 0.02870092632358137
[Epoch 18, Batch 1000] loss: 0.022500966665611487
[Epoch 18, Batch 1100] loss: 0.018816488614174887
[Epoch 18, Batch 1200] loss: 0.026177194783376764
[Epoch 18, Batch 1300] loss: 0.016718649376998657
[Epoch 18, Batch 1400] loss: 0.01940609579978627
[Epoch 18, Batch 1500] loss: 0.027693302797124487
[Epoch 18, Batch 1600] loss: 0.02484531430010975
[Epoch 18, Batch 1700] loss: 0.018868432557101186
[Epoch 18, Batch 1800] loss: 0.04041137722961139
[Epoch 18, Batch 1900] loss: 0.01160710206018848
[Epoch 18, Batch 2000] loss: 0.03528942401579115
[Epoch 18, Batch 2100] loss: 0.029750258635904175
[Epoch 18, Batch 2200] loss: 0.02814448177254235
[Epoch 18, Batch 2300] loss: 0.02874198638863163
[Epoch 18, Batch 2400] loss: 0.021104609788380913
[Epoch 18, Batch 2500] loss: 0.019118377770646476
[Epoch 18, Batch 2600] loss: 0.026914535026662634
[Epoch 18, Batch 2700] loss: 0.02307078747675405
[Epoch 18, Batch 2800] loss: 0.03192349356382693
[Epoch 18, Batch 2900] loss: 0.019037863400080825
[Epoch 18, Batch 3000] loss: 0.018709021941031096
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9838
Overfitting: 0.0505
[Epoch 19, Batch 100] loss: 0.01670359319770796
[Epoch 19, Batch 200] loss: 0.011981527995958459
[Epoch 19, Batch 300] loss: 0.025334804296471704
[Epoch 19, Batch 400] loss: 0.015501552301138873
[Epoch 19, Batch 500] loss: 0.022160264785488836
[Epoch 19, Batch 600] loss: 0.02548959072057187
[Epoch 19, Batch 700] loss: 0.02260599835164612
[Epoch 19, Batch 800] loss: 0.026050585975208377
[Epoch 19, Batch 900] loss: 0.032302378227759616
[Epoch 19, Batch 1000] loss: 0.02609581613643968
[Epoch 19, Batch 1100] loss: 0.016956334841015632
[Epoch 19, Batch 1200] loss: 0.019040308922158147
[Epoch 19, Batch 1300] loss: 0.03325080750219058
[Epoch 19, Batch 1400] loss: 0.02335921620382578
[Epoch 19, Batch 1500] loss: 0.016460227504940122
[Epoch 19, Batch 1600] loss: 0.01730791553047311
[Epoch 19, Batch 1700] loss: 0.0229844488746312
[Epoch 19, Batch 1800] loss: 0.028612491468447843
[Epoch 19, Batch 1900] loss: 0.019293501512147485
[Epoch 19, Batch 2000] loss: 0.022877907714646425
[Epoch 19, Batch 2100] loss: 0.02210686364051071
[Epoch 19, Batch 2200] loss: 0.02360322019052546
[Epoch 19, Batch 2300] loss: 0.03149814520951622
[Epoch 19, Batch 2400] loss: 0.021849136051532696
[Epoch 19, Batch 2500] loss: 0.025589000434847547
[Epoch 19, Batch 2600] loss: 0.018671077784456428
[Epoch 19, Batch 2700] loss: 0.021682420607248787
[Epoch 19, Batch 2800] loss: 0.014029227835453639
[Epoch 19, Batch 2900] loss: 0.025674720139722922
[Epoch 19, Batch 3000] loss: 0.026260279530288245
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0451
Validation Accuracy: 0.9859
Overfitting: 0.0451
[Epoch 20, Batch 100] loss: 0.013850689481441804
[Epoch 20, Batch 200] loss: 0.02665161202334275
[Epoch 20, Batch 300] loss: 0.012490692290884908
[Epoch 20, Batch 400] loss: 0.014926812901103403
[Epoch 20, Batch 500] loss: 0.015009777407431101
[Epoch 20, Batch 600] loss: 0.024666337803610078
[Epoch 20, Batch 700] loss: 0.027555485051270808
[Epoch 20, Batch 800] loss: 0.024806267411186127
[Epoch 20, Batch 900] loss: 0.02081204484871705
[Epoch 20, Batch 1000] loss: 0.01831523319844564
[Epoch 20, Batch 1100] loss: 0.017246814966638338
[Epoch 20, Batch 1200] loss: 0.029521703615027945
[Epoch 20, Batch 1300] loss: 0.0203902560230199
[Epoch 20, Batch 1400] loss: 0.017043607679661364
[Epoch 20, Batch 1500] loss: 0.01741040972076007
[Epoch 20, Batch 1600] loss: 0.0167837317277008
[Epoch 20, Batch 1700] loss: 0.025182367929519386
[Epoch 20, Batch 1800] loss: 0.017802079007087742
[Epoch 20, Batch 1900] loss: 0.024298405743247712
[Epoch 20, Batch 2000] loss: 0.019736343784488783
[Epoch 20, Batch 2100] loss: 0.023658967971932725
[Epoch 20, Batch 2200] loss: 0.018674893297102244
[Epoch 20, Batch 2300] loss: 0.020067611020058395
[Epoch 20, Batch 2400] loss: 0.023104754815067283
[Epoch 20, Batch 2500] loss: 0.01602179781300947
[Epoch 20, Batch 2600] loss: 0.022087772506019974
[Epoch 20, Batch 2700] loss: 0.024556844100370654
[Epoch 20, Batch 2800] loss: 0.024342694458609912
[Epoch 20, Batch 2900] loss: 0.022313115638644375
[Epoch 20, Batch 3000] loss: 0.021638850855179043
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9870
Overfitting: 0.0431
Best model saved at epoch 20 with validation loss: 0.0431
[Epoch 21, Batch 100] loss: 0.01713502718939708
[Epoch 21, Batch 200] loss: 0.016185614025889663
[Epoch 21, Batch 300] loss: 0.012457253455941099
[Epoch 21, Batch 400] loss: 0.021128625112760348
[Epoch 21, Batch 500] loss: 0.020207885184063343
[Epoch 21, Batch 600] loss: 0.018839842341694748
[Epoch 21, Batch 700] loss: 0.017256549544181325
[Epoch 21, Batch 800] loss: 0.02197706813978584
[Epoch 21, Batch 900] loss: 0.02458329763092479
[Epoch 21, Batch 1000] loss: 0.01840734526325832
[Epoch 21, Batch 1100] loss: 0.029025195789145072
[Epoch 21, Batch 1200] loss: 0.017550648299729802
[Epoch 21, Batch 1300] loss: 0.009691282350941037
[Epoch 21, Batch 1400] loss: 0.019148051251613653
[Epoch 21, Batch 1500] loss: 0.012921917672720155
[Epoch 21, Batch 1600] loss: 0.019142541178334794
[Epoch 21, Batch 1700] loss: 0.019500737781563658
[Epoch 21, Batch 1800] loss: 0.017355041559349048
[Epoch 21, Batch 1900] loss: 0.042256688866327746
[Epoch 21, Batch 2000] loss: 0.016771144583908607
[Epoch 21, Batch 2100] loss: 0.02139730484010215
[Epoch 21, Batch 2200] loss: 0.016454301159574244
[Epoch 21, Batch 2300] loss: 0.011924450840742793
[Epoch 21, Batch 2400] loss: 0.016322286429203813
[Epoch 21, Batch 2500] loss: 0.018793954349839624
[Epoch 21, Batch 2600] loss: 0.009110254453116796
[Epoch 21, Batch 2700] loss: 0.016527864419986146
[Epoch 21, Batch 2800] loss: 0.027440022673126806
[Epoch 21, Batch 2900] loss: 0.021981249294331064
[Epoch 21, Batch 3000] loss: 0.02398903760700705
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9849
Overfitting: 0.0507
[Epoch 22, Batch 100] loss: 0.01195632543422107
[Epoch 22, Batch 200] loss: 0.01123102600202401
[Epoch 22, Batch 300] loss: 0.010253830313595245
[Epoch 22, Batch 400] loss: 0.01756076501937059
[Epoch 22, Batch 500] loss: 0.011881818605907028
[Epoch 22, Batch 600] loss: 0.02679567589366343
[Epoch 22, Batch 700] loss: 0.01729859503422631
[Epoch 22, Batch 800] loss: 0.017266910859707423
[Epoch 22, Batch 900] loss: 0.027924911426343898
[Epoch 22, Batch 1000] loss: 0.019531925713163218
[Epoch 22, Batch 1100] loss: 0.01882737736614217
[Epoch 22, Batch 1200] loss: 0.019202047988837876
[Epoch 22, Batch 1300] loss: 0.020912889799074037
[Epoch 22, Batch 1400] loss: 0.01392996191207203
[Epoch 22, Batch 1500] loss: 0.023765130891260925
[Epoch 22, Batch 1600] loss: 0.015207918931364474
[Epoch 22, Batch 1700] loss: 0.02155815332229395
[Epoch 22, Batch 1800] loss: 0.024389079269094508
[Epoch 22, Batch 1900] loss: 0.01539264078346605
[Epoch 22, Batch 2000] loss: 0.02958523985958891
[Epoch 22, Batch 2100] loss: 0.020152643073342916
[Epoch 22, Batch 2200] loss: 0.012108981435430906
[Epoch 22, Batch 2300] loss: 0.017426172927443986
[Epoch 22, Batch 2400] loss: 0.018867723081311853
[Epoch 22, Batch 2500] loss: 0.01777591439480602
[Epoch 22, Batch 2600] loss: 0.020044753947195203
[Epoch 22, Batch 2700] loss: 0.016985496182605857
[Epoch 22, Batch 2800] loss: 0.011344307443850994
[Epoch 22, Batch 2900] loss: 0.015173063647052914
[Epoch 22, Batch 3000] loss: 0.018762063795438735
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9859
Overfitting: 0.0446
[Epoch 23, Batch 100] loss: 0.015120967809689318
[Epoch 23, Batch 200] loss: 0.01376355858747047
[Epoch 23, Batch 300] loss: 0.007401766050825245
[Epoch 23, Batch 400] loss: 0.017748942109701602
[Epoch 23, Batch 500] loss: 0.017016956081643
[Epoch 23, Batch 600] loss: 0.01361001859805583
[Epoch 23, Batch 700] loss: 0.012180962947386433
[Epoch 23, Batch 800] loss: 0.019781055451894645
[Epoch 23, Batch 900] loss: 0.019491328594303924
[Epoch 23, Batch 1000] loss: 0.010796824897006445
[Epoch 23, Batch 1100] loss: 0.010507195219724963
[Epoch 23, Batch 1200] loss: 0.0171423666517876
[Epoch 23, Batch 1300] loss: 0.024336663588765076
[Epoch 23, Batch 1400] loss: 0.01861912828331697
[Epoch 23, Batch 1500] loss: 0.017327657029236433
[Epoch 23, Batch 1600] loss: 0.021241661345447936
[Epoch 23, Batch 1700] loss: 0.02247698972641956
[Epoch 23, Batch 1800] loss: 0.01759361220681967
[Epoch 23, Batch 1900] loss: 0.01009393300046213
[Epoch 23, Batch 2000] loss: 0.030919706869153744
[Epoch 23, Batch 2100] loss: 0.021279901236266597
[Epoch 23, Batch 2200] loss: 0.014700265927021974
[Epoch 23, Batch 2300] loss: 0.01977941354198265
[Epoch 23, Batch 2400] loss: 0.01880275066163449
[Epoch 23, Batch 2500] loss: 0.01907401225882495
[Epoch 23, Batch 2600] loss: 0.015854584905719095
[Epoch 23, Batch 2700] loss: 0.0227168455276842
[Epoch 23, Batch 2800] loss: 0.029489983536659565
[Epoch 23, Batch 2900] loss: 0.021660859239436833
[Epoch 23, Batch 3000] loss: 0.014678597364345479
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9865
Overfitting: 0.0431
[Epoch 24, Batch 100] loss: 0.0166141791532209
[Epoch 24, Batch 200] loss: 0.011905129722836137
[Epoch 24, Batch 300] loss: 0.009779822192213032
[Epoch 24, Batch 400] loss: 0.01255753931095569
[Epoch 24, Batch 500] loss: 0.014795950637198985
[Epoch 24, Batch 600] loss: 0.009459036709158682
[Epoch 24, Batch 700] loss: 0.012031432664061868
[Epoch 24, Batch 800] loss: 0.010601382511740667
[Epoch 24, Batch 900] loss: 0.013621423867061822
[Epoch 24, Batch 1000] loss: 0.03932111302485282
[Epoch 24, Batch 1100] loss: 0.011754587230952893
[Epoch 24, Batch 1200] loss: 0.014421731840357097
[Epoch 24, Batch 1300] loss: 0.013286162300973956
[Epoch 24, Batch 1400] loss: 0.008401485195718124
[Epoch 24, Batch 1500] loss: 0.011268200134582003
[Epoch 24, Batch 1600] loss: 0.02028992108978855
[Epoch 24, Batch 1700] loss: 0.012539953802370291
[Epoch 24, Batch 1800] loss: 0.01917523619289568
[Epoch 24, Batch 1900] loss: 0.018188579119632776
[Epoch 24, Batch 2000] loss: 0.01715975362665631
[Epoch 24, Batch 2100] loss: 0.018114033024012315
[Epoch 24, Batch 2200] loss: 0.013937660860992764
[Epoch 24, Batch 2300] loss: 0.020359416510736993
[Epoch 24, Batch 2400] loss: 0.012073149602510966
[Epoch 24, Batch 2500] loss: 0.012126559492571687
[Epoch 24, Batch 2600] loss: 0.014024574715022027
[Epoch 24, Batch 2700] loss: 0.014898146455161623
[Epoch 24, Batch 2800] loss: 0.014969033212255454
[Epoch 24, Batch 2900] loss: 0.027743145262993495
[Epoch 24, Batch 3000] loss: 0.019669044979127647
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9861
Overfitting: 0.0469
Fold 5 validation loss: 0.0469
Mean validation loss across all folds for Trial 5 is 0.0469 with trial config:  l1: 256, l2: 128, lr: 0.00032927591344236165, batch_size: 16
[I 2024-12-10 06:53:12,444] Trial 4 finished with value: 0.046893630782967134 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16}. Best is trial 4 with value: 0.046893630782967134.

Selected Hyperparameters for Trial 6:
  l1: 256, l2: 128, lr: 0.00011348084525743877, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2992156028747557
[Epoch 1, Batch 200] loss: 2.3019759392738344
[Epoch 1, Batch 300] loss: 2.2974631714820863
[Epoch 1, Batch 400] loss: 2.292926592826843
[Epoch 1, Batch 500] loss: 2.289275288581848
[Epoch 1, Batch 600] loss: 2.284437880516052
[Epoch 1, Batch 700] loss: 2.277989230155945
[Epoch 1, Batch 800] loss: 2.270291893482208
[Epoch 1, Batch 900] loss: 2.264790515899658
[Epoch 1, Batch 1000] loss: 2.25563001871109
[Epoch 1, Batch 1100] loss: 2.2489405179023745
[Epoch 1, Batch 1200] loss: 2.2357623195648193
[Epoch 1, Batch 1300] loss: 2.2234331464767454
[Epoch 1, Batch 1400] loss: 2.206638879776001
[Epoch 1, Batch 1500] loss: 2.1828411769866944
[Epoch 1, Batch 1600] loss: 2.160825548171997
[Epoch 1, Batch 1700] loss: 2.1267076468467714
[Epoch 1, Batch 1800] loss: 2.080531997680664
[Epoch 1, Batch 1900] loss: 2.008440351486206
[Epoch 1, Batch 2000] loss: 1.9202334487438202
[Epoch 1, Batch 2100] loss: 1.837484246492386
[Epoch 1, Batch 2200] loss: 1.66868488073349
[Epoch 1, Batch 2300] loss: 1.4862907803058625
[Epoch 1, Batch 2400] loss: 1.355481989979744
[Epoch 1, Batch 2500] loss: 1.1818295300006867
[Epoch 1, Batch 2600] loss: 1.0478868556022645
[Epoch 1, Batch 2700] loss: 0.9250439214706421
[Epoch 1, Batch 2800] loss: 0.8295239293575287
[Epoch 1, Batch 2900] loss: 0.7409079560637474
[Epoch 1, Batch 3000] loss: 0.6791544419527054
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.6296
Validation Accuracy: 0.8310
Overfitting: 0.6296
Best model saved at epoch 1 with validation loss: 0.6296
[Epoch 2, Batch 100] loss: 0.5971020896732807
[Epoch 2, Batch 200] loss: 0.590504113137722
[Epoch 2, Batch 300] loss: 0.551024647951126
[Epoch 2, Batch 400] loss: 0.5599546246230602
[Epoch 2, Batch 500] loss: 0.4884905482828617
[Epoch 2, Batch 600] loss: 0.4948546073585749
[Epoch 2, Batch 700] loss: 0.45644954904913904
[Epoch 2, Batch 800] loss: 0.4864758645743132
[Epoch 2, Batch 900] loss: 0.432418874502182
[Epoch 2, Batch 1000] loss: 0.46366093009710313
[Epoch 2, Batch 1100] loss: 0.44728979624807835
[Epoch 2, Batch 1200] loss: 0.45199268996715547
[Epoch 2, Batch 1300] loss: 0.3982221423834562
[Epoch 2, Batch 1400] loss: 0.4285883077979088
[Epoch 2, Batch 1500] loss: 0.4181159233301878
[Epoch 2, Batch 1600] loss: 0.37613624036312104
[Epoch 2, Batch 1700] loss: 0.3976793630048633
[Epoch 2, Batch 1800] loss: 0.40415455508977177
[Epoch 2, Batch 1900] loss: 0.426506217867136
[Epoch 2, Batch 2000] loss: 0.3330456643551588
[Epoch 2, Batch 2100] loss: 0.3635588867589831
[Epoch 2, Batch 2200] loss: 0.3212559525296092
[Epoch 2, Batch 2300] loss: 0.34328785017132757
[Epoch 2, Batch 2400] loss: 0.36188157230615614
[Epoch 2, Batch 2500] loss: 0.33836589340120554
[Epoch 2, Batch 2600] loss: 0.35342739798128603
[Epoch 2, Batch 2700] loss: 0.35001665659248826
[Epoch 2, Batch 2800] loss: 0.3417082668840885
[Epoch 2, Batch 2900] loss: 0.3567578513920307
[Epoch 2, Batch 3000] loss: 0.3198193846270442
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.3052
Validation Accuracy: 0.9091
Overfitting: 0.3052
Best model saved at epoch 2 with validation loss: 0.3052
[Epoch 3, Batch 100] loss: 0.3380169245228171
[Epoch 3, Batch 200] loss: 0.29767523128539325
[Epoch 3, Batch 300] loss: 0.3212347183004022
[Epoch 3, Batch 400] loss: 0.2898985516652465
[Epoch 3, Batch 500] loss: 0.27979134902358055
[Epoch 3, Batch 600] loss: 0.32929002679884434
[Epoch 3, Batch 700] loss: 0.31312839113175867
[Epoch 3, Batch 800] loss: 0.25583008728921414
[Epoch 3, Batch 900] loss: 0.29802754312753676
[Epoch 3, Batch 1000] loss: 0.26766665568575265
[Epoch 3, Batch 1100] loss: 0.31615986172109845
[Epoch 3, Batch 1200] loss: 0.2785383240878582
[Epoch 3, Batch 1300] loss: 0.2847404681891203
[Epoch 3, Batch 1400] loss: 0.29259865790605544
[Epoch 3, Batch 1500] loss: 0.29070467641577125
[Epoch 3, Batch 1600] loss: 0.2794298208504915
[Epoch 3, Batch 1700] loss: 0.2453440179862082
[Epoch 3, Batch 1800] loss: 0.2620474234782159
[Epoch 3, Batch 1900] loss: 0.2503097549080849
[Epoch 3, Batch 2000] loss: 0.268217131216079
[Epoch 3, Batch 2100] loss: 0.30027642846107483
[Epoch 3, Batch 2200] loss: 0.2621091789379716
[Epoch 3, Batch 2300] loss: 0.2837833337858319
[Epoch 3, Batch 2400] loss: 0.2518648850545287
[Epoch 3, Batch 2500] loss: 0.2541889274306595
[Epoch 3, Batch 2600] loss: 0.2789536490663886
[Epoch 3, Batch 2700] loss: 0.23349428882822396
[Epoch 3, Batch 2800] loss: 0.23323252240195871
[Epoch 3, Batch 2900] loss: 0.2543213727325201
[Epoch 3, Batch 3000] loss: 0.24498226799070835
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.2241
Validation Accuracy: 0.9343
Overfitting: 0.2241
Best model saved at epoch 3 with validation loss: 0.2241
[Epoch 4, Batch 100] loss: 0.22857450049370528
[Epoch 4, Batch 200] loss: 0.23327923560515046
[Epoch 4, Batch 300] loss: 0.23071765433065594
[Epoch 4, Batch 400] loss: 0.23706052149645984
[Epoch 4, Batch 500] loss: 0.2300860907882452
[Epoch 4, Batch 600] loss: 0.2494485610537231
[Epoch 4, Batch 700] loss: 0.21748396122828126
[Epoch 4, Batch 800] loss: 0.2288798107393086
[Epoch 4, Batch 900] loss: 0.24175013184547425
[Epoch 4, Batch 1000] loss: 0.21407839484512806
[Epoch 4, Batch 1100] loss: 0.20858728542923927
[Epoch 4, Batch 1200] loss: 0.2232973820809275
[Epoch 4, Batch 1300] loss: 0.22046154983341693
[Epoch 4, Batch 1400] loss: 0.23719539913348853
[Epoch 4, Batch 1500] loss: 0.23304911891929805
[Epoch 4, Batch 1600] loss: 0.2155430302210152
[Epoch 4, Batch 1700] loss: 0.20286632107570768
[Epoch 4, Batch 1800] loss: 0.22760985458269714
[Epoch 4, Batch 1900] loss: 0.20091253941878676
[Epoch 4, Batch 2000] loss: 0.18107889870647342
[Epoch 4, Batch 2100] loss: 0.17785442059859632
[Epoch 4, Batch 2200] loss: 0.20990993740037084
[Epoch 4, Batch 2300] loss: 0.23094985779374838
[Epoch 4, Batch 2400] loss: 0.17576642110012472
[Epoch 4, Batch 2500] loss: 0.18364103856030853
[Epoch 4, Batch 2600] loss: 0.19358846846967936
[Epoch 4, Batch 2700] loss: 0.161832273658365
[Epoch 4, Batch 2800] loss: 0.20661774734035135
[Epoch 4, Batch 2900] loss: 0.21495278498157858
[Epoch 4, Batch 3000] loss: 0.1800277244206518
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1723
Validation Accuracy: 0.9491
Overfitting: 0.1723
Best model saved at epoch 4 with validation loss: 0.1723
[Epoch 5, Batch 100] loss: 0.1875847811624408
[Epoch 5, Batch 200] loss: 0.16893440176732838
[Epoch 5, Batch 300] loss: 0.18400971559807658
[Epoch 5, Batch 400] loss: 0.19446879611350595
[Epoch 5, Batch 500] loss: 0.1615291578695178
[Epoch 5, Batch 600] loss: 0.1813178657833487
[Epoch 5, Batch 700] loss: 0.20460078466683626
[Epoch 5, Batch 800] loss: 0.1802884310670197
[Epoch 5, Batch 900] loss: 0.19653198558837176
[Epoch 5, Batch 1000] loss: 0.1963568175304681
[Epoch 5, Batch 1100] loss: 0.153754743617028
[Epoch 5, Batch 1200] loss: 0.16822358628734946
[Epoch 5, Batch 1300] loss: 0.16340171608142554
[Epoch 5, Batch 1400] loss: 0.1783108062017709
[Epoch 5, Batch 1500] loss: 0.17483674644492567
[Epoch 5, Batch 1600] loss: 0.13772092738188804
[Epoch 5, Batch 1700] loss: 0.14312550672329963
[Epoch 5, Batch 1800] loss: 0.18931067720986902
[Epoch 5, Batch 1900] loss: 0.19181569418869912
[Epoch 5, Batch 2000] loss: 0.15984676672145726
[Epoch 5, Batch 2100] loss: 0.15617076609283687
[Epoch 5, Batch 2200] loss: 0.1800707378424704
[Epoch 5, Batch 2300] loss: 0.15475012810900807
[Epoch 5, Batch 2400] loss: 0.15492028871551156
[Epoch 5, Batch 2500] loss: 0.1953241732157767
[Epoch 5, Batch 2600] loss: 0.17399911708198487
[Epoch 5, Batch 2700] loss: 0.16575841065496205
[Epoch 5, Batch 2800] loss: 0.17572802643291652
[Epoch 5, Batch 2900] loss: 0.13672079533338546
[Epoch 5, Batch 3000] loss: 0.14343656391836704
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1381
Validation Accuracy: 0.9564
Overfitting: 0.1381
Best model saved at epoch 5 with validation loss: 0.1381
[Epoch 6, Batch 100] loss: 0.14045696618966758
[Epoch 6, Batch 200] loss: 0.17131475921254605
[Epoch 6, Batch 300] loss: 0.1474887250456959
[Epoch 6, Batch 400] loss: 0.17530693031381817
[Epoch 6, Batch 500] loss: 0.1456651533767581
[Epoch 6, Batch 600] loss: 0.16061987841501832
[Epoch 6, Batch 700] loss: 0.1600958477705717
[Epoch 6, Batch 800] loss: 0.15153880270197986
[Epoch 6, Batch 900] loss: 0.1389638800313696
[Epoch 6, Batch 1000] loss: 0.11643588004633784
[Epoch 6, Batch 1100] loss: 0.13055021033622324
[Epoch 6, Batch 1200] loss: 0.13548564962577075
[Epoch 6, Batch 1300] loss: 0.1337934360932559
[Epoch 6, Batch 1400] loss: 0.1652377661317587
[Epoch 6, Batch 1500] loss: 0.16850024981424214
[Epoch 6, Batch 1600] loss: 0.17682439050637186
[Epoch 6, Batch 1700] loss: 0.138813484525308
[Epoch 6, Batch 1800] loss: 0.12529865016695113
[Epoch 6, Batch 1900] loss: 0.12434521303512155
[Epoch 6, Batch 2000] loss: 0.12975114558823406
[Epoch 6, Batch 2100] loss: 0.16502494388259947
[Epoch 6, Batch 2200] loss: 0.14351039073430003
[Epoch 6, Batch 2300] loss: 0.13265613286290318
[Epoch 6, Batch 2400] loss: 0.13436386958695948
[Epoch 6, Batch 2500] loss: 0.15174653398804366
[Epoch 6, Batch 2600] loss: 0.15592881524469704
[Epoch 6, Batch 2700] loss: 0.12082436335273088
[Epoch 6, Batch 2800] loss: 0.1109078416414559
[Epoch 6, Batch 2900] loss: 0.13350169642828405
[Epoch 6, Batch 3000] loss: 0.1373115743184462
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.1390
Validation Accuracy: 0.9566
Overfitting: 0.1390
[I 2024-12-10 06:54:47,280] Trial 5 pruned. 

Selected Hyperparameters for Trial 7:
  l1: 256, l2: 128, lr: 0.002439578684743188, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.269386968612671
[Epoch 1, Batch 200] loss: 1.4882496625185013
[Epoch 1, Batch 300] loss: 0.49544353783130646
[Epoch 1, Batch 400] loss: 0.3401570385694504
[Epoch 1, Batch 500] loss: 0.29525669783353803
[Epoch 1, Batch 600] loss: 0.2616923478990793
[Epoch 1, Batch 700] loss: 0.19574210606515408
**STATS for Epoch 1** : 
Average training loss: 0.0138
Average validation loss: 0.1682
Validation Accuracy: 0.9508
Overfitting: 0.1544
Best model saved at epoch 1 with validation loss: 0.1682
[Epoch 2, Batch 100] loss: 0.16745828837156296
[Epoch 2, Batch 200] loss: 0.18693215608596803
[Epoch 2, Batch 300] loss: 0.14471174739301204
[Epoch 2, Batch 400] loss: 0.1263310044258833
[Epoch 2, Batch 500] loss: 0.12993148097768425
[Epoch 2, Batch 600] loss: 0.12348350573331118
[Epoch 2, Batch 700] loss: 0.10925466833636165
**STATS for Epoch 2** : 
Average training loss: 0.0073
Average validation loss: 0.0954
Validation Accuracy: 0.9706
Overfitting: 0.0881
Best model saved at epoch 2 with validation loss: 0.0954
[Epoch 3, Batch 100] loss: 0.10293331570923328
[Epoch 3, Batch 200] loss: 0.10602191428653895
[Epoch 3, Batch 300] loss: 0.09316021305508912
[Epoch 3, Batch 400] loss: 0.08786043314263224
[Epoch 3, Batch 500] loss: 0.09201627314090728
[Epoch 3, Batch 600] loss: 0.08769855223596096
[Epoch 3, Batch 700] loss: 0.09108581344597041
**STATS for Epoch 3** : 
Average training loss: 0.0057
Average validation loss: 0.0726
Validation Accuracy: 0.9770
Overfitting: 0.0669
Best model saved at epoch 3 with validation loss: 0.0726
[Epoch 4, Batch 100] loss: 0.07789503928273916
[Epoch 4, Batch 200] loss: 0.06682596544735134
[Epoch 4, Batch 300] loss: 0.08240458456799388
[Epoch 4, Batch 400] loss: 0.0763473100308329
[Epoch 4, Batch 500] loss: 0.07899300317745656
[Epoch 4, Batch 600] loss: 0.06877586052753032
[Epoch 4, Batch 700] loss: 0.0709831489622593
**STATS for Epoch 4** : 
Average training loss: 0.0042
Average validation loss: 0.0684
Validation Accuracy: 0.9792
Overfitting: 0.0642
Best model saved at epoch 4 with validation loss: 0.0684
[Epoch 5, Batch 100] loss: 0.06518999086227267
[Epoch 5, Batch 200] loss: 0.057162795905023815
[Epoch 5, Batch 300] loss: 0.06725637444877065
[Epoch 5, Batch 400] loss: 0.06076872545760125
[Epoch 5, Batch 500] loss: 0.058337636990472674
[Epoch 5, Batch 600] loss: 0.05976248006802052
[Epoch 5, Batch 700] loss: 0.055882391859777274
**STATS for Epoch 5** : 
Average training loss: 0.0044
Average validation loss: 0.0620
Validation Accuracy: 0.9810
Overfitting: 0.0576
Best model saved at epoch 5 with validation loss: 0.0620
[Epoch 6, Batch 100] loss: 0.053973544598557056
[Epoch 6, Batch 200] loss: 0.05008668297203258
[Epoch 6, Batch 300] loss: 0.05057867096504196
[Epoch 6, Batch 400] loss: 0.048348601751495156
[Epoch 6, Batch 500] loss: 0.05613506435416639
[Epoch 6, Batch 600] loss: 0.054958711778745055
[Epoch 6, Batch 700] loss: 0.042988139272201804
**STATS for Epoch 6** : 
Average training loss: 0.0030
Average validation loss: 0.0648
Validation Accuracy: 0.9797
Overfitting: 0.0617
[Epoch 7, Batch 100] loss: 0.04634908180451021
[Epoch 7, Batch 200] loss: 0.038146066770423204
[Epoch 7, Batch 300] loss: 0.04717391256475821
[Epoch 7, Batch 400] loss: 0.046216831137426195
[Epoch 7, Batch 500] loss: 0.042145060780458155
[Epoch 7, Batch 600] loss: 0.0481872111139819
[Epoch 7, Batch 700] loss: 0.04802961288718507
**STATS for Epoch 7** : 
Average training loss: 0.0028
Average validation loss: 0.0517
Validation Accuracy: 0.9836
Overfitting: 0.0488
Best model saved at epoch 7 with validation loss: 0.0517
[Epoch 8, Batch 100] loss: 0.0334595918370178
[Epoch 8, Batch 200] loss: 0.04416818019933998
[Epoch 8, Batch 300] loss: 0.03626616308116354
[Epoch 8, Batch 400] loss: 0.03951980945654213
[Epoch 8, Batch 500] loss: 0.03758536304114386
[Epoch 8, Batch 600] loss: 0.04418933377368375
[Epoch 8, Batch 700] loss: 0.03938517709728331
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0515
Validation Accuracy: 0.9842
Overfitting: 0.0491
Best model saved at epoch 8 with validation loss: 0.0515
[Epoch 9, Batch 100] loss: 0.033459165781969204
[Epoch 9, Batch 200] loss: 0.027817541136173532
[Epoch 9, Batch 300] loss: 0.038978436994366344
[Epoch 9, Batch 400] loss: 0.03908028140198439
[Epoch 9, Batch 500] loss: 0.02928831577533856
[Epoch 9, Batch 600] loss: 0.03153878187760711
[Epoch 9, Batch 700] loss: 0.04310278735705651
**STATS for Epoch 9** : 
Average training loss: 0.0022
Average validation loss: 0.0507
Validation Accuracy: 0.9849
Overfitting: 0.0485
Best model saved at epoch 9 with validation loss: 0.0507
[Epoch 10, Batch 100] loss: 0.028827522514620795
[Epoch 10, Batch 200] loss: 0.032576042667496946
[Epoch 10, Batch 300] loss: 0.028274534344673155
[Epoch 10, Batch 400] loss: 0.02867228743620217
[Epoch 10, Batch 500] loss: 0.030511917527765036
[Epoch 10, Batch 600] loss: 0.030530632499721832
[Epoch 10, Batch 700] loss: 0.03355902516865172
**STATS for Epoch 10** : 
Average training loss: 0.0021
Average validation loss: 0.0501
Validation Accuracy: 0.9847
Overfitting: 0.0480
Best model saved at epoch 10 with validation loss: 0.0501
[Epoch 11, Batch 100] loss: 0.025368103977525605
[Epoch 11, Batch 200] loss: 0.024538720253913196
[Epoch 11, Batch 300] loss: 0.031210877860430628
[Epoch 11, Batch 400] loss: 0.03130180195672438
[Epoch 11, Batch 500] loss: 0.02521571311284788
[Epoch 11, Batch 600] loss: 0.021921170725254343
[Epoch 11, Batch 700] loss: 0.029021820126799866
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0490
Validation Accuracy: 0.9851
Overfitting: 0.0472
Best model saved at epoch 11 with validation loss: 0.0490
[Epoch 12, Batch 100] loss: 0.016013970475760288
[Epoch 12, Batch 200] loss: 0.027271314899480786
[Epoch 12, Batch 300] loss: 0.027298641299712472
[Epoch 12, Batch 400] loss: 0.029965033173793926
[Epoch 12, Batch 500] loss: 0.02419560707581695
[Epoch 12, Batch 600] loss: 0.02423526739992667
[Epoch 12, Batch 700] loss: 0.027818457255489194
**STATS for Epoch 12** : 
Average training loss: 0.0019
Average validation loss: 0.0503
Validation Accuracy: 0.9839
Overfitting: 0.0484
[Epoch 13, Batch 100] loss: 0.02496602166327648
[Epoch 13, Batch 200] loss: 0.02231678504962474
[Epoch 13, Batch 300] loss: 0.012842271387926303
[Epoch 13, Batch 400] loss: 0.02170653502602363
[Epoch 13, Batch 500] loss: 0.024023925127694384
[Epoch 13, Batch 600] loss: 0.021849212346278363
[Epoch 13, Batch 700] loss: 0.023361783630680293
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0499
Validation Accuracy: 0.9849
Overfitting: 0.0484
[I 2024-12-10 06:57:06,860] Trial 6 pruned. 

Selected Hyperparameters for Trial 8:
  l1: 256, l2: 128, lr: 0.0006380434077440606, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.300049297809601
**STATS for Epoch 1** : 
Average training loss: 1.0722
Average validation loss: 2.2843
Validation Accuracy: 0.1809
Overfitting: 1.2122
Best model saved at epoch 1 with validation loss: 2.2843
[Epoch 2, Batch 100] loss: 2.276748421192169
**STATS for Epoch 2** : 
Average training loss: 1.0557
Average validation loss: 2.2393
Validation Accuracy: 0.4023
Overfitting: 1.1836
Best model saved at epoch 2 with validation loss: 2.2393
[Epoch 3, Batch 100] loss: 2.2082683563232424
**STATS for Epoch 3** : 
Average training loss: 0.9741
Average validation loss: 1.9405
Validation Accuracy: 0.5602
Overfitting: 0.9665
Best model saved at epoch 3 with validation loss: 1.9405
[Epoch 4, Batch 100] loss: 1.6221940863132476
**STATS for Epoch 4** : 
Average training loss: 0.4494
Average validation loss: 0.7454
Validation Accuracy: 0.7889
Overfitting: 0.2960
Best model saved at epoch 4 with validation loss: 0.7454
[Epoch 5, Batch 100] loss: 0.6342260622978211
**STATS for Epoch 5** : 
Average training loss: 0.2380
Average validation loss: 0.4560
Validation Accuracy: 0.8584
Overfitting: 0.2180
Best model saved at epoch 5 with validation loss: 0.4560
[Epoch 6, Batch 100] loss: 0.4392661839723587
**STATS for Epoch 6** : 
Average training loss: 0.1880
Average validation loss: 0.3700
Validation Accuracy: 0.8875
Overfitting: 0.1820
[I 2024-12-10 06:58:02,360] Trial 7 pruned. 

Selected Hyperparameters for Trial 9:
  l1: 256, l2: 64, lr: 0.0011075021673381486, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.285388221740723
[Epoch 1, Batch 200] loss: 2.188204039335251
[Epoch 1, Batch 300] loss: 1.5020299077033996
[Epoch 1, Batch 400] loss: 0.697105533182621
[Epoch 1, Batch 500] loss: 0.559061829149723
[Epoch 1, Batch 600] loss: 0.4313298738747835
[Epoch 1, Batch 700] loss: 0.44392608880996703
[Epoch 1, Batch 800] loss: 0.327759101241827
[Epoch 1, Batch 900] loss: 0.3637379097752273
[Epoch 1, Batch 1000] loss: 0.27300584994256494
[Epoch 1, Batch 1100] loss: 0.33434750854969025
[Epoch 1, Batch 1200] loss: 0.2617795879393816
[Epoch 1, Batch 1300] loss: 0.21456702014431359
[Epoch 1, Batch 1400] loss: 0.24458859767764807
[Epoch 1, Batch 1500] loss: 0.22578236538916827
[Epoch 1, Batch 1600] loss: 0.20322336237877608
[Epoch 1, Batch 1700] loss: 0.2338157040067017
[Epoch 1, Batch 1800] loss: 0.19023882857523858
[Epoch 1, Batch 1900] loss: 0.1548868156876415
[Epoch 1, Batch 2000] loss: 0.18022146949544549
[Epoch 1, Batch 2100] loss: 0.16648998233489692
[Epoch 1, Batch 2200] loss: 0.15588705496862532
[Epoch 1, Batch 2300] loss: 0.14471238667145372
[Epoch 1, Batch 2400] loss: 0.13759042509831487
[Epoch 1, Batch 2500] loss: 0.11051089513581246
[Epoch 1, Batch 2600] loss: 0.1170423923432827
[Epoch 1, Batch 2700] loss: 0.13620081713423132
[Epoch 1, Batch 2800] loss: 0.14459499855525793
[Epoch 1, Batch 2900] loss: 0.1311629094183445
[Epoch 1, Batch 3000] loss: 0.13278945881174878
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1125
Validation Accuracy: 0.9641
Overfitting: 0.1125
Best model saved at epoch 1 with validation loss: 0.1125
[Epoch 2, Batch 100] loss: 0.104445073264651
[Epoch 2, Batch 200] loss: 0.11983042675536126
[Epoch 2, Batch 300] loss: 0.11485242615919561
[Epoch 2, Batch 400] loss: 0.09424872032832354
[Epoch 2, Batch 500] loss: 0.08633839926216752
[Epoch 2, Batch 600] loss: 0.10152248154394329
[Epoch 2, Batch 700] loss: 0.10968676494667307
[Epoch 2, Batch 800] loss: 0.1032223040633835
[Epoch 2, Batch 900] loss: 0.0970900795632042
[Epoch 2, Batch 1000] loss: 0.09397293709567749
[Epoch 2, Batch 1100] loss: 0.11937348487786949
[Epoch 2, Batch 1200] loss: 0.12591141218785196
[Epoch 2, Batch 1300] loss: 0.10414819116704166
[Epoch 2, Batch 1400] loss: 0.09693977714050561
[Epoch 2, Batch 1500] loss: 0.10219744326081127
[Epoch 2, Batch 1600] loss: 0.09026068148959894
[Epoch 2, Batch 1700] loss: 0.07135650075390004
[Epoch 2, Batch 1800] loss: 0.09535956910112872
[Epoch 2, Batch 1900] loss: 0.11231964624021203
[Epoch 2, Batch 2000] loss: 0.08216749416664243
[Epoch 2, Batch 2100] loss: 0.07575205662171357
[Epoch 2, Batch 2200] loss: 0.09300492415903136
[Epoch 2, Batch 2300] loss: 0.0793718344863737
[Epoch 2, Batch 2400] loss: 0.08438387056346983
[Epoch 2, Batch 2500] loss: 0.10079963066265918
[Epoch 2, Batch 2600] loss: 0.06232678012340329
[Epoch 2, Batch 2700] loss: 0.13194025922217406
[Epoch 2, Batch 2800] loss: 0.07548378647887148
[Epoch 2, Batch 2900] loss: 0.08174418652197346
[Epoch 2, Batch 3000] loss: 0.08183756363228895
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0783
Validation Accuracy: 0.9751
Overfitting: 0.0783
Best model saved at epoch 2 with validation loss: 0.0783
[Epoch 3, Batch 100] loss: 0.08203783240634949
[Epoch 3, Batch 200] loss: 0.07023219447932207
[Epoch 3, Batch 300] loss: 0.07778474685852416
[Epoch 3, Batch 400] loss: 0.08024138703243806
[Epoch 3, Batch 500] loss: 0.06625421663629823
[Epoch 3, Batch 600] loss: 0.06466744072851725
[Epoch 3, Batch 700] loss: 0.08920406968565658
[Epoch 3, Batch 800] loss: 0.06513808984309435
[Epoch 3, Batch 900] loss: 0.05777706976339687
[Epoch 3, Batch 1000] loss: 0.055327096099499616
[Epoch 3, Batch 1100] loss: 0.06912321103969589
[Epoch 3, Batch 1200] loss: 0.05878898316703271
[Epoch 3, Batch 1300] loss: 0.06757785301888361
[Epoch 3, Batch 1400] loss: 0.07484030363208148
[Epoch 3, Batch 1500] loss: 0.06761544707405846
[Epoch 3, Batch 1600] loss: 0.07075356795219705
[Epoch 3, Batch 1700] loss: 0.075939934993512
[Epoch 3, Batch 1800] loss: 0.07930305760470219
[Epoch 3, Batch 1900] loss: 0.058565833020256836
[Epoch 3, Batch 2000] loss: 0.06208277651108801
[Epoch 3, Batch 2100] loss: 0.08575311298831366
[Epoch 3, Batch 2200] loss: 0.058593632153933865
[Epoch 3, Batch 2300] loss: 0.0423454361432232
[Epoch 3, Batch 2400] loss: 0.07451878970052349
[Epoch 3, Batch 2500] loss: 0.056240830376045776
[Epoch 3, Batch 2600] loss: 0.06663459753675852
[Epoch 3, Batch 2700] loss: 0.05194805945284316
[Epoch 3, Batch 2800] loss: 0.05697646872373298
[Epoch 3, Batch 2900] loss: 0.06867298274330097
[Epoch 3, Batch 3000] loss: 0.04124348617566284
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0616
Validation Accuracy: 0.9802
Overfitting: 0.0616
Best model saved at epoch 3 with validation loss: 0.0616
[Epoch 4, Batch 100] loss: 0.0692283206115826
[Epoch 4, Batch 200] loss: 0.05495741324295523
[Epoch 4, Batch 300] loss: 0.04209943243768066
[Epoch 4, Batch 400] loss: 0.04022305851176498
[Epoch 4, Batch 500] loss: 0.059732793055445654
[Epoch 4, Batch 600] loss: 0.05221598821342923
[Epoch 4, Batch 700] loss: 0.041145431336481124
[Epoch 4, Batch 800] loss: 0.05014322478731628
[Epoch 4, Batch 900] loss: 0.048981194047082684
[Epoch 4, Batch 1000] loss: 0.042915642692241816
[Epoch 4, Batch 1100] loss: 0.059117841621045955
[Epoch 4, Batch 1200] loss: 0.04912313605163945
[Epoch 4, Batch 1300] loss: 0.05535991257289424
[Epoch 4, Batch 1400] loss: 0.05248718798451591
[Epoch 4, Batch 1500] loss: 0.04745871834486024
[Epoch 4, Batch 1600] loss: 0.06954160137451254
[Epoch 4, Batch 1700] loss: 0.053295795581070705
[Epoch 4, Batch 1800] loss: 0.04386323112907121
[Epoch 4, Batch 1900] loss: 0.04701337879443599
[Epoch 4, Batch 2000] loss: 0.05341126800951315
[Epoch 4, Batch 2100] loss: 0.03645895920722978
[Epoch 4, Batch 2200] loss: 0.0481504443770973
[Epoch 4, Batch 2300] loss: 0.03967175584693905
[Epoch 4, Batch 2400] loss: 0.048781334573141065
[Epoch 4, Batch 2500] loss: 0.05809170122083742
[Epoch 4, Batch 2600] loss: 0.04208245549001731
[Epoch 4, Batch 2700] loss: 0.0492293798411265
[Epoch 4, Batch 2800] loss: 0.049543363125121684
[Epoch 4, Batch 2900] loss: 0.051898406637774314
[Epoch 4, Batch 3000] loss: 0.062433556524920275
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9832
Overfitting: 0.0509
Best model saved at epoch 4 with validation loss: 0.0509
[Epoch 5, Batch 100] loss: 0.04107885461417027
[Epoch 5, Batch 200] loss: 0.030003556237352312
[Epoch 5, Batch 300] loss: 0.04086074288890813
[Epoch 5, Batch 400] loss: 0.03478998670063447
[Epoch 5, Batch 500] loss: 0.04117611171517638
[Epoch 5, Batch 600] loss: 0.051173828504324774
[Epoch 5, Batch 700] loss: 0.03916388252764591
[Epoch 5, Batch 800] loss: 0.03927841774275294
[Epoch 5, Batch 900] loss: 0.028278065231934307
[Epoch 5, Batch 1000] loss: 0.039931969365134136
[Epoch 5, Batch 1100] loss: 0.03693046963453526
[Epoch 5, Batch 1200] loss: 0.036548882441566094
[Epoch 5, Batch 1300] loss: 0.044760116417019165
[Epoch 5, Batch 1400] loss: 0.051307342587097085
[Epoch 5, Batch 1500] loss: 0.04647610029263888
[Epoch 5, Batch 1600] loss: 0.044528675218462016
[Epoch 5, Batch 1700] loss: 0.035647188657021614
[Epoch 5, Batch 1800] loss: 0.04842633444000967
[Epoch 5, Batch 1900] loss: 0.05861707973148441
[Epoch 5, Batch 2000] loss: 0.03265286999841919
[Epoch 5, Batch 2100] loss: 0.042970273596438346
[Epoch 5, Batch 2200] loss: 0.053717132360761755
[Epoch 5, Batch 2300] loss: 0.038811201274220365
[Epoch 5, Batch 2400] loss: 0.04678848964045756
[Epoch 5, Batch 2500] loss: 0.04129472004045965
[Epoch 5, Batch 2600] loss: 0.028100491346849596
[Epoch 5, Batch 2700] loss: 0.031464594586141176
[Epoch 5, Batch 2800] loss: 0.04486299068375956
[Epoch 5, Batch 2900] loss: 0.036516373157792256
[Epoch 5, Batch 3000] loss: 0.04640237389641697
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9836
Overfitting: 0.0450
Best model saved at epoch 5 with validation loss: 0.0450
[Epoch 6, Batch 100] loss: 0.037074950047535825
[Epoch 6, Batch 200] loss: 0.04154200577992015
[Epoch 6, Batch 300] loss: 0.048533134019526185
[Epoch 6, Batch 400] loss: 0.028364634402096273
[Epoch 6, Batch 500] loss: 0.02774641238815093
[Epoch 6, Batch 600] loss: 0.05824224537616828
[Epoch 6, Batch 700] loss: 0.03918071035266621
[Epoch 6, Batch 800] loss: 0.04245901795336977
[Epoch 6, Batch 900] loss: 0.0323845740831166
[Epoch 6, Batch 1000] loss: 0.03710093401823542
[Epoch 6, Batch 1100] loss: 0.02681059583592287
[Epoch 6, Batch 1200] loss: 0.026746903053281132
[Epoch 6, Batch 1300] loss: 0.0336753610818414
[Epoch 6, Batch 1400] loss: 0.03517002808890538
[Epoch 6, Batch 1500] loss: 0.030173484672995982
[Epoch 6, Batch 1600] loss: 0.022393670237070184
[Epoch 6, Batch 1700] loss: 0.027620680893523968
[Epoch 6, Batch 1800] loss: 0.04336757540004328
[Epoch 6, Batch 1900] loss: 0.03720245178454206
[Epoch 6, Batch 2000] loss: 0.03734242670027015
[Epoch 6, Batch 2100] loss: 0.026111847796855728
[Epoch 6, Batch 2200] loss: 0.03324645862096077
[Epoch 6, Batch 2300] loss: 0.04296653388475533
[Epoch 6, Batch 2400] loss: 0.03115794413475669
[Epoch 6, Batch 2500] loss: 0.032934312916186176
[Epoch 6, Batch 2600] loss: 0.032410656737411045
[Epoch 6, Batch 2700] loss: 0.0336848040042787
[Epoch 6, Batch 2800] loss: 0.033086706464528104
[Epoch 6, Batch 2900] loss: 0.024255464652742375
[Epoch 6, Batch 3000] loss: 0.031994840701372596
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9838
Overfitting: 0.0513
[Epoch 7, Batch 100] loss: 0.02543688918951375
[Epoch 7, Batch 200] loss: 0.029687462489528117
[Epoch 7, Batch 300] loss: 0.02004617333441274
[Epoch 7, Batch 400] loss: 0.019728940626664554
[Epoch 7, Batch 500] loss: 0.033863170410913884
[Epoch 7, Batch 600] loss: 0.028801021552935707
[Epoch 7, Batch 700] loss: 0.026616946419380838
[Epoch 7, Batch 800] loss: 0.033118240428739225
[Epoch 7, Batch 900] loss: 0.02381793308952183
[Epoch 7, Batch 1000] loss: 0.02511123003125249
[Epoch 7, Batch 1100] loss: 0.02534367385895166
[Epoch 7, Batch 1200] loss: 0.04185936372319702
[Epoch 7, Batch 1300] loss: 0.03263677897513844
[Epoch 7, Batch 1400] loss: 0.032517145809179054
[Epoch 7, Batch 1500] loss: 0.03093504892254714
[Epoch 7, Batch 1600] loss: 0.0273643344303855
[Epoch 7, Batch 1700] loss: 0.027537672615289922
[Epoch 7, Batch 1800] loss: 0.026722013959915785
[Epoch 7, Batch 1900] loss: 0.026028605943356525
[Epoch 7, Batch 2000] loss: 0.03948469366005156
[Epoch 7, Batch 2100] loss: 0.031038280646607744
[Epoch 7, Batch 2200] loss: 0.03660385358482017
[Epoch 7, Batch 2300] loss: 0.02346606650902686
[Epoch 7, Batch 2400] loss: 0.027544736440977432
[Epoch 7, Batch 2500] loss: 0.02536139511881629
[Epoch 7, Batch 2600] loss: 0.03552807738509728
[Epoch 7, Batch 2700] loss: 0.027532339480785595
[Epoch 7, Batch 2800] loss: 0.04133999439411127
[Epoch 7, Batch 2900] loss: 0.030952859011740656
[Epoch 7, Batch 3000] loss: 0.024468227788674995
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0409
Validation Accuracy: 0.9868
Overfitting: 0.0409
Best model saved at epoch 7 with validation loss: 0.0409
[Epoch 8, Batch 100] loss: 0.0232093857615655
[Epoch 8, Batch 200] loss: 0.01558097783368794
[Epoch 8, Batch 300] loss: 0.01996222825071527
[Epoch 8, Batch 400] loss: 0.026460398354302014
[Epoch 8, Batch 500] loss: 0.027852858190744883
[Epoch 8, Batch 600] loss: 0.020855416795238852
[Epoch 8, Batch 700] loss: 0.021499813591872224
[Epoch 8, Batch 800] loss: 0.017158887065525052
[Epoch 8, Batch 900] loss: 0.027754892116608972
[Epoch 8, Batch 1000] loss: 0.018080000302088593
[Epoch 8, Batch 1100] loss: 0.021431544148072135
[Epoch 8, Batch 1200] loss: 0.02910883204800484
[Epoch 8, Batch 1300] loss: 0.019921177375963453
[Epoch 8, Batch 1400] loss: 0.028380044804580392
[Epoch 8, Batch 1500] loss: 0.029145383531140396
[Epoch 8, Batch 1600] loss: 0.023558696498366772
[Epoch 8, Batch 1700] loss: 0.030728227122745012
[Epoch 8, Batch 1800] loss: 0.01891113493780722
[Epoch 8, Batch 1900] loss: 0.02212015415989299
[Epoch 8, Batch 2000] loss: 0.020872602700910646
[Epoch 8, Batch 2100] loss: 0.02142642285209149
[Epoch 8, Batch 2200] loss: 0.014188854059655113
[Epoch 8, Batch 2300] loss: 0.03768723735651292
[Epoch 8, Batch 2400] loss: 0.024059161721015698
[Epoch 8, Batch 2500] loss: 0.02802066013449803
[Epoch 8, Batch 2600] loss: 0.02522360879724147
[Epoch 8, Batch 2700] loss: 0.03810210676005227
[Epoch 8, Batch 2800] loss: 0.023622121114749463
[Epoch 8, Batch 2900] loss: 0.018244842946733116
[Epoch 8, Batch 3000] loss: 0.028419776027549234
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0415
Validation Accuracy: 0.9880
Overfitting: 0.0415
[Epoch 9, Batch 100] loss: 0.018646343406526284
[Epoch 9, Batch 200] loss: 0.01722661623625754
[Epoch 9, Batch 300] loss: 0.016063503520417726
[Epoch 9, Batch 400] loss: 0.02255802663695249
[Epoch 9, Batch 500] loss: 0.01991785790589347
[Epoch 9, Batch 600] loss: 0.027037528352193477
[Epoch 9, Batch 700] loss: 0.025002394593248028
[Epoch 9, Batch 800] loss: 0.016015114442998312
[Epoch 9, Batch 900] loss: 0.014436991677102924
[Epoch 9, Batch 1000] loss: 0.030541444147456787
[Epoch 9, Batch 1100] loss: 0.024286131990738796
[Epoch 9, Batch 1200] loss: 0.014197865035694122
[Epoch 9, Batch 1300] loss: 0.015027289265563014
[Epoch 9, Batch 1400] loss: 0.019053018191625595
[Epoch 9, Batch 1500] loss: 0.01824667338583822
[Epoch 9, Batch 1600] loss: 0.019744074952686787
[Epoch 9, Batch 1700] loss: 0.0220033137291648
[Epoch 9, Batch 1800] loss: 0.01721604842114175
[Epoch 9, Batch 1900] loss: 0.02167390659571538
[Epoch 9, Batch 2000] loss: 0.0213568733966531
[Epoch 9, Batch 2100] loss: 0.026605352665028476
[Epoch 9, Batch 2200] loss: 0.019597636525140842
[Epoch 9, Batch 2300] loss: 0.02262752647610796
[Epoch 9, Batch 2400] loss: 0.018993344148857432
[Epoch 9, Batch 2500] loss: 0.02342228545349826
[Epoch 9, Batch 2600] loss: 0.022635584390591247
[Epoch 9, Batch 2700] loss: 0.03578666508596143
[Epoch 9, Batch 2800] loss: 0.023901146505013456
[Epoch 9, Batch 2900] loss: 0.028082913304606338
[Epoch 9, Batch 3000] loss: 0.029769018732913537
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0396
Validation Accuracy: 0.9871
Overfitting: 0.0396
Best model saved at epoch 9 with validation loss: 0.0396
[Epoch 10, Batch 100] loss: 0.01657906385153183
[Epoch 10, Batch 200] loss: 0.011834257599402917
[Epoch 10, Batch 300] loss: 0.01688028746168129
[Epoch 10, Batch 400] loss: 0.011924923459582714
[Epoch 10, Batch 500] loss: 0.015258706621680176
[Epoch 10, Batch 600] loss: 0.00881674402335193
[Epoch 10, Batch 700] loss: 0.01321615652618675
[Epoch 10, Batch 800] loss: 0.019641049325682617
[Epoch 10, Batch 900] loss: 0.0199118001664101
[Epoch 10, Batch 1000] loss: 0.020429117617677548
[Epoch 10, Batch 1100] loss: 0.017891021481018468
[Epoch 10, Batch 1200] loss: 0.014982161407315288
[Epoch 10, Batch 1300] loss: 0.020745714925742505
[Epoch 10, Batch 1400] loss: 0.014878089270023338
[Epoch 10, Batch 1500] loss: 0.01878070089916946
[Epoch 10, Batch 1600] loss: 0.01202690230447388
[Epoch 10, Batch 1700] loss: 0.01647500616083107
[Epoch 10, Batch 1800] loss: 0.016288785374363214
[Epoch 10, Batch 1900] loss: 0.013954758255431443
[Epoch 10, Batch 2000] loss: 0.012264036110182133
[Epoch 10, Batch 2100] loss: 0.015824520820551698
[Epoch 10, Batch 2200] loss: 0.015633590131365054
[Epoch 10, Batch 2300] loss: 0.016909330953858444
[Epoch 10, Batch 2400] loss: 0.017640366942086986
[Epoch 10, Batch 2500] loss: 0.027795339866861467
[Epoch 10, Batch 2600] loss: 0.01408953128655412
[Epoch 10, Batch 2700] loss: 0.021011893284703546
[Epoch 10, Batch 2800] loss: 0.022080640906569898
[Epoch 10, Batch 2900] loss: 0.01835881832584164
[Epoch 10, Batch 3000] loss: 0.03474095589853277
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0424
Validation Accuracy: 0.9875
Overfitting: 0.0424
[Epoch 11, Batch 100] loss: 0.012676236850820715
[Epoch 11, Batch 200] loss: 0.010142858294439066
[Epoch 11, Batch 300] loss: 0.017943605620530434
[Epoch 11, Batch 400] loss: 0.008815248108876404
[Epoch 11, Batch 500] loss: 0.016398301534973143
[Epoch 11, Batch 600] loss: 0.01176086670582663
[Epoch 11, Batch 700] loss: 0.008381879313610625
[Epoch 11, Batch 800] loss: 0.0162258257915164
[Epoch 11, Batch 900] loss: 0.009434355470320952
[Epoch 11, Batch 1000] loss: 0.02126244688657607
[Epoch 11, Batch 1100] loss: 0.015425388527219183
[Epoch 11, Batch 1200] loss: 0.012775300398989203
[Epoch 11, Batch 1300] loss: 0.016603635929313895
[Epoch 11, Batch 1400] loss: 0.020986466504054987
[Epoch 11, Batch 1500] loss: 0.015660569553656387
[Epoch 11, Batch 1600] loss: 0.015903097350474127
[Epoch 11, Batch 1700] loss: 0.024172332458947496
[Epoch 11, Batch 1800] loss: 0.01565791753717349
[Epoch 11, Batch 1900] loss: 0.008441883968298498
[Epoch 11, Batch 2000] loss: 0.01580515296123849
[Epoch 11, Batch 2100] loss: 0.019279021201964498
[Epoch 11, Batch 2200] loss: 0.014337808107366073
[Epoch 11, Batch 2300] loss: 0.020204587602147512
[Epoch 11, Batch 2400] loss: 0.01885321596488211
[Epoch 11, Batch 2500] loss: 0.009517512770198664
[Epoch 11, Batch 2600] loss: 0.010359818457845903
[Epoch 11, Batch 2700] loss: 0.017402029232443966
[Epoch 11, Batch 2800] loss: 0.00696519423300515
[Epoch 11, Batch 2900] loss: 0.013488954242393447
[Epoch 11, Batch 3000] loss: 0.024369572413224887
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0566
Validation Accuracy: 0.9844
Overfitting: 0.0566
[Epoch 12, Batch 100] loss: 0.011978384756916967
[Epoch 12, Batch 200] loss: 0.01015567665607705
[Epoch 12, Batch 300] loss: 0.015381396735401722
[Epoch 12, Batch 400] loss: 0.011884284781681345
[Epoch 12, Batch 500] loss: 0.00820225508266958
[Epoch 12, Batch 600] loss: 0.0096039466574166
[Epoch 12, Batch 700] loss: 0.011566603896328615
[Epoch 12, Batch 800] loss: 0.015019805955175798
[Epoch 12, Batch 900] loss: 0.0154063982319758
[Epoch 12, Batch 1000] loss: 0.01181394667778477
[Epoch 12, Batch 1100] loss: 0.014061292397873331
[Epoch 12, Batch 1200] loss: 0.0068787728390634585
[Epoch 12, Batch 1300] loss: 0.009705361952983367
[Epoch 12, Batch 1400] loss: 0.006730802721290274
[Epoch 12, Batch 1500] loss: 0.013959970886644442
[Epoch 12, Batch 1600] loss: 0.011767597428013232
[Epoch 12, Batch 1700] loss: 0.01110917119075566
[Epoch 12, Batch 1800] loss: 0.0073055634661182015
[Epoch 12, Batch 1900] loss: 0.011856592803897002
[Epoch 12, Batch 2000] loss: 0.011819166208433672
[Epoch 12, Batch 2100] loss: 0.011224737286684104
[Epoch 12, Batch 2200] loss: 0.008954845460775686
[Epoch 12, Batch 2300] loss: 0.014843554106819283
[Epoch 12, Batch 2400] loss: 0.015007066271382428
[Epoch 12, Batch 2500] loss: 0.018729830923480222
[Epoch 12, Batch 2600] loss: 0.015848011681837307
[Epoch 12, Batch 2700] loss: 0.00869389389243679
[Epoch 12, Batch 2800] loss: 0.010051659689534063
[Epoch 12, Batch 2900] loss: 0.011711825894415141
[Epoch 12, Batch 3000] loss: 0.00787154368679694
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0416
Validation Accuracy: 0.9878
Overfitting: 0.0416
[Epoch 13, Batch 100] loss: 0.014975208832283897
[Epoch 13, Batch 200] loss: 0.011234603813441026
[Epoch 13, Batch 300] loss: 0.006286287611794705
[Epoch 13, Batch 400] loss: 0.018167517277070146
[Epoch 13, Batch 500] loss: 0.008102985118916876
[Epoch 13, Batch 600] loss: 0.007324448125200433
[Epoch 13, Batch 700] loss: 0.006281343245523203
[Epoch 13, Batch 800] loss: 0.018816388097079653
[Epoch 13, Batch 900] loss: 0.006825251577033668
[Epoch 13, Batch 1000] loss: 0.013803481775589717
[Epoch 13, Batch 1100] loss: 0.012238312094909816
[Epoch 13, Batch 1200] loss: 0.00808532719690902
[Epoch 13, Batch 1300] loss: 0.013479106386548666
[Epoch 13, Batch 1400] loss: 0.013936835943958385
[Epoch 13, Batch 1500] loss: 0.014198302455306476
[Epoch 13, Batch 1600] loss: 0.015539703847086911
[Epoch 13, Batch 1700] loss: 0.011091350524784502
[Epoch 13, Batch 1800] loss: 0.0059454032311464285
[Epoch 13, Batch 1900] loss: 0.010895864290923783
[Epoch 13, Batch 2000] loss: 0.01570182435329116
[Epoch 13, Batch 2100] loss: 0.007269891416674454
[Epoch 13, Batch 2200] loss: 0.007938195324131812
[Epoch 13, Batch 2300] loss: 0.011305215346019394
[Epoch 13, Batch 2400] loss: 0.01341441401064003
[Epoch 13, Batch 2500] loss: 0.009379961235154041
[Epoch 13, Batch 2600] loss: 0.0270937593515373
[Epoch 13, Batch 2700] loss: 0.010443361750194526
[Epoch 13, Batch 2800] loss: 0.013019975749466539
[Epoch 13, Batch 2900] loss: 0.012884132742956354
[Epoch 13, Batch 3000] loss: 0.015468028429800142
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0397
Validation Accuracy: 0.9899
Overfitting: 0.0397
[Epoch 14, Batch 100] loss: 0.009431140347760446
[Epoch 14, Batch 200] loss: 0.007269995518499855
[Epoch 14, Batch 300] loss: 0.0049067349966844635
[Epoch 14, Batch 400] loss: 0.006773895930152775
[Epoch 14, Batch 500] loss: 0.006543026895699313
[Epoch 14, Batch 600] loss: 0.005574389782532307
[Epoch 14, Batch 700] loss: 0.010491685148597298
[Epoch 14, Batch 800] loss: 0.011826817712544653
[Epoch 14, Batch 900] loss: 0.006913481398923977
[Epoch 14, Batch 1000] loss: 0.007872387912193517
[Epoch 14, Batch 1100] loss: 0.008891233615245256
[Epoch 14, Batch 1200] loss: 0.010636836738099191
[Epoch 14, Batch 1300] loss: 0.013273702960134415
[Epoch 14, Batch 1400] loss: 0.009163211229990793
[Epoch 14, Batch 1500] loss: 0.01366824854792867
[Epoch 14, Batch 1600] loss: 0.00617720159149485
[Epoch 14, Batch 1700] loss: 0.006813758378812053
[Epoch 14, Batch 1800] loss: 0.011927638978531831
[Epoch 14, Batch 1900] loss: 0.011437435639904833
[Epoch 14, Batch 2000] loss: 0.01401861085944347
[Epoch 14, Batch 2100] loss: 0.004189993568334102
[Epoch 14, Batch 2200] loss: 0.011223803648126704
[Epoch 14, Batch 2300] loss: 0.013085623721664205
[Epoch 14, Batch 2400] loss: 0.013737566777508618
[Epoch 14, Batch 2500] loss: 0.008504169874122454
[Epoch 14, Batch 2600] loss: 0.008587658384994938
[Epoch 14, Batch 2700] loss: 0.018353184996030905
[Epoch 14, Batch 2800] loss: 0.004089013039874772
[Epoch 14, Batch 2900] loss: 0.006181115367890015
[Epoch 14, Batch 3000] loss: 0.014031183320148556
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9883
Overfitting: 0.0439
[Epoch 15, Batch 100] loss: 0.008071851430613605
[Epoch 15, Batch 200] loss: 0.01005677073681909
[Epoch 15, Batch 300] loss: 0.004550640123406993
[Epoch 15, Batch 400] loss: 0.0075548528911258475
[Epoch 15, Batch 500] loss: 0.00746838721169297
[Epoch 15, Batch 600] loss: 0.00879299098808815
[Epoch 15, Batch 700] loss: 0.01295741441910252
[Epoch 15, Batch 800] loss: 0.006989369909720153
[Epoch 15, Batch 900] loss: 0.007546535476456029
[Epoch 15, Batch 1000] loss: 0.01670181062439724
[Epoch 15, Batch 1100] loss: 0.008014415999303992
[Epoch 15, Batch 1200] loss: 0.0076188341898591715
[Epoch 15, Batch 1300] loss: 0.009299565781866477
[Epoch 15, Batch 1400] loss: 0.008826059961054965
[Epoch 15, Batch 1500] loss: 0.0068772630332819065
[Epoch 15, Batch 1600] loss: 0.00624749106322497
[Epoch 15, Batch 1700] loss: 0.005582354401327621
[Epoch 15, Batch 1800] loss: 0.007315607035141056
[Epoch 15, Batch 1900] loss: 0.007989761667607809
[Epoch 15, Batch 2000] loss: 0.010406907859010061
[Epoch 15, Batch 2100] loss: 0.005848732810887896
[Epoch 15, Batch 2200] loss: 0.011474272415287033
[Epoch 15, Batch 2300] loss: 0.004943400088349108
[Epoch 15, Batch 2400] loss: 0.012121246118664431
[Epoch 15, Batch 2500] loss: 0.015245455982233124
[Epoch 15, Batch 2600] loss: 0.011224862804324403
[Epoch 15, Batch 2700] loss: 0.006223715990165602
[Epoch 15, Batch 2800] loss: 0.012547729097340152
[Epoch 15, Batch 2900] loss: 0.006179625176739592
[Epoch 15, Batch 3000] loss: 0.016167083739320562
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9889
Overfitting: 0.0450
[Epoch 16, Batch 100] loss: 0.010941409753019115
[Epoch 16, Batch 200] loss: 0.00894708835885467
[Epoch 16, Batch 300] loss: 0.009689807219868101
[Epoch 16, Batch 400] loss: 0.013574728874391439
[Epoch 16, Batch 500] loss: 0.00597975669253401
[Epoch 16, Batch 600] loss: 0.006730074508091093
[Epoch 16, Batch 700] loss: 0.015789960130748567
[Epoch 16, Batch 800] loss: 0.002593740137322129
[Epoch 16, Batch 900] loss: 0.009609234008976272
[Epoch 16, Batch 1000] loss: 0.013672092323763535
[Epoch 16, Batch 1100] loss: 0.014021286296056132
[Epoch 16, Batch 1200] loss: 0.0089088562553502
[Epoch 16, Batch 1300] loss: 0.006250526155806711
[Epoch 16, Batch 1400] loss: 0.0049119764541910626
[Epoch 16, Batch 1500] loss: 0.003846139641098034
[Epoch 16, Batch 1600] loss: 0.007991228133853952
[Epoch 16, Batch 1700] loss: 0.00625681363022295
[Epoch 16, Batch 1800] loss: 0.004726826334840553
[Epoch 16, Batch 1900] loss: 0.009925259792510133
[Epoch 16, Batch 2000] loss: 0.011221936534874431
[Epoch 16, Batch 2100] loss: 0.007476364492417815
[Epoch 16, Batch 2200] loss: 0.008218940425626898
[Epoch 16, Batch 2300] loss: 0.0049819680306598
[Epoch 16, Batch 2400] loss: 0.009806489314923396
[Epoch 16, Batch 2500] loss: 0.014147374315552953
[Epoch 16, Batch 2600] loss: 0.006492905975630947
[Epoch 16, Batch 2700] loss: 0.0043685018931250855
[Epoch 16, Batch 2800] loss: 0.006286873798216135
[Epoch 16, Batch 2900] loss: 0.011823345182119738
[Epoch 16, Batch 3000] loss: 0.010379222940091495
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0402
Validation Accuracy: 0.9894
Overfitting: 0.0402
[Epoch 17, Batch 100] loss: 0.003470180114766208
[Epoch 17, Batch 200] loss: 0.007248416346910745
[Epoch 17, Batch 300] loss: 0.004469633759108547
[Epoch 17, Batch 400] loss: 0.005139826854622243
[Epoch 17, Batch 500] loss: 0.0059577968688495275
[Epoch 17, Batch 600] loss: 0.010538522773310887
[Epoch 17, Batch 700] loss: 0.006777063006616117
[Epoch 17, Batch 800] loss: 0.0031066676676266523
[Epoch 17, Batch 900] loss: 0.006167144111324205
[Epoch 17, Batch 1000] loss: 0.00311486948873835
[Epoch 17, Batch 1100] loss: 0.0070048785206302
[Epoch 17, Batch 1200] loss: 0.010635151044830309
[Epoch 17, Batch 1300] loss: 0.00314681987645713
[Epoch 17, Batch 1400] loss: 0.0040895163459038035
[Epoch 17, Batch 1500] loss: 0.00409486040672391
[Epoch 17, Batch 1600] loss: 0.0028083895399339553
[Epoch 17, Batch 1700] loss: 0.0010679352507247586
[Epoch 17, Batch 1800] loss: 0.003058790516168983
[Epoch 17, Batch 1900] loss: 0.004029156583416587
[Epoch 17, Batch 2000] loss: 0.0015694425977153515
[Epoch 17, Batch 2100] loss: 0.0058861221204455205
[Epoch 17, Batch 2200] loss: 0.004587168124119785
[Epoch 17, Batch 2300] loss: 0.005696680545927393
[Epoch 17, Batch 2400] loss: 0.004913213742482867
[Epoch 17, Batch 2500] loss: 0.005448118359425962
[Epoch 17, Batch 2600] loss: 0.0025232597722839503
[Epoch 17, Batch 2700] loss: 0.009251688854804173
[Epoch 17, Batch 2800] loss: 0.015414221154512688
[Epoch 17, Batch 2900] loss: 0.00622302474850585
[Epoch 17, Batch 3000] loss: 0.006933938073361787
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0433
Validation Accuracy: 0.9896
Overfitting: 0.0433
[Epoch 18, Batch 100] loss: 0.0015168587152314217
[Epoch 18, Batch 200] loss: 0.0010717849560052174
[Epoch 18, Batch 300] loss: 0.0046765843043598924
[Epoch 18, Batch 400] loss: 0.008183753028916883
[Epoch 18, Batch 500] loss: 0.006703211442440988
[Epoch 18, Batch 600] loss: 0.0036758779063205795
[Epoch 18, Batch 700] loss: 0.004384561157720981
[Epoch 18, Batch 800] loss: 0.004636831168290882
[Epoch 18, Batch 900] loss: 0.002387973524866993
[Epoch 18, Batch 1000] loss: 0.003362645219958722
[Epoch 18, Batch 1100] loss: 0.0022910441944816286
[Epoch 18, Batch 1200] loss: 0.00509591929380008
[Epoch 18, Batch 1300] loss: 0.001564650714256004
[Epoch 18, Batch 1400] loss: 0.004162830226368328
[Epoch 18, Batch 1500] loss: 0.011383479659288582
[Epoch 18, Batch 1600] loss: 0.00914446783461301
[Epoch 18, Batch 1700] loss: 0.004489086009257903
[Epoch 18, Batch 1800] loss: 0.0034434320439265774
[Epoch 18, Batch 1900] loss: 0.0018720015973575244
[Epoch 18, Batch 2000] loss: 0.002690562058527064
[Epoch 18, Batch 2100] loss: 0.001195316614560511
[Epoch 18, Batch 2200] loss: 0.005490645163366708
[Epoch 18, Batch 2300] loss: 0.004501602686203796
[Epoch 18, Batch 2400] loss: 0.0048962349749274384
[Epoch 18, Batch 2500] loss: 0.007057576612580192
[Epoch 18, Batch 2600] loss: 0.0032267607913155417
[Epoch 18, Batch 2700] loss: 0.00671303327646882
[Epoch 18, Batch 2800] loss: 0.013856926108978769
[Epoch 18, Batch 2900] loss: 0.003952015593504825
[Epoch 18, Batch 3000] loss: 0.006817505346476196
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9888
Overfitting: 0.0469
[Epoch 19, Batch 100] loss: 0.005734568166914471
[Epoch 19, Batch 200] loss: 0.006107690113717581
[Epoch 19, Batch 300] loss: 0.008209879547195272
[Epoch 19, Batch 400] loss: 0.00450910089336503
[Epoch 19, Batch 500] loss: 0.0027924612500942205
[Epoch 19, Batch 600] loss: 0.002832237678229603
[Epoch 19, Batch 700] loss: 0.001095208828558043
[Epoch 19, Batch 800] loss: 0.005760342618973482
[Epoch 19, Batch 900] loss: 0.007271777188167334
[Epoch 19, Batch 1000] loss: 0.007814071075249557
[Epoch 19, Batch 1100] loss: 0.0016955352920547285
[Epoch 19, Batch 1200] loss: 0.0015906570309152813
[Epoch 19, Batch 1300] loss: 0.003409305651304635
[Epoch 19, Batch 1400] loss: 0.002047191830585575
[Epoch 19, Batch 1500] loss: 0.00313542349412927
[Epoch 19, Batch 1600] loss: 0.0030288650756902058
[Epoch 19, Batch 1700] loss: 0.004463679060033882
[Epoch 19, Batch 1800] loss: 0.005154365894868534
[Epoch 19, Batch 1900] loss: 0.0020887216308682266
[Epoch 19, Batch 2000] loss: 0.0029707834405922995
[Epoch 19, Batch 2100] loss: 0.004949777705097631
[Epoch 19, Batch 2200] loss: 0.01570475945302121
[Epoch 19, Batch 2300] loss: 0.005672854591761051
[Epoch 19, Batch 2400] loss: 0.0029634944004851603
[Epoch 19, Batch 2500] loss: 0.008822253967688312
[Epoch 19, Batch 2600] loss: 0.012919295882987285
[Epoch 19, Batch 2700] loss: 0.005156050071445861
[Epoch 19, Batch 2800] loss: 0.006068770973330402
[Epoch 19, Batch 2900] loss: 0.004588342027649333
[Epoch 19, Batch 3000] loss: 0.004286267865840045
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0427
Validation Accuracy: 0.9899
Overfitting: 0.0427
[Epoch 20, Batch 100] loss: 0.01042996077786711
[Epoch 20, Batch 200] loss: 0.0048209584424967035
[Epoch 20, Batch 300] loss: 0.001868511386331022
[Epoch 20, Batch 400] loss: 0.005121199775904017
[Epoch 20, Batch 500] loss: 0.005708100107253031
[Epoch 20, Batch 600] loss: 0.005542363890183708
[Epoch 20, Batch 700] loss: 0.004698688858341598
[Epoch 20, Batch 800] loss: 0.004338402066519507
[Epoch 20, Batch 900] loss: 0.0018313441560201228
[Epoch 20, Batch 1000] loss: 0.004226671116444436
[Epoch 20, Batch 1100] loss: 0.00613816416698171
[Epoch 20, Batch 1200] loss: 0.008797228135389901
[Epoch 20, Batch 1300] loss: 0.0015365764781790857
[Epoch 20, Batch 1400] loss: 0.006947206274319342
[Epoch 20, Batch 1500] loss: 0.0056767036037052776
[Epoch 20, Batch 1600] loss: 0.008922208309688812
[Epoch 20, Batch 1700] loss: 0.0023081877498589165
[Epoch 20, Batch 1800] loss: 0.0032143238685250707
[Epoch 20, Batch 1900] loss: 0.0060805765833436
[Epoch 20, Batch 2000] loss: 0.004773363883009552
[Epoch 20, Batch 2100] loss: 0.0059324130248904795
[Epoch 20, Batch 2200] loss: 0.0035968341705596174
[Epoch 20, Batch 2300] loss: 0.004794237448577974
[Epoch 20, Batch 2400] loss: 0.004048994184639412
[Epoch 20, Batch 2500] loss: 0.001638383641628991
[Epoch 20, Batch 2600] loss: 0.004406110382400925
[Epoch 20, Batch 2700] loss: 0.013529714901230817
[Epoch 20, Batch 2800] loss: 0.007162366822793729
[Epoch 20, Batch 2900] loss: 0.006335566688059373
[Epoch 20, Batch 3000] loss: 0.005794663994632572
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0406
Validation Accuracy: 0.9891
Overfitting: 0.0406
[Epoch 21, Batch 100] loss: 0.001812664981295029
[Epoch 21, Batch 200] loss: 0.0029827812136551304
[Epoch 21, Batch 300] loss: 0.0017366071418048535
[Epoch 21, Batch 400] loss: 0.009259788757499053
[Epoch 21, Batch 500] loss: 0.005246616132060353
[Epoch 21, Batch 600] loss: 0.0020269454289287125
[Epoch 21, Batch 700] loss: 0.0010256200157965623
[Epoch 21, Batch 800] loss: 0.0015655569661910107
[Epoch 21, Batch 900] loss: 0.0010896772362605134
[Epoch 21, Batch 1000] loss: 0.002383404314991253
[Epoch 21, Batch 1100] loss: 0.001959870780235491
[Epoch 21, Batch 1200] loss: 0.008674726441087301
[Epoch 21, Batch 1300] loss: 0.0025441710900776116
[Epoch 21, Batch 1400] loss: 0.003918235811528916
[Epoch 21, Batch 1500] loss: 0.005567505036746923
[Epoch 21, Batch 1600] loss: 0.0012054533926152543
[Epoch 21, Batch 1700] loss: 0.0015848230140500163
[Epoch 21, Batch 1800] loss: 0.007697217804588021
[Epoch 21, Batch 1900] loss: 0.0013247323123921717
[Epoch 21, Batch 2000] loss: 0.0016726131166433333
[Epoch 21, Batch 2100] loss: 0.0013280464726614127
[Epoch 21, Batch 2200] loss: 0.0037700254050261604
[Epoch 21, Batch 2300] loss: 0.0029699297778121546
[Epoch 21, Batch 2400] loss: 0.0023249589405709512
[Epoch 21, Batch 2500] loss: 0.0029009200914950385
[Epoch 21, Batch 2600] loss: 0.0029360326443912755
[Epoch 21, Batch 2700] loss: 0.005908617652954149
[Epoch 21, Batch 2800] loss: 0.002949375785881898
[Epoch 21, Batch 2900] loss: 0.002142294321659932
[Epoch 21, Batch 3000] loss: 0.004304917569792792
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0427
Validation Accuracy: 0.9897
Overfitting: 0.0427
[Epoch 22, Batch 100] loss: 0.0010413287350525024
[Epoch 22, Batch 200] loss: 0.0028927868705960692
[Epoch 22, Batch 300] loss: 0.0010223836600154357
[Epoch 22, Batch 400] loss: 0.0037128998976053394
[Epoch 22, Batch 500] loss: 0.0011180323210976438
[Epoch 22, Batch 600] loss: 0.0014387154127737745
[Epoch 22, Batch 700] loss: 0.001168091660490731
[Epoch 22, Batch 800] loss: 0.0013082264774709352
[Epoch 22, Batch 900] loss: 0.0007009053505352369
[Epoch 22, Batch 1000] loss: 0.001241922498429311
[Epoch 22, Batch 1100] loss: 0.007529873087603392
[Epoch 22, Batch 1200] loss: 0.0012514086568194216
[Epoch 22, Batch 1300] loss: 0.0020319336456765314
[Epoch 22, Batch 1400] loss: 0.002413216259996034
[Epoch 22, Batch 1500] loss: 0.0008808819468944762
[Epoch 22, Batch 1600] loss: 0.0037878315862372603
[Epoch 22, Batch 1700] loss: 0.001905155382398913
[Epoch 22, Batch 1800] loss: 0.0031302295897690157
[Epoch 22, Batch 1900] loss: 0.0014383872662865826
[Epoch 22, Batch 2000] loss: 0.004033129787112771
[Epoch 22, Batch 2100] loss: 0.0008854169320605365
[Epoch 22, Batch 2200] loss: 0.0023796797524444457
[Epoch 22, Batch 2300] loss: 0.0014258741364054116
[Epoch 22, Batch 2400] loss: 0.002548090452970655
[Epoch 22, Batch 2500] loss: 0.0008499961559355995
[Epoch 22, Batch 2600] loss: 0.0018554158949525856
[Epoch 22, Batch 2700] loss: 0.0031542295167420777
[Epoch 22, Batch 2800] loss: 0.0006885862127103338
[Epoch 22, Batch 2900] loss: 0.0013432922048113437
[Epoch 22, Batch 3000] loss: 0.0036160278171493586
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0408
Validation Accuracy: 0.9905
Overfitting: 0.0408
[Epoch 23, Batch 100] loss: 0.0012866229335553926
[Epoch 23, Batch 200] loss: 0.0013396383423658165
[Epoch 23, Batch 300] loss: 0.0012066787068578577
[Epoch 23, Batch 400] loss: 0.0004078549679601906
[Epoch 23, Batch 500] loss: 0.0009630333260927193
[Epoch 23, Batch 600] loss: 0.000411804633813655
[Epoch 23, Batch 700] loss: 0.002354895914478732
[Epoch 23, Batch 800] loss: 0.0018506159848308457
[Epoch 23, Batch 900] loss: 0.0009708525173448201
[Epoch 23, Batch 1000] loss: 0.0004842422471848806
[Epoch 23, Batch 1100] loss: 0.0008744403263264555
[Epoch 23, Batch 1200] loss: 0.0014518246264742629
[Epoch 23, Batch 1300] loss: 0.0016562827200885266
[Epoch 23, Batch 1400] loss: 0.0020930949604021976
[Epoch 23, Batch 1500] loss: 0.0009369613469085891
[Epoch 23, Batch 1600] loss: 0.0011005236219468629
[Epoch 23, Batch 1700] loss: 0.0029315285399746926
[Epoch 23, Batch 1800] loss: 0.004762281548221167
[Epoch 23, Batch 1900] loss: 0.0009299413414172796
[Epoch 23, Batch 2000] loss: 0.003038054172002518
[Epoch 23, Batch 2100] loss: 0.0016971980158697875
[Epoch 23, Batch 2200] loss: 0.000877801424399518
[Epoch 23, Batch 2300] loss: 0.0004470558636776012
[Epoch 23, Batch 2400] loss: 0.0007551535460213188
[Epoch 23, Batch 2500] loss: 0.0028798023515050632
[Epoch 23, Batch 2600] loss: 0.0008475516082042133
[Epoch 23, Batch 2700] loss: 0.0006873391498080395
[Epoch 23, Batch 2800] loss: 0.000905080486091947
[Epoch 23, Batch 2900] loss: 0.0012635153166300483
[Epoch 23, Batch 3000] loss: 0.00200878270347701
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0427
Validation Accuracy: 0.9908
Overfitting: 0.0427
[Epoch 24, Batch 100] loss: 0.0013121577674093743
[Epoch 24, Batch 200] loss: 0.0005052910615653162
[Epoch 24, Batch 300] loss: 0.00036714949971994315
[Epoch 24, Batch 400] loss: 0.00266227919928923
[Epoch 24, Batch 500] loss: 0.0005275150631623049
[Epoch 24, Batch 600] loss: 0.002047017297553637
[Epoch 24, Batch 700] loss: 0.0017887903168058016
[Epoch 24, Batch 800] loss: 0.0012969506671490195
[Epoch 24, Batch 900] loss: 0.0006364759831459565
[Epoch 24, Batch 1000] loss: 0.0004593315065323278
[Epoch 24, Batch 1100] loss: 0.0005537846943472325
[Epoch 24, Batch 1200] loss: 0.0004514905215365417
[Epoch 24, Batch 1300] loss: 0.0004633398368456909
[Epoch 24, Batch 1400] loss: 0.00044267587747034656
[Epoch 24, Batch 1500] loss: 0.0013884844741490808
[Epoch 24, Batch 1600] loss: 0.0008273405541629586
[Epoch 24, Batch 1700] loss: 0.001968146090153642
[Epoch 24, Batch 1800] loss: 0.0003742313287800414
[Epoch 24, Batch 1900] loss: 0.0011521371593221019
[Epoch 24, Batch 2000] loss: 0.0010877945856906735
[Epoch 24, Batch 2100] loss: 0.0007370467317535079
[Epoch 24, Batch 2200] loss: 0.0021882498216746525
[Epoch 24, Batch 2300] loss: 0.0008442243998285815
[Epoch 24, Batch 2400] loss: 0.005640810705027377
[Epoch 24, Batch 2500] loss: 0.0008843297945528405
[Epoch 24, Batch 2600] loss: 0.0013490200858680623
[Epoch 24, Batch 2700] loss: 0.0008549822675439555
[Epoch 24, Batch 2800] loss: 0.005964652458106876
[Epoch 24, Batch 2900] loss: 0.0007887717833764718
[Epoch 24, Batch 3000] loss: 0.0007182114257912531
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0435
Validation Accuracy: 0.9908
Overfitting: 0.0435
Fold 1 validation loss: 0.0435
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2951240611076353
[Epoch 1, Batch 200] loss: 2.266539833545685
[Epoch 1, Batch 300] loss: 2.135464220046997
[Epoch 1, Batch 400] loss: 1.3376016983389853
[Epoch 1, Batch 500] loss: 0.6769162341952324
[Epoch 1, Batch 600] loss: 0.5004698941856622
[Epoch 1, Batch 700] loss: 0.45558136634528634
[Epoch 1, Batch 800] loss: 0.3762530837953091
[Epoch 1, Batch 900] loss: 0.3725118677318096
[Epoch 1, Batch 1000] loss: 0.3061526208370924
[Epoch 1, Batch 1100] loss: 0.28899455912411215
[Epoch 1, Batch 1200] loss: 0.30152776814997195
[Epoch 1, Batch 1300] loss: 0.282725639231503
[Epoch 1, Batch 1400] loss: 0.2118739577382803
[Epoch 1, Batch 1500] loss: 0.20651905482634902
[Epoch 1, Batch 1600] loss: 0.21927451176568866
[Epoch 1, Batch 1700] loss: 0.16610728835687041
[Epoch 1, Batch 1800] loss: 0.1733571698423475
[Epoch 1, Batch 1900] loss: 0.19128616875037552
[Epoch 1, Batch 2000] loss: 0.18378764445893467
[Epoch 1, Batch 2100] loss: 0.18210866682231427
[Epoch 1, Batch 2200] loss: 0.148304000236094
[Epoch 1, Batch 2300] loss: 0.13793254238087685
[Epoch 1, Batch 2400] loss: 0.14636097049340605
[Epoch 1, Batch 2500] loss: 0.15545165170915426
[Epoch 1, Batch 2600] loss: 0.15008606938645244
[Epoch 1, Batch 2700] loss: 0.13121406136546285
[Epoch 1, Batch 2800] loss: 0.11751178537961096
[Epoch 1, Batch 2900] loss: 0.15292221695417538
[Epoch 1, Batch 3000] loss: 0.132525547305122
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1186
Validation Accuracy: 0.9633
Overfitting: 0.1186
Best model saved at epoch 1 with validation loss: 0.1186
[Epoch 2, Batch 100] loss: 0.12371354199480265
[Epoch 2, Batch 200] loss: 0.14349077333696186
[Epoch 2, Batch 300] loss: 0.09977063399273903
[Epoch 2, Batch 400] loss: 0.11855357321212068
[Epoch 2, Batch 500] loss: 0.11879218039801344
[Epoch 2, Batch 600] loss: 0.11391344880219549
[Epoch 2, Batch 700] loss: 0.10777495331130922
[Epoch 2, Batch 800] loss: 0.09723383518634364
[Epoch 2, Batch 900] loss: 0.09089351367671043
[Epoch 2, Batch 1000] loss: 0.10833518744038884
[Epoch 2, Batch 1100] loss: 0.0910109557758551
[Epoch 2, Batch 1200] loss: 0.10140063988394105
[Epoch 2, Batch 1300] loss: 0.09144998521369416
[Epoch 2, Batch 1400] loss: 0.1208230876759626
[Epoch 2, Batch 1500] loss: 0.10714482244336977
[Epoch 2, Batch 1600] loss: 0.10119186844443902
[Epoch 2, Batch 1700] loss: 0.07246035761898384
[Epoch 2, Batch 1800] loss: 0.0939668493741192
[Epoch 2, Batch 1900] loss: 0.09514054175582715
[Epoch 2, Batch 2000] loss: 0.09250451618805527
[Epoch 2, Batch 2100] loss: 0.07564476805564482
[Epoch 2, Batch 2200] loss: 0.09015728709753602
[Epoch 2, Batch 2300] loss: 0.08716481091687456
[Epoch 2, Batch 2400] loss: 0.08173280321992933
[Epoch 2, Batch 2500] loss: 0.0898715390136931
[Epoch 2, Batch 2600] loss: 0.07731481513939797
[Epoch 2, Batch 2700] loss: 0.08520842327387072
[Epoch 2, Batch 2800] loss: 0.10912308179656975
[Epoch 2, Batch 2900] loss: 0.07734415725455619
[Epoch 2, Batch 3000] loss: 0.09188416446384508
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0848
Validation Accuracy: 0.9734
Overfitting: 0.0848
Best model saved at epoch 2 with validation loss: 0.0848
[Epoch 3, Batch 100] loss: 0.06916720775421709
[Epoch 3, Batch 200] loss: 0.08737242571078241
[Epoch 3, Batch 300] loss: 0.07040759819559753
[Epoch 3, Batch 400] loss: 0.08340313591819722
[Epoch 3, Batch 500] loss: 0.05908169513568282
[Epoch 3, Batch 600] loss: 0.07181754657416604
[Epoch 3, Batch 700] loss: 0.05505775142344646
[Epoch 3, Batch 800] loss: 0.05881357205624226
[Epoch 3, Batch 900] loss: 0.06111044803867117
[Epoch 3, Batch 1000] loss: 0.05505168419331312
[Epoch 3, Batch 1100] loss: 0.06478690615738741
[Epoch 3, Batch 1200] loss: 0.08071679821121507
[Epoch 3, Batch 1300] loss: 0.07492567377397791
[Epoch 3, Batch 1400] loss: 0.06262150402239058
[Epoch 3, Batch 1500] loss: 0.0799975509858632
[Epoch 3, Batch 1600] loss: 0.09402438159217126
[Epoch 3, Batch 1700] loss: 0.0533137950883247
[Epoch 3, Batch 1800] loss: 0.06581126799108461
[Epoch 3, Batch 1900] loss: 0.05393857249233406
[Epoch 3, Batch 2000] loss: 0.07475423475611023
[Epoch 3, Batch 2100] loss: 0.07335871106770356
[Epoch 3, Batch 2200] loss: 0.04922749472549185
[Epoch 3, Batch 2300] loss: 0.07203037662780844
[Epoch 3, Batch 2400] loss: 0.05818586395587772
[Epoch 3, Batch 2500] loss: 0.06360325029090745
[Epoch 3, Batch 2600] loss: 0.07655519032850862
[Epoch 3, Batch 2700] loss: 0.06704061575088417
[Epoch 3, Batch 2800] loss: 0.06141393892699853
[Epoch 3, Batch 2900] loss: 0.07490540734084788
[Epoch 3, Batch 3000] loss: 0.05274286277766805
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0774
Validation Accuracy: 0.9755
Overfitting: 0.0774
Best model saved at epoch 3 with validation loss: 0.0774
[Epoch 4, Batch 100] loss: 0.04876730598276481
[Epoch 4, Batch 200] loss: 0.043991275820299054
[Epoch 4, Batch 300] loss: 0.057295805201283655
[Epoch 4, Batch 400] loss: 0.057985136003117076
[Epoch 4, Batch 500] loss: 0.05062349332816666
[Epoch 4, Batch 600] loss: 0.06366056851751636
[Epoch 4, Batch 700] loss: 0.06730094805243425
[Epoch 4, Batch 800] loss: 0.03683938228321495
[Epoch 4, Batch 900] loss: 0.05333442259638105
[Epoch 4, Batch 1000] loss: 0.04712793425889686
[Epoch 4, Batch 1100] loss: 0.051417328694078605
[Epoch 4, Batch 1200] loss: 0.06485550161829451
[Epoch 4, Batch 1300] loss: 0.047714577728766014
[Epoch 4, Batch 1400] loss: 0.060244601309823335
[Epoch 4, Batch 1500] loss: 0.06423992589348927
[Epoch 4, Batch 1600] loss: 0.06798650107753929
[Epoch 4, Batch 1700] loss: 0.054163859046529976
[Epoch 4, Batch 1800] loss: 0.050152991421055046
[Epoch 4, Batch 1900] loss: 0.04835619566292735
[Epoch 4, Batch 2000] loss: 0.04919498762639705
[Epoch 4, Batch 2100] loss: 0.03848190264397999
[Epoch 4, Batch 2200] loss: 0.03957402566826204
[Epoch 4, Batch 2300] loss: 0.062431467617861926
[Epoch 4, Batch 2400] loss: 0.033540129688335585
[Epoch 4, Batch 2500] loss: 0.047513105472025925
[Epoch 4, Batch 2600] loss: 0.05048933068261249
[Epoch 4, Batch 2700] loss: 0.05056056960194837
[Epoch 4, Batch 2800] loss: 0.0654654002757161
[Epoch 4, Batch 2900] loss: 0.04614994199037028
[Epoch 4, Batch 3000] loss: 0.0476400014013052
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0839
Validation Accuracy: 0.9742
Overfitting: 0.0839
[Epoch 5, Batch 100] loss: 0.05050371901394101
[Epoch 5, Batch 200] loss: 0.038120239709387535
[Epoch 5, Batch 300] loss: 0.04332474813243607
[Epoch 5, Batch 400] loss: 0.03479429045066354
[Epoch 5, Batch 500] loss: 0.03965322240270325
[Epoch 5, Batch 600] loss: 0.03510695696430048
[Epoch 5, Batch 700] loss: 0.03834909720550059
[Epoch 5, Batch 800] loss: 0.05040946194101707
[Epoch 5, Batch 900] loss: 0.052395260752527976
[Epoch 5, Batch 1000] loss: 0.05629241330781951
[Epoch 5, Batch 1100] loss: 0.03156486449879594
[Epoch 5, Batch 1200] loss: 0.04617964110671892
[Epoch 5, Batch 1300] loss: 0.04295858511293773
[Epoch 5, Batch 1400] loss: 0.04461941475077765
[Epoch 5, Batch 1500] loss: 0.041782534162484807
[Epoch 5, Batch 1600] loss: 0.05561826427350752
[Epoch 5, Batch 1700] loss: 0.03565551589446841
[Epoch 5, Batch 1800] loss: 0.04064010816713562
[Epoch 5, Batch 1900] loss: 0.05846620014955988
[Epoch 5, Batch 2000] loss: 0.04851985110086389
[Epoch 5, Batch 2100] loss: 0.04128889239174896
[Epoch 5, Batch 2200] loss: 0.035495891941245646
[Epoch 5, Batch 2300] loss: 0.051600622146215754
[Epoch 5, Batch 2400] loss: 0.04366670616378542
[Epoch 5, Batch 2500] loss: 0.033953245496959425
[Epoch 5, Batch 2600] loss: 0.05595948938338552
[Epoch 5, Batch 2700] loss: 0.03803321519611927
[Epoch 5, Batch 2800] loss: 0.05044231858802959
[Epoch 5, Batch 2900] loss: 0.051902047624316765
[Epoch 5, Batch 3000] loss: 0.04488333857807447
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0640
Validation Accuracy: 0.9812
Overfitting: 0.0640
Best model saved at epoch 5 with validation loss: 0.0640
[Epoch 6, Batch 100] loss: 0.023830295456646125
[Epoch 6, Batch 200] loss: 0.029384955681016435
[Epoch 6, Batch 300] loss: 0.04423992891854141
[Epoch 6, Batch 400] loss: 0.03179457083897432
[Epoch 6, Batch 500] loss: 0.046783227514242756
[Epoch 6, Batch 600] loss: 0.03266787116546766
[Epoch 6, Batch 700] loss: 0.032942229857872006
[Epoch 6, Batch 800] loss: 0.02808674168161815
[Epoch 6, Batch 900] loss: 0.02231329899164848
[Epoch 6, Batch 1000] loss: 0.04473342639219482
[Epoch 6, Batch 1100] loss: 0.05558756682745297
[Epoch 6, Batch 1200] loss: 0.042098885533487194
[Epoch 6, Batch 1300] loss: 0.04423557786954916
[Epoch 6, Batch 1400] loss: 0.042375654644856695
[Epoch 6, Batch 1500] loss: 0.02955733640490507
[Epoch 6, Batch 1600] loss: 0.03477090924803633
[Epoch 6, Batch 1700] loss: 0.038111711733436096
[Epoch 6, Batch 1800] loss: 0.03134197114326526
[Epoch 6, Batch 1900] loss: 0.03853897210250579
[Epoch 6, Batch 2000] loss: 0.049858751825377114
[Epoch 6, Batch 2100] loss: 0.04112359397375258
[Epoch 6, Batch 2200] loss: 0.03503509204296279
[Epoch 6, Batch 2300] loss: 0.038447550791024694
[Epoch 6, Batch 2400] loss: 0.042346365944540595
[Epoch 6, Batch 2500] loss: 0.025560633302520726
[Epoch 6, Batch 2600] loss: 0.044380814255855515
[Epoch 6, Batch 2700] loss: 0.026718319888750557
[Epoch 6, Batch 2800] loss: 0.03513960873835458
[Epoch 6, Batch 2900] loss: 0.04047130209255556
[Epoch 6, Batch 3000] loss: 0.04957161060709041
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0676
Validation Accuracy: 0.9799
Overfitting: 0.0676
[Epoch 7, Batch 100] loss: 0.022583842710591853
[Epoch 7, Batch 200] loss: 0.022054849674532306
[Epoch 7, Batch 300] loss: 0.031532939167154835
[Epoch 7, Batch 400] loss: 0.029470640256768092
[Epoch 7, Batch 500] loss: 0.03770167357826722
[Epoch 7, Batch 600] loss: 0.03669349790361594
[Epoch 7, Batch 700] loss: 0.016557847959920765
[Epoch 7, Batch 800] loss: 0.03398679475518293
[Epoch 7, Batch 900] loss: 0.03632789940747898
[Epoch 7, Batch 1000] loss: 0.03851187120650138
[Epoch 7, Batch 1100] loss: 0.029642612323368667
[Epoch 7, Batch 1200] loss: 0.04185778745813877
[Epoch 7, Batch 1300] loss: 0.02870098591200076
[Epoch 7, Batch 1400] loss: 0.02579651357486
[Epoch 7, Batch 1500] loss: 0.03941435084299883
[Epoch 7, Batch 1600] loss: 0.028539220552775076
[Epoch 7, Batch 1700] loss: 0.03569220609817421
[Epoch 7, Batch 1800] loss: 0.03179765308519564
[Epoch 7, Batch 1900] loss: 0.04228927206997469
[Epoch 7, Batch 2000] loss: 0.03245321041205898
[Epoch 7, Batch 2100] loss: 0.027619047688385762
[Epoch 7, Batch 2200] loss: 0.0327847678836406
[Epoch 7, Batch 2300] loss: 0.028494346218503778
[Epoch 7, Batch 2400] loss: 0.033301672368397706
[Epoch 7, Batch 2500] loss: 0.02179201771861699
[Epoch 7, Batch 2600] loss: 0.03614240642782533
[Epoch 7, Batch 2700] loss: 0.022877354857337197
[Epoch 7, Batch 2800] loss: 0.02939138746878598
[Epoch 7, Batch 2900] loss: 0.03334003254058189
[Epoch 7, Batch 3000] loss: 0.03359000820652
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9840
Overfitting: 0.0532
Best model saved at epoch 7 with validation loss: 0.0532
[Epoch 8, Batch 100] loss: 0.029022631786087914
[Epoch 8, Batch 200] loss: 0.028913967845437583
[Epoch 8, Batch 300] loss: 0.03143071043698001
[Epoch 8, Batch 400] loss: 0.021011726419237674
[Epoch 8, Batch 500] loss: 0.014005174108569917
[Epoch 8, Batch 600] loss: 0.03289331286512606
[Epoch 8, Batch 700] loss: 0.02251501599610492
[Epoch 8, Batch 800] loss: 0.02658124644836789
[Epoch 8, Batch 900] loss: 0.031171347891067853
[Epoch 8, Batch 1000] loss: 0.029557556010258848
[Epoch 8, Batch 1100] loss: 0.016206472879966894
[Epoch 8, Batch 1200] loss: 0.036406208129483274
[Epoch 8, Batch 1300] loss: 0.02477160456532147
[Epoch 8, Batch 1400] loss: 0.02458125958692108
[Epoch 8, Batch 1500] loss: 0.021968509128782898
[Epoch 8, Batch 1600] loss: 0.026163923000422074
[Epoch 8, Batch 1700] loss: 0.025088472197985538
[Epoch 8, Batch 1800] loss: 0.03232937293494615
[Epoch 8, Batch 1900] loss: 0.027376903692347698
[Epoch 8, Batch 2000] loss: 0.026059793985023134
[Epoch 8, Batch 2100] loss: 0.03019897236423276
[Epoch 8, Batch 2200] loss: 0.024719981934285897
[Epoch 8, Batch 2300] loss: 0.020477420152819833
[Epoch 8, Batch 2400] loss: 0.02199109957224209
[Epoch 8, Batch 2500] loss: 0.029854240499225852
[Epoch 8, Batch 2600] loss: 0.031660912815459595
[Epoch 8, Batch 2700] loss: 0.03535468714007948
[Epoch 8, Batch 2800] loss: 0.02947373084120045
[Epoch 8, Batch 2900] loss: 0.03275988285968197
[Epoch 8, Batch 3000] loss: 0.027062320470904525
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9850
Overfitting: 0.0526
Best model saved at epoch 8 with validation loss: 0.0526
[Epoch 9, Batch 100] loss: 0.020922471029334703
[Epoch 9, Batch 200] loss: 0.01456406160010374
[Epoch 9, Batch 300] loss: 0.037168174110302064
[Epoch 9, Batch 400] loss: 0.024384742729780556
[Epoch 9, Batch 500] loss: 0.02964695927352295
[Epoch 9, Batch 600] loss: 0.02067473312799848
[Epoch 9, Batch 700] loss: 0.01547101799689699
[Epoch 9, Batch 800] loss: 0.01137149475496699
[Epoch 9, Batch 900] loss: 0.014389745181106264
[Epoch 9, Batch 1000] loss: 0.020550483203132897
[Epoch 9, Batch 1100] loss: 0.01654994395103131
[Epoch 9, Batch 1200] loss: 0.033465879384857546
[Epoch 9, Batch 1300] loss: 0.026841498351714108
[Epoch 9, Batch 1400] loss: 0.015671988354588395
[Epoch 9, Batch 1500] loss: 0.02301727212041442
[Epoch 9, Batch 1600] loss: 0.023143897233676398
[Epoch 9, Batch 1700] loss: 0.0264541306263709
[Epoch 9, Batch 1800] loss: 0.02701393514897063
[Epoch 9, Batch 1900] loss: 0.020557405433391976
[Epoch 9, Batch 2000] loss: 0.017926635631247335
[Epoch 9, Batch 2100] loss: 0.024122622813592898
[Epoch 9, Batch 2200] loss: 0.019502650685790286
[Epoch 9, Batch 2300] loss: 0.016897164727274684
[Epoch 9, Batch 2400] loss: 0.02175492847833084
[Epoch 9, Batch 2500] loss: 0.021086082199599333
[Epoch 9, Batch 2600] loss: 0.032087893239440744
[Epoch 9, Batch 2700] loss: 0.018318569526854844
[Epoch 9, Batch 2800] loss: 0.02518841481094569
[Epoch 9, Batch 2900] loss: 0.02370125603662018
[Epoch 9, Batch 3000] loss: 0.024401169126285822
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9832
Overfitting: 0.0559
[Epoch 10, Batch 100] loss: 0.013385662445980415
[Epoch 10, Batch 200] loss: 0.015895752246451594
[Epoch 10, Batch 300] loss: 0.014020337304573331
[Epoch 10, Batch 400] loss: 0.025865509499308246
[Epoch 10, Batch 500] loss: 0.02270283840729462
[Epoch 10, Batch 600] loss: 0.017074868213776427
[Epoch 10, Batch 700] loss: 0.016464830652148522
[Epoch 10, Batch 800] loss: 0.01444568848630297
[Epoch 10, Batch 900] loss: 0.022028895282819577
[Epoch 10, Batch 1000] loss: 0.02212490199966396
[Epoch 10, Batch 1100] loss: 0.026885416668765174
[Epoch 10, Batch 1200] loss: 0.009944455174118048
[Epoch 10, Batch 1300] loss: 0.027156927259838995
[Epoch 10, Batch 1400] loss: 0.026675254281653907
[Epoch 10, Batch 1500] loss: 0.01879977543892892
[Epoch 10, Batch 1600] loss: 0.01900965285791244
[Epoch 10, Batch 1700] loss: 0.0214457408781891
[Epoch 10, Batch 1800] loss: 0.022719923612166893
[Epoch 10, Batch 1900] loss: 0.0202192656322768
[Epoch 10, Batch 2000] loss: 0.02063674703820652
[Epoch 10, Batch 2100] loss: 0.016605864030498196
[Epoch 10, Batch 2200] loss: 0.0188193547145147
[Epoch 10, Batch 2300] loss: 0.009628976990370575
[Epoch 10, Batch 2400] loss: 0.016673474591043486
[Epoch 10, Batch 2500] loss: 0.014305010663038046
[Epoch 10, Batch 2600] loss: 0.019127987422389196
[Epoch 10, Batch 2700] loss: 0.01617599844435972
[Epoch 10, Batch 2800] loss: 0.03715225172889405
[Epoch 10, Batch 2900] loss: 0.01973495597641886
[Epoch 10, Batch 3000] loss: 0.024896076525428724
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9860
Overfitting: 0.0484
Best model saved at epoch 10 with validation loss: 0.0484
[Epoch 11, Batch 100] loss: 0.020130141917179573
[Epoch 11, Batch 200] loss: 0.012288512414797878
[Epoch 11, Batch 300] loss: 0.011334320160767675
[Epoch 11, Batch 400] loss: 0.013644131718451717
[Epoch 11, Batch 500] loss: 0.01527961066511125
[Epoch 11, Batch 600] loss: 0.013616057354593068
[Epoch 11, Batch 700] loss: 0.01217317886013916
[Epoch 11, Batch 800] loss: 0.02504584530055581
[Epoch 11, Batch 900] loss: 0.020769046168152273
[Epoch 11, Batch 1000] loss: 0.02045478205274776
[Epoch 11, Batch 1100] loss: 0.030148981103484403
[Epoch 11, Batch 1200] loss: 0.01712661902185573
[Epoch 11, Batch 1300] loss: 0.010589631381644721
[Epoch 11, Batch 1400] loss: 0.014517589882780157
[Epoch 11, Batch 1500] loss: 0.020841038219223264
[Epoch 11, Batch 1600] loss: 0.015112190491213368
[Epoch 11, Batch 1700] loss: 0.02128864055297072
[Epoch 11, Batch 1800] loss: 0.023940397083833886
[Epoch 11, Batch 1900] loss: 0.015933978867701627
[Epoch 11, Batch 2000] loss: 0.01822990118263988
[Epoch 11, Batch 2100] loss: 0.016038738853785615
[Epoch 11, Batch 2200] loss: 0.030340367345070264
[Epoch 11, Batch 2300] loss: 0.017150749314241695
[Epoch 11, Batch 2400] loss: 0.012957193751662998
[Epoch 11, Batch 2500] loss: 0.0172226645808405
[Epoch 11, Batch 2600] loss: 0.015095437116760877
[Epoch 11, Batch 2700] loss: 0.013776202509943688
[Epoch 11, Batch 2800] loss: 0.014880997779036988
[Epoch 11, Batch 2900] loss: 0.02083094104200427
[Epoch 11, Batch 3000] loss: 0.02105835062431652
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9850
Overfitting: 0.0538
[Epoch 12, Batch 100] loss: 0.014865843591760495
[Epoch 12, Batch 200] loss: 0.014465208851652278
[Epoch 12, Batch 300] loss: 0.01053021340379928
[Epoch 12, Batch 400] loss: 0.009128837062344247
[Epoch 12, Batch 500] loss: 0.014343440742895836
[Epoch 12, Batch 600] loss: 0.01269319022484524
[Epoch 12, Batch 700] loss: 0.019345403179459028
[Epoch 12, Batch 800] loss: 0.018477358010241005
[Epoch 12, Batch 900] loss: 0.020379570017785228
[Epoch 12, Batch 1000] loss: 0.018054432023245682
[Epoch 12, Batch 1100] loss: 0.010812738343447563
[Epoch 12, Batch 1200] loss: 0.02079407959708078
[Epoch 12, Batch 1300] loss: 0.02064104795079402
[Epoch 12, Batch 1400] loss: 0.007967183843265956
[Epoch 12, Batch 1500] loss: 0.029698966196265247
[Epoch 12, Batch 1600] loss: 0.01291923180438971
[Epoch 12, Batch 1700] loss: 0.01512346636123766
[Epoch 12, Batch 1800] loss: 0.009918620584321615
[Epoch 12, Batch 1900] loss: 0.005897836048006866
[Epoch 12, Batch 2000] loss: 0.03426223127788035
[Epoch 12, Batch 2100] loss: 0.01696461040610302
[Epoch 12, Batch 2200] loss: 0.024507207512087917
[Epoch 12, Batch 2300] loss: 0.011395824736518989
[Epoch 12, Batch 2400] loss: 0.026324036258029083
[Epoch 12, Batch 2500] loss: 0.011540711215384363
[Epoch 12, Batch 2600] loss: 0.004933828993725911
[Epoch 12, Batch 2700] loss: 0.014749737176325653
[Epoch 12, Batch 2800] loss: 0.018279740946722994
[Epoch 12, Batch 2900] loss: 0.017133495377202053
[Epoch 12, Batch 3000] loss: 0.015175121085503633
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9847
Overfitting: 0.0523
[Epoch 13, Batch 100] loss: 0.008002982794860145
[Epoch 13, Batch 200] loss: 0.006335100608666835
[Epoch 13, Batch 300] loss: 0.009568293475667814
[Epoch 13, Batch 400] loss: 0.01669168862506922
[Epoch 13, Batch 500] loss: 0.014806543208969743
[Epoch 13, Batch 600] loss: 0.00525858826646072
[Epoch 13, Batch 700] loss: 0.0047029803522991645
[Epoch 13, Batch 800] loss: 0.008601739056912265
[Epoch 13, Batch 900] loss: 0.011475221791333751
[Epoch 13, Batch 1000] loss: 0.011854337454353754
[Epoch 13, Batch 1100] loss: 0.013855740405042526
[Epoch 13, Batch 1200] loss: 0.009078779118717649
[Epoch 13, Batch 1300] loss: 0.012923190142398653
[Epoch 13, Batch 1400] loss: 0.013614456970262836
[Epoch 13, Batch 1500] loss: 0.017422984463437388
[Epoch 13, Batch 1600] loss: 0.011930120710021584
[Epoch 13, Batch 1700] loss: 0.012525006398436744
[Epoch 13, Batch 1800] loss: 0.021026864602745263
[Epoch 13, Batch 1900] loss: 0.01799338952139806
[Epoch 13, Batch 2000] loss: 0.022735303581321205
[Epoch 13, Batch 2100] loss: 0.021356033366901103
[Epoch 13, Batch 2200] loss: 0.015038403912112698
[Epoch 13, Batch 2300] loss: 0.009073261125831778
[Epoch 13, Batch 2400] loss: 0.009861149965099686
[Epoch 13, Batch 2500] loss: 0.01765746393262816
[Epoch 13, Batch 2600] loss: 0.010505255407479127
[Epoch 13, Batch 2700] loss: 0.006385498704648853
[Epoch 13, Batch 2800] loss: 0.02933384729190948
[Epoch 13, Batch 2900] loss: 0.012043222819411312
[Epoch 13, Batch 3000] loss: 0.009993923857000481
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9872
Overfitting: 0.0478
Best model saved at epoch 13 with validation loss: 0.0478
[Epoch 14, Batch 100] loss: 0.009385021677198893
[Epoch 14, Batch 200] loss: 0.012624642329517427
[Epoch 14, Batch 300] loss: 0.006671135743290506
[Epoch 14, Batch 400] loss: 0.012974387142107843
[Epoch 14, Batch 500] loss: 0.010579650984263935
[Epoch 14, Batch 600] loss: 0.005552782850668336
[Epoch 14, Batch 700] loss: 0.0064887465861284
[Epoch 14, Batch 800] loss: 0.005036525737750708
[Epoch 14, Batch 900] loss: 0.016353108717394208
[Epoch 14, Batch 1000] loss: 0.010075329613182476
[Epoch 14, Batch 1100] loss: 0.01719814483945811
[Epoch 14, Batch 1200] loss: 0.013570653997526279
[Epoch 14, Batch 1300] loss: 0.009130762653821876
[Epoch 14, Batch 1400] loss: 0.009218486809188561
[Epoch 14, Batch 1500] loss: 0.012537418080855787
[Epoch 14, Batch 1600] loss: 0.012876781640334229
[Epoch 14, Batch 1700] loss: 0.005437196131892961
[Epoch 14, Batch 1800] loss: 0.01258660449090712
[Epoch 14, Batch 1900] loss: 0.015628906297170033
[Epoch 14, Batch 2000] loss: 0.008189840968880162
[Epoch 14, Batch 2100] loss: 0.01076467856642921
[Epoch 14, Batch 2200] loss: 0.011014245189576286
[Epoch 14, Batch 2300] loss: 0.005491858967893677
[Epoch 14, Batch 2400] loss: 0.005413545729566067
[Epoch 14, Batch 2500] loss: 0.004628148958686324
[Epoch 14, Batch 2600] loss: 0.006316003991637445
[Epoch 14, Batch 2700] loss: 0.01066357404217797
[Epoch 14, Batch 2800] loss: 0.010192859069111364
[Epoch 14, Batch 2900] loss: 0.013407082284520583
[Epoch 14, Batch 3000] loss: 0.017947875071645285
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0580
Validation Accuracy: 0.9852
Overfitting: 0.0580
[Epoch 15, Batch 100] loss: 0.004863783243247326
[Epoch 15, Batch 200] loss: 0.006498590832115951
[Epoch 15, Batch 300] loss: 0.007090945267937059
[Epoch 15, Batch 400] loss: 0.007841427636685694
[Epoch 15, Batch 500] loss: 0.005780824176181341
[Epoch 15, Batch 600] loss: 0.015289045110421284
[Epoch 15, Batch 700] loss: 0.011110306794121243
[Epoch 15, Batch 800] loss: 0.010045623294254256
[Epoch 15, Batch 900] loss: 0.012204988689964011
[Epoch 15, Batch 1000] loss: 0.013956779879404167
[Epoch 15, Batch 1100] loss: 0.012238009216998762
[Epoch 15, Batch 1200] loss: 0.00584499192428666
[Epoch 15, Batch 1300] loss: 0.0021355873750405862
[Epoch 15, Batch 1400] loss: 0.006401791221142048
[Epoch 15, Batch 1500] loss: 0.003624704173448663
[Epoch 15, Batch 1600] loss: 0.002695618225384351
[Epoch 15, Batch 1700] loss: 0.0119913876573969
[Epoch 15, Batch 1800] loss: 0.015146058634388736
[Epoch 15, Batch 1900] loss: 0.010621541735677056
[Epoch 15, Batch 2000] loss: 0.010909190987263173
[Epoch 15, Batch 2100] loss: 0.01215844221345833
[Epoch 15, Batch 2200] loss: 0.008811147553011552
[Epoch 15, Batch 2300] loss: 0.01062369062368134
[Epoch 15, Batch 2400] loss: 0.008776397328741723
[Epoch 15, Batch 2500] loss: 0.00673401039487544
[Epoch 15, Batch 2600] loss: 0.006579933240936952
[Epoch 15, Batch 2700] loss: 0.00477730647715589
[Epoch 15, Batch 2800] loss: 0.009764316298391123
[Epoch 15, Batch 2900] loss: 0.029356486729232075
[Epoch 15, Batch 3000] loss: 0.015296925513606539
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0610
Validation Accuracy: 0.9848
Overfitting: 0.0610
[Epoch 16, Batch 100] loss: 0.0059966459782936
[Epoch 16, Batch 200] loss: 0.005940652011627207
[Epoch 16, Batch 300] loss: 0.007994803379865516
[Epoch 16, Batch 400] loss: 0.0038782099931086124
[Epoch 16, Batch 500] loss: 0.00462851049066785
[Epoch 16, Batch 600] loss: 0.005256262515094931
[Epoch 16, Batch 700] loss: 0.0026803743639402457
[Epoch 16, Batch 800] loss: 0.008681808672388342
[Epoch 16, Batch 900] loss: 0.008668123735528752
[Epoch 16, Batch 1000] loss: 0.00701630754079531
[Epoch 16, Batch 1100] loss: 0.009906940613675488
[Epoch 16, Batch 1200] loss: 0.014142465919701409
[Epoch 16, Batch 1300] loss: 0.017234956992656408
[Epoch 16, Batch 1400] loss: 0.006625060172927988
[Epoch 16, Batch 1500] loss: 0.00611015000290081
[Epoch 16, Batch 1600] loss: 0.0094559822571523
[Epoch 16, Batch 1700] loss: 0.006090251337299719
[Epoch 16, Batch 1800] loss: 0.008440786273916388
[Epoch 16, Batch 1900] loss: 0.009928368492528533
[Epoch 16, Batch 2000] loss: 0.009582253524285989
[Epoch 16, Batch 2100] loss: 0.013266140498133154
[Epoch 16, Batch 2200] loss: 0.007580402708185829
[Epoch 16, Batch 2300] loss: 0.017960659626260166
[Epoch 16, Batch 2400] loss: 0.006266143133789228
[Epoch 16, Batch 2500] loss: 0.009327122248349725
[Epoch 16, Batch 2600] loss: 0.007542770216837198
[Epoch 16, Batch 2700] loss: 0.006354996981440308
[Epoch 16, Batch 2800] loss: 0.0077990116288674475
[Epoch 16, Batch 2900] loss: 0.011472807257441674
[Epoch 16, Batch 3000] loss: 0.005151511768829096
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9872
Overfitting: 0.0504
[Epoch 17, Batch 100] loss: 0.005481548039920198
[Epoch 17, Batch 200] loss: 0.004442992714234606
[Epoch 17, Batch 300] loss: 0.004851026035149175
[Epoch 17, Batch 400] loss: 0.0029994506144674915
[Epoch 17, Batch 500] loss: 0.003299083208828506
[Epoch 17, Batch 600] loss: 0.011487597638433726
[Epoch 17, Batch 700] loss: 0.005511255246210567
[Epoch 17, Batch 800] loss: 0.004921585844820129
[Epoch 17, Batch 900] loss: 0.0033729814103253377
[Epoch 17, Batch 1000] loss: 0.0074470784832408295
[Epoch 17, Batch 1100] loss: 0.004825674935145799
[Epoch 17, Batch 1200] loss: 0.002688231097949938
[Epoch 17, Batch 1300] loss: 0.007594644102314305
[Epoch 17, Batch 1400] loss: 0.01315560273112169
[Epoch 17, Batch 1500] loss: 0.005019201739107757
[Epoch 17, Batch 1600] loss: 0.004643251730001339
[Epoch 17, Batch 1700] loss: 0.004862551821429406
[Epoch 17, Batch 1800] loss: 0.0087996357566567
[Epoch 17, Batch 1900] loss: 0.004548185924663812
[Epoch 17, Batch 2000] loss: 0.008779938223592581
[Epoch 17, Batch 2100] loss: 0.005412860570882003
[Epoch 17, Batch 2200] loss: 0.003249299162131649
[Epoch 17, Batch 2300] loss: 0.008719896043021435
[Epoch 17, Batch 2400] loss: 0.006159654232105822
[Epoch 17, Batch 2500] loss: 0.006544042471022067
[Epoch 17, Batch 2600] loss: 0.020151139103593323
[Epoch 17, Batch 2700] loss: 0.007186595618443334
[Epoch 17, Batch 2800] loss: 0.006193959642487244
[Epoch 17, Batch 2900] loss: 0.00963033122662182
[Epoch 17, Batch 3000] loss: 0.013168665646305725
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9873
Overfitting: 0.0496
[Epoch 18, Batch 100] loss: 0.0031533788983153952
[Epoch 18, Batch 200] loss: 0.006589520853794966
[Epoch 18, Batch 300] loss: 0.006625369721446077
[Epoch 18, Batch 400] loss: 0.008874221762607704
[Epoch 18, Batch 500] loss: 0.007288061067607714
[Epoch 18, Batch 600] loss: 0.005631637622783501
[Epoch 18, Batch 700] loss: 0.004341470964700705
[Epoch 18, Batch 800] loss: 0.001994313559487182
[Epoch 18, Batch 900] loss: 0.004350169409501063
[Epoch 18, Batch 1000] loss: 0.0067746092204640715
[Epoch 18, Batch 1100] loss: 0.006435809472525307
[Epoch 18, Batch 1200] loss: 0.004506974469841225
[Epoch 18, Batch 1300] loss: 0.014833167086738968
[Epoch 18, Batch 1400] loss: 0.01210372190637031
[Epoch 18, Batch 1500] loss: 0.008027580596972258
[Epoch 18, Batch 1600] loss: 0.014913675793981156
[Epoch 18, Batch 1700] loss: 0.011938942435149329
[Epoch 18, Batch 1800] loss: 0.0039841334290076705
[Epoch 18, Batch 1900] loss: 0.004267790209025861
[Epoch 18, Batch 2000] loss: 0.002744150574487776
[Epoch 18, Batch 2100] loss: 0.01173948672210031
[Epoch 18, Batch 2200] loss: 0.007180446986237712
[Epoch 18, Batch 2300] loss: 0.004168182367720874
[Epoch 18, Batch 2400] loss: 0.025685370445066837
[Epoch 18, Batch 2500] loss: 0.004072638215498046
[Epoch 18, Batch 2600] loss: 0.004062684866916015
[Epoch 18, Batch 2700] loss: 0.007891244283105153
[Epoch 18, Batch 2800] loss: 0.006991017570024382
[Epoch 18, Batch 2900] loss: 0.010892207499360894
[Epoch 18, Batch 3000] loss: 0.009836109258165493
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0598
Validation Accuracy: 0.9862
Overfitting: 0.0598
[Epoch 19, Batch 100] loss: 0.007308374795245527
[Epoch 19, Batch 200] loss: 0.007415962887306477
[Epoch 19, Batch 300] loss: 0.009083544249743909
[Epoch 19, Batch 400] loss: 0.003285912109495257
[Epoch 19, Batch 500] loss: 0.0027844848662994083
[Epoch 19, Batch 600] loss: 0.0033641094108213566
[Epoch 19, Batch 700] loss: 0.0016341326313897753
[Epoch 19, Batch 800] loss: 0.0013639915235773969
[Epoch 19, Batch 900] loss: 0.003007600009722751
[Epoch 19, Batch 1000] loss: 0.0032403648221315962
[Epoch 19, Batch 1100] loss: 0.005164393187396286
[Epoch 19, Batch 1200] loss: 0.004164547051648242
[Epoch 19, Batch 1300] loss: 0.005442108224415278
[Epoch 19, Batch 1400] loss: 0.009327622112043627
[Epoch 19, Batch 1500] loss: 0.006986483372138537
[Epoch 19, Batch 1600] loss: 0.004661257332156765
[Epoch 19, Batch 1700] loss: 0.0013963304374033213
[Epoch 19, Batch 1800] loss: 0.007385568243904572
[Epoch 19, Batch 1900] loss: 0.008507742503047666
[Epoch 19, Batch 2000] loss: 0.009791562083755138
[Epoch 19, Batch 2100] loss: 0.0032977094832335753
[Epoch 19, Batch 2200] loss: 0.002374684528331272
[Epoch 19, Batch 2300] loss: 0.005275934691275097
[Epoch 19, Batch 2400] loss: 0.005068589976216345
[Epoch 19, Batch 2500] loss: 0.00748543105622673
[Epoch 19, Batch 2600] loss: 0.007367839043279218
[Epoch 19, Batch 2700] loss: 0.0071000844983643676
[Epoch 19, Batch 2800] loss: 0.007024508356000432
[Epoch 19, Batch 2900] loss: 0.017249392280702977
[Epoch 19, Batch 3000] loss: 0.012722934205914384
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0703
Validation Accuracy: 0.9825
Overfitting: 0.0703
[Epoch 20, Batch 100] loss: 0.006873040022118176
[Epoch 20, Batch 200] loss: 0.005213582680639774
[Epoch 20, Batch 300] loss: 0.008082765845732637
[Epoch 20, Batch 400] loss: 0.0063407125113866415
[Epoch 20, Batch 500] loss: 0.007207117002869268
[Epoch 20, Batch 600] loss: 0.0016821022896829163
[Epoch 20, Batch 700] loss: 0.0027328326699876016
[Epoch 20, Batch 800] loss: 0.002876151875148025
[Epoch 20, Batch 900] loss: 0.0023167877072336296
[Epoch 20, Batch 1000] loss: 0.004166771675474479
[Epoch 20, Batch 1100] loss: 0.0058957452704726165
[Epoch 20, Batch 1200] loss: 0.00789700057831169
[Epoch 20, Batch 1300] loss: 0.007779130511815708
[Epoch 20, Batch 1400] loss: 0.008188055210404457
[Epoch 20, Batch 1500] loss: 0.003472822656499375
[Epoch 20, Batch 1600] loss: 0.004697038064687718
[Epoch 20, Batch 1700] loss: 0.01500108833478862
[Epoch 20, Batch 1800] loss: 0.004380728356258601
[Epoch 20, Batch 1900] loss: 0.004712692575711799
[Epoch 20, Batch 2000] loss: 0.003346817259377204
[Epoch 20, Batch 2100] loss: 0.001047080906254223
[Epoch 20, Batch 2200] loss: 0.005591100711948229
[Epoch 20, Batch 2300] loss: 0.0025039913313537453
[Epoch 20, Batch 2400] loss: 0.0022393630784893048
[Epoch 20, Batch 2500] loss: 0.0028631054858686868
[Epoch 20, Batch 2600] loss: 0.00419402093134579
[Epoch 20, Batch 2700] loss: 0.0019988359409433085
[Epoch 20, Batch 2800] loss: 0.006540936833257685
[Epoch 20, Batch 2900] loss: 0.004499332572518142
[Epoch 20, Batch 3000] loss: 0.00713002033330099
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9872
Overfitting: 0.0573
[Epoch 21, Batch 100] loss: 0.0019212183181639376
[Epoch 21, Batch 200] loss: 0.005034398135029079
[Epoch 21, Batch 300] loss: 0.0042213033523213995
[Epoch 21, Batch 400] loss: 0.00506804469297208
[Epoch 21, Batch 500] loss: 0.004447192865418401
[Epoch 21, Batch 600] loss: 0.0051353748405131225
[Epoch 21, Batch 700] loss: 0.001397523686674713
[Epoch 21, Batch 800] loss: 0.002346994141656751
[Epoch 21, Batch 900] loss: 0.0024926128807339866
[Epoch 21, Batch 1000] loss: 0.0019991481206682237
[Epoch 21, Batch 1100] loss: 0.0035116333647590638
[Epoch 21, Batch 1200] loss: 0.008408998848339299
[Epoch 21, Batch 1300] loss: 0.004622949381405874
[Epoch 21, Batch 1400] loss: 0.00298849402358087
[Epoch 21, Batch 1500] loss: 0.00723561830524913
[Epoch 21, Batch 1600] loss: 0.011100071567436203
[Epoch 21, Batch 1700] loss: 0.010479495783837365
[Epoch 21, Batch 1800] loss: 0.004365077548112879
[Epoch 21, Batch 1900] loss: 0.0023029582572024056
[Epoch 21, Batch 2000] loss: 0.003186265709329632
[Epoch 21, Batch 2100] loss: 0.002750932063886964
[Epoch 21, Batch 2200] loss: 0.002444170639495411
[Epoch 21, Batch 2300] loss: 0.0031207269078444666
[Epoch 21, Batch 2400] loss: 0.0024707740093992923
[Epoch 21, Batch 2500] loss: 0.007687320683028105
[Epoch 21, Batch 2600] loss: 0.005099713945867279
[Epoch 21, Batch 2700] loss: 0.005967043044595357
[Epoch 21, Batch 2800] loss: 0.0037963435270154376
[Epoch 21, Batch 2900] loss: 0.004171166075487065
[Epoch 21, Batch 3000] loss: 0.0018669804249481104
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9882
Overfitting: 0.0494
[Epoch 22, Batch 100] loss: 0.0029972752494541056
[Epoch 22, Batch 200] loss: 0.0013040968842904022
[Epoch 22, Batch 300] loss: 0.0018981660930307953
[Epoch 22, Batch 400] loss: 0.0009727737557955152
[Epoch 22, Batch 500] loss: 0.0036802614843662695
[Epoch 22, Batch 600] loss: 0.0018241965411652217
[Epoch 22, Batch 700] loss: 0.0017595064958990747
[Epoch 22, Batch 800] loss: 0.0016733015646900639
[Epoch 22, Batch 900] loss: 0.0011998181053091627
[Epoch 22, Batch 1000] loss: 0.004795764290144575
[Epoch 22, Batch 1100] loss: 0.0031883733801288372
[Epoch 22, Batch 1200] loss: 0.0023135066968788466
[Epoch 22, Batch 1300] loss: 0.0009635329579483453
[Epoch 22, Batch 1400] loss: 0.0027436782032059528
[Epoch 22, Batch 1500] loss: 0.0007662021180919965
[Epoch 22, Batch 1600] loss: 0.0015006346763805566
[Epoch 22, Batch 1700] loss: 0.0016481864373328393
[Epoch 22, Batch 1800] loss: 0.0017889668171500262
[Epoch 22, Batch 1900] loss: 0.006614701899885631
[Epoch 22, Batch 2000] loss: 0.001503280433223466
[Epoch 22, Batch 2100] loss: 0.0028630276508481243
[Epoch 22, Batch 2200] loss: 0.0016363732878131997
[Epoch 22, Batch 2300] loss: 0.005051480034525753
[Epoch 22, Batch 2400] loss: 0.0016475481736836174
[Epoch 22, Batch 2500] loss: 0.005496715165493526
[Epoch 22, Batch 2600] loss: 0.005057737809652991
[Epoch 22, Batch 2700] loss: 0.002275864852442773
[Epoch 22, Batch 2800] loss: 0.0020409981988581192
[Epoch 22, Batch 2900] loss: 0.003617889878155012
[Epoch 22, Batch 3000] loss: 0.004447163064688198
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9874
Overfitting: 0.0554
[Epoch 23, Batch 100] loss: 0.0006851242754882491
[Epoch 23, Batch 200] loss: 0.0015826255535853128
[Epoch 23, Batch 300] loss: 0.00099230207895598
[Epoch 23, Batch 400] loss: 0.00419099077519391
[Epoch 23, Batch 500] loss: 0.0025851690520778446
[Epoch 23, Batch 600] loss: 0.0007883040071465075
[Epoch 23, Batch 700] loss: 0.0005957779107053795
[Epoch 23, Batch 800] loss: 0.0007502093149116718
[Epoch 23, Batch 900] loss: 0.0009497368893349112
[Epoch 23, Batch 1000] loss: 0.0008810760456947264
[Epoch 23, Batch 1100] loss: 0.0018588551096883421
[Epoch 23, Batch 1200] loss: 0.004135749570261141
[Epoch 23, Batch 1300] loss: 0.0017900009489424918
[Epoch 23, Batch 1400] loss: 0.0014663653011132282
[Epoch 23, Batch 1500] loss: 0.0006709290679410884
[Epoch 23, Batch 1600] loss: 0.0014478631024780952
[Epoch 23, Batch 1700] loss: 0.0017740947119024497
[Epoch 23, Batch 1800] loss: 0.0009725692601591617
[Epoch 23, Batch 1900] loss: 0.0025563400503955335
[Epoch 23, Batch 2000] loss: 0.0020974441204997165
[Epoch 23, Batch 2100] loss: 0.005743824384940979
[Epoch 23, Batch 2200] loss: 0.002352317192865314
[Epoch 23, Batch 2300] loss: 0.00761033545574179
[Epoch 23, Batch 2400] loss: 0.002452829721374101
[Epoch 23, Batch 2500] loss: 0.007993936749018929
[Epoch 23, Batch 2600] loss: 0.00805311578182085
[Epoch 23, Batch 2700] loss: 0.002872506836464055
[Epoch 23, Batch 2800] loss: 0.002219782235431467
[Epoch 23, Batch 2900] loss: 0.007244331631189596
[Epoch 23, Batch 3000] loss: 0.005697888628066039
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0587
Validation Accuracy: 0.9872
Overfitting: 0.0587
[Epoch 24, Batch 100] loss: 0.00280682251314591
[Epoch 24, Batch 200] loss: 0.0011871677455809503
[Epoch 24, Batch 300] loss: 0.0014794517812263264
[Epoch 24, Batch 400] loss: 0.0047919390916504765
[Epoch 24, Batch 500] loss: 0.006913666128859273
[Epoch 24, Batch 600] loss: 0.007226215896812533
[Epoch 24, Batch 700] loss: 0.012251771955083797
[Epoch 24, Batch 800] loss: 0.005688797481879178
[Epoch 24, Batch 900] loss: 0.008312910065247934
[Epoch 24, Batch 1000] loss: 0.005139478880880261
[Epoch 24, Batch 1100] loss: 0.0035547707178676547
[Epoch 24, Batch 1200] loss: 0.002151118046762974
[Epoch 24, Batch 1300] loss: 0.0017796530905522445
[Epoch 24, Batch 1400] loss: 0.003231414314926155
[Epoch 24, Batch 1500] loss: 0.004905330850359064
[Epoch 24, Batch 1600] loss: 0.0009701701933033746
[Epoch 24, Batch 1700] loss: 0.0004162340622210081
[Epoch 24, Batch 1800] loss: 0.0024308360644533875
[Epoch 24, Batch 1900] loss: 0.009037816423585775
[Epoch 24, Batch 2000] loss: 0.0029478085443345138
[Epoch 24, Batch 2100] loss: 0.011631192163110598
[Epoch 24, Batch 2200] loss: 0.004708815972033733
[Epoch 24, Batch 2300] loss: 0.006970765577872556
[Epoch 24, Batch 2400] loss: 0.0026288319074271984
[Epoch 24, Batch 2500] loss: 0.005459492132131914
[Epoch 24, Batch 2600] loss: 0.012622405685280568
[Epoch 24, Batch 2700] loss: 0.0029397480734695593
[Epoch 24, Batch 2800] loss: 0.007495084697789025
[Epoch 24, Batch 2900] loss: 0.01260553272177276
[Epoch 24, Batch 3000] loss: 0.005008035967611591
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9865
Overfitting: 0.0608
Fold 2 validation loss: 0.0608
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.293259551525116
[Epoch 1, Batch 200] loss: 2.2669789171218873
[Epoch 1, Batch 300] loss: 2.1565945303440093
[Epoch 1, Batch 400] loss: 1.4753496378660202
[Epoch 1, Batch 500] loss: 0.73575345993042
[Epoch 1, Batch 600] loss: 0.5709631040692329
[Epoch 1, Batch 700] loss: 0.43936765268445016
[Epoch 1, Batch 800] loss: 0.36803672201931475
[Epoch 1, Batch 900] loss: 0.3933701168745756
[Epoch 1, Batch 1000] loss: 0.30084131930023433
[Epoch 1, Batch 1100] loss: 0.31096522776409985
[Epoch 1, Batch 1200] loss: 0.3047374965809286
[Epoch 1, Batch 1300] loss: 0.2600894453935325
[Epoch 1, Batch 1400] loss: 0.212806729786098
[Epoch 1, Batch 1500] loss: 0.21125787978991867
[Epoch 1, Batch 1600] loss: 0.2119289521500468
[Epoch 1, Batch 1700] loss: 0.16101358662359416
[Epoch 1, Batch 1800] loss: 0.19206053246743976
[Epoch 1, Batch 1900] loss: 0.21391667273826898
[Epoch 1, Batch 2000] loss: 0.16994243807625026
[Epoch 1, Batch 2100] loss: 0.15378884673118592
[Epoch 1, Batch 2200] loss: 0.14637690665200354
[Epoch 1, Batch 2300] loss: 0.16164807565044612
[Epoch 1, Batch 2400] loss: 0.10826250422745944
[Epoch 1, Batch 2500] loss: 0.14740117410197853
[Epoch 1, Batch 2600] loss: 0.12993926818016915
[Epoch 1, Batch 2700] loss: 0.13571619615890085
[Epoch 1, Batch 2800] loss: 0.10292317563435063
[Epoch 1, Batch 2900] loss: 0.14835355693940072
[Epoch 1, Batch 3000] loss: 0.11768705606926233
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1229
Validation Accuracy: 0.9617
Overfitting: 0.1229
Best model saved at epoch 1 with validation loss: 0.1229
[Epoch 2, Batch 100] loss: 0.1196917588217184
[Epoch 2, Batch 200] loss: 0.09603575650136918
[Epoch 2, Batch 300] loss: 0.11919480019714683
[Epoch 2, Batch 400] loss: 0.09318865696201101
[Epoch 2, Batch 500] loss: 0.11225188074284233
[Epoch 2, Batch 600] loss: 0.10370953301200643
[Epoch 2, Batch 700] loss: 0.10329984300769865
[Epoch 2, Batch 800] loss: 0.088496430204832
[Epoch 2, Batch 900] loss: 0.11905905805295333
[Epoch 2, Batch 1000] loss: 0.09423272708547302
[Epoch 2, Batch 1100] loss: 0.0987155450345017
[Epoch 2, Batch 1200] loss: 0.08226036209147423
[Epoch 2, Batch 1300] loss: 0.08938210610533133
[Epoch 2, Batch 1400] loss: 0.1024161421484314
[Epoch 2, Batch 1500] loss: 0.1002912789909169
[Epoch 2, Batch 1600] loss: 0.09748000945430249
[Epoch 2, Batch 1700] loss: 0.11800298675429076
[Epoch 2, Batch 1800] loss: 0.0931663660844788
[Epoch 2, Batch 1900] loss: 0.07793767830124125
[Epoch 2, Batch 2000] loss: 0.08006538015266415
[Epoch 2, Batch 2100] loss: 0.08604072589194402
[Epoch 2, Batch 2200] loss: 0.08694491236237809
[Epoch 2, Batch 2300] loss: 0.06869769354583695
[Epoch 2, Batch 2400] loss: 0.0923150215682108
[Epoch 2, Batch 2500] loss: 0.10767613214906305
[Epoch 2, Batch 2600] loss: 0.08867113136686385
[Epoch 2, Batch 2700] loss: 0.08097997648408636
[Epoch 2, Batch 2800] loss: 0.1065839564066846
[Epoch 2, Batch 2900] loss: 0.07011801705928519
[Epoch 2, Batch 3000] loss: 0.08423537299153395
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1010
Validation Accuracy: 0.9681
Overfitting: 0.1010
Best model saved at epoch 2 with validation loss: 0.1010
[Epoch 3, Batch 100] loss: 0.08113392364117317
[Epoch 3, Batch 200] loss: 0.0708479816786712
[Epoch 3, Batch 300] loss: 0.06402813465188956
[Epoch 3, Batch 400] loss: 0.06318936374213081
[Epoch 3, Batch 500] loss: 0.06551204347226303
[Epoch 3, Batch 600] loss: 0.069686987985624
[Epoch 3, Batch 700] loss: 0.0485607638626243
[Epoch 3, Batch 800] loss: 0.06580491887114476
[Epoch 3, Batch 900] loss: 0.048899386389530265
[Epoch 3, Batch 1000] loss: 0.05938154717005091
[Epoch 3, Batch 1100] loss: 0.09507112525054254
[Epoch 3, Batch 1200] loss: 0.07549167175893672
[Epoch 3, Batch 1300] loss: 0.08702241403749213
[Epoch 3, Batch 1400] loss: 0.04968603868677746
[Epoch 3, Batch 1500] loss: 0.0960822846670635
[Epoch 3, Batch 1600] loss: 0.07084965113957878
[Epoch 3, Batch 1700] loss: 0.07594323759549297
[Epoch 3, Batch 1800] loss: 0.0656130939826835
[Epoch 3, Batch 1900] loss: 0.07021973891649395
[Epoch 3, Batch 2000] loss: 0.048317771004512906
[Epoch 3, Batch 2100] loss: 0.07439537698344793
[Epoch 3, Batch 2200] loss: 0.07569612117426004
[Epoch 3, Batch 2300] loss: 0.0784747000806965
[Epoch 3, Batch 2400] loss: 0.06177701045293361
[Epoch 3, Batch 2500] loss: 0.06281065832357853
[Epoch 3, Batch 2600] loss: 0.06089833996025845
[Epoch 3, Batch 2700] loss: 0.07050865436787718
[Epoch 3, Batch 2800] loss: 0.07181352671585045
[Epoch 3, Batch 2900] loss: 0.038233242245041765
[Epoch 3, Batch 3000] loss: 0.05959983352571726
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0669
Validation Accuracy: 0.9796
Overfitting: 0.0669
Best model saved at epoch 3 with validation loss: 0.0669
[Epoch 4, Batch 100] loss: 0.053397919795825144
[Epoch 4, Batch 200] loss: 0.05777966303285211
[Epoch 4, Batch 300] loss: 0.06814453475410119
[Epoch 4, Batch 400] loss: 0.03998975012917071
[Epoch 4, Batch 500] loss: 0.05490489239891758
[Epoch 4, Batch 600] loss: 0.05060328939405736
[Epoch 4, Batch 700] loss: 0.034213502805214374
[Epoch 4, Batch 800] loss: 0.0713814593711868
[Epoch 4, Batch 900] loss: 0.057451367831090464
[Epoch 4, Batch 1000] loss: 0.060561344767920675
[Epoch 4, Batch 1100] loss: 0.04210867503483314
[Epoch 4, Batch 1200] loss: 0.04497422788612312
[Epoch 4, Batch 1300] loss: 0.05231717532384209
[Epoch 4, Batch 1400] loss: 0.04640765930278576
[Epoch 4, Batch 1500] loss: 0.047952177778352055
[Epoch 4, Batch 1600] loss: 0.05474599970766576
[Epoch 4, Batch 1700] loss: 0.06416190183896106
[Epoch 4, Batch 1800] loss: 0.05904909255099483
[Epoch 4, Batch 1900] loss: 0.06130364049691707
[Epoch 4, Batch 2000] loss: 0.05128637543966761
[Epoch 4, Batch 2100] loss: 0.04579156329855323
[Epoch 4, Batch 2200] loss: 0.03712264203873929
[Epoch 4, Batch 2300] loss: 0.04347074210367282
[Epoch 4, Batch 2400] loss: 0.042806327485304795
[Epoch 4, Batch 2500] loss: 0.04794628805211687
[Epoch 4, Batch 2600] loss: 0.04065024095369154
[Epoch 4, Batch 2700] loss: 0.04973631903892965
[Epoch 4, Batch 2800] loss: 0.053449543687165715
[Epoch 4, Batch 2900] loss: 0.0562256669063936
[Epoch 4, Batch 3000] loss: 0.054028988720674534
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0696
Validation Accuracy: 0.9787
Overfitting: 0.0696
[Epoch 5, Batch 100] loss: 0.0431905072266818
[Epoch 5, Batch 200] loss: 0.040893504932755606
[Epoch 5, Batch 300] loss: 0.04326327201910317
[Epoch 5, Batch 400] loss: 0.044334989988128654
[Epoch 5, Batch 500] loss: 0.03251055660424754
[Epoch 5, Batch 600] loss: 0.04636150461810758
[Epoch 5, Batch 700] loss: 0.0294712285969581
[Epoch 5, Batch 800] loss: 0.0444875984598184
[Epoch 5, Batch 900] loss: 0.05918367959035095
[Epoch 5, Batch 1000] loss: 0.05571113712489023
[Epoch 5, Batch 1100] loss: 0.048253493616648484
[Epoch 5, Batch 1200] loss: 0.03593447635095799
[Epoch 5, Batch 1300] loss: 0.038729943075450135
[Epoch 5, Batch 1400] loss: 0.03368348000294645
[Epoch 5, Batch 1500] loss: 0.04160277634866361
[Epoch 5, Batch 1600] loss: 0.045986012653811484
[Epoch 5, Batch 1700] loss: 0.0354118560950883
[Epoch 5, Batch 1800] loss: 0.060832353742735
[Epoch 5, Batch 1900] loss: 0.05728293283638777
[Epoch 5, Batch 2000] loss: 0.04557709199842066
[Epoch 5, Batch 2100] loss: 0.03426088848835206
[Epoch 5, Batch 2200] loss: 0.041985605482186654
[Epoch 5, Batch 2300] loss: 0.049598590273380976
[Epoch 5, Batch 2400] loss: 0.042321373399463486
[Epoch 5, Batch 2500] loss: 0.036011953870474823
[Epoch 5, Batch 2600] loss: 0.04284731252933852
[Epoch 5, Batch 2700] loss: 0.036070743891177696
[Epoch 5, Batch 2800] loss: 0.040315478785341835
[Epoch 5, Batch 2900] loss: 0.05257284150487976
[Epoch 5, Batch 3000] loss: 0.05490791290067136
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9815
Overfitting: 0.0567
Best model saved at epoch 5 with validation loss: 0.0567
[Epoch 6, Batch 100] loss: 0.03637558681948576
[Epoch 6, Batch 200] loss: 0.03525574252504157
[Epoch 6, Batch 300] loss: 0.03650646534675616
[Epoch 6, Batch 400] loss: 0.04006905633257702
[Epoch 6, Batch 500] loss: 0.030382877624142567
[Epoch 6, Batch 600] loss: 0.032257840998645405
[Epoch 6, Batch 700] loss: 0.0356915515907167
[Epoch 6, Batch 800] loss: 0.03102874498566962
[Epoch 6, Batch 900] loss: 0.03071988570030953
[Epoch 6, Batch 1000] loss: 0.02347063169727335
[Epoch 6, Batch 1100] loss: 0.03703724365244852
[Epoch 6, Batch 1200] loss: 0.03848183512731339
[Epoch 6, Batch 1300] loss: 0.040373402796394654
[Epoch 6, Batch 1400] loss: 0.023996772240643623
[Epoch 6, Batch 1500] loss: 0.03703091309238516
[Epoch 6, Batch 1600] loss: 0.04744838584039826
[Epoch 6, Batch 1700] loss: 0.03255285063467454
[Epoch 6, Batch 1800] loss: 0.0358055859200249
[Epoch 6, Batch 1900] loss: 0.03812132450337231
[Epoch 6, Batch 2000] loss: 0.03053013608499896
[Epoch 6, Batch 2100] loss: 0.04317677881772397
[Epoch 6, Batch 2200] loss: 0.03990935126581462
[Epoch 6, Batch 2300] loss: 0.04757578072487376
[Epoch 6, Batch 2400] loss: 0.04208240904212289
[Epoch 6, Batch 2500] loss: 0.025811505823294282
[Epoch 6, Batch 2600] loss: 0.03212321707687806
[Epoch 6, Batch 2700] loss: 0.04218265476549277
[Epoch 6, Batch 2800] loss: 0.037423263629025316
[Epoch 6, Batch 2900] loss: 0.0421031174914242
[Epoch 6, Batch 3000] loss: 0.031760615280945786
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9852
Overfitting: 0.0507
Best model saved at epoch 6 with validation loss: 0.0507
[Epoch 7, Batch 100] loss: 0.02943523317029758
[Epoch 7, Batch 200] loss: 0.022142719522016706
[Epoch 7, Batch 300] loss: 0.03506170587657834
[Epoch 7, Batch 400] loss: 0.022685198985855096
[Epoch 7, Batch 500] loss: 0.028378017503637238
[Epoch 7, Batch 600] loss: 0.02598318787815515
[Epoch 7, Batch 700] loss: 0.03496422024545609
[Epoch 7, Batch 800] loss: 0.033425322489638344
[Epoch 7, Batch 900] loss: 0.015817185473279097
[Epoch 7, Batch 1000] loss: 0.03841585380436299
[Epoch 7, Batch 1100] loss: 0.02555683148028038
[Epoch 7, Batch 1200] loss: 0.03203692065340874
[Epoch 7, Batch 1300] loss: 0.029936218319198814
[Epoch 7, Batch 1400] loss: 0.022658570515704923
[Epoch 7, Batch 1500] loss: 0.034164213549665874
[Epoch 7, Batch 1600] loss: 0.029059512550229556
[Epoch 7, Batch 1700] loss: 0.03385058043748359
[Epoch 7, Batch 1800] loss: 0.026672806637725442
[Epoch 7, Batch 1900] loss: 0.03345071517804172
[Epoch 7, Batch 2000] loss: 0.03580273835563275
[Epoch 7, Batch 2100] loss: 0.031000118956144435
[Epoch 7, Batch 2200] loss: 0.0308987373598211
[Epoch 7, Batch 2300] loss: 0.02324397761716682
[Epoch 7, Batch 2400] loss: 0.04163075638745795
[Epoch 7, Batch 2500] loss: 0.025569636485597583
[Epoch 7, Batch 2600] loss: 0.02136542174324859
[Epoch 7, Batch 2700] loss: 0.03349874245344836
[Epoch 7, Batch 2800] loss: 0.032951085685745056
[Epoch 7, Batch 2900] loss: 0.037092927783814955
[Epoch 7, Batch 3000] loss: 0.045753451562486586
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9854
Overfitting: 0.0487
Best model saved at epoch 7 with validation loss: 0.0487
[Epoch 8, Batch 100] loss: 0.024583279541548108
[Epoch 8, Batch 200] loss: 0.010006252817984205
[Epoch 8, Batch 300] loss: 0.023524726106770685
[Epoch 8, Batch 400] loss: 0.026023063351021846
[Epoch 8, Batch 500] loss: 0.018999692302459154
[Epoch 8, Batch 600] loss: 0.02477202642350676
[Epoch 8, Batch 700] loss: 0.01945640719950461
[Epoch 8, Batch 800] loss: 0.026246918685210403
[Epoch 8, Batch 900] loss: 0.024124279987663613
[Epoch 8, Batch 1000] loss: 0.0168297898624769
[Epoch 8, Batch 1100] loss: 0.02926851846423233
[Epoch 8, Batch 1200] loss: 0.03301152129846741
[Epoch 8, Batch 1300] loss: 0.03295491534499888
[Epoch 8, Batch 1400] loss: 0.02238548055609499
[Epoch 8, Batch 1500] loss: 0.026953461112425428
[Epoch 8, Batch 1600] loss: 0.024374945851050142
[Epoch 8, Batch 1700] loss: 0.025380326034028258
[Epoch 8, Batch 1800] loss: 0.033347489546104045
[Epoch 8, Batch 1900] loss: 0.023694467156165046
[Epoch 8, Batch 2000] loss: 0.033737996562194894
[Epoch 8, Batch 2100] loss: 0.02758488185364513
[Epoch 8, Batch 2200] loss: 0.03183870839369774
[Epoch 8, Batch 2300] loss: 0.03619869668080355
[Epoch 8, Batch 2400] loss: 0.01187187751980673
[Epoch 8, Batch 2500] loss: 0.021691165888478282
[Epoch 8, Batch 2600] loss: 0.02309081370731292
[Epoch 8, Batch 2700] loss: 0.03637787183572073
[Epoch 8, Batch 2800] loss: 0.02559291294121067
[Epoch 8, Batch 2900] loss: 0.017046772306912317
[Epoch 8, Batch 3000] loss: 0.04737996751493483
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9875
Overfitting: 0.0449
Best model saved at epoch 8 with validation loss: 0.0449
[Epoch 9, Batch 100] loss: 0.022054801203266833
[Epoch 9, Batch 200] loss: 0.014889102993765845
[Epoch 9, Batch 300] loss: 0.012354104350506531
[Epoch 9, Batch 400] loss: 0.01720419183751801
[Epoch 9, Batch 500] loss: 0.010737697267286421
[Epoch 9, Batch 600] loss: 0.015402303328901325
[Epoch 9, Batch 700] loss: 0.02054587414739217
[Epoch 9, Batch 800] loss: 0.027373669162225268
[Epoch 9, Batch 900] loss: 0.02146858008382878
[Epoch 9, Batch 1000] loss: 0.019660685780472704
[Epoch 9, Batch 1100] loss: 0.037771658522369765
[Epoch 9, Batch 1200] loss: 0.018213851596228778
[Epoch 9, Batch 1300] loss: 0.019820832382283698
[Epoch 9, Batch 1400] loss: 0.02016269679297693
[Epoch 9, Batch 1500] loss: 0.03194497153601333
[Epoch 9, Batch 1600] loss: 0.020927317477253383
[Epoch 9, Batch 1700] loss: 0.023038012739925763
[Epoch 9, Batch 1800] loss: 0.02751620392777113
[Epoch 9, Batch 1900] loss: 0.03508888529937394
[Epoch 9, Batch 2000] loss: 0.018787841610683243
[Epoch 9, Batch 2100] loss: 0.0248501819305784
[Epoch 9, Batch 2200] loss: 0.018101147117813524
[Epoch 9, Batch 2300] loss: 0.023234783925872762
[Epoch 9, Batch 2400] loss: 0.019384400243579875
[Epoch 9, Batch 2500] loss: 0.01907069393788788
[Epoch 9, Batch 2600] loss: 0.010687173139376682
[Epoch 9, Batch 2700] loss: 0.019737358743605
[Epoch 9, Batch 2800] loss: 0.0395676558109335
[Epoch 9, Batch 2900] loss: 0.01715887677321007
[Epoch 9, Batch 3000] loss: 0.017496668553594646
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9882
Overfitting: 0.0437
Best model saved at epoch 9 with validation loss: 0.0437
[Epoch 10, Batch 100] loss: 0.013983427799048513
[Epoch 10, Batch 200] loss: 0.013356531327335688
[Epoch 10, Batch 300] loss: 0.020007161972034736
[Epoch 10, Batch 400] loss: 0.013857159881836197
[Epoch 10, Batch 500] loss: 0.017782607066801574
[Epoch 10, Batch 600] loss: 0.009502872276784728
[Epoch 10, Batch 700] loss: 0.008883646536287416
[Epoch 10, Batch 800] loss: 0.017588269021871383
[Epoch 10, Batch 900] loss: 0.016265845850939514
[Epoch 10, Batch 1000] loss: 0.020704566595286453
[Epoch 10, Batch 1100] loss: 0.016393888624734246
[Epoch 10, Batch 1200] loss: 0.015383235760073149
[Epoch 10, Batch 1300] loss: 0.017334577695637562
[Epoch 10, Batch 1400] loss: 0.023821759971069695
[Epoch 10, Batch 1500] loss: 0.02273013386233288
[Epoch 10, Batch 1600] loss: 0.013478361961169867
[Epoch 10, Batch 1700] loss: 0.013818419106337387
[Epoch 10, Batch 1800] loss: 0.016456070193562482
[Epoch 10, Batch 1900] loss: 0.016228762127448136
[Epoch 10, Batch 2000] loss: 0.028830282598282794
[Epoch 10, Batch 2100] loss: 0.020625498216413688
[Epoch 10, Batch 2200] loss: 0.01834957614164523
[Epoch 10, Batch 2300] loss: 0.028457473969865532
[Epoch 10, Batch 2400] loss: 0.022232943726485245
[Epoch 10, Batch 2500] loss: 0.024642220225796336
[Epoch 10, Batch 2600] loss: 0.02246584911760692
[Epoch 10, Batch 2700] loss: 0.025976774976807063
[Epoch 10, Batch 2800] loss: 0.023365805265093513
[Epoch 10, Batch 2900] loss: 0.015922300436977822
[Epoch 10, Batch 3000] loss: 0.0178896150077162
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9860
Overfitting: 0.0472
[Epoch 11, Batch 100] loss: 0.01060143445374706
[Epoch 11, Batch 200] loss: 0.014373363633039845
[Epoch 11, Batch 300] loss: 0.015788953556593696
[Epoch 11, Batch 400] loss: 0.017110777695961588
[Epoch 11, Batch 500] loss: 0.018257779765644955
[Epoch 11, Batch 600] loss: 0.016234938758570933
[Epoch 11, Batch 700] loss: 0.02273911276271974
[Epoch 11, Batch 800] loss: 0.018534708998340647
[Epoch 11, Batch 900] loss: 0.01731296720499813
[Epoch 11, Batch 1000] loss: 0.015733890180931666
[Epoch 11, Batch 1100] loss: 0.013891795729978184
[Epoch 11, Batch 1200] loss: 0.014975400406729022
[Epoch 11, Batch 1300] loss: 0.025269625842847743
[Epoch 11, Batch 1400] loss: 0.012991177055446314
[Epoch 11, Batch 1500] loss: 0.019157528010246096
[Epoch 11, Batch 1600] loss: 0.016039437200852262
[Epoch 11, Batch 1700] loss: 0.0101454216928596
[Epoch 11, Batch 1800] loss: 0.015588414497187841
[Epoch 11, Batch 1900] loss: 0.018818207993508623
[Epoch 11, Batch 2000] loss: 0.020673665190549854
[Epoch 11, Batch 2100] loss: 0.009071664479433821
[Epoch 11, Batch 2200] loss: 0.008124540158023592
[Epoch 11, Batch 2300] loss: 0.018365619149276428
[Epoch 11, Batch 2400] loss: 0.006360008179974556
[Epoch 11, Batch 2500] loss: 0.012076589991829678
[Epoch 11, Batch 2600] loss: 0.01729458848851209
[Epoch 11, Batch 2700] loss: 0.014773547710719868
[Epoch 11, Batch 2800] loss: 0.015457291365655691
[Epoch 11, Batch 2900] loss: 0.016888839885923518
[Epoch 11, Batch 3000] loss: 0.02581470507017002
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9880
Overfitting: 0.0430
Best model saved at epoch 11 with validation loss: 0.0430
[Epoch 12, Batch 100] loss: 0.016023001874009422
[Epoch 12, Batch 200] loss: 0.016111690047036973
[Epoch 12, Batch 300] loss: 0.008956126578486873
[Epoch 12, Batch 400] loss: 0.02040894729761476
[Epoch 12, Batch 500] loss: 0.010078118170240487
[Epoch 12, Batch 600] loss: 0.016521357678675484
[Epoch 12, Batch 700] loss: 0.012084489248736644
[Epoch 12, Batch 800] loss: 0.012999434475295857
[Epoch 12, Batch 900] loss: 0.011965907432709174
[Epoch 12, Batch 1000] loss: 0.008467273215997011
[Epoch 12, Batch 1100] loss: 0.013289362660980259
[Epoch 12, Batch 1200] loss: 0.00994104064291605
[Epoch 12, Batch 1300] loss: 0.0238594929067267
[Epoch 12, Batch 1400] loss: 0.019047286798786443
[Epoch 12, Batch 1500] loss: 0.015176428376826152
[Epoch 12, Batch 1600] loss: 0.021514840935524263
[Epoch 12, Batch 1700] loss: 0.012098886921457962
[Epoch 12, Batch 1800] loss: 0.011099981637189558
[Epoch 12, Batch 1900] loss: 0.014683648466525484
[Epoch 12, Batch 2000] loss: 0.013669040909821888
[Epoch 12, Batch 2100] loss: 0.01129919676193822
[Epoch 12, Batch 2200] loss: 0.017982427471915797
[Epoch 12, Batch 2300] loss: 0.011377791561772028
[Epoch 12, Batch 2400] loss: 0.007138433908867228
[Epoch 12, Batch 2500] loss: 0.010140505656827371
[Epoch 12, Batch 2600] loss: 0.008501359877136565
[Epoch 12, Batch 2700] loss: 0.012347179650105318
[Epoch 12, Batch 2800] loss: 0.02590049347152217
[Epoch 12, Batch 2900] loss: 0.017761950734829952
[Epoch 12, Batch 3000] loss: 0.017607980896882508
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9872
Overfitting: 0.0478
[Epoch 13, Batch 100] loss: 0.01027016175740755
[Epoch 13, Batch 200] loss: 0.00937692245362996
[Epoch 13, Batch 300] loss: 0.003976611252210205
[Epoch 13, Batch 400] loss: 0.0075377294706197515
[Epoch 13, Batch 500] loss: 0.015790772412910884
[Epoch 13, Batch 600] loss: 0.014974709220905425
[Epoch 13, Batch 700] loss: 0.010062663811804668
[Epoch 13, Batch 800] loss: 0.007882028674196136
[Epoch 13, Batch 900] loss: 0.015508520852457651
[Epoch 13, Batch 1000] loss: 0.0068612893063300364
[Epoch 13, Batch 1100] loss: 0.009637849263290263
[Epoch 13, Batch 1200] loss: 0.011594917686179542
[Epoch 13, Batch 1300] loss: 0.015371999657500055
[Epoch 13, Batch 1400] loss: 0.014130518066098148
[Epoch 13, Batch 1500] loss: 0.007697854125769937
[Epoch 13, Batch 1600] loss: 0.00858017215728978
[Epoch 13, Batch 1700] loss: 0.014197023684440637
[Epoch 13, Batch 1800] loss: 0.01026130667471989
[Epoch 13, Batch 1900] loss: 0.008577713395552564
[Epoch 13, Batch 2000] loss: 0.011155748266473893
[Epoch 13, Batch 2100] loss: 0.016020371251411234
[Epoch 13, Batch 2200] loss: 0.008779153863238208
[Epoch 13, Batch 2300] loss: 0.005923095840175847
[Epoch 13, Batch 2400] loss: 0.00940690772493099
[Epoch 13, Batch 2500] loss: 0.020312329350490474
[Epoch 13, Batch 2600] loss: 0.012535847250919687
[Epoch 13, Batch 2700] loss: 0.014397782113378525
[Epoch 13, Batch 2800] loss: 0.013386280283716587
[Epoch 13, Batch 2900] loss: 0.017342984071819955
[Epoch 13, Batch 3000] loss: 0.011952552693664985
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9837
Overfitting: 0.0608
[Epoch 14, Batch 100] loss: 0.013277145400788868
[Epoch 14, Batch 200] loss: 0.01420915149985376
[Epoch 14, Batch 300] loss: 0.006720104576911581
[Epoch 14, Batch 400] loss: 0.0054333061495071885
[Epoch 14, Batch 500] loss: 0.008223671572359308
[Epoch 14, Batch 600] loss: 0.009090172663428575
[Epoch 14, Batch 700] loss: 0.011697947907980505
[Epoch 14, Batch 800] loss: 0.006977664720861867
[Epoch 14, Batch 900] loss: 0.010647183358942129
[Epoch 14, Batch 1000] loss: 0.006242549516773579
[Epoch 14, Batch 1100] loss: 0.010599134385998923
[Epoch 14, Batch 1200] loss: 0.015458115132861393
[Epoch 14, Batch 1300] loss: 0.013612782568789044
[Epoch 14, Batch 1400] loss: 0.010231870493365705
[Epoch 14, Batch 1500] loss: 0.016873099069780437
[Epoch 14, Batch 1600] loss: 0.01047959761278321
[Epoch 14, Batch 1700] loss: 0.011536986762000651
[Epoch 14, Batch 1800] loss: 0.008900226911982827
[Epoch 14, Batch 1900] loss: 0.007975166200958483
[Epoch 14, Batch 2000] loss: 0.011303185756473795
[Epoch 14, Batch 2100] loss: 0.006919587974546175
[Epoch 14, Batch 2200] loss: 0.012892445373398119
[Epoch 14, Batch 2300] loss: 0.011447183045366955
[Epoch 14, Batch 2400] loss: 0.010845010274165361
[Epoch 14, Batch 2500] loss: 0.012820829329616572
[Epoch 14, Batch 2600] loss: 0.017551530501896194
[Epoch 14, Batch 2700] loss: 0.007777732099073092
[Epoch 14, Batch 2800] loss: 0.008521426336649256
[Epoch 14, Batch 2900] loss: 0.015233471993565218
[Epoch 14, Batch 3000] loss: 0.00860465789650334
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9881
Overfitting: 0.0456
[Epoch 15, Batch 100] loss: 0.0069320099055130415
[Epoch 15, Batch 200] loss: 0.003614142556916704
[Epoch 15, Batch 300] loss: 0.008026758772607535
[Epoch 15, Batch 400] loss: 0.0048674115972380605
[Epoch 15, Batch 500] loss: 0.011410885130473503
[Epoch 15, Batch 600] loss: 0.0064667473693225475
[Epoch 15, Batch 700] loss: 0.011580404721562444
[Epoch 15, Batch 800] loss: 0.006247762788154887
[Epoch 15, Batch 900] loss: 0.00832791042478675
[Epoch 15, Batch 1000] loss: 0.010013385870965976
[Epoch 15, Batch 1100] loss: 0.00960487211389136
[Epoch 15, Batch 1200] loss: 0.008336982737032485
[Epoch 15, Batch 1300] loss: 0.008916335790086122
[Epoch 15, Batch 1400] loss: 0.013442953835447042
[Epoch 15, Batch 1500] loss: 0.013310430730871303
[Epoch 15, Batch 1600] loss: 0.0036903203144447614
[Epoch 15, Batch 1700] loss: 0.00845375120735298
[Epoch 15, Batch 1800] loss: 0.004979399957144324
[Epoch 15, Batch 1900] loss: 0.007250247981123721
[Epoch 15, Batch 2000] loss: 0.010728536426076971
[Epoch 15, Batch 2100] loss: 0.004653029410561658
[Epoch 15, Batch 2200] loss: 0.004779003759676925
[Epoch 15, Batch 2300] loss: 0.014492294497896978
[Epoch 15, Batch 2400] loss: 0.010512299187661256
[Epoch 15, Batch 2500] loss: 0.009225379563994806
[Epoch 15, Batch 2600] loss: 0.00856372189019794
[Epoch 15, Batch 2700] loss: 0.007183998808371826
[Epoch 15, Batch 2800] loss: 0.009340390964332528
[Epoch 15, Batch 2900] loss: 0.009270654797560382
[Epoch 15, Batch 3000] loss: 0.003063701338554665
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9889
Overfitting: 0.0439
[Epoch 16, Batch 100] loss: 0.006333077318195137
[Epoch 16, Batch 200] loss: 0.009154618459044741
[Epoch 16, Batch 300] loss: 0.0069853849625127395
[Epoch 16, Batch 400] loss: 0.0056972316858514204
[Epoch 16, Batch 500] loss: 0.0053314655660733476
[Epoch 16, Batch 600] loss: 0.011645614801718693
[Epoch 16, Batch 700] loss: 0.01051521872402418
[Epoch 16, Batch 800] loss: 0.0073719009079184165
[Epoch 16, Batch 900] loss: 0.005073668399077178
[Epoch 16, Batch 1000] loss: 0.012704508597234963
[Epoch 16, Batch 1100] loss: 0.005091408906085064
[Epoch 16, Batch 1200] loss: 0.0066985879794560785
[Epoch 16, Batch 1300] loss: 0.008302763113669016
[Epoch 16, Batch 1400] loss: 0.009586330743393318
[Epoch 16, Batch 1500] loss: 0.004503367524380905
[Epoch 16, Batch 1600] loss: 0.0032753490243214857
[Epoch 16, Batch 1700] loss: 0.004747751398662672
[Epoch 16, Batch 1800] loss: 0.013952876082817057
[Epoch 16, Batch 1900] loss: 0.01169248581840293
[Epoch 16, Batch 2000] loss: 0.006225316123986886
[Epoch 16, Batch 2100] loss: 0.0036364181436010765
[Epoch 16, Batch 2200] loss: 0.0021571825053132445
[Epoch 16, Batch 2300] loss: 0.014591124888018073
[Epoch 16, Batch 2400] loss: 0.011473539215033952
[Epoch 16, Batch 2500] loss: 0.012312342143401338
[Epoch 16, Batch 2600] loss: 0.009576611956909176
[Epoch 16, Batch 2700] loss: 0.0061807180874296815
[Epoch 16, Batch 2800] loss: 0.009585538440816777
[Epoch 16, Batch 2900] loss: 0.010680991754036313
[Epoch 16, Batch 3000] loss: 0.017675519717805628
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0530
Validation Accuracy: 0.9872
Overfitting: 0.0530
[Epoch 17, Batch 100] loss: 0.008769283544692143
[Epoch 17, Batch 200] loss: 0.007379535734850151
[Epoch 17, Batch 300] loss: 0.0016315790866826773
[Epoch 17, Batch 400] loss: 0.003998649568336532
[Epoch 17, Batch 500] loss: 0.0035793835382492032
[Epoch 17, Batch 600] loss: 0.0040983046506107715
[Epoch 17, Batch 700] loss: 0.002999673229803932
[Epoch 17, Batch 800] loss: 0.00249400576038326
[Epoch 17, Batch 900] loss: 0.008420648955934666
[Epoch 17, Batch 1000] loss: 0.004547365006234827
[Epoch 17, Batch 1100] loss: 0.00551698259993259
[Epoch 17, Batch 1200] loss: 0.0049906323511424945
[Epoch 17, Batch 1300] loss: 0.004189024517221754
[Epoch 17, Batch 1400] loss: 0.01038014441607885
[Epoch 17, Batch 1500] loss: 0.0031518874287957033
[Epoch 17, Batch 1600] loss: 0.005848058920905714
[Epoch 17, Batch 1700] loss: 0.004211700727251469
[Epoch 17, Batch 1800] loss: 0.0056385818979583745
[Epoch 17, Batch 1900] loss: 0.0036967880234647053
[Epoch 17, Batch 2000] loss: 0.014317049912978063
[Epoch 17, Batch 2100] loss: 0.003006568109486807
[Epoch 17, Batch 2200] loss: 0.0027834167349874406
[Epoch 17, Batch 2300] loss: 0.0034525940228354556
[Epoch 17, Batch 2400] loss: 0.009328608621995329
[Epoch 17, Batch 2500] loss: 0.006692705566708809
[Epoch 17, Batch 2600] loss: 0.005046874020434586
[Epoch 17, Batch 2700] loss: 0.0039374731918974245
[Epoch 17, Batch 2800] loss: 0.0023479090511096955
[Epoch 17, Batch 2900] loss: 0.005176626114889587
[Epoch 17, Batch 3000] loss: 0.0045123410019822785
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9886
Overfitting: 0.0479
[Epoch 18, Batch 100] loss: 0.009242745162563324
[Epoch 18, Batch 200] loss: 0.004764268635603912
[Epoch 18, Batch 300] loss: 0.0015460376632196926
[Epoch 18, Batch 400] loss: 0.0023381275859361496
[Epoch 18, Batch 500] loss: 0.002382745274612006
[Epoch 18, Batch 600] loss: 0.003492675785414008
[Epoch 18, Batch 700] loss: 0.003976515414112924
[Epoch 18, Batch 800] loss: 0.005604312846271569
[Epoch 18, Batch 900] loss: 0.002134666274177164
[Epoch 18, Batch 1000] loss: 0.007280298777912435
[Epoch 18, Batch 1100] loss: 0.004413859106410883
[Epoch 18, Batch 1200] loss: 0.0023797882566698545
[Epoch 18, Batch 1300] loss: 0.004643739334550218
[Epoch 18, Batch 1400] loss: 0.003021163698658711
[Epoch 18, Batch 1500] loss: 0.004258952104649367
[Epoch 18, Batch 1600] loss: 0.00463514401813363
[Epoch 18, Batch 1700] loss: 0.004191958671856923
[Epoch 18, Batch 1800] loss: 0.002346515645498357
[Epoch 18, Batch 1900] loss: 0.0034196846236471856
[Epoch 18, Batch 2000] loss: 0.011182624216886553
[Epoch 18, Batch 2100] loss: 0.0037765662600384078
[Epoch 18, Batch 2200] loss: 0.003163877153567114
[Epoch 18, Batch 2300] loss: 0.006942703167547961
[Epoch 18, Batch 2400] loss: 0.004412425244489384
[Epoch 18, Batch 2500] loss: 0.004778449327165788
[Epoch 18, Batch 2600] loss: 0.0027844443273980345
[Epoch 18, Batch 2700] loss: 0.0034994266452901004
[Epoch 18, Batch 2800] loss: 0.005623756494352534
[Epoch 18, Batch 2900] loss: 0.0037802191275588372
[Epoch 18, Batch 3000] loss: 0.0021751961823764532
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9898
Overfitting: 0.0470
[Epoch 19, Batch 100] loss: 0.006982169428113281
[Epoch 19, Batch 200] loss: 0.009142318288318164
[Epoch 19, Batch 300] loss: 0.008227645188668475
[Epoch 19, Batch 400] loss: 0.005281197071207941
[Epoch 19, Batch 500] loss: 0.0024081214615711134
[Epoch 19, Batch 600] loss: 0.0035792768870778957
[Epoch 19, Batch 700] loss: 0.007630799372987269
[Epoch 19, Batch 800] loss: 0.007796807448846721
[Epoch 19, Batch 900] loss: 0.00370042772529672
[Epoch 19, Batch 1000] loss: 0.005274461257448309
[Epoch 19, Batch 1100] loss: 0.00768203578576788
[Epoch 19, Batch 1200] loss: 0.003691600360376839
[Epoch 19, Batch 1300] loss: 0.003377397824797299
[Epoch 19, Batch 1400] loss: 0.006958495562899145
[Epoch 19, Batch 1500] loss: 0.005887768854593673
[Epoch 19, Batch 1600] loss: 0.004394333049752923
[Epoch 19, Batch 1700] loss: 0.003306067493052467
[Epoch 19, Batch 1800] loss: 0.0038661734438801432
[Epoch 19, Batch 1900] loss: 0.005278385764256086
[Epoch 19, Batch 2000] loss: 0.0036513957576042345
[Epoch 19, Batch 2100] loss: 0.0044881901209697615
[Epoch 19, Batch 2200] loss: 0.003286820199448357
[Epoch 19, Batch 2300] loss: 0.0020234607531074288
[Epoch 19, Batch 2400] loss: 0.007212829569710948
[Epoch 19, Batch 2500] loss: 0.004476804435165889
[Epoch 19, Batch 2600] loss: 0.0021505326287433136
[Epoch 19, Batch 2700] loss: 0.004512739071845005
[Epoch 19, Batch 2800] loss: 0.00240757613935358
[Epoch 19, Batch 2900] loss: 0.002491435030964624
[Epoch 19, Batch 3000] loss: 0.00148461341500564
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9884
Overfitting: 0.0513
[Epoch 20, Batch 100] loss: 0.0033220419035936287
[Epoch 20, Batch 200] loss: 0.001523929592195543
[Epoch 20, Batch 300] loss: 0.0032100661744674853
[Epoch 20, Batch 400] loss: 0.0032673222382838675
[Epoch 20, Batch 500] loss: 0.004594377251293053
[Epoch 20, Batch 600] loss: 0.0018589630437347183
[Epoch 20, Batch 700] loss: 0.004637067304485641
[Epoch 20, Batch 800] loss: 0.008481706465896365
[Epoch 20, Batch 900] loss: 0.003992895332975191
[Epoch 20, Batch 1000] loss: 0.01425813688133843
[Epoch 20, Batch 1100] loss: 0.004203358016602579
[Epoch 20, Batch 1200] loss: 0.003008045110484829
[Epoch 20, Batch 1300] loss: 0.0064771495786225585
[Epoch 20, Batch 1400] loss: 0.009196266608065287
[Epoch 20, Batch 1500] loss: 0.005403495002574346
[Epoch 20, Batch 1600] loss: 0.005229939175462732
[Epoch 20, Batch 1700] loss: 0.01097918851005545
[Epoch 20, Batch 1800] loss: 0.009553795653260977
[Epoch 20, Batch 1900] loss: 0.006944986019644261
[Epoch 20, Batch 2000] loss: 0.0017641477245922488
[Epoch 20, Batch 2100] loss: 0.0025740060382607767
[Epoch 20, Batch 2200] loss: 0.009017115193807967
[Epoch 20, Batch 2300] loss: 0.002467329489087433
[Epoch 20, Batch 2400] loss: 0.004630210854563472
[Epoch 20, Batch 2500] loss: 0.002224822290811659
[Epoch 20, Batch 2600] loss: 0.0016763891703403288
[Epoch 20, Batch 2700] loss: 0.001622192721968556
[Epoch 20, Batch 2800] loss: 0.003433420670204228
[Epoch 20, Batch 2900] loss: 0.004294304054873806
[Epoch 20, Batch 3000] loss: 0.0022364539483102418
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9890
Overfitting: 0.0522
[Epoch 21, Batch 100] loss: 0.0075170471591522415
[Epoch 21, Batch 200] loss: 0.0020556581801020003
[Epoch 21, Batch 300] loss: 0.008038294645116366
[Epoch 21, Batch 400] loss: 0.0038408572829871446
[Epoch 21, Batch 500] loss: 0.007409805762644765
[Epoch 21, Batch 600] loss: 0.0016928042953196609
[Epoch 21, Batch 700] loss: 0.0022912407910799003
[Epoch 21, Batch 800] loss: 0.0035534484943738676
[Epoch 21, Batch 900] loss: 0.0014202275458668012
[Epoch 21, Batch 1000] loss: 0.0016519875171919552
[Epoch 21, Batch 1100] loss: 0.00157481709964145
[Epoch 21, Batch 1200] loss: 0.0005729592127327266
[Epoch 21, Batch 1300] loss: 0.003868430140636714
[Epoch 21, Batch 1400] loss: 0.0007004928362128027
[Epoch 21, Batch 1500] loss: 0.0053952605842093075
[Epoch 21, Batch 1600] loss: 0.00854863860232399
[Epoch 21, Batch 1700] loss: 0.003908395332724979
[Epoch 21, Batch 1800] loss: 0.002894260578954402
[Epoch 21, Batch 1900] loss: 0.002570265950901387
[Epoch 21, Batch 2000] loss: 0.004218253589969833
[Epoch 21, Batch 2100] loss: 0.0032319611016660586
[Epoch 21, Batch 2200] loss: 0.0072865195681791305
[Epoch 21, Batch 2300] loss: 0.009236421434744386
[Epoch 21, Batch 2400] loss: 0.0071151045119424335
[Epoch 21, Batch 2500] loss: 0.007619220793094854
[Epoch 21, Batch 2600] loss: 0.0032981395650176636
[Epoch 21, Batch 2700] loss: 0.01007494942891185
[Epoch 21, Batch 2800] loss: 0.013472074196794068
[Epoch 21, Batch 2900] loss: 0.004314046430635869
[Epoch 21, Batch 3000] loss: 0.007417110515777665
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9889
Overfitting: 0.0512
[Epoch 22, Batch 100] loss: 0.0016337526318621087
[Epoch 22, Batch 200] loss: 0.0034847889512533924
[Epoch 22, Batch 300] loss: 0.0015786879763305705
[Epoch 22, Batch 400] loss: 0.005448741692320631
[Epoch 22, Batch 500] loss: 0.0043795044912153715
[Epoch 22, Batch 600] loss: 0.0013414353523083732
[Epoch 22, Batch 700] loss: 0.002048831920293921
[Epoch 22, Batch 800] loss: 0.006344316902585661
[Epoch 22, Batch 900] loss: 0.0012991277164041293
[Epoch 22, Batch 1000] loss: 0.0008844331940311179
[Epoch 22, Batch 1100] loss: 0.011654240444888764
[Epoch 22, Batch 1200] loss: 0.006573410020434096
[Epoch 22, Batch 1300] loss: 0.0013945466318031662
[Epoch 22, Batch 1400] loss: 0.0033247621410187377
[Epoch 22, Batch 1500] loss: 0.006199144904377496
[Epoch 22, Batch 1600] loss: 0.0017378299373933715
[Epoch 22, Batch 1700] loss: 0.0016878146645680659
[Epoch 22, Batch 1800] loss: 0.004273740393887948
[Epoch 22, Batch 1900] loss: 0.002531352931396782
[Epoch 22, Batch 2000] loss: 0.001871153616454535
[Epoch 22, Batch 2100] loss: 0.004863484660287432
[Epoch 22, Batch 2200] loss: 0.00772785502249306
[Epoch 22, Batch 2300] loss: 0.0020734605229529635
[Epoch 22, Batch 2400] loss: 0.003851582241907021
[Epoch 22, Batch 2500] loss: 0.003415015226706899
[Epoch 22, Batch 2600] loss: 0.0015742864445268444
[Epoch 22, Batch 2700] loss: 0.001880283584496425
[Epoch 22, Batch 2800] loss: 0.0022636012113946436
[Epoch 22, Batch 2900] loss: 0.0012012056032784813
[Epoch 22, Batch 3000] loss: 0.0036266783498461307
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9898
Overfitting: 0.0489
[Epoch 23, Batch 100] loss: 0.0008405830416506888
[Epoch 23, Batch 200] loss: 0.0012040961989891485
[Epoch 23, Batch 300] loss: 0.0007287534312700927
[Epoch 23, Batch 400] loss: 0.0008466485899925314
[Epoch 23, Batch 500] loss: 0.0015209284995450646
[Epoch 23, Batch 600] loss: 0.0023733970106768255
[Epoch 23, Batch 700] loss: 0.004009054265045933
[Epoch 23, Batch 800] loss: 0.003245683999220965
[Epoch 23, Batch 900] loss: 0.004874090919719265
[Epoch 23, Batch 1000] loss: 0.007490064744963245
[Epoch 23, Batch 1100] loss: 0.001322266736657407
[Epoch 23, Batch 1200] loss: 0.0028921857105704872
[Epoch 23, Batch 1300] loss: 0.0032240212996082285
[Epoch 23, Batch 1400] loss: 0.00312044775841855
[Epoch 23, Batch 1500] loss: 0.0021703624313471393
[Epoch 23, Batch 1600] loss: 0.0017174334802115255
[Epoch 23, Batch 1700] loss: 0.0042079184627968405
[Epoch 23, Batch 1800] loss: 0.0022097874332633882
[Epoch 23, Batch 1900] loss: 0.004728568932367381
[Epoch 23, Batch 2000] loss: 0.005693208029644375
[Epoch 23, Batch 2100] loss: 0.0042703993522283665
[Epoch 23, Batch 2200] loss: 0.0021943076543185923
[Epoch 23, Batch 2300] loss: 0.000973769769928623
[Epoch 23, Batch 2400] loss: 0.0060197221768330065
[Epoch 23, Batch 2500] loss: 0.012059462412721515
[Epoch 23, Batch 2600] loss: 0.006386378620491069
[Epoch 23, Batch 2700] loss: 0.0014503800261329047
[Epoch 23, Batch 2800] loss: 0.0014326555736452918
[Epoch 23, Batch 2900] loss: 0.0050012318420129985
[Epoch 23, Batch 3000] loss: 0.002775403504139575
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9897
Overfitting: 0.0519
[Epoch 24, Batch 100] loss: 0.0028700237941182037
[Epoch 24, Batch 200] loss: 0.0015851027252625372
[Epoch 24, Batch 300] loss: 0.0029225487599717683
[Epoch 24, Batch 400] loss: 0.0037768195264800395
[Epoch 24, Batch 500] loss: 0.0016660485134223535
[Epoch 24, Batch 600] loss: 0.00155669105203728
[Epoch 24, Batch 700] loss: 0.000878134126382335
[Epoch 24, Batch 800] loss: 0.00047896669194141594
[Epoch 24, Batch 900] loss: 0.0009083414462741323
[Epoch 24, Batch 1000] loss: 0.001214305553637729
[Epoch 24, Batch 1100] loss: 0.0008603305867308464
[Epoch 24, Batch 1200] loss: 0.0014999704186273988
[Epoch 24, Batch 1300] loss: 0.0009503483731361229
[Epoch 24, Batch 1400] loss: 0.005041416814107577
[Epoch 24, Batch 1500] loss: 0.001044853290161356
[Epoch 24, Batch 1600] loss: 0.0017478343953452136
[Epoch 24, Batch 1700] loss: 0.0007552855719521556
[Epoch 24, Batch 1800] loss: 0.001017174870838886
[Epoch 24, Batch 1900] loss: 0.0005582429234082964
[Epoch 24, Batch 2000] loss: 0.0022272938235952467
[Epoch 24, Batch 2100] loss: 0.0018668339677730473
[Epoch 24, Batch 2200] loss: 0.0011880839475342953
[Epoch 24, Batch 2300] loss: 0.002289323032772188
[Epoch 24, Batch 2400] loss: 0.0016448856826542623
[Epoch 24, Batch 2500] loss: 0.0007127886087475943
[Epoch 24, Batch 2600] loss: 0.0011702963940751943
[Epoch 24, Batch 2700] loss: 0.0006937598707801707
[Epoch 24, Batch 2800] loss: 0.0015628572696487454
[Epoch 24, Batch 2900] loss: 0.00046615406756702173
[Epoch 24, Batch 3000] loss: 0.0008007452938716764
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9898
Overfitting: 0.0527
Fold 3 validation loss: 0.0527
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2982881474494934
[Epoch 1, Batch 200] loss: 2.2803654289245605
[Epoch 1, Batch 300] loss: 2.2205025267601015
[Epoch 1, Batch 400] loss: 1.8147768533229829
[Epoch 1, Batch 500] loss: 0.8717039194703102
[Epoch 1, Batch 600] loss: 0.579257423132658
[Epoch 1, Batch 700] loss: 0.48465179204940795
[Epoch 1, Batch 800] loss: 0.4041170915961266
[Epoch 1, Batch 900] loss: 0.3848365390300751
[Epoch 1, Batch 1000] loss: 0.30921372765675187
[Epoch 1, Batch 1100] loss: 0.3290873919427395
[Epoch 1, Batch 1200] loss: 0.2701534373499453
[Epoch 1, Batch 1300] loss: 0.2507059898786247
[Epoch 1, Batch 1400] loss: 0.24465785689651967
[Epoch 1, Batch 1500] loss: 0.21667994116432965
[Epoch 1, Batch 1600] loss: 0.2298044986464083
[Epoch 1, Batch 1700] loss: 0.1736851407866925
[Epoch 1, Batch 1800] loss: 0.16309770841151475
[Epoch 1, Batch 1900] loss: 0.1920390162989497
[Epoch 1, Batch 2000] loss: 0.15354596083052457
[Epoch 1, Batch 2100] loss: 0.18521683264523744
[Epoch 1, Batch 2200] loss: 0.16444965825416147
[Epoch 1, Batch 2300] loss: 0.19593798151239752
[Epoch 1, Batch 2400] loss: 0.13095477503724395
[Epoch 1, Batch 2500] loss: 0.2047940576262772
[Epoch 1, Batch 2600] loss: 0.13523780911695213
[Epoch 1, Batch 2700] loss: 0.11591085679130629
[Epoch 1, Batch 2800] loss: 0.1629991266457364
[Epoch 1, Batch 2900] loss: 0.15070770284160973
[Epoch 1, Batch 3000] loss: 0.14442618693225084
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1235
Validation Accuracy: 0.9587
Overfitting: 0.1235
Best model saved at epoch 1 with validation loss: 0.1235
[Epoch 2, Batch 100] loss: 0.11076158412266522
[Epoch 2, Batch 200] loss: 0.12170331098139286
[Epoch 2, Batch 300] loss: 0.11323783040046692
[Epoch 2, Batch 400] loss: 0.10893912085099146
[Epoch 2, Batch 500] loss: 0.12524121614173056
[Epoch 2, Batch 600] loss: 0.09688083412591368
[Epoch 2, Batch 700] loss: 0.11723327156156302
[Epoch 2, Batch 800] loss: 0.12750384891871364
[Epoch 2, Batch 900] loss: 0.08911406225059182
[Epoch 2, Batch 1000] loss: 0.0971765073086135
[Epoch 2, Batch 1100] loss: 0.10874845468671993
[Epoch 2, Batch 1200] loss: 0.11259696180233732
[Epoch 2, Batch 1300] loss: 0.11747009033802897
[Epoch 2, Batch 1400] loss: 0.08851880609523505
[Epoch 2, Batch 1500] loss: 0.10557594946352765
[Epoch 2, Batch 1600] loss: 0.09903918456169776
[Epoch 2, Batch 1700] loss: 0.08153564692562214
[Epoch 2, Batch 1800] loss: 0.08121587605390232
[Epoch 2, Batch 1900] loss: 0.0916259696346242
[Epoch 2, Batch 2000] loss: 0.07389162983337882
[Epoch 2, Batch 2100] loss: 0.0898166937730275
[Epoch 2, Batch 2200] loss: 0.09134774620411917
[Epoch 2, Batch 2300] loss: 0.07149981857510283
[Epoch 2, Batch 2400] loss: 0.07687442332156934
[Epoch 2, Batch 2500] loss: 0.0711322618694976
[Epoch 2, Batch 2600] loss: 0.0867623339581769
[Epoch 2, Batch 2700] loss: 0.08011607954278588
[Epoch 2, Batch 2800] loss: 0.09177796881063842
[Epoch 2, Batch 2900] loss: 0.08574189459439367
[Epoch 2, Batch 3000] loss: 0.08869189049233682
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0756
Validation Accuracy: 0.9768
Overfitting: 0.0756
Best model saved at epoch 2 with validation loss: 0.0756
[Epoch 3, Batch 100] loss: 0.05492082588549238
[Epoch 3, Batch 200] loss: 0.06763178387132938
[Epoch 3, Batch 300] loss: 0.07023974023992195
[Epoch 3, Batch 400] loss: 0.07630461121501866
[Epoch 3, Batch 500] loss: 0.0705196605087258
[Epoch 3, Batch 600] loss: 0.08002143183141015
[Epoch 3, Batch 700] loss: 0.07362962376791984
[Epoch 3, Batch 800] loss: 0.06794316319166682
[Epoch 3, Batch 900] loss: 0.07435708765056916
[Epoch 3, Batch 1000] loss: 0.06566422619740479
[Epoch 3, Batch 1100] loss: 0.08577923426753842
[Epoch 3, Batch 1200] loss: 0.06287864400306717
[Epoch 3, Batch 1300] loss: 0.06442805509839672
[Epoch 3, Batch 1400] loss: 0.06407703933422454
[Epoch 3, Batch 1500] loss: 0.0678986608190462
[Epoch 3, Batch 1600] loss: 0.057853637608932335
[Epoch 3, Batch 1700] loss: 0.05780536611215212
[Epoch 3, Batch 1800] loss: 0.06495835506706499
[Epoch 3, Batch 1900] loss: 0.05018241224985104
[Epoch 3, Batch 2000] loss: 0.04625774511951022
[Epoch 3, Batch 2100] loss: 0.06243245130113792
[Epoch 3, Batch 2200] loss: 0.05499260481214151
[Epoch 3, Batch 2300] loss: 0.07201974262454314
[Epoch 3, Batch 2400] loss: 0.05026797440485097
[Epoch 3, Batch 2500] loss: 0.06402963903499767
[Epoch 3, Batch 2600] loss: 0.05740046716702636
[Epoch 3, Batch 2700] loss: 0.08468802319461247
[Epoch 3, Batch 2800] loss: 0.06794155665149447
[Epoch 3, Batch 2900] loss: 0.05083552658790722
[Epoch 3, Batch 3000] loss: 0.06679932984843617
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0637
Validation Accuracy: 0.9801
Overfitting: 0.0637
Best model saved at epoch 3 with validation loss: 0.0637
[Epoch 4, Batch 100] loss: 0.054837227881071156
[Epoch 4, Batch 200] loss: 0.03770690854958957
[Epoch 4, Batch 300] loss: 0.04299420357914641
[Epoch 4, Batch 400] loss: 0.060568695391411895
[Epoch 4, Batch 500] loss: 0.05922571077360771
[Epoch 4, Batch 600] loss: 0.05439257778431056
[Epoch 4, Batch 700] loss: 0.03774865290673915
[Epoch 4, Batch 800] loss: 0.0480277343565831
[Epoch 4, Batch 900] loss: 0.04477119611081434
[Epoch 4, Batch 1000] loss: 0.07403105556964874
[Epoch 4, Batch 1100] loss: 0.056478482210659424
[Epoch 4, Batch 1200] loss: 0.05654930183693068
[Epoch 4, Batch 1300] loss: 0.047872184189036486
[Epoch 4, Batch 1400] loss: 0.04932909745228244
[Epoch 4, Batch 1500] loss: 0.05993302773917094
[Epoch 4, Batch 1600] loss: 0.04225714817614062
[Epoch 4, Batch 1700] loss: 0.05823993932484882
[Epoch 4, Batch 1800] loss: 0.04142733107524691
[Epoch 4, Batch 1900] loss: 0.06780893130868208
[Epoch 4, Batch 2000] loss: 0.0632236132529215
[Epoch 4, Batch 2100] loss: 0.03429835058108438
[Epoch 4, Batch 2200] loss: 0.04890158401831286
[Epoch 4, Batch 2300] loss: 0.03474915016820887
[Epoch 4, Batch 2400] loss: 0.05322201539966045
[Epoch 4, Batch 2500] loss: 0.04431115715400665
[Epoch 4, Batch 2600] loss: 0.04731693692941917
[Epoch 4, Batch 2700] loss: 0.060115875377669
[Epoch 4, Batch 2800] loss: 0.0398506881139474
[Epoch 4, Batch 2900] loss: 0.05523742901626974
[Epoch 4, Batch 3000] loss: 0.05391208473709412
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9815
Overfitting: 0.0564
Best model saved at epoch 4 with validation loss: 0.0564
[Epoch 5, Batch 100] loss: 0.03666940006427467
[Epoch 5, Batch 200] loss: 0.04913579892716371
[Epoch 5, Batch 300] loss: 0.043434584498463664
[Epoch 5, Batch 400] loss: 0.04698563348661992
[Epoch 5, Batch 500] loss: 0.04601831320382189
[Epoch 5, Batch 600] loss: 0.03922118943883106
[Epoch 5, Batch 700] loss: 0.032210662255529314
[Epoch 5, Batch 800] loss: 0.032919994650146694
[Epoch 5, Batch 900] loss: 0.02449183563396218
[Epoch 5, Batch 1000] loss: 0.03992700956296176
[Epoch 5, Batch 1100] loss: 0.04218164406978758
[Epoch 5, Batch 1200] loss: 0.04651019487369922
[Epoch 5, Batch 1300] loss: 0.03554109140852233
[Epoch 5, Batch 1400] loss: 0.04751230336420122
[Epoch 5, Batch 1500] loss: 0.04371000042519881
[Epoch 5, Batch 1600] loss: 0.03824546242598444
[Epoch 5, Batch 1700] loss: 0.038473739306209606
[Epoch 5, Batch 1800] loss: 0.032828921670297856
[Epoch 5, Batch 1900] loss: 0.040006832921935714
[Epoch 5, Batch 2000] loss: 0.06526734904618933
[Epoch 5, Batch 2100] loss: 0.0445571855106391
[Epoch 5, Batch 2200] loss: 0.05232346419215901
[Epoch 5, Batch 2300] loss: 0.03657702815908124
[Epoch 5, Batch 2400] loss: 0.05543748848111136
[Epoch 5, Batch 2500] loss: 0.0307122830269509
[Epoch 5, Batch 2600] loss: 0.05186127062552259
[Epoch 5, Batch 2700] loss: 0.04591728753206553
[Epoch 5, Batch 2800] loss: 0.0459472499765252
[Epoch 5, Batch 2900] loss: 0.04544301936373813
[Epoch 5, Batch 3000] loss: 0.04855979071406182
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0547
Validation Accuracy: 0.9822
Overfitting: 0.0547
Best model saved at epoch 5 with validation loss: 0.0547
[Epoch 6, Batch 100] loss: 0.03460697637361591
[Epoch 6, Batch 200] loss: 0.029803267044044332
[Epoch 6, Batch 300] loss: 0.03564037434058264
[Epoch 6, Batch 400] loss: 0.03826920228311792
[Epoch 6, Batch 500] loss: 0.033278191716526635
[Epoch 6, Batch 600] loss: 0.03799626403939328
[Epoch 6, Batch 700] loss: 0.0359001367376186
[Epoch 6, Batch 800] loss: 0.040786102158599534
[Epoch 6, Batch 900] loss: 0.03561298921515117
[Epoch 6, Batch 1000] loss: 0.02256821993003541
[Epoch 6, Batch 1100] loss: 0.028793340009142413
[Epoch 6, Batch 1200] loss: 0.03456364854137064
[Epoch 6, Batch 1300] loss: 0.028936980094440515
[Epoch 6, Batch 1400] loss: 0.03298163064522669
[Epoch 6, Batch 1500] loss: 0.03429973893216811
[Epoch 6, Batch 1600] loss: 0.030316991926010815
[Epoch 6, Batch 1700] loss: 0.03949783794378163
[Epoch 6, Batch 1800] loss: 0.026930071996030164
[Epoch 6, Batch 1900] loss: 0.03149642889329698
[Epoch 6, Batch 2000] loss: 0.03433916113597661
[Epoch 6, Batch 2100] loss: 0.041153861151906314
[Epoch 6, Batch 2200] loss: 0.027046768464933847
[Epoch 6, Batch 2300] loss: 0.02736234431977209
[Epoch 6, Batch 2400] loss: 0.030446494438438096
[Epoch 6, Batch 2500] loss: 0.031956219025305474
[Epoch 6, Batch 2600] loss: 0.029840439048784903
[Epoch 6, Batch 2700] loss: 0.04554771581635578
[Epoch 6, Batch 2800] loss: 0.05189604291008436
[Epoch 6, Batch 2900] loss: 0.045733541885856537
[Epoch 6, Batch 3000] loss: 0.04808920850700815
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9830
Overfitting: 0.0514
Best model saved at epoch 6 with validation loss: 0.0514
[Epoch 7, Batch 100] loss: 0.028445221723377472
[Epoch 7, Batch 200] loss: 0.024477489051496378
[Epoch 7, Batch 300] loss: 0.018560419129498767
[Epoch 7, Batch 400] loss: 0.021262758708326147
[Epoch 7, Batch 500] loss: 0.02564013818227977
[Epoch 7, Batch 600] loss: 0.028484970328645432
[Epoch 7, Batch 700] loss: 0.019522463104622148
[Epoch 7, Batch 800] loss: 0.03413930717040785
[Epoch 7, Batch 900] loss: 0.025565672337834258
[Epoch 7, Batch 1000] loss: 0.03582623327263718
[Epoch 7, Batch 1100] loss: 0.03940238492767094
[Epoch 7, Batch 1200] loss: 0.04898239774440299
[Epoch 7, Batch 1300] loss: 0.04097941064770566
[Epoch 7, Batch 1400] loss: 0.018974053863930748
[Epoch 7, Batch 1500] loss: 0.022809006897186918
[Epoch 7, Batch 1600] loss: 0.030021957108401692
[Epoch 7, Batch 1700] loss: 0.03187652611206431
[Epoch 7, Batch 1800] loss: 0.03399616112568765
[Epoch 7, Batch 1900] loss: 0.048003242621198296
[Epoch 7, Batch 2000] loss: 0.0295095734714414
[Epoch 7, Batch 2100] loss: 0.030351990228664364
[Epoch 7, Batch 2200] loss: 0.02992694860949996
[Epoch 7, Batch 2300] loss: 0.03754324013549194
[Epoch 7, Batch 2400] loss: 0.025391698534513125
[Epoch 7, Batch 2500] loss: 0.022238193232988125
[Epoch 7, Batch 2600] loss: 0.027818444032382105
[Epoch 7, Batch 2700] loss: 0.02081739623354224
[Epoch 7, Batch 2800] loss: 0.019620312637416645
[Epoch 7, Batch 2900] loss: 0.02902571063603318
[Epoch 7, Batch 3000] loss: 0.024294980183403824
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9867
Overfitting: 0.0449
Best model saved at epoch 7 with validation loss: 0.0449
[Epoch 8, Batch 100] loss: 0.022164849873515777
[Epoch 8, Batch 200] loss: 0.034015906224049104
[Epoch 8, Batch 300] loss: 0.01561460214201361
[Epoch 8, Batch 400] loss: 0.02114835408396175
[Epoch 8, Batch 500] loss: 0.026387371001037538
[Epoch 8, Batch 600] loss: 0.028200092520200996
[Epoch 8, Batch 700] loss: 0.026744345777406125
[Epoch 8, Batch 800] loss: 0.031793408226803876
[Epoch 8, Batch 900] loss: 0.03273961917446286
[Epoch 8, Batch 1000] loss: 0.030954334568232298
[Epoch 8, Batch 1100] loss: 0.024500154047564136
[Epoch 8, Batch 1200] loss: 0.025161919730053342
[Epoch 8, Batch 1300] loss: 0.02904880546482673
[Epoch 8, Batch 1400] loss: 0.030200852831912924
[Epoch 8, Batch 1500] loss: 0.01840906274279405
[Epoch 8, Batch 1600] loss: 0.03712793427846919
[Epoch 8, Batch 1700] loss: 0.024894558658779715
[Epoch 8, Batch 1800] loss: 0.04625331094794092
[Epoch 8, Batch 1900] loss: 0.02201733386667911
[Epoch 8, Batch 2000] loss: 0.017086085391420057
[Epoch 8, Batch 2100] loss: 0.0139461460612074
[Epoch 8, Batch 2200] loss: 0.020219880286058468
[Epoch 8, Batch 2300] loss: 0.02127300476684468
[Epoch 8, Batch 2400] loss: 0.02849322178059083
[Epoch 8, Batch 2500] loss: 0.026494677547598256
[Epoch 8, Batch 2600] loss: 0.01862830270729319
[Epoch 8, Batch 2700] loss: 0.036766865791287275
[Epoch 8, Batch 2800] loss: 0.021171331709992955
[Epoch 8, Batch 2900] loss: 0.026039316176538704
[Epoch 8, Batch 3000] loss: 0.022544501422307805
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9862
Overfitting: 0.0480
[Epoch 9, Batch 100] loss: 0.014895497030738624
[Epoch 9, Batch 200] loss: 0.007750411827219068
[Epoch 9, Batch 300] loss: 0.025774173417994463
[Epoch 9, Batch 400] loss: 0.021569755184518726
[Epoch 9, Batch 500] loss: 0.024027324207090715
[Epoch 9, Batch 600] loss: 0.013921059251806582
[Epoch 9, Batch 700] loss: 0.018385300770241884
[Epoch 9, Batch 800] loss: 0.02302156114985337
[Epoch 9, Batch 900] loss: 0.022197787317891196
[Epoch 9, Batch 1000] loss: 0.026727637631320248
[Epoch 9, Batch 1100] loss: 0.01014340877180075
[Epoch 9, Batch 1200] loss: 0.018582438540142902
[Epoch 9, Batch 1300] loss: 0.022076051402873418
[Epoch 9, Batch 1400] loss: 0.01920750944296742
[Epoch 9, Batch 1500] loss: 0.02017105278715462
[Epoch 9, Batch 1600] loss: 0.019446596337656955
[Epoch 9, Batch 1700] loss: 0.03453528930291214
[Epoch 9, Batch 1800] loss: 0.02194032549381518
[Epoch 9, Batch 1900] loss: 0.02036775061918888
[Epoch 9, Batch 2000] loss: 0.02720823010206004
[Epoch 9, Batch 2100] loss: 0.028081375213732825
[Epoch 9, Batch 2200] loss: 0.03744480055735039
[Epoch 9, Batch 2300] loss: 0.020970376853001654
[Epoch 9, Batch 2400] loss: 0.024902330982295096
[Epoch 9, Batch 2500] loss: 0.023307897073755156
[Epoch 9, Batch 2600] loss: 0.021642257511466596
[Epoch 9, Batch 2700] loss: 0.01829651597305201
[Epoch 9, Batch 2800] loss: 0.02638454492045639
[Epoch 9, Batch 2900] loss: 0.012392761972350855
[Epoch 9, Batch 3000] loss: 0.02359277402934822
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0434
Validation Accuracy: 0.9862
Overfitting: 0.0434
Best model saved at epoch 9 with validation loss: 0.0434
[Epoch 10, Batch 100] loss: 0.023069906306336634
[Epoch 10, Batch 200] loss: 0.016652339959327946
[Epoch 10, Batch 300] loss: 0.013992501322723
[Epoch 10, Batch 400] loss: 0.01743975914683688
[Epoch 10, Batch 500] loss: 0.014683854794420768
[Epoch 10, Batch 600] loss: 0.012409920776790387
[Epoch 10, Batch 700] loss: 0.012419937408340046
[Epoch 10, Batch 800] loss: 0.01174909107959138
[Epoch 10, Batch 900] loss: 0.020099877789998572
[Epoch 10, Batch 1000] loss: 0.017746384917236357
[Epoch 10, Batch 1100] loss: 0.013578971655479109
[Epoch 10, Batch 1200] loss: 0.014397356915142155
[Epoch 10, Batch 1300] loss: 0.016036900817625793
[Epoch 10, Batch 1400] loss: 0.017326953740921455
[Epoch 10, Batch 1500] loss: 0.018187640935248054
[Epoch 10, Batch 1600] loss: 0.021742121070701614
[Epoch 10, Batch 1700] loss: 0.014897462196713604
[Epoch 10, Batch 1800] loss: 0.015357067733466465
[Epoch 10, Batch 1900] loss: 0.03324226117714715
[Epoch 10, Batch 2000] loss: 0.011450655405787984
[Epoch 10, Batch 2100] loss: 0.018341120615123146
[Epoch 10, Batch 2200] loss: 0.025168809764509206
[Epoch 10, Batch 2300] loss: 0.013034737603447866
[Epoch 10, Batch 2400] loss: 0.02015354517207015
[Epoch 10, Batch 2500] loss: 0.0315921265832003
[Epoch 10, Batch 2600] loss: 0.022046484875900205
[Epoch 10, Batch 2700] loss: 0.014191721774805046
[Epoch 10, Batch 2800] loss: 0.02300526373095636
[Epoch 10, Batch 2900] loss: 0.021458813108511096
[Epoch 10, Batch 3000] loss: 0.01617437979493843
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9862
Overfitting: 0.0449
[Epoch 11, Batch 100] loss: 0.014176233737871372
[Epoch 11, Batch 200] loss: 0.011700996415947884
[Epoch 11, Batch 300] loss: 0.019660202887998822
[Epoch 11, Batch 400] loss: 0.015346007531588839
[Epoch 11, Batch 500] loss: 0.012843783919270208
[Epoch 11, Batch 600] loss: 0.01375019995681214
[Epoch 11, Batch 700] loss: 0.02560001213671967
[Epoch 11, Batch 800] loss: 0.01883477704757752
[Epoch 11, Batch 900] loss: 0.011609609364959396
[Epoch 11, Batch 1000] loss: 0.01792464206175282
[Epoch 11, Batch 1100] loss: 0.023273679690205426
[Epoch 11, Batch 1200] loss: 0.024135778265626868
[Epoch 11, Batch 1300] loss: 0.0190618638144133
[Epoch 11, Batch 1400] loss: 0.01502853581445379
[Epoch 11, Batch 1500] loss: 0.014357500887645074
[Epoch 11, Batch 1600] loss: 0.01422211797224918
[Epoch 11, Batch 1700] loss: 0.013222507456666789
[Epoch 11, Batch 1800] loss: 0.008965742847030923
[Epoch 11, Batch 1900] loss: 0.018279468931073097
[Epoch 11, Batch 2000] loss: 0.011843383910145349
[Epoch 11, Batch 2100] loss: 0.019118644656982722
[Epoch 11, Batch 2200] loss: 0.01533272805442266
[Epoch 11, Batch 2300] loss: 0.013338417232389474
[Epoch 11, Batch 2400] loss: 0.01960403009962647
[Epoch 11, Batch 2500] loss: 0.021819214583811117
[Epoch 11, Batch 2600] loss: 0.017237196872138157
[Epoch 11, Batch 2700] loss: 0.013727018104018497
[Epoch 11, Batch 2800] loss: 0.023556372258572083
[Epoch 11, Batch 2900] loss: 0.019264779089548937
[Epoch 11, Batch 3000] loss: 0.013015692426160968
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9877
Overfitting: 0.0431
Best model saved at epoch 11 with validation loss: 0.0431
[Epoch 12, Batch 100] loss: 0.0056660948507760624
[Epoch 12, Batch 200] loss: 0.006960706575937365
[Epoch 12, Batch 300] loss: 0.015785403114750806
[Epoch 12, Batch 400] loss: 0.01477136704741497
[Epoch 12, Batch 500] loss: 0.013940116364292408
[Epoch 12, Batch 600] loss: 0.01835267311169446
[Epoch 12, Batch 700] loss: 0.015862281541108133
[Epoch 12, Batch 800] loss: 0.011990933516608493
[Epoch 12, Batch 900] loss: 0.018368268191889
[Epoch 12, Batch 1000] loss: 0.013759356199848298
[Epoch 12, Batch 1100] loss: 0.007996932977712277
[Epoch 12, Batch 1200] loss: 0.015045809119042132
[Epoch 12, Batch 1300] loss: 0.014754732582650832
[Epoch 12, Batch 1400] loss: 0.009415517175448258
[Epoch 12, Batch 1500] loss: 0.009838731038685182
[Epoch 12, Batch 1600] loss: 0.01504491331555755
[Epoch 12, Batch 1700] loss: 0.019252624461796587
[Epoch 12, Batch 1800] loss: 0.021362467885146542
[Epoch 12, Batch 1900] loss: 0.01602862738098338
[Epoch 12, Batch 2000] loss: 0.018823275363847643
[Epoch 12, Batch 2100] loss: 0.012227913242932119
[Epoch 12, Batch 2200] loss: 0.007902232589822233
[Epoch 12, Batch 2300] loss: 0.01398601851640251
[Epoch 12, Batch 2400] loss: 0.006828246208069686
[Epoch 12, Batch 2500] loss: 0.016033610282274822
[Epoch 12, Batch 2600] loss: 0.007652476407142786
[Epoch 12, Batch 2700] loss: 0.014180641947650657
[Epoch 12, Batch 2800] loss: 0.017002107889151147
[Epoch 12, Batch 2900] loss: 0.011846468919211475
[Epoch 12, Batch 3000] loss: 0.02263491554763277
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9862
Overfitting: 0.0483
[Epoch 13, Batch 100] loss: 0.01842470921792483
[Epoch 13, Batch 200] loss: 0.012862357987477252
[Epoch 13, Batch 300] loss: 0.005670177961974332
[Epoch 13, Batch 400] loss: 0.010615171074546197
[Epoch 13, Batch 500] loss: 0.00909610217278896
[Epoch 13, Batch 600] loss: 0.011997549202437768
[Epoch 13, Batch 700] loss: 0.011333282100740688
[Epoch 13, Batch 800] loss: 0.01677723320492987
[Epoch 13, Batch 900] loss: 0.01184078052666564
[Epoch 13, Batch 1000] loss: 0.008172541708072458
[Epoch 13, Batch 1100] loss: 0.006677780793961574
[Epoch 13, Batch 1200] loss: 0.009881988566539802
[Epoch 13, Batch 1300] loss: 0.019032356545017136
[Epoch 13, Batch 1400] loss: 0.01644517953849572
[Epoch 13, Batch 1500] loss: 0.00803257456231222
[Epoch 13, Batch 1600] loss: 0.012027013812312361
[Epoch 13, Batch 1700] loss: 0.008302115674450761
[Epoch 13, Batch 1800] loss: 0.0036550425603036276
[Epoch 13, Batch 1900] loss: 0.01042817659304319
[Epoch 13, Batch 2000] loss: 0.008931830150920632
[Epoch 13, Batch 2100] loss: 0.02493105985859984
[Epoch 13, Batch 2200] loss: 0.013957129746322607
[Epoch 13, Batch 2300] loss: 0.010025065561269458
[Epoch 13, Batch 2400] loss: 0.009343067424938454
[Epoch 13, Batch 2500] loss: 0.02498476359961387
[Epoch 13, Batch 2600] loss: 0.020882836115042665
[Epoch 13, Batch 2700] loss: 0.007172248024380679
[Epoch 13, Batch 2800] loss: 0.015000498726080877
[Epoch 13, Batch 2900] loss: 0.021203955891223814
[Epoch 13, Batch 3000] loss: 0.01889878040853546
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9877
Overfitting: 0.0462
[Epoch 14, Batch 100] loss: 0.00846085100088203
[Epoch 14, Batch 200] loss: 0.012163965930076301
[Epoch 14, Batch 300] loss: 0.0059824884067325
[Epoch 14, Batch 400] loss: 0.005120283321102761
[Epoch 14, Batch 500] loss: 0.007113775489278851
[Epoch 14, Batch 600] loss: 0.011318930337138227
[Epoch 14, Batch 700] loss: 0.011728717039691219
[Epoch 14, Batch 800] loss: 0.01346490397407024
[Epoch 14, Batch 900] loss: 0.005840896169507346
[Epoch 14, Batch 1000] loss: 0.007733158379624001
[Epoch 14, Batch 1100] loss: 0.006346964076292352
[Epoch 14, Batch 1200] loss: 0.006872226994487391
[Epoch 14, Batch 1300] loss: 0.00960591421965546
[Epoch 14, Batch 1400] loss: 0.008076787120271546
[Epoch 14, Batch 1500] loss: 0.006714602686254238
[Epoch 14, Batch 1600] loss: 0.010708702880717737
[Epoch 14, Batch 1700] loss: 0.009622175658957986
[Epoch 14, Batch 1800] loss: 0.009074011958325627
[Epoch 14, Batch 1900] loss: 0.02199769086342144
[Epoch 14, Batch 2000] loss: 0.011749820518775777
[Epoch 14, Batch 2100] loss: 0.011164180033988487
[Epoch 14, Batch 2200] loss: 0.007168851300070856
[Epoch 14, Batch 2300] loss: 0.006128101280694409
[Epoch 14, Batch 2400] loss: 0.013814188666722203
[Epoch 14, Batch 2500] loss: 0.010093365521154283
[Epoch 14, Batch 2600] loss: 0.017406146726225414
[Epoch 14, Batch 2700] loss: 0.015569368754131573
[Epoch 14, Batch 2800] loss: 0.00899275063289906
[Epoch 14, Batch 2900] loss: 0.01005644644826134
[Epoch 14, Batch 3000] loss: 0.009051141913928404
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9872
Overfitting: 0.0485
[Epoch 15, Batch 100] loss: 0.004207920618682692
[Epoch 15, Batch 200] loss: 0.006876775218026409
[Epoch 15, Batch 300] loss: 0.004454707347740623
[Epoch 15, Batch 400] loss: 0.005844732466521237
[Epoch 15, Batch 500] loss: 0.013189416640930176
[Epoch 15, Batch 600] loss: 0.01914957335966392
[Epoch 15, Batch 700] loss: 0.007374336849188694
[Epoch 15, Batch 800] loss: 0.007253726421383817
[Epoch 15, Batch 900] loss: 0.006996827746035023
[Epoch 15, Batch 1000] loss: 0.011751533690337511
[Epoch 15, Batch 1100] loss: 0.00906874631184337
[Epoch 15, Batch 1200] loss: 0.004095256029063421
[Epoch 15, Batch 1300] loss: 0.010270526635445094
[Epoch 15, Batch 1400] loss: 0.003201245299501352
[Epoch 15, Batch 1500] loss: 0.011168841535861703
[Epoch 15, Batch 1600] loss: 0.006291251532602473
[Epoch 15, Batch 1700] loss: 0.020623766355003
[Epoch 15, Batch 1800] loss: 0.009716469869280217
[Epoch 15, Batch 1900] loss: 0.007758739628884541
[Epoch 15, Batch 2000] loss: 0.009430092309553401
[Epoch 15, Batch 2100] loss: 0.00853559624866648
[Epoch 15, Batch 2200] loss: 0.02303299353386592
[Epoch 15, Batch 2300] loss: 0.011525217701251905
[Epoch 15, Batch 2400] loss: 0.01509872029100734
[Epoch 15, Batch 2500] loss: 0.007652262939659522
[Epoch 15, Batch 2600] loss: 0.009859085505543135
[Epoch 15, Batch 2700] loss: 0.005850675176602636
[Epoch 15, Batch 2800] loss: 0.007124551628089648
[Epoch 15, Batch 2900] loss: 0.004200804001977758
[Epoch 15, Batch 3000] loss: 0.011853854679376354
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9867
Overfitting: 0.0497
[Epoch 16, Batch 100] loss: 0.009053070887603099
[Epoch 16, Batch 200] loss: 0.005851580715689125
[Epoch 16, Batch 300] loss: 0.005309203346828326
[Epoch 16, Batch 400] loss: 0.004984168224323185
[Epoch 16, Batch 500] loss: 0.006444835037901839
[Epoch 16, Batch 600] loss: 0.009570741267697257
[Epoch 16, Batch 700] loss: 0.003577700971670765
[Epoch 16, Batch 800] loss: 0.0054661521860930404
[Epoch 16, Batch 900] loss: 0.005853644640097855
[Epoch 16, Batch 1000] loss: 0.0035873006124734273
[Epoch 16, Batch 1100] loss: 0.008459324504183314
[Epoch 16, Batch 1200] loss: 0.008992007374043282
[Epoch 16, Batch 1300] loss: 0.004940191466776014
[Epoch 16, Batch 1400] loss: 0.0072005535022594816
[Epoch 16, Batch 1500] loss: 0.011273520794035222
[Epoch 16, Batch 1600] loss: 0.01568717482587317
[Epoch 16, Batch 1700] loss: 0.010132336758549626
[Epoch 16, Batch 1800] loss: 0.006131063546050654
[Epoch 16, Batch 1900] loss: 0.012251579904710184
[Epoch 16, Batch 2000] loss: 0.0035766010228758206
[Epoch 16, Batch 2100] loss: 0.0035402527594919774
[Epoch 16, Batch 2200] loss: 0.012389345184113268
[Epoch 16, Batch 2300] loss: 0.011271692573218388
[Epoch 16, Batch 2400] loss: 0.009354854072619219
[Epoch 16, Batch 2500] loss: 0.008929258824325643
[Epoch 16, Batch 2600] loss: 0.007210116066655701
[Epoch 16, Batch 2700] loss: 0.010507188891189116
[Epoch 16, Batch 2800] loss: 0.009926112320792982
[Epoch 16, Batch 2900] loss: 0.017888265166736802
[Epoch 16, Batch 3000] loss: 0.003867899598656095
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0427
Validation Accuracy: 0.9884
Overfitting: 0.0427
Best model saved at epoch 16 with validation loss: 0.0427
[Epoch 17, Batch 100] loss: 0.0042552613935208684
[Epoch 17, Batch 200] loss: 0.00527532999569587
[Epoch 17, Batch 300] loss: 0.009116061311333397
[Epoch 17, Batch 400] loss: 0.0026792655000667763
[Epoch 17, Batch 500] loss: 0.002994268955644088
[Epoch 17, Batch 600] loss: 0.009684936689707229
[Epoch 17, Batch 700] loss: 0.003063768531039841
[Epoch 17, Batch 800] loss: 0.0022087648738278176
[Epoch 17, Batch 900] loss: 0.005252392166552227
[Epoch 17, Batch 1000] loss: 0.011009073601833279
[Epoch 17, Batch 1100] loss: 0.0034337862514883
[Epoch 17, Batch 1200] loss: 0.0032908367495736003
[Epoch 17, Batch 1300] loss: 0.010945532637397264
[Epoch 17, Batch 1400] loss: 0.004450084714773084
[Epoch 17, Batch 1500] loss: 0.005498282901243101
[Epoch 17, Batch 1600] loss: 0.004313925073365681
[Epoch 17, Batch 1700] loss: 0.012316675604242277
[Epoch 17, Batch 1800] loss: 0.01287929988009637
[Epoch 17, Batch 1900] loss: 0.006324978883048971
[Epoch 17, Batch 2000] loss: 0.008795780559027548
[Epoch 17, Batch 2100] loss: 0.008114637024783633
[Epoch 17, Batch 2200] loss: 0.006979231686611911
[Epoch 17, Batch 2300] loss: 0.004009020687668112
[Epoch 17, Batch 2400] loss: 0.006498763401336874
[Epoch 17, Batch 2500] loss: 0.0052007688623410785
[Epoch 17, Batch 2600] loss: 0.008131123774832076
[Epoch 17, Batch 2700] loss: 0.004595533992701278
[Epoch 17, Batch 2800] loss: 0.004964103711337202
[Epoch 17, Batch 2900] loss: 0.007316576093785585
[Epoch 17, Batch 3000] loss: 0.008210124908250691
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9874
Overfitting: 0.0452
[Epoch 18, Batch 100] loss: 0.0016321197159339818
[Epoch 18, Batch 200] loss: 0.0030105555497272007
[Epoch 18, Batch 300] loss: 0.0056516458745886665
[Epoch 18, Batch 400] loss: 0.0018025146300237793
[Epoch 18, Batch 500] loss: 0.005745955621541157
[Epoch 18, Batch 600] loss: 0.002427043124961585
[Epoch 18, Batch 700] loss: 0.0029969544563361694
[Epoch 18, Batch 800] loss: 0.00726659312703731
[Epoch 18, Batch 900] loss: 0.004625990495668475
[Epoch 18, Batch 1000] loss: 0.006650015303991949
[Epoch 18, Batch 1100] loss: 0.0033650219233729217
[Epoch 18, Batch 1200] loss: 0.002714742563584309
[Epoch 18, Batch 1300] loss: 0.002884115662233171
[Epoch 18, Batch 1400] loss: 0.003192997349013922
[Epoch 18, Batch 1500] loss: 0.002713662630026192
[Epoch 18, Batch 1600] loss: 0.003701946679152002
[Epoch 18, Batch 1700] loss: 0.009874091590098714
[Epoch 18, Batch 1800] loss: 0.009381215081282335
[Epoch 18, Batch 1900] loss: 0.002296245724095343
[Epoch 18, Batch 2000] loss: 0.00757920999223586
[Epoch 18, Batch 2100] loss: 0.01197945506878682
[Epoch 18, Batch 2200] loss: 0.0034530095623745184
[Epoch 18, Batch 2300] loss: 0.010274021791603331
[Epoch 18, Batch 2400] loss: 0.008324572286970523
[Epoch 18, Batch 2500] loss: 0.007768856005672262
[Epoch 18, Batch 2600] loss: 0.0046739455619223234
[Epoch 18, Batch 2700] loss: 0.011668637528885598
[Epoch 18, Batch 2800] loss: 0.009363949014993125
[Epoch 18, Batch 2900] loss: 0.008808029139520225
[Epoch 18, Batch 3000] loss: 0.009921746531659323
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9872
Overfitting: 0.0524
[Epoch 19, Batch 100] loss: 0.006547084936346437
[Epoch 19, Batch 200] loss: 0.003158662441976503
[Epoch 19, Batch 300] loss: 0.001756887003667771
[Epoch 19, Batch 400] loss: 0.017313792044034812
[Epoch 19, Batch 500] loss: 0.006209585530654067
[Epoch 19, Batch 600] loss: 0.0023062875478834146
[Epoch 19, Batch 700] loss: 0.0028273672724026255
[Epoch 19, Batch 800] loss: 0.0031738468218391346
[Epoch 19, Batch 900] loss: 0.002828712541188736
[Epoch 19, Batch 1000] loss: 0.0017259413617102836
[Epoch 19, Batch 1100] loss: 0.0029338063415190164
[Epoch 19, Batch 1200] loss: 0.002038853591631362
[Epoch 19, Batch 1300] loss: 0.005734830384597558
[Epoch 19, Batch 1400] loss: 0.0031477987463010494
[Epoch 19, Batch 1500] loss: 0.007799923720389152
[Epoch 19, Batch 1600] loss: 0.003090344070101807
[Epoch 19, Batch 1700] loss: 0.0030861182221238437
[Epoch 19, Batch 1800] loss: 0.0026797287584930983
[Epoch 19, Batch 1900] loss: 0.005251710268456833
[Epoch 19, Batch 2000] loss: 0.0010793387991775206
[Epoch 19, Batch 2100] loss: 0.0048883857230970305
[Epoch 19, Batch 2200] loss: 0.0065856884252875145
[Epoch 19, Batch 2300] loss: 0.0135674711945461
[Epoch 19, Batch 2400] loss: 0.0032400446682834174
[Epoch 19, Batch 2500] loss: 0.00764882308087067
[Epoch 19, Batch 2600] loss: 0.0038499223521860416
[Epoch 19, Batch 2700] loss: 0.013195658780694827
[Epoch 19, Batch 2800] loss: 0.006058395445244287
[Epoch 19, Batch 2900] loss: 0.002375112499923944
[Epoch 19, Batch 3000] loss: 0.011113923163157721
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0671
Validation Accuracy: 0.9825
Overfitting: 0.0671
[Epoch 20, Batch 100] loss: 0.01005359117496397
[Epoch 20, Batch 200] loss: 0.007964078203626742
[Epoch 20, Batch 300] loss: 0.0026340958897603174
[Epoch 20, Batch 400] loss: 0.002807059747237872
[Epoch 20, Batch 500] loss: 0.0034930634288595284
[Epoch 20, Batch 600] loss: 0.0015331643296519815
[Epoch 20, Batch 700] loss: 0.0061464117100535984
[Epoch 20, Batch 800] loss: 0.006258759389976803
[Epoch 20, Batch 900] loss: 0.00289137879896316
[Epoch 20, Batch 1000] loss: 0.003769285340682096
[Epoch 20, Batch 1100] loss: 0.0027501073318649105
[Epoch 20, Batch 1200] loss: 0.001310384832576119
[Epoch 20, Batch 1300] loss: 0.003350416007408938
[Epoch 20, Batch 1400] loss: 0.003970447470820204
[Epoch 20, Batch 1500] loss: 0.004592698602831149
[Epoch 20, Batch 1600] loss: 0.007742018451866883
[Epoch 20, Batch 1700] loss: 0.007863378673192969
[Epoch 20, Batch 1800] loss: 0.002752590461711293
[Epoch 20, Batch 1900] loss: 0.0035470986637633926
[Epoch 20, Batch 2000] loss: 0.0033889509747887557
[Epoch 20, Batch 2100] loss: 0.0033162880614008828
[Epoch 20, Batch 2200] loss: 0.006831061428763121
[Epoch 20, Batch 2300] loss: 0.005882985073166083
[Epoch 20, Batch 2400] loss: 0.0036267125560540594
[Epoch 20, Batch 2500] loss: 0.012329070318758895
[Epoch 20, Batch 2600] loss: 0.00726292919043658
[Epoch 20, Batch 2700] loss: 0.007806822542966075
[Epoch 20, Batch 2800] loss: 0.012752460599635924
[Epoch 20, Batch 2900] loss: 0.0064519916225026465
[Epoch 20, Batch 3000] loss: 0.004384209669902361
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9885
Overfitting: 0.0469
[Epoch 21, Batch 100] loss: 0.00316570280681475
[Epoch 21, Batch 200] loss: 0.0027273034011057007
[Epoch 21, Batch 300] loss: 0.0012776385704754035
[Epoch 21, Batch 400] loss: 0.004482758551370694
[Epoch 21, Batch 500] loss: 0.005483119187915974
[Epoch 21, Batch 600] loss: 0.006058542660967134
[Epoch 21, Batch 700] loss: 0.009328329988487382
[Epoch 21, Batch 800] loss: 0.003046907811716579
[Epoch 21, Batch 900] loss: 0.002424954762439029
[Epoch 21, Batch 1000] loss: 0.001691883241518326
[Epoch 21, Batch 1100] loss: 0.0009477190530162716
[Epoch 21, Batch 1200] loss: 0.00451739464755704
[Epoch 21, Batch 1300] loss: 0.003696459631739515
[Epoch 21, Batch 1400] loss: 0.0031741243030131727
[Epoch 21, Batch 1500] loss: 0.003549921078382461
[Epoch 21, Batch 1600] loss: 0.00427248004172327
[Epoch 21, Batch 1700] loss: 0.0047529631815280025
[Epoch 21, Batch 1800] loss: 0.005126545122435289
[Epoch 21, Batch 1900] loss: 0.003397924921553681
[Epoch 21, Batch 2000] loss: 0.0043588810608539315
[Epoch 21, Batch 2100] loss: 0.0015942575484471178
[Epoch 21, Batch 2200] loss: 0.0013532803728514863
[Epoch 21, Batch 2300] loss: 0.006511404789757194
[Epoch 21, Batch 2400] loss: 0.0023393594186647704
[Epoch 21, Batch 2500] loss: 0.003614588306713529
[Epoch 21, Batch 2600] loss: 0.004212080425645013
[Epoch 21, Batch 2700] loss: 0.003834829026559987
[Epoch 21, Batch 2800] loss: 0.007275664472118848
[Epoch 21, Batch 2900] loss: 0.015422696160979967
[Epoch 21, Batch 3000] loss: 0.008942867274344195
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0637
Validation Accuracy: 0.9852
Overfitting: 0.0637
[Epoch 22, Batch 100] loss: 0.005303135478332024
[Epoch 22, Batch 200] loss: 0.00466076513801454
[Epoch 22, Batch 300] loss: 0.002349715559334413
[Epoch 22, Batch 400] loss: 0.00261924148580448
[Epoch 22, Batch 500] loss: 0.005818627073708171
[Epoch 22, Batch 600] loss: 0.0013067416759807316
[Epoch 22, Batch 700] loss: 0.005130611007460857
[Epoch 22, Batch 800] loss: 0.003135936523935605
[Epoch 22, Batch 900] loss: 0.004208941370711728
[Epoch 22, Batch 1000] loss: 0.008887476316409036
[Epoch 22, Batch 1100] loss: 0.023438314608362116
[Epoch 22, Batch 1200] loss: 0.0107157199744573
[Epoch 22, Batch 1300] loss: 0.008605280587374437
[Epoch 22, Batch 1400] loss: 0.0039161102371383545
[Epoch 22, Batch 1500] loss: 0.005531740145311091
[Epoch 22, Batch 1600] loss: 0.0019015485403332377
[Epoch 22, Batch 1700] loss: 0.005033032784245677
[Epoch 22, Batch 1800] loss: 0.0022139024242233065
[Epoch 22, Batch 1900] loss: 0.006096102543379516
[Epoch 22, Batch 2000] loss: 0.004273701854410774
[Epoch 22, Batch 2100] loss: 0.0029723284399200624
[Epoch 22, Batch 2200] loss: 0.003096978779334094
[Epoch 22, Batch 2300] loss: 0.001922150161656333
[Epoch 22, Batch 2400] loss: 0.005812360053437899
[Epoch 22, Batch 2500] loss: 0.006000028667890262
[Epoch 22, Batch 2600] loss: 0.010356056464942184
[Epoch 22, Batch 2700] loss: 0.0030698823396119223
[Epoch 22, Batch 2800] loss: 0.002352589313713338
[Epoch 22, Batch 2900] loss: 0.0032395681376148388
[Epoch 22, Batch 3000] loss: 0.0025171925882082747
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9882
Overfitting: 0.0514
[Epoch 23, Batch 100] loss: 0.0029109234633884285
[Epoch 23, Batch 200] loss: 0.001314891642806515
[Epoch 23, Batch 300] loss: 0.0054405799179410505
[Epoch 23, Batch 400] loss: 0.003307739692186118
[Epoch 23, Batch 500] loss: 0.0015810588288130134
[Epoch 23, Batch 600] loss: 0.001300203925380501
[Epoch 23, Batch 700] loss: 0.0014222214000301392
[Epoch 23, Batch 800] loss: 0.001367928457351013
[Epoch 23, Batch 900] loss: 0.001759719405027056
[Epoch 23, Batch 1000] loss: 0.005623531367820221
[Epoch 23, Batch 1100] loss: 0.0023864743408415733
[Epoch 23, Batch 1200] loss: 0.006130498472793331
[Epoch 23, Batch 1300] loss: 0.0054070809022731935
[Epoch 23, Batch 1400] loss: 0.0027484742074835467
[Epoch 23, Batch 1500] loss: 0.005087372815348985
[Epoch 23, Batch 1600] loss: 0.0029735762075679874
[Epoch 23, Batch 1700] loss: 0.001962802162428545
[Epoch 23, Batch 1800] loss: 0.002049072181435605
[Epoch 23, Batch 1900] loss: 0.0011752328090264541
[Epoch 23, Batch 2000] loss: 0.00361974777747335
[Epoch 23, Batch 2100] loss: 0.0033831512182074166
[Epoch 23, Batch 2200] loss: 0.00506076947126676
[Epoch 23, Batch 2300] loss: 0.005186562577302425
[Epoch 23, Batch 2400] loss: 0.0036283286676723494
[Epoch 23, Batch 2500] loss: 0.0011769352086195184
[Epoch 23, Batch 2600] loss: 0.008292154176129704
[Epoch 23, Batch 2700] loss: 0.003094587089109062
[Epoch 23, Batch 2800] loss: 0.004366616652726325
[Epoch 23, Batch 2900] loss: 0.002385839384453163
[Epoch 23, Batch 3000] loss: 0.00419684198630435
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9883
Overfitting: 0.0500
[Epoch 24, Batch 100] loss: 0.0036178794823989334
[Epoch 24, Batch 200] loss: 0.002044732039543362
[Epoch 24, Batch 300] loss: 0.0041933612230730995
[Epoch 24, Batch 400] loss: 0.0029450217823879
[Epoch 24, Batch 500] loss: 0.0010131628401727254
[Epoch 24, Batch 600] loss: 0.0010218872449154048
[Epoch 24, Batch 700] loss: 0.0004296992489556217
[Epoch 24, Batch 800] loss: 0.0008392285152029854
[Epoch 24, Batch 900] loss: 0.0005232302099598307
[Epoch 24, Batch 1000] loss: 0.0008768842948807443
[Epoch 24, Batch 1100] loss: 0.00044070011750584114
[Epoch 24, Batch 1200] loss: 0.001147534438933775
[Epoch 24, Batch 1300] loss: 0.0030052803643216917
[Epoch 24, Batch 1400] loss: 0.0013463925970518887
[Epoch 24, Batch 1500] loss: 0.0010981661702645252
[Epoch 24, Batch 1600] loss: 0.0009075958272656237
[Epoch 24, Batch 1700] loss: 0.0016375231652829036
[Epoch 24, Batch 1800] loss: 0.004456799785782941
[Epoch 24, Batch 1900] loss: 0.0027801285936879336
[Epoch 24, Batch 2000] loss: 0.001333904802840209
[Epoch 24, Batch 2100] loss: 0.0022705339830957883
[Epoch 24, Batch 2200] loss: 0.0024675284426665554
[Epoch 24, Batch 2300] loss: 0.0019674800464933462
[Epoch 24, Batch 2400] loss: 0.0006239281724468349
[Epoch 24, Batch 2500] loss: 0.0009035623351042688
[Epoch 24, Batch 2600] loss: 0.0005184108818403388
[Epoch 24, Batch 2700] loss: 0.0011816255504265882
[Epoch 24, Batch 2800] loss: 0.0007534511613178507
[Epoch 24, Batch 2900] loss: 0.0011319937458902985
[Epoch 24, Batch 3000] loss: 0.00479724470882303
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9873
Overfitting: 0.0576
Fold 4 validation loss: 0.0576
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2892583799362183
[Epoch 1, Batch 200] loss: 2.211584753990173
[Epoch 1, Batch 300] loss: 1.717464474439621
[Epoch 1, Batch 400] loss: 0.7765086600184441
[Epoch 1, Batch 500] loss: 0.4919599002599716
[Epoch 1, Batch 600] loss: 0.445558607801795
[Epoch 1, Batch 700] loss: 0.3814454273506999
[Epoch 1, Batch 800] loss: 0.36007343113422396
[Epoch 1, Batch 900] loss: 0.30720937497913836
[Epoch 1, Batch 1000] loss: 0.29969395460560916
[Epoch 1, Batch 1100] loss: 0.2974955344945192
[Epoch 1, Batch 1200] loss: 0.21631386891007423
[Epoch 1, Batch 1300] loss: 0.2026209751330316
[Epoch 1, Batch 1400] loss: 0.19218398228287698
[Epoch 1, Batch 1500] loss: 0.19878591087646783
[Epoch 1, Batch 1600] loss: 0.20468042344786228
[Epoch 1, Batch 1700] loss: 0.17715288987383246
[Epoch 1, Batch 1800] loss: 0.20213777936063707
[Epoch 1, Batch 1900] loss: 0.155402761856094
[Epoch 1, Batch 2000] loss: 0.2042260759882629
[Epoch 1, Batch 2100] loss: 0.15580095417797565
[Epoch 1, Batch 2200] loss: 0.1528144715167582
[Epoch 1, Batch 2300] loss: 0.1570664141792804
[Epoch 1, Batch 2400] loss: 0.15731337044853716
[Epoch 1, Batch 2500] loss: 0.1427397418860346
[Epoch 1, Batch 2600] loss: 0.1471910609258339
[Epoch 1, Batch 2700] loss: 0.15562716642627492
[Epoch 1, Batch 2800] loss: 0.15588999160099776
[Epoch 1, Batch 2900] loss: 0.14355185551103206
[Epoch 1, Batch 3000] loss: 0.12508115223143249
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1153
Validation Accuracy: 0.9658
Overfitting: 0.1153
Best model saved at epoch 1 with validation loss: 0.1153
[Epoch 2, Batch 100] loss: 0.10401982040144503
[Epoch 2, Batch 200] loss: 0.08646290095988661
[Epoch 2, Batch 300] loss: 0.12106457548914477
[Epoch 2, Batch 400] loss: 0.10722860909299925
[Epoch 2, Batch 500] loss: 0.09230479524703697
[Epoch 2, Batch 600] loss: 0.09213418032508343
[Epoch 2, Batch 700] loss: 0.11146469241240993
[Epoch 2, Batch 800] loss: 0.10576569484430365
[Epoch 2, Batch 900] loss: 0.07841780100716278
[Epoch 2, Batch 1000] loss: 0.08650761586963199
[Epoch 2, Batch 1100] loss: 0.11951984122162684
[Epoch 2, Batch 1200] loss: 0.1144699299405329
[Epoch 2, Batch 1300] loss: 0.07889029593672603
[Epoch 2, Batch 1400] loss: 0.12433880931697786
[Epoch 2, Batch 1500] loss: 0.0924903151334729
[Epoch 2, Batch 1600] loss: 0.12542067573871463
[Epoch 2, Batch 1700] loss: 0.09387688228162006
[Epoch 2, Batch 1800] loss: 0.10271010943572037
[Epoch 2, Batch 1900] loss: 0.08681909713428468
[Epoch 2, Batch 2000] loss: 0.07316076045943191
[Epoch 2, Batch 2100] loss: 0.08532507875119336
[Epoch 2, Batch 2200] loss: 0.08264335628366098
[Epoch 2, Batch 2300] loss: 0.0777240726177115
[Epoch 2, Batch 2400] loss: 0.08838594796019607
[Epoch 2, Batch 2500] loss: 0.08497256728936918
[Epoch 2, Batch 2600] loss: 0.08388005753047764
[Epoch 2, Batch 2700] loss: 0.09521938263904303
[Epoch 2, Batch 2800] loss: 0.07028848682297394
[Epoch 2, Batch 2900] loss: 0.07991335670929402
[Epoch 2, Batch 3000] loss: 0.08461534142727033
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0866
Validation Accuracy: 0.9728
Overfitting: 0.0866
Best model saved at epoch 2 with validation loss: 0.0866
[Epoch 3, Batch 100] loss: 0.07920772493293043
[Epoch 3, Batch 200] loss: 0.06735300148138776
[Epoch 3, Batch 300] loss: 0.09448358355439268
[Epoch 3, Batch 400] loss: 0.06166829622699879
[Epoch 3, Batch 500] loss: 0.05823446048219921
[Epoch 3, Batch 600] loss: 0.08159479980473407
[Epoch 3, Batch 700] loss: 0.050667089935741386
[Epoch 3, Batch 800] loss: 0.07805982787627727
[Epoch 3, Batch 900] loss: 0.06157525826653
[Epoch 3, Batch 1000] loss: 0.07321570804808289
[Epoch 3, Batch 1100] loss: 0.07962648694170639
[Epoch 3, Batch 1200] loss: 0.05879662820603698
[Epoch 3, Batch 1300] loss: 0.07391444219334517
[Epoch 3, Batch 1400] loss: 0.06967892571468838
[Epoch 3, Batch 1500] loss: 0.06548774494614917
[Epoch 3, Batch 1600] loss: 0.061151169451186434
[Epoch 3, Batch 1700] loss: 0.06247051944141276
[Epoch 3, Batch 1800] loss: 0.06290598714986118
[Epoch 3, Batch 1900] loss: 0.06917917276063236
[Epoch 3, Batch 2000] loss: 0.0597278384945821
[Epoch 3, Batch 2100] loss: 0.05340723988309037
[Epoch 3, Batch 2200] loss: 0.0480150025972398
[Epoch 3, Batch 2300] loss: 0.06350664561265149
[Epoch 3, Batch 2400] loss: 0.05605239047552459
[Epoch 3, Batch 2500] loss: 0.06270939240872395
[Epoch 3, Batch 2600] loss: 0.05658727088739397
[Epoch 3, Batch 2700] loss: 0.08094142181740609
[Epoch 3, Batch 2800] loss: 0.0651687255280558
[Epoch 3, Batch 2900] loss: 0.046355892064748334
[Epoch 3, Batch 3000] loss: 0.0568711433748831
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0595
Validation Accuracy: 0.9810
Overfitting: 0.0595
Best model saved at epoch 3 with validation loss: 0.0595
[Epoch 4, Batch 100] loss: 0.04644712617096957
[Epoch 4, Batch 200] loss: 0.04676158136426238
[Epoch 4, Batch 300] loss: 0.05008776135277003
[Epoch 4, Batch 400] loss: 0.044323845601757055
[Epoch 4, Batch 500] loss: 0.04065948746458162
[Epoch 4, Batch 600] loss: 0.051976155935262794
[Epoch 4, Batch 700] loss: 0.04540110833971994
[Epoch 4, Batch 800] loss: 0.05740918143041199
[Epoch 4, Batch 900] loss: 0.06076886493145139
[Epoch 4, Batch 1000] loss: 0.06658778066339437
[Epoch 4, Batch 1100] loss: 0.0391932241350878
[Epoch 4, Batch 1200] loss: 0.058480675796745346
[Epoch 4, Batch 1300] loss: 0.04280907045525964
[Epoch 4, Batch 1400] loss: 0.06089856210630387
[Epoch 4, Batch 1500] loss: 0.0420812878178549
[Epoch 4, Batch 1600] loss: 0.0472804018453462
[Epoch 4, Batch 1700] loss: 0.04828734384151176
[Epoch 4, Batch 1800] loss: 0.04677678914013086
[Epoch 4, Batch 1900] loss: 0.07307926931447582
[Epoch 4, Batch 2000] loss: 0.04216038677142933
[Epoch 4, Batch 2100] loss: 0.048948088015895334
[Epoch 4, Batch 2200] loss: 0.0479953262572235
[Epoch 4, Batch 2300] loss: 0.05762209824490128
[Epoch 4, Batch 2400] loss: 0.04542486452759476
[Epoch 4, Batch 2500] loss: 0.06575115658575668
[Epoch 4, Batch 2600] loss: 0.047498789558012504
[Epoch 4, Batch 2700] loss: 0.05601201981509803
[Epoch 4, Batch 2800] loss: 0.0658413076303259
[Epoch 4, Batch 2900] loss: 0.03754771576554049
[Epoch 4, Batch 3000] loss: 0.048206145783769895
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9820
Overfitting: 0.0520
Best model saved at epoch 4 with validation loss: 0.0520
[Epoch 5, Batch 100] loss: 0.03809056985104689
[Epoch 5, Batch 200] loss: 0.03154934776801383
[Epoch 5, Batch 300] loss: 0.04710405686404556
[Epoch 5, Batch 400] loss: 0.04568149163009366
[Epoch 5, Batch 500] loss: 0.04062207647337345
[Epoch 5, Batch 600] loss: 0.033198177614976884
[Epoch 5, Batch 700] loss: 0.04356056017975789
[Epoch 5, Batch 800] loss: 0.03952960430338862
[Epoch 5, Batch 900] loss: 0.040657164917574845
[Epoch 5, Batch 1000] loss: 0.04663559297274333
[Epoch 5, Batch 1100] loss: 0.0409682749141939
[Epoch 5, Batch 1200] loss: 0.03889513565329253
[Epoch 5, Batch 1300] loss: 0.03425455896503991
[Epoch 5, Batch 1400] loss: 0.04781060012057423
[Epoch 5, Batch 1500] loss: 0.0314892467368918
[Epoch 5, Batch 1600] loss: 0.044962057935772466
[Epoch 5, Batch 1700] loss: 0.046963676908490015
[Epoch 5, Batch 1800] loss: 0.04167257260371116
[Epoch 5, Batch 1900] loss: 0.05188243857352063
[Epoch 5, Batch 2000] loss: 0.04523646192319575
[Epoch 5, Batch 2100] loss: 0.03779679635263165
[Epoch 5, Batch 2200] loss: 0.03563749013250345
[Epoch 5, Batch 2300] loss: 0.03884420575435797
[Epoch 5, Batch 2400] loss: 0.037513530302385335
[Epoch 5, Batch 2500] loss: 0.04206832482392201
[Epoch 5, Batch 2600] loss: 0.06668810693081469
[Epoch 5, Batch 2700] loss: 0.04705397287500091
[Epoch 5, Batch 2800] loss: 0.03709879892296158
[Epoch 5, Batch 2900] loss: 0.02939394685206935
[Epoch 5, Batch 3000] loss: 0.03156796667855815
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9834
Overfitting: 0.0494
Best model saved at epoch 5 with validation loss: 0.0494
[Epoch 6, Batch 100] loss: 0.03811515580164269
[Epoch 6, Batch 200] loss: 0.023259048080071808
[Epoch 6, Batch 300] loss: 0.01447016487334622
[Epoch 6, Batch 400] loss: 0.03706963898308459
[Epoch 6, Batch 500] loss: 0.03675966537761269
[Epoch 6, Batch 600] loss: 0.022523478537623307
[Epoch 6, Batch 700] loss: 0.045313087741233174
[Epoch 6, Batch 800] loss: 0.025367985326302005
[Epoch 6, Batch 900] loss: 0.04085197113789036
[Epoch 6, Batch 1000] loss: 0.028745265813631703
[Epoch 6, Batch 1100] loss: 0.02421560214381316
[Epoch 6, Batch 1200] loss: 0.026938710444956087
[Epoch 6, Batch 1300] loss: 0.0396866580886126
[Epoch 6, Batch 1400] loss: 0.029902071277247158
[Epoch 6, Batch 1500] loss: 0.035858895650344495
[Epoch 6, Batch 1600] loss: 0.026401588633307257
[Epoch 6, Batch 1700] loss: 0.045249268898551236
[Epoch 6, Batch 1800] loss: 0.04185457329134806
[Epoch 6, Batch 1900] loss: 0.03833807062641426
[Epoch 6, Batch 2000] loss: 0.040528402567542796
[Epoch 6, Batch 2100] loss: 0.041616087811416944
[Epoch 6, Batch 2200] loss: 0.039498167283745715
[Epoch 6, Batch 2300] loss: 0.028407772180216853
[Epoch 6, Batch 2400] loss: 0.02718524344250909
[Epoch 6, Batch 2500] loss: 0.043217265679559205
[Epoch 6, Batch 2600] loss: 0.03805594517318241
[Epoch 6, Batch 2700] loss: 0.034668980408314384
[Epoch 6, Batch 2800] loss: 0.04338835093964008
[Epoch 6, Batch 2900] loss: 0.038383760044525844
[Epoch 6, Batch 3000] loss: 0.022902854398853378
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9851
Overfitting: 0.0462
Best model saved at epoch 6 with validation loss: 0.0462
[Epoch 7, Batch 100] loss: 0.024162020079165812
[Epoch 7, Batch 200] loss: 0.030138800466957036
[Epoch 7, Batch 300] loss: 0.04050177020893898
[Epoch 7, Batch 400] loss: 0.02633587793156039
[Epoch 7, Batch 500] loss: 0.02716649245005101
[Epoch 7, Batch 600] loss: 0.027366653060453244
[Epoch 7, Batch 700] loss: 0.02028023369581206
[Epoch 7, Batch 800] loss: 0.01643836214178009
[Epoch 7, Batch 900] loss: 0.023780607851840614
[Epoch 7, Batch 1000] loss: 0.013568544771733287
[Epoch 7, Batch 1100] loss: 0.022877889324736316
[Epoch 7, Batch 1200] loss: 0.018294696660632326
[Epoch 7, Batch 1300] loss: 0.026319979252029953
[Epoch 7, Batch 1400] loss: 0.03823034276800172
[Epoch 7, Batch 1500] loss: 0.01745633309255936
[Epoch 7, Batch 1600] loss: 0.020506715166120557
[Epoch 7, Batch 1700] loss: 0.03852029253903311
[Epoch 7, Batch 1800] loss: 0.02661398314048711
[Epoch 7, Batch 1900] loss: 0.03828665342694876
[Epoch 7, Batch 2000] loss: 0.03161628429123084
[Epoch 7, Batch 2100] loss: 0.024235921126819448
[Epoch 7, Batch 2200] loss: 0.04385566424010903
[Epoch 7, Batch 2300] loss: 0.03479898339883221
[Epoch 7, Batch 2400] loss: 0.031443419118804744
[Epoch 7, Batch 2500] loss: 0.017867449822151684
[Epoch 7, Batch 2600] loss: 0.04243570941544021
[Epoch 7, Batch 2700] loss: 0.03534810051187378
[Epoch 7, Batch 2800] loss: 0.029997201247861083
[Epoch 7, Batch 2900] loss: 0.032444466496090174
[Epoch 7, Batch 3000] loss: 0.02996139788730943
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9841
Overfitting: 0.0499
[Epoch 8, Batch 100] loss: 0.02471546588356432
[Epoch 8, Batch 200] loss: 0.032155905850522686
[Epoch 8, Batch 300] loss: 0.022509963524098568
[Epoch 8, Batch 400] loss: 0.019725752177000688
[Epoch 8, Batch 500] loss: 0.022528922921101185
[Epoch 8, Batch 600] loss: 0.013808053315078722
[Epoch 8, Batch 700] loss: 0.03665058007951302
[Epoch 8, Batch 800] loss: 0.02062562279355916
[Epoch 8, Batch 900] loss: 0.014207821656673331
[Epoch 8, Batch 1000] loss: 0.027366017514723354
[Epoch 8, Batch 1100] loss: 0.03198684887877789
[Epoch 8, Batch 1200] loss: 0.025064053394489746
[Epoch 8, Batch 1300] loss: 0.01950988524180502
[Epoch 8, Batch 1400] loss: 0.01289583303303516
[Epoch 8, Batch 1500] loss: 0.018702809878159313
[Epoch 8, Batch 1600] loss: 0.027586079589855216
[Epoch 8, Batch 1700] loss: 0.025351397567637834
[Epoch 8, Batch 1800] loss: 0.027440514505724423
[Epoch 8, Batch 1900] loss: 0.015804709243275282
[Epoch 8, Batch 2000] loss: 0.02064519956129516
[Epoch 8, Batch 2100] loss: 0.03509729047098517
[Epoch 8, Batch 2200] loss: 0.022344489741044526
[Epoch 8, Batch 2300] loss: 0.030974698110949248
[Epoch 8, Batch 2400] loss: 0.035661022641288585
[Epoch 8, Batch 2500] loss: 0.016787396643485407
[Epoch 8, Batch 2600] loss: 0.03011875453488756
[Epoch 8, Batch 2700] loss: 0.03044407635079551
[Epoch 8, Batch 2800] loss: 0.039638993205226146
[Epoch 8, Batch 2900] loss: 0.030486090065096505
[Epoch 8, Batch 3000] loss: 0.02133313356680446
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0415
Validation Accuracy: 0.9866
Overfitting: 0.0415
Best model saved at epoch 8 with validation loss: 0.0415
[Epoch 9, Batch 100] loss: 0.015509996983673772
[Epoch 9, Batch 200] loss: 0.014807193907472538
[Epoch 9, Batch 300] loss: 0.009235026669666696
[Epoch 9, Batch 400] loss: 0.023740071373831596
[Epoch 9, Batch 500] loss: 0.016986678264383954
[Epoch 9, Batch 600] loss: 0.022747683807301654
[Epoch 9, Batch 700] loss: 0.016642311192190392
[Epoch 9, Batch 800] loss: 0.01730850395604648
[Epoch 9, Batch 900] loss: 0.013386536319230799
[Epoch 9, Batch 1000] loss: 0.015055743925186106
[Epoch 9, Batch 1100] loss: 0.027905183692528226
[Epoch 9, Batch 1200] loss: 0.03096048657896972
[Epoch 9, Batch 1300] loss: 0.028721189871357636
[Epoch 9, Batch 1400] loss: 0.027706407892947028
[Epoch 9, Batch 1500] loss: 0.02636591037549806
[Epoch 9, Batch 1600] loss: 0.0156493290684557
[Epoch 9, Batch 1700] loss: 0.03298498916960853
[Epoch 9, Batch 1800] loss: 0.02793463507456181
[Epoch 9, Batch 1900] loss: 0.02852478922017326
[Epoch 9, Batch 2000] loss: 0.018592424385569756
[Epoch 9, Batch 2100] loss: 0.021142494651139713
[Epoch 9, Batch 2200] loss: 0.022694717420235974
[Epoch 9, Batch 2300] loss: 0.013914706710274914
[Epoch 9, Batch 2400] loss: 0.016245976787231484
[Epoch 9, Batch 2500] loss: 0.023348817436526587
[Epoch 9, Batch 2600] loss: 0.01619872631134058
[Epoch 9, Batch 2700] loss: 0.01275218482343007
[Epoch 9, Batch 2800] loss: 0.04164630318045966
[Epoch 9, Batch 2900] loss: 0.020378690811776325
[Epoch 9, Batch 3000] loss: 0.022038217956524022
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0448
Validation Accuracy: 0.9861
Overfitting: 0.0448
[Epoch 10, Batch 100] loss: 0.01844307678156838
[Epoch 10, Batch 200] loss: 0.016576504122385812
[Epoch 10, Batch 300] loss: 0.014156842289285123
[Epoch 10, Batch 400] loss: 0.01758794705768196
[Epoch 10, Batch 500] loss: 0.019012080097099898
[Epoch 10, Batch 600] loss: 0.017493377393911942
[Epoch 10, Batch 700] loss: 0.015105080837174682
[Epoch 10, Batch 800] loss: 0.022314803103718077
[Epoch 10, Batch 900] loss: 0.016341781458959304
[Epoch 10, Batch 1000] loss: 0.024783694803581967
[Epoch 10, Batch 1100] loss: 0.016453087703412167
[Epoch 10, Batch 1200] loss: 0.016378136783405352
[Epoch 10, Batch 1300] loss: 0.015897046313493774
[Epoch 10, Batch 1400] loss: 0.0272423189458641
[Epoch 10, Batch 1500] loss: 0.01658082999925682
[Epoch 10, Batch 1600] loss: 0.033517635564494414
[Epoch 10, Batch 1700] loss: 0.02248627160963224
[Epoch 10, Batch 1800] loss: 0.012820157719870622
[Epoch 10, Batch 1900] loss: 0.010884489550626313
[Epoch 10, Batch 2000] loss: 0.014214599452952826
[Epoch 10, Batch 2100] loss: 0.013114456887396955
[Epoch 10, Batch 2200] loss: 0.011767112205970988
[Epoch 10, Batch 2300] loss: 0.013566603578290141
[Epoch 10, Batch 2400] loss: 0.016648103858497052
[Epoch 10, Batch 2500] loss: 0.019581845090006027
[Epoch 10, Batch 2600] loss: 0.02484686521547701
[Epoch 10, Batch 2700] loss: 0.03427307592626676
[Epoch 10, Batch 2800] loss: 0.019683347067129944
[Epoch 10, Batch 2900] loss: 0.0104866994405711
[Epoch 10, Batch 3000] loss: 0.015730902817335846
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0377
Validation Accuracy: 0.9882
Overfitting: 0.0377
Best model saved at epoch 10 with validation loss: 0.0377
[Epoch 11, Batch 100] loss: 0.017906820137807245
[Epoch 11, Batch 200] loss: 0.012670016287156614
[Epoch 11, Batch 300] loss: 0.015499186100660154
[Epoch 11, Batch 400] loss: 0.0187188593350038
[Epoch 11, Batch 500] loss: 0.019714233973381852
[Epoch 11, Batch 600] loss: 0.011017994183948759
[Epoch 11, Batch 700] loss: 0.012124013724769612
[Epoch 11, Batch 800] loss: 0.005529264325032273
[Epoch 11, Batch 900] loss: 0.006560742609444788
[Epoch 11, Batch 1000] loss: 0.016341615040932993
[Epoch 11, Batch 1100] loss: 0.011322643870480533
[Epoch 11, Batch 1200] loss: 0.018186227945097926
[Epoch 11, Batch 1300] loss: 0.021154016352129476
[Epoch 11, Batch 1400] loss: 0.011347053889949166
[Epoch 11, Batch 1500] loss: 0.01794281834031153
[Epoch 11, Batch 1600] loss: 0.013637081267588655
[Epoch 11, Batch 1700] loss: 0.022425391409765325
[Epoch 11, Batch 1800] loss: 0.011983799760100737
[Epoch 11, Batch 1900] loss: 0.02069901133467283
[Epoch 11, Batch 2000] loss: 0.022767576786354767
[Epoch 11, Batch 2100] loss: 0.012670994371774214
[Epoch 11, Batch 2200] loss: 0.012571177377649291
[Epoch 11, Batch 2300] loss: 0.012031361488243419
[Epoch 11, Batch 2400] loss: 0.01984384102313925
[Epoch 11, Batch 2500] loss: 0.022514834411576885
[Epoch 11, Batch 2600] loss: 0.01625956229185249
[Epoch 11, Batch 2700] loss: 0.010541524175278028
[Epoch 11, Batch 2800] loss: 0.016494483685492015
[Epoch 11, Batch 2900] loss: 0.01900413163374651
[Epoch 11, Batch 3000] loss: 0.01844980900266819
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0421
Validation Accuracy: 0.9881
Overfitting: 0.0421
[Epoch 12, Batch 100] loss: 0.01568133178034486
[Epoch 12, Batch 200] loss: 0.004910368822056626
[Epoch 12, Batch 300] loss: 0.018767150483345176
[Epoch 12, Batch 400] loss: 0.006784889342225142
[Epoch 12, Batch 500] loss: 0.007485671982467465
[Epoch 12, Batch 600] loss: 0.011675824306512367
[Epoch 12, Batch 700] loss: 0.0034322537698517406
[Epoch 12, Batch 800] loss: 0.006137393853359754
[Epoch 12, Batch 900] loss: 0.013099327841364356
[Epoch 12, Batch 1000] loss: 0.00464155286876121
[Epoch 12, Batch 1100] loss: 0.008840363846256877
[Epoch 12, Batch 1200] loss: 0.024966260811070243
[Epoch 12, Batch 1300] loss: 0.014828750401052275
[Epoch 12, Batch 1400] loss: 0.010681888161416282
[Epoch 12, Batch 1500] loss: 0.006929397875460382
[Epoch 12, Batch 1600] loss: 0.01598570686523544
[Epoch 12, Batch 1700] loss: 0.016497003748095266
[Epoch 12, Batch 1800] loss: 0.02039025722348697
[Epoch 12, Batch 1900] loss: 0.023688089847300944
[Epoch 12, Batch 2000] loss: 0.015428559318952467
[Epoch 12, Batch 2100] loss: 0.012666924451878003
[Epoch 12, Batch 2200] loss: 0.01946501993917991
[Epoch 12, Batch 2300] loss: 0.023940179841811186
[Epoch 12, Batch 2400] loss: 0.017599132963778175
[Epoch 12, Batch 2500] loss: 0.013323752865007919
[Epoch 12, Batch 2600] loss: 0.019803702169069765
[Epoch 12, Batch 2700] loss: 0.017629997494977942
[Epoch 12, Batch 2800] loss: 0.011303454621129276
[Epoch 12, Batch 2900] loss: 0.013952027771229041
[Epoch 12, Batch 3000] loss: 0.018908759044516044
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9859
Overfitting: 0.0489
[Epoch 13, Batch 100] loss: 0.008253803560946835
[Epoch 13, Batch 200] loss: 0.005687684556214663
[Epoch 13, Batch 300] loss: 0.004540842135320418
[Epoch 13, Batch 400] loss: 0.010222560189267824
[Epoch 13, Batch 500] loss: 0.006972225351337329
[Epoch 13, Batch 600] loss: 0.0064794221635429495
[Epoch 13, Batch 700] loss: 0.006969661314210498
[Epoch 13, Batch 800] loss: 0.01296893004339836
[Epoch 13, Batch 900] loss: 0.004587083654851085
[Epoch 13, Batch 1000] loss: 0.006481163388989444
[Epoch 13, Batch 1100] loss: 0.01127949263084929
[Epoch 13, Batch 1200] loss: 0.009419127772907814
[Epoch 13, Batch 1300] loss: 0.009633135052622492
[Epoch 13, Batch 1400] loss: 0.0105121362534328
[Epoch 13, Batch 1500] loss: 0.0066635902012876615
[Epoch 13, Batch 1600] loss: 0.0185387993568429
[Epoch 13, Batch 1700] loss: 0.012748729026563979
[Epoch 13, Batch 1800] loss: 0.016820788412792352
[Epoch 13, Batch 1900] loss: 0.009653658026045377
[Epoch 13, Batch 2000] loss: 0.01356089915823759
[Epoch 13, Batch 2100] loss: 0.010910257320692835
[Epoch 13, Batch 2200] loss: 0.014345736881459743
[Epoch 13, Batch 2300] loss: 0.009332702182687171
[Epoch 13, Batch 2400] loss: 0.009824965840534787
[Epoch 13, Batch 2500] loss: 0.015099860759132753
[Epoch 13, Batch 2600] loss: 0.0062509002479419
[Epoch 13, Batch 2700] loss: 0.020957789516432967
[Epoch 13, Batch 2800] loss: 0.018159415735963195
[Epoch 13, Batch 2900] loss: 0.007132081861582265
[Epoch 13, Batch 3000] loss: 0.016583434706672052
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0448
Validation Accuracy: 0.9874
Overfitting: 0.0448
[Epoch 14, Batch 100] loss: 0.017055336410676317
[Epoch 14, Batch 200] loss: 0.012954227355808144
[Epoch 14, Batch 300] loss: 0.004742534702063495
[Epoch 14, Batch 400] loss: 0.004500266214427029
[Epoch 14, Batch 500] loss: 0.004018654954656995
[Epoch 14, Batch 600] loss: 0.013524769096954402
[Epoch 14, Batch 700] loss: 0.004750145285320286
[Epoch 14, Batch 800] loss: 0.007998536981122016
[Epoch 14, Batch 900] loss: 0.010188699842356073
[Epoch 14, Batch 1000] loss: 0.00891917090665629
[Epoch 14, Batch 1100] loss: 0.008947039465638226
[Epoch 14, Batch 1200] loss: 0.0090280111629977
[Epoch 14, Batch 1300] loss: 0.005289958936863286
[Epoch 14, Batch 1400] loss: 0.014504934381884596
[Epoch 14, Batch 1500] loss: 0.011557818809535547
[Epoch 14, Batch 1600] loss: 0.00874458744692788
[Epoch 14, Batch 1700] loss: 0.020586623396694106
[Epoch 14, Batch 1800] loss: 0.012463317761103099
[Epoch 14, Batch 1900] loss: 0.011883254650570052
[Epoch 14, Batch 2000] loss: 0.004486138276529345
[Epoch 14, Batch 2100] loss: 0.012818132590764435
[Epoch 14, Batch 2200] loss: 0.0064696872811180126
[Epoch 14, Batch 2300] loss: 0.007059230293702967
[Epoch 14, Batch 2400] loss: 0.01111919396693338
[Epoch 14, Batch 2500] loss: 0.011871732416020677
[Epoch 14, Batch 2600] loss: 0.009034305895665966
[Epoch 14, Batch 2700] loss: 0.004160397791320065
[Epoch 14, Batch 2800] loss: 0.011062306299031661
[Epoch 14, Batch 2900] loss: 0.0169887062454427
[Epoch 14, Batch 3000] loss: 0.005718397477107828
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0429
Validation Accuracy: 0.9886
Overfitting: 0.0429
[Epoch 15, Batch 100] loss: 0.005689008375131834
[Epoch 15, Batch 200] loss: 0.010896683809605748
[Epoch 15, Batch 300] loss: 0.009141535713696384
[Epoch 15, Batch 400] loss: 0.004603242773025613
[Epoch 15, Batch 500] loss: 0.01038768047975509
[Epoch 15, Batch 600] loss: 0.02180236166125269
[Epoch 15, Batch 700] loss: 0.01774417437558441
[Epoch 15, Batch 800] loss: 0.010772177351045685
[Epoch 15, Batch 900] loss: 0.009017529701154672
[Epoch 15, Batch 1000] loss: 0.008795998615310054
[Epoch 15, Batch 1100] loss: 0.006170547102042292
[Epoch 15, Batch 1200] loss: 0.0097709684879419
[Epoch 15, Batch 1300] loss: 0.007876525661772575
[Epoch 15, Batch 1400] loss: 0.010055402060597771
[Epoch 15, Batch 1500] loss: 0.006866626107857883
[Epoch 15, Batch 1600] loss: 0.009763446641140944
[Epoch 15, Batch 1700] loss: 0.011817889571111663
[Epoch 15, Batch 1800] loss: 0.00512664125831634
[Epoch 15, Batch 1900] loss: 0.016951366009872116
[Epoch 15, Batch 2000] loss: 0.00894463715989332
[Epoch 15, Batch 2100] loss: 0.011382011987095667
[Epoch 15, Batch 2200] loss: 0.010926006683025662
[Epoch 15, Batch 2300] loss: 0.007093238292309251
[Epoch 15, Batch 2400] loss: 0.009034898504375236
[Epoch 15, Batch 2500] loss: 0.006597649350759412
[Epoch 15, Batch 2600] loss: 0.0061185412940585595
[Epoch 15, Batch 2700] loss: 0.00966232898322005
[Epoch 15, Batch 2800] loss: 0.008546972228643882
[Epoch 15, Batch 2900] loss: 0.012575654839930622
[Epoch 15, Batch 3000] loss: 0.009209679959606093
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9873
Overfitting: 0.0464
[Epoch 16, Batch 100] loss: 0.005683079386180907
[Epoch 16, Batch 200] loss: 0.004132097386248006
[Epoch 16, Batch 300] loss: 0.007312416877887244
[Epoch 16, Batch 400] loss: 0.009295073205922221
[Epoch 16, Batch 500] loss: 0.010883328283257469
[Epoch 16, Batch 600] loss: 0.003643094130927693
[Epoch 16, Batch 700] loss: 0.004562896467982682
[Epoch 16, Batch 800] loss: 0.00527331275467759
[Epoch 16, Batch 900] loss: 0.011737805402951836
[Epoch 16, Batch 1000] loss: 0.004353201409103277
[Epoch 16, Batch 1100] loss: 0.00477339948552526
[Epoch 16, Batch 1200] loss: 0.005782017646452004
[Epoch 16, Batch 1300] loss: 0.004226077012198175
[Epoch 16, Batch 1400] loss: 0.006351908812792999
[Epoch 16, Batch 1500] loss: 0.008011843312824568
[Epoch 16, Batch 1600] loss: 0.00898879126871634
[Epoch 16, Batch 1700] loss: 0.007973880252618528
[Epoch 16, Batch 1800] loss: 0.003834030313396397
[Epoch 16, Batch 1900] loss: 0.01199291974305538
[Epoch 16, Batch 2000] loss: 0.005557986942631032
[Epoch 16, Batch 2100] loss: 0.00579260177164997
[Epoch 16, Batch 2200] loss: 0.009361582865613513
[Epoch 16, Batch 2300] loss: 0.00397873108465717
[Epoch 16, Batch 2400] loss: 0.004557401381250656
[Epoch 16, Batch 2500] loss: 0.00394755769780204
[Epoch 16, Batch 2600] loss: 0.009864185977588136
[Epoch 16, Batch 2700] loss: 0.004765276795747013
[Epoch 16, Batch 2800] loss: 0.007293110695281939
[Epoch 16, Batch 2900] loss: 0.00745845490032707
[Epoch 16, Batch 3000] loss: 0.012727396588347801
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9894
Overfitting: 0.0422
[Epoch 17, Batch 100] loss: 0.002144985293200534
[Epoch 17, Batch 200] loss: 0.008254866487488641
[Epoch 17, Batch 300] loss: 0.0032371044337401143
[Epoch 17, Batch 400] loss: 0.00343853661849721
[Epoch 17, Batch 500] loss: 0.001954548391518074
[Epoch 17, Batch 600] loss: 0.0033953872033890774
[Epoch 17, Batch 700] loss: 0.0032838485959422316
[Epoch 17, Batch 800] loss: 0.004265546312158506
[Epoch 17, Batch 900] loss: 0.009311012472899165
[Epoch 17, Batch 1000] loss: 0.00609943226868495
[Epoch 17, Batch 1100] loss: 0.00890887092004391
[Epoch 17, Batch 1200] loss: 0.008516240947137703
[Epoch 17, Batch 1300] loss: 0.012803762810085573
[Epoch 17, Batch 1400] loss: 0.008286018964158757
[Epoch 17, Batch 1500] loss: 0.006565807543601068
[Epoch 17, Batch 1600] loss: 0.004970602453577158
[Epoch 17, Batch 1700] loss: 0.013099812181640118
[Epoch 17, Batch 1800] loss: 0.0030159486702223148
[Epoch 17, Batch 1900] loss: 0.007444960387567789
[Epoch 17, Batch 2000] loss: 0.009487474738360788
[Epoch 17, Batch 2100] loss: 0.015113110904044333
[Epoch 17, Batch 2200] loss: 0.006415964386593487
[Epoch 17, Batch 2300] loss: 0.007638406926451466
[Epoch 17, Batch 2400] loss: 0.00723745783022423
[Epoch 17, Batch 2500] loss: 0.012254637234097886
[Epoch 17, Batch 2600] loss: 0.005418766750344162
[Epoch 17, Batch 2700] loss: 0.0023745528474916
[Epoch 17, Batch 2800] loss: 0.0033173476079025477
[Epoch 17, Batch 2900] loss: 0.005103035302585113
[Epoch 17, Batch 3000] loss: 0.007943806540965851
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9863
Overfitting: 0.0522
[Epoch 18, Batch 100] loss: 0.00700322241520098
[Epoch 18, Batch 200] loss: 0.004558972306301143
[Epoch 18, Batch 300] loss: 0.005668145231639983
[Epoch 18, Batch 400] loss: 0.0038248395031018844
[Epoch 18, Batch 500] loss: 0.00544370048757969
[Epoch 18, Batch 600] loss: 0.003269777639883955
[Epoch 18, Batch 700] loss: 0.003674569560443217
[Epoch 18, Batch 800] loss: 0.006107967396167169
[Epoch 18, Batch 900] loss: 0.006848042585036751
[Epoch 18, Batch 1000] loss: 0.007755621399849133
[Epoch 18, Batch 1100] loss: 0.003646434985489577
[Epoch 18, Batch 1200] loss: 0.0023698531825550617
[Epoch 18, Batch 1300] loss: 0.004321075974497717
[Epoch 18, Batch 1400] loss: 0.0034027476223957363
[Epoch 18, Batch 1500] loss: 0.004982579125870359
[Epoch 18, Batch 1600] loss: 0.007376152393723849
[Epoch 18, Batch 1700] loss: 0.003030132589991581
[Epoch 18, Batch 1800] loss: 0.005731419159924905
[Epoch 18, Batch 1900] loss: 0.007938688403727667
[Epoch 18, Batch 2000] loss: 0.009552972026347958
[Epoch 18, Batch 2100] loss: 0.0016110957864006537
[Epoch 18, Batch 2200] loss: 0.0059156368459224494
[Epoch 18, Batch 2300] loss: 0.003901159959978031
[Epoch 18, Batch 2400] loss: 0.004502261276633703
[Epoch 18, Batch 2500] loss: 0.01009516413962558
[Epoch 18, Batch 2600] loss: 0.006531629594940966
[Epoch 18, Batch 2700] loss: 0.009961354656703635
[Epoch 18, Batch 2800] loss: 0.0033022926594094316
[Epoch 18, Batch 2900] loss: 0.009683227808457104
[Epoch 18, Batch 3000] loss: 0.007225937891794274
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0427
Validation Accuracy: 0.9891
Overfitting: 0.0427
[Epoch 19, Batch 100] loss: 0.0025524690164684216
[Epoch 19, Batch 200] loss: 0.002703144069805603
[Epoch 19, Batch 300] loss: 0.00854144541086555
[Epoch 19, Batch 400] loss: 0.0048110815407170545
[Epoch 19, Batch 500] loss: 0.0020087119649888053
[Epoch 19, Batch 600] loss: 0.001557265560758765
[Epoch 19, Batch 700] loss: 0.008517906265329316
[Epoch 19, Batch 800] loss: 0.007149529186466026
[Epoch 19, Batch 900] loss: 0.003891784416343853
[Epoch 19, Batch 1000] loss: 0.0019190202718559846
[Epoch 19, Batch 1100] loss: 0.0021069037788683433
[Epoch 19, Batch 1200] loss: 0.0053409090087808055
[Epoch 19, Batch 1300] loss: 0.013976793407781258
[Epoch 19, Batch 1400] loss: 0.004939637485664719
[Epoch 19, Batch 1500] loss: 0.005657807008286681
[Epoch 19, Batch 1600] loss: 0.004325802081977201
[Epoch 19, Batch 1700] loss: 0.006682561463891119
[Epoch 19, Batch 1800] loss: 0.004728910199384586
[Epoch 19, Batch 1900] loss: 0.0035044724252361447
[Epoch 19, Batch 2000] loss: 0.00313016431081337
[Epoch 19, Batch 2100] loss: 0.00416886372743221
[Epoch 19, Batch 2200] loss: 0.0033230874523985676
[Epoch 19, Batch 2300] loss: 0.0032834977389757116
[Epoch 19, Batch 2400] loss: 0.004913401093137964
[Epoch 19, Batch 2500] loss: 0.0024067377679520517
[Epoch 19, Batch 2600] loss: 0.004803809696419421
[Epoch 19, Batch 2700] loss: 0.0033556333741670843
[Epoch 19, Batch 2800] loss: 0.003603680756881147
[Epoch 19, Batch 2900] loss: 0.005354410944765391
[Epoch 19, Batch 3000] loss: 0.0039029771945986625
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0411
Validation Accuracy: 0.9895
Overfitting: 0.0411
[Epoch 20, Batch 100] loss: 0.00419273805881403
[Epoch 20, Batch 200] loss: 0.0029924596770877086
[Epoch 20, Batch 300] loss: 0.003641515649124898
[Epoch 20, Batch 400] loss: 0.0030825347246246793
[Epoch 20, Batch 500] loss: 0.006627796959515422
[Epoch 20, Batch 600] loss: 0.0030069208111353873
[Epoch 20, Batch 700] loss: 0.006540811696012838
[Epoch 20, Batch 800] loss: 0.0017942975497743418
[Epoch 20, Batch 900] loss: 0.0027435086782423923
[Epoch 20, Batch 1000] loss: 0.0064829239273427675
[Epoch 20, Batch 1100] loss: 0.0033174741756327817
[Epoch 20, Batch 1200] loss: 0.0022435041132801816
[Epoch 20, Batch 1300] loss: 0.0027310807775241842
[Epoch 20, Batch 1400] loss: 0.0016039673646167784
[Epoch 20, Batch 1500] loss: 0.0012145147961440728
[Epoch 20, Batch 1600] loss: 0.00198606708393811
[Epoch 20, Batch 1700] loss: 0.007719547424912889
[Epoch 20, Batch 1800] loss: 0.0037385824661406632
[Epoch 20, Batch 1900] loss: 0.0012877405747022408
[Epoch 20, Batch 2000] loss: 0.00205377882690712
[Epoch 20, Batch 2100] loss: 0.0009269020852462973
[Epoch 20, Batch 2200] loss: 0.0024651767126435686
[Epoch 20, Batch 2300] loss: 0.0017195967287829993
[Epoch 20, Batch 2400] loss: 0.0031514380314646927
[Epoch 20, Batch 2500] loss: 0.007251822598751545
[Epoch 20, Batch 2600] loss: 0.002521033994156312
[Epoch 20, Batch 2700] loss: 0.00717039348104322
[Epoch 20, Batch 2800] loss: 0.004897947775684628
[Epoch 20, Batch 2900] loss: 0.0046711841766945384
[Epoch 20, Batch 3000] loss: 0.009573711882119938
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9887
Overfitting: 0.0450
[Epoch 21, Batch 100] loss: 0.0013802711078226082
[Epoch 21, Batch 200] loss: 0.003790739630407529
[Epoch 21, Batch 300] loss: 0.002303999726157997
[Epoch 21, Batch 400] loss: 0.002607242664881255
[Epoch 21, Batch 500] loss: 0.002696418214364371
[Epoch 21, Batch 600] loss: 0.001935344620262498
[Epoch 21, Batch 700] loss: 0.005002984049259283
[Epoch 21, Batch 800] loss: 0.0053216547068745965
[Epoch 21, Batch 900] loss: 0.0018575619014129074
[Epoch 21, Batch 1000] loss: 0.0015901970872326033
[Epoch 21, Batch 1100] loss: 0.0031952109600192104
[Epoch 21, Batch 1200] loss: 0.0034267053019823336
[Epoch 21, Batch 1300] loss: 0.0019581637333028114
[Epoch 21, Batch 1400] loss: 0.0008896759879728933
[Epoch 21, Batch 1500] loss: 0.000976604362983835
[Epoch 21, Batch 1600] loss: 0.0009345424381633727
[Epoch 21, Batch 1700] loss: 0.006293163341338115
[Epoch 21, Batch 1800] loss: 0.0018398058322655687
[Epoch 21, Batch 1900] loss: 0.0013540275289290094
[Epoch 21, Batch 2000] loss: 0.0018334115161060538
[Epoch 21, Batch 2100] loss: 0.008443009552327112
[Epoch 21, Batch 2200] loss: 0.01063597250891803
[Epoch 21, Batch 2300] loss: 0.009789204986713002
[Epoch 21, Batch 2400] loss: 0.004756437577227573
[Epoch 21, Batch 2500] loss: 0.004152494567217388
[Epoch 21, Batch 2600] loss: 0.002762375810833628
[Epoch 21, Batch 2700] loss: 0.004750690487752252
[Epoch 21, Batch 2800] loss: 0.003675716411058687
[Epoch 21, Batch 2900] loss: 0.003923561882083812
[Epoch 21, Batch 3000] loss: 0.0029911394031373107
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9888
Overfitting: 0.0465
[Epoch 22, Batch 100] loss: 0.0005760067598079388
[Epoch 22, Batch 200] loss: 0.0007622647116500758
[Epoch 22, Batch 300] loss: 0.0016577158597699793
[Epoch 22, Batch 400] loss: 0.0031410011832899445
[Epoch 22, Batch 500] loss: 0.004016681045474186
[Epoch 22, Batch 600] loss: 0.002566533054752398
[Epoch 22, Batch 700] loss: 0.0011846447145694584
[Epoch 22, Batch 800] loss: 0.0008507485681890259
[Epoch 22, Batch 900] loss: 0.003751140894651286
[Epoch 22, Batch 1000] loss: 0.0010353332273632533
[Epoch 22, Batch 1100] loss: 0.0007884549787814877
[Epoch 22, Batch 1200] loss: 0.0017434902422096598
[Epoch 22, Batch 1300] loss: 0.0009573153230701337
[Epoch 22, Batch 1400] loss: 0.0018164114922473828
[Epoch 22, Batch 1500] loss: 0.0035952102036821997
[Epoch 22, Batch 1600] loss: 0.0012460040501278335
[Epoch 22, Batch 1700] loss: 0.0008632137305590249
[Epoch 22, Batch 1800] loss: 0.0035194648468425526
[Epoch 22, Batch 1900] loss: 0.00464711896777942
[Epoch 22, Batch 2000] loss: 0.004789751688735464
[Epoch 22, Batch 2100] loss: 0.0037682239341651426
[Epoch 22, Batch 2200] loss: 0.0036148531638161784
[Epoch 22, Batch 2300] loss: 0.0067657149117147245
[Epoch 22, Batch 2400] loss: 0.001116623945974169
[Epoch 22, Batch 2500] loss: 0.010530080068718205
[Epoch 22, Batch 2600] loss: 0.0020228387466961805
[Epoch 22, Batch 2700] loss: 0.004962777574985395
[Epoch 22, Batch 2800] loss: 0.0035814082543546987
[Epoch 22, Batch 2900] loss: 0.003346602279381443
[Epoch 22, Batch 3000] loss: 0.0021915664179098827
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9892
Overfitting: 0.0474
[Epoch 23, Batch 100] loss: 0.0018209695908323908
[Epoch 23, Batch 200] loss: 0.004996219838409211
[Epoch 23, Batch 300] loss: 0.0023169443928148323
[Epoch 23, Batch 400] loss: 0.00436984007976875
[Epoch 23, Batch 500] loss: 0.0013832034550512163
[Epoch 23, Batch 600] loss: 0.0019074187791288466
[Epoch 23, Batch 700] loss: 0.004935091789325341
[Epoch 23, Batch 800] loss: 0.003808378519549507
[Epoch 23, Batch 900] loss: 0.004346745674684982
[Epoch 23, Batch 1000] loss: 0.001899563281050689
[Epoch 23, Batch 1100] loss: 0.0016518348088438728
[Epoch 23, Batch 1200] loss: 0.0028837117728228636
[Epoch 23, Batch 1300] loss: 0.0020316134206101568
[Epoch 23, Batch 1400] loss: 0.0008333509433822872
[Epoch 23, Batch 1500] loss: 0.004355842816681133
[Epoch 23, Batch 1600] loss: 0.0009232105356164411
[Epoch 23, Batch 1700] loss: 0.000970092439942043
[Epoch 23, Batch 1800] loss: 0.0009292880282723725
[Epoch 23, Batch 1900] loss: 0.000998440480174665
[Epoch 23, Batch 2000] loss: 0.000578057633533362
[Epoch 23, Batch 2100] loss: 0.0008454803207662565
[Epoch 23, Batch 2200] loss: 0.0027580845254479413
[Epoch 23, Batch 2300] loss: 0.0012810743924840118
[Epoch 23, Batch 2400] loss: 0.0011274593532786526
[Epoch 23, Batch 2500] loss: 0.0008893493242919703
[Epoch 23, Batch 2600] loss: 0.002128575093248628
[Epoch 23, Batch 2700] loss: 0.0007258808725026711
[Epoch 23, Batch 2800] loss: 0.0015325592559902645
[Epoch 23, Batch 2900] loss: 0.0021290334369136587
[Epoch 23, Batch 3000] loss: 0.011567726914906581
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9884
Overfitting: 0.0486
[Epoch 24, Batch 100] loss: 0.002792312758935154
[Epoch 24, Batch 200] loss: 0.002393160998779247
[Epoch 24, Batch 300] loss: 0.0011637396392796973
[Epoch 24, Batch 400] loss: 0.0018018699678063398
[Epoch 24, Batch 500] loss: 0.0016519641438155475
[Epoch 24, Batch 600] loss: 0.001146150732799427
[Epoch 24, Batch 700] loss: 0.0009955168293228666
[Epoch 24, Batch 800] loss: 0.0011361739696442896
[Epoch 24, Batch 900] loss: 0.000519169573959859
[Epoch 24, Batch 1000] loss: 0.000693700586815229
[Epoch 24, Batch 1100] loss: 0.0012403734680863465
[Epoch 24, Batch 1200] loss: 0.0006795687245732829
[Epoch 24, Batch 1300] loss: 0.001024644830217123
[Epoch 24, Batch 1400] loss: 0.0006869693777069408
[Epoch 24, Batch 1500] loss: 0.0012340089212901973
[Epoch 24, Batch 1600] loss: 0.0006119302783258007
[Epoch 24, Batch 1700] loss: 0.0015747459084499127
[Epoch 24, Batch 1800] loss: 0.0033316436286241567
[Epoch 24, Batch 1900] loss: 0.002340098724967188
[Epoch 24, Batch 2000] loss: 0.006214651985161818
[Epoch 24, Batch 2100] loss: 0.0033771488431503373
[Epoch 24, Batch 2200] loss: 0.002073712656513922
[Epoch 24, Batch 2300] loss: 0.0006548221594288251
[Epoch 24, Batch 2400] loss: 0.0005690386008404858
[Epoch 24, Batch 2500] loss: 0.0007919719953538618
[Epoch 24, Batch 2600] loss: 0.0030207048685585393
[Epoch 24, Batch 2700] loss: 0.0017617683543603492
[Epoch 24, Batch 2800] loss: 0.0009942269702631278
[Epoch 24, Batch 2900] loss: 0.0005958695749636434
[Epoch 24, Batch 3000] loss: 0.0003892222234590292
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9898
Overfitting: 0.0447
Fold 5 validation loss: 0.0447
Mean validation loss across all folds for Trial 9 is 0.0519 with trial config:  l1: 256, l2: 64, lr: 0.0011075021673381486, batch_size: 16
[I 2024-12-10 07:28:50,520] Trial 8 finished with value: 0.05185071098342007 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0011075021673381486, 'batch_size': 16}. Best is trial 4 with value: 0.046893630782967134.

Selected Hyperparameters for Trial 10:
  l1: 256, l2: 64, lr: 0.009053062590497972, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.9549649876356125
[Epoch 1, Batch 200] loss: 0.4028303723037243
[Epoch 1, Batch 300] loss: 0.2142792648077011
**STATS for Epoch 1** : 
Average training loss: 0.0298
Average validation loss: 0.1309
Validation Accuracy: 0.9568
Overfitting: 0.1010
Best model saved at epoch 1 with validation loss: 0.1309
[Epoch 2, Batch 100] loss: 0.11088843142613769
[Epoch 2, Batch 200] loss: 0.10252367157489062
[Epoch 2, Batch 300] loss: 0.08888951245695352
**STATS for Epoch 2** : 
Average training loss: 0.0186
Average validation loss: 0.0822
Validation Accuracy: 0.9745
Overfitting: 0.0636
Best model saved at epoch 2 with validation loss: 0.0822
[Epoch 3, Batch 100] loss: 0.07080358929000795
[Epoch 3, Batch 200] loss: 0.06567556566558778
[Epoch 3, Batch 300] loss: 0.07280104015022516
**STATS for Epoch 3** : 
Average training loss: 0.0124
Average validation loss: 0.0557
Validation Accuracy: 0.9820
Overfitting: 0.0433
Best model saved at epoch 3 with validation loss: 0.0557
[Epoch 4, Batch 100] loss: 0.04303269456606358
[Epoch 4, Batch 200] loss: 0.050158176459372046
[Epoch 4, Batch 300] loss: 0.05544107421534136
**STATS for Epoch 4** : 
Average training loss: 0.0103
Average validation loss: 0.0598
Validation Accuracy: 0.9816
Overfitting: 0.0496
[Epoch 5, Batch 100] loss: 0.03700669323094189
[Epoch 5, Batch 200] loss: 0.04038671316113323
[Epoch 5, Batch 300] loss: 0.043285767128691074
**STATS for Epoch 5** : 
Average training loss: 0.0087
Average validation loss: 0.0463
Validation Accuracy: 0.9846
Overfitting: 0.0377
Best model saved at epoch 5 with validation loss: 0.0463
[Epoch 6, Batch 100] loss: 0.030893182544969023
[Epoch 6, Batch 200] loss: 0.03579713719547726
[Epoch 6, Batch 300] loss: 0.03729039075784385
**STATS for Epoch 6** : 
Average training loss: 0.0066
Average validation loss: 0.0481
Validation Accuracy: 0.9850
Overfitting: 0.0415
[Epoch 7, Batch 100] loss: 0.027325464996974917
[Epoch 7, Batch 200] loss: 0.029033012595027684
[Epoch 7, Batch 300] loss: 0.02746117559960112
**STATS for Epoch 7** : 
Average training loss: 0.0059
Average validation loss: 0.0439
Validation Accuracy: 0.9863
Overfitting: 0.0379
Best model saved at epoch 7 with validation loss: 0.0439
[Epoch 8, Batch 100] loss: 0.021167988241650164
[Epoch 8, Batch 200] loss: 0.023036729489685968
[Epoch 8, Batch 300] loss: 0.028008915674872695
**STATS for Epoch 8** : 
Average training loss: 0.0054
Average validation loss: 0.0435
Validation Accuracy: 0.9866
Overfitting: 0.0381
Best model saved at epoch 8 with validation loss: 0.0435
[Epoch 9, Batch 100] loss: 0.01708746796939522
[Epoch 9, Batch 200] loss: 0.022254339563660325
[Epoch 9, Batch 300] loss: 0.01999947754549794
**STATS for Epoch 9** : 
Average training loss: 0.0048
Average validation loss: 0.0476
Validation Accuracy: 0.9864
Overfitting: 0.0428
[Epoch 10, Batch 100] loss: 0.019386172433150932
[Epoch 10, Batch 200] loss: 0.01534281272033695
[Epoch 10, Batch 300] loss: 0.01988664083648473
**STATS for Epoch 10** : 
Average training loss: 0.0051
Average validation loss: 0.0487
Validation Accuracy: 0.9858
Overfitting: 0.0436
[Epoch 11, Batch 100] loss: 0.019601566681521944
[Epoch 11, Batch 200] loss: 0.015350344745675102
[Epoch 11, Batch 300] loss: 0.014315069464500993
**STATS for Epoch 11** : 
Average training loss: 0.0033
Average validation loss: 0.0403
Validation Accuracy: 0.9879
Overfitting: 0.0370
Best model saved at epoch 11 with validation loss: 0.0403
[Epoch 12, Batch 100] loss: 0.00976332558435388
[Epoch 12, Batch 200] loss: 0.013736371774575673
[Epoch 12, Batch 300] loss: 0.01347269770631101
**STATS for Epoch 12** : 
Average training loss: 0.0028
Average validation loss: 0.0371
Validation Accuracy: 0.9888
Overfitting: 0.0343
Best model saved at epoch 12 with validation loss: 0.0371
[Epoch 13, Batch 100] loss: 0.013318600354250521
[Epoch 13, Batch 200] loss: 0.007710379590134835
[Epoch 13, Batch 300] loss: 0.01053883210697677
**STATS for Epoch 13** : 
Average training loss: 0.0024
Average validation loss: 0.0421
Validation Accuracy: 0.9881
Overfitting: 0.0397
[Epoch 14, Batch 100] loss: 0.006951016966777388
[Epoch 14, Batch 200] loss: 0.008945155973924557
[Epoch 14, Batch 300] loss: 0.011327126472606324
**STATS for Epoch 14** : 
Average training loss: 0.0022
Average validation loss: 0.0429
Validation Accuracy: 0.9880
Overfitting: 0.0407
[Epoch 15, Batch 100] loss: 0.007423363641719334
[Epoch 15, Batch 200] loss: 0.00781487470230786
[Epoch 15, Batch 300] loss: 0.006958153348823544
**STATS for Epoch 15** : 
Average training loss: 0.0015
Average validation loss: 0.0440
Validation Accuracy: 0.9885
Overfitting: 0.0424
[Epoch 16, Batch 100] loss: 0.005636946203012485
[Epoch 16, Batch 200] loss: 0.005154440320620779
[Epoch 16, Batch 300] loss: 0.0062775723545928485
**STATS for Epoch 16** : 
Average training loss: 0.0017
Average validation loss: 0.0457
Validation Accuracy: 0.9885
Overfitting: 0.0441
[Epoch 17, Batch 100] loss: 0.004168865128885955
[Epoch 17, Batch 200] loss: 0.006079642874829006
[Epoch 17, Batch 300] loss: 0.008893361990049016
**STATS for Epoch 17** : 
Average training loss: 0.0016
Average validation loss: 0.0426
Validation Accuracy: 0.9882
Overfitting: 0.0410
[Epoch 18, Batch 100] loss: 0.00559196768241236
[Epoch 18, Batch 200] loss: 0.002840907272839104
[Epoch 18, Batch 300] loss: 0.004079088733742537
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0434
Validation Accuracy: 0.9884
Overfitting: 0.0426
[Epoch 19, Batch 100] loss: 0.0038116857770364733
[Epoch 19, Batch 200] loss: 0.0016080432317539816
[Epoch 19, Batch 300] loss: 0.0038668326193874235
**STATS for Epoch 19** : 
Average training loss: 0.0011
Average validation loss: 0.0443
Validation Accuracy: 0.9884
Overfitting: 0.0432
[Epoch 20, Batch 100] loss: 0.00271350009010348
[Epoch 20, Batch 200] loss: 0.002072256581959664
[Epoch 20, Batch 300] loss: 0.0033862230242812075
**STATS for Epoch 20** : 
Average training loss: 0.0015
Average validation loss: 0.0481
Validation Accuracy: 0.9889
Overfitting: 0.0465
[Epoch 21, Batch 100] loss: 0.00308965987074771
[Epoch 21, Batch 200] loss: 0.0025689140925896936
[Epoch 21, Batch 300] loss: 0.002436368250528176
**STATS for Epoch 21** : 
Average training loss: 0.0012
Average validation loss: 0.0453
Validation Accuracy: 0.9885
Overfitting: 0.0440
[Epoch 22, Batch 100] loss: 0.002077324929559836
[Epoch 22, Batch 200] loss: 0.0015208760776567942
[Epoch 22, Batch 300] loss: 0.001492162770809955
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0444
Validation Accuracy: 0.9896
Overfitting: 0.0440
[Epoch 23, Batch 100] loss: 0.0011677557737129972
[Epoch 23, Batch 200] loss: 0.001612502210882667
[Epoch 23, Batch 300] loss: 0.0006526117496468941
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0425
Validation Accuracy: 0.9909
Overfitting: 0.0421
[Epoch 24, Batch 100] loss: 0.0017986653403022502
[Epoch 24, Batch 200] loss: 0.0008360404903760355
[Epoch 24, Batch 300] loss: 0.0009762618125932932
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0471
Validation Accuracy: 0.9906
Overfitting: 0.0469
Fold 1 validation loss: 0.0471
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.8177924537658692
[Epoch 1, Batch 200] loss: 0.3349171872437
[Epoch 1, Batch 300] loss: 0.17728710867464542
**STATS for Epoch 1** : 
Average training loss: 0.0284
Average validation loss: 0.1397
Validation Accuracy: 0.9557
Overfitting: 0.1113
Best model saved at epoch 1 with validation loss: 0.1397
[Epoch 2, Batch 100] loss: 0.11203174361959099
[Epoch 2, Batch 200] loss: 0.10272938849404455
[Epoch 2, Batch 300] loss: 0.091748609803617
**STATS for Epoch 2** : 
Average training loss: 0.0164
Average validation loss: 0.0827
Validation Accuracy: 0.9731
Overfitting: 0.0663
Best model saved at epoch 2 with validation loss: 0.0827
[Epoch 3, Batch 100] loss: 0.06377412050031125
[Epoch 3, Batch 200] loss: 0.06877144765108824
[Epoch 3, Batch 300] loss: 0.06476110640913248
**STATS for Epoch 3** : 
Average training loss: 0.0125
Average validation loss: 0.0745
Validation Accuracy: 0.9763
Overfitting: 0.0620
Best model saved at epoch 3 with validation loss: 0.0745
[Epoch 4, Batch 100] loss: 0.05194270793348551
[Epoch 4, Batch 200] loss: 0.04788374154828489
[Epoch 4, Batch 300] loss: 0.047697653071954844
**STATS for Epoch 4** : 
Average training loss: 0.0097
Average validation loss: 0.0718
Validation Accuracy: 0.9782
Overfitting: 0.0622
Best model saved at epoch 4 with validation loss: 0.0718
[Epoch 5, Batch 100] loss: 0.03827511568088084
[Epoch 5, Batch 200] loss: 0.04353038631379604
[Epoch 5, Batch 300] loss: 0.04361297708004713
**STATS for Epoch 5** : 
Average training loss: 0.0085
Average validation loss: 0.0524
Validation Accuracy: 0.9837
Overfitting: 0.0439
Best model saved at epoch 5 with validation loss: 0.0524
[Epoch 6, Batch 100] loss: 0.032049689879640936
[Epoch 6, Batch 200] loss: 0.034640759273897856
[Epoch 6, Batch 300] loss: 0.026788518398534508
**STATS for Epoch 6** : 
Average training loss: 0.0071
Average validation loss: 0.0573
Validation Accuracy: 0.9838
Overfitting: 0.0502
[Epoch 7, Batch 100] loss: 0.021737977508455516
[Epoch 7, Batch 200] loss: 0.028428976498544214
[Epoch 7, Batch 300] loss: 0.030077962127979845
**STATS for Epoch 7** : 
Average training loss: 0.0061
Average validation loss: 0.0548
Validation Accuracy: 0.9837
Overfitting: 0.0486
[Epoch 8, Batch 100] loss: 0.02136049296706915
[Epoch 8, Batch 200] loss: 0.021637084712274372
[Epoch 8, Batch 300] loss: 0.02267154921311885
**STATS for Epoch 8** : 
Average training loss: 0.0057
Average validation loss: 0.0757
Validation Accuracy: 0.9766
Overfitting: 0.0701
[Epoch 9, Batch 100] loss: 0.019028264278313146
[Epoch 9, Batch 200] loss: 0.017152925301343203
[Epoch 9, Batch 300] loss: 0.019699652249692008
**STATS for Epoch 9** : 
Average training loss: 0.0046
Average validation loss: 0.0555
Validation Accuracy: 0.9837
Overfitting: 0.0509
[Epoch 10, Batch 100] loss: 0.016047024630825035
[Epoch 10, Batch 200] loss: 0.016296385244640988
[Epoch 10, Batch 300] loss: 0.020065868825186045
**STATS for Epoch 10** : 
Average training loss: 0.0043
Average validation loss: 0.0662
Validation Accuracy: 0.9825
Overfitting: 0.0619
[Epoch 11, Batch 100] loss: 0.0134063560818322
[Epoch 11, Batch 200] loss: 0.01452774226781912
[Epoch 11, Batch 300] loss: 0.014502554721548221
**STATS for Epoch 11** : 
Average training loss: 0.0029
Average validation loss: 0.0527
Validation Accuracy: 0.9863
Overfitting: 0.0499
[Epoch 12, Batch 100] loss: 0.011656621596193873
[Epoch 12, Batch 200] loss: 0.012613633255532476
[Epoch 12, Batch 300] loss: 0.011648231556464453
**STATS for Epoch 12** : 
Average training loss: 0.0024
Average validation loss: 0.0587
Validation Accuracy: 0.9858
Overfitting: 0.0563
[Epoch 13, Batch 100] loss: 0.009106286913447548
[Epoch 13, Batch 200] loss: 0.01059660846600309
[Epoch 13, Batch 300] loss: 0.011746420754352584
**STATS for Epoch 13** : 
Average training loss: 0.0027
Average validation loss: 0.0561
Validation Accuracy: 0.9865
Overfitting: 0.0533
[Epoch 14, Batch 100] loss: 0.011772486948175356
[Epoch 14, Batch 200] loss: 0.010117612540780101
[Epoch 14, Batch 300] loss: 0.01007080420240527
**STATS for Epoch 14** : 
Average training loss: 0.0030
Average validation loss: 0.0565
Validation Accuracy: 0.9865
Overfitting: 0.0536
[Epoch 15, Batch 100] loss: 0.005760332155332435
[Epoch 15, Batch 200] loss: 0.00805304439010797
[Epoch 15, Batch 300] loss: 0.006827914953464642
**STATS for Epoch 15** : 
Average training loss: 0.0020
Average validation loss: 0.0485
Validation Accuracy: 0.9885
Overfitting: 0.0465
Best model saved at epoch 15 with validation loss: 0.0485
[Epoch 16, Batch 100] loss: 0.007215397225518245
[Epoch 16, Batch 200] loss: 0.006081742004098487
[Epoch 16, Batch 300] loss: 0.00560181352251675
**STATS for Epoch 16** : 
Average training loss: 0.0019
Average validation loss: 0.0566
Validation Accuracy: 0.9865
Overfitting: 0.0546
[Epoch 17, Batch 100] loss: 0.005047379299357999
[Epoch 17, Batch 200] loss: 0.005416999393928563
[Epoch 17, Batch 300] loss: 0.009985042551707011
**STATS for Epoch 17** : 
Average training loss: 0.0015
Average validation loss: 0.0602
Validation Accuracy: 0.9873
Overfitting: 0.0587
[Epoch 18, Batch 100] loss: 0.005148330291776801
[Epoch 18, Batch 200] loss: 0.004307952275630669
[Epoch 18, Batch 300] loss: 0.004986520332131476
**STATS for Epoch 18** : 
Average training loss: 0.0010
Average validation loss: 0.0553
Validation Accuracy: 0.9882
Overfitting: 0.0543
[Epoch 19, Batch 100] loss: 0.00337264731493633
[Epoch 19, Batch 200] loss: 0.0023195127322105692
[Epoch 19, Batch 300] loss: 0.004146174725974561
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0589
Validation Accuracy: 0.9878
Overfitting: 0.0581
[Epoch 20, Batch 100] loss: 0.0033691227276722202
[Epoch 20, Batch 200] loss: 0.0020487205430254106
[Epoch 20, Batch 300] loss: 0.002313661587322713
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0609
Validation Accuracy: 0.9877
Overfitting: 0.0599
[Epoch 21, Batch 100] loss: 0.002801803105612635
[Epoch 21, Batch 200] loss: 0.002778683979486232
[Epoch 21, Batch 300] loss: 0.003547033174800163
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0580
Validation Accuracy: 0.9875
Overfitting: 0.0575
[Epoch 22, Batch 100] loss: 0.0012074403912265552
[Epoch 22, Batch 200] loss: 0.0011406599762267434
[Epoch 22, Batch 300] loss: 0.0023149058138369582
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0588
Validation Accuracy: 0.9888
Overfitting: 0.0583
[Epoch 23, Batch 100] loss: 0.0008793274313575239
[Epoch 23, Batch 200] loss: 0.000987624747613154
[Epoch 23, Batch 300] loss: 0.0013441389871877618
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0613
Validation Accuracy: 0.9878
Overfitting: 0.0610
[Epoch 24, Batch 100] loss: 0.0007251610181356228
[Epoch 24, Batch 200] loss: 0.0011670794644851412
[Epoch 24, Batch 300] loss: 0.0010242526419642671
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0620
Validation Accuracy: 0.9883
Overfitting: 0.0618
Fold 2 validation loss: 0.0620
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 1.6306910970807076
[Epoch 1, Batch 200] loss: 0.35284565687179564
[Epoch 1, Batch 300] loss: 0.1978239493072033
**STATS for Epoch 1** : 
Average training loss: 0.0304
Average validation loss: 0.1362
Validation Accuracy: 0.9564
Overfitting: 0.1058
Best model saved at epoch 1 with validation loss: 0.1362
[Epoch 2, Batch 100] loss: 0.1183369910158217
[Epoch 2, Batch 200] loss: 0.10690484281629324
[Epoch 2, Batch 300] loss: 0.09270195432938635
**STATS for Epoch 2** : 
Average training loss: 0.0197
Average validation loss: 0.0971
Validation Accuracy: 0.9692
Overfitting: 0.0774
Best model saved at epoch 2 with validation loss: 0.0971
[Epoch 3, Batch 100] loss: 0.0867510706372559
[Epoch 3, Batch 200] loss: 0.07322082757949828
[Epoch 3, Batch 300] loss: 0.06513075141701848
**STATS for Epoch 3** : 
Average training loss: 0.0123
Average validation loss: 0.0682
Validation Accuracy: 0.9803
Overfitting: 0.0558
Best model saved at epoch 3 with validation loss: 0.0682
[Epoch 4, Batch 100] loss: 0.0529475648701191
[Epoch 4, Batch 200] loss: 0.06050716075114906
[Epoch 4, Batch 300] loss: 0.06620274540502578
**STATS for Epoch 4** : 
Average training loss: 0.0104
Average validation loss: 0.0568
Validation Accuracy: 0.9827
Overfitting: 0.0464
Best model saved at epoch 4 with validation loss: 0.0568
[Epoch 5, Batch 100] loss: 0.044867690517567095
[Epoch 5, Batch 200] loss: 0.04551434596534818
[Epoch 5, Batch 300] loss: 0.04655865633161738
**STATS for Epoch 5** : 
Average training loss: 0.0086
Average validation loss: 0.0501
Validation Accuracy: 0.9848
Overfitting: 0.0414
Best model saved at epoch 5 with validation loss: 0.0501
[Epoch 6, Batch 100] loss: 0.03618570760823786
[Epoch 6, Batch 200] loss: 0.03551395337097347
[Epoch 6, Batch 300] loss: 0.04177817291580141
**STATS for Epoch 6** : 
Average training loss: 0.0088
Average validation loss: 0.0492
Validation Accuracy: 0.9839
Overfitting: 0.0405
Best model saved at epoch 6 with validation loss: 0.0492
[Epoch 7, Batch 100] loss: 0.028989160475321116
[Epoch 7, Batch 200] loss: 0.03706126236356795
[Epoch 7, Batch 300] loss: 0.032132172903511676
**STATS for Epoch 7** : 
Average training loss: 0.0059
Average validation loss: 0.0469
Validation Accuracy: 0.9852
Overfitting: 0.0410
Best model saved at epoch 7 with validation loss: 0.0469
[Epoch 8, Batch 100] loss: 0.022414251742884517
[Epoch 8, Batch 200] loss: 0.025998787970747797
[Epoch 8, Batch 300] loss: 0.03096082231029868
**STATS for Epoch 8** : 
Average training loss: 0.0052
Average validation loss: 0.0577
Validation Accuracy: 0.9822
Overfitting: 0.0525
[Epoch 9, Batch 100] loss: 0.02329083017189987
[Epoch 9, Batch 200] loss: 0.02129095300566405
[Epoch 9, Batch 300] loss: 0.025086875499400776
**STATS for Epoch 9** : 
Average training loss: 0.0052
Average validation loss: 0.0472
Validation Accuracy: 0.9860
Overfitting: 0.0421
[Epoch 10, Batch 100] loss: 0.019536252761026843
[Epoch 10, Batch 200] loss: 0.016731863030290697
[Epoch 10, Batch 300] loss: 0.022176306956098416
**STATS for Epoch 10** : 
Average training loss: 0.0039
Average validation loss: 0.0480
Validation Accuracy: 0.9868
Overfitting: 0.0441
[Epoch 11, Batch 100] loss: 0.015828919922932984
[Epoch 11, Batch 200] loss: 0.015918681999901308
[Epoch 11, Batch 300] loss: 0.017969167542178185
**STATS for Epoch 11** : 
Average training loss: 0.0041
Average validation loss: 0.0451
Validation Accuracy: 0.9872
Overfitting: 0.0411
Best model saved at epoch 11 with validation loss: 0.0451
[Epoch 12, Batch 100] loss: 0.012490854705683887
[Epoch 12, Batch 200] loss: 0.012907293650787324
[Epoch 12, Batch 300] loss: 0.017724243511911483
**STATS for Epoch 12** : 
Average training loss: 0.0033
Average validation loss: 0.0469
Validation Accuracy: 0.9864
Overfitting: 0.0435
[Epoch 13, Batch 100] loss: 0.010364461732679046
[Epoch 13, Batch 200] loss: 0.011401470605487702
[Epoch 13, Batch 300] loss: 0.013991043081041425
**STATS for Epoch 13** : 
Average training loss: 0.0034
Average validation loss: 0.0492
Validation Accuracy: 0.9859
Overfitting: 0.0458
[Epoch 14, Batch 100] loss: 0.014360750681807985
[Epoch 14, Batch 200] loss: 0.012923245761485305
[Epoch 14, Batch 300] loss: 0.010223514734825585
**STATS for Epoch 14** : 
Average training loss: 0.0019
Average validation loss: 0.0515
Validation Accuracy: 0.9867
Overfitting: 0.0497
[Epoch 15, Batch 100] loss: 0.007035450506664347
[Epoch 15, Batch 200] loss: 0.009478362378358725
[Epoch 15, Batch 300] loss: 0.011593459353607614
**STATS for Epoch 15** : 
Average training loss: 0.0023
Average validation loss: 0.0514
Validation Accuracy: 0.9863
Overfitting: 0.0491
[Epoch 16, Batch 100] loss: 0.005096532611933071
[Epoch 16, Batch 200] loss: 0.007781173746043351
[Epoch 16, Batch 300] loss: 0.011979354597715429
**STATS for Epoch 16** : 
Average training loss: 0.0020
Average validation loss: 0.0573
Validation Accuracy: 0.9850
Overfitting: 0.0553
[Epoch 17, Batch 100] loss: 0.00726095772071858
[Epoch 17, Batch 200] loss: 0.007869654340465786
[Epoch 17, Batch 300] loss: 0.007113929278129944
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0487
Validation Accuracy: 0.9875
Overfitting: 0.0477
[Epoch 18, Batch 100] loss: 0.006814107499230886
[Epoch 18, Batch 200] loss: 0.002880903374607442
[Epoch 18, Batch 300] loss: 0.005405036164811463
**STATS for Epoch 18** : 
Average training loss: 0.0013
Average validation loss: 0.0546
Validation Accuracy: 0.9866
Overfitting: 0.0534
[Epoch 19, Batch 100] loss: 0.0050132877199212085
[Epoch 19, Batch 200] loss: 0.0036268260716315124
[Epoch 19, Batch 300] loss: 0.006914093074592529
**STATS for Epoch 19** : 
Average training loss: 0.0010
Average validation loss: 0.0535
Validation Accuracy: 0.9868
Overfitting: 0.0526
[Epoch 20, Batch 100] loss: 0.0027873495146195637
[Epoch 20, Batch 200] loss: 0.003381212704771315
[Epoch 20, Batch 300] loss: 0.004507112469873391
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0572
Validation Accuracy: 0.9868
Overfitting: 0.0563
[Epoch 21, Batch 100] loss: 0.004862478160830506
[Epoch 21, Batch 200] loss: 0.007224548390950076
[Epoch 21, Batch 300] loss: 0.005956134089792613
**STATS for Epoch 21** : 
Average training loss: 0.0016
Average validation loss: 0.0600
Validation Accuracy: 0.9878
Overfitting: 0.0584
[Epoch 22, Batch 100] loss: 0.004866701346800255
[Epoch 22, Batch 200] loss: 0.003966508842422627
[Epoch 22, Batch 300] loss: 0.005741194701913628
**STATS for Epoch 22** : 
Average training loss: 0.0008
Average validation loss: 0.0543
Validation Accuracy: 0.9884
Overfitting: 0.0534
[Epoch 23, Batch 100] loss: 0.0032139319903944853
[Epoch 23, Batch 200] loss: 0.0031863666913886845
[Epoch 23, Batch 300] loss: 0.0016293721090187318
**STATS for Epoch 23** : 
Average training loss: 0.0010
Average validation loss: 0.0588
Validation Accuracy: 0.9878
Overfitting: 0.0578
[Epoch 24, Batch 100] loss: 0.0024684166625957003
[Epoch 24, Batch 200] loss: 0.0022717176815785934
[Epoch 24, Batch 300] loss: 0.0029193113169822026
**STATS for Epoch 24** : 
Average training loss: 0.0009
Average validation loss: 0.0689
Validation Accuracy: 0.9852
Overfitting: 0.0680
Fold 3 validation loss: 0.0689
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.7170735362172127
[Epoch 1, Batch 200] loss: 0.3282249365746975
[Epoch 1, Batch 300] loss: 0.1788122145831585
**STATS for Epoch 1** : 
Average training loss: 0.0289
Average validation loss: 0.1297
Validation Accuracy: 0.9584
Overfitting: 0.1008
Best model saved at epoch 1 with validation loss: 0.1297
[Epoch 2, Batch 100] loss: 0.11461383607238532
[Epoch 2, Batch 200] loss: 0.11048059733584523
[Epoch 2, Batch 300] loss: 0.1000670463219285
**STATS for Epoch 2** : 
Average training loss: 0.0168
Average validation loss: 0.0747
Validation Accuracy: 0.9759
Overfitting: 0.0579
Best model saved at epoch 2 with validation loss: 0.0747
[Epoch 3, Batch 100] loss: 0.07211583863012493
[Epoch 3, Batch 200] loss: 0.07451494077220559
[Epoch 3, Batch 300] loss: 0.06947749821469187
**STATS for Epoch 3** : 
Average training loss: 0.0127
Average validation loss: 0.0650
Validation Accuracy: 0.9780
Overfitting: 0.0524
Best model saved at epoch 3 with validation loss: 0.0650
[Epoch 4, Batch 100] loss: 0.05123402461409569
[Epoch 4, Batch 200] loss: 0.05616798439528793
[Epoch 4, Batch 300] loss: 0.061221131645143034
**STATS for Epoch 4** : 
Average training loss: 0.0110
Average validation loss: 0.0586
Validation Accuracy: 0.9818
Overfitting: 0.0476
Best model saved at epoch 4 with validation loss: 0.0586
[Epoch 5, Batch 100] loss: 0.045142391892150045
[Epoch 5, Batch 200] loss: 0.04970365167595446
[Epoch 5, Batch 300] loss: 0.04048685282235965
**STATS for Epoch 5** : 
Average training loss: 0.0088
Average validation loss: 0.0541
Validation Accuracy: 0.9818
Overfitting: 0.0453
Best model saved at epoch 5 with validation loss: 0.0541
[Epoch 6, Batch 100] loss: 0.03693611242808401
[Epoch 6, Batch 200] loss: 0.04156673624180257
[Epoch 6, Batch 300] loss: 0.03569274893263355
**STATS for Epoch 6** : 
Average training loss: 0.0078
Average validation loss: 0.0508
Validation Accuracy: 0.9838
Overfitting: 0.0430
Best model saved at epoch 6 with validation loss: 0.0508
[Epoch 7, Batch 100] loss: 0.02918014982249588
[Epoch 7, Batch 200] loss: 0.037666454033460466
[Epoch 7, Batch 300] loss: 0.027590277306735515
**STATS for Epoch 7** : 
Average training loss: 0.0073
Average validation loss: 0.0559
Validation Accuracy: 0.9815
Overfitting: 0.0486
[Epoch 8, Batch 100] loss: 0.03209616204258055
[Epoch 8, Batch 200] loss: 0.026612708556931465
[Epoch 8, Batch 300] loss: 0.028470541120041163
**STATS for Epoch 8** : 
Average training loss: 0.0067
Average validation loss: 0.0443
Validation Accuracy: 0.9854
Overfitting: 0.0376
Best model saved at epoch 8 with validation loss: 0.0443
[Epoch 9, Batch 100] loss: 0.021071315224980937
[Epoch 9, Batch 200] loss: 0.02528187897289172
[Epoch 9, Batch 300] loss: 0.0274404628702905
**STATS for Epoch 9** : 
Average training loss: 0.0057
Average validation loss: 0.0443
Validation Accuracy: 0.9865
Overfitting: 0.0386
[Epoch 10, Batch 100] loss: 0.022100539149250836
[Epoch 10, Batch 200] loss: 0.018426080718054436
[Epoch 10, Batch 300] loss: 0.021760307461954655
**STATS for Epoch 10** : 
Average training loss: 0.0040
Average validation loss: 0.0410
Validation Accuracy: 0.9873
Overfitting: 0.0370
Best model saved at epoch 10 with validation loss: 0.0410
[Epoch 11, Batch 100] loss: 0.016956610202323644
[Epoch 11, Batch 200] loss: 0.013481846987269818
[Epoch 11, Batch 300] loss: 0.020760959461913444
**STATS for Epoch 11** : 
Average training loss: 0.0040
Average validation loss: 0.0433
Validation Accuracy: 0.9868
Overfitting: 0.0393
[Epoch 12, Batch 100] loss: 0.013790442504687235
[Epoch 12, Batch 200] loss: 0.016859345799311996
[Epoch 12, Batch 300] loss: 0.01829631586209871
**STATS for Epoch 12** : 
Average training loss: 0.0031
Average validation loss: 0.0401
Validation Accuracy: 0.9872
Overfitting: 0.0370
Best model saved at epoch 12 with validation loss: 0.0401
[Epoch 13, Batch 100] loss: 0.01129873598460108
[Epoch 13, Batch 200] loss: 0.01074253663100535
[Epoch 13, Batch 300] loss: 0.015355701072257944
**STATS for Epoch 13** : 
Average training loss: 0.0031
Average validation loss: 0.0584
Validation Accuracy: 0.9825
Overfitting: 0.0553
[Epoch 14, Batch 100] loss: 0.013771809793834109
[Epoch 14, Batch 200] loss: 0.01198842414014507
[Epoch 14, Batch 300] loss: 0.011336565483215964
**STATS for Epoch 14** : 
Average training loss: 0.0020
Average validation loss: 0.0429
Validation Accuracy: 0.9879
Overfitting: 0.0409
[Epoch 15, Batch 100] loss: 0.008415465174330165
[Epoch 15, Batch 200] loss: 0.010300561195181216
[Epoch 15, Batch 300] loss: 0.010324810997408349
**STATS for Epoch 15** : 
Average training loss: 0.0025
Average validation loss: 0.0405
Validation Accuracy: 0.9887
Overfitting: 0.0380
[Epoch 16, Batch 100] loss: 0.0068298885595868344
[Epoch 16, Batch 200] loss: 0.008391730740113417
[Epoch 16, Batch 300] loss: 0.01006519155605929
**STATS for Epoch 16** : 
Average training loss: 0.0024
Average validation loss: 0.0518
Validation Accuracy: 0.9869
Overfitting: 0.0494
[Epoch 17, Batch 100] loss: 0.005285507587977918
[Epoch 17, Batch 200] loss: 0.008372093711514025
[Epoch 17, Batch 300] loss: 0.00829221579231671
**STATS for Epoch 17** : 
Average training loss: 0.0022
Average validation loss: 0.0508
Validation Accuracy: 0.9862
Overfitting: 0.0486
[Epoch 18, Batch 100] loss: 0.0079023041795881
[Epoch 18, Batch 200] loss: 0.0061225590686808575
[Epoch 18, Batch 300] loss: 0.006706707547855331
**STATS for Epoch 18** : 
Average training loss: 0.0021
Average validation loss: 0.0467
Validation Accuracy: 0.9877
Overfitting: 0.0446
[Epoch 19, Batch 100] loss: 0.005277274414693238
[Epoch 19, Batch 200] loss: 0.008951389081194066
[Epoch 19, Batch 300] loss: 0.007884301553713158
**STATS for Epoch 19** : 
Average training loss: 0.0020
Average validation loss: 0.0616
Validation Accuracy: 0.9848
Overfitting: 0.0596
[Epoch 20, Batch 100] loss: 0.007021035345023847
[Epoch 20, Batch 200] loss: 0.005186944593588123
[Epoch 20, Batch 300] loss: 0.006752939481812064
**STATS for Epoch 20** : 
Average training loss: 0.0018
Average validation loss: 0.0498
Validation Accuracy: 0.9882
Overfitting: 0.0480
[Epoch 21, Batch 100] loss: 0.006146884519548621
[Epoch 21, Batch 200] loss: 0.005922466126648942
[Epoch 21, Batch 300] loss: 0.004981086775660515
**STATS for Epoch 21** : 
Average training loss: 0.0014
Average validation loss: 0.0548
Validation Accuracy: 0.9850
Overfitting: 0.0534
[Epoch 22, Batch 100] loss: 0.004162880422154558
[Epoch 22, Batch 200] loss: 0.0037260673869604945
[Epoch 22, Batch 300] loss: 0.003613629936662619
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0487
Validation Accuracy: 0.9879
Overfitting: 0.0482
[Epoch 23, Batch 100] loss: 0.003625285132748104
[Epoch 23, Batch 200] loss: 0.0020079649010585855
[Epoch 23, Batch 300] loss: 0.0024704775004283875
**STATS for Epoch 23** : 
Average training loss: 0.0007
Average validation loss: 0.0535
Validation Accuracy: 0.9871
Overfitting: 0.0528
[Epoch 24, Batch 100] loss: 0.0015934217062567768
[Epoch 24, Batch 200] loss: 0.0017964159515577193
[Epoch 24, Batch 300] loss: 0.0013855423968379909
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0522
Validation Accuracy: 0.9880
Overfitting: 0.0518
Fold 4 validation loss: 0.0522
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 1.546638326048851
[Epoch 1, Batch 200] loss: 0.3738869085907936
[Epoch 1, Batch 300] loss: 0.225670622959733
**STATS for Epoch 1** : 
Average training loss: 0.0348
Average validation loss: 0.1499
Validation Accuracy: 0.9570
Overfitting: 0.1151
Best model saved at epoch 1 with validation loss: 0.1499
[Epoch 2, Batch 100] loss: 0.15220191217958928
[Epoch 2, Batch 200] loss: 0.13221952617168425
[Epoch 2, Batch 300] loss: 0.10644412191584707
**STATS for Epoch 2** : 
Average training loss: 0.0201
Average validation loss: 0.1189
Validation Accuracy: 0.9653
Overfitting: 0.0988
Best model saved at epoch 2 with validation loss: 0.1189
[Epoch 3, Batch 100] loss: 0.08905681066215038
[Epoch 3, Batch 200] loss: 0.08724386354908348
[Epoch 3, Batch 300] loss: 0.08427544339559973
**STATS for Epoch 3** : 
Average training loss: 0.0152
Average validation loss: 0.0891
Validation Accuracy: 0.9735
Overfitting: 0.0738
Best model saved at epoch 3 with validation loss: 0.0891
[Epoch 4, Batch 100] loss: 0.06532198639586567
[Epoch 4, Batch 200] loss: 0.06433738371357321
[Epoch 4, Batch 300] loss: 0.06400499188341201
**STATS for Epoch 4** : 
Average training loss: 0.0119
Average validation loss: 0.0747
Validation Accuracy: 0.9778
Overfitting: 0.0628
Best model saved at epoch 4 with validation loss: 0.0747
[Epoch 5, Batch 100] loss: 0.0521105771465227
[Epoch 5, Batch 200] loss: 0.050297689074650404
[Epoch 5, Batch 300] loss: 0.04684702541213483
**STATS for Epoch 5** : 
Average training loss: 0.0100
Average validation loss: 0.0659
Validation Accuracy: 0.9797
Overfitting: 0.0559
Best model saved at epoch 5 with validation loss: 0.0659
[Epoch 6, Batch 100] loss: 0.04152408747933805
[Epoch 6, Batch 200] loss: 0.045383179392665625
[Epoch 6, Batch 300] loss: 0.04285098861902952
**STATS for Epoch 6** : 
Average training loss: 0.0069
Average validation loss: 0.0629
Validation Accuracy: 0.9809
Overfitting: 0.0560
Best model saved at epoch 6 with validation loss: 0.0629
[Epoch 7, Batch 100] loss: 0.03863477422390133
[Epoch 7, Batch 200] loss: 0.037460147752426565
[Epoch 7, Batch 300] loss: 0.03449334749020636
**STATS for Epoch 7** : 
Average training loss: 0.0067
Average validation loss: 0.0516
Validation Accuracy: 0.9846
Overfitting: 0.0449
Best model saved at epoch 7 with validation loss: 0.0516
[Epoch 8, Batch 100] loss: 0.03061961067141965
[Epoch 8, Batch 200] loss: 0.029204868283122777
[Epoch 8, Batch 300] loss: 0.03306299768388271
**STATS for Epoch 8** : 
Average training loss: 0.0059
Average validation loss: 0.0498
Validation Accuracy: 0.9854
Overfitting: 0.0438
Best model saved at epoch 8 with validation loss: 0.0498
[Epoch 9, Batch 100] loss: 0.02509714939747937
[Epoch 9, Batch 200] loss: 0.02741645963746123
[Epoch 9, Batch 300] loss: 0.032026980484370145
**STATS for Epoch 9** : 
Average training loss: 0.0052
Average validation loss: 0.0477
Validation Accuracy: 0.9862
Overfitting: 0.0425
Best model saved at epoch 9 with validation loss: 0.0477
[Epoch 10, Batch 100] loss: 0.016936514107510448
[Epoch 10, Batch 200] loss: 0.02728830252075568
[Epoch 10, Batch 300] loss: 0.024550386080518363
**STATS for Epoch 10** : 
Average training loss: 0.0043
Average validation loss: 0.0456
Validation Accuracy: 0.9866
Overfitting: 0.0413
Best model saved at epoch 10 with validation loss: 0.0456
[Epoch 11, Batch 100] loss: 0.018521219390677288
[Epoch 11, Batch 200] loss: 0.0184844586730469
[Epoch 11, Batch 300] loss: 0.019591287022922187
**STATS for Epoch 11** : 
Average training loss: 0.0042
Average validation loss: 0.0446
Validation Accuracy: 0.9880
Overfitting: 0.0404
Best model saved at epoch 11 with validation loss: 0.0446
[Epoch 12, Batch 100] loss: 0.014343701254110783
[Epoch 12, Batch 200] loss: 0.015217468818300404
[Epoch 12, Batch 300] loss: 0.015451723684673197
**STATS for Epoch 12** : 
Average training loss: 0.0037
Average validation loss: 0.0522
Validation Accuracy: 0.9848
Overfitting: 0.0484
[Epoch 13, Batch 100] loss: 0.014418109206017106
[Epoch 13, Batch 200] loss: 0.01617720963375177
[Epoch 13, Batch 300] loss: 0.014511132684419862
**STATS for Epoch 13** : 
Average training loss: 0.0037
Average validation loss: 0.0446
Validation Accuracy: 0.9876
Overfitting: 0.0409
[Epoch 14, Batch 100] loss: 0.010970768461702392
[Epoch 14, Batch 200] loss: 0.009614510155515746
[Epoch 14, Batch 300] loss: 0.011952230962051544
**STATS for Epoch 14** : 
Average training loss: 0.0029
Average validation loss: 0.0478
Validation Accuracy: 0.9870
Overfitting: 0.0449
[Epoch 15, Batch 100] loss: 0.009472890738688875
[Epoch 15, Batch 200] loss: 0.010122318367939443
[Epoch 15, Batch 300] loss: 0.012165519477566705
**STATS for Epoch 15** : 
Average training loss: 0.0026
Average validation loss: 0.0526
Validation Accuracy: 0.9852
Overfitting: 0.0500
[Epoch 16, Batch 100] loss: 0.008464379245997406
[Epoch 16, Batch 200] loss: 0.009557901307707652
[Epoch 16, Batch 300] loss: 0.015774582426529377
**STATS for Epoch 16** : 
Average training loss: 0.0028
Average validation loss: 0.0494
Validation Accuracy: 0.9868
Overfitting: 0.0466
[Epoch 17, Batch 100] loss: 0.00584247686623712
[Epoch 17, Batch 200] loss: 0.0095526738037006
[Epoch 17, Batch 300] loss: 0.00932033965305891
**STATS for Epoch 17** : 
Average training loss: 0.0013
Average validation loss: 0.0490
Validation Accuracy: 0.9875
Overfitting: 0.0476
[Epoch 18, Batch 100] loss: 0.007512847639154643
[Epoch 18, Batch 200] loss: 0.007021509482583497
[Epoch 18, Batch 300] loss: 0.005568130485189613
**STATS for Epoch 18** : 
Average training loss: 0.0020
Average validation loss: 0.0489
Validation Accuracy: 0.9877
Overfitting: 0.0469
[Epoch 19, Batch 100] loss: 0.006390649096283596
[Epoch 19, Batch 200] loss: 0.004983824927112437
[Epoch 19, Batch 300] loss: 0.008293607335435809
**STATS for Epoch 19** : 
Average training loss: 0.0017
Average validation loss: 0.0566
Validation Accuracy: 0.9876
Overfitting: 0.0549
[Epoch 20, Batch 100] loss: 0.009508414005395024
[Epoch 20, Batch 200] loss: 0.012794302000111201
[Epoch 20, Batch 300] loss: 0.00855079351553286
**STATS for Epoch 20** : 
Average training loss: 0.0012
Average validation loss: 0.0569
Validation Accuracy: 0.9864
Overfitting: 0.0557
[Epoch 21, Batch 100] loss: 0.0055050118394865425
[Epoch 21, Batch 200] loss: 0.008727370377382613
[Epoch 21, Batch 300] loss: 0.006544610975106479
**STATS for Epoch 21** : 
Average training loss: 0.0010
Average validation loss: 0.0476
Validation Accuracy: 0.9890
Overfitting: 0.0466
[Epoch 22, Batch 100] loss: 0.003920478744403226
[Epoch 22, Batch 200] loss: 0.003951495577348396
[Epoch 22, Batch 300] loss: 0.0038688631271361373
**STATS for Epoch 22** : 
Average training loss: 0.0013
Average validation loss: 0.0501
Validation Accuracy: 0.9884
Overfitting: 0.0488
[Epoch 23, Batch 100] loss: 0.004658960314336582
[Epoch 23, Batch 200] loss: 0.004880514934338862
[Epoch 23, Batch 300] loss: 0.004758827252371703
**STATS for Epoch 23** : 
Average training loss: 0.0019
Average validation loss: 0.0597
Validation Accuracy: 0.9856
Overfitting: 0.0578
[Epoch 24, Batch 100] loss: 0.0036693904286221367
[Epoch 24, Batch 200] loss: 0.006293373601365602
[Epoch 24, Batch 300] loss: 0.005060079312679591
**STATS for Epoch 24** : 
Average training loss: 0.0010
Average validation loss: 0.0508
Validation Accuracy: 0.9885
Overfitting: 0.0498
Fold 5 validation loss: 0.0508
Mean validation loss across all folds for Trial 10 is 0.0562 with trial config:  l1: 256, l2: 64, lr: 0.009053062590497972, batch_size: 128
[I 2024-12-10 07:48:20,628] Trial 9 finished with value: 0.05619467794961739 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.009053062590497972, 'batch_size': 128}. Best is trial 4 with value: 0.046893630782967134.

Selected Hyperparameters for Trial 11:
  l1: 128, l2: 128, lr: 0.00017288172462230452, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3064596700668334
[Epoch 1, Batch 200] loss: 2.300275568962097
[Epoch 1, Batch 300] loss: 2.2948228240013124
[Epoch 1, Batch 400] loss: 2.289070415496826
[Epoch 1, Batch 500] loss: 2.285539216995239
[Epoch 1, Batch 600] loss: 2.2787561297416685
[Epoch 1, Batch 700] loss: 2.2694741749763487
[Epoch 1, Batch 800] loss: 2.2604186224937437
[Epoch 1, Batch 900] loss: 2.2483435010910036
[Epoch 1, Batch 1000] loss: 2.233250343799591
[Epoch 1, Batch 1100] loss: 2.2134649538993836
[Epoch 1, Batch 1200] loss: 2.190498361587524
[Epoch 1, Batch 1300] loss: 2.1566043996810915
[Epoch 1, Batch 1400] loss: 2.1040267896652223
[Epoch 1, Batch 1500] loss: 2.0282342445850374
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 1.9825
Validation Accuracy: 0.5245
Overfitting: 1.9825
Best model saved at epoch 1 with validation loss: 1.9825
[Epoch 2, Batch 100] loss: 1.9165785920619964
[Epoch 2, Batch 200] loss: 1.775014590024948
[Epoch 2, Batch 300] loss: 1.5857369565963746
[Epoch 2, Batch 400] loss: 1.3528801500797272
[Epoch 2, Batch 500] loss: 1.1311628383398056
[Epoch 2, Batch 600] loss: 0.9303353559970856
[Epoch 2, Batch 700] loss: 0.794586486518383
[Epoch 2, Batch 800] loss: 0.7152765014767647
[Epoch 2, Batch 900] loss: 0.6423895379900932
[Epoch 2, Batch 1000] loss: 0.6346006932854652
[Epoch 2, Batch 1100] loss: 0.5533249706029892
[Epoch 2, Batch 1200] loss: 0.5153176948428154
[Epoch 2, Batch 1300] loss: 0.4966456052660942
[Epoch 2, Batch 1400] loss: 0.45923444226384164
[Epoch 2, Batch 1500] loss: 0.43810368806123734
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.4351
Validation Accuracy: 0.8741
Overfitting: 0.4351
Best model saved at epoch 2 with validation loss: 0.4351
[Epoch 3, Batch 100] loss: 0.4242242154479027
[Epoch 3, Batch 200] loss: 0.42379782393574716
[Epoch 3, Batch 300] loss: 0.39532390832901
[Epoch 3, Batch 400] loss: 0.40749773383140564
[Epoch 3, Batch 500] loss: 0.4014502616971731
[Epoch 3, Batch 600] loss: 0.389835067242384
[Epoch 3, Batch 700] loss: 0.38549845017492773
[Epoch 3, Batch 800] loss: 0.3499855060875416
[Epoch 3, Batch 900] loss: 0.36418002627789975
[Epoch 3, Batch 1000] loss: 0.3262985423207283
[Epoch 3, Batch 1100] loss: 0.3284469848871231
[Epoch 3, Batch 1200] loss: 0.32497339099645617
[Epoch 3, Batch 1300] loss: 0.3424381534010172
[Epoch 3, Batch 1400] loss: 0.3461895915865898
[Epoch 3, Batch 1500] loss: 0.30689178831875324
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.2989
Validation Accuracy: 0.9097
Overfitting: 0.2989
Best model saved at epoch 3 with validation loss: 0.2989
[Epoch 4, Batch 100] loss: 0.29936960101127624
[Epoch 4, Batch 200] loss: 0.32437752187252045
[Epoch 4, Batch 300] loss: 0.3047062523663044
[Epoch 4, Batch 400] loss: 0.28966569900512695
[Epoch 4, Batch 500] loss: 0.29433514714241027
[Epoch 4, Batch 600] loss: 0.27135961435735223
[Epoch 4, Batch 700] loss: 0.2829379915446043
[Epoch 4, Batch 800] loss: 0.26202554561197755
[Epoch 4, Batch 900] loss: 0.26259293138980866
[Epoch 4, Batch 1000] loss: 0.2481270258128643
[Epoch 4, Batch 1100] loss: 0.24874757803976535
[Epoch 4, Batch 1200] loss: 0.26377188302576543
[Epoch 4, Batch 1300] loss: 0.2704774739965796
[Epoch 4, Batch 1400] loss: 0.26190174635499713
[Epoch 4, Batch 1500] loss: 0.23922610472887754
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.2379
Validation Accuracy: 0.9293
Overfitting: 0.2379
Best model saved at epoch 4 with validation loss: 0.2379
[Epoch 5, Batch 100] loss: 0.22524017464369536
[Epoch 5, Batch 200] loss: 0.23437204118818045
[Epoch 5, Batch 300] loss: 0.23078763652592899
[Epoch 5, Batch 400] loss: 0.22743966210633515
[Epoch 5, Batch 500] loss: 0.23916336238384248
[Epoch 5, Batch 600] loss: 0.228414045907557
[Epoch 5, Batch 700] loss: 0.20812713947147132
[Epoch 5, Batch 800] loss: 0.2070760628208518
[Epoch 5, Batch 900] loss: 0.22053606081753968
[Epoch 5, Batch 1000] loss: 0.21684215985238553
[Epoch 5, Batch 1100] loss: 0.2376893476769328
[Epoch 5, Batch 1200] loss: 0.21571326065808535
[Epoch 5, Batch 1300] loss: 0.21230205938220023
[Epoch 5, Batch 1400] loss: 0.19988406678661705
[Epoch 5, Batch 1500] loss: 0.23779302701354027
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1966
Validation Accuracy: 0.9406
Overfitting: 0.1966
Best model saved at epoch 5 with validation loss: 0.1966
[Epoch 6, Batch 100] loss: 0.20661328194662928
[Epoch 6, Batch 200] loss: 0.20738275837153197
[Epoch 6, Batch 300] loss: 0.20599341226741671
[Epoch 6, Batch 400] loss: 0.20423175865784288
[Epoch 6, Batch 500] loss: 0.1745557607896626
[Epoch 6, Batch 600] loss: 0.19409776166081427
[Epoch 6, Batch 700] loss: 0.1684533934108913
[Epoch 6, Batch 800] loss: 0.18537426963448525
[Epoch 6, Batch 900] loss: 0.16335590582340956
[Epoch 6, Batch 1000] loss: 0.1880977277830243
[Epoch 6, Batch 1100] loss: 0.1788153936713934
[Epoch 6, Batch 1200] loss: 0.20236786801367998
[Epoch 6, Batch 1300] loss: 0.18537853620946407
[Epoch 6, Batch 1400] loss: 0.17408598124980926
[Epoch 6, Batch 1500] loss: 0.1542074842751026
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.1682
Validation Accuracy: 0.9495
Overfitting: 0.1682
[I 2024-12-10 07:49:33,589] Trial 10 pruned. 

Selected Hyperparameters for Trial 12:
  l1: 128, l2: 128, lr: 0.0005464615115107326, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2943299293518065
[Epoch 1, Batch 200] loss: 2.282640769481659
[Epoch 1, Batch 300] loss: 2.2659724307060243
[Epoch 1, Batch 400] loss: 2.2345975470542907
[Epoch 1, Batch 500] loss: 2.1628760266304017
[Epoch 1, Batch 600] loss: 1.923325628042221
[Epoch 1, Batch 700] loss: 1.3203593051433564
[Epoch 1, Batch 800] loss: 0.7814432647824288
[Epoch 1, Batch 900] loss: 0.6004980240762233
[Epoch 1, Batch 1000] loss: 0.4834804208576679
[Epoch 1, Batch 1100] loss: 0.4093868887424469
[Epoch 1, Batch 1200] loss: 0.37890865579247474
[Epoch 1, Batch 1300] loss: 0.36515308387577533
[Epoch 1, Batch 1400] loss: 0.3699097742885351
[Epoch 1, Batch 1500] loss: 0.35922476582229135
[Epoch 1, Batch 1600] loss: 0.322656220048666
[Epoch 1, Batch 1700] loss: 0.28767811875790356
[Epoch 1, Batch 1800] loss: 0.301356996782124
[Epoch 1, Batch 1900] loss: 0.2687903457507491
[Epoch 1, Batch 2000] loss: 0.2884115993976593
[Epoch 1, Batch 2100] loss: 0.24279618050903082
[Epoch 1, Batch 2200] loss: 0.26373681347817185
[Epoch 1, Batch 2300] loss: 0.22873248431831597
[Epoch 1, Batch 2400] loss: 0.22208064473234118
[Epoch 1, Batch 2500] loss: 0.20980659862980247
[Epoch 1, Batch 2600] loss: 0.22380499245598912
[Epoch 1, Batch 2700] loss: 0.19620563775766642
[Epoch 1, Batch 2800] loss: 0.19731202629394828
[Epoch 1, Batch 2900] loss: 0.18625408509746194
[Epoch 1, Batch 3000] loss: 0.19801416208967568
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1608
Validation Accuracy: 0.9533
Overfitting: 0.1608
Best model saved at epoch 1 with validation loss: 0.1608
[Epoch 2, Batch 100] loss: 0.18269497700035572
[Epoch 2, Batch 200] loss: 0.1426398420520127
[Epoch 2, Batch 300] loss: 0.17138019325211645
[Epoch 2, Batch 400] loss: 0.1873459553718567
[Epoch 2, Batch 500] loss: 0.16700265194289388
[Epoch 2, Batch 600] loss: 0.1640293119568378
[Epoch 2, Batch 700] loss: 0.1387555815652013
[Epoch 2, Batch 800] loss: 0.13448856687173247
[Epoch 2, Batch 900] loss: 0.1415087378351018
[Epoch 2, Batch 1000] loss: 0.14833885803818703
[Epoch 2, Batch 1100] loss: 0.12973904630169272
[Epoch 2, Batch 1200] loss: 0.14293472168967128
[Epoch 2, Batch 1300] loss: 0.16014942057896406
[Epoch 2, Batch 1400] loss: 0.13544669955503197
[Epoch 2, Batch 1500] loss: 0.13541513149626552
[Epoch 2, Batch 1600] loss: 0.11581014555878938
[Epoch 2, Batch 1700] loss: 0.1253615164756775
[Epoch 2, Batch 1800] loss: 0.15064909759908915
[Epoch 2, Batch 1900] loss: 0.13144771313294767
[Epoch 2, Batch 2000] loss: 0.11027383647859096
[Epoch 2, Batch 2100] loss: 0.12241701225750148
[Epoch 2, Batch 2200] loss: 0.1521218273928389
[Epoch 2, Batch 2300] loss: 0.09665990252047778
[Epoch 2, Batch 2400] loss: 0.11290981461061164
[Epoch 2, Batch 2500] loss: 0.1124476049747318
[Epoch 2, Batch 2600] loss: 0.09639769269153475
[Epoch 2, Batch 2700] loss: 0.1152048233244568
[Epoch 2, Batch 2800] loss: 0.12088409466203302
[Epoch 2, Batch 2900] loss: 0.107520679642912
[Epoch 2, Batch 3000] loss: 0.10249090678058564
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1022
Validation Accuracy: 0.9690
Overfitting: 0.1022
Best model saved at epoch 2 with validation loss: 0.1022
[Epoch 3, Batch 100] loss: 0.10052056355634705
[Epoch 3, Batch 200] loss: 0.0824388956266921
[Epoch 3, Batch 300] loss: 0.08217453459044918
[Epoch 3, Batch 400] loss: 0.10089009507326409
[Epoch 3, Batch 500] loss: 0.0977234055986628
[Epoch 3, Batch 600] loss: 0.10974550747312606
[Epoch 3, Batch 700] loss: 0.08276948693906888
[Epoch 3, Batch 800] loss: 0.10869633446680382
[Epoch 3, Batch 900] loss: 0.06866549622733147
[Epoch 3, Batch 1000] loss: 0.09432703359751031
[Epoch 3, Batch 1100] loss: 0.09192672190256417
[Epoch 3, Batch 1200] loss: 0.07621733112027869
[Epoch 3, Batch 1300] loss: 0.10808921827701852
[Epoch 3, Batch 1400] loss: 0.09520552544854581
[Epoch 3, Batch 1500] loss: 0.08898240141104907
[Epoch 3, Batch 1600] loss: 0.07586089867749252
[Epoch 3, Batch 1700] loss: 0.08568330047768541
[Epoch 3, Batch 1800] loss: 0.07713359709479846
[Epoch 3, Batch 1900] loss: 0.08280216958140954
[Epoch 3, Batch 2000] loss: 0.08663679582299665
[Epoch 3, Batch 2100] loss: 0.09327149238670245
[Epoch 3, Batch 2200] loss: 0.07488907549821305
[Epoch 3, Batch 2300] loss: 0.09447483887313865
[Epoch 3, Batch 2400] loss: 0.07827555648167618
[Epoch 3, Batch 2500] loss: 0.08126627959893085
[Epoch 3, Batch 2600] loss: 0.10695883327629417
[Epoch 3, Batch 2700] loss: 0.08166941637755372
[Epoch 3, Batch 2800] loss: 0.10702708870521746
[Epoch 3, Batch 2900] loss: 0.07196130903437734
[Epoch 3, Batch 3000] loss: 0.08254345661960542
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0769
Validation Accuracy: 0.9764
Overfitting: 0.0769
Best model saved at epoch 3 with validation loss: 0.0769
[Epoch 4, Batch 100] loss: 0.07470599265769123
[Epoch 4, Batch 200] loss: 0.06822743474738673
[Epoch 4, Batch 300] loss: 0.09074929589929524
[Epoch 4, Batch 400] loss: 0.06456081099575385
[Epoch 4, Batch 500] loss: 0.08619191949255764
[Epoch 4, Batch 600] loss: 0.06720449885819108
[Epoch 4, Batch 700] loss: 0.07234038772410713
[Epoch 4, Batch 800] loss: 0.08711058507789858
[Epoch 4, Batch 900] loss: 0.05830718490469735
[Epoch 4, Batch 1000] loss: 0.07438567601609974
[Epoch 4, Batch 1100] loss: 0.07392923261388205
[Epoch 4, Batch 1200] loss: 0.06429952686710749
[Epoch 4, Batch 1300] loss: 0.07256273055099882
[Epoch 4, Batch 1400] loss: 0.06653404553886504
[Epoch 4, Batch 1500] loss: 0.07928119209012947
[Epoch 4, Batch 1600] loss: 0.06459672920638695
[Epoch 4, Batch 1700] loss: 0.08407121249474585
[Epoch 4, Batch 1800] loss: 0.07521258168155327
[Epoch 4, Batch 1900] loss: 0.06919090249110013
[Epoch 4, Batch 2000] loss: 0.06620868488040287
[Epoch 4, Batch 2100] loss: 0.050620921083027494
[Epoch 4, Batch 2200] loss: 0.07343188919825479
[Epoch 4, Batch 2300] loss: 0.06242511568649206
[Epoch 4, Batch 2400] loss: 0.05441205914714373
[Epoch 4, Batch 2500] loss: 0.05618222696240991
[Epoch 4, Batch 2600] loss: 0.07887843638309278
[Epoch 4, Batch 2700] loss: 0.07329324799997267
[Epoch 4, Batch 2800] loss: 0.06797929648775608
[Epoch 4, Batch 2900] loss: 0.059738096873625184
[Epoch 4, Batch 3000] loss: 0.05901681178133003
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0643
Validation Accuracy: 0.9802
Overfitting: 0.0643
Best model saved at epoch 4 with validation loss: 0.0643
[Epoch 5, Batch 100] loss: 0.0635768741281936
[Epoch 5, Batch 200] loss: 0.06380734990583732
[Epoch 5, Batch 300] loss: 0.05597128246794455
[Epoch 5, Batch 400] loss: 0.059977752514532766
[Epoch 5, Batch 500] loss: 0.06258065339876338
[Epoch 5, Batch 600] loss: 0.08271494908374734
[Epoch 5, Batch 700] loss: 0.04832724008825608
[Epoch 5, Batch 800] loss: 0.06319866616046056
[Epoch 5, Batch 900] loss: 0.06153088738967199
[Epoch 5, Batch 1000] loss: 0.05507181605848018
[Epoch 5, Batch 1100] loss: 0.04680348209629301
[Epoch 5, Batch 1200] loss: 0.06900625153677538
[Epoch 5, Batch 1300] loss: 0.040852162394439805
[Epoch 5, Batch 1400] loss: 0.07275323527748696
[Epoch 5, Batch 1500] loss: 0.0544435591052752
[Epoch 5, Batch 1600] loss: 0.0623322283453308
[Epoch 5, Batch 1700] loss: 0.06903432340652216
[Epoch 5, Batch 1800] loss: 0.0507428911246825
[Epoch 5, Batch 1900] loss: 0.05836409944691695
[Epoch 5, Batch 2000] loss: 0.06612996613257564
[Epoch 5, Batch 2100] loss: 0.03013088974810671
[Epoch 5, Batch 2200] loss: 0.05503277456475189
[Epoch 5, Batch 2300] loss: 0.05459525942700566
[Epoch 5, Batch 2400] loss: 0.07640069723915076
[Epoch 5, Batch 2500] loss: 0.07887427867040969
[Epoch 5, Batch 2600] loss: 0.04627172996755689
[Epoch 5, Batch 2700] loss: 0.047061836015782316
[Epoch 5, Batch 2800] loss: 0.0526756608847063
[Epoch 5, Batch 2900] loss: 0.04847904273599852
[Epoch 5, Batch 3000] loss: 0.05407667361549102
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9827
Overfitting: 0.0605
Best model saved at epoch 5 with validation loss: 0.0605
[Epoch 6, Batch 100] loss: 0.05840476345212665
[Epoch 6, Batch 200] loss: 0.04884360890195239
[Epoch 6, Batch 300] loss: 0.05354014119278872
[Epoch 6, Batch 400] loss: 0.04134566202905262
[Epoch 6, Batch 500] loss: 0.05700833480863366
[Epoch 6, Batch 600] loss: 0.058948228388326245
[Epoch 6, Batch 700] loss: 0.051985561860492455
[Epoch 6, Batch 800] loss: 0.04720344907807885
[Epoch 6, Batch 900] loss: 0.03939811993739568
[Epoch 6, Batch 1000] loss: 0.03422388984647114
[Epoch 6, Batch 1100] loss: 0.04784078730852343
[Epoch 6, Batch 1200] loss: 0.06273231671948451
[Epoch 6, Batch 1300] loss: 0.05836139678955078
[Epoch 6, Batch 1400] loss: 0.05863220049504889
[Epoch 6, Batch 1500] loss: 0.05382602966914419
[Epoch 6, Batch 1600] loss: 0.05002574441256002
[Epoch 6, Batch 1700] loss: 0.04005931236373726
[Epoch 6, Batch 1800] loss: 0.05405220015323721
[Epoch 6, Batch 1900] loss: 0.04701258736226009
[Epoch 6, Batch 2000] loss: 0.05499238164862618
[Epoch 6, Batch 2100] loss: 0.06271023822337156
[Epoch 6, Batch 2200] loss: 0.047348292354727164
[Epoch 6, Batch 2300] loss: 0.05418643895071
[Epoch 6, Batch 2400] loss: 0.035759815063793214
[Epoch 6, Batch 2500] loss: 0.0509447766590165
[Epoch 6, Batch 2600] loss: 0.04266661830886733
[Epoch 6, Batch 2700] loss: 0.03656417831487488
[Epoch 6, Batch 2800] loss: 0.06628943587376852
[Epoch 6, Batch 2900] loss: 0.045368422152096174
[Epoch 6, Batch 3000] loss: 0.054009012906317364
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0667
Validation Accuracy: 0.9793
Overfitting: 0.0667
[I 2024-12-10 07:51:07,350] Trial 11 pruned. 

Selected Hyperparameters for Trial 13:
  l1: 128, l2: 128, lr: 0.0010872222491939436, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.299599549770355
[Epoch 1, Batch 200] loss: 2.2703468084335325
[Epoch 1, Batch 300] loss: 2.1826721358299257
**STATS for Epoch 1** : 
Average training loss: 0.3479
Average validation loss: 1.2162
Validation Accuracy: 0.7382
Overfitting: 0.8682
Best model saved at epoch 1 with validation loss: 1.2162
[Epoch 2, Batch 100] loss: 0.7331431382894515
[Epoch 2, Batch 200] loss: 0.4415193024277687
[Epoch 2, Batch 300] loss: 0.3547895610332489
**STATS for Epoch 2** : 
Average training loss: 0.0641
Average validation loss: 0.2869
Validation Accuracy: 0.9150
Overfitting: 0.2227
Best model saved at epoch 2 with validation loss: 0.2869
[Epoch 3, Batch 100] loss: 0.27220367804169654
[Epoch 3, Batch 200] loss: 0.25715228900313375
[Epoch 3, Batch 300] loss: 0.23519039265811442
**STATS for Epoch 3** : 
Average training loss: 0.0433
Average validation loss: 0.1978
Validation Accuracy: 0.9405
Overfitting: 0.1546
Best model saved at epoch 3 with validation loss: 0.1978
[Epoch 4, Batch 100] loss: 0.19654747933149339
[Epoch 4, Batch 200] loss: 0.17998637638986112
[Epoch 4, Batch 300] loss: 0.17386176511645318
**STATS for Epoch 4** : 
Average training loss: 0.0330
Average validation loss: 0.1559
Validation Accuracy: 0.9539
Overfitting: 0.1229
Best model saved at epoch 4 with validation loss: 0.1559
[Epoch 5, Batch 100] loss: 0.14830962501466274
[Epoch 5, Batch 200] loss: 0.14339180912822486
[Epoch 5, Batch 300] loss: 0.14857292842119932
**STATS for Epoch 5** : 
Average training loss: 0.0272
Average validation loss: 0.1226
Validation Accuracy: 0.9636
Overfitting: 0.0954
Best model saved at epoch 5 with validation loss: 0.1226
[Epoch 6, Batch 100] loss: 0.13272287838160993
[Epoch 6, Batch 200] loss: 0.12240891993045806
[Epoch 6, Batch 300] loss: 0.11711261134594679
**STATS for Epoch 6** : 
Average training loss: 0.0226
Average validation loss: 0.1036
Validation Accuracy: 0.9687
Overfitting: 0.0811
[I 2024-12-10 07:52:05,952] Trial 12 pruned. 

Selected Hyperparameters for Trial 14:
  l1: 256, l2: 128, lr: 0.0005688161395509089, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.298395631313324
[Epoch 1, Batch 200] loss: 2.2804869079589842
[Epoch 1, Batch 300] loss: 2.2486449813842775
[Epoch 1, Batch 400] loss: 2.181070740222931
[Epoch 1, Batch 500] loss: 1.9337333202362061
[Epoch 1, Batch 600] loss: 1.2290923768281936
[Epoch 1, Batch 700] loss: 0.7462278547883033
[Epoch 1, Batch 800] loss: 0.620719061344862
[Epoch 1, Batch 900] loss: 0.5591151776909828
[Epoch 1, Batch 1000] loss: 0.49348966404795647
[Epoch 1, Batch 1100] loss: 0.4716854150593281
[Epoch 1, Batch 1200] loss: 0.4197673802450299
[Epoch 1, Batch 1300] loss: 0.39899553172290325
[Epoch 1, Batch 1400] loss: 0.3751405418664217
[Epoch 1, Batch 1500] loss: 0.3903098746389151
[Epoch 1, Batch 1600] loss: 0.33977861315011976
[Epoch 1, Batch 1700] loss: 0.296301569249481
[Epoch 1, Batch 1800] loss: 0.32504281278699637
[Epoch 1, Batch 1900] loss: 0.323028925023973
[Epoch 1, Batch 2000] loss: 0.2781699920073152
[Epoch 1, Batch 2100] loss: 0.2845481701288372
[Epoch 1, Batch 2200] loss: 0.25604746395722033
[Epoch 1, Batch 2300] loss: 0.23825821224600077
[Epoch 1, Batch 2400] loss: 0.22314646745100616
[Epoch 1, Batch 2500] loss: 0.24583687242120505
[Epoch 1, Batch 2600] loss: 0.2129343519732356
[Epoch 1, Batch 2700] loss: 0.2507556143589318
[Epoch 1, Batch 2800] loss: 0.23354396272450687
[Epoch 1, Batch 2900] loss: 0.16775434516370297
[Epoch 1, Batch 3000] loss: 0.21318955771625042
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1694
Validation Accuracy: 0.9473
Overfitting: 0.1694
Best model saved at epoch 1 with validation loss: 0.1694
[Epoch 2, Batch 100] loss: 0.21270535297691823
[Epoch 2, Batch 200] loss: 0.21594106322154402
[Epoch 2, Batch 300] loss: 0.1797958975378424
[Epoch 2, Batch 400] loss: 0.18608321506530046
[Epoch 2, Batch 500] loss: 0.17814075823873282
[Epoch 2, Batch 600] loss: 0.16163015518337487
[Epoch 2, Batch 700] loss: 0.14986264629289509
[Epoch 2, Batch 800] loss: 0.15256832505576312
[Epoch 2, Batch 900] loss: 0.16553913085721433
[Epoch 2, Batch 1000] loss: 0.17429582566488533
[Epoch 2, Batch 1100] loss: 0.1504089941550046
[Epoch 2, Batch 1200] loss: 0.18053686466999352
[Epoch 2, Batch 1300] loss: 0.14739189422689378
[Epoch 2, Batch 1400] loss: 0.13237637833692134
[Epoch 2, Batch 1500] loss: 0.12883805457735434
[Epoch 2, Batch 1600] loss: 0.12881311074830593
[Epoch 2, Batch 1700] loss: 0.12520295375958085
[Epoch 2, Batch 1800] loss: 0.11346434896346182
[Epoch 2, Batch 1900] loss: 0.11718393075279891
[Epoch 2, Batch 2000] loss: 0.13385590156540275
[Epoch 2, Batch 2100] loss: 0.1186984852468595
[Epoch 2, Batch 2200] loss: 0.10745103154797107
[Epoch 2, Batch 2300] loss: 0.14639031902421265
[Epoch 2, Batch 2400] loss: 0.14399887261446565
[Epoch 2, Batch 2500] loss: 0.14109458841383457
[Epoch 2, Batch 2600] loss: 0.11673713161144406
[Epoch 2, Batch 2700] loss: 0.11657739713322371
[Epoch 2, Batch 2800] loss: 0.10894355389289558
[Epoch 2, Batch 2900] loss: 0.12505392982624472
[Epoch 2, Batch 3000] loss: 0.11600731204496696
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1062
Validation Accuracy: 0.9657
Overfitting: 0.1062
Best model saved at epoch 2 with validation loss: 0.1062
[Epoch 3, Batch 100] loss: 0.12501095805782825
[Epoch 3, Batch 200] loss: 0.1077709145611152
[Epoch 3, Batch 300] loss: 0.09393712600693106
[Epoch 3, Batch 400] loss: 0.09415259374771268
[Epoch 3, Batch 500] loss: 0.11293534286203794
[Epoch 3, Batch 600] loss: 0.130775341168046
[Epoch 3, Batch 700] loss: 0.10358337754267267
[Epoch 3, Batch 800] loss: 0.08979702926706523
[Epoch 3, Batch 900] loss: 0.09483679588651285
[Epoch 3, Batch 1000] loss: 0.0913474629726261
[Epoch 3, Batch 1100] loss: 0.10188064118498005
[Epoch 3, Batch 1200] loss: 0.0969485166692175
[Epoch 3, Batch 1300] loss: 0.08136735158739611
[Epoch 3, Batch 1400] loss: 0.08625530210789294
[Epoch 3, Batch 1500] loss: 0.09271424969192595
[Epoch 3, Batch 1600] loss: 0.11210364569444209
[Epoch 3, Batch 1700] loss: 0.07858290053904056
[Epoch 3, Batch 1800] loss: 0.10157847035676242
[Epoch 3, Batch 1900] loss: 0.09365227307542227
[Epoch 3, Batch 2000] loss: 0.07676158548565581
[Epoch 3, Batch 2100] loss: 0.07397445274924394
[Epoch 3, Batch 2200] loss: 0.08010649303207173
[Epoch 3, Batch 2300] loss: 0.10593781167175621
[Epoch 3, Batch 2400] loss: 0.08114655184792355
[Epoch 3, Batch 2500] loss: 0.10033304687123745
[Epoch 3, Batch 2600] loss: 0.0975025066616945
[Epoch 3, Batch 2700] loss: 0.07478682945948094
[Epoch 3, Batch 2800] loss: 0.0796267447876744
[Epoch 3, Batch 2900] loss: 0.11990207897732034
[Epoch 3, Batch 3000] loss: 0.07947326780413277
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0813
Validation Accuracy: 0.9742
Overfitting: 0.0813
Best model saved at epoch 3 with validation loss: 0.0813
[Epoch 4, Batch 100] loss: 0.07211012303130701
[Epoch 4, Batch 200] loss: 0.07785230248700828
[Epoch 4, Batch 300] loss: 0.082807326518232
[Epoch 4, Batch 400] loss: 0.05907682397344615
[Epoch 4, Batch 500] loss: 0.06069819877156988
[Epoch 4, Batch 600] loss: 0.0907401858898811
[Epoch 4, Batch 700] loss: 0.06859918956062756
[Epoch 4, Batch 800] loss: 0.09323585855250713
[Epoch 4, Batch 900] loss: 0.06978682730346918
[Epoch 4, Batch 1000] loss: 0.06324275083374233
[Epoch 4, Batch 1100] loss: 0.0751906266482547
[Epoch 4, Batch 1200] loss: 0.06544538918882609
[Epoch 4, Batch 1300] loss: 0.09304167199647054
[Epoch 4, Batch 1400] loss: 0.06797003117157147
[Epoch 4, Batch 1500] loss: 0.09886495640967041
[Epoch 4, Batch 1600] loss: 0.06588960381166543
[Epoch 4, Batch 1700] loss: 0.07668395078275353
[Epoch 4, Batch 1800] loss: 0.07493296908214689
[Epoch 4, Batch 1900] loss: 0.06255509824259206
[Epoch 4, Batch 2000] loss: 0.08061115212854929
[Epoch 4, Batch 2100] loss: 0.04792088921298273
[Epoch 4, Batch 2200] loss: 0.06512656882754526
[Epoch 4, Batch 2300] loss: 0.05589572410332039
[Epoch 4, Batch 2400] loss: 0.06639267111429945
[Epoch 4, Batch 2500] loss: 0.07038665637548547
[Epoch 4, Batch 2600] loss: 0.0720058670011349
[Epoch 4, Batch 2700] loss: 0.06788928807945922
[Epoch 4, Batch 2800] loss: 0.06439517397549935
[Epoch 4, Batch 2900] loss: 0.06559767567785457
[Epoch 4, Batch 3000] loss: 0.07245490352273919
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0669
Validation Accuracy: 0.9787
Overfitting: 0.0669
Best model saved at epoch 4 with validation loss: 0.0669
[Epoch 5, Batch 100] loss: 0.05767633379786275
[Epoch 5, Batch 200] loss: 0.052974345803959294
[Epoch 5, Batch 300] loss: 0.0774821794568561
[Epoch 5, Batch 400] loss: 0.07091199762653559
[Epoch 5, Batch 500] loss: 0.043428622552310114
[Epoch 5, Batch 600] loss: 0.08083684106066358
[Epoch 5, Batch 700] loss: 0.0690327950468054
[Epoch 5, Batch 800] loss: 0.0575567287276499
[Epoch 5, Batch 900] loss: 0.06572449802653864
[Epoch 5, Batch 1000] loss: 0.07818993612891063
[Epoch 5, Batch 1100] loss: 0.052098406916484236
[Epoch 5, Batch 1200] loss: 0.05147419218788855
[Epoch 5, Batch 1300] loss: 0.0704771013656864
[Epoch 5, Batch 1400] loss: 0.06376666003721766
[Epoch 5, Batch 1500] loss: 0.047947405409649944
[Epoch 5, Batch 1600] loss: 0.045330375568009916
[Epoch 5, Batch 1700] loss: 0.050724241305142644
[Epoch 5, Batch 1800] loss: 0.051305352051858794
[Epoch 5, Batch 1900] loss: 0.06627447033592034
[Epoch 5, Batch 2000] loss: 0.059745615788269785
[Epoch 5, Batch 2100] loss: 0.07715278480405686
[Epoch 5, Batch 2200] loss: 0.04368086407484952
[Epoch 5, Batch 2300] loss: 0.06357818645483349
[Epoch 5, Batch 2400] loss: 0.06295649027975742
[Epoch 5, Batch 2500] loss: 0.05156488004577113
[Epoch 5, Batch 2600] loss: 0.06214789806632325
[Epoch 5, Batch 2700] loss: 0.0471444210014306
[Epoch 5, Batch 2800] loss: 0.043502020674059165
[Epoch 5, Batch 2900] loss: 0.04422905578510836
[Epoch 5, Batch 3000] loss: 0.05588273983827094
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9836
Overfitting: 0.0512
Best model saved at epoch 5 with validation loss: 0.0512
[Epoch 6, Batch 100] loss: 0.051227978012175296
[Epoch 6, Batch 200] loss: 0.031496116395574064
[Epoch 6, Batch 300] loss: 0.04757449729018845
[Epoch 6, Batch 400] loss: 0.06463299915427342
[Epoch 6, Batch 500] loss: 0.03785015690140426
[Epoch 6, Batch 600] loss: 0.05692660959321074
[Epoch 6, Batch 700] loss: 0.0503938186171581
[Epoch 6, Batch 800] loss: 0.03822556036408059
[Epoch 6, Batch 900] loss: 0.04624395308201201
[Epoch 6, Batch 1000] loss: 0.04484114075195975
[Epoch 6, Batch 1100] loss: 0.025131484286976046
[Epoch 6, Batch 1200] loss: 0.0400384412042331
[Epoch 6, Batch 1300] loss: 0.043709355559258256
[Epoch 6, Batch 1400] loss: 0.05724402931111399
[Epoch 6, Batch 1500] loss: 0.04603463298190036
[Epoch 6, Batch 1600] loss: 0.051956273154937664
[Epoch 6, Batch 1700] loss: 0.053019189103215465
[Epoch 6, Batch 1800] loss: 0.06095304987306008
[Epoch 6, Batch 1900] loss: 0.048122858798597005
[Epoch 6, Batch 2000] loss: 0.07861775415367447
[Epoch 6, Batch 2100] loss: 0.04235241850634339
[Epoch 6, Batch 2200] loss: 0.05444452483905479
[Epoch 6, Batch 2300] loss: 0.057420888292253947
[Epoch 6, Batch 2400] loss: 0.04215509991568979
[Epoch 6, Batch 2500] loss: 0.03981558605271857
[Epoch 6, Batch 2600] loss: 0.04770428105141036
[Epoch 6, Batch 2700] loss: 0.05502670491754543
[Epoch 6, Batch 2800] loss: 0.04779348753276281
[Epoch 6, Batch 2900] loss: 0.05512002460774965
[Epoch 6, Batch 3000] loss: 0.051126197556150145
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9833
Overfitting: 0.0532
[Epoch 7, Batch 100] loss: 0.04683960492227925
[Epoch 7, Batch 200] loss: 0.039149259702826386
[Epoch 7, Batch 300] loss: 0.048178874669538345
[Epoch 7, Batch 400] loss: 0.035815894241968634
[Epoch 7, Batch 500] loss: 0.04950055369583424
[Epoch 7, Batch 600] loss: 0.0466952586377738
[Epoch 7, Batch 700] loss: 0.053240804448141714
[Epoch 7, Batch 800] loss: 0.04860035794205032
[Epoch 7, Batch 900] loss: 0.03239265134936432
[Epoch 7, Batch 1000] loss: 0.02598054542657337
[Epoch 7, Batch 1100] loss: 0.02891652901467751
[Epoch 7, Batch 1200] loss: 0.03345371195056941
[Epoch 7, Batch 1300] loss: 0.02945219142944552
[Epoch 7, Batch 1400] loss: 0.053497812999994496
[Epoch 7, Batch 1500] loss: 0.03597309532837244
[Epoch 7, Batch 1600] loss: 0.0512946628627833
[Epoch 7, Batch 1700] loss: 0.03362386360458913
[Epoch 7, Batch 1800] loss: 0.04935472899102024
[Epoch 7, Batch 1900] loss: 0.048205760789569466
[Epoch 7, Batch 2000] loss: 0.04858492290310096
[Epoch 7, Batch 2100] loss: 0.047320494695886735
[Epoch 7, Batch 2200] loss: 0.041242329055676236
[Epoch 7, Batch 2300] loss: 0.04141316220426233
[Epoch 7, Batch 2400] loss: 0.03399386285193032
[Epoch 7, Batch 2500] loss: 0.053937686462304554
[Epoch 7, Batch 2600] loss: 0.043392833897378295
[Epoch 7, Batch 2700] loss: 0.03174907109176275
[Epoch 7, Batch 2800] loss: 0.04443254874524428
[Epoch 7, Batch 2900] loss: 0.04112028263916727
[Epoch 7, Batch 3000] loss: 0.0496919141188846
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0460
Validation Accuracy: 0.9857
Overfitting: 0.0460
Best model saved at epoch 7 with validation loss: 0.0460
[Epoch 8, Batch 100] loss: 0.02956859755795449
[Epoch 8, Batch 200] loss: 0.03284841403394239
[Epoch 8, Batch 300] loss: 0.026393985206086653
[Epoch 8, Batch 400] loss: 0.029225591871945653
[Epoch 8, Batch 500] loss: 0.03377724928228418
[Epoch 8, Batch 600] loss: 0.028484295901143923
[Epoch 8, Batch 700] loss: 0.02379524684045464
[Epoch 8, Batch 800] loss: 0.04134320372570073
[Epoch 8, Batch 900] loss: 0.040395385179144795
[Epoch 8, Batch 1000] loss: 0.02920431508886395
[Epoch 8, Batch 1100] loss: 0.0169218260346679
[Epoch 8, Batch 1200] loss: 0.030227453557672562
[Epoch 8, Batch 1300] loss: 0.0335034016208374
[Epoch 8, Batch 1400] loss: 0.061145804589032196
[Epoch 8, Batch 1500] loss: 0.037736004393955226
[Epoch 8, Batch 1600] loss: 0.039446902046038304
[Epoch 8, Batch 1700] loss: 0.04708960558637045
[Epoch 8, Batch 1800] loss: 0.04571929709156393
[Epoch 8, Batch 1900] loss: 0.032058358330396004
[Epoch 8, Batch 2000] loss: 0.038347546539444013
[Epoch 8, Batch 2100] loss: 0.04678446448349859
[Epoch 8, Batch 2200] loss: 0.04501944709976669
[Epoch 8, Batch 2300] loss: 0.03445945913263131
[Epoch 8, Batch 2400] loss: 0.03225887514679925
[Epoch 8, Batch 2500] loss: 0.029962269482493867
[Epoch 8, Batch 2600] loss: 0.041860959301120604
[Epoch 8, Batch 2700] loss: 0.056642560875043275
[Epoch 8, Batch 2800] loss: 0.03043405886310211
[Epoch 8, Batch 2900] loss: 0.03352283545100363
[Epoch 8, Batch 3000] loss: 0.03778479165601311
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9841
Overfitting: 0.0516
[Epoch 9, Batch 100] loss: 0.03810200181309483
[Epoch 9, Batch 200] loss: 0.030369770131655968
[Epoch 9, Batch 300] loss: 0.02109047351696063
[Epoch 9, Batch 400] loss: 0.031760885177063755
[Epoch 9, Batch 500] loss: 0.03508004650459043
[Epoch 9, Batch 600] loss: 0.03204729036486242
[Epoch 9, Batch 700] loss: 0.02095574754232075
[Epoch 9, Batch 800] loss: 0.03304035939640016
[Epoch 9, Batch 900] loss: 0.02602701747797255
[Epoch 9, Batch 1000] loss: 0.03895717095139844
[Epoch 9, Batch 1100] loss: 0.04641036215412896
[Epoch 9, Batch 1200] loss: 0.02264126482681604
[Epoch 9, Batch 1300] loss: 0.042844646732555704
[Epoch 9, Batch 1400] loss: 0.022850448268727633
[Epoch 9, Batch 1500] loss: 0.034637345306400676
[Epoch 9, Batch 1600] loss: 0.05595945686043706
[Epoch 9, Batch 1700] loss: 0.028452256874588785
[Epoch 9, Batch 1800] loss: 0.02459079465814284
[Epoch 9, Batch 1900] loss: 0.035059414763236416
[Epoch 9, Batch 2000] loss: 0.02147374675667379
[Epoch 9, Batch 2100] loss: 0.024818321068887598
[Epoch 9, Batch 2200] loss: 0.037681654503830944
[Epoch 9, Batch 2300] loss: 0.02216615692275809
[Epoch 9, Batch 2400] loss: 0.038977983100048734
[Epoch 9, Batch 2500] loss: 0.028145790324779228
[Epoch 9, Batch 2600] loss: 0.03218640894949203
[Epoch 9, Batch 2700] loss: 0.03474551275532576
[Epoch 9, Batch 2800] loss: 0.03403978792295675
[Epoch 9, Batch 2900] loss: 0.03403267412169953
[Epoch 9, Batch 3000] loss: 0.022871336495445576
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9861
Overfitting: 0.0437
Best model saved at epoch 9 with validation loss: 0.0437
[Epoch 10, Batch 100] loss: 0.02851671975760837
[Epoch 10, Batch 200] loss: 0.021986653758649482
[Epoch 10, Batch 300] loss: 0.02260725105443271
[Epoch 10, Batch 400] loss: 0.025124231516674627
[Epoch 10, Batch 500] loss: 0.030485924973763758
[Epoch 10, Batch 600] loss: 0.0281168244566652
[Epoch 10, Batch 700] loss: 0.03140083524816873
[Epoch 10, Batch 800] loss: 0.02883727881780942
[Epoch 10, Batch 900] loss: 0.01710153280495433
[Epoch 10, Batch 1000] loss: 0.026623019060352818
[Epoch 10, Batch 1100] loss: 0.03972599823107885
[Epoch 10, Batch 1200] loss: 0.022742604219456553
[Epoch 10, Batch 1300] loss: 0.034910201695311116
[Epoch 10, Batch 1400] loss: 0.024410447754489722
[Epoch 10, Batch 1500] loss: 0.03466654320800444
[Epoch 10, Batch 1600] loss: 0.023467489050963197
[Epoch 10, Batch 1700] loss: 0.02785148021852365
[Epoch 10, Batch 1800] loss: 0.02132796948775649
[Epoch 10, Batch 1900] loss: 0.02076986467694951
[Epoch 10, Batch 2000] loss: 0.02392426095568226
[Epoch 10, Batch 2100] loss: 0.02470605921917013
[Epoch 10, Batch 2200] loss: 0.020437475064827595
[Epoch 10, Batch 2300] loss: 0.05110076121447491
[Epoch 10, Batch 2400] loss: 0.03233487230594619
[Epoch 10, Batch 2500] loss: 0.01726402490530745
[Epoch 10, Batch 2600] loss: 0.03800341581518296
[Epoch 10, Batch 2700] loss: 0.02538822061222163
[Epoch 10, Batch 2800] loss: 0.019449929049078492
[Epoch 10, Batch 2900] loss: 0.03469353446478635
[Epoch 10, Batch 3000] loss: 0.040360174228335384
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9843
Overfitting: 0.0544
[Epoch 11, Batch 100] loss: 0.021458978709561052
[Epoch 11, Batch 200] loss: 0.027276670643914258
[Epoch 11, Batch 300] loss: 0.026446511910980918
[Epoch 11, Batch 400] loss: 0.01823932982093538
[Epoch 11, Batch 500] loss: 0.02278335643961327
[Epoch 11, Batch 600] loss: 0.029909610438044184
[Epoch 11, Batch 700] loss: 0.025423576194734777
[Epoch 11, Batch 800] loss: 0.02313613767895731
[Epoch 11, Batch 900] loss: 0.03126675893523498
[Epoch 11, Batch 1000] loss: 0.024376407025629307
[Epoch 11, Batch 1100] loss: 0.023391695242607966
[Epoch 11, Batch 1200] loss: 0.028308536401636955
[Epoch 11, Batch 1300] loss: 0.018593466073325543
[Epoch 11, Batch 1400] loss: 0.029821079196881328
[Epoch 11, Batch 1500] loss: 0.023317631697573234
[Epoch 11, Batch 1600] loss: 0.016345149597727867
[Epoch 11, Batch 1700] loss: 0.02017750385839463
[Epoch 11, Batch 1800] loss: 0.017995704383756674
[Epoch 11, Batch 1900] loss: 0.028240725824980474
[Epoch 11, Batch 2000] loss: 0.029945626157568767
[Epoch 11, Batch 2100] loss: 0.04340065519740165
[Epoch 11, Batch 2200] loss: 0.023756240625734792
[Epoch 11, Batch 2300] loss: 0.02132380641438431
[Epoch 11, Batch 2400] loss: 0.025665643615975568
[Epoch 11, Batch 2500] loss: 0.027222789388688398
[Epoch 11, Batch 2600] loss: 0.03492449342928012
[Epoch 11, Batch 2700] loss: 0.01954161635003402
[Epoch 11, Batch 2800] loss: 0.01938557201930962
[Epoch 11, Batch 2900] loss: 0.020917625005095034
[Epoch 11, Batch 3000] loss: 0.035880644773496895
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9866
Overfitting: 0.0446
[Epoch 12, Batch 100] loss: 0.01719216430974484
[Epoch 12, Batch 200] loss: 0.011837027250585379
[Epoch 12, Batch 300] loss: 0.022166644208118667
[Epoch 12, Batch 400] loss: 0.026159541929337136
[Epoch 12, Batch 500] loss: 0.014820280038620695
[Epoch 12, Batch 600] loss: 0.02208385358006126
[Epoch 12, Batch 700] loss: 0.02246510130673414
[Epoch 12, Batch 800] loss: 0.013806599465024192
[Epoch 12, Batch 900] loss: 0.01666361013916685
[Epoch 12, Batch 1000] loss: 0.020499610179977024
[Epoch 12, Batch 1100] loss: 0.023317778732962324
[Epoch 12, Batch 1200] loss: 0.024113851848669585
[Epoch 12, Batch 1300] loss: 0.020538240845198744
[Epoch 12, Batch 1400] loss: 0.016278790622272936
[Epoch 12, Batch 1500] loss: 0.02885906848969171
[Epoch 12, Batch 1600] loss: 0.02657691686239559
[Epoch 12, Batch 1700] loss: 0.02990460012515541
[Epoch 12, Batch 1800] loss: 0.020812157935579306
[Epoch 12, Batch 1900] loss: 0.022203832104496543
[Epoch 12, Batch 2000] loss: 0.024250885012916116
[Epoch 12, Batch 2100] loss: 0.029244120848925376
[Epoch 12, Batch 2200] loss: 0.020553966799052432
[Epoch 12, Batch 2300] loss: 0.019446158248902067
[Epoch 12, Batch 2400] loss: 0.018664688108910924
[Epoch 12, Batch 2500] loss: 0.025032432092048112
[Epoch 12, Batch 2600] loss: 0.02496802281606506
[Epoch 12, Batch 2700] loss: 0.042858212716710115
[Epoch 12, Batch 2800] loss: 0.032820641289581544
[Epoch 12, Batch 2900] loss: 0.01625422749100835
[Epoch 12, Batch 3000] loss: 0.016464384754071942
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9867
Overfitting: 0.0469
[Epoch 13, Batch 100] loss: 0.024234089176352426
[Epoch 13, Batch 200] loss: 0.014488304194110242
[Epoch 13, Batch 300] loss: 0.020697694543996475
[Epoch 13, Batch 400] loss: 0.023426431019706796
[Epoch 13, Batch 500] loss: 0.014954976717235694
[Epoch 13, Batch 600] loss: 0.019312348215826204
[Epoch 13, Batch 700] loss: 0.01650307067335234
[Epoch 13, Batch 800] loss: 0.010891831686531078
[Epoch 13, Batch 900] loss: 0.013150225183708245
[Epoch 13, Batch 1000] loss: 0.012537967187090543
[Epoch 13, Batch 1100] loss: 0.022468233994732145
[Epoch 13, Batch 1200] loss: 0.018208808056770068
[Epoch 13, Batch 1300] loss: 0.029125837195897473
[Epoch 13, Batch 1400] loss: 0.015171252916334197
[Epoch 13, Batch 1500] loss: 0.01619092940731207
[Epoch 13, Batch 1600] loss: 0.01807745058886212
[Epoch 13, Batch 1700] loss: 0.025886243504046433
[Epoch 13, Batch 1800] loss: 0.024269707139210367
[Epoch 13, Batch 1900] loss: 0.022900038536754437
[Epoch 13, Batch 2000] loss: 0.01388589277506071
[Epoch 13, Batch 2100] loss: 0.01657191196905842
[Epoch 13, Batch 2200] loss: 0.02911867725870252
[Epoch 13, Batch 2300] loss: 0.023400823567153565
[Epoch 13, Batch 2400] loss: 0.012873550169952069
[Epoch 13, Batch 2500] loss: 0.030534078807613697
[Epoch 13, Batch 2600] loss: 0.027956779540290883
[Epoch 13, Batch 2700] loss: 0.019010108046786628
[Epoch 13, Batch 2800] loss: 0.025814463228161912
[Epoch 13, Batch 2900] loss: 0.032807763274831814
[Epoch 13, Batch 3000] loss: 0.022615790452982766
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0401
Validation Accuracy: 0.9873
Overfitting: 0.0401
Best model saved at epoch 13 with validation loss: 0.0401
[Epoch 14, Batch 100] loss: 0.011696339669833833
[Epoch 14, Batch 200] loss: 0.019026924911886452
[Epoch 14, Batch 300] loss: 0.019341397942625918
[Epoch 14, Batch 400] loss: 0.018182706828811207
[Epoch 14, Batch 500] loss: 0.024766270382569927
[Epoch 14, Batch 600] loss: 0.02015988409213605
[Epoch 14, Batch 700] loss: 0.017764650400495158
[Epoch 14, Batch 800] loss: 0.01179253486043308
[Epoch 14, Batch 900] loss: 0.008576553595048608
[Epoch 14, Batch 1000] loss: 0.015784185109150712
[Epoch 14, Batch 1100] loss: 0.009318016156903468
[Epoch 14, Batch 1200] loss: 0.0199665504175573
[Epoch 14, Batch 1300] loss: 0.018563135734002572
[Epoch 14, Batch 1400] loss: 0.017147018538489645
[Epoch 14, Batch 1500] loss: 0.01956396253202911
[Epoch 14, Batch 1600] loss: 0.01909288531925995
[Epoch 14, Batch 1700] loss: 0.01281594510503055
[Epoch 14, Batch 1800] loss: 0.020721017163273247
[Epoch 14, Batch 1900] loss: 0.011060866642264956
[Epoch 14, Batch 2000] loss: 0.029445226780990198
[Epoch 14, Batch 2100] loss: 0.02364103073157821
[Epoch 14, Batch 2200] loss: 0.009455528765411145
[Epoch 14, Batch 2300] loss: 0.017956958313661744
[Epoch 14, Batch 2400] loss: 0.019579424895491682
[Epoch 14, Batch 2500] loss: 0.014491450228561006
[Epoch 14, Batch 2600] loss: 0.023348545295757504
[Epoch 14, Batch 2700] loss: 0.016024825431413772
[Epoch 14, Batch 2800] loss: 0.020573867504808732
[Epoch 14, Batch 2900] loss: 0.011417375435194117
[Epoch 14, Batch 3000] loss: 0.023012757049618814
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0394
Validation Accuracy: 0.9872
Overfitting: 0.0394
Best model saved at epoch 14 with validation loss: 0.0394
[Epoch 15, Batch 100] loss: 0.009013914517308876
[Epoch 15, Batch 200] loss: 0.01684303967967935
[Epoch 15, Batch 300] loss: 0.015855747729583525
[Epoch 15, Batch 400] loss: 0.012334836490026646
[Epoch 15, Batch 500] loss: 0.017214196575623647
[Epoch 15, Batch 600] loss: 0.018944500883153522
[Epoch 15, Batch 700] loss: 0.013827405584452208
[Epoch 15, Batch 800] loss: 0.010683758948362083
[Epoch 15, Batch 900] loss: 0.012132373363965599
[Epoch 15, Batch 1000] loss: 0.01711935653594992
[Epoch 15, Batch 1100] loss: 0.025748228482079867
[Epoch 15, Batch 1200] loss: 0.019288983472288235
[Epoch 15, Batch 1300] loss: 0.016298510363594688
[Epoch 15, Batch 1400] loss: 0.011618127138581258
[Epoch 15, Batch 1500] loss: 0.011289884793395686
[Epoch 15, Batch 1600] loss: 0.024814347207793616
[Epoch 15, Batch 1700] loss: 0.019147295356015094
[Epoch 15, Batch 1800] loss: 0.018992037622156205
[Epoch 15, Batch 1900] loss: 0.021026804817702215
[Epoch 15, Batch 2000] loss: 0.016404308835990377
[Epoch 15, Batch 2100] loss: 0.025431539735782282
[Epoch 15, Batch 2200] loss: 0.02643618916066771
[Epoch 15, Batch 2300] loss: 0.008818543150209735
[Epoch 15, Batch 2400] loss: 0.01822773006373609
[Epoch 15, Batch 2500] loss: 0.012831624659520457
[Epoch 15, Batch 2600] loss: 0.015227034953531983
[Epoch 15, Batch 2700] loss: 0.008653392410451488
[Epoch 15, Batch 2800] loss: 0.01957993618219916
[Epoch 15, Batch 2900] loss: 0.017030427635072554
[Epoch 15, Batch 3000] loss: 0.00948439269622213
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0377
Validation Accuracy: 0.9883
Overfitting: 0.0377
Best model saved at epoch 15 with validation loss: 0.0377
[Epoch 16, Batch 100] loss: 0.009600019944628002
[Epoch 16, Batch 200] loss: 0.024474972971984244
[Epoch 16, Batch 300] loss: 0.018030705620112712
[Epoch 16, Batch 400] loss: 0.013844198802144093
[Epoch 16, Batch 500] loss: 0.016512273994085263
[Epoch 16, Batch 600] loss: 0.011771587191997241
[Epoch 16, Batch 700] loss: 0.019635004287119954
[Epoch 16, Batch 800] loss: 0.01173672187678676
[Epoch 16, Batch 900] loss: 0.012770357713352496
[Epoch 16, Batch 1000] loss: 0.008097599517914205
[Epoch 16, Batch 1100] loss: 0.021092334364293492
[Epoch 16, Batch 1200] loss: 0.013873075101691938
[Epoch 16, Batch 1300] loss: 0.009566278884049097
[Epoch 16, Batch 1400] loss: 0.011417978062290786
[Epoch 16, Batch 1500] loss: 0.009598770371740102
[Epoch 16, Batch 1600] loss: 0.015760973555297823
[Epoch 16, Batch 1700] loss: 0.018879190910429316
[Epoch 16, Batch 1800] loss: 0.0163700846879874
[Epoch 16, Batch 1900] loss: 0.018870071038363675
[Epoch 16, Batch 2000] loss: 0.010067627280568559
[Epoch 16, Batch 2100] loss: 0.019131514069104013
[Epoch 16, Batch 2200] loss: 0.00791633616654508
[Epoch 16, Batch 2300] loss: 0.013867430603204412
[Epoch 16, Batch 2400] loss: 0.008176493280170689
[Epoch 16, Batch 2500] loss: 0.01933687620309229
[Epoch 16, Batch 2600] loss: 0.022961708506627473
[Epoch 16, Batch 2700] loss: 0.025780594504776672
[Epoch 16, Batch 2800] loss: 0.013389343731250846
[Epoch 16, Batch 2900] loss: 0.010665298405983776
[Epoch 16, Batch 3000] loss: 0.03659984010002518
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0387
Validation Accuracy: 0.9886
Overfitting: 0.0387
[Epoch 17, Batch 100] loss: 0.00739679311413056
[Epoch 17, Batch 200] loss: 0.007478406281643401
[Epoch 17, Batch 300] loss: 0.011594088197289238
[Epoch 17, Batch 400] loss: 0.011734108341915999
[Epoch 17, Batch 500] loss: 0.01712862995697833
[Epoch 17, Batch 600] loss: 0.009195310761097062
[Epoch 17, Batch 700] loss: 0.02040104679450451
[Epoch 17, Batch 800] loss: 0.02876146975060692
[Epoch 17, Batch 900] loss: 0.008948792156634227
[Epoch 17, Batch 1000] loss: 0.021041757362672796
[Epoch 17, Batch 1100] loss: 0.011270332931508165
[Epoch 17, Batch 1200] loss: 0.014032663370526279
[Epoch 17, Batch 1300] loss: 0.009982875205951132
[Epoch 17, Batch 1400] loss: 0.011673756137838609
[Epoch 17, Batch 1500] loss: 0.016622140536946974
[Epoch 17, Batch 1600] loss: 0.021689509022162382
[Epoch 17, Batch 1700] loss: 0.017040546763200836
[Epoch 17, Batch 1800] loss: 0.008476898308872478
[Epoch 17, Batch 1900] loss: 0.014112595162132494
[Epoch 17, Batch 2000] loss: 0.014978092295386887
[Epoch 17, Batch 2100] loss: 0.01768718637566053
[Epoch 17, Batch 2200] loss: 0.009763996783476614
[Epoch 17, Batch 2300] loss: 0.00789235552642367
[Epoch 17, Batch 2400] loss: 0.00700734346587069
[Epoch 17, Batch 2500] loss: 0.007933742500499648
[Epoch 17, Batch 2600] loss: 0.00899004246939512
[Epoch 17, Batch 2700] loss: 0.01846248058745914
[Epoch 17, Batch 2800] loss: 0.012200761783024063
[Epoch 17, Batch 2900] loss: 0.007939940151391055
[Epoch 17, Batch 3000] loss: 0.014885630858916556
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9858
Overfitting: 0.0473
[Epoch 18, Batch 100] loss: 0.012006244848362258
[Epoch 18, Batch 200] loss: 0.010334772748283285
[Epoch 18, Batch 300] loss: 0.008719695983236306
[Epoch 18, Batch 400] loss: 0.00835898790855481
[Epoch 18, Batch 500] loss: 0.004610395347913254
[Epoch 18, Batch 600] loss: 0.008571958729744438
[Epoch 18, Batch 700] loss: 0.019667745893193568
[Epoch 18, Batch 800] loss: 0.005868632332358174
[Epoch 18, Batch 900] loss: 0.008728716354921744
[Epoch 18, Batch 1000] loss: 0.005834473023655846
[Epoch 18, Batch 1100] loss: 0.008582309676594378
[Epoch 18, Batch 1200] loss: 0.006645853387490206
[Epoch 18, Batch 1300] loss: 0.009228692478627636
[Epoch 18, Batch 1400] loss: 0.008659957008158017
[Epoch 18, Batch 1500] loss: 0.011465736844666025
[Epoch 18, Batch 1600] loss: 0.010327521718809294
[Epoch 18, Batch 1700] loss: 0.01656461188657886
[Epoch 18, Batch 1800] loss: 0.012800205027551782
[Epoch 18, Batch 1900] loss: 0.014245858768499603
[Epoch 18, Batch 2000] loss: 0.009302517589803756
[Epoch 18, Batch 2100] loss: 0.009284520818619057
[Epoch 18, Batch 2200] loss: 0.013420786471288011
[Epoch 18, Batch 2300] loss: 0.017268133512243367
[Epoch 18, Batch 2400] loss: 0.020324880782445688
[Epoch 18, Batch 2500] loss: 0.008432113702347123
[Epoch 18, Batch 2600] loss: 0.01370908519224031
[Epoch 18, Batch 2700] loss: 0.009205949260012858
[Epoch 18, Batch 2800] loss: 0.020344023495817966
[Epoch 18, Batch 2900] loss: 0.023652806198660982
[Epoch 18, Batch 3000] loss: 0.013953524156640924
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0405
Validation Accuracy: 0.9884
Overfitting: 0.0405
[Epoch 19, Batch 100] loss: 0.006411312167147116
[Epoch 19, Batch 200] loss: 0.00665460529225129
[Epoch 19, Batch 300] loss: 0.008864115489450342
[Epoch 19, Batch 400] loss: 0.011155136301595122
[Epoch 19, Batch 500] loss: 0.011043833420080773
[Epoch 19, Batch 600] loss: 0.00630438347301606
[Epoch 19, Batch 700] loss: 0.005153243904860574
[Epoch 19, Batch 800] loss: 0.018353632613980153
[Epoch 19, Batch 900] loss: 0.015053798938188265
[Epoch 19, Batch 1000] loss: 0.006791256531523686
[Epoch 19, Batch 1100] loss: 0.007082641414569935
[Epoch 19, Batch 1200] loss: 0.007685527500188982
[Epoch 19, Batch 1300] loss: 0.005978301757504596
[Epoch 19, Batch 1400] loss: 0.011207849226566395
[Epoch 19, Batch 1500] loss: 0.01428642886769012
[Epoch 19, Batch 1600] loss: 0.013648534768922218
[Epoch 19, Batch 1700] loss: 0.01063210923161023
[Epoch 19, Batch 1800] loss: 0.009544004953113472
[Epoch 19, Batch 1900] loss: 0.014550225953394147
[Epoch 19, Batch 2000] loss: 0.015382734593513305
[Epoch 19, Batch 2100] loss: 0.008841134022122787
[Epoch 19, Batch 2200] loss: 0.0164695425684522
[Epoch 19, Batch 2300] loss: 0.01175038487920574
[Epoch 19, Batch 2400] loss: 0.02100798925934214
[Epoch 19, Batch 2500] loss: 0.021351930514674676
[Epoch 19, Batch 2600] loss: 0.013025171617628076
[Epoch 19, Batch 2700] loss: 0.012329028085259779
[Epoch 19, Batch 2800] loss: 0.008628150577224006
[Epoch 19, Batch 2900] loss: 0.011655652215395093
[Epoch 19, Batch 3000] loss: 0.009687355735281926
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0396
Validation Accuracy: 0.9888
Overfitting: 0.0396
[Epoch 20, Batch 100] loss: 0.007403431360335162
[Epoch 20, Batch 200] loss: 0.007023246767994351
[Epoch 20, Batch 300] loss: 0.004803013661128262
[Epoch 20, Batch 400] loss: 0.01157313942861947
[Epoch 20, Batch 500] loss: 0.006336561357547907
[Epoch 20, Batch 600] loss: 0.009552909089835566
[Epoch 20, Batch 700] loss: 0.008899599290389233
[Epoch 20, Batch 800] loss: 0.009746786621471984
[Epoch 20, Batch 900] loss: 0.006584837696364048
[Epoch 20, Batch 1000] loss: 0.00987910434929745
[Epoch 20, Batch 1100] loss: 0.008045724413523202
[Epoch 20, Batch 1200] loss: 0.007012301134686823
[Epoch 20, Batch 1300] loss: 0.007600126042078727
[Epoch 20, Batch 1400] loss: 0.007460194655259329
[Epoch 20, Batch 1500] loss: 0.007040885459509809
[Epoch 20, Batch 1600] loss: 0.008478394201483752
[Epoch 20, Batch 1700] loss: 0.006820416350046798
[Epoch 20, Batch 1800] loss: 0.016407752936381713
[Epoch 20, Batch 1900] loss: 0.011932464204955978
[Epoch 20, Batch 2000] loss: 0.010673723067325227
[Epoch 20, Batch 2100] loss: 0.0053511732497827326
[Epoch 20, Batch 2200] loss: 0.010069904918848351
[Epoch 20, Batch 2300] loss: 0.008688900624733834
[Epoch 20, Batch 2400] loss: 0.005696377957667665
[Epoch 20, Batch 2500] loss: 0.018559390885795893
[Epoch 20, Batch 2600] loss: 0.011274257404420496
[Epoch 20, Batch 2700] loss: 0.016307856949092637
[Epoch 20, Batch 2800] loss: 0.010033201244696102
[Epoch 20, Batch 2900] loss: 0.008254385427762826
[Epoch 20, Batch 3000] loss: 0.012298167014387218
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0389
Validation Accuracy: 0.9888
Overfitting: 0.0389
[Epoch 21, Batch 100] loss: 0.008680186369665534
[Epoch 21, Batch 200] loss: 0.00671916886120016
[Epoch 21, Batch 300] loss: 0.008682025287010902
[Epoch 21, Batch 400] loss: 0.006605083204392486
[Epoch 21, Batch 500] loss: 0.011223844489722978
[Epoch 21, Batch 600] loss: 0.006821274073367931
[Epoch 21, Batch 700] loss: 0.004055488467417945
[Epoch 21, Batch 800] loss: 0.007309569453149152
[Epoch 21, Batch 900] loss: 0.005011919188691536
[Epoch 21, Batch 1000] loss: 0.002460127119700246
[Epoch 21, Batch 1100] loss: 0.006191736453829435
[Epoch 21, Batch 1200] loss: 0.010444108448684802
[Epoch 21, Batch 1300] loss: 0.014532605336198686
[Epoch 21, Batch 1400] loss: 0.006456618278170936
[Epoch 21, Batch 1500] loss: 0.004874910961761998
[Epoch 21, Batch 1600] loss: 0.013258630472209916
[Epoch 21, Batch 1700] loss: 0.006103418336103914
[Epoch 21, Batch 1800] loss: 0.006527374785327993
[Epoch 21, Batch 1900] loss: 0.012193575767068978
[Epoch 21, Batch 2000] loss: 0.005103599852675416
[Epoch 21, Batch 2100] loss: 0.00732427616444511
[Epoch 21, Batch 2200] loss: 0.015468677762241896
[Epoch 21, Batch 2300] loss: 0.00979624859324531
[Epoch 21, Batch 2400] loss: 0.011307962757672384
[Epoch 21, Batch 2500] loss: 0.004582316046371489
[Epoch 21, Batch 2600] loss: 0.006983527384436456
[Epoch 21, Batch 2700] loss: 0.005951357276428553
[Epoch 21, Batch 2800] loss: 0.01739295849451082
[Epoch 21, Batch 2900] loss: 0.00670318191534534
[Epoch 21, Batch 3000] loss: 0.007594356427034654
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0404
Validation Accuracy: 0.9888
Overfitting: 0.0404
[Epoch 22, Batch 100] loss: 0.008052560786991307
[Epoch 22, Batch 200] loss: 0.005248948002337102
[Epoch 22, Batch 300] loss: 0.0038256636747428276
[Epoch 22, Batch 400] loss: 0.0032166266895592346
[Epoch 22, Batch 500] loss: 0.006754078440785634
[Epoch 22, Batch 600] loss: 0.006768460913053787
[Epoch 22, Batch 700] loss: 0.006882130948279155
[Epoch 22, Batch 800] loss: 0.006544934331009245
[Epoch 22, Batch 900] loss: 0.011334662522058352
[Epoch 22, Batch 1000] loss: 0.014908587114846342
[Epoch 22, Batch 1100] loss: 0.00807513982062119
[Epoch 22, Batch 1200] loss: 0.004365102930105422
[Epoch 22, Batch 1300] loss: 0.011937712490521335
[Epoch 22, Batch 1400] loss: 0.00568597502116063
[Epoch 22, Batch 1500] loss: 0.010318871346603373
[Epoch 22, Batch 1600] loss: 0.00908138522680929
[Epoch 22, Batch 1700] loss: 0.009046901667816201
[Epoch 22, Batch 1800] loss: 0.005146703963460481
[Epoch 22, Batch 1900] loss: 0.006420035613077743
[Epoch 22, Batch 2000] loss: 0.0036370365228310677
[Epoch 22, Batch 2100] loss: 0.0032772574028058442
[Epoch 22, Batch 2200] loss: 0.005851647658546426
[Epoch 22, Batch 2300] loss: 0.004627060488483607
[Epoch 22, Batch 2400] loss: 0.004833387307126031
[Epoch 22, Batch 2500] loss: 0.003520149993214545
[Epoch 22, Batch 2600] loss: 0.007430701278703964
[Epoch 22, Batch 2700] loss: 0.013225941420164417
[Epoch 22, Batch 2800] loss: 0.013719187529525244
[Epoch 22, Batch 2900] loss: 0.0038181179592515946
[Epoch 22, Batch 3000] loss: 0.009133447420841776
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0404
Validation Accuracy: 0.9894
Overfitting: 0.0404
[Epoch 23, Batch 100] loss: 0.008328501617506845
[Epoch 23, Batch 200] loss: 0.0067725574480346044
[Epoch 23, Batch 300] loss: 0.00812833594213771
[Epoch 23, Batch 400] loss: 0.005125477779638459
[Epoch 23, Batch 500] loss: 0.002492226406232021
[Epoch 23, Batch 600] loss: 0.006009398986334418
[Epoch 23, Batch 700] loss: 0.0037721014908163398
[Epoch 23, Batch 800] loss: 0.005092116959719988
[Epoch 23, Batch 900] loss: 0.006216261764443516
[Epoch 23, Batch 1000] loss: 0.012119899886984057
[Epoch 23, Batch 1100] loss: 0.004596151980717877
[Epoch 23, Batch 1200] loss: 0.011668026466637685
[Epoch 23, Batch 1300] loss: 0.012333604103496328
[Epoch 23, Batch 1400] loss: 0.002987107467433816
[Epoch 23, Batch 1500] loss: 0.004948867005118416
[Epoch 23, Batch 1600] loss: 0.004712469814576252
[Epoch 23, Batch 1700] loss: 0.006406351445504015
[Epoch 23, Batch 1800] loss: 0.006743179122058791
[Epoch 23, Batch 1900] loss: 0.006977684254261476
[Epoch 23, Batch 2000] loss: 0.0037594800078431943
[Epoch 23, Batch 2100] loss: 0.00684015652916969
[Epoch 23, Batch 2200] loss: 0.004469138718650356
[Epoch 23, Batch 2300] loss: 0.01057507460411216
[Epoch 23, Batch 2400] loss: 0.005211514729012379
[Epoch 23, Batch 2500] loss: 0.0070490273790051105
[Epoch 23, Batch 2600] loss: 0.006759754871349628
[Epoch 23, Batch 2700] loss: 0.0042325692690712916
[Epoch 23, Batch 2800] loss: 0.004114534999189345
[Epoch 23, Batch 2900] loss: 0.013464491725264338
[Epoch 23, Batch 3000] loss: 0.020299424776758314
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9880
Overfitting: 0.0449
[Epoch 24, Batch 100] loss: 0.005324672915303381
[Epoch 24, Batch 200] loss: 0.0062687201367862145
[Epoch 24, Batch 300] loss: 0.007697300510594687
[Epoch 24, Batch 400] loss: 0.002836146921022191
[Epoch 24, Batch 500] loss: 0.0029316050402258043
[Epoch 24, Batch 600] loss: 0.011331139658259416
[Epoch 24, Batch 700] loss: 0.0035023612083659827
[Epoch 24, Batch 800] loss: 0.00383947936094728
[Epoch 24, Batch 900] loss: 0.007265476136938105
[Epoch 24, Batch 1000] loss: 0.008172463045252699
[Epoch 24, Batch 1100] loss: 0.004756380318999618
[Epoch 24, Batch 1200] loss: 0.006751290284528295
[Epoch 24, Batch 1300] loss: 0.006710249140560336
[Epoch 24, Batch 1400] loss: 0.0017931708700052696
[Epoch 24, Batch 1500] loss: 0.008757771696746203
[Epoch 24, Batch 1600] loss: 0.004360504365126872
[Epoch 24, Batch 1700] loss: 0.0060034852020271505
[Epoch 24, Batch 1800] loss: 0.007342556559342484
[Epoch 24, Batch 1900] loss: 0.0055331524636551424
[Epoch 24, Batch 2000] loss: 0.008828760285953195
[Epoch 24, Batch 2100] loss: 0.0031211003521877958
[Epoch 24, Batch 2200] loss: 0.007556024038032092
[Epoch 24, Batch 2300] loss: 0.003488748914325015
[Epoch 24, Batch 2400] loss: 0.006988544330956756
[Epoch 24, Batch 2500] loss: 0.007697400403853863
[Epoch 24, Batch 2600] loss: 0.005588079250668443
[Epoch 24, Batch 2700] loss: 0.00561897380117216
[Epoch 24, Batch 2800] loss: 0.004997681684814097
[Epoch 24, Batch 2900] loss: 0.006088337015455636
[Epoch 24, Batch 3000] loss: 0.00760214879973887
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9880
Overfitting: 0.0441
Fold 1 validation loss: 0.0441
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2996719217300416
[Epoch 1, Batch 200] loss: 2.289911251068115
[Epoch 1, Batch 300] loss: 2.2721824526786802
[Epoch 1, Batch 400] loss: 2.248984112739563
[Epoch 1, Batch 500] loss: 2.190456109046936
[Epoch 1, Batch 600] loss: 2.0033036875724792
[Epoch 1, Batch 700] loss: 1.443851063847542
[Epoch 1, Batch 800] loss: 0.7934721064567566
[Epoch 1, Batch 900] loss: 0.629713604748249
[Epoch 1, Batch 1000] loss: 0.47945763245224954
[Epoch 1, Batch 1100] loss: 0.43087699510157107
[Epoch 1, Batch 1200] loss: 0.3914037179946899
[Epoch 1, Batch 1300] loss: 0.32830745801329614
[Epoch 1, Batch 1400] loss: 0.2999217652156949
[Epoch 1, Batch 1500] loss: 0.3197038619965315
[Epoch 1, Batch 1600] loss: 0.2703853678703308
[Epoch 1, Batch 1700] loss: 0.25723245372995734
[Epoch 1, Batch 1800] loss: 0.2467066627368331
[Epoch 1, Batch 1900] loss: 0.2738075015693903
[Epoch 1, Batch 2000] loss: 0.23751269166357816
[Epoch 1, Batch 2100] loss: 0.19283880800008774
[Epoch 1, Batch 2200] loss: 0.20537234924733638
[Epoch 1, Batch 2300] loss: 0.17339643131941557
[Epoch 1, Batch 2400] loss: 0.21600336222909391
[Epoch 1, Batch 2500] loss: 0.17827990372665226
[Epoch 1, Batch 2600] loss: 0.18918119018897414
[Epoch 1, Batch 2700] loss: 0.19959527998231352
[Epoch 1, Batch 2800] loss: 0.17221370812505485
[Epoch 1, Batch 2900] loss: 0.17036936152726412
[Epoch 1, Batch 3000] loss: 0.15526419334113598
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1758
Validation Accuracy: 0.9473
Overfitting: 0.1758
Best model saved at epoch 1 with validation loss: 0.1758
[Epoch 2, Batch 100] loss: 0.18645267156884074
[Epoch 2, Batch 200] loss: 0.19138261171989143
[Epoch 2, Batch 300] loss: 0.1250751731917262
[Epoch 2, Batch 400] loss: 0.1590797333791852
[Epoch 2, Batch 500] loss: 0.13482000017073006
[Epoch 2, Batch 600] loss: 0.15094041563570498
[Epoch 2, Batch 700] loss: 0.1522161426767707
[Epoch 2, Batch 800] loss: 0.12750491895712912
[Epoch 2, Batch 900] loss: 0.13631951656658203
[Epoch 2, Batch 1000] loss: 0.1292422072472982
[Epoch 2, Batch 1100] loss: 0.14216747279278935
[Epoch 2, Batch 1200] loss: 0.13922181356698274
[Epoch 2, Batch 1300] loss: 0.1496314503531903
[Epoch 2, Batch 1400] loss: 0.10911836939398199
[Epoch 2, Batch 1500] loss: 0.10636573111172766
[Epoch 2, Batch 1600] loss: 0.11505602900637314
[Epoch 2, Batch 1700] loss: 0.12321785769425332
[Epoch 2, Batch 1800] loss: 0.11139732536161319
[Epoch 2, Batch 1900] loss: 0.10300744217820465
[Epoch 2, Batch 2000] loss: 0.12026194313075393
[Epoch 2, Batch 2100] loss: 0.1215889139752835
[Epoch 2, Batch 2200] loss: 0.11750542904715985
[Epoch 2, Batch 2300] loss: 0.123259465447627
[Epoch 2, Batch 2400] loss: 0.12712969144573436
[Epoch 2, Batch 2500] loss: 0.10010330413468183
[Epoch 2, Batch 2600] loss: 0.09747130407951772
[Epoch 2, Batch 2700] loss: 0.1106820999411866
[Epoch 2, Batch 2800] loss: 0.09451043180422858
[Epoch 2, Batch 2900] loss: 0.12618066859431565
[Epoch 2, Batch 3000] loss: 0.09169633757788688
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1157
Validation Accuracy: 0.9653
Overfitting: 0.1157
Best model saved at epoch 2 with validation loss: 0.1157
[Epoch 3, Batch 100] loss: 0.08437244910048321
[Epoch 3, Batch 200] loss: 0.09136909140972421
[Epoch 3, Batch 300] loss: 0.08952324814628809
[Epoch 3, Batch 400] loss: 0.10809142356039957
[Epoch 3, Batch 500] loss: 0.08732729087583721
[Epoch 3, Batch 600] loss: 0.08752466581761836
[Epoch 3, Batch 700] loss: 0.08058178615407087
[Epoch 3, Batch 800] loss: 0.07649425233248622
[Epoch 3, Batch 900] loss: 0.08659666859311983
[Epoch 3, Batch 1000] loss: 0.09511390610365197
[Epoch 3, Batch 1100] loss: 0.08781001743860543
[Epoch 3, Batch 1200] loss: 0.0838049928494729
[Epoch 3, Batch 1300] loss: 0.11853813756024464
[Epoch 3, Batch 1400] loss: 0.0921756122505758
[Epoch 3, Batch 1500] loss: 0.08911220804438927
[Epoch 3, Batch 1600] loss: 0.09165388058521785
[Epoch 3, Batch 1700] loss: 0.0755236896709539
[Epoch 3, Batch 1800] loss: 0.10017853843513876
[Epoch 3, Batch 1900] loss: 0.08308717347565107
[Epoch 3, Batch 2000] loss: 0.0782878431910649
[Epoch 3, Batch 2100] loss: 0.09202881292905658
[Epoch 3, Batch 2200] loss: 0.0688663186028134
[Epoch 3, Batch 2300] loss: 0.09677722142310813
[Epoch 3, Batch 2400] loss: 0.08941553586162626
[Epoch 3, Batch 2500] loss: 0.09753824630519375
[Epoch 3, Batch 2600] loss: 0.08378133665886707
[Epoch 3, Batch 2700] loss: 0.07164744839188643
[Epoch 3, Batch 2800] loss: 0.06962559316772968
[Epoch 3, Batch 2900] loss: 0.09867871374124661
[Epoch 3, Batch 3000] loss: 0.0740062063978985
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0953
Validation Accuracy: 0.9718
Overfitting: 0.0953
Best model saved at epoch 3 with validation loss: 0.0953
[Epoch 4, Batch 100] loss: 0.07581251070660074
[Epoch 4, Batch 200] loss: 0.07484419784392231
[Epoch 4, Batch 300] loss: 0.06669053336256184
[Epoch 4, Batch 400] loss: 0.07300921617192216
[Epoch 4, Batch 500] loss: 0.05831713753694203
[Epoch 4, Batch 600] loss: 0.08036079651210457
[Epoch 4, Batch 700] loss: 0.07602741217706352
[Epoch 4, Batch 800] loss: 0.07619775349041447
[Epoch 4, Batch 900] loss: 0.07494388632592745
[Epoch 4, Batch 1000] loss: 0.07823610404506326
[Epoch 4, Batch 1100] loss: 0.06250105936313048
[Epoch 4, Batch 1200] loss: 0.0669703006313648
[Epoch 4, Batch 1300] loss: 0.09009871274116449
[Epoch 4, Batch 1400] loss: 0.06056385191448498
[Epoch 4, Batch 1500] loss: 0.054969960229936984
[Epoch 4, Batch 1600] loss: 0.08251994547783398
[Epoch 4, Batch 1700] loss: 0.06373229376506061
[Epoch 4, Batch 1800] loss: 0.051842617073562
[Epoch 4, Batch 1900] loss: 0.073415992144146
[Epoch 4, Batch 2000] loss: 0.06634926358179655
[Epoch 4, Batch 2100] loss: 0.05202859694254584
[Epoch 4, Batch 2200] loss: 0.08332983320578932
[Epoch 4, Batch 2300] loss: 0.08228108296636492
[Epoch 4, Batch 2400] loss: 0.08276180330780335
[Epoch 4, Batch 2500] loss: 0.06820410644868388
[Epoch 4, Batch 2600] loss: 0.06518921342270914
[Epoch 4, Batch 2700] loss: 0.06869792173383757
[Epoch 4, Batch 2800] loss: 0.07234119717555586
[Epoch 4, Batch 2900] loss: 0.05824248942109989
[Epoch 4, Batch 3000] loss: 0.0411760673194658
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0752
Validation Accuracy: 0.9771
Overfitting: 0.0752
Best model saved at epoch 4 with validation loss: 0.0752
[Epoch 5, Batch 100] loss: 0.054746122401556935
[Epoch 5, Batch 200] loss: 0.06359304347482976
[Epoch 5, Batch 300] loss: 0.05222991083748638
[Epoch 5, Batch 400] loss: 0.07389161357074045
[Epoch 5, Batch 500] loss: 0.05706843663065229
[Epoch 5, Batch 600] loss: 0.055267666635772913
[Epoch 5, Batch 700] loss: 0.061245381782064214
[Epoch 5, Batch 800] loss: 0.05896585593291093
[Epoch 5, Batch 900] loss: 0.045540285165188835
[Epoch 5, Batch 1000] loss: 0.08043741292960477
[Epoch 5, Batch 1100] loss: 0.06663483864045702
[Epoch 5, Batch 1200] loss: 0.05527775548223872
[Epoch 5, Batch 1300] loss: 0.058153235638164914
[Epoch 5, Batch 1400] loss: 0.048572099957382306
[Epoch 5, Batch 1500] loss: 0.058343708723550665
[Epoch 5, Batch 1600] loss: 0.0572826050047297
[Epoch 5, Batch 1700] loss: 0.0501631659589475
[Epoch 5, Batch 1800] loss: 0.05730824692989699
[Epoch 5, Batch 1900] loss: 0.042261596870957874
[Epoch 5, Batch 2000] loss: 0.07602965821512044
[Epoch 5, Batch 2100] loss: 0.053435538250487295
[Epoch 5, Batch 2200] loss: 0.04891845933103468
[Epoch 5, Batch 2300] loss: 0.06351113768672803
[Epoch 5, Batch 2400] loss: 0.050565509755542734
[Epoch 5, Batch 2500] loss: 0.04876306302030571
[Epoch 5, Batch 2600] loss: 0.07257087961537763
[Epoch 5, Batch 2700] loss: 0.06335830048657953
[Epoch 5, Batch 2800] loss: 0.049415455847629346
[Epoch 5, Batch 2900] loss: 0.044663231229933445
[Epoch 5, Batch 3000] loss: 0.05418409233330749
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0733
Validation Accuracy: 0.9785
Overfitting: 0.0733
Best model saved at epoch 5 with validation loss: 0.0733
[Epoch 6, Batch 100] loss: 0.06784230334742461
[Epoch 6, Batch 200] loss: 0.0461680793389678
[Epoch 6, Batch 300] loss: 0.03801172825566027
[Epoch 6, Batch 400] loss: 0.037368601389898684
[Epoch 6, Batch 500] loss: 0.045612512194784356
[Epoch 6, Batch 600] loss: 0.06068602611252572
[Epoch 6, Batch 700] loss: 0.0457729058311088
[Epoch 6, Batch 800] loss: 0.03256768490595277
[Epoch 6, Batch 900] loss: 0.06185122571187094
[Epoch 6, Batch 1000] loss: 0.044073931895254645
[Epoch 6, Batch 1100] loss: 0.04846115012071096
[Epoch 6, Batch 1200] loss: 0.043589451705338435
[Epoch 6, Batch 1300] loss: 0.04847438640310429
[Epoch 6, Batch 1400] loss: 0.05128205475921277
[Epoch 6, Batch 1500] loss: 0.0405424243141897
[Epoch 6, Batch 1600] loss: 0.07473766062408686
[Epoch 6, Batch 1700] loss: 0.04957873194623971
[Epoch 6, Batch 1800] loss: 0.05960913305840222
[Epoch 6, Batch 1900] loss: 0.05520293341949582
[Epoch 6, Batch 2000] loss: 0.05526904380443739
[Epoch 6, Batch 2100] loss: 0.04814435456908541
[Epoch 6, Batch 2200] loss: 0.042515023963642304
[Epoch 6, Batch 2300] loss: 0.0715882487790077
[Epoch 6, Batch 2400] loss: 0.04071899745555129
[Epoch 6, Batch 2500] loss: 0.042909744975331704
[Epoch 6, Batch 2600] loss: 0.051065209088556
[Epoch 6, Batch 2700] loss: 0.051282479812798556
[Epoch 6, Batch 2800] loss: 0.06589475351735018
[Epoch 6, Batch 2900] loss: 0.03401651478285203
[Epoch 6, Batch 3000] loss: 0.06127688236825634
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0701
Validation Accuracy: 0.9784
Overfitting: 0.0701
Best model saved at epoch 6 with validation loss: 0.0701
[Epoch 7, Batch 100] loss: 0.027876073264342268
[Epoch 7, Batch 200] loss: 0.03885017611435614
[Epoch 7, Batch 300] loss: 0.037175762196129655
[Epoch 7, Batch 400] loss: 0.04496236654973473
[Epoch 7, Batch 500] loss: 0.03215416290739086
[Epoch 7, Batch 600] loss: 0.04549944453523494
[Epoch 7, Batch 700] loss: 0.03928604601431289
[Epoch 7, Batch 800] loss: 0.04350350787164643
[Epoch 7, Batch 900] loss: 0.046130912586813795
[Epoch 7, Batch 1000] loss: 0.04842368635290768
[Epoch 7, Batch 1100] loss: 0.037066029348934534
[Epoch 7, Batch 1200] loss: 0.03923182514263317
[Epoch 7, Batch 1300] loss: 0.032139080549386564
[Epoch 7, Batch 1400] loss: 0.04651054333080538
[Epoch 7, Batch 1500] loss: 0.050531973357719834
[Epoch 7, Batch 1600] loss: 0.04365797923775972
[Epoch 7, Batch 1700] loss: 0.039543299017241226
[Epoch 7, Batch 1800] loss: 0.0790771414405026
[Epoch 7, Batch 1900] loss: 0.0452639452155563
[Epoch 7, Batch 2000] loss: 0.03766673115998856
[Epoch 7, Batch 2100] loss: 0.03624618953544996
[Epoch 7, Batch 2200] loss: 0.04547956594265998
[Epoch 7, Batch 2300] loss: 0.053262844936398324
[Epoch 7, Batch 2400] loss: 0.04497768354718573
[Epoch 7, Batch 2500] loss: 0.06218312210054137
[Epoch 7, Batch 2600] loss: 0.055086960148764776
[Epoch 7, Batch 2700] loss: 0.03383766661019763
[Epoch 7, Batch 2800] loss: 0.036521810341073435
[Epoch 7, Batch 2900] loss: 0.037160163627268046
[Epoch 7, Batch 3000] loss: 0.04731744598480873
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9820
Overfitting: 0.0603
Best model saved at epoch 7 with validation loss: 0.0603
[Epoch 8, Batch 100] loss: 0.04446736502024578
[Epoch 8, Batch 200] loss: 0.05354488180746557
[Epoch 8, Batch 300] loss: 0.04465395453866222
[Epoch 8, Batch 400] loss: 0.03989526450430276
[Epoch 8, Batch 500] loss: 0.034644646798551545
[Epoch 8, Batch 600] loss: 0.040998713176231834
[Epoch 8, Batch 700] loss: 0.029051575920893812
[Epoch 8, Batch 800] loss: 0.0259224851745239
[Epoch 8, Batch 900] loss: 0.04476544790886692
[Epoch 8, Batch 1000] loss: 0.02890715145971626
[Epoch 8, Batch 1100] loss: 0.05278189287972054
[Epoch 8, Batch 1200] loss: 0.041549661720055156
[Epoch 8, Batch 1300] loss: 0.05381185555219417
[Epoch 8, Batch 1400] loss: 0.027595995558076538
[Epoch 8, Batch 1500] loss: 0.046554228909662924
[Epoch 8, Batch 1600] loss: 0.04203141281090211
[Epoch 8, Batch 1700] loss: 0.03669186705432367
[Epoch 8, Batch 1800] loss: 0.027819769067282323
[Epoch 8, Batch 1900] loss: 0.04266856024769368
[Epoch 8, Batch 2000] loss: 0.027237054845900274
[Epoch 8, Batch 2100] loss: 0.04502406852378044
[Epoch 8, Batch 2200] loss: 0.039843165462225445
[Epoch 8, Batch 2300] loss: 0.05372100073087495
[Epoch 8, Batch 2400] loss: 0.02928647337073926
[Epoch 8, Batch 2500] loss: 0.043401369596540465
[Epoch 8, Batch 2600] loss: 0.030183403031624038
[Epoch 8, Batch 2700] loss: 0.04268270401778864
[Epoch 8, Batch 2800] loss: 0.03195999948453391
[Epoch 8, Batch 2900] loss: 0.03506977227210882
[Epoch 8, Batch 3000] loss: 0.02519029338407563
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0578
Validation Accuracy: 0.9824
Overfitting: 0.0578
Best model saved at epoch 8 with validation loss: 0.0578
[Epoch 9, Batch 100] loss: 0.026591527067794232
[Epoch 9, Batch 200] loss: 0.023078289144323208
[Epoch 9, Batch 300] loss: 0.046884061835153264
[Epoch 9, Batch 400] loss: 0.029239664702035952
[Epoch 9, Batch 500] loss: 0.03875506306445459
[Epoch 9, Batch 600] loss: 0.03754882964145509
[Epoch 9, Batch 700] loss: 0.025449885361886117
[Epoch 9, Batch 800] loss: 0.03245722159223078
[Epoch 9, Batch 900] loss: 0.034080908853648
[Epoch 9, Batch 1000] loss: 0.02882462701149052
[Epoch 9, Batch 1100] loss: 0.03651046979619423
[Epoch 9, Batch 1200] loss: 0.04381217423695489
[Epoch 9, Batch 1300] loss: 0.033320484064315675
[Epoch 9, Batch 1400] loss: 0.03834483462327626
[Epoch 9, Batch 1500] loss: 0.04143720836844295
[Epoch 9, Batch 1600] loss: 0.032725170693884136
[Epoch 9, Batch 1700] loss: 0.038068815699225524
[Epoch 9, Batch 1800] loss: 0.03324540688321576
[Epoch 9, Batch 1900] loss: 0.03927979498606873
[Epoch 9, Batch 2000] loss: 0.03250493179526529
[Epoch 9, Batch 2100] loss: 0.03119517710256332
[Epoch 9, Batch 2200] loss: 0.03591912945463264
[Epoch 9, Batch 2300] loss: 0.037955049597803735
[Epoch 9, Batch 2400] loss: 0.03352314522315283
[Epoch 9, Batch 2500] loss: 0.02949894314238918
[Epoch 9, Batch 2600] loss: 0.044620840866991786
[Epoch 9, Batch 2700] loss: 0.020637731925671688
[Epoch 9, Batch 2800] loss: 0.024292004928720416
[Epoch 9, Batch 2900] loss: 0.038690864772361236
[Epoch 9, Batch 3000] loss: 0.03163914475975616
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0589
Validation Accuracy: 0.9823
Overfitting: 0.0589
[Epoch 10, Batch 100] loss: 0.027168052931519925
[Epoch 10, Batch 200] loss: 0.02159751601415337
[Epoch 10, Batch 300] loss: 0.03752042767162493
[Epoch 10, Batch 400] loss: 0.02640645511186449
[Epoch 10, Batch 500] loss: 0.031203532009458287
[Epoch 10, Batch 600] loss: 0.028178967172352715
[Epoch 10, Batch 700] loss: 0.025639586257748304
[Epoch 10, Batch 800] loss: 0.03629167405721091
[Epoch 10, Batch 900] loss: 0.023078663481137483
[Epoch 10, Batch 1000] loss: 0.036952279810211625
[Epoch 10, Batch 1100] loss: 0.030584204688930184
[Epoch 10, Batch 1200] loss: 0.04032259434374282
[Epoch 10, Batch 1300] loss: 0.03925745861975884
[Epoch 10, Batch 1400] loss: 0.023340243239508708
[Epoch 10, Batch 1500] loss: 0.03299851216157549
[Epoch 10, Batch 1600] loss: 0.03258353621626156
[Epoch 10, Batch 1700] loss: 0.02685181938846654
[Epoch 10, Batch 1800] loss: 0.026437752302808804
[Epoch 10, Batch 1900] loss: 0.02841457918213564
[Epoch 10, Batch 2000] loss: 0.036372325410375196
[Epoch 10, Batch 2100] loss: 0.0307300624196796
[Epoch 10, Batch 2200] loss: 0.03712361502082786
[Epoch 10, Batch 2300] loss: 0.023644179669208825
[Epoch 10, Batch 2400] loss: 0.030291897975184837
[Epoch 10, Batch 2500] loss: 0.019334764043160247
[Epoch 10, Batch 2600] loss: 0.019724672391894273
[Epoch 10, Batch 2700] loss: 0.0271495977275481
[Epoch 10, Batch 2800] loss: 0.05734431216085795
[Epoch 10, Batch 2900] loss: 0.03194606460558134
[Epoch 10, Batch 3000] loss: 0.03716303635505028
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0591
Validation Accuracy: 0.9834
Overfitting: 0.0591
[Epoch 11, Batch 100] loss: 0.019697788039629814
[Epoch 11, Batch 200] loss: 0.01576476577185531
[Epoch 11, Batch 300] loss: 0.030073416399536656
[Epoch 11, Batch 400] loss: 0.03210146010904282
[Epoch 11, Batch 500] loss: 0.03735317648584896
[Epoch 11, Batch 600] loss: 0.031688371861309864
[Epoch 11, Batch 700] loss: 0.03363273942319211
[Epoch 11, Batch 800] loss: 0.04281632690603146
[Epoch 11, Batch 900] loss: 0.023879650521903387
[Epoch 11, Batch 1000] loss: 0.016942916712869193
[Epoch 11, Batch 1100] loss: 0.018675002131058136
[Epoch 11, Batch 1200] loss: 0.021716107562242543
[Epoch 11, Batch 1300] loss: 0.02029401461586531
[Epoch 11, Batch 1400] loss: 0.03910987906972878
[Epoch 11, Batch 1500] loss: 0.036857488560126515
[Epoch 11, Batch 1600] loss: 0.028976515521535476
[Epoch 11, Batch 1700] loss: 0.020938117782316114
[Epoch 11, Batch 1800] loss: 0.02547732184350025
[Epoch 11, Batch 1900] loss: 0.028512624826980755
[Epoch 11, Batch 2000] loss: 0.022712077023315944
[Epoch 11, Batch 2100] loss: 0.01825580388729577
[Epoch 11, Batch 2200] loss: 0.03572144047204347
[Epoch 11, Batch 2300] loss: 0.029585104372963543
[Epoch 11, Batch 2400] loss: 0.030236351451967493
[Epoch 11, Batch 2500] loss: 0.027026655727022442
[Epoch 11, Batch 2600] loss: 0.027354148550366518
[Epoch 11, Batch 2700] loss: 0.03661470449726039
[Epoch 11, Batch 2800] loss: 0.025620144257918583
[Epoch 11, Batch 2900] loss: 0.020578076615638565
[Epoch 11, Batch 3000] loss: 0.04494132558189449
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9848
Overfitting: 0.0516
Best model saved at epoch 11 with validation loss: 0.0516
[Epoch 12, Batch 100] loss: 0.01895842888363404
[Epoch 12, Batch 200] loss: 0.02921453317743726
[Epoch 12, Batch 300] loss: 0.030164898963557788
[Epoch 12, Batch 400] loss: 0.03225591133435955
[Epoch 12, Batch 500] loss: 0.02002052124007605
[Epoch 12, Batch 600] loss: 0.01930687108571874
[Epoch 12, Batch 700] loss: 0.01566772709134966
[Epoch 12, Batch 800] loss: 0.01992134259075101
[Epoch 12, Batch 900] loss: 0.02194836158756516
[Epoch 12, Batch 1000] loss: 0.019847521993942793
[Epoch 12, Batch 1100] loss: 0.019211923905459116
[Epoch 12, Batch 1200] loss: 0.026284945932566188
[Epoch 12, Batch 1300] loss: 0.019634207488343235
[Epoch 12, Batch 1400] loss: 0.017630110384307045
[Epoch 12, Batch 1500] loss: 0.026433020387994475
[Epoch 12, Batch 1600] loss: 0.01687581830239651
[Epoch 12, Batch 1700] loss: 0.025579751619152376
[Epoch 12, Batch 1800] loss: 0.02797758628414158
[Epoch 12, Batch 1900] loss: 0.03363509896953474
[Epoch 12, Batch 2000] loss: 0.020120051190679077
[Epoch 12, Batch 2100] loss: 0.02744939948472165
[Epoch 12, Batch 2200] loss: 0.0215162532632894
[Epoch 12, Batch 2300] loss: 0.035034850822994484
[Epoch 12, Batch 2400] loss: 0.03126567269959196
[Epoch 12, Batch 2500] loss: 0.022657362443496823
[Epoch 12, Batch 2600] loss: 0.016508614258273154
[Epoch 12, Batch 2700] loss: 0.0166961129705669
[Epoch 12, Batch 2800] loss: 0.027341330068593378
[Epoch 12, Batch 2900] loss: 0.033812143759278115
[Epoch 12, Batch 3000] loss: 0.05004846728159464
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0620
Validation Accuracy: 0.9824
Overfitting: 0.0620
[Epoch 13, Batch 100] loss: 0.01835145187043963
[Epoch 13, Batch 200] loss: 0.018615668623460806
[Epoch 13, Batch 300] loss: 0.026305162543576444
[Epoch 13, Batch 400] loss: 0.01482290158783144
[Epoch 13, Batch 500] loss: 0.020530521242708346
[Epoch 13, Batch 600] loss: 0.018406448349960556
[Epoch 13, Batch 700] loss: 0.015857126720502494
[Epoch 13, Batch 800] loss: 0.02578322715962713
[Epoch 13, Batch 900] loss: 0.03159069101064233
[Epoch 13, Batch 1000] loss: 0.030415832205471817
[Epoch 13, Batch 1100] loss: 0.014649661749172083
[Epoch 13, Batch 1200] loss: 0.02168793059157906
[Epoch 13, Batch 1300] loss: 0.014030350012762937
[Epoch 13, Batch 1400] loss: 0.010361827082197123
[Epoch 13, Batch 1500] loss: 0.027162106289688383
[Epoch 13, Batch 1600] loss: 0.03393616061533976
[Epoch 13, Batch 1700] loss: 0.01860085635296855
[Epoch 13, Batch 1800] loss: 0.02254089410551387
[Epoch 13, Batch 1900] loss: 0.02716854191159655
[Epoch 13, Batch 2000] loss: 0.01729134365123173
[Epoch 13, Batch 2100] loss: 0.04210980977750296
[Epoch 13, Batch 2200] loss: 0.03420943067059852
[Epoch 13, Batch 2300] loss: 0.016614290688194158
[Epoch 13, Batch 2400] loss: 0.025458823079825377
[Epoch 13, Batch 2500] loss: 0.018001701633365882
[Epoch 13, Batch 2600] loss: 0.015838449974435207
[Epoch 13, Batch 2700] loss: 0.027931981023430127
[Epoch 13, Batch 2800] loss: 0.025384407931887835
[Epoch 13, Batch 2900] loss: 0.029175723247390123
[Epoch 13, Batch 3000] loss: 0.027073313380315087
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9836
Overfitting: 0.0537
[Epoch 14, Batch 100] loss: 0.0161317095625418
[Epoch 14, Batch 200] loss: 0.014765193544626527
[Epoch 14, Batch 300] loss: 0.023738141024477955
[Epoch 14, Batch 400] loss: 0.02083971484419635
[Epoch 14, Batch 500] loss: 0.019513968960454806
[Epoch 14, Batch 600] loss: 0.028143714889520197
[Epoch 14, Batch 700] loss: 0.020852937818581267
[Epoch 14, Batch 800] loss: 0.020344540488695204
[Epoch 14, Batch 900] loss: 0.014958155577915022
[Epoch 14, Batch 1000] loss: 0.017836867980095122
[Epoch 14, Batch 1100] loss: 0.01948700657500012
[Epoch 14, Batch 1200] loss: 0.02813636786817369
[Epoch 14, Batch 1300] loss: 0.013891916765278439
[Epoch 14, Batch 1400] loss: 0.023321098938158685
[Epoch 14, Batch 1500] loss: 0.024033088386058808
[Epoch 14, Batch 1600] loss: 0.01491395231122624
[Epoch 14, Batch 1700] loss: 0.02547835075720286
[Epoch 14, Batch 1800] loss: 0.013741980147569848
[Epoch 14, Batch 1900] loss: 0.018803459030823432
[Epoch 14, Batch 2000] loss: 0.021313853812680462
[Epoch 14, Batch 2100] loss: 0.013919904608483193
[Epoch 14, Batch 2200] loss: 0.019576961509737884
[Epoch 14, Batch 2300] loss: 0.02032836995611433
[Epoch 14, Batch 2400] loss: 0.019451687820273945
[Epoch 14, Batch 2500] loss: 0.021873045404754522
[Epoch 14, Batch 2600] loss: 0.030352214151971566
[Epoch 14, Batch 2700] loss: 0.018816980227165915
[Epoch 14, Batch 2800] loss: 0.01679157157857844
[Epoch 14, Batch 2900] loss: 0.026413680276345986
[Epoch 14, Batch 3000] loss: 0.02616483874953701
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9843
Overfitting: 0.0554
[Epoch 15, Batch 100] loss: 0.010334113409808197
[Epoch 15, Batch 200] loss: 0.017228816037059006
[Epoch 15, Batch 300] loss: 0.01383835678196192
[Epoch 15, Batch 400] loss: 0.011970010719414859
[Epoch 15, Batch 500] loss: 0.019877009835799982
[Epoch 15, Batch 600] loss: 0.011510116349909368
[Epoch 15, Batch 700] loss: 0.008784299880317122
[Epoch 15, Batch 800] loss: 0.013126074967767637
[Epoch 15, Batch 900] loss: 0.020379518247591478
[Epoch 15, Batch 1000] loss: 0.009691201974274009
[Epoch 15, Batch 1100] loss: 0.009261989761107543
[Epoch 15, Batch 1200] loss: 0.015310551158181624
[Epoch 15, Batch 1300] loss: 0.013736076119930657
[Epoch 15, Batch 1400] loss: 0.01770706438124762
[Epoch 15, Batch 1500] loss: 0.01837377999276214
[Epoch 15, Batch 1600] loss: 0.020684704629466068
[Epoch 15, Batch 1700] loss: 0.01666824086350971
[Epoch 15, Batch 1800] loss: 0.022809996218456946
[Epoch 15, Batch 1900] loss: 0.019615443366637918
[Epoch 15, Batch 2000] loss: 0.026528479759163018
[Epoch 15, Batch 2100] loss: 0.01720224232052715
[Epoch 15, Batch 2200] loss: 0.024413701996218153
[Epoch 15, Batch 2300] loss: 0.031061412030394423
[Epoch 15, Batch 2400] loss: 0.03478243554054643
[Epoch 15, Batch 2500] loss: 0.01810085690860433
[Epoch 15, Batch 2600] loss: 0.018045051950612106
[Epoch 15, Batch 2700] loss: 0.020089321856803507
[Epoch 15, Batch 2800] loss: 0.03631919922092493
[Epoch 15, Batch 2900] loss: 0.01618781123399458
[Epoch 15, Batch 3000] loss: 0.016984254009948928
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9859
Overfitting: 0.0515
Best model saved at epoch 15 with validation loss: 0.0515
[Epoch 16, Batch 100] loss: 0.017394210419270167
[Epoch 16, Batch 200] loss: 0.013752887720547733
[Epoch 16, Batch 300] loss: 0.009220419628363744
[Epoch 16, Batch 400] loss: 0.02520683923692559
[Epoch 16, Batch 500] loss: 0.01758099416163532
[Epoch 16, Batch 600] loss: 0.015647387317712855
[Epoch 16, Batch 700] loss: 0.01346420563870197
[Epoch 16, Batch 800] loss: 0.018483269979928992
[Epoch 16, Batch 900] loss: 0.0248808024450409
[Epoch 16, Batch 1000] loss: 0.009733583598535916
[Epoch 16, Batch 1100] loss: 0.016993123648244363
[Epoch 16, Batch 1200] loss: 0.030524542309576644
[Epoch 16, Batch 1300] loss: 0.0185094029703032
[Epoch 16, Batch 1400] loss: 0.015085860116014373
[Epoch 16, Batch 1500] loss: 0.0190960444805296
[Epoch 16, Batch 1600] loss: 0.010784673644520808
[Epoch 16, Batch 1700] loss: 0.017786152024491457
[Epoch 16, Batch 1800] loss: 0.01868923179475132
[Epoch 16, Batch 1900] loss: 0.011602910804795101
[Epoch 16, Batch 2000] loss: 0.013431305064623303
[Epoch 16, Batch 2100] loss: 0.00840828946817055
[Epoch 16, Batch 2200] loss: 0.010883703478539246
[Epoch 16, Batch 2300] loss: 0.017399198589373555
[Epoch 16, Batch 2400] loss: 0.021660212802325985
[Epoch 16, Batch 2500] loss: 0.02726593793508073
[Epoch 16, Batch 2600] loss: 0.020572017942431558
[Epoch 16, Batch 2700] loss: 0.017874454163356857
[Epoch 16, Batch 2800] loss: 0.021125562796460145
[Epoch 16, Batch 2900] loss: 0.02651612380575898
[Epoch 16, Batch 3000] loss: 0.014509508299342997
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9846
Overfitting: 0.0592
[Epoch 17, Batch 100] loss: 0.016976554073535224
[Epoch 17, Batch 200] loss: 0.01920358804756688
[Epoch 17, Batch 300] loss: 0.014892034362856067
[Epoch 17, Batch 400] loss: 0.014933272656198824
[Epoch 17, Batch 500] loss: 0.010680639459033046
[Epoch 17, Batch 600] loss: 0.009557980640629467
[Epoch 17, Batch 700] loss: 0.01621095971462637
[Epoch 17, Batch 800] loss: 0.011056805584012182
[Epoch 17, Batch 900] loss: 0.00949105731093823
[Epoch 17, Batch 1000] loss: 0.01711580754550596
[Epoch 17, Batch 1100] loss: 0.011001221292408445
[Epoch 17, Batch 1200] loss: 0.015586271373485942
[Epoch 17, Batch 1300] loss: 0.018566971481004658
[Epoch 17, Batch 1400] loss: 0.014652625096423434
[Epoch 17, Batch 1500] loss: 0.022750324862827256
[Epoch 17, Batch 1600] loss: 0.007832176819420056
[Epoch 17, Batch 1700] loss: 0.010931373168768915
[Epoch 17, Batch 1800] loss: 0.01938266535184084
[Epoch 17, Batch 1900] loss: 0.022177360874602526
[Epoch 17, Batch 2000] loss: 0.014323765554390775
[Epoch 17, Batch 2100] loss: 0.022643287613027495
[Epoch 17, Batch 2200] loss: 0.021521538257547945
[Epoch 17, Batch 2300] loss: 0.016836699698187657
[Epoch 17, Batch 2400] loss: 0.024896143762580324
[Epoch 17, Batch 2500] loss: 0.019243909251363222
[Epoch 17, Batch 2600] loss: 0.015608833964179211
[Epoch 17, Batch 2700] loss: 0.01707637183766565
[Epoch 17, Batch 2800] loss: 0.024326311424310916
[Epoch 17, Batch 2900] loss: 0.011777439924226201
[Epoch 17, Batch 3000] loss: 0.02319661297442508
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9862
Overfitting: 0.0505
Best model saved at epoch 17 with validation loss: 0.0505
[Epoch 18, Batch 100] loss: 0.012059026705828728
[Epoch 18, Batch 200] loss: 0.01348652998376565
[Epoch 18, Batch 300] loss: 0.009578272046092025
[Epoch 18, Batch 400] loss: 0.008034827803785448
[Epoch 18, Batch 500] loss: 0.014100033567756328
[Epoch 18, Batch 600] loss: 0.010160216786644014
[Epoch 18, Batch 700] loss: 0.014043932628374023
[Epoch 18, Batch 800] loss: 0.010828069464041619
[Epoch 18, Batch 900] loss: 0.014927666834059891
[Epoch 18, Batch 1000] loss: 0.018527454882605526
[Epoch 18, Batch 1100] loss: 0.01944283266893308
[Epoch 18, Batch 1200] loss: 0.014137270043356694
[Epoch 18, Batch 1300] loss: 0.01857969377970221
[Epoch 18, Batch 1400] loss: 0.014175366746594592
[Epoch 18, Batch 1500] loss: 0.013596281880290917
[Epoch 18, Batch 1600] loss: 0.021456146602108674
[Epoch 18, Batch 1700] loss: 0.02106466429437205
[Epoch 18, Batch 1800] loss: 0.012624686506169382
[Epoch 18, Batch 1900] loss: 0.02041917935199308
[Epoch 18, Batch 2000] loss: 0.011104766899752577
[Epoch 18, Batch 2100] loss: 0.015235546981857624
[Epoch 18, Batch 2200] loss: 0.011088660008208535
[Epoch 18, Batch 2300] loss: 0.018994092730681585
[Epoch 18, Batch 2400] loss: 0.011001086206670152
[Epoch 18, Batch 2500] loss: 0.0074961539552168685
[Epoch 18, Batch 2600] loss: 0.009510266179458994
[Epoch 18, Batch 2700] loss: 0.008103314689435592
[Epoch 18, Batch 2800] loss: 0.012548070307275339
[Epoch 18, Batch 2900] loss: 0.007118615860763384
[Epoch 18, Batch 3000] loss: 0.013862626175086917
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9846
Overfitting: 0.0581
[Epoch 19, Batch 100] loss: 0.012667703775550763
[Epoch 19, Batch 200] loss: 0.00578942149408249
[Epoch 19, Batch 300] loss: 0.006369881703785722
[Epoch 19, Batch 400] loss: 0.014776916140381218
[Epoch 19, Batch 500] loss: 0.010357911327164402
[Epoch 19, Batch 600] loss: 0.006362679948842924
[Epoch 19, Batch 700] loss: 0.019735315227353566
[Epoch 19, Batch 800] loss: 0.008006524306001666
[Epoch 19, Batch 900] loss: 0.016379241425652252
[Epoch 19, Batch 1000] loss: 0.007962001776904799
[Epoch 19, Batch 1100] loss: 0.01060576500874049
[Epoch 19, Batch 1200] loss: 0.012132495349492274
[Epoch 19, Batch 1300] loss: 0.011510009496970498
[Epoch 19, Batch 1400] loss: 0.015076464202138595
[Epoch 19, Batch 1500] loss: 0.023038516804190293
[Epoch 19, Batch 1600] loss: 0.019916356176836417
[Epoch 19, Batch 1700] loss: 0.02071059209044506
[Epoch 19, Batch 1800] loss: 0.010638462594142766
[Epoch 19, Batch 1900] loss: 0.015367576536555135
[Epoch 19, Batch 2000] loss: 0.010242697660851263
[Epoch 19, Batch 2100] loss: 0.014347053218816654
[Epoch 19, Batch 2200] loss: 0.012366383831404164
[Epoch 19, Batch 2300] loss: 0.018116549848191426
[Epoch 19, Batch 2400] loss: 0.01123270585840146
[Epoch 19, Batch 2500] loss: 0.011503145861588564
[Epoch 19, Batch 2600] loss: 0.005885897453833877
[Epoch 19, Batch 2700] loss: 0.015360312749730837
[Epoch 19, Batch 2800] loss: 0.015717209378904043
[Epoch 19, Batch 2900] loss: 0.009570873300463063
[Epoch 19, Batch 3000] loss: 0.008049194516024727
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9868
Overfitting: 0.0523
[Epoch 20, Batch 100] loss: 0.013726103989019975
[Epoch 20, Batch 200] loss: 0.01121507972823565
[Epoch 20, Batch 300] loss: 0.010928377185837234
[Epoch 20, Batch 400] loss: 0.015196992975852482
[Epoch 20, Batch 500] loss: 0.006221244818843843
[Epoch 20, Batch 600] loss: 0.017722540892195868
[Epoch 20, Batch 700] loss: 0.020206933725567068
[Epoch 20, Batch 800] loss: 0.010371527659590356
[Epoch 20, Batch 900] loss: 0.00859456947984654
[Epoch 20, Batch 1000] loss: 0.006530277076490165
[Epoch 20, Batch 1100] loss: 0.012210133791468252
[Epoch 20, Batch 1200] loss: 0.009384739338602231
[Epoch 20, Batch 1300] loss: 0.008449685102643798
[Epoch 20, Batch 1400] loss: 0.01225779846142359
[Epoch 20, Batch 1500] loss: 0.01855556956386863
[Epoch 20, Batch 1600] loss: 0.015128936718201657
[Epoch 20, Batch 1700] loss: 0.005984297109625914
[Epoch 20, Batch 1800] loss: 0.009414271126879613
[Epoch 20, Batch 1900] loss: 0.01428931188590468
[Epoch 20, Batch 2000] loss: 0.009681164536286814
[Epoch 20, Batch 2100] loss: 0.008158829518936272
[Epoch 20, Batch 2200] loss: 0.005954459646745818
[Epoch 20, Batch 2300] loss: 0.011079686241955641
[Epoch 20, Batch 2400] loss: 0.016387643560465223
[Epoch 20, Batch 2500] loss: 0.009797041259175784
[Epoch 20, Batch 2600] loss: 0.01521157209629564
[Epoch 20, Batch 2700] loss: 0.013910747464683482
[Epoch 20, Batch 2800] loss: 0.016729431905441742
[Epoch 20, Batch 2900] loss: 0.012319384993102176
[Epoch 20, Batch 3000] loss: 0.010224124830970141
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9863
Overfitting: 0.0569
[Epoch 21, Batch 100] loss: 0.00934323823673367
[Epoch 21, Batch 200] loss: 0.012787847271756619
[Epoch 21, Batch 300] loss: 0.004778152898670669
[Epoch 21, Batch 400] loss: 0.017755269955596304
[Epoch 21, Batch 500] loss: 0.017289990352896894
[Epoch 21, Batch 600] loss: 0.009984150695099742
[Epoch 21, Batch 700] loss: 0.010403031544537953
[Epoch 21, Batch 800] loss: 0.013500845733078677
[Epoch 21, Batch 900] loss: 0.006595870511528119
[Epoch 21, Batch 1000] loss: 0.01489523839300091
[Epoch 21, Batch 1100] loss: 0.015820293103697623
[Epoch 21, Batch 1200] loss: 0.005400287343836681
[Epoch 21, Batch 1300] loss: 0.0040153127895519
[Epoch 21, Batch 1400] loss: 0.009436907324497952
[Epoch 21, Batch 1500] loss: 0.00972065206553907
[Epoch 21, Batch 1600] loss: 0.011770519713936665
[Epoch 21, Batch 1700] loss: 0.007944428766134024
[Epoch 21, Batch 1800] loss: 0.017994217493219368
[Epoch 21, Batch 1900] loss: 0.013974331105323472
[Epoch 21, Batch 2000] loss: 0.014078536833676481
[Epoch 21, Batch 2100] loss: 0.009285705103538931
[Epoch 21, Batch 2200] loss: 0.009587714586505171
[Epoch 21, Batch 2300] loss: 0.01859342446374285
[Epoch 21, Batch 2400] loss: 0.010395129904168243
[Epoch 21, Batch 2500] loss: 0.016382380601417026
[Epoch 21, Batch 2600] loss: 0.018608710970129325
[Epoch 21, Batch 2700] loss: 0.0092594517461157
[Epoch 21, Batch 2800] loss: 0.010939064301733198
[Epoch 21, Batch 2900] loss: 0.011886776103474404
[Epoch 21, Batch 3000] loss: 0.005896022316305789
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9866
Overfitting: 0.0520
[Epoch 22, Batch 100] loss: 0.009832834283479315
[Epoch 22, Batch 200] loss: 0.009094549350568287
[Epoch 22, Batch 300] loss: 0.010584205028726501
[Epoch 22, Batch 400] loss: 0.009248377932512994
[Epoch 22, Batch 500] loss: 0.010737342268603242
[Epoch 22, Batch 600] loss: 0.013428412771518197
[Epoch 22, Batch 700] loss: 0.008629225676918395
[Epoch 22, Batch 800] loss: 0.006505012708144023
[Epoch 22, Batch 900] loss: 0.006218761682366676
[Epoch 22, Batch 1000] loss: 0.004861605313492418
[Epoch 22, Batch 1100] loss: 0.010113176932027273
[Epoch 22, Batch 1200] loss: 0.014278228697414762
[Epoch 22, Batch 1300] loss: 0.0043694496472153335
[Epoch 22, Batch 1400] loss: 0.014425391673244121
[Epoch 22, Batch 1500] loss: 0.009459757181007262
[Epoch 22, Batch 1600] loss: 0.00669597550094295
[Epoch 22, Batch 1700] loss: 0.007537935648565508
[Epoch 22, Batch 1800] loss: 0.011027751763692776
[Epoch 22, Batch 1900] loss: 0.007873448818254474
[Epoch 22, Batch 2000] loss: 0.01230069483762236
[Epoch 22, Batch 2100] loss: 0.00908462379298271
[Epoch 22, Batch 2200] loss: 0.009124777947372422
[Epoch 22, Batch 2300] loss: 0.0062062805185723845
[Epoch 22, Batch 2400] loss: 0.006744267266094539
[Epoch 22, Batch 2500] loss: 0.004169070436519178
[Epoch 22, Batch 2600] loss: 0.010277541202106022
[Epoch 22, Batch 2700] loss: 0.011402529153724573
[Epoch 22, Batch 2800] loss: 0.011422559356369676
[Epoch 22, Batch 2900] loss: 0.01103642961026253
[Epoch 22, Batch 3000] loss: 0.005817005368896844
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9860
Overfitting: 0.0570
[Epoch 23, Batch 100] loss: 0.014235991974428543
[Epoch 23, Batch 200] loss: 0.0038104713819137716
[Epoch 23, Batch 300] loss: 0.008295590407540203
[Epoch 23, Batch 400] loss: 0.003041240845034281
[Epoch 23, Batch 500] loss: 0.008524953656349225
[Epoch 23, Batch 600] loss: 0.00564089549586015
[Epoch 23, Batch 700] loss: 0.006785962168603419
[Epoch 23, Batch 800] loss: 0.004992054774011195
[Epoch 23, Batch 900] loss: 0.0086710154251341
[Epoch 23, Batch 1000] loss: 0.00852857222602097
[Epoch 23, Batch 1100] loss: 0.009219295919347132
[Epoch 23, Batch 1200] loss: 0.010636975623558555
[Epoch 23, Batch 1300] loss: 0.00634082634222068
[Epoch 23, Batch 1400] loss: 0.006357913311360335
[Epoch 23, Batch 1500] loss: 0.012776890299892329
[Epoch 23, Batch 1600] loss: 0.006583591851076562
[Epoch 23, Batch 1700] loss: 0.008808633360255272
[Epoch 23, Batch 1800] loss: 0.004449530114670779
[Epoch 23, Batch 1900] loss: 0.006899142284360096
[Epoch 23, Batch 2000] loss: 0.00812892146183799
[Epoch 23, Batch 2100] loss: 0.008757178260864293
[Epoch 23, Batch 2200] loss: 0.011518191233353719
[Epoch 23, Batch 2300] loss: 0.00960914468841338
[Epoch 23, Batch 2400] loss: 0.008455436427620953
[Epoch 23, Batch 2500] loss: 0.009678020318010567
[Epoch 23, Batch 2600] loss: 0.007974539419344638
[Epoch 23, Batch 2700] loss: 0.027436740716527765
[Epoch 23, Batch 2800] loss: 0.006873428722333302
[Epoch 23, Batch 2900] loss: 0.006849442992497643
[Epoch 23, Batch 3000] loss: 0.007645273003790862
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9865
Overfitting: 0.0539
[Epoch 24, Batch 100] loss: 0.007659827412066988
[Epoch 24, Batch 200] loss: 0.006340531093337631
[Epoch 24, Batch 300] loss: 0.006329106951543508
[Epoch 24, Batch 400] loss: 0.0034957813576306763
[Epoch 24, Batch 500] loss: 0.004806618598122441
[Epoch 24, Batch 600] loss: 0.008122644440963995
[Epoch 24, Batch 700] loss: 0.004543552031723266
[Epoch 24, Batch 800] loss: 0.012264918287928594
[Epoch 24, Batch 900] loss: 0.005280047389858282
[Epoch 24, Batch 1000] loss: 0.009458795921818818
[Epoch 24, Batch 1100] loss: 0.005309182551571894
[Epoch 24, Batch 1200] loss: 0.00577946302082637
[Epoch 24, Batch 1300] loss: 0.01424444598730588
[Epoch 24, Batch 1400] loss: 0.006719649116885194
[Epoch 24, Batch 1500] loss: 0.003730139968488402
[Epoch 24, Batch 1600] loss: 0.004264082258189319
[Epoch 24, Batch 1700] loss: 0.007966009696065156
[Epoch 24, Batch 1800] loss: 0.004716435714605041
[Epoch 24, Batch 1900] loss: 0.0076664899942676355
[Epoch 24, Batch 2000] loss: 0.010803519768237492
[Epoch 24, Batch 2100] loss: 0.012271655244092017
[Epoch 24, Batch 2200] loss: 0.004359332843932862
[Epoch 24, Batch 2300] loss: 0.007475710262195889
[Epoch 24, Batch 2400] loss: 0.009015347885788288
[Epoch 24, Batch 2500] loss: 0.005218920589682057
[Epoch 24, Batch 2600] loss: 0.00519359870800713
[Epoch 24, Batch 2700] loss: 0.008763235549856745
[Epoch 24, Batch 2800] loss: 0.0065195241020501275
[Epoch 24, Batch 2900] loss: 0.01145875747201444
[Epoch 24, Batch 3000] loss: 0.010073433778056824
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0621
Validation Accuracy: 0.9842
Overfitting: 0.0621
Fold 2 validation loss: 0.0621
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3010409808158876
[Epoch 1, Batch 200] loss: 2.291951892375946
[Epoch 1, Batch 300] loss: 2.282734122276306
[Epoch 1, Batch 400] loss: 2.2648249816894532
[Epoch 1, Batch 500] loss: 2.226060872077942
[Epoch 1, Batch 600] loss: 2.127915998697281
[Epoch 1, Batch 700] loss: 1.7658044970035554
[Epoch 1, Batch 800] loss: 1.1030571192502976
[Epoch 1, Batch 900] loss: 0.8240348553657532
[Epoch 1, Batch 1000] loss: 0.6600487220287323
[Epoch 1, Batch 1100] loss: 0.5557645136117935
[Epoch 1, Batch 1200] loss: 0.538174859881401
[Epoch 1, Batch 1300] loss: 0.5253649546205997
[Epoch 1, Batch 1400] loss: 0.45062060341238974
[Epoch 1, Batch 1500] loss: 0.43786274522542956
[Epoch 1, Batch 1600] loss: 0.3754903085157275
[Epoch 1, Batch 1700] loss: 0.3641538982093334
[Epoch 1, Batch 1800] loss: 0.34011669173836706
[Epoch 1, Batch 1900] loss: 0.33568498186767104
[Epoch 1, Batch 2000] loss: 0.2940465546399355
[Epoch 1, Batch 2100] loss: 0.2568510891869664
[Epoch 1, Batch 2200] loss: 0.24733799029141665
[Epoch 1, Batch 2300] loss: 0.23669352307915686
[Epoch 1, Batch 2400] loss: 0.2638767717964947
[Epoch 1, Batch 2500] loss: 0.23439236626029014
[Epoch 1, Batch 2600] loss: 0.2180596359446645
[Epoch 1, Batch 2700] loss: 0.225936192413792
[Epoch 1, Batch 2800] loss: 0.22017520494759082
[Epoch 1, Batch 2900] loss: 0.1972046272456646
[Epoch 1, Batch 3000] loss: 0.1955263586435467
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2037
Validation Accuracy: 0.9424
Overfitting: 0.2037
Best model saved at epoch 1 with validation loss: 0.2037
[Epoch 2, Batch 100] loss: 0.17886815614998341
[Epoch 2, Batch 200] loss: 0.18718768569640815
[Epoch 2, Batch 300] loss: 0.14564165249001235
[Epoch 2, Batch 400] loss: 0.1346309440396726
[Epoch 2, Batch 500] loss: 0.1476683653285727
[Epoch 2, Batch 600] loss: 0.15418759416323155
[Epoch 2, Batch 700] loss: 0.17623175650835038
[Epoch 2, Batch 800] loss: 0.14440792311448603
[Epoch 2, Batch 900] loss: 0.13558498268015684
[Epoch 2, Batch 1000] loss: 0.12140567113645374
[Epoch 2, Batch 1100] loss: 0.14315315791405736
[Epoch 2, Batch 1200] loss: 0.17223032750189304
[Epoch 2, Batch 1300] loss: 0.14714509611949325
[Epoch 2, Batch 1400] loss: 0.16122324450872838
[Epoch 2, Batch 1500] loss: 0.15155332379043102
[Epoch 2, Batch 1600] loss: 0.11539700451306999
[Epoch 2, Batch 1700] loss: 0.1378389458497986
[Epoch 2, Batch 1800] loss: 0.12251484714914113
[Epoch 2, Batch 1900] loss: 0.11077854681760073
[Epoch 2, Batch 2000] loss: 0.09234612939646468
[Epoch 2, Batch 2100] loss: 0.11059172799810767
[Epoch 2, Batch 2200] loss: 0.12214988426771015
[Epoch 2, Batch 2300] loss: 0.10200977427884936
[Epoch 2, Batch 2400] loss: 0.11478441007435322
[Epoch 2, Batch 2500] loss: 0.0982530632102862
[Epoch 2, Batch 2600] loss: 0.10970895526348613
[Epoch 2, Batch 2700] loss: 0.12196021764073521
[Epoch 2, Batch 2800] loss: 0.0919679515552707
[Epoch 2, Batch 2900] loss: 0.08113199475686997
[Epoch 2, Batch 3000] loss: 0.13205689301947132
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1226
Validation Accuracy: 0.9638
Overfitting: 0.1226
Best model saved at epoch 2 with validation loss: 0.1226
[Epoch 3, Batch 100] loss: 0.10589974391739815
[Epoch 3, Batch 200] loss: 0.08389258525334299
[Epoch 3, Batch 300] loss: 0.10211841906653717
[Epoch 3, Batch 400] loss: 0.09835247677518055
[Epoch 3, Batch 500] loss: 0.09877551815239713
[Epoch 3, Batch 600] loss: 0.08092605107929557
[Epoch 3, Batch 700] loss: 0.07966561235138216
[Epoch 3, Batch 800] loss: 0.07554047766840086
[Epoch 3, Batch 900] loss: 0.07863983027869835
[Epoch 3, Batch 1000] loss: 0.10969579753582366
[Epoch 3, Batch 1100] loss: 0.08376030257903039
[Epoch 3, Batch 1200] loss: 0.08456179674016312
[Epoch 3, Batch 1300] loss: 0.0982129243889358
[Epoch 3, Batch 1400] loss: 0.08818784570554271
[Epoch 3, Batch 1500] loss: 0.07242617760901339
[Epoch 3, Batch 1600] loss: 0.07144642065744847
[Epoch 3, Batch 1700] loss: 0.10375799478730187
[Epoch 3, Batch 1800] loss: 0.06293652555439622
[Epoch 3, Batch 1900] loss: 0.09077763973386027
[Epoch 3, Batch 2000] loss: 0.08786874909652397
[Epoch 3, Batch 2100] loss: 0.07974844367825426
[Epoch 3, Batch 2200] loss: 0.08412781584076584
[Epoch 3, Batch 2300] loss: 0.07408130440395326
[Epoch 3, Batch 2400] loss: 0.07357858462492003
[Epoch 3, Batch 2500] loss: 0.0933856406196719
[Epoch 3, Batch 2600] loss: 0.08924744171788916
[Epoch 3, Batch 2700] loss: 0.09065908787539229
[Epoch 3, Batch 2800] loss: 0.06507862586877308
[Epoch 3, Batch 2900] loss: 0.06956764257396571
[Epoch 3, Batch 3000] loss: 0.09098139981273562
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0834
Validation Accuracy: 0.9745
Overfitting: 0.0834
Best model saved at epoch 3 with validation loss: 0.0834
[Epoch 4, Batch 100] loss: 0.09299311309703626
[Epoch 4, Batch 200] loss: 0.060668926453217864
[Epoch 4, Batch 300] loss: 0.05520411665551364
[Epoch 4, Batch 400] loss: 0.07378051189589314
[Epoch 4, Batch 500] loss: 0.06354236629791558
[Epoch 4, Batch 600] loss: 0.08692561983480118
[Epoch 4, Batch 700] loss: 0.06970222752308473
[Epoch 4, Batch 800] loss: 0.054393442471046
[Epoch 4, Batch 900] loss: 0.07645617613801732
[Epoch 4, Batch 1000] loss: 0.0810238952038344
[Epoch 4, Batch 1100] loss: 0.067644700887613
[Epoch 4, Batch 1200] loss: 0.06469354792963714
[Epoch 4, Batch 1300] loss: 0.056124885417521
[Epoch 4, Batch 1400] loss: 0.05237567387637682
[Epoch 4, Batch 1500] loss: 0.0623343230097089
[Epoch 4, Batch 1600] loss: 0.058614324170048346
[Epoch 4, Batch 1700] loss: 0.0564286056754645
[Epoch 4, Batch 1800] loss: 0.07410711441538297
[Epoch 4, Batch 1900] loss: 0.057942702536820434
[Epoch 4, Batch 2000] loss: 0.06683207773137838
[Epoch 4, Batch 2100] loss: 0.06810649936262053
[Epoch 4, Batch 2200] loss: 0.07967096893698908
[Epoch 4, Batch 2300] loss: 0.0604616584663745
[Epoch 4, Batch 2400] loss: 0.05787285289959982
[Epoch 4, Batch 2500] loss: 0.08625165466684848
[Epoch 4, Batch 2600] loss: 0.06421393527649343
[Epoch 4, Batch 2700] loss: 0.05572798152337782
[Epoch 4, Batch 2800] loss: 0.05175046402902808
[Epoch 4, Batch 2900] loss: 0.072576417386299
[Epoch 4, Batch 3000] loss: 0.06319504451414104
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0719
Validation Accuracy: 0.9782
Overfitting: 0.0719
Best model saved at epoch 4 with validation loss: 0.0719
[Epoch 5, Batch 100] loss: 0.04292019212385639
[Epoch 5, Batch 200] loss: 0.04145855296927039
[Epoch 5, Batch 300] loss: 0.06527912745310459
[Epoch 5, Batch 400] loss: 0.04366682195221074
[Epoch 5, Batch 500] loss: 0.06933703810645966
[Epoch 5, Batch 600] loss: 0.05929126515547978
[Epoch 5, Batch 700] loss: 0.07297536215395667
[Epoch 5, Batch 800] loss: 0.05672793762525544
[Epoch 5, Batch 900] loss: 0.05640443624346517
[Epoch 5, Batch 1000] loss: 0.056796583956456745
[Epoch 5, Batch 1100] loss: 0.0543705903517548
[Epoch 5, Batch 1200] loss: 0.05822469088539947
[Epoch 5, Batch 1300] loss: 0.053176946602761746
[Epoch 5, Batch 1400] loss: 0.06129072870477103
[Epoch 5, Batch 1500] loss: 0.0574956961243879
[Epoch 5, Batch 1600] loss: 0.06836316886474378
[Epoch 5, Batch 1700] loss: 0.07173438078491018
[Epoch 5, Batch 1800] loss: 0.05408368538832292
[Epoch 5, Batch 1900] loss: 0.055700793866417374
[Epoch 5, Batch 2000] loss: 0.051445815870538356
[Epoch 5, Batch 2100] loss: 0.055040499159367755
[Epoch 5, Batch 2200] loss: 0.05772072928550188
[Epoch 5, Batch 2300] loss: 0.0393958111241227
[Epoch 5, Batch 2400] loss: 0.04361326770042069
[Epoch 5, Batch 2500] loss: 0.05802123315370409
[Epoch 5, Batch 2600] loss: 0.056869539842882656
[Epoch 5, Batch 2700] loss: 0.062431838179472836
[Epoch 5, Batch 2800] loss: 0.04820748300931882
[Epoch 5, Batch 2900] loss: 0.05478130141389556
[Epoch 5, Batch 3000] loss: 0.056312753957754466
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9808
Overfitting: 0.0635
Best model saved at epoch 5 with validation loss: 0.0635
[Epoch 6, Batch 100] loss: 0.0532347070047399
[Epoch 6, Batch 200] loss: 0.041551838894374665
[Epoch 6, Batch 300] loss: 0.04479339595985948
[Epoch 6, Batch 400] loss: 0.0499331720022019
[Epoch 6, Batch 500] loss: 0.05926651597532327
[Epoch 6, Batch 600] loss: 0.03749305916717276
[Epoch 6, Batch 700] loss: 0.038945706837112085
[Epoch 6, Batch 800] loss: 0.052976358033338326
[Epoch 6, Batch 900] loss: 0.03825687230448239
[Epoch 6, Batch 1000] loss: 0.03903386856225552
[Epoch 6, Batch 1100] loss: 0.048555102494283346
[Epoch 6, Batch 1200] loss: 0.05656411129748449
[Epoch 6, Batch 1300] loss: 0.03909973693429492
[Epoch 6, Batch 1400] loss: 0.04755495039978996
[Epoch 6, Batch 1500] loss: 0.05742600942903664
[Epoch 6, Batch 1600] loss: 0.07265828484742087
[Epoch 6, Batch 1700] loss: 0.05283972671139054
[Epoch 6, Batch 1800] loss: 0.07011634398251772
[Epoch 6, Batch 1900] loss: 0.04006620989937801
[Epoch 6, Batch 2000] loss: 0.039086942624417136
[Epoch 6, Batch 2100] loss: 0.05185691561026033
[Epoch 6, Batch 2200] loss: 0.04964691269036848
[Epoch 6, Batch 2300] loss: 0.054172785949485845
[Epoch 6, Batch 2400] loss: 0.047144073813979046
[Epoch 6, Batch 2500] loss: 0.04067162817431381
[Epoch 6, Batch 2600] loss: 0.04443052442831686
[Epoch 6, Batch 2700] loss: 0.0364350016649405
[Epoch 6, Batch 2800] loss: 0.0316366248606937
[Epoch 6, Batch 2900] loss: 0.0568644671815855
[Epoch 6, Batch 3000] loss: 0.04428904938104097
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0616
Validation Accuracy: 0.9814
Overfitting: 0.0616
Best model saved at epoch 6 with validation loss: 0.0616
[Epoch 7, Batch 100] loss: 0.0558322713081725
[Epoch 7, Batch 200] loss: 0.033343365820473994
[Epoch 7, Batch 300] loss: 0.06326187800703337
[Epoch 7, Batch 400] loss: 0.02896430872322526
[Epoch 7, Batch 500] loss: 0.051512338918983006
[Epoch 7, Batch 600] loss: 0.036852730823302406
[Epoch 7, Batch 700] loss: 0.06214039003447397
[Epoch 7, Batch 800] loss: 0.04906691494688857
[Epoch 7, Batch 900] loss: 0.03933331750216894
[Epoch 7, Batch 1000] loss: 0.04344848971108149
[Epoch 7, Batch 1100] loss: 0.04383313937054481
[Epoch 7, Batch 1200] loss: 0.032814294779673216
[Epoch 7, Batch 1300] loss: 0.041926198416040276
[Epoch 7, Batch 1400] loss: 0.05067091916629579
[Epoch 7, Batch 1500] loss: 0.03761082782351877
[Epoch 7, Batch 1600] loss: 0.028603756741940742
[Epoch 7, Batch 1700] loss: 0.04172925776365446
[Epoch 7, Batch 1800] loss: 0.043047685372876
[Epoch 7, Batch 1900] loss: 0.03614697156022885
[Epoch 7, Batch 2000] loss: 0.04313621349967434
[Epoch 7, Batch 2100] loss: 0.0370534571200551
[Epoch 7, Batch 2200] loss: 0.04247295786466566
[Epoch 7, Batch 2300] loss: 0.03321369710116415
[Epoch 7, Batch 2400] loss: 0.0443555511093291
[Epoch 7, Batch 2500] loss: 0.054154897967528086
[Epoch 7, Batch 2600] loss: 0.0372235805215314
[Epoch 7, Batch 2700] loss: 0.044062065608595734
[Epoch 7, Batch 2800] loss: 0.0369921087223338
[Epoch 7, Batch 2900] loss: 0.04565585338365054
[Epoch 7, Batch 3000] loss: 0.028518598715018016
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9848
Overfitting: 0.0532
Best model saved at epoch 7 with validation loss: 0.0532
[Epoch 8, Batch 100] loss: 0.03062677320362127
[Epoch 8, Batch 200] loss: 0.031769566036527974
[Epoch 8, Batch 300] loss: 0.04467632652434986
[Epoch 8, Batch 400] loss: 0.04454099254551693
[Epoch 8, Batch 500] loss: 0.048797819153405725
[Epoch 8, Batch 600] loss: 0.0238325763719331
[Epoch 8, Batch 700] loss: 0.034848145058349475
[Epoch 8, Batch 800] loss: 0.035562588698812764
[Epoch 8, Batch 900] loss: 0.04786148229875835
[Epoch 8, Batch 1000] loss: 0.03469565860024886
[Epoch 8, Batch 1100] loss: 0.04695112630841322
[Epoch 8, Batch 1200] loss: 0.027188700118567794
[Epoch 8, Batch 1300] loss: 0.03421835054876283
[Epoch 8, Batch 1400] loss: 0.0458723541314248
[Epoch 8, Batch 1500] loss: 0.030807310687960124
[Epoch 8, Batch 1600] loss: 0.02836566769168712
[Epoch 8, Batch 1700] loss: 0.03289972960497835
[Epoch 8, Batch 1800] loss: 0.04429601086318144
[Epoch 8, Batch 1900] loss: 0.027676099855307258
[Epoch 8, Batch 2000] loss: 0.03436750076609314
[Epoch 8, Batch 2100] loss: 0.02042813200459932
[Epoch 8, Batch 2200] loss: 0.04846313992908108
[Epoch 8, Batch 2300] loss: 0.03858943271814496
[Epoch 8, Batch 2400] loss: 0.03402600737201283
[Epoch 8, Batch 2500] loss: 0.03060300085111521
[Epoch 8, Batch 2600] loss: 0.048080941070220436
[Epoch 8, Batch 2700] loss: 0.023922232531622286
[Epoch 8, Batch 2800] loss: 0.027028393969376337
[Epoch 8, Batch 2900] loss: 0.03498715008601721
[Epoch 8, Batch 3000] loss: 0.048958840574050554
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9842
Overfitting: 0.0554
[Epoch 9, Batch 100] loss: 0.02884043996236869
[Epoch 9, Batch 200] loss: 0.021637918283959154
[Epoch 9, Batch 300] loss: 0.02699271947647503
[Epoch 9, Batch 400] loss: 0.01940986909023195
[Epoch 9, Batch 500] loss: 0.033155458830151474
[Epoch 9, Batch 600] loss: 0.027122547584585845
[Epoch 9, Batch 700] loss: 0.03790782590411254
[Epoch 9, Batch 800] loss: 0.04427254954927776
[Epoch 9, Batch 900] loss: 0.03362383227307873
[Epoch 9, Batch 1000] loss: 0.02718298175983364
[Epoch 9, Batch 1100] loss: 0.0378591425200284
[Epoch 9, Batch 1200] loss: 0.01542271123456885
[Epoch 9, Batch 1300] loss: 0.03429362401351682
[Epoch 9, Batch 1400] loss: 0.03688321719135274
[Epoch 9, Batch 1500] loss: 0.05117751930971281
[Epoch 9, Batch 1600] loss: 0.03126215934862557
[Epoch 9, Batch 1700] loss: 0.04616657713515451
[Epoch 9, Batch 1800] loss: 0.03668344386067474
[Epoch 9, Batch 1900] loss: 0.03692702666245168
[Epoch 9, Batch 2000] loss: 0.033128686225390995
[Epoch 9, Batch 2100] loss: 0.03449160901625874
[Epoch 9, Batch 2200] loss: 0.024112828099459874
[Epoch 9, Batch 2300] loss: 0.02803943364207953
[Epoch 9, Batch 2400] loss: 0.033646212093008214
[Epoch 9, Batch 2500] loss: 0.024970894539146683
[Epoch 9, Batch 2600] loss: 0.030747924983734264
[Epoch 9, Batch 2700] loss: 0.03059082950319862
[Epoch 9, Batch 2800] loss: 0.03159527971161879
[Epoch 9, Batch 2900] loss: 0.03328188088387833
[Epoch 9, Batch 3000] loss: 0.044846581300516844
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9842
Overfitting: 0.0529
Best model saved at epoch 9 with validation loss: 0.0529
[Epoch 10, Batch 100] loss: 0.026564269295340635
[Epoch 10, Batch 200] loss: 0.02440221512952121
[Epoch 10, Batch 300] loss: 0.030236472701035383
[Epoch 10, Batch 400] loss: 0.04191607879954972
[Epoch 10, Batch 500] loss: 0.018696885899407788
[Epoch 10, Batch 600] loss: 0.024167984151863494
[Epoch 10, Batch 700] loss: 0.02196487902881927
[Epoch 10, Batch 800] loss: 0.02397931876112125
[Epoch 10, Batch 900] loss: 0.029966997313713363
[Epoch 10, Batch 1000] loss: 0.024657364572922235
[Epoch 10, Batch 1100] loss: 0.030308751102056705
[Epoch 10, Batch 1200] loss: 0.043366160449440944
[Epoch 10, Batch 1300] loss: 0.031249922821880317
[Epoch 10, Batch 1400] loss: 0.035041539539088264
[Epoch 10, Batch 1500] loss: 0.026652819254741188
[Epoch 10, Batch 1600] loss: 0.0329967097620829
[Epoch 10, Batch 1700] loss: 0.022670436911139406
[Epoch 10, Batch 1800] loss: 0.03626254783637705
[Epoch 10, Batch 1900] loss: 0.022495258603448746
[Epoch 10, Batch 2000] loss: 0.02316072291485398
[Epoch 10, Batch 2100] loss: 0.03487656359953689
[Epoch 10, Batch 2200] loss: 0.03138717888636165
[Epoch 10, Batch 2300] loss: 0.030713995791957133
[Epoch 10, Batch 2400] loss: 0.02881741327466443
[Epoch 10, Batch 2500] loss: 0.02883886082949175
[Epoch 10, Batch 2600] loss: 0.028189432092694915
[Epoch 10, Batch 2700] loss: 0.03400983076688135
[Epoch 10, Batch 2800] loss: 0.03150475419213763
[Epoch 10, Batch 2900] loss: 0.03070303270833392
[Epoch 10, Batch 3000] loss: 0.029622013162297664
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9861
Overfitting: 0.0496
Best model saved at epoch 10 with validation loss: 0.0496
[Epoch 11, Batch 100] loss: 0.027515145020588536
[Epoch 11, Batch 200] loss: 0.020897550504741957
[Epoch 11, Batch 300] loss: 0.019812956540954475
[Epoch 11, Batch 400] loss: 0.019820777648928926
[Epoch 11, Batch 500] loss: 0.012578164857950469
[Epoch 11, Batch 600] loss: 0.016209510547996617
[Epoch 11, Batch 700] loss: 0.02933842754318903
[Epoch 11, Batch 800] loss: 0.02101850579476377
[Epoch 11, Batch 900] loss: 0.023945446903962875
[Epoch 11, Batch 1000] loss: 0.02901297374854039
[Epoch 11, Batch 1100] loss: 0.016703109846275765
[Epoch 11, Batch 1200] loss: 0.02453590598917799
[Epoch 11, Batch 1300] loss: 0.020923294157546478
[Epoch 11, Batch 1400] loss: 0.029631619992214836
[Epoch 11, Batch 1500] loss: 0.03266914017578529
[Epoch 11, Batch 1600] loss: 0.032115354259221934
[Epoch 11, Batch 1700] loss: 0.02176297988917213
[Epoch 11, Batch 1800] loss: 0.0246186658746592
[Epoch 11, Batch 1900] loss: 0.012667003288406704
[Epoch 11, Batch 2000] loss: 0.020194761742459377
[Epoch 11, Batch 2100] loss: 0.034268364054660196
[Epoch 11, Batch 2200] loss: 0.029474644030960916
[Epoch 11, Batch 2300] loss: 0.04335566971771186
[Epoch 11, Batch 2400] loss: 0.027611586458006057
[Epoch 11, Batch 2500] loss: 0.031976756879812454
[Epoch 11, Batch 2600] loss: 0.024928792758000782
[Epoch 11, Batch 2700] loss: 0.028468988636741414
[Epoch 11, Batch 2800] loss: 0.029995229341438973
[Epoch 11, Batch 2900] loss: 0.024479906149063025
[Epoch 11, Batch 3000] loss: 0.02412119104919839
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9852
Overfitting: 0.0504
[Epoch 12, Batch 100] loss: 0.024085309006259194
[Epoch 12, Batch 200] loss: 0.014294607228439418
[Epoch 12, Batch 300] loss: 0.026301498168322723
[Epoch 12, Batch 400] loss: 0.020123723454089484
[Epoch 12, Batch 500] loss: 0.013497765094507485
[Epoch 12, Batch 600] loss: 0.01777209513638809
[Epoch 12, Batch 700] loss: 0.011174974600326095
[Epoch 12, Batch 800] loss: 0.01650664801687526
[Epoch 12, Batch 900] loss: 0.014181005328064203
[Epoch 12, Batch 1000] loss: 0.024299015550132027
[Epoch 12, Batch 1100] loss: 0.021358080362333567
[Epoch 12, Batch 1200] loss: 0.03235309906543989
[Epoch 12, Batch 1300] loss: 0.020923355389786593
[Epoch 12, Batch 1400] loss: 0.02371734107953671
[Epoch 12, Batch 1500] loss: 0.034004597296079735
[Epoch 12, Batch 1600] loss: 0.03002171999498387
[Epoch 12, Batch 1700] loss: 0.020676203229741077
[Epoch 12, Batch 1800] loss: 0.02226928533462342
[Epoch 12, Batch 1900] loss: 0.03161707630297315
[Epoch 12, Batch 2000] loss: 0.013846916501934174
[Epoch 12, Batch 2100] loss: 0.03913651117691188
[Epoch 12, Batch 2200] loss: 0.020876370833393595
[Epoch 12, Batch 2300] loss: 0.016395476710385992
[Epoch 12, Batch 2400] loss: 0.02531174158457361
[Epoch 12, Batch 2500] loss: 0.02779512349607103
[Epoch 12, Batch 2600] loss: 0.02258928879931773
[Epoch 12, Batch 2700] loss: 0.026829094178028753
[Epoch 12, Batch 2800] loss: 0.03350511822500266
[Epoch 12, Batch 2900] loss: 0.02350093791152176
[Epoch 12, Batch 3000] loss: 0.019829144404466207
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9858
Overfitting: 0.0506
[Epoch 13, Batch 100] loss: 0.019563050268225197
[Epoch 13, Batch 200] loss: 0.026129661458180634
[Epoch 13, Batch 300] loss: 0.012159547559986095
[Epoch 13, Batch 400] loss: 0.01195645516917466
[Epoch 13, Batch 500] loss: 0.019659622346480318
[Epoch 13, Batch 600] loss: 0.019876268183725187
[Epoch 13, Batch 700] loss: 0.020247494385257594
[Epoch 13, Batch 800] loss: 0.010914245691128598
[Epoch 13, Batch 900] loss: 0.02816494626476924
[Epoch 13, Batch 1000] loss: 0.013259599506091036
[Epoch 13, Batch 1100] loss: 0.01145009597614262
[Epoch 13, Batch 1200] loss: 0.02098294865767457
[Epoch 13, Batch 1300] loss: 0.011927664374088636
[Epoch 13, Batch 1400] loss: 0.018945785963915114
[Epoch 13, Batch 1500] loss: 0.0297113317241201
[Epoch 13, Batch 1600] loss: 0.027348260828985074
[Epoch 13, Batch 1700] loss: 0.03019792654482444
[Epoch 13, Batch 1800] loss: 0.0254432187526254
[Epoch 13, Batch 1900] loss: 0.025698754838122114
[Epoch 13, Batch 2000] loss: 0.02707140433929453
[Epoch 13, Batch 2100] loss: 0.017507792882970535
[Epoch 13, Batch 2200] loss: 0.020535380785149757
[Epoch 13, Batch 2300] loss: 0.013718733231798978
[Epoch 13, Batch 2400] loss: 0.023805543179223607
[Epoch 13, Batch 2500] loss: 0.019506460661868914
[Epoch 13, Batch 2600] loss: 0.020983537727061047
[Epoch 13, Batch 2700] loss: 0.023142928480483535
[Epoch 13, Batch 2800] loss: 0.013634722086790134
[Epoch 13, Batch 2900] loss: 0.02516071557023679
[Epoch 13, Batch 3000] loss: 0.00987186751994159
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0442
Validation Accuracy: 0.9881
Overfitting: 0.0442
Best model saved at epoch 13 with validation loss: 0.0442
[Epoch 14, Batch 100] loss: 0.02076820766029414
[Epoch 14, Batch 200] loss: 0.01978535522512175
[Epoch 14, Batch 300] loss: 0.012027430315902166
[Epoch 14, Batch 400] loss: 0.014947586194884933
[Epoch 14, Batch 500] loss: 0.03118570212041959
[Epoch 14, Batch 600] loss: 0.014634704605086882
[Epoch 14, Batch 700] loss: 0.012925479891564465
[Epoch 14, Batch 800] loss: 0.015479241856110094
[Epoch 14, Batch 900] loss: 0.016006603263267607
[Epoch 14, Batch 1000] loss: 0.0170499276281771
[Epoch 14, Batch 1100] loss: 0.014326638604343316
[Epoch 14, Batch 1200] loss: 0.014744054011353001
[Epoch 14, Batch 1300] loss: 0.015099146950215072
[Epoch 14, Batch 1400] loss: 0.015888861712410288
[Epoch 14, Batch 1500] loss: 0.012498485075993812
[Epoch 14, Batch 1600] loss: 0.015743949206989783
[Epoch 14, Batch 1700] loss: 0.013261527043814567
[Epoch 14, Batch 1800] loss: 0.020576790144605183
[Epoch 14, Batch 1900] loss: 0.019288074899523052
[Epoch 14, Batch 2000] loss: 0.013577436238556402
[Epoch 14, Batch 2100] loss: 0.02744520111874408
[Epoch 14, Batch 2200] loss: 0.024108661099162418
[Epoch 14, Batch 2300] loss: 0.02347300480589183
[Epoch 14, Batch 2400] loss: 0.008833164138850406
[Epoch 14, Batch 2500] loss: 0.01690153357996678
[Epoch 14, Batch 2600] loss: 0.01560626820581092
[Epoch 14, Batch 2700] loss: 0.01625419886506279
[Epoch 14, Batch 2800] loss: 0.016434869259064726
[Epoch 14, Batch 2900] loss: 0.02230197956894699
[Epoch 14, Batch 3000] loss: 0.0286576440812496
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9864
Overfitting: 0.0476
[Epoch 15, Batch 100] loss: 0.008606276893551694
[Epoch 15, Batch 200] loss: 0.02084513425701516
[Epoch 15, Batch 300] loss: 0.011406562276097248
[Epoch 15, Batch 400] loss: 0.009298191724410572
[Epoch 15, Batch 500] loss: 0.011542041500870254
[Epoch 15, Batch 600] loss: 0.0157962598848826
[Epoch 15, Batch 700] loss: 0.014117151419268338
[Epoch 15, Batch 800] loss: 0.008030428091478825
[Epoch 15, Batch 900] loss: 0.019086466422886587
[Epoch 15, Batch 1000] loss: 0.020422593626863092
[Epoch 15, Batch 1100] loss: 0.019756397219171048
[Epoch 15, Batch 1200] loss: 0.012167271517246264
[Epoch 15, Batch 1300] loss: 0.024118808365319638
[Epoch 15, Batch 1400] loss: 0.013583241285268742
[Epoch 15, Batch 1500] loss: 0.015520492381961048
[Epoch 15, Batch 1600] loss: 0.016752944921427114
[Epoch 15, Batch 1700] loss: 0.01666823004701655
[Epoch 15, Batch 1800] loss: 0.008830689129854363
[Epoch 15, Batch 1900] loss: 0.027045644063382498
[Epoch 15, Batch 2000] loss: 0.035222094113560164
[Epoch 15, Batch 2100] loss: 0.010644157429560437
[Epoch 15, Batch 2200] loss: 0.0113947734634894
[Epoch 15, Batch 2300] loss: 0.011717658755296725
[Epoch 15, Batch 2400] loss: 0.019522346070043568
[Epoch 15, Batch 2500] loss: 0.020440926480441702
[Epoch 15, Batch 2600] loss: 0.01939393354168715
[Epoch 15, Batch 2700] loss: 0.015505561057416344
[Epoch 15, Batch 2800] loss: 0.01368058754615049
[Epoch 15, Batch 2900] loss: 0.013794468311289165
[Epoch 15, Batch 3000] loss: 0.013491536165693105
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9871
Overfitting: 0.0458
[Epoch 16, Batch 100] loss: 0.011563319366468932
[Epoch 16, Batch 200] loss: 0.01788479966358864
[Epoch 16, Batch 300] loss: 0.008396677783330232
[Epoch 16, Batch 400] loss: 0.011598945297737372
[Epoch 16, Batch 500] loss: 0.009462184153726412
[Epoch 16, Batch 600] loss: 0.013622384560849242
[Epoch 16, Batch 700] loss: 0.010289921270741615
[Epoch 16, Batch 800] loss: 0.00859261704164055
[Epoch 16, Batch 900] loss: 0.013218390097954398
[Epoch 16, Batch 1000] loss: 0.013644295625472296
[Epoch 16, Batch 1100] loss: 0.015625586556689088
[Epoch 16, Batch 1200] loss: 0.01478650034421662
[Epoch 16, Batch 1300] loss: 0.01619151812925338
[Epoch 16, Batch 1400] loss: 0.01827697466735117
[Epoch 16, Batch 1500] loss: 0.01945964063259453
[Epoch 16, Batch 1600] loss: 0.009315629232951324
[Epoch 16, Batch 1700] loss: 0.016164688992666924
[Epoch 16, Batch 1800] loss: 0.012783351372245306
[Epoch 16, Batch 1900] loss: 0.01241114096043475
[Epoch 16, Batch 2000] loss: 0.018264308187135612
[Epoch 16, Batch 2100] loss: 0.022310946764291656
[Epoch 16, Batch 2200] loss: 0.015784568674480397
[Epoch 16, Batch 2300] loss: 0.013637443398110918
[Epoch 16, Batch 2400] loss: 0.02052560221054591
[Epoch 16, Batch 2500] loss: 0.021164626125264475
[Epoch 16, Batch 2600] loss: 0.008575876873364904
[Epoch 16, Batch 2700] loss: 0.01075717236935816
[Epoch 16, Batch 2800] loss: 0.01288169639673697
[Epoch 16, Batch 2900] loss: 0.005132484046175705
[Epoch 16, Batch 3000] loss: 0.015458671795004193
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9859
Overfitting: 0.0502
[Epoch 17, Batch 100] loss: 0.008510198153858254
[Epoch 17, Batch 200] loss: 0.006763346428033401
[Epoch 17, Batch 300] loss: 0.009487323541616206
[Epoch 17, Batch 400] loss: 0.008706638657295117
[Epoch 17, Batch 500] loss: 0.011322098072814696
[Epoch 17, Batch 600] loss: 0.006410319472579431
[Epoch 17, Batch 700] loss: 0.012631742914099959
[Epoch 17, Batch 800] loss: 0.013915426281837426
[Epoch 17, Batch 900] loss: 0.016435402957895348
[Epoch 17, Batch 1000] loss: 0.013643178929050918
[Epoch 17, Batch 1100] loss: 0.009004197747399302
[Epoch 17, Batch 1200] loss: 0.008494303785532793
[Epoch 17, Batch 1300] loss: 0.007044569159024832
[Epoch 17, Batch 1400] loss: 0.018153463013450163
[Epoch 17, Batch 1500] loss: 0.014152086007634353
[Epoch 17, Batch 1600] loss: 0.012416489902207103
[Epoch 17, Batch 1700] loss: 0.010763461446931615
[Epoch 17, Batch 1800] loss: 0.010349184999740827
[Epoch 17, Batch 1900] loss: 0.00905507012463204
[Epoch 17, Batch 2000] loss: 0.007883429695216364
[Epoch 17, Batch 2100] loss: 0.016988238671920043
[Epoch 17, Batch 2200] loss: 0.007703017009152973
[Epoch 17, Batch 2300] loss: 0.017868760319033755
[Epoch 17, Batch 2400] loss: 0.017205051559431014
[Epoch 17, Batch 2500] loss: 0.014711630631863955
[Epoch 17, Batch 2600] loss: 0.009323186517394787
[Epoch 17, Batch 2700] loss: 0.010856845493367472
[Epoch 17, Batch 2800] loss: 0.013374906906592514
[Epoch 17, Batch 2900] loss: 0.012143934588766569
[Epoch 17, Batch 3000] loss: 0.02379952264351232
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0596
Validation Accuracy: 0.9836
Overfitting: 0.0596
[Epoch 18, Batch 100] loss: 0.015327161508630525
[Epoch 18, Batch 200] loss: 0.006441721855553624
[Epoch 18, Batch 300] loss: 0.010737135556573775
[Epoch 18, Batch 400] loss: 0.012718524023621286
[Epoch 18, Batch 500] loss: 0.00927806288175816
[Epoch 18, Batch 600] loss: 0.006129150454362389
[Epoch 18, Batch 700] loss: 0.005329024179627595
[Epoch 18, Batch 800] loss: 0.013126150642892753
[Epoch 18, Batch 900] loss: 0.016692398414097625
[Epoch 18, Batch 1000] loss: 0.010651696626609919
[Epoch 18, Batch 1100] loss: 0.007008949185683377
[Epoch 18, Batch 1200] loss: 0.011906615048987988
[Epoch 18, Batch 1300] loss: 0.005542280854192541
[Epoch 18, Batch 1400] loss: 0.024167471444588955
[Epoch 18, Batch 1500] loss: 0.009427270298156145
[Epoch 18, Batch 1600] loss: 0.011629149121345108
[Epoch 18, Batch 1700] loss: 0.009572234798984027
[Epoch 18, Batch 1800] loss: 0.014374698018159507
[Epoch 18, Batch 1900] loss: 0.01114257711571554
[Epoch 18, Batch 2000] loss: 0.011519728614848646
[Epoch 18, Batch 2100] loss: 0.017557296852601212
[Epoch 18, Batch 2200] loss: 0.006104929510129296
[Epoch 18, Batch 2300] loss: 0.007775023136218806
[Epoch 18, Batch 2400] loss: 0.009220168410295174
[Epoch 18, Batch 2500] loss: 0.01109131639057523
[Epoch 18, Batch 2600] loss: 0.008307441164142802
[Epoch 18, Batch 2700] loss: 0.019163805105263235
[Epoch 18, Batch 2800] loss: 0.010668794861662717
[Epoch 18, Batch 2900] loss: 0.008414142261221969
[Epoch 18, Batch 3000] loss: 0.010994371579963627
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9885
Overfitting: 0.0471
[Epoch 19, Batch 100] loss: 0.007286634508700445
[Epoch 19, Batch 200] loss: 0.006945457975134559
[Epoch 19, Batch 300] loss: 0.011954698765105149
[Epoch 19, Batch 400] loss: 0.007793328019770343
[Epoch 19, Batch 500] loss: 0.003891535370158863
[Epoch 19, Batch 600] loss: 0.006191114557768742
[Epoch 19, Batch 700] loss: 0.007180138425865152
[Epoch 19, Batch 800] loss: 0.010757229643040774
[Epoch 19, Batch 900] loss: 0.010918147147358469
[Epoch 19, Batch 1000] loss: 0.004041817950610494
[Epoch 19, Batch 1100] loss: 0.0073291210846514335
[Epoch 19, Batch 1200] loss: 0.009572353771377494
[Epoch 19, Batch 1300] loss: 0.009757722303211267
[Epoch 19, Batch 1400] loss: 0.006971631404453547
[Epoch 19, Batch 1500] loss: 0.00668548934039336
[Epoch 19, Batch 1600] loss: 0.010329298782953628
[Epoch 19, Batch 1700] loss: 0.006991403154181626
[Epoch 19, Batch 1800] loss: 0.006836487364917048
[Epoch 19, Batch 1900] loss: 0.006928808101210961
[Epoch 19, Batch 2000] loss: 0.009876651913723436
[Epoch 19, Batch 2100] loss: 0.009215008722899256
[Epoch 19, Batch 2200] loss: 0.011620645637767666
[Epoch 19, Batch 2300] loss: 0.0065363447535855814
[Epoch 19, Batch 2400] loss: 0.007733509346844585
[Epoch 19, Batch 2500] loss: 0.024531483547398238
[Epoch 19, Batch 2600] loss: 0.012522301463259283
[Epoch 19, Batch 2700] loss: 0.0104316877019005
[Epoch 19, Batch 2800] loss: 0.004424852820952765
[Epoch 19, Batch 2900] loss: 0.008264754244919459
[Epoch 19, Batch 3000] loss: 0.025234475701508927
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9883
Overfitting: 0.0462
[Epoch 20, Batch 100] loss: 0.007578945125715109
[Epoch 20, Batch 200] loss: 0.009193916279682525
[Epoch 20, Batch 300] loss: 0.007949424159769479
[Epoch 20, Batch 400] loss: 0.003723514688645082
[Epoch 20, Batch 500] loss: 0.0066361670608876015
[Epoch 20, Batch 600] loss: 0.011291238375156354
[Epoch 20, Batch 700] loss: 0.009589890045136827
[Epoch 20, Batch 800] loss: 0.0050747458054252095
[Epoch 20, Batch 900] loss: 0.003490824632888234
[Epoch 20, Batch 1000] loss: 0.007769384816463117
[Epoch 20, Batch 1100] loss: 0.007527649751643821
[Epoch 20, Batch 1200] loss: 0.006377257964159071
[Epoch 20, Batch 1300] loss: 0.011587118021543575
[Epoch 20, Batch 1400] loss: 0.01226736646494942
[Epoch 20, Batch 1500] loss: 0.009227478873817745
[Epoch 20, Batch 1600] loss: 0.009306631052822922
[Epoch 20, Batch 1700] loss: 0.007028548434486765
[Epoch 20, Batch 1800] loss: 0.006800240885077073
[Epoch 20, Batch 1900] loss: 0.010904777950408971
[Epoch 20, Batch 2000] loss: 0.012521488923921424
[Epoch 20, Batch 2100] loss: 0.010099669728215304
[Epoch 20, Batch 2200] loss: 0.01586683492947486
[Epoch 20, Batch 2300] loss: 0.0068468752729813785
[Epoch 20, Batch 2400] loss: 0.006594812186588115
[Epoch 20, Batch 2500] loss: 0.006612874211655253
[Epoch 20, Batch 2600] loss: 0.014879970366191628
[Epoch 20, Batch 2700] loss: 0.006503816424351498
[Epoch 20, Batch 2800] loss: 0.012350657327542649
[Epoch 20, Batch 2900] loss: 0.012744731406244228
[Epoch 20, Batch 3000] loss: 0.01672277211351684
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9870
Overfitting: 0.0491
[Epoch 21, Batch 100] loss: 0.006303477256510632
[Epoch 21, Batch 200] loss: 0.006573316808171512
[Epoch 21, Batch 300] loss: 0.004597077306398205
[Epoch 21, Batch 400] loss: 0.004909474119576771
[Epoch 21, Batch 500] loss: 0.004590079267200053
[Epoch 21, Batch 600] loss: 0.004045517759782342
[Epoch 21, Batch 700] loss: 0.006117720259344424
[Epoch 21, Batch 800] loss: 0.009051689265020287
[Epoch 21, Batch 900] loss: 0.00446205913140318
[Epoch 21, Batch 1000] loss: 0.015445704434489472
[Epoch 21, Batch 1100] loss: 0.006101393226708751
[Epoch 21, Batch 1200] loss: 0.005260900620986604
[Epoch 21, Batch 1300] loss: 0.006780747272509871
[Epoch 21, Batch 1400] loss: 0.006701339013800407
[Epoch 21, Batch 1500] loss: 0.013196113468688963
[Epoch 21, Batch 1600] loss: 0.01200841903403841
[Epoch 21, Batch 1700] loss: 0.007282333162484065
[Epoch 21, Batch 1800] loss: 0.006864666190258504
[Epoch 21, Batch 1900] loss: 0.006912111261697191
[Epoch 21, Batch 2000] loss: 0.009463024175511236
[Epoch 21, Batch 2100] loss: 0.0036792435983670655
[Epoch 21, Batch 2200] loss: 0.006402687824197529
[Epoch 21, Batch 2300] loss: 0.012099154527522842
[Epoch 21, Batch 2400] loss: 0.006488642014492143
[Epoch 21, Batch 2500] loss: 0.005400519697723212
[Epoch 21, Batch 2600] loss: 0.012549010615393853
[Epoch 21, Batch 2700] loss: 0.01243487758296851
[Epoch 21, Batch 2800] loss: 0.004277943723486714
[Epoch 21, Batch 2900] loss: 0.007761994287534435
[Epoch 21, Batch 3000] loss: 0.004319863140420353
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9876
Overfitting: 0.0489
[Epoch 22, Batch 100] loss: 0.0032228734180716856
[Epoch 22, Batch 200] loss: 0.007132030491820842
[Epoch 22, Batch 300] loss: 0.006546061615620147
[Epoch 22, Batch 400] loss: 0.004249097195092873
[Epoch 22, Batch 500] loss: 0.002142403856519195
[Epoch 22, Batch 600] loss: 0.004587274897393456
[Epoch 22, Batch 700] loss: 0.006016850569208146
[Epoch 22, Batch 800] loss: 0.006831444035901768
[Epoch 22, Batch 900] loss: 0.007313277848902544
[Epoch 22, Batch 1000] loss: 0.007909525771614198
[Epoch 22, Batch 1100] loss: 0.0052807903489537015
[Epoch 22, Batch 1200] loss: 0.0031725093186150844
[Epoch 22, Batch 1300] loss: 0.0105061758450654
[Epoch 22, Batch 1400] loss: 0.013528440177285574
[Epoch 22, Batch 1500] loss: 0.010420771360456911
[Epoch 22, Batch 1600] loss: 0.005311588706692873
[Epoch 22, Batch 1700] loss: 0.00296859675892847
[Epoch 22, Batch 1800] loss: 0.0025874840447136192
[Epoch 22, Batch 1900] loss: 0.00385748536682172
[Epoch 22, Batch 2000] loss: 0.0032970233228644475
[Epoch 22, Batch 2100] loss: 0.007821659975243166
[Epoch 22, Batch 2200] loss: 0.010456743875588473
[Epoch 22, Batch 2300] loss: 0.005859113278045242
[Epoch 22, Batch 2400] loss: 0.004824162857455576
[Epoch 22, Batch 2500] loss: 0.005331518216485165
[Epoch 22, Batch 2600] loss: 0.006685557141936443
[Epoch 22, Batch 2700] loss: 0.011242096578997688
[Epoch 22, Batch 2800] loss: 0.00444935929924668
[Epoch 22, Batch 2900] loss: 0.006969503537522997
[Epoch 22, Batch 3000] loss: 0.007759424374457353
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9879
Overfitting: 0.0497
[Epoch 23, Batch 100] loss: 0.0021636140717214403
[Epoch 23, Batch 200] loss: 0.005067645987116976
[Epoch 23, Batch 300] loss: 0.0036119927823870055
[Epoch 23, Batch 400] loss: 0.005600782000669824
[Epoch 23, Batch 500] loss: 0.007940543501545676
[Epoch 23, Batch 600] loss: 0.006503191277622023
[Epoch 23, Batch 700] loss: 0.010666869673869712
[Epoch 23, Batch 800] loss: 0.005242772712874739
[Epoch 23, Batch 900] loss: 0.0021565501159295764
[Epoch 23, Batch 1000] loss: 0.006628839426434751
[Epoch 23, Batch 1100] loss: 0.011836732609652926
[Epoch 23, Batch 1200] loss: 0.008769838550732061
[Epoch 23, Batch 1300] loss: 0.00761091742450617
[Epoch 23, Batch 1400] loss: 0.004684541757735587
[Epoch 23, Batch 1500] loss: 0.005476980310295403
[Epoch 23, Batch 1600] loss: 0.006009827367251432
[Epoch 23, Batch 1700] loss: 0.00393470794653922
[Epoch 23, Batch 1800] loss: 0.005902113196161736
[Epoch 23, Batch 1900] loss: 0.0025655078996760492
[Epoch 23, Batch 2000] loss: 0.005843638426017606
[Epoch 23, Batch 2100] loss: 0.005055250115526632
[Epoch 23, Batch 2200] loss: 0.003437753621572028
[Epoch 23, Batch 2300] loss: 0.006927190640644057
[Epoch 23, Batch 2400] loss: 0.007930022042851306
[Epoch 23, Batch 2500] loss: 0.0033245798445295806
[Epoch 23, Batch 2600] loss: 0.0028713581812485245
[Epoch 23, Batch 2700] loss: 0.007588294102791906
[Epoch 23, Batch 2800] loss: 0.004976030031184564
[Epoch 23, Batch 2900] loss: 0.006103384386249217
[Epoch 23, Batch 3000] loss: 0.004328494085430065
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9880
Overfitting: 0.0487
[Epoch 24, Batch 100] loss: 0.0029445161477826788
[Epoch 24, Batch 200] loss: 0.0019366741029648437
[Epoch 24, Batch 300] loss: 0.0058196636088950985
[Epoch 24, Batch 400] loss: 0.004249686694627712
[Epoch 24, Batch 500] loss: 0.006899197402088646
[Epoch 24, Batch 600] loss: 0.004165395728755357
[Epoch 24, Batch 700] loss: 0.0023239516388753145
[Epoch 24, Batch 800] loss: 0.002129032680130649
[Epoch 24, Batch 900] loss: 0.006035154440321548
[Epoch 24, Batch 1000] loss: 0.005401743279720677
[Epoch 24, Batch 1100] loss: 0.003015683295911913
[Epoch 24, Batch 1200] loss: 0.003095794722338496
[Epoch 24, Batch 1300] loss: 0.0028513323466864905
[Epoch 24, Batch 1400] loss: 0.002502161588938634
[Epoch 24, Batch 1500] loss: 0.003071198890774838
[Epoch 24, Batch 1600] loss: 0.0021138854843138688
[Epoch 24, Batch 1700] loss: 0.00351177336060573
[Epoch 24, Batch 1800] loss: 0.007499396629888224
[Epoch 24, Batch 1900] loss: 0.0032948730968553265
[Epoch 24, Batch 2000] loss: 0.016280042375158815
[Epoch 24, Batch 2100] loss: 0.009447858446186785
[Epoch 24, Batch 2200] loss: 0.0076090199054996786
[Epoch 24, Batch 2300] loss: 0.005991397201599966
[Epoch 24, Batch 2400] loss: 0.010337589231379809
[Epoch 24, Batch 2500] loss: 0.004334353241169993
[Epoch 24, Batch 2600] loss: 0.006589192314639831
[Epoch 24, Batch 2700] loss: 0.00891140812454978
[Epoch 24, Batch 2800] loss: 0.0051702550436903034
[Epoch 24, Batch 2900] loss: 0.015067131235213865
[Epoch 24, Batch 3000] loss: 0.006767320753815511
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9874
Overfitting: 0.0525
Fold 3 validation loss: 0.0525
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.297625846862793
[Epoch 1, Batch 200] loss: 2.279203109741211
[Epoch 1, Batch 300] loss: 2.2458280611038206
[Epoch 1, Batch 400] loss: 2.1678669667243957
[Epoch 1, Batch 500] loss: 1.8872614431381225
[Epoch 1, Batch 600] loss: 1.2136841189861298
[Epoch 1, Batch 700] loss: 0.6733531038463115
[Epoch 1, Batch 800] loss: 0.5577714490890503
[Epoch 1, Batch 900] loss: 0.4905065508186817
[Epoch 1, Batch 1000] loss: 0.4728174725174904
[Epoch 1, Batch 1100] loss: 0.41762690007686615
[Epoch 1, Batch 1200] loss: 0.41763899445533753
[Epoch 1, Batch 1300] loss: 0.3186664355918765
[Epoch 1, Batch 1400] loss: 0.3476778011023998
[Epoch 1, Batch 1500] loss: 0.3499566633626819
[Epoch 1, Batch 1600] loss: 0.2918013310432434
[Epoch 1, Batch 1700] loss: 0.3198180941864848
[Epoch 1, Batch 1800] loss: 0.25259036097675563
[Epoch 1, Batch 1900] loss: 0.29618971708230674
[Epoch 1, Batch 2000] loss: 0.25518422286957504
[Epoch 1, Batch 2100] loss: 0.22612079862505197
[Epoch 1, Batch 2200] loss: 0.23842660719528794
[Epoch 1, Batch 2300] loss: 0.22659867027774452
[Epoch 1, Batch 2400] loss: 0.20710738776251675
[Epoch 1, Batch 2500] loss: 0.220144960694015
[Epoch 1, Batch 2600] loss: 0.2121956888400018
[Epoch 1, Batch 2700] loss: 0.1761168584600091
[Epoch 1, Batch 2800] loss: 0.21149581737816334
[Epoch 1, Batch 2900] loss: 0.18491775883361697
[Epoch 1, Batch 3000] loss: 0.193893455658108
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1879
Validation Accuracy: 0.9403
Overfitting: 0.1879
Best model saved at epoch 1 with validation loss: 0.1879
[Epoch 2, Batch 100] loss: 0.1483875254355371
[Epoch 2, Batch 200] loss: 0.18082615449558945
[Epoch 2, Batch 300] loss: 0.18256453244015575
[Epoch 2, Batch 400] loss: 0.15393465019762517
[Epoch 2, Batch 500] loss: 0.1504785012360662
[Epoch 2, Batch 600] loss: 0.18227914934046566
[Epoch 2, Batch 700] loss: 0.13912594128400088
[Epoch 2, Batch 800] loss: 0.1478783820848912
[Epoch 2, Batch 900] loss: 0.15214955870062113
[Epoch 2, Batch 1000] loss: 0.14379520105198026
[Epoch 2, Batch 1100] loss: 0.16306057720445097
[Epoch 2, Batch 1200] loss: 0.16391787164378913
[Epoch 2, Batch 1300] loss: 0.12673404427710921
[Epoch 2, Batch 1400] loss: 0.1448817620659247
[Epoch 2, Batch 1500] loss: 0.10460735125467181
[Epoch 2, Batch 1600] loss: 0.12375062790233642
[Epoch 2, Batch 1700] loss: 0.1375127072725445
[Epoch 2, Batch 1800] loss: 0.10416770338546484
[Epoch 2, Batch 1900] loss: 0.1281942610954866
[Epoch 2, Batch 2000] loss: 0.1134924807259813
[Epoch 2, Batch 2100] loss: 0.11496743804775178
[Epoch 2, Batch 2200] loss: 0.12648641761392354
[Epoch 2, Batch 2300] loss: 0.1699546538013965
[Epoch 2, Batch 2400] loss: 0.14303045206703247
[Epoch 2, Batch 2500] loss: 0.13546357800951228
[Epoch 2, Batch 2600] loss: 0.10560107687488199
[Epoch 2, Batch 2700] loss: 0.1437648597545922
[Epoch 2, Batch 2800] loss: 0.13110884659923613
[Epoch 2, Batch 2900] loss: 0.10665193994529545
[Epoch 2, Batch 3000] loss: 0.1526317794341594
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1204
Validation Accuracy: 0.9607
Overfitting: 0.1204
Best model saved at epoch 2 with validation loss: 0.1204
[Epoch 3, Batch 100] loss: 0.10216015003621579
[Epoch 3, Batch 200] loss: 0.10379169222898782
[Epoch 3, Batch 300] loss: 0.08635937428567558
[Epoch 3, Batch 400] loss: 0.11877728978637606
[Epoch 3, Batch 500] loss: 0.1328877332713455
[Epoch 3, Batch 600] loss: 0.10737488399259747
[Epoch 3, Batch 700] loss: 0.11117842893116175
[Epoch 3, Batch 800] loss: 0.09634458597982302
[Epoch 3, Batch 900] loss: 0.11168886094586923
[Epoch 3, Batch 1000] loss: 0.12186258971691132
[Epoch 3, Batch 1100] loss: 0.09272541999816894
[Epoch 3, Batch 1200] loss: 0.10695644235471263
[Epoch 3, Batch 1300] loss: 0.09122285915538669
[Epoch 3, Batch 1400] loss: 0.09134776944993064
[Epoch 3, Batch 1500] loss: 0.10388036645948887
[Epoch 3, Batch 1600] loss: 0.0850893243169412
[Epoch 3, Batch 1700] loss: 0.09555872065247968
[Epoch 3, Batch 1800] loss: 0.09642234332859516
[Epoch 3, Batch 1900] loss: 0.0886468725069426
[Epoch 3, Batch 2000] loss: 0.06741167390020564
[Epoch 3, Batch 2100] loss: 0.08258577775675803
[Epoch 3, Batch 2200] loss: 0.07909273297991604
[Epoch 3, Batch 2300] loss: 0.08621318915393203
[Epoch 3, Batch 2400] loss: 0.10454858830198646
[Epoch 3, Batch 2500] loss: 0.09873836803017184
[Epoch 3, Batch 2600] loss: 0.08426807577954605
[Epoch 3, Batch 2700] loss: 0.09675608063465915
[Epoch 3, Batch 2800] loss: 0.0860268638189882
[Epoch 3, Batch 2900] loss: 0.09835067491047084
[Epoch 3, Batch 3000] loss: 0.09351737337885424
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0812
Validation Accuracy: 0.9745
Overfitting: 0.0812
Best model saved at epoch 3 with validation loss: 0.0812
[Epoch 4, Batch 100] loss: 0.08248417378636078
[Epoch 4, Batch 200] loss: 0.08872126018744893
[Epoch 4, Batch 300] loss: 0.0757908132718876
[Epoch 4, Batch 400] loss: 0.08736688817967661
[Epoch 4, Batch 500] loss: 0.06495370518765413
[Epoch 4, Batch 600] loss: 0.07527329202508554
[Epoch 4, Batch 700] loss: 0.07501305743178818
[Epoch 4, Batch 800] loss: 0.10507175121339969
[Epoch 4, Batch 900] loss: 0.07426593830459752
[Epoch 4, Batch 1000] loss: 0.07365043787052855
[Epoch 4, Batch 1100] loss: 0.08334632479352877
[Epoch 4, Batch 1200] loss: 0.0570354789425619
[Epoch 4, Batch 1300] loss: 0.06567973667522892
[Epoch 4, Batch 1400] loss: 0.08747693360724952
[Epoch 4, Batch 1500] loss: 0.07048043391318061
[Epoch 4, Batch 1600] loss: 0.07551928777713329
[Epoch 4, Batch 1700] loss: 0.05343434259761125
[Epoch 4, Batch 1800] loss: 0.05095575326791732
[Epoch 4, Batch 1900] loss: 0.07395268415450118
[Epoch 4, Batch 2000] loss: 0.07105415497382638
[Epoch 4, Batch 2100] loss: 0.06698306321632116
[Epoch 4, Batch 2200] loss: 0.096404708531918
[Epoch 4, Batch 2300] loss: 0.05713470890419558
[Epoch 4, Batch 2400] loss: 0.07860228131641633
[Epoch 4, Batch 2500] loss: 0.07129042359360029
[Epoch 4, Batch 2600] loss: 0.061462967977277
[Epoch 4, Batch 2700] loss: 0.08878688169526867
[Epoch 4, Batch 2800] loss: 0.08738313254434615
[Epoch 4, Batch 2900] loss: 0.09309971513925121
[Epoch 4, Batch 3000] loss: 0.06668921724660322
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0694
Validation Accuracy: 0.9783
Overfitting: 0.0694
Best model saved at epoch 4 with validation loss: 0.0694
[Epoch 5, Batch 100] loss: 0.05908071803831263
[Epoch 5, Batch 200] loss: 0.07321885300683789
[Epoch 5, Batch 300] loss: 0.07483708013198338
[Epoch 5, Batch 400] loss: 0.05743378820130601
[Epoch 5, Batch 500] loss: 0.0530265605263412
[Epoch 5, Batch 600] loss: 0.06659413874323945
[Epoch 5, Batch 700] loss: 0.07029903937014752
[Epoch 5, Batch 800] loss: 0.06050165817490779
[Epoch 5, Batch 900] loss: 0.057380177811719474
[Epoch 5, Batch 1000] loss: 0.05048531517968513
[Epoch 5, Batch 1100] loss: 0.06629803074640223
[Epoch 5, Batch 1200] loss: 0.06002371817827225
[Epoch 5, Batch 1300] loss: 0.08841475592926144
[Epoch 5, Batch 1400] loss: 0.06224113256437704
[Epoch 5, Batch 1500] loss: 0.05893251870584208
[Epoch 5, Batch 1600] loss: 0.07466810635000001
[Epoch 5, Batch 1700] loss: 0.03842311906337272
[Epoch 5, Batch 1800] loss: 0.06900436012889259
[Epoch 5, Batch 1900] loss: 0.06650809120503254
[Epoch 5, Batch 2000] loss: 0.05824724200036144
[Epoch 5, Batch 2100] loss: 0.054233748211408965
[Epoch 5, Batch 2200] loss: 0.05767277805716731
[Epoch 5, Batch 2300] loss: 0.06995652954676189
[Epoch 5, Batch 2400] loss: 0.0650135090877302
[Epoch 5, Batch 2500] loss: 0.06796538652386516
[Epoch 5, Batch 2600] loss: 0.06641273571993224
[Epoch 5, Batch 2700] loss: 0.05369660925702192
[Epoch 5, Batch 2800] loss: 0.06323714267869945
[Epoch 5, Batch 2900] loss: 0.07085997102665714
[Epoch 5, Batch 3000] loss: 0.07860684750601649
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0649
Validation Accuracy: 0.9788
Overfitting: 0.0649
Best model saved at epoch 5 with validation loss: 0.0649
[Epoch 6, Batch 100] loss: 0.05687247981084511
[Epoch 6, Batch 200] loss: 0.048347642602748236
[Epoch 6, Batch 300] loss: 0.048203501731914004
[Epoch 6, Batch 400] loss: 0.04744503355468623
[Epoch 6, Batch 500] loss: 0.04151722110225819
[Epoch 6, Batch 600] loss: 0.052110761677613485
[Epoch 6, Batch 700] loss: 0.07563472767127678
[Epoch 6, Batch 800] loss: 0.04946956792176934
[Epoch 6, Batch 900] loss: 0.056993369155097756
[Epoch 6, Batch 1000] loss: 0.06264040800277143
[Epoch 6, Batch 1100] loss: 0.046665610114578156
[Epoch 6, Batch 1200] loss: 0.05323740246589295
[Epoch 6, Batch 1300] loss: 0.05720351330121048
[Epoch 6, Batch 1400] loss: 0.051479017337260305
[Epoch 6, Batch 1500] loss: 0.052388081311946735
[Epoch 6, Batch 1600] loss: 0.065690386495844
[Epoch 6, Batch 1700] loss: 0.06053816654311959
[Epoch 6, Batch 1800] loss: 0.05551266827096697
[Epoch 6, Batch 1900] loss: 0.04535122508008499
[Epoch 6, Batch 2000] loss: 0.0534622661958565
[Epoch 6, Batch 2100] loss: 0.06146882633329369
[Epoch 6, Batch 2200] loss: 0.05293901037424803
[Epoch 6, Batch 2300] loss: 0.04474996791337617
[Epoch 6, Batch 2400] loss: 0.06536324816741398
[Epoch 6, Batch 2500] loss: 0.03787851678236621
[Epoch 6, Batch 2600] loss: 0.03873979687981773
[Epoch 6, Batch 2700] loss: 0.06734313879627735
[Epoch 6, Batch 2800] loss: 0.0657052660593763
[Epoch 6, Batch 2900] loss: 0.057022002139128745
[Epoch 6, Batch 3000] loss: 0.061618026935029775
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0609
Validation Accuracy: 0.9814
Overfitting: 0.0609
Best model saved at epoch 6 with validation loss: 0.0609
[Epoch 7, Batch 100] loss: 0.041106973571004346
[Epoch 7, Batch 200] loss: 0.05269708537583938
[Epoch 7, Batch 300] loss: 0.040139044632815056
[Epoch 7, Batch 400] loss: 0.056925022425130006
[Epoch 7, Batch 500] loss: 0.038506977518263735
[Epoch 7, Batch 600] loss: 0.06071237603668123
[Epoch 7, Batch 700] loss: 0.04178591050847899
[Epoch 7, Batch 800] loss: 0.05881685640197247
[Epoch 7, Batch 900] loss: 0.048838654160208536
[Epoch 7, Batch 1000] loss: 0.05122246657439973
[Epoch 7, Batch 1100] loss: 0.040215400281595065
[Epoch 7, Batch 1200] loss: 0.051592347032856194
[Epoch 7, Batch 1300] loss: 0.04269870050426107
[Epoch 7, Batch 1400] loss: 0.05082984353939537
[Epoch 7, Batch 1500] loss: 0.05133410410067882
[Epoch 7, Batch 1600] loss: 0.04661972541362047
[Epoch 7, Batch 1700] loss: 0.041872606441829704
[Epoch 7, Batch 1800] loss: 0.037268397711159196
[Epoch 7, Batch 1900] loss: 0.040754372716473884
[Epoch 7, Batch 2000] loss: 0.049816081128810766
[Epoch 7, Batch 2100] loss: 0.05930876516409626
[Epoch 7, Batch 2200] loss: 0.04836392020995845
[Epoch 7, Batch 2300] loss: 0.036437361456628424
[Epoch 7, Batch 2400] loss: 0.03559257133223582
[Epoch 7, Batch 2500] loss: 0.03730977741332026
[Epoch 7, Batch 2600] loss: 0.03346489635412581
[Epoch 7, Batch 2700] loss: 0.05886640297045233
[Epoch 7, Batch 2800] loss: 0.06547927803272614
[Epoch 7, Batch 2900] loss: 0.04389332355582155
[Epoch 7, Batch 3000] loss: 0.059260422452935016
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9840
Overfitting: 0.0548
Best model saved at epoch 7 with validation loss: 0.0548
[Epoch 8, Batch 100] loss: 0.03757703654118814
[Epoch 8, Batch 200] loss: 0.053628547269472616
[Epoch 8, Batch 300] loss: 0.04969112412596587
[Epoch 8, Batch 400] loss: 0.04482285252190195
[Epoch 8, Batch 500] loss: 0.03525371224619448
[Epoch 8, Batch 600] loss: 0.03444566070480505
[Epoch 8, Batch 700] loss: 0.05920225340028992
[Epoch 8, Batch 800] loss: 0.04819654848644859
[Epoch 8, Batch 900] loss: 0.04894814798841253
[Epoch 8, Batch 1000] loss: 0.03566934634916834
[Epoch 8, Batch 1100] loss: 0.056417441179510204
[Epoch 8, Batch 1200] loss: 0.049971332895365775
[Epoch 8, Batch 1300] loss: 0.04046531305240933
[Epoch 8, Batch 1400] loss: 0.025279711050970946
[Epoch 8, Batch 1500] loss: 0.050321096414118076
[Epoch 8, Batch 1600] loss: 0.037799171137448864
[Epoch 8, Batch 1700] loss: 0.0469267578975996
[Epoch 8, Batch 1800] loss: 0.03820658031880157
[Epoch 8, Batch 1900] loss: 0.03523441465455107
[Epoch 8, Batch 2000] loss: 0.03701497442598338
[Epoch 8, Batch 2100] loss: 0.0423400167436921
[Epoch 8, Batch 2200] loss: 0.03716980934914318
[Epoch 8, Batch 2300] loss: 0.044410496886703184
[Epoch 8, Batch 2400] loss: 0.050523842946422516
[Epoch 8, Batch 2500] loss: 0.03874177544654231
[Epoch 8, Batch 2600] loss: 0.0430954807359376
[Epoch 8, Batch 2700] loss: 0.03587816053652205
[Epoch 8, Batch 2800] loss: 0.05578678286576178
[Epoch 8, Batch 2900] loss: 0.03702646624122281
[Epoch 8, Batch 3000] loss: 0.027678687852749136
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9837
Overfitting: 0.0544
Best model saved at epoch 8 with validation loss: 0.0544
[Epoch 9, Batch 100] loss: 0.031098686346085744
[Epoch 9, Batch 200] loss: 0.034657653559406754
[Epoch 9, Batch 300] loss: 0.03780284462220152
[Epoch 9, Batch 400] loss: 0.04757375865443464
[Epoch 9, Batch 500] loss: 0.04789878383773612
[Epoch 9, Batch 600] loss: 0.03248053149029147
[Epoch 9, Batch 700] loss: 0.04405725529199117
[Epoch 9, Batch 800] loss: 0.028902850701488205
[Epoch 9, Batch 900] loss: 0.026532870599912713
[Epoch 9, Batch 1000] loss: 0.04359378799679689
[Epoch 9, Batch 1100] loss: 0.026532910346868447
[Epoch 9, Batch 1200] loss: 0.03860185677054687
[Epoch 9, Batch 1300] loss: 0.030642201733280673
[Epoch 9, Batch 1400] loss: 0.03033733430915163
[Epoch 9, Batch 1500] loss: 0.043338307751400865
[Epoch 9, Batch 1600] loss: 0.03853687642986188
[Epoch 9, Batch 1700] loss: 0.025393835900176784
[Epoch 9, Batch 1800] loss: 0.0466764772994793
[Epoch 9, Batch 1900] loss: 0.04334897402208299
[Epoch 9, Batch 2000] loss: 0.03574205624798196
[Epoch 9, Batch 2100] loss: 0.053238296445051674
[Epoch 9, Batch 2200] loss: 0.04395897903450532
[Epoch 9, Batch 2300] loss: 0.03308363585740153
[Epoch 9, Batch 2400] loss: 0.05955221046227962
[Epoch 9, Batch 2500] loss: 0.01997745444183238
[Epoch 9, Batch 2600] loss: 0.020249183589039602
[Epoch 9, Batch 2700] loss: 0.03989403554391174
[Epoch 9, Batch 2800] loss: 0.03758490850421367
[Epoch 9, Batch 2900] loss: 0.04237221730116289
[Epoch 9, Batch 3000] loss: 0.04195630389658618
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9839
Overfitting: 0.0535
Best model saved at epoch 9 with validation loss: 0.0535
[Epoch 10, Batch 100] loss: 0.028498646694933995
[Epoch 10, Batch 200] loss: 0.027353718775484596
[Epoch 10, Batch 300] loss: 0.021751039757509714
[Epoch 10, Batch 400] loss: 0.03336228751228191
[Epoch 10, Batch 500] loss: 0.031336174528405536
[Epoch 10, Batch 600] loss: 0.030467238882411037
[Epoch 10, Batch 700] loss: 0.03450371229519078
[Epoch 10, Batch 800] loss: 0.035511115399131085
[Epoch 10, Batch 900] loss: 0.04085132349966443
[Epoch 10, Batch 1000] loss: 0.02862622176311561
[Epoch 10, Batch 1100] loss: 0.03745520723241498
[Epoch 10, Batch 1200] loss: 0.03079595754854381
[Epoch 10, Batch 1300] loss: 0.0366212805887335
[Epoch 10, Batch 1400] loss: 0.03237951919989428
[Epoch 10, Batch 1500] loss: 0.03400706485059345
[Epoch 10, Batch 1600] loss: 0.027307546141018976
[Epoch 10, Batch 1700] loss: 0.03443477846041788
[Epoch 10, Batch 1800] loss: 0.02446567104605492
[Epoch 10, Batch 1900] loss: 0.025287232320406475
[Epoch 10, Batch 2000] loss: 0.03798085634465678
[Epoch 10, Batch 2100] loss: 0.03489901419445232
[Epoch 10, Batch 2200] loss: 0.0313557800273702
[Epoch 10, Batch 2300] loss: 0.028419187111358043
[Epoch 10, Batch 2400] loss: 0.042417346241709314
[Epoch 10, Batch 2500] loss: 0.04639602608134737
[Epoch 10, Batch 2600] loss: 0.0488632751928526
[Epoch 10, Batch 2700] loss: 0.046533798762538936
[Epoch 10, Batch 2800] loss: 0.03534753764353809
[Epoch 10, Batch 2900] loss: 0.02913921252300497
[Epoch 10, Batch 3000] loss: 0.03455798259470612
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9841
Overfitting: 0.0523
Best model saved at epoch 10 with validation loss: 0.0523
[Epoch 11, Batch 100] loss: 0.03586099519903655
[Epoch 11, Batch 200] loss: 0.020980739595688646
[Epoch 11, Batch 300] loss: 0.024202709456003505
[Epoch 11, Batch 400] loss: 0.031570219205459576
[Epoch 11, Batch 500] loss: 0.02701573070749873
[Epoch 11, Batch 600] loss: 0.020573441571832517
[Epoch 11, Batch 700] loss: 0.022856622868530393
[Epoch 11, Batch 800] loss: 0.027668597128031252
[Epoch 11, Batch 900] loss: 0.031006648380425758
[Epoch 11, Batch 1000] loss: 0.025588708202849374
[Epoch 11, Batch 1100] loss: 0.029221623195480786
[Epoch 11, Batch 1200] loss: 0.03178788317945873
[Epoch 11, Batch 1300] loss: 0.024432361028302693
[Epoch 11, Batch 1400] loss: 0.030222107029621838
[Epoch 11, Batch 1500] loss: 0.03224232588145241
[Epoch 11, Batch 1600] loss: 0.0424335386409075
[Epoch 11, Batch 1700] loss: 0.031615415619198756
[Epoch 11, Batch 1800] loss: 0.022106830108896247
[Epoch 11, Batch 1900] loss: 0.033222468377716724
[Epoch 11, Batch 2000] loss: 0.03820827459683642
[Epoch 11, Batch 2100] loss: 0.040384423462892304
[Epoch 11, Batch 2200] loss: 0.03464214530598838
[Epoch 11, Batch 2300] loss: 0.04174882801751664
[Epoch 11, Batch 2400] loss: 0.04517714833273203
[Epoch 11, Batch 2500] loss: 0.04143601469550049
[Epoch 11, Batch 2600] loss: 0.02653569843925652
[Epoch 11, Batch 2700] loss: 0.028246113364148187
[Epoch 11, Batch 2800] loss: 0.025714357222022956
[Epoch 11, Batch 2900] loss: 0.030399889856489608
[Epoch 11, Batch 3000] loss: 0.029558724555245136
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0488
Validation Accuracy: 0.9849
Overfitting: 0.0488
Best model saved at epoch 11 with validation loss: 0.0488
[Epoch 12, Batch 100] loss: 0.02168529167531233
[Epoch 12, Batch 200] loss: 0.031881476544440374
[Epoch 12, Batch 300] loss: 0.02777008835284505
[Epoch 12, Batch 400] loss: 0.02530551720985386
[Epoch 12, Batch 500] loss: 0.02927035303626326
[Epoch 12, Batch 600] loss: 0.030423612878930726
[Epoch 12, Batch 700] loss: 0.025289094280306016
[Epoch 12, Batch 800] loss: 0.02330134464544244
[Epoch 12, Batch 900] loss: 0.02056256116426084
[Epoch 12, Batch 1000] loss: 0.020589482216746547
[Epoch 12, Batch 1100] loss: 0.03199285924558353
[Epoch 12, Batch 1200] loss: 0.03860084515094059
[Epoch 12, Batch 1300] loss: 0.029362121690646746
[Epoch 12, Batch 1400] loss: 0.024806751523137792
[Epoch 12, Batch 1500] loss: 0.013566087539438741
[Epoch 12, Batch 1600] loss: 0.019100214641875935
[Epoch 12, Batch 1700] loss: 0.018794895839237144
[Epoch 12, Batch 1800] loss: 0.02926031757204328
[Epoch 12, Batch 1900] loss: 0.030065528228369658
[Epoch 12, Batch 2000] loss: 0.02992665536083223
[Epoch 12, Batch 2100] loss: 0.03435202138229215
[Epoch 12, Batch 2200] loss: 0.02919754485192243
[Epoch 12, Batch 2300] loss: 0.022492359537791343
[Epoch 12, Batch 2400] loss: 0.016422919237957103
[Epoch 12, Batch 2500] loss: 0.037803730384039225
[Epoch 12, Batch 2600] loss: 0.040261730550191714
[Epoch 12, Batch 2700] loss: 0.027306339530623516
[Epoch 12, Batch 2800] loss: 0.019183048971754033
[Epoch 12, Batch 2900] loss: 0.0376317838972318
[Epoch 12, Batch 3000] loss: 0.021018921783179392
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9860
Overfitting: 0.0472
Best model saved at epoch 12 with validation loss: 0.0472
[Epoch 13, Batch 100] loss: 0.02400359369785292
[Epoch 13, Batch 200] loss: 0.022481223980357755
[Epoch 13, Batch 300] loss: 0.013655676553680678
[Epoch 13, Batch 400] loss: 0.024761009146168363
[Epoch 13, Batch 500] loss: 0.02594305415375857
[Epoch 13, Batch 600] loss: 0.021573943039766164
[Epoch 13, Batch 700] loss: 0.01775263891195209
[Epoch 13, Batch 800] loss: 0.020144556368759368
[Epoch 13, Batch 900] loss: 0.029096399652817125
[Epoch 13, Batch 1000] loss: 0.03402387967093091
[Epoch 13, Batch 1100] loss: 0.015489457595722343
[Epoch 13, Batch 1200] loss: 0.0234506125041662
[Epoch 13, Batch 1300] loss: 0.021170613068243256
[Epoch 13, Batch 1400] loss: 0.028530272453390352
[Epoch 13, Batch 1500] loss: 0.024789841848469222
[Epoch 13, Batch 1600] loss: 0.031178559631553072
[Epoch 13, Batch 1700] loss: 0.017510468718974152
[Epoch 13, Batch 1800] loss: 0.013065186719686608
[Epoch 13, Batch 1900] loss: 0.030729309693124377
[Epoch 13, Batch 2000] loss: 0.041946263138634095
[Epoch 13, Batch 2100] loss: 0.026508448286767815
[Epoch 13, Batch 2200] loss: 0.01719199050159659
[Epoch 13, Batch 2300] loss: 0.028943589471309678
[Epoch 13, Batch 2400] loss: 0.02547507787385257
[Epoch 13, Batch 2500] loss: 0.027359651164442767
[Epoch 13, Batch 2600] loss: 0.028446547960338648
[Epoch 13, Batch 2700] loss: 0.014557373564275621
[Epoch 13, Batch 2800] loss: 0.028119790808814285
[Epoch 13, Batch 2900] loss: 0.035958194166669274
[Epoch 13, Batch 3000] loss: 0.025990378949063597
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0580
Validation Accuracy: 0.9830
Overfitting: 0.0580
[Epoch 14, Batch 100] loss: 0.023169536895293278
[Epoch 14, Batch 200] loss: 0.023340401587774978
[Epoch 14, Batch 300] loss: 0.015221748277544975
[Epoch 14, Batch 400] loss: 0.025205821609633857
[Epoch 14, Batch 500] loss: 0.018439254996301314
[Epoch 14, Batch 600] loss: 0.020171944370886194
[Epoch 14, Batch 700] loss: 0.022859278208197793
[Epoch 14, Batch 800] loss: 0.02323480302693497
[Epoch 14, Batch 900] loss: 0.020665254565828947
[Epoch 14, Batch 1000] loss: 0.021895126386953054
[Epoch 14, Batch 1100] loss: 0.014886012080023648
[Epoch 14, Batch 1200] loss: 0.028385491257504326
[Epoch 14, Batch 1300] loss: 0.028711142407628357
[Epoch 14, Batch 1400] loss: 0.013545312588175875
[Epoch 14, Batch 1500] loss: 0.013362556866632076
[Epoch 14, Batch 1600] loss: 0.02244804081186885
[Epoch 14, Batch 1700] loss: 0.019349359897751127
[Epoch 14, Batch 1800] loss: 0.024808674437881564
[Epoch 14, Batch 1900] loss: 0.03052717158003361
[Epoch 14, Batch 2000] loss: 0.01649669744714629
[Epoch 14, Batch 2100] loss: 0.020171267423866084
[Epoch 14, Batch 2200] loss: 0.04508442567526799
[Epoch 14, Batch 2300] loss: 0.01585762838843948
[Epoch 14, Batch 2400] loss: 0.031816486503958005
[Epoch 14, Batch 2500] loss: 0.02196161571460834
[Epoch 14, Batch 2600] loss: 0.024719931648287456
[Epoch 14, Batch 2700] loss: 0.031800393116427586
[Epoch 14, Batch 2800] loss: 0.02531343907379778
[Epoch 14, Batch 2900] loss: 0.018113819449972653
[Epoch 14, Batch 3000] loss: 0.014031455618751352
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9857
Overfitting: 0.0511
[Epoch 15, Batch 100] loss: 0.022436206234706334
[Epoch 15, Batch 200] loss: 0.02952651055946262
[Epoch 15, Batch 300] loss: 0.014595322694658535
[Epoch 15, Batch 400] loss: 0.017646671780530598
[Epoch 15, Batch 500] loss: 0.018926206229571106
[Epoch 15, Batch 600] loss: 0.01427471391594736
[Epoch 15, Batch 700] loss: 0.017459127351921778
[Epoch 15, Batch 800] loss: 0.01630711077737942
[Epoch 15, Batch 900] loss: 0.010167336637641711
[Epoch 15, Batch 1000] loss: 0.022432196299996578
[Epoch 15, Batch 1100] loss: 0.014390466796758119
[Epoch 15, Batch 1200] loss: 0.04090204047439329
[Epoch 15, Batch 1300] loss: 0.022272441327077105
[Epoch 15, Batch 1400] loss: 0.012695391181805462
[Epoch 15, Batch 1500] loss: 0.01724903156326036
[Epoch 15, Batch 1600] loss: 0.011251708996060188
[Epoch 15, Batch 1700] loss: 0.01013426422887278
[Epoch 15, Batch 1800] loss: 0.03112899341213051
[Epoch 15, Batch 1900] loss: 0.01802480729869785
[Epoch 15, Batch 2000] loss: 0.02310706073479196
[Epoch 15, Batch 2100] loss: 0.01949882651486405
[Epoch 15, Batch 2200] loss: 0.014241905902235886
[Epoch 15, Batch 2300] loss: 0.020031192397400446
[Epoch 15, Batch 2400] loss: 0.027600544974411605
[Epoch 15, Batch 2500] loss: 0.03606224234968977
[Epoch 15, Batch 2600] loss: 0.019932813522318613
[Epoch 15, Batch 2700] loss: 0.01636009079995347
[Epoch 15, Batch 2800] loss: 0.030751709858159303
[Epoch 15, Batch 2900] loss: 0.018129857074745813
[Epoch 15, Batch 3000] loss: 0.023591813679013286
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9828
Overfitting: 0.0560
[Epoch 16, Batch 100] loss: 0.01878060964445467
[Epoch 16, Batch 200] loss: 0.014338243189195054
[Epoch 16, Batch 300] loss: 0.020768736259597062
[Epoch 16, Batch 400] loss: 0.006483799899870064
[Epoch 16, Batch 500] loss: 0.020378655921485914
[Epoch 16, Batch 600] loss: 0.015030280498594948
[Epoch 16, Batch 700] loss: 0.02081721317372285
[Epoch 16, Batch 800] loss: 0.0248150667275695
[Epoch 16, Batch 900] loss: 0.012937714881300053
[Epoch 16, Batch 1000] loss: 0.021396865733004235
[Epoch 16, Batch 1100] loss: 0.017533310501421512
[Epoch 16, Batch 1200] loss: 0.02510460602432431
[Epoch 16, Batch 1300] loss: 0.020050869644746852
[Epoch 16, Batch 1400] loss: 0.02069576569221681
[Epoch 16, Batch 1500] loss: 0.014545945752033732
[Epoch 16, Batch 1600] loss: 0.021132599388456585
[Epoch 16, Batch 1700] loss: 0.0176226529835003
[Epoch 16, Batch 1800] loss: 0.018108792079528938
[Epoch 16, Batch 1900] loss: 0.01700388479301182
[Epoch 16, Batch 2000] loss: 0.01945393730147771
[Epoch 16, Batch 2100] loss: 0.013901835005162866
[Epoch 16, Batch 2200] loss: 0.012175040601014188
[Epoch 16, Batch 2300] loss: 0.022350141355955203
[Epoch 16, Batch 2400] loss: 0.029970117170487354
[Epoch 16, Batch 2500] loss: 0.020455372096439533
[Epoch 16, Batch 2600] loss: 0.017931920121682196
[Epoch 16, Batch 2700] loss: 0.018523002712572633
[Epoch 16, Batch 2800] loss: 0.018370024986779754
[Epoch 16, Batch 2900] loss: 0.015598413796597014
[Epoch 16, Batch 3000] loss: 0.014818401515040023
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9852
Overfitting: 0.0485
[Epoch 17, Batch 100] loss: 0.01634817673400903
[Epoch 17, Batch 200] loss: 0.027102311644839575
[Epoch 17, Batch 300] loss: 0.013669699542206218
[Epoch 17, Batch 400] loss: 0.006447281795826712
[Epoch 17, Batch 500] loss: 0.013391181580482225
[Epoch 17, Batch 600] loss: 0.011729018430560244
[Epoch 17, Batch 700] loss: 0.015061254782631294
[Epoch 17, Batch 800] loss: 0.011563350778305902
[Epoch 17, Batch 900] loss: 0.009286814489423706
[Epoch 17, Batch 1000] loss: 0.02591345231012383
[Epoch 17, Batch 1100] loss: 0.014824396400899786
[Epoch 17, Batch 1200] loss: 0.01713361638434435
[Epoch 17, Batch 1300] loss: 0.017006005091116095
[Epoch 17, Batch 1400] loss: 0.0150429238709512
[Epoch 17, Batch 1500] loss: 0.018197801823225744
[Epoch 17, Batch 1600] loss: 0.02254142636229517
[Epoch 17, Batch 1700] loss: 0.013826932765441597
[Epoch 17, Batch 1800] loss: 0.01623996974029069
[Epoch 17, Batch 1900] loss: 0.013613194376594038
[Epoch 17, Batch 2000] loss: 0.01279212558598374
[Epoch 17, Batch 2100] loss: 0.01706514600016817
[Epoch 17, Batch 2200] loss: 0.023146396173597168
[Epoch 17, Batch 2300] loss: 0.017997689325720784
[Epoch 17, Batch 2400] loss: 0.012231769596965023
[Epoch 17, Batch 2500] loss: 0.017088630015132368
[Epoch 17, Batch 2600] loss: 0.018905486011099128
[Epoch 17, Batch 2700] loss: 0.021299165896070917
[Epoch 17, Batch 2800] loss: 0.012592187409945837
[Epoch 17, Batch 2900] loss: 0.01949871377722957
[Epoch 17, Batch 3000] loss: 0.01873546935486047
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9862
Overfitting: 0.0473
[Epoch 18, Batch 100] loss: 0.01727000209972175
[Epoch 18, Batch 200] loss: 0.008043772879282186
[Epoch 18, Batch 300] loss: 0.018750631919756414
[Epoch 18, Batch 400] loss: 0.008086453612258992
[Epoch 18, Batch 500] loss: 0.02636739710927941
[Epoch 18, Batch 600] loss: 0.01902446429750853
[Epoch 18, Batch 700] loss: 0.012405358248797712
[Epoch 18, Batch 800] loss: 0.0111545195601866
[Epoch 18, Batch 900] loss: 0.009201807345743874
[Epoch 18, Batch 1000] loss: 0.011608362850365666
[Epoch 18, Batch 1100] loss: 0.01585565539784511
[Epoch 18, Batch 1200] loss: 0.008359139067906654
[Epoch 18, Batch 1300] loss: 0.010350916581319324
[Epoch 18, Batch 1400] loss: 0.011788443012537755
[Epoch 18, Batch 1500] loss: 0.02198286889938572
[Epoch 18, Batch 1600] loss: 0.016348734402308763
[Epoch 18, Batch 1700] loss: 0.011195772474129626
[Epoch 18, Batch 1800] loss: 0.00987355879660754
[Epoch 18, Batch 1900] loss: 0.014534503117192798
[Epoch 18, Batch 2000] loss: 0.010770345558576082
[Epoch 18, Batch 2100] loss: 0.015050946561323143
[Epoch 18, Batch 2200] loss: 0.012246952338264236
[Epoch 18, Batch 2300] loss: 0.013938923488176443
[Epoch 18, Batch 2400] loss: 0.018489943397498793
[Epoch 18, Batch 2500] loss: 0.017008091821189737
[Epoch 18, Batch 2600] loss: 0.0167639989887266
[Epoch 18, Batch 2700] loss: 0.023614714890991307
[Epoch 18, Batch 2800] loss: 0.016558955787986634
[Epoch 18, Batch 2900] loss: 0.014444802485813852
[Epoch 18, Batch 3000] loss: 0.01989522628080067
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9864
Overfitting: 0.0505
[Epoch 19, Batch 100] loss: 0.009249068006979541
[Epoch 19, Batch 200] loss: 0.009813758583986783
[Epoch 19, Batch 300] loss: 0.008741926998573036
[Epoch 19, Batch 400] loss: 0.008952129798472016
[Epoch 19, Batch 500] loss: 0.012877693209256904
[Epoch 19, Batch 600] loss: 0.010316068096362868
[Epoch 19, Batch 700] loss: 0.01594879129154833
[Epoch 19, Batch 800] loss: 0.017054303949694257
[Epoch 19, Batch 900] loss: 0.029515494864717766
[Epoch 19, Batch 1000] loss: 0.014580143419807427
[Epoch 19, Batch 1100] loss: 0.013514110624992099
[Epoch 19, Batch 1200] loss: 0.016020941395017873
[Epoch 19, Batch 1300] loss: 0.010348496252881888
[Epoch 19, Batch 1400] loss: 0.013638266496914185
[Epoch 19, Batch 1500] loss: 0.0105765607444755
[Epoch 19, Batch 1600] loss: 0.013621622636483153
[Epoch 19, Batch 1700] loss: 0.013510045896764496
[Epoch 19, Batch 1800] loss: 0.014535223965140176
[Epoch 19, Batch 1900] loss: 0.01789314119682331
[Epoch 19, Batch 2000] loss: 0.020816564129981997
[Epoch 19, Batch 2100] loss: 0.008661076965322536
[Epoch 19, Batch 2200] loss: 0.01802148564169329
[Epoch 19, Batch 2300] loss: 0.009742771142282437
[Epoch 19, Batch 2400] loss: 0.012521502779618459
[Epoch 19, Batch 2500] loss: 0.02275911156715665
[Epoch 19, Batch 2600] loss: 0.009372610407963293
[Epoch 19, Batch 2700] loss: 0.009395047092612003
[Epoch 19, Batch 2800] loss: 0.00924308165741877
[Epoch 19, Batch 2900] loss: 0.01549965051347499
[Epoch 19, Batch 3000] loss: 0.012361297164388815
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9859
Overfitting: 0.0493
[Epoch 20, Batch 100] loss: 0.013674755323891077
[Epoch 20, Batch 200] loss: 0.004997246126267782
[Epoch 20, Batch 300] loss: 0.009064138032063056
[Epoch 20, Batch 400] loss: 0.013760447259101057
[Epoch 20, Batch 500] loss: 0.011865439467746909
[Epoch 20, Batch 600] loss: 0.006898218278456625
[Epoch 20, Batch 700] loss: 0.005015481793493564
[Epoch 20, Batch 800] loss: 0.006279670979301955
[Epoch 20, Batch 900] loss: 0.011928479373411847
[Epoch 20, Batch 1000] loss: 0.01505261146947305
[Epoch 20, Batch 1100] loss: 0.005187154264085621
[Epoch 20, Batch 1200] loss: 0.006100010617246881
[Epoch 20, Batch 1300] loss: 0.009187581608457548
[Epoch 20, Batch 1400] loss: 0.009849171893110907
[Epoch 20, Batch 1500] loss: 0.012874898852724073
[Epoch 20, Batch 1600] loss: 0.013679891064070944
[Epoch 20, Batch 1700] loss: 0.0047938694162667165
[Epoch 20, Batch 1800] loss: 0.012166698719247505
[Epoch 20, Batch 1900] loss: 0.007577193251727295
[Epoch 20, Batch 2000] loss: 0.01050938819871135
[Epoch 20, Batch 2100] loss: 0.027487203202003912
[Epoch 20, Batch 2200] loss: 0.014158068404140068
[Epoch 20, Batch 2300] loss: 0.013511289164207484
[Epoch 20, Batch 2400] loss: 0.024457145126525574
[Epoch 20, Batch 2500] loss: 0.024066060643872334
[Epoch 20, Batch 2600] loss: 0.014262132042840676
[Epoch 20, Batch 2700] loss: 0.012092791682443932
[Epoch 20, Batch 2800] loss: 0.009878157617804391
[Epoch 20, Batch 2900] loss: 0.01767452103252708
[Epoch 20, Batch 3000] loss: 0.013596077596621398
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9854
Overfitting: 0.0509
[Epoch 21, Batch 100] loss: 0.01013779837160655
[Epoch 21, Batch 200] loss: 0.011243832394791297
[Epoch 21, Batch 300] loss: 0.006850739690735281
[Epoch 21, Batch 400] loss: 0.0053042778512349285
[Epoch 21, Batch 500] loss: 0.008590252700214478
[Epoch 21, Batch 600] loss: 0.011212032899843507
[Epoch 21, Batch 700] loss: 0.01487687094764624
[Epoch 21, Batch 800] loss: 0.004444530784285234
[Epoch 21, Batch 900] loss: 0.004151272150002114
[Epoch 21, Batch 1000] loss: 0.011470420045482115
[Epoch 21, Batch 1100] loss: 0.012314441474100022
[Epoch 21, Batch 1200] loss: 0.02661669252075626
[Epoch 21, Batch 1300] loss: 0.005517244605171072
[Epoch 21, Batch 1400] loss: 0.00907517977488169
[Epoch 21, Batch 1500] loss: 0.024061942991447722
[Epoch 21, Batch 1600] loss: 0.012169871848936965
[Epoch 21, Batch 1700] loss: 0.01082752758659808
[Epoch 21, Batch 1800] loss: 0.01004104379851924
[Epoch 21, Batch 1900] loss: 0.012191879523497847
[Epoch 21, Batch 2000] loss: 0.013307836198073346
[Epoch 21, Batch 2100] loss: 0.009676580167106295
[Epoch 21, Batch 2200] loss: 0.014951172699111339
[Epoch 21, Batch 2300] loss: 0.008417939506730364
[Epoch 21, Batch 2400] loss: 0.03175797712492113
[Epoch 21, Batch 2500] loss: 0.010377966567075418
[Epoch 21, Batch 2600] loss: 0.011917549020131446
[Epoch 21, Batch 2700] loss: 0.009735550289933599
[Epoch 21, Batch 2800] loss: 0.017125168420127467
[Epoch 21, Batch 2900] loss: 0.01366832304730451
[Epoch 21, Batch 3000] loss: 0.012714383588622695
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9855
Overfitting: 0.0492
[Epoch 22, Batch 100] loss: 0.0061044922590281206
[Epoch 22, Batch 200] loss: 0.004546026674070162
[Epoch 22, Batch 300] loss: 0.011481659549044707
[Epoch 22, Batch 400] loss: 0.012026790707614055
[Epoch 22, Batch 500] loss: 0.017532986372034428
[Epoch 22, Batch 600] loss: 0.014014190879452144
[Epoch 22, Batch 700] loss: 0.008218117791775512
[Epoch 22, Batch 800] loss: 0.008376093835481697
[Epoch 22, Batch 900] loss: 0.005657280672619436
[Epoch 22, Batch 1000] loss: 0.00926974692893964
[Epoch 22, Batch 1100] loss: 0.008823149589961759
[Epoch 22, Batch 1200] loss: 0.011076649787009956
[Epoch 22, Batch 1300] loss: 0.017613212229362032
[Epoch 22, Batch 1400] loss: 0.009333454121074282
[Epoch 22, Batch 1500] loss: 0.008816652219820753
[Epoch 22, Batch 1600] loss: 0.006469511486234297
[Epoch 22, Batch 1700] loss: 0.007370937399073228
[Epoch 22, Batch 1800] loss: 0.005447645507538255
[Epoch 22, Batch 1900] loss: 0.004484558152794307
[Epoch 22, Batch 2000] loss: 0.014032334185740182
[Epoch 22, Batch 2100] loss: 0.009951911404191377
[Epoch 22, Batch 2200] loss: 0.008800507692542396
[Epoch 22, Batch 2300] loss: 0.0112870065150355
[Epoch 22, Batch 2400] loss: 0.013127667557082532
[Epoch 22, Batch 2500] loss: 0.009227375385180495
[Epoch 22, Batch 2600] loss: 0.010896180480185081
[Epoch 22, Batch 2700] loss: 0.01833616846314044
[Epoch 22, Batch 2800] loss: 0.02255921713974658
[Epoch 22, Batch 2900] loss: 0.008219988040286808
[Epoch 22, Batch 3000] loss: 0.011079423465171203
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9868
Overfitting: 0.0459
Best model saved at epoch 22 with validation loss: 0.0459
[Epoch 23, Batch 100] loss: 0.008384678959616849
[Epoch 23, Batch 200] loss: 0.006699750887164555
[Epoch 23, Batch 300] loss: 0.007223201199467439
[Epoch 23, Batch 400] loss: 0.006620543550125149
[Epoch 23, Batch 500] loss: 0.007322503552748003
[Epoch 23, Batch 600] loss: 0.0056880244827698335
[Epoch 23, Batch 700] loss: 0.003757296453500203
[Epoch 23, Batch 800] loss: 0.006312812353405662
[Epoch 23, Batch 900] loss: 0.00591931258613613
[Epoch 23, Batch 1000] loss: 0.0055795780456037395
[Epoch 23, Batch 1100] loss: 0.004829357567405168
[Epoch 23, Batch 1200] loss: 0.006291016925865733
[Epoch 23, Batch 1300] loss: 0.006526188395774853
[Epoch 23, Batch 1400] loss: 0.00519653271422726
[Epoch 23, Batch 1500] loss: 0.006921914031886444
[Epoch 23, Batch 1600] loss: 0.009244123332480285
[Epoch 23, Batch 1700] loss: 0.00922864011034676
[Epoch 23, Batch 1800] loss: 0.013362092249658418
[Epoch 23, Batch 1900] loss: 0.010123440655552257
[Epoch 23, Batch 2000] loss: 0.010251447522568924
[Epoch 23, Batch 2100] loss: 0.006789503606969447
[Epoch 23, Batch 2200] loss: 0.009165516097541513
[Epoch 23, Batch 2300] loss: 0.010416953931071475
[Epoch 23, Batch 2400] loss: 0.01305894253147926
[Epoch 23, Batch 2500] loss: 0.010584074793650871
[Epoch 23, Batch 2600] loss: 0.014064560539409285
[Epoch 23, Batch 2700] loss: 0.009315384306519263
[Epoch 23, Batch 2800] loss: 0.004807976272832093
[Epoch 23, Batch 2900] loss: 0.004071428611257488
[Epoch 23, Batch 3000] loss: 0.008965147169237752
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9875
Overfitting: 0.0482
[Epoch 24, Batch 100] loss: 0.005827384663339217
[Epoch 24, Batch 200] loss: 0.014710956227308997
[Epoch 24, Batch 300] loss: 0.012780624573561
[Epoch 24, Batch 400] loss: 0.007160730340197006
[Epoch 24, Batch 500] loss: 0.0038164457345965276
[Epoch 24, Batch 600] loss: 0.005010420689861803
[Epoch 24, Batch 700] loss: 0.007072548306325643
[Epoch 24, Batch 800] loss: 0.013723205225678612
[Epoch 24, Batch 900] loss: 0.011161810095445616
[Epoch 24, Batch 1000] loss: 0.00790773284059469
[Epoch 24, Batch 1100] loss: 0.0066279200103736
[Epoch 24, Batch 1200] loss: 0.004833681694356074
[Epoch 24, Batch 1300] loss: 0.0035697872111268227
[Epoch 24, Batch 1400] loss: 0.009104416949708139
[Epoch 24, Batch 1500] loss: 0.011129367301232379
[Epoch 24, Batch 1600] loss: 0.008012861603299655
[Epoch 24, Batch 1700] loss: 0.004505528250756469
[Epoch 24, Batch 1800] loss: 0.01106439080137534
[Epoch 24, Batch 1900] loss: 0.004777268787893263
[Epoch 24, Batch 2000] loss: 0.01009032003653374
[Epoch 24, Batch 2100] loss: 0.006585115328018105
[Epoch 24, Batch 2200] loss: 0.009841807558705113
[Epoch 24, Batch 2300] loss: 0.006306347598974753
[Epoch 24, Batch 2400] loss: 0.009728493354264173
[Epoch 24, Batch 2500] loss: 0.01136106241465086
[Epoch 24, Batch 2600] loss: 0.007269624459847818
[Epoch 24, Batch 2700] loss: 0.007820604255542776
[Epoch 24, Batch 2800] loss: 0.002609970198150222
[Epoch 24, Batch 2900] loss: 0.006853791311950772
[Epoch 24, Batch 3000] loss: 0.0034746861256599003
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9877
Overfitting: 0.0511
Fold 4 validation loss: 0.0511
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.302552993297577
[Epoch 1, Batch 200] loss: 2.2994278335571288
[Epoch 1, Batch 300] loss: 2.2873199796676635
[Epoch 1, Batch 400] loss: 2.28208327293396
[Epoch 1, Batch 500] loss: 2.272669081687927
[Epoch 1, Batch 600] loss: 2.2490617656707763
[Epoch 1, Batch 700] loss: 2.2008509516716
[Epoch 1, Batch 800] loss: 2.083889489173889
[Epoch 1, Batch 900] loss: 1.6260236644744872
[Epoch 1, Batch 1000] loss: 0.8763616433739663
[Epoch 1, Batch 1100] loss: 0.5598874597251415
[Epoch 1, Batch 1200] loss: 0.48719379216432573
[Epoch 1, Batch 1300] loss: 0.4067530382424593
[Epoch 1, Batch 1400] loss: 0.32845009010285137
[Epoch 1, Batch 1500] loss: 0.309195213727653
[Epoch 1, Batch 1600] loss: 0.2582845167070627
[Epoch 1, Batch 1700] loss: 0.29952881794422864
[Epoch 1, Batch 1800] loss: 0.29864223808050155
[Epoch 1, Batch 1900] loss: 0.2839655923098326
[Epoch 1, Batch 2000] loss: 0.2635481873899698
[Epoch 1, Batch 2100] loss: 0.20391289804130794
[Epoch 1, Batch 2200] loss: 0.22158221958205104
[Epoch 1, Batch 2300] loss: 0.20100143973715603
[Epoch 1, Batch 2400] loss: 0.22843547385185958
[Epoch 1, Batch 2500] loss: 0.19513171253725886
[Epoch 1, Batch 2600] loss: 0.18504364618100225
[Epoch 1, Batch 2700] loss: 0.14475422659888865
[Epoch 1, Batch 2800] loss: 0.18612306393682956
[Epoch 1, Batch 2900] loss: 0.16989765158854425
[Epoch 1, Batch 3000] loss: 0.1915135036688298
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1715
Validation Accuracy: 0.9497
Overfitting: 0.1715
Best model saved at epoch 1 with validation loss: 0.1715
[Epoch 2, Batch 100] loss: 0.15377610765397548
[Epoch 2, Batch 200] loss: 0.15741940509993582
[Epoch 2, Batch 300] loss: 0.17210082514211536
[Epoch 2, Batch 400] loss: 0.16933253227733075
[Epoch 2, Batch 500] loss: 0.1309848320670426
[Epoch 2, Batch 600] loss: 0.14250285109039396
[Epoch 2, Batch 700] loss: 0.1458542443625629
[Epoch 2, Batch 800] loss: 0.13200770025141537
[Epoch 2, Batch 900] loss: 0.14952911279164255
[Epoch 2, Batch 1000] loss: 0.1249841551319696
[Epoch 2, Batch 1100] loss: 0.14452387312659995
[Epoch 2, Batch 1200] loss: 0.12652958602644504
[Epoch 2, Batch 1300] loss: 0.10794887809781357
[Epoch 2, Batch 1400] loss: 0.1442252922710031
[Epoch 2, Batch 1500] loss: 0.10848482385277748
[Epoch 2, Batch 1600] loss: 0.1195105373999104
[Epoch 2, Batch 1700] loss: 0.11738804878899828
[Epoch 2, Batch 1800] loss: 0.11866000212030485
[Epoch 2, Batch 1900] loss: 0.1151899948483333
[Epoch 2, Batch 2000] loss: 0.13765341226011515
[Epoch 2, Batch 2100] loss: 0.10839153820648789
[Epoch 2, Batch 2200] loss: 0.11119124696357176
[Epoch 2, Batch 2300] loss: 0.09493042797781527
[Epoch 2, Batch 2400] loss: 0.13192974760662765
[Epoch 2, Batch 2500] loss: 0.11215021580923348
[Epoch 2, Batch 2600] loss: 0.09491112719755619
[Epoch 2, Batch 2700] loss: 0.0945938602462411
[Epoch 2, Batch 2800] loss: 0.0964684369880706
[Epoch 2, Batch 2900] loss: 0.0882527058920823
[Epoch 2, Batch 3000] loss: 0.0935723257646896
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1004
Validation Accuracy: 0.9702
Overfitting: 0.1004
Best model saved at epoch 2 with validation loss: 0.1004
[Epoch 3, Batch 100] loss: 0.08003136100829579
[Epoch 3, Batch 200] loss: 0.09073418104788289
[Epoch 3, Batch 300] loss: 0.08281822860939428
[Epoch 3, Batch 400] loss: 0.08076944664353505
[Epoch 3, Batch 500] loss: 0.0833252453582827
[Epoch 3, Batch 600] loss: 0.11705831609666348
[Epoch 3, Batch 700] loss: 0.09691066096071153
[Epoch 3, Batch 800] loss: 0.07550727876601741
[Epoch 3, Batch 900] loss: 0.0926650965976296
[Epoch 3, Batch 1000] loss: 0.0765911204519216
[Epoch 3, Batch 1100] loss: 0.09280475684208796
[Epoch 3, Batch 1200] loss: 0.09234617337351665
[Epoch 3, Batch 1300] loss: 0.07790070976596325
[Epoch 3, Batch 1400] loss: 0.08322289686417207
[Epoch 3, Batch 1500] loss: 0.11411843094392679
[Epoch 3, Batch 1600] loss: 0.08040754702640697
[Epoch 3, Batch 1700] loss: 0.06203329193987884
[Epoch 3, Batch 1800] loss: 0.08069467469584196
[Epoch 3, Batch 1900] loss: 0.08540786850266159
[Epoch 3, Batch 2000] loss: 0.062325709614669905
[Epoch 3, Batch 2100] loss: 0.08731716863112524
[Epoch 3, Batch 2200] loss: 0.08429569849162362
[Epoch 3, Batch 2300] loss: 0.07191615628427826
[Epoch 3, Batch 2400] loss: 0.11376471858238801
[Epoch 3, Batch 2500] loss: 0.08096281642559916
[Epoch 3, Batch 2600] loss: 0.0654891961615067
[Epoch 3, Batch 2700] loss: 0.11036666356259957
[Epoch 3, Batch 2800] loss: 0.08048450753558427
[Epoch 3, Batch 2900] loss: 0.09422906841267832
[Epoch 3, Batch 3000] loss: 0.06843093630392104
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0861
Validation Accuracy: 0.9728
Overfitting: 0.0861
Best model saved at epoch 3 with validation loss: 0.0861
[Epoch 4, Batch 100] loss: 0.0750521980272606
[Epoch 4, Batch 200] loss: 0.05954594498849474
[Epoch 4, Batch 300] loss: 0.07377182572497987
[Epoch 4, Batch 400] loss: 0.05090240250865463
[Epoch 4, Batch 500] loss: 0.0490469792264048
[Epoch 4, Batch 600] loss: 0.0832045101345284
[Epoch 4, Batch 700] loss: 0.07384965009579901
[Epoch 4, Batch 800] loss: 0.07770478691090829
[Epoch 4, Batch 900] loss: 0.05873488542856649
[Epoch 4, Batch 1000] loss: 0.07246250775991939
[Epoch 4, Batch 1100] loss: 0.052937318959739056
[Epoch 4, Batch 1200] loss: 0.055205458843847734
[Epoch 4, Batch 1300] loss: 0.07675390526768751
[Epoch 4, Batch 1400] loss: 0.03951405591913499
[Epoch 4, Batch 1500] loss: 0.056016710203839463
[Epoch 4, Batch 1600] loss: 0.0787163744965801
[Epoch 4, Batch 1700] loss: 0.07430994187132456
[Epoch 4, Batch 1800] loss: 0.0756279777653981
[Epoch 4, Batch 1900] loss: 0.05856415275717154
[Epoch 4, Batch 2000] loss: 0.06861654013395309
[Epoch 4, Batch 2100] loss: 0.058640164890675806
[Epoch 4, Batch 2200] loss: 0.07097718988312408
[Epoch 4, Batch 2300] loss: 0.06914770463423338
[Epoch 4, Batch 2400] loss: 0.052002515310887246
[Epoch 4, Batch 2500] loss: 0.05413607286522165
[Epoch 4, Batch 2600] loss: 0.07532944754697382
[Epoch 4, Batch 2700] loss: 0.07434443141304654
[Epoch 4, Batch 2800] loss: 0.07112012576195412
[Epoch 4, Batch 2900] loss: 0.08059506660094484
[Epoch 4, Batch 3000] loss: 0.0849831804598216
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0764
Validation Accuracy: 0.9768
Overfitting: 0.0764
Best model saved at epoch 4 with validation loss: 0.0764
[Epoch 5, Batch 100] loss: 0.0592208850744646
[Epoch 5, Batch 200] loss: 0.060084478406934066
[Epoch 5, Batch 300] loss: 0.05089142883894965
[Epoch 5, Batch 400] loss: 0.04250733571534511
[Epoch 5, Batch 500] loss: 0.058842870851513
[Epoch 5, Batch 600] loss: 0.06708109781728126
[Epoch 5, Batch 700] loss: 0.056817778209224346
[Epoch 5, Batch 800] loss: 0.06474981962703169
[Epoch 5, Batch 900] loss: 0.0437742838205304
[Epoch 5, Batch 1000] loss: 0.06848804256995208
[Epoch 5, Batch 1100] loss: 0.05266481751576066
[Epoch 5, Batch 1200] loss: 0.053265317833283914
[Epoch 5, Batch 1300] loss: 0.052735156691633166
[Epoch 5, Batch 1400] loss: 0.047155887392000294
[Epoch 5, Batch 1500] loss: 0.04394788892139331
[Epoch 5, Batch 1600] loss: 0.04902135316398926
[Epoch 5, Batch 1700] loss: 0.08001853553723777
[Epoch 5, Batch 1800] loss: 0.05007159597298596
[Epoch 5, Batch 1900] loss: 0.05111549820750952
[Epoch 5, Batch 2000] loss: 0.0632585860742256
[Epoch 5, Batch 2100] loss: 0.05904236819013022
[Epoch 5, Batch 2200] loss: 0.04403792855504435
[Epoch 5, Batch 2300] loss: 0.05075337241345551
[Epoch 5, Batch 2400] loss: 0.05485900212501292
[Epoch 5, Batch 2500] loss: 0.06251537358184578
[Epoch 5, Batch 2600] loss: 0.0637585125840269
[Epoch 5, Batch 2700] loss: 0.05711951421748381
[Epoch 5, Batch 2800] loss: 0.04981950290268287
[Epoch 5, Batch 2900] loss: 0.05429618188878521
[Epoch 5, Batch 3000] loss: 0.04860405160347
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0666
Validation Accuracy: 0.9798
Overfitting: 0.0666
Best model saved at epoch 5 with validation loss: 0.0666
[Epoch 6, Batch 100] loss: 0.04886258994054515
[Epoch 6, Batch 200] loss: 0.06576397581666242
[Epoch 6, Batch 300] loss: 0.046573907058191255
[Epoch 6, Batch 400] loss: 0.04691058533964679
[Epoch 6, Batch 500] loss: 0.052928757293266245
[Epoch 6, Batch 600] loss: 0.0553509960899828
[Epoch 6, Batch 700] loss: 0.03869533669727389
[Epoch 6, Batch 800] loss: 0.04915528534329496
[Epoch 6, Batch 900] loss: 0.03557241527538281
[Epoch 6, Batch 1000] loss: 0.04517609198519494
[Epoch 6, Batch 1100] loss: 0.04080133655836107
[Epoch 6, Batch 1200] loss: 0.05473681187868351
[Epoch 6, Batch 1300] loss: 0.03677547396728187
[Epoch 6, Batch 1400] loss: 0.045030926488689144
[Epoch 6, Batch 1500] loss: 0.04351603037677705
[Epoch 6, Batch 1600] loss: 0.04681959472363815
[Epoch 6, Batch 1700] loss: 0.04332040053530364
[Epoch 6, Batch 1800] loss: 0.05569639615307096
[Epoch 6, Batch 1900] loss: 0.04024273334594909
[Epoch 6, Batch 2000] loss: 0.05063590782898245
[Epoch 6, Batch 2100] loss: 0.05111331522930414
[Epoch 6, Batch 2200] loss: 0.06197226790332934
[Epoch 6, Batch 2300] loss: 0.04190035088773584
[Epoch 6, Batch 2400] loss: 0.05663312290154863
[Epoch 6, Batch 2500] loss: 0.033581125101773066
[Epoch 6, Batch 2600] loss: 0.0433736725433846
[Epoch 6, Batch 2700] loss: 0.05047466303105466
[Epoch 6, Batch 2800] loss: 0.04384877573203994
[Epoch 6, Batch 2900] loss: 0.04551494245490176
[Epoch 6, Batch 3000] loss: 0.03712435063178418
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0557
Validation Accuracy: 0.9828
Overfitting: 0.0557
Best model saved at epoch 6 with validation loss: 0.0557
[Epoch 7, Batch 100] loss: 0.03711917180684395
[Epoch 7, Batch 200] loss: 0.03622436043195194
[Epoch 7, Batch 300] loss: 0.0498459080910834
[Epoch 7, Batch 400] loss: 0.04610541341535281
[Epoch 7, Batch 500] loss: 0.04857159347971901
[Epoch 7, Batch 600] loss: 0.04410602984542493
[Epoch 7, Batch 700] loss: 0.03469981434871443
[Epoch 7, Batch 800] loss: 0.03777619528176729
[Epoch 7, Batch 900] loss: 0.04160328074649442
[Epoch 7, Batch 1000] loss: 0.03300994567514863
[Epoch 7, Batch 1100] loss: 0.039748262028151654
[Epoch 7, Batch 1200] loss: 0.043343442009645516
[Epoch 7, Batch 1300] loss: 0.0350932599423686
[Epoch 7, Batch 1400] loss: 0.03699009998643305
[Epoch 7, Batch 1500] loss: 0.04617885144558386
[Epoch 7, Batch 1600] loss: 0.04238273835275322
[Epoch 7, Batch 1700] loss: 0.04259496149519691
[Epoch 7, Batch 1800] loss: 0.035283736283017786
[Epoch 7, Batch 1900] loss: 0.045359961034264415
[Epoch 7, Batch 2000] loss: 0.05789670465499512
[Epoch 7, Batch 2100] loss: 0.05032796886167489
[Epoch 7, Batch 2200] loss: 0.026574279103224397
[Epoch 7, Batch 2300] loss: 0.028971946429956007
[Epoch 7, Batch 2400] loss: 0.05450353270425694
[Epoch 7, Batch 2500] loss: 0.052200826623302415
[Epoch 7, Batch 2600] loss: 0.03257573679264169
[Epoch 7, Batch 2700] loss: 0.044475927891617174
[Epoch 7, Batch 2800] loss: 0.04526283637591405
[Epoch 7, Batch 2900] loss: 0.03922125451383181
[Epoch 7, Batch 3000] loss: 0.042555605207599004
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9828
Overfitting: 0.0533
Best model saved at epoch 7 with validation loss: 0.0533
[Epoch 8, Batch 100] loss: 0.03405112530963379
[Epoch 8, Batch 200] loss: 0.02764499908356811
[Epoch 8, Batch 300] loss: 0.03913013171113562
[Epoch 8, Batch 400] loss: 0.03433669053352787
[Epoch 8, Batch 500] loss: 0.03592856907183886
[Epoch 8, Batch 600] loss: 0.03754694868781371
[Epoch 8, Batch 700] loss: 0.021602296269848012
[Epoch 8, Batch 800] loss: 0.045531518945063
[Epoch 8, Batch 900] loss: 0.04064605029729137
[Epoch 8, Batch 1000] loss: 0.0358482569885382
[Epoch 8, Batch 1100] loss: 0.033672611100628275
[Epoch 8, Batch 1200] loss: 0.030254710010340205
[Epoch 8, Batch 1300] loss: 0.03634949449449778
[Epoch 8, Batch 1400] loss: 0.029877696163457586
[Epoch 8, Batch 1500] loss: 0.03441047563726898
[Epoch 8, Batch 1600] loss: 0.033466513403691354
[Epoch 8, Batch 1700] loss: 0.04684379372891272
[Epoch 8, Batch 1800] loss: 0.049986356271838304
[Epoch 8, Batch 1900] loss: 0.03718500021714135
[Epoch 8, Batch 2000] loss: 0.04149407124175923
[Epoch 8, Batch 2100] loss: 0.03938232244050596
[Epoch 8, Batch 2200] loss: 0.03422708834015793
[Epoch 8, Batch 2300] loss: 0.03747730934672291
[Epoch 8, Batch 2400] loss: 0.045101542814227284
[Epoch 8, Batch 2500] loss: 0.030895086956443264
[Epoch 8, Batch 2600] loss: 0.031654510100197514
[Epoch 8, Batch 2700] loss: 0.029927355376421473
[Epoch 8, Batch 2800] loss: 0.05975828772439854
[Epoch 8, Batch 2900] loss: 0.040590066232252864
[Epoch 8, Batch 3000] loss: 0.042676199656416426
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9830
Overfitting: 0.0550
[Epoch 9, Batch 100] loss: 0.028155634294089394
[Epoch 9, Batch 200] loss: 0.032890283089363946
[Epoch 9, Batch 300] loss: 0.03432813782710582
[Epoch 9, Batch 400] loss: 0.03535707367089344
[Epoch 9, Batch 500] loss: 0.03233643243831466
[Epoch 9, Batch 600] loss: 0.02766631840422633
[Epoch 9, Batch 700] loss: 0.030290480970579667
[Epoch 9, Batch 800] loss: 0.03253278641670477
[Epoch 9, Batch 900] loss: 0.026651005265011917
[Epoch 9, Batch 1000] loss: 0.05210631826746976
[Epoch 9, Batch 1100] loss: 0.02477781106339535
[Epoch 9, Batch 1200] loss: 0.034709428964924884
[Epoch 9, Batch 1300] loss: 0.032578123943458194
[Epoch 9, Batch 1400] loss: 0.016945011227508074
[Epoch 9, Batch 1500] loss: 0.024577177703467897
[Epoch 9, Batch 1600] loss: 0.04424381971723051
[Epoch 9, Batch 1700] loss: 0.02853855673543876
[Epoch 9, Batch 1800] loss: 0.03776474364676687
[Epoch 9, Batch 1900] loss: 0.04002440687341732
[Epoch 9, Batch 2000] loss: 0.03351579009264242
[Epoch 9, Batch 2100] loss: 0.029463940057758008
[Epoch 9, Batch 2200] loss: 0.03541805147091509
[Epoch 9, Batch 2300] loss: 0.028095007153606275
[Epoch 9, Batch 2400] loss: 0.03671927665374824
[Epoch 9, Batch 2500] loss: 0.02231702100543771
[Epoch 9, Batch 2600] loss: 0.028064398476126372
[Epoch 9, Batch 2700] loss: 0.029765605368593243
[Epoch 9, Batch 2800] loss: 0.03684828058139829
[Epoch 9, Batch 2900] loss: 0.037952136884268836
[Epoch 9, Batch 3000] loss: 0.03868943094610586
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9859
Overfitting: 0.0459
Best model saved at epoch 9 with validation loss: 0.0459
[Epoch 10, Batch 100] loss: 0.02969786740562995
[Epoch 10, Batch 200] loss: 0.022398980049183594
[Epoch 10, Batch 300] loss: 0.023419249479993597
[Epoch 10, Batch 400] loss: 0.04649100755414111
[Epoch 10, Batch 500] loss: 0.022616877966211178
[Epoch 10, Batch 600] loss: 0.02738561629812466
[Epoch 10, Batch 700] loss: 0.025299577990735997
[Epoch 10, Batch 800] loss: 0.023140916904230834
[Epoch 10, Batch 900] loss: 0.028093788361074984
[Epoch 10, Batch 1000] loss: 0.028554514886054677
[Epoch 10, Batch 1100] loss: 0.030603878545807674
[Epoch 10, Batch 1200] loss: 0.024774280113633723
[Epoch 10, Batch 1300] loss: 0.023207007556156897
[Epoch 10, Batch 1400] loss: 0.020640407395694636
[Epoch 10, Batch 1500] loss: 0.03136810668511316
[Epoch 10, Batch 1600] loss: 0.039790286695351826
[Epoch 10, Batch 1700] loss: 0.023051649388144142
[Epoch 10, Batch 1800] loss: 0.032815157832228575
[Epoch 10, Batch 1900] loss: 0.0330681872209243
[Epoch 10, Batch 2000] loss: 0.03726456069780397
[Epoch 10, Batch 2100] loss: 0.019519280631866424
[Epoch 10, Batch 2200] loss: 0.03026304906263249
[Epoch 10, Batch 2300] loss: 0.032365014813403835
[Epoch 10, Batch 2400] loss: 0.028210483828588623
[Epoch 10, Batch 2500] loss: 0.03051278049388202
[Epoch 10, Batch 2600] loss: 0.027870588705845876
[Epoch 10, Batch 2700] loss: 0.02951859185392095
[Epoch 10, Batch 2800] loss: 0.041268081665839416
[Epoch 10, Batch 2900] loss: 0.02419402833576896
[Epoch 10, Batch 3000] loss: 0.026680873902951135
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0498
Validation Accuracy: 0.9850
Overfitting: 0.0498
[Epoch 11, Batch 100] loss: 0.030193764388823183
[Epoch 11, Batch 200] loss: 0.014822939549339935
[Epoch 11, Batch 300] loss: 0.024656625457573682
[Epoch 11, Batch 400] loss: 0.019724684472894296
[Epoch 11, Batch 500] loss: 0.02412304684672563
[Epoch 11, Batch 600] loss: 0.032071235878684094
[Epoch 11, Batch 700] loss: 0.026628322077849587
[Epoch 11, Batch 800] loss: 0.024139296057328466
[Epoch 11, Batch 900] loss: 0.028761914926799362
[Epoch 11, Batch 1000] loss: 0.023939963002922015
[Epoch 11, Batch 1100] loss: 0.022616785067293678
[Epoch 11, Batch 1200] loss: 0.026959150247712386
[Epoch 11, Batch 1300] loss: 0.031064425330841913
[Epoch 11, Batch 1400] loss: 0.02663338395621395
[Epoch 11, Batch 1500] loss: 0.034862033427052665
[Epoch 11, Batch 1600] loss: 0.03275810702783929
[Epoch 11, Batch 1700] loss: 0.020543696544118573
[Epoch 11, Batch 1800] loss: 0.03385409260969027
[Epoch 11, Batch 1900] loss: 0.035778995582513747
[Epoch 11, Batch 2000] loss: 0.015538268152813544
[Epoch 11, Batch 2100] loss: 0.017914694647988654
[Epoch 11, Batch 2200] loss: 0.032171446038337305
[Epoch 11, Batch 2300] loss: 0.021485976650728843
[Epoch 11, Batch 2400] loss: 0.022054774866992376
[Epoch 11, Batch 2500] loss: 0.02368654873003834
[Epoch 11, Batch 2600] loss: 0.028568878238002072
[Epoch 11, Batch 2700] loss: 0.02655079101357842
[Epoch 11, Batch 2800] loss: 0.0323575061000156
[Epoch 11, Batch 2900] loss: 0.024998857979808234
[Epoch 11, Batch 3000] loss: 0.02482900250921375
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9844
Overfitting: 0.0494
[Epoch 12, Batch 100] loss: 0.03166283120473963
[Epoch 12, Batch 200] loss: 0.016406660352513428
[Epoch 12, Batch 300] loss: 0.029550856004716478
[Epoch 12, Batch 400] loss: 0.01493154476484051
[Epoch 12, Batch 500] loss: 0.01440917004365474
[Epoch 12, Batch 600] loss: 0.040928616383171176
[Epoch 12, Batch 700] loss: 0.02168801725743833
[Epoch 12, Batch 800] loss: 0.02186356795587926
[Epoch 12, Batch 900] loss: 0.015610782771909726
[Epoch 12, Batch 1000] loss: 0.02140822189729079
[Epoch 12, Batch 1100] loss: 0.02069682582544374
[Epoch 12, Batch 1200] loss: 0.024671879913075827
[Epoch 12, Batch 1300] loss: 0.020119194966609938
[Epoch 12, Batch 1400] loss: 0.021535918879308155
[Epoch 12, Batch 1500] loss: 0.024203327519899176
[Epoch 12, Batch 1600] loss: 0.03067506421044527
[Epoch 12, Batch 1700] loss: 0.022646445152786326
[Epoch 12, Batch 1800] loss: 0.02577645380240938
[Epoch 12, Batch 1900] loss: 0.02195568196075328
[Epoch 12, Batch 2000] loss: 0.023661084659033806
[Epoch 12, Batch 2100] loss: 0.025338091251906007
[Epoch 12, Batch 2200] loss: 0.019426261018343213
[Epoch 12, Batch 2300] loss: 0.022897802720690377
[Epoch 12, Batch 2400] loss: 0.022536908950169163
[Epoch 12, Batch 2500] loss: 0.016421975949670015
[Epoch 12, Batch 2600] loss: 0.02806396370360744
[Epoch 12, Batch 2700] loss: 0.019640544362373474
[Epoch 12, Batch 2800] loss: 0.028471394458429132
[Epoch 12, Batch 2900] loss: 0.024754050339870447
[Epoch 12, Batch 3000] loss: 0.026390201528556645
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0498
Validation Accuracy: 0.9838
Overfitting: 0.0498
[Epoch 13, Batch 100] loss: 0.013573988673961139
[Epoch 13, Batch 200] loss: 0.011521977863740176
[Epoch 13, Batch 300] loss: 0.014414246846135938
[Epoch 13, Batch 400] loss: 0.01533898695735843
[Epoch 13, Batch 500] loss: 0.01541682875900733
[Epoch 13, Batch 600] loss: 0.02234073446721595
[Epoch 13, Batch 700] loss: 0.014138601479389763
[Epoch 13, Batch 800] loss: 0.021022475491226943
[Epoch 13, Batch 900] loss: 0.02073734508419875
[Epoch 13, Batch 1000] loss: 0.02799199193737877
[Epoch 13, Batch 1100] loss: 0.025831293632800224
[Epoch 13, Batch 1200] loss: 0.023073823538506986
[Epoch 13, Batch 1300] loss: 0.020343106867512686
[Epoch 13, Batch 1400] loss: 0.017637867434059443
[Epoch 13, Batch 1500] loss: 0.019124638065040927
[Epoch 13, Batch 1600] loss: 0.020611729642805585
[Epoch 13, Batch 1700] loss: 0.013229218522246811
[Epoch 13, Batch 1800] loss: 0.022663218772613618
[Epoch 13, Batch 1900] loss: 0.018058443379195523
[Epoch 13, Batch 2000] loss: 0.028235446858179785
[Epoch 13, Batch 2100] loss: 0.016788024505058275
[Epoch 13, Batch 2200] loss: 0.019056642246177945
[Epoch 13, Batch 2300] loss: 0.025902717302415112
[Epoch 13, Batch 2400] loss: 0.03963737584737828
[Epoch 13, Batch 2500] loss: 0.022483060766862763
[Epoch 13, Batch 2600] loss: 0.021552621928385633
[Epoch 13, Batch 2700] loss: 0.021965255832437833
[Epoch 13, Batch 2800] loss: 0.021245816731388912
[Epoch 13, Batch 2900] loss: 0.025029736315082117
[Epoch 13, Batch 3000] loss: 0.02947312579741265
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9797
Overfitting: 0.0606
[Epoch 14, Batch 100] loss: 0.018056536108615545
[Epoch 14, Batch 200] loss: 0.016456764142822065
[Epoch 14, Batch 300] loss: 0.013744829096831382
[Epoch 14, Batch 400] loss: 0.01330179873315501
[Epoch 14, Batch 500] loss: 0.024103219319222262
[Epoch 14, Batch 600] loss: 0.019208932755682327
[Epoch 14, Batch 700] loss: 0.013308960370777641
[Epoch 14, Batch 800] loss: 0.01924734344034732
[Epoch 14, Batch 900] loss: 0.030419904835871422
[Epoch 14, Batch 1000] loss: 0.015462793686238001
[Epoch 14, Batch 1100] loss: 0.021477636208292097
[Epoch 14, Batch 1200] loss: 0.026580588259384967
[Epoch 14, Batch 1300] loss: 0.012540042194686976
[Epoch 14, Batch 1400] loss: 0.024453487215723727
[Epoch 14, Batch 1500] loss: 0.009597592234349576
[Epoch 14, Batch 1600] loss: 0.030658412389857403
[Epoch 14, Batch 1700] loss: 0.01796277483430458
[Epoch 14, Batch 1800] loss: 0.011741063634544843
[Epoch 14, Batch 1900] loss: 0.013118100294486795
[Epoch 14, Batch 2000] loss: 0.011748628894565627
[Epoch 14, Batch 2100] loss: 0.015176973948782688
[Epoch 14, Batch 2200] loss: 0.016343677250115433
[Epoch 14, Batch 2300] loss: 0.014681346285160544
[Epoch 14, Batch 2400] loss: 0.03705097073219804
[Epoch 14, Batch 2500] loss: 0.01150626884505982
[Epoch 14, Batch 2600] loss: 0.013087948787897404
[Epoch 14, Batch 2700] loss: 0.023278975741341128
[Epoch 14, Batch 2800] loss: 0.021752718381103476
[Epoch 14, Batch 2900] loss: 0.0218624541151803
[Epoch 14, Batch 3000] loss: 0.02627958543271234
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9852
Overfitting: 0.0483
[Epoch 15, Batch 100] loss: 0.02081634906403451
[Epoch 15, Batch 200] loss: 0.021269255427487224
[Epoch 15, Batch 300] loss: 0.010028564664644364
[Epoch 15, Batch 400] loss: 0.017739032661884268
[Epoch 15, Batch 500] loss: 0.02513417961767118
[Epoch 15, Batch 600] loss: 0.02435562150698388
[Epoch 15, Batch 700] loss: 0.012265385182945465
[Epoch 15, Batch 800] loss: 0.010491161344434658
[Epoch 15, Batch 900] loss: 0.016249324717282434
[Epoch 15, Batch 1000] loss: 0.01267821253692091
[Epoch 15, Batch 1100] loss: 0.02415020371421633
[Epoch 15, Batch 1200] loss: 0.009737264172290452
[Epoch 15, Batch 1300] loss: 0.008237688896042528
[Epoch 15, Batch 1400] loss: 0.03836196026250036
[Epoch 15, Batch 1500] loss: 0.017804642582923406
[Epoch 15, Batch 1600] loss: 0.018197197896915894
[Epoch 15, Batch 1700] loss: 0.014839904237487645
[Epoch 15, Batch 1800] loss: 0.014180582210719876
[Epoch 15, Batch 1900] loss: 0.020276082735326783
[Epoch 15, Batch 2000] loss: 0.022876550316250358
[Epoch 15, Batch 2100] loss: 0.018652153255898155
[Epoch 15, Batch 2200] loss: 0.011935249069138081
[Epoch 15, Batch 2300] loss: 0.013968520420385176
[Epoch 15, Batch 2400] loss: 0.022514825229500275
[Epoch 15, Batch 2500] loss: 0.01385615282379149
[Epoch 15, Batch 2600] loss: 0.020746459936199245
[Epoch 15, Batch 2700] loss: 0.015063566168937541
[Epoch 15, Batch 2800] loss: 0.012106476722601655
[Epoch 15, Batch 2900] loss: 0.01237094707423239
[Epoch 15, Batch 3000] loss: 0.022406440486720386
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0388
Validation Accuracy: 0.9887
Overfitting: 0.0388
Best model saved at epoch 15 with validation loss: 0.0388
[Epoch 16, Batch 100] loss: 0.010663321503816405
[Epoch 16, Batch 200] loss: 0.013838959515051102
[Epoch 16, Batch 300] loss: 0.015267492588000095
[Epoch 16, Batch 400] loss: 0.012948131550147082
[Epoch 16, Batch 500] loss: 0.010741855112883059
[Epoch 16, Batch 600] loss: 0.016754230213991833
[Epoch 16, Batch 700] loss: 0.02257852375460061
[Epoch 16, Batch 800] loss: 0.01860926440142066
[Epoch 16, Batch 900] loss: 0.020636405365657993
[Epoch 16, Batch 1000] loss: 0.01836874353208259
[Epoch 16, Batch 1100] loss: 0.01198780093662208
[Epoch 16, Batch 1200] loss: 0.013469193456585345
[Epoch 16, Batch 1300] loss: 0.015141984542005958
[Epoch 16, Batch 1400] loss: 0.016220634614473966
[Epoch 16, Batch 1500] loss: 0.014288399400757044
[Epoch 16, Batch 1600] loss: 0.014383125703307086
[Epoch 16, Batch 1700] loss: 0.01639278308241046
[Epoch 16, Batch 1800] loss: 0.018546232597363998
[Epoch 16, Batch 1900] loss: 0.011538103471903014
[Epoch 16, Batch 2000] loss: 0.01922567360534231
[Epoch 16, Batch 2100] loss: 0.013993059132826603
[Epoch 16, Batch 2200] loss: 0.01772490634206406
[Epoch 16, Batch 2300] loss: 0.01164306058522925
[Epoch 16, Batch 2400] loss: 0.01631803372503782
[Epoch 16, Batch 2500] loss: 0.018669515502242575
[Epoch 16, Batch 2600] loss: 0.019840666021973447
[Epoch 16, Batch 2700] loss: 0.013664625473356864
[Epoch 16, Batch 2800] loss: 0.015701140058095007
[Epoch 16, Batch 2900] loss: 0.008910799071409202
[Epoch 16, Batch 3000] loss: 0.02768983123030921
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9861
Overfitting: 0.0480
[Epoch 17, Batch 100] loss: 0.01137921048075441
[Epoch 17, Batch 200] loss: 0.010386418348898587
[Epoch 17, Batch 300] loss: 0.010710093094185141
[Epoch 17, Batch 400] loss: 0.013279509120729926
[Epoch 17, Batch 500] loss: 0.013472782716071378
[Epoch 17, Batch 600] loss: 0.008686116535600377
[Epoch 17, Batch 700] loss: 0.015271224813041044
[Epoch 17, Batch 800] loss: 0.020205026344556246
[Epoch 17, Batch 900] loss: 0.02260458459979418
[Epoch 17, Batch 1000] loss: 0.01911992694165747
[Epoch 17, Batch 1100] loss: 0.022901588139720843
[Epoch 17, Batch 1200] loss: 0.016077807395640777
[Epoch 17, Batch 1300] loss: 0.009017906844510435
[Epoch 17, Batch 1400] loss: 0.02046591964241088
[Epoch 17, Batch 1500] loss: 0.013987666960310889
[Epoch 17, Batch 1600] loss: 0.012645762203546837
[Epoch 17, Batch 1700] loss: 0.009961034792795545
[Epoch 17, Batch 1800] loss: 0.017120313047148557
[Epoch 17, Batch 1900] loss: 0.01048633052396326
[Epoch 17, Batch 2000] loss: 0.01109698505978031
[Epoch 17, Batch 2100] loss: 0.00966829131401937
[Epoch 17, Batch 2200] loss: 0.009799848433394799
[Epoch 17, Batch 2300] loss: 0.011561948737717103
[Epoch 17, Batch 2400] loss: 0.007979874105585623
[Epoch 17, Batch 2500] loss: 0.01296050834858761
[Epoch 17, Batch 2600] loss: 0.02027299889380629
[Epoch 17, Batch 2700] loss: 0.018256322171059765
[Epoch 17, Batch 2800] loss: 0.015328963313213534
[Epoch 17, Batch 2900] loss: 0.011594726759467449
[Epoch 17, Batch 3000] loss: 0.011087423715143813
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9873
Overfitting: 0.0436
[Epoch 18, Batch 100] loss: 0.014053491678932915
[Epoch 18, Batch 200] loss: 0.016649568701886892
[Epoch 18, Batch 300] loss: 0.012638618635419334
[Epoch 18, Batch 400] loss: 0.012648262799941676
[Epoch 18, Batch 500] loss: 0.015617201535528693
[Epoch 18, Batch 600] loss: 0.01076851308973346
[Epoch 18, Batch 700] loss: 0.016051971586161926
[Epoch 18, Batch 800] loss: 0.00987772221194973
[Epoch 18, Batch 900] loss: 0.016105519271077354
[Epoch 18, Batch 1000] loss: 0.011049032866394555
[Epoch 18, Batch 1100] loss: 0.016445412880085542
[Epoch 18, Batch 1200] loss: 0.010256788299029722
[Epoch 18, Batch 1300] loss: 0.015825860018585446
[Epoch 18, Batch 1400] loss: 0.00612863016067422
[Epoch 18, Batch 1500] loss: 0.011239321195553202
[Epoch 18, Batch 1600] loss: 0.009286570550580108
[Epoch 18, Batch 1700] loss: 0.012058149831736954
[Epoch 18, Batch 1800] loss: 0.010466215660799208
[Epoch 18, Batch 1900] loss: 0.012474138831603341
[Epoch 18, Batch 2000] loss: 0.015630226032828886
[Epoch 18, Batch 2100] loss: 0.013073236072050349
[Epoch 18, Batch 2200] loss: 0.018128904534496542
[Epoch 18, Batch 2300] loss: 0.010263649062653712
[Epoch 18, Batch 2400] loss: 0.01889843896338789
[Epoch 18, Batch 2500] loss: 0.009661043252422133
[Epoch 18, Batch 2600] loss: 0.017467501420715053
[Epoch 18, Batch 2700] loss: 0.01770360403092127
[Epoch 18, Batch 2800] loss: 0.026196044143507607
[Epoch 18, Batch 2900] loss: 0.012785577135164204
[Epoch 18, Batch 3000] loss: 0.015373348631583213
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0387
Validation Accuracy: 0.9887
Overfitting: 0.0387
Best model saved at epoch 18 with validation loss: 0.0387
[Epoch 19, Batch 100] loss: 0.015500609219843682
[Epoch 19, Batch 200] loss: 0.00562957738275145
[Epoch 19, Batch 300] loss: 0.005220022259345569
[Epoch 19, Batch 400] loss: 0.007867180514840583
[Epoch 19, Batch 500] loss: 0.007423020944315795
[Epoch 19, Batch 600] loss: 0.011153597289326172
[Epoch 19, Batch 700] loss: 0.01036254780170566
[Epoch 19, Batch 800] loss: 0.014379630554294635
[Epoch 19, Batch 900] loss: 0.00830734852957903
[Epoch 19, Batch 1000] loss: 0.010268152106330036
[Epoch 19, Batch 1100] loss: 0.010012864277155132
[Epoch 19, Batch 1200] loss: 0.014611445179361908
[Epoch 19, Batch 1300] loss: 0.010889385272103027
[Epoch 19, Batch 1400] loss: 0.01218360340455547
[Epoch 19, Batch 1500] loss: 0.025156902278758934
[Epoch 19, Batch 1600] loss: 0.0076951718448344765
[Epoch 19, Batch 1700] loss: 0.013784354201325186
[Epoch 19, Batch 1800] loss: 0.01274855254004251
[Epoch 19, Batch 1900] loss: 0.012257266875276401
[Epoch 19, Batch 2000] loss: 0.007220491233256326
[Epoch 19, Batch 2100] loss: 0.008355788513281368
[Epoch 19, Batch 2200] loss: 0.012112789651027925
[Epoch 19, Batch 2300] loss: 0.013485814141495212
[Epoch 19, Batch 2400] loss: 0.013382146111330257
[Epoch 19, Batch 2500] loss: 0.011717144195863512
[Epoch 19, Batch 2600] loss: 0.019611454403420794
[Epoch 19, Batch 2700] loss: 0.014852096196036654
[Epoch 19, Batch 2800] loss: 0.019363126933130845
[Epoch 19, Batch 2900] loss: 0.015743468221080546
[Epoch 19, Batch 3000] loss: 0.014277127422724334
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0393
Validation Accuracy: 0.9891
Overfitting: 0.0393
[Epoch 20, Batch 100] loss: 0.00722657568786417
[Epoch 20, Batch 200] loss: 0.0035197923100804473
[Epoch 20, Batch 300] loss: 0.020807209728166073
[Epoch 20, Batch 400] loss: 0.0066849395950157485
[Epoch 20, Batch 500] loss: 0.006387029635116051
[Epoch 20, Batch 600] loss: 0.012427735697619936
[Epoch 20, Batch 700] loss: 0.005768662453256183
[Epoch 20, Batch 800] loss: 0.015519997355968372
[Epoch 20, Batch 900] loss: 0.011309799807331728
[Epoch 20, Batch 1000] loss: 0.010728684211708242
[Epoch 20, Batch 1100] loss: 0.010379621144975317
[Epoch 20, Batch 1200] loss: 0.014856907937637515
[Epoch 20, Batch 1300] loss: 0.006875895825260159
[Epoch 20, Batch 1400] loss: 0.01224414724124017
[Epoch 20, Batch 1500] loss: 0.00936611512572199
[Epoch 20, Batch 1600] loss: 0.01314055178718263
[Epoch 20, Batch 1700] loss: 0.017328993228225044
[Epoch 20, Batch 1800] loss: 0.008911477282745182
[Epoch 20, Batch 1900] loss: 0.010262544131892355
[Epoch 20, Batch 2000] loss: 0.014568230845511607
[Epoch 20, Batch 2100] loss: 0.005387068692816683
[Epoch 20, Batch 2200] loss: 0.0069817696126665395
[Epoch 20, Batch 2300] loss: 0.01231845162206355
[Epoch 20, Batch 2400] loss: 0.006201776072439316
[Epoch 20, Batch 2500] loss: 0.011033634988734775
[Epoch 20, Batch 2600] loss: 0.009979088833042625
[Epoch 20, Batch 2700] loss: 0.01324585557365026
[Epoch 20, Batch 2800] loss: 0.01355904751750586
[Epoch 20, Batch 2900] loss: 0.012191235252867045
[Epoch 20, Batch 3000] loss: 0.007422934739224729
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0419
Validation Accuracy: 0.9881
Overfitting: 0.0419
[Epoch 21, Batch 100] loss: 0.010372643554255774
[Epoch 21, Batch 200] loss: 0.007878795935357629
[Epoch 21, Batch 300] loss: 0.007794582957258172
[Epoch 21, Batch 400] loss: 0.010848598195625527
[Epoch 21, Batch 500] loss: 0.005011999374146398
[Epoch 21, Batch 600] loss: 0.010687900086204537
[Epoch 21, Batch 700] loss: 0.006100941444824457
[Epoch 21, Batch 800] loss: 0.013106156285430189
[Epoch 21, Batch 900] loss: 0.003596141900463863
[Epoch 21, Batch 1000] loss: 0.007588557691478854
[Epoch 21, Batch 1100] loss: 0.006504095920172403
[Epoch 21, Batch 1200] loss: 0.014729978509785724
[Epoch 21, Batch 1300] loss: 0.004829941370549023
[Epoch 21, Batch 1400] loss: 0.005659717012367765
[Epoch 21, Batch 1500] loss: 0.0073530382198055124
[Epoch 21, Batch 1600] loss: 0.013802349265079101
[Epoch 21, Batch 1700] loss: 0.022705360239010586
[Epoch 21, Batch 1800] loss: 0.003823908793283408
[Epoch 21, Batch 1900] loss: 0.0038603831603563777
[Epoch 21, Batch 2000] loss: 0.003992522691555677
[Epoch 21, Batch 2100] loss: 0.0038361522664035873
[Epoch 21, Batch 2200] loss: 0.01065875701715413
[Epoch 21, Batch 2300] loss: 0.015271361103791604
[Epoch 21, Batch 2400] loss: 0.0049022913538578905
[Epoch 21, Batch 2500] loss: 0.016111967658075627
[Epoch 21, Batch 2600] loss: 0.014421011320391698
[Epoch 21, Batch 2700] loss: 0.01165478992717908
[Epoch 21, Batch 2800] loss: 0.014561652090660572
[Epoch 21, Batch 2900] loss: 0.01050969657026883
[Epoch 21, Batch 3000] loss: 0.007342781589306924
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9876
Overfitting: 0.0437
[Epoch 22, Batch 100] loss: 0.004747888982551558
[Epoch 22, Batch 200] loss: 0.00773461012606731
[Epoch 22, Batch 300] loss: 0.015608192512554525
[Epoch 22, Batch 400] loss: 0.007827652323057918
[Epoch 22, Batch 500] loss: 0.007401677517307235
[Epoch 22, Batch 600] loss: 0.009109788700727676
[Epoch 22, Batch 700] loss: 0.00491937415637949
[Epoch 22, Batch 800] loss: 0.013787166252786847
[Epoch 22, Batch 900] loss: 0.004622370989839055
[Epoch 22, Batch 1000] loss: 0.0042769151330685415
[Epoch 22, Batch 1100] loss: 0.008394936021045397
[Epoch 22, Batch 1200] loss: 0.011600165519346319
[Epoch 22, Batch 1300] loss: 0.009992450621230092
[Epoch 22, Batch 1400] loss: 0.007477729055299278
[Epoch 22, Batch 1500] loss: 0.007356342473947279
[Epoch 22, Batch 1600] loss: 0.0066189996204548155
[Epoch 22, Batch 1700] loss: 0.011468412521600158
[Epoch 22, Batch 1800] loss: 0.008449578616364306
[Epoch 22, Batch 1900] loss: 0.00965422309423957
[Epoch 22, Batch 2000] loss: 0.008722853914150619
[Epoch 22, Batch 2100] loss: 0.0069461538753694185
[Epoch 22, Batch 2200] loss: 0.010635919064595782
[Epoch 22, Batch 2300] loss: 0.007829078208221745
[Epoch 22, Batch 2400] loss: 0.011649607097799048
[Epoch 22, Batch 2500] loss: 0.01425886123894088
[Epoch 22, Batch 2600] loss: 0.008909325390405912
[Epoch 22, Batch 2700] loss: 0.01195814087900544
[Epoch 22, Batch 2800] loss: 0.014174447565628724
[Epoch 22, Batch 2900] loss: 0.00455274335300146
[Epoch 22, Batch 3000] loss: 0.011183637825151891
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9866
Overfitting: 0.0481
[Epoch 23, Batch 100] loss: 0.009865560453081344
[Epoch 23, Batch 200] loss: 0.004671602750147485
[Epoch 23, Batch 300] loss: 0.0054151832563911735
[Epoch 23, Batch 400] loss: 0.017328717053078434
[Epoch 23, Batch 500] loss: 0.003234911432109584
[Epoch 23, Batch 600] loss: 0.00829114717883158
[Epoch 23, Batch 700] loss: 0.007225912636795328
[Epoch 23, Batch 800] loss: 0.006107421009701284
[Epoch 23, Batch 900] loss: 0.0036232437697026397
[Epoch 23, Batch 1000] loss: 0.006681382763326837
[Epoch 23, Batch 1100] loss: 0.010275364966426536
[Epoch 23, Batch 1200] loss: 0.016325135195525035
[Epoch 23, Batch 1300] loss: 0.006905662718536405
[Epoch 23, Batch 1400] loss: 0.008676488700268692
[Epoch 23, Batch 1500] loss: 0.011134677836089395
[Epoch 23, Batch 1600] loss: 0.008775737519947598
[Epoch 23, Batch 1700] loss: 0.00666366160357029
[Epoch 23, Batch 1800] loss: 0.013222155325820495
[Epoch 23, Batch 1900] loss: 0.007225379175174566
[Epoch 23, Batch 2000] loss: 0.005321729068341483
[Epoch 23, Batch 2100] loss: 0.009886607936891778
[Epoch 23, Batch 2200] loss: 0.007516676883960826
[Epoch 23, Batch 2300] loss: 0.0053873256227007
[Epoch 23, Batch 2400] loss: 0.00971366878745485
[Epoch 23, Batch 2500] loss: 0.006302872240172519
[Epoch 23, Batch 2600] loss: 0.0043927181258243304
[Epoch 23, Batch 2700] loss: 0.013573093203933694
[Epoch 23, Batch 2800] loss: 0.005930422175033527
[Epoch 23, Batch 2900] loss: 0.01195219951796389
[Epoch 23, Batch 3000] loss: 0.007717308705568939
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0400
Validation Accuracy: 0.9890
Overfitting: 0.0400
[Epoch 24, Batch 100] loss: 0.002863059281585265
[Epoch 24, Batch 200] loss: 0.008375461903306132
[Epoch 24, Batch 300] loss: 0.004660934065245783
[Epoch 24, Batch 400] loss: 0.006597318458352106
[Epoch 24, Batch 500] loss: 0.004831219623233665
[Epoch 24, Batch 600] loss: 0.008562747856210536
[Epoch 24, Batch 700] loss: 0.007609125056284256
[Epoch 24, Batch 800] loss: 0.00575968857760472
[Epoch 24, Batch 900] loss: 0.006606130411219055
[Epoch 24, Batch 1000] loss: 0.006082282515205861
[Epoch 24, Batch 1100] loss: 0.008070419566308829
[Epoch 24, Batch 1200] loss: 0.007352353638398199
[Epoch 24, Batch 1300] loss: 0.003149335184548363
[Epoch 24, Batch 1400] loss: 0.008525771832604506
[Epoch 24, Batch 1500] loss: 0.004577269416190574
[Epoch 24, Batch 1600] loss: 0.006076550535606202
[Epoch 24, Batch 1700] loss: 0.00551266493510866
[Epoch 24, Batch 1800] loss: 0.003989858892516622
[Epoch 24, Batch 1900] loss: 0.0029778311755035247
[Epoch 24, Batch 2000] loss: 0.009189353811480032
[Epoch 24, Batch 2100] loss: 0.008884956191777746
[Epoch 24, Batch 2200] loss: 0.01581720777627197
[Epoch 24, Batch 2300] loss: 0.007076720136424229
[Epoch 24, Batch 2400] loss: 0.009899262046728837
[Epoch 24, Batch 2500] loss: 0.00604059357440292
[Epoch 24, Batch 2600] loss: 0.009105890144519435
[Epoch 24, Batch 2700] loss: 0.0078198676248212
[Epoch 24, Batch 2800] loss: 0.007735137053400649
[Epoch 24, Batch 2900] loss: 0.004238820658952136
[Epoch 24, Batch 3000] loss: 0.004745324508168949
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9879
Overfitting: 0.0471
Fold 5 validation loss: 0.0471
Mean validation loss across all folds for Trial 14 is 0.0514 with trial config:  l1: 256, l2: 128, lr: 0.0005688161395509089, batch_size: 16
[I 2024-12-10 08:22:39,435] Trial 13 finished with value: 0.05138641223125506 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0005688161395509089, 'batch_size': 16}. Best is trial 4 with value: 0.046893630782967134.

Selected Hyperparameters for Trial 15:
  l1: 128, l2: 64, lr: 0.000545723813546676, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.298508574962616
**STATS for Epoch 1** : 
Average training loss: 1.0713
Average validation loss: 2.2831
Validation Accuracy: 0.1620
Overfitting: 1.2117
Best model saved at epoch 1 with validation loss: 2.2831
[Epoch 2, Batch 100] loss: 2.27482444524765
**STATS for Epoch 2** : 
Average training loss: 1.0551
Average validation loss: 2.2360
Validation Accuracy: 0.2663
Overfitting: 1.1809
Best model saved at epoch 2 with validation loss: 2.2360
[Epoch 3, Batch 100] loss: 2.206631395816803
**STATS for Epoch 3** : 
Average training loss: 0.9758
Average validation loss: 1.9671
Validation Accuracy: 0.4953
Overfitting: 0.9913
Best model saved at epoch 3 with validation loss: 1.9671
[Epoch 4, Batch 100] loss: 1.7161759221553803
**STATS for Epoch 4** : 
Average training loss: 0.5003
Average validation loss: 0.8110
Validation Accuracy: 0.7880
Overfitting: 0.3107
Best model saved at epoch 4 with validation loss: 0.8110
[Epoch 5, Batch 100] loss: 0.688755815923214
**STATS for Epoch 5** : 
Average training loss: 0.2563
Average validation loss: 0.4880
Validation Accuracy: 0.8609
Overfitting: 0.2317
Best model saved at epoch 5 with validation loss: 0.4880
[Epoch 6, Batch 100] loss: 0.4802743598818779
**STATS for Epoch 6** : 
Average training loss: 0.2068
Average validation loss: 0.3996
Validation Accuracy: 0.8842
Overfitting: 0.1928
[I 2024-12-10 08:23:32,187] Trial 14 pruned. 

Selected Hyperparameters for Trial 16:
  l1: 128, l2: 64, lr: 0.001524205108202716, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2902717757225037
[Epoch 1, Batch 200] loss: 2.175381385087967
[Epoch 1, Batch 300] loss: 1.3745776265859604
[Epoch 1, Batch 400] loss: 0.686255342811346
[Epoch 1, Batch 500] loss: 0.4739497745782137
[Epoch 1, Batch 600] loss: 0.40128341257572175
[Epoch 1, Batch 700] loss: 0.37315052770078183
[Epoch 1, Batch 800] loss: 0.2940946648642421
[Epoch 1, Batch 900] loss: 0.2576964428368956
[Epoch 1, Batch 1000] loss: 0.2514467907696962
[Epoch 1, Batch 1100] loss: 0.2121865033917129
[Epoch 1, Batch 1200] loss: 0.22846158672124148
[Epoch 1, Batch 1300] loss: 0.21134397277608513
[Epoch 1, Batch 1400] loss: 0.1892693920992315
[Epoch 1, Batch 1500] loss: 0.1727605993207544
[Epoch 1, Batch 1600] loss: 0.1498704855516553
[Epoch 1, Batch 1700] loss: 0.19392293341457845
[Epoch 1, Batch 1800] loss: 0.163630602392368
[Epoch 1, Batch 1900] loss: 0.14165755365975202
[Epoch 1, Batch 2000] loss: 0.1705922951316461
[Epoch 1, Batch 2100] loss: 0.1390282262628898
[Epoch 1, Batch 2200] loss: 0.13938270149752496
[Epoch 1, Batch 2300] loss: 0.1214583071647212
[Epoch 1, Batch 2400] loss: 0.12103714028373361
[Epoch 1, Batch 2500] loss: 0.12880637800786643
[Epoch 1, Batch 2600] loss: 0.16035214598290623
[Epoch 1, Batch 2700] loss: 0.1280842337431386
[Epoch 1, Batch 2800] loss: 0.1178475119988434
[Epoch 1, Batch 2900] loss: 0.11540557759813964
[Epoch 1, Batch 3000] loss: 0.10993912527454086
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1244
Validation Accuracy: 0.9598
Overfitting: 0.1244
Best model saved at epoch 1 with validation loss: 0.1244
[Epoch 2, Batch 100] loss: 0.12497210784349591
[Epoch 2, Batch 200] loss: 0.08428219142719172
[Epoch 2, Batch 300] loss: 0.09086570460814983
[Epoch 2, Batch 400] loss: 0.09667860201559961
[Epoch 2, Batch 500] loss: 0.10833023409126326
[Epoch 2, Batch 600] loss: 0.0889591187844053
[Epoch 2, Batch 700] loss: 0.09745615398045629
[Epoch 2, Batch 800] loss: 0.09743272930732928
[Epoch 2, Batch 900] loss: 0.1187193922768347
[Epoch 2, Batch 1000] loss: 0.11365806750021874
[Epoch 2, Batch 1100] loss: 0.09866793453576975
[Epoch 2, Batch 1200] loss: 0.10916900252457708
[Epoch 2, Batch 1300] loss: 0.06727848539478146
[Epoch 2, Batch 1400] loss: 0.08797931131441146
[Epoch 2, Batch 1500] loss: 0.07127316017169505
[Epoch 2, Batch 1600] loss: 0.09127392447553576
[Epoch 2, Batch 1700] loss: 0.06833742573158816
[Epoch 2, Batch 1800] loss: 0.06406494099705014
[Epoch 2, Batch 1900] loss: 0.07836447345558555
[Epoch 2, Batch 2000] loss: 0.08084983502194518
[Epoch 2, Batch 2100] loss: 0.07585672715096735
[Epoch 2, Batch 2200] loss: 0.09367898527591023
[Epoch 2, Batch 2300] loss: 0.06911007254966535
[Epoch 2, Batch 2400] loss: 0.09322227668773848
[Epoch 2, Batch 2500] loss: 0.06441505013790447
[Epoch 2, Batch 2600] loss: 0.08611675380263478
[Epoch 2, Batch 2700] loss: 0.07670044135535135
[Epoch 2, Batch 2800] loss: 0.10725550956311053
[Epoch 2, Batch 2900] loss: 0.08426632101880387
[Epoch 2, Batch 3000] loss: 0.07169125579297543
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0696
Validation Accuracy: 0.9784
Overfitting: 0.0696
Best model saved at epoch 2 with validation loss: 0.0696
[Epoch 3, Batch 100] loss: 0.07765622648817953
[Epoch 3, Batch 200] loss: 0.050288303564302625
[Epoch 3, Batch 300] loss: 0.06255030310945585
[Epoch 3, Batch 400] loss: 0.0882230591296684
[Epoch 3, Batch 500] loss: 0.06492927111685276
[Epoch 3, Batch 600] loss: 0.05010603628994431
[Epoch 3, Batch 700] loss: 0.06925458374433219
[Epoch 3, Batch 800] loss: 0.05796123011154122
[Epoch 3, Batch 900] loss: 0.06101829491555691
[Epoch 3, Batch 1000] loss: 0.0430273251113249
[Epoch 3, Batch 1100] loss: 0.06812347095343284
[Epoch 3, Batch 1200] loss: 0.07889965853886678
[Epoch 3, Batch 1300] loss: 0.05260136257391423
[Epoch 3, Batch 1400] loss: 0.06886689743143506
[Epoch 3, Batch 1500] loss: 0.06561606088740518
[Epoch 3, Batch 1600] loss: 0.0610969695384847
[Epoch 3, Batch 1700] loss: 0.041378317101916764
[Epoch 3, Batch 1800] loss: 0.05998953643022105
[Epoch 3, Batch 1900] loss: 0.05156565256867907
[Epoch 3, Batch 2000] loss: 0.05309680563339498
[Epoch 3, Batch 2100] loss: 0.08784481144335586
[Epoch 3, Batch 2200] loss: 0.05155268814502051
[Epoch 3, Batch 2300] loss: 0.05271266325493343
[Epoch 3, Batch 2400] loss: 0.07469719108194113
[Epoch 3, Batch 2500] loss: 0.0540832199115539
[Epoch 3, Batch 2600] loss: 0.03896820150956046
[Epoch 3, Batch 2700] loss: 0.05523729930922855
[Epoch 3, Batch 2800] loss: 0.05527725806372473
[Epoch 3, Batch 2900] loss: 0.05727106502163224
[Epoch 3, Batch 3000] loss: 0.07026543246523943
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0721
Validation Accuracy: 0.9777
Overfitting: 0.0721
[Epoch 4, Batch 100] loss: 0.04057497428875649
[Epoch 4, Batch 200] loss: 0.05221194042067509
[Epoch 4, Batch 300] loss: 0.062379130367189645
[Epoch 4, Batch 400] loss: 0.0423174557738821
[Epoch 4, Batch 500] loss: 0.03977263440494425
[Epoch 4, Batch 600] loss: 0.049066428021615136
[Epoch 4, Batch 700] loss: 0.05318839192346786
[Epoch 4, Batch 800] loss: 0.061156807362422114
[Epoch 4, Batch 900] loss: 0.043940617606858724
[Epoch 4, Batch 1000] loss: 0.04139481784033706
[Epoch 4, Batch 1100] loss: 0.050799422936106564
[Epoch 4, Batch 1200] loss: 0.04335559648345225
[Epoch 4, Batch 1300] loss: 0.06393940276611829
[Epoch 4, Batch 1400] loss: 0.05052978292718763
[Epoch 4, Batch 1500] loss: 0.054733902405714616
[Epoch 4, Batch 1600] loss: 0.056961505299550484
[Epoch 4, Batch 1700] loss: 0.05477031509100925
[Epoch 4, Batch 1800] loss: 0.03014498955279123
[Epoch 4, Batch 1900] loss: 0.05052865566918627
[Epoch 4, Batch 2000] loss: 0.04382991622202098
[Epoch 4, Batch 2100] loss: 0.04624333469124395
[Epoch 4, Batch 2200] loss: 0.04793833423347678
[Epoch 4, Batch 2300] loss: 0.04329183367270161
[Epoch 4, Batch 2400] loss: 0.05067888311081333
[Epoch 4, Batch 2500] loss: 0.05339358835888561
[Epoch 4, Batch 2600] loss: 0.039111525562475435
[Epoch 4, Batch 2700] loss: 0.03743851413251832
[Epoch 4, Batch 2800] loss: 0.06422510591815808
[Epoch 4, Batch 2900] loss: 0.04448223693209002
[Epoch 4, Batch 3000] loss: 0.03979321365331998
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0724
Validation Accuracy: 0.9782
Overfitting: 0.0724
[Epoch 5, Batch 100] loss: 0.03799925021317904
[Epoch 5, Batch 200] loss: 0.035964574504760094
[Epoch 5, Batch 300] loss: 0.036660563353652836
[Epoch 5, Batch 400] loss: 0.046729981981043237
[Epoch 5, Batch 500] loss: 0.025942204848397522
[Epoch 5, Batch 600] loss: 0.03082242365981074
[Epoch 5, Batch 700] loss: 0.05034943916652992
[Epoch 5, Batch 800] loss: 0.043496192388265624
[Epoch 5, Batch 900] loss: 0.034059891472570596
[Epoch 5, Batch 1000] loss: 0.03994303788538673
[Epoch 5, Batch 1100] loss: 0.038875322802050506
[Epoch 5, Batch 1200] loss: 0.03213902016839711
[Epoch 5, Batch 1300] loss: 0.039912899605114946
[Epoch 5, Batch 1400] loss: 0.04194546385311696
[Epoch 5, Batch 1500] loss: 0.03890436790898093
[Epoch 5, Batch 1600] loss: 0.04684397943034128
[Epoch 5, Batch 1700] loss: 0.037050460528116676
[Epoch 5, Batch 1800] loss: 0.029763080547272693
[Epoch 5, Batch 1900] loss: 0.03113505575391173
[Epoch 5, Batch 2000] loss: 0.04731085833584075
[Epoch 5, Batch 2100] loss: 0.034674573093889195
[Epoch 5, Batch 2200] loss: 0.050387549965962536
[Epoch 5, Batch 2300] loss: 0.03171667771530338
[Epoch 5, Batch 2400] loss: 0.04652039676388085
[Epoch 5, Batch 2500] loss: 0.05389301771625469
[Epoch 5, Batch 2600] loss: 0.05308693997925729
[Epoch 5, Batch 2700] loss: 0.03217566485560383
[Epoch 5, Batch 2800] loss: 0.03362724173170136
[Epoch 5, Batch 2900] loss: 0.03448368650082557
[Epoch 5, Batch 3000] loss: 0.047197300411498874
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9828
Overfitting: 0.0549
Best model saved at epoch 5 with validation loss: 0.0549
[Epoch 6, Batch 100] loss: 0.027672564833046635
[Epoch 6, Batch 200] loss: 0.029139145455119433
[Epoch 6, Batch 300] loss: 0.023446023418655385
[Epoch 6, Batch 400] loss: 0.03575784743006807
[Epoch 6, Batch 500] loss: 0.034070337633311285
[Epoch 6, Batch 600] loss: 0.032385251615924066
[Epoch 6, Batch 700] loss: 0.027142646020529355
[Epoch 6, Batch 800] loss: 0.03228487060288899
[Epoch 6, Batch 900] loss: 0.04151945328194415
[Epoch 6, Batch 1000] loss: 0.04108706121580326
[Epoch 6, Batch 1100] loss: 0.04477846638299525
[Epoch 6, Batch 1200] loss: 0.03622264566234662
[Epoch 6, Batch 1300] loss: 0.033075523856678044
[Epoch 6, Batch 1400] loss: 0.03867989772930741
[Epoch 6, Batch 1500] loss: 0.03130591506662313
[Epoch 6, Batch 1600] loss: 0.03104098104216973
[Epoch 6, Batch 1700] loss: 0.03787867088405619
[Epoch 6, Batch 1800] loss: 0.03220227278070524
[Epoch 6, Batch 1900] loss: 0.052823784091960986
[Epoch 6, Batch 2000] loss: 0.022542909228504868
[Epoch 6, Batch 2100] loss: 0.03436132360257034
[Epoch 6, Batch 2200] loss: 0.03495140893079224
[Epoch 6, Batch 2300] loss: 0.02491326700517675
[Epoch 6, Batch 2400] loss: 0.0364330132320174
[Epoch 6, Batch 2500] loss: 0.02846481094333285
[Epoch 6, Batch 2600] loss: 0.02973436935346399
[Epoch 6, Batch 2700] loss: 0.0274995338323788
[Epoch 6, Batch 2800] loss: 0.03413476152025396
[Epoch 6, Batch 2900] loss: 0.023597402643208625
[Epoch 6, Batch 3000] loss: 0.021465023668260984
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9831
Overfitting: 0.0533
Best model saved at epoch 6 with validation loss: 0.0533
[Epoch 7, Batch 100] loss: 0.036199560239329
[Epoch 7, Batch 200] loss: 0.03176755546039203
[Epoch 7, Batch 300] loss: 0.032526855057367354
[Epoch 7, Batch 400] loss: 0.016447798956141922
[Epoch 7, Batch 500] loss: 0.020758241660150816
[Epoch 7, Batch 600] loss: 0.034860420719669494
[Epoch 7, Batch 700] loss: 0.02593560960754985
[Epoch 7, Batch 800] loss: 0.014272088324432844
[Epoch 7, Batch 900] loss: 0.03504170411473751
[Epoch 7, Batch 1000] loss: 0.027073834504553817
[Epoch 7, Batch 1100] loss: 0.03140198188877548
[Epoch 7, Batch 1200] loss: 0.02360200588591397
[Epoch 7, Batch 1300] loss: 0.03270610384301108
[Epoch 7, Batch 1400] loss: 0.0237618703985936
[Epoch 7, Batch 1500] loss: 0.04437282643401886
[Epoch 7, Batch 1600] loss: 0.02465368082121131
[Epoch 7, Batch 1700] loss: 0.01675756687989633
[Epoch 7, Batch 1800] loss: 0.009988486801012187
[Epoch 7, Batch 1900] loss: 0.02648967409971192
[Epoch 7, Batch 2000] loss: 0.034402409283102314
[Epoch 7, Batch 2100] loss: 0.03086026030643552
[Epoch 7, Batch 2200] loss: 0.036468182651697136
[Epoch 7, Batch 2300] loss: 0.03309643158198014
[Epoch 7, Batch 2400] loss: 0.021691788099706174
[Epoch 7, Batch 2500] loss: 0.03495415724381019
[Epoch 7, Batch 2600] loss: 0.03111723411726416
[Epoch 7, Batch 2700] loss: 0.034395458577582756
[Epoch 7, Batch 2800] loss: 0.033573908468242736
[Epoch 7, Batch 2900] loss: 0.02603006750341592
[Epoch 7, Batch 3000] loss: 0.03986435647631879
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9848
Overfitting: 0.0468
Best model saved at epoch 7 with validation loss: 0.0468
[Epoch 8, Batch 100] loss: 0.026256378635735017
[Epoch 8, Batch 200] loss: 0.021494173241881073
[Epoch 8, Batch 300] loss: 0.021645187832182274
[Epoch 8, Batch 400] loss: 0.012606541873174138
[Epoch 8, Batch 500] loss: 0.023963528305139335
[Epoch 8, Batch 600] loss: 0.0161469664618744
[Epoch 8, Batch 700] loss: 0.025379057788322824
[Epoch 8, Batch 800] loss: 0.026658586151643248
[Epoch 8, Batch 900] loss: 0.010746818192892534
[Epoch 8, Batch 1000] loss: 0.02852035714427984
[Epoch 8, Batch 1100] loss: 0.03265194512401649
[Epoch 8, Batch 1200] loss: 0.02591022049109597
[Epoch 8, Batch 1300] loss: 0.02637633738997465
[Epoch 8, Batch 1400] loss: 0.026317049226781818
[Epoch 8, Batch 1500] loss: 0.0214415766010643
[Epoch 8, Batch 1600] loss: 0.022399662654529494
[Epoch 8, Batch 1700] loss: 0.039322335197357464
[Epoch 8, Batch 1800] loss: 0.026209719202233826
[Epoch 8, Batch 1900] loss: 0.037665115295894794
[Epoch 8, Batch 2000] loss: 0.021937171184945328
[Epoch 8, Batch 2100] loss: 0.03132988957757334
[Epoch 8, Batch 2200] loss: 0.03550090624914446
[Epoch 8, Batch 2300] loss: 0.023269624110762378
[Epoch 8, Batch 2400] loss: 0.03314095107902176
[Epoch 8, Batch 2500] loss: 0.032042328468160124
[Epoch 8, Batch 2600] loss: 0.027996361578589132
[Epoch 8, Batch 2700] loss: 0.03276362076838268
[Epoch 8, Batch 2800] loss: 0.027302262384255302
[Epoch 8, Batch 2900] loss: 0.026698519424462573
[Epoch 8, Batch 3000] loss: 0.02423215691553196
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9873
Overfitting: 0.0447
Best model saved at epoch 8 with validation loss: 0.0447
[Epoch 9, Batch 100] loss: 0.023435158994725497
[Epoch 9, Batch 200] loss: 0.011990502298576757
[Epoch 9, Batch 300] loss: 0.016110984660590476
[Epoch 9, Batch 400] loss: 0.02265135271489271
[Epoch 9, Batch 500] loss: 0.017579650383304397
[Epoch 9, Batch 600] loss: 0.01626127855046434
[Epoch 9, Batch 700] loss: 0.03112179681300404
[Epoch 9, Batch 800] loss: 0.034504248782750435
[Epoch 9, Batch 900] loss: 0.02683445341221159
[Epoch 9, Batch 1000] loss: 0.023281209540873534
[Epoch 9, Batch 1100] loss: 0.016306474167331542
[Epoch 9, Batch 1200] loss: 0.012816575513697899
[Epoch 9, Batch 1300] loss: 0.014529750300571322
[Epoch 9, Batch 1400] loss: 0.03588671702400461
[Epoch 9, Batch 1500] loss: 0.011875670318368066
[Epoch 9, Batch 1600] loss: 0.02757897143754235
[Epoch 9, Batch 1700] loss: 0.026607596868452675
[Epoch 9, Batch 1800] loss: 0.025834119894170726
[Epoch 9, Batch 1900] loss: 0.026579163556798447
[Epoch 9, Batch 2000] loss: 0.028811561453621834
[Epoch 9, Batch 2100] loss: 0.03610567136744067
[Epoch 9, Batch 2200] loss: 0.02245983690889261
[Epoch 9, Batch 2300] loss: 0.01365364899922497
[Epoch 9, Batch 2400] loss: 0.018300150506498768
[Epoch 9, Batch 2500] loss: 0.019255426010040537
[Epoch 9, Batch 2600] loss: 0.020111636027795612
[Epoch 9, Batch 2700] loss: 0.02518070359197736
[Epoch 9, Batch 2800] loss: 0.03473255812737989
[Epoch 9, Batch 2900] loss: 0.028717012163433538
[Epoch 9, Batch 3000] loss: 0.018614517715504916
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9863
Overfitting: 0.0472
[Epoch 10, Batch 100] loss: 0.009750597501933952
[Epoch 10, Batch 200] loss: 0.023417540003374596
[Epoch 10, Batch 300] loss: 0.014234044172044378
[Epoch 10, Batch 400] loss: 0.012671303895040183
[Epoch 10, Batch 500] loss: 0.022010342483554268
[Epoch 10, Batch 600] loss: 0.013232017038353661
[Epoch 10, Batch 700] loss: 0.017652972001233138
[Epoch 10, Batch 800] loss: 0.018364966500721492
[Epoch 10, Batch 900] loss: 0.020312627414405142
[Epoch 10, Batch 1000] loss: 0.018228195723677346
[Epoch 10, Batch 1100] loss: 0.014726271257659391
[Epoch 10, Batch 1200] loss: 0.03185787592714405
[Epoch 10, Batch 1300] loss: 0.014557358025158465
[Epoch 10, Batch 1400] loss: 0.01515645292631234
[Epoch 10, Batch 1500] loss: 0.016328083085591062
[Epoch 10, Batch 1600] loss: 0.01697357534580988
[Epoch 10, Batch 1700] loss: 0.021716314813493228
[Epoch 10, Batch 1800] loss: 0.01948042185435952
[Epoch 10, Batch 1900] loss: 0.013464192937663029
[Epoch 10, Batch 2000] loss: 0.021815485538936627
[Epoch 10, Batch 2100] loss: 0.01968583754791325
[Epoch 10, Batch 2200] loss: 0.017991082000080497
[Epoch 10, Batch 2300] loss: 0.013264303728083177
[Epoch 10, Batch 2400] loss: 0.017622387075061852
[Epoch 10, Batch 2500] loss: 0.019511255094503212
[Epoch 10, Batch 2600] loss: 0.027777135203396027
[Epoch 10, Batch 2700] loss: 0.02513771724208709
[Epoch 10, Batch 2800] loss: 0.03230762786923151
[Epoch 10, Batch 2900] loss: 0.0273424197813074
[Epoch 10, Batch 3000] loss: 0.025548333746883145
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9850
Overfitting: 0.0512
[Epoch 11, Batch 100] loss: 0.011086965837312163
[Epoch 11, Batch 200] loss: 0.010953462561237757
[Epoch 11, Batch 300] loss: 0.012990486858807344
[Epoch 11, Batch 400] loss: 0.01715806793302363
[Epoch 11, Batch 500] loss: 0.01219999588913197
[Epoch 11, Batch 600] loss: 0.0168469065523459
[Epoch 11, Batch 700] loss: 0.01599397374468026
[Epoch 11, Batch 800] loss: 0.019279590049395664
[Epoch 11, Batch 900] loss: 0.014721824611879129
[Epoch 11, Batch 1000] loss: 0.014224647732189623
[Epoch 11, Batch 1100] loss: 0.027445327735222236
[Epoch 11, Batch 1200] loss: 0.015416986792588431
[Epoch 11, Batch 1300] loss: 0.016376930789338075
[Epoch 11, Batch 1400] loss: 0.014794329027899948
[Epoch 11, Batch 1500] loss: 0.014330785808397195
[Epoch 11, Batch 1600] loss: 0.016766947504347627
[Epoch 11, Batch 1700] loss: 0.01120591292633435
[Epoch 11, Batch 1800] loss: 0.015398776491665558
[Epoch 11, Batch 1900] loss: 0.01536398542955112
[Epoch 11, Batch 2000] loss: 0.01521477849751136
[Epoch 11, Batch 2100] loss: 0.013234504705023938
[Epoch 11, Batch 2200] loss: 0.016657314252952346
[Epoch 11, Batch 2300] loss: 0.015381272581223585
[Epoch 11, Batch 2400] loss: 0.0312986479266965
[Epoch 11, Batch 2500] loss: 0.013418642954948155
[Epoch 11, Batch 2600] loss: 0.021726945345639025
[Epoch 11, Batch 2700] loss: 0.01863869544885347
[Epoch 11, Batch 2800] loss: 0.00993839764076256
[Epoch 11, Batch 2900] loss: 0.012073632368517337
[Epoch 11, Batch 3000] loss: 0.013593664674051525
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9869
Overfitting: 0.0464
[Epoch 12, Batch 100] loss: 0.01471324114586423
[Epoch 12, Batch 200] loss: 0.013613550654808933
[Epoch 12, Batch 300] loss: 0.00996113587927539
[Epoch 12, Batch 400] loss: 0.019392144695457317
[Epoch 12, Batch 500] loss: 0.03171002079405298
[Epoch 12, Batch 600] loss: 0.016996392272121737
[Epoch 12, Batch 700] loss: 0.007759297709287694
[Epoch 12, Batch 800] loss: 0.010654217034916655
[Epoch 12, Batch 900] loss: 0.017787236561784995
[Epoch 12, Batch 1000] loss: 0.010797033499625287
[Epoch 12, Batch 1100] loss: 0.007575259347880774
[Epoch 12, Batch 1200] loss: 0.010148445373056347
[Epoch 12, Batch 1300] loss: 0.01036687068959509
[Epoch 12, Batch 1400] loss: 0.015070859972297512
[Epoch 12, Batch 1500] loss: 0.007453076264416154
[Epoch 12, Batch 1600] loss: 0.008892829925230217
[Epoch 12, Batch 1700] loss: 0.018850319704731645
[Epoch 12, Batch 1800] loss: 0.015335543790062047
[Epoch 12, Batch 1900] loss: 0.015897869889577122
[Epoch 12, Batch 2000] loss: 0.007102655003686778
[Epoch 12, Batch 2100] loss: 0.016828324950283788
[Epoch 12, Batch 2200] loss: 0.02378703160584337
[Epoch 12, Batch 2300] loss: 0.01683270495351735
[Epoch 12, Batch 2400] loss: 0.018453962784842588
[Epoch 12, Batch 2500] loss: 0.011480171550683736
[Epoch 12, Batch 2600] loss: 0.007243331953313828
[Epoch 12, Batch 2700] loss: 0.014091449638340237
[Epoch 12, Batch 2800] loss: 0.01876716515771932
[Epoch 12, Batch 2900] loss: 0.010737023238434631
[Epoch 12, Batch 3000] loss: 0.008384603624222109
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9851
Overfitting: 0.0564
[Epoch 13, Batch 100] loss: 0.008428424279907176
[Epoch 13, Batch 200] loss: 0.021605639555348263
[Epoch 13, Batch 300] loss: 0.003930118567345744
[Epoch 13, Batch 400] loss: 0.013413289478041861
[Epoch 13, Batch 500] loss: 0.009652957023995441
[Epoch 13, Batch 600] loss: 0.014056594855560434
[Epoch 13, Batch 700] loss: 0.00973820072303738
[Epoch 13, Batch 800] loss: 0.016247229823143243
[Epoch 13, Batch 900] loss: 0.010276343931282099
[Epoch 13, Batch 1000] loss: 0.007108076955353227
[Epoch 13, Batch 1100] loss: 0.010885409343199513
[Epoch 13, Batch 1200] loss: 0.020475993530251913
[Epoch 13, Batch 1300] loss: 0.007121183405674855
[Epoch 13, Batch 1400] loss: 0.018795162629248807
[Epoch 13, Batch 1500] loss: 0.01007306412348953
[Epoch 13, Batch 1600] loss: 0.009045513745331846
[Epoch 13, Batch 1700] loss: 0.021443752655562774
[Epoch 13, Batch 1800] loss: 0.010128726700577318
[Epoch 13, Batch 1900] loss: 0.01037082169231553
[Epoch 13, Batch 2000] loss: 0.020870100493616518
[Epoch 13, Batch 2100] loss: 0.008936704100219685
[Epoch 13, Batch 2200] loss: 0.02885186538853759
[Epoch 13, Batch 2300] loss: 0.01531108806821976
[Epoch 13, Batch 2400] loss: 0.011200223719924907
[Epoch 13, Batch 2500] loss: 0.011808825291795983
[Epoch 13, Batch 2600] loss: 0.016765178418884263
[Epoch 13, Batch 2700] loss: 0.01544043621368246
[Epoch 13, Batch 2800] loss: 0.005242539801743078
[Epoch 13, Batch 2900] loss: 0.01512084560796211
[Epoch 13, Batch 3000] loss: 0.01361421859134225
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9845
Overfitting: 0.0556
[Epoch 14, Batch 100] loss: 0.01344649964803466
[Epoch 14, Batch 200] loss: 0.010457091823677728
[Epoch 14, Batch 300] loss: 0.007247201235202283
[Epoch 14, Batch 400] loss: 0.006764000085640873
[Epoch 14, Batch 500] loss: 0.014585119760608905
[Epoch 14, Batch 600] loss: 0.007776395835063568
[Epoch 14, Batch 700] loss: 0.012238068433443914
[Epoch 14, Batch 800] loss: 0.013197475532515456
[Epoch 14, Batch 900] loss: 0.016201263692090323
[Epoch 14, Batch 1000] loss: 0.008098939737908494
[Epoch 14, Batch 1100] loss: 0.009542790615287232
[Epoch 14, Batch 1200] loss: 0.0038823076292214863
[Epoch 14, Batch 1300] loss: 0.004330363230186549
[Epoch 14, Batch 1400] loss: 0.010209716712196268
[Epoch 14, Batch 1500] loss: 0.011414299624684645
[Epoch 14, Batch 1600] loss: 0.009277464940851132
[Epoch 14, Batch 1700] loss: 0.003975156038980004
[Epoch 14, Batch 1800] loss: 0.006598990971783678
[Epoch 14, Batch 1900] loss: 0.010124681646025237
[Epoch 14, Batch 2000] loss: 0.011852755088953585
[Epoch 14, Batch 2100] loss: 0.008694149140363833
[Epoch 14, Batch 2200] loss: 0.016374044548268785
[Epoch 14, Batch 2300] loss: 0.009285721929149986
[Epoch 14, Batch 2400] loss: 0.01645363971703375
[Epoch 14, Batch 2500] loss: 0.030714726852547756
[Epoch 14, Batch 2600] loss: 0.010934275380823238
[Epoch 14, Batch 2700] loss: 0.009871990145564951
[Epoch 14, Batch 2800] loss: 0.0053145794348006346
[Epoch 14, Batch 2900] loss: 0.01707831252204187
[Epoch 14, Batch 3000] loss: 0.01846140133737208
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0488
Validation Accuracy: 0.9875
Overfitting: 0.0488
[Epoch 15, Batch 100] loss: 0.010036851234126516
[Epoch 15, Batch 200] loss: 0.0063991112711892124
[Epoch 15, Batch 300] loss: 0.00807932292010264
[Epoch 15, Batch 400] loss: 0.003129520656398199
[Epoch 15, Batch 500] loss: 0.003752172671749463
[Epoch 15, Batch 600] loss: 0.014277535796811663
[Epoch 15, Batch 700] loss: 0.006482489104698743
[Epoch 15, Batch 800] loss: 0.003943619531537479
[Epoch 15, Batch 900] loss: 0.0118098202786814
[Epoch 15, Batch 1000] loss: 0.012761358346685937
[Epoch 15, Batch 1100] loss: 0.008195085976121846
[Epoch 15, Batch 1200] loss: 0.011354379540121045
[Epoch 15, Batch 1300] loss: 0.004096426607139847
[Epoch 15, Batch 1400] loss: 0.006144641573637557
[Epoch 15, Batch 1500] loss: 0.007780697662663556
[Epoch 15, Batch 1600] loss: 0.005288343118959347
[Epoch 15, Batch 1700] loss: 0.01621863456814026
[Epoch 15, Batch 1800] loss: 0.012748447835399475
[Epoch 15, Batch 1900] loss: 0.0046885691301201855
[Epoch 15, Batch 2000] loss: 0.006651490247727452
[Epoch 15, Batch 2100] loss: 0.009534429023365192
[Epoch 15, Batch 2200] loss: 0.01063629069350526
[Epoch 15, Batch 2300] loss: 0.01153683318981109
[Epoch 15, Batch 2400] loss: 0.016020158939531584
[Epoch 15, Batch 2500] loss: 0.015563877327292062
[Epoch 15, Batch 2600] loss: 0.015578057265313987
[Epoch 15, Batch 2700] loss: 0.009065414592174647
[Epoch 15, Batch 2800] loss: 0.017785351241011115
[Epoch 15, Batch 2900] loss: 0.010833557722348815
[Epoch 15, Batch 3000] loss: 0.01009713564062622
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9872
Overfitting: 0.0513
[Epoch 16, Batch 100] loss: 0.005758136193194332
[Epoch 16, Batch 200] loss: 0.005984637030433077
[Epoch 16, Batch 300] loss: 0.005867488750084249
[Epoch 16, Batch 400] loss: 0.017583913094834997
[Epoch 16, Batch 500] loss: 0.006485781254543781
[Epoch 16, Batch 600] loss: 0.007399131427754355
[Epoch 16, Batch 700] loss: 0.004063593896657949
[Epoch 16, Batch 800] loss: 0.006693473814000868
[Epoch 16, Batch 900] loss: 0.009718450198706137
[Epoch 16, Batch 1000] loss: 0.004124090721317089
[Epoch 16, Batch 1100] loss: 0.008828160449082247
[Epoch 16, Batch 1200] loss: 0.01576743723556149
[Epoch 16, Batch 1300] loss: 0.0070392561521737205
[Epoch 16, Batch 1400] loss: 0.0075444072479888295
[Epoch 16, Batch 1500] loss: 0.012252518869166807
[Epoch 16, Batch 1600] loss: 0.014108399408017646
[Epoch 16, Batch 1700] loss: 0.01729337410677033
[Epoch 16, Batch 1800] loss: 0.011963749153275104
[Epoch 16, Batch 1900] loss: 0.0074471987414926845
[Epoch 16, Batch 2000] loss: 0.011735309946265033
[Epoch 16, Batch 2100] loss: 0.009879124148475284
[Epoch 16, Batch 2200] loss: 0.004270559492626376
[Epoch 16, Batch 2300] loss: 0.003792116707453488
[Epoch 16, Batch 2400] loss: 0.009157559494644545
[Epoch 16, Batch 2500] loss: 0.0047595697492067756
[Epoch 16, Batch 2600] loss: 0.0034966581626963487
[Epoch 16, Batch 2700] loss: 0.0050188201635444326
[Epoch 16, Batch 2800] loss: 0.006242284187100325
[Epoch 16, Batch 2900] loss: 0.007489444411602903
[Epoch 16, Batch 3000] loss: 0.011748090198259432
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0443
Validation Accuracy: 0.9886
Overfitting: 0.0443
Best model saved at epoch 16 with validation loss: 0.0443
[Epoch 17, Batch 100] loss: 0.0018407954458689345
[Epoch 17, Batch 200] loss: 0.0058857567292849924
[Epoch 17, Batch 300] loss: 0.0053002066577300866
[Epoch 17, Batch 400] loss: 0.001697510748440436
[Epoch 17, Batch 500] loss: 0.005386019240138218
[Epoch 17, Batch 600] loss: 0.003956718909873729
[Epoch 17, Batch 700] loss: 0.003587267761720767
[Epoch 17, Batch 800] loss: 0.013962877011235407
[Epoch 17, Batch 900] loss: 0.008897075174472776
[Epoch 17, Batch 1000] loss: 0.003240308219809265
[Epoch 17, Batch 1100] loss: 0.006400642492385486
[Epoch 17, Batch 1200] loss: 0.005046330756923112
[Epoch 17, Batch 1300] loss: 0.008868196881381749
[Epoch 17, Batch 1400] loss: 0.005544865931972254
[Epoch 17, Batch 1500] loss: 0.014559554072457672
[Epoch 17, Batch 1600] loss: 0.00882792179740818
[Epoch 17, Batch 1700] loss: 0.012865995900643697
[Epoch 17, Batch 1800] loss: 0.011233395258633436
[Epoch 17, Batch 1900] loss: 0.0032249225851546724
[Epoch 17, Batch 2000] loss: 0.006454409628707936
[Epoch 17, Batch 2100] loss: 0.005859191285098859
[Epoch 17, Batch 2200] loss: 0.010502293371910412
[Epoch 17, Batch 2300] loss: 0.008341385065252211
[Epoch 17, Batch 2400] loss: 0.003133765495891794
[Epoch 17, Batch 2500] loss: 0.01112005956187545
[Epoch 17, Batch 2600] loss: 0.008412984116818052
[Epoch 17, Batch 2700] loss: 0.009172735314274405
[Epoch 17, Batch 2800] loss: 0.003368935664165065
[Epoch 17, Batch 2900] loss: 0.0061709604914858395
[Epoch 17, Batch 3000] loss: 0.005181815059296468
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9873
Overfitting: 0.0516
[Epoch 18, Batch 100] loss: 0.0051167268612501
[Epoch 18, Batch 200] loss: 0.007729252140088363
[Epoch 18, Batch 300] loss: 0.0029932710296567675
[Epoch 18, Batch 400] loss: 0.0022421051472124986
[Epoch 18, Batch 500] loss: 0.003030799867018743
[Epoch 18, Batch 600] loss: 0.0030445889715561237
[Epoch 18, Batch 700] loss: 0.003438840954428315
[Epoch 18, Batch 800] loss: 0.007711659807981164
[Epoch 18, Batch 900] loss: 0.00281068010873355
[Epoch 18, Batch 1000] loss: 0.0070862222971959455
[Epoch 18, Batch 1100] loss: 0.005459959395872715
[Epoch 18, Batch 1200] loss: 0.005386024633132251
[Epoch 18, Batch 1300] loss: 0.005872634828851062
[Epoch 18, Batch 1400] loss: 0.005822975350392881
[Epoch 18, Batch 1500] loss: 0.003199925910084076
[Epoch 18, Batch 1600] loss: 0.0048322461209954785
[Epoch 18, Batch 1700] loss: 0.008562898578841205
[Epoch 18, Batch 1800] loss: 0.012284626071281082
[Epoch 18, Batch 1900] loss: 0.004862001496250628
[Epoch 18, Batch 2000] loss: 0.0038140206309721946
[Epoch 18, Batch 2100] loss: 0.008832658733377343
[Epoch 18, Batch 2200] loss: 0.005410402742317615
[Epoch 18, Batch 2300] loss: 0.0040216568646465585
[Epoch 18, Batch 2400] loss: 0.01016631949197432
[Epoch 18, Batch 2500] loss: 0.007185768605703799
[Epoch 18, Batch 2600] loss: 0.007557082611963608
[Epoch 18, Batch 2700] loss: 0.014320313313241968
[Epoch 18, Batch 2800] loss: 0.009341598176939669
[Epoch 18, Batch 2900] loss: 0.004710982770324108
[Epoch 18, Batch 3000] loss: 0.0024549292479138884
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9879
Overfitting: 0.0485
[Epoch 19, Batch 100] loss: 0.007290038909696932
[Epoch 19, Batch 200] loss: 0.006797503678451306
[Epoch 19, Batch 300] loss: 0.0026033494938507928
[Epoch 19, Batch 400] loss: 0.0030848631096497313
[Epoch 19, Batch 500] loss: 0.01230667355713294
[Epoch 19, Batch 600] loss: 0.013656184257021557
[Epoch 19, Batch 700] loss: 0.004827316527096741
[Epoch 19, Batch 800] loss: 0.009570919670905056
[Epoch 19, Batch 900] loss: 0.010578616979498605
[Epoch 19, Batch 1000] loss: 0.004456993236790297
[Epoch 19, Batch 1100] loss: 0.0028245321415425904
[Epoch 19, Batch 1200] loss: 0.014099719580028704
[Epoch 19, Batch 1300] loss: 0.005345900129103569
[Epoch 19, Batch 1400] loss: 0.007140229390132049
[Epoch 19, Batch 1500] loss: 0.003721311233546203
[Epoch 19, Batch 1600] loss: 0.004071467513163043
[Epoch 19, Batch 1700] loss: 0.009441042927276157
[Epoch 19, Batch 1800] loss: 0.006116785370881957
[Epoch 19, Batch 1900] loss: 0.0025357029346088212
[Epoch 19, Batch 2000] loss: 0.002274495251326201
[Epoch 19, Batch 2100] loss: 0.0020304640041175757
[Epoch 19, Batch 2200] loss: 0.004788729236320215
[Epoch 19, Batch 2300] loss: 0.00426700087103697
[Epoch 19, Batch 2400] loss: 0.011762043122817544
[Epoch 19, Batch 2500] loss: 0.00514162781329901
[Epoch 19, Batch 2600] loss: 0.003927983497240035
[Epoch 19, Batch 2700] loss: 0.018389783285779195
[Epoch 19, Batch 2800] loss: 0.014818041494260114
[Epoch 19, Batch 2900] loss: 0.008387829989560487
[Epoch 19, Batch 3000] loss: 0.006037740995571852
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0553
Validation Accuracy: 0.9864
Overfitting: 0.0553
[Epoch 20, Batch 100] loss: 0.0049651368671069914
[Epoch 20, Batch 200] loss: 0.005933291414099813
[Epoch 20, Batch 300] loss: 0.0020825401059030744
[Epoch 20, Batch 400] loss: 0.0029940105473821176
[Epoch 20, Batch 500] loss: 0.00631501844728291
[Epoch 20, Batch 600] loss: 0.002416770276489615
[Epoch 20, Batch 700] loss: 0.0013036751728928665
[Epoch 20, Batch 800] loss: 0.010630460500467507
[Epoch 20, Batch 900] loss: 0.008136107733912467
[Epoch 20, Batch 1000] loss: 0.0021884886316949803
[Epoch 20, Batch 1100] loss: 0.003017085361210086
[Epoch 20, Batch 1200] loss: 0.004283826811034004
[Epoch 20, Batch 1300] loss: 0.007354817797584872
[Epoch 20, Batch 1400] loss: 0.0038971771700721546
[Epoch 20, Batch 1500] loss: 0.008307867377718168
[Epoch 20, Batch 1600] loss: 0.008758507984243807
[Epoch 20, Batch 1700] loss: 0.005724568937103527
[Epoch 20, Batch 1800] loss: 0.0025840673210932863
[Epoch 20, Batch 1900] loss: 0.0021154336819111563
[Epoch 20, Batch 2000] loss: 0.003588035194754582
[Epoch 20, Batch 2100] loss: 0.0036839838071755083
[Epoch 20, Batch 2200] loss: 0.002489769397740673
[Epoch 20, Batch 2300] loss: 0.006123044833012017
[Epoch 20, Batch 2400] loss: 0.01756352913326735
[Epoch 20, Batch 2500] loss: 0.008584297629881235
[Epoch 20, Batch 2600] loss: 0.005083416785060706
[Epoch 20, Batch 2700] loss: 0.008666561813461086
[Epoch 20, Batch 2800] loss: 0.011730972925914074
[Epoch 20, Batch 2900] loss: 0.0026917231904465665
[Epoch 20, Batch 3000] loss: 0.010467717414521438
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0574
Validation Accuracy: 0.9878
Overfitting: 0.0574
[Epoch 21, Batch 100] loss: 0.010807166077463784
[Epoch 21, Batch 200] loss: 0.010593772949438147
[Epoch 21, Batch 300] loss: 0.008167792793144883
[Epoch 21, Batch 400] loss: 0.003145806106125946
[Epoch 21, Batch 500] loss: 0.0015958772633754847
[Epoch 21, Batch 600] loss: 0.0016765673041358297
[Epoch 21, Batch 700] loss: 0.003027445508007531
[Epoch 21, Batch 800] loss: 0.0012789521132053495
[Epoch 21, Batch 900] loss: 0.0009212204285609715
[Epoch 21, Batch 1000] loss: 0.0010185604763434952
[Epoch 21, Batch 1100] loss: 0.0025634568446983507
[Epoch 21, Batch 1200] loss: 0.004330333938471176
[Epoch 21, Batch 1300] loss: 0.004455738508262641
[Epoch 21, Batch 1400] loss: 0.009597043406756996
[Epoch 21, Batch 1500] loss: 0.002022703063035891
[Epoch 21, Batch 1600] loss: 0.0035582247128309063
[Epoch 21, Batch 1700] loss: 0.00432311449292655
[Epoch 21, Batch 1800] loss: 0.008371720366175594
[Epoch 21, Batch 1900] loss: 0.008593856512451339
[Epoch 21, Batch 2000] loss: 0.010392631797015994
[Epoch 21, Batch 2100] loss: 0.007355163172110224
[Epoch 21, Batch 2200] loss: 0.002904710293933448
[Epoch 21, Batch 2300] loss: 0.003714442064582499
[Epoch 21, Batch 2400] loss: 0.005960653450119793
[Epoch 21, Batch 2500] loss: 0.002940781269310548
[Epoch 21, Batch 2600] loss: 0.0018093261354090195
[Epoch 21, Batch 2700] loss: 0.002150112731238205
[Epoch 21, Batch 2800] loss: 0.003931848139762048
[Epoch 21, Batch 2900] loss: 0.0042631227345322036
[Epoch 21, Batch 3000] loss: 0.004501672228829818
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9884
Overfitting: 0.0542
[Epoch 22, Batch 100] loss: 0.0029495030846484836
[Epoch 22, Batch 200] loss: 0.0037854663329996187
[Epoch 22, Batch 300] loss: 0.0020983942794796915
[Epoch 22, Batch 400] loss: 0.0019041717468174114
[Epoch 22, Batch 500] loss: 0.001145453831294816
[Epoch 22, Batch 600] loss: 0.0009904991220622606
[Epoch 22, Batch 700] loss: 0.0007399234203425209
[Epoch 22, Batch 800] loss: 0.004678034803199367
[Epoch 22, Batch 900] loss: 0.0013611024590857567
[Epoch 22, Batch 1000] loss: 0.0020953226616710198
[Epoch 22, Batch 1100] loss: 0.0016026704280247372
[Epoch 22, Batch 1200] loss: 0.0034532095464819435
[Epoch 22, Batch 1300] loss: 0.0019238043147543494
[Epoch 22, Batch 1400] loss: 0.0025269310302215332
[Epoch 22, Batch 1500] loss: 0.00437806466701403
[Epoch 22, Batch 1600] loss: 0.0034489524948721952
[Epoch 22, Batch 1700] loss: 0.0072558261499341995
[Epoch 22, Batch 1800] loss: 0.007185673801798771
[Epoch 22, Batch 1900] loss: 0.0027177928088461113
[Epoch 22, Batch 2000] loss: 0.012867024196331726
[Epoch 22, Batch 2100] loss: 0.004352969546050218
[Epoch 22, Batch 2200] loss: 0.0035983404334105984
[Epoch 22, Batch 2300] loss: 0.002204162225256847
[Epoch 22, Batch 2400] loss: 0.006521277011919224
[Epoch 22, Batch 2500] loss: 0.0014810685765787035
[Epoch 22, Batch 2600] loss: 0.004175815091539672
[Epoch 22, Batch 2700] loss: 0.004013193892421754
[Epoch 22, Batch 2800] loss: 0.00198081128508548
[Epoch 22, Batch 2900] loss: 0.0078719615525155
[Epoch 22, Batch 3000] loss: 0.0017852626688013907
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0558
Validation Accuracy: 0.9882
Overfitting: 0.0558
[Epoch 23, Batch 100] loss: 0.0021449544166586023
[Epoch 23, Batch 200] loss: 0.011999961966153804
[Epoch 23, Batch 300] loss: 0.007312211123194476
[Epoch 23, Batch 400] loss: 0.00409145385532744
[Epoch 23, Batch 500] loss: 0.0030162013208069995
[Epoch 23, Batch 600] loss: 0.0011815961459411284
[Epoch 23, Batch 700] loss: 0.0011778035896172412
[Epoch 23, Batch 800] loss: 0.0026761622090035074
[Epoch 23, Batch 900] loss: 0.0035979557272751528
[Epoch 23, Batch 1000] loss: 0.000996144915090511
[Epoch 23, Batch 1100] loss: 0.0014873993275567354
[Epoch 23, Batch 1200] loss: 0.0021914632208475293
[Epoch 23, Batch 1300] loss: 0.0017495392758732997
[Epoch 23, Batch 1400] loss: 0.0017564739348787085
[Epoch 23, Batch 1500] loss: 0.0009665995498917823
[Epoch 23, Batch 1600] loss: 0.002160090463928732
[Epoch 23, Batch 1700] loss: 0.0023667070079542362
[Epoch 23, Batch 1800] loss: 0.0009021258086827899
[Epoch 23, Batch 1900] loss: 0.0007774330230769877
[Epoch 23, Batch 2000] loss: 0.0019858992623534278
[Epoch 23, Batch 2100] loss: 0.0017674830189624612
[Epoch 23, Batch 2200] loss: 0.0010411379556430943
[Epoch 23, Batch 2300] loss: 0.0009105972232148752
[Epoch 23, Batch 2400] loss: 0.0006195407309287048
[Epoch 23, Batch 2500] loss: 0.0027706803818560743
[Epoch 23, Batch 2600] loss: 0.001969211017680905
[Epoch 23, Batch 2700] loss: 0.0010377997178977693
[Epoch 23, Batch 2800] loss: 0.010457336070061558
[Epoch 23, Batch 2900] loss: 0.0010699467425190079
[Epoch 23, Batch 3000] loss: 0.000958418674594248
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9888
Overfitting: 0.0514
[Epoch 24, Batch 100] loss: 0.0010995412667595828
[Epoch 24, Batch 200] loss: 0.003107215090240767
[Epoch 24, Batch 300] loss: 0.001397520562312593
[Epoch 24, Batch 400] loss: 0.0007941401544461968
[Epoch 24, Batch 500] loss: 0.0006464671534725763
[Epoch 24, Batch 600] loss: 0.0008496332779506455
[Epoch 24, Batch 700] loss: 0.000549996334739502
[Epoch 24, Batch 800] loss: 0.0010866863546568695
[Epoch 24, Batch 900] loss: 0.0006951209157106941
[Epoch 24, Batch 1000] loss: 0.0005098336599912301
[Epoch 24, Batch 1100] loss: 0.00044905877133881943
[Epoch 24, Batch 1200] loss: 0.0006314407967407299
[Epoch 24, Batch 1300] loss: 0.0005311026612693759
[Epoch 24, Batch 1400] loss: 0.0003848486133460494
[Epoch 24, Batch 1500] loss: 0.0007151930124750417
[Epoch 24, Batch 1600] loss: 0.0005213025480841082
[Epoch 24, Batch 1700] loss: 0.003219614223086751
[Epoch 24, Batch 1800] loss: 0.0014764458665376123
[Epoch 24, Batch 1900] loss: 0.0016965307418314657
[Epoch 24, Batch 2000] loss: 0.0017008835685842704
[Epoch 24, Batch 2100] loss: 0.0005778122763734128
[Epoch 24, Batch 2200] loss: 0.00043970146219432846
[Epoch 24, Batch 2300] loss: 0.000531568393735311
[Epoch 24, Batch 2400] loss: 0.00046778114248951396
[Epoch 24, Batch 2500] loss: 0.00034719843482292843
[Epoch 24, Batch 2600] loss: 0.0005690205782863078
[Epoch 24, Batch 2700] loss: 0.0014050799238302502
[Epoch 24, Batch 2800] loss: 0.0005518667578736958
[Epoch 24, Batch 2900] loss: 0.00043621637468767017
[Epoch 24, Batch 3000] loss: 0.0005909340802214081
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9893
Overfitting: 0.0523
Fold 1 validation loss: 0.0523
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.284311583042145
[Epoch 1, Batch 200] loss: 2.1346725952625274
[Epoch 1, Batch 300] loss: 1.1219324004650115
[Epoch 1, Batch 400] loss: 0.5862370932102203
[Epoch 1, Batch 500] loss: 0.4429360769689083
[Epoch 1, Batch 600] loss: 0.44505918577313425
[Epoch 1, Batch 700] loss: 0.3613109857216477
[Epoch 1, Batch 800] loss: 0.31025959411635995
[Epoch 1, Batch 900] loss: 0.26397009041160346
[Epoch 1, Batch 1000] loss: 0.23078189939260482
[Epoch 1, Batch 1100] loss: 0.2579735536687076
[Epoch 1, Batch 1200] loss: 0.20883868023753166
[Epoch 1, Batch 1300] loss: 0.19895635645836593
[Epoch 1, Batch 1400] loss: 0.15150954720564186
[Epoch 1, Batch 1500] loss: 0.18179735301062463
[Epoch 1, Batch 1600] loss: 0.1877499925531447
[Epoch 1, Batch 1700] loss: 0.18625249786302447
[Epoch 1, Batch 1800] loss: 0.14939858268015085
[Epoch 1, Batch 1900] loss: 0.1586055748583749
[Epoch 1, Batch 2000] loss: 0.11751788821769878
[Epoch 1, Batch 2100] loss: 0.1539244058728218
[Epoch 1, Batch 2200] loss: 0.1609189603663981
[Epoch 1, Batch 2300] loss: 0.12497746929060667
[Epoch 1, Batch 2400] loss: 0.11865519972983747
[Epoch 1, Batch 2500] loss: 0.10954032134730368
[Epoch 1, Batch 2600] loss: 0.13219692589947954
[Epoch 1, Batch 2700] loss: 0.11523006549105048
[Epoch 1, Batch 2800] loss: 0.10954058003379032
[Epoch 1, Batch 2900] loss: 0.11057500153081491
[Epoch 1, Batch 3000] loss: 0.10986401050933636
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1177
Validation Accuracy: 0.9628
Overfitting: 0.1177
Best model saved at epoch 1 with validation loss: 0.1177
[Epoch 2, Batch 100] loss: 0.09743839334929362
[Epoch 2, Batch 200] loss: 0.08389971857191995
[Epoch 2, Batch 300] loss: 0.101259868760244
[Epoch 2, Batch 400] loss: 0.0996229079447221
[Epoch 2, Batch 500] loss: 0.06460953273810446
[Epoch 2, Batch 600] loss: 0.09655191687634215
[Epoch 2, Batch 700] loss: 0.08201437926036306
[Epoch 2, Batch 800] loss: 0.06467606185178738
[Epoch 2, Batch 900] loss: 0.09128161013184581
[Epoch 2, Batch 1000] loss: 0.09060973282437772
[Epoch 2, Batch 1100] loss: 0.06717652996652759
[Epoch 2, Batch 1200] loss: 0.12954591020359657
[Epoch 2, Batch 1300] loss: 0.07622757182689384
[Epoch 2, Batch 1400] loss: 0.0855066424619872
[Epoch 2, Batch 1500] loss: 0.08138838882674464
[Epoch 2, Batch 1600] loss: 0.08379966203239747
[Epoch 2, Batch 1700] loss: 0.10170471813064069
[Epoch 2, Batch 1800] loss: 0.07396757525391877
[Epoch 2, Batch 1900] loss: 0.07550737581099383
[Epoch 2, Batch 2000] loss: 0.06368059605825692
[Epoch 2, Batch 2100] loss: 0.0880785867269151
[Epoch 2, Batch 2200] loss: 0.08872949225769844
[Epoch 2, Batch 2300] loss: 0.0917902637203224
[Epoch 2, Batch 2400] loss: 0.0718356892169686
[Epoch 2, Batch 2500] loss: 0.08537985007162206
[Epoch 2, Batch 2600] loss: 0.056904160781996324
[Epoch 2, Batch 2700] loss: 0.06208034496288747
[Epoch 2, Batch 2800] loss: 0.08243668639683165
[Epoch 2, Batch 2900] loss: 0.05868946847156622
[Epoch 2, Batch 3000] loss: 0.06231587008340284
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0785
Validation Accuracy: 0.9766
Overfitting: 0.0785
Best model saved at epoch 2 with validation loss: 0.0785
[Epoch 3, Batch 100] loss: 0.08003907886421074
[Epoch 3, Batch 200] loss: 0.06018051065795589
[Epoch 3, Batch 300] loss: 0.050399343381868675
[Epoch 3, Batch 400] loss: 0.06660637563967611
[Epoch 3, Batch 500] loss: 0.05177562022232451
[Epoch 3, Batch 600] loss: 0.06411195551641867
[Epoch 3, Batch 700] loss: 0.05777501363889314
[Epoch 3, Batch 800] loss: 0.05676064735103864
[Epoch 3, Batch 900] loss: 0.05319207917607855
[Epoch 3, Batch 1000] loss: 0.07014237148454412
[Epoch 3, Batch 1100] loss: 0.053532800769462485
[Epoch 3, Batch 1200] loss: 0.0662093340291176
[Epoch 3, Batch 1300] loss: 0.05275630343850935
[Epoch 3, Batch 1400] loss: 0.03532254334990284
[Epoch 3, Batch 1500] loss: 0.053793624098179865
[Epoch 3, Batch 1600] loss: 0.07871105146536138
[Epoch 3, Batch 1700] loss: 0.052292416157142724
[Epoch 3, Batch 1800] loss: 0.0569738973947824
[Epoch 3, Batch 1900] loss: 0.0688454589236062
[Epoch 3, Batch 2000] loss: 0.06467864561680471
[Epoch 3, Batch 2100] loss: 0.05672258489357773
[Epoch 3, Batch 2200] loss: 0.04083035068964819
[Epoch 3, Batch 2300] loss: 0.06475365777441766
[Epoch 3, Batch 2400] loss: 0.03514710908610141
[Epoch 3, Batch 2500] loss: 0.06565382489236071
[Epoch 3, Batch 2600] loss: 0.06565949811192695
[Epoch 3, Batch 2700] loss: 0.0478915400520782
[Epoch 3, Batch 2800] loss: 0.06256455263326643
[Epoch 3, Batch 2900] loss: 0.04174915489697014
[Epoch 3, Batch 3000] loss: 0.061661851963435765
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0677
Validation Accuracy: 0.9782
Overfitting: 0.0677
Best model saved at epoch 3 with validation loss: 0.0677
[Epoch 4, Batch 100] loss: 0.04555628268775763
[Epoch 4, Batch 200] loss: 0.03486053843691479
[Epoch 4, Batch 300] loss: 0.04478869689948624
[Epoch 4, Batch 400] loss: 0.042986504802247506
[Epoch 4, Batch 500] loss: 0.030502987357322126
[Epoch 4, Batch 600] loss: 0.06883262984702014
[Epoch 4, Batch 700] loss: 0.05087684744416038
[Epoch 4, Batch 800] loss: 0.024438995732562033
[Epoch 4, Batch 900] loss: 0.04227989783015801
[Epoch 4, Batch 1000] loss: 0.046396356988116165
[Epoch 4, Batch 1100] loss: 0.050327542120357976
[Epoch 4, Batch 1200] loss: 0.04653387934551574
[Epoch 4, Batch 1300] loss: 0.04351082066830713
[Epoch 4, Batch 1400] loss: 0.05681179088103818
[Epoch 4, Batch 1500] loss: 0.03064024964274722
[Epoch 4, Batch 1600] loss: 0.04265004753659014
[Epoch 4, Batch 1700] loss: 0.05116378411868936
[Epoch 4, Batch 1800] loss: 0.050827973199775445
[Epoch 4, Batch 1900] loss: 0.048243637327395845
[Epoch 4, Batch 2000] loss: 0.03756368060916429
[Epoch 4, Batch 2100] loss: 0.04212748991907574
[Epoch 4, Batch 2200] loss: 0.03249685285059968
[Epoch 4, Batch 2300] loss: 0.04127212731065811
[Epoch 4, Batch 2400] loss: 0.04296011027974601
[Epoch 4, Batch 2500] loss: 0.037237527644902
[Epoch 4, Batch 2600] loss: 0.04077497732265328
[Epoch 4, Batch 2700] loss: 0.06744869084534003
[Epoch 4, Batch 2800] loss: 0.06016105946400785
[Epoch 4, Batch 2900] loss: 0.0404053057479905
[Epoch 4, Batch 3000] loss: 0.04349824242832256
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0599
Validation Accuracy: 0.9825
Overfitting: 0.0599
Best model saved at epoch 4 with validation loss: 0.0599
[Epoch 5, Batch 100] loss: 0.026562479862332112
[Epoch 5, Batch 200] loss: 0.02625520023451827
[Epoch 5, Batch 300] loss: 0.03412733775563538
[Epoch 5, Batch 400] loss: 0.027260476802985066
[Epoch 5, Batch 500] loss: 0.027798848471211387
[Epoch 5, Batch 600] loss: 0.043604506069386845
[Epoch 5, Batch 700] loss: 0.04248105670689256
[Epoch 5, Batch 800] loss: 0.03633065671136137
[Epoch 5, Batch 900] loss: 0.030350540907529647
[Epoch 5, Batch 1000] loss: 0.023160299491428303
[Epoch 5, Batch 1100] loss: 0.041238134523882766
[Epoch 5, Batch 1200] loss: 0.04733772903542558
[Epoch 5, Batch 1300] loss: 0.0414547509374097
[Epoch 5, Batch 1400] loss: 0.025676754306186923
[Epoch 5, Batch 1500] loss: 0.04880574017734034
[Epoch 5, Batch 1600] loss: 0.037722548823803666
[Epoch 5, Batch 1700] loss: 0.04060476051665319
[Epoch 5, Batch 1800] loss: 0.024057779351132923
[Epoch 5, Batch 1900] loss: 0.02602914394068648
[Epoch 5, Batch 2000] loss: 0.047527841411647384
[Epoch 5, Batch 2100] loss: 0.04894427399543929
[Epoch 5, Batch 2200] loss: 0.040944803825696
[Epoch 5, Batch 2300] loss: 0.043913865717913725
[Epoch 5, Batch 2400] loss: 0.025618313569066232
[Epoch 5, Batch 2500] loss: 0.03675296046800213
[Epoch 5, Batch 2600] loss: 0.026937849385503795
[Epoch 5, Batch 2700] loss: 0.033891010661172914
[Epoch 5, Batch 2800] loss: 0.04290424006780086
[Epoch 5, Batch 2900] loss: 0.048799499167871546
[Epoch 5, Batch 3000] loss: 0.05096041674027219
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0621
Validation Accuracy: 0.9818
Overfitting: 0.0621
[Epoch 6, Batch 100] loss: 0.02983983248093864
[Epoch 6, Batch 200] loss: 0.03426575715107902
[Epoch 6, Batch 300] loss: 0.039803481989656574
[Epoch 6, Batch 400] loss: 0.03503522983082803
[Epoch 6, Batch 500] loss: 0.01749427015216497
[Epoch 6, Batch 600] loss: 0.03334258936854894
[Epoch 6, Batch 700] loss: 0.024531727318826597
[Epoch 6, Batch 800] loss: 0.028999119954241905
[Epoch 6, Batch 900] loss: 0.03756694538795273
[Epoch 6, Batch 1000] loss: 0.02726016046377481
[Epoch 6, Batch 1100] loss: 0.02804281229065964
[Epoch 6, Batch 1200] loss: 0.022077794732686017
[Epoch 6, Batch 1300] loss: 0.0351008224436373
[Epoch 6, Batch 1400] loss: 0.036370617911597944
[Epoch 6, Batch 1500] loss: 0.03424686590471538
[Epoch 6, Batch 1600] loss: 0.036895442689201446
[Epoch 6, Batch 1700] loss: 0.018525540146802088
[Epoch 6, Batch 1800] loss: 0.030074149685351586
[Epoch 6, Batch 1900] loss: 0.03342027517646784
[Epoch 6, Batch 2000] loss: 0.03668217180442298
[Epoch 6, Batch 2100] loss: 0.025269952542294048
[Epoch 6, Batch 2200] loss: 0.02956985129370878
[Epoch 6, Batch 2300] loss: 0.02295177466719906
[Epoch 6, Batch 2400] loss: 0.03296151109545462
[Epoch 6, Batch 2500] loss: 0.0365478169900598
[Epoch 6, Batch 2600] loss: 0.03674131252882944
[Epoch 6, Batch 2700] loss: 0.01844984922234289
[Epoch 6, Batch 2800] loss: 0.03521745221885794
[Epoch 6, Batch 2900] loss: 0.035783412869641325
[Epoch 6, Batch 3000] loss: 0.04555766999095795
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9855
Overfitting: 0.0529
Best model saved at epoch 6 with validation loss: 0.0529
[Epoch 7, Batch 100] loss: 0.013691480871711974
[Epoch 7, Batch 200] loss: 0.024209784395934547
[Epoch 7, Batch 300] loss: 0.025798188601802396
[Epoch 7, Batch 400] loss: 0.020224260505419808
[Epoch 7, Batch 500] loss: 0.02055028838905855
[Epoch 7, Batch 600] loss: 0.027421378409198952
[Epoch 7, Batch 700] loss: 0.023768781742983264
[Epoch 7, Batch 800] loss: 0.029564350791879405
[Epoch 7, Batch 900] loss: 0.03228224577535002
[Epoch 7, Batch 1000] loss: 0.03833033255505143
[Epoch 7, Batch 1100] loss: 0.02497872391664714
[Epoch 7, Batch 1200] loss: 0.03123658430093201
[Epoch 7, Batch 1300] loss: 0.021614822151059344
[Epoch 7, Batch 1400] loss: 0.0358720280900161
[Epoch 7, Batch 1500] loss: 0.02330297793872887
[Epoch 7, Batch 1600] loss: 0.01611581134457083
[Epoch 7, Batch 1700] loss: 0.02894716809347301
[Epoch 7, Batch 1800] loss: 0.028370979111932683
[Epoch 7, Batch 1900] loss: 0.04041037004244572
[Epoch 7, Batch 2000] loss: 0.020289296856863075
[Epoch 7, Batch 2100] loss: 0.017017250204989978
[Epoch 7, Batch 2200] loss: 0.04389847583719529
[Epoch 7, Batch 2300] loss: 0.04030670179716253
[Epoch 7, Batch 2400] loss: 0.03196942091468372
[Epoch 7, Batch 2500] loss: 0.014757272636707057
[Epoch 7, Batch 2600] loss: 0.022494720547038015
[Epoch 7, Batch 2700] loss: 0.024623955221031793
[Epoch 7, Batch 2800] loss: 0.03016719382852898
[Epoch 7, Batch 2900] loss: 0.024862504512529995
[Epoch 7, Batch 3000] loss: 0.028369894070601732
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9863
Overfitting: 0.0479
Best model saved at epoch 7 with validation loss: 0.0479
[Epoch 8, Batch 100] loss: 0.012281367046525701
[Epoch 8, Batch 200] loss: 0.012353194094503124
[Epoch 8, Batch 300] loss: 0.030395944465963113
[Epoch 8, Batch 400] loss: 0.018022557702770427
[Epoch 8, Batch 500] loss: 0.031978930695695455
[Epoch 8, Batch 600] loss: 0.0252316456025801
[Epoch 8, Batch 700] loss: 0.02404523877601605
[Epoch 8, Batch 800] loss: 0.023255498018625077
[Epoch 8, Batch 900] loss: 0.021625508967626956
[Epoch 8, Batch 1000] loss: 0.030480572125597974
[Epoch 8, Batch 1100] loss: 0.021546907921983802
[Epoch 8, Batch 1200] loss: 0.011740874357874418
[Epoch 8, Batch 1300] loss: 0.010624072006412461
[Epoch 8, Batch 1400] loss: 0.024008113773052172
[Epoch 8, Batch 1500] loss: 0.017739548837307665
[Epoch 8, Batch 1600] loss: 0.031211837546579774
[Epoch 8, Batch 1700] loss: 0.020692005340824837
[Epoch 8, Batch 1800] loss: 0.018181460448449798
[Epoch 8, Batch 1900] loss: 0.02201878675567059
[Epoch 8, Batch 2000] loss: 0.02012686989017311
[Epoch 8, Batch 2100] loss: 0.028185391274892026
[Epoch 8, Batch 2200] loss: 0.02090685226408823
[Epoch 8, Batch 2300] loss: 0.03864527712801646
[Epoch 8, Batch 2400] loss: 0.02447853307378864
[Epoch 8, Batch 2500] loss: 0.017315273373560557
[Epoch 8, Batch 2600] loss: 0.01955267986179024
[Epoch 8, Batch 2700] loss: 0.025546507321041644
[Epoch 8, Batch 2800] loss: 0.03779341329009185
[Epoch 8, Batch 2900] loss: 0.023825118889726583
[Epoch 8, Batch 3000] loss: 0.030374312790881958
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9839
Overfitting: 0.0522
[Epoch 9, Batch 100] loss: 0.014947825179588108
[Epoch 9, Batch 200] loss: 0.02304209881481256
[Epoch 9, Batch 300] loss: 0.016821801614169088
[Epoch 9, Batch 400] loss: 0.01041733910664334
[Epoch 9, Batch 500] loss: 0.013299253682387189
[Epoch 9, Batch 600] loss: 0.01987228383712136
[Epoch 9, Batch 700] loss: 0.02202341052268821
[Epoch 9, Batch 800] loss: 0.019671925627080783
[Epoch 9, Batch 900] loss: 0.01326039420977395
[Epoch 9, Batch 1000] loss: 0.022528119366429563
[Epoch 9, Batch 1100] loss: 0.025010145267806365
[Epoch 9, Batch 1200] loss: 0.027974192061719805
[Epoch 9, Batch 1300] loss: 0.020990365068691973
[Epoch 9, Batch 1400] loss: 0.018876899135830173
[Epoch 9, Batch 1500] loss: 0.03167425885447301
[Epoch 9, Batch 1600] loss: 0.008209147033412592
[Epoch 9, Batch 1700] loss: 0.024380573427606578
[Epoch 9, Batch 1800] loss: 0.016832872470495204
[Epoch 9, Batch 1900] loss: 0.01825175259007665
[Epoch 9, Batch 2000] loss: 0.029420717818575214
[Epoch 9, Batch 2100] loss: 0.031099183583137346
[Epoch 9, Batch 2200] loss: 0.017690033179242164
[Epoch 9, Batch 2300] loss: 0.013883251897786976
[Epoch 9, Batch 2400] loss: 0.015091810541907762
[Epoch 9, Batch 2500] loss: 0.023012369700909405
[Epoch 9, Batch 2600] loss: 0.018558503135645877
[Epoch 9, Batch 2700] loss: 0.007019343277761436
[Epoch 9, Batch 2800] loss: 0.01709459469738249
[Epoch 9, Batch 2900] loss: 0.022923434502863528
[Epoch 9, Batch 3000] loss: 0.031028539560502395
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9858
Overfitting: 0.0527
[Epoch 10, Batch 100] loss: 0.007904509183244954
[Epoch 10, Batch 200] loss: 0.006702726778839861
[Epoch 10, Batch 300] loss: 0.014758718950397452
[Epoch 10, Batch 400] loss: 0.015184288249001839
[Epoch 10, Batch 500] loss: 0.020661257523570384
[Epoch 10, Batch 600] loss: 0.016736101168871757
[Epoch 10, Batch 700] loss: 0.016642450189629017
[Epoch 10, Batch 800] loss: 0.012763666459486558
[Epoch 10, Batch 900] loss: 0.04345498115882947
[Epoch 10, Batch 1000] loss: 0.019068506645562592
[Epoch 10, Batch 1100] loss: 0.008578546359422035
[Epoch 10, Batch 1200] loss: 0.023631569377339474
[Epoch 10, Batch 1300] loss: 0.013440186584066396
[Epoch 10, Batch 1400] loss: 0.021167362508786026
[Epoch 10, Batch 1500] loss: 0.026394486981935188
[Epoch 10, Batch 1600] loss: 0.02265240751559759
[Epoch 10, Batch 1700] loss: 0.015966222373435812
[Epoch 10, Batch 1800] loss: 0.013443061900170505
[Epoch 10, Batch 1900] loss: 0.013443890211910912
[Epoch 10, Batch 2000] loss: 0.01371923867980513
[Epoch 10, Batch 2100] loss: 0.02160941577207268
[Epoch 10, Batch 2200] loss: 0.01071386487552445
[Epoch 10, Batch 2300] loss: 0.010713489366280556
[Epoch 10, Batch 2400] loss: 0.013213436676396668
[Epoch 10, Batch 2500] loss: 0.025927531579818607
[Epoch 10, Batch 2600] loss: 0.014241809809609549
[Epoch 10, Batch 2700] loss: 0.014297109034050664
[Epoch 10, Batch 2800] loss: 0.010988852672799112
[Epoch 10, Batch 2900] loss: 0.02172216682451108
[Epoch 10, Batch 3000] loss: 0.009221876640503978
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0587
Validation Accuracy: 0.9841
Overfitting: 0.0587
[Epoch 11, Batch 100] loss: 0.01142422596858296
[Epoch 11, Batch 200] loss: 0.011052066691518122
[Epoch 11, Batch 300] loss: 0.011000945090017922
[Epoch 11, Batch 400] loss: 0.021557782456070526
[Epoch 11, Batch 500] loss: 0.023703343058114116
[Epoch 11, Batch 600] loss: 0.010934171315875573
[Epoch 11, Batch 700] loss: 0.01081356426660477
[Epoch 11, Batch 800] loss: 0.009037919840266114
[Epoch 11, Batch 900] loss: 0.022171328716967764
[Epoch 11, Batch 1000] loss: 0.012307401712505453
[Epoch 11, Batch 1100] loss: 0.013775797775342652
[Epoch 11, Batch 1200] loss: 0.013907412441940324
[Epoch 11, Batch 1300] loss: 0.02164036645500346
[Epoch 11, Batch 1400] loss: 0.01127113246279805
[Epoch 11, Batch 1500] loss: 0.019097405945462925
[Epoch 11, Batch 1600] loss: 0.015819403458790474
[Epoch 11, Batch 1700] loss: 0.010326467625072838
[Epoch 11, Batch 1800] loss: 0.03209278502386951
[Epoch 11, Batch 1900] loss: 0.025229257311561924
[Epoch 11, Batch 2000] loss: 0.010504472463853744
[Epoch 11, Batch 2100] loss: 0.010865409593736785
[Epoch 11, Batch 2200] loss: 0.014226524996838635
[Epoch 11, Batch 2300] loss: 0.011590671215562906
[Epoch 11, Batch 2400] loss: 0.008732118900652494
[Epoch 11, Batch 2500] loss: 0.02045406719716084
[Epoch 11, Batch 2600] loss: 0.02688231182672098
[Epoch 11, Batch 2700] loss: 0.01144370903503841
[Epoch 11, Batch 2800] loss: 0.012228735576954933
[Epoch 11, Batch 2900] loss: 0.013139656702032881
[Epoch 11, Batch 3000] loss: 0.015108940456657364
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9859
Overfitting: 0.0581
[Epoch 12, Batch 100] loss: 0.00838517654462521
[Epoch 12, Batch 200] loss: 0.007934730213110015
[Epoch 12, Batch 300] loss: 0.007321077925807913
[Epoch 12, Batch 400] loss: 0.017032301187932718
[Epoch 12, Batch 500] loss: 0.018276282313045157
[Epoch 12, Batch 600] loss: 0.005824524266140543
[Epoch 12, Batch 700] loss: 0.008185415365774133
[Epoch 12, Batch 800] loss: 0.006842662228573318
[Epoch 12, Batch 900] loss: 0.010177975247756876
[Epoch 12, Batch 1000] loss: 0.008166165289226228
[Epoch 12, Batch 1100] loss: 0.020587842332179206
[Epoch 12, Batch 1200] loss: 0.0158432006250996
[Epoch 12, Batch 1300] loss: 0.013513726777473494
[Epoch 12, Batch 1400] loss: 0.005196082885613578
[Epoch 12, Batch 1500] loss: 0.008772667794851259
[Epoch 12, Batch 1600] loss: 0.011405391781291883
[Epoch 12, Batch 1700] loss: 0.01352857111068829
[Epoch 12, Batch 1800] loss: 0.014948739202939123
[Epoch 12, Batch 1900] loss: 0.008126106914658067
[Epoch 12, Batch 2000] loss: 0.009178279747961824
[Epoch 12, Batch 2100] loss: 0.009850698133782317
[Epoch 12, Batch 2200] loss: 0.011407145203611435
[Epoch 12, Batch 2300] loss: 0.009512853035703301
[Epoch 12, Batch 2400] loss: 0.008856962761694832
[Epoch 12, Batch 2500] loss: 0.011101745876630957
[Epoch 12, Batch 2600] loss: 0.00790367945527578
[Epoch 12, Batch 2700] loss: 0.021831626517973747
[Epoch 12, Batch 2800] loss: 0.013006802836872566
[Epoch 12, Batch 2900] loss: 0.02365493570054241
[Epoch 12, Batch 3000] loss: 0.0161408690101689
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0600
Validation Accuracy: 0.9862
Overfitting: 0.0600
[Epoch 13, Batch 100] loss: 0.0089204144784685
[Epoch 13, Batch 200] loss: 0.022511768456538447
[Epoch 13, Batch 300] loss: 0.0049774232586173636
[Epoch 13, Batch 400] loss: 0.005917626445892665
[Epoch 13, Batch 500] loss: 0.006128129214175715
[Epoch 13, Batch 600] loss: 0.017815958875662546
[Epoch 13, Batch 700] loss: 0.018965098695070993
[Epoch 13, Batch 800] loss: 0.017130791309073176
[Epoch 13, Batch 900] loss: 0.013716758308646604
[Epoch 13, Batch 1000] loss: 0.00831027991438532
[Epoch 13, Batch 1100] loss: 0.014566888579647639
[Epoch 13, Batch 1200] loss: 0.01166741551782934
[Epoch 13, Batch 1300] loss: 0.011552675751095193
[Epoch 13, Batch 1400] loss: 0.01084843464698679
[Epoch 13, Batch 1500] loss: 0.006721718711678477
[Epoch 13, Batch 1600] loss: 0.006926233098711237
[Epoch 13, Batch 1700] loss: 0.0038201987727813956
[Epoch 13, Batch 1800] loss: 0.011429840196492479
[Epoch 13, Batch 1900] loss: 0.006957202897028765
[Epoch 13, Batch 2000] loss: 0.00806890701667271
[Epoch 13, Batch 2100] loss: 0.008539341516119521
[Epoch 13, Batch 2200] loss: 0.015250805212622254
[Epoch 13, Batch 2300] loss: 0.011871915899881742
[Epoch 13, Batch 2400] loss: 0.008696190568859946
[Epoch 13, Batch 2500] loss: 0.01770068243623882
[Epoch 13, Batch 2600] loss: 0.015591215522426864
[Epoch 13, Batch 2700] loss: 0.010316646669698457
[Epoch 13, Batch 2800] loss: 0.013182836663936541
[Epoch 13, Batch 2900] loss: 0.00994251543597784
[Epoch 13, Batch 3000] loss: 0.027922333589385742
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9854
Overfitting: 0.0573
[Epoch 14, Batch 100] loss: 0.013141178635896722
[Epoch 14, Batch 200] loss: 0.006743880012722911
[Epoch 14, Batch 300] loss: 0.008792454386762074
[Epoch 14, Batch 400] loss: 0.009583329354013586
[Epoch 14, Batch 500] loss: 0.004847432477713482
[Epoch 14, Batch 600] loss: 0.006076977850734693
[Epoch 14, Batch 700] loss: 0.0039425664701593635
[Epoch 14, Batch 800] loss: 0.00958786086353939
[Epoch 14, Batch 900] loss: 0.005682538094533811
[Epoch 14, Batch 1000] loss: 0.004236081027677301
[Epoch 14, Batch 1100] loss: 0.007757196596462563
[Epoch 14, Batch 1200] loss: 0.010249277151614677
[Epoch 14, Batch 1300] loss: 0.011287707689662056
[Epoch 14, Batch 1400] loss: 0.010330414112141853
[Epoch 14, Batch 1500] loss: 0.007453041245069017
[Epoch 14, Batch 1600] loss: 0.010875706738834196
[Epoch 14, Batch 1700] loss: 0.009453578628929336
[Epoch 14, Batch 1800] loss: 0.005505813060781292
[Epoch 14, Batch 1900] loss: 0.00803218653301883
[Epoch 14, Batch 2000] loss: 0.010316160572133698
[Epoch 14, Batch 2100] loss: 0.01803584282306929
[Epoch 14, Batch 2200] loss: 0.01302177938571731
[Epoch 14, Batch 2300] loss: 0.007499954180918849
[Epoch 14, Batch 2400] loss: 0.007447463571309072
[Epoch 14, Batch 2500] loss: 0.011198479328546682
[Epoch 14, Batch 2600] loss: 0.008894950269710903
[Epoch 14, Batch 2700] loss: 0.016195058063168517
[Epoch 14, Batch 2800] loss: 0.017336721898436734
[Epoch 14, Batch 2900] loss: 0.011686352678320872
[Epoch 14, Batch 3000] loss: 0.017932802243690274
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0774
Validation Accuracy: 0.9817
Overfitting: 0.0774
[Epoch 15, Batch 100] loss: 0.010001961959669643
[Epoch 15, Batch 200] loss: 0.008612920116938767
[Epoch 15, Batch 300] loss: 0.012869477870222
[Epoch 15, Batch 400] loss: 0.005804904648252887
[Epoch 15, Batch 500] loss: 0.012252819180953339
[Epoch 15, Batch 600] loss: 0.005670058083198342
[Epoch 15, Batch 700] loss: 0.014232274819988788
[Epoch 15, Batch 800] loss: 0.005801163669129892
[Epoch 15, Batch 900] loss: 0.007210452570461712
[Epoch 15, Batch 1000] loss: 0.0039464688834306115
[Epoch 15, Batch 1100] loss: 0.00500359027516879
[Epoch 15, Batch 1200] loss: 0.008995465897976373
[Epoch 15, Batch 1300] loss: 0.015208438982763256
[Epoch 15, Batch 1400] loss: 0.004599854914354182
[Epoch 15, Batch 1500] loss: 0.016469809209386312
[Epoch 15, Batch 1600] loss: 0.009278110792173493
[Epoch 15, Batch 1700] loss: 0.005401100727028734
[Epoch 15, Batch 1800] loss: 0.015544566622202183
[Epoch 15, Batch 1900] loss: 0.007991971830747388
[Epoch 15, Batch 2000] loss: 0.006015705899601471
[Epoch 15, Batch 2100] loss: 0.012402960661499946
[Epoch 15, Batch 2200] loss: 0.012491712318730492
[Epoch 15, Batch 2300] loss: 0.01240858732797733
[Epoch 15, Batch 2400] loss: 0.003592151720951051
[Epoch 15, Batch 2500] loss: 0.006634278124997763
[Epoch 15, Batch 2600] loss: 0.004571424502354375
[Epoch 15, Batch 2700] loss: 0.011484674529669973
[Epoch 15, Batch 2800] loss: 0.006694204436041673
[Epoch 15, Batch 2900] loss: 0.013280906096443914
[Epoch 15, Batch 3000] loss: 0.007158547776448358
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9861
Overfitting: 0.0603
[Epoch 16, Batch 100] loss: 0.009100858705311908
[Epoch 16, Batch 200] loss: 0.006361783628796331
[Epoch 16, Batch 300] loss: 0.010452078081657419
[Epoch 16, Batch 400] loss: 0.004400284516448778
[Epoch 16, Batch 500] loss: 0.0077021455435442475
[Epoch 16, Batch 600] loss: 0.019013048171678405
[Epoch 16, Batch 700] loss: 0.006896884786010559
[Epoch 16, Batch 800] loss: 0.008272172832159015
[Epoch 16, Batch 900] loss: 0.007139425470204515
[Epoch 16, Batch 1000] loss: 0.008110837347577443
[Epoch 16, Batch 1100] loss: 0.007856827970413179
[Epoch 16, Batch 1200] loss: 0.0038656760689923433
[Epoch 16, Batch 1300] loss: 0.002958161029403641
[Epoch 16, Batch 1400] loss: 0.0025133945800646985
[Epoch 16, Batch 1500] loss: 0.001431794826847863
[Epoch 16, Batch 1600] loss: 0.006275153820213291
[Epoch 16, Batch 1700] loss: 0.003022726513843281
[Epoch 16, Batch 1800] loss: 0.016716461923717816
[Epoch 16, Batch 1900] loss: 0.01287425921586646
[Epoch 16, Batch 2000] loss: 0.006910924370921805
[Epoch 16, Batch 2100] loss: 0.004261462260635653
[Epoch 16, Batch 2200] loss: 0.011323560235950367
[Epoch 16, Batch 2300] loss: 0.0046517429456935135
[Epoch 16, Batch 2400] loss: 0.0167739764716805
[Epoch 16, Batch 2500] loss: 0.010491528174970881
[Epoch 16, Batch 2600] loss: 0.00498557477268264
[Epoch 16, Batch 2700] loss: 0.003339761762242688
[Epoch 16, Batch 2800] loss: 0.008218889214188039
[Epoch 16, Batch 2900] loss: 0.009974031497627038
[Epoch 16, Batch 3000] loss: 0.004225976860295759
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9858
Overfitting: 0.0564
[Epoch 17, Batch 100] loss: 0.0030445750423848494
[Epoch 17, Batch 200] loss: 0.006891155223320311
[Epoch 17, Batch 300] loss: 0.0024035876392849787
[Epoch 17, Batch 400] loss: 0.001707620804107819
[Epoch 17, Batch 500] loss: 0.008317653944504854
[Epoch 17, Batch 600] loss: 0.004643425910089718
[Epoch 17, Batch 700] loss: 0.004605391492538615
[Epoch 17, Batch 800] loss: 0.003752577576967724
[Epoch 17, Batch 900] loss: 0.0034810927942029936
[Epoch 17, Batch 1000] loss: 0.011125993186228698
[Epoch 17, Batch 1100] loss: 0.0037951003307316
[Epoch 17, Batch 1200] loss: 0.0027406221632000436
[Epoch 17, Batch 1300] loss: 0.008818329691887072
[Epoch 17, Batch 1400] loss: 0.0029869632764483356
[Epoch 17, Batch 1500] loss: 0.006766628210869916
[Epoch 17, Batch 1600] loss: 0.01225476655640705
[Epoch 17, Batch 1700] loss: 0.006379040714462576
[Epoch 17, Batch 1800] loss: 0.008527933436836293
[Epoch 17, Batch 1900] loss: 0.012012310168042575
[Epoch 17, Batch 2000] loss: 0.009827548108328301
[Epoch 17, Batch 2100] loss: 0.0190013271063566
[Epoch 17, Batch 2200] loss: 0.013097721847343565
[Epoch 17, Batch 2300] loss: 0.010336978156873329
[Epoch 17, Batch 2400] loss: 0.009223393851912079
[Epoch 17, Batch 2500] loss: 0.024206011326056112
[Epoch 17, Batch 2600] loss: 0.015598682897247045
[Epoch 17, Batch 2700] loss: 0.008852497606067117
[Epoch 17, Batch 2800] loss: 0.009543226571869923
[Epoch 17, Batch 2900] loss: 0.011855482379856994
[Epoch 17, Batch 3000] loss: 0.009289459788878957
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0634
Validation Accuracy: 0.9865
Overfitting: 0.0634
[Epoch 18, Batch 100] loss: 0.0052288080467030795
[Epoch 18, Batch 200] loss: 0.00326788935030379
[Epoch 18, Batch 300] loss: 0.00559660048704016
[Epoch 18, Batch 400] loss: 0.003777578558491541
[Epoch 18, Batch 500] loss: 0.008710492112830934
[Epoch 18, Batch 600] loss: 0.006229934629163836
[Epoch 18, Batch 700] loss: 0.00734550091178221
[Epoch 18, Batch 800] loss: 0.001701732100176514
[Epoch 18, Batch 900] loss: 0.0027046649989620163
[Epoch 18, Batch 1000] loss: 0.0027574597975393543
[Epoch 18, Batch 1100] loss: 0.012083985923974297
[Epoch 18, Batch 1200] loss: 0.006942625846345436
[Epoch 18, Batch 1300] loss: 0.005448986928712714
[Epoch 18, Batch 1400] loss: 0.008844635664707142
[Epoch 18, Batch 1500] loss: 0.00563627551987679
[Epoch 18, Batch 1600] loss: 0.003883375614308022
[Epoch 18, Batch 1700] loss: 0.006697184327346548
[Epoch 18, Batch 1800] loss: 0.006503538379334373
[Epoch 18, Batch 1900] loss: 0.007785432431192021
[Epoch 18, Batch 2000] loss: 0.011878781733420283
[Epoch 18, Batch 2100] loss: 0.009406496721884991
[Epoch 18, Batch 2200] loss: 0.009809952672553664
[Epoch 18, Batch 2300] loss: 0.012865871732239497
[Epoch 18, Batch 2400] loss: 0.004367682648814934
[Epoch 18, Batch 2500] loss: 0.01006403684136103
[Epoch 18, Batch 2600] loss: 0.01589213825131196
[Epoch 18, Batch 2700] loss: 0.011528874178093815
[Epoch 18, Batch 2800] loss: 0.005528903842483715
[Epoch 18, Batch 2900] loss: 0.002797553693503687
[Epoch 18, Batch 3000] loss: 0.007916118723129558
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9869
Overfitting: 0.0551
[Epoch 19, Batch 100] loss: 0.003330400602675354
[Epoch 19, Batch 200] loss: 0.005406420499521118
[Epoch 19, Batch 300] loss: 0.0020510923340164313
[Epoch 19, Batch 400] loss: 0.0020138658036225367
[Epoch 19, Batch 500] loss: 0.0014954432592341504
[Epoch 19, Batch 600] loss: 0.010504622171760047
[Epoch 19, Batch 700] loss: 0.011838941675107436
[Epoch 19, Batch 800] loss: 0.01416001061595125
[Epoch 19, Batch 900] loss: 0.013855321168255158
[Epoch 19, Batch 1000] loss: 0.009566094606710181
[Epoch 19, Batch 1100] loss: 0.003996282325563243
[Epoch 19, Batch 1200] loss: 0.00682618535505469
[Epoch 19, Batch 1300] loss: 0.004358521349653302
[Epoch 19, Batch 1400] loss: 0.008070030267687116
[Epoch 19, Batch 1500] loss: 0.0037740207399679093
[Epoch 19, Batch 1600] loss: 0.009499617244911178
[Epoch 19, Batch 1700] loss: 0.004116384393804537
[Epoch 19, Batch 1800] loss: 0.0030625511755738443
[Epoch 19, Batch 1900] loss: 0.01098116123332204
[Epoch 19, Batch 2000] loss: 0.0020511830089235874
[Epoch 19, Batch 2100] loss: 0.007505760968610957
[Epoch 19, Batch 2200] loss: 0.0045547525448799316
[Epoch 19, Batch 2300] loss: 0.004314294029158532
[Epoch 19, Batch 2400] loss: 0.004484916230394731
[Epoch 19, Batch 2500] loss: 0.005126100709584307
[Epoch 19, Batch 2600] loss: 0.007411777151403385
[Epoch 19, Batch 2700] loss: 0.009680293310469778
[Epoch 19, Batch 2800] loss: 0.007658349712614978
[Epoch 19, Batch 2900] loss: 0.0024783374132363177
[Epoch 19, Batch 3000] loss: 0.006975541073357476
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0598
Validation Accuracy: 0.9855
Overfitting: 0.0598
[Epoch 20, Batch 100] loss: 0.003258391947271946
[Epoch 20, Batch 200] loss: 0.007156110818027912
[Epoch 20, Batch 300] loss: 0.00289435283865771
[Epoch 20, Batch 400] loss: 0.008255092786802934
[Epoch 20, Batch 500] loss: 0.002663686052128469
[Epoch 20, Batch 600] loss: 0.008928605482831814
[Epoch 20, Batch 700] loss: 0.005581670562420697
[Epoch 20, Batch 800] loss: 0.002335779917837613
[Epoch 20, Batch 900] loss: 0.002946106224741243
[Epoch 20, Batch 1000] loss: 0.00430937666420931
[Epoch 20, Batch 1100] loss: 0.0016199345867117642
[Epoch 20, Batch 1200] loss: 0.002130578426134093
[Epoch 20, Batch 1300] loss: 0.0017919979150698851
[Epoch 20, Batch 1400] loss: 0.000940633246540159
[Epoch 20, Batch 1500] loss: 0.0014044104539053138
[Epoch 20, Batch 1600] loss: 0.004331500720428636
[Epoch 20, Batch 1700] loss: 0.0007108059789666754
[Epoch 20, Batch 1800] loss: 0.0060237020342637495
[Epoch 20, Batch 1900] loss: 0.008844107710192475
[Epoch 20, Batch 2000] loss: 0.002714524740840716
[Epoch 20, Batch 2100] loss: 0.005477449108725239
[Epoch 20, Batch 2200] loss: 0.014742319376383648
[Epoch 20, Batch 2300] loss: 0.007488101253256048
[Epoch 20, Batch 2400] loss: 0.006330837865079815
[Epoch 20, Batch 2500] loss: 0.007421856719658697
[Epoch 20, Batch 2600] loss: 0.0033180815067859726
[Epoch 20, Batch 2700] loss: 0.0029163907372753784
[Epoch 20, Batch 2800] loss: 0.00853459674109331
[Epoch 20, Batch 2900] loss: 0.003514133165875819
[Epoch 20, Batch 3000] loss: 0.0019078679330498006
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0607
Validation Accuracy: 0.9863
Overfitting: 0.0607
[Epoch 21, Batch 100] loss: 0.0042945525332731905
[Epoch 21, Batch 200] loss: 0.0013296881307201147
[Epoch 21, Batch 300] loss: 0.0012754604188896224
[Epoch 21, Batch 400] loss: 0.0018619114507281154
[Epoch 21, Batch 500] loss: 0.0022747964072697257
[Epoch 21, Batch 600] loss: 0.00391463048964809
[Epoch 21, Batch 700] loss: 0.0058879017749134555
[Epoch 21, Batch 800] loss: 0.0024875597549680606
[Epoch 21, Batch 900] loss: 0.005538786930741822
[Epoch 21, Batch 1000] loss: 0.0036785610165514983
[Epoch 21, Batch 1100] loss: 0.0009294703781584701
[Epoch 21, Batch 1200] loss: 0.0029900882645853243
[Epoch 21, Batch 1300] loss: 0.002429949991276885
[Epoch 21, Batch 1400] loss: 0.001179038307557505
[Epoch 21, Batch 1500] loss: 0.002926293973606704
[Epoch 21, Batch 1600] loss: 0.004505372667393033
[Epoch 21, Batch 1700] loss: 0.0039060482497275117
[Epoch 21, Batch 1800] loss: 0.004723733678664601
[Epoch 21, Batch 1900] loss: 0.0037719837868769447
[Epoch 21, Batch 2000] loss: 0.003199558108024121
[Epoch 21, Batch 2100] loss: 0.005265342332777863
[Epoch 21, Batch 2200] loss: 0.0032609030203214926
[Epoch 21, Batch 2300] loss: 0.006374374957242068
[Epoch 21, Batch 2400] loss: 0.00834155897910705
[Epoch 21, Batch 2500] loss: 0.0031141250240942497
[Epoch 21, Batch 2600] loss: 0.007255809114536369
[Epoch 21, Batch 2700] loss: 0.004439144617383875
[Epoch 21, Batch 2800] loss: 0.0018572720247391316
[Epoch 21, Batch 2900] loss: 0.005591251688121588
[Epoch 21, Batch 3000] loss: 0.013874232983875032
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0644
Validation Accuracy: 0.9867
Overfitting: 0.0644
[Epoch 22, Batch 100] loss: 0.0023322027498440434
[Epoch 22, Batch 200] loss: 0.0018795452946386603
[Epoch 22, Batch 300] loss: 0.003352226656569428
[Epoch 22, Batch 400] loss: 0.0031185102775320673
[Epoch 22, Batch 500] loss: 0.0015824830155291637
[Epoch 22, Batch 600] loss: 0.0012113888114332382
[Epoch 22, Batch 700] loss: 0.0013693453935544398
[Epoch 22, Batch 800] loss: 0.0007237205773439826
[Epoch 22, Batch 900] loss: 0.0010184121422526005
[Epoch 22, Batch 1000] loss: 0.0010662272236954351
[Epoch 22, Batch 1100] loss: 0.004946096519799425
[Epoch 22, Batch 1200] loss: 0.0010274968610639946
[Epoch 22, Batch 1300] loss: 0.004156064511663829
[Epoch 22, Batch 1400] loss: 0.0036215065346360074
[Epoch 22, Batch 1500] loss: 0.002715551068501156
[Epoch 22, Batch 1600] loss: 0.003136799816335554
[Epoch 22, Batch 1700] loss: 0.0018529839353301015
[Epoch 22, Batch 1800] loss: 0.0008429672592543369
[Epoch 22, Batch 1900] loss: 0.0018909402540633379
[Epoch 22, Batch 2000] loss: 0.0015149654402005907
[Epoch 22, Batch 2100] loss: 0.0023091432576811143
[Epoch 22, Batch 2200] loss: 0.0018248499073547464
[Epoch 22, Batch 2300] loss: 0.00191025552273004
[Epoch 22, Batch 2400] loss: 0.003544307528278523
[Epoch 22, Batch 2500] loss: 0.0014698822749016926
[Epoch 22, Batch 2600] loss: 0.0024760105250142316
[Epoch 22, Batch 2700] loss: 0.001866386080373763
[Epoch 22, Batch 2800] loss: 0.0019196535252309133
[Epoch 22, Batch 2900] loss: 0.004409385384659856
[Epoch 22, Batch 3000] loss: 0.00576602736480762
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0730
Validation Accuracy: 0.9858
Overfitting: 0.0730
[Epoch 23, Batch 100] loss: 0.000723021318406154
[Epoch 23, Batch 200] loss: 0.0015446762992692698
[Epoch 23, Batch 300] loss: 0.002626262280745477
[Epoch 23, Batch 400] loss: 0.00221070182612916
[Epoch 23, Batch 500] loss: 0.00020422326860739304
[Epoch 23, Batch 600] loss: 0.0027501694715445523
[Epoch 23, Batch 700] loss: 0.0021041382351390326
[Epoch 23, Batch 800] loss: 0.0029583390510837227
[Epoch 23, Batch 900] loss: 0.0038696735595827605
[Epoch 23, Batch 1000] loss: 0.0023565198304039826
[Epoch 23, Batch 1100] loss: 0.0025930513368606968
[Epoch 23, Batch 1200] loss: 0.003197699486137244
[Epoch 23, Batch 1300] loss: 0.00045358320468452006
[Epoch 23, Batch 1400] loss: 0.0005642440635773482
[Epoch 23, Batch 1500] loss: 0.0007190512018480533
[Epoch 23, Batch 1600] loss: 0.0029253941434628583
[Epoch 23, Batch 1700] loss: 0.002200429657760168
[Epoch 23, Batch 1800] loss: 0.00498634543285263
[Epoch 23, Batch 1900] loss: 0.002650252181023571
[Epoch 23, Batch 2000] loss: 0.0006242438338277623
[Epoch 23, Batch 2100] loss: 0.001958827040669746
[Epoch 23, Batch 2200] loss: 0.005234257642666029
[Epoch 23, Batch 2300] loss: 0.003301058730446722
[Epoch 23, Batch 2400] loss: 0.0022648876596946367
[Epoch 23, Batch 2500] loss: 0.006578541870541699
[Epoch 23, Batch 2600] loss: 0.001581293137841442
[Epoch 23, Batch 2700] loss: 0.0029566536357981833
[Epoch 23, Batch 2800] loss: 0.0017350913373728183
[Epoch 23, Batch 2900] loss: 0.0019769245181090068
[Epoch 23, Batch 3000] loss: 0.015505354617536398
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0832
Validation Accuracy: 0.9851
Overfitting: 0.0832
[Epoch 24, Batch 100] loss: 0.009007355276357175
[Epoch 24, Batch 200] loss: 0.01097644355882636
[Epoch 24, Batch 300] loss: 0.003695928496586021
[Epoch 24, Batch 400] loss: 0.0020776703689488587
[Epoch 24, Batch 500] loss: 0.0021888713374893596
[Epoch 24, Batch 600] loss: 0.000575996478527383
[Epoch 24, Batch 700] loss: 0.0016493353197068927
[Epoch 24, Batch 800] loss: 0.002692704321743378
[Epoch 24, Batch 900] loss: 0.004174301240295648
[Epoch 24, Batch 1000] loss: 0.00993024327259633
[Epoch 24, Batch 1100] loss: 0.0047874879262580095
[Epoch 24, Batch 1200] loss: 0.016782835002818075
[Epoch 24, Batch 1300] loss: 0.0018033314621021645
[Epoch 24, Batch 1400] loss: 0.006873399744480296
[Epoch 24, Batch 1500] loss: 0.003951394456440199
[Epoch 24, Batch 1600] loss: 0.004586584117580355
[Epoch 24, Batch 1700] loss: 0.001439604910423924
[Epoch 24, Batch 1800] loss: 0.0026590033595136476
[Epoch 24, Batch 1900] loss: 0.006046789399819162
[Epoch 24, Batch 2000] loss: 0.0018565821083525692
[Epoch 24, Batch 2100] loss: 0.0018249544953638974
[Epoch 24, Batch 2200] loss: 0.0017170718616287672
[Epoch 24, Batch 2300] loss: 0.0022427594334175184
[Epoch 24, Batch 2400] loss: 0.0038977081161552006
[Epoch 24, Batch 2500] loss: 0.004792071985619444
[Epoch 24, Batch 2600] loss: 0.00268933606309564
[Epoch 24, Batch 2700] loss: 0.0034353832503634684
[Epoch 24, Batch 2800] loss: 0.009560972992102705
[Epoch 24, Batch 2900] loss: 0.007559331100216511
[Epoch 24, Batch 3000] loss: 0.0005492870877080235
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0589
Validation Accuracy: 0.9884
Overfitting: 0.0589
Fold 2 validation loss: 0.0589
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2864343333244324
[Epoch 1, Batch 200] loss: 2.144352341890335
[Epoch 1, Batch 300] loss: 1.2033054685592652
[Epoch 1, Batch 400] loss: 0.6517168540507555
[Epoch 1, Batch 500] loss: 0.44294938936829564
[Epoch 1, Batch 600] loss: 0.37309977278113365
[Epoch 1, Batch 700] loss: 0.3259127974137664
[Epoch 1, Batch 800] loss: 0.2801566046476364
[Epoch 1, Batch 900] loss: 0.25808429218828677
[Epoch 1, Batch 1000] loss: 0.21920559413731097
[Epoch 1, Batch 1100] loss: 0.19864205421414227
[Epoch 1, Batch 1200] loss: 0.22035945845767857
[Epoch 1, Batch 1300] loss: 0.2059371121833101
[Epoch 1, Batch 1400] loss: 0.17544354185461997
[Epoch 1, Batch 1500] loss: 0.15759892229922115
[Epoch 1, Batch 1600] loss: 0.15186864691786467
[Epoch 1, Batch 1700] loss: 0.17300297102658077
[Epoch 1, Batch 1800] loss: 0.1478492048289627
[Epoch 1, Batch 1900] loss: 0.1498642011731863
[Epoch 1, Batch 2000] loss: 0.15477813803125173
[Epoch 1, Batch 2100] loss: 0.1480609841272235
[Epoch 1, Batch 2200] loss: 0.13093134864931927
[Epoch 1, Batch 2300] loss: 0.11912271725479513
[Epoch 1, Batch 2400] loss: 0.11747992296237499
[Epoch 1, Batch 2500] loss: 0.08166031833738088
[Epoch 1, Batch 2600] loss: 0.11812315789982676
[Epoch 1, Batch 2700] loss: 0.1085482268128544
[Epoch 1, Batch 2800] loss: 0.11779836812522262
[Epoch 1, Batch 2900] loss: 0.08828976226272062
[Epoch 1, Batch 3000] loss: 0.11622808862943203
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1186
Validation Accuracy: 0.9636
Overfitting: 0.1186
Best model saved at epoch 1 with validation loss: 0.1186
[Epoch 2, Batch 100] loss: 0.09021367590408773
[Epoch 2, Batch 200] loss: 0.10815780306234955
[Epoch 2, Batch 300] loss: 0.10453007609583437
[Epoch 2, Batch 400] loss: 0.09220652286894619
[Epoch 2, Batch 500] loss: 0.09105198316159659
[Epoch 2, Batch 600] loss: 0.06877592934528366
[Epoch 2, Batch 700] loss: 0.08896329205483199
[Epoch 2, Batch 800] loss: 0.08424984659068287
[Epoch 2, Batch 900] loss: 0.0735975573095493
[Epoch 2, Batch 1000] loss: 0.09451302002882585
[Epoch 2, Batch 1100] loss: 0.1016919433977455
[Epoch 2, Batch 1200] loss: 0.07186143774422817
[Epoch 2, Batch 1300] loss: 0.07250091284688097
[Epoch 2, Batch 1400] loss: 0.0934905555343721
[Epoch 2, Batch 1500] loss: 0.08391048502875492
[Epoch 2, Batch 1600] loss: 0.086189136976609
[Epoch 2, Batch 1700] loss: 0.0744300340511836
[Epoch 2, Batch 1800] loss: 0.07443475548207061
[Epoch 2, Batch 1900] loss: 0.0884710864094086
[Epoch 2, Batch 2000] loss: 0.09088176643592305
[Epoch 2, Batch 2100] loss: 0.06955585335555953
[Epoch 2, Batch 2200] loss: 0.0760891818010714
[Epoch 2, Batch 2300] loss: 0.07649595498340205
[Epoch 2, Batch 2400] loss: 0.07155774265178479
[Epoch 2, Batch 2500] loss: 0.05611206093832152
[Epoch 2, Batch 2600] loss: 0.08579150557168759
[Epoch 2, Batch 2700] loss: 0.07842190039693378
[Epoch 2, Batch 2800] loss: 0.07209522221703082
[Epoch 2, Batch 2900] loss: 0.06530010869493708
[Epoch 2, Batch 3000] loss: 0.06706579574150964
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0767
Validation Accuracy: 0.9771
Overfitting: 0.0767
Best model saved at epoch 2 with validation loss: 0.0767
[Epoch 3, Batch 100] loss: 0.06231121221440844
[Epoch 3, Batch 200] loss: 0.06410833697707857
[Epoch 3, Batch 300] loss: 0.040173341961344707
[Epoch 3, Batch 400] loss: 0.04618227132363245
[Epoch 3, Batch 500] loss: 0.06646216400986305
[Epoch 3, Batch 600] loss: 0.06373664696264314
[Epoch 3, Batch 700] loss: 0.06460988328501116
[Epoch 3, Batch 800] loss: 0.06634682373260148
[Epoch 3, Batch 900] loss: 0.057813257760135454
[Epoch 3, Batch 1000] loss: 0.06279490808898118
[Epoch 3, Batch 1100] loss: 0.05027303953043884
[Epoch 3, Batch 1200] loss: 0.040539900184085126
[Epoch 3, Batch 1300] loss: 0.0817077842791332
[Epoch 3, Batch 1400] loss: 0.0660023946093861
[Epoch 3, Batch 1500] loss: 0.04113331039989134
[Epoch 3, Batch 1600] loss: 0.040237647583708167
[Epoch 3, Batch 1700] loss: 0.06336807499086718
[Epoch 3, Batch 1800] loss: 0.04201228159305174
[Epoch 3, Batch 1900] loss: 0.05807032209588215
[Epoch 3, Batch 2000] loss: 0.05944106036506128
[Epoch 3, Batch 2100] loss: 0.06502394130657194
[Epoch 3, Batch 2200] loss: 0.03914389547688188
[Epoch 3, Batch 2300] loss: 0.05256202112446772
[Epoch 3, Batch 2400] loss: 0.05134575087402481
[Epoch 3, Batch 2500] loss: 0.06221430330188014
[Epoch 3, Batch 2600] loss: 0.06423601354123093
[Epoch 3, Batch 2700] loss: 0.04915676954784431
[Epoch 3, Batch 2800] loss: 0.05593889425028465
[Epoch 3, Batch 2900] loss: 0.056486943837662694
[Epoch 3, Batch 3000] loss: 0.04888567238202086
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0660
Validation Accuracy: 0.9808
Overfitting: 0.0660
Best model saved at epoch 3 with validation loss: 0.0660
[Epoch 4, Batch 100] loss: 0.043567346058553086
[Epoch 4, Batch 200] loss: 0.043531964425055775
[Epoch 4, Batch 300] loss: 0.03620804603589931
[Epoch 4, Batch 400] loss: 0.03875050095230108
[Epoch 4, Batch 500] loss: 0.040370604282652496
[Epoch 4, Batch 600] loss: 0.039420064686855764
[Epoch 4, Batch 700] loss: 0.04809651058749296
[Epoch 4, Batch 800] loss: 0.06034982026088983
[Epoch 4, Batch 900] loss: 0.04476225427584723
[Epoch 4, Batch 1000] loss: 0.049584372654353503
[Epoch 4, Batch 1100] loss: 0.04687629405030748
[Epoch 4, Batch 1200] loss: 0.04655603736522607
[Epoch 4, Batch 1300] loss: 0.05255704788782168
[Epoch 4, Batch 1400] loss: 0.03406893004765152
[Epoch 4, Batch 1500] loss: 0.0375885993486736
[Epoch 4, Batch 1600] loss: 0.05729871784627903
[Epoch 4, Batch 1700] loss: 0.05285443143598968
[Epoch 4, Batch 1800] loss: 0.05497851143009029
[Epoch 4, Batch 1900] loss: 0.03747897976834793
[Epoch 4, Batch 2000] loss: 0.050305141523422206
[Epoch 4, Batch 2100] loss: 0.043130345482204575
[Epoch 4, Batch 2200] loss: 0.04254345001332695
[Epoch 4, Batch 2300] loss: 0.05821591549145524
[Epoch 4, Batch 2400] loss: 0.03351881641050568
[Epoch 4, Batch 2500] loss: 0.043775511978092256
[Epoch 4, Batch 2600] loss: 0.04353183027720661
[Epoch 4, Batch 2700] loss: 0.04003712674224516
[Epoch 4, Batch 2800] loss: 0.0482306598341529
[Epoch 4, Batch 2900] loss: 0.024073683163296663
[Epoch 4, Batch 3000] loss: 0.049960447136109
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9825
Overfitting: 0.0567
Best model saved at epoch 4 with validation loss: 0.0567
[Epoch 5, Batch 100] loss: 0.043552381438639716
[Epoch 5, Batch 200] loss: 0.021967334070395736
[Epoch 5, Batch 300] loss: 0.04410657891989103
[Epoch 5, Batch 400] loss: 0.044527740556150094
[Epoch 5, Batch 500] loss: 0.03675727814403217
[Epoch 5, Batch 600] loss: 0.03577649137063418
[Epoch 5, Batch 700] loss: 0.03801345586580283
[Epoch 5, Batch 800] loss: 0.047192762508930175
[Epoch 5, Batch 900] loss: 0.03722851618324057
[Epoch 5, Batch 1000] loss: 0.053973147681099364
[Epoch 5, Batch 1100] loss: 0.02705584832787281
[Epoch 5, Batch 1200] loss: 0.03019212530052755
[Epoch 5, Batch 1300] loss: 0.04910722269400139
[Epoch 5, Batch 1400] loss: 0.02787484943619347
[Epoch 5, Batch 1500] loss: 0.03693159458081936
[Epoch 5, Batch 1600] loss: 0.033451443001977166
[Epoch 5, Batch 1700] loss: 0.036904357876628636
[Epoch 5, Batch 1800] loss: 0.045138607987901196
[Epoch 5, Batch 1900] loss: 0.05504276542087609
[Epoch 5, Batch 2000] loss: 0.03419664159679087
[Epoch 5, Batch 2100] loss: 0.02420561175531475
[Epoch 5, Batch 2200] loss: 0.03474765868508257
[Epoch 5, Batch 2300] loss: 0.038958071931556336
[Epoch 5, Batch 2400] loss: 0.03794086620066082
[Epoch 5, Batch 2500] loss: 0.019788485372555443
[Epoch 5, Batch 2600] loss: 0.03505693786588381
[Epoch 5, Batch 2700] loss: 0.01941822876186052
[Epoch 5, Batch 2800] loss: 0.03450654573905922
[Epoch 5, Batch 2900] loss: 0.030389592065839677
[Epoch 5, Batch 3000] loss: 0.05552891638624715
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9839
Overfitting: 0.0546
Best model saved at epoch 5 with validation loss: 0.0546
[Epoch 6, Batch 100] loss: 0.024922261320534746
[Epoch 6, Batch 200] loss: 0.030542009975724795
[Epoch 6, Batch 300] loss: 0.041754906956011834
[Epoch 6, Batch 400] loss: 0.029461030972815935
[Epoch 6, Batch 500] loss: 0.026704530107654136
[Epoch 6, Batch 600] loss: 0.027997637886510347
[Epoch 6, Batch 700] loss: 0.02454282473961939
[Epoch 6, Batch 800] loss: 0.033277381931839045
[Epoch 6, Batch 900] loss: 0.026714940227320766
[Epoch 6, Batch 1000] loss: 0.022830870082507317
[Epoch 6, Batch 1100] loss: 0.02276643387871445
[Epoch 6, Batch 1200] loss: 0.03217606800768408
[Epoch 6, Batch 1300] loss: 0.03298586077733489
[Epoch 6, Batch 1400] loss: 0.0306998556558392
[Epoch 6, Batch 1500] loss: 0.033927525315521054
[Epoch 6, Batch 1600] loss: 0.026581237365062408
[Epoch 6, Batch 1700] loss: 0.030354682936340395
[Epoch 6, Batch 1800] loss: 0.019917943406762787
[Epoch 6, Batch 1900] loss: 0.03321739457867807
[Epoch 6, Batch 2000] loss: 0.030891032474901294
[Epoch 6, Batch 2100] loss: 0.0376542009509285
[Epoch 6, Batch 2200] loss: 0.04414325379766524
[Epoch 6, Batch 2300] loss: 0.026157814506732394
[Epoch 6, Batch 2400] loss: 0.03179640292641125
[Epoch 6, Batch 2500] loss: 0.03126658086774114
[Epoch 6, Batch 2600] loss: 0.04217589312363998
[Epoch 6, Batch 2700] loss: 0.031613734864076835
[Epoch 6, Batch 2800] loss: 0.035474023207061695
[Epoch 6, Batch 2900] loss: 0.03025450565306528
[Epoch 6, Batch 3000] loss: 0.023249486854474526
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0661
Validation Accuracy: 0.9820
Overfitting: 0.0661
[Epoch 7, Batch 100] loss: 0.024365950159553906
[Epoch 7, Batch 200] loss: 0.019184179185394896
[Epoch 7, Batch 300] loss: 0.020083295831427678
[Epoch 7, Batch 400] loss: 0.027326833271872603
[Epoch 7, Batch 500] loss: 0.027340582257384085
[Epoch 7, Batch 600] loss: 0.025945839692576557
[Epoch 7, Batch 700] loss: 0.011394868957358995
[Epoch 7, Batch 800] loss: 0.01857458227330426
[Epoch 7, Batch 900] loss: 0.02160870473500836
[Epoch 7, Batch 1000] loss: 0.02938077816516852
[Epoch 7, Batch 1100] loss: 0.024441468383993196
[Epoch 7, Batch 1200] loss: 0.026717645255266688
[Epoch 7, Batch 1300] loss: 0.024052313415086245
[Epoch 7, Batch 1400] loss: 0.04283668108102574
[Epoch 7, Batch 1500] loss: 0.025735289238655243
[Epoch 7, Batch 1600] loss: 0.02390342707862146
[Epoch 7, Batch 1700] loss: 0.019775869434088236
[Epoch 7, Batch 1800] loss: 0.030452062479271264
[Epoch 7, Batch 1900] loss: 0.01736261170898615
[Epoch 7, Batch 2000] loss: 0.03197278578216355
[Epoch 7, Batch 2100] loss: 0.025563637629093135
[Epoch 7, Batch 2200] loss: 0.02560706355048751
[Epoch 7, Batch 2300] loss: 0.029719216486009826
[Epoch 7, Batch 2400] loss: 0.016357313168700784
[Epoch 7, Batch 2500] loss: 0.03552600503557187
[Epoch 7, Batch 2600] loss: 0.01879213871925458
[Epoch 7, Batch 2700] loss: 0.03131815685279435
[Epoch 7, Batch 2800] loss: 0.019672931122859155
[Epoch 7, Batch 2900] loss: 0.032318439286391366
[Epoch 7, Batch 3000] loss: 0.029705707106040792
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9852
Overfitting: 0.0489
Best model saved at epoch 7 with validation loss: 0.0489
[Epoch 8, Batch 100] loss: 0.03394077161145106
[Epoch 8, Batch 200] loss: 0.022593246061369428
[Epoch 8, Batch 300] loss: 0.0143925516748277
[Epoch 8, Batch 400] loss: 0.02864750990309403
[Epoch 8, Batch 500] loss: 0.01353599014932115
[Epoch 8, Batch 600] loss: 0.023932260460205725
[Epoch 8, Batch 700] loss: 0.01934022844889114
[Epoch 8, Batch 800] loss: 0.02321329840362523
[Epoch 8, Batch 900] loss: 0.025026653007880668
[Epoch 8, Batch 1000] loss: 0.0220675033736552
[Epoch 8, Batch 1100] loss: 0.023234929216923775
[Epoch 8, Batch 1200] loss: 0.012513663810750586
[Epoch 8, Batch 1300] loss: 0.01887396547899698
[Epoch 8, Batch 1400] loss: 0.010929860981559614
[Epoch 8, Batch 1500] loss: 0.012748773983657884
[Epoch 8, Batch 1600] loss: 0.02463569780542457
[Epoch 8, Batch 1700] loss: 0.022125463661004686
[Epoch 8, Batch 1800] loss: 0.02173186301579335
[Epoch 8, Batch 1900] loss: 0.023271291256760376
[Epoch 8, Batch 2000] loss: 0.027722776120535853
[Epoch 8, Batch 2100] loss: 0.0238496498256427
[Epoch 8, Batch 2200] loss: 0.029384485082700848
[Epoch 8, Batch 2300] loss: 0.014354929980891029
[Epoch 8, Batch 2400] loss: 0.024719919482904515
[Epoch 8, Batch 2500] loss: 0.03373668438616732
[Epoch 8, Batch 2600] loss: 0.018476212079549442
[Epoch 8, Batch 2700] loss: 0.02598095263828327
[Epoch 8, Batch 2800] loss: 0.03608874972420381
[Epoch 8, Batch 2900] loss: 0.016220763736218943
[Epoch 8, Batch 3000] loss: 0.022725865075481123
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9848
Overfitting: 0.0556
[Epoch 9, Batch 100] loss: 0.009009365861984406
[Epoch 9, Batch 200] loss: 0.026438752006561116
[Epoch 9, Batch 300] loss: 0.01287068122488563
[Epoch 9, Batch 400] loss: 0.021984106258896643
[Epoch 9, Batch 500] loss: 0.027839957418291306
[Epoch 9, Batch 600] loss: 0.012232126843082369
[Epoch 9, Batch 700] loss: 0.01390336141035732
[Epoch 9, Batch 800] loss: 0.011806793426367222
[Epoch 9, Batch 900] loss: 0.01657932685006017
[Epoch 9, Batch 1000] loss: 0.02113425049901707
[Epoch 9, Batch 1100] loss: 0.012294025792361935
[Epoch 9, Batch 1200] loss: 0.02448953067898401
[Epoch 9, Batch 1300] loss: 0.020037254343678798
[Epoch 9, Batch 1400] loss: 0.009202923379489221
[Epoch 9, Batch 1500] loss: 0.013214605910925457
[Epoch 9, Batch 1600] loss: 0.02076158963416674
[Epoch 9, Batch 1700] loss: 0.018193529116288118
[Epoch 9, Batch 1800] loss: 0.014902428026161943
[Epoch 9, Batch 1900] loss: 0.021276872431881203
[Epoch 9, Batch 2000] loss: 0.011168353983521229
[Epoch 9, Batch 2100] loss: 0.026253094762505497
[Epoch 9, Batch 2200] loss: 0.023222042942124974
[Epoch 9, Batch 2300] loss: 0.020986952986550022
[Epoch 9, Batch 2400] loss: 0.015229307314202743
[Epoch 9, Batch 2500] loss: 0.023603945830107022
[Epoch 9, Batch 2600] loss: 0.03050083632235328
[Epoch 9, Batch 2700] loss: 0.024484351029386744
[Epoch 9, Batch 2800] loss: 0.03395209022990457
[Epoch 9, Batch 2900] loss: 0.017419526006488013
[Epoch 9, Batch 3000] loss: 0.021601723207604662
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9857
Overfitting: 0.0485
Best model saved at epoch 9 with validation loss: 0.0485
[Epoch 10, Batch 100] loss: 0.010481537307277904
[Epoch 10, Batch 200] loss: 0.011524918272443755
[Epoch 10, Batch 300] loss: 0.022286419386400667
[Epoch 10, Batch 400] loss: 0.010350445605477035
[Epoch 10, Batch 500] loss: 0.015682615859259386
[Epoch 10, Batch 600] loss: 0.007402592824000749
[Epoch 10, Batch 700] loss: 0.006481666705603857
[Epoch 10, Batch 800] loss: 0.02600296104192239
[Epoch 10, Batch 900] loss: 0.017816145053629953
[Epoch 10, Batch 1000] loss: 0.018701600491144745
[Epoch 10, Batch 1100] loss: 0.02535716521408176
[Epoch 10, Batch 1200] loss: 0.030483084984334708
[Epoch 10, Batch 1300] loss: 0.010862730662793182
[Epoch 10, Batch 1400] loss: 0.016656676590118876
[Epoch 10, Batch 1500] loss: 0.016555844471022284
[Epoch 10, Batch 1600] loss: 0.01730024741438683
[Epoch 10, Batch 1700] loss: 0.020678163489592408
[Epoch 10, Batch 1800] loss: 0.008956591735109215
[Epoch 10, Batch 1900] loss: 0.014380568267533818
[Epoch 10, Batch 2000] loss: 0.02105835426165868
[Epoch 10, Batch 2100] loss: 0.011060764985036258
[Epoch 10, Batch 2200] loss: 0.022859187276098966
[Epoch 10, Batch 2300] loss: 0.019266426043905084
[Epoch 10, Batch 2400] loss: 0.014958376078661786
[Epoch 10, Batch 2500] loss: 0.00866772931588912
[Epoch 10, Batch 2600] loss: 0.010546165777786881
[Epoch 10, Batch 2700] loss: 0.019513781627988464
[Epoch 10, Batch 2800] loss: 0.01730731431300228
[Epoch 10, Batch 2900] loss: 0.01154474680635758
[Epoch 10, Batch 3000] loss: 0.01613023685566077
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0443
Validation Accuracy: 0.9882
Overfitting: 0.0443
Best model saved at epoch 10 with validation loss: 0.0443
[Epoch 11, Batch 100] loss: 0.005674048464402404
[Epoch 11, Batch 200] loss: 0.014919553340796483
[Epoch 11, Batch 300] loss: 0.019024503082018782
[Epoch 11, Batch 400] loss: 0.011664959957251995
[Epoch 11, Batch 500] loss: 0.021378730265350896
[Epoch 11, Batch 600] loss: 0.01513585554619567
[Epoch 11, Batch 700] loss: 0.012205879009904948
[Epoch 11, Batch 800] loss: 0.011557428626219916
[Epoch 11, Batch 900] loss: 0.008892584828918188
[Epoch 11, Batch 1000] loss: 0.006478768998488249
[Epoch 11, Batch 1100] loss: 0.01458915716753836
[Epoch 11, Batch 1200] loss: 0.009594819881538683
[Epoch 11, Batch 1300] loss: 0.014389936655481961
[Epoch 11, Batch 1400] loss: 0.010461393967252661
[Epoch 11, Batch 1500] loss: 0.02055485157716248
[Epoch 11, Batch 1600] loss: 0.024855722746369793
[Epoch 11, Batch 1700] loss: 0.024782927196647507
[Epoch 11, Batch 1800] loss: 0.013928958279484505
[Epoch 11, Batch 1900] loss: 0.015902332910563928
[Epoch 11, Batch 2000] loss: 0.016100951470143628
[Epoch 11, Batch 2100] loss: 0.010158397923660231
[Epoch 11, Batch 2200] loss: 0.012917525771081273
[Epoch 11, Batch 2300] loss: 0.023948033161582317
[Epoch 11, Batch 2400] loss: 0.017053843605990552
[Epoch 11, Batch 2500] loss: 0.016960620336994907
[Epoch 11, Batch 2600] loss: 0.02609987286231217
[Epoch 11, Batch 2700] loss: 0.01898368800922526
[Epoch 11, Batch 2800] loss: 0.007007736140039924
[Epoch 11, Batch 2900] loss: 0.017876644492491777
[Epoch 11, Batch 3000] loss: 0.009078188454204793
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9870
Overfitting: 0.0472
[Epoch 12, Batch 100] loss: 0.018805966776581043
[Epoch 12, Batch 200] loss: 0.012903519899782622
[Epoch 12, Batch 300] loss: 0.007498639304876633
[Epoch 12, Batch 400] loss: 0.0070169524014909255
[Epoch 12, Batch 500] loss: 0.020896557943160587
[Epoch 12, Batch 600] loss: 0.013613724843958152
[Epoch 12, Batch 700] loss: 0.00940292238407892
[Epoch 12, Batch 800] loss: 0.008159654226128623
[Epoch 12, Batch 900] loss: 0.010655367603530976
[Epoch 12, Batch 1000] loss: 0.017283765174333894
[Epoch 12, Batch 1100] loss: 0.018017810258706957
[Epoch 12, Batch 1200] loss: 0.013012117174685044
[Epoch 12, Batch 1300] loss: 0.01059327775872589
[Epoch 12, Batch 1400] loss: 0.014535618705117485
[Epoch 12, Batch 1500] loss: 0.01021537518956393
[Epoch 12, Batch 1600] loss: 0.012708388121382086
[Epoch 12, Batch 1700] loss: 0.010379950055512382
[Epoch 12, Batch 1800] loss: 0.014118765981145316
[Epoch 12, Batch 1900] loss: 0.005566957584219381
[Epoch 12, Batch 2000] loss: 0.008546526842665117
[Epoch 12, Batch 2100] loss: 0.018875325564204105
[Epoch 12, Batch 2200] loss: 0.008651304432241887
[Epoch 12, Batch 2300] loss: 0.006526735454829122
[Epoch 12, Batch 2400] loss: 0.013907704498969907
[Epoch 12, Batch 2500] loss: 0.021957562042616702
[Epoch 12, Batch 2600] loss: 0.009234053023542401
[Epoch 12, Batch 2700] loss: 0.012797713206416574
[Epoch 12, Batch 2800] loss: 0.016591124034639505
[Epoch 12, Batch 2900] loss: 0.01827739672337657
[Epoch 12, Batch 3000] loss: 0.015603016951226891
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0433
Validation Accuracy: 0.9883
Overfitting: 0.0433
Best model saved at epoch 12 with validation loss: 0.0433
[Epoch 13, Batch 100] loss: 0.008016201003333662
[Epoch 13, Batch 200] loss: 0.00743994556906955
[Epoch 13, Batch 300] loss: 0.013344392783837975
[Epoch 13, Batch 400] loss: 0.009168874920596863
[Epoch 13, Batch 500] loss: 0.007067808785068337
[Epoch 13, Batch 600] loss: 0.010066284853578508
[Epoch 13, Batch 700] loss: 0.006831079455421332
[Epoch 13, Batch 800] loss: 0.005778105448523547
[Epoch 13, Batch 900] loss: 0.008896454752184582
[Epoch 13, Batch 1000] loss: 0.013468304185196303
[Epoch 13, Batch 1100] loss: 0.013047311777694404
[Epoch 13, Batch 1200] loss: 0.006502193100877776
[Epoch 13, Batch 1300] loss: 0.011399614513586585
[Epoch 13, Batch 1400] loss: 0.007187844542222592
[Epoch 13, Batch 1500] loss: 0.004419856779885549
[Epoch 13, Batch 1600] loss: 0.003275953575625863
[Epoch 13, Batch 1700] loss: 0.009573704488674365
[Epoch 13, Batch 1800] loss: 0.004307105269872409
[Epoch 13, Batch 1900] loss: 0.022085896371162334
[Epoch 13, Batch 2000] loss: 0.010949253271687666
[Epoch 13, Batch 2100] loss: 0.012433480083959694
[Epoch 13, Batch 2200] loss: 0.00905241970822317
[Epoch 13, Batch 2300] loss: 0.011643855533579881
[Epoch 13, Batch 2400] loss: 0.014459240748794854
[Epoch 13, Batch 2500] loss: 0.030682209935839637
[Epoch 13, Batch 2600] loss: 0.010662970290868544
[Epoch 13, Batch 2700] loss: 0.013503850635524941
[Epoch 13, Batch 2800] loss: 0.014568286155190435
[Epoch 13, Batch 2900] loss: 0.016134844511088885
[Epoch 13, Batch 3000] loss: 0.013177507072389289
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9875
Overfitting: 0.0497
[Epoch 14, Batch 100] loss: 0.00998143760367384
[Epoch 14, Batch 200] loss: 0.004280397774850826
[Epoch 14, Batch 300] loss: 0.00857520070596479
[Epoch 14, Batch 400] loss: 0.011299257796725897
[Epoch 14, Batch 500] loss: 0.004449704383846438
[Epoch 14, Batch 600] loss: 0.004432486423013415
[Epoch 14, Batch 700] loss: 0.007180967178478568
[Epoch 14, Batch 800] loss: 0.0029711956672031194
[Epoch 14, Batch 900] loss: 0.011188482418247644
[Epoch 14, Batch 1000] loss: 0.018281114159481148
[Epoch 14, Batch 1100] loss: 0.005681610625929352
[Epoch 14, Batch 1200] loss: 0.010482882096266622
[Epoch 14, Batch 1300] loss: 0.006264956059387714
[Epoch 14, Batch 1400] loss: 0.009916101358878677
[Epoch 14, Batch 1500] loss: 0.006520641479814912
[Epoch 14, Batch 1600] loss: 0.010048421098001654
[Epoch 14, Batch 1700] loss: 0.008490427993777985
[Epoch 14, Batch 1800] loss: 0.005621021346616715
[Epoch 14, Batch 1900] loss: 0.0072283393759175855
[Epoch 14, Batch 2000] loss: 0.010784407023968469
[Epoch 14, Batch 2100] loss: 0.008949896445179774
[Epoch 14, Batch 2200] loss: 0.006775365659568706
[Epoch 14, Batch 2300] loss: 0.0068283115047256615
[Epoch 14, Batch 2400] loss: 0.0037351520260369853
[Epoch 14, Batch 2500] loss: 0.008306168200343791
[Epoch 14, Batch 2600] loss: 0.008074345253728552
[Epoch 14, Batch 2700] loss: 0.00857943328421868
[Epoch 14, Batch 2800] loss: 0.009381389041467401
[Epoch 14, Batch 2900] loss: 0.008057728636007368
[Epoch 14, Batch 3000] loss: 0.0072617766844518886
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9881
Overfitting: 0.0486
[Epoch 15, Batch 100] loss: 0.0068367983551740966
[Epoch 15, Batch 200] loss: 0.008794548084965754
[Epoch 15, Batch 300] loss: 0.006993952011951024
[Epoch 15, Batch 400] loss: 0.010011760977765221
[Epoch 15, Batch 500] loss: 0.005805325251617433
[Epoch 15, Batch 600] loss: 0.005728784255296091
[Epoch 15, Batch 700] loss: 0.0030234396208163616
[Epoch 15, Batch 800] loss: 0.004298005043841613
[Epoch 15, Batch 900] loss: 0.006157570447212493
[Epoch 15, Batch 1000] loss: 0.0033111396971719385
[Epoch 15, Batch 1100] loss: 0.0047106757753965665
[Epoch 15, Batch 1200] loss: 0.008736935527663263
[Epoch 15, Batch 1300] loss: 0.0029675151801308174
[Epoch 15, Batch 1400] loss: 0.009666639671107192
[Epoch 15, Batch 1500] loss: 0.004961552018996827
[Epoch 15, Batch 1600] loss: 0.006505790908324798
[Epoch 15, Batch 1700] loss: 0.010374470310982814
[Epoch 15, Batch 1800] loss: 0.009362555860829786
[Epoch 15, Batch 1900] loss: 0.0052330656690963906
[Epoch 15, Batch 2000] loss: 0.01399740157446331
[Epoch 15, Batch 2100] loss: 0.015032730148835754
[Epoch 15, Batch 2200] loss: 0.007083555908641301
[Epoch 15, Batch 2300] loss: 0.002677416286520611
[Epoch 15, Batch 2400] loss: 0.010263025548782707
[Epoch 15, Batch 2500] loss: 0.009303610182654439
[Epoch 15, Batch 2600] loss: 0.004164120102041124
[Epoch 15, Batch 2700] loss: 0.012757234030524955
[Epoch 15, Batch 2800] loss: 0.00633368785522876
[Epoch 15, Batch 2900] loss: 0.012061474949834974
[Epoch 15, Batch 3000] loss: 0.005282999872293886
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9883
Overfitting: 0.0496
[Epoch 16, Batch 100] loss: 0.01004362808728274
[Epoch 16, Batch 200] loss: 0.012211716861456808
[Epoch 16, Batch 300] loss: 0.008835307030496438
[Epoch 16, Batch 400] loss: 0.008774646298047629
[Epoch 16, Batch 500] loss: 0.0027392332498214957
[Epoch 16, Batch 600] loss: 0.0015687163974330077
[Epoch 16, Batch 700] loss: 0.002794557016027426
[Epoch 16, Batch 800] loss: 0.006828529512704335
[Epoch 16, Batch 900] loss: 0.009778154908879202
[Epoch 16, Batch 1000] loss: 0.007090243345056706
[Epoch 16, Batch 1100] loss: 0.005462720568596069
[Epoch 16, Batch 1200] loss: 0.008414868182034638
[Epoch 16, Batch 1300] loss: 0.008231888470121476
[Epoch 16, Batch 1400] loss: 0.003746595220524114
[Epoch 16, Batch 1500] loss: 0.005707593418874524
[Epoch 16, Batch 1600] loss: 0.003276021901610875
[Epoch 16, Batch 1700] loss: 0.01121750712355805
[Epoch 16, Batch 1800] loss: 0.010737433470521297
[Epoch 16, Batch 1900] loss: 0.005012694613283202
[Epoch 16, Batch 2000] loss: 0.013895601085475278
[Epoch 16, Batch 2100] loss: 0.006664341316117373
[Epoch 16, Batch 2200] loss: 0.003933305899121251
[Epoch 16, Batch 2300] loss: 0.012539458294105259
[Epoch 16, Batch 2400] loss: 0.005839448319879353
[Epoch 16, Batch 2500] loss: 0.004759239131495292
[Epoch 16, Batch 2600] loss: 0.011976332530973082
[Epoch 16, Batch 2700] loss: 0.006005078103416963
[Epoch 16, Batch 2800] loss: 0.013681261606634507
[Epoch 16, Batch 2900] loss: 0.016056620624345895
[Epoch 16, Batch 3000] loss: 0.01878183853082987
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0604
Validation Accuracy: 0.9866
Overfitting: 0.0604
[Epoch 17, Batch 100] loss: 0.016762034942209993
[Epoch 17, Batch 200] loss: 0.007843390393295522
[Epoch 17, Batch 300] loss: 0.005004203643440519
[Epoch 17, Batch 400] loss: 0.005602937041296627
[Epoch 17, Batch 500] loss: 0.010138436072811601
[Epoch 17, Batch 600] loss: 0.008912109950134663
[Epoch 17, Batch 700] loss: 0.006837473664622848
[Epoch 17, Batch 800] loss: 0.016262421356177583
[Epoch 17, Batch 900] loss: 0.008875068057256498
[Epoch 17, Batch 1000] loss: 0.007019088323264668
[Epoch 17, Batch 1100] loss: 0.012316353010049567
[Epoch 17, Batch 1200] loss: 0.006484106491241164
[Epoch 17, Batch 1300] loss: 0.006378171729829773
[Epoch 17, Batch 1400] loss: 0.007368748077403779
[Epoch 17, Batch 1500] loss: 0.005529543287479725
[Epoch 17, Batch 1600] loss: 0.00814022254187421
[Epoch 17, Batch 1700] loss: 0.012453752709820378
[Epoch 17, Batch 1800] loss: 0.009623920549122431
[Epoch 17, Batch 1900] loss: 0.003840801129867373
[Epoch 17, Batch 2000] loss: 0.01330587691446226
[Epoch 17, Batch 2100] loss: 0.006562030501238496
[Epoch 17, Batch 2200] loss: 0.008093636665843179
[Epoch 17, Batch 2300] loss: 0.0035108465129289356
[Epoch 17, Batch 2400] loss: 0.015410024411083896
[Epoch 17, Batch 2500] loss: 0.011783067005761722
[Epoch 17, Batch 2600] loss: 0.006070786620178126
[Epoch 17, Batch 2700] loss: 0.013131325446777283
[Epoch 17, Batch 2800] loss: 0.002938079143025334
[Epoch 17, Batch 2900] loss: 0.01316044049460288
[Epoch 17, Batch 3000] loss: 0.012050165135833594
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9887
Overfitting: 0.0490
[Epoch 18, Batch 100] loss: 0.006462388665004255
[Epoch 18, Batch 200] loss: 0.004283371921540606
[Epoch 18, Batch 300] loss: 0.002643322761391005
[Epoch 18, Batch 400] loss: 0.007328521053792087
[Epoch 18, Batch 500] loss: 0.00918397806664018
[Epoch 18, Batch 600] loss: 0.005411522623339806
[Epoch 18, Batch 700] loss: 0.006625136155290648
[Epoch 18, Batch 800] loss: 0.011477003608141557
[Epoch 18, Batch 900] loss: 0.00913916519156146
[Epoch 18, Batch 1000] loss: 0.004985559128379009
[Epoch 18, Batch 1100] loss: 0.0025274990020295717
[Epoch 18, Batch 1200] loss: 0.003503374078103434
[Epoch 18, Batch 1300] loss: 0.0034597853069186614
[Epoch 18, Batch 1400] loss: 0.002624747821511164
[Epoch 18, Batch 1500] loss: 0.0012732689378447048
[Epoch 18, Batch 1600] loss: 0.0028354958670473705
[Epoch 18, Batch 1700] loss: 0.01674297683374789
[Epoch 18, Batch 1800] loss: 0.007699425436177876
[Epoch 18, Batch 1900] loss: 0.0025828580632776266
[Epoch 18, Batch 2000] loss: 0.003142299764984955
[Epoch 18, Batch 2100] loss: 0.0015778041968559364
[Epoch 18, Batch 2200] loss: 0.003472680188486379
[Epoch 18, Batch 2300] loss: 0.005413645862944882
[Epoch 18, Batch 2400] loss: 0.005500835009386264
[Epoch 18, Batch 2500] loss: 0.0026855326662240486
[Epoch 18, Batch 2600] loss: 0.0030943533723350927
[Epoch 18, Batch 2700] loss: 0.0033788326290732583
[Epoch 18, Batch 2800] loss: 0.0015050555563466616
[Epoch 18, Batch 2900] loss: 0.002698146385981417
[Epoch 18, Batch 3000] loss: 0.0029227994996671035
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0568
Validation Accuracy: 0.9880
Overfitting: 0.0568
[Epoch 19, Batch 100] loss: 0.006112498287863275
[Epoch 19, Batch 200] loss: 0.007602053433313145
[Epoch 19, Batch 300] loss: 0.0056774870807347
[Epoch 19, Batch 400] loss: 0.0015960701572201685
[Epoch 19, Batch 500] loss: 0.0008790074029077743
[Epoch 19, Batch 600] loss: 0.0034566303160707434
[Epoch 19, Batch 700] loss: 0.0019692723257692534
[Epoch 19, Batch 800] loss: 0.005504647095443644
[Epoch 19, Batch 900] loss: 0.0009719861597783819
[Epoch 19, Batch 1000] loss: 0.0009125801041403747
[Epoch 19, Batch 1100] loss: 0.0010416807009795458
[Epoch 19, Batch 1200] loss: 0.004354232001114888
[Epoch 19, Batch 1300] loss: 0.0030975497947977717
[Epoch 19, Batch 1400] loss: 0.0013130156171010298
[Epoch 19, Batch 1500] loss: 0.004450418103015465
[Epoch 19, Batch 1600] loss: 0.0017512112380518375
[Epoch 19, Batch 1700] loss: 0.001693372692587296
[Epoch 19, Batch 1800] loss: 0.006825504358178734
[Epoch 19, Batch 1900] loss: 0.0034748483234602646
[Epoch 19, Batch 2000] loss: 0.0022029392918666703
[Epoch 19, Batch 2100] loss: 0.007232717046073418
[Epoch 19, Batch 2200] loss: 0.006223141659571069
[Epoch 19, Batch 2300] loss: 0.009670168609331
[Epoch 19, Batch 2400] loss: 0.004695770106016752
[Epoch 19, Batch 2500] loss: 0.002602351469382742
[Epoch 19, Batch 2600] loss: 0.003139020105533632
[Epoch 19, Batch 2700] loss: 0.00488772960638336
[Epoch 19, Batch 2800] loss: 0.002200184792224036
[Epoch 19, Batch 2900] loss: 0.003156382909817239
[Epoch 19, Batch 3000] loss: 0.0014344230996672814
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9893
Overfitting: 0.0526
[Epoch 20, Batch 100] loss: 0.0011031726526092812
[Epoch 20, Batch 200] loss: 0.0025039354248325195
[Epoch 20, Batch 300] loss: 0.0011392709218114305
[Epoch 20, Batch 400] loss: 0.0010297414289640017
[Epoch 20, Batch 500] loss: 0.0012007044746803607
[Epoch 20, Batch 600] loss: 0.0018156629077084574
[Epoch 20, Batch 700] loss: 0.0006637054330717973
[Epoch 20, Batch 800] loss: 0.0030970724708760857
[Epoch 20, Batch 900] loss: 0.0035547224730761505
[Epoch 20, Batch 1000] loss: 0.004505708098891574
[Epoch 20, Batch 1100] loss: 0.003432586277440066
[Epoch 20, Batch 1200] loss: 0.0010196822443926123
[Epoch 20, Batch 1300] loss: 0.003451637435803434
[Epoch 20, Batch 1400] loss: 0.00131243101177402
[Epoch 20, Batch 1500] loss: 0.004867382534005173
[Epoch 20, Batch 1600] loss: 0.002673980118068968
[Epoch 20, Batch 1700] loss: 0.001568380416129851
[Epoch 20, Batch 1800] loss: 0.0041339661667062445
[Epoch 20, Batch 1900] loss: 0.004125414765750577
[Epoch 20, Batch 2000] loss: 0.0019046197422682098
[Epoch 20, Batch 2100] loss: 0.001666028509017714
[Epoch 20, Batch 2200] loss: 0.0013710350892560542
[Epoch 20, Batch 2300] loss: 0.0018330608244362168
[Epoch 20, Batch 2400] loss: 0.0010494618684679935
[Epoch 20, Batch 2500] loss: 0.0023650318205795883
[Epoch 20, Batch 2600] loss: 0.0008751531937623724
[Epoch 20, Batch 2700] loss: 0.0013707965217534834
[Epoch 20, Batch 2800] loss: 0.006330255129900166
[Epoch 20, Batch 2900] loss: 0.0014280234567769412
[Epoch 20, Batch 3000] loss: 0.004051870204138979
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0607
Validation Accuracy: 0.9878
Overfitting: 0.0607
[Epoch 21, Batch 100] loss: 0.0023437554278630656
[Epoch 21, Batch 200] loss: 0.0008162046727760596
[Epoch 21, Batch 300] loss: 0.0007144158819017133
[Epoch 21, Batch 400] loss: 0.0013412408423030086
[Epoch 21, Batch 500] loss: 0.004503556284520727
[Epoch 21, Batch 600] loss: 0.01855307949290392
[Epoch 21, Batch 700] loss: 0.0014703697939073379
[Epoch 21, Batch 800] loss: 0.0008420051004634033
[Epoch 21, Batch 900] loss: 0.0012065382722791186
[Epoch 21, Batch 1000] loss: 0.001097868304375953
[Epoch 21, Batch 1100] loss: 0.0008358469217530296
[Epoch 21, Batch 1200] loss: 0.001984347242390143
[Epoch 21, Batch 1300] loss: 0.0008773591667757996
[Epoch 21, Batch 1400] loss: 0.004499574145456649
[Epoch 21, Batch 1500] loss: 0.006872346853153157
[Epoch 21, Batch 1600] loss: 0.0037111082718582146
[Epoch 21, Batch 1700] loss: 0.005262050005191838
[Epoch 21, Batch 1800] loss: 0.0019144718629045343
[Epoch 21, Batch 1900] loss: 0.007552523297518814
[Epoch 21, Batch 2000] loss: 0.007803969033104821
[Epoch 21, Batch 2100] loss: 0.009635843031467174
[Epoch 21, Batch 2200] loss: 0.0045250352515014925
[Epoch 21, Batch 2300] loss: 0.004431295547867364
[Epoch 21, Batch 2400] loss: 0.004444539834747019
[Epoch 21, Batch 2500] loss: 0.002626612066853866
[Epoch 21, Batch 2600] loss: 0.00294800168700025
[Epoch 21, Batch 2700] loss: 0.01183903030134651
[Epoch 21, Batch 2800] loss: 0.002089109629762547
[Epoch 21, Batch 2900] loss: 0.006179599938213372
[Epoch 21, Batch 3000] loss: 0.005338252838046173
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9881
Overfitting: 0.0542
[Epoch 22, Batch 100] loss: 0.0031520160412746635
[Epoch 22, Batch 200] loss: 0.0021006429154732586
[Epoch 22, Batch 300] loss: 0.000945927207506454
[Epoch 22, Batch 400] loss: 0.0007684314672017933
[Epoch 22, Batch 500] loss: 0.0019213457668246293
[Epoch 22, Batch 600] loss: 0.0013778167907090477
[Epoch 22, Batch 700] loss: 0.0015085136260676534
[Epoch 22, Batch 800] loss: 0.0017692907701012928
[Epoch 22, Batch 900] loss: 0.004137172336616431
[Epoch 22, Batch 1000] loss: 0.002334906794556417
[Epoch 22, Batch 1100] loss: 0.0007827638208035381
[Epoch 22, Batch 1200] loss: 0.0009210825579548044
[Epoch 22, Batch 1300] loss: 0.0018910467144135756
[Epoch 22, Batch 1400] loss: 0.0010972937648327985
[Epoch 22, Batch 1500] loss: 0.0008985600591817188
[Epoch 22, Batch 1600] loss: 0.0008164835543889736
[Epoch 22, Batch 1700] loss: 0.000698280224572887
[Epoch 22, Batch 1800] loss: 0.005555131298414224
[Epoch 22, Batch 1900] loss: 0.0012687304471559369
[Epoch 22, Batch 2000] loss: 0.0013179298336777733
[Epoch 22, Batch 2100] loss: 0.0014141754696334274
[Epoch 22, Batch 2200] loss: 0.00404840175677915
[Epoch 22, Batch 2300] loss: 0.0015478387616371947
[Epoch 22, Batch 2400] loss: 0.0011175526137208892
[Epoch 22, Batch 2500] loss: 0.0011466866769839256
[Epoch 22, Batch 2600] loss: 0.0015315168451701133
[Epoch 22, Batch 2700] loss: 0.0005820340764827314
[Epoch 22, Batch 2800] loss: 0.0006787636376727591
[Epoch 22, Batch 2900] loss: 0.0013505702099929052
[Epoch 22, Batch 3000] loss: 0.0017037509415546027
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9898
Overfitting: 0.0538
[Epoch 23, Batch 100] loss: 0.0010754915767942207
[Epoch 23, Batch 200] loss: 0.0011896138643887255
[Epoch 23, Batch 300] loss: 0.0005515989168748448
[Epoch 23, Batch 400] loss: 0.0005302139335179668
[Epoch 23, Batch 500] loss: 0.0014459477114115416
[Epoch 23, Batch 600] loss: 0.0004596027549207449
[Epoch 23, Batch 700] loss: 0.00096332116530359
[Epoch 23, Batch 800] loss: 0.0009234239837823921
[Epoch 23, Batch 900] loss: 0.0008675122176489625
[Epoch 23, Batch 1000] loss: 0.0003682898580583105
[Epoch 23, Batch 1100] loss: 0.004428794227544333
[Epoch 23, Batch 1200] loss: 0.006847602771047932
[Epoch 23, Batch 1300] loss: 0.0015821605726034171
[Epoch 23, Batch 1400] loss: 0.0020503808397170074
[Epoch 23, Batch 1500] loss: 0.0004300307499510403
[Epoch 23, Batch 1600] loss: 0.0010558081521651274
[Epoch 23, Batch 1700] loss: 0.0006493934201819584
[Epoch 23, Batch 1800] loss: 0.001542436855233289
[Epoch 23, Batch 1900] loss: 0.0013956591282553532
[Epoch 23, Batch 2000] loss: 0.001347150911987356
[Epoch 23, Batch 2100] loss: 0.002551412346830375
[Epoch 23, Batch 2200] loss: 0.0025523801612471076
[Epoch 23, Batch 2300] loss: 0.0010913439759902088
[Epoch 23, Batch 2400] loss: 0.001097975028942173
[Epoch 23, Batch 2500] loss: 0.0007833925819809462
[Epoch 23, Batch 2600] loss: 0.0007163311450810639
[Epoch 23, Batch 2700] loss: 0.0010232093677661736
[Epoch 23, Batch 2800] loss: 0.0012998004157152598
[Epoch 23, Batch 2900] loss: 0.0005325310033983621
[Epoch 23, Batch 3000] loss: 0.0011458511013965644
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9895
Overfitting: 0.0556
[Epoch 24, Batch 100] loss: 0.0007979796894203872
[Epoch 24, Batch 200] loss: 0.0006564297648133178
[Epoch 24, Batch 300] loss: 0.0003365691538349669
[Epoch 24, Batch 400] loss: 0.0003693090315693226
[Epoch 24, Batch 500] loss: 0.0003264208540138291
[Epoch 24, Batch 600] loss: 0.00028177616250036675
[Epoch 24, Batch 700] loss: 0.0009132007974787104
[Epoch 24, Batch 800] loss: 0.003379456675890946
[Epoch 24, Batch 900] loss: 0.003528275040298006
[Epoch 24, Batch 1000] loss: 0.0022585806668693077
[Epoch 24, Batch 1100] loss: 0.0006780260536975824
[Epoch 24, Batch 1200] loss: 0.0007194890736835192
[Epoch 24, Batch 1300] loss: 0.0006169641108266788
[Epoch 24, Batch 1400] loss: 0.00035908879996340295
[Epoch 24, Batch 1500] loss: 0.0002385024055362983
[Epoch 24, Batch 1600] loss: 0.0024589823978988035
[Epoch 24, Batch 1700] loss: 0.0007292352291274185
[Epoch 24, Batch 1800] loss: 0.000330892823648572
[Epoch 24, Batch 1900] loss: 0.00041269013817858637
[Epoch 24, Batch 2000] loss: 0.0010692255793968285
[Epoch 24, Batch 2100] loss: 0.00045693581380747974
[Epoch 24, Batch 2200] loss: 0.00041855197172194106
[Epoch 24, Batch 2300] loss: 0.0005959633679062826
[Epoch 24, Batch 2400] loss: 0.0006394002777576268
[Epoch 24, Batch 2500] loss: 0.0005988041656481969
[Epoch 24, Batch 2600] loss: 0.0005368271680091485
[Epoch 24, Batch 2700] loss: 0.00019671386361500787
[Epoch 24, Batch 2800] loss: 0.0008446994370955041
[Epoch 24, Batch 2900] loss: 0.0006914724324147637
[Epoch 24, Batch 3000] loss: 0.0008957976969648973
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9898
Overfitting: 0.0544
Fold 3 validation loss: 0.0544
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.301221265792847
[Epoch 1, Batch 200] loss: 2.2965953373908996
[Epoch 1, Batch 300] loss: 2.2664525866508485
[Epoch 1, Batch 400] loss: 2.0761982226371765
[Epoch 1, Batch 500] loss: 1.1601061969995499
[Epoch 1, Batch 600] loss: 0.6611956115067005
[Epoch 1, Batch 700] loss: 0.5429641416668892
[Epoch 1, Batch 800] loss: 0.4788217696174979
[Epoch 1, Batch 900] loss: 0.38000623885542156
[Epoch 1, Batch 1000] loss: 0.30234789207577706
[Epoch 1, Batch 1100] loss: 0.2854980352520943
[Epoch 1, Batch 1200] loss: 0.3138069410249591
[Epoch 1, Batch 1300] loss: 0.22792027154937386
[Epoch 1, Batch 1400] loss: 0.20737788619473577
[Epoch 1, Batch 1500] loss: 0.19563922527246178
[Epoch 1, Batch 1600] loss: 0.19409443869721144
[Epoch 1, Batch 1700] loss: 0.18377658114768564
[Epoch 1, Batch 1800] loss: 0.15598012087866664
[Epoch 1, Batch 1900] loss: 0.17880340138915926
[Epoch 1, Batch 2000] loss: 0.17134065378457308
[Epoch 1, Batch 2100] loss: 0.12118564064148814
[Epoch 1, Batch 2200] loss: 0.16679460900835694
[Epoch 1, Batch 2300] loss: 0.13354016137775035
[Epoch 1, Batch 2400] loss: 0.16104328427929432
[Epoch 1, Batch 2500] loss: 0.14800418896600603
[Epoch 1, Batch 2600] loss: 0.11348527918802574
[Epoch 1, Batch 2700] loss: 0.1198354355781339
[Epoch 1, Batch 2800] loss: 0.1190601366525516
[Epoch 1, Batch 2900] loss: 0.11795449543278665
[Epoch 1, Batch 3000] loss: 0.12107994282618165
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1077
Validation Accuracy: 0.9654
Overfitting: 0.1077
Best model saved at epoch 1 with validation loss: 0.1077
[Epoch 2, Batch 100] loss: 0.1215066948859021
[Epoch 2, Batch 200] loss: 0.11028749112505466
[Epoch 2, Batch 300] loss: 0.11872594443033449
[Epoch 2, Batch 400] loss: 0.10106493038125336
[Epoch 2, Batch 500] loss: 0.09738722239388153
[Epoch 2, Batch 600] loss: 0.0984542493103072
[Epoch 2, Batch 700] loss: 0.10526154853170738
[Epoch 2, Batch 800] loss: 0.10080192158464342
[Epoch 2, Batch 900] loss: 0.06860433720517904
[Epoch 2, Batch 1000] loss: 0.10880171479657293
[Epoch 2, Batch 1100] loss: 0.09255974317202345
[Epoch 2, Batch 1200] loss: 0.11118452619062737
[Epoch 2, Batch 1300] loss: 0.06212028160691261
[Epoch 2, Batch 1400] loss: 0.11730498952383642
[Epoch 2, Batch 1500] loss: 0.08386475690407678
[Epoch 2, Batch 1600] loss: 0.09980434525059537
[Epoch 2, Batch 1700] loss: 0.09168882377212867
[Epoch 2, Batch 1800] loss: 0.07497377694700845
[Epoch 2, Batch 1900] loss: 0.0843031393387355
[Epoch 2, Batch 2000] loss: 0.08425085243303329
[Epoch 2, Batch 2100] loss: 0.06940479578042869
[Epoch 2, Batch 2200] loss: 0.08397224739543162
[Epoch 2, Batch 2300] loss: 0.08473096573899966
[Epoch 2, Batch 2400] loss: 0.06439398931455799
[Epoch 2, Batch 2500] loss: 0.06605605399701744
[Epoch 2, Batch 2600] loss: 0.06618540266412311
[Epoch 2, Batch 2700] loss: 0.06119519215484615
[Epoch 2, Batch 2800] loss: 0.05798794933158206
[Epoch 2, Batch 2900] loss: 0.07348398994770833
[Epoch 2, Batch 3000] loss: 0.0960124204249587
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0711
Validation Accuracy: 0.9782
Overfitting: 0.0711
Best model saved at epoch 2 with validation loss: 0.0711
[Epoch 3, Batch 100] loss: 0.07597916213679128
[Epoch 3, Batch 200] loss: 0.08107768455753103
[Epoch 3, Batch 300] loss: 0.06314702012517955
[Epoch 3, Batch 400] loss: 0.06107868951832643
[Epoch 3, Batch 500] loss: 0.061798466612817717
[Epoch 3, Batch 600] loss: 0.07183913273154757
[Epoch 3, Batch 700] loss: 0.05683302933524828
[Epoch 3, Batch 800] loss: 0.05178708203806309
[Epoch 3, Batch 900] loss: 0.047667818744084794
[Epoch 3, Batch 1000] loss: 0.07014129810675512
[Epoch 3, Batch 1100] loss: 0.05415657362667844
[Epoch 3, Batch 1200] loss: 0.07948545246239519
[Epoch 3, Batch 1300] loss: 0.04874979122192599
[Epoch 3, Batch 1400] loss: 0.06813195843948051
[Epoch 3, Batch 1500] loss: 0.058731600702158174
[Epoch 3, Batch 1600] loss: 0.0486526261002291
[Epoch 3, Batch 1700] loss: 0.06366837827299605
[Epoch 3, Batch 1800] loss: 0.06428819099091924
[Epoch 3, Batch 1900] loss: 0.06082711565308273
[Epoch 3, Batch 2000] loss: 0.07102158857655012
[Epoch 3, Batch 2100] loss: 0.05053197304107016
[Epoch 3, Batch 2200] loss: 0.048102163779258265
[Epoch 3, Batch 2300] loss: 0.060196873967652206
[Epoch 3, Batch 2400] loss: 0.07463976913684746
[Epoch 3, Batch 2500] loss: 0.05813480391050689
[Epoch 3, Batch 2600] loss: 0.06409895548480563
[Epoch 3, Batch 2700] loss: 0.0711801065178588
[Epoch 3, Batch 2800] loss: 0.04844690764613915
[Epoch 3, Batch 2900] loss: 0.05735964510240592
[Epoch 3, Batch 3000] loss: 0.056571176613215354
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0644
Validation Accuracy: 0.9808
Overfitting: 0.0644
Best model saved at epoch 3 with validation loss: 0.0644
[Epoch 4, Batch 100] loss: 0.05046527946775314
[Epoch 4, Batch 200] loss: 0.05443299213438877
[Epoch 4, Batch 300] loss: 0.04726958039944293
[Epoch 4, Batch 400] loss: 0.044966744140547237
[Epoch 4, Batch 500] loss: 0.04461894415449933
[Epoch 4, Batch 600] loss: 0.038666494362114466
[Epoch 4, Batch 700] loss: 0.04977440866001416
[Epoch 4, Batch 800] loss: 0.06489418398006819
[Epoch 4, Batch 900] loss: 0.04381432444555685
[Epoch 4, Batch 1000] loss: 0.06626106220908695
[Epoch 4, Batch 1100] loss: 0.045861361693241634
[Epoch 4, Batch 1200] loss: 0.05347637246653903
[Epoch 4, Batch 1300] loss: 0.05383424744359218
[Epoch 4, Batch 1400] loss: 0.052770796548575166
[Epoch 4, Batch 1500] loss: 0.04554468893184094
[Epoch 4, Batch 1600] loss: 0.051514833889959845
[Epoch 4, Batch 1700] loss: 0.05796894628147129
[Epoch 4, Batch 1800] loss: 0.04731931062706281
[Epoch 4, Batch 1900] loss: 0.04414058897527866
[Epoch 4, Batch 2000] loss: 0.05050482876569731
[Epoch 4, Batch 2100] loss: 0.05388415326131508
[Epoch 4, Batch 2200] loss: 0.03987579079373973
[Epoch 4, Batch 2300] loss: 0.058613872739952055
[Epoch 4, Batch 2400] loss: 0.05220314893114846
[Epoch 4, Batch 2500] loss: 0.052528796752740164
[Epoch 4, Batch 2600] loss: 0.032948342126328495
[Epoch 4, Batch 2700] loss: 0.04636474473227281
[Epoch 4, Batch 2800] loss: 0.04315122564788908
[Epoch 4, Batch 2900] loss: 0.03738630428502802
[Epoch 4, Batch 3000] loss: 0.06916534763149684
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0545
Validation Accuracy: 0.9823
Overfitting: 0.0545
Best model saved at epoch 4 with validation loss: 0.0545
[Epoch 5, Batch 100] loss: 0.05590905176912202
[Epoch 5, Batch 200] loss: 0.040703797742608
[Epoch 5, Batch 300] loss: 0.03841478068527067
[Epoch 5, Batch 400] loss: 0.03836111984594027
[Epoch 5, Batch 500] loss: 0.03212744348245906
[Epoch 5, Batch 600] loss: 0.03071548191983311
[Epoch 5, Batch 700] loss: 0.03742977890826296
[Epoch 5, Batch 800] loss: 0.054379829952667935
[Epoch 5, Batch 900] loss: 0.040619767030875664
[Epoch 5, Batch 1000] loss: 0.05422087918806937
[Epoch 5, Batch 1100] loss: 0.033645151470118435
[Epoch 5, Batch 1200] loss: 0.03456683031239663
[Epoch 5, Batch 1300] loss: 0.033473031942994565
[Epoch 5, Batch 1400] loss: 0.04816943166122655
[Epoch 5, Batch 1500] loss: 0.04277966034715064
[Epoch 5, Batch 1600] loss: 0.04219035465022898
[Epoch 5, Batch 1700] loss: 0.0492037749348674
[Epoch 5, Batch 1800] loss: 0.033845267691431216
[Epoch 5, Batch 1900] loss: 0.04990279499470489
[Epoch 5, Batch 2000] loss: 0.03825010384942289
[Epoch 5, Batch 2100] loss: 0.03445124766847584
[Epoch 5, Batch 2200] loss: 0.03988175342150498
[Epoch 5, Batch 2300] loss: 0.04021155745052965
[Epoch 5, Batch 2400] loss: 0.03656192876529531
[Epoch 5, Batch 2500] loss: 0.04371288873051526
[Epoch 5, Batch 2600] loss: 0.04232793430433958
[Epoch 5, Batch 2700] loss: 0.03874070961624966
[Epoch 5, Batch 2800] loss: 0.029086672784906113
[Epoch 5, Batch 2900] loss: 0.04240813983429689
[Epoch 5, Batch 3000] loss: 0.028375013593249607
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9835
Overfitting: 0.0523
Best model saved at epoch 5 with validation loss: 0.0523
[Epoch 6, Batch 100] loss: 0.036051026751374594
[Epoch 6, Batch 200] loss: 0.026326231269558777
[Epoch 6, Batch 300] loss: 0.028784675206115936
[Epoch 6, Batch 400] loss: 0.029427416172911763
[Epoch 6, Batch 500] loss: 0.03120252647480811
[Epoch 6, Batch 600] loss: 0.03187028616113821
[Epoch 6, Batch 700] loss: 0.021370074419901356
[Epoch 6, Batch 800] loss: 0.032873424348435945
[Epoch 6, Batch 900] loss: 0.028423792441899423
[Epoch 6, Batch 1000] loss: 0.03968161790799059
[Epoch 6, Batch 1100] loss: 0.036642996681912336
[Epoch 6, Batch 1200] loss: 0.019728439431019068
[Epoch 6, Batch 1300] loss: 0.028538295387261315
[Epoch 6, Batch 1400] loss: 0.034345258981484224
[Epoch 6, Batch 1500] loss: 0.058422672247761515
[Epoch 6, Batch 1600] loss: 0.04648171939930762
[Epoch 6, Batch 1700] loss: 0.03850316871285031
[Epoch 6, Batch 1800] loss: 0.04083490383949538
[Epoch 6, Batch 1900] loss: 0.04278074774425477
[Epoch 6, Batch 2000] loss: 0.03555438559440518
[Epoch 6, Batch 2100] loss: 0.046947418691124766
[Epoch 6, Batch 2200] loss: 0.025376270006818233
[Epoch 6, Batch 2300] loss: 0.02533866432524519
[Epoch 6, Batch 2400] loss: 0.03750617217199761
[Epoch 6, Batch 2500] loss: 0.04413393913884647
[Epoch 6, Batch 2600] loss: 0.030724780002637998
[Epoch 6, Batch 2700] loss: 0.038901391838298875
[Epoch 6, Batch 2800] loss: 0.02336149499824387
[Epoch 6, Batch 2900] loss: 0.03197717049588391
[Epoch 6, Batch 3000] loss: 0.03543567738732236
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9853
Overfitting: 0.0463
Best model saved at epoch 6 with validation loss: 0.0463
[Epoch 7, Batch 100] loss: 0.016085352117588627
[Epoch 7, Batch 200] loss: 0.027882229043934784
[Epoch 7, Batch 300] loss: 0.0207118589264428
[Epoch 7, Batch 400] loss: 0.03474820021503547
[Epoch 7, Batch 500] loss: 0.025235933633957756
[Epoch 7, Batch 600] loss: 0.023173911295307336
[Epoch 7, Batch 700] loss: 0.023425896295302662
[Epoch 7, Batch 800] loss: 0.038385152743285286
[Epoch 7, Batch 900] loss: 0.0248494793584905
[Epoch 7, Batch 1000] loss: 0.019586517724910664
[Epoch 7, Batch 1100] loss: 0.02809788873535581
[Epoch 7, Batch 1200] loss: 0.030860052498064762
[Epoch 7, Batch 1300] loss: 0.04154030344099738
[Epoch 7, Batch 1400] loss: 0.0334610629742383
[Epoch 7, Batch 1500] loss: 0.020381283383176196
[Epoch 7, Batch 1600] loss: 0.03157271631876938
[Epoch 7, Batch 1700] loss: 0.031415615453297505
[Epoch 7, Batch 1800] loss: 0.035262828517443265
[Epoch 7, Batch 1900] loss: 0.02963400499756972
[Epoch 7, Batch 2000] loss: 0.01941274524309847
[Epoch 7, Batch 2100] loss: 0.03363189310854068
[Epoch 7, Batch 2200] loss: 0.02491117717807356
[Epoch 7, Batch 2300] loss: 0.02907299467828125
[Epoch 7, Batch 2400] loss: 0.020998358270881
[Epoch 7, Batch 2500] loss: 0.02914181902397104
[Epoch 7, Batch 2600] loss: 0.028548548096478044
[Epoch 7, Batch 2700] loss: 0.03124093168951731
[Epoch 7, Batch 2800] loss: 0.02583152534221881
[Epoch 7, Batch 2900] loss: 0.03088975799139007
[Epoch 7, Batch 3000] loss: 0.02929486215209181
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0435
Validation Accuracy: 0.9870
Overfitting: 0.0435
Best model saved at epoch 7 with validation loss: 0.0435
[Epoch 8, Batch 100] loss: 0.023896584072426775
[Epoch 8, Batch 200] loss: 0.020701462348515633
[Epoch 8, Batch 300] loss: 0.019001247687228898
[Epoch 8, Batch 400] loss: 0.022270099832348934
[Epoch 8, Batch 500] loss: 0.01257509497430874
[Epoch 8, Batch 600] loss: 0.025674447779510955
[Epoch 8, Batch 700] loss: 0.03811115650380088
[Epoch 8, Batch 800] loss: 0.030093247103759494
[Epoch 8, Batch 900] loss: 0.01855952796288875
[Epoch 8, Batch 1000] loss: 0.03195039257690951
[Epoch 8, Batch 1100] loss: 0.026649091090766887
[Epoch 8, Batch 1200] loss: 0.03251920143477036
[Epoch 8, Batch 1300] loss: 0.03347274177343934
[Epoch 8, Batch 1400] loss: 0.023239289607445243
[Epoch 8, Batch 1500] loss: 0.03596609272655769
[Epoch 8, Batch 1600] loss: 0.022266956658550042
[Epoch 8, Batch 1700] loss: 0.02761037372125429
[Epoch 8, Batch 1800] loss: 0.013553765945434861
[Epoch 8, Batch 1900] loss: 0.008706547157853493
[Epoch 8, Batch 2000] loss: 0.031831379847390054
[Epoch 8, Batch 2100] loss: 0.024536923534942617
[Epoch 8, Batch 2200] loss: 0.019793543936903007
[Epoch 8, Batch 2300] loss: 0.02763131785850419
[Epoch 8, Batch 2400] loss: 0.013159846979760914
[Epoch 8, Batch 2500] loss: 0.022631561324596986
[Epoch 8, Batch 2600] loss: 0.03196633203762758
[Epoch 8, Batch 2700] loss: 0.017288014214918802
[Epoch 8, Batch 2800] loss: 0.02371423413111188
[Epoch 8, Batch 2900] loss: 0.024538498954789247
[Epoch 8, Batch 3000] loss: 0.035300183850304166
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9867
Overfitting: 0.0453
[Epoch 9, Batch 100] loss: 0.01799588525556828
[Epoch 9, Batch 200] loss: 0.010414555462684803
[Epoch 9, Batch 300] loss: 0.02245202281344973
[Epoch 9, Batch 400] loss: 0.01208357490693743
[Epoch 9, Batch 500] loss: 0.011650362580239744
[Epoch 9, Batch 600] loss: 0.027149151729026925
[Epoch 9, Batch 700] loss: 0.019441718205125653
[Epoch 9, Batch 800] loss: 0.017317353892722168
[Epoch 9, Batch 900] loss: 0.01995654897124041
[Epoch 9, Batch 1000] loss: 0.018152279197020105
[Epoch 9, Batch 1100] loss: 0.025117026785301276
[Epoch 9, Batch 1200] loss: 0.014790903660341428
[Epoch 9, Batch 1300] loss: 0.02521012750371483
[Epoch 9, Batch 1400] loss: 0.029991308258777282
[Epoch 9, Batch 1500] loss: 0.023730183897750976
[Epoch 9, Batch 1600] loss: 0.039047326950549174
[Epoch 9, Batch 1700] loss: 0.013654082994980854
[Epoch 9, Batch 1800] loss: 0.013533977710721956
[Epoch 9, Batch 1900] loss: 0.02149659799080837
[Epoch 9, Batch 2000] loss: 0.00928732398808279
[Epoch 9, Batch 2100] loss: 0.01651749834014481
[Epoch 9, Batch 2200] loss: 0.022204727957323485
[Epoch 9, Batch 2300] loss: 0.017560006554676873
[Epoch 9, Batch 2400] loss: 0.018109392178912456
[Epoch 9, Batch 2500] loss: 0.02892039573543116
[Epoch 9, Batch 2600] loss: 0.03301471467308147
[Epoch 9, Batch 2700] loss: 0.04485936980265251
[Epoch 9, Batch 2800] loss: 0.02650311968944152
[Epoch 9, Batch 2900] loss: 0.016657795011269627
[Epoch 9, Batch 3000] loss: 0.030858466942790982
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9862
Overfitting: 0.0462
[Epoch 10, Batch 100] loss: 0.014673328658172977
[Epoch 10, Batch 200] loss: 0.03152531546125829
[Epoch 10, Batch 300] loss: 0.014536001323758683
[Epoch 10, Batch 400] loss: 0.015349717792778392
[Epoch 10, Batch 500] loss: 0.015065429262012913
[Epoch 10, Batch 600] loss: 0.024739302370398945
[Epoch 10, Batch 700] loss: 0.019139367499083165
[Epoch 10, Batch 800] loss: 0.020187522052910935
[Epoch 10, Batch 900] loss: 0.020181934963075035
[Epoch 10, Batch 1000] loss: 0.016136221411361475
[Epoch 10, Batch 1100] loss: 0.013266416485676018
[Epoch 10, Batch 1200] loss: 0.026065530320629478
[Epoch 10, Batch 1300] loss: 0.017602359146367236
[Epoch 10, Batch 1400] loss: 0.019112785160723435
[Epoch 10, Batch 1500] loss: 0.01828785067773424
[Epoch 10, Batch 1600] loss: 0.024634581342616
[Epoch 10, Batch 1700] loss: 0.029539451621731133
[Epoch 10, Batch 1800] loss: 0.016580207572951623
[Epoch 10, Batch 1900] loss: 0.018034556657876236
[Epoch 10, Batch 2000] loss: 0.012050206459207402
[Epoch 10, Batch 2100] loss: 0.03239549146830541
[Epoch 10, Batch 2200] loss: 0.018711151535426324
[Epoch 10, Batch 2300] loss: 0.01542201807791571
[Epoch 10, Batch 2400] loss: 0.011895170270645395
[Epoch 10, Batch 2500] loss: 0.01906254554492989
[Epoch 10, Batch 2600] loss: 0.011248574911487595
[Epoch 10, Batch 2700] loss: 0.020836057299079586
[Epoch 10, Batch 2800] loss: 0.013332797981020121
[Epoch 10, Batch 2900] loss: 0.009769560472814192
[Epoch 10, Batch 3000] loss: 0.032135942910003906
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0461
Validation Accuracy: 0.9857
Overfitting: 0.0461
[Epoch 11, Batch 100] loss: 0.01629768213296302
[Epoch 11, Batch 200] loss: 0.013938610981795137
[Epoch 11, Batch 300] loss: 0.009294576843467439
[Epoch 11, Batch 400] loss: 0.011227127393576666
[Epoch 11, Batch 500] loss: 0.021942682710086956
[Epoch 11, Batch 600] loss: 0.01179259988870399
[Epoch 11, Batch 700] loss: 0.012488883202204306
[Epoch 11, Batch 800] loss: 0.01703431769558847
[Epoch 11, Batch 900] loss: 0.015340407142939511
[Epoch 11, Batch 1000] loss: 0.02304250301739103
[Epoch 11, Batch 1100] loss: 0.010732690040513262
[Epoch 11, Batch 1200] loss: 0.01929783519679404
[Epoch 11, Batch 1300] loss: 0.012037421971290313
[Epoch 11, Batch 1400] loss: 0.014651165342620516
[Epoch 11, Batch 1500] loss: 0.017186898067920994
[Epoch 11, Batch 1600] loss: 0.011824548339263856
[Epoch 11, Batch 1700] loss: 0.01523451023555026
[Epoch 11, Batch 1800] loss: 0.028419379654280874
[Epoch 11, Batch 1900] loss: 0.028262916984394905
[Epoch 11, Batch 2000] loss: 0.01703894211754232
[Epoch 11, Batch 2100] loss: 0.01712966910945397
[Epoch 11, Batch 2200] loss: 0.01852833522894116
[Epoch 11, Batch 2300] loss: 0.012687622943512906
[Epoch 11, Batch 2400] loss: 0.028589123587830726
[Epoch 11, Batch 2500] loss: 0.019977295727935596
[Epoch 11, Batch 2600] loss: 0.016405070384898864
[Epoch 11, Batch 2700] loss: 0.010007339601888815
[Epoch 11, Batch 2800] loss: 0.010701333736415108
[Epoch 11, Batch 2900] loss: 0.026423246446138363
[Epoch 11, Batch 3000] loss: 0.017567295237204236
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9867
Overfitting: 0.0477
[Epoch 12, Batch 100] loss: 0.012297727982049764
[Epoch 12, Batch 200] loss: 0.00822716904724075
[Epoch 12, Batch 300] loss: 0.017287448273764314
[Epoch 12, Batch 400] loss: 0.00893985680242622
[Epoch 12, Batch 500] loss: 0.007191654059106441
[Epoch 12, Batch 600] loss: 0.01684704914803433
[Epoch 12, Batch 700] loss: 0.010138181449829062
[Epoch 12, Batch 800] loss: 0.012281152579698756
[Epoch 12, Batch 900] loss: 0.013947351964006885
[Epoch 12, Batch 1000] loss: 0.01110888364094535
[Epoch 12, Batch 1100] loss: 0.008040868657324153
[Epoch 12, Batch 1200] loss: 0.013310422160602685
[Epoch 12, Batch 1300] loss: 0.018534826537188565
[Epoch 12, Batch 1400] loss: 0.009766196073665015
[Epoch 12, Batch 1500] loss: 0.015287987756291841
[Epoch 12, Batch 1600] loss: 0.01872816992740809
[Epoch 12, Batch 1700] loss: 0.01376976190260848
[Epoch 12, Batch 1800] loss: 0.012986143234356859
[Epoch 12, Batch 1900] loss: 0.01787940364100905
[Epoch 12, Batch 2000] loss: 0.0295270868832813
[Epoch 12, Batch 2100] loss: 0.013867898318867446
[Epoch 12, Batch 2200] loss: 0.0109454594003455
[Epoch 12, Batch 2300] loss: 0.010370103692732755
[Epoch 12, Batch 2400] loss: 0.01505548357029511
[Epoch 12, Batch 2500] loss: 0.01903053990567969
[Epoch 12, Batch 2600] loss: 0.01666735108951798
[Epoch 12, Batch 2700] loss: 0.005723170582787134
[Epoch 12, Batch 2800] loss: 0.009391433816267636
[Epoch 12, Batch 2900] loss: 0.029147877155101014
[Epoch 12, Batch 3000] loss: 0.016732126626734498
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9859
Overfitting: 0.0473
[Epoch 13, Batch 100] loss: 0.00915864788394174
[Epoch 13, Batch 200] loss: 0.0037018733198237895
[Epoch 13, Batch 300] loss: 0.009314161417632931
[Epoch 13, Batch 400] loss: 0.009659531966282203
[Epoch 13, Batch 500] loss: 0.013027236577195254
[Epoch 13, Batch 600] loss: 0.01568951023507907
[Epoch 13, Batch 700] loss: 0.012605164023957513
[Epoch 13, Batch 800] loss: 0.008016885102447304
[Epoch 13, Batch 900] loss: 0.006076379565570278
[Epoch 13, Batch 1000] loss: 0.010836096756174812
[Epoch 13, Batch 1100] loss: 0.02124827117098448
[Epoch 13, Batch 1200] loss: 0.011234759225069411
[Epoch 13, Batch 1300] loss: 0.006103944754877375
[Epoch 13, Batch 1400] loss: 0.012275865269643874
[Epoch 13, Batch 1500] loss: 0.00656931343431097
[Epoch 13, Batch 1600] loss: 0.01968196679312541
[Epoch 13, Batch 1700] loss: 0.013839341128232263
[Epoch 13, Batch 1800] loss: 0.01615547099678224
[Epoch 13, Batch 1900] loss: 0.02387415225976838
[Epoch 13, Batch 2000] loss: 0.0170679516948303
[Epoch 13, Batch 2100] loss: 0.013599969778927062
[Epoch 13, Batch 2200] loss: 0.005069672833278673
[Epoch 13, Batch 2300] loss: 0.01125979373058044
[Epoch 13, Batch 2400] loss: 0.01250990133317373
[Epoch 13, Batch 2500] loss: 0.011989241827091063
[Epoch 13, Batch 2600] loss: 0.019318734015623704
[Epoch 13, Batch 2700] loss: 0.014663444535558482
[Epoch 13, Batch 2800] loss: 0.007869085469728816
[Epoch 13, Batch 2900] loss: 0.017123590429400794
[Epoch 13, Batch 3000] loss: 0.012178772079400914
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9844
Overfitting: 0.0548
[Epoch 14, Batch 100] loss: 0.007979954270763302
[Epoch 14, Batch 200] loss: 0.01000030886096056
[Epoch 14, Batch 300] loss: 0.008581414708933153
[Epoch 14, Batch 400] loss: 0.009497193975489608
[Epoch 14, Batch 500] loss: 0.006060678491319322
[Epoch 14, Batch 600] loss: 0.010383810884693503
[Epoch 14, Batch 700] loss: 0.010212560201171072
[Epoch 14, Batch 800] loss: 0.005978555596506112
[Epoch 14, Batch 900] loss: 0.012915781670920978
[Epoch 14, Batch 1000] loss: 0.011561339044849035
[Epoch 14, Batch 1100] loss: 0.00845318786938833
[Epoch 14, Batch 1200] loss: 0.009948367082247387
[Epoch 14, Batch 1300] loss: 0.01685868019364989
[Epoch 14, Batch 1400] loss: 0.015824377502049174
[Epoch 14, Batch 1500] loss: 0.00849999268248439
[Epoch 14, Batch 1600] loss: 0.017981559402046515
[Epoch 14, Batch 1700] loss: 0.011680292689161433
[Epoch 14, Batch 1800] loss: 0.016093894217335675
[Epoch 14, Batch 1900] loss: 0.005128144149302898
[Epoch 14, Batch 2000] loss: 0.008546362937177037
[Epoch 14, Batch 2100] loss: 0.00642647185711212
[Epoch 14, Batch 2200] loss: 0.01106674248300351
[Epoch 14, Batch 2300] loss: 0.0072522798823229095
[Epoch 14, Batch 2400] loss: 0.009016772314289483
[Epoch 14, Batch 2500] loss: 0.007000836774222989
[Epoch 14, Batch 2600] loss: 0.008549729903779734
[Epoch 14, Batch 2700] loss: 0.01164588331261939
[Epoch 14, Batch 2800] loss: 0.01233481534378143
[Epoch 14, Batch 2900] loss: 0.010387042252493756
[Epoch 14, Batch 3000] loss: 0.006914952814568096
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9870
Overfitting: 0.0459
[Epoch 15, Batch 100] loss: 0.0028663667910367964
[Epoch 15, Batch 200] loss: 0.003527380727862237
[Epoch 15, Batch 300] loss: 0.009424828306507607
[Epoch 15, Batch 400] loss: 0.0050074206190902255
[Epoch 15, Batch 500] loss: 0.0025316406490514965
[Epoch 15, Batch 600] loss: 0.004715128029711195
[Epoch 15, Batch 700] loss: 0.015137555571751875
[Epoch 15, Batch 800] loss: 0.008282911351711846
[Epoch 15, Batch 900] loss: 0.004929592431483343
[Epoch 15, Batch 1000] loss: 0.01392782165220524
[Epoch 15, Batch 1100] loss: 0.008053048231272442
[Epoch 15, Batch 1200] loss: 0.01189863299212675
[Epoch 15, Batch 1300] loss: 0.012956490849753664
[Epoch 15, Batch 1400] loss: 0.008373119331540693
[Epoch 15, Batch 1500] loss: 0.015727567376885646
[Epoch 15, Batch 1600] loss: 0.016935918317178535
[Epoch 15, Batch 1700] loss: 0.011488592311908406
[Epoch 15, Batch 1800] loss: 0.013168732799204007
[Epoch 15, Batch 1900] loss: 0.0043896223383106305
[Epoch 15, Batch 2000] loss: 0.01591747947208887
[Epoch 15, Batch 2100] loss: 0.01663188087780327
[Epoch 15, Batch 2200] loss: 0.006336707216069044
[Epoch 15, Batch 2300] loss: 0.004927383499162943
[Epoch 15, Batch 2400] loss: 0.008921632040235182
[Epoch 15, Batch 2500] loss: 0.007510417578273519
[Epoch 15, Batch 2600] loss: 0.00823809821575935
[Epoch 15, Batch 2700] loss: 0.006679912878750116
[Epoch 15, Batch 2800] loss: 0.005203603238960568
[Epoch 15, Batch 2900] loss: 0.005445113549760663
[Epoch 15, Batch 3000] loss: 0.012564643775822332
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9867
Overfitting: 0.0501
[Epoch 16, Batch 100] loss: 0.00811474253765482
[Epoch 16, Batch 200] loss: 0.01496653814436172
[Epoch 16, Batch 300] loss: 0.014071554095655756
[Epoch 16, Batch 400] loss: 0.010041596059429593
[Epoch 16, Batch 500] loss: 0.012757836409253969
[Epoch 16, Batch 600] loss: 0.00953405150992694
[Epoch 16, Batch 700] loss: 0.006503594380451432
[Epoch 16, Batch 800] loss: 0.009545154658669617
[Epoch 16, Batch 900] loss: 0.0061597618059499835
[Epoch 16, Batch 1000] loss: 0.004568060493506891
[Epoch 16, Batch 1100] loss: 0.009948372100645884
[Epoch 16, Batch 1200] loss: 0.014461463350994564
[Epoch 16, Batch 1300] loss: 0.021598276881402968
[Epoch 16, Batch 1400] loss: 0.012469066597095662
[Epoch 16, Batch 1500] loss: 0.004267157458950805
[Epoch 16, Batch 1600] loss: 0.006940938568504862
[Epoch 16, Batch 1700] loss: 0.006421265562801181
[Epoch 16, Batch 1800] loss: 0.0027931648709866863
[Epoch 16, Batch 1900] loss: 0.002694392582787941
[Epoch 16, Batch 2000] loss: 0.004474815534286165
[Epoch 16, Batch 2100] loss: 0.006574452948358385
[Epoch 16, Batch 2200] loss: 0.011853940850788548
[Epoch 16, Batch 2300] loss: 0.014553862431246501
[Epoch 16, Batch 2400] loss: 0.022992242955419896
[Epoch 16, Batch 2500] loss: 0.01301681953800653
[Epoch 16, Batch 2600] loss: 0.008804745814599571
[Epoch 16, Batch 2700] loss: 0.006423080125300657
[Epoch 16, Batch 2800] loss: 0.02414597708233373
[Epoch 16, Batch 2900] loss: 0.0214995506488458
[Epoch 16, Batch 3000] loss: 0.008976589400976991
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9882
Overfitting: 0.0465
[Epoch 17, Batch 100] loss: 0.009224076408638666
[Epoch 17, Batch 200] loss: 0.009733741382697758
[Epoch 17, Batch 300] loss: 0.004641768877579295
[Epoch 17, Batch 400] loss: 0.0031625190603301687
[Epoch 17, Batch 500] loss: 0.003651206478600386
[Epoch 17, Batch 600] loss: 0.0027535954709776433
[Epoch 17, Batch 700] loss: 0.0027449427177927534
[Epoch 17, Batch 800] loss: 0.0028719525771069244
[Epoch 17, Batch 900] loss: 0.0016284239731885464
[Epoch 17, Batch 1000] loss: 0.0019391909734849833
[Epoch 17, Batch 1100] loss: 0.007561369122761263
[Epoch 17, Batch 1200] loss: 0.0032772331093701723
[Epoch 17, Batch 1300] loss: 0.01206087443822753
[Epoch 17, Batch 1400] loss: 0.012933443067241797
[Epoch 17, Batch 1500] loss: 0.00542312401174172
[Epoch 17, Batch 1600] loss: 0.011303615481661637
[Epoch 17, Batch 1700] loss: 0.012269799674315891
[Epoch 17, Batch 1800] loss: 0.010009957983936602
[Epoch 17, Batch 1900] loss: 0.006350973445717045
[Epoch 17, Batch 2000] loss: 0.0029626090808017123
[Epoch 17, Batch 2100] loss: 0.008821836709498711
[Epoch 17, Batch 2200] loss: 0.005902363229027969
[Epoch 17, Batch 2300] loss: 0.007233068930200375
[Epoch 17, Batch 2400] loss: 0.008645220459977737
[Epoch 17, Batch 2500] loss: 0.006787151278358578
[Epoch 17, Batch 2600] loss: 0.009505211410420315
[Epoch 17, Batch 2700] loss: 0.011798016497805293
[Epoch 17, Batch 2800] loss: 0.003521205711629136
[Epoch 17, Batch 2900] loss: 0.009433493939405367
[Epoch 17, Batch 3000] loss: 0.02590803768354817
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9869
Overfitting: 0.0523
[Epoch 18, Batch 100] loss: 0.007984617071986121
[Epoch 18, Batch 200] loss: 0.00618013292917567
[Epoch 18, Batch 300] loss: 0.0034176976182288855
[Epoch 18, Batch 400] loss: 0.0020702436177538175
[Epoch 18, Batch 500] loss: 0.00404467630246927
[Epoch 18, Batch 600] loss: 0.007200983967316006
[Epoch 18, Batch 700] loss: 0.007750908045989035
[Epoch 18, Batch 800] loss: 0.007460034818925578
[Epoch 18, Batch 900] loss: 0.002349059392553272
[Epoch 18, Batch 1000] loss: 0.003987670772910405
[Epoch 18, Batch 1100] loss: 0.007832153771859111
[Epoch 18, Batch 1200] loss: 0.006379584733302011
[Epoch 18, Batch 1300] loss: 0.015566166630568716
[Epoch 18, Batch 1400] loss: 0.011616114672369804
[Epoch 18, Batch 1500] loss: 0.008436697259213588
[Epoch 18, Batch 1600] loss: 0.004993606014156739
[Epoch 18, Batch 1700] loss: 0.008012856394808523
[Epoch 18, Batch 1800] loss: 0.007541466265954568
[Epoch 18, Batch 1900] loss: 0.006717040363816977
[Epoch 18, Batch 2000] loss: 0.01702139543031649
[Epoch 18, Batch 2100] loss: 0.004799369566433143
[Epoch 18, Batch 2200] loss: 0.005346748704325819
[Epoch 18, Batch 2300] loss: 0.003171883405453144
[Epoch 18, Batch 2400] loss: 0.005348557965826046
[Epoch 18, Batch 2500] loss: 0.007567998471897681
[Epoch 18, Batch 2600] loss: 0.007812104480677107
[Epoch 18, Batch 2700] loss: 0.008578117582605103
[Epoch 18, Batch 2800] loss: 0.004120436701296058
[Epoch 18, Batch 2900] loss: 0.008760284183209137
[Epoch 18, Batch 3000] loss: 0.004210389085753832
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9878
Overfitting: 0.0487
[Epoch 19, Batch 100] loss: 0.0019297131744383479
[Epoch 19, Batch 200] loss: 0.009524440991935706
[Epoch 19, Batch 300] loss: 0.004838294980030469
[Epoch 19, Batch 400] loss: 0.003169648335169768
[Epoch 19, Batch 500] loss: 0.001947418000528387
[Epoch 19, Batch 600] loss: 0.007561441429113529
[Epoch 19, Batch 700] loss: 0.008189096524940851
[Epoch 19, Batch 800] loss: 0.0036999895384207094
[Epoch 19, Batch 900] loss: 0.006086819056954482
[Epoch 19, Batch 1000] loss: 0.0035819653596223587
[Epoch 19, Batch 1100] loss: 0.0022520927824854196
[Epoch 19, Batch 1200] loss: 0.0055800864176194405
[Epoch 19, Batch 1300] loss: 0.0023216988918457557
[Epoch 19, Batch 1400] loss: 0.0013414484590761333
[Epoch 19, Batch 1500] loss: 0.005308799736300216
[Epoch 19, Batch 1600] loss: 0.009013367642860431
[Epoch 19, Batch 1700] loss: 0.007124081900802253
[Epoch 19, Batch 1800] loss: 0.004626725526531601
[Epoch 19, Batch 1900] loss: 0.003565226206284251
[Epoch 19, Batch 2000] loss: 0.0031845834556737886
[Epoch 19, Batch 2100] loss: 0.0022021419117614015
[Epoch 19, Batch 2200] loss: 0.004147278278953764
[Epoch 19, Batch 2300] loss: 0.0055429771754053545
[Epoch 19, Batch 2400] loss: 0.005460506264031277
[Epoch 19, Batch 2500] loss: 0.010358803971636804
[Epoch 19, Batch 2600] loss: 0.002342969324902242
[Epoch 19, Batch 2700] loss: 0.010053234385929954
[Epoch 19, Batch 2800] loss: 0.008162331438326618
[Epoch 19, Batch 2900] loss: 0.0048652405384746085
[Epoch 19, Batch 3000] loss: 0.0014428674505946048
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9887
Overfitting: 0.0471
[Epoch 20, Batch 100] loss: 0.0010960860446348874
[Epoch 20, Batch 200] loss: 0.003030871598043774
[Epoch 20, Batch 300] loss: 0.0015572114217030553
[Epoch 20, Batch 400] loss: 0.004188889958240036
[Epoch 20, Batch 500] loss: 0.011458885845875386
[Epoch 20, Batch 600] loss: 0.010154205674490128
[Epoch 20, Batch 700] loss: 0.005901240630413298
[Epoch 20, Batch 800] loss: 0.008066269222096025
[Epoch 20, Batch 900] loss: 0.0018033524393365496
[Epoch 20, Batch 1000] loss: 0.003066273196162328
[Epoch 20, Batch 1100] loss: 0.0022480432587079235
[Epoch 20, Batch 1200] loss: 0.004318147829129923
[Epoch 20, Batch 1300] loss: 0.004123926211288733
[Epoch 20, Batch 1400] loss: 0.005928819256320708
[Epoch 20, Batch 1500] loss: 0.004808674060851672
[Epoch 20, Batch 1600] loss: 0.00618789531981065
[Epoch 20, Batch 1700] loss: 0.0047743823604866975
[Epoch 20, Batch 1800] loss: 0.0059191433645199255
[Epoch 20, Batch 1900] loss: 0.007165237461909868
[Epoch 20, Batch 2000] loss: 0.010880028101300922
[Epoch 20, Batch 2100] loss: 0.0038733820265109387
[Epoch 20, Batch 2200] loss: 0.002255865445487757
[Epoch 20, Batch 2300] loss: 0.0019245104820893744
[Epoch 20, Batch 2400] loss: 0.003266129194639973
[Epoch 20, Batch 2500] loss: 0.005375410949512798
[Epoch 20, Batch 2600] loss: 0.003943857345504105
[Epoch 20, Batch 2700] loss: 0.008871245668277634
[Epoch 20, Batch 2800] loss: 0.008820022750496719
[Epoch 20, Batch 2900] loss: 0.0057221155804705855
[Epoch 20, Batch 3000] loss: 0.009530949537419247
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0664
Validation Accuracy: 0.9856
Overfitting: 0.0664
[Epoch 21, Batch 100] loss: 0.003613323926553562
[Epoch 21, Batch 200] loss: 0.0071525283590668206
[Epoch 21, Batch 300] loss: 0.0016293259852203689
[Epoch 21, Batch 400] loss: 0.0024505458383342216
[Epoch 21, Batch 500] loss: 0.004308979328699252
[Epoch 21, Batch 600] loss: 0.0026983863877688917
[Epoch 21, Batch 700] loss: 0.0020082284729508616
[Epoch 21, Batch 800] loss: 0.002048539776397149
[Epoch 21, Batch 900] loss: 0.0006102341698655067
[Epoch 21, Batch 1000] loss: 0.0050403494854141685
[Epoch 21, Batch 1100] loss: 0.0015265838195008996
[Epoch 21, Batch 1200] loss: 0.0006719125984712803
[Epoch 21, Batch 1300] loss: 0.0007638418748295095
[Epoch 21, Batch 1400] loss: 0.0005544543111891187
[Epoch 21, Batch 1500] loss: 0.004882864463216734
[Epoch 21, Batch 1600] loss: 0.0016361583952947357
[Epoch 21, Batch 1700] loss: 0.006313839021322565
[Epoch 21, Batch 1800] loss: 0.0033230170818622897
[Epoch 21, Batch 1900] loss: 0.001711685439617554
[Epoch 21, Batch 2000] loss: 0.0022217131932914923
[Epoch 21, Batch 2100] loss: 0.002695177440401437
[Epoch 21, Batch 2200] loss: 0.005043411600201466
[Epoch 21, Batch 2300] loss: 0.0019704429852694717
[Epoch 21, Batch 2400] loss: 0.0032675524047921555
[Epoch 21, Batch 2500] loss: 0.002502618708126185
[Epoch 21, Batch 2600] loss: 0.00190077903883342
[Epoch 21, Batch 2700] loss: 0.008818238216026657
[Epoch 21, Batch 2800] loss: 0.004304897603000768
[Epoch 21, Batch 2900] loss: 0.0007003467819401443
[Epoch 21, Batch 3000] loss: 0.0046750683855651684
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9874
Overfitting: 0.0560
[Epoch 22, Batch 100] loss: 0.00468935964925965
[Epoch 22, Batch 200] loss: 0.0014361316995174177
[Epoch 22, Batch 300] loss: 0.002297931018596837
[Epoch 22, Batch 400] loss: 0.0016354906085797438
[Epoch 22, Batch 500] loss: 0.0024206696348880816
[Epoch 22, Batch 600] loss: 0.0023547792449039617
[Epoch 22, Batch 700] loss: 0.0013350382287433149
[Epoch 22, Batch 800] loss: 0.0008000577832327949
[Epoch 22, Batch 900] loss: 0.0011755121051215767
[Epoch 22, Batch 1000] loss: 0.0011905611445807462
[Epoch 22, Batch 1100] loss: 0.00040464779214479665
[Epoch 22, Batch 1200] loss: 0.0015871034389047622
[Epoch 22, Batch 1300] loss: 0.005063989829805422
[Epoch 22, Batch 1400] loss: 0.0013418944748529072
[Epoch 22, Batch 1500] loss: 0.0023940392371111585
[Epoch 22, Batch 1600] loss: 0.003568518724788987
[Epoch 22, Batch 1700] loss: 0.004259299447539959
[Epoch 22, Batch 1800] loss: 0.002216858047288106
[Epoch 22, Batch 1900] loss: 0.0006727771688724671
[Epoch 22, Batch 2000] loss: 0.010237395770817947
[Epoch 22, Batch 2100] loss: 0.008361358485625487
[Epoch 22, Batch 2200] loss: 0.004963901593067988
[Epoch 22, Batch 2300] loss: 0.003946089455372431
[Epoch 22, Batch 2400] loss: 0.006663298314719555
[Epoch 22, Batch 2500] loss: 0.005333616604940516
[Epoch 22, Batch 2600] loss: 0.005688509937498623
[Epoch 22, Batch 2700] loss: 0.005217899919271077
[Epoch 22, Batch 2800] loss: 0.007564062662616457
[Epoch 22, Batch 2900] loss: 0.0026044870512313524
[Epoch 22, Batch 3000] loss: 0.0025735203076951052
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0599
Validation Accuracy: 0.9879
Overfitting: 0.0599
[Epoch 23, Batch 100] loss: 0.0037373920569930873
[Epoch 23, Batch 200] loss: 0.0019173738696643694
[Epoch 23, Batch 300] loss: 0.00123567412912859
[Epoch 23, Batch 400] loss: 0.0014982266301736713
[Epoch 23, Batch 500] loss: 0.001072989270448268
[Epoch 23, Batch 600] loss: 0.0008265458903604283
[Epoch 23, Batch 700] loss: 0.0010704600866036174
[Epoch 23, Batch 800] loss: 0.0018566998897590991
[Epoch 23, Batch 900] loss: 0.004836359566347639
[Epoch 23, Batch 1000] loss: 0.0025652380807766662
[Epoch 23, Batch 1100] loss: 0.00045513090596129404
[Epoch 23, Batch 1200] loss: 0.0018788210471557675
[Epoch 23, Batch 1300] loss: 0.001101874233911957
[Epoch 23, Batch 1400] loss: 0.005183660994389214
[Epoch 23, Batch 1500] loss: 0.002285142679248917
[Epoch 23, Batch 1600] loss: 0.006789623595609835
[Epoch 23, Batch 1700] loss: 0.007902041070182761
[Epoch 23, Batch 1800] loss: 0.008801884894672369
[Epoch 23, Batch 1900] loss: 0.00414969141238629
[Epoch 23, Batch 2000] loss: 0.0076099855829335535
[Epoch 23, Batch 2100] loss: 0.01173427949897345
[Epoch 23, Batch 2200] loss: 0.00537615435838191
[Epoch 23, Batch 2300] loss: 0.0025398731414193777
[Epoch 23, Batch 2400] loss: 0.0008841884344907313
[Epoch 23, Batch 2500] loss: 0.0010359664078811903
[Epoch 23, Batch 2600] loss: 0.006086201812454628
[Epoch 23, Batch 2700] loss: 0.0015876763699921525
[Epoch 23, Batch 2800] loss: 0.0013259006786643468
[Epoch 23, Batch 2900] loss: 0.0011255337125298936
[Epoch 23, Batch 3000] loss: 0.003812653464343505
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9881
Overfitting: 0.0519
[Epoch 24, Batch 100] loss: 0.0009657999248462757
[Epoch 24, Batch 200] loss: 0.0014415465209080835
[Epoch 24, Batch 300] loss: 0.0005813091397960868
[Epoch 24, Batch 400] loss: 0.0012670296068672737
[Epoch 24, Batch 500] loss: 0.0021046099492367885
[Epoch 24, Batch 600] loss: 0.0015841851185805212
[Epoch 24, Batch 700] loss: 0.0007996576591305882
[Epoch 24, Batch 800] loss: 0.00039022949930011207
[Epoch 24, Batch 900] loss: 0.002097959165298988
[Epoch 24, Batch 1000] loss: 0.0005980462992640057
[Epoch 24, Batch 1100] loss: 0.0005175330438898485
[Epoch 24, Batch 1200] loss: 0.0006994156149377418
[Epoch 24, Batch 1300] loss: 0.0011044119063284797
[Epoch 24, Batch 1400] loss: 0.0009071379239433241
[Epoch 24, Batch 1500] loss: 0.0012056324595246615
[Epoch 24, Batch 1600] loss: 0.0035366399038931993
[Epoch 24, Batch 1700] loss: 0.0017041920471201166
[Epoch 24, Batch 1800] loss: 0.0003918585665789287
[Epoch 24, Batch 1900] loss: 0.0013672242031231008
[Epoch 24, Batch 2000] loss: 0.0005339484849378095
[Epoch 24, Batch 2100] loss: 0.0005604882338983153
[Epoch 24, Batch 2200] loss: 0.00042525251941652795
[Epoch 24, Batch 2300] loss: 0.0008679355405639199
[Epoch 24, Batch 2400] loss: 0.00044895213993029426
[Epoch 24, Batch 2500] loss: 0.0004223602606290511
[Epoch 24, Batch 2600] loss: 0.0005259847929904815
[Epoch 24, Batch 2700] loss: 0.000310289448765273
[Epoch 24, Batch 2800] loss: 0.0007425707412677163
[Epoch 24, Batch 2900] loss: 0.0011381989106496705
[Epoch 24, Batch 3000] loss: 0.001455889320582191
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9890
Overfitting: 0.0543
Fold 4 validation loss: 0.0543
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.279418830871582
[Epoch 1, Batch 200] loss: 2.0842702341079713
[Epoch 1, Batch 300] loss: 0.9790278741717339
[Epoch 1, Batch 400] loss: 0.573166963905096
[Epoch 1, Batch 500] loss: 0.4426270791515708
[Epoch 1, Batch 600] loss: 0.3791964247077704
[Epoch 1, Batch 700] loss: 0.3639985363557935
[Epoch 1, Batch 800] loss: 0.3042046710848808
[Epoch 1, Batch 900] loss: 0.28298420167528093
[Epoch 1, Batch 1000] loss: 0.22974009728059172
[Epoch 1, Batch 1100] loss: 0.21385028291493655
[Epoch 1, Batch 1200] loss: 0.2159798164945096
[Epoch 1, Batch 1300] loss: 0.18566441986709833
[Epoch 1, Batch 1400] loss: 0.2097663665097207
[Epoch 1, Batch 1500] loss: 0.17400826564989985
[Epoch 1, Batch 1600] loss: 0.15379001112654805
[Epoch 1, Batch 1700] loss: 0.15916732663288713
[Epoch 1, Batch 1800] loss: 0.1730637571029365
[Epoch 1, Batch 1900] loss: 0.14783463759347795
[Epoch 1, Batch 2000] loss: 0.16012275940738618
[Epoch 1, Batch 2100] loss: 0.13428749934770168
[Epoch 1, Batch 2200] loss: 0.1435979721369222
[Epoch 1, Batch 2300] loss: 0.09336208955850452
[Epoch 1, Batch 2400] loss: 0.12552738285274245
[Epoch 1, Batch 2500] loss: 0.12014476099750027
[Epoch 1, Batch 2600] loss: 0.1196894251089543
[Epoch 1, Batch 2700] loss: 0.1438893228385132
[Epoch 1, Batch 2800] loss: 0.10612405373249204
[Epoch 1, Batch 2900] loss: 0.11855417667888105
[Epoch 1, Batch 3000] loss: 0.10639530065702274
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1236
Validation Accuracy: 0.9596
Overfitting: 0.1236
Best model saved at epoch 1 with validation loss: 0.1236
[Epoch 2, Batch 100] loss: 0.09097411774331704
[Epoch 2, Batch 200] loss: 0.10101954382378608
[Epoch 2, Batch 300] loss: 0.09950225938227959
[Epoch 2, Batch 400] loss: 0.09733890421222896
[Epoch 2, Batch 500] loss: 0.11087052882881836
[Epoch 2, Batch 600] loss: 0.09723612068220973
[Epoch 2, Batch 700] loss: 0.1044932841300033
[Epoch 2, Batch 800] loss: 0.08745871438411995
[Epoch 2, Batch 900] loss: 0.11937204188201576
[Epoch 2, Batch 1000] loss: 0.09578607159899548
[Epoch 2, Batch 1100] loss: 0.07896293976809829
[Epoch 2, Batch 1200] loss: 0.08708014556905255
[Epoch 2, Batch 1300] loss: 0.08199639639002271
[Epoch 2, Batch 1400] loss: 0.09119021823978983
[Epoch 2, Batch 1500] loss: 0.08781643370981328
[Epoch 2, Batch 1600] loss: 0.09795241076382809
[Epoch 2, Batch 1700] loss: 0.08723577821045182
[Epoch 2, Batch 1800] loss: 0.09688910311553628
[Epoch 2, Batch 1900] loss: 0.08453644552326295
[Epoch 2, Batch 2000] loss: 0.08797917372663505
[Epoch 2, Batch 2100] loss: 0.07862064255517907
[Epoch 2, Batch 2200] loss: 0.08686909901094624
[Epoch 2, Batch 2300] loss: 0.07697845912043703
[Epoch 2, Batch 2400] loss: 0.07932215877808631
[Epoch 2, Batch 2500] loss: 0.08734886416699737
[Epoch 2, Batch 2600] loss: 0.07219894467270933
[Epoch 2, Batch 2700] loss: 0.0839615023159422
[Epoch 2, Batch 2800] loss: 0.08203491944004782
[Epoch 2, Batch 2900] loss: 0.0746254678326659
[Epoch 2, Batch 3000] loss: 0.07832654510159046
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9788
Overfitting: 0.0665
Best model saved at epoch 2 with validation loss: 0.0665
[Epoch 3, Batch 100] loss: 0.07970608087838628
[Epoch 3, Batch 200] loss: 0.08329376831185073
[Epoch 3, Batch 300] loss: 0.06453846583026461
[Epoch 3, Batch 400] loss: 0.04733440606680233
[Epoch 3, Batch 500] loss: 0.05425242449389771
[Epoch 3, Batch 600] loss: 0.06644432944303844
[Epoch 3, Batch 700] loss: 0.06080569830199238
[Epoch 3, Batch 800] loss: 0.04927271952154115
[Epoch 3, Batch 900] loss: 0.06826802031777333
[Epoch 3, Batch 1000] loss: 0.06398660161648877
[Epoch 3, Batch 1100] loss: 0.06883701223530807
[Epoch 3, Batch 1200] loss: 0.06147371069411747
[Epoch 3, Batch 1300] loss: 0.05959576696157456
[Epoch 3, Batch 1400] loss: 0.0826904213767557
[Epoch 3, Batch 1500] loss: 0.07979882642044686
[Epoch 3, Batch 1600] loss: 0.058105773042771036
[Epoch 3, Batch 1700] loss: 0.04992711290571606
[Epoch 3, Batch 1800] loss: 0.06807739804731681
[Epoch 3, Batch 1900] loss: 0.05045419788628351
[Epoch 3, Batch 2000] loss: 0.06987015330931172
[Epoch 3, Batch 2100] loss: 0.06828734037582762
[Epoch 3, Batch 2200] loss: 0.048198661691858435
[Epoch 3, Batch 2300] loss: 0.053588234523776916
[Epoch 3, Batch 2400] loss: 0.053814018244011094
[Epoch 3, Batch 2500] loss: 0.07149851526774001
[Epoch 3, Batch 2600] loss: 0.061473417225352024
[Epoch 3, Batch 2700] loss: 0.07058054525638
[Epoch 3, Batch 2800] loss: 0.06824008282041177
[Epoch 3, Batch 2900] loss: 0.05069279171642847
[Epoch 3, Batch 3000] loss: 0.04507504823064665
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0572
Validation Accuracy: 0.9822
Overfitting: 0.0572
Best model saved at epoch 3 with validation loss: 0.0572
[Epoch 4, Batch 100] loss: 0.03641897915134905
[Epoch 4, Batch 200] loss: 0.022812735027691815
[Epoch 4, Batch 300] loss: 0.044155068127729465
[Epoch 4, Batch 400] loss: 0.04138406656318693
[Epoch 4, Batch 500] loss: 0.03621188517041446
[Epoch 4, Batch 600] loss: 0.0530151426550583
[Epoch 4, Batch 700] loss: 0.04435346882179147
[Epoch 4, Batch 800] loss: 0.0552056992528378
[Epoch 4, Batch 900] loss: 0.061043760566681156
[Epoch 4, Batch 1000] loss: 0.05537150917050895
[Epoch 4, Batch 1100] loss: 0.059953664923086764
[Epoch 4, Batch 1200] loss: 0.04959852139843861
[Epoch 4, Batch 1300] loss: 0.04194591936859069
[Epoch 4, Batch 1400] loss: 0.04627132722729584
[Epoch 4, Batch 1500] loss: 0.05017749992606696
[Epoch 4, Batch 1600] loss: 0.06275865224422887
[Epoch 4, Batch 1700] loss: 0.04713378337910399
[Epoch 4, Batch 1800] loss: 0.06036887451307848
[Epoch 4, Batch 1900] loss: 0.063603083610069
[Epoch 4, Batch 2000] loss: 0.05633256937784609
[Epoch 4, Batch 2100] loss: 0.040821609488048125
[Epoch 4, Batch 2200] loss: 0.06116292625200003
[Epoch 4, Batch 2300] loss: 0.05437617281306302
[Epoch 4, Batch 2400] loss: 0.0454269353923155
[Epoch 4, Batch 2500] loss: 0.046705971018818675
[Epoch 4, Batch 2600] loss: 0.03377875059552025
[Epoch 4, Batch 2700] loss: 0.04398332806114922
[Epoch 4, Batch 2800] loss: 0.06253638487803982
[Epoch 4, Batch 2900] loss: 0.04069076653278898
[Epoch 4, Batch 3000] loss: 0.05321618700458203
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0610
Validation Accuracy: 0.9807
Overfitting: 0.0610
[Epoch 5, Batch 100] loss: 0.03964465987257427
[Epoch 5, Batch 200] loss: 0.031981695735885295
[Epoch 5, Batch 300] loss: 0.03830125964712352
[Epoch 5, Batch 400] loss: 0.03902793715533335
[Epoch 5, Batch 500] loss: 0.0496832386762253
[Epoch 5, Batch 600] loss: 0.03529879309156968
[Epoch 5, Batch 700] loss: 0.053816523688183224
[Epoch 5, Batch 800] loss: 0.034186382090265394
[Epoch 5, Batch 900] loss: 0.03985737992756185
[Epoch 5, Batch 1000] loss: 0.03726995254444773
[Epoch 5, Batch 1100] loss: 0.05786144766010693
[Epoch 5, Batch 1200] loss: 0.04188159031429677
[Epoch 5, Batch 1300] loss: 0.030517627721710596
[Epoch 5, Batch 1400] loss: 0.04953449139808072
[Epoch 5, Batch 1500] loss: 0.03807783301555901
[Epoch 5, Batch 1600] loss: 0.04172179090586724
[Epoch 5, Batch 1700] loss: 0.06624025136727141
[Epoch 5, Batch 1800] loss: 0.03984286299077212
[Epoch 5, Batch 1900] loss: 0.030923128431604708
[Epoch 5, Batch 2000] loss: 0.03486252749455161
[Epoch 5, Batch 2100] loss: 0.03986894742003642
[Epoch 5, Batch 2200] loss: 0.024381220414652488
[Epoch 5, Batch 2300] loss: 0.0467055916035315
[Epoch 5, Batch 2400] loss: 0.0332614167452266
[Epoch 5, Batch 2500] loss: 0.03886329264860251
[Epoch 5, Batch 2600] loss: 0.05014926845760783
[Epoch 5, Batch 2700] loss: 0.03912394947197754
[Epoch 5, Batch 2800] loss: 0.05151877480035182
[Epoch 5, Batch 2900] loss: 0.03566931270826899
[Epoch 5, Batch 3000] loss: 0.03522052517044358
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9844
Overfitting: 0.0491
Best model saved at epoch 5 with validation loss: 0.0491
[Epoch 6, Batch 100] loss: 0.017844810821588907
[Epoch 6, Batch 200] loss: 0.04950191756184722
[Epoch 6, Batch 300] loss: 0.04529323589969863
[Epoch 6, Batch 400] loss: 0.042718003994086755
[Epoch 6, Batch 500] loss: 0.037520823357481276
[Epoch 6, Batch 600] loss: 0.036196752085379556
[Epoch 6, Batch 700] loss: 0.03627480763396306
[Epoch 6, Batch 800] loss: 0.024846274456649553
[Epoch 6, Batch 900] loss: 0.03821026651770808
[Epoch 6, Batch 1000] loss: 0.0323973166468204
[Epoch 6, Batch 1100] loss: 0.032790838671789974
[Epoch 6, Batch 1200] loss: 0.04503519835838233
[Epoch 6, Batch 1300] loss: 0.03869584886429948
[Epoch 6, Batch 1400] loss: 0.030590398532003748
[Epoch 6, Batch 1500] loss: 0.036730656734653165
[Epoch 6, Batch 1600] loss: 0.04109144685935462
[Epoch 6, Batch 1700] loss: 0.02822492278937716
[Epoch 6, Batch 1800] loss: 0.023015021203173093
[Epoch 6, Batch 1900] loss: 0.02848452409834863
[Epoch 6, Batch 2000] loss: 0.027656524120247925
[Epoch 6, Batch 2100] loss: 0.037876300287025516
[Epoch 6, Batch 2200] loss: 0.03829246923778555
[Epoch 6, Batch 2300] loss: 0.028711834443674887
[Epoch 6, Batch 2400] loss: 0.04040506529330742
[Epoch 6, Batch 2500] loss: 0.04017554388825374
[Epoch 6, Batch 2600] loss: 0.02547157707485894
[Epoch 6, Batch 2700] loss: 0.028584877621688064
[Epoch 6, Batch 2800] loss: 0.03527127333356475
[Epoch 6, Batch 2900] loss: 0.033462910773341716
[Epoch 6, Batch 3000] loss: 0.024787526234285907
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9832
Overfitting: 0.0560
[Epoch 7, Batch 100] loss: 0.020054075832813396
[Epoch 7, Batch 200] loss: 0.03346573438233463
[Epoch 7, Batch 300] loss: 0.033808315687274444
[Epoch 7, Batch 400] loss: 0.018563174289593008
[Epoch 7, Batch 500] loss: 0.0426365801342763
[Epoch 7, Batch 600] loss: 0.02388800762644678
[Epoch 7, Batch 700] loss: 0.009784739597271254
[Epoch 7, Batch 800] loss: 0.0188083784194896
[Epoch 7, Batch 900] loss: 0.020464576230806414
[Epoch 7, Batch 1000] loss: 0.03712024003834813
[Epoch 7, Batch 1100] loss: 0.022972004569455747
[Epoch 7, Batch 1200] loss: 0.020427149300667226
[Epoch 7, Batch 1300] loss: 0.023326172698816663
[Epoch 7, Batch 1400] loss: 0.02464678444855963
[Epoch 7, Batch 1500] loss: 0.02841234023522702
[Epoch 7, Batch 1600] loss: 0.03311377420013741
[Epoch 7, Batch 1700] loss: 0.02519306030408188
[Epoch 7, Batch 1800] loss: 0.024725375444977545
[Epoch 7, Batch 1900] loss: 0.023915766028003417
[Epoch 7, Batch 2000] loss: 0.033586208630331384
[Epoch 7, Batch 2100] loss: 0.021262301105780354
[Epoch 7, Batch 2200] loss: 0.0501422129270577
[Epoch 7, Batch 2300] loss: 0.03916958866029745
[Epoch 7, Batch 2400] loss: 0.04445660564946593
[Epoch 7, Batch 2500] loss: 0.0245977053646493
[Epoch 7, Batch 2600] loss: 0.057111569020562455
[Epoch 7, Batch 2700] loss: 0.040480300389172046
[Epoch 7, Batch 2800] loss: 0.028592087696597445
[Epoch 7, Batch 2900] loss: 0.027130281249701512
[Epoch 7, Batch 3000] loss: 0.024131691462462187
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9842
Overfitting: 0.0450
Best model saved at epoch 7 with validation loss: 0.0450
[Epoch 8, Batch 100] loss: 0.021664154122699984
[Epoch 8, Batch 200] loss: 0.026611353918306123
[Epoch 8, Batch 300] loss: 0.02217578000301728
[Epoch 8, Batch 400] loss: 0.010814412218423967
[Epoch 8, Batch 500] loss: 0.020418874154711376
[Epoch 8, Batch 600] loss: 0.022249813357266248
[Epoch 8, Batch 700] loss: 0.02373022155728904
[Epoch 8, Batch 800] loss: 0.019776128161993256
[Epoch 8, Batch 900] loss: 0.02229079781933251
[Epoch 8, Batch 1000] loss: 0.01288442520353783
[Epoch 8, Batch 1100] loss: 0.017270052408821356
[Epoch 8, Batch 1200] loss: 0.020683928083162755
[Epoch 8, Batch 1300] loss: 0.03566729167374433
[Epoch 8, Batch 1400] loss: 0.028474787398226908
[Epoch 8, Batch 1500] loss: 0.03592863770903932
[Epoch 8, Batch 1600] loss: 0.02302840238691715
[Epoch 8, Batch 1700] loss: 0.015945619272315525
[Epoch 8, Batch 1800] loss: 0.028086295041066477
[Epoch 8, Batch 1900] loss: 0.036988011050998464
[Epoch 8, Batch 2000] loss: 0.031229568535636645
[Epoch 8, Batch 2100] loss: 0.018260292304476025
[Epoch 8, Batch 2200] loss: 0.020860534423081844
[Epoch 8, Batch 2300] loss: 0.02119904566599871
[Epoch 8, Batch 2400] loss: 0.026636224064041016
[Epoch 8, Batch 2500] loss: 0.01975467901720549
[Epoch 8, Batch 2600] loss: 0.013540696217751247
[Epoch 8, Batch 2700] loss: 0.040544362923683366
[Epoch 8, Batch 2800] loss: 0.02839059019672277
[Epoch 8, Batch 2900] loss: 0.041890210934652714
[Epoch 8, Batch 3000] loss: 0.02743416887082276
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0419
Validation Accuracy: 0.9873
Overfitting: 0.0419
Best model saved at epoch 8 with validation loss: 0.0419
[Epoch 9, Batch 100] loss: 0.011695333556235709
[Epoch 9, Batch 200] loss: 0.015806876463284426
[Epoch 9, Batch 300] loss: 0.020032612819586574
[Epoch 9, Batch 400] loss: 0.024441369191918055
[Epoch 9, Batch 500] loss: 0.023443249953270424
[Epoch 9, Batch 600] loss: 0.021821761283481466
[Epoch 9, Batch 700] loss: 0.03425173135216028
[Epoch 9, Batch 800] loss: 0.018421677740589074
[Epoch 9, Batch 900] loss: 0.022183692603684902
[Epoch 9, Batch 1000] loss: 0.024214102623036523
[Epoch 9, Batch 1100] loss: 0.028262715880664473
[Epoch 9, Batch 1200] loss: 0.025206614615381113
[Epoch 9, Batch 1300] loss: 0.019215562520112143
[Epoch 9, Batch 1400] loss: 0.01691376387647324
[Epoch 9, Batch 1500] loss: 0.018398862020439992
[Epoch 9, Batch 1600] loss: 0.020203037793708065
[Epoch 9, Batch 1700] loss: 0.03698408736815509
[Epoch 9, Batch 1800] loss: 0.031372936161642426
[Epoch 9, Batch 1900] loss: 0.027208325039937337
[Epoch 9, Batch 2000] loss: 0.01927339159807161
[Epoch 9, Batch 2100] loss: 0.026793714482701035
[Epoch 9, Batch 2200] loss: 0.0198490609610235
[Epoch 9, Batch 2300] loss: 0.035107179931837894
[Epoch 9, Batch 2400] loss: 0.009916523972169671
[Epoch 9, Batch 2500] loss: 0.010982377531545353
[Epoch 9, Batch 2600] loss: 0.017454541925826562
[Epoch 9, Batch 2700] loss: 0.023917585163071634
[Epoch 9, Batch 2800] loss: 0.017265827317623918
[Epoch 9, Batch 2900] loss: 0.020413714551259544
[Epoch 9, Batch 3000] loss: 0.015810981788636127
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9853
Overfitting: 0.0510
[Epoch 10, Batch 100] loss: 0.016058687312470284
[Epoch 10, Batch 200] loss: 0.008043498838014784
[Epoch 10, Batch 300] loss: 0.021803501984013565
[Epoch 10, Batch 400] loss: 0.02417110303800655
[Epoch 10, Batch 500] loss: 0.027226335382574688
[Epoch 10, Batch 600] loss: 0.016433227460702256
[Epoch 10, Batch 700] loss: 0.012143289936775546
[Epoch 10, Batch 800] loss: 0.01584781093529273
[Epoch 10, Batch 900] loss: 0.023009789284196815
[Epoch 10, Batch 1000] loss: 0.020119303500796378
[Epoch 10, Batch 1100] loss: 0.023781216378774842
[Epoch 10, Batch 1200] loss: 0.020012027377870254
[Epoch 10, Batch 1300] loss: 0.027848841244831418
[Epoch 10, Batch 1400] loss: 0.018430576052251128
[Epoch 10, Batch 1500] loss: 0.01828522948923819
[Epoch 10, Batch 1600] loss: 0.016351522282129737
[Epoch 10, Batch 1700] loss: 0.015211736387464043
[Epoch 10, Batch 1800] loss: 0.014599900568537123
[Epoch 10, Batch 1900] loss: 0.011272464204430434
[Epoch 10, Batch 2000] loss: 0.020739331872800904
[Epoch 10, Batch 2100] loss: 0.01667570661758873
[Epoch 10, Batch 2200] loss: 0.01678434972039213
[Epoch 10, Batch 2300] loss: 0.01983209518320564
[Epoch 10, Batch 2400] loss: 0.016595046754173382
[Epoch 10, Batch 2500] loss: 0.014672992343330407
[Epoch 10, Batch 2600] loss: 0.03003503155782255
[Epoch 10, Batch 2700] loss: 0.016284220052566526
[Epoch 10, Batch 2800] loss: 0.016518497420729545
[Epoch 10, Batch 2900] loss: 0.022542659528699004
[Epoch 10, Batch 3000] loss: 0.014483611443647532
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9867
Overfitting: 0.0466
[Epoch 11, Batch 100] loss: 0.013212778004563006
[Epoch 11, Batch 200] loss: 0.021723434868822552
[Epoch 11, Batch 300] loss: 0.01475993205773193
[Epoch 11, Batch 400] loss: 0.009783297344074526
[Epoch 11, Batch 500] loss: 0.013531251280573997
[Epoch 11, Batch 600] loss: 0.010133484021662299
[Epoch 11, Batch 700] loss: 0.011136008794310329
[Epoch 11, Batch 800] loss: 0.011666823952236883
[Epoch 11, Batch 900] loss: 0.023753727711236933
[Epoch 11, Batch 1000] loss: 0.01124769501046785
[Epoch 11, Batch 1100] loss: 0.009428736721747554
[Epoch 11, Batch 1200] loss: 0.00913897604662452
[Epoch 11, Batch 1300] loss: 0.01122783364402494
[Epoch 11, Batch 1400] loss: 0.009787134992993742
[Epoch 11, Batch 1500] loss: 0.01627176739509423
[Epoch 11, Batch 1600] loss: 0.02014712278071329
[Epoch 11, Batch 1700] loss: 0.020572664334049477
[Epoch 11, Batch 1800] loss: 0.013054385649065808
[Epoch 11, Batch 1900] loss: 0.022428010677213023
[Epoch 11, Batch 2000] loss: 0.01479844207111455
[Epoch 11, Batch 2100] loss: 0.01911766843434634
[Epoch 11, Batch 2200] loss: 0.02400079104838369
[Epoch 11, Batch 2300] loss: 0.03391195096086449
[Epoch 11, Batch 2400] loss: 0.013067045627581137
[Epoch 11, Batch 2500] loss: 0.011167048955494465
[Epoch 11, Batch 2600] loss: 0.02416156729618251
[Epoch 11, Batch 2700] loss: 0.01960627873301746
[Epoch 11, Batch 2800] loss: 0.029326642180922135
[Epoch 11, Batch 2900] loss: 0.02035712646906177
[Epoch 11, Batch 3000] loss: 0.015542929976363666
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0410
Validation Accuracy: 0.9872
Overfitting: 0.0410
Best model saved at epoch 11 with validation loss: 0.0410
[Epoch 12, Batch 100] loss: 0.010013491798172253
[Epoch 12, Batch 200] loss: 0.012447893192220363
[Epoch 12, Batch 300] loss: 0.009560345224758748
[Epoch 12, Batch 400] loss: 0.009155772385238379
[Epoch 12, Batch 500] loss: 0.008195910538256612
[Epoch 12, Batch 600] loss: 0.009351980198293858
[Epoch 12, Batch 700] loss: 0.014117356413098605
[Epoch 12, Batch 800] loss: 0.009511131179901895
[Epoch 12, Batch 900] loss: 0.014244897348276027
[Epoch 12, Batch 1000] loss: 0.017031726297400383
[Epoch 12, Batch 1100] loss: 0.012414329788384748
[Epoch 12, Batch 1200] loss: 0.005878905705571924
[Epoch 12, Batch 1300] loss: 0.023409404503418045
[Epoch 12, Batch 1400] loss: 0.01787168885745814
[Epoch 12, Batch 1500] loss: 0.02256669330702607
[Epoch 12, Batch 1600] loss: 0.011164654437397985
[Epoch 12, Batch 1700] loss: 0.013044334898331726
[Epoch 12, Batch 1800] loss: 0.021300560439735817
[Epoch 12, Batch 1900] loss: 0.01228870239522621
[Epoch 12, Batch 2000] loss: 0.009391342700200766
[Epoch 12, Batch 2100] loss: 0.007582534703465172
[Epoch 12, Batch 2200] loss: 0.011863861121282753
[Epoch 12, Batch 2300] loss: 0.03261213273575777
[Epoch 12, Batch 2400] loss: 0.020584536269525416
[Epoch 12, Batch 2500] loss: 0.01033525881930018
[Epoch 12, Batch 2600] loss: 0.01876805895709822
[Epoch 12, Batch 2700] loss: 0.01625859022759869
[Epoch 12, Batch 2800] loss: 0.018700409424227474
[Epoch 12, Batch 2900] loss: 0.009059333461955248
[Epoch 12, Batch 3000] loss: 0.013735251904709003
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0426
Validation Accuracy: 0.9879
Overfitting: 0.0426
[Epoch 13, Batch 100] loss: 0.005695612613931189
[Epoch 13, Batch 200] loss: 0.014525580254544366
[Epoch 13, Batch 300] loss: 0.018507163131798735
[Epoch 13, Batch 400] loss: 0.008527477024522341
[Epoch 13, Batch 500] loss: 0.0100613436384333
[Epoch 13, Batch 600] loss: 0.01067281127762726
[Epoch 13, Batch 700] loss: 0.012511213984675465
[Epoch 13, Batch 800] loss: 0.003192521398386816
[Epoch 13, Batch 900] loss: 0.010833199552598672
[Epoch 13, Batch 1000] loss: 0.009896496501024785
[Epoch 13, Batch 1100] loss: 0.012236005858749194
[Epoch 13, Batch 1200] loss: 0.007947049715912726
[Epoch 13, Batch 1300] loss: 0.0057265978622308466
[Epoch 13, Batch 1400] loss: 0.0089337591220567
[Epoch 13, Batch 1500] loss: 0.017572665206398597
[Epoch 13, Batch 1600] loss: 0.013178489574365813
[Epoch 13, Batch 1700] loss: 0.017820943984224867
[Epoch 13, Batch 1800] loss: 0.021950212983197163
[Epoch 13, Batch 1900] loss: 0.004265567950915284
[Epoch 13, Batch 2000] loss: 0.010540711969815675
[Epoch 13, Batch 2100] loss: 0.02155804212194653
[Epoch 13, Batch 2200] loss: 0.03283249829268243
[Epoch 13, Batch 2300] loss: 0.01695066553472316
[Epoch 13, Batch 2400] loss: 0.011756661807557975
[Epoch 13, Batch 2500] loss: 0.014524565858191636
[Epoch 13, Batch 2600] loss: 0.01861543535036617
[Epoch 13, Batch 2700] loss: 0.006204530180229995
[Epoch 13, Batch 2800] loss: 0.011541880930617482
[Epoch 13, Batch 2900] loss: 0.008443669435655466
[Epoch 13, Batch 3000] loss: 0.016693037229670152
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9858
Overfitting: 0.0518
[Epoch 14, Batch 100] loss: 0.006375874058408044
[Epoch 14, Batch 200] loss: 0.0057730397716704825
[Epoch 14, Batch 300] loss: 0.0065904909273149315
[Epoch 14, Batch 400] loss: 0.012756008574451699
[Epoch 14, Batch 500] loss: 0.017846608926777207
[Epoch 14, Batch 600] loss: 0.009279149553640877
[Epoch 14, Batch 700] loss: 0.01162063634909373
[Epoch 14, Batch 800] loss: 0.011587700667839727
[Epoch 14, Batch 900] loss: 0.006292482534290684
[Epoch 14, Batch 1000] loss: 0.005155169372018804
[Epoch 14, Batch 1100] loss: 0.013212011196879416
[Epoch 14, Batch 1200] loss: 0.020986328336407498
[Epoch 14, Batch 1300] loss: 0.012593798477399786
[Epoch 14, Batch 1400] loss: 0.012149059373331283
[Epoch 14, Batch 1500] loss: 0.012351215996700375
[Epoch 14, Batch 1600] loss: 0.011303914116983832
[Epoch 14, Batch 1700] loss: 0.00660392192866766
[Epoch 14, Batch 1800] loss: 0.008978598988499016
[Epoch 14, Batch 1900] loss: 0.008836193415729667
[Epoch 14, Batch 2000] loss: 0.007934646667861216
[Epoch 14, Batch 2100] loss: 0.005959664627266647
[Epoch 14, Batch 2200] loss: 0.010351797538801293
[Epoch 14, Batch 2300] loss: 0.006231476306852528
[Epoch 14, Batch 2400] loss: 0.012366617855694812
[Epoch 14, Batch 2500] loss: 0.02377401936564411
[Epoch 14, Batch 2600] loss: 0.015061983613827578
[Epoch 14, Batch 2700] loss: 0.01008403662427213
[Epoch 14, Batch 2800] loss: 0.01626453623772477
[Epoch 14, Batch 2900] loss: 0.006244340304720026
[Epoch 14, Batch 3000] loss: 0.016070743475111157
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9863
Overfitting: 0.0529
[Epoch 15, Batch 100] loss: 0.014513587324354376
[Epoch 15, Batch 200] loss: 0.007357809693480703
[Epoch 15, Batch 300] loss: 0.00439782217076754
[Epoch 15, Batch 400] loss: 0.005405684164361446
[Epoch 15, Batch 500] loss: 0.006918318640414327
[Epoch 15, Batch 600] loss: 0.0036770682049980506
[Epoch 15, Batch 700] loss: 0.0042788087041098774
[Epoch 15, Batch 800] loss: 0.015954376049512574
[Epoch 15, Batch 900] loss: 0.01152329879970921
[Epoch 15, Batch 1000] loss: 0.006932965872462091
[Epoch 15, Batch 1100] loss: 0.013318106355645795
[Epoch 15, Batch 1200] loss: 0.012049901864775165
[Epoch 15, Batch 1300] loss: 0.0123127359596117
[Epoch 15, Batch 1400] loss: 0.008888129874351306
[Epoch 15, Batch 1500] loss: 0.008353843789743678
[Epoch 15, Batch 1600] loss: 0.010559271495269513
[Epoch 15, Batch 1700] loss: 0.006707477609195394
[Epoch 15, Batch 1800] loss: 0.01406379507411657
[Epoch 15, Batch 1900] loss: 0.013565772249902465
[Epoch 15, Batch 2000] loss: 0.007022882558981109
[Epoch 15, Batch 2100] loss: 0.006057486122444686
[Epoch 15, Batch 2200] loss: 0.01738085632143111
[Epoch 15, Batch 2300] loss: 0.007461714011668619
[Epoch 15, Batch 2400] loss: 0.009847777132881675
[Epoch 15, Batch 2500] loss: 0.009165864495337246
[Epoch 15, Batch 2600] loss: 0.015419659221238361
[Epoch 15, Batch 2700] loss: 0.010615818948626838
[Epoch 15, Batch 2800] loss: 0.00546811753049667
[Epoch 15, Batch 2900] loss: 0.01597327917400719
[Epoch 15, Batch 3000] loss: 0.010715083235928092
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9874
Overfitting: 0.0482
[Epoch 16, Batch 100] loss: 0.006249391836335576
[Epoch 16, Batch 200] loss: 0.0049110967500905645
[Epoch 16, Batch 300] loss: 0.015478795552383531
[Epoch 16, Batch 400] loss: 0.0030986427399489003
[Epoch 16, Batch 500] loss: 0.00719104792553594
[Epoch 16, Batch 600] loss: 0.014348592031283828
[Epoch 16, Batch 700] loss: 0.01128467807528068
[Epoch 16, Batch 800] loss: 0.008604979693610631
[Epoch 16, Batch 900] loss: 0.006753615905012111
[Epoch 16, Batch 1000] loss: 0.003706711704844565
[Epoch 16, Batch 1100] loss: 0.003934219262741579
[Epoch 16, Batch 1200] loss: 0.007881949836298077
[Epoch 16, Batch 1300] loss: 0.010311602782372517
[Epoch 16, Batch 1400] loss: 0.005370202579817374
[Epoch 16, Batch 1500] loss: 0.005191196976270475
[Epoch 16, Batch 1600] loss: 0.0072612357216337384
[Epoch 16, Batch 1700] loss: 0.004800138519982369
[Epoch 16, Batch 1800] loss: 0.007201720824013478
[Epoch 16, Batch 1900] loss: 0.006020416887823785
[Epoch 16, Batch 2000] loss: 0.005075014652807113
[Epoch 16, Batch 2100] loss: 0.004161041189378807
[Epoch 16, Batch 2200] loss: 0.0038227452554758655
[Epoch 16, Batch 2300] loss: 0.004812780175004718
[Epoch 16, Batch 2400] loss: 0.00759030807094394
[Epoch 16, Batch 2500] loss: 0.006490861819315796
[Epoch 16, Batch 2600] loss: 0.013386379943331122
[Epoch 16, Batch 2700] loss: 0.012946968136672012
[Epoch 16, Batch 2800] loss: 0.01583752721326782
[Epoch 16, Batch 2900] loss: 0.01820828665561919
[Epoch 16, Batch 3000] loss: 0.011870273113455596
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9865
Overfitting: 0.0537
[Epoch 17, Batch 100] loss: 0.006041111777484502
[Epoch 17, Batch 200] loss: 0.003620104772389823
[Epoch 17, Batch 300] loss: 0.0037565505773750375
[Epoch 17, Batch 400] loss: 0.00270671667067063
[Epoch 17, Batch 500] loss: 0.007328261242014946
[Epoch 17, Batch 600] loss: 0.005768283325778043
[Epoch 17, Batch 700] loss: 0.005179225972501058
[Epoch 17, Batch 800] loss: 0.005744485519152818
[Epoch 17, Batch 900] loss: 0.00678763580214337
[Epoch 17, Batch 1000] loss: 0.006122669934986717
[Epoch 17, Batch 1100] loss: 0.004656686878155796
[Epoch 17, Batch 1200] loss: 0.012858376338563958
[Epoch 17, Batch 1300] loss: 0.01789712968748063
[Epoch 17, Batch 1400] loss: 0.006350140223465814
[Epoch 17, Batch 1500] loss: 0.007593568541091144
[Epoch 17, Batch 1600] loss: 0.003558386201356427
[Epoch 17, Batch 1700] loss: 0.005034175909424903
[Epoch 17, Batch 1800] loss: 0.005065864442419752
[Epoch 17, Batch 1900] loss: 0.003999846144848789
[Epoch 17, Batch 2000] loss: 0.0035914730800874397
[Epoch 17, Batch 2100] loss: 0.008118649318848838
[Epoch 17, Batch 2200] loss: 0.005104409717640123
[Epoch 17, Batch 2300] loss: 0.015476353893153884
[Epoch 17, Batch 2400] loss: 0.016811342428128456
[Epoch 17, Batch 2500] loss: 0.01094543860037561
[Epoch 17, Batch 2600] loss: 0.012263189800148667
[Epoch 17, Batch 2700] loss: 0.013043426844776605
[Epoch 17, Batch 2800] loss: 0.02414338335287425
[Epoch 17, Batch 2900] loss: 0.01646491121324459
[Epoch 17, Batch 3000] loss: 0.008669662397046522
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9878
Overfitting: 0.0520
[Epoch 18, Batch 100] loss: 0.01006169819081606
[Epoch 18, Batch 200] loss: 0.018452586354010803
[Epoch 18, Batch 300] loss: 0.007444339906134019
[Epoch 18, Batch 400] loss: 0.003552142102683291
[Epoch 18, Batch 500] loss: 0.005856307334976236
[Epoch 18, Batch 600] loss: 0.0009744885656016322
[Epoch 18, Batch 700] loss: 0.0072520129056505315
[Epoch 18, Batch 800] loss: 0.01094116150925771
[Epoch 18, Batch 900] loss: 0.004543048313904876
[Epoch 18, Batch 1000] loss: 0.004992853062828431
[Epoch 18, Batch 1100] loss: 0.0048613697000661205
[Epoch 18, Batch 1200] loss: 0.00633675780695171
[Epoch 18, Batch 1300] loss: 0.009054010398813404
[Epoch 18, Batch 1400] loss: 0.00516882972642847
[Epoch 18, Batch 1500] loss: 0.004006959293719774
[Epoch 18, Batch 1600] loss: 0.021501456719979828
[Epoch 18, Batch 1700] loss: 0.006695778716666609
[Epoch 18, Batch 1800] loss: 0.007111643443640752
[Epoch 18, Batch 1900] loss: 0.014339359019679705
[Epoch 18, Batch 2000] loss: 0.008566572551615081
[Epoch 18, Batch 2100] loss: 0.008684130084036212
[Epoch 18, Batch 2200] loss: 0.007527901221104685
[Epoch 18, Batch 2300] loss: 0.012270037271451031
[Epoch 18, Batch 2400] loss: 0.00861139357006678
[Epoch 18, Batch 2500] loss: 0.00452573255021079
[Epoch 18, Batch 2600] loss: 0.004506357770906675
[Epoch 18, Batch 2700] loss: 0.007379319230626571
[Epoch 18, Batch 2800] loss: 0.01567719664700178
[Epoch 18, Batch 2900] loss: 0.009762762816749274
[Epoch 18, Batch 3000] loss: 0.013853892604411158
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9866
Overfitting: 0.0519
[Epoch 19, Batch 100] loss: 0.006596572772159561
[Epoch 19, Batch 200] loss: 0.004728828964968273
[Epoch 19, Batch 300] loss: 0.007647963833787799
[Epoch 19, Batch 400] loss: 0.00382261529642733
[Epoch 19, Batch 500] loss: 0.007227408559044761
[Epoch 19, Batch 600] loss: 0.0015655065133523749
[Epoch 19, Batch 700] loss: 0.014225737885194007
[Epoch 19, Batch 800] loss: 0.002308675494954855
[Epoch 19, Batch 900] loss: 0.0037180743215958502
[Epoch 19, Batch 1000] loss: 0.007768611953841287
[Epoch 19, Batch 1100] loss: 0.009749448786521953
[Epoch 19, Batch 1200] loss: 0.005446157775934815
[Epoch 19, Batch 1300] loss: 0.001702294969792888
[Epoch 19, Batch 1400] loss: 0.00513524864495082
[Epoch 19, Batch 1500] loss: 0.006408324163765542
[Epoch 19, Batch 1600] loss: 0.0030204651099018064
[Epoch 19, Batch 1700] loss: 0.004788105987746718
[Epoch 19, Batch 1800] loss: 0.01007770758636184
[Epoch 19, Batch 1900] loss: 0.009757467597389678
[Epoch 19, Batch 2000] loss: 0.005319155849655814
[Epoch 19, Batch 2100] loss: 0.006682826856753081
[Epoch 19, Batch 2200] loss: 0.002630756685574056
[Epoch 19, Batch 2300] loss: 0.005509333726957948
[Epoch 19, Batch 2400] loss: 0.004457340670311396
[Epoch 19, Batch 2500] loss: 0.005390839748578173
[Epoch 19, Batch 2600] loss: 0.005248306392520874
[Epoch 19, Batch 2700] loss: 0.005269108877645578
[Epoch 19, Batch 2800] loss: 0.020806174421727518
[Epoch 19, Batch 2900] loss: 0.009733909929839796
[Epoch 19, Batch 3000] loss: 0.005310409229905417
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9886
Overfitting: 0.0486
[Epoch 20, Batch 100] loss: 0.014217508951162899
[Epoch 20, Batch 200] loss: 0.002310924628145159
[Epoch 20, Batch 300] loss: 0.0029694353863939683
[Epoch 20, Batch 400] loss: 0.0030422150769831547
[Epoch 20, Batch 500] loss: 0.005541282127491485
[Epoch 20, Batch 600] loss: 0.0022176141615746657
[Epoch 20, Batch 700] loss: 0.0032574613518306706
[Epoch 20, Batch 800] loss: 0.004983177316551917
[Epoch 20, Batch 900] loss: 0.0069203053717376405
[Epoch 20, Batch 1000] loss: 0.0017778928149066787
[Epoch 20, Batch 1100] loss: 0.00908669855388581
[Epoch 20, Batch 1200] loss: 0.006738349213984804
[Epoch 20, Batch 1300] loss: 0.006482686333960715
[Epoch 20, Batch 1400] loss: 0.011363047367333259
[Epoch 20, Batch 1500] loss: 0.008291177850868508
[Epoch 20, Batch 1600] loss: 0.009714147309829856
[Epoch 20, Batch 1700] loss: 0.003898740320161096
[Epoch 20, Batch 1800] loss: 0.0059592565136370014
[Epoch 20, Batch 1900] loss: 0.012031023983906835
[Epoch 20, Batch 2000] loss: 0.008727459345704175
[Epoch 20, Batch 2100] loss: 0.008638816455550823
[Epoch 20, Batch 2200] loss: 0.004049126332488982
[Epoch 20, Batch 2300] loss: 0.005003171369947382
[Epoch 20, Batch 2400] loss: 0.010473037918939667
[Epoch 20, Batch 2500] loss: 0.008159465299911801
[Epoch 20, Batch 2600] loss: 0.012538253114086184
[Epoch 20, Batch 2700] loss: 0.009020976492545857
[Epoch 20, Batch 2800] loss: 0.015430258642192456
[Epoch 20, Batch 2900] loss: 0.009262134995875044
[Epoch 20, Batch 3000] loss: 0.006614796946269905
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0545
Validation Accuracy: 0.9875
Overfitting: 0.0545
[Epoch 21, Batch 100] loss: 0.010548468605667266
[Epoch 21, Batch 200] loss: 0.008766913734701731
[Epoch 21, Batch 300] loss: 0.005424783393072516
[Epoch 21, Batch 400] loss: 0.01071243308956344
[Epoch 21, Batch 500] loss: 0.001890959915255621
[Epoch 21, Batch 600] loss: 0.0030283271749868847
[Epoch 21, Batch 700] loss: 0.001800414432917421
[Epoch 21, Batch 800] loss: 0.0023079852056005733
[Epoch 21, Batch 900] loss: 0.003781572688635606
[Epoch 21, Batch 1000] loss: 0.0026148048629517006
[Epoch 21, Batch 1100] loss: 0.004181910433850362
[Epoch 21, Batch 1200] loss: 0.0026783821950955656
[Epoch 21, Batch 1300] loss: 0.002934267046161523
[Epoch 21, Batch 1400] loss: 0.003198038615642744
[Epoch 21, Batch 1500] loss: 0.0075012309509315854
[Epoch 21, Batch 1600] loss: 0.006984298329829813
[Epoch 21, Batch 1700] loss: 0.0038374227612996492
[Epoch 21, Batch 1800] loss: 0.002967521340454482
[Epoch 21, Batch 1900] loss: 0.0032345089646376836
[Epoch 21, Batch 2000] loss: 0.0039044970004573545
[Epoch 21, Batch 2100] loss: 0.003842007327238406
[Epoch 21, Batch 2200] loss: 0.0074611070365543245
[Epoch 21, Batch 2300] loss: 0.008303819165501096
[Epoch 21, Batch 2400] loss: 0.009914051693997976
[Epoch 21, Batch 2500] loss: 0.008394122360005838
[Epoch 21, Batch 2600] loss: 0.011606236501794313
[Epoch 21, Batch 2700] loss: 0.00469479995328328
[Epoch 21, Batch 2800] loss: 0.003461558162990741
[Epoch 21, Batch 2900] loss: 0.002066808190789544
[Epoch 21, Batch 3000] loss: 0.005485737750659326
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0575
Validation Accuracy: 0.9871
Overfitting: 0.0575
[Epoch 22, Batch 100] loss: 0.0027040869721096784
[Epoch 22, Batch 200] loss: 0.002094621707427109
[Epoch 22, Batch 300] loss: 0.010716184170348982
[Epoch 22, Batch 400] loss: 0.002288202176946754
[Epoch 22, Batch 500] loss: 0.0057896099313703075
[Epoch 22, Batch 600] loss: 0.00437101689382672
[Epoch 22, Batch 700] loss: 0.00638531088645081
[Epoch 22, Batch 800] loss: 0.005548114764348923
[Epoch 22, Batch 900] loss: 0.006598010793061064
[Epoch 22, Batch 1000] loss: 0.004908611355907482
[Epoch 22, Batch 1100] loss: 0.0018277592648230367
[Epoch 22, Batch 1200] loss: 0.0022609174212379203
[Epoch 22, Batch 1300] loss: 0.010588146483463276
[Epoch 22, Batch 1400] loss: 0.010584592825986902
[Epoch 22, Batch 1500] loss: 0.009120813630321419
[Epoch 22, Batch 1600] loss: 0.0037988714767010377
[Epoch 22, Batch 1700] loss: 0.0027009715372793507
[Epoch 22, Batch 1800] loss: 0.00277508067650067
[Epoch 22, Batch 1900] loss: 0.005013551435911365
[Epoch 22, Batch 2000] loss: 0.005411991327537597
[Epoch 22, Batch 2100] loss: 0.0029460699278110437
[Epoch 22, Batch 2200] loss: 0.009195058872999696
[Epoch 22, Batch 2300] loss: 0.003823548189820514
[Epoch 22, Batch 2400] loss: 0.0034940517645193838
[Epoch 22, Batch 2500] loss: 0.013886601343348843
[Epoch 22, Batch 2600] loss: 0.013847493261187402
[Epoch 22, Batch 2700] loss: 0.012165274148459257
[Epoch 22, Batch 2800] loss: 0.006033443092777447
[Epoch 22, Batch 2900] loss: 0.005302132482553361
[Epoch 22, Batch 3000] loss: 0.010243271205701773
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0555
Validation Accuracy: 0.9862
Overfitting: 0.0555
[Epoch 23, Batch 100] loss: 0.004696231847715069
[Epoch 23, Batch 200] loss: 0.0017822888675476634
[Epoch 23, Batch 300] loss: 0.0010940727099020364
[Epoch 23, Batch 400] loss: 0.002185452791852356
[Epoch 23, Batch 500] loss: 0.005238789456575326
[Epoch 23, Batch 600] loss: 0.006218415515880267
[Epoch 23, Batch 700] loss: 0.006444641201141792
[Epoch 23, Batch 800] loss: 0.01752577684389678
[Epoch 23, Batch 900] loss: 0.0056833706403878635
[Epoch 23, Batch 1000] loss: 0.0070651900312651604
[Epoch 23, Batch 1100] loss: 0.004138156198030458
[Epoch 23, Batch 1200] loss: 0.004711628725987111
[Epoch 23, Batch 1300] loss: 0.004344812299675454
[Epoch 23, Batch 1400] loss: 0.0021338506088726204
[Epoch 23, Batch 1500] loss: 0.0034578433637088325
[Epoch 23, Batch 1600] loss: 0.0009580780412048906
[Epoch 23, Batch 1700] loss: 0.0054845595695949
[Epoch 23, Batch 1800] loss: 0.014239284752731826
[Epoch 23, Batch 1900] loss: 0.007903432249438484
[Epoch 23, Batch 2000] loss: 0.007281383064130846
[Epoch 23, Batch 2100] loss: 0.004258491612770996
[Epoch 23, Batch 2200] loss: 0.009568382954663833
[Epoch 23, Batch 2300] loss: 0.008521077260005505
[Epoch 23, Batch 2400] loss: 0.004796624160882139
[Epoch 23, Batch 2500] loss: 0.0035904685259658463
[Epoch 23, Batch 2600] loss: 0.006150422679376959
[Epoch 23, Batch 2700] loss: 0.002100334603758247
[Epoch 23, Batch 2800] loss: 0.010627870843848121
[Epoch 23, Batch 2900] loss: 0.00779355888538916
[Epoch 23, Batch 3000] loss: 0.0038038032050740256
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9878
Overfitting: 0.0511
[Epoch 24, Batch 100] loss: 0.0035176081651220412
[Epoch 24, Batch 200] loss: 0.007682432405657842
[Epoch 24, Batch 300] loss: 0.0029235253108165792
[Epoch 24, Batch 400] loss: 0.002195980231576584
[Epoch 24, Batch 500] loss: 0.005799082832365228
[Epoch 24, Batch 600] loss: 0.0040953183490108815
[Epoch 24, Batch 700] loss: 0.0018741926761695993
[Epoch 24, Batch 800] loss: 0.00046278356905773423
[Epoch 24, Batch 900] loss: 0.0055595446427958
[Epoch 24, Batch 1000] loss: 0.0036812118121488167
[Epoch 24, Batch 1100] loss: 0.0017196923288918242
[Epoch 24, Batch 1200] loss: 0.0020350982092838875
[Epoch 24, Batch 1300] loss: 0.0027282848726865438
[Epoch 24, Batch 1400] loss: 0.0007727048723489816
[Epoch 24, Batch 1500] loss: 0.0005387724157086638
[Epoch 24, Batch 1600] loss: 0.0018618510557608615
[Epoch 24, Batch 1700] loss: 0.0014325673761135071
[Epoch 24, Batch 1800] loss: 0.0016763442594217538
[Epoch 24, Batch 1900] loss: 0.0018062932650876817
[Epoch 24, Batch 2000] loss: 0.0017973521602945653
[Epoch 24, Batch 2100] loss: 0.0008326760101028885
[Epoch 24, Batch 2200] loss: 0.002994501384959949
[Epoch 24, Batch 2300] loss: 0.0012362608523706698
[Epoch 24, Batch 2400] loss: 0.0013304441334015804
[Epoch 24, Batch 2500] loss: 0.0038895065460231716
[Epoch 24, Batch 2600] loss: 0.0009776680677784765
[Epoch 24, Batch 2700] loss: 0.0017706081654558403
[Epoch 24, Batch 2800] loss: 0.0008198512882836439
[Epoch 24, Batch 2900] loss: 0.0013519498073856085
[Epoch 24, Batch 3000] loss: 0.0006554105670211152
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9896
Overfitting: 0.0483
Fold 5 validation loss: 0.0483
Mean validation loss across all folds for Trial 16 is 0.0536 with trial config:  l1: 128, l2: 64, lr: 0.001524205108202716, batch_size: 16
[I 2024-12-10 08:52:50,100] Trial 15 finished with value: 0.053627030878964276 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.001524205108202716, 'batch_size': 16}. Best is trial 4 with value: 0.046893630782967134.

Selected Hyperparameters for Trial 17:
  l1: 128, l2: 128, lr: 0.0020975457910271645, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2818719506263734
[Epoch 1, Batch 200] loss: 1.892785101532936
[Epoch 1, Batch 300] loss: 0.6324324756860733
[Epoch 1, Batch 400] loss: 0.4306038862466812
[Epoch 1, Batch 500] loss: 0.34139837615191937
[Epoch 1, Batch 600] loss: 0.2896757464855909
[Epoch 1, Batch 700] loss: 0.2570738913118839
[Epoch 1, Batch 800] loss: 0.2378116983920336
[Epoch 1, Batch 900] loss: 0.19493587682023644
[Epoch 1, Batch 1000] loss: 0.17932799492031337
[Epoch 1, Batch 1100] loss: 0.16669256627559662
[Epoch 1, Batch 1200] loss: 0.1283042516373098
[Epoch 1, Batch 1300] loss: 0.16579254938289523
[Epoch 1, Batch 1400] loss: 0.1233813579659909
[Epoch 1, Batch 1500] loss: 0.13664046250283718
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1109
Validation Accuracy: 0.9662
Overfitting: 0.1109
Best model saved at epoch 1 with validation loss: 0.1109
[Epoch 2, Batch 100] loss: 0.11452844437677413
[Epoch 2, Batch 200] loss: 0.12825028075836598
[Epoch 2, Batch 300] loss: 0.11197354623815045
[Epoch 2, Batch 400] loss: 0.09337859730236232
[Epoch 2, Batch 500] loss: 0.11995145655237138
[Epoch 2, Batch 600] loss: 0.11428899074904621
[Epoch 2, Batch 700] loss: 0.10362659880891442
[Epoch 2, Batch 800] loss: 0.080580760743469
[Epoch 2, Batch 900] loss: 0.10316663034725934
[Epoch 2, Batch 1000] loss: 0.08796110573923216
[Epoch 2, Batch 1100] loss: 0.09985871758311987
[Epoch 2, Batch 1200] loss: 0.08890673830173909
[Epoch 2, Batch 1300] loss: 0.08156578802503646
[Epoch 2, Batch 1400] loss: 0.09613846727646887
[Epoch 2, Batch 1500] loss: 0.08212861298350617
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0875
Validation Accuracy: 0.9727
Overfitting: 0.0875
Best model saved at epoch 2 with validation loss: 0.0875
[Epoch 3, Batch 100] loss: 0.08744112177286296
[Epoch 3, Batch 200] loss: 0.06282511573750525
[Epoch 3, Batch 300] loss: 0.0845488934381865
[Epoch 3, Batch 400] loss: 0.06882899024989456
[Epoch 3, Batch 500] loss: 0.07301209078170359
[Epoch 3, Batch 600] loss: 0.08015955625334754
[Epoch 3, Batch 700] loss: 0.07087161575676873
[Epoch 3, Batch 800] loss: 0.059491786108119414
[Epoch 3, Batch 900] loss: 0.0709282935387455
[Epoch 3, Batch 1000] loss: 0.058725872365757825
[Epoch 3, Batch 1100] loss: 0.0682227623660583
[Epoch 3, Batch 1200] loss: 0.054103566736448554
[Epoch 3, Batch 1300] loss: 0.0770232690719422
[Epoch 3, Batch 1400] loss: 0.07654717643046752
[Epoch 3, Batch 1500] loss: 0.060446651224046945
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0666
Validation Accuracy: 0.9798
Overfitting: 0.0666
Best model saved at epoch 3 with validation loss: 0.0666
[Epoch 4, Batch 100] loss: 0.05351324718911201
[Epoch 4, Batch 200] loss: 0.050638655473012474
[Epoch 4, Batch 300] loss: 0.06502064980799332
[Epoch 4, Batch 400] loss: 0.053047674715635366
[Epoch 4, Batch 500] loss: 0.06290219008456915
[Epoch 4, Batch 600] loss: 0.05187640662654303
[Epoch 4, Batch 700] loss: 0.057108012520475315
[Epoch 4, Batch 800] loss: 0.054134565386921164
[Epoch 4, Batch 900] loss: 0.053851845664903523
[Epoch 4, Batch 1000] loss: 0.05966350940056145
[Epoch 4, Batch 1100] loss: 0.046773219277965836
[Epoch 4, Batch 1200] loss: 0.054551179605768996
[Epoch 4, Batch 1300] loss: 0.05698778554913588
[Epoch 4, Batch 1400] loss: 0.05129401218960993
[Epoch 4, Batch 1500] loss: 0.04382558880664874
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0572
Validation Accuracy: 0.9824
Overfitting: 0.0572
Best model saved at epoch 4 with validation loss: 0.0572
[Epoch 5, Batch 100] loss: 0.05395314118242823
[Epoch 5, Batch 200] loss: 0.04561825116514228
[Epoch 5, Batch 300] loss: 0.04626813054113882
[Epoch 5, Batch 400] loss: 0.04639879960450344
[Epoch 5, Batch 500] loss: 0.04923552693682723
[Epoch 5, Batch 600] loss: 0.04965585707861465
[Epoch 5, Batch 700] loss: 0.04545996327535249
[Epoch 5, Batch 800] loss: 0.05086126759415492
[Epoch 5, Batch 900] loss: 0.053207570769591254
[Epoch 5, Batch 1000] loss: 0.04053890981187578
[Epoch 5, Batch 1100] loss: 0.03788175093679456
[Epoch 5, Batch 1200] loss: 0.05108911640243605
[Epoch 5, Batch 1300] loss: 0.04805902135325596
[Epoch 5, Batch 1400] loss: 0.025278852018527687
[Epoch 5, Batch 1500] loss: 0.039279331338766495
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9838
Overfitting: 0.0507
Best model saved at epoch 5 with validation loss: 0.0507
[Epoch 6, Batch 100] loss: 0.03633868279895978
[Epoch 6, Batch 200] loss: 0.03511777886975324
[Epoch 6, Batch 300] loss: 0.03732365326970467
[Epoch 6, Batch 400] loss: 0.052066422897041775
[Epoch 6, Batch 500] loss: 0.04838543652032968
[Epoch 6, Batch 600] loss: 0.04520466292509809
[Epoch 6, Batch 700] loss: 0.035983905458124354
[Epoch 6, Batch 800] loss: 0.03141328655125108
[Epoch 6, Batch 900] loss: 0.04201726222294383
[Epoch 6, Batch 1000] loss: 0.040684832824044864
[Epoch 6, Batch 1100] loss: 0.03323289839318022
[Epoch 6, Batch 1200] loss: 0.040594847099855544
[Epoch 6, Batch 1300] loss: 0.032635975448356475
[Epoch 6, Batch 1400] loss: 0.03991880829882575
[Epoch 6, Batch 1500] loss: 0.03499850769876502
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9831
Overfitting: 0.0536
[Epoch 7, Batch 100] loss: 0.023978456893819385
[Epoch 7, Batch 200] loss: 0.028288814661791548
[Epoch 7, Batch 300] loss: 0.034914363872085234
[Epoch 7, Batch 400] loss: 0.03999234015820548
[Epoch 7, Batch 500] loss: 0.03438192711560987
[Epoch 7, Batch 600] loss: 0.02948070935846772
[Epoch 7, Batch 700] loss: 0.03883687272929819
[Epoch 7, Batch 800] loss: 0.0372346184856724
[Epoch 7, Batch 900] loss: 0.04583614303555805
[Epoch 7, Batch 1000] loss: 0.03199956708587706
[Epoch 7, Batch 1100] loss: 0.023144871465920005
[Epoch 7, Batch 1200] loss: 0.029071363072143867
[Epoch 7, Batch 1300] loss: 0.02920108778605936
[Epoch 7, Batch 1400] loss: 0.033591759810515216
[Epoch 7, Batch 1500] loss: 0.03516562750242883
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9852
Overfitting: 0.0490
[I 2024-12-10 08:54:09,237] Trial 16 pruned. 

Selected Hyperparameters for Trial 18:
  l1: 256, l2: 128, lr: 0.00033754957940139744, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.301143968105316
[Epoch 1, Batch 200] loss: 2.288917806148529
[Epoch 1, Batch 300] loss: 2.2755612659454347
**STATS for Epoch 1** : 
Average training loss: 0.4516
Average validation loss: 2.2494
Validation Accuracy: 0.2930
Overfitting: 1.7978
Best model saved at epoch 1 with validation loss: 2.2494
[Epoch 2, Batch 100] loss: 2.2369433569908144
[Epoch 2, Batch 200] loss: 2.19490348815918
[Epoch 2, Batch 300] loss: 2.114551348686218
**STATS for Epoch 2** : 
Average training loss: 0.3956
Average validation loss: 1.8810
Validation Accuracy: 0.6776
Overfitting: 1.4853
Best model saved at epoch 2 with validation loss: 1.8810
[Epoch 3, Batch 100] loss: 1.6850618374347688
[Epoch 3, Batch 200] loss: 1.1641812348365783
[Epoch 3, Batch 300] loss: 0.7485999321937561
**STATS for Epoch 3** : 
Average training loss: 0.1181
Average validation loss: 0.5377
Validation Accuracy: 0.8532
Overfitting: 0.4196
Best model saved at epoch 3 with validation loss: 0.5377
[Epoch 4, Batch 100] loss: 0.5113031360507011
[Epoch 4, Batch 200] loss: 0.46383683949708937
[Epoch 4, Batch 300] loss: 0.4095134797692299
**STATS for Epoch 4** : 
Average training loss: 0.0804
Average validation loss: 0.3725
Validation Accuracy: 0.8927
Overfitting: 0.2920
Best model saved at epoch 4 with validation loss: 0.3725
[Epoch 5, Batch 100] loss: 0.39050315707921984
[Epoch 5, Batch 200] loss: 0.3642624916136265
[Epoch 5, Batch 300] loss: 0.33003625318408014
**STATS for Epoch 5** : 
Average training loss: 0.0628
Average validation loss: 0.3122
Validation Accuracy: 0.9073
Overfitting: 0.2494
Best model saved at epoch 5 with validation loss: 0.3122
[Epoch 6, Batch 100] loss: 0.3184531944990158
[Epoch 6, Batch 200] loss: 0.30237949430942535
[Epoch 6, Batch 300] loss: 0.29679717421531676
**STATS for Epoch 6** : 
Average training loss: 0.0565
Average validation loss: 0.2679
Validation Accuracy: 0.9199
Overfitting: 0.2114
[I 2024-12-10 08:55:05,996] Trial 17 pruned. 

Selected Hyperparameters for Trial 19:
  l1: 256, l2: 128, lr: 0.00032185899588167477, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.298957870006561
[Epoch 1, Batch 200] loss: 2.2939438915252683
[Epoch 1, Batch 300] loss: 2.2868824577331544
[Epoch 1, Batch 400] loss: 2.280550594329834
[Epoch 1, Batch 500] loss: 2.26938334941864
[Epoch 1, Batch 600] loss: 2.251143500804901
[Epoch 1, Batch 700] loss: 2.222875714302063
[Epoch 1, Batch 800] loss: 2.1788945531845094
[Epoch 1, Batch 900] loss: 2.079851235151291
[Epoch 1, Batch 1000] loss: 1.8747243511676788
[Epoch 1, Batch 1100] loss: 1.4647357726097108
[Epoch 1, Batch 1200] loss: 0.9994604021310807
[Epoch 1, Batch 1300] loss: 0.7483357098698616
[Epoch 1, Batch 1400] loss: 0.6247121754288674
[Epoch 1, Batch 1500] loss: 0.5513654342293739
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.5259
Validation Accuracy: 0.8440
Overfitting: 0.5259
Best model saved at epoch 1 with validation loss: 0.5259
[Epoch 2, Batch 100] loss: 0.49756821915507315
[Epoch 2, Batch 200] loss: 0.44546547055244445
[Epoch 2, Batch 300] loss: 0.41942214727401733
[Epoch 2, Batch 400] loss: 0.3986233976483345
[Epoch 2, Batch 500] loss: 0.3760256094485521
[Epoch 2, Batch 600] loss: 0.3448368780314922
[Epoch 2, Batch 700] loss: 0.3346877481043339
[Epoch 2, Batch 800] loss: 0.32380659360438585
[Epoch 2, Batch 900] loss: 0.3163073694705963
[Epoch 2, Batch 1000] loss: 0.29163735479116437
[Epoch 2, Batch 1100] loss: 0.27221071101725103
[Epoch 2, Batch 1200] loss: 0.2753122724592686
[Epoch 2, Batch 1300] loss: 0.27344893783330915
[Epoch 2, Batch 1400] loss: 0.2604748670011759
[Epoch 2, Batch 1500] loss: 0.2873688827827573
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2530
Validation Accuracy: 0.9232
Overfitting: 0.2530
Best model saved at epoch 2 with validation loss: 0.2530
[Epoch 3, Batch 100] loss: 0.2500392804294825
[Epoch 3, Batch 200] loss: 0.23034193824976681
[Epoch 3, Batch 300] loss: 0.24985142193734647
[Epoch 3, Batch 400] loss: 0.23040349630638957
[Epoch 3, Batch 500] loss: 0.2302251211553812
[Epoch 3, Batch 600] loss: 0.2294120797328651
[Epoch 3, Batch 700] loss: 0.21477229751646518
[Epoch 3, Batch 800] loss: 0.23584584642201661
[Epoch 3, Batch 900] loss: 0.2044845001772046
[Epoch 3, Batch 1000] loss: 0.22533509630709886
[Epoch 3, Batch 1100] loss: 0.20103901833295823
[Epoch 3, Batch 1200] loss: 0.1997559057921171
[Epoch 3, Batch 1300] loss: 0.21349732257425785
[Epoch 3, Batch 1400] loss: 0.19100158663466574
[Epoch 3, Batch 1500] loss: 0.1982015722617507
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1731
Validation Accuracy: 0.9494
Overfitting: 0.1731
Best model saved at epoch 3 with validation loss: 0.1731
[Epoch 4, Batch 100] loss: 0.18089115062728525
[Epoch 4, Batch 200] loss: 0.18709705542773009
[Epoch 4, Batch 300] loss: 0.18817153330892325
[Epoch 4, Batch 400] loss: 0.18452395252883436
[Epoch 4, Batch 500] loss: 0.16299478212371468
[Epoch 4, Batch 600] loss: 0.1803259390220046
[Epoch 4, Batch 700] loss: 0.17174524864181875
[Epoch 4, Batch 800] loss: 0.17989965744316577
[Epoch 4, Batch 900] loss: 0.17490542809478937
[Epoch 4, Batch 1000] loss: 0.158663916233927
[Epoch 4, Batch 1100] loss: 0.160669217556715
[Epoch 4, Batch 1200] loss: 0.1575286710076034
[Epoch 4, Batch 1300] loss: 0.15811800428666176
[Epoch 4, Batch 1400] loss: 0.16041035601869225
[Epoch 4, Batch 1500] loss: 0.14710153156891465
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1417
Validation Accuracy: 0.9573
Overfitting: 0.1417
Best model saved at epoch 4 with validation loss: 0.1417
[Epoch 5, Batch 100] loss: 0.1398286040406674
[Epoch 5, Batch 200] loss: 0.1461996484361589
[Epoch 5, Batch 300] loss: 0.1491472201794386
[Epoch 5, Batch 400] loss: 0.15368316967971624
[Epoch 5, Batch 500] loss: 0.14427346560172738
[Epoch 5, Batch 600] loss: 0.13262205096893012
[Epoch 5, Batch 700] loss: 0.14675018255598843
[Epoch 5, Batch 800] loss: 0.1409800902940333
[Epoch 5, Batch 900] loss: 0.139982719225809
[Epoch 5, Batch 1000] loss: 0.11618436282500624
[Epoch 5, Batch 1100] loss: 0.13440582023002207
[Epoch 5, Batch 1200] loss: 0.1343422260694206
[Epoch 5, Batch 1300] loss: 0.1352380645554513
[Epoch 5, Batch 1400] loss: 0.14686968222260474
[Epoch 5, Batch 1500] loss: 0.14695398946292698
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1292
Validation Accuracy: 0.9603
Overfitting: 0.1292
Best model saved at epoch 5 with validation loss: 0.1292
[Epoch 6, Batch 100] loss: 0.1553430699557066
[Epoch 6, Batch 200] loss: 0.12116269417107105
[Epoch 6, Batch 300] loss: 0.1274871327355504
[Epoch 6, Batch 400] loss: 0.11494891265407205
[Epoch 6, Batch 500] loss: 0.12083033051341772
[Epoch 6, Batch 600] loss: 0.11814090359024704
[Epoch 6, Batch 700] loss: 0.10917579660657793
[Epoch 6, Batch 800] loss: 0.11532812333665789
[Epoch 6, Batch 900] loss: 0.11900185440666973
[Epoch 6, Batch 1000] loss: 0.1225886674132198
[Epoch 6, Batch 1100] loss: 0.11853641962632537
[Epoch 6, Batch 1200] loss: 0.11766104061622172
[Epoch 6, Batch 1300] loss: 0.1247574613057077
[Epoch 6, Batch 1400] loss: 0.12237316655926406
[Epoch 6, Batch 1500] loss: 0.09543413747102023
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.1030
Validation Accuracy: 0.9701
Overfitting: 0.1030
[I 2024-12-10 08:56:14,191] Trial 18 pruned. 

Selected Hyperparameters for Trial 20:
  l1: 128, l2: 128, lr: 0.0008834543141088621, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2899321150779723
[Epoch 1, Batch 200] loss: 2.2472673892974853
[Epoch 1, Batch 300] loss: 2.091015877723694
[Epoch 1, Batch 400] loss: 1.3044211792945861
[Epoch 1, Batch 500] loss: 0.6672713497281074
[Epoch 1, Batch 600] loss: 0.533719576895237
[Epoch 1, Batch 700] loss: 0.4569807168841362
**STATS for Epoch 1** : 
Average training loss: 0.0280
Average validation loss: 0.3900
Validation Accuracy: 0.8842
Overfitting: 0.3620
Best model saved at epoch 1 with validation loss: 0.3900
[Epoch 2, Batch 100] loss: 0.38763012424111365
[Epoch 2, Batch 200] loss: 0.3373321305215359
[Epoch 2, Batch 300] loss: 0.31701628878712657
[Epoch 2, Batch 400] loss: 0.2782803899049759
[Epoch 2, Batch 500] loss: 0.27766677357256414
[Epoch 2, Batch 600] loss: 0.27786667928099634
[Epoch 2, Batch 700] loss: 0.2278123577684164
**STATS for Epoch 2** : 
Average training loss: 0.0168
Average validation loss: 0.2156
Validation Accuracy: 0.9361
Overfitting: 0.1988
Best model saved at epoch 2 with validation loss: 0.2156
[Epoch 3, Batch 100] loss: 0.21080231182277204
[Epoch 3, Batch 200] loss: 0.20684759810566902
[Epoch 3, Batch 300] loss: 0.20663812227547168
[Epoch 3, Batch 400] loss: 0.1968916168808937
[Epoch 3, Batch 500] loss: 0.19161793306469918
[Epoch 3, Batch 600] loss: 0.18484934113919735
[Epoch 3, Batch 700] loss: 0.158855690471828
**STATS for Epoch 3** : 
Average training loss: 0.0111
Average validation loss: 0.1480
Validation Accuracy: 0.9542
Overfitting: 0.1369
Best model saved at epoch 3 with validation loss: 0.1480
[Epoch 4, Batch 100] loss: 0.16466713223606347
[Epoch 4, Batch 200] loss: 0.15495281014591455
[Epoch 4, Batch 300] loss: 0.1370474860072136
[Epoch 4, Batch 400] loss: 0.13051424968987704
[Epoch 4, Batch 500] loss: 0.1571701581776142
[Epoch 4, Batch 600] loss: 0.13024352099746467
[Epoch 4, Batch 700] loss: 0.13339741460978985
**STATS for Epoch 4** : 
Average training loss: 0.0090
Average validation loss: 0.1228
Validation Accuracy: 0.9623
Overfitting: 0.1138
Best model saved at epoch 4 with validation loss: 0.1228
[Epoch 5, Batch 100] loss: 0.11238118590787054
[Epoch 5, Batch 200] loss: 0.12007878491654993
[Epoch 5, Batch 300] loss: 0.11653134288266301
[Epoch 5, Batch 400] loss: 0.10890313379466533
[Epoch 5, Batch 500] loss: 0.12309878213331103
[Epoch 5, Batch 600] loss: 0.11198589272797108
[Epoch 5, Batch 700] loss: 0.10838549133390188
**STATS for Epoch 5** : 
Average training loss: 0.0072
Average validation loss: 0.1152
Validation Accuracy: 0.9638
Overfitting: 0.1080
Best model saved at epoch 5 with validation loss: 0.1152
[Epoch 6, Batch 100] loss: 0.11235782032832503
[Epoch 6, Batch 200] loss: 0.09907867763191462
[Epoch 6, Batch 300] loss: 0.09316038687713445
[Epoch 6, Batch 400] loss: 0.10400523345917463
[Epoch 6, Batch 500] loss: 0.08183816492557526
[Epoch 6, Batch 600] loss: 0.09338789759203792
[Epoch 6, Batch 700] loss: 0.09203928871080279
**STATS for Epoch 6** : 
Average training loss: 0.0073
Average validation loss: 0.0912
Validation Accuracy: 0.9721
Overfitting: 0.0839
[I 2024-12-10 08:57:13,989] Trial 19 pruned. 

Selected Hyperparameters for Trial 21:
  l1: 128, l2: 128, lr: 0.0031053956017158386, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.050950925350189
**STATS for Epoch 1** : 
Average training loss: 0.2883
Average validation loss: 0.4053
Validation Accuracy: 0.8804
Overfitting: 0.1170
Best model saved at epoch 1 with validation loss: 0.4053
[Epoch 2, Batch 100] loss: 0.3640208208560944
**STATS for Epoch 2** : 
Average training loss: 0.1345
Average validation loss: 0.2328
Validation Accuracy: 0.9310
Overfitting: 0.0983
Best model saved at epoch 2 with validation loss: 0.2328
[Epoch 3, Batch 100] loss: 0.22697099179029465
**STATS for Epoch 3** : 
Average training loss: 0.0939
Average validation loss: 0.1715
Validation Accuracy: 0.9479
Overfitting: 0.0776
Best model saved at epoch 3 with validation loss: 0.1715
[Epoch 4, Batch 100] loss: 0.1728559509664774
**STATS for Epoch 4** : 
Average training loss: 0.0695
Average validation loss: 0.1345
Validation Accuracy: 0.9583
Overfitting: 0.0650
Best model saved at epoch 4 with validation loss: 0.1345
[Epoch 5, Batch 100] loss: 0.1350300869718194
**STATS for Epoch 5** : 
Average training loss: 0.0574
Average validation loss: 0.1118
Validation Accuracy: 0.9641
Overfitting: 0.0544
Best model saved at epoch 5 with validation loss: 0.1118
[Epoch 6, Batch 100] loss: 0.1108921543508768
**STATS for Epoch 6** : 
Average training loss: 0.0522
Average validation loss: 0.0960
Validation Accuracy: 0.9696
Overfitting: 0.0438
[I 2024-12-10 08:58:06,996] Trial 20 pruned. 

Selected Hyperparameters for Trial 22:
  l1: 256, l2: 128, lr: 0.0008396549169269917, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3005163168907163
[Epoch 1, Batch 200] loss: 2.2842244482040406
[Epoch 1, Batch 300] loss: 2.25175562620163
[Epoch 1, Batch 400] loss: 2.1406962549686432
[Epoch 1, Batch 500] loss: 1.6201150292158126
[Epoch 1, Batch 600] loss: 0.8318211925029755
[Epoch 1, Batch 700] loss: 0.5582394680380821
[Epoch 1, Batch 800] loss: 0.53052630007267
[Epoch 1, Batch 900] loss: 0.4251183653622866
[Epoch 1, Batch 1000] loss: 0.4030042310804129
[Epoch 1, Batch 1100] loss: 0.3475925946235657
[Epoch 1, Batch 1200] loss: 0.34615548089146614
[Epoch 1, Batch 1300] loss: 0.28872018814086914
[Epoch 1, Batch 1400] loss: 0.31587849486619235
[Epoch 1, Batch 1500] loss: 0.27352411568164825
[Epoch 1, Batch 1600] loss: 0.2632804657332599
[Epoch 1, Batch 1700] loss: 0.20761115910485387
[Epoch 1, Batch 1800] loss: 0.1860553662851453
[Epoch 1, Batch 1900] loss: 0.18644775786437096
[Epoch 1, Batch 2000] loss: 0.20686409370973707
[Epoch 1, Batch 2100] loss: 0.21125985166057945
[Epoch 1, Batch 2200] loss: 0.1599421258829534
[Epoch 1, Batch 2300] loss: 0.17801672516390682
[Epoch 1, Batch 2400] loss: 0.19311125714331864
[Epoch 1, Batch 2500] loss: 0.15596956339664758
[Epoch 1, Batch 2600] loss: 0.1429452343378216
[Epoch 1, Batch 2700] loss: 0.13333017954602838
[Epoch 1, Batch 2800] loss: 0.12192799258511514
[Epoch 1, Batch 2900] loss: 0.13364770860644057
[Epoch 1, Batch 3000] loss: 0.1595038108434528
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1300
Validation Accuracy: 0.9601
Overfitting: 0.1300
Best model saved at epoch 1 with validation loss: 0.1300
[Epoch 2, Batch 100] loss: 0.10866764119360596
[Epoch 2, Batch 200] loss: 0.13322182121220977
[Epoch 2, Batch 300] loss: 0.1275158713036217
[Epoch 2, Batch 400] loss: 0.11362287916243076
[Epoch 2, Batch 500] loss: 0.08936275464016945
[Epoch 2, Batch 600] loss: 0.11564503065077587
[Epoch 2, Batch 700] loss: 0.1082513267127797
[Epoch 2, Batch 800] loss: 0.11833078903146088
[Epoch 2, Batch 900] loss: 0.12295335209346377
[Epoch 2, Batch 1000] loss: 0.13527538521680982
[Epoch 2, Batch 1100] loss: 0.09425959062064067
[Epoch 2, Batch 1200] loss: 0.10568889080313966
[Epoch 2, Batch 1300] loss: 0.09374566065846011
[Epoch 2, Batch 1400] loss: 0.08917936988815199
[Epoch 2, Batch 1500] loss: 0.0927200296614319
[Epoch 2, Batch 1600] loss: 0.11284394280810375
[Epoch 2, Batch 1700] loss: 0.09100513928802684
[Epoch 2, Batch 1800] loss: 0.08347861569141969
[Epoch 2, Batch 1900] loss: 0.08399948619189672
[Epoch 2, Batch 2000] loss: 0.07540973786264658
[Epoch 2, Batch 2100] loss: 0.09084811973792967
[Epoch 2, Batch 2200] loss: 0.07929973548976704
[Epoch 2, Batch 2300] loss: 0.08316989303566516
[Epoch 2, Batch 2400] loss: 0.11318488735472783
[Epoch 2, Batch 2500] loss: 0.08597092296928167
[Epoch 2, Batch 2600] loss: 0.07409880563209299
[Epoch 2, Batch 2700] loss: 0.08877407860127277
[Epoch 2, Batch 2800] loss: 0.08496018111007288
[Epoch 2, Batch 2900] loss: 0.07141321905481163
[Epoch 2, Batch 3000] loss: 0.1004419174126815
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0730
Validation Accuracy: 0.9777
Overfitting: 0.0730
Best model saved at epoch 2 with validation loss: 0.0730
[Epoch 3, Batch 100] loss: 0.06356714442837984
[Epoch 3, Batch 200] loss: 0.07703939451661426
[Epoch 3, Batch 300] loss: 0.06323713449412026
[Epoch 3, Batch 400] loss: 0.08781447391491383
[Epoch 3, Batch 500] loss: 0.06970692005357705
[Epoch 3, Batch 600] loss: 0.07941588834277354
[Epoch 3, Batch 700] loss: 0.0634026863949839
[Epoch 3, Batch 800] loss: 0.07549962629680522
[Epoch 3, Batch 900] loss: 0.07774664538213984
[Epoch 3, Batch 1000] loss: 0.08249595958157442
[Epoch 3, Batch 1100] loss: 0.05453930826624855
[Epoch 3, Batch 1200] loss: 0.06698460817569866
[Epoch 3, Batch 1300] loss: 0.061867480201181026
[Epoch 3, Batch 1400] loss: 0.07807860664324835
[Epoch 3, Batch 1500] loss: 0.0804214005661197
[Epoch 3, Batch 1600] loss: 0.06422341773519293
[Epoch 3, Batch 1700] loss: 0.06210741690301802
[Epoch 3, Batch 1800] loss: 0.07022093881154433
[Epoch 3, Batch 1900] loss: 0.061946454785065726
[Epoch 3, Batch 2000] loss: 0.050553174206288534
[Epoch 3, Batch 2100] loss: 0.08167107306799153
[Epoch 3, Batch 2200] loss: 0.06253890440566465
[Epoch 3, Batch 2300] loss: 0.05509177611093037
[Epoch 3, Batch 2400] loss: 0.06207438507612096
[Epoch 3, Batch 2500] loss: 0.06621382203302346
[Epoch 3, Batch 2600] loss: 0.04429030368686654
[Epoch 3, Batch 2700] loss: 0.0693567711376818
[Epoch 3, Batch 2800] loss: 0.05075844265287742
[Epoch 3, Batch 2900] loss: 0.05880105930031277
[Epoch 3, Batch 3000] loss: 0.061781316394917664
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0727
Validation Accuracy: 0.9772
Overfitting: 0.0727
Best model saved at epoch 3 with validation loss: 0.0727
[Epoch 4, Batch 100] loss: 0.06351376377046108
[Epoch 4, Batch 200] loss: 0.04862768982187845
[Epoch 4, Batch 300] loss: 0.047417402657447386
[Epoch 4, Batch 400] loss: 0.05362229563848814
[Epoch 4, Batch 500] loss: 0.071132409456186
[Epoch 4, Batch 600] loss: 0.05491229585139081
[Epoch 4, Batch 700] loss: 0.05187955850211438
[Epoch 4, Batch 800] loss: 0.03237047672562767
[Epoch 4, Batch 900] loss: 0.05131370541057549
[Epoch 4, Batch 1000] loss: 0.05642908260284457
[Epoch 4, Batch 1100] loss: 0.060364928832277655
[Epoch 4, Batch 1200] loss: 0.04926113671099301
[Epoch 4, Batch 1300] loss: 0.06096606981649529
[Epoch 4, Batch 1400] loss: 0.07410503381368472
[Epoch 4, Batch 1500] loss: 0.05271311592805432
[Epoch 4, Batch 1600] loss: 0.04679062576557044
[Epoch 4, Batch 1700] loss: 0.052782908403896725
[Epoch 4, Batch 1800] loss: 0.035491147189750334
[Epoch 4, Batch 1900] loss: 0.049471643737633714
[Epoch 4, Batch 2000] loss: 0.051405311749549584
[Epoch 4, Batch 2100] loss: 0.053983769539918285
[Epoch 4, Batch 2200] loss: 0.04915756533213425
[Epoch 4, Batch 2300] loss: 0.03451100991864223
[Epoch 4, Batch 2400] loss: 0.06318358069867827
[Epoch 4, Batch 2500] loss: 0.038155179806344676
[Epoch 4, Batch 2600] loss: 0.0469270164181944
[Epoch 4, Batch 2700] loss: 0.048737869902688545
[Epoch 4, Batch 2800] loss: 0.06291733537218533
[Epoch 4, Batch 2900] loss: 0.04778440234134905
[Epoch 4, Batch 3000] loss: 0.06808603139943444
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9792
Overfitting: 0.0636
Best model saved at epoch 4 with validation loss: 0.0636
[Epoch 5, Batch 100] loss: 0.05596455710707232
[Epoch 5, Batch 200] loss: 0.03995806689665187
[Epoch 5, Batch 300] loss: 0.04581833407224622
[Epoch 5, Batch 400] loss: 0.03282147641817573
[Epoch 5, Batch 500] loss: 0.040233194254979024
[Epoch 5, Batch 600] loss: 0.03794813429776696
[Epoch 5, Batch 700] loss: 0.04544559560687048
[Epoch 5, Batch 800] loss: 0.04983552591744228
[Epoch 5, Batch 900] loss: 0.03678465802426217
[Epoch 5, Batch 1000] loss: 0.050509256709192416
[Epoch 5, Batch 1100] loss: 0.040615502840373664
[Epoch 5, Batch 1200] loss: 0.05355996979757038
[Epoch 5, Batch 1300] loss: 0.04063907809293596
[Epoch 5, Batch 1400] loss: 0.04091438066185219
[Epoch 5, Batch 1500] loss: 0.03431425483555359
[Epoch 5, Batch 1600] loss: 0.029889576380955987
[Epoch 5, Batch 1700] loss: 0.04625184699791134
[Epoch 5, Batch 1800] loss: 0.0419293490457494
[Epoch 5, Batch 1900] loss: 0.05628474114899291
[Epoch 5, Batch 2000] loss: 0.03836453554511536
[Epoch 5, Batch 2100] loss: 0.038792157650459555
[Epoch 5, Batch 2200] loss: 0.05016118239262141
[Epoch 5, Batch 2300] loss: 0.06014464076957665
[Epoch 5, Batch 2400] loss: 0.040110095586278476
[Epoch 5, Batch 2500] loss: 0.06686922243185109
[Epoch 5, Batch 2600] loss: 0.03955577867396642
[Epoch 5, Batch 2700] loss: 0.04012536364971311
[Epoch 5, Batch 2800] loss: 0.04420042271027341
[Epoch 5, Batch 2900] loss: 0.0331386676148395
[Epoch 5, Batch 3000] loss: 0.04904816256705089
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0572
Validation Accuracy: 0.9832
Overfitting: 0.0572
Best model saved at epoch 5 with validation loss: 0.0572
[Epoch 6, Batch 100] loss: 0.04340787161199842
[Epoch 6, Batch 200] loss: 0.030240567292203195
[Epoch 6, Batch 300] loss: 0.02731126107275486
[Epoch 6, Batch 400] loss: 0.04153400224342477
[Epoch 6, Batch 500] loss: 0.03450164735899307
[Epoch 6, Batch 600] loss: 0.05153297894721618
[Epoch 6, Batch 700] loss: 0.033314630856039
[Epoch 6, Batch 800] loss: 0.021624668823933463
[Epoch 6, Batch 900] loss: 0.027071773135685363
[Epoch 6, Batch 1000] loss: 0.044128249375789894
[Epoch 6, Batch 1100] loss: 0.03806343567564909
[Epoch 6, Batch 1200] loss: 0.048571709356983774
[Epoch 6, Batch 1300] loss: 0.02500909602371394
[Epoch 6, Batch 1400] loss: 0.040622856058180334
[Epoch 6, Batch 1500] loss: 0.03875733628141461
[Epoch 6, Batch 1600] loss: 0.035560725920731784
[Epoch 6, Batch 1700] loss: 0.04753316058064229
[Epoch 6, Batch 1800] loss: 0.039508802894415565
[Epoch 6, Batch 1900] loss: 0.03500341599341482
[Epoch 6, Batch 2000] loss: 0.025099213433131807
[Epoch 6, Batch 2100] loss: 0.03603561559342779
[Epoch 6, Batch 2200] loss: 0.049078338272156546
[Epoch 6, Batch 2300] loss: 0.041385252199834216
[Epoch 6, Batch 2400] loss: 0.03468979165889323
[Epoch 6, Batch 2500] loss: 0.027792116601085583
[Epoch 6, Batch 2600] loss: 0.03788888250244781
[Epoch 6, Batch 2700] loss: 0.03941394125431543
[Epoch 6, Batch 2800] loss: 0.027742244954715715
[Epoch 6, Batch 2900] loss: 0.0305228185300075
[Epoch 6, Batch 3000] loss: 0.03141205060514039
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9866
Overfitting: 0.0449
Best model saved at epoch 6 with validation loss: 0.0449
[Epoch 7, Batch 100] loss: 0.02446926146309124
[Epoch 7, Batch 200] loss: 0.029496109488536603
[Epoch 7, Batch 300] loss: 0.03602670957625378
[Epoch 7, Batch 400] loss: 0.033866841074923285
[Epoch 7, Batch 500] loss: 0.025806161634391173
[Epoch 7, Batch 600] loss: 0.022926075956165734
[Epoch 7, Batch 700] loss: 0.02856058660596318
[Epoch 7, Batch 800] loss: 0.02716434463545738
[Epoch 7, Batch 900] loss: 0.03814472153542738
[Epoch 7, Batch 1000] loss: 0.03669640496365901
[Epoch 7, Batch 1100] loss: 0.028222966991888823
[Epoch 7, Batch 1200] loss: 0.032578509356826546
[Epoch 7, Batch 1300] loss: 0.02141693651174137
[Epoch 7, Batch 1400] loss: 0.019292884929454884
[Epoch 7, Batch 1500] loss: 0.030142473758751294
[Epoch 7, Batch 1600] loss: 0.03797919590550009
[Epoch 7, Batch 1700] loss: 0.02856483136845782
[Epoch 7, Batch 1800] loss: 0.03000158947039381
[Epoch 7, Batch 1900] loss: 0.017060557204276846
[Epoch 7, Batch 2000] loss: 0.03290864848688216
[Epoch 7, Batch 2100] loss: 0.025735726976527075
[Epoch 7, Batch 2200] loss: 0.03524431652069324
[Epoch 7, Batch 2300] loss: 0.035002761477662715
[Epoch 7, Batch 2400] loss: 0.025920122274619643
[Epoch 7, Batch 2500] loss: 0.028551674170885236
[Epoch 7, Batch 2600] loss: 0.038135363381879867
[Epoch 7, Batch 2700] loss: 0.024185241614104597
[Epoch 7, Batch 2800] loss: 0.03363170320211793
[Epoch 7, Batch 2900] loss: 0.044689656783884854
[Epoch 7, Batch 3000] loss: 0.038976781695528186
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0426
Validation Accuracy: 0.9872
Overfitting: 0.0426
Best model saved at epoch 7 with validation loss: 0.0426
[Epoch 8, Batch 100] loss: 0.021520237239819835
[Epoch 8, Batch 200] loss: 0.025954727643402294
[Epoch 8, Batch 300] loss: 0.02203727428786806
[Epoch 8, Batch 400] loss: 0.025170986443044968
[Epoch 8, Batch 500] loss: 0.025976713235431815
[Epoch 8, Batch 600] loss: 0.02836077059255331
[Epoch 8, Batch 700] loss: 0.020525572729384295
[Epoch 8, Batch 800] loss: 0.026948826142397592
[Epoch 8, Batch 900] loss: 0.03753676973268739
[Epoch 8, Batch 1000] loss: 0.015502329647497391
[Epoch 8, Batch 1100] loss: 0.024758005328894796
[Epoch 8, Batch 1200] loss: 0.018614400871538237
[Epoch 8, Batch 1300] loss: 0.017332722469509464
[Epoch 8, Batch 1400] loss: 0.0365902842847936
[Epoch 8, Batch 1500] loss: 0.022818804626440398
[Epoch 8, Batch 1600] loss: 0.04061773787208949
[Epoch 8, Batch 1700] loss: 0.016337706961639924
[Epoch 8, Batch 1800] loss: 0.020077035026006343
[Epoch 8, Batch 1900] loss: 0.01761524153389473
[Epoch 8, Batch 2000] loss: 0.022357459834383916
[Epoch 8, Batch 2100] loss: 0.04830661590764066
[Epoch 8, Batch 2200] loss: 0.033606389061460504
[Epoch 8, Batch 2300] loss: 0.03532971384440316
[Epoch 8, Batch 2400] loss: 0.021073686535819435
[Epoch 8, Batch 2500] loss: 0.03030130107385048
[Epoch 8, Batch 2600] loss: 0.026273359081387754
[Epoch 8, Batch 2700] loss: 0.029078114555450157
[Epoch 8, Batch 2800] loss: 0.027894889608942323
[Epoch 8, Batch 2900] loss: 0.02474043412363244
[Epoch 8, Batch 3000] loss: 0.028631771233922337
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0604
Validation Accuracy: 0.9793
Overfitting: 0.0604
[Epoch 9, Batch 100] loss: 0.018712554127050682
[Epoch 9, Batch 200] loss: 0.018905716872250195
[Epoch 9, Batch 300] loss: 0.021050547773556902
[Epoch 9, Batch 400] loss: 0.018326444740087027
[Epoch 9, Batch 500] loss: 0.02361652091509313
[Epoch 9, Batch 600] loss: 0.02162693445559853
[Epoch 9, Batch 700] loss: 0.0246635053546197
[Epoch 9, Batch 800] loss: 0.02256767902552383
[Epoch 9, Batch 900] loss: 0.026669698968235026
[Epoch 9, Batch 1000] loss: 0.015867375229499884
[Epoch 9, Batch 1100] loss: 0.02540950037211587
[Epoch 9, Batch 1200] loss: 0.03086740500972155
[Epoch 9, Batch 1300] loss: 0.015620963785695495
[Epoch 9, Batch 1400] loss: 0.022218688591656245
[Epoch 9, Batch 1500] loss: 0.023661462433010455
[Epoch 9, Batch 1600] loss: 0.02033300716717349
[Epoch 9, Batch 1700] loss: 0.03486108907962262
[Epoch 9, Batch 1800] loss: 0.028049962361073995
[Epoch 9, Batch 1900] loss: 0.01766048822493758
[Epoch 9, Batch 2000] loss: 0.020705517604437774
[Epoch 9, Batch 2100] loss: 0.022909098233576515
[Epoch 9, Batch 2200] loss: 0.03001633780560951
[Epoch 9, Batch 2300] loss: 0.02230380457425781
[Epoch 9, Batch 2400] loss: 0.021139575151610187
[Epoch 9, Batch 2500] loss: 0.027166514218388328
[Epoch 9, Batch 2600] loss: 0.01541766921072849
[Epoch 9, Batch 2700] loss: 0.015486746429942286
[Epoch 9, Batch 2800] loss: 0.020061304356031543
[Epoch 9, Batch 2900] loss: 0.02619212903369771
[Epoch 9, Batch 3000] loss: 0.030263403737189946
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9864
Overfitting: 0.0449
[Epoch 10, Batch 100] loss: 0.014735897175196442
[Epoch 10, Batch 200] loss: 0.019022212665586267
[Epoch 10, Batch 300] loss: 0.02514464956781012
[Epoch 10, Batch 400] loss: 0.019864000449924788
[Epoch 10, Batch 500] loss: 0.017573654055777297
[Epoch 10, Batch 600] loss: 0.015225691003361136
[Epoch 10, Batch 700] loss: 0.0147988214247016
[Epoch 10, Batch 800] loss: 0.02321023074331606
[Epoch 10, Batch 900] loss: 0.012785495027401339
[Epoch 10, Batch 1000] loss: 0.025707521152789924
[Epoch 10, Batch 1100] loss: 0.01702611896309918
[Epoch 10, Batch 1200] loss: 0.025622282884141895
[Epoch 10, Batch 1300] loss: 0.01175125445906815
[Epoch 10, Batch 1400] loss: 0.011722683978296117
[Epoch 10, Batch 1500] loss: 0.0230978789148503
[Epoch 10, Batch 1600] loss: 0.017763342954112887
[Epoch 10, Batch 1700] loss: 0.0221168332407251
[Epoch 10, Batch 1800] loss: 0.01806095099360391
[Epoch 10, Batch 1900] loss: 0.017699545636678523
[Epoch 10, Batch 2000] loss: 0.02429466328008857
[Epoch 10, Batch 2100] loss: 0.015203618408777401
[Epoch 10, Batch 2200] loss: 0.018869549560295126
[Epoch 10, Batch 2300] loss: 0.019157452329372972
[Epoch 10, Batch 2400] loss: 0.03641813911966892
[Epoch 10, Batch 2500] loss: 0.02983069223402708
[Epoch 10, Batch 2600] loss: 0.016409265948750543
[Epoch 10, Batch 2700] loss: 0.014706136523163877
[Epoch 10, Batch 2800] loss: 0.021881142758411444
[Epoch 10, Batch 2900] loss: 0.02403510766875115
[Epoch 10, Batch 3000] loss: 0.02296330192391906
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0417
Validation Accuracy: 0.9880
Overfitting: 0.0417
Best model saved at epoch 10 with validation loss: 0.0417
[Epoch 11, Batch 100] loss: 0.016430781296821805
[Epoch 11, Batch 200] loss: 0.01564161618854996
[Epoch 11, Batch 300] loss: 0.017018395880986647
[Epoch 11, Batch 400] loss: 0.019819819383301365
[Epoch 11, Batch 500] loss: 0.010999089688230015
[Epoch 11, Batch 600] loss: 0.01464100549746945
[Epoch 11, Batch 700] loss: 0.01845827010976791
[Epoch 11, Batch 800] loss: 0.018439193567246548
[Epoch 11, Batch 900] loss: 0.019192865057557355
[Epoch 11, Batch 1000] loss: 0.017102908183333057
[Epoch 11, Batch 1100] loss: 0.021142486012595326
[Epoch 11, Batch 1200] loss: 0.01417781742522493
[Epoch 11, Batch 1300] loss: 0.019879371267788885
[Epoch 11, Batch 1400] loss: 0.014557173018474714
[Epoch 11, Batch 1500] loss: 0.024589028233503996
[Epoch 11, Batch 1600] loss: 0.012663307736338537
[Epoch 11, Batch 1700] loss: 0.010971933105574863
[Epoch 11, Batch 1800] loss: 0.010975097631599056
[Epoch 11, Batch 1900] loss: 0.019797354865877425
[Epoch 11, Batch 2000] loss: 0.019525766085753276
[Epoch 11, Batch 2100] loss: 0.023004965768250257
[Epoch 11, Batch 2200] loss: 0.026697351724960752
[Epoch 11, Batch 2300] loss: 0.021312901359051464
[Epoch 11, Batch 2400] loss: 0.014197660163517867
[Epoch 11, Batch 2500] loss: 0.02156753298409967
[Epoch 11, Batch 2600] loss: 0.022266792896853075
[Epoch 11, Batch 2700] loss: 0.016918050972635684
[Epoch 11, Batch 2800] loss: 0.019853250221713095
[Epoch 11, Batch 2900] loss: 0.01574930505114935
[Epoch 11, Batch 3000] loss: 0.03524643802022183
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0394
Validation Accuracy: 0.9890
Overfitting: 0.0394
Best model saved at epoch 11 with validation loss: 0.0394
[Epoch 12, Batch 100] loss: 0.01368855301468102
[Epoch 12, Batch 200] loss: 0.015500672883190418
[Epoch 12, Batch 300] loss: 0.021893700504479058
[Epoch 12, Batch 400] loss: 0.017153195475366374
[Epoch 12, Batch 500] loss: 0.015684141019855814
[Epoch 12, Batch 600] loss: 0.01187553223423265
[Epoch 12, Batch 700] loss: 0.016265280576844815
[Epoch 12, Batch 800] loss: 0.013147905546738912
[Epoch 12, Batch 900] loss: 0.008287780532828037
[Epoch 12, Batch 1000] loss: 0.01684032079012013
[Epoch 12, Batch 1100] loss: 0.019318658952506666
[Epoch 12, Batch 1200] loss: 0.011168701094557037
[Epoch 12, Batch 1300] loss: 0.010986018061666982
[Epoch 12, Batch 1400] loss: 0.007716737331720651
[Epoch 12, Batch 1500] loss: 0.02010785345093609
[Epoch 12, Batch 1600] loss: 0.013787130497003091
[Epoch 12, Batch 1700] loss: 0.012443092366065684
[Epoch 12, Batch 1800] loss: 0.02072817418204977
[Epoch 12, Batch 1900] loss: 0.01797092337385038
[Epoch 12, Batch 2000] loss: 0.014855352715494518
[Epoch 12, Batch 2100] loss: 0.017245604136678593
[Epoch 12, Batch 2200] loss: 0.013827183847211018
[Epoch 12, Batch 2300] loss: 0.007623020508544869
[Epoch 12, Batch 2400] loss: 0.01666528275805831
[Epoch 12, Batch 2500] loss: 0.017595315486123583
[Epoch 12, Batch 2600] loss: 0.00696953452190428
[Epoch 12, Batch 2700] loss: 0.0158078820879814
[Epoch 12, Batch 2800] loss: 0.015477814785845112
[Epoch 12, Batch 2900] loss: 0.011590711526641826
[Epoch 12, Batch 3000] loss: 0.006103574647131609
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0423
Validation Accuracy: 0.9880
Overfitting: 0.0423
[Epoch 13, Batch 100] loss: 0.01586510104503759
[Epoch 13, Batch 200] loss: 0.004026348723873525
[Epoch 13, Batch 300] loss: 0.027246769585599396
[Epoch 13, Batch 400] loss: 0.017665866220031603
[Epoch 13, Batch 500] loss: 0.012979428663038561
[Epoch 13, Batch 600] loss: 0.014550675906539254
[Epoch 13, Batch 700] loss: 0.010171576030045345
[Epoch 13, Batch 800] loss: 0.005116747295014648
[Epoch 13, Batch 900] loss: 0.014488244660660711
[Epoch 13, Batch 1000] loss: 0.015661546607725542
[Epoch 13, Batch 1100] loss: 0.018988215802316973
[Epoch 13, Batch 1200] loss: 0.00963638341886508
[Epoch 13, Batch 1300] loss: 0.015217946139564446
[Epoch 13, Batch 1400] loss: 0.014731903414553927
[Epoch 13, Batch 1500] loss: 0.008954335146513585
[Epoch 13, Batch 1600] loss: 0.00998251719642667
[Epoch 13, Batch 1700] loss: 0.016199206354012858
[Epoch 13, Batch 1800] loss: 0.018753223584431
[Epoch 13, Batch 1900] loss: 0.007267971774535908
[Epoch 13, Batch 2000] loss: 0.00909343683507359
[Epoch 13, Batch 2100] loss: 0.009409315106813665
[Epoch 13, Batch 2200] loss: 0.010363923898667053
[Epoch 13, Batch 2300] loss: 0.011545625180369825
[Epoch 13, Batch 2400] loss: 0.015454089461845797
[Epoch 13, Batch 2500] loss: 0.007437144233695108
[Epoch 13, Batch 2600] loss: 0.015003721728337496
[Epoch 13, Batch 2700] loss: 0.011348415856209612
[Epoch 13, Batch 2800] loss: 0.017988101992395967
[Epoch 13, Batch 2900] loss: 0.018629435328384715
[Epoch 13, Batch 3000] loss: 0.014439700004568295
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0421
Validation Accuracy: 0.9887
Overfitting: 0.0421
[Epoch 14, Batch 100] loss: 0.004403251447042749
[Epoch 14, Batch 200] loss: 0.005614245031711107
[Epoch 14, Batch 300] loss: 0.00975800834803067
[Epoch 14, Batch 400] loss: 0.004568059208831982
[Epoch 14, Batch 500] loss: 0.005587351686826878
[Epoch 14, Batch 600] loss: 0.006260266645590491
[Epoch 14, Batch 700] loss: 0.010648589110787724
[Epoch 14, Batch 800] loss: 0.012948059061595813
[Epoch 14, Batch 900] loss: 0.012537934356216737
[Epoch 14, Batch 1000] loss: 0.006277397236408433
[Epoch 14, Batch 1100] loss: 0.00528815530288341
[Epoch 14, Batch 1200] loss: 0.006412576334100777
[Epoch 14, Batch 1300] loss: 0.005468937516247933
[Epoch 14, Batch 1400] loss: 0.013476286069444541
[Epoch 14, Batch 1500] loss: 0.012482325015194534
[Epoch 14, Batch 1600] loss: 0.022907630505144425
[Epoch 14, Batch 1700] loss: 0.02971306869821092
[Epoch 14, Batch 1800] loss: 0.014861477054291755
[Epoch 14, Batch 1900] loss: 0.011687529273822293
[Epoch 14, Batch 2000] loss: 0.010579997344079857
[Epoch 14, Batch 2100] loss: 0.010388410340224254
[Epoch 14, Batch 2200] loss: 0.017617361338752743
[Epoch 14, Batch 2300] loss: 0.011394799247505603
[Epoch 14, Batch 2400] loss: 0.011018004173247392
[Epoch 14, Batch 2500] loss: 0.01879712553394711
[Epoch 14, Batch 2600] loss: 0.009165695412664264
[Epoch 14, Batch 2700] loss: 0.02389664802411062
[Epoch 14, Batch 2800] loss: 0.01598703108516929
[Epoch 14, Batch 2900] loss: 0.0073662460621653734
[Epoch 14, Batch 3000] loss: 0.009692049738405331
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0426
Validation Accuracy: 0.9888
Overfitting: 0.0426
[Epoch 15, Batch 100] loss: 0.010959458014153824
[Epoch 15, Batch 200] loss: 0.011674016956894774
[Epoch 15, Batch 300] loss: 0.007021487286820048
[Epoch 15, Batch 400] loss: 0.006337389605314456
[Epoch 15, Batch 500] loss: 0.009078552625396696
[Epoch 15, Batch 600] loss: 0.004225961765705506
[Epoch 15, Batch 700] loss: 0.0030772531186676133
[Epoch 15, Batch 800] loss: 0.011047766128901912
[Epoch 15, Batch 900] loss: 0.0051640129184602306
[Epoch 15, Batch 1000] loss: 0.008167801100320275
[Epoch 15, Batch 1100] loss: 0.007077534394140912
[Epoch 15, Batch 1200] loss: 0.009406926383342125
[Epoch 15, Batch 1300] loss: 0.010042933342047035
[Epoch 15, Batch 1400] loss: 0.00866255844959369
[Epoch 15, Batch 1500] loss: 0.012042261162187061
[Epoch 15, Batch 1600] loss: 0.01615907011663353
[Epoch 15, Batch 1700] loss: 0.0076438649604233435
[Epoch 15, Batch 1800] loss: 0.008083901075067387
[Epoch 15, Batch 1900] loss: 0.010824817736174736
[Epoch 15, Batch 2000] loss: 0.00791195559352218
[Epoch 15, Batch 2100] loss: 0.009715096413201537
[Epoch 15, Batch 2200] loss: 0.005514408721162454
[Epoch 15, Batch 2300] loss: 0.01048556119911609
[Epoch 15, Batch 2400] loss: 0.013766156510882865
[Epoch 15, Batch 2500] loss: 0.00550758573525286
[Epoch 15, Batch 2600] loss: 0.006132896629669631
[Epoch 15, Batch 2700] loss: 0.018702053648562467
[Epoch 15, Batch 2800] loss: 0.008516402228633525
[Epoch 15, Batch 2900] loss: 0.005110220409405884
[Epoch 15, Batch 3000] loss: 0.015623646341182393
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9889
Overfitting: 0.0464
[Epoch 16, Batch 100] loss: 0.005372060080899246
[Epoch 16, Batch 200] loss: 0.0035629679015005424
[Epoch 16, Batch 300] loss: 0.006452872882268821
[Epoch 16, Batch 400] loss: 0.008870386141443304
[Epoch 16, Batch 500] loss: 0.005333564712682346
[Epoch 16, Batch 600] loss: 0.0025791024832415134
[Epoch 16, Batch 700] loss: 0.006920815312923878
[Epoch 16, Batch 800] loss: 0.008797882999353988
[Epoch 16, Batch 900] loss: 0.005309318832469216
[Epoch 16, Batch 1000] loss: 0.005129561420061463
[Epoch 16, Batch 1100] loss: 0.007432974724742962
[Epoch 16, Batch 1200] loss: 0.01158237266197375
[Epoch 16, Batch 1300] loss: 0.009609008572779203
[Epoch 16, Batch 1400] loss: 0.004178073184959885
[Epoch 16, Batch 1500] loss: 0.013660973869943973
[Epoch 16, Batch 1600] loss: 0.002115551635978363
[Epoch 16, Batch 1700] loss: 0.013659180208059354
[Epoch 16, Batch 1800] loss: 0.009436120792847759
[Epoch 16, Batch 1900] loss: 0.013723128254737276
[Epoch 16, Batch 2000] loss: 0.011136587460171085
[Epoch 16, Batch 2100] loss: 0.019616329500022404
[Epoch 16, Batch 2200] loss: 0.006274470114203723
[Epoch 16, Batch 2300] loss: 0.014395374324665226
[Epoch 16, Batch 2400] loss: 0.010503939142317904
[Epoch 16, Batch 2500] loss: 0.005260297348886524
[Epoch 16, Batch 2600] loss: 0.00834387816790013
[Epoch 16, Batch 2700] loss: 0.008435257068796317
[Epoch 16, Batch 2800] loss: 0.007196742279325008
[Epoch 16, Batch 2900] loss: 0.011599077200526154
[Epoch 16, Batch 3000] loss: 0.004363145210033963
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0410
Validation Accuracy: 0.9896
Overfitting: 0.0410
[Epoch 17, Batch 100] loss: 0.004335252973455681
[Epoch 17, Batch 200] loss: 0.0019975952284244157
[Epoch 17, Batch 300] loss: 0.006924509993712036
[Epoch 17, Batch 400] loss: 0.0051295223790612
[Epoch 17, Batch 500] loss: 0.012427848284996799
[Epoch 17, Batch 600] loss: 0.011553578620057578
[Epoch 17, Batch 700] loss: 0.0030136955696184486
[Epoch 17, Batch 800] loss: 0.005471961496583617
[Epoch 17, Batch 900] loss: 0.01187641647347391
[Epoch 17, Batch 1000] loss: 0.004751301114701221
[Epoch 17, Batch 1100] loss: 0.006766992624637851
[Epoch 17, Batch 1200] loss: 0.008689578242558582
[Epoch 17, Batch 1300] loss: 0.006328228519035975
[Epoch 17, Batch 1400] loss: 0.0032929158206616194
[Epoch 17, Batch 1500] loss: 0.009167463651821209
[Epoch 17, Batch 1600] loss: 0.006442714771374085
[Epoch 17, Batch 1700] loss: 0.00524619377910767
[Epoch 17, Batch 1800] loss: 0.0034327916605400334
[Epoch 17, Batch 1900] loss: 0.007521083848228045
[Epoch 17, Batch 2000] loss: 0.0055041046939186345
[Epoch 17, Batch 2100] loss: 0.0051995122725224975
[Epoch 17, Batch 2200] loss: 0.007367257277533099
[Epoch 17, Batch 2300] loss: 0.005185542879386276
[Epoch 17, Batch 2400] loss: 0.005263256098320426
[Epoch 17, Batch 2500] loss: 0.00829707932998872
[Epoch 17, Batch 2600] loss: 0.012202200847471829
[Epoch 17, Batch 2700] loss: 0.007758434884390226
[Epoch 17, Batch 2800] loss: 0.011346953893211663
[Epoch 17, Batch 2900] loss: 0.006267713552347232
[Epoch 17, Batch 3000] loss: 0.004230473878125167
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9882
Overfitting: 0.0465
[Epoch 18, Batch 100] loss: 0.0034173610233426644
[Epoch 18, Batch 200] loss: 0.0038941885724034365
[Epoch 18, Batch 300] loss: 0.013299020090610156
[Epoch 18, Batch 400] loss: 0.007721601883960147
[Epoch 18, Batch 500] loss: 0.007905166922533909
[Epoch 18, Batch 600] loss: 0.0031727993103049814
[Epoch 18, Batch 700] loss: 0.0027461151968986995
[Epoch 18, Batch 800] loss: 0.002798063874752188
[Epoch 18, Batch 900] loss: 0.008093517587769838
[Epoch 18, Batch 1000] loss: 0.006227880573594575
[Epoch 18, Batch 1100] loss: 0.006521138880416401
[Epoch 18, Batch 1200] loss: 0.004719213761143237
[Epoch 18, Batch 1300] loss: 0.003997609574661283
[Epoch 18, Batch 1400] loss: 0.006289272722182773
[Epoch 18, Batch 1500] loss: 0.012001342045167576
[Epoch 18, Batch 1600] loss: 0.006075276626301047
[Epoch 18, Batch 1700] loss: 0.007506829736410054
[Epoch 18, Batch 1800] loss: 0.006093609794471036
[Epoch 18, Batch 1900] loss: 0.00846097367692238
[Epoch 18, Batch 2000] loss: 0.005032646043136992
[Epoch 18, Batch 2100] loss: 0.007542755067635199
[Epoch 18, Batch 2200] loss: 0.012244501140889383
[Epoch 18, Batch 2300] loss: 0.004204235340595232
[Epoch 18, Batch 2400] loss: 0.006346598715064147
[Epoch 18, Batch 2500] loss: 0.012577885209616398
[Epoch 18, Batch 2600] loss: 0.005211828737137694
[Epoch 18, Batch 2700] loss: 0.0064842307521098515
[Epoch 18, Batch 2800] loss: 0.0028323127062617457
[Epoch 18, Batch 2900] loss: 0.011060400907477685
[Epoch 18, Batch 3000] loss: 0.007514370393764693
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9872
Overfitting: 0.0492
[Epoch 19, Batch 100] loss: 0.0037260375013579506
[Epoch 19, Batch 200] loss: 0.005421380282211885
[Epoch 19, Batch 300] loss: 0.006535417719489942
[Epoch 19, Batch 400] loss: 0.0035870514874345363
[Epoch 19, Batch 500] loss: 0.0025763680166048177
[Epoch 19, Batch 600] loss: 0.00455259781347479
[Epoch 19, Batch 700] loss: 0.0019232151724077084
[Epoch 19, Batch 800] loss: 0.0020348880853498486
[Epoch 19, Batch 900] loss: 0.004705111224350276
[Epoch 19, Batch 1000] loss: 0.0015605845023321763
[Epoch 19, Batch 1100] loss: 0.011323670071408286
[Epoch 19, Batch 1200] loss: 0.008448898562951399
[Epoch 19, Batch 1300] loss: 0.003276953771231774
[Epoch 19, Batch 1400] loss: 0.0024002066911566543
[Epoch 19, Batch 1500] loss: 0.0041253786259355255
[Epoch 19, Batch 1600] loss: 0.00537633225300965
[Epoch 19, Batch 1700] loss: 0.004874901769600762
[Epoch 19, Batch 1800] loss: 0.0029236999864156133
[Epoch 19, Batch 1900] loss: 0.00577467731322713
[Epoch 19, Batch 2000] loss: 0.006400484220499152
[Epoch 19, Batch 2100] loss: 0.0051907439465068705
[Epoch 19, Batch 2200] loss: 0.00291082881908892
[Epoch 19, Batch 2300] loss: 0.014802586952187937
[Epoch 19, Batch 2400] loss: 0.010333006878358902
[Epoch 19, Batch 2500] loss: 0.005720013549757823
[Epoch 19, Batch 2600] loss: 0.004168004212160241
[Epoch 19, Batch 2700] loss: 0.0019187891755308329
[Epoch 19, Batch 2800] loss: 0.009895064615811862
[Epoch 19, Batch 2900] loss: 0.0035160337210646733
[Epoch 19, Batch 3000] loss: 0.003728474052820161
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9888
Overfitting: 0.0452
[Epoch 20, Batch 100] loss: 0.0025694924258377228
[Epoch 20, Batch 200] loss: 0.0015966144583683217
[Epoch 20, Batch 300] loss: 0.0025109919283482895
[Epoch 20, Batch 400] loss: 0.0019192111188169748
[Epoch 20, Batch 500] loss: 0.0011891788115644176
[Epoch 20, Batch 600] loss: 0.002138246947097997
[Epoch 20, Batch 700] loss: 0.005494645146200128
[Epoch 20, Batch 800] loss: 0.0031799619187813733
[Epoch 20, Batch 900] loss: 0.0046985747624466966
[Epoch 20, Batch 1000] loss: 0.0059631947831177
[Epoch 20, Batch 1100] loss: 0.003132161395598132
[Epoch 20, Batch 1200] loss: 0.00397853528679093
[Epoch 20, Batch 1300] loss: 0.003950240472431119
[Epoch 20, Batch 1400] loss: 0.0050450344510352355
[Epoch 20, Batch 1500] loss: 0.004197021455041181
[Epoch 20, Batch 1600] loss: 0.002080574577137213
[Epoch 20, Batch 1700] loss: 0.002054864290082392
[Epoch 20, Batch 1800] loss: 0.007844269038056951
[Epoch 20, Batch 1900] loss: 0.002944610748489538
[Epoch 20, Batch 2000] loss: 0.0025313335886795584
[Epoch 20, Batch 2100] loss: 0.0017450470484044445
[Epoch 20, Batch 2200] loss: 0.0020044944616628866
[Epoch 20, Batch 2300] loss: 0.0040527939586411325
[Epoch 20, Batch 2400] loss: 0.003933323238811113
[Epoch 20, Batch 2500] loss: 0.004527510060169107
[Epoch 20, Batch 2600] loss: 0.001828082326128424
[Epoch 20, Batch 2700] loss: 0.002965449220479854
[Epoch 20, Batch 2800] loss: 0.011589654442475278
[Epoch 20, Batch 2900] loss: 0.005887230717471539
[Epoch 20, Batch 3000] loss: 0.006082366543258786
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0454
Validation Accuracy: 0.9893
Overfitting: 0.0454
[Epoch 21, Batch 100] loss: 0.006056794799189618
[Epoch 21, Batch 200] loss: 0.010039953884549676
[Epoch 21, Batch 300] loss: 0.009776360482715064
[Epoch 21, Batch 400] loss: 0.002755417385506007
[Epoch 21, Batch 500] loss: 0.002559959714792512
[Epoch 21, Batch 600] loss: 0.0024896541955143903
[Epoch 21, Batch 700] loss: 0.0033238646604345943
[Epoch 21, Batch 800] loss: 0.004968253225525814
[Epoch 21, Batch 900] loss: 0.0028497335340023256
[Epoch 21, Batch 1000] loss: 0.0033842358182403134
[Epoch 21, Batch 1100] loss: 0.0035019893441948823
[Epoch 21, Batch 1200] loss: 0.00565861222271991
[Epoch 21, Batch 1300] loss: 0.003561449562991612
[Epoch 21, Batch 1400] loss: 0.0022996429279103837
[Epoch 21, Batch 1500] loss: 0.0013039512028541367
[Epoch 21, Batch 1600] loss: 0.004679455210176684
[Epoch 21, Batch 1700] loss: 0.007437107999436563
[Epoch 21, Batch 1800] loss: 0.004470127081473834
[Epoch 21, Batch 1900] loss: 0.002387816929779518
[Epoch 21, Batch 2000] loss: 0.008067201566201448
[Epoch 21, Batch 2100] loss: 0.002889188108939109
[Epoch 21, Batch 2200] loss: 0.006006679680360207
[Epoch 21, Batch 2300] loss: 0.00720250270803291
[Epoch 21, Batch 2400] loss: 0.003356402861228389
[Epoch 21, Batch 2500] loss: 0.011010745896440995
[Epoch 21, Batch 2600] loss: 0.007444936038194499
[Epoch 21, Batch 2700] loss: 0.003368173101260652
[Epoch 21, Batch 2800] loss: 0.002343587656823445
[Epoch 21, Batch 2900] loss: 0.004917663254043418
[Epoch 21, Batch 3000] loss: 0.005835039302558833
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9879
Overfitting: 0.0510
[Epoch 22, Batch 100] loss: 0.0035282634115962708
[Epoch 22, Batch 200] loss: 0.0017592285551424425
[Epoch 22, Batch 300] loss: 0.008103258508622844
[Epoch 22, Batch 400] loss: 0.0028412692933716243
[Epoch 22, Batch 500] loss: 0.002744810751462978
[Epoch 22, Batch 600] loss: 0.0023089795620279572
[Epoch 22, Batch 700] loss: 0.0037699623419068474
[Epoch 22, Batch 800] loss: 0.0012786011673630781
[Epoch 22, Batch 900] loss: 0.0021533012366471383
[Epoch 22, Batch 1000] loss: 0.0016443634765701454
[Epoch 22, Batch 1100] loss: 0.007284100098459856
[Epoch 22, Batch 1200] loss: 0.002192461823258327
[Epoch 22, Batch 1300] loss: 0.005364445027602471
[Epoch 22, Batch 1400] loss: 0.005498287471725689
[Epoch 22, Batch 1500] loss: 0.004450887555769754
[Epoch 22, Batch 1600] loss: 0.006088607687145213
[Epoch 22, Batch 1700] loss: 0.0015553790058788052
[Epoch 22, Batch 1800] loss: 0.004964047989558616
[Epoch 22, Batch 1900] loss: 0.005462592501466475
[Epoch 22, Batch 2000] loss: 0.0029720152639997367
[Epoch 22, Batch 2100] loss: 0.008776515233568033
[Epoch 22, Batch 2200] loss: 0.002720810570542653
[Epoch 22, Batch 2300] loss: 0.0036153814823461517
[Epoch 22, Batch 2400] loss: 0.002435209083599226
[Epoch 22, Batch 2500] loss: 0.0013654735462978352
[Epoch 22, Batch 2600] loss: 0.0015756346039816549
[Epoch 22, Batch 2700] loss: 0.00257866729637243
[Epoch 22, Batch 2800] loss: 0.0013556086328577522
[Epoch 22, Batch 2900] loss: 0.001453882622671898
[Epoch 22, Batch 3000] loss: 0.004051954633889956
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9893
Overfitting: 0.0479
[Epoch 23, Batch 100] loss: 0.002287630201969364
[Epoch 23, Batch 200] loss: 0.006068709278112578
[Epoch 23, Batch 300] loss: 0.0010014212212634277
[Epoch 23, Batch 400] loss: 0.0028341190753184264
[Epoch 23, Batch 500] loss: 0.004744773259694596
[Epoch 23, Batch 600] loss: 0.0009810214038375876
[Epoch 23, Batch 700] loss: 0.0012901101224428403
[Epoch 23, Batch 800] loss: 0.0007447293746912464
[Epoch 23, Batch 900] loss: 0.004701931977274398
[Epoch 23, Batch 1000] loss: 0.002548663743810664
[Epoch 23, Batch 1100] loss: 0.0014245985216409407
[Epoch 23, Batch 1200] loss: 0.001549339765419866
[Epoch 23, Batch 1300] loss: 0.0014962904072737615
[Epoch 23, Batch 1400] loss: 0.004526119799491824
[Epoch 23, Batch 1500] loss: 0.00245175816993878
[Epoch 23, Batch 1600] loss: 0.0028340305913903308
[Epoch 23, Batch 1700] loss: 0.002069348695934252
[Epoch 23, Batch 1800] loss: 0.002232475814072643
[Epoch 23, Batch 1900] loss: 0.0008738779664314222
[Epoch 23, Batch 2000] loss: 0.003105768405279683
[Epoch 23, Batch 2100] loss: 0.0012109533894155788
[Epoch 23, Batch 2200] loss: 0.004228183061155378
[Epoch 23, Batch 2300] loss: 0.0011097737037512444
[Epoch 23, Batch 2400] loss: 0.0035924990519974644
[Epoch 23, Batch 2500] loss: 0.0012836136975724343
[Epoch 23, Batch 2600] loss: 0.0015087230851389677
[Epoch 23, Batch 2700] loss: 0.0044383122558240016
[Epoch 23, Batch 2800] loss: 0.004344564856855584
[Epoch 23, Batch 2900] loss: 0.004218608118320315
[Epoch 23, Batch 3000] loss: 0.0033154328306929416
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9888
Overfitting: 0.0506
[Epoch 24, Batch 100] loss: 0.0012267468031595286
[Epoch 24, Batch 200] loss: 0.00214818646816493
[Epoch 24, Batch 300] loss: 0.0017716960590950848
[Epoch 24, Batch 400] loss: 0.0009871277634147901
[Epoch 24, Batch 500] loss: 0.0013323352481100414
[Epoch 24, Batch 600] loss: 0.0008445442773202671
[Epoch 24, Batch 700] loss: 0.0013349905502724369
[Epoch 24, Batch 800] loss: 0.0019210978897714881
[Epoch 24, Batch 900] loss: 0.0018321028578679943
[Epoch 24, Batch 1000] loss: 0.0034032825422097047
[Epoch 24, Batch 1100] loss: 0.001979001522715862
[Epoch 24, Batch 1200] loss: 0.001134365663953929
[Epoch 24, Batch 1300] loss: 0.0009482151176889175
[Epoch 24, Batch 1400] loss: 0.0009295620082448863
[Epoch 24, Batch 1500] loss: 0.0017398036354683022
[Epoch 24, Batch 1600] loss: 0.0017490808150163418
[Epoch 24, Batch 1700] loss: 0.0008221763941673643
[Epoch 24, Batch 1800] loss: 0.000894803732730045
[Epoch 24, Batch 1900] loss: 0.0004700363968025556
[Epoch 24, Batch 2000] loss: 0.0018775371248079863
[Epoch 24, Batch 2100] loss: 0.003494311217442885
[Epoch 24, Batch 2200] loss: 0.0011895907920782634
[Epoch 24, Batch 2300] loss: 0.005990064496565779
[Epoch 24, Batch 2400] loss: 0.002036247780222169
[Epoch 24, Batch 2500] loss: 0.001684592993784726
[Epoch 24, Batch 2600] loss: 0.0025755661746079284
[Epoch 24, Batch 2700] loss: 0.0015909270028990363
[Epoch 24, Batch 2800] loss: 0.002518853048457714
[Epoch 24, Batch 2900] loss: 0.0019003331370916498
[Epoch 24, Batch 3000] loss: 0.0020479460322599154
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9888
Overfitting: 0.0500
Fold 1 validation loss: 0.0500
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.3003626894950866
[Epoch 1, Batch 200] loss: 2.2878492140769957
[Epoch 1, Batch 300] loss: 2.2539433336257932
[Epoch 1, Batch 400] loss: 2.1675037682056426
[Epoch 1, Batch 500] loss: 1.7037433409690856
[Epoch 1, Batch 600] loss: 0.891835189461708
[Epoch 1, Batch 700] loss: 0.607236111909151
[Epoch 1, Batch 800] loss: 0.4702043666690588
[Epoch 1, Batch 900] loss: 0.4260995269566774
[Epoch 1, Batch 1000] loss: 0.372319333255291
[Epoch 1, Batch 1100] loss: 0.34773815751075743
[Epoch 1, Batch 1200] loss: 0.3044136926531792
[Epoch 1, Batch 1300] loss: 0.2776793842948973
[Epoch 1, Batch 1400] loss: 0.2580845138989389
[Epoch 1, Batch 1500] loss: 0.29769481636583806
[Epoch 1, Batch 1600] loss: 0.22134650068357586
[Epoch 1, Batch 1700] loss: 0.24227265199646353
[Epoch 1, Batch 1800] loss: 0.22592863479629158
[Epoch 1, Batch 1900] loss: 0.20921580333262682
[Epoch 1, Batch 2000] loss: 0.22293625436723233
[Epoch 1, Batch 2100] loss: 0.18480631353333593
[Epoch 1, Batch 2200] loss: 0.14816203546710313
[Epoch 1, Batch 2300] loss: 0.17080416064709425
[Epoch 1, Batch 2400] loss: 0.1640450811665505
[Epoch 1, Batch 2500] loss: 0.1430921671539545
[Epoch 1, Batch 2600] loss: 0.17652868657372892
[Epoch 1, Batch 2700] loss: 0.13370015243068337
[Epoch 1, Batch 2800] loss: 0.12492348815314472
[Epoch 1, Batch 2900] loss: 0.12712040454614906
[Epoch 1, Batch 3000] loss: 0.15549482261762024
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1330
Validation Accuracy: 0.9594
Overfitting: 0.1330
Best model saved at epoch 1 with validation loss: 0.1330
[Epoch 2, Batch 100] loss: 0.13800900127738713
[Epoch 2, Batch 200] loss: 0.11251329560764134
[Epoch 2, Batch 300] loss: 0.11355547516141087
[Epoch 2, Batch 400] loss: 0.14149893864290788
[Epoch 2, Batch 500] loss: 0.1130100050708279
[Epoch 2, Batch 600] loss: 0.10727913451846689
[Epoch 2, Batch 700] loss: 0.10147674374631606
[Epoch 2, Batch 800] loss: 0.10213055588770657
[Epoch 2, Batch 900] loss: 0.13552760778926312
[Epoch 2, Batch 1000] loss: 0.15098737037274987
[Epoch 2, Batch 1100] loss: 0.10291997999884188
[Epoch 2, Batch 1200] loss: 0.0881393396272324
[Epoch 2, Batch 1300] loss: 0.09993356466758996
[Epoch 2, Batch 1400] loss: 0.11436847513541579
[Epoch 2, Batch 1500] loss: 0.08164740541717037
[Epoch 2, Batch 1600] loss: 0.09392522592330352
[Epoch 2, Batch 1700] loss: 0.07896620595594868
[Epoch 2, Batch 1800] loss: 0.07795595682167913
[Epoch 2, Batch 1900] loss: 0.10651176890474744
[Epoch 2, Batch 2000] loss: 0.09918811926385387
[Epoch 2, Batch 2100] loss: 0.09342560125049204
[Epoch 2, Batch 2200] loss: 0.12151765192393213
[Epoch 2, Batch 2300] loss: 0.1218955133575946
[Epoch 2, Batch 2400] loss: 0.09761485519120469
[Epoch 2, Batch 2500] loss: 0.11677167128305882
[Epoch 2, Batch 2600] loss: 0.09578697540564463
[Epoch 2, Batch 2700] loss: 0.07290378312580287
[Epoch 2, Batch 2800] loss: 0.09238591970643029
[Epoch 2, Batch 2900] loss: 0.07751150106312707
[Epoch 2, Batch 3000] loss: 0.08856319410959258
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0883
Validation Accuracy: 0.9728
Overfitting: 0.0883
Best model saved at epoch 2 with validation loss: 0.0883
[Epoch 3, Batch 100] loss: 0.08577844973420724
[Epoch 3, Batch 200] loss: 0.07573645375203342
[Epoch 3, Batch 300] loss: 0.08601141183404253
[Epoch 3, Batch 400] loss: 0.07661943566752598
[Epoch 3, Batch 500] loss: 0.07868428309680894
[Epoch 3, Batch 600] loss: 0.0766230062278919
[Epoch 3, Batch 700] loss: 0.08180026642279699
[Epoch 3, Batch 800] loss: 0.08107738044112921
[Epoch 3, Batch 900] loss: 0.06650343792396597
[Epoch 3, Batch 1000] loss: 0.06771640050923451
[Epoch 3, Batch 1100] loss: 0.0788738876854768
[Epoch 3, Batch 1200] loss: 0.07598155185813084
[Epoch 3, Batch 1300] loss: 0.08259214147226884
[Epoch 3, Batch 1400] loss: 0.07508243082440458
[Epoch 3, Batch 1500] loss: 0.06531613693281542
[Epoch 3, Batch 1600] loss: 0.0814083266427042
[Epoch 3, Batch 1700] loss: 0.08391876472742296
[Epoch 3, Batch 1800] loss: 0.07570230526733213
[Epoch 3, Batch 1900] loss: 0.057421468073735014
[Epoch 3, Batch 2000] loss: 0.05157362012192607
[Epoch 3, Batch 2100] loss: 0.058751699603162705
[Epoch 3, Batch 2200] loss: 0.06600932357017882
[Epoch 3, Batch 2300] loss: 0.07285844938945957
[Epoch 3, Batch 2400] loss: 0.07143503675004467
[Epoch 3, Batch 2500] loss: 0.061435418611508794
[Epoch 3, Batch 2600] loss: 0.0649524984008167
[Epoch 3, Batch 2700] loss: 0.05540415246738121
[Epoch 3, Batch 2800] loss: 0.08190943945141044
[Epoch 3, Batch 2900] loss: 0.05027769054984674
[Epoch 3, Batch 3000] loss: 0.0688277543731965
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0867
Validation Accuracy: 0.9727
Overfitting: 0.0867
Best model saved at epoch 3 with validation loss: 0.0867
[Epoch 4, Batch 100] loss: 0.06855302165378817
[Epoch 4, Batch 200] loss: 0.036106146819656716
[Epoch 4, Batch 300] loss: 0.05681541347701568
[Epoch 4, Batch 400] loss: 0.05263309999019839
[Epoch 4, Batch 500] loss: 0.05827302556950599
[Epoch 4, Batch 600] loss: 0.03861183901201002
[Epoch 4, Batch 700] loss: 0.06168055435060524
[Epoch 4, Batch 800] loss: 0.07918704979470931
[Epoch 4, Batch 900] loss: 0.061451432061730885
[Epoch 4, Batch 1000] loss: 0.04954903290665243
[Epoch 4, Batch 1100] loss: 0.03420888702850789
[Epoch 4, Batch 1200] loss: 0.09192980551742949
[Epoch 4, Batch 1300] loss: 0.06411361885955558
[Epoch 4, Batch 1400] loss: 0.05296075446647592
[Epoch 4, Batch 1500] loss: 0.061001882170094175
[Epoch 4, Batch 1600] loss: 0.05606717708171345
[Epoch 4, Batch 1700] loss: 0.04928866079600994
[Epoch 4, Batch 1800] loss: 0.0575810071232263
[Epoch 4, Batch 1900] loss: 0.05850973149179481
[Epoch 4, Batch 2000] loss: 0.046866122122155504
[Epoch 4, Batch 2100] loss: 0.054023393266252245
[Epoch 4, Batch 2200] loss: 0.0626398360687017
[Epoch 4, Batch 2300] loss: 0.04692540543037467
[Epoch 4, Batch 2400] loss: 0.05416539749159711
[Epoch 4, Batch 2500] loss: 0.04820882346131839
[Epoch 4, Batch 2600] loss: 0.062290537290973585
[Epoch 4, Batch 2700] loss: 0.05254357175494079
[Epoch 4, Batch 2800] loss: 0.05932644820568385
[Epoch 4, Batch 2900] loss: 0.07756535128602991
[Epoch 4, Batch 3000] loss: 0.05569893594190944
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0729
Validation Accuracy: 0.9787
Overfitting: 0.0729
Best model saved at epoch 4 with validation loss: 0.0729
[Epoch 5, Batch 100] loss: 0.04769689340959303
[Epoch 5, Batch 200] loss: 0.04638745125557762
[Epoch 5, Batch 300] loss: 0.05473360940348357
[Epoch 5, Batch 400] loss: 0.03539218352729222
[Epoch 5, Batch 500] loss: 0.0484595607087249
[Epoch 5, Batch 600] loss: 0.04854536315659061
[Epoch 5, Batch 700] loss: 0.04293121180089656
[Epoch 5, Batch 800] loss: 0.03645843692735071
[Epoch 5, Batch 900] loss: 0.034429366853000826
[Epoch 5, Batch 1000] loss: 0.039509537778503724
[Epoch 5, Batch 1100] loss: 0.03613811210321728
[Epoch 5, Batch 1200] loss: 0.04103649790835334
[Epoch 5, Batch 1300] loss: 0.06099466568353819
[Epoch 5, Batch 1400] loss: 0.05921089690906228
[Epoch 5, Batch 1500] loss: 0.04943200513895135
[Epoch 5, Batch 1600] loss: 0.05136584529071115
[Epoch 5, Batch 1700] loss: 0.0477774747213698
[Epoch 5, Batch 1800] loss: 0.05097714790987084
[Epoch 5, Batch 1900] loss: 0.03732092599850148
[Epoch 5, Batch 2000] loss: 0.046938844424439595
[Epoch 5, Batch 2100] loss: 0.0626994608080713
[Epoch 5, Batch 2200] loss: 0.0395779249505722
[Epoch 5, Batch 2300] loss: 0.0674348969530547
[Epoch 5, Batch 2400] loss: 0.04450004123034887
[Epoch 5, Batch 2500] loss: 0.03245761965052225
[Epoch 5, Batch 2600] loss: 0.04344005913008005
[Epoch 5, Batch 2700] loss: 0.03973004487546859
[Epoch 5, Batch 2800] loss: 0.06363156963139772
[Epoch 5, Batch 2900] loss: 0.056988243866653646
[Epoch 5, Batch 3000] loss: 0.04491653404838871
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0641
Validation Accuracy: 0.9808
Overfitting: 0.0641
Best model saved at epoch 5 with validation loss: 0.0641
[Epoch 6, Batch 100] loss: 0.03189550333452644
[Epoch 6, Batch 200] loss: 0.04803507052056375
[Epoch 6, Batch 300] loss: 0.031473730279540174
[Epoch 6, Batch 400] loss: 0.034506936397228856
[Epoch 6, Batch 500] loss: 0.0392412795223936
[Epoch 6, Batch 600] loss: 0.023129746901104226
[Epoch 6, Batch 700] loss: 0.03073878559662262
[Epoch 6, Batch 800] loss: 0.04952356194262393
[Epoch 6, Batch 900] loss: 0.04765502486101468
[Epoch 6, Batch 1000] loss: 0.03711695467995014
[Epoch 6, Batch 1100] loss: 0.04900401426188182
[Epoch 6, Batch 1200] loss: 0.029669335660873913
[Epoch 6, Batch 1300] loss: 0.03171858885471011
[Epoch 6, Batch 1400] loss: 0.04273518751535448
[Epoch 6, Batch 1500] loss: 0.059335490725934505
[Epoch 6, Batch 1600] loss: 0.036012031111022226
[Epoch 6, Batch 1700] loss: 0.03700921046969597
[Epoch 6, Batch 1800] loss: 0.03887885660471511
[Epoch 6, Batch 1900] loss: 0.052329231291078034
[Epoch 6, Batch 2000] loss: 0.041663826704898384
[Epoch 6, Batch 2100] loss: 0.039459307059587445
[Epoch 6, Batch 2200] loss: 0.03700427307499922
[Epoch 6, Batch 2300] loss: 0.029837084289247286
[Epoch 6, Batch 2400] loss: 0.02449313030083431
[Epoch 6, Batch 2500] loss: 0.04375118094147183
[Epoch 6, Batch 2600] loss: 0.0548246922637918
[Epoch 6, Batch 2700] loss: 0.04133515362424078
[Epoch 6, Batch 2800] loss: 0.05026900418713922
[Epoch 6, Batch 2900] loss: 0.02738996100961231
[Epoch 6, Batch 3000] loss: 0.03469302375626285
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0584
Validation Accuracy: 0.9846
Overfitting: 0.0584
Best model saved at epoch 6 with validation loss: 0.0584
[Epoch 7, Batch 100] loss: 0.03271802316245157
[Epoch 7, Batch 200] loss: 0.0399437555338227
[Epoch 7, Batch 300] loss: 0.027929810097266455
[Epoch 7, Batch 400] loss: 0.022882409820449538
[Epoch 7, Batch 500] loss: 0.032102065088110976
[Epoch 7, Batch 600] loss: 0.045855988922994584
[Epoch 7, Batch 700] loss: 0.03148826893186197
[Epoch 7, Batch 800] loss: 0.041044085134199125
[Epoch 7, Batch 900] loss: 0.02826891023563803
[Epoch 7, Batch 1000] loss: 0.0384307107294444
[Epoch 7, Batch 1100] loss: 0.03925749422414811
[Epoch 7, Batch 1200] loss: 0.04088585623117979
[Epoch 7, Batch 1300] loss: 0.03455371997319162
[Epoch 7, Batch 1400] loss: 0.03692751506358036
[Epoch 7, Batch 1500] loss: 0.040463021451723764
[Epoch 7, Batch 1600] loss: 0.0345351339528861
[Epoch 7, Batch 1700] loss: 0.04782774999184767
[Epoch 7, Batch 1800] loss: 0.030541536809905664
[Epoch 7, Batch 1900] loss: 0.0388780038029654
[Epoch 7, Batch 2000] loss: 0.040692062762536806
[Epoch 7, Batch 2100] loss: 0.029124369691417087
[Epoch 7, Batch 2200] loss: 0.032230890298815214
[Epoch 7, Batch 2300] loss: 0.02724312557715166
[Epoch 7, Batch 2400] loss: 0.04194324019641499
[Epoch 7, Batch 2500] loss: 0.03076972578273853
[Epoch 7, Batch 2600] loss: 0.0327140117365343
[Epoch 7, Batch 2700] loss: 0.04018137772931368
[Epoch 7, Batch 2800] loss: 0.03417424751482031
[Epoch 7, Batch 2900] loss: 0.029174726781930074
[Epoch 7, Batch 3000] loss: 0.030005273279894027
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0557
Validation Accuracy: 0.9837
Overfitting: 0.0557
Best model saved at epoch 7 with validation loss: 0.0557
[Epoch 8, Batch 100] loss: 0.039060137285996464
[Epoch 8, Batch 200] loss: 0.01957908715150552
[Epoch 8, Batch 300] loss: 0.026685975750078795
[Epoch 8, Batch 400] loss: 0.023854151727427962
[Epoch 8, Batch 500] loss: 0.022907046082473244
[Epoch 8, Batch 600] loss: 0.02785904668387957
[Epoch 8, Batch 700] loss: 0.034507612655870615
[Epoch 8, Batch 800] loss: 0.02493012335486128
[Epoch 8, Batch 900] loss: 0.03590092429105425
[Epoch 8, Batch 1000] loss: 0.017406094427169592
[Epoch 8, Batch 1100] loss: 0.02957834837572591
[Epoch 8, Batch 1200] loss: 0.033351291549042796
[Epoch 8, Batch 1300] loss: 0.028082535232824737
[Epoch 8, Batch 1400] loss: 0.039349915601633256
[Epoch 8, Batch 1500] loss: 0.03333799411000655
[Epoch 8, Batch 1600] loss: 0.02943199067733076
[Epoch 8, Batch 1700] loss: 0.04258124060288537
[Epoch 8, Batch 1800] loss: 0.023726097590406427
[Epoch 8, Batch 1900] loss: 0.033748514051985694
[Epoch 8, Batch 2000] loss: 0.03252738884926657
[Epoch 8, Batch 2100] loss: 0.020152352398145012
[Epoch 8, Batch 2200] loss: 0.0273056404270028
[Epoch 8, Batch 2300] loss: 0.03472115660537384
[Epoch 8, Batch 2400] loss: 0.027778382782853443
[Epoch 8, Batch 2500] loss: 0.02095268166354799
[Epoch 8, Batch 2600] loss: 0.031050999508806854
[Epoch 8, Batch 2700] loss: 0.022021911724295934
[Epoch 8, Batch 2800] loss: 0.023085209151904564
[Epoch 8, Batch 2900] loss: 0.04020877657691017
[Epoch 8, Batch 3000] loss: 0.026433311029395553
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9848
Overfitting: 0.0539
Best model saved at epoch 8 with validation loss: 0.0539
[Epoch 9, Batch 100] loss: 0.019511545645436855
[Epoch 9, Batch 200] loss: 0.02020426982497156
[Epoch 9, Batch 300] loss: 0.02850377504790231
[Epoch 9, Batch 400] loss: 0.02021888793373364
[Epoch 9, Batch 500] loss: 0.01671903168906283
[Epoch 9, Batch 600] loss: 0.032432273626327515
[Epoch 9, Batch 700] loss: 0.028403614300368644
[Epoch 9, Batch 800] loss: 0.020916923074109944
[Epoch 9, Batch 900] loss: 0.024833122913114493
[Epoch 9, Batch 1000] loss: 0.016752735507543547
[Epoch 9, Batch 1100] loss: 0.03923421458530356
[Epoch 9, Batch 1200] loss: 0.01781902414695651
[Epoch 9, Batch 1300] loss: 0.02300396621518303
[Epoch 9, Batch 1400] loss: 0.02665175510221161
[Epoch 9, Batch 1500] loss: 0.035508586799842305
[Epoch 9, Batch 1600] loss: 0.022383846168304446
[Epoch 9, Batch 1700] loss: 0.020851996029377914
[Epoch 9, Batch 1800] loss: 0.046032590142640405
[Epoch 9, Batch 1900] loss: 0.018493344766829976
[Epoch 9, Batch 2000] loss: 0.02759396727720741
[Epoch 9, Batch 2100] loss: 0.030057686662075866
[Epoch 9, Batch 2200] loss: 0.01840683421516587
[Epoch 9, Batch 2300] loss: 0.02919020663241099
[Epoch 9, Batch 2400] loss: 0.016925095328479075
[Epoch 9, Batch 2500] loss: 0.04180902173859067
[Epoch 9, Batch 2600] loss: 0.015109270073444349
[Epoch 9, Batch 2700] loss: 0.025172643076366512
[Epoch 9, Batch 2800] loss: 0.014821601112962525
[Epoch 9, Batch 2900] loss: 0.026341367152199383
[Epoch 9, Batch 3000] loss: 0.02817983274704602
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0565
Validation Accuracy: 0.9834
Overfitting: 0.0565
[Epoch 10, Batch 100] loss: 0.021768792708708132
[Epoch 10, Batch 200] loss: 0.02538641782637569
[Epoch 10, Batch 300] loss: 0.016693405828555115
[Epoch 10, Batch 400] loss: 0.026649351379710425
[Epoch 10, Batch 500] loss: 0.043887984746688743
[Epoch 10, Batch 600] loss: 0.017935586870007684
[Epoch 10, Batch 700] loss: 0.02502876156442653
[Epoch 10, Batch 800] loss: 0.013768815447401722
[Epoch 10, Batch 900] loss: 0.010339014717901591
[Epoch 10, Batch 1000] loss: 0.01966069839312695
[Epoch 10, Batch 1100] loss: 0.034164503781721575
[Epoch 10, Batch 1200] loss: 0.015252271508761623
[Epoch 10, Batch 1300] loss: 0.01914392058417434
[Epoch 10, Batch 1400] loss: 0.016230946471005155
[Epoch 10, Batch 1500] loss: 0.02253894606796166
[Epoch 10, Batch 1600] loss: 0.024818742004754313
[Epoch 10, Batch 1700] loss: 0.020960503563692327
[Epoch 10, Batch 1800] loss: 0.021693928471868275
[Epoch 10, Batch 1900] loss: 0.010114509917439136
[Epoch 10, Batch 2000] loss: 0.025271583321482466
[Epoch 10, Batch 2100] loss: 0.024413085352643974
[Epoch 10, Batch 2200] loss: 0.015053010264673504
[Epoch 10, Batch 2300] loss: 0.03108188476340729
[Epoch 10, Batch 2400] loss: 0.030420193010031654
[Epoch 10, Batch 2500] loss: 0.030092809050747748
[Epoch 10, Batch 2600] loss: 0.022638406496407696
[Epoch 10, Batch 2700] loss: 0.03315764262173616
[Epoch 10, Batch 2800] loss: 0.02768258411128045
[Epoch 10, Batch 2900] loss: 0.03196697291416058
[Epoch 10, Batch 3000] loss: 0.019330179677781417
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9835
Overfitting: 0.0552
[Epoch 11, Batch 100] loss: 0.01676436730485875
[Epoch 11, Batch 200] loss: 0.019389599380083382
[Epoch 11, Batch 300] loss: 0.013572672537629843
[Epoch 11, Batch 400] loss: 0.020681879841613408
[Epoch 11, Batch 500] loss: 0.01693357805630512
[Epoch 11, Batch 600] loss: 0.023396743292105383
[Epoch 11, Batch 700] loss: 0.02161085262072447
[Epoch 11, Batch 800] loss: 0.021720428951230133
[Epoch 11, Batch 900] loss: 0.02036735765519552
[Epoch 11, Batch 1000] loss: 0.006681917954556411
[Epoch 11, Batch 1100] loss: 0.018341735953054012
[Epoch 11, Batch 1200] loss: 0.023966607674592525
[Epoch 11, Batch 1300] loss: 0.024755062531221485
[Epoch 11, Batch 1400] loss: 0.01869496050887392
[Epoch 11, Batch 1500] loss: 0.02516347934431906
[Epoch 11, Batch 1600] loss: 0.011349479792042984
[Epoch 11, Batch 1700] loss: 0.01840219626947146
[Epoch 11, Batch 1800] loss: 0.014926260679148982
[Epoch 11, Batch 1900] loss: 0.018236736122198637
[Epoch 11, Batch 2000] loss: 0.023116195588318077
[Epoch 11, Batch 2100] loss: 0.01587957971238211
[Epoch 11, Batch 2200] loss: 0.016192598227844426
[Epoch 11, Batch 2300] loss: 0.03230319559188501
[Epoch 11, Batch 2400] loss: 0.01806559888544143
[Epoch 11, Batch 2500] loss: 0.024081053029512987
[Epoch 11, Batch 2600] loss: 0.020025544556710885
[Epoch 11, Batch 2700] loss: 0.029512149957881775
[Epoch 11, Batch 2800] loss: 0.016366931615812062
[Epoch 11, Batch 2900] loss: 0.030661546995343087
[Epoch 11, Batch 3000] loss: 0.025820879923576286
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0521
Validation Accuracy: 0.9853
Overfitting: 0.0521
Best model saved at epoch 11 with validation loss: 0.0521
[Epoch 12, Batch 100] loss: 0.01148065735873388
[Epoch 12, Batch 200] loss: 0.01134109890936088
[Epoch 12, Batch 300] loss: 0.00977921691526717
[Epoch 12, Batch 400] loss: 0.023359251355977904
[Epoch 12, Batch 500] loss: 0.014332256796551519
[Epoch 12, Batch 600] loss: 0.01661484103111434
[Epoch 12, Batch 700] loss: 0.009677458917503828
[Epoch 12, Batch 800] loss: 0.021463906525805213
[Epoch 12, Batch 900] loss: 0.005592974676783342
[Epoch 12, Batch 1000] loss: 0.02067739174053713
[Epoch 12, Batch 1100] loss: 0.012504551407946565
[Epoch 12, Batch 1200] loss: 0.01787433091328239
[Epoch 12, Batch 1300] loss: 0.01916577507810871
[Epoch 12, Batch 1400] loss: 0.016702731582518025
[Epoch 12, Batch 1500] loss: 0.01415912834539995
[Epoch 12, Batch 1600] loss: 0.0263775258570422
[Epoch 12, Batch 1700] loss: 0.02342926434277615
[Epoch 12, Batch 1800] loss: 0.01383069857616647
[Epoch 12, Batch 1900] loss: 0.029362254571442464
[Epoch 12, Batch 2000] loss: 0.013361075124139461
[Epoch 12, Batch 2100] loss: 0.019542692333570814
[Epoch 12, Batch 2200] loss: 0.016470169374624675
[Epoch 12, Batch 2300] loss: 0.020620715036357068
[Epoch 12, Batch 2400] loss: 0.021367757460684516
[Epoch 12, Batch 2500] loss: 0.02148270952537132
[Epoch 12, Batch 2600] loss: 0.025852525336922554
[Epoch 12, Batch 2700] loss: 0.021979004176118908
[Epoch 12, Batch 2800] loss: 0.01519502919205479
[Epoch 12, Batch 2900] loss: 0.02024910568474297
[Epoch 12, Batch 3000] loss: 0.0239081959964642
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0683
Validation Accuracy: 0.9799
Overfitting: 0.0683
[Epoch 13, Batch 100] loss: 0.017274059432093054
[Epoch 13, Batch 200] loss: 0.008397303542524241
[Epoch 13, Batch 300] loss: 0.015497397508170252
[Epoch 13, Batch 400] loss: 0.011174264117653366
[Epoch 13, Batch 500] loss: 0.016842289022260957
[Epoch 13, Batch 600] loss: 0.020951503851310917
[Epoch 13, Batch 700] loss: 0.014996266453144926
[Epoch 13, Batch 800] loss: 0.0076633902361390935
[Epoch 13, Batch 900] loss: 0.015370849309874757
[Epoch 13, Batch 1000] loss: 0.011668586415780738
[Epoch 13, Batch 1100] loss: 0.010856059629350056
[Epoch 13, Batch 1200] loss: 0.013638445425767714
[Epoch 13, Batch 1300] loss: 0.016873285453111748
[Epoch 13, Batch 1400] loss: 0.008558350482308014
[Epoch 13, Batch 1500] loss: 0.019796899214579753
[Epoch 13, Batch 1600] loss: 0.010679190293176362
[Epoch 13, Batch 1700] loss: 0.010732667370393755
[Epoch 13, Batch 1800] loss: 0.01714586832785244
[Epoch 13, Batch 1900] loss: 0.02004673434967117
[Epoch 13, Batch 2000] loss: 0.014418612401323116
[Epoch 13, Batch 2100] loss: 0.019677473807532805
[Epoch 13, Batch 2200] loss: 0.01731357876142283
[Epoch 13, Batch 2300] loss: 0.005392502057202364
[Epoch 13, Batch 2400] loss: 0.009698642431576445
[Epoch 13, Batch 2500] loss: 0.012105130636164176
[Epoch 13, Batch 2600] loss: 0.019754016462002255
[Epoch 13, Batch 2700] loss: 0.02131727649534696
[Epoch 13, Batch 2800] loss: 0.03315046174546296
[Epoch 13, Batch 2900] loss: 0.020040404452101937
[Epoch 13, Batch 3000] loss: 0.02060280270055955
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0547
Validation Accuracy: 0.9844
Overfitting: 0.0547
[Epoch 14, Batch 100] loss: 0.01157162496939236
[Epoch 14, Batch 200] loss: 0.007064003382292867
[Epoch 14, Batch 300] loss: 0.00843912929221915
[Epoch 14, Batch 400] loss: 0.016014465546286372
[Epoch 14, Batch 500] loss: 0.01482428591716598
[Epoch 14, Batch 600] loss: 0.00846939255759935
[Epoch 14, Batch 700] loss: 0.008290277620781127
[Epoch 14, Batch 800] loss: 0.006984043037136871
[Epoch 14, Batch 900] loss: 0.00421855903665346
[Epoch 14, Batch 1000] loss: 0.010434861686298973
[Epoch 14, Batch 1100] loss: 0.013053353557102127
[Epoch 14, Batch 1200] loss: 0.011384023516634444
[Epoch 14, Batch 1300] loss: 0.01878135162727631
[Epoch 14, Batch 1400] loss: 0.013319339833578851
[Epoch 14, Batch 1500] loss: 0.007237363564890984
[Epoch 14, Batch 1600] loss: 0.008512307140827034
[Epoch 14, Batch 1700] loss: 0.014307489191642162
[Epoch 14, Batch 1800] loss: 0.01164216507850142
[Epoch 14, Batch 1900] loss: 0.012161072168473765
[Epoch 14, Batch 2000] loss: 0.012503204164206637
[Epoch 14, Batch 2100] loss: 0.019956727965472966
[Epoch 14, Batch 2200] loss: 0.02184720795357862
[Epoch 14, Batch 2300] loss: 0.01835571652640283
[Epoch 14, Batch 2400] loss: 0.014963709715175355
[Epoch 14, Batch 2500] loss: 0.025330604219934685
[Epoch 14, Batch 2600] loss: 0.019258336588864042
[Epoch 14, Batch 2700] loss: 0.017396578492471237
[Epoch 14, Batch 2800] loss: 0.012089506145130144
[Epoch 14, Batch 2900] loss: 0.01891924221719819
[Epoch 14, Batch 3000] loss: 0.012470202667755075
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9838
Overfitting: 0.0586
[Epoch 15, Batch 100] loss: 0.008461555508183664
[Epoch 15, Batch 200] loss: 0.009015922983389829
[Epoch 15, Batch 300] loss: 0.010519179183970663
[Epoch 15, Batch 400] loss: 0.01008385422777792
[Epoch 15, Batch 500] loss: 0.00533547795681443
[Epoch 15, Batch 600] loss: 0.010187366838608795
[Epoch 15, Batch 700] loss: 0.006083378960938717
[Epoch 15, Batch 800] loss: 0.010829454771433121
[Epoch 15, Batch 900] loss: 0.005990910566933963
[Epoch 15, Batch 1000] loss: 0.011541644770641141
[Epoch 15, Batch 1100] loss: 0.015346597315692634
[Epoch 15, Batch 1200] loss: 0.007094847447788198
[Epoch 15, Batch 1300] loss: 0.018762561896382975
[Epoch 15, Batch 1400] loss: 0.008867287579905679
[Epoch 15, Batch 1500] loss: 0.016004498398169743
[Epoch 15, Batch 1600] loss: 0.00874534658473749
[Epoch 15, Batch 1700] loss: 0.007973166772899276
[Epoch 15, Batch 1800] loss: 0.007604550942949118
[Epoch 15, Batch 1900] loss: 0.007776389183050014
[Epoch 15, Batch 2000] loss: 0.014930901715670188
[Epoch 15, Batch 2100] loss: 0.010252341877021535
[Epoch 15, Batch 2200] loss: 0.008897668610325126
[Epoch 15, Batch 2300] loss: 0.013780522619620116
[Epoch 15, Batch 2400] loss: 0.02264131066937807
[Epoch 15, Batch 2500] loss: 0.01743754912469967
[Epoch 15, Batch 2600] loss: 0.01137453641968932
[Epoch 15, Batch 2700] loss: 0.009830152217250542
[Epoch 15, Batch 2800] loss: 0.0121997520926152
[Epoch 15, Batch 2900] loss: 0.016623545563616064
[Epoch 15, Batch 3000] loss: 0.007332546222937708
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0655
Validation Accuracy: 0.9847
Overfitting: 0.0655
[Epoch 16, Batch 100] loss: 0.013176922947304775
[Epoch 16, Batch 200] loss: 0.008808447933897696
[Epoch 16, Batch 300] loss: 0.0038866225613401182
[Epoch 16, Batch 400] loss: 0.0052711487324677364
[Epoch 16, Batch 500] loss: 0.0041947075329085235
[Epoch 16, Batch 600] loss: 0.012959575164750277
[Epoch 16, Batch 700] loss: 0.007200883030109253
[Epoch 16, Batch 800] loss: 0.009177614497825743
[Epoch 16, Batch 900] loss: 0.011540204787429502
[Epoch 16, Batch 1000] loss: 0.008157581310319984
[Epoch 16, Batch 1100] loss: 0.01067299062901384
[Epoch 16, Batch 1200] loss: 0.009856534221803485
[Epoch 16, Batch 1300] loss: 0.008993422210469362
[Epoch 16, Batch 1400] loss: 0.014588979522050067
[Epoch 16, Batch 1500] loss: 0.01817370934964856
[Epoch 16, Batch 1600] loss: 0.011398512470286733
[Epoch 16, Batch 1700] loss: 0.01120342490220537
[Epoch 16, Batch 1800] loss: 0.0068693917597113345
[Epoch 16, Batch 1900] loss: 0.008243053857968334
[Epoch 16, Batch 2000] loss: 0.012204349172689035
[Epoch 16, Batch 2100] loss: 0.010694121041906328
[Epoch 16, Batch 2200] loss: 0.013727470635717508
[Epoch 16, Batch 2300] loss: 0.007394551240131477
[Epoch 16, Batch 2400] loss: 0.012255529344429306
[Epoch 16, Batch 2500] loss: 0.010067052905798164
[Epoch 16, Batch 2600] loss: 0.007255238576271949
[Epoch 16, Batch 2700] loss: 0.018284738799829937
[Epoch 16, Batch 2800] loss: 0.01293393399461138
[Epoch 16, Batch 2900] loss: 0.0077599263421598156
[Epoch 16, Batch 3000] loss: 0.007256279717958023
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9852
Overfitting: 0.0567
[Epoch 17, Batch 100] loss: 0.006141651934902086
[Epoch 17, Batch 200] loss: 0.004551157624009647
[Epoch 17, Batch 300] loss: 0.0067035009990740945
[Epoch 17, Batch 400] loss: 0.006654014770165304
[Epoch 17, Batch 500] loss: 0.009548458521948078
[Epoch 17, Batch 600] loss: 0.01097649003838569
[Epoch 17, Batch 700] loss: 0.0109271907341963
[Epoch 17, Batch 800] loss: 0.004787411361394334
[Epoch 17, Batch 900] loss: 0.004649180544565752
[Epoch 17, Batch 1000] loss: 0.00781445605177396
[Epoch 17, Batch 1100] loss: 0.006009044314005223
[Epoch 17, Batch 1200] loss: 0.006194346269730886
[Epoch 17, Batch 1300] loss: 0.006389475217933978
[Epoch 17, Batch 1400] loss: 0.01133341688695282
[Epoch 17, Batch 1500] loss: 0.017178878356071438
[Epoch 17, Batch 1600] loss: 0.014218777261237391
[Epoch 17, Batch 1700] loss: 0.0077116811742416755
[Epoch 17, Batch 1800] loss: 0.00833113516288222
[Epoch 17, Batch 1900] loss: 0.005259668873368355
[Epoch 17, Batch 2000] loss: 0.005127247652387723
[Epoch 17, Batch 2100] loss: 0.008500778726880754
[Epoch 17, Batch 2200] loss: 0.00977412290940265
[Epoch 17, Batch 2300] loss: 0.01737367186010033
[Epoch 17, Batch 2400] loss: 0.007423750428406492
[Epoch 17, Batch 2500] loss: 0.005009947395689665
[Epoch 17, Batch 2600] loss: 0.014333597003063686
[Epoch 17, Batch 2700] loss: 0.005974459751932955
[Epoch 17, Batch 2800] loss: 0.00999111455485945
[Epoch 17, Batch 2900] loss: 0.004410476920093061
[Epoch 17, Batch 3000] loss: 0.012565637135289763
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0699
Validation Accuracy: 0.9845
Overfitting: 0.0699
[Epoch 18, Batch 100] loss: 0.008325587183464904
[Epoch 18, Batch 200] loss: 0.00839828068669931
[Epoch 18, Batch 300] loss: 0.00767656316573948
[Epoch 18, Batch 400] loss: 0.00848364993409291
[Epoch 18, Batch 500] loss: 0.005970384728162799
[Epoch 18, Batch 600] loss: 0.005482739418139318
[Epoch 18, Batch 700] loss: 0.005794661891841315
[Epoch 18, Batch 800] loss: 0.008743967783444759
[Epoch 18, Batch 900] loss: 0.008499110540533365
[Epoch 18, Batch 1000] loss: 0.011167616228722182
[Epoch 18, Batch 1100] loss: 0.007316228918425622
[Epoch 18, Batch 1200] loss: 0.013722614266625896
[Epoch 18, Batch 1300] loss: 0.014024739857177337
[Epoch 18, Batch 1400] loss: 0.012553312235731938
[Epoch 18, Batch 1500] loss: 0.005820692352615424
[Epoch 18, Batch 1600] loss: 0.01117853729174385
[Epoch 18, Batch 1700] loss: 0.008147257449458607
[Epoch 18, Batch 1800] loss: 0.005860042812681741
[Epoch 18, Batch 1900] loss: 0.006167757064124544
[Epoch 18, Batch 2000] loss: 0.006020687192568062
[Epoch 18, Batch 2100] loss: 0.004182693670675235
[Epoch 18, Batch 2200] loss: 0.0057974900840326886
[Epoch 18, Batch 2300] loss: 0.01047936057836523
[Epoch 18, Batch 2400] loss: 0.01049110523019408
[Epoch 18, Batch 2500] loss: 0.005257154383834859
[Epoch 18, Batch 2600] loss: 0.012194904741472784
[Epoch 18, Batch 2700] loss: 0.00616364604425371
[Epoch 18, Batch 2800] loss: 0.0033845234305863413
[Epoch 18, Batch 2900] loss: 0.008150276103168607
[Epoch 18, Batch 3000] loss: 0.006777171593603271
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0585
Validation Accuracy: 0.9862
Overfitting: 0.0585
[Epoch 19, Batch 100] loss: 0.003412762441294035
[Epoch 19, Batch 200] loss: 0.004997497834035585
[Epoch 19, Batch 300] loss: 0.0036335809573256484
[Epoch 19, Batch 400] loss: 0.007087331335158069
[Epoch 19, Batch 500] loss: 0.004087580167345095
[Epoch 19, Batch 600] loss: 0.007231188449424621
[Epoch 19, Batch 700] loss: 0.006812659661306952
[Epoch 19, Batch 800] loss: 0.003425060287938777
[Epoch 19, Batch 900] loss: 0.0026507786039883284
[Epoch 19, Batch 1000] loss: 0.0036373673381683604
[Epoch 19, Batch 1100] loss: 0.005617905969509138
[Epoch 19, Batch 1200] loss: 0.005270491596941156
[Epoch 19, Batch 1300] loss: 0.004352661926745895
[Epoch 19, Batch 1400] loss: 0.008270391152169623
[Epoch 19, Batch 1500] loss: 0.007578023005961541
[Epoch 19, Batch 1600] loss: 0.0053992686710353155
[Epoch 19, Batch 1700] loss: 0.005480680080916045
[Epoch 19, Batch 1800] loss: 0.002761416062917874
[Epoch 19, Batch 1900] loss: 0.011002855543698615
[Epoch 19, Batch 2000] loss: 0.007825284256980466
[Epoch 19, Batch 2100] loss: 0.006367672730889353
[Epoch 19, Batch 2200] loss: 0.005573252522312941
[Epoch 19, Batch 2300] loss: 0.016094808871770283
[Epoch 19, Batch 2400] loss: 0.006791597372588285
[Epoch 19, Batch 2500] loss: 0.0057238061671398555
[Epoch 19, Batch 2600] loss: 0.006617891117675754
[Epoch 19, Batch 2700] loss: 0.012044845321431694
[Epoch 19, Batch 2800] loss: 0.017431681736147765
[Epoch 19, Batch 2900] loss: 0.005805170193420963
[Epoch 19, Batch 3000] loss: 0.0053910048898342215
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0574
Validation Accuracy: 0.9870
Overfitting: 0.0574
[Epoch 20, Batch 100] loss: 0.011394855594208195
[Epoch 20, Batch 200] loss: 0.0037697475304753424
[Epoch 20, Batch 300] loss: 0.005392699576752875
[Epoch 20, Batch 400] loss: 0.0063771730756388935
[Epoch 20, Batch 500] loss: 0.0028843560873815476
[Epoch 20, Batch 600] loss: 0.0023890864306099504
[Epoch 20, Batch 700] loss: 0.0028094310506810416
[Epoch 20, Batch 800] loss: 0.0033546605632000137
[Epoch 20, Batch 900] loss: 0.002578532077320972
[Epoch 20, Batch 1000] loss: 0.002133779869233763
[Epoch 20, Batch 1100] loss: 0.003449422146575216
[Epoch 20, Batch 1200] loss: 0.005192082385664207
[Epoch 20, Batch 1300] loss: 0.004698427958176126
[Epoch 20, Batch 1400] loss: 0.004488275556811913
[Epoch 20, Batch 1500] loss: 0.00906328083117387
[Epoch 20, Batch 1600] loss: 0.003446825236197739
[Epoch 20, Batch 1700] loss: 0.001956891119247075
[Epoch 20, Batch 1800] loss: 0.004647107821197097
[Epoch 20, Batch 1900] loss: 0.0037666953715961428
[Epoch 20, Batch 2000] loss: 0.005627898663917676
[Epoch 20, Batch 2100] loss: 0.008184255381711409
[Epoch 20, Batch 2200] loss: 0.00747954640893795
[Epoch 20, Batch 2300] loss: 0.009005125907779075
[Epoch 20, Batch 2400] loss: 0.005905398381614759
[Epoch 20, Batch 2500] loss: 0.008613286495761372
[Epoch 20, Batch 2600] loss: 0.008640731391247982
[Epoch 20, Batch 2700] loss: 0.0035532432774317614
[Epoch 20, Batch 2800] loss: 0.003578604293428782
[Epoch 20, Batch 2900] loss: 0.007533618151425117
[Epoch 20, Batch 3000] loss: 0.003128857979482973
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0577
Validation Accuracy: 0.9867
Overfitting: 0.0577
[Epoch 21, Batch 100] loss: 0.004658431146610837
[Epoch 21, Batch 200] loss: 0.007796048527687845
[Epoch 21, Batch 300] loss: 0.0012126422626236887
[Epoch 21, Batch 400] loss: 0.004529169338724017
[Epoch 21, Batch 500] loss: 0.0012823866586910526
[Epoch 21, Batch 600] loss: 0.005823000329081651
[Epoch 21, Batch 700] loss: 0.008977666758135001
[Epoch 21, Batch 800] loss: 0.003817799693424604
[Epoch 21, Batch 900] loss: 0.007287819657026375
[Epoch 21, Batch 1000] loss: 0.0022351487431152605
[Epoch 21, Batch 1100] loss: 0.00470134878872841
[Epoch 21, Batch 1200] loss: 0.00576032054925463
[Epoch 21, Batch 1300] loss: 0.006352606741908176
[Epoch 21, Batch 1400] loss: 0.00229009819033962
[Epoch 21, Batch 1500] loss: 0.00271077766976191
[Epoch 21, Batch 1600] loss: 0.005756336801591147
[Epoch 21, Batch 1700] loss: 0.008158171431988137
[Epoch 21, Batch 1800] loss: 0.009780286530311742
[Epoch 21, Batch 1900] loss: 0.00835877938530757
[Epoch 21, Batch 2000] loss: 0.0025948125353130536
[Epoch 21, Batch 2100] loss: 0.00888533632645931
[Epoch 21, Batch 2200] loss: 0.0077678436184874045
[Epoch 21, Batch 2300] loss: 0.00684990028627908
[Epoch 21, Batch 2400] loss: 0.007743104396562899
[Epoch 21, Batch 2500] loss: 0.0042898672984961195
[Epoch 21, Batch 2600] loss: 0.0042200091952349795
[Epoch 21, Batch 2700] loss: 0.005802952592250392
[Epoch 21, Batch 2800] loss: 0.005716572788570602
[Epoch 21, Batch 2900] loss: 0.012196287094321861
[Epoch 21, Batch 3000] loss: 0.007470160996813319
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0594
Validation Accuracy: 0.9868
Overfitting: 0.0594
[Epoch 22, Batch 100] loss: 0.0046785061879336355
[Epoch 22, Batch 200] loss: 0.00848649070142983
[Epoch 22, Batch 300] loss: 0.003181008316266798
[Epoch 22, Batch 400] loss: 0.002943046186096581
[Epoch 22, Batch 500] loss: 0.005923422068255491
[Epoch 22, Batch 600] loss: 0.004060071830226661
[Epoch 22, Batch 700] loss: 0.007687234609884399
[Epoch 22, Batch 800] loss: 0.0045067787469690755
[Epoch 22, Batch 900] loss: 0.006327006562089537
[Epoch 22, Batch 1000] loss: 0.005805464829405764
[Epoch 22, Batch 1100] loss: 0.0062207699716736896
[Epoch 22, Batch 1200] loss: 0.0049146738235469915
[Epoch 22, Batch 1300] loss: 0.00307348159544631
[Epoch 22, Batch 1400] loss: 0.007759035657561526
[Epoch 22, Batch 1500] loss: 0.00496501390179219
[Epoch 22, Batch 1600] loss: 0.004187718582030015
[Epoch 22, Batch 1700] loss: 0.003371089811899992
[Epoch 22, Batch 1800] loss: 0.0019710377480504347
[Epoch 22, Batch 1900] loss: 0.006373943061967111
[Epoch 22, Batch 2000] loss: 0.003104588801855357
[Epoch 22, Batch 2100] loss: 0.0034442902681286114
[Epoch 22, Batch 2200] loss: 0.0039602541100009605
[Epoch 22, Batch 2300] loss: 0.00389073637335855
[Epoch 22, Batch 2400] loss: 0.0043451103256006715
[Epoch 22, Batch 2500] loss: 0.0035942653608890397
[Epoch 22, Batch 2600] loss: 0.001769932711577553
[Epoch 22, Batch 2700] loss: 0.003670692247533225
[Epoch 22, Batch 2800] loss: 0.004273809725689546
[Epoch 22, Batch 2900] loss: 0.0027976097259185197
[Epoch 22, Batch 3000] loss: 0.0111819651778535
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0698
Validation Accuracy: 0.9864
Overfitting: 0.0698
[Epoch 23, Batch 100] loss: 0.009292538572328724
[Epoch 23, Batch 200] loss: 0.005317576105053945
[Epoch 23, Batch 300] loss: 0.004938126390501338
[Epoch 23, Batch 400] loss: 0.00445469997672916
[Epoch 23, Batch 500] loss: 0.0027514529386215257
[Epoch 23, Batch 600] loss: 0.0033757492008209054
[Epoch 23, Batch 700] loss: 0.005538413632334596
[Epoch 23, Batch 800] loss: 0.0028790295762063066
[Epoch 23, Batch 900] loss: 0.0017395582104944652
[Epoch 23, Batch 1000] loss: 0.0025020714623565253
[Epoch 23, Batch 1100] loss: 0.00297006466080175
[Epoch 23, Batch 1200] loss: 0.001018175605381657
[Epoch 23, Batch 1300] loss: 0.0013230685123767217
[Epoch 23, Batch 1400] loss: 0.002135538376878543
[Epoch 23, Batch 1500] loss: 0.0025645504850815826
[Epoch 23, Batch 1600] loss: 0.002234137252799826
[Epoch 23, Batch 1700] loss: 0.004147771677149308
[Epoch 23, Batch 1800] loss: 0.003618966468879137
[Epoch 23, Batch 1900] loss: 0.004937053921419477
[Epoch 23, Batch 2000] loss: 0.004860609789152335
[Epoch 23, Batch 2100] loss: 0.0026614094224589736
[Epoch 23, Batch 2200] loss: 0.004244918318671509
[Epoch 23, Batch 2300] loss: 0.004206548711115943
[Epoch 23, Batch 2400] loss: 0.003646198786949526
[Epoch 23, Batch 2500] loss: 0.004428581313366351
[Epoch 23, Batch 2600] loss: 0.00602862976836704
[Epoch 23, Batch 2700] loss: 0.0023253568571851703
[Epoch 23, Batch 2800] loss: 0.0011509034749860624
[Epoch 23, Batch 2900] loss: 0.0050412784630810845
[Epoch 23, Batch 3000] loss: 0.00959931375025178
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0651
Validation Accuracy: 0.9856
Overfitting: 0.0651
[Epoch 24, Batch 100] loss: 0.002765180142723267
[Epoch 24, Batch 200] loss: 0.004943603081424044
[Epoch 24, Batch 300] loss: 0.006460137132178403
[Epoch 24, Batch 400] loss: 0.003404620262745084
[Epoch 24, Batch 500] loss: 0.013293655461835101
[Epoch 24, Batch 600] loss: 0.0015630975133038305
[Epoch 24, Batch 700] loss: 0.0038685801125950547
[Epoch 24, Batch 800] loss: 0.0018942394696398425
[Epoch 24, Batch 900] loss: 0.0029247962926694984
[Epoch 24, Batch 1000] loss: 0.0034999471868098907
[Epoch 24, Batch 1100] loss: 0.0033248652880513417
[Epoch 24, Batch 1200] loss: 0.0029471903849037063
[Epoch 24, Batch 1300] loss: 0.0027513156481413148
[Epoch 24, Batch 1400] loss: 0.004969563781278339
[Epoch 24, Batch 1500] loss: 0.005265605635278234
[Epoch 24, Batch 1600] loss: 0.004597409522293674
[Epoch 24, Batch 1700] loss: 0.0053109756077350315
[Epoch 24, Batch 1800] loss: 0.0028299879425361498
[Epoch 24, Batch 1900] loss: 0.0013339330877317934
[Epoch 24, Batch 2000] loss: 0.0052945536238064505
[Epoch 24, Batch 2100] loss: 0.00585738290983727
[Epoch 24, Batch 2200] loss: 0.005497278443204294
[Epoch 24, Batch 2300] loss: 0.002761766204354199
[Epoch 24, Batch 2400] loss: 0.002685536391342964
[Epoch 24, Batch 2500] loss: 0.0018468854128536093
[Epoch 24, Batch 2600] loss: 0.0039032533274857427
[Epoch 24, Batch 2700] loss: 0.0010780615973897056
[Epoch 24, Batch 2800] loss: 0.0014362403542914138
[Epoch 24, Batch 2900] loss: 0.00992707715605775
[Epoch 24, Batch 3000] loss: 0.0022146496494733015
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0580
Validation Accuracy: 0.9874
Overfitting: 0.0580
Fold 2 validation loss: 0.0580
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.301033535003662
[Epoch 1, Batch 200] loss: 2.2929411578178405
[Epoch 1, Batch 300] loss: 2.2805289888381957
[Epoch 1, Batch 400] loss: 2.256316783428192
[Epoch 1, Batch 500] loss: 2.189736371040344
[Epoch 1, Batch 600] loss: 1.8736021637916564
[Epoch 1, Batch 700] loss: 0.9553906962275505
[Epoch 1, Batch 800] loss: 0.6524500779807567
[Epoch 1, Batch 900] loss: 0.48249964855611327
[Epoch 1, Batch 1000] loss: 0.44075233690440657
[Epoch 1, Batch 1100] loss: 0.36329559572041037
[Epoch 1, Batch 1200] loss: 0.35224181473255156
[Epoch 1, Batch 1300] loss: 0.31273163929581643
[Epoch 1, Batch 1400] loss: 0.3202024200186133
[Epoch 1, Batch 1500] loss: 0.3137341381981969
[Epoch 1, Batch 1600] loss: 0.2680796879529953
[Epoch 1, Batch 1700] loss: 0.254113608263433
[Epoch 1, Batch 1800] loss: 0.17987479493021966
[Epoch 1, Batch 1900] loss: 0.2599340558517724
[Epoch 1, Batch 2000] loss: 0.2465907596051693
[Epoch 1, Batch 2100] loss: 0.14806109882891177
[Epoch 1, Batch 2200] loss: 0.20037269281223416
[Epoch 1, Batch 2300] loss: 0.17409847365692258
[Epoch 1, Batch 2400] loss: 0.19800183263607324
[Epoch 1, Batch 2500] loss: 0.16289120668545365
[Epoch 1, Batch 2600] loss: 0.2026277695596218
[Epoch 1, Batch 2700] loss: 0.1808294280618429
[Epoch 1, Batch 2800] loss: 0.1529480874259025
[Epoch 1, Batch 2900] loss: 0.14590545056387783
[Epoch 1, Batch 3000] loss: 0.15787107300944625
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1526
Validation Accuracy: 0.9517
Overfitting: 0.1526
Best model saved at epoch 1 with validation loss: 0.1526
[Epoch 2, Batch 100] loss: 0.14469666887074709
[Epoch 2, Batch 200] loss: 0.14127526863943785
[Epoch 2, Batch 300] loss: 0.1534179867291823
[Epoch 2, Batch 400] loss: 0.14446446744725108
[Epoch 2, Batch 500] loss: 0.14926832635886966
[Epoch 2, Batch 600] loss: 0.11639057971537113
[Epoch 2, Batch 700] loss: 0.14416485534980894
[Epoch 2, Batch 800] loss: 0.12345951744122431
[Epoch 2, Batch 900] loss: 0.14293691142462195
[Epoch 2, Batch 1000] loss: 0.13430495200213044
[Epoch 2, Batch 1100] loss: 0.10715305743273347
[Epoch 2, Batch 1200] loss: 0.09805137717630714
[Epoch 2, Batch 1300] loss: 0.13147274316521362
[Epoch 2, Batch 1400] loss: 0.1250832278910093
[Epoch 2, Batch 1500] loss: 0.14120314749190585
[Epoch 2, Batch 1600] loss: 0.133674874487333
[Epoch 2, Batch 1700] loss: 0.11335198918357492
[Epoch 2, Batch 1800] loss: 0.10978644797811285
[Epoch 2, Batch 1900] loss: 0.08408649475080893
[Epoch 2, Batch 2000] loss: 0.11372267482569441
[Epoch 2, Batch 2100] loss: 0.12109965650597587
[Epoch 2, Batch 2200] loss: 0.09434468020685018
[Epoch 2, Batch 2300] loss: 0.12576203541830183
[Epoch 2, Batch 2400] loss: 0.12070706839673222
[Epoch 2, Batch 2500] loss: 0.08708082336466759
[Epoch 2, Batch 2600] loss: 0.10150758617091923
[Epoch 2, Batch 2700] loss: 0.10042753152083606
[Epoch 2, Batch 2800] loss: 0.08846403123810888
[Epoch 2, Batch 2900] loss: 0.09156839530915022
[Epoch 2, Batch 3000] loss: 0.10222484130295925
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1011
Validation Accuracy: 0.9719
Overfitting: 0.1011
Best model saved at epoch 2 with validation loss: 0.1011
[Epoch 3, Batch 100] loss: 0.0889796913205646
[Epoch 3, Batch 200] loss: 0.07943877764279023
[Epoch 3, Batch 300] loss: 0.09290054936427623
[Epoch 3, Batch 400] loss: 0.08879244389361701
[Epoch 3, Batch 500] loss: 0.08366191996028646
[Epoch 3, Batch 600] loss: 0.07377743903663941
[Epoch 3, Batch 700] loss: 0.0837579928454943
[Epoch 3, Batch 800] loss: 0.07892781259259209
[Epoch 3, Batch 900] loss: 0.08424916451796889
[Epoch 3, Batch 1000] loss: 0.07747579275863245
[Epoch 3, Batch 1100] loss: 0.08425186752574518
[Epoch 3, Batch 1200] loss: 0.08089413302717731
[Epoch 3, Batch 1300] loss: 0.08460092481807806
[Epoch 3, Batch 1400] loss: 0.08330394015647472
[Epoch 3, Batch 1500] loss: 0.07674343715654686
[Epoch 3, Batch 1600] loss: 0.08521510293590837
[Epoch 3, Batch 1700] loss: 0.07179106676223455
[Epoch 3, Batch 1800] loss: 0.06961332353646867
[Epoch 3, Batch 1900] loss: 0.0831610092369374
[Epoch 3, Batch 2000] loss: 0.05917817536217626
[Epoch 3, Batch 2100] loss: 0.10683564177830704
[Epoch 3, Batch 2200] loss: 0.08492532674921677
[Epoch 3, Batch 2300] loss: 0.07241147430846467
[Epoch 3, Batch 2400] loss: 0.06861962103866973
[Epoch 3, Batch 2500] loss: 0.07476619974360801
[Epoch 3, Batch 2600] loss: 0.07628881250158884
[Epoch 3, Batch 2700] loss: 0.06954204541281797
[Epoch 3, Batch 2800] loss: 0.08180079904384911
[Epoch 3, Batch 2900] loss: 0.06672933307825588
[Epoch 3, Batch 3000] loss: 0.0783142723434139
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0856
Validation Accuracy: 0.9722
Overfitting: 0.0856
Best model saved at epoch 3 with validation loss: 0.0856
[Epoch 4, Batch 100] loss: 0.06943098321789876
[Epoch 4, Batch 200] loss: 0.07284647831285838
[Epoch 4, Batch 300] loss: 0.05522970671649091
[Epoch 4, Batch 400] loss: 0.06506210221908987
[Epoch 4, Batch 500] loss: 0.0641288083884865
[Epoch 4, Batch 600] loss: 0.07865282204351388
[Epoch 4, Batch 700] loss: 0.06402830861741676
[Epoch 4, Batch 800] loss: 0.050684902460779994
[Epoch 4, Batch 900] loss: 0.06322638962010388
[Epoch 4, Batch 1000] loss: 0.07379991196445189
[Epoch 4, Batch 1100] loss: 0.06733295246143825
[Epoch 4, Batch 1200] loss: 0.05371429637714755
[Epoch 4, Batch 1300] loss: 0.05291539168683812
[Epoch 4, Batch 1400] loss: 0.056610845344839615
[Epoch 4, Batch 1500] loss: 0.05533910755999386
[Epoch 4, Batch 1600] loss: 0.05818152619234752
[Epoch 4, Batch 1700] loss: 0.04695462042815052
[Epoch 4, Batch 1800] loss: 0.06096847288892605
[Epoch 4, Batch 1900] loss: 0.07381030025077052
[Epoch 4, Batch 2000] loss: 0.07831764601287432
[Epoch 4, Batch 2100] loss: 0.0546907992567867
[Epoch 4, Batch 2200] loss: 0.07741436465410516
[Epoch 4, Batch 2300] loss: 0.06467131073586643
[Epoch 4, Batch 2400] loss: 0.05992287582193967
[Epoch 4, Batch 2500] loss: 0.04194942920352332
[Epoch 4, Batch 2600] loss: 0.062034120035532395
[Epoch 4, Batch 2700] loss: 0.06603875233704457
[Epoch 4, Batch 2800] loss: 0.07301155322929845
[Epoch 4, Batch 2900] loss: 0.07274923574121203
[Epoch 4, Batch 3000] loss: 0.06791184150788468
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0712
Validation Accuracy: 0.9777
Overfitting: 0.0712
Best model saved at epoch 4 with validation loss: 0.0712
[Epoch 5, Batch 100] loss: 0.04001734053890686
[Epoch 5, Batch 200] loss: 0.053342086655902676
[Epoch 5, Batch 300] loss: 0.06382038443349301
[Epoch 5, Batch 400] loss: 0.04725882836821256
[Epoch 5, Batch 500] loss: 0.049688644706620835
[Epoch 5, Batch 600] loss: 0.04811351646785624
[Epoch 5, Batch 700] loss: 0.05814296706783353
[Epoch 5, Batch 800] loss: 0.054885423447703946
[Epoch 5, Batch 900] loss: 0.050921711051487364
[Epoch 5, Batch 1000] loss: 0.05517613912874367
[Epoch 5, Batch 1100] loss: 0.06641021174960769
[Epoch 5, Batch 1200] loss: 0.049493744145147504
[Epoch 5, Batch 1300] loss: 0.035523858455999285
[Epoch 5, Batch 1400] loss: 0.049347311949240975
[Epoch 5, Batch 1500] loss: 0.05673655603415682
[Epoch 5, Batch 1600] loss: 0.05666884120873874
[Epoch 5, Batch 1700] loss: 0.059731020130566324
[Epoch 5, Batch 1800] loss: 0.045630729199037885
[Epoch 5, Batch 1900] loss: 0.04681187844544184
[Epoch 5, Batch 2000] loss: 0.04995889095327584
[Epoch 5, Batch 2100] loss: 0.05009495508216787
[Epoch 5, Batch 2200] loss: 0.04782176255481318
[Epoch 5, Batch 2300] loss: 0.0651969175049453
[Epoch 5, Batch 2400] loss: 0.04067060681278235
[Epoch 5, Batch 2500] loss: 0.03769026476235013
[Epoch 5, Batch 2600] loss: 0.0566837937568198
[Epoch 5, Batch 2700] loss: 0.0499833766388474
[Epoch 5, Batch 2800] loss: 0.044357258057571014
[Epoch 5, Batch 2900] loss: 0.041459640968823805
[Epoch 5, Batch 3000] loss: 0.06253496213452309
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0625
Validation Accuracy: 0.9798
Overfitting: 0.0625
Best model saved at epoch 5 with validation loss: 0.0625
[Epoch 6, Batch 100] loss: 0.05686964514839929
[Epoch 6, Batch 200] loss: 0.033669422814564316
[Epoch 6, Batch 300] loss: 0.04922041219731909
[Epoch 6, Batch 400] loss: 0.033622542823795815
[Epoch 6, Batch 500] loss: 0.03608627479203278
[Epoch 6, Batch 600] loss: 0.05899900630873162
[Epoch 6, Batch 700] loss: 0.03589119800162734
[Epoch 6, Batch 800] loss: 0.04549483321199659
[Epoch 6, Batch 900] loss: 0.035363875347102294
[Epoch 6, Batch 1000] loss: 0.05148181425407529
[Epoch 6, Batch 1100] loss: 0.039001786757289665
[Epoch 6, Batch 1200] loss: 0.04568379897900741
[Epoch 6, Batch 1300] loss: 0.04124786318076076
[Epoch 6, Batch 1400] loss: 0.037565798482391985
[Epoch 6, Batch 1500] loss: 0.03989585505478317
[Epoch 6, Batch 1600] loss: 0.05250895279867109
[Epoch 6, Batch 1700] loss: 0.04444525506347418
[Epoch 6, Batch 1800] loss: 0.04097830886079464
[Epoch 6, Batch 1900] loss: 0.044596494727302344
[Epoch 6, Batch 2000] loss: 0.03943644007587863
[Epoch 6, Batch 2100] loss: 0.05094024997808447
[Epoch 6, Batch 2200] loss: 0.056564601099817084
[Epoch 6, Batch 2300] loss: 0.047017852920107545
[Epoch 6, Batch 2400] loss: 0.042150377360812855
[Epoch 6, Batch 2500] loss: 0.04421421481994912
[Epoch 6, Batch 2600] loss: 0.04397623257391388
[Epoch 6, Batch 2700] loss: 0.04697222635615617
[Epoch 6, Batch 2800] loss: 0.03632191268232418
[Epoch 6, Batch 2900] loss: 0.03751686137286015
[Epoch 6, Batch 3000] loss: 0.0433364185935352
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9852
Overfitting: 0.0504
Best model saved at epoch 6 with validation loss: 0.0504
[Epoch 7, Batch 100] loss: 0.035855960959452204
[Epoch 7, Batch 200] loss: 0.042352211137185805
[Epoch 7, Batch 300] loss: 0.0320958311369759
[Epoch 7, Batch 400] loss: 0.02277136069955304
[Epoch 7, Batch 500] loss: 0.03599419731312082
[Epoch 7, Batch 600] loss: 0.03660918480127293
[Epoch 7, Batch 700] loss: 0.02539345787023194
[Epoch 7, Batch 800] loss: 0.03557876160426531
[Epoch 7, Batch 900] loss: 0.037345139638055115
[Epoch 7, Batch 1000] loss: 0.035956650553416694
[Epoch 7, Batch 1100] loss: 0.02542741898316308
[Epoch 7, Batch 1200] loss: 0.038542500655312326
[Epoch 7, Batch 1300] loss: 0.035038583817586184
[Epoch 7, Batch 1400] loss: 0.037891018155496566
[Epoch 7, Batch 1500] loss: 0.031219204938824987
[Epoch 7, Batch 1600] loss: 0.04483913937030593
[Epoch 7, Batch 1700] loss: 0.030915608690556838
[Epoch 7, Batch 1800] loss: 0.0259216959701007
[Epoch 7, Batch 1900] loss: 0.049354322836443316
[Epoch 7, Batch 2000] loss: 0.0455437501106644
[Epoch 7, Batch 2100] loss: 0.038823980013257826
[Epoch 7, Batch 2200] loss: 0.03484591170083149
[Epoch 7, Batch 2300] loss: 0.03255252618182567
[Epoch 7, Batch 2400] loss: 0.030341363533952972
[Epoch 7, Batch 2500] loss: 0.05120740392812877
[Epoch 7, Batch 2600] loss: 0.04193771624792134
[Epoch 7, Batch 2700] loss: 0.05071199684854946
[Epoch 7, Batch 2800] loss: 0.036896283340247464
[Epoch 7, Batch 2900] loss: 0.0363375618030841
[Epoch 7, Batch 3000] loss: 0.038366726731474045
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0555
Validation Accuracy: 0.9832
Overfitting: 0.0555
[Epoch 8, Batch 100] loss: 0.027862437862204388
[Epoch 8, Batch 200] loss: 0.03412348522891989
[Epoch 8, Batch 300] loss: 0.025944009608210764
[Epoch 8, Batch 400] loss: 0.027216618826350895
[Epoch 8, Batch 500] loss: 0.022842495648947077
[Epoch 8, Batch 600] loss: 0.020643581239273772
[Epoch 8, Batch 700] loss: 0.018953180816752138
[Epoch 8, Batch 800] loss: 0.04666912178119673
[Epoch 8, Batch 900] loss: 0.03377732246779488
[Epoch 8, Batch 1000] loss: 0.02580138349228946
[Epoch 8, Batch 1100] loss: 0.030366121511760866
[Epoch 8, Batch 1200] loss: 0.0209524738500113
[Epoch 8, Batch 1300] loss: 0.03708810103042197
[Epoch 8, Batch 1400] loss: 0.031368410784489244
[Epoch 8, Batch 1500] loss: 0.03764474316943961
[Epoch 8, Batch 1600] loss: 0.025027812543994513
[Epoch 8, Batch 1700] loss: 0.041162987164279914
[Epoch 8, Batch 1800] loss: 0.019943672520894323
[Epoch 8, Batch 1900] loss: 0.03386897343232704
[Epoch 8, Batch 2000] loss: 0.019927946092939238
[Epoch 8, Batch 2100] loss: 0.02070979078362143
[Epoch 8, Batch 2200] loss: 0.042676567897215134
[Epoch 8, Batch 2300] loss: 0.052227600665937644
[Epoch 8, Batch 2400] loss: 0.0335516857338007
[Epoch 8, Batch 2500] loss: 0.023733216932596404
[Epoch 8, Batch 2600] loss: 0.03070851304786629
[Epoch 8, Batch 2700] loss: 0.039532406286271
[Epoch 8, Batch 2800] loss: 0.03163340021113981
[Epoch 8, Batch 2900] loss: 0.04400308605734608
[Epoch 8, Batch 3000] loss: 0.025365580248326296
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9843
Overfitting: 0.0519
[Epoch 9, Batch 100] loss: 0.018996714310633253
[Epoch 9, Batch 200] loss: 0.02991102443280397
[Epoch 9, Batch 300] loss: 0.01801817229046719
[Epoch 9, Batch 400] loss: 0.017558982872833438
[Epoch 9, Batch 500] loss: 0.02080909889220493
[Epoch 9, Batch 600] loss: 0.030827218405829627
[Epoch 9, Batch 700] loss: 0.020850961298565382
[Epoch 9, Batch 800] loss: 0.021520689106073406
[Epoch 9, Batch 900] loss: 0.025755951986211584
[Epoch 9, Batch 1000] loss: 0.03094548322274932
[Epoch 9, Batch 1100] loss: 0.03178437315760675
[Epoch 9, Batch 1200] loss: 0.020247165723849322
[Epoch 9, Batch 1300] loss: 0.02332861965012853
[Epoch 9, Batch 1400] loss: 0.01980366440890066
[Epoch 9, Batch 1500] loss: 0.04038335308709065
[Epoch 9, Batch 1600] loss: 0.03354839948147856
[Epoch 9, Batch 1700] loss: 0.029946232960210182
[Epoch 9, Batch 1800] loss: 0.014611964952782728
[Epoch 9, Batch 1900] loss: 0.027539509171328972
[Epoch 9, Batch 2000] loss: 0.021649318866875548
[Epoch 9, Batch 2100] loss: 0.023033368679462
[Epoch 9, Batch 2200] loss: 0.02487093578980421
[Epoch 9, Batch 2300] loss: 0.030708386601991152
[Epoch 9, Batch 2400] loss: 0.025382317056355533
[Epoch 9, Batch 2500] loss: 0.03739503848075401
[Epoch 9, Batch 2600] loss: 0.0251196622632051
[Epoch 9, Batch 2700] loss: 0.02143953503033117
[Epoch 9, Batch 2800] loss: 0.019639934364804504
[Epoch 9, Batch 2900] loss: 0.03090600224000809
[Epoch 9, Batch 3000] loss: 0.02520226498221746
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9844
Overfitting: 0.0512
[Epoch 10, Batch 100] loss: 0.031146839561697563
[Epoch 10, Batch 200] loss: 0.022315890601021238
[Epoch 10, Batch 300] loss: 0.022620896413263834
[Epoch 10, Batch 400] loss: 0.02607623673909984
[Epoch 10, Batch 500] loss: 0.012724736933814712
[Epoch 10, Batch 600] loss: 0.017869620239980576
[Epoch 10, Batch 700] loss: 0.01939154920681176
[Epoch 10, Batch 800] loss: 0.01652824048316688
[Epoch 10, Batch 900] loss: 0.02935867098347444
[Epoch 10, Batch 1000] loss: 0.02761773567121054
[Epoch 10, Batch 1100] loss: 0.02482299969302403
[Epoch 10, Batch 1200] loss: 0.014328728802065599
[Epoch 10, Batch 1300] loss: 0.023300015527929645
[Epoch 10, Batch 1400] loss: 0.02181129025608243
[Epoch 10, Batch 1500] loss: 0.025368597517408487
[Epoch 10, Batch 1600] loss: 0.02949737216145877
[Epoch 10, Batch 1700] loss: 0.025648108028199203
[Epoch 10, Batch 1800] loss: 0.022296068542054855
[Epoch 10, Batch 1900] loss: 0.018260327043317374
[Epoch 10, Batch 2000] loss: 0.015993821284282603
[Epoch 10, Batch 2100] loss: 0.025445140068623005
[Epoch 10, Batch 2200] loss: 0.020867620286589953
[Epoch 10, Batch 2300] loss: 0.022014247592378525
[Epoch 10, Batch 2400] loss: 0.02127765519384411
[Epoch 10, Batch 2500] loss: 0.026589673846392544
[Epoch 10, Batch 2600] loss: 0.015101411897740035
[Epoch 10, Batch 2700] loss: 0.01700377869674412
[Epoch 10, Batch 2800] loss: 0.017394172102958693
[Epoch 10, Batch 2900] loss: 0.023961522959034483
[Epoch 10, Batch 3000] loss: 0.03388926515915955
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9842
Overfitting: 0.0570
[Epoch 11, Batch 100] loss: 0.009871935859810037
[Epoch 11, Batch 200] loss: 0.01112282880724706
[Epoch 11, Batch 300] loss: 0.02035660936624481
[Epoch 11, Batch 400] loss: 0.01522785461876083
[Epoch 11, Batch 500] loss: 0.02329742759815417
[Epoch 11, Batch 600] loss: 0.02018312402849915
[Epoch 11, Batch 700] loss: 0.01245210646342457
[Epoch 11, Batch 800] loss: 0.01632831078255549
[Epoch 11, Batch 900] loss: 0.008048269004921166
[Epoch 11, Batch 1000] loss: 0.01738973331888701
[Epoch 11, Batch 1100] loss: 0.02180256225830817
[Epoch 11, Batch 1200] loss: 0.011642778756504412
[Epoch 11, Batch 1300] loss: 0.01477191382966339
[Epoch 11, Batch 1400] loss: 0.031130261478756437
[Epoch 11, Batch 1500] loss: 0.026682255708947195
[Epoch 11, Batch 1600] loss: 0.024998587717600457
[Epoch 11, Batch 1700] loss: 0.023074292234159657
[Epoch 11, Batch 1800] loss: 0.027652802373240776
[Epoch 11, Batch 1900] loss: 0.024211299666822016
[Epoch 11, Batch 2000] loss: 0.017730630796759215
[Epoch 11, Batch 2100] loss: 0.026960989674789743
[Epoch 11, Batch 2200] loss: 0.016508886598458047
[Epoch 11, Batch 2300] loss: 0.0186528687048758
[Epoch 11, Batch 2400] loss: 0.034939418072535776
[Epoch 11, Batch 2500] loss: 0.01982479522077483
[Epoch 11, Batch 2600] loss: 0.019892651172594925
[Epoch 11, Batch 2700] loss: 0.02471895728058371
[Epoch 11, Batch 2800] loss: 0.018301064339229924
[Epoch 11, Batch 2900] loss: 0.01756719546065142
[Epoch 11, Batch 3000] loss: 0.01924116669328214
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9872
Overfitting: 0.0457
Best model saved at epoch 11 with validation loss: 0.0457
[Epoch 12, Batch 100] loss: 0.01411474667424045
[Epoch 12, Batch 200] loss: 0.015686490172229242
[Epoch 12, Batch 300] loss: 0.024291136517458654
[Epoch 12, Batch 400] loss: 0.01291653949108877
[Epoch 12, Batch 500] loss: 0.01637086951341189
[Epoch 12, Batch 600] loss: 0.009928324736956711
[Epoch 12, Batch 700] loss: 0.013904833891238012
[Epoch 12, Batch 800] loss: 0.009023502787676989
[Epoch 12, Batch 900] loss: 0.016611163217457942
[Epoch 12, Batch 1000] loss: 0.012391474593932798
[Epoch 12, Batch 1100] loss: 0.008381269450474065
[Epoch 12, Batch 1200] loss: 0.014202089726513805
[Epoch 12, Batch 1300] loss: 0.01608899953328546
[Epoch 12, Batch 1400] loss: 0.01618083430691513
[Epoch 12, Batch 1500] loss: 0.010884936900411049
[Epoch 12, Batch 1600] loss: 0.01689552302278116
[Epoch 12, Batch 1700] loss: 0.017161369185614603
[Epoch 12, Batch 1800] loss: 0.010582241091597097
[Epoch 12, Batch 1900] loss: 0.020410249498927443
[Epoch 12, Batch 2000] loss: 0.021265998129783838
[Epoch 12, Batch 2100] loss: 0.013604282871528994
[Epoch 12, Batch 2200] loss: 0.028681756198720904
[Epoch 12, Batch 2300] loss: 0.01568950106966895
[Epoch 12, Batch 2400] loss: 0.020933186571710394
[Epoch 12, Batch 2500] loss: 0.019494685975078026
[Epoch 12, Batch 2600] loss: 0.018125902753704393
[Epoch 12, Batch 2700] loss: 0.017418620972293866
[Epoch 12, Batch 2800] loss: 0.012805796610728067
[Epoch 12, Batch 2900] loss: 0.024248044658270372
[Epoch 12, Batch 3000] loss: 0.02234442282353484
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9863
Overfitting: 0.0459
[Epoch 13, Batch 100] loss: 0.013800560339604999
[Epoch 13, Batch 200] loss: 0.011464670286059117
[Epoch 13, Batch 300] loss: 0.00993721080105388
[Epoch 13, Batch 400] loss: 0.01048582782590529
[Epoch 13, Batch 500] loss: 0.01974416087494319
[Epoch 13, Batch 600] loss: 0.011112326279794615
[Epoch 13, Batch 700] loss: 0.02399755706490396
[Epoch 13, Batch 800] loss: 0.01594971162768161
[Epoch 13, Batch 900] loss: 0.01979314517986495
[Epoch 13, Batch 1000] loss: 0.012462117770446639
[Epoch 13, Batch 1100] loss: 0.01612145149414573
[Epoch 13, Batch 1200] loss: 0.009723632496461505
[Epoch 13, Batch 1300] loss: 0.01641423862796728
[Epoch 13, Batch 1400] loss: 0.012493377308965136
[Epoch 13, Batch 1500] loss: 0.0062272760980340534
[Epoch 13, Batch 1600] loss: 0.020144021818514376
[Epoch 13, Batch 1700] loss: 0.017823715715521757
[Epoch 13, Batch 1800] loss: 0.02041994164526841
[Epoch 13, Batch 1900] loss: 0.013894495642684888
[Epoch 13, Batch 2000] loss: 0.008741839246213204
[Epoch 13, Batch 2100] loss: 0.0097599498281852
[Epoch 13, Batch 2200] loss: 0.013176612221768665
[Epoch 13, Batch 2300] loss: 0.0213886916208412
[Epoch 13, Batch 2400] loss: 0.01925134718805566
[Epoch 13, Batch 2500] loss: 0.020644353441784915
[Epoch 13, Batch 2600] loss: 0.010524932584303315
[Epoch 13, Batch 2700] loss: 0.01644842446307848
[Epoch 13, Batch 2800] loss: 0.015419386898702214
[Epoch 13, Batch 2900] loss: 0.015111588689032942
[Epoch 13, Batch 3000] loss: 0.01457441941010984
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9876
Overfitting: 0.0453
Best model saved at epoch 13 with validation loss: 0.0453
[Epoch 14, Batch 100] loss: 0.010192386714661552
[Epoch 14, Batch 200] loss: 0.008832380206058588
[Epoch 14, Batch 300] loss: 0.010119705406441425
[Epoch 14, Batch 400] loss: 0.007694266567659725
[Epoch 14, Batch 500] loss: 0.007606621621862359
[Epoch 14, Batch 600] loss: 0.00629692599153259
[Epoch 14, Batch 700] loss: 0.01051756258981186
[Epoch 14, Batch 800] loss: 0.0074766872007194255
[Epoch 14, Batch 900] loss: 0.017554010917410778
[Epoch 14, Batch 1000] loss: 0.022815511074004462
[Epoch 14, Batch 1100] loss: 0.019639342022273923
[Epoch 14, Batch 1200] loss: 0.014969638416878296
[Epoch 14, Batch 1300] loss: 0.010279699140473894
[Epoch 14, Batch 1400] loss: 0.012602972802242221
[Epoch 14, Batch 1500] loss: 0.009173770153056466
[Epoch 14, Batch 1600] loss: 0.010614731691689486
[Epoch 14, Batch 1700] loss: 0.016178006394347903
[Epoch 14, Batch 1800] loss: 0.01082396308492207
[Epoch 14, Batch 1900] loss: 0.00616202642625467
[Epoch 14, Batch 2000] loss: 0.00797545560522849
[Epoch 14, Batch 2100] loss: 0.015170922779684588
[Epoch 14, Batch 2200] loss: 0.016738263450197337
[Epoch 14, Batch 2300] loss: 0.020389493395314276
[Epoch 14, Batch 2400] loss: 0.013968117543161043
[Epoch 14, Batch 2500] loss: 0.010080277714414478
[Epoch 14, Batch 2600] loss: 0.018976035524459575
[Epoch 14, Batch 2700] loss: 0.019249673877839088
[Epoch 14, Batch 2800] loss: 0.011241580911423625
[Epoch 14, Batch 2900] loss: 0.012488611529151967
[Epoch 14, Batch 3000] loss: 0.015281977726681361
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9867
Overfitting: 0.0512
[Epoch 15, Batch 100] loss: 0.012231855320042086
[Epoch 15, Batch 200] loss: 0.008752204215033999
[Epoch 15, Batch 300] loss: 0.0067292136148944335
[Epoch 15, Batch 400] loss: 0.010383920311996917
[Epoch 15, Batch 500] loss: 0.005144909858481697
[Epoch 15, Batch 600] loss: 0.008865250541491605
[Epoch 15, Batch 700] loss: 0.009288449950709037
[Epoch 15, Batch 800] loss: 0.01634246412677385
[Epoch 15, Batch 900] loss: 0.006928016398560431
[Epoch 15, Batch 1000] loss: 0.012977997265109025
[Epoch 15, Batch 1100] loss: 0.012251725415899273
[Epoch 15, Batch 1200] loss: 0.016369899225073824
[Epoch 15, Batch 1300] loss: 0.012686217272348586
[Epoch 15, Batch 1400] loss: 0.00971219920075896
[Epoch 15, Batch 1500] loss: 0.014695659258622982
[Epoch 15, Batch 1600] loss: 0.010249504981657083
[Epoch 15, Batch 1700] loss: 0.0075718431530140155
[Epoch 15, Batch 1800] loss: 0.008473682663143335
[Epoch 15, Batch 1900] loss: 0.005708913440967081
[Epoch 15, Batch 2000] loss: 0.016318511088620653
[Epoch 15, Batch 2100] loss: 0.009933714555454571
[Epoch 15, Batch 2200] loss: 0.009699899984402691
[Epoch 15, Batch 2300] loss: 0.013452187444872834
[Epoch 15, Batch 2400] loss: 0.01059424665244478
[Epoch 15, Batch 2500] loss: 0.017966878740330684
[Epoch 15, Batch 2600] loss: 0.00829204073422261
[Epoch 15, Batch 2700] loss: 0.01609910910075996
[Epoch 15, Batch 2800] loss: 0.01360835944984501
[Epoch 15, Batch 2900] loss: 0.009780063755169977
[Epoch 15, Batch 3000] loss: 0.007793858907689355
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9881
Overfitting: 0.0480
[Epoch 16, Batch 100] loss: 0.00842745907238168
[Epoch 16, Batch 200] loss: 0.008244613708234283
[Epoch 16, Batch 300] loss: 0.0072202259937148485
[Epoch 16, Batch 400] loss: 0.0054341201381953395
[Epoch 16, Batch 500] loss: 0.009926734539603785
[Epoch 16, Batch 600] loss: 0.0057273145569888585
[Epoch 16, Batch 700] loss: 0.010688231750856403
[Epoch 16, Batch 800] loss: 0.007917576519400883
[Epoch 16, Batch 900] loss: 0.00530086568202023
[Epoch 16, Batch 1000] loss: 0.006052370767615116
[Epoch 16, Batch 1100] loss: 0.009457822101148849
[Epoch 16, Batch 1200] loss: 0.009403713104143207
[Epoch 16, Batch 1300] loss: 0.004507382676870293
[Epoch 16, Batch 1400] loss: 0.005906194826377486
[Epoch 16, Batch 1500] loss: 0.009096829593786424
[Epoch 16, Batch 1600] loss: 0.002768801741030984
[Epoch 16, Batch 1700] loss: 0.011125648946685942
[Epoch 16, Batch 1800] loss: 0.013178407941906016
[Epoch 16, Batch 1900] loss: 0.010471587262197773
[Epoch 16, Batch 2000] loss: 0.015851749348080375
[Epoch 16, Batch 2100] loss: 0.008829750652021176
[Epoch 16, Batch 2200] loss: 0.017206941922504482
[Epoch 16, Batch 2300] loss: 0.010603962835721176
[Epoch 16, Batch 2400] loss: 0.016030867957670124
[Epoch 16, Batch 2500] loss: 0.015220502014885824
[Epoch 16, Batch 2600] loss: 0.013405824341004973
[Epoch 16, Batch 2700] loss: 0.008040859907468985
[Epoch 16, Batch 2800] loss: 0.01171201030044358
[Epoch 16, Batch 2900] loss: 0.012172009721202812
[Epoch 16, Batch 3000] loss: 0.006080062945353575
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9878
Overfitting: 0.0500
[Epoch 17, Batch 100] loss: 0.0058271015500668
[Epoch 17, Batch 200] loss: 0.0071200927075415164
[Epoch 17, Batch 300] loss: 0.00799312722141167
[Epoch 17, Batch 400] loss: 0.008571739215385605
[Epoch 17, Batch 500] loss: 0.006740549545608019
[Epoch 17, Batch 600] loss: 0.007250266291584921
[Epoch 17, Batch 700] loss: 0.004964053818589491
[Epoch 17, Batch 800] loss: 0.009235487806329275
[Epoch 17, Batch 900] loss: 0.0028812810634508425
[Epoch 17, Batch 1000] loss: 0.005453802261927194
[Epoch 17, Batch 1100] loss: 0.004695419372746983
[Epoch 17, Batch 1200] loss: 0.005197655543770452
[Epoch 17, Batch 1300] loss: 0.008082839859134765
[Epoch 17, Batch 1400] loss: 0.011084071307209342
[Epoch 17, Batch 1500] loss: 0.0068305582780294576
[Epoch 17, Batch 1600] loss: 0.003889266306055106
[Epoch 17, Batch 1700] loss: 0.010813180624876396
[Epoch 17, Batch 1800] loss: 0.004625898296008017
[Epoch 17, Batch 1900] loss: 0.003266077071446034
[Epoch 17, Batch 2000] loss: 0.006128261778887918
[Epoch 17, Batch 2100] loss: 0.0034081687386583325
[Epoch 17, Batch 2200] loss: 0.004267450488684972
[Epoch 17, Batch 2300] loss: 0.0033992978988169396
[Epoch 17, Batch 2400] loss: 0.009887271716454506
[Epoch 17, Batch 2500] loss: 0.005310836324289312
[Epoch 17, Batch 2600] loss: 0.015620256343993617
[Epoch 17, Batch 2700] loss: 0.011144178369845577
[Epoch 17, Batch 2800] loss: 0.015656537842253328
[Epoch 17, Batch 2900] loss: 0.013571040712586182
[Epoch 17, Batch 3000] loss: 0.010292551478307814
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9868
Overfitting: 0.0524
[Epoch 18, Batch 100] loss: 0.00222313928751646
[Epoch 18, Batch 200] loss: 0.004424321197129757
[Epoch 18, Batch 300] loss: 0.008871183978794762
[Epoch 18, Batch 400] loss: 0.004918625839172819
[Epoch 18, Batch 500] loss: 0.004163891014279671
[Epoch 18, Batch 600] loss: 0.004479305093097991
[Epoch 18, Batch 700] loss: 0.004171647845099642
[Epoch 18, Batch 800] loss: 0.0034944766813532623
[Epoch 18, Batch 900] loss: 0.0034663000630166607
[Epoch 18, Batch 1000] loss: 0.0018023571422941132
[Epoch 18, Batch 1100] loss: 0.0025189898330040704
[Epoch 18, Batch 1200] loss: 0.014298330677643207
[Epoch 18, Batch 1300] loss: 0.007136497632764076
[Epoch 18, Batch 1400] loss: 0.00404041329772781
[Epoch 18, Batch 1500] loss: 0.0025058463164828026
[Epoch 18, Batch 1600] loss: 0.006677189843248926
[Epoch 18, Batch 1700] loss: 0.008861353586717087
[Epoch 18, Batch 1800] loss: 0.008108626549710039
[Epoch 18, Batch 1900] loss: 0.0054078217328208215
[Epoch 18, Batch 2000] loss: 0.0030126345454641523
[Epoch 18, Batch 2100] loss: 0.005846745534508955
[Epoch 18, Batch 2200] loss: 0.008480529380442477
[Epoch 18, Batch 2300] loss: 0.004530596306437928
[Epoch 18, Batch 2400] loss: 0.008498912253762682
[Epoch 18, Batch 2500] loss: 0.0030724480118493602
[Epoch 18, Batch 2600] loss: 0.004526169007410772
[Epoch 18, Batch 2700] loss: 0.006792564484038621
[Epoch 18, Batch 2800] loss: 0.006292779688338896
[Epoch 18, Batch 2900] loss: 0.008215870007113893
[Epoch 18, Batch 3000] loss: 0.020085839523708272
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9868
Overfitting: 0.0554
[Epoch 19, Batch 100] loss: 0.011276657411167434
[Epoch 19, Batch 200] loss: 0.005824637670498305
[Epoch 19, Batch 300] loss: 0.007685727174228987
[Epoch 19, Batch 400] loss: 0.0030899859116675543
[Epoch 19, Batch 500] loss: 0.005440566088730066
[Epoch 19, Batch 600] loss: 0.003527246894309428
[Epoch 19, Batch 700] loss: 0.0027674126723354676
[Epoch 19, Batch 800] loss: 0.0030837809680110697
[Epoch 19, Batch 900] loss: 0.0023810413200817493
[Epoch 19, Batch 1000] loss: 0.011369785172914816
[Epoch 19, Batch 1100] loss: 0.003962524483958987
[Epoch 19, Batch 1200] loss: 0.005576232395221723
[Epoch 19, Batch 1300] loss: 0.005078374643128427
[Epoch 19, Batch 1400] loss: 0.0040668232358041225
[Epoch 19, Batch 1500] loss: 0.0065403451773158846
[Epoch 19, Batch 1600] loss: 0.005610924407565107
[Epoch 19, Batch 1700] loss: 0.005361494781137708
[Epoch 19, Batch 1800] loss: 0.01911288749965479
[Epoch 19, Batch 1900] loss: 0.011865391538865424
[Epoch 19, Batch 2000] loss: 0.007395409886079278
[Epoch 19, Batch 2100] loss: 0.008680923920128408
[Epoch 19, Batch 2200] loss: 0.010968101038023405
[Epoch 19, Batch 2300] loss: 0.010160997971584039
[Epoch 19, Batch 2400] loss: 0.008868473065949728
[Epoch 19, Batch 2500] loss: 0.0038729424297798687
[Epoch 19, Batch 2600] loss: 0.002985398154385166
[Epoch 19, Batch 2700] loss: 0.0055039612432926785
[Epoch 19, Batch 2800] loss: 0.008137443293441605
[Epoch 19, Batch 2900] loss: 0.006086329644317629
[Epoch 19, Batch 3000] loss: 0.012813002309426337
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0578
Validation Accuracy: 0.9866
Overfitting: 0.0578
[Epoch 20, Batch 100] loss: 0.0036653572257483802
[Epoch 20, Batch 200] loss: 0.007918836737811717
[Epoch 20, Batch 300] loss: 0.0038897256208082352
[Epoch 20, Batch 400] loss: 0.00650709563961783
[Epoch 20, Batch 500] loss: 0.0044132304475787976
[Epoch 20, Batch 600] loss: 0.0033403481748825927
[Epoch 20, Batch 700] loss: 0.0045827050469756615
[Epoch 20, Batch 800] loss: 0.003656913979871206
[Epoch 20, Batch 900] loss: 0.006181691176234381
[Epoch 20, Batch 1000] loss: 0.006419134147829481
[Epoch 20, Batch 1100] loss: 0.003757443152904898
[Epoch 20, Batch 1200] loss: 0.001711480456228287
[Epoch 20, Batch 1300] loss: 0.0022012207209743907
[Epoch 20, Batch 1400] loss: 0.0017552638338656835
[Epoch 20, Batch 1500] loss: 0.006566971330237266
[Epoch 20, Batch 1600] loss: 0.003734778305756663
[Epoch 20, Batch 1700] loss: 0.007670643828072343
[Epoch 20, Batch 1800] loss: 0.01093909081655056
[Epoch 20, Batch 1900] loss: 0.011581547446742207
[Epoch 20, Batch 2000] loss: 0.006901172515216558
[Epoch 20, Batch 2100] loss: 0.0035089331434005546
[Epoch 20, Batch 2200] loss: 0.0024198642076305532
[Epoch 20, Batch 2300] loss: 0.009495164525277459
[Epoch 20, Batch 2400] loss: 0.0033523908750434828
[Epoch 20, Batch 2500] loss: 0.003084090243615378
[Epoch 20, Batch 2600] loss: 0.011180352388389565
[Epoch 20, Batch 2700] loss: 0.0031647410713361523
[Epoch 20, Batch 2800] loss: 0.005036610116190729
[Epoch 20, Batch 2900] loss: 0.01793814749751846
[Epoch 20, Batch 3000] loss: 0.00642472424774212
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9880
Overfitting: 0.0515
[Epoch 21, Batch 100] loss: 0.002276517133063578
[Epoch 21, Batch 200] loss: 0.0028451760411519443
[Epoch 21, Batch 300] loss: 0.002357731246668209
[Epoch 21, Batch 400] loss: 0.0013472712062474557
[Epoch 21, Batch 500] loss: 0.003377512378982601
[Epoch 21, Batch 600] loss: 0.002733251262361591
[Epoch 21, Batch 700] loss: 0.0018351207373102341
[Epoch 21, Batch 800] loss: 0.0030377808198461765
[Epoch 21, Batch 900] loss: 0.0018846547634194621
[Epoch 21, Batch 1000] loss: 0.0018010178531457654
[Epoch 21, Batch 1100] loss: 0.004351001712741152
[Epoch 21, Batch 1200] loss: 0.003552765020357356
[Epoch 21, Batch 1300] loss: 0.003795355673667018
[Epoch 21, Batch 1400] loss: 0.003939922563779419
[Epoch 21, Batch 1500] loss: 0.0038246254466758954
[Epoch 21, Batch 1600] loss: 0.005041781309300291
[Epoch 21, Batch 1700] loss: 0.0043037079961897005
[Epoch 21, Batch 1800] loss: 0.004004062423073265
[Epoch 21, Batch 1900] loss: 0.006583036546737162
[Epoch 21, Batch 2000] loss: 0.003151855853249117
[Epoch 21, Batch 2100] loss: 0.003956064453008139
[Epoch 21, Batch 2200] loss: 0.00792396256932534
[Epoch 21, Batch 2300] loss: 0.0026804476938696096
[Epoch 21, Batch 2400] loss: 0.0064820526851713115
[Epoch 21, Batch 2500] loss: 0.004244480296879374
[Epoch 21, Batch 2600] loss: 0.026882955175821906
[Epoch 21, Batch 2700] loss: 0.012701825049774983
[Epoch 21, Batch 2800] loss: 0.0025179365495694127
[Epoch 21, Batch 2900] loss: 0.005378201530807019
[Epoch 21, Batch 3000] loss: 0.0038831319319396584
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9874
Overfitting: 0.0519
[Epoch 22, Batch 100] loss: 0.0032013472689686752
[Epoch 22, Batch 200] loss: 0.0026885525814827815
[Epoch 22, Batch 300] loss: 0.0023712867414644734
[Epoch 22, Batch 400] loss: 0.002405919879587373
[Epoch 22, Batch 500] loss: 0.0015685631554853785
[Epoch 22, Batch 600] loss: 0.0015073615733444967
[Epoch 22, Batch 700] loss: 0.003964339106477155
[Epoch 22, Batch 800] loss: 0.006384023423570966
[Epoch 22, Batch 900] loss: 0.00691943914992919
[Epoch 22, Batch 1000] loss: 0.003581129123108795
[Epoch 22, Batch 1100] loss: 0.00488481163076358
[Epoch 22, Batch 1200] loss: 0.006378348017532858
[Epoch 22, Batch 1300] loss: 0.007691360461646468
[Epoch 22, Batch 1400] loss: 0.004816458174221339
[Epoch 22, Batch 1500] loss: 0.004016290759967944
[Epoch 22, Batch 1600] loss: 0.010228611273219883
[Epoch 22, Batch 1700] loss: 0.009435797446567449
[Epoch 22, Batch 1800] loss: 0.002991560680998191
[Epoch 22, Batch 1900] loss: 0.005616314034346033
[Epoch 22, Batch 2000] loss: 0.003470169390085971
[Epoch 22, Batch 2100] loss: 0.005795496853189661
[Epoch 22, Batch 2200] loss: 0.002278124267295425
[Epoch 22, Batch 2300] loss: 0.002053194804659597
[Epoch 22, Batch 2400] loss: 0.005801786393797812
[Epoch 22, Batch 2500] loss: 0.003537326807766732
[Epoch 22, Batch 2600] loss: 0.009994585826493676
[Epoch 22, Batch 2700] loss: 0.002507440764524631
[Epoch 22, Batch 2800] loss: 0.0019066167515222787
[Epoch 22, Batch 2900] loss: 0.008606355223847686
[Epoch 22, Batch 3000] loss: 0.006852365938142952
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0565
Validation Accuracy: 0.9868
Overfitting: 0.0565
[Epoch 23, Batch 100] loss: 0.0061274856335211325
[Epoch 23, Batch 200] loss: 0.0014449115407489188
[Epoch 23, Batch 300] loss: 0.0011609092207004324
[Epoch 23, Batch 400] loss: 0.0032928704529879838
[Epoch 23, Batch 500] loss: 0.0026898572419440823
[Epoch 23, Batch 600] loss: 0.004155607701749204
[Epoch 23, Batch 700] loss: 0.002216804136982091
[Epoch 23, Batch 800] loss: 0.0012443073126530634
[Epoch 23, Batch 900] loss: 0.0015600326971932077
[Epoch 23, Batch 1000] loss: 0.0012709987548572598
[Epoch 23, Batch 1100] loss: 0.002291511809886799
[Epoch 23, Batch 1200] loss: 0.005390592863778068
[Epoch 23, Batch 1300] loss: 0.0016001161171567445
[Epoch 23, Batch 1400] loss: 0.0017183343324006727
[Epoch 23, Batch 1500] loss: 0.004127006218799352
[Epoch 23, Batch 1600] loss: 0.0020579046415752345
[Epoch 23, Batch 1700] loss: 0.0024441150557867174
[Epoch 23, Batch 1800] loss: 0.0014643133041981572
[Epoch 23, Batch 1900] loss: 0.0020144729132158547
[Epoch 23, Batch 2000] loss: 0.001279585149810991
[Epoch 23, Batch 2100] loss: 0.002910598248506062
[Epoch 23, Batch 2200] loss: 0.007879989889585205
[Epoch 23, Batch 2300] loss: 0.0012720076306356987
[Epoch 23, Batch 2400] loss: 0.004237654191206275
[Epoch 23, Batch 2500] loss: 0.0023476737380806866
[Epoch 23, Batch 2600] loss: 0.0023894799415614364
[Epoch 23, Batch 2700] loss: 0.00207039417053565
[Epoch 23, Batch 2800] loss: 0.002651622501502118
[Epoch 23, Batch 2900] loss: 0.002006183180772041
[Epoch 23, Batch 3000] loss: 0.00182516377876766
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9891
Overfitting: 0.0508
[Epoch 24, Batch 100] loss: 0.0014208016024985426
[Epoch 24, Batch 200] loss: 0.0014506955263725275
[Epoch 24, Batch 300] loss: 0.0008672621682313774
[Epoch 24, Batch 400] loss: 0.0010949503738707732
[Epoch 24, Batch 500] loss: 0.0013292155705028107
[Epoch 24, Batch 600] loss: 0.0018215987758311769
[Epoch 24, Batch 700] loss: 0.0015078834745802538
[Epoch 24, Batch 800] loss: 0.0019222360033456453
[Epoch 24, Batch 900] loss: 0.0012586350078083797
[Epoch 24, Batch 1000] loss: 0.0007553669801009733
[Epoch 24, Batch 1100] loss: 0.003865671005243989
[Epoch 24, Batch 1200] loss: 0.0013838630448924506
[Epoch 24, Batch 1300] loss: 0.0009365593763715197
[Epoch 24, Batch 1400] loss: 0.0011229861506193827
[Epoch 24, Batch 1500] loss: 0.003999821092643288
[Epoch 24, Batch 1600] loss: 0.00474609260274633
[Epoch 24, Batch 1700] loss: 0.0016667789842676939
[Epoch 24, Batch 1800] loss: 0.0010389917635043133
[Epoch 24, Batch 1900] loss: 0.002295362210273595
[Epoch 24, Batch 2000] loss: 0.003254575371276616
[Epoch 24, Batch 2100] loss: 0.0038620400710669854
[Epoch 24, Batch 2200] loss: 0.0051862611329242725
[Epoch 24, Batch 2300] loss: 0.002072485596567759
[Epoch 24, Batch 2400] loss: 0.0029049310516433024
[Epoch 24, Batch 2500] loss: 0.002486233861893652
[Epoch 24, Batch 2600] loss: 0.004294216772561868
[Epoch 24, Batch 2700] loss: 0.010395743475767745
[Epoch 24, Batch 2800] loss: 0.0011538381036999112
[Epoch 24, Batch 2900] loss: 0.003719680629161246
[Epoch 24, Batch 3000] loss: 0.005187881009020146
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0669
Validation Accuracy: 0.9858
Overfitting: 0.0669
Fold 3 validation loss: 0.0669
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2951974749565123
[Epoch 1, Batch 200] loss: 2.2546332764625547
[Epoch 1, Batch 300] loss: 2.0883195984363554
[Epoch 1, Batch 400] loss: 1.3662120169401168
[Epoch 1, Batch 500] loss: 0.7153055101633072
[Epoch 1, Batch 600] loss: 0.5204652436077595
[Epoch 1, Batch 700] loss: 0.49627041481435297
[Epoch 1, Batch 800] loss: 0.3955142147839069
[Epoch 1, Batch 900] loss: 0.3665167328715324
[Epoch 1, Batch 1000] loss: 0.32422813534736633
[Epoch 1, Batch 1100] loss: 0.302802917342633
[Epoch 1, Batch 1200] loss: 0.29684648975729944
[Epoch 1, Batch 1300] loss: 0.24800822470337153
[Epoch 1, Batch 1400] loss: 0.22464630065485836
[Epoch 1, Batch 1500] loss: 0.23063646629452705
[Epoch 1, Batch 1600] loss: 0.22450242687016725
[Epoch 1, Batch 1700] loss: 0.1821302768215537
[Epoch 1, Batch 1800] loss: 0.2066450992319733
[Epoch 1, Batch 1900] loss: 0.20774481299798936
[Epoch 1, Batch 2000] loss: 0.19933222166262568
[Epoch 1, Batch 2100] loss: 0.20756236722692847
[Epoch 1, Batch 2200] loss: 0.17221615101210774
[Epoch 1, Batch 2300] loss: 0.1311036368086934
[Epoch 1, Batch 2400] loss: 0.1324245863314718
[Epoch 1, Batch 2500] loss: 0.1448934968141839
[Epoch 1, Batch 2600] loss: 0.16045044511556625
[Epoch 1, Batch 2700] loss: 0.1472544558160007
[Epoch 1, Batch 2800] loss: 0.17789484797976912
[Epoch 1, Batch 2900] loss: 0.15093537568114698
[Epoch 1, Batch 3000] loss: 0.13177372773643584
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1292
Validation Accuracy: 0.9603
Overfitting: 0.1292
Best model saved at epoch 1 with validation loss: 0.1292
[Epoch 2, Batch 100] loss: 0.10764702645130456
[Epoch 2, Batch 200] loss: 0.13195116226561368
[Epoch 2, Batch 300] loss: 0.11014258638489992
[Epoch 2, Batch 400] loss: 0.13948898459784687
[Epoch 2, Batch 500] loss: 0.14438182168174535
[Epoch 2, Batch 600] loss: 0.12268758576828986
[Epoch 2, Batch 700] loss: 0.1208230619947426
[Epoch 2, Batch 800] loss: 0.09622421700507403
[Epoch 2, Batch 900] loss: 0.11196954384678975
[Epoch 2, Batch 1000] loss: 0.113490520354826
[Epoch 2, Batch 1100] loss: 0.10520628311205656
[Epoch 2, Batch 1200] loss: 0.09043033964000642
[Epoch 2, Batch 1300] loss: 0.09047646523220465
[Epoch 2, Batch 1400] loss: 0.12264559256844222
[Epoch 2, Batch 1500] loss: 0.1011846379225608
[Epoch 2, Batch 1600] loss: 0.09789979164022952
[Epoch 2, Batch 1700] loss: 0.0892062161071226
[Epoch 2, Batch 1800] loss: 0.09920772795099765
[Epoch 2, Batch 1900] loss: 0.11058921468211338
[Epoch 2, Batch 2000] loss: 0.08045291817281396
[Epoch 2, Batch 2100] loss: 0.09657078512012958
[Epoch 2, Batch 2200] loss: 0.08161291651194916
[Epoch 2, Batch 2300] loss: 0.09472460846882313
[Epoch 2, Batch 2400] loss: 0.09436420017154887
[Epoch 2, Batch 2500] loss: 0.09247222999343649
[Epoch 2, Batch 2600] loss: 0.0636313087772578
[Epoch 2, Batch 2700] loss: 0.09386643789475783
[Epoch 2, Batch 2800] loss: 0.07374679666711018
[Epoch 2, Batch 2900] loss: 0.08609843687270768
[Epoch 2, Batch 3000] loss: 0.10516768928151578
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0758
Validation Accuracy: 0.9768
Overfitting: 0.0758
Best model saved at epoch 2 with validation loss: 0.0758
[Epoch 3, Batch 100] loss: 0.08451190704014153
[Epoch 3, Batch 200] loss: 0.08261049784952774
[Epoch 3, Batch 300] loss: 0.052323476168094206
[Epoch 3, Batch 400] loss: 0.09643888709833845
[Epoch 3, Batch 500] loss: 0.08508722743019462
[Epoch 3, Batch 600] loss: 0.05819317046902142
[Epoch 3, Batch 700] loss: 0.07207717280602083
[Epoch 3, Batch 800] loss: 0.07269658226985484
[Epoch 3, Batch 900] loss: 0.09385496051050722
[Epoch 3, Batch 1000] loss: 0.05453903162619099
[Epoch 3, Batch 1100] loss: 0.06848007533233613
[Epoch 3, Batch 1200] loss: 0.061465567308478054
[Epoch 3, Batch 1300] loss: 0.059420627186773343
[Epoch 3, Batch 1400] loss: 0.0785450788657181
[Epoch 3, Batch 1500] loss: 0.05728877554880455
[Epoch 3, Batch 1600] loss: 0.07023458455689252
[Epoch 3, Batch 1700] loss: 0.08865484750829637
[Epoch 3, Batch 1800] loss: 0.0644042339909356
[Epoch 3, Batch 1900] loss: 0.07661466744204518
[Epoch 3, Batch 2000] loss: 0.08189785095863045
[Epoch 3, Batch 2100] loss: 0.08777759268064983
[Epoch 3, Batch 2200] loss: 0.07985132649890148
[Epoch 3, Batch 2300] loss: 0.05706493772915564
[Epoch 3, Batch 2400] loss: 0.05509348381543532
[Epoch 3, Batch 2500] loss: 0.057960580236976963
[Epoch 3, Batch 2600] loss: 0.08126236164243891
[Epoch 3, Batch 2700] loss: 0.0654996866628062
[Epoch 3, Batch 2800] loss: 0.05718542637419887
[Epoch 3, Batch 2900] loss: 0.07293637994036545
[Epoch 3, Batch 3000] loss: 0.04840540985460393
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0672
Validation Accuracy: 0.9799
Overfitting: 0.0672
Best model saved at epoch 3 with validation loss: 0.0672
[Epoch 4, Batch 100] loss: 0.045497233248315755
[Epoch 4, Batch 200] loss: 0.07360027682734653
[Epoch 4, Batch 300] loss: 0.05787286195263732
[Epoch 4, Batch 400] loss: 0.06681776603800245
[Epoch 4, Batch 500] loss: 0.04559912121621892
[Epoch 4, Batch 600] loss: 0.06477009786991403
[Epoch 4, Batch 700] loss: 0.055185483868117446
[Epoch 4, Batch 800] loss: 0.04773377938545309
[Epoch 4, Batch 900] loss: 0.05423824385041371
[Epoch 4, Batch 1000] loss: 0.057316949276719244
[Epoch 4, Batch 1100] loss: 0.05722274689818732
[Epoch 4, Batch 1200] loss: 0.05983704319805838
[Epoch 4, Batch 1300] loss: 0.04947647991561098
[Epoch 4, Batch 1400] loss: 0.04377173927612603
[Epoch 4, Batch 1500] loss: 0.03722665427485481
[Epoch 4, Batch 1600] loss: 0.051044508281629535
[Epoch 4, Batch 1700] loss: 0.04821340352413245
[Epoch 4, Batch 1800] loss: 0.06679986845178064
[Epoch 4, Batch 1900] loss: 0.04788679188932292
[Epoch 4, Batch 2000] loss: 0.05562301755649969
[Epoch 4, Batch 2100] loss: 0.059373392543639054
[Epoch 4, Batch 2200] loss: 0.06728106892376673
[Epoch 4, Batch 2300] loss: 0.05123080661869608
[Epoch 4, Batch 2400] loss: 0.06163460171344923
[Epoch 4, Batch 2500] loss: 0.0502057073902688
[Epoch 4, Batch 2600] loss: 0.05680850455421023
[Epoch 4, Batch 2700] loss: 0.057376934534695466
[Epoch 4, Batch 2800] loss: 0.03908903594245203
[Epoch 4, Batch 2900] loss: 0.07519391859415919
[Epoch 4, Batch 3000] loss: 0.05240874872950371
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9835
Overfitting: 0.0548
Best model saved at epoch 4 with validation loss: 0.0548
[Epoch 5, Batch 100] loss: 0.040327883480349554
[Epoch 5, Batch 200] loss: 0.0436716875055572
[Epoch 5, Batch 300] loss: 0.04716966696782038
[Epoch 5, Batch 400] loss: 0.05670496176753659
[Epoch 5, Batch 500] loss: 0.043076364069711416
[Epoch 5, Batch 600] loss: 0.03932477568348986
[Epoch 5, Batch 700] loss: 0.03514966836490203
[Epoch 5, Batch 800] loss: 0.06441117440350354
[Epoch 5, Batch 900] loss: 0.037608998207724655
[Epoch 5, Batch 1000] loss: 0.0436251985738636
[Epoch 5, Batch 1100] loss: 0.052370658672589346
[Epoch 5, Batch 1200] loss: 0.06711782023485284
[Epoch 5, Batch 1300] loss: 0.03576018213178031
[Epoch 5, Batch 1400] loss: 0.050211454860691444
[Epoch 5, Batch 1500] loss: 0.038709448932786474
[Epoch 5, Batch 1600] loss: 0.055286737734277266
[Epoch 5, Batch 1700] loss: 0.05009242131287465
[Epoch 5, Batch 1800] loss: 0.04682007628900465
[Epoch 5, Batch 1900] loss: 0.03957748134445865
[Epoch 5, Batch 2000] loss: 0.0376288416373427
[Epoch 5, Batch 2100] loss: 0.043587667753890856
[Epoch 5, Batch 2200] loss: 0.03747486825566739
[Epoch 5, Batch 2300] loss: 0.04509903583828418
[Epoch 5, Batch 2400] loss: 0.03873822971145273
[Epoch 5, Batch 2500] loss: 0.028767888134898386
[Epoch 5, Batch 2600] loss: 0.031379617543425414
[Epoch 5, Batch 2700] loss: 0.040890037676726936
[Epoch 5, Batch 2800] loss: 0.056661619186925236
[Epoch 5, Batch 2900] loss: 0.05664289642183576
[Epoch 5, Batch 3000] loss: 0.05312539756472688
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0582
Validation Accuracy: 0.9828
Overfitting: 0.0582
[Epoch 6, Batch 100] loss: 0.036550097370054574
[Epoch 6, Batch 200] loss: 0.03166196198711987
[Epoch 6, Batch 300] loss: 0.03214112894114805
[Epoch 6, Batch 400] loss: 0.03765373455826193
[Epoch 6, Batch 500] loss: 0.027938868942146654
[Epoch 6, Batch 600] loss: 0.040620179539255334
[Epoch 6, Batch 700] loss: 0.03854804580274504
[Epoch 6, Batch 800] loss: 0.035229713183289275
[Epoch 6, Batch 900] loss: 0.03281893228224362
[Epoch 6, Batch 1000] loss: 0.040979065457213436
[Epoch 6, Batch 1100] loss: 0.03832210039079655
[Epoch 6, Batch 1200] loss: 0.03950430287513882
[Epoch 6, Batch 1300] loss: 0.03522563432023162
[Epoch 6, Batch 1400] loss: 0.03821834635324194
[Epoch 6, Batch 1500] loss: 0.040074163591489194
[Epoch 6, Batch 1600] loss: 0.04691251144977286
[Epoch 6, Batch 1700] loss: 0.040358958732394964
[Epoch 6, Batch 1800] loss: 0.03250137346200063
[Epoch 6, Batch 1900] loss: 0.0324467575235758
[Epoch 6, Batch 2000] loss: 0.06584056328458246
[Epoch 6, Batch 2100] loss: 0.032830094038217794
[Epoch 6, Batch 2200] loss: 0.04581055214337539
[Epoch 6, Batch 2300] loss: 0.036590596454625486
[Epoch 6, Batch 2400] loss: 0.03221205215289956
[Epoch 6, Batch 2500] loss: 0.04154845529585145
[Epoch 6, Batch 2600] loss: 0.03969580771401524
[Epoch 6, Batch 2700] loss: 0.03145933301289915
[Epoch 6, Batch 2800] loss: 0.03572424578422215
[Epoch 6, Batch 2900] loss: 0.04213143947483331
[Epoch 6, Batch 3000] loss: 0.024944712539290776
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9841
Overfitting: 0.0483
Best model saved at epoch 6 with validation loss: 0.0483
[Epoch 7, Batch 100] loss: 0.01800218222786498
[Epoch 7, Batch 200] loss: 0.03494942747347522
[Epoch 7, Batch 300] loss: 0.028339256988256237
[Epoch 7, Batch 400] loss: 0.024307586769864428
[Epoch 7, Batch 500] loss: 0.02076862516842084
[Epoch 7, Batch 600] loss: 0.04369531960837776
[Epoch 7, Batch 700] loss: 0.028163406017847593
[Epoch 7, Batch 800] loss: 0.03656942859379342
[Epoch 7, Batch 900] loss: 0.03079034947542823
[Epoch 7, Batch 1000] loss: 0.027364127985492814
[Epoch 7, Batch 1100] loss: 0.03864219964401855
[Epoch 7, Batch 1200] loss: 0.021228238746552962
[Epoch 7, Batch 1300] loss: 0.030440137711266288
[Epoch 7, Batch 1400] loss: 0.041017065111154806
[Epoch 7, Batch 1500] loss: 0.0296350847814756
[Epoch 7, Batch 1600] loss: 0.031178402972291224
[Epoch 7, Batch 1700] loss: 0.017380424872608272
[Epoch 7, Batch 1800] loss: 0.036035908731610104
[Epoch 7, Batch 1900] loss: 0.029717390358855483
[Epoch 7, Batch 2000] loss: 0.04333968057515449
[Epoch 7, Batch 2100] loss: 0.03151231367330183
[Epoch 7, Batch 2200] loss: 0.035029755018331346
[Epoch 7, Batch 2300] loss: 0.03894830577381072
[Epoch 7, Batch 2400] loss: 0.021926653994596562
[Epoch 7, Batch 2500] loss: 0.0542629399553698
[Epoch 7, Batch 2600] loss: 0.02665332188218599
[Epoch 7, Batch 2700] loss: 0.03458526341644756
[Epoch 7, Batch 2800] loss: 0.02979317100107437
[Epoch 7, Batch 2900] loss: 0.03250940780038945
[Epoch 7, Batch 3000] loss: 0.035550429928989616
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9845
Overfitting: 0.0474
Best model saved at epoch 7 with validation loss: 0.0474
[Epoch 8, Batch 100] loss: 0.02636311678652419
[Epoch 8, Batch 200] loss: 0.029454348131839652
[Epoch 8, Batch 300] loss: 0.022733591665601124
[Epoch 8, Batch 400] loss: 0.035541845065745294
[Epoch 8, Batch 500] loss: 0.023281893017556284
[Epoch 8, Batch 600] loss: 0.021542170440225165
[Epoch 8, Batch 700] loss: 0.026737649416536443
[Epoch 8, Batch 800] loss: 0.01841657525881601
[Epoch 8, Batch 900] loss: 0.043707682871754513
[Epoch 8, Batch 1000] loss: 0.0171461823694699
[Epoch 8, Batch 1100] loss: 0.016435661735013127
[Epoch 8, Batch 1200] loss: 0.017582209151878487
[Epoch 8, Batch 1300] loss: 0.02843508827572805
[Epoch 8, Batch 1400] loss: 0.03168975920823868
[Epoch 8, Batch 1500] loss: 0.03216202487550618
[Epoch 8, Batch 1600] loss: 0.024485116546420615
[Epoch 8, Batch 1700] loss: 0.03214370817062445
[Epoch 8, Batch 1800] loss: 0.025914060106588296
[Epoch 8, Batch 1900] loss: 0.02480918838555226
[Epoch 8, Batch 2000] loss: 0.029068887609355443
[Epoch 8, Batch 2100] loss: 0.03644911537012376
[Epoch 8, Batch 2200] loss: 0.030792361035128123
[Epoch 8, Batch 2300] loss: 0.03044369055198331
[Epoch 8, Batch 2400] loss: 0.021662269159132847
[Epoch 8, Batch 2500] loss: 0.02924944843907724
[Epoch 8, Batch 2600] loss: 0.02836297140816896
[Epoch 8, Batch 2700] loss: 0.026550704024157313
[Epoch 8, Batch 2800] loss: 0.033169609340984604
[Epoch 8, Batch 2900] loss: 0.02391309357844875
[Epoch 8, Batch 3000] loss: 0.028719309857769985
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9842
Overfitting: 0.0507
[Epoch 9, Batch 100] loss: 0.023650436867537792
[Epoch 9, Batch 200] loss: 0.02649840841339028
[Epoch 9, Batch 300] loss: 0.01818872632989951
[Epoch 9, Batch 400] loss: 0.018575443692316184
[Epoch 9, Batch 500] loss: 0.01881277102678723
[Epoch 9, Batch 600] loss: 0.02259183113274048
[Epoch 9, Batch 700] loss: 0.022413217003631872
[Epoch 9, Batch 800] loss: 0.02732736600773933
[Epoch 9, Batch 900] loss: 0.018471052809109097
[Epoch 9, Batch 1000] loss: 0.027771560025867073
[Epoch 9, Batch 1100] loss: 0.01954834019896225
[Epoch 9, Batch 1200] loss: 0.010703788730570523
[Epoch 9, Batch 1300] loss: 0.02653592453476449
[Epoch 9, Batch 1400] loss: 0.03021706004597945
[Epoch 9, Batch 1500] loss: 0.028499142894870603
[Epoch 9, Batch 1600] loss: 0.0331278878224839
[Epoch 9, Batch 1700] loss: 0.03246997023197764
[Epoch 9, Batch 1800] loss: 0.013801644578888954
[Epoch 9, Batch 1900] loss: 0.0218873306986643
[Epoch 9, Batch 2000] loss: 0.022049007739424267
[Epoch 9, Batch 2100] loss: 0.020983898416197917
[Epoch 9, Batch 2200] loss: 0.019146099863646668
[Epoch 9, Batch 2300] loss: 0.025229292442199947
[Epoch 9, Batch 2400] loss: 0.03493974090053598
[Epoch 9, Batch 2500] loss: 0.0247846511843818
[Epoch 9, Batch 2600] loss: 0.032617333719827
[Epoch 9, Batch 2700] loss: 0.019900647686372393
[Epoch 9, Batch 2800] loss: 0.02181700026849285
[Epoch 9, Batch 2900] loss: 0.026332456684976933
[Epoch 9, Batch 3000] loss: 0.02775385393288161
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0428
Validation Accuracy: 0.9872
Overfitting: 0.0428
Best model saved at epoch 9 with validation loss: 0.0428
[Epoch 10, Batch 100] loss: 0.017015982379962224
[Epoch 10, Batch 200] loss: 0.014103725668173866
[Epoch 10, Batch 300] loss: 0.02551634627452586
[Epoch 10, Batch 400] loss: 0.019575472901851753
[Epoch 10, Batch 500] loss: 0.017632448092463164
[Epoch 10, Batch 600] loss: 0.02843277722458879
[Epoch 10, Batch 700] loss: 0.022620756585765775
[Epoch 10, Batch 800] loss: 0.025477567431589705
[Epoch 10, Batch 900] loss: 0.01805111805530032
[Epoch 10, Batch 1000] loss: 0.017946964349903283
[Epoch 10, Batch 1100] loss: 0.01869940939184744
[Epoch 10, Batch 1200] loss: 0.01714534719918447
[Epoch 10, Batch 1300] loss: 0.017202187983602926
[Epoch 10, Batch 1400] loss: 0.02545258424295753
[Epoch 10, Batch 1500] loss: 0.02777154997387697
[Epoch 10, Batch 1600] loss: 0.030754861621171584
[Epoch 10, Batch 1700] loss: 0.027085465248310358
[Epoch 10, Batch 1800] loss: 0.02195553511439357
[Epoch 10, Batch 1900] loss: 0.030930250239180168
[Epoch 10, Batch 2000] loss: 0.01712141475058161
[Epoch 10, Batch 2100] loss: 0.014525751783839951
[Epoch 10, Batch 2200] loss: 0.015043144115193172
[Epoch 10, Batch 2300] loss: 0.011827302049241553
[Epoch 10, Batch 2400] loss: 0.03487874032520267
[Epoch 10, Batch 2500] loss: 0.014960803274589126
[Epoch 10, Batch 2600] loss: 0.019735612808726728
[Epoch 10, Batch 2700] loss: 0.011059026686871221
[Epoch 10, Batch 2800] loss: 0.021972643590852384
[Epoch 10, Batch 2900] loss: 0.015355358798078669
[Epoch 10, Batch 3000] loss: 0.022511778930565926
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9857
Overfitting: 0.0496
[Epoch 11, Batch 100] loss: 0.01553953964388711
[Epoch 11, Batch 200] loss: 0.019719191113899796
[Epoch 11, Batch 300] loss: 0.016236729561187532
[Epoch 11, Batch 400] loss: 0.01639552276616996
[Epoch 11, Batch 500] loss: 0.01846335562753666
[Epoch 11, Batch 600] loss: 0.018545458139342372
[Epoch 11, Batch 700] loss: 0.01762948815303389
[Epoch 11, Batch 800] loss: 0.012203427111653582
[Epoch 11, Batch 900] loss: 0.02226930842793081
[Epoch 11, Batch 1000] loss: 0.014021390768684796
[Epoch 11, Batch 1100] loss: 0.013311272471955817
[Epoch 11, Batch 1200] loss: 0.02232943881341271
[Epoch 11, Batch 1300] loss: 0.01904222937002487
[Epoch 11, Batch 1400] loss: 0.023419526265060994
[Epoch 11, Batch 1500] loss: 0.016280746736156287
[Epoch 11, Batch 1600] loss: 0.013343829249388364
[Epoch 11, Batch 1700] loss: 0.011362061049076146
[Epoch 11, Batch 1800] loss: 0.01907813443818668
[Epoch 11, Batch 1900] loss: 0.018459329575161974
[Epoch 11, Batch 2000] loss: 0.024467350772720237
[Epoch 11, Batch 2100] loss: 0.012144278174746432
[Epoch 11, Batch 2200] loss: 0.019984249939489017
[Epoch 11, Batch 2300] loss: 0.012443501750203723
[Epoch 11, Batch 2400] loss: 0.027657357473362936
[Epoch 11, Batch 2500] loss: 0.015873672954221547
[Epoch 11, Batch 2600] loss: 0.018071285360420006
[Epoch 11, Batch 2700] loss: 0.021292260399427505
[Epoch 11, Batch 2800] loss: 0.023036609276132367
[Epoch 11, Batch 2900] loss: 0.02967207108917137
[Epoch 11, Batch 3000] loss: 0.017270841058043516
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0424
Validation Accuracy: 0.9866
Overfitting: 0.0424
Best model saved at epoch 11 with validation loss: 0.0424
[Epoch 12, Batch 100] loss: 0.014479688503902252
[Epoch 12, Batch 200] loss: 0.01670770233742587
[Epoch 12, Batch 300] loss: 0.026377094907347784
[Epoch 12, Batch 400] loss: 0.018727409649309266
[Epoch 12, Batch 500] loss: 0.023099474928276322
[Epoch 12, Batch 600] loss: 0.01513979882649437
[Epoch 12, Batch 700] loss: 0.023449325190867967
[Epoch 12, Batch 800] loss: 0.015184104148611368
[Epoch 12, Batch 900] loss: 0.013344547201922978
[Epoch 12, Batch 1000] loss: 0.012266968706953776
[Epoch 12, Batch 1100] loss: 0.017650853713021206
[Epoch 12, Batch 1200] loss: 0.013011556485434995
[Epoch 12, Batch 1300] loss: 0.018996787531959852
[Epoch 12, Batch 1400] loss: 0.007999093053763317
[Epoch 12, Batch 1500] loss: 0.01827032268873154
[Epoch 12, Batch 1600] loss: 0.019799343817030603
[Epoch 12, Batch 1700] loss: 0.013507358483889221
[Epoch 12, Batch 1800] loss: 0.01934780486544696
[Epoch 12, Batch 1900] loss: 0.022651871742164077
[Epoch 12, Batch 2000] loss: 0.01784365362906101
[Epoch 12, Batch 2100] loss: 0.01582108377078839
[Epoch 12, Batch 2200] loss: 0.018067424867203953
[Epoch 12, Batch 2300] loss: 0.022122519415825083
[Epoch 12, Batch 2400] loss: 0.01056066659410135
[Epoch 12, Batch 2500] loss: 0.013498472508781561
[Epoch 12, Batch 2600] loss: 0.014047473872851697
[Epoch 12, Batch 2700] loss: 0.011970802561627351
[Epoch 12, Batch 2800] loss: 0.010433408866720128
[Epoch 12, Batch 2900] loss: 0.017841255399825968
[Epoch 12, Batch 3000] loss: 0.017008869896744726
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0454
Validation Accuracy: 0.9874
Overfitting: 0.0454
[Epoch 13, Batch 100] loss: 0.008197538724652986
[Epoch 13, Batch 200] loss: 0.008071533560469106
[Epoch 13, Batch 300] loss: 0.017854818661699027
[Epoch 13, Batch 400] loss: 0.009896873252873774
[Epoch 13, Batch 500] loss: 0.0088667755869551
[Epoch 13, Batch 600] loss: 0.011918815778296904
[Epoch 13, Batch 700] loss: 0.017142246306793823
[Epoch 13, Batch 800] loss: 0.009863181458513282
[Epoch 13, Batch 900] loss: 0.023797903466906974
[Epoch 13, Batch 1000] loss: 0.010526791305387632
[Epoch 13, Batch 1100] loss: 0.011347945759580398
[Epoch 13, Batch 1200] loss: 0.007421680890602147
[Epoch 13, Batch 1300] loss: 0.013444784327139131
[Epoch 13, Batch 1400] loss: 0.012086219104712654
[Epoch 13, Batch 1500] loss: 0.02167217807729685
[Epoch 13, Batch 1600] loss: 0.01806428586020047
[Epoch 13, Batch 1700] loss: 0.007901481337344194
[Epoch 13, Batch 1800] loss: 0.008853170599904843
[Epoch 13, Batch 1900] loss: 0.023550058642749717
[Epoch 13, Batch 2000] loss: 0.019433801015220523
[Epoch 13, Batch 2100] loss: 0.015584150670492817
[Epoch 13, Batch 2200] loss: 0.013536389920682268
[Epoch 13, Batch 2300] loss: 0.007717031920747104
[Epoch 13, Batch 2400] loss: 0.01410850236139595
[Epoch 13, Batch 2500] loss: 0.012706392225641138
[Epoch 13, Batch 2600] loss: 0.016441951659971893
[Epoch 13, Batch 2700] loss: 0.012458479143388103
[Epoch 13, Batch 2800] loss: 0.013891455977991428
[Epoch 13, Batch 2900] loss: 0.011588208201501402
[Epoch 13, Batch 3000] loss: 0.024994123751134793
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0408
Validation Accuracy: 0.9884
Overfitting: 0.0408
Best model saved at epoch 13 with validation loss: 0.0408
[Epoch 14, Batch 100] loss: 0.00762571102433867
[Epoch 14, Batch 200] loss: 0.005049229296064368
[Epoch 14, Batch 300] loss: 0.014247579903480983
[Epoch 14, Batch 400] loss: 0.012264020084876393
[Epoch 14, Batch 500] loss: 0.008311000339890597
[Epoch 14, Batch 600] loss: 0.010394250733925218
[Epoch 14, Batch 700] loss: 0.020740724327806673
[Epoch 14, Batch 800] loss: 0.008199816039468715
[Epoch 14, Batch 900] loss: 0.009810975697619143
[Epoch 14, Batch 1000] loss: 0.013228679573985573
[Epoch 14, Batch 1100] loss: 0.008955013072782094
[Epoch 14, Batch 1200] loss: 0.010181951325798765
[Epoch 14, Batch 1300] loss: 0.0068265030268230475
[Epoch 14, Batch 1400] loss: 0.013294146334924335
[Epoch 14, Batch 1500] loss: 0.01681905638050466
[Epoch 14, Batch 1600] loss: 0.009497232202247687
[Epoch 14, Batch 1700] loss: 0.015273723311438517
[Epoch 14, Batch 1800] loss: 0.014035538593489036
[Epoch 14, Batch 1900] loss: 0.009070415923433757
[Epoch 14, Batch 2000] loss: 0.01056100591598124
[Epoch 14, Batch 2100] loss: 0.012516243034797299
[Epoch 14, Batch 2200] loss: 0.005509564143487751
[Epoch 14, Batch 2300] loss: 0.008796002800913812
[Epoch 14, Batch 2400] loss: 0.013557420312044996
[Epoch 14, Batch 2500] loss: 0.012818642169513624
[Epoch 14, Batch 2600] loss: 0.007919915926431714
[Epoch 14, Batch 2700] loss: 0.01244610224924145
[Epoch 14, Batch 2800] loss: 0.012245297702197604
[Epoch 14, Batch 2900] loss: 0.012887980018958842
[Epoch 14, Batch 3000] loss: 0.013040327279818485
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0405
Validation Accuracy: 0.9877
Overfitting: 0.0405
Best model saved at epoch 14 with validation loss: 0.0405
[Epoch 15, Batch 100] loss: 0.011915329112598556
[Epoch 15, Batch 200] loss: 0.008248160431339784
[Epoch 15, Batch 300] loss: 0.005638727991099586
[Epoch 15, Batch 400] loss: 0.006017957459466743
[Epoch 15, Batch 500] loss: 0.011029667777643226
[Epoch 15, Batch 600] loss: 0.016657512753217817
[Epoch 15, Batch 700] loss: 0.007822514475626575
[Epoch 15, Batch 800] loss: 0.01036227834251349
[Epoch 15, Batch 900] loss: 0.006960295744047471
[Epoch 15, Batch 1000] loss: 0.008306773476545005
[Epoch 15, Batch 1100] loss: 0.005860063921231813
[Epoch 15, Batch 1200] loss: 0.011504390671416332
[Epoch 15, Batch 1300] loss: 0.013483367358612669
[Epoch 15, Batch 1400] loss: 0.009628585014711461
[Epoch 15, Batch 1500] loss: 0.013243515124404439
[Epoch 15, Batch 1600] loss: 0.012319335334013885
[Epoch 15, Batch 1700] loss: 0.01645114808780363
[Epoch 15, Batch 1800] loss: 0.02024241953166893
[Epoch 15, Batch 1900] loss: 0.013139056718418942
[Epoch 15, Batch 2000] loss: 0.01733146257077351
[Epoch 15, Batch 2100] loss: 0.023041005878295665
[Epoch 15, Batch 2200] loss: 0.006800749989001815
[Epoch 15, Batch 2300] loss: 0.009283785068146245
[Epoch 15, Batch 2400] loss: 0.009688014049188495
[Epoch 15, Batch 2500] loss: 0.01176666546686647
[Epoch 15, Batch 2600] loss: 0.01324794382060645
[Epoch 15, Batch 2700] loss: 0.012003870751705108
[Epoch 15, Batch 2800] loss: 0.0049241866814190875
[Epoch 15, Batch 2900] loss: 0.011048671846147044
[Epoch 15, Batch 3000] loss: 0.007918706790142095
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9866
Overfitting: 0.0473
[Epoch 16, Batch 100] loss: 0.006413899151530131
[Epoch 16, Batch 200] loss: 0.007277987995714739
[Epoch 16, Batch 300] loss: 0.006261274492312623
[Epoch 16, Batch 400] loss: 0.00690336751697032
[Epoch 16, Batch 500] loss: 0.019020098988366953
[Epoch 16, Batch 600] loss: 0.014311198691293612
[Epoch 16, Batch 700] loss: 0.005457707863934047
[Epoch 16, Batch 800] loss: 0.00411298738383266
[Epoch 16, Batch 900] loss: 0.008181583826385577
[Epoch 16, Batch 1000] loss: 0.004152387771346184
[Epoch 16, Batch 1100] loss: 0.005756904447875968
[Epoch 16, Batch 1200] loss: 0.009790705492259804
[Epoch 16, Batch 1300] loss: 0.010018710587658006
[Epoch 16, Batch 1400] loss: 0.004968781373875118
[Epoch 16, Batch 1500] loss: 0.005908755448103875
[Epoch 16, Batch 1600] loss: 0.013052795798321313
[Epoch 16, Batch 1700] loss: 0.007573833620986079
[Epoch 16, Batch 1800] loss: 0.004178621403736429
[Epoch 16, Batch 1900] loss: 0.012267923918270753
[Epoch 16, Batch 2000] loss: 0.0061658353599750625
[Epoch 16, Batch 2100] loss: 0.010328195540269007
[Epoch 16, Batch 2200] loss: 0.009448915180244058
[Epoch 16, Batch 2300] loss: 0.011196373132393092
[Epoch 16, Batch 2400] loss: 0.013570541845033403
[Epoch 16, Batch 2500] loss: 0.004420297879798909
[Epoch 16, Batch 2600] loss: 0.005637710805708593
[Epoch 16, Batch 2700] loss: 0.018669087143066462
[Epoch 16, Batch 2800] loss: 0.0078403722304256
[Epoch 16, Batch 2900] loss: 0.010859944821359022
[Epoch 16, Batch 3000] loss: 0.010937396261251706
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0440
Validation Accuracy: 0.9873
Overfitting: 0.0440
[Epoch 17, Batch 100] loss: 0.0058223278114201095
[Epoch 17, Batch 200] loss: 0.010192256947957503
[Epoch 17, Batch 300] loss: 0.0049001792121089235
[Epoch 17, Batch 400] loss: 0.007801914991377998
[Epoch 17, Batch 500] loss: 0.004366363632911998
[Epoch 17, Batch 600] loss: 0.008003906233798262
[Epoch 17, Batch 700] loss: 0.004430597625314476
[Epoch 17, Batch 800] loss: 0.005283916543494343
[Epoch 17, Batch 900] loss: 0.008050000304967853
[Epoch 17, Batch 1000] loss: 0.00824925746056124
[Epoch 17, Batch 1100] loss: 0.008391270371294012
[Epoch 17, Batch 1200] loss: 0.009990501507915042
[Epoch 17, Batch 1300] loss: 0.008011998149449938
[Epoch 17, Batch 1400] loss: 0.003941950819530575
[Epoch 17, Batch 1500] loss: 0.008125981353223323
[Epoch 17, Batch 1600] loss: 0.007571697297912579
[Epoch 17, Batch 1700] loss: 0.011712612461085428
[Epoch 17, Batch 1800] loss: 0.021307174956618838
[Epoch 17, Batch 1900] loss: 0.0074582245958936255
[Epoch 17, Batch 2000] loss: 0.0163660519418886
[Epoch 17, Batch 2100] loss: 0.013054212188581004
[Epoch 17, Batch 2200] loss: 0.008354475832975368
[Epoch 17, Batch 2300] loss: 0.0033068748141567993
[Epoch 17, Batch 2400] loss: 0.0059189760143431155
[Epoch 17, Batch 2500] loss: 0.01104721587432323
[Epoch 17, Batch 2600] loss: 0.012496354216207237
[Epoch 17, Batch 2700] loss: 0.012852702339530992
[Epoch 17, Batch 2800] loss: 0.0062811728332667375
[Epoch 17, Batch 2900] loss: 0.004868407970598128
[Epoch 17, Batch 3000] loss: 0.012973529609512298
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9874
Overfitting: 0.0470
[Epoch 18, Batch 100] loss: 0.003048834550651236
[Epoch 18, Batch 200] loss: 0.0038732044438802406
[Epoch 18, Batch 300] loss: 0.00952474532472479
[Epoch 18, Batch 400] loss: 0.0066174847079855685
[Epoch 18, Batch 500] loss: 0.011404321410810355
[Epoch 18, Batch 600] loss: 0.007126963984172789
[Epoch 18, Batch 700] loss: 0.00500516644174013
[Epoch 18, Batch 800] loss: 0.008985143477750625
[Epoch 18, Batch 900] loss: 0.0028778316185258746
[Epoch 18, Batch 1000] loss: 0.0017243952020248798
[Epoch 18, Batch 1100] loss: 0.011086006743522035
[Epoch 18, Batch 1200] loss: 0.005994324814955689
[Epoch 18, Batch 1300] loss: 0.009009030408810759
[Epoch 18, Batch 1400] loss: 0.00566726886626725
[Epoch 18, Batch 1500] loss: 0.008383757884935221
[Epoch 18, Batch 1600] loss: 0.005401944196177055
[Epoch 18, Batch 1700] loss: 0.0029197060189017064
[Epoch 18, Batch 1800] loss: 0.002864585534798607
[Epoch 18, Batch 1900] loss: 0.0028735877543385867
[Epoch 18, Batch 2000] loss: 0.002762194806652474
[Epoch 18, Batch 2100] loss: 0.003121979690694161
[Epoch 18, Batch 2200] loss: 0.011072645388744605
[Epoch 18, Batch 2300] loss: 0.0041832449849130175
[Epoch 18, Batch 2400] loss: 0.008001324173146713
[Epoch 18, Batch 2500] loss: 0.01708215322878459
[Epoch 18, Batch 2600] loss: 0.007112048636363397
[Epoch 18, Batch 2700] loss: 0.007313353278071873
[Epoch 18, Batch 2800] loss: 0.004782311631066705
[Epoch 18, Batch 2900] loss: 0.007777110785588093
[Epoch 18, Batch 3000] loss: 0.004968158644853702
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0454
Validation Accuracy: 0.9882
Overfitting: 0.0454
[Epoch 19, Batch 100] loss: 0.0016477510885164292
[Epoch 19, Batch 200] loss: 0.0035374752875623017
[Epoch 19, Batch 300] loss: 0.0022526537407611615
[Epoch 19, Batch 400] loss: 0.002663648680656934
[Epoch 19, Batch 500] loss: 0.002431929822820393
[Epoch 19, Batch 600] loss: 0.00202734333935382
[Epoch 19, Batch 700] loss: 0.008551990521273183
[Epoch 19, Batch 800] loss: 0.0029316465031263305
[Epoch 19, Batch 900] loss: 0.0012149443373317581
[Epoch 19, Batch 1000] loss: 0.006170577949710463
[Epoch 19, Batch 1100] loss: 0.006245183932575174
[Epoch 19, Batch 1200] loss: 0.004114067520465738
[Epoch 19, Batch 1300] loss: 0.003914936475407558
[Epoch 19, Batch 1400] loss: 0.0019651766959754013
[Epoch 19, Batch 1500] loss: 0.0023917997686066883
[Epoch 19, Batch 1600] loss: 0.0044853889167524134
[Epoch 19, Batch 1700] loss: 0.002660488874278144
[Epoch 19, Batch 1800] loss: 0.004282993542441318
[Epoch 19, Batch 1900] loss: 0.0043099539811919385
[Epoch 19, Batch 2000] loss: 0.010637329764162474
[Epoch 19, Batch 2100] loss: 0.0127753892524413
[Epoch 19, Batch 2200] loss: 0.011991838592546173
[Epoch 19, Batch 2300] loss: 0.004483481378798615
[Epoch 19, Batch 2400] loss: 0.003914546062604245
[Epoch 19, Batch 2500] loss: 0.006905553345807363
[Epoch 19, Batch 2600] loss: 0.005916903559175353
[Epoch 19, Batch 2700] loss: 0.007734201697758181
[Epoch 19, Batch 2800] loss: 0.009599167719509296
[Epoch 19, Batch 2900] loss: 0.013371824697856027
[Epoch 19, Batch 3000] loss: 0.0089815375760827
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9880
Overfitting: 0.0527
[Epoch 20, Batch 100] loss: 0.003970782383145348
[Epoch 20, Batch 200] loss: 0.0019254673495470343
[Epoch 20, Batch 300] loss: 0.003449505878152195
[Epoch 20, Batch 400] loss: 0.0032545544635991064
[Epoch 20, Batch 500] loss: 0.005980155249777966
[Epoch 20, Batch 600] loss: 0.004231752766993395
[Epoch 20, Batch 700] loss: 0.0031181198611085394
[Epoch 20, Batch 800] loss: 0.0027881290642966404
[Epoch 20, Batch 900] loss: 0.0018158889892997366
[Epoch 20, Batch 1000] loss: 0.001922345582916023
[Epoch 20, Batch 1100] loss: 0.0030819066374255044
[Epoch 20, Batch 1200] loss: 0.0017329234884618926
[Epoch 20, Batch 1300] loss: 0.002732960690846653
[Epoch 20, Batch 1400] loss: 0.005936425754836137
[Epoch 20, Batch 1500] loss: 0.0041199325078497395
[Epoch 20, Batch 1600] loss: 0.004265340197522391
[Epoch 20, Batch 1700] loss: 0.00162991098771208
[Epoch 20, Batch 1800] loss: 0.0023232838260094013
[Epoch 20, Batch 1900] loss: 0.0039383123159922205
[Epoch 20, Batch 2000] loss: 0.015824358470656535
[Epoch 20, Batch 2100] loss: 0.006793128933396702
[Epoch 20, Batch 2200] loss: 0.007076382360439766
[Epoch 20, Batch 2300] loss: 0.008976208164963282
[Epoch 20, Batch 2400] loss: 0.005695068189968993
[Epoch 20, Batch 2500] loss: 0.008371860960720597
[Epoch 20, Batch 2600] loss: 0.005057280924734187
[Epoch 20, Batch 2700] loss: 0.005052978441062237
[Epoch 20, Batch 2800] loss: 0.00463789462024124
[Epoch 20, Batch 2900] loss: 0.008636904211904835
[Epoch 20, Batch 3000] loss: 0.015451551528276469
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9876
Overfitting: 0.0499
[Epoch 21, Batch 100] loss: 0.0030140731881493823
[Epoch 21, Batch 200] loss: 0.008406823333740477
[Epoch 21, Batch 300] loss: 0.004137346069796877
[Epoch 21, Batch 400] loss: 0.0019809783828810624
[Epoch 21, Batch 500] loss: 0.002795422789250779
[Epoch 21, Batch 600] loss: 0.0026776298779853393
[Epoch 21, Batch 700] loss: 0.005154661220830121
[Epoch 21, Batch 800] loss: 0.007971516876016266
[Epoch 21, Batch 900] loss: 0.0066437868124904756
[Epoch 21, Batch 1000] loss: 0.0028060410905180787
[Epoch 21, Batch 1100] loss: 0.002576477537750179
[Epoch 21, Batch 1200] loss: 0.005774136982337268
[Epoch 21, Batch 1300] loss: 0.002271485341171342
[Epoch 21, Batch 1400] loss: 0.007371532701922093
[Epoch 21, Batch 1500] loss: 0.008295537091388496
[Epoch 21, Batch 1600] loss: 0.005349673536495629
[Epoch 21, Batch 1700] loss: 0.01243884326274781
[Epoch 21, Batch 1800] loss: 0.009633074645488477
[Epoch 21, Batch 1900] loss: 0.005874020114981704
[Epoch 21, Batch 2000] loss: 0.0038468053033909656
[Epoch 21, Batch 2100] loss: 0.006599605159195221
[Epoch 21, Batch 2200] loss: 0.0033211320975826196
[Epoch 21, Batch 2300] loss: 0.0054022600781343045
[Epoch 21, Batch 2400] loss: 0.0067281091563188514
[Epoch 21, Batch 2500] loss: 0.0106807922511382
[Epoch 21, Batch 2600] loss: 0.0031416055012510923
[Epoch 21, Batch 2700] loss: 0.010871263202839146
[Epoch 21, Batch 2800] loss: 0.0021015856416056523
[Epoch 21, Batch 2900] loss: 0.00886222447297655
[Epoch 21, Batch 3000] loss: 0.0035547133204988767
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9877
Overfitting: 0.0471
[Epoch 22, Batch 100] loss: 0.0031174602789053553
[Epoch 22, Batch 200] loss: 0.004580164415796162
[Epoch 22, Batch 300] loss: 0.005716657183195366
[Epoch 22, Batch 400] loss: 0.001855535000456001
[Epoch 22, Batch 500] loss: 0.004913571381137558
[Epoch 22, Batch 600] loss: 0.00786547395397406
[Epoch 22, Batch 700] loss: 0.007348429459676708
[Epoch 22, Batch 800] loss: 0.002023519037122128
[Epoch 22, Batch 900] loss: 0.0016778949926595033
[Epoch 22, Batch 1000] loss: 0.0015747986677126847
[Epoch 22, Batch 1100] loss: 0.002818264045217802
[Epoch 22, Batch 1200] loss: 0.0011592030294599453
[Epoch 22, Batch 1300] loss: 0.0016532270759103086
[Epoch 22, Batch 1400] loss: 0.003192282152134567
[Epoch 22, Batch 1500] loss: 0.00224990275721666
[Epoch 22, Batch 1600] loss: 0.0014577459478010723
[Epoch 22, Batch 1700] loss: 0.001882579196161487
[Epoch 22, Batch 1800] loss: 0.002279013707990316
[Epoch 22, Batch 1900] loss: 0.001780453221538494
[Epoch 22, Batch 2000] loss: 0.0048371914210787285
[Epoch 22, Batch 2100] loss: 0.0023410723155961933
[Epoch 22, Batch 2200] loss: 0.005346822106045579
[Epoch 22, Batch 2300] loss: 0.0069763681646720956
[Epoch 22, Batch 2400] loss: 0.006448593191819328
[Epoch 22, Batch 2500] loss: 0.004689754438915088
[Epoch 22, Batch 2600] loss: 0.004978216277177694
[Epoch 22, Batch 2700] loss: 0.010202212112767483
[Epoch 22, Batch 2800] loss: 0.014624632098891652
[Epoch 22, Batch 2900] loss: 0.003626021936451025
[Epoch 22, Batch 3000] loss: 0.003739691468853721
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9887
Overfitting: 0.0459
[Epoch 23, Batch 100] loss: 0.002211800460253244
[Epoch 23, Batch 200] loss: 0.0070138159052416426
[Epoch 23, Batch 300] loss: 0.001609236322748302
[Epoch 23, Batch 400] loss: 0.0017973420009380447
[Epoch 23, Batch 500] loss: 0.001421422105858028
[Epoch 23, Batch 600] loss: 0.0034618391559331483
[Epoch 23, Batch 700] loss: 0.001539660397188314
[Epoch 23, Batch 800] loss: 0.0019623574729268965
[Epoch 23, Batch 900] loss: 0.0028247074319631338
[Epoch 23, Batch 1000] loss: 0.0014589107400425406
[Epoch 23, Batch 1100] loss: 0.003703849680507574
[Epoch 23, Batch 1200] loss: 0.006812026691652023
[Epoch 23, Batch 1300] loss: 0.0017862440453666295
[Epoch 23, Batch 1400] loss: 0.004015841755710241
[Epoch 23, Batch 1500] loss: 0.0026128893291564735
[Epoch 23, Batch 1600] loss: 0.002878858856726083
[Epoch 23, Batch 1700] loss: 0.006190312003976999
[Epoch 23, Batch 1800] loss: 0.015131590602321126
[Epoch 23, Batch 1900] loss: 0.0028265999871064196
[Epoch 23, Batch 2000] loss: 0.0025730248238176046
[Epoch 23, Batch 2100] loss: 0.0021566860355483187
[Epoch 23, Batch 2200] loss: 0.0034632521871822064
[Epoch 23, Batch 2300] loss: 0.0054781935114459656
[Epoch 23, Batch 2400] loss: 0.0027551665077470487
[Epoch 23, Batch 2500] loss: 0.007680878203684642
[Epoch 23, Batch 2600] loss: 0.0016451089832560228
[Epoch 23, Batch 2700] loss: 0.0036881929316336937
[Epoch 23, Batch 2800] loss: 0.008124486722721258
[Epoch 23, Batch 2900] loss: 0.006813121490289973
[Epoch 23, Batch 3000] loss: 0.001996935869417484
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9884
Overfitting: 0.0436
[Epoch 24, Batch 100] loss: 0.002021231087665143
[Epoch 24, Batch 200] loss: 0.001406166481060609
[Epoch 24, Batch 300] loss: 0.0019538427299846716
[Epoch 24, Batch 400] loss: 0.002264754360793404
[Epoch 24, Batch 500] loss: 0.000732677041492309
[Epoch 24, Batch 600] loss: 0.0008636536377390769
[Epoch 24, Batch 700] loss: 0.001885709030630096
[Epoch 24, Batch 800] loss: 0.0028708988192542506
[Epoch 24, Batch 900] loss: 0.0006693875467988164
[Epoch 24, Batch 1000] loss: 0.0017308637514054225
[Epoch 24, Batch 1100] loss: 0.0017246833900679804
[Epoch 24, Batch 1200] loss: 0.0022645170676138093
[Epoch 24, Batch 1300] loss: 0.002247694762806418
[Epoch 24, Batch 1400] loss: 0.009368778794249693
[Epoch 24, Batch 1500] loss: 0.0012166363492622167
[Epoch 24, Batch 1600] loss: 0.00197713350612446
[Epoch 24, Batch 1700] loss: 0.003977503446473065
[Epoch 24, Batch 1800] loss: 0.003163106646747167
[Epoch 24, Batch 1900] loss: 0.006531755713443204
[Epoch 24, Batch 2000] loss: 0.002967014582303591
[Epoch 24, Batch 2100] loss: 0.001781366019257007
[Epoch 24, Batch 2200] loss: 0.0020581373295341975
[Epoch 24, Batch 2300] loss: 0.0047708681185335425
[Epoch 24, Batch 2400] loss: 0.00322776737663105
[Epoch 24, Batch 2500] loss: 0.002595847464060057
[Epoch 24, Batch 2600] loss: 0.00826562847496426
[Epoch 24, Batch 2700] loss: 0.0014151276819404578
[Epoch 24, Batch 2800] loss: 0.0024345745518590434
[Epoch 24, Batch 2900] loss: 0.0065328258724395025
[Epoch 24, Batch 3000] loss: 0.0045902139083949575
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0438
Validation Accuracy: 0.9878
Overfitting: 0.0438
Fold 4 validation loss: 0.0438
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2776678228378295
[Epoch 1, Batch 200] loss: 2.1899933433532714
[Epoch 1, Batch 300] loss: 1.6841012132167816
[Epoch 1, Batch 400] loss: 0.8735314828157424
[Epoch 1, Batch 500] loss: 0.6367212332785129
[Epoch 1, Batch 600] loss: 0.49465457528829576
[Epoch 1, Batch 700] loss: 0.48222782894968985
[Epoch 1, Batch 800] loss: 0.40389630317687986
[Epoch 1, Batch 900] loss: 0.4245519618690014
[Epoch 1, Batch 1000] loss: 0.346283721588552
[Epoch 1, Batch 1100] loss: 0.3421906555816531
[Epoch 1, Batch 1200] loss: 0.31406289666891096
[Epoch 1, Batch 1300] loss: 0.2539845404401422
[Epoch 1, Batch 1400] loss: 0.283798196837306
[Epoch 1, Batch 1500] loss: 0.25622612342238427
[Epoch 1, Batch 1600] loss: 0.22536491826176644
[Epoch 1, Batch 1700] loss: 0.23899193599820137
[Epoch 1, Batch 1800] loss: 0.23282251244410873
[Epoch 1, Batch 1900] loss: 0.2294717637449503
[Epoch 1, Batch 2000] loss: 0.1948032046481967
[Epoch 1, Batch 2100] loss: 0.19186750028049573
[Epoch 1, Batch 2200] loss: 0.18989547551609576
[Epoch 1, Batch 2300] loss: 0.1992809936357662
[Epoch 1, Batch 2400] loss: 0.18208328623790293
[Epoch 1, Batch 2500] loss: 0.20096693743951619
[Epoch 1, Batch 2600] loss: 0.16970073680393397
[Epoch 1, Batch 2700] loss: 0.14031158517114817
[Epoch 1, Batch 2800] loss: 0.16805247851647437
[Epoch 1, Batch 2900] loss: 0.16505680510774254
[Epoch 1, Batch 3000] loss: 0.1383935076277703
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2632
Validation Accuracy: 0.9154
Overfitting: 0.2632
Best model saved at epoch 1 with validation loss: 0.2632
[Epoch 2, Batch 100] loss: 0.14498980328440667
[Epoch 2, Batch 200] loss: 0.12931420545326547
[Epoch 2, Batch 300] loss: 0.12224244741722941
[Epoch 2, Batch 400] loss: 0.13234462671913205
[Epoch 2, Batch 500] loss: 0.14461605243384837
[Epoch 2, Batch 600] loss: 0.10737540149828419
[Epoch 2, Batch 700] loss: 0.11591232103295625
[Epoch 2, Batch 800] loss: 0.10113420992041938
[Epoch 2, Batch 900] loss: 0.13425448778783902
[Epoch 2, Batch 1000] loss: 0.11130203884094954
[Epoch 2, Batch 1100] loss: 0.1251469302829355
[Epoch 2, Batch 1200] loss: 0.11931536961346864
[Epoch 2, Batch 1300] loss: 0.1156470389617607
[Epoch 2, Batch 1400] loss: 0.12325136764906347
[Epoch 2, Batch 1500] loss: 0.08970139822922647
[Epoch 2, Batch 1600] loss: 0.12164538494311274
[Epoch 2, Batch 1700] loss: 0.09093177999835461
[Epoch 2, Batch 1800] loss: 0.10279802406672388
[Epoch 2, Batch 1900] loss: 0.09001543293241411
[Epoch 2, Batch 2000] loss: 0.09121154005872086
[Epoch 2, Batch 2100] loss: 0.10855923461029306
[Epoch 2, Batch 2200] loss: 0.10681839023949578
[Epoch 2, Batch 2300] loss: 0.11515707880724221
[Epoch 2, Batch 2400] loss: 0.10076842782087624
[Epoch 2, Batch 2500] loss: 0.09339480974944309
[Epoch 2, Batch 2600] loss: 0.08023675779346377
[Epoch 2, Batch 2700] loss: 0.07518305098405108
[Epoch 2, Batch 2800] loss: 0.09698721012100578
[Epoch 2, Batch 2900] loss: 0.09693336850148626
[Epoch 2, Batch 3000] loss: 0.09529672121512704
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0889
Validation Accuracy: 0.9722
Overfitting: 0.0889
Best model saved at epoch 2 with validation loss: 0.0889
[Epoch 3, Batch 100] loss: 0.08178954078350216
[Epoch 3, Batch 200] loss: 0.06415932421805337
[Epoch 3, Batch 300] loss: 0.09379492914536967
[Epoch 3, Batch 400] loss: 0.10566830162657424
[Epoch 3, Batch 500] loss: 0.09841960517689585
[Epoch 3, Batch 600] loss: 0.06740810851857532
[Epoch 3, Batch 700] loss: 0.0864454723050585
[Epoch 3, Batch 800] loss: 0.08908876885310747
[Epoch 3, Batch 900] loss: 0.10095300898770802
[Epoch 3, Batch 1000] loss: 0.05290131151210517
[Epoch 3, Batch 1100] loss: 0.07216614242410287
[Epoch 3, Batch 1200] loss: 0.07417588501935825
[Epoch 3, Batch 1300] loss: 0.06303669567278121
[Epoch 3, Batch 1400] loss: 0.0863050387846306
[Epoch 3, Batch 1500] loss: 0.06076178659306606
[Epoch 3, Batch 1600] loss: 0.06697542419482488
[Epoch 3, Batch 1700] loss: 0.08608505275216885
[Epoch 3, Batch 1800] loss: 0.08009423375828191
[Epoch 3, Batch 1900] loss: 0.061960151069797575
[Epoch 3, Batch 2000] loss: 0.06764830638305284
[Epoch 3, Batch 2100] loss: 0.056288581200642514
[Epoch 3, Batch 2200] loss: 0.05529402479180135
[Epoch 3, Batch 2300] loss: 0.06548178436787566
[Epoch 3, Batch 2400] loss: 0.06916916354792192
[Epoch 3, Batch 2500] loss: 0.0765002095681848
[Epoch 3, Batch 2600] loss: 0.06656108709867112
[Epoch 3, Batch 2700] loss: 0.0826784700655844
[Epoch 3, Batch 2800] loss: 0.0981043891061563
[Epoch 3, Batch 2900] loss: 0.060601822950993665
[Epoch 3, Batch 3000] loss: 0.07195502842892892
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0724
Validation Accuracy: 0.9783
Overfitting: 0.0724
Best model saved at epoch 3 with validation loss: 0.0724
[Epoch 4, Batch 100] loss: 0.054438392956508326
[Epoch 4, Batch 200] loss: 0.0487770076218294
[Epoch 4, Batch 300] loss: 0.048628563978127204
[Epoch 4, Batch 400] loss: 0.052608046744717286
[Epoch 4, Batch 500] loss: 0.05732013294007629
[Epoch 4, Batch 600] loss: 0.051428526579984465
[Epoch 4, Batch 700] loss: 0.06290225889009889
[Epoch 4, Batch 800] loss: 0.05793921937583946
[Epoch 4, Batch 900] loss: 0.06261246084817686
[Epoch 4, Batch 1000] loss: 0.05085142594878562
[Epoch 4, Batch 1100] loss: 0.07820482846931555
[Epoch 4, Batch 1200] loss: 0.062386006625019946
[Epoch 4, Batch 1300] loss: 0.05449757050781045
[Epoch 4, Batch 1400] loss: 0.051639131561969406
[Epoch 4, Batch 1500] loss: 0.07372514730901457
[Epoch 4, Batch 1600] loss: 0.057991879950277506
[Epoch 4, Batch 1700] loss: 0.07197635601391085
[Epoch 4, Batch 1800] loss: 0.0560251319676172
[Epoch 4, Batch 1900] loss: 0.046811672732001174
[Epoch 4, Batch 2000] loss: 0.055509143892559225
[Epoch 4, Batch 2100] loss: 0.0775959874567343
[Epoch 4, Batch 2200] loss: 0.07284725570119917
[Epoch 4, Batch 2300] loss: 0.041504840839188546
[Epoch 4, Batch 2400] loss: 0.06411110736895352
[Epoch 4, Batch 2500] loss: 0.06288741255993954
[Epoch 4, Batch 2600] loss: 0.05451381197810406
[Epoch 4, Batch 2700] loss: 0.03923897528264206
[Epoch 4, Batch 2800] loss: 0.06362699141027406
[Epoch 4, Batch 2900] loss: 0.04219936874054838
[Epoch 4, Batch 3000] loss: 0.06868414718774148
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0729
Validation Accuracy: 0.9758
Overfitting: 0.0729
[Epoch 5, Batch 100] loss: 0.047704424483235926
[Epoch 5, Batch 200] loss: 0.040658009966427926
[Epoch 5, Batch 300] loss: 0.05875533408019692
[Epoch 5, Batch 400] loss: 0.05410468973539537
[Epoch 5, Batch 500] loss: 0.062243603515380524
[Epoch 5, Batch 600] loss: 0.048503022787044756
[Epoch 5, Batch 700] loss: 0.05153402335810824
[Epoch 5, Batch 800] loss: 0.04906628271040972
[Epoch 5, Batch 900] loss: 0.04506860338296974
[Epoch 5, Batch 1000] loss: 0.050989813666965346
[Epoch 5, Batch 1100] loss: 0.05981615075579612
[Epoch 5, Batch 1200] loss: 0.04374211975286016
[Epoch 5, Batch 1300] loss: 0.04519099582219496
[Epoch 5, Batch 1400] loss: 0.044377447886072334
[Epoch 5, Batch 1500] loss: 0.04058044108227477
[Epoch 5, Batch 1600] loss: 0.04178728377039079
[Epoch 5, Batch 1700] loss: 0.05890540745749604
[Epoch 5, Batch 1800] loss: 0.05548671808850486
[Epoch 5, Batch 1900] loss: 0.052968706811079756
[Epoch 5, Batch 2000] loss: 0.061089377608441284
[Epoch 5, Batch 2100] loss: 0.04823121121095028
[Epoch 5, Batch 2200] loss: 0.03717034641536884
[Epoch 5, Batch 2300] loss: 0.05551779992878437
[Epoch 5, Batch 2400] loss: 0.05116449242108501
[Epoch 5, Batch 2500] loss: 0.05435863831895404
[Epoch 5, Batch 2600] loss: 0.05557982385973446
[Epoch 5, Batch 2700] loss: 0.041058156828366915
[Epoch 5, Batch 2800] loss: 0.04421440181613434
[Epoch 5, Batch 2900] loss: 0.04182026631722693
[Epoch 5, Batch 3000] loss: 0.04644477619585814
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0651
Validation Accuracy: 0.9793
Overfitting: 0.0651
Best model saved at epoch 5 with validation loss: 0.0651
[Epoch 6, Batch 100] loss: 0.0412105050838727
[Epoch 6, Batch 200] loss: 0.028986504534987034
[Epoch 6, Batch 300] loss: 0.06413605640467722
[Epoch 6, Batch 400] loss: 0.03266318203372066
[Epoch 6, Batch 500] loss: 0.046203701208578425
[Epoch 6, Batch 600] loss: 0.030380293219204758
[Epoch 6, Batch 700] loss: 0.03723063042270951
[Epoch 6, Batch 800] loss: 0.05780259720340837
[Epoch 6, Batch 900] loss: 0.060273008896037934
[Epoch 6, Batch 1000] loss: 0.041136526939226314
[Epoch 6, Batch 1100] loss: 0.033355021608440436
[Epoch 6, Batch 1200] loss: 0.03607717931328807
[Epoch 6, Batch 1300] loss: 0.042997273429355116
[Epoch 6, Batch 1400] loss: 0.04911688621970825
[Epoch 6, Batch 1500] loss: 0.035309444106096634
[Epoch 6, Batch 1600] loss: 0.04494169753976166
[Epoch 6, Batch 1700] loss: 0.04075343620977947
[Epoch 6, Batch 1800] loss: 0.049664769874943886
[Epoch 6, Batch 1900] loss: 0.052270845594757705
[Epoch 6, Batch 2000] loss: 0.04942763816390652
[Epoch 6, Batch 2100] loss: 0.04337909208465135
[Epoch 6, Batch 2200] loss: 0.0346795269503491
[Epoch 6, Batch 2300] loss: 0.0493308591764071
[Epoch 6, Batch 2400] loss: 0.03869533250544919
[Epoch 6, Batch 2500] loss: 0.023795809676958015
[Epoch 6, Batch 2600] loss: 0.04486751256670687
[Epoch 6, Batch 2700] loss: 0.03790855723491404
[Epoch 6, Batch 2800] loss: 0.03724222020813613
[Epoch 6, Batch 2900] loss: 0.028389886783115797
[Epoch 6, Batch 3000] loss: 0.04373494154104265
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0668
Validation Accuracy: 0.9793
Overfitting: 0.0668
[Epoch 7, Batch 100] loss: 0.028365511739393695
[Epoch 7, Batch 200] loss: 0.0320320963843551
[Epoch 7, Batch 300] loss: 0.032091430876898815
[Epoch 7, Batch 400] loss: 0.03647909159350093
[Epoch 7, Batch 500] loss: 0.040769606893445595
[Epoch 7, Batch 600] loss: 0.047799705431971234
[Epoch 7, Batch 700] loss: 0.03121810447948519
[Epoch 7, Batch 800] loss: 0.027713470645976485
[Epoch 7, Batch 900] loss: 0.06158933119935682
[Epoch 7, Batch 1000] loss: 0.0397010095132282
[Epoch 7, Batch 1100] loss: 0.03459516837960109
[Epoch 7, Batch 1200] loss: 0.02914908590610139
[Epoch 7, Batch 1300] loss: 0.026460854179167655
[Epoch 7, Batch 1400] loss: 0.05543950383449556
[Epoch 7, Batch 1500] loss: 0.02778167309181299
[Epoch 7, Batch 1600] loss: 0.03311320405715378
[Epoch 7, Batch 1700] loss: 0.03927697137289215
[Epoch 7, Batch 1800] loss: 0.03280444183255895
[Epoch 7, Batch 1900] loss: 0.03825932353196549
[Epoch 7, Batch 2000] loss: 0.042832021318608894
[Epoch 7, Batch 2100] loss: 0.025845922628068365
[Epoch 7, Batch 2200] loss: 0.03735204712837003
[Epoch 7, Batch 2300] loss: 0.036182687775144586
[Epoch 7, Batch 2400] loss: 0.03358855981423403
[Epoch 7, Batch 2500] loss: 0.0476121338889061
[Epoch 7, Batch 2600] loss: 0.024813373262877577
[Epoch 7, Batch 2700] loss: 0.029393487471388653
[Epoch 7, Batch 2800] loss: 0.036052712157106724
[Epoch 7, Batch 2900] loss: 0.031102762315422295
[Epoch 7, Batch 3000] loss: 0.036968846423551444
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9858
Overfitting: 0.0479
Best model saved at epoch 7 with validation loss: 0.0479
[Epoch 8, Batch 100] loss: 0.025081674889152056
[Epoch 8, Batch 200] loss: 0.02532958783704089
[Epoch 8, Batch 300] loss: 0.03235979907796718
[Epoch 8, Batch 400] loss: 0.026097666890127585
[Epoch 8, Batch 500] loss: 0.02608045965564088
[Epoch 8, Batch 600] loss: 0.03045487175877497
[Epoch 8, Batch 700] loss: 0.0326398858250468
[Epoch 8, Batch 800] loss: 0.028663701682307873
[Epoch 8, Batch 900] loss: 0.035800725068293106
[Epoch 8, Batch 1000] loss: 0.03990906984283356
[Epoch 8, Batch 1100] loss: 0.02220155505114235
[Epoch 8, Batch 1200] loss: 0.025751639677328058
[Epoch 8, Batch 1300] loss: 0.03165067598951282
[Epoch 8, Batch 1400] loss: 0.019287735104371678
[Epoch 8, Batch 1500] loss: 0.04862378561643709
[Epoch 8, Batch 1600] loss: 0.030583076048860677
[Epoch 8, Batch 1700] loss: 0.024873194669016812
[Epoch 8, Batch 1800] loss: 0.01681896820773545
[Epoch 8, Batch 1900] loss: 0.03696789886962506
[Epoch 8, Batch 2000] loss: 0.02575078284877236
[Epoch 8, Batch 2100] loss: 0.03555567998046172
[Epoch 8, Batch 2200] loss: 0.04398746608261717
[Epoch 8, Batch 2300] loss: 0.031443145048397125
[Epoch 8, Batch 2400] loss: 0.023815724942105588
[Epoch 8, Batch 2500] loss: 0.03194171896342596
[Epoch 8, Batch 2600] loss: 0.021526950173138173
[Epoch 8, Batch 2700] loss: 0.0338149884532686
[Epoch 8, Batch 2800] loss: 0.043221219172119164
[Epoch 8, Batch 2900] loss: 0.03675839023409935
[Epoch 8, Batch 3000] loss: 0.04432811521110125
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9858
Overfitting: 0.0439
Best model saved at epoch 8 with validation loss: 0.0439
[Epoch 9, Batch 100] loss: 0.0271879808610538
[Epoch 9, Batch 200] loss: 0.015117855166026857
[Epoch 9, Batch 300] loss: 0.05000016147008864
[Epoch 9, Batch 400] loss: 0.021500469001257443
[Epoch 9, Batch 500] loss: 0.03375241519381234
[Epoch 9, Batch 600] loss: 0.022438075197678698
[Epoch 9, Batch 700] loss: 0.014883617609229986
[Epoch 9, Batch 800] loss: 0.02470988561919512
[Epoch 9, Batch 900] loss: 0.017620097706385424
[Epoch 9, Batch 1000] loss: 0.018587409180763643
[Epoch 9, Batch 1100] loss: 0.02975726936267165
[Epoch 9, Batch 1200] loss: 0.028381378220001353
[Epoch 9, Batch 1300] loss: 0.01977103338587767
[Epoch 9, Batch 1400] loss: 0.022913185449360753
[Epoch 9, Batch 1500] loss: 0.022549160717717315
[Epoch 9, Batch 1600] loss: 0.02922487423300481
[Epoch 9, Batch 1700] loss: 0.039803646747823225
[Epoch 9, Batch 1800] loss: 0.04002047659872915
[Epoch 9, Batch 1900] loss: 0.034935777430946474
[Epoch 9, Batch 2000] loss: 0.021430121455487096
[Epoch 9, Batch 2100] loss: 0.028569500098383285
[Epoch 9, Batch 2200] loss: 0.022838923347226227
[Epoch 9, Batch 2300] loss: 0.033053909868467596
[Epoch 9, Batch 2400] loss: 0.02175230371143698
[Epoch 9, Batch 2500] loss: 0.05043790157447802
[Epoch 9, Batch 2600] loss: 0.023312448048527584
[Epoch 9, Batch 2700] loss: 0.03437481149605446
[Epoch 9, Batch 2800] loss: 0.018794118622026873
[Epoch 9, Batch 2900] loss: 0.03044138121527794
[Epoch 9, Batch 3000] loss: 0.0250269166657381
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0434
Validation Accuracy: 0.9866
Overfitting: 0.0434
Best model saved at epoch 9 with validation loss: 0.0434
[Epoch 10, Batch 100] loss: 0.0232465587893239
[Epoch 10, Batch 200] loss: 0.02184111378432135
[Epoch 10, Batch 300] loss: 0.020005138312444614
[Epoch 10, Batch 400] loss: 0.029546469544802677
[Epoch 10, Batch 500] loss: 0.017813460616234806
[Epoch 10, Batch 600] loss: 0.023111821778620652
[Epoch 10, Batch 700] loss: 0.020884995149208406
[Epoch 10, Batch 800] loss: 0.03707975229285694
[Epoch 10, Batch 900] loss: 0.015188949905495974
[Epoch 10, Batch 1000] loss: 0.016744307158878657
[Epoch 10, Batch 1100] loss: 0.022339979197349747
[Epoch 10, Batch 1200] loss: 0.02346684231546533
[Epoch 10, Batch 1300] loss: 0.023187382377582253
[Epoch 10, Batch 1400] loss: 0.01742604176248278
[Epoch 10, Batch 1500] loss: 0.022452595346185263
[Epoch 10, Batch 1600] loss: 0.022934329076524592
[Epoch 10, Batch 1700] loss: 0.025891815807153763
[Epoch 10, Batch 1800] loss: 0.026040652593001142
[Epoch 10, Batch 1900] loss: 0.02596390649661771
[Epoch 10, Batch 2000] loss: 0.026617828226371786
[Epoch 10, Batch 2100] loss: 0.025906747185290444
[Epoch 10, Batch 2200] loss: 0.021800485097701314
[Epoch 10, Batch 2300] loss: 0.022687783517285426
[Epoch 10, Batch 2400] loss: 0.02332318700122414
[Epoch 10, Batch 2500] loss: 0.038898816463806725
[Epoch 10, Batch 2600] loss: 0.018421444641207926
[Epoch 10, Batch 2700] loss: 0.02954600497185311
[Epoch 10, Batch 2800] loss: 0.019971673135623858
[Epoch 10, Batch 2900] loss: 0.023046775330949457
[Epoch 10, Batch 3000] loss: 0.021353191174675885
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0451
Validation Accuracy: 0.9859
Overfitting: 0.0451
[Epoch 11, Batch 100] loss: 0.017719579077274828
[Epoch 11, Batch 200] loss: 0.026228351682766514
[Epoch 11, Batch 300] loss: 0.023108554459849984
[Epoch 11, Batch 400] loss: 0.020868340873421404
[Epoch 11, Batch 500] loss: 0.022774853618393535
[Epoch 11, Batch 600] loss: 0.016865263545842026
[Epoch 11, Batch 700] loss: 0.014381812012725276
[Epoch 11, Batch 800] loss: 0.01385584052404738
[Epoch 11, Batch 900] loss: 0.03177896256758686
[Epoch 11, Batch 1000] loss: 0.027205684156051575
[Epoch 11, Batch 1100] loss: 0.02296477013391268
[Epoch 11, Batch 1200] loss: 0.030514609432357245
[Epoch 11, Batch 1300] loss: 0.0174113567751192
[Epoch 11, Batch 1400] loss: 0.024608844668946403
[Epoch 11, Batch 1500] loss: 0.029778296875920204
[Epoch 11, Batch 1600] loss: 0.016827957848799997
[Epoch 11, Batch 1700] loss: 0.01489156685591297
[Epoch 11, Batch 1800] loss: 0.01510898502463533
[Epoch 11, Batch 1900] loss: 0.0162826583079368
[Epoch 11, Batch 2000] loss: 0.023927457270347077
[Epoch 11, Batch 2100] loss: 0.022556990864977707
[Epoch 11, Batch 2200] loss: 0.024819677090963523
[Epoch 11, Batch 2300] loss: 0.02609083509818447
[Epoch 11, Batch 2400] loss: 0.020861699750712434
[Epoch 11, Batch 2500] loss: 0.019298193199401795
[Epoch 11, Batch 2600] loss: 0.011777687237608915
[Epoch 11, Batch 2700] loss: 0.022784830672535464
[Epoch 11, Batch 2800] loss: 0.026657614541945804
[Epoch 11, Batch 2900] loss: 0.01994682605843991
[Epoch 11, Batch 3000] loss: 0.01760484605644706
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9852
Overfitting: 0.0508
[Epoch 12, Batch 100] loss: 0.01868276169316232
[Epoch 12, Batch 200] loss: 0.006408228860054805
[Epoch 12, Batch 300] loss: 0.013614134386734804
[Epoch 12, Batch 400] loss: 0.011105557708906416
[Epoch 12, Batch 500] loss: 0.014266247677333012
[Epoch 12, Batch 600] loss: 0.023012314833231358
[Epoch 12, Batch 700] loss: 0.014269621354633272
[Epoch 12, Batch 800] loss: 0.011823214254218329
[Epoch 12, Batch 900] loss: 0.023513184762678066
[Epoch 12, Batch 1000] loss: 0.02022028009985661
[Epoch 12, Batch 1100] loss: 0.022062172845048734
[Epoch 12, Batch 1200] loss: 0.027816837757745815
[Epoch 12, Batch 1300] loss: 0.026069587050405973
[Epoch 12, Batch 1400] loss: 0.013217207783418417
[Epoch 12, Batch 1500] loss: 0.02116445219875459
[Epoch 12, Batch 1600] loss: 0.021923271311679857
[Epoch 12, Batch 1700] loss: 0.02041378577137948
[Epoch 12, Batch 1800] loss: 0.019612986235242717
[Epoch 12, Batch 1900] loss: 0.014911395479539352
[Epoch 12, Batch 2000] loss: 0.020054893145461394
[Epoch 12, Batch 2100] loss: 0.016478229947024373
[Epoch 12, Batch 2200] loss: 0.027710489542223514
[Epoch 12, Batch 2300] loss: 0.03154469304077793
[Epoch 12, Batch 2400] loss: 0.02184158108484553
[Epoch 12, Batch 2500] loss: 0.014810305240280286
[Epoch 12, Batch 2600] loss: 0.018350723178564295
[Epoch 12, Batch 2700] loss: 0.019244436022927403
[Epoch 12, Batch 2800] loss: 0.012283907668788743
[Epoch 12, Batch 2900] loss: 0.030622097863852105
[Epoch 12, Batch 3000] loss: 0.019957156513119117
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0434
Validation Accuracy: 0.9870
Overfitting: 0.0434
Best model saved at epoch 12 with validation loss: 0.0434
[Epoch 13, Batch 100] loss: 0.017662695500112024
[Epoch 13, Batch 200] loss: 0.013004418918862939
[Epoch 13, Batch 300] loss: 0.017670200425327492
[Epoch 13, Batch 400] loss: 0.016060104678253993
[Epoch 13, Batch 500] loss: 0.015039159278758233
[Epoch 13, Batch 600] loss: 0.014439190691446129
[Epoch 13, Batch 700] loss: 0.012175505022514698
[Epoch 13, Batch 800] loss: 0.012766416250824477
[Epoch 13, Batch 900] loss: 0.020676876956531486
[Epoch 13, Batch 1000] loss: 0.024465220481106373
[Epoch 13, Batch 1100] loss: 0.018808055569043063
[Epoch 13, Batch 1200] loss: 0.02378863538042424
[Epoch 13, Batch 1300] loss: 0.019879976053416612
[Epoch 13, Batch 1400] loss: 0.017808779516853973
[Epoch 13, Batch 1500] loss: 0.021414774434670106
[Epoch 13, Batch 1600] loss: 0.011834204211263568
[Epoch 13, Batch 1700] loss: 0.010814371140731964
[Epoch 13, Batch 1800] loss: 0.01001813842656702
[Epoch 13, Batch 1900] loss: 0.018819949614116923
[Epoch 13, Batch 2000] loss: 0.017128155546688503
[Epoch 13, Batch 2100] loss: 0.01585065942590518
[Epoch 13, Batch 2200] loss: 0.01947752441818011
[Epoch 13, Batch 2300] loss: 0.02619455224063131
[Epoch 13, Batch 2400] loss: 0.01991036085328233
[Epoch 13, Batch 2500] loss: 0.014420222635417304
[Epoch 13, Batch 2600] loss: 0.016782826926155393
[Epoch 13, Batch 2700] loss: 0.015349020848334475
[Epoch 13, Batch 2800] loss: 0.013982999867566832
[Epoch 13, Batch 2900] loss: 0.017568071744954068
[Epoch 13, Batch 3000] loss: 0.018965921283925127
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0408
Validation Accuracy: 0.9872
Overfitting: 0.0408
Best model saved at epoch 13 with validation loss: 0.0408
[Epoch 14, Batch 100] loss: 0.010189305748172046
[Epoch 14, Batch 200] loss: 0.010464785771546303
[Epoch 14, Batch 300] loss: 0.011384235957630153
[Epoch 14, Batch 400] loss: 0.01246276461893558
[Epoch 14, Batch 500] loss: 0.021839275757956786
[Epoch 14, Batch 600] loss: 0.015105608523481352
[Epoch 14, Batch 700] loss: 0.015855443170767102
[Epoch 14, Batch 800] loss: 0.008131421272082662
[Epoch 14, Batch 900] loss: 0.01168145753466888
[Epoch 14, Batch 1000] loss: 0.018370493854854432
[Epoch 14, Batch 1100] loss: 0.025937372541666264
[Epoch 14, Batch 1200] loss: 0.026713099427306587
[Epoch 14, Batch 1300] loss: 0.020166581371377106
[Epoch 14, Batch 1400] loss: 0.024787202844208878
[Epoch 14, Batch 1500] loss: 0.015277022566988308
[Epoch 14, Batch 1600] loss: 0.005729115963704317
[Epoch 14, Batch 1700] loss: 0.010446379613385943
[Epoch 14, Batch 1800] loss: 0.012422579917520125
[Epoch 14, Batch 1900] loss: 0.015321314725115371
[Epoch 14, Batch 2000] loss: 0.01661542927317896
[Epoch 14, Batch 2100] loss: 0.017892204101744937
[Epoch 14, Batch 2200] loss: 0.01486371796044068
[Epoch 14, Batch 2300] loss: 0.012186569362711452
[Epoch 14, Batch 2400] loss: 0.018868932195164233
[Epoch 14, Batch 2500] loss: 0.015357742935402713
[Epoch 14, Batch 2600] loss: 0.019607230799542776
[Epoch 14, Batch 2700] loss: 0.015554449746837236
[Epoch 14, Batch 2800] loss: 0.012159858156028349
[Epoch 14, Batch 2900] loss: 0.021013877035147743
[Epoch 14, Batch 3000] loss: 0.00898805840737623
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0409
Validation Accuracy: 0.9882
Overfitting: 0.0409
[Epoch 15, Batch 100] loss: 0.018219717169486102
[Epoch 15, Batch 200] loss: 0.0053974457114509275
[Epoch 15, Batch 300] loss: 0.011574921269839252
[Epoch 15, Batch 400] loss: 0.00981944817227486
[Epoch 15, Batch 500] loss: 0.005918423076827821
[Epoch 15, Batch 600] loss: 0.011156877356247605
[Epoch 15, Batch 700] loss: 0.010576940533323977
[Epoch 15, Batch 800] loss: 0.010916242767007135
[Epoch 15, Batch 900] loss: 0.011913311109881307
[Epoch 15, Batch 1000] loss: 0.014524405260990534
[Epoch 15, Batch 1100] loss: 0.012404654227884749
[Epoch 15, Batch 1200] loss: 0.009033356372337948
[Epoch 15, Batch 1300] loss: 0.01356332720408318
[Epoch 15, Batch 1400] loss: 0.007214230323866104
[Epoch 15, Batch 1500] loss: 0.012793793380018315
[Epoch 15, Batch 1600] loss: 0.013482558178898216
[Epoch 15, Batch 1700] loss: 0.006863013071128989
[Epoch 15, Batch 1800] loss: 0.010850457337173793
[Epoch 15, Batch 1900] loss: 0.01075857726516915
[Epoch 15, Batch 2000] loss: 0.03027263249686257
[Epoch 15, Batch 2100] loss: 0.015027796921872323
[Epoch 15, Batch 2200] loss: 0.01591361725758361
[Epoch 15, Batch 2300] loss: 0.015225343048205104
[Epoch 15, Batch 2400] loss: 0.009687591905792487
[Epoch 15, Batch 2500] loss: 0.006390297181078495
[Epoch 15, Batch 2600] loss: 0.020189489974291062
[Epoch 15, Batch 2700] loss: 0.00871119506172363
[Epoch 15, Batch 2800] loss: 0.012039694155146208
[Epoch 15, Batch 2900] loss: 0.019218857269625005
[Epoch 15, Batch 3000] loss: 0.02825314470237572
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0429
Validation Accuracy: 0.9863
Overfitting: 0.0429
[Epoch 16, Batch 100] loss: 0.00912911598986284
[Epoch 16, Batch 200] loss: 0.014392300961367255
[Epoch 16, Batch 300] loss: 0.00967015155181798
[Epoch 16, Batch 400] loss: 0.00777429279775788
[Epoch 16, Batch 500] loss: 0.008180052141779016
[Epoch 16, Batch 600] loss: 0.010947741164031868
[Epoch 16, Batch 700] loss: 0.009188457325687977
[Epoch 16, Batch 800] loss: 0.004842980243611236
[Epoch 16, Batch 900] loss: 0.012192601180313432
[Epoch 16, Batch 1000] loss: 0.012494288123234583
[Epoch 16, Batch 1100] loss: 0.009318281318501249
[Epoch 16, Batch 1200] loss: 0.004449050982857443
[Epoch 16, Batch 1300] loss: 0.00600710444151673
[Epoch 16, Batch 1400] loss: 0.016245670548023554
[Epoch 16, Batch 1500] loss: 0.011486128420874592
[Epoch 16, Batch 1600] loss: 0.008480090562459281
[Epoch 16, Batch 1700] loss: 0.013123449759641517
[Epoch 16, Batch 1800] loss: 0.005595498295151629
[Epoch 16, Batch 1900] loss: 0.007981904318003217
[Epoch 16, Batch 2000] loss: 0.011795986107290445
[Epoch 16, Batch 2100] loss: 0.01840796990194349
[Epoch 16, Batch 2200] loss: 0.007974856275523053
[Epoch 16, Batch 2300] loss: 0.018950198742950307
[Epoch 16, Batch 2400] loss: 0.01432340087169905
[Epoch 16, Batch 2500] loss: 0.016824264517872507
[Epoch 16, Batch 2600] loss: 0.017583332896829233
[Epoch 16, Batch 2700] loss: 0.02059390590115072
[Epoch 16, Batch 2800] loss: 0.022422393092824677
[Epoch 16, Batch 2900] loss: 0.01466829783526009
[Epoch 16, Batch 3000] loss: 0.008822321130173805
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0381
Validation Accuracy: 0.9882
Overfitting: 0.0381
Best model saved at epoch 16 with validation loss: 0.0381
[Epoch 17, Batch 100] loss: 0.007045923966679766
[Epoch 17, Batch 200] loss: 0.0038912150873056817
[Epoch 17, Batch 300] loss: 0.00665473233708326
[Epoch 17, Batch 400] loss: 0.015973806069773673
[Epoch 17, Batch 500] loss: 0.012524037259167927
[Epoch 17, Batch 600] loss: 0.013900532773368468
[Epoch 17, Batch 700] loss: 0.01026000925081462
[Epoch 17, Batch 800] loss: 0.008667028920449411
[Epoch 17, Batch 900] loss: 0.013132643753579032
[Epoch 17, Batch 1000] loss: 0.012399097559606389
[Epoch 17, Batch 1100] loss: 0.022436851494226175
[Epoch 17, Batch 1200] loss: 0.008138582604541398
[Epoch 17, Batch 1300] loss: 0.006909104696107988
[Epoch 17, Batch 1400] loss: 0.007203188056469117
[Epoch 17, Batch 1500] loss: 0.006627658513480128
[Epoch 17, Batch 1600] loss: 0.006315738826310735
[Epoch 17, Batch 1700] loss: 0.009309547953932906
[Epoch 17, Batch 1800] loss: 0.014900326480174045
[Epoch 17, Batch 1900] loss: 0.005969988741680936
[Epoch 17, Batch 2000] loss: 0.011467630248066598
[Epoch 17, Batch 2100] loss: 0.017261527732644028
[Epoch 17, Batch 2200] loss: 0.01586988370698691
[Epoch 17, Batch 2300] loss: 0.012482522340815195
[Epoch 17, Batch 2400] loss: 0.004087852049060529
[Epoch 17, Batch 2500] loss: 0.006527411328290214
[Epoch 17, Batch 2600] loss: 0.008316230034515683
[Epoch 17, Batch 2700] loss: 0.014530708298768786
[Epoch 17, Batch 2800] loss: 0.012667759365326674
[Epoch 17, Batch 2900] loss: 0.012366570604008302
[Epoch 17, Batch 3000] loss: 0.014915773806339985
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0407
Validation Accuracy: 0.9878
Overfitting: 0.0407
[Epoch 18, Batch 100] loss: 0.0037672091653689677
[Epoch 18, Batch 200] loss: 0.006627108088669047
[Epoch 18, Batch 300] loss: 0.00856046004790187
[Epoch 18, Batch 400] loss: 0.0031121992972020962
[Epoch 18, Batch 500] loss: 0.014306079412317558
[Epoch 18, Batch 600] loss: 0.006708498280154913
[Epoch 18, Batch 700] loss: 0.007030644838691842
[Epoch 18, Batch 800] loss: 0.007806593907780553
[Epoch 18, Batch 900] loss: 0.009041243773876885
[Epoch 18, Batch 1000] loss: 0.007313089006775044
[Epoch 18, Batch 1100] loss: 0.008066495831606062
[Epoch 18, Batch 1200] loss: 0.00599458203436825
[Epoch 18, Batch 1300] loss: 0.009074977854636472
[Epoch 18, Batch 1400] loss: 0.007455852965862277
[Epoch 18, Batch 1500] loss: 0.003969687634444199
[Epoch 18, Batch 1600] loss: 0.008678122469959818
[Epoch 18, Batch 1700] loss: 0.01119495051099534
[Epoch 18, Batch 1800] loss: 0.010663172391189165
[Epoch 18, Batch 1900] loss: 0.005655849017059609
[Epoch 18, Batch 2000] loss: 0.009154859269198496
[Epoch 18, Batch 2100] loss: 0.017289771479549926
[Epoch 18, Batch 2200] loss: 0.011633358678709555
[Epoch 18, Batch 2300] loss: 0.007343467570854046
[Epoch 18, Batch 2400] loss: 0.014147714053165146
[Epoch 18, Batch 2500] loss: 0.014057843334130666
[Epoch 18, Batch 2600] loss: 0.009613440126179852
[Epoch 18, Batch 2700] loss: 0.007817008298029577
[Epoch 18, Batch 2800] loss: 0.007941230370065569
[Epoch 18, Batch 2900] loss: 0.008749240595402625
[Epoch 18, Batch 3000] loss: 0.024962992399923677
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9862
Overfitting: 0.0511
[Epoch 19, Batch 100] loss: 0.010228963011427368
[Epoch 19, Batch 200] loss: 0.007729523627281196
[Epoch 19, Batch 300] loss: 0.0050180803059720345
[Epoch 19, Batch 400] loss: 0.0037379187697683847
[Epoch 19, Batch 500] loss: 0.008539148762329205
[Epoch 19, Batch 600] loss: 0.0077977061981346196
[Epoch 19, Batch 700] loss: 0.009419489399188024
[Epoch 19, Batch 800] loss: 0.011467955059247288
[Epoch 19, Batch 900] loss: 0.014793121458751557
[Epoch 19, Batch 1000] loss: 0.007053992480255147
[Epoch 19, Batch 1100] loss: 0.01047531238315969
[Epoch 19, Batch 1200] loss: 0.010162659929537767
[Epoch 19, Batch 1300] loss: 0.007894592728134739
[Epoch 19, Batch 1400] loss: 0.005074554133262837
[Epoch 19, Batch 1500] loss: 0.007680362044729918
[Epoch 19, Batch 1600] loss: 0.007169770186810638
[Epoch 19, Batch 1700] loss: 0.003877635893104525
[Epoch 19, Batch 1800] loss: 0.008286556134842159
[Epoch 19, Batch 1900] loss: 0.009968182895007657
[Epoch 19, Batch 2000] loss: 0.007927649195062258
[Epoch 19, Batch 2100] loss: 0.008882508358228734
[Epoch 19, Batch 2200] loss: 0.0034583697554307945
[Epoch 19, Batch 2300] loss: 0.004523889142592452
[Epoch 19, Batch 2400] loss: 0.007940194934831198
[Epoch 19, Batch 2500] loss: 0.005695970313063299
[Epoch 19, Batch 2600] loss: 0.01162455154751342
[Epoch 19, Batch 2700] loss: 0.00636442034353081
[Epoch 19, Batch 2800] loss: 0.020789355540518955
[Epoch 19, Batch 2900] loss: 0.007190701144600098
[Epoch 19, Batch 3000] loss: 0.006564589334051618
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9872
Overfitting: 0.0471
[Epoch 20, Batch 100] loss: 0.011446014054017723
[Epoch 20, Batch 200] loss: 0.010088232473994197
[Epoch 20, Batch 300] loss: 0.0035276223910250338
[Epoch 20, Batch 400] loss: 0.005740139736867604
[Epoch 20, Batch 500] loss: 0.0021433304312768087
[Epoch 20, Batch 600] loss: 0.006117004332992337
[Epoch 20, Batch 700] loss: 0.005532252950374641
[Epoch 20, Batch 800] loss: 0.008322416118719502
[Epoch 20, Batch 900] loss: 0.008345793340636192
[Epoch 20, Batch 1000] loss: 0.006710123537011228
[Epoch 20, Batch 1100] loss: 0.002204260435123615
[Epoch 20, Batch 1200] loss: 0.011042307961315601
[Epoch 20, Batch 1300] loss: 0.009671271464302435
[Epoch 20, Batch 1400] loss: 0.007603648429667373
[Epoch 20, Batch 1500] loss: 0.006333761616401716
[Epoch 20, Batch 1600] loss: 0.006325177013427492
[Epoch 20, Batch 1700] loss: 0.008312886941632769
[Epoch 20, Batch 1800] loss: 0.009865807869866785
[Epoch 20, Batch 1900] loss: 0.009149543276711256
[Epoch 20, Batch 2000] loss: 0.007296504658918366
[Epoch 20, Batch 2100] loss: 0.004784644755234808
[Epoch 20, Batch 2200] loss: 0.004457892080140482
[Epoch 20, Batch 2300] loss: 0.003622573559561033
[Epoch 20, Batch 2400] loss: 0.007807619210302619
[Epoch 20, Batch 2500] loss: 0.02062022953680298
[Epoch 20, Batch 2600] loss: 0.012623474442083876
[Epoch 20, Batch 2700] loss: 0.006152167345402404
[Epoch 20, Batch 2800] loss: 0.004421671416298523
[Epoch 20, Batch 2900] loss: 0.009403750657529599
[Epoch 20, Batch 3000] loss: 0.005949777660969175
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0418
Validation Accuracy: 0.9884
Overfitting: 0.0418
[Epoch 21, Batch 100] loss: 0.0036510957284394863
[Epoch 21, Batch 200] loss: 0.0050455539196627795
[Epoch 21, Batch 300] loss: 0.0025954884166560534
[Epoch 21, Batch 400] loss: 0.008589285322623255
[Epoch 21, Batch 500] loss: 0.002972135256518413
[Epoch 21, Batch 600] loss: 0.004206827709099343
[Epoch 21, Batch 700] loss: 0.006108390934134605
[Epoch 21, Batch 800] loss: 0.0067648207340107545
[Epoch 21, Batch 900] loss: 0.005373428841235182
[Epoch 21, Batch 1000] loss: 0.0016849536160202661
[Epoch 21, Batch 1100] loss: 0.009363268575381199
[Epoch 21, Batch 1200] loss: 0.00960430072268082
[Epoch 21, Batch 1300] loss: 0.010983451267818509
[Epoch 21, Batch 1400] loss: 0.012209976563704004
[Epoch 21, Batch 1500] loss: 0.003719345112359633
[Epoch 21, Batch 1600] loss: 0.00863647284804756
[Epoch 21, Batch 1700] loss: 0.011838615316030428
[Epoch 21, Batch 1800] loss: 0.004712699016869238
[Epoch 21, Batch 1900] loss: 0.0027536454339269767
[Epoch 21, Batch 2000] loss: 0.007972742562777739
[Epoch 21, Batch 2100] loss: 0.004888763732599273
[Epoch 21, Batch 2200] loss: 0.004118393984648492
[Epoch 21, Batch 2300] loss: 0.009132743031229892
[Epoch 21, Batch 2400] loss: 0.007014481117266769
[Epoch 21, Batch 2500] loss: 0.004159783152001637
[Epoch 21, Batch 2600] loss: 0.010476883501277144
[Epoch 21, Batch 2700] loss: 0.009636594076539495
[Epoch 21, Batch 2800] loss: 0.00541799614805484
[Epoch 21, Batch 2900] loss: 0.008947090163117082
[Epoch 21, Batch 3000] loss: 0.004505004197640119
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0408
Validation Accuracy: 0.9893
Overfitting: 0.0408
[Epoch 22, Batch 100] loss: 0.004587930943928314
[Epoch 22, Batch 200] loss: 0.0044492307662198985
[Epoch 22, Batch 300] loss: 0.0026283382506670705
[Epoch 22, Batch 400] loss: 0.004526152470659781
[Epoch 22, Batch 500] loss: 0.0026917243372372467
[Epoch 22, Batch 600] loss: 0.0025387618039255243
[Epoch 22, Batch 700] loss: 0.003113624524340253
[Epoch 22, Batch 800] loss: 0.0042789652559974915
[Epoch 22, Batch 900] loss: 0.0024124009492035724
[Epoch 22, Batch 1000] loss: 0.0029918916517277694
[Epoch 22, Batch 1100] loss: 0.004171936713027549
[Epoch 22, Batch 1200] loss: 0.003641414833924728
[Epoch 22, Batch 1300] loss: 0.007402896300796158
[Epoch 22, Batch 1400] loss: 0.0030734455862807407
[Epoch 22, Batch 1500] loss: 0.008629663738441878
[Epoch 22, Batch 1600] loss: 0.004732304977649164
[Epoch 22, Batch 1700] loss: 0.008201834812400648
[Epoch 22, Batch 1800] loss: 0.00692396882224017
[Epoch 22, Batch 1900] loss: 0.0032721529431022846
[Epoch 22, Batch 2000] loss: 0.006989777384444551
[Epoch 22, Batch 2100] loss: 0.004992008885037649
[Epoch 22, Batch 2200] loss: 0.003937541999747509
[Epoch 22, Batch 2300] loss: 0.009264893352066395
[Epoch 22, Batch 2400] loss: 0.007024163763463776
[Epoch 22, Batch 2500] loss: 0.003950159176379202
[Epoch 22, Batch 2600] loss: 0.004103479311372453
[Epoch 22, Batch 2700] loss: 0.002580133809352674
[Epoch 22, Batch 2800] loss: 0.006459844717950318
[Epoch 22, Batch 2900] loss: 0.013082294284529325
[Epoch 22, Batch 3000] loss: 0.00644018891290898
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9880
Overfitting: 0.0458
[Epoch 23, Batch 100] loss: 0.0026027099396402774
[Epoch 23, Batch 200] loss: 0.00446468360545822
[Epoch 23, Batch 300] loss: 0.003637838443366945
[Epoch 23, Batch 400] loss: 0.00307537766992823
[Epoch 23, Batch 500] loss: 0.004413297989353851
[Epoch 23, Batch 600] loss: 0.001404785899512575
[Epoch 23, Batch 700] loss: 0.001947638346996925
[Epoch 23, Batch 800] loss: 0.005716301175368699
[Epoch 23, Batch 900] loss: 0.002500387155963324
[Epoch 23, Batch 1000] loss: 0.005164312431460303
[Epoch 23, Batch 1100] loss: 0.008528388871234256
[Epoch 23, Batch 1200] loss: 0.010998900844224408
[Epoch 23, Batch 1300] loss: 0.0071463940755757
[Epoch 23, Batch 1400] loss: 0.004494457981546134
[Epoch 23, Batch 1500] loss: 0.007242331913557791
[Epoch 23, Batch 1600] loss: 0.005089072833416139
[Epoch 23, Batch 1700] loss: 0.009228857913619208
[Epoch 23, Batch 1800] loss: 0.005270351967017746
[Epoch 23, Batch 1900] loss: 0.0029529692956907637
[Epoch 23, Batch 2000] loss: 0.004818677481320037
[Epoch 23, Batch 2100] loss: 0.008683250480127781
[Epoch 23, Batch 2200] loss: 0.003718032760806267
[Epoch 23, Batch 2300] loss: 0.006595972092237048
[Epoch 23, Batch 2400] loss: 0.009495133128021962
[Epoch 23, Batch 2500] loss: 0.005194791514395547
[Epoch 23, Batch 2600] loss: 0.0034306151940548093
[Epoch 23, Batch 2700] loss: 0.001790953128424917
[Epoch 23, Batch 2800] loss: 0.005341351718730607
[Epoch 23, Batch 2900] loss: 0.0036077247757756938
[Epoch 23, Batch 3000] loss: 0.003360463163971872
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9890
Overfitting: 0.0446
[Epoch 24, Batch 100] loss: 0.004626624422942313
[Epoch 24, Batch 200] loss: 0.004447796035849478
[Epoch 24, Batch 300] loss: 0.001637491613958275
[Epoch 24, Batch 400] loss: 0.0023666603348920035
[Epoch 24, Batch 500] loss: 0.005411054331207481
[Epoch 24, Batch 600] loss: 0.0039032186575178682
[Epoch 24, Batch 700] loss: 0.003162953344508992
[Epoch 24, Batch 800] loss: 0.003869011423813049
[Epoch 24, Batch 900] loss: 0.0016624540482268913
[Epoch 24, Batch 1000] loss: 0.005025747691059905
[Epoch 24, Batch 1100] loss: 0.003568121574938914
[Epoch 24, Batch 1200] loss: 0.00486025894119706
[Epoch 24, Batch 1300] loss: 0.0018586975440638299
[Epoch 24, Batch 1400] loss: 0.00576545914528424
[Epoch 24, Batch 1500] loss: 0.013210162395535009
[Epoch 24, Batch 1600] loss: 0.00426442597309915
[Epoch 24, Batch 1700] loss: 0.00693297329417021
[Epoch 24, Batch 1800] loss: 0.0021463051288753833
[Epoch 24, Batch 1900] loss: 0.0039802785220499
[Epoch 24, Batch 2000] loss: 0.007551753584747303
[Epoch 24, Batch 2100] loss: 0.0034685765079785647
[Epoch 24, Batch 2200] loss: 0.002184476839759668
[Epoch 24, Batch 2300] loss: 0.010661477303436832
[Epoch 24, Batch 2400] loss: 0.008572372960114727
[Epoch 24, Batch 2500] loss: 0.003360923656965724
[Epoch 24, Batch 2600] loss: 0.008632416861266846
[Epoch 24, Batch 2700] loss: 0.006245629750828811
[Epoch 24, Batch 2800] loss: 0.007640372310465295
[Epoch 24, Batch 2900] loss: 0.00346033613518955
[Epoch 24, Batch 3000] loss: 0.003752712629768098
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9879
Overfitting: 0.0487
Fold 5 validation loss: 0.0487
Mean validation loss across all folds for Trial 22 is 0.0535 with trial config:  l1: 256, l2: 128, lr: 0.0008396549169269917, batch_size: 16
[I 2024-12-10 09:26:13,484] Trial 21 finished with value: 0.05348133431336588 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0008396549169269917, 'batch_size': 16}. Best is trial 4 with value: 0.046893630782967134.

Selected Hyperparameters for Trial 23:
  l1: 256, l2: 128, lr: 0.000383500802246011, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2951396322250366
[Epoch 1, Batch 200] loss: 2.2910551476478576
[Epoch 1, Batch 300] loss: 2.281729040145874
[Epoch 1, Batch 400] loss: 2.2730529284477234
[Epoch 1, Batch 500] loss: 2.2527996778488157
[Epoch 1, Batch 600] loss: 2.2272833585739136
[Epoch 1, Batch 700] loss: 2.160720911026001
[Epoch 1, Batch 800] loss: 2.0137090384960175
[Epoch 1, Batch 900] loss: 1.6799916970729827
[Epoch 1, Batch 1000] loss: 1.1606302231550216
[Epoch 1, Batch 1100] loss: 0.861426597237587
[Epoch 1, Batch 1200] loss: 0.6954323300719261
[Epoch 1, Batch 1300] loss: 0.5906284140050411
[Epoch 1, Batch 1400] loss: 0.6192708951234818
[Epoch 1, Batch 1500] loss: 0.518075180798769
[Epoch 1, Batch 1600] loss: 0.4557698716968298
[Epoch 1, Batch 1700] loss: 0.4228861893713474
[Epoch 1, Batch 1800] loss: 0.45515337377786635
[Epoch 1, Batch 1900] loss: 0.4149333482980728
[Epoch 1, Batch 2000] loss: 0.4049858710169792
[Epoch 1, Batch 2100] loss: 0.38140961959958075
[Epoch 1, Batch 2200] loss: 0.3574550994485617
[Epoch 1, Batch 2300] loss: 0.3296774945408106
[Epoch 1, Batch 2400] loss: 0.35339549124240877
[Epoch 1, Batch 2500] loss: 0.32823266742751
[Epoch 1, Batch 2600] loss: 0.2751044453680515
[Epoch 1, Batch 2700] loss: 0.2700281817279756
[Epoch 1, Batch 2800] loss: 0.27796976195648315
[Epoch 1, Batch 2900] loss: 0.2599040270224214
[Epoch 1, Batch 3000] loss: 0.2923081572446972
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2560
Validation Accuracy: 0.9215
Overfitting: 0.2560
Best model saved at epoch 1 with validation loss: 0.2560
[Epoch 2, Batch 100] loss: 0.2535489126853645
[Epoch 2, Batch 200] loss: 0.264856369625777
[Epoch 2, Batch 300] loss: 0.2306222234480083
[Epoch 2, Batch 400] loss: 0.271572883464396
[Epoch 2, Batch 500] loss: 0.24814506890252233
[Epoch 2, Batch 600] loss: 0.2653528314456344
[Epoch 2, Batch 700] loss: 0.234231844432652
[Epoch 2, Batch 800] loss: 0.20192552311345935
[Epoch 2, Batch 900] loss: 0.17379167266190051
[Epoch 2, Batch 1000] loss: 0.209985955581069
[Epoch 2, Batch 1100] loss: 0.21843615114688875
[Epoch 2, Batch 1200] loss: 0.2159332379233092
[Epoch 2, Batch 1300] loss: 0.23934106167405844
[Epoch 2, Batch 1400] loss: 0.19383947296068071
[Epoch 2, Batch 1500] loss: 0.19355123249813913
[Epoch 2, Batch 1600] loss: 0.1844653824158013
[Epoch 2, Batch 1700] loss: 0.20873925394378604
[Epoch 2, Batch 1800] loss: 0.1918139432184398
[Epoch 2, Batch 1900] loss: 0.15307761235628278
[Epoch 2, Batch 2000] loss: 0.17666396765969694
[Epoch 2, Batch 2100] loss: 0.16101772453635932
[Epoch 2, Batch 2200] loss: 0.15127874807454644
[Epoch 2, Batch 2300] loss: 0.16513347623869776
[Epoch 2, Batch 2400] loss: 0.16069628949277104
[Epoch 2, Batch 2500] loss: 0.13220011218916625
[Epoch 2, Batch 2600] loss: 0.14703602793160825
[Epoch 2, Batch 2700] loss: 0.17677540332078934
[Epoch 2, Batch 2800] loss: 0.12446432768367231
[Epoch 2, Batch 2900] loss: 0.15417071497999132
[Epoch 2, Batch 3000] loss: 0.1512219053413719
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1435
Validation Accuracy: 0.9555
Overfitting: 0.1435
Best model saved at epoch 2 with validation loss: 0.1435
[Epoch 3, Batch 100] loss: 0.14188137210905552
[Epoch 3, Batch 200] loss: 0.12923093041405082
[Epoch 3, Batch 300] loss: 0.1281945925951004
[Epoch 3, Batch 400] loss: 0.17177695127669723
[Epoch 3, Batch 500] loss: 0.1507846133876592
[Epoch 3, Batch 600] loss: 0.10438572799786926
[Epoch 3, Batch 700] loss: 0.14384335619630292
[Epoch 3, Batch 800] loss: 0.10453851545229555
[Epoch 3, Batch 900] loss: 0.14105246921186335
[Epoch 3, Batch 1000] loss: 0.1326330766058527
[Epoch 3, Batch 1100] loss: 0.09872209490276873
[Epoch 3, Batch 1200] loss: 0.12067302038660273
[Epoch 3, Batch 1300] loss: 0.1326770268706605
[Epoch 3, Batch 1400] loss: 0.13545649570412935
[Epoch 3, Batch 1500] loss: 0.15242560875136404
[Epoch 3, Batch 1600] loss: 0.12071406870614737
[Epoch 3, Batch 1700] loss: 0.13193216366693378
[Epoch 3, Batch 1800] loss: 0.10594108038116247
[Epoch 3, Batch 1900] loss: 0.10314767417497933
[Epoch 3, Batch 2000] loss: 0.13513539048843085
[Epoch 3, Batch 2100] loss: 0.10975484034745023
[Epoch 3, Batch 2200] loss: 0.1258832203829661
[Epoch 3, Batch 2300] loss: 0.12329688419122249
[Epoch 3, Batch 2400] loss: 0.10354208857519552
[Epoch 3, Batch 2500] loss: 0.10197333118412644
[Epoch 3, Batch 2600] loss: 0.1223511871509254
[Epoch 3, Batch 2700] loss: 0.10683144997805356
[Epoch 3, Batch 2800] loss: 0.139716704308521
[Epoch 3, Batch 2900] loss: 0.09842435558792204
[Epoch 3, Batch 3000] loss: 0.09773296640254557
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0941
Validation Accuracy: 0.9707
Overfitting: 0.0941
Best model saved at epoch 3 with validation loss: 0.0941
[Epoch 4, Batch 100] loss: 0.12108863577013836
[Epoch 4, Batch 200] loss: 0.11076795866712928
[Epoch 4, Batch 300] loss: 0.1192118102312088
[Epoch 4, Batch 400] loss: 0.08945926699787378
[Epoch 4, Batch 500] loss: 0.09399856196483597
[Epoch 4, Batch 600] loss: 0.08230344298528508
[Epoch 4, Batch 700] loss: 0.11133090217364952
[Epoch 4, Batch 800] loss: 0.07923473092494532
[Epoch 4, Batch 900] loss: 0.08650335530284792
[Epoch 4, Batch 1000] loss: 0.08883424524217844
[Epoch 4, Batch 1100] loss: 0.10154017867287621
[Epoch 4, Batch 1200] loss: 0.09792408088454976
[Epoch 4, Batch 1300] loss: 0.09896179757313803
[Epoch 4, Batch 1400] loss: 0.09213087632437236
[Epoch 4, Batch 1500] loss: 0.09289615614223294
[Epoch 4, Batch 1600] loss: 0.12446533008711412
[Epoch 4, Batch 1700] loss: 0.10897605375619605
[Epoch 4, Batch 1800] loss: 0.08955752290785313
[Epoch 4, Batch 1900] loss: 0.11001500356011093
[Epoch 4, Batch 2000] loss: 0.06109400518238545
[Epoch 4, Batch 2100] loss: 0.0957021189830266
[Epoch 4, Batch 2200] loss: 0.0789933086722158
[Epoch 4, Batch 2300] loss: 0.09093083009589463
[Epoch 4, Batch 2400] loss: 0.07329600946046412
[Epoch 4, Batch 2500] loss: 0.10081379781244322
[Epoch 4, Batch 2600] loss: 0.10417854321654886
[Epoch 4, Batch 2700] loss: 0.08995656654238701
[Epoch 4, Batch 2800] loss: 0.08731719682225958
[Epoch 4, Batch 2900] loss: 0.07569809148903005
[Epoch 4, Batch 3000] loss: 0.07054689223179594
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0886
Validation Accuracy: 0.9738
Overfitting: 0.0886
Best model saved at epoch 4 with validation loss: 0.0886
[Epoch 5, Batch 100] loss: 0.07092397531727329
[Epoch 5, Batch 200] loss: 0.08384860333753749
[Epoch 5, Batch 300] loss: 0.09954532844480127
[Epoch 5, Batch 400] loss: 0.08755487342947163
[Epoch 5, Batch 500] loss: 0.08676374698407016
[Epoch 5, Batch 600] loss: 0.09035082031972706
[Epoch 5, Batch 700] loss: 0.08120127529255114
[Epoch 5, Batch 800] loss: 0.07680723701487295
[Epoch 5, Batch 900] loss: 0.06557009489974007
[Epoch 5, Batch 1000] loss: 0.10593801800161601
[Epoch 5, Batch 1100] loss: 0.08205430996371434
[Epoch 5, Batch 1200] loss: 0.06498456114903092
[Epoch 5, Batch 1300] loss: 0.07180048859212547
[Epoch 5, Batch 1400] loss: 0.07238903858698904
[Epoch 5, Batch 1500] loss: 0.06279034610372036
[Epoch 5, Batch 1600] loss: 0.08791362218616997
[Epoch 5, Batch 1700] loss: 0.0740486997005064
[Epoch 5, Batch 1800] loss: 0.06433478016173468
[Epoch 5, Batch 1900] loss: 0.0932816949969856
[Epoch 5, Batch 2000] loss: 0.06708734738640487
[Epoch 5, Batch 2100] loss: 0.0700053374201525
[Epoch 5, Batch 2200] loss: 0.08090094276471063
[Epoch 5, Batch 2300] loss: 0.07262173100491054
[Epoch 5, Batch 2400] loss: 0.06967456348473205
[Epoch 5, Batch 2500] loss: 0.08068790980731137
[Epoch 5, Batch 2600] loss: 0.07341556845349259
[Epoch 5, Batch 2700] loss: 0.09694135663332418
[Epoch 5, Batch 2800] loss: 0.0803201382397674
[Epoch 5, Batch 2900] loss: 0.07095590570010245
[Epoch 5, Batch 3000] loss: 0.0479862733266782
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0799
Validation Accuracy: 0.9749
Overfitting: 0.0799
Best model saved at epoch 5 with validation loss: 0.0799
[Epoch 6, Batch 100] loss: 0.07294219771865755
[Epoch 6, Batch 200] loss: 0.06380677038803696
[Epoch 6, Batch 300] loss: 0.06667664991691709
[Epoch 6, Batch 400] loss: 0.05644351342110895
[Epoch 6, Batch 500] loss: 0.07779727956396527
[Epoch 6, Batch 600] loss: 0.06810353136505
[Epoch 6, Batch 700] loss: 0.07725339991273358
[Epoch 6, Batch 800] loss: 0.05729831018368713
[Epoch 6, Batch 900] loss: 0.08049199666769709
[Epoch 6, Batch 1000] loss: 0.08019682397833094
[Epoch 6, Batch 1100] loss: 0.04931448568240739
[Epoch 6, Batch 1200] loss: 0.08786187999940012
[Epoch 6, Batch 1300] loss: 0.05206983976473566
[Epoch 6, Batch 1400] loss: 0.06332043875590898
[Epoch 6, Batch 1500] loss: 0.055930760332848876
[Epoch 6, Batch 1600] loss: 0.0675616830564104
[Epoch 6, Batch 1700] loss: 0.05989915183221456
[Epoch 6, Batch 1800] loss: 0.043404051743564195
[Epoch 6, Batch 1900] loss: 0.07414326520287431
[Epoch 6, Batch 2000] loss: 0.07255637847003527
[Epoch 6, Batch 2100] loss: 0.06564984251337591
[Epoch 6, Batch 2200] loss: 0.0531467877398245
[Epoch 6, Batch 2300] loss: 0.06483129526488483
[Epoch 6, Batch 2400] loss: 0.06662058443878777
[Epoch 6, Batch 2500] loss: 0.05794040363747627
[Epoch 6, Batch 2600] loss: 0.07840332680149004
[Epoch 6, Batch 2700] loss: 0.05492440025089309
[Epoch 6, Batch 2800] loss: 0.05621474205108825
[Epoch 6, Batch 2900] loss: 0.09968221075716428
[Epoch 6, Batch 3000] loss: 0.07905719715461601
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0625
Validation Accuracy: 0.9799
Overfitting: 0.0625
[I 2024-12-10 09:27:38,544] Trial 22 pruned. 

Selected Hyperparameters for Trial 24:
  l1: 128, l2: 64, lr: 0.0002691104779323301, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.306621377468109
[Epoch 1, Batch 200] loss: 2.3002017021179197
[Epoch 1, Batch 300] loss: 2.3005139112472532
[Epoch 1, Batch 400] loss: 2.2923954796791075
[Epoch 1, Batch 500] loss: 2.2940680956840516
[Epoch 1, Batch 600] loss: 2.2918422961235048
[Epoch 1, Batch 700] loss: 2.2862158370018006
[Epoch 1, Batch 800] loss: 2.2791455507278444
[Epoch 1, Batch 900] loss: 2.272613332271576
[Epoch 1, Batch 1000] loss: 2.263580393791199
[Epoch 1, Batch 1100] loss: 2.249369058609009
[Epoch 1, Batch 1200] loss: 2.235736918449402
[Epoch 1, Batch 1300] loss: 2.2054811406135557
[Epoch 1, Batch 1400] loss: 2.160438437461853
[Epoch 1, Batch 1500] loss: 2.0776700699329376
[Epoch 1, Batch 1600] loss: 1.9406589269638062
[Epoch 1, Batch 1700] loss: 1.6295928001403808
[Epoch 1, Batch 1800] loss: 1.2622659611701965
[Epoch 1, Batch 1900] loss: 0.895518953204155
[Epoch 1, Batch 2000] loss: 0.7276702174544334
[Epoch 1, Batch 2100] loss: 0.6298169189691544
[Epoch 1, Batch 2200] loss: 0.5755022817850113
[Epoch 1, Batch 2300] loss: 0.5209789741039276
[Epoch 1, Batch 2400] loss: 0.4666709046065807
[Epoch 1, Batch 2500] loss: 0.47480689600110054
[Epoch 1, Batch 2600] loss: 0.4637287275493145
[Epoch 1, Batch 2700] loss: 0.40155046865344046
[Epoch 1, Batch 2800] loss: 0.42372722081840036
[Epoch 1, Batch 2900] loss: 0.42652184844017027
[Epoch 1, Batch 3000] loss: 0.3478256563842297
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3642
Validation Accuracy: 0.8914
Overfitting: 0.3642
Best model saved at epoch 1 with validation loss: 0.3642
[Epoch 2, Batch 100] loss: 0.38152336593717334
[Epoch 2, Batch 200] loss: 0.33489273346960546
[Epoch 2, Batch 300] loss: 0.3569276439398527
[Epoch 2, Batch 400] loss: 0.31580977246165276
[Epoch 2, Batch 500] loss: 0.32172232687473296
[Epoch 2, Batch 600] loss: 0.3510168591141701
[Epoch 2, Batch 700] loss: 0.300495795942843
[Epoch 2, Batch 800] loss: 0.31619152694940567
[Epoch 2, Batch 900] loss: 0.27123696990311147
[Epoch 2, Batch 1000] loss: 0.3131737511977553
[Epoch 2, Batch 1100] loss: 0.2715241191536188
[Epoch 2, Batch 1200] loss: 0.27401330672204494
[Epoch 2, Batch 1300] loss: 0.24468000929802655
[Epoch 2, Batch 1400] loss: 0.27771145772188904
[Epoch 2, Batch 1500] loss: 0.23684332806617023
[Epoch 2, Batch 1600] loss: 0.23469496824312955
[Epoch 2, Batch 1700] loss: 0.25771505342796447
[Epoch 2, Batch 1800] loss: 0.24856632543727755
[Epoch 2, Batch 1900] loss: 0.2325323660764843
[Epoch 2, Batch 2000] loss: 0.23876356203109025
[Epoch 2, Batch 2100] loss: 0.23693452954292296
[Epoch 2, Batch 2200] loss: 0.21707628183066846
[Epoch 2, Batch 2300] loss: 0.22228243516758084
[Epoch 2, Batch 2400] loss: 0.22124173445627093
[Epoch 2, Batch 2500] loss: 0.21213705215603113
[Epoch 2, Batch 2600] loss: 0.23459990167059006
[Epoch 2, Batch 2700] loss: 0.2135054188221693
[Epoch 2, Batch 2800] loss: 0.17782194997183978
[Epoch 2, Batch 2900] loss: 0.18331601650686935
[Epoch 2, Batch 3000] loss: 0.21168788721784948
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1927
Validation Accuracy: 0.9406
Overfitting: 0.1927
Best model saved at epoch 2 with validation loss: 0.1927
[Epoch 3, Batch 100] loss: 0.17987620239146054
[Epoch 3, Batch 200] loss: 0.1903007707791403
[Epoch 3, Batch 300] loss: 0.21111553758382798
[Epoch 3, Batch 400] loss: 0.2006615682132542
[Epoch 3, Batch 500] loss: 0.20181034734472633
[Epoch 3, Batch 600] loss: 0.1761257697176188
[Epoch 3, Batch 700] loss: 0.15199833882041275
[Epoch 3, Batch 800] loss: 0.1671705451235175
[Epoch 3, Batch 900] loss: 0.15887141783721745
[Epoch 3, Batch 1000] loss: 0.1780353766679764
[Epoch 3, Batch 1100] loss: 0.15830454731360077
[Epoch 3, Batch 1200] loss: 0.17586338391527534
[Epoch 3, Batch 1300] loss: 0.16839842658489942
[Epoch 3, Batch 1400] loss: 0.15635881277732552
[Epoch 3, Batch 1500] loss: 0.1788826622441411
[Epoch 3, Batch 1600] loss: 0.16127315762452782
[Epoch 3, Batch 1700] loss: 0.15626099692191928
[Epoch 3, Batch 1800] loss: 0.1753552430588752
[Epoch 3, Batch 1900] loss: 0.17866971103474497
[Epoch 3, Batch 2000] loss: 0.1648773624841124
[Epoch 3, Batch 2100] loss: 0.15155304576270281
[Epoch 3, Batch 2200] loss: 0.1674745705863461
[Epoch 3, Batch 2300] loss: 0.14710463056340814
[Epoch 3, Batch 2400] loss: 0.16005510670132936
[Epoch 3, Batch 2500] loss: 0.16456988282501697
[Epoch 3, Batch 2600] loss: 0.14483823180198668
[Epoch 3, Batch 2700] loss: 0.16691122141666712
[Epoch 3, Batch 2800] loss: 0.13842595874331892
[Epoch 3, Batch 2900] loss: 0.14462576255202295
[Epoch 3, Batch 3000] loss: 0.1422776245791465
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1304
Validation Accuracy: 0.9587
Overfitting: 0.1304
Best model saved at epoch 3 with validation loss: 0.1304
[Epoch 4, Batch 100] loss: 0.14153283450752496
[Epoch 4, Batch 200] loss: 0.14439220615662635
[Epoch 4, Batch 300] loss: 0.15322088587563484
[Epoch 4, Batch 400] loss: 0.11239562357775867
[Epoch 4, Batch 500] loss: 0.12960578177589924
[Epoch 4, Batch 600] loss: 0.17426782228052617
[Epoch 4, Batch 700] loss: 0.11403854133095592
[Epoch 4, Batch 800] loss: 0.14658092209603638
[Epoch 4, Batch 900] loss: 0.12545540128368884
[Epoch 4, Batch 1000] loss: 0.1231369648175314
[Epoch 4, Batch 1100] loss: 0.1442739854939282
[Epoch 4, Batch 1200] loss: 0.13165706866886467
[Epoch 4, Batch 1300] loss: 0.15422061044257135
[Epoch 4, Batch 1400] loss: 0.14377321185544134
[Epoch 4, Batch 1500] loss: 0.10425368649885058
[Epoch 4, Batch 1600] loss: 0.12867455233819783
[Epoch 4, Batch 1700] loss: 0.12488331984262914
[Epoch 4, Batch 1800] loss: 0.11871891998220235
[Epoch 4, Batch 1900] loss: 0.1074307570187375
[Epoch 4, Batch 2000] loss: 0.12984123003669082
[Epoch 4, Batch 2100] loss: 0.11261136719258502
[Epoch 4, Batch 2200] loss: 0.11745983279775828
[Epoch 4, Batch 2300] loss: 0.1150727095734328
[Epoch 4, Batch 2400] loss: 0.11635126969311387
[Epoch 4, Batch 2500] loss: 0.11692976720398292
[Epoch 4, Batch 2600] loss: 0.12179009359329938
[Epoch 4, Batch 2700] loss: 0.11834146474488079
[Epoch 4, Batch 2800] loss: 0.12288396988529712
[Epoch 4, Batch 2900] loss: 0.11976673995610326
[Epoch 4, Batch 3000] loss: 0.10615664661861957
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1080
Validation Accuracy: 0.9667
Overfitting: 0.1080
Best model saved at epoch 4 with validation loss: 0.1080
[Epoch 5, Batch 100] loss: 0.12958649746142328
[Epoch 5, Batch 200] loss: 0.11341841339366511
[Epoch 5, Batch 300] loss: 0.12118450493551791
[Epoch 5, Batch 400] loss: 0.11595701045822353
[Epoch 5, Batch 500] loss: 0.08730244205100463
[Epoch 5, Batch 600] loss: 0.09547364524099976
[Epoch 5, Batch 700] loss: 0.12298592439852656
[Epoch 5, Batch 800] loss: 0.09275860703550279
[Epoch 5, Batch 900] loss: 0.10545311781577765
[Epoch 5, Batch 1000] loss: 0.10275415725307539
[Epoch 5, Batch 1100] loss: 0.09289597692433745
[Epoch 5, Batch 1200] loss: 0.13266958270221949
[Epoch 5, Batch 1300] loss: 0.10404937275219708
[Epoch 5, Batch 1400] loss: 0.12764850667444988
[Epoch 5, Batch 1500] loss: 0.10778689042199403
[Epoch 5, Batch 1600] loss: 0.10194771643262357
[Epoch 5, Batch 1700] loss: 0.10306304597994313
[Epoch 5, Batch 1800] loss: 0.1173112641228363
[Epoch 5, Batch 1900] loss: 0.10210256076883524
[Epoch 5, Batch 2000] loss: 0.08800952327670529
[Epoch 5, Batch 2100] loss: 0.0967524098791182
[Epoch 5, Batch 2200] loss: 0.10498216140782461
[Epoch 5, Batch 2300] loss: 0.09895469976589083
[Epoch 5, Batch 2400] loss: 0.11039852456655354
[Epoch 5, Batch 2500] loss: 0.11043924606405199
[Epoch 5, Batch 2600] loss: 0.12236122643575072
[Epoch 5, Batch 2700] loss: 0.10103721512947232
[Epoch 5, Batch 2800] loss: 0.10098497140686959
[Epoch 5, Batch 2900] loss: 0.10468084717635065
[Epoch 5, Batch 3000] loss: 0.11675113748991862
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1065
Validation Accuracy: 0.9679
Overfitting: 0.1065
Best model saved at epoch 5 with validation loss: 0.1065
[Epoch 6, Batch 100] loss: 0.09818771329941228
[Epoch 6, Batch 200] loss: 0.08649524235632271
[Epoch 6, Batch 300] loss: 0.08416636218782514
[Epoch 6, Batch 400] loss: 0.08788743030047044
[Epoch 6, Batch 500] loss: 0.10570657793665304
[Epoch 6, Batch 600] loss: 0.08890155310626141
[Epoch 6, Batch 700] loss: 0.09240843948558904
[Epoch 6, Batch 800] loss: 0.10946136560523882
[Epoch 6, Batch 900] loss: 0.09446448867674917
[Epoch 6, Batch 1000] loss: 0.08479344802442938
[Epoch 6, Batch 1100] loss: 0.0824210563278757
[Epoch 6, Batch 1200] loss: 0.07512270394712686
[Epoch 6, Batch 1300] loss: 0.08733805861556902
[Epoch 6, Batch 1400] loss: 0.10365105779375881
[Epoch 6, Batch 1500] loss: 0.0896689325850457
[Epoch 6, Batch 1600] loss: 0.07572786090429873
[Epoch 6, Batch 1700] loss: 0.11095160370925441
[Epoch 6, Batch 1800] loss: 0.0912779069528915
[Epoch 6, Batch 1900] loss: 0.0863569414918311
[Epoch 6, Batch 2000] loss: 0.09075662952382117
[Epoch 6, Batch 2100] loss: 0.09363995269988663
[Epoch 6, Batch 2200] loss: 0.10829061768949032
[Epoch 6, Batch 2300] loss: 0.0819927114341408
[Epoch 6, Batch 2400] loss: 0.08649261436541565
[Epoch 6, Batch 2500] loss: 0.11173360735410824
[Epoch 6, Batch 2600] loss: 0.08771222087088973
[Epoch 6, Batch 2700] loss: 0.10406780869932845
[Epoch 6, Batch 2800] loss: 0.06346841747872531
[Epoch 6, Batch 2900] loss: 0.08891984566114843
[Epoch 6, Batch 3000] loss: 0.08359503180196043
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0831
Validation Accuracy: 0.9748
Overfitting: 0.0831
[I 2024-12-10 09:29:08,695] Trial 23 pruned. 
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  14
  Number of complete trials:  10
Best hyperparameters found:
{'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16}
Best trial:
  Value:  0.046893630782967134
Loaded best model checkpoint from: instances/1165062_20241210/best_checkpoint_trial_4/model.pth
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 2.2965969014167786
[Epoch 1, Batch 200] loss: 2.2784907102584837
[Epoch 1, Batch 300] loss: 2.2609212040901183
[Epoch 1, Batch 400] loss: 2.22701132774353
[Epoch 1, Batch 500] loss: 2.153303530216217
[Epoch 1, Batch 600] loss: 2.027174221277237
[Epoch 1, Batch 700] loss: 1.721636813879013
[Epoch 1, Batch 800] loss: 1.221967388987541
[Epoch 1, Batch 900] loss: 0.866368043422699
[Epoch 1, Batch 1000] loss: 0.6750265303254127
[Epoch 1, Batch 1100] loss: 0.5827527563273907
[Epoch 1, Batch 1200] loss: 0.5383624032139778
[Epoch 1, Batch 1300] loss: 0.4694255924224853
[Epoch 1, Batch 1400] loss: 0.4725839227437973
[Epoch 1, Batch 1500] loss: 0.4165725573897362
[Epoch 1, Batch 1600] loss: 0.3592128909006715
[Epoch 1, Batch 1700] loss: 0.35083181839436295
[Epoch 1, Batch 1800] loss: 0.39698562636971474
[Epoch 1, Batch 1900] loss: 0.3243690177425742
[Epoch 1, Batch 2000] loss: 0.34558516725897787
[Epoch 1, Batch 2100] loss: 0.3525275535881519
[Epoch 1, Batch 2200] loss: 0.3296726759523153
[Epoch 1, Batch 2300] loss: 0.31210153583437206
[Epoch 1, Batch 2400] loss: 0.319884217120707
[Epoch 1, Batch 2500] loss: 0.28181854929775
[Epoch 1, Batch 2600] loss: 0.26058864722028374
[Epoch 1, Batch 2700] loss: 0.2866497086174786
[Epoch 1, Batch 2800] loss: 0.30385464619845154
[Epoch 1, Batch 2900] loss: 0.24542410243302584
[Epoch 1, Batch 3000] loss: 0.25165650524199007
[Epoch 1, Batch 3100] loss: 0.24908177569508552
[Epoch 1, Batch 3200] loss: 0.25899440560489895
[Epoch 1, Batch 3300] loss: 0.2456899230182171
[Epoch 1, Batch 3400] loss: 0.23016466049477458
[Epoch 1, Batch 3500] loss: 0.2257399782910943
[Epoch 1, Batch 3600] loss: 0.2307961168512702
[Epoch 1, Batch 3700] loss: 0.22314254354685545
**STATS for Epoch 1** : 
Average training loss: 0.0029
Average validation loss: 0.1918
Overfitting: 0.1889
Best model saved at epoch 1 with training loss: 0.0029
[Epoch 2, Batch 100] loss: 0.21799285062588752
[Epoch 2, Batch 200] loss: 0.1965620824508369
[Epoch 2, Batch 300] loss: 0.2178870685584843
[Epoch 2, Batch 400] loss: 0.2021031397022307
[Epoch 2, Batch 500] loss: 0.13780145560391246
[Epoch 2, Batch 600] loss: 0.1708725466299802
[Epoch 2, Batch 700] loss: 0.16583718661218882
[Epoch 2, Batch 800] loss: 0.20215399004518986
[Epoch 2, Batch 900] loss: 0.15521220514550804
[Epoch 2, Batch 1000] loss: 0.17498662047088145
[Epoch 2, Batch 1100] loss: 0.16957484648562968
[Epoch 2, Batch 1200] loss: 0.17104336694814265
[Epoch 2, Batch 1300] loss: 0.17843825080431996
[Epoch 2, Batch 1400] loss: 0.15860511360224336
[Epoch 2, Batch 1500] loss: 0.15434163843747228
[Epoch 2, Batch 1600] loss: 0.16751448331866414
[Epoch 2, Batch 1700] loss: 0.16865853767842054
[Epoch 2, Batch 1800] loss: 0.15073417405597866
[Epoch 2, Batch 1900] loss: 0.15631050597876311
[Epoch 2, Batch 2000] loss: 0.15593550890218466
[Epoch 2, Batch 2100] loss: 0.13166191595140844
[Epoch 2, Batch 2200] loss: 0.152109109852463
[Epoch 2, Batch 2300] loss: 0.14715227290056646
[Epoch 2, Batch 2400] loss: 0.12478167950175703
[Epoch 2, Batch 2500] loss: 0.10805496448650956
[Epoch 2, Batch 2600] loss: 0.13134309178683906
[Epoch 2, Batch 2700] loss: 0.15243860841728746
[Epoch 2, Batch 2800] loss: 0.12553530738223345
[Epoch 2, Batch 2900] loss: 0.14299122605472803
[Epoch 2, Batch 3000] loss: 0.13130837123375386
[Epoch 2, Batch 3100] loss: 0.13150579381734132
[Epoch 2, Batch 3200] loss: 0.12247084103059024
[Epoch 2, Batch 3300] loss: 0.11288236641790718
[Epoch 2, Batch 3400] loss: 0.13724599898327142
[Epoch 2, Batch 3500] loss: 0.11324281957466155
[Epoch 2, Batch 3600] loss: 0.14219079092144965
[Epoch 2, Batch 3700] loss: 0.10804919798858464
**STATS for Epoch 2** : 
Average training loss: 0.0018
Average validation loss: 0.1059
Overfitting: 0.1041
Best model saved at epoch 2 with training loss: 0.0018
[Epoch 3, Batch 100] loss: 0.11771763962693513
[Epoch 3, Batch 200] loss: 0.11880031233653426
[Epoch 3, Batch 300] loss: 0.10102024131920188
[Epoch 3, Batch 400] loss: 0.12326800704700873
[Epoch 3, Batch 500] loss: 0.10562573521398008
[Epoch 3, Batch 600] loss: 0.10700142852030695
[Epoch 3, Batch 700] loss: 0.11747895103413612
[Epoch 3, Batch 800] loss: 0.10387828768230975
[Epoch 3, Batch 900] loss: 0.10408487932290882
[Epoch 3, Batch 1000] loss: 0.10712189383339137
[Epoch 3, Batch 1100] loss: 0.10125990256434307
[Epoch 3, Batch 1200] loss: 0.12423212704714387
[Epoch 3, Batch 1300] loss: 0.088323602064047
[Epoch 3, Batch 1400] loss: 0.09319478479679674
[Epoch 3, Batch 1500] loss: 0.0830432387208566
[Epoch 3, Batch 1600] loss: 0.11573120253859087
[Epoch 3, Batch 1700] loss: 0.08920040691504255
[Epoch 3, Batch 1800] loss: 0.12026879612356424
[Epoch 3, Batch 1900] loss: 0.11462934944313019
[Epoch 3, Batch 2000] loss: 0.09571941883303225
[Epoch 3, Batch 2100] loss: 0.12042306739836932
[Epoch 3, Batch 2200] loss: 0.09749611362814903
[Epoch 3, Batch 2300] loss: 0.09671327896649018
[Epoch 3, Batch 2400] loss: 0.08606870112242176
[Epoch 3, Batch 2500] loss: 0.0776035940879956
[Epoch 3, Batch 2600] loss: 0.09994857354322448
[Epoch 3, Batch 2700] loss: 0.0894236775347963
[Epoch 3, Batch 2800] loss: 0.0861617591441609
[Epoch 3, Batch 2900] loss: 0.08422760116867721
[Epoch 3, Batch 3000] loss: 0.11543933021021076
[Epoch 3, Batch 3100] loss: 0.08815262645948678
[Epoch 3, Batch 3200] loss: 0.09089232728234492
[Epoch 3, Batch 3300] loss: 0.07902988468296826
[Epoch 3, Batch 3400] loss: 0.10225964508019388
[Epoch 3, Batch 3500] loss: 0.0720912924525328
[Epoch 3, Batch 3600] loss: 0.08725209272233769
[Epoch 3, Batch 3700] loss: 0.08185209752758965
**STATS for Epoch 3** : 
Average training loss: 0.0010
Average validation loss: 0.0721
Overfitting: 0.0711
Best model saved at epoch 3 with training loss: 0.0010
[Epoch 4, Batch 100] loss: 0.07749601288232952
[Epoch 4, Batch 200] loss: 0.08093050992814824
[Epoch 4, Batch 300] loss: 0.07659673208603636
[Epoch 4, Batch 400] loss: 0.09133562205242925
[Epoch 4, Batch 500] loss: 0.10425437937024981
[Epoch 4, Batch 600] loss: 0.07388756317319349
[Epoch 4, Batch 700] loss: 0.08365063004777767
[Epoch 4, Batch 800] loss: 0.09404727068729699
[Epoch 4, Batch 900] loss: 0.07963817652896978
[Epoch 4, Batch 1000] loss: 0.09252721200231463
[Epoch 4, Batch 1100] loss: 0.08761823287466541
[Epoch 4, Batch 1200] loss: 0.07533733106334693
[Epoch 4, Batch 1300] loss: 0.08263464973540977
[Epoch 4, Batch 1400] loss: 0.07856010795047041
[Epoch 4, Batch 1500] loss: 0.07197074026800693
[Epoch 4, Batch 1600] loss: 0.06378371368162333
[Epoch 4, Batch 1700] loss: 0.07384107090649195
[Epoch 4, Batch 1800] loss: 0.07086389170377515
[Epoch 4, Batch 1900] loss: 0.07798157619603444
[Epoch 4, Batch 2000] loss: 0.07107959934743122
[Epoch 4, Batch 2100] loss: 0.06564022819744424
[Epoch 4, Batch 2200] loss: 0.08103671681601554
[Epoch 4, Batch 2300] loss: 0.08859523182618431
[Epoch 4, Batch 2400] loss: 0.07525954786222427
[Epoch 4, Batch 2500] loss: 0.08582670521107502
[Epoch 4, Batch 2600] loss: 0.06339470900245942
[Epoch 4, Batch 2700] loss: 0.06624647269723936
[Epoch 4, Batch 2800] loss: 0.05342829946137499
[Epoch 4, Batch 2900] loss: 0.06632231145864352
[Epoch 4, Batch 3000] loss: 0.06573960423178506
[Epoch 4, Batch 3100] loss: 0.0787237105058739
[Epoch 4, Batch 3200] loss: 0.07377739888848737
[Epoch 4, Batch 3300] loss: 0.07830888409167529
[Epoch 4, Batch 3400] loss: 0.076299982087221
[Epoch 4, Batch 3500] loss: 0.10296202997851651
[Epoch 4, Batch 3600] loss: 0.07324711470049806
[Epoch 4, Batch 3700] loss: 0.05541654320724774
**STATS for Epoch 4** : 
Average training loss: 0.0011
Average validation loss: 0.0622
Overfitting: 0.0612
[Epoch 5, Batch 100] loss: 0.0561277600977337
[Epoch 5, Batch 200] loss: 0.061867301753372884
[Epoch 5, Batch 300] loss: 0.06794129578396678
[Epoch 5, Batch 400] loss: 0.07161339190206491
[Epoch 5, Batch 500] loss: 0.06799205143703148
[Epoch 5, Batch 600] loss: 0.06500384895247407
[Epoch 5, Batch 700] loss: 0.07191333105845843
[Epoch 5, Batch 800] loss: 0.053401793224038555
[Epoch 5, Batch 900] loss: 0.08325266077474225
[Epoch 5, Batch 1000] loss: 0.07915918835671619
[Epoch 5, Batch 1100] loss: 0.07066358178039081
[Epoch 5, Batch 1200] loss: 0.08000804873532616
[Epoch 5, Batch 1300] loss: 0.06770328088896349
[Epoch 5, Batch 1400] loss: 0.050322019923478366
[Epoch 5, Batch 1500] loss: 0.06534603560459801
[Epoch 5, Batch 1600] loss: 0.06114963538246229
[Epoch 5, Batch 1700] loss: 0.05077565540064825
[Epoch 5, Batch 1800] loss: 0.07316883491119369
[Epoch 5, Batch 1900] loss: 0.052691864035441544
[Epoch 5, Batch 2000] loss: 0.06333723591757007
[Epoch 5, Batch 2100] loss: 0.0804207727155881
[Epoch 5, Batch 2200] loss: 0.06336125409172383
[Epoch 5, Batch 2300] loss: 0.061118658958002926
[Epoch 5, Batch 2400] loss: 0.06216889095958322
[Epoch 5, Batch 2500] loss: 0.07726018183981069
[Epoch 5, Batch 2600] loss: 0.05670076791633619
[Epoch 5, Batch 2700] loss: 0.0640812020318117
[Epoch 5, Batch 2800] loss: 0.06198086203832645
[Epoch 5, Batch 2900] loss: 0.06380621184187475
[Epoch 5, Batch 3000] loss: 0.07822599190287292
[Epoch 5, Batch 3100] loss: 0.06524476886086632
[Epoch 5, Batch 3200] loss: 0.05986135023413226
[Epoch 5, Batch 3300] loss: 0.05519451173837297
[Epoch 5, Batch 3400] loss: 0.07176913768867962
[Epoch 5, Batch 3500] loss: 0.050697877005441115
[Epoch 5, Batch 3600] loss: 0.06980180120444857
[Epoch 5, Batch 3700] loss: 0.07750019607250579
**STATS for Epoch 5** : 
Average training loss: 0.0007
Average validation loss: 0.0642
Overfitting: 0.0635
Best model saved at epoch 5 with training loss: 0.0007
[Epoch 6, Batch 100] loss: 0.07095978895900772
[Epoch 6, Batch 200] loss: 0.057266663613845595
[Epoch 6, Batch 300] loss: 0.06807671504036988
[Epoch 6, Batch 400] loss: 0.04220021486398764
[Epoch 6, Batch 500] loss: 0.07111695608356967
[Epoch 6, Batch 600] loss: 0.056853363025002185
[Epoch 6, Batch 700] loss: 0.06107418116996996
[Epoch 6, Batch 800] loss: 0.047213137060170995
[Epoch 6, Batch 900] loss: 0.04731061933969613
[Epoch 6, Batch 1000] loss: 0.05185155430692248
[Epoch 6, Batch 1100] loss: 0.04566402780474164
[Epoch 6, Batch 1200] loss: 0.06554506644926733
[Epoch 6, Batch 1300] loss: 0.05285338389279787
[Epoch 6, Batch 1400] loss: 0.05481014462129678
[Epoch 6, Batch 1500] loss: 0.06077450826589484
[Epoch 6, Batch 1600] loss: 0.04850816486927215
[Epoch 6, Batch 1700] loss: 0.06034188104589702
[Epoch 6, Batch 1800] loss: 0.05874149913550355
[Epoch 6, Batch 1900] loss: 0.05115111318184063
[Epoch 6, Batch 2000] loss: 0.0536900021135807
[Epoch 6, Batch 2100] loss: 0.07261730652448023
[Epoch 6, Batch 2200] loss: 0.04674259058665484
[Epoch 6, Batch 2300] loss: 0.05462826933071483
[Epoch 6, Batch 2400] loss: 0.04700289437925676
[Epoch 6, Batch 2500] loss: 0.06471249683294446
[Epoch 6, Batch 2600] loss: 0.06920990194543265
[Epoch 6, Batch 2700] loss: 0.05506626185029745
[Epoch 6, Batch 2800] loss: 0.04366906401817687
[Epoch 6, Batch 2900] loss: 0.047030315250449345
[Epoch 6, Batch 3000] loss: 0.05342685574578354
[Epoch 6, Batch 3100] loss: 0.06325116936059202
[Epoch 6, Batch 3200] loss: 0.05246826509479433
[Epoch 6, Batch 3300] loss: 0.05887611124489922
[Epoch 6, Batch 3400] loss: 0.05084017191431485
[Epoch 6, Batch 3500] loss: 0.05979029232228641
[Epoch 6, Batch 3600] loss: 0.06961712961085141
[Epoch 6, Batch 3700] loss: 0.05539175691606943
**STATS for Epoch 6** : 
Average training loss: 0.0006
Average validation loss: 0.0607
Overfitting: 0.0600
Best model saved at epoch 6 with training loss: 0.0006
[Epoch 7, Batch 100] loss: 0.03493819575116504
[Epoch 7, Batch 200] loss: 0.050505671922001054
[Epoch 7, Batch 300] loss: 0.05216961973463185
[Epoch 7, Batch 400] loss: 0.04133166406070814
[Epoch 7, Batch 500] loss: 0.048303891893010584
[Epoch 7, Batch 600] loss: 0.04470227488433011
[Epoch 7, Batch 700] loss: 0.06617030360270292
[Epoch 7, Batch 800] loss: 0.051110577765502964
[Epoch 7, Batch 900] loss: 0.040290877970983276
[Epoch 7, Batch 1000] loss: 0.05607666762021836
[Epoch 7, Batch 1100] loss: 0.046491189724765715
[Epoch 7, Batch 1200] loss: 0.044913321104831996
[Epoch 7, Batch 1300] loss: 0.05498395608505234
[Epoch 7, Batch 1400] loss: 0.06875043828244089
[Epoch 7, Batch 1500] loss: 0.05264428440132178
[Epoch 7, Batch 1600] loss: 0.0546696028066799
[Epoch 7, Batch 1700] loss: 0.0359340187322232
[Epoch 7, Batch 1800] loss: 0.05089002277469262
[Epoch 7, Batch 1900] loss: 0.05874711307609687
[Epoch 7, Batch 2000] loss: 0.07020476528909057
[Epoch 7, Batch 2100] loss: 0.05003524001338519
[Epoch 7, Batch 2200] loss: 0.0518798597456771
[Epoch 7, Batch 2300] loss: 0.04112907178059686
[Epoch 7, Batch 2400] loss: 0.04744720133952796
[Epoch 7, Batch 2500] loss: 0.04407346279520425
[Epoch 7, Batch 2600] loss: 0.06339174832944991
[Epoch 7, Batch 2700] loss: 0.05184128009248525
[Epoch 7, Batch 2800] loss: 0.04777957812359091
[Epoch 7, Batch 2900] loss: 0.052811488558654675
[Epoch 7, Batch 3000] loss: 0.057941474950057456
[Epoch 7, Batch 3100] loss: 0.059219523812644184
[Epoch 7, Batch 3200] loss: 0.043694644795614294
[Epoch 7, Batch 3300] loss: 0.044526880100020205
[Epoch 7, Batch 3400] loss: 0.04678031728166388
[Epoch 7, Batch 3500] loss: 0.04958041083358694
[Epoch 7, Batch 3600] loss: 0.05651760263950564
[Epoch 7, Batch 3700] loss: 0.046199899550993
**STATS for Epoch 7** : 
Average training loss: 0.0007
Average validation loss: 0.0448
Overfitting: 0.0441
[Epoch 8, Batch 100] loss: 0.048903219223284396
[Epoch 8, Batch 200] loss: 0.036544302845431954
[Epoch 8, Batch 300] loss: 0.05542391807219246
[Epoch 8, Batch 400] loss: 0.03855975977290654
[Epoch 8, Batch 500] loss: 0.04160818107950035
[Epoch 8, Batch 600] loss: 0.050124202477163635
[Epoch 8, Batch 700] loss: 0.05723242300737184
[Epoch 8, Batch 800] loss: 0.03686245737189893
[Epoch 8, Batch 900] loss: 0.044625828445132354
[Epoch 8, Batch 1000] loss: 0.04675537541814265
[Epoch 8, Batch 1100] loss: 0.06312784444948193
[Epoch 8, Batch 1200] loss: 0.04022920689196326
[Epoch 8, Batch 1300] loss: 0.03518652142985957
[Epoch 8, Batch 1400] loss: 0.040427613779902456
[Epoch 8, Batch 1500] loss: 0.04143939393747132
[Epoch 8, Batch 1600] loss: 0.04828045083908364
[Epoch 8, Batch 1700] loss: 0.04598253925803874
[Epoch 8, Batch 1800] loss: 0.04459926569310482
[Epoch 8, Batch 1900] loss: 0.04356606678571552
[Epoch 8, Batch 2000] loss: 0.05504471263266168
[Epoch 8, Batch 2100] loss: 0.04274994507286465
[Epoch 8, Batch 2200] loss: 0.054998563372646456
[Epoch 8, Batch 2300] loss: 0.0498810642916942
[Epoch 8, Batch 2400] loss: 0.04406328207551269
[Epoch 8, Batch 2500] loss: 0.037924273623211775
[Epoch 8, Batch 2600] loss: 0.05296217544208048
[Epoch 8, Batch 2700] loss: 0.05349586649914272
[Epoch 8, Batch 2800] loss: 0.06202768291579559
[Epoch 8, Batch 2900] loss: 0.04041204384760931
[Epoch 8, Batch 3000] loss: 0.03842735512473155
[Epoch 8, Batch 3100] loss: 0.04295698060945142
[Epoch 8, Batch 3200] loss: 0.041435636834357865
[Epoch 8, Batch 3300] loss: 0.04608583550900221
[Epoch 8, Batch 3400] loss: 0.052170189974422104
[Epoch 8, Batch 3500] loss: 0.03970955378725193
[Epoch 8, Batch 3600] loss: 0.05012719038757495
[Epoch 8, Batch 3700] loss: 0.04382950790633913
**STATS for Epoch 8** : 
Average training loss: 0.0004
Average validation loss: 0.0429
Overfitting: 0.0425
Best model saved at epoch 8 with training loss: 0.0004
[Epoch 9, Batch 100] loss: 0.03726191416353686
[Epoch 9, Batch 200] loss: 0.03776959958631778
[Epoch 9, Batch 300] loss: 0.035201746700913646
[Epoch 9, Batch 400] loss: 0.038032860551320484
[Epoch 9, Batch 500] loss: 0.02276686812954722
[Epoch 9, Batch 600] loss: 0.05008811317908112
[Epoch 9, Batch 700] loss: 0.03386724464362487
[Epoch 9, Batch 800] loss: 0.042251502500439526
[Epoch 9, Batch 900] loss: 0.03503726927097887
[Epoch 9, Batch 1000] loss: 0.04995456056116382
[Epoch 9, Batch 1100] loss: 0.04399242846702691
[Epoch 9, Batch 1200] loss: 0.054518159801664294
[Epoch 9, Batch 1300] loss: 0.043375524877337736
[Epoch 9, Batch 1400] loss: 0.03830939777311869
[Epoch 9, Batch 1500] loss: 0.03586176898214035
[Epoch 9, Batch 1600] loss: 0.03779531373642385
[Epoch 9, Batch 1700] loss: 0.039218915048986676
[Epoch 9, Batch 1800] loss: 0.0227910232017166
[Epoch 9, Batch 1900] loss: 0.0505087683344027
[Epoch 9, Batch 2000] loss: 0.03933749870615429
[Epoch 9, Batch 2100] loss: 0.0301958827933413
[Epoch 9, Batch 2200] loss: 0.06067182687460445
[Epoch 9, Batch 2300] loss: 0.049933968908735554
[Epoch 9, Batch 2400] loss: 0.03730669569602469
[Epoch 9, Batch 2500] loss: 0.03468176881608088
[Epoch 9, Batch 2600] loss: 0.0247719757334562
[Epoch 9, Batch 2700] loss: 0.04228163589155884
[Epoch 9, Batch 2800] loss: 0.047430993790039795
[Epoch 9, Batch 2900] loss: 0.03387702358784736
[Epoch 9, Batch 3000] loss: 0.04242564846616006
[Epoch 9, Batch 3100] loss: 0.05249095796869369
[Epoch 9, Batch 3200] loss: 0.03705321776535129
[Epoch 9, Batch 3300] loss: 0.04173012545506936
[Epoch 9, Batch 3400] loss: 0.043356051036098506
[Epoch 9, Batch 3500] loss: 0.05963304509634327
[Epoch 9, Batch 3600] loss: 0.03883133673400153
[Epoch 9, Batch 3700] loss: 0.03552099152700976
**STATS for Epoch 9** : 
Average training loss: 0.0007
Average validation loss: 0.0501
Overfitting: 0.0494
[Epoch 10, Batch 100] loss: 0.03405844059656374
[Epoch 10, Batch 200] loss: 0.03857036369881826
[Epoch 10, Batch 300] loss: 0.03331440775422379
[Epoch 10, Batch 400] loss: 0.028730543529527496
[Epoch 10, Batch 500] loss: 0.0318528951749613
[Epoch 10, Batch 600] loss: 0.03744437442685012
[Epoch 10, Batch 700] loss: 0.0356793934685993
[Epoch 10, Batch 800] loss: 0.027290720923338084
[Epoch 10, Batch 900] loss: 0.02946811289410107
[Epoch 10, Batch 1000] loss: 0.039946024231612684
[Epoch 10, Batch 1100] loss: 0.03370076119550504
[Epoch 10, Batch 1200] loss: 0.03806295369518921
[Epoch 10, Batch 1300] loss: 0.03990689607046079
[Epoch 10, Batch 1400] loss: 0.030169729733170243
[Epoch 10, Batch 1500] loss: 0.03743551186766126
[Epoch 10, Batch 1600] loss: 0.03519784141040873
[Epoch 10, Batch 1700] loss: 0.03497677365725394
[Epoch 10, Batch 1800] loss: 0.0481525910293567
[Epoch 10, Batch 1900] loss: 0.042261516751314045
[Epoch 10, Batch 2000] loss: 0.03174045758714783
[Epoch 10, Batch 2100] loss: 0.03223271156923147
[Epoch 10, Batch 2200] loss: 0.0466090775115299
[Epoch 10, Batch 2300] loss: 0.04900897244428051
[Epoch 10, Batch 2400] loss: 0.0446115820176783
[Epoch 10, Batch 2500] loss: 0.0271854169209837
[Epoch 10, Batch 2600] loss: 0.044462389426771554
[Epoch 10, Batch 2700] loss: 0.03915176807655371
[Epoch 10, Batch 2800] loss: 0.03483422534613055
[Epoch 10, Batch 2900] loss: 0.05581548306246987
[Epoch 10, Batch 3000] loss: 0.029606458373891656
[Epoch 10, Batch 3100] loss: 0.03125288989860565
[Epoch 10, Batch 3200] loss: 0.025712813838981673
[Epoch 10, Batch 3300] loss: 0.04229518526117317
[Epoch 10, Batch 3400] loss: 0.041124713653116485
[Epoch 10, Batch 3500] loss: 0.04342168476228835
[Epoch 10, Batch 3600] loss: 0.058646186211844906
[Epoch 10, Batch 3700] loss: 0.02269991103807115
**STATS for Epoch 10** : 
Average training loss: 0.0006
Average validation loss: 0.0405
Overfitting: 0.0400
[Epoch 11, Batch 100] loss: 0.030211217539326752
[Epoch 11, Batch 200] loss: 0.039244165843192604
[Epoch 11, Batch 300] loss: 0.03172543946755468
[Epoch 11, Batch 400] loss: 0.038106333380710566
[Epoch 11, Batch 500] loss: 0.031492713090847245
[Epoch 11, Batch 600] loss: 0.03102384801095468
[Epoch 11, Batch 700] loss: 0.03172660443393397
[Epoch 11, Batch 800] loss: 0.0246293633847381
[Epoch 11, Batch 900] loss: 0.03282270339637762
[Epoch 11, Batch 1000] loss: 0.03411299645231338
[Epoch 11, Batch 1100] loss: 0.018502280009997776
[Epoch 11, Batch 1200] loss: 0.033496186058910096
[Epoch 11, Batch 1300] loss: 0.043330808133541725
[Epoch 11, Batch 1400] loss: 0.035370080950378906
[Epoch 11, Batch 1500] loss: 0.03901815106219146
[Epoch 11, Batch 1600] loss: 0.022528414123516995
[Epoch 11, Batch 1700] loss: 0.03963369243618217
[Epoch 11, Batch 1800] loss: 0.04001410455181031
[Epoch 11, Batch 1900] loss: 0.03825573262824036
[Epoch 11, Batch 2000] loss: 0.03360924219581648
[Epoch 11, Batch 2100] loss: 0.03288422017241828
[Epoch 11, Batch 2200] loss: 0.025584786373656243
[Epoch 11, Batch 2300] loss: 0.030098931277461816
[Epoch 11, Batch 2400] loss: 0.033323625587509016
[Epoch 11, Batch 2500] loss: 0.03053586372087011
[Epoch 11, Batch 2600] loss: 0.032791159754124236
[Epoch 11, Batch 2700] loss: 0.03408631973477896
[Epoch 11, Batch 2800] loss: 0.030791660593677078
[Epoch 11, Batch 2900] loss: 0.04490083957600291
[Epoch 11, Batch 3000] loss: 0.033276803586340976
[Epoch 11, Batch 3100] loss: 0.04485194505250547
[Epoch 11, Batch 3200] loss: 0.03615107158766477
[Epoch 11, Batch 3300] loss: 0.04845269194935099
[Epoch 11, Batch 3400] loss: 0.02572078773053363
[Epoch 11, Batch 3500] loss: 0.03856973081696197
[Epoch 11, Batch 3600] loss: 0.03897720644978108
[Epoch 11, Batch 3700] loss: 0.0354915363980399
**STATS for Epoch 11** : 
Average training loss: 0.0003
Average validation loss: 0.0386
Overfitting: 0.0383
Best model saved at epoch 11 with training loss: 0.0003
[Epoch 12, Batch 100] loss: 0.03172527871662169
[Epoch 12, Batch 200] loss: 0.02979347553970001
[Epoch 12, Batch 300] loss: 0.02564169349585427
[Epoch 12, Batch 400] loss: 0.030409600002749358
[Epoch 12, Batch 500] loss: 0.03581514241144759
[Epoch 12, Batch 600] loss: 0.02640463870644453
[Epoch 12, Batch 700] loss: 0.032857777495955816
[Epoch 12, Batch 800] loss: 0.04766084597955342
[Epoch 12, Batch 900] loss: 0.031169037469517206
[Epoch 12, Batch 1000] loss: 0.03679281799471937
[Epoch 12, Batch 1100] loss: 0.03733956019787001
[Epoch 12, Batch 1200] loss: 0.03927492509312287
[Epoch 12, Batch 1300] loss: 0.0324049973313231
[Epoch 12, Batch 1400] loss: 0.03502819267218001
[Epoch 12, Batch 1500] loss: 0.035027721174265024
[Epoch 12, Batch 1600] loss: 0.0288504727097461
[Epoch 12, Batch 1700] loss: 0.04106762972776778
[Epoch 12, Batch 1800] loss: 0.025101292245235527
[Epoch 12, Batch 1900] loss: 0.013753271140594735
[Epoch 12, Batch 2000] loss: 0.03229044180698111
[Epoch 12, Batch 2100] loss: 0.03166179459221894
[Epoch 12, Batch 2200] loss: 0.034766412644821686
[Epoch 12, Batch 2300] loss: 0.025282479514862642
[Epoch 12, Batch 2400] loss: 0.034355764753272525
[Epoch 12, Batch 2500] loss: 0.03363645602410543
[Epoch 12, Batch 2600] loss: 0.029409393659298077
[Epoch 12, Batch 2700] loss: 0.03764858533388178
[Epoch 12, Batch 2800] loss: 0.029226013430379682
[Epoch 12, Batch 2900] loss: 0.031333670907770284
[Epoch 12, Batch 3000] loss: 0.031923697676684244
[Epoch 12, Batch 3100] loss: 0.04089966122555779
[Epoch 12, Batch 3200] loss: 0.03739934991939663
[Epoch 12, Batch 3300] loss: 0.027473016827134416
[Epoch 12, Batch 3400] loss: 0.018818752391962335
[Epoch 12, Batch 3500] loss: 0.030555667020962574
[Epoch 12, Batch 3600] loss: 0.02644080142272287
[Epoch 12, Batch 3700] loss: 0.029585157420733595
**STATS for Epoch 12** : 
Average training loss: 0.0005
Average validation loss: 0.0373
Overfitting: 0.0368
[Epoch 13, Batch 100] loss: 0.02918142833721504
[Epoch 13, Batch 200] loss: 0.04725635992872412
[Epoch 13, Batch 300] loss: 0.026414643909374716
[Epoch 13, Batch 400] loss: 0.025295024474689853
[Epoch 13, Batch 500] loss: 0.029581443086281068
[Epoch 13, Batch 600] loss: 0.029587761867587686
[Epoch 13, Batch 700] loss: 0.03952373443782562
[Epoch 13, Batch 800] loss: 0.023712918290984816
[Epoch 13, Batch 900] loss: 0.030379551786973026
[Epoch 13, Batch 1000] loss: 0.0313643596835027
[Epoch 13, Batch 1100] loss: 0.02147593211622734
[Epoch 13, Batch 1200] loss: 0.02537671984217013
[Epoch 13, Batch 1300] loss: 0.0312897167976189
[Epoch 13, Batch 1400] loss: 0.02168567587941652
[Epoch 13, Batch 1500] loss: 0.02143413506739307
[Epoch 13, Batch 1600] loss: 0.02249130034586415
[Epoch 13, Batch 1700] loss: 0.03779902419017162
[Epoch 13, Batch 1800] loss: 0.02498545580463542
[Epoch 13, Batch 1900] loss: 0.0271136850851326
[Epoch 13, Batch 2000] loss: 0.02526554087518889
[Epoch 13, Batch 2100] loss: 0.02953325956943445
[Epoch 13, Batch 2200] loss: 0.03093837039436039
[Epoch 13, Batch 2300] loss: 0.025323303348232004
[Epoch 13, Batch 2400] loss: 0.020670175435298005
[Epoch 13, Batch 2500] loss: 0.019472164938779315
[Epoch 13, Batch 2600] loss: 0.0359426261894987
[Epoch 13, Batch 2700] loss: 0.03295133924795664
[Epoch 13, Batch 2800] loss: 0.0298777377132501
[Epoch 13, Batch 2900] loss: 0.027904131184332073
[Epoch 13, Batch 3000] loss: 0.032269935929216446
[Epoch 13, Batch 3100] loss: 0.04698365850272239
[Epoch 13, Batch 3200] loss: 0.018404776462048175
[Epoch 13, Batch 3300] loss: 0.02382775765960105
[Epoch 13, Batch 3400] loss: 0.04883840577909723
[Epoch 13, Batch 3500] loss: 0.026301332950533832
[Epoch 13, Batch 3600] loss: 0.037979265110916455
[Epoch 13, Batch 3700] loss: 0.023449661895865573
**STATS for Epoch 13** : 
Average training loss: 0.0003
Average validation loss: 0.0363
Overfitting: 0.0360
[Epoch 14, Batch 100] loss: 0.02142121010198025
[Epoch 14, Batch 200] loss: 0.025329687366320287
[Epoch 14, Batch 300] loss: 0.028370855298562675
[Epoch 14, Batch 400] loss: 0.02002209999554907
[Epoch 14, Batch 500] loss: 0.02062088402421068
[Epoch 14, Batch 600] loss: 0.026178096112416824
[Epoch 14, Batch 700] loss: 0.030682843684917315
[Epoch 14, Batch 800] loss: 0.02599401536026562
[Epoch 14, Batch 900] loss: 0.01670679104368901
[Epoch 14, Batch 1000] loss: 0.03228385815746151
[Epoch 14, Batch 1100] loss: 0.025408693386707454
[Epoch 14, Batch 1200] loss: 0.016514960044951295
[Epoch 14, Batch 1300] loss: 0.03437031385165028
[Epoch 14, Batch 1400] loss: 0.02853345119081496
[Epoch 14, Batch 1500] loss: 0.027466291075688785
[Epoch 14, Batch 1600] loss: 0.019342720179847676
[Epoch 14, Batch 1700] loss: 0.013758974933734862
[Epoch 14, Batch 1800] loss: 0.02940136895966134
[Epoch 14, Batch 1900] loss: 0.03067079967193422
[Epoch 14, Batch 2000] loss: 0.029461790838395244
[Epoch 14, Batch 2100] loss: 0.017377029423441853
[Epoch 14, Batch 2200] loss: 0.0266279102495173
[Epoch 14, Batch 2300] loss: 0.037996608812682096
[Epoch 14, Batch 2400] loss: 0.018025171806439175
[Epoch 14, Batch 2500] loss: 0.030307046936650296
[Epoch 14, Batch 2600] loss: 0.021754915137571516
[Epoch 14, Batch 2700] loss: 0.04248610911119613
[Epoch 14, Batch 2800] loss: 0.0308185000429512
[Epoch 14, Batch 2900] loss: 0.03206767319876235
[Epoch 14, Batch 3000] loss: 0.03362481068346824
[Epoch 14, Batch 3100] loss: 0.023890804976254003
[Epoch 14, Batch 3200] loss: 0.022080183212819973
[Epoch 14, Batch 3300] loss: 0.03126890406092571
[Epoch 14, Batch 3400] loss: 0.035096771011740205
[Epoch 14, Batch 3500] loss: 0.028561568240984343
[Epoch 14, Batch 3600] loss: 0.025202534317650134
[Epoch 14, Batch 3700] loss: 0.03981788500066614
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0414
Overfitting: 0.0409
[Epoch 15, Batch 100] loss: 0.024722321970621124
[Epoch 15, Batch 200] loss: 0.024079870174464304
[Epoch 15, Batch 300] loss: 0.016006241643772227
[Epoch 15, Batch 400] loss: 0.03765438602407812
[Epoch 15, Batch 500] loss: 0.03353923698639846
[Epoch 15, Batch 600] loss: 0.017503207778645447
[Epoch 15, Batch 700] loss: 0.025441089229134378
[Epoch 15, Batch 800] loss: 0.01688976936649851
[Epoch 15, Batch 900] loss: 0.02148737671537674
[Epoch 15, Batch 1000] loss: 0.018990090364095522
[Epoch 15, Batch 1100] loss: 0.02085292332820245
[Epoch 15, Batch 1200] loss: 0.021468284397560638
[Epoch 15, Batch 1300] loss: 0.020571106240167863
[Epoch 15, Batch 1400] loss: 0.01481644293962745
[Epoch 15, Batch 1500] loss: 0.034619173672490434
[Epoch 15, Batch 1600] loss: 0.021288410171473517
[Epoch 15, Batch 1700] loss: 0.025446593746746658
[Epoch 15, Batch 1800] loss: 0.024228789112676168
[Epoch 15, Batch 1900] loss: 0.018168257995275782
[Epoch 15, Batch 2000] loss: 0.017638375836431807
[Epoch 15, Batch 2100] loss: 0.03966225339168886
[Epoch 15, Batch 2200] loss: 0.025058665635879152
[Epoch 15, Batch 2300] loss: 0.028034764203839588
[Epoch 15, Batch 2400] loss: 0.015457651450487902
[Epoch 15, Batch 2500] loss: 0.015244237587758107
[Epoch 15, Batch 2600] loss: 0.03651532443851466
[Epoch 15, Batch 2700] loss: 0.022830845924654567
[Epoch 15, Batch 2800] loss: 0.03049301180486509
[Epoch 15, Batch 2900] loss: 0.01870441510458477
[Epoch 15, Batch 3000] loss: 0.02595831673614157
[Epoch 15, Batch 3100] loss: 0.04083320177669521
[Epoch 15, Batch 3200] loss: 0.016544453651295043
[Epoch 15, Batch 3300] loss: 0.018032474964365976
[Epoch 15, Batch 3400] loss: 0.022334645564842503
[Epoch 15, Batch 3500] loss: 0.019994515020989638
[Epoch 15, Batch 3600] loss: 0.040224900176508524
[Epoch 15, Batch 3700] loss: 0.023799394018933526
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0440
Overfitting: 0.0434
[Epoch 16, Batch 100] loss: 0.030958591290254845
[Epoch 16, Batch 200] loss: 0.013004901680833427
[Epoch 16, Batch 300] loss: 0.013915819556568749
[Epoch 16, Batch 400] loss: 0.023864271934726275
[Epoch 16, Batch 500] loss: 0.03503428567506489
[Epoch 16, Batch 600] loss: 0.026475375660156716
[Epoch 16, Batch 700] loss: 0.03808205753746734
[Epoch 16, Batch 800] loss: 0.03787222565515549
[Epoch 16, Batch 900] loss: 0.01798648543364834
[Epoch 16, Batch 1000] loss: 0.03394089392410024
[Epoch 16, Batch 1100] loss: 0.016299118080933112
[Epoch 16, Batch 1200] loss: 0.01933118645902141
[Epoch 16, Batch 1300] loss: 0.02483567447092355
[Epoch 16, Batch 1400] loss: 0.01510898012137659
[Epoch 16, Batch 1500] loss: 0.031075767581060062
[Epoch 16, Batch 1600] loss: 0.020488060044699524
[Epoch 16, Batch 1700] loss: 0.023165155908400265
[Epoch 16, Batch 1800] loss: 0.024577292110116104
[Epoch 16, Batch 1900] loss: 0.022123459884314797
[Epoch 16, Batch 2000] loss: 0.01894459988216113
[Epoch 16, Batch 2100] loss: 0.01812302846694365
[Epoch 16, Batch 2200] loss: 0.0244644193757631
[Epoch 16, Batch 2300] loss: 0.017381007258663886
[Epoch 16, Batch 2400] loss: 0.0215167020294939
[Epoch 16, Batch 2500] loss: 0.023767920767077157
[Epoch 16, Batch 2600] loss: 0.020265313520794734
[Epoch 16, Batch 2700] loss: 0.018579632611654233
[Epoch 16, Batch 2800] loss: 0.02985391221838654
[Epoch 16, Batch 2900] loss: 0.0239669486474304
[Epoch 16, Batch 3000] loss: 0.02076690719983162
[Epoch 16, Batch 3100] loss: 0.026288322034597512
[Epoch 16, Batch 3200] loss: 0.012887739410653012
[Epoch 16, Batch 3300] loss: 0.019544944800436496
[Epoch 16, Batch 3400] loss: 0.02265900967457128
[Epoch 16, Batch 3500] loss: 0.023440186743628147
[Epoch 16, Batch 3600] loss: 0.015132916527199995
[Epoch 16, Batch 3700] loss: 0.015701749342915718
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0359
Overfitting: 0.0355
[Epoch 17, Batch 100] loss: 0.017272924631288333
[Epoch 17, Batch 200] loss: 0.02086435778885061
[Epoch 17, Batch 300] loss: 0.021345352133212144
[Epoch 17, Batch 400] loss: 0.02692065833878587
[Epoch 17, Batch 500] loss: 0.025321780921076426
[Epoch 17, Batch 600] loss: 0.02215823139864369
[Epoch 17, Batch 700] loss: 0.023890053381746837
[Epoch 17, Batch 800] loss: 0.014345933091972256
[Epoch 17, Batch 900] loss: 0.026534265091067936
[Epoch 17, Batch 1000] loss: 0.03550177132761746
[Epoch 17, Batch 1100] loss: 0.02686665919904044
[Epoch 17, Batch 1200] loss: 0.02220629092418676
[Epoch 17, Batch 1300] loss: 0.02205798698530998
[Epoch 17, Batch 1400] loss: 0.03294269300466112
[Epoch 17, Batch 1500] loss: 0.03507162553090893
[Epoch 17, Batch 1600] loss: 0.022301638108547194
[Epoch 17, Batch 1700] loss: 0.022158583671043744
[Epoch 17, Batch 1800] loss: 0.020440523381112144
[Epoch 17, Batch 1900] loss: 0.018365395731525496
[Epoch 17, Batch 2000] loss: 0.02279886812899349
[Epoch 17, Batch 2100] loss: 0.012078095213364577
[Epoch 17, Batch 2200] loss: 0.026044694034644635
[Epoch 17, Batch 2300] loss: 0.01888129655009834
[Epoch 17, Batch 2400] loss: 0.018826211567866267
[Epoch 17, Batch 2500] loss: 0.01093456155696913
[Epoch 17, Batch 2600] loss: 0.02218398965334927
[Epoch 17, Batch 2700] loss: 0.017721562706537953
[Epoch 17, Batch 2800] loss: 0.0251775681986328
[Epoch 17, Batch 2900] loss: 0.025758622160647063
[Epoch 17, Batch 3000] loss: 0.012778951176987902
[Epoch 17, Batch 3100] loss: 0.016704170292650814
[Epoch 17, Batch 3200] loss: 0.02544531495823321
[Epoch 17, Batch 3300] loss: 0.02711371803259681
[Epoch 17, Batch 3400] loss: 0.02430975409464736
[Epoch 17, Batch 3500] loss: 0.0269325802237654
[Epoch 17, Batch 3600] loss: 0.019677967785537476
[Epoch 17, Batch 3700] loss: 0.012728906106858631
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0312
Overfitting: 0.0309
[Epoch 18, Batch 100] loss: 0.016344908841783762
[Epoch 18, Batch 200] loss: 0.018258763196972724
[Epoch 18, Batch 300] loss: 0.027645403238857398
[Epoch 18, Batch 400] loss: 0.023560545638392796
[Epoch 18, Batch 500] loss: 0.012754173081484623
[Epoch 18, Batch 600] loss: 0.014824643723259215
[Epoch 18, Batch 700] loss: 0.020132168971467763
[Epoch 18, Batch 800] loss: 0.015986288824497024
[Epoch 18, Batch 900] loss: 0.02589359391720791
[Epoch 18, Batch 1000] loss: 0.0304632200625565
[Epoch 18, Batch 1100] loss: 0.021947815036037356
[Epoch 18, Batch 1200] loss: 0.028414691683501588
[Epoch 18, Batch 1300] loss: 0.013048002377327067
[Epoch 18, Batch 1400] loss: 0.01914206214089063
[Epoch 18, Batch 1500] loss: 0.017021214999913353
[Epoch 18, Batch 1600] loss: 0.021452395269479892
[Epoch 18, Batch 1700] loss: 0.023403511146607343
[Epoch 18, Batch 1800] loss: 0.029852800098888112
[Epoch 18, Batch 1900] loss: 0.018588367868178465
[Epoch 18, Batch 2000] loss: 0.017715707741117512
[Epoch 18, Batch 2100] loss: 0.01727401328171254
[Epoch 18, Batch 2200] loss: 0.018916451078039246
[Epoch 18, Batch 2300] loss: 0.019588513921989945
[Epoch 18, Batch 2400] loss: 0.01746345422405284
[Epoch 18, Batch 2500] loss: 0.018913910586197746
[Epoch 18, Batch 2600] loss: 0.027491914352904132
[Epoch 18, Batch 2700] loss: 0.019184435295610456
[Epoch 18, Batch 2800] loss: 0.010377602203734569
[Epoch 18, Batch 2900] loss: 0.019578382606559898
[Epoch 18, Batch 3000] loss: 0.016667225823875923
[Epoch 18, Batch 3100] loss: 0.02087540828881174
[Epoch 18, Batch 3200] loss: 0.013588012326508761
[Epoch 18, Batch 3300] loss: 0.01205598290762282
[Epoch 18, Batch 3400] loss: 0.024710943249010596
[Epoch 18, Batch 3500] loss: 0.020640891461298452
[Epoch 18, Batch 3600] loss: 0.02089705297345063
[Epoch 18, Batch 3700] loss: 0.010887662884088059
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0441
Overfitting: 0.0439
Best model saved at epoch 18 with training loss: 0.0002
[Epoch 19, Batch 100] loss: 0.01307975029169029
[Epoch 19, Batch 200] loss: 0.02351565445842425
[Epoch 19, Batch 300] loss: 0.01204173881735187
[Epoch 19, Batch 400] loss: 0.01596152209851425
[Epoch 19, Batch 500] loss: 0.020251984614806134
[Epoch 19, Batch 600] loss: 0.015889839127485175
[Epoch 19, Batch 700] loss: 0.020868349606826087
[Epoch 19, Batch 800] loss: 0.01864140820260218
[Epoch 19, Batch 900] loss: 0.01360451676948287
[Epoch 19, Batch 1000] loss: 0.02169873748320242
[Epoch 19, Batch 1100] loss: 0.014499679637574446
[Epoch 19, Batch 1200] loss: 0.010197237249085446
[Epoch 19, Batch 1300] loss: 0.026542975898264556
[Epoch 19, Batch 1400] loss: 0.016030198824737454
[Epoch 19, Batch 1500] loss: 0.016124968945150614
[Epoch 19, Batch 1600] loss: 0.015615834361888119
[Epoch 19, Batch 1700] loss: 0.023986525874061044
[Epoch 19, Batch 1800] loss: 0.026288989938548182
[Epoch 19, Batch 1900] loss: 0.016998440844654395
[Epoch 19, Batch 2000] loss: 0.02144447175473033
[Epoch 19, Batch 2100] loss: 0.013531667890165409
[Epoch 19, Batch 2200] loss: 0.018612860436223854
[Epoch 19, Batch 2300] loss: 0.01744788247793622
[Epoch 19, Batch 2400] loss: 0.020832000639907165
[Epoch 19, Batch 2500] loss: 0.021507175283677498
[Epoch 19, Batch 2600] loss: 0.01657548133032833
[Epoch 19, Batch 2700] loss: 0.017214779722999084
[Epoch 19, Batch 2800] loss: 0.015378308966901386
[Epoch 19, Batch 2900] loss: 0.015479701894000754
[Epoch 19, Batch 3000] loss: 0.03694695598605904
[Epoch 19, Batch 3100] loss: 0.019773980074824067
[Epoch 19, Batch 3200] loss: 0.02864729442884709
[Epoch 19, Batch 3300] loss: 0.013037009097060945
[Epoch 19, Batch 3400] loss: 0.01725010040350753
[Epoch 19, Batch 3500] loss: 0.022011957804934354
[Epoch 19, Batch 3600] loss: 0.012324279436106735
[Epoch 19, Batch 3700] loss: 0.02422875170263069
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0323
Overfitting: 0.0321
Best model saved at epoch 19 with training loss: 0.0002
[Epoch 20, Batch 100] loss: 0.007611642971569381
[Epoch 20, Batch 200] loss: 0.00962783198850957
[Epoch 20, Batch 300] loss: 0.024317561565039794
[Epoch 20, Batch 400] loss: 0.019826654632115605
[Epoch 20, Batch 500] loss: 0.014789020268835884
[Epoch 20, Batch 600] loss: 0.019556860796110413
[Epoch 20, Batch 700] loss: 0.012469057261805574
[Epoch 20, Batch 800] loss: 0.019630304994607287
[Epoch 20, Batch 900] loss: 0.02118798462974155
[Epoch 20, Batch 1000] loss: 0.014712655383264064
[Epoch 20, Batch 1100] loss: 0.022979780998393835
[Epoch 20, Batch 1200] loss: 0.015922191613717586
[Epoch 20, Batch 1300] loss: 0.01327183163321024
[Epoch 20, Batch 1400] loss: 0.013974715144358925
[Epoch 20, Batch 1500] loss: 0.02455669369599491
[Epoch 20, Batch 1600] loss: 0.012567626245509018
[Epoch 20, Batch 1700] loss: 0.017173034523657406
[Epoch 20, Batch 1800] loss: 0.0103990505631009
[Epoch 20, Batch 1900] loss: 0.01485530594298325
[Epoch 20, Batch 2000] loss: 0.014677302114941995
[Epoch 20, Batch 2100] loss: 0.01504764693989273
[Epoch 20, Batch 2200] loss: 0.016361220564176618
[Epoch 20, Batch 2300] loss: 0.014705842772436882
[Epoch 20, Batch 2400] loss: 0.021765499848143008
[Epoch 20, Batch 2500] loss: 0.015725141491620888
[Epoch 20, Batch 2600] loss: 0.013164127061490944
[Epoch 20, Batch 2700] loss: 0.018689158335037065
[Epoch 20, Batch 2800] loss: 0.01787178580001637
[Epoch 20, Batch 2900] loss: 0.018028307398963078
[Epoch 20, Batch 3000] loss: 0.02017313212792942
[Epoch 20, Batch 3100] loss: 0.009886943227083975
[Epoch 20, Batch 3200] loss: 0.027792448831751245
[Epoch 20, Batch 3300] loss: 0.026507497615311876
[Epoch 20, Batch 3400] loss: 0.01763006815457629
[Epoch 20, Batch 3500] loss: 0.016842941316972428
[Epoch 20, Batch 3600] loss: 0.02118267609701434
[Epoch 20, Batch 3700] loss: 0.010048563735235803
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0318
Overfitting: 0.0316
[Epoch 21, Batch 100] loss: 0.012838179587270133
[Epoch 21, Batch 200] loss: 0.011752564591697592
[Epoch 21, Batch 300] loss: 0.011548040959842182
[Epoch 21, Batch 400] loss: 0.017229070332468836
[Epoch 21, Batch 500] loss: 0.015461132861310034
[Epoch 21, Batch 600] loss: 0.02695744868822658
[Epoch 21, Batch 700] loss: 0.008392749657450621
[Epoch 21, Batch 800] loss: 0.017466571017030218
[Epoch 21, Batch 900] loss: 0.022955243148135195
[Epoch 21, Batch 1000] loss: 0.007711504781036637
[Epoch 21, Batch 1100] loss: 0.018020793161886105
[Epoch 21, Batch 1200] loss: 0.023459395546879022
[Epoch 21, Batch 1300] loss: 0.013038405278239225
[Epoch 21, Batch 1400] loss: 0.015772653677122436
[Epoch 21, Batch 1500] loss: 0.01253222472512789
[Epoch 21, Batch 1600] loss: 0.010252986139396398
[Epoch 21, Batch 1700] loss: 0.012047398713475559
[Epoch 21, Batch 1800] loss: 0.00908831815866506
[Epoch 21, Batch 1900] loss: 0.01074925934204657
[Epoch 21, Batch 2000] loss: 0.01576977973378234
[Epoch 21, Batch 2100] loss: 0.009570073830482216
[Epoch 21, Batch 2200] loss: 0.018906168698595138
[Epoch 21, Batch 2300] loss: 0.018950358631209384
[Epoch 21, Batch 2400] loss: 0.017006266480930208
[Epoch 21, Batch 2500] loss: 0.02021650671902535
[Epoch 21, Batch 2600] loss: 0.021843581074572283
[Epoch 21, Batch 2700] loss: 0.016703692304654395
[Epoch 21, Batch 2800] loss: 0.010138361894278206
[Epoch 21, Batch 2900] loss: 0.010331013496906962
[Epoch 21, Batch 3000] loss: 0.01412385719753729
[Epoch 21, Batch 3100] loss: 0.010023893574016255
[Epoch 21, Batch 3200] loss: 0.022349583572358823
[Epoch 21, Batch 3300] loss: 0.02202193729131068
[Epoch 21, Batch 3400] loss: 0.01653156240350654
[Epoch 21, Batch 3500] loss: 0.020443261625587184
[Epoch 21, Batch 3600] loss: 0.022624707254035457
[Epoch 21, Batch 3700] loss: 0.01377988280946738
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0314
Overfitting: 0.0310
[Epoch 22, Batch 100] loss: 0.015366404963478998
[Epoch 22, Batch 200] loss: 0.0073176287472870175
[Epoch 22, Batch 300] loss: 0.009694951938381564
[Epoch 22, Batch 400] loss: 0.019913384867941204
[Epoch 22, Batch 500] loss: 0.010545772027198837
[Epoch 22, Batch 600] loss: 0.0065635494711932555
[Epoch 22, Batch 700] loss: 0.014229826849841629
[Epoch 22, Batch 800] loss: 0.010355098125655786
[Epoch 22, Batch 900] loss: 0.013154629932669195
[Epoch 22, Batch 1000] loss: 0.014610040874595142
[Epoch 22, Batch 1100] loss: 0.010045241596017149
[Epoch 22, Batch 1200] loss: 0.015890403510256876
[Epoch 22, Batch 1300] loss: 0.013375053715808462
[Epoch 22, Batch 1400] loss: 0.009278350682434393
[Epoch 22, Batch 1500] loss: 0.008637699414803137
[Epoch 22, Batch 1600] loss: 0.026090564006735803
[Epoch 22, Batch 1700] loss: 0.014923644038626662
[Epoch 22, Batch 1800] loss: 0.01446775040429202
[Epoch 22, Batch 1900] loss: 0.017797559229061333
[Epoch 22, Batch 2000] loss: 0.009856045090082262
[Epoch 22, Batch 2100] loss: 0.016209669065574417
[Epoch 22, Batch 2200] loss: 0.011229513539401523
[Epoch 22, Batch 2300] loss: 0.012351647036948634
[Epoch 22, Batch 2400] loss: 0.040512173314882605
[Epoch 22, Batch 2500] loss: 0.010874094613700435
[Epoch 22, Batch 2600] loss: 0.018991431100330372
[Epoch 22, Batch 2700] loss: 0.022049061080597312
[Epoch 22, Batch 2800] loss: 0.01686050860727846
[Epoch 22, Batch 2900] loss: 0.010440828677019454
[Epoch 22, Batch 3000] loss: 0.010567810285665473
[Epoch 22, Batch 3100] loss: 0.011763235817797977
[Epoch 22, Batch 3200] loss: 0.017513654294234585
[Epoch 22, Batch 3300] loss: 0.013885880751986405
[Epoch 22, Batch 3400] loss: 0.017351267664125772
[Epoch 22, Batch 3500] loss: 0.01355193478439105
[Epoch 22, Batch 3600] loss: 0.015545722266560915
[Epoch 22, Batch 3700] loss: 0.014757605290633365
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0325
Overfitting: 0.0323
[Epoch 23, Batch 100] loss: 0.00989802270749351
[Epoch 23, Batch 200] loss: 0.006828455372851749
[Epoch 23, Batch 300] loss: 0.01095052392942307
[Epoch 23, Batch 400] loss: 0.02229493387403636
[Epoch 23, Batch 500] loss: 0.016569199729892715
[Epoch 23, Batch 600] loss: 0.009500224023668125
[Epoch 23, Batch 700] loss: 0.006692006007051532
[Epoch 23, Batch 800] loss: 0.009794335524202325
[Epoch 23, Batch 900] loss: 0.014262145645079726
[Epoch 23, Batch 1000] loss: 0.01061562272010633
[Epoch 23, Batch 1100] loss: 0.012302888105868987
[Epoch 23, Batch 1200] loss: 0.011661862223591016
[Epoch 23, Batch 1300] loss: 0.019630846136860784
[Epoch 23, Batch 1400] loss: 0.013831097322290589
[Epoch 23, Batch 1500] loss: 0.006505974035535473
[Epoch 23, Batch 1600] loss: 0.007934901321204961
[Epoch 23, Batch 1700] loss: 0.011612139939534244
[Epoch 23, Batch 1800] loss: 0.007639292996200311
[Epoch 23, Batch 1900] loss: 0.007190833391796332
[Epoch 23, Batch 2000] loss: 0.017533781211536734
[Epoch 23, Batch 2100] loss: 0.011727883135381489
[Epoch 23, Batch 2200] loss: 0.024265300544902856
[Epoch 23, Batch 2300] loss: 0.01498655950628745
[Epoch 23, Batch 2400] loss: 0.00897085570112722
[Epoch 23, Batch 2500] loss: 0.0133070441403288
[Epoch 23, Batch 2600] loss: 0.012122831565911839
[Epoch 23, Batch 2700] loss: 0.02451752412647693
[Epoch 23, Batch 2800] loss: 0.013931298652969416
[Epoch 23, Batch 2900] loss: 0.01733737760107033
[Epoch 23, Batch 3000] loss: 0.015997338627494175
[Epoch 23, Batch 3100] loss: 0.01997232786834502
[Epoch 23, Batch 3200] loss: 0.02401331641919569
[Epoch 23, Batch 3300] loss: 0.016505824315645443
[Epoch 23, Batch 3400] loss: 0.01620692286753183
[Epoch 23, Batch 3500] loss: 0.014111263294616948
[Epoch 23, Batch 3600] loss: 0.0213604176248009
[Epoch 23, Batch 3700] loss: 0.009972379313576312
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0303
Overfitting: 0.0302
Best model saved at epoch 23 with training loss: 0.0001
[Epoch 24, Batch 100] loss: 0.008997587066587584
[Epoch 24, Batch 200] loss: 0.009508329280870385
[Epoch 24, Batch 300] loss: 0.010085463417694882
[Epoch 24, Batch 400] loss: 0.013177940520354241
[Epoch 24, Batch 500] loss: 0.010290448400646711
[Epoch 24, Batch 600] loss: 0.009826919647894101
[Epoch 24, Batch 700] loss: 0.012528704143751384
[Epoch 24, Batch 800] loss: 0.017890540632652118
[Epoch 24, Batch 900] loss: 0.00754429626995261
[Epoch 24, Batch 1000] loss: 0.010077972753206267
[Epoch 24, Batch 1100] loss: 0.01598971469569733
[Epoch 24, Batch 1200] loss: 0.012294270923739532
[Epoch 24, Batch 1300] loss: 0.0189823144391994
[Epoch 24, Batch 1400] loss: 0.013815459136403661
[Epoch 24, Batch 1500] loss: 0.010693273299111752
[Epoch 24, Batch 1600] loss: 0.016403690838815238
[Epoch 24, Batch 1700] loss: 0.01321208460829439
[Epoch 24, Batch 1800] loss: 0.012318729680955584
[Epoch 24, Batch 1900] loss: 0.012815411697056333
[Epoch 24, Batch 2000] loss: 0.009754430311004399
[Epoch 24, Batch 2100] loss: 0.011275802460986598
[Epoch 24, Batch 2200] loss: 0.01696893163380082
[Epoch 24, Batch 2300] loss: 0.007408184667265232
[Epoch 24, Batch 2400] loss: 0.0089799000957737
[Epoch 24, Batch 2500] loss: 0.01417601817058312
[Epoch 24, Batch 2600] loss: 0.022604964625443244
[Epoch 24, Batch 2700] loss: 0.010955513868502749
[Epoch 24, Batch 2800] loss: 0.02447431031256201
[Epoch 24, Batch 2900] loss: 0.011661102536927502
[Epoch 24, Batch 3000] loss: 0.009986656362098074
[Epoch 24, Batch 3100] loss: 0.01277606221523456
[Epoch 24, Batch 3200] loss: 0.011115307570798904
[Epoch 24, Batch 3300] loss: 0.017319897089755613
[Epoch 24, Batch 3400] loss: 0.008931559021748399
[Epoch 24, Batch 3500] loss: 0.012210032944585692
[Epoch 24, Batch 3600] loss: 0.010562277743592858
[Epoch 24, Batch 3700] loss: 0.015232798658244064
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0356
Overfitting: 0.0353
qt.qpa.xcb: X server does not support XInput 2
+++FINAL STATS++++
Training Loss 0.00022083720532731
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Test set to find Test loss for overfitting
 Testing loss : 0.0356
Calculated Overfitting : 0.0353
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9890
Total time taken for hyperparameter tuning and evaluation: 4:53:46
/home/ahussain/PycharmProjects/optunaNew/Median_pruner_Testing.py:493: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.

Traceback (most recent call last):
  File "/home/ahussain/PycharmProjects/optunaNew/Median_pruner_Testing.py", line 500, in <module>
    run_optuna(num_samples=NUM_SAMPLES)
  File "/home/ahussain/PycharmProjects/optunaNew/Median_pruner_Testing.py", line 495, in run_optuna
    fig2.write_image("IResults/TPE/Ranges_dec_10/timeline_Split5_median_ranges_AAG.png")
  File "/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/plotly/basedatatypes.py", line 3835, in write_image
    return pio.write_image(self, *args, **kwargs)
  File "/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/plotly/io/_kaleido.py", line 296, in write_image
    path.write_bytes(img_data)
  File "/usr/lib/python3.8/pathlib.py", line 1245, in write_bytes
    with self.open(mode='wb') as f:
  File "/usr/lib/python3.8/pathlib.py", line 1222, in open
    return io.open(self, mode, buffering, encoding, errors, newline,
  File "/usr/lib/python3.8/pathlib.py", line 1078, in _opener
    return self._accessor.open(self, flags, mode)
FileNotFoundError: [Errno 2] No such file or directory: 'IResults/TPE/Ranges_dec_10/timeline_Split5_median_ranges_AAG.png'

Process finished with exit code 1

