700] loss: 0.07835642403922975
**STATS for Epoch 22** : 
Average training loss: 0.0044
Average validation loss: 0.0923
Validation Accuracy: 0.9735
Overfitting: 0.0879
Best model saved at epoch 22 with validation loss: 0.0923
[Epoch 23, Batch 100] loss: 0.08634730181656777
[Epoch 23, Batch 200] loss: 0.07608300149440765
[Epoch 23, Batch 300] loss: 0.07464823151938617
[Epoch 23, Batch 400] loss: 0.08668720564804971
[Epoch 23, Batch 500] loss: 0.08414906622841954
[Epoch 23, Batch 600] loss: 0.0811009067762643
[Epoch 23, Batch 700] loss: 0.08645817369222641
**STATS for Epoch 23** : 
Average training loss: 0.0052
Average validation loss: 0.0887
Validation Accuracy: 0.9746
Overfitting: 0.0835
Best model saved at epoch 23 with validation loss: 0.0887
[Epoch 24, Batch 100] loss: 0.08739554101601243
[Epoch 24, Batch 200] loss: 0.08349252631887794
[Epoch 24, Batch 300] loss: 0.07323030340485275
[Epoch 24, Batch 400] loss: 0.08191400103271007
[Epoch 24, Batch 500] loss: 0.08091859210282565
[Epoch 24, Batch 600] loss: 0.07727310433983803
[Epoch 24, Batch 700] loss: 0.0713488849811256
**STATS for Epoch 24** : 
Average training loss: 0.0056
Average validation loss: 0.0907
Validation Accuracy: 0.9735
Overfitting: 0.0851
Fold 5 validation loss: 0.0907
Mean validation loss across all folds for Trial 1 is 0.0909 with trial config:  l1: 256, l2: 64, lr: 0.0002051338263087451, batch_size: 64
[I 2024-12-10 04:58:42,397] Trial 0 finished with value: 0.09092029184350706 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0002051338263087451, 'batch_size': 64}. Best is trial 0 with value: 0.09092029184350706.

Selected Hyperparameters for Trial 2:
  l1: 256, l2: 64, lr: 0.0002310201887845295, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3002007937431337
[Epoch 1, Batch 200] loss: 2.296467545032501
[Epoch 1, Batch 300] loss: 2.29378212928772
[Epoch 1, Batch 400] loss: 2.290189130306244
[Epoch 1, Batch 500] loss: 2.2858749079704284
[Epoch 1, Batch 600] loss: 2.2813247799873353
[Epoch 1, Batch 700] loss: 2.2737796449661256
**STATS for Epoch 1** : 
Average training loss: 0.1512
Average validation loss: 2.2659
Validation Accuracy: 0.2680
Overfitting: 2.1147
Best model saved at epoch 1 with validation loss: 2.2659
[Epoch 2, Batch 100] loss: 2.2607155013084412
[Epoch 2, Batch 200] loss: 2.2485386514663697
[Epoch 2, Batch 300] loss: 2.231530659198761
[Epoch 2, Batch 400] loss: 2.2019264483451844
[Epoch 2, Batch 500] loss: 2.1652284336090086
[Epoch 2, Batch 600] loss: 2.0970121574401857
[Epoch 2, Batch 700] loss: 1.9808222472667694
**STATS for Epoch 2** : 
Average training loss: 0.1232
Average validation loss: 1.7861
Validation Accuracy: 0.5803
Overfitting: 1.6629
Best model saved at epoch 2 with validation loss: 1.7861
[Epoch 3, Batch 100] loss: 1.6587727761268616
[Epoch 3, Batch 200] loss: 1.3096734166145325
[Epoch 3, Batch 300] loss: 0.9831510275602341
[Epoch 3, Batch 400] loss: 0.7906617319583893
[Epoch 3, Batch 500] loss: 0.6351355147361756
[Epoch 3, Batch 600] loss: 0.5611660042405129
[Epoch 3, Batch 700] loss: 0.5358288711309434
**STATS for Epoch 3** : 
Average training loss: 0.0317
Average validation loss: 0.4661
Validation Accuracy: 0.8630
Overfitting: 0.4345
Best model saved at epoch 3 with validation loss: 0.4661
[Epoch 4, Batch 100] loss: 0.4517490814626217
[Epoch 4, Batch 200] loss: 0.45162307828664777
[Epoch 4, Batch 300] loss: 0.4044785761833191
[Epoch 4, Batch 400] loss: 0.400842794328928
[Epoch 4, Batch 500] loss: 0.39067956775426865
[Epoch 4, Batch 600] loss: 0.3720911115407944
[Epoch 4, Batch 700] loss: 0.36108616113662717
**STATS for Epoch 4** : 
Average training loss: 0.0234
Average validation loss: 0.3334
Validation Accuracy: 0.8999
Overfitting: 0.3100
Best model saved at epoch 4 with validation loss: 0.3334
[Epoch 5, Batch 100] loss: 0.34677896946668624
[Epoch 5, Batch 200] loss: 0.33126769319176674
[Epoch 5, Batch 300] loss: 0.3050655418634415
[Epoch 5, Batch 400] loss: 0.2958023199439049
[Epoch 5, Batch 500] loss: 0.30470123037695884
[Epoch 5, Batch 600] loss: 0.29407326474785805
[Epoch 5, Batch 700] loss: 0.2834747977554798
**STATS for Epoch 5** : 
Average training loss: 0.0198
Average validation loss: 0.2619
Validation Accuracy: 0.9199
Overfitting: 0.2421
Best model saved at epoch 5 with validation loss: 0.2619
[Epoch 6, Batch 100] loss: 0.2747699873894453
[Epoch 6, Batch 200] loss: 0.25276342786848544
[Epoch 6, Batch 300] loss: 0.24649330526590346
[Epoch 6, Batch 400] loss: 0.23961699910461903
[Epoch 6, Batch 500] loss: 0.2513584782928228
[Epoch 6, Batch 600] loss: 0.24684381164610386
[Epoch 6, Batch 700] loss: 0.22923729330301285
**STATS for Epoch 6** : 
Average training loss: 0.0162
Average validation loss: 0.2161
Validation Accuracy: 0.9382
Overfitting: 0.1998
Best model saved at epoch 6 with validation loss: 0.2161
[Epoch 7, Batch 100] loss: 0.2258089703321457
[Epoch 7, Batch 200] loss: 0.24265611805021764
[Epoch 7, Batch 300] loss: 0.2032579092681408
[Epoch 7, Batch 400] loss: 0.20489349689334632
[Epoch 7, Batch 500] loss: 0.19716109469532966
[Epoch 7, Batch 600] loss: 0.20493346460163595
[Epoch 7, Batch 700] loss: 0.200400129891932
**STATS for Epoch 7** : 
Average training loss: 0.0117
Average validation loss: 0.1893
Validation Accuracy: 0.9433
Overfitting: 0.1776
Best model saved at epoch 7 with validation loss: 0.1893
[Epoch 8, Batch 100] loss: 0.18543754234910012
[Epoch 8, Batch 200] loss: 0.19170160442590714
[Epoch 8, Batch 300] loss: 0.19453124653548
[Epoch 8, Batch 400] loss: 0.18463223930448294
[Epoch 8, Batch 500] loss: 0.17338750593364238
[Epoch 8, Batch 600] loss: 0.1728753501176834
[Epoch 8, Batch 700] loss: 0.1713153610378504
**STATS for Epoch 8** : 
Average training loss: 0.0113
Average validation loss: 0.1537
Validation Accuracy: 0.9550
Overfitting: 0.1424
Best model saved at epoch 8 with validation loss: 0.1537
[Epoch 9, Batch 100] loss: 0.1722492791712284
[Epoch 9, Batch 200] loss: 0.17100060641765594
[Epoch 9, Batch 300] loss: 0.1686601846292615
[Epoch 9, Batch 400] loss: 0.15453595522791147
[Epoch 9, Batch 500] loss: 0.15762409579008818
[Epoch 9, Batch 600] loss: 0.15724441453814506
[Epoch 9, Batch 700] loss: 0.15580511901527644
**STATS for Epoch 9** : 
Average training loss: 0.0095
Average validation loss: 0.1434
Validation Accuracy: 0.9567
Overfitting: 0.1340
Best model saved at epoch 9 with validation loss: 0.1434
[Epoch 10, Batch 100] loss: 0.13970130087807775
[Epoch 10, Batch 200] loss: 0.15077149886637925
[Epoch 10, Batch 300] loss: 0.1566291819885373
[Epoch 10, Batch 400] loss: 0.1471341211348772
[Epoch 10, Batch 500] loss: 0.1431681769527495
[Epoch 10, Batch 600] loss: 0.13914907228201628
[Epoch 10, Batch 700] loss: 0.14085321124643088
**STATS for Epoch 10** : 
Average training loss: 0.0096
Average validation loss: 0.1325
Validation Accuracy: 0.9600
Overfitting: 0.1229
Best model saved at epoch 10 with validation loss: 0.1325
[Epoch 11, Batch 100] loss: 0.13274991082027554
[Epoch 11, Batch 200] loss: 0.1278767246566713
[Epoch 11, Batch 300] loss: 0.1341837713494897
[Epoch 11, Batch 400] loss: 0.13207846077159047
[Epoch 11, Batch 500] loss: 0.14142982747405766
[Epoch 11, Batch 600] loss: 0.14099573258310558
[Epoch 11, Batch 700] loss: 0.12575011420994997
**STATS for Epoch 11** : 
Average training loss: 0.0090
Average validation loss: 0.1191
Validation Accuracy: 0.9645
Overfitting: 0.1101
Best model saved at epoch 11 with validation loss: 0.1191
[Epoch 12, Batch 100] loss: 0.12757682448253035
[Epoch 12, Batch 200] loss: 0.11851103160530328
[Epoch 12, Batch 300] loss: 0.13252800431102515
[Epoch 12, Batch 400] loss: 0.12306240428239107
[Epoch 12, Batch 500] loss: 0.12948018414899706
[Epoch 12, Batch 600] loss: 0.12044316068291665
[Epoch 12, Batch 700] loss: 0.12354999655857682
**STATS for Epoch 12** : 
Average training loss: 0.0069
Average validation loss: 0.1110
Validation Accuracy: 0.9664
Overfitting: 0.1041
Best model saved at epoch 12 with validation loss: 0.1110
[Epoch 13, Batch 100] loss: 0.11334235940128565
[Epoch 13, Batch 200] loss: 0.12109075630083681
[Epoch 13, Batch 300] loss: 0.11110918562859297
[Epoch 13, Batch 400] loss: 0.12157202523201704
[Epoch 13, Batch 500] loss: 0.1217609760351479
[Epoch 13, Batch 600] loss: 0.11203846829943359
[Epoch 13, Batch 700] loss: 0.12281245717778802
**STATS for Epoch 13** : 
Average training loss: 0.0066
Average validation loss: 0.1036
Validation Accuracy: 0.9673
Overfitting: 0.0970
Best model saved at epoch 13 with validation loss: 0.1036
[Epoch 14, Batch 100] loss: 0.10989312576130032
[Epoch 14, Batch 200] loss: 0.1067360688559711
[Epoch 14, Batch 300] loss: 0.1051343918312341
[Epoch 14, Batch 400] loss: 0.11290053086355328
[Epoch 14, Batch 500] loss: 0.11654833113774657
[Epoch 14, Batch 600] loss: 0.10413263829424978
[Epoch 14, Batch 700] loss: 0.11001710787415504
**STATS for Epoch 14** : 
Average training loss: 0.0065
Average validation loss: 0.1009
Validation Accuracy: 0.9678
Overfitting: 0.0945
Best model saved at epoch 14 with validation loss: 0.1009
[Epoch 15, Batch 100] loss: 0.1061460766196251
[Epoch 15, Batch 200] loss: 0.11886766768991947
[Epoch 15, Batch 300] loss: 0.10773822691291571
[Epoch 15, Batch 400] loss: 0.09941336629912258
[Epoch 15, Batch 500] loss: 0.10811751969158649
[Epoch 15, Batch 600] loss: 0.1001256718300283
[Epoch 15, Batch 700] loss: 0.09120330270379781
**STATS for Epoch 15** : 
Average training loss: 0.0060
Average validation loss: 0.0988
Validation Accuracy: 0.9692
Overfitting: 0.0929
Best model saved at epoch 15 with validation loss: 0.0988
[Epoch 16, Batch 100] loss: 0.09656788675114512
[Epoch 16, Batch 200] loss: 0.10702980061993003
[Epoch 16, Batch 300] loss: 0.10191810925491154
[Epoch 16, Batch 400] loss: 0.09867392368614673
[Epoch 16, Batch 500] loss: 0.09957689214497804
[Epoch 16, Batch 600] loss: 0.09780398641712963
[Epoch 16, Batch 700] loss: 0.09468834036029876
**STATS for Epoch 16** : 
Average training loss: 0.0053
Average validation loss: 0.0899
Validation Accuracy: 0.9720
Overfitting: 0.0846
Best model saved at epoch 16 with validation loss: 0.0899
[Epoch 17, Batch 100] loss: 0.09356609932146967
[Epoch 17, Batch 200] loss: 0.09860501680523157
[Epoch 17, Batch 300] loss: 0.09433622311800718
[Epoch 17, Batch 400] loss: 0.08241687857080252
[Epoch 17, Batch 500] loss: 0.09310511788353323
[Epoch 17, Batch 600] loss: 0.09938605133444071
[Epoch 17, Batch 700] loss: 0.09050227938219906
**STATS for Epoch 17** : 
Average training loss: 0.0067
Average validation loss: 0.0853
Validation Accuracy: 0.9738
Overfitting: 0.0786
Best model saved at epoch 17 with validation loss: 0.0853
[Epoch 18, Batch 100] loss: 0.09398702403530479
[Epoch 18, Batch 200] loss: 0.08637270433828234
[Epoch 18, Batch 300] loss: 0.08561335696838795
[Epoch 18, Batch 400] loss: 0.07635541316121816
[Epoch 18, Batch 500] loss: 0.09092972326092422
[Epoch 18, Batch 600] loss: 0.09141989532858133
[Epoch 18, Batch 700] loss: 0.08505436452105641
**STATS for Epoch 18** : 
Average training loss: 0.0077
Average validation loss: 0.0858
Validation Accuracy: 0.9731
Overfitting: 0.0781
[Epoch 19, Batch 100] loss: 0.07888538647443057
[Epoch 19, Batch 200] loss: 0.08080920914188028
[Epoch 19, Batch 300] loss: 0.09078269267454743
[Epoch 19, Batch 400] loss: 0.08354980543255806
[Epoch 19, Batch 500] loss: 0.09569999948143959
[Epoch 19, Batch 600] loss: 0.08209929067641497
[Epoch 19, Batch 700] loss: 0.08741841511800885
**STATS for Epoch 19** : 
Average training loss: 0.0055
Average validation loss: 0.0815
Validation Accuracy: 0.9748
Overfitting: 0.0760
Best model saved at epoch 19 with validation loss: 0.0815
[Epoch 20, Batch 100] loss: 0.07748075284995139
[Epoch 20, Batch 200] loss: 0.08931217620149255
[Epoch 20, Batch 300] loss: 0.08413046007044614
[Epoch 20, Batch 400] loss: 0.07380457145161927
[Epoch 20, Batch 500] loss: 0.07885475962422789
[Epoch 20, Batch 600] loss: 0.07876084556803108
[Epoch 20, Batch 700] loss: 0.0918585580214858
**STATS for Epoch 20** : 
Average training loss: 0.0053
Average validation loss: 0.0778
Validation Accuracy: 0.9762
Overfitting: 0.0725
Best model saved at epoch 20 with validation loss: 0.0778
[Epoch 21, Batch 100] loss: 0.08216979117132724
[Epoch 21, Batch 200] loss: 0.07704098145477474
[Epoch 21, Batch 300] loss: 0.07431825881358237
[Epoch 21, Batch 400] loss: 0.07937026513740421
[Epoch 21, Batch 500] loss: 0.0841392820328474
[Epoch 21, Batch 600] loss: 0.0745682512037456
[Epoch 21, Batch 700] loss: 0.07652307423762977
**STATS for Epoch 21** : 
Average training loss: 0.0065
Average validation loss: 0.0772
Validation Accuracy: 0.9759
Overfitting: 0.0707
Best model saved at epoch 21 with validation loss: 0.0772
[Epoch 22, Batch 100] loss: 0.07557366509921849
[Epoch 22, Batch 200] loss: 0.07161566192284226
[Epoch 22, Batch 300] loss: 0.0816496482398361
[Epoch 22, Batch 400] loss: 0.07306018996052444
[Epoch 22, Batch 500] loss: 0.07825745255686342
[Epoch 22, Batch 600] loss: 0.07249643152114003
[Epoch 22, Batch 700] loss: 0.08557062309235335
**STATS for Epoch 22** : 
Average training loss: 0.0043
Average validation loss: 0.0753
Validation Accuracy: 0.9758
Overfitting: 0.0709
Best model saved at epoch 22 with validation loss: 0.0753
[Epoch 23, Batch 100] loss: 0.07037608405575156
[Epoch 23, Batch 200] loss: 0.0743133732303977
[Epoch 23, Batch 300] loss: 0.06940153842791914
[Epoch 23, Batch 400] loss: 0.07149493486620485
[Epoch 23, Batch 500] loss: 0.0706470002932474
[Epoch 23, Batch 600] loss: 0.07862402683123947
[Epoch 23, Batch 700] loss: 0.07970438080839813
**STATS for Epoch 23** : 
Average training loss: 0.0051
Average validation loss: 0.0705
Validation Accuracy: 0.9781
Overfitting: 0.0654
Best model saved at epoch 23 with validation loss: 0.0705
[Epoch 24, Batch 100] loss: 0.07195375978946686
[Epoch 24, Batch 200] loss: 0.0719890163373202
[Epoch 24, Batch 300] loss: 0.07635653720237315
[Epoch 24, Batch 400] loss: 0.06698160955682397
[Epoch 24, Batch 500] loss: 0.0689587414637208
[Epoch 24, Batch 600] loss: 0.07237004534341394
[Epoch 24, Batch 700] loss: 0.06700598936062306
**STATS for Epoch 24** : 
Average training loss: 0.0048
Average validation loss: 0.0704
Validation Accuracy: 0.9783
Overfitting: 0.0656
Best model saved at epoch 24 with validation loss: 0.0704
Fold 1 validation loss: 0.0704
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.3057330679893493
[Epoch 1, Batch 200] loss: 2.2944433641433717
[Epoch 1, Batch 300] loss: 2.2830620503425596
[Epoch 1, Batch 400] loss: 2.272041447162628
[Epoch 1, Batch 500] loss: 2.253621053695679
[Epoch 1, Batch 600] loss: 2.2316452193260194
[Epoch 1, Batch 700] loss: 2.196585953235626
**STATS for Epoch 1** : 
Average training loss: 0.1440
Average validation loss: 2.1487
Validation Accuracy: 0.4099
Overfitting: 2.0047
Best model saved at epoch 1 with validation loss: 2.1487
[Epoch 2, Batch 100] loss: 2.108585650920868
[Epoch 2, Batch 200] loss: 1.9849336576461791
[Epoch 2, Batch 300] loss: 1.7753087556362153
[Epoch 2, Batch 400] loss: 1.4600055515766144
[Epoch 2, Batch 500] loss: 1.1183757370710372
[Epoch 2, Batch 600] loss: 0.8779334104061127
[Epoch 2, Batch 700] loss: 0.7270441716909408
**STATS for Epoch 2** : 
Average training loss: 0.0452
Average validation loss: 0.6652
Validation Accuracy: 0.8043
Overfitting: 0.6199
Best model saved at epoch 2 with validation loss: 0.6652
[Epoch 3, Batch 100] loss: 0.612482753098011
[Epoch 3, Batch 200] loss: 0.5608847627043724
[Epoch 3, Batch 300] loss: 0.5067336690425873
[Epoch 3, Batch 400] loss: 0.4636897899210453
[Epoch 3, Batch 500] loss: 0.46083696573972704
[Epoch 3, Batch 600] loss: 0.4181430435180664
[Epoch 3, Batch 700] loss: 0.39768524542450906
**STATS for Epoch 3** : 
Average training loss: 0.0267
Average validation loss: 0.4071
Validation Accuracy: 0.8842
Overfitting: 0.3804
Best model saved at epoch 3 with validation loss: 0.4071
[Epoch 4, Batch 100] loss: 0.39505550429224967
[Epoch 4, Batch 200] loss: 0.37874049246311187
[Epoch 4, Batch 300] loss: 0.36511083602905275
[Epoch 4, Batch 400] loss: 0.3419779460132122
[Epoch 4, Batch 500] loss: 0.35066192731261253
[Epoch 4, Batch 600] loss: 0.3390807069838047
[Epoch 4, Batch 700] loss: 0.3081205400824547
**STATS for Epoch 4** : 
Average training loss: 0.0193
Average validation loss: 0.3267
Validation Accuracy: 0.9060
Overfitting: 0.3074
Best model saved at epoch 4 with validation loss: 0.3267
[Epoch 5, Batch 100] loss: 0.309686062335968
[Epoch 5, Batch 200] loss: 0.29979089707136153
[Epoch 5, Batch 300] loss: 0.2999969332665205
[Epoch 5, Batch 400] loss: 0.2996104633808136
[Epoch 5, Batch 500] loss: 0.27296400047838687
[Epoch 5, Batch 600] loss: 0.2611755744367838
[Epoch 5, Batch 700] loss: 0.2776662590354681
**STATS for Epoch 5** : 
Average training loss: 0.0180
Average validation loss: 0.2759
Validation Accuracy: 0.9203
Overfitting: 0.2579
Best model saved at epoch 5 with validation loss: 0.2759
[Epoch 6, Batch 100] loss: 0.26212021969258786
[Epoch 6, Batch 200] loss: 0.23701308615505695
[Epoch 6, Batch 300] loss: 0.25730196967720986
[Epoch 6, Batch 400] loss: 0.2595637960731983
[Epoch 6, Batch 500] loss: 0.22629555985331534
[Epoch 6, Batch 600] loss: 0.22462902300059795
[Epoch 6, Batch 700] loss: 0.22812421515583992
**STATS for Epoch 6** : 
Average training loss: 0.0161
Average validation loss: 0.2424
Validation Accuracy: 0.9289
Overfitting: 0.2263
Best model saved at epoch 6 with validation loss: 0.2424
[Epoch 7, Batch 100] loss: 0.20138772912323474
[Epoch 7, Batch 200] loss: 0.2259898304194212
[Epoch 7, Batch 300] loss: 0.2153050533682108
[Epoch 7, Batch 400] loss: 0.20966814190149308
[Epoch 7, Batch 500] loss: 0.21252893704921008
[Epoch 7, Batch 600] loss: 0.20369103971868754
[Epoch 7, Batch 700] loss: 0.20044448889791966
**STATS for Epoch 7** : 
Average training loss: 0.0127
Average validation loss: 0.2104
Validation Accuracy: 0.9359
Overfitting: 0.1977
Best model saved at epoch 7 with validation loss: 0.2104
[Epoch 8, Batch 100] loss: 0.1836802938207984
[Epoch 8, Batch 200] loss: 0.18709928832948208
[Epoch 8, Batch 300] loss: 0.18482012346386908
[Epoch 8, Batch 400] loss: 0.18381455164402724
[Epoch 8, Batch 500] loss: 0.18495320100337267
[Epoch 8, Batch 600] loss: 0.1830797666311264
[Epoch 8, Batch 700] loss: 0.1858886742591858
**STATS for Epoch 8** : 
Average training loss: 0.0105
Average validation loss: 0.1863
Validation Accuracy: 0.9423
Overfitting: 0.1759
Best model saved at epoch 8 with validation loss: 0.1863
[Epoch 9, Batch 100] loss: 0.1728784913942218
[Epoch 9, Batch 200] loss: 0.16937191125005482
[Epoch 9, Batch 300] loss: 0.16501406248658895
[Epoch 9, Batch 400] loss: 0.15846921101212502
[Epoch 9, Batch 500] loss: 0.1647342948615551
[Epoch 9, Batch 600] loss: 0.1493271106854081
[Epoch 9, Batch 700] loss: 0.15532165925949812
**STATS for Epoch 9** : 
Average training loss: 0.0110
Average validation loss: 0.1684
Validation Accuracy: 0.9497
Overfitting: 0.1575
Best model saved at epoch 9 with validation loss: 0.1684
[Epoch 10, Batch 100] loss: 0.14530653618276118
[Epoch 10, Batch 200] loss: 0.16293508633971215
[Epoch 10, Batch 300] loss: 0.14950868457555772
[Epoch 10, Batch 400] loss: 0.13737914457917214
[Epoch 10, Batch 500] loss: 0.1388714005239308
[Epoch 10, Batch 600] loss: 0.1499079080671072
[Epoch 10, Batch 700] loss: 0.13969942186027764
**STATS for Epoch 10** : 
Average training loss: 0.0095
Average validation loss: 0.1542
Validation Accuracy: 0.9537
Overfitting: 0.1447
Best model saved at epoch 10 with validation loss: 0.1542
[Epoch 11, Batch 100] loss: 0.13896730829030277
[Epoch 11, Batch 200] loss: 0.12683485163375735
[Epoch 11, Batch 300] loss: 0.1284046322479844
[Epoch 11, Batch 400] loss: 0.13599899189546705
[Epoch 11, Batch 500] loss: 0.1293486581929028
[Epoch 11, Batch 600] loss: 0.14423991907387973
[Epoch 11, Batch 700] loss: 0.13017178747802974
**STATS for Epoch 11** : 
Average training loss: 0.0090
Average validation loss: 0.1481
Validation Accuracy: 0.9542
Overfitting: 0.1390
Best model saved at epoch 11 with validation loss: 0.1481
[Epoch 12, Batch 100] loss: 0.1333442885428667
[Epoch 12, Batch 200] loss: 0.13136749304831027
[Epoch 12, Batch 300] loss: 0.12416629411280156
[Epoch 12, Batch 400] loss: 0.12664898676797748
[Epoch 12, Batch 500] loss: 0.10589093087241054
[Epoch 12, Batch 600] loss: 0.10869937425479292
[Epoch 12, Batch 700] loss: 0.12925442308187485
**STATS for Epoch 12** : 
Average training loss: 0.0089
Average validation loss: 0.1409
Validation Accuracy: 0.9578
Overfitting: 0.1320
Best model saved at epoch 12 with validation loss: 0.1409
[Epoch 13, Batch 100] loss: 0.1228981275856495
[Epoch 13, Batch 200] loss: 0.11756287569180131
[Epoch 13, Batch 300] loss: 0.11114172112196684
[Epoch 13, Batch 400] loss: 0.11347321942448615
[Epoch 13, Batch 500] loss: 0.11476461408659816
[Epoch 13, Batch 600] loss: 0.11254245748743415
[Epoch 13, Batch 700] loss: 0.1118822592869401
**STATS for Epoch 13** : 
Average training loss: 0.0081
Average validation loss: 0.1310
Validation Accuracy: 0.9594
Overfitting: 0.1229
Best model saved at epoch 13 with validation loss: 0.1310
[Epoch 14, Batch 100] loss: 0.10582920517772436
[Epoch 14, Batch 200] loss: 0.1221559451520443
[Epoch 14, Batch 300] loss: 0.10432381819933653
[Epoch 14, Batch 400] loss: 0.10784327676519752
[Epoch 14, Batch 500] loss: 0.10636390995234252
[Epoch 14, Batch 600] loss: 0.11219496499747038
[Epoch 14, Batch 700] loss: 0.10130574103444814
**STATS for Epoch 14** : 
Average training loss: 0.0069
Average validation loss: 0.1269
Validation Accuracy: 0.9603
Overfitting: 0.1200
Best model saved at epoch 14 with validation loss: 0.1269
[Epoch 15, Batch 100] loss: 0.10614890614524483
[Epoch 15, Batch 200] loss: 0.111311239246279
[Epoch 15, Batch 300] loss: 0.09843523249030113
[Epoch 15, Batch 400] loss: 0.09157435927540064
[Epoch 15, Batch 500] loss: 0.09322735289111733
[Epoch 15, Batch 600] loss: 0.11076534559950232
[Epoch 15, Batch 700] loss: 0.10335998309776187
**STATS for Epoch 15** : 
Average training loss: 0.0072
Average validation loss: 0.1165
Validation Accuracy: 0.9647
Overfitting: 0.1093
Best model saved at epoch 15 with validation loss: 0.1165
[Epoch 16, Batch 100] loss: 0.10304204056970775
[Epoch 16, Batch 200] loss: 0.09267270032316446
[Epoch 16, Batch 300] loss: 0.08854709945619106
[Epoch 16, Batch 400] loss: 0.11404333885759116
[Epoch 16, Batch 500] loss: 0.09416431032121181
[Epoch 16, Batch 600] loss: 0.09639369076117874
[Epoch 16, Batch 700] loss: 0.10353160038590431
**STATS for Epoch 16** : 
Average training loss: 0.0052
Average validation loss: 0.1216
Validation Accuracy: 0.9617
Overfitting: 0.1163
[Epoch 17, Batch 100] loss: 0.09037989598698914
[Epoch 17, Batch 200] loss: 0.09190188949927687
[Epoch 17, Batch 300] loss: 0.09419284474104643
[Epoch 17, Batch 400] loss: 0.08635095222853124
[Epoch 17, Batch 500] loss: 0.0986783913243562
[Epoch 17, Batch 600] loss: 0.09362956686876714
[Epoch 17, Batch 700] loss: 0.09754488985054195
**STATS for Epoch 17** : 
Average training loss: 0.0064
Average validation loss: 0.1096
Validation Accuracy: 0.9665
Overfitting: 0.1032
Best model saved at epoch 17 with validation loss: 0.1096
[Epoch 18, Batch 100] loss: 0.08794082334265113
[Epoch 18, Batch 200] loss: 0.09066020420752466
[Epoch 18, Batch 300] loss: 0.08334829120896757
[Epoch 18, Batch 400] loss: 0.09699074362404644
[Epoch 18, Batch 500] loss: 0.08332015147432685
[Epoch 18, Batch 600] loss: 0.0847015729919076
[Epoch 18, Batch 700] loss: 0.09287697914987803
**STATS for Epoch 18** : 
Average training loss: 0.0060
Average validation loss: 0.1038
Validation Accuracy: 0.9680
Overfitting: 0.0978
Best model saved at epoch 18 with validation loss: 0.1038
[Epoch 19, Batch 100] loss: 0.10044220106676222
[Epoch 19, Batch 200] loss: 0.08888570671901107
[Epoch 19, Batch 300] loss: 0.08083407384809106
[Epoch 19, Batch 400] loss: 0.07324091841466725
[Epoch 19, Batch 500] loss: 0.08196910650469363
[Epoch 19, Batch 600] loss: 0.08806248319800943
[Epoch 19, Batch 700] loss: 0.08512745408341288
**STATS for Epoch 19** : 
Average training loss: 0.0052
Average validation loss: 0.0995
Validation Accuracy: 0.9692
Overfitting: 0.0943
Best model saved at epoch 19 with validation loss: 0.0995
[Epoch 20, Batch 100] loss: 0.0839991366211325
[Epoch 20, Batch 200] loss: 0.0768579438328743
[Epoch 20, Batch 300] loss: 0.07965302812866866
[Epoch 20, Batch 400] loss: 0.08946820912882686
[Epoch 20, Batch 500] loss: 0.0912357119936496
[Epoch 20, Batch 600] loss: 0.0746787784434855
[Epoch 20, Batch 700] loss: 0.07988198067992926
**STATS for Epoch 20** : 
Average training loss: 0.0049
Average validation loss: 0.0957
Validation Accuracy: 0.9700
Overfitting: 0.0908
Best model saved at epoch 20 with validation loss: 0.0957
[Epoch 21, Batch 100] loss: 0.08397289855405689
[Epoch 21, Batch 200] loss: 0.08769792975857854
[Epoch 21, Batch 300] loss: 0.0836624964978546
[Epoch 21, Batch 400] loss: 0.06954465820454062
[Epoch 21, Batch 500] loss: 0.08784662139602005
[Epoch 21, Batch 600] loss: 0.06986268715001642
[Epoch 21, Batch 700] loss: 0.07491699105128646
**STATS for Epoch 21** : 
Average training loss: 0.0044
Average validation loss: 0.0968
Validation Accuracy: 0.9697
Overfitting: 0.0924
[Epoch 22, Batch 100] loss: 0.07671206816099584
[Epoch 22, Batch 200] loss: 0.07900202677585184
[Epoch 22, Batch 300] loss: 0.07485233794897794
[Epoch 22, Batch 400] loss: 0.06948465511202812
[Epoch 22, Batch 500] loss: 0.07553969820030033
[Epoch 22, Batch 600] loss: 0.06569754038471728
[Epoch 22, Batch 700] loss: 0.07597126952372492
**STATS for Epoch 22** : 
Average training loss: 0.0058
Average validation loss: 0.0963
Validation Accuracy: 0.9712
Overfitting: 0.0905
[Epoch 23, Batch 100] loss: 0.08149218102917075
[Epoch 23, Batch 200] loss: 0.07369340928271413
[Epoch 23, Batch 300] loss: 0.07510485007427632
[Epoch 23, Batch 400] loss: 0.07148787273094058
[Epoch 23, Batch 500] loss: 0.06103116999845952
[Epoch 23, Batch 600] loss: 0.07572283582761884
[Epoch 23, Batch 700] loss: 0.07570184055250138
**STATS for Epoch 23** : 
Average training loss: 0.0043
Average validation loss: 0.0958
Validation Accuracy: 0.9696
Overfitting: 0.0915
[Epoch 24, Batch 100] loss: 0.06615460191853345
[Epoch 24, Batch 200] loss: 0.06649195609614253
[Epoch 24, Batch 300] loss: 0.06687610062770545
[Epoch 24, Batch 400] loss: 0.0736842467263341
[Epoch 24, Batch 500] loss: 0.07006759731099009
[Epoch 24, Batch 600] loss: 0.06866341789718718
[Epoch 24, Batch 700] loss: 0.08009938414208591
**STATS for Epoch 24** : 
Average training loss: 0.0051
Average validation loss: 0.0902
Validation Accuracy: 0.9718
Overfitting: 0.0850
Best model saved at epoch 24 with validation loss: 0.0902
Fold 2 validation loss: 0.0902
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3033501410484316
[Epoch 1, Batch 200] loss: 2.2966918468475344
[Epoch 1, Batch 300] loss: 2.289939522743225
[Epoch 1, Batch 400] loss: 2.28331191778183
[Epoch 1, Batch 500] loss: 2.2735759925842287
[Epoch 1, Batch 600] loss: 2.257635090351105
[Epoch 1, Batch 700] loss: 2.2391224122047424
**STATS for Epoch 1** : 
Average training loss: 0.1479
Average validation loss: 2.2094
Validation Accuracy: 0.3173
Overfitting: 2.0614
Best model saved at epoch 1 with validation loss: 2.2094
[Epoch 2, Batch 100] loss: 2.1862404012680052
[Epoch 2, Batch 200] loss: 2.1297784304618834
[Epoch 2, Batch 300] loss: 2.0221554446220398
[Epoch 2, Batch 400] loss: 1.84741401553154
[Epoch 2, Batch 500] loss: 1.599770506620407
[Epoch 2, Batch 600] loss: 1.3363585877418518
[Epoch 2, Batch 700] loss: 1.1033548617362976
**STATS for Epoch 2** : 
Average training loss: 0.0635
Average validation loss: 0.8969
Validation Accuracy: 0.7566
Overfitting: 0.8335
Best model saved at epoch 2 with validation loss: 0.8969
[Epoch 3, Batch 100] loss: 0.8657137042284012
[Epoch 3, Batch 200] loss: 0.7426288175582886
[Epoch 3, Batch 300] loss: 0.6481080034375191
[Epoch 3, Batch 400] loss: 0.5792110729217529
[Epoch 3, Batch 500] loss: 0.5351043060421944
[Epoch 3, Batch 600] loss: 0.49179868936538695
[Epoch 3, Batch 700] loss: 0.4574034343659878
**STATS for Epoch 3** : 
Average training loss: 0.0307
Average validation loss: 0.4276
Validation Accuracy: 0.8756
Overfitting: 0.3969
Best model saved at epoch 3 with validation loss: 0.4276
[Epoch 4, Batch 100] loss: 0.4289011943340302
[Epoch 4, Batch 200] loss: 0.40933285549283027
[Epoch 4, Batch 300] loss: 0.38347708478569986
[Epoch 4, Batch 400] loss: 0.3720117200911045
[Epoch 4, Batch 500] loss: 0.35571897745132447
[Epoch 4, Batch 600] loss: 0.3803419491648674
[Epoch 4, Batch 700] loss: 0.34758779525756833
**STATS for Epoch 4** : 
Average training loss: 0.0239
Average validation loss: 0.3324
Validation Accuracy: 0.9054
Overfitting: 0.3085
Best model saved at epoch 4 with validation loss: 0.3324
[Epoch 5, Batch 100] loss: 0.31625851050019266
[Epoch 5, Batch 200] loss: 0.30698387682437894
[Epoch 5, Batch 300] loss: 0.31869253553450105
[Epoch 5, Batch 400] loss: 0.30763599574565886
[Epoch 5, Batch 500] loss: 0.31059930875897407
[Epoch 5, Batch 600] loss: 0.28589243985712526
[Epoch 5, Batch 700] loss: 0.28597780138254164
**STATS for Epoch 5** : 
Average training loss: 0.0191
Average validation loss: 0.2788
Validation Accuracy: 0.9176
Overfitting: 0.2597
Best model saved at epoch 5 with validation loss: 0.2788
[Epoch 6, Batch 100] loss: 0.27755148336291313
[Epoch 6, Batch 200] loss: 0.2624231293797493
[Epoch 6, Batch 300] loss: 0.24989320129156112
[Epoch 6, Batch 400] loss: 0.2566741993278265
[Epoch 6, Batch 500] loss: 0.25478479638695717
[Epoch 6, Batch 600] loss: 0.24461942322552205
[Epoch 6, Batch 700] loss: 0.25018772028386593
**STATS for Epoch 6** : 
Average training loss: 0.0169
Average validation loss: 0.2400
Validation Accuracy: 0.9283
Overfitting: 0.2231
Best model saved at epoch 6 with validation loss: 0.2400
[Epoch 7, Batch 100] loss: 0.22535119734704495
[Epoch 7, Batch 200] loss: 0.24550021857023238
[Epoch 7, Batch 300] loss: 0.23841428264975548
[Epoch 7, Batch 400] loss: 0.20508597537875176
[Epoch 7, Batch 500] loss: 0.22358010344207288
[Epoch 7, Batch 600] loss: 0.20556808695197104
[Epoch 7, Batch 700] loss: 0.21224079608917237
**STATS for Epoch 7** : 
Average training loss: 0.0132
Average validation loss: 0.2155
Validation Accuracy: 0.9369
Overfitting: 0.2023
Best model saved at epoch 7 with validation loss: 0.2155
[Epoch 8, Batch 100] loss: 0.19961230769753457
[Epoch 8, Batch 200] loss: 0.20947728030383586
[Epoch 8, Batch 300] loss: 0.1937937416881323
[Epoch 8, Batch 400] loss: 0.20832945488393306
[Epoch 8, Batch 500] loss: 0.18529642157256604
[Epoch 8, Batch 600] loss: 0.1907713558897376
[Epoch 8, Batch 700] loss: 0.19443560495972634
**STATS for Epoch 8** : 
Average training loss: 0.0128
Average validation loss: 0.1923
Validation Accuracy: 0.9398
Overfitting: 0.1795
Best model saved at epoch 8 with validation loss: 0.1923
[Epoch 9, Batch 100] loss: 0.1884521335735917
[Epoch 9, Batch 200] loss: 0.19070080984383822
[Epoch 9, Batch 300] loss: 0.17602908443659543
[Epoch 9, Batch 400] loss: 0.1902064435184002
[Epoch 9, Batch 500] loss: 0.1561481697112322
[Epoch 9, Batch 600] loss: 0.1761407505720854
[Epoch 9, Batch 700] loss: 0.15795856934040786
**STATS for Epoch 9** : 
Average training loss: 0.0111
Average validation loss: 0.1687
Validation Accuracy: 0.9476
Overfitting: 0.1576
Best model saved at epoch 9 with validation loss: 0.1687
[Epoch 10, Batch 100] loss: 0.16156630478799344
[Epoch 10, Batch 200] loss: 0.15996252939105035
[Epoch 10, Batch 300] loss: 0.1565570329129696
[Epoch 10, Batch 400] loss: 0.15355888847261667
[Epoch 10, Batch 500] loss: 0.16166678737848997
[Epoch 10, Batch 600] loss: 0.14885308105498551
[Epoch 10, Batch 700] loss: 0.16602053459733723
**STATS for Epoch 10** : 
Average training loss: 0.0105
Average validation loss: 0.1566
Validation Accuracy: 0.9525
Overfitting: 0.1461
Best model saved at epoch 10 with validation loss: 0.1566
[Epoch 11, Batch 100] loss: 0.14755408637225628
[Epoch 11, Batch 200] loss: 0.15026704808697106
[Epoch 11, Batch 300] loss: 0.14417249601334334
[Epoch 11, Batch 400] loss: 0.14762356750667094
[Epoch 11, Batch 500] loss: 0.14327618926763536
[Epoch 11, Batch 600] loss: 0.14309450056403875
[Epoch 11, Batch 700] loss: 0.1480137711018324
**STATS for Epoch 11** : 
Average training loss: 0.0099
Average validation loss: 0.1485
Validation Accuracy: 0.9533
Overfitting: 0.1385
Best model saved at epoch 11 with validation loss: 0.1485
[Epoch 12, Batch 100] loss: 0.1232399270683527
[Epoch 12, Batch 200] loss: 0.15054719410836698
[Epoch 12, Batch 300] loss: 0.13025884721428155
[Epoch 12, Batch 400] loss: 0.13259510636329652
[Epoch 12, Batch 500] loss: 0.13593456853181124
[Epoch 12, Batch 600] loss: 0.12885428469628096
[Epoch 12, Batch 700] loss: 0.13367390885949135
**STATS for Epoch 12** : 
Average training loss: 0.0099
Average validation loss: 0.1325
Validation Accuracy: 0.9623
Overfitting: 0.1227
Best model saved at epoch 12 with validation loss: 0.1325
[Epoch 13, Batch 100] loss: 0.12139727581292391
[Epoch 13, Batch 200] loss: 0.13486434338614345
[Epoch 13, Batch 300] loss: 0.11821276919916272
[Epoch 13, Batch 400] loss: 0.1251067153736949
[Epoch 13, Batch 500] loss: 0.13296256739646195
[Epoch 13, Batch 600] loss: 0.11794276745989919
[Epoch 13, Batch 700] loss: 0.12504566764459013
**STATS for Epoch 13** : 
Average training loss: 0.0083
Average validation loss: 0.1333
Validation Accuracy: 0.9595
Overfitting: 0.1250
[Epoch 14, Batch 100] loss: 0.12280912140384316
[Epoch 14, Batch 200] loss: 0.11921314664185047
[Epoch 14, Batch 300] loss: 0.1171956970077008
[Epoch 14, Batch 400] loss: 0.1186208068113774
[Epoch 14, Batch 500] loss: 0.12175274312496186
[Epoch 14, Batch 600] loss: 0.11721170082688331
[Epoch 14, Batch 700] loss: 0.1066966340597719
**STATS for Epoch 14** : 
Average training loss: 0.0070
Average validation loss: 0.1223
Validation Accuracy: 0.9635
Overfitting: 0.1153
Best model saved at epoch 14 with validation loss: 0.1223
[Epoch 15, Batch 100] loss: 0.1279548410885036
[Epoch 15, Batch 200] loss: 0.11005271967500448
[Epoch 15, Batch 300] loss: 0.11515844125300646
[Epoch 15, Batch 400] loss: 0.10467976171523333
[Epoch 15, Batch 500] loss: 0.11310009490698576
[Epoch 15, Batch 600] loss: 0.10757882764562965
[Epoch 15, Batch 700] loss: 0.11003943525254727
**STATS for Epoch 15** : 
Average training loss: 0.0063
Average validation loss: 0.1161
Validation Accuracy: 0.9665
Overfitting: 0.1098
Best model saved at epoch 15 with validation loss: 0.1161
[Epoch 16, Batch 100] loss: 0.09709907548502088
[Epoch 16, Batch 200] loss: 0.10462580123916268
[Epoch 16, Batch 300] loss: 0.09894996590912342
[Epoch 16, Batch 400] loss: 0.10331750936806201
[Epoch 16, Batch 500] loss: 0.11063523072749376
[Epoch 16, Batch 600] loss: 0.11359578528441489
[Epoch 16, Batch 700] loss: 0.10107728449627756
**STATS for Epoch 16** : 
Average training loss: 0.0070
Average validation loss: 0.1196
Validation Accuracy: 0.9633
Overfitting: 0.1126
[Epoch 17, Batch 100] loss: 0.10008351739495992
[Epoch 17, Batch 200] loss: 0.10042319983243943
[Epoch 17, Batch 300] loss: 0.09257359351962804
[Epoch 17, Batch 400] loss: 0.09616770947352052
[Epoch 17, Batch 500] loss: 0.09833013097755611
[Epoch 17, Batch 600] loss: 0.10535371351987123
[Epoch 17, Batch 700] loss: 0.09835564525797963
**STATS for Epoch 17** : 
Average training loss: 0.0076
Average validation loss: 0.1048
Validation Accuracy: 0.9693
Overfitting: 0.0972
Best model saved at epoch 17 with validation loss: 0.1048
[Epoch 18, Batch 100] loss: 0.08927372329868376
[Epoch 18, Batch 200] loss: 0.09299827381968498
[Epoch 18, Batch 300] loss: 0.09711469439789652
[Epoch 18, Batch 400] loss: 0.09436718816868961
[Epoch 18, Batch 500] loss: 0.09565396839752793
[Epoch 18, Batch 600] loss: 0.1044473640434444
[Epoch 18, Batch 700] loss: 0.08599473559297621
**STATS for Epoch 18** : 
Average training loss: 0.0065
Average validation loss: 0.1046
Validation Accuracy: 0.9688
Overfitting: 0.0981
Best model saved at epoch 18 with validation loss: 0.1046
[Epoch 19, Batch 100] loss: 0.09116282762028277
[Epoch 19, Batch 200] loss: 0.08294714564457535
[Epoch 19, Batch 300] loss: 0.09499293985776604
[Epoch 19, Batch 400] loss: 0.09941103480756283
[Epoch 19, Batch 500] loss: 0.08863089131191373
[Epoch 19, Batch 600] loss: 0.08702345138415694
[Epoch 19, Batch 700] loss: 0.08464614210650324
**STATS for Epoch 19** : 
Average training loss: 0.0063
Average validation loss: 0.1041
Validation Accuracy: 0.9696
Overfitting: 0.0978
Best model saved at epoch 19 with validation loss: 0.1041
[Epoch 20, Batch 100] loss: 0.09415292583405971
[Epoch 20, Batch 200] loss: 0.09119677541777492
[Epoch 20, Batch 300] loss: 0.09022699642926454
[Epoch 20, Batch 400] loss: 0.08222226963378489
[Epoch 20, Batch 500] loss: 0.07959590381011367
[Epoch 20, Batch 600] loss: 0.0804277419578284
[Epoch 20, Batch 700] loss: 0.08136570480652154
**STATS for Epoch 20** : 
Average training loss: 0.0068
Average validation loss: 0.0920
Validation Accuracy: 0.9723
Overfitting: 0.0853
Best model saved at epoch 20 with validation loss: 0.0920
[Epoch 21, Batch 100] loss: 0.08085006719455123
[Epoch 21, Batch 200] loss: 0.08279661213979125
[Epoch 21, Batch 300] loss: 0.08449813605286181
[Epoch 21, Batch 400] loss: 0.07996990260202437
[Epoch 21, Batch 500] loss: 0.08222731433808804
[Epoch 21, Batch 600] loss: 0.07881848151795566
[Epoch 21, Batch 700] loss: 0.08512311444617808
**STATS for Epoch 21** : 
Average training loss: 0.0062
Average validation loss: 0.0937
Validation Accuracy: 0.9726
Overfitting: 0.0875
[Epoch 22, Batch 100] loss: 0.07385783527046443
[Epoch 22, Batch 200] loss: 0.07446555856615306
[Epoch 22, Batch 300] loss: 0.07515162429772318
[Epoch 22, Batch 400] loss: 0.08416526075452566
[Epoch 22, Batch 500] loss: 0.0764946010056883
[Epoch 22, Batch 600] loss: 0.07955391330644489
[Epoch 22, Batch 700] loss: 0.08560014251619577
**STATS for Epoch 22** : 
Average training loss: 0.0058
Average validation loss: 0.0901
Validation Accuracy: 0.9732
Overfitting: 0.0844
Best model saved at epoch 22 with validation loss: 0.0901
[Epoch 23, Batch 100] loss: 0.08449106207117438
[Epoch 23, Batch 200] loss: 0.0777170339319855
[Epoch 23, Batch 300] loss: 0.0785110271256417
[Epoch 23, Batch 400] loss: 0.07415774493478239
[Epoch 23, Batch 500] loss: 0.08232499144971371
[Epoch 23, Batch 600] loss: 0.07026361022144556
[Epoch 23, Batch 700] loss: 0.07409688810817898
**STATS for Epoch 23** : 
Average training loss: 0.0049
Average validation loss: 0.0898
Validation Accuracy: 0.9735
Overfitting: 0.0849
Best model saved at epoch 23 with validation loss: 0.0898
[Epoch 24, Batch 100] loss: 0.06755458771251142
[Epoch 24, Batch 200] loss: 0.07232190798036754
[Epoch 24, Batch 300] loss: 0.06737731674686075
[Epoch 24, Batch 400] loss: 0.08575702573172748
[Epoch 24, Batch 500] loss: 0.07145462040789426
[Epoch 24, Batch 600] loss: 0.07713185016997158
[Epoch 24, Batch 700] loss: 0.07317519064992667
**STATS for Epoch 24** : 
Average training loss: 0.0051
Average validation loss: 0.0843
Validation Accuracy: 0.9748
Overfitting: 0.0793
Best model saved at epoch 24 with validation loss: 0.0843
Fold 3 validation loss: 0.0843
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.301092891693115
[Epoch 1, Batch 200] loss: 2.2948172330856322
[Epoch 1, Batch 300] loss: 2.2874122786521913
[Epoch 1, Batch 400] loss: 2.2791299748420717
[Epoch 1, Batch 500] loss: 2.268923361301422
[Epoch 1, Batch 600] loss: 2.255282688140869
[Epoch 1, Batch 700] loss: 2.2371076703071595
**STATS for Epoch 1** : 
Average training loss: 0.1479
Average validation loss: 2.2124
Validation Accuracy: 0.4223
Overfitting: 2.0646
Best model saved at epoch 1 with validation loss: 2.2124
[Epoch 2, Batch 100] loss: 2.192093434333801
[Epoch 2, Batch 200] loss: 2.140914878845215
[Epoch 2, Batch 300] loss: 2.0533149433135987
[Epoch 2, Batch 400] loss: 1.9053914749622345
[Epoch 2, Batch 500] loss: 1.6280829775333405
[Epoch 2, Batch 600] loss: 1.311913049221039
[Epoch 2, Batch 700] loss: 1.004852421283722
**STATS for Epoch 2** : 
Average training loss: 0.0553
Average validation loss: 0.7877
Validation Accuracy: 0.7988
Overfitting: 0.7324
Best model saved at epoch 2 with validation loss: 0.7877
[Epoch 3, Batch 100] loss: 0.7024048066139221
[Epoch 3, Batch 200] loss: 0.6144681605696678
[Epoch 3, Batch 300] loss: 0.5609224110841751
[Epoch 3, Batch 400] loss: 0.5063230162858963
[Epoch 3, Batch 500] loss: 0.46681367814540864
[Epoch 3, Batch 600] loss: 0.45272122412919996
[Epoch 3, Batch 700] loss: 0.41692429840564726
**STATS for Epoch 3** : 
Average training loss: 0.0276
Average validation loss: 0.4117
Validation Accuracy: 0.8778
Overfitting: 0.3841
Best model saved at epoch 3 with validation loss: 0.4117
[Epoch 4, Batch 100] loss: 0.391972993761301
[Epoch 4, Batch 200] loss: 0.37454782709479334
[Epoch 4, Batch 300] loss: 0.3681288354098797
[Epoch 4, Batch 400] loss: 0.34486458331346515
[Epoch 4, Batch 500] loss: 0.3415395440161228
[Epoch 4, Batch 600] loss: 0.3292016179859638
[Epoch 4, Batch 700] loss: 0.3201842066645622
**STATS for Epoch 4** : 
Average training loss: 0.0211
Average validation loss: 0.3197
Validation Accuracy: 0.9020
Overfitting: 0.2986
Best model saved at epoch 4 with validation loss: 0.3197
[Epoch 5, Batch 100] loss: 0.2959330806136131
[Epoch 5, Batch 200] loss: 0.3033378916978836
[Epoch 5, Batch 300] loss: 0.2821147362887859
[Epoch 5, Batch 400] loss: 0.3032660676538944
[Epoch 5, Batch 500] loss: 0.29052181370556357
[Epoch 5, Batch 600] loss: 0.26469752602279184
[Epoch 5, Batch 700] loss: 0.25653452292084694
**STATS for Epoch 5** : 
Average training loss: 0.0176
Average validation loss: 0.2616
Validation Accuracy: 0.9187
Overfitting: 0.2440
Best model saved at epoch 5 with validation loss: 0.2616
[Epoch 6, Batch 100] loss: 0.25673914290964606
[Epoch 6, Batch 200] loss: 0.26229556582868097
[Epoch 6, Batch 300] loss: 0.2349335879087448
[Epoch 6, Batch 400] loss: 0.23968734927475452
[Epoch 6, Batch 500] loss: 0.23771672174334527
[Epoch 6, Batch 600] loss: 0.2239943614602089
[Epoch 6, Batch 700] loss: 0.24613930702209472
**STATS for Epoch 6** : 
Average training loss: 0.0152
Average validation loss: 0.2252
Validation Accuracy: 0.9319
Overfitting: 0.2100
Best model saved at epoch 6 with validation loss: 0.2252
[Epoch 7, Batch 100] loss: 0.22405363388359548
[Epoch 7, Batch 200] loss: 0.22678776483982802
[Epoch 7, Batch 300] loss: 0.20730159133672715
[Epoch 7, Batch 400] loss: 0.201367459371686
[Epoch 7, Batch 500] loss: 0.2071141964942217
[Epoch 7, Batch 600] loss: 0.20465484607964754
[Epoch 7, Batch 700] loss: 0.20556186124682427
**STATS for Epoch 7** : 
Average training loss: 0.0137
Average validation loss: 0.1982
Validation Accuracy: 0.9403
Overfitting: 0.1845
Best model saved at epoch 7 with validation loss: 0.1982
[Epoch 8, Batch 100] loss: 0.2038837906718254
[Epoch 8, Batch 200] loss: 0.1859016279131174
[Epoch 8, Batch 300] loss: 0.17718316052109004
[Epoch 8, Batch 400] loss: 0.18807499587535859
[Epoch 8, Batch 500] loss: 0.19377183232456446
[Epoch 8, Batch 600] loss: 0.17427427541464569
[Epoch 8, Batch 700] loss: 0.17854773037135602
**STATS for Epoch 8** : 
Average training loss: 0.0131
Average validation loss: 0.1814
Validation Accuracy: 0.9454
Overfitting: 0.1683
Best model saved at epoch 8 with validation loss: 0.1814
[Epoch 9, Batch 100] loss: 0.16871862087398767
[Epoch 9, Batch 200] loss: 0.16405297569930555
[Epoch 9, Batch 300] loss: 0.166746735740453
[Epoch 9, Batch 400] loss: 0.16850680995732545
[Epoch 9, Batch 500] loss: 0.16996147640049458
[Epoch 9, Batch 600] loss: 0.15620309680700303
[Epoch 9, Batch 700] loss: 0.16931743949651717
**STATS for Epoch 9** : 
Average training loss: 0.0114
Average validation loss: 0.1561
Validation Accuracy: 0.9533
Overfitting: 0.1448
Best model saved at epoch 9 with validation loss: 0.1561
[Epoch 10, Batch 100] loss: 0.16216695614159107
[Epoch 10, Batch 200] loss: 0.15585169302299617
[Epoch 10, Batch 300] loss: 0.15265461444854736
[Epoch 10, Batch 400] loss: 0.14690427511930465
[Epoch 10, Batch 500] loss: 0.14731990300118925
[Epoch 10, Batch 600] loss: 0.14261321894824505
[Epoch 10, Batch 700] loss: 0.15785694781690837
**STATS for Epoch 10** : 
Average training loss: 0.0086
Average validation loss: 0.1442
Validation Accuracy: 0.9572
Overfitting: 0.1357
Best model saved at epoch 10 with validation loss: 0.1442
[Epoch 11, Batch 100] loss: 0.14219978952780365
[Epoch 11, Batch 200] loss: 0.13870025094598532
[Epoch 11, Batch 300] loss: 0.13639853518456221
[Epoch 11, Batch 400] loss: 0.1507718336582184
[Epoch 11, Batch 500] loss: 0.13246221374720335
[Epoch 11, Batch 600] loss: 0.13206076813861728
[Epoch 11, Batch 700] loss: 0.13621285274624825
**STATS for Epoch 11** : 
Average training loss: 0.0086
Average validation loss: 0.1327
Validation Accuracy: 0.9603
Overfitting: 0.1241
Best model saved at epoch 11 with validation loss: 0.1327
[Epoch 12, Batch 100] loss: 0.1293988036364317
[Epoch 12, Batch 200] loss: 0.13570467066019773
[Epoch 12, Batch 300] loss: 0.1224498032219708
[Epoch 12, Batch 400] loss: 0.12813363075256348
[Epoch 12, Batch 500] loss: 0.12659433998167516
[Epoch 12, Batch 600] loss: 0.12942927530035375
[Epoch 12, Batch 700] loss: 0.12561525456607342
**STATS for Epoch 12** : 
Average training loss: 0.0077
Average validation loss: 0.1219
Validation Accuracy: 0.9634
Overfitting: 0.1142
Best model saved at epoch 12 with validation loss: 0.1219
[Epoch 13, Batch 100] loss: 0.12139916907995939
[Epoch 13, Batch 200] loss: 0.11728917730972171
[Epoch 13, Batch 300] loss: 0.12689639624208213
[Epoch 13, Batch 400] loss: 0.11125800968147814
[Epoch 13, Batch 500] loss: 0.12149042338132858
[Epoch 13, Batch 600] loss: 0.11583670541644096
[Epoch 13, Batch 700] loss: 0.11766440611332656
**STATS for Epoch 13** : 
Average training loss: 0.0077
Average validation loss: 0.1219
Validation Accuracy: 0.9631
Overfitting: 0.1143
Best model saved at epoch 13 with validation loss: 0.1219
[Epoch 14, Batch 100] loss: 0.11724561043083667
[Epoch 14, Batch 200] loss: 0.10833330605179071
[Epoch 14, Batch 300] loss: 0.12590644372627138
[Epoch 14, Batch 400] loss: 0.11060802035033702
[Epoch 14, Batch 500] loss: 0.10346123863011598
[Epoch 14, Batch 600] loss: 0.1046042587980628
[Epoch 14, Batch 700] loss: 0.10827489886432887
**STATS for Epoch 14** : 
Average training loss: 0.0074
Average validation loss: 0.1081
Validation Accuracy: 0.9673
Overfitting: 0.1007
Best model saved at epoch 14 with validation loss: 0.1081
[Epoch 15, Batch 100] loss: 0.11409938129596413
[Epoch 15, Batch 200] loss: 0.1068132047355175
[Epoch 15, Batch 300] loss: 0.10125124602578581
[Epoch 15, Batch 400] loss: 0.10406395971775055
[Epoch 15, Batch 500] loss: 0.10184708803892135
[Epoch 15, Batch 600] loss: 0.10970513029024005
[Epoch 15, Batch 700] loss: 0.10089889777824283
**STATS for Epoch 15** : 
Average training loss: 0.0062
Average validation loss: 0.1060
Validation Accuracy: 0.9683
Overfitting: 0.0998
Best model saved at epoch 15 with validation loss: 0.1060
[Epoch 16, Batch 100] loss: 0.09857195036485791
[Epoch 16, Batch 200] loss: 0.10237736629322171
[Epoch 16, Batch 300] loss: 0.09799517096020281
[Epoch 16, Batch 400] loss: 0.09617703453637659
[Epoch 16, Batch 500] loss: 0.10504454907029867
[Epoch 16, Batch 600] loss: 0.09268512999638916
[Epoch 16, Batch 700] loss: 0.10408165138214827
**STATS for Epoch 16** : 
Average training loss: 0.0065
Average validation loss: 0.1100
Validation Accuracy: 0.9672
Overfitting: 0.1035
[Epoch 17, Batch 100] loss: 0.09909226661548018
[Epoch 17, Batch 200] loss: 0.09544041551649571
[Epoch 17, Batch 300] loss: 0.0869684430398047
[Epoch 17, Batch 400] loss: 0.09193595683202148
[Epoch 17, Batch 500] loss: 0.10252858094871044
[Epoch 17, Batch 600] loss: 0.09099164878949523
[Epoch 17, Batch 700] loss: 0.09266393950209022
**STATS for Epoch 17** : 
Average training loss: 0.0070
Average validation loss: 0.0957
Validation Accuracy: 0.9717
Overfitting: 0.0887
Best model saved at epoch 17 with validation loss: 0.0957
[Epoch 18, Batch 100] loss: 0.08148712945170701
[Epoch 18, Batch 200] loss: 0.0978463237453252
[Epoch 18, Batch 300] loss: 0.09911965849809348
[Epoch 18, Batch 400] loss: 0.09433367790654301
[Epoch 18, Batch 500] loss: 0.0904832568205893
[Epoch 18, Batch 600] loss: 0.0887166010029614
[Epoch 18, Batch 700] loss: 0.0830795313976705
**STATS for Epoch 18** : 
Average training loss: 0.0058
Average validation loss: 0.0905
Validation Accuracy: 0.9716
Overfitting: 0.0847
Best model saved at epoch 18 with validation loss: 0.0905
[Epoch 19, Batch 100] loss: 0.08230442638508975
[Epoch 19, Batch 200] loss: 0.10129324580542744
[Epoch 19, Batch 300] loss: 0.08364885607734322
[Epoch 19, Batch 400] loss: 0.08579987979494036
[Epoch 19, Batch 500] loss: 0.0849910084437579
[Epoch 19, Batch 600] loss: 0.09989332066848874
[Epoch 19, Batch 700] loss: 0.07448757805861533
**STATS for Epoch 19** : 
Average training loss: 0.0047
Average validation loss: 0.0876
Validation Accuracy: 0.9732
Overfitting: 0.0830
Best model saved at epoch 19 with validation loss: 0.0876
[Epoch 20, Batch 100] loss: 0.08713005458936095
[Epoch 20, Batch 200] loss: 0.0795804538950324
[Epoch 20, Batch 300] loss: 0.08859235011041164
[Epoch 20, Batch 400] loss: 0.09014728969894349
[Epoch 20, Batch 500] loss: 0.08047309453599155
[Epoch 20, Batch 600] loss: 0.07233724294230343
[Epoch 20, Batch 700] loss: 0.08593678323552012
**STATS for Epoch 20** : 
Average training loss: 0.0051
Average validation loss: 0.0846
Validation Accuracy: 0.9749
Overfitting: 0.0795
Best model saved at epoch 20 with validation loss: 0.0846
[Epoch 21, Batch 100] loss: 0.08148951516486705
[Epoch 21, Batch 200] loss: 0.08749146119691431
[Epoch 21, Batch 300] loss: 0.08453087603673339
[Epoch 21, Batch 400] loss: 0.07951005656272173
[Epoch 21, Batch 500] loss: 0.0745777329057455
[Epoch 21, Batch 600] loss: 0.08408343796618283
[Epoch 21, Batch 700] loss: 0.07895012766122818
**STATS for Epoch 21** : 
Average training loss: 0.0043
Average validation loss: 0.0856
Validation Accuracy: 0.9741
Overfitting: 0.0813
[Epoch 22, Batch 100] loss: 0.08161690375767648
[Epoch 22, Batch 200] loss: 0.07246703565586358
[Epoch 22, Batch 300] loss: 0.07848952531814575
[Epoch 22, Batch 400] loss: 0.07071318004280329
[Epoch 22, Batch 500] loss: 0.07679128265008331
[Epoch 22, Batch 600] loss: 0.07101962413173168
[Epoch 22, Batch 700] loss: 0.08085899020545184
**STATS for Epoch 22** : 
Average training loss: 0.0061
Average validation loss: 0.0868
Validation Accuracy: 0.9739
Overfitting: 0.0807
[Epoch 23, Batch 100] loss: 0.07335361247882247
[Epoch 23, Batch 200] loss: 0.06995375293307006
[Epoch 23, Batch 300] loss: 0.07133738516829907
[Epoch 23, Batch 400] loss: 0.07093228899873794
[Epoch 23, Batch 500] loss: 0.07618516470771283
[Epoch 23, Batch 600] loss: 0.07893622030504048
[Epoch 23, Batch 700] loss: 0.07078493784181773
**STATS for Epoch 23** : 
Average training loss: 0.0055
Average validation loss: 0.0765
Validation Accuracy: 0.9772
Overfitting: 0.0710
Best model saved at epoch 23 with validation loss: 0.0765
[Epoch 24, Batch 100] loss: 0.07178712299093604
[Epoch 24, Batch 200] loss: 0.07221338870935141
[Epoch 24, Batch 300] loss: 0.07116820296272636
[Epoch 24, Batch 400] loss: 0.07747926778160036
[Epoch 24, Batch 500] loss: 0.06660065515898168
[Epoch 24, Batch 600] loss: 0.0737126595666632
[Epoch 24, Batch 700] loss: 0.07008465516380966
**STATS for Epoch 24** : 
Average training loss: 0.0050
Average validation loss: 0.0784
Validation Accuracy: 0.9761
Overfitting: 0.0734
Fold 4 validation loss: 0.0784
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.306923155784607
[Epoch 1, Batch 200] loss: 2.3015909934043886
[Epoch 1, Batch 300] loss: 2.2949447798728944
[Epoch 1, Batch 400] loss: 2.290050013065338
[Epoch 1, Batch 500] loss: 2.28078355550766
[Epoch 1, Batch 600] loss: 2.2698589253425596
[Epoch 1, Batch 700] loss: 2.2571650886535646
**STATS for Epoch 1** : 
Average training loss: 0.1495
Average validation loss: 2.2348
Validation Accuracy: 0.3272
Overfitting: 2.0854
Best model saved at epoch 1 with validation loss: 2.2348
[Epoch 2, Batch 100] loss: 2.2242003107070922
[Epoch 2, Batch 200] loss: 2.185189380645752
[Epoch 2, Batch 300] loss: 2.128333773612976
[Epoch 2, Batch 400] loss: 2.0193814980983733
[Epoch 2, Batch 500] loss: 1.8375552916526794
[Epoch 2, Batch 600] loss: 1.5598162722587585
[Epoch 2, Batch 700] loss: 1.2491382241249085
**STATS for Epoch 2** : 
Average training loss: 0.0692
Average validation loss: 0.9752
Validation Accuracy: 0.7500
Overfitting: 0.9060
Best model saved at epoch 2 with validation loss: 0.9752
[Epoch 3, Batch 100] loss: 0.878622036576271
[Epoch 3, Batch 200] loss: 0.7301767176389694
[Epoch 3, Batch 300] loss: 0.6337236261367798
[Epoch 3, Batch 400] loss: 0.578540726006031
[Epoch 3, Batch 500] loss: 0.5480145239830017
[Epoch 3, Batch 600] loss: 0.49217582762241363
[Epoch 3, Batch 700] loss: 0.46325927823781965
**STATS for Epoch 3** : 
Average training loss: 0.0292
Average validation loss: 0.4456
Validation Accuracy: 0.8660
Overfitting: 0.4164
Best model saved at epoch 3 with validation loss: 0.4456
[Epoch 4, Batch 100] loss: 0.42926801487803457
[Epoch 4, Batch 200] loss: 0.425742671340704
[Epoch 4, Batch 300] loss: 0.3878732626140118
[Epoch 4, Batch 400] loss: 0.3901201683282852
[Epoch 4, Batch 500] loss: 0.3758595259487629
[Epoch 4, Batch 600] loss: 0.35955904826521873
[Epoch 4, Batch 700] loss: 0.348908477127552
**STATS for Epoch 4** : 
Average training loss: 0.0226
Average validation loss: 0.3553
Validation Accuracy: 0.8936
Overfitting: 0.3327
Best model saved at epoch 4 with validation loss: 0.3553
[Epoch 5, Batch 100] loss: 0.33331781432032587
[Epoch 5, Batch 200] loss: 0.3128240118920803
[Epoch 5, Batch 300] loss: 0.32785421013832095
[Epoch 5, Batch 400] loss: 0.30351488150656225
[Epoch 5, Batch 500] loss: 0.3073878452926874
[Epoch 5, Batch 600] loss: 0.30407372534275057
[Epoch 5, Batch 700] loss: 0.2800859971344471
**STATS for Epoch 5** : 
Average training loss: 0.0197
Average validation loss: 0.2919
Validation Accuracy: 0.9113
Overfitting: 0.2723
Best model saved at epoch 5 with validation loss: 0.2919
[Epoch 6, Batch 100] loss: 0.2896533042937517
[Epoch 6, Batch 200] loss: 0.29207175739109514
[Epoch 6, Batch 300] loss: 0.2665159220248461
[Epoch 6, Batch 400] loss: 0.26206058755517003
[Epoch 6, Batch 500] loss: 0.25770056806504726
[Epoch 6, Batch 600] loss: 0.2438131321966648
[Epoch 6, Batch 700] loss: 0.22940714567899703
**STATS for Epoch 6** : 
Average training loss: 0.0160
Average validation loss: 0.2448
Validation Accuracy: 0.9261
Overfitting: 0.2288
Best model saved at epoch 6 with validation loss: 0.2448
[Epoch 7, Batch 100] loss: 0.23226873733103276
[Epoch 7, Batch 200] loss: 0.23756350547075272
[Epoch 7, Batch 300] loss: 0.23476845629513263
[Epoch 7, Batch 400] loss: 0.2292288101837039
[Epoch 7, Batch 500] loss: 0.220390531308949
[Epoch 7, Batch 600] loss: 0.2208775382116437
[Epoch 7, Batch 700] loss: 0.2066446281224489
**STATS for Epoch 7** : 
Average training loss: 0.0138
Average validation loss: 0.2107
Validation Accuracy: 0.9389
Overfitting: 0.1969
Best model saved at epoch 7 with validation loss: 0.2107
[Epoch 8, Batch 100] loss: 0.20248793870210646
[Epoch 8, Batch 200] loss: 0.20619100123643874
[Epoch 8, Batch 300] loss: 0.19794609516859055
[Epoch 8, Batch 400] loss: 0.18969991847872733
[Epoch 8, Batch 500] loss: 0.2055008229240775
[Epoch 8, Batch 600] loss: 0.18749824952334165
[Epoch 8, Batch 700] loss: 0.19288817256689073
**STATS for Epoch 8** : 
Average training loss: 0.0117
Average validation loss: 0.2069
Validation Accuracy: 0.9380
Overfitting: 0.1951
Best model saved at epoch 8 with validation loss: 0.2069
[Epoch 9, Batch 100] loss: 0.18788804329931735
[Epoch 9, Batch 200] loss: 0.18156723834574223
[Epoch 9, Batch 300] loss: 0.1742522830888629
[Epoch 9, Batch 400] loss: 0.1821236840635538
[Epoch 9, Batch 500] loss: 0.16442448925226927
[Epoch 9, Batch 600] loss: 0.1743457067385316
[Epoch 9, Batch 700] loss: 0.15728661708533764
**STATS for Epoch 9** : 
Average training loss: 0.0110
Average validation loss: 0.1763
Validation Accuracy: 0.9474
Overfitting: 0.1654
Best model saved at epoch 9 with validation loss: 0.1763
[Epoch 10, Batch 100] loss: 0.15306177973747254
[Epoch 10, Batch 200] loss: 0.1649387063086033
[Epoch 10, Batch 300] loss: 0.16845935948193072
[Epoch 10, Batch 400] loss: 0.15746257413178683
[Epoch 10, Batch 500] loss: 0.15970650248229504
[Epoch 10, Batch 600] loss: 0.15046381074935197
[Epoch 10, Batch 700] loss: 0.15071195028722287
**STATS for Epoch 10** : 
Average training loss: 0.0089
Average validation loss: 0.1519
Validation Accuracy: 0.9566
Overfitting: 0.1430
Best model saved at epoch 10 with validation loss: 0.1519
[Epoch 11, Batch 100] loss: 0.1470880527049303
[Epoch 11, Batch 200] loss: 0.14811292912811042
[Epoch 11, Batch 300] loss: 0.14419407408684493
[Epoch 11, Batch 400] loss: 0.1428443644940853
[Epoch 11, Batch 500] loss: 0.13410867001861335
[Epoch 11, Batch 600] loss: 0.12882372617721558
[Epoch 11, Batch 700] loss: 0.14037496842443942
**STATS for Epoch 11** : 
Average training loss: 0.0098
Average validation loss: 0.1439
Validation Accuracy: 0.9582
Overfitting: 0.1341
Best model saved at epoch 11 with validation loss: 0.1439
[Epoch 12, Batch 100] loss: 0.13752837784588337
[Epoch 12, Batch 200] loss: 0.13704637940973044
[Epoch 12, Batch 300] loss: 0.1399382115341723
[Epoch 12, Batch 400] loss: 0.13578619055449961
[Epoch 12, Batch 500] loss: 0.12218762462958693
[Epoch 12, Batch 600] loss: 0.12556475998833774
[Epoch 12, Batch 700] loss: 0.1191384944319725
**STATS for Epoch 12** : 
Average training loss: 0.0071
Average validation loss: 0.1263
Validation Accuracy: 0.9627
Overfitting: 0.1192
Best model saved at epoch 12 with validation loss: 0.1263
[Epoch 13, Batch 100] loss: 0.1218423587270081
[Epoch 13, Batch 200] loss: 0.12319306444376707
[Epoch 13, Batch 300] loss: 0.11809869756922126
[Epoch 13, Batch 400] loss: 0.12035757327452302
[Epoch 13, Batch 500] loss: 0.13607896264642477
[Epoch 13, Batch 600] loss: 0.11902383595705032
[Epoch 13, Batch 700] loss: 0.10360781041905284
**STATS for Epoch 13** : 
Average training loss: 0.0080
Average validation loss: 0.1210
Validation Accuracy: 0.9649
Overfitting: 0.1131
Best model saved at epoch 13 with validation loss: 0.1210
[Epoch 14, Batch 100] loss: 0.10861729299649596
[Epoch 14, Batch 200] loss: 0.10971971234306693
[Epoch 14, Batch 300] loss: 0.11498312896117568
[Epoch 14, Batch 400] loss: 0.11049740433692933
[Epoch 14, Batch 500] loss: 0.11675196861848235
[Epoch 14, Batch 600] loss: 0.11062659611925482
[Epoch 14, Batch 700] loss: 0.11169042050838471
**STATS for Epoch 14** : 
Average training loss: 0.0068
Average validation loss: 0.1255
Validation Accuracy: 0.9625
Overfitting: 0.1187
[Epoch 15, Batch 100] loss: 0.1086089158244431
[Epoch 15, Batch 200] loss: 0.10771084982901812
[Epoch 15, Batch 300] loss: 0.10908617950975895
[Epoch 15, Batch 400] loss: 0.10733607919886708
[Epoch 15, Batch 500] loss: 0.1060690641310066
[Epoch 15, Batch 600] loss: 0.1104811906348914
[Epoch 15, Batch 700] loss: 0.10067042666487395
**STATS for Epoch 15** : 
Average training loss: 0.0065
Average validation loss: 0.1121
Validation Accuracy: 0.9656
Overfitting: 0.1056
Best model saved at epoch 15 with validation loss: 0.1121
[Epoch 16, Batch 100] loss: 0.10047906540334224
[Epoch 16, Batch 200] loss: 0.09531802793033421
[Epoch 16, Batch 300] loss: 0.09931167600676417
[Epoch 16, Batch 400] loss: 0.099925217628479
[Epoch 16, Batch 500] loss: 0.10826665384694933
[Epoch 16, Batch 600] loss: 0.09885279586538673
[Epoch 16, Batch 700] loss: 0.09718515722081066
**STATS for Epoch 16** : 
Average training loss: 0.0065
Average validation loss: 0.1087
Validation Accuracy: 0.9675
Overfitting: 0.1022
Best model saved at epoch 16 with validation loss: 0.1087
[Epoch 17, Batch 100] loss: 0.09487074922770261
[Epoch 17, Batch 200] loss: 0.09260665291920304
[Epoch 17, Batch 300] loss: 0.09320893774740398
[Epoch 17, Batch 400] loss: 0.09828369458205997
[Epoch 17, Batch 500] loss: 0.10003144273534417
[Epoch 17, Batch 600] loss: 0.08732946113683283
[Epoch 17, Batch 700] loss: 0.1041614255681634
**STATS for Epoch 17** : 
Average training loss: 0.0066
Average validation loss: 0.0983
Validation Accuracy: 0.9695
Overfitting: 0.0917
Best model saved at epoch 17 with validation loss: 0.0983
[Epoch 18, Batch 100] loss: 0.0918199260532856
[Epoch 18, Batch 200] loss: 0.09001845005899668
[Epoch 18, Batch 300] loss: 0.09023910446092487
[Epoch 18, Batch 400] loss: 0.08295375665649772
[Epoch 18, Batch 500] loss: 0.0983982974756509
[Epoch 18, Batch 600] loss: 0.0881506673246622
[Epoch 18, Batch 700] loss: 0.0936874233931303
**STATS for Epoch 18** : 
Average training loss: 0.0055
Average validation loss: 0.0935
Validation Accuracy: 0.9725
Overfitting: 0.0880
Best model saved at epoch 18 with validation loss: 0.0935
[Epoch 19, Batch 100] loss: 0.09509708024561406
[Epoch 19, Batch 200] loss: 0.07551819005049765
[Epoch 19, Batch 300] loss: 0.0940058652497828
[Epoch 19, Batch 400] loss: 0.0812553337495774
[Epoch 19, Batch 500] loss: 0.08847866108641028
[Epoch 19, Batch 600] loss: 0.08600420884788036
[Epoch 19, Batch 700] loss: 0.08883180517703294
**STATS for Epoch 19** : 
Average training loss: 0.0053
Average validation loss: 0.0912
Validation Accuracy: 0.9736
Overfitting: 0.0859
Best model saved at epoch 19 with validation loss: 0.0912
[Epoch 20, Batch 100] loss: 0.09410604249686003
[Epoch 20, Batch 200] loss: 0.07720167687162757
[Epoch 20, Batch 300] loss: 0.08777549585327506
[Epoch 20, Batch 400] loss: 0.08536419617943465
[Epoch 20, Batch 500] loss: 0.07920543886721135
[Epoch 20, Batch 600] loss: 0.08462014600634575
[Epoch 20, Batch 700] loss: 0.08025090301409364
**STATS for Epoch 20** : 
Average training loss: 0.0052
Average validation loss: 0.0910
Validation Accuracy: 0.9720
Overfitting: 0.0858
Best model saved at epoch 20 with validation loss: 0.0910
[Epoch 21, Batch 100] loss: 0.07569552689790726
[Epoch 21, Batch 200] loss: 0.08938276833854615
[Epoch 21, Batch 300] loss: 0.08200618553906679
[Epoch 21, Batch 400] loss: 0.07748114537447691
[Epoch 21, Batch 500] loss: 0.08523310063406825
[Epoch 21, Batch 600] loss: 0.07657234311103821
[Epoch 21, Batch 700] loss: 0.0824074393324554
**STATS for Epoch 21** : 
Average training loss: 0.0047
Average validation loss: 0.0916
Validation Accuracy: 0.9722
Overfitting: 0.0868
[Epoch 22, Batch 100] loss: 0.08088777388911694
[Epoch 22, Batch 200] loss: 0.07866812404245138
[Epoch 22, Batch 300] loss: 0.07128424440510571
[Epoch 22, Batch 400] loss: 0.07057494656182825
[Epoch 22, Batch 500] loss: 0.08569243740290404
[Epoch 22, Batch 600] loss: 0.07970804224722088
[Epoch 22, Batch 700] loss: 0.08073922879993915
**STATS for Epoch 22** : 
Average training loss: 0.0048
Average validation loss: 0.0824
Validation Accuracy: 0.9748
Overfitting: 0.0776
Best model saved at epoch 22 with validation loss: 0.0824
[Epoch 23, Batch 100] loss: 0.08361577555537224
[Epoch 23, Batch 200] loss: 0.0763225285988301
[Epoch 23, Batch 300] loss: 0.06709238708019256
[Epoch 23, Batch 400] loss: 0.07361142327077687
[Epoch 23, Batch 500] loss: 0.07678543615154922
[Epoch 23, Batch 600] loss: 0.0791260602325201
[Epoch 23, Batch 700] loss: 0.07442710043862462
**STATS for Epoch 23** : 
Average training loss: 0.0044
Average validation loss: 0.0805
Validation Accuracy: 0.9757
Overfitting: 0.0761
Best model saved at epoch 23 with validation loss: 0.0805
[Epoch 24, Batch 100] loss: 0.06763212651014328
[Epoch 24, Batch 200] loss: 0.07169019804336131
[Epoch 24, Batch 300] loss: 0.07677792854374274
[Epoch 24, Batch 400] loss: 0.0747829938447103
[Epoch 24, Batch 500] loss: 0.07246315928176045
[Epoch 24, Batch 600] loss: 0.07474400967359543
[Epoch 24, Batch 700] loss: 0.06560478324070573
**STATS for Epoch 24** : 
Average training loss: 0.0051
Average validation loss: 0.0813
Validation Accuracy: 0.9759
Overfitting: 0.0762
Fold 5 validation loss: 0.0813
Mean validation loss across all folds for Trial 2 is 0.0809 with trial config:  l1: 256, l2: 64, lr: 0.0002310201887845295, batch_size: 64
[I 2024-12-10 05:18:41,157] Trial 1 finished with value: 0.08092438080496692 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0002310201887845295, 'batch_size': 64}. Best is trial 1 with value: 0.08092438080496692.

Selected Hyperparameters for Trial 3:
  l1: 128, l2: 128, lr: 0.000816845589476017, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.300757727622986
[Epoch 1, Batch 200] loss: 2.285334289073944
[Epoch 1, Batch 300] loss: 2.255316820144653
[Epoch 1, Batch 400] loss: 2.1518690323829652
[Epoch 1, Batch 500] loss: 1.6693262803554534
[Epoch 1, Batch 600] loss: 0.8543479734659195
[Epoch 1, Batch 700] loss: 0.5551229008287192
[Epoch 1, Batch 800] loss: 0.46842043347656726
[Epoch 1, Batch 900] loss: 0.471477862149477
[Epoch 1, Batch 1000] loss: 0.36354999281466005
[Epoch 1, Batch 1100] loss: 0.3357086179405451
[Epoch 1, Batch 1200] loss: 0.3021470596641302
[Epoch 1, Batch 1300] loss: 0.32967473298311234
[Epoch 1, Batch 1400] loss: 0.3124249825999141
[Epoch 1, Batch 1500] loss: 0.23946260103955866
[Epoch 1, Batch 1600] loss: 0.2730494990944862
[Epoch 1, Batch 1700] loss: 0.20327145676128566
[Epoch 1, Batch 1800] loss: 0.2077037300541997
[Epoch 1, Batch 1900] loss: 0.2160840581730008
[Epoch 1, Batch 2000] loss: 0.17970822491683067
[Epoch 1, Batch 2100] loss: 0.19787981868721544
[Epoch 1, Batch 2200] loss: 0.17438790540210902
[Epoch 1, Batch 2300] loss: 0.1774769074842334
[Epoch 1, Batch 2400] loss: 0.15765227989293634
[Epoch 1, Batch 2500] loss: 0.18372166741173715
[Epoch 1, Batch 2600] loss: 0.15397573122754693
[Epoch 1, Batch 2700] loss: 0.1713269907189533
[Epoch 1, Batch 2800] loss: 0.16179735666140915
[Epoch 1, Batch 2900] loss: 0.14074037824757396
[Epoch 1, Batch 3000] loss: 0.13574710047338157
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1413
Validation Accuracy: 0.9560
Overfitting: 0.1413
Best model saved at epoch 1 with validation loss: 0.1413
[Epoch 2, Batch 100] loss: 0.12137580109760165
[Epoch 2, Batch 200] loss: 0.14254601079737766
[Epoch 2, Batch 300] loss: 0.10774994870880619
[Epoch 2, Batch 400] loss: 0.15911027700640262
[Epoch 2, Batch 500] loss: 0.12576548749115318
[Epoch 2, Batch 600] loss: 0.11240794225595892
[Epoch 2, Batch 700] loss: 0.12496340275858529
[Epoch 2, Batch 800] loss: 0.11531786353094503
[Epoch 2, Batch 900] loss: 0.10626185997389256
[Epoch 2, Batch 1000] loss: 0.11571448245085776
[Epoch 2, Batch 1100] loss: 0.11906260647810996
[Epoch 2, Batch 1200] loss: 0.12570576719474047
[Epoch 2, Batch 1300] loss: 0.11236907264683396
[Epoch 2, Batch 1400] loss: 0.10918662756448612
[Epoch 2, Batch 1500] loss: 0.08637493191752582
[Epoch 2, Batch 1600] loss: 0.11458456680644304
[Epoch 2, Batch 1700] loss: 0.10165254113962874
[Epoch 2, Batch 1800] loss: 0.09193888736073859
[Epoch 2, Batch 1900] loss: 0.11545553940348327
[Epoch 2, Batch 2000] loss: 0.13023660335689782
[Epoch 2, Batch 2100] loss: 0.11156818587565795
[Epoch 2, Batch 2200] loss: 0.07985382163431495
[Epoch 2, Batch 2300] loss: 0.12715192811214365
[Epoch 2, Batch 2400] loss: 0.09214645858854055
[Epoch 2, Batch 2500] loss: 0.09583768185577356
[Epoch 2, Batch 2600] loss: 0.09229685640195384
[Epoch 2, Batch 2700] loss: 0.09054843212943524
[Epoch 2, Batch 2800] loss: 0.09195754133514128
[Epoch 2, Batch 2900] loss: 0.1003597432281822
[Epoch 2, Batch 3000] loss: 0.10287782091414556
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0810
Validation Accuracy: 0.9742
Overfitting: 0.0810
Best model saved at epoch 2 with validation loss: 0.0810
[Epoch 3, Batch 100] loss: 0.09021943284315057
[Epoch 3, Batch 200] loss: 0.08032787845586427
[Epoch 3, Batch 300] loss: 0.08537532944465057
[Epoch 3, Batch 400] loss: 0.06021988824941218
[Epoch 3, Batch 500] loss: 0.0745876737096114
[Epoch 3, Batch 600] loss: 0.08660701735410839
[Epoch 3, Batch 700] loss: 0.08658226765634026
[Epoch 3, Batch 800] loss: 0.07782641753205098
[Epoch 3, Batch 900] loss: 0.07648253392544575
[Epoch 3, Batch 1000] loss: 0.08551003083819524
[Epoch 3, Batch 1100] loss: 0.08152484519116115
[Epoch 3, Batch 1200] loss: 0.06616058475803584
[Epoch 3, Batch 1300] loss: 0.06982652669772506
[Epoch 3, Batch 1400] loss: 0.08674407186452299
[Epoch 3, Batch 1500] loss: 0.07206990591424983
[Epoch 3, Batch 1600] loss: 0.07503155766054988
[Epoch 3, Batch 1700] loss: 0.06679510106216185
[Epoch 3, Batch 1800] loss: 0.09239377511665225
[Epoch 3, Batch 1900] loss: 0.07030359109048731
[Epoch 3, Batch 2000] loss: 0.08797974476939999
[Epoch 3, Batch 2100] loss: 0.08033150436589494
[Epoch 3, Batch 2200] loss: 0.058728066248586404
[Epoch 3, Batch 2300] loss: 0.06237064949556952
[Epoch 3, Batch 2400] loss: 0.09403897361014969
[Epoch 3, Batch 2500] loss: 0.06298531270702369
[Epoch 3, Batch 2600] loss: 0.05583512424316723
[Epoch 3, Batch 2700] loss: 0.07319299908122048
[Epoch 3, Batch 2800] loss: 0.0662479832128156
[Epoch 3, Batch 2900] loss: 0.08224003453040496
[Epoch 3, Batch 3000] loss: 0.07304133362136782
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0621
Validation Accuracy: 0.9802
Overfitting: 0.0621
Best model saved at epoch 3 with validation loss: 0.0621
[Epoch 4, Batch 100] loss: 0.067689086466562
[Epoch 4, Batch 200] loss: 0.05991544248361606
[Epoch 4, Batch 300] loss: 0.05345282134367153
[Epoch 4, Batch 400] loss: 0.06852471218910068
[Epoch 4, Batch 500] loss: 0.056856325968401504
[Epoch 4, Batch 600] loss: 0.04154940205640742
[Epoch 4, Batch 700] loss: 0.04993202338751871
[Epoch 4, Batch 800] loss: 0.06850157028238754
[Epoch 4, Batch 900] loss: 0.051562468755437296
[Epoch 4, Batch 1000] loss: 0.05472542503848672
[Epoch 4, Batch 1100] loss: 0.05082347211369779
[Epoch 4, Batch 1200] loss: 0.05708577535115182
[Epoch 4, Batch 1300] loss: 0.07279394404322374
[Epoch 4, Batch 1400] loss: 0.045849464815109965
[Epoch 4, Batch 1500] loss: 0.06791303821722977
[Epoch 4, Batch 1600] loss: 0.07178057462529978
[Epoch 4, Batch 1700] loss: 0.0512971591076348
[Epoch 4, Batch 1800] loss: 0.046178348340908996
[Epoch 4, Batch 1900] loss: 0.08035188830661355
[Epoch 4, Batch 2000] loss: 0.07349281476577744
[Epoch 4, Batch 2100] loss: 0.05665442851895932
[Epoch 4, Batch 2200] loss: 0.06595902176864911
[Epoch 4, Batch 2300] loss: 0.06801513490790967
[Epoch 4, Batch 2400] loss: 0.06857754377619131
[Epoch 4, Batch 2500] loss: 0.06564387627469842
[Epoch 4, Batch 2600] loss: 0.07540599516010843
[Epoch 4, Batch 2700] loss: 0.05575978013686836
[Epoch 4, Batch 2800] loss: 0.04497810052300338
[Epoch 4, Batch 2900] loss: 0.04780569159192964
[Epoch 4, Batch 3000] loss: 0.06210089501313632
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9798
Overfitting: 0.0632
[Epoch 5, Batch 100] loss: 0.044537757579237225
[Epoch 5, Batch 200] loss: 0.05909050520553137
[Epoch 5, Batch 300] loss: 0.05508595378720202
[Epoch 5, Batch 400] loss: 0.04848266024375334
[Epoch 5, Batch 500] loss: 0.048285003368364415
[Epoch 5, Batch 600] loss: 0.03858712407381972
[Epoch 5, Batch 700] loss: 0.04905663916200865
[Epoch 5, Batch 800] loss: 0.04656547361635603
[Epoch 5, Batch 900] loss: 0.06371418675291352
[Epoch 5, Batch 1000] loss: 0.06007852836220991
[Epoch 5, Batch 1100] loss: 0.05078780669049593
[Epoch 5, Batch 1200] loss: 0.05116721672995481
[Epoch 5, Batch 1300] loss: 0.04468703892664053
[Epoch 5, Batch 1400] loss: 0.05793456017272547
[Epoch 5, Batch 1500] loss: 0.051438328980584626
[Epoch 5, Batch 1600] loss: 0.04997192961316614
[Epoch 5, Batch 1700] loss: 0.04371622221136931
[Epoch 5, Batch 1800] loss: 0.04049744114163332
[Epoch 5, Batch 1900] loss: 0.033618587519740686
[Epoch 5, Batch 2000] loss: 0.05458125377946999
[Epoch 5, Batch 2100] loss: 0.058490356904803774
[Epoch 5, Batch 2200] loss: 0.06969417067128234
[Epoch 5, Batch 2300] loss: 0.0440421265020268
[Epoch 5, Batch 2400] loss: 0.046549653002875856
[Epoch 5, Batch 2500] loss: 0.04546753664064454
[Epoch 5, Batch 2600] loss: 0.04270999530854169
[Epoch 5, Batch 2700] loss: 0.049755233096657324
[Epoch 5, Batch 2800] loss: 0.05942277599242516
[Epoch 5, Batch 2900] loss: 0.04187320309167262
[Epoch 5, Batch 3000] loss: 0.04428029912727652
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9828
Overfitting: 0.0544
Best model saved at epoch 5 with validation loss: 0.0544
[Epoch 6, Batch 100] loss: 0.05437032452653511
[Epoch 6, Batch 200] loss: 0.02882727362186415
[Epoch 6, Batch 300] loss: 0.02948475650686305
[Epoch 6, Batch 400] loss: 0.04493229715502821
[Epoch 6, Batch 500] loss: 0.045424227872281335
[Epoch 6, Batch 600] loss: 0.046964487798104526
[Epoch 6, Batch 700] loss: 0.046565834223583805
[Epoch 6, Batch 800] loss: 0.05162926060263999
[Epoch 6, Batch 900] loss: 0.048908108471659946
[Epoch 6, Batch 1000] loss: 0.04250017058337107
[Epoch 6, Batch 1100] loss: 0.04135276179062203
[Epoch 6, Batch 1200] loss: 0.03635213996531093
[Epoch 6, Batch 1300] loss: 0.03226295761531219
[Epoch 6, Batch 1400] loss: 0.05414645406970522
[Epoch 6, Batch 1500] loss: 0.03807340074286913
[Epoch 6, Batch 1600] loss: 0.05559929985945928
[Epoch 6, Batch 1700] loss: 0.04344398848566925
[Epoch 6, Batch 1800] loss: 0.04007993154591531
[Epoch 6, Batch 1900] loss: 0.042369290826973154
[Epoch 6, Batch 2000] loss: 0.031679038463626054
[Epoch 6, Batch 2100] loss: 0.04857180717954179
[Epoch 6, Batch 2200] loss: 0.047779753453214655
[Epoch 6, Batch 2300] loss: 0.0379409959827899
[Epoch 6, Batch 2400] loss: 0.043614271730184555
[Epoch 6, Batch 2500] loss: 0.03402621624059975
[Epoch 6, Batch 2600] loss: 0.03742403778524021
[Epoch 6, Batch 2700] loss: 0.038827707588352495
[Epoch 6, Batch 2800] loss: 0.03164261852856726
[Epoch 6, Batch 2900] loss: 0.04846202652886859
[Epoch 6, Batch 3000] loss: 0.0432747079024557
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0488
Validation Accuracy: 0.9847
Overfitting: 0.0488
Best model saved at epoch 6 with validation loss: 0.0488
[Epoch 7, Batch 100] loss: 0.027416673698462547
[Epoch 7, Batch 200] loss: 0.022617700577829965
[Epoch 7, Batch 300] loss: 0.03509196472994518
[Epoch 7, Batch 400] loss: 0.03998243635956897
[Epoch 7, Batch 500] loss: 0.03608280877553625
[Epoch 7, Batch 600] loss: 0.03708781239925884
[Epoch 7, Batch 700] loss: 0.03491055393733404
[Epoch 7, Batch 800] loss: 0.024812659259769134
[Epoch 7, Batch 900] loss: 0.04746170985294157
[Epoch 7, Batch 1000] loss: 0.04223085352292401
[Epoch 7, Batch 1100] loss: 0.031542410245747304
[Epoch 7, Batch 1200] loss: 0.04192981298459927
[Epoch 7, Batch 1300] loss: 0.0415033359717927
[Epoch 7, Batch 1400] loss: 0.05284157047506596
[Epoch 7, Batch 1500] loss: 0.05362625648675021
[Epoch 7, Batch 1600] loss: 0.03790924772401923
[Epoch 7, Batch 1700] loss: 0.042985366164939476
[Epoch 7, Batch 1800] loss: 0.029144013568584343
[Epoch 7, Batch 1900] loss: 0.042599645747977775
[Epoch 7, Batch 2000] loss: 0.04463819939053792
[Epoch 7, Batch 2100] loss: 0.04063509924177197
[Epoch 7, Batch 2200] loss: 0.03070480510694324
[Epoch 7, Batch 2300] loss: 0.03179312312262482
[Epoch 7, Batch 2400] loss: 0.033288730282656616
[Epoch 7, Batch 2500] loss: 0.0355469752807403
[Epoch 7, Batch 2600] loss: 0.032047802399029025
[Epoch 7, Batch 2700] loss: 0.02664051668027241
[Epoch 7, Batch 2800] loss: 0.036130175676953515
[Epoch 7, Batch 2900] loss: 0.030272895054877152
[Epoch 7, Batch 3000] loss: 0.04475033272057772
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9838
Overfitting: 0.0522
[Epoch 8, Batch 100] loss: 0.02853450837479613
[Epoch 8, Batch 200] loss: 0.03334356261009816
[Epoch 8, Batch 300] loss: 0.03296920667271479
[Epoch 8, Batch 400] loss: 0.022008462779631373
[Epoch 8, Batch 500] loss: 0.03436516330679296
[Epoch 8, Batch 600] loss: 0.039471223597938664
[Epoch 8, Batch 700] loss: 0.03087764925661759
[Epoch 8, Batch 800] loss: 0.032040947732311906
[Epoch 8, Batch 900] loss: 0.02945332263057935
[Epoch 8, Batch 1000] loss: 0.028842922360781814
[Epoch 8, Batch 1100] loss: 0.026851841147290542
[Epoch 8, Batch 1200] loss: 0.03285956766922027
[Epoch 8, Batch 1300] loss: 0.028518994936312082
[Epoch 8, Batch 1400] loss: 0.038966988586471414
[Epoch 8, Batch 1500] loss: 0.03523249504462001
[Epoch 8, Batch 1600] loss: 0.025038095186027932
[Epoch 8, Batch 1700] loss: 0.028324824778101176
[Epoch 8, Batch 1800] loss: 0.02226072139907046
[Epoch 8, Batch 1900] loss: 0.029869928220723523
[Epoch 8, Batch 2000] loss: 0.05130235023709247
[Epoch 8, Batch 2100] loss: 0.031910624774100144
[Epoch 8, Batch 2200] loss: 0.029748870417024592
[Epoch 8, Batch 2300] loss: 0.027751741147221766
[Epoch 8, Batch 2400] loss: 0.036955632733297536
[Epoch 8, Batch 2500] loss: 0.02277305125418934
[Epoch 8, Batch 2600] loss: 0.051608706394727054
[Epoch 8, Batch 2700] loss: 0.03605053286679322
[Epoch 8, Batch 2800] loss: 0.047124948300770485
[Epoch 8, Batch 2900] loss: 0.022246706053992968
[Epoch 8, Batch 3000] loss: 0.03502459870825987
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0435
Validation Accuracy: 0.9858
Overfitting: 0.0435
Best model saved at epoch 8 with validation loss: 0.0435
[Epoch 9, Batch 100] loss: 0.021724993687676032
[Epoch 9, Batch 200] loss: 0.036759565894753904
[Epoch 9, Batch 300] loss: 0.01868938157120283
[Epoch 9, Batch 400] loss: 0.02070413321023807
[Epoch 9, Batch 500] loss: 0.032154404706525384
[Epoch 9, Batch 600] loss: 0.03270480845487327
[Epoch 9, Batch 700] loss: 0.023027508486266016
[Epoch 9, Batch 800] loss: 0.01948290646840178
[Epoch 9, Batch 900] loss: 0.03230879186710808
[Epoch 9, Batch 1000] loss: 0.042255093895364554
[Epoch 9, Batch 1100] loss: 0.022644704310660017
[Epoch 9, Batch 1200] loss: 0.03037502777959162
[Epoch 9, Batch 1300] loss: 0.029664546303774842
[Epoch 9, Batch 1400] loss: 0.019406876493958405
[Epoch 9, Batch 1500] loss: 0.026364250165061096
[Epoch 9, Batch 1600] loss: 0.031194336157641375
[Epoch 9, Batch 1700] loss: 0.02852363622016128
[Epoch 9, Batch 1800] loss: 0.026857947669959685
[Epoch 9, Batch 1900] loss: 0.025431733855220955
[Epoch 9, Batch 2000] loss: 0.016335761550508324
[Epoch 9, Batch 2100] loss: 0.03468475197510998
[Epoch 9, Batch 2200] loss: 0.03325312763601687
[Epoch 9, Batch 2300] loss: 0.029149426520853013
[Epoch 9, Batch 2400] loss: 0.02043216031874181
[Epoch 9, Batch 2500] loss: 0.022427161042724037
[Epoch 9, Batch 2600] loss: 0.033058521201091935
[Epoch 9, Batch 2700] loss: 0.026409894982425613
[Epoch 9, Batch 2800] loss: 0.030632673112031626
[Epoch 9, Batch 2900] loss: 0.04368960055093339
[Epoch 9, Batch 3000] loss: 0.025998854034769467
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0407
Validation Accuracy: 0.9870
Overfitting: 0.0407
Best model saved at epoch 9 with validation loss: 0.0407
[Epoch 10, Batch 100] loss: 0.01797574260366673
[Epoch 10, Batch 200] loss: 0.02384475317936449
[Epoch 10, Batch 300] loss: 0.03064887794281276
[Epoch 10, Batch 400] loss: 0.01912874061068578
[Epoch 10, Batch 500] loss: 0.025096163760172204
[Epoch 10, Batch 600] loss: 0.02416887612414939
[Epoch 10, Batch 700] loss: 0.016606971918736235
[Epoch 10, Batch 800] loss: 0.018015642092541383
[Epoch 10, Batch 900] loss: 0.02007099204854967
[Epoch 10, Batch 1000] loss: 0.021517546979375766
[Epoch 10, Batch 1100] loss: 0.017131089290815
[Epoch 10, Batch 1200] loss: 0.03493612567035598
[Epoch 10, Batch 1300] loss: 0.026185175172613526
[Epoch 10, Batch 1400] loss: 0.040710733309242644
[Epoch 10, Batch 1500] loss: 0.02188819471106399
[Epoch 10, Batch 1600] loss: 0.023977914952356513
[Epoch 10, Batch 1700] loss: 0.02095799019891274
[Epoch 10, Batch 1800] loss: 0.02423267485013639
[Epoch 10, Batch 1900] loss: 0.018966390932910145
[Epoch 10, Batch 2000] loss: 0.023676163945892767
[Epoch 10, Batch 2100] loss: 0.044003444138434135
[Epoch 10, Batch 2200] loss: 0.0316716168228595
[Epoch 10, Batch 2300] loss: 0.026039861497483798
[Epoch 10, Batch 2400] loss: 0.028600528908064006
[Epoch 10, Batch 2500] loss: 0.02983136674236903
[Epoch 10, Batch 2600] loss: 0.029557303512410725
[Epoch 10, Batch 2700] loss: 0.02438706018816447
[Epoch 10, Batch 2800] loss: 0.02084402980894083
[Epoch 10, Batch 2900] loss: 0.02131265748746955
[Epoch 10, Batch 3000] loss: 0.02047408694328624
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0413
Validation Accuracy: 0.9877
Overfitting: 0.0413
[Epoch 11, Batch 100] loss: 0.019646253234641337
[Epoch 11, Batch 200] loss: 0.022796451971953503
[Epoch 11, Batch 300] loss: 0.016051362394500758
[Epoch 11, Batch 400] loss: 0.021627462708438544
[Epoch 11, Batch 500] loss: 0.016594841674232155
[Epoch 11, Batch 600] loss: 0.03623451573635975
[Epoch 11, Batch 700] loss: 0.024554300827585394
[Epoch 11, Batch 800] loss: 0.022303784134564922
[Epoch 11, Batch 900] loss: 0.019967729499203415
[Epoch 11, Batch 1000] loss: 0.02171820048126392
[Epoch 11, Batch 1100] loss: 0.0156834329452613
[Epoch 11, Batch 1200] loss: 0.013410492471903126
[Epoch 11, Batch 1300] loss: 0.018081273799143673
[Epoch 11, Batch 1400] loss: 0.01564198538857454
[Epoch 11, Batch 1500] loss: 0.023957144010091726
[Epoch 11, Batch 1600] loss: 0.024559785977698992
[Epoch 11, Batch 1700] loss: 0.022031535434307442
[Epoch 11, Batch 1800] loss: 0.014434279477864038
[Epoch 11, Batch 1900] loss: 0.0185417778844203
[Epoch 11, Batch 2000] loss: 0.02376463903054173
[Epoch 11, Batch 2100] loss: 0.01694626428144602
[Epoch 11, Batch 2200] loss: 0.03250600055107498
[Epoch 11, Batch 2300] loss: 0.014262852540614403
[Epoch 11, Batch 2400] loss: 0.03266653982511343
[Epoch 11, Batch 2500] loss: 0.0274092454615311
[Epoch 11, Batch 2600] loss: 0.02321365234123732
[Epoch 11, Batch 2700] loss: 0.02351019578436535
[Epoch 11, Batch 2800] loss: 0.016560242930609093
[Epoch 11, Batch 2900] loss: 0.012113419056368003
[Epoch 11, Batch 3000] loss: 0.0300336535729366
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9849
Overfitting: 0.0513
[Epoch 12, Batch 100] loss: 0.022775720070239914
[Epoch 12, Batch 200] loss: 0.016488885145845414
[Epoch 12, Batch 300] loss: 0.011031227841158397
[Epoch 12, Batch 400] loss: 0.012601892724596837
[Epoch 12, Batch 500] loss: 0.017514466938664555
[Epoch 12, Batch 600] loss: 0.027463012669832098
[Epoch 12, Batch 700] loss: 0.015090506255837681
[Epoch 12, Batch 800] loss: 0.025506318775660473
[Epoch 12, Batch 900] loss: 0.019850869491310732
[Epoch 12, Batch 1000] loss: 0.010514867908750603
[Epoch 12, Batch 1100] loss: 0.010876138691855886
[Epoch 12, Batch 1200] loss: 0.01462210321053135
[Epoch 12, Batch 1300] loss: 0.017456390585866757
[Epoch 12, Batch 1400] loss: 0.020910717585193198
[Epoch 12, Batch 1500] loss: 0.023068528372459696
[Epoch 12, Batch 1600] loss: 0.01893789664844917
[Epoch 12, Batch 1700] loss: 0.01984626527184446
[Epoch 12, Batch 1800] loss: 0.019661001863096318
[Epoch 12, Batch 1900] loss: 0.027317814816560714
[Epoch 12, Batch 2000] loss: 0.015936556485912662
[Epoch 12, Batch 2100] loss: 0.023830827327037694
[Epoch 12, Batch 2200] loss: 0.019939496636179683
[Epoch 12, Batch 2300] loss: 0.025910085852519842
[Epoch 12, Batch 2400] loss: 0.017999282623713954
[Epoch 12, Batch 2500] loss: 0.021219432136858812
[Epoch 12, Batch 2600] loss: 0.021175047047854605
[Epoch 12, Batch 2700] loss: 0.029189722201408586
[Epoch 12, Batch 2800] loss: 0.015526976528708474
[Epoch 12, Batch 2900] loss: 0.02229268876459173
[Epoch 12, Batch 3000] loss: 0.026726639120606705
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9867
Overfitting: 0.0455
[Epoch 13, Batch 100] loss: 0.01664383482904668
[Epoch 13, Batch 200] loss: 0.009936344727975666
[Epoch 13, Batch 300] loss: 0.01441370435751196
[Epoch 13, Batch 400] loss: 0.02581238138987828
[Epoch 13, Batch 500] loss: 0.013258328998963407
[Epoch 13, Batch 600] loss: 0.019872385339199355
[Epoch 13, Batch 700] loss: 0.025648189825296867
[Epoch 13, Batch 800] loss: 0.016834375200960493
[Epoch 13, Batch 900] loss: 0.020462558433282537
[Epoch 13, Batch 1000] loss: 0.01085598866462533
[Epoch 13, Batch 1100] loss: 0.024263485415722243
[Epoch 13, Batch 1200] loss: 0.011329365968149431
[Epoch 13, Batch 1300] loss: 0.0317294620044413
[Epoch 13, Batch 1400] loss: 0.021376701338012935
[Epoch 13, Batch 1500] loss: 0.015003716070405062
[Epoch 13, Batch 1600] loss: 0.024216896923901457
[Epoch 13, Batch 1700] loss: 0.015059072321428175
[Epoch 13, Batch 1800] loss: 0.02263984202689244
[Epoch 13, Batch 1900] loss: 0.016907629293036734
[Epoch 13, Batch 2000] loss: 0.011534454697994079
[Epoch 13, Batch 2100] loss: 0.027231607814828748
[Epoch 13, Batch 2200] loss: 0.028718677466677035
[Epoch 13, Batch 2300] loss: 0.012214057038836473
[Epoch 13, Batch 2400] loss: 0.011865429549434339
[Epoch 13, Batch 2500] loss: 0.011863632973836502
[Epoch 13, Batch 2600] loss: 0.014746493373681915
[Epoch 13, Batch 2700] loss: 0.01581980745140754
[Epoch 13, Batch 2800] loss: 0.015952381233619237
[Epoch 13, Batch 2900] loss: 0.018796514988716807
[Epoch 13, Batch 3000] loss: 0.03001077119639376
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0416
Validation Accuracy: 0.9879
Overfitting: 0.0416
[Epoch 14, Batch 100] loss: 0.015834236632363174
[Epoch 14, Batch 200] loss: 0.018682160190837748
[Epoch 14, Batch 300] loss: 0.013249111113027538
[Epoch 14, Batch 400] loss: 0.02150577264075764
[Epoch 14, Batch 500] loss: 0.006638143127001967
[Epoch 14, Batch 600] loss: 0.013527026254450902
[Epoch 14, Batch 700] loss: 0.020434116692413226
[Epoch 14, Batch 800] loss: 0.01110016983337573
[Epoch 14, Batch 900] loss: 0.01686075554756826
[Epoch 14, Batch 1000] loss: 0.014003307550510727
[Epoch 14, Batch 1100] loss: 0.010503477842357825
[Epoch 14, Batch 1200] loss: 0.01938332991419884
[Epoch 14, Batch 1300] loss: 0.012840581025193388
[Epoch 14, Batch 1400] loss: 0.009853152614396095
[Epoch 14, Batch 1500] loss: 0.011199356086654006
[Epoch 14, Batch 1600] loss: 0.019131885653732753
[Epoch 14, Batch 1700] loss: 0.014068852245363814
[Epoch 14, Batch 1800] loss: 0.012634911388322507
[Epoch 14, Batch 1900] loss: 0.016378403782791793
[Epoch 14, Batch 2000] loss: 0.0076152862847266075
[Epoch 14, Batch 2100] loss: 0.011882477803483197
[Epoch 14, Batch 2200] loss: 0.014305107285176746
[Epoch 14, Batch 2300] loss: 0.023157628686317367
[Epoch 14, Batch 2400] loss: 0.013777379056168684
[Epoch 14, Batch 2500] loss: 0.025955439697181646
[Epoch 14, Batch 2600] loss: 0.01791853858085233
[Epoch 14, Batch 2700] loss: 0.015654106479678374
[Epoch 14, Batch 2800] loss: 0.021680163828141304
[Epoch 14, Batch 2900] loss: 0.031159066908148816
[Epoch 14, Batch 3000] loss: 0.02034921285288874
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9878
Overfitting: 0.0453
[Epoch 15, Batch 100] loss: 0.02193781213616603
[Epoch 15, Batch 200] loss: 0.007538102340186014
[Epoch 15, Batch 300] loss: 0.01005661149531079
[Epoch 15, Batch 400] loss: 0.015092046874706284
[Epoch 15, Batch 500] loss: 0.01269064862301093
[Epoch 15, Batch 600] loss: 0.017982991663720894
[Epoch 15, Batch 700] loss: 0.013111231792536274
[Epoch 15, Batch 800] loss: 0.010999640563513822
[Epoch 15, Batch 900] loss: 0.009986233352037743
[Epoch 15, Batch 1000] loss: 0.013099329868255153
[Epoch 15, Batch 1100] loss: 0.012960212954785675
[Epoch 15, Batch 1200] loss: 0.009675351357818726
[Epoch 15, Batch 1300] loss: 0.014021753917572823
[Epoch 15, Batch 1400] loss: 0.01830988397508918
[Epoch 15, Batch 1500] loss: 0.008473306370419778
[Epoch 15, Batch 1600] loss: 0.011623519125514577
[Epoch 15, Batch 1700] loss: 0.008132600629242006
[Epoch 15, Batch 1800] loss: 0.011280055857630486
[Epoch 15, Batch 1900] loss: 0.012731953782690653
[Epoch 15, Batch 2000] loss: 0.010037175347588346
[Epoch 15, Batch 2100] loss: 0.019515955574679538
[Epoch 15, Batch 2200] loss: 0.017203848095505236
[Epoch 15, Batch 2300] loss: 0.0211825563597813
[Epoch 15, Batch 2400] loss: 0.024414761791222192
[Epoch 15, Batch 2500] loss: 0.013535513082733814
[Epoch 15, Batch 2600] loss: 0.0060694292980406316
[Epoch 15, Batch 2700] loss: 0.024452453825606426
[Epoch 15, Batch 2800] loss: 0.008621810498657395
[Epoch 15, Batch 2900] loss: 0.007574215092108716
[Epoch 15, Batch 3000] loss: 0.012754825499869185
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9882
Overfitting: 0.0431
[Epoch 16, Batch 100] loss: 0.008067771569155866
[Epoch 16, Batch 200] loss: 0.007297248938803022
[Epoch 16, Batch 300] loss: 0.006412503977744563
[Epoch 16, Batch 400] loss: 0.008694748968773638
[Epoch 16, Batch 500] loss: 0.006689331999157275
[Epoch 16, Batch 600] loss: 0.011296249132356025
[Epoch 16, Batch 700] loss: 0.006373911328150825
[Epoch 16, Batch 800] loss: 0.009733181591245739
[Epoch 16, Batch 900] loss: 0.011698172964186142
[Epoch 16, Batch 1000] loss: 0.009987008982952829
[Epoch 16, Batch 1100] loss: 0.01761470896767605
[Epoch 16, Batch 1200] loss: 0.012054084481487735
[Epoch 16, Batch 1300] loss: 0.01662050891864055
[Epoch 16, Batch 1400] loss: 0.00999140053811061
[Epoch 16, Batch 1500] loss: 0.012888590594502602
[Epoch 16, Batch 1600] loss: 0.010525481492416021
[Epoch 16, Batch 1700] loss: 0.008579552254905138
[Epoch 16, Batch 1800] loss: 0.00781825910603402
[Epoch 16, Batch 1900] loss: 0.011021398850932656
[Epoch 16, Batch 2000] loss: 0.00849981641292743
[Epoch 16, Batch 2100] loss: 0.005646774360266136
[Epoch 16, Batch 2200] loss: 0.033089394594753685
[Epoch 16, Batch 2300] loss: 0.02552095830624694
[Epoch 16, Batch 2400] loss: 0.024369779726239358
[Epoch 16, Batch 2500] loss: 0.013362216286948296
[Epoch 16, Batch 2600] loss: 0.011332576632821657
[Epoch 16, Batch 2700] loss: 0.008967724898459437
[Epoch 16, Batch 2800] loss: 0.0161702698587942
[Epoch 16, Batch 2900] loss: 0.034174229789300625
[Epoch 16, Batch 3000] loss: 0.01715837994177491
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0435
Validation Accuracy: 0.9881
Overfitting: 0.0435
[Epoch 17, Batch 100] loss: 0.012918573995284533
[Epoch 17, Batch 200] loss: 0.012551609150978037
[Epoch 17, Batch 300] loss: 0.006536083132414205
[Epoch 17, Batch 400] loss: 0.005550078350152035
[Epoch 17, Batch 500] loss: 0.00856154352439262
[Epoch 17, Batch 600] loss: 0.011148478552699998
[Epoch 17, Batch 700] loss: 0.006344234221842271
[Epoch 17, Batch 800] loss: 0.007529417168143482
[Epoch 17, Batch 900] loss: 0.011474827212759919
[Epoch 17, Batch 1000] loss: 0.010586341363532483
[Epoch 17, Batch 1100] loss: 0.008582300255300197
[Epoch 17, Batch 1200] loss: 0.011335027547847858
[Epoch 17, Batch 1300] loss: 0.005878944313940338
[Epoch 17, Batch 1400] loss: 0.01616550344316238
[Epoch 17, Batch 1500] loss: 0.0139369851050958
[Epoch 17, Batch 1600] loss: 0.008043575610347489
[Epoch 17, Batch 1700] loss: 0.02227428641091137
[Epoch 17, Batch 1800] loss: 0.010949432505503865
[Epoch 17, Batch 1900] loss: 0.012375505125128257
[Epoch 17, Batch 2000] loss: 0.008923004724513248
[Epoch 17, Batch 2100] loss: 0.00867452053780653
[Epoch 17, Batch 2200] loss: 0.01633369258972266
[Epoch 17, Batch 2300] loss: 0.011225977399531075
[Epoch 17, Batch 2400] loss: 0.01978753297739786
[Epoch 17, Batch 2500] loss: 0.005707806179379986
[Epoch 17, Batch 2600] loss: 0.008430056814431737
[Epoch 17, Batch 2700] loss: 0.010449757721119113
[Epoch 17, Batch 2800] loss: 0.009172038162882928
[Epoch 17, Batch 2900] loss: 0.008454893232637914
[Epoch 17, Batch 3000] loss: 0.013639465818969257
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0440
Validation Accuracy: 0.9884
Overfitting: 0.0440
[Epoch 18, Batch 100] loss: 0.008169181310464069
[Epoch 18, Batch 200] loss: 0.007178097839487236
[Epoch 18, Batch 300] loss: 0.010574671351723736
[Epoch 18, Batch 400] loss: 0.007974334319389981
[Epoch 18, Batch 500] loss: 0.00928463002890112
[Epoch 18, Batch 600] loss: 0.005340920211128832
[Epoch 18, Batch 700] loss: 0.006670908221026366
[Epoch 18, Batch 800] loss: 0.012922297131362939
[Epoch 18, Batch 900] loss: 0.0110562247124426
[Epoch 18, Batch 1000] loss: 0.01719607131815792
[Epoch 18, Batch 1100] loss: 0.009938033748699126
[Epoch 18, Batch 1200] loss: 0.007568123136202302
[Epoch 18, Batch 1300] loss: 0.006980273115850651
[Epoch 18, Batch 1400] loss: 0.015647462467622972
[Epoch 18, Batch 1500] loss: 0.021033657949355983
[Epoch 18, Batch 1600] loss: 0.013904264470311319
[Epoch 18, Batch 1700] loss: 0.013402602950236542
[Epoch 18, Batch 1800] loss: 0.007500509213907662
[Epoch 18, Batch 1900] loss: 0.005461942923980132
[Epoch 18, Batch 2000] loss: 0.015709981786558275
[Epoch 18, Batch 2100] loss: 0.0102572601281463
[Epoch 18, Batch 2200] loss: 0.007624843884341317
[Epoch 18, Batch 2300] loss: 0.004974646721082081
[Epoch 18, Batch 2400] loss: 0.012408282902329119
[Epoch 18, Batch 2500] loss: 0.00832886559348026
[Epoch 18, Batch 2600] loss: 0.012441378561530882
[Epoch 18, Batch 2700] loss: 0.019181182624029135
[Epoch 18, Batch 2800] loss: 0.00964031724409324
[Epoch 18, Batch 2900] loss: 0.006005839893605298
[Epoch 18, Batch 3000] loss: 0.00691427505304091
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0425
Validation Accuracy: 0.9888
Overfitting: 0.0425
[Epoch 19, Batch 100] loss: 0.003230928285797745
[Epoch 19, Batch 200] loss: 0.005260874161522224
[Epoch 19, Batch 300] loss: 0.006447952320149853
[Epoch 19, Batch 400] loss: 0.013931245415451486
[Epoch 19, Batch 500] loss: 0.006472778939796626
[Epoch 19, Batch 600] loss: 0.014176476414445461
[Epoch 19, Batch 700] loss: 0.007646607135243357
[Epoch 19, Batch 800] loss: 0.007379013690060674
[Epoch 19, Batch 900] loss: 0.007330861700256719
[Epoch 19, Batch 1000] loss: 0.00805894653589803
[Epoch 19, Batch 1100] loss: 0.005652634284595024
[Epoch 19, Batch 1200] loss: 0.012002748080285529
[Epoch 19, Batch 1300] loss: 0.010611293491595007
[Epoch 19, Batch 1400] loss: 0.008709368598441358
[Epoch 19, Batch 1500] loss: 0.01016310698279085
[Epoch 19, Batch 1600] loss: 0.01337761691829428
[Epoch 19, Batch 1700] loss: 0.007479172967073282
[Epoch 19, Batch 1800] loss: 0.0043372747859109495
[Epoch 19, Batch 1900] loss: 0.004386046809863728
[Epoch 19, Batch 2000] loss: 0.0020897356739891394
[Epoch 19, Batch 2100] loss: 0.01899848856862718
[Epoch 19, Batch 2200] loss: 0.008889868822948302
[Epoch 19, Batch 2300] loss: 0.010578136094491129
[Epoch 19, Batch 2400] loss: 0.008878571152340555
[Epoch 19, Batch 2500] loss: 0.010171952696268818
[Epoch 19, Batch 2600] loss: 0.005899067871025636
[Epoch 19, Batch 2700] loss: 0.007545515741455801
[Epoch 19, Batch 2800] loss: 0.011078533305908422
[Epoch 19, Batch 2900] loss: 0.009063281644571361
[Epoch 19, Batch 3000] loss: 0.011699943239154891
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9878
Overfitting: 0.0458
[Epoch 20, Batch 100] loss: 0.0075773737645647545
[Epoch 20, Batch 200] loss: 0.0037601923114175405
[Epoch 20, Batch 300] loss: 0.0075103939481982705
[Epoch 20, Batch 400] loss: 0.005229773940005771
[Epoch 20, Batch 500] loss: 0.009341154282869866
[Epoch 20, Batch 600] loss: 0.006050943427038646
[Epoch 20, Batch 700] loss: 0.003843332367466701
[Epoch 20, Batch 800] loss: 0.009030196571056876
[Epoch 20, Batch 900] loss: 0.006796493422539243
[Epoch 20, Batch 1000] loss: 0.0028580581670871654
[Epoch 20, Batch 1100] loss: 0.004997847642285933
[Epoch 20, Batch 1200] loss: 0.007781150667643431
[Epoch 20, Batch 1300] loss: 0.005580725161410669
[Epoch 20, Batch 1400] loss: 0.001974962827150648
[Epoch 20, Batch 1500] loss: 0.017306470020608346
[Epoch 20, Batch 1600] loss: 0.007270682201423142
[Epoch 20, Batch 1700] loss: 0.00859020491260253
[Epoch 20, Batch 1800] loss: 0.003988600733991916
[Epoch 20, Batch 1900] loss: 0.004037651569198033
[Epoch 20, Batch 2000] loss: 0.005215071065430265
[Epoch 20, Batch 2100] loss: 0.025358280358498176
[Epoch 20, Batch 2200] loss: 0.015012969291137778
[Epoch 20, Batch 2300] loss: 0.009451270858166936
[Epoch 20, Batch 2400] loss: 0.008172298551595531
[Epoch 20, Batch 2500] loss: 0.006378061840325415
[Epoch 20, Batch 2600] loss: 0.011624170610150485
[Epoch 20, Batch 2700] loss: 0.005621188482808748
[Epoch 20, Batch 2800] loss: 0.018153950457913196
[Epoch 20, Batch 2900] loss: 0.012846973602854632
[Epoch 20, Batch 3000] loss: 0.008988242924251608
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9871
Overfitting: 0.0507
[Epoch 21, Batch 100] loss: 0.004300992883918298
[Epoch 21, Batch 200] loss: 0.0034282365424860473
[Epoch 21, Batch 300] loss: 0.006768832034731531
[Epoch 21, Batch 400] loss: 0.0030569696060410933
[Epoch 21, Batch 500] loss: 0.005084310456820731
[Epoch 21, Batch 600] loss: 0.014760332889009077
[Epoch 21, Batch 700] loss: 0.01513131760758597
[Epoch 21, Batch 800] loss: 0.007030110592270375
[Epoch 21, Batch 900] loss: 0.00805659108800228
[Epoch 21, Batch 1000] loss: 0.006063354664449889
[Epoch 21, Batch 1100] loss: 0.007939084295153408
[Epoch 21, Batch 1200] loss: 0.003062970697524179
[Epoch 21, Batch 1300] loss: 0.005095795967489494
[Epoch 21, Batch 1400] loss: 0.007382087138885254
[Epoch 21, Batch 1500] loss: 0.004245216877661733
[Epoch 21, Batch 1600] loss: 0.005500757908794185
[Epoch 21, Batch 1700] loss: 0.013216800265832945
[Epoch 21, Batch 1800] loss: 0.004034095078013706
[Epoch 21, Batch 1900] loss: 0.011066637685376008
[Epoch 21, Batch 2000] loss: 0.004697982073942057
[Epoch 21, Batch 2100] loss: 0.0051406260513897455
[Epoch 21, Batch 2200] loss: 0.005165336691325137
[Epoch 21, Batch 2300] loss: 0.003195080555219647
[Epoch 21, Batch 2400] loss: 0.00485742525066371
[Epoch 21, Batch 2500] loss: 0.003207535286373968
[Epoch 21, Batch 2600] loss: 0.0037878384652742627
[Epoch 21, Batch 2700] loss: 0.011519519126210867
[Epoch 21, Batch 2800] loss: 0.011942217309881471
[Epoch 21, Batch 2900] loss: 0.006474222492799981
[Epoch 21, Batch 3000] loss: 0.006841681298424191
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9878
Overfitting: 0.0479
[Epoch 22, Batch 100] loss: 0.0038293643843189786
[Epoch 22, Batch 200] loss: 0.003881338857271999
[Epoch 22, Batch 300] loss: 0.0025552477276983153
[Epoch 22, Batch 400] loss: 0.002717560388243072
[Epoch 22, Batch 500] loss: 0.009600121710977873
[Epoch 22, Batch 600] loss: 0.002993048984228608
[Epoch 22, Batch 700] loss: 0.003551044981580276
[Epoch 22, Batch 800] loss: 0.012489683939204497
[Epoch 22, Batch 900] loss: 0.006602203089787508
[Epoch 22, Batch 1000] loss: 0.010956184096069138
[Epoch 22, Batch 1100] loss: 0.008057697372112215
[Epoch 22, Batch 1200] loss: 0.010944619332292405
[Epoch 22, Batch 1300] loss: 0.00206727133240058
[Epoch 22, Batch 1400] loss: 0.003935629237357716
[Epoch 22, Batch 1500] loss: 0.005151997924292573
[Epoch 22, Batch 1600] loss: 0.006889885030428786
[Epoch 22, Batch 1700] loss: 0.01290666495886967
[Epoch 22, Batch 1800] loss: 0.004115695367061107
[Epoch 22, Batch 1900] loss: 0.017359763798344828
[Epoch 22, Batch 2000] loss: 0.006030781693137897
[Epoch 22, Batch 2100] loss: 0.00838453065676589
[Epoch 22, Batch 2200] loss: 0.003934598210087756
[Epoch 22, Batch 2300] loss: 0.003471198707932217
[Epoch 22, Batch 2400] loss: 0.001735286351457148
[Epoch 22, Batch 2500] loss: 0.0037921232352096015
[Epoch 22, Batch 2600] loss: 0.003764767115453651
[Epoch 22, Batch 2700] loss: 0.006434877240263859
[Epoch 22, Batch 2800] loss: 0.005359453953269053
[Epoch 22, Batch 2900] loss: 0.001214832748394201
[Epoch 22, Batch 3000] loss: 0.005543230894256794
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9892
Overfitting: 0.0449
[Epoch 23, Batch 100] loss: 0.0020805763084001685
[Epoch 23, Batch 200] loss: 0.0066118201433474156
[Epoch 23, Batch 300] loss: 0.003011035827773867
[Epoch 23, Batch 400] loss: 0.002316740243523441
[Epoch 23, Batch 500] loss: 0.0031675496378329626
[Epoch 23, Batch 600] loss: 0.002352901590993497
[Epoch 23, Batch 700] loss: 0.00304335212962485
[Epoch 23, Batch 800] loss: 0.0036615682948945506
[Epoch 23, Batch 900] loss: 0.0017897809999851688
[Epoch 23, Batch 1000] loss: 0.0021443795554324653
[Epoch 23, Batch 1100] loss: 0.002421165895468391
[Epoch 23, Batch 1200] loss: 0.0011906425647481456
[Epoch 23, Batch 1300] loss: 0.002862473978709659
[Epoch 23, Batch 1400] loss: 0.008078727387858748
[Epoch 23, Batch 1500] loss: 0.005640700668189993
[Epoch 23, Batch 1600] loss: 0.0023783849378551736
[Epoch 23, Batch 1700] loss: 0.001973675141542799
[Epoch 23, Batch 1800] loss: 0.002297252590208103
[Epoch 23, Batch 1900] loss: 0.005302129676889536
[Epoch 23, Batch 2000] loss: 0.003027371722960197
[Epoch 23, Batch 2100] loss: 0.0023627834131966096
[Epoch 23, Batch 2200] loss: 0.005175102791760651
[Epoch 23, Batch 2300] loss: 0.007274203749742583
[Epoch 23, Batch 2400] loss: 0.0046262430930886465
[Epoch 23, Batch 2500] loss: 0.007732452081629617
[Epoch 23, Batch 2600] loss: 0.010575006525504022
[Epoch 23, Batch 2700] loss: 0.008625106664515556
[Epoch 23, Batch 2800] loss: 0.007616033551693704
[Epoch 23, Batch 2900] loss: 0.013661675309511451
[Epoch 23, Batch 3000] loss: 0.00955330835013001
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9880
Overfitting: 0.0512
[Epoch 24, Batch 100] loss: 0.012485417957504978
[Epoch 24, Batch 200] loss: 0.0035438951086325687
[Epoch 24, Batch 300] loss: 0.006176628278212775
[Epoch 24, Batch 400] loss: 0.006930925069282239
[Epoch 24, Batch 500] loss: 0.0025160052822388933
[Epoch 24, Batch 600] loss: 0.003278044629408896
[Epoch 24, Batch 700] loss: 0.005145558536322596
[Epoch 24, Batch 800] loss: 0.0062645772808645
[Epoch 24, Batch 900] loss: 0.0027003726535795637
[Epoch 24, Batch 1000] loss: 0.0016461884636140667
[Epoch 24, Batch 1100] loss: 0.003723892762990744
[Epoch 24, Batch 1200] loss: 0.002736781407164699
[Epoch 24, Batch 1300] loss: 0.004079433974098094
[Epoch 24, Batch 1400] loss: 0.0043064564954440245
[Epoch 24, Batch 1500] loss: 0.009881378297455114
[Epoch 24, Batch 1600] loss: 0.0014527016938905035
[Epoch 24, Batch 1700] loss: 0.004205701061459593
[Epoch 24, Batch 1800] loss: 0.003503104203557541
[Epoch 24, Batch 1900] loss: 0.0014595101977437253
[Epoch 24, Batch 2000] loss: 0.0024326497145943904
[Epoch 24, Batch 2100] loss: 0.004154747539481747
[Epoch 24, Batch 2200] loss: 0.0017567112445445333
[Epoch 24, Batch 2300] loss: 0.0023282377858572546
[Epoch 24, Batch 2400] loss: 0.0031485373409512363
[Epoch 24, Batch 2500] loss: 0.0035369538913377595
[Epoch 24, Batch 2600] loss: 0.006275762335864101
[Epoch 24, Batch 2700] loss: 0.005182320135459122
[Epoch 24, Batch 2800] loss: 0.003443815152624552
[Epoch 24, Batch 2900] loss: 0.003218598979856608
[Epoch 24, Batch 3000] loss: 0.00587381681525244
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9886
Overfitting: 0.0489
Fold 1 validation loss: 0.0489
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.296698336601257
[Epoch 1, Batch 200] loss: 2.2785217905044557
[Epoch 1, Batch 300] loss: 2.2357951903343203
[Epoch 1, Batch 400] loss: 2.085837050676346
[Epoch 1, Batch 500] loss: 1.431706444621086
[Epoch 1, Batch 600] loss: 0.7351702082157135
[Epoch 1, Batch 700] loss: 0.5361370106041431
[Epoch 1, Batch 800] loss: 0.4068196510523558
[Epoch 1, Batch 900] loss: 0.44211208529770374
[Epoch 1, Batch 1000] loss: 0.35621633343398573
[Epoch 1, Batch 1100] loss: 0.31449177078902724
[Epoch 1, Batch 1200] loss: 0.32509985722601414
[Epoch 1, Batch 1300] loss: 0.3155941466242075
[Epoch 1, Batch 1400] loss: 0.25541038677096367
[Epoch 1, Batch 1500] loss: 0.26045338502153753
[Epoch 1, Batch 1600] loss: 0.21656748469918966
[Epoch 1, Batch 1700] loss: 0.2200080139748752
[Epoch 1, Batch 1800] loss: 0.2244944691285491
[Epoch 1, Batch 1900] loss: 0.19234562700614333
[Epoch 1, Batch 2000] loss: 0.20049551086500286
[Epoch 1, Batch 2100] loss: 0.19787249153479933
[Epoch 1, Batch 2200] loss: 0.16726157123222948
[Epoch 1, Batch 2300] loss: 0.16111035692272707
[Epoch 1, Batch 2400] loss: 0.16950978538719938
[Epoch 1, Batch 2500] loss: 0.1758530461974442
[Epoch 1, Batch 2600] loss: 0.14088480446487664
[Epoch 1, Batch 2700] loss: 0.1423923585889861
[Epoch 1, Batch 2800] loss: 0.09800656789913774
[Epoch 1, Batch 2900] loss: 0.12040186807047576
[Epoch 1, Batch 3000] loss: 0.1557148922048509
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1368
Validation Accuracy: 0.9591
Overfitting: 0.1368
Best model saved at epoch 1 with validation loss: 0.1368
[Epoch 2, Batch 100] loss: 0.12084361352957786
[Epoch 2, Batch 200] loss: 0.12240932076238095
[Epoch 2, Batch 300] loss: 0.12148272691993042
[Epoch 2, Batch 400] loss: 0.11175423544365913
[Epoch 2, Batch 500] loss: 0.12898414049996063
[Epoch 2, Batch 600] loss: 0.11256925939116627
[Epoch 2, Batch 700] loss: 0.10532167957630008
[Epoch 2, Batch 800] loss: 0.1029383979528211
[Epoch 2, Batch 900] loss: 0.14402918660547584
[Epoch 2, Batch 1000] loss: 0.10503620914067141
[Epoch 2, Batch 1100] loss: 0.09315003785071894
[Epoch 2, Batch 1200] loss: 0.12318484149174765
[Epoch 2, Batch 1300] loss: 0.09206520131323487
[Epoch 2, Batch 1400] loss: 0.09038497705943882
[Epoch 2, Batch 1500] loss: 0.12376094100996853
[Epoch 2, Batch 1600] loss: 0.10710242787608877
[Epoch 2, Batch 1700] loss: 0.10054211540846154
[Epoch 2, Batch 1800] loss: 0.095105574761983
[Epoch 2, Batch 1900] loss: 0.09579107489902526
[Epoch 2, Batch 2000] loss: 0.09954806285910309
[Epoch 2, Batch 2100] loss: 0.09322202382958494
[Epoch 2, Batch 2200] loss: 0.10363249190384521
[Epoch 2, Batch 2300] loss: 0.0970436713215895
[Epoch 2, Batch 2400] loss: 0.09050396881182678
[Epoch 2, Batch 2500] loss: 0.06420512241311371
[Epoch 2, Batch 2600] loss: 0.09221535984543153
[Epoch 2, Batch 2700] loss: 0.1155661204061471
[Epoch 2, Batch 2800] loss: 0.09827158245723694
[Epoch 2, Batch 2900] loss: 0.08107402578461916
[Epoch 2, Batch 3000] loss: 0.10091219610767439
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0983
Validation Accuracy: 0.9698
Overfitting: 0.0983
Best model saved at epoch 2 with validation loss: 0.0983
[Epoch 3, Batch 100] loss: 0.08269732856424525
[Epoch 3, Batch 200] loss: 0.07026928603125271
[Epoch 3, Batch 300] loss: 0.07115570520574693
[Epoch 3, Batch 400] loss: 0.07905891624628567
[Epoch 3, Batch 500] loss: 0.07976395556121134
[Epoch 3, Batch 600] loss: 0.08742301468038932
[Epoch 3, Batch 700] loss: 0.07829561046557501
[Epoch 3, Batch 800] loss: 0.07709043823648244
[Epoch 3, Batch 900] loss: 0.08268307527992874
[Epoch 3, Batch 1000] loss: 0.09227829050272703
[Epoch 3, Batch 1100] loss: 0.07291660951566882
[Epoch 3, Batch 1200] loss: 0.062346262972569094
[Epoch 3, Batch 1300] loss: 0.06376476965990151
[Epoch 3, Batch 1400] loss: 0.06320668004220352
[Epoch 3, Batch 1500] loss: 0.05621807481860742
[Epoch 3, Batch 1600] loss: 0.0661062112118816
[Epoch 3, Batch 1700] loss: 0.07357313913293183
[Epoch 3, Batch 1800] loss: 0.095637363193091
[Epoch 3, Batch 1900] loss: 0.05804840983822942
[Epoch 3, Batch 2000] loss: 0.06776565349951852
[Epoch 3, Batch 2100] loss: 0.07009243724518456
[Epoch 3, Batch 2200] loss: 0.05139224334503524
[Epoch 3, Batch 2300] loss: 0.08209276156092528
[Epoch 3, Batch 2400] loss: 0.07043177065672353
[Epoch 3, Batch 2500] loss: 0.07309326453483664
[Epoch 3, Batch 2600] loss: 0.0590772430843208
[Epoch 3, Batch 2700] loss: 0.061667373358795886
[Epoch 3, Batch 2800] loss: 0.06506427684449591
[Epoch 3, Batch 2900] loss: 0.08708151480765082
[Epoch 3, Batch 3000] loss: 0.07289374041662086
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0867
Validation Accuracy: 0.9732
Overfitting: 0.0867
Best model saved at epoch 3 with validation loss: 0.0867
[Epoch 4, Batch 100] loss: 0.05623073604365345
[Epoch 4, Batch 200] loss: 0.05405366252060048
[Epoch 4, Batch 300] loss: 0.06495341034373268
[Epoch 4, Batch 400] loss: 0.05190451966365799
[Epoch 4, Batch 500] loss: 0.06354144527635071
[Epoch 4, Batch 600] loss: 0.05913982557540294
[Epoch 4, Batch 700] loss: 0.05291036884736968
[Epoch 4, Batch 800] loss: 0.05067931437573861
[Epoch 4, Batch 900] loss: 0.06565982791507849
[Epoch 4, Batch 1000] loss: 0.045992275131720814
[Epoch 4, Batch 1100] loss: 0.06237845410243608
[Epoch 4, Batch 1200] loss: 0.06091367077751784
[Epoch 4, Batch 1300] loss: 0.05077108638361096
[Epoch 4, Batch 1400] loss: 0.07103794170659966
[Epoch 4, Batch 1500] loss: 0.05662792236602399
[Epoch 4, Batch 1600] loss: 0.05473518196726218
[Epoch 4, Batch 1700] loss: 0.06300867042125902
[Epoch 4, Batch 1800] loss: 0.059592168708913956
[Epoch 4, Batch 1900] loss: 0.06575069544487633
[Epoch 4, Batch 2000] loss: 0.053164884889265525
[Epoch 4, Batch 2100] loss: 0.044656743182567876
[Epoch 4, Batch 2200] loss: 0.055292421852936965
[Epoch 4, Batch 2300] loss: 0.05270550239016302
[Epoch 4, Batch 2400] loss: 0.05333114502573153
[Epoch 4, Batch 2500] loss: 0.06014293847430963
[Epoch 4, Batch 2600] loss: 0.06358066875487565
[Epoch 4, Batch 2700] loss: 0.04351304560434073
[Epoch 4, Batch 2800] loss: 0.0380719163021422
[Epoch 4, Batch 2900] loss: 0.06224315706291236
[Epoch 4, Batch 3000] loss: 0.06069489988440182
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0705
Validation Accuracy: 0.9768
Overfitting: 0.0705
Best model saved at epoch 4 with validation loss: 0.0705
[Epoch 5, Batch 100] loss: 0.0602004223287804
[Epoch 5, Batch 200] loss: 0.06049722655443475
[Epoch 5, Batch 300] loss: 0.04022468408744317
[Epoch 5, Batch 400] loss: 0.05806541859463323
[Epoch 5, Batch 500] loss: 0.0649815111971111
[Epoch 5, Batch 600] loss: 0.03846290887537179
[Epoch 5, Batch 700] loss: 0.044418476675928104
[Epoch 5, Batch 800] loss: 0.03396647623492754
[Epoch 5, Batch 900] loss: 0.03775246408549719
[Epoch 5, Batch 1000] loss: 0.05137953916972037
[Epoch 5, Batch 1100] loss: 0.06201268470991636
[Epoch 5, Batch 1200] loss: 0.03726676709251478
[Epoch 5, Batch 1300] loss: 0.057399883122416215
[Epoch 5, Batch 1400] loss: 0.04557450496067759
[Epoch 5, Batch 1500] loss: 0.049792680225509686
[Epoch 5, Batch 1600] loss: 0.05614171863300726
[Epoch 5, Batch 1700] loss: 0.050350278816185895
[Epoch 5, Batch 1800] loss: 0.03928703813580796
[Epoch 5, Batch 1900] loss: 0.04309896561375354
[Epoch 5, Batch 2000] loss: 0.06455030959652504
[Epoch 5, Batch 2100] loss: 0.03953043000859907
[Epoch 5, Batch 2200] loss: 0.043167441644473004
[Epoch 5, Batch 2300] loss: 0.03500907281864784
[Epoch 5, Batch 2400] loss: 0.05997754528594669
[Epoch 5, Batch 2500] loss: 0.04574455014517298
[Epoch 5, Batch 2600] loss: 0.03250433504814282
[Epoch 5, Batch 2700] loss: 0.04949501100229099
[Epoch 5, Batch 2800] loss: 0.04382222670756164
[Epoch 5, Batch 2900] loss: 0.041885681043495424
[Epoch 5, Batch 3000] loss: 0.05269535939965863
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0690
Validation Accuracy: 0.9783
Overfitting: 0.0690
Best model saved at epoch 5 with validation loss: 0.0690
[Epoch 6, Batch 100] loss: 0.04372378041240154
[Epoch 6, Batch 200] loss: 0.0322320987371495
[Epoch 6, Batch 300] loss: 0.051024789336952384
[Epoch 6, Batch 400] loss: 0.03418917857692577
[Epoch 6, Batch 500] loss: 0.0392518902674783
[Epoch 6, Batch 600] loss: 0.04185274964722339
[Epoch 6, Batch 700] loss: 0.046986159345833584
[Epoch 6, Batch 800] loss: 0.043949015683610926
[Epoch 6, Batch 900] loss: 0.03571119271102361
[Epoch 6, Batch 1000] loss: 0.04726619733075495
[Epoch 6, Batch 1100] loss: 0.04455674820317654
[Epoch 6, Batch 1200] loss: 0.026818107090366538
[Epoch 6, Batch 1300] loss: 0.0490356174983026
[Epoch 6, Batch 1400] loss: 0.03863179874126217
[Epoch 6, Batch 1500] loss: 0.03686329369316809
[Epoch 6, Batch 1600] loss: 0.04274970517857582
[Epoch 6, Batch 1700] loss: 0.03317229894266347
[Epoch 6, Batch 1800] loss: 0.05550213692971738
[Epoch 6, Batch 1900] loss: 0.03528464839939261
[Epoch 6, Batch 2000] loss: 0.04534635215182789
[Epoch 6, Batch 2100] loss: 0.027831276040378727
[Epoch 6, Batch 2200] loss: 0.031107554529444314
[Epoch 6, Batch 2300] loss: 0.048001053557527484
[Epoch 6, Batch 2400] loss: 0.04387908418633742
[Epoch 6, Batch 2500] loss: 0.033379513456020506
[Epoch 6, Batch 2600] loss: 0.045847324737696905
[Epoch 6, Batch 2700] loss: 0.03743078652070835
[Epoch 6, Batch 2800] loss: 0.03455133399365877
[Epoch 6, Batch 2900] loss: 0.038777045573006035
[Epoch 6, Batch 3000] loss: 0.03428781436727149
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9842
Overfitting: 0.0550
Best model saved at epoch 6 with validation loss: 0.0550
[Epoch 7, Batch 100] loss: 0.03789150404656539
[Epoch 7, Batch 200] loss: 0.03423616535787005
[Epoch 7, Batch 300] loss: 0.03440090961928945
[Epoch 7, Batch 400] loss: 0.030324417580704904
[Epoch 7, Batch 500] loss: 0.03296651889657369
[Epoch 7, Batch 600] loss: 0.04347307622723747
[Epoch 7, Batch 700] loss: 0.04197659792785999
[Epoch 7, Batch 800] loss: 0.035234444689413065
[Epoch 7, Batch 900] loss: 0.029714297631871885
[Epoch 7, Batch 1000] loss: 0.030151493753219256
[Epoch 7, Batch 1100] loss: 0.03046085777154076
[Epoch 7, Batch 1200] loss: 0.040516986777620334
[Epoch 7, Batch 1300] loss: 0.04664896940754261
[Epoch 7, Batch 1400] loss: 0.03593288189687883
[Epoch 7, Batch 1500] loss: 0.04094619201889145
[Epoch 7, Batch 1600] loss: 0.030196545326434718
[Epoch 7, Batch 1700] loss: 0.026846248979891244
[Epoch 7, Batch 1800] loss: 0.03566580112870724
[Epoch 7, Batch 1900] loss: 0.03956700649199774
[Epoch 7, Batch 2000] loss: 0.027683181889442493
[Epoch 7, Batch 2100] loss: 0.04079794140896411
[Epoch 7, Batch 2200] loss: 0.041713898431771666
[Epoch 7, Batch 2300] loss: 0.03871502918380429
[Epoch 7, Batch 2400] loss: 0.023347117373341462
[Epoch 7, Batch 2500] loss: 0.03219695128747844
[Epoch 7, Batch 2600] loss: 0.05137294515719987
[Epoch 7, Batch 2700] loss: 0.03914075010892702
[Epoch 7, Batch 2800] loss: 0.039867584964740674
[Epoch 7, Batch 2900] loss: 0.035759759836801096
[Epoch 7, Batch 3000] loss: 0.03589953494607471
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0558
Validation Accuracy: 0.9837
Overfitting: 0.0558
[Epoch 8, Batch 100] loss: 0.027767433513654394
[Epoch 8, Batch 200] loss: 0.023453612307057482
[Epoch 8, Batch 300] loss: 0.021091422261088157
[Epoch 8, Batch 400] loss: 0.03742143167750328
[Epoch 8, Batch 500] loss: 0.040083892292823296
[Epoch 8, Batch 600] loss: 0.01567951426077343
[Epoch 8, Batch 700] loss: 0.028496716806694168
[Epoch 8, Batch 800] loss: 0.031282634956078255
[Epoch 8, Batch 900] loss: 0.03955406186891196
[Epoch 8, Batch 1000] loss: 0.02688610306038754
[Epoch 8, Batch 1100] loss: 0.026004368415597126
[Epoch 8, Batch 1200] loss: 0.024293278344484862
[Epoch 8, Batch 1300] loss: 0.030509610608642105
[Epoch 8, Batch 1400] loss: 0.027058561357753207
[Epoch 8, Batch 1500] loss: 0.030743260508606908
[Epoch 8, Batch 1600] loss: 0.043053968583262756
[Epoch 8, Batch 1700] loss: 0.03584724824759178
[Epoch 8, Batch 1800] loss: 0.03665418287040666
[Epoch 8, Batch 1900] loss: 0.02155163569113938
[Epoch 8, Batch 2000] loss: 0.03701583826354181
[Epoch 8, Batch 2100] loss: 0.0190284745865938
[Epoch 8, Batch 2200] loss: 0.0408884887547174
[Epoch 8, Batch 2300] loss: 0.02821646492655418
[Epoch 8, Batch 2400] loss: 0.02805394691818947
[Epoch 8, Batch 2500] loss: 0.02665834265179001
[Epoch 8, Batch 2600] loss: 0.02218336619102047
[Epoch 8, Batch 2700] loss: 0.02713311847706791
[Epoch 8, Batch 2800] loss: 0.026528112662927015
[Epoch 8, Batch 2900] loss: 0.030578359190731135
[Epoch 8, Batch 3000] loss: 0.05156461406419112
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0553
Validation Accuracy: 0.9838
Overfitting: 0.0553
[Epoch 9, Batch 100] loss: 0.035328198187053204
[Epoch 9, Batch 200] loss: 0.021214370075285843
[Epoch 9, Batch 300] loss: 0.019649287281863506
[Epoch 9, Batch 400] loss: 0.030905810531294264
[Epoch 9, Batch 500] loss: 0.020631952424664632
[Epoch 9, Batch 600] loss: 0.025391879452872673
[Epoch 9, Batch 700] loss: 0.030985942973056808
[Epoch 9, Batch 800] loss: 0.020827425576062524
[Epoch 9, Batch 900] loss: 0.037608093365997776
[Epoch 9, Batch 1000] loss: 0.02501474669417803
[Epoch 9, Batch 1100] loss: 0.022639611643608077
[Epoch 9, Batch 1200] loss: 0.02241360714251641
[Epoch 9, Batch 1300] loss: 0.03379154893103987
[Epoch 9, Batch 1400] loss: 0.025231065407606366
[Epoch 9, Batch 1500] loss: 0.027059648639151418
[Epoch 9, Batch 1600] loss: 0.024790480575611583
[Epoch 9, Batch 1700] loss: 0.0232443533409878
[Epoch 9, Batch 1800] loss: 0.02712126023514429
[Epoch 9, Batch 1900] loss: 0.01911010893087223
[Epoch 9, Batch 2000] loss: 0.03480049409743515
[Epoch 9, Batch 2100] loss: 0.03243321238784119
[Epoch 9, Batch 2200] loss: 0.03546305398489494
[Epoch 9, Batch 2300] loss: 0.02881007225245412
[Epoch 9, Batch 2400] loss: 0.04309709963563364
[Epoch 9, Batch 2500] loss: 0.025901044991769595
[Epoch 9, Batch 2600] loss: 0.04563564961936208
[Epoch 9, Batch 2700] loss: 0.021972673445125112
[Epoch 9, Batch 2800] loss: 0.017885632920515492
[Epoch 9, Batch 2900] loss: 0.024494914074166443
[Epoch 9, Batch 3000] loss: 0.029742995833366877
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9859
Overfitting: 0.0502
Best model saved at epoch 9 with validation loss: 0.0502
[Epoch 10, Batch 100] loss: 0.018276791706121003
[Epoch 10, Batch 200] loss: 0.020137093231096515
[Epoch 10, Batch 300] loss: 0.02884794832159969
[Epoch 10, Batch 400] loss: 0.026000421775970606
[Epoch 10, Batch 500] loss: 0.015012770389876095
[Epoch 10, Batch 600] loss: 0.018288924720563954
[Epoch 10, Batch 700] loss: 0.016307796367837
[Epoch 10, Batch 800] loss: 0.030404767360669212
[Epoch 10, Batch 900] loss: 0.02052407645365747
[Epoch 10, Batch 1000] loss: 0.030211438582373375
[Epoch 10, Batch 1100] loss: 0.021009024352679262
[Epoch 10, Batch 1200] loss: 0.022566194153987452
[Epoch 10, Batch 1300] loss: 0.025688333292127937
[Epoch 10, Batch 1400] loss: 0.029801655629780724
[Epoch 10, Batch 1500] loss: 0.026867727769786142
[Epoch 10, Batch 1600] loss: 0.018075368487552625
[Epoch 10, Batch 1700] loss: 0.031722090503208164
[Epoch 10, Batch 1800] loss: 0.02052384783853995
[Epoch 10, Batch 1900] loss: 0.027895498891593887
[Epoch 10, Batch 2000] loss: 0.008491962398329634
[Epoch 10, Batch 2100] loss: 0.031926503812137526
[Epoch 10, Batch 2200] loss: 0.025780948804676882
[Epoch 10, Batch 2300] loss: 0.023281467281994993
[Epoch 10, Batch 2400] loss: 0.03104319439356914
[Epoch 10, Batch 2500] loss: 0.017805142479992354
[Epoch 10, Batch 2600] loss: 0.020633136915421346
[Epoch 10, Batch 2700] loss: 0.015612852136328001
[Epoch 10, Batch 2800] loss: 0.026528475958839406
[Epoch 10, Batch 2900] loss: 0.02526319347005483
[Epoch 10, Batch 3000] loss: 0.02274379238850088
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9857
Overfitting: 0.0491
Best model saved at epoch 10 with validation loss: 0.0491
[Epoch 11, Batch 100] loss: 0.0281364939550258
[Epoch 11, Batch 200] loss: 0.021621736392262392
[Epoch 11, Batch 300] loss: 0.020040967132081276
[Epoch 11, Batch 400] loss: 0.018097845080401385
[Epoch 11, Batch 500] loss: 0.014411816853607888
[Epoch 11, Batch 600] loss: 0.021266420646461483
[Epoch 11, Batch 700] loss: 0.018774360161314688
[Epoch 11, Batch 800] loss: 0.02419361654741806
[Epoch 11, Batch 900] loss: 0.022628086352742684
[Epoch 11, Batch 1000] loss: 0.02673055140881843
[Epoch 11, Batch 1100] loss: 0.020450054592147354
[Epoch 11, Batch 1200] loss: 0.014364535278637049
[Epoch 11, Batch 1300] loss: 0.016785201065540604
[Epoch 11, Batch 1400] loss: 0.01597694031712308
[Epoch 11, Batch 1500] loss: 0.019976604764015065
[Epoch 11, Batch 1600] loss: 0.014161818655193201
[Epoch 11, Batch 1700] loss: 0.020678660722296627
[Epoch 11, Batch 1800] loss: 0.026016774228301075
[Epoch 11, Batch 1900] loss: 0.026637886428679848
[Epoch 11, Batch 2000] loss: 0.02498660686183939
[Epoch 11, Batch 2100] loss: 0.02102054140115797
[Epoch 11, Batch 2200] loss: 0.023593242590313823
[Epoch 11, Batch 2300] loss: 0.017279848157413652
[Epoch 11, Batch 2400] loss: 0.043335451931670835
[Epoch 11, Batch 2500] loss: 0.0343991815346817
[Epoch 11, Batch 2600] loss: 0.03662023721059086
[Epoch 11, Batch 2700] loss: 0.01554997118881147
[Epoch 11, Batch 2800] loss: 0.0164730243282429
[Epoch 11, Batch 2900] loss: 0.025471360021983854
[Epoch 11, Batch 3000] loss: 0.01347149950266612
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9850
Overfitting: 0.0534
[Epoch 12, Batch 100] loss: 0.017300386778406392
[Epoch 12, Batch 200] loss: 0.015219386867247522
[Epoch 12, Batch 300] loss: 0.017711714194665548
[Epoch 12, Batch 400] loss: 0.02215370644318682
[Epoch 12, Batch 500] loss: 0.011700800179432917
[Epoch 12, Batch 600] loss: 0.014137310703608819
[Epoch 12, Batch 700] loss: 0.03462652631873425
[Epoch 12, Batch 800] loss: 0.03332392945376341
[Epoch 12, Batch 900] loss: 0.02420274019695171
[Epoch 12, Batch 1000] loss: 0.010394789447473159
[Epoch 12, Batch 1100] loss: 0.027875062932962463
[Epoch 12, Batch 1200] loss: 0.02383998314384371
[Epoch 12, Batch 1300] loss: 0.022621321740662097
[Epoch 12, Batch 1400] loss: 0.01800649817301746
[Epoch 12, Batch 1500] loss: 0.02413071231345384
[Epoch 12, Batch 1600] loss: 0.018795859916608607
[Epoch 12, Batch 1700] loss: 0.011660379136556003
[Epoch 12, Batch 1800] loss: 0.021648238226125615
[Epoch 12, Batch 1900] loss: 0.00993559286574964
[Epoch 12, Batch 2000] loss: 0.020950676493830544
[Epoch 12, Batch 2100] loss: 0.017046482580735756
[Epoch 12, Batch 2200] loss: 0.016301750458878814
[Epoch 12, Batch 2300] loss: 0.01157617203611153
[Epoch 12, Batch 2400] loss: 0.03558336889960628
[Epoch 12, Batch 2500] loss: 0.016594158487714596
[Epoch 12, Batch 2600] loss: 0.016034351429707386
[Epoch 12, Batch 2700] loss: 0.023511413323540183
[Epoch 12, Batch 2800] loss: 0.007340889764782333
[Epoch 12, Batch 2900] loss: 0.014822943336075695
[Epoch 12, Batch 3000] loss: 0.024644267900694104
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9856
Overfitting: 0.0544
[Epoch 13, Batch 100] loss: 0.007251051532193742
[Epoch 13, Batch 200] loss: 0.012734943122686672
[Epoch 13, Batch 300] loss: 0.017644388585085834
[Epoch 13, Batch 400] loss: 0.016765001375788416
[Epoch 13, Batch 500] loss: 0.014581643053898006
[Epoch 13, Batch 600] loss: 0.02282869247623239
[Epoch 13, Batch 700] loss: 0.012771518515437492
[Epoch 13, Batch 800] loss: 0.015756287445838096
[Epoch 13, Batch 900] loss: 0.02220369055606625
[Epoch 13, Batch 1000] loss: 0.013174819511705209
[Epoch 13, Batch 1100] loss: 0.010774264807359941
[Epoch 13, Batch 1200] loss: 0.019658388192751772
[Epoch 13, Batch 1300] loss: 0.017274551990667533
[Epoch 13, Batch 1400] loss: 0.017565213612906517
[Epoch 13, Batch 1500] loss: 0.022325304605910787
[Epoch 13, Batch 1600] loss: 0.009042534460495516
[Epoch 13, Batch 1700] loss: 0.016608439227838973
[Epoch 13, Batch 1800] loss: 0.016319523716351796
[Epoch 13, Batch 1900] loss: 0.018458332250229432
[Epoch 13, Batch 2000] loss: 0.031515265670491316
[Epoch 13, Batch 2100] loss: 0.011595428729960985
[Epoch 13, Batch 2200] loss: 0.008332366574250046
[Epoch 13, Batch 2300] loss: 0.017292309389886212
[Epoch 13, Batch 2400] loss: 0.012683431158384337
[Epoch 13, Batch 2500] loss: 0.0275899231898984
[Epoch 13, Batch 2600] loss: 0.02179255340464806
[Epoch 13, Batch 2700] loss: 0.019734883469773194
[Epoch 13, Batch 2800] loss: 0.029283926933876502
[Epoch 13, Batch 2900] loss: 0.020332202891968337
[Epoch 13, Batch 3000] loss: 0.014744256466365187
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9851
Overfitting: 0.0560
[Epoch 14, Batch 100] loss: 0.0107021607347815
[Epoch 14, Batch 200] loss: 0.012094246667056724
[Epoch 14, Batch 300] loss: 0.016671432875864412
[Epoch 14, Batch 400] loss: 0.013521796833429108
[Epoch 14, Batch 500] loss: 0.012461741769602668
[Epoch 14, Batch 600] loss: 0.011898362049178103
[Epoch 14, Batch 700] loss: 0.016530661727429105
[Epoch 14, Batch 800] loss: 0.019224474367056245
[Epoch 14, Batch 900] loss: 0.006229989194807785
[Epoch 14, Batch 1000] loss: 0.01739681924501383
[Epoch 14, Batch 1100] loss: 0.015537572289276795
[Epoch 14, Batch 1200] loss: 0.016497357591160836
[Epoch 14, Batch 1300] loss: 0.008737746806400538
[Epoch 14, Batch 1400] loss: 0.015990543325933686
[Epoch 14, Batch 1500] loss: 0.013454178532256264
[Epoch 14, Batch 1600] loss: 0.014004601842989359
[Epoch 14, Batch 1700] loss: 0.021626190551669425
[Epoch 14, Batch 1800] loss: 0.01700362704080362
[Epoch 14, Batch 1900] loss: 0.010555847653140518
[Epoch 14, Batch 2000] loss: 0.013411433197034058
[Epoch 14, Batch 2100] loss: 0.01638017263844631
[Epoch 14, Batch 2200] loss: 0.020900782629469178
[Epoch 14, Batch 2300] loss: 0.027278802965865906
[Epoch 14, Batch 2400] loss: 0.015342308552462783
[Epoch 14, Batch 2500] loss: 0.013041574617423066
[Epoch 14, Batch 2600] loss: 0.01991493382676708
[Epoch 14, Batch 2700] loss: 0.022775618574805777
[Epoch 14, Batch 2800] loss: 0.012870938386859052
[Epoch 14, Batch 2900] loss: 0.022176505422503396
[Epoch 14, Batch 3000] loss: 0.01011443730355495
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9849
Overfitting: 0.0535
[Epoch 15, Batch 100] loss: 0.005997374784237763
[Epoch 15, Batch 200] loss: 0.007982814878769205
[Epoch 15, Batch 300] loss: 0.009250634113877823
[Epoch 15, Batch 400] loss: 0.011942760016054307
[Epoch 15, Batch 500] loss: 0.013854809868698794
[Epoch 15, Batch 600] loss: 0.013909064713025145
[Epoch 15, Batch 700] loss: 0.007475534908662667
[Epoch 15, Batch 800] loss: 0.01280776038505337
[Epoch 15, Batch 900] loss: 0.008491819061089246
[Epoch 15, Batch 1000] loss: 0.012202327770892226
[Epoch 15, Batch 1100] loss: 0.019513409807195785
[Epoch 15, Batch 1200] loss: 0.020162622083616952
[Epoch 15, Batch 1300] loss: 0.015577499940513917
[Epoch 15, Batch 1400] loss: 0.015131661301620625
[Epoch 15, Batch 1500] loss: 0.009079451651775799
[Epoch 15, Batch 1600] loss: 0.017035048353618548
[Epoch 15, Batch 1700] loss: 0.012506712617614539
[Epoch 15, Batch 1800] loss: 0.011100573744588473
[Epoch 15, Batch 1900] loss: 0.012167972115066731
[Epoch 15, Batch 2000] loss: 0.020845529076486857
[Epoch 15, Batch 2100] loss: 0.012113132540907828
[Epoch 15, Batch 2200] loss: 0.017455188958961115
[Epoch 15, Batch 2300] loss: 0.025932383752879106
[Epoch 15, Batch 2400] loss: 0.029239223136301007
[Epoch 15, Batch 2500] loss: 0.00824359821818689
[Epoch 15, Batch 2600] loss: 0.011592804202009574
[Epoch 15, Batch 2700] loss: 0.020308733544334247
[Epoch 15, Batch 2800] loss: 0.012047632962421631
[Epoch 15, Batch 2900] loss: 0.021819531692199235
[Epoch 15, Batch 3000] loss: 0.02475658101890076
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9843
Overfitting: 0.0499
[Epoch 16, Batch 100] loss: 0.020725566197506852
[Epoch 16, Batch 200] loss: 0.006227485212857573
[Epoch 16, Batch 300] loss: 0.009542290118297388
[Epoch 16, Batch 400] loss: 0.00878991011319158
[Epoch 16, Batch 500] loss: 0.011457449116815042
[Epoch 16, Batch 600] loss: 0.010590928737215108
[Epoch 16, Batch 700] loss: 0.015453549290796217
[Epoch 16, Batch 800] loss: 0.012075326345411667
[Epoch 16, Batch 900] loss: 0.012781773163278559
[Epoch 16, Batch 1000] loss: 0.009557862004132858
[Epoch 16, Batch 1100] loss: 0.006925920950634463
[Epoch 16, Batch 1200] loss: 0.00933071690318684
[Epoch 16, Batch 1300] loss: 0.014882435171875841
[Epoch 16, Batch 1400] loss: 0.01826906311636776
[Epoch 16, Batch 1500] loss: 0.013587746577941288
[Epoch 16, Batch 1600] loss: 0.015744261458667096
[Epoch 16, Batch 1700] loss: 0.006258667184001751
[Epoch 16, Batch 1800] loss: 0.021226081214134638
[Epoch 16, Batch 1900] loss: 0.019272983121016978
[Epoch 16, Batch 2000] loss: 0.006728289593988848
[Epoch 16, Batch 2100] loss: 0.0246271988548051
[Epoch 16, Batch 2200] loss: 0.010698411296680206
[Epoch 16, Batch 2300] loss: 0.006204127360078928
[Epoch 16, Batch 2400] loss: 0.015513816206826049
[Epoch 16, Batch 2500] loss: 0.012127710407157792
[Epoch 16, Batch 2600] loss: 0.02039902169070956
[Epoch 16, Batch 2700] loss: 0.010438430549716032
[Epoch 16, Batch 2800] loss: 0.009608240766542622
[Epoch 16, Batch 2900] loss: 0.0212527602877708
[Epoch 16, Batch 3000] loss: 0.01897767970619043
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9862
Overfitting: 0.0494
[Epoch 17, Batch 100] loss: 0.006879382032020658
[Epoch 17, Batch 200] loss: 0.007459962410098342
[Epoch 17, Batch 300] loss: 0.006222694213743125
[Epoch 17, Batch 400] loss: 0.013134253368925784
[Epoch 17, Batch 500] loss: 0.004615335294074612
[Epoch 17, Batch 600] loss: 0.014404689002517443
[Epoch 17, Batch 700] loss: 0.009105177976767891
[Epoch 17, Batch 800] loss: 0.007915065243146273
[Epoch 17, Batch 900] loss: 0.011482473835826568
[Epoch 17, Batch 1000] loss: 0.010767825976104177
[Epoch 17, Batch 1100] loss: 0.004803318537938139
[Epoch 17, Batch 1200] loss: 0.008768311127687412
[Epoch 17, Batch 1300] loss: 0.005334225937365318
[Epoch 17, Batch 1400] loss: 0.021344624726089022
[Epoch 17, Batch 1500] loss: 0.008801619039495563
[Epoch 17, Batch 1600] loss: 0.0093663619144354
[Epoch 17, Batch 1700] loss: 0.013926308641712239
[Epoch 17, Batch 1800] loss: 0.006310904758527159
[Epoch 17, Batch 1900] loss: 0.015382305653172352
[Epoch 17, Batch 2000] loss: 0.012521168714285977
[Epoch 17, Batch 2100] loss: 0.019425763653698594
[Epoch 17, Batch 2200] loss: 0.0217318798938652
[Epoch 17, Batch 2300] loss: 0.00753213291519387
[Epoch 17, Batch 2400] loss: 0.011920047152361803
[Epoch 17, Batch 2500] loss: 0.015816715392672903
[Epoch 17, Batch 2600] loss: 0.007742137394780002
[Epoch 17, Batch 2700] loss: 0.00938211103105914
[Epoch 17, Batch 2800] loss: 0.008135097513786604
[Epoch 17, Batch 2900] loss: 0.018309217183395957
[Epoch 17, Batch 3000] loss: 0.011116702817885198
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9861
Overfitting: 0.0543
[Epoch 18, Batch 100] loss: 0.0105820926215614
[Epoch 18, Batch 200] loss: 0.007397013350978341
[Epoch 18, Batch 300] loss: 0.01386851960262902
[Epoch 18, Batch 400] loss: 0.008824273579184591
[Epoch 18, Batch 500] loss: 0.012584510908300216
[Epoch 18, Batch 600] loss: 0.008057679009680215
[Epoch 18, Batch 700] loss: 0.003980492201199013
[Epoch 18, Batch 800] loss: 0.009523644517601041
[Epoch 18, Batch 900] loss: 0.006347326515851819
[Epoch 18, Batch 1000] loss: 0.005934357143831903
[Epoch 18, Batch 1100] loss: 0.0063667579264460985
[Epoch 18, Batch 1200] loss: 0.009128641829056506
[Epoch 18, Batch 1300] loss: 0.010153729881160416
[Epoch 18, Batch 1400] loss: 0.005145649895966926
[Epoch 18, Batch 1500] loss: 0.009644227580379265
[Epoch 18, Batch 1600] loss: 0.009480546835052337
[Epoch 18, Batch 1700] loss: 0.010830097191892492
[Epoch 18, Batch 1800] loss: 0.0070488185031962304
[Epoch 18, Batch 1900] loss: 0.01308209765707943
[Epoch 18, Batch 2000] loss: 0.015155395766400943
[Epoch 18, Batch 2100] loss: 0.01074937425232747
[Epoch 18, Batch 2200] loss: 0.011658998740074367
[Epoch 18, Batch 2300] loss: 0.010670507105273827
[Epoch 18, Batch 2400] loss: 0.014286196856101014
[Epoch 18, Batch 2500] loss: 0.01653731585875903
[Epoch 18, Batch 2600] loss: 0.007291891342774761
[Epoch 18, Batch 2700] loss: 0.017680866312441593
[Epoch 18, Batch 2800] loss: 0.005661369328496448
[Epoch 18, Batch 2900] loss: 0.008812062491624601
[Epoch 18, Batch 3000] loss: 0.004813734471113094
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9864
Overfitting: 0.0522
[Epoch 19, Batch 100] loss: 0.011462219271907088
[Epoch 19, Batch 200] loss: 0.011443413635963679
[Epoch 19, Batch 300] loss: 0.006190069665224201
[Epoch 19, Batch 400] loss: 0.004915077360938085
[Epoch 19, Batch 500] loss: 0.007269221064934755
[Epoch 19, Batch 600] loss: 0.010130393944173192
[Epoch 19, Batch 700] loss: 0.005411391622019437
[Epoch 19, Batch 800] loss: 0.003081478052265538
[Epoch 19, Batch 900] loss: 0.005826036768255562
[Epoch 19, Batch 1000] loss: 0.003800909700628381
[Epoch 19, Batch 1100] loss: 0.008057787961465692
[Epoch 19, Batch 1200] loss: 0.013881890362793001
[Epoch 19, Batch 1300] loss: 0.007305250629360671
[Epoch 19, Batch 1400] loss: 0.005735833912688122
[Epoch 19, Batch 1500] loss: 0.008642209916499723
[Epoch 19, Batch 1600] loss: 0.00695382443030212
[Epoch 19, Batch 1700] loss: 0.012014873434109176
[Epoch 19, Batch 1800] loss: 0.015427990404550656
[Epoch 19, Batch 1900] loss: 0.017209239104977313
[Epoch 19, Batch 2000] loss: 0.011937262230574106
[Epoch 19, Batch 2100] loss: 0.009568458144253783
[Epoch 19, Batch 2200] loss: 0.005719231181390114
[Epoch 19, Batch 2300] loss: 0.008604268214444346
[Epoch 19, Batch 2400] loss: 0.011198233344914002
[Epoch 19, Batch 2500] loss: 0.00722896007436475
[Epoch 19, Batch 2600] loss: 0.0049565195864522595
[Epoch 19, Batch 2700] loss: 0.013227432715896157
[Epoch 19, Batch 2800] loss: 0.006855605879154609
[Epoch 19, Batch 2900] loss: 0.0062403609499688175
[Epoch 19, Batch 3000] loss: 0.008087982643892246
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9876
Overfitting: 0.0489
Best model saved at epoch 19 with validation loss: 0.0489
[Epoch 20, Batch 100] loss: 0.008043234279716672
[Epoch 20, Batch 200] loss: 0.005423504020120618
[Epoch 20, Batch 300] loss: 0.011466314089958587
[Epoch 20, Batch 400] loss: 0.0066588261053266255
[Epoch 20, Batch 500] loss: 0.004096403917717168
[Epoch 20, Batch 600] loss: 0.0018539572312658947
[Epoch 20, Batch 700] loss: 0.005329138988511204
[Epoch 20, Batch 800] loss: 0.008804821034993892
[Epoch 20, Batch 900] loss: 0.008045256221153067
[Epoch 20, Batch 1000] loss: 0.008520490652858825
[Epoch 20, Batch 1100] loss: 0.005669412106169602
[Epoch 20, Batch 1200] loss: 0.01342619248504434
[Epoch 20, Batch 1300] loss: 0.006076635807844468
[Epoch 20, Batch 1400] loss: 0.006981512184650569
[Epoch 20, Batch 1500] loss: 0.012089526093459426
[Epoch 20, Batch 1600] loss: 0.008547113904151048
[Epoch 20, Batch 1700] loss: 0.006957910706835264
[Epoch 20, Batch 1800] loss: 0.010096656015368808
[Epoch 20, Batch 1900] loss: 0.004610292170611956
[Epoch 20, Batch 2000] loss: 0.005355188511400683
[Epoch 20, Batch 2100] loss: 0.0047596451809658906
[Epoch 20, Batch 2200] loss: 0.0052535810180791035
[Epoch 20, Batch 2300] loss: 0.017883014142381626
[Epoch 20, Batch 2400] loss: 0.00999052001284781
[Epoch 20, Batch 2500] loss: 0.007927652839307485
[Epoch 20, Batch 2600] loss: 0.005141082801887933
[Epoch 20, Batch 2700] loss: 0.007401457431255949
[Epoch 20, Batch 2800] loss: 0.012741943046637515
[Epoch 20, Batch 2900] loss: 0.004930112674612701
[Epoch 20, Batch 3000] loss: 0.009770775722772669
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0562
Validation Accuracy: 0.9866
Overfitting: 0.0562
[Epoch 21, Batch 100] loss: 0.011932738955226795
[Epoch 21, Batch 200] loss: 0.007034822481296032
[Epoch 21, Batch 300] loss: 0.008970770255014032
[Epoch 21, Batch 400] loss: 0.00438115321465375
[Epoch 21, Batch 500] loss: 0.0029583589999037942
[Epoch 21, Batch 600] loss: 0.004617507137151051
[Epoch 21, Batch 700] loss: 0.00700316287985288
[Epoch 21, Batch 800] loss: 0.0024836729512844615
[Epoch 21, Batch 900] loss: 0.003378251681998563
[Epoch 21, Batch 1000] loss: 0.004548248329892885
[Epoch 21, Batch 1100] loss: 0.004303783862860655
[Epoch 21, Batch 1200] loss: 0.0034797711864575833
[Epoch 21, Batch 1300] loss: 0.0034633011504593015
[Epoch 21, Batch 1400] loss: 0.0021746751672424127
[Epoch 21, Batch 1500] loss: 0.009362888541595567
[Epoch 21, Batch 1600] loss: 0.009197950723629446
[Epoch 21, Batch 1700] loss: 0.008910999805166284
[Epoch 21, Batch 1800] loss: 0.016692795331650814
[Epoch 21, Batch 1900] loss: 0.005189815480177913
[Epoch 21, Batch 2000] loss: 0.00816382542362703
[Epoch 21, Batch 2100] loss: 0.00549185588242608
[Epoch 21, Batch 2200] loss: 0.004377354965081395
[Epoch 21, Batch 2300] loss: 0.00678466430225626
[Epoch 21, Batch 2400] loss: 0.01040830508410636
[Epoch 21, Batch 2500] loss: 0.009876952847575922
[Epoch 21, Batch 2600] loss: 0.009252650869220815
[Epoch 21, Batch 2700] loss: 0.0035247880029737645
[Epoch 21, Batch 2800] loss: 0.0045582109398174
[Epoch 21, Batch 2900] loss: 0.00899332513287277
[Epoch 21, Batch 3000] loss: 0.00625194964538764
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9877
Overfitting: 0.0535
[Epoch 22, Batch 100] loss: 0.007179445157516398
[Epoch 22, Batch 200] loss: 0.0027630591456255615
[Epoch 22, Batch 300] loss: 0.0010892320376092357
[Epoch 22, Batch 400] loss: 0.0049356186800901015
[Epoch 22, Batch 500] loss: 0.0035200024489154204
[Epoch 22, Batch 600] loss: 0.003627924836399643
[Epoch 22, Batch 700] loss: 0.004238361538555182
[Epoch 22, Batch 800] loss: 0.003002421583993282
[Epoch 22, Batch 900] loss: 0.011822331079795276
[Epoch 22, Batch 1000] loss: 0.007791493784951626
[Epoch 22, Batch 1100] loss: 0.008487204127955011
[Epoch 22, Batch 1200] loss: 0.009743402597307523
[Epoch 22, Batch 1300] loss: 0.008045971354989093
[Epoch 22, Batch 1400] loss: 0.004304601123661769
[Epoch 22, Batch 1500] loss: 0.013510908779853708
[Epoch 22, Batch 1600] loss: 0.0057166234150309945
[Epoch 22, Batch 1700] loss: 0.01733673412501503
[Epoch 22, Batch 1800] loss: 0.02066008456562031
[Epoch 22, Batch 1900] loss: 0.011443321448889493
[Epoch 22, Batch 2000] loss: 0.008305487206920361
[Epoch 22, Batch 2100] loss: 0.003913770828457928
[Epoch 22, Batch 2200] loss: 0.0021963847986296516
[Epoch 22, Batch 2300] loss: 0.004047418467447415
[Epoch 22, Batch 2400] loss: 0.0066332447374838925
[Epoch 22, Batch 2500] loss: 0.011606252761598625
[Epoch 22, Batch 2600] loss: 0.004570683251620267
[Epoch 22, Batch 2700] loss: 0.01177906494756712
[Epoch 22, Batch 2800] loss: 0.007351532818956912
[Epoch 22, Batch 2900] loss: 0.006647640985038379
[Epoch 22, Batch 3000] loss: 0.011061646902162466
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9871
Overfitting: 0.0526
[Epoch 23, Batch 100] loss: 0.012970281104528567
[Epoch 23, Batch 200] loss: 0.008339851655297253
[Epoch 23, Batch 300] loss: 0.0038470718898321364
[Epoch 23, Batch 400] loss: 0.001966995377172225
[Epoch 23, Batch 500] loss: 0.004706312324906321
[Epoch 23, Batch 600] loss: 0.005859930415476242
[Epoch 23, Batch 700] loss: 0.003068832189208024
[Epoch 23, Batch 800] loss: 0.0025983449491695865
[Epoch 23, Batch 900] loss: 0.005906794151845815
[Epoch 23, Batch 1000] loss: 0.002512440532639744
[Epoch 23, Batch 1100] loss: 0.005209645687108946
[Epoch 23, Batch 1200] loss: 0.005845093575615579
[Epoch 23, Batch 1300] loss: 0.0035800123937701754
[Epoch 23, Batch 1400] loss: 0.005138995466214737
[Epoch 23, Batch 1500] loss: 0.005055797775532937
[Epoch 23, Batch 1600] loss: 0.006968427553854326
[Epoch 23, Batch 1700] loss: 0.009775398392109764
[Epoch 23, Batch 1800] loss: 0.004202673055788182
[Epoch 23, Batch 1900] loss: 0.006487814691625999
[Epoch 23, Batch 2000] loss: 0.010372644609672079
[Epoch 23, Batch 2100] loss: 0.0033889213027589447
[Epoch 23, Batch 2200] loss: 0.0020789843410420872
[Epoch 23, Batch 2300] loss: 0.0027319297563101943
[Epoch 23, Batch 2400] loss: 0.006282760366993898
[Epoch 23, Batch 2500] loss: 0.005418538357494071
[Epoch 23, Batch 2600] loss: 0.006504671635530599
[Epoch 23, Batch 2700] loss: 0.003716957688650382
[Epoch 23, Batch 2800] loss: 0.0058276475091435034
[Epoch 23, Batch 2900] loss: 0.0030945736191893046
[Epoch 23, Batch 3000] loss: 0.003793473031569192
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9858
Overfitting: 0.0551
[Epoch 24, Batch 100] loss: 0.00969538392600839
[Epoch 24, Batch 200] loss: 0.004824669906233794
[Epoch 24, Batch 300] loss: 0.0011828876275581024
[Epoch 24, Batch 400] loss: 0.005415891746092711
[Epoch 24, Batch 500] loss: 0.0032989516924106965
[Epoch 24, Batch 600] loss: 0.0048475280574552925
[Epoch 24, Batch 700] loss: 0.0023542343591992677
[Epoch 24, Batch 800] loss: 0.0013989305766136794
[Epoch 24, Batch 900] loss: 0.0036498650902035477
[Epoch 24, Batch 1000] loss: 0.007308764864440036
[Epoch 24, Batch 1100] loss: 0.007133304751828575
[Epoch 24, Batch 1200] loss: 0.008305647187341093
[Epoch 24, Batch 1300] loss: 0.006361825254942915
[Epoch 24, Batch 1400] loss: 0.006992998352820905
[Epoch 24, Batch 1500] loss: 0.008984134216489963
[Epoch 24, Batch 1600] loss: 0.0032939367126414254
[Epoch 24, Batch 1700] loss: 0.008303318304236314
[Epoch 24, Batch 1800] loss: 0.003285109580019707
[Epoch 24, Batch 1900] loss: 0.00348999230024873
[Epoch 24, Batch 2000] loss: 0.005378674098107012
[Epoch 24, Batch 2100] loss: 0.003599695039565631
[Epoch 24, Batch 2200] loss: 0.007612632134362229
[Epoch 24, Batch 2300] loss: 0.0025879713878464374
[Epoch 24, Batch 2400] loss: 0.004138077941473881
[Epoch 24, Batch 2500] loss: 0.005889908130594108
[Epoch 24, Batch 2600] loss: 0.010720364809911872
[Epoch 24, Batch 2700] loss: 0.006270567077605165
[Epoch 24, Batch 2800] loss: 0.01150211745856268
[Epoch 24, Batch 2900] loss: 0.006291208460595499
[Epoch 24, Batch 3000] loss: 0.005642024671874424
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9876
Overfitting: 0.0539
Fold 2 validation loss: 0.0539
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2947707772254944
[Epoch 1, Batch 200] loss: 2.2576010417938233
[Epoch 1, Batch 300] loss: 2.1564767265319826
[Epoch 1, Batch 400] loss: 1.6281832730770112
[Epoch 1, Batch 500] loss: 0.8054419875144958
[Epoch 1, Batch 600] loss: 0.6609218746423722
[Epoch 1, Batch 700] loss: 0.5143280278891325
[Epoch 1, Batch 800] loss: 0.44606611944735053
[Epoch 1, Batch 900] loss: 0.4032381683588028
[Epoch 1, Batch 1000] loss: 0.41395873107016085
[Epoch 1, Batch 1100] loss: 0.35869659364223483
[Epoch 1, Batch 1200] loss: 0.3485815818607807
[Epoch 1, Batch 1300] loss: 0.3369272877275944
[Epoch 1, Batch 1400] loss: 0.29629696138203143
[Epoch 1, Batch 1500] loss: 0.28283618241548536
[Epoch 1, Batch 1600] loss: 0.26050417449325325
[Epoch 1, Batch 1700] loss: 0.23422928497195245
[Epoch 1, Batch 1800] loss: 0.23517529409378768
[Epoch 1, Batch 1900] loss: 0.20842471769079565
[Epoch 1, Batch 2000] loss: 0.24956721967086196
[Epoch 1, Batch 2100] loss: 0.20134159771725535
[Epoch 1, Batch 2200] loss: 0.190682762991637
[Epoch 1, Batch 2300] loss: 0.1646127850841731
[Epoch 1, Batch 2400] loss: 0.1878194643743336
[Epoch 1, Batch 2500] loss: 0.15595483229495585
[Epoch 1, Batch 2600] loss: 0.16995893471874296
[Epoch 1, Batch 2700] loss: 0.1490854480769485
[Epoch 1, Batch 2800] loss: 0.1492901089275256
[Epoch 1, Batch 2900] loss: 0.13293637094087898
[Epoch 1, Batch 3000] loss: 0.13884201657958328
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1626
Validation Accuracy: 0.9517
Overfitting: 0.1626
Best model saved at epoch 1 with validation loss: 0.1626
[Epoch 2, Batch 100] loss: 0.12747006978373976
[Epoch 2, Batch 200] loss: 0.14245434449519961
[Epoch 2, Batch 300] loss: 0.14425615023821592
[Epoch 2, Batch 400] loss: 0.12166217097314075
[Epoch 2, Batch 500] loss: 0.12268165055196732
[Epoch 2, Batch 600] loss: 0.11340439304709435
[Epoch 2, Batch 700] loss: 0.11714127646060661
[Epoch 2, Batch 800] loss: 0.13269793211249634
[Epoch 2, Batch 900] loss: 0.12385738542769104
[Epoch 2, Batch 1000] loss: 0.1296660395292565
[Epoch 2, Batch 1100] loss: 0.12323151223361492
[Epoch 2, Batch 1200] loss: 0.1218275954015553
[Epoch 2, Batch 1300] loss: 0.115628229114227
[Epoch 2, Batch 1400] loss: 0.1072294125217013
[Epoch 2, Batch 1500] loss: 0.11554701291723177
[Epoch 2, Batch 1600] loss: 0.09235202818643301
[Epoch 2, Batch 1700] loss: 0.11367887515341862
[Epoch 2, Batch 1800] loss: 0.11204633706249296
[Epoch 2, Batch 1900] loss: 0.10707722437684425
[Epoch 2, Batch 2000] loss: 0.10357978482963517
[Epoch 2, Batch 2100] loss: 0.12125243118265644
[Epoch 2, Batch 2200] loss: 0.0764920780574903
[Epoch 2, Batch 2300] loss: 0.12384184103808366
[Epoch 2, Batch 2400] loss: 0.09905796714592725
[Epoch 2, Batch 2500] loss: 0.08822469986509532
[Epoch 2, Batch 2600] loss: 0.09892583676846697
[Epoch 2, Batch 2700] loss: 0.08902464607032017
[Epoch 2, Batch 2800] loss: 0.07566050573252142
[Epoch 2, Batch 2900] loss: 0.08154790357279125
[Epoch 2, Batch 3000] loss: 0.09674167185032274
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0978
Validation Accuracy: 0.9698
Overfitting: 0.0978
Best model saved at epoch 2 with validation loss: 0.0978
[Epoch 3, Batch 100] loss: 0.08791150379460305
[Epoch 3, Batch 200] loss: 0.09202340729767457
[Epoch 3, Batch 300] loss: 0.08496840209467336
[Epoch 3, Batch 400] loss: 0.0703045782202389
[Epoch 3, Batch 500] loss: 0.09938458434713539
[Epoch 3, Batch 600] loss: 0.07658263749268372
[Epoch 3, Batch 700] loss: 0.08875178502115887
[Epoch 3, Batch 800] loss: 0.07952354568638839
[Epoch 3, Batch 900] loss: 0.08298251001979225
[Epoch 3, Batch 1000] loss: 0.06997000832576304
[Epoch 3, Batch 1100] loss: 0.08398758078925311
[Epoch 3, Batch 1200] loss: 0.07234753420751076
[Epoch 3, Batch 1300] loss: 0.052617313155788
[Epoch 3, Batch 1400] loss: 0.0783863083034521
[Epoch 3, Batch 1500] loss: 0.0768774932809174
[Epoch 3, Batch 1600] loss: 0.07836217329953797
[Epoch 3, Batch 1700] loss: 0.07543082071118988
[Epoch 3, Batch 1800] loss: 0.0788402932707686
[Epoch 3, Batch 1900] loss: 0.09281366565206554
[Epoch 3, Batch 2000] loss: 0.07582210188847967
[Epoch 3, Batch 2100] loss: 0.06770440550986677
[Epoch 3, Batch 2200] loss: 0.08467189224378671
[Epoch 3, Batch 2300] loss: 0.07949680388788692
[Epoch 3, Batch 2400] loss: 0.08462200470850803
[Epoch 3, Batch 2500] loss: 0.07626438484177925
[Epoch 3, Batch 2600] loss: 0.08200759543688037
[Epoch 3, Batch 2700] loss: 0.08273010726785288
[Epoch 3, Batch 2800] loss: 0.056760258280846757
[Epoch 3, Batch 2900] loss: 0.07045601952995639
[Epoch 3, Batch 3000] loss: 0.05798285170691088
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0786
Validation Accuracy: 0.9761
Overfitting: 0.0786
Best model saved at epoch 3 with validation loss: 0.0786
[Epoch 4, Batch 100] loss: 0.0478731031154166
[Epoch 4, Batch 200] loss: 0.05027209849795326
[Epoch 4, Batch 300] loss: 0.05997326532553416
[Epoch 4, Batch 400] loss: 0.0506176986254286
[Epoch 4, Batch 500] loss: 0.07827687703073025
[Epoch 4, Batch 600] loss: 0.06583362652454525
[Epoch 4, Batch 700] loss: 0.04453706455824431
[Epoch 4, Batch 800] loss: 0.06207622964837355
[Epoch 4, Batch 900] loss: 0.07727539402840193
[Epoch 4, Batch 1000] loss: 0.07415491453954019
[Epoch 4, Batch 1100] loss: 0.06740116856410168
[Epoch 4, Batch 1200] loss: 0.08055925156106242
[Epoch 4, Batch 1300] loss: 0.05183676705462858
[Epoch 4, Batch 1400] loss: 0.06559241121751257
[Epoch 4, Batch 1500] loss: 0.05784609778202139
[Epoch 4, Batch 1600] loss: 0.053502271768520585
[Epoch 4, Batch 1700] loss: 0.04345947685476858
[Epoch 4, Batch 1800] loss: 0.07120965555106523
[Epoch 4, Batch 1900] loss: 0.07357787349144929
[Epoch 4, Batch 2000] loss: 0.07015240463486407
[Epoch 4, Batch 2100] loss: 0.0771683865308296
[Epoch 4, Batch 2200] loss: 0.046924295945791526
[Epoch 4, Batch 2300] loss: 0.06340198388381396
[Epoch 4, Batch 2400] loss: 0.05033073646016419
[Epoch 4, Batch 2500] loss: 0.06287712916149758
[Epoch 4, Batch 2600] loss: 0.05429161595064216
[Epoch 4, Batch 2700] loss: 0.05875147394457599
[Epoch 4, Batch 2800] loss: 0.07997620902722702
[Epoch 4, Batch 2900] loss: 0.06352870246686507
[Epoch 4, Batch 3000] loss: 0.04670011071721092
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0722
Validation Accuracy: 0.9778
Overfitting: 0.0722
Best model saved at epoch 4 with validation loss: 0.0722
[Epoch 5, Batch 100] loss: 0.04730275637644809
[Epoch 5, Batch 200] loss: 0.07003751717304113
[Epoch 5, Batch 300] loss: 0.055880543873063286
[Epoch 5, Batch 400] loss: 0.06457936439546756
[Epoch 5, Batch 500] loss: 0.050576195878675206
[Epoch 5, Batch 600] loss: 0.0476616725360509
[Epoch 5, Batch 700] loss: 0.0441921873256797
[Epoch 5, Batch 800] loss: 0.05685846344771562
[Epoch 5, Batch 900] loss: 0.04507947141188197
[Epoch 5, Batch 1000] loss: 0.046001043790602124
[Epoch 5, Batch 1100] loss: 0.032110877565282865
[Epoch 5, Batch 1200] loss: 0.05110164881654782
[Epoch 5, Batch 1300] loss: 0.04724763813006575
[Epoch 5, Batch 1400] loss: 0.05184517767978832
[Epoch 5, Batch 1500] loss: 0.04476308700832306
[Epoch 5, Batch 1600] loss: 0.039459613602084574
[Epoch 5, Batch 1700] loss: 0.05034853315417422
[Epoch 5, Batch 1800] loss: 0.06825990775243554
[Epoch 5, Batch 1900] loss: 0.049321063014213
[Epoch 5, Batch 2000] loss: 0.041021562289388386
[Epoch 5, Batch 2100] loss: 0.04308754104335094
[Epoch 5, Batch 2200] loss: 0.05065729278634535
[Epoch 5, Batch 2300] loss: 0.03957739942852641
[Epoch 5, Batch 2400] loss: 0.05470536264358088
[Epoch 5, Batch 2500] loss: 0.04798288604186382
[Epoch 5, Batch 2600] loss: 0.059670774743135556
[Epoch 5, Batch 2700] loss: 0.04738786407207954
[Epoch 5, Batch 2800] loss: 0.044954760783730306
[Epoch 5, Batch 2900] loss: 0.047166440083092315
[Epoch 5, Batch 3000] loss: 0.074035882272874
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0650
Validation Accuracy: 0.9800
Overfitting: 0.0650
Best model saved at epoch 5 with validation loss: 0.0650
[Epoch 6, Batch 100] loss: 0.03187470251054037
[Epoch 6, Batch 200] loss: 0.03887336439045612
[Epoch 6, Batch 300] loss: 0.05220157206931617
[Epoch 6, Batch 400] loss: 0.03611383817653405
[Epoch 6, Batch 500] loss: 0.04989899129315745
[Epoch 6, Batch 600] loss: 0.04095091119437711
[Epoch 6, Batch 700] loss: 0.05447836037841625
[Epoch 6, Batch 800] loss: 0.03121312625342398
[Epoch 6, Batch 900] loss: 0.04942463951731042
[Epoch 6, Batch 1000] loss: 0.039408834256755655
[Epoch 6, Batch 1100] loss: 0.04259925720660249
[Epoch 6, Batch 1200] loss: 0.05424449963727966
[Epoch 6, Batch 1300] loss: 0.040659507952805145
[Epoch 6, Batch 1400] loss: 0.0437982078337518
[Epoch 6, Batch 1500] loss: 0.04671466953790514
[Epoch 6, Batch 1600] loss: 0.03703787904320052
[Epoch 6, Batch 1700] loss: 0.02897806380642578
[Epoch 6, Batch 1800] loss: 0.05871543992398074
[Epoch 6, Batch 1900] loss: 0.05577918748313095
[Epoch 6, Batch 2000] loss: 0.03872079592227237
[Epoch 6, Batch 2100] loss: 0.0463672756854794
[Epoch 6, Batch 2200] loss: 0.03892760585440556
[Epoch 6, Batch 2300] loss: 0.03656792220659554
[Epoch 6, Batch 2400] loss: 0.026706071113731012
[Epoch 6, Batch 2500] loss: 0.04424270290561253
[Epoch 6, Batch 2600] loss: 0.05245972185919527
[Epoch 6, Batch 2700] loss: 0.04648955011274666
[Epoch 6, Batch 2800] loss: 0.044690977110585665
[Epoch 6, Batch 2900] loss: 0.03948643905052449
[Epoch 6, Batch 3000] loss: 0.04616692722614971
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9808
Overfitting: 0.0593
Best model saved at epoch 6 with validation loss: 0.0593
[Epoch 7, Batch 100] loss: 0.04339459904062096
[Epoch 7, Batch 200] loss: 0.020987699165270896
[Epoch 7, Batch 300] loss: 0.028695633836032356
[Epoch 7, Batch 400] loss: 0.03475687019497855
[Epoch 7, Batch 500] loss: 0.025505128886143213
[Epoch 7, Batch 600] loss: 0.04661073397321161
[Epoch 7, Batch 700] loss: 0.042205932566721456
[Epoch 7, Batch 800] loss: 0.035569776307238496
[Epoch 7, Batch 900] loss: 0.03529965419613291
[Epoch 7, Batch 1000] loss: 0.03178126160375541
[Epoch 7, Batch 1100] loss: 0.03514312617300675
[Epoch 7, Batch 1200] loss: 0.05271677512530005
[Epoch 7, Batch 1300] loss: 0.04542276994616259
[Epoch 7, Batch 1400] loss: 0.03956972004205454
[Epoch 7, Batch 1500] loss: 0.028075979413115418
[Epoch 7, Batch 1600] loss: 0.03544095241522882
[Epoch 7, Batch 1700] loss: 0.030286312633979833
[Epoch 7, Batch 1800] loss: 0.031070411259424873
[Epoch 7, Batch 1900] loss: 0.04002029772178503
[Epoch 7, Batch 2000] loss: 0.03742656905946205
[Epoch 7, Batch 2100] loss: 0.027289988931224796
[Epoch 7, Batch 2200] loss: 0.038365456764877306
[Epoch 7, Batch 2300] loss: 0.043990876570460385
[Epoch 7, Batch 2400] loss: 0.03659360901852779
[Epoch 7, Batch 2500] loss: 0.04716403069196531
[Epoch 7, Batch 2600] loss: 0.0303151358179457
[Epoch 7, Batch 2700] loss: 0.040714361410209676
[Epoch 7, Batch 2800] loss: 0.04137853155232733
[Epoch 7, Batch 2900] loss: 0.03900642889915616
[Epoch 7, Batch 3000] loss: 0.057460298260994025
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0580
Validation Accuracy: 0.9806
Overfitting: 0.0580
Best model saved at epoch 7 with validation loss: 0.0580
[Epoch 8, Batch 100] loss: 0.038730071441677866
[Epoch 8, Batch 200] loss: 0.036743950657255484
[Epoch 8, Batch 300] loss: 0.022704230259987527
[Epoch 8, Batch 400] loss: 0.02415389271307504
[Epoch 8, Batch 500] loss: 0.017252188826241764
[Epoch 8, Batch 600] loss: 0.02894645820997539
[Epoch 8, Batch 700] loss: 0.033265370480003185
[Epoch 8, Batch 800] loss: 0.03761338885407895
[Epoch 8, Batch 900] loss: 0.03554548220628931
[Epoch 8, Batch 1000] loss: 0.03449917763893609
[Epoch 8, Batch 1100] loss: 0.03491218226714409
[Epoch 8, Batch 1200] loss: 0.020236946899858596
[Epoch 8, Batch 1300] loss: 0.0283261963420955
[Epoch 8, Batch 1400] loss: 0.04409981319462531
[Epoch 8, Batch 1500] loss: 0.031890144173885346
[Epoch 8, Batch 1600] loss: 0.043183375991648065
[Epoch 8, Batch 1700] loss: 0.028690564203352552
[Epoch 8, Batch 1800] loss: 0.031003921465453457
[Epoch 8, Batch 1900] loss: 0.03666738469488337
[Epoch 8, Batch 2000] loss: 0.025472346640599428
[Epoch 8, Batch 2100] loss: 0.026030542556
[Epoch 8, Batch 2200] loss: 0.02893055817599816
[Epoch 8, Batch 2300] loss: 0.024875886262962013
[Epoch 8, Batch 2400] loss: 0.05154896801992436
[Epoch 8, Batch 2500] loss: 0.026135372234275565
[Epoch 8, Batch 2600] loss: 0.04197299537408981
[Epoch 8, Batch 2700] loss: 0.05416601836499467
[Epoch 8, Batch 2800] loss: 0.02964738442984526
[Epoch 8, Batch 2900] loss: 0.020720274094346677
[Epoch 8, Batch 3000] loss: 0.038197166862373705
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9847
Overfitting: 0.0495
Best model saved at epoch 8 with validation loss: 0.0495
[Epoch 9, Batch 100] loss: 0.024441354962546027
[Epoch 9, Batch 200] loss: 0.028676675218957826
[Epoch 9, Batch 300] loss: 0.019348032884372514
[Epoch 9, Batch 400] loss: 0.026238094217660546
[Epoch 9, Batch 500] loss: 0.017043801122999868
[Epoch 9, Batch 600] loss: 0.044171719044097696
[Epoch 9, Batch 700] loss: 0.03181044969729555
[Epoch 9, Batch 800] loss: 0.026986954434760263
[Epoch 9, Batch 900] loss: 0.03368059446911502
[Epoch 9, Batch 1000] loss: 0.0307648446733765
[Epoch 9, Batch 1100] loss: 0.031327462145891334
[Epoch 9, Batch 1200] loss: 0.027144995121634565
[Epoch 9, Batch 1300] loss: 0.030272117508939118
[Epoch 9, Batch 1400] loss: 0.01666711792720889
[Epoch 9, Batch 1500] loss: 0.02638400542182353
[Epoch 9, Batch 1600] loss: 0.024765894434749497
[Epoch 9, Batch 1700] loss: 0.026880557692347793
[Epoch 9, Batch 1800] loss: 0.03261857564368256
[Epoch 9, Batch 1900] loss: 0.04557256650994532
[Epoch 9, Batch 2000] loss: 0.024964194321219112
[Epoch 9, Batch 2100] loss: 0.023780980710944276
[Epoch 9, Batch 2200] loss: 0.027603280652620014
[Epoch 9, Batch 2300] loss: 0.021321489215188193
[Epoch 9, Batch 2400] loss: 0.024213295290974202
[Epoch 9, Batch 2500] loss: 0.03155859897349728
[Epoch 9, Batch 2600] loss: 0.03504623372813512
[Epoch 9, Batch 2700] loss: 0.02368673787013904
[Epoch 9, Batch 2800] loss: 0.03351393636854482
[Epoch 9, Batch 2900] loss: 0.03280588900212024
[Epoch 9, Batch 3000] loss: 0.014049925966101
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9857
Overfitting: 0.0473
Best model saved at epoch 9 with validation loss: 0.0473
[Epoch 10, Batch 100] loss: 0.024702370454469928
[Epoch 10, Batch 200] loss: 0.022458501449800678
[Epoch 10, Batch 300] loss: 0.019611202335945564
[Epoch 10, Batch 400] loss: 0.02552943875627534
[Epoch 10, Batch 500] loss: 0.03081274083813696
[Epoch 10, Batch 600] loss: 0.025689039425269584
[Epoch 10, Batch 700] loss: 0.017520835120176343
[Epoch 10, Batch 800] loss: 0.029418114234540552
[Epoch 10, Batch 900] loss: 0.016140143091233766
[Epoch 10, Batch 1000] loss: 0.02200972377526341
[Epoch 10, Batch 1100] loss: 0.02103353148406313
[Epoch 10, Batch 1200] loss: 0.02414855145616457
[Epoch 10, Batch 1300] loss: 0.021902746129781006
[Epoch 10, Batch 1400] loss: 0.022713331554878095
[Epoch 10, Batch 1500] loss: 0.031013566893161624
[Epoch 10, Batch 1600] loss: 0.027491745488441667
[Epoch 10, Batch 1700] loss: 0.032446585642173884
[Epoch 10, Batch 1800] loss: 0.02005694766427041
[Epoch 10, Batch 1900] loss: 0.02013205311355705
[Epoch 10, Batch 2000] loss: 0.021382800029841748
[Epoch 10, Batch 2100] loss: 0.01089590697125459
[Epoch 10, Batch 2200] loss: 0.02258485928272421
[Epoch 10, Batch 2300] loss: 0.024969120107998607
[Epoch 10, Batch 2400] loss: 0.036296859308313285
[Epoch 10, Batch 2500] loss: 0.04866019152512308
[Epoch 10, Batch 2600] loss: 0.021747052284626988
[Epoch 10, Batch 2700] loss: 0.02916872202171362
[Epoch 10, Batch 2800] loss: 0.02498030073795235
[Epoch 10, Batch 2900] loss: 0.023832934316942556
[Epoch 10, Batch 3000] loss: 0.02464471245191817
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9863
Overfitting: 0.0447
Best model saved at epoch 10 with validation loss: 0.0447
[Epoch 11, Batch 100] loss: 0.014341944244333717
[Epoch 11, Batch 200] loss: 0.019643147134265748
[Epoch 11, Batch 300] loss: 0.016530348619453433
[Epoch 11, Batch 400] loss: 0.023679152500553757
[Epoch 11, Batch 500] loss: 0.023494017339926357
[Epoch 11, Batch 600] loss: 0.015808975632862713
[Epoch 11, Batch 700] loss: 0.011983456682501128
[Epoch 11, Batch 800] loss: 0.014029524316065363
[Epoch 11, Batch 900] loss: 0.021356482317351037
[Epoch 11, Batch 1000] loss: 0.01661445009536692
[Epoch 11, Batch 1100] loss: 0.0217518472942902
[Epoch 11, Batch 1200] loss: 0.01687189689700972
[Epoch 11, Batch 1300] loss: 0.023072888440037787
[Epoch 11, Batch 1400] loss: 0.035608495846609
[Epoch 11, Batch 1500] loss: 0.031937282204744406
[Epoch 11, Batch 1600] loss: 0.02096423249640793
[Epoch 11, Batch 1700] loss: 0.022344862503377954
[Epoch 11, Batch 1800] loss: 0.022564874306153795
[Epoch 11, Batch 1900] loss: 0.012004036464204546
[Epoch 11, Batch 2000] loss: 0.029287468706970684
[Epoch 11, Batch 2100] loss: 0.024695993261193507
[Epoch 11, Batch 2200] loss: 0.02078575083411124
[Epoch 11, Batch 2300] loss: 0.013426100081560435
[Epoch 11, Batch 2400] loss: 0.025521991865207382
[Epoch 11, Batch 2500] loss: 0.027863032335626484
[Epoch 11, Batch 2600] loss: 0.022358088828332255
[Epoch 11, Batch 2700] loss: 0.029371197203508927
[Epoch 11, Batch 2800] loss: 0.02550576633117089
[Epoch 11, Batch 2900] loss: 0.03688163543936753
[Epoch 11, Batch 3000] loss: 0.026830704338881333
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9849
Overfitting: 0.0518
[Epoch 12, Batch 100] loss: 0.02299379599025997
[Epoch 12, Batch 200] loss: 0.0184871272104283
[Epoch 12, Batch 300] loss: 0.012424553971650312
[Epoch 12, Batch 400] loss: 0.0127781340405636
[Epoch 12, Batch 500] loss: 0.021227330164365413
[Epoch 12, Batch 600] loss: 0.020617681054172863
[Epoch 12, Batch 700] loss: 0.030424078977885075
[Epoch 12, Batch 800] loss: 0.019783101540360802
[Epoch 12, Batch 900] loss: 0.021100935473959907
[Epoch 12, Batch 1000] loss: 0.017402187642946956
[Epoch 12, Batch 1100] loss: 0.016044319016791632
[Epoch 12, Batch 1200] loss: 0.013489301054614771
[Epoch 12, Batch 1300] loss: 0.020242902689424226
[Epoch 12, Batch 1400] loss: 0.011134982718758693
[Epoch 12, Batch 1500] loss: 0.013479806024106438
[Epoch 12, Batch 1600] loss: 0.01517461111771354
[Epoch 12, Batch 1700] loss: 0.01611384010142501
[Epoch 12, Batch 1800] loss: 0.0271611329393636
[Epoch 12, Batch 1900] loss: 0.010657845859477676
[Epoch 12, Batch 2000] loss: 0.02193912143287889
[Epoch 12, Batch 2100] loss: 0.0250568525575909
[Epoch 12, Batch 2200] loss: 0.037514059749701116
[Epoch 12, Batch 2300] loss: 0.018607474215277763
[Epoch 12, Batch 2400] loss: 0.028901852569615586
[Epoch 12, Batch 2500] loss: 0.013189054817512442
[Epoch 12, Batch 2600] loss: 0.01750878551860296
[Epoch 12, Batch 2700] loss: 0.019520281654258724
[Epoch 12, Batch 2800] loss: 0.02340542860527421
[Epoch 12, Batch 2900] loss: 0.01737174333771691
[Epoch 12, Batch 3000] loss: 0.026135528678059926
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9847
Overfitting: 0.0524
[Epoch 13, Batch 100] loss: 0.013025846440978057
[Epoch 13, Batch 200] loss: 0.01174356642874045
[Epoch 13, Batch 300] loss: 0.018567490632922273
[Epoch 13, Batch 400] loss: 0.02698468563212373
[Epoch 13, Batch 500] loss: 0.021937296993783093
[Epoch 13, Batch 600] loss: 0.015640673402303948
[Epoch 13, Batch 700] loss: 0.02565902771806577
[Epoch 13, Batch 800] loss: 0.02379600683998433
[Epoch 13, Batch 900] loss: 0.02468473023011029
[Epoch 13, Batch 1000] loss: 0.014607776260945685
[Epoch 13, Batch 1100] loss: 0.009162571272327114
[Epoch 13, Batch 1200] loss: 0.009183065952320248
[Epoch 13, Batch 1300] loss: 0.015751489696767748
[Epoch 13, Batch 1400] loss: 0.0140177373172628
[Epoch 13, Batch 1500] loss: 0.013424739021511414
[Epoch 13, Batch 1600] loss: 0.01043603099863958
[Epoch 13, Batch 1700] loss: 0.02378097953107499
[Epoch 13, Batch 1800] loss: 0.015954327173294588
[Epoch 13, Batch 1900] loss: 0.020507926503505587
[Epoch 13, Batch 2000] loss: 0.013358722492621383
[Epoch 13, Batch 2100] loss: 0.011354861316467577
[Epoch 13, Batch 2200] loss: 0.01583395363508316
[Epoch 13, Batch 2300] loss: 0.015793446414681965
[Epoch 13, Batch 2400] loss: 0.0282958729893835
[Epoch 13, Batch 2500] loss: 0.015310410463753215
[Epoch 13, Batch 2600] loss: 0.014439522480788582
[Epoch 13, Batch 2700] loss: 0.02766430479932751
[Epoch 13, Batch 2800] loss: 0.017223485732529298
[Epoch 13, Batch 2900] loss: 0.02353154835596797
[Epoch 13, Batch 3000] loss: 0.023985989979846637
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0503
Validation Accuracy: 0.9853
Overfitting: 0.0503
[Epoch 14, Batch 100] loss: 0.015376527802436613
[Epoch 14, Batch 200] loss: 0.023556726171627816
[Epoch 14, Batch 300] loss: 0.011470583811369579
[Epoch 14, Batch 400] loss: 0.0172428471701096
[Epoch 14, Batch 500] loss: 0.0116466890902484
[Epoch 14, Batch 600] loss: 0.01783814162154158
[Epoch 14, Batch 700] loss: 0.0117751311529355
[Epoch 14, Batch 800] loss: 0.022699588161049177
[Epoch 14, Batch 900] loss: 0.014505856933392352
[Epoch 14, Batch 1000] loss: 0.010956255444543785
[Epoch 14, Batch 1100] loss: 0.01848641034085631
[Epoch 14, Batch 1200] loss: 0.008511191358429641
[Epoch 14, Batch 1300] loss: 0.012957874289922984
[Epoch 14, Batch 1400] loss: 0.03183560367842801
[Epoch 14, Batch 1500] loss: 0.011530322256876389
[Epoch 14, Batch 1600] loss: 0.02151158293505432
[Epoch 14, Batch 1700] loss: 0.020364748789725128
[Epoch 14, Batch 1800] loss: 0.020264154792348565
[Epoch 14, Batch 1900] loss: 0.022758287690703583
[Epoch 14, Batch 2000] loss: 0.01761519955020958
[Epoch 14, Batch 2100] loss: 0.012010345435355703
[Epoch 14, Batch 2200] loss: 0.014024478508126777
[Epoch 14, Batch 2300] loss: 0.017819955445738743
[Epoch 14, Batch 2400] loss: 0.011053118692007046
[Epoch 14, Batch 2500] loss: 0.012711911948290435
[Epoch 14, Batch 2600] loss: 0.005978779484039478
[Epoch 14, Batch 2700] loss: 0.009457188218511874
[Epoch 14, Batch 2800] loss: 0.013222874798129851
[Epoch 14, Batch 2900] loss: 0.010999643351706254
[Epoch 14, Batch 3000] loss: 0.011665316658327356
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9881
Overfitting: 0.0453
[Epoch 15, Batch 100] loss: 0.010770789648559003
[Epoch 15, Batch 200] loss: 0.013671296748998429
[Epoch 15, Batch 300] loss: 0.005943094396234301
[Epoch 15, Batch 400] loss: 0.014810654653683742
[Epoch 15, Batch 500] loss: 0.011825295967992134
[Epoch 15, Batch 600] loss: 0.013420308412410122
[Epoch 15, Batch 700] loss: 0.018620203989098628
[Epoch 15, Batch 800] loss: 0.013190293294592266
[Epoch 15, Batch 900] loss: 0.008356887240834112
[Epoch 15, Batch 1000] loss: 0.011127651842816704
[Epoch 15, Batch 1100] loss: 0.0197695793181083
[Epoch 15, Batch 1200] loss: 0.01499641631099621
[Epoch 15, Batch 1300] loss: 0.01825008596471889
[Epoch 15, Batch 1400] loss: 0.011497886024126274
[Epoch 15, Batch 1500] loss: 0.014952401050168191
[Epoch 15, Batch 1600] loss: 0.013358029066625931
[Epoch 15, Batch 1700] loss: 0.009291588891974243
[Epoch 15, Batch 1800] loss: 0.01215582146821589
[Epoch 15, Batch 1900] loss: 0.00914727070790832
[Epoch 15, Batch 2000] loss: 0.013548921628635071
[Epoch 15, Batch 2100] loss: 0.014153593407045265
[Epoch 15, Batch 2200] loss: 0.014636888534255377
[Epoch 15, Batch 2300] loss: 0.015528699435226372
[Epoch 15, Batch 2400] loss: 0.014160099395191993
[Epoch 15, Batch 2500] loss: 0.019278712769237247
[Epoch 15, Batch 2600] loss: 0.019974180644640002
[Epoch 15, Batch 2700] loss: 0.01315985654317501
[Epoch 15, Batch 2800] loss: 0.011405725521426576
[Epoch 15, Batch 2900] loss: 0.021861384807152717
[Epoch 15, Batch 3000] loss: 0.016647465390130945
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9873
Overfitting: 0.0493
[Epoch 16, Batch 100] loss: 0.007209317311335326
[Epoch 16, Batch 200] loss: 0.007039175122376946
[Epoch 16, Batch 300] loss: 0.009749648332217475
[Epoch 16, Batch 400] loss: 0.008652410825493461
[Epoch 16, Batch 500] loss: 0.008683885385319173
[Epoch 16, Batch 600] loss: 0.006896294558064255
[Epoch 16, Batch 700] loss: 0.013358899051577283
[Epoch 16, Batch 800] loss: 0.009923641285313351
[Epoch 16, Batch 900] loss: 0.011570888920159632
[Epoch 16, Batch 1000] loss: 0.015684789393271784
[Epoch 16, Batch 1100] loss: 0.008002831040048477
[Epoch 16, Batch 1200] loss: 0.011387760070292643
[Epoch 16, Batch 1300] loss: 0.0073181496727011104
[Epoch 16, Batch 1400] loss: 0.0121000198481579
[Epoch 16, Batch 1500] loss: 0.015289294747117311
[Epoch 16, Batch 1600] loss: 0.014144481453549816
[Epoch 16, Batch 1700] loss: 0.01233284357216462
[Epoch 16, Batch 1800] loss: 0.012314991501866643
[Epoch 16, Batch 1900] loss: 0.008457292800244431
[Epoch 16, Batch 2000] loss: 0.011164378123544339
[Epoch 16, Batch 2100] loss: 0.017291069612965657
[Epoch 16, Batch 2200] loss: 0.017347734888394372
[Epoch 16, Batch 2300] loss: 0.014399296688989125
[Epoch 16, Batch 2400] loss: 0.010366440943944327
[Epoch 16, Batch 2500] loss: 0.009118527896407613
[Epoch 16, Batch 2600] loss: 0.012661797535238294
[Epoch 16, Batch 2700] loss: 0.007835598650794964
[Epoch 16, Batch 2800] loss: 0.02126099285119153
[Epoch 16, Batch 2900] loss: 0.016865515558565677
[Epoch 16, Batch 3000] loss: 0.024919612692374356
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9882
Overfitting: 0.0447
[Epoch 17, Batch 100] loss: 0.006832597305328818
[Epoch 17, Batch 200] loss: 0.01018886608972025
[Epoch 17, Batch 300] loss: 0.018604278977636567
[Epoch 17, Batch 400] loss: 0.009479804730472097
[Epoch 17, Batch 500] loss: 0.009150098897553107
[Epoch 17, Batch 600] loss: 0.0037009415873944817
[Epoch 17, Batch 700] loss: 0.004540439529075684
[Epoch 17, Batch 800] loss: 0.005353781148269263
[Epoch 17, Batch 900] loss: 0.0035790903977795095
[Epoch 17, Batch 1000] loss: 0.008497490820909661
[Epoch 17, Batch 1100] loss: 0.01125108360929744
[Epoch 17, Batch 1200] loss: 0.014614959179707511
[Epoch 17, Batch 1300] loss: 0.00847128652387255
[Epoch 17, Batch 1400] loss: 0.006524606176908492
[Epoch 17, Batch 1500] loss: 0.016036937251675452
[Epoch 17, Batch 1600] loss: 0.005216220243496537
[Epoch 17, Batch 1700] loss: 0.007752749799051344
[Epoch 17, Batch 1800] loss: 0.008184867000871919
[Epoch 17, Batch 1900] loss: 0.01149338859181853
[Epoch 17, Batch 2000] loss: 0.0037398729322194414
[Epoch 17, Batch 2100] loss: 0.011050143423144618
[Epoch 17, Batch 2200] loss: 0.01801336781417831
[Epoch 17, Batch 2300] loss: 0.011791536336654645
[Epoch 17, Batch 2400] loss: 0.009336383093001359
[Epoch 17, Batch 2500] loss: 0.01240115995583892
[Epoch 17, Batch 2600] loss: 0.014364950057783972
[Epoch 17, Batch 2700] loss: 0.015225464042746353
[Epoch 17, Batch 2800] loss: 0.011298113962175194
[Epoch 17, Batch 2900] loss: 0.0077214339210138405
[Epoch 17, Batch 3000] loss: 0.014200951275104217
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9857
Overfitting: 0.0520
[Epoch 18, Batch 100] loss: 0.006795051866906761
[Epoch 18, Batch 200] loss: 0.010364065295470936
[Epoch 18, Batch 300] loss: 0.0033213010786130328
[Epoch 18, Batch 400] loss: 0.00972881991616873
[Epoch 18, Batch 500] loss: 0.009683192324309857
[Epoch 18, Batch 600] loss: 0.013638334702147575
[Epoch 18, Batch 700] loss: 0.004609235736156733
[Epoch 18, Batch 800] loss: 0.007295258473827743
[Epoch 18, Batch 900] loss: 0.007058663330622039
[Epoch 18, Batch 1000] loss: 0.008258942182360443
[Epoch 18, Batch 1100] loss: 0.011230590251304875
[Epoch 18, Batch 1200] loss: 0.013515900390135584
[Epoch 18, Batch 1300] loss: 0.011567197074855358
[Epoch 18, Batch 1400] loss: 0.007464712645979716
[Epoch 18, Batch 1500] loss: 0.009989589288577462
[Epoch 18, Batch 1600] loss: 0.00919394412301699
[Epoch 18, Batch 1700] loss: 0.006696045436206078
[Epoch 18, Batch 1800] loss: 0.0067621044101724695
[Epoch 18, Batch 1900] loss: 0.003780721478271971
[Epoch 18, Batch 2000] loss: 0.007585532374491777
[Epoch 18, Batch 2100] loss: 0.009208751483995456
[Epoch 18, Batch 2200] loss: 0.007637385496918228
[Epoch 18, Batch 2300] loss: 0.012444648441593244
[Epoch 18, Batch 2400] loss: 0.008306091226403823
[Epoch 18, Batch 2500] loss: 0.010416143525058033
[Epoch 18, Batch 2600] loss: 0.009992764396554322
[Epoch 18, Batch 2700] loss: 0.006597304985793926
[Epoch 18, Batch 2800] loss: 0.010184992941231031
[Epoch 18, Batch 2900] loss: 0.013876215749622816
[Epoch 18, Batch 3000] loss: 0.016900641509477055
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9848
Overfitting: 0.0576
[Epoch 19, Batch 100] loss: 0.010466578525592922
[Epoch 19, Batch 200] loss: 0.004460857167211998
[Epoch 19, Batch 300] loss: 0.0030540547422924645
[Epoch 19, Batch 400] loss: 0.0062825178706913225
[Epoch 19, Batch 500] loss: 0.0055506656719990135
[Epoch 19, Batch 600] loss: 0.003779581365636204
[Epoch 19, Batch 700] loss: 0.007831539140739778
[Epoch 19, Batch 800] loss: 0.008298173706607485
[Epoch 19, Batch 900] loss: 0.0035451137516702147
[Epoch 19, Batch 1000] loss: 0.0042238785667734645
[Epoch 19, Batch 1100] loss: 0.0070526426672563505
[Epoch 19, Batch 1200] loss: 0.003559445380434738
[Epoch 19, Batch 1300] loss: 0.014309229054339312
[Epoch 19, Batch 1400] loss: 0.007761600021055983
[Epoch 19, Batch 1500] loss: 0.004653049175642252
[Epoch 19, Batch 1600] loss: 0.008498766466174175
[Epoch 19, Batch 1700] loss: 0.017964573547805004
[Epoch 19, Batch 1800] loss: 0.01419647982244669
[Epoch 19, Batch 1900] loss: 0.011424970920475062
[Epoch 19, Batch 2000] loss: 0.007684241006709272
[Epoch 19, Batch 2100] loss: 0.005125451189526302
[Epoch 19, Batch 2200] loss: 0.007622610974963208
[Epoch 19, Batch 2300] loss: 0.010681273766472259
[Epoch 19, Batch 2400] loss: 0.010931914180964668
[Epoch 19, Batch 2500] loss: 0.005225204923763158
[Epoch 19, Batch 2600] loss: 0.016907900693602186
[Epoch 19, Batch 2700] loss: 0.0042241433083290755
[Epoch 19, Batch 2800] loss: 0.005813434868578042
[Epoch 19, Batch 2900] loss: 0.008237843419124147
[Epoch 19, Batch 3000] loss: 0.012486095963371326
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9863
Overfitting: 0.0501
[Epoch 20, Batch 100] loss: 0.011848104748814876
[Epoch 20, Batch 200] loss: 0.008574517911924887
[Epoch 20, Batch 300] loss: 0.0038311628941755773
[Epoch 20, Batch 400] loss: 0.003469250988503063
[Epoch 20, Batch 500] loss: 0.009624893826762673
[Epoch 20, Batch 600] loss: 0.004751185747037426
[Epoch 20, Batch 700] loss: 0.004757570324773042
[Epoch 20, Batch 800] loss: 0.005423173023975778
[Epoch 20, Batch 900] loss: 0.01050493926992658
[Epoch 20, Batch 1000] loss: 0.00443695993136771
[Epoch 20, Batch 1100] loss: 0.007492235332470613
[Epoch 20, Batch 1200] loss: 0.003175754364460772
[Epoch 20, Batch 1300] loss: 0.0033276445451940616
[Epoch 20, Batch 1400] loss: 0.0027444962890052693
[Epoch 20, Batch 1500] loss: 0.005739330895230523
[Epoch 20, Batch 1600] loss: 0.00830223068134046
[Epoch 20, Batch 1700] loss: 0.008318615942316683
[Epoch 20, Batch 1800] loss: 0.009101408382575756
[Epoch 20, Batch 1900] loss: 0.009723516771976505
[Epoch 20, Batch 2000] loss: 0.0056945650255738655
[Epoch 20, Batch 2100] loss: 0.0037516228225831583
[Epoch 20, Batch 2200] loss: 0.006341532743805374
[Epoch 20, Batch 2300] loss: 0.021866834767787394
[Epoch 20, Batch 2400] loss: 0.008988434663910994
[Epoch 20, Batch 2500] loss: 0.004279583376829805
[Epoch 20, Batch 2600] loss: 0.007330620509928849
[Epoch 20, Batch 2700] loss: 0.011899184950923427
[Epoch 20, Batch 2800] loss: 0.017768281449382927
[Epoch 20, Batch 2900] loss: 0.004453699543353196
[Epoch 20, Batch 3000] loss: 0.005690705433894436
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9878
Overfitting: 0.0527
[Epoch 21, Batch 100] loss: 0.005757850956393895
[Epoch 21, Batch 200] loss: 0.0032044031036417664
[Epoch 21, Batch 300] loss: 0.005226086583178358
[Epoch 21, Batch 400] loss: 0.00546430107873789
[Epoch 21, Batch 500] loss: 0.0034774871509091554
[Epoch 21, Batch 600] loss: 0.013459843353684846
[Epoch 21, Batch 700] loss: 0.0021224733772527314
[Epoch 21, Batch 800] loss: 0.004144660184630311
[Epoch 21, Batch 900] loss: 0.008708461157683587
[Epoch 21, Batch 1000] loss: 0.005280948980057474
[Epoch 21, Batch 1100] loss: 0.005922826835653722
[Epoch 21, Batch 1200] loss: 0.01035286328061261
[Epoch 21, Batch 1300] loss: 0.0025376509441653637
[Epoch 21, Batch 1400] loss: 0.006985807310845757
[Epoch 21, Batch 1500] loss: 0.004186784266130417
[Epoch 21, Batch 1600] loss: 0.005366077913204776
[Epoch 21, Batch 1700] loss: 0.0022687694259340674
[Epoch 21, Batch 1800] loss: 0.009109266512196542
[Epoch 21, Batch 1900] loss: 0.006145785704311493
[Epoch 21, Batch 2000] loss: 0.007082422568001903
[Epoch 21, Batch 2100] loss: 0.0082727461839022
[Epoch 21, Batch 2200] loss: 0.006798250692362444
[Epoch 21, Batch 2300] loss: 0.008984343169520343
[Epoch 21, Batch 2400] loss: 0.0022585896936311656
[Epoch 21, Batch 2500] loss: 0.0036694699090583072
[Epoch 21, Batch 2600] loss: 0.00832306820523513
[Epoch 21, Batch 2700] loss: 0.014492710067321469
[Epoch 21, Batch 2800] loss: 0.011055483034110693
[Epoch 21, Batch 2900] loss: 0.008724940438578415
[Epoch 21, Batch 3000] loss: 0.006980942992277051
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9855
Overfitting: 0.0560
[Epoch 22, Batch 100] loss: 0.005730466382142367
[Epoch 22, Batch 200] loss: 0.003111965101354599
[Epoch 22, Batch 300] loss: 0.004571714155877374
[Epoch 22, Batch 400] loss: 0.008368212622279998
[Epoch 22, Batch 500] loss: 0.0035442305812306784
[Epoch 22, Batch 600] loss: 0.010115978528328923
[Epoch 22, Batch 700] loss: 0.0033592611128918292
[Epoch 22, Batch 800] loss: 0.005214809130529829
[Epoch 22, Batch 900] loss: 0.005300100373578971
[Epoch 22, Batch 1000] loss: 0.004032576962857775
[Epoch 22, Batch 1100] loss: 0.006047430958253699
[Epoch 22, Batch 1200] loss: 0.006723861588598652
[Epoch 22, Batch 1300] loss: 0.006545512817122301
[Epoch 22, Batch 1400] loss: 0.011322789783922644
[Epoch 22, Batch 1500] loss: 0.01379076303143819
[Epoch 22, Batch 1600] loss: 0.005508322483619849
[Epoch 22, Batch 1700] loss: 0.0041053571048234976
[Epoch 22, Batch 1800] loss: 0.0017208169703542353
[Epoch 22, Batch 1900] loss: 0.003458753515657236
[Epoch 22, Batch 2000] loss: 0.004404340210289775
[Epoch 22, Batch 2100] loss: 0.004029064182492448
[Epoch 22, Batch 2200] loss: 0.0027704804816974615
[Epoch 22, Batch 2300] loss: 0.005444442819712094
[Epoch 22, Batch 2400] loss: 0.007197526950263864
[Epoch 22, Batch 2500] loss: 0.005593952927450232
[Epoch 22, Batch 2600] loss: 0.0030813366928106236
[Epoch 22, Batch 2700] loss: 0.005239555728747973
[Epoch 22, Batch 2800] loss: 0.0034436676042855652
[Epoch 22, Batch 2900] loss: 0.004505974079576731
[Epoch 22, Batch 3000] loss: 0.00487222676852042
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9884
Overfitting: 0.0513
[Epoch 23, Batch 100] loss: 0.001678755306123776
[Epoch 23, Batch 200] loss: 0.002572722874488491
[Epoch 23, Batch 300] loss: 0.0033092087837442463
[Epoch 23, Batch 400] loss: 0.001005384104326481
[Epoch 23, Batch 500] loss: 0.004928250101966683
[Epoch 23, Batch 600] loss: 0.002893525041797034
[Epoch 23, Batch 700] loss: 0.004658398916307931
[Epoch 23, Batch 800] loss: 0.0036528026250834955
[Epoch 23, Batch 900] loss: 0.005913040955609575
[Epoch 23, Batch 1000] loss: 0.002719659981997893
[Epoch 23, Batch 1100] loss: 0.005857465017280532
[Epoch 23, Batch 1200] loss: 0.007663407422517707
[Epoch 23, Batch 1300] loss: 0.005027256143071099
[Epoch 23, Batch 1400] loss: 0.004131153552416578
[Epoch 23, Batch 1500] loss: 0.007179204102849326
[Epoch 23, Batch 1600] loss: 0.010839658195166066
[Epoch 23, Batch 1700] loss: 0.004080313934111075
[Epoch 23, Batch 1800] loss: 0.002940168211678582
[Epoch 23, Batch 1900] loss: 0.0069030500461826705
[Epoch 23, Batch 2000] loss: 0.004379897928934042
[Epoch 23, Batch 2100] loss: 0.003003156422171287
[Epoch 23, Batch 2200] loss: 0.002248231408067056
[Epoch 23, Batch 2300] loss: 0.005399353883921947
[Epoch 23, Batch 2400] loss: 0.010059091152739796
[Epoch 23, Batch 2500] loss: 0.005221901562744051
[Epoch 23, Batch 2600] loss: 0.005747518689793054
[Epoch 23, Batch 2700] loss: 0.002676178105548388
[Epoch 23, Batch 2800] loss: 0.003694885321122001
[Epoch 23, Batch 2900] loss: 0.0037356961673343392
[Epoch 23, Batch 3000] loss: 0.00301061499811226
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0517
Validation Accuracy: 0.9878
Overfitting: 0.0517
[Epoch 24, Batch 100] loss: 0.004011928336090875
[Epoch 24, Batch 200] loss: 0.0029285346798098998
[Epoch 24, Batch 300] loss: 0.005598374254733187
[Epoch 24, Batch 400] loss: 0.0037258324744288986
[Epoch 24, Batch 500] loss: 0.0037370722353329455
[Epoch 24, Batch 600] loss: 0.0023303118864807003
[Epoch 24, Batch 700] loss: 0.004111233817847193
[Epoch 24, Batch 800] loss: 0.004350090734695584
[Epoch 24, Batch 900] loss: 0.0024238921372847244
[Epoch 24, Batch 1000] loss: 0.01005260958599365
[Epoch 24, Batch 1100] loss: 0.005253999125824151
[Epoch 24, Batch 1200] loss: 0.002628343903363657
[Epoch 24, Batch 1300] loss: 0.009732760625980745
[Epoch 24, Batch 1400] loss: 0.003970637928053975
[Epoch 24, Batch 1500] loss: 0.002330616387301916
[Epoch 24, Batch 1600] loss: 0.006669309619306531
[Epoch 24, Batch 1700] loss: 0.01020163975063042
[Epoch 24, Batch 1800] loss: 0.002224636474064141
[Epoch 24, Batch 1900] loss: 0.003009460215479862
[Epoch 24, Batch 2000] loss: 0.003822056876593365
[Epoch 24, Batch 2100] loss: 0.0019746571480794726
[Epoch 24, Batch 2200] loss: 0.0021740519801437585
[Epoch 24, Batch 2300] loss: 0.004080737509032133
[Epoch 24, Batch 2400] loss: 0.002105438538557962
[Epoch 24, Batch 2500] loss: 0.002371968907711448
[Epoch 24, Batch 2600] loss: 0.0039398229418764075
[Epoch 24, Batch 2700] loss: 0.0021616685226730683
[Epoch 24, Batch 2800] loss: 0.0033040936201601313
[Epoch 24, Batch 2900] loss: 0.003504722322005591
[Epoch 24, Batch 3000] loss: 0.0031755841353864867
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0568
Validation Accuracy: 0.9878
Overfitting: 0.0568
Fold 3 validation loss: 0.0568
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.3007517671585083
[Epoch 1, Batch 200] loss: 2.288702621459961
[Epoch 1, Batch 300] loss: 2.2650666546821596
[Epoch 1, Batch 400] loss: 2.198014984130859
[Epoch 1, Batch 500] loss: 1.8664162361621857
[Epoch 1, Batch 600] loss: 1.0394986388087273
[Epoch 1, Batch 700] loss: 0.6701823726296425
[Epoch 1, Batch 800] loss: 0.5282959438860416
[Epoch 1, Batch 900] loss: 0.49208395995199683
[Epoch 1, Batch 1000] loss: 0.42685552008450034
[Epoch 1, Batch 1100] loss: 0.4358790505677462
[Epoch 1, Batch 1200] loss: 0.3371523593738675
[Epoch 1, Batch 1300] loss: 0.32452110804617407
[Epoch 1, Batch 1400] loss: 0.26802108380943535
[Epoch 1, Batch 1500] loss: 0.28852421894669533
[Epoch 1, Batch 1600] loss: 0.2490950908511877
[Epoch 1, Batch 1700] loss: 0.2774941184837371
[Epoch 1, Batch 1800] loss: 0.22113257247954607
[Epoch 1, Batch 1900] loss: 0.20567462023347616
[Epoch 1, Batch 2000] loss: 0.1959862433373928
[Epoch 1, Batch 2100] loss: 0.20254727834835648
[Epoch 1, Batch 2200] loss: 0.19141893138177693
[Epoch 1, Batch 2300] loss: 0.21388648338615895
[Epoch 1, Batch 2400] loss: 0.16611840010620654
[Epoch 1, Batch 2500] loss: 0.16891129228286444
[Epoch 1, Batch 2600] loss: 0.17076389147900045
[Epoch 1, Batch 2700] loss: 0.17002465531229974
[Epoch 1, Batch 2800] loss: 0.17020466445013882
[Epoch 1, Batch 2900] loss: 0.16772968895733356
[Epoch 1, Batch 3000] loss: 0.1581619763094932
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1685
Validation Accuracy: 0.9466
Overfitting: 0.1685
Best model saved at epoch 1 with validation loss: 0.1685
[Epoch 2, Batch 100] loss: 0.148448012820445
[Epoch 2, Batch 200] loss: 0.12712787626776845
[Epoch 2, Batch 300] loss: 0.12609371775062755
[Epoch 2, Batch 400] loss: 0.11945928990840912
[Epoch 2, Batch 500] loss: 0.1409571014996618
[Epoch 2, Batch 600] loss: 0.11122780974721536
[Epoch 2, Batch 700] loss: 0.14438102721236645
[Epoch 2, Batch 800] loss: 0.1155220024427399
[Epoch 2, Batch 900] loss: 0.09908188509056344
[Epoch 2, Batch 1000] loss: 0.11446707168826833
[Epoch 2, Batch 1100] loss: 0.11296771488152445
[Epoch 2, Batch 1200] loss: 0.12378344933036715
[Epoch 2, Batch 1300] loss: 0.1106907371757552
[Epoch 2, Batch 1400] loss: 0.10753056154120713
[Epoch 2, Batch 1500] loss: 0.09995928545715288
[Epoch 2, Batch 1600] loss: 0.09167631328338757
[Epoch 2, Batch 1700] loss: 0.11374445664929227
[Epoch 2, Batch 1800] loss: 0.11027582264272497
[Epoch 2, Batch 1900] loss: 0.10038158384617418
[Epoch 2, Batch 2000] loss: 0.12298845005454495
[Epoch 2, Batch 2100] loss: 0.09116679725935682
[Epoch 2, Batch 2200] loss: 0.1038272196543403
[Epoch 2, Batch 2300] loss: 0.12773734748130663
[Epoch 2, Batch 2400] loss: 0.10544605969917029
[Epoch 2, Batch 2500] loss: 0.11714418529300019
[Epoch 2, Batch 2600] loss: 0.11925865109078586
[Epoch 2, Batch 2700] loss: 0.11341071911156178
[Epoch 2, Batch 2800] loss: 0.12182080855825916
[Epoch 2, Batch 2900] loss: 0.09036420804914087
[Epoch 2, Batch 3000] loss: 0.10486539239645935
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0983
Validation Accuracy: 0.9704
Overfitting: 0.0983
Best model saved at epoch 2 with validation loss: 0.0983
[Epoch 3, Batch 100] loss: 0.059939709634054456
[Epoch 3, Batch 200] loss: 0.0898011887667235
[Epoch 3, Batch 300] loss: 0.0797076740814373
[Epoch 3, Batch 400] loss: 0.10152025279356167
[Epoch 3, Batch 500] loss: 0.10397773527540266
[Epoch 3, Batch 600] loss: 0.08187493807054125
[Epoch 3, Batch 700] loss: 0.07263460247777402
[Epoch 3, Batch 800] loss: 0.09257866219850257
[Epoch 3, Batch 900] loss: 0.08700292944675311
[Epoch 3, Batch 1000] loss: 0.09367139249690809
[Epoch 3, Batch 1100] loss: 0.08473282040562481
[Epoch 3, Batch 1200] loss: 0.09876727927010506
[Epoch 3, Batch 1300] loss: 0.06719186288537457
[Epoch 3, Batch 1400] loss: 0.0770461578364484
[Epoch 3, Batch 1500] loss: 0.09502105437917635
[Epoch 3, Batch 1600] loss: 0.07446781567879952
[Epoch 3, Batch 1700] loss: 0.061198168996488674
[Epoch 3, Batch 1800] loss: 0.06181801745784469
[Epoch 3, Batch 1900] loss: 0.07483520147856325
[Epoch 3, Batch 2000] loss: 0.0654104714677669
[Epoch 3, Batch 2100] loss: 0.0880795069411397
[Epoch 3, Batch 2200] loss: 0.08777903610432986
[Epoch 3, Batch 2300] loss: 0.09123620044905692
[Epoch 3, Batch 2400] loss: 0.09322334174416028
[Epoch 3, Batch 2500] loss: 0.07569125068373977
[Epoch 3, Batch 2600] loss: 0.08704150253208354
[Epoch 3, Batch 2700] loss: 0.0657525121094659
[Epoch 3, Batch 2800] loss: 0.06983484620053787
[Epoch 3, Batch 2900] loss: 0.05937925780541264
[Epoch 3, Batch 3000] loss: 0.08614211459644139
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0738
Validation Accuracy: 0.9762
Overfitting: 0.0738
Best model saved at epoch 3 with validation loss: 0.0738
[Epoch 4, Batch 100] loss: 0.07412724453024566
[Epoch 4, Batch 200] loss: 0.062487108352361244
[Epoch 4, Batch 300] loss: 0.08642570931406227
[Epoch 4, Batch 400] loss: 0.05981646730331704
[Epoch 4, Batch 500] loss: 0.05276717917295173
[Epoch 4, Batch 600] loss: 0.07324929939233699
[Epoch 4, Batch 700] loss: 0.062354852650896644
[Epoch 4, Batch 800] loss: 0.06711921360576525
[Epoch 4, Batch 900] loss: 0.05418135167681612
[Epoch 4, Batch 1000] loss: 0.04920557301491499
[Epoch 4, Batch 1100] loss: 0.07727853007963859
[Epoch 4, Batch 1200] loss: 0.0700228741770843
[Epoch 4, Batch 1300] loss: 0.055416290605207905
[Epoch 4, Batch 1400] loss: 0.05560509457369335
[Epoch 4, Batch 1500] loss: 0.06773190538777271
[Epoch 4, Batch 1600] loss: 0.07604662288213149
[Epoch 4, Batch 1700] loss: 0.07978829181636683
[Epoch 4, Batch 1800] loss: 0.056148406144639014
[Epoch 4, Batch 1900] loss: 0.058792643794440665
[Epoch 4, Batch 2000] loss: 0.06096474839287112
[Epoch 4, Batch 2100] loss: 0.0622624225798063
[Epoch 4, Batch 2200] loss: 0.07794221449643374
[Epoch 4, Batch 2300] loss: 0.05492276843229774
[Epoch 4, Batch 2400] loss: 0.047064880075631664
[Epoch 4, Batch 2500] loss: 0.0583930689987028
[Epoch 4, Batch 2600] loss: 0.060684282820438966
[Epoch 4, Batch 2700] loss: 0.08729601615690626
[Epoch 4, Batch 2800] loss: 0.05179650152509566
[Epoch 4, Batch 2900] loss: 0.06764825008809566
[Epoch 4, Batch 3000] loss: 0.0620738862970029
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0690
Validation Accuracy: 0.9790
Overfitting: 0.0690
Best model saved at epoch 4 with validation loss: 0.0690
[Epoch 5, Batch 100] loss: 0.04413854988408275
[Epoch 5, Batch 200] loss: 0.05435474273690488
[Epoch 5, Batch 300] loss: 0.04660801822436042
[Epoch 5, Batch 400] loss: 0.04012114499520976
[Epoch 5, Batch 500] loss: 0.07208128458922147
[Epoch 5, Batch 600] loss: 0.06052391720528249
[Epoch 5, Batch 700] loss: 0.05269169691891875
[Epoch 5, Batch 800] loss: 0.04160350850987015
[Epoch 5, Batch 900] loss: 0.04932554790371796
[Epoch 5, Batch 1000] loss: 0.044452386166667565
[Epoch 5, Batch 1100] loss: 0.07247689038194949
[Epoch 5, Batch 1200] loss: 0.07380986960124573
[Epoch 5, Batch 1300] loss: 0.05297896682983264
[Epoch 5, Batch 1400] loss: 0.05463847225997597
[Epoch 5, Batch 1500] loss: 0.061177326696633824
[Epoch 5, Batch 1600] loss: 0.046607889579609034
[Epoch 5, Batch 1700] loss: 0.03638392103894148
[Epoch 5, Batch 1800] loss: 0.057441018736717524
[Epoch 5, Batch 1900] loss: 0.053046831361134535
[Epoch 5, Batch 2000] loss: 0.053176780798239634
[Epoch 5, Batch 2100] loss: 0.056165480986237526
[Epoch 5, Batch 2200] loss: 0.04532016400858993
[Epoch 5, Batch 2300] loss: 0.060036263136280466
[Epoch 5, Batch 2400] loss: 0.06494627433770801
[Epoch 5, Batch 2500] loss: 0.051944291584659366
[Epoch 5, Batch 2600] loss: 0.0550099935795879
[Epoch 5, Batch 2700] loss: 0.04830476635019295
[Epoch 5, Batch 2800] loss: 0.0639486885361839
[Epoch 5, Batch 2900] loss: 0.04666105576965492
[Epoch 5, Batch 3000] loss: 0.07111813081020955
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0610
Validation Accuracy: 0.9818
Overfitting: 0.0610
Best model saved at epoch 5 with validation loss: 0.0610
[Epoch 6, Batch 100] loss: 0.04164966809970792
[Epoch 6, Batch 200] loss: 0.04626249771681614
[Epoch 6, Batch 300] loss: 0.044578288020566105
[Epoch 6, Batch 400] loss: 0.04203423219412798
[Epoch 6, Batch 500] loss: 0.0569218326540431
[Epoch 6, Batch 600] loss: 0.03579972506166087
[Epoch 6, Batch 700] loss: 0.0466093029465992
[Epoch 6, Batch 800] loss: 0.04663230675010709
[Epoch 6, Batch 900] loss: 0.045316782667650844
[Epoch 6, Batch 1000] loss: 0.04926371810142882
[Epoch 6, Batch 1100] loss: 0.0394429463238339
[Epoch 6, Batch 1200] loss: 0.04957961518870434
[Epoch 6, Batch 1300] loss: 0.03670034827504423
[Epoch 6, Batch 1400] loss: 0.03571335829474265
[Epoch 6, Batch 1500] loss: 0.03779949312942335
[Epoch 6, Batch 1600] loss: 0.052528880857280455
[Epoch 6, Batch 1700] loss: 0.061850631203269585
[Epoch 6, Batch 1800] loss: 0.06318239346001064
[Epoch 6, Batch 1900] loss: 0.06771166523511056
[Epoch 6, Batch 2000] loss: 0.039646250541845805
[Epoch 6, Batch 2100] loss: 0.05174641050572973
[Epoch 6, Batch 2200] loss: 0.056145000191172585
[Epoch 6, Batch 2300] loss: 0.05101857450557873
[Epoch 6, Batch 2400] loss: 0.04172868551278953
[Epoch 6, Batch 2500] loss: 0.04077478381557739
[Epoch 6, Batch 2600] loss: 0.032534535089507696
[Epoch 6, Batch 2700] loss: 0.057773882801120634
[Epoch 6, Batch 2800] loss: 0.05696262890269281
[Epoch 6, Batch 2900] loss: 0.038962990887230264
[Epoch 6, Batch 3000] loss: 0.03157555571466219
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0595
Validation Accuracy: 0.9812
Overfitting: 0.0595
Best model saved at epoch 6 with validation loss: 0.0595
[Epoch 7, Batch 100] loss: 0.04436472827597754
[Epoch 7, Batch 200] loss: 0.04424371081928257
[Epoch 7, Batch 300] loss: 0.04437737454107264
[Epoch 7, Batch 400] loss: 0.056860625370172786
[Epoch 7, Batch 500] loss: 0.03924352598507539
[Epoch 7, Batch 600] loss: 0.0410050785675412
[Epoch 7, Batch 700] loss: 0.03609297644579783
[Epoch 7, Batch 800] loss: 0.0390490963938646
[Epoch 7, Batch 900] loss: 0.04974648891482502
[Epoch 7, Batch 1000] loss: 0.04343815463973442
[Epoch 7, Batch 1100] loss: 0.032169416526594434
[Epoch 7, Batch 1200] loss: 0.035548726363340395
[Epoch 7, Batch 1300] loss: 0.04862454244139371
[Epoch 7, Batch 1400] loss: 0.05130291347566526
[Epoch 7, Batch 1500] loss: 0.022360921359068017
[Epoch 7, Batch 1600] loss: 0.06526501936648856
[Epoch 7, Batch 1700] loss: 0.04228470334113808
[Epoch 7, Batch 1800] loss: 0.031991073155077175
[Epoch 7, Batch 1900] loss: 0.0501288353317068
[Epoch 7, Batch 2000] loss: 0.03858119678312505
[Epoch 7, Batch 2100] loss: 0.0382622537795396
[Epoch 7, Batch 2200] loss: 0.04281285117322113
[Epoch 7, Batch 2300] loss: 0.05337340243917424
[Epoch 7, Batch 2400] loss: 0.024853623795788735
[Epoch 7, Batch 2500] loss: 0.031219152128323914
[Epoch 7, Batch 2600] loss: 0.037354354913695716
[Epoch 7, Batch 2700] loss: 0.04734407338153687
[Epoch 7, Batch 2800] loss: 0.05227228898613248
[Epoch 7, Batch 2900] loss: 0.04301029570036917
[Epoch 7, Batch 3000] loss: 0.022819798797718248
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9840
Overfitting: 0.0514
Best model saved at epoch 7 with validation loss: 0.0514
[Epoch 8, Batch 100] loss: 0.03802126179129118
[Epoch 8, Batch 200] loss: 0.02649602328390756
[Epoch 8, Batch 300] loss: 0.016672206700313837
[Epoch 8, Batch 400] loss: 0.0288030797567626
[Epoch 8, Batch 500] loss: 0.03104047759086825
[Epoch 8, Batch 600] loss: 0.0368908458018268
[Epoch 8, Batch 700] loss: 0.04900072024916881
[Epoch 8, Batch 800] loss: 0.033412964181479765
[Epoch 8, Batch 900] loss: 0.041155575334705645
[Epoch 8, Batch 1000] loss: 0.039336683665897
[Epoch 8, Batch 1100] loss: 0.043609694593615134
[Epoch 8, Batch 1200] loss: 0.05845918874416384
[Epoch 8, Batch 1300] loss: 0.044531088675430514
[Epoch 8, Batch 1400] loss: 0.033220908506773415
[Epoch 8, Batch 1500] loss: 0.034929122163448484
[Epoch 8, Batch 1600] loss: 0.02780659538897453
[Epoch 8, Batch 1700] loss: 0.03854069998313207
[Epoch 8, Batch 1800] loss: 0.041847176164010305
[Epoch 8, Batch 1900] loss: 0.0438934051853721
[Epoch 8, Batch 2000] loss: 0.04144943519379012
[Epoch 8, Batch 2100] loss: 0.04048339445886086
[Epoch 8, Batch 2200] loss: 0.03250764482865634
[Epoch 8, Batch 2300] loss: 0.0379205591119171
[Epoch 8, Batch 2400] loss: 0.018436718564043986
[Epoch 8, Batch 2500] loss: 0.03333440503127349
[Epoch 8, Batch 2600] loss: 0.027316086790669943
[Epoch 8, Batch 2700] loss: 0.02891633432722301
[Epoch 8, Batch 2800] loss: 0.03403707371937344
[Epoch 8, Batch 2900] loss: 0.0355926515563624
[Epoch 8, Batch 3000] loss: 0.050296154801762895
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9849
Overfitting: 0.0508
Best model saved at epoch 8 with validation loss: 0.0508
[Epoch 9, Batch 100] loss: 0.026779187001811807
[Epoch 9, Batch 200] loss: 0.03749385130562587
[Epoch 9, Batch 300] loss: 0.029144348242261912
[Epoch 9, Batch 400] loss: 0.03377396038573352
[Epoch 9, Batch 500] loss: 0.03361358753434615
[Epoch 9, Batch 600] loss: 0.023736402412214374
[Epoch 9, Batch 700] loss: 0.04348725835676305
[Epoch 9, Batch 800] loss: 0.04460244550831703
[Epoch 9, Batch 900] loss: 0.025513402122669504
[Epoch 9, Batch 1000] loss: 0.02349853965573857
[Epoch 9, Batch 1100] loss: 0.03013967198879982
[Epoch 9, Batch 1200] loss: 0.021983394367998697
[Epoch 9, Batch 1300] loss: 0.025395207135370582
[Epoch 9, Batch 1400] loss: 0.032338821507291865
[Epoch 9, Batch 1500] loss: 0.029820061674618047
[Epoch 9, Batch 1600] loss: 0.039179554795482546
[Epoch 9, Batch 1700] loss: 0.02758290325247799
[Epoch 9, Batch 1800] loss: 0.03561665645538596
[Epoch 9, Batch 1900] loss: 0.04299022936516849
[Epoch 9, Batch 2000] loss: 0.023441128954873422
[Epoch 9, Batch 2100] loss: 0.02428469128004508
[Epoch 9, Batch 2200] loss: 0.019974056010978528
[Epoch 9, Batch 2300] loss: 0.024371456881053747
[Epoch 9, Batch 2400] loss: 0.030689709724101705
[Epoch 9, Batch 2500] loss: 0.039829515308665575
[Epoch 9, Batch 2600] loss: 0.03493263994278095
[Epoch 9, Batch 2700] loss: 0.032723742186499295
[Epoch 9, Batch 2800] loss: 0.03337860488827573
[Epoch 9, Batch 2900] loss: 0.03067244797523017
[Epoch 9, Batch 3000] loss: 0.02216706049803179
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9857
Overfitting: 0.0468
Best model saved at epoch 9 with validation loss: 0.0468
[Epoch 10, Batch 100] loss: 0.03436219830604387
[Epoch 10, Batch 200] loss: 0.014650256534223445
[Epoch 10, Batch 300] loss: 0.023415955419841337
[Epoch 10, Batch 400] loss: 0.03145964212199033
[Epoch 10, Batch 500] loss: 0.030177733439486473
[Epoch 10, Batch 600] loss: 0.03235984579892829
[Epoch 10, Batch 700] loss: 0.019895781786253793
[Epoch 10, Batch 800] loss: 0.02148650922208617
[Epoch 10, Batch 900] loss: 0.028788500173996
[Epoch 10, Batch 1000] loss: 0.03585260817031667
[Epoch 10, Batch 1100] loss: 0.02868031699945277
[Epoch 10, Batch 1200] loss: 0.0154454952823653
[Epoch 10, Batch 1300] loss: 0.02783363830385497
[Epoch 10, Batch 1400] loss: 0.023038169283827303
[Epoch 10, Batch 1500] loss: 0.031089067092325423
[Epoch 10, Batch 1600] loss: 0.02445063093677163
[Epoch 10, Batch 1700] loss: 0.03099172492969956
[Epoch 10, Batch 1800] loss: 0.049173869723599634
[Epoch 10, Batch 1900] loss: 0.01932508282829076
[Epoch 10, Batch 2000] loss: 0.03944254351925338
[Epoch 10, Batch 2100] loss: 0.02353553288645344
[Epoch 10, Batch 2200] loss: 0.02799183694580279
[Epoch 10, Batch 2300] loss: 0.015848386909492546
[Epoch 10, Batch 2400] loss: 0.041401848645764405
[Epoch 10, Batch 2500] loss: 0.038925250991214855
[Epoch 10, Batch 2600] loss: 0.022083861862083724
[Epoch 10, Batch 2700] loss: 0.029599666165740928
[Epoch 10, Batch 2800] loss: 0.019113392789440697
[Epoch 10, Batch 2900] loss: 0.02971533561916658
[Epoch 10, Batch 3000] loss: 0.030354057604563424
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0443
Validation Accuracy: 0.9861
Overfitting: 0.0443
Best model saved at epoch 10 with validation loss: 0.0443
[Epoch 11, Batch 100] loss: 0.027850851392868206
[Epoch 11, Batch 200] loss: 0.027434481285163202
[Epoch 11, Batch 300] loss: 0.0350284787005512
[Epoch 11, Batch 400] loss: 0.02940581059658143
[Epoch 11, Batch 500] loss: 0.02661106599633058
[Epoch 11, Batch 600] loss: 0.03455336128914496
[Epoch 11, Batch 700] loss: 0.03505689590165275
[Epoch 11, Batch 800] loss: 0.029079872335714754
[Epoch 11, Batch 900] loss: 0.013436985701482627
[Epoch 11, Batch 1000] loss: 0.01982350744496216
[Epoch 11, Batch 1100] loss: 0.02294818376765761
[Epoch 11, Batch 1200] loss: 0.025282739829490312
[Epoch 11, Batch 1300] loss: 0.027368719251098808
[Epoch 11, Batch 1400] loss: 0.028949072609466383
[Epoch 11, Batch 1500] loss: 0.025595569970610087
[Epoch 11, Batch 1600] loss: 0.016072737053582385
[Epoch 11, Batch 1700] loss: 0.03316697356705845
[Epoch 11, Batch 1800] loss: 0.027127941881481092
[Epoch 11, Batch 1900] loss: 0.012365789244067855
[Epoch 11, Batch 2000] loss: 0.024583006455359283
[Epoch 11, Batch 2100] loss: 0.028780104032266537
[Epoch 11, Batch 2200] loss: 0.03632993464852916
[Epoch 11, Batch 2300] loss: 0.025085919915509295
[Epoch 11, Batch 2400] loss: 0.026134878891461995
[Epoch 11, Batch 2500] loss: 0.018091735377965962
[Epoch 11, Batch 2600] loss: 0.02684378303001722
[Epoch 11, Batch 2700] loss: 0.021034358035576586
[Epoch 11, Batch 2800] loss: 0.03343303936348093
[Epoch 11, Batch 2900] loss: 0.011611003680700378
[Epoch 11, Batch 3000] loss: 0.020719238391357066
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9862
Overfitting: 0.0475
[Epoch 12, Batch 100] loss: 0.022945165706187255
[Epoch 12, Batch 200] loss: 0.014471318567448179
[Epoch 12, Batch 300] loss: 0.018819542268502118
[Epoch 12, Batch 400] loss: 0.012349504419762524
[Epoch 12, Batch 500] loss: 0.022737319855114037
[Epoch 12, Batch 600] loss: 0.03243260386418115
[Epoch 12, Batch 700] loss: 0.012865984448362724
[Epoch 12, Batch 800] loss: 0.01609898293223523
[Epoch 12, Batch 900] loss: 0.018669297090673352
[Epoch 12, Batch 1000] loss: 0.028878226198939955
[Epoch 12, Batch 1100] loss: 0.019780778546701187
[Epoch 12, Batch 1200] loss: 0.02202819225843996
[Epoch 12, Batch 1300] loss: 0.028414118214568587
[Epoch 12, Batch 1400] loss: 0.03390535496422672
[Epoch 12, Batch 1500] loss: 0.023793571103451542
[Epoch 12, Batch 1600] loss: 0.024234127242380055
[Epoch 12, Batch 1700] loss: 0.02449166972459352
[Epoch 12, Batch 1800] loss: 0.02229254107514862
[Epoch 12, Batch 1900] loss: 0.019406620571535315
[Epoch 12, Batch 2000] loss: 0.0305985969514586
[Epoch 12, Batch 2100] loss: 0.028389923066279153
[Epoch 12, Batch 2200] loss: 0.02356179310107109
[Epoch 12, Batch 2300] loss: 0.026408550761125298
[Epoch 12, Batch 2400] loss: 0.0220103429035953
[Epoch 12, Batch 2500] loss: 0.0414504048449453
[Epoch 12, Batch 2600] loss: 0.019552791929527302
[Epoch 12, Batch 2700] loss: 0.029646659395511962
[Epoch 12, Batch 2800] loss: 0.019000300781044643
[Epoch 12, Batch 2900] loss: 0.023530991297811853
[Epoch 12, Batch 3000] loss: 0.014361289253574796
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9868
Overfitting: 0.0422
Best model saved at epoch 12 with validation loss: 0.0422
[Epoch 13, Batch 100] loss: 0.017176538672083554
[Epoch 13, Batch 200] loss: 0.021933548107544994
[Epoch 13, Batch 300] loss: 0.010894680856563355
[Epoch 13, Batch 400] loss: 0.023230971577868333
[Epoch 13, Batch 500] loss: 0.014589530490566176
[Epoch 13, Batch 600] loss: 0.02042245507669577
[Epoch 13, Batch 700] loss: 0.015979816685394325
[Epoch 13, Batch 800] loss: 0.022351460665886405
[Epoch 13, Batch 900] loss: 0.013073224948711867
[Epoch 13, Batch 1000] loss: 0.02453926703245088
[Epoch 13, Batch 1100] loss: 0.014331612501373457
[Epoch 13, Batch 1200] loss: 0.016760232643428026
[Epoch 13, Batch 1300] loss: 0.028881109049434597
[Epoch 13, Batch 1400] loss: 0.023820523463236896
[Epoch 13, Batch 1500] loss: 0.02385264254447975
[Epoch 13, Batch 1600] loss: 0.023708075833455952
[Epoch 13, Batch 1700] loss: 0.020662186177360126
[Epoch 13, Batch 1800] loss: 0.018324465356272412
[Epoch 13, Batch 1900] loss: 0.0238718258555582
[Epoch 13, Batch 2000] loss: 0.02689858422807447
[Epoch 13, Batch 2100] loss: 0.0174208207079937
[Epoch 13, Batch 2200] loss: 0.01861414007616986
[Epoch 13, Batch 2300] loss: 0.0266544616115425
[Epoch 13, Batch 2400] loss: 0.01835308329504187
[Epoch 13, Batch 2500] loss: 0.013241344398829824
[Epoch 13, Batch 2600] loss: 0.034652826096353236
[Epoch 13, Batch 2700] loss: 0.013858875703117519
[Epoch 13, Batch 2800] loss: 0.02792616466715117
[Epoch 13, Batch 2900] loss: 0.015910628612182336
[Epoch 13, Batch 3000] loss: 0.016189777520394272
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0432
Validation Accuracy: 0.9869
Overfitting: 0.0432
[Epoch 14, Batch 100] loss: 0.012885743974075013
[Epoch 14, Batch 200] loss: 0.010410928548899391
[Epoch 14, Batch 300] loss: 0.018703097159159368
[Epoch 14, Batch 400] loss: 0.00840692515936098
[Epoch 14, Batch 500] loss: 0.011601503577803669
[Epoch 14, Batch 600] loss: 0.014119266802044877
[Epoch 14, Batch 700] loss: 0.01446194852111148
[Epoch 14, Batch 800] loss: 0.014370911034729943
[Epoch 14, Batch 900] loss: 0.008874475818010978
[Epoch 14, Batch 1000] loss: 0.022992554440788807
[Epoch 14, Batch 1100] loss: 0.03276976429244314
[Epoch 14, Batch 1200] loss: 0.020356496810272802
[Epoch 14, Batch 1300] loss: 0.03146887545091886
[Epoch 14, Batch 1400] loss: 0.01406384850946779
[Epoch 14, Batch 1500] loss: 0.02897101068019765
[Epoch 14, Batch 1600] loss: 0.020209956846210842
[Epoch 14, Batch 1700] loss: 0.011721409979654708
[Epoch 14, Batch 1800] loss: 0.024029867946701415
[Epoch 14, Batch 1900] loss: 0.020137760281868394
[Epoch 14, Batch 2000] loss: 0.02565783826428742
[Epoch 14, Batch 2100] loss: 0.02374511775720748
[Epoch 14, Batch 2200] loss: 0.015158625248113821
[Epoch 14, Batch 2300] loss: 0.018537845574101083
[Epoch 14, Batch 2400] loss: 0.024706566655149798
[Epoch 14, Batch 2500] loss: 0.020888615148542157
[Epoch 14, Batch 2600] loss: 0.024924454627580417
[Epoch 14, Batch 2700] loss: 0.021563108802547505
[Epoch 14, Batch 2800] loss: 0.012986813635561702
[Epoch 14, Batch 2900] loss: 0.014815922718589718
[Epoch 14, Batch 3000] loss: 0.011519177787031367
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9868
Overfitting: 0.0447
[Epoch 15, Batch 100] loss: 0.013947017123846307
[Epoch 15, Batch 200] loss: 0.014695850428934136
[Epoch 15, Batch 300] loss: 0.012705263342957096
[Epoch 15, Batch 400] loss: 0.009431662043571123
[Epoch 15, Batch 500] loss: 0.011503964634393925
[Epoch 15, Batch 600] loss: 0.01569210044297506
[Epoch 15, Batch 700] loss: 0.01566819909082369
[Epoch 15, Batch 800] loss: 0.010812688473724847
[Epoch 15, Batch 900] loss: 0.018762471843047024
[Epoch 15, Batch 1000] loss: 0.022458014095409453
[Epoch 15, Batch 1100] loss: 0.018171067121311352
[Epoch 15, Batch 1200] loss: 0.015054627370209345
[Epoch 15, Batch 1300] loss: 0.012984702671274136
[Epoch 15, Batch 1400] loss: 0.015801289596447533
[Epoch 15, Batch 1500] loss: 0.016780911387650123
[Epoch 15, Batch 1600] loss: 0.013380685324700608
[Epoch 15, Batch 1700] loss: 0.02427173969179421
[Epoch 15, Batch 1800] loss: 0.02863682996123316
[Epoch 15, Batch 1900] loss: 0.013935692747472785
[Epoch 15, Batch 2000] loss: 0.01723667407200992
[Epoch 15, Batch 2100] loss: 0.007776609774664394
[Epoch 15, Batch 2200] loss: 0.00977818532443962
[Epoch 15, Batch 2300] loss: 0.018258705509333596
[Epoch 15, Batch 2400] loss: 0.011698595444954663
[Epoch 15, Batch 2500] loss: 0.021072917262790723
[Epoch 15, Batch 2600] loss: 0.01255433416525193
[Epoch 15, Batch 2700] loss: 0.024731059751029533
[Epoch 15, Batch 2800] loss: 0.018862163474041155
[Epoch 15, Batch 2900] loss: 0.025972394097170764
[Epoch 15, Batch 3000] loss: 0.009113505373134103
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0418
Validation Accuracy: 0.9868
Overfitting: 0.0418
Best model saved at epoch 15 with validation loss: 0.0418
[Epoch 16, Batch 100] loss: 0.015154625861268868
[Epoch 16, Batch 200] loss: 0.008522754299301596
[Epoch 16, Batch 300] loss: 0.01642410183099855
[Epoch 16, Batch 400] loss: 0.017543069906896563
[Epoch 16, Batch 500] loss: 0.011981736651832761
[Epoch 16, Batch 600] loss: 0.008512254172137546
[Epoch 16, Batch 700] loss: 0.01337084407347902
[Epoch 16, Batch 800] loss: 0.012049254275093518
[Epoch 16, Batch 900] loss: 0.01513868638099666
[Epoch 16, Batch 1000] loss: 0.0090188647179707
[Epoch 16, Batch 1100] loss: 0.006156842055866037
[Epoch 16, Batch 1200] loss: 0.003977626338510163
[Epoch 16, Batch 1300] loss: 0.016313934577583497
[Epoch 16, Batch 1400] loss: 0.011425211997502628
[Epoch 16, Batch 1500] loss: 0.015563923100608008
[Epoch 16, Batch 1600] loss: 0.01841894131302979
[Epoch 16, Batch 1700] loss: 0.018313729476003574
[Epoch 16, Batch 1800] loss: 0.01792086243453923
[Epoch 16, Batch 1900] loss: 0.010846490587118751
[Epoch 16, Batch 2000] loss: 0.018572900032868347
[Epoch 16, Batch 2100] loss: 0.016518495197597075
[Epoch 16, Batch 2200] loss: 0.017681690641593376
[Epoch 16, Batch 2300] loss: 0.017870304632215266
[Epoch 16, Batch 2400] loss: 0.011941400020878063
[Epoch 16, Batch 2500] loss: 0.01885689571407056
[Epoch 16, Batch 2600] loss: 0.011857209466215863
[Epoch 16, Batch 2700] loss: 0.012904204995920735
[Epoch 16, Batch 2800] loss: 0.025776593398331896
[Epoch 16, Batch 2900] loss: 0.013091067808654771
[Epoch 16, Batch 3000] loss: 0.007664618234196041
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9861
Overfitting: 0.0501
[Epoch 17, Batch 100] loss: 0.013510247992635414
[Epoch 17, Batch 200] loss: 0.007560944170982111
[Epoch 17, Batch 300] loss: 0.006762713506241198
[Epoch 17, Batch 400] loss: 0.007563390581908607
[Epoch 17, Batch 500] loss: 0.011647648192699762
[Epoch 17, Batch 600] loss: 0.010264944406640098
[Epoch 17, Batch 700] loss: 0.00764364619852131
[Epoch 17, Batch 800] loss: 0.010053583756334774
[Epoch 17, Batch 900] loss: 0.005815636813940728
[Epoch 17, Batch 1000] loss: 0.010705530319551144
[Epoch 17, Batch 1100] loss: 0.018437251460254628
[Epoch 17, Batch 1200] loss: 0.012818208084045182
[Epoch 17, Batch 1300] loss: 0.024333564512007796
[Epoch 17, Batch 1400] loss: 0.016539023423965772
[Epoch 17, Batch 1500] loss: 0.012285240793880802
[Epoch 17, Batch 1600] loss: 0.013006462362127422
[Epoch 17, Batch 1700] loss: 0.004660577611739427
[Epoch 17, Batch 1800] loss: 0.008632975936943694
[Epoch 17, Batch 1900] loss: 0.018966849821299547
[Epoch 17, Batch 2000] loss: 0.019346030303963743
[Epoch 17, Batch 2100] loss: 0.007102674704228775
[Epoch 17, Batch 2200] loss: 0.009199699631885778
[Epoch 17, Batch 2300] loss: 0.019407291286527198
[Epoch 17, Batch 2400] loss: 0.014054838419624502
[Epoch 17, Batch 2500] loss: 0.021092420277482232
[Epoch 17, Batch 2600] loss: 0.021295757430898447
[Epoch 17, Batch 2700] loss: 0.013859967708795011
[Epoch 17, Batch 2800] loss: 0.011085756405891515
[Epoch 17, Batch 2900] loss: 0.014082631210008002
[Epoch 17, Batch 3000] loss: 0.011446541336126756
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9875
Overfitting: 0.0481
[Epoch 18, Batch 100] loss: 0.008133176720971278
[Epoch 18, Batch 200] loss: 0.009547215668435456
[Epoch 18, Batch 300] loss: 0.0070626160129722846
[Epoch 18, Batch 400] loss: 0.006111697810238184
[Epoch 18, Batch 500] loss: 0.011514403411642888
[Epoch 18, Batch 600] loss: 0.01390717247964858
[Epoch 18, Batch 700] loss: 0.009507002040033968
[Epoch 18, Batch 800] loss: 0.012066227523555427
[Epoch 18, Batch 900] loss: 0.011946313808948616
[Epoch 18, Batch 1000] loss: 0.00985808233892385
[Epoch 18, Batch 1100] loss: 0.009856247077577792
[Epoch 18, Batch 1200] loss: 0.01088880798059563
[Epoch 18, Batch 1300] loss: 0.010923728702109656
[Epoch 18, Batch 1400] loss: 0.011093070559654734
[Epoch 18, Batch 1500] loss: 0.016716691015481046
[Epoch 18, Batch 1600] loss: 0.015783964999172895
[Epoch 18, Batch 1700] loss: 0.013026320048093112
[Epoch 18, Batch 1800] loss: 0.007375072363051913
[Epoch 18, Batch 1900] loss: 0.01646057322620891
[Epoch 18, Batch 2000] loss: 0.005944410047814017
[Epoch 18, Batch 2100] loss: 0.009329376484838576
[Epoch 18, Batch 2200] loss: 0.013133508744585925
[Epoch 18, Batch 2300] loss: 0.011019651932765556
[Epoch 18, Batch 2400] loss: 0.010525256956843804
[Epoch 18, Batch 2500] loss: 0.01088753770747644
[Epoch 18, Batch 2600] loss: 0.011997438788985165
[Epoch 18, Batch 2700] loss: 0.00883313783110907
[Epoch 18, Batch 2800] loss: 0.009309870211172893
[Epoch 18, Batch 2900] loss: 0.024052797845506575
[Epoch 18, Batch 3000] loss: 0.011230901699855167
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9847
Overfitting: 0.0528
[Epoch 19, Batch 100] loss: 0.013241467059015122
[Epoch 19, Batch 200] loss: 0.008147593860676351
[Epoch 19, Batch 300] loss: 0.00986372211537855
[Epoch 19, Batch 400] loss: 0.012995376067997312
[Epoch 19, Batch 500] loss: 0.01357049752445164
[Epoch 19, Batch 600] loss: 0.005601148943078442
[Epoch 19, Batch 700] loss: 0.0099187915594257
[Epoch 19, Batch 800] loss: 0.007568904209744005
[Epoch 19, Batch 900] loss: 0.009273845922898545
[Epoch 19, Batch 1000] loss: 0.010764273396819134
[Epoch 19, Batch 1100] loss: 0.008400018351962898
[Epoch 19, Batch 1200] loss: 0.014660876717985048
[Epoch 19, Batch 1300] loss: 0.012677795448780671
[Epoch 19, Batch 1400] loss: 0.007150652848422396
[Epoch 19, Batch 1500] loss: 0.011293127438975717
[Epoch 19, Batch 1600] loss: 0.011668984771222312
[Epoch 19, Batch 1700] loss: 0.020987866325158394
[Epoch 19, Batch 1800] loss: 0.004175410508341883
[Epoch 19, Batch 1900] loss: 0.004494271782928081
[Epoch 19, Batch 2000] loss: 0.0073185258598823565
[Epoch 19, Batch 2100] loss: 0.011862385898039065
[Epoch 19, Batch 2200] loss: 0.014396003955130254
[Epoch 19, Batch 2300] loss: 0.008267916262075231
[Epoch 19, Batch 2400] loss: 0.0073642106193278776
[Epoch 19, Batch 2500] loss: 0.010002694690456337
[Epoch 19, Batch 2600] loss: 0.007805529036600092
[Epoch 19, Batch 2700] loss: 0.012437798287346596
[Epoch 19, Batch 2800] loss: 0.00811134031024949
[Epoch 19, Batch 2900] loss: 0.013234710024935339
[Epoch 19, Batch 3000] loss: 0.01461327732452446
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9861
Overfitting: 0.0551
[Epoch 20, Batch 100] loss: 0.013897851028727927
[Epoch 20, Batch 200] loss: 0.004250556510314709
[Epoch 20, Batch 300] loss: 0.006389315337717107
[Epoch 20, Batch 400] loss: 0.0050995690534227835
[Epoch 20, Batch 500] loss: 0.005909362178033462
[Epoch 20, Batch 600] loss: 0.004516620615654574
[Epoch 20, Batch 700] loss: 0.0071874320966162485
[Epoch 20, Batch 800] loss: 0.007445089160792122
[Epoch 20, Batch 900] loss: 0.0064387595379048436
[Epoch 20, Batch 1000] loss: 0.006637264170939261
[Epoch 20, Batch 1100] loss: 0.006393030254819223
[Epoch 20, Batch 1200] loss: 0.006506015061963808
[Epoch 20, Batch 1300] loss: 0.005783142437101105
[Epoch 20, Batch 1400] loss: 0.012094123427514205
[Epoch 20, Batch 1500] loss: 0.004814988582484148
[Epoch 20, Batch 1600] loss: 0.007198659443333782
[Epoch 20, Batch 1700] loss: 0.009712985079308964
[Epoch 20, Batch 1800] loss: 0.011839478508063621
[Epoch 20, Batch 1900] loss: 0.010868986566283639
[Epoch 20, Batch 2000] loss: 0.016176031144697164
[Epoch 20, Batch 2100] loss: 0.010003159335469717
[Epoch 20, Batch 2200] loss: 0.01247985588283882
[Epoch 20, Batch 2300] loss: 0.011356668512464694
[Epoch 20, Batch 2400] loss: 0.011143729328925928
[Epoch 20, Batch 2500] loss: 0.015695513159989787
[Epoch 20, Batch 2600] loss: 0.009533780768108499
[Epoch 20, Batch 2700] loss: 0.005012901903480724
[Epoch 20, Batch 2800] loss: 0.016881949532207726
[Epoch 20, Batch 2900] loss: 0.020612417265388105
[Epoch 20, Batch 3000] loss: 0.0077139354129212735
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0448
Validation Accuracy: 0.9887
Overfitting: 0.0448
[Epoch 21, Batch 100] loss: 0.00841483239935087
[Epoch 21, Batch 200] loss: 0.004181796267855589
[Epoch 21, Batch 300] loss: 0.002481574205966126
[Epoch 21, Batch 400] loss: 0.016655148684553752
[Epoch 21, Batch 500] loss: 0.0123857850341642
[Epoch 21, Batch 600] loss: 0.01236927990008553
[Epoch 21, Batch 700] loss: 0.009032481337694662
[Epoch 21, Batch 800] loss: 0.003910639004409404
[Epoch 21, Batch 900] loss: 0.0032916966507076494
[Epoch 21, Batch 1000] loss: 0.004515084383862131
[Epoch 21, Batch 1100] loss: 0.005972090645680055
[Epoch 21, Batch 1200] loss: 0.0031670417866848767
[Epoch 21, Batch 1300] loss: 0.0033266105579889426
[Epoch 21, Batch 1400] loss: 0.00578135354028177
[Epoch 21, Batch 1500] loss: 0.01436235791466288
[Epoch 21, Batch 1600] loss: 0.008915924127850304
[Epoch 21, Batch 1700] loss: 0.005655896566462388
[Epoch 21, Batch 1800] loss: 0.008782151582877304
[Epoch 21, Batch 1900] loss: 0.010145601699466624
[Epoch 21, Batch 2000] loss: 0.008642530732381602
[Epoch 21, Batch 2100] loss: 0.007768246205314426
[Epoch 21, Batch 2200] loss: 0.010645915269321904
[Epoch 21, Batch 2300] loss: 0.014540099087962517
[Epoch 21, Batch 2400] loss: 0.00845537779613096
[Epoch 21, Batch 2500] loss: 0.004413882205765276
[Epoch 21, Batch 2600] loss: 0.003774999008085729
[Epoch 21, Batch 2700] loss: 0.007060166488479354
[Epoch 21, Batch 2800] loss: 0.007345185448799612
[Epoch 21, Batch 2900] loss: 0.020071914446330084
[Epoch 21, Batch 3000] loss: 0.011859734075189863
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9842
Overfitting: 0.0569
[Epoch 22, Batch 100] loss: 0.006364773789518949
[Epoch 22, Batch 200] loss: 0.006640671370084874
[Epoch 22, Batch 300] loss: 0.010006912856000553
[Epoch 22, Batch 400] loss: 0.006000226120581828
[Epoch 22, Batch 500] loss: 0.011979088590451284
[Epoch 22, Batch 600] loss: 0.009007973464590577
[Epoch 22, Batch 700] loss: 0.007127088843069487
[Epoch 22, Batch 800] loss: 0.006533857791623632
[Epoch 22, Batch 900] loss: 0.005627580962532193
[Epoch 22, Batch 1000] loss: 0.0116272222063958
[Epoch 22, Batch 1100] loss: 0.0065679726580333405
[Epoch 22, Batch 1200] loss: 0.005854156787909233
[Epoch 22, Batch 1300] loss: 0.006498637087890984
[Epoch 22, Batch 1400] loss: 0.00892397807288944
[Epoch 22, Batch 1500] loss: 0.005909165863772614
[Epoch 22, Batch 1600] loss: 0.002797350237149203
[Epoch 22, Batch 1700] loss: 0.0050477947408228375
[Epoch 22, Batch 1800] loss: 0.012052923660676243
[Epoch 22, Batch 1900] loss: 0.004310383449475239
[Epoch 22, Batch 2000] loss: 0.005848427662909899
[Epoch 22, Batch 2100] loss: 0.010688995759775822
[Epoch 22, Batch 2200] loss: 0.010224815205810955
[Epoch 22, Batch 2300] loss: 0.01386121835197173
[Epoch 22, Batch 2400] loss: 0.009639914729889369
[Epoch 22, Batch 2500] loss: 0.006138253460514989
[Epoch 22, Batch 2600] loss: 0.014908256880253247
[Epoch 22, Batch 2700] loss: 0.016801496280603487
[Epoch 22, Batch 2800] loss: 0.008973142381214529
[Epoch 22, Batch 2900] loss: 0.009087420507571551
[Epoch 22, Batch 3000] loss: 0.005746355621326984
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0451
Validation Accuracy: 0.9890
Overfitting: 0.0451
[Epoch 23, Batch 100] loss: 0.007015821621716895
[Epoch 23, Batch 200] loss: 0.004379976283339602
[Epoch 23, Batch 300] loss: 0.002606149708440171
[Epoch 23, Batch 400] loss: 0.008511745648518455
[Epoch 23, Batch 500] loss: 0.009235348742447514
[Epoch 23, Batch 600] loss: 0.007967193464331786
[Epoch 23, Batch 700] loss: 0.012648125441174898
[Epoch 23, Batch 800] loss: 0.00287309331749384
[Epoch 23, Batch 900] loss: 0.0068747560707242885
[Epoch 23, Batch 1000] loss: 0.005642081117093767
[Epoch 23, Batch 1100] loss: 0.002768503439651795
[Epoch 23, Batch 1200] loss: 0.0025995091700701067
[Epoch 23, Batch 1300] loss: 0.004365514094352534
[Epoch 23, Batch 1400] loss: 0.005984579711711149
[Epoch 23, Batch 1500] loss: 0.010013735067614106
[Epoch 23, Batch 1600] loss: 0.008919398730627108
[Epoch 23, Batch 1700] loss: 0.005540797824494916
[Epoch 23, Batch 1800] loss: 0.005868904618987472
[Epoch 23, Batch 1900] loss: 0.004539872119377151
[Epoch 23, Batch 2000] loss: 0.01108526230716052
[Epoch 23, Batch 2100] loss: 0.005792792142472081
[Epoch 23, Batch 2200] loss: 0.011095357480553646
[Epoch 23, Batch 2300] loss: 0.007121663652765164
[Epoch 23, Batch 2400] loss: 0.004055728316017735
[Epoch 23, Batch 2500] loss: 0.006443598843673613
[Epoch 23, Batch 2600] loss: 0.006195561631698183
[Epoch 23, Batch 2700] loss: 0.008195159691047138
[Epoch 23, Batch 2800] loss: 0.005011870658277076
[Epoch 23, Batch 2900] loss: 0.00870718809352411
[Epoch 23, Batch 3000] loss: 0.013519219226943734
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9861
Overfitting: 0.0506
[Epoch 24, Batch 100] loss: 0.007234308289217779
[Epoch 24, Batch 200] loss: 0.005032868725070312
[Epoch 24, Batch 300] loss: 0.003381239056930667
[Epoch 24, Batch 400] loss: 0.007425870011043684
[Epoch 24, Batch 500] loss: 0.0052631282550794365
[Epoch 24, Batch 600] loss: 0.0036822702306744757
[Epoch 24, Batch 700] loss: 0.0046970043932515184
[Epoch 24, Batch 800] loss: 0.0036889676006950367
[Epoch 24, Batch 900] loss: 0.0018597100768272413
[Epoch 24, Batch 1000] loss: 0.005618659790216043
[Epoch 24, Batch 1100] loss: 0.003669793132949053
[Epoch 24, Batch 1200] loss: 0.004062949007173983
[Epoch 24, Batch 1300] loss: 0.007675699384948303
[Epoch 24, Batch 1400] loss: 0.00496810556377568
[Epoch 24, Batch 1500] loss: 0.0033610408484364028
[Epoch 24, Batch 1600] loss: 0.0033518753663372538
[Epoch 24, Batch 1700] loss: 0.003630812971155706
[Epoch 24, Batch 1800] loss: 0.003507008376432168
[Epoch 24, Batch 1900] loss: 0.011148900405557924
[Epoch 24, Batch 2000] loss: 0.004571542503367141
[Epoch 24, Batch 2100] loss: 0.004847296229366975
[Epoch 24, Batch 2200] loss: 0.00521087534182243
[Epoch 24, Batch 2300] loss: 0.007944927782946252
[Epoch 24, Batch 2400] loss: 0.009237237827650234
[Epoch 24, Batch 2500] loss: 0.005957417362782494
[Epoch 24, Batch 2600] loss: 0.008051866386263101
[Epoch 24, Batch 2700] loss: 0.005603032604800546
[Epoch 24, Batch 2800] loss: 0.002254294336640896
[Epoch 24, Batch 2900] loss: 0.007603149656117694
[Epoch 24, Batch 3000] loss: 0.006626131618394311
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9876
Overfitting: 0.0556
Fold 4 validation loss: 0.0556
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.299677760601044
[Epoch 1, Batch 200] loss: 2.277302007675171
[Epoch 1, Batch 300] loss: 2.2401788783073426
[Epoch 1, Batch 400] loss: 2.067450691461563
[Epoch 1, Batch 500] loss: 1.2784392324090004
[Epoch 1, Batch 600] loss: 0.7441428510844708
[Epoch 1, Batch 700] loss: 0.5689093990623951
[Epoch 1, Batch 800] loss: 0.4726408741623163
[Epoch 1, Batch 900] loss: 0.4597633460909128
[Epoch 1, Batch 1000] loss: 0.4129777353256941
[Epoch 1, Batch 1100] loss: 0.4232679610699415
[Epoch 1, Batch 1200] loss: 0.3980152119323611
[Epoch 1, Batch 1300] loss: 0.3361630153283477
[Epoch 1, Batch 1400] loss: 0.2994737007841468
[Epoch 1, Batch 1500] loss: 0.2884552450478077
[Epoch 1, Batch 1600] loss: 0.2913342980667949
[Epoch 1, Batch 1700] loss: 0.2771526521630585
[Epoch 1, Batch 1800] loss: 0.288556563667953
[Epoch 1, Batch 1900] loss: 0.2475889689102769
[Epoch 1, Batch 2000] loss: 0.22611331947147847
[Epoch 1, Batch 2100] loss: 0.25362299121916293
[Epoch 1, Batch 2200] loss: 0.2134644173271954
[Epoch 1, Batch 2300] loss: 0.2030987181700766
[Epoch 1, Batch 2400] loss: 0.19362143558450043
[Epoch 1, Batch 2500] loss: 0.16355364508926867
[Epoch 1, Batch 2600] loss: 0.18286583300679923
[Epoch 1, Batch 2700] loss: 0.1824430071003735
[Epoch 1, Batch 2800] loss: 0.1738105309382081
[Epoch 1, Batch 2900] loss: 0.16398978729732336
[Epoch 1, Batch 3000] loss: 0.1894791237730533
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1450
Validation Accuracy: 0.9570
Overfitting: 0.1450
Best model saved at epoch 1 with validation loss: 0.1450
[Epoch 2, Batch 100] loss: 0.14998762251343578
[Epoch 2, Batch 200] loss: 0.1452184764575213
[Epoch 2, Batch 300] loss: 0.13413231718353927
[Epoch 2, Batch 400] loss: 0.16283863714896143
[Epoch 2, Batch 500] loss: 0.15180877051316202
[Epoch 2, Batch 600] loss: 0.1533742511132732
[Epoch 2, Batch 700] loss: 0.12423163978382945
[Epoch 2, Batch 800] loss: 0.1423480640631169
[Epoch 2, Batch 900] loss: 0.1152970292698592
[Epoch 2, Batch 1000] loss: 0.10884023492224515
[Epoch 2, Batch 1100] loss: 0.11175321011804044
[Epoch 2, Batch 1200] loss: 0.1086410816165153
[Epoch 2, Batch 1300] loss: 0.10486362613271921
[Epoch 2, Batch 1400] loss: 0.11458173869643361
[Epoch 2, Batch 1500] loss: 0.13285448311362416
[Epoch 2, Batch 1600] loss: 0.11417276095133275
[Epoch 2, Batch 1700] loss: 0.1132700644666329
[Epoch 2, Batch 1800] loss: 0.09809157261857764
[Epoch 2, Batch 1900] loss: 0.09402941861655563
[Epoch 2, Batch 2000] loss: 0.11637388328788802
[Epoch 2, Batch 2100] loss: 0.10662123388145119
[Epoch 2, Batch 2200] loss: 0.1054315681848675
[Epoch 2, Batch 2300] loss: 0.12577319046715274
[Epoch 2, Batch 2400] loss: 0.0945724820473697
[Epoch 2, Batch 2500] loss: 0.12292245784541592
[Epoch 2, Batch 2600] loss: 0.09277790089137852
[Epoch 2, Batch 2700] loss: 0.11143032322346698
[Epoch 2, Batch 2800] loss: 0.09888391786022112
[Epoch 2, Batch 2900] loss: 0.09439592367736623
[Epoch 2, Batch 3000] loss: 0.10028055663686246
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0963
Validation Accuracy: 0.9697
Overfitting: 0.0963
Best model saved at epoch 2 with validation loss: 0.0963
[Epoch 3, Batch 100] loss: 0.08056867819279433
[Epoch 3, Batch 200] loss: 0.08798762187594548
[Epoch 3, Batch 300] loss: 0.08435513329692185
[Epoch 3, Batch 400] loss: 0.07201827338663862
[Epoch 3, Batch 500] loss: 0.07464123829617166
[Epoch 3, Batch 600] loss: 0.10012470573652536
[Epoch 3, Batch 700] loss: 0.07976109066512435
[Epoch 3, Batch 800] loss: 0.09566699344082735
[Epoch 3, Batch 900] loss: 0.07192662850953639
[Epoch 3, Batch 1000] loss: 0.06892864346504211
[Epoch 3, Batch 1100] loss: 0.08263652282999828
[Epoch 3, Batch 1200] loss: 0.09809630590025335
[Epoch 3, Batch 1300] loss: 0.08117279638070612
[Epoch 3, Batch 1400] loss: 0.0809311680542305
[Epoch 3, Batch 1500] loss: 0.07403540037339554
[Epoch 3, Batch 1600] loss: 0.08529989915783517
[Epoch 3, Batch 1700] loss: 0.07462252507859375
[Epoch 3, Batch 1800] loss: 0.08006016792380251
[Epoch 3, Batch 1900] loss: 0.08570884506567382
[Epoch 3, Batch 2000] loss: 0.08293119310517795
[Epoch 3, Batch 2100] loss: 0.06426277387537993
[Epoch 3, Batch 2200] loss: 0.08873577515623765
[Epoch 3, Batch 2300] loss: 0.07142524709866847
[Epoch 3, Batch 2400] loss: 0.08090208471636288
[Epoch 3, Batch 2500] loss: 0.07073751895106398
[Epoch 3, Batch 2600] loss: 0.07266826233128086
[Epoch 3, Batch 2700] loss: 0.060104094186099244
[Epoch 3, Batch 2800] loss: 0.08116013476625085
[Epoch 3, Batch 2900] loss: 0.060852540025371125
[Epoch 3, Batch 3000] loss: 0.07608445066376589
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0749
Validation Accuracy: 0.9756
Overfitting: 0.0749
Best model saved at epoch 3 with validation loss: 0.0749
[Epoch 4, Batch 100] loss: 0.06107706406153739
[Epoch 4, Batch 200] loss: 0.04532106427184772
[Epoch 4, Batch 300] loss: 0.05415930132672656
[Epoch 4, Batch 400] loss: 0.06887965738831553
[Epoch 4, Batch 500] loss: 0.07529790612141368
[Epoch 4, Batch 600] loss: 0.07533617559005507
[Epoch 4, Batch 700] loss: 0.06938066980801523
[Epoch 4, Batch 800] loss: 0.060848694597370925
[Epoch 4, Batch 900] loss: 0.061094422474852764
[Epoch 4, Batch 1000] loss: 0.0581769655586686
[Epoch 4, Batch 1100] loss: 0.0730508143058978
[Epoch 4, Batch 1200] loss: 0.07426461837952957
[Epoch 4, Batch 1300] loss: 0.07800457612727768
[Epoch 4, Batch 1400] loss: 0.06523849759425503
[Epoch 4, Batch 1500] loss: 0.08237135200819466
[Epoch 4, Batch 1600] loss: 0.06335026699001901
[Epoch 4, Batch 1700] loss: 0.06682302678585984
[Epoch 4, Batch 1800] loss: 0.0647034620307386
[Epoch 4, Batch 1900] loss: 0.05199543853930663
[Epoch 4, Batch 2000] loss: 0.056875770497717894
[Epoch 4, Batch 2100] loss: 0.0580515712761553
[Epoch 4, Batch 2200] loss: 0.051565799395903014
[Epoch 4, Batch 2300] loss: 0.055918505357112736
[Epoch 4, Batch 2400] loss: 0.05182694852061104
[Epoch 4, Batch 2500] loss: 0.061172104738652706
[Epoch 4, Batch 2600] loss: 0.06464633430819959
[Epoch 4, Batch 2700] loss: 0.048430197588604645
[Epoch 4, Batch 2800] loss: 0.05341319313738495
[Epoch 4, Batch 2900] loss: 0.06318113345274469
[Epoch 4, Batch 3000] loss: 0.06817201621597632
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0719
Validation Accuracy: 0.9766
Overfitting: 0.0719
Best model saved at epoch 4 with validation loss: 0.0719
[Epoch 5, Batch 100] loss: 0.05885232151747914
[Epoch 5, Batch 200] loss: 0.05441602719714865
[Epoch 5, Batch 300] loss: 0.06496070666587911
[Epoch 5, Batch 400] loss: 0.06417511662235484
[Epoch 5, Batch 500] loss: 0.056363749696174636
[Epoch 5, Batch 600] loss: 0.053939576777338516
[Epoch 5, Batch 700] loss: 0.05570007660950069
[Epoch 5, Batch 800] loss: 0.03795184431161033
[Epoch 5, Batch 900] loss: 0.043356055540498345
[Epoch 5, Batch 1000] loss: 0.053159692136978264
[Epoch 5, Batch 1100] loss: 0.04690752995404182
[Epoch 5, Batch 1200] loss: 0.050133175424125515
[Epoch 5, Batch 1300] loss: 0.062240698271780276
[Epoch 5, Batch 1400] loss: 0.06720534780819434
[Epoch 5, Batch 1500] loss: 0.051966439789102876
[Epoch 5, Batch 1600] loss: 0.04474097761354642
[Epoch 5, Batch 1700] loss: 0.04089522886890336
[Epoch 5, Batch 1800] loss: 0.06414215067634359
[Epoch 5, Batch 1900] loss: 0.07842399046756326
[Epoch 5, Batch 2000] loss: 0.06662456911988557
[Epoch 5, Batch 2100] loss: 0.05619345219747629
[Epoch 5, Batch 2200] loss: 0.05294377240468748
[Epoch 5, Batch 2300] loss: 0.03824947936634999
[Epoch 5, Batch 2400] loss: 0.047875516946369316
[Epoch 5, Batch 2500] loss: 0.034991315371298695
[Epoch 5, Batch 2600] loss: 0.04228361357774702
[Epoch 5, Batch 2700] loss: 0.03637683164590271
[Epoch 5, Batch 2800] loss: 0.03869969469858916
[Epoch 5, Batch 2900] loss: 0.045085620230529456
[Epoch 5, Batch 3000] loss: 0.04986272763781017
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0614
Validation Accuracy: 0.9812
Overfitting: 0.0614
Best model saved at epoch 5 with validation loss: 0.0614
[Epoch 6, Batch 100] loss: 0.034342176151985766
[Epoch 6, Batch 200] loss: 0.03950086654920597
[Epoch 6, Batch 300] loss: 0.03193423574761255
[Epoch 6, Batch 400] loss: 0.05970544177864213
[Epoch 6, Batch 500] loss: 0.04713943313290656
[Epoch 6, Batch 600] loss: 0.047058166010829156
[Epoch 6, Batch 700] loss: 0.039479121797776316
[Epoch 6, Batch 800] loss: 0.02791966098287958
[Epoch 6, Batch 900] loss: 0.032614046062226405
[Epoch 6, Batch 1000] loss: 0.04028036681134836
[Epoch 6, Batch 1100] loss: 0.038055326582107224
[Epoch 6, Batch 1200] loss: 0.034338146666123066
[Epoch 6, Batch 1300] loss: 0.05175783382874215
[Epoch 6, Batch 1400] loss: 0.05557444356338238
[Epoch 6, Batch 1500] loss: 0.03438157997909002
[Epoch 6, Batch 1600] loss: 0.04717055239743786
[Epoch 6, Batch 1700] loss: 0.0362237360078143
[Epoch 6, Batch 1800] loss: 0.04311797248672519
[Epoch 6, Batch 1900] loss: 0.040961569264763964
[Epoch 6, Batch 2000] loss: 0.0573241878405679
[Epoch 6, Batch 2100] loss: 0.04179062076262199
[Epoch 6, Batch 2200] loss: 0.040271220545691905
[Epoch 6, Batch 2300] loss: 0.04754319531435613
[Epoch 6, Batch 2400] loss: 0.037625108722713775
[Epoch 6, Batch 2500] loss: 0.058508425409236224
[Epoch 6, Batch 2600] loss: 0.03932161221600836
[Epoch 6, Batch 2700] loss: 0.06356414354289881
[Epoch 6, Batch 2800] loss: 0.036369677552429494
[Epoch 6, Batch 2900] loss: 0.05801375123875914
[Epoch 6, Batch 3000] loss: 0.057701735611772165
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9847
Overfitting: 0.0512
Best model saved at epoch 6 with validation loss: 0.0512
[Epoch 7, Batch 100] loss: 0.022594352200394498
[Epoch 7, Batch 200] loss: 0.049946492477611175
[Epoch 7, Batch 300] loss: 0.036259738990920595
[Epoch 7, Batch 400] loss: 0.03604098545067245
[Epoch 7, Batch 500] loss: 0.03175777935393853
[Epoch 7, Batch 600] loss: 0.04005978524859529
[Epoch 7, Batch 700] loss: 0.041767037595855074
[Epoch 7, Batch 800] loss: 0.05319093026220798
[Epoch 7, Batch 900] loss: 0.044838832753594036
[Epoch 7, Batch 1000] loss: 0.031078008118493018
[Epoch 7, Batch 1100] loss: 0.03487899017593008
[Epoch 7, Batch 1200] loss: 0.041530849025439236
[Epoch 7, Batch 1300] loss: 0.03949073285737541
[Epoch 7, Batch 1400] loss: 0.030044446872489063
[Epoch 7, Batch 1500] loss: 0.028897341446281644
[Epoch 7, Batch 1600] loss: 0.03516205585896387
[Epoch 7, Batch 1700] loss: 0.026994952325403575
[Epoch 7, Batch 1800] loss: 0.04709311275371874
[Epoch 7, Batch 1900] loss: 0.02466220602946123
[Epoch 7, Batch 2000] loss: 0.04532401418007794
[Epoch 7, Batch 2100] loss: 0.04302321641225717
[Epoch 7, Batch 2200] loss: 0.03513908783294028
[Epoch 7, Batch 2300] loss: 0.04469082460433128
[Epoch 7, Batch 2400] loss: 0.04007291198300664
[Epoch 7, Batch 2500] loss: 0.05815927636867855
[Epoch 7, Batch 2600] loss: 0.053557052432588535
[Epoch 7, Batch 2700] loss: 0.029671213928813812
[Epoch 7, Batch 2800] loss: 0.02956847586996446
[Epoch 7, Batch 2900] loss: 0.03423546757199802
[Epoch 7, Batch 3000] loss: 0.05122551913038478
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9852
Overfitting: 0.0478
Best model saved at epoch 7 with validation loss: 0.0478
[Epoch 8, Batch 100] loss: 0.021883419875521212
[Epoch 8, Batch 200] loss: 0.034011183952825375
[Epoch 8, Batch 300] loss: 0.03319425445777597
[Epoch 8, Batch 400] loss: 0.025603230935666944
[Epoch 8, Batch 500] loss: 0.028273030029376967
[Epoch 8, Batch 600] loss: 0.03056924702395918
[Epoch 8, Batch 700] loss: 0.034200797609737495
[Epoch 8, Batch 800] loss: 0.04015042796374473
[Epoch 8, Batch 900] loss: 0.03701849486715218
[Epoch 8, Batch 1000] loss: 0.03176608562578622
[Epoch 8, Batch 1100] loss: 0.058263616538024504
[Epoch 8, Batch 1200] loss: 0.024523367547080854
[Epoch 8, Batch 1300] loss: 0.019575843778584387
[Epoch 8, Batch 1400] loss: 0.024916397303095437
[Epoch 8, Batch 1500] loss: 0.029184505262674066
[Epoch 8, Batch 1600] loss: 0.0298898626495793
[Epoch 8, Batch 1700] loss: 0.0264499942567636
[Epoch 8, Batch 1800] loss: 0.02989924986501137
[Epoch 8, Batch 1900] loss: 0.023040170508102163
[Epoch 8, Batch 2000] loss: 0.03407868493610294
[Epoch 8, Batch 2100] loss: 0.03512405853423843
[Epoch 8, Batch 2200] loss: 0.039549864083601276
[Epoch 8, Batch 2300] loss: 0.03474109976785258
[Epoch 8, Batch 2400] loss: 0.04615881399709906
[Epoch 8, Batch 2500] loss: 0.025578889387834352
[Epoch 8, Batch 2600] loss: 0.038254704600112745
[Epoch 8, Batch 2700] loss: 0.035454095731693086
[Epoch 8, Batch 2800] loss: 0.042397549355664525
[Epoch 8, Batch 2900] loss: 0.03807742493401747
[Epoch 8, Batch 3000] loss: 0.039347852533392146
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9863
Overfitting: 0.0459
Best model saved at epoch 8 with validation loss: 0.0459
[Epoch 9, Batch 100] loss: 0.0476420756909647
[Epoch 9, Batch 200] loss: 0.02598260883609328
[Epoch 9, Batch 300] loss: 0.021275736509851415
[Epoch 9, Batch 400] loss: 0.023668190993266763
[Epoch 9, Batch 500] loss: 0.04072007551236311
[Epoch 9, Batch 600] loss: 0.02290670186179341
[Epoch 9, Batch 700] loss: 0.03206539775666897
[Epoch 9, Batch 800] loss: 0.023790195266192315
[Epoch 9, Batch 900] loss: 0.02158612446826737
[Epoch 9, Batch 1000] loss: 0.02323932079321821
[Epoch 9, Batch 1100] loss: 0.025246892932700576
[Epoch 9, Batch 1200] loss: 0.030321511999864013
[Epoch 9, Batch 1300] loss: 0.02580833366191655
[Epoch 9, Batch 1400] loss: 0.042161271759323424
[Epoch 9, Batch 1500] loss: 0.03618425701890374
[Epoch 9, Batch 1600] loss: 0.029929251569119516
[Epoch 9, Batch 1700] loss: 0.030833276466291862
[Epoch 9, Batch 1800] loss: 0.035637164396466685
[Epoch 9, Batch 1900] loss: 0.030406363571310067
[Epoch 9, Batch 2000] loss: 0.021494131189538166
[Epoch 9, Batch 2100] loss: 0.027130919822157012
[Epoch 9, Batch 2200] loss: 0.03288987778549199
[Epoch 9, Batch 2300] loss: 0.02275681134458864
[Epoch 9, Batch 2400] loss: 0.0381388929296736
[Epoch 9, Batch 2500] loss: 0.019949409509863472
[Epoch 9, Batch 2600] loss: 0.0314964490912098
[Epoch 9, Batch 2700] loss: 0.037787364586693004
[Epoch 9, Batch 2800] loss: 0.029086904814103035
[Epoch 9, Batch 2900] loss: 0.019528829483533627
[Epoch 9, Batch 3000] loss: 0.033954509370814775
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9848
Overfitting: 0.0463
[Epoch 10, Batch 100] loss: 0.016462569068171434
[Epoch 10, Batch 200] loss: 0.021320775285203125
[Epoch 10, Batch 300] loss: 0.018820756989662187
[Epoch 10, Batch 400] loss: 0.019298625242954587
[Epoch 10, Batch 500] loss: 0.016970853473649187
[Epoch 10, Batch 600] loss: 0.022803724412879093
[Epoch 10, Batch 700] loss: 0.03125063356253122
[Epoch 10, Batch 800] loss: 0.025082667743990896
[Epoch 10, Batch 900] loss: 0.02639393247634871
[Epoch 10, Batch 1000] loss: 0.01926661941659404
[Epoch 10, Batch 1100] loss: 0.020593660566592006
[Epoch 10, Batch 1200] loss: 0.0295500602397442
[Epoch 10, Batch 1300] loss: 0.02865320209413767
[Epoch 10, Batch 1400] loss: 0.019082383692657457
[Epoch 10, Batch 1500] loss: 0.02637783369562385
[Epoch 10, Batch 1600] loss: 0.015855192644667112
[Epoch 10, Batch 1700] loss: 0.024567089766424032
[Epoch 10, Batch 1800] loss: 0.03415170743515773
[Epoch 10, Batch 1900] loss: 0.02706649153122271
[Epoch 10, Batch 2000] loss: 0.022431601802909425
[Epoch 10, Batch 2100] loss: 0.03075341921983636
[Epoch 10, Batch 2200] loss: 0.039143421386834236
[Epoch 10, Batch 2300] loss: 0.02292815934983082
[Epoch 10, Batch 2400] loss: 0.031441478891210864
[Epoch 10, Batch 2500] loss: 0.0357515803854767
[Epoch 10, Batch 2600] loss: 0.022528001716418656
[Epoch 10, Batch 2700] loss: 0.03642479363923485
[Epoch 10, Batch 2800] loss: 0.02541442117453698
[Epoch 10, Batch 2900] loss: 0.0258948764539673
[Epoch 10, Batch 3000] loss: 0.036475804010042336
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9862
Overfitting: 0.0437
Best model saved at epoch 10 with validation loss: 0.0437
[Epoch 11, Batch 100] loss: 0.01278940645082912
[Epoch 11, Batch 200] loss: 0.022132019157943432
[Epoch 11, Batch 300] loss: 0.015069937911976012
[Epoch 11, Batch 400] loss: 0.03415088084366289
[Epoch 11, Batch 500] loss: 0.02135855876535061
[Epoch 11, Batch 600] loss: 0.027615291666588746
[Epoch 11, Batch 700] loss: 0.01591278964348021
[Epoch 11, Batch 800] loss: 0.026279806811071466
[Epoch 11, Batch 900] loss: 0.013158171715404024
[Epoch 11, Batch 1000] loss: 0.017592929858074056
[Epoch 11, Batch 1100] loss: 0.01977301844788599
[Epoch 11, Batch 1200] loss: 0.013004529616864602
[Epoch 11, Batch 1300] loss: 0.016989422583792477
[Epoch 11, Batch 1400] loss: 0.040546156622131097
[Epoch 11, Batch 1500] loss: 0.0197515810533514
[Epoch 11, Batch 1600] loss: 0.01724007045291728
[Epoch 11, Batch 1700] loss: 0.013313922909437679
[Epoch 11, Batch 1800] loss: 0.02020305177429691
[Epoch 11, Batch 1900] loss: 0.033727885662810875
[Epoch 11, Batch 2000] loss: 0.029900064170142286
[Epoch 11, Batch 2100] loss: 0.029232439611769225
[Epoch 11, Batch 2200] loss: 0.022807726996761632
[Epoch 11, Batch 2300] loss: 0.025838807766413084
[Epoch 11, Batch 2400] loss: 0.019403359402058413
[Epoch 11, Batch 2500] loss: 0.022374421919957966
[Epoch 11, Batch 2600] loss: 0.03519189968865248
[Epoch 11, Batch 2700] loss: 0.011300557000940898
[Epoch 11, Batch 2800] loss: 0.025881141809295512
[Epoch 11, Batch 2900] loss: 0.027048032042766863
[Epoch 11, Batch 3000] loss: 0.023996189708268504
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9876
Overfitting: 0.0431
Best model saved at epoch 11 with validation loss: 0.0431
[Epoch 12, Batch 100] loss: 0.016315139487269335
[Epoch 12, Batch 200] loss: 0.01829458022955805
[Epoch 12, Batch 300] loss: 0.014136001498627593
[Epoch 12, Batch 400] loss: 0.016175724765307677
[Epoch 12, Batch 500] loss: 0.023724613838712685
[Epoch 12, Batch 600] loss: 0.017883232229723944
[Epoch 12, Batch 700] loss: 0.025755163437388547
[Epoch 12, Batch 800] loss: 0.012730598114503664
[Epoch 12, Batch 900] loss: 0.013437505325273378
[Epoch 12, Batch 1000] loss: 0.011591447496539332
[Epoch 12, Batch 1100] loss: 0.017311666488385526
[Epoch 12, Batch 1200] loss: 0.019656563429452944
[Epoch 12, Batch 1300] loss: 0.01741726823427598
[Epoch 12, Batch 1400] loss: 0.03395966811527615
[Epoch 12, Batch 1500] loss: 0.03132525135515607
[Epoch 12, Batch 1600] loss: 0.021992805958143437
[Epoch 12, Batch 1700] loss: 0.009549248600797
[Epoch 12, Batch 1800] loss: 0.025715396928535483
[Epoch 12, Batch 1900] loss: 0.013914715225910186
[Epoch 12, Batch 2000] loss: 0.01706647725386574
[Epoch 12, Batch 2100] loss: 0.01949509733087325
[Epoch 12, Batch 2200] loss: 0.024077631275649766
[Epoch 12, Batch 2300] loss: 0.021471138211418293
[Epoch 12, Batch 2400] loss: 0.02655988361724667
[Epoch 12, Batch 2500] loss: 0.021576446063445474
[Epoch 12, Batch 2600] loss: 0.027453208217411883
[Epoch 12, Batch 2700] loss: 0.019465951004258387
[Epoch 12, Batch 2800] loss: 0.015261830683975859
[Epoch 12, Batch 2900] loss: 0.024152432603004856
[Epoch 12, Batch 3000] loss: 0.02719412634112814
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9830
Overfitting: 0.0619
[Epoch 13, Batch 100] loss: 0.02311667717207456
[Epoch 13, Batch 200] loss: 0.010707837291010946
[Epoch 13, Batch 300] loss: 0.010125433298871939
[Epoch 13, Batch 400] loss: 0.010394259522217907
[Epoch 13, Batch 500] loss: 0.008223546528042788
[Epoch 13, Batch 600] loss: 0.013385385915389634
[Epoch 13, Batch 700] loss: 0.013148177580642368
[Epoch 13, Batch 800] loss: 0.013704630125648692
[Epoch 13, Batch 900] loss: 0.016340151366048303
[Epoch 13, Batch 1000] loss: 0.01989596959658229
[Epoch 13, Batch 1100] loss: 0.015178925271120533
[Epoch 13, Batch 1200] loss: 0.019847171307083043
[Epoch 13, Batch 1300] loss: 0.012178025736284325
[Epoch 13, Batch 1400] loss: 0.015326127456373797
[Epoch 13, Batch 1500] loss: 0.029252961947386212
[Epoch 13, Batch 1600] loss: 0.026444958781567038
[Epoch 13, Batch 1700] loss: 0.01032105178303027
[Epoch 13, Batch 1800] loss: 0.021952237920340848
[Epoch 13, Batch 1900] loss: 0.020414537732676763
[Epoch 13, Batch 2000] loss: 0.013905793325266131
[Epoch 13, Batch 2100] loss: 0.02709567545323807
[Epoch 13, Batch 2200] loss: 0.01753554074006388
[Epoch 13, Batch 2300] loss: 0.022014113019640718
[Epoch 13, Batch 2400] loss: 0.01836981051736075
[Epoch 13, Batch 2500] loss: 0.015281013448402518
[Epoch 13, Batch 2600] loss: 0.027271862314519238
[Epoch 13, Batch 2700] loss: 0.0315149381064839
[Epoch 13, Batch 2800] loss: 0.02127941187736724
[Epoch 13, Batch 2900] loss: 0.012977775213221321
[Epoch 13, Batch 3000] loss: 0.015063847361525405
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9872
Overfitting: 0.0457
[Epoch 14, Batch 100] loss: 0.014802742647034392
[Epoch 14, Batch 200] loss: 0.01962115607926535
[Epoch 14, Batch 300] loss: 0.024522102271985206
[Epoch 14, Batch 400] loss: 0.019637019654946925
[Epoch 14, Batch 500] loss: 0.016991286996781128
[Epoch 14, Batch 600] loss: 0.017788705749967448
[Epoch 14, Batch 700] loss: 0.014145487466121267
[Epoch 14, Batch 800] loss: 0.0149561072763845
[Epoch 14, Batch 900] loss: 0.012700513905811022
[Epoch 14, Batch 1000] loss: 0.018636906092033313
[Epoch 14, Batch 1100] loss: 0.012950391475906145
[Epoch 14, Batch 1200] loss: 0.01552277598384535
[Epoch 14, Batch 1300] loss: 0.012387554258457384
[Epoch 14, Batch 1400] loss: 0.010912007327287938
[Epoch 14, Batch 1500] loss: 0.008192368109439485
[Epoch 14, Batch 1600] loss: 0.01378736981874681
[Epoch 14, Batch 1700] loss: 0.01861201014566177
[Epoch 14, Batch 1800] loss: 0.018847449075674375
[Epoch 14, Batch 1900] loss: 0.007886745301138944
[Epoch 14, Batch 2000] loss: 0.022825609005085425
[Epoch 14, Batch 2100] loss: 0.02250504571326019
[Epoch 14, Batch 2200] loss: 0.023929372562197387
[Epoch 14, Batch 2300] loss: 0.011833637683484994
[Epoch 14, Batch 2400] loss: 0.016630593281588515
[Epoch 14, Batch 2500] loss: 0.009907797156292872
[Epoch 14, Batch 2600] loss: 0.016669135827314677
[Epoch 14, Batch 2700] loss: 0.018824464876161073
[Epoch 14, Batch 2800] loss: 0.023635780663735204
[Epoch 14, Batch 2900] loss: 0.018190549334394745
[Epoch 14, Batch 3000] loss: 0.01948770676070126
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0498
Validation Accuracy: 0.9852
Overfitting: 0.0498
[Epoch 15, Batch 100] loss: 0.010212004156928743
[Epoch 15, Batch 200] loss: 0.01053054131612953
[Epoch 15, Batch 300] loss: 0.013111383161399317
[Epoch 15, Batch 400] loss: 0.013409876397827248
[Epoch 15, Batch 500] loss: 0.009698223606355895
[Epoch 15, Batch 600] loss: 0.014768631995611941
[Epoch 15, Batch 700] loss: 0.018755301817845973
[Epoch 15, Batch 800] loss: 0.007696009183800925
[Epoch 15, Batch 900] loss: 0.012390589875412843
[Epoch 15, Batch 1000] loss: 0.015917112641764108
[Epoch 15, Batch 1100] loss: 0.011942184926965638
[Epoch 15, Batch 1200] loss: 0.013513293573905684
[Epoch 15, Batch 1300] loss: 0.012229630054189328
[Epoch 15, Batch 1400] loss: 0.013743018440363812
[Epoch 15, Batch 1500] loss: 0.00856829780078442
[Epoch 15, Batch 1600] loss: 0.016524712019077015
[Epoch 15, Batch 1700] loss: 0.005221545145932396
[Epoch 15, Batch 1800] loss: 0.02037080713626892
[Epoch 15, Batch 1900] loss: 0.010908899154765095
[Epoch 15, Batch 2000] loss: 0.021811769054820615
[Epoch 15, Batch 2100] loss: 0.009467480529719978
[Epoch 15, Batch 2200] loss: 0.015133477332656185
[Epoch 15, Batch 2300] loss: 0.015386402798249037
[Epoch 15, Batch 2400] loss: 0.019225244444860436
[Epoch 15, Batch 2500] loss: 0.009122162700987247
[Epoch 15, Batch 2600] loss: 0.02048457165136824
[Epoch 15, Batch 2700] loss: 0.012880740713339946
[Epoch 15, Batch 2800] loss: 0.02700654295866116
[Epoch 15, Batch 2900] loss: 0.016670403023483688
[Epoch 15, Batch 3000] loss: 0.022750619294729404
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9868
Overfitting: 0.0473
[Epoch 16, Batch 100] loss: 0.017884934945004715
[Epoch 16, Batch 200] loss: 0.01506896260958456
[Epoch 16, Batch 300] loss: 0.009802549946189175
[Epoch 16, Batch 400] loss: 0.012215533707676514
[Epoch 16, Batch 500] loss: 0.009820904748444263
[Epoch 16, Batch 600] loss: 0.018943098161616944
[Epoch 16, Batch 700] loss: 0.01697088589216946
[Epoch 16, Batch 800] loss: 0.01459898367202186
[Epoch 16, Batch 900] loss: 0.018264969251467846
[Epoch 16, Batch 1000] loss: 0.014704443333775997
[Epoch 16, Batch 1100] loss: 0.008199654269992607
[Epoch 16, Batch 1200] loss: 0.021189540637162736
[Epoch 16, Batch 1300] loss: 0.011881834410487499
[Epoch 16, Batch 1400] loss: 0.0159885937495892
[Epoch 16, Batch 1500] loss: 0.006661661194070803
[Epoch 16, Batch 1600] loss: 0.012598543601243364
[Epoch 16, Batch 1700] loss: 0.009200135700812098
[Epoch 16, Batch 1800] loss: 0.00624824975446586
[Epoch 16, Batch 1900] loss: 0.011272272396981862
[Epoch 16, Batch 2000] loss: 0.00923159482860683
[Epoch 16, Batch 2100] loss: 0.013942593976621539
[Epoch 16, Batch 2200] loss: 0.006994638208052493
[Epoch 16, Batch 2300] loss: 0.00955323400987254
[Epoch 16, Batch 2400] loss: 0.014107843790698097
[Epoch 16, Batch 2500] loss: 0.0114707513925714
[Epoch 16, Batch 2600] loss: 0.019093774511557058
[Epoch 16, Batch 2700] loss: 0.009718976414205827
[Epoch 16, Batch 2800] loss: 0.016262601893408828
[Epoch 16, Batch 2900] loss: 0.012010552413066762
[Epoch 16, Batch 3000] loss: 0.012599391871126499
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9872
Overfitting: 0.0492
[Epoch 17, Batch 100] loss: 0.011624230992292723
[Epoch 17, Batch 200] loss: 0.007192982117230713
[Epoch 17, Batch 300] loss: 0.015436851936929088
[Epoch 17, Batch 400] loss: 0.012069107202933083
[Epoch 17, Batch 500] loss: 0.018477081552046002
[Epoch 17, Batch 600] loss: 0.006030625829116616
[Epoch 17, Batch 700] loss: 0.011879782492887897
[Epoch 17, Batch 800] loss: 0.0068992403607171585
[Epoch 17, Batch 900] loss: 0.005567396387407371
[Epoch 17, Batch 1000] loss: 0.006249317847978091
[Epoch 17, Batch 1100] loss: 0.010976190660021529
[Epoch 17, Batch 1200] loss: 0.007845618593109975
[Epoch 17, Batch 1300] loss: 0.011271891991987104
[Epoch 17, Batch 1400] loss: 0.00508067856718526
[Epoch 17, Batch 1500] loss: 0.0072651938021067505
[Epoch 17, Batch 1600] loss: 0.018402502632836784
[Epoch 17, Batch 1700] loss: 0.005587907569461095
[Epoch 17, Batch 1800] loss: 0.007821433951605741
[Epoch 17, Batch 1900] loss: 0.013309673231390207
[Epoch 17, Batch 2000] loss: 0.006195242426178993
[Epoch 17, Batch 2100] loss: 0.018919507159457682
[Epoch 17, Batch 2200] loss: 0.016924621812970598
[Epoch 17, Batch 2300] loss: 0.024337513714435773
[Epoch 17, Batch 2400] loss: 0.009493547229253637
[Epoch 17, Batch 2500] loss: 0.017857462057208978
[Epoch 17, Batch 2600] loss: 0.015415315782520337
[Epoch 17, Batch 2700] loss: 0.006690644465270452
[Epoch 17, Batch 2800] loss: 0.015596507756026768
[Epoch 17, Batch 2900] loss: 0.0170405913275863
[Epoch 17, Batch 3000] loss: 0.017861668424848175
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0442
Validation Accuracy: 0.9883
Overfitting: 0.0442
[Epoch 18, Batch 100] loss: 0.011554046665949044
[Epoch 18, Batch 200] loss: 0.007185310715667584
[Epoch 18, Batch 300] loss: 0.0061086852970515795
[Epoch 18, Batch 400] loss: 0.006856920740592614
[Epoch 18, Batch 500] loss: 0.011645989000880945
[Epoch 18, Batch 600] loss: 0.00936722164663479
[Epoch 18, Batch 700] loss: 0.006452453572983359
[Epoch 18, Batch 800] loss: 0.011870847630179924
[Epoch 18, Batch 900] loss: 0.00970303251167934
[Epoch 18, Batch 1000] loss: 0.015179864741799064
[Epoch 18, Batch 1100] loss: 0.01836556402539827
[Epoch 18, Batch 1200] loss: 0.012462886123055341
[Epoch 18, Batch 1300] loss: 0.014971504258305686
[Epoch 18, Batch 1400] loss: 0.007674195348381545
[Epoch 18, Batch 1500] loss: 0.015084617370225714
[Epoch 18, Batch 1600] loss: 0.004320518268564229
[Epoch 18, Batch 1700] loss: 0.006145574561055582
[Epoch 18, Batch 1800] loss: 0.005735985874366634
[Epoch 18, Batch 1900] loss: 0.004886784258765146
[Epoch 18, Batch 2000] loss: 0.016578328835407774
[Epoch 18, Batch 2100] loss: 0.009326169761579309
[Epoch 18, Batch 2200] loss: 0.012654638861858985
[Epoch 18, Batch 2300] loss: 0.019866398170728418
[Epoch 18, Batch 2400] loss: 0.008663274347622974
[Epoch 18, Batch 2500] loss: 0.005477845390910261
[Epoch 18, Batch 2600] loss: 0.015786299868432253
[Epoch 18, Batch 2700] loss: 0.01044137814948499
[Epoch 18, Batch 2800] loss: 0.014446989604448391
[Epoch 18, Batch 2900] loss: 0.015617992424331532
[Epoch 18, Batch 3000] loss: 0.006881616502068937
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0541
Validation Accuracy: 0.9858
Overfitting: 0.0541
[Epoch 19, Batch 100] loss: 0.01283422454117499
[Epoch 19, Batch 200] loss: 0.014817635775298186
[Epoch 19, Batch 300] loss: 0.009439095642887878
[Epoch 19, Batch 400] loss: 0.014149066035943179
[Epoch 19, Batch 500] loss: 0.007233915322985922
[Epoch 19, Batch 600] loss: 0.011221100490161007
[Epoch 19, Batch 700] loss: 0.005774039690984409
[Epoch 19, Batch 800] loss: 0.0037091464271190944
[Epoch 19, Batch 900] loss: 0.003330802195054048
[Epoch 19, Batch 1000] loss: 0.003675860001012552
[Epoch 19, Batch 1100] loss: 0.021578234716066617
[Epoch 19, Batch 1200] loss: 0.011146688672315577
[Epoch 19, Batch 1300] loss: 0.011509379808576341
[Epoch 19, Batch 1400] loss: 0.009514177028859195
[Epoch 19, Batch 1500] loss: 0.006257383722331724
[Epoch 19, Batch 1600] loss: 0.009092305290437253
[Epoch 19, Batch 1700] loss: 0.016942422629830388
[Epoch 19, Batch 1800] loss: 0.010490086970621633
[Epoch 19, Batch 1900] loss: 0.006887284572580938
[Epoch 19, Batch 2000] loss: 0.00689990419311016
[Epoch 19, Batch 2100] loss: 0.0061631434475521015
[Epoch 19, Batch 2200] loss: 0.00684503754132038
[Epoch 19, Batch 2300] loss: 0.004553285012806896
[Epoch 19, Batch 2400] loss: 0.012815223910206442
[Epoch 19, Batch 2500] loss: 0.005315417423971667
[Epoch 19, Batch 2600] loss: 0.0043818650195248665
[Epoch 19, Batch 2700] loss: 0.008950274602540845
[Epoch 19, Batch 2800] loss: 0.0075920853699449255
[Epoch 19, Batch 2900] loss: 0.006140033142823995
[Epoch 19, Batch 3000] loss: 0.009710677156072052
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9878
Overfitting: 0.0489
[Epoch 20, Batch 100] loss: 0.00450757770272503
[Epoch 20, Batch 200] loss: 0.005410188443943298
[Epoch 20, Batch 300] loss: 0.011113232050197439
[Epoch 20, Batch 400] loss: 0.005019007737478205
[Epoch 20, Batch 500] loss: 0.009138234062920674
[Epoch 20, Batch 600] loss: 0.01691610768457849
[Epoch 20, Batch 700] loss: 0.013249268175150064
[Epoch 20, Batch 800] loss: 0.006927466577301402
[Epoch 20, Batch 900] loss: 0.0023390687840827693
[Epoch 20, Batch 1000] loss: 0.003979084963459627
[Epoch 20, Batch 1100] loss: 0.0054999060648231075
[Epoch 20, Batch 1200] loss: 0.0029079578685605157
[Epoch 20, Batch 1300] loss: 0.004428159864655185
[Epoch 20, Batch 1400] loss: 0.006467157595104709
[Epoch 20, Batch 1500] loss: 0.011450672266806237
[Epoch 20, Batch 1600] loss: 0.007004172825459136
[Epoch 20, Batch 1700] loss: 0.010189926575442314
[Epoch 20, Batch 1800] loss: 0.017702592630514574
[Epoch 20, Batch 1900] loss: 0.011837986109683243
[Epoch 20, Batch 2000] loss: 0.006704426850042182
[Epoch 20, Batch 2100] loss: 0.006495918971892251
[Epoch 20, Batch 2200] loss: 0.005758701370717461
[Epoch 20, Batch 2300] loss: 0.012218002860544174
[Epoch 20, Batch 2400] loss: 0.002849272474095983
[Epoch 20, Batch 2500] loss: 0.0038232941521187057
[Epoch 20, Batch 2600] loss: 0.004648872931786627
[Epoch 20, Batch 2700] loss: 0.012626359503988169
[Epoch 20, Batch 2800] loss: 0.015688258356163942
[Epoch 20, Batch 2900] loss: 0.009313023475638147
[Epoch 20, Batch 3000] loss: 0.011379878156496943
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9860
Overfitting: 0.0556
[Epoch 21, Batch 100] loss: 0.012095071755284152
[Epoch 21, Batch 200] loss: 0.002865992530037147
[Epoch 21, Batch 300] loss: 0.00406312208401232
[Epoch 21, Batch 400] loss: 0.003818522001287192
[Epoch 21, Batch 500] loss: 0.0033434575832097836
[Epoch 21, Batch 600] loss: 0.005303642509311431
[Epoch 21, Batch 700] loss: 0.006152674564546033
[Epoch 21, Batch 800] loss: 0.005619645042490902
[Epoch 21, Batch 900] loss: 0.00648216813283625
[Epoch 21, Batch 1000] loss: 0.008418379359434312
[Epoch 21, Batch 1100] loss: 0.004664916983854255
[Epoch 21, Batch 1200] loss: 0.008003709292319172
[Epoch 21, Batch 1300] loss: 0.007808686013875104
[Epoch 21, Batch 1400] loss: 0.00713594586308318
[Epoch 21, Batch 1500] loss: 0.005032899289992656
[Epoch 21, Batch 1600] loss: 0.006254984667547206
[Epoch 21, Batch 1700] loss: 0.006052140597696507
[Epoch 21, Batch 1800] loss: 0.009789580580753637
[Epoch 21, Batch 1900] loss: 0.012930603072163649
[Epoch 21, Batch 2000] loss: 0.009191586698650554
[Epoch 21, Batch 2100] loss: 0.010285475341985944
[Epoch 21, Batch 2200] loss: 0.004104150750391682
[Epoch 21, Batch 2300] loss: 0.0035468808176455013
[Epoch 21, Batch 2400] loss: 0.008463535513906209
[Epoch 21, Batch 2500] loss: 0.014268117004181704
[Epoch 21, Batch 2600] loss: 0.0066919714230778025
[Epoch 21, Batch 2700] loss: 0.00508115124908727
[Epoch 21, Batch 2800] loss: 0.006097198175241942
[Epoch 21, Batch 2900] loss: 0.005199871408329955
[Epoch 21, Batch 3000] loss: 0.01142267787709443
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9884
Overfitting: 0.0525
[Epoch 22, Batch 100] loss: 0.009164504658276656
[Epoch 22, Batch 200] loss: 0.003639196620124281
[Epoch 22, Batch 300] loss: 0.0014909343330961632
[Epoch 22, Batch 400] loss: 0.0057466463005403055
[Epoch 22, Batch 500] loss: 0.009373810209646082
[Epoch 22, Batch 600] loss: 0.005876757205600853
[Epoch 22, Batch 700] loss: 0.005440533758983293
[Epoch 22, Batch 800] loss: 0.003802475773095466
[Epoch 22, Batch 900] loss: 0.0033317266811536683
[Epoch 22, Batch 1000] loss: 0.005967245452711723
[Epoch 22, Batch 1100] loss: 0.008216682966394728
[Epoch 22, Batch 1200] loss: 0.0056589678094042025
[Epoch 22, Batch 1300] loss: 0.004685164705683746
[Epoch 22, Batch 1400] loss: 0.008623252078788255
[Epoch 22, Batch 1500] loss: 0.00578992232726705
[Epoch 22, Batch 1600] loss: 0.005343095185753555
[Epoch 22, Batch 1700] loss: 0.004614115365430962
[Epoch 22, Batch 1800] loss: 0.008948292815849754
[Epoch 22, Batch 1900] loss: 0.006693762198085835
[Epoch 22, Batch 2000] loss: 0.008818193931144833
[Epoch 22, Batch 2100] loss: 0.009188939034406757
[Epoch 22, Batch 2200] loss: 0.008505903320474318
[Epoch 22, Batch 2300] loss: 0.006241794160173413
[Epoch 22, Batch 2400] loss: 0.010636890452028638
[Epoch 22, Batch 2500] loss: 0.01060078145718876
[Epoch 22, Batch 2600] loss: 0.013999431625666147
[Epoch 22, Batch 2700] loss: 0.006686421852259627
[Epoch 22, Batch 2800] loss: 0.011239797821601769
[Epoch 22, Batch 2900] loss: 0.01432429559603861
[Epoch 22, Batch 3000] loss: 0.009329569956478281
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9887
Overfitting: 0.0512
[Epoch 23, Batch 100] loss: 0.007168812079075906
[Epoch 23, Batch 200] loss: 0.006808996312713589
[Epoch 23, Batch 300] loss: 0.002123776924345293
[Epoch 23, Batch 400] loss: 0.00380565482998918
[Epoch 23, Batch 500] loss: 0.004035587252228651
[Epoch 23, Batch 600] loss: 0.005681273213134545
[Epoch 23, Batch 700] loss: 0.0032487321870110007
[Epoch 23, Batch 800] loss: 0.003377084220443258
[Epoch 23, Batch 900] loss: 0.0050189434575554515
[Epoch 23, Batch 1000] loss: 0.005546314456638584
[Epoch 23, Batch 1100] loss: 0.004205846889997247
[Epoch 23, Batch 1200] loss: 0.0052938545099274845
[Epoch 23, Batch 1300] loss: 0.004762284739346114
[Epoch 23, Batch 1400] loss: 0.009838775667521987
[Epoch 23, Batch 1500] loss: 0.003473125562760515
[Epoch 23, Batch 1600] loss: 0.00526638406160032
[Epoch 23, Batch 1700] loss: 0.005081502445040371
[Epoch 23, Batch 1800] loss: 0.010926188603939693
[Epoch 23, Batch 1900] loss: 0.003018499168965718
[Epoch 23, Batch 2000] loss: 0.004093899237714709
[Epoch 23, Batch 2100] loss: 0.00489126458614237
[Epoch 23, Batch 2200] loss: 0.004374314321374868
[Epoch 23, Batch 2300] loss: 0.004342169586054467
[Epoch 23, Batch 2400] loss: 0.0039331861858784125
[Epoch 23, Batch 2500] loss: 0.014980479438737575
[Epoch 23, Batch 2600] loss: 0.005068695664840561
[Epoch 23, Batch 2700] loss: 0.004392226938892918
[Epoch 23, Batch 2800] loss: 0.012534033088743684
[Epoch 23, Batch 2900] loss: 0.010088413732247545
[Epoch 23, Batch 3000] loss: 0.005335253849378816
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9851
Overfitting: 0.0630
[Epoch 24, Batch 100] loss: 0.004551374406311197
[Epoch 24, Batch 200] loss: 0.003399686768853485
[Epoch 24, Batch 300] loss: 0.004259108449116411
[Epoch 24, Batch 400] loss: 0.0041391833227839925
[Epoch 24, Batch 500] loss: 0.00637385058492498
[Epoch 24, Batch 600] loss: 0.00522061618262029
[Epoch 24, Batch 700] loss: 0.003919397103268238
[Epoch 24, Batch 800] loss: 0.004167290702296214
[Epoch 24, Batch 900] loss: 0.0074628606660752436
[Epoch 24, Batch 1000] loss: 0.003158777888313189
[Epoch 24, Batch 1100] loss: 0.0050153649245692124
[Epoch 24, Batch 1200] loss: 0.008948938553634775
[Epoch 24, Batch 1300] loss: 0.00600350582919873
[Epoch 24, Batch 1400] loss: 0.0015090590349791455
[Epoch 24, Batch 1500] loss: 0.002850856275431397
[Epoch 24, Batch 1600] loss: 0.003985639371948366
[Epoch 24, Batch 1700] loss: 0.003128120328545947
[Epoch 24, Batch 1800] loss: 0.007761226402766397
[Epoch 24, Batch 1900] loss: 0.003250414001468016
[Epoch 24, Batch 2000] loss: 0.0020861876850426595
[Epoch 24, Batch 2100] loss: 0.0036075667870522922
[Epoch 24, Batch 2200] loss: 0.003400693494739926
[Epoch 24, Batch 2300] loss: 0.004063208017324769
[Epoch 24, Batch 2400] loss: 0.0038193555596933494
[Epoch 24, Batch 2500] loss: 0.0037705235082029277
[Epoch 24, Batch 2600] loss: 0.007281077582420323
[Epoch 24, Batch 2700] loss: 0.00386465291491902
[Epoch 24, Batch 2800] loss: 0.00347318200098357
[Epoch 24, Batch 2900] loss: 0.0037236087567373488
[Epoch 24, Batch 3000] loss: 0.00407416454504073
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9882
Overfitting: 0.0515
Fold 5 validation loss: 0.0515
Mean validation loss across all folds for Trial 3 is 0.0533 with trial config:  l1: 128, l2: 128, lr: 0.000816845589476017, batch_size: 16
[I 2024-12-10 05:48:34,356] Trial 2 finished with value: 0.05332992686522152 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.000816845589476017, 'batch_size': 16}. Best is trial 2 with value: 0.05332992686522152.

Selected Hyperparameters for Trial 4:
  l1: 128, l2: 128, lr: 0.00853618986286683, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.7137062644958496
[Epoch 1, Batch 200] loss: 0.6226196111738682
[Epoch 1, Batch 300] loss: 0.4383383860997856
[Epoch 1, Batch 400] loss: 0.31194650489836934
[Epoch 1, Batch 500] loss: 0.24226264198310674
[Epoch 1, Batch 600] loss: 0.1978581993933767
[Epoch 1, Batch 700] loss: 0.17903246731963007
[Epoch 1, Batch 800] loss: 0.1673098069553089
[Epoch 1, Batch 900] loss: 0.15779569504549726
[Epoch 1, Batch 1000] loss: 0.1604627225943841
[Epoch 1, Batch 1100] loss: 0.16225264503620565
[Epoch 1, Batch 1200] loss: 0.10223404066753573
[Epoch 1, Batch 1300] loss: 0.163436883186223
[Epoch 1, Batch 1400] loss: 0.11191320152545814
[Epoch 1, Batch 1500] loss: 0.15332390031660906
[Epoch 1, Batch 1600] loss: 0.13611938298505266
[Epoch 1, Batch 1700] loss: 0.13021276881103405
[Epoch 1, Batch 1800] loss: 0.11564262212021276
[Epoch 1, Batch 1900] loss: 0.10475183562783058
[Epoch 1, Batch 2000] loss: 0.09432689134788234
[Epoch 1, Batch 2100] loss: 0.12962586497538722
[Epoch 1, Batch 2200] loss: 0.07224078405590262
[Epoch 1, Batch 2300] loss: 0.11046037203559536
[Epoch 1, Batch 2400] loss: 0.10300587815334439
[Epoch 1, Batch 2500] loss: 0.08921807078557321
[Epoch 1, Batch 2600] loss: 0.10536414259229787
[Epoch 1, Batch 2700] loss: 0.08041668747493531
[Epoch 1, Batch 2800] loss: 0.10427315411565359
[Epoch 1, Batch 2900] loss: 0.08167345945315901
[Epoch 1, Batch 3000] loss: 0.07948058845940978
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0832
Validation Accuracy: 0.9762
Overfitting: 0.0832
Best model saved at epoch 1 with validation loss: 0.0832
[Epoch 2, Batch 100] loss: 0.0738432794813707
[Epoch 2, Batch 200] loss: 0.0632477713530534
[Epoch 2, Batch 300] loss: 0.09792785438825376
[Epoch 2, Batch 400] loss: 0.05928258012223523
[Epoch 2, Batch 500] loss: 0.06478050738864112
[Epoch 2, Batch 600] loss: 0.06818396968010347
[Epoch 2, Batch 700] loss: 0.06978922619171499
[Epoch 2, Batch 800] loss: 0.06881826000833825
[Epoch 2, Batch 900] loss: 0.09902857102628332
[Epoch 2, Batch 1000] loss: 0.057634863586899884
[Epoch 2, Batch 1100] loss: 0.10182930628528993
[Epoch 2, Batch 1200] loss: 0.08627918313257396
[Epoch 2, Batch 1300] loss: 0.05290842855203664
[Epoch 2, Batch 1400] loss: 0.05979966115275601
[Epoch 2, Batch 1500] loss: 0.05910811828834994
[Epoch 2, Batch 1600] loss: 0.08539257327196538
[Epoch 2, Batch 1700] loss: 0.07427861504605972
[Epoch 2, Batch 1800] loss: 0.05746439394060872
[Epoch 2, Batch 1900] loss: 0.059663052733867517
[Epoch 2, Batch 2000] loss: 0.08176856326841517
[Epoch 2, Batch 2100] loss: 0.04713753493160766
[Epoch 2, Batch 2200] loss: 0.07055995074544626
[Epoch 2, Batch 2300] loss: 0.08872530820066458
[Epoch 2, Batch 2400] loss: 0.08933094675769099
[Epoch 2, Batch 2500] loss: 0.05111693876620848
[Epoch 2, Batch 2600] loss: 0.04199724552800035
[Epoch 2, Batch 2700] loss: 0.09217292603847455
[Epoch 2, Batch 2800] loss: 0.09512172776419903
[Epoch 2, Batch 2900] loss: 0.04703535540495068
[Epoch 2, Batch 3000] loss: 0.05082062775552913
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0661
Validation Accuracy: 0.9805
Overfitting: 0.0661
Best model saved at epoch 2 with validation loss: 0.0661
[Epoch 3, Batch 100] loss: 0.058504092371367736
[Epoch 3, Batch 200] loss: 0.050694337085988084
[Epoch 3, Batch 300] loss: 0.05203727001993684
[Epoch 3, Batch 400] loss: 0.059434844893221456
[Epoch 3, Batch 500] loss: 0.04172834313067142
[Epoch 3, Batch 600] loss: 0.06862805717835727
[Epoch 3, Batch 700] loss: 0.0382610152153211
[Epoch 3, Batch 800] loss: 0.04736965884818346
[Epoch 3, Batch 900] loss: 0.06942935339518953
[Epoch 3, Batch 1000] loss: 0.05201849572837091
[Epoch 3, Batch 1100] loss: 0.05829713730578078
[Epoch 3, Batch 1200] loss: 0.0528335963661084
[Epoch 3, Batch 1300] loss: 0.08456297861484927
[Epoch 3, Batch 1400] loss: 0.07601585460477508
[Epoch 3, Batch 1500] loss: 0.061061586334762975
[Epoch 3, Batch 1600] loss: 0.05922116162153543
[Epoch 3, Batch 1700] loss: 0.0481589518081455
[Epoch 3, Batch 1800] loss: 0.0344588464892513
[Epoch 3, Batch 1900] loss: 0.04438999553525719
[Epoch 3, Batch 2000] loss: 0.059966339989673545
[Epoch 3, Batch 2100] loss: 0.042822496718872574
[Epoch 3, Batch 2200] loss: 0.03719426134382957
[Epoch 3, Batch 2300] loss: 0.05249537562677233
[Epoch 3, Batch 2400] loss: 0.06175391222423059
[Epoch 3, Batch 2500] loss: 0.0440290435341376
[Epoch 3, Batch 2600] loss: 0.04920302875656489
[Epoch 3, Batch 2700] loss: 0.041538858881394844
[Epoch 3, Batch 2800] loss: 0.04981897310091881
[Epoch 3, Batch 2900] loss: 0.021525533638898652
[Epoch 3, Batch 3000] loss: 0.0428657137153823
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9847
Overfitting: 0.0569
Best model saved at epoch 3 with validation loss: 0.0569
[Epoch 4, Batch 100] loss: 0.035611775141933324
[Epoch 4, Batch 200] loss: 0.05926530888391426
[Epoch 4, Batch 300] loss: 0.0379986376776651
[Epoch 4, Batch 400] loss: 0.03191599417448742
[Epoch 4, Batch 500] loss: 0.015574112097888247
[Epoch 4, Batch 600] loss: 0.0604819464000866
[Epoch 4, Batch 700] loss: 0.03630735670316426
[Epoch 4, Batch 800] loss: 0.05138294832901693
[Epoch 4, Batch 900] loss: 0.03360813273986423
[Epoch 4, Batch 1000] loss: 0.029326763915942137
[Epoch 4, Batch 1100] loss: 0.05371845571837184
[Epoch 4, Batch 1200] loss: 0.056039486948975537
[Epoch 4, Batch 1300] loss: 0.04660914390851758
[Epoch 4, Batch 1400] loss: 0.048648975172400244
[Epoch 4, Batch 1500] loss: 0.042595523352624697
[Epoch 4, Batch 1600] loss: 0.03231800455917437
[Epoch 4, Batch 1700] loss: 0.06307185488300092
[Epoch 4, Batch 1800] loss: 0.057594986061376405
[Epoch 4, Batch 1900] loss: 0.04253544071420037
[Epoch 4, Batch 2000] loss: 0.037561358937546176
[Epoch 4, Batch 2100] loss: 0.03988236268873152
[Epoch 4, Batch 2200] loss: 0.0463101531051143
[Epoch 4, Batch 2300] loss: 0.048498968975109163
[Epoch 4, Batch 2400] loss: 0.04891719635166737
[Epoch 4, Batch 2500] loss: 0.03494793071164168
[Epoch 4, Batch 2600] loss: 0.05662832450674614
[Epoch 4, Batch 2700] loss: 0.04192715004857746
[Epoch 4, Batch 2800] loss: 0.03570335727010388
[Epoch 4, Batch 2900] loss: 0.04007068480838825
[Epoch 4, Batch 3000] loss: 0.037795984511813006
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0562
Validation Accuracy: 0.9842
Overfitting: 0.0562
Best model saved at epoch 4 with validation loss: 0.0562
[Epoch 5, Batch 100] loss: 0.03240301547832132
[Epoch 5, Batch 200] loss: 0.03183556087758916
[Epoch 5, Batch 300] loss: 0.029849511053062088
[Epoch 5, Batch 400] loss: 0.02784500032572396
[Epoch 5, Batch 500] loss: 0.06462621960126853
[Epoch 5, Batch 600] loss: 0.036146419213419
[Epoch 5, Batch 700] loss: 0.02157385650029255
[Epoch 5, Batch 800] loss: 0.03558139968423205
[Epoch 5, Batch 900] loss: 0.04405956059498294
[Epoch 5, Batch 1000] loss: 0.02920030807060357
[Epoch 5, Batch 1100] loss: 0.045440722058101526
[Epoch 5, Batch 1200] loss: 0.04265764471318107
[Epoch 5, Batch 1300] loss: 0.040495577125593624
[Epoch 5, Batch 1400] loss: 0.04186373451495456
[Epoch 5, Batch 1500] loss: 0.03520392256294144
[Epoch 5, Batch 1600] loss: 0.04005429314882349
[Epoch 5, Batch 1700] loss: 0.04486767221300397
[Epoch 5, Batch 1800] loss: 0.03286909703629135
[Epoch 5, Batch 1900] loss: 0.03390132826903937
[Epoch 5, Batch 2000] loss: 0.023762434125055732
[Epoch 5, Batch 2100] loss: 0.053666497400336084
[Epoch 5, Batch 2200] loss: 0.03963701385036984
[Epoch 5, Batch 2300] loss: 0.036820765400516396
[Epoch 5, Batch 2400] loss: 0.02068381700108148
[Epoch 5, Batch 2500] loss: 0.021330374357185065
[Epoch 5, Batch 2600] loss: 0.049138980394236566
[Epoch 5, Batch 2700] loss: 0.04583933419512505
[Epoch 5, Batch 2800] loss: 0.03144373327588255
[Epoch 5, Batch 2900] loss: 0.025874021743802586
[Epoch 5, Batch 3000] loss: 0.03767557381261213
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9862
Overfitting: 0.0456
Best model saved at epoch 5 with validation loss: 0.0456
[Epoch 6, Batch 100] loss: 0.036631502541822555
[Epoch 6, Batch 200] loss: 0.02793107369732752
[Epoch 6, Batch 300] loss: 0.03685354473236657
[Epoch 6, Batch 400] loss: 0.023388839755989467
[Epoch 6, Batch 500] loss: 0.024929066270160546
[Epoch 6, Batch 600] loss: 0.017013529256455513
[Epoch 6, Batch 700] loss: 0.02580681745165748
[Epoch 6, Batch 800] loss: 0.034462075079839
[Epoch 6, Batch 900] loss: 0.043612580751282624
[Epoch 6, Batch 1000] loss: 0.04292974452682756
[Epoch 6, Batch 1100] loss: 0.027127094860352374
[Epoch 6, Batch 1200] loss: 0.014470485474412272
[Epoch 6, Batch 1300] loss: 0.03551344971842582
[Epoch 6, Batch 1400] loss: 0.033721002508107174
[Epoch 6, Batch 1500] loss: 0.06124636872585711
[Epoch 6, Batch 1600] loss: 0.030678929243563288
[Epoch 6, Batch 1700] loss: 0.02906517880780939
[Epoch 6, Batch 1800] loss: 0.028710670179052614
[Epoch 6, Batch 1900] loss: 0.03352506002590644
[Epoch 6, Batch 2000] loss: 0.016155609454194746
[Epoch 6, Batch 2100] loss: 0.032121764679363875
[Epoch 6, Batch 2200] loss: 0.05226533659869119
[Epoch 6, Batch 2300] loss: 0.022758788406190434
[Epoch 6, Batch 2400] loss: 0.036943700112327636
[Epoch 6, Batch 2500] loss: 0.026931204578156665
[Epoch 6, Batch 2600] loss: 0.023939536184838062
[Epoch 6, Batch 2700] loss: 0.027749487333667274
[Epoch 6, Batch 2800] loss: 0.02045640400125535
[Epoch 6, Batch 2900] loss: 0.035267650978705094
[Epoch 6, Batch 3000] loss: 0.03847861454864869
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0628
Validation Accuracy: 0.9820
Overfitting: 0.0628
[Epoch 7, Batch 100] loss: 0.02466643249500521
[Epoch 7, Batch 200] loss: 0.028347052833960332
[Epoch 7, Batch 300] loss: 0.022683190039338115
[Epoch 7, Batch 400] loss: 0.010809071108560601
[Epoch 7, Batch 500] loss: 0.027158567048888926
[Epoch 7, Batch 600] loss: 0.033554557913998334
[Epoch 7, Batch 700] loss: 0.03983541371295587
[Epoch 7, Batch 800] loss: 0.026452679200046986
[Epoch 7, Batch 900] loss: 0.028935801092375188
[Epoch 7, Batch 1000] loss: 0.011089697585093745
[Epoch 7, Batch 1100] loss: 0.027493514179047905
[Epoch 7, Batch 1200] loss: 0.02929380862195785
[Epoch 7, Batch 1300] loss: 0.01837583945632673
[Epoch 7, Batch 1400] loss: 0.04266525718954199
[Epoch 7, Batch 1500] loss: 0.035295556390437924
[Epoch 7, Batch 1600] loss: 0.029073184990223808
[Epoch 7, Batch 1700] loss: 0.02073749161790147
[Epoch 7, Batch 1800] loss: 0.030849924162703247
[Epoch 7, Batch 1900] loss: 0.02287456287815985
[Epoch 7, Batch 2000] loss: 0.031296471880856415
[Epoch 7, Batch 2100] loss: 0.03030029686763555
[Epoch 7, Batch 2200] loss: 0.033798369522255595
[Epoch 7, Batch 2300] loss: 0.034922506803169426
[Epoch 7, Batch 2400] loss: 0.041765937250324896
[Epoch 7, Batch 2500] loss: 0.03886390123539968
[Epoch 7, Batch 2600] loss: 0.030549247755652688
[Epoch 7, Batch 2700] loss: 0.03431250034127516
[Epoch 7, Batch 2800] loss: 0.030882296884804532
[Epoch 7, Batch 2900] loss: 0.030828918780857747
[Epoch 7, Batch 3000] loss: 0.03743976133965361
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0601
Validation Accuracy: 0.9838
Overfitting: 0.0601
[Epoch 8, Batch 100] loss: 0.02267279821424836
[Epoch 8, Batch 200] loss: 0.021304012467253414
[Epoch 8, Batch 300] loss: 0.015682480134114486
[Epoch 8, Batch 400] loss: 0.01927369827482039
[Epoch 8, Batch 500] loss: 0.03642042493562258
[Epoch 8, Batch 600] loss: 0.026885138404059036
[Epoch 8, Batch 700] loss: 0.013606226292853591
[Epoch 8, Batch 800] loss: 0.01965248078265972
[Epoch 8, Batch 900] loss: 0.04471155216942634
[Epoch 8, Batch 1000] loss: 0.025107401206109044
[Epoch 8, Batch 1100] loss: 0.01443699509939151
[Epoch 8, Batch 1200] loss: 0.011826833621799437
[Epoch 8, Batch 1300] loss: 0.02836244505831871
[Epoch 8, Batch 1400] loss: 0.025035366637576998
[Epoch 8, Batch 1500] loss: 0.05166037934051701
[Epoch 8, Batch 1600] loss: 0.028379144616865234
[Epoch 8, Batch 1700] loss: 0.038397093695953115
[Epoch 8, Batch 1800] loss: 0.044708779000059165
[Epoch 8, Batch 1900] loss: 0.03790378870471613
[Epoch 8, Batch 2000] loss: 0.01880690074201084
[Epoch 8, Batch 2100] loss: 0.018594759365560095
[Epoch 8, Batch 2200] loss: 0.017378008597293045
[Epoch 8, Batch 2300] loss: 0.018716250552740236
[Epoch 8, Batch 2400] loss: 0.05292593653678921
[Epoch 8, Batch 2500] loss: 0.04379438702567768
[Epoch 8, Batch 2600] loss: 0.028525834053680227
[Epoch 8, Batch 2700] loss: 0.027572872649152487
[Epoch 8, Batch 2800] loss: 0.03871039956717141
[Epoch 8, Batch 2900] loss: 0.033480582897891506
[Epoch 8, Batch 3000] loss: 0.026871536543967522
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0890
Validation Accuracy: 0.9760
Overfitting: 0.0890
[Epoch 9, Batch 100] loss: 0.02200248674328577
[Epoch 9, Batch 200] loss: 0.014468745245980017
[Epoch 9, Batch 300] loss: 0.010736844550517616
[Epoch 9, Batch 400] loss: 0.011681827984874644
[Epoch 9, Batch 500] loss: 0.015778684156280177
[Epoch 9, Batch 600] loss: 0.02263548250648455
[Epoch 9, Batch 700] loss: 0.022982017848359532
[Epoch 9, Batch 800] loss: 0.019721702231217365
[Epoch 9, Batch 900] loss: 0.03147339658037709
[Epoch 9, Batch 1000] loss: 0.034972838156434136
[Epoch 9, Batch 1100] loss: 0.0361354931342413
[Epoch 9, Batch 1200] loss: 0.03022397269299205
[Epoch 9, Batch 1300] loss: 0.01098466671178926
[Epoch 9, Batch 1400] loss: 0.024162870370005293
[Epoch 9, Batch 1500] loss: 0.01747254205114558
[Epoch 9, Batch 1600] loss: 0.04258742441710183
[Epoch 9, Batch 1700] loss: 0.029631461137937548
[Epoch 9, Batch 1800] loss: 0.01567346209999414
[Epoch 9, Batch 1900] loss: 0.019190305970564623
[Epoch 9, Batch 2000] loss: 0.05474632479154364
[Epoch 9, Batch 2100] loss: 0.013544647586154496
[Epoch 9, Batch 2200] loss: 0.012020657428888627
[Epoch 9, Batch 2300] loss: 0.025903066606812217
[Epoch 9, Batch 2400] loss: 0.023087268892272163
[Epoch 9, Batch 2500] loss: 0.038085466404820634
[Epoch 9, Batch 2600] loss: 0.031230343896741033
[Epoch 9, Batch 2700] loss: 0.015440957001358129
[Epoch 9, Batch 2800] loss: 0.028503318343478554
[Epoch 9, Batch 2900] loss: 0.013502944295248653
[Epoch 9, Batch 3000] loss: 0.017482363295048344
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9865
Overfitting: 0.0573
[Epoch 10, Batch 100] loss: 0.023461716422283986
[Epoch 10, Batch 200] loss: 0.014647992574334695
[Epoch 10, Batch 300] loss: 0.01281373877946642
[Epoch 10, Batch 400] loss: 0.015669559613853964
[Epoch 10, Batch 500] loss: 0.010309126788082495
[Epoch 10, Batch 600] loss: 0.0168225408095833
[Epoch 10, Batch 700] loss: 0.042302032876649916
[Epoch 10, Batch 800] loss: 0.02309074083355867
[Epoch 10, Batch 900] loss: 0.03170086398032851
[Epoch 10, Batch 1000] loss: 0.012713489390082487
[Epoch 10, Batch 1100] loss: 0.018481021665793948
[Epoch 10, Batch 1200] loss: 0.027635640387715057
[Epoch 10, Batch 1300] loss: 0.018263074533996927
[Epoch 10, Batch 1400] loss: 0.020122222858804478
[Epoch 10, Batch 1500] loss: 0.013473083377029961
[Epoch 10, Batch 1600] loss: 0.01556564863936586
[Epoch 10, Batch 1700] loss: 0.04050021694575903
[Epoch 10, Batch 1800] loss: 0.03793935768448023
[Epoch 10, Batch 1900] loss: 0.017856762091266774
[Epoch 10, Batch 2000] loss: 0.026382842892638224
[Epoch 10, Batch 2100] loss: 0.021918152699863636
[Epoch 10, Batch 2200] loss: 0.024030021020994923
[Epoch 10, Batch 2300] loss: 0.014673024219068792
[Epoch 10, Batch 2400] loss: 0.01684154966964911
[Epoch 10, Batch 2500] loss: 0.017408146469897474
[Epoch 10, Batch 2600] loss: 0.029642399915119598
[Epoch 10, Batch 2700] loss: 0.02483186417170998
[Epoch 10, Batch 2800] loss: 0.012963138664306371
[Epoch 10, Batch 2900] loss: 0.01992306182114131
[Epoch 10, Batch 3000] loss: 0.02104143839473366
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9882
Overfitting: 0.0603
[Epoch 11, Batch 100] loss: 0.019521530676170188
[Epoch 11, Batch 200] loss: 0.013107506673006242
[Epoch 11, Batch 300] loss: 0.03184809411864411
[Epoch 11, Batch 400] loss: 0.021281051287637638
[Epoch 11, Batch 500] loss: 0.011862125728880528
[Epoch 11, Batch 600] loss: 0.015343423247994679
[Epoch 11, Batch 700] loss: 0.01337068192989733
[Epoch 11, Batch 800] loss: 0.007094580704521576
[Epoch 11, Batch 900] loss: 0.022680035065052805
[Epoch 11, Batch 1000] loss: 0.03540330976272457
[Epoch 11, Batch 1100] loss: 0.011942645670820866
[Epoch 11, Batch 1200] loss: 0.024137170477413292
[Epoch 11, Batch 1300] loss: 0.014506718002997515
[Epoch 11, Batch 1400] loss: 0.014983225646950139
[Epoch 11, Batch 1500] loss: 0.02810941028124148
[Epoch 11, Batch 1600] loss: 0.01933450015049715
[Epoch 11, Batch 1700] loss: 0.033855072804240646
[Epoch 11, Batch 1800] loss: 0.02763459096266672
[Epoch 11, Batch 1900] loss: 0.01604394935257801
[Epoch 11, Batch 2000] loss: 0.04954767069432819
[Epoch 11, Batch 2100] loss: 0.029788633548027976
[Epoch 11, Batch 2200] loss: 0.00964065927509182
[Epoch 11, Batch 2300] loss: 0.030105916787689466
[Epoch 11, Batch 2400] loss: 0.020104310019981426
[Epoch 11, Batch 2500] loss: 0.04301534144425318
[Epoch 11, Batch 2600] loss: 0.009770184753078866
[Epoch 11, Batch 2700] loss: 0.022808523751929783
[Epoch 11, Batch 2800] loss: 0.018259900514610194
[Epoch 11, Batch 2900] loss: 0.03255457948263711
[Epoch 11, Batch 3000] loss: 0.028419492995036533
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0562
Validation Accuracy: 0.9866
Overfitting: 0.0562
[Epoch 12, Batch 100] loss: 0.020313469239530944
[Epoch 12, Batch 200] loss: 0.010695279961092865
[Epoch 12, Batch 300] loss: 0.018310692402464426
[Epoch 12, Batch 400] loss: 0.017420728860722365
[Epoch 12, Batch 500] loss: 0.026099495433548156
[Epoch 12, Batch 600] loss: 0.02637198071698037
[Epoch 12, Batch 700] loss: 0.025014729029729777
[Epoch 12, Batch 800] loss: 0.021923053698628788
[Epoch 12, Batch 900] loss: 0.010644060092892626
[Epoch 12, Batch 1000] loss: 0.040004617430220574
[Epoch 12, Batch 1100] loss: 0.017991502086973695
[Epoch 12, Batch 1200] loss: 0.03033154507762873
[Epoch 12, Batch 1300] loss: 0.017949006277686978
[Epoch 12, Batch 1400] loss: 0.026879358536788515
[Epoch 12, Batch 1500] loss: 0.019696933434355978
[Epoch 12, Batch 1600] loss: 0.03172564451772303
[Epoch 12, Batch 1700] loss: 0.029750344418803962
[Epoch 12, Batch 1800] loss: 0.01383803441680783
[Epoch 12, Batch 1900] loss: 0.01207121146888639
[Epoch 12, Batch 2000] loss: 0.009006062433395811
[Epoch 12, Batch 2100] loss: 0.021575950621308345
[Epoch 12, Batch 2200] loss: 0.02619232005225971
[Epoch 12, Batch 2300] loss: 0.016306094855117977
[Epoch 12, Batch 2400] loss: 0.02551770430650464
[Epoch 12, Batch 2500] loss: 0.02882982638184558
[Epoch 12, Batch 2600] loss: 0.031452200773968715
[Epoch 12, Batch 2700] loss: 0.014162590474038552
[Epoch 12, Batch 2800] loss: 0.01692752469019865
[Epoch 12, Batch 2900] loss: 0.007171305783971853
[Epoch 12, Batch 3000] loss: 0.01621945170511644
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9887
Overfitting: 0.0499
[Epoch 13, Batch 100] loss: 0.010850308190629505
[Epoch 13, Batch 200] loss: 0.023639031328952457
[Epoch 13, Batch 300] loss: 0.01605451888627215
[Epoch 13, Batch 400] loss: 0.0090387763934541
[Epoch 13, Batch 500] loss: 0.010499923736483367
[Epoch 13, Batch 600] loss: 0.014100025704265953
[Epoch 13, Batch 700] loss: 0.016117641232842886
[Epoch 13, Batch 800] loss: 0.014210932101107954
[Epoch 13, Batch 900] loss: 0.013533011734518964
[Epoch 13, Batch 1000] loss: 0.013166161930880662
[Epoch 13, Batch 1100] loss: 0.016532207018998334
[Epoch 13, Batch 1200] loss: 0.024774101833146035
[Epoch 13, Batch 1300] loss: 0.019856644138149873
[Epoch 13, Batch 1400] loss: 0.034633077447288656
[Epoch 13, Batch 1500] loss: 0.01625785812156897
[Epoch 13, Batch 1600] loss: 0.015117300525883568
[Epoch 13, Batch 1700] loss: 0.01696303860105985
[Epoch 13, Batch 1800] loss: 0.0287615119399776
[Epoch 13, Batch 1900] loss: 0.03662938281593938
[Epoch 13, Batch 2000] loss: 0.03285999885194613
[Epoch 13, Batch 2100] loss: 0.04641414548968214
[Epoch 13, Batch 2200] loss: 0.025019873124129503
[Epoch 13, Batch 2300] loss: 0.04622344241891028
[Epoch 13, Batch 2400] loss: 0.02041046851221438
[Epoch 13, Batch 2500] loss: 0.02059126975693644
[Epoch 13, Batch 2600] loss: 0.030799945701695038
[Epoch 13, Batch 2700] loss: 0.04530876974138266
[Epoch 13, Batch 2800] loss: 0.01520858107423713
[Epoch 13, Batch 2900] loss: 0.026860176980843916
[Epoch 13, Batch 3000] loss: 0.02165901150727077
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0791
Validation Accuracy: 0.9810
Overfitting: 0.0791
[Epoch 14, Batch 100] loss: 0.019314945491159818
[Epoch 14, Batch 200] loss: 0.020831963875715936
[Epoch 14, Batch 300] loss: 0.017986616383341245
[Epoch 14, Batch 400] loss: 0.012579352527650016
[Epoch 14, Batch 500] loss: 0.024574572221845017
[Epoch 14, Batch 600] loss: 0.03149509588486779
[Epoch 14, Batch 700] loss: 0.04932857197248268
[Epoch 14, Batch 800] loss: 0.0343488386880756
[Epoch 14, Batch 900] loss: 0.025795740529011867
[Epoch 14, Batch 1000] loss: 0.01162511849197763
[Epoch 14, Batch 1100] loss: 0.014007352962607128
[Epoch 14, Batch 1200] loss: 0.023852831524330754
[Epoch 14, Batch 1300] loss: 0.010618135309531844
[Epoch 14, Batch 1400] loss: 0.030834416138865776
[Epoch 14, Batch 1500] loss: 0.0073237560383063284
[Epoch 14, Batch 1600] loss: 0.009091273022381876
[Epoch 14, Batch 1700] loss: 0.014595157171453366
[Epoch 14, Batch 1800] loss: 0.024606488902177755
[Epoch 14, Batch 1900] loss: 0.023564883464341334
[Epoch 14, Batch 2000] loss: 0.013057450488800306
[Epoch 14, Batch 2100] loss: 0.017015172844121445
[Epoch 14, Batch 2200] loss: 0.012808263541356762
[Epoch 14, Batch 2300] loss: 0.016380611539945977
[Epoch 14, Batch 2400] loss: 0.03546050518797684
[Epoch 14, Batch 2500] loss: 0.01792850692351024
[Epoch 14, Batch 2600] loss: 0.02337383500721785
[Epoch 14, Batch 2700] loss: 0.027976502057926424
[Epoch 14, Batch 2800] loss: 0.02724223216970131
[Epoch 14, Batch 2900] loss: 0.038435044115173296
[Epoch 14, Batch 3000] loss: 0.011444384171353477
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9888
Overfitting: 0.0507
[Epoch 15, Batch 100] loss: 0.011739980820691755
[Epoch 15, Batch 200] loss: 0.020643887553890163
[Epoch 15, Batch 300] loss: 0.0064297145001654425
[Epoch 15, Batch 400] loss: 0.014737496955766503
[Epoch 15, Batch 500] loss: 0.009783921284825397
[Epoch 15, Batch 600] loss: 0.013807177674066154
[Epoch 15, Batch 700] loss: 0.022657081679124183
[Epoch 15, Batch 800] loss: 0.005873200610613658
[Epoch 15, Batch 900] loss: 0.005970436703871864
[Epoch 15, Batch 1000] loss: 0.0086721227464892
[Epoch 15, Batch 1100] loss: 0.006266594068745719
[Epoch 15, Batch 1200] loss: 0.03129357372647149
[Epoch 15, Batch 1300] loss: 0.022335494009568392
[Epoch 15, Batch 1400] loss: 0.01721862907700796
[Epoch 15, Batch 1500] loss: 0.02032759053763822
[Epoch 15, Batch 1600] loss: 0.019739510501550157
[Epoch 15, Batch 1700] loss: 0.022754916747067564
[Epoch 15, Batch 1800] loss: 0.0170115489974318
[Epoch 15, Batch 1900] loss: 0.036200734692474264
[Epoch 15, Batch 2000] loss: 0.012816747558198926
[Epoch 15, Batch 2100] loss: 0.034026713576803896
[Epoch 15, Batch 2200] loss: 0.01324918956754658
[Epoch 15, Batch 2300] loss: 0.015232935258923917
[Epoch 15, Batch 2400] loss: 0.030804397780463545
[Epoch 15, Batch 2500] loss: 0.011525959181460621
[Epoch 15, Batch 2600] loss: 0.009010569906685712
[Epoch 15, Batch 2700] loss: 0.02011206917402859
[Epoch 15, Batch 2800] loss: 0.01869839636412493
[Epoch 15, Batch 2900] loss: 0.011759839157938642
[Epoch 15, Batch 3000] loss: 0.010197780204386362
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9891
Overfitting: 0.0540
[Epoch 16, Batch 100] loss: 0.008113752353962127
[Epoch 16, Batch 200] loss: 0.014191394339087395
[Epoch 16, Batch 300] loss: 0.007882523260644234
[Epoch 16, Batch 400] loss: 0.0037115404735661175
[Epoch 16, Batch 500] loss: 0.010829509571772178
[Epoch 16, Batch 600] loss: 0.007555338486967993
[Epoch 16, Batch 700] loss: 0.006294031454766275
[Epoch 16, Batch 800] loss: 0.008812287391942241
[Epoch 16, Batch 900] loss: 0.02117832146183396
[Epoch 16, Batch 1000] loss: 0.019395280639460565
[Epoch 16, Batch 1100] loss: 0.037459296057757004
[Epoch 16, Batch 1200] loss: 0.013043324094911952
[Epoch 16, Batch 1300] loss: 0.005621601777019048
[Epoch 16, Batch 1400] loss: 0.006992226096057124
[Epoch 16, Batch 1500] loss: 0.010060683845652956
[Epoch 16, Batch 1600] loss: 0.010635925782800829
[Epoch 16, Batch 1700] loss: 0.013331062197587529
[Epoch 16, Batch 1800] loss: 0.012323275565700054
[Epoch 16, Batch 1900] loss: 0.010426789417086208
[Epoch 16, Batch 2000] loss: 0.0012414420484719057
[Epoch 16, Batch 2100] loss: 0.010609990479865336
[Epoch 16, Batch 2200] loss: 0.011161905768768849
[Epoch 16, Batch 2300] loss: 0.042719705487564784
[Epoch 16, Batch 2400] loss: 0.011248287651216344
[Epoch 16, Batch 2500] loss: 0.015595289730951834
[Epoch 16, Batch 2600] loss: 0.012061124495635909
[Epoch 16, Batch 2700] loss: 0.007893940877105194
[Epoch 16, Batch 2800] loss: 0.014768134779007411
[Epoch 16, Batch 2900] loss: 0.011172296548335847
[Epoch 16, Batch 3000] loss: 0.004988940079741577
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9887
Overfitting: 0.0570
[Epoch 17, Batch 100] loss: 0.002104140871316971
[Epoch 17, Batch 200] loss: 0.009988045764461294
[Epoch 17, Batch 300] loss: 0.011270486589661823
[Epoch 17, Batch 400] loss: 0.024789509179472122
[Epoch 17, Batch 500] loss: 0.0188769631565391
[Epoch 17, Batch 600] loss: 0.012642928220893216
[Epoch 17, Batch 700] loss: 0.019253654370498963
[Epoch 17, Batch 800] loss: 0.008804256422801035
[Epoch 17, Batch 900] loss: 0.008637678049354171
[Epoch 17, Batch 1000] loss: 0.042717800926098164
[Epoch 17, Batch 1100] loss: 0.023210557841429634
[Epoch 17, Batch 1200] loss: 0.028130687797397743
[Epoch 17, Batch 1300] loss: 0.019756177727671444
[Epoch 17, Batch 1400] loss: 0.02037594380644011
[Epoch 17, Batch 1500] loss: 0.014291187201285211
[Epoch 17, Batch 1600] loss: 0.008690066475472307
[Epoch 17, Batch 1700] loss: 0.026844505808356418
[Epoch 17, Batch 1800] loss: 0.024783487078006886
[Epoch 17, Batch 1900] loss: 0.017485331329244555
[Epoch 17, Batch 2000] loss: 0.02044824683081742
[Epoch 17, Batch 2100] loss: 0.02165908250986765
[Epoch 17, Batch 2200] loss: 0.01384092266339518
[Epoch 17, Batch 2300] loss: 0.030422345305223076
[Epoch 17, Batch 2400] loss: 0.014745039754812197
[Epoch 17, Batch 2500] loss: 0.009520747467537798
[Epoch 17, Batch 2600] loss: 0.021973302367541178
[Epoch 17, Batch 2700] loss: 0.02475011363135039
[Epoch 17, Batch 2800] loss: 0.025967466382450937
[Epoch 17, Batch 2900] loss: 0.03481927926514977
[Epoch 17, Batch 3000] loss: 0.026333332680724908
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9879
Overfitting: 0.0524
[Epoch 18, Batch 100] loss: 0.012545915489546644
[Epoch 18, Batch 200] loss: 0.0154359268821311
[Epoch 18, Batch 300] loss: 0.01583515901824549
[Epoch 18, Batch 400] loss: 0.010949234181031144
[Epoch 18, Batch 500] loss: 0.02053402638228171
[Epoch 18, Batch 600] loss: 0.007429845971464033
[Epoch 18, Batch 700] loss: 0.014644643718818063
[Epoch 18, Batch 800] loss: 0.030384475757173065
[Epoch 18, Batch 900] loss: 0.02970264650911969
[Epoch 18, Batch 1000] loss: 0.026950204864748317
[Epoch 18, Batch 1100] loss: 0.018674506306905942
[Epoch 18, Batch 1200] loss: 0.011189919116389219
[Epoch 18, Batch 1300] loss: 0.04137502366387039
[Epoch 18, Batch 1400] loss: 0.014947574103478587
[Epoch 18, Batch 1500] loss: 0.011511996154733736
[Epoch 18, Batch 1600] loss: 0.008949619924953573
[Epoch 18, Batch 1700] loss: 0.02184325493021523
[Epoch 18, Batch 1800] loss: 0.03412667029287678
[Epoch 18, Batch 1900] loss: 0.027612812131293227
[Epoch 18, Batch 2000] loss: 0.02113085767006922
[Epoch 18, Batch 2100] loss: 0.02606451155633806
[Epoch 18, Batch 2200] loss: 0.023280046498091737
[Epoch 18, Batch 2300] loss: 0.015457379404012438
[Epoch 18, Batch 2400] loss: 0.021356331456644687
[Epoch 18, Batch 2500] loss: 0.025609926279589957
[Epoch 18, Batch 2600] loss: 0.01397217697951568
[Epoch 18, Batch 2700] loss: 0.008624544368819218
[Epoch 18, Batch 2800] loss: 0.03264795708619286
[Epoch 18, Batch 2900] loss: 0.022263789172777743
[Epoch 18, Batch 3000] loss: 0.014991756310717945
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0757
Validation Accuracy: 0.9862
Overfitting: 0.0757
[Epoch 19, Batch 100] loss: 0.005902444454229503
[Epoch 19, Batch 200] loss: 0.012400880985161926
[Epoch 19, Batch 300] loss: 0.024990671434919315
[Epoch 19, Batch 400] loss: 0.012195131748856057
[Epoch 19, Batch 500] loss: 0.02492936052835212
[Epoch 19, Batch 600] loss: 0.011838544911427676
[Epoch 19, Batch 700] loss: 0.020303188933873385
[Epoch 19, Batch 800] loss: 0.015110953591579466
[Epoch 19, Batch 900] loss: 0.01887166778362189
[Epoch 19, Batch 1000] loss: 0.0098376281054097
[Epoch 19, Batch 1100] loss: 0.018557788220698933
[Epoch 19, Batch 1200] loss: 0.02834581115437393
[Epoch 19, Batch 1300] loss: 0.012445662300206361
[Epoch 19, Batch 1400] loss: 0.02586058560445819
[Epoch 19, Batch 1500] loss: 0.02611672518329186
[Epoch 19, Batch 1600] loss: 0.025129421141671174
[Epoch 19, Batch 1700] loss: 0.01236519111443954
[Epoch 19, Batch 1800] loss: 0.012695208093208805
[Epoch 19, Batch 1900] loss: 0.010919522015316475
[Epoch 19, Batch 2000] loss: 0.0035117436986592844
[Epoch 19, Batch 2100] loss: 0.005937957664515778
[Epoch 19, Batch 2200] loss: 0.007025284840308901
[Epoch 19, Batch 2300] loss: 0.020383404949903615
[Epoch 19, Batch 2400] loss: 0.011979870041025293
[Epoch 19, Batch 2500] loss: 0.007915298234570654
[Epoch 19, Batch 2600] loss: 0.025353042280688777
[Epoch 19, Batch 2700] loss: 0.02340090931026515
[Epoch 19, Batch 2800] loss: 0.01702287027755304
[Epoch 19, Batch 2900] loss: 0.017767360626987302
[Epoch 19, Batch 3000] loss: 0.012369381308287401
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0637
Validation Accuracy: 0.9871
Overfitting: 0.0637
[Epoch 20, Batch 100] loss: 0.009994627788509583
[Epoch 20, Batch 200] loss: 0.0018030641501264543
[Epoch 20, Batch 300] loss: 0.008532625722034802
[Epoch 20, Batch 400] loss: 0.0123211977808674
[Epoch 20, Batch 500] loss: 0.015891014539281195
[Epoch 20, Batch 600] loss: 0.018023925180507248
[Epoch 20, Batch 700] loss: 0.01879825189955049
[Epoch 20, Batch 800] loss: 0.016476434180962226
[Epoch 20, Batch 900] loss: 0.015172133314985957
[Epoch 20, Batch 1000] loss: 0.00836831606895689
[Epoch 20, Batch 1100] loss: 0.012736974791876743
[Epoch 20, Batch 1200] loss: 0.007144126482777624
[Epoch 20, Batch 1300] loss: 0.011180059004428982
[Epoch 20, Batch 1400] loss: 0.013435369126501064
[Epoch 20, Batch 1500] loss: 0.03626387959480897
[Epoch 20, Batch 1600] loss: 0.0253542278275596
[Epoch 20, Batch 1700] loss: 0.01304130822112498
[Epoch 20, Batch 1800] loss: 0.015631090127323544
[Epoch 20, Batch 1900] loss: 0.01530870533062993
[Epoch 20, Batch 2000] loss: 0.01676012884001016
[Epoch 20, Batch 2100] loss: 0.02360428615500382
[Epoch 20, Batch 2200] loss: 0.01934453421375082
[Epoch 20, Batch 2300] loss: 0.0125772789547204
[Epoch 20, Batch 2400] loss: 0.024862086997488275
[Epoch 20, Batch 2500] loss: 0.01761402124207006
[Epoch 20, Batch 2600] loss: 0.02063602666811867
[Epoch 20, Batch 2700] loss: 0.004970385139386906
[Epoch 20, Batch 2800] loss: 0.021828552668098453
[Epoch 20, Batch 2900] loss: 0.030132272343164887
[Epoch 20, Batch 3000] loss: 0.016267539399545967
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0803
Validation Accuracy: 0.9825
Overfitting: 0.0803
[Epoch 21, Batch 100] loss: 0.009183615413163721
[Epoch 21, Batch 200] loss: 0.014699546363961034
[Epoch 21, Batch 300] loss: 0.026244711633903108
[Epoch 21, Batch 400] loss: 0.008991223055863386
[Epoch 21, Batch 500] loss: 0.010118674211545926
[Epoch 21, Batch 600] loss: 0.014286013998536618
[Epoch 21, Batch 700] loss: 0.030390367669473194
[Epoch 21, Batch 800] loss: 0.015074324485114138
[Epoch 21, Batch 900] loss: 0.017541608179047753
[Epoch 21, Batch 1000] loss: 0.0038703108673336173
[Epoch 21, Batch 1100] loss: 0.008745080649323117
[Epoch 21, Batch 1200] loss: 0.022188737652486558
[Epoch 21, Batch 1300] loss: 0.018502476846243333
[Epoch 21, Batch 1400] loss: 0.015940553402772978
[Epoch 21, Batch 1500] loss: 0.011427776034279904
[Epoch 21, Batch 1600] loss: 0.03481640471419103
[Epoch 21, Batch 1700] loss: 0.02854356924129673
[Epoch 21, Batch 1800] loss: 0.04720984871560454
[Epoch 21, Batch 1900] loss: 0.023815592163669023
[Epoch 21, Batch 2000] loss: 0.03917401438487804
[Epoch 21, Batch 2100] loss: 0.025961051228046723
[Epoch 21, Batch 2200] loss: 0.020424962347141785
[Epoch 21, Batch 2300] loss: 0.011704008558840849
[Epoch 21, Batch 2400] loss: 0.024048004065605665
[Epoch 21, Batch 2500] loss: 0.01831160597219046
[Epoch 21, Batch 2600] loss: 0.025485792825148863
[Epoch 21, Batch 2700] loss: 0.007502835766154985
[Epoch 21, Batch 2800] loss: 0.024659962059730308
[Epoch 21, Batch 2900] loss: 0.010952220040530775
[Epoch 21, Batch 3000] loss: 0.012490987672728587
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0667
Validation Accuracy: 0.9861
Overfitting: 0.0667
[Epoch 22, Batch 100] loss: 0.008243815308197821
[Epoch 22, Batch 200] loss: 0.00595841027828036
[Epoch 22, Batch 300] loss: 0.005935144234448919
[Epoch 22, Batch 400] loss: 0.0017631663110582174
[Epoch 22, Batch 500] loss: 0.03253254154598302
[Epoch 22, Batch 600] loss: 0.02707912119154798
[Epoch 22, Batch 700] loss: 0.012422755068835617
[Epoch 22, Batch 800] loss: 0.02412999493768177
[Epoch 22, Batch 900] loss: 0.0341501990875588
[Epoch 22, Batch 1000] loss: 0.04404267420654302
[Epoch 22, Batch 1100] loss: 0.016507849895605612
[Epoch 22, Batch 1200] loss: 0.006933444376365965
[Epoch 22, Batch 1300] loss: 0.019130214419330892
[Epoch 22, Batch 1400] loss: 0.00583995591631079
[Epoch 22, Batch 1500] loss: 0.013076309049795141
[Epoch 22, Batch 1600] loss: 0.012057621388598404
[Epoch 22, Batch 1700] loss: 0.016477764521698135
[Epoch 22, Batch 1800] loss: 0.019023114778715954
[Epoch 22, Batch 1900] loss: 0.0034854062265886475
[Epoch 22, Batch 2000] loss: 0.002671487256828251
[Epoch 22, Batch 2100] loss: 0.004365976911843705
[Epoch 22, Batch 2200] loss: 0.010033595167169068
[Epoch 22, Batch 2300] loss: 0.006614190235568879
[Epoch 22, Batch 2400] loss: 0.014427732185749172
[Epoch 22, Batch 2500] loss: 0.019574492151113124
[Epoch 22, Batch 2600] loss: 0.035552981311917545
[Epoch 22, Batch 2700] loss: 0.02088636784620525
[Epoch 22, Batch 2800] loss: 0.012207508160597333
[Epoch 22, Batch 2900] loss: 0.013998447584129962
[Epoch 22, Batch 3000] loss: 0.014439381222749131
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0674
Validation Accuracy: 0.9849
Overfitting: 0.0674
[Epoch 23, Batch 100] loss: 0.008535922294671136
[Epoch 23, Batch 200] loss: 0.01142925605784483
[Epoch 23, Batch 300] loss: 0.005210450075968058
[Epoch 23, Batch 400] loss: 0.0169060187343352
[Epoch 23, Batch 500] loss: 0.011111364916266986
[Epoch 23, Batch 600] loss: 0.007564063221769146
[Epoch 23, Batch 700] loss: 0.005558702973404345
[Epoch 23, Batch 800] loss: 0.0025771221856961857
[Epoch 23, Batch 900] loss: 0.02506535578647525
[Epoch 23, Batch 1000] loss: 0.013589169820452014
[Epoch 23, Batch 1100] loss: 0.02505276200398565
[Epoch 23, Batch 1200] loss: 0.002955715718515779
[Epoch 23, Batch 1300] loss: 0.007965933121598745
[Epoch 23, Batch 1400] loss: 0.027534413191002437
[Epoch 23, Batch 1500] loss: 0.011405389620447721
[Epoch 23, Batch 1600] loss: 0.0211645371570324
[Epoch 23, Batch 1700] loss: 0.008023513414317724
[Epoch 23, Batch 1800] loss: 0.02356695136584463
[Epoch 23, Batch 1900] loss: 0.005929058107969931
[Epoch 23, Batch 2000] loss: 0.006758362504508897
[Epoch 23, Batch 2100] loss: 0.011148959374434563
[Epoch 23, Batch 2200] loss: 0.04004471726833241
[Epoch 23, Batch 2300] loss: 0.024568309982575514
[Epoch 23, Batch 2400] loss: 0.012190777982841175
[Epoch 23, Batch 2500] loss: 0.008742814283498622
[Epoch 23, Batch 2600] loss: 0.014147402112935619
[Epoch 23, Batch 2700] loss: 0.012262715909501641
[Epoch 23, Batch 2800] loss: 0.01092567573712696
[Epoch 23, Batch 2900] loss: 0.01699449250601242
[Epoch 23, Batch 3000] loss: 0.00570751530921981
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0624
Validation Accuracy: 0.9890
Overfitting: 0.0624
[Epoch 24, Batch 100] loss: 0.005769909018787427
[Epoch 24, Batch 200] loss: 0.020206380419010895
[Epoch 24, Batch 300] loss: 0.004696778503904455
[Epoch 24, Batch 400] loss: 0.002411072103499996
[Epoch 24, Batch 500] loss: 0.001752268559846133
[Epoch 24, Batch 600] loss: 0.0064146261544181194
[Epoch 24, Batch 700] loss: 0.009242082947125176
[Epoch 24, Batch 800] loss: 0.007831996302361826
[Epoch 24, Batch 900] loss: 0.003083470893489708
[Epoch 24, Batch 1000] loss: 0.001053386194534034
[Epoch 24, Batch 1100] loss: 0.0069776422116335675
[Epoch 24, Batch 1200] loss: 0.005800811595001423
[Epoch 24, Batch 1300] loss: 0.004179419237318549
[Epoch 24, Batch 1400] loss: 0.005777281921958859
[Epoch 24, Batch 1500] loss: 0.006930557400669306
[Epoch 24, Batch 1600] loss: 0.013371308461833844
[Epoch 24, Batch 1700] loss: 0.008702787846505765
[Epoch 24, Batch 1800] loss: 0.0034068444526769693
[Epoch 24, Batch 1900] loss: 0.0066953489599369045
[Epoch 24, Batch 2000] loss: 0.015977197280070903
[Epoch 24, Batch 2100] loss: 0.014543423285999366
[Epoch 24, Batch 2200] loss: 0.006606706661099491
[Epoch 24, Batch 2300] loss: 0.004061702132763445
[Epoch 24, Batch 2400] loss: 0.004687499717004972
[Epoch 24, Batch 2500] loss: 0.01366517527023559
[Epoch 24, Batch 2600] loss: 0.016920910207284198
[Epoch 24, Batch 2700] loss: 0.020488158060150127
[Epoch 24, Batch 2800] loss: 0.021598423288974097
[Epoch 24, Batch 2900] loss: 0.021530300566460197
[Epoch 24, Batch 3000] loss: 0.02594073322690011
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0704
Validation Accuracy: 0.9875
Overfitting: 0.0704
Fold 1 validation loss: 0.0704
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.896688263118267
[Epoch 1, Batch 200] loss: 0.5327034234255552
[Epoch 1, Batch 300] loss: 0.29149912906810643
[Epoch 1, Batch 400] loss: 0.2547537936270237
[Epoch 1, Batch 500] loss: 0.20826887169852853
[Epoch 1, Batch 600] loss: 0.16310385209973902
[Epoch 1, Batch 700] loss: 0.1993310304451734
[Epoch 1, Batch 800] loss: 0.17834044110961259
[Epoch 1, Batch 900] loss: 0.1492937783198431
[Epoch 1, Batch 1000] loss: 0.12668710540165193
[Epoch 1, Batch 1100] loss: 0.1230649202526547
[Epoch 1, Batch 1200] loss: 0.12636399367940612
[Epoch 1, Batch 1300] loss: 0.11666125430492684
[Epoch 1, Batch 1400] loss: 0.11301394764217548
[Epoch 1, Batch 1500] loss: 0.11294211897940841
[Epoch 1, Batch 1600] loss: 0.10727891005575657
[Epoch 1, Batch 1700] loss: 0.11474817504175007
[Epoch 1, Batch 1800] loss: 0.10428539083659416
[Epoch 1, Batch 1900] loss: 0.09081001201848267
[Epoch 1, Batch 2000] loss: 0.10140917257405818
[Epoch 1, Batch 2100] loss: 0.09922962217271561
[Epoch 1, Batch 2200] loss: 0.09933977224107365
[Epoch 1, Batch 2300] loss: 0.12133377919148187
[Epoch 1, Batch 2400] loss: 0.07185581960482523
[Epoch 1, Batch 2500] loss: 0.0892636885344109
[Epoch 1, Batch 2600] loss: 0.08736303098645294
[Epoch 1, Batch 2700] loss: 0.0768830581655493
[Epoch 1, Batch 2800] loss: 0.07860948781657498
[Epoch 1, Batch 2900] loss: 0.0913943062434555
[Epoch 1, Batch 3000] loss: 0.0840044330056844
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0807
Validation Accuracy: 0.9776
Overfitting: 0.0807
Best model saved at epoch 1 with validation loss: 0.0807
[Epoch 2, Batch 100] loss: 0.06541850225927191
[Epoch 2, Batch 200] loss: 0.0587289870724635
[Epoch 2, Batch 300] loss: 0.08117048708314542
[Epoch 2, Batch 400] loss: 0.07975103662465699
[Epoch 2, Batch 500] loss: 0.05742100824718364
[Epoch 2, Batch 600] loss: 0.09250537038315088
[Epoch 2, Batch 700] loss: 0.043563942233813574
[Epoch 2, Batch 800] loss: 0.074977587768808
[Epoch 2, Batch 900] loss: 0.04676969787586131
[Epoch 2, Batch 1000] loss: 0.07084694566510734
[Epoch 2, Batch 1100] loss: 0.06739935889287153
[Epoch 2, Batch 1200] loss: 0.06128762708642171
[Epoch 2, Batch 1300] loss: 0.05902569655991101
[Epoch 2, Batch 1400] loss: 0.06935332534791087
[Epoch 2, Batch 1500] loss: 0.03599906954194012
[Epoch 2, Batch 1600] loss: 0.0744541994685278
[Epoch 2, Batch 1700] loss: 0.06119862596067833
[Epoch 2, Batch 1800] loss: 0.05262765552884957
[Epoch 2, Batch 1900] loss: 0.05815555312401557
[Epoch 2, Batch 2000] loss: 0.059247696579550396
[Epoch 2, Batch 2100] loss: 0.10343986215535551
[Epoch 2, Batch 2200] loss: 0.05388960315380245
[Epoch 2, Batch 2300] loss: 0.06803169807346421
[Epoch 2, Batch 2400] loss: 0.03963412011551554
[Epoch 2, Batch 2500] loss: 0.07082378113591403
[Epoch 2, Batch 2600] loss: 0.058298459689176525
[Epoch 2, Batch 2700] loss: 0.05668962887219095
[Epoch 2, Batch 2800] loss: 0.07387634527811315
[Epoch 2, Batch 2900] loss: 0.0715675273249508
[Epoch 2, Batch 3000] loss: 0.06012572254549013
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0625
Validation Accuracy: 0.9835
Overfitting: 0.0625
Best model saved at epoch 2 with validation loss: 0.0625
[Epoch 3, Batch 100] loss: 0.03726799942436628
[Epoch 3, Batch 200] loss: 0.047485924113752846
[Epoch 3, Batch 300] loss: 0.06151696247368818
[Epoch 3, Batch 400] loss: 0.04125597235186433
[Epoch 3, Batch 500] loss: 0.05074854715821857
[Epoch 3, Batch 600] loss: 0.05412985101582308
[Epoch 3, Batch 700] loss: 0.07087137407623231
[Epoch 3, Batch 800] loss: 0.04202755071179126
[Epoch 3, Batch 900] loss: 0.0654265366690015
[Epoch 3, Batch 1000] loss: 0.04277330599819834
[Epoch 3, Batch 1100] loss: 0.0539757589175133
[Epoch 3, Batch 1200] loss: 0.030007667282989134
[Epoch 3, Batch 1300] loss: 0.048751724226585795
[Epoch 3, Batch 1400] loss: 0.044643388907516054
[Epoch 3, Batch 1500] loss: 0.05627013800956775
[Epoch 3, Batch 1600] loss: 0.056375607081427005
[Epoch 3, Batch 1700] loss: 0.04226469491732132
[Epoch 3, Batch 1800] loss: 0.0395089904958877
[Epoch 3, Batch 1900] loss: 0.06268973566515341
[Epoch 3, Batch 2000] loss: 0.0750322737838178
[Epoch 3, Batch 2100] loss: 0.02831006070206058
[Epoch 3, Batch 2200] loss: 0.034703968711055494
[Epoch 3, Batch 2300] loss: 0.0385711341129354
[Epoch 3, Batch 2400] loss: 0.039895014792764416
[Epoch 3, Batch 2500] loss: 0.04892060700194634
[Epoch 3, Batch 2600] loss: 0.03659152568980062
[Epoch 3, Batch 2700] loss: 0.049912568320141876
[Epoch 3, Batch 2800] loss: 0.04703687665587495
[Epoch 3, Batch 2900] loss: 0.04230107578697243
[Epoch 3, Batch 3000] loss: 0.023392855856218375
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0697
Validation Accuracy: 0.9827
Overfitting: 0.0697
[Epoch 4, Batch 100] loss: 0.030849347089133516
[Epoch 4, Batch 200] loss: 0.06342960762148322
[Epoch 4, Batch 300] loss: 0.037285103377798806
[Epoch 4, Batch 400] loss: 0.04456378312403103
[Epoch 4, Batch 500] loss: 0.03586804532984388
[Epoch 4, Batch 600] loss: 0.044946187090044984
[Epoch 4, Batch 700] loss: 0.03352564282133244
[Epoch 4, Batch 800] loss: 0.03218920160223206
[Epoch 4, Batch 900] loss: 0.03820139200635822
[Epoch 4, Batch 1000] loss: 0.051377767573067105
[Epoch 4, Batch 1100] loss: 0.03538027777045499
[Epoch 4, Batch 1200] loss: 0.04844584304271848
[Epoch 4, Batch 1300] loss: 0.04102536733076704
[Epoch 4, Batch 1400] loss: 0.062194133258381044
[Epoch 4, Batch 1500] loss: 0.0380400456632924
[Epoch 4, Batch 1600] loss: 0.04036466178833507
[Epoch 4, Batch 1700] loss: 0.037488410852056404
[Epoch 4, Batch 1800] loss: 0.0362944514132505
[Epoch 4, Batch 1900] loss: 0.02430446141158427
[Epoch 4, Batch 2000] loss: 0.03470187250926756
[Epoch 4, Batch 2100] loss: 0.045472746531922896
[Epoch 4, Batch 2200] loss: 0.030565957803919446
[Epoch 4, Batch 2300] loss: 0.0500855776894332
[Epoch 4, Batch 2400] loss: 0.0376373155813053
[Epoch 4, Batch 2500] loss: 0.04702570378984092
[Epoch 4, Batch 2600] loss: 0.040298190018729654
[Epoch 4, Batch 2700] loss: 0.055635917199888356
[Epoch 4, Batch 2800] loss: 0.021876623215603103
[Epoch 4, Batch 2900] loss: 0.03655611936248533
[Epoch 4, Batch 3000] loss: 0.028069469190177186
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0710
Validation Accuracy: 0.9814
Overfitting: 0.0710
[Epoch 5, Batch 100] loss: 0.02046903212984944
[Epoch 5, Batch 200] loss: 0.04048707082516103
[Epoch 5, Batch 300] loss: 0.03316138553465862
[Epoch 5, Batch 400] loss: 0.024366814643872203
[Epoch 5, Batch 500] loss: 0.022842997270736305
[Epoch 5, Batch 600] loss: 0.0320852257846218
[Epoch 5, Batch 700] loss: 0.022277216452871472
[Epoch 5, Batch 800] loss: 0.04231882808922137
[Epoch 5, Batch 900] loss: 0.03328603445328099
[Epoch 5, Batch 1000] loss: 0.030276332334360632
[Epoch 5, Batch 1100] loss: 0.028561037917006614
[Epoch 5, Batch 1200] loss: 0.03998500921950836
[Epoch 5, Batch 1300] loss: 0.03668969989892503
[Epoch 5, Batch 1400] loss: 0.03995933826050077
[Epoch 5, Batch 1500] loss: 0.02843166472327994
[Epoch 5, Batch 1600] loss: 0.05667470192391193
[Epoch 5, Batch 1700] loss: 0.022879136956435106
[Epoch 5, Batch 1800] loss: 0.02778317300857452
[Epoch 5, Batch 1900] loss: 0.03046821347792502
[Epoch 5, Batch 2000] loss: 0.03333577058209812
[Epoch 5, Batch 2100] loss: 0.03657511159213755
[Epoch 5, Batch 2200] loss: 0.03534823563889404
[Epoch 5, Batch 2300] loss: 0.025535938318607804
[Epoch 5, Batch 2400] loss: 0.035665492642583556
[Epoch 5, Batch 2500] loss: 0.03046588317357873
[Epoch 5, Batch 2600] loss: 0.040352367985706225
[Epoch 5, Batch 2700] loss: 0.034298893468858296
[Epoch 5, Batch 2800] loss: 0.033070481941067556
[Epoch 5, Batch 2900] loss: 0.047773065527217114
[Epoch 5, Batch 3000] loss: 0.015782108645798872
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9850
Overfitting: 0.0552
Best model saved at epoch 5 with validation loss: 0.0552
[Epoch 6, Batch 100] loss: 0.0270890996594062
[Epoch 6, Batch 200] loss: 0.020498078397841367
[Epoch 6, Batch 300] loss: 0.024466356080074546
[Epoch 6, Batch 400] loss: 0.029151814515657862
[Epoch 6, Batch 500] loss: 0.024062575986981756
[Epoch 6, Batch 600] loss: 0.02224945871989121
[Epoch 6, Batch 700] loss: 0.022158266901460593
[Epoch 6, Batch 800] loss: 0.018776937548054776
[Epoch 6, Batch 900] loss: 0.03070646411357302
[Epoch 6, Batch 1000] loss: 0.020266246342689555
[Epoch 6, Batch 1100] loss: 0.03762358387275981
[Epoch 6, Batch 1200] loss: 0.0258622278348048
[Epoch 6, Batch 1300] loss: 0.01919092881702454
[Epoch 6, Batch 1400] loss: 0.03734107036892738
[Epoch 6, Batch 1500] loss: 0.024937327195502804
[Epoch 6, Batch 1600] loss: 0.01361766602668922
[Epoch 6, Batch 1700] loss: 0.026451302650962134
[Epoch 6, Batch 1800] loss: 0.030085786563295188
[Epoch 6, Batch 1900] loss: 0.026238530725067905
[Epoch 6, Batch 2000] loss: 0.03218078049199903
[Epoch 6, Batch 2100] loss: 0.025499592458145343
[Epoch 6, Batch 2200] loss: 0.02391934126942033
[Epoch 6, Batch 2300] loss: 0.026996015066524704
[Epoch 6, Batch 2400] loss: 0.032750530353705475
[Epoch 6, Batch 2500] loss: 0.02780767017196922
[Epoch 6, Batch 2600] loss: 0.019396985689108987
[Epoch 6, Batch 2700] loss: 0.023693171172832875
[Epoch 6, Batch 2800] loss: 0.03760323899702683
[Epoch 6, Batch 2900] loss: 0.03547508774336165
[Epoch 6, Batch 3000] loss: 0.03651728068800367
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9861
Overfitting: 0.0507
Best model saved at epoch 6 with validation loss: 0.0507
[Epoch 7, Batch 100] loss: 0.02564405725560391
[Epoch 7, Batch 200] loss: 0.013468843489349638
[Epoch 7, Batch 300] loss: 0.014071093363143064
[Epoch 7, Batch 400] loss: 0.028027285373509583
[Epoch 7, Batch 500] loss: 0.0354244651603949
[Epoch 7, Batch 600] loss: 0.03677406858159884
[Epoch 7, Batch 700] loss: 0.02012417103614325
[Epoch 7, Batch 800] loss: 0.009217754273686296
[Epoch 7, Batch 900] loss: 0.01967138379667517
[Epoch 7, Batch 1000] loss: 0.03071905771495949
[Epoch 7, Batch 1100] loss: 0.02316011830140269
[Epoch 7, Batch 1200] loss: 0.021790772789481706
[Epoch 7, Batch 1300] loss: 0.01880989020011839
[Epoch 7, Batch 1400] loss: 0.013242260576917034
[Epoch 7, Batch 1500] loss: 0.06548531088357777
[Epoch 7, Batch 1600] loss: 0.037829659241979244
[Epoch 7, Batch 1700] loss: 0.03368141589231527
[Epoch 7, Batch 1800] loss: 0.035577815020842535
[Epoch 7, Batch 1900] loss: 0.021958595391840845
[Epoch 7, Batch 2000] loss: 0.028605754178061035
[Epoch 7, Batch 2100] loss: 0.01755386052869426
[Epoch 7, Batch 2200] loss: 0.02599830026392965
[Epoch 7, Batch 2300] loss: 0.03443292702537292
[Epoch 7, Batch 2400] loss: 0.022134901696895214
[Epoch 7, Batch 2500] loss: 0.016366660836097252
[Epoch 7, Batch 2600] loss: 0.009730314908063349
[Epoch 7, Batch 2700] loss: 0.019549901817147202
[Epoch 7, Batch 2800] loss: 0.041876911970206265
[Epoch 7, Batch 2900] loss: 0.03517834101450262
[Epoch 7, Batch 3000] loss: 0.025813512737649945
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9865
Overfitting: 0.0524
[Epoch 8, Batch 100] loss: 0.011341050996747981
[Epoch 8, Batch 200] loss: 0.011536937408480412
[Epoch 8, Batch 300] loss: 0.02335838997311612
[Epoch 8, Batch 400] loss: 0.011925346843557918
[Epoch 8, Batch 500] loss: 0.04354666485045072
[Epoch 8, Batch 600] loss: 0.019146368531789904
[Epoch 8, Batch 700] loss: 0.0401363298011313
[Epoch 8, Batch 800] loss: 0.03274792708178666
[Epoch 8, Batch 900] loss: 0.019109611744353286
[Epoch 8, Batch 1000] loss: 0.027686453409853585
[Epoch 8, Batch 1100] loss: 0.017238587176074134
[Epoch 8, Batch 1200] loss: 0.021587366414823634
[Epoch 8, Batch 1300] loss: 0.0177309782441705
[Epoch 8, Batch 1400] loss: 0.035385684758792876
[Epoch 8, Batch 1500] loss: 0.02266565144855349
[Epoch 8, Batch 1600] loss: 0.029931200893697676
[Epoch 8, Batch 1700] loss: 0.03574370202682985
[Epoch 8, Batch 1800] loss: 0.015753434084689388
[Epoch 8, Batch 1900] loss: 0.019277790187279324
[Epoch 8, Batch 2000] loss: 0.020510000325432428
[Epoch 8, Batch 2100] loss: 0.019618025948404352
[Epoch 8, Batch 2200] loss: 0.038290414089022985
[Epoch 8, Batch 2300] loss: 0.029091213211931973
[Epoch 8, Batch 2400] loss: 0.019806112395344827
[Epoch 8, Batch 2500] loss: 0.013447007573901146
[Epoch 8, Batch 2600] loss: 0.030758498128584506
[Epoch 8, Batch 2700] loss: 0.022430014383394335
[Epoch 8, Batch 2800] loss: 0.02525940939676957
[Epoch 8, Batch 2900] loss: 0.04513666690862692
[Epoch 8, Batch 3000] loss: 0.023683587889071874
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0616
Validation Accuracy: 0.9858
Overfitting: 0.0616
[Epoch 9, Batch 100] loss: 0.03377445281983683
[Epoch 9, Batch 200] loss: 0.02165782099399621
[Epoch 9, Batch 300] loss: 0.010749816377242497
[Epoch 9, Batch 400] loss: 0.011777293228230973
[Epoch 9, Batch 500] loss: 0.013739789606788691
[Epoch 9, Batch 600] loss: 0.00949551355305573
[Epoch 9, Batch 700] loss: 0.011558827796405779
[Epoch 9, Batch 800] loss: 0.005978063899882784
[Epoch 9, Batch 900] loss: 0.014231826296714871
[Epoch 9, Batch 1000] loss: 0.031118506840591635
[Epoch 9, Batch 1100] loss: 0.025079292706718662
[Epoch 9, Batch 1200] loss: 0.015431242760558348
[Epoch 9, Batch 1300] loss: 0.012115241777487986
[Epoch 9, Batch 1400] loss: 0.02016839899326101
[Epoch 9, Batch 1500] loss: 0.028107230326172614
[Epoch 9, Batch 1600] loss: 0.02214480053873558
[Epoch 9, Batch 1700] loss: 0.0465153612447466
[Epoch 9, Batch 1800] loss: 0.04921732350951061
[Epoch 9, Batch 1900] loss: 0.029160379417317018
[Epoch 9, Batch 2000] loss: 0.013197072434895745
[Epoch 9, Batch 2100] loss: 0.01318481253517632
[Epoch 9, Batch 2200] loss: 0.029597696652140258
[Epoch 9, Batch 2300] loss: 0.016924700289226848
[Epoch 9, Batch 2400] loss: 0.02084192412861057
[Epoch 9, Batch 2500] loss: 0.026889481561856884
[Epoch 9, Batch 2600] loss: 0.019874025715894278
[Epoch 9, Batch 2700] loss: 0.03762281832571375
[Epoch 9, Batch 2800] loss: 0.020116650132945325
[Epoch 9, Batch 2900] loss: 0.024665765259539965
[Epoch 9, Batch 3000] loss: 0.021856055223998964
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1002
Validation Accuracy: 0.9807
Overfitting: 0.1002
[Epoch 10, Batch 100] loss: 0.024035331491158444
[Epoch 10, Batch 200] loss: 0.022116266746465954
[Epoch 10, Batch 300] loss: 0.017449414032852245
[Epoch 10, Batch 400] loss: 0.012955522749493867
[Epoch 10, Batch 500] loss: 0.013374123294535564
[Epoch 10, Batch 600] loss: 0.01716292711026455
[Epoch 10, Batch 700] loss: 0.015812936353829344
[Epoch 10, Batch 800] loss: 0.037980661030329085
[Epoch 10, Batch 900] loss: 0.015817721618026324
[Epoch 10, Batch 1000] loss: 0.011908469224788405
[Epoch 10, Batch 1100] loss: 0.010740954070805877
[Epoch 10, Batch 1200] loss: 0.013649382193685522
[Epoch 10, Batch 1300] loss: 0.027629061520867425
[Epoch 10, Batch 1400] loss: 0.014636212292440404
[Epoch 10, Batch 1500] loss: 0.012258795638405217
[Epoch 10, Batch 1600] loss: 0.02805323364033498
[Epoch 10, Batch 1700] loss: 0.020361864724624184
[Epoch 10, Batch 1800] loss: 0.013087401117887794
[Epoch 10, Batch 1900] loss: 0.022305684193497655
[Epoch 10, Batch 2000] loss: 0.014281867050619894
[Epoch 10, Batch 2100] loss: 0.013267324442533663
[Epoch 10, Batch 2200] loss: 0.018312132899725383
[Epoch 10, Batch 2300] loss: 0.012509494928036683
[Epoch 10, Batch 2400] loss: 0.016135063772504735
[Epoch 10, Batch 2500] loss: 0.03513519843355652
[Epoch 10, Batch 2600] loss: 0.014498323144021014
[Epoch 10, Batch 2700] loss: 0.02139446289557469
[Epoch 10, Batch 2800] loss: 0.013402299736227405
[Epoch 10, Batch 2900] loss: 0.027509740712798703
[Epoch 10, Batch 3000] loss: 0.022653461796714965
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0667
Validation Accuracy: 0.9855
Overfitting: 0.0667
[Epoch 11, Batch 100] loss: 0.004167871270343539
[Epoch 11, Batch 200] loss: 0.02029919883475827
[Epoch 11, Batch 300] loss: 0.020192027468210652
[Epoch 11, Batch 400] loss: 0.009878348205210443
[Epoch 11, Batch 500] loss: 0.010775087255941571
[Epoch 11, Batch 600] loss: 0.015993328618625072
[Epoch 11, Batch 700] loss: 0.029550347683129682
[Epoch 11, Batch 800] loss: 0.029275780532453267
[Epoch 11, Batch 900] loss: 0.020889302512562723
[Epoch 11, Batch 1000] loss: 0.034131327992618025
[Epoch 11, Batch 1100] loss: 0.011774841373290884
[Epoch 11, Batch 1200] loss: 0.01596484678579827
[Epoch 11, Batch 1300] loss: 0.01514916488733519
[Epoch 11, Batch 1400] loss: 0.009156134843437372
[Epoch 11, Batch 1500] loss: 0.02273484585058313
[Epoch 11, Batch 1600] loss: 0.014547478053577798
[Epoch 11, Batch 1700] loss: 0.010427275396463785
[Epoch 11, Batch 1800] loss: 0.025657829931310515
[Epoch 11, Batch 1900] loss: 0.0258793801102955
[Epoch 11, Batch 2000] loss: 0.013764111055873655
[Epoch 11, Batch 2100] loss: 0.013130489428599504
[Epoch 11, Batch 2200] loss: 0.028839154227486716
[Epoch 11, Batch 2300] loss: 0.014650691414882431
[Epoch 11, Batch 2400] loss: 0.0231460759607333
[Epoch 11, Batch 2500] loss: 0.027364297338966708
[Epoch 11, Batch 2600] loss: 0.0327948074686833
[Epoch 11, Batch 2700] loss: 0.01590756035942434
[Epoch 11, Batch 2800] loss: 0.017692934119196195
[Epoch 11, Batch 2900] loss: 0.016438531098965967
[Epoch 11, Batch 3000] loss: 0.03929208483556508
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0801
Validation Accuracy: 0.9832
Overfitting: 0.0801
[Epoch 12, Batch 100] loss: 0.020977264904843765
[Epoch 12, Batch 200] loss: 0.02105219267188886
[Epoch 12, Batch 300] loss: 0.034806469919912215
[Epoch 12, Batch 400] loss: 0.026389947385898723
[Epoch 12, Batch 500] loss: 0.03513563020466108
[Epoch 12, Batch 600] loss: 0.014102095705198395
[Epoch 12, Batch 700] loss: 0.015072202648783985
[Epoch 12, Batch 800] loss: 0.015129946807958277
[Epoch 12, Batch 900] loss: 0.020477084593650476
[Epoch 12, Batch 1000] loss: 0.008005579792678503
[Epoch 12, Batch 1100] loss: 0.02311674530937637
[Epoch 12, Batch 1200] loss: 0.010838272821343135
[Epoch 12, Batch 1300] loss: 0.018749011887207477
[Epoch 12, Batch 1400] loss: 0.047676773778091215
[Epoch 12, Batch 1500] loss: 0.013890366077417582
[Epoch 12, Batch 1600] loss: 0.009426378884161295
[Epoch 12, Batch 1700] loss: 0.01475832680324899
[Epoch 12, Batch 1800] loss: 0.021627161580717598
[Epoch 12, Batch 1900] loss: 0.010636268019614974
[Epoch 12, Batch 2000] loss: 0.022349855758984346
[Epoch 12, Batch 2100] loss: 0.030552740021448557
[Epoch 12, Batch 2200] loss: 0.007300719910642215
[Epoch 12, Batch 2300] loss: 0.01776498085626258
[Epoch 12, Batch 2400] loss: 0.010828340753528209
[Epoch 12, Batch 2500] loss: 0.0334127001836174
[Epoch 12, Batch 2600] loss: 0.024082536164781912
[Epoch 12, Batch 2700] loss: 0.017415497479820487
[Epoch 12, Batch 2800] loss: 0.005984300689033048
[Epoch 12, Batch 2900] loss: 0.032970323228654765
[Epoch 12, Batch 3000] loss: 0.028060079337898714
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0870
Validation Accuracy: 0.9815
Overfitting: 0.0870
[Epoch 13, Batch 100] loss: 0.023477310959839313
[Epoch 13, Batch 200] loss: 0.020762787015200956
[Epoch 13, Batch 300] loss: 0.013085094675424215
[Epoch 13, Batch 400] loss: 0.0058515270172981105
[Epoch 13, Batch 500] loss: 0.01003857066404052
[Epoch 13, Batch 600] loss: 0.001982001985380748
[Epoch 13, Batch 700] loss: 0.014350364371160787
[Epoch 13, Batch 800] loss: 0.01596115162398604
[Epoch 13, Batch 900] loss: 0.016035777707744073
[Epoch 13, Batch 1000] loss: 0.01262398326913626
[Epoch 13, Batch 1100] loss: 0.004826953838845896
[Epoch 13, Batch 1200] loss: 0.011580618840494737
[Epoch 13, Batch 1300] loss: 0.00896538907733742
[Epoch 13, Batch 1400] loss: 0.0165410890547858
[Epoch 13, Batch 1500] loss: 0.02449106881477519
[Epoch 13, Batch 1600] loss: 0.006855163903956054
[Epoch 13, Batch 1700] loss: 0.0073975832225657715
[Epoch 13, Batch 1800] loss: 0.010299961493465588
[Epoch 13, Batch 1900] loss: 0.015146095429978744
[Epoch 13, Batch 2000] loss: 0.012771432446157006
[Epoch 13, Batch 2100] loss: 0.01761915065339096
[Epoch 13, Batch 2200] loss: 0.001815264317046541
[Epoch 13, Batch 2300] loss: 0.02027187514085
[Epoch 13, Batch 2400] loss: 0.027861263462822874
[Epoch 13, Batch 2500] loss: 0.02931404151179194
[Epoch 13, Batch 2600] loss: 0.014152358179644864
[Epoch 13, Batch 2700] loss: 0.017115845326797725
[Epoch 13, Batch 2800] loss: 0.021908014769871826
[Epoch 13, Batch 2900] loss: 0.014434796319200416
[Epoch 13, Batch 3000] loss: 0.01871858103798772
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9865
Overfitting: 0.0636
[Epoch 14, Batch 100] loss: 0.003958057390057661
[Epoch 14, Batch 200] loss: 0.01143144863842906
[Epoch 14, Batch 300] loss: 0.006170184224927305
[Epoch 14, Batch 400] loss: 0.004283694699177114
[Epoch 14, Batch 500] loss: 0.008971549428947654
[Epoch 14, Batch 600] loss: 0.016594149066313672
[Epoch 14, Batch 700] loss: 0.0226760791957183
[Epoch 14, Batch 800] loss: 0.017646357835773178
[Epoch 14, Batch 900] loss: 0.0279487755660557
[Epoch 14, Batch 1000] loss: 0.03945217015698745
[Epoch 14, Batch 1100] loss: 0.014157398583981826
[Epoch 14, Batch 1200] loss: 0.010890847480263801
[Epoch 14, Batch 1300] loss: 0.010810883312039152
[Epoch 14, Batch 1400] loss: 0.02542080087722921
[Epoch 14, Batch 1500] loss: 0.03994522714332928
[Epoch 14, Batch 1600] loss: 0.017142877714503017
[Epoch 14, Batch 1700] loss: 0.01956902096358533
[Epoch 14, Batch 1800] loss: 0.04431056586133586
[Epoch 14, Batch 1900] loss: 0.02021937606522165
[Epoch 14, Batch 2000] loss: 0.026544880526590334
[Epoch 14, Batch 2100] loss: 0.0279103092948737
[Epoch 14, Batch 2200] loss: 0.015267814598503833
[Epoch 14, Batch 2300] loss: 0.014620026925128683
[Epoch 14, Batch 2400] loss: 0.026131933895378552
[Epoch 14, Batch 2500] loss: 0.03104294984099397
[Epoch 14, Batch 2600] loss: 0.019052081858793955
[Epoch 14, Batch 2700] loss: 0.00778323217080966
[Epoch 14, Batch 2800] loss: 0.026341257814200592
[Epoch 14, Batch 2900] loss: 0.02505703429409003
[Epoch 14, Batch 3000] loss: 0.036190941036030606
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0653
Validation Accuracy: 0.9839
Overfitting: 0.0653
[Epoch 15, Batch 100] loss: 0.013054018054831432
[Epoch 15, Batch 200] loss: 0.014194930979789433
[Epoch 15, Batch 300] loss: 0.01505013962570615
[Epoch 15, Batch 400] loss: 0.0032394543746357128
[Epoch 15, Batch 500] loss: 0.011012012778320184
[Epoch 15, Batch 600] loss: 0.007531501986156783
[Epoch 15, Batch 700] loss: 0.009019888317050952
[Epoch 15, Batch 800] loss: 0.007435797557037747
[Epoch 15, Batch 900] loss: 0.005449962126655872
[Epoch 15, Batch 1000] loss: 0.0016175865841740844
[Epoch 15, Batch 1100] loss: 0.01085839879591358
[Epoch 15, Batch 1200] loss: 0.006196352518967627
[Epoch 15, Batch 1300] loss: 0.014323723517700416
[Epoch 15, Batch 1400] loss: 0.025319112071932038
[Epoch 15, Batch 1500] loss: 0.03214810594525374
[Epoch 15, Batch 1600] loss: 0.014032074050825117
[Epoch 15, Batch 1700] loss: 0.006911447403916427
[Epoch 15, Batch 1800] loss: 0.008309638498616377
[Epoch 15, Batch 1900] loss: 0.0048263610152710565
[Epoch 15, Batch 2000] loss: 0.015485001871255531
[Epoch 15, Batch 2100] loss: 0.032634103138032486
[Epoch 15, Batch 2200] loss: 0.028804498374506764
[Epoch 15, Batch 2300] loss: 0.009937970676327837
[Epoch 15, Batch 2400] loss: 0.028696864831307636
[Epoch 15, Batch 2500] loss: 0.028008459494578516
[Epoch 15, Batch 2600] loss: 0.03623816370748898
[Epoch 15, Batch 2700] loss: 0.015694070345061276
[Epoch 15, Batch 2800] loss: 0.015742146736060933
[Epoch 15, Batch 2900] loss: 0.017031984393466645
[Epoch 15, Batch 3000] loss: 0.025910672567109713
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0741
Validation Accuracy: 0.9840
Overfitting: 0.0741
[Epoch 16, Batch 100] loss: 0.006691043861450225
[Epoch 16, Batch 200] loss: 0.012076758988397955
[Epoch 16, Batch 300] loss: 0.015011524927621594
[Epoch 16, Batch 400] loss: 0.020040262717833882
[Epoch 16, Batch 500] loss: 0.004646046506241532
[Epoch 16, Batch 600] loss: 0.009511116875495773
[Epoch 16, Batch 700] loss: 0.009033318152781326
[Epoch 16, Batch 800] loss: 0.014939735521395719
[Epoch 16, Batch 900] loss: 0.006483876075174404
[Epoch 16, Batch 1000] loss: 0.0022551262811081997
[Epoch 16, Batch 1100] loss: 0.01440973122538921
[Epoch 16, Batch 1200] loss: 0.004891485484852893
[Epoch 16, Batch 1300] loss: 0.007456586884007796
[Epoch 16, Batch 1400] loss: 0.006104470740905814
[Epoch 16, Batch 1500] loss: 0.005252754092135277
[Epoch 16, Batch 1600] loss: 0.02217960783696725
[Epoch 16, Batch 1700] loss: 0.005138955600679047
[Epoch 16, Batch 1800] loss: 0.024531004294170097
[Epoch 16, Batch 1900] loss: 0.017091035585435465
[Epoch 16, Batch 2000] loss: 0.02421265173927246
[Epoch 16, Batch 2100] loss: 0.013674570453954815
[Epoch 16, Batch 2200] loss: 0.012503626007420988
[Epoch 16, Batch 2300] loss: 0.020007788581268605
[Epoch 16, Batch 2400] loss: 0.013182090291367032
[Epoch 16, Batch 2500] loss: 0.031212229107541987
[Epoch 16, Batch 2600] loss: 0.02858161701230488
[Epoch 16, Batch 2700] loss: 0.015481065952137385
[Epoch 16, Batch 2800] loss: 0.02102319843058126
[Epoch 16, Batch 2900] loss: 0.008299153108653172
[Epoch 16, Batch 3000] loss: 0.0053683730012670594
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0662
Validation Accuracy: 0.9860
Overfitting: 0.0662
[Epoch 17, Batch 100] loss: 0.0027297015571840434
[Epoch 17, Batch 200] loss: 0.007331248868399558
[Epoch 17, Batch 300] loss: 0.015029361541517261
[Epoch 17, Batch 400] loss: 0.013624469181904323
[Epoch 17, Batch 500] loss: 0.007777794987214644
[Epoch 17, Batch 600] loss: 0.015496008376763641
[Epoch 17, Batch 700] loss: 0.0348115489234196
[Epoch 17, Batch 800] loss: 0.028432792540988884
[Epoch 17, Batch 900] loss: 0.011616622827378898
[Epoch 17, Batch 1000] loss: 0.005733373953544554
[Epoch 17, Batch 1100] loss: 0.022806261952203588
[Epoch 17, Batch 1200] loss: 0.01219031263633866
[Epoch 17, Batch 1300] loss: 0.0028098589286330933
[Epoch 17, Batch 1400] loss: 0.008376388735553703
[Epoch 17, Batch 1500] loss: 0.008802996791581204
[Epoch 17, Batch 1600] loss: 0.012825405072452903
[Epoch 17, Batch 1700] loss: 0.005403747164707187
[Epoch 17, Batch 1800] loss: 0.013260330248427366
[Epoch 17, Batch 1900] loss: 0.004714323892892551
[Epoch 17, Batch 2000] loss: 0.015154432049693254
[Epoch 17, Batch 2100] loss: 0.010361648894631693
[Epoch 17, Batch 2200] loss: 0.014160299989180749
[Epoch 17, Batch 2300] loss: 0.004915659385216546
[Epoch 17, Batch 2400] loss: 0.006963409576529287
[Epoch 17, Batch 2500] loss: 0.004197953451043097
[Epoch 17, Batch 2600] loss: 0.004535820686485828
[Epoch 17, Batch 2700] loss: 0.012604444748600053
[Epoch 17, Batch 2800] loss: 0.01906056228762168
[Epoch 17, Batch 2900] loss: 0.018619574635561947
[Epoch 17, Batch 3000] loss: 0.017294164510321508
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9858
Overfitting: 0.0630
[Epoch 18, Batch 100] loss: 0.015023608341135244
[Epoch 18, Batch 200] loss: 0.007492511411273455
[Epoch 18, Batch 300] loss: 0.005923176208876977
[Epoch 18, Batch 400] loss: 0.006355931436368891
[Epoch 18, Batch 500] loss: 0.0077628484113836296
[Epoch 18, Batch 600] loss: 0.014631398678555386
[Epoch 18, Batch 700] loss: 0.011882434900145409
[Epoch 18, Batch 800] loss: 0.008455521796550368
[Epoch 18, Batch 900] loss: 0.021997542110853835
[Epoch 18, Batch 1000] loss: 0.004203143741177371
[Epoch 18, Batch 1100] loss: 0.00561646637165373
[Epoch 18, Batch 1200] loss: 0.03226702919366778
[Epoch 18, Batch 1300] loss: 0.02518464702705753
[Epoch 18, Batch 1400] loss: 0.014581043755501177
[Epoch 18, Batch 1500] loss: 0.011054838583584328
[Epoch 18, Batch 1600] loss: 0.011620621412358574
[Epoch 18, Batch 1700] loss: 0.010218738770471063
[Epoch 18, Batch 1800] loss: 0.01301219285606848
[Epoch 18, Batch 1900] loss: 0.02111213931773051
[Epoch 18, Batch 2000] loss: 0.010420144718689866
[Epoch 18, Batch 2100] loss: 0.006147968157734738
[Epoch 18, Batch 2200] loss: 0.01784181897305971
[Epoch 18, Batch 2300] loss: 0.011666569383360326
[Epoch 18, Batch 2400] loss: 0.004440020210750486
[Epoch 18, Batch 2500] loss: 0.006774323108338382
[Epoch 18, Batch 2600] loss: 0.013447608004575918
[Epoch 18, Batch 2700] loss: 0.008915783873298576
[Epoch 18, Batch 2800] loss: 0.012521437819937375
[Epoch 18, Batch 2900] loss: 0.019171517548446565
[Epoch 18, Batch 3000] loss: 0.021999507177971722
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0680
Validation Accuracy: 0.9874
Overfitting: 0.0680
[Epoch 19, Batch 100] loss: 0.005296547216489209
[Epoch 19, Batch 200] loss: 0.008628167775813647
[Epoch 19, Batch 300] loss: 0.01228492831502617
[Epoch 19, Batch 400] loss: 0.011398032633087416
[Epoch 19, Batch 500] loss: 0.014846508126414566
[Epoch 19, Batch 600] loss: 0.008371930691992815
[Epoch 19, Batch 700] loss: 0.004029779489994674
[Epoch 19, Batch 800] loss: 0.02440034585043918
[Epoch 19, Batch 900] loss: 0.00884174639852656
[Epoch 19, Batch 1000] loss: 0.00931976509437309
[Epoch 19, Batch 1100] loss: 0.007239989051039965
[Epoch 19, Batch 1200] loss: 0.00205511292684065
[Epoch 19, Batch 1300] loss: 0.0014966228934886593
[Epoch 19, Batch 1400] loss: 0.016159344155733467
[Epoch 19, Batch 1500] loss: 0.016402426964725266
[Epoch 19, Batch 1600] loss: 0.011875483350988954
[Epoch 19, Batch 1700] loss: 0.008575283183742144
[Epoch 19, Batch 1800] loss: 0.007266404036311718
[Epoch 19, Batch 1900] loss: 0.017361659436616782
[Epoch 19, Batch 2000] loss: 0.01860053673282913
[Epoch 19, Batch 2100] loss: 0.009211971488424951
[Epoch 19, Batch 2200] loss: 0.022559612857033996
[Epoch 19, Batch 2300] loss: 0.013359455530290592
[Epoch 19, Batch 2400] loss: 0.016077563982732385
[Epoch 19, Batch 2500] loss: 0.005075890498385003
[Epoch 19, Batch 2600] loss: 0.01333559358893669
[Epoch 19, Batch 2700] loss: 0.003273215666153373
[Epoch 19, Batch 2800] loss: 0.01254118818055666
[Epoch 19, Batch 2900] loss: 0.037899215198189076
[Epoch 19, Batch 3000] loss: 0.021507887654223908
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0871
Validation Accuracy: 0.9830
Overfitting: 0.0871
[Epoch 20, Batch 100] loss: 0.020194258096859877
[Epoch 20, Batch 200] loss: 0.0246011630828599
[Epoch 20, Batch 300] loss: 0.006738208761713835
[Epoch 20, Batch 400] loss: 0.009314033638808316
[Epoch 20, Batch 500] loss: 0.010478707506801417
[Epoch 20, Batch 600] loss: 0.005699656279288217
[Epoch 20, Batch 700] loss: 0.006581881547982178
[Epoch 20, Batch 800] loss: 0.006839564640792424
[Epoch 20, Batch 900] loss: 0.00542955224526092
[Epoch 20, Batch 1000] loss: 0.0064313743800692436
[Epoch 20, Batch 1100] loss: 0.01943911482916476
[Epoch 20, Batch 1200] loss: 0.025497075619125634
[Epoch 20, Batch 1300] loss: 0.01728895822868079
[Epoch 20, Batch 1400] loss: 0.00825045752620063
[Epoch 20, Batch 1500] loss: 0.0112382472116321
[Epoch 20, Batch 1600] loss: 0.03356718772530812
[Epoch 20, Batch 1700] loss: 0.017103886652172093
[Epoch 20, Batch 1800] loss: 0.010058302316953132
[Epoch 20, Batch 1900] loss: 0.002689210770901127
[Epoch 20, Batch 2000] loss: 0.00934017704714611
[Epoch 20, Batch 2100] loss: 0.0027103850576973045
[Epoch 20, Batch 2200] loss: 0.0029293635876069144
[Epoch 20, Batch 2300] loss: 0.005914734953224876
[Epoch 20, Batch 2400] loss: 0.01920282688947559
[Epoch 20, Batch 2500] loss: 0.009008445168554414
[Epoch 20, Batch 2600] loss: 0.02392222471001986
[Epoch 20, Batch 2700] loss: 0.007250522376462385
[Epoch 20, Batch 2800] loss: 0.006811687389614747
[Epoch 20, Batch 2900] loss: 0.0436930026449987
[Epoch 20, Batch 3000] loss: 0.011436909339656721
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0688
Validation Accuracy: 0.9871
Overfitting: 0.0688
[Epoch 21, Batch 100] loss: 0.016147503565893402
[Epoch 21, Batch 200] loss: 0.014241539979685455
[Epoch 21, Batch 300] loss: 0.0041704502984237024
[Epoch 21, Batch 400] loss: 0.00529862529886449
[Epoch 21, Batch 500] loss: 0.001905226801467066
[Epoch 21, Batch 600] loss: 0.00786628928002397
[Epoch 21, Batch 700] loss: 0.01054511265216691
[Epoch 21, Batch 800] loss: 0.010307361827811348
[Epoch 21, Batch 900] loss: 0.008238731831827049
[Epoch 21, Batch 1000] loss: 0.006073074224859933
[Epoch 21, Batch 1100] loss: 0.005477891613093026
[Epoch 21, Batch 1200] loss: 0.004063630990142362
[Epoch 21, Batch 1300] loss: 0.008766599146336453
[Epoch 21, Batch 1400] loss: 0.004734487946310608
[Epoch 21, Batch 1500] loss: 0.00102641580384212
[Epoch 21, Batch 1600] loss: 0.008953720375178373
[Epoch 21, Batch 1700] loss: 0.009026369943014983
[Epoch 21, Batch 1800] loss: 0.010703140461307213
[Epoch 21, Batch 1900] loss: 0.007687867298072213
[Epoch 21, Batch 2000] loss: 0.01002215769727531
[Epoch 21, Batch 2100] loss: 0.008315004675753771
[Epoch 21, Batch 2200] loss: 0.047706440797247965
[Epoch 21, Batch 2300] loss: 0.012449869945671242
[Epoch 21, Batch 2400] loss: 0.011604382472665034
[Epoch 21, Batch 2500] loss: 0.011298325228633664
[Epoch 21, Batch 2600] loss: 0.004632016416553673
[Epoch 21, Batch 2700] loss: 0.0020639415247220992
[Epoch 21, Batch 2800] loss: 0.004824465153383706
[Epoch 21, Batch 2900] loss: 0.014823749059218776
[Epoch 21, Batch 3000] loss: 0.006184520089563396
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0810
Validation Accuracy: 0.9872
Overfitting: 0.0810
[Epoch 22, Batch 100] loss: 0.009406440271940335
[Epoch 22, Batch 200] loss: 0.006109520247125842
[Epoch 22, Batch 300] loss: 0.008997648097707258
[Epoch 22, Batch 400] loss: 0.010529135208225529
[Epoch 22, Batch 500] loss: 0.0016433004722935297
[Epoch 22, Batch 600] loss: 0.0015277130027470066
[Epoch 22, Batch 700] loss: 0.0022782023672660314
[Epoch 22, Batch 800] loss: 0.009027616968664604
[Epoch 22, Batch 900] loss: 0.009079969194770738
[Epoch 22, Batch 1000] loss: 0.005868114171526551
[Epoch 22, Batch 1100] loss: 0.011615366110082235
[Epoch 22, Batch 1200] loss: 0.012710680412373021
[Epoch 22, Batch 1300] loss: 0.012599832052759425
[Epoch 22, Batch 1400] loss: 0.00989969980000707
[Epoch 22, Batch 1500] loss: 0.006254808927834792
[Epoch 22, Batch 1600] loss: 0.0050220616093292585
[Epoch 22, Batch 1700] loss: 0.004093242600198183
[Epoch 22, Batch 1800] loss: 0.01474135144949165
[Epoch 22, Batch 1900] loss: 0.03381532969670435
[Epoch 22, Batch 2000] loss: 0.06707796901523083
[Epoch 22, Batch 2100] loss: 0.03973374111793191
[Epoch 22, Batch 2200] loss: 0.027641596705038865
[Epoch 22, Batch 2300] loss: 0.010681482921315277
[Epoch 22, Batch 2400] loss: 0.013671176531980755
[Epoch 22, Batch 2500] loss: 0.005861405196667295
[Epoch 22, Batch 2600] loss: 0.004147111574833673
[Epoch 22, Batch 2700] loss: 0.020212857292925972
[Epoch 22, Batch 2800] loss: 0.0045105860047239335
[Epoch 22, Batch 2900] loss: 0.016424779345598602
[Epoch 22, Batch 3000] loss: 0.011283920316320887
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0833
Validation Accuracy: 0.9852
Overfitting: 0.0833
[Epoch 23, Batch 100] loss: 0.013526559989786038
[Epoch 23, Batch 200] loss: 0.00914914617545911
[Epoch 23, Batch 300] loss: 0.0161356583007383
[Epoch 23, Batch 400] loss: 0.008228763397130879
[Epoch 23, Batch 500] loss: 0.005246840139768452
[Epoch 23, Batch 600] loss: 0.0018598789596312982
[Epoch 23, Batch 700] loss: 0.004175947667938056
[Epoch 23, Batch 800] loss: 0.006746770759392997
[Epoch 23, Batch 900] loss: 0.025462416588596354
[Epoch 23, Batch 1000] loss: 0.018130530145792103
[Epoch 23, Batch 1100] loss: 0.006634878671260278
[Epoch 23, Batch 1200] loss: 0.017628040031731622
[Epoch 23, Batch 1300] loss: 0.007656888201765994
[Epoch 23, Batch 1400] loss: 0.003991804528589284
[Epoch 23, Batch 1500] loss: 0.0053837584392941555
[Epoch 23, Batch 1600] loss: 0.009172647593336651
[Epoch 23, Batch 1700] loss: 0.013627220051655403
[Epoch 23, Batch 1800] loss: 0.001293607326574815
[Epoch 23, Batch 1900] loss: 0.007542779118171974
[Epoch 23, Batch 2000] loss: 0.00837892911384886
[Epoch 23, Batch 2100] loss: 0.007599110075252038
[Epoch 23, Batch 2200] loss: 0.011656037593474276
[Epoch 23, Batch 2300] loss: 0.03093290538293953
[Epoch 23, Batch 2400] loss: 0.012016161799835352
[Epoch 23, Batch 2500] loss: 0.014471570880329363
[Epoch 23, Batch 2600] loss: 0.0060172215422001196
[Epoch 23, Batch 2700] loss: 0.003616922717312141
[Epoch 23, Batch 2800] loss: 0.003428290758889001
[Epoch 23, Batch 2900] loss: 0.013183603964082464
[Epoch 23, Batch 3000] loss: 0.01218902495430251
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0806
Validation Accuracy: 0.9872
Overfitting: 0.0806
[Epoch 24, Batch 100] loss: 0.0034228757154486987
[Epoch 24, Batch 200] loss: 0.007010924161743631
[Epoch 24, Batch 300] loss: 0.005162480310855338
[Epoch 24, Batch 400] loss: 0.002149453719898484
[Epoch 24, Batch 500] loss: 0.02892543507749471
[Epoch 24, Batch 600] loss: 0.014271188562731511
[Epoch 24, Batch 700] loss: 0.013108449640803639
[Epoch 24, Batch 800] loss: 0.018489652574676527
[Epoch 24, Batch 900] loss: 0.020631864089814867
[Epoch 24, Batch 1000] loss: 0.025652769351916054
[Epoch 24, Batch 1100] loss: 0.022291396080987
[Epoch 24, Batch 1200] loss: 0.012042809468355382
[Epoch 24, Batch 1300] loss: 0.02338581879403552
[Epoch 24, Batch 1400] loss: 0.01859339510622046
[Epoch 24, Batch 1500] loss: 0.004737186210524769
[Epoch 24, Batch 1600] loss: 0.007848162028047327
[Epoch 24, Batch 1700] loss: 0.01101956870353721
[Epoch 24, Batch 1800] loss: 0.03965068326454036
[Epoch 24, Batch 1900] loss: 0.019586429552214533
[Epoch 24, Batch 2000] loss: 0.02114485299420551
[Epoch 24, Batch 2100] loss: 0.009750419226674256
[Epoch 24, Batch 2200] loss: 0.019585339244615127
[Epoch 24, Batch 2300] loss: 0.009531498976756368
[Epoch 24, Batch 2400] loss: 0.008153506381180176
[Epoch 24, Batch 2500] loss: 0.0022245385934157548
[Epoch 24, Batch 2600] loss: 0.008797851018655968
[Epoch 24, Batch 2700] loss: 0.027881679801065352
[Epoch 24, Batch 2800] loss: 0.02368503825923277
[Epoch 24, Batch 2900] loss: 0.013784682665330696
[Epoch 24, Batch 3000] loss: 0.015165786906210812
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0905
Validation Accuracy: 0.9843
Overfitting: 0.0905
Fold 2 validation loss: 0.0905
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 1.9399546372890473
[Epoch 1, Batch 200] loss: 0.6254088543355465
[Epoch 1, Batch 300] loss: 0.30904777206480505
[Epoch 1, Batch 400] loss: 0.25508268002886325
[Epoch 1, Batch 500] loss: 0.2047643687017262
[Epoch 1, Batch 600] loss: 0.18147638398688287
[Epoch 1, Batch 700] loss: 0.2038675567880273
[Epoch 1, Batch 800] loss: 0.19268132824450732
[Epoch 1, Batch 900] loss: 0.14621298932936042
[Epoch 1, Batch 1000] loss: 0.13748226977768355
[Epoch 1, Batch 1100] loss: 0.11719820478581823
[Epoch 1, Batch 1200] loss: 0.12316213380894624
[Epoch 1, Batch 1300] loss: 0.1071544992888812
[Epoch 1, Batch 1400] loss: 0.10250433983484981
[Epoch 1, Batch 1500] loss: 0.11279072272183839
[Epoch 1, Batch 1600] loss: 0.1271361643774435
[Epoch 1, Batch 1700] loss: 0.11571123882080428
[Epoch 1, Batch 1800] loss: 0.11574899128056132
[Epoch 1, Batch 1900] loss: 0.11452833927236497
[Epoch 1, Batch 2000] loss: 0.08932535278756404
[Epoch 1, Batch 2100] loss: 0.12297850753180682
[Epoch 1, Batch 2200] loss: 0.08135265617805999
[Epoch 1, Batch 2300] loss: 0.11665314071171451
[Epoch 1, Batch 2400] loss: 0.10001089922443498
[Epoch 1, Batch 2500] loss: 0.08384091046289541
[Epoch 1, Batch 2600] loss: 0.1132305789401289
[Epoch 1, Batch 2700] loss: 0.09863655962049961
[Epoch 1, Batch 2800] loss: 0.07442346865267609
[Epoch 1, Batch 2900] loss: 0.10251469405950048
[Epoch 1, Batch 3000] loss: 0.08533135065925307
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0725
Validation Accuracy: 0.9792
Overfitting: 0.0725
Best model saved at epoch 1 with validation loss: 0.0725
[Epoch 2, Batch 100] loss: 0.06489920144211282
[Epoch 2, Batch 200] loss: 0.07458679669245612
[Epoch 2, Batch 300] loss: 0.06592474585573654
[Epoch 2, Batch 400] loss: 0.05334692354066647
[Epoch 2, Batch 500] loss: 0.07318348211381817
[Epoch 2, Batch 600] loss: 0.06786600926076063
[Epoch 2, Batch 700] loss: 0.06406952665187418
[Epoch 2, Batch 800] loss: 0.059248527787276545
[Epoch 2, Batch 900] loss: 0.06384014345356263
[Epoch 2, Batch 1000] loss: 0.0739232345041819
[Epoch 2, Batch 1100] loss: 0.06684803947107866
[Epoch 2, Batch 1200] loss: 0.061989539709029484
[Epoch 2, Batch 1300] loss: 0.08001500370141003
[Epoch 2, Batch 1400] loss: 0.059256219817252716
[Epoch 2, Batch 1500] loss: 0.061794138474360806
[Epoch 2, Batch 1600] loss: 0.04378188373346347
[Epoch 2, Batch 1700] loss: 0.08127322814631043
[Epoch 2, Batch 1800] loss: 0.06790749713029072
[Epoch 2, Batch 1900] loss: 0.06453645321540534
[Epoch 2, Batch 2000] loss: 0.05217254794828477
[Epoch 2, Batch 2100] loss: 0.06904437025266816
[Epoch 2, Batch 2200] loss: 0.06644701179204276
[Epoch 2, Batch 2300] loss: 0.07508229098166339
[Epoch 2, Batch 2400] loss: 0.057560446203278846
[Epoch 2, Batch 2500] loss: 0.06804312010077411
[Epoch 2, Batch 2600] loss: 0.07898650249058846
[Epoch 2, Batch 2700] loss: 0.055397228974034075
[Epoch 2, Batch 2800] loss: 0.05738649751954654
[Epoch 2, Batch 2900] loss: 0.05427953536593123
[Epoch 2, Batch 3000] loss: 0.06233089094661409
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0615
Validation Accuracy: 0.9815
Overfitting: 0.0615
Best model saved at epoch 2 with validation loss: 0.0615
[Epoch 3, Batch 100] loss: 0.04884619247721275
[Epoch 3, Batch 200] loss: 0.03747409895629971
[Epoch 3, Batch 300] loss: 0.040620061606896345
[Epoch 3, Batch 400] loss: 0.053933739385138325
[Epoch 3, Batch 500] loss: 0.05370942316672881
[Epoch 3, Batch 600] loss: 0.05426727079997363
[Epoch 3, Batch 700] loss: 0.024000964829501755
[Epoch 3, Batch 800] loss: 0.057676563384538894
[Epoch 3, Batch 900] loss: 0.057423546922946114
[Epoch 3, Batch 1000] loss: 0.04684443674901559
[Epoch 3, Batch 1100] loss: 0.04837319602294883
[Epoch 3, Batch 1200] loss: 0.039839515303356166
[Epoch 3, Batch 1300] loss: 0.06913271583391178
[Epoch 3, Batch 1400] loss: 0.0735641879591276
[Epoch 3, Batch 1500] loss: 0.028582562102565136
[Epoch 3, Batch 1600] loss: 0.048763975451656734
[Epoch 3, Batch 1700] loss: 0.0618142531781632
[Epoch 3, Batch 1800] loss: 0.03687031418296101
[Epoch 3, Batch 1900] loss: 0.04087711688775016
[Epoch 3, Batch 2000] loss: 0.03633518778638972
[Epoch 3, Batch 2100] loss: 0.04946611825042055
[Epoch 3, Batch 2200] loss: 0.05478054561877798
[Epoch 3, Batch 2300] loss: 0.0419264710671996
[Epoch 3, Batch 2400] loss: 0.05541375831762707
[Epoch 3, Batch 2500] loss: 0.04174753327151848
[Epoch 3, Batch 2600] loss: 0.03166999958029919
[Epoch 3, Batch 2700] loss: 0.04724287179611565
[Epoch 3, Batch 2800] loss: 0.03739885203929589
[Epoch 3, Batch 2900] loss: 0.04563595032146622
[Epoch 3, Batch 3000] loss: 0.06567612833707244
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0565
Validation Accuracy: 0.9832
Overfitting: 0.0565
Best model saved at epoch 3 with validation loss: 0.0565
[Epoch 4, Batch 100] loss: 0.02978846692254592
[Epoch 4, Batch 200] loss: 0.02554388591352108
[Epoch 4, Batch 300] loss: 0.023079589607214075
[Epoch 4, Batch 400] loss: 0.04900861807338515
[Epoch 4, Batch 500] loss: 0.028328469851676346
[Epoch 4, Batch 600] loss: 0.03812893449470721
[Epoch 4, Batch 700] loss: 0.038212980373173194
[Epoch 4, Batch 800] loss: 0.027573969445602416
[Epoch 4, Batch 900] loss: 0.027075777528407344
[Epoch 4, Batch 1000] loss: 0.03760354042027757
[Epoch 4, Batch 1100] loss: 0.0371569110854216
[Epoch 4, Batch 1200] loss: 0.03988950855037103
[Epoch 4, Batch 1300] loss: 0.048060224508208196
[Epoch 4, Batch 1400] loss: 0.03507579682620417
[Epoch 4, Batch 1500] loss: 0.03188435396225032
[Epoch 4, Batch 1600] loss: 0.04640266036549292
[Epoch 4, Batch 1700] loss: 0.03965887215497787
[Epoch 4, Batch 1800] loss: 0.05120197647676832
[Epoch 4, Batch 1900] loss: 0.03519525566018274
[Epoch 4, Batch 2000] loss: 0.06335806389051868
[Epoch 4, Batch 2100] loss: 0.047353844063509315
[Epoch 4, Batch 2200] loss: 0.029298149608530367
[Epoch 4, Batch 2300] loss: 0.018283154157579702
[Epoch 4, Batch 2400] loss: 0.049659562080105385
[Epoch 4, Batch 2500] loss: 0.029701670069734974
[Epoch 4, Batch 2600] loss: 0.0554114539737202
[Epoch 4, Batch 2700] loss: 0.04954376206442248
[Epoch 4, Batch 2800] loss: 0.042539419468084816
[Epoch 4, Batch 2900] loss: 0.03627834066191099
[Epoch 4, Batch 3000] loss: 0.047999189729780484
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0654
Validation Accuracy: 0.9818
Overfitting: 0.0654
[Epoch 5, Batch 100] loss: 0.027156939309988956
[Epoch 5, Batch 200] loss: 0.034863587721929434
[Epoch 5, Batch 300] loss: 0.027772730034685084
[Epoch 5, Batch 400] loss: 0.040377169078501536
[Epoch 5, Batch 500] loss: 0.023220258707192444
[Epoch 5, Batch 600] loss: 0.029128056148110773
[Epoch 5, Batch 700] loss: 0.029117472455654932
[Epoch 5, Batch 800] loss: 0.029034493063300033
[Epoch 5, Batch 900] loss: 0.04441792475143302
[Epoch 5, Batch 1000] loss: 0.040657970320135066
[Epoch 5, Batch 1100] loss: 0.02433491008840065
[Epoch 5, Batch 1200] loss: 0.024134611902318283
[Epoch 5, Batch 1300] loss: 0.018357830609893426
[Epoch 5, Batch 1400] loss: 0.0363371010253195
[Epoch 5, Batch 1500] loss: 0.040185834617823275
[Epoch 5, Batch 1600] loss: 0.015628246272081016
[Epoch 5, Batch 1700] loss: 0.03977078500109201
[Epoch 5, Batch 1800] loss: 0.021462260049688667
[Epoch 5, Batch 1900] loss: 0.01661705550312945
[Epoch 5, Batch 2000] loss: 0.02512382650141262
[Epoch 5, Batch 2100] loss: 0.016666900428418785
[Epoch 5, Batch 2200] loss: 0.03734697881876855
[Epoch 5, Batch 2300] loss: 0.020691724247990352
[Epoch 5, Batch 2400] loss: 0.050464143399412936
[Epoch 5, Batch 2500] loss: 0.04765460186074051
[Epoch 5, Batch 2600] loss: 0.04255953571391501
[Epoch 5, Batch 2700] loss: 0.029711985448502672
[Epoch 5, Batch 2800] loss: 0.03158436385969253
[Epoch 5, Batch 2900] loss: 0.03813386024408828
[Epoch 5, Batch 3000] loss: 0.03266780146524979
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0709
Validation Accuracy: 0.9828
Overfitting: 0.0709
[Epoch 6, Batch 100] loss: 0.03340943246016195
[Epoch 6, Batch 200] loss: 0.027956998084782754
[Epoch 6, Batch 300] loss: 0.020695964070962417
[Epoch 6, Batch 400] loss: 0.02838496077986747
[Epoch 6, Batch 500] loss: 0.03411551837697061
[Epoch 6, Batch 600] loss: 0.030115927064243805
[Epoch 6, Batch 700] loss: 0.0344150950508083
[Epoch 6, Batch 800] loss: 0.05559832409955561
[Epoch 6, Batch 900] loss: 0.04039867555413366
[Epoch 6, Batch 1000] loss: 0.020194112126009713
[Epoch 6, Batch 1100] loss: 0.02008495391834913
[Epoch 6, Batch 1200] loss: 0.036460405380667
[Epoch 6, Batch 1300] loss: 0.023738532483839662
[Epoch 6, Batch 1400] loss: 0.03154921313952855
[Epoch 6, Batch 1500] loss: 0.04829505777906888
[Epoch 6, Batch 1600] loss: 0.03877216182074335
[Epoch 6, Batch 1700] loss: 0.025644008235035473
[Epoch 6, Batch 1800] loss: 0.024733417021643618
[Epoch 6, Batch 1900] loss: 0.023577516497259695
[Epoch 6, Batch 2000] loss: 0.014586671409541624
[Epoch 6, Batch 2100] loss: 0.021291131762716305
[Epoch 6, Batch 2200] loss: 0.040911015824596005
[Epoch 6, Batch 2300] loss: 0.02161432728993873
[Epoch 6, Batch 2400] loss: 0.023466936588730506
[Epoch 6, Batch 2500] loss: 0.03150561397465481
[Epoch 6, Batch 2600] loss: 0.013834512184857886
[Epoch 6, Batch 2700] loss: 0.02631736541550822
[Epoch 6, Batch 2800] loss: 0.03942356669282276
[Epoch 6, Batch 2900] loss: 0.044520057957615794
[Epoch 6, Batch 3000] loss: 0.03210797378558709
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0658
Validation Accuracy: 0.9819
Overfitting: 0.0658
[Epoch 7, Batch 100] loss: 0.019501124237335715
[Epoch 7, Batch 200] loss: 0.014547064910429697
[Epoch 7, Batch 300] loss: 0.03071685027267904
[Epoch 7, Batch 400] loss: 0.01546754891798173
[Epoch 7, Batch 500] loss: 0.028200675576697448
[Epoch 7, Batch 600] loss: 0.025562966613974822
[Epoch 7, Batch 700] loss: 0.020310051966698096
[Epoch 7, Batch 800] loss: 0.024181733451910076
[Epoch 7, Batch 900] loss: 0.01698250924280728
[Epoch 7, Batch 1000] loss: 0.024285580010327976
[Epoch 7, Batch 1100] loss: 0.01059982487455045
[Epoch 7, Batch 1200] loss: 0.03680745347477682
[Epoch 7, Batch 1300] loss: 0.04048703992926221
[Epoch 7, Batch 1400] loss: 0.03333326681540712
[Epoch 7, Batch 1500] loss: 0.022068521276337377
[Epoch 7, Batch 1600] loss: 0.020126370079344723
[Epoch 7, Batch 1700] loss: 0.04628247281181757
[Epoch 7, Batch 1800] loss: 0.02855016009624251
[Epoch 7, Batch 1900] loss: 0.01957728503245562
[Epoch 7, Batch 2000] loss: 0.028336680535762753
[Epoch 7, Batch 2100] loss: 0.03445063265151248
[Epoch 7, Batch 2200] loss: 0.027215890626494002
[Epoch 7, Batch 2300] loss: 0.026029844186405172
[Epoch 7, Batch 2400] loss: 0.04422121987502578
[Epoch 7, Batch 2500] loss: 0.04208205177619675
[Epoch 7, Batch 2600] loss: 0.01856995232774352
[Epoch 7, Batch 2700] loss: 0.019372324042216178
[Epoch 7, Batch 2800] loss: 0.033617782993608784
[Epoch 7, Batch 2900] loss: 0.018259940041457413
[Epoch 7, Batch 3000] loss: 0.04350520952477836
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0555
Validation Accuracy: 0.9866
Overfitting: 0.0555
Best model saved at epoch 7 with validation loss: 0.0555
[Epoch 8, Batch 100] loss: 0.017782683883501703
[Epoch 8, Batch 200] loss: 0.01393223776671789
[Epoch 8, Batch 300] loss: 0.014196224317788619
[Epoch 8, Batch 400] loss: 0.011691933301261202
[Epoch 8, Batch 500] loss: 0.016601199144101315
[Epoch 8, Batch 600] loss: 0.014286089546906168
[Epoch 8, Batch 700] loss: 0.03742610330517323
[Epoch 8, Batch 800] loss: 0.03017924011401874
[Epoch 8, Batch 900] loss: 0.016270508239388165
[Epoch 8, Batch 1000] loss: 0.023139278587659646
[Epoch 8, Batch 1100] loss: 0.03802284995433183
[Epoch 8, Batch 1200] loss: 0.021837268876279268
[Epoch 8, Batch 1300] loss: 0.013432203454551655
[Epoch 8, Batch 1400] loss: 0.025184827805260282
[Epoch 8, Batch 1500] loss: 0.029278807084212984
[Epoch 8, Batch 1600] loss: 0.016122690288984814
[Epoch 8, Batch 1700] loss: 0.01795689771960042
[Epoch 8, Batch 1800] loss: 0.020285840842179822
[Epoch 8, Batch 1900] loss: 0.02583629734549163
[Epoch 8, Batch 2000] loss: 0.023794096186120443
[Epoch 8, Batch 2100] loss: 0.019061751043062715
[Epoch 8, Batch 2200] loss: 0.030515202267214932
[Epoch 8, Batch 2300] loss: 0.03616556067981037
[Epoch 8, Batch 2400] loss: 0.031189193172426712
[Epoch 8, Batch 2500] loss: 0.030483049291585757
[Epoch 8, Batch 2600] loss: 0.020638684899078042
[Epoch 8, Batch 2700] loss: 0.017296242465246508
[Epoch 8, Batch 2800] loss: 0.023995310322528666
[Epoch 8, Batch 2900] loss: 0.024432308603248812
[Epoch 8, Batch 3000] loss: 0.028792715245498927
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0889
Validation Accuracy: 0.9792
Overfitting: 0.0889
[Epoch 9, Batch 100] loss: 0.019844131028920627
[Epoch 9, Batch 200] loss: 0.02953689228488372
[Epoch 9, Batch 300] loss: 0.01673872456442723
[Epoch 9, Batch 400] loss: 0.018789276872038272
[Epoch 9, Batch 500] loss: 0.017667222376061317
[Epoch 9, Batch 600] loss: 0.009704647021001165
[Epoch 9, Batch 700] loss: 0.017067740106294877
[Epoch 9, Batch 800] loss: 0.015086484762042503
[Epoch 9, Batch 900] loss: 0.017346224626226387
[Epoch 9, Batch 1000] loss: 0.028297037014094712
[Epoch 9, Batch 1100] loss: 0.017108513409357328
[Epoch 9, Batch 1200] loss: 0.01284582027380253
[Epoch 9, Batch 1300] loss: 0.02715404292026733
[Epoch 9, Batch 1400] loss: 0.012384078584474274
[Epoch 9, Batch 1500] loss: 0.00878912249905138
[Epoch 9, Batch 1600] loss: 0.014930288433246659
[Epoch 9, Batch 1700] loss: 0.041327500202442025
[Epoch 9, Batch 1800] loss: 0.021354537796245267
[Epoch 9, Batch 1900] loss: 0.015477423153382687
[Epoch 9, Batch 2000] loss: 0.0229836690772089
[Epoch 9, Batch 2100] loss: 0.01779230624818524
[Epoch 9, Batch 2200] loss: 0.02825279996274759
[Epoch 9, Batch 2300] loss: 0.023337020874181463
[Epoch 9, Batch 2400] loss: 0.03442509921463625
[Epoch 9, Batch 2500] loss: 0.030970872932748535
[Epoch 9, Batch 2600] loss: 0.017028085845674924
[Epoch 9, Batch 2700] loss: 0.020681327277037552
[Epoch 9, Batch 2800] loss: 0.012889467910301846
[Epoch 9, Batch 2900] loss: 0.015365759795033683
[Epoch 9, Batch 3000] loss: 0.015126480014804428
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0645
Validation Accuracy: 0.9848
Overfitting: 0.0645
[Epoch 10, Batch 100] loss: 0.013577259863336905
[Epoch 10, Batch 200] loss: 0.011862111479194937
[Epoch 10, Batch 300] loss: 0.01323251325523664
[Epoch 10, Batch 400] loss: 0.011479476408543974
[Epoch 10, Batch 500] loss: 0.014923082778654475
[Epoch 10, Batch 600] loss: 0.019556579961787293
[Epoch 10, Batch 700] loss: 0.025445452074920924
[Epoch 10, Batch 800] loss: 0.026372368332454245
[Epoch 10, Batch 900] loss: 0.0060572365705050405
[Epoch 10, Batch 1000] loss: 0.02668817082123539
[Epoch 10, Batch 1100] loss: 0.016043657267268828
[Epoch 10, Batch 1200] loss: 0.02639364101375577
[Epoch 10, Batch 1300] loss: 0.009586337276793415
[Epoch 10, Batch 1400] loss: 0.016116176867467403
[Epoch 10, Batch 1500] loss: 0.011319153497597654
[Epoch 10, Batch 1600] loss: 0.033348847996812765
[Epoch 10, Batch 1700] loss: 0.019376148339715654
[Epoch 10, Batch 1800] loss: 0.018696978584318912
[Epoch 10, Batch 1900] loss: 0.009352218086371166
[Epoch 10, Batch 2000] loss: 0.014547875074933358
[Epoch 10, Batch 2100] loss: 0.013895481879640244
[Epoch 10, Batch 2200] loss: 0.027998030711525033
[Epoch 10, Batch 2300] loss: 0.03357200666682616
[Epoch 10, Batch 2400] loss: 0.022838504797200017
[Epoch 10, Batch 2500] loss: 0.028903102432182665
[Epoch 10, Batch 2600] loss: 0.03060774277442306
[Epoch 10, Batch 2700] loss: 0.016415741498058196
[Epoch 10, Batch 2800] loss: 0.05181519484312048
[Epoch 10, Batch 2900] loss: 0.02723032329467969
[Epoch 10, Batch 3000] loss: 0.016923026503167193
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0644
Validation Accuracy: 0.9857
Overfitting: 0.0644
[Epoch 11, Batch 100] loss: 0.009356891509889493
[Epoch 11, Batch 200] loss: 0.01392925513821524
[Epoch 11, Batch 300] loss: 0.015165719819318042
[Epoch 11, Batch 400] loss: 0.01826115444098775
[Epoch 11, Batch 500] loss: 0.011733936237094298
[Epoch 11, Batch 600] loss: 0.008397806924961629
[Epoch 11, Batch 700] loss: 0.017551374593195987
[Epoch 11, Batch 800] loss: 0.030829434788450846
[Epoch 11, Batch 900] loss: 0.01452748951412559
[Epoch 11, Batch 1000] loss: 0.011120984213080831
[Epoch 11, Batch 1100] loss: 0.02087245515069469
[Epoch 11, Batch 1200] loss: 0.021792874435868543
[Epoch 11, Batch 1300] loss: 0.01394741734266475
[Epoch 11, Batch 1400] loss: 0.01709221944390805
[Epoch 11, Batch 1500] loss: 0.01305061060998753
[Epoch 11, Batch 1600] loss: 0.020173131200062713
[Epoch 11, Batch 1700] loss: 0.0333470866806606
[Epoch 11, Batch 1800] loss: 0.03976401961609554
[Epoch 11, Batch 1900] loss: 0.03017732875788269
[Epoch 11, Batch 2000] loss: 0.022919038853139853
[Epoch 11, Batch 2100] loss: 0.02079688259489899
[Epoch 11, Batch 2200] loss: 0.009781332588221971
[Epoch 11, Batch 2300] loss: 0.02116003382148392
[Epoch 11, Batch 2400] loss: 0.01944828270231824
[Epoch 11, Batch 2500] loss: 0.011295018277750727
[Epoch 11, Batch 2600] loss: 0.022342518069451554
[Epoch 11, Batch 2700] loss: 0.016812896212423423
[Epoch 11, Batch 2800] loss: 0.017065421527896057
[Epoch 11, Batch 2900] loss: 0.017609661718424104
[Epoch 11, Batch 3000] loss: 0.02671663722625084
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0728
Validation Accuracy: 0.9857
Overfitting: 0.0728
[Epoch 12, Batch 100] loss: 0.018301629321139715
[Epoch 12, Batch 200] loss: 0.006742252287510548
[Epoch 12, Batch 300] loss: 0.009574511906149467
[Epoch 12, Batch 400] loss: 0.010651477329066239
[Epoch 12, Batch 500] loss: 0.010815231192754729
[Epoch 12, Batch 600] loss: 0.0035921596094419072
[Epoch 12, Batch 700] loss: 0.03842520561175235
[Epoch 12, Batch 800] loss: 0.019325080350658937
[Epoch 12, Batch 900] loss: 0.024525361310945043
[Epoch 12, Batch 1000] loss: 0.01752628652930504
[Epoch 12, Batch 1100] loss: 0.04362098435400753
[Epoch 12, Batch 1200] loss: 0.021902479096266348
[Epoch 12, Batch 1300] loss: 0.027345629279367074
[Epoch 12, Batch 1400] loss: 0.0333241126827857
[Epoch 12, Batch 1500] loss: 0.022647494138814183
[Epoch 12, Batch 1600] loss: 0.030846655284452674
[Epoch 12, Batch 1700] loss: 0.02234559725227655
[Epoch 12, Batch 1800] loss: 0.030889239761397534
[Epoch 12, Batch 1900] loss: 0.024588219382503666
[Epoch 12, Batch 2000] loss: 0.045483480209777556
[Epoch 12, Batch 2100] loss: 0.020908626386770806
[Epoch 12, Batch 2200] loss: 0.01865889651784016
[Epoch 12, Batch 2300] loss: 0.009351728253595227
[Epoch 12, Batch 2400] loss: 0.020801436989279408
[Epoch 12, Batch 2500] loss: 0.020554395473989188
[Epoch 12, Batch 2600] loss: 0.013576184264518076
[Epoch 12, Batch 2700] loss: 0.010357028789723853
[Epoch 12, Batch 2800] loss: 0.010567308293460496
[Epoch 12, Batch 2900] loss: 0.01196250854130696
[Epoch 12, Batch 3000] loss: 0.008188234189196598
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0866
Validation Accuracy: 0.9840
Overfitting: 0.0866
[Epoch 13, Batch 100] loss: 0.013191202435734222
[Epoch 13, Batch 200] loss: 0.002426288436855746
[Epoch 13, Batch 300] loss: 0.015518583761087106
[Epoch 13, Batch 400] loss: 0.006519464007356248
[Epoch 13, Batch 500] loss: 0.013300942859325282
[Epoch 13, Batch 600] loss: 0.02402152146924138
[Epoch 13, Batch 700] loss: 0.014558614850125195
[Epoch 13, Batch 800] loss: 0.015023425240340095
[Epoch 13, Batch 900] loss: 0.02793914760678817
[Epoch 13, Batch 1000] loss: 0.014720685313443766
[Epoch 13, Batch 1100] loss: 0.011195620132252553
[Epoch 13, Batch 1200] loss: 0.009950530857092708
[Epoch 13, Batch 1300] loss: 0.04348544992897765
[Epoch 13, Batch 1400] loss: 0.021660753020677815
[Epoch 13, Batch 1500] loss: 0.011614235582040066
[Epoch 13, Batch 1600] loss: 0.006631321125127272
[Epoch 13, Batch 1700] loss: 0.006589973415586279
[Epoch 13, Batch 1800] loss: 0.0067353976519719085
[Epoch 13, Batch 1900] loss: 0.009199819205005469
[Epoch 13, Batch 2000] loss: 0.019752877758291446
[Epoch 13, Batch 2100] loss: 0.01606670645541513
[Epoch 13, Batch 2200] loss: 0.022075124973845277
[Epoch 13, Batch 2300] loss: 0.011855394449105888
[Epoch 13, Batch 2400] loss: 0.014967103373390236
[Epoch 13, Batch 2500] loss: 0.016402510533765593
[Epoch 13, Batch 2600] loss: 0.015962682085149192
[Epoch 13, Batch 2700] loss: 0.03169442983467773
[Epoch 13, Batch 2800] loss: 0.01821227395739164
[Epoch 13, Batch 2900] loss: 0.029734670492494217
[Epoch 13, Batch 3000] loss: 0.031108515137374296
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0913
Validation Accuracy: 0.9828
Overfitting: 0.0913
[Epoch 14, Batch 100] loss: 0.00972444803556257
[Epoch 14, Batch 200] loss: 0.0164342631144133
[Epoch 14, Batch 300] loss: 0.006685693268927598
[Epoch 14, Batch 400] loss: 0.005180308447264376
[Epoch 14, Batch 500] loss: 0.024343546604870384
[Epoch 14, Batch 600] loss: 0.01269336037404411
[Epoch 14, Batch 700] loss: 0.02781587041378508
[Epoch 14, Batch 800] loss: 0.02656408178998788
[Epoch 14, Batch 900] loss: 0.010660291243016285
[Epoch 14, Batch 1000] loss: 0.03822921209555928
[Epoch 14, Batch 1100] loss: 0.051824852301178906
[Epoch 14, Batch 1200] loss: 0.01457392199387023
[Epoch 14, Batch 1300] loss: 0.02094725746251072
[Epoch 14, Batch 1400] loss: 0.01704602918107028
[Epoch 14, Batch 1500] loss: 0.019006918722696185
[Epoch 14, Batch 1600] loss: 0.013165021218803403
[Epoch 14, Batch 1700] loss: 0.010335606450794045
[Epoch 14, Batch 1800] loss: 0.03812094060859806
[Epoch 14, Batch 1900] loss: 0.018126027931903224
[Epoch 14, Batch 2000] loss: 0.021161754978895147
[Epoch 14, Batch 2100] loss: 0.022204564419565854
[Epoch 14, Batch 2200] loss: 0.022863696954923397
[Epoch 14, Batch 2300] loss: 0.017297687715369534
[Epoch 14, Batch 2400] loss: 0.022947388752560798
[Epoch 14, Batch 2500] loss: 0.021474651352569082
[Epoch 14, Batch 2600] loss: 0.034463428450189876
[Epoch 14, Batch 2700] loss: 0.025908599264725895
[Epoch 14, Batch 2800] loss: 0.027449049562408304
[Epoch 14, Batch 2900] loss: 0.019445143916917686
[Epoch 14, Batch 3000] loss: 0.023458296068442054
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0649
Validation Accuracy: 0.9843
Overfitting: 0.0649
[Epoch 15, Batch 100] loss: 0.013887584307798163
[Epoch 15, Batch 200] loss: 0.018539517610088582
[Epoch 15, Batch 300] loss: 0.006275879157062145
[Epoch 15, Batch 400] loss: 0.005962200133599169
[Epoch 15, Batch 500] loss: 0.004902831725934362
[Epoch 15, Batch 600] loss: 0.003277533262968131
[Epoch 15, Batch 700] loss: 0.002069831640744404
[Epoch 15, Batch 800] loss: 0.0333128420311267
[Epoch 15, Batch 900] loss: 0.013935995068891316
[Epoch 15, Batch 1000] loss: 0.011819661213536494
[Epoch 15, Batch 1100] loss: 0.003535420695921374
[Epoch 15, Batch 1200] loss: 0.0037266571963304696
[Epoch 15, Batch 1300] loss: 0.01106232680072749
[Epoch 15, Batch 1400] loss: 0.006919671324845993
[Epoch 15, Batch 1500] loss: 0.007979535052308506
[Epoch 15, Batch 1600] loss: 0.013957913470234793
[Epoch 15, Batch 1700] loss: 0.0043794522310796995
[Epoch 15, Batch 1800] loss: 0.0065100903285043275
[Epoch 15, Batch 1900] loss: 0.014348356133226754
[Epoch 15, Batch 2000] loss: 0.015620515483567167
[Epoch 15, Batch 2100] loss: 0.005840518077292849
[Epoch 15, Batch 2200] loss: 0.006789284178801154
[Epoch 15, Batch 2300] loss: 0.004279954805642449
[Epoch 15, Batch 2400] loss: 0.02517552081237617
[Epoch 15, Batch 2500] loss: 0.019688321823312826
[Epoch 15, Batch 2600] loss: 0.013885428337782174
[Epoch 15, Batch 2700] loss: 0.025318859343414955
[Epoch 15, Batch 2800] loss: 0.008585478393618437
[Epoch 15, Batch 2900] loss: 0.023473951195848344
[Epoch 15, Batch 3000] loss: 0.012904237127709575
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0803
Validation Accuracy: 0.9866
Overfitting: 0.0803
[Epoch 16, Batch 100] loss: 0.0053646580995104194
[Epoch 16, Batch 200] loss: 0.009937196418923912
[Epoch 16, Batch 300] loss: 0.004008329444371413
[Epoch 16, Batch 400] loss: 0.007922880217537677
[Epoch 16, Batch 500] loss: 0.0055443287422192265
[Epoch 16, Batch 600] loss: 0.004225191020317292
[Epoch 16, Batch 700] loss: 0.00955217489947299
[Epoch 16, Batch 800] loss: 0.013610658674069583
[Epoch 16, Batch 900] loss: 0.008858291374621116
[Epoch 16, Batch 1000] loss: 0.00852603152038938
[Epoch 16, Batch 1100] loss: 0.02247597609681975
[Epoch 16, Batch 1200] loss: 0.02775532297479943
[Epoch 16, Batch 1300] loss: 0.005311286634881682
[Epoch 16, Batch 1400] loss: 0.021689402525289333
[Epoch 16, Batch 1500] loss: 0.017139912706641027
[Epoch 16, Batch 1600] loss: 0.020381966945784948
[Epoch 16, Batch 1700] loss: 0.010260055851965735
[Epoch 16, Batch 1800] loss: 0.01110870341497801
[Epoch 16, Batch 1900] loss: 0.032719390123186254
[Epoch 16, Batch 2000] loss: 0.01711199441072125
[Epoch 16, Batch 2100] loss: 0.012638375382988544
[Epoch 16, Batch 2200] loss: 0.0173463450684296
[Epoch 16, Batch 2300] loss: 0.01587916636872073
[Epoch 16, Batch 2400] loss: 0.024971981073642836
[Epoch 16, Batch 2500] loss: 0.018290719482209568
[Epoch 16, Batch 2600] loss: 0.01196405660503895
[Epoch 16, Batch 2700] loss: 0.028365675362040644
[Epoch 16, Batch 2800] loss: 0.02549356543096209
[Epoch 16, Batch 2900] loss: 0.01609852619576472
[Epoch 16, Batch 3000] loss: 0.01742296449294882
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0689
Validation Accuracy: 0.9872
Overfitting: 0.0689
[Epoch 17, Batch 100] loss: 0.006374272080672796
[Epoch 17, Batch 200] loss: 0.006458120636138158
[Epoch 17, Batch 300] loss: 0.005644038575373025
[Epoch 17, Batch 400] loss: 0.008872964106718778
[Epoch 17, Batch 500] loss: 0.006835196682420057
[Epoch 17, Batch 600] loss: 0.02606529343814806
[Epoch 17, Batch 700] loss: 0.004488642727496028
[Epoch 17, Batch 800] loss: 0.011817135760608792
[Epoch 17, Batch 900] loss: 0.00786881224618325
[Epoch 17, Batch 1000] loss: 0.022997091097203475
[Epoch 17, Batch 1100] loss: 0.02617366568442826
[Epoch 17, Batch 1200] loss: 0.020869321694726675
[Epoch 17, Batch 1300] loss: 0.01657415412802081
[Epoch 17, Batch 1400] loss: 0.014517600286507885
[Epoch 17, Batch 1500] loss: 0.026015938373717233
[Epoch 17, Batch 1600] loss: 0.010984284243444992
[Epoch 17, Batch 1700] loss: 0.009575442990291694
[Epoch 17, Batch 1800] loss: 0.016975673017614597
[Epoch 17, Batch 1900] loss: 0.01712091024998976
[Epoch 17, Batch 2000] loss: 0.01049402136386234
[Epoch 17, Batch 2100] loss: 0.028302905795851246
[Epoch 17, Batch 2200] loss: 0.020604122796508903
[Epoch 17, Batch 2300] loss: 0.027478786575496007
[Epoch 17, Batch 2400] loss: 0.00745147165372122
[Epoch 17, Batch 2500] loss: 0.027068881797656128
[Epoch 17, Batch 2600] loss: 0.025319564186998614
[Epoch 17, Batch 2700] loss: 0.011832522583152314
[Epoch 17, Batch 2800] loss: 0.02674931803607084
[Epoch 17, Batch 2900] loss: 0.0025964514212531453
[Epoch 17, Batch 3000] loss: 0.018496560215107642
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0937
Validation Accuracy: 0.9842
Overfitting: 0.0937
[Epoch 18, Batch 100] loss: 0.014254527629061004
[Epoch 18, Batch 200] loss: 0.03207373509711555
[Epoch 18, Batch 300] loss: 0.005186524321753185
[Epoch 18, Batch 400] loss: 0.008921352521454505
[Epoch 18, Batch 500] loss: 0.002901999839008411
[Epoch 18, Batch 600] loss: 0.0030232584039557864
[Epoch 18, Batch 700] loss: 0.007890202548336762
[Epoch 18, Batch 800] loss: 0.019586326589879233
[Epoch 18, Batch 900] loss: 0.011831541456754292
[Epoch 18, Batch 1000] loss: 0.018878129295768223
[Epoch 18, Batch 1100] loss: 0.013422653873658277
[Epoch 18, Batch 1200] loss: 0.01022813913607095
[Epoch 18, Batch 1300] loss: 0.02128571668334587
[Epoch 18, Batch 1400] loss: 0.015259650939736958
[Epoch 18, Batch 1500] loss: 0.018218552522517584
[Epoch 18, Batch 1600] loss: 0.01377819518642827
[Epoch 18, Batch 1700] loss: 0.018883574489120605
[Epoch 18, Batch 1800] loss: 0.00693258400139158
[Epoch 18, Batch 1900] loss: 0.01309289983171916
[Epoch 18, Batch 2000] loss: 0.013922290786264493
[Epoch 18, Batch 2100] loss: 0.021695433246809826
[Epoch 18, Batch 2200] loss: 0.01581773458343843
[Epoch 18, Batch 2300] loss: 0.008049904927680913
[Epoch 18, Batch 2400] loss: 0.02225530970259996
[Epoch 18, Batch 2500] loss: 0.0036669420943052345
[Epoch 18, Batch 2600] loss: 0.012109595250330897
[Epoch 18, Batch 2700] loss: 0.01136176155064721
[Epoch 18, Batch 2800] loss: 0.014763040605926637
[Epoch 18, Batch 2900] loss: 0.021857552591250842
[Epoch 18, Batch 3000] loss: 0.02281878172741557
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0728
Validation Accuracy: 0.9853
Overfitting: 0.0728
[Epoch 19, Batch 100] loss: 0.013914082982978755
[Epoch 19, Batch 200] loss: 0.003712001939526566
[Epoch 19, Batch 300] loss: 0.0028106165779666448
[Epoch 19, Batch 400] loss: 0.002587386467267758
[Epoch 19, Batch 500] loss: 0.003681732704670049
[Epoch 19, Batch 600] loss: 0.013839880073353555
[Epoch 19, Batch 700] loss: 0.008217239120212518
[Epoch 19, Batch 800] loss: 0.010949806602938476
[Epoch 19, Batch 900] loss: 0.006112042270861497
[Epoch 19, Batch 1000] loss: 0.003632696367117485
[Epoch 19, Batch 1100] loss: 0.007240920745949016
[Epoch 19, Batch 1200] loss: 0.005835057702397193
[Epoch 19, Batch 1300] loss: 0.008648338907822057
[Epoch 19, Batch 1400] loss: 0.00961913462073695
[Epoch 19, Batch 1500] loss: 0.000993314212626828
[Epoch 19, Batch 1600] loss: 0.0017769766563463163
[Epoch 19, Batch 1700] loss: 0.006341908553875793
[Epoch 19, Batch 1800] loss: 0.01624466564257984
[Epoch 19, Batch 1900] loss: 0.019225222919260997
[Epoch 19, Batch 2000] loss: 0.011191758488448222
[Epoch 19, Batch 2100] loss: 0.004132599516796755
[Epoch 19, Batch 2200] loss: 0.011459082613056734
[Epoch 19, Batch 2300] loss: 0.012835422332293542
[Epoch 19, Batch 2400] loss: 0.013153568940614892
[Epoch 19, Batch 2500] loss: 0.013477529996760907
[Epoch 19, Batch 2600] loss: 0.016509015873812878
[Epoch 19, Batch 2700] loss: 0.006490214153577045
[Epoch 19, Batch 2800] loss: 0.021750728238775042
[Epoch 19, Batch 2900] loss: 0.018210893005231803
[Epoch 19, Batch 3000] loss: 0.005701461219323907
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0740
Validation Accuracy: 0.9866
Overfitting: 0.0740
[Epoch 20, Batch 100] loss: 0.011130561737951607
[Epoch 20, Batch 200] loss: 0.004973160793509184
[Epoch 20, Batch 300] loss: 0.0029420542789969284
[Epoch 20, Batch 400] loss: 0.013545197477153707
[Epoch 20, Batch 500] loss: 0.006435325513032248
[Epoch 20, Batch 600] loss: 0.0180205196698234
[Epoch 20, Batch 700] loss: 0.004754682594792277
[Epoch 20, Batch 800] loss: 0.009740463173319029
[Epoch 20, Batch 900] loss: 0.0145500744724677
[Epoch 20, Batch 1000] loss: 0.009376457915933055
[Epoch 20, Batch 1100] loss: 0.02284969693714748
[Epoch 20, Batch 1200] loss: 0.018113113081290086
[Epoch 20, Batch 1300] loss: 0.019444425724019106
[Epoch 20, Batch 1400] loss: 0.014694524930581033
[Epoch 20, Batch 1500] loss: 0.020369400948165355
[Epoch 20, Batch 1600] loss: 0.007130863676853152
[Epoch 20, Batch 1700] loss: 0.00694178889761091
[Epoch 20, Batch 1800] loss: 0.006729953881673753
[Epoch 20, Batch 1900] loss: 0.0027973109793865357
[Epoch 20, Batch 2000] loss: 0.006831153786283064
[Epoch 20, Batch 2100] loss: 0.02683224768745616
[Epoch 20, Batch 2200] loss: 0.006075020203185488
[Epoch 20, Batch 2300] loss: 0.014684683033488044
[Epoch 20, Batch 2400] loss: 0.012769883186388675
[Epoch 20, Batch 2500] loss: 0.007238813424857842
[Epoch 20, Batch 2600] loss: 0.011903998300892909
[Epoch 20, Batch 2700] loss: 0.025197723082641472
[Epoch 20, Batch 2800] loss: 0.005721177978531511
[Epoch 20, Batch 2900] loss: 0.0013862796587963055
[Epoch 20, Batch 3000] loss: 0.00583837005244543
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0830
Validation Accuracy: 0.9872
Overfitting: 0.0830
[Epoch 21, Batch 100] loss: 0.008616359956731197
[Epoch 21, Batch 200] loss: 0.011512985185694422
[Epoch 21, Batch 300] loss: 0.007936049348556802
[Epoch 21, Batch 400] loss: 0.0011218071429777022
[Epoch 21, Batch 500] loss: 0.000698291033276508
[Epoch 21, Batch 600] loss: 0.0031987823240082714
[Epoch 21, Batch 700] loss: 0.014408298733435285
[Epoch 21, Batch 800] loss: 0.019718670033583657
[Epoch 21, Batch 900] loss: 0.029761309428249522
[Epoch 21, Batch 1000] loss: 0.020049294919760624
[Epoch 21, Batch 1100] loss: 0.012848128063439664
[Epoch 21, Batch 1200] loss: 0.010709154833153253
[Epoch 21, Batch 1300] loss: 0.010960865393408525
[Epoch 21, Batch 1400] loss: 0.012275174832061682
[Epoch 21, Batch 1500] loss: 0.013820622521497761
[Epoch 21, Batch 1600] loss: 0.008103639847134464
[Epoch 21, Batch 1700] loss: 0.003094043911648274
[Epoch 21, Batch 1800] loss: 0.012581185858789548
[Epoch 21, Batch 1900] loss: 0.011083844515249908
[Epoch 21, Batch 2000] loss: 0.023739516733098962
[Epoch 21, Batch 2100] loss: 0.01374954781257053
[Epoch 21, Batch 2200] loss: 0.0209162761756799
[Epoch 21, Batch 2300] loss: 0.007132075506059126
[Epoch 21, Batch 2400] loss: 0.00836284614014014
[Epoch 21, Batch 2500] loss: 0.021999340089015752
[Epoch 21, Batch 2600] loss: 0.008469179282797836
[Epoch 21, Batch 2700] loss: 0.005994962627052724
[Epoch 21, Batch 2800] loss: 0.02158697256671095
[Epoch 21, Batch 2900] loss: 0.01235105172671028
[Epoch 21, Batch 3000] loss: 0.007639941451347898
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0826
Validation Accuracy: 0.9860
Overfitting: 0.0826
[Epoch 22, Batch 100] loss: 0.014840740551735641
[Epoch 22, Batch 200] loss: 0.0037636774207295298
[Epoch 22, Batch 300] loss: 0.003654363272140726
[Epoch 22, Batch 400] loss: 0.001996454426083596
[Epoch 22, Batch 500] loss: 0.005941331393362654
[Epoch 22, Batch 600] loss: 0.009700658937127363
[Epoch 22, Batch 700] loss: 0.01153300299824195
[Epoch 22, Batch 800] loss: 0.0315765292540213
[Epoch 22, Batch 900] loss: 0.023724188321295272
[Epoch 22, Batch 1000] loss: 0.0070597766219071545
[Epoch 22, Batch 1100] loss: 0.016137288901725045
[Epoch 22, Batch 1200] loss: 0.03446511946732883
[Epoch 22, Batch 1300] loss: 0.023920355465674982
[Epoch 22, Batch 1400] loss: 0.007562703952456249
[Epoch 22, Batch 1500] loss: 0.01634820072622135
[Epoch 22, Batch 1600] loss: 0.017010283132705483
[Epoch 22, Batch 1700] loss: 0.007187902017578676
[Epoch 22, Batch 1800] loss: 0.006127894373971566
[Epoch 22, Batch 1900] loss: 0.0011138110435865523
[Epoch 22, Batch 2000] loss: 0.007026450926251497
[Epoch 22, Batch 2100] loss: 0.002963500913384327
[Epoch 22, Batch 2200] loss: 0.014381010237565918
[Epoch 22, Batch 2300] loss: 0.007878260470174415
[Epoch 22, Batch 2400] loss: 0.012684659051367958
[Epoch 22, Batch 2500] loss: 0.00911701816789611
[Epoch 22, Batch 2600] loss: 0.026991746372919612
[Epoch 22, Batch 2700] loss: 0.008656724252644766
[Epoch 22, Batch 2800] loss: 0.032617723333699555
[Epoch 22, Batch 2900] loss: 0.017710788154585867
[Epoch 22, Batch 3000] loss: 0.022480907851462794
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0839
Validation Accuracy: 0.9858
Overfitting: 0.0839
[Epoch 23, Batch 100] loss: 0.00678260092968555
[Epoch 23, Batch 200] loss: 0.004146521974028264
[Epoch 23, Batch 300] loss: 0.0029138253982326657
[Epoch 23, Batch 400] loss: 0.005427863162403091
[Epoch 23, Batch 500] loss: 0.030232054026291023
[Epoch 23, Batch 600] loss: 0.008073001747316707
[Epoch 23, Batch 700] loss: 0.010276785953848941
[Epoch 23, Batch 800] loss: 0.010616102344289127
[Epoch 23, Batch 900] loss: 0.005214397344570294
[Epoch 23, Batch 1000] loss: 0.0077958414960349965
[Epoch 23, Batch 1100] loss: 0.0051505816914560396
[Epoch 23, Batch 1200] loss: 0.0025452768519095637
[Epoch 23, Batch 1300] loss: 0.009915202880380218
[Epoch 23, Batch 1400] loss: 0.030594876779894076
[Epoch 23, Batch 1500] loss: 0.014255439621117727
[Epoch 23, Batch 1600] loss: 0.021556060728289618
[Epoch 23, Batch 1700] loss: 0.006323575247165109
[Epoch 23, Batch 1800] loss: 0.003055516723823404
[Epoch 23, Batch 1900] loss: 0.012222187976457204
[Epoch 23, Batch 2000] loss: 0.007137226354026302
[Epoch 23, Batch 2100] loss: 0.00371295800127601
[Epoch 23, Batch 2200] loss: 0.014054351239143847
[Epoch 23, Batch 2300] loss: 0.008738653965025316
[Epoch 23, Batch 2400] loss: 0.016622795855802144
[Epoch 23, Batch 2500] loss: 0.0143748084807144
[Epoch 23, Batch 2600] loss: 0.022330054567304653
[Epoch 23, Batch 2700] loss: 0.03161307828049882
[Epoch 23, Batch 2800] loss: 0.03187988089080421
[Epoch 23, Batch 2900] loss: 0.020258676143582885
[Epoch 23, Batch 3000] loss: 0.017136759342828625
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0974
Validation Accuracy: 0.9856
Overfitting: 0.0974
[Epoch 24, Batch 100] loss: 0.020813287511246205
[Epoch 24, Batch 200] loss: 0.005791806771769004
[Epoch 24, Batch 300] loss: 0.00631993196476226
[Epoch 24, Batch 400] loss: 0.012561038843064693
[Epoch 24, Batch 500] loss: 0.012233394514435676
[Epoch 24, Batch 600] loss: 0.007013999301669513
[Epoch 24, Batch 700] loss: 0.015413319117691846
[Epoch 24, Batch 800] loss: 0.013323054853593641
[Epoch 24, Batch 900] loss: 0.017660720622954987
[Epoch 24, Batch 1000] loss: 0.015625857125741646
[Epoch 24, Batch 1100] loss: 0.019725244189532597
[Epoch 24, Batch 1200] loss: 0.026237298416904312
[Epoch 24, Batch 1300] loss: 0.03871942121002217
[Epoch 24, Batch 1400] loss: 0.018081306711303813
[Epoch 24, Batch 1500] loss: 0.01846647707679799
[Epoch 24, Batch 1600] loss: 0.004472969138764693
[Epoch 24, Batch 1700] loss: 0.009185638565599613
[Epoch 24, Batch 1800] loss: 0.006006120297038313
[Epoch 24, Batch 1900] loss: 0.04100784456665707
[Epoch 24, Batch 2000] loss: 0.03127423968564283
[Epoch 24, Batch 2100] loss: 0.005680175893558359
[Epoch 24, Batch 2200] loss: 0.024911076512084657
[Epoch 24, Batch 2300] loss: 0.005204118359638019
[Epoch 24, Batch 2400] loss: 0.01108628959684019
[Epoch 24, Batch 2500] loss: 0.009686781213563629
[Epoch 24, Batch 2600] loss: 0.013316778636495363
[Epoch 24, Batch 2700] loss: 0.014321146908452658
[Epoch 24, Batch 2800] loss: 0.01554487576492387
[Epoch 24, Batch 2900] loss: 0.007072914410824458
[Epoch 24, Batch 3000] loss: 0.008399527793799403
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0938
Validation Accuracy: 0.9870
Overfitting: 0.0938
Fold 3 validation loss: 0.0938
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.8243414551019668
[Epoch 1, Batch 200] loss: 0.49929001085460184
[Epoch 1, Batch 300] loss: 0.3676771645620465
[Epoch 1, Batch 400] loss: 0.20615995245985685
[Epoch 1, Batch 500] loss: 0.22329406856792047
[Epoch 1, Batch 600] loss: 0.20219933917978777
[Epoch 1, Batch 700] loss: 0.1516178752691485
[Epoch 1, Batch 800] loss: 0.18080931049771606
[Epoch 1, Batch 900] loss: 0.1520281889254693
[Epoch 1, Batch 1000] loss: 0.13029013184597715
[Epoch 1, Batch 1100] loss: 0.14317157481098547
[Epoch 1, Batch 1200] loss: 0.11897869180364068
[Epoch 1, Batch 1300] loss: 0.12830829376587644
[Epoch 1, Batch 1400] loss: 0.14313807079102844
[Epoch 1, Batch 1500] loss: 0.10886332191061228
[Epoch 1, Batch 1600] loss: 0.09985115815041354
[Epoch 1, Batch 1700] loss: 0.12838108245865443
[Epoch 1, Batch 1800] loss: 0.09884965222212486
[Epoch 1, Batch 1900] loss: 0.10100065648788586
[Epoch 1, Batch 2000] loss: 0.10927978738443926
[Epoch 1, Batch 2100] loss: 0.09336322924114938
[Epoch 1, Batch 2200] loss: 0.07592776681034592
[Epoch 1, Batch 2300] loss: 0.12591394918650622
[Epoch 1, Batch 2400] loss: 0.11700468189490493
[Epoch 1, Batch 2500] loss: 0.0837118367347648
[Epoch 1, Batch 2600] loss: 0.08782988944134558
[Epoch 1, Batch 2700] loss: 0.0845040735125076
[Epoch 1, Batch 2800] loss: 0.10087457258894574
[Epoch 1, Batch 2900] loss: 0.0852359909407096
[Epoch 1, Batch 3000] loss: 0.08521795450622449
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0786
Validation Accuracy: 0.9768
Overfitting: 0.0786
Best model saved at epoch 1 with validation loss: 0.0786
[Epoch 2, Batch 100] loss: 0.06480843136130715
[Epoch 2, Batch 200] loss: 0.07587074350165494
[Epoch 2, Batch 300] loss: 0.08221807554014958
[Epoch 2, Batch 400] loss: 0.06556475341625628
[Epoch 2, Batch 500] loss: 0.08734261552919634
[Epoch 2, Batch 600] loss: 0.07215406056973733
[Epoch 2, Batch 700] loss: 0.099396854552906
[Epoch 2, Batch 800] loss: 0.09084788335720077
[Epoch 2, Batch 900] loss: 0.06172798429906834
[Epoch 2, Batch 1000] loss: 0.08029395280012977
[Epoch 2, Batch 1100] loss: 0.057073604019969935
[Epoch 2, Batch 1200] loss: 0.043705556520508254
[Epoch 2, Batch 1300] loss: 0.08853826349033625
[Epoch 2, Batch 1400] loss: 0.06997229761400377
[Epoch 2, Batch 1500] loss: 0.0599890852819226
[Epoch 2, Batch 1600] loss: 0.06093767698010197
[Epoch 2, Batch 1700] loss: 0.06369079705225886
[Epoch 2, Batch 1800] loss: 0.08056096278189216
[Epoch 2, Batch 1900] loss: 0.06795301266778551
[Epoch 2, Batch 2000] loss: 0.06890886911467532
[Epoch 2, Batch 2100] loss: 0.06289504484040663
[Epoch 2, Batch 2200] loss: 0.054327737893036104
[Epoch 2, Batch 2300] loss: 0.07156959105443093
[Epoch 2, Batch 2400] loss: 0.04869221834873315
[Epoch 2, Batch 2500] loss: 0.05317924577379017
[Epoch 2, Batch 2600] loss: 0.06311689042835496
[Epoch 2, Batch 2700] loss: 0.07269496124237776
[Epoch 2, Batch 2800] loss: 0.08648953848460224
[Epoch 2, Batch 2900] loss: 0.068551038945443
[Epoch 2, Batch 3000] loss: 0.041786014237441126
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0638
Validation Accuracy: 0.9816
Overfitting: 0.0638
Best model saved at epoch 2 with validation loss: 0.0638
[Epoch 3, Batch 100] loss: 0.06299172263112268
[Epoch 3, Batch 200] loss: 0.030070557499911957
[Epoch 3, Batch 300] loss: 0.034912408761992995
[Epoch 3, Batch 400] loss: 0.062093277961248534
[Epoch 3, Batch 500] loss: 0.07023054161472828
[Epoch 3, Batch 600] loss: 0.05708420174414641
[Epoch 3, Batch 700] loss: 0.0396046275790286
[Epoch 3, Batch 800] loss: 0.04775318064901512
[Epoch 3, Batch 900] loss: 0.05824125420193013
[Epoch 3, Batch 1000] loss: 0.06137427760077117
[Epoch 3, Batch 1100] loss: 0.05693666744278744
[Epoch 3, Batch 1200] loss: 0.05906676632876042
[Epoch 3, Batch 1300] loss: 0.05300552204920678
[Epoch 3, Batch 1400] loss: 0.0649944549362408
[Epoch 3, Batch 1500] loss: 0.047877853710524505
[Epoch 3, Batch 1600] loss: 0.04878298082359834
[Epoch 3, Batch 1700] loss: 0.04391166166184121
[Epoch 3, Batch 1800] loss: 0.03642535289038278
[Epoch 3, Batch 1900] loss: 0.0613521572638092
[Epoch 3, Batch 2000] loss: 0.06298040622918051
[Epoch 3, Batch 2100] loss: 0.0651546151281218
[Epoch 3, Batch 2200] loss: 0.05613300088487449
[Epoch 3, Batch 2300] loss: 0.041319824953679925
[Epoch 3, Batch 2400] loss: 0.036948444209119774
[Epoch 3, Batch 2500] loss: 0.026756827878343756
[Epoch 3, Batch 2600] loss: 0.048823821466066876
[Epoch 3, Batch 2700] loss: 0.056114475890208265
[Epoch 3, Batch 2800] loss: 0.0504062218836043
[Epoch 3, Batch 2900] loss: 0.03859738878250937
[Epoch 3, Batch 3000] loss: 0.06146039238541562
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9832
Overfitting: 0.0619
Best model saved at epoch 3 with validation loss: 0.0619
[Epoch 4, Batch 100] loss: 0.042505489622217285
[Epoch 4, Batch 200] loss: 0.046818795691760895
[Epoch 4, Batch 300] loss: 0.03821724303026713
[Epoch 4, Batch 400] loss: 0.041859643979769316
[Epoch 4, Batch 500] loss: 0.04898253531035152
[Epoch 4, Batch 600] loss: 0.03084261642110505
[Epoch 4, Batch 700] loss: 0.048189179333421636
[Epoch 4, Batch 800] loss: 0.05813680776263937
[Epoch 4, Batch 900] loss: 0.026474145447082265
[Epoch 4, Batch 1000] loss: 0.045971608177164856
[Epoch 4, Batch 1100] loss: 0.04347799667759318
[Epoch 4, Batch 1200] loss: 0.036089029219001534
[Epoch 4, Batch 1300] loss: 0.06043156382726011
[Epoch 4, Batch 1400] loss: 0.03233250662113278
[Epoch 4, Batch 1500] loss: 0.03651883113441727
[Epoch 4, Batch 1600] loss: 0.019804869923900695
[Epoch 4, Batch 1700] loss: 0.025773248985087774
[Epoch 4, Batch 1800] loss: 0.03231991196550098
[Epoch 4, Batch 1900] loss: 0.04635524178553624
[Epoch 4, Batch 2000] loss: 0.044538111588408355
[Epoch 4, Batch 2100] loss: 0.06278087486920413
[Epoch 4, Batch 2200] loss: 0.02662024720288173
[Epoch 4, Batch 2300] loss: 0.06671004362972781
[Epoch 4, Batch 2400] loss: 0.0448196798308345
[Epoch 4, Batch 2500] loss: 0.03780897679815098
[Epoch 4, Batch 2600] loss: 0.03836406781227197
[Epoch 4, Batch 2700] loss: 0.0386601341912683
[Epoch 4, Batch 2800] loss: 0.03187338518735487
[Epoch 4, Batch 2900] loss: 0.029470261828028015
[Epoch 4, Batch 3000] loss: 0.04255237170480541
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9851
Overfitting: 0.0527
Best model saved at epoch 4 with validation loss: 0.0527
[Epoch 5, Batch 100] loss: 0.04932510352373356
[Epoch 5, Batch 200] loss: 0.02910284699506292
[Epoch 5, Batch 300] loss: 0.025833926536470243
[Epoch 5, Batch 400] loss: 0.032711391246888294
[Epoch 5, Batch 500] loss: 0.025321487872879515
[Epoch 5, Batch 600] loss: 0.03573861610865606
[Epoch 5, Batch 700] loss: 0.04767736112964485
[Epoch 5, Batch 800] loss: 0.04166736487975413
[Epoch 5, Batch 900] loss: 0.03510120827829269
[Epoch 5, Batch 1000] loss: 0.03516698755103789
[Epoch 5, Batch 1100] loss: 0.017095527732035407
[Epoch 5, Batch 1200] loss: 0.01720507840682558
[Epoch 5, Batch 1300] loss: 0.03380984280991925
[Epoch 5, Batch 1400] loss: 0.03543312366860846
[Epoch 5, Batch 1500] loss: 0.04677549669795553
[Epoch 5, Batch 1600] loss: 0.04223234841720114
[Epoch 5, Batch 1700] loss: 0.02638787008788313
[Epoch 5, Batch 1800] loss: 0.034365403698047886
[Epoch 5, Batch 1900] loss: 0.036004493667890075
[Epoch 5, Batch 2000] loss: 0.04741756470789369
[Epoch 5, Batch 2100] loss: 0.04164702263259642
[Epoch 5, Batch 2200] loss: 0.025092233437253527
[Epoch 5, Batch 2300] loss: 0.03332343540584588
[Epoch 5, Batch 2400] loss: 0.03784316522524023
[Epoch 5, Batch 2500] loss: 0.04463700709698969
[Epoch 5, Batch 2600] loss: 0.03749033342213806
[Epoch 5, Batch 2700] loss: 0.04501482714476879
[Epoch 5, Batch 2800] loss: 0.03673934997434117
[Epoch 5, Batch 2900] loss: 0.0339740048524186
[Epoch 5, Batch 3000] loss: 0.04244882873532333
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0650
Validation Accuracy: 0.9801
Overfitting: 0.0650
[Epoch 6, Batch 100] loss: 0.020478528710486898
[Epoch 6, Batch 200] loss: 0.019937177698584493
[Epoch 6, Batch 300] loss: 0.016048894236396338
[Epoch 6, Batch 400] loss: 0.03425379636054572
[Epoch 6, Batch 500] loss: 0.029531346441635832
[Epoch 6, Batch 600] loss: 0.010821456538469647
[Epoch 6, Batch 700] loss: 0.021809655369347637
[Epoch 6, Batch 800] loss: 0.023888903285181867
[Epoch 6, Batch 900] loss: 0.016907090025424624
[Epoch 6, Batch 1000] loss: 0.036366540833707856
[Epoch 6, Batch 1100] loss: 0.05210430429789881
[Epoch 6, Batch 1200] loss: 0.04431537016394941
[Epoch 6, Batch 1300] loss: 0.026845323384150105
[Epoch 6, Batch 1400] loss: 0.031681312452719795
[Epoch 6, Batch 1500] loss: 0.020791942135592763
[Epoch 6, Batch 1600] loss: 0.020776047652170747
[Epoch 6, Batch 1700] loss: 0.04674058039827287
[Epoch 6, Batch 1800] loss: 0.04327999800463658
[Epoch 6, Batch 1900] loss: 0.018879911783333227
[Epoch 6, Batch 2000] loss: 0.031916128876455334
[Epoch 6, Batch 2100] loss: 0.025111294758139592
[Epoch 6, Batch 2200] loss: 0.04167178740095551
[Epoch 6, Batch 2300] loss: 0.02737745821610588
[Epoch 6, Batch 2400] loss: 0.04599079321814315
[Epoch 6, Batch 2500] loss: 0.02585846997067165
[Epoch 6, Batch 2600] loss: 0.0370426842359484
[Epoch 6, Batch 2700] loss: 0.026137621688094442
[Epoch 6, Batch 2800] loss: 0.016153815729962842
[Epoch 6, Batch 2900] loss: 0.026670084686775227
[Epoch 6, Batch 3000] loss: 0.0067285306209942065
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0409
Validation Accuracy: 0.9890
Overfitting: 0.0409
Best model saved at epoch 6 with validation loss: 0.0409
[Epoch 7, Batch 100] loss: 0.022390005830250175
[Epoch 7, Batch 200] loss: 0.03153241430171647
[Epoch 7, Batch 300] loss: 0.010179867867295798
[Epoch 7, Batch 400] loss: 0.009260524105732202
[Epoch 7, Batch 500] loss: 0.011803655705352299
[Epoch 7, Batch 600] loss: 0.027781203727470255
[Epoch 7, Batch 700] loss: 0.03400181864414094
[Epoch 7, Batch 800] loss: 0.03357283081893001
[Epoch 7, Batch 900] loss: 0.02476872711838723
[Epoch 7, Batch 1000] loss: 0.02584139800491357
[Epoch 7, Batch 1100] loss: 0.02537487037193614
[Epoch 7, Batch 1200] loss: 0.023058098450050295
[Epoch 7, Batch 1300] loss: 0.017557693977391865
[Epoch 7, Batch 1400] loss: 0.03582038220686968
[Epoch 7, Batch 1500] loss: 0.01960953870450794
[Epoch 7, Batch 1600] loss: 0.02611146606443981
[Epoch 7, Batch 1700] loss: 0.03621774234229406
[Epoch 7, Batch 1800] loss: 0.016020514304453854
[Epoch 7, Batch 1900] loss: 0.014963739950853778
[Epoch 7, Batch 2000] loss: 0.019890863797449043
[Epoch 7, Batch 2100] loss: 0.04191978518534484
[Epoch 7, Batch 2200] loss: 0.019232375008436976
[Epoch 7, Batch 2300] loss: 0.01930015610789724
[Epoch 7, Batch 2400] loss: 0.02659059867266933
[Epoch 7, Batch 2500] loss: 0.03693243111912125
[Epoch 7, Batch 2600] loss: 0.04486621937447126
[Epoch 7, Batch 2700] loss: 0.02307495692380144
[Epoch 7, Batch 2800] loss: 0.0343647762213277
[Epoch 7, Batch 2900] loss: 0.02220276443866169
[Epoch 7, Batch 3000] loss: 0.02238637940802505
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9851
Overfitting: 0.0531
[Epoch 8, Batch 100] loss: 0.03203837143836836
[Epoch 8, Batch 200] loss: 0.03737961540902006
[Epoch 8, Batch 300] loss: 0.02466016449497147
[Epoch 8, Batch 400] loss: 0.02574845809236649
[Epoch 8, Batch 500] loss: 0.02399263766619697
[Epoch 8, Batch 600] loss: 0.025656072339506862
[Epoch 8, Batch 700] loss: 0.014193447192336067
[Epoch 8, Batch 800] loss: 0.02170386973761538
[Epoch 8, Batch 900] loss: 0.028326856557860082
[Epoch 8, Batch 1000] loss: 0.018567432381619255
[Epoch 8, Batch 1100] loss: 0.017236312293139235
[Epoch 8, Batch 1200] loss: 0.022391150038449725
[Epoch 8, Batch 1300] loss: 0.014196028617934644
[Epoch 8, Batch 1400] loss: 0.030233031231123277
[Epoch 8, Batch 1500] loss: 0.02002955896379717
[Epoch 8, Batch 1600] loss: 0.025952797460438434
[Epoch 8, Batch 1700] loss: 0.021098415933888646
[Epoch 8, Batch 1800] loss: 0.025511778671418597
[Epoch 8, Batch 1900] loss: 0.01617101450028713
[Epoch 8, Batch 2000] loss: 0.025731518695590695
[Epoch 8, Batch 2100] loss: 0.013900739729892848
[Epoch 8, Batch 2200] loss: 0.031776786014511345
[Epoch 8, Batch 2300] loss: 0.011092751164869696
[Epoch 8, Batch 2400] loss: 0.017441919678470297
[Epoch 8, Batch 2500] loss: 0.00958195159061198
[Epoch 8, Batch 2600] loss: 0.02304835562361973
[Epoch 8, Batch 2700] loss: 0.04704839624172223
[Epoch 8, Batch 2800] loss: 0.04228171618564375
[Epoch 8, Batch 2900] loss: 0.0313754178572367
[Epoch 8, Batch 3000] loss: 0.023642192407332913
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9874
Overfitting: 0.0470
[Epoch 9, Batch 100] loss: 0.018612571320613825
[Epoch 9, Batch 200] loss: 0.01053534979973051
[Epoch 9, Batch 300] loss: 0.009621535407664493
[Epoch 9, Batch 400] loss: 0.022804283009497793
[Epoch 9, Batch 500] loss: 0.012469401987493143
[Epoch 9, Batch 600] loss: 0.019972654508763982
[Epoch 9, Batch 700] loss: 0.009558477278283704
[Epoch 9, Batch 800] loss: 0.021533690411025076
[Epoch 9, Batch 900] loss: 0.017211906282630595
[Epoch 9, Batch 1000] loss: 0.019652094773380212
[Epoch 9, Batch 1100] loss: 0.025891040964311288
[Epoch 9, Batch 1200] loss: 0.0200367714101651
[Epoch 9, Batch 1300] loss: 0.01401873834392319
[Epoch 9, Batch 1400] loss: 0.014325199510655154
[Epoch 9, Batch 1500] loss: 0.009955817676285506
[Epoch 9, Batch 1600] loss: 0.02865640315033957
[Epoch 9, Batch 1700] loss: 0.024807367652588255
[Epoch 9, Batch 1800] loss: 0.019329590786021953
[Epoch 9, Batch 1900] loss: 0.033142920345081844
[Epoch 9, Batch 2000] loss: 0.030482865510584673
[Epoch 9, Batch 2100] loss: 0.0484394303139743
[Epoch 9, Batch 2200] loss: 0.03003215261214109
[Epoch 9, Batch 2300] loss: 0.028750455376357422
[Epoch 9, Batch 2400] loss: 0.0199272505701461
[Epoch 9, Batch 2500] loss: 0.01678095326548373
[Epoch 9, Batch 2600] loss: 0.020808612108235137
[Epoch 9, Batch 2700] loss: 0.027541017022030018
[Epoch 9, Batch 2800] loss: 0.01619706697576703
[Epoch 9, Batch 2900] loss: 0.01621873834379528
[Epoch 9, Batch 3000] loss: 0.025730609739655675
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9838
Overfitting: 0.0573
[Epoch 10, Batch 100] loss: 0.030079258402176946
[Epoch 10, Batch 200] loss: 0.010879313541646098
[Epoch 10, Batch 300] loss: 0.024175409236924565
[Epoch 10, Batch 400] loss: 0.02623158062808443
[Epoch 10, Batch 500] loss: 0.022649835861157045
[Epoch 10, Batch 600] loss: 0.02300881596843169
[Epoch 10, Batch 700] loss: 0.017106505668413662
[Epoch 10, Batch 800] loss: 0.02568458962920545
[Epoch 10, Batch 900] loss: 0.023164962369301066
[Epoch 10, Batch 1000] loss: 0.019472181340142926
[Epoch 10, Batch 1100] loss: 0.025615684368676738
[Epoch 10, Batch 1200] loss: 0.018005114083014178
[Epoch 10, Batch 1300] loss: 0.017981126976484633
[Epoch 10, Batch 1400] loss: 0.01259482420868153
[Epoch 10, Batch 1500] loss: 0.014733049453075181
[Epoch 10, Batch 1600] loss: 0.01553397091125646
[Epoch 10, Batch 1700] loss: 0.009616190644999278
[Epoch 10, Batch 1800] loss: 0.016454366147759174
[Epoch 10, Batch 1900] loss: 0.02801791778677341
[Epoch 10, Batch 2000] loss: 0.018285614021342555
[Epoch 10, Batch 2100] loss: 0.013532272347372327
[Epoch 10, Batch 2200] loss: 0.025854617377331125
[Epoch 10, Batch 2300] loss: 0.01456631659826911
[Epoch 10, Batch 2400] loss: 0.044046332077732585
[Epoch 10, Batch 2500] loss: 0.01859345967807485
[Epoch 10, Batch 2600] loss: 0.018919157626279458
[Epoch 10, Batch 2700] loss: 0.024196187692052718
[Epoch 10, Batch 2800] loss: 0.02118476821248407
[Epoch 10, Batch 2900] loss: 0.022879042962554195
[Epoch 10, Batch 3000] loss: 0.026918967295969196
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9870
Overfitting: 0.0441
[Epoch 11, Batch 100] loss: 0.011510897041553107
[Epoch 11, Batch 200] loss: 0.007462176998096766
[Epoch 11, Batch 300] loss: 0.013534565978537784
[Epoch 11, Batch 400] loss: 0.015572453954722504
[Epoch 11, Batch 500] loss: 0.006641666929265853
[Epoch 11, Batch 600] loss: 0.02050596957686551
[Epoch 11, Batch 700] loss: 0.029676255099283823
[Epoch 11, Batch 800] loss: 0.006943146460286016
[Epoch 11, Batch 900] loss: 0.008751065732886048
[Epoch 11, Batch 1000] loss: 0.01580785329440772
[Epoch 11, Batch 1100] loss: 0.005107766682119746
[Epoch 11, Batch 1200] loss: 0.01216913166302959
[Epoch 11, Batch 1300] loss: 0.0239336477582674
[Epoch 11, Batch 1400] loss: 0.013514485193052223
[Epoch 11, Batch 1500] loss: 0.029068468524397418
[Epoch 11, Batch 1600] loss: 0.015913649927971393
[Epoch 11, Batch 1700] loss: 0.011752849774889001
[Epoch 11, Batch 1800] loss: 0.006254710067501179
[Epoch 11, Batch 1900] loss: 0.0037939401601681765
[Epoch 11, Batch 2000] loss: 0.013276829377733747
[Epoch 11, Batch 2100] loss: 0.03590682801525389
[Epoch 11, Batch 2200] loss: 0.020531440597764003
[Epoch 11, Batch 2300] loss: 0.018493291459784303
[Epoch 11, Batch 2400] loss: 0.015550671196692747
[Epoch 11, Batch 2500] loss: 0.0201245979544143
[Epoch 11, Batch 2600] loss: 0.035952177546859046
[Epoch 11, Batch 2700] loss: 0.015486751372459367
[Epoch 11, Batch 2800] loss: 0.007932137580336302
[Epoch 11, Batch 2900] loss: 0.011383771026564205
[Epoch 11, Batch 3000] loss: 0.007087440448470375
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0454
Validation Accuracy: 0.9898
Overfitting: 0.0454
[Epoch 12, Batch 100] loss: 0.014214470808366854
[Epoch 12, Batch 200] loss: 0.010667472119766312
[Epoch 12, Batch 300] loss: 0.007057977350799441
[Epoch 12, Batch 400] loss: 0.010444235653880857
[Epoch 12, Batch 500] loss: 0.020411165867975853
[Epoch 12, Batch 600] loss: 0.01388404959468474
[Epoch 12, Batch 700] loss: 0.013600281774671999
[Epoch 12, Batch 800] loss: 0.010113890194496307
[Epoch 12, Batch 900] loss: 0.008817536760736999
[Epoch 12, Batch 1000] loss: 0.005756824766712465
[Epoch 12, Batch 1100] loss: 0.00741943430432439
[Epoch 12, Batch 1200] loss: 0.005637459863844967
[Epoch 12, Batch 1300] loss: 0.0034253896668712926
[Epoch 12, Batch 1400] loss: 0.019867596992037998
[Epoch 12, Batch 1500] loss: 0.019210457571302866
[Epoch 12, Batch 1600] loss: 0.024007225941929562
[Epoch 12, Batch 1700] loss: 0.011481119419264586
[Epoch 12, Batch 1800] loss: 0.013580652016112395
[Epoch 12, Batch 1900] loss: 0.00628507271292122
[Epoch 12, Batch 2000] loss: 0.008667482871893135
[Epoch 12, Batch 2100] loss: 0.016300163455260447
[Epoch 12, Batch 2200] loss: 0.012519914319165588
[Epoch 12, Batch 2300] loss: 0.011773417013042815
[Epoch 12, Batch 2400] loss: 0.008397647434772323
[Epoch 12, Batch 2500] loss: 0.024850388525527994
[Epoch 12, Batch 2600] loss: 0.006162670318349228
[Epoch 12, Batch 2700] loss: 0.01312719276208838
[Epoch 12, Batch 2800] loss: 0.021098330416072796
[Epoch 12, Batch 2900] loss: 0.023606076472013057
[Epoch 12, Batch 3000] loss: 0.012975707809786456
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0590
Validation Accuracy: 0.9854
Overfitting: 0.0590
[Epoch 13, Batch 100] loss: 0.019870021339600613
[Epoch 13, Batch 200] loss: 0.006538313799594562
[Epoch 13, Batch 300] loss: 0.0039015766799008087
[Epoch 13, Batch 400] loss: 0.01362095444118955
[Epoch 13, Batch 500] loss: 0.009587830782414031
[Epoch 13, Batch 600] loss: 0.009093633305095565
[Epoch 13, Batch 700] loss: 0.016740808395244642
[Epoch 13, Batch 800] loss: 0.03230570050897128
[Epoch 13, Batch 900] loss: 0.011203628659547604
[Epoch 13, Batch 1000] loss: 0.007239862336300718
[Epoch 13, Batch 1100] loss: 0.012613024071041465
[Epoch 13, Batch 1200] loss: 0.0158267968727565
[Epoch 13, Batch 1300] loss: 0.017698182940715342
[Epoch 13, Batch 1400] loss: 0.009271474467942582
[Epoch 13, Batch 1500] loss: 0.006470891013087363
[Epoch 13, Batch 1600] loss: 0.008944936756752427
[Epoch 13, Batch 1700] loss: 0.0035142872393356937
[Epoch 13, Batch 1800] loss: 0.02199589038011309
[Epoch 13, Batch 1900] loss: 0.0222653500530987
[Epoch 13, Batch 2000] loss: 0.013203324054449012
[Epoch 13, Batch 2100] loss: 0.013432581656636699
[Epoch 13, Batch 2200] loss: 0.009389038069504778
[Epoch 13, Batch 2300] loss: 0.017338095666368715
[Epoch 13, Batch 2400] loss: 0.006291823407274855
[Epoch 13, Batch 2500] loss: 0.010308742213487383
[Epoch 13, Batch 2600] loss: 0.01221732052184318
[Epoch 13, Batch 2700] loss: 0.014326909530723598
[Epoch 13, Batch 2800] loss: 0.03445740098308932
[Epoch 13, Batch 2900] loss: 0.01827322798045927
[Epoch 13, Batch 3000] loss: 0.029333518560107734
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9870
Overfitting: 0.0524
[Epoch 14, Batch 100] loss: 0.006491976282366902
[Epoch 14, Batch 200] loss: 0.006485933732742239
[Epoch 14, Batch 300] loss: 0.01823573935502086
[Epoch 14, Batch 400] loss: 0.022243151205450572
[Epoch 14, Batch 500] loss: 0.010386572219373882
[Epoch 14, Batch 600] loss: 0.020253657681502377
[Epoch 14, Batch 700] loss: 0.015532317174276625
[Epoch 14, Batch 800] loss: 0.01596884208213112
[Epoch 14, Batch 900] loss: 0.0055114169838023485
[Epoch 14, Batch 1000] loss: 0.004592388704559123
[Epoch 14, Batch 1100] loss: 0.0060341746153094135
[Epoch 14, Batch 1200] loss: 0.008106443001442889
[Epoch 14, Batch 1300] loss: 0.01106463380836515
[Epoch 14, Batch 1400] loss: 0.009581301215969855
[Epoch 14, Batch 1500] loss: 0.012205330731957868
[Epoch 14, Batch 1600] loss: 0.00714413505030886
[Epoch 14, Batch 1700] loss: 0.013427732453584725
[Epoch 14, Batch 1800] loss: 0.011585902427917443
[Epoch 14, Batch 1900] loss: 0.020988708222545026
[Epoch 14, Batch 2000] loss: 0.021095529222480876
[Epoch 14, Batch 2100] loss: 0.01939009642259094
[Epoch 14, Batch 2200] loss: 0.012400376374383395
[Epoch 14, Batch 2300] loss: 0.019651230654675257
[Epoch 14, Batch 2400] loss: 0.007132039308262689
[Epoch 14, Batch 2500] loss: 0.014015020710657175
[Epoch 14, Batch 2600] loss: 0.014800162161346808
[Epoch 14, Batch 2700] loss: 0.015747103882927133
[Epoch 14, Batch 2800] loss: 0.01847721592959111
[Epoch 14, Batch 2900] loss: 0.01801188568555361
[Epoch 14, Batch 3000] loss: 0.03845059356525397
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0851
Validation Accuracy: 0.9808
Overfitting: 0.0851
[Epoch 15, Batch 100] loss: 0.017438882059438755
[Epoch 15, Batch 200] loss: 0.017779214929805748
[Epoch 15, Batch 300] loss: 0.020280314200161874
[Epoch 15, Batch 400] loss: 0.028259693366422808
[Epoch 15, Batch 500] loss: 0.02506290945145736
[Epoch 15, Batch 600] loss: 0.022426521482882152
[Epoch 15, Batch 700] loss: 0.01885849231813623
[Epoch 15, Batch 800] loss: 0.03075788582575001
[Epoch 15, Batch 900] loss: 0.04746646015511843
[Epoch 15, Batch 1000] loss: 0.011072317117470903
[Epoch 15, Batch 1100] loss: 0.025839352210610685
[Epoch 15, Batch 1200] loss: 0.016864544263847103
[Epoch 15, Batch 1300] loss: 0.004580063477328338
[Epoch 15, Batch 1400] loss: 0.014701858068900862
[Epoch 15, Batch 1500] loss: 0.0028800143127795997
[Epoch 15, Batch 1600] loss: 0.01838762010814539
[Epoch 15, Batch 1700] loss: 0.020649921350070245
[Epoch 15, Batch 1800] loss: 0.01449395697656854
[Epoch 15, Batch 1900] loss: 0.018759835544880688
[Epoch 15, Batch 2000] loss: 0.03663166468237414
[Epoch 15, Batch 2100] loss: 0.029216868589449517
[Epoch 15, Batch 2200] loss: 0.018088358927102987
[Epoch 15, Batch 2300] loss: 0.011436276043988584
[Epoch 15, Batch 2400] loss: 0.012913502096696306
[Epoch 15, Batch 2500] loss: 0.017695707803619315
[Epoch 15, Batch 2600] loss: 0.014734271657483334
[Epoch 15, Batch 2700] loss: 0.014746811635306188
[Epoch 15, Batch 2800] loss: 0.02075692910908117
[Epoch 15, Batch 2900] loss: 0.018588473277178955
[Epoch 15, Batch 3000] loss: 0.022010189128582453
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9875
Overfitting: 0.0569
[Epoch 16, Batch 100] loss: 0.0075221178567459555
[Epoch 16, Batch 200] loss: 0.013858117975322557
[Epoch 16, Batch 300] loss: 0.0060148989881516355
[Epoch 16, Batch 400] loss: 0.012458227580171304
[Epoch 16, Batch 500] loss: 0.008268485337332834
[Epoch 16, Batch 600] loss: 0.019395479214821806
[Epoch 16, Batch 700] loss: 0.045309100703016136
[Epoch 16, Batch 800] loss: 0.010177317177996912
[Epoch 16, Batch 900] loss: 0.010513432741439743
[Epoch 16, Batch 1000] loss: 0.01946270580395007
[Epoch 16, Batch 1100] loss: 0.006272010844248186
[Epoch 16, Batch 1200] loss: 0.017106020826026143
[Epoch 16, Batch 1300] loss: 0.014030058048368942
[Epoch 16, Batch 1400] loss: 0.009673661356202325
[Epoch 16, Batch 1500] loss: 0.007118476311003685
[Epoch 16, Batch 1600] loss: 0.006342410214411345
[Epoch 16, Batch 1700] loss: 0.011046430373765927
[Epoch 16, Batch 1800] loss: 0.011841066817772727
[Epoch 16, Batch 1900] loss: 0.006402582230314238
[Epoch 16, Batch 2000] loss: 0.032585755245276835
[Epoch 16, Batch 2100] loss: 0.027478622799307847
[Epoch 16, Batch 2200] loss: 0.009348147830462202
[Epoch 16, Batch 2300] loss: 0.023021624084513484
[Epoch 16, Batch 2400] loss: 0.009754302476342059
[Epoch 16, Batch 2500] loss: 0.016034323412277604
[Epoch 16, Batch 2600] loss: 0.013066839931772444
[Epoch 16, Batch 2700] loss: 0.02875405507936211
[Epoch 16, Batch 2800] loss: 0.022359188150483364
[Epoch 16, Batch 2900] loss: 0.02353317309742227
[Epoch 16, Batch 3000] loss: 0.053462681985533
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0853
Validation Accuracy: 0.9788
Overfitting: 0.0853
[Epoch 17, Batch 100] loss: 0.031173149706489767
[Epoch 17, Batch 200] loss: 0.01411814704770336
[Epoch 17, Batch 300] loss: 0.008667389138162597
[Epoch 17, Batch 400] loss: 0.011500275425596307
[Epoch 17, Batch 500] loss: 0.00528048034174116
[Epoch 17, Batch 600] loss: 0.0145624910485928
[Epoch 17, Batch 700] loss: 0.00909619120192635
[Epoch 17, Batch 800] loss: 0.0196791477009199
[Epoch 17, Batch 900] loss: 0.020325562694880263
[Epoch 17, Batch 1000] loss: 0.024022604839447067
[Epoch 17, Batch 1100] loss: 0.021350340150684523
[Epoch 17, Batch 1200] loss: 0.0110424080114759
[Epoch 17, Batch 1300] loss: 0.009991449120111504
[Epoch 17, Batch 1400] loss: 0.014343895424085065
[Epoch 17, Batch 1500] loss: 0.027801690252381873
[Epoch 17, Batch 1600] loss: 0.019924045865070922
[Epoch 17, Batch 1700] loss: 0.027759580088302867
[Epoch 17, Batch 1800] loss: 0.011028670687452027
[Epoch 17, Batch 1900] loss: 0.015189695614995143
[Epoch 17, Batch 2000] loss: 0.016055366679496714
[Epoch 17, Batch 2100] loss: 0.006908572916593201
[Epoch 17, Batch 2200] loss: 0.00957011660983774
[Epoch 17, Batch 2300] loss: 0.024232281779778545
[Epoch 17, Batch 2400] loss: 0.008232614083500955
[Epoch 17, Batch 2500] loss: 0.008522758651452182
[Epoch 17, Batch 2600] loss: 0.020516265777921202
[Epoch 17, Batch 2700] loss: 0.015761047664771547
[Epoch 17, Batch 2800] loss: 0.0308221462547354
[Epoch 17, Batch 2900] loss: 0.018564943742914577
[Epoch 17, Batch 3000] loss: 0.016804679273949148
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0712
Validation Accuracy: 0.9855
Overfitting: 0.0712
[Epoch 18, Batch 100] loss: 0.009188791825613545
[Epoch 18, Batch 200] loss: 0.004620714331469311
[Epoch 18, Batch 300] loss: 0.01842400628948361
[Epoch 18, Batch 400] loss: 0.018911946794206838
[Epoch 18, Batch 500] loss: 0.00684385904187522
[Epoch 18, Batch 600] loss: 0.010024448141186788
[Epoch 18, Batch 700] loss: 0.012702634424377237
[Epoch 18, Batch 800] loss: 0.02403893803030179
[Epoch 18, Batch 900] loss: 0.02914110705489719
[Epoch 18, Batch 1000] loss: 0.02218891814743472
[Epoch 18, Batch 1100] loss: 0.03190351430366491
[Epoch 18, Batch 1200] loss: 0.03401717245460615
[Epoch 18, Batch 1300] loss: 0.01855585445647023
[Epoch 18, Batch 1400] loss: 0.00837723936699831
[Epoch 18, Batch 1500] loss: 0.005603756960408069
[Epoch 18, Batch 1600] loss: 0.003813219304654929
[Epoch 18, Batch 1700] loss: 0.010614669978940157
[Epoch 18, Batch 1800] loss: 0.02050736726165841
[Epoch 18, Batch 1900] loss: 0.006028091263736943
[Epoch 18, Batch 2000] loss: 0.01097480711541042
[Epoch 18, Batch 2100] loss: 0.009601964371953481
[Epoch 18, Batch 2200] loss: 0.017987082165179587
[Epoch 18, Batch 2300] loss: 0.0156852936559876
[Epoch 18, Batch 2400] loss: 0.017838128202097597
[Epoch 18, Batch 2500] loss: 0.015310440766765278
[Epoch 18, Batch 2600] loss: 0.018201322016409307
[Epoch 18, Batch 2700] loss: 0.013587519313799663
[Epoch 18, Batch 2800] loss: 0.008231927344327268
[Epoch 18, Batch 2900] loss: 0.016119338282107324
[Epoch 18, Batch 3000] loss: 0.011349432588132263
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0645
Validation Accuracy: 0.9882
Overfitting: 0.0645
[Epoch 19, Batch 100] loss: 0.009757413491835485
[Epoch 19, Batch 200] loss: 0.015308296847140882
[Epoch 19, Batch 300] loss: 0.023953339087069595
[Epoch 19, Batch 400] loss: 0.008759410102640341
[Epoch 19, Batch 500] loss: 0.005871756388954874
[Epoch 19, Batch 600] loss: 0.013088668333630421
[Epoch 19, Batch 700] loss: 0.013986608251210448
[Epoch 19, Batch 800] loss: 0.019254599022943707
[Epoch 19, Batch 900] loss: 0.02724527185003067
[Epoch 19, Batch 1000] loss: 0.02343087451660779
[Epoch 19, Batch 1100] loss: 0.0306768845861626
[Epoch 19, Batch 1200] loss: 0.021059327205765043
[Epoch 19, Batch 1300] loss: 0.012291310926044331
[Epoch 19, Batch 1400] loss: 0.01379384475862501
[Epoch 19, Batch 1500] loss: 0.01646235734777222
[Epoch 19, Batch 1600] loss: 0.013370863616733003
[Epoch 19, Batch 1700] loss: 0.0311315998875046
[Epoch 19, Batch 1800] loss: 0.016773719258882904
[Epoch 19, Batch 1900] loss: 0.021641140003881936
[Epoch 19, Batch 2000] loss: 0.03161564381900979
[Epoch 19, Batch 2100] loss: 0.04546675706702544
[Epoch 19, Batch 2200] loss: 0.02532963549783851
[Epoch 19, Batch 2300] loss: 0.02002963600750128
[Epoch 19, Batch 2400] loss: 0.020467426623751662
[Epoch 19, Batch 2500] loss: 0.01616369427043516
[Epoch 19, Batch 2600] loss: 0.007020482843087361
[Epoch 19, Batch 2700] loss: 0.0017793603169097593
[Epoch 19, Batch 2800] loss: 0.01140982760236161
[Epoch 19, Batch 2900] loss: 0.015003258292625183
[Epoch 19, Batch 3000] loss: 0.011283364695665744
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9877
Overfitting: 0.0554
[Epoch 20, Batch 100] loss: 0.002784114349073419
[Epoch 20, Batch 200] loss: 0.00226960741630311
[Epoch 20, Batch 300] loss: 0.0028810481110125253
[Epoch 20, Batch 400] loss: 0.007060437575425484
[Epoch 20, Batch 500] loss: 0.0029530915386901135
[Epoch 20, Batch 600] loss: 0.0045156681424602186
[Epoch 20, Batch 700] loss: 0.002164911503005413
[Epoch 20, Batch 800] loss: 0.008407209861088725
[Epoch 20, Batch 900] loss: 0.0032333238278484224
[Epoch 20, Batch 1000] loss: 0.002190065125712306
[Epoch 20, Batch 1100] loss: 0.01810466730841397
[Epoch 20, Batch 1200] loss: 0.05455735879608837
[Epoch 20, Batch 1300] loss: 0.027961175047277412
[Epoch 20, Batch 1400] loss: 0.006983605800809647
[Epoch 20, Batch 1500] loss: 0.03088591020210726
[Epoch 20, Batch 1600] loss: 0.013593840386810614
[Epoch 20, Batch 1700] loss: 0.016965332032374394
[Epoch 20, Batch 1800] loss: 0.011044983744093635
[Epoch 20, Batch 1900] loss: 0.010019414228701277
[Epoch 20, Batch 2000] loss: 0.031095151017762047
[Epoch 20, Batch 2100] loss: 0.040934385686151466
[Epoch 20, Batch 2200] loss: 0.040422878586058746
[Epoch 20, Batch 2300] loss: 0.0424973135974767
[Epoch 20, Batch 2400] loss: 0.012916195963344989
[Epoch 20, Batch 2500] loss: 0.02621522815463308
[Epoch 20, Batch 2600] loss: 0.013285386377020387
[Epoch 20, Batch 2700] loss: 0.019205783908695935
[Epoch 20, Batch 2800] loss: 0.015226757828543071
[Epoch 20, Batch 2900] loss: 0.018626524448724792
[Epoch 20, Batch 3000] loss: 0.009313602138293894
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9879
Overfitting: 0.0523
[Epoch 21, Batch 100] loss: 0.005794677619898252
[Epoch 21, Batch 200] loss: 0.0020661961599358404
[Epoch 21, Batch 300] loss: 0.005500855524494241
[Epoch 21, Batch 400] loss: 0.008583578050437256
[Epoch 21, Batch 500] loss: 0.011868044844768675
[Epoch 21, Batch 600] loss: 0.005718367815669274
[Epoch 21, Batch 700] loss: 0.023108606649760173
[Epoch 21, Batch 800] loss: 0.005440844597571157
[Epoch 21, Batch 900] loss: 0.009589232807260295
[Epoch 21, Batch 1000] loss: 0.015492139597773348
[Epoch 21, Batch 1100] loss: 0.0024354746734074253
[Epoch 21, Batch 1200] loss: 0.0019915113409885122
[Epoch 21, Batch 1300] loss: 0.009078275583896987
[Epoch 21, Batch 1400] loss: 0.006186659157938559
[Epoch 21, Batch 1500] loss: 0.006988017087183609
[Epoch 21, Batch 1600] loss: 0.008038869937279411
[Epoch 21, Batch 1700] loss: 0.03020364022747142
[Epoch 21, Batch 1800] loss: 0.027674670959575955
[Epoch 21, Batch 1900] loss: 0.016988886788877746
[Epoch 21, Batch 2000] loss: 0.009411273921590232
[Epoch 21, Batch 2100] loss: 0.019918080486890942
[Epoch 21, Batch 2200] loss: 0.017512761406266578
[Epoch 21, Batch 2300] loss: 0.016574831840402378
[Epoch 21, Batch 2400] loss: 0.022738688061644884
[Epoch 21, Batch 2500] loss: 0.008915164699089524
[Epoch 21, Batch 2600] loss: 0.013764417969608735
[Epoch 21, Batch 2700] loss: 0.016615207924753114
[Epoch 21, Batch 2800] loss: 0.037529905061447
[Epoch 21, Batch 2900] loss: 0.02029637890232123
[Epoch 21, Batch 3000] loss: 0.025356044515998998
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9864
Overfitting: 0.0665
[Epoch 22, Batch 100] loss: 0.011032402780063144
[Epoch 22, Batch 200] loss: 0.007785903343912266
[Epoch 22, Batch 300] loss: 0.0021551652259065215
[Epoch 22, Batch 400] loss: 0.005402034740706822
[Epoch 22, Batch 500] loss: 0.012353818304394543
[Epoch 22, Batch 600] loss: 0.007142311688837539
[Epoch 22, Batch 700] loss: 0.011025059329995073
[Epoch 22, Batch 800] loss: 0.015166566269960864
[Epoch 22, Batch 900] loss: 0.013448638091293104
[Epoch 22, Batch 1000] loss: 0.005608122956471209
[Epoch 22, Batch 1100] loss: 0.0101689483259049
[Epoch 22, Batch 1200] loss: 0.0034154498969433834
[Epoch 22, Batch 1300] loss: 0.005977037532117757
[Epoch 22, Batch 1400] loss: 0.025303059865043675
[Epoch 22, Batch 1500] loss: 0.008496505565939075
[Epoch 22, Batch 1600] loss: 0.01605399612417516
[Epoch 22, Batch 1700] loss: 0.0029338786200586455
[Epoch 22, Batch 1800] loss: 0.009506328131988399
[Epoch 22, Batch 1900] loss: 0.02152172535967309
[Epoch 22, Batch 2000] loss: 0.013597186082584862
[Epoch 22, Batch 2100] loss: 0.022404734307729646
[Epoch 22, Batch 2200] loss: 0.019572461510697498
[Epoch 22, Batch 2300] loss: 0.03994835615483127
[Epoch 22, Batch 2400] loss: 0.03315456652894284
[Epoch 22, Batch 2500] loss: 0.015000176339011535
[Epoch 22, Batch 2600] loss: 0.012500998847720646
[Epoch 22, Batch 2700] loss: 0.013073499579654273
[Epoch 22, Batch 2800] loss: 0.014620714264418936
[Epoch 22, Batch 2900] loss: 0.022487553333694663
[Epoch 22, Batch 3000] loss: 0.00562347488870703
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0629
Validation Accuracy: 0.9878
Overfitting: 0.0629
[Epoch 23, Batch 100] loss: 0.0012722646919153568
[Epoch 23, Batch 200] loss: 0.005271328016364509
[Epoch 23, Batch 300] loss: 0.005559045406411318
[Epoch 23, Batch 400] loss: 0.012214275660177085
[Epoch 23, Batch 500] loss: 0.02052883944616119
[Epoch 23, Batch 600] loss: 0.012876399727553247
[Epoch 23, Batch 700] loss: 0.005628363688740698
[Epoch 23, Batch 800] loss: 0.013755517500881505
[Epoch 23, Batch 900] loss: 0.008730171617688028
[Epoch 23, Batch 1000] loss: 0.01908140447337689
[Epoch 23, Batch 1100] loss: 0.024591648488492157
[Epoch 23, Batch 1200] loss: 0.013019244852026017
[Epoch 23, Batch 1300] loss: 0.006724421437744388
[Epoch 23, Batch 1400] loss: 0.015191078471087565
[Epoch 23, Batch 1500] loss: 0.014948437094463545
[Epoch 23, Batch 1600] loss: 0.009764408299731415
[Epoch 23, Batch 1700] loss: 0.023223806015696596
[Epoch 23, Batch 1800] loss: 0.03701388525431206
[Epoch 23, Batch 1900] loss: 0.01070516058416423
[Epoch 23, Batch 2000] loss: 0.014460569723611698
[Epoch 23, Batch 2100] loss: 0.033352159017239306
[Epoch 23, Batch 2200] loss: 0.019953130962994284
[Epoch 23, Batch 2300] loss: 0.022422412094353028
[Epoch 23, Batch 2400] loss: 0.022866996668451267
[Epoch 23, Batch 2500] loss: 0.009671513665147336
[Epoch 23, Batch 2600] loss: 0.017625650615984513
[Epoch 23, Batch 2700] loss: 0.007192211325280136
[Epoch 23, Batch 2800] loss: 0.008155245895285072
[Epoch 23, Batch 2900] loss: 0.017055375914820137
[Epoch 23, Batch 3000] loss: 0.022449975507631708
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0679
Validation Accuracy: 0.9864
Overfitting: 0.0679
[Epoch 24, Batch 100] loss: 0.013242366745302814
[Epoch 24, Batch 200] loss: 0.015427072242639919
[Epoch 24, Batch 300] loss: 0.012989219127129652
[Epoch 24, Batch 400] loss: 0.005158425342850319
[Epoch 24, Batch 500] loss: 0.00488168943470833
[Epoch 24, Batch 600] loss: 0.002213430968138801
[Epoch 24, Batch 700] loss: 0.004524044531578961
[Epoch 24, Batch 800] loss: 0.005371918243105864
[Epoch 24, Batch 900] loss: 0.007087025719679292
[Epoch 24, Batch 1000] loss: 0.002405824269503878
[Epoch 24, Batch 1100] loss: 0.013114560546244514
[Epoch 24, Batch 1200] loss: 0.00689393347124895
[Epoch 24, Batch 1300] loss: 0.01675900790181522
[Epoch 24, Batch 1400] loss: 0.015840478590212932
[Epoch 24, Batch 1500] loss: 0.0072867276028818
[Epoch 24, Batch 1600] loss: 0.018391970793371445
[Epoch 24, Batch 1700] loss: 0.02420291529114509
[Epoch 24, Batch 1800] loss: 0.010510402142779398
[Epoch 24, Batch 1900] loss: 0.023617923727801693
[Epoch 24, Batch 2000] loss: 0.004195517172286829
[Epoch 24, Batch 2100] loss: 0.016070198425124423
[Epoch 24, Batch 2200] loss: 0.0104770887331081
[Epoch 24, Batch 2300] loss: 0.019668535343875856
[Epoch 24, Batch 2400] loss: 0.019417115982286418
[Epoch 24, Batch 2500] loss: 0.02410229479278854
[Epoch 24, Batch 2600] loss: 0.023964957508183633
[Epoch 24, Batch 2700] loss: 0.028140600247280982
[Epoch 24, Batch 2800] loss: 0.018066691795520375
[Epoch 24, Batch 2900] loss: 0.01007151733483731
[Epoch 24, Batch 3000] loss: 0.0018200253625221662
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0613
Validation Accuracy: 0.9874
Overfitting: 0.0613
Fold 4 validation loss: 0.0613
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 1.9052794086933136
[Epoch 1, Batch 200] loss: 0.5661537074297667
[Epoch 1, Batch 300] loss: 0.30717990281060337
[Epoch 1, Batch 400] loss: 0.2229209920577705
[Epoch 1, Batch 500] loss: 0.17960488700773566
[Epoch 1, Batch 600] loss: 0.21661722164135427
[Epoch 1, Batch 700] loss: 0.18542680448386817
[Epoch 1, Batch 800] loss: 0.16560106637887656
[Epoch 1, Batch 900] loss: 0.16146123444428667
[Epoch 1, Batch 1000] loss: 0.1521994064608589
[Epoch 1, Batch 1100] loss: 0.11854964741098228
[Epoch 1, Batch 1200] loss: 0.14257653864013264
[Epoch 1, Batch 1300] loss: 0.11389886663644574
[Epoch 1, Batch 1400] loss: 0.11286967840278521
[Epoch 1, Batch 1500] loss: 0.1114773182949284
[Epoch 1, Batch 1600] loss: 0.11682534506195225
[Epoch 1, Batch 1700] loss: 0.14567059942230118
[Epoch 1, Batch 1800] loss: 0.11250019917730242
[Epoch 1, Batch 1900] loss: 0.10376198739744723
[Epoch 1, Batch 2000] loss: 0.1062210292959935
[Epoch 1, Batch 2100] loss: 0.10259335854381789
[Epoch 1, Batch 2200] loss: 0.09366094462544425
[Epoch 1, Batch 2300] loss: 0.0857443377445452
[Epoch 1, Batch 2400] loss: 0.10620637996820732
[Epoch 1, Batch 2500] loss: 0.09870068877455196
[Epoch 1, Batch 2600] loss: 0.09248204766423442
[Epoch 1, Batch 2700] loss: 0.10918321719800587
[Epoch 1, Batch 2800] loss: 0.0818956472093123
[Epoch 1, Batch 2900] loss: 0.07498830808326602
[Epoch 1, Batch 3000] loss: 0.09320786985132144
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0960
Validation Accuracy: 0.9706
Overfitting: 0.0960
Best model saved at epoch 1 with validation loss: 0.0960
[Epoch 2, Batch 100] loss: 0.03465859693606035
[Epoch 2, Batch 200] loss: 0.06262834298162488
[Epoch 2, Batch 300] loss: 0.07768159330735216
[Epoch 2, Batch 400] loss: 0.05842913962318562
[Epoch 2, Batch 500] loss: 0.08304987446783343
[Epoch 2, Batch 600] loss: 0.06048357685125666
[Epoch 2, Batch 700] loss: 0.06215519456833135
[Epoch 2, Batch 800] loss: 0.09062933200242697
[Epoch 2, Batch 900] loss: 0.07594152682300774
[Epoch 2, Batch 1000] loss: 0.06066991009109188
[Epoch 2, Batch 1100] loss: 0.07469845942629036
[Epoch 2, Batch 1200] loss: 0.0713873978774791
[Epoch 2, Batch 1300] loss: 0.04711407953873277
[Epoch 2, Batch 1400] loss: 0.05252839698838216
[Epoch 2, Batch 1500] loss: 0.05898252453785972
[Epoch 2, Batch 1600] loss: 0.07999217279837467
[Epoch 2, Batch 1700] loss: 0.05637583111165441
[Epoch 2, Batch 1800] loss: 0.11275341283995659
[Epoch 2, Batch 1900] loss: 0.06290392453534878
[Epoch 2, Batch 2000] loss: 0.07336793778202264
[Epoch 2, Batch 2100] loss: 0.06521687857413781
[Epoch 2, Batch 2200] loss: 0.06508726726024179
[Epoch 2, Batch 2300] loss: 0.05089393212823779
[Epoch 2, Batch 2400] loss: 0.06018257073199493
[Epoch 2, Batch 2500] loss: 0.0733319469547132
[Epoch 2, Batch 2600] loss: 0.06295926657941892
[Epoch 2, Batch 2700] loss: 0.04316498287163995
[Epoch 2, Batch 2800] loss: 0.05780048565808102
[Epoch 2, Batch 2900] loss: 0.06510678066653781
[Epoch 2, Batch 3000] loss: 0.06871316174147069
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0744
Validation Accuracy: 0.9769
Overfitting: 0.0744
Best model saved at epoch 2 with validation loss: 0.0744
[Epoch 3, Batch 100] loss: 0.0615068634605268
[Epoch 3, Batch 200] loss: 0.043462804537266496
[Epoch 3, Batch 300] loss: 0.040109988796466496
[Epoch 3, Batch 400] loss: 0.04948084696181468
[Epoch 3, Batch 500] loss: 0.03911052071722224
[Epoch 3, Batch 600] loss: 0.05459301098562719
[Epoch 3, Batch 700] loss: 0.05003607809650021
[Epoch 3, Batch 800] loss: 0.04890003971024271
[Epoch 3, Batch 900] loss: 0.05539304419474775
[Epoch 3, Batch 1000] loss: 0.07779605691030156
[Epoch 3, Batch 1100] loss: 0.0504319521997968
[Epoch 3, Batch 1200] loss: 0.030012286091987334
[Epoch 3, Batch 1300] loss: 0.05244172447894016
[Epoch 3, Batch 1400] loss: 0.032603120652856886
[Epoch 3, Batch 1500] loss: 0.047873931882204485
[Epoch 3, Batch 1600] loss: 0.053109624529606665
[Epoch 3, Batch 1700] loss: 0.058914367863617374
[Epoch 3, Batch 1800] loss: 0.037614701100465026
[Epoch 3, Batch 1900] loss: 0.0756525427653105
[Epoch 3, Batch 2000] loss: 0.04502513926505344
[Epoch 3, Batch 2100] loss: 0.06615038137257216
[Epoch 3, Batch 2200] loss: 0.06479509249154944
[Epoch 3, Batch 2300] loss: 0.054140845905130845
[Epoch 3, Batch 2400] loss: 0.04514032919656529
[Epoch 3, Batch 2500] loss: 0.05586477070130059
[Epoch 3, Batch 2600] loss: 0.041446095764295025
[Epoch 3, Batch 2700] loss: 0.07288076308665041
[Epoch 3, Batch 2800] loss: 0.05822575609519845
[Epoch 3, Batch 2900] loss: 0.04354231491743121
[Epoch 3, Batch 3000] loss: 0.042576482246513475
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0575
Validation Accuracy: 0.9836
Overfitting: 0.0575
Best model saved at epoch 3 with validation loss: 0.0575
[Epoch 4, Batch 100] loss: 0.02356163537069733
[Epoch 4, Batch 200] loss: 0.03106483606781694
[Epoch 4, Batch 300] loss: 0.02941098439925554
[Epoch 4, Batch 400] loss: 0.054313065956012
[Epoch 4, Batch 500] loss: 0.04462666895182338
[Epoch 4, Batch 600] loss: 0.03215948948141886
[Epoch 4, Batch 700] loss: 0.02985400467812724
[Epoch 4, Batch 800] loss: 0.0417225940141725
[Epoch 4, Batch 900] loss: 0.041807863027825076
[Epoch 4, Batch 1000] loss: 0.03778877777888738
[Epoch 4, Batch 1100] loss: 0.03462310575820084
[Epoch 4, Batch 1200] loss: 0.048931034680517765
[Epoch 4, Batch 1300] loss: 0.05737512619180052
[Epoch 4, Batch 1400] loss: 0.030882117372480023
[Epoch 4, Batch 1500] loss: 0.0397077715897376
[Epoch 4, Batch 1600] loss: 0.028260359292016802
[Epoch 4, Batch 1700] loss: 0.046686255564927705
[Epoch 4, Batch 1800] loss: 0.05983818904860527
[Epoch 4, Batch 1900] loss: 0.058642250079428776
[Epoch 4, Batch 2000] loss: 0.024990034521943018
[Epoch 4, Batch 2100] loss: 0.04227804062731593
[Epoch 4, Batch 2200] loss: 0.03659636765236428
[Epoch 4, Batch 2300] loss: 0.0498311054396072
[Epoch 4, Batch 2400] loss: 0.040815009925372576
[Epoch 4, Batch 2500] loss: 0.032233065151604026
[Epoch 4, Batch 2600] loss: 0.053840968456588596
[Epoch 4, Batch 2700] loss: 0.04528063084763744
[Epoch 4, Batch 2800] loss: 0.03318410775205848
[Epoch 4, Batch 2900] loss: 0.024813871452852253
[Epoch 4, Batch 3000] loss: 0.04019976112151198
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9817
Overfitting: 0.0603
[Epoch 5, Batch 100] loss: 0.03321868715220262
[Epoch 5, Batch 200] loss: 0.032451777849328206
[Epoch 5, Batch 300] loss: 0.033111177904429495
[Epoch 5, Batch 400] loss: 0.038805395727586074
[Epoch 5, Batch 500] loss: 0.021981564290235837
[Epoch 5, Batch 600] loss: 0.047478545372941314
[Epoch 5, Batch 700] loss: 0.018558749490657646
[Epoch 5, Batch 800] loss: 0.029616101513747706
[Epoch 5, Batch 900] loss: 0.030651257116787747
[Epoch 5, Batch 1000] loss: 0.01471890030168879
[Epoch 5, Batch 1100] loss: 0.047095393337440325
[Epoch 5, Batch 1200] loss: 0.02175641987705603
[Epoch 5, Batch 1300] loss: 0.02425011374838505
[Epoch 5, Batch 1400] loss: 0.03292522257726887
[Epoch 5, Batch 1500] loss: 0.022437974046674754
[Epoch 5, Batch 1600] loss: 0.039746231023655126
[Epoch 5, Batch 1700] loss: 0.03629120983201574
[Epoch 5, Batch 1800] loss: 0.037195853005878236
[Epoch 5, Batch 1900] loss: 0.02958947360431921
[Epoch 5, Batch 2000] loss: 0.025150116340581688
[Epoch 5, Batch 2100] loss: 0.02292021668124562
[Epoch 5, Batch 2200] loss: 0.05829929692445148
[Epoch 5, Batch 2300] loss: 0.0337543154910054
[Epoch 5, Batch 2400] loss: 0.032268897630365244
[Epoch 5, Batch 2500] loss: 0.030793957658861473
[Epoch 5, Batch 2600] loss: 0.027682147952509693
[Epoch 5, Batch 2700] loss: 0.035697206655386254
[Epoch 5, Batch 2800] loss: 0.036954018018850544
[Epoch 5, Batch 2900] loss: 0.06421619262047898
[Epoch 5, Batch 3000] loss: 0.04281638244064652
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0555
Validation Accuracy: 0.9835
Overfitting: 0.0555
Best model saved at epoch 5 with validation loss: 0.0555
[Epoch 6, Batch 100] loss: 0.015884456683816096
[Epoch 6, Batch 200] loss: 0.03730171562628129
[Epoch 6, Batch 300] loss: 0.02345940849571889
[Epoch 6, Batch 400] loss: 0.02886274365562258
[Epoch 6, Batch 500] loss: 0.015531384017325536
[Epoch 6, Batch 600] loss: 0.02739780728785263
[Epoch 6, Batch 700] loss: 0.05034996689981199
[Epoch 6, Batch 800] loss: 0.01829957823967561
[Epoch 6, Batch 900] loss: 0.02924859797969475
[Epoch 6, Batch 1000] loss: 0.020654786762070217
[Epoch 6, Batch 1100] loss: 0.02488612073256263
[Epoch 6, Batch 1200] loss: 0.03171498126132064
[Epoch 6, Batch 1300] loss: 0.017316708280759485
[Epoch 6, Batch 1400] loss: 0.026021800433052248
[Epoch 6, Batch 1500] loss: 0.034509073259050636
[Epoch 6, Batch 1600] loss: 0.026913111413205116
[Epoch 6, Batch 1700] loss: 0.031449077327633856
[Epoch 6, Batch 1800] loss: 0.024470153335942088
[Epoch 6, Batch 1900] loss: 0.03516630336253911
[Epoch 6, Batch 2000] loss: 0.02693643327064592
[Epoch 6, Batch 2100] loss: 0.03672649712744715
[Epoch 6, Batch 2200] loss: 0.021731930484929763
[Epoch 6, Batch 2300] loss: 0.03741136508269847
[Epoch 6, Batch 2400] loss: 0.024185383498411282
[Epoch 6, Batch 2500] loss: 0.029761417626232287
[Epoch 6, Batch 2600] loss: 0.02875929161226395
[Epoch 6, Batch 2700] loss: 0.02680769186041289
[Epoch 6, Batch 2800] loss: 0.02037968364293306
[Epoch 6, Batch 2900] loss: 0.03354734352666583
[Epoch 6, Batch 3000] loss: 0.03135580181054138
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0802
Validation Accuracy: 0.9789
Overfitting: 0.0802
[Epoch 7, Batch 100] loss: 0.02816604784411709
[Epoch 7, Batch 200] loss: 0.032816127433357
[Epoch 7, Batch 300] loss: 0.012880432173807322
[Epoch 7, Batch 400] loss: 0.02176634320473397
[Epoch 7, Batch 500] loss: 0.047226847648998954
[Epoch 7, Batch 600] loss: 0.0231841429587962
[Epoch 7, Batch 700] loss: 0.019157309576988836
[Epoch 7, Batch 800] loss: 0.027661545187532964
[Epoch 7, Batch 900] loss: 0.023077804669919714
[Epoch 7, Batch 1000] loss: 0.023113649155620804
[Epoch 7, Batch 1100] loss: 0.03599990070824788
[Epoch 7, Batch 1200] loss: 0.030949580599062755
[Epoch 7, Batch 1300] loss: 0.022929699048581824
[Epoch 7, Batch 1400] loss: 0.011144681811692862
[Epoch 7, Batch 1500] loss: 0.01735134551741794
[Epoch 7, Batch 1600] loss: 0.026303765677366756
[Epoch 7, Batch 1700] loss: 0.0146602020885026
[Epoch 7, Batch 1800] loss: 0.03293798189412314
[Epoch 7, Batch 1900] loss: 0.03398455876408121
[Epoch 7, Batch 2000] loss: 0.02896924530960405
[Epoch 7, Batch 2100] loss: 0.017115628193848806
[Epoch 7, Batch 2200] loss: 0.04377375031633392
[Epoch 7, Batch 2300] loss: 0.024032796851370223
[Epoch 7, Batch 2400] loss: 0.01722273026808125
[Epoch 7, Batch 2500] loss: 0.02445209215577506
[Epoch 7, Batch 2600] loss: 0.02580277960785679
[Epoch 7, Batch 2700] loss: 0.023610634008480815
[Epoch 7, Batch 2800] loss: 0.032309256220432875
[Epoch 7, Batch 2900] loss: 0.042088817686808395
[Epoch 7, Batch 3000] loss: 0.028800306308257858
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0454
Validation Accuracy: 0.9880
Overfitting: 0.0454
Best model saved at epoch 7 with validation loss: 0.0454
[Epoch 8, Batch 100] loss: 0.013635373295449539
[Epoch 8, Batch 200] loss: 0.013520215755709159
[Epoch 8, Batch 300] loss: 0.01583745744648468
[Epoch 8, Batch 400] loss: 0.025633773620112946
[Epoch 8, Batch 500] loss: 0.024407571147752948
[Epoch 8, Batch 600] loss: 0.04894090617119673
[Epoch 8, Batch 700] loss: 0.027813331067427498
[Epoch 8, Batch 800] loss: 0.027190754516886954
[Epoch 8, Batch 900] loss: 0.033864950866282016
[Epoch 8, Batch 1000] loss: 0.0322032427835768
[Epoch 8, Batch 1100] loss: 0.0240137037333443
[Epoch 8, Batch 1200] loss: 0.031092736817236073
[Epoch 8, Batch 1300] loss: 0.019892189769564084
[Epoch 8, Batch 1400] loss: 0.025371143332443183
[Epoch 8, Batch 1500] loss: 0.00948075189657061
[Epoch 8, Batch 1600] loss: 0.03761430871114612
[Epoch 8, Batch 1700] loss: 0.016594383080326906
[Epoch 8, Batch 1800] loss: 0.027737354610476928
[Epoch 8, Batch 1900] loss: 0.020730002621085077
[Epoch 8, Batch 2000] loss: 0.021002545225549056
[Epoch 8, Batch 2100] loss: 0.016544356177556663
[Epoch 8, Batch 2200] loss: 0.026657215927048127
[Epoch 8, Batch 2300] loss: 0.01889785527317571
[Epoch 8, Batch 2400] loss: 0.026018090735379928
[Epoch 8, Batch 2500] loss: 0.023790718952958513
[Epoch 8, Batch 2600] loss: 0.021266820518013672
[Epoch 8, Batch 2700] loss: 0.041844839350160326
[Epoch 8, Batch 2800] loss: 0.04048076381390274
[Epoch 8, Batch 2900] loss: 0.02540697078940866
[Epoch 8, Batch 3000] loss: 0.025942712329312487
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9883
Overfitting: 0.0476
[Epoch 9, Batch 100] loss: 0.010515729042244288
[Epoch 9, Batch 200] loss: 0.020218392491401574
[Epoch 9, Batch 300] loss: 0.023499876886778567
[Epoch 9, Batch 400] loss: 0.02704676723897819
[Epoch 9, Batch 500] loss: 0.023884146490299827
[Epoch 9, Batch 600] loss: 0.015981767665598456
[Epoch 9, Batch 700] loss: 0.013935981576927929
[Epoch 9, Batch 800] loss: 0.019274541995476967
[Epoch 9, Batch 900] loss: 0.013073091675205149
[Epoch 9, Batch 1000] loss: 0.01638405873622901
[Epoch 9, Batch 1100] loss: 0.009104552984674684
[Epoch 9, Batch 1200] loss: 0.009775670449136839
[Epoch 9, Batch 1300] loss: 0.01718390657244754
[Epoch 9, Batch 1400] loss: 0.03849637784278002
[Epoch 9, Batch 1500] loss: 0.022005443598882266
[Epoch 9, Batch 1600] loss: 0.025394999696177364
[Epoch 9, Batch 1700] loss: 0.0214558063388165
[Epoch 9, Batch 1800] loss: 0.023829452819491052
[Epoch 9, Batch 1900] loss: 0.04576002188163329
[Epoch 9, Batch 2000] loss: 0.021702801793743447
[Epoch 9, Batch 2100] loss: 0.025886179939991507
[Epoch 9, Batch 2200] loss: 0.0210131933633329
[Epoch 9, Batch 2300] loss: 0.0345456415528912
[Epoch 9, Batch 2400] loss: 0.03082319749384624
[Epoch 9, Batch 2500] loss: 0.03933264818811949
[Epoch 9, Batch 2600] loss: 0.040738791030717036
[Epoch 9, Batch 2700] loss: 0.023184218189171588
[Epoch 9, Batch 2800] loss: 0.009206564068047101
[Epoch 9, Batch 2900] loss: 0.030176942548969805
[Epoch 9, Batch 3000] loss: 0.03209799843371457
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9878
Overfitting: 0.0527
[Epoch 10, Batch 100] loss: 0.015522232691773752
[Epoch 10, Batch 200] loss: 0.013927884540713933
[Epoch 10, Batch 300] loss: 0.008643055587258175
[Epoch 10, Batch 400] loss: 0.008395924730683646
[Epoch 10, Batch 500] loss: 0.019393104428808598
[Epoch 10, Batch 600] loss: 0.04818356034450119
[Epoch 10, Batch 700] loss: 0.015101381116051017
[Epoch 10, Batch 800] loss: 0.01203709405289203
[Epoch 10, Batch 900] loss: 0.00927579476826878
[Epoch 10, Batch 1000] loss: 0.027496994907460815
[Epoch 10, Batch 1100] loss: 0.024310645191735317
[Epoch 10, Batch 1200] loss: 0.014423374965891184
[Epoch 10, Batch 1300] loss: 0.006021478876014612
[Epoch 10, Batch 1400] loss: 0.02610712316769849
[Epoch 10, Batch 1500] loss: 0.02101682497923271
[Epoch 10, Batch 1600] loss: 0.024349196161831514
[Epoch 10, Batch 1700] loss: 0.025060474335598427
[Epoch 10, Batch 1800] loss: 0.01594870534841448
[Epoch 10, Batch 1900] loss: 0.010462227901275583
[Epoch 10, Batch 2000] loss: 0.017709083320178252
[Epoch 10, Batch 2100] loss: 0.013499734559577377
[Epoch 10, Batch 2200] loss: 0.02792326337122688
[Epoch 10, Batch 2300] loss: 0.022305372801469048
[Epoch 10, Batch 2400] loss: 0.025230813939498376
[Epoch 10, Batch 2500] loss: 0.00872538416656596
[Epoch 10, Batch 2600] loss: 0.033802192163801405
[Epoch 10, Batch 2700] loss: 0.03500544378817267
[Epoch 10, Batch 2800] loss: 0.0315178221590611
[Epoch 10, Batch 2900] loss: 0.029660009519609502
[Epoch 10, Batch 3000] loss: 0.02315097637137818
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9851
Overfitting: 0.0632
[Epoch 11, Batch 100] loss: 0.023403578124692785
[Epoch 11, Batch 200] loss: 0.01187546127268888
[Epoch 11, Batch 300] loss: 0.013938361907231354
[Epoch 11, Batch 400] loss: 0.018155069563048302
[Epoch 11, Batch 500] loss: 0.010857996940801442
[Epoch 11, Batch 600] loss: 0.01195466640000145
[Epoch 11, Batch 700] loss: 0.029375071909600193
[Epoch 11, Batch 800] loss: 0.01230207255691127
[Epoch 11, Batch 900] loss: 0.0126060996089236
[Epoch 11, Batch 1000] loss: 0.015228428724978897
[Epoch 11, Batch 1100] loss: 0.02221738680544277
[Epoch 11, Batch 1200] loss: 0.027742513096434288
[Epoch 11, Batch 1300] loss: 0.026719730345815266
[Epoch 11, Batch 1400] loss: 0.034065429619501514
[Epoch 11, Batch 1500] loss: 0.008779344489266806
[Epoch 11, Batch 1600] loss: 0.01568977106500057
[Epoch 11, Batch 1700] loss: 0.02749569373220311
[Epoch 11, Batch 1800] loss: 0.030772145706200717
[Epoch 11, Batch 1900] loss: 0.006283420820246874
[Epoch 11, Batch 2000] loss: 0.03404941561928013
[Epoch 11, Batch 2100] loss: 0.01124975750050794
[Epoch 11, Batch 2200] loss: 0.018995672671762803
[Epoch 11, Batch 2300] loss: 0.006939702865885025
[Epoch 11, Batch 2400] loss: 0.009534870092996925
[Epoch 11, Batch 2500] loss: 0.010888950970074661
[Epoch 11, Batch 2600] loss: 0.012317173017204369
[Epoch 11, Batch 2700] loss: 0.015016225115272447
[Epoch 11, Batch 2800] loss: 0.02750765249191829
[Epoch 11, Batch 2900] loss: 0.01572379499928729
[Epoch 11, Batch 3000] loss: 0.027483897722907644
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9873
Overfitting: 0.0543
[Epoch 12, Batch 100] loss: 0.013132785934528499
[Epoch 12, Batch 200] loss: 0.01677658568626839
[Epoch 12, Batch 300] loss: 0.014299613549171255
[Epoch 12, Batch 400] loss: 0.0077737724457404055
[Epoch 12, Batch 500] loss: 0.016294114844878464
[Epoch 12, Batch 600] loss: 0.018607602034812487
[Epoch 12, Batch 700] loss: 0.009744043440661584
[Epoch 12, Batch 800] loss: 0.009538895683594149
[Epoch 12, Batch 900] loss: 0.01665793321866147
[Epoch 12, Batch 1000] loss: 0.017704841695636443
[Epoch 12, Batch 1100] loss: 0.012443623578965201
[Epoch 12, Batch 1200] loss: 0.02254643147208199
[Epoch 12, Batch 1300] loss: 0.007851949480289307
[Epoch 12, Batch 1400] loss: 0.011459016875660843
[Epoch 12, Batch 1500] loss: 0.030072003928166988
[Epoch 12, Batch 1600] loss: 0.011831131661486723
[Epoch 12, Batch 1700] loss: 0.010918752368349658
[Epoch 12, Batch 1800] loss: 0.014798436721561501
[Epoch 12, Batch 1900] loss: 0.02104397373113926
[Epoch 12, Batch 2000] loss: 0.004628512495023927
[Epoch 12, Batch 2100] loss: 0.016361662995971072
[Epoch 12, Batch 2200] loss: 0.0206237272722187
[Epoch 12, Batch 2300] loss: 0.01583937585683639
[Epoch 12, Batch 2400] loss: 0.017894880957702527
[Epoch 12, Batch 2500] loss: 0.007482106753993776
[Epoch 12, Batch 2600] loss: 0.042398195650945214
[Epoch 12, Batch 2700] loss: 0.04932441620595227
[Epoch 12, Batch 2800] loss: 0.02177547948789993
[Epoch 12, Batch 2900] loss: 0.016327196764042356
[Epoch 12, Batch 3000] loss: 0.04308638879515001
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0730
Validation Accuracy: 0.9820
Overfitting: 0.0730
[Epoch 13, Batch 100] loss: 0.02918260458464374
[Epoch 13, Batch 200] loss: 0.00673215907789114
[Epoch 13, Batch 300] loss: 0.015731354690163356
[Epoch 13, Batch 400] loss: 0.012137837475305986
[Epoch 13, Batch 500] loss: 0.024972083139561202
[Epoch 13, Batch 600] loss: 0.011499353517642703
[Epoch 13, Batch 700] loss: 0.009088498618198155
[Epoch 13, Batch 800] loss: 0.013031468565732335
[Epoch 13, Batch 900] loss: 0.0258518826026841
[Epoch 13, Batch 1000] loss: 0.008332928792943903
[Epoch 13, Batch 1100] loss: 0.019590718820084518
[Epoch 13, Batch 1200] loss: 0.014600273637136639
[Epoch 13, Batch 1300] loss: 0.010876501552178296
[Epoch 13, Batch 1400] loss: 0.016219294006052234
[Epoch 13, Batch 1500] loss: 0.009876431148203295
[Epoch 13, Batch 1600] loss: 0.022921638185700317
[Epoch 13, Batch 1700] loss: 0.022689411662472594
[Epoch 13, Batch 1800] loss: 0.03320809007650766
[Epoch 13, Batch 1900] loss: 0.017170314222485102
[Epoch 13, Batch 2000] loss: 0.014423139269459
[Epoch 13, Batch 2100] loss: 0.01288872223440876
[Epoch 13, Batch 2200] loss: 0.008693234485361571
[Epoch 13, Batch 2300] loss: 0.015603221878694456
[Epoch 13, Batch 2400] loss: 0.021223237189265075
[Epoch 13, Batch 2500] loss: 0.012610322949500681
[Epoch 13, Batch 2600] loss: 0.009339377094003681
[Epoch 13, Batch 2700] loss: 0.02133858391776471
[Epoch 13, Batch 2800] loss: 0.029991886686733266
[Epoch 13, Batch 2900] loss: 0.02771350368078515
[Epoch 13, Batch 3000] loss: 0.015601045034303667
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0604
Validation Accuracy: 0.9860
Overfitting: 0.0604
[Epoch 14, Batch 100] loss: 0.011553365673579914
[Epoch 14, Batch 200] loss: 0.032321391672225704
[Epoch 14, Batch 300] loss: 0.01997083874282559
[Epoch 14, Batch 400] loss: 0.010772044831159632
[Epoch 14, Batch 500] loss: 0.01835098653251748
[Epoch 14, Batch 600] loss: 0.0054309718567944285
[Epoch 14, Batch 700] loss: 0.008711694997081736
[Epoch 14, Batch 800] loss: 0.01739510245844823
[Epoch 14, Batch 900] loss: 0.02747174060480148
[Epoch 14, Batch 1000] loss: 0.037041301173558666
[Epoch 14, Batch 1100] loss: 0.01237114775412536
[Epoch 14, Batch 1200] loss: 0.030047376392875053
[Epoch 14, Batch 1300] loss: 0.04545015277333988
[Epoch 14, Batch 1400] loss: 0.02062194269684589
[Epoch 14, Batch 1500] loss: 0.015845820445259874
[Epoch 14, Batch 1600] loss: 0.044555298599844945
[Epoch 14, Batch 1700] loss: 0.02013294232506496
[Epoch 14, Batch 1800] loss: 0.00830708456384798
[Epoch 14, Batch 1900] loss: 0.0160063863114506
[Epoch 14, Batch 2000] loss: 0.009747231730201023
[Epoch 14, Batch 2100] loss: 0.023612907834009603
[Epoch 14, Batch 2200] loss: 0.022765854270440825
[Epoch 14, Batch 2300] loss: 0.02121180029576692
[Epoch 14, Batch 2400] loss: 0.012360473732918535
[Epoch 14, Batch 2500] loss: 0.020784624495612435
[Epoch 14, Batch 2600] loss: 0.02377114964866081
[Epoch 14, Batch 2700] loss: 0.007857624467995095
[Epoch 14, Batch 2800] loss: 0.017381191913056208
[Epoch 14, Batch 2900] loss: 0.019179621539413737
[Epoch 14, Batch 3000] loss: 0.023679573855388297
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0598
Validation Accuracy: 0.9862
Overfitting: 0.0598
[Epoch 15, Batch 100] loss: 0.004005111381887758
[Epoch 15, Batch 200] loss: 0.005510846625774768
[Epoch 15, Batch 300] loss: 0.005251969474470144
[Epoch 15, Batch 400] loss: 0.006179949541735734
[Epoch 15, Batch 500] loss: 0.008891992690173751
[Epoch 15, Batch 600] loss: 0.02034775935711279
[Epoch 15, Batch 700] loss: 0.007081842391811506
[Epoch 15, Batch 800] loss: 0.008308962159376487
[Epoch 15, Batch 900] loss: 0.01015366475388852
[Epoch 15, Batch 1000] loss: 0.008452650009683503
[Epoch 15, Batch 1100] loss: 0.01528447065231859
[Epoch 15, Batch 1200] loss: 0.008757881921356372
[Epoch 15, Batch 1300] loss: 0.008089651945280938
[Epoch 15, Batch 1400] loss: 0.006103407148375979
[Epoch 15, Batch 1500] loss: 0.01180993213736432
[Epoch 15, Batch 1600] loss: 0.017188907964102853
[Epoch 15, Batch 1700] loss: 0.003418866495645041
[Epoch 15, Batch 1800] loss: 0.004788713560921813
[Epoch 15, Batch 1900] loss: 0.016874915949950716
[Epoch 15, Batch 2000] loss: 0.017680024387610294
[Epoch 15, Batch 2100] loss: 0.006526413912778342
[Epoch 15, Batch 2200] loss: 0.033696624700200746
[Epoch 15, Batch 2300] loss: 0.026820913291024696
[Epoch 15, Batch 2400] loss: 0.023483334931860465
[Epoch 15, Batch 2500] loss: 0.035668284161918674
[Epoch 15, Batch 2600] loss: 0.012323655021800448
[Epoch 15, Batch 2700] loss: 0.010613862019723967
[Epoch 15, Batch 2800] loss: 0.01285679849712153
[Epoch 15, Batch 2900] loss: 0.017072126982407277
[Epoch 15, Batch 3000] loss: 0.01667246991496697
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9875
Overfitting: 0.0635
[Epoch 16, Batch 100] loss: 0.01657232825160669
[Epoch 16, Batch 200] loss: 0.0076400582561082335
[Epoch 16, Batch 300] loss: 0.011611881897072171
[Epoch 16, Batch 400] loss: 0.011855438829830827
[Epoch 16, Batch 500] loss: 0.0033295593970362348
[Epoch 16, Batch 600] loss: 0.011493552343320203
[Epoch 16, Batch 700] loss: 0.01682234924926135
[Epoch 16, Batch 800] loss: 0.004466984183156306
[Epoch 16, Batch 900] loss: 0.004067632973156324
[Epoch 16, Batch 1000] loss: 0.007247148918111512
[Epoch 16, Batch 1100] loss: 0.005253340298863427
[Epoch 16, Batch 1200] loss: 0.008900251663869797
[Epoch 16, Batch 1300] loss: 0.007759051540471629
[Epoch 16, Batch 1400] loss: 0.019726528681793507
[Epoch 16, Batch 1500] loss: 0.006509430446179465
[Epoch 16, Batch 1600] loss: 0.016817785765345993
[Epoch 16, Batch 1700] loss: 0.02243486872060398
[Epoch 16, Batch 1800] loss: 0.01545237284206542
[Epoch 16, Batch 1900] loss: 0.016119748209946893
[Epoch 16, Batch 2000] loss: 0.01912098267579381
[Epoch 16, Batch 2100] loss: 0.023226536171616737
[Epoch 16, Batch 2200] loss: 0.01934225268948694
[Epoch 16, Batch 2300] loss: 0.024178980220457866
[Epoch 16, Batch 2400] loss: 0.023849923334884407
[Epoch 16, Batch 2500] loss: 0.01870876492611172
[Epoch 16, Batch 2600] loss: 0.009272505680149834
[Epoch 16, Batch 2700] loss: 0.009011471596886943
[Epoch 16, Batch 2800] loss: 0.024673017322544552
[Epoch 16, Batch 2900] loss: 0.02746958673281199
[Epoch 16, Batch 3000] loss: 0.01671572851492499
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9867
Overfitting: 0.0630
[Epoch 17, Batch 100] loss: 0.011313494514918289
[Epoch 17, Batch 200] loss: 0.0034741014231830293
[Epoch 17, Batch 300] loss: 0.011383846334247725
[Epoch 17, Batch 400] loss: 0.01086952614586778
[Epoch 17, Batch 500] loss: 0.01070815045264169
[Epoch 17, Batch 600] loss: 0.01004716696596759
[Epoch 17, Batch 700] loss: 0.020039624425922397
[Epoch 17, Batch 800] loss: 0.007035800342255243
[Epoch 17, Batch 900] loss: 0.007661632801324139
[Epoch 17, Batch 1000] loss: 0.007701241358754132
[Epoch 17, Batch 1100] loss: 0.02031236175305537
[Epoch 17, Batch 1200] loss: 0.015040005879207001
[Epoch 17, Batch 1300] loss: 0.012051708638925192
[Epoch 17, Batch 1400] loss: 0.004561098421142194
[Epoch 17, Batch 1500] loss: 0.006913371651324729
[Epoch 17, Batch 1600] loss: 0.005943069891513049
[Epoch 17, Batch 1700] loss: 0.011976437701044703
[Epoch 17, Batch 1800] loss: 0.01582276702467546
[Epoch 17, Batch 1900] loss: 0.004412913910315566
[Epoch 17, Batch 2000] loss: 0.009126935415590598
[Epoch 17, Batch 2100] loss: 0.008967900263871318
[Epoch 17, Batch 2200] loss: 0.005611414090294518
[Epoch 17, Batch 2300] loss: 0.016616017797593113
[Epoch 17, Batch 2400] loss: 0.017318416246767613
[Epoch 17, Batch 2500] loss: 0.034445449734606975
[Epoch 17, Batch 2600] loss: 0.05006127627100625
[Epoch 17, Batch 2700] loss: 0.025192854048447372
[Epoch 17, Batch 2800] loss: 0.026165440163758102
[Epoch 17, Batch 2900] loss: 0.01907860286483448
[Epoch 17, Batch 3000] loss: 0.013584050403858749
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0731
Validation Accuracy: 0.9869
Overfitting: 0.0731
[Epoch 18, Batch 100] loss: 0.008330016486419432
[Epoch 18, Batch 200] loss: 0.009580403455149288
[Epoch 18, Batch 300] loss: 0.022478012742025353
[Epoch 18, Batch 400] loss: 0.023050794793540774
[Epoch 18, Batch 500] loss: 0.009735815634222504
[Epoch 18, Batch 600] loss: 0.01519043542337506
[Epoch 18, Batch 700] loss: 0.02559282179704276
[Epoch 18, Batch 800] loss: 0.008201794375402685
[Epoch 18, Batch 900] loss: 0.014520914099218202
[Epoch 18, Batch 1000] loss: 0.017094632951196388
[Epoch 18, Batch 1100] loss: 0.003416172007928484
[Epoch 18, Batch 1200] loss: 0.0073002859556031965
[Epoch 18, Batch 1300] loss: 0.0040381486125635165
[Epoch 18, Batch 1400] loss: 0.002870712850672241
[Epoch 18, Batch 1500] loss: 0.004216016083726126
[Epoch 18, Batch 1600] loss: 0.005680414335585908
[Epoch 18, Batch 1700] loss: 0.006139501271997325
[Epoch 18, Batch 1800] loss: 0.04268350382661893
[Epoch 18, Batch 1900] loss: 0.03394370955703835
[Epoch 18, Batch 2000] loss: 0.015849938324548132
[Epoch 18, Batch 2100] loss: 0.009066380527267305
[Epoch 18, Batch 2200] loss: 0.024064885032229668
[Epoch 18, Batch 2300] loss: 0.012640146305295565
[Epoch 18, Batch 2400] loss: 0.019778837854368653
[Epoch 18, Batch 2500] loss: 0.018384759411544563
[Epoch 18, Batch 2600] loss: 0.018364048330983422
[Epoch 18, Batch 2700] loss: 0.021265258007959104
[Epoch 18, Batch 2800] loss: 0.05934400004344198
[Epoch 18, Batch 2900] loss: 0.034347983323154946
[Epoch 18, Batch 3000] loss: 0.04623097816505066
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0633
Validation Accuracy: 0.9862
Overfitting: 0.0633
[Epoch 19, Batch 100] loss: 0.016118065701588195
[Epoch 19, Batch 200] loss: 0.006596115411814481
[Epoch 19, Batch 300] loss: 0.009173245019659645
[Epoch 19, Batch 400] loss: 0.01695214807904449
[Epoch 19, Batch 500] loss: 0.004929851309604771
[Epoch 19, Batch 600] loss: 0.007865854590219845
[Epoch 19, Batch 700] loss: 0.0017034684875066475
[Epoch 19, Batch 800] loss: 0.010234320854683024
[Epoch 19, Batch 900] loss: 0.024850899503273655
[Epoch 19, Batch 1000] loss: 0.020456784694820485
[Epoch 19, Batch 1100] loss: 0.02319088219535473
[Epoch 19, Batch 1200] loss: 0.009473660071504497
[Epoch 19, Batch 1300] loss: 0.015296219069719532
[Epoch 19, Batch 1400] loss: 0.026266827338816866
[Epoch 19, Batch 1500] loss: 0.010797726095303216
[Epoch 19, Batch 1600] loss: 0.02800875338218562
[Epoch 19, Batch 1700] loss: 0.0251029437339451
[Epoch 19, Batch 1800] loss: 0.01069046820244651
[Epoch 19, Batch 1900] loss: 0.005173303532091325
[Epoch 19, Batch 2000] loss: 0.01386660519670853
[Epoch 19, Batch 2100] loss: 0.012211874968105505
[Epoch 19, Batch 2200] loss: 0.013373560896125482
[Epoch 19, Batch 2300] loss: 0.009873217537412566
[Epoch 19, Batch 2400] loss: 0.022811108443068148
[Epoch 19, Batch 2500] loss: 0.006078321919477143
[Epoch 19, Batch 2600] loss: 0.0037906552699555674
[Epoch 19, Batch 2700] loss: 0.011808026447231832
[Epoch 19, Batch 2800] loss: 0.00841896922489381
[Epoch 19, Batch 2900] loss: 0.004743219473551807
[Epoch 19, Batch 3000] loss: 0.004523567980668224
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0659
Validation Accuracy: 0.9879
Overfitting: 0.0659
[Epoch 20, Batch 100] loss: 0.03720678066042509
[Epoch 20, Batch 200] loss: 0.018203359195285103
[Epoch 20, Batch 300] loss: 0.004102044404713645
[Epoch 20, Batch 400] loss: 0.006084359327795492
[Epoch 20, Batch 500] loss: 0.008625065405503314
[Epoch 20, Batch 600] loss: 0.015579131612333152
[Epoch 20, Batch 700] loss: 0.02186450927572576
[Epoch 20, Batch 800] loss: 0.004764224488673729
[Epoch 20, Batch 900] loss: 0.009086229854710694
[Epoch 20, Batch 1000] loss: 0.007046064128957901
[Epoch 20, Batch 1100] loss: 0.009342442840775789
[Epoch 20, Batch 1200] loss: 0.004609470088817318
[Epoch 20, Batch 1300] loss: 0.005154192536244539
[Epoch 20, Batch 1400] loss: 0.002193399540403562
[Epoch 20, Batch 1500] loss: 0.020497311787688086
[Epoch 20, Batch 1600] loss: 0.0031472356993787007
[Epoch 20, Batch 1700] loss: 0.009476121675380563
[Epoch 20, Batch 1800] loss: 0.014439117686241567
[Epoch 20, Batch 1900] loss: 0.009930880407977578
[Epoch 20, Batch 2000] loss: 0.026311035357706992
[Epoch 20, Batch 2100] loss: 0.017139588181343087
[Epoch 20, Batch 2200] loss: 0.003554787821056946
[Epoch 20, Batch 2300] loss: 0.006730244462665657
[Epoch 20, Batch 2400] loss: 0.004968474523208215
[Epoch 20, Batch 2500] loss: 0.006463084247579505
[Epoch 20, Batch 2600] loss: 0.007072484150195635
[Epoch 20, Batch 2700] loss: 0.026349676220921908
[Epoch 20, Batch 2800] loss: 0.024861644132977107
[Epoch 20, Batch 2900] loss: 0.024898038661249372
[Epoch 20, Batch 3000] loss: 0.031933868923903146
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0799
Validation Accuracy: 0.9848
Overfitting: 0.0799
[Epoch 21, Batch 100] loss: 0.01721708333292584
[Epoch 21, Batch 200] loss: 0.010153988593330183
[Epoch 21, Batch 300] loss: 0.0029709583887062153
[Epoch 21, Batch 400] loss: 0.013910622751414468
[Epoch 21, Batch 500] loss: 0.014569183708452407
[Epoch 21, Batch 600] loss: 0.005237674450315191
[Epoch 21, Batch 700] loss: 0.01170273151644976
[Epoch 21, Batch 800] loss: 0.006380778939642458
[Epoch 21, Batch 900] loss: 0.01047876835016717
[Epoch 21, Batch 1000] loss: 0.013435670908479058
[Epoch 21, Batch 1100] loss: 0.008096709530222759
[Epoch 21, Batch 1200] loss: 0.00248942473932209
[Epoch 21, Batch 1300] loss: 0.015221415148078505
[Epoch 21, Batch 1400] loss: 0.001246230645233073
[Epoch 21, Batch 1500] loss: 0.01326910006009776
[Epoch 21, Batch 1600] loss: 0.005681896243872293
[Epoch 21, Batch 1700] loss: 0.018303347537917222
[Epoch 21, Batch 1800] loss: 0.025792674694369994
[Epoch 21, Batch 1900] loss: 0.017559209653682704
[Epoch 21, Batch 2000] loss: 0.011569748807792166
[Epoch 21, Batch 2100] loss: 0.01417766928043819
[Epoch 21, Batch 2200] loss: 0.01318241379912756
[Epoch 21, Batch 2300] loss: 0.01619636491396779
[Epoch 21, Batch 2400] loss: 0.016588626276230364
[Epoch 21, Batch 2500] loss: 0.008820526491003627
[Epoch 21, Batch 2600] loss: 0.018337365035725597
[Epoch 21, Batch 2700] loss: 0.014908560737049222
[Epoch 21, Batch 2800] loss: 0.016388785740242794
[Epoch 21, Batch 2900] loss: 0.00786561962759759
[Epoch 21, Batch 3000] loss: 0.010441551252290245
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0902
Validation Accuracy: 0.9845
Overfitting: 0.0902
[Epoch 22, Batch 100] loss: 0.010470780475019814
[Epoch 22, Batch 200] loss: 0.025458770830401222
[Epoch 22, Batch 300] loss: 0.015444665736236231
[Epoch 22, Batch 400] loss: 0.011730890759206067
[Epoch 22, Batch 500] loss: 0.006906131802337096
[Epoch 22, Batch 600] loss: 0.006874913678118801
[Epoch 22, Batch 700] loss: 0.017381436828067014
[Epoch 22, Batch 800] loss: 0.0063533122455354495
[Epoch 22, Batch 900] loss: 0.021724222333389914
[Epoch 22, Batch 1000] loss: 0.005293420601170235
[Epoch 22, Batch 1100] loss: 0.01470068748723655
[Epoch 22, Batch 1200] loss: 0.009841685090873931
[Epoch 22, Batch 1300] loss: 0.011445144012938573
[Epoch 22, Batch 1400] loss: 0.003213023530413004
[Epoch 22, Batch 1500] loss: 0.0032462834219229198
[Epoch 22, Batch 1600] loss: 0.020613596850263555
[Epoch 22, Batch 1700] loss: 0.014723723150756344
[Epoch 22, Batch 1800] loss: 0.013251853549567922
[Epoch 22, Batch 1900] loss: 0.006846668979235062
[Epoch 22, Batch 2000] loss: 0.006847349886796072
[Epoch 22, Batch 2100] loss: 0.0012760800528559945
[Epoch 22, Batch 2200] loss: 0.01136304146750713
[Epoch 22, Batch 2300] loss: 0.010862217543580624
[Epoch 22, Batch 2400] loss: 0.004105233152626466
[Epoch 22, Batch 2500] loss: 0.008330879541723868
[Epoch 22, Batch 2600] loss: 0.004341542827984055
[Epoch 22, Batch 2700] loss: 0.021688981640620355
[Epoch 22, Batch 2800] loss: 0.011587739797321665
[Epoch 22, Batch 2900] loss: 0.015495572048566286
[Epoch 22, Batch 3000] loss: 0.01224295904546803
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0726
Validation Accuracy: 0.9864
Overfitting: 0.0726
[Epoch 23, Batch 100] loss: 0.007842026260551105
[Epoch 23, Batch 200] loss: 0.009957940408950261
[Epoch 23, Batch 300] loss: 0.016913700588145956
[Epoch 23, Batch 400] loss: 0.009643742943379023
[Epoch 23, Batch 500] loss: 0.013986306635537104
[Epoch 23, Batch 600] loss: 0.032538728617208544
[Epoch 23, Batch 700] loss: 0.0323720100819044
[Epoch 23, Batch 800] loss: 0.027137556308409035
[Epoch 23, Batch 900] loss: 0.02942492761238199
[Epoch 23, Batch 1000] loss: 0.010280720333513927
[Epoch 23, Batch 1100] loss: 0.002608776569880593
[Epoch 23, Batch 1200] loss: 0.006434238842610993
[Epoch 23, Batch 1300] loss: 0.004723810685607677
[Epoch 23, Batch 1400] loss: 0.004739472867611978
[Epoch 23, Batch 1500] loss: 0.02264209263507877
[Epoch 23, Batch 1600] loss: 0.050905196438551154
[Epoch 23, Batch 1700] loss: 0.021583578654973144
[Epoch 23, Batch 1800] loss: 0.019671284820105606
[Epoch 23, Batch 1900] loss: 0.026401485599457427
[Epoch 23, Batch 2000] loss: 0.010133191260334762
[Epoch 23, Batch 2100] loss: 0.005450188359302634
[Epoch 23, Batch 2200] loss: 0.015226379113690198
[Epoch 23, Batch 2300] loss: 0.03136264144206983
[Epoch 23, Batch 2400] loss: 0.01773621786192379
[Epoch 23, Batch 2500] loss: 0.0238079106189457
[Epoch 23, Batch 2600] loss: 0.036886010579876796
[Epoch 23, Batch 2700] loss: 0.009421492737701254
[Epoch 23, Batch 2800] loss: 0.027800416058998034
[Epoch 23, Batch 2900] loss: 0.03866555089696082
[Epoch 23, Batch 3000] loss: 0.013668125106073176
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0613
Validation Accuracy: 0.9872
Overfitting: 0.0613
[Epoch 24, Batch 100] loss: 0.004486701378561184
[Epoch 24, Batch 200] loss: 0.014501220213665511
[Epoch 24, Batch 300] loss: 0.008808158929320697
[Epoch 24, Batch 400] loss: 0.005061061765952193
[Epoch 24, Batch 500] loss: 0.007453490452336648
[Epoch 24, Batch 600] loss: 0.0032407433948931042
[Epoch 24, Batch 700] loss: 0.0046348053794197505
[Epoch 24, Batch 800] loss: 0.004276853896357839
[Epoch 24, Batch 900] loss: 0.011970919742075163
[Epoch 24, Batch 1000] loss: 0.007866955289559772
[Epoch 24, Batch 1100] loss: 0.010990572580178269
[Epoch 24, Batch 1200] loss: 0.01782331365938443
[Epoch 24, Batch 1300] loss: 0.019080142248950594
[Epoch 24, Batch 1400] loss: 0.004545421623543366
[Epoch 24, Batch 1500] loss: 0.014017514225760634
[Epoch 24, Batch 1600] loss: 0.008771345497798797
[Epoch 24, Batch 1700] loss: 0.006098537053399435
[Epoch 24, Batch 1800] loss: 0.008691351440720587
[Epoch 24, Batch 1900] loss: 0.004790965763607828
[Epoch 24, Batch 2000] loss: 0.020508177990234747
[Epoch 24, Batch 2100] loss: 0.021545697110523
[Epoch 24, Batch 2200] loss: 0.012472661882883825
[Epoch 24, Batch 2300] loss: 0.009748686302301399
[Epoch 24, Batch 2400] loss: 0.016081691784137445
[Epoch 24, Batch 2500] loss: 0.002748254797359291
[Epoch 24, Batch 2600] loss: 0.021680787226404753
[Epoch 24, Batch 2700] loss: 0.022451282826049145
[Epoch 24, Batch 2800] loss: 0.014569866454869391
[Epoch 24, Batch 2900] loss: 0.00949630309164371
[Epoch 24, Batch 3000] loss: 0.01145223641965794
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0832
Validation Accuracy: 0.9829
Overfitting: 0.0832
Fold 5 validation loss: 0.0832
Mean validation loss across all folds for Trial 4 is 0.0798 with trial config:  l1: 128, l2: 128, lr: 0.00853618986286683, batch_size: 16
[I 2024-12-10 06:18:47,166] Trial 3 finished with value: 0.0798480516978463 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.00853618986286683, 'batch_size': 16}. Best is trial 2 with value: 0.05332992686522152.

Selected Hyperparameters for Trial 5:
  l1: 256, l2: 128, lr: 0.00032927591344236165, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.303337733745575
[Epoch 1, Batch 200] loss: 2.2894918584823607
[Epoch 1, Batch 300] loss: 2.2692210626602174
[Epoch 1, Batch 400] loss: 2.240860502719879
[Epoch 1, Batch 500] loss: 2.1964425468444824
[Epoch 1, Batch 600] loss: 2.0915585136413575
[Epoch 1, Batch 700] loss: 1.8746960580348968
[Epoch 1, Batch 800] loss: 1.4410211390256882
[Epoch 1, Batch 900] loss: 0.9828538179397583
[Epoch 1, Batch 1000] loss: 0.7389947476983071
[Epoch 1, Batch 1100] loss: 0.6348510199785232
[Epoch 1, Batch 1200] loss: 0.5378104956448078
[Epoch 1, Batch 1300] loss: 0.5576096139848232
[Epoch 1, Batch 1400] loss: 0.4844606874883175
[Epoch 1, Batch 1500] loss: 0.4531469724327326
[Epoch 1, Batch 1600] loss: 0.4040713097900152
[Epoch 1, Batch 1700] loss: 0.41108196139335634
[Epoch 1, Batch 1800] loss: 0.4178416274487972
[Epoch 1, Batch 1900] loss: 0.3755596945807338
[Epoch 1, Batch 2000] loss: 0.35529774211347104
[Epoch 1, Batch 2100] loss: 0.4017647618055344
[Epoch 1, Batch 2200] loss: 0.36239624947309496
[Epoch 1, Batch 2300] loss: 0.3225505904853344
[Epoch 1, Batch 2400] loss: 0.2925580924749374
[Epoch 1, Batch 2500] loss: 0.3106752270832658
[Epoch 1, Batch 2600] loss: 0.32261156998574736
[Epoch 1, Batch 2700] loss: 0.28809586744755505
[Epoch 1, Batch 2800] loss: 0.2538826338201761
[Epoch 1, Batch 2900] loss: 0.294830536916852
[Epoch 1, Batch 3000] loss: 0.2633958768844604
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2312
Validation Accuracy: 0.9333
Overfitting: 0.2312
Best model saved at epoch 1 with validation loss: 0.2312
[Epoch 2, Batch 100] loss: 0.2406461356766522
[Epoch 2, Batch 200] loss: 0.26283289354294537
[Epoch 2, Batch 300] loss: 0.21549191135913134
[Epoch 2, Batch 400] loss: 0.21878690911456944
[Epoch 2, Batch 500] loss: 0.22283303996548057
[Epoch 2, Batch 600] loss: 0.225189947783947
[Epoch 2, Batch 700] loss: 0.19598568089306354
[Epoch 2, Batch 800] loss: 0.2154946216195822
[Epoch 2, Batch 900] loss: 0.24345516487956048
[Epoch 2, Batch 1000] loss: 0.17174661792814733
[Epoch 2, Batch 1100] loss: 0.20851320158690215
[Epoch 2, Batch 1200] loss: 0.19279923054389655
[Epoch 2, Batch 1300] loss: 0.21264554523397236
[Epoch 2, Batch 1400] loss: 0.21322670415043832
[Epoch 2, Batch 1500] loss: 0.17308750724419952
[Epoch 2, Batch 1600] loss: 0.172344012549147
[Epoch 2, Batch 1700] loss: 0.17751972832717
[Epoch 2, Batch 1800] loss: 0.18773766066879033
[Epoch 2, Batch 1900] loss: 0.15310668855905532
[Epoch 2, Batch 2000] loss: 0.1786127471551299
[Epoch 2, Batch 2100] loss: 0.14947399141266943
[Epoch 2, Batch 2200] loss: 0.16359810054302215
[Epoch 2, Batch 2300] loss: 0.16206175434403122
[Epoch 2, Batch 2400] loss: 0.14564411889761686
[Epoch 2, Batch 2500] loss: 0.1750501713482663
[Epoch 2, Batch 2600] loss: 0.17301950546912848
[Epoch 2, Batch 2700] loss: 0.14447062646970152
[Epoch 2, Batch 2800] loss: 0.138822899190709
[Epoch 2, Batch 2900] loss: 0.17961372015066446
[Epoch 2, Batch 3000] loss: 0.15183724568225443
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1264
Validation Accuracy: 0.9606
Overfitting: 0.1264
Best model saved at epoch 2 with validation loss: 0.1264
[Epoch 3, Batch 100] loss: 0.12849820744711907
[Epoch 3, Batch 200] loss: 0.14584898214787245
[Epoch 3, Batch 300] loss: 0.15165348612703383
[Epoch 3, Batch 400] loss: 0.12219999003689735
[Epoch 3, Batch 500] loss: 0.1408992891944945
[Epoch 3, Batch 600] loss: 0.12674347593449056
[Epoch 3, Batch 700] loss: 0.12459444577340037
[Epoch 3, Batch 800] loss: 0.13392065659165384
[Epoch 3, Batch 900] loss: 0.13081321832723916
[Epoch 3, Batch 1000] loss: 0.11447096450719982
[Epoch 3, Batch 1100] loss: 0.1132166950381361
[Epoch 3, Batch 1200] loss: 0.11231228053104132
[Epoch 3, Batch 1300] loss: 0.13317763862200083
[Epoch 3, Batch 1400] loss: 0.13772741549648346
[Epoch 3, Batch 1500] loss: 0.12126527652842924
[Epoch 3, Batch 1600] loss: 0.11277509124483913
[Epoch 3, Batch 1700] loss: 0.15496862050611526
[Epoch 3, Batch 1800] loss: 0.12611452424898745
[Epoch 3, Batch 1900] loss: 0.10443936318159103
[Epoch 3, Batch 2000] loss: 0.12228958077030257
[Epoch 3, Batch 2100] loss: 0.12260508352541365
[Epoch 3, Batch 2200] loss: 0.11884376468602569
[Epoch 3, Batch 2300] loss: 0.1288703764602542
[Epoch 3, Batch 2400] loss: 0.120926612643525
[Epoch 3, Batch 2500] loss: 0.10495685645379126
[Epoch 3, Batch 2600] loss: 0.1030718555743806
[Epoch 3, Batch 2700] loss: 0.11064047866035252
[Epoch 3, Batch 2800] loss: 0.12848950971383602
[Epoch 3, Batch 2900] loss: 0.09906853549182415
[Epoch 3, Batch 3000] loss: 0.1055844771314878
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0982
Validation Accuracy: 0.9693
Overfitting: 0.0982
Best model saved at epoch 3 with validation loss: 0.0982
[Epoch 4, Batch 100] loss: 0.11462156930472701
[Epoch 4, Batch 200] loss: 0.0948808181588538
[Epoch 4, Batch 300] loss: 0.11321801319718361
[Epoch 4, Batch 400] loss: 0.08968316317768768
[Epoch 4, Batch 500] loss: 0.09259103374090046
[Epoch 4, Batch 600] loss: 0.09695987338898704
[Epoch 4, Batch 700] loss: 0.1049943057820201
[Epoch 4, Batch 800] loss: 0.10805839221458882
[Epoch 4, Batch 900] loss: 0.08678429528838023
[Epoch 4, Batch 1000] loss: 0.10263201989815571
[Epoch 4, Batch 1100] loss: 0.09429989627096802
[Epoch 4, Batch 1200] loss: 0.09831748817116022
[Epoch 4, Batch 1300] loss: 0.09534563571447506
[Epoch 4, Batch 1400] loss: 0.11425281999632717
[Epoch 4, Batch 1500] loss: 0.08222106571076437
[Epoch 4, Batch 1600] loss: 0.10580868108663707
[Epoch 4, Batch 1700] loss: 0.08759022070793435
[Epoch 4, Batch 1800] loss: 0.10005411522230133
[Epoch 4, Batch 1900] loss: 0.10432257539127023
[Epoch 4, Batch 2000] loss: 0.08924332475406117
[Epoch 4, Batch 2100] loss: 0.08091716959141194
[Epoch 4, Batch 2200] loss: 0.105913910435047
[Epoch 4, Batch 2300] loss: 0.0821284822979942
[Epoch 4, Batch 2400] loss: 0.0748370147892274
[Epoch 4, Batch 2500] loss: 0.10290646977024152
[Epoch 4, Batch 2600] loss: 0.10768058019573801
[Epoch 4, Batch 2700] loss: 0.08689967300044373
[Epoch 4, Batch 2800] loss: 0.07336806010338477
[Epoch 4, Batch 2900] loss: 0.08748515464365482
[Epoch 4, Batch 3000] loss: 0.10437602993217297
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0879
Validation Accuracy: 0.9740
Overfitting: 0.0879
Best model saved at epoch 4 with validation loss: 0.0879
[Epoch 5, Batch 100] loss: 0.08499871331965551
[Epoch 5, Batch 200] loss: 0.06758417763747275
[Epoch 5, Batch 300] loss: 0.0961576406401582
[Epoch 5, Batch 400] loss: 0.08453725770115852
[Epoch 5, Batch 500] loss: 0.07847159349243156
[Epoch 5, Batch 600] loss: 0.07681746155838481
[Epoch 5, Batch 700] loss: 0.07147547057596966
[Epoch 5, Batch 800] loss: 0.06817140005470719
[Epoch 5, Batch 900] loss: 0.08562306908890605
[Epoch 5, Batch 1000] loss: 0.07484459806815721
[Epoch 5, Batch 1100] loss: 0.08048174881841988
[Epoch 5, Batch 1200] loss: 0.09396838559769094
[Epoch 5, Batch 1300] loss: 0.06605237130424939
[Epoch 5, Batch 1400] loss: 0.06576865663053467
[Epoch 5, Batch 1500] loss: 0.06377711370703765
[Epoch 5, Batch 1600] loss: 0.09854677212773823
[Epoch 5, Batch 1700] loss: 0.09207612413680182
[Epoch 5, Batch 1800] loss: 0.08477828689734451
[Epoch 5, Batch 1900] loss: 0.08052443818887696
[Epoch 5, Batch 2000] loss: 0.10129894417477772
[Epoch 5, Batch 2100] loss: 0.07667239029426128
[Epoch 5, Batch 2200] loss: 0.07820894696633332
[Epoch 5, Batch 2300] loss: 0.061640834762947634
[Epoch 5, Batch 2400] loss: 0.09952109701000154
[Epoch 5, Batch 2500] loss: 0.06846613216679544
[Epoch 5, Batch 2600] loss: 0.08076553051359951
[Epoch 5, Batch 2700] loss: 0.08070038439065684
[Epoch 5, Batch 2800] loss: 0.07830791530082934
[Epoch 5, Batch 2900] loss: 0.059775030051823705
[Epoch 5, Batch 3000] loss: 0.08874014594766777
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0688
Validation Accuracy: 0.9787
Overfitting: 0.0688
Best model saved at epoch 5 with validation loss: 0.0688
[Epoch 6, Batch 100] loss: 0.06287469399278052
[Epoch 6, Batch 200] loss: 0.06551442361436784
[Epoch 6, Batch 300] loss: 0.07131813590298407
[Epoch 6, Batch 400] loss: 0.06337961058481596
[Epoch 6, Batch 500] loss: 0.07142860021675006
[Epoch 6, Batch 600] loss: 0.061383839091286065
[Epoch 6, Batch 700] loss: 0.05537882335716859
[Epoch 6, Batch 800] loss: 0.08573979807435535
[Epoch 6, Batch 900] loss: 0.06751120395725593
[Epoch 6, Batch 1000] loss: 0.07525887961848639
[Epoch 6, Batch 1100] loss: 0.06717300929129123
[Epoch 6, Batch 1200] loss: 0.06054156605736352
[Epoch 6, Batch 1300] loss: 0.07821612213621848
[Epoch 6, Batch 1400] loss: 0.07234076134278439
[Epoch 6, Batch 1500] loss: 0.09580273600295186
[Epoch 6, Batch 1600] loss: 0.06251957458560355
[Epoch 6, Batch 1700] loss: 0.07628343237563967
[Epoch 6, Batch 1800] loss: 0.06029323010763619
[Epoch 6, Batch 1900] loss: 0.06887074804515578
[Epoch 6, Batch 2000] loss: 0.054601649351534436
[Epoch 6, Batch 2100] loss: 0.0611380486539565
[Epoch 6, Batch 2200] loss: 0.06210833586635999
[Epoch 6, Batch 2300] loss: 0.06004651993222069
[Epoch 6, Batch 2400] loss: 0.07564596035750583
[Epoch 6, Batch 2500] loss: 0.05439998870308045
[Epoch 6, Batch 2600] loss: 0.08332652872428298
[Epoch 6, Batch 2700] loss: 0.057545211935648696
[Epoch 6, Batch 2800] loss: 0.0784917887870688
[Epoch 6, Batch 2900] loss: 0.08339929717883933
[Epoch 6, Batch 3000] loss: 0.06734281053533778
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0643
Validation Accuracy: 0.9795
Overfitting: 0.0643
Best model saved at epoch 6 with validation loss: 0.0643
[Epoch 7, Batch 100] loss: 0.05897604748490266
[Epoch 7, Batch 200] loss: 0.05486168839037418
[Epoch 7, Batch 300] loss: 0.07102049886249005
[Epoch 7, Batch 400] loss: 0.06347526896512136
[Epoch 7, Batch 500] loss: 0.05039774489239789
[Epoch 7, Batch 600] loss: 0.07624212452792563
[Epoch 7, Batch 700] loss: 0.07142877623671666
[Epoch 7, Batch 800] loss: 0.06301002080494073
[Epoch 7, Batch 900] loss: 0.05040417024632916
[Epoch 7, Batch 1000] loss: 0.054168159655528146
[Epoch 7, Batch 1100] loss: 0.06287511183938477
[Epoch 7, Batch 1200] loss: 0.05075654321932234
[Epoch 7, Batch 1300] loss: 0.06431462005362847
[Epoch 7, Batch 1400] loss: 0.06112636120058596
[Epoch 7, Batch 1500] loss: 0.04807682913145982
[Epoch 7, Batch 1600] loss: 0.07296517950715498
[Epoch 7, Batch 1700] loss: 0.06498310324386694
[Epoch 7, Batch 1800] loss: 0.07033960007771384
[Epoch 7, Batch 1900] loss: 0.06797378889459652
[Epoch 7, Batch 2000] loss: 0.04187552546150983
[Epoch 7, Batch 2100] loss: 0.06457084957626648
[Epoch 7, Batch 2200] loss: 0.053159838003339246
[Epoch 7, Batch 2300] loss: 0.04278387194790412
[Epoch 7, Batch 2400] loss: 0.04545962790871272
[Epoch 7, Batch 2500] loss: 0.0594524616812123
[Epoch 7, Batch 2600] loss: 0.06783031402388588
[Epoch 7, Batch 2700] loss: 0.06821760676044505
[Epoch 7, Batch 2800] loss: 0.05459584051044658
[Epoch 7, Batch 2900] loss: 0.060005233824485915
[Epoch 7, Batch 3000] loss: 0.06123023338033818
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0629
Validation Accuracy: 0.9797
Overfitting: 0.0629
Best model saved at epoch 7 with validation loss: 0.0629
[Epoch 8, Batch 100] loss: 0.04933105397911277
[Epoch 8, Batch 200] loss: 0.051792241396615285
[Epoch 8, Batch 300] loss: 0.054358679946744815
[Epoch 8, Batch 400] loss: 0.06166632857377408
[Epoch 8, Batch 500] loss: 0.050360092330956834
[Epoch 8, Batch 600] loss: 0.04874412021832541
[Epoch 8, Batch 700] loss: 0.07271072743227705
[Epoch 8, Batch 800] loss: 0.0538349133124575
[Epoch 8, Batch 900] loss: 0.056132270485104524
[Epoch 8, Batch 1000] loss: 0.047555346864974125
[Epoch 8, Batch 1100] loss: 0.06560745651950128
[Epoch 8, Batch 1200] loss: 0.044743396367412064
[Epoch 8, Batch 1300] loss: 0.05730759670550469
[Epoch 8, Batch 1400] loss: 0.06271383123646956
[Epoch 8, Batch 1500] loss: 0.04648450604698155
[Epoch 8, Batch 1600] loss: 0.042300069729390086
[Epoch 8, Batch 1700] loss: 0.04231270945543656
[Epoch 8, Batch 1800] loss: 0.04612646994472016
[Epoch 8, Batch 1900] loss: 0.04144718231720617
[Epoch 8, Batch 2000] loss: 0.06367486550996546
[Epoch 8, Batch 2100] loss: 0.050678952849120835
[Epoch 8, Batch 2200] loss: 0.056348733530321625
[Epoch 8, Batch 2300] loss: 0.05697209650534205
[Epoch 8, Batch 2400] loss: 0.08304733240627683
[Epoch 8, Batch 2500] loss: 0.046595572061778515
[Epoch 8, Batch 2600] loss: 0.06505673359817593
[Epoch 8, Batch 2700] loss: 0.057397859886405056
[Epoch 8, Batch 2800] loss: 0.03824028839037055
[Epoch 8, Batch 2900] loss: 0.043936812415340684
[Epoch 8, Batch 3000] loss: 0.06265913313894998
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0663
Validation Accuracy: 0.9787
Overfitting: 0.0663
[Epoch 9, Batch 100] loss: 0.04839902445266489
[Epoch 9, Batch 200] loss: 0.04945486227516085
[Epoch 9, Batch 300] loss: 0.039393620518385436
[Epoch 9, Batch 400] loss: 0.06305405496736056
[Epoch 9, Batch 500] loss: 0.04942868046666263
[Epoch 9, Batch 600] loss: 0.0338215771317482
[Epoch 9, Batch 700] loss: 0.04279848228557967
[Epoch 9, Batch 800] loss: 0.043723343471065164
[Epoch 9, Batch 900] loss: 0.06636594796204008
[Epoch 9, Batch 1000] loss: 0.03388358420517761
[Epoch 9, Batch 1100] loss: 0.04061479135940317
[Epoch 9, Batch 1200] loss: 0.034336042806389744
[Epoch 9, Batch 1300] loss: 0.04095081402600045
[Epoch 9, Batch 1400] loss: 0.052897388594574296
[Epoch 9, Batch 1500] loss: 0.06937621494755149
[Epoch 9, Batch 1600] loss: 0.06979352510883473
[Epoch 9, Batch 1700] loss: 0.05003235972486436
[Epoch 9, Batch 1800] loss: 0.05459786307474133
[Epoch 9, Batch 1900] loss: 0.061083759822067804
[Epoch 9, Batch 2000] loss: 0.03793886290921364
[Epoch 9, Batch 2100] loss: 0.04539007349201711
[Epoch 9, Batch 2200] loss: 0.04901867108419537
[Epoch 9, Batch 2300] loss: 0.04609339172893669
[Epoch 9, Batch 2400] loss: 0.04410059140587691
[Epoch 9, Batch 2500] loss: 0.044038090025424026
[Epoch 9, Batch 2600] loss: 0.03689881894941209
[Epoch 9, Batch 2700] loss: 0.036550798232783566
[Epoch 9, Batch 2800] loss: 0.06619351540284697
[Epoch 9, Batch 2900] loss: 0.04859184301574714
[Epoch 9, Batch 3000] loss: 0.04203482268727385
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9826
Overfitting: 0.0576
[I 2024-12-10 06:21:10,601] Trial 4 pruned. 

Selected Hyperparameters for Trial 6:
  l1: 128, l2: 64, lr: 0.0015696396388661157, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2835279726982116
[Epoch 1, Batch 200] loss: 2.037404954433441
[Epoch 1, Batch 300] loss: 1.0337446457147599
[Epoch 1, Batch 400] loss: 0.6357747073471546
[Epoch 1, Batch 500] loss: 0.481585378870368
[Epoch 1, Batch 600] loss: 0.3914959724992514
[Epoch 1, Batch 700] loss: 0.30103306006640196
[Epoch 1, Batch 800] loss: 0.29432548124343155
[Epoch 1, Batch 900] loss: 0.30644575752317904
[Epoch 1, Batch 1000] loss: 0.24983071461319922
[Epoch 1, Batch 1100] loss: 0.24170669216662646
[Epoch 1, Batch 1200] loss: 0.20328083130531013
[Epoch 1, Batch 1300] loss: 0.19273579224944115
[Epoch 1, Batch 1400] loss: 0.19592823183164002
[Epoch 1, Batch 1500] loss: 0.16762314077466725
[Epoch 1, Batch 1600] loss: 0.14499367668293417
[Epoch 1, Batch 1700] loss: 0.16188397344201802
[Epoch 1, Batch 1800] loss: 0.14992996899411082
[Epoch 1, Batch 1900] loss: 0.16508998133707792
[Epoch 1, Batch 2000] loss: 0.1399206850072369
[Epoch 1, Batch 2100] loss: 0.14562309153378009
[Epoch 1, Batch 2200] loss: 0.12784765801392495
[Epoch 1, Batch 2300] loss: 0.10834186656633392
[Epoch 1, Batch 2400] loss: 0.12043248038738966
[Epoch 1, Batch 2500] loss: 0.10097250666702166
[Epoch 1, Batch 2600] loss: 0.14078735487535596
[Epoch 1, Batch 2700] loss: 0.1253399057057686
[Epoch 1, Batch 2800] loss: 0.14901366386562587
[Epoch 1, Batch 2900] loss: 0.1340728805074468
[Epoch 1, Batch 3000] loss: 0.09085569286486134
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1091
Validation Accuracy: 0.9663
Overfitting: 0.1091
Best model saved at epoch 1 with validation loss: 0.1091
[Epoch 2, Batch 100] loss: 0.09812339403550141
[Epoch 2, Batch 200] loss: 0.10029113559983671
[Epoch 2, Batch 300] loss: 0.09064147885073907
[Epoch 2, Batch 400] loss: 0.09655801974586212
[Epoch 2, Batch 500] loss: 0.0893107617739588
[Epoch 2, Batch 600] loss: 0.07517463910626247
[Epoch 2, Batch 700] loss: 0.0797313879057765
[Epoch 2, Batch 800] loss: 0.09382052194210701
[Epoch 2, Batch 900] loss: 0.13004253693390638
[Epoch 2, Batch 1000] loss: 0.08872956981649623
[Epoch 2, Batch 1100] loss: 0.09872047757846303
[Epoch 2, Batch 1200] loss: 0.07324116869829594
[Epoch 2, Batch 1300] loss: 0.0827854823495727
[Epoch 2, Batch 1400] loss: 0.10466515207197517
[Epoch 2, Batch 1500] loss: 0.0715635601466056
[Epoch 2, Batch 1600] loss: 0.07766359618399292
[Epoch 2, Batch 1700] loss: 0.07965394005412235
[Epoch 2, Batch 1800] loss: 0.08055093053611927
[Epoch 2, Batch 1900] loss: 0.07578444770188071
[Epoch 2, Batch 2000] loss: 0.09128930930281058
[Epoch 2, Batch 2100] loss: 0.06043458765198011
[Epoch 2, Batch 2200] loss: 0.062183188576018435
[Epoch 2, Batch 2300] loss: 0.0788915571779944
[Epoch 2, Batch 2400] loss: 0.07852026545908303
[Epoch 2, Batch 2500] loss: 0.09735887498944067
[Epoch 2, Batch 2600] loss: 0.07012591686216182
[Epoch 2, Batch 2700] loss: 0.04946285534853814
[Epoch 2, Batch 2800] loss: 0.06829966332181357
[Epoch 2, Batch 2900] loss: 0.07669701134844217
[Epoch 2, Batch 3000] loss: 0.08494943649275229
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0771
Validation Accuracy: 0.9744
Overfitting: 0.0771
Best model saved at epoch 2 with validation loss: 0.0771
[Epoch 3, Batch 100] loss: 0.06402133630821481
[Epoch 3, Batch 200] loss: 0.05682722182536963
[Epoch 3, Batch 300] loss: 0.06141619138099486
[Epoch 3, Batch 400] loss: 0.03818367808984476
[Epoch 3, Batch 500] loss: 0.0649464677175274
[Epoch 3, Batch 600] loss: 0.07490365584846587
[Epoch 3, Batch 700] loss: 0.06231506670941599
[Epoch 3, Batch 800] loss: 0.03449012693687109
[Epoch 3, Batch 900] loss: 0.07857295224617701
[Epoch 3, Batch 1000] loss: 0.060913077807344965
[Epoch 3, Batch 1100] loss: 0.07578515630157198
[Epoch 3, Batch 1200] loss: 0.07339733917295234
[Epoch 3, Batch 1300] loss: 0.04590134490281343
[Epoch 3, Batch 1400] loss: 0.06865024666680256
[Epoch 3, Batch 1500] loss: 0.055205905114708
[Epoch 3, Batch 1600] loss: 0.05646079123020172
[Epoch 3, Batch 1700] loss: 0.05684291917947121
[Epoch 3, Batch 1800] loss: 0.055939326719380913
[Epoch 3, Batch 1900] loss: 0.058305274670128714
[Epoch 3, Batch 2000] loss: 0.052951637199148534
[Epoch 3, Batch 2100] loss: 0.054837526457122296
[Epoch 3, Batch 2200] loss: 0.05045981108152773
[Epoch 3, Batch 2300] loss: 0.07349772944493452
[Epoch 3, Batch 2400] loss: 0.057890378123847765
[Epoch 3, Batch 2500] loss: 0.046694495364499745
[Epoch 3, Batch 2600] loss: 0.05305841817811597
[Epoch 3, Batch 2700] loss: 0.0541237802800606
[Epoch 3, Batch 2800] loss: 0.0591459845911595
[Epoch 3, Batch 2900] loss: 0.06728942366724368
[Epoch 3, Batch 3000] loss: 0.043870064847869795
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0618
Validation Accuracy: 0.9798
Overfitting: 0.0618
Best model saved at epoch 3 with validation loss: 0.0618
[Epoch 4, Batch 100] loss: 0.05092822240840178
[Epoch 4, Batch 200] loss: 0.06377626539149787
[Epoch 4, Batch 300] loss: 0.05493111259071157
[Epoch 4, Batch 400] loss: 0.04575813683914021
[Epoch 4, Batch 500] loss: 0.04521799151218147
[Epoch 4, Batch 600] loss: 0.0526520958544279
[Epoch 4, Batch 700] loss: 0.052935275187555815
[Epoch 4, Batch 800] loss: 0.04265493287704885
[Epoch 4, Batch 900] loss: 0.045490183532965606
[Epoch 4, Batch 1000] loss: 0.045049975223737417
[Epoch 4, Batch 1100] loss: 0.04297022582293721
[Epoch 4, Batch 1200] loss: 0.03930825932096923
[Epoch 4, Batch 1300] loss: 0.07935382687661331
[Epoch 4, Batch 1400] loss: 0.06750617553829215
[Epoch 4, Batch 1500] loss: 0.05160008189908694
[Epoch 4, Batch 1600] loss: 0.05418061366377515
[Epoch 4, Batch 1700] loss: 0.0343015368966735
[Epoch 4, Batch 1800] loss: 0.04279171665235481
[Epoch 4, Batch 1900] loss: 0.04525627364317188
[Epoch 4, Batch 2000] loss: 0.04553730008898128
[Epoch 4, Batch 2100] loss: 0.04144162023541867
[Epoch 4, Batch 2200] loss: 0.03480454545042448
[Epoch 4, Batch 2300] loss: 0.038681868772400776
[Epoch 4, Batch 2400] loss: 0.039727787391893796
[Epoch 4, Batch 2500] loss: 0.026597250695922413
[Epoch 4, Batch 2600] loss: 0.05690716975281248
[Epoch 4, Batch 2700] loss: 0.048154346248193175
[Epoch 4, Batch 2800] loss: 0.04846449393749935
[Epoch 4, Batch 2900] loss: 0.05933036861446453
[Epoch 4, Batch 3000] loss: 0.02475950498308521
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9836
Overfitting: 0.0529
Best model saved at epoch 4 with validation loss: 0.0529
[Epoch 5, Batch 100] loss: 0.03395590107887983
[Epoch 5, Batch 200] loss: 0.037343955014948735
[Epoch 5, Batch 300] loss: 0.032240981095674213
[Epoch 5, Batch 400] loss: 0.042380902303702894
[Epoch 5, Batch 500] loss: 0.059982574130408466
[Epoch 5, Batch 600] loss: 0.03265013716823887
[Epoch 5, Batch 700] loss: 0.028302743272215592
[Epoch 5, Batch 800] loss: 0.04089658929311554
[Epoch 5, Batch 900] loss: 0.05340960362314945
[Epoch 5, Batch 1000] loss: 0.04372304393909872
[Epoch 5, Batch 1100] loss: 0.037425643855822276
[Epoch 5, Batch 1200] loss: 0.033927708263217934
[Epoch 5, Batch 1300] loss: 0.029661666417887318
[Epoch 5, Batch 1400] loss: 0.04323378077126108
[Epoch 5, Batch 1500] loss: 0.03641051847611379
[Epoch 5, Batch 1600] loss: 0.038238975171698254
[Epoch 5, Batch 1700] loss: 0.04153718818866764
[Epoch 5, Batch 1800] loss: 0.03337218574190046
[Epoch 5, Batch 1900] loss: 0.03153061413810065
[Epoch 5, Batch 2000] loss: 0.0437652399158469
[Epoch 5, Batch 2100] loss: 0.05012995838711504
[Epoch 5, Batch 2200] loss: 0.04279880729751312
[Epoch 5, Batch 2300] loss: 0.04344688937475439
[Epoch 5, Batch 2400] loss: 0.041962342932602044
[Epoch 5, Batch 2500] loss: 0.03227142882504268
[Epoch 5, Batch 2600] loss: 0.03392565272020875
[Epoch 5, Batch 2700] loss: 0.027573382873961237
[Epoch 5, Batch 2800] loss: 0.03948852392299159
[Epoch 5, Batch 2900] loss: 0.04316404888522811
[Epoch 5, Batch 3000] loss: 0.04293933671870036
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9821
Overfitting: 0.0560
[Epoch 6, Batch 100] loss: 0.02600031389272772
[Epoch 6, Batch 200] loss: 0.03713329992293438
[Epoch 6, Batch 300] loss: 0.044103456365483
[Epoch 6, Batch 400] loss: 0.036931600219395476
[Epoch 6, Batch 500] loss: 0.043359661886133834
[Epoch 6, Batch 600] loss: 0.047202919578921865
[Epoch 6, Batch 700] loss: 0.03187419859314104
[Epoch 6, Batch 800] loss: 0.03111615027344669
[Epoch 6, Batch 900] loss: 0.034917370880575616
[Epoch 6, Batch 1000] loss: 0.04381636493861151
[Epoch 6, Batch 1100] loss: 0.0339135991508374
[Epoch 6, Batch 1200] loss: 0.027994997672358295
[Epoch 6, Batch 1300] loss: 0.018900283768598456
[Epoch 6, Batch 1400] loss: 0.03104462925257394
[Epoch 6, Batch 1500] loss: 0.029176411929547612
[Epoch 6, Batch 1600] loss: 0.03291777501181059
[Epoch 6, Batch 1700] loss: 0.02585767727330676
[Epoch 6, Batch 1800] loss: 0.024173518589232116
[Epoch 6, Batch 1900] loss: 0.026892832784506028
[Epoch 6, Batch 2000] loss: 0.04594554757455626
[Epoch 6, Batch 2100] loss: 0.03032061529243947
[Epoch 6, Batch 2200] loss: 0.040060510089679154
[Epoch 6, Batch 2300] loss: 0.022907667210383807
[Epoch 6, Batch 2400] loss: 0.04052720137562574
[Epoch 6, Batch 2500] loss: 0.037641407339397116
[Epoch 6, Batch 2600] loss: 0.04112992929505708
[Epoch 6, Batch 2700] loss: 0.030653768868651243
[Epoch 6, Batch 2800] loss: 0.032990726771313345
[Epoch 6, Batch 2900] loss: 0.02863227815993014
[Epoch 6, Batch 3000] loss: 0.023970811317121844
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9818
Overfitting: 0.0635
[Epoch 7, Batch 100] loss: 0.04413375902986445
[Epoch 7, Batch 200] loss: 0.019540577971056336
[Epoch 7, Batch 300] loss: 0.025001706708935673
[Epoch 7, Batch 400] loss: 0.04317354318700382
[Epoch 7, Batch 500] loss: 0.03384969604303478
[Epoch 7, Batch 600] loss: 0.0298898128032306
[Epoch 7, Batch 700] loss: 0.03955443027567526
[Epoch 7, Batch 800] loss: 0.019733521193775232
[Epoch 7, Batch 900] loss: 0.028504707647771285
[Epoch 7, Batch 1000] loss: 0.03199793126445002
[Epoch 7, Batch 1100] loss: 0.046382520593069784
[Epoch 7, Batch 1200] loss: 0.02315567652905884
[Epoch 7, Batch 1300] loss: 0.03802011645471794
[Epoch 7, Batch 1400] loss: 0.023352712292034995
[Epoch 7, Batch 1500] loss: 0.02059952074094326
[Epoch 7, Batch 1600] loss: 0.03208520624743414
[Epoch 7, Batch 1700] loss: 0.03412050508570246
[Epoch 7, Batch 1800] loss: 0.020851253247528803
[Epoch 7, Batch 1900] loss: 0.026476492399197013
[Epoch 7, Batch 2000] loss: 0.04053696215367381
[Epoch 7, Batch 2100] loss: 0.01964421900072921
[Epoch 7, Batch 2200] loss: 0.012752015403693804
[Epoch 7, Batch 2300] loss: 0.02645997674211685
[Epoch 7, Batch 2400] loss: 0.016690009749727324
[Epoch 7, Batch 2500] loss: 0.0359050785458021
[Epoch 7, Batch 2600] loss: 0.025760743131904747
[Epoch 7, Batch 2700] loss: 0.029058178570448946
[Epoch 7, Batch 2800] loss: 0.021114212377342484
[Epoch 7, Batch 2900] loss: 0.02537589788385958
[Epoch 7, Batch 3000] loss: 0.034473571057769735
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9858
Overfitting: 0.0477
Best model saved at epoch 7 with validation loss: 0.0477
[Epoch 8, Batch 100] loss: 0.01375878721686604
[Epoch 8, Batch 200] loss: 0.010847284472815773
[Epoch 8, Batch 300] loss: 0.01739208293093725
[Epoch 8, Batch 400] loss: 0.032687595102497656
[Epoch 8, Batch 500] loss: 0.026112598326399165
[Epoch 8, Batch 600] loss: 0.021765970766573446
[Epoch 8, Batch 700] loss: 0.017363911342854407
[Epoch 8, Batch 800] loss: 0.03978104185382108
[Epoch 8, Batch 900] loss: 0.019200058900796648
[Epoch 8, Batch 1000] loss: 0.023562941405543825
[Epoch 8, Batch 1100] loss: 0.0315084244416721
[Epoch 8, Batch 1200] loss: 0.00884488482757547
[Epoch 8, Batch 1300] loss: 0.01253719983940755
[Epoch 8, Batch 1400] loss: 0.017538538527278432
[Epoch 8, Batch 1500] loss: 0.01369716530205551
[Epoch 8, Batch 1600] loss: 0.031310693766445186
[Epoch 8, Batch 1700] loss: 0.03520446856437047
[Epoch 8, Batch 1800] loss: 0.034930322172476734
[Epoch 8, Batch 1900] loss: 0.03015766474072734
[Epoch 8, Batch 2000] loss: 0.025064362298435297
[Epoch 8, Batch 2100] loss: 0.044300739202499245
[Epoch 8, Batch 2200] loss: 0.03444235564726114
[Epoch 8, Batch 2300] loss: 0.019744205304286878
[Epoch 8, Batch 2400] loss: 0.021607756866469572
[Epoch 8, Batch 2500] loss: 0.029694911077713187
[Epoch 8, Batch 2600] loss: 0.018539467741420596
[Epoch 8, Batch 2700] loss: 0.03746446344339347
[Epoch 8, Batch 2800] loss: 0.02802990588330431
[Epoch 8, Batch 2900] loss: 0.021438564095296896
[Epoch 8, Batch 3000] loss: 0.02081474610411533
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9854
Overfitting: 0.0550
[Epoch 9, Batch 100] loss: 0.01182444447718808
[Epoch 9, Batch 200] loss: 0.02687544697091653
[Epoch 9, Batch 300] loss: 0.022350317338805326
[Epoch 9, Batch 400] loss: 0.0289766560454882
[Epoch 9, Batch 500] loss: 0.023493824962170038
[Epoch 9, Batch 600] loss: 0.017069777271353816
[Epoch 9, Batch 700] loss: 0.016392716639966238
[Epoch 9, Batch 800] loss: 0.02399783581349766
[Epoch 9, Batch 900] loss: 0.009869815795318572
[Epoch 9, Batch 1000] loss: 0.02205679825252446
[Epoch 9, Batch 1100] loss: 0.02094904786426923
[Epoch 9, Batch 1200] loss: 0.018125236588630286
[Epoch 9, Batch 1300] loss: 0.018434506870398763
[Epoch 9, Batch 1400] loss: 0.018270667238975875
[Epoch 9, Batch 1500] loss: 0.01667231156071466
[Epoch 9, Batch 1600] loss: 0.020032784728173283
[Epoch 9, Batch 1700] loss: 0.027099269241625736
[Epoch 9, Batch 1800] loss: 0.017102151630242587
[Epoch 9, Batch 1900] loss: 0.016079162313872075
[Epoch 9, Batch 2000] loss: 0.02001431243477782
[Epoch 9, Batch 2100] loss: 0.02404058931970212
[Epoch 9, Batch 2200] loss: 0.021010733369503213
[Epoch 9, Batch 2300] loss: 0.013930233166574909
[Epoch 9, Batch 2400] loss: 0.03538608606247522
[Epoch 9, Batch 2500] loss: 0.01598513392062159
[Epoch 9, Batch 2600] loss: 0.019103110432643008
[Epoch 9, Batch 2700] loss: 0.019028212672665176
[Epoch 9, Batch 2800] loss: 0.026101499649603285
[Epoch 9, Batch 2900] loss: 0.016114086017423687
[Epoch 9, Batch 3000] loss: 0.0262764205071926
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9846
Overfitting: 0.0519
[Epoch 10, Batch 100] loss: 0.017696519535966217
[Epoch 10, Batch 200] loss: 0.015865554197007442
[Epoch 10, Batch 300] loss: 0.012379872347300988
[Epoch 10, Batch 400] loss: 0.016618261913217792
[Epoch 10, Batch 500] loss: 0.012472448452599564
[Epoch 10, Batch 600] loss: 0.011120021842216374
[Epoch 10, Batch 700] loss: 0.029214760441418547
[Epoch 10, Batch 800] loss: 0.011791434521464908
[Epoch 10, Batch 900] loss: 0.018173451708789798
[Epoch 10, Batch 1000] loss: 0.020557385653164603
[Epoch 10, Batch 1100] loss: 0.02013550730138377
[Epoch 10, Batch 1200] loss: 0.014015935820079903
[Epoch 10, Batch 1300] loss: 0.01698087632425995
[Epoch 10, Batch 1400] loss: 0.012333405018171106
[Epoch 10, Batch 1500] loss: 0.013832334627013552
[Epoch 10, Batch 1600] loss: 0.021844818172476153
[Epoch 10, Batch 1700] loss: 0.011907737091951276
[Epoch 10, Batch 1800] loss: 0.01774953887828815
[Epoch 10, Batch 1900] loss: 0.020622802621383017
[Epoch 10, Batch 2000] loss: 0.02651010751786316
[Epoch 10, Batch 2100] loss: 0.015508474337893858
[Epoch 10, Batch 2200] loss: 0.01638576355908299
[Epoch 10, Batch 2300] loss: 0.01571205706357432
[Epoch 10, Batch 2400] loss: 0.018372182511575373
[Epoch 10, Batch 2500] loss: 0.030311736888361338
[Epoch 10, Batch 2600] loss: 0.018232519088196567
[Epoch 10, Batch 2700] loss: 0.0258132699364387
[Epoch 10, Batch 2800] loss: 0.02459545853905183
[Epoch 10, Batch 2900] loss: 0.016159902043491457
[Epoch 10, Batch 3000] loss: 0.02697843300246859
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9855
Overfitting: 0.0529
[Epoch 11, Batch 100] loss: 0.018558668421519542
[Epoch 11, Batch 200] loss: 0.015008706028847883
[Epoch 11, Batch 300] loss: 0.016289853087664598
[Epoch 11, Batch 400] loss: 0.01780334882012994
[Epoch 11, Batch 500] loss: 0.020742367756683963
[Epoch 11, Batch 600] loss: 0.011957040561073882
[Epoch 11, Batch 700] loss: 0.008300117342591874
[Epoch 11, Batch 800] loss: 0.01959667020888901
[Epoch 11, Batch 900] loss: 0.01596478935707637
[Epoch 11, Batch 1000] loss: 0.012580461603947697
[Epoch 11, Batch 1100] loss: 0.025606979536296422
[Epoch 11, Batch 1200] loss: 0.0140631302433394
[Epoch 11, Batch 1300] loss: 0.02060693073853372
[Epoch 11, Batch 1400] loss: 0.019869425329443403
[Epoch 11, Batch 1500] loss: 0.00747068155323177
[Epoch 11, Batch 1600] loss: 0.012066167408279397
[Epoch 11, Batch 1700] loss: 0.011024996726055178
[Epoch 11, Batch 1800] loss: 0.015236956886833469
[Epoch 11, Batch 1900] loss: 0.00704325825774049
[Epoch 11, Batch 2000] loss: 0.01932436048989075
[Epoch 11, Batch 2100] loss: 0.03050687805080088
[Epoch 11, Batch 2200] loss: 0.026337364826295017
[Epoch 11, Batch 2300] loss: 0.012856130060517898
[Epoch 11, Batch 2400] loss: 0.0192128122081931
[Epoch 11, Batch 2500] loss: 0.029882150687553802
[Epoch 11, Batch 2600] loss: 0.01260407007059257
[Epoch 11, Batch 2700] loss: 0.018265719308546976
[Epoch 11, Batch 2800] loss: 0.0200473088344188
[Epoch 11, Batch 2900] loss: 0.011201253316958173
[Epoch 11, Batch 3000] loss: 0.008616150147508961
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9868
Overfitting: 0.0514
[Epoch 12, Batch 100] loss: 0.011081451147015286
[Epoch 12, Batch 200] loss: 0.013603406129250288
[Epoch 12, Batch 300] loss: 0.012378759111817317
[Epoch 12, Batch 400] loss: 0.008452387120287312
[Epoch 12, Batch 500] loss: 0.012704653297105324
[Epoch 12, Batch 600] loss: 0.015460987600545196
[Epoch 12, Batch 700] loss: 0.014957830096154794
[Epoch 12, Batch 800] loss: 0.008712563440408303
[Epoch 12, Batch 900] loss: 0.020820859076804935
[Epoch 12, Batch 1000] loss: 0.016502474844519385
[Epoch 12, Batch 1100] loss: 0.022806278367634148
[Epoch 12, Batch 1200] loss: 0.013805100093850341
[Epoch 12, Batch 1300] loss: 0.009434542817389228
[Epoch 12, Batch 1400] loss: 0.008139929705216674
[Epoch 12, Batch 1500] loss: 0.01005068525558272
[Epoch 12, Batch 1600] loss: 0.011089791758163301
[Epoch 12, Batch 1700] loss: 0.03543323181537744
[Epoch 12, Batch 1800] loss: 0.01754878788648057
[Epoch 12, Batch 1900] loss: 0.026649038586479035
[Epoch 12, Batch 2000] loss: 0.01465823054644261
[Epoch 12, Batch 2100] loss: 0.022327295418144787
[Epoch 12, Batch 2200] loss: 0.014028729035735522
[Epoch 12, Batch 2300] loss: 0.01042223939017731
[Epoch 12, Batch 2400] loss: 0.02584475585807013
[Epoch 12, Batch 2500] loss: 0.023591038757831483
[Epoch 12, Batch 2600] loss: 0.020072821386029317
[Epoch 12, Batch 2700] loss: 0.01338049252924975
[Epoch 12, Batch 2800] loss: 0.012064995058908607
[Epoch 12, Batch 2900] loss: 0.013732306407059696
[Epoch 12, Batch 3000] loss: 0.015114747177776736
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9855
Overfitting: 0.0499
[Epoch 13, Batch 100] loss: 0.009535401486400587
[Epoch 13, Batch 200] loss: 0.007741623841311594
[Epoch 13, Batch 300] loss: 0.010372521342378604
[Epoch 13, Batch 400] loss: 0.021203139613642178
[Epoch 13, Batch 500] loss: 0.006861383064733673
[Epoch 13, Batch 600] loss: 0.009501665015829986
[Epoch 13, Batch 700] loss: 0.008925536346914668
[Epoch 13, Batch 800] loss: 0.004677578986284061
[Epoch 13, Batch 900] loss: 0.016965139250569337
[Epoch 13, Batch 1000] loss: 0.012774820827676194
[Epoch 13, Batch 1100] loss: 0.027609047752494006
[Epoch 13, Batch 1200] loss: 0.013302036572013095
[Epoch 13, Batch 1300] loss: 0.01682355177952559
[Epoch 13, Batch 1400] loss: 0.01994581865508735
[Epoch 13, Batch 1500] loss: 0.0187859536017595
[Epoch 13, Batch 1600] loss: 0.012944718086228022
[Epoch 13, Batch 1700] loss: 0.024075192779893086
[Epoch 13, Batch 1800] loss: 0.027737806069289946
[Epoch 13, Batch 1900] loss: 0.01699521719853692
[Epoch 13, Batch 2000] loss: 0.014649308062807904
[Epoch 13, Batch 2100] loss: 0.014061451173465684
[Epoch 13, Batch 2200] loss: 0.013429681042189258
[Epoch 13, Batch 2300] loss: 0.016618210673796055
[Epoch 13, Batch 2400] loss: 0.013617173192033078
[Epoch 13, Batch 2500] loss: 0.016899661259199093
[Epoch 13, Batch 2600] loss: 0.0138790146438987
[Epoch 13, Batch 2700] loss: 0.016682923572225263
[Epoch 13, Batch 2800] loss: 0.008247932133099312
[Epoch 13, Batch 2900] loss: 0.00440165887369659
[Epoch 13, Batch 3000] loss: 0.007781952807745256
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9860
Overfitting: 0.0526
[Epoch 14, Batch 100] loss: 0.013201672952877743
[Epoch 14, Batch 200] loss: 0.00978006378571081
[Epoch 14, Batch 300] loss: 0.008544246806111459
[Epoch 14, Batch 400] loss: 0.0047693272991728005
[Epoch 14, Batch 500] loss: 0.01842466290691391
[Epoch 14, Batch 600] loss: 0.0071562691834833455
[Epoch 14, Batch 700] loss: 0.0055075678300408985
[Epoch 14, Batch 800] loss: 0.008074486943047531
[Epoch 14, Batch 900] loss: 0.014043048752744198
[Epoch 14, Batch 1000] loss: 0.016525918901788828
[Epoch 14, Batch 1100] loss: 0.0035346093090197427
[Epoch 14, Batch 1200] loss: 0.00781304356386272
[Epoch 14, Batch 1300] loss: 0.011282034458949965
[Epoch 14, Batch 1400] loss: 0.013038274968542964
[Epoch 14, Batch 1500] loss: 0.018845403649979744
[Epoch 14, Batch 1600] loss: 0.011990143587181592
[Epoch 14, Batch 1700] loss: 0.012555004874757287
[Epoch 14, Batch 1800] loss: 0.01743698117923941
[Epoch 14, Batch 1900] loss: 0.011277877660506874
[Epoch 14, Batch 2000] loss: 0.011581479162996402
[Epoch 14, Batch 2100] loss: 0.00901091861681948
[Epoch 14, Batch 2200] loss: 0.01187145716557552
[Epoch 14, Batch 2300] loss: 0.019084134274230564
[Epoch 14, Batch 2400] loss: 0.008187018938733671
[Epoch 14, Batch 2500] loss: 0.008705987341095352
[Epoch 14, Batch 2600] loss: 0.010447290206586786
[Epoch 14, Batch 2700] loss: 0.01683165756604012
[Epoch 14, Batch 2800] loss: 0.007671061644569477
[Epoch 14, Batch 2900] loss: 0.01805909590555416
[Epoch 14, Batch 3000] loss: 0.009481466432353045
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9872
Overfitting: 0.0538
[Epoch 15, Batch 100] loss: 0.013062669528915194
[Epoch 15, Batch 200] loss: 0.007024997255568905
[Epoch 15, Batch 300] loss: 0.00508899729253244
[Epoch 15, Batch 400] loss: 0.0074320433306206725
[Epoch 15, Batch 500] loss: 0.00662315042129535
[Epoch 15, Batch 600] loss: 0.012059556920519868
[Epoch 15, Batch 700] loss: 0.005743606004322146
[Epoch 15, Batch 800] loss: 0.0021214585867335243
[Epoch 15, Batch 900] loss: 0.005459530405464648
[Epoch 15, Batch 1000] loss: 0.00747337658487595
[Epoch 15, Batch 1100] loss: 0.003655205549965217
[Epoch 15, Batch 1200] loss: 0.009238473205527953
[Epoch 15, Batch 1300] loss: 0.007904428051292314
[Epoch 15, Batch 1400] loss: 0.012433852628838622
[Epoch 15, Batch 1500] loss: 0.014112764574794028
[Epoch 15, Batch 1600] loss: 0.01479937795441117
[Epoch 15, Batch 1700] loss: 0.010154674373737863
[Epoch 15, Batch 1800] loss: 0.011309041090776191
[Epoch 15, Batch 1900] loss: 0.013384420150759978
[Epoch 15, Batch 2000] loss: 0.0146299922613548
[Epoch 15, Batch 2100] loss: 0.0065093422214158635
[Epoch 15, Batch 2200] loss: 0.009715966807925724
[Epoch 15, Batch 2300] loss: 0.007827246409942746
[Epoch 15, Batch 2400] loss: 0.016545104726459953
[Epoch 15, Batch 2500] loss: 0.00619427831908979
[Epoch 15, Batch 2600] loss: 0.015232756517141866
[Epoch 15, Batch 2700] loss: 0.016952233941489113
[Epoch 15, Batch 2800] loss: 0.0135759317814518
[Epoch 15, Batch 2900] loss: 0.006376750123095008
[Epoch 15, Batch 3000] loss: 0.015683171055725323
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9862
Overfitting: 0.0552
[Epoch 16, Batch 100] loss: 0.005414489221998338
[Epoch 16, Batch 200] loss: 0.009276065368903802
[Epoch 16, Batch 300] loss: 0.00566876528296234
[Epoch 16, Batch 400] loss: 0.0020411664263679085
[Epoch 16, Batch 500] loss: 0.008708766272235664
[Epoch 16, Batch 600] loss: 0.01414269230182299
[Epoch 16, Batch 700] loss: 0.017978700189686166
[Epoch 16, Batch 800] loss: 0.013690908710091208
[Epoch 16, Batch 900] loss: 0.0036073910619376193
[Epoch 16, Batch 1000] loss: 0.007346818593496209
[Epoch 16, Batch 1100] loss: 0.01472927054622744
[Epoch 16, Batch 1200] loss: 0.009416135170476706
[Epoch 16, Batch 1300] loss: 0.009115578634695112
[Epoch 16, Batch 1400] loss: 0.010210786588183928
[Epoch 16, Batch 1500] loss: 0.008842984497237581
[Epoch 16, Batch 1600] loss: 0.004629839884859166
[Epoch 16, Batch 1700] loss: 0.014817219231574655
[Epoch 16, Batch 1800] loss: 0.015735977707408894
[Epoch 16, Batch 1900] loss: 0.007356340617267278
[Epoch 16, Batch 2000] loss: 0.01064448611683929
[Epoch 16, Batch 2100] loss: 0.004725052336554541
[Epoch 16, Batch 2200] loss: 0.006298109919323451
[Epoch 16, Batch 2300] loss: 0.009363332040934438
[Epoch 16, Batch 2400] loss: 0.004386500656920731
[Epoch 16, Batch 2500] loss: 0.01797697899406842
[Epoch 16, Batch 2600] loss: 0.014592764349636127
[Epoch 16, Batch 2700] loss: 0.013250388520613115
[Epoch 16, Batch 2800] loss: 0.012087818095717467
[Epoch 16, Batch 2900] loss: 0.018733450467520923
[Epoch 16, Batch 3000] loss: 0.0056669258385170455
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9875
Overfitting: 0.0493
[Epoch 17, Batch 100] loss: 0.004810745074968565
[Epoch 17, Batch 200] loss: 0.01128057949558297
[Epoch 17, Batch 300] loss: 0.005906904661469525
[Epoch 17, Batch 400] loss: 0.002135578419566286
[Epoch 17, Batch 500] loss: 0.0017523259277839997
[Epoch 17, Batch 600] loss: 0.0063357270211270135
[Epoch 17, Batch 700] loss: 0.011071341570602727
[Epoch 17, Batch 800] loss: 0.006591748195962737
[Epoch 17, Batch 900] loss: 0.00585496935355053
[Epoch 17, Batch 1000] loss: 0.0049816850874867665
[Epoch 17, Batch 1100] loss: 0.0030914840553009524
[Epoch 17, Batch 1200] loss: 0.008254496950262648
[Epoch 17, Batch 1300] loss: 0.005368931834027535
[Epoch 17, Batch 1400] loss: 0.00852533271158194
[Epoch 17, Batch 1500] loss: 0.005756505491874719
[Epoch 17, Batch 1600] loss: 0.006020583502073009
[Epoch 17, Batch 1700] loss: 0.005372873458181715
[Epoch 17, Batch 1800] loss: 0.005619085923988223
[Epoch 17, Batch 1900] loss: 0.002066846746238866
[Epoch 17, Batch 2000] loss: 0.016639279340269014
[Epoch 17, Batch 2100] loss: 0.0047495929863316634
[Epoch 17, Batch 2200] loss: 0.009199557355631214
[Epoch 17, Batch 2300] loss: 0.004218372282605287
[Epoch 17, Batch 2400] loss: 0.0033742698954250727
[Epoch 17, Batch 2500] loss: 0.0038539830564232602
[Epoch 17, Batch 2600] loss: 0.006659253716710083
[Epoch 17, Batch 2700] loss: 0.004077823946289527
[Epoch 17, Batch 2800] loss: 0.011369941188068538
[Epoch 17, Batch 2900] loss: 0.006657696686010439
[Epoch 17, Batch 3000] loss: 0.0034409320325977434
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0587
Validation Accuracy: 0.9866
Overfitting: 0.0587
[I 2024-12-10 06:25:39,203] Trial 5 pruned. 

Selected Hyperparameters for Trial 7:
  l1: 128, l2: 64, lr: 0.0003646439558980723, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.304963116645813
**STATS for Epoch 1** : 
Average training loss: 1.0738
Average validation loss: 2.2885
Validation Accuracy: 0.1198
Overfitting: 1.2147
Best model saved at epoch 1 with validation loss: 2.2885
[Epoch 2, Batch 100] loss: 2.282032322883606
**STATS for Epoch 2** : 
Average training loss: 1.0603
Average validation loss: 2.2544
Validation Accuracy: 0.2507
Overfitting: 1.1941
Best model saved at epoch 2 with validation loss: 2.2544
[Epoch 3, Batch 100] loss: 2.2395126032829284
**STATS for Epoch 3** : 
Average training loss: 1.0258
Average validation loss: 2.1560
Validation Accuracy: 0.4372
Overfitting: 1.1301
Best model saved at epoch 3 with validation loss: 2.1560
[Epoch 4, Batch 100] loss: 2.090215961933136
**STATS for Epoch 4** : 
Average training loss: 0.8644
Average validation loss: 1.6491
Validation Accuracy: 0.6281
Overfitting: 0.7847
Best model saved at epoch 4 with validation loss: 1.6491
[Epoch 5, Batch 100] loss: 1.3706376779079437
**STATS for Epoch 5** : 
Average training loss: 0.4409
Average validation loss: 0.7860
Validation Accuracy: 0.7826
Overfitting: 0.3451
Best model saved at epoch 5 with validation loss: 0.7860
[Epoch 6, Batch 100] loss: 0.7099363976716995
**STATS for Epoch 6** : 
Average training loss: 0.2810
Average validation loss: 0.5515
Validation Accuracy: 0.8335
Overfitting: 0.2705
Best model saved at epoch 6 with validation loss: 0.5515
[Epoch 7, Batch 100] loss: 0.5383051356673241
**STATS for Epoch 7** : 
Average training loss: 0.2310
Average validation loss: 0.4584
Validation Accuracy: 0.8660
Overfitting: 0.2274
Best model saved at epoch 7 with validation loss: 0.4584
[Epoch 8, Batch 100] loss: 0.4606015884876251
**STATS for Epoch 8** : 
Average training loss: 0.2008
Average validation loss: 0.4004
Validation Accuracy: 0.8832
Overfitting: 0.1996
Best model saved at epoch 8 with validation loss: 0.4004
[Epoch 9, Batch 100] loss: 0.4115151196718216
**STATS for Epoch 9** : 
Average training loss: 0.1781
Average validation loss: 0.3583
Validation Accuracy: 0.8954
Overfitting: 0.1802
[I 2024-12-10 06:27:04,399] Trial 6 pruned. 

Selected Hyperparameters for Trial 8:
  l1: 128, l2: 128, lr: 0.002592475660475161, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2805521488189697
[Epoch 1, Batch 200] loss: 1.6401602512598037
[Epoch 1, Batch 300] loss: 0.632297927737236
[Epoch 1, Batch 400] loss: 0.42736326918005946
[Epoch 1, Batch 500] loss: 0.34245342150330543
[Epoch 1, Batch 600] loss: 0.2628579778596759
[Epoch 1, Batch 700] loss: 0.24655386112630368
[Epoch 1, Batch 800] loss: 0.22082003213465215
[Epoch 1, Batch 900] loss: 0.22494256937876345
[Epoch 1, Batch 1000] loss: 0.17004009503871204
[Epoch 1, Batch 1100] loss: 0.1621633261628449
[Epoch 1, Batch 1200] loss: 0.14683675270527602
[Epoch 1, Batch 1300] loss: 0.1516353216394782
[Epoch 1, Batch 1400] loss: 0.13502954196184874
[Epoch 1, Batch 1500] loss: 0.14870106228627264
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1059
Validation Accuracy: 0.9680
Overfitting: 0.1059
Best model saved at epoch 1 with validation loss: 0.1059
[Epoch 2, Batch 100] loss: 0.10907094344496727
[Epoch 2, Batch 200] loss: 0.12472824375145138
[Epoch 2, Batch 300] loss: 0.10409057136625051
[Epoch 2, Batch 400] loss: 0.09719715251587331
[Epoch 2, Batch 500] loss: 0.11300118761137128
[Epoch 2, Batch 600] loss: 0.0946104867849499
[Epoch 2, Batch 700] loss: 0.08852026407141239
[Epoch 2, Batch 800] loss: 0.09077808080939576
[Epoch 2, Batch 900] loss: 0.09294383350294083
[Epoch 2, Batch 1000] loss: 0.10009109787177295
[Epoch 2, Batch 1100] loss: 0.07615655881818384
[Epoch 2, Batch 1200] loss: 0.0844783255434595
[Epoch 2, Batch 1300] loss: 0.07266319768503308
[Epoch 2, Batch 1400] loss: 0.08796259108697996
[Epoch 2, Batch 1500] loss: 0.08855803277809172
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0790
Validation Accuracy: 0.9761
Overfitting: 0.0790
Best model saved at epoch 2 with validation loss: 0.0790
[Epoch 3, Batch 100] loss: 0.06172522614360787
[Epoch 3, Batch 200] loss: 0.0583150133350864
[Epoch 3, Batch 300] loss: 0.0633682340150699
[Epoch 3, Batch 400] loss: 0.06873021690058521
[Epoch 3, Batch 500] loss: 0.056579233941156416
[Epoch 3, Batch 600] loss: 0.08209693187964148
[Epoch 3, Batch 700] loss: 0.06048572599305771
[Epoch 3, Batch 800] loss: 0.062478375768405384
[Epoch 3, Batch 900] loss: 0.07001790600363166
[Epoch 3, Batch 1000] loss: 0.06471933803753928
[Epoch 3, Batch 1100] loss: 0.054736699066124855
[Epoch 3, Batch 1200] loss: 0.052775844480493106
[Epoch 3, Batch 1300] loss: 0.06813530837651342
[Epoch 3, Batch 1400] loss: 0.0638044066587463
[Epoch 3, Batch 1500] loss: 0.06480491078575142
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0590
Validation Accuracy: 0.9807
Overfitting: 0.0590
Best model saved at epoch 3 with validation loss: 0.0590
[Epoch 4, Batch 100] loss: 0.051063474338734524
[Epoch 4, Batch 200] loss: 0.0412214231165126
[Epoch 4, Batch 300] loss: 0.05598460622830317
[Epoch 4, Batch 400] loss: 0.05635614099126542
[Epoch 4, Batch 500] loss: 0.05555855434911791
[Epoch 4, Batch 600] loss: 0.04367895187926479
[Epoch 4, Batch 700] loss: 0.04517234138620552
[Epoch 4, Batch 800] loss: 0.04890782580885571
[Epoch 4, Batch 900] loss: 0.04813027023919858
[Epoch 4, Batch 1000] loss: 0.04671125178283546
[Epoch 4, Batch 1100] loss: 0.03985033873119392
[Epoch 4, Batch 1200] loss: 0.05195481876260601
[Epoch 4, Batch 1300] loss: 0.04665866396506317
[Epoch 4, Batch 1400] loss: 0.04503151335287839
[Epoch 4, Batch 1500] loss: 0.05036089215660468
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0687
Validation Accuracy: 0.9806
Overfitting: 0.0687
[Epoch 5, Batch 100] loss: 0.03777079197898274
[Epoch 5, Batch 200] loss: 0.03859785613894928
[Epoch 5, Batch 300] loss: 0.034883071544463747
[Epoch 5, Batch 400] loss: 0.041848514520097524
[Epoch 5, Batch 500] loss: 0.04016466421599034
[Epoch 5, Batch 600] loss: 0.03153608154214453
[Epoch 5, Batch 700] loss: 0.037893663076029045
[Epoch 5, Batch 800] loss: 0.04046924203867093
[Epoch 5, Batch 900] loss: 0.03461913878796622
[Epoch 5, Batch 1000] loss: 0.047898473390960136
[Epoch 5, Batch 1100] loss: 0.040792220445582644
[Epoch 5, Batch 1200] loss: 0.043692315798834896
[Epoch 5, Batch 1300] loss: 0.03824671736336313
[Epoch 5, Batch 1400] loss: 0.054994210792938245
[Epoch 5, Batch 1500] loss: 0.03265997020062059
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9848
Overfitting: 0.0482
Best model saved at epoch 5 with validation loss: 0.0482
[Epoch 6, Batch 100] loss: 0.03286626806278946
[Epoch 6, Batch 200] loss: 0.02724294488405576
[Epoch 6, Batch 300] loss: 0.03493118824568228
[Epoch 6, Batch 400] loss: 0.03438222378259525
[Epoch 6, Batch 500] loss: 0.0315406778617762
[Epoch 6, Batch 600] loss: 0.03103011254570447
[Epoch 6, Batch 700] loss: 0.03773898334940896
[Epoch 6, Batch 800] loss: 0.04242620751203503
[Epoch 6, Batch 900] loss: 0.029762691937503406
[Epoch 6, Batch 1000] loss: 0.02788816833141027
[Epoch 6, Batch 1100] loss: 0.03436457974283257
[Epoch 6, Batch 1200] loss: 0.03802858992799884
[Epoch 6, Batch 1300] loss: 0.037988080672803334
[Epoch 6, Batch 1400] loss: 0.0317331862761057
[Epoch 6, Batch 1500] loss: 0.03386745323892683
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9862
Overfitting: 0.0497
[Epoch 7, Batch 100] loss: 0.030794288655743005
[Epoch 7, Batch 200] loss: 0.019871921036756248
[Epoch 7, Batch 300] loss: 0.022284883764223197
[Epoch 7, Batch 400] loss: 0.023170496108941733
[Epoch 7, Batch 500] loss: 0.03722568739001872
[Epoch 7, Batch 600] loss: 0.024074389924935533
[Epoch 7, Batch 700] loss: 0.02772729546937626
[Epoch 7, Batch 800] loss: 0.03147411954501877
[Epoch 7, Batch 900] loss: 0.02174776436208049
[Epoch 7, Batch 1000] loss: 0.02750701759025105
[Epoch 7, Batch 1100] loss: 0.03785348131248611
[Epoch 7, Batch 1200] loss: 0.029288362286170013
[Epoch 7, Batch 1300] loss: 0.041485025481379126
[Epoch 7, Batch 1400] loss: 0.02996145950484788
[Epoch 7, Batch 1500] loss: 0.032888715812878215
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0432
Validation Accuracy: 0.9865
Overfitting: 0.0432
Best model saved at epoch 7 with validation loss: 0.0432
[Epoch 8, Batch 100] loss: 0.029240332565095742
[Epoch 8, Batch 200] loss: 0.02223759285581764
[Epoch 8, Batch 300] loss: 0.0175293793954188
[Epoch 8, Batch 400] loss: 0.02360466094654839
[Epoch 8, Batch 500] loss: 0.02481226815638365
[Epoch 8, Batch 600] loss: 0.018995331875776175
[Epoch 8, Batch 700] loss: 0.023493415023258423
[Epoch 8, Batch 800] loss: 0.024634074403584238
[Epoch 8, Batch 900] loss: 0.024350273979798658
[Epoch 8, Batch 1000] loss: 0.02229181113310915
[Epoch 8, Batch 1100] loss: 0.025877945738320706
[Epoch 8, Batch 1200] loss: 0.02342760326806456
[Epoch 8, Batch 1300] loss: 0.027576575295679504
[Epoch 8, Batch 1400] loss: 0.020031760552083142
[Epoch 8, Batch 1500] loss: 0.03679582379569183
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0541
Validation Accuracy: 0.9823
Overfitting: 0.0541
[Epoch 9, Batch 100] loss: 0.018086214804206975
[Epoch 9, Batch 200] loss: 0.027173908813419984
[Epoch 9, Batch 300] loss: 0.018270722493034554
[Epoch 9, Batch 400] loss: 0.021209700551553398
[Epoch 9, Batch 500] loss: 0.020830905092734612
[Epoch 9, Batch 600] loss: 0.017588387017458445
[Epoch 9, Batch 700] loss: 0.01867843488289509
[Epoch 9, Batch 800] loss: 0.021679076757500297
[Epoch 9, Batch 900] loss: 0.020374501428959774
[Epoch 9, Batch 1000] loss: 0.016986798054058453
[Epoch 9, Batch 1100] loss: 0.028881043493020116
[Epoch 9, Batch 1200] loss: 0.03160723964887438
[Epoch 9, Batch 1300] loss: 0.018931531183043263
[Epoch 9, Batch 1400] loss: 0.028536414827685805
[Epoch 9, Batch 1500] loss: 0.014398323111236096
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0488
Validation Accuracy: 0.9858
Overfitting: 0.0488
[Epoch 10, Batch 100] loss: 0.019050337666412814
[Epoch 10, Batch 200] loss: 0.02288778963382356
[Epoch 10, Batch 300] loss: 0.01998121481303315
[Epoch 10, Batch 400] loss: 0.025870025786425686
[Epoch 10, Batch 500] loss: 0.011946809919754742
[Epoch 10, Batch 600] loss: 0.01809607245348161
[Epoch 10, Batch 700] loss: 0.022218561977497303
[Epoch 10, Batch 800] loss: 0.019361228520137955
[Epoch 10, Batch 900] loss: 0.02062203875393607
[Epoch 10, Batch 1000] loss: 0.015203355570483836
[Epoch 10, Batch 1100] loss: 0.017732098039705307
[Epoch 10, Batch 1200] loss: 0.015638835966892656
[Epoch 10, Batch 1300] loss: 0.015384537674981403
[Epoch 10, Batch 1400] loss: 0.01751687421099632
[Epoch 10, Batch 1500] loss: 0.031761600000754696
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9874
Overfitting: 0.0459
[Epoch 11, Batch 100] loss: 0.012371078651140123
[Epoch 11, Batch 200] loss: 0.0159114235387824
[Epoch 11, Batch 300] loss: 0.018248477724191615
[Epoch 11, Batch 400] loss: 0.025289575570859597
[Epoch 11, Batch 500] loss: 0.01583071598866809
[Epoch 11, Batch 600] loss: 0.02372615789194242
[Epoch 11, Batch 700] loss: 0.013746691262858803
[Epoch 11, Batch 800] loss: 0.01252265800263558
[Epoch 11, Batch 900] loss: 0.009614930614661716
[Epoch 11, Batch 1000] loss: 0.01414722190649627
[Epoch 11, Batch 1100] loss: 0.01970457863964839
[Epoch 11, Batch 1200] loss: 0.01957877217217174
[Epoch 11, Batch 1300] loss: 0.01616621527256939
[Epoch 11, Batch 1400] loss: 0.01507642332409887
[Epoch 11, Batch 1500] loss: 0.019132604712649482
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9863
Overfitting: 0.0499
[Epoch 12, Batch 100] loss: 0.017994652826446328
[Epoch 12, Batch 200] loss: 0.012074104573621298
[Epoch 12, Batch 300] loss: 0.009655816223676084
[Epoch 12, Batch 400] loss: 0.017054089872399345
[Epoch 12, Batch 500] loss: 0.010956630284927087
[Epoch 12, Batch 600] loss: 0.009420268800276972
[Epoch 12, Batch 700] loss: 0.01245426088487875
[Epoch 12, Batch 800] loss: 0.02004008820738818
[Epoch 12, Batch 900] loss: 0.013660333935767995
[Epoch 12, Batch 1000] loss: 0.014662728588809841
[Epoch 12, Batch 1100] loss: 0.0081804417942476
[Epoch 12, Batch 1200] loss: 0.017241889801407524
[Epoch 12, Batch 1300] loss: 0.02532909421279328
[Epoch 12, Batch 1400] loss: 0.013771122311154613
[Epoch 12, Batch 1500] loss: 0.015386160816633491
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9878
Overfitting: 0.0452
[Epoch 13, Batch 100] loss: 0.010266817109313707
[Epoch 13, Batch 200] loss: 0.011390881419283688
[Epoch 13, Batch 300] loss: 0.00853652960733598
[Epoch 13, Batch 400] loss: 0.008515211696530968
[Epoch 13, Batch 500] loss: 0.011970446871237073
[Epoch 13, Batch 600] loss: 0.010748271531820137
[Epoch 13, Batch 700] loss: 0.015922503187321125
[Epoch 13, Batch 800] loss: 0.013963647181153647
[Epoch 13, Batch 900] loss: 0.008112322474808024
[Epoch 13, Batch 1000] loss: 0.01696257453153521
[Epoch 13, Batch 1100] loss: 0.019122690489384694
[Epoch 13, Batch 1200] loss: 0.010754594701220413
[Epoch 13, Batch 1300] loss: 0.01602067064795847
[Epoch 13, Batch 1400] loss: 0.011199497399429674
[Epoch 13, Batch 1500] loss: 0.01883866627698808
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9852
Overfitting: 0.0527
[Epoch 14, Batch 100] loss: 0.01182634807209979
[Epoch 14, Batch 200] loss: 0.014429681052515662
[Epoch 14, Batch 300] loss: 0.012923920467183053
[Epoch 14, Batch 400] loss: 0.0064359683959810355
[Epoch 14, Batch 500] loss: 0.012445313127464032
[Epoch 14, Batch 600] loss: 0.005819767828870681
[Epoch 14, Batch 700] loss: 0.015974070602933352
[Epoch 14, Batch 800] loss: 0.013088716564052447
[Epoch 14, Batch 900] loss: 0.008521938032754407
[Epoch 14, Batch 1000] loss: 0.007921638722505122
[Epoch 14, Batch 1100] loss: 0.009719934365211885
[Epoch 14, Batch 1200] loss: 0.013246286378689546
[Epoch 14, Batch 1300] loss: 0.016229446428224038
[Epoch 14, Batch 1400] loss: 0.013694100670800253
[Epoch 14, Batch 1500] loss: 0.014254017977691547
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0433
Validation Accuracy: 0.9880
Overfitting: 0.0433
[Epoch 15, Batch 100] loss: 0.008067556733367382
[Epoch 15, Batch 200] loss: 0.012896368025212723
[Epoch 15, Batch 300] loss: 0.00605723704691627
[Epoch 15, Batch 400] loss: 0.007527418687814134
[Epoch 15, Batch 500] loss: 0.009625669443885272
[Epoch 15, Batch 600] loss: 0.0058802787551030635
[Epoch 15, Batch 700] loss: 0.010117221640157367
[Epoch 15, Batch 800] loss: 0.01196599885623982
[Epoch 15, Batch 900] loss: 0.01132771548650453
[Epoch 15, Batch 1000] loss: 0.01229298723206739
[Epoch 15, Batch 1100] loss: 0.01729039351781239
[Epoch 15, Batch 1200] loss: 0.015221758247753315
[Epoch 15, Batch 1300] loss: 0.013293456353876536
[Epoch 15, Batch 1400] loss: 0.006160797381016892
[Epoch 15, Batch 1500] loss: 0.009998384115733642
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0633
Validation Accuracy: 0.9835
Overfitting: 0.0633
[Epoch 16, Batch 100] loss: 0.010448839913019583
[Epoch 16, Batch 200] loss: 0.007499107576695679
[Epoch 16, Batch 300] loss: 0.007328414685803182
[Epoch 16, Batch 400] loss: 0.008728651324672683
[Epoch 16, Batch 500] loss: 0.0053066337840255075
[Epoch 16, Batch 600] loss: 0.00930713909026963
[Epoch 16, Batch 700] loss: 0.010576571889287152
[Epoch 16, Batch 800] loss: 0.009012711926097837
[Epoch 16, Batch 900] loss: 0.0062932515108695955
[Epoch 16, Batch 1000] loss: 0.011465319127837574
[Epoch 16, Batch 1100] loss: 0.011175643235840199
[Epoch 16, Batch 1200] loss: 0.012515386086752187
[Epoch 16, Batch 1300] loss: 0.01155601743132138
[Epoch 16, Batch 1400] loss: 0.012468182129432535
[Epoch 16, Batch 1500] loss: 0.012615838727651863
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9881
Overfitting: 0.0472
[Epoch 17, Batch 100] loss: 0.007773319232592257
[Epoch 17, Batch 200] loss: 0.0047286177316345854
[Epoch 17, Batch 300] loss: 0.0035031451343547817
[Epoch 17, Batch 400] loss: 0.006439172616137512
[Epoch 17, Batch 500] loss: 0.005379752343214932
[Epoch 17, Batch 600] loss: 0.011603794907709925
[Epoch 17, Batch 700] loss: 0.004734545981045812
[Epoch 17, Batch 800] loss: 0.004012762420406943
[Epoch 17, Batch 900] loss: 0.006138976378915686
[Epoch 17, Batch 1000] loss: 0.006992896083784217
[Epoch 17, Batch 1100] loss: 0.011146406984225905
[Epoch 17, Batch 1200] loss: 0.012737196888119797
[Epoch 17, Batch 1300] loss: 0.014094937785175716
[Epoch 17, Batch 1400] loss: 0.009244347992780604
[Epoch 17, Batch 1500] loss: 0.011538197918712285
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0588
Validation Accuracy: 0.9862
Overfitting: 0.0588
[I 2024-12-10 06:30:30,091] Trial 7 pruned. 

Selected Hyperparameters for Trial 9:
  l1: 128, l2: 128, lr: 0.00016867164929354415, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3031225752830506
[Epoch 1, Batch 200] loss: 2.3036018776893616
[Epoch 1, Batch 300] loss: 2.302799873352051
[Epoch 1, Batch 400] loss: 2.297539086341858
[Epoch 1, Batch 500] loss: 2.2984399962425233
[Epoch 1, Batch 600] loss: 2.2987168288230895
[Epoch 1, Batch 700] loss: 2.2928949999809265
[Epoch 1, Batch 800] loss: 2.2898487091064452
[Epoch 1, Batch 900] loss: 2.2900692415237427
[Epoch 1, Batch 1000] loss: 2.2853359150886536
[Epoch 1, Batch 1100] loss: 2.283514769077301
[Epoch 1, Batch 1200] loss: 2.2769594240188598
[Epoch 1, Batch 1300] loss: 2.275323140621185
[Epoch 1, Batch 1400] loss: 2.2700565099716186
[Epoch 1, Batch 1500] loss: 2.2607156920433042
[Epoch 1, Batch 1600] loss: 2.2558099174499513
[Epoch 1, Batch 1700] loss: 2.2473539185523985
[Epoch 1, Batch 1800] loss: 2.2361178302764895
[Epoch 1, Batch 1900] loss: 2.2171481609344483
[Epoch 1, Batch 2000] loss: 2.202508099079132
[Epoch 1, Batch 2100] loss: 2.1717275643348692
[Epoch 1, Batch 2200] loss: 2.1356702852249145
[Epoch 1, Batch 2300] loss: 2.076183387041092
[Epoch 1, Batch 2400] loss: 2.000374262332916
[Epoch 1, Batch 2500] loss: 1.8748431265354157
[Epoch 1, Batch 2600] loss: 1.6933882665634155
[Epoch 1, Batch 2700] loss: 1.4650428581237793
[Epoch 1, Batch 2800] loss: 1.1933773064613342
[Epoch 1, Batch 2900] loss: 0.9989566481113434
[Epoch 1, Batch 3000] loss: 0.8292726570367813
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.7557
Validation Accuracy: 0.7969
Overfitting: 0.7557
Best model saved at epoch 1 with validation loss: 0.7557
[Epoch 2, Batch 100] loss: 0.7397137746214867
[Epoch 2, Batch 200] loss: 0.6334033598005772
[Epoch 2, Batch 300] loss: 0.5882939052581787
[Epoch 2, Batch 400] loss: 0.5629895487427712
[Epoch 2, Batch 500] loss: 0.5472029857337475
[Epoch 2, Batch 600] loss: 0.516399949491024
[Epoch 2, Batch 700] loss: 0.44327550306916236
[Epoch 2, Batch 800] loss: 0.48104310169816017
[Epoch 2, Batch 900] loss: 0.43522496335208416
[Epoch 2, Batch 1000] loss: 0.43824749551713466
[Epoch 2, Batch 1100] loss: 0.4113059985637665
[Epoch 2, Batch 1200] loss: 0.3839287219941616
[Epoch 2, Batch 1300] loss: 0.39507399626076223
[Epoch 2, Batch 1400] loss: 0.3668786634504795
[Epoch 2, Batch 1500] loss: 0.34728951096534727
[Epoch 2, Batch 1600] loss: 0.3225858540087938
[Epoch 2, Batch 1700] loss: 0.36617416933178903
[Epoch 2, Batch 1800] loss: 0.33281052827835084
[Epoch 2, Batch 1900] loss: 0.35878012791275976
[Epoch 2, Batch 2000] loss: 0.36438974730670454
[Epoch 2, Batch 2100] loss: 0.3372139844298363
[Epoch 2, Batch 2200] loss: 0.36208996560424567
[Epoch 2, Batch 2300] loss: 0.30398566238582136
[Epoch 2, Batch 2400] loss: 0.29424922555685046
[Epoch 2, Batch 2500] loss: 0.3360704642161727
[Epoch 2, Batch 2600] loss: 0.26093712728470564
[Epoch 2, Batch 2700] loss: 0.2817684266343713
[Epoch 2, Batch 2800] loss: 0.2875529196858406
[Epoch 2, Batch 2900] loss: 0.3411223502457142
[Epoch 2, Batch 3000] loss: 0.26667926598340275
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2669
Validation Accuracy: 0.9199
Overfitting: 0.2669
Best model saved at epoch 2 with validation loss: 0.2669
[Epoch 3, Batch 100] loss: 0.3008742416277528
[Epoch 3, Batch 200] loss: 0.2529027473367751
[Epoch 3, Batch 300] loss: 0.3043664165958762
[Epoch 3, Batch 400] loss: 0.2666551917232573
[Epoch 3, Batch 500] loss: 0.24753760322928428
[Epoch 3, Batch 600] loss: 0.24731859996914862
[Epoch 3, Batch 700] loss: 0.27389808441512287
[Epoch 3, Batch 800] loss: 0.24325017552822828
[Epoch 3, Batch 900] loss: 0.23390376280993222
[Epoch 3, Batch 1000] loss: 0.24134943891316651
[Epoch 3, Batch 1100] loss: 0.2315640063583851
[Epoch 3, Batch 1200] loss: 0.2313041971437633
[Epoch 3, Batch 1300] loss: 0.21926543707028032
[Epoch 3, Batch 1400] loss: 0.2447098685801029
[Epoch 3, Batch 1500] loss: 0.21430009813979267
[Epoch 3, Batch 1600] loss: 0.2199047360382974
[Epoch 3, Batch 1700] loss: 0.23234985816292464
[Epoch 3, Batch 1800] loss: 0.22976201370358468
[Epoch 3, Batch 1900] loss: 0.23004968071356416
[Epoch 3, Batch 2000] loss: 0.23707215799950063
[Epoch 3, Batch 2100] loss: 0.26271467354148625
[Epoch 3, Batch 2200] loss: 0.2314808101952076
[Epoch 3, Batch 2300] loss: 0.26330423291772603
[Epoch 3, Batch 2400] loss: 0.22429954504594207
[Epoch 3, Batch 2500] loss: 0.20448054185137152
[Epoch 3, Batch 2600] loss: 0.17580170596018432
[Epoch 3, Batch 2700] loss: 0.2299114252720028
[Epoch 3, Batch 2800] loss: 0.17833174634724855
[Epoch 3, Batch 2900] loss: 0.21287359132431447
[Epoch 3, Batch 3000] loss: 0.1646265488024801
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1834
Validation Accuracy: 0.9434
Overfitting: 0.1834
Best model saved at epoch 3 with validation loss: 0.1834
[Epoch 4, Batch 100] loss: 0.19371232544071973
[Epoch 4, Batch 200] loss: 0.18983137229457497
[Epoch 4, Batch 300] loss: 0.17689721080474555
[Epoch 4, Batch 400] loss: 0.17736579705495387
[Epoch 4, Batch 500] loss: 0.20013002295512705
[Epoch 4, Batch 600] loss: 0.20140348881483078
[Epoch 4, Batch 700] loss: 0.20035599715076388
[Epoch 4, Batch 800] loss: 0.1791444760467857
[Epoch 4, Batch 900] loss: 0.16687997475266456
[Epoch 4, Batch 1000] loss: 0.1733667537383735
[Epoch 4, Batch 1100] loss: 0.15851014452055096
[Epoch 4, Batch 1200] loss: 0.1761195336468518
[Epoch 4, Batch 1300] loss: 0.19479489039629697
[Epoch 4, Batch 1400] loss: 0.17601626698859035
[Epoch 4, Batch 1500] loss: 0.18075598782859742
[Epoch 4, Batch 1600] loss: 0.18550110201351344
[Epoch 4, Batch 1700] loss: 0.1744458587002009
[Epoch 4, Batch 1800] loss: 0.16201306105591357
[Epoch 4, Batch 1900] loss: 0.1407386381365359
[Epoch 4, Batch 2000] loss: 0.1693346587382257
[Epoch 4, Batch 2100] loss: 0.16668573550879956
[Epoch 4, Batch 2200] loss: 0.1586448625102639
[Epoch 4, Batch 2300] loss: 0.17002847263589502
[Epoch 4, Batch 2400] loss: 0.17300324951298535
[Epoch 4, Batch 2500] loss: 0.18096348303370177
[Epoch 4, Batch 2600] loss: 0.18325103662908077
[Epoch 4, Batch 2700] loss: 0.14793570207431914
[Epoch 4, Batch 2800] loss: 0.1986421873793006
[Epoch 4, Batch 2900] loss: 0.14393922170624138
[Epoch 4, Batch 3000] loss: 0.16782940133940427
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1381
Validation Accuracy: 0.9573
Overfitting: 0.1381
Best model saved at epoch 4 with validation loss: 0.1381
[Epoch 5, Batch 100] loss: 0.12724466703366488
[Epoch 5, Batch 200] loss: 0.15210980508476496
[Epoch 5, Batch 300] loss: 0.16052482618950306
[Epoch 5, Batch 400] loss: 0.18312391804531217
[Epoch 5, Batch 500] loss: 0.14548617228865623
[Epoch 5, Batch 600] loss: 0.1619005602411926
[Epoch 5, Batch 700] loss: 0.14872222694568335
[Epoch 5, Batch 800] loss: 0.13625960793346167
[Epoch 5, Batch 900] loss: 0.15194902285933495
[Epoch 5, Batch 1000] loss: 0.1391711722780019
[Epoch 5, Batch 1100] loss: 0.16707250075414776
[Epoch 5, Batch 1200] loss: 0.15711558639770373
[Epoch 5, Batch 1300] loss: 0.13945607173256577
[Epoch 5, Batch 1400] loss: 0.15968158372677863
[Epoch 5, Batch 1500] loss: 0.16735999623779207
[Epoch 5, Batch 1600] loss: 0.12137635837309063
[Epoch 5, Batch 1700] loss: 0.13815403153188527
[Epoch 5, Batch 1800] loss: 0.1418748082825914
[Epoch 5, Batch 1900] loss: 0.14029577360954135
[Epoch 5, Batch 2000] loss: 0.15238957771100103
[Epoch 5, Batch 2100] loss: 0.12661548758856953
[Epoch 5, Batch 2200] loss: 0.1400684978812933
[Epoch 5, Batch 2300] loss: 0.11999972064979375
[Epoch 5, Batch 2400] loss: 0.13625150686129928
[Epoch 5, Batch 2500] loss: 0.11960569558665156
[Epoch 5, Batch 2600] loss: 0.1148697205632925
[Epoch 5, Batch 2700] loss: 0.1398495890875347
[Epoch 5, Batch 2800] loss: 0.15975375935900957
[Epoch 5, Batch 2900] loss: 0.12385908884927631
[Epoch 5, Batch 3000] loss: 0.14421938315033914
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1136
Validation Accuracy: 0.9648
Overfitting: 0.1136
Best model saved at epoch 5 with validation loss: 0.1136
[Epoch 6, Batch 100] loss: 0.13547233890742064
[Epoch 6, Batch 200] loss: 0.12464132262859494
[Epoch 6, Batch 300] loss: 0.10356550895608961
[Epoch 6, Batch 400] loss: 0.1379818708775565
[Epoch 6, Batch 500] loss: 0.145584030081518
[Epoch 6, Batch 600] loss: 0.16313552882056684
[Epoch 6, Batch 700] loss: 0.1289766312111169
[Epoch 6, Batch 800] loss: 0.13454924244433641
[Epoch 6, Batch 900] loss: 0.10996454953681678
[Epoch 6, Batch 1000] loss: 0.1144424721202813
[Epoch 6, Batch 1100] loss: 0.13532800671178846
[Epoch 6, Batch 1200] loss: 0.13993849590420723
[Epoch 6, Batch 1300] loss: 0.1300869171973318
[Epoch 6, Batch 1400] loss: 0.10643650201614946
[Epoch 6, Batch 1500] loss: 0.12478841078933328
[Epoch 6, Batch 1600] loss: 0.11624987987335772
[Epoch 6, Batch 1700] loss: 0.11553577790036798
[Epoch 6, Batch 1800] loss: 0.1286243512108922
[Epoch 6, Batch 1900] loss: 0.10991331664845347
[Epoch 6, Batch 2000] loss: 0.11610837339423596
[Epoch 6, Batch 2100] loss: 0.12040678185177967
[Epoch 6, Batch 2200] loss: 0.10832814908120782
[Epoch 6, Batch 2300] loss: 0.15629970066715032
[Epoch 6, Batch 2400] loss: 0.11569025361910462
[Epoch 6, Batch 2500] loss: 0.10808891766471788
[Epoch 6, Batch 2600] loss: 0.10994982800912112
[Epoch 6, Batch 2700] loss: 0.13343081544619054
[Epoch 6, Batch 2800] loss: 0.12731559151783586
[Epoch 6, Batch 2900] loss: 0.09721596607938408
[Epoch 6, Batch 3000] loss: 0.1020510815596208
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.1078
Validation Accuracy: 0.9676
Overfitting: 0.1078
Best model saved at epoch 6 with validation loss: 0.1078
[Epoch 7, Batch 100] loss: 0.14108433799119666
[Epoch 7, Batch 200] loss: 0.1246471555903554
[Epoch 7, Batch 300] loss: 0.1007635082071647
[Epoch 7, Batch 400] loss: 0.10809307138668373
[Epoch 7, Batch 500] loss: 0.11651958269998432
[Epoch 7, Batch 600] loss: 0.08173060983885079
[Epoch 7, Batch 700] loss: 0.11176863368134946
[Epoch 7, Batch 800] loss: 0.1033089567348361
[Epoch 7, Batch 900] loss: 0.12411990769673138
[Epoch 7, Batch 1000] loss: 0.10535625482909382
[Epoch 7, Batch 1100] loss: 0.12627582216635347
[Epoch 7, Batch 1200] loss: 0.09247855683090166
[Epoch 7, Batch 1300] loss: 0.1139756138715893
[Epoch 7, Batch 1400] loss: 0.10976933064870537
[Epoch 7, Batch 1500] loss: 0.09671813866123558
[Epoch 7, Batch 1600] loss: 0.09402464906452224
[Epoch 7, Batch 1700] loss: 0.1081539092422463
[Epoch 7, Batch 1800] loss: 0.09724054853082635
[Epoch 7, Batch 1900] loss: 0.08423009430756792
[Epoch 7, Batch 2000] loss: 0.11510833410313354
[Epoch 7, Batch 2100] loss: 0.11295468405820429
[Epoch 7, Batch 2200] loss: 0.10995098441606388
[Epoch 7, Batch 2300] loss: 0.09742619362426921
[Epoch 7, Batch 2400] loss: 0.10904453698312863
[Epoch 7, Batch 2500] loss: 0.11244418297428638
[Epoch 7, Batch 2600] loss: 0.12511786342598497
[Epoch 7, Batch 2700] loss: 0.08050376855768264
[Epoch 7, Batch 2800] loss: 0.09714169833343476
[Epoch 7, Batch 2900] loss: 0.11565590208163484
[Epoch 7, Batch 3000] loss: 0.12570861357729882
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0991
Validation Accuracy: 0.9700
Overfitting: 0.0991
Best model saved at epoch 7 with validation loss: 0.0991
[Epoch 8, Batch 100] loss: 0.08244641827302984
[Epoch 8, Batch 200] loss: 0.09529055753489957
[Epoch 8, Batch 300] loss: 0.10584180157398805
[Epoch 8, Batch 400] loss: 0.10825097212102264
[Epoch 8, Batch 500] loss: 0.10713925200048834
[Epoch 8, Batch 600] loss: 0.11685641190269962
[Epoch 8, Batch 700] loss: 0.08382571791065857
[Epoch 8, Batch 800] loss: 0.10084687126334757
[Epoch 8, Batch 900] loss: 0.10380279683507979
[Epoch 8, Batch 1000] loss: 0.12568617473822086
[Epoch 8, Batch 1100] loss: 0.08680023650638759
[Epoch 8, Batch 1200] loss: 0.08157823268324137
[Epoch 8, Batch 1300] loss: 0.08880961735034361
[Epoch 8, Batch 1400] loss: 0.09504271548241378
[Epoch 8, Batch 1500] loss: 0.10739644771325402
[Epoch 8, Batch 1600] loss: 0.11470121553400531
[Epoch 8, Batch 1700] loss: 0.11110376415774226
[Epoch 8, Batch 1800] loss: 0.07531960987718776
[Epoch 8, Batch 1900] loss: 0.09116475406102836
[Epoch 8, Batch 2000] loss: 0.07186850558966398
[Epoch 8, Batch 2100] loss: 0.09576829383382574
[Epoch 8, Batch 2200] loss: 0.11712360858684406
[Epoch 8, Batch 2300] loss: 0.1032287426001858
[Epoch 8, Batch 2400] loss: 0.10166852823458612
[Epoch 8, Batch 2500] loss: 0.09911734490422532
[Epoch 8, Batch 2600] loss: 0.09612321497872472
[Epoch 8, Batch 2700] loss: 0.10632376956753432
[Epoch 8, Batch 2800] loss: 0.07747371619101613
[Epoch 8, Batch 2900] loss: 0.08794000127818435
[Epoch 8, Batch 3000] loss: 0.08825319910887629
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0843
Validation Accuracy: 0.9736
Overfitting: 0.0843
Best model saved at epoch 8 with validation loss: 0.0843
[Epoch 9, Batch 100] loss: 0.0793450556427706
[Epoch 9, Batch 200] loss: 0.11349143785890192
[Epoch 9, Batch 300] loss: 0.0898241303744726
[Epoch 9, Batch 400] loss: 0.10216953038470819
[Epoch 9, Batch 500] loss: 0.08202710254583508
[Epoch 9, Batch 600] loss: 0.08810142988571897
[Epoch 9, Batch 700] loss: 0.09629649617359974
[Epoch 9, Batch 800] loss: 0.10751908332807943
[Epoch 9, Batch 900] loss: 0.07326916017453186
[Epoch 9, Batch 1000] loss: 0.09581317785894498
[Epoch 9, Batch 1100] loss: 0.07744829716160893
[Epoch 9, Batch 1200] loss: 0.08478361749788746
[Epoch 9, Batch 1300] loss: 0.10821511429385282
[Epoch 9, Batch 1400] loss: 0.07533222811995074
[Epoch 9, Batch 1500] loss: 0.0680928395409137
[Epoch 9, Batch 1600] loss: 0.09618079310050234
[Epoch 9, Batch 1700] loss: 0.08733152718516067
[Epoch 9, Batch 1800] loss: 0.09047606319887563
[Epoch 9, Batch 1900] loss: 0.0805692685872782
[Epoch 9, Batch 2000] loss: 0.09878250867594034
[Epoch 9, Batch 2100] loss: 0.07870504235848784
[Epoch 9, Batch 2200] loss: 0.08539604380261152
[Epoch 9, Batch 2300] loss: 0.08608517425367608
[Epoch 9, Batch 2400] loss: 0.08014266796410084
[Epoch 9, Batch 2500] loss: 0.07996637483127415
[Epoch 9, Batch 2600] loss: 0.10383538239053451
[Epoch 9, Batch 2700] loss: 0.08317152129486204
[Epoch 9, Batch 2800] loss: 0.09838201423408463
[Epoch 9, Batch 2900] loss: 0.07072649650741368
[Epoch 9, Batch 3000] loss: 0.07882150255376473
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0901
Validation Accuracy: 0.9719
Overfitting: 0.0901
[I 2024-12-10 06:32:51,843] Trial 8 pruned. 

Selected Hyperparameters for Trial 10:
  l1: 256, l2: 128, lr: 0.0026936379642822942, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2406936430931093
[Epoch 1, Batch 200] loss: 1.0025389513373375
[Epoch 1, Batch 300] loss: 0.43173383325338366
[Epoch 1, Batch 400] loss: 0.3147470982372761
[Epoch 1, Batch 500] loss: 0.22284129269421102
[Epoch 1, Batch 600] loss: 0.20350016996264458
[Epoch 1, Batch 700] loss: 0.1707310514524579
**STATS for Epoch 1** : 
Average training loss: 0.0116
Average validation loss: 0.1554
Validation Accuracy: 0.9513
Overfitting: 0.1438
Best model saved at epoch 1 with validation loss: 0.1554
[Epoch 2, Batch 100] loss: 0.14902575001120566
[Epoch 2, Batch 200] loss: 0.1268614633753896
[Epoch 2, Batch 300] loss: 0.13321800999343394
[Epoch 2, Batch 400] loss: 0.10097473300993443
[Epoch 2, Batch 500] loss: 0.12154199765995145
[Epoch 2, Batch 600] loss: 0.10998293050564825
[Epoch 2, Batch 700] loss: 0.10022241431288421
**STATS for Epoch 2** : 
Average training loss: 0.0077
Average validation loss: 0.0873
Validation Accuracy: 0.9722
Overfitting: 0.0796
Best model saved at epoch 2 with validation loss: 0.0873
[Epoch 3, Batch 100] loss: 0.08255932244472206
[Epoch 3, Batch 200] loss: 0.07632214501034468
[Epoch 3, Batch 300] loss: 0.08275971666909754
[Epoch 3, Batch 400] loss: 0.071128692724742
[Epoch 3, Batch 500] loss: 0.08349976257421077
[Epoch 3, Batch 600] loss: 0.07752832329366356
[Epoch 3, Batch 700] loss: 0.0760035228729248
**STATS for Epoch 3** : 
Average training loss: 0.0057
Average validation loss: 0.0791
Validation Accuracy: 0.9742
Overfitting: 0.0734
Best model saved at epoch 3 with validation loss: 0.0791
[Epoch 4, Batch 100] loss: 0.0682010498084128
[Epoch 4, Batch 200] loss: 0.06934359380975366
[Epoch 4, Batch 300] loss: 0.05798877361230552
[Epoch 4, Batch 400] loss: 0.06411686133593321
[Epoch 4, Batch 500] loss: 0.05520984607515857
[Epoch 4, Batch 600] loss: 0.06935260217636824
[Epoch 4, Batch 700] loss: 0.055319116669707
**STATS for Epoch 4** : 
Average training loss: 0.0046
Average validation loss: 0.0646
Validation Accuracy: 0.9793
Overfitting: 0.0600
Best model saved at epoch 4 with validation loss: 0.0646
[Epoch 5, Batch 100] loss: 0.051609142903471364
[Epoch 5, Batch 200] loss: 0.04966862830799073
[Epoch 5, Batch 300] loss: 0.05604383940575644
[Epoch 5, Batch 400] loss: 0.04820435342611745
[Epoch 5, Batch 500] loss: 0.05183427279349417
[Epoch 5, Batch 600] loss: 0.04723578495439142
[Epoch 5, Batch 700] loss: 0.05618162310682237
**STATS for Epoch 5** : 
Average training loss: 0.0036
Average validation loss: 0.0535
Validation Accuracy: 0.9833
Overfitting: 0.0499
Best model saved at epoch 5 with validation loss: 0.0535
[Epoch 6, Batch 100] loss: 0.04525972192175686
[Epoch 6, Batch 200] loss: 0.041670824375469234
[Epoch 6, Batch 300] loss: 0.04306665376760065
[Epoch 6, Batch 400] loss: 0.03914123316528276
[Epoch 6, Batch 500] loss: 0.05091066007735208
[Epoch 6, Batch 600] loss: 0.04064803136046976
[Epoch 6, Batch 700] loss: 0.036884857289260255
**STATS for Epoch 6** : 
Average training loss: 0.0031
Average validation loss: 0.0507
Validation Accuracy: 0.9842
Overfitting: 0.0476
Best model saved at epoch 6 with validation loss: 0.0507
[Epoch 7, Batch 100] loss: 0.03554872059612535
[Epoch 7, Batch 200] loss: 0.03443857399513945
[Epoch 7, Batch 300] loss: 0.038735089818947015
[Epoch 7, Batch 400] loss: 0.038117437004693784
[Epoch 7, Batch 500] loss: 0.03753714377293363
[Epoch 7, Batch 600] loss: 0.033308948549674824
[Epoch 7, Batch 700] loss: 0.03653377309907228
**STATS for Epoch 7** : 
Average training loss: 0.0026
Average validation loss: 0.0534
Validation Accuracy: 0.9838
Overfitting: 0.0508
[Epoch 8, Batch 100] loss: 0.03537098713219166
[Epoch 8, Batch 200] loss: 0.03434818064211868
[Epoch 8, Batch 300] loss: 0.028137942330213262
[Epoch 8, Batch 400] loss: 0.03331875283969566
[Epoch 8, Batch 500] loss: 0.03022183875320479
[Epoch 8, Batch 600] loss: 0.029314043949125335
[Epoch 8, Batch 700] loss: 0.035493292461615054
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0552
Validation Accuracy: 0.9822
Overfitting: 0.0528
[Epoch 9, Batch 100] loss: 0.02554292166722007
[Epoch 9, Batch 200] loss: 0.025535030079772696
[Epoch 9, Batch 300] loss: 0.029665643471525983
[Epoch 9, Batch 400] loss: 0.027623038612073287
[Epoch 9, Batch 500] loss: 0.03014661721070297
[Epoch 9, Batch 600] loss: 0.024988986995304004
[Epoch 9, Batch 700] loss: 0.035570249145384876
**STATS for Epoch 9** : 
Average training loss: 0.0021
Average validation loss: 0.0453
Validation Accuracy: 0.9865
Overfitting: 0.0432
Best model saved at epoch 9 with validation loss: 0.0453
[Epoch 10, Batch 100] loss: 0.033491010807920246
[Epoch 10, Batch 200] loss: 0.021383923434186727
[Epoch 10, Batch 300] loss: 0.025942749156383796
[Epoch 10, Batch 400] loss: 0.023263343495491428
[Epoch 10, Batch 500] loss: 0.023505008121719583
[Epoch 10, Batch 600] loss: 0.028128143136855216
[Epoch 10, Batch 700] loss: 0.025568799209140708
**STATS for Epoch 10** : 
Average training loss: 0.0015
Average validation loss: 0.0414
Validation Accuracy: 0.9875
Overfitting: 0.0399
Best model saved at epoch 10 with validation loss: 0.0414
[Epoch 11, Batch 100] loss: 0.012675493308342993
[Epoch 11, Batch 200] loss: 0.016605450279603248
[Epoch 11, Batch 300] loss: 0.02390559918654617
[Epoch 11, Batch 400] loss: 0.027852066201157866
[Epoch 11, Batch 500] loss: 0.022889736208016983
[Epoch 11, Batch 600] loss: 0.023264128692389932
[Epoch 11, Batch 700] loss: 0.02449072499293834
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0463
Validation Accuracy: 0.9862
Overfitting: 0.0446
[Epoch 12, Batch 100] loss: 0.014022124765324407
[Epoch 12, Batch 200] loss: 0.017327686847711448
[Epoch 12, Batch 300] loss: 0.017573088540229945
[Epoch 12, Batch 400] loss: 0.022067194088594987
[Epoch 12, Batch 500] loss: 0.018081631885725074
[Epoch 12, Batch 600] loss: 0.020513345460640268
[Epoch 12, Batch 700] loss: 0.023904631406185217
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0417
Validation Accuracy: 0.9887
Overfitting: 0.0407
[Epoch 13, Batch 100] loss: 0.015825904702069238
[Epoch 13, Batch 200] loss: 0.01199196307134116
[Epoch 13, Batch 300] loss: 0.01727742279326776
[Epoch 13, Batch 400] loss: 0.01726746472530067
[Epoch 13, Batch 500] loss: 0.016564235283149174
[Epoch 13, Batch 600] loss: 0.021609440704633016
[Epoch 13, Batch 700] loss: 0.023848284949781372
**STATS for Epoch 13** : 
Average training loss: 0.0012
Average validation loss: 0.0398
Validation Accuracy: 0.9882
Overfitting: 0.0386
Best model saved at epoch 13 with validation loss: 0.0398
[Epoch 14, Batch 100] loss: 0.0158849063917296
[Epoch 14, Batch 200] loss: 0.011547531049000099
[Epoch 14, Batch 300] loss: 0.014621163991105277
[Epoch 14, Batch 400] loss: 0.016446228452550712
[Epoch 14, Batch 500] loss: 0.020919362452987117
[Epoch 14, Batch 600] loss: 0.016200541546859314
[Epoch 14, Batch 700] loss: 0.01615249609807506
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0435
Validation Accuracy: 0.9880
Overfitting: 0.0426
[Epoch 15, Batch 100] loss: 0.012686490227060858
[Epoch 15, Batch 200] loss: 0.012153516596808913
[Epoch 15, Batch 300] loss: 0.011379411764646647
[Epoch 15, Batch 400] loss: 0.012342210413771681
[Epoch 15, Batch 500] loss: 0.014942162674851716
[Epoch 15, Batch 600] loss: 0.020196831086359453
[Epoch 15, Batch 700] loss: 0.016997829010360874
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0398
Validation Accuracy: 0.9882
Overfitting: 0.0391
[Epoch 16, Batch 100] loss: 0.010075590152555379
[Epoch 16, Batch 200] loss: 0.01223252998534008
[Epoch 16, Batch 300] loss: 0.014133922742912546
[Epoch 16, Batch 400] loss: 0.01151086595175002
[Epoch 16, Batch 500] loss: 0.011202406121301465
[Epoch 16, Batch 600] loss: 0.01362068774018553
[Epoch 16, Batch 700] loss: 0.013147250440888457
**STATS for Epoch 16** : 
Average training loss: 0.0011
Average validation loss: 0.0453
Validation Accuracy: 0.9885
Overfitting: 0.0442
[Epoch 17, Batch 100] loss: 0.010023136001400416
[Epoch 17, Batch 200] loss: 0.012334575554123149
[Epoch 17, Batch 300] loss: 0.010432138684263919
[Epoch 17, Batch 400] loss: 0.008799850449286169
[Epoch 17, Batch 500] loss: 0.009223851871975058
[Epoch 17, Batch 600] loss: 0.011308547817316139
[Epoch 17, Batch 700] loss: 0.009246672137596761
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0416
Validation Accuracy: 0.9890
Overfitting: 0.0410
[Epoch 18, Batch 100] loss: 0.006846316971714259
[Epoch 18, Batch 200] loss: 0.006669179733435158
[Epoch 18, Batch 300] loss: 0.010049661261873552
[Epoch 18, Batch 400] loss: 0.008190754825554904
[Epoch 18, Batch 500] loss: 0.013600453158578602
[Epoch 18, Batch 600] loss: 0.011073105176219542
[Epoch 18, Batch 700] loss: 0.008564002946623078
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0478
Validation Accuracy: 0.9871
Overfitting: 0.0470
[Epoch 19, Batch 100] loss: 0.00654787281571771
[Epoch 19, Batch 200] loss: 0.00912559841395705
[Epoch 19, Batch 300] loss: 0.01172416528366739
[Epoch 19, Batch 400] loss: 0.009759662346041295
[Epoch 19, Batch 500] loss: 0.009225794237318041
[Epoch 19, Batch 600] loss: 0.00838933531609655
[Epoch 19, Batch 700] loss: 0.0052511014371702915
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0418
Validation Accuracy: 0.9901
Overfitting: 0.0414
[Epoch 20, Batch 100] loss: 0.006718503108641016
[Epoch 20, Batch 200] loss: 0.0056641586940531854
[Epoch 20, Batch 300] loss: 0.0063142969278123925
[Epoch 20, Batch 400] loss: 0.005938452899645199
[Epoch 20, Batch 500] loss: 0.007515890752292762
[Epoch 20, Batch 600] loss: 0.009539353860163828
[Epoch 20, Batch 700] loss: 0.008106641492486234
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0443
Validation Accuracy: 0.9890
Overfitting: 0.0440
[Epoch 21, Batch 100] loss: 0.005991917023420683
[Epoch 21, Batch 200] loss: 0.0042255423347342
[Epoch 21, Batch 300] loss: 0.006034533111997007
[Epoch 21, Batch 400] loss: 0.005145491496441537
[Epoch 21, Batch 500] loss: 0.006950561326739262
[Epoch 21, Batch 600] loss: 0.013122171040304238
[Epoch 21, Batch 700] loss: 0.010245712039468344
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0436
Validation Accuracy: 0.9890
Overfitting: 0.0432
[Epoch 22, Batch 100] loss: 0.005494743962626672
[Epoch 22, Batch 200] loss: 0.007532388512263424
[Epoch 22, Batch 300] loss: 0.007031672727316618
[Epoch 22, Batch 400] loss: 0.004807046554378758
[Epoch 22, Batch 500] loss: 0.004005196038597205
[Epoch 22, Batch 600] loss: 0.004781260463387298
[Epoch 22, Batch 700] loss: 0.004207289647420112
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0484
Validation Accuracy: 0.9875
Overfitting: 0.0479
[Epoch 23, Batch 100] loss: 0.003082935220991203
[Epoch 23, Batch 200] loss: 0.0029300678961863016
[Epoch 23, Batch 300] loss: 0.005261659666357446
[Epoch 23, Batch 400] loss: 0.006142726628695527
[Epoch 23, Batch 500] loss: 0.007586412501368613
[Epoch 23, Batch 600] loss: 0.006100883266190067
[Epoch 23, Batch 700] loss: 0.005992480643362797
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0443
Validation Accuracy: 0.9887
Overfitting: 0.0438
[Epoch 24, Batch 100] loss: 0.002582935977698071
[Epoch 24, Batch 200] loss: 0.0037964511102472898
[Epoch 24, Batch 300] loss: 0.0031593138182506664
[Epoch 24, Batch 400] loss: 0.005806182814776548
[Epoch 24, Batch 500] loss: 0.00952682155668299
[Epoch 24, Batch 600] loss: 0.004541460383734375
[Epoch 24, Batch 700] loss: 0.005867839103284495
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0443
Validation Accuracy: 0.9892
Overfitting: 0.0441
Fold 1 validation loss: 0.0443
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.252469563484192
[Epoch 1, Batch 200] loss: 1.138411672115326
[Epoch 1, Batch 300] loss: 0.4237735158205032
[Epoch 1, Batch 400] loss: 0.3376215970516205
[Epoch 1, Batch 500] loss: 0.2537182554602623
[Epoch 1, Batch 600] loss: 0.21012787867337465
[Epoch 1, Batch 700] loss: 0.19059873141348363
**STATS for Epoch 1** : 
Average training loss: 0.0120
Average validation loss: 0.1754
Validation Accuracy: 0.9453
Overfitting: 0.1634
Best model saved at epoch 1 with validation loss: 0.1754
[Epoch 2, Batch 100] loss: 0.16108504872769117
[Epoch 2, Batch 200] loss: 0.13310067303478718
[Epoch 2, Batch 300] loss: 0.1331017454713583
[Epoch 2, Batch 400] loss: 0.10403091518208385
[Epoch 2, Batch 500] loss: 0.11678449319675564
[Epoch 2, Batch 600] loss: 0.11281355069950223
[Epoch 2, Batch 700] loss: 0.09641663428395987
**STATS for Epoch 2** : 
Average training loss: 0.0070
Average validation loss: 0.1148
Validation Accuracy: 0.9646
Overfitting: 0.1077
Best model saved at epoch 2 with validation loss: 0.1148
[Epoch 3, Batch 100] loss: 0.08426854686811566
[Epoch 3, Batch 200] loss: 0.08012119208462537
[Epoch 3, Batch 300] loss: 0.0849303377699107
[Epoch 3, Batch 400] loss: 0.08644173284061253
[Epoch 3, Batch 500] loss: 0.0801541005494073
[Epoch 3, Batch 600] loss: 0.08498054860159755
[Epoch 3, Batch 700] loss: 0.07271908454131334
**STATS for Epoch 3** : 
Average training loss: 0.0047
Average validation loss: 0.0895
Validation Accuracy: 0.9740
Overfitting: 0.0847
Best model saved at epoch 3 with validation loss: 0.0895
[Epoch 4, Batch 100] loss: 0.06629818660672754
[Epoch 4, Batch 200] loss: 0.0716046852292493
[Epoch 4, Batch 300] loss: 0.055958609709050505
[Epoch 4, Batch 400] loss: 0.0645547086931765
[Epoch 4, Batch 500] loss: 0.06479929402004928
[Epoch 4, Batch 600] loss: 0.07229192085564136
[Epoch 4, Batch 700] loss: 0.06355141176376491
**STATS for Epoch 4** : 
Average training loss: 0.0043
Average validation loss: 0.0722
Validation Accuracy: 0.9767
Overfitting: 0.0679
Best model saved at epoch 4 with validation loss: 0.0722
[Epoch 5, Batch 100] loss: 0.04196943074930459
[Epoch 5, Batch 200] loss: 0.06033684291876853
[Epoch 5, Batch 300] loss: 0.049406055849976836
[Epoch 5, Batch 400] loss: 0.058166372082196174
[Epoch 5, Batch 500] loss: 0.049837654647417365
[Epoch 5, Batch 600] loss: 0.05287138976622373
[Epoch 5, Batch 700] loss: 0.060233184744138274
**STATS for Epoch 5** : 
Average training loss: 0.0033
Average validation loss: 0.0651
Validation Accuracy: 0.9797
Overfitting: 0.0618
Best model saved at epoch 5 with validation loss: 0.0651
[Epoch 6, Batch 100] loss: 0.04435783497989178
[Epoch 6, Batch 200] loss: 0.04485352242831141
[Epoch 6, Batch 300] loss: 0.03671013040468097
[Epoch 6, Batch 400] loss: 0.04684845931362361
[Epoch 6, Batch 500] loss: 0.039503121896414084
[Epoch 6, Batch 600] loss: 0.04152132975868881
[Epoch 6, Batch 700] loss: 0.04756640203529969
**STATS for Epoch 6** : 
Average training loss: 0.0037
Average validation loss: 0.0665
Validation Accuracy: 0.9794
Overfitting: 0.0628
[Epoch 7, Batch 100] loss: 0.034697665573330594
[Epoch 7, Batch 200] loss: 0.03397401274181902
[Epoch 7, Batch 300] loss: 0.03258608196629211
[Epoch 7, Batch 400] loss: 0.04782423614291474
[Epoch 7, Batch 500] loss: 0.04064102233503945
[Epoch 7, Batch 600] loss: 0.0357409131876193
[Epoch 7, Batch 700] loss: 0.039105501046869905
**STATS for Epoch 7** : 
Average training loss: 0.0023
Average validation loss: 0.0603
Validation Accuracy: 0.9813
Overfitting: 0.0580
Best model saved at epoch 7 with validation loss: 0.0603
[Epoch 8, Batch 100] loss: 0.02855413212237181
[Epoch 8, Batch 200] loss: 0.03517836235929281
[Epoch 8, Batch 300] loss: 0.032572451571468264
[Epoch 8, Batch 400] loss: 0.03669474732247181
[Epoch 8, Batch 500] loss: 0.0365614056319464
[Epoch 8, Batch 600] loss: 0.032153322068043055
[Epoch 8, Batch 700] loss: 0.031292386391432954
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0576
Validation Accuracy: 0.9842
Overfitting: 0.0552
Best model saved at epoch 8 with validation loss: 0.0576
[Epoch 9, Batch 100] loss: 0.0266138141148258
[Epoch 9, Batch 200] loss: 0.028394040464190765
[Epoch 9, Batch 300] loss: 0.02931735338876024
[Epoch 9, Batch 400] loss: 0.03745575007051229
[Epoch 9, Batch 500] loss: 0.027253093987237662
[Epoch 9, Batch 600] loss: 0.029897693022503516
[Epoch 9, Batch 700] loss: 0.026853166843065993
**STATS for Epoch 9** : 
Average training loss: 0.0021
Average validation loss: 0.0564
Validation Accuracy: 0.9831
Overfitting: 0.0542
Best model saved at epoch 9 with validation loss: 0.0564
[Epoch 10, Batch 100] loss: 0.025687992761959322
[Epoch 10, Batch 200] loss: 0.024279549931525254
[Epoch 10, Batch 300] loss: 0.030619713172200136
[Epoch 10, Batch 400] loss: 0.02418596589472145
[Epoch 10, Batch 500] loss: 0.02671736317628529
[Epoch 10, Batch 600] loss: 0.021504125100327655
[Epoch 10, Batch 700] loss: 0.023725136579596438
**STATS for Epoch 10** : 
Average training loss: 0.0020
Average validation loss: 0.0678
Validation Accuracy: 0.9799
Overfitting: 0.0657
[Epoch 11, Batch 100] loss: 0.018658570178085938
[Epoch 11, Batch 200] loss: 0.022843830882629847
[Epoch 11, Batch 300] loss: 0.02733808274875628
[Epoch 11, Batch 400] loss: 0.023048952437820843
[Epoch 11, Batch 500] loss: 0.02179753119125962
[Epoch 11, Batch 600] loss: 0.022895632936852053
[Epoch 11, Batch 700] loss: 0.02024620581767522
**STATS for Epoch 11** : 
Average training loss: 0.0015
Average validation loss: 0.0522
Validation Accuracy: 0.9848
Overfitting: 0.0507
Best model saved at epoch 11 with validation loss: 0.0522
[Epoch 12, Batch 100] loss: 0.01681250497989822
[Epoch 12, Batch 200] loss: 0.02058711168821901
[Epoch 12, Batch 300] loss: 0.01909471428312827
[Epoch 12, Batch 400] loss: 0.019290190741012337
[Epoch 12, Batch 500] loss: 0.021140076171723195
[Epoch 12, Batch 600] loss: 0.023043755308026447
[Epoch 12, Batch 700] loss: 0.020745930434786716
**STATS for Epoch 12** : 
Average training loss: 0.0017
Average validation loss: 0.0657
Validation Accuracy: 0.9810
Overfitting: 0.0640
[Epoch 13, Batch 100] loss: 0.019075064889038915
[Epoch 13, Batch 200] loss: 0.014668968134501484
[Epoch 13, Batch 300] loss: 0.019004295057384296
[Epoch 13, Batch 400] loss: 0.013192203132639406
[Epoch 13, Batch 500] loss: 0.01639341549249366
[Epoch 13, Batch 600] loss: 0.019369128238467967
[Epoch 13, Batch 700] loss: 0.01766076908854302
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0572
Validation Accuracy: 0.9850
Overfitting: 0.0558
[Epoch 14, Batch 100] loss: 0.014212273801967967
[Epoch 14, Batch 200] loss: 0.020297460339497773
[Epoch 14, Batch 300] loss: 0.014019720956566744
[Epoch 14, Batch 400] loss: 0.013097619030741043
[Epoch 14, Batch 500] loss: 0.012531788976193638
[Epoch 14, Batch 600] loss: 0.01818897491219104
[Epoch 14, Batch 700] loss: 0.01830469958105823
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0503
Validation Accuracy: 0.9858
Overfitting: 0.0495
Best model saved at epoch 14 with validation loss: 0.0503
[Epoch 15, Batch 100] loss: 0.011765624722320353
[Epoch 15, Batch 200] loss: 0.015029679367726203
[Epoch 15, Batch 300] loss: 0.012180005062255077
[Epoch 15, Batch 400] loss: 0.01567001628354774
[Epoch 15, Batch 500] loss: 0.01383731229492696
[Epoch 15, Batch 600] loss: 0.015675458124896978
[Epoch 15, Batch 700] loss: 0.00992490588731016
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0530
Validation Accuracy: 0.9858
Overfitting: 0.0521
[Epoch 16, Batch 100] loss: 0.007677410677461012
[Epoch 16, Batch 200] loss: 0.010594775351055432
[Epoch 16, Batch 300] loss: 0.012388900159858168
[Epoch 16, Batch 400] loss: 0.011474425795022399
[Epoch 16, Batch 500] loss: 0.014513507213559934
[Epoch 16, Batch 600] loss: 0.011349677005782724
[Epoch 16, Batch 700] loss: 0.013670263138919836
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0482
Validation Accuracy: 0.9866
Overfitting: 0.0475
Best model saved at epoch 16 with validation loss: 0.0482
[Epoch 17, Batch 100] loss: 0.005766108452517074
[Epoch 17, Batch 200] loss: 0.009896657934586984
[Epoch 17, Batch 300] loss: 0.013730910134327132
[Epoch 17, Batch 400] loss: 0.012085167232726235
[Epoch 17, Batch 500] loss: 0.010863482851855224
[Epoch 17, Batch 600] loss: 0.007535877246118617
[Epoch 17, Batch 700] loss: 0.016610868486895924
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0507
Validation Accuracy: 0.9865
Overfitting: 0.0503
[Epoch 18, Batch 100] loss: 0.008950475158926566
[Epoch 18, Batch 200] loss: 0.007844697942782659
[Epoch 18, Batch 300] loss: 0.010588254947506356
[Epoch 18, Batch 400] loss: 0.012836922710193903
[Epoch 18, Batch 500] loss: 0.009831968594153296
[Epoch 18, Batch 600] loss: 0.011012900965797599
[Epoch 18, Batch 700] loss: 0.008060081912699388
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0501
Validation Accuracy: 0.9860
Overfitting: 0.0497
[Epoch 19, Batch 100] loss: 0.005623256194012356
[Epoch 19, Batch 200] loss: 0.004419561015638464
[Epoch 19, Batch 300] loss: 0.0057188931771815985
[Epoch 19, Batch 400] loss: 0.007962692132932716
[Epoch 19, Batch 500] loss: 0.009487003162430483
[Epoch 19, Batch 600] loss: 0.011802385655537364
[Epoch 19, Batch 700] loss: 0.012537664624396712
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0540
Validation Accuracy: 0.9866
Overfitting: 0.0532
[Epoch 20, Batch 100] loss: 0.008498765496333362
[Epoch 20, Batch 200] loss: 0.00397846479958389
[Epoch 20, Batch 300] loss: 0.007326953656920523
[Epoch 20, Batch 400] loss: 0.004670881128658948
[Epoch 20, Batch 500] loss: 0.003716893457094557
[Epoch 20, Batch 600] loss: 0.006923765769170131
[Epoch 20, Batch 700] loss: 0.00638863722615497
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0590
Validation Accuracy: 0.9847
Overfitting: 0.0580
[Epoch 21, Batch 100] loss: 0.008124716838501626
[Epoch 21, Batch 200] loss: 0.00801263550099975
[Epoch 21, Batch 300] loss: 0.009379481559299165
[Epoch 21, Batch 400] loss: 0.006937311190267792
[Epoch 21, Batch 500] loss: 0.005413945501932176
[Epoch 21, Batch 600] loss: 0.006044780180309317
[Epoch 21, Batch 700] loss: 0.005148345422967395
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0647
Validation Accuracy: 0.9851
Overfitting: 0.0645
[Epoch 22, Batch 100] loss: 0.004870579554299184
[Epoch 22, Batch 200] loss: 0.002600521958675017
[Epoch 22, Batch 300] loss: 0.009454516318637616
[Epoch 22, Batch 400] loss: 0.00649532498595363
[Epoch 22, Batch 500] loss: 0.005836942666855975
[Epoch 22, Batch 600] loss: 0.006326531694285222
[Epoch 22, Batch 700] loss: 0.005780359412510734
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0573
Validation Accuracy: 0.9862
Overfitting: 0.0569
[Epoch 23, Batch 100] loss: 0.0071084427846835755
[Epoch 23, Batch 200] loss: 0.009916021105236723
[Epoch 23, Batch 300] loss: 0.007692847009966499
[Epoch 23, Batch 400] loss: 0.004268535286555562
[Epoch 23, Batch 500] loss: 0.004703807440491801
[Epoch 23, Batch 600] loss: 0.004458209837193863
[Epoch 23, Batch 700] loss: 0.004927122225271887
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0559
Validation Accuracy: 0.9866
Overfitting: 0.0556
[Epoch 24, Batch 100] loss: 0.0027341054804310263
[Epoch 24, Batch 200] loss: 0.006770054618455106
[Epoch 24, Batch 300] loss: 0.003962063149083405
[Epoch 24, Batch 400] loss: 0.0024022779529332184
[Epoch 24, Batch 500] loss: 0.002420499494910473
[Epoch 24, Batch 600] loss: 0.008038129955493786
[Epoch 24, Batch 700] loss: 0.005352743930307042
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0609
Validation Accuracy: 0.9848
Overfitting: 0.0604
Fold 2 validation loss: 0.0609
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.263486588001251
[Epoch 1, Batch 200] loss: 1.3506725952029228
[Epoch 1, Batch 300] loss: 0.4749011181294918
[Epoch 1, Batch 400] loss: 0.32497386902570724
[Epoch 1, Batch 500] loss: 0.2806700274348259
[Epoch 1, Batch 600] loss: 0.24517113499343396
[Epoch 1, Batch 700] loss: 0.21439540781080724
**STATS for Epoch 1** : 
Average training loss: 0.0112
Average validation loss: 0.1673
Validation Accuracy: 0.9505
Overfitting: 0.1561
Best model saved at epoch 1 with validation loss: 0.1673
[Epoch 2, Batch 100] loss: 0.16408915854990483
[Epoch 2, Batch 200] loss: 0.14466926980763672
[Epoch 2, Batch 300] loss: 0.13591327514499427
[Epoch 2, Batch 400] loss: 0.13053997922688723
[Epoch 2, Batch 500] loss: 0.12294774133712054
[Epoch 2, Batch 600] loss: 0.10906490611843765
[Epoch 2, Batch 700] loss: 0.10270635831169785
**STATS for Epoch 2** : 
Average training loss: 0.0058
Average validation loss: 0.1113
Validation Accuracy: 0.9675
Overfitting: 0.1054
Best model saved at epoch 2 with validation loss: 0.1113
[Epoch 3, Batch 100] loss: 0.0944090420473367
[Epoch 3, Batch 200] loss: 0.09035443646833301
[Epoch 3, Batch 300] loss: 0.07646805702708662
[Epoch 3, Batch 400] loss: 0.08929706063587219
[Epoch 3, Batch 500] loss: 0.08533238939940929
[Epoch 3, Batch 600] loss: 0.07736057755537332
[Epoch 3, Batch 700] loss: 0.08153366108424961
**STATS for Epoch 3** : 
Average training loss: 0.0050
Average validation loss: 0.0949
Validation Accuracy: 0.9727
Overfitting: 0.0899
Best model saved at epoch 3 with validation loss: 0.0949
[Epoch 4, Batch 100] loss: 0.0751830794615671
[Epoch 4, Batch 200] loss: 0.0690151781309396
[Epoch 4, Batch 300] loss: 0.06013962209224701
[Epoch 4, Batch 400] loss: 0.07156213201582431
[Epoch 4, Batch 500] loss: 0.06888087172061205
[Epoch 4, Batch 600] loss: 0.06091015040874481
[Epoch 4, Batch 700] loss: 0.05877120472025126
**STATS for Epoch 4** : 
Average training loss: 0.0048
Average validation loss: 0.0642
Validation Accuracy: 0.9810
Overfitting: 0.0594
Best model saved at epoch 4 with validation loss: 0.0642
[Epoch 5, Batch 100] loss: 0.05065725089982152
[Epoch 5, Batch 200] loss: 0.049134379043243824
[Epoch 5, Batch 300] loss: 0.06269279594998807
[Epoch 5, Batch 400] loss: 0.04719409954734147
[Epoch 5, Batch 500] loss: 0.053123018476180735
[Epoch 5, Batch 600] loss: 0.053061818797141315
[Epoch 5, Batch 700] loss: 0.062223691078834235
**STATS for Epoch 5** : 
Average training loss: 0.0036
Average validation loss: 0.0597
Validation Accuracy: 0.9825
Overfitting: 0.0561
Best model saved at epoch 5 with validation loss: 0.0597
[Epoch 6, Batch 100] loss: 0.04160958142485469
[Epoch 6, Batch 200] loss: 0.034064469984732566
[Epoch 6, Batch 300] loss: 0.04894191194558516
[Epoch 6, Batch 400] loss: 0.050368123752996326
[Epoch 6, Batch 500] loss: 0.04792710871435702
[Epoch 6, Batch 600] loss: 0.05311658849008381
[Epoch 6, Batch 700] loss: 0.05041896835900843
**STATS for Epoch 6** : 
Average training loss: 0.0033
Average validation loss: 0.0599
Validation Accuracy: 0.9821
Overfitting: 0.0566
[Epoch 7, Batch 100] loss: 0.03984986663097516
[Epoch 7, Batch 200] loss: 0.03415734420414083
[Epoch 7, Batch 300] loss: 0.03991035676328465
[Epoch 7, Batch 400] loss: 0.042418520508799705
[Epoch 7, Batch 500] loss: 0.04539456214057282
[Epoch 7, Batch 600] loss: 0.0386530507565476
[Epoch 7, Batch 700] loss: 0.035269874653313306
**STATS for Epoch 7** : 
Average training loss: 0.0026
Average validation loss: 0.0558
Validation Accuracy: 0.9838
Overfitting: 0.0531
Best model saved at epoch 7 with validation loss: 0.0558
[Epoch 8, Batch 100] loss: 0.02906449347385205
[Epoch 8, Batch 200] loss: 0.036049336490686985
[Epoch 8, Batch 300] loss: 0.035580834737047554
[Epoch 8, Batch 400] loss: 0.036643759907456115
[Epoch 8, Batch 500] loss: 0.033840202146675435
[Epoch 8, Batch 600] loss: 0.034075833573006094
[Epoch 8, Batch 700] loss: 0.03677171053481288
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0563
Validation Accuracy: 0.9828
Overfitting: 0.0540
[Epoch 9, Batch 100] loss: 0.027145790979266168
[Epoch 9, Batch 200] loss: 0.029798453461844475
[Epoch 9, Batch 300] loss: 0.031285988946910946
[Epoch 9, Batch 400] loss: 0.03268491366761737
[Epoch 9, Batch 500] loss: 0.03142096715630032
[Epoch 9, Batch 600] loss: 0.028372108828043564
[Epoch 9, Batch 700] loss: 0.035587769662961365
**STATS for Epoch 9** : 
Average training loss: 0.0023
Average validation loss: 0.0476
Validation Accuracy: 0.9854
Overfitting: 0.0453
Best model saved at epoch 9 with validation loss: 0.0476
[Epoch 10, Batch 100] loss: 0.02443625928135589
[Epoch 10, Batch 200] loss: 0.024968418007483707
[Epoch 10, Batch 300] loss: 0.03254293841426261
[Epoch 10, Batch 400] loss: 0.02341320517065469
[Epoch 10, Batch 500] loss: 0.029351276652887462
[Epoch 10, Batch 600] loss: 0.029243450324283913
[Epoch 10, Batch 700] loss: 0.025744301202939822
**STATS for Epoch 10** : 
Average training loss: 0.0021
Average validation loss: 0.0523
Validation Accuracy: 0.9841
Overfitting: 0.0502
[Epoch 11, Batch 100] loss: 0.021144090608577245
[Epoch 11, Batch 200] loss: 0.020741889479686505
[Epoch 11, Batch 300] loss: 0.025176014482276514
[Epoch 11, Batch 400] loss: 0.017313865413307213
[Epoch 11, Batch 500] loss: 0.024134148795856163
[Epoch 11, Batch 600] loss: 0.02940795761969639
[Epoch 11, Batch 700] loss: 0.026592696804436856
**STATS for Epoch 11** : 
Average training loss: 0.0014
Average validation loss: 0.0467
Validation Accuracy: 0.9862
Overfitting: 0.0453
Best model saved at epoch 11 with validation loss: 0.0467
[Epoch 12, Batch 100] loss: 0.02320287742302753
[Epoch 12, Batch 200] loss: 0.017019942556507885
[Epoch 12, Batch 300] loss: 0.022373484226409345
[Epoch 12, Batch 400] loss: 0.023780963183380664
[Epoch 12, Batch 500] loss: 0.017851200972218068
[Epoch 12, Batch 600] loss: 0.019061548869649413
[Epoch 12, Batch 700] loss: 0.023588857723225373
**STATS for Epoch 12** : 
Average training loss: 0.0020
Average validation loss: 0.0446
Validation Accuracy: 0.9877
Overfitting: 0.0426
Best model saved at epoch 12 with validation loss: 0.0446
[Epoch 13, Batch 100] loss: 0.016865840365644546
[Epoch 13, Batch 200] loss: 0.02013845119974576
[Epoch 13, Batch 300] loss: 0.018625770943181123
[Epoch 13, Batch 400] loss: 0.020946540965815073
[Epoch 13, Batch 500] loss: 0.014998245168244466
[Epoch 13, Batch 600] loss: 0.020143846856663004
[Epoch 13, Batch 700] loss: 0.021570061855018138
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0438
Validation Accuracy: 0.9872
Overfitting: 0.0424
Best model saved at epoch 13 with validation loss: 0.0438
[Epoch 14, Batch 100] loss: 0.014402003585128114
[Epoch 14, Batch 200] loss: 0.017919394776108676
[Epoch 14, Batch 300] loss: 0.01947412594628986
[Epoch 14, Batch 400] loss: 0.022660559369251133
[Epoch 14, Batch 500] loss: 0.01678680716897361
[Epoch 14, Batch 600] loss: 0.01743317048094468
[Epoch 14, Batch 700] loss: 0.014842918647336773
**STATS for Epoch 14** : 
Average training loss: 0.0011
Average validation loss: 0.0429
Validation Accuracy: 0.9887
Overfitting: 0.0419
Best model saved at epoch 14 with validation loss: 0.0429
[Epoch 15, Batch 100] loss: 0.011785480349644786
[Epoch 15, Batch 200] loss: 0.017575220132130198
[Epoch 15, Batch 300] loss: 0.014999752549338155
[Epoch 15, Batch 400] loss: 0.018799801933637353
[Epoch 15, Batch 500] loss: 0.012131213016982657
[Epoch 15, Batch 600] loss: 0.01734113177022664
[Epoch 15, Batch 700] loss: 0.0158971067587845
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0496
Validation Accuracy: 0.9865
Overfitting: 0.0486
[Epoch 16, Batch 100] loss: 0.01410459843245917
[Epoch 16, Batch 200] loss: 0.013738382390583866
[Epoch 16, Batch 300] loss: 0.013026639653398888
[Epoch 16, Batch 400] loss: 0.010316499970358564
[Epoch 16, Batch 500] loss: 0.01508527259735274
[Epoch 16, Batch 600] loss: 0.012328756680508377
[Epoch 16, Batch 700] loss: 0.013740740046123391
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0423
Validation Accuracy: 0.9898
Overfitting: 0.0413
Best model saved at epoch 16 with validation loss: 0.0423
[Epoch 17, Batch 100] loss: 0.013268985848408193
[Epoch 17, Batch 200] loss: 0.01201925286437472
[Epoch 17, Batch 300] loss: 0.010171376490761759
[Epoch 17, Batch 400] loss: 0.01195132356344402
[Epoch 17, Batch 500] loss: 0.01256088930691476
[Epoch 17, Batch 600] loss: 0.01279205724989879
[Epoch 17, Batch 700] loss: 0.011883777854964138
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0478
Validation Accuracy: 0.9870
Overfitting: 0.0469
[Epoch 18, Batch 100] loss: 0.011066227175469977
[Epoch 18, Batch 200] loss: 0.012186711479953373
[Epoch 18, Batch 300] loss: 0.011453924818633823
[Epoch 18, Batch 400] loss: 0.007255373132938985
[Epoch 18, Batch 500] loss: 0.012357836207083892
[Epoch 18, Batch 600] loss: 0.011120033810439054
[Epoch 18, Batch 700] loss: 0.009114815408102004
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0466
Validation Accuracy: 0.9883
Overfitting: 0.0460
[Epoch 19, Batch 100] loss: 0.009617848121961288
[Epoch 19, Batch 200] loss: 0.008332319155342702
[Epoch 19, Batch 300] loss: 0.011264114205769147
[Epoch 19, Batch 400] loss: 0.010131011291086907
[Epoch 19, Batch 500] loss: 0.009889042250579223
[Epoch 19, Batch 600] loss: 0.006710232709083357
[Epoch 19, Batch 700] loss: 0.00955079273411684
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0512
Validation Accuracy: 0.9867
Overfitting: 0.0504
[Epoch 20, Batch 100] loss: 0.006555780323324143
[Epoch 20, Batch 200] loss: 0.007139333180239191
[Epoch 20, Batch 300] loss: 0.006417426279913343
[Epoch 20, Batch 400] loss: 0.007468909798481036
[Epoch 20, Batch 500] loss: 0.009720740827324334
[Epoch 20, Batch 600] loss: 0.01201376050230465
[Epoch 20, Batch 700] loss: 0.010779016890683123
**STATS for Epoch 20** : 
Average training loss: 0.0009
Average validation loss: 0.0446
Validation Accuracy: 0.9888
Overfitting: 0.0437
[Epoch 21, Batch 100] loss: 0.006735038086007989
[Epoch 21, Batch 200] loss: 0.005457350533761201
[Epoch 21, Batch 300] loss: 0.009204947772232117
[Epoch 21, Batch 400] loss: 0.007992993184816442
[Epoch 21, Batch 500] loss: 0.007982191045884974
[Epoch 21, Batch 600] loss: 0.007347756770286651
[Epoch 21, Batch 700] loss: 0.0066292040911503135
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0519
Validation Accuracy: 0.9869
Overfitting: 0.0514
[Epoch 22, Batch 100] loss: 0.004918807314497826
[Epoch 22, Batch 200] loss: 0.005455472103640204
[Epoch 22, Batch 300] loss: 0.006076293427940982
[Epoch 22, Batch 400] loss: 0.004663790920858446
[Epoch 22, Batch 500] loss: 0.0038903601568381417
[Epoch 22, Batch 600] loss: 0.00557949388952693
[Epoch 22, Batch 700] loss: 0.005011411185987527
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0504
Validation Accuracy: 0.9882
Overfitting: 0.0498
[Epoch 23, Batch 100] loss: 0.005613692874558183
[Epoch 23, Batch 200] loss: 0.004392028772999765
[Epoch 23, Batch 300] loss: 0.0029971929081875712
[Epoch 23, Batch 400] loss: 0.003956131233753695
[Epoch 23, Batch 500] loss: 0.005684744940499514
[Epoch 23, Batch 600] loss: 0.006766716978745535
[Epoch 23, Batch 700] loss: 0.005191921065706992
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0471
Validation Accuracy: 0.9892
Overfitting: 0.0468
[Epoch 24, Batch 100] loss: 0.006310374606700861
[Epoch 24, Batch 200] loss: 0.005773187543363747
[Epoch 24, Batch 300] loss: 0.0039131003910733856
[Epoch 24, Batch 400] loss: 0.00344265088911925
[Epoch 24, Batch 500] loss: 0.0055996619242705496
[Epoch 24, Batch 600] loss: 0.003917680752201704
[Epoch 24, Batch 700] loss: 0.008259576403943356
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0534
Validation Accuracy: 0.9878
Overfitting: 0.0530
Fold 3 validation loss: 0.0534
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.1649717545509337
[Epoch 1, Batch 200] loss: 0.7555913338065148
[Epoch 1, Batch 300] loss: 0.3941620597243309
[Epoch 1, Batch 400] loss: 0.3105076888203621
[Epoch 1, Batch 500] loss: 0.23961771123111247
[Epoch 1, Batch 600] loss: 0.21042048200964927
[Epoch 1, Batch 700] loss: 0.18022469464689495
**STATS for Epoch 1** : 
Average training loss: 0.0109
Average validation loss: 0.1530
Validation Accuracy: 0.9527
Overfitting: 0.1421
Best model saved at epoch 1 with validation loss: 0.1530
[Epoch 2, Batch 100] loss: 0.1626737479120493
[Epoch 2, Batch 200] loss: 0.1479421198181808
[Epoch 2, Batch 300] loss: 0.12717400316148997
[Epoch 2, Batch 400] loss: 0.11238526230677963
[Epoch 2, Batch 500] loss: 0.10688256151974201
[Epoch 2, Batch 600] loss: 0.10311041934415698
[Epoch 2, Batch 700] loss: 0.09905002342537045
**STATS for Epoch 2** : 
Average training loss: 0.0066
Average validation loss: 0.0950
Validation Accuracy: 0.9706
Overfitting: 0.0884
Best model saved at epoch 2 with validation loss: 0.0950
[Epoch 3, Batch 100] loss: 0.08891324768774211
[Epoch 3, Batch 200] loss: 0.08141436252743006
[Epoch 3, Batch 300] loss: 0.08160950220189989
[Epoch 3, Batch 400] loss: 0.07620132453739643
[Epoch 3, Batch 500] loss: 0.07735560352914035
[Epoch 3, Batch 600] loss: 0.08349915890954435
[Epoch 3, Batch 700] loss: 0.06576807460281998
**STATS for Epoch 3** : 
Average training loss: 0.0060
Average validation loss: 0.0738
Validation Accuracy: 0.9772
Overfitting: 0.0678
Best model saved at epoch 3 with validation loss: 0.0738
[Epoch 4, Batch 100] loss: 0.06022728460840881
[Epoch 4, Batch 200] loss: 0.05559608336072415
[Epoch 4, Batch 300] loss: 0.07154612137470394
[Epoch 4, Batch 400] loss: 0.05949864327907562
[Epoch 4, Batch 500] loss: 0.06288893704302609
[Epoch 4, Batch 600] loss: 0.059140974190086126
[Epoch 4, Batch 700] loss: 0.06727929329033941
**STATS for Epoch 4** : 
Average training loss: 0.0042
Average validation loss: 0.0575
Validation Accuracy: 0.9820
Overfitting: 0.0533
Best model saved at epoch 4 with validation loss: 0.0575
[Epoch 5, Batch 100] loss: 0.048749343673698604
[Epoch 5, Batch 200] loss: 0.05571839087177068
[Epoch 5, Batch 300] loss: 0.048603768050670626
[Epoch 5, Batch 400] loss: 0.05093868302181363
[Epoch 5, Batch 500] loss: 0.05233339896192774
[Epoch 5, Batch 600] loss: 0.06232046654447913
[Epoch 5, Batch 700] loss: 0.048015829180367293
**STATS for Epoch 5** : 
Average training loss: 0.0030
Average validation loss: 0.0560
Validation Accuracy: 0.9820
Overfitting: 0.0529
Best model saved at epoch 5 with validation loss: 0.0560
[Epoch 6, Batch 100] loss: 0.04486372841289267
[Epoch 6, Batch 200] loss: 0.03400115018710494
[Epoch 6, Batch 300] loss: 0.040499432091601194
[Epoch 6, Batch 400] loss: 0.04823509154375642
[Epoch 6, Batch 500] loss: 0.04891369003336877
[Epoch 6, Batch 600] loss: 0.0516681753587909
[Epoch 6, Batch 700] loss: 0.04926918448647484
**STATS for Epoch 6** : 
Average training loss: 0.0025
Average validation loss: 0.0568
Validation Accuracy: 0.9812
Overfitting: 0.0544
[Epoch 7, Batch 100] loss: 0.034111944124451836
[Epoch 7, Batch 200] loss: 0.035746023431420325
[Epoch 7, Batch 300] loss: 0.043341794116422534
[Epoch 7, Batch 400] loss: 0.037031075169797985
[Epoch 7, Batch 500] loss: 0.038688166616484526
[Epoch 7, Batch 600] loss: 0.036661048885434866
[Epoch 7, Batch 700] loss: 0.03475259780767374
**STATS for Epoch 7** : 
Average training loss: 0.0030
Average validation loss: 0.0450
Validation Accuracy: 0.9858
Overfitting: 0.0420
Best model saved at epoch 7 with validation loss: 0.0450
[Epoch 8, Batch 100] loss: 0.03345710137422429
[Epoch 8, Batch 200] loss: 0.027996280991937964
[Epoch 8, Batch 300] loss: 0.03674050671048462
[Epoch 8, Batch 400] loss: 0.0365129956707824
[Epoch 8, Batch 500] loss: 0.034999058034736664
[Epoch 8, Batch 600] loss: 0.038907868752721696
[Epoch 8, Batch 700] loss: 0.03225941954064183
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0509
Validation Accuracy: 0.9848
Overfitting: 0.0490
[Epoch 9, Batch 100] loss: 0.024387764311395586
[Epoch 9, Batch 200] loss: 0.027360963398823514
[Epoch 9, Batch 300] loss: 0.024096316972863862
[Epoch 9, Batch 400] loss: 0.03477727772871731
[Epoch 9, Batch 500] loss: 0.038928984716767444
[Epoch 9, Batch 600] loss: 0.029623168198158963
[Epoch 9, Batch 700] loss: 0.027290252543753012
**STATS for Epoch 9** : 
Average training loss: 0.0019
Average validation loss: 0.0464
Validation Accuracy: 0.9839
Overfitting: 0.0445
[Epoch 10, Batch 100] loss: 0.01819370789162349
[Epoch 10, Batch 200] loss: 0.023948156876140273
[Epoch 10, Batch 300] loss: 0.028182262738118878
[Epoch 10, Batch 400] loss: 0.031742399324430154
[Epoch 10, Batch 500] loss: 0.026475687099737116
[Epoch 10, Batch 600] loss: 0.027436332564102484
[Epoch 10, Batch 700] loss: 0.033114197874674574
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0419
Validation Accuracy: 0.9862
Overfitting: 0.0403
Best model saved at epoch 10 with validation loss: 0.0419
[Epoch 11, Batch 100] loss: 0.020636555281234904
[Epoch 11, Batch 200] loss: 0.016834975412930362
[Epoch 11, Batch 300] loss: 0.025353384957415983
[Epoch 11, Batch 400] loss: 0.0237945752509404
[Epoch 11, Batch 500] loss: 0.02220568801072659
[Epoch 11, Batch 600] loss: 0.02911370405985508
[Epoch 11, Batch 700] loss: 0.02541267841937952
**STATS for Epoch 11** : 
Average training loss: 0.0013
Average validation loss: 0.0424
Validation Accuracy: 0.9857
Overfitting: 0.0411
[Epoch 12, Batch 100] loss: 0.017771892627642956
[Epoch 12, Batch 200] loss: 0.01785312724648975
[Epoch 12, Batch 300] loss: 0.019438222615863195
[Epoch 12, Batch 400] loss: 0.022281248238286935
[Epoch 12, Batch 500] loss: 0.028080807502556128
[Epoch 12, Batch 600] loss: 0.017348314831615426
[Epoch 12, Batch 700] loss: 0.023564934807363897
**STATS for Epoch 12** : 
Average training loss: 0.0021
Average validation loss: 0.0445
Validation Accuracy: 0.9858
Overfitting: 0.0424
[Epoch 13, Batch 100] loss: 0.015509932151180692
[Epoch 13, Batch 200] loss: 0.018355051155667754
[Epoch 13, Batch 300] loss: 0.01589596307632746
[Epoch 13, Batch 400] loss: 0.02365227386006154
[Epoch 13, Batch 500] loss: 0.01838999742292799
[Epoch 13, Batch 600] loss: 0.015816801995970308
[Epoch 13, Batch 700] loss: 0.018525232691463316
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0508
Validation Accuracy: 0.9848
Overfitting: 0.0498
[Epoch 14, Batch 100] loss: 0.01737143026519334
[Epoch 14, Batch 200] loss: 0.014630302782461514
[Epoch 14, Batch 300] loss: 0.018856333544827065
[Epoch 14, Batch 400] loss: 0.014311500116018578
[Epoch 14, Batch 500] loss: 0.014914680926303846
[Epoch 14, Batch 600] loss: 0.01495035999279935
[Epoch 14, Batch 700] loss: 0.01847951193980407
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0394
Validation Accuracy: 0.9882
Overfitting: 0.0382
Best model saved at epoch 14 with validation loss: 0.0394
[Epoch 15, Batch 100] loss: 0.015359458078892203
[Epoch 15, Batch 200] loss: 0.01707972661592066
[Epoch 15, Batch 300] loss: 0.01103541939490242
[Epoch 15, Batch 400] loss: 0.012960582144150976
[Epoch 15, Batch 500] loss: 0.013620635089318966
[Epoch 15, Batch 600] loss: 0.011410213665221818
[Epoch 15, Batch 700] loss: 0.019883699957135834
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0412
Validation Accuracy: 0.9871
Overfitting: 0.0405
[Epoch 16, Batch 100] loss: 0.007855313539039344
[Epoch 16, Batch 200] loss: 0.008471987617813283
[Epoch 16, Batch 300] loss: 0.01598224127286812
[Epoch 16, Batch 400] loss: 0.016679167876427526
[Epoch 16, Batch 500] loss: 0.015052685943664983
[Epoch 16, Batch 600] loss: 0.00903244344284758
[Epoch 16, Batch 700] loss: 0.012812033075570071
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0420
Validation Accuracy: 0.9874
Overfitting: 0.0411
[Epoch 17, Batch 100] loss: 0.00933790222494281
[Epoch 17, Batch 200] loss: 0.011060824758751552
[Epoch 17, Batch 300] loss: 0.011816680542251561
[Epoch 17, Batch 400] loss: 0.009384759162931005
[Epoch 17, Batch 500] loss: 0.011340409549011382
[Epoch 17, Batch 600] loss: 0.014497388407908146
[Epoch 17, Batch 700] loss: 0.011014062629692489
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0433
Validation Accuracy: 0.9868
Overfitting: 0.0423
[Epoch 18, Batch 100] loss: 0.009580557212175336
[Epoch 18, Batch 200] loss: 0.010063961654232116
[Epoch 18, Batch 300] loss: 0.011963055622618412
[Epoch 18, Batch 400] loss: 0.0076863581844372674
[Epoch 18, Batch 500] loss: 0.008646878599538468
[Epoch 18, Batch 600] loss: 0.013328662251733476
[Epoch 18, Batch 700] loss: 0.01166820730199106
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0457
Validation Accuracy: 0.9867
Overfitting: 0.0452
[Epoch 19, Batch 100] loss: 0.006402749348781072
[Epoch 19, Batch 200] loss: 0.00801128261940903
[Epoch 19, Batch 300] loss: 0.006728210663277423
[Epoch 19, Batch 400] loss: 0.008768626240416778
[Epoch 19, Batch 500] loss: 0.008427333658546558
[Epoch 19, Batch 600] loss: 0.01134142451788648
[Epoch 19, Batch 700] loss: 0.013696854916634037
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0448
Validation Accuracy: 0.9871
Overfitting: 0.0444
[Epoch 20, Batch 100] loss: 0.008667778153903783
[Epoch 20, Batch 200] loss: 0.004868773059861269
[Epoch 20, Batch 300] loss: 0.007243374889876577
[Epoch 20, Batch 400] loss: 0.012390904900894385
[Epoch 20, Batch 500] loss: 0.009257203613087768
[Epoch 20, Batch 600] loss: 0.011391273600165732
[Epoch 20, Batch 700] loss: 0.009137001262351986
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0418
Validation Accuracy: 0.9888
Overfitting: 0.0414
[Epoch 21, Batch 100] loss: 0.007507864621074987
[Epoch 21, Batch 200] loss: 0.005661487414472504
[Epoch 21, Batch 300] loss: 0.007399480718449922
[Epoch 21, Batch 400] loss: 0.00463030654220347
[Epoch 21, Batch 500] loss: 0.008054263472185994
[Epoch 21, Batch 600] loss: 0.011655277977624792
[Epoch 21, Batch 700] loss: 0.0074617017271521036
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0412
Validation Accuracy: 0.9879
Overfitting: 0.0406
[Epoch 22, Batch 100] loss: 0.008075427359763125
[Epoch 22, Batch 200] loss: 0.005049465994306957
[Epoch 22, Batch 300] loss: 0.006575967024182319
[Epoch 22, Batch 400] loss: 0.006668371934865718
[Epoch 22, Batch 500] loss: 0.004487684123087092
[Epoch 22, Batch 600] loss: 0.007270531849935651
[Epoch 22, Batch 700] loss: 0.011999948903248878
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0455
Validation Accuracy: 0.9875
Overfitting: 0.0450
[Epoch 23, Batch 100] loss: 0.004968185025936691
[Epoch 23, Batch 200] loss: 0.005738034913229058
[Epoch 23, Batch 300] loss: 0.004434731772598752
[Epoch 23, Batch 400] loss: 0.005919370556512149
[Epoch 23, Batch 500] loss: 0.0038429716942482628
[Epoch 23, Batch 600] loss: 0.006196477503690403
[Epoch 23, Batch 700] loss: 0.00614600101895121
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0454
Validation Accuracy: 0.9878
Overfitting: 0.0451
[Epoch 24, Batch 100] loss: 0.004356980060401838
[Epoch 24, Batch 200] loss: 0.004697123669029679
[Epoch 24, Batch 300] loss: 0.0032335635698836993
[Epoch 24, Batch 400] loss: 0.005847967290192173
[Epoch 24, Batch 500] loss: 0.006776574582454486
[Epoch 24, Batch 600] loss: 0.007868230709427736
[Epoch 24, Batch 700] loss: 0.004010629128388245
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0472
Validation Accuracy: 0.9872
Overfitting: 0.0469
Fold 4 validation loss: 0.0472
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2342892587184906
[Epoch 1, Batch 200] loss: 0.9968876400589943
[Epoch 1, Batch 300] loss: 0.41720269158482554
[Epoch 1, Batch 400] loss: 0.31117983281612394
[Epoch 1, Batch 500] loss: 0.26946239948272704
[Epoch 1, Batch 600] loss: 0.2067336917668581
[Epoch 1, Batch 700] loss: 0.19180248007178308
**STATS for Epoch 1** : 
Average training loss: 0.0127
Average validation loss: 0.1654
Validation Accuracy: 0.9519
Overfitting: 0.1527
Best model saved at epoch 1 with validation loss: 0.1654
[Epoch 2, Batch 100] loss: 0.16961986418813468
[Epoch 2, Batch 200] loss: 0.14822943961247803
[Epoch 2, Batch 300] loss: 0.15267760049551726
[Epoch 2, Batch 400] loss: 0.12387941051274538
[Epoch 2, Batch 500] loss: 0.1100020859297365
[Epoch 2, Batch 600] loss: 0.11560554916970432
[Epoch 2, Batch 700] loss: 0.1204324147850275
**STATS for Epoch 2** : 
Average training loss: 0.0067
Average validation loss: 0.1037
Validation Accuracy: 0.9682
Overfitting: 0.0969
Best model saved at epoch 2 with validation loss: 0.1037
[Epoch 3, Batch 100] loss: 0.10836259578354657
[Epoch 3, Batch 200] loss: 0.10024515554308891
[Epoch 3, Batch 300] loss: 0.08967561453580856
[Epoch 3, Batch 400] loss: 0.08802711831405759
[Epoch 3, Batch 500] loss: 0.07875387538224458
[Epoch 3, Batch 600] loss: 0.08404735864140093
[Epoch 3, Batch 700] loss: 0.08126001324504614
**STATS for Epoch 3** : 
Average training loss: 0.0042
Average validation loss: 0.0763
Validation Accuracy: 0.9763
Overfitting: 0.0720
Best model saved at epoch 3 with validation loss: 0.0763
[Epoch 4, Batch 100] loss: 0.07549206440337003
[Epoch 4, Batch 200] loss: 0.07895691804587841
[Epoch 4, Batch 300] loss: 0.06290918133687227
[Epoch 4, Batch 400] loss: 0.06665868462063372
[Epoch 4, Batch 500] loss: 0.06831210100091994
[Epoch 4, Batch 600] loss: 0.06758046115748584
[Epoch 4, Batch 700] loss: 0.06978326295502484
**STATS for Epoch 4** : 
Average training loss: 0.0045
Average validation loss: 0.0675
Validation Accuracy: 0.9801
Overfitting: 0.0629
Best model saved at epoch 4 with validation loss: 0.0675
[Epoch 5, Batch 100] loss: 0.052521066456101835
[Epoch 5, Batch 200] loss: 0.06134119041729719
[Epoch 5, Batch 300] loss: 0.06055067067965865
[Epoch 5, Batch 400] loss: 0.049498996119946244
[Epoch 5, Batch 500] loss: 0.05835350621491671
[Epoch 5, Batch 600] loss: 0.05550090222619474
[Epoch 5, Batch 700] loss: 0.05060964984702878
**STATS for Epoch 5** : 
Average training loss: 0.0038
Average validation loss: 0.0615
Validation Accuracy: 0.9812
Overfitting: 0.0577
Best model saved at epoch 5 with validation loss: 0.0615
[Epoch 6, Batch 100] loss: 0.05408957717940211
[Epoch 6, Batch 200] loss: 0.04873338053934276
[Epoch 6, Batch 300] loss: 0.04099202939774841
[Epoch 6, Batch 400] loss: 0.03985444459598511
[Epoch 6, Batch 500] loss: 0.0523844910459593
[Epoch 6, Batch 600] loss: 0.05550930362194777
[Epoch 6, Batch 700] loss: 0.042793966089375315
**STATS for Epoch 6** : 
Average training loss: 0.0028
Average validation loss: 0.0561
Validation Accuracy: 0.9830
Overfitting: 0.0533
Best model saved at epoch 6 with validation loss: 0.0561
[Epoch 7, Batch 100] loss: 0.0364853389095515
[Epoch 7, Batch 200] loss: 0.03998719160212204
[Epoch 7, Batch 300] loss: 0.03924292512703687
[Epoch 7, Batch 400] loss: 0.04355310713173822
[Epoch 7, Batch 500] loss: 0.04234512480907142
[Epoch 7, Batch 600] loss: 0.03919811987085268
[Epoch 7, Batch 700] loss: 0.04598561027087271
**STATS for Epoch 7** : 
Average training loss: 0.0021
Average validation loss: 0.0580
Validation Accuracy: 0.9814
Overfitting: 0.0559
[Epoch 8, Batch 100] loss: 0.038954982557334004
[Epoch 8, Batch 200] loss: 0.03630155220511369
[Epoch 8, Batch 300] loss: 0.029952139200177044
[Epoch 8, Batch 400] loss: 0.03448396719875745
[Epoch 8, Batch 500] loss: 0.03498570761177689
[Epoch 8, Batch 600] loss: 0.03959650102769956
[Epoch 8, Batch 700] loss: 0.0350524047028739
**STATS for Epoch 8** : 
Average training loss: 0.0025
Average validation loss: 0.0507
Validation Accuracy: 0.9848
Overfitting: 0.0482
Best model saved at epoch 8 with validation loss: 0.0507
[Epoch 9, Batch 100] loss: 0.02906949638039805
[Epoch 9, Batch 200] loss: 0.033690346129005774
[Epoch 9, Batch 300] loss: 0.029820367459906266
[Epoch 9, Batch 400] loss: 0.028394165501813406
[Epoch 9, Batch 500] loss: 0.033190179127268495
[Epoch 9, Batch 600] loss: 0.03768336230044952
[Epoch 9, Batch 700] loss: 0.029716238130349668
**STATS for Epoch 9** : 
Average training loss: 0.0029
Average validation loss: 0.0522
Validation Accuracy: 0.9835
Overfitting: 0.0493
[Epoch 10, Batch 100] loss: 0.029791394075145944
[Epoch 10, Batch 200] loss: 0.029327764129266142
[Epoch 10, Batch 300] loss: 0.020722008682787417
[Epoch 10, Batch 400] loss: 0.023742490082513543
[Epoch 10, Batch 500] loss: 0.029161502360366284
[Epoch 10, Batch 600] loss: 0.02636671782936901
[Epoch 10, Batch 700] loss: 0.028872911769431086
**STATS for Epoch 10** : 
Average training loss: 0.0019
Average validation loss: 0.0540
Validation Accuracy: 0.9844
Overfitting: 0.0521
[Epoch 11, Batch 100] loss: 0.020120416059507987
[Epoch 11, Batch 200] loss: 0.019244041940546595
[Epoch 11, Batch 300] loss: 0.026074781154311496
[Epoch 11, Batch 400] loss: 0.027078528750571422
[Epoch 11, Batch 500] loss: 0.02318292102892883
[Epoch 11, Batch 600] loss: 0.024043135331012308
[Epoch 11, Batch 700] loss: 0.030519612315110863
**STATS for Epoch 11** : 
Average training loss: 0.0025
Average validation loss: 0.0537
Validation Accuracy: 0.9844
Overfitting: 0.0512
[Epoch 12, Batch 100] loss: 0.01762003630225081
[Epoch 12, Batch 200] loss: 0.0201238677528454
[Epoch 12, Batch 300] loss: 0.01961845116893528
[Epoch 12, Batch 400] loss: 0.02893331837200094
[Epoch 12, Batch 500] loss: 0.025490343478741125
[Epoch 12, Batch 600] loss: 0.018006572511512785
[Epoch 12, Batch 700] loss: 0.021288483430980706
**STATS for Epoch 12** : 
Average training loss: 0.0019
Average validation loss: 0.0445
Validation Accuracy: 0.9868
Overfitting: 0.0427
Best model saved at epoch 12 with validation loss: 0.0445
[Epoch 13, Batch 100] loss: 0.017680455862137023
[Epoch 13, Batch 200] loss: 0.01568672210953082
[Epoch 13, Batch 300] loss: 0.025134581614111084
[Epoch 13, Batch 400] loss: 0.021524179450352676
[Epoch 13, Batch 500] loss: 0.018074171591433697
[Epoch 13, Batch 600] loss: 0.01708853609612561
[Epoch 13, Batch 700] loss: 0.019379677176184485
**STATS for Epoch 13** : 
Average training loss: 0.0012
Average validation loss: 0.0417
Validation Accuracy: 0.9879
Overfitting: 0.0405
Best model saved at epoch 13 with validation loss: 0.0417
[Epoch 14, Batch 100] loss: 0.014261659644107567
[Epoch 14, Batch 200] loss: 0.014745208582025953
[Epoch 14, Batch 300] loss: 0.02007264574756846
[Epoch 14, Batch 400] loss: 0.014738552412891294
[Epoch 14, Batch 500] loss: 0.01697787079756381
[Epoch 14, Batch 600] loss: 0.017960773213708307
[Epoch 14, Batch 700] loss: 0.01687865019426681
**STATS for Epoch 14** : 
Average training loss: 0.0015
Average validation loss: 0.0475
Validation Accuracy: 0.9862
Overfitting: 0.0460
[Epoch 15, Batch 100] loss: 0.013910778680874501
[Epoch 15, Batch 200] loss: 0.011830949527211487
[Epoch 15, Batch 300] loss: 0.014067733383271844
[Epoch 15, Batch 400] loss: 0.018992594695009756
[Epoch 15, Batch 500] loss: 0.015689039794087877
[Epoch 15, Batch 600] loss: 0.016882438138418367
[Epoch 15, Batch 700] loss: 0.02125447889600764
**STATS for Epoch 15** : 
Average training loss: 0.0011
Average validation loss: 0.0443
Validation Accuracy: 0.9878
Overfitting: 0.0432
[Epoch 16, Batch 100] loss: 0.012789053601154591
[Epoch 16, Batch 200] loss: 0.010547180374633171
[Epoch 16, Batch 300] loss: 0.011934783858596348
[Epoch 16, Batch 400] loss: 0.014733056871045846
[Epoch 16, Batch 500] loss: 0.01566202264642925
[Epoch 16, Batch 600] loss: 0.011792553856503218
[Epoch 16, Batch 700] loss: 0.01811054549732944
**STATS for Epoch 16** : 
Average training loss: 0.0011
Average validation loss: 0.0484
Validation Accuracy: 0.9881
Overfitting: 0.0473
[Epoch 17, Batch 100] loss: 0.009673943342932034
[Epoch 17, Batch 200] loss: 0.0070679992419900375
[Epoch 17, Batch 300] loss: 0.012142930622940185
[Epoch 17, Batch 400] loss: 0.012039172260847409
[Epoch 17, Batch 500] loss: 0.007740323801990598
[Epoch 17, Batch 600] loss: 0.014582309146753687
[Epoch 17, Batch 700] loss: 0.014737935112789273
**STATS for Epoch 17** : 
Average training loss: 0.0012
Average validation loss: 0.0465
Validation Accuracy: 0.9884
Overfitting: 0.0453
[Epoch 18, Batch 100] loss: 0.009560698737332132
[Epoch 18, Batch 200] loss: 0.013861717080581003
[Epoch 18, Batch 300] loss: 0.010475982593634399
[Epoch 18, Batch 400] loss: 0.012099990470160265
[Epoch 18, Batch 500] loss: 0.009353715481120161
[Epoch 18, Batch 600] loss: 0.011256724267223035
[Epoch 18, Batch 700] loss: 0.011115887799387564
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0538
Validation Accuracy: 0.9858
Overfitting: 0.0528
[Epoch 19, Batch 100] loss: 0.009221934876695741
[Epoch 19, Batch 200] loss: 0.01217781497980468
[Epoch 19, Batch 300] loss: 0.010006247883720789
[Epoch 19, Batch 400] loss: 0.00991263782590977
[Epoch 19, Batch 500] loss: 0.006611987425130792
[Epoch 19, Batch 600] loss: 0.010673967482507579
[Epoch 19, Batch 700] loss: 0.013407695283458452
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0495
Validation Accuracy: 0.9871
Overfitting: 0.0487
[Epoch 20, Batch 100] loss: 0.005612238286994397
[Epoch 20, Batch 200] loss: 0.006577439708271413
[Epoch 20, Batch 300] loss: 0.007260061800625408
[Epoch 20, Batch 400] loss: 0.009109612893535086
[Epoch 20, Batch 500] loss: 0.009813102166044701
[Epoch 20, Batch 600] loss: 0.013728073246711573
[Epoch 20, Batch 700] loss: 0.008089709254600166
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0480
Validation Accuracy: 0.9885
Overfitting: 0.0474
[Epoch 21, Batch 100] loss: 0.007189095931244083
[Epoch 21, Batch 200] loss: 0.012614901810011361
[Epoch 21, Batch 300] loss: 0.0070589837818988595
[Epoch 21, Batch 400] loss: 0.005401451643374458
[Epoch 21, Batch 500] loss: 0.008143415135218674
[Epoch 21, Batch 600] loss: 0.005246051132398861
[Epoch 21, Batch 700] loss: 0.009987293850026618
**STATS for Epoch 21** : 
Average training loss: 0.0007
Average validation loss: 0.0501
Validation Accuracy: 0.9867
Overfitting: 0.0494
[Epoch 22, Batch 100] loss: 0.005435816153949418
[Epoch 22, Batch 200] loss: 0.007424405566907808
[Epoch 22, Batch 300] loss: 0.008659780081070495
[Epoch 22, Batch 400] loss: 0.008487059596955077
[Epoch 22, Batch 500] loss: 0.007249062447372125
[Epoch 22, Batch 600] loss: 0.008381604606547625
[Epoch 22, Batch 700] loss: 0.009141155099132447
**STATS for Epoch 22** : 
Average training loss: 0.0009
Average validation loss: 0.0534
Validation Accuracy: 0.9870
Overfitting: 0.0525
[Epoch 23, Batch 100] loss: 0.00685587655290874
[Epoch 23, Batch 200] loss: 0.006231126954880892
[Epoch 23, Batch 300] loss: 0.004823105492723698
[Epoch 23, Batch 400] loss: 0.006487196503039741
[Epoch 23, Batch 500] loss: 0.004972399851249065
[Epoch 23, Batch 600] loss: 0.007318282960122815
[Epoch 23, Batch 700] loss: 0.00863566001826257
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0440
Validation Accuracy: 0.9893
Overfitting: 0.0439
[Epoch 24, Batch 100] loss: 0.004438796335816733
[Epoch 24, Batch 200] loss: 0.0030982475789642196
[Epoch 24, Batch 300] loss: 0.0029247715633755433
[Epoch 24, Batch 400] loss: 0.005442073438443913
[Epoch 24, Batch 500] loss: 0.00672394727851497
[Epoch 24, Batch 600] loss: 0.003171081217042229
[Epoch 24, Batch 700] loss: 0.0071596963425236025
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0466
Validation Accuracy: 0.9888
Overfitting: 0.0463
Fold 5 validation loss: 0.0466
Mean validation loss across all folds for Trial 10 is 0.0505 with trial config:  l1: 256, l2: 128, lr: 0.0026936379642822942, batch_size: 64
[I 2024-12-10 06:54:07,988] Trial 9 finished with value: 0.05047078778321675 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0026936379642822942, 'batch_size': 64}. Best is trial 9 with value: 0.05047078778321675.

Selected Hyperparameters for Trial 11:
  l1: 256, l2: 128, lr: 0.0028666428011813474, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2574476480484007
[Epoch 1, Batch 200] loss: 1.1750564178824425
[Epoch 1, Batch 300] loss: 0.3961704045534134
[Epoch 1, Batch 400] loss: 0.26188889004290106
[Epoch 1, Batch 500] loss: 0.2118450715392828
[Epoch 1, Batch 600] loss: 0.18411366280168295
[Epoch 1, Batch 700] loss: 0.1655186839029193
**STATS for Epoch 1** : 
Average training loss: 0.0091
Average validation loss: 0.1287
Validation Accuracy: 0.9604
Overfitting: 0.1196
Best model saved at epoch 1 with validation loss: 0.1287
[Epoch 2, Batch 100] loss: 0.12514255117624998
[Epoch 2, Batch 200] loss: 0.12575038728304208
[Epoch 2, Batch 300] loss: 0.11454038644209504
[Epoch 2, Batch 400] loss: 0.12270244410261512
[Epoch 2, Batch 500] loss: 0.10115750957280398
[Epoch 2, Batch 600] loss: 0.10286439552903176
[Epoch 2, Batch 700] loss: 0.08240946665871889
**STATS for Epoch 2** : 
Average training loss: 0.0060
Average validation loss: 0.0804
Validation Accuracy: 0.9740
Overfitting: 0.0745
Best model saved at epoch 2 with validation loss: 0.0804
[Epoch 3, Batch 100] loss: 0.0793269894272089
[Epoch 3, Batch 200] loss: 0.07474650550168008
[Epoch 3, Batch 300] loss: 0.08083476643078029
[Epoch 3, Batch 400] loss: 0.07773576516658068
[Epoch 3, Batch 500] loss: 0.07590294071473182
[Epoch 3, Batch 600] loss: 0.07402062614448368
[Epoch 3, Batch 700] loss: 0.07600837943609803
**STATS for Epoch 3** : 
Average training loss: 0.0048
Average validation loss: 0.0614
Validation Accuracy: 0.9802
Overfitting: 0.0565
Best model saved at epoch 3 with validation loss: 0.0614
[Epoch 4, Batch 100] loss: 0.06089547710027546
[Epoch 4, Batch 200] loss: 0.06087954074610025
[Epoch 4, Batch 300] loss: 0.06596896656323224
[Epoch 4, Batch 400] loss: 0.06527274913154542
[Epoch 4, Batch 500] loss: 0.055604032129049304
[Epoch 4, Batch 600] loss: 0.059816105044446885
[Epoch 4, Batch 700] loss: 0.05644345758948475
**STATS for Epoch 4** : 
Average training loss: 0.0032
Average validation loss: 0.0573
Validation Accuracy: 0.9817
Overfitting: 0.0541
Best model saved at epoch 4 with validation loss: 0.0573
[Epoch 5, Batch 100] loss: 0.04790100538171828
[Epoch 5, Batch 200] loss: 0.053164952325169
[Epoch 5, Batch 300] loss: 0.04558331094449386
[Epoch 5, Batch 400] loss: 0.044892289980780334
[Epoch 5, Batch 500] loss: 0.0507204637513496
[Epoch 5, Batch 600] loss: 0.04747533411718905
[Epoch 5, Batch 700] loss: 0.04887482647784054
**STATS for Epoch 5** : 
Average training loss: 0.0034
Average validation loss: 0.0492
Validation Accuracy: 0.9838
Overfitting: 0.0458
Best model saved at epoch 5 with validation loss: 0.0492
[Epoch 6, Batch 100] loss: 0.03785982436966151
[Epoch 6, Batch 200] loss: 0.04085902594728395
[Epoch 6, Batch 300] loss: 0.04816206001210958
[Epoch 6, Batch 400] loss: 0.045276096030138435
[Epoch 6, Batch 500] loss: 0.03859113233163953
[Epoch 6, Batch 600] loss: 0.044622905736323444
[Epoch 6, Batch 700] loss: 0.04432517065200955
**STATS for Epoch 6** : 
Average training loss: 0.0026
Average validation loss: 0.0468
Validation Accuracy: 0.9847
Overfitting: 0.0441
Best model saved at epoch 6 with validation loss: 0.0468
[Epoch 7, Batch 100] loss: 0.03534153395332396
[Epoch 7, Batch 200] loss: 0.03677209028741345
[Epoch 7, Batch 300] loss: 0.033914597429102286
[Epoch 7, Batch 400] loss: 0.03744303013954777
[Epoch 7, Batch 500] loss: 0.036557611087337134
[Epoch 7, Batch 600] loss: 0.0336544134747237
[Epoch 7, Batch 700] loss: 0.044144422558601945
**STATS for Epoch 7** : 
Average training loss: 0.0021
Average validation loss: 0.0442
Validation Accuracy: 0.9863
Overfitting: 0.0420
Best model saved at epoch 7 with validation loss: 0.0442
[Epoch 8, Batch 100] loss: 0.03140183881681878
[Epoch 8, Batch 200] loss: 0.03511308220564388
[Epoch 8, Batch 300] loss: 0.03547157029854134
[Epoch 8, Batch 400] loss: 0.035207533992361276
[Epoch 8, Batch 500] loss: 0.031589348511770365
[Epoch 8, Batch 600] loss: 0.02693287215894088
[Epoch 8, Batch 700] loss: 0.03344124406634364
**STATS for Epoch 8** : 
Average training loss: 0.0023
Average validation loss: 0.0482
Validation Accuracy: 0.9849
Overfitting: 0.0459
[Epoch 9, Batch 100] loss: 0.023173521221615374
[Epoch 9, Batch 200] loss: 0.028320697975577788
[Epoch 9, Batch 300] loss: 0.031098098094807937
[Epoch 9, Batch 400] loss: 0.021369912396767176
[Epoch 9, Batch 500] loss: 0.03569088836782612
[Epoch 9, Batch 600] loss: 0.02935251340153627
[Epoch 9, Batch 700] loss: 0.027873386612627657
**STATS for Epoch 9** : 
Average training loss: 0.0019
Average validation loss: 0.0417
Validation Accuracy: 0.9867
Overfitting: 0.0398
Best model saved at epoch 9 with validation loss: 0.0417
[Epoch 10, Batch 100] loss: 0.023810736421728505
[Epoch 10, Batch 200] loss: 0.030468892990611493
[Epoch 10, Batch 300] loss: 0.025043204939574935
[Epoch 10, Batch 400] loss: 0.02508289443096146
[Epoch 10, Batch 500] loss: 0.021081850569462404
[Epoch 10, Batch 600] loss: 0.02379332149459515
[Epoch 10, Batch 700] loss: 0.032687636612681675
**STATS for Epoch 10** : 
Average training loss: 0.0013
Average validation loss: 0.0409
Validation Accuracy: 0.9876
Overfitting: 0.0396
Best model saved at epoch 10 with validation loss: 0.0409
[Epoch 11, Batch 100] loss: 0.018454548834997694
[Epoch 11, Batch 200] loss: 0.019875448350503575
[Epoch 11, Batch 300] loss: 0.02167035092948936
[Epoch 11, Batch 400] loss: 0.021424150465172716
[Epoch 11, Batch 500] loss: 0.01863664571166737
[Epoch 11, Batch 600] loss: 0.024620578000321983
[Epoch 11, Batch 700] loss: 0.03320022996980697
**STATS for Epoch 11** : 
Average training loss: 0.0015
Average validation loss: 0.0427
Validation Accuracy: 0.9868
Overfitting: 0.0412
[Epoch 12, Batch 100] loss: 0.015300552211410832
[Epoch 12, Batch 200] loss: 0.026926904476131313
[Epoch 12, Batch 300] loss: 0.01723179893451743
[Epoch 12, Batch 400] loss: 0.01936325441172812
[Epoch 12, Batch 500] loss: 0.020808378938818352
[Epoch 12, Batch 600] loss: 0.020934537324646955
[Epoch 12, Batch 700] loss: 0.020048644503112882
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0396
Validation Accuracy: 0.9874
Overfitting: 0.0384
Best model saved at epoch 12 with validation loss: 0.0396
[Epoch 13, Batch 100] loss: 0.013137088552466593
[Epoch 13, Batch 200] loss: 0.011468295188678894
[Epoch 13, Batch 300] loss: 0.019679823597252833
[Epoch 13, Batch 400] loss: 0.01812141008063918
[Epoch 13, Batch 500] loss: 0.017643719759362284
[Epoch 13, Batch 600] loss: 0.01756143487582449
[Epoch 13, Batch 700] loss: 0.01733486537777935
**STATS for Epoch 13** : 
Average training loss: 0.0016
Average validation loss: 0.0361
Validation Accuracy: 0.9894
Overfitting: 0.0345
Best model saved at epoch 13 with validation loss: 0.0361
[Epoch 14, Batch 100] loss: 0.013356034251046367
[Epoch 14, Batch 200] loss: 0.014196921020920855
[Epoch 14, Batch 300] loss: 0.015990963850053958
[Epoch 14, Batch 400] loss: 0.01641444765496999
[Epoch 14, Batch 500] loss: 0.012237117890908849
[Epoch 14, Batch 600] loss: 0.013621171043196227
[Epoch 14, Batch 700] loss: 0.020356789251236476
**STATS for Epoch 14** : 
Average training loss: 0.0010
Average validation loss: 0.0569
Validation Accuracy: 0.9838
Overfitting: 0.0559
[Epoch 15, Batch 100] loss: 0.011698157942737453
[Epoch 15, Batch 200] loss: 0.01580830973922275
[Epoch 15, Batch 300] loss: 0.010006126703956397
[Epoch 15, Batch 400] loss: 0.013513372229645028
[Epoch 15, Batch 500] loss: 0.011777259654627415
[Epoch 15, Batch 600] loss: 0.012857952910271706
[Epoch 15, Batch 700] loss: 0.013975028056447627
**STATS for Epoch 15** : 
Average training loss: 0.0016
Average validation loss: 0.0483
Validation Accuracy: 0.9854
Overfitting: 0.0467
[Epoch 16, Batch 100] loss: 0.01015687573919422
[Epoch 16, Batch 200] loss: 0.010147043054166716
[Epoch 16, Batch 300] loss: 0.016050377791689243
[Epoch 16, Batch 400] loss: 0.014487037926155608
[Epoch 16, Batch 500] loss: 0.014449303999863333
[Epoch 16, Batch 600] loss: 0.01008080285962933
[Epoch 16, Batch 700] loss: 0.011322837430634536
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0409
Validation Accuracy: 0.9882
Overfitting: 0.0399
[Epoch 17, Batch 100] loss: 0.011075673341401852
[Epoch 17, Batch 200] loss: 0.009216018260194686
[Epoch 17, Batch 300] loss: 0.010041128777447738
[Epoch 17, Batch 400] loss: 0.00766161587642273
[Epoch 17, Batch 500] loss: 0.013581072342203697
[Epoch 17, Batch 600] loss: 0.009339264457958052
[Epoch 17, Batch 700] loss: 0.011764885904267431
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0395
Validation Accuracy: 0.9894
Overfitting: 0.0386
[Epoch 18, Batch 100] loss: 0.00560035382899514
[Epoch 18, Batch 200] loss: 0.008890868734379182
[Epoch 18, Batch 300] loss: 0.011200283981088433
[Epoch 18, Batch 400] loss: 0.008997800553624985
[Epoch 18, Batch 500] loss: 0.00852334790470195
[Epoch 18, Batch 600] loss: 0.006917245630320395
[Epoch 18, Batch 700] loss: 0.013692926599105704
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0460
Validation Accuracy: 0.9869
Overfitting: 0.0453
[Epoch 19, Batch 100] loss: 0.007375145000769408
[Epoch 19, Batch 200] loss: 0.011093272315920331
[Epoch 19, Batch 300] loss: 0.0058950195022043775
[Epoch 19, Batch 400] loss: 0.007868528067774605
[Epoch 19, Batch 500] loss: 0.008047558059624862
[Epoch 19, Batch 600] loss: 0.008685274898598437
[Epoch 19, Batch 700] loss: 0.007264338545355713
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0464
Validation Accuracy: 0.9874
Overfitting: 0.0457
[Epoch 20, Batch 100] loss: 0.008510448602974065
[Epoch 20, Batch 200] loss: 0.009002726721955696
[Epoch 20, Batch 300] loss: 0.009712813966325484
[Epoch 20, Batch 400] loss: 0.00971696015636553
[Epoch 20, Batch 500] loss: 0.005782485057497979
[Epoch 20, Batch 600] loss: 0.00552453555057582
[Epoch 20, Batch 700] loss: 0.00871203739552584
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0439
Validation Accuracy: 0.9874
Overfitting: 0.0433
[Epoch 21, Batch 100] loss: 0.006552046841898118
[Epoch 21, Batch 200] loss: 0.0050224676723519225
[Epoch 21, Batch 300] loss: 0.009955000734444185
[Epoch 21, Batch 400] loss: 0.00889688047554955
[Epoch 21, Batch 500] loss: 0.007955705302520074
[Epoch 21, Batch 600] loss: 0.009525867004231258
[Epoch 21, Batch 700] loss: 0.008971472185585298
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0420
Validation Accuracy: 0.9898
Overfitting: 0.0415
[Epoch 22, Batch 100] loss: 0.005131447959793149
[Epoch 22, Batch 200] loss: 0.004769240324021666
[Epoch 22, Batch 300] loss: 0.005499605025834171
[Epoch 22, Batch 400] loss: 0.0057131606914481384
[Epoch 22, Batch 500] loss: 0.004246584009924845
[Epoch 22, Batch 600] loss: 0.0053465907490499376
[Epoch 22, Batch 700] loss: 0.011756372769159498
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0430
Validation Accuracy: 0.9885
Overfitting: 0.0427
[Epoch 23, Batch 100] loss: 0.004288495565015182
[Epoch 23, Batch 200] loss: 0.006284007059730356
[Epoch 23, Batch 300] loss: 0.003231730735533347
[Epoch 23, Batch 400] loss: 0.006119065146867797
[Epoch 23, Batch 500] loss: 0.004221940618954249
[Epoch 23, Batch 600] loss: 0.006222738313153968
[Epoch 23, Batch 700] loss: 0.004573356132386835
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0406
Validation Accuracy: 0.9893
Overfitting: 0.0404
[Epoch 24, Batch 100] loss: 0.002362296664978203
[Epoch 24, Batch 200] loss: 0.0034670516910773586
[Epoch 24, Batch 300] loss: 0.003280927769083064
[Epoch 24, Batch 400] loss: 0.003959115815960103
[Epoch 24, Batch 500] loss: 0.0030551462909716065
[Epoch 24, Batch 600] loss: 0.003278464318245824
[Epoch 24, Batch 700] loss: 0.0054340409464566615
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0427
Validation Accuracy: 0.9897
Overfitting: 0.0425
Fold 1 validation loss: 0.0427
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.29320481300354
[Epoch 1, Batch 200] loss: 2.116948375701904
[Epoch 1, Batch 300] loss: 0.834379970729351
[Epoch 1, Batch 400] loss: 0.4219953069090843
[Epoch 1, Batch 500] loss: 0.30877800315618514
[Epoch 1, Batch 600] loss: 0.27576440263539553
[Epoch 1, Batch 700] loss: 0.21359464321285487
**STATS for Epoch 1** : 
Average training loss: 0.0116
Average validation loss: 0.1817
Validation Accuracy: 0.9438
Overfitting: 0.1701
Best model saved at epoch 1 with validation loss: 0.1817
[Epoch 2, Batch 100] loss: 0.16583717841655016
[Epoch 2, Batch 200] loss: 0.13680066172033548
[Epoch 2, Batch 300] loss: 0.13463753167539835
[Epoch 2, Batch 400] loss: 0.12474833514541388
[Epoch 2, Batch 500] loss: 0.11057229300960898
[Epoch 2, Batch 600] loss: 0.09805715874768793
[Epoch 2, Batch 700] loss: 0.09296503257006407
**STATS for Epoch 2** : 
Average training loss: 0.0064
Average validation loss: 0.1067
Validation Accuracy: 0.9653
Overfitting: 0.1002
Best model saved at epoch 2 with validation loss: 0.1067
[Epoch 3, Batch 100] loss: 0.08880514005199075
[Epoch 3, Batch 200] loss: 0.08281053552404045
[Epoch 3, Batch 300] loss: 0.08123808614443988
[Epoch 3, Batch 400] loss: 0.07786872746888548
[Epoch 3, Batch 500] loss: 0.07313721460755915
[Epoch 3, Batch 600] loss: 0.06034279190935195
[Epoch 3, Batch 700] loss: 0.06842487219022587
**STATS for Epoch 3** : 
Average training loss: 0.0052
Average validation loss: 0.0797
Validation Accuracy: 0.9762
Overfitting: 0.0744
Best model saved at epoch 3 with validation loss: 0.0797
[Epoch 4, Batch 100] loss: 0.06418630294501781
[Epoch 4, Batch 200] loss: 0.058303245003335176
[Epoch 4, Batch 300] loss: 0.053695595944300296
[Epoch 4, Batch 400] loss: 0.05892618321115151
[Epoch 4, Batch 500] loss: 0.060199007829651235
[Epoch 4, Batch 600] loss: 0.06289670139551162
[Epoch 4, Batch 700] loss: 0.05183670971309766
**STATS for Epoch 4** : 
Average training loss: 0.0038
Average validation loss: 0.0691
Validation Accuracy: 0.9795
Overfitting: 0.0653
Best model saved at epoch 4 with validation loss: 0.0691
[Epoch 5, Batch 100] loss: 0.047646134113892916
[Epoch 5, Batch 200] loss: 0.054806882871780545
[Epoch 5, Batch 300] loss: 0.04738970343023539
[Epoch 5, Batch 400] loss: 0.05330331868259236
[Epoch 5, Batch 500] loss: 0.04718102231156081
[Epoch 5, Batch 600] loss: 0.046687221301253884
[Epoch 5, Batch 700] loss: 0.04831807583919726
**STATS for Epoch 5** : 
Average training loss: 0.0028
Average validation loss: 0.0634
Validation Accuracy: 0.9808
Overfitting: 0.0606
Best model saved at epoch 5 with validation loss: 0.0634
[Epoch 6, Batch 100] loss: 0.03590074995299801
[Epoch 6, Batch 200] loss: 0.039171574141364546
[Epoch 6, Batch 300] loss: 0.04462597296223976
[Epoch 6, Batch 400] loss: 0.03416103655472398
[Epoch 6, Batch 500] loss: 0.0428716914425604
[Epoch 6, Batch 600] loss: 0.04013489255332388
[Epoch 6, Batch 700] loss: 0.04719772832700983
**STATS for Epoch 6** : 
Average training loss: 0.0032
Average validation loss: 0.0539
Validation Accuracy: 0.9840
Overfitting: 0.0506
Best model saved at epoch 6 with validation loss: 0.0539
[Epoch 7, Batch 100] loss: 0.03391577246948145
[Epoch 7, Batch 200] loss: 0.036629336590413
[Epoch 7, Batch 300] loss: 0.04107881986303255
[Epoch 7, Batch 400] loss: 0.02583702311734669
[Epoch 7, Batch 500] loss: 0.044935186778893695
[Epoch 7, Batch 600] loss: 0.03938013174571097
[Epoch 7, Batch 700] loss: 0.04073857585899532
**STATS for Epoch 7** : 
Average training loss: 0.0014
Average validation loss: 0.0566
Validation Accuracy: 0.9833
Overfitting: 0.0553
[Epoch 8, Batch 100] loss: 0.026819077171967364
[Epoch 8, Batch 200] loss: 0.03934218278736808
[Epoch 8, Batch 300] loss: 0.03221070789848454
[Epoch 8, Batch 400] loss: 0.027528139831265435
[Epoch 8, Batch 500] loss: 0.027519677642267197
[Epoch 8, Batch 600] loss: 0.03017700048512779
[Epoch 8, Batch 700] loss: 0.03170383358723484
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0539
Validation Accuracy: 0.9843
Overfitting: 0.0519
[Epoch 9, Batch 100] loss: 0.02781805406557396
[Epoch 9, Batch 200] loss: 0.026004337347694674
[Epoch 9, Batch 300] loss: 0.024636381096206604
[Epoch 9, Batch 400] loss: 0.0284088599140523
[Epoch 9, Batch 500] loss: 0.030371092118439264
[Epoch 9, Batch 600] loss: 0.02459286671830341
[Epoch 9, Batch 700] loss: 0.029704439226770775
**STATS for Epoch 9** : 
Average training loss: 0.0017
Average validation loss: 0.0559
Validation Accuracy: 0.9840
Overfitting: 0.0542
[Epoch 10, Batch 100] loss: 0.02033207247091923
[Epoch 10, Batch 200] loss: 0.021431726157024968
[Epoch 10, Batch 300] loss: 0.02549880767823197
[Epoch 10, Batch 400] loss: 0.020151214118814095
[Epoch 10, Batch 500] loss: 0.024938972388335968
[Epoch 10, Batch 600] loss: 0.027731617293320597
[Epoch 10, Batch 700] loss: 0.02886627901578322
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0522
Validation Accuracy: 0.9860
Overfitting: 0.0506
Best model saved at epoch 10 with validation loss: 0.0522
[Epoch 11, Batch 100] loss: 0.023375952641945332
[Epoch 11, Batch 200] loss: 0.020244139298447407
[Epoch 11, Batch 300] loss: 0.019820525189570618
[Epoch 11, Batch 400] loss: 0.02691925864899531
[Epoch 11, Batch 500] loss: 0.017073899761016947
[Epoch 11, Batch 600] loss: 0.021082327085896396
[Epoch 11, Batch 700] loss: 0.014854726647317875
**STATS for Epoch 11** : 
Average training loss: 0.0013
Average validation loss: 0.0547
Validation Accuracy: 0.9851
Overfitting: 0.0533
[Epoch 12, Batch 100] loss: 0.015831584634433966
[Epoch 12, Batch 200] loss: 0.014903270563227124
[Epoch 12, Batch 300] loss: 0.020448572575696745
[Epoch 12, Batch 400] loss: 0.018727890285372268
[Epoch 12, Batch 500] loss: 0.018564671148196793
[Epoch 12, Batch 600] loss: 0.022161164204590023
[Epoch 12, Batch 700] loss: 0.0173100020410493
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0468
Validation Accuracy: 0.9875
Overfitting: 0.0456
Best model saved at epoch 12 with validation loss: 0.0468
[Epoch 13, Batch 100] loss: 0.01289016758732032
[Epoch 13, Batch 200] loss: 0.013851727494475198
[Epoch 13, Batch 300] loss: 0.017876056607055945
[Epoch 13, Batch 400] loss: 0.019046872793114743
[Epoch 13, Batch 500] loss: 0.014550792101363185
[Epoch 13, Batch 600] loss: 0.020656042440823513
[Epoch 13, Batch 700] loss: 0.018759139772155323
**STATS for Epoch 13** : 
Average training loss: 0.0015
Average validation loss: 0.0578
Validation Accuracy: 0.9845
Overfitting: 0.0563
[Epoch 14, Batch 100] loss: 0.013141266196616925
[Epoch 14, Batch 200] loss: 0.014233437479997519
[Epoch 14, Batch 300] loss: 0.011494901194528211
[Epoch 14, Batch 400] loss: 0.016005215284239968
[Epoch 14, Batch 500] loss: 0.01828526914905524
[Epoch 14, Batch 600] loss: 0.015424772395344916
[Epoch 14, Batch 700] loss: 0.012455627875169739
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0573
Validation Accuracy: 0.9848
Overfitting: 0.0564
[Epoch 15, Batch 100] loss: 0.010692562659678516
[Epoch 15, Batch 200] loss: 0.008715419587169891
[Epoch 15, Batch 300] loss: 0.0162530111495289
[Epoch 15, Batch 400] loss: 0.010643165162036894
[Epoch 15, Batch 500] loss: 0.01086543994373642
[Epoch 15, Batch 600] loss: 0.011453810983512084
[Epoch 15, Batch 700] loss: 0.013986765426961938
**STATS for Epoch 15** : 
Average training loss: 0.0011
Average validation loss: 0.0510
Validation Accuracy: 0.9856
Overfitting: 0.0499
[Epoch 16, Batch 100] loss: 0.009853507434163475
[Epoch 16, Batch 200] loss: 0.009997673472680617
[Epoch 16, Batch 300] loss: 0.009696083551971242
[Epoch 16, Batch 400] loss: 0.010127711897075642
[Epoch 16, Batch 500] loss: 0.010099558366346174
[Epoch 16, Batch 600] loss: 0.016597023583308328
[Epoch 16, Batch 700] loss: 0.013515665033191909
**STATS for Epoch 16** : 
Average training loss: 0.0008
Average validation loss: 0.0539
Validation Accuracy: 0.9867
Overfitting: 0.0531
[Epoch 17, Batch 100] loss: 0.010810496800258989
[Epoch 17, Batch 200] loss: 0.007793174418111448
[Epoch 17, Batch 300] loss: 0.006427667782554635
[Epoch 17, Batch 400] loss: 0.013817904273309978
[Epoch 17, Batch 500] loss: 0.013868645410693716
[Epoch 17, Batch 600] loss: 0.009009568522742484
[Epoch 17, Batch 700] loss: 0.00851977987898863
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0564
Validation Accuracy: 0.9848
Overfitting: 0.0558
[Epoch 18, Batch 100] loss: 0.007356916221106076
[Epoch 18, Batch 200] loss: 0.006526722240596428
[Epoch 18, Batch 300] loss: 0.012117860076723446
[Epoch 18, Batch 400] loss: 0.010996263458800969
[Epoch 18, Batch 500] loss: 0.010834592087994678
[Epoch 18, Batch 600] loss: 0.014768859666364733
[Epoch 18, Batch 700] loss: 0.007933837708551437
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0504
Validation Accuracy: 0.9865
Overfitting: 0.0498
[Epoch 19, Batch 100] loss: 0.007269709253887413
[Epoch 19, Batch 200] loss: 0.007049212919155252
[Epoch 19, Batch 300] loss: 0.005382366805752099
[Epoch 19, Batch 400] loss: 0.007695999192783347
[Epoch 19, Batch 500] loss: 0.0076257575744966746
[Epoch 19, Batch 600] loss: 0.007578914779733168
[Epoch 19, Batch 700] loss: 0.007308435771810764
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0552
Validation Accuracy: 0.9859
Overfitting: 0.0545
[Epoch 20, Batch 100] loss: 0.006165969301073346
[Epoch 20, Batch 200] loss: 0.007345883796442649
[Epoch 20, Batch 300] loss: 0.005757713619659626
[Epoch 20, Batch 400] loss: 0.008017476787717897
[Epoch 20, Batch 500] loss: 0.005387799215568521
[Epoch 20, Batch 600] loss: 0.004282099514075526
[Epoch 20, Batch 700] loss: 0.0068538181235635424
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0512
Validation Accuracy: 0.9879
Overfitting: 0.0508
[Epoch 21, Batch 100] loss: 0.003534053357434459
[Epoch 21, Batch 200] loss: 0.004615038846604875
[Epoch 21, Batch 300] loss: 0.005647786373865529
[Epoch 21, Batch 400] loss: 0.0046405188120661476
[Epoch 21, Batch 500] loss: 0.008746927322717965
[Epoch 21, Batch 600] loss: 0.008503942617007852
[Epoch 21, Batch 700] loss: 0.006147248348815993
**STATS for Epoch 21** : 
Average training loss: 0.0008
Average validation loss: 0.0584
Validation Accuracy: 0.9847
Overfitting: 0.0576
[Epoch 22, Batch 100] loss: 0.004949379496465554
[Epoch 22, Batch 200] loss: 0.0038603318366222084
[Epoch 22, Batch 300] loss: 0.005890808065469173
[Epoch 22, Batch 400] loss: 0.005207372769800714
[Epoch 22, Batch 500] loss: 0.0041039822339189415
[Epoch 22, Batch 600] loss: 0.003461310058628442
[Epoch 22, Batch 700] loss: 0.004426018949670834
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0552
Validation Accuracy: 0.9872
Overfitting: 0.0549
[Epoch 23, Batch 100] loss: 0.002910865828835085
[Epoch 23, Batch 200] loss: 0.0048750180118167915
[Epoch 23, Batch 300] loss: 0.002643447462014592
[Epoch 23, Batch 400] loss: 0.0023586376107232352
[Epoch 23, Batch 500] loss: 0.0031394188974627466
[Epoch 23, Batch 600] loss: 0.00249502509526792
[Epoch 23, Batch 700] loss: 0.0037713666065610596
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0558
Validation Accuracy: 0.9879
Overfitting: 0.0557
[Epoch 24, Batch 100] loss: 0.0019294814719614806
[Epoch 24, Batch 200] loss: 0.001990121067037762
[Epoch 24, Batch 300] loss: 0.0014809682960003556
[Epoch 24, Batch 400] loss: 0.0015142847041897767
[Epoch 24, Batch 500] loss: 0.003484138470594189
[Epoch 24, Batch 600] loss: 0.003479009751645208
[Epoch 24, Batch 700] loss: 0.0031441160568829217
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0590
Validation Accuracy: 0.9868
Overfitting: 0.0588
Fold 2 validation loss: 0.0590
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2767692828178405
[Epoch 1, Batch 200] loss: 1.4854850709438323
[Epoch 1, Batch 300] loss: 0.5168162094056606
[Epoch 1, Batch 400] loss: 0.3507561552524567
[Epoch 1, Batch 500] loss: 0.2707691314816475
[Epoch 1, Batch 600] loss: 0.2409077437222004
[Epoch 1, Batch 700] loss: 0.1830081132799387
**STATS for Epoch 1** : 
Average training loss: 0.0108
Average validation loss: 0.1678
Validation Accuracy: 0.9487
Overfitting: 0.1570
Best model saved at epoch 1 with validation loss: 0.1678
[Epoch 2, Batch 100] loss: 0.1501187113672495
[Epoch 2, Batch 200] loss: 0.14610226538032292
[Epoch 2, Batch 300] loss: 0.12053059730678797
[Epoch 2, Batch 400] loss: 0.1288923182338476
[Epoch 2, Batch 500] loss: 0.10546794006600976
[Epoch 2, Batch 600] loss: 0.10770413732156157
[Epoch 2, Batch 700] loss: 0.10108835419639944
**STATS for Epoch 2** : 
Average training loss: 0.0069
Average validation loss: 0.0999
Validation Accuracy: 0.9688
Overfitting: 0.0930
Best model saved at epoch 2 with validation loss: 0.0999
[Epoch 3, Batch 100] loss: 0.08429199042264372
[Epoch 3, Batch 200] loss: 0.08053042077459395
[Epoch 3, Batch 300] loss: 0.07958672251552343
[Epoch 3, Batch 400] loss: 0.08446326363831759
[Epoch 3, Batch 500] loss: 0.07705645749345422
[Epoch 3, Batch 600] loss: 0.07818550917319954
[Epoch 3, Batch 700] loss: 0.08576255927793681
**STATS for Epoch 3** : 
Average training loss: 0.0051
Average validation loss: 0.0750
Validation Accuracy: 0.9752
Overfitting: 0.0700
Best model saved at epoch 3 with validation loss: 0.0750
[Epoch 4, Batch 100] loss: 0.06476295751519501
[Epoch 4, Batch 200] loss: 0.05972748965024948
[Epoch 4, Batch 300] loss: 0.06665058739949017
[Epoch 4, Batch 400] loss: 0.07059326530434192
[Epoch 4, Batch 500] loss: 0.06335081397322938
[Epoch 4, Batch 600] loss: 0.06206107773818076
[Epoch 4, Batch 700] loss: 0.06719573237933218
**STATS for Epoch 4** : 
Average training loss: 0.0036
Average validation loss: 0.0653
Validation Accuracy: 0.9798
Overfitting: 0.0617
Best model saved at epoch 4 with validation loss: 0.0653
[Epoch 5, Batch 100] loss: 0.04669826728990301
[Epoch 5, Batch 200] loss: 0.04685869568493217
[Epoch 5, Batch 300] loss: 0.05092156805214472
[Epoch 5, Batch 400] loss: 0.054736075736582276
[Epoch 5, Batch 500] loss: 0.05369308061897755
[Epoch 5, Batch 600] loss: 0.058684837219771
[Epoch 5, Batch 700] loss: 0.05573218731209636
**STATS for Epoch 5** : 
Average training loss: 0.0034
Average validation loss: 0.0541
Validation Accuracy: 0.9840
Overfitting: 0.0507
Best model saved at epoch 5 with validation loss: 0.0541
[Epoch 6, Batch 100] loss: 0.03734127557836473
[Epoch 6, Batch 200] loss: 0.04411061049439013
[Epoch 6, Batch 300] loss: 0.049861490898765626
[Epoch 6, Batch 400] loss: 0.04773620272288099
[Epoch 6, Batch 500] loss: 0.04616265785880387
[Epoch 6, Batch 600] loss: 0.0371883220016025
[Epoch 6, Batch 700] loss: 0.038750451451633125
**STATS for Epoch 6** : 
Average training loss: 0.0034
Average validation loss: 0.0549
Validation Accuracy: 0.9824
Overfitting: 0.0515
[Epoch 7, Batch 100] loss: 0.0360283556394279
[Epoch 7, Batch 200] loss: 0.029771243075374515
[Epoch 7, Batch 300] loss: 0.04436771534907166
[Epoch 7, Batch 400] loss: 0.03816586314700544
[Epoch 7, Batch 500] loss: 0.03152424826635979
[Epoch 7, Batch 600] loss: 0.03602181975962594
[Epoch 7, Batch 700] loss: 0.03964673485606909
**STATS for Epoch 7** : 
Average training loss: 0.0032
Average validation loss: 0.0498
Validation Accuracy: 0.9850
Overfitting: 0.0466
Best model saved at epoch 7 with validation loss: 0.0498
[Epoch 8, Batch 100] loss: 0.02620539140305482
[Epoch 8, Batch 200] loss: 0.024613866302534006
[Epoch 8, Batch 300] loss: 0.04374594465072732
[Epoch 8, Batch 400] loss: 0.0360688757407479
[Epoch 8, Batch 500] loss: 0.03649923380115069
[Epoch 8, Batch 600] loss: 0.03462544628011528
[Epoch 8, Batch 700] loss: 0.034561538884881886
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0477
Validation Accuracy: 0.9850
Overfitting: 0.0459
Best model saved at epoch 8 with validation loss: 0.0477
[Epoch 9, Batch 100] loss: 0.024648175936890768
[Epoch 9, Batch 200] loss: 0.02948171837895643
[Epoch 9, Batch 300] loss: 0.03224183318379801
[Epoch 9, Batch 400] loss: 0.029583332777256145
[Epoch 9, Batch 500] loss: 0.030452518458478153
[Epoch 9, Batch 600] loss: 0.023638347532250917
[Epoch 9, Batch 700] loss: 0.02932213946158299
**STATS for Epoch 9** : 
Average training loss: 0.0021
Average validation loss: 0.0477
Validation Accuracy: 0.9857
Overfitting: 0.0456
Best model saved at epoch 9 with validation loss: 0.0477
[Epoch 10, Batch 100] loss: 0.021802220222307368
[Epoch 10, Batch 200] loss: 0.020447621594939847
[Epoch 10, Batch 300] loss: 0.020458833922457415
[Epoch 10, Batch 400] loss: 0.02988203077984508
[Epoch 10, Batch 500] loss: 0.025721823853673415
[Epoch 10, Batch 600] loss: 0.029763912996277214
[Epoch 10, Batch 700] loss: 0.02613112217921298
**STATS for Epoch 10** : 
Average training loss: 0.0018
Average validation loss: 0.0502
Validation Accuracy: 0.9852
Overfitting: 0.0484
[Epoch 11, Batch 100] loss: 0.02261331374873407
[Epoch 11, Batch 200] loss: 0.01818458540685242
[Epoch 11, Batch 300] loss: 0.02239441281009931
[Epoch 11, Batch 400] loss: 0.023071564813144506
[Epoch 11, Batch 500] loss: 0.02126283719437197
[Epoch 11, Batch 600] loss: 0.026003485861583613
[Epoch 11, Batch 700] loss: 0.02258807671314571
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0449
Validation Accuracy: 0.9870
Overfitting: 0.0437
Best model saved at epoch 11 with validation loss: 0.0449
[Epoch 12, Batch 100] loss: 0.016035599027527495
[Epoch 12, Batch 200] loss: 0.01763512930367142
[Epoch 12, Batch 300] loss: 0.015493391029594931
[Epoch 12, Batch 400] loss: 0.01962811947130831
[Epoch 12, Batch 500] loss: 0.021222275582840667
[Epoch 12, Batch 600] loss: 0.022083284602558706
[Epoch 12, Batch 700] loss: 0.02288739712101233
**STATS for Epoch 12** : 
Average training loss: 0.0016
Average validation loss: 0.0468
Validation Accuracy: 0.9864
Overfitting: 0.0451
[Epoch 13, Batch 100] loss: 0.015544103919528424
[Epoch 13, Batch 200] loss: 0.01220141346566379
[Epoch 13, Batch 300] loss: 0.01833764941751724
[Epoch 13, Batch 400] loss: 0.018721275590069128
[Epoch 13, Batch 500] loss: 0.02031230062886607
[Epoch 13, Batch 600] loss: 0.01794410577043891
[Epoch 13, Batch 700] loss: 0.016641380620421843
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0441
Validation Accuracy: 0.9872
Overfitting: 0.0430
Best model saved at epoch 13 with validation loss: 0.0441
[Epoch 14, Batch 100] loss: 0.013222262310737278
[Epoch 14, Batch 200] loss: 0.015149399296496995
[Epoch 14, Batch 300] loss: 0.019342360752052628
[Epoch 14, Batch 400] loss: 0.013757205867150332
[Epoch 14, Batch 500] loss: 0.018732077321619727
[Epoch 14, Batch 600] loss: 0.021064054299786222
[Epoch 14, Batch 700] loss: 0.01580422122933669
**STATS for Epoch 14** : 
Average training loss: 0.0013
Average validation loss: 0.0530
Validation Accuracy: 0.9843
Overfitting: 0.0517
[Epoch 15, Batch 100] loss: 0.015471034077054356
[Epoch 15, Batch 200] loss: 0.012933736486447743
[Epoch 15, Batch 300] loss: 0.013310517242571223
[Epoch 15, Batch 400] loss: 0.018984409343538573
[Epoch 15, Batch 500] loss: 0.012276260908110999
[Epoch 15, Batch 600] loss: 0.01187542790423322
[Epoch 15, Batch 700] loss: 0.012588176402496175
**STATS for Epoch 15** : 
Average training loss: 0.0014
Average validation loss: 0.0501
Validation Accuracy: 0.9872
Overfitting: 0.0487
[Epoch 16, Batch 100] loss: 0.009956875420029973
[Epoch 16, Batch 200] loss: 0.013632771068660076
[Epoch 16, Batch 300] loss: 0.00990566822787514
[Epoch 16, Batch 400] loss: 0.010898181648481114
[Epoch 16, Batch 500] loss: 0.012883371902134969
[Epoch 16, Batch 600] loss: 0.011696249571978115
[Epoch 16, Batch 700] loss: 0.013499037788060378
**STATS for Epoch 16** : 
Average training loss: 0.0011
Average validation loss: 0.0566
Validation Accuracy: 0.9842
Overfitting: 0.0556
[Epoch 17, Batch 100] loss: 0.0113748788688099
[Epoch 17, Batch 200] loss: 0.01031471959377086
[Epoch 17, Batch 300] loss: 0.00849734712362988
[Epoch 17, Batch 400] loss: 0.008289626011974178
[Epoch 17, Batch 500] loss: 0.007112301627566922
[Epoch 17, Batch 600] loss: 0.009789693048587652
[Epoch 17, Batch 700] loss: 0.01375001879343472
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0533
Validation Accuracy: 0.9862
Overfitting: 0.0526
[Epoch 18, Batch 100] loss: 0.010306162772903917
[Epoch 18, Batch 200] loss: 0.010356717065296834
[Epoch 18, Batch 300] loss: 0.00885530801700952
[Epoch 18, Batch 400] loss: 0.011785784484964097
[Epoch 18, Batch 500] loss: 0.00807784218530287
[Epoch 18, Batch 600] loss: 0.010939981332339812
[Epoch 18, Batch 700] loss: 0.008562614164693514
**STATS for Epoch 18** : 
Average training loss: 0.0014
Average validation loss: 0.0503
Validation Accuracy: 0.9872
Overfitting: 0.0489
[Epoch 19, Batch 100] loss: 0.009081361198623199
[Epoch 19, Batch 200] loss: 0.008771246841570246
[Epoch 19, Batch 300] loss: 0.009788025035595638
[Epoch 19, Batch 400] loss: 0.009485294210753637
[Epoch 19, Batch 500] loss: 0.006670374862951575
[Epoch 19, Batch 600] loss: 0.006394022689637496
[Epoch 19, Batch 700] loss: 0.009256615706253796
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0555
Validation Accuracy: 0.9863
Overfitting: 0.0548
[Epoch 20, Batch 100] loss: 0.00655811276184977
[Epoch 20, Batch 200] loss: 0.005167481619864702
[Epoch 20, Batch 300] loss: 0.0048335276330180935
[Epoch 20, Batch 400] loss: 0.006305041969899321
[Epoch 20, Batch 500] loss: 0.006466261198220309
[Epoch 20, Batch 600] loss: 0.009475806300761178
[Epoch 20, Batch 700] loss: 0.0061446696268103555
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0583
Validation Accuracy: 0.9855
Overfitting: 0.0578
[Epoch 21, Batch 100] loss: 0.0063050726143410426
[Epoch 21, Batch 200] loss: 0.006331483309350005
[Epoch 21, Batch 300] loss: 0.004060077120848291
[Epoch 21, Batch 400] loss: 0.005688625668117311
[Epoch 21, Batch 500] loss: 0.0068432205618046285
[Epoch 21, Batch 600] loss: 0.005308579871079928
[Epoch 21, Batch 700] loss: 0.005953553733370427
**STATS for Epoch 21** : 
Average training loss: 0.0008
Average validation loss: 0.0511
Validation Accuracy: 0.9877
Overfitting: 0.0502
[Epoch 22, Batch 100] loss: 0.006751246081912541
[Epoch 22, Batch 200] loss: 0.006949734742493092
[Epoch 22, Batch 300] loss: 0.0042630789652503154
[Epoch 22, Batch 400] loss: 0.004698303910590767
[Epoch 22, Batch 500] loss: 0.006597688440597267
[Epoch 22, Batch 600] loss: 0.006226421937826672
[Epoch 22, Batch 700] loss: 0.004286069046356715
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0474
Validation Accuracy: 0.9885
Overfitting: 0.0468
[Epoch 23, Batch 100] loss: 0.002155866422035615
[Epoch 23, Batch 200] loss: 0.004154030623176368
[Epoch 23, Batch 300] loss: 0.0021635168933789826
[Epoch 23, Batch 400] loss: 0.002918357316812035
[Epoch 23, Batch 500] loss: 0.003209007698460482
[Epoch 23, Batch 600] loss: 0.005519808870558336
[Epoch 23, Batch 700] loss: 0.0076386277575875286
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0486
Validation Accuracy: 0.9891
Overfitting: 0.0482
[Epoch 24, Batch 100] loss: 0.0034332455638286775
[Epoch 24, Batch 200] loss: 0.0024585244035552024
[Epoch 24, Batch 300] loss: 0.003946968394711803
[Epoch 24, Batch 400] loss: 0.008213034013424476
[Epoch 24, Batch 500] loss: 0.007612595287396289
[Epoch 24, Batch 600] loss: 0.004009925614063832
[Epoch 24, Batch 700] loss: 0.004761275142336672
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0515
Validation Accuracy: 0.9879
Overfitting: 0.0511
Fold 3 validation loss: 0.0515
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2109151482582092
[Epoch 1, Batch 200] loss: 0.9186322641372681
[Epoch 1, Batch 300] loss: 0.4067283730208874
[Epoch 1, Batch 400] loss: 0.30587051570415497
[Epoch 1, Batch 500] loss: 0.22794497314840556
[Epoch 1, Batch 600] loss: 0.20573140796273948
[Epoch 1, Batch 700] loss: 0.1840557761117816
**STATS for Epoch 1** : 
Average training loss: 0.0117
Average validation loss: 0.1607
Validation Accuracy: 0.9492
Overfitting: 0.1490
Best model saved at epoch 1 with validation loss: 0.1607
[Epoch 2, Batch 100] loss: 0.1334180840011686
[Epoch 2, Batch 200] loss: 0.1340484332293272
[Epoch 2, Batch 300] loss: 0.14083191514015198
[Epoch 2, Batch 400] loss: 0.12352485736832022
[Epoch 2, Batch 500] loss: 0.10402082663029433
[Epoch 2, Batch 600] loss: 0.0937171009927988
[Epoch 2, Batch 700] loss: 0.09751549030654133
**STATS for Epoch 2** : 
Average training loss: 0.0068
Average validation loss: 0.0897
Validation Accuracy: 0.9726
Overfitting: 0.0829
Best model saved at epoch 2 with validation loss: 0.0897
[Epoch 3, Batch 100] loss: 0.0924030285794288
[Epoch 3, Batch 200] loss: 0.08448226574342697
[Epoch 3, Batch 300] loss: 0.08849970211274921
[Epoch 3, Batch 400] loss: 0.0874190184660256
[Epoch 3, Batch 500] loss: 0.0639047922939062
[Epoch 3, Batch 600] loss: 0.07337589139584452
[Epoch 3, Batch 700] loss: 0.07063450293149799
**STATS for Epoch 3** : 
Average training loss: 0.0048
Average validation loss: 0.0697
Validation Accuracy: 0.9785
Overfitting: 0.0650
Best model saved at epoch 3 with validation loss: 0.0697
[Epoch 4, Batch 100] loss: 0.06242404060438275
[Epoch 4, Batch 200] loss: 0.05994330643676221
[Epoch 4, Batch 300] loss: 0.07655976339243352
[Epoch 4, Batch 400] loss: 0.06570519079454243
[Epoch 4, Batch 500] loss: 0.069621834193822
[Epoch 4, Batch 600] loss: 0.05679842953570187
[Epoch 4, Batch 700] loss: 0.06322377617936581
**STATS for Epoch 4** : 
Average training loss: 0.0044
Average validation loss: 0.0689
Validation Accuracy: 0.9779
Overfitting: 0.0645
Best model saved at epoch 4 with validation loss: 0.0689
[Epoch 5, Batch 100] loss: 0.05236552481073886
[Epoch 5, Batch 200] loss: 0.049133346846792846
[Epoch 5, Batch 300] loss: 0.05448728641262278
[Epoch 5, Batch 400] loss: 0.04948066519573331
[Epoch 5, Batch 500] loss: 0.04737664458341897
[Epoch 5, Batch 600] loss: 0.06130481215193868
[Epoch 5, Batch 700] loss: 0.050259406794793904
**STATS for Epoch 5** : 
Average training loss: 0.0035
Average validation loss: 0.0572
Validation Accuracy: 0.9821
Overfitting: 0.0536
Best model saved at epoch 5 with validation loss: 0.0572
[Epoch 6, Batch 100] loss: 0.04749517746735364
[Epoch 6, Batch 200] loss: 0.050441571564879266
[Epoch 6, Batch 300] loss: 0.04379505892517045
[Epoch 6, Batch 400] loss: 0.0381094074388966
[Epoch 6, Batch 500] loss: 0.039627431666012854
[Epoch 6, Batch 600] loss: 0.045820725737139585
[Epoch 6, Batch 700] loss: 0.04826003898400813
**STATS for Epoch 6** : 
Average training loss: 0.0026
Average validation loss: 0.0515
Validation Accuracy: 0.9824
Overfitting: 0.0489
Best model saved at epoch 6 with validation loss: 0.0515
[Epoch 7, Batch 100] loss: 0.03829673289437778
[Epoch 7, Batch 200] loss: 0.033707536128349605
[Epoch 7, Batch 300] loss: 0.04604683362180367
[Epoch 7, Batch 400] loss: 0.03841372949304059
[Epoch 7, Batch 500] loss: 0.034183837859891354
[Epoch 7, Batch 600] loss: 0.03682922372594476
[Epoch 7, Batch 700] loss: 0.037983732565189714
**STATS for Epoch 7** : 
Average training loss: 0.0029
Average validation loss: 0.0516
Validation Accuracy: 0.9842
Overfitting: 0.0487
[Epoch 8, Batch 100] loss: 0.032524795320932755
[Epoch 8, Batch 200] loss: 0.03067965087480843
[Epoch 8, Batch 300] loss: 0.026545857205055656
[Epoch 8, Batch 400] loss: 0.03578252554754727
[Epoch 8, Batch 500] loss: 0.032724500790936875
[Epoch 8, Batch 600] loss: 0.03820928805158474
[Epoch 8, Batch 700] loss: 0.03803017944213934
**STATS for Epoch 8** : 
Average training loss: 0.0023
Average validation loss: 0.0534
Validation Accuracy: 0.9833
Overfitting: 0.0511
[Epoch 9, Batch 100] loss: 0.027185783886234275
[Epoch 9, Batch 200] loss: 0.02771334875666071
[Epoch 9, Batch 300] loss: 0.027488680392852984
[Epoch 9, Batch 400] loss: 0.03732313711778261
[Epoch 9, Batch 500] loss: 0.031235842043533923
[Epoch 9, Batch 600] loss: 0.03536641381215304
[Epoch 9, Batch 700] loss: 0.019356794445775448
**STATS for Epoch 9** : 
Average training loss: 0.0024
Average validation loss: 0.0523
Validation Accuracy: 0.9850
Overfitting: 0.0500
[Epoch 10, Batch 100] loss: 0.024600088839652017
[Epoch 10, Batch 200] loss: 0.0253693986532744
[Epoch 10, Batch 300] loss: 0.022095958878635427
[Epoch 10, Batch 400] loss: 0.02462765194475651
[Epoch 10, Batch 500] loss: 0.031333530665724536
[Epoch 10, Batch 600] loss: 0.029963119578314944
[Epoch 10, Batch 700] loss: 0.022898355989018456
**STATS for Epoch 10** : 
Average training loss: 0.0019
Average validation loss: 0.0525
Validation Accuracy: 0.9842
Overfitting: 0.0505
[Epoch 11, Batch 100] loss: 0.019730207711691036
[Epoch 11, Batch 200] loss: 0.02218752048211172
[Epoch 11, Batch 300] loss: 0.02358367741398979
[Epoch 11, Batch 400] loss: 0.025592094898456708
[Epoch 11, Batch 500] loss: 0.022616410269401966
[Epoch 11, Batch 600] loss: 0.026015873565047514
[Epoch 11, Batch 700] loss: 0.02237086702385568
**STATS for Epoch 11** : 
Average training loss: 0.0015
Average validation loss: 0.0470
Validation Accuracy: 0.9851
Overfitting: 0.0455
Best model saved at epoch 11 with validation loss: 0.0470
[Epoch 12, Batch 100] loss: 0.019555821155081504
[Epoch 12, Batch 200] loss: 0.02306703871639911
[Epoch 12, Batch 300] loss: 0.017502135227259713
[Epoch 12, Batch 400] loss: 0.020084950185846537
[Epoch 12, Batch 500] loss: 0.015030361359094968
[Epoch 12, Batch 600] loss: 0.02682976840529591
[Epoch 12, Batch 700] loss: 0.02096539049700368
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0455
Validation Accuracy: 0.9862
Overfitting: 0.0443
Best model saved at epoch 12 with validation loss: 0.0455
[Epoch 13, Batch 100] loss: 0.011490408068857505
[Epoch 13, Batch 200] loss: 0.01525841051887255
[Epoch 13, Batch 300] loss: 0.024784465293050742
[Epoch 13, Batch 400] loss: 0.022810178572544828
[Epoch 13, Batch 500] loss: 0.01777605741895968
[Epoch 13, Batch 600] loss: 0.013760645099973772
[Epoch 13, Batch 700] loss: 0.016086238646385028
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0556
Validation Accuracy: 0.9849
Overfitting: 0.0542
[Epoch 14, Batch 100] loss: 0.012673458391800523
[Epoch 14, Batch 200] loss: 0.011865569470392074
[Epoch 14, Batch 300] loss: 0.019760946337191852
[Epoch 14, Batch 400] loss: 0.017537937371525914
[Epoch 14, Batch 500] loss: 0.015475700614915695
[Epoch 14, Batch 600] loss: 0.0167424420043244
[Epoch 14, Batch 700] loss: 0.01503573836875148
**STATS for Epoch 14** : 
Average training loss: 0.0015
Average validation loss: 0.0495
Validation Accuracy: 0.9856
Overfitting: 0.0480
[Epoch 15, Batch 100] loss: 0.013445998531824443
[Epoch 15, Batch 200] loss: 0.014593295859813225
[Epoch 15, Batch 300] loss: 0.01305021212407155
[Epoch 15, Batch 400] loss: 0.011661082682549022
[Epoch 15, Batch 500] loss: 0.013000162036551046
[Epoch 15, Batch 600] loss: 0.013869843890279298
[Epoch 15, Batch 700] loss: 0.015472928386880086
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0441
Validation Accuracy: 0.9874
Overfitting: 0.0434
Best model saved at epoch 15 with validation loss: 0.0441
[Epoch 16, Batch 100] loss: 0.012310601651115576
[Epoch 16, Batch 200] loss: 0.015152258312591585
[Epoch 16, Batch 300] loss: 0.015397976787644438
[Epoch 16, Batch 400] loss: 0.008223818172991742
[Epoch 16, Batch 500] loss: 0.014259305061859778
[Epoch 16, Batch 600] loss: 0.013989606140603428
[Epoch 16, Batch 700] loss: 0.013480070829973555
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0497
Validation Accuracy: 0.9864
Overfitting: 0.0492
[Epoch 17, Batch 100] loss: 0.010686183445504866
[Epoch 17, Batch 200] loss: 0.009917320183594711
[Epoch 17, Batch 300] loss: 0.01561753772693919
[Epoch 17, Batch 400] loss: 0.011261117173271487
[Epoch 17, Batch 500] loss: 0.011615267356828553
[Epoch 17, Batch 600] loss: 0.007627301862521562
[Epoch 17, Batch 700] loss: 0.008425590050028403
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0576
Validation Accuracy: 0.9837
Overfitting: 0.0570
[Epoch 18, Batch 100] loss: 0.004912282495060935
[Epoch 18, Batch 200] loss: 0.007143474230979337
[Epoch 18, Batch 300] loss: 0.010630846039857715
[Epoch 18, Batch 400] loss: 0.013637500947879744
[Epoch 18, Batch 500] loss: 0.010393253600195749
[Epoch 18, Batch 600] loss: 0.010472502791926672
[Epoch 18, Batch 700] loss: 0.009889161248538584
**STATS for Epoch 18** : 
Average training loss: 0.0005
Average validation loss: 0.0526
Validation Accuracy: 0.9858
Overfitting: 0.0522
[Epoch 19, Batch 100] loss: 0.00875666043786623
[Epoch 19, Batch 200] loss: 0.010348862819300848
[Epoch 19, Batch 300] loss: 0.007757676611945498
[Epoch 19, Batch 400] loss: 0.0074684351534233424
[Epoch 19, Batch 500] loss: 0.007608341827508411
[Epoch 19, Batch 600] loss: 0.007976542223204888
[Epoch 19, Batch 700] loss: 0.008528860679798527
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0511
Validation Accuracy: 0.9862
Overfitting: 0.0504
[Epoch 20, Batch 100] loss: 0.007774835821182932
[Epoch 20, Batch 200] loss: 0.006055285401380388
[Epoch 20, Batch 300] loss: 0.008564437040913617
[Epoch 20, Batch 400] loss: 0.007308386436052388
[Epoch 20, Batch 500] loss: 0.006634036421528436
[Epoch 20, Batch 600] loss: 0.009586512367823161
[Epoch 20, Batch 700] loss: 0.004234734886267688
**STATS for Epoch 20** : 
Average training loss: 0.0009
Average validation loss: 0.0583
Validation Accuracy: 0.9847
Overfitting: 0.0574
[Epoch 21, Batch 100] loss: 0.007192307850127691
[Epoch 21, Batch 200] loss: 0.006719439358021191
[Epoch 21, Batch 300] loss: 0.006809415031093522
[Epoch 21, Batch 400] loss: 0.006095335563877598
[Epoch 21, Batch 500] loss: 0.006389724002001457
[Epoch 21, Batch 600] loss: 0.005396184782184719
[Epoch 21, Batch 700] loss: 0.0068364135454066855
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0515
Validation Accuracy: 0.9870
Overfitting: 0.0511
[Epoch 22, Batch 100] loss: 0.0037133586032541644
[Epoch 22, Batch 200] loss: 0.0054676069279958025
[Epoch 22, Batch 300] loss: 0.004362717212970892
[Epoch 22, Batch 400] loss: 0.00903873571247459
[Epoch 22, Batch 500] loss: 0.0082348576989898
[Epoch 22, Batch 600] loss: 0.005350793937923299
[Epoch 22, Batch 700] loss: 0.008248165480945318
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0573
Validation Accuracy: 0.9847
Overfitting: 0.0568
[Epoch 23, Batch 100] loss: 0.006755132441758178
[Epoch 23, Batch 200] loss: 0.004226992898547905
[Epoch 23, Batch 300] loss: 0.0045038875998579895
[Epoch 23, Batch 400] loss: 0.004111299984106154
[Epoch 23, Batch 500] loss: 0.0061367980628710935
[Epoch 23, Batch 600] loss: 0.0075191394215471516
[Epoch 23, Batch 700] loss: 0.004244588833025773
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0554
Validation Accuracy: 0.9868
Overfitting: 0.0552
[Epoch 24, Batch 100] loss: 0.002963399207656039
[Epoch 24, Batch 200] loss: 0.004506909378324053
[Epoch 24, Batch 300] loss: 0.0029516645937474094
[Epoch 24, Batch 400] loss: 0.004069554051675368
[Epoch 24, Batch 500] loss: 0.0024223108338355813
[Epoch 24, Batch 600] loss: 0.001883903913840186
[Epoch 24, Batch 700] loss: 0.0048215854993395625
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0524
Validation Accuracy: 0.9874
Overfitting: 0.0521
Fold 4 validation loss: 0.0524
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.292862846851349
[Epoch 1, Batch 200] loss: 2.120132791996002
[Epoch 1, Batch 300] loss: 0.7082480242848397
[Epoch 1, Batch 400] loss: 0.37074571922421456
[Epoch 1, Batch 500] loss: 0.2862452524900436
[Epoch 1, Batch 600] loss: 0.23669521681964398
[Epoch 1, Batch 700] loss: 0.19185233078897
**STATS for Epoch 1** : 
Average training loss: 0.0105
Average validation loss: 0.1863
Validation Accuracy: 0.9440
Overfitting: 0.1758
Best model saved at epoch 1 with validation loss: 0.1863
[Epoch 2, Batch 100] loss: 0.15813585927709936
[Epoch 2, Batch 200] loss: 0.13783516693860293
[Epoch 2, Batch 300] loss: 0.13167497977614404
[Epoch 2, Batch 400] loss: 0.1411861758492887
[Epoch 2, Batch 500] loss: 0.11365385286509991
[Epoch 2, Batch 600] loss: 0.10262507680803537
[Epoch 2, Batch 700] loss: 0.10240487588569522
**STATS for Epoch 2** : 
Average training loss: 0.0072
Average validation loss: 0.0961
Validation Accuracy: 0.9702
Overfitting: 0.0889
Best model saved at epoch 2 with validation loss: 0.0961
[Epoch 3, Batch 100] loss: 0.08416677194647491
[Epoch 3, Batch 200] loss: 0.09747975043021143
[Epoch 3, Batch 300] loss: 0.08907570251263679
[Epoch 3, Batch 400] loss: 0.07256696395576
[Epoch 3, Batch 500] loss: 0.07835611145012081
[Epoch 3, Batch 600] loss: 0.07766128652729094
[Epoch 3, Batch 700] loss: 0.07528175651095807
**STATS for Epoch 3** : 
Average training loss: 0.0046
Average validation loss: 0.0795
Validation Accuracy: 0.9732
Overfitting: 0.0748
Best model saved at epoch 3 with validation loss: 0.0795
[Epoch 4, Batch 100] loss: 0.07421916254330427
[Epoch 4, Batch 200] loss: 0.05811496214009822
[Epoch 4, Batch 300] loss: 0.05527417131932452
[Epoch 4, Batch 400] loss: 0.058039451390504836
[Epoch 4, Batch 500] loss: 0.05774349049665034
[Epoch 4, Batch 600] loss: 0.06240965995006263
[Epoch 4, Batch 700] loss: 0.06173725854838267
**STATS for Epoch 4** : 
Average training loss: 0.0051
Average validation loss: 0.0643
Validation Accuracy: 0.9803
Overfitting: 0.0593
Best model saved at epoch 4 with validation loss: 0.0643
[Epoch 5, Batch 100] loss: 0.04898798050824553
[Epoch 5, Batch 200] loss: 0.05129392859293148
[Epoch 5, Batch 300] loss: 0.05780091702006757
[Epoch 5, Batch 400] loss: 0.0511850731773302
[Epoch 5, Batch 500] loss: 0.05871332576498389
[Epoch 5, Batch 600] loss: 0.046290739628020675
[Epoch 5, Batch 700] loss: 0.0509220464178361
**STATS for Epoch 5** : 
Average training loss: 0.0036
Average validation loss: 0.0521
Validation Accuracy: 0.9850
Overfitting: 0.0485
Best model saved at epoch 5 with validation loss: 0.0521
[Epoch 6, Batch 100] loss: 0.037622043802402916
[Epoch 6, Batch 200] loss: 0.04392889988259412
[Epoch 6, Batch 300] loss: 0.03358093486807775
[Epoch 6, Batch 400] loss: 0.04076641204301268
[Epoch 6, Batch 500] loss: 0.05116194447735325
[Epoch 6, Batch 600] loss: 0.045176194000523535
[Epoch 6, Batch 700] loss: 0.04668404282303527
**STATS for Epoch 6** : 
Average training loss: 0.0024
Average validation loss: 0.0496
Validation Accuracy: 0.9852
Overfitting: 0.0472
Best model saved at epoch 6 with validation loss: 0.0496
[Epoch 7, Batch 100] loss: 0.03306459294864908
[Epoch 7, Batch 200] loss: 0.039000948388129474
[Epoch 7, Batch 300] loss: 0.03797647790634073
[Epoch 7, Batch 400] loss: 0.03197569439886138
[Epoch 7, Batch 500] loss: 0.033022543582483195
[Epoch 7, Batch 600] loss: 0.04117348143190611
[Epoch 7, Batch 700] loss: 0.045668034304399044
**STATS for Epoch 7** : 
Average training loss: 0.0026
Average validation loss: 0.0455
Validation Accuracy: 0.9872
Overfitting: 0.0429
Best model saved at epoch 7 with validation loss: 0.0455
[Epoch 8, Batch 100] loss: 0.03422236339654774
[Epoch 8, Batch 200] loss: 0.0321577727003023
[Epoch 8, Batch 300] loss: 0.02845502213574946
[Epoch 8, Batch 400] loss: 0.029618270796490834
[Epoch 8, Batch 500] loss: 0.03966782239964232
[Epoch 8, Batch 600] loss: 0.02929800029611215
[Epoch 8, Batch 700] loss: 0.028646414160029963
**STATS for Epoch 8** : 
Average training loss: 0.0025
Average validation loss: 0.0456
Validation Accuracy: 0.9862
Overfitting: 0.0432
[Epoch 9, Batch 100] loss: 0.025368847213685514
[Epoch 9, Batch 200] loss: 0.02320877171936445
[Epoch 9, Batch 300] loss: 0.024470266748103313
[Epoch 9, Batch 400] loss: 0.029728679794934577
[Epoch 9, Batch 500] loss: 0.031564273696858436
[Epoch 9, Batch 600] loss: 0.029636409004451705
[Epoch 9, Batch 700] loss: 0.0283276410237886
**STATS for Epoch 9** : 
Average training loss: 0.0015
Average validation loss: 0.0444
Validation Accuracy: 0.9866
Overfitting: 0.0428
Best model saved at epoch 9 with validation loss: 0.0444
[Epoch 10, Batch 100] loss: 0.020067498572170734
[Epoch 10, Batch 200] loss: 0.028138266359455884
[Epoch 10, Batch 300] loss: 0.024002489906852133
[Epoch 10, Batch 400] loss: 0.023175043411320075
[Epoch 10, Batch 500] loss: 0.026472210738575086
[Epoch 10, Batch 600] loss: 0.02454627264465671
[Epoch 10, Batch 700] loss: 0.030121137587120757
**STATS for Epoch 10** : 
Average training loss: 0.0017
Average validation loss: 0.0501
Validation Accuracy: 0.9853
Overfitting: 0.0483
[Epoch 11, Batch 100] loss: 0.022894491683109662
[Epoch 11, Batch 200] loss: 0.019232249205815607
[Epoch 11, Batch 300] loss: 0.017229057868826204
[Epoch 11, Batch 400] loss: 0.02159294676501304
[Epoch 11, Batch 500] loss: 0.018991127690824214
[Epoch 11, Batch 600] loss: 0.01886932296503801
[Epoch 11, Batch 700] loss: 0.029239628443028777
**STATS for Epoch 11** : 
Average training loss: 0.0021
Average validation loss: 0.0442
Validation Accuracy: 0.9872
Overfitting: 0.0421
Best model saved at epoch 11 with validation loss: 0.0442
[Epoch 12, Batch 100] loss: 0.014606702078890522
[Epoch 12, Batch 200] loss: 0.013721025474369526
[Epoch 12, Batch 300] loss: 0.024008540912764147
[Epoch 12, Batch 400] loss: 0.016483727243903557
[Epoch 12, Batch 500] loss: 0.017020744254114106
[Epoch 12, Batch 600] loss: 0.016801690914435313
[Epoch 12, Batch 700] loss: 0.024052372052683495
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0473
Validation Accuracy: 0.9864
Overfitting: 0.0460
[Epoch 13, Batch 100] loss: 0.015492754956067074
[Epoch 13, Batch 200] loss: 0.013843531640595756
[Epoch 13, Batch 300] loss: 0.01959184892999474
[Epoch 13, Batch 400] loss: 0.012906178109406028
[Epoch 13, Batch 500] loss: 0.02159455799963325
[Epoch 13, Batch 600] loss: 0.016648402917344356
[Epoch 13, Batch 700] loss: 0.020341785731143317
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0482
Validation Accuracy: 0.9863
Overfitting: 0.0472
[Epoch 14, Batch 100] loss: 0.015070992753608152
[Epoch 14, Batch 200] loss: 0.01585953961708583
[Epoch 14, Batch 300] loss: 0.012437448905548081
[Epoch 14, Batch 400] loss: 0.015321643901988863
[Epoch 14, Batch 500] loss: 0.013307603812136222
[Epoch 14, Batch 600] loss: 0.01683822493767366
[Epoch 14, Batch 700] loss: 0.018915574516286143
**STATS for Epoch 14** : 
Average training loss: 0.0015
Average validation loss: 0.0455
Validation Accuracy: 0.9865
Overfitting: 0.0440
[Epoch 15, Batch 100] loss: 0.013176082261488774
[Epoch 15, Batch 200] loss: 0.014046649260417326
[Epoch 15, Batch 300] loss: 0.012159104807215044
[Epoch 15, Batch 400] loss: 0.014033413980505428
[Epoch 15, Batch 500] loss: 0.013356308047368657
[Epoch 15, Batch 600] loss: 0.012184534619154874
[Epoch 15, Batch 700] loss: 0.008969466307025869
**STATS for Epoch 15** : 
Average training loss: 0.0012
Average validation loss: 0.0486
Validation Accuracy: 0.9860
Overfitting: 0.0474
[Epoch 16, Batch 100] loss: 0.009305886225483846
[Epoch 16, Batch 200] loss: 0.009361171732016373
[Epoch 16, Batch 300] loss: 0.01086392406912637
[Epoch 16, Batch 400] loss: 0.009654501950426492
[Epoch 16, Batch 500] loss: 0.013678255237755366
[Epoch 16, Batch 600] loss: 0.018756062240281608
[Epoch 16, Batch 700] loss: 0.012145357246336062
**STATS for Epoch 16** : 
Average training loss: 0.0008
Average validation loss: 0.0461
Validation Accuracy: 0.9871
Overfitting: 0.0453
[Epoch 17, Batch 100] loss: 0.009098414531617891
[Epoch 17, Batch 200] loss: 0.012660226156294812
[Epoch 17, Batch 300] loss: 0.00800750980291923
[Epoch 17, Batch 400] loss: 0.009564353307432612
[Epoch 17, Batch 500] loss: 0.00824577494910045
[Epoch 17, Batch 600] loss: 0.01763565421457315
[Epoch 17, Batch 700] loss: 0.013143510832451284
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0421
Validation Accuracy: 0.9890
Overfitting: 0.0412
Best model saved at epoch 17 with validation loss: 0.0421
[Epoch 18, Batch 100] loss: 0.011282686398189981
[Epoch 18, Batch 200] loss: 0.006809263455797918
[Epoch 18, Batch 300] loss: 0.006342162861255929
[Epoch 18, Batch 400] loss: 0.009199725156577188
[Epoch 18, Batch 500] loss: 0.007679606248493656
[Epoch 18, Batch 600] loss: 0.010856009606795851
[Epoch 18, Batch 700] loss: 0.01065282621551887
**STATS for Epoch 18** : 
Average training loss: 0.0005
Average validation loss: 0.0453
Validation Accuracy: 0.9885
Overfitting: 0.0448
[Epoch 19, Batch 100] loss: 0.011319478733712458
[Epoch 19, Batch 200] loss: 0.0132591058449907
[Epoch 19, Batch 300] loss: 0.0063633126819331665
[Epoch 19, Batch 400] loss: 0.00892778864952561
[Epoch 19, Batch 500] loss: 0.009759123702096986
[Epoch 19, Batch 600] loss: 0.00762643030459003
[Epoch 19, Batch 700] loss: 0.006882507480549975
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0456
Validation Accuracy: 0.9879
Overfitting: 0.0448
[Epoch 20, Batch 100] loss: 0.008759776739752851
[Epoch 20, Batch 200] loss: 0.0055378452283912335
[Epoch 20, Batch 300] loss: 0.0053894497419969415
[Epoch 20, Batch 400] loss: 0.008851490404340438
[Epoch 20, Batch 500] loss: 0.005572661549558688
[Epoch 20, Batch 600] loss: 0.007465312999265734
[Epoch 20, Batch 700] loss: 0.00934382786108472
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0485
Validation Accuracy: 0.9877
Overfitting: 0.0481
[Epoch 21, Batch 100] loss: 0.007035451285046293
[Epoch 21, Batch 200] loss: 0.00789514975847851
[Epoch 21, Batch 300] loss: 0.006116243609576486
[Epoch 21, Batch 400] loss: 0.004920922171040729
[Epoch 21, Batch 500] loss: 0.0036417090294344236
[Epoch 21, Batch 600] loss: 0.005379810537961021
[Epoch 21, Batch 700] loss: 0.009510543736105319
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0484
Validation Accuracy: 0.9882
Overfitting: 0.0479
[Epoch 22, Batch 100] loss: 0.005525249420861656
[Epoch 22, Batch 200] loss: 0.006298900880087785
[Epoch 22, Batch 300] loss: 0.0055824494678381595
[Epoch 22, Batch 400] loss: 0.006362432586774958
[Epoch 22, Batch 500] loss: 0.004003151209981297
[Epoch 22, Batch 600] loss: 0.006517507755415863
[Epoch 22, Batch 700] loss: 0.004196105902065028
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0483
Validation Accuracy: 0.9888
Overfitting: 0.0481
[Epoch 23, Batch 100] loss: 0.0023873791674395763
[Epoch 23, Batch 200] loss: 0.004429601028441539
[Epoch 23, Batch 300] loss: 0.004431973792661665
[Epoch 23, Batch 400] loss: 0.0035891935382824157
[Epoch 23, Batch 500] loss: 0.003364800960298453
[Epoch 23, Batch 600] loss: 0.005069612325219169
[Epoch 23, Batch 700] loss: 0.005121295357876079
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0540
Validation Accuracy: 0.9868
Overfitting: 0.0536
[Epoch 24, Batch 100] loss: 0.003729708527280309
[Epoch 24, Batch 200] loss: 0.0022562994929648996
[Epoch 24, Batch 300] loss: 0.00478320034855642
[Epoch 24, Batch 400] loss: 0.004856541908520739
[Epoch 24, Batch 500] loss: 0.00536848445753094
[Epoch 24, Batch 600] loss: 0.005061875888786744
[Epoch 24, Batch 700] loss: 0.00927399755195438
**STATS for Epoch 24** : 
Average training loss: 0.0006
Average validation loss: 0.0510
Validation Accuracy: 0.9884
Overfitting: 0.0505
Fold 5 validation loss: 0.0510
Mean validation loss across all folds for Trial 11 is 0.0514 with trial config:  l1: 256, l2: 128, lr: 0.0028666428011813474, batch_size: 64
[I 2024-12-10 07:15:22,817] Trial 10 finished with value: 0.05135433652282719 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0028666428011813474, 'batch_size': 64}. Best is trial 9 with value: 0.05047078778321675.

Selected Hyperparameters for Trial 12:
  l1: 256, l2: 128, lr: 0.008332334231893158, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.3542739613354207
[Epoch 1, Batch 200] loss: 0.3299920827895403
[Epoch 1, Batch 300] loss: 0.2300835483521223
[Epoch 1, Batch 400] loss: 0.1661978141963482
[Epoch 1, Batch 500] loss: 0.1303566617332399
[Epoch 1, Batch 600] loss: 0.13651451610028745
[Epoch 1, Batch 700] loss: 0.10893332007341087
**STATS for Epoch 1** : 
Average training loss: 0.0060
Average validation loss: 0.0841
Validation Accuracy: 0.9728
Overfitting: 0.0781
Best model saved at epoch 1 with validation loss: 0.0841
[Epoch 2, Batch 100] loss: 0.08818801939021796
[Epoch 2, Batch 200] loss: 0.09769408468622715
[Epoch 2, Batch 300] loss: 0.08130322985816747
[Epoch 2, Batch 400] loss: 0.07921319868415594
[Epoch 2, Batch 500] loss: 0.07415921829640865
[Epoch 2, Batch 600] loss: 0.06764330950565636
[Epoch 2, Batch 700] loss: 0.07741348697803914
**STATS for Epoch 2** : 
Average training loss: 0.0046
Average validation loss: 0.0602
Validation Accuracy: 0.9795
Overfitting: 0.0556
Best model saved at epoch 2 with validation loss: 0.0602
[Epoch 3, Batch 100] loss: 0.04714692622772418
[Epoch 3, Batch 200] loss: 0.051426463695243
[Epoch 3, Batch 300] loss: 0.058930640988983214
[Epoch 3, Batch 400] loss: 0.06046482444624417
[Epoch 3, Batch 500] loss: 0.049129625709028915
[Epoch 3, Batch 600] loss: 0.04961058226181194
[Epoch 3, Batch 700] loss: 0.05674067366169765
**STATS for Epoch 3** : 
Average training loss: 0.0037
Average validation loss: 0.0674
Validation Accuracy: 0.9790
Overfitting: 0.0636
[Epoch 4, Batch 100] loss: 0.04050102039123885
[Epoch 4, Batch 200] loss: 0.043354537449777124
[Epoch 4, Batch 300] loss: 0.04539825331885368
[Epoch 4, Batch 400] loss: 0.04334873561514541
[Epoch 4, Batch 500] loss: 0.04270672756247222
[Epoch 4, Batch 600] loss: 0.04541861288482323
[Epoch 4, Batch 700] loss: 0.03461938487947919
**STATS for Epoch 4** : 
Average training loss: 0.0027
Average validation loss: 0.0579
Validation Accuracy: 0.9821
Overfitting: 0.0551
Best model saved at epoch 4 with validation loss: 0.0579
[Epoch 5, Batch 100] loss: 0.027803712240420282
[Epoch 5, Batch 200] loss: 0.025192065177252518
[Epoch 5, Batch 300] loss: 0.032541405993397346
[Epoch 5, Batch 400] loss: 0.03327887215767987
[Epoch 5, Batch 500] loss: 0.033641911877784876
[Epoch 5, Batch 600] loss: 0.03719998265412869
[Epoch 5, Batch 700] loss: 0.03122358904860448
**STATS for Epoch 5** : 
Average training loss: 0.0018
Average validation loss: 0.0439
Validation Accuracy: 0.9862
Overfitting: 0.0421
Best model saved at epoch 5 with validation loss: 0.0439
[Epoch 6, Batch 100] loss: 0.02806601352756843
[Epoch 6, Batch 200] loss: 0.022919061622815207
[Epoch 6, Batch 300] loss: 0.024719166884897278
[Epoch 6, Batch 400] loss: 0.02937987014243845
[Epoch 6, Batch 500] loss: 0.023356945904670284
[Epoch 6, Batch 600] loss: 0.028116116034798324
[Epoch 6, Batch 700] loss: 0.026773217894369736
**STATS for Epoch 6** : 
Average training loss: 0.0018
Average validation loss: 0.0557
Validation Accuracy: 0.9824
Overfitting: 0.0539
[Epoch 7, Batch 100] loss: 0.020050282299635
[Epoch 7, Batch 200] loss: 0.022260136433469597
[Epoch 7, Batch 300] loss: 0.020734786757675466
[Epoch 7, Batch 400] loss: 0.018808985472132916
[Epoch 7, Batch 500] loss: 0.020581290393747623
[Epoch 7, Batch 600] loss: 0.03517056768061593
[Epoch 7, Batch 700] loss: 0.02360128074826207
**STATS for Epoch 7** : 
Average training loss: 0.0014
Average validation loss: 0.0465
Validation Accuracy: 0.9854
Overfitting: 0.0451
[Epoch 8, Batch 100] loss: 0.020230431720847264
[Epoch 8, Batch 200] loss: 0.013462681977835018
[Epoch 8, Batch 300] loss: 0.015787903571326752
[Epoch 8, Batch 400] loss: 0.018867743404989597
[Epoch 8, Batch 500] loss: 0.019243605149677025
[Epoch 8, Batch 600] loss: 0.021315824795601658
[Epoch 8, Batch 700] loss: 0.01616245754150441
**STATS for Epoch 8** : 
Average training loss: 0.0014
Average validation loss: 0.0415
Validation Accuracy: 0.9876
Overfitting: 0.0401
Best model saved at epoch 8 with validation loss: 0.0415
[Epoch 9, Batch 100] loss: 0.009930927413297468
[Epoch 9, Batch 200] loss: 0.013895128761650994
[Epoch 9, Batch 300] loss: 0.01154492902714992
[Epoch 9, Batch 400] loss: 0.012317117166821845
[Epoch 9, Batch 500] loss: 0.015997103930567393
[Epoch 9, Batch 600] loss: 0.014995284327451373
[Epoch 9, Batch 700] loss: 0.02018948242737679
**STATS for Epoch 9** : 
Average training loss: 0.0015
Average validation loss: 0.0473
Validation Accuracy: 0.9864
Overfitting: 0.0459
[Epoch 10, Batch 100] loss: 0.008933665097210906
[Epoch 10, Batch 200] loss: 0.013073175159443054
[Epoch 10, Batch 300] loss: 0.010541443998663453
[Epoch 10, Batch 400] loss: 0.011319147114190855
[Epoch 10, Batch 500] loss: 0.012489713820250471
[Epoch 10, Batch 600] loss: 0.011216386172018247
[Epoch 10, Batch 700] loss: 0.013974364325404167
**STATS for Epoch 10** : 
Average training loss: 0.0010
Average validation loss: 0.0515
Validation Accuracy: 0.9865
Overfitting: 0.0505
[Epoch 11, Batch 100] loss: 0.013050158760597697
[Epoch 11, Batch 200] loss: 0.01007039027477731
[Epoch 11, Batch 300] loss: 0.008709904954230296
[Epoch 11, Batch 400] loss: 0.009815236757249294
[Epoch 11, Batch 500] loss: 0.013072553167912702
[Epoch 11, Batch 600] loss: 0.013213278022303711
[Epoch 11, Batch 700] loss: 0.016644698568852617
**STATS for Epoch 11** : 
Average training loss: 0.0006
Average validation loss: 0.0708
Validation Accuracy: 0.9823
Overfitting: 0.0702
[Epoch 12, Batch 100] loss: 0.010891677910694852
[Epoch 12, Batch 200] loss: 0.00635353713441873
[Epoch 12, Batch 300] loss: 0.007713592538111698
[Epoch 12, Batch 400] loss: 0.009194551226682961
[Epoch 12, Batch 500] loss: 0.008803716080983577
[Epoch 12, Batch 600] loss: 0.006059275397637976
[Epoch 12, Batch 700] loss: 0.0064608833617239726
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0496
Validation Accuracy: 0.9883
Overfitting: 0.0488
[Epoch 13, Batch 100] loss: 0.008895900349743897
[Epoch 13, Batch 200] loss: 0.007083909785360447
[Epoch 13, Batch 300] loss: 0.006181745973299258
[Epoch 13, Batch 400] loss: 0.004009755189572388
[Epoch 13, Batch 500] loss: 0.007440725073038266
[Epoch 13, Batch 600] loss: 0.007944972141431209
[Epoch 13, Batch 700] loss: 0.009964914819775003
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0586
Validation Accuracy: 0.9850
Overfitting: 0.0580
[Epoch 14, Batch 100] loss: 0.003546460245866001
[Epoch 14, Batch 200] loss: 0.003815713796302589
[Epoch 14, Batch 300] loss: 0.005576575760023843
[Epoch 14, Batch 400] loss: 0.004949426602779567
[Epoch 14, Batch 500] loss: 0.004761282388826658
[Epoch 14, Batch 600] loss: 0.006413480999144667
[Epoch 14, Batch 700] loss: 0.006338648438054406
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0529
Validation Accuracy: 0.9865
Overfitting: 0.0523
[Epoch 15, Batch 100] loss: 0.00301965537812066
[Epoch 15, Batch 200] loss: 0.0068087709480096235
[Epoch 15, Batch 300] loss: 0.0034767203189585414
[Epoch 15, Batch 400] loss: 0.004162087073800649
[Epoch 15, Batch 500] loss: 0.00609275679383245
[Epoch 15, Batch 600] loss: 0.006444740458218803
[Epoch 15, Batch 700] loss: 0.012803680581255321
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0475
Validation Accuracy: 0.9882
Overfitting: 0.0468
[Epoch 16, Batch 100] loss: 0.007391854792513186
[Epoch 16, Batch 200] loss: 0.005708292052213437
[Epoch 16, Batch 300] loss: 0.004857929380668793
[Epoch 16, Batch 400] loss: 0.003092922422188167
[Epoch 16, Batch 500] loss: 0.0025958530991647424
[Epoch 16, Batch 600] loss: 0.003644475026430882
[Epoch 16, Batch 700] loss: 0.002178525566719145
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0469
Validation Accuracy: 0.9881
Overfitting: 0.0464
[Epoch 17, Batch 100] loss: 0.006653568795281899
[Epoch 17, Batch 200] loss: 0.003773223983362186
[Epoch 17, Batch 300] loss: 0.00392081319792851
[Epoch 17, Batch 400] loss: 0.004144694755823366
[Epoch 17, Batch 500] loss: 0.008362366863120769
[Epoch 17, Batch 600] loss: 0.0038391113526267872
[Epoch 17, Batch 700] loss: 0.005487960921509511
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0590
Validation Accuracy: 0.9874
Overfitting: 0.0584
[I 2024-12-10 07:18:20,809] Trial 11 pruned. 

Selected Hyperparameters for Trial 13:
  l1: 256, l2: 128, lr: 0.0014164377539505066, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3004871678352354
[Epoch 1, Batch 200] loss: 2.286811800003052
[Epoch 1, Batch 300] loss: 2.2414377665519716
[Epoch 1, Batch 400] loss: 1.8049703115224838
[Epoch 1, Batch 500] loss: 0.6920268762111664
[Epoch 1, Batch 600] loss: 0.45402593433856964
[Epoch 1, Batch 700] loss: 0.38129807129502297
**STATS for Epoch 1** : 
Average training loss: 0.0191
Average validation loss: 0.3031
Validation Accuracy: 0.9103
Overfitting: 0.2840
Best model saved at epoch 1 with validation loss: 0.3031
[Epoch 2, Batch 100] loss: 0.2756888535618782
[Epoch 2, Batch 200] loss: 0.26606049567461015
[Epoch 2, Batch 300] loss: 0.23858939200639726
[Epoch 2, Batch 400] loss: 0.19827444072812794
[Epoch 2, Batch 500] loss: 0.1783622343465686
[Epoch 2, Batch 600] loss: 0.17458834275603294
[Epoch 2, Batch 700] loss: 0.16185799684375524
**STATS for Epoch 2** : 
Average training loss: 0.0099
Average validation loss: 0.1402
Validation Accuracy: 0.9578
Overfitting: 0.1303
Best model saved at epoch 2 with validation loss: 0.1402
[Epoch 3, Batch 100] loss: 0.1502901883982122
[Epoch 3, Batch 200] loss: 0.126644376963377
[Epoch 3, Batch 300] loss: 0.12951913133263587
[Epoch 3, Batch 400] loss: 0.10474433183670044
[Epoch 3, Batch 500] loss: 0.10507534037344157
[Epoch 3, Batch 600] loss: 0.11608947377651929
[Epoch 3, Batch 700] loss: 0.11762911340221763
**STATS for Epoch 3** : 
Average training loss: 0.0078
Average validation loss: 0.0987
Validation Accuracy: 0.9676
Overfitting: 0.0909
Best model saved at epoch 3 with validation loss: 0.0987
[Epoch 4, Batch 100] loss: 0.10303376281633973
[Epoch 4, Batch 200] loss: 0.08533686244860292
[Epoch 4, Batch 300] loss: 0.0920694633666426
[Epoch 4, Batch 400] loss: 0.0929923711065203
[Epoch 4, Batch 500] loss: 0.09669820768758655
[Epoch 4, Batch 600] loss: 0.08517985582351685
[Epoch 4, Batch 700] loss: 0.09264017247594893
**STATS for Epoch 4** : 
Average training loss: 0.0060
Average validation loss: 0.0769
Validation Accuracy: 0.9758
Overfitting: 0.0709
Best model saved at epoch 4 with validation loss: 0.0769
[Epoch 5, Batch 100] loss: 0.07291918778792024
[Epoch 5, Batch 200] loss: 0.07401358993258328
[Epoch 5, Batch 300] loss: 0.06753897079266608
[Epoch 5, Batch 400] loss: 0.07088740227743984
[Epoch 5, Batch 500] loss: 0.07999491933733224
[Epoch 5, Batch 600] loss: 0.0887020436860621
[Epoch 5, Batch 700] loss: 0.07891006966587157
**STATS for Epoch 5** : 
Average training loss: 0.0057
Average validation loss: 0.0642
Validation Accuracy: 0.9801
Overfitting: 0.0585
Best model saved at epoch 5 with validation loss: 0.0642
[Epoch 6, Batch 100] loss: 0.06779543117620052
[Epoch 6, Batch 200] loss: 0.06836568458471447
[Epoch 6, Batch 300] loss: 0.06296521052718163
[Epoch 6, Batch 400] loss: 0.0755856963712722
[Epoch 6, Batch 500] loss: 0.06948570764623582
[Epoch 6, Batch 600] loss: 0.06649035913404078
[Epoch 6, Batch 700] loss: 0.05144607551861555
**STATS for Epoch 6** : 
Average training loss: 0.0047
Average validation loss: 0.0598
Validation Accuracy: 0.9820
Overfitting: 0.0552
Best model saved at epoch 6 with validation loss: 0.0598
[Epoch 7, Batch 100] loss: 0.05847449908033013
[Epoch 7, Batch 200] loss: 0.054181440416723486
[Epoch 7, Batch 300] loss: 0.06267407231964171
[Epoch 7, Batch 400] loss: 0.06473416698165238
[Epoch 7, Batch 500] loss: 0.06501938439439982
[Epoch 7, Batch 600] loss: 0.056215967927128074
[Epoch 7, Batch 700] loss: 0.05678450156934559
**STATS for Epoch 7** : 
Average training loss: 0.0039
Average validation loss: 0.0575
Validation Accuracy: 0.9818
Overfitting: 0.0536
Best model saved at epoch 7 with validation loss: 0.0575
[Epoch 8, Batch 100] loss: 0.046878633303567764
[Epoch 8, Batch 200] loss: 0.05555907726287842
[Epoch 8, Batch 300] loss: 0.054657433168031275
[Epoch 8, Batch 400] loss: 0.04690802152501419
[Epoch 8, Batch 500] loss: 0.048597184348618615
[Epoch 8, Batch 600] loss: 0.05685782925691456
[Epoch 8, Batch 700] loss: 0.06547409408725798
**STATS for Epoch 8** : 
Average training loss: 0.0034
Average validation loss: 0.0600
Validation Accuracy: 0.9809
Overfitting: 0.0566
[Epoch 9, Batch 100] loss: 0.05407870581955649
[Epoch 9, Batch 200] loss: 0.046699442230165006
[Epoch 9, Batch 300] loss: 0.04536326038883999
[Epoch 9, Batch 400] loss: 0.04681823192164302
[Epoch 9, Batch 500] loss: 0.04191805517300964
[Epoch 9, Batch 600] loss: 0.047430698601529
[Epoch 9, Batch 700] loss: 0.05927612849045545
**STATS for Epoch 9** : 
Average training loss: 0.0031
Average validation loss: 0.0541
Validation Accuracy: 0.9828
Overfitting: 0.0510
[I 2024-12-10 07:19:55,640] Trial 12 pruned. 

Selected Hyperparameters for Trial 14:
  l1: 128, l2: 64, lr: 0.009510851642562738, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.7216218265891075
[Epoch 1, Batch 200] loss: 0.3726263899356127
[Epoch 1, Batch 300] loss: 0.20229240752756594
[Epoch 1, Batch 400] loss: 0.14426453080028295
[Epoch 1, Batch 500] loss: 0.1278115665912628
[Epoch 1, Batch 600] loss: 0.10772276883944869
[Epoch 1, Batch 700] loss: 0.09893328187055886
**STATS for Epoch 1** : 
Average training loss: 0.0074
Average validation loss: 0.0900
Validation Accuracy: 0.9738
Overfitting: 0.0826
Best model saved at epoch 1 with validation loss: 0.0900
[Epoch 2, Batch 100] loss: 0.08069470300339163
[Epoch 2, Batch 200] loss: 0.06880588995059952
[Epoch 2, Batch 300] loss: 0.06574679613113403
[Epoch 2, Batch 400] loss: 0.061858732714317737
[Epoch 2, Batch 500] loss: 0.07136108060833067
[Epoch 2, Batch 600] loss: 0.0777524642040953
[Epoch 2, Batch 700] loss: 0.06905699455877766
**STATS for Epoch 2** : 
Average training loss: 0.0042
Average validation loss: 0.0663
Validation Accuracy: 0.9795
Overfitting: 0.0621
Best model saved at epoch 2 with validation loss: 0.0663
[Epoch 3, Batch 100] loss: 0.049611518145538866
[Epoch 3, Batch 200] loss: 0.05028247887268662
[Epoch 3, Batch 300] loss: 0.042825740851694716
[Epoch 3, Batch 400] loss: 0.05129028443945572
[Epoch 3, Batch 500] loss: 0.04874264769256115
[Epoch 3, Batch 600] loss: 0.04855544961290434
[Epoch 3, Batch 700] loss: 0.04767014541197568
**STATS for Epoch 3** : 
Average training loss: 0.0042
Average validation loss: 0.0498
Validation Accuracy: 0.9850
Overfitting: 0.0457
Best model saved at epoch 3 with validation loss: 0.0498
[Epoch 4, Batch 100] loss: 0.04369463779497892
[Epoch 4, Batch 200] loss: 0.03361078438349068
[Epoch 4, Batch 300] loss: 0.049286161296186036
[Epoch 4, Batch 400] loss: 0.03526193390018307
[Epoch 4, Batch 500] loss: 0.03640443193493411
[Epoch 4, Batch 600] loss: 0.03033229540917091
[Epoch 4, Batch 700] loss: 0.04023114567855373
**STATS for Epoch 4** : 
Average training loss: 0.0018
Average validation loss: 0.0488
Validation Accuracy: 0.9853
Overfitting: 0.0470
Best model saved at epoch 4 with validation loss: 0.0488
[Epoch 5, Batch 100] loss: 0.03928550568409264
[Epoch 5, Batch 200] loss: 0.029178825112176128
[Epoch 5, Batch 300] loss: 0.028200908376602454
[Epoch 5, Batch 400] loss: 0.03289757563150488
[Epoch 5, Batch 500] loss: 0.03129205532255583
[Epoch 5, Batch 600] loss: 0.030748514770530165
[Epoch 5, Batch 700] loss: 0.035622779915574936
**STATS for Epoch 5** : 
Average training loss: 0.0021
Average validation loss: 0.0414
Validation Accuracy: 0.9871
Overfitting: 0.0393
Best model saved at epoch 5 with validation loss: 0.0414
[Epoch 6, Batch 100] loss: 0.02180868868890684
[Epoch 6, Batch 200] loss: 0.02143696744227782
[Epoch 6, Batch 300] loss: 0.02671863405557815
[Epoch 6, Batch 400] loss: 0.03059721341007389
[Epoch 6, Batch 500] loss: 0.029611607377883046
[Epoch 6, Batch 600] loss: 0.027672653924673794
[Epoch 6, Batch 700] loss: 0.02703052442811895
**STATS for Epoch 6** : 
Average training loss: 0.0015
Average validation loss: 0.0387
Validation Accuracy: 0.9882
Overfitting: 0.0372
Best model saved at epoch 6 with validation loss: 0.0387
[Epoch 7, Batch 100] loss: 0.015431287289247848
[Epoch 7, Batch 200] loss: 0.02300561861920869
[Epoch 7, Batch 300] loss: 0.021697614299482665
[Epoch 7, Batch 400] loss: 0.018712686604994814
[Epoch 7, Batch 500] loss: 0.023261772280966396
[Epoch 7, Batch 600] loss: 0.01883018644148251
[Epoch 7, Batch 700] loss: 0.022806147751398383
**STATS for Epoch 7** : 
Average training loss: 0.0023
Average validation loss: 0.0400
Validation Accuracy: 0.9875
Overfitting: 0.0377
[Epoch 8, Batch 100] loss: 0.014769240556197473
[Epoch 8, Batch 200] loss: 0.0148718851681042
[Epoch 8, Batch 300] loss: 0.014405648703104816
[Epoch 8, Batch 400] loss: 0.01603675720776664
[Epoch 8, Batch 500] loss: 0.018100077800045255
[Epoch 8, Batch 600] loss: 0.01952850643720012
[Epoch 8, Batch 700] loss: 0.01776633393485099
**STATS for Epoch 8** : 
Average training loss: 0.0011
Average validation loss: 0.0449
Validation Accuracy: 0.9871
Overfitting: 0.0439
[Epoch 9, Batch 100] loss: 0.014735872521414421
[Epoch 9, Batch 200] loss: 0.011302362154383445
[Epoch 9, Batch 300] loss: 0.013606215845829866
[Epoch 9, Batch 400] loss: 0.017063910321812727
[Epoch 9, Batch 500] loss: 0.013455942232249073
[Epoch 9, Batch 600] loss: 0.01502839674398274
[Epoch 9, Batch 700] loss: 0.026382719134853686
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0428
Validation Accuracy: 0.9881
Overfitting: 0.0412
[Epoch 10, Batch 100] loss: 0.011492984087090008
[Epoch 10, Batch 200] loss: 0.017021987951593473
[Epoch 10, Batch 300] loss: 0.011677030966966413
[Epoch 10, Batch 400] loss: 0.010577137674044935
[Epoch 10, Batch 500] loss: 0.023451217342953898
[Epoch 10, Batch 600] loss: 0.015074836326384684
[Epoch 10, Batch 700] loss: 0.01135525787860388
**STATS for Epoch 10** : 
Average training loss: 0.0007
Average validation loss: 0.0405
Validation Accuracy: 0.9899
Overfitting: 0.0398
[Epoch 11, Batch 100] loss: 0.010794921575361514
[Epoch 11, Batch 200] loss: 0.009681929567013867
[Epoch 11, Batch 300] loss: 0.0072959296444605574
[Epoch 11, Batch 400] loss: 0.010233708025225496
[Epoch 11, Batch 500] loss: 0.01591629681744962
[Epoch 11, Batch 600] loss: 0.011494558472622884
[Epoch 11, Batch 700] loss: 0.018425268437276827
**STATS for Epoch 11** : 
Average training loss: 0.0010
Average validation loss: 0.0450
Validation Accuracy: 0.9882
Overfitting: 0.0440
[Epoch 12, Batch 100] loss: 0.008943726818488358
[Epoch 12, Batch 200] loss: 0.012037922915260424
[Epoch 12, Batch 300] loss: 0.009872411005126196
[Epoch 12, Batch 400] loss: 0.007622419342187641
[Epoch 12, Batch 500] loss: 0.00914813849820348
[Epoch 12, Batch 600] loss: 0.007947587655107781
[Epoch 12, Batch 700] loss: 0.00977203442293103
**STATS for Epoch 12** : 
Average training loss: 0.0006
Average validation loss: 0.0450
Validation Accuracy: 0.9889
Overfitting: 0.0445
[Epoch 13, Batch 100] loss: 0.006613703831681051
[Epoch 13, Batch 200] loss: 0.006316282968800806
[Epoch 13, Batch 300] loss: 0.010073252103338745
[Epoch 13, Batch 400] loss: 0.006252702749843592
[Epoch 13, Batch 500] loss: 0.009658711258380208
[Epoch 13, Batch 600] loss: 0.01398276621095647
[Epoch 13, Batch 700] loss: 0.009361976854415843
**STATS for Epoch 13** : 
Average training loss: 0.0005
Average validation loss: 0.0486
Validation Accuracy: 0.9888
Overfitting: 0.0481
[Epoch 14, Batch 100] loss: 0.006015160317110713
[Epoch 14, Batch 200] loss: 0.00969323113475184
[Epoch 14, Batch 300] loss: 0.008962832287561468
[Epoch 14, Batch 400] loss: 0.01639786160099902
[Epoch 14, Batch 500] loss: 0.010331412578925664
[Epoch 14, Batch 600] loss: 0.012013975831432617
[Epoch 14, Batch 700] loss: 0.00681643424255526
**STATS for Epoch 14** : 
Average training loss: 0.0003
Average validation loss: 0.0431
Validation Accuracy: 0.9888
Overfitting: 0.0428
[Epoch 15, Batch 100] loss: 0.007365717503416818
[Epoch 15, Batch 200] loss: 0.006063325318373245
[Epoch 15, Batch 300] loss: 0.011111032864318986
[Epoch 15, Batch 400] loss: 0.005042628640694602
[Epoch 15, Batch 500] loss: 0.008147270127465163
[Epoch 15, Batch 600] loss: 0.0068220390455098825
[Epoch 15, Batch 700] loss: 0.008962061639231252
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0480
Validation Accuracy: 0.9886
Overfitting: 0.0476
[Epoch 16, Batch 100] loss: 0.005305582407036127
[Epoch 16, Batch 200] loss: 0.00350614974160635
[Epoch 16, Batch 300] loss: 0.005563126230927082
[Epoch 16, Batch 400] loss: 0.0067657949177919365
[Epoch 16, Batch 500] loss: 0.005531155235248661
[Epoch 16, Batch 600] loss: 0.008648455119353003
[Epoch 16, Batch 700] loss: 0.009379695445932156
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0426
Validation Accuracy: 0.9902
Overfitting: 0.0422
[Epoch 17, Batch 100] loss: 0.002738702119163463
[Epoch 17, Batch 200] loss: 0.005042972071651093
[Epoch 17, Batch 300] loss: 0.005619911900903389
[Epoch 17, Batch 400] loss: 0.007253743918336113
[Epoch 17, Batch 500] loss: 0.0041520019954623425
[Epoch 17, Batch 600] loss: 0.005950728996267572
[Epoch 17, Batch 700] loss: 0.005119710520475564
**STATS for Epoch 17** : 
Average training loss: 0.0002
Average validation loss: 0.0482
Validation Accuracy: 0.9900
Overfitting: 0.0479
[Epoch 18, Batch 100] loss: 0.0026741404365316157
[Epoch 18, Batch 200] loss: 0.002634132818625403
[Epoch 18, Batch 300] loss: 0.005094858442112127
[Epoch 18, Batch 400] loss: 0.0032528984966302232
[Epoch 18, Batch 500] loss: 0.0017689866591217651
[Epoch 18, Batch 600] loss: 0.004092311068043273
[Epoch 18, Batch 700] loss: 0.0015625342330827152
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0458
Validation Accuracy: 0.9906
Overfitting: 0.0457
[Epoch 19, Batch 100] loss: 0.0014435751656333195
[Epoch 19, Batch 200] loss: 0.0019012518427030045
[Epoch 19, Batch 300] loss: 0.0011581771760484116
[Epoch 19, Batch 400] loss: 0.004696281726270399
[Epoch 19, Batch 500] loss: 0.0030653821054409036
[Epoch 19, Batch 600] loss: 0.0023420675201418816
[Epoch 19, Batch 700] loss: 0.0016791230392396983
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0501
Validation Accuracy: 0.9902
Overfitting: 0.0499
[Epoch 20, Batch 100] loss: 0.002101294242588665
[Epoch 20, Batch 200] loss: 0.0012031423260714291
[Epoch 20, Batch 300] loss: 0.0008760207916873241
[Epoch 20, Batch 400] loss: 0.002693064900349782
[Epoch 20, Batch 500] loss: 0.004261891074584412
[Epoch 20, Batch 600] loss: 0.008977372160841242
[Epoch 20, Batch 700] loss: 0.005522241475782721
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0480
Validation Accuracy: 0.9906
Overfitting: 0.0477
[Epoch 21, Batch 100] loss: 0.0019597847407931113
[Epoch 21, Batch 200] loss: 0.004297625467656872
[Epoch 21, Batch 300] loss: 0.0026117070077816607
[Epoch 21, Batch 400] loss: 0.003710102563994724
[Epoch 21, Batch 500] loss: 0.0019363890225963588
[Epoch 21, Batch 600] loss: 0.0031392006445383914
[Epoch 21, Batch 700] loss: 0.0062194745326667085
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0530
Validation Accuracy: 0.9901
Overfitting: 0.0524
[Epoch 22, Batch 100] loss: 0.0038203468618610258
[Epoch 22, Batch 200] loss: 0.008465422550227687
[Epoch 22, Batch 300] loss: 0.008739055958149038
[Epoch 22, Batch 400] loss: 0.007893575705957119
[Epoch 22, Batch 500] loss: 0.011043587248695984
[Epoch 22, Batch 600] loss: 0.013317749508877342
[Epoch 22, Batch 700] loss: 0.012112655282498963
**STATS for Epoch 22** : 
Average training loss: 0.0010
Average validation loss: 0.0669
Validation Accuracy: 0.9869
Overfitting: 0.0660
[Epoch 23, Batch 100] loss: 0.007631494299912447
[Epoch 23, Batch 200] loss: 0.006501493100149674
[Epoch 23, Batch 300] loss: 0.0064498916232082594
[Epoch 23, Batch 400] loss: 0.005777528626986168
[Epoch 23, Batch 500] loss: 0.009929901848832969
[Epoch 23, Batch 600] loss: 0.0038448147910867194
[Epoch 23, Batch 700] loss: 0.009858911868640234
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0626
Validation Accuracy: 0.9871
Overfitting: 0.0622
[Epoch 24, Batch 100] loss: 0.006865942211406946
[Epoch 24, Batch 200] loss: 0.002258566004771012
[Epoch 24, Batch 300] loss: 0.0019551328248462595
[Epoch 24, Batch 400] loss: 0.0039023685903202933
[Epoch 24, Batch 500] loss: 0.012760481746172446
[Epoch 24, Batch 600] loss: 0.008883117808916268
[Epoch 24, Batch 700] loss: 0.007595572222917326
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0548
Validation Accuracy: 0.9887
Overfitting: 0.0543
Fold 1 validation loss: 0.0548
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.733232123851776
[Epoch 1, Batch 200] loss: 0.3811925834417343
[Epoch 1, Batch 300] loss: 0.21291835533455014
[Epoch 1, Batch 400] loss: 0.18457941979169845
[Epoch 1, Batch 500] loss: 0.12737190196290613
[Epoch 1, Batch 600] loss: 0.11577530464157462
[Epoch 1, Batch 700] loss: 0.11435829451307654
**STATS for Epoch 1** : 
Average training loss: 0.0075
Average validation loss: 0.1104
Validation Accuracy: 0.9668
Overfitting: 0.1029
Best model saved at epoch 1 with validation loss: 0.1104
[Epoch 2, Batch 100] loss: 0.07976463462226092
[Epoch 2, Batch 200] loss: 0.09365595944225788
[Epoch 2, Batch 300] loss: 0.09242001709993929
[Epoch 2, Batch 400] loss: 0.07813550749793649
[Epoch 2, Batch 500] loss: 0.07005195798352361
[Epoch 2, Batch 600] loss: 0.07195464606862516
[Epoch 2, Batch 700] loss: 0.08025404057465493
**STATS for Epoch 2** : 
Average training loss: 0.0037
Average validation loss: 0.0810
Validation Accuracy: 0.9758
Overfitting: 0.0773
Best model saved at epoch 2 with validation loss: 0.0810
[Epoch 3, Batch 100] loss: 0.05501528583234176
[Epoch 3, Batch 200] loss: 0.05292512661777437
[Epoch 3, Batch 300] loss: 0.061834399681538345
[Epoch 3, Batch 400] loss: 0.05371908657019958
[Epoch 3, Batch 500] loss: 0.05118332522804849
[Epoch 3, Batch 600] loss: 0.05037480651342776
[Epoch 3, Batch 700] loss: 0.05048801362514496
**STATS for Epoch 3** : 
Average training loss: 0.0039
Average validation loss: 0.0693
Validation Accuracy: 0.9808
Overfitting: 0.0654
Best model saved at epoch 3 with validation loss: 0.0693
[Epoch 4, Batch 100] loss: 0.040781990817049515
[Epoch 4, Batch 200] loss: 0.03808288714964874
[Epoch 4, Batch 300] loss: 0.04136756661348045
[Epoch 4, Batch 400] loss: 0.03954752045101486
[Epoch 4, Batch 500] loss: 0.03739808878861368
[Epoch 4, Batch 600] loss: 0.044274520768085496
[Epoch 4, Batch 700] loss: 0.04660212236572989
**STATS for Epoch 4** : 
Average training loss: 0.0027
Average validation loss: 0.0562
Validation Accuracy: 0.9842
Overfitting: 0.0535
Best model saved at epoch 4 with validation loss: 0.0562
[Epoch 5, Batch 100] loss: 0.031724278419278565
[Epoch 5, Batch 200] loss: 0.032700795833661686
[Epoch 5, Batch 300] loss: 0.028206573118804954
[Epoch 5, Batch 400] loss: 0.026122138570062816
[Epoch 5, Batch 500] loss: 0.03646677897020709
[Epoch 5, Batch 600] loss: 0.04299116834648885
[Epoch 5, Batch 700] loss: 0.030777050129836427
**STATS for Epoch 5** : 
Average training loss: 0.0019
Average validation loss: 0.0616
Validation Accuracy: 0.9825
Overfitting: 0.0597
[Epoch 6, Batch 100] loss: 0.023508590784476837
[Epoch 6, Batch 200] loss: 0.02764558822091203
[Epoch 6, Batch 300] loss: 0.029630990641308017
[Epoch 6, Batch 400] loss: 0.019086117960105186
[Epoch 6, Batch 500] loss: 0.026078785459394568
[Epoch 6, Batch 600] loss: 0.026776701086491814
[Epoch 6, Batch 700] loss: 0.029726944575668313
**STATS for Epoch 6** : 
Average training loss: 0.0019
Average validation loss: 0.0578
Validation Accuracy: 0.9842
Overfitting: 0.0559
[Epoch 7, Batch 100] loss: 0.022515054905088618
[Epoch 7, Batch 200] loss: 0.025252284825837704
[Epoch 7, Batch 300] loss: 0.02195334548363462
[Epoch 7, Batch 400] loss: 0.01824050618597539
[Epoch 7, Batch 500] loss: 0.026226540751813444
[Epoch 7, Batch 600] loss: 0.019711517366813494
[Epoch 7, Batch 700] loss: 0.023985514603264164
**STATS for Epoch 7** : 
Average training loss: 0.0020
Average validation loss: 0.0785
Validation Accuracy: 0.9795
Overfitting: 0.0764
[Epoch 8, Batch 100] loss: 0.015764365290524437
[Epoch 8, Batch 200] loss: 0.02566446016280679
[Epoch 8, Batch 300] loss: 0.023397038982948287
[Epoch 8, Batch 400] loss: 0.020325262960395777
[Epoch 8, Batch 500] loss: 0.019775184583559167
[Epoch 8, Batch 600] loss: 0.016518184616870712
[Epoch 8, Batch 700] loss: 0.02243331567326095
**STATS for Epoch 8** : 
Average training loss: 0.0014
Average validation loss: 0.0592
Validation Accuracy: 0.9848
Overfitting: 0.0579
[Epoch 9, Batch 100] loss: 0.012384533639560687
[Epoch 9, Batch 200] loss: 0.022887572332110723
[Epoch 9, Batch 300] loss: 0.020165012520446907
[Epoch 9, Batch 400] loss: 0.020565993628042633
[Epoch 9, Batch 500] loss: 0.025378632345673394
[Epoch 9, Batch 600] loss: 0.015955584646435456
[Epoch 9, Batch 700] loss: 0.01964893546060921
**STATS for Epoch 9** : 
Average training loss: 0.0015
Average validation loss: 0.0626
Validation Accuracy: 0.9846
Overfitting: 0.0610
[Epoch 10, Batch 100] loss: 0.018394613748969276
[Epoch 10, Batch 200] loss: 0.015084185822997824
[Epoch 10, Batch 300] loss: 0.013332905028582899
[Epoch 10, Batch 400] loss: 0.013278302600228926
[Epoch 10, Batch 500] loss: 0.014115765428505256
[Epoch 10, Batch 600] loss: 0.018596512303120108
[Epoch 10, Batch 700] loss: 0.02015222349204123
**STATS for Epoch 10** : 
Average training loss: 0.0006
Average validation loss: 0.0536
Validation Accuracy: 0.9877
Overfitting: 0.0530
Best model saved at epoch 10 with validation loss: 0.0536
[Epoch 11, Batch 100] loss: 0.008275052575118024
[Epoch 11, Batch 200] loss: 0.016193575749857702
[Epoch 11, Batch 300] loss: 0.009514220121745893
[Epoch 11, Batch 400] loss: 0.010276683775409766
[Epoch 11, Batch 500] loss: 0.01366537259957113
[Epoch 11, Batch 600] loss: 0.016776092133331987
[Epoch 11, Batch 700] loss: 0.015342126156538143
**STATS for Epoch 11** : 
Average training loss: 0.0007
Average validation loss: 0.0655
Validation Accuracy: 0.9848
Overfitting: 0.0649
[Epoch 12, Batch 100] loss: 0.006289887355269457
[Epoch 12, Batch 200] loss: 0.011792682284940383
[Epoch 12, Batch 300] loss: 0.009116149512956327
[Epoch 12, Batch 400] loss: 0.008158706998365232
[Epoch 12, Batch 500] loss: 0.011354769452445908
[Epoch 12, Batch 600] loss: 0.010688398982129001
[Epoch 12, Batch 700] loss: 0.011610475556626625
**STATS for Epoch 12** : 
Average training loss: 0.0007
Average validation loss: 0.0591
Validation Accuracy: 0.9862
Overfitting: 0.0584
[Epoch 13, Batch 100] loss: 0.008789808024885134
[Epoch 13, Batch 200] loss: 0.009821983398614976
[Epoch 13, Batch 300] loss: 0.013271075010998175
[Epoch 13, Batch 400] loss: 0.00803774506197442
[Epoch 13, Batch 500] loss: 0.01076223081068747
[Epoch 13, Batch 600] loss: 0.00795492911238398
[Epoch 13, Batch 700] loss: 0.010720605391761638
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0629
Validation Accuracy: 0.9865
Overfitting: 0.0623
[Epoch 14, Batch 100] loss: 0.005928931514717988
[Epoch 14, Batch 200] loss: 0.00551706251863834
[Epoch 14, Batch 300] loss: 0.006231984499754617
[Epoch 14, Batch 400] loss: 0.01424357344290911
[Epoch 14, Batch 500] loss: 0.01203013831327553
[Epoch 14, Batch 600] loss: 0.011347894620648731
[Epoch 14, Batch 700] loss: 0.011928278487175703
**STATS for Epoch 14** : 
Average training loss: 0.0010
Average validation loss: 0.0572
Validation Accuracy: 0.9862
Overfitting: 0.0562
[Epoch 15, Batch 100] loss: 0.008146013583609602
[Epoch 15, Batch 200] loss: 0.00522373671801688
[Epoch 15, Batch 300] loss: 0.008212115166861622
[Epoch 15, Batch 400] loss: 0.009364944440058025
[Epoch 15, Batch 500] loss: 0.011858350511920435
[Epoch 15, Batch 600] loss: 0.009634216547365213
[Epoch 15, Batch 700] loss: 0.008797467604929353
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0689
Validation Accuracy: 0.9848
Overfitting: 0.0680
[Epoch 16, Batch 100] loss: 0.01159677589435887
[Epoch 16, Batch 200] loss: 0.005787808943568962
[Epoch 16, Batch 300] loss: 0.006185900168354692
[Epoch 16, Batch 400] loss: 0.010110171145934146
[Epoch 16, Batch 500] loss: 0.005455209090214339
[Epoch 16, Batch 600] loss: 0.009136542434516741
[Epoch 16, Batch 700] loss: 0.011385143273746507
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0644
Validation Accuracy: 0.9869
Overfitting: 0.0640
[Epoch 17, Batch 100] loss: 0.0028166017308421942
[Epoch 17, Batch 200] loss: 0.0035732283198740334
[Epoch 17, Batch 300] loss: 0.0076179305500772895
[Epoch 17, Batch 400] loss: 0.004659177594367066
[Epoch 17, Batch 500] loss: 0.003780037335379802
[Epoch 17, Batch 600] loss: 0.0037076779148605965
[Epoch 17, Batch 700] loss: 0.00434014457738158
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0644
Validation Accuracy: 0.9883
Overfitting: 0.0641
[Epoch 18, Batch 100] loss: 0.002728436374809462
[Epoch 18, Batch 200] loss: 0.005750505290320689
[Epoch 18, Batch 300] loss: 0.0075360318847924644
[Epoch 18, Batch 400] loss: 0.006093289581422141
[Epoch 18, Batch 500] loss: 0.004304021617253966
[Epoch 18, Batch 600] loss: 0.0038197479341192777
[Epoch 18, Batch 700] loss: 0.013974821803922169
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0681
Validation Accuracy: 0.9868
Overfitting: 0.0677
[Epoch 19, Batch 100] loss: 0.0042736795338987575
[Epoch 19, Batch 200] loss: 0.00435108944267995
[Epoch 19, Batch 300] loss: 0.0031181531681522758
[Epoch 19, Batch 400] loss: 0.0028279674127816177
[Epoch 19, Batch 500] loss: 0.009743999536722186
[Epoch 19, Batch 600] loss: 0.007038768319816881
[Epoch 19, Batch 700] loss: 0.009385288636749464
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0658
Validation Accuracy: 0.9875
Overfitting: 0.0656
[Epoch 20, Batch 100] loss: 0.004692159193996304
[Epoch 20, Batch 200] loss: 0.006875767319088482
[Epoch 20, Batch 300] loss: 0.005632692216840951
[Epoch 20, Batch 400] loss: 0.0037052445818812883
[Epoch 20, Batch 500] loss: 0.007432563128936635
[Epoch 20, Batch 600] loss: 0.005145020576637762
[Epoch 20, Batch 700] loss: 0.005383712553411897
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0689
Validation Accuracy: 0.9873
Overfitting: 0.0685
[Epoch 21, Batch 100] loss: 0.0014434022121349698
[Epoch 21, Batch 200] loss: 0.0034878281246938057
[Epoch 21, Batch 300] loss: 0.0019810374858820977
[Epoch 21, Batch 400] loss: 0.0026835266580488336
[Epoch 21, Batch 500] loss: 0.0025074035458146683
[Epoch 21, Batch 600] loss: 0.004155254014009415
[Epoch 21, Batch 700] loss: 0.005099111276607573
**STATS for Epoch 21** : 
Average training loss: 0.0007
Average validation loss: 0.0798
Validation Accuracy: 0.9852
Overfitting: 0.0791
[Epoch 22, Batch 100] loss: 0.0036760240059106764
[Epoch 22, Batch 200] loss: 0.0031832549433329404
[Epoch 22, Batch 300] loss: 0.0011451520535251801
[Epoch 22, Batch 400] loss: 0.001774732035269153
[Epoch 22, Batch 500] loss: 0.0028677654138778053
[Epoch 22, Batch 600] loss: 0.003910119919815429
[Epoch 22, Batch 700] loss: 0.004469629612053723
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0697
Validation Accuracy: 0.9876
Overfitting: 0.0696
[Epoch 23, Batch 100] loss: 0.0058505227037767326
[Epoch 23, Batch 200] loss: 0.0023152817689924632
[Epoch 23, Batch 300] loss: 0.0031864345721123754
[Epoch 23, Batch 400] loss: 0.0015077820881867865
[Epoch 23, Batch 500] loss: 0.0053330451104079656
[Epoch 23, Batch 600] loss: 0.008009838034467406
[Epoch 23, Batch 700] loss: 0.004555995866917328
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0701
Validation Accuracy: 0.9876
Overfitting: 0.0698
[Epoch 24, Batch 100] loss: 0.002866377758809051
[Epoch 24, Batch 200] loss: 0.002447204717873319
[Epoch 24, Batch 300] loss: 0.007394452904660512
[Epoch 24, Batch 400] loss: 0.0021712450276118035
[Epoch 24, Batch 500] loss: 0.005827402951736076
[Epoch 24, Batch 600] loss: 0.0018350791683587886
[Epoch 24, Batch 700] loss: 0.0011054686473102038
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0684
Validation Accuracy: 0.9882
Overfitting: 0.0684
Fold 2 validation loss: 0.0684
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 1.540816014111042
[Epoch 1, Batch 200] loss: 0.3339859916269779
[Epoch 1, Batch 300] loss: 0.19457127064466476
[Epoch 1, Batch 400] loss: 0.1612146937660873
[Epoch 1, Batch 500] loss: 0.1141837359033525
[Epoch 1, Batch 600] loss: 0.12045850852504372
[Epoch 1, Batch 700] loss: 0.10777155133895576
**STATS for Epoch 1** : 
Average training loss: 0.0078
Average validation loss: 0.0939
Validation Accuracy: 0.9712
Overfitting: 0.0861
Best model saved at epoch 1 with validation loss: 0.0939
[Epoch 2, Batch 100] loss: 0.08084830427542329
[Epoch 2, Batch 200] loss: 0.0878847718751058
[Epoch 2, Batch 300] loss: 0.08104480223730207
[Epoch 2, Batch 400] loss: 0.07784421822056174
[Epoch 2, Batch 500] loss: 0.07367491520475596
[Epoch 2, Batch 600] loss: 0.06958303592167794
[Epoch 2, Batch 700] loss: 0.07284848585492
**STATS for Epoch 2** : 
Average training loss: 0.0044
Average validation loss: 0.0685
Validation Accuracy: 0.9783
Overfitting: 0.0641
Best model saved at epoch 2 with validation loss: 0.0685
[Epoch 3, Batch 100] loss: 0.04894341199658811
[Epoch 3, Batch 200] loss: 0.05947345504537225
[Epoch 3, Batch 300] loss: 0.05773242970695719
[Epoch 3, Batch 400] loss: 0.045572041685227306
[Epoch 3, Batch 500] loss: 0.05902023671427742
[Epoch 3, Batch 600] loss: 0.04630729414289817
[Epoch 3, Batch 700] loss: 0.05366380341234617
**STATS for Epoch 3** : 
Average training loss: 0.0042
Average validation loss: 0.0621
Validation Accuracy: 0.9805
Overfitting: 0.0579
Best model saved at epoch 3 with validation loss: 0.0621
[Epoch 4, Batch 100] loss: 0.039221141054295
[Epoch 4, Batch 200] loss: 0.044102337216027084
[Epoch 4, Batch 300] loss: 0.045458163905423135
[Epoch 4, Batch 400] loss: 0.04671434712945484
[Epoch 4, Batch 500] loss: 0.03621355666778982
[Epoch 4, Batch 600] loss: 0.03729783826507628
[Epoch 4, Batch 700] loss: 0.043853683162014934
**STATS for Epoch 4** : 
Average training loss: 0.0030
Average validation loss: 0.0506
Validation Accuracy: 0.9849
Overfitting: 0.0476
Best model saved at epoch 4 with validation loss: 0.0506
[Epoch 5, Batch 100] loss: 0.027179319374263287
[Epoch 5, Batch 200] loss: 0.03318490331992507
[Epoch 5, Batch 300] loss: 0.02713456108409446
[Epoch 5, Batch 400] loss: 0.030035432288423182
[Epoch 5, Batch 500] loss: 0.04413844602066092
[Epoch 5, Batch 600] loss: 0.04008164358325303
[Epoch 5, Batch 700] loss: 0.030167952358024195
**STATS for Epoch 5** : 
Average training loss: 0.0022
Average validation loss: 0.0543
Validation Accuracy: 0.9839
Overfitting: 0.0522
[Epoch 6, Batch 100] loss: 0.030981421882752328
[Epoch 6, Batch 200] loss: 0.03185541650513187
[Epoch 6, Batch 300] loss: 0.022042134522343985
[Epoch 6, Batch 400] loss: 0.030006821600254627
[Epoch 6, Batch 500] loss: 0.02174327840737533
[Epoch 6, Batch 600] loss: 0.03440780531789642
[Epoch 6, Batch 700] loss: 0.026983513521845453
**STATS for Epoch 6** : 
Average training loss: 0.0018
Average validation loss: 0.0422
Validation Accuracy: 0.9877
Overfitting: 0.0405
Best model saved at epoch 6 with validation loss: 0.0422
[Epoch 7, Batch 100] loss: 0.020227897054282948
[Epoch 7, Batch 200] loss: 0.019676074589951895
[Epoch 7, Batch 300] loss: 0.02220825669632177
[Epoch 7, Batch 400] loss: 0.021770855252980253
[Epoch 7, Batch 500] loss: 0.02725279639766086
[Epoch 7, Batch 600] loss: 0.022177945417934098
[Epoch 7, Batch 700] loss: 0.027136884637584444
**STATS for Epoch 7** : 
Average training loss: 0.0015
Average validation loss: 0.0464
Validation Accuracy: 0.9867
Overfitting: 0.0448
[Epoch 8, Batch 100] loss: 0.01482609699771274
[Epoch 8, Batch 200] loss: 0.01673843359705643
[Epoch 8, Batch 300] loss: 0.016791310231783426
[Epoch 8, Batch 400] loss: 0.020364237146568483
[Epoch 8, Batch 500] loss: 0.020070856213569643
[Epoch 8, Batch 600] loss: 0.024422674389497842
[Epoch 8, Batch 700] loss: 0.023841537286061795
**STATS for Epoch 8** : 
Average training loss: 0.0017
Average validation loss: 0.0528
Validation Accuracy: 0.9852
Overfitting: 0.0511
[Epoch 9, Batch 100] loss: 0.016706147811491975
[Epoch 9, Batch 200] loss: 0.01671018163411645
[Epoch 9, Batch 300] loss: 0.01390674750226026
[Epoch 9, Batch 400] loss: 0.012733774871667264
[Epoch 9, Batch 500] loss: 0.01759664897923358
[Epoch 9, Batch 600] loss: 0.016343246008618736
[Epoch 9, Batch 700] loss: 0.026487196859961842
**STATS for Epoch 9** : 
Average training loss: 0.0013
Average validation loss: 0.0498
Validation Accuracy: 0.9857
Overfitting: 0.0485
[Epoch 10, Batch 100] loss: 0.0119326348490722
[Epoch 10, Batch 200] loss: 0.015229094244132284
[Epoch 10, Batch 300] loss: 0.014919529689941556
[Epoch 10, Batch 400] loss: 0.011978255878057098
[Epoch 10, Batch 500] loss: 0.010777361471336917
[Epoch 10, Batch 600] loss: 0.01624368677905295
[Epoch 10, Batch 700] loss: 0.01641765956181189
**STATS for Epoch 10** : 
Average training loss: 0.0011
Average validation loss: 0.0490
Validation Accuracy: 0.9879
Overfitting: 0.0479
[Epoch 11, Batch 100] loss: 0.015403488502488471
[Epoch 11, Batch 200] loss: 0.010673653453122824
[Epoch 11, Batch 300] loss: 0.01382242563449836
[Epoch 11, Batch 400] loss: 0.014954879707365762
[Epoch 11, Batch 500] loss: 0.010636956847702096
[Epoch 11, Batch 600] loss: 0.011817254596680869
[Epoch 11, Batch 700] loss: 0.007192369161111855
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0527
Validation Accuracy: 0.9872
Overfitting: 0.0515
[Epoch 12, Batch 100] loss: 0.011884367985985592
[Epoch 12, Batch 200] loss: 0.01110708563865046
[Epoch 12, Batch 300] loss: 0.01672042531616171
[Epoch 12, Batch 400] loss: 0.012118601702859451
[Epoch 12, Batch 500] loss: 0.01322611731096913
[Epoch 12, Batch 600] loss: 0.011157672502813512
[Epoch 12, Batch 700] loss: 0.010929992912133457
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0526
Validation Accuracy: 0.9873
Overfitting: 0.0518
[Epoch 13, Batch 100] loss: 0.00967993455567921
[Epoch 13, Batch 200] loss: 0.007749981308024872
[Epoch 13, Batch 300] loss: 0.008883680530398124
[Epoch 13, Batch 400] loss: 0.0085665642812819
[Epoch 13, Batch 500] loss: 0.009650068888586247
[Epoch 13, Batch 600] loss: 0.008848036728122679
[Epoch 13, Batch 700] loss: 0.008330235640833052
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0503
Validation Accuracy: 0.9872
Overfitting: 0.0494
[Epoch 14, Batch 100] loss: 0.008207924637235919
[Epoch 14, Batch 200] loss: 0.006812016187141125
[Epoch 14, Batch 300] loss: 0.006647618557763053
[Epoch 14, Batch 400] loss: 0.006612091597853578
[Epoch 14, Batch 500] loss: 0.005460127771475527
[Epoch 14, Batch 600] loss: 0.010265893217338088
[Epoch 14, Batch 700] loss: 0.010963744070419352
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0584
Validation Accuracy: 0.9850
Overfitting: 0.0577
[Epoch 15, Batch 100] loss: 0.008804669354540239
[Epoch 15, Batch 200] loss: 0.006794562090290128
[Epoch 15, Batch 300] loss: 0.005674358934111296
[Epoch 15, Batch 400] loss: 0.009203632461740198
[Epoch 15, Batch 500] loss: 0.008166885041209753
[Epoch 15, Batch 600] loss: 0.008177434971876209
[Epoch 15, Batch 700] loss: 0.010756439275264712
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0554
Validation Accuracy: 0.9876
Overfitting: 0.0547
[Epoch 16, Batch 100] loss: 0.009192517811061406
[Epoch 16, Batch 200] loss: 0.010282378229699135
[Epoch 16, Batch 300] loss: 0.005749200273021416
[Epoch 16, Batch 400] loss: 0.006426339103054488
[Epoch 16, Batch 500] loss: 0.0052516484979696545
[Epoch 16, Batch 600] loss: 0.011904964937675686
[Epoch 16, Batch 700] loss: 0.010080560447095195
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0571
Validation Accuracy: 0.9882
Overfitting: 0.0565
[Epoch 17, Batch 100] loss: 0.005148172349977358
[Epoch 17, Batch 200] loss: 0.005208711945797404
[Epoch 17, Batch 300] loss: 0.004634803346925764
[Epoch 17, Batch 400] loss: 0.00807979015595265
[Epoch 17, Batch 500] loss: 0.006167071691379533
[Epoch 17, Batch 600] loss: 0.005296843252353938
[Epoch 17, Batch 700] loss: 0.006715400548819162
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0586
Validation Accuracy: 0.9875
Overfitting: 0.0583
[Epoch 18, Batch 100] loss: 0.004511514670239194
[Epoch 18, Batch 200] loss: 0.005908280323035342
[Epoch 18, Batch 300] loss: 0.0072424696345683515
[Epoch 18, Batch 400] loss: 0.008033181964265168
[Epoch 18, Batch 500] loss: 0.009451078453089394
[Epoch 18, Batch 600] loss: 0.006224118497921154
[Epoch 18, Batch 700] loss: 0.005087845572406877
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0615
Validation Accuracy: 0.9882
Overfitting: 0.0612
[Epoch 19, Batch 100] loss: 0.002420403044561681
[Epoch 19, Batch 200] loss: 0.005514290539686044
[Epoch 19, Batch 300] loss: 0.007827102425985687
[Epoch 19, Batch 400] loss: 0.006542024896943986
[Epoch 19, Batch 500] loss: 0.005530614127928856
[Epoch 19, Batch 600] loss: 0.00513840481353327
[Epoch 19, Batch 700] loss: 0.004684654734473952
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0569
Validation Accuracy: 0.9880
Overfitting: 0.0566
[Epoch 20, Batch 100] loss: 0.0015503574598085379
[Epoch 20, Batch 200] loss: 0.0035741462003124978
[Epoch 20, Batch 300] loss: 0.002776681431241741
[Epoch 20, Batch 400] loss: 0.0024167173873092906
[Epoch 20, Batch 500] loss: 0.009051183907777158
[Epoch 20, Batch 600] loss: 0.0031955254272156707
[Epoch 20, Batch 700] loss: 0.0030669721658046
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0587
Validation Accuracy: 0.9886
Overfitting: 0.0585
[Epoch 21, Batch 100] loss: 0.0021683689205906375
[Epoch 21, Batch 200] loss: 0.0006468667068975265
[Epoch 21, Batch 300] loss: 0.002178229517330692
[Epoch 21, Batch 400] loss: 0.0013647793334848758
[Epoch 21, Batch 500] loss: 0.001079411830312438
[Epoch 21, Batch 600] loss: 0.0006546561906077031
[Epoch 21, Batch 700] loss: 0.0035642982829347148
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0588
Validation Accuracy: 0.9891
Overfitting: 0.0586
[Epoch 22, Batch 100] loss: 0.0008244872487252053
[Epoch 22, Batch 200] loss: 0.0005200188900721514
[Epoch 22, Batch 300] loss: 0.00035402742786970975
[Epoch 22, Batch 400] loss: 0.00038554973882128253
[Epoch 22, Batch 500] loss: 0.0005491612477931085
[Epoch 22, Batch 600] loss: 0.0011979423066742357
[Epoch 22, Batch 700] loss: 0.0005611367256724975
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9882
Overfitting: 0.0604
[Epoch 23, Batch 100] loss: 0.00025272155999800816
[Epoch 23, Batch 200] loss: 0.00021203386367005806
[Epoch 23, Batch 300] loss: 0.0002666116163186416
[Epoch 23, Batch 400] loss: 0.00015426558867005725
[Epoch 23, Batch 500] loss: 0.0005277325282818879
[Epoch 23, Batch 600] loss: 0.00013750136030822092
[Epoch 23, Batch 700] loss: 0.00033930894835382475
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0588
Validation Accuracy: 0.9894
Overfitting: 0.0588
[Epoch 24, Batch 100] loss: 0.0009479910786143364
[Epoch 24, Batch 200] loss: 0.0001609811039591591
[Epoch 24, Batch 300] loss: 0.00013358565636536923
[Epoch 24, Batch 400] loss: 0.00016555479648900474
[Epoch 24, Batch 500] loss: 0.00021082793015878565
[Epoch 24, Batch 600] loss: 0.00028618140249392354
[Epoch 24, Batch 700] loss: 0.00020352848252329635
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9896
Overfitting: 0.0608
Fold 3 validation loss: 0.0608
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.5049524280428885
[Epoch 1, Batch 200] loss: 0.3470201252400875
[Epoch 1, Batch 300] loss: 0.20791315726935863
[Epoch 1, Batch 400] loss: 0.16032805908471345
[Epoch 1, Batch 500] loss: 0.12707076016813518
[Epoch 1, Batch 600] loss: 0.12009168336167932
[Epoch 1, Batch 700] loss: 0.10521016407757998
**STATS for Epoch 1** : 
Average training loss: 0.0066
Average validation loss: 0.0898
Validation Accuracy: 0.9712
Overfitting: 0.0831
Best model saved at epoch 1 with validation loss: 0.0898
[Epoch 2, Batch 100] loss: 0.09438374303281308
[Epoch 2, Batch 200] loss: 0.07691296016331763
[Epoch 2, Batch 300] loss: 0.08351877103559673
[Epoch 2, Batch 400] loss: 0.07779412163654342
[Epoch 2, Batch 500] loss: 0.07530986928381025
[Epoch 2, Batch 600] loss: 0.0684001902351156
[Epoch 2, Batch 700] loss: 0.06691797822946682
**STATS for Epoch 2** : 
Average training loss: 0.0041
Average validation loss: 0.0588
Validation Accuracy: 0.9816
Overfitting: 0.0547
Best model saved at epoch 2 with validation loss: 0.0588
[Epoch 3, Batch 100] loss: 0.051763718244619665
[Epoch 3, Batch 200] loss: 0.06359913520980626
[Epoch 3, Batch 300] loss: 0.0548492139740847
[Epoch 3, Batch 400] loss: 0.06062802415108308
[Epoch 3, Batch 500] loss: 0.052813944877125325
[Epoch 3, Batch 600] loss: 0.04985266075935215
[Epoch 3, Batch 700] loss: 0.05164284666068852
**STATS for Epoch 3** : 
Average training loss: 0.0031
Average validation loss: 0.0512
Validation Accuracy: 0.9847
Overfitting: 0.0481
Best model saved at epoch 3 with validation loss: 0.0512
[Epoch 4, Batch 100] loss: 0.03810717017622665
[Epoch 4, Batch 200] loss: 0.04074752468033694
[Epoch 4, Batch 300] loss: 0.043194298218004405
[Epoch 4, Batch 400] loss: 0.05688458419870585
[Epoch 4, Batch 500] loss: 0.03991901512257755
[Epoch 4, Batch 600] loss: 0.04706872302806005
[Epoch 4, Batch 700] loss: 0.0377893584233243
**STATS for Epoch 4** : 
Average training loss: 0.0023
Average validation loss: 0.0510
Validation Accuracy: 0.9847
Overfitting: 0.0487
Best model saved at epoch 4 with validation loss: 0.0510
[Epoch 5, Batch 100] loss: 0.032632949055405334
[Epoch 5, Batch 200] loss: 0.04510776247130707
[Epoch 5, Batch 300] loss: 0.03778809943236411
[Epoch 5, Batch 400] loss: 0.03608316894504242
[Epoch 5, Batch 500] loss: 0.0314297130308114
[Epoch 5, Batch 600] loss: 0.03642646119813435
[Epoch 5, Batch 700] loss: 0.033186495386471504
**STATS for Epoch 5** : 
Average training loss: 0.0020
Average validation loss: 0.0522
Validation Accuracy: 0.9846
Overfitting: 0.0501
[Epoch 6, Batch 100] loss: 0.025993385504116305
[Epoch 6, Batch 200] loss: 0.02971724302857183
[Epoch 6, Batch 300] loss: 0.030209513947484085
[Epoch 6, Batch 400] loss: 0.029166914203669875
[Epoch 6, Batch 500] loss: 0.02832403626409359
[Epoch 6, Batch 600] loss: 0.03589973048074171
[Epoch 6, Batch 700] loss: 0.03769863033114234
**STATS for Epoch 6** : 
Average training loss: 0.0025
Average validation loss: 0.0367
Validation Accuracy: 0.9893
Overfitting: 0.0343
Best model saved at epoch 6 with validation loss: 0.0367
[Epoch 7, Batch 100] loss: 0.02216571375989588
[Epoch 7, Batch 200] loss: 0.020464665335894097
[Epoch 7, Batch 300] loss: 0.023205047752999235
[Epoch 7, Batch 400] loss: 0.026766776152071542
[Epoch 7, Batch 500] loss: 0.028804625248449157
[Epoch 7, Batch 600] loss: 0.02856671342160553
[Epoch 7, Batch 700] loss: 0.026968657384277322
**STATS for Epoch 7** : 
Average training loss: 0.0021
Average validation loss: 0.0411
Validation Accuracy: 0.9881
Overfitting: 0.0390
[Epoch 8, Batch 100] loss: 0.020272426645678934
[Epoch 8, Batch 200] loss: 0.017992711797123775
[Epoch 8, Batch 300] loss: 0.018164989047218114
[Epoch 8, Batch 400] loss: 0.02285585269855801
[Epoch 8, Batch 500] loss: 0.014124197687197011
[Epoch 8, Batch 600] loss: 0.024638412536296526
[Epoch 8, Batch 700] loss: 0.022886359293188434
**STATS for Epoch 8** : 
Average training loss: 0.0018
Average validation loss: 0.0473
Validation Accuracy: 0.9865
Overfitting: 0.0455
[Epoch 9, Batch 100] loss: 0.019081845542968948
[Epoch 9, Batch 200] loss: 0.01714073193958029
[Epoch 9, Batch 300] loss: 0.019253801667073276
[Epoch 9, Batch 400] loss: 0.01545043725782307
[Epoch 9, Batch 500] loss: 0.014759190114273225
[Epoch 9, Batch 600] loss: 0.018288209386664676
[Epoch 9, Batch 700] loss: 0.026279086847498547
**STATS for Epoch 9** : 
Average training loss: 0.0014
Average validation loss: 0.0383
Validation Accuracy: 0.9884
Overfitting: 0.0369
[Epoch 10, Batch 100] loss: 0.01729710247775074
[Epoch 10, Batch 200] loss: 0.014149830511305481
[Epoch 10, Batch 300] loss: 0.01705201550386846
[Epoch 10, Batch 400] loss: 0.01153993758285651
[Epoch 10, Batch 500] loss: 0.019283818213734774
[Epoch 10, Batch 600] loss: 0.011164891257794806
[Epoch 10, Batch 700] loss: 0.015614123501145515
**STATS for Epoch 10** : 
Average training loss: 0.0019
Average validation loss: 0.0610
Validation Accuracy: 0.9813
Overfitting: 0.0592
[Epoch 11, Batch 100] loss: 0.013775939144688892
[Epoch 11, Batch 200] loss: 0.008946295030182228
[Epoch 11, Batch 300] loss: 0.013038280405817204
[Epoch 11, Batch 400] loss: 0.009956690077960956
[Epoch 11, Batch 500] loss: 0.013075732001743745
[Epoch 11, Batch 600] loss: 0.01891489208512212
[Epoch 11, Batch 700] loss: 0.01592391321537434
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0398
Validation Accuracy: 0.9888
Overfitting: 0.0386
[Epoch 12, Batch 100] loss: 0.007281652082274377
[Epoch 12, Batch 200] loss: 0.007278301333208219
[Epoch 12, Batch 300] loss: 0.01139327393284475
[Epoch 12, Batch 400] loss: 0.00879091932263691
[Epoch 12, Batch 500] loss: 0.008781038443448779
[Epoch 12, Batch 600] loss: 0.011382243495027068
[Epoch 12, Batch 700] loss: 0.010975006317676162
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0373
Validation Accuracy: 0.9902
Overfitting: 0.0363
[Epoch 13, Batch 100] loss: 0.007274600852178991
[Epoch 13, Batch 200] loss: 0.011841393450895339
[Epoch 13, Batch 300] loss: 0.013529251854561154
[Epoch 13, Batch 400] loss: 0.007457417981277104
[Epoch 13, Batch 500] loss: 0.008917510977444181
[Epoch 13, Batch 600] loss: 0.013576067728936323
[Epoch 13, Batch 700] loss: 0.012750125697857584
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0524
Validation Accuracy: 0.9861
Overfitting: 0.0513
[Epoch 14, Batch 100] loss: 0.009701093572730315
[Epoch 14, Batch 200] loss: 0.005032240103100776
[Epoch 14, Batch 300] loss: 0.0057312515497505954
[Epoch 14, Batch 400] loss: 0.008758173188443834
[Epoch 14, Batch 500] loss: 0.011154714507392782
[Epoch 14, Batch 600] loss: 0.00730531196553784
[Epoch 14, Batch 700] loss: 0.008133362402586499
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0582
Validation Accuracy: 0.9866
Overfitting: 0.0577
[Epoch 15, Batch 100] loss: 0.006028291924194491
[Epoch 15, Batch 200] loss: 0.007713686514907749
[Epoch 15, Batch 300] loss: 0.006973781129217969
[Epoch 15, Batch 400] loss: 0.008089133431039954
[Epoch 15, Batch 500] loss: 0.006594403330655041
[Epoch 15, Batch 600] loss: 0.009081347789310712
[Epoch 15, Batch 700] loss: 0.004913993625614239
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0514
Validation Accuracy: 0.9890
Overfitting: 0.0509
[Epoch 16, Batch 100] loss: 0.007537536548979915
[Epoch 16, Batch 200] loss: 0.0069010720975529695
[Epoch 16, Batch 300] loss: 0.00960473493554673
[Epoch 16, Batch 400] loss: 0.008391459716231111
[Epoch 16, Batch 500] loss: 0.011507530601384132
[Epoch 16, Batch 600] loss: 0.010149112735707604
[Epoch 16, Batch 700] loss: 0.018174145053817484
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0567
Validation Accuracy: 0.9877
Overfitting: 0.0562
[Epoch 17, Batch 100] loss: 0.007717839513134095
[Epoch 17, Batch 200] loss: 0.008403264424687222
[Epoch 17, Batch 300] loss: 0.007953660694929567
[Epoch 17, Batch 400] loss: 0.0069564091833717616
[Epoch 17, Batch 500] loss: 0.007648313934014368
[Epoch 17, Batch 600] loss: 0.00777341822039034
[Epoch 17, Batch 700] loss: 0.01627788975714793
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0492
Validation Accuracy: 0.9886
Overfitting: 0.0484
[Epoch 18, Batch 100] loss: 0.004104884707203382
[Epoch 18, Batch 200] loss: 0.0035882160076744184
[Epoch 18, Batch 300] loss: 0.004154642499300963
[Epoch 18, Batch 400] loss: 0.004252087717286485
[Epoch 18, Batch 500] loss: 0.012409069325040037
[Epoch 18, Batch 600] loss: 0.00606923973216908
[Epoch 18, Batch 700] loss: 0.01113565814469439
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0505
Validation Accuracy: 0.9888
Overfitting: 0.0501
[Epoch 19, Batch 100] loss: 0.0038878700113582454
[Epoch 19, Batch 200] loss: 0.00518695373837545
[Epoch 19, Batch 300] loss: 0.004465879456215589
[Epoch 19, Batch 400] loss: 0.011864408998367253
[Epoch 19, Batch 500] loss: 0.01079182933507127
[Epoch 19, Batch 600] loss: 0.012745696105903336
[Epoch 19, Batch 700] loss: 0.011957576569802768
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0506
Validation Accuracy: 0.9884
Overfitting: 0.0501
[Epoch 20, Batch 100] loss: 0.0050827434395978345
[Epoch 20, Batch 200] loss: 0.003757526697445428
[Epoch 20, Batch 300] loss: 0.007133602246613009
[Epoch 20, Batch 400] loss: 0.008164940745846252
[Epoch 20, Batch 500] loss: 0.0076667892225123066
[Epoch 20, Batch 600] loss: 0.009614636830415293
[Epoch 20, Batch 700] loss: 0.009197891246003564
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0506
Validation Accuracy: 0.9888
Overfitting: 0.0502
[Epoch 21, Batch 100] loss: 0.005067369641054711
[Epoch 21, Batch 200] loss: 0.004627546409037678
[Epoch 21, Batch 300] loss: 0.004253805157368333
[Epoch 21, Batch 400] loss: 0.005454509930447102
[Epoch 21, Batch 500] loss: 0.003983573375280685
[Epoch 21, Batch 600] loss: 0.004687108007013876
[Epoch 21, Batch 700] loss: 0.00472221038614407
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0488
Validation Accuracy: 0.9893
Overfitting: 0.0485
[Epoch 22, Batch 100] loss: 0.006480154542036871
[Epoch 22, Batch 200] loss: 0.002941572578311025
[Epoch 22, Batch 300] loss: 0.003106510209281623
[Epoch 22, Batch 400] loss: 0.0036055682089863694
[Epoch 22, Batch 500] loss: 0.002742589602726184
[Epoch 22, Batch 600] loss: 0.005619003452087554
[Epoch 22, Batch 700] loss: 0.006145817788574277
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0540
Validation Accuracy: 0.9892
Overfitting: 0.0540
[Epoch 23, Batch 100] loss: 0.003155666207061358
[Epoch 23, Batch 200] loss: 0.003097868850743453
[Epoch 23, Batch 300] loss: 0.002430181707066481
[Epoch 23, Batch 400] loss: 0.0027807830819597257
[Epoch 23, Batch 500] loss: 0.0033782071756235156
[Epoch 23, Batch 600] loss: 0.0009426859808114329
[Epoch 23, Batch 700] loss: 0.0012775985880855956
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0496
Validation Accuracy: 0.9895
Overfitting: 0.0493
[Epoch 24, Batch 100] loss: 0.0010385867721424801
[Epoch 24, Batch 200] loss: 0.0012639021105314897
[Epoch 24, Batch 300] loss: 0.0030266628242929983
[Epoch 24, Batch 400] loss: 0.0012854275455481457
[Epoch 24, Batch 500] loss: 0.00037271566909211626
[Epoch 24, Batch 600] loss: 0.001165207658784908
[Epoch 24, Batch 700] loss: 0.001076696629959315
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0536
Validation Accuracy: 0.9893
Overfitting: 0.0533
Fold 4 validation loss: 0.0536
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 1.6907784575223923
[Epoch 1, Batch 200] loss: 0.35786198258399965
[Epoch 1, Batch 300] loss: 0.2106336094252765
[Epoch 1, Batch 400] loss: 0.15343871053308247
[Epoch 1, Batch 500] loss: 0.14330883380025625
[Epoch 1, Batch 600] loss: 0.10856164485216141
[Epoch 1, Batch 700] loss: 0.10536233099177479
**STATS for Epoch 1** : 
Average training loss: 0.0056
Average validation loss: 0.0861
Validation Accuracy: 0.9726
Overfitting: 0.0805
Best model saved at epoch 1 with validation loss: 0.0861
[Epoch 2, Batch 100] loss: 0.08394426936283708
[Epoch 2, Batch 200] loss: 0.09048380504362286
[Epoch 2, Batch 300] loss: 0.07573565148748457
[Epoch 2, Batch 400] loss: 0.07072004357818513
[Epoch 2, Batch 500] loss: 0.06809558246517554
[Epoch 2, Batch 600] loss: 0.06356696097180248
[Epoch 2, Batch 700] loss: 0.07246138763148338
**STATS for Epoch 2** : 
Average training loss: 0.0038
Average validation loss: 0.0547
Validation Accuracy: 0.9823
Overfitting: 0.0509
Best model saved at epoch 2 with validation loss: 0.0547
[Epoch 3, Batch 100] loss: 0.055769241901580245
[Epoch 3, Batch 200] loss: 0.04455348939052783
[Epoch 3, Batch 300] loss: 0.056088507864624264
[Epoch 3, Batch 400] loss: 0.05468713047681376
[Epoch 3, Batch 500] loss: 0.05248612822266296
[Epoch 3, Batch 600] loss: 0.049294679211452606
[Epoch 3, Batch 700] loss: 0.04568959726719186
**STATS for Epoch 3** : 
Average training loss: 0.0036
Average validation loss: 0.0518
Validation Accuracy: 0.9843
Overfitting: 0.0482
Best model saved at epoch 3 with validation loss: 0.0518
[Epoch 4, Batch 100] loss: 0.03749895660788752
[Epoch 4, Batch 200] loss: 0.046655859305756164
[Epoch 4, Batch 300] loss: 0.04253539391094819
[Epoch 4, Batch 400] loss: 0.041992019874742256
[Epoch 4, Batch 500] loss: 0.038586072182515634
[Epoch 4, Batch 600] loss: 0.0419102999655297
[Epoch 4, Batch 700] loss: 0.037003028416074814
**STATS for Epoch 4** : 
Average training loss: 0.0031
Average validation loss: 0.0447
Validation Accuracy: 0.9866
Overfitting: 0.0416
Best model saved at epoch 4 with validation loss: 0.0447
[Epoch 5, Batch 100] loss: 0.032258990679401904
[Epoch 5, Batch 200] loss: 0.030534737924463116
[Epoch 5, Batch 300] loss: 0.029397672768100166
[Epoch 5, Batch 400] loss: 0.03214564749010606
[Epoch 5, Batch 500] loss: 0.03133798007911537
[Epoch 5, Batch 600] loss: 0.03453228307538666
[Epoch 5, Batch 700] loss: 0.03311001911817584
**STATS for Epoch 5** : 
Average training loss: 0.0025
Average validation loss: 0.0437
Validation Accuracy: 0.9858
Overfitting: 0.0412
Best model saved at epoch 5 with validation loss: 0.0437
[Epoch 6, Batch 100] loss: 0.026102863339765463
[Epoch 6, Batch 200] loss: 0.02239208079816308
[Epoch 6, Batch 300] loss: 0.027572636285040062
[Epoch 6, Batch 400] loss: 0.024414291696739383
[Epoch 6, Batch 500] loss: 0.026451947436871705
[Epoch 6, Batch 600] loss: 0.02707383870088961
[Epoch 6, Batch 700] loss: 0.03228643636452034
**STATS for Epoch 6** : 
Average training loss: 0.0025
Average validation loss: 0.0394
Validation Accuracy: 0.9884
Overfitting: 0.0369
Best model saved at epoch 6 with validation loss: 0.0394
[Epoch 7, Batch 100] loss: 0.01828760238684481
[Epoch 7, Batch 200] loss: 0.02099422868457623
[Epoch 7, Batch 300] loss: 0.02001735753714456
[Epoch 7, Batch 400] loss: 0.02153119538212195
[Epoch 7, Batch 500] loss: 0.02752236722095404
[Epoch 7, Batch 600] loss: 0.016522515912220113
[Epoch 7, Batch 700] loss: 0.028120686270849547
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0397
Validation Accuracy: 0.9872
Overfitting: 0.0378
[Epoch 8, Batch 100] loss: 0.0224240230799478
[Epoch 8, Batch 200] loss: 0.023197966399311553
[Epoch 8, Batch 300] loss: 0.01749436723650433
[Epoch 8, Batch 400] loss: 0.01775610582655645
[Epoch 8, Batch 500] loss: 0.01700757159931527
[Epoch 8, Batch 600] loss: 0.024448993701953442
[Epoch 8, Batch 700] loss: 0.01943955169786932
**STATS for Epoch 8** : 
Average training loss: 0.0011
Average validation loss: 0.0407
Validation Accuracy: 0.9888
Overfitting: 0.0396
[Epoch 9, Batch 100] loss: 0.014612435186572839
[Epoch 9, Batch 200] loss: 0.014801828224663041
[Epoch 9, Batch 300] loss: 0.014518207174842247
[Epoch 9, Batch 400] loss: 0.015791225079010474
[Epoch 9, Batch 500] loss: 0.018689922395860776
[Epoch 9, Batch 600] loss: 0.010007293808012036
[Epoch 9, Batch 700] loss: 0.022933079890499357
**STATS for Epoch 9** : 
Average training loss: 0.0012
Average validation loss: 0.0490
Validation Accuracy: 0.9862
Overfitting: 0.0478
[Epoch 10, Batch 100] loss: 0.013912180555344093
[Epoch 10, Batch 200] loss: 0.010508617713931016
[Epoch 10, Batch 300] loss: 0.017921653029698063
[Epoch 10, Batch 400] loss: 0.01566060561894119
[Epoch 10, Batch 500] loss: 0.01003187727270415
[Epoch 10, Batch 600] loss: 0.012956902812729822
[Epoch 10, Batch 700] loss: 0.016826325477704813
**STATS for Epoch 10** : 
Average training loss: 0.0008
Average validation loss: 0.0456
Validation Accuracy: 0.9872
Overfitting: 0.0448
[Epoch 11, Batch 100] loss: 0.014042069752977114
[Epoch 11, Batch 200] loss: 0.008398196681664558
[Epoch 11, Batch 300] loss: 0.0124363961617928
[Epoch 11, Batch 400] loss: 0.020012033381353832
[Epoch 11, Batch 500] loss: 0.014250245648290728
[Epoch 11, Batch 600] loss: 0.013511262912506936
[Epoch 11, Batch 700] loss: 0.012626589331775904
**STATS for Epoch 11** : 
Average training loss: 0.0005
Average validation loss: 0.0382
Validation Accuracy: 0.9902
Overfitting: 0.0377
Best model saved at epoch 11 with validation loss: 0.0382
[Epoch 12, Batch 100] loss: 0.006030275970297225
[Epoch 12, Batch 200] loss: 0.012005474082725414
[Epoch 12, Batch 300] loss: 0.009335160603259283
[Epoch 12, Batch 400] loss: 0.01398160804019426
[Epoch 12, Batch 500] loss: 0.010982759025609993
[Epoch 12, Batch 600] loss: 0.009183098186967982
[Epoch 12, Batch 700] loss: 0.009414116766238293
**STATS for Epoch 12** : 
Average training loss: 0.0009
Average validation loss: 0.0464
Validation Accuracy: 0.9880
Overfitting: 0.0456
[Epoch 13, Batch 100] loss: 0.011097125811356818
[Epoch 13, Batch 200] loss: 0.010327926512109115
[Epoch 13, Batch 300] loss: 0.01156492798261752
[Epoch 13, Batch 400] loss: 0.011768163734668633
[Epoch 13, Batch 500] loss: 0.01096575700561516
[Epoch 13, Batch 600] loss: 0.011630014128313633
[Epoch 13, Batch 700] loss: 0.005682876070786733
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0403
Validation Accuracy: 0.9897
Overfitting: 0.0397
[Epoch 14, Batch 100] loss: 0.007575961738875776
[Epoch 14, Batch 200] loss: 0.010201269700883132
[Epoch 14, Batch 300] loss: 0.006522676405247694
[Epoch 14, Batch 400] loss: 0.008139795231318202
[Epoch 14, Batch 500] loss: 0.010591854865101596
[Epoch 14, Batch 600] loss: 0.008770163328192667
[Epoch 14, Batch 700] loss: 0.014503227679088014
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0477
Validation Accuracy: 0.9877
Overfitting: 0.0468
[Epoch 15, Batch 100] loss: 0.010939811825446668
[Epoch 15, Batch 200] loss: 0.006144663304003189
[Epoch 15, Batch 300] loss: 0.004842395027380917
[Epoch 15, Batch 400] loss: 0.010821208462602953
[Epoch 15, Batch 500] loss: 0.0097969779932464
[Epoch 15, Batch 600] loss: 0.006939252836764354
[Epoch 15, Batch 700] loss: 0.007608393688415162
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0455
Validation Accuracy: 0.9882
Overfitting: 0.0448
[Epoch 16, Batch 100] loss: 0.0025687665693840244
[Epoch 16, Batch 200] loss: 0.004138634105829624
[Epoch 16, Batch 300] loss: 0.005528894286230752
[Epoch 16, Batch 400] loss: 0.00882659217930268
[Epoch 16, Batch 500] loss: 0.013540538041197578
[Epoch 16, Batch 600] loss: 0.01076337774782587
[Epoch 16, Batch 700] loss: 0.008252295288111782
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0412
Validation Accuracy: 0.9892
Overfitting: 0.0408
[Epoch 17, Batch 100] loss: 0.0041768572577075246
[Epoch 17, Batch 200] loss: 0.004428577793769364
[Epoch 17, Batch 300] loss: 0.01185172096282713
[Epoch 17, Batch 400] loss: 0.006629243383990797
[Epoch 17, Batch 500] loss: 0.00569064594061274
[Epoch 17, Batch 600] loss: 0.005577658615675318
[Epoch 17, Batch 700] loss: 0.007604843486160462
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0474
Validation Accuracy: 0.9883
Overfitting: 0.0469
[Epoch 18, Batch 100] loss: 0.0051492486872530205
[Epoch 18, Batch 200] loss: 0.008512885119125712
[Epoch 18, Batch 300] loss: 0.0058096162435754195
[Epoch 18, Batch 400] loss: 0.004347705385894188
[Epoch 18, Batch 500] loss: 0.005477421161685925
[Epoch 18, Batch 600] loss: 0.008204572966537853
[Epoch 18, Batch 700] loss: 0.008714160490662835
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0518
Validation Accuracy: 0.9878
Overfitting: 0.0516
[Epoch 19, Batch 100] loss: 0.004361407274536759
[Epoch 19, Batch 200] loss: 0.004268466174085006
[Epoch 19, Batch 300] loss: 0.0053658680255011856
[Epoch 19, Batch 400] loss: 0.006067358874470301
[Epoch 19, Batch 500] loss: 0.00695119384437021
[Epoch 19, Batch 600] loss: 0.007710011601240012
[Epoch 19, Batch 700] loss: 0.007906348560918559
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0438
Validation Accuracy: 0.9901
Overfitting: 0.0435
[Epoch 20, Batch 100] loss: 0.003926152431349692
[Epoch 20, Batch 200] loss: 0.003314768178709073
[Epoch 20, Batch 300] loss: 0.004302392481707784
[Epoch 20, Batch 400] loss: 0.003621385298877158
[Epoch 20, Batch 500] loss: 0.00409331171267695
[Epoch 20, Batch 600] loss: 0.003505890677802199
[Epoch 20, Batch 700] loss: 0.007352422317540004
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0518
Validation Accuracy: 0.9892
Overfitting: 0.0516
[Epoch 21, Batch 100] loss: 0.003021538469222378
[Epoch 21, Batch 200] loss: 0.003249854033967381
[Epoch 21, Batch 300] loss: 0.002642805009872973
[Epoch 21, Batch 400] loss: 0.0018021738062998338
[Epoch 21, Batch 500] loss: 0.003957933914916794
[Epoch 21, Batch 600] loss: 0.004000568556514281
[Epoch 21, Batch 700] loss: 0.006634073115631622
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0603
Validation Accuracy: 0.9880
Overfitting: 0.0599
[Epoch 22, Batch 100] loss: 0.0036196497139326313
[Epoch 22, Batch 200] loss: 0.00487246094499369
[Epoch 22, Batch 300] loss: 0.0018993641666520489
[Epoch 22, Batch 400] loss: 0.006134558436242514
[Epoch 22, Batch 500] loss: 0.00196491755770694
[Epoch 22, Batch 600] loss: 0.0025503796134216826
[Epoch 22, Batch 700] loss: 0.003964293947408066
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0503
Validation Accuracy: 0.9897
Overfitting: 0.0501
[Epoch 23, Batch 100] loss: 0.0009322598970823037
[Epoch 23, Batch 200] loss: 0.001265912467151793
[Epoch 23, Batch 300] loss: 0.0008328723535936433
[Epoch 23, Batch 400] loss: 0.0003210964419854534
[Epoch 23, Batch 500] loss: 0.001424291649192355
[Epoch 23, Batch 600] loss: 0.0007605986730851555
[Epoch 23, Batch 700] loss: 0.004594663452801342
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0529
Validation Accuracy: 0.9885
Overfitting: 0.0528
[Epoch 24, Batch 100] loss: 0.0011911004944863634
[Epoch 24, Batch 200] loss: 0.004623339959355235
[Epoch 24, Batch 300] loss: 0.005404483560358813
[Epoch 24, Batch 400] loss: 0.0030693363237443805
[Epoch 24, Batch 500] loss: 0.0011456407165178462
[Epoch 24, Batch 600] loss: 0.001774672757755411
[Epoch 24, Batch 700] loss: 0.0012633021806846044
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0515
Validation Accuracy: 0.9899
Overfitting: 0.0514
Fold 5 validation loss: 0.0515
Mean validation loss across all folds for Trial 14 is 0.0578 with trial config:  l1: 128, l2: 64, lr: 0.009510851642562738, batch_size: 64
[I 2024-12-10 07:40:54,922] Trial 13 finished with value: 0.05781195494020178 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.009510851642562738, 'batch_size': 64}. Best is trial 9 with value: 0.05047078778321675.

Selected Hyperparameters for Trial 15:
  l1: 256, l2: 128, lr: 0.0032659664983692143, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.1497866678237916
**STATS for Epoch 1** : 
Average training loss: 0.3010
Average validation loss: 0.4536
Validation Accuracy: 0.8497
Overfitting: 0.1525
Best model saved at epoch 1 with validation loss: 0.4536
[Epoch 2, Batch 100] loss: 0.3370710723102093
**STATS for Epoch 2** : 
Average training loss: 0.1232
Average validation loss: 0.2266
Validation Accuracy: 0.9337
Overfitting: 0.1034
Best model saved at epoch 2 with validation loss: 0.2266
[Epoch 3, Batch 100] loss: 0.21251242086291314
**STATS for Epoch 3** : 
Average training loss: 0.0831
Average validation loss: 0.1562
Validation Accuracy: 0.9511
Overfitting: 0.0731
Best model saved at epoch 3 with validation loss: 0.1562
[Epoch 4, Batch 100] loss: 0.15722070299088955
**STATS for Epoch 4** : 
Average training loss: 0.0634
Average validation loss: 0.1343
Validation Accuracy: 0.9566
Overfitting: 0.0709
Best model saved at epoch 4 with validation loss: 0.1343
[Epoch 5, Batch 100] loss: 0.12272097464650869
**STATS for Epoch 5** : 
Average training loss: 0.0536
Average validation loss: 0.1011
Validation Accuracy: 0.9675
Overfitting: 0.0475
Best model saved at epoch 5 with validation loss: 0.1011
[Epoch 6, Batch 100] loss: 0.10443035222589969
**STATS for Epoch 6** : 
Average training loss: 0.0440
Average validation loss: 0.0994
Validation Accuracy: 0.9697
Overfitting: 0.0554
Best model saved at epoch 6 with validation loss: 0.0994
[Epoch 7, Batch 100] loss: 0.08638861481100321
**STATS for Epoch 7** : 
Average training loss: 0.0414
Average validation loss: 0.0762
Validation Accuracy: 0.9756
Overfitting: 0.0349
Best model saved at epoch 7 with validation loss: 0.0762
[Epoch 8, Batch 100] loss: 0.08113451682031154
**STATS for Epoch 8** : 
Average training loss: 0.0347
Average validation loss: 0.0753
Validation Accuracy: 0.9752
Overfitting: 0.0405
Best model saved at epoch 8 with validation loss: 0.0753
[Epoch 9, Batch 100] loss: 0.06767661662772298
**STATS for Epoch 9** : 
Average training loss: 0.0349
Average validation loss: 0.0726
Validation Accuracy: 0.9762
Overfitting: 0.0377
[I 2024-12-10 07:42:19,070] Trial 14 pruned. 

Selected Hyperparameters for Trial 16:
  l1: 256, l2: 128, lr: 0.0011976325173585483, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2933517146110534
[Epoch 1, Batch 200] loss: 2.2543922090530395
[Epoch 1, Batch 300] loss: 2.0568501281738283
**STATS for Epoch 1** : 
Average training loss: 0.2223
Average validation loss: 0.6765
Validation Accuracy: 0.8078
Overfitting: 0.4542
Best model saved at epoch 1 with validation loss: 0.6765
[Epoch 2, Batch 100] loss: 0.5582328155636788
[Epoch 2, Batch 200] loss: 0.4206571421027184
[Epoch 2, Batch 300] loss: 0.3694590337574482
**STATS for Epoch 2** : 
Average training loss: 0.0609
Average validation loss: 0.2741
Validation Accuracy: 0.9157
Overfitting: 0.2132
Best model saved at epoch 2 with validation loss: 0.2741
[Epoch 3, Batch 100] loss: 0.2785379011929035
[Epoch 3, Batch 200] loss: 0.2634926873445511
[Epoch 3, Batch 300] loss: 0.2301480555534363
**STATS for Epoch 3** : 
Average training loss: 0.0432
Average validation loss: 0.1881
Validation Accuracy: 0.9422
Overfitting: 0.1450
Best model saved at epoch 3 with validation loss: 0.1881
[Epoch 4, Batch 100] loss: 0.19082309551537036
[Epoch 4, Batch 200] loss: 0.184292596206069
[Epoch 4, Batch 300] loss: 0.15638563461601734
**STATS for Epoch 4** : 
Average training loss: 0.0327
Average validation loss: 0.1359
Validation Accuracy: 0.9583
Overfitting: 0.1032
Best model saved at epoch 4 with validation loss: 0.1359
[Epoch 5, Batch 100] loss: 0.15232095655053854
[Epoch 5, Batch 200] loss: 0.1360537614300847
[Epoch 5, Batch 300] loss: 0.1339573011919856
**STATS for Epoch 5** : 
Average training loss: 0.0250
Average validation loss: 0.1108
Validation Accuracy: 0.9649
Overfitting: 0.0858
Best model saved at epoch 5 with validation loss: 0.1108
[Epoch 6, Batch 100] loss: 0.10915364567190408
[Epoch 6, Batch 200] loss: 0.12291803527623416
[Epoch 6, Batch 300] loss: 0.11078878100961446
**STATS for Epoch 6** : 
Average training loss: 0.0232
Average validation loss: 0.0933
Validation Accuracy: 0.9730
Overfitting: 0.0701
Best model saved at epoch 6 with validation loss: 0.0933
[Epoch 7, Batch 100] loss: 0.09938630070537328
[Epoch 7, Batch 200] loss: 0.09904814068228006
[Epoch 7, Batch 300] loss: 0.10151875253766775
**STATS for Epoch 7** : 
Average training loss: 0.0195
Average validation loss: 0.0879
Validation Accuracy: 0.9722
Overfitting: 0.0684
Best model saved at epoch 7 with validation loss: 0.0879
[Epoch 8, Batch 100] loss: 0.09181795282289386
[Epoch 8, Batch 200] loss: 0.08524650886654854
[Epoch 8, Batch 300] loss: 0.0931399067863822
**STATS for Epoch 8** : 
Average training loss: 0.0176
Average validation loss: 0.0834
Validation Accuracy: 0.9728
Overfitting: 0.0658
Best model saved at epoch 8 with validation loss: 0.0834
[Epoch 9, Batch 100] loss: 0.08023907493799926
[Epoch 9, Batch 200] loss: 0.08369681511074305
[Epoch 9, Batch 300] loss: 0.07738536337390542
**STATS for Epoch 9** : 
Average training loss: 0.0160
Average validation loss: 0.0805
Validation Accuracy: 0.9738
Overfitting: 0.0645
[I 2024-12-10 07:43:46,173] Trial 15 pruned. 

Selected Hyperparameters for Trial 17:
  l1: 256, l2: 64, lr: 0.0021343086136530096, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2207973444461824
[Epoch 1, Batch 200] loss: 1.084000643491745
[Epoch 1, Batch 300] loss: 0.49508015558123586
[Epoch 1, Batch 400] loss: 0.3678375066816807
[Epoch 1, Batch 500] loss: 0.3090826666355133
[Epoch 1, Batch 600] loss: 0.25716075841337444
[Epoch 1, Batch 700] loss: 0.2234283385425806
**STATS for Epoch 1** : 
Average training loss: 0.0141
Average validation loss: 0.1785
Validation Accuracy: 0.9447
Overfitting: 0.1643
Best model saved at epoch 1 with validation loss: 0.1785
[Epoch 2, Batch 100] loss: 0.18444599144160748
[Epoch 2, Batch 200] loss: 0.1618713105097413
[Epoch 2, Batch 300] loss: 0.1475548653304577
[Epoch 2, Batch 400] loss: 0.1298867560736835
[Epoch 2, Batch 500] loss: 0.14554684776812793
[Epoch 2, Batch 600] loss: 0.14585710790008308
[Epoch 2, Batch 700] loss: 0.11134295171126724
**STATS for Epoch 2** : 
Average training loss: 0.0073
Average validation loss: 0.1067
Validation Accuracy: 0.9669
Overfitting: 0.0994
Best model saved at epoch 2 with validation loss: 0.1067
[Epoch 3, Batch 100] loss: 0.11002155527472496
[Epoch 3, Batch 200] loss: 0.09318892044015228
[Epoch 3, Batch 300] loss: 0.0976258722692728
[Epoch 3, Batch 400] loss: 0.09661387800239027
[Epoch 3, Batch 500] loss: 0.09108677978627383
[Epoch 3, Batch 600] loss: 0.0965522975474596
[Epoch 3, Batch 700] loss: 0.09167099778540433
**STATS for Epoch 3** : 
Average training loss: 0.0058
Average validation loss: 0.0844
Validation Accuracy: 0.9746
Overfitting: 0.0786
Best model saved at epoch 3 with validation loss: 0.0844
[Epoch 4, Batch 100] loss: 0.07635196763090789
[Epoch 4, Batch 200] loss: 0.07383118627592922
[Epoch 4, Batch 300] loss: 0.06284961023367941
[Epoch 4, Batch 400] loss: 0.0722695627482608
[Epoch 4, Batch 500] loss: 0.07341579963453114
[Epoch 4, Batch 600] loss: 0.0690441205026582
[Epoch 4, Batch 700] loss: 0.07380827028304339
**STATS for Epoch 4** : 
Average training loss: 0.0045
Average validation loss: 0.0681
Validation Accuracy: 0.9783
Overfitting: 0.0635
Best model saved at epoch 4 with validation loss: 0.0681
[Epoch 5, Batch 100] loss: 0.0635006961878389
[Epoch 5, Batch 200] loss: 0.07011966473422944
[Epoch 5, Batch 300] loss: 0.06319887896068394
[Epoch 5, Batch 400] loss: 0.05247617639135569
[Epoch 5, Batch 500] loss: 0.058707286580465735
[Epoch 5, Batch 600] loss: 0.06076843376271426
[Epoch 5, Batch 700] loss: 0.06122515413444489
**STATS for Epoch 5** : 
Average training loss: 0.0031
Average validation loss: 0.0605
Validation Accuracy: 0.9818
Overfitting: 0.0575
Best model saved at epoch 5 with validation loss: 0.0605
[Epoch 6, Batch 100] loss: 0.05204017330193892
[Epoch 6, Batch 200] loss: 0.054090272672474383
[Epoch 6, Batch 300] loss: 0.042092905822210015
[Epoch 6, Batch 400] loss: 0.04533794237766415
[Epoch 6, Batch 500] loss: 0.056327277305535974
[Epoch 6, Batch 600] loss: 0.049881150596775115
[Epoch 6, Batch 700] loss: 0.05395284107653424
**STATS for Epoch 6** : 
Average training loss: 0.0035
Average validation loss: 0.0532
Validation Accuracy: 0.9842
Overfitting: 0.0498
Best model saved at epoch 6 with validation loss: 0.0532
[Epoch 7, Batch 100] loss: 0.041188712118891996
[Epoch 7, Batch 200] loss: 0.03785717190010473
[Epoch 7, Batch 300] loss: 0.04898860691580922
[Epoch 7, Batch 400] loss: 0.04133016100851819
[Epoch 7, Batch 500] loss: 0.04647143881884404
[Epoch 7, Batch 600] loss: 0.0455097941798158
[Epoch 7, Batch 700] loss: 0.05182710603345186
**STATS for Epoch 7** : 
Average training loss: 0.0022
Average validation loss: 0.0567
Validation Accuracy: 0.9820
Overfitting: 0.0546
[Epoch 8, Batch 100] loss: 0.03786089622532018
[Epoch 8, Batch 200] loss: 0.037727690134197474
[Epoch 8, Batch 300] loss: 0.039843557357089596
[Epoch 8, Batch 400] loss: 0.0357680009258911
[Epoch 8, Batch 500] loss: 0.03580772142973729
[Epoch 8, Batch 600] loss: 0.04511008864501491
[Epoch 8, Batch 700] loss: 0.03263265221845359
**STATS for Epoch 8** : 
Average training loss: 0.0037
Average validation loss: 0.0521
Validation Accuracy: 0.9839
Overfitting: 0.0484
Best model saved at epoch 8 with validation loss: 0.0521
[Epoch 9, Batch 100] loss: 0.0366648237220943
[Epoch 9, Batch 200] loss: 0.03044949520844966
[Epoch 9, Batch 300] loss: 0.032030870360322296
[Epoch 9, Batch 400] loss: 0.03142562196822837
[Epoch 9, Batch 500] loss: 0.03378891858854331
[Epoch 9, Batch 600] loss: 0.029955044536618517
[Epoch 9, Batch 700] loss: 0.0424848639999982
**STATS for Epoch 9** : 
Average training loss: 0.0026
Average validation loss: 0.0478
Validation Accuracy: 0.9849
Overfitting: 0.0452
Best model saved at epoch 9 with validation loss: 0.0478
[Epoch 10, Batch 100] loss: 0.027621628495398908
[Epoch 10, Batch 200] loss: 0.03097181523218751
[Epoch 10, Batch 300] loss: 0.03341477359936107
[Epoch 10, Batch 400] loss: 0.03436113050323911
[Epoch 10, Batch 500] loss: 0.02456624119542539
[Epoch 10, Batch 600] loss: 0.029370363920461388
[Epoch 10, Batch 700] loss: 0.034200772190233694
**STATS for Epoch 10** : 
Average training loss: 0.0022
Average validation loss: 0.0507
Validation Accuracy: 0.9847
Overfitting: 0.0485
[Epoch 11, Batch 100] loss: 0.024500364917621482
[Epoch 11, Batch 200] loss: 0.02877292567049153
[Epoch 11, Batch 300] loss: 0.02943821255408693
[Epoch 11, Batch 400] loss: 0.02637313517043367
[Epoch 11, Batch 500] loss: 0.025782676823437215
[Epoch 11, Batch 600] loss: 0.02981364091683645
[Epoch 11, Batch 700] loss: 0.029392362721264362
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0428
Validation Accuracy: 0.9872
Overfitting: 0.0410
Best model saved at epoch 11 with validation loss: 0.0428
[Epoch 12, Batch 100] loss: 0.022027054395293816
[Epoch 12, Batch 200] loss: 0.02605585186975077
[Epoch 12, Batch 300] loss: 0.02515852673735935
[Epoch 12, Batch 400] loss: 0.021799612174509094
[Epoch 12, Batch 500] loss: 0.02053382190060802
[Epoch 12, Batch 600] loss: 0.025413504989992362
[Epoch 12, Batch 700] loss: 0.028629154176451267
**STATS for Epoch 12** : 
Average training loss: 0.0017
Average validation loss: 0.0451
Validation Accuracy: 0.9861
Overfitting: 0.0434
[Epoch 13, Batch 100] loss: 0.020542137782322244
[Epoch 13, Batch 200] loss: 0.023123801461188122
[Epoch 13, Batch 300] loss: 0.017812171762343496
[Epoch 13, Batch 400] loss: 0.023803700451389888
[Epoch 13, Batch 500] loss: 0.01627096424344927
[Epoch 13, Batch 600] loss: 0.024935544601466974
[Epoch 13, Batch 700] loss: 0.021353122294531204
**STATS for Epoch 13** : 
Average training loss: 0.0013
Average validation loss: 0.0445
Validation Accuracy: 0.9862
Overfitting: 0.0432
[Epoch 14, Batch 100] loss: 0.015836468684137798
[Epoch 14, Batch 200] loss: 0.018345254338346422
[Epoch 14, Batch 300] loss: 0.014553684881539084
[Epoch 14, Batch 400] loss: 0.02129997813332011
[Epoch 14, Batch 500] loss: 0.020055041928135325
[Epoch 14, Batch 600] loss: 0.01893170437135268
[Epoch 14, Batch 700] loss: 0.02284786763426382
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0445
Validation Accuracy: 0.9871
Overfitting: 0.0433
[Epoch 15, Batch 100] loss: 0.01863493969081901
[Epoch 15, Batch 200] loss: 0.0180572793551255
[Epoch 15, Batch 300] loss: 0.01931468294962542
[Epoch 15, Batch 400] loss: 0.014298580700851745
[Epoch 15, Batch 500] loss: 0.018537249584769596
[Epoch 15, Batch 600] loss: 0.020308616634574717
[Epoch 15, Batch 700] loss: 0.01818190599180525
**STATS for Epoch 15** : 
Average training loss: 0.0014
Average validation loss: 0.0456
Validation Accuracy: 0.9857
Overfitting: 0.0442
[Epoch 16, Batch 100] loss: 0.011895613127562684
[Epoch 16, Batch 200] loss: 0.01675944118091138
[Epoch 16, Batch 300] loss: 0.01132448919932358
[Epoch 16, Batch 400] loss: 0.01440950708987657
[Epoch 16, Batch 500] loss: 0.017676621559658087
[Epoch 16, Batch 600] loss: 0.015495199092547408
[Epoch 16, Batch 700] loss: 0.022328603226633277
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0443
Validation Accuracy: 0.9867
Overfitting: 0.0433
[Epoch 17, Batch 100] loss: 0.014471114864572882
[Epoch 17, Batch 200] loss: 0.009539964536670595
[Epoch 17, Batch 300] loss: 0.014733308152353857
[Epoch 17, Batch 400] loss: 0.014814998787769582
[Epoch 17, Batch 500] loss: 0.013260999847843777
[Epoch 17, Batch 600] loss: 0.0179040931398049
[Epoch 17, Batch 700] loss: 0.014056365602300502
**STATS for Epoch 17** : 
Average training loss: 0.0013
Average validation loss: 0.0463
Validation Accuracy: 0.9864
Overfitting: 0.0450
[Epoch 18, Batch 100] loss: 0.01294428107983549
[Epoch 18, Batch 200] loss: 0.011227941481920425
[Epoch 18, Batch 300] loss: 0.0147460768345627
[Epoch 18, Batch 400] loss: 0.012165094021474943
[Epoch 18, Batch 500] loss: 0.0101220302573347
[Epoch 18, Batch 600] loss: 0.011343433982838179
[Epoch 18, Batch 700] loss: 0.011290544354560552
**STATS for Epoch 18** : 
Average training loss: 0.0013
Average validation loss: 0.0512
Validation Accuracy: 0.9857
Overfitting: 0.0500
[Epoch 19, Batch 100] loss: 0.011858173872169572
[Epoch 19, Batch 200] loss: 0.013123218016989995
[Epoch 19, Batch 300] loss: 0.008213981430308194
[Epoch 19, Batch 400] loss: 0.009901270595873939
[Epoch 19, Batch 500] loss: 0.010942605090349389
[Epoch 19, Batch 600] loss: 0.013399483422981575
[Epoch 19, Batch 700] loss: 0.012151793567900313
**STATS for Epoch 19** : 
Average training loss: 0.0008
Average validation loss: 0.0463
Validation Accuracy: 0.9870
Overfitting: 0.0455
[Epoch 20, Batch 100] loss: 0.008892923579624038
[Epoch 20, Batch 200] loss: 0.008839639378711581
[Epoch 20, Batch 300] loss: 0.008248520430424833
[Epoch 20, Batch 400] loss: 0.013467039402748925
[Epoch 20, Batch 500] loss: 0.01135976734876749
[Epoch 20, Batch 600] loss: 0.008539971945865546
[Epoch 20, Batch 700] loss: 0.011471234650962288
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0448
Validation Accuracy: 0.9885
Overfitting: 0.0439
[Epoch 21, Batch 100] loss: 0.010952557989949128
[Epoch 21, Batch 200] loss: 0.012412337220157497
[Epoch 21, Batch 300] loss: 0.0101704358097777
[Epoch 21, Batch 400] loss: 0.009272795186843723
[Epoch 21, Batch 500] loss: 0.010235690144763793
[Epoch 21, Batch 600] loss: 0.008054244865488726
[Epoch 21, Batch 700] loss: 0.009190832904496347
**STATS for Epoch 21** : 
Average training loss: 0.0007
Average validation loss: 0.0448
Validation Accuracy: 0.9875
Overfitting: 0.0441
[Epoch 22, Batch 100] loss: 0.005328546042474045
[Epoch 22, Batch 200] loss: 0.005095108363457257
[Epoch 22, Batch 300] loss: 0.0042650529981619915
[Epoch 22, Batch 400] loss: 0.009407387209430454
[Epoch 22, Batch 500] loss: 0.006152728218585253
[Epoch 22, Batch 600] loss: 0.010771834393381141
[Epoch 22, Batch 700] loss: 0.007643041735427687
**STATS for Epoch 22** : 
Average training loss: 0.0011
Average validation loss: 0.0463
Validation Accuracy: 0.9878
Overfitting: 0.0452
[Epoch 23, Batch 100] loss: 0.006610470479936339
[Epoch 23, Batch 200] loss: 0.007134617779374821
[Epoch 23, Batch 300] loss: 0.004098731406484149
[Epoch 23, Batch 400] loss: 0.009178418468836753
[Epoch 23, Batch 500] loss: 0.012902893729733477
[Epoch 23, Batch 600] loss: 0.005579888635038515
[Epoch 23, Batch 700] loss: 0.006872376973551582
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0530
Validation Accuracy: 0.9852
Overfitting: 0.0524
[Epoch 24, Batch 100] loss: 0.010062838818121235
[Epoch 24, Batch 200] loss: 0.011487989064262365
[Epoch 24, Batch 300] loss: 0.005435134717990877
[Epoch 24, Batch 400] loss: 0.0059250576282101975
[Epoch 24, Batch 500] loss: 0.00804411755721958
[Epoch 24, Batch 600] loss: 0.006316592784132808
[Epoch 24, Batch 700] loss: 0.006714646385189553
**STATS for Epoch 24** : 
Average training loss: 0.0007
Average validation loss: 0.0430
Validation Accuracy: 0.9892
Overfitting: 0.0423
Fold 1 validation loss: 0.0430
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2791697907447817
[Epoch 1, Batch 200] loss: 1.659212446808815
[Epoch 1, Batch 300] loss: 0.5754384782910347
[Epoch 1, Batch 400] loss: 0.4047504112124443
[Epoch 1, Batch 500] loss: 0.31892115116119385
[Epoch 1, Batch 600] loss: 0.2678850257396698
[Epoch 1, Batch 700] loss: 0.20535387560725213
**STATS for Epoch 1** : 
Average training loss: 0.0122
Average validation loss: 0.1967
Validation Accuracy: 0.9419
Overfitting: 0.1845
Best model saved at epoch 1 with validation loss: 0.1967
[Epoch 2, Batch 100] loss: 0.16182061344385146
[Epoch 2, Batch 200] loss: 0.16899369321763516
[Epoch 2, Batch 300] loss: 0.15373477220535278
[Epoch 2, Batch 400] loss: 0.12552473140880466
[Epoch 2, Batch 500] loss: 0.12068748531863094
[Epoch 2, Batch 600] loss: 0.11727409388870001
[Epoch 2, Batch 700] loss: 0.1144686986785382
**STATS for Epoch 2** : 
Average training loss: 0.0074
Average validation loss: 0.1140
Validation Accuracy: 0.9653
Overfitting: 0.1066
Best model saved at epoch 2 with validation loss: 0.1140
[Epoch 3, Batch 100] loss: 0.10449322840198874
[Epoch 3, Batch 200] loss: 0.08553061753511429
[Epoch 3, Batch 300] loss: 0.09292086133733392
[Epoch 3, Batch 400] loss: 0.09458445872180164
[Epoch 3, Batch 500] loss: 0.07369075091555714
[Epoch 3, Batch 600] loss: 0.0939842182211578
[Epoch 3, Batch 700] loss: 0.08463030397891998
**STATS for Epoch 3** : 
Average training loss: 0.0046
Average validation loss: 0.0871
Validation Accuracy: 0.9736
Overfitting: 0.0825
Best model saved at epoch 3 with validation loss: 0.0871
[Epoch 4, Batch 100] loss: 0.07280872780829668
[Epoch 4, Batch 200] loss: 0.06145472915843129
[Epoch 4, Batch 300] loss: 0.0670578551478684
[Epoch 4, Batch 400] loss: 0.07492921384982765
[Epoch 4, Batch 500] loss: 0.0686177735356614
[Epoch 4, Batch 600] loss: 0.07065736032091081
[Epoch 4, Batch 700] loss: 0.060285872374661265
**STATS for Epoch 4** : 
Average training loss: 0.0040
Average validation loss: 0.0784
Validation Accuracy: 0.9762
Overfitting: 0.0744
Best model saved at epoch 4 with validation loss: 0.0784
[Epoch 5, Batch 100] loss: 0.057727417736314235
[Epoch 5, Batch 200] loss: 0.05559193582739681
[Epoch 5, Batch 300] loss: 0.064147658678703
[Epoch 5, Batch 400] loss: 0.04942661148495972
[Epoch 5, Batch 500] loss: 0.05637166085653007
[Epoch 5, Batch 600] loss: 0.057831063456833365
[Epoch 5, Batch 700] loss: 0.0554664340429008
**STATS for Epoch 5** : 
Average training loss: 0.0039
Average validation loss: 0.0757
Validation Accuracy: 0.9777
Overfitting: 0.0719
Best model saved at epoch 5 with validation loss: 0.0757
[Epoch 6, Batch 100] loss: 0.05320365556050092
[Epoch 6, Batch 200] loss: 0.05921589298173785
[Epoch 6, Batch 300] loss: 0.03833196989726275
[Epoch 6, Batch 400] loss: 0.04697748515289277
[Epoch 6, Batch 500] loss: 0.05511080572847277
[Epoch 6, Batch 600] loss: 0.04360988921951502
[Epoch 6, Batch 700] loss: 0.0462466347287409
**STATS for Epoch 6** : 
Average training loss: 0.0032
Average validation loss: 0.0726
Validation Accuracy: 0.9778
Overfitting: 0.0694
Best model saved at epoch 6 with validation loss: 0.0726
[Epoch 7, Batch 100] loss: 0.05028001681668684
[Epoch 7, Batch 200] loss: 0.03910976198967546
[Epoch 7, Batch 300] loss: 0.04518458140315488
[Epoch 7, Batch 400] loss: 0.03350671455729753
[Epoch 7, Batch 500] loss: 0.04982604549499228
[Epoch 7, Batch 600] loss: 0.04206683796364814
[Epoch 7, Batch 700] loss: 0.037368645266396924
**STATS for Epoch 7** : 
Average training loss: 0.0028
Average validation loss: 0.0597
Validation Accuracy: 0.9814
Overfitting: 0.0568
Best model saved at epoch 7 with validation loss: 0.0597
[Epoch 8, Batch 100] loss: 0.035196317883674055
[Epoch 8, Batch 200] loss: 0.03934067837428302
[Epoch 8, Batch 300] loss: 0.04084721642546356
[Epoch 8, Batch 400] loss: 0.03395504392683506
[Epoch 8, Batch 500] loss: 0.04233163874363527
[Epoch 8, Batch 600] loss: 0.037097346037626266
[Epoch 8, Batch 700] loss: 0.03278880177531392
**STATS for Epoch 8** : 
Average training loss: 0.0028
Average validation loss: 0.0586
Validation Accuracy: 0.9827
Overfitting: 0.0558
Best model saved at epoch 8 with validation loss: 0.0586
[Epoch 9, Batch 100] loss: 0.029109374798135832
[Epoch 9, Batch 200] loss: 0.034863273221999405
[Epoch 9, Batch 300] loss: 0.03552928252378479
[Epoch 9, Batch 400] loss: 0.035734221717575565
[Epoch 9, Batch 500] loss: 0.029771201765397562
[Epoch 9, Batch 600] loss: 0.035530787434545345
[Epoch 9, Batch 700] loss: 0.036280766595155
**STATS for Epoch 9** : 
Average training loss: 0.0018
Average validation loss: 0.0558
Validation Accuracy: 0.9842
Overfitting: 0.0540
Best model saved at epoch 9 with validation loss: 0.0558
[Epoch 10, Batch 100] loss: 0.026234526730841024
[Epoch 10, Batch 200] loss: 0.027996522420435214
[Epoch 10, Batch 300] loss: 0.030662671909085476
[Epoch 10, Batch 400] loss: 0.03571159629500471
[Epoch 10, Batch 500] loss: 0.028615208924748003
[Epoch 10, Batch 600] loss: 0.02758474896196276
[Epoch 10, Batch 700] loss: 0.030069130234187467
**STATS for Epoch 10** : 
Average training loss: 0.0021
Average validation loss: 0.0580
Validation Accuracy: 0.9829
Overfitting: 0.0559
[Epoch 11, Batch 100] loss: 0.03108527523931116
[Epoch 11, Batch 200] loss: 0.027429809444001876
[Epoch 11, Batch 300] loss: 0.02235595166566782
[Epoch 11, Batch 400] loss: 0.02405514151614625
[Epoch 11, Batch 500] loss: 0.026177500910998786
[Epoch 11, Batch 600] loss: 0.033606006653863006
[Epoch 11, Batch 700] loss: 0.0242445933597628
**STATS for Epoch 11** : 
Average training loss: 0.0021
Average validation loss: 0.0551
Validation Accuracy: 0.9829
Overfitting: 0.0530
Best model saved at epoch 11 with validation loss: 0.0551
[Epoch 12, Batch 100] loss: 0.024924392936518415
[Epoch 12, Batch 200] loss: 0.02395654699357692
[Epoch 12, Batch 300] loss: 0.026173551240353844
[Epoch 12, Batch 400] loss: 0.02555222013965249
[Epoch 12, Batch 500] loss: 0.023747615873580798
[Epoch 12, Batch 600] loss: 0.017504097631608602
[Epoch 12, Batch 700] loss: 0.02906298064859584
**STATS for Epoch 12** : 
Average training loss: 0.0017
Average validation loss: 0.0522
Validation Accuracy: 0.9857
Overfitting: 0.0505
Best model saved at epoch 12 with validation loss: 0.0522
[Epoch 13, Batch 100] loss: 0.017243587364500854
[Epoch 13, Batch 200] loss: 0.02115956880210433
[Epoch 13, Batch 300] loss: 0.025181122269132175
[Epoch 13, Batch 400] loss: 0.019803241002373396
[Epoch 13, Batch 500] loss: 0.024423347729607484
[Epoch 13, Batch 600] loss: 0.027064088103361427
[Epoch 13, Batch 700] loss: 0.02643001619086135
**STATS for Epoch 13** : 
Average training loss: 0.0015
Average validation loss: 0.0512
Validation Accuracy: 0.9859
Overfitting: 0.0497
Best model saved at epoch 13 with validation loss: 0.0512
[Epoch 14, Batch 100] loss: 0.015972451760899276
[Epoch 14, Batch 200] loss: 0.01843717722716974
[Epoch 14, Batch 300] loss: 0.021596127749799052
[Epoch 14, Batch 400] loss: 0.018790991971618497
[Epoch 14, Batch 500] loss: 0.020073399464599788
[Epoch 14, Batch 600] loss: 0.024876311806146988
[Epoch 14, Batch 700] loss: 0.016575614640605637
**STATS for Epoch 14** : 
Average training loss: 0.0015
Average validation loss: 0.0532
Validation Accuracy: 0.9851
Overfitting: 0.0517
[Epoch 15, Batch 100] loss: 0.01537900920957327
[Epoch 15, Batch 200] loss: 0.014420894241775386
[Epoch 15, Batch 300] loss: 0.01748991921893321
[Epoch 15, Batch 400] loss: 0.01604186117241625
[Epoch 15, Batch 500] loss: 0.01622766218148172
[Epoch 15, Batch 600] loss: 0.014010018475310061
[Epoch 15, Batch 700] loss: 0.02782306760578649
**STATS for Epoch 15** : 
Average training loss: 0.0016
Average validation loss: 0.0522
Validation Accuracy: 0.9855
Overfitting: 0.0506
[Epoch 16, Batch 100] loss: 0.014597182713187067
[Epoch 16, Batch 200] loss: 0.01307076899392996
[Epoch 16, Batch 300] loss: 0.013374228091852274
[Epoch 16, Batch 400] loss: 0.017439107801765205
[Epoch 16, Batch 500] loss: 0.015433021539647597
[Epoch 16, Batch 600] loss: 0.02024356657115277
[Epoch 16, Batch 700] loss: 0.01664819530720706
**STATS for Epoch 16** : 
Average training loss: 0.0017
Average validation loss: 0.0519
Validation Accuracy: 0.9860
Overfitting: 0.0503
[Epoch 17, Batch 100] loss: 0.015713118417188525
[Epoch 17, Batch 200] loss: 0.013021994705995894
[Epoch 17, Batch 300] loss: 0.009490909626183566
[Epoch 17, Batch 400] loss: 0.014499085715069669
[Epoch 17, Batch 500] loss: 0.015866591087542473
[Epoch 17, Batch 600] loss: 0.012557473079068586
[Epoch 17, Batch 700] loss: 0.0172386671465938
**STATS for Epoch 17** : 
Average training loss: 0.0017
Average validation loss: 0.0542
Validation Accuracy: 0.9854
Overfitting: 0.0524
[Epoch 18, Batch 100] loss: 0.01106905356507923
[Epoch 18, Batch 200] loss: 0.015973289434914478
[Epoch 18, Batch 300] loss: 0.01341700257078628
[Epoch 18, Batch 400] loss: 0.009996508956828621
[Epoch 18, Batch 500] loss: 0.011153688834456261
[Epoch 18, Batch 600] loss: 0.013646500619652216
[Epoch 18, Batch 700] loss: 0.01622887244724552
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0496
Validation Accuracy: 0.9858
Overfitting: 0.0488
Best model saved at epoch 18 with validation loss: 0.0496
[Epoch 19, Batch 100] loss: 0.009923183590872213
[Epoch 19, Batch 200] loss: 0.008342740299995058
[Epoch 19, Batch 300] loss: 0.009698207930778153
[Epoch 19, Batch 400] loss: 0.01257095760651282
[Epoch 19, Batch 500] loss: 0.014697025142304483
[Epoch 19, Batch 600] loss: 0.01586096828308655
[Epoch 19, Batch 700] loss: 0.01431691757417866
**STATS for Epoch 19** : 
Average training loss: 0.0011
Average validation loss: 0.0529
Validation Accuracy: 0.9863
Overfitting: 0.0518
[Epoch 20, Batch 100] loss: 0.01236246252170531
[Epoch 20, Batch 200] loss: 0.008728544713303563
[Epoch 20, Batch 300] loss: 0.012089022563231992
[Epoch 20, Batch 400] loss: 0.011875278875377262
[Epoch 20, Batch 500] loss: 0.01243743993807584
[Epoch 20, Batch 600] loss: 0.010312928957428085
[Epoch 20, Batch 700] loss: 0.011850774597405689
**STATS for Epoch 20** : 
Average training loss: 0.0009
Average validation loss: 0.0528
Validation Accuracy: 0.9867
Overfitting: 0.0519
[Epoch 21, Batch 100] loss: 0.007614524754317244
[Epoch 21, Batch 200] loss: 0.011064129833612242
[Epoch 21, Batch 300] loss: 0.010503495863376884
[Epoch 21, Batch 400] loss: 0.01519389488035813
[Epoch 21, Batch 500] loss: 0.007356902246901882
[Epoch 21, Batch 600] loss: 0.009286322972038762
[Epoch 21, Batch 700] loss: 0.01038513812731253
**STATS for Epoch 21** : 
Average training loss: 0.0007
Average validation loss: 0.0517
Validation Accuracy: 0.9871
Overfitting: 0.0509
[Epoch 22, Batch 100] loss: 0.008754972251626896
[Epoch 22, Batch 200] loss: 0.0063542599637730745
[Epoch 22, Batch 300] loss: 0.006736916532754549
[Epoch 22, Batch 400] loss: 0.011550230816574185
[Epoch 22, Batch 500] loss: 0.009887921374465805
[Epoch 22, Batch 600] loss: 0.006704726879106602
[Epoch 22, Batch 700] loss: 0.007494840221916092
**STATS for Epoch 22** : 
Average training loss: 0.0007
Average validation loss: 0.0549
Validation Accuracy: 0.9877
Overfitting: 0.0542
[Epoch 23, Batch 100] loss: 0.004323136854800395
[Epoch 23, Batch 200] loss: 0.006749651211575838
[Epoch 23, Batch 300] loss: 0.005190997815625451
[Epoch 23, Batch 400] loss: 0.008140363254788098
[Epoch 23, Batch 500] loss: 0.00832272818639467
[Epoch 23, Batch 600] loss: 0.008353662271983921
[Epoch 23, Batch 700] loss: 0.007215560363110853
**STATS for Epoch 23** : 
Average training loss: 0.0010
Average validation loss: 0.0533
Validation Accuracy: 0.9876
Overfitting: 0.0522
[Epoch 24, Batch 100] loss: 0.00482775834898348
[Epoch 24, Batch 200] loss: 0.008890539584135694
[Epoch 24, Batch 300] loss: 0.005653408018406481
[Epoch 24, Batch 400] loss: 0.00833076879978762
[Epoch 24, Batch 500] loss: 0.005753513550953358
[Epoch 24, Batch 600] loss: 0.010188726072083227
[Epoch 24, Batch 700] loss: 0.0097152725086562
**STATS for Epoch 24** : 
Average training loss: 0.0007
Average validation loss: 0.0572
Validation Accuracy: 0.9859
Overfitting: 0.0565
Fold 2 validation loss: 0.0572
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.285620219707489
[Epoch 1, Batch 200] loss: 1.9175790393352508
[Epoch 1, Batch 300] loss: 0.7361754766106605
[Epoch 1, Batch 400] loss: 0.4361415663361549
[Epoch 1, Batch 500] loss: 0.3371267604827881
[Epoch 1, Batch 600] loss: 0.27632372833788393
[Epoch 1, Batch 700] loss: 0.24781512908637524
**STATS for Epoch 1** : 
Average training loss: 0.0137
Average validation loss: 0.2048
Validation Accuracy: 0.9357
Overfitting: 0.1911
Best model saved at epoch 1 with validation loss: 0.2048
[Epoch 2, Batch 100] loss: 0.18458385284990073
[Epoch 2, Batch 200] loss: 0.17424327589571476
[Epoch 2, Batch 300] loss: 0.17256811164319516
[Epoch 2, Batch 400] loss: 0.13674171971157192
[Epoch 2, Batch 500] loss: 0.1351490484084934
[Epoch 2, Batch 600] loss: 0.12361252581700682
[Epoch 2, Batch 700] loss: 0.12212122289463878
**STATS for Epoch 2** : 
Average training loss: 0.0062
Average validation loss: 0.1126
Validation Accuracy: 0.9643
Overfitting: 0.1064
Best model saved at epoch 2 with validation loss: 0.1126
[Epoch 3, Batch 100] loss: 0.10333716554567218
[Epoch 3, Batch 200] loss: 0.0980925671942532
[Epoch 3, Batch 300] loss: 0.09778879308141768
[Epoch 3, Batch 400] loss: 0.08985214163549245
[Epoch 3, Batch 500] loss: 0.08055936007760466
[Epoch 3, Batch 600] loss: 0.09939024780876934
[Epoch 3, Batch 700] loss: 0.08360489897429943
**STATS for Epoch 3** : 
Average training loss: 0.0057
Average validation loss: 0.0940
Validation Accuracy: 0.9717
Overfitting: 0.0883
Best model saved at epoch 3 with validation loss: 0.0940
[Epoch 4, Batch 100] loss: 0.07496507140807808
[Epoch 4, Batch 200] loss: 0.06909901848062873
[Epoch 4, Batch 300] loss: 0.0697003553621471
[Epoch 4, Batch 400] loss: 0.07468113153241575
[Epoch 4, Batch 500] loss: 0.06685093769803643
[Epoch 4, Batch 600] loss: 0.07092499583028257
[Epoch 4, Batch 700] loss: 0.06247132077347487
**STATS for Epoch 4** : 
Average training loss: 0.0047
Average validation loss: 0.0682
Validation Accuracy: 0.9792
Overfitting: 0.0635
Best model saved at epoch 4 with validation loss: 0.0682
[Epoch 5, Batch 100] loss: 0.06205522821052
[Epoch 5, Batch 200] loss: 0.05667406097985804
[Epoch 5, Batch 300] loss: 0.05340685355477035
[Epoch 5, Batch 400] loss: 0.05633858469547704
[Epoch 5, Batch 500] loss: 0.06222991686314344
[Epoch 5, Batch 600] loss: 0.05709701052401215
[Epoch 5, Batch 700] loss: 0.06664285614620895
**STATS for Epoch 5** : 
Average training loss: 0.0038
Average validation loss: 0.0666
Validation Accuracy: 0.9792
Overfitting: 0.0628
Best model saved at epoch 5 with validation loss: 0.0666
[Epoch 6, Batch 100] loss: 0.04795784895308316
[Epoch 6, Batch 200] loss: 0.04730046315817162
[Epoch 6, Batch 300] loss: 0.04995962344110012
[Epoch 6, Batch 400] loss: 0.049252649906557054
[Epoch 6, Batch 500] loss: 0.04559322405140847
[Epoch 6, Batch 600] loss: 0.04973549362272024
[Epoch 6, Batch 700] loss: 0.04712817827938125
**STATS for Epoch 6** : 
Average training loss: 0.0034
Average validation loss: 0.0576
Validation Accuracy: 0.9819
Overfitting: 0.0542
Best model saved at epoch 6 with validation loss: 0.0576
[Epoch 7, Batch 100] loss: 0.04094803204527125
[Epoch 7, Batch 200] loss: 0.049378594239242374
[Epoch 7, Batch 300] loss: 0.035453735740156846
[Epoch 7, Batch 400] loss: 0.04672032757662237
[Epoch 7, Batch 500] loss: 0.038237016663188114
[Epoch 7, Batch 600] loss: 0.049339569362346083
[Epoch 7, Batch 700] loss: 0.040100196143612266
**STATS for Epoch 7** : 
Average training loss: 0.0035
Average validation loss: 0.0637
Validation Accuracy: 0.9806
Overfitting: 0.0602
[Epoch 8, Batch 100] loss: 0.04339616337325424
[Epoch 8, Batch 200] loss: 0.04155542531516403
[Epoch 8, Batch 300] loss: 0.03169531833613291
[Epoch 8, Batch 400] loss: 0.037906466035638006
[Epoch 8, Batch 500] loss: 0.03239042892004363
[Epoch 8, Batch 600] loss: 0.040390394083224236
[Epoch 8, Batch 700] loss: 0.03659600103041157
**STATS for Epoch 8** : 
Average training loss: 0.0022
Average validation loss: 0.0477
Validation Accuracy: 0.9858
Overfitting: 0.0455
Best model saved at epoch 8 with validation loss: 0.0477
[Epoch 9, Batch 100] loss: 0.028062654600362294
[Epoch 9, Batch 200] loss: 0.02972678262507543
[Epoch 9, Batch 300] loss: 0.029756350435782224
[Epoch 9, Batch 400] loss: 0.038840816220035775
[Epoch 9, Batch 500] loss: 0.029517005851957948
[Epoch 9, Batch 600] loss: 0.03890862675034441
[Epoch 9, Batch 700] loss: 0.036781201994745064
**STATS for Epoch 9** : 
Average training loss: 0.0021
Average validation loss: 0.0528
Validation Accuracy: 0.9832
Overfitting: 0.0507
[Epoch 10, Batch 100] loss: 0.03565079516149126
[Epoch 10, Batch 200] loss: 0.02627797838882543
[Epoch 10, Batch 300] loss: 0.02615745563816745
[Epoch 10, Batch 400] loss: 0.026668214199598878
[Epoch 10, Batch 500] loss: 0.02875014702556655
[Epoch 10, Batch 600] loss: 0.03086093634716235
[Epoch 10, Batch 700] loss: 0.0288904653233476
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0482
Validation Accuracy: 0.9856
Overfitting: 0.0465
[Epoch 11, Batch 100] loss: 0.02241686065681279
[Epoch 11, Batch 200] loss: 0.02830689518712461
[Epoch 11, Batch 300] loss: 0.022162395821651443
[Epoch 11, Batch 400] loss: 0.02402853114064783
[Epoch 11, Batch 500] loss: 0.02748801850597374
[Epoch 11, Batch 600] loss: 0.02490811226365622
[Epoch 11, Batch 700] loss: 0.028048565750941633
**STATS for Epoch 11** : 
Average training loss: 0.0021
Average validation loss: 0.0503
Validation Accuracy: 0.9838
Overfitting: 0.0482
[Epoch 12, Batch 100] loss: 0.02225475972983986
[Epoch 12, Batch 200] loss: 0.024188087622169407
[Epoch 12, Batch 300] loss: 0.023592685511684978
[Epoch 12, Batch 400] loss: 0.02687212430173531
[Epoch 12, Batch 500] loss: 0.023437285645632074
[Epoch 12, Batch 600] loss: 0.021093746410333552
[Epoch 12, Batch 700] loss: 0.02268858430426917
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0467
Validation Accuracy: 0.9865
Overfitting: 0.0454
Best model saved at epoch 12 with validation loss: 0.0467
[Epoch 13, Batch 100] loss: 0.02103921094094403
[Epoch 13, Batch 200] loss: 0.016843663035542702
[Epoch 13, Batch 300] loss: 0.022781371876917547
[Epoch 13, Batch 400] loss: 0.017528014205308865
[Epoch 13, Batch 500] loss: 0.01956084148318041
[Epoch 13, Batch 600] loss: 0.0231213001353899
[Epoch 13, Batch 700] loss: 0.023605928036849945
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0435
Validation Accuracy: 0.9873
Overfitting: 0.0426
Best model saved at epoch 13 with validation loss: 0.0435
[Epoch 14, Batch 100] loss: 0.016282621268474032
[Epoch 14, Batch 200] loss: 0.015472810082428623
[Epoch 14, Batch 300] loss: 0.02141495817399118
[Epoch 14, Batch 400] loss: 0.02267485510848928
[Epoch 14, Batch 500] loss: 0.020439554755430436
[Epoch 14, Batch 600] loss: 0.020613774153607666
[Epoch 14, Batch 700] loss: 0.017742480439483187
**STATS for Epoch 14** : 
Average training loss: 0.0016
Average validation loss: 0.0617
Validation Accuracy: 0.9815
Overfitting: 0.0600
[Epoch 15, Batch 100] loss: 0.019971616632537915
[Epoch 15, Batch 200] loss: 0.011983295771933626
[Epoch 15, Batch 300] loss: 0.017800356083898804
[Epoch 15, Batch 400] loss: 0.016169702268089167
[Epoch 15, Batch 500] loss: 0.017818541136512066
[Epoch 15, Batch 600] loss: 0.018911123890429735
[Epoch 15, Batch 700] loss: 0.016221591852081475
**STATS for Epoch 15** : 
Average training loss: 0.0011
Average validation loss: 0.0427
Validation Accuracy: 0.9883
Overfitting: 0.0416
Best model saved at epoch 15 with validation loss: 0.0427
[Epoch 16, Batch 100] loss: 0.010097844256379176
[Epoch 16, Batch 200] loss: 0.016634165054711048
[Epoch 16, Batch 300] loss: 0.012991954953758978
[Epoch 16, Batch 400] loss: 0.015134755712933838
[Epoch 16, Batch 500] loss: 0.013380823438201333
[Epoch 16, Batch 600] loss: 0.017270242495651473
[Epoch 16, Batch 700] loss: 0.018471061097516214
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0447
Validation Accuracy: 0.9876
Overfitting: 0.0439
[Epoch 17, Batch 100] loss: 0.009329861742153299
[Epoch 17, Batch 200] loss: 0.01160325171527802
[Epoch 17, Batch 300] loss: 0.014836866422556341
[Epoch 17, Batch 400] loss: 0.013501804276020267
[Epoch 17, Batch 500] loss: 0.012589835947437678
[Epoch 17, Batch 600] loss: 0.01333215101294627
[Epoch 17, Batch 700] loss: 0.012275673775293398
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0488
Validation Accuracy: 0.9868
Overfitting: 0.0479
[Epoch 18, Batch 100] loss: 0.010450136434228626
[Epoch 18, Batch 200] loss: 0.01400149959808914
[Epoch 18, Batch 300] loss: 0.013407811315846629
[Epoch 18, Batch 400] loss: 0.011462532580335392
[Epoch 18, Batch 500] loss: 0.011413851879769937
[Epoch 18, Batch 600] loss: 0.015400423941318877
[Epoch 18, Batch 700] loss: 0.015682399950019316
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0453
Validation Accuracy: 0.9872
Overfitting: 0.0444
[Epoch 19, Batch 100] loss: 0.009191039313736837
[Epoch 19, Batch 200] loss: 0.012437694550171727
[Epoch 19, Batch 300] loss: 0.009442545745987446
[Epoch 19, Batch 400] loss: 0.010049288061563856
[Epoch 19, Batch 500] loss: 0.011499773411815113
[Epoch 19, Batch 600] loss: 0.011588585910576512
[Epoch 19, Batch 700] loss: 0.00895444582652999
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0466
Validation Accuracy: 0.9883
Overfitting: 0.0460
[Epoch 20, Batch 100] loss: 0.0065851887294411425
[Epoch 20, Batch 200] loss: 0.007225964678582386
[Epoch 20, Batch 300] loss: 0.009053647785476642
[Epoch 20, Batch 400] loss: 0.00990775452402886
[Epoch 20, Batch 500] loss: 0.006168251725539448
[Epoch 20, Batch 600] loss: 0.013108044286782387
[Epoch 20, Batch 700] loss: 0.01022799849670264
**STATS for Epoch 20** : 
Average training loss: 0.0008
Average validation loss: 0.0514
Validation Accuracy: 0.9867
Overfitting: 0.0506
[Epoch 21, Batch 100] loss: 0.008284062447492033
[Epoch 21, Batch 200] loss: 0.0074914259633806065
[Epoch 21, Batch 300] loss: 0.006646715484166634
[Epoch 21, Batch 400] loss: 0.00718610034455196
[Epoch 21, Batch 500] loss: 0.01000386234925827
[Epoch 21, Batch 600] loss: 0.009376195140939672
[Epoch 21, Batch 700] loss: 0.009166109560756013
**STATS for Epoch 21** : 
Average training loss: 0.0007
Average validation loss: 0.0511
Validation Accuracy: 0.9866
Overfitting: 0.0504
[Epoch 22, Batch 100] loss: 0.007083183751237811
[Epoch 22, Batch 200] loss: 0.007011855910823215
[Epoch 22, Batch 300] loss: 0.006328233273234218
[Epoch 22, Batch 400] loss: 0.007594302532161237
[Epoch 22, Batch 500] loss: 0.007897242580438614
[Epoch 22, Batch 600] loss: 0.0065258352336968525
[Epoch 22, Batch 700] loss: 0.007697948824024934
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0483
Validation Accuracy: 0.9873
Overfitting: 0.0478
[Epoch 23, Batch 100] loss: 0.006389231279317755
[Epoch 23, Batch 200] loss: 0.006751801764476113
[Epoch 23, Batch 300] loss: 0.006207181530553499
[Epoch 23, Batch 400] loss: 0.007227063175159856
[Epoch 23, Batch 500] loss: 0.004758576432723202
[Epoch 23, Batch 600] loss: 0.005003849288041238
[Epoch 23, Batch 700] loss: 0.00926173603580537
**STATS for Epoch 23** : 
Average training loss: 0.0008
Average validation loss: 0.0471
Validation Accuracy: 0.9883
Overfitting: 0.0463
[Epoch 24, Batch 100] loss: 0.007366411028051516
[Epoch 24, Batch 200] loss: 0.005084774858769379
[Epoch 24, Batch 300] loss: 0.006509804459819861
[Epoch 24, Batch 400] loss: 0.004178370428599009
[Epoch 24, Batch 500] loss: 0.008074431569912121
[Epoch 24, Batch 600] loss: 0.006140951961860992
[Epoch 24, Batch 700] loss: 0.006368977229394659
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0482
Validation Accuracy: 0.9885
Overfitting: 0.0478
Fold 3 validation loss: 0.0482
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2928587579727173
[Epoch 1, Batch 200] loss: 2.137195519208908
[Epoch 1, Batch 300] loss: 0.830523493885994
[Epoch 1, Batch 400] loss: 0.40888562574982645
[Epoch 1, Batch 500] loss: 0.3055997622013092
[Epoch 1, Batch 600] loss: 0.2769944517314434
[Epoch 1, Batch 700] loss: 0.22260311588644982
**STATS for Epoch 1** : 
Average training loss: 0.0125
Average validation loss: 0.2059
Validation Accuracy: 0.9350
Overfitting: 0.1935
Best model saved at epoch 1 with validation loss: 0.2059
[Epoch 2, Batch 100] loss: 0.17599134735763072
[Epoch 2, Batch 200] loss: 0.17054553035646677
[Epoch 2, Batch 300] loss: 0.16352686058729887
[Epoch 2, Batch 400] loss: 0.1377441257983446
[Epoch 2, Batch 500] loss: 0.1613937366940081
[Epoch 2, Batch 600] loss: 0.12882056379690765
[Epoch 2, Batch 700] loss: 0.13921605027280748
**STATS for Epoch 2** : 
Average training loss: 0.0081
Average validation loss: 0.1251
Validation Accuracy: 0.9597
Overfitting: 0.1170
Best model saved at epoch 2 with validation loss: 0.1251
[Epoch 3, Batch 100] loss: 0.12013394417241216
[Epoch 3, Batch 200] loss: 0.10253268575295806
[Epoch 3, Batch 300] loss: 0.0980462785018608
[Epoch 3, Batch 400] loss: 0.09444997143000364
[Epoch 3, Batch 500] loss: 0.09219718738459051
[Epoch 3, Batch 600] loss: 0.10605582654476166
[Epoch 3, Batch 700] loss: 0.08477239618077874
**STATS for Epoch 3** : 
Average training loss: 0.0064
Average validation loss: 0.1104
Validation Accuracy: 0.9649
Overfitting: 0.1040
Best model saved at epoch 3 with validation loss: 0.1104
[Epoch 4, Batch 100] loss: 0.08059526028577238
[Epoch 4, Batch 200] loss: 0.0796591925714165
[Epoch 4, Batch 300] loss: 0.08096788714639842
[Epoch 4, Batch 400] loss: 0.08047023177146911
[Epoch 4, Batch 500] loss: 0.07023207472637295
[Epoch 4, Batch 600] loss: 0.0786859576543793
[Epoch 4, Batch 700] loss: 0.0668460767576471
**STATS for Epoch 4** : 
Average training loss: 0.0056
Average validation loss: 0.0709
Validation Accuracy: 0.9778
Overfitting: 0.0654
Best model saved at epoch 4 with validation loss: 0.0709
[Epoch 5, Batch 100] loss: 0.06909954744391143
[Epoch 5, Batch 200] loss: 0.05963688523508608
[Epoch 5, Batch 300] loss: 0.062255056533031164
[Epoch 5, Batch 400] loss: 0.06569263346958905
[Epoch 5, Batch 500] loss: 0.061860000393353404
[Epoch 5, Batch 600] loss: 0.07063257656991481
[Epoch 5, Batch 700] loss: 0.06352751267142594
**STATS for Epoch 5** : 
Average training loss: 0.0044
Average validation loss: 0.0835
Validation Accuracy: 0.9724
Overfitting: 0.0790
[Epoch 6, Batch 100] loss: 0.059520003707148134
[Epoch 6, Batch 200] loss: 0.0604320830386132
[Epoch 6, Batch 300] loss: 0.045713001792319116
[Epoch 6, Batch 400] loss: 0.060512591297738255
[Epoch 6, Batch 500] loss: 0.06018602675292641
[Epoch 6, Batch 600] loss: 0.04862657058052719
[Epoch 6, Batch 700] loss: 0.0543536646827124
**STATS for Epoch 6** : 
Average training loss: 0.0034
Average validation loss: 0.0593
Validation Accuracy: 0.9822
Overfitting: 0.0559
Best model saved at epoch 6 with validation loss: 0.0593
[Epoch 7, Batch 100] loss: 0.044613418304361406
[Epoch 7, Batch 200] loss: 0.0516857371525839
[Epoch 7, Batch 300] loss: 0.05352250547613949
[Epoch 7, Batch 400] loss: 0.04585676808375865
[Epoch 7, Batch 500] loss: 0.048005633621942254
[Epoch 7, Batch 600] loss: 0.04564534963108599
[Epoch 7, Batch 700] loss: 0.04508184378850274
**STATS for Epoch 7** : 
Average training loss: 0.0031
Average validation loss: 0.0507
Validation Accuracy: 0.9842
Overfitting: 0.0475
Best model saved at epoch 7 with validation loss: 0.0507
[Epoch 8, Batch 100] loss: 0.04860735405702144
[Epoch 8, Batch 200] loss: 0.03666006860556081
[Epoch 8, Batch 300] loss: 0.03950570661807433
[Epoch 8, Batch 400] loss: 0.047041698629036545
[Epoch 8, Batch 500] loss: 0.0390043818554841
[Epoch 8, Batch 600] loss: 0.037866492206230756
[Epoch 8, Batch 700] loss: 0.038205606765113774
**STATS for Epoch 8** : 
Average training loss: 0.0025
Average validation loss: 0.0499
Validation Accuracy: 0.9842
Overfitting: 0.0473
Best model saved at epoch 8 with validation loss: 0.0499
[Epoch 9, Batch 100] loss: 0.03425476614502258
[Epoch 9, Batch 200] loss: 0.03459522674093023
[Epoch 9, Batch 300] loss: 0.03971916474518366
[Epoch 9, Batch 400] loss: 0.041438555216882375
[Epoch 9, Batch 500] loss: 0.03836248605977744
[Epoch 9, Batch 600] loss: 0.03477151581202634
[Epoch 9, Batch 700] loss: 0.04069056518143043
**STATS for Epoch 9** : 
Average training loss: 0.0020
Average validation loss: 0.0622
Validation Accuracy: 0.9817
Overfitting: 0.0602
[Epoch 10, Batch 100] loss: 0.03110864701215178
[Epoch 10, Batch 200] loss: 0.033661379445111377
[Epoch 10, Batch 300] loss: 0.03362650525057689
[Epoch 10, Batch 400] loss: 0.03252822111709975
[Epoch 10, Batch 500] loss: 0.03464187246048823
[Epoch 10, Batch 600] loss: 0.0340407547086943
[Epoch 10, Batch 700] loss: 0.029642303120344878
**STATS for Epoch 10** : 
Average training loss: 0.0025
Average validation loss: 0.0527
Validation Accuracy: 0.9831
Overfitting: 0.0502
[Epoch 11, Batch 100] loss: 0.0270751255430514
[Epoch 11, Batch 200] loss: 0.031577373722102495
[Epoch 11, Batch 300] loss: 0.03026463170419447
[Epoch 11, Batch 400] loss: 0.02556971245619934
[Epoch 11, Batch 500] loss: 0.032080857073888185
[Epoch 11, Batch 600] loss: 0.03270403140224516
[Epoch 11, Batch 700] loss: 0.029512427839217707
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0488
Validation Accuracy: 0.9853
Overfitting: 0.0471
Best model saved at epoch 11 with validation loss: 0.0488
[Epoch 12, Batch 100] loss: 0.026920709906262344
[Epoch 12, Batch 200] loss: 0.024999720733030698
[Epoch 12, Batch 300] loss: 0.03297491785895545
[Epoch 12, Batch 400] loss: 0.028682168283266946
[Epoch 12, Batch 500] loss: 0.023300041675684044
[Epoch 12, Batch 600] loss: 0.024932075024116783
[Epoch 12, Batch 700] loss: 0.021087862264830618
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0448
Validation Accuracy: 0.9868
Overfitting: 0.0436
Best model saved at epoch 12 with validation loss: 0.0448
[Epoch 13, Batch 100] loss: 0.022718923952779732
[Epoch 13, Batch 200] loss: 0.028103755686315707
[Epoch 13, Batch 300] loss: 0.02320721484371461
[Epoch 13, Batch 400] loss: 0.027277587876305916
[Epoch 13, Batch 500] loss: 0.02367851547722239
[Epoch 13, Batch 600] loss: 0.02264754603500478
[Epoch 13, Batch 700] loss: 0.03254992456408218
**STATS for Epoch 13** : 
Average training loss: 0.0022
Average validation loss: 0.0434
Validation Accuracy: 0.9864
Overfitting: 0.0413
Best model saved at epoch 13 with validation loss: 0.0434
[Epoch 14, Batch 100] loss: 0.020385645286587532
[Epoch 14, Batch 200] loss: 0.019342552204907406
[Epoch 14, Batch 300] loss: 0.019577525207423604
[Epoch 14, Batch 400] loss: 0.02336780551762786
[Epoch 14, Batch 500] loss: 0.023556134652462788
[Epoch 14, Batch 600] loss: 0.027971914167283105
[Epoch 14, Batch 700] loss: 0.019181269632535986
**STATS for Epoch 14** : 
Average training loss: 0.0015
Average validation loss: 0.0435
Validation Accuracy: 0.9862
Overfitting: 0.0420
[Epoch 15, Batch 100] loss: 0.019162831638241187
[Epoch 15, Batch 200] loss: 0.018743634849670343
[Epoch 15, Batch 300] loss: 0.02654382502892986
[Epoch 15, Batch 400] loss: 0.015305746732628904
[Epoch 15, Batch 500] loss: 0.021392770751263016
[Epoch 15, Batch 600] loss: 0.018139059867244213
[Epoch 15, Batch 700] loss: 0.017993813280772885
**STATS for Epoch 15** : 
Average training loss: 0.0012
Average validation loss: 0.0420
Validation Accuracy: 0.9881
Overfitting: 0.0407
Best model saved at epoch 15 with validation loss: 0.0420
[Epoch 16, Batch 100] loss: 0.014856694346526637
[Epoch 16, Batch 200] loss: 0.01643167688889662
[Epoch 16, Batch 300] loss: 0.015070428844628623
[Epoch 16, Batch 400] loss: 0.018296557385911003
[Epoch 16, Batch 500] loss: 0.017247588083846493
[Epoch 16, Batch 600] loss: 0.0210465298226336
[Epoch 16, Batch 700] loss: 0.016925764416519086
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0453
Validation Accuracy: 0.9860
Overfitting: 0.0443
[Epoch 17, Batch 100] loss: 0.012886285223357845
[Epoch 17, Batch 200] loss: 0.012042657603597035
[Epoch 17, Batch 300] loss: 0.019279696262383367
[Epoch 17, Batch 400] loss: 0.013619820038002217
[Epoch 17, Batch 500] loss: 0.020952519451384433
[Epoch 17, Batch 600] loss: 0.011823630116705317
[Epoch 17, Batch 700] loss: 0.016509798597398914
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0467
Validation Accuracy: 0.9862
Overfitting: 0.0458
[Epoch 18, Batch 100] loss: 0.010132079767645337
[Epoch 18, Batch 200] loss: 0.012288721759396139
[Epoch 18, Batch 300] loss: 0.01403512950782897
[Epoch 18, Batch 400] loss: 0.015004418889293446
[Epoch 18, Batch 500] loss: 0.022341479926835744
[Epoch 18, Batch 600] loss: 0.01706464046248584
[Epoch 18, Batch 700] loss: 0.012339055074844509
**STATS for Epoch 18** : 
Average training loss: 0.0011
Average validation loss: 0.0445
Validation Accuracy: 0.9871
Overfitting: 0.0434
[Epoch 19, Batch 100] loss: 0.010906756374024553
[Epoch 19, Batch 200] loss: 0.013294159537763335
[Epoch 19, Batch 300] loss: 0.020208967550715898
[Epoch 19, Batch 400] loss: 0.014537963928014506
[Epoch 19, Batch 500] loss: 0.013116728422755842
[Epoch 19, Batch 600] loss: 0.010072457787246095
[Epoch 19, Batch 700] loss: 0.012512195812450954
**STATS for Epoch 19** : 
Average training loss: 0.0010
Average validation loss: 0.0481
Validation Accuracy: 0.9854
Overfitting: 0.0472
[Epoch 20, Batch 100] loss: 0.012130887466337299
[Epoch 20, Batch 200] loss: 0.01044815742148785
[Epoch 20, Batch 300] loss: 0.007468953876814339
[Epoch 20, Batch 400] loss: 0.012393884027987951
[Epoch 20, Batch 500] loss: 0.008050094445352443
[Epoch 20, Batch 600] loss: 0.015674596761527937
[Epoch 20, Batch 700] loss: 0.012955466049897951
**STATS for Epoch 20** : 
Average training loss: 0.0009
Average validation loss: 0.0437
Validation Accuracy: 0.9888
Overfitting: 0.0428
[Epoch 21, Batch 100] loss: 0.010507181387220043
[Epoch 21, Batch 200] loss: 0.006538708931184373
[Epoch 21, Batch 300] loss: 0.007285476768447552
[Epoch 21, Batch 400] loss: 0.013219657528970856
[Epoch 21, Batch 500] loss: 0.01183648587015341
[Epoch 21, Batch 600] loss: 0.010107238812561264
[Epoch 21, Batch 700] loss: 0.01185629857427557
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0435
Validation Accuracy: 0.9882
Overfitting: 0.0430
[Epoch 22, Batch 100] loss: 0.007104266760870814
[Epoch 22, Batch 200] loss: 0.008386026634980226
[Epoch 22, Batch 300] loss: 0.008238468764830031
[Epoch 22, Batch 400] loss: 0.007509692663006717
[Epoch 22, Batch 500] loss: 0.008543387431418524
[Epoch 22, Batch 600] loss: 0.010078818230249453
[Epoch 22, Batch 700] loss: 0.008385177131567617
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0433
Validation Accuracy: 0.9875
Overfitting: 0.0426
[Epoch 23, Batch 100] loss: 0.006262213077279739
[Epoch 23, Batch 200] loss: 0.004505232626688667
[Epoch 23, Batch 300] loss: 0.010883414102718234
[Epoch 23, Batch 400] loss: 0.012236685040297743
[Epoch 23, Batch 500] loss: 0.008128619230628829
[Epoch 23, Batch 600] loss: 0.010377690678869839
[Epoch 23, Batch 700] loss: 0.011777659290091834
**STATS for Epoch 23** : 
Average training loss: 0.0009
Average validation loss: 0.0480
Validation Accuracy: 0.9860
Overfitting: 0.0472
[Epoch 24, Batch 100] loss: 0.007555921975144883
[Epoch 24, Batch 200] loss: 0.007667030235534184
[Epoch 24, Batch 300] loss: 0.007562364476034418
[Epoch 24, Batch 400] loss: 0.00731389190084883
[Epoch 24, Batch 500] loss: 0.010843190217819938
[Epoch 24, Batch 600] loss: 0.006761413243802963
[Epoch 24, Batch 700] loss: 0.007847052841025288
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0453
Validation Accuracy: 0.9870
Overfitting: 0.0448
Fold 4 validation loss: 0.0453
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2910417318344116
[Epoch 1, Batch 200] loss: 2.1105741131305695
[Epoch 1, Batch 300] loss: 0.8115938293933869
[Epoch 1, Batch 400] loss: 0.47279183760285376
[Epoch 1, Batch 500] loss: 0.38175240069627764
[Epoch 1, Batch 600] loss: 0.314843480437994
[Epoch 1, Batch 700] loss: 0.2570646499097347
**STATS for Epoch 1** : 
Average training loss: 0.0144
Average validation loss: 0.2169
Validation Accuracy: 0.9349
Overfitting: 0.2024
Best model saved at epoch 1 with validation loss: 0.2169
[Epoch 2, Batch 100] loss: 0.2124515985697508
[Epoch 2, Batch 200] loss: 0.19063963484019042
[Epoch 2, Batch 300] loss: 0.18325892735272645
[Epoch 2, Batch 400] loss: 0.15968600623309612
[Epoch 2, Batch 500] loss: 0.1562935619056225
[Epoch 2, Batch 600] loss: 0.13352989125996828
[Epoch 2, Batch 700] loss: 0.1180519806407392
**STATS for Epoch 2** : 
Average training loss: 0.0087
Average validation loss: 0.1219
Validation Accuracy: 0.9640
Overfitting: 0.1132
Best model saved at epoch 2 with validation loss: 0.1219
[Epoch 3, Batch 100] loss: 0.10701752593740821
[Epoch 3, Batch 200] loss: 0.11095005479641258
[Epoch 3, Batch 300] loss: 0.10097330872900784
[Epoch 3, Batch 400] loss: 0.11315749295055866
[Epoch 3, Batch 500] loss: 0.08637127260677517
[Epoch 3, Batch 600] loss: 0.09948635445907712
[Epoch 3, Batch 700] loss: 0.09163133916445076
**STATS for Epoch 3** : 
Average training loss: 0.0058
Average validation loss: 0.0876
Validation Accuracy: 0.9733
Overfitting: 0.0818
Best model saved at epoch 3 with validation loss: 0.0876
[Epoch 4, Batch 100] loss: 0.08774298810400069
[Epoch 4, Batch 200] loss: 0.08273209117352963
[Epoch 4, Batch 300] loss: 0.06776557866018265
[Epoch 4, Batch 400] loss: 0.07165434824302792
[Epoch 4, Batch 500] loss: 0.0677412736415863
[Epoch 4, Batch 600] loss: 0.07476577390450984
[Epoch 4, Batch 700] loss: 0.07890908683650195
**STATS for Epoch 4** : 
Average training loss: 0.0053
Average validation loss: 0.0675
Validation Accuracy: 0.9796
Overfitting: 0.0622
Best model saved at epoch 4 with validation loss: 0.0675
[Epoch 5, Batch 100] loss: 0.05467098122928291
[Epoch 5, Batch 200] loss: 0.061158187249675394
[Epoch 5, Batch 300] loss: 0.06722740726545454
[Epoch 5, Batch 400] loss: 0.06778319388628005
[Epoch 5, Batch 500] loss: 0.062450985233299436
[Epoch 5, Batch 600] loss: 0.06445982619188725
[Epoch 5, Batch 700] loss: 0.06542176560498775
**STATS for Epoch 5** : 
Average training loss: 0.0042
Average validation loss: 0.0670
Validation Accuracy: 0.9794
Overfitting: 0.0628
Best model saved at epoch 5 with validation loss: 0.0670
[Epoch 6, Batch 100] loss: 0.05923361786175519
[Epoch 6, Batch 200] loss: 0.05719591997098178
[Epoch 6, Batch 300] loss: 0.05752973749302328
[Epoch 6, Batch 400] loss: 0.05481908271089196
[Epoch 6, Batch 500] loss: 0.05142734170891344
[Epoch 6, Batch 600] loss: 0.04535646907519549
[Epoch 6, Batch 700] loss: 0.0699310795776546
**STATS for Epoch 6** : 
Average training loss: 0.0032
Average validation loss: 0.0626
Validation Accuracy: 0.9800
Overfitting: 0.0594
Best model saved at epoch 6 with validation loss: 0.0626
[Epoch 7, Batch 100] loss: 0.04855345622170717
[Epoch 7, Batch 200] loss: 0.047516419517342
[Epoch 7, Batch 300] loss: 0.039336001304909586
[Epoch 7, Batch 400] loss: 0.04977345202933066
[Epoch 7, Batch 500] loss: 0.04222478012787178
[Epoch 7, Batch 600] loss: 0.05198120567947626
[Epoch 7, Batch 700] loss: 0.046775677688419816
**STATS for Epoch 7** : 
Average training loss: 0.0039
Average validation loss: 0.0536
Validation Accuracy: 0.9828
Overfitting: 0.0497
Best model saved at epoch 7 with validation loss: 0.0536
[Epoch 8, Batch 100] loss: 0.038515289048664275
[Epoch 8, Batch 200] loss: 0.046704405350610614
[Epoch 8, Batch 300] loss: 0.04332394177792594
[Epoch 8, Batch 400] loss: 0.03831112820887938
[Epoch 8, Batch 500] loss: 0.041286475972738115
[Epoch 8, Batch 600] loss: 0.042318002812098715
[Epoch 8, Batch 700] loss: 0.040063077951781455
**STATS for Epoch 8** : 
Average training loss: 0.0029
Average validation loss: 0.0559
Validation Accuracy: 0.9831
Overfitting: 0.0531
[Epoch 9, Batch 100] loss: 0.04023784163175151
[Epoch 9, Batch 200] loss: 0.033236160870874304
[Epoch 9, Batch 300] loss: 0.03383515864086803
[Epoch 9, Batch 400] loss: 0.03777434401679784
[Epoch 9, Batch 500] loss: 0.038572219765046614
[Epoch 9, Batch 600] loss: 0.0394161727046594
[Epoch 9, Batch 700] loss: 0.039389090356417
**STATS for Epoch 9** : 
Average training loss: 0.0025
Average validation loss: 0.0477
Validation Accuracy: 0.9863
Overfitting: 0.0453
Best model saved at epoch 9 with validation loss: 0.0477
[Epoch 10, Batch 100] loss: 0.031190720497397705
[Epoch 10, Batch 200] loss: 0.034746191756566985
[Epoch 10, Batch 300] loss: 0.02681399975437671
[Epoch 10, Batch 400] loss: 0.0390767447988037
[Epoch 10, Batch 500] loss: 0.02561399995815009
[Epoch 10, Batch 600] loss: 0.04213902361516375
[Epoch 10, Batch 700] loss: 0.03688816334004514
**STATS for Epoch 10** : 
Average training loss: 0.0019
Average validation loss: 0.0445
Validation Accuracy: 0.9863
Overfitting: 0.0426
Best model saved at epoch 10 with validation loss: 0.0445
[Epoch 11, Batch 100] loss: 0.022639209014596418
[Epoch 11, Batch 200] loss: 0.025265649991342797
[Epoch 11, Batch 300] loss: 0.02711861116345972
[Epoch 11, Batch 400] loss: 0.03307366600027308
[Epoch 11, Batch 500] loss: 0.03363392452942207
[Epoch 11, Batch 600] loss: 0.031147253466770053
[Epoch 11, Batch 700] loss: 0.032468076666118575
**STATS for Epoch 11** : 
Average training loss: 0.0019
Average validation loss: 0.0467
Validation Accuracy: 0.9853
Overfitting: 0.0448
[Epoch 12, Batch 100] loss: 0.028219717642641626
[Epoch 12, Batch 200] loss: 0.02751209467125591
[Epoch 12, Batch 300] loss: 0.028509929908905177
[Epoch 12, Batch 400] loss: 0.027409567604772745
[Epoch 12, Batch 500] loss: 0.023421659934101627
[Epoch 12, Batch 600] loss: 0.019328689396497793
[Epoch 12, Batch 700] loss: 0.024486504809756296
**STATS for Epoch 12** : 
Average training loss: 0.0025
Average validation loss: 0.0492
Validation Accuracy: 0.9850
Overfitting: 0.0468
[Epoch 13, Batch 100] loss: 0.02672291699331254
[Epoch 13, Batch 200] loss: 0.020394152220687828
[Epoch 13, Batch 300] loss: 0.024051647481974213
[Epoch 13, Batch 400] loss: 0.020842506948974916
[Epoch 13, Batch 500] loss: 0.024924038687022403
[Epoch 13, Batch 600] loss: 0.023212908708374017
[Epoch 13, Batch 700] loss: 0.02655235744197853
**STATS for Epoch 13** : 
Average training loss: 0.0017
Average validation loss: 0.0431
Validation Accuracy: 0.9872
Overfitting: 0.0414
Best model saved at epoch 13 with validation loss: 0.0431
[Epoch 14, Batch 100] loss: 0.022596210274496115
[Epoch 14, Batch 200] loss: 0.02361091910628602
[Epoch 14, Batch 300] loss: 0.022259953000466338
[Epoch 14, Batch 400] loss: 0.020485916853649543
[Epoch 14, Batch 500] loss: 0.02391928120458033
[Epoch 14, Batch 600] loss: 0.02301369864377193
[Epoch 14, Batch 700] loss: 0.027164331288076937
**STATS for Epoch 14** : 
Average training loss: 0.0013
Average validation loss: 0.0433
Validation Accuracy: 0.9867
Overfitting: 0.0420
[Epoch 15, Batch 100] loss: 0.013645607025537174
[Epoch 15, Batch 200] loss: 0.021960759743815287
[Epoch 15, Batch 300] loss: 0.018913025669171475
[Epoch 15, Batch 400] loss: 0.021845559382927603
[Epoch 15, Batch 500] loss: 0.020021781402319902
[Epoch 15, Batch 600] loss: 0.017663872601115144
[Epoch 15, Batch 700] loss: 0.01853633321239613
**STATS for Epoch 15** : 
Average training loss: 0.0019
Average validation loss: 0.0418
Validation Accuracy: 0.9877
Overfitting: 0.0399
Best model saved at epoch 15 with validation loss: 0.0418
[Epoch 16, Batch 100] loss: 0.013613952337182126
[Epoch 16, Batch 200] loss: 0.012989428784349001
[Epoch 16, Batch 300] loss: 0.017645714126410895
[Epoch 16, Batch 400] loss: 0.0237830863011186
[Epoch 16, Batch 500] loss: 0.017664544050931
[Epoch 16, Batch 600] loss: 0.01334607400058303
[Epoch 16, Batch 700] loss: 0.020988637535192537
**STATS for Epoch 16** : 
Average training loss: 0.0014
Average validation loss: 0.0430
Validation Accuracy: 0.9868
Overfitting: 0.0415
[Epoch 17, Batch 100] loss: 0.014779898501583375
[Epoch 17, Batch 200] loss: 0.014142820333654526
[Epoch 17, Batch 300] loss: 0.011656906232819892
[Epoch 17, Batch 400] loss: 0.014692550782638137
[Epoch 17, Batch 500] loss: 0.016518471510207747
[Epoch 17, Batch 600] loss: 0.02009952806853107
[Epoch 17, Batch 700] loss: 0.016603812850080432
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0454
Validation Accuracy: 0.9868
Overfitting: 0.0443
[Epoch 18, Batch 100] loss: 0.013314857080113143
[Epoch 18, Batch 200] loss: 0.016233621055725962
[Epoch 18, Batch 300] loss: 0.01080285298754461
[Epoch 18, Batch 400] loss: 0.015381129923043772
[Epoch 18, Batch 500] loss: 0.022117899776494598
[Epoch 18, Batch 600] loss: 0.01462703805824276
[Epoch 18, Batch 700] loss: 0.014706470155360876
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0445
Validation Accuracy: 0.9863
Overfitting: 0.0438
[Epoch 19, Batch 100] loss: 0.011455816250891076
[Epoch 19, Batch 200] loss: 0.011696025739365724
[Epoch 19, Batch 300] loss: 0.01411658824494225
[Epoch 19, Batch 400] loss: 0.012930210336926394
[Epoch 19, Batch 500] loss: 0.017173308365163394
[Epoch 19, Batch 600] loss: 0.011228756314958446
[Epoch 19, Batch 700] loss: 0.013757139605222618
**STATS for Epoch 19** : 
Average training loss: 0.0011
Average validation loss: 0.0416
Validation Accuracy: 0.9879
Overfitting: 0.0405
Best model saved at epoch 19 with validation loss: 0.0416
[Epoch 20, Batch 100] loss: 0.01197142890348914
[Epoch 20, Batch 200] loss: 0.011784359445882728
[Epoch 20, Batch 300] loss: 0.011208801715401933
[Epoch 20, Batch 400] loss: 0.01534300514991628
[Epoch 20, Batch 500] loss: 0.012139821734745055
[Epoch 20, Batch 600] loss: 0.014291924337449018
[Epoch 20, Batch 700] loss: 0.012577966444659978
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0438
Validation Accuracy: 0.9879
Overfitting: 0.0428
[Epoch 21, Batch 100] loss: 0.009055311607626208
[Epoch 21, Batch 200] loss: 0.008346134241583059
[Epoch 21, Batch 300] loss: 0.009201126841217046
[Epoch 21, Batch 400] loss: 0.006448353382511414
[Epoch 21, Batch 500] loss: 0.011609519922276377
[Epoch 21, Batch 600] loss: 0.013236912126449169
[Epoch 21, Batch 700] loss: 0.012181943885079817
**STATS for Epoch 21** : 
Average training loss: 0.0009
Average validation loss: 0.0439
Validation Accuracy: 0.9879
Overfitting: 0.0430
[Epoch 22, Batch 100] loss: 0.010329530495437212
[Epoch 22, Batch 200] loss: 0.007961844141827896
[Epoch 22, Batch 300] loss: 0.009947018286038656
[Epoch 22, Batch 400] loss: 0.010251127730443841
[Epoch 22, Batch 500] loss: 0.011666291147412267
[Epoch 22, Batch 600] loss: 0.010143516953321522
[Epoch 22, Batch 700] loss: 0.006613302142650355
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0445
Validation Accuracy: 0.9886
Overfitting: 0.0440
[Epoch 23, Batch 100] loss: 0.008422559560785884
[Epoch 23, Batch 200] loss: 0.008692706602305407
[Epoch 23, Batch 300] loss: 0.008027393104202928
[Epoch 23, Batch 400] loss: 0.00654094832145347
[Epoch 23, Batch 500] loss: 0.009778919329546625
[Epoch 23, Batch 600] loss: 0.010112639702565502
[Epoch 23, Batch 700] loss: 0.010976013434192283
**STATS for Epoch 23** : 
Average training loss: 0.0008
Average validation loss: 0.0453
Validation Accuracy: 0.9877
Overfitting: 0.0445
[Epoch 24, Batch 100] loss: 0.006261498178500915
[Epoch 24, Batch 200] loss: 0.007236437095707515
[Epoch 24, Batch 300] loss: 0.008149097495843307
[Epoch 24, Batch 400] loss: 0.009594978670938871
[Epoch 24, Batch 500] loss: 0.008440403758431785
[Epoch 24, Batch 600] loss: 0.007652709167887224
[Epoch 24, Batch 700] loss: 0.010750999712981865
**STATS for Epoch 24** : 
Average training loss: 0.0006
Average validation loss: 0.0425
Validation Accuracy: 0.9886
Overfitting: 0.0419
Fold 5 validation loss: 0.0425
Mean validation loss across all folds for Trial 17 is 0.0472 with trial config:  l1: 256, l2: 64, lr: 0.0021343086136530096, batch_size: 64
[I 2024-12-10 08:04:53,446] Trial 16 finished with value: 0.04722271221232811 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0021343086136530096, 'batch_size': 64}. Best is trial 16 with value: 0.04722271221232811.

Selected Hyperparameters for Trial 18:
  l1: 256, l2: 64, lr: 0.0038216021085446107, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2478029799461363
[Epoch 1, Batch 200] loss: 0.950760989189148
[Epoch 1, Batch 300] loss: 0.38780944973230363
[Epoch 1, Batch 400] loss: 0.266689625158906
[Epoch 1, Batch 500] loss: 0.20851564705371856
[Epoch 1, Batch 600] loss: 0.16696367952972652
[Epoch 1, Batch 700] loss: 0.14016150385141374
**STATS for Epoch 1** : 
Average training loss: 0.0098
Average validation loss: 0.1099
Validation Accuracy: 0.9640
Overfitting: 0.1001
Best model saved at epoch 1 with validation loss: 0.1099
[Epoch 2, Batch 100] loss: 0.11857046218588949
[Epoch 2, Batch 200] loss: 0.10989928965456784
[Epoch 2, Batch 300] loss: 0.10214641857892275
[Epoch 2, Batch 400] loss: 0.11380993332713843
[Epoch 2, Batch 500] loss: 0.08885115460492671
[Epoch 2, Batch 600] loss: 0.0969710607919842
[Epoch 2, Batch 700] loss: 0.08635416258126498
**STATS for Epoch 2** : 
Average training loss: 0.0048
Average validation loss: 0.0935
Validation Accuracy: 0.9706
Overfitting: 0.0887
Best model saved at epoch 2 with validation loss: 0.0935
[Epoch 3, Batch 100] loss: 0.06998175229411573
[Epoch 3, Batch 200] loss: 0.0719034473085776
[Epoch 3, Batch 300] loss: 0.07440619297791272
[Epoch 3, Batch 400] loss: 0.06110505357850343
[Epoch 3, Batch 500] loss: 0.06454324370250106
[Epoch 3, Batch 600] loss: 0.06917543476913124
[Epoch 3, Batch 700] loss: 0.07032960711047054
**STATS for Epoch 3** : 
Average training loss: 0.0035
Average validation loss: 0.0770
Validation Accuracy: 0.9762
Overfitting: 0.0735
Best model saved at epoch 3 with validation loss: 0.0770
[Epoch 4, Batch 100] loss: 0.05033380559645593
[Epoch 4, Batch 200] loss: 0.06433814686723054
[Epoch 4, Batch 300] loss: 0.056650754455477
[Epoch 4, Batch 400] loss: 0.05424453905550763
[Epoch 4, Batch 500] loss: 0.05490758827887476
[Epoch 4, Batch 600] loss: 0.047756974102230745
[Epoch 4, Batch 700] loss: 0.04586885190801695
**STATS for Epoch 4** : 
Average training loss: 0.0030
Average validation loss: 0.0538
Validation Accuracy: 0.9838
Overfitting: 0.0508
Best model saved at epoch 4 with validation loss: 0.0538
[Epoch 5, Batch 100] loss: 0.0461100422218442
[Epoch 5, Batch 200] loss: 0.05457089088857174
[Epoch 5, Batch 300] loss: 0.03714364198734984
[Epoch 5, Batch 400] loss: 0.04515037961420603
[Epoch 5, Batch 500] loss: 0.04200772038660944
[Epoch 5, Batch 600] loss: 0.041903239858802406
[Epoch 5, Batch 700] loss: 0.044393544138874856
**STATS for Epoch 5** : 
Average training loss: 0.0035
Average validation loss: 0.0473
Validation Accuracy: 0.9848
Overfitting: 0.0438
Best model saved at epoch 5 with validation loss: 0.0473
[Epoch 6, Batch 100] loss: 0.039008893432328474
[Epoch 6, Batch 200] loss: 0.032460213631857186
[Epoch 6, Batch 300] loss: 0.03927695956779644
[Epoch 6, Batch 400] loss: 0.030914783666376025
[Epoch 6, Batch 500] loss: 0.03275547468219884
[Epoch 6, Batch 600] loss: 0.031015164441196248
[Epoch 6, Batch 700] loss: 0.045193022091407326
**STATS for Epoch 6** : 
Average training loss: 0.0024
Average validation loss: 0.0510
Validation Accuracy: 0.9832
Overfitting: 0.0485
[Epoch 7, Batch 100] loss: 0.028534232800593598
[Epoch 7, Batch 200] loss: 0.033353786097140986
[Epoch 7, Batch 300] loss: 0.03500319477170706
[Epoch 7, Batch 400] loss: 0.02531879870162811
[Epoch 7, Batch 500] loss: 0.03319676441606134
[Epoch 7, Batch 600] loss: 0.02780469078104943
[Epoch 7, Batch 700] loss: 0.02656414261844475
**STATS for Epoch 7** : 
Average training loss: 0.0025
Average validation loss: 0.0496
Validation Accuracy: 0.9852
Overfitting: 0.0470
[Epoch 8, Batch 100] loss: 0.024920248685521073
[Epoch 8, Batch 200] loss: 0.02931015174544882
[Epoch 8, Batch 300] loss: 0.027682913440512495
[Epoch 8, Batch 400] loss: 0.026533084578695708
[Epoch 8, Batch 500] loss: 0.02759452915401198
[Epoch 8, Batch 600] loss: 0.02680770413542632
[Epoch 8, Batch 700] loss: 0.03005921495263465
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0526
Validation Accuracy: 0.9835
Overfitting: 0.0506
[Epoch 9, Batch 100] loss: 0.02410209037072491
[Epoch 9, Batch 200] loss: 0.02879335723235272
[Epoch 9, Batch 300] loss: 0.025303292432799936
[Epoch 9, Batch 400] loss: 0.023616089699789882
[Epoch 9, Batch 500] loss: 0.01575539250858128
[Epoch 9, Batch 600] loss: 0.02560721706075128
[Epoch 9, Batch 700] loss: 0.024346783344517463
**STATS for Epoch 9** : 
Average training loss: 0.0019
Average validation loss: 0.0475
Validation Accuracy: 0.9859
Overfitting: 0.0456
[Epoch 10, Batch 100] loss: 0.016863874995615334
[Epoch 10, Batch 200] loss: 0.0206371569231851
[Epoch 10, Batch 300] loss: 0.021396941634593533
[Epoch 10, Batch 400] loss: 0.01814374730514828
[Epoch 10, Batch 500] loss: 0.02009147617238341
[Epoch 10, Batch 600] loss: 0.021016623620525934
[Epoch 10, Batch 700] loss: 0.02357235805160599
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0472
Validation Accuracy: 0.9856
Overfitting: 0.0460
Best model saved at epoch 10 with validation loss: 0.0472
[Epoch 11, Batch 100] loss: 0.015773644719156436
[Epoch 11, Batch 200] loss: 0.017283212256879777
[Epoch 11, Batch 300] loss: 0.014051210041798186
[Epoch 11, Batch 400] loss: 0.016934887132665607
[Epoch 11, Batch 500] loss: 0.019870845766272394
[Epoch 11, Batch 600] loss: 0.01934814635766088
[Epoch 11, Batch 700] loss: 0.01570409443163953
**STATS for Epoch 11** : 
Average training loss: 0.0011
Average validation loss: 0.0476
Validation Accuracy: 0.9862
Overfitting: 0.0465
[Epoch 12, Batch 100] loss: 0.017682677884295117
[Epoch 12, Batch 200] loss: 0.012532055908231997
[Epoch 12, Batch 300] loss: 0.01642162047297461
[Epoch 12, Batch 400] loss: 0.015663885776593816
[Epoch 12, Batch 500] loss: 0.01281744379288284
[Epoch 12, Batch 600] loss: 0.020004530399164652
[Epoch 12, Batch 700] loss: 0.017643786771659505
**STATS for Epoch 12** : 
Average training loss: 0.0014
Average validation loss: 0.0505
Validation Accuracy: 0.9854
Overfitting: 0.0491
[Epoch 13, Batch 100] loss: 0.014659521637950092
[Epoch 13, Batch 200] loss: 0.015771791551233035
[Epoch 13, Batch 300] loss: 0.011246487391035771
[Epoch 13, Batch 400] loss: 0.012521341469546315
[Epoch 13, Batch 500] loss: 0.009915509778729757
[Epoch 13, Batch 600] loss: 0.01963419996201992
[Epoch 13, Batch 700] loss: 0.020393097731866875
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0481
Validation Accuracy: 0.9872
Overfitting: 0.0470
[Epoch 14, Batch 100] loss: 0.009832563930540345
[Epoch 14, Batch 200] loss: 0.010929490799608175
[Epoch 14, Batch 300] loss: 0.007712190367165021
[Epoch 14, Batch 400] loss: 0.008744188329437748
[Epoch 14, Batch 500] loss: 0.01381618571744184
[Epoch 14, Batch 600] loss: 0.013148294467391679
[Epoch 14, Batch 700] loss: 0.013929559005846385
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0447
Validation Accuracy: 0.9871
Overfitting: 0.0435
Best model saved at epoch 14 with validation loss: 0.0447
[Epoch 15, Batch 100] loss: 0.008667185581289231
[Epoch 15, Batch 200] loss: 0.00612992677364673
[Epoch 15, Batch 300] loss: 0.008995049183649826
[Epoch 15, Batch 400] loss: 0.011243757173651829
[Epoch 15, Batch 500] loss: 0.0077393250449677
[Epoch 15, Batch 600] loss: 0.014156998888938687
[Epoch 15, Batch 700] loss: 0.010852633580216207
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0431
Validation Accuracy: 0.9898
Overfitting: 0.0426
Best model saved at epoch 15 with validation loss: 0.0431
[Epoch 16, Batch 100] loss: 0.006871071418572683
[Epoch 16, Batch 200] loss: 0.006105208023436717
[Epoch 16, Batch 300] loss: 0.0074133430761503406
[Epoch 16, Batch 400] loss: 0.008023669663598411
[Epoch 16, Batch 500] loss: 0.011508543597228709
[Epoch 16, Batch 600] loss: 0.009528144454307039
[Epoch 16, Batch 700] loss: 0.008619222089400864
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0474
Validation Accuracy: 0.9863
Overfitting: 0.0469
[Epoch 17, Batch 100] loss: 0.007665214398803073
[Epoch 17, Batch 200] loss: 0.006356044241183554
[Epoch 17, Batch 300] loss: 0.006868548570055282
[Epoch 17, Batch 400] loss: 0.006040341920815991
[Epoch 17, Batch 500] loss: 0.010067091373348375
[Epoch 17, Batch 600] loss: 0.010433951011727914
[Epoch 17, Batch 700] loss: 0.008410722816552151
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0449
Validation Accuracy: 0.9884
Overfitting: 0.0445
[Epoch 18, Batch 100] loss: 0.004988019124648417
[Epoch 18, Batch 200] loss: 0.004793409838821389
[Epoch 18, Batch 300] loss: 0.0077421182047964976
[Epoch 18, Batch 400] loss: 0.005955263146224752
[Epoch 18, Batch 500] loss: 0.00788192344167328
[Epoch 18, Batch 600] loss: 0.019006212585882167
[Epoch 18, Batch 700] loss: 0.006553694609028753
**STATS for Epoch 18** : 
Average training loss: 0.0005
Average validation loss: 0.0513
Validation Accuracy: 0.9870
Overfitting: 0.0508
[Epoch 19, Batch 100] loss: 0.0048806291422442884
[Epoch 19, Batch 200] loss: 0.007321650248632068
[Epoch 19, Batch 300] loss: 0.004466618494552677
[Epoch 19, Batch 400] loss: 0.003178569234078168
[Epoch 19, Batch 500] loss: 0.007037309954039301
[Epoch 19, Batch 600] loss: 0.010308434606231457
[Epoch 19, Batch 700] loss: 0.00710266478068661
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0478
Validation Accuracy: 0.9880
Overfitting: 0.0475
[Epoch 20, Batch 100] loss: 0.006405613150691352
[Epoch 20, Batch 200] loss: 0.008134470433324168
[Epoch 20, Batch 300] loss: 0.004783802462006861
[Epoch 20, Batch 400] loss: 0.003649941106014012
[Epoch 20, Batch 500] loss: 0.005330052949520905
[Epoch 20, Batch 600] loss: 0.009930063837709896
[Epoch 20, Batch 700] loss: 0.007841717479896032
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0471
Validation Accuracy: 0.9883
Overfitting: 0.0469
[Epoch 21, Batch 100] loss: 0.005803867021641053
[Epoch 21, Batch 200] loss: 0.00377572011508164
[Epoch 21, Batch 300] loss: 0.005473805922647444
[Epoch 21, Batch 400] loss: 0.004859768287751649
[Epoch 21, Batch 500] loss: 0.004469508651673095
[Epoch 21, Batch 600] loss: 0.003953473763940565
[Epoch 21, Batch 700] loss: 0.005784640085403225
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0497
Validation Accuracy: 0.9876
Overfitting: 0.0492
[Epoch 22, Batch 100] loss: 0.003659188724914202
[Epoch 22, Batch 200] loss: 0.0036427528940475894
[Epoch 22, Batch 300] loss: 0.0030497359175842577
[Epoch 22, Batch 400] loss: 0.006747601531969849
[Epoch 22, Batch 500] loss: 0.0027175958415864444
[Epoch 22, Batch 600] loss: 0.003716252265512594
[Epoch 22, Batch 700] loss: 0.0036017336705208435
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0693
Validation Accuracy: 0.9848
Overfitting: 0.0690
[Epoch 23, Batch 100] loss: 0.006883085842564469
[Epoch 23, Batch 200] loss: 0.005315486460121974
[Epoch 23, Batch 300] loss: 0.0029273532574916315
[Epoch 23, Batch 400] loss: 0.004313045702401723
[Epoch 23, Batch 500] loss: 0.004860626356157809
[Epoch 23, Batch 600] loss: 0.0038312432104430625
[Epoch 23, Batch 700] loss: 0.0033017992499571845
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0578
Validation Accuracy: 0.9883
Overfitting: 0.0574
[Epoch 24, Batch 100] loss: 0.003044893205792505
[Epoch 24, Batch 200] loss: 0.0029628633185711808
[Epoch 24, Batch 300] loss: 0.0013968475997899077
[Epoch 24, Batch 400] loss: 0.0032298678632469093
[Epoch 24, Batch 500] loss: 0.0058803577798107656
[Epoch 24, Batch 600] loss: 0.006330665677110119
[Epoch 24, Batch 700] loss: 0.0018113058977451146
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0585
Validation Accuracy: 0.9878
Overfitting: 0.0583
Fold 1 validation loss: 0.0585
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2403076457977296
[Epoch 1, Batch 200] loss: 0.8942211124300957
[Epoch 1, Batch 300] loss: 0.37094960764050483
[Epoch 1, Batch 400] loss: 0.26186638861894607
[Epoch 1, Batch 500] loss: 0.20132797054946422
[Epoch 1, Batch 600] loss: 0.1931584594398737
[Epoch 1, Batch 700] loss: 0.1548193283751607
**STATS for Epoch 1** : 
Average training loss: 0.0094
Average validation loss: 0.1375
Validation Accuracy: 0.9565
Overfitting: 0.1281
Best model saved at epoch 1 with validation loss: 0.1375
[Epoch 2, Batch 100] loss: 0.1337833808362484
[Epoch 2, Batch 200] loss: 0.12188782693818212
[Epoch 2, Batch 300] loss: 0.11423414118587971
[Epoch 2, Batch 400] loss: 0.09282236661761999
[Epoch 2, Batch 500] loss: 0.09525925622321665
[Epoch 2, Batch 600] loss: 0.09558414701372385
[Epoch 2, Batch 700] loss: 0.0798069166764617
**STATS for Epoch 2** : 
Average training loss: 0.0061
Average validation loss: 0.1121
Validation Accuracy: 0.9657
Overfitting: 0.1060
Best model saved at epoch 2 with validation loss: 0.1121
[Epoch 3, Batch 100] loss: 0.07796090851537883
[Epoch 3, Batch 200] loss: 0.08059282023925335
[Epoch 3, Batch 300] loss: 0.08269537230487913
[Epoch 3, Batch 400] loss: 0.07506611298769712
[Epoch 3, Batch 500] loss: 0.07544562407303601
[Epoch 3, Batch 600] loss: 0.06683086210396141
[Epoch 3, Batch 700] loss: 0.07199792815372348
**STATS for Epoch 3** : 
Average training loss: 0.0047
Average validation loss: 0.0831
Validation Accuracy: 0.9729
Overfitting: 0.0784
Best model saved at epoch 3 with validation loss: 0.0831
[Epoch 4, Batch 100] loss: 0.052981811792124064
[Epoch 4, Batch 200] loss: 0.05845559733337723
[Epoch 4, Batch 300] loss: 0.05691309960559011
[Epoch 4, Batch 400] loss: 0.05865545080509037
[Epoch 4, Batch 500] loss: 0.0546727762313094
[Epoch 4, Batch 600] loss: 0.05910428000497632
[Epoch 4, Batch 700] loss: 0.058392662182450296
**STATS for Epoch 4** : 
Average training loss: 0.0039
Average validation loss: 0.0686
Validation Accuracy: 0.9779
Overfitting: 0.0647
Best model saved at epoch 4 with validation loss: 0.0686
[Epoch 5, Batch 100] loss: 0.03721278215292841
[Epoch 5, Batch 200] loss: 0.047428118190728126
[Epoch 5, Batch 300] loss: 0.047677857130765916
[Epoch 5, Batch 400] loss: 0.047959517815615985
[Epoch 5, Batch 500] loss: 0.051552639766596256
[Epoch 5, Batch 600] loss: 0.04957457421347499
[Epoch 5, Batch 700] loss: 0.04891470408299938
**STATS for Epoch 5** : 
Average training loss: 0.0037
Average validation loss: 0.0722
Validation Accuracy: 0.9777
Overfitting: 0.0684
[Epoch 6, Batch 100] loss: 0.039037969501223416
[Epoch 6, Batch 200] loss: 0.033190961189102385
[Epoch 6, Batch 300] loss: 0.04029819020302966
[Epoch 6, Batch 400] loss: 0.03795049202628434
[Epoch 6, Batch 500] loss: 0.038719848324544726
[Epoch 6, Batch 600] loss: 0.04032163317548111
[Epoch 6, Batch 700] loss: 0.04214491391205229
**STATS for Epoch 6** : 
Average training loss: 0.0025
Average validation loss: 0.0652
Validation Accuracy: 0.9803
Overfitting: 0.0626
Best model saved at epoch 6 with validation loss: 0.0652
[Epoch 7, Batch 100] loss: 0.03442670207004994
[Epoch 7, Batch 200] loss: 0.02862396170035936
[Epoch 7, Batch 300] loss: 0.03754613224475179
[Epoch 7, Batch 400] loss: 0.030681151326862163
[Epoch 7, Batch 500] loss: 0.029379112719907424
[Epoch 7, Batch 600] loss: 0.031835182839422486
[Epoch 7, Batch 700] loss: 0.03268725564470515
**STATS for Epoch 7** : 
Average training loss: 0.0017
Average validation loss: 0.0569
Validation Accuracy: 0.9836
Overfitting: 0.0552
Best model saved at epoch 7 with validation loss: 0.0569
[Epoch 8, Batch 100] loss: 0.030390229084878227
[Epoch 8, Batch 200] loss: 0.022789575128117575
[Epoch 8, Batch 300] loss: 0.025477342923986724
[Epoch 8, Batch 400] loss: 0.02638206473959144
[Epoch 8, Batch 500] loss: 0.025964637833531014
[Epoch 8, Batch 600] loss: 0.03401076758862473
[Epoch 8, Batch 700] loss: 0.03546179945464246
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0575
Validation Accuracy: 0.9824
Overfitting: 0.0556
[Epoch 9, Batch 100] loss: 0.023600145567324943
[Epoch 9, Batch 200] loss: 0.02564367022830993
[Epoch 9, Batch 300] loss: 0.022812949803774244
[Epoch 9, Batch 400] loss: 0.022408164459629915
[Epoch 9, Batch 500] loss: 0.025420957348251248
[Epoch 9, Batch 600] loss: 0.02385443425970152
[Epoch 9, Batch 700] loss: 0.02375700713484548
**STATS for Epoch 9** : 
Average training loss: 0.0019
Average validation loss: 0.0633
Validation Accuracy: 0.9811
Overfitting: 0.0614
[Epoch 10, Batch 100] loss: 0.016634030870336575
[Epoch 10, Batch 200] loss: 0.022856540109496563
[Epoch 10, Batch 300] loss: 0.01964433693821775
[Epoch 10, Batch 400] loss: 0.01709108793467749
[Epoch 10, Batch 500] loss: 0.01837607122870395
[Epoch 10, Batch 600] loss: 0.018772573340684176
[Epoch 10, Batch 700] loss: 0.022676549771858845
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0627
Validation Accuracy: 0.9827
Overfitting: 0.0616
[Epoch 11, Batch 100] loss: 0.0177325488103088
[Epoch 11, Batch 200] loss: 0.0156949516327586
[Epoch 11, Batch 300] loss: 0.016635991244984324
[Epoch 11, Batch 400] loss: 0.01844358275469858
[Epoch 11, Batch 500] loss: 0.019227116591937373
[Epoch 11, Batch 600] loss: 0.019399802552652546
[Epoch 11, Batch 700] loss: 0.01193737447494641
**STATS for Epoch 11** : 
Average training loss: 0.0015
Average validation loss: 0.0523
Validation Accuracy: 0.9853
Overfitting: 0.0508
Best model saved at epoch 11 with validation loss: 0.0523
[Epoch 12, Batch 100] loss: 0.017174185984767974
[Epoch 12, Batch 200] loss: 0.018193894929936505
[Epoch 12, Batch 300] loss: 0.015855212167080027
[Epoch 12, Batch 400] loss: 0.01668307193671353
[Epoch 12, Batch 500] loss: 0.015418494709010702
[Epoch 12, Batch 600] loss: 0.012967296707356581
[Epoch 12, Batch 700] loss: 0.013813225562626031
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0524
Validation Accuracy: 0.9858
Overfitting: 0.0513
[Epoch 13, Batch 100] loss: 0.009521797995985253
[Epoch 13, Batch 200] loss: 0.01410481123108184
[Epoch 13, Batch 300] loss: 0.014715793618524913
[Epoch 13, Batch 400] loss: 0.014229176926746731
[Epoch 13, Batch 500] loss: 0.014086876701330766
[Epoch 13, Batch 600] loss: 0.015901115463348107
[Epoch 13, Batch 700] loss: 0.011724451180780306
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0578
Validation Accuracy: 0.9858
Overfitting: 0.0569
[Epoch 14, Batch 100] loss: 0.010699735853704625
[Epoch 14, Batch 200] loss: 0.008933856187504717
[Epoch 14, Batch 300] loss: 0.010271398678305559
[Epoch 14, Batch 400] loss: 0.008469413494385663
[Epoch 14, Batch 500] loss: 0.010487126301886746
[Epoch 14, Batch 600] loss: 0.013660282954424475
[Epoch 14, Batch 700] loss: 0.015239504853379913
**STATS for Epoch 14** : 
Average training loss: 0.0011
Average validation loss: 0.0754
Validation Accuracy: 0.9805
Overfitting: 0.0743
[Epoch 15, Batch 100] loss: 0.010171843984135193
[Epoch 15, Batch 200] loss: 0.011797701275645523
[Epoch 15, Batch 300] loss: 0.008511943547055124
[Epoch 15, Batch 400] loss: 0.014395558797841658
[Epoch 15, Batch 500] loss: 0.01703765934667899
[Epoch 15, Batch 600] loss: 0.007548017922672443
[Epoch 15, Batch 700] loss: 0.009942702117696172
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0571
Validation Accuracy: 0.9853
Overfitting: 0.0561
[Epoch 16, Batch 100] loss: 0.007525471925109741
[Epoch 16, Batch 200] loss: 0.006881351380143314
[Epoch 16, Batch 300] loss: 0.006991890315894125
[Epoch 16, Batch 400] loss: 0.00938891792909999
[Epoch 16, Batch 500] loss: 0.010404819513896655
[Epoch 16, Batch 600] loss: 0.005986223657891969
[Epoch 16, Batch 700] loss: 0.009308896113871014
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0548
Validation Accuracy: 0.9854
Overfitting: 0.0542
[Epoch 17, Batch 100] loss: 0.012089375163050135
[Epoch 17, Batch 200] loss: 0.008037955298459565
[Epoch 17, Batch 300] loss: 0.00745651533427008
[Epoch 17, Batch 400] loss: 0.008397099506983068
[Epoch 17, Batch 500] loss: 0.006958116430141672
[Epoch 17, Batch 600] loss: 0.011896283697169566
[Epoch 17, Batch 700] loss: 0.011551730799983489
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0612
Validation Accuracy: 0.9850
Overfitting: 0.0606
[Epoch 18, Batch 100] loss: 0.008151204350579064
[Epoch 18, Batch 200] loss: 0.006727459331013961
[Epoch 18, Batch 300] loss: 0.009565776790404925
[Epoch 18, Batch 400] loss: 0.00426052066621196
[Epoch 18, Batch 500] loss: 0.006766245747203356
[Epoch 18, Batch 600] loss: 0.0067304271636385235
[Epoch 18, Batch 700] loss: 0.0026446808963919467
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0608
Validation Accuracy: 0.9856
Overfitting: 0.0605
[Epoch 19, Batch 100] loss: 0.0025016167837020476
[Epoch 19, Batch 200] loss: 0.002519761469884543
[Epoch 19, Batch 300] loss: 0.00319208703651384
[Epoch 19, Batch 400] loss: 0.00367845603479509
[Epoch 19, Batch 500] loss: 0.008049128427910546
[Epoch 19, Batch 600] loss: 0.004933594086178345
[Epoch 19, Batch 700] loss: 0.005686090998351574
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0640
Validation Accuracy: 0.9852
Overfitting: 0.0633
[Epoch 20, Batch 100] loss: 0.008359754282355424
[Epoch 20, Batch 200] loss: 0.004816848561167717
[Epoch 20, Batch 300] loss: 0.005277360245781892
[Epoch 20, Batch 400] loss: 0.0046208194924111014
[Epoch 20, Batch 500] loss: 0.00865189500526867
[Epoch 20, Batch 600] loss: 0.0030065807401115307
[Epoch 20, Batch 700] loss: 0.006705156947136856
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0653
Validation Accuracy: 0.9852
Overfitting: 0.0650
[Epoch 21, Batch 100] loss: 0.004776519328524955
[Epoch 21, Batch 200] loss: 0.0051716810140897
[Epoch 21, Batch 300] loss: 0.004828041672944892
[Epoch 21, Batch 400] loss: 0.00288020449308533
[Epoch 21, Batch 500] loss: 0.0034134064023055542
[Epoch 21, Batch 600] loss: 0.005238589648488414
[Epoch 21, Batch 700] loss: 0.003625239103403146
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0653
Validation Accuracy: 0.9862
Overfitting: 0.0652
[Epoch 22, Batch 100] loss: 0.0027393253026639286
[Epoch 22, Batch 200] loss: 0.0017326519420794283
[Epoch 22, Batch 300] loss: 0.0014765342212058386
[Epoch 22, Batch 400] loss: 0.0029158610016020246
[Epoch 22, Batch 500] loss: 0.002541465068479738
[Epoch 22, Batch 600] loss: 0.003982474316162552
[Epoch 22, Batch 700] loss: 0.001986122878479364
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0609
Validation Accuracy: 0.9863
Overfitting: 0.0608
[Epoch 23, Batch 100] loss: 0.0011637031275131449
[Epoch 23, Batch 200] loss: 0.001296264307693491
[Epoch 23, Batch 300] loss: 0.0017763335344807274
[Epoch 23, Batch 400] loss: 0.002218597009182304
[Epoch 23, Batch 500] loss: 0.0024467385703883337
[Epoch 23, Batch 600] loss: 0.001915350002566356
[Epoch 23, Batch 700] loss: 0.0030030622528829554
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0638
Validation Accuracy: 0.9866
Overfitting: 0.0637
[Epoch 24, Batch 100] loss: 0.0009864145104847922
[Epoch 24, Batch 200] loss: 0.002250511811889737
[Epoch 24, Batch 300] loss: 0.001513982423948619
[Epoch 24, Batch 400] loss: 0.004424725070339264
[Epoch 24, Batch 500] loss: 0.0013082478168871604
[Epoch 24, Batch 600] loss: 0.0025928680280640037
[Epoch 24, Batch 700] loss: 0.004759988888381485
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0605
Validation Accuracy: 0.9868
Overfitting: 0.0604
Fold 2 validation loss: 0.0605
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.290539448261261
[Epoch 1, Batch 200] loss: 1.6166470006108284
[Epoch 1, Batch 300] loss: 0.4228277833759785
[Epoch 1, Batch 400] loss: 0.2619065014272928
[Epoch 1, Batch 500] loss: 0.17973361779004335
[Epoch 1, Batch 600] loss: 0.19424550373107194
[Epoch 1, Batch 700] loss: 0.15071285270154477
**STATS for Epoch 1** : 
Average training loss: 0.0098
Average validation loss: 0.1247
Validation Accuracy: 0.9623
Overfitting: 0.1149
Best model saved at epoch 1 with validation loss: 0.1247
[Epoch 2, Batch 100] loss: 0.10921108135022223
[Epoch 2, Batch 200] loss: 0.11532872581854463
[Epoch 2, Batch 300] loss: 0.10360193369910121
[Epoch 2, Batch 400] loss: 0.096328788343817
[Epoch 2, Batch 500] loss: 0.10034604497253895
[Epoch 2, Batch 600] loss: 0.10178263417445123
[Epoch 2, Batch 700] loss: 0.08774454100057483
**STATS for Epoch 2** : 
Average training loss: 0.0074
Average validation loss: 0.0843
Validation Accuracy: 0.9732
Overfitting: 0.0768
Best model saved at epoch 2 with validation loss: 0.0843
[Epoch 3, Batch 100] loss: 0.07840098580345511
[Epoch 3, Batch 200] loss: 0.07966947603039444
[Epoch 3, Batch 300] loss: 0.07214512284845113
[Epoch 3, Batch 400] loss: 0.06768851892556996
[Epoch 3, Batch 500] loss: 0.06682126900879666
[Epoch 3, Batch 600] loss: 0.06881707296706736
[Epoch 3, Batch 700] loss: 0.07926378493197263
**STATS for Epoch 3** : 
Average training loss: 0.0038
Average validation loss: 0.0761
Validation Accuracy: 0.9758
Overfitting: 0.0722
Best model saved at epoch 3 with validation loss: 0.0761
[Epoch 4, Batch 100] loss: 0.052889745491556825
[Epoch 4, Batch 200] loss: 0.059046632584650066
[Epoch 4, Batch 300] loss: 0.058397781453095376
[Epoch 4, Batch 400] loss: 0.05981209698366001
[Epoch 4, Batch 500] loss: 0.05178424786077812
[Epoch 4, Batch 600] loss: 0.06715480056125671
[Epoch 4, Batch 700] loss: 0.05369810212170705
**STATS for Epoch 4** : 
Average training loss: 0.0036
Average validation loss: 0.0669
Validation Accuracy: 0.9794
Overfitting: 0.0633
Best model saved at epoch 4 with validation loss: 0.0669
[Epoch 5, Batch 100] loss: 0.03814948608865962
[Epoch 5, Batch 200] loss: 0.04955745271872729
[Epoch 5, Batch 300] loss: 0.04378944253781811
[Epoch 5, Batch 400] loss: 0.03815863163908943
[Epoch 5, Batch 500] loss: 0.050902563319541516
[Epoch 5, Batch 600] loss: 0.04540802869014442
[Epoch 5, Batch 700] loss: 0.057103906087577344
**STATS for Epoch 5** : 
Average training loss: 0.0024
Average validation loss: 0.0626
Validation Accuracy: 0.9795
Overfitting: 0.0602
Best model saved at epoch 5 with validation loss: 0.0626
[Epoch 6, Batch 100] loss: 0.0350393114448525
[Epoch 6, Batch 200] loss: 0.03592551282607019
[Epoch 6, Batch 300] loss: 0.03919674870092422
[Epoch 6, Batch 400] loss: 0.04050144967623055
[Epoch 6, Batch 500] loss: 0.03909057591401506
[Epoch 6, Batch 600] loss: 0.040144578616600486
[Epoch 6, Batch 700] loss: 0.043162338819820435
**STATS for Epoch 6** : 
Average training loss: 0.0031
Average validation loss: 0.0486
Validation Accuracy: 0.9848
Overfitting: 0.0455
Best model saved at epoch 6 with validation loss: 0.0486
[Epoch 7, Batch 100] loss: 0.027330305064097046
[Epoch 7, Batch 200] loss: 0.029964783585164696
[Epoch 7, Batch 300] loss: 0.03632561327132862
[Epoch 7, Batch 400] loss: 0.034580831157509234
[Epoch 7, Batch 500] loss: 0.038964952252572405
[Epoch 7, Batch 600] loss: 0.03349265042808838
[Epoch 7, Batch 700] loss: 0.035146973088849336
**STATS for Epoch 7** : 
Average training loss: 0.0026
Average validation loss: 0.0491
Validation Accuracy: 0.9844
Overfitting: 0.0466
[Epoch 8, Batch 100] loss: 0.026535363876027986
[Epoch 8, Batch 200] loss: 0.03199794780346565
[Epoch 8, Batch 300] loss: 0.02942064326023683
[Epoch 8, Batch 400] loss: 0.03483793899184093
[Epoch 8, Batch 500] loss: 0.0295856047043344
[Epoch 8, Batch 600] loss: 0.027003815707284957
[Epoch 8, Batch 700] loss: 0.02619491623539943
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0463
Validation Accuracy: 0.9866
Overfitting: 0.0443
Best model saved at epoch 8 with validation loss: 0.0463
[Epoch 9, Batch 100] loss: 0.017342958601657302
[Epoch 9, Batch 200] loss: 0.023603331384365447
[Epoch 9, Batch 300] loss: 0.02161472381965723
[Epoch 9, Batch 400] loss: 0.03228099795756861
[Epoch 9, Batch 500] loss: 0.024853525940852706
[Epoch 9, Batch 600] loss: 0.02212063810089603
[Epoch 9, Batch 700] loss: 0.0323545491398545
**STATS for Epoch 9** : 
Average training loss: 0.0019
Average validation loss: 0.0452
Validation Accuracy: 0.9862
Overfitting: 0.0433
Best model saved at epoch 9 with validation loss: 0.0452
[Epoch 10, Batch 100] loss: 0.021948133985279127
[Epoch 10, Batch 200] loss: 0.028255143631249667
[Epoch 10, Batch 300] loss: 0.02183294347312767
[Epoch 10, Batch 400] loss: 0.018357705048692878
[Epoch 10, Batch 500] loss: 0.02144793722894974
[Epoch 10, Batch 600] loss: 0.021098129756283016
[Epoch 10, Batch 700] loss: 0.023164485805318692
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0523
Validation Accuracy: 0.9857
Overfitting: 0.0511
[Epoch 11, Batch 100] loss: 0.012147806177235907
[Epoch 11, Batch 200] loss: 0.014475975199602545
[Epoch 11, Batch 300] loss: 0.020058606761449483
[Epoch 11, Batch 400] loss: 0.01912892165593803
[Epoch 11, Batch 500] loss: 0.019255320389056578
[Epoch 11, Batch 600] loss: 0.018352472092956304
[Epoch 11, Batch 700] loss: 0.021168709616176784
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0429
Validation Accuracy: 0.9879
Overfitting: 0.0417
Best model saved at epoch 11 with validation loss: 0.0429
[Epoch 12, Batch 100] loss: 0.013857653464656323
[Epoch 12, Batch 200] loss: 0.01337989780378848
[Epoch 12, Batch 300] loss: 0.014782573315605986
[Epoch 12, Batch 400] loss: 0.019138332644361072
[Epoch 12, Batch 500] loss: 0.013431516485870815
[Epoch 12, Batch 600] loss: 0.021698053790751147
[Epoch 12, Batch 700] loss: 0.02042409980262164
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0483
Validation Accuracy: 0.9861
Overfitting: 0.0473
[Epoch 13, Batch 100] loss: 0.009947315888421144
[Epoch 13, Batch 200] loss: 0.012971740270295413
[Epoch 13, Batch 300] loss: 0.017645644477161115
[Epoch 13, Batch 400] loss: 0.012544577927037608
[Epoch 13, Batch 500] loss: 0.019126042069110553
[Epoch 13, Batch 600] loss: 0.014271098419558257
[Epoch 13, Batch 700] loss: 0.01811183793921373
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0458
Validation Accuracy: 0.9874
Overfitting: 0.0444
[Epoch 14, Batch 100] loss: 0.012142339650017675
[Epoch 14, Batch 200] loss: 0.007667266899734387
[Epoch 14, Batch 300] loss: 0.012862421091704164
[Epoch 14, Batch 400] loss: 0.013563334091595608
[Epoch 14, Batch 500] loss: 0.012620025320502463
[Epoch 14, Batch 600] loss: 0.014066787283518352
[Epoch 14, Batch 700] loss: 0.016762578831257997
**STATS for Epoch 14** : 
Average training loss: 0.0011
Average validation loss: 0.0495
Validation Accuracy: 0.9878
Overfitting: 0.0484
[Epoch 15, Batch 100] loss: 0.012085692190594273
[Epoch 15, Batch 200] loss: 0.011380367997189752
[Epoch 15, Batch 300] loss: 0.009984336208726746
[Epoch 15, Batch 400] loss: 0.00814069098138134
[Epoch 15, Batch 500] loss: 0.009176851520023774
[Epoch 15, Batch 600] loss: 0.012038501667557284
[Epoch 15, Batch 700] loss: 0.011852679966832511
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0498
Validation Accuracy: 0.9879
Overfitting: 0.0490
[Epoch 16, Batch 100] loss: 0.007705374343240692
[Epoch 16, Batch 200] loss: 0.007662234868839732
[Epoch 16, Batch 300] loss: 0.012328778399714793
[Epoch 16, Batch 400] loss: 0.008471003820413898
[Epoch 16, Batch 500] loss: 0.008412075232845382
[Epoch 16, Batch 600] loss: 0.010687828098598402
[Epoch 16, Batch 700] loss: 0.0075524916295034925
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0467
Validation Accuracy: 0.9877
Overfitting: 0.0460
[Epoch 17, Batch 100] loss: 0.006933522454783087
[Epoch 17, Batch 200] loss: 0.00560925289093575
[Epoch 17, Batch 300] loss: 0.0062365182064968395
[Epoch 17, Batch 400] loss: 0.007697544581315014
[Epoch 17, Batch 500] loss: 0.006097384190734374
[Epoch 17, Batch 600] loss: 0.01061452355250367
[Epoch 17, Batch 700] loss: 0.011599380543702863
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0477
Validation Accuracy: 0.9878
Overfitting: 0.0469
[Epoch 18, Batch 100] loss: 0.006400787432794459
[Epoch 18, Batch 200] loss: 0.007271376609405706
[Epoch 18, Batch 300] loss: 0.005008714426512597
[Epoch 18, Batch 400] loss: 0.009355808430409524
[Epoch 18, Batch 500] loss: 0.008484539460914675
[Epoch 18, Batch 600] loss: 0.0060467733635596235
[Epoch 18, Batch 700] loss: 0.012837751739643863
**STATS for Epoch 18** : 
Average training loss: 0.0005
Average validation loss: 0.0526
Validation Accuracy: 0.9872
Overfitting: 0.0521
[Epoch 19, Batch 100] loss: 0.00806628730169905
[Epoch 19, Batch 200] loss: 0.00907036716802395
[Epoch 19, Batch 300] loss: 0.007281952228149749
[Epoch 19, Batch 400] loss: 0.00516116208755193
[Epoch 19, Batch 500] loss: 0.006110910720763058
[Epoch 19, Batch 600] loss: 0.008257871386813349
[Epoch 19, Batch 700] loss: 0.009010271917104547
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0482
Validation Accuracy: 0.9888
Overfitting: 0.0478
[Epoch 20, Batch 100] loss: 0.0034507387566736726
[Epoch 20, Batch 200] loss: 0.0028746287284229766
[Epoch 20, Batch 300] loss: 0.0044279767740408715
[Epoch 20, Batch 400] loss: 0.007228525666323549
[Epoch 20, Batch 500] loss: 0.010278101213407354
[Epoch 20, Batch 600] loss: 0.003172652662588007
[Epoch 20, Batch 700] loss: 0.008035298378454172
**STATS for Epoch 20** : 
Average training loss: 0.0007
Average validation loss: 0.0541
Validation Accuracy: 0.9872
Overfitting: 0.0534
[Epoch 21, Batch 100] loss: 0.0036464464594428135
[Epoch 21, Batch 200] loss: 0.002871042318865875
[Epoch 21, Batch 300] loss: 0.0029352126962476177
[Epoch 21, Batch 400] loss: 0.0049506472498978835
[Epoch 21, Batch 500] loss: 0.003654400129507849
[Epoch 21, Batch 600] loss: 0.005416887529136148
[Epoch 21, Batch 700] loss: 0.0050929494408956085
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0521
Validation Accuracy: 0.9880
Overfitting: 0.0517
[Epoch 22, Batch 100] loss: 0.0035268445507426805
[Epoch 22, Batch 200] loss: 0.0028907705194069423
[Epoch 22, Batch 300] loss: 0.003892624381396672
[Epoch 22, Batch 400] loss: 0.004676868321039365
[Epoch 22, Batch 500] loss: 0.003079805424949882
[Epoch 22, Batch 600] loss: 0.005071042238105292
[Epoch 22, Batch 700] loss: 0.00969884092834036
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0568
Validation Accuracy: 0.9871
Overfitting: 0.0564
[Epoch 23, Batch 100] loss: 0.0022809953174873954
[Epoch 23, Batch 200] loss: 0.0018940443341307401
[Epoch 23, Batch 300] loss: 0.005177000219973706
[Epoch 23, Batch 400] loss: 0.004191296293674896
[Epoch 23, Batch 500] loss: 0.003643790843680108
[Epoch 23, Batch 600] loss: 0.005732465706969379
[Epoch 23, Batch 700] loss: 0.006276191629476671
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0575
Validation Accuracy: 0.9878
Overfitting: 0.0568
[Epoch 24, Batch 100] loss: 0.004659243936639541
[Epoch 24, Batch 200] loss: 0.004315889622357644
[Epoch 24, Batch 300] loss: 0.005619530574640521
[Epoch 24, Batch 400] loss: 0.005430526416976136
[Epoch 24, Batch 500] loss: 0.00497890877926693
[Epoch 24, Batch 600] loss: 0.006493048395541336
[Epoch 24, Batch 700] loss: 0.005731195964854123
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0589
Validation Accuracy: 0.9884
Overfitting: 0.0587
Fold 3 validation loss: 0.0589
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.236294651031494
[Epoch 1, Batch 200] loss: 0.8192888724803925
[Epoch 1, Batch 300] loss: 0.28488597355782985
[Epoch 1, Batch 400] loss: 0.20357747122645378
[Epoch 1, Batch 500] loss: 0.18049129562452434
[Epoch 1, Batch 600] loss: 0.12756542587652803
[Epoch 1, Batch 700] loss: 0.13247792810201645
**STATS for Epoch 1** : 
Average training loss: 0.0089
Average validation loss: 0.1074
Validation Accuracy: 0.9669
Overfitting: 0.0985
Best model saved at epoch 1 with validation loss: 0.1074
[Epoch 2, Batch 100] loss: 0.09632475271821023
[Epoch 2, Batch 200] loss: 0.11611206324771046
[Epoch 2, Batch 300] loss: 0.09214143013581634
[Epoch 2, Batch 400] loss: 0.08466354621574283
[Epoch 2, Batch 500] loss: 0.08290950659662485
[Epoch 2, Batch 600] loss: 0.08096607529558242
[Epoch 2, Batch 700] loss: 0.08609633390791714
**STATS for Epoch 2** : 
Average training loss: 0.0055
Average validation loss: 0.0680
Validation Accuracy: 0.9793
Overfitting: 0.0625
Best model saved at epoch 2 with validation loss: 0.0680
[Epoch 3, Batch 100] loss: 0.06725779380649329
[Epoch 3, Batch 200] loss: 0.06487939598038793
[Epoch 3, Batch 300] loss: 0.0658441293053329
[Epoch 3, Batch 400] loss: 0.07361743823625147
[Epoch 3, Batch 500] loss: 0.06737834060564638
[Epoch 3, Batch 600] loss: 0.06634631088702009
[Epoch 3, Batch 700] loss: 0.05997492389753461
**STATS for Epoch 3** : 
Average training loss: 0.0035
Average validation loss: 0.0591
Validation Accuracy: 0.9813
Overfitting: 0.0555
Best model saved at epoch 3 with validation loss: 0.0591
[Epoch 4, Batch 100] loss: 0.05479981299489736
[Epoch 4, Batch 200] loss: 0.04989993213210255
[Epoch 4, Batch 300] loss: 0.047524550082162026
[Epoch 4, Batch 400] loss: 0.04954233768163249
[Epoch 4, Batch 500] loss: 0.04495238950010389
[Epoch 4, Batch 600] loss: 0.05688745289575309
[Epoch 4, Batch 700] loss: 0.054094337904825804
**STATS for Epoch 4** : 
Average training loss: 0.0035
Average validation loss: 0.0512
Validation Accuracy: 0.9839
Overfitting: 0.0478
Best model saved at epoch 4 with validation loss: 0.0512
[Epoch 5, Batch 100] loss: 0.04573549478780478
[Epoch 5, Batch 200] loss: 0.043994379609357565
[Epoch 5, Batch 300] loss: 0.05083333827089518
[Epoch 5, Batch 400] loss: 0.037364553043153136
[Epoch 5, Batch 500] loss: 0.03725478596403264
[Epoch 5, Batch 600] loss: 0.03886681910022162
[Epoch 5, Batch 700] loss: 0.03982841388555244
**STATS for Epoch 5** : 
Average training loss: 0.0030
Average validation loss: 0.0547
Validation Accuracy: 0.9823
Overfitting: 0.0517
[Epoch 6, Batch 100] loss: 0.03508192361681722
[Epoch 6, Batch 200] loss: 0.036667888490483164
[Epoch 6, Batch 300] loss: 0.03375912883784622
[Epoch 6, Batch 400] loss: 0.03629433211288415
[Epoch 6, Batch 500] loss: 0.03388758448767476
[Epoch 6, Batch 600] loss: 0.034128513993346134
[Epoch 6, Batch 700] loss: 0.033568466063588855
**STATS for Epoch 6** : 
Average training loss: 0.0026
Average validation loss: 0.0435
Validation Accuracy: 0.9862
Overfitting: 0.0409
Best model saved at epoch 6 with validation loss: 0.0435
[Epoch 7, Batch 100] loss: 0.02983794052444864
[Epoch 7, Batch 200] loss: 0.03058421693742275
[Epoch 7, Batch 300] loss: 0.03409387308231089
[Epoch 7, Batch 400] loss: 0.03142636754724663
[Epoch 7, Batch 500] loss: 0.02890697464114055
[Epoch 7, Batch 600] loss: 0.026679803651059045
[Epoch 7, Batch 700] loss: 0.031786921895109115
**STATS for Epoch 7** : 
Average training loss: 0.0021
Average validation loss: 0.0431
Validation Accuracy: 0.9868
Overfitting: 0.0411
Best model saved at epoch 7 with validation loss: 0.0431
[Epoch 8, Batch 100] loss: 0.025070810780161993
[Epoch 8, Batch 200] loss: 0.033874974371865395
[Epoch 8, Batch 300] loss: 0.02303055501077324
[Epoch 8, Batch 400] loss: 0.021951859121909365
[Epoch 8, Batch 500] loss: 0.027553131612949075
[Epoch 8, Batch 600] loss: 0.027492403862415814
[Epoch 8, Batch 700] loss: 0.021196832659188657
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0423
Validation Accuracy: 0.9863
Overfitting: 0.0403
Best model saved at epoch 8 with validation loss: 0.0423
[Epoch 9, Batch 100] loss: 0.021187994873616844
[Epoch 9, Batch 200] loss: 0.02330458923097467
[Epoch 9, Batch 300] loss: 0.025269692695874254
[Epoch 9, Batch 400] loss: 0.024160365160787477
[Epoch 9, Batch 500] loss: 0.02045912619214505
[Epoch 9, Batch 600] loss: 0.02694412494369317
[Epoch 9, Batch 700] loss: 0.02098882968246471
**STATS for Epoch 9** : 
Average training loss: 0.0015
Average validation loss: 0.0380
Validation Accuracy: 0.9874
Overfitting: 0.0365
Best model saved at epoch 9 with validation loss: 0.0380
[Epoch 10, Batch 100] loss: 0.01911609634262277
[Epoch 10, Batch 200] loss: 0.015323933938634581
[Epoch 10, Batch 300] loss: 0.024331639055453706
[Epoch 10, Batch 400] loss: 0.02088152578275185
[Epoch 10, Batch 500] loss: 0.02319777955650352
[Epoch 10, Batch 600] loss: 0.017416308749525343
[Epoch 10, Batch 700] loss: 0.019877619218605105
**STATS for Epoch 10** : 
Average training loss: 0.0010
Average validation loss: 0.0373
Validation Accuracy: 0.9886
Overfitting: 0.0363
Best model saved at epoch 10 with validation loss: 0.0373
[Epoch 11, Batch 100] loss: 0.01717080329253804
[Epoch 11, Batch 200] loss: 0.01495737870776793
[Epoch 11, Batch 300] loss: 0.014976708375033922
[Epoch 11, Batch 400] loss: 0.015068854311539325
[Epoch 11, Batch 500] loss: 0.021950566744053504
[Epoch 11, Batch 600] loss: 0.015877926418179412
[Epoch 11, Batch 700] loss: 0.024945063080231193
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0410
Validation Accuracy: 0.9872
Overfitting: 0.0402
[Epoch 12, Batch 100] loss: 0.00857613508022041
[Epoch 12, Batch 200] loss: 0.01661063976076548
[Epoch 12, Batch 300] loss: 0.01509890206012642
[Epoch 12, Batch 400] loss: 0.02122255856724223
[Epoch 12, Batch 500] loss: 0.019401722615584732
[Epoch 12, Batch 600] loss: 0.01805987185711274
[Epoch 12, Batch 700] loss: 0.020636208563810213
**STATS for Epoch 12** : 
Average training loss: 0.0011
Average validation loss: 0.0381
Validation Accuracy: 0.9889
Overfitting: 0.0370
[Epoch 13, Batch 100] loss: 0.010422600030287867
[Epoch 13, Batch 200] loss: 0.011470258350891526
[Epoch 13, Batch 300] loss: 0.01511711850980646
[Epoch 13, Batch 400] loss: 0.014238788610673509
[Epoch 13, Batch 500] loss: 0.020590421412925934
[Epoch 13, Batch 600] loss: 0.01319285185832996
[Epoch 13, Batch 700] loss: 0.01297918335068971
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0411
Validation Accuracy: 0.9861
Overfitting: 0.0402
[Epoch 14, Batch 100] loss: 0.00900969749687647
[Epoch 14, Batch 200] loss: 0.009119584963118542
[Epoch 14, Batch 300] loss: 0.013354014179785736
[Epoch 14, Batch 400] loss: 0.009924793692553066
[Epoch 14, Batch 500] loss: 0.010720559064575355
[Epoch 14, Batch 600] loss: 0.009078144980376237
[Epoch 14, Batch 700] loss: 0.014868072817043866
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0410
Validation Accuracy: 0.9878
Overfitting: 0.0402
[Epoch 15, Batch 100] loss: 0.01033446888846811
[Epoch 15, Batch 200] loss: 0.010430313752804067
[Epoch 15, Batch 300] loss: 0.012570699801362934
[Epoch 15, Batch 400] loss: 0.008803572830074699
[Epoch 15, Batch 500] loss: 0.009743346282812126
[Epoch 15, Batch 600] loss: 0.012447708312174654
[Epoch 15, Batch 700] loss: 0.008711392105760751
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0441
Validation Accuracy: 0.9872
Overfitting: 0.0431
[Epoch 16, Batch 100] loss: 0.007248434699431527
[Epoch 16, Batch 200] loss: 0.005099363394110696
[Epoch 16, Batch 300] loss: 0.00690703559324902
[Epoch 16, Batch 400] loss: 0.00975147570570698
[Epoch 16, Batch 500] loss: 0.008325389813617221
[Epoch 16, Batch 600] loss: 0.009041504599990731
[Epoch 16, Batch 700] loss: 0.014039274295082577
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0396
Validation Accuracy: 0.9888
Overfitting: 0.0391
[Epoch 17, Batch 100] loss: 0.008839455144698149
[Epoch 17, Batch 200] loss: 0.00611300755670527
[Epoch 17, Batch 300] loss: 0.0059335006488254296
[Epoch 17, Batch 400] loss: 0.011383106512803352
[Epoch 17, Batch 500] loss: 0.008480622188435517
[Epoch 17, Batch 600] loss: 0.007592795060918434
[Epoch 17, Batch 700] loss: 0.009073132215598889
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0431
Validation Accuracy: 0.9885
Overfitting: 0.0426
[Epoch 18, Batch 100] loss: 0.006617530286384863
[Epoch 18, Batch 200] loss: 0.0072816541198153575
[Epoch 18, Batch 300] loss: 0.009266953580008704
[Epoch 18, Batch 400] loss: 0.005872964783593488
[Epoch 18, Batch 500] loss: 0.0071880276744559525
[Epoch 18, Batch 600] loss: 0.009036277595077991
[Epoch 18, Batch 700] loss: 0.005107606793062587
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0522
Validation Accuracy: 0.9868
Overfitting: 0.0514
[Epoch 19, Batch 100] loss: 0.008464990577849676
[Epoch 19, Batch 200] loss: 0.004633122363138682
[Epoch 19, Batch 300] loss: 0.004222077109479869
[Epoch 19, Batch 400] loss: 0.003542340997883002
[Epoch 19, Batch 500] loss: 0.0030301208789023804
[Epoch 19, Batch 600] loss: 0.004974255765373528
[Epoch 19, Batch 700] loss: 0.008707068629501009
**STATS for Epoch 19** : 
Average training loss: 0.0012
Average validation loss: 0.0401
Validation Accuracy: 0.9897
Overfitting: 0.0390
[Epoch 20, Batch 100] loss: 0.007885906114970566
[Epoch 20, Batch 200] loss: 0.005691721589628287
[Epoch 20, Batch 300] loss: 0.010794429303787182
[Epoch 20, Batch 400] loss: 0.004979340007739665
[Epoch 20, Batch 500] loss: 0.002465532104943122
[Epoch 20, Batch 600] loss: 0.014363395893742564
[Epoch 20, Batch 700] loss: 0.0050562078071016
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0372
Validation Accuracy: 0.9892
Overfitting: 0.0370
Best model saved at epoch 20 with validation loss: 0.0372
[Epoch 21, Batch 100] loss: 0.0027402477848409035
[Epoch 21, Batch 200] loss: 0.0058585860380298985
[Epoch 21, Batch 300] loss: 0.004516642530652462
[Epoch 21, Batch 400] loss: 0.007036609747683542
[Epoch 21, Batch 500] loss: 0.005125174351151145
[Epoch 21, Batch 600] loss: 0.006966400597630127
[Epoch 21, Batch 700] loss: 0.0039355604357479024
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0420
Validation Accuracy: 0.9895
Overfitting: 0.0417
[Epoch 22, Batch 100] loss: 0.002249045184607894
[Epoch 22, Batch 200] loss: 0.003249531932033278
[Epoch 22, Batch 300] loss: 0.0021530745609015865
[Epoch 22, Batch 400] loss: 0.007869310935802787
[Epoch 22, Batch 500] loss: 0.0019741593683647806
[Epoch 22, Batch 600] loss: 0.0041837304696946374
[Epoch 22, Batch 700] loss: 0.0044632936455673185
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0447
Validation Accuracy: 0.9880
Overfitting: 0.0443
[Epoch 23, Batch 100] loss: 0.0026097806191683046
[Epoch 23, Batch 200] loss: 0.002302134715819193
[Epoch 23, Batch 300] loss: 0.004336652459751349
[Epoch 23, Batch 400] loss: 0.0023681157754072047
[Epoch 23, Batch 500] loss: 0.003253754077356916
[Epoch 23, Batch 600] loss: 0.004060806542092905
[Epoch 23, Batch 700] loss: 0.004339013719982176
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0445
Validation Accuracy: 0.9891
Overfitting: 0.0441
[Epoch 24, Batch 100] loss: 0.0035586780051744425
[Epoch 24, Batch 200] loss: 0.005438020047049577
[Epoch 24, Batch 300] loss: 0.0011462400926575355
[Epoch 24, Batch 400] loss: 0.002792045345995575
[Epoch 24, Batch 500] loss: 0.003928027332412967
[Epoch 24, Batch 600] loss: 0.0028964515855477656
[Epoch 24, Batch 700] loss: 0.0054030294904487165
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0412
Validation Accuracy: 0.9898
Overfitting: 0.0411
Fold 4 validation loss: 0.0412
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.22207422375679
[Epoch 1, Batch 200] loss: 0.7648898549377918
[Epoch 1, Batch 300] loss: 0.3583213910460472
[Epoch 1, Batch 400] loss: 0.26319768130779264
[Epoch 1, Batch 500] loss: 0.2126619276404381
[Epoch 1, Batch 600] loss: 0.16461770389229058
[Epoch 1, Batch 700] loss: 0.14981586560606958
**STATS for Epoch 1** : 
Average training loss: 0.0103
Average validation loss: 0.1437
Validation Accuracy: 0.9552
Overfitting: 0.1334
Best model saved at epoch 1 with validation loss: 0.1437
[Epoch 2, Batch 100] loss: 0.13816245567053556
[Epoch 2, Batch 200] loss: 0.12027874316088855
[Epoch 2, Batch 300] loss: 0.11592163566499948
[Epoch 2, Batch 400] loss: 0.10191842230036854
[Epoch 2, Batch 500] loss: 0.10522056221961976
[Epoch 2, Batch 600] loss: 0.08765258853323758
[Epoch 2, Batch 700] loss: 0.09059751158580184
**STATS for Epoch 2** : 
Average training loss: 0.0061
Average validation loss: 0.0970
Validation Accuracy: 0.9710
Overfitting: 0.0909
Best model saved at epoch 2 with validation loss: 0.0970
[Epoch 3, Batch 100] loss: 0.0770783568918705
[Epoch 3, Batch 200] loss: 0.0903382646664977
[Epoch 3, Batch 300] loss: 0.081010336978361
[Epoch 3, Batch 400] loss: 0.06274983441922814
[Epoch 3, Batch 500] loss: 0.07965796614531427
[Epoch 3, Batch 600] loss: 0.06805262300185859
[Epoch 3, Batch 700] loss: 0.07201250373385847
**STATS for Epoch 3** : 
Average training loss: 0.0047
Average validation loss: 0.0701
Validation Accuracy: 0.9781
Overfitting: 0.0654
Best model saved at epoch 3 with validation loss: 0.0701
[Epoch 4, Batch 100] loss: 0.05925069522112608
[Epoch 4, Batch 200] loss: 0.06101702393498272
[Epoch 4, Batch 300] loss: 0.05266472651623189
[Epoch 4, Batch 400] loss: 0.0619247735303361
[Epoch 4, Batch 500] loss: 0.06168243570486084
[Epoch 4, Batch 600] loss: 0.0500989041198045
[Epoch 4, Batch 700] loss: 0.05374382954556495
**STATS for Epoch 4** : 
Average training loss: 0.0045
Average validation loss: 0.0605
Validation Accuracy: 0.9809
Overfitting: 0.0560
Best model saved at epoch 4 with validation loss: 0.0605
[Epoch 5, Batch 100] loss: 0.049690723700914534
[Epoch 5, Batch 200] loss: 0.04524797227699309
[Epoch 5, Batch 300] loss: 0.04197996124159545
[Epoch 5, Batch 400] loss: 0.046961049805395304
[Epoch 5, Batch 500] loss: 0.04947256783489138
[Epoch 5, Batch 600] loss: 0.0514732227101922
[Epoch 5, Batch 700] loss: 0.04395838058902882
**STATS for Epoch 5** : 
Average training loss: 0.0036
Average validation loss: 0.0579
Validation Accuracy: 0.9814
Overfitting: 0.0543
Best model saved at epoch 5 with validation loss: 0.0579
[Epoch 6, Batch 100] loss: 0.03891674718586728
[Epoch 6, Batch 200] loss: 0.039404823736986144
[Epoch 6, Batch 300] loss: 0.04727599834324792
[Epoch 6, Batch 400] loss: 0.037448006097693
[Epoch 6, Batch 500] loss: 0.044104966598097234
[Epoch 6, Batch 600] loss: 0.03535799476550892
[Epoch 6, Batch 700] loss: 0.04060546787804924
**STATS for Epoch 6** : 
Average training loss: 0.0024
Average validation loss: 0.0599
Validation Accuracy: 0.9803
Overfitting: 0.0575
[Epoch 7, Batch 100] loss: 0.0421037414658349
[Epoch 7, Batch 200] loss: 0.038094330206513406
[Epoch 7, Batch 300] loss: 0.030369683306780644
[Epoch 7, Batch 400] loss: 0.03283017477951944
[Epoch 7, Batch 500] loss: 0.031063527242513374
[Epoch 7, Batch 600] loss: 0.036509164213202897
[Epoch 7, Batch 700] loss: 0.03932941742823459
**STATS for Epoch 7** : 
Average training loss: 0.0018
Average validation loss: 0.0475
Validation Accuracy: 0.9860
Overfitting: 0.0457
Best model saved at epoch 7 with validation loss: 0.0475
[Epoch 8, Batch 100] loss: 0.03143912442494184
[Epoch 8, Batch 200] loss: 0.01896528258221224
[Epoch 8, Batch 300] loss: 0.035121591858332975
[Epoch 8, Batch 400] loss: 0.030216845811810344
[Epoch 8, Batch 500] loss: 0.028017976733972317
[Epoch 8, Batch 600] loss: 0.034476195599418134
[Epoch 8, Batch 700] loss: 0.035000962549238464
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0453
Validation Accuracy: 0.9867
Overfitting: 0.0429
Best model saved at epoch 8 with validation loss: 0.0453
[Epoch 9, Batch 100] loss: 0.024539673044346275
[Epoch 9, Batch 200] loss: 0.02780318278237246
[Epoch 9, Batch 300] loss: 0.028644141572294758
[Epoch 9, Batch 400] loss: 0.021093156588613056
[Epoch 9, Batch 500] loss: 0.02897850130801089
[Epoch 9, Batch 600] loss: 0.02394494201609632
[Epoch 9, Batch 700] loss: 0.03107690262811957
**STATS for Epoch 9** : 
Average training loss: 0.0020
Average validation loss: 0.0414
Validation Accuracy: 0.9867
Overfitting: 0.0395
Best model saved at epoch 9 with validation loss: 0.0414
[Epoch 10, Batch 100] loss: 0.019944093312951737
[Epoch 10, Batch 200] loss: 0.02355311676627025
[Epoch 10, Batch 300] loss: 0.018359842108038718
[Epoch 10, Batch 400] loss: 0.014470674653130117
[Epoch 10, Batch 500] loss: 0.02611093469779007
[Epoch 10, Batch 600] loss: 0.026908023438300007
[Epoch 10, Batch 700] loss: 0.03175629125151318
**STATS for Epoch 10** : 
Average training loss: 0.0021
Average validation loss: 0.0443
Validation Accuracy: 0.9861
Overfitting: 0.0422
[Epoch 11, Batch 100] loss: 0.018728300731163473
[Epoch 11, Batch 200] loss: 0.019073314698180185
[Epoch 11, Batch 300] loss: 0.02568030614289455
[Epoch 11, Batch 400] loss: 0.01777805156772956
[Epoch 11, Batch 500] loss: 0.02134481110231718
[Epoch 11, Batch 600] loss: 0.015745316535758322
[Epoch 11, Batch 700] loss: 0.023414226524037077
**STATS for Epoch 11** : 
Average training loss: 0.0014
Average validation loss: 0.0487
Validation Accuracy: 0.9848
Overfitting: 0.0473
[Epoch 12, Batch 100] loss: 0.014803013942728285
[Epoch 12, Batch 200] loss: 0.01856469252728857
[Epoch 12, Batch 300] loss: 0.01129103448591195
[Epoch 12, Batch 400] loss: 0.022326212194748223
[Epoch 12, Batch 500] loss: 0.017086584042408502
[Epoch 12, Batch 600] loss: 0.019647884556325153
[Epoch 12, Batch 700] loss: 0.017787076765089296
**STATS for Epoch 12** : 
Average training loss: 0.0015
Average validation loss: 0.0470
Validation Accuracy: 0.9862
Overfitting: 0.0456
[Epoch 13, Batch 100] loss: 0.018878853695350698
[Epoch 13, Batch 200] loss: 0.012339304861961864
[Epoch 13, Batch 300] loss: 0.01968314056721283
[Epoch 13, Batch 400] loss: 0.017231862056141835
[Epoch 13, Batch 500] loss: 0.01892065447580535
[Epoch 13, Batch 600] loss: 0.014743313561775722
[Epoch 13, Batch 700] loss: 0.0148931245849235
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0470
Validation Accuracy: 0.9853
Overfitting: 0.0459
[Epoch 14, Batch 100] loss: 0.012210548135917633
[Epoch 14, Batch 200] loss: 0.01577716471510939
[Epoch 14, Batch 300] loss: 0.012655248449882493
[Epoch 14, Batch 400] loss: 0.011022384754905943
[Epoch 14, Batch 500] loss: 0.009947888431051979
[Epoch 14, Batch 600] loss: 0.015869118459377204
[Epoch 14, Batch 700] loss: 0.018895266229083062
**STATS for Epoch 14** : 
Average training loss: 0.0010
Average validation loss: 0.0448
Validation Accuracy: 0.9871
Overfitting: 0.0438
[Epoch 15, Batch 100] loss: 0.014285785864049104
[Epoch 15, Batch 200] loss: 0.009658705636393278
[Epoch 15, Batch 300] loss: 0.013476734562718775
[Epoch 15, Batch 400] loss: 0.008359102474205429
[Epoch 15, Batch 500] loss: 0.010213498097728006
[Epoch 15, Batch 600] loss: 0.008497719824372325
[Epoch 15, Batch 700] loss: 0.0166867042236845
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0446
Validation Accuracy: 0.9872
Overfitting: 0.0440
[Epoch 16, Batch 100] loss: 0.006296667695132783
[Epoch 16, Batch 200] loss: 0.007897157472398249
[Epoch 16, Batch 300] loss: 0.006726342877518618
[Epoch 16, Batch 400] loss: 0.006379608038478182
[Epoch 16, Batch 500] loss: 0.010972780702941236
[Epoch 16, Batch 600] loss: 0.012078652516938746
[Epoch 16, Batch 700] loss: 0.013493754154187626
**STATS for Epoch 16** : 
Average training loss: 0.0016
Average validation loss: 0.0463
Validation Accuracy: 0.9868
Overfitting: 0.0446
[Epoch 17, Batch 100] loss: 0.0061055401040357535
[Epoch 17, Batch 200] loss: 0.007495636716776062
[Epoch 17, Batch 300] loss: 0.00811432487469574
[Epoch 17, Batch 400] loss: 0.0076464003715955185
[Epoch 17, Batch 500] loss: 0.009429207305729506
[Epoch 17, Batch 600] loss: 0.008712954439688473
[Epoch 17, Batch 700] loss: 0.013074895659810864
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0465
Validation Accuracy: 0.9880
Overfitting: 0.0457
[Epoch 18, Batch 100] loss: 0.007468789868580643
[Epoch 18, Batch 200] loss: 0.009380095240485388
[Epoch 18, Batch 300] loss: 0.005395216952310875
[Epoch 18, Batch 400] loss: 0.00854527799965581
[Epoch 18, Batch 500] loss: 0.006740271344970097
[Epoch 18, Batch 600] loss: 0.005591213971056277
[Epoch 18, Batch 700] loss: 0.012016154493121576
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0516
Validation Accuracy: 0.9872
Overfitting: 0.0508
[Epoch 19, Batch 100] loss: 0.005629124726619921
[Epoch 19, Batch 200] loss: 0.0058279377446888245
[Epoch 19, Batch 300] loss: 0.008751512391536381
[Epoch 19, Batch 400] loss: 0.005457452094342443
[Epoch 19, Batch 500] loss: 0.009028960143696167
[Epoch 19, Batch 600] loss: 0.008020945624630259
[Epoch 19, Batch 700] loss: 0.0051822925986198245
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0466
Validation Accuracy: 0.9880
Overfitting: 0.0460
[Epoch 20, Batch 100] loss: 0.004737599026975658
[Epoch 20, Batch 200] loss: 0.006332996019264101
[Epoch 20, Batch 300] loss: 0.006239477274357341
[Epoch 20, Batch 400] loss: 0.010359276492927165
[Epoch 20, Batch 500] loss: 0.006614918215600483
[Epoch 20, Batch 600] loss: 0.008940820685747895
[Epoch 20, Batch 700] loss: 0.005905271779338364
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0496
Validation Accuracy: 0.9875
Overfitting: 0.0491
[Epoch 21, Batch 100] loss: 0.006124386657611467
[Epoch 21, Batch 200] loss: 0.007623573693417711
[Epoch 21, Batch 300] loss: 0.005763540481966629
[Epoch 21, Batch 400] loss: 0.008618549112434266
[Epoch 21, Batch 500] loss: 0.003259526857291348
[Epoch 21, Batch 600] loss: 0.007132821787063221
[Epoch 21, Batch 700] loss: 0.005321551870947587
**STATS for Epoch 21** : 
Average training loss: 0.0006
Average validation loss: 0.0480
Validation Accuracy: 0.9881
Overfitting: 0.0474
[Epoch 22, Batch 100] loss: 0.006192361428729782
[Epoch 22, Batch 200] loss: 0.0036040132049856765
[Epoch 22, Batch 300] loss: 0.005476339052229377
[Epoch 22, Batch 400] loss: 0.004370330238834867
[Epoch 22, Batch 500] loss: 0.005100015368298045
[Epoch 22, Batch 600] loss: 0.006618268417059881
[Epoch 22, Batch 700] loss: 0.005629781580355484
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0504
Validation Accuracy: 0.9874
Overfitting: 0.0500
[Epoch 23, Batch 100] loss: 0.0032805383451704985
[Epoch 23, Batch 200] loss: 0.0068042801912270075
[Epoch 23, Batch 300] loss: 0.006475614917217171
[Epoch 23, Batch 400] loss: 0.0038097685686170734
[Epoch 23, Batch 500] loss: 0.005002278513256897
[Epoch 23, Batch 600] loss: 0.006662308777958969
[Epoch 23, Batch 700] loss: 0.002822956847739988
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0506
Validation Accuracy: 0.9880
Overfitting: 0.0505
[Epoch 24, Batch 100] loss: 0.002661630793927543
[Epoch 24, Batch 200] loss: 0.002566969636345675
[Epoch 24, Batch 300] loss: 0.003441793918300391
[Epoch 24, Batch 400] loss: 0.0041899859595650926
[Epoch 24, Batch 500] loss: 0.0051967787238390885
[Epoch 24, Batch 600] loss: 0.006650421936719795
[Epoch 24, Batch 700] loss: 0.009618732523158542
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0535
Validation Accuracy: 0.9882
Overfitting: 0.0532
Fold 5 validation loss: 0.0535
Mean validation loss across all folds for Trial 18 is 0.0545 with trial config:  l1: 256, l2: 64, lr: 0.0038216021085446107, batch_size: 64
[I 2024-12-10 08:25:12,228] Trial 17 finished with value: 0.05452604108871423 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0038216021085446107, 'batch_size': 64}. Best is trial 16 with value: 0.04722271221232811.

Selected Hyperparameters for Trial 19:
  l1: 256, l2: 64, lr: 0.0021003588557559176, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2660319924354555
[Epoch 1, Batch 200] loss: 1.6263598388433456
[Epoch 1, Batch 300] loss: 0.6680796934664249
[Epoch 1, Batch 400] loss: 0.4822086852788925
[Epoch 1, Batch 500] loss: 0.37412986874580384
[Epoch 1, Batch 600] loss: 0.3111449171602726
[Epoch 1, Batch 700] loss: 0.27197601929306986
[Epoch 1, Batch 800] loss: 0.249476996101439
[Epoch 1, Batch 900] loss: 0.2124506675451994
[Epoch 1, Batch 1000] loss: 0.1914294922724366
[Epoch 1, Batch 1100] loss: 0.1550208380818367
[Epoch 1, Batch 1200] loss: 0.1721214196458459
[Epoch 1, Batch 1300] loss: 0.14310424318537115
[Epoch 1, Batch 1400] loss: 0.15034397366456687
[Epoch 1, Batch 1500] loss: 0.12492297861725092
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1274
Validation Accuracy: 0.9587
Overfitting: 0.1274
Best model saved at epoch 1 with validation loss: 0.1274
[Epoch 2, Batch 100] loss: 0.12123000650200993
[Epoch 2, Batch 200] loss: 0.1087920988863334
[Epoch 2, Batch 300] loss: 0.12265884447842837
[Epoch 2, Batch 400] loss: 0.09959830603562296
[Epoch 2, Batch 500] loss: 0.09508337416918948
[Epoch 2, Batch 600] loss: 0.09549217275809496
[Epoch 2, Batch 700] loss: 0.09581845249747857
[Epoch 2, Batch 800] loss: 0.08576940973754972
[Epoch 2, Batch 900] loss: 0.08924089293461293
[Epoch 2, Batch 1000] loss: 0.0880684719781857
[Epoch 2, Batch 1100] loss: 0.08708963653538376
[Epoch 2, Batch 1200] loss: 0.07918047540588305
[Epoch 2, Batch 1300] loss: 0.09460233956575394
[Epoch 2, Batch 1400] loss: 0.07545198027044535
[Epoch 2, Batch 1500] loss: 0.09082165169529617
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0717
Validation Accuracy: 0.9775
Overfitting: 0.0717
Best model saved at epoch 2 with validation loss: 0.0717
[Epoch 3, Batch 100] loss: 0.07695885961642489
[Epoch 3, Batch 200] loss: 0.10021091314032674
[Epoch 3, Batch 300] loss: 0.05583388927625492
[Epoch 3, Batch 400] loss: 0.07012680182699114
[Epoch 3, Batch 500] loss: 0.06420943266130053
[Epoch 3, Batch 600] loss: 0.06369004199746996
[Epoch 3, Batch 700] loss: 0.05634999099420383
[Epoch 3, Batch 800] loss: 0.0558506754564587
[Epoch 3, Batch 900] loss: 0.06326432957779617
[Epoch 3, Batch 1000] loss: 0.05987651003059
[Epoch 3, Batch 1100] loss: 0.05550275495741516
[Epoch 3, Batch 1200] loss: 0.0695664745918475
[Epoch 3, Batch 1300] loss: 0.07166480591055006
[Epoch 3, Batch 1400] loss: 0.0603390789416153
[Epoch 3, Batch 1500] loss: 0.0584439940424636
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9829
Overfitting: 0.0519
Best model saved at epoch 3 with validation loss: 0.0519
[Epoch 4, Batch 100] loss: 0.052477207735646514
[Epoch 4, Batch 200] loss: 0.05405678816139698
[Epoch 4, Batch 300] loss: 0.05874909557402134
[Epoch 4, Batch 400] loss: 0.0496336418390274
[Epoch 4, Batch 500] loss: 0.05110955230891705
[Epoch 4, Batch 600] loss: 0.06700507546891458
[Epoch 4, Batch 700] loss: 0.05612621236476116
[Epoch 4, Batch 800] loss: 0.04412876817630604
[Epoch 4, Batch 900] loss: 0.04349808627797756
[Epoch 4, Batch 1000] loss: 0.05018816872383468
[Epoch 4, Batch 1100] loss: 0.0436453689209884
[Epoch 4, Batch 1200] loss: 0.04345063283108175
[Epoch 4, Batch 1300] loss: 0.04437268630019389
[Epoch 4, Batch 1400] loss: 0.049256028066156435
[Epoch 4, Batch 1500] loss: 0.042093360387953
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9834
Overfitting: 0.0499
Best model saved at epoch 4 with validation loss: 0.0499
[Epoch 5, Batch 100] loss: 0.04087700123724062
[Epoch 5, Batch 200] loss: 0.05042910783784464
[Epoch 5, Batch 300] loss: 0.03394299533683807
[Epoch 5, Batch 400] loss: 0.034779587478842584
[Epoch 5, Batch 500] loss: 0.04357064922340214
[Epoch 5, Batch 600] loss: 0.03932536510052159
[Epoch 5, Batch 700] loss: 0.03166777575737797
[Epoch 5, Batch 800] loss: 0.047531031190883366
[Epoch 5, Batch 900] loss: 0.03819042326300405
[Epoch 5, Batch 1000] loss: 0.04208551530260593
[Epoch 5, Batch 1100] loss: 0.04093736107693985
[Epoch 5, Batch 1200] loss: 0.03921526172605809
[Epoch 5, Batch 1300] loss: 0.04681994970480446
[Epoch 5, Batch 1400] loss: 0.03656441126368008
[Epoch 5, Batch 1500] loss: 0.04232813802431337
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0460
Validation Accuracy: 0.9852
Overfitting: 0.0460
Best model saved at epoch 5 with validation loss: 0.0460
[Epoch 6, Batch 100] loss: 0.030828046122333034
[Epoch 6, Batch 200] loss: 0.030952485919115133
[Epoch 6, Batch 300] loss: 0.03963119432854
[Epoch 6, Batch 400] loss: 0.02904816189809935
[Epoch 6, Batch 500] loss: 0.031922243471781256
[Epoch 6, Batch 600] loss: 0.02863407346769236
[Epoch 6, Batch 700] loss: 0.04152800464886241
[Epoch 6, Batch 800] loss: 0.028389242818375352
[Epoch 6, Batch 900] loss: 0.04086100367247127
[Epoch 6, Batch 1000] loss: 0.036816440753173085
[Epoch 6, Batch 1100] loss: 0.04405007580993697
[Epoch 6, Batch 1200] loss: 0.035499164394132095
[Epoch 6, Batch 1300] loss: 0.03492433212828473
[Epoch 6, Batch 1400] loss: 0.04022221271356102
[Epoch 6, Batch 1500] loss: 0.038330075178528204
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0435
Validation Accuracy: 0.9872
Overfitting: 0.0435
Best model saved at epoch 6 with validation loss: 0.0435
[Epoch 7, Batch 100] loss: 0.0231511080879136
[Epoch 7, Batch 200] loss: 0.02511865790496813
[Epoch 7, Batch 300] loss: 0.03414338159956969
[Epoch 7, Batch 400] loss: 0.02627063952473691
[Epoch 7, Batch 500] loss: 0.03711753825540654
[Epoch 7, Batch 600] loss: 0.028060697497567164
[Epoch 7, Batch 700] loss: 0.022573435484664516
[Epoch 7, Batch 800] loss: 0.026140175638429356
[Epoch 7, Batch 900] loss: 0.03134666512836702
[Epoch 7, Batch 1000] loss: 0.03324561655143043
[Epoch 7, Batch 1100] loss: 0.018511785948649048
[Epoch 7, Batch 1200] loss: 0.03438403490494238
[Epoch 7, Batch 1300] loss: 0.033460792640107685
[Epoch 7, Batch 1400] loss: 0.02680885302310344
[Epoch 7, Batch 1500] loss: 0.03261172121128766
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0403
Validation Accuracy: 0.9875
Overfitting: 0.0403
Best model saved at epoch 7 with validation loss: 0.0403
[Epoch 8, Batch 100] loss: 0.022732350150472484
[Epoch 8, Batch 200] loss: 0.021905066795734455
[Epoch 8, Batch 300] loss: 0.019765022225910797
[Epoch 8, Batch 400] loss: 0.026908803232654464
[Epoch 8, Batch 500] loss: 0.024823963969538454
[Epoch 8, Batch 600] loss: 0.0210675850205007
[Epoch 8, Batch 700] loss: 0.035522967686556516
[Epoch 8, Batch 800] loss: 0.018401718031673227
[Epoch 8, Batch 900] loss: 0.03171183984610252
[Epoch 8, Batch 1000] loss: 0.02819579218426952
[Epoch 8, Batch 1100] loss: 0.017506166749517434
[Epoch 8, Batch 1200] loss: 0.026898258198343683
[Epoch 8, Batch 1300] loss: 0.02788945487278397
[Epoch 8, Batch 1400] loss: 0.024179955647850873
[Epoch 8, Batch 1500] loss: 0.025550384472735457
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0375
Validation Accuracy: 0.9876
Overfitting: 0.0375
Best model saved at epoch 8 with validation loss: 0.0375
[Epoch 9, Batch 100] loss: 0.026876822378544604
[Epoch 9, Batch 200] loss: 0.014514657784966403
[Epoch 9, Batch 300] loss: 0.018980044317941064
[Epoch 9, Batch 400] loss: 0.0203436132427305
[Epoch 9, Batch 500] loss: 0.018815581856906648
[Epoch 9, Batch 600] loss: 0.020892481417467933
[Epoch 9, Batch 700] loss: 0.019567055783991236
[Epoch 9, Batch 800] loss: 0.019158971707802265
[Epoch 9, Batch 900] loss: 0.01972978838632116
[Epoch 9, Batch 1000] loss: 0.026313136990575005
[Epoch 9, Batch 1100] loss: 0.02180309165662038
[Epoch 9, Batch 1200] loss: 0.02308432073055883
[Epoch 9, Batch 1300] loss: 0.021660678988992002
[Epoch 9, Batch 1400] loss: 0.02217931990955549
[Epoch 9, Batch 1500] loss: 0.024960704834520585
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0363
Validation Accuracy: 0.9886
Overfitting: 0.0363
Best model saved at epoch 9 with validation loss: 0.0363
[Epoch 10, Batch 100] loss: 0.015234267236010055
[Epoch 10, Batch 200] loss: 0.018236977421765915
[Epoch 10, Batch 300] loss: 0.010385614066472044
[Epoch 10, Batch 400] loss: 0.01987311565244454
[Epoch 10, Batch 500] loss: 0.01817480698111467
[Epoch 10, Batch 600] loss: 0.012308456947357627
[Epoch 10, Batch 700] loss: 0.02171655302416184
[Epoch 10, Batch 800] loss: 0.022839421972748825
[Epoch 10, Batch 900] loss: 0.018520857072180662
[Epoch 10, Batch 1000] loss: 0.02484661508642603
[Epoch 10, Batch 1100] loss: 0.014385146377899219
[Epoch 10, Batch 1200] loss: 0.021045119957925636
[Epoch 10, Batch 1300] loss: 0.015990889200620587
[Epoch 10, Batch 1400] loss: 0.020663772420921305
[Epoch 10, Batch 1500] loss: 0.024618267637633834
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0413
Validation Accuracy: 0.9875
Overfitting: 0.0413
[Epoch 11, Batch 100] loss: 0.022068426410551182
[Epoch 11, Batch 200] loss: 0.014182111418231216
[Epoch 11, Batch 300] loss: 0.017545134556421545
[Epoch 11, Batch 400] loss: 0.014895920294948154
[Epoch 11, Batch 500] loss: 0.014632277941054782
[Epoch 11, Batch 600] loss: 0.011231605544853664
[Epoch 11, Batch 700] loss: 0.015975524466193748
[Epoch 11, Batch 800] loss: 0.013518031824714853
[Epoch 11, Batch 900] loss: 0.01518991680455656
[Epoch 11, Batch 1000] loss: 0.012537296039263311
[Epoch 11, Batch 1100] loss: 0.022198369131729123
[Epoch 11, Batch 1200] loss: 0.012778555354889249
[Epoch 11, Batch 1300] loss: 0.015256546252057888
[Epoch 11, Batch 1400] loss: 0.02499224421713734
[Epoch 11, Batch 1500] loss: 0.01749838165444089
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0432
Validation Accuracy: 0.9862
Overfitting: 0.0432
[Epoch 12, Batch 100] loss: 0.01286783784184081
[Epoch 12, Batch 200] loss: 0.010943592766670918
[Epoch 12, Batch 300] loss: 0.01328607424540678
[Epoch 12, Batch 400] loss: 0.01280451370148512
[Epoch 12, Batch 500] loss: 0.017310929826853682
[Epoch 12, Batch 600] loss: 0.010784977651455847
[Epoch 12, Batch 700] loss: 0.01355805051023708
[Epoch 12, Batch 800] loss: 0.021960159396912787
[Epoch 12, Batch 900] loss: 0.012293571229129156
[Epoch 12, Batch 1000] loss: 0.011867924720827433
[Epoch 12, Batch 1100] loss: 0.01728870215767529
[Epoch 12, Batch 1200] loss: 0.008534507704898714
[Epoch 12, Batch 1300] loss: 0.020828427261239995
[Epoch 12, Batch 1400] loss: 0.012482012249238323
[Epoch 12, Batch 1500] loss: 0.007936177161354863
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0380
Validation Accuracy: 0.9882
Overfitting: 0.0380
[Epoch 13, Batch 100] loss: 0.00518349450824644
[Epoch 13, Batch 200] loss: 0.017613302785775886
[Epoch 13, Batch 300] loss: 0.011767220552919753
[Epoch 13, Batch 400] loss: 0.008944028482037538
[Epoch 13, Batch 500] loss: 0.014709489488486724
[Epoch 13, Batch 600] loss: 0.008597144027444301
[Epoch 13, Batch 700] loss: 0.012854572382207153
[Epoch 13, Batch 800] loss: 0.009682919623119233
[Epoch 13, Batch 900] loss: 0.016621777722784826
[Epoch 13, Batch 1000] loss: 0.018321072773633203
[Epoch 13, Batch 1100] loss: 0.009468973477632972
[Epoch 13, Batch 1200] loss: 0.01031233765752404
[Epoch 13, Batch 1300] loss: 0.010661899630795233
[Epoch 13, Batch 1400] loss: 0.0177783209784684
[Epoch 13, Batch 1500] loss: 0.011837819504671642
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0386
Validation Accuracy: 0.9892
Overfitting: 0.0386
[Epoch 14, Batch 100] loss: 0.008553936884400173
[Epoch 14, Batch 200] loss: 0.007635051637043944
[Epoch 14, Batch 300] loss: 0.009450525647134783
[Epoch 14, Batch 400] loss: 0.011702522458908788
[Epoch 14, Batch 500] loss: 0.010213532670968561
[Epoch 14, Batch 600] loss: 0.011411960918012483
[Epoch 14, Batch 700] loss: 0.010833239490930282
[Epoch 14, Batch 800] loss: 0.008621447060722858
[Epoch 14, Batch 900] loss: 0.011147582628909731
[Epoch 14, Batch 1000] loss: 0.008779722287472395
[Epoch 14, Batch 1100] loss: 0.015333356688461208
[Epoch 14, Batch 1200] loss: 0.016137254462300916
[Epoch 14, Batch 1300] loss: 0.008421564116506488
[Epoch 14, Batch 1400] loss: 0.012633865571688148
[Epoch 14, Batch 1500] loss: 0.013345229628594097
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0391
Validation Accuracy: 0.9886
Overfitting: 0.0391
[Epoch 15, Batch 100] loss: 0.00639679509184134
[Epoch 15, Batch 200] loss: 0.005592277440346152
[Epoch 15, Batch 300] loss: 0.01129469832918403
[Epoch 15, Batch 400] loss: 0.00914368066645693
[Epoch 15, Batch 500] loss: 0.009845549129640857
[Epoch 15, Batch 600] loss: 0.008553641602884455
[Epoch 15, Batch 700] loss: 0.012692021503244177
[Epoch 15, Batch 800] loss: 0.005665339167935599
[Epoch 15, Batch 900] loss: 0.009230181429993536
[Epoch 15, Batch 1000] loss: 0.00944789848101209
[Epoch 15, Batch 1100] loss: 0.0070531873211803035
[Epoch 15, Batch 1200] loss: 0.01057302556677314
[Epoch 15, Batch 1300] loss: 0.012187015921972489
[Epoch 15, Batch 1400] loss: 0.012365350830975785
[Epoch 15, Batch 1500] loss: 0.00889375798266883
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0363
Validation Accuracy: 0.9892
Overfitting: 0.0363
Best model saved at epoch 15 with validation loss: 0.0363
[Epoch 16, Batch 100] loss: 0.004632437283094077
[Epoch 16, Batch 200] loss: 0.004189085518164575
[Epoch 16, Batch 300] loss: 0.004456921004557444
[Epoch 16, Batch 400] loss: 0.004271982822938298
[Epoch 16, Batch 500] loss: 0.008216001730970675
[Epoch 16, Batch 600] loss: 0.009889259599456182
[Epoch 16, Batch 700] loss: 0.006466989945092792
[Epoch 16, Batch 800] loss: 0.00512357375360807
[Epoch 16, Batch 900] loss: 0.007062513527944248
[Epoch 16, Batch 1000] loss: 0.011857993616067687
[Epoch 16, Batch 1100] loss: 0.008384986182363718
[Epoch 16, Batch 1200] loss: 0.01256911191288964
[Epoch 16, Batch 1300] loss: 0.01154705118399761
[Epoch 16, Batch 1400] loss: 0.010203394158024822
[Epoch 16, Batch 1500] loss: 0.01035023995958909
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0416
Validation Accuracy: 0.9887
Overfitting: 0.0416
[Epoch 17, Batch 100] loss: 0.00825029729659036
[Epoch 17, Batch 200] loss: 0.004626261658868316
[Epoch 17, Batch 300] loss: 0.01230644609083356
[Epoch 17, Batch 400] loss: 0.00758112805264318
[Epoch 17, Batch 500] loss: 0.004582380361439391
[Epoch 17, Batch 600] loss: 0.0052288634888100205
[Epoch 17, Batch 700] loss: 0.007065402229718529
[Epoch 17, Batch 800] loss: 0.005419758218249626
[Epoch 17, Batch 900] loss: 0.0082245882256575
[Epoch 17, Batch 1000] loss: 0.009556440695632773
[Epoch 17, Batch 1100] loss: 0.0066705255698434485
[Epoch 17, Batch 1200] loss: 0.004111383280196605
[Epoch 17, Batch 1300] loss: 0.008517583226730494
[Epoch 17, Batch 1400] loss: 0.007738094853229995
[Epoch 17, Batch 1500] loss: 0.010154120358940873
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9880
Overfitting: 0.0430
[Epoch 18, Batch 100] loss: 0.006537371917356722
[Epoch 18, Batch 200] loss: 0.007189227136168483
[Epoch 18, Batch 300] loss: 0.0031783277940940022
[Epoch 18, Batch 400] loss: 0.004008904995525881
[Epoch 18, Batch 500] loss: 0.0063893688702683
[Epoch 18, Batch 600] loss: 0.004896498685534425
[Epoch 18, Batch 700] loss: 0.007505349122420739
[Epoch 18, Batch 800] loss: 0.003592753461743996
[Epoch 18, Batch 900] loss: 0.0027649329243740793
[Epoch 18, Batch 1000] loss: 0.004777431246275228
[Epoch 18, Batch 1100] loss: 0.006146334483826194
[Epoch 18, Batch 1200] loss: 0.00641441714584289
[Epoch 18, Batch 1300] loss: 0.00602602117229253
[Epoch 18, Batch 1400] loss: 0.005563817095226114
[Epoch 18, Batch 1500] loss: 0.0053360775674764225
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0460
Validation Accuracy: 0.9881
Overfitting: 0.0460
[Epoch 19, Batch 100] loss: 0.0043848973227250095
[Epoch 19, Batch 200] loss: 0.0025170815967067027
[Epoch 19, Batch 300] loss: 0.003906059722585269
[Epoch 19, Batch 400] loss: 0.003183636532694436
[Epoch 19, Batch 500] loss: 0.005303222360948894
[Epoch 19, Batch 600] loss: 0.0022828897766157753
[Epoch 19, Batch 700] loss: 0.005883998101699035
[Epoch 19, Batch 800] loss: 0.0043847183873572245
[Epoch 19, Batch 900] loss: 0.003712195001419332
[Epoch 19, Batch 1000] loss: 0.005327162317889815
[Epoch 19, Batch 1100] loss: 0.005179911946011089
[Epoch 19, Batch 1200] loss: 0.007488930374843221
[Epoch 19, Batch 1300] loss: 0.007255749687792559
[Epoch 19, Batch 1400] loss: 0.0026968863876936666
[Epoch 19, Batch 1500] loss: 0.005797613076895232
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0409
Validation Accuracy: 0.9898
Overfitting: 0.0409
[Epoch 20, Batch 100] loss: 0.0029437887468702685
[Epoch 20, Batch 200] loss: 0.0019296897137064662
[Epoch 20, Batch 300] loss: 0.004043389384175953
[Epoch 20, Batch 400] loss: 0.002089412938107671
[Epoch 20, Batch 500] loss: 0.001670816054949853
[Epoch 20, Batch 600] loss: 0.003738766466594825
[Epoch 20, Batch 700] loss: 0.004116839867004387
[Epoch 20, Batch 800] loss: 0.005642314777844604
[Epoch 20, Batch 900] loss: 0.0030458737005346847
[Epoch 20, Batch 1000] loss: 0.011867829536495265
[Epoch 20, Batch 1100] loss: 0.0039755715441151555
[Epoch 20, Batch 1200] loss: 0.006962857544865528
[Epoch 20, Batch 1300] loss: 0.007487596000388521
[Epoch 20, Batch 1400] loss: 0.004459280559312901
[Epoch 20, Batch 1500] loss: 0.008004093655185897
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9882
Overfitting: 0.0492
[Epoch 21, Batch 100] loss: 0.009574990425180658
[Epoch 21, Batch 200] loss: 0.004753719595366874
[Epoch 21, Batch 300] loss: 0.0054064448428380275
[Epoch 21, Batch 400] loss: 0.002854115296670443
[Epoch 21, Batch 500] loss: 0.00198318024787568
[Epoch 21, Batch 600] loss: 0.0038882252776284076
[Epoch 21, Batch 700] loss: 0.003161607322867894
[Epoch 21, Batch 800] loss: 0.004538260678336883
[Epoch 21, Batch 900] loss: 0.005151455729815097
[Epoch 21, Batch 1000] loss: 0.00811390492985538
[Epoch 21, Batch 1100] loss: 0.00910776529019131
[Epoch 21, Batch 1200] loss: 0.008081045052388163
[Epoch 21, Batch 1300] loss: 0.010243598202882821
[Epoch 21, Batch 1400] loss: 0.00752547460070673
[Epoch 21, Batch 1500] loss: 0.007329672680539261
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0454
Validation Accuracy: 0.9887
Overfitting: 0.0454
[Epoch 22, Batch 100] loss: 0.00620467314272446
[Epoch 22, Batch 200] loss: 0.0014033959756571334
[Epoch 22, Batch 300] loss: 0.0055051599086891655
[Epoch 22, Batch 400] loss: 0.0040215916241527335
[Epoch 22, Batch 500] loss: 0.005610626808647794
[Epoch 22, Batch 600] loss: 0.007904246515722661
[Epoch 22, Batch 700] loss: 0.009501606702815479
[Epoch 22, Batch 800] loss: 0.002949678887766822
[Epoch 22, Batch 900] loss: 0.004496785503110914
[Epoch 22, Batch 1000] loss: 0.004946618152362134
[Epoch 22, Batch 1100] loss: 0.0024208285914573933
[Epoch 22, Batch 1200] loss: 0.006163539849956124
[Epoch 22, Batch 1300] loss: 0.0076670494034988225
[Epoch 22, Batch 1400] loss: 0.005661620827809201
[Epoch 22, Batch 1500] loss: 0.003802256385713463
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0429
Validation Accuracy: 0.9885
Overfitting: 0.0429
[Epoch 23, Batch 100] loss: 0.001238061190737767
[Epoch 23, Batch 200] loss: 0.0020717952939514816
[Epoch 23, Batch 300] loss: 0.007419293507825842
[Epoch 23, Batch 400] loss: 0.0071755061799967735
[Epoch 23, Batch 500] loss: 0.002682613311399109
[Epoch 23, Batch 600] loss: 0.0024650407589388123
[Epoch 23, Batch 700] loss: 0.002142380474167567
[Epoch 23, Batch 800] loss: 0.002200280429428858
[Epoch 23, Batch 900] loss: 0.004824622670420808
[Epoch 23, Batch 1000] loss: 0.0028358793608708765
[Epoch 23, Batch 1100] loss: 0.006362708079991535
[Epoch 23, Batch 1200] loss: 0.0074353049448654925
[Epoch 23, Batch 1300] loss: 0.005533017005459442
[Epoch 23, Batch 1400] loss: 0.0072662956948499864
[Epoch 23, Batch 1500] loss: 0.002027181492597947
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9898
Overfitting: 0.0441
[Epoch 24, Batch 100] loss: 0.0022092085345678924
[Epoch 24, Batch 200] loss: 0.005489195235842601
[Epoch 24, Batch 300] loss: 0.003693119958661555
[Epoch 24, Batch 400] loss: 0.000983258580436086
[Epoch 24, Batch 500] loss: 0.0013471916892603985
[Epoch 24, Batch 600] loss: 0.005158595740388136
[Epoch 24, Batch 700] loss: 0.0023788197289195522
[Epoch 24, Batch 800] loss: 0.0026523390874353936
[Epoch 24, Batch 900] loss: 0.0019074726093742812
[Epoch 24, Batch 1000] loss: 0.002002295937305689
[Epoch 24, Batch 1100] loss: 0.003162046493118851
[Epoch 24, Batch 1200] loss: 0.0030695224712258096
[Epoch 24, Batch 1300] loss: 0.0008783571186563677
[Epoch 24, Batch 1400] loss: 0.001152476730939611
[Epoch 24, Batch 1500] loss: 0.0008122590755465354
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0437
Validation Accuracy: 0.9905
Overfitting: 0.0437
Fold 1 validation loss: 0.0437
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2912198805809023
[Epoch 1, Batch 200] loss: 2.130410704612732
[Epoch 1, Batch 300] loss: 0.8726285922527314
[Epoch 1, Batch 400] loss: 0.42084577605128287
[Epoch 1, Batch 500] loss: 0.3482879488170147
[Epoch 1, Batch 600] loss: 0.3181511836498976
[Epoch 1, Batch 700] loss: 0.2337478671222925
[Epoch 1, Batch 800] loss: 0.22573853593319654
[Epoch 1, Batch 900] loss: 0.20935883617028594
[Epoch 1, Batch 1000] loss: 0.19857802983373404
[Epoch 1, Batch 1100] loss: 0.17058646909892558
[Epoch 1, Batch 1200] loss: 0.16807747326791286
[Epoch 1, Batch 1300] loss: 0.14591264052316547
[Epoch 1, Batch 1400] loss: 0.14241770445369184
[Epoch 1, Batch 1500] loss: 0.14754845887422563
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1351
Validation Accuracy: 0.9575
Overfitting: 0.1351
Best model saved at epoch 1 with validation loss: 0.1351
[Epoch 2, Batch 100] loss: 0.12891787662170828
[Epoch 2, Batch 200] loss: 0.12007990102283657
[Epoch 2, Batch 300] loss: 0.12480134243145585
[Epoch 2, Batch 400] loss: 0.11013880127109588
[Epoch 2, Batch 500] loss: 0.1221016233926639
[Epoch 2, Batch 600] loss: 0.11160042306408285
[Epoch 2, Batch 700] loss: 0.10713707375805825
[Epoch 2, Batch 800] loss: 0.11443278657272458
[Epoch 2, Batch 900] loss: 0.11280579758808017
[Epoch 2, Batch 1000] loss: 0.07096043842379003
[Epoch 2, Batch 1100] loss: 0.09473442913033069
[Epoch 2, Batch 1200] loss: 0.09603882706724107
[Epoch 2, Batch 1300] loss: 0.07243254580069333
[Epoch 2, Batch 1400] loss: 0.07903914532624184
[Epoch 2, Batch 1500] loss: 0.08611695782514289
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0953
Validation Accuracy: 0.9695
Overfitting: 0.0953
Best model saved at epoch 2 with validation loss: 0.0953
[Epoch 3, Batch 100] loss: 0.08968733677640557
[Epoch 3, Batch 200] loss: 0.08030901606660336
[Epoch 3, Batch 300] loss: 0.07512617047643289
[Epoch 3, Batch 400] loss: 0.07030611913185567
[Epoch 3, Batch 500] loss: 0.06667960153077729
[Epoch 3, Batch 600] loss: 0.06251983022782952
[Epoch 3, Batch 700] loss: 0.0727881889080163
[Epoch 3, Batch 800] loss: 0.06875416366034187
[Epoch 3, Batch 900] loss: 0.06254713842296042
[Epoch 3, Batch 1000] loss: 0.0652124197257217
[Epoch 3, Batch 1100] loss: 0.06331784778973087
[Epoch 3, Batch 1200] loss: 0.06592714169528335
[Epoch 3, Batch 1300] loss: 0.07520105023868381
[Epoch 3, Batch 1400] loss: 0.0573685706674587
[Epoch 3, Batch 1500] loss: 0.05655635198811069
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0767
Validation Accuracy: 0.9773
Overfitting: 0.0767
Best model saved at epoch 3 with validation loss: 0.0767
[Epoch 4, Batch 100] loss: 0.05459131505340338
[Epoch 4, Batch 200] loss: 0.051123912573093545
[Epoch 4, Batch 300] loss: 0.044434047206887047
[Epoch 4, Batch 400] loss: 0.04209292895393446
[Epoch 4, Batch 500] loss: 0.06802037578832824
[Epoch 4, Batch 600] loss: 0.04974516457179561
[Epoch 4, Batch 700] loss: 0.05978978613391519
[Epoch 4, Batch 800] loss: 0.04600463301758282
[Epoch 4, Batch 900] loss: 0.042251602723263205
[Epoch 4, Batch 1000] loss: 0.05665398118202575
[Epoch 4, Batch 1100] loss: 0.059850356673123314
[Epoch 4, Batch 1200] loss: 0.05513574527576566
[Epoch 4, Batch 1300] loss: 0.0492497551755514
[Epoch 4, Batch 1400] loss: 0.059068230809643865
[Epoch 4, Batch 1500] loss: 0.05082852854568046
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0667
Validation Accuracy: 0.9799
Overfitting: 0.0667
Best model saved at epoch 4 with validation loss: 0.0667
[Epoch 5, Batch 100] loss: 0.045757694174535575
[Epoch 5, Batch 200] loss: 0.04164663869218202
[Epoch 5, Batch 300] loss: 0.045473854466108604
[Epoch 5, Batch 400] loss: 0.040674133198335766
[Epoch 5, Batch 500] loss: 0.04194228603388183
[Epoch 5, Batch 600] loss: 0.04962330296810251
[Epoch 5, Batch 700] loss: 0.04404328754288144
[Epoch 5, Batch 800] loss: 0.040211105333874
[Epoch 5, Batch 900] loss: 0.04341985128790839
[Epoch 5, Batch 1000] loss: 0.038759524759370834
[Epoch 5, Batch 1100] loss: 0.04176479753688909
[Epoch 5, Batch 1200] loss: 0.03209184944804292
[Epoch 5, Batch 1300] loss: 0.05227982560114469
[Epoch 5, Batch 1400] loss: 0.04969659783877432
[Epoch 5, Batch 1500] loss: 0.040843907186063004
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0599
Validation Accuracy: 0.9812
Overfitting: 0.0599
Best model saved at epoch 5 with validation loss: 0.0599
[Epoch 6, Batch 100] loss: 0.03145141917804722
[Epoch 6, Batch 200] loss: 0.030427951102901717
[Epoch 6, Batch 300] loss: 0.03368194572860375
[Epoch 6, Batch 400] loss: 0.03578403525694739
[Epoch 6, Batch 500] loss: 0.04419517661735881
[Epoch 6, Batch 600] loss: 0.041484918308560735
[Epoch 6, Batch 700] loss: 0.03297239013103535
[Epoch 6, Batch 800] loss: 0.03672774898412172
[Epoch 6, Batch 900] loss: 0.03394606046087574
[Epoch 6, Batch 1000] loss: 0.03938459627213888
[Epoch 6, Batch 1100] loss: 0.0405093306559138
[Epoch 6, Batch 1200] loss: 0.03207486294966657
[Epoch 6, Batch 1300] loss: 0.03636726677941624
[Epoch 6, Batch 1400] loss: 0.03715300792158814
[Epoch 6, Batch 1500] loss: 0.033129634055076164
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0672
Validation Accuracy: 0.9797
Overfitting: 0.0672
[Epoch 7, Batch 100] loss: 0.028856957413518104
[Epoch 7, Batch 200] loss: 0.024268414724792818
[Epoch 7, Batch 300] loss: 0.02302730607741978
[Epoch 7, Batch 400] loss: 0.02408287516256678
[Epoch 7, Batch 500] loss: 0.02021670193396858
[Epoch 7, Batch 600] loss: 0.033367975087021474
[Epoch 7, Batch 700] loss: 0.03992255851335358
[Epoch 7, Batch 800] loss: 0.03267324323300272
[Epoch 7, Batch 900] loss: 0.022210513781174085
[Epoch 7, Batch 1000] loss: 0.03255602828226983
[Epoch 7, Batch 1100] loss: 0.0474556387233315
[Epoch 7, Batch 1200] loss: 0.02912311757565476
[Epoch 7, Batch 1300] loss: 0.024219620131625562
[Epoch 7, Batch 1400] loss: 0.043653579204692504
[Epoch 7, Batch 1500] loss: 0.029074149956868495
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0517
Validation Accuracy: 0.9850
Overfitting: 0.0517
Best model saved at epoch 7 with validation loss: 0.0517
[Epoch 8, Batch 100] loss: 0.029665573851380033
[Epoch 8, Batch 200] loss: 0.022563643257599325
[Epoch 8, Batch 300] loss: 0.025334457720746287
[Epoch 8, Batch 400] loss: 0.023841268807882444
[Epoch 8, Batch 500] loss: 0.037750266553339316
[Epoch 8, Batch 600] loss: 0.0182711956455023
[Epoch 8, Batch 700] loss: 0.01669506523536256
[Epoch 8, Batch 800] loss: 0.02989181769284187
[Epoch 8, Batch 900] loss: 0.020056235232113976
[Epoch 8, Batch 1000] loss: 0.024125302956963423
[Epoch 8, Batch 1100] loss: 0.025205756962677697
[Epoch 8, Batch 1200] loss: 0.02993611719895853
[Epoch 8, Batch 1300] loss: 0.028276464570080862
[Epoch 8, Batch 1400] loss: 0.030498796896863495
[Epoch 8, Batch 1500] loss: 0.026701385711785406
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9851
Overfitting: 0.0529
[Epoch 9, Batch 100] loss: 0.02606519962719176
[Epoch 9, Batch 200] loss: 0.01909835974161979
[Epoch 9, Batch 300] loss: 0.023947613830969203
[Epoch 9, Batch 400] loss: 0.021437724806019104
[Epoch 9, Batch 500] loss: 0.011695515211176826
[Epoch 9, Batch 600] loss: 0.030640324146079364
[Epoch 9, Batch 700] loss: 0.02155875493772328
[Epoch 9, Batch 800] loss: 0.02286173262138618
[Epoch 9, Batch 900] loss: 0.02254336847738159
[Epoch 9, Batch 1000] loss: 0.02663601442523941
[Epoch 9, Batch 1100] loss: 0.018478897975364818
[Epoch 9, Batch 1200] loss: 0.015315771440073149
[Epoch 9, Batch 1300] loss: 0.02234173888246005
[Epoch 9, Batch 1400] loss: 0.024295776945145918
[Epoch 9, Batch 1500] loss: 0.02660922007606132
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9847
Overfitting: 0.0546
[Epoch 10, Batch 100] loss: 0.016955185390252155
[Epoch 10, Batch 200] loss: 0.023257961658819114
[Epoch 10, Batch 300] loss: 0.021403979331516894
[Epoch 10, Batch 400] loss: 0.017362253807950766
[Epoch 10, Batch 500] loss: 0.015571375593535776
[Epoch 10, Batch 600] loss: 0.015547189674616674
[Epoch 10, Batch 700] loss: 0.02098568357047043
[Epoch 10, Batch 800] loss: 0.017037043356103822
[Epoch 10, Batch 900] loss: 0.017153862625127657
[Epoch 10, Batch 1000] loss: 0.01634745512768859
[Epoch 10, Batch 1100] loss: 0.020718471798682005
[Epoch 10, Batch 1200] loss: 0.022456823606480613
[Epoch 10, Batch 1300] loss: 0.020007287090702448
[Epoch 10, Batch 1400] loss: 0.025973263091873377
[Epoch 10, Batch 1500] loss: 0.02292466061320738
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9855
Overfitting: 0.0520
[Epoch 11, Batch 100] loss: 0.011372222423524363
[Epoch 11, Batch 200] loss: 0.014315202168145334
[Epoch 11, Batch 300] loss: 0.012771984245082421
[Epoch 11, Batch 400] loss: 0.015107540007011266
[Epoch 11, Batch 500] loss: 0.015820493864594026
[Epoch 11, Batch 600] loss: 0.019480656418163562
[Epoch 11, Batch 700] loss: 0.019837288975249976
[Epoch 11, Batch 800] loss: 0.01597134474257473
[Epoch 11, Batch 900] loss: 0.017318272335978692
[Epoch 11, Batch 1000] loss: 0.024889781435631447
[Epoch 11, Batch 1100] loss: 0.01992841168612358
[Epoch 11, Batch 1200] loss: 0.01787966893578414
[Epoch 11, Batch 1300] loss: 0.01636076503476943
[Epoch 11, Batch 1400] loss: 0.014834660602209624
[Epoch 11, Batch 1500] loss: 0.02032799727792735
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0565
Validation Accuracy: 0.9848
Overfitting: 0.0565
[Epoch 12, Batch 100] loss: 0.013414230740600032
[Epoch 12, Batch 200] loss: 0.015336033490675617
[Epoch 12, Batch 300] loss: 0.015148122478130972
[Epoch 12, Batch 400] loss: 0.017002530973331886
[Epoch 12, Batch 500] loss: 0.015903656231166678
[Epoch 12, Batch 600] loss: 0.012430541806461406
[Epoch 12, Batch 700] loss: 0.014557508998914273
[Epoch 12, Batch 800] loss: 0.016073533407325157
[Epoch 12, Batch 900] loss: 0.010581085361191072
[Epoch 12, Batch 1000] loss: 0.011839389110500633
[Epoch 12, Batch 1100] loss: 0.013487511132252621
[Epoch 12, Batch 1200] loss: 0.017476364354151883
[Epoch 12, Batch 1300] loss: 0.00931500825972762
[Epoch 12, Batch 1400] loss: 0.011399749315423834
[Epoch 12, Batch 1500] loss: 0.022747317071189172
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9856
Overfitting: 0.0529
[Epoch 13, Batch 100] loss: 0.008244547466056247
[Epoch 13, Batch 200] loss: 0.013003781524894294
[Epoch 13, Batch 300] loss: 0.0123951785985264
[Epoch 13, Batch 400] loss: 0.01780351478504599
[Epoch 13, Batch 500] loss: 0.01218223361116543
[Epoch 13, Batch 600] loss: 0.0146375797626024
[Epoch 13, Batch 700] loss: 0.012589457471131027
[Epoch 13, Batch 800] loss: 0.015938181284254824
[Epoch 13, Batch 900] loss: 0.014305749242557795
[Epoch 13, Batch 1000] loss: 0.017273725324994302
[Epoch 13, Batch 1100] loss: 0.014626898495625937
[Epoch 13, Batch 1200] loss: 0.010383874873623427
[Epoch 13, Batch 1300] loss: 0.01331195681101235
[Epoch 13, Batch 1400] loss: 0.013295342999917921
[Epoch 13, Batch 1500] loss: 0.01927245725382818
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9860
Overfitting: 0.0543
[Epoch 14, Batch 100] loss: 0.012497473738221743
[Epoch 14, Batch 200] loss: 0.008092390171150328
[Epoch 14, Batch 300] loss: 0.006950770550429297
[Epoch 14, Batch 400] loss: 0.012437313203045051
[Epoch 14, Batch 500] loss: 0.012575100550857315
[Epoch 14, Batch 600] loss: 0.006010528776441788
[Epoch 14, Batch 700] loss: 0.016491267827695992
[Epoch 14, Batch 800] loss: 0.00967925082295551
[Epoch 14, Batch 900] loss: 0.009049527602146555
[Epoch 14, Batch 1000] loss: 0.01766284680685203
[Epoch 14, Batch 1100] loss: 0.01142724050412653
[Epoch 14, Batch 1200] loss: 0.007240505929621577
[Epoch 14, Batch 1300] loss: 0.008720808024711459
[Epoch 14, Batch 1400] loss: 0.012348263479216257
[Epoch 14, Batch 1500] loss: 0.013781978020833776
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9872
Overfitting: 0.0536
[Epoch 15, Batch 100] loss: 0.006783765977779695
[Epoch 15, Batch 200] loss: 0.007648954860123922
[Epoch 15, Batch 300] loss: 0.014386301656686555
[Epoch 15, Batch 400] loss: 0.010052479657106232
[Epoch 15, Batch 500] loss: 0.008432170969517755
[Epoch 15, Batch 600] loss: 0.0075407540539890764
[Epoch 15, Batch 700] loss: 0.012508549238864361
[Epoch 15, Batch 800] loss: 0.008233038553589722
[Epoch 15, Batch 900] loss: 0.010695236011415546
[Epoch 15, Batch 1000] loss: 0.00734152691332838
[Epoch 15, Batch 1100] loss: 0.005671231482865551
[Epoch 15, Batch 1200] loss: 0.008099341473580353
[Epoch 15, Batch 1300] loss: 0.01057410777420273
[Epoch 15, Batch 1400] loss: 0.010960419495440875
[Epoch 15, Batch 1500] loss: 0.0084035563596899
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9868
Overfitting: 0.0529
[Epoch 16, Batch 100] loss: 0.009570492727589227
[Epoch 16, Batch 200] loss: 0.005572850130247389
[Epoch 16, Batch 300] loss: 0.011975595101957878
[Epoch 16, Batch 400] loss: 0.010567722618561674
[Epoch 16, Batch 500] loss: 0.005370424918210119
[Epoch 16, Batch 600] loss: 0.006964735880319495
[Epoch 16, Batch 700] loss: 0.006240489779820564
[Epoch 16, Batch 800] loss: 0.01177006718591656
[Epoch 16, Batch 900] loss: 0.0052727721156315965
[Epoch 16, Batch 1000] loss: 0.006249198677705863
[Epoch 16, Batch 1100] loss: 0.014456162988208234
[Epoch 16, Batch 1200] loss: 0.009486952781835499
[Epoch 16, Batch 1300] loss: 0.009377378068056713
[Epoch 16, Batch 1400] loss: 0.010054888485328775
[Epoch 16, Batch 1500] loss: 0.005678884431981715
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9872
Overfitting: 0.0543
[Epoch 17, Batch 100] loss: 0.005791085736873356
[Epoch 17, Batch 200] loss: 0.003243444622212337
[Epoch 17, Batch 300] loss: 0.002450278786859599
[Epoch 17, Batch 400] loss: 0.003739739970351366
[Epoch 17, Batch 500] loss: 0.007692485228344595
[Epoch 17, Batch 600] loss: 0.004902561700364458
[Epoch 17, Batch 700] loss: 0.0061047669299478
[Epoch 17, Batch 800] loss: 0.009019213999818022
[Epoch 17, Batch 900] loss: 0.009072840186236135
[Epoch 17, Batch 1000] loss: 0.0035002998673598993
[Epoch 17, Batch 1100] loss: 0.009531565373426929
[Epoch 17, Batch 1200] loss: 0.008284307052767871
[Epoch 17, Batch 1300] loss: 0.005504745929101773
[Epoch 17, Batch 1400] loss: 0.008294692890594889
[Epoch 17, Batch 1500] loss: 0.006550598489939148
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9875
Overfitting: 0.0515
Best model saved at epoch 17 with validation loss: 0.0515
[Epoch 18, Batch 100] loss: 0.0027976207520168826
[Epoch 18, Batch 200] loss: 0.005666353117994731
[Epoch 18, Batch 300] loss: 0.003089468797807058
[Epoch 18, Batch 400] loss: 0.005821940224323043
[Epoch 18, Batch 500] loss: 0.006500427074724939
[Epoch 18, Batch 600] loss: 0.006788881533057065
[Epoch 18, Batch 700] loss: 0.003893658668093849
[Epoch 18, Batch 800] loss: 0.004485415681447193
[Epoch 18, Batch 900] loss: 0.0037073474137059746
[Epoch 18, Batch 1000] loss: 0.00911705940664433
[Epoch 18, Batch 1100] loss: 0.008104745422442647
[Epoch 18, Batch 1200] loss: 0.005356424144538323
[Epoch 18, Batch 1300] loss: 0.0066593166055099575
[Epoch 18, Batch 1400] loss: 0.005464985445551065
[Epoch 18, Batch 1500] loss: 0.004558091968165172
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9878
Overfitting: 0.0552
[Epoch 19, Batch 100] loss: 0.004727691885500462
[Epoch 19, Batch 200] loss: 0.00377193385589635
[Epoch 19, Batch 300] loss: 0.00504816198723347
[Epoch 19, Batch 400] loss: 0.006111696602979464
[Epoch 19, Batch 500] loss: 0.004723654431563773
[Epoch 19, Batch 600] loss: 0.004151758525163132
[Epoch 19, Batch 700] loss: 0.005858552640211201
[Epoch 19, Batch 800] loss: 0.005455805342239728
[Epoch 19, Batch 900] loss: 0.005089714320720304
[Epoch 19, Batch 1000] loss: 0.00480456037102158
[Epoch 19, Batch 1100] loss: 0.008063734745087458
[Epoch 19, Batch 1200] loss: 0.011600136295282937
[Epoch 19, Batch 1300] loss: 0.009017817968297094
[Epoch 19, Batch 1400] loss: 0.009115221926094819
[Epoch 19, Batch 1500] loss: 0.007682575358130634
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0596
Validation Accuracy: 0.9869
Overfitting: 0.0596
[Epoch 20, Batch 100] loss: 0.003671154766643667
[Epoch 20, Batch 200] loss: 0.0017436916205815578
[Epoch 20, Batch 300] loss: 0.002095388296111196
[Epoch 20, Batch 400] loss: 0.0015813173953574734
[Epoch 20, Batch 500] loss: 0.0034527103964410344
[Epoch 20, Batch 600] loss: 0.0032013917575125107
[Epoch 20, Batch 700] loss: 0.004743948339780673
[Epoch 20, Batch 800] loss: 0.0026508341594490047
[Epoch 20, Batch 900] loss: 0.00200971618964104
[Epoch 20, Batch 1000] loss: 0.0050266058892680125
[Epoch 20, Batch 1100] loss: 0.002865329384665074
[Epoch 20, Batch 1200] loss: 0.00622420551657342
[Epoch 20, Batch 1300] loss: 0.013043359237399273
[Epoch 20, Batch 1400] loss: 0.005948116975426956
[Epoch 20, Batch 1500] loss: 0.004355009098180745
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9882
Overfitting: 0.0569
[Epoch 21, Batch 100] loss: 0.0015624904213177614
[Epoch 21, Batch 200] loss: 0.0016105346195286075
[Epoch 21, Batch 300] loss: 0.0019800325385858743
[Epoch 21, Batch 400] loss: 0.004674546128886732
[Epoch 21, Batch 500] loss: 0.0019408253817118748
[Epoch 21, Batch 600] loss: 0.002081000166701301
[Epoch 21, Batch 700] loss: 0.0018274528889423891
[Epoch 21, Batch 800] loss: 0.003615313459167737
[Epoch 21, Batch 900] loss: 0.0033447812293411518
[Epoch 21, Batch 1000] loss: 0.0016397282005800662
[Epoch 21, Batch 1100] loss: 0.006544800351073263
[Epoch 21, Batch 1200] loss: 0.005609338642959756
[Epoch 21, Batch 1300] loss: 0.004830987507411919
[Epoch 21, Batch 1400] loss: 0.007036547464545038
[Epoch 21, Batch 1500] loss: 0.00801009401932788
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0585
Validation Accuracy: 0.9878
Overfitting: 0.0585
[Epoch 22, Batch 100] loss: 0.006342680212710548
[Epoch 22, Batch 200] loss: 0.004157015557939303
[Epoch 22, Batch 300] loss: 0.002760916743322923
[Epoch 22, Batch 400] loss: 0.00473426135740283
[Epoch 22, Batch 500] loss: 0.0021682159593729012
[Epoch 22, Batch 600] loss: 0.004536350260417521
[Epoch 22, Batch 700] loss: 0.0016087307310772303
[Epoch 22, Batch 800] loss: 0.002970896890701624
[Epoch 22, Batch 900] loss: 0.0019497268529687518
[Epoch 22, Batch 1000] loss: 0.003121548993176475
[Epoch 22, Batch 1100] loss: 0.0031105612483361255
[Epoch 22, Batch 1200] loss: 0.0013202923654660025
[Epoch 22, Batch 1300] loss: 0.0012947610641663233
[Epoch 22, Batch 1400] loss: 0.001535757729134275
[Epoch 22, Batch 1500] loss: 0.005832739584018327
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9873
Overfitting: 0.0586
[Epoch 23, Batch 100] loss: 0.0019648457116045394
[Epoch 23, Batch 200] loss: 0.0014359224349459508
[Epoch 23, Batch 300] loss: 0.002225290052280258
[Epoch 23, Batch 400] loss: 0.0019716997873894114
[Epoch 23, Batch 500] loss: 0.0020752142894775714
[Epoch 23, Batch 600] loss: 0.0010154251134628111
[Epoch 23, Batch 700] loss: 0.00258515365703488
[Epoch 23, Batch 800] loss: 0.0013465344371093124
[Epoch 23, Batch 900] loss: 0.0012124400862199992
[Epoch 23, Batch 1000] loss: 0.002830609617715254
[Epoch 23, Batch 1100] loss: 0.006121888685776185
[Epoch 23, Batch 1200] loss: 0.005705099959113795
[Epoch 23, Batch 1300] loss: 0.0023988154915696213
[Epoch 23, Batch 1400] loss: 0.0036278971057299714
[Epoch 23, Batch 1500] loss: 0.002534909877682594
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9888
Overfitting: 0.0581
[Epoch 24, Batch 100] loss: 0.0011752942189241368
[Epoch 24, Batch 200] loss: 0.0013408922786106814
[Epoch 24, Batch 300] loss: 0.0017813675902084468
[Epoch 24, Batch 400] loss: 0.001166777777276593
[Epoch 24, Batch 500] loss: 0.0013575004799008638
[Epoch 24, Batch 600] loss: 0.002303204077479677
[Epoch 24, Batch 700] loss: 0.0018772607225855608
[Epoch 24, Batch 800] loss: 0.0010444263724355097
[Epoch 24, Batch 900] loss: 0.0016661710341099934
[Epoch 24, Batch 1000] loss: 0.0007125003740759439
[Epoch 24, Batch 1100] loss: 0.00218015032331607
[Epoch 24, Batch 1200] loss: 0.0020747749418629268
[Epoch 24, Batch 1300] loss: 0.0014572533205750916
[Epoch 24, Batch 1400] loss: 0.001419885198110933
[Epoch 24, Batch 1500] loss: 0.002309556435079685
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9889
Overfitting: 0.0630
Fold 2 validation loss: 0.0630
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2835888957977293
[Epoch 1, Batch 200] loss: 1.9155429077148438
[Epoch 1, Batch 300] loss: 0.7468075850605964
[Epoch 1, Batch 400] loss: 0.4985177430510521
[Epoch 1, Batch 500] loss: 0.3717698169499636
[Epoch 1, Batch 600] loss: 0.2987974951416254
[Epoch 1, Batch 700] loss: 0.24414509791880845
[Epoch 1, Batch 800] loss: 0.2314322042092681
[Epoch 1, Batch 900] loss: 0.22124346505850553
[Epoch 1, Batch 1000] loss: 0.18114440634846687
[Epoch 1, Batch 1100] loss: 0.193898102119565
[Epoch 1, Batch 1200] loss: 0.15060585521161557
[Epoch 1, Batch 1300] loss: 0.18203247364610434
[Epoch 1, Batch 1400] loss: 0.15390602574218065
[Epoch 1, Batch 1500] loss: 0.155976587170735
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1373
Validation Accuracy: 0.9560
Overfitting: 0.1373
Best model saved at epoch 1 with validation loss: 0.1373
[Epoch 2, Batch 100] loss: 0.12393441436812282
[Epoch 2, Batch 200] loss: 0.15443901398219168
[Epoch 2, Batch 300] loss: 0.12131249516271055
[Epoch 2, Batch 400] loss: 0.12146413651295006
[Epoch 2, Batch 500] loss: 0.10369218850973994
[Epoch 2, Batch 600] loss: 0.11133174104616046
[Epoch 2, Batch 700] loss: 0.0985337629262358
[Epoch 2, Batch 800] loss: 0.09379134670365602
[Epoch 2, Batch 900] loss: 0.1016292740078643
[Epoch 2, Batch 1000] loss: 0.0983842301229015
[Epoch 2, Batch 1100] loss: 0.10996609581168741
[Epoch 2, Batch 1200] loss: 0.11151067901169881
[Epoch 2, Batch 1300] loss: 0.09546147906687111
[Epoch 2, Batch 1400] loss: 0.1002932810690254
[Epoch 2, Batch 1500] loss: 0.09883219102397561
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0922
Validation Accuracy: 0.9723
Overfitting: 0.0922
Best model saved at epoch 2 with validation loss: 0.0922
[Epoch 3, Batch 100] loss: 0.07518279148964212
[Epoch 3, Batch 200] loss: 0.06525261865230277
[Epoch 3, Batch 300] loss: 0.07422754728235305
[Epoch 3, Batch 400] loss: 0.08989584625232964
[Epoch 3, Batch 500] loss: 0.06894989838823676
[Epoch 3, Batch 600] loss: 0.08083802259061486
[Epoch 3, Batch 700] loss: 0.07285507272463292
[Epoch 3, Batch 800] loss: 0.07760608181357384
[Epoch 3, Batch 900] loss: 0.07986163200344891
[Epoch 3, Batch 1000] loss: 0.07743074339348822
[Epoch 3, Batch 1100] loss: 0.06028705984121188
[Epoch 3, Batch 1200] loss: 0.08328338750638067
[Epoch 3, Batch 1300] loss: 0.07032992576947436
[Epoch 3, Batch 1400] loss: 0.07493054737569764
[Epoch 3, Batch 1500] loss: 0.07863280623336323
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0727
Validation Accuracy: 0.9788
Overfitting: 0.0727
Best model saved at epoch 3 with validation loss: 0.0727
[Epoch 4, Batch 100] loss: 0.06724423818057403
[Epoch 4, Batch 200] loss: 0.05141847560880706
[Epoch 4, Batch 300] loss: 0.046047642402118075
[Epoch 4, Batch 400] loss: 0.0654117031849455
[Epoch 4, Batch 500] loss: 0.058306779246777296
[Epoch 4, Batch 600] loss: 0.06866937431972474
[Epoch 4, Batch 700] loss: 0.05582189771928824
[Epoch 4, Batch 800] loss: 0.07406120833242312
[Epoch 4, Batch 900] loss: 0.058380725226015784
[Epoch 4, Batch 1000] loss: 0.06311407756875269
[Epoch 4, Batch 1100] loss: 0.062365222995867955
[Epoch 4, Batch 1200] loss: 0.060325521295890215
[Epoch 4, Batch 1300] loss: 0.055770097181666645
[Epoch 4, Batch 1400] loss: 0.05339869037619792
[Epoch 4, Batch 1500] loss: 0.051263178218505345
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0661
Validation Accuracy: 0.9810
Overfitting: 0.0661
Best model saved at epoch 4 with validation loss: 0.0661
[Epoch 5, Batch 100] loss: 0.0459182862949092
[Epoch 5, Batch 200] loss: 0.04684839900233783
[Epoch 5, Batch 300] loss: 0.044556256700307134
[Epoch 5, Batch 400] loss: 0.055012788510939575
[Epoch 5, Batch 500] loss: 0.04633629711228423
[Epoch 5, Batch 600] loss: 0.059881061643827706
[Epoch 5, Batch 700] loss: 0.03486212382209487
[Epoch 5, Batch 800] loss: 0.043342701857327484
[Epoch 5, Batch 900] loss: 0.04545072431443259
[Epoch 5, Batch 1000] loss: 0.05936975855147466
[Epoch 5, Batch 1100] loss: 0.05746227563067805
[Epoch 5, Batch 1200] loss: 0.04489225654746406
[Epoch 5, Batch 1300] loss: 0.055701416942756626
[Epoch 5, Batch 1400] loss: 0.042876378915971146
[Epoch 5, Batch 1500] loss: 0.04771092637616675
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0754
Validation Accuracy: 0.9762
Overfitting: 0.0754
[Epoch 6, Batch 100] loss: 0.03646547148411628
[Epoch 6, Batch 200] loss: 0.030839608629758004
[Epoch 6, Batch 300] loss: 0.03583105861005606
[Epoch 6, Batch 400] loss: 0.03414619413291803
[Epoch 6, Batch 500] loss: 0.04762271209678147
[Epoch 6, Batch 600] loss: 0.04033915111154784
[Epoch 6, Batch 700] loss: 0.034309635611716655
[Epoch 6, Batch 800] loss: 0.038771228541736494
[Epoch 6, Batch 900] loss: 0.03368509275023825
[Epoch 6, Batch 1000] loss: 0.0417093355738325
[Epoch 6, Batch 1100] loss: 0.04627599308732897
[Epoch 6, Batch 1200] loss: 0.05082826510901214
[Epoch 6, Batch 1300] loss: 0.05557406811683904
[Epoch 6, Batch 1400] loss: 0.04618096430436708
[Epoch 6, Batch 1500] loss: 0.03975021730468143
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0585
Validation Accuracy: 0.9818
Overfitting: 0.0585
Best model saved at epoch 6 with validation loss: 0.0585
[Epoch 7, Batch 100] loss: 0.026501137598243078
[Epoch 7, Batch 200] loss: 0.0343926380953053
[Epoch 7, Batch 300] loss: 0.03873658867669292
[Epoch 7, Batch 400] loss: 0.02814206757233478
[Epoch 7, Batch 500] loss: 0.041805358782876285
[Epoch 7, Batch 600] loss: 0.026136097958660686
[Epoch 7, Batch 700] loss: 0.025637914881808683
[Epoch 7, Batch 800] loss: 0.02762055873288773
[Epoch 7, Batch 900] loss: 0.03430888676433824
[Epoch 7, Batch 1000] loss: 0.03301988051622175
[Epoch 7, Batch 1100] loss: 0.046920002405822746
[Epoch 7, Batch 1200] loss: 0.03163099986792076
[Epoch 7, Batch 1300] loss: 0.033141070695710366
[Epoch 7, Batch 1400] loss: 0.04013146300858352
[Epoch 7, Batch 1500] loss: 0.044224411614995913
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9831
Overfitting: 0.0554
Best model saved at epoch 7 with validation loss: 0.0554
[Epoch 8, Batch 100] loss: 0.022868931055563736
[Epoch 8, Batch 200] loss: 0.02416289473650977
[Epoch 8, Batch 300] loss: 0.022858518204884604
[Epoch 8, Batch 400] loss: 0.028159223999100504
[Epoch 8, Batch 500] loss: 0.02188599595509004
[Epoch 8, Batch 600] loss: 0.030265153984073548
[Epoch 8, Batch 700] loss: 0.03089437538816128
[Epoch 8, Batch 800] loss: 0.02201417569347541
[Epoch 8, Batch 900] loss: 0.0265771556096297
[Epoch 8, Batch 1000] loss: 0.031999423317611214
[Epoch 8, Batch 1100] loss: 0.03507439327637257
[Epoch 8, Batch 1200] loss: 0.03271486442652531
[Epoch 8, Batch 1300] loss: 0.0401189707685262
[Epoch 8, Batch 1400] loss: 0.035974411077913826
[Epoch 8, Batch 1500] loss: 0.033599569192447235
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9829
Overfitting: 0.0581
[Epoch 9, Batch 100] loss: 0.01837302033236483
[Epoch 9, Batch 200] loss: 0.030227903254126432
[Epoch 9, Batch 300] loss: 0.028267679114360362
[Epoch 9, Batch 400] loss: 0.018768422775901853
[Epoch 9, Batch 500] loss: 0.02284334036652581
[Epoch 9, Batch 600] loss: 0.02150896224033204
[Epoch 9, Batch 700] loss: 0.019453036171762507
[Epoch 9, Batch 800] loss: 0.025411827644347795
[Epoch 9, Batch 900] loss: 0.02692948705967865
[Epoch 9, Batch 1000] loss: 0.02820736907873652
[Epoch 9, Batch 1100] loss: 0.02654816966445651
[Epoch 9, Batch 1200] loss: 0.0240500905746012
[Epoch 9, Batch 1300] loss: 0.022721958799957066
[Epoch 9, Batch 1400] loss: 0.025220173466514097
[Epoch 9, Batch 1500] loss: 0.03622397926839767
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9838
Overfitting: 0.0540
Best model saved at epoch 9 with validation loss: 0.0540
[Epoch 10, Batch 100] loss: 0.02408616438653553
[Epoch 10, Batch 200] loss: 0.024155564071115805
[Epoch 10, Batch 300] loss: 0.01543189863281441
[Epoch 10, Batch 400] loss: 0.015355046852782835
[Epoch 10, Batch 500] loss: 0.016263760446527158
[Epoch 10, Batch 600] loss: 0.016378325961704833
[Epoch 10, Batch 700] loss: 0.017924438765185187
[Epoch 10, Batch 800] loss: 0.018093120576522778
[Epoch 10, Batch 900] loss: 0.02236344121996808
[Epoch 10, Batch 1000] loss: 0.02189577902689052
[Epoch 10, Batch 1100] loss: 0.023347415636089865
[Epoch 10, Batch 1200] loss: 0.030451355298719136
[Epoch 10, Batch 1300] loss: 0.022581043598365796
[Epoch 10, Batch 1400] loss: 0.028967226128443144
[Epoch 10, Batch 1500] loss: 0.029124898976006078
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0521
Validation Accuracy: 0.9848
Overfitting: 0.0521
Best model saved at epoch 10 with validation loss: 0.0521
[Epoch 11, Batch 100] loss: 0.013532921985024586
[Epoch 11, Batch 200] loss: 0.01957738508754119
[Epoch 11, Batch 300] loss: 0.01632748071133392
[Epoch 11, Batch 400] loss: 0.011843326355301543
[Epoch 11, Batch 500] loss: 0.013577752828859957
[Epoch 11, Batch 600] loss: 0.013138144897911843
[Epoch 11, Batch 700] loss: 0.014859117503510788
[Epoch 11, Batch 800] loss: 0.011958777720283252
[Epoch 11, Batch 900] loss: 0.021216178878712525
[Epoch 11, Batch 1000] loss: 0.018746602797582456
[Epoch 11, Batch 1100] loss: 0.02170103275340807
[Epoch 11, Batch 1200] loss: 0.021478548059531023
[Epoch 11, Batch 1300] loss: 0.028609980944311247
[Epoch 11, Batch 1400] loss: 0.016694773469062056
[Epoch 11, Batch 1500] loss: 0.02152666947062244
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9858
Overfitting: 0.0531
[Epoch 12, Batch 100] loss: 0.01193599345660914
[Epoch 12, Batch 200] loss: 0.0156141081673195
[Epoch 12, Batch 300] loss: 0.01698208089772379
[Epoch 12, Batch 400] loss: 0.014791376670473255
[Epoch 12, Batch 500] loss: 0.01489589381366386
[Epoch 12, Batch 600] loss: 0.020534663245816775
[Epoch 12, Batch 700] loss: 0.01003890953194059
[Epoch 12, Batch 800] loss: 0.015952916597816513
[Epoch 12, Batch 900] loss: 0.01680575311620487
[Epoch 12, Batch 1000] loss: 0.011938646373746451
[Epoch 12, Batch 1100] loss: 0.01232532432062726
[Epoch 12, Batch 1200] loss: 0.01576831331145513
[Epoch 12, Batch 1300] loss: 0.013352586438222715
[Epoch 12, Batch 1400] loss: 0.01848454730319645
[Epoch 12, Batch 1500] loss: 0.019418219685248914
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9858
Overfitting: 0.0529
[Epoch 13, Batch 100] loss: 0.010398039396714012
[Epoch 13, Batch 200] loss: 0.010620496948686196
[Epoch 13, Batch 300] loss: 0.007479397600909579
[Epoch 13, Batch 400] loss: 0.007553309028771764
[Epoch 13, Batch 500] loss: 0.011656486413885432
[Epoch 13, Batch 600] loss: 0.01851154030435282
[Epoch 13, Batch 700] loss: 0.021820212450693363
[Epoch 13, Batch 800] loss: 0.022237514917287628
[Epoch 13, Batch 900] loss: 0.012294485792008345
[Epoch 13, Batch 1000] loss: 0.016316758390821633
[Epoch 13, Batch 1100] loss: 0.014066215489674506
[Epoch 13, Batch 1200] loss: 0.016957357759674777
[Epoch 13, Batch 1300] loss: 0.012758490745727612
[Epoch 13, Batch 1400] loss: 0.018319243548467055
[Epoch 13, Batch 1500] loss: 0.01391400484048063
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0577
Validation Accuracy: 0.9856
Overfitting: 0.0577
[Epoch 14, Batch 100] loss: 0.007189514552155742
[Epoch 14, Batch 200] loss: 0.010050825851294576
[Epoch 14, Batch 300] loss: 0.01136561889312361
[Epoch 14, Batch 400] loss: 0.009238557546705124
[Epoch 14, Batch 500] loss: 0.008647176914309966
[Epoch 14, Batch 600] loss: 0.01239402929742937
[Epoch 14, Batch 700] loss: 0.010525631020673245
[Epoch 14, Batch 800] loss: 0.006862433414353291
[Epoch 14, Batch 900] loss: 0.012066164157222375
[Epoch 14, Batch 1000] loss: 0.008966386248539493
[Epoch 14, Batch 1100] loss: 0.013249487818848138
[Epoch 14, Batch 1200] loss: 0.011605601490446133
[Epoch 14, Batch 1300] loss: 0.019494886624379433
[Epoch 14, Batch 1400] loss: 0.012470051756263274
[Epoch 14, Batch 1500] loss: 0.00989017701679586
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0664
Validation Accuracy: 0.9831
Overfitting: 0.0664
[Epoch 15, Batch 100] loss: 0.011187564314295741
[Epoch 15, Batch 200] loss: 0.00977154854190303
[Epoch 15, Batch 300] loss: 0.005373406142807653
[Epoch 15, Batch 400] loss: 0.006088133376151745
[Epoch 15, Batch 500] loss: 0.005240191440207127
[Epoch 15, Batch 600] loss: 0.007464027251262451
[Epoch 15, Batch 700] loss: 0.011387926016122946
[Epoch 15, Batch 800] loss: 0.008164443000068786
[Epoch 15, Batch 900] loss: 0.011894397205860514
[Epoch 15, Batch 1000] loss: 0.020109138240331958
[Epoch 15, Batch 1100] loss: 0.013802687119996335
[Epoch 15, Batch 1200] loss: 0.015342721735796658
[Epoch 15, Batch 1300] loss: 0.011468050656731066
[Epoch 15, Batch 1400] loss: 0.009239718028411517
[Epoch 15, Batch 1500] loss: 0.013658424800496505
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0678
Validation Accuracy: 0.9824
Overfitting: 0.0678
[Epoch 16, Batch 100] loss: 0.007140893036321359
[Epoch 16, Batch 200] loss: 0.008769856313956553
[Epoch 16, Batch 300] loss: 0.0062735237605829755
[Epoch 16, Batch 400] loss: 0.008067120989162504
[Epoch 16, Batch 500] loss: 0.009223312839239953
[Epoch 16, Batch 600] loss: 0.007561392585830618
[Epoch 16, Batch 700] loss: 0.004495836304704426
[Epoch 16, Batch 800] loss: 0.010101784010894335
[Epoch 16, Batch 900] loss: 0.005709086795013718
[Epoch 16, Batch 1000] loss: 0.00774842328000318
[Epoch 16, Batch 1100] loss: 0.012862164177058731
[Epoch 16, Batch 1200] loss: 0.011386273805583188
[Epoch 16, Batch 1300] loss: 0.013341079313313457
[Epoch 16, Batch 1400] loss: 0.011741952367701742
[Epoch 16, Batch 1500] loss: 0.015498485707521468
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9877
Overfitting: 0.0524
[Epoch 17, Batch 100] loss: 0.010262362179796583
[Epoch 17, Batch 200] loss: 0.0072852588931777975
[Epoch 17, Batch 300] loss: 0.00586931603089397
[Epoch 17, Batch 400] loss: 0.005016831008019835
[Epoch 17, Batch 500] loss: 0.0038170762564914184
[Epoch 17, Batch 600] loss: 0.00874144425232771
[Epoch 17, Batch 700] loss: 0.008581014614528613
[Epoch 17, Batch 800] loss: 0.005793858538672794
[Epoch 17, Batch 900] loss: 0.00504125628033762
[Epoch 17, Batch 1000] loss: 0.005201459356449049
[Epoch 17, Batch 1100] loss: 0.007703694166775676
[Epoch 17, Batch 1200] loss: 0.014502119313037838
[Epoch 17, Batch 1300] loss: 0.010013917799587943
[Epoch 17, Batch 1400] loss: 0.006354795436054701
[Epoch 17, Batch 1500] loss: 0.004063001517140492
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0555
Validation Accuracy: 0.9872
Overfitting: 0.0555
[Epoch 18, Batch 100] loss: 0.004519641810829853
[Epoch 18, Batch 200] loss: 0.0048300109275623984
[Epoch 18, Batch 300] loss: 0.005204490209007417
[Epoch 18, Batch 400] loss: 0.006636892283418092
[Epoch 18, Batch 500] loss: 0.004289474582240018
[Epoch 18, Batch 600] loss: 0.004439693812387304
[Epoch 18, Batch 700] loss: 0.0030532352739419365
[Epoch 18, Batch 800] loss: 0.004529264897191751
[Epoch 18, Batch 900] loss: 0.004161285619296677
[Epoch 18, Batch 1000] loss: 0.004016293677159411
[Epoch 18, Batch 1100] loss: 0.004021530571615131
[Epoch 18, Batch 1200] loss: 0.0138776307194712
[Epoch 18, Batch 1300] loss: 0.010350872033554878
[Epoch 18, Batch 1400] loss: 0.0068307056647608985
[Epoch 18, Batch 1500] loss: 0.0070717678280789184
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0589
Validation Accuracy: 0.9864
Overfitting: 0.0589
[Epoch 19, Batch 100] loss: 0.008376969310038476
[Epoch 19, Batch 200] loss: 0.005455328826110417
[Epoch 19, Batch 300] loss: 0.002766998392930873
[Epoch 19, Batch 400] loss: 0.0046342846304196425
[Epoch 19, Batch 500] loss: 0.005978894813842998
[Epoch 19, Batch 600] loss: 0.006606555418254629
[Epoch 19, Batch 700] loss: 0.006934497409256437
[Epoch 19, Batch 800] loss: 0.005408002461349497
[Epoch 19, Batch 900] loss: 0.006938189298389261
[Epoch 19, Batch 1000] loss: 0.007538849245529491
[Epoch 19, Batch 1100] loss: 0.0038818413018088904
[Epoch 19, Batch 1200] loss: 0.003055495513540336
[Epoch 19, Batch 1300] loss: 0.0035501716637827484
[Epoch 19, Batch 1400] loss: 0.005897484537290438
[Epoch 19, Batch 1500] loss: 0.004408587337866266
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0622
Validation Accuracy: 0.9858
Overfitting: 0.0622
[Epoch 20, Batch 100] loss: 0.0045924819944275445
[Epoch 20, Batch 200] loss: 0.004289490005230618
[Epoch 20, Batch 300] loss: 0.0042548914736380535
[Epoch 20, Batch 400] loss: 0.003213774599075805
[Epoch 20, Batch 500] loss: 0.003798275443016337
[Epoch 20, Batch 600] loss: 0.006912990105429344
[Epoch 20, Batch 700] loss: 0.003969841135566412
[Epoch 20, Batch 800] loss: 0.0025868238667112564
[Epoch 20, Batch 900] loss: 0.007345453653725258
[Epoch 20, Batch 1000] loss: 0.0030597303554765177
[Epoch 20, Batch 1100] loss: 0.006856621462320618
[Epoch 20, Batch 1200] loss: 0.005688046072023099
[Epoch 20, Batch 1300] loss: 0.0017756749219074663
[Epoch 20, Batch 1400] loss: 0.005117318111875875
[Epoch 20, Batch 1500] loss: 0.004968234198913706
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0644
Validation Accuracy: 0.9863
Overfitting: 0.0644
[Epoch 21, Batch 100] loss: 0.0029532326834282685
[Epoch 21, Batch 200] loss: 0.003327247045255035
[Epoch 21, Batch 300] loss: 0.0018957929063094525
[Epoch 21, Batch 400] loss: 0.004018696368448218
[Epoch 21, Batch 500] loss: 0.0035159254009158756
[Epoch 21, Batch 600] loss: 0.0037684519289950913
[Epoch 21, Batch 700] loss: 0.002931531326970571
[Epoch 21, Batch 800] loss: 0.002537047029902624
[Epoch 21, Batch 900] loss: 0.006609139241850244
[Epoch 21, Batch 1000] loss: 0.0018475285515796712
[Epoch 21, Batch 1100] loss: 0.0062746673830156394
[Epoch 21, Batch 1200] loss: 0.004317903068217674
[Epoch 21, Batch 1300] loss: 0.005472336529234383
[Epoch 21, Batch 1400] loss: 0.003461726639297922
[Epoch 21, Batch 1500] loss: 0.0022666475424045983
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0651
Validation Accuracy: 0.9871
Overfitting: 0.0651
[Epoch 22, Batch 100] loss: 0.0029587512348780366
[Epoch 22, Batch 200] loss: 0.0017376803245235807
[Epoch 22, Batch 300] loss: 0.0014704166102552563
[Epoch 22, Batch 400] loss: 0.0017376783678871278
[Epoch 22, Batch 500] loss: 0.0022845784930075295
[Epoch 22, Batch 600] loss: 0.004542729026822485
[Epoch 22, Batch 700] loss: 0.0018407724484168853
[Epoch 22, Batch 800] loss: 0.0010209017832079326
[Epoch 22, Batch 900] loss: 0.001010418660096093
[Epoch 22, Batch 1000] loss: 0.0013955807994744873
[Epoch 22, Batch 1100] loss: 0.0033849056413987454
[Epoch 22, Batch 1200] loss: 0.003456505237891179
[Epoch 22, Batch 1300] loss: 0.0016683067707262468
[Epoch 22, Batch 1400] loss: 0.0021245318484614016
[Epoch 22, Batch 1500] loss: 0.005245471327185669
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0633
Validation Accuracy: 0.9868
Overfitting: 0.0633
[Epoch 23, Batch 100] loss: 0.00824156225550837
[Epoch 23, Batch 200] loss: 0.00539844488577728
[Epoch 23, Batch 300] loss: 0.006729350973884039
[Epoch 23, Batch 400] loss: 0.0038044265797560683
[Epoch 23, Batch 500] loss: 0.004260744192890229
[Epoch 23, Batch 600] loss: 0.0015283547565695698
[Epoch 23, Batch 700] loss: 0.0008205213791961796
[Epoch 23, Batch 800] loss: 0.001610716546078379
[Epoch 23, Batch 900] loss: 0.0016324957556585673
[Epoch 23, Batch 1000] loss: 0.0015115997065532837
[Epoch 23, Batch 1100] loss: 0.0011546762059776938
[Epoch 23, Batch 1200] loss: 0.0031532523754526664
[Epoch 23, Batch 1300] loss: 0.0020518429683511388
[Epoch 23, Batch 1400] loss: 0.006475197784445754
[Epoch 23, Batch 1500] loss: 0.001688252497733629
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0649
Validation Accuracy: 0.9865
Overfitting: 0.0649
[Epoch 24, Batch 100] loss: 0.003890798769899959
[Epoch 24, Batch 200] loss: 0.0012362928096240466
[Epoch 24, Batch 300] loss: 0.0026451814527176866
[Epoch 24, Batch 400] loss: 0.0015496442945726586
[Epoch 24, Batch 500] loss: 0.0006107999851190015
[Epoch 24, Batch 600] loss: 0.0013884764263173111
[Epoch 24, Batch 700] loss: 0.0008303082153804553
[Epoch 24, Batch 800] loss: 0.0007441695819738925
[Epoch 24, Batch 900] loss: 0.0009633196844538361
[Epoch 24, Batch 1000] loss: 0.0008202407618807683
[Epoch 24, Batch 1100] loss: 0.004978341345228046
[Epoch 24, Batch 1200] loss: 0.003582148079217404
[Epoch 24, Batch 1300] loss: 0.002042276408957946
[Epoch 24, Batch 1400] loss: 0.0017298847716952536
[Epoch 24, Batch 1500] loss: 0.0012248047253888216
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0641
Validation Accuracy: 0.9870
Overfitting: 0.0641
Fold 3 validation loss: 0.0641
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.294243886470795
[Epoch 1, Batch 200] loss: 2.243171226978302
[Epoch 1, Batch 300] loss: 1.5471709847450257
[Epoch 1, Batch 400] loss: 0.5034631071984768
[Epoch 1, Batch 500] loss: 0.3380637039989233
[Epoch 1, Batch 600] loss: 0.29621769696474076
[Epoch 1, Batch 700] loss: 0.22485407166182994
[Epoch 1, Batch 800] loss: 0.204722463414073
[Epoch 1, Batch 900] loss: 0.19375717965885997
[Epoch 1, Batch 1000] loss: 0.17075100326910614
[Epoch 1, Batch 1100] loss: 0.16264858355745673
[Epoch 1, Batch 1200] loss: 0.15015764334239065
[Epoch 1, Batch 1300] loss: 0.153126067109406
[Epoch 1, Batch 1400] loss: 0.17896776942536236
[Epoch 1, Batch 1500] loss: 0.12618938475847244
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1236
Validation Accuracy: 0.9603
Overfitting: 0.1236
Best model saved at epoch 1 with validation loss: 0.1236
[Epoch 2, Batch 100] loss: 0.11363068825565278
[Epoch 2, Batch 200] loss: 0.1173331435304135
[Epoch 2, Batch 300] loss: 0.10764556491281838
[Epoch 2, Batch 400] loss: 0.10347978983074427
[Epoch 2, Batch 500] loss: 0.12994727099314332
[Epoch 2, Batch 600] loss: 0.10915235646069049
[Epoch 2, Batch 700] loss: 0.10537234921474009
[Epoch 2, Batch 800] loss: 0.11546325381845236
[Epoch 2, Batch 900] loss: 0.10364650955889373
[Epoch 2, Batch 1000] loss: 0.09165151863824576
[Epoch 2, Batch 1100] loss: 0.10800251216161996
[Epoch 2, Batch 1200] loss: 0.08662364637944847
[Epoch 2, Batch 1300] loss: 0.08896018224302679
[Epoch 2, Batch 1400] loss: 0.10107905376702547
[Epoch 2, Batch 1500] loss: 0.08316384588601068
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0892
Validation Accuracy: 0.9700
Overfitting: 0.0892
Best model saved at epoch 2 with validation loss: 0.0892
[Epoch 3, Batch 100] loss: 0.08143160704988986
[Epoch 3, Batch 200] loss: 0.06544991033384577
[Epoch 3, Batch 300] loss: 0.08225718195317314
[Epoch 3, Batch 400] loss: 0.07385826766025275
[Epoch 3, Batch 500] loss: 0.07449492504121735
[Epoch 3, Batch 600] loss: 0.07048569133738056
[Epoch 3, Batch 700] loss: 0.06992909306194633
[Epoch 3, Batch 800] loss: 0.06897835936862975
[Epoch 3, Batch 900] loss: 0.08806947111152112
[Epoch 3, Batch 1000] loss: 0.0797338136495091
[Epoch 3, Batch 1100] loss: 0.07211928952252493
[Epoch 3, Batch 1200] loss: 0.06393366423435509
[Epoch 3, Batch 1300] loss: 0.06429507992696017
[Epoch 3, Batch 1400] loss: 0.06389461177866906
[Epoch 3, Batch 1500] loss: 0.06379662614082918
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0731
Validation Accuracy: 0.9762
Overfitting: 0.0731
Best model saved at epoch 3 with validation loss: 0.0731
[Epoch 4, Batch 100] loss: 0.04550111575401388
[Epoch 4, Batch 200] loss: 0.06704499955754727
[Epoch 4, Batch 300] loss: 0.05839041596686002
[Epoch 4, Batch 400] loss: 0.06224513045162894
[Epoch 4, Batch 500] loss: 0.05865934372763149
[Epoch 4, Batch 600] loss: 0.06710450244601816
[Epoch 4, Batch 700] loss: 0.05490401106188074
[Epoch 4, Batch 800] loss: 0.06113192245131358
[Epoch 4, Batch 900] loss: 0.06268063626659569
[Epoch 4, Batch 1000] loss: 0.05372789077227935
[Epoch 4, Batch 1100] loss: 0.049811738326679914
[Epoch 4, Batch 1200] loss: 0.04618947973358445
[Epoch 4, Batch 1300] loss: 0.05249872539192438
[Epoch 4, Batch 1400] loss: 0.061838632248109204
[Epoch 4, Batch 1500] loss: 0.06207500937394798
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0757
Validation Accuracy: 0.9752
Overfitting: 0.0757
[Epoch 5, Batch 100] loss: 0.04914983671624214
[Epoch 5, Batch 200] loss: 0.0461482913402142
[Epoch 5, Batch 300] loss: 0.03944162566040177
[Epoch 5, Batch 400] loss: 0.0490421868651174
[Epoch 5, Batch 500] loss: 0.045843302520224824
[Epoch 5, Batch 600] loss: 0.06455703639658168
[Epoch 5, Batch 700] loss: 0.04655836810939945
[Epoch 5, Batch 800] loss: 0.04808335828623967
[Epoch 5, Batch 900] loss: 0.04468192701111548
[Epoch 5, Batch 1000] loss: 0.04130963480973151
[Epoch 5, Batch 1100] loss: 0.05094122800277546
[Epoch 5, Batch 1200] loss: 0.051861719962907955
[Epoch 5, Batch 1300] loss: 0.046711458435747776
[Epoch 5, Batch 1400] loss: 0.04683737684506923
[Epoch 5, Batch 1500] loss: 0.028741748688044026
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9841
Overfitting: 0.0552
Best model saved at epoch 5 with validation loss: 0.0552
[Epoch 6, Batch 100] loss: 0.048292161219287665
[Epoch 6, Batch 200] loss: 0.04072890955023468
[Epoch 6, Batch 300] loss: 0.028061294043436647
[Epoch 6, Batch 400] loss: 0.033006500259507444
[Epoch 6, Batch 500] loss: 0.03869647350220475
[Epoch 6, Batch 600] loss: 0.044296343370224346
[Epoch 6, Batch 700] loss: 0.03968460822070483
[Epoch 6, Batch 800] loss: 0.04237902518972987
[Epoch 6, Batch 900] loss: 0.0382423511496745
[Epoch 6, Batch 1000] loss: 0.028015392795205117
[Epoch 6, Batch 1100] loss: 0.03871335144969635
[Epoch 6, Batch 1200] loss: 0.04343647054920439
[Epoch 6, Batch 1300] loss: 0.04134328071493656
[Epoch 6, Batch 1400] loss: 0.03700740812637378
[Epoch 6, Batch 1500] loss: 0.032721103142248464
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0671
Validation Accuracy: 0.9777
Overfitting: 0.0671
[Epoch 7, Batch 100] loss: 0.031063059219741264
[Epoch 7, Batch 200] loss: 0.044004652063595134
[Epoch 7, Batch 300] loss: 0.03601547268044669
[Epoch 7, Batch 400] loss: 0.027568939213524574
[Epoch 7, Batch 500] loss: 0.026679833936796057
[Epoch 7, Batch 600] loss: 0.040775571311241945
[Epoch 7, Batch 700] loss: 0.02785318133275723
[Epoch 7, Batch 800] loss: 0.043436069845629394
[Epoch 7, Batch 900] loss: 0.0264393639145419
[Epoch 7, Batch 1000] loss: 0.030999803653685376
[Epoch 7, Batch 1100] loss: 0.03231916148593882
[Epoch 7, Batch 1200] loss: 0.036314965013880283
[Epoch 7, Batch 1300] loss: 0.03248592108633602
[Epoch 7, Batch 1400] loss: 0.029700181180087385
[Epoch 7, Batch 1500] loss: 0.03521605487170745
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9872
Overfitting: 0.0436
Best model saved at epoch 7 with validation loss: 0.0436
[Epoch 8, Batch 100] loss: 0.02057637246158265
[Epoch 8, Batch 200] loss: 0.026160345755633897
[Epoch 8, Batch 300] loss: 0.02427884332166286
[Epoch 8, Batch 400] loss: 0.03018531820765929
[Epoch 8, Batch 500] loss: 0.024263884027604946
[Epoch 8, Batch 600] loss: 0.02501172967837192
[Epoch 8, Batch 700] loss: 0.030271803319483297
[Epoch 8, Batch 800] loss: 0.02743170099274721
[Epoch 8, Batch 900] loss: 0.0350101525856735
[Epoch 8, Batch 1000] loss: 0.03427398841624381
[Epoch 8, Batch 1100] loss: 0.032539546753687316
[Epoch 8, Batch 1200] loss: 0.028212516218045495
[Epoch 8, Batch 1300] loss: 0.03952700512454612
[Epoch 8, Batch 1400] loss: 0.029455559645430184
[Epoch 8, Batch 1500] loss: 0.022118255902605598
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9842
Overfitting: 0.0496
[Epoch 9, Batch 100] loss: 0.021811586764961248
[Epoch 9, Batch 200] loss: 0.023414650036138483
[Epoch 9, Batch 300] loss: 0.021794706290820615
[Epoch 9, Batch 400] loss: 0.02119173751794733
[Epoch 9, Batch 500] loss: 0.02648496661509853
[Epoch 9, Batch 600] loss: 0.028289251906680874
[Epoch 9, Batch 700] loss: 0.029738750551914564
[Epoch 9, Batch 800] loss: 0.027156407287402543
[Epoch 9, Batch 900] loss: 0.022491699595120734
[Epoch 9, Batch 1000] loss: 0.02428616533296008
[Epoch 9, Batch 1100] loss: 0.02810930129227927
[Epoch 9, Batch 1200] loss: 0.026027533059823325
[Epoch 9, Batch 1300] loss: 0.02786577095874236
[Epoch 9, Batch 1400] loss: 0.02644355154101504
[Epoch 9, Batch 1500] loss: 0.02111157695064321
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0405
Validation Accuracy: 0.9874
Overfitting: 0.0405
Best model saved at epoch 9 with validation loss: 0.0405
[Epoch 10, Batch 100] loss: 0.02041603887628298
[Epoch 10, Batch 200] loss: 0.026565898997578188
[Epoch 10, Batch 300] loss: 0.01807134349211992
[Epoch 10, Batch 400] loss: 0.01975849970302079
[Epoch 10, Batch 500] loss: 0.019930426102546334
[Epoch 10, Batch 600] loss: 0.024444095555409148
[Epoch 10, Batch 700] loss: 0.02052503434548271
[Epoch 10, Batch 800] loss: 0.02477798469859408
[Epoch 10, Batch 900] loss: 0.015644585140398702
[Epoch 10, Batch 1000] loss: 0.025938799367722823
[Epoch 10, Batch 1100] loss: 0.033015207261341856
[Epoch 10, Batch 1200] loss: 0.020642721885524226
[Epoch 10, Batch 1300] loss: 0.02108696378491004
[Epoch 10, Batch 1400] loss: 0.021908367836731488
[Epoch 10, Batch 1500] loss: 0.013323459440725856
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0388
Validation Accuracy: 0.9882
Overfitting: 0.0388
Best model saved at epoch 10 with validation loss: 0.0388
[Epoch 11, Batch 100] loss: 0.014068086065672105
[Epoch 11, Batch 200] loss: 0.013227778169384691
[Epoch 11, Batch 300] loss: 0.016778730480637022
[Epoch 11, Batch 400] loss: 0.01738582094090816
[Epoch 11, Batch 500] loss: 0.026725499933818356
[Epoch 11, Batch 600] loss: 0.016506155826500616
[Epoch 11, Batch 700] loss: 0.01391919618999964
[Epoch 11, Batch 800] loss: 0.023485323805070946
[Epoch 11, Batch 900] loss: 0.026879766726415254
[Epoch 11, Batch 1000] loss: 0.017040712497764617
[Epoch 11, Batch 1100] loss: 0.01727827111040824
[Epoch 11, Batch 1200] loss: 0.0270281375401828
[Epoch 11, Batch 1300] loss: 0.019518501030252083
[Epoch 11, Batch 1400] loss: 0.023096928073791788
[Epoch 11, Batch 1500] loss: 0.01917925873436616
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0395
Validation Accuracy: 0.9885
Overfitting: 0.0395
[Epoch 12, Batch 100] loss: 0.013139279761526268
[Epoch 12, Batch 200] loss: 0.01511445093092334
[Epoch 12, Batch 300] loss: 0.018730717278340307
[Epoch 12, Batch 400] loss: 0.011025801812429563
[Epoch 12, Batch 500] loss: 0.018783508405849716
[Epoch 12, Batch 600] loss: 0.011140203540526273
[Epoch 12, Batch 700] loss: 0.017114934169621846
[Epoch 12, Batch 800] loss: 0.017737231881619665
[Epoch 12, Batch 900] loss: 0.014098873369621288
[Epoch 12, Batch 1000] loss: 0.015672771136887604
[Epoch 12, Batch 1100] loss: 0.02276930410254863
[Epoch 12, Batch 1200] loss: 0.018406959215644746
[Epoch 12, Batch 1300] loss: 0.017876094777384423
[Epoch 12, Batch 1400] loss: 0.013805842063520686
[Epoch 12, Batch 1500] loss: 0.019833752906270093
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0433
Validation Accuracy: 0.9865
Overfitting: 0.0433
[Epoch 13, Batch 100] loss: 0.011535904976408346
[Epoch 13, Batch 200] loss: 0.015557460521267785
[Epoch 13, Batch 300] loss: 0.008465958055276133
[Epoch 13, Batch 400] loss: 0.010081729730991355
[Epoch 13, Batch 500] loss: 0.009003833992792351
[Epoch 13, Batch 600] loss: 0.01879325554775278
[Epoch 13, Batch 700] loss: 0.013419563021598151
[Epoch 13, Batch 800] loss: 0.009282797266350826
[Epoch 13, Batch 900] loss: 0.01853787726497103
[Epoch 13, Batch 1000] loss: 0.013006515275210405
[Epoch 13, Batch 1100] loss: 0.015023646497502341
[Epoch 13, Batch 1200] loss: 0.019599485590078985
[Epoch 13, Batch 1300] loss: 0.013669593708764296
[Epoch 13, Batch 1400] loss: 0.017914670089085122
[Epoch 13, Batch 1500] loss: 0.014270610888379451
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9862
Overfitting: 0.0456
[Epoch 14, Batch 100] loss: 0.016240591513778782
[Epoch 14, Batch 200] loss: 0.008798693140852265
[Epoch 14, Batch 300] loss: 0.009006112736824435
[Epoch 14, Batch 400] loss: 0.006636843460328236
[Epoch 14, Batch 500] loss: 0.005388448729463562
[Epoch 14, Batch 600] loss: 0.01084024349755964
[Epoch 14, Batch 700] loss: 0.008813185225299093
[Epoch 14, Batch 800] loss: 0.015471588368382073
[Epoch 14, Batch 900] loss: 0.015903111705156334
[Epoch 14, Batch 1000] loss: 0.014749440763553138
[Epoch 14, Batch 1100] loss: 0.01753760738620258
[Epoch 14, Batch 1200] loss: 0.01636715363525582
[Epoch 14, Batch 1300] loss: 0.015159308550646528
[Epoch 14, Batch 1400] loss: 0.019778953232307685
[Epoch 14, Batch 1500] loss: 0.013938103369537203
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9862
Overfitting: 0.0475
[Epoch 15, Batch 100] loss: 0.00854511087807623
[Epoch 15, Batch 200] loss: 0.006495238708012039
[Epoch 15, Batch 300] loss: 0.010080400399056088
[Epoch 15, Batch 400] loss: 0.009285043387299083
[Epoch 15, Batch 500] loss: 0.007699150537882815
[Epoch 15, Batch 600] loss: 0.007574674922107078
[Epoch 15, Batch 700] loss: 0.012384578349665389
[Epoch 15, Batch 800] loss: 0.01482906459037622
[Epoch 15, Batch 900] loss: 0.00942492919190954
[Epoch 15, Batch 1000] loss: 0.015080488524909015
[Epoch 15, Batch 1100] loss: 0.005870834132620076
[Epoch 15, Batch 1200] loss: 0.013646181005660764
[Epoch 15, Batch 1300] loss: 0.009487548037104715
[Epoch 15, Batch 1400] loss: 0.017281245948179275
[Epoch 15, Batch 1500] loss: 0.00968116802426266
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0391
Validation Accuracy: 0.9888
Overfitting: 0.0391
[Epoch 16, Batch 100] loss: 0.006952270068977668
[Epoch 16, Batch 200] loss: 0.004813534544355207
[Epoch 16, Batch 300] loss: 0.004511907075957424
[Epoch 16, Batch 400] loss: 0.008714403842132014
[Epoch 16, Batch 500] loss: 0.00642887272655571
[Epoch 16, Batch 600] loss: 0.012172873450917904
[Epoch 16, Batch 700] loss: 0.007396688735425414
[Epoch 16, Batch 800] loss: 0.010996803269904376
[Epoch 16, Batch 900] loss: 0.010290012597470194
[Epoch 16, Batch 1000] loss: 0.013674511121535034
[Epoch 16, Batch 1100] loss: 0.009733678638572201
[Epoch 16, Batch 1200] loss: 0.011926883730920964
[Epoch 16, Batch 1300] loss: 0.007570183109173741
[Epoch 16, Batch 1400] loss: 0.013981113573172478
[Epoch 16, Batch 1500] loss: 0.011691949712399037
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9885
Overfitting: 0.0450
[Epoch 17, Batch 100] loss: 0.007662431733679114
[Epoch 17, Batch 200] loss: 0.012415160132804885
[Epoch 17, Batch 300] loss: 0.007643606119145261
[Epoch 17, Batch 400] loss: 0.004565187137286557
[Epoch 17, Batch 500] loss: 0.005437393760228133
[Epoch 17, Batch 600] loss: 0.0058983431320893944
[Epoch 17, Batch 700] loss: 0.004443412130058277
[Epoch 17, Batch 800] loss: 0.0059870723891617674
[Epoch 17, Batch 900] loss: 0.01430588851111679
[Epoch 17, Batch 1000] loss: 0.015969256414500706
[Epoch 17, Batch 1100] loss: 0.013692111208874848
[Epoch 17, Batch 1200] loss: 0.010356750261798879
[Epoch 17, Batch 1300] loss: 0.015187132036298862
[Epoch 17, Batch 1400] loss: 0.006462495056894113
[Epoch 17, Batch 1500] loss: 0.00786303877546743
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0366
Validation Accuracy: 0.9902
Overfitting: 0.0366
Best model saved at epoch 17 with validation loss: 0.0366
[Epoch 18, Batch 100] loss: 0.004210688922430563
[Epoch 18, Batch 200] loss: 0.008620208176607776
[Epoch 18, Batch 300] loss: 0.0033958354604487796
[Epoch 18, Batch 400] loss: 0.00708794477363881
[Epoch 18, Batch 500] loss: 0.008929515907539098
[Epoch 18, Batch 600] loss: 0.00881790123875362
[Epoch 18, Batch 700] loss: 0.005481736319961783
[Epoch 18, Batch 800] loss: 0.009397382631832443
[Epoch 18, Batch 900] loss: 0.008300627050375623
[Epoch 18, Batch 1000] loss: 0.008380872920197362
[Epoch 18, Batch 1100] loss: 0.00856526819134615
[Epoch 18, Batch 1200] loss: 0.008387344959714937
[Epoch 18, Batch 1300] loss: 0.00784007827845926
[Epoch 18, Batch 1400] loss: 0.0035089719330972003
[Epoch 18, Batch 1500] loss: 0.00705058791254487
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9871
Overfitting: 0.0497
[Epoch 19, Batch 100] loss: 0.007696097121552157
[Epoch 19, Batch 200] loss: 0.012046092331888757
[Epoch 19, Batch 300] loss: 0.003972986637872964
[Epoch 19, Batch 400] loss: 0.003613282216301741
[Epoch 19, Batch 500] loss: 0.006296086672236924
[Epoch 19, Batch 600] loss: 0.005561198940740724
[Epoch 19, Batch 700] loss: 0.010452274454373765
[Epoch 19, Batch 800] loss: 0.006041571688415388
[Epoch 19, Batch 900] loss: 0.0062020241381469535
[Epoch 19, Batch 1000] loss: 0.004369269833555336
[Epoch 19, Batch 1100] loss: 0.005074054827441614
[Epoch 19, Batch 1200] loss: 0.006937878778235245
[Epoch 19, Batch 1300] loss: 0.008744344488281968
[Epoch 19, Batch 1400] loss: 0.0057303152476060855
[Epoch 19, Batch 1500] loss: 0.007961088951715283
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9854
Overfitting: 0.0519
[Epoch 20, Batch 100] loss: 0.007677328861109345
[Epoch 20, Batch 200] loss: 0.006694770555723153
[Epoch 20, Batch 300] loss: 0.005297524528141366
[Epoch 20, Batch 400] loss: 0.007351753760913198
[Epoch 20, Batch 500] loss: 0.005933014454668637
[Epoch 20, Batch 600] loss: 0.009416870380364343
[Epoch 20, Batch 700] loss: 0.005130351345942472
[Epoch 20, Batch 800] loss: 0.004125851790327033
[Epoch 20, Batch 900] loss: 0.00802095575550993
[Epoch 20, Batch 1000] loss: 0.007122233463883276
[Epoch 20, Batch 1100] loss: 0.009330127335620091
[Epoch 20, Batch 1200] loss: 0.003401514957145082
[Epoch 20, Batch 1300] loss: 0.007663872387001902
[Epoch 20, Batch 1400] loss: 0.00859190427170688
[Epoch 20, Batch 1500] loss: 0.008242359748290937
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0424
Validation Accuracy: 0.9889
Overfitting: 0.0424
[Epoch 21, Batch 100] loss: 0.00397695806860952
[Epoch 21, Batch 200] loss: 0.0046691633375667155
[Epoch 21, Batch 300] loss: 0.0054382457939664165
[Epoch 21, Batch 400] loss: 0.002817784455992296
[Epoch 21, Batch 500] loss: 0.0035634367876559736
[Epoch 21, Batch 600] loss: 0.0036360831626871004
[Epoch 21, Batch 700] loss: 0.0018308816960393415
[Epoch 21, Batch 800] loss: 0.001968043409933671
[Epoch 21, Batch 900] loss: 0.00684137947581803
[Epoch 21, Batch 1000] loss: 0.00594908561455668
[Epoch 21, Batch 1100] loss: 0.0032076000392180504
[Epoch 21, Batch 1200] loss: 0.003821256895480474
[Epoch 21, Batch 1300] loss: 0.004166217462317263
[Epoch 21, Batch 1400] loss: 0.004302452058166182
[Epoch 21, Batch 1500] loss: 0.003752244114448331
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0451
Validation Accuracy: 0.9882
Overfitting: 0.0451
[Epoch 22, Batch 100] loss: 0.004338816548347495
[Epoch 22, Batch 200] loss: 0.002570061838653146
[Epoch 22, Batch 300] loss: 0.0015786137039106051
[Epoch 22, Batch 400] loss: 0.0039502528955245
[Epoch 22, Batch 500] loss: 0.007949631125484302
[Epoch 22, Batch 600] loss: 0.0026977331483362833
[Epoch 22, Batch 700] loss: 0.0020657312675677986
[Epoch 22, Batch 800] loss: 0.00242677310166755
[Epoch 22, Batch 900] loss: 0.0009322349725698586
[Epoch 22, Batch 1000] loss: 0.004488105034472483
[Epoch 22, Batch 1100] loss: 0.00545766888019557
[Epoch 22, Batch 1200] loss: 0.002358642828862685
[Epoch 22, Batch 1300] loss: 0.00370485095730146
[Epoch 22, Batch 1400] loss: 0.0011222339750531773
[Epoch 22, Batch 1500] loss: 0.0018239346959967406
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0403
Validation Accuracy: 0.9904
Overfitting: 0.0403
[Epoch 23, Batch 100] loss: 0.0011095588218108788
[Epoch 23, Batch 200] loss: 0.0021748245699473047
[Epoch 23, Batch 300] loss: 0.003565582490020347
[Epoch 23, Batch 400] loss: 0.004468187157825696
[Epoch 23, Batch 500] loss: 0.0031030241905455115
[Epoch 23, Batch 600] loss: 0.0016256295537692722
[Epoch 23, Batch 700] loss: 0.008437336724396118
[Epoch 23, Batch 800] loss: 0.00422407785784344
[Epoch 23, Batch 900] loss: 0.0018492893750851635
[Epoch 23, Batch 1000] loss: 0.0016161235640663562
[Epoch 23, Batch 1100] loss: 0.0016198631790928174
[Epoch 23, Batch 1200] loss: 0.0035583753811079077
[Epoch 23, Batch 1300] loss: 0.002464207364328672
[Epoch 23, Batch 1400] loss: 0.003740275389654926
[Epoch 23, Batch 1500] loss: 0.0014875286953088106
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0405
Validation Accuracy: 0.9901
Overfitting: 0.0405
[Epoch 24, Batch 100] loss: 0.0010960216265107191
[Epoch 24, Batch 200] loss: 0.0012255655838453094
[Epoch 24, Batch 300] loss: 0.0015556125327077551
[Epoch 24, Batch 400] loss: 0.001882964678082999
[Epoch 24, Batch 500] loss: 0.0013776372570032435
[Epoch 24, Batch 600] loss: 0.0007470713812358554
[Epoch 24, Batch 700] loss: 0.0037686930209463298
[Epoch 24, Batch 800] loss: 0.0009601868681852466
[Epoch 24, Batch 900] loss: 0.00072281836674847
[Epoch 24, Batch 1000] loss: 0.0022229527078218327
[Epoch 24, Batch 1100] loss: 0.0013734543137360333
[Epoch 24, Batch 1200] loss: 0.0010718829961717802
[Epoch 24, Batch 1300] loss: 0.003976952337106923
[Epoch 24, Batch 1400] loss: 0.003879600740380056
[Epoch 24, Batch 1500] loss: 0.003402245284116816
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0444
Validation Accuracy: 0.9892
Overfitting: 0.0444
Fold 4 validation loss: 0.0444
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2488829016685488
[Epoch 1, Batch 200] loss: 1.3027626132965089
[Epoch 1, Batch 300] loss: 0.5562474276125431
[Epoch 1, Batch 400] loss: 0.40179742641746996
[Epoch 1, Batch 500] loss: 0.2951052862778306
[Epoch 1, Batch 600] loss: 0.2712934802100062
[Epoch 1, Batch 700] loss: 0.23603228837251664
[Epoch 1, Batch 800] loss: 0.1833748314715922
[Epoch 1, Batch 900] loss: 0.15288939374499022
[Epoch 1, Batch 1000] loss: 0.15225119489245117
[Epoch 1, Batch 1100] loss: 0.15307275848463178
[Epoch 1, Batch 1200] loss: 0.14503704031929374
[Epoch 1, Batch 1300] loss: 0.13727197173051536
[Epoch 1, Batch 1400] loss: 0.1319176019867882
[Epoch 1, Batch 1500] loss: 0.12032629980705678
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1332
Validation Accuracy: 0.9607
Overfitting: 0.1332
Best model saved at epoch 1 with validation loss: 0.1332
[Epoch 2, Batch 100] loss: 0.10841378219425678
[Epoch 2, Batch 200] loss: 0.10700183575972914
[Epoch 2, Batch 300] loss: 0.10942659351974726
[Epoch 2, Batch 400] loss: 0.08957678654696792
[Epoch 2, Batch 500] loss: 0.0939753375435248
[Epoch 2, Batch 600] loss: 0.09944542961195112
[Epoch 2, Batch 700] loss: 0.07318704197648912
[Epoch 2, Batch 800] loss: 0.09062396185006946
[Epoch 2, Batch 900] loss: 0.08059033467434347
[Epoch 2, Batch 1000] loss: 0.08148077400983311
[Epoch 2, Batch 1100] loss: 0.08253105924231932
[Epoch 2, Batch 1200] loss: 0.07547668437357061
[Epoch 2, Batch 1300] loss: 0.08335926312254742
[Epoch 2, Batch 1400] loss: 0.07899957076879219
[Epoch 2, Batch 1500] loss: 0.08160618803929537
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0761
Validation Accuracy: 0.9777
Overfitting: 0.0761
Best model saved at epoch 2 with validation loss: 0.0761
[Epoch 3, Batch 100] loss: 0.06702098916517571
[Epoch 3, Batch 200] loss: 0.06575458457693457
[Epoch 3, Batch 300] loss: 0.0684479508223012
[Epoch 3, Batch 400] loss: 0.05720383318257518
[Epoch 3, Batch 500] loss: 0.05282530916621909
[Epoch 3, Batch 600] loss: 0.06657110185595229
[Epoch 3, Batch 700] loss: 0.07740473555866628
[Epoch 3, Batch 800] loss: 0.059218825402203946
[Epoch 3, Batch 900] loss: 0.05836823556688614
[Epoch 3, Batch 1000] loss: 0.05563066148897633
[Epoch 3, Batch 1100] loss: 0.06267121805343777
[Epoch 3, Batch 1200] loss: 0.0600104662287049
[Epoch 3, Batch 1300] loss: 0.05849184932303615
[Epoch 3, Batch 1400] loss: 0.05945666463114321
[Epoch 3, Batch 1500] loss: 0.06468563145725056
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9833
Overfitting: 0.0544
Best model saved at epoch 3 with validation loss: 0.0544
[Epoch 4, Batch 100] loss: 0.04694071609294042
[Epoch 4, Batch 200] loss: 0.05914328958606348
[Epoch 4, Batch 300] loss: 0.05021860846085474
[Epoch 4, Batch 400] loss: 0.041026832996867595
[Epoch 4, Batch 500] loss: 0.04187448510492686
[Epoch 4, Batch 600] loss: 0.0653952491749078
[Epoch 4, Batch 700] loss: 0.05516370284138247
[Epoch 4, Batch 800] loss: 0.05154380045598373
[Epoch 4, Batch 900] loss: 0.04368331941193901
[Epoch 4, Batch 1000] loss: 0.05574512332386803
[Epoch 4, Batch 1100] loss: 0.039150400690268726
[Epoch 4, Batch 1200] loss: 0.04503005576581927
[Epoch 4, Batch 1300] loss: 0.03665246691554785
[Epoch 4, Batch 1400] loss: 0.0555843935807934
[Epoch 4, Batch 1500] loss: 0.04783294588327408
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0557
Validation Accuracy: 0.9828
Overfitting: 0.0557
[Epoch 5, Batch 100] loss: 0.03506215182453161
[Epoch 5, Batch 200] loss: 0.03601091828197241
[Epoch 5, Batch 300] loss: 0.035206632507033646
[Epoch 5, Batch 400] loss: 0.0375960873067379
[Epoch 5, Batch 500] loss: 0.04441082751378417
[Epoch 5, Batch 600] loss: 0.04418718103668653
[Epoch 5, Batch 700] loss: 0.04061960459279362
[Epoch 5, Batch 800] loss: 0.044162462264648636
[Epoch 5, Batch 900] loss: 0.03509446527285036
[Epoch 5, Batch 1000] loss: 0.0357294388464652
[Epoch 5, Batch 1100] loss: 0.041740542205807286
[Epoch 5, Batch 1200] loss: 0.03536782047944143
[Epoch 5, Batch 1300] loss: 0.032067936417879535
[Epoch 5, Batch 1400] loss: 0.04733784636948258
[Epoch 5, Batch 1500] loss: 0.04101623826398281
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9852
Overfitting: 0.0466
Best model saved at epoch 5 with validation loss: 0.0466
[Epoch 6, Batch 100] loss: 0.02674938406853471
[Epoch 6, Batch 200] loss: 0.028122286534053274
[Epoch 6, Batch 300] loss: 0.03850033905124292
[Epoch 6, Batch 400] loss: 0.030726488921500275
[Epoch 6, Batch 500] loss: 0.03225532889220631
[Epoch 6, Batch 600] loss: 0.0419523363938788
[Epoch 6, Batch 700] loss: 0.03873742417228641
[Epoch 6, Batch 800] loss: 0.032309890475298746
[Epoch 6, Batch 900] loss: 0.028008568953373468
[Epoch 6, Batch 1000] loss: 0.026544214305467904
[Epoch 6, Batch 1100] loss: 0.033755891250330024
[Epoch 6, Batch 1200] loss: 0.04258344740199391
[Epoch 6, Batch 1300] loss: 0.029600160237168893
[Epoch 6, Batch 1400] loss: 0.035241676658188226
[Epoch 6, Batch 1500] loss: 0.025094680447218708
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9855
Overfitting: 0.0492
[Epoch 7, Batch 100] loss: 0.02993924201146001
[Epoch 7, Batch 200] loss: 0.030859937730710954
[Epoch 7, Batch 300] loss: 0.03486019211995881
[Epoch 7, Batch 400] loss: 0.02655634566443041
[Epoch 7, Batch 500] loss: 0.01772261687903665
[Epoch 7, Batch 600] loss: 0.0268987075262703
[Epoch 7, Batch 700] loss: 0.027511831676820295
[Epoch 7, Batch 800] loss: 0.023932811470876912
[Epoch 7, Batch 900] loss: 0.0286364162582322
[Epoch 7, Batch 1000] loss: 0.02570163699419936
[Epoch 7, Batch 1100] loss: 0.030617605340958108
[Epoch 7, Batch 1200] loss: 0.02570130959909875
[Epoch 7, Batch 1300] loss: 0.028968182852258904
[Epoch 7, Batch 1400] loss: 0.031676540990447394
[Epoch 7, Batch 1500] loss: 0.028722004419541917
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9855
Overfitting: 0.0472
[Epoch 8, Batch 100] loss: 0.018734443195571656
[Epoch 8, Batch 200] loss: 0.020642579649866093
[Epoch 8, Batch 300] loss: 0.019471099187940127
[Epoch 8, Batch 400] loss: 0.017926649142900715
[Epoch 8, Batch 500] loss: 0.01886553400552657
[Epoch 8, Batch 600] loss: 0.0184586828063766
[Epoch 8, Batch 700] loss: 0.01530482968155411
[Epoch 8, Batch 800] loss: 0.02071314239423373
[Epoch 8, Batch 900] loss: 0.02004229682719597
[Epoch 8, Batch 1000] loss: 0.0320215151803859
[Epoch 8, Batch 1100] loss: 0.030420717300730756
[Epoch 8, Batch 1200] loss: 0.024714875739300625
[Epoch 8, Batch 1300] loss: 0.034117644769867186
[Epoch 8, Batch 1400] loss: 0.032937183205358454
[Epoch 8, Batch 1500] loss: 0.020316909827306516
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0406
Validation Accuracy: 0.9885
Overfitting: 0.0406
Best model saved at epoch 8 with validation loss: 0.0406
[Epoch 9, Batch 100] loss: 0.015169942289576284
[Epoch 9, Batch 200] loss: 0.02591886667847575
[Epoch 9, Batch 300] loss: 0.019767733336339008
[Epoch 9, Batch 400] loss: 0.01929804364874144
[Epoch 9, Batch 500] loss: 0.014726339120679768
[Epoch 9, Batch 600] loss: 0.019776994316343915
[Epoch 9, Batch 700] loss: 0.018592530209862162
[Epoch 9, Batch 800] loss: 0.02039608839273569
[Epoch 9, Batch 900] loss: 0.018499157757323702
[Epoch 9, Batch 1000] loss: 0.0173381472483743
[Epoch 9, Batch 1100] loss: 0.02058802129191463
[Epoch 9, Batch 1200] loss: 0.024396101950551384
[Epoch 9, Batch 1300] loss: 0.016410343190946152
[Epoch 9, Batch 1400] loss: 0.01955446891108295
[Epoch 9, Batch 1500] loss: 0.020790378321908064
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0425
Validation Accuracy: 0.9874
Overfitting: 0.0425
[Epoch 10, Batch 100] loss: 0.018814975447166944
[Epoch 10, Batch 200] loss: 0.01574148191146378
[Epoch 10, Batch 300] loss: 0.0180653293809155
[Epoch 10, Batch 400] loss: 0.01605570560153865
[Epoch 10, Batch 500] loss: 0.02152208110645006
[Epoch 10, Batch 600] loss: 0.012386061475044698
[Epoch 10, Batch 700] loss: 0.014341067234126967
[Epoch 10, Batch 800] loss: 0.017242520763647916
[Epoch 10, Batch 900] loss: 0.016702381001450703
[Epoch 10, Batch 1000] loss: 0.0170707073151425
[Epoch 10, Batch 1100] loss: 0.027100791859265883
[Epoch 10, Batch 1200] loss: 0.015768734297234913
[Epoch 10, Batch 1300] loss: 0.018052599116672355
[Epoch 10, Batch 1400] loss: 0.01748998281356762
[Epoch 10, Batch 1500] loss: 0.013260606364601699
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9864
Overfitting: 0.0467
[Epoch 11, Batch 100] loss: 0.011377109194399963
[Epoch 11, Batch 200] loss: 0.007974339807806246
[Epoch 11, Batch 300] loss: 0.014470205949728553
[Epoch 11, Batch 400] loss: 0.009800884210844742
[Epoch 11, Batch 500] loss: 0.011837230379969697
[Epoch 11, Batch 600] loss: 0.013200882428645856
[Epoch 11, Batch 700] loss: 0.021751287889419473
[Epoch 11, Batch 800] loss: 0.014223184933362063
[Epoch 11, Batch 900] loss: 0.014048826609796379
[Epoch 11, Batch 1000] loss: 0.013061467457664549
[Epoch 11, Batch 1100] loss: 0.011279284444244695
[Epoch 11, Batch 1200] loss: 0.021119159625814062
[Epoch 11, Batch 1300] loss: 0.02147537460163221
[Epoch 11, Batch 1400] loss: 0.010485287986084587
[Epoch 11, Batch 1500] loss: 0.024047379015846672
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9878
Overfitting: 0.0422
[Epoch 12, Batch 100] loss: 0.014638133803127857
[Epoch 12, Batch 200] loss: 0.011342088921119285
[Epoch 12, Batch 300] loss: 0.007826634769662633
[Epoch 12, Batch 400] loss: 0.010874089381541125
[Epoch 12, Batch 500] loss: 0.013194366695388452
[Epoch 12, Batch 600] loss: 0.010567293629901543
[Epoch 12, Batch 700] loss: 0.012631310661563476
[Epoch 12, Batch 800] loss: 0.00893540155435403
[Epoch 12, Batch 900] loss: 0.013810755408067053
[Epoch 12, Batch 1000] loss: 0.014277296059663058
[Epoch 12, Batch 1100] loss: 0.014455759680640768
[Epoch 12, Batch 1200] loss: 0.012214303352357092
[Epoch 12, Batch 1300] loss: 0.008291379782422155
[Epoch 12, Batch 1400] loss: 0.020344557250973595
[Epoch 12, Batch 1500] loss: 0.021415636420151714
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9863
Overfitting: 0.0486
[Epoch 13, Batch 100] loss: 0.010134737724147271
[Epoch 13, Batch 200] loss: 0.010898334876619628
[Epoch 13, Batch 300] loss: 0.011906027463519422
[Epoch 13, Batch 400] loss: 0.0074245779521515945
[Epoch 13, Batch 500] loss: 0.0039500458402199
[Epoch 13, Batch 600] loss: 0.007181715331280429
[Epoch 13, Batch 700] loss: 0.018258363554632524
[Epoch 13, Batch 800] loss: 0.006138914265784478
[Epoch 13, Batch 900] loss: 0.015137514418483988
[Epoch 13, Batch 1000] loss: 0.014497169694732293
[Epoch 13, Batch 1100] loss: 0.010136857246889121
[Epoch 13, Batch 1200] loss: 0.008667909456780762
[Epoch 13, Batch 1300] loss: 0.008329236098761612
[Epoch 13, Batch 1400] loss: 0.007313214558198524
[Epoch 13, Batch 1500] loss: 0.015124584601635434
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0414
Validation Accuracy: 0.9882
Overfitting: 0.0414
[Epoch 14, Batch 100] loss: 0.009500906725766072
[Epoch 14, Batch 200] loss: 0.007056504176907765
[Epoch 14, Batch 300] loss: 0.012919091247458709
[Epoch 14, Batch 400] loss: 0.005273938230238855
[Epoch 14, Batch 500] loss: 0.00436111826051274
[Epoch 14, Batch 600] loss: 0.009310881660676387
[Epoch 14, Batch 700] loss: 0.006925684720999925
[Epoch 14, Batch 800] loss: 0.010664116707648646
[Epoch 14, Batch 900] loss: 0.008335976579173803
[Epoch 14, Batch 1000] loss: 0.010232169959840576
[Epoch 14, Batch 1100] loss: 0.01328318874217075
[Epoch 14, Batch 1200] loss: 0.005299904513176443
[Epoch 14, Batch 1300] loss: 0.013381895875945703
[Epoch 14, Batch 1400] loss: 0.009100241453863874
[Epoch 14, Batch 1500] loss: 0.008671791006745479
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9880
Overfitting: 0.0450
[Epoch 15, Batch 100] loss: 0.010318969832051153
[Epoch 15, Batch 200] loss: 0.013235096875669115
[Epoch 15, Batch 300] loss: 0.004077306599656367
[Epoch 15, Batch 400] loss: 0.010918178149768209
[Epoch 15, Batch 500] loss: 0.009447803033162927
[Epoch 15, Batch 600] loss: 0.011333487563533709
[Epoch 15, Batch 700] loss: 0.003961816631344845
[Epoch 15, Batch 800] loss: 0.010054304709410645
[Epoch 15, Batch 900] loss: 0.006876949391689777
[Epoch 15, Batch 1000] loss: 0.004568095920149062
[Epoch 15, Batch 1100] loss: 0.0035289811210896006
[Epoch 15, Batch 1200] loss: 0.008000523701775819
[Epoch 15, Batch 1300] loss: 0.010427707908670527
[Epoch 15, Batch 1400] loss: 0.011416222982952605
[Epoch 15, Batch 1500] loss: 0.008046676814376496
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9878
Overfitting: 0.0459
[Epoch 16, Batch 100] loss: 0.0057845860754696336
[Epoch 16, Batch 200] loss: 0.0040839934093150985
[Epoch 16, Batch 300] loss: 0.006276524589611654
[Epoch 16, Batch 400] loss: 0.010439633222971452
[Epoch 16, Batch 500] loss: 0.007435174461161296
[Epoch 16, Batch 600] loss: 0.006555730615043558
[Epoch 16, Batch 700] loss: 0.003393754335970698
[Epoch 16, Batch 800] loss: 0.00903183461385197
[Epoch 16, Batch 900] loss: 0.005862996939076766
[Epoch 16, Batch 1000] loss: 0.007369089959693156
[Epoch 16, Batch 1100] loss: 0.010313278640760473
[Epoch 16, Batch 1200] loss: 0.008033252777604503
[Epoch 16, Batch 1300] loss: 0.011775416172276891
[Epoch 16, Batch 1400] loss: 0.008818381892560866
[Epoch 16, Batch 1500] loss: 0.016874545343903265
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9882
Overfitting: 0.0446
[Epoch 17, Batch 100] loss: 0.005760420660817544
[Epoch 17, Batch 200] loss: 0.005302235032850149
[Epoch 17, Batch 300] loss: 0.005444838665612224
[Epoch 17, Batch 400] loss: 0.004744114150535097
[Epoch 17, Batch 500] loss: 0.006975016117185078
[Epoch 17, Batch 600] loss: 0.007348647202179564
[Epoch 17, Batch 700] loss: 0.005406074350057679
[Epoch 17, Batch 800] loss: 0.007228310867708388
[Epoch 17, Batch 900] loss: 0.006179844815624165
[Epoch 17, Batch 1000] loss: 0.005465990733341641
[Epoch 17, Batch 1100] loss: 0.005741147642664828
[Epoch 17, Batch 1200] loss: 0.011689961092220074
[Epoch 17, Batch 1300] loss: 0.010955847044499478
[Epoch 17, Batch 1400] loss: 0.004960933856727934
[Epoch 17, Batch 1500] loss: 0.006432339137727467
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9890
Overfitting: 0.0453
[Epoch 18, Batch 100] loss: 0.0026221685698828876
[Epoch 18, Batch 200] loss: 0.00420186225729367
[Epoch 18, Batch 300] loss: 0.004176707299784539
[Epoch 18, Batch 400] loss: 0.002167046892650433
[Epoch 18, Batch 500] loss: 0.004495015672532645
[Epoch 18, Batch 600] loss: 0.00585347381680549
[Epoch 18, Batch 700] loss: 0.0027209050629244304
[Epoch 18, Batch 800] loss: 0.004947676101560319
[Epoch 18, Batch 900] loss: 0.0035171732075605176
[Epoch 18, Batch 1000] loss: 0.0044966635224136554
[Epoch 18, Batch 1100] loss: 0.005596035288342591
[Epoch 18, Batch 1200] loss: 0.002447088722851731
[Epoch 18, Batch 1300] loss: 0.005431396414496703
[Epoch 18, Batch 1400] loss: 0.006371648176705094
[Epoch 18, Batch 1500] loss: 0.006055048003308912
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9882
Overfitting: 0.0470
[Epoch 19, Batch 100] loss: 0.004069160387539341
[Epoch 19, Batch 200] loss: 0.0012799906841974007
[Epoch 19, Batch 300] loss: 0.0029516836295812253
[Epoch 19, Batch 400] loss: 0.005917435020060094
[Epoch 19, Batch 500] loss: 0.00247278221538636
[Epoch 19, Batch 600] loss: 0.0012610854552019646
[Epoch 19, Batch 700] loss: 0.004971913434951602
[Epoch 19, Batch 800] loss: 0.0068469286646723046
[Epoch 19, Batch 900] loss: 0.005219193814386926
[Epoch 19, Batch 1000] loss: 0.004257341028494466
[Epoch 19, Batch 1100] loss: 0.006522019635544893
[Epoch 19, Batch 1200] loss: 0.0068573854904570904
[Epoch 19, Batch 1300] loss: 0.004186112755155591
[Epoch 19, Batch 1400] loss: 0.005534100482366284
[Epoch 19, Batch 1500] loss: 0.00946588818866303
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9865
Overfitting: 0.0570
[Epoch 20, Batch 100] loss: 0.0024891347017569386
[Epoch 20, Batch 200] loss: 0.005140836633700587
[Epoch 20, Batch 300] loss: 0.0028113929887194898
[Epoch 20, Batch 400] loss: 0.004941123493272812
[Epoch 20, Batch 500] loss: 0.003917342619836291
[Epoch 20, Batch 600] loss: 0.0036338844021940988
[Epoch 20, Batch 700] loss: 0.003336577446480078
[Epoch 20, Batch 800] loss: 0.011423239457451472
[Epoch 20, Batch 900] loss: 0.009630211848648287
[Epoch 20, Batch 1000] loss: 0.004326355043513103
[Epoch 20, Batch 1100] loss: 0.003807437064021997
[Epoch 20, Batch 1200] loss: 0.0038917499439912718
[Epoch 20, Batch 1300] loss: 0.005422457629149449
[Epoch 20, Batch 1400] loss: 0.002732482197304762
[Epoch 20, Batch 1500] loss: 0.0034048232036502668
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9892
Overfitting: 0.0471
[Epoch 21, Batch 100] loss: 0.003257713687656292
[Epoch 21, Batch 200] loss: 0.0034351962636242207
[Epoch 21, Batch 300] loss: 0.001540135192544767
[Epoch 21, Batch 400] loss: 0.002187959576240246
[Epoch 21, Batch 500] loss: 0.0020444221125670483
[Epoch 21, Batch 600] loss: 0.003664714706092127
[Epoch 21, Batch 700] loss: 0.007723879465802383
[Epoch 21, Batch 800] loss: 0.002188227835408725
[Epoch 21, Batch 900] loss: 0.002840239092143975
[Epoch 21, Batch 1000] loss: 0.00412807049937328
[Epoch 21, Batch 1100] loss: 0.00480989570521146
[Epoch 21, Batch 1200] loss: 0.007231769191290596
[Epoch 21, Batch 1300] loss: 0.0021402261749744866
[Epoch 21, Batch 1400] loss: 0.005320493566146069
[Epoch 21, Batch 1500] loss: 0.003685951894178743
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9876
Overfitting: 0.0490
[Epoch 22, Batch 100] loss: 0.0031603556695381486
[Epoch 22, Batch 200] loss: 0.0024927889106538714
[Epoch 22, Batch 300] loss: 0.003440340423685484
[Epoch 22, Batch 400] loss: 0.0037270615472954206
[Epoch 22, Batch 500] loss: 0.0028063995912066277
[Epoch 22, Batch 600] loss: 0.002641031025641496
[Epoch 22, Batch 700] loss: 0.0020902337398683813
[Epoch 22, Batch 800] loss: 0.0069532843543584025
[Epoch 22, Batch 900] loss: 0.0035407977792357315
[Epoch 22, Batch 1000] loss: 0.007089986303336104
[Epoch 22, Batch 1100] loss: 0.00541476956879336
[Epoch 22, Batch 1200] loss: 0.0052398984069293416
[Epoch 22, Batch 1300] loss: 0.006082891084788571
[Epoch 22, Batch 1400] loss: 0.012530077038190939
[Epoch 22, Batch 1500] loss: 0.0027525167148905894
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9883
Overfitting: 0.0505
[Epoch 23, Batch 100] loss: 0.0030690985724271514
[Epoch 23, Batch 200] loss: 0.0031597335338858557
[Epoch 23, Batch 300] loss: 0.0013990958898176587
[Epoch 23, Batch 400] loss: 0.0020425900846714738
[Epoch 23, Batch 500] loss: 0.0022331390125225423
[Epoch 23, Batch 600] loss: 0.0048577343319504964
[Epoch 23, Batch 700] loss: 0.00509838359071523
[Epoch 23, Batch 800] loss: 0.003011757207233359
[Epoch 23, Batch 900] loss: 0.0016109175889573635
[Epoch 23, Batch 1000] loss: 0.0011753957352311772
[Epoch 23, Batch 1100] loss: 0.004526482686201234
[Epoch 23, Batch 1200] loss: 0.005696938759202794
[Epoch 23, Batch 1300] loss: 0.003048273747523922
[Epoch 23, Batch 1400] loss: 0.006123327240840126
[Epoch 23, Batch 1500] loss: 0.005671527555899729
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9887
Overfitting: 0.0531
[Epoch 24, Batch 100] loss: 0.00438692961391439
[Epoch 24, Batch 200] loss: 0.0014201463417850846
[Epoch 24, Batch 300] loss: 0.0014709121266247393
[Epoch 24, Batch 400] loss: 0.00281854681163793
[Epoch 24, Batch 500] loss: 0.0012521934116520583
[Epoch 24, Batch 600] loss: 0.006064480938054544
[Epoch 24, Batch 700] loss: 0.003909528705860908
[Epoch 24, Batch 800] loss: 0.008839483031267718
[Epoch 24, Batch 900] loss: 0.009545062596134812
[Epoch 24, Batch 1000] loss: 0.003236413605017674
[Epoch 24, Batch 1100] loss: 0.0036195647238196215
[Epoch 24, Batch 1200] loss: 0.007620579690335489
[Epoch 24, Batch 1300] loss: 0.003599311230545936
[Epoch 24, Batch 1400] loss: 0.005068028942332603
[Epoch 24, Batch 1500] loss: 0.0035378993923325195
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9890
Overfitting: 0.0494
Fold 5 validation loss: 0.0494
Mean validation loss across all folds for Trial 19 is 0.0529 with trial config:  l1: 256, l2: 64, lr: 0.0021003588557559176, batch_size: 32
[I 2024-12-10 08:48:21,633] Trial 18 finished with value: 0.0529216759214872 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0021003588557559176, 'batch_size': 32}. Best is trial 16 with value: 0.04722271221232811.

Selected Hyperparameters for Trial 20:
  l1: 256, l2: 64, lr: 0.0019210774775195118, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2806134247779846
[Epoch 1, Batch 200] loss: 2.0407302820682527
[Epoch 1, Batch 300] loss: 0.7877456241846085
[Epoch 1, Batch 400] loss: 0.5193494012206793
[Epoch 1, Batch 500] loss: 0.42207241870462897
[Epoch 1, Batch 600] loss: 0.37234746731817725
[Epoch 1, Batch 700] loss: 0.2735834597051144
[Epoch 1, Batch 800] loss: 0.25438804980367424
[Epoch 1, Batch 900] loss: 0.19286485844291745
[Epoch 1, Batch 1000] loss: 0.22603840552270413
[Epoch 1, Batch 1100] loss: 0.220418042675592
[Epoch 1, Batch 1200] loss: 0.17929848845116794
[Epoch 1, Batch 1300] loss: 0.15866946327500045
[Epoch 1, Batch 1400] loss: 0.16493812419474124
[Epoch 1, Batch 1500] loss: 0.14453925943933427
[Epoch 1, Batch 1600] loss: 0.15680305230431257
[Epoch 1, Batch 1700] loss: 0.1506200660346076
[Epoch 1, Batch 1800] loss: 0.14645669972640463
[Epoch 1, Batch 1900] loss: 0.13125330588780343
[Epoch 1, Batch 2000] loss: 0.1325002830266021
[Epoch 1, Batch 2100] loss: 0.11003147944575176
[Epoch 1, Batch 2200] loss: 0.13402074044803158
[Epoch 1, Batch 2300] loss: 0.09850121540948749
[Epoch 1, Batch 2400] loss: 0.10256152604240924
[Epoch 1, Batch 2500] loss: 0.11546400876715779
[Epoch 1, Batch 2600] loss: 0.09787262441823259
[Epoch 1, Batch 2700] loss: 0.10396350513212382
[Epoch 1, Batch 2800] loss: 0.10379651196417398
[Epoch 1, Batch 2900] loss: 0.10576709370943718
[Epoch 1, Batch 3000] loss: 0.10365880258614198
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0889
Validation Accuracy: 0.9718
Overfitting: 0.0889
Best model saved at epoch 1 with validation loss: 0.0889
[Epoch 2, Batch 100] loss: 0.09879165840276982
[Epoch 2, Batch 200] loss: 0.10330889256321825
[Epoch 2, Batch 300] loss: 0.10996428263839335
[Epoch 2, Batch 400] loss: 0.07497400301333983
[Epoch 2, Batch 500] loss: 0.08800492345471866
[Epoch 2, Batch 600] loss: 0.09060236089047975
[Epoch 2, Batch 700] loss: 0.08118623966845917
[Epoch 2, Batch 800] loss: 0.07323253626702353
[Epoch 2, Batch 900] loss: 0.06170414629683364
[Epoch 2, Batch 1000] loss: 0.08475800662883558
[Epoch 2, Batch 1100] loss: 0.07051632216433062
[Epoch 2, Batch 1200] loss: 0.07650473660440184
[Epoch 2, Batch 1300] loss: 0.08175839719246142
[Epoch 2, Batch 1400] loss: 0.08209305254975334
[Epoch 2, Batch 1500] loss: 0.06369525146612431
[Epoch 2, Batch 1600] loss: 0.06742609701032051
[Epoch 2, Batch 1700] loss: 0.09308481735992245
[Epoch 2, Batch 1800] loss: 0.07844414321007206
[Epoch 2, Batch 1900] loss: 0.0682086248305859
[Epoch 2, Batch 2000] loss: 0.06636367750528734
[Epoch 2, Batch 2100] loss: 0.0699513151316205
[Epoch 2, Batch 2200] loss: 0.07070369826047682
[Epoch 2, Batch 2300] loss: 0.0767260142142186
[Epoch 2, Batch 2400] loss: 0.09934014546102844
[Epoch 2, Batch 2500] loss: 0.07862665172142443
[Epoch 2, Batch 2600] loss: 0.057114556516171436
[Epoch 2, Batch 2700] loss: 0.04818128218772472
[Epoch 2, Batch 2800] loss: 0.06428973466274329
[Epoch 2, Batch 2900] loss: 0.07105664118425921
[Epoch 2, Batch 3000] loss: 0.0636916423717048
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0622
Validation Accuracy: 0.9801
Overfitting: 0.0622
Best model saved at epoch 2 with validation loss: 0.0622
[Epoch 3, Batch 100] loss: 0.058162559636693915
[Epoch 3, Batch 200] loss: 0.07413910916424356
[Epoch 3, Batch 300] loss: 0.06561051805969327
[Epoch 3, Batch 400] loss: 0.04774916852125898
[Epoch 3, Batch 500] loss: 0.05662634599386365
[Epoch 3, Batch 600] loss: 0.05992825260793325
[Epoch 3, Batch 700] loss: 0.06279646293638506
[Epoch 3, Batch 800] loss: 0.05935198814695468
[Epoch 3, Batch 900] loss: 0.04742546125256922
[Epoch 3, Batch 1000] loss: 0.059470072287658694
[Epoch 3, Batch 1100] loss: 0.03821581534983125
[Epoch 3, Batch 1200] loss: 0.042813819834263994
[Epoch 3, Batch 1300] loss: 0.04767630130445468
[Epoch 3, Batch 1400] loss: 0.04490323572230409
[Epoch 3, Batch 1500] loss: 0.04672046976193087
[Epoch 3, Batch 1600] loss: 0.07457505179918371
[Epoch 3, Batch 1700] loss: 0.05891539878532057
[Epoch 3, Batch 1800] loss: 0.06346271480259019
[Epoch 3, Batch 1900] loss: 0.06318051537091378
[Epoch 3, Batch 2000] loss: 0.04338076547632227
[Epoch 3, Batch 2100] loss: 0.052980543374433184
[Epoch 3, Batch 2200] loss: 0.03921716299242689
[Epoch 3, Batch 2300] loss: 0.03994865080465388
[Epoch 3, Batch 2400] loss: 0.06494208218209678
[Epoch 3, Batch 2500] loss: 0.03960415098379599
[Epoch 3, Batch 2600] loss: 0.05083086002465279
[Epoch 3, Batch 2700] loss: 0.06327889008709463
[Epoch 3, Batch 2800] loss: 0.040040211518644356
[Epoch 3, Batch 2900] loss: 0.06381242540373933
[Epoch 3, Batch 3000] loss: 0.06243021894566482
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0615
Validation Accuracy: 0.9803
Overfitting: 0.0615
Best model saved at epoch 3 with validation loss: 0.0615
[Epoch 4, Batch 100] loss: 0.04917393062118208
[Epoch 4, Batch 200] loss: 0.03649174398480682
[Epoch 4, Batch 300] loss: 0.048773811577120796
[Epoch 4, Batch 400] loss: 0.04814186014154984
[Epoch 4, Batch 500] loss: 0.057379633261298295
[Epoch 4, Batch 600] loss: 0.030595792999956756
[Epoch 4, Batch 700] loss: 0.03838971322766156
[Epoch 4, Batch 800] loss: 0.04755667548335623
[Epoch 4, Batch 900] loss: 0.04682925710570998
[Epoch 4, Batch 1000] loss: 0.03344293345915503
[Epoch 4, Batch 1100] loss: 0.0404122663801536
[Epoch 4, Batch 1200] loss: 0.03387350827877526
[Epoch 4, Batch 1300] loss: 0.03747317893350555
[Epoch 4, Batch 1400] loss: 0.03761624732069322
[Epoch 4, Batch 1500] loss: 0.02769306957023218
[Epoch 4, Batch 1600] loss: 0.03745281979237916
[Epoch 4, Batch 1700] loss: 0.05522062090694817
[Epoch 4, Batch 1800] loss: 0.03788042907806812
[Epoch 4, Batch 1900] loss: 0.052325041180447444
[Epoch 4, Batch 2000] loss: 0.06125698081130395
[Epoch 4, Batch 2100] loss: 0.046452998445602134
[Epoch 4, Batch 2200] loss: 0.039012188268388856
[Epoch 4, Batch 2300] loss: 0.04024919459036028
[Epoch 4, Batch 2400] loss: 0.06826299846637994
[Epoch 4, Batch 2500] loss: 0.04842692243779311
[Epoch 4, Batch 2600] loss: 0.032277166314597705
[Epoch 4, Batch 2700] loss: 0.03577520125807496
[Epoch 4, Batch 2800] loss: 0.04009577811142662
[Epoch 4, Batch 2900] loss: 0.03983693566871807
[Epoch 4, Batch 3000] loss: 0.03282500511908438
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9858
Overfitting: 0.0466
Best model saved at epoch 4 with validation loss: 0.0466
[Epoch 5, Batch 100] loss: 0.041151143801398574
[Epoch 5, Batch 200] loss: 0.029562741427580478
[Epoch 5, Batch 300] loss: 0.03667047873568663
[Epoch 5, Batch 400] loss: 0.02119728774880059
[Epoch 5, Batch 500] loss: 0.04081686839432223
[Epoch 5, Batch 600] loss: 0.03242687469864904
[Epoch 5, Batch 700] loss: 0.030363902634417173
[Epoch 5, Batch 800] loss: 0.02320557467173785
[Epoch 5, Batch 900] loss: 0.032820367310851
[Epoch 5, Batch 1000] loss: 0.028409407758445013
[Epoch 5, Batch 1100] loss: 0.0431486033971305
[Epoch 5, Batch 1200] loss: 0.025388202676695074
[Epoch 5, Batch 1300] loss: 0.03240807521469833
[Epoch 5, Batch 1400] loss: 0.04346905903214065
[Epoch 5, Batch 1500] loss: 0.04116560461538029
[Epoch 5, Batch 1600] loss: 0.03529724302967224
[Epoch 5, Batch 1700] loss: 0.04148204611454275
[Epoch 5, Batch 1800] loss: 0.038767575259807924
[Epoch 5, Batch 1900] loss: 0.03572681123136135
[Epoch 5, Batch 2000] loss: 0.032275784336816285
[Epoch 5, Batch 2100] loss: 0.03300601990275027
[Epoch 5, Batch 2200] loss: 0.034952698980341666
[Epoch 5, Batch 2300] loss: 0.0224437043031503
[Epoch 5, Batch 2400] loss: 0.027706555924341954
[Epoch 5, Batch 2500] loss: 0.02410088755777906
[Epoch 5, Batch 2600] loss: 0.04148524989956059
[Epoch 5, Batch 2700] loss: 0.04019152811153617
[Epoch 5, Batch 2800] loss: 0.021716951587513904
[Epoch 5, Batch 2900] loss: 0.030697479086957174
[Epoch 5, Batch 3000] loss: 0.035988568196826234
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0617
Validation Accuracy: 0.9819
Overfitting: 0.0617
[Epoch 6, Batch 100] loss: 0.03712328272587911
[Epoch 6, Batch 200] loss: 0.044249756576900834
[Epoch 6, Batch 300] loss: 0.029822377676173347
[Epoch 6, Batch 400] loss: 0.02117073158355197
[Epoch 6, Batch 500] loss: 0.021448760752646193
[Epoch 6, Batch 600] loss: 0.02266964473252301
[Epoch 6, Batch 700] loss: 0.030376768895075658
[Epoch 6, Batch 800] loss: 0.035695370150351666
[Epoch 6, Batch 900] loss: 0.030432100354373687
[Epoch 6, Batch 1000] loss: 0.02552200560676283
[Epoch 6, Batch 1100] loss: 0.029542406219643453
[Epoch 6, Batch 1200] loss: 0.015868704796394014
[Epoch 6, Batch 1300] loss: 0.015341257965410478
[Epoch 6, Batch 1400] loss: 0.021950951820945194
[Epoch 6, Batch 1500] loss: 0.03030503757268889
[Epoch 6, Batch 1600] loss: 0.021143335489368836
[Epoch 6, Batch 1700] loss: 0.03791401217634302
[Epoch 6, Batch 1800] loss: 0.029954573384311515
[Epoch 6, Batch 1900] loss: 0.02579474737707642
[Epoch 6, Batch 2000] loss: 0.025023418132223016
[Epoch 6, Batch 2100] loss: 0.04367404061335037
[Epoch 6, Batch 2200] loss: 0.031853695023492036
[Epoch 6, Batch 2300] loss: 0.03178685470842538
[Epoch 6, Batch 2400] loss: 0.021102100778625753
[Epoch 6, Batch 2500] loss: 0.019141648653530866
[Epoch 6, Batch 2600] loss: 0.027805087895249016
[Epoch 6, Batch 2700] loss: 0.037608576246420854
[Epoch 6, Batch 2800] loss: 0.03011906927498785
[Epoch 6, Batch 2900] loss: 0.030617966200661612
[Epoch 6, Batch 3000] loss: 0.02540650017122971
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9867
Overfitting: 0.0450
Best model saved at epoch 6 with validation loss: 0.0450
[Epoch 7, Batch 100] loss: 0.024574475572335358
[Epoch 7, Batch 200] loss: 0.015854950758402993
[Epoch 7, Batch 300] loss: 0.01447367287990346
[Epoch 7, Batch 400] loss: 0.01376631461240322
[Epoch 7, Batch 500] loss: 0.020544776503120376
[Epoch 7, Batch 600] loss: 0.021641311100629536
[Epoch 7, Batch 700] loss: 0.019392211972299265
[Epoch 7, Batch 800] loss: 0.02198723988911297
[Epoch 7, Batch 900] loss: 0.03507173068398515
[Epoch 7, Batch 1000] loss: 0.024254645577402697
[Epoch 7, Batch 1100] loss: 0.033789099088717196
[Epoch 7, Batch 1200] loss: 0.022258312544145155
[Epoch 7, Batch 1300] loss: 0.024852953893441734
[Epoch 7, Batch 1400] loss: 0.03002599203329737
[Epoch 7, Batch 1500] loss: 0.024861936122906627
[Epoch 7, Batch 1600] loss: 0.00910553535542931
[Epoch 7, Batch 1700] loss: 0.027047830979472564
[Epoch 7, Batch 1800] loss: 0.028535017396134208
[Epoch 7, Batch 1900] loss: 0.02128565291481209
[Epoch 7, Batch 2000] loss: 0.02154355004313402
[Epoch 7, Batch 2100] loss: 0.024162648509445717
[Epoch 7, Batch 2200] loss: 0.018742013631635926
[Epoch 7, Batch 2300] loss: 0.018788601080123046
[Epoch 7, Batch 2400] loss: 0.01680125667795437
[Epoch 7, Batch 2500] loss: 0.026904289429530763
[Epoch 7, Batch 2600] loss: 0.017171881399772247
[Epoch 7, Batch 2700] loss: 0.02337417905187067
[Epoch 7, Batch 2800] loss: 0.01896604142657452
[Epoch 7, Batch 2900] loss: 0.025151629758865965
[Epoch 7, Batch 3000] loss: 0.012131272955139138
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9868
Overfitting: 0.0482
[Epoch 8, Batch 100] loss: 0.01370994309946127
[Epoch 8, Batch 200] loss: 0.02042109864220038
[Epoch 8, Batch 300] loss: 0.016448721590350032
[Epoch 8, Batch 400] loss: 0.01191848942616616
[Epoch 8, Batch 500] loss: 0.01920826134606614
[Epoch 8, Batch 600] loss: 0.022320616771057757
[Epoch 8, Batch 700] loss: 0.02388483977292708
[Epoch 8, Batch 800] loss: 0.017895529180113955
[Epoch 8, Batch 900] loss: 0.014003168370136336
[Epoch 8, Batch 1000] loss: 0.020155228945277485
[Epoch 8, Batch 1100] loss: 0.014134345482952995
[Epoch 8, Batch 1200] loss: 0.010231482072681502
[Epoch 8, Batch 1300] loss: 0.01835088768857531
[Epoch 8, Batch 1400] loss: 0.011751403825664966
[Epoch 8, Batch 1500] loss: 0.015795219807068862
[Epoch 8, Batch 1600] loss: 0.011480341744542101
[Epoch 8, Batch 1700] loss: 0.022851696280704346
[Epoch 8, Batch 1800] loss: 0.0213539362137999
[Epoch 8, Batch 1900] loss: 0.023235215825661727
[Epoch 8, Batch 2000] loss: 0.024218413728867745
[Epoch 8, Batch 2100] loss: 0.02947284675051378
[Epoch 8, Batch 2200] loss: 0.01752681626319827
[Epoch 8, Batch 2300] loss: 0.015419742691938155
[Epoch 8, Batch 2400] loss: 0.021402195156142625
[Epoch 8, Batch 2500] loss: 0.029948922226326433
[Epoch 8, Batch 2600] loss: 0.02304366412203308
[Epoch 8, Batch 2700] loss: 0.024529072450040986
[Epoch 8, Batch 2800] loss: 0.013515437966998434
[Epoch 8, Batch 2900] loss: 0.019495587061437617
[Epoch 8, Batch 3000] loss: 0.012003149193697027
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0406
Validation Accuracy: 0.9882
Overfitting: 0.0406
Best model saved at epoch 8 with validation loss: 0.0406
[Epoch 9, Batch 100] loss: 0.008612933279441676
[Epoch 9, Batch 200] loss: 0.008411854503501673
[Epoch 9, Batch 300] loss: 0.010317566751635922
[Epoch 9, Batch 400] loss: 0.010193032604111068
[Epoch 9, Batch 500] loss: 0.00772864944166372
[Epoch 9, Batch 600] loss: 0.00441894514734031
[Epoch 9, Batch 700] loss: 0.01731077224892033
[Epoch 9, Batch 800] loss: 0.017159642595238438
[Epoch 9, Batch 900] loss: 0.016054461452049508
[Epoch 9, Batch 1000] loss: 0.01780314928232656
[Epoch 9, Batch 1100] loss: 0.01696867380961976
[Epoch 9, Batch 1200] loss: 0.010709863133761245
[Epoch 9, Batch 1300] loss: 0.011562939138973433
[Epoch 9, Batch 1400] loss: 0.01781792212779237
[Epoch 9, Batch 1500] loss: 0.018417938295187924
[Epoch 9, Batch 1600] loss: 0.015916628139452767
[Epoch 9, Batch 1700] loss: 0.021572650980124307
[Epoch 9, Batch 1800] loss: 0.01996690442844738
[Epoch 9, Batch 1900] loss: 0.014580381500040858
[Epoch 9, Batch 2000] loss: 0.011397473774926538
[Epoch 9, Batch 2100] loss: 0.01931926778824959
[Epoch 9, Batch 2200] loss: 0.01965707810461936
[Epoch 9, Batch 2300] loss: 0.01578124561295226
[Epoch 9, Batch 2400] loss: 0.015334962284400717
[Epoch 9, Batch 2500] loss: 0.013632245246417369
[Epoch 9, Batch 2600] loss: 0.018986198634283937
[Epoch 9, Batch 2700] loss: 0.014793244147476799
[Epoch 9, Batch 2800] loss: 0.014188854968149372
[Epoch 9, Batch 2900] loss: 0.025308228782332663
[Epoch 9, Batch 3000] loss: 0.025983591664089544
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0547
Validation Accuracy: 0.9855
Overfitting: 0.0547
[I 2024-12-10 08:50:32,961] Trial 19 pruned. 

Selected Hyperparameters for Trial 21:
  l1: 256, l2: 64, lr: 0.008320236814708993, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.6863254278898239
**STATS for Epoch 1** : 
Average training loss: 0.1653
Average validation loss: 0.2125
Validation Accuracy: 0.9381
Overfitting: 0.0473
Best model saved at epoch 1 with validation loss: 0.2125
[Epoch 2, Batch 100] loss: 0.19228922098875045
**STATS for Epoch 2** : 
Average training loss: 0.0642
Average validation loss: 0.1175
Validation Accuracy: 0.9632
Overfitting: 0.0533
Best model saved at epoch 2 with validation loss: 0.1175
[Epoch 3, Batch 100] loss: 0.10535545136779546
**STATS for Epoch 3** : 
Average training loss: 0.0424
Average validation loss: 0.0899
Validation Accuracy: 0.9698
Overfitting: 0.0475
Best model saved at epoch 3 with validation loss: 0.0899
[Epoch 4, Batch 100] loss: 0.07592309357598424
**STATS for Epoch 4** : 
Average training loss: 0.0324
Average validation loss: 0.0752
Validation Accuracy: 0.9755
Overfitting: 0.0428
Best model saved at epoch 4 with validation loss: 0.0752
[Epoch 5, Batch 100] loss: 0.06343852791935206
**STATS for Epoch 5** : 
Average training loss: 0.0283
Average validation loss: 0.0633
Validation Accuracy: 0.9800
Overfitting: 0.0349
Best model saved at epoch 5 with validation loss: 0.0633
[Epoch 6, Batch 100] loss: 0.05235781276598573
**STATS for Epoch 6** : 
Average training loss: 0.0222
Average validation loss: 0.0573
Validation Accuracy: 0.9814
Overfitting: 0.0351
Best model saved at epoch 6 with validation loss: 0.0573
[Epoch 7, Batch 100] loss: 0.04322272578254342
**STATS for Epoch 7** : 
Average training loss: 0.0214
Average validation loss: 0.0520
Validation Accuracy: 0.9842
Overfitting: 0.0306
Best model saved at epoch 7 with validation loss: 0.0520
[Epoch 8, Batch 100] loss: 0.036336760660633446
**STATS for Epoch 8** : 
Average training loss: 0.0185
Average validation loss: 0.0490
Validation Accuracy: 0.9842
Overfitting: 0.0305
Best model saved at epoch 8 with validation loss: 0.0490
[Epoch 9, Batch 100] loss: 0.03442143780644983
**STATS for Epoch 9** : 
Average training loss: 0.0158
Average validation loss: 0.0469
Validation Accuracy: 0.9853
Overfitting: 0.0311
Best model saved at epoch 9 with validation loss: 0.0469
[Epoch 10, Batch 100] loss: 0.029821294331923126
**STATS for Epoch 10** : 
Average training loss: 0.0149
Average validation loss: 0.0466
Validation Accuracy: 0.9867
Overfitting: 0.0318
Best model saved at epoch 10 with validation loss: 0.0466
[Epoch 11, Batch 100] loss: 0.030526109877973794
**STATS for Epoch 11** : 
Average training loss: 0.0140
Average validation loss: 0.0452
Validation Accuracy: 0.9862
Overfitting: 0.0312
Best model saved at epoch 11 with validation loss: 0.0452
[Epoch 12, Batch 100] loss: 0.025724468529224397
**STATS for Epoch 12** : 
Average training loss: 0.0106
Average validation loss: 0.0420
Validation Accuracy: 0.9873
Overfitting: 0.0314
Best model saved at epoch 12 with validation loss: 0.0420
[Epoch 13, Batch 100] loss: 0.02302794488845393
**STATS for Epoch 13** : 
Average training loss: 0.0111
Average validation loss: 0.0479
Validation Accuracy: 0.9862
Overfitting: 0.0368
[Epoch 14, Batch 100] loss: 0.021537333845626564
**STATS for Epoch 14** : 
Average training loss: 0.0101
Average validation loss: 0.0442
Validation Accuracy: 0.9868
Overfitting: 0.0342
[Epoch 15, Batch 100] loss: 0.0182946285023354
**STATS for Epoch 15** : 
Average training loss: 0.0104
Average validation loss: 0.0421
Validation Accuracy: 0.9875
Overfitting: 0.0317
[Epoch 16, Batch 100] loss: 0.014516078034648671
**STATS for Epoch 16** : 
Average training loss: 0.0082
Average validation loss: 0.0432
Validation Accuracy: 0.9879
Overfitting: 0.0350
[Epoch 17, Batch 100] loss: 0.015732751346658917
**STATS for Epoch 17** : 
Average training loss: 0.0076
Average validation loss: 0.0466
Validation Accuracy: 0.9866
Overfitting: 0.0390
[Epoch 18, Batch 100] loss: 0.016140924778301268
**STATS for Epoch 18** : 
Average training loss: 0.0056
Average validation loss: 0.0431
Validation Accuracy: 0.9877
Overfitting: 0.0375
[Epoch 19, Batch 100] loss: 0.011826147789834067
**STATS for Epoch 19** : 
Average training loss: 0.0065
Average validation loss: 0.0406
Validation Accuracy: 0.9888
Overfitting: 0.0341
Best model saved at epoch 19 with validation loss: 0.0406
[Epoch 20, Batch 100] loss: 0.009517585156136193
**STATS for Epoch 20** : 
Average training loss: 0.0060
Average validation loss: 0.0428
Validation Accuracy: 0.9882
Overfitting: 0.0368
[Epoch 21, Batch 100] loss: 0.010081375839654357
**STATS for Epoch 21** : 
Average training loss: 0.0045
Average validation loss: 0.0414
Validation Accuracy: 0.9886
Overfitting: 0.0369
[Epoch 22, Batch 100] loss: 0.009045652315253392
**STATS for Epoch 22** : 
Average training loss: 0.0049
Average validation loss: 0.0454
Validation Accuracy: 0.9882
Overfitting: 0.0405
[Epoch 23, Batch 100] loss: 0.010976755482843145
**STATS for Epoch 23** : 
Average training loss: 0.0035
Average validation loss: 0.0460
Validation Accuracy: 0.9881
Overfitting: 0.0425
[Epoch 24, Batch 100] loss: 0.007838436289457604
**STATS for Epoch 24** : 
Average training loss: 0.0032
Average validation loss: 0.0510
Validation Accuracy: 0.9873
Overfitting: 0.0478
Fold 1 validation loss: 0.0510
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.5420044243335724
**STATS for Epoch 1** : 
Average training loss: 0.1574
Average validation loss: 0.2721
Validation Accuracy: 0.9188
Overfitting: 0.1147
Best model saved at epoch 1 with validation loss: 0.2721
[Epoch 2, Batch 100] loss: 0.21006638184189796
**STATS for Epoch 2** : 
Average training loss: 0.0654
Average validation loss: 0.1402
Validation Accuracy: 0.9570
Overfitting: 0.0748
Best model saved at epoch 2 with validation loss: 0.1402
[Epoch 3, Batch 100] loss: 0.10905023146420717
**STATS for Epoch 3** : 
Average training loss: 0.0439
Average validation loss: 0.1010
Validation Accuracy: 0.9683
Overfitting: 0.0570
Best model saved at epoch 3 with validation loss: 0.1010
[Epoch 4, Batch 100] loss: 0.07872364986687899
**STATS for Epoch 4** : 
Average training loss: 0.0364
Average validation loss: 0.0802
Validation Accuracy: 0.9752
Overfitting: 0.0438
Best model saved at epoch 4 with validation loss: 0.0802
[Epoch 5, Batch 100] loss: 0.06607132432982325
**STATS for Epoch 5** : 
Average training loss: 0.0296
Average validation loss: 0.0795
Validation Accuracy: 0.9760
Overfitting: 0.0499
Best model saved at epoch 5 with validation loss: 0.0795
[Epoch 6, Batch 100] loss: 0.0554917832929641
**STATS for Epoch 6** : 
Average training loss: 0.0230
Average validation loss: 0.0648
Validation Accuracy: 0.9802
Overfitting: 0.0418
Best model saved at epoch 6 with validation loss: 0.0648
[Epoch 7, Batch 100] loss: 0.044931425591930745
**STATS for Epoch 7** : 
Average training loss: 0.0219
Average validation loss: 0.0646
Validation Accuracy: 0.9804
Overfitting: 0.0427
Best model saved at epoch 7 with validation loss: 0.0646
[Epoch 8, Batch 100] loss: 0.03793771093711257
**STATS for Epoch 8** : 
Average training loss: 0.0204
Average validation loss: 0.0576
Validation Accuracy: 0.9822
Overfitting: 0.0373
Best model saved at epoch 8 with validation loss: 0.0576
[Epoch 9, Batch 100] loss: 0.033632730762474236
**STATS for Epoch 9** : 
Average training loss: 0.0169
Average validation loss: 0.0574
Validation Accuracy: 0.9829
Overfitting: 0.0405
Best model saved at epoch 9 with validation loss: 0.0574
[Epoch 10, Batch 100] loss: 0.0312541243294254
**STATS for Epoch 10** : 
Average training loss: 0.0144
Average validation loss: 0.0531
Validation Accuracy: 0.9842
Overfitting: 0.0387
Best model saved at epoch 10 with validation loss: 0.0531
[Epoch 11, Batch 100] loss: 0.026388658890500665
**STATS for Epoch 11** : 
Average training loss: 0.0137
Average validation loss: 0.0584
Validation Accuracy: 0.9822
Overfitting: 0.0447
[Epoch 12, Batch 100] loss: 0.025689378571696578
**STATS for Epoch 12** : 
Average training loss: 0.0116
Average validation loss: 0.0596
Validation Accuracy: 0.9820
Overfitting: 0.0481
[Epoch 13, Batch 100] loss: 0.02026774894213304
**STATS for Epoch 13** : 
Average training loss: 0.0120
Average validation loss: 0.0518
Validation Accuracy: 0.9847
Overfitting: 0.0398
Best model saved at epoch 13 with validation loss: 0.0518
[Epoch 14, Batch 100] loss: 0.019993167174980044
**STATS for Epoch 14** : 
Average training loss: 0.0111
Average validation loss: 0.0593
Validation Accuracy: 0.9828
Overfitting: 0.0483
[Epoch 15, Batch 100] loss: 0.01976365643553436
**STATS for Epoch 15** : 
Average training loss: 0.0086
Average validation loss: 0.0533
Validation Accuracy: 0.9846
Overfitting: 0.0447
[Epoch 16, Batch 100] loss: 0.01627733931876719
**STATS for Epoch 16** : 
Average training loss: 0.0094
Average validation loss: 0.0513
Validation Accuracy: 0.9853
Overfitting: 0.0419
Best model saved at epoch 16 with validation loss: 0.0513
[Epoch 17, Batch 100] loss: 0.013894485323689879
**STATS for Epoch 17** : 
Average training loss: 0.0081
Average validation loss: 0.0562
Validation Accuracy: 0.9846
Overfitting: 0.0481
[Epoch 18, Batch 100] loss: 0.014473636236507445
**STATS for Epoch 18** : 
Average training loss: 0.0065
Average validation loss: 0.0515
Validation Accuracy: 0.9854
Overfitting: 0.0449
[Epoch 19, Batch 100] loss: 0.011428281454136595
**STATS for Epoch 19** : 
Average training loss: 0.0060
Average validation loss: 0.0561
Validation Accuracy: 0.9848
Overfitting: 0.0501
[Epoch 20, Batch 100] loss: 0.009901710242265835
**STATS for Epoch 20** : 
Average training loss: 0.0061
Average validation loss: 0.0648
Validation Accuracy: 0.9837
Overfitting: 0.0586
[Epoch 21, Batch 100] loss: 0.011428178545320406
**STATS for Epoch 21** : 
Average training loss: 0.0052
Average validation loss: 0.0554
Validation Accuracy: 0.9849
Overfitting: 0.0502
[Epoch 22, Batch 100] loss: 0.008780268811970018
**STATS for Epoch 22** : 
Average training loss: 0.0039
Average validation loss: 0.0532
Validation Accuracy: 0.9866
Overfitting: 0.0493
[Epoch 23, Batch 100] loss: 0.008397263431106694
**STATS for Epoch 23** : 
Average training loss: 0.0043
Average validation loss: 0.0542
Validation Accuracy: 0.9859
Overfitting: 0.0500
[Epoch 24, Batch 100] loss: 0.006177137981285341
**STATS for Epoch 24** : 
Average training loss: 0.0046
Average validation loss: 0.0549
Validation Accuracy: 0.9861
Overfitting: 0.0503
Fold 2 validation loss: 0.0549
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 1.5739438897371292
**STATS for Epoch 1** : 
Average training loss: 0.1442
Average validation loss: 0.2203
Validation Accuracy: 0.9368
Overfitting: 0.0761
Best model saved at epoch 1 with validation loss: 0.2203
[Epoch 2, Batch 100] loss: 0.1756827048957348
**STATS for Epoch 2** : 
Average training loss: 0.0643
Average validation loss: 0.1169
Validation Accuracy: 0.9648
Overfitting: 0.0526
Best model saved at epoch 2 with validation loss: 0.1169
[Epoch 3, Batch 100] loss: 0.09737921837717295
**STATS for Epoch 3** : 
Average training loss: 0.0429
Average validation loss: 0.1037
Validation Accuracy: 0.9683
Overfitting: 0.0607
Best model saved at epoch 3 with validation loss: 0.1037
[Epoch 4, Batch 100] loss: 0.07719324653968215
**STATS for Epoch 4** : 
Average training loss: 0.0336
Average validation loss: 0.0935
Validation Accuracy: 0.9700
Overfitting: 0.0599
Best model saved at epoch 4 with validation loss: 0.0935
[Epoch 5, Batch 100] loss: 0.06445685729384422
**STATS for Epoch 5** : 
Average training loss: 0.0292
Average validation loss: 0.0639
Validation Accuracy: 0.9795
Overfitting: 0.0347
Best model saved at epoch 5 with validation loss: 0.0639
[Epoch 6, Batch 100] loss: 0.05392303686589003
**STATS for Epoch 6** : 
Average training loss: 0.0268
Average validation loss: 0.0704
Validation Accuracy: 0.9782
Overfitting: 0.0436
[Epoch 7, Batch 100] loss: 0.04687812753021717
**STATS for Epoch 7** : 
Average training loss: 0.0237
Average validation loss: 0.0549
Validation Accuracy: 0.9832
Overfitting: 0.0312
Best model saved at epoch 7 with validation loss: 0.0549
[Epoch 8, Batch 100] loss: 0.04053507829550654
**STATS for Epoch 8** : 
Average training loss: 0.0206
Average validation loss: 0.0635
Validation Accuracy: 0.9799
Overfitting: 0.0429
[Epoch 9, Batch 100] loss: 0.038065973930060865
**STATS for Epoch 9** : 
Average training loss: 0.0172
Average validation loss: 0.0521
Validation Accuracy: 0.9846
Overfitting: 0.0349
Best model saved at epoch 9 with validation loss: 0.0521
[Epoch 10, Batch 100] loss: 0.03324005727656185
**STATS for Epoch 10** : 
Average training loss: 0.0163
Average validation loss: 0.0514
Validation Accuracy: 0.9831
Overfitting: 0.0352
Best model saved at epoch 10 with validation loss: 0.0514
[Epoch 11, Batch 100] loss: 0.029586557233706116
**STATS for Epoch 11** : 
Average training loss: 0.0145
Average validation loss: 0.0508
Validation Accuracy: 0.9846
Overfitting: 0.0363
Best model saved at epoch 11 with validation loss: 0.0508
[Epoch 12, Batch 100] loss: 0.027450929507613183
**STATS for Epoch 12** : 
Average training loss: 0.0123
Average validation loss: 0.0440
Validation Accuracy: 0.9866
Overfitting: 0.0316
Best model saved at epoch 12 with validation loss: 0.0440
[Epoch 13, Batch 100] loss: 0.023449129117652776
**STATS for Epoch 13** : 
Average training loss: 0.0115
Average validation loss: 0.0451
Validation Accuracy: 0.9865
Overfitting: 0.0337
[Epoch 14, Batch 100] loss: 0.022590139242820443
**STATS for Epoch 14** : 
Average training loss: 0.0100
Average validation loss: 0.0464
Validation Accuracy: 0.9869
Overfitting: 0.0364
[Epoch 15, Batch 100] loss: 0.02222939756931737
**STATS for Epoch 15** : 
Average training loss: 0.0084
Average validation loss: 0.0474
Validation Accuracy: 0.9859
Overfitting: 0.0390
[Epoch 16, Batch 100] loss: 0.017131446551065892
**STATS for Epoch 16** : 
Average training loss: 0.0085
Average validation loss: 0.0434
Validation Accuracy: 0.9879
Overfitting: 0.0349
Best model saved at epoch 16 with validation loss: 0.0434
[Epoch 17, Batch 100] loss: 0.017224884920287876
**STATS for Epoch 17** : 
Average training loss: 0.0067
Average validation loss: 0.0471
Validation Accuracy: 0.9865
Overfitting: 0.0404
[Epoch 18, Batch 100] loss: 0.01589678426971659
**STATS for Epoch 18** : 
Average training loss: 0.0071
Average validation loss: 0.0439
Validation Accuracy: 0.9876
Overfitting: 0.0369
[Epoch 19, Batch 100] loss: 0.010381316839484497
**STATS for Epoch 19** : 
Average training loss: 0.0065
Average validation loss: 0.0448
Validation Accuracy: 0.9868
Overfitting: 0.0383
[Epoch 20, Batch 100] loss: 0.010156252008164302
**STATS for Epoch 20** : 
Average training loss: 0.0057
Average validation loss: 0.0421
Validation Accuracy: 0.9887
Overfitting: 0.0364
Best model saved at epoch 20 with validation loss: 0.0421
[Epoch 21, Batch 100] loss: 0.008919671292533167
**STATS for Epoch 21** : 
Average training loss: 0.0053
Average validation loss: 0.0439
Validation Accuracy: 0.9890
Overfitting: 0.0386
[Epoch 22, Batch 100] loss: 0.006944428760325536
**STATS for Epoch 22** : 
Average training loss: 0.0040
Average validation loss: 0.0516
Validation Accuracy: 0.9862
Overfitting: 0.0476
[Epoch 23, Batch 100] loss: 0.0072007568532717415
**STATS for Epoch 23** : 
Average training loss: 0.0034
Average validation loss: 0.0436
Validation Accuracy: 0.9896
Overfitting: 0.0402
[Epoch 24, Batch 100] loss: 0.006448672486003488
**STATS for Epoch 24** : 
Average training loss: 0.0038
Average validation loss: 0.0445
Validation Accuracy: 0.9886
Overfitting: 0.0407
Fold 3 validation loss: 0.0445
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.5075106278061867
**STATS for Epoch 1** : 
Average training loss: 0.1371
Average validation loss: 0.2371
Validation Accuracy: 0.9244
Overfitting: 0.1000
Best model saved at epoch 1 with validation loss: 0.2371
[Epoch 2, Batch 100] loss: 0.18885025076568127
**STATS for Epoch 2** : 
Average training loss: 0.0672
Average validation loss: 0.1419
Validation Accuracy: 0.9556
Overfitting: 0.0747
Best model saved at epoch 2 with validation loss: 0.1419
[Epoch 3, Batch 100] loss: 0.11291494246572256
**STATS for Epoch 3** : 
Average training loss: 0.0484
Average validation loss: 0.0962
Validation Accuracy: 0.9692
Overfitting: 0.0477
Best model saved at epoch 3 with validation loss: 0.0962
[Epoch 4, Batch 100] loss: 0.08463994149118662
**STATS for Epoch 4** : 
Average training loss: 0.0370
Average validation loss: 0.0771
Validation Accuracy: 0.9751
Overfitting: 0.0401
Best model saved at epoch 4 with validation loss: 0.0771
[Epoch 5, Batch 100] loss: 0.06882543090730905
**STATS for Epoch 5** : 
Average training loss: 0.0314
Average validation loss: 0.0762
Validation Accuracy: 0.9755
Overfitting: 0.0448
Best model saved at epoch 5 with validation loss: 0.0762
[Epoch 6, Batch 100] loss: 0.05517266372218728
**STATS for Epoch 6** : 
Average training loss: 0.0277
Average validation loss: 0.0634
Validation Accuracy: 0.9811
Overfitting: 0.0357
Best model saved at epoch 6 with validation loss: 0.0634
[Epoch 7, Batch 100] loss: 0.04937477819621563
**STATS for Epoch 7** : 
Average training loss: 0.0222
Average validation loss: 0.0557
Validation Accuracy: 0.9826
Overfitting: 0.0335
Best model saved at epoch 7 with validation loss: 0.0557
[Epoch 8, Batch 100] loss: 0.04217574371956289
**STATS for Epoch 8** : 
Average training loss: 0.0214
Average validation loss: 0.0807
Validation Accuracy: 0.9752
Overfitting: 0.0594
[Epoch 9, Batch 100] loss: 0.03749700635205954
**STATS for Epoch 9** : 
Average training loss: 0.0196
Average validation loss: 0.0592
Validation Accuracy: 0.9818
Overfitting: 0.0396
[Epoch 10, Batch 100] loss: 0.03665112905204296
**STATS for Epoch 10** : 
Average training loss: 0.0141
Average validation loss: 0.0507
Validation Accuracy: 0.9842
Overfitting: 0.0367
Best model saved at epoch 10 with validation loss: 0.0507
[Epoch 11, Batch 100] loss: 0.031618618690408766
**STATS for Epoch 11** : 
Average training loss: 0.0137
Average validation loss: 0.0495
Validation Accuracy: 0.9839
Overfitting: 0.0358
Best model saved at epoch 11 with validation loss: 0.0495
[Epoch 12, Batch 100] loss: 0.028586164014413953
**STATS for Epoch 12** : 
Average training loss: 0.0118
Average validation loss: 0.0493
Validation Accuracy: 0.9848
Overfitting: 0.0375
Best model saved at epoch 12 with validation loss: 0.0493
[Epoch 13, Batch 100] loss: 0.024585191216319798
**STATS for Epoch 13** : 
Average training loss: 0.0132
Average validation loss: 0.0473
Validation Accuracy: 0.9847
Overfitting: 0.0341
Best model saved at epoch 13 with validation loss: 0.0473
[Epoch 14, Batch 100] loss: 0.023576222427655013
**STATS for Epoch 14** : 
Average training loss: 0.0109
Average validation loss: 0.0443
Validation Accuracy: 0.9862
Overfitting: 0.0334
Best model saved at epoch 14 with validation loss: 0.0443
[Epoch 15, Batch 100] loss: 0.021048247134312987
**STATS for Epoch 15** : 
Average training loss: 0.0100
Average validation loss: 0.0417
Validation Accuracy: 0.9868
Overfitting: 0.0317
Best model saved at epoch 15 with validation loss: 0.0417
[Epoch 16, Batch 100] loss: 0.01664762375643477
**STATS for Epoch 16** : 
Average training loss: 0.0093
Average validation loss: 0.0471
Validation Accuracy: 0.9859
Overfitting: 0.0378
[Epoch 17, Batch 100] loss: 0.016128878605086355
**STATS for Epoch 17** : 
Average training loss: 0.0079
Average validation loss: 0.0451
Validation Accuracy: 0.9858
Overfitting: 0.0371
[Epoch 18, Batch 100] loss: 0.0137052762391977
**STATS for Epoch 18** : 
Average training loss: 0.0064
Average validation loss: 0.0430
Validation Accuracy: 0.9879
Overfitting: 0.0366
[Epoch 19, Batch 100] loss: 0.01191843676730059
**STATS for Epoch 19** : 
Average training loss: 0.0055
Average validation loss: 0.0421
Validation Accuracy: 0.9878
Overfitting: 0.0366
[Epoch 20, Batch 100] loss: 0.010523344328976236
**STATS for Epoch 20** : 
Average training loss: 0.0058
Average validation loss: 0.0446
Validation Accuracy: 0.9861
Overfitting: 0.0387
[Epoch 21, Batch 100] loss: 0.011144997269148006
**STATS for Epoch 21** : 
Average training loss: 0.0045
Average validation loss: 0.0450
Validation Accuracy: 0.9881
Overfitting: 0.0405
[Epoch 22, Batch 100] loss: 0.009512551079969853
**STATS for Epoch 22** : 
Average training loss: 0.0046
Average validation loss: 0.0440
Validation Accuracy: 0.9878
Overfitting: 0.0394
[Epoch 23, Batch 100] loss: 0.009085944722173736
**STATS for Epoch 23** : 
Average training loss: 0.0034
Average validation loss: 0.0453
Validation Accuracy: 0.9880
Overfitting: 0.0419
[Epoch 24, Batch 100] loss: 0.005619393564411439
**STATS for Epoch 24** : 
Average training loss: 0.0031
Average validation loss: 0.0491
Validation Accuracy: 0.9862
Overfitting: 0.0460
Fold 4 validation loss: 0.0491
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 1.629726891517639
**STATS for Epoch 1** : 
Average training loss: 0.1297
Average validation loss: 0.2039
Validation Accuracy: 0.9403
Overfitting: 0.0741
Best model saved at epoch 1 with validation loss: 0.2039
[Epoch 2, Batch 100] loss: 0.16343070946633817
**STATS for Epoch 2** : 
Average training loss: 0.0548
Average validation loss: 0.1223
Validation Accuracy: 0.9634
Overfitting: 0.0676
Best model saved at epoch 2 with validation loss: 0.1223
[Epoch 3, Batch 100] loss: 0.09806244099512697
**STATS for Epoch 3** : 
Average training loss: 0.0436
Average validation loss: 0.0937
Validation Accuracy: 0.9717
Overfitting: 0.0501
Best model saved at epoch 3 with validation loss: 0.0937
[Epoch 4, Batch 100] loss: 0.07592052875086665
**STATS for Epoch 4** : 
Average training loss: 0.0327
Average validation loss: 0.0714
Validation Accuracy: 0.9778
Overfitting: 0.0387
Best model saved at epoch 4 with validation loss: 0.0714
[Epoch 5, Batch 100] loss: 0.059915203414857385
**STATS for Epoch 5** : 
Average training loss: 0.0283
Average validation loss: 0.0609
Validation Accuracy: 0.9812
Overfitting: 0.0327
Best model saved at epoch 5 with validation loss: 0.0609
[Epoch 6, Batch 100] loss: 0.05188113920390606
**STATS for Epoch 6** : 
Average training loss: 0.0261
Average validation loss: 0.0570
Validation Accuracy: 0.9823
Overfitting: 0.0309
Best model saved at epoch 6 with validation loss: 0.0570
[Epoch 7, Batch 100] loss: 0.04474315325729549
**STATS for Epoch 7** : 
Average training loss: 0.0224
Average validation loss: 0.0520
Validation Accuracy: 0.9837
Overfitting: 0.0296
Best model saved at epoch 7 with validation loss: 0.0520
[Epoch 8, Batch 100] loss: 0.040582190775312485
**STATS for Epoch 8** : 
Average training loss: 0.0196
Average validation loss: 0.0528
Validation Accuracy: 0.9832
Overfitting: 0.0332
[Epoch 9, Batch 100] loss: 0.037832713695243
**STATS for Epoch 9** : 
Average training loss: 0.0179
Average validation loss: 0.0562
Validation Accuracy: 0.9820
Overfitting: 0.0383
[Epoch 10, Batch 100] loss: 0.034790076673962174
**STATS for Epoch 10** : 
Average training loss: 0.0152
Average validation loss: 0.0484
Validation Accuracy: 0.9844
Overfitting: 0.0332
Best model saved at epoch 10 with validation loss: 0.0484
[Epoch 11, Batch 100] loss: 0.029188574068248273
**STATS for Epoch 11** : 
Average training loss: 0.0140
Average validation loss: 0.0438
Validation Accuracy: 0.9852
Overfitting: 0.0297
Best model saved at epoch 11 with validation loss: 0.0438
[Epoch 12, Batch 100] loss: 0.02478830627631396
**STATS for Epoch 12** : 
Average training loss: 0.0132
Average validation loss: 0.0479
Validation Accuracy: 0.9859
Overfitting: 0.0347
[Epoch 13, Batch 100] loss: 0.024184008622542025
**STATS for Epoch 13** : 
Average training loss: 0.0124
Average validation loss: 0.0416
Validation Accuracy: 0.9879
Overfitting: 0.0292
Best model saved at epoch 13 with validation loss: 0.0416
[Epoch 14, Batch 100] loss: 0.02253016295377165
**STATS for Epoch 14** : 
Average training loss: 0.0103
Average validation loss: 0.0431
Validation Accuracy: 0.9875
Overfitting: 0.0328
[Epoch 15, Batch 100] loss: 0.020640770974569022
**STATS for Epoch 15** : 
Average training loss: 0.0111
Average validation loss: 0.0470
Validation Accuracy: 0.9854
Overfitting: 0.0359
[Epoch 16, Batch 100] loss: 0.01876380227506161
**STATS for Epoch 16** : 
Average training loss: 0.0091
Average validation loss: 0.0396
Validation Accuracy: 0.9883
Overfitting: 0.0305
Best model saved at epoch 16 with validation loss: 0.0396
[Epoch 17, Batch 100] loss: 0.01743154669413343
**STATS for Epoch 17** : 
Average training loss: 0.0079
Average validation loss: 0.0437
Validation Accuracy: 0.9880
Overfitting: 0.0358
[Epoch 18, Batch 100] loss: 0.014855137497652321
**STATS for Epoch 18** : 
Average training loss: 0.0082
Average validation loss: 0.0422
Validation Accuracy: 0.9880
Overfitting: 0.0340
[Epoch 19, Batch 100] loss: 0.013535163684282451
**STATS for Epoch 19** : 
Average training loss: 0.0064
Average validation loss: 0.0407
Validation Accuracy: 0.9882
Overfitting: 0.0343
[Epoch 20, Batch 100] loss: 0.01173609536665026
**STATS for Epoch 20** : 
Average training loss: 0.0059
Average validation loss: 0.0423
Validation Accuracy: 0.9885
Overfitting: 0.0365
[Epoch 21, Batch 100] loss: 0.011499191571492701
**STATS for Epoch 21** : 
Average training loss: 0.0055
Average validation loss: 0.0431
Validation Accuracy: 0.9888
Overfitting: 0.0376
[Epoch 22, Batch 100] loss: 0.01007139664143324
**STATS for Epoch 22** : 
Average training loss: 0.0046
Average validation loss: 0.0402
Validation Accuracy: 0.9888
Overfitting: 0.0355
[Epoch 23, Batch 100] loss: 0.007748189514386467
**STATS for Epoch 23** : 
Average training loss: 0.0046
Average validation loss: 0.0404
Validation Accuracy: 0.9884
Overfitting: 0.0358
[Epoch 24, Batch 100] loss: 0.00748583318432793
**STATS for Epoch 24** : 
Average training loss: 0.0036
Average validation loss: 0.0469
Validation Accuracy: 0.9877
Overfitting: 0.0433
Fold 5 validation loss: 0.0469
Mean validation loss across all folds for Trial 21 is 0.0493 with trial config:  l1: 256, l2: 64, lr: 0.008320236814708993, batch_size: 256
[I 2024-12-10 09:08:09,385] Trial 20 finished with value: 0.04930006756467071 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.008320236814708993, 'batch_size': 256}. Best is trial 16 with value: 0.04722271221232811.

Selected Hyperparameters for Trial 22:
  l1: 256, l2: 64, lr: 0.0028290898987210033, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2422286653518677
**STATS for Epoch 1** : 
Average training loss: 0.5213
Average validation loss: 0.5019
Validation Accuracy: 0.8492
Overfitting: -0.0194
Best model saved at epoch 1 with validation loss: 0.5019
[Epoch 2, Batch 100] loss: 0.40994964838027953
**STATS for Epoch 2** : 
Average training loss: 0.1285
Average validation loss: 0.2324
Validation Accuracy: 0.9320
Overfitting: 0.1039
Best model saved at epoch 2 with validation loss: 0.2324
[Epoch 3, Batch 100] loss: 0.21924498736858367
**STATS for Epoch 3** : 
Average training loss: 0.0868
Average validation loss: 0.1542
Validation Accuracy: 0.9546
Overfitting: 0.0675
Best model saved at epoch 3 with validation loss: 0.1542
[Epoch 4, Batch 100] loss: 0.15917620085179807
**STATS for Epoch 4** : 
Average training loss: 0.0662
Average validation loss: 0.1259
Validation Accuracy: 0.9611
Overfitting: 0.0597
Best model saved at epoch 4 with validation loss: 0.1259
[Epoch 5, Batch 100] loss: 0.12294793251901864
**STATS for Epoch 5** : 
Average training loss: 0.0555
Average validation loss: 0.1042
Validation Accuracy: 0.9680
Overfitting: 0.0487
Best model saved at epoch 5 with validation loss: 0.1042
[Epoch 6, Batch 100] loss: 0.10837001103907823
**STATS for Epoch 6** : 
Average training loss: 0.0468
Average validation loss: 0.0898
Validation Accuracy: 0.9718
Overfitting: 0.0431
Best model saved at epoch 6 with validation loss: 0.0898
[Epoch 7, Batch 100] loss: 0.09229640878736972
**STATS for Epoch 7** : 
Average training loss: 0.0439
Average validation loss: 0.0774
Validation Accuracy: 0.9764
Overfitting: 0.0336
Best model saved at epoch 7 with validation loss: 0.0774
[Epoch 8, Batch 100] loss: 0.08423822101205587
**STATS for Epoch 8** : 
Average training loss: 0.0368
Average validation loss: 0.0809
Validation Accuracy: 0.9748
Overfitting: 0.0441
[Epoch 9, Batch 100] loss: 0.08043854450806975
**STATS for Epoch 9** : 
Average training loss: 0.0344
Average validation loss: 0.0721
Validation Accuracy: 0.9770
Overfitting: 0.0377
[I 2024-12-10 09:09:28,503] Trial 21 pruned. 

Selected Hyperparameters for Trial 23:
  l1: 256, l2: 64, lr: 0.006307908822596799, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.833705604672432
**STATS for Epoch 1** : 
Average training loss: 0.1869
Average validation loss: 0.2643
Validation Accuracy: 0.9217
Overfitting: 0.0773
Best model saved at epoch 1 with validation loss: 0.2643
[Epoch 2, Batch 100] loss: 0.22537245377898216
**STATS for Epoch 2** : 
Average training loss: 0.0857
Average validation loss: 0.1478
Validation Accuracy: 0.9535
Overfitting: 0.0621
Best model saved at epoch 2 with validation loss: 0.1478
[Epoch 3, Batch 100] loss: 0.13511222548782825
**STATS for Epoch 3** : 
Average training loss: 0.0555
Average validation loss: 0.1027
Validation Accuracy: 0.9686
Overfitting: 0.0472
Best model saved at epoch 3 with validation loss: 0.1027
[Epoch 4, Batch 100] loss: 0.10086588010191917
**STATS for Epoch 4** : 
Average training loss: 0.0437
Average validation loss: 0.0904
Validation Accuracy: 0.9714
Overfitting: 0.0467
Best model saved at epoch 4 with validation loss: 0.0904
[Epoch 5, Batch 100] loss: 0.0808047278225422
**STATS for Epoch 5** : 
Average training loss: 0.0356
Average validation loss: 0.0703
Validation Accuracy: 0.9772
Overfitting: 0.0347
Best model saved at epoch 5 with validation loss: 0.0703
[Epoch 6, Batch 100] loss: 0.07166631877422333
**STATS for Epoch 6** : 
Average training loss: 0.0282
Average validation loss: 0.0698
Validation Accuracy: 0.9788
Overfitting: 0.0416
Best model saved at epoch 6 with validation loss: 0.0698
[Epoch 7, Batch 100] loss: 0.05829500823281705
**STATS for Epoch 7** : 
Average training loss: 0.0263
Average validation loss: 0.0609
Validation Accuracy: 0.9814
Overfitting: 0.0346
Best model saved at epoch 7 with validation loss: 0.0609
[Epoch 8, Batch 100] loss: 0.05329047545790672
**STATS for Epoch 8** : 
Average training loss: 0.0237
Average validation loss: 0.0554
Validation Accuracy: 0.9839
Overfitting: 0.0317
Best model saved at epoch 8 with validation loss: 0.0554
[Epoch 9, Batch 100] loss: 0.04693651399575174
**STATS for Epoch 9** : 
Average training loss: 0.0208
Average validation loss: 0.0506
Validation Accuracy: 0.9849
Overfitting: 0.0298
Best model saved at epoch 9 with validation loss: 0.0506
[Epoch 10, Batch 100] loss: 0.039278745390474795
**STATS for Epoch 10** : 
Average training loss: 0.0204
Average validation loss: 0.0568
Validation Accuracy: 0.9827
Overfitting: 0.0363
[Epoch 11, Batch 100] loss: 0.03591516457963735
**STATS for Epoch 11** : 
Average training loss: 0.0183
Average validation loss: 0.0455
Validation Accuracy: 0.9860
Overfitting: 0.0272
Best model saved at epoch 11 with validation loss: 0.0455
[Epoch 12, Batch 100] loss: 0.03262200156226754
**STATS for Epoch 12** : 
Average training loss: 0.0176
Average validation loss: 0.0489
Validation Accuracy: 0.9851
Overfitting: 0.0314
[Epoch 13, Batch 100] loss: 0.03023629370611161
**STATS for Epoch 13** : 
Average training loss: 0.0144
Average validation loss: 0.0471
Validation Accuracy: 0.9852
Overfitting: 0.0326
[Epoch 14, Batch 100] loss: 0.027180639980360865
**STATS for Epoch 14** : 
Average training loss: 0.0138
Average validation loss: 0.0450
Validation Accuracy: 0.9862
Overfitting: 0.0312
Best model saved at epoch 14 with validation loss: 0.0450
[Epoch 15, Batch 100] loss: 0.026629328331910073
**STATS for Epoch 15** : 
Average training loss: 0.0114
Average validation loss: 0.0419
Validation Accuracy: 0.9879
Overfitting: 0.0305
Best model saved at epoch 15 with validation loss: 0.0419
[Epoch 16, Batch 100] loss: 0.02339995943941176
**STATS for Epoch 16** : 
Average training loss: 0.0111
Average validation loss: 0.0463
Validation Accuracy: 0.9854
Overfitting: 0.0352
[Epoch 17, Batch 100] loss: 0.024098559259437026
**STATS for Epoch 17** : 
Average training loss: 0.0098
Average validation loss: 0.0389
Validation Accuracy: 0.9887
Overfitting: 0.0290
Best model saved at epoch 17 with validation loss: 0.0389
[Epoch 18, Batch 100] loss: 0.018711802274920045
**STATS for Epoch 18** : 
Average training loss: 0.0105
Average validation loss: 0.0455
Validation Accuracy: 0.9863
Overfitting: 0.0350
[Epoch 19, Batch 100] loss: 0.01744953840970993
**STATS for Epoch 19** : 
Average training loss: 0.0094
Average validation loss: 0.0398
Validation Accuracy: 0.9891
Overfitting: 0.0305
[Epoch 20, Batch 100] loss: 0.015496139025781303
**STATS for Epoch 20** : 
Average training loss: 0.0089
Average validation loss: 0.0460
Validation Accuracy: 0.9868
Overfitting: 0.0371
[Epoch 21, Batch 100] loss: 0.01534221466514282
**STATS for Epoch 21** : 
Average training loss: 0.0085
Average validation loss: 0.0421
Validation Accuracy: 0.9888
Overfitting: 0.0336
[Epoch 22, Batch 100] loss: 0.014405939509160817
**STATS for Epoch 22** : 
Average training loss: 0.0065
Average validation loss: 0.0378
Validation Accuracy: 0.9900
Overfitting: 0.0314
Best model saved at epoch 22 with validation loss: 0.0378
[Epoch 23, Batch 100] loss: 0.012426185201620683
**STATS for Epoch 23** : 
Average training loss: 0.0064
Average validation loss: 0.0401
Validation Accuracy: 0.9887
Overfitting: 0.0336
[Epoch 24, Batch 100] loss: 0.013028846076922491
**STATS for Epoch 24** : 
Average training loss: 0.0067
Average validation loss: 0.0403
Validation Accuracy: 0.9888
Overfitting: 0.0335
Fold 1 validation loss: 0.0403
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.9648550057411194
**STATS for Epoch 1** : 
Average training loss: 0.1691
Average validation loss: 0.2733
Validation Accuracy: 0.9171
Overfitting: 0.1043
Best model saved at epoch 1 with validation loss: 0.2733
[Epoch 2, Batch 100] loss: 0.19805011093616487
**STATS for Epoch 2** : 
Average training loss: 0.0735
Average validation loss: 0.1657
Validation Accuracy: 0.9481
Overfitting: 0.0922
Best model saved at epoch 2 with validation loss: 0.1657
[Epoch 3, Batch 100] loss: 0.1281663316488266
**STATS for Epoch 3** : 
Average training loss: 0.0508
Average validation loss: 0.1151
Validation Accuracy: 0.9649
Overfitting: 0.0643
Best model saved at epoch 3 with validation loss: 0.1151
[Epoch 4, Batch 100] loss: 0.09741047415882349
**STATS for Epoch 4** : 
Average training loss: 0.0419
Average validation loss: 0.1081
Validation Accuracy: 0.9698
Overfitting: 0.0662
Best model saved at epoch 4 with validation loss: 0.1081
[Epoch 5, Batch 100] loss: 0.07896419379860163
**STATS for Epoch 5** : 
Average training loss: 0.0341
Average validation loss: 0.0821
Validation Accuracy: 0.9760
Overfitting: 0.0480
Best model saved at epoch 5 with validation loss: 0.0821
[Epoch 6, Batch 100] loss: 0.07028271887451411
**STATS for Epoch 6** : 
Average training loss: 0.0296
Average validation loss: 0.0795
Validation Accuracy: 0.9766
Overfitting: 0.0499
Best model saved at epoch 6 with validation loss: 0.0795
[Epoch 7, Batch 100] loss: 0.060676040966063736
**STATS for Epoch 7** : 
Average training loss: 0.0262
Average validation loss: 0.0709
Validation Accuracy: 0.9784
Overfitting: 0.0447
Best model saved at epoch 7 with validation loss: 0.0709
[Epoch 8, Batch 100] loss: 0.054624719815328716
**STATS for Epoch 8** : 
Average training loss: 0.0239
Average validation loss: 0.0704
Validation Accuracy: 0.9789
Overfitting: 0.0465
Best model saved at epoch 8 with validation loss: 0.0704
[Epoch 9, Batch 100] loss: 0.04574807251803577
**STATS for Epoch 9** : 
Average training loss: 0.0224
Average validation loss: 0.0721
Validation Accuracy: 0.9773
Overfitting: 0.0497
[Epoch 10, Batch 100] loss: 0.04050823391415179
**STATS for Epoch 10** : 
Average training loss: 0.0196
Average validation loss: 0.0617
Validation Accuracy: 0.9815
Overfitting: 0.0421
Best model saved at epoch 10 with validation loss: 0.0617
[Epoch 11, Batch 100] loss: 0.0358951214235276
**STATS for Epoch 11** : 
Average training loss: 0.0184
Average validation loss: 0.0651
Validation Accuracy: 0.9800
Overfitting: 0.0467
[Epoch 12, Batch 100] loss: 0.03383441950194538
**STATS for Epoch 12** : 
Average training loss: 0.0171
Average validation loss: 0.0614
Validation Accuracy: 0.9816
Overfitting: 0.0443
Best model saved at epoch 12 with validation loss: 0.0614
[Epoch 13, Batch 100] loss: 0.03229127916507423
**STATS for Epoch 13** : 
Average training loss: 0.0154
Average validation loss: 0.0635
Validation Accuracy: 0.9820
Overfitting: 0.0482
[Epoch 14, Batch 100] loss: 0.031243211734108628
**STATS for Epoch 14** : 
Average training loss: 0.0146
Average validation loss: 0.0641
Validation Accuracy: 0.9809
Overfitting: 0.0495
[Epoch 15, Batch 100] loss: 0.02785233189817518
**STATS for Epoch 15** : 
Average training loss: 0.0122
Average validation loss: 0.0578
Validation Accuracy: 0.9840
Overfitting: 0.0456
Best model saved at epoch 15 with validation loss: 0.0578
[Epoch 16, Batch 100] loss: 0.02299084233120084
**STATS for Epoch 16** : 
Average training loss: 0.0124
Average validation loss: 0.0606
Validation Accuracy: 0.9833
Overfitting: 0.0482
[Epoch 17, Batch 100] loss: 0.02398301429115236
**STATS for Epoch 17** : 
Average training loss: 0.0104
Average validation loss: 0.0558
Validation Accuracy: 0.9838
Overfitting: 0.0454
Best model saved at epoch 17 with validation loss: 0.0558
[Epoch 18, Batch 100] loss: 0.01959275043103844
**STATS for Epoch 18** : 
Average training loss: 0.0099
Average validation loss: 0.0557
Validation Accuracy: 0.9842
Overfitting: 0.0458
Best model saved at epoch 18 with validation loss: 0.0557
[Epoch 19, Batch 100] loss: 0.020863335812464356
**STATS for Epoch 19** : 
Average training loss: 0.0103
Average validation loss: 0.0547
Validation Accuracy: 0.9845
Overfitting: 0.0444
Best model saved at epoch 19 with validation loss: 0.0547
[Epoch 20, Batch 100] loss: 0.016046743467450143
**STATS for Epoch 20** : 
Average training loss: 0.0094
Average validation loss: 0.0596
Validation Accuracy: 0.9843
Overfitting: 0.0502
[Epoch 21, Batch 100] loss: 0.01654990453040227
**STATS for Epoch 21** : 
Average training loss: 0.0078
Average validation loss: 0.0576
Validation Accuracy: 0.9842
Overfitting: 0.0498
[Epoch 22, Batch 100] loss: 0.016177571441512554
**STATS for Epoch 22** : 
Average training loss: 0.0084
Average validation loss: 0.0737
Validation Accuracy: 0.9802
Overfitting: 0.0653
[Epoch 23, Batch 100] loss: 0.01651473598089069
**STATS for Epoch 23** : 
Average training loss: 0.0066
Average validation loss: 0.0570
Validation Accuracy: 0.9845
Overfitting: 0.0505
[Epoch 24, Batch 100] loss: 0.013482337733730674
**STATS for Epoch 24** : 
Average training loss: 0.0062
Average validation loss: 0.0567
Validation Accuracy: 0.9844
Overfitting: 0.0504
Fold 2 validation loss: 0.0567
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.215404745340347
**STATS for Epoch 1** : 
Average training loss: 0.2697
Average validation loss: 0.3620
Validation Accuracy: 0.8878
Overfitting: 0.0923
Best model saved at epoch 1 with validation loss: 0.3620
[Epoch 2, Batch 100] loss: 0.26487191796302795
**STATS for Epoch 2** : 
Average training loss: 0.0851
Average validation loss: 0.1654
Validation Accuracy: 0.9506
Overfitting: 0.0803
Best model saved at epoch 2 with validation loss: 0.1654
[Epoch 3, Batch 100] loss: 0.14903933372348546
**STATS for Epoch 3** : 
Average training loss: 0.0567
Average validation loss: 0.1268
Validation Accuracy: 0.9623
Overfitting: 0.0702
Best model saved at epoch 3 with validation loss: 0.1268
[Epoch 4, Batch 100] loss: 0.10870148245245219
**STATS for Epoch 4** : 
Average training loss: 0.0477
Average validation loss: 0.1017
Validation Accuracy: 0.9683
Overfitting: 0.0540
Best model saved at epoch 4 with validation loss: 0.1017
[Epoch 5, Batch 100] loss: 0.08202242910861969
**STATS for Epoch 5** : 
Average training loss: 0.0399
Average validation loss: 0.0843
Validation Accuracy: 0.9752
Overfitting: 0.0444
Best model saved at epoch 5 with validation loss: 0.0843
[Epoch 6, Batch 100] loss: 0.07055751336738467
**STATS for Epoch 6** : 
Average training loss: 0.0317
Average validation loss: 0.0939
Validation Accuracy: 0.9697
Overfitting: 0.0622
[Epoch 7, Batch 100] loss: 0.06146572694182396
**STATS for Epoch 7** : 
Average training loss: 0.0268
Average validation loss: 0.0686
Validation Accuracy: 0.9791
Overfitting: 0.0417
Best model saved at epoch 7 with validation loss: 0.0686
[Epoch 8, Batch 100] loss: 0.05330275004729629
**STATS for Epoch 8** : 
Average training loss: 0.0233
Average validation loss: 0.0640
Validation Accuracy: 0.9805
Overfitting: 0.0407
Best model saved at epoch 8 with validation loss: 0.0640
[Epoch 9, Batch 100] loss: 0.04565923284739256
**STATS for Epoch 9** : 
Average training loss: 0.0227
Average validation loss: 0.0609
Validation Accuracy: 0.9819
Overfitting: 0.0382
Best model saved at epoch 9 with validation loss: 0.0609
[Epoch 10, Batch 100] loss: 0.04038077544420957
**STATS for Epoch 10** : 
Average training loss: 0.0199
Average validation loss: 0.0568
Validation Accuracy: 0.9837
Overfitting: 0.0369
Best model saved at epoch 10 with validation loss: 0.0568
[Epoch 11, Batch 100] loss: 0.037829552190378306
**STATS for Epoch 11** : 
Average training loss: 0.0171
Average validation loss: 0.0522
Validation Accuracy: 0.9852
Overfitting: 0.0352
Best model saved at epoch 11 with validation loss: 0.0522
[Epoch 12, Batch 100] loss: 0.03426533489488065
**STATS for Epoch 12** : 
Average training loss: 0.0156
Average validation loss: 0.0563
Validation Accuracy: 0.9838
Overfitting: 0.0407
[Epoch 13, Batch 100] loss: 0.031038321433588863
**STATS for Epoch 13** : 
Average training loss: 0.0144
Average validation loss: 0.0546
Validation Accuracy: 0.9837
Overfitting: 0.0402
[Epoch 14, Batch 100] loss: 0.025757127483375372
**STATS for Epoch 14** : 
Average training loss: 0.0133
Average validation loss: 0.0537
Validation Accuracy: 0.9846
Overfitting: 0.0403
[Epoch 15, Batch 100] loss: 0.024856595220044256
**STATS for Epoch 15** : 
Average training loss: 0.0124
Average validation loss: 0.0543
Validation Accuracy: 0.9844
Overfitting: 0.0419
[Epoch 16, Batch 100] loss: 0.022264366848394276
**STATS for Epoch 16** : 
Average training loss: 0.0116
Average validation loss: 0.0488
Validation Accuracy: 0.9862
Overfitting: 0.0372
Best model saved at epoch 16 with validation loss: 0.0488
[Epoch 17, Batch 100] loss: 0.021681275847367943
**STATS for Epoch 17** : 
Average training loss: 0.0103
Average validation loss: 0.0530
Validation Accuracy: 0.9852
Overfitting: 0.0427
[Epoch 18, Batch 100] loss: 0.0190120240743272
**STATS for Epoch 18** : 
Average training loss: 0.0089
Average validation loss: 0.0496
Validation Accuracy: 0.9865
Overfitting: 0.0407
[Epoch 19, Batch 100] loss: 0.015637558200396598
**STATS for Epoch 19** : 
Average training loss: 0.0095
Average validation loss: 0.0458
Validation Accuracy: 0.9876
Overfitting: 0.0363
Best model saved at epoch 19 with validation loss: 0.0458
[Epoch 20, Batch 100] loss: 0.01655606081010774
**STATS for Epoch 20** : 
Average training loss: 0.0099
Average validation loss: 0.0499
Validation Accuracy: 0.9858
Overfitting: 0.0400
[Epoch 21, Batch 100] loss: 0.01588016205467284
**STATS for Epoch 21** : 
Average training loss: 0.0072
Average validation loss: 0.0534
Validation Accuracy: 0.9846
Overfitting: 0.0462
[Epoch 22, Batch 100] loss: 0.013030560036422684
**STATS for Epoch 22** : 
Average training loss: 0.0079
Average validation loss: 0.0501
Validation Accuracy: 0.9871
Overfitting: 0.0422
[Epoch 23, Batch 100] loss: 0.012197196194902062
**STATS for Epoch 23** : 
Average training loss: 0.0060
Average validation loss: 0.0508
Validation Accuracy: 0.9866
Overfitting: 0.0448
[Epoch 24, Batch 100] loss: 0.010477428836748005
**STATS for Epoch 24** : 
Average training loss: 0.0049
Average validation loss: 0.0489
Validation Accuracy: 0.9863
Overfitting: 0.0440
Fold 3 validation loss: 0.0489
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.6696118447184563
**STATS for Epoch 1** : 
Average training loss: 0.1653
Average validation loss: 0.2532
Validation Accuracy: 0.9204
Overfitting: 0.0879
Best model saved at epoch 1 with validation loss: 0.2532
[Epoch 2, Batch 100] loss: 0.21160440362989902
**STATS for Epoch 2** : 
Average training loss: 0.0776
Average validation loss: 0.1361
Validation Accuracy: 0.9581
Overfitting: 0.0585
Best model saved at epoch 2 with validation loss: 0.1361
[Epoch 3, Batch 100] loss: 0.13305069908499717
**STATS for Epoch 3** : 
Average training loss: 0.0557
Average validation loss: 0.1254
Validation Accuracy: 0.9609
Overfitting: 0.0697
Best model saved at epoch 3 with validation loss: 0.1254
[Epoch 4, Batch 100] loss: 0.10359400559216737
**STATS for Epoch 4** : 
Average training loss: 0.0448
Average validation loss: 0.0956
Validation Accuracy: 0.9723
Overfitting: 0.0508
Best model saved at epoch 4 with validation loss: 0.0956
[Epoch 5, Batch 100] loss: 0.08564087230712175
**STATS for Epoch 5** : 
Average training loss: 0.0387
Average validation loss: 0.0954
Validation Accuracy: 0.9699
Overfitting: 0.0567
Best model saved at epoch 5 with validation loss: 0.0954
[Epoch 6, Batch 100] loss: 0.07409654032438993
**STATS for Epoch 6** : 
Average training loss: 0.0326
Average validation loss: 0.0714
Validation Accuracy: 0.9782
Overfitting: 0.0388
Best model saved at epoch 6 with validation loss: 0.0714
[Epoch 7, Batch 100] loss: 0.06096681129187345
**STATS for Epoch 7** : 
Average training loss: 0.0281
Average validation loss: 0.0694
Validation Accuracy: 0.9782
Overfitting: 0.0413
Best model saved at epoch 7 with validation loss: 0.0694
[Epoch 8, Batch 100] loss: 0.05633635147474706
**STATS for Epoch 8** : 
Average training loss: 0.0260
Average validation loss: 0.0707
Validation Accuracy: 0.9782
Overfitting: 0.0448
[Epoch 9, Batch 100] loss: 0.05195202698931098
**STATS for Epoch 9** : 
Average training loss: 0.0214
Average validation loss: 0.0548
Validation Accuracy: 0.9832
Overfitting: 0.0334
Best model saved at epoch 9 with validation loss: 0.0548
[Epoch 10, Batch 100] loss: 0.04609835227020085
**STATS for Epoch 10** : 
Average training loss: 0.0191
Average validation loss: 0.0563
Validation Accuracy: 0.9827
Overfitting: 0.0372
[Epoch 11, Batch 100] loss: 0.041594873289577665
**STATS for Epoch 11** : 
Average training loss: 0.0175
Average validation loss: 0.0540
Validation Accuracy: 0.9842
Overfitting: 0.0366
Best model saved at epoch 11 with validation loss: 0.0540
[Epoch 12, Batch 100] loss: 0.03686368404421955
**STATS for Epoch 12** : 
Average training loss: 0.0166
Average validation loss: 0.0532
Validation Accuracy: 0.9838
Overfitting: 0.0366
Best model saved at epoch 12 with validation loss: 0.0532
[Epoch 13, Batch 100] loss: 0.03254284487105906
**STATS for Epoch 13** : 
Average training loss: 0.0159
Average validation loss: 0.0532
Validation Accuracy: 0.9831
Overfitting: 0.0374
[Epoch 14, Batch 100] loss: 0.027502762973308562
**STATS for Epoch 14** : 
Average training loss: 0.0161
Average validation loss: 0.0586
Validation Accuracy: 0.9819
Overfitting: 0.0424
[Epoch 15, Batch 100] loss: 0.029476163771469145
**STATS for Epoch 15** : 
Average training loss: 0.0141
Average validation loss: 0.0572
Validation Accuracy: 0.9818
Overfitting: 0.0431
[Epoch 16, Batch 100] loss: 0.02574660879559815
**STATS for Epoch 16** : 
Average training loss: 0.0121
Average validation loss: 0.0530
Validation Accuracy: 0.9835
Overfitting: 0.0409
Best model saved at epoch 16 with validation loss: 0.0530
[Epoch 17, Batch 100] loss: 0.025069363552611322
**STATS for Epoch 17** : 
Average training loss: 0.0117
Average validation loss: 0.0559
Validation Accuracy: 0.9828
Overfitting: 0.0441
[Epoch 18, Batch 100] loss: 0.022449883297085763
**STATS for Epoch 18** : 
Average training loss: 0.0090
Average validation loss: 0.0530
Validation Accuracy: 0.9842
Overfitting: 0.0440
Best model saved at epoch 18 with validation loss: 0.0530
[Epoch 19, Batch 100] loss: 0.018403923157602548
**STATS for Epoch 19** : 
Average training loss: 0.0107
Average validation loss: 0.0485
Validation Accuracy: 0.9858
Overfitting: 0.0378
Best model saved at epoch 19 with validation loss: 0.0485
[Epoch 20, Batch 100] loss: 0.018661333057098092
**STATS for Epoch 20** : 
Average training loss: 0.0095
Average validation loss: 0.0524
Validation Accuracy: 0.9851
Overfitting: 0.0429
[Epoch 21, Batch 100] loss: 0.017640280008781702
**STATS for Epoch 21** : 
Average training loss: 0.0075
Average validation loss: 0.0502
Validation Accuracy: 0.9848
Overfitting: 0.0427
[Epoch 22, Batch 100] loss: 0.014147676776628941
**STATS for Epoch 22** : 
Average training loss: 0.0077
Average validation loss: 0.0555
Validation Accuracy: 0.9838
Overfitting: 0.0478
[Epoch 23, Batch 100] loss: 0.014824555277591571
**STATS for Epoch 23** : 
Average training loss: 0.0072
Average validation loss: 0.0525
Validation Accuracy: 0.9846
Overfitting: 0.0452
[Epoch 24, Batch 100] loss: 0.01085746370954439
**STATS for Epoch 24** : 
Average training loss: 0.0063
Average validation loss: 0.0519
Validation Accuracy: 0.9849
Overfitting: 0.0456
Fold 4 validation loss: 0.0519
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.129440360069275
**STATS for Epoch 1** : 
Average training loss: 0.2405
Average validation loss: 0.3167
Validation Accuracy: 0.9070
Overfitting: 0.0762
Best model saved at epoch 1 with validation loss: 0.3167
[Epoch 2, Batch 100] loss: 0.25873637974262237
**STATS for Epoch 2** : 
Average training loss: 0.0807
Average validation loss: 0.1486
Validation Accuracy: 0.9582
Overfitting: 0.0678
Best model saved at epoch 2 with validation loss: 0.1486
[Epoch 3, Batch 100] loss: 0.13249928038567305
**STATS for Epoch 3** : 
Average training loss: 0.0541
Average validation loss: 0.1033
Validation Accuracy: 0.9682
Overfitting: 0.0492
Best model saved at epoch 3 with validation loss: 0.1033
[Epoch 4, Batch 100] loss: 0.09448845773935317
**STATS for Epoch 4** : 
Average training loss: 0.0384
Average validation loss: 0.0838
Validation Accuracy: 0.9751
Overfitting: 0.0455
Best model saved at epoch 4 with validation loss: 0.0838
[Epoch 5, Batch 100] loss: 0.07311332743614912
**STATS for Epoch 5** : 
Average training loss: 0.0337
Average validation loss: 0.0672
Validation Accuracy: 0.9801
Overfitting: 0.0335
Best model saved at epoch 5 with validation loss: 0.0672
[Epoch 6, Batch 100] loss: 0.0628195488639176
**STATS for Epoch 6** : 
Average training loss: 0.0297
Average validation loss: 0.0677
Validation Accuracy: 0.9794
Overfitting: 0.0381
[Epoch 7, Batch 100] loss: 0.05424158565700054
**STATS for Epoch 7** : 
Average training loss: 0.0276
Average validation loss: 0.0623
Validation Accuracy: 0.9814
Overfitting: 0.0347
Best model saved at epoch 7 with validation loss: 0.0623
[Epoch 8, Batch 100] loss: 0.051329948008060455
**STATS for Epoch 8** : 
Average training loss: 0.0234
Average validation loss: 0.0669
Validation Accuracy: 0.9796
Overfitting: 0.0435
[Epoch 9, Batch 100] loss: 0.04508563586510718
**STATS for Epoch 9** : 
Average training loss: 0.0218
Average validation loss: 0.0553
Validation Accuracy: 0.9833
Overfitting: 0.0335
Best model saved at epoch 9 with validation loss: 0.0553
[Epoch 10, Batch 100] loss: 0.03981069314293564
**STATS for Epoch 10** : 
Average training loss: 0.0191
Average validation loss: 0.0501
Validation Accuracy: 0.9856
Overfitting: 0.0310
Best model saved at epoch 10 with validation loss: 0.0501
[Epoch 11, Batch 100] loss: 0.0349856061115861
**STATS for Epoch 11** : 
Average training loss: 0.0174
Average validation loss: 0.0482
Validation Accuracy: 0.9836
Overfitting: 0.0307
Best model saved at epoch 11 with validation loss: 0.0482
[Epoch 12, Batch 100] loss: 0.03303435144014657
**STATS for Epoch 12** : 
Average training loss: 0.0159
Average validation loss: 0.0493
Validation Accuracy: 0.9838
Overfitting: 0.0335
[Epoch 13, Batch 100] loss: 0.02927448640111834
**STATS for Epoch 13** : 
Average training loss: 0.0146
Average validation loss: 0.0537
Validation Accuracy: 0.9824
Overfitting: 0.0392
[Epoch 14, Batch 100] loss: 0.025089761270210148
**STATS for Epoch 14** : 
Average training loss: 0.0147
Average validation loss: 0.0427
Validation Accuracy: 0.9862
Overfitting: 0.0280
Best model saved at epoch 14 with validation loss: 0.0427
[Epoch 15, Batch 100] loss: 0.02535023756790906
**STATS for Epoch 15** : 
Average training loss: 0.0125
Average validation loss: 0.0487
Validation Accuracy: 0.9843
Overfitting: 0.0363
[Epoch 16, Batch 100] loss: 0.022778547443449496
**STATS for Epoch 16** : 
Average training loss: 0.0123
Average validation loss: 0.0527
Validation Accuracy: 0.9834
Overfitting: 0.0404
[Epoch 17, Batch 100] loss: 0.02313476940849796
**STATS for Epoch 17** : 
Average training loss: 0.0109
Average validation loss: 0.0470
Validation Accuracy: 0.9856
Overfitting: 0.0361
[Epoch 18, Batch 100] loss: 0.024601729875430463
**STATS for Epoch 18** : 
Average training loss: 0.0093
Average validation loss: 0.0479
Validation Accuracy: 0.9848
Overfitting: 0.0386
[Epoch 19, Batch 100] loss: 0.016560480075422674
**STATS for Epoch 19** : 
Average training loss: 0.0092
Average validation loss: 0.0460
Validation Accuracy: 0.9858
Overfitting: 0.0367
[Epoch 20, Batch 100] loss: 0.017405323304701598
**STATS for Epoch 20** : 
Average training loss: 0.0092
Average validation loss: 0.0491
Validation Accuracy: 0.9861
Overfitting: 0.0399
[Epoch 21, Batch 100] loss: 0.013433037428185343
**STATS for Epoch 21** : 
Average training loss: 0.0080
Average validation loss: 0.0478
Validation Accuracy: 0.9859
Overfitting: 0.0398
[Epoch 22, Batch 100] loss: 0.013377798316068947
**STATS for Epoch 22** : 
Average training loss: 0.0072
Average validation loss: 0.0441
Validation Accuracy: 0.9863
Overfitting: 0.0369
[Epoch 23, Batch 100] loss: 0.011978833007160574
**STATS for Epoch 23** : 
Average training loss: 0.0065
Average validation loss: 0.0489
Validation Accuracy: 0.9858
Overfitting: 0.0423
[Epoch 24, Batch 100] loss: 0.00962085306760855
**STATS for Epoch 24** : 
Average training loss: 0.0063
Average validation loss: 0.0454
Validation Accuracy: 0.9868
Overfitting: 0.0391
Fold 5 validation loss: 0.0454
Mean validation loss across all folds for Trial 23 is 0.0486 with trial config:  l1: 256, l2: 64, lr: 0.006307908822596799, batch_size: 256
[I 2024-12-10 09:27:16,912] Trial 22 finished with value: 0.04863713928894635 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.006307908822596799, 'batch_size': 256}. Best is trial 16 with value: 0.04722271221232811.

Selected Hyperparameters for Trial 24:
  l1: 256, l2: 64, lr: 0.009282796472456396, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.691765433549881
**STATS for Epoch 1** : 
Average training loss: 0.1516
Average validation loss: 0.2106
Validation Accuracy: 0.9348
Overfitting: 0.0590
Best model saved at epoch 1 with validation loss: 0.2106
[Epoch 2, Batch 100] loss: 0.18069976150989533
**STATS for Epoch 2** : 
Average training loss: 0.0609
Average validation loss: 0.1167
Validation Accuracy: 0.9637
Overfitting: 0.0558
Best model saved at epoch 2 with validation loss: 0.1167
[Epoch 3, Batch 100] loss: 0.10610094089061022
**STATS for Epoch 3** : 
Average training loss: 0.0424
Average validation loss: 0.0763
Validation Accuracy: 0.9762
Overfitting: 0.0339
Best model saved at epoch 3 with validation loss: 0.0763
[Epoch 4, Batch 100] loss: 0.08062296804040671
**STATS for Epoch 4** : 
Average training loss: 0.0344
Average validation loss: 0.0643
Validation Accuracy: 0.9793
Overfitting: 0.0299
Best model saved at epoch 4 with validation loss: 0.0643
[Epoch 5, Batch 100] loss: 0.06381129056215286
**STATS for Epoch 5** : 
Average training loss: 0.0261
Average validation loss: 0.0567
Validation Accuracy: 0.9832
Overfitting: 0.0306
Best model saved at epoch 5 with validation loss: 0.0567
[Epoch 6, Batch 100] loss: 0.05573797139339149
**STATS for Epoch 6** : 
Average training loss: 0.0240
Average validation loss: 0.0524
Validation Accuracy: 0.9842
Overfitting: 0.0284
Best model saved at epoch 6 with validation loss: 0.0524
[Epoch 7, Batch 100] loss: 0.046878592213615775
**STATS for Epoch 7** : 
Average training loss: 0.0193
Average validation loss: 0.0510
Validation Accuracy: 0.9839
Overfitting: 0.0317
Best model saved at epoch 7 with validation loss: 0.0510
[Epoch 8, Batch 100] loss: 0.03909501547925174
**STATS for Epoch 8** : 
Average training loss: 0.0187
Average validation loss: 0.0488
Validation Accuracy: 0.9853
Overfitting: 0.0301
Best model saved at epoch 8 with validation loss: 0.0488
[Epoch 9, Batch 100] loss: 0.03482887855730951
**STATS for Epoch 9** : 
Average training loss: 0.0146
Average validation loss: 0.0446
Validation Accuracy: 0.9864
Overfitting: 0.0299
Best model saved at epoch 9 with validation loss: 0.0446
[Epoch 10, Batch 100] loss: 0.034189829453825954
**STATS for Epoch 10** : 
Average training loss: 0.0136
Average validation loss: 0.0488
Validation Accuracy: 0.9849
Overfitting: 0.0352
[Epoch 11, Batch 100] loss: 0.024202491692267358
**STATS for Epoch 11** : 
Average training loss: 0.0129
Average validation loss: 0.0453
Validation Accuracy: 0.9868
Overfitting: 0.0324
[Epoch 12, Batch 100] loss: 0.023535360940732063
**STATS for Epoch 12** : 
Average training loss: 0.0105
Average validation loss: 0.0488
Validation Accuracy: 0.9861
Overfitting: 0.0383
[Epoch 13, Batch 100] loss: 0.019287155717611314
**STATS for Epoch 13** : 
Average training loss: 0.0111
Average validation loss: 0.0454
Validation Accuracy: 0.9860
Overfitting: 0.0343
[Epoch 14, Batch 100] loss: 0.018177884966135024
**STATS for Epoch 14** : 
Average training loss: 0.0102
Average validation loss: 0.0495
Validation Accuracy: 0.9852
Overfitting: 0.0393
[Epoch 15, Batch 100] loss: 0.01785262345103547
**STATS for Epoch 15** : 
Average training loss: 0.0081
Average validation loss: 0.0424
Validation Accuracy: 0.9882
Overfitting: 0.0343
Best model saved at epoch 15 with validation loss: 0.0424
[Epoch 16, Batch 100] loss: 0.015376740789506585
**STATS for Epoch 16** : 
Average training loss: 0.0083
Average validation loss: 0.0402
Validation Accuracy: 0.9886
Overfitting: 0.0319
Best model saved at epoch 16 with validation loss: 0.0402
[Epoch 17, Batch 100] loss: 0.013991714799776673
**STATS for Epoch 17** : 
Average training loss: 0.0072
Average validation loss: 0.0468
Validation Accuracy: 0.9869
Overfitting: 0.0396
[I 2024-12-10 09:29:48,444] Trial 23 pruned. 
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  12
  Number of complete trials:  12
Best hyperparameters found:
{'l1': 256, 'l2': 64, 'lr': 0.0021343086136530096, 'batch_size': 64}
Best trial:
  Value:  0.04722271221232811
Loaded best model checkpoint from: instances/1164374_20241210/best_checkpoint_trial_16/model.pth
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0021343086136530096, 'batch_size': 64} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 2.2805183911323548
[Epoch 1, Batch 200] loss: 1.8604706519842147
[Epoch 1, Batch 300] loss: 0.6399223387241364
[Epoch 1, Batch 400] loss: 0.40977267250418664
[Epoch 1, Batch 500] loss: 0.32175731286406517
[Epoch 1, Batch 600] loss: 0.2568115293979645
[Epoch 1, Batch 700] loss: 0.21368266142904757
[Epoch 1, Batch 800] loss: 0.19015258263796567
[Epoch 1, Batch 900] loss: 0.1723493817076087
**STATS for Epoch 1** : 
Average training loss: 0.0061
Average validation loss: 0.1429
Overfitting: 0.1368
Best model saved at epoch 1 with training loss: 0.0061
[Epoch 2, Batch 100] loss: 0.14527404423803092
[Epoch 2, Batch 200] loss: 0.12537907099351286
[Epoch 2, Batch 300] loss: 0.12269328188151121
[Epoch 2, Batch 400] loss: 0.11917404849082232
[Epoch 2, Batch 500] loss: 0.11063164742663503
[Epoch 2, Batch 600] loss: 0.10030440697446466
[Epoch 2, Batch 700] loss: 0.1087354729231447
[Epoch 2, Batch 800] loss: 0.10717634394764901
[Epoch 2, Batch 900] loss: 0.08803336636163295
**STATS for Epoch 2** : 
Average training loss: 0.0033
Average validation loss: 0.0703
Overfitting: 0.0670
Best model saved at epoch 2 with training loss: 0.0033
[Epoch 3, Batch 100] loss: 0.07854542968794703
[Epoch 3, Batch 200] loss: 0.08768261224962771
[Epoch 3, Batch 300] loss: 0.06884162239730358
[Epoch 3, Batch 400] loss: 0.07325385032221675
[Epoch 3, Batch 500] loss: 0.0744964520353824
[Epoch 3, Batch 600] loss: 0.07538319095037878
[Epoch 3, Batch 700] loss: 0.08801584917120636
[Epoch 3, Batch 800] loss: 0.079257734362036
[Epoch 3, Batch 900] loss: 0.07401284750085324
**STATS for Epoch 3** : 
Average training loss: 0.0027
Average validation loss: 0.0599
Overfitting: 0.0572
Best model saved at epoch 3 with training loss: 0.0027
[Epoch 4, Batch 100] loss: 0.0636227612150833
[Epoch 4, Batch 200] loss: 0.06406615250278264
[Epoch 4, Batch 300] loss: 0.07376790953334421
[Epoch 4, Batch 400] loss: 0.05906940197106451
[Epoch 4, Batch 500] loss: 0.0638250350439921
[Epoch 4, Batch 600] loss: 0.05514976780395955
[Epoch 4, Batch 700] loss: 0.06324746368452906
[Epoch 4, Batch 800] loss: 0.056674420488998296
[Epoch 4, Batch 900] loss: 0.06314894687966444
**STATS for Epoch 4** : 
Average training loss: 0.0023
Average validation loss: 0.0524
Overfitting: 0.0502
Best model saved at epoch 4 with training loss: 0.0023
[Epoch 5, Batch 100] loss: 0.05073879667092115
[Epoch 5, Batch 200] loss: 0.05009375711902976
[Epoch 5, Batch 300] loss: 0.0493327328749001
[Epoch 5, Batch 400] loss: 0.05628578201169148
[Epoch 5, Batch 500] loss: 0.056175998193211854
[Epoch 5, Batch 600] loss: 0.061706123198382555
[Epoch 5, Batch 700] loss: 0.05148391923052259
[Epoch 5, Batch 800] loss: 0.04369416370987892
[Epoch 5, Batch 900] loss: 0.0526850749924779
**STATS for Epoch 5** : 
Average training loss: 0.0015
Average validation loss: 0.0462
Overfitting: 0.0447
Best model saved at epoch 5 with training loss: 0.0015
[Epoch 6, Batch 100] loss: 0.04376691072247922
[Epoch 6, Batch 200] loss: 0.04538276349194348
[Epoch 6, Batch 300] loss: 0.05131653217598796
[Epoch 6, Batch 400] loss: 0.051041250994894656
[Epoch 6, Batch 500] loss: 0.03652407377143391
[Epoch 6, Batch 600] loss: 0.04744029148947448
[Epoch 6, Batch 700] loss: 0.03730235088150948
[Epoch 6, Batch 800] loss: 0.042409672221401705
[Epoch 6, Batch 900] loss: 0.04381933957687579
**STATS for Epoch 6** : 
Average training loss: 0.0012
Average validation loss: 0.0424
Overfitting: 0.0411
Best model saved at epoch 6 with training loss: 0.0012
[Epoch 7, Batch 100] loss: 0.030611533015035094
[Epoch 7, Batch 200] loss: 0.03978703641798347
[Epoch 7, Batch 300] loss: 0.04618837296613492
[Epoch 7, Batch 400] loss: 0.045007015601731835
[Epoch 7, Batch 500] loss: 0.04361817636527121
[Epoch 7, Batch 600] loss: 0.03654356426093727
[Epoch 7, Batch 700] loss: 0.03708262652857229
[Epoch 7, Batch 800] loss: 0.03653246314497664
[Epoch 7, Batch 900] loss: 0.03745884657255374
**STATS for Epoch 7** : 
Average training loss: 0.0011
Average validation loss: 0.0487
Overfitting: 0.0476
Best model saved at epoch 7 with training loss: 0.0011
[Epoch 8, Batch 100] loss: 0.03425454578886274
[Epoch 8, Batch 200] loss: 0.031596221550134945
[Epoch 8, Batch 300] loss: 0.0322871949034743
[Epoch 8, Batch 400] loss: 0.03057036821555812
[Epoch 8, Batch 500] loss: 0.03040120122139342
[Epoch 8, Batch 600] loss: 0.03804513287846931
[Epoch 8, Batch 700] loss: 0.03095452270586975
[Epoch 8, Batch 800] loss: 0.039701005113311115
[Epoch 8, Batch 900] loss: 0.0326017068058718
**STATS for Epoch 8** : 
Average training loss: 0.0022
Average validation loss: 0.0403
Overfitting: 0.0381
[Epoch 9, Batch 100] loss: 0.033168670788872985
[Epoch 9, Batch 200] loss: 0.031410796922864394
[Epoch 9, Batch 300] loss: 0.025306125909555704
[Epoch 9, Batch 400] loss: 0.028298749178065918
[Epoch 9, Batch 500] loss: 0.03299536108621396
[Epoch 9, Batch 600] loss: 0.031190765984356404
[Epoch 9, Batch 700] loss: 0.03126576109556481
[Epoch 9, Batch 800] loss: 0.031370212791953234
[Epoch 9, Batch 900] loss: 0.029866444455692545
**STATS for Epoch 9** : 
Average training loss: 0.0013
Average validation loss: 0.0342
Overfitting: 0.0329
[Epoch 10, Batch 100] loss: 0.02358216077554971
[Epoch 10, Batch 200] loss: 0.024046481596888044
[Epoch 10, Batch 300] loss: 0.028088131754193457
[Epoch 10, Batch 400] loss: 0.031043186782626436
[Epoch 10, Batch 500] loss: 0.024613675416330808
[Epoch 10, Batch 600] loss: 0.027576325655099935
[Epoch 10, Batch 700] loss: 0.030749188258778305
[Epoch 10, Batch 800] loss: 0.02507558993413113
[Epoch 10, Batch 900] loss: 0.033350323302438485
**STATS for Epoch 10** : 
Average training loss: 0.0010
Average validation loss: 0.0409
Overfitting: 0.0400
Best model saved at epoch 10 with training loss: 0.0010
[Epoch 11, Batch 100] loss: 0.024257936485810205
[Epoch 11, Batch 200] loss: 0.02513550655450672
[Epoch 11, Batch 300] loss: 0.018907617529039272
[Epoch 11, Batch 400] loss: 0.022875489965081215
[Epoch 11, Batch 500] loss: 0.023299530836520716
[Epoch 11, Batch 600] loss: 0.02320912851835601
[Epoch 11, Batch 700] loss: 0.028846953856409528
[Epoch 11, Batch 800] loss: 0.03017477631161455
[Epoch 11, Batch 900] loss: 0.028087728648679332
**STATS for Epoch 11** : 
Average training loss: 0.0014
Average validation loss: 0.0348
Overfitting: 0.0334
[Epoch 12, Batch 100] loss: 0.023277126913890243
[Epoch 12, Batch 200] loss: 0.02193822780274786
[Epoch 12, Batch 300] loss: 0.021272888914681973
[Epoch 12, Batch 400] loss: 0.019668496524682267
[Epoch 12, Batch 500] loss: 0.025307381288148464
[Epoch 12, Batch 600] loss: 0.025337900096783415
[Epoch 12, Batch 700] loss: 0.023799735029460863
[Epoch 12, Batch 800] loss: 0.03072733402834274
[Epoch 12, Batch 900] loss: 0.015408352019148879
**STATS for Epoch 12** : 
Average training loss: 0.0007
Average validation loss: 0.0329
Overfitting: 0.0322
Best model saved at epoch 12 with training loss: 0.0007
[Epoch 13, Batch 100] loss: 0.019420124635507817
[Epoch 13, Batch 200] loss: 0.025315950190997683
[Epoch 13, Batch 300] loss: 0.02369468070450239
[Epoch 13, Batch 400] loss: 0.020681627037702127
[Epoch 13, Batch 500] loss: 0.02195028002199251
[Epoch 13, Batch 600] loss: 0.018845430751680395
[Epoch 13, Batch 700] loss: 0.0175797364776372
[Epoch 13, Batch 800] loss: 0.020411651360773247
[Epoch 13, Batch 900] loss: 0.01809853317157831
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0313
Overfitting: 0.0305
[Epoch 14, Batch 100] loss: 0.01728538888506591
[Epoch 14, Batch 200] loss: 0.01912070689664688
[Epoch 14, Batch 300] loss: 0.014883619286702015
[Epoch 14, Batch 400] loss: 0.022166794828081038
[Epoch 14, Batch 500] loss: 0.01487961205886677
[Epoch 14, Batch 600] loss: 0.025068664545251522
[Epoch 14, Batch 700] loss: 0.018237467595463387
[Epoch 14, Batch 800] loss: 0.01619099172647111
[Epoch 14, Batch 900] loss: 0.01549231403914746
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0332
Overfitting: 0.0325
Best model saved at epoch 14 with training loss: 0.0007
[Epoch 15, Batch 100] loss: 0.015658339846413582
[Epoch 15, Batch 200] loss: 0.012770841119054238
[Epoch 15, Batch 300] loss: 0.016104435810702852
[Epoch 15, Batch 400] loss: 0.01875699521842762
[Epoch 15, Batch 500] loss: 0.01258210616899305
[Epoch 15, Batch 600] loss: 0.021164727316063364
[Epoch 15, Batch 700] loss: 0.0201172466026037
[Epoch 15, Batch 800] loss: 0.018401589159038848
[Epoch 15, Batch 900] loss: 0.019415503389318474
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0350
Overfitting: 0.0344
Best model saved at epoch 15 with training loss: 0.0006
[Epoch 16, Batch 100] loss: 0.01530303504463518
[Epoch 16, Batch 200] loss: 0.016027010619873182
[Epoch 16, Batch 300] loss: 0.016534822978137527
[Epoch 16, Batch 400] loss: 0.013485955106734764
[Epoch 16, Batch 500] loss: 0.013869866618479136
[Epoch 16, Batch 600] loss: 0.017679315801360646
[Epoch 16, Batch 700] loss: 0.0177836839488009
[Epoch 16, Batch 800] loss: 0.015621624521736521
[Epoch 16, Batch 900] loss: 0.013340362349408679
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0335
Overfitting: 0.0329
Best model saved at epoch 16 with training loss: 0.0006
[Epoch 17, Batch 100] loss: 0.00945792177459225
[Epoch 17, Batch 200] loss: 0.012370825098987553
[Epoch 17, Batch 300] loss: 0.013963571917265653
[Epoch 17, Batch 400] loss: 0.01345723322709091
[Epoch 17, Batch 500] loss: 0.017568601729144574
[Epoch 17, Batch 600] loss: 0.01573913692991482
[Epoch 17, Batch 700] loss: 0.014694072384299943
[Epoch 17, Batch 800] loss: 0.012223565708845854
[Epoch 17, Batch 900] loss: 0.01555448456434533
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0357
Overfitting: 0.0348
[Epoch 18, Batch 100] loss: 0.013950717117404565
[Epoch 18, Batch 200] loss: 0.01000326699577272
[Epoch 18, Batch 300] loss: 0.011610143517755205
[Epoch 18, Batch 400] loss: 0.012113405715790577
[Epoch 18, Batch 500] loss: 0.013086804094782564
[Epoch 18, Batch 600] loss: 0.01343862736794108
[Epoch 18, Batch 700] loss: 0.01326686455970048
[Epoch 18, Batch 800] loss: 0.014136710813181708
[Epoch 18, Batch 900] loss: 0.010253009062435012
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0314
Overfitting: 0.0305
[Epoch 19, Batch 100] loss: 0.009053742576725199
[Epoch 19, Batch 200] loss: 0.009823839066084474
[Epoch 19, Batch 300] loss: 0.015048036135121947
[Epoch 19, Batch 400] loss: 0.010691652038949541
[Epoch 19, Batch 500] loss: 0.01266143362121511
[Epoch 19, Batch 600] loss: 0.0083135578049405
[Epoch 19, Batch 700] loss: 0.00862852290410956
[Epoch 19, Batch 800] loss: 0.012437370419538638
[Epoch 19, Batch 900] loss: 0.01013669407700945
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0399
Overfitting: 0.0391
[Epoch 20, Batch 100] loss: 0.013659705853206106
[Epoch 20, Batch 200] loss: 0.011280403005512198
[Epoch 20, Batch 300] loss: 0.00838215692427184
[Epoch 20, Batch 400] loss: 0.008441112485452323
[Epoch 20, Batch 500] loss: 0.012727796149556525
[Epoch 20, Batch 600] loss: 0.009765478227927815
[Epoch 20, Batch 700] loss: 0.012083031644215226
[Epoch 20, Batch 800] loss: 0.0083090995047678
[Epoch 20, Batch 900] loss: 0.009904005470816627
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0430
Overfitting: 0.0426
Best model saved at epoch 20 with training loss: 0.0004
[Epoch 21, Batch 100] loss: 0.011985612943099112
[Epoch 21, Batch 200] loss: 0.008188258456648327
[Epoch 21, Batch 300] loss: 0.009846896190247208
[Epoch 21, Batch 400] loss: 0.009206990547354507
[Epoch 21, Batch 500] loss: 0.008293883060978259
[Epoch 21, Batch 600] loss: 0.007629047306982102
[Epoch 21, Batch 700] loss: 0.00805698004682199
[Epoch 21, Batch 800] loss: 0.008524276468815515
[Epoch 21, Batch 900] loss: 0.010573024017867283
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0342
Overfitting: 0.0338
[Epoch 22, Batch 100] loss: 0.00939426394565089
[Epoch 22, Batch 200] loss: 0.008800962856257684
[Epoch 22, Batch 300] loss: 0.0072320142438547915
[Epoch 22, Batch 400] loss: 0.006120299455760687
[Epoch 22, Batch 500] loss: 0.009245368964184309
[Epoch 22, Batch 600] loss: 0.006670752034915494
[Epoch 22, Batch 700] loss: 0.007576311218072078
[Epoch 22, Batch 800] loss: 0.00969716601735854
[Epoch 22, Batch 900] loss: 0.010313354246754898
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0477
Overfitting: 0.0474
Best model saved at epoch 22 with training loss: 0.0003
[Epoch 23, Batch 100] loss: 0.007019783375435509
[Epoch 23, Batch 200] loss: 0.007143833042864572
[Epoch 23, Batch 300] loss: 0.007631125219049863
[Epoch 23, Batch 400] loss: 0.004451180772157386
[Epoch 23, Batch 500] loss: 0.008357138301435044
[Epoch 23, Batch 600] loss: 0.0056348988419631495
[Epoch 23, Batch 700] loss: 0.011185656041088805
[Epoch 23, Batch 800] loss: 0.00798828783979843
[Epoch 23, Batch 900] loss: 0.006887184745428385
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0410
Overfitting: 0.0406
[Epoch 24, Batch 100] loss: 0.0034737291650526456
[Epoch 24, Batch 200] loss: 0.003516818308562506
[Epoch 24, Batch 300] loss: 0.008570688749423426
[Epoch 24, Batch 400] loss: 0.003736915723748098
[Epoch 24, Batch 500] loss: 0.0074775596246036006
[Epoch 24, Batch 600] loss: 0.007112359921156894
[Epoch 24, Batch 700] loss: 0.004052833275200101
[Epoch 24, Batch 800] loss: 0.008129113678096473
[Epoch 24, Batch 900] loss: 0.005726018544792168
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0398
Overfitting: 0.0393
qt.qpa.xcb: X server does not support XInput 2
+++FINAL STATS++++
Training Loss 0.00048588743515393096
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0021343086136530096, 'batch_size': 64} on final Test set to find Test loss for overfitting
 Testing loss : 0.0398
Calculated Overfitting : 0.0393
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0021343086136530096, 'batch_size': 64} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9902
Total time taken for hyperparameter tuning and evaluation: 4:55:5
/home/ahussain/PycharmProjects/optunaNew/optuna_TrialPruner.py:515: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.


Process finished with exit code 0

