205527
[Epoch 18, Batch 500] loss: 0.0194043201182285
[Epoch 18, Batch 600] loss: 0.026314384124416394
[Epoch 18, Batch 700] loss: 0.024743654766789403
[Epoch 18, Batch 800] loss: 0.024500435553054558
[Epoch 18, Batch 900] loss: 0.023175176708755317
[Epoch 18, Batch 1000] loss: 0.022391207082546317
[Epoch 18, Batch 1100] loss: 0.018588087702228223
[Epoch 18, Batch 1200] loss: 0.030891454518059618
[Epoch 18, Batch 1300] loss: 0.019444572556967615
[Epoch 18, Batch 1400] loss: 0.024688636322971434
[Epoch 18, Batch 1500] loss: 0.025081072199172924
[Epoch 18, Batch 1600] loss: 0.01797294680371124
[Epoch 18, Batch 1700] loss: 0.024176366847896133
[Epoch 18, Batch 1800] loss: 0.01950297376322851
[Epoch 18, Batch 1900] loss: 0.02907317682311259
[Epoch 18, Batch 2000] loss: 0.01968190206318468
[Epoch 18, Batch 2100] loss: 0.020148221087947605
[Epoch 18, Batch 2200] loss: 0.02191645858998527
[Epoch 18, Batch 2300] loss: 0.02545451720856363
[Epoch 18, Batch 2400] loss: 0.02546097196151095
[Epoch 18, Batch 2500] loss: 0.024688551556755554
[Epoch 18, Batch 2600] loss: 0.026630102266935865
[Epoch 18, Batch 2700] loss: 0.012113171388518822
[Epoch 18, Batch 2800] loss: 0.025211493647329917
[Epoch 18, Batch 2900] loss: 0.019599456897340134
[Epoch 18, Batch 3000] loss: 0.015568554263882105
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9852
Overfitting: 0.0505
Best model saved at epoch 18 with validation loss: 0.0505
[Epoch 19, Batch 100] loss: 0.028006755834940122
[Epoch 19, Batch 200] loss: 0.021809459697833516
[Epoch 19, Batch 300] loss: 0.020913078126395705
[Epoch 19, Batch 400] loss: 0.019169783574434406
[Epoch 19, Batch 500] loss: 0.02785116797869705
[Epoch 19, Batch 600] loss: 0.022600352084791667
[Epoch 19, Batch 700] loss: 0.029162001909135142
[Epoch 19, Batch 800] loss: 0.016167768991872434
[Epoch 19, Batch 900] loss: 0.015973717391389072
[Epoch 19, Batch 1000] loss: 0.019218989433938988
[Epoch 19, Batch 1100] loss: 0.02672502255118161
[Epoch 19, Batch 1200] loss: 0.01241953829607155
[Epoch 19, Batch 1300] loss: 0.019457313286839053
[Epoch 19, Batch 1400] loss: 0.017257274669500475
[Epoch 19, Batch 1500] loss: 0.01791247792172726
[Epoch 19, Batch 1600] loss: 0.019744771005935035
[Epoch 19, Batch 1700] loss: 0.020279586794495118
[Epoch 19, Batch 1800] loss: 0.030329489655268844
[Epoch 19, Batch 1900] loss: 0.015057914233566408
[Epoch 19, Batch 2000] loss: 0.023029978007507453
[Epoch 19, Batch 2100] loss: 0.01545350061111094
[Epoch 19, Batch 2200] loss: 0.01614050267082348
[Epoch 19, Batch 2300] loss: 0.020053675533417845
[Epoch 19, Batch 2400] loss: 0.021377896550984588
[Epoch 19, Batch 2500] loss: 0.013006098172991188
[Epoch 19, Batch 2600] loss: 0.013501059674199496
[Epoch 19, Batch 2700] loss: 0.01911916826507877
[Epoch 19, Batch 2800] loss: 0.019536362023864058
[Epoch 19, Batch 2900] loss: 0.01881144850714918
[Epoch 19, Batch 3000] loss: 0.02124319479433325
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9863
Overfitting: 0.0501
Best model saved at epoch 19 with validation loss: 0.0501
[Epoch 20, Batch 100] loss: 0.014770983682519728
[Epoch 20, Batch 200] loss: 0.011115911680863065
[Epoch 20, Batch 300] loss: 0.020163424661477622
[Epoch 20, Batch 400] loss: 0.01263940385357273
[Epoch 20, Batch 500] loss: 0.015016970556171145
[Epoch 20, Batch 600] loss: 0.019505127261181768
[Epoch 20, Batch 700] loss: 0.021510581044640275
[Epoch 20, Batch 800] loss: 0.021470580116510974
[Epoch 20, Batch 900] loss: 0.020427386279006896
[Epoch 20, Batch 1000] loss: 0.02014053360406251
[Epoch 20, Batch 1100] loss: 0.03218290745353443
[Epoch 20, Batch 1200] loss: 0.019948667677599587
[Epoch 20, Batch 1300] loss: 0.017310124921641544
[Epoch 20, Batch 1400] loss: 0.015160361386660952
[Epoch 20, Batch 1500] loss: 0.014761114530410851
[Epoch 20, Batch 1600] loss: 0.022358992088757076
[Epoch 20, Batch 1700] loss: 0.02062654409372044
[Epoch 20, Batch 1800] loss: 0.014216385443651234
[Epoch 20, Batch 1900] loss: 0.02782816060796904
[Epoch 20, Batch 2000] loss: 0.01928530562814558
[Epoch 20, Batch 2100] loss: 0.014649789727754978
[Epoch 20, Batch 2200] loss: 0.014522262348291405
[Epoch 20, Batch 2300] loss: 0.020160889377511922
[Epoch 20, Batch 2400] loss: 0.010921359525891603
[Epoch 20, Batch 2500] loss: 0.01504479714810259
[Epoch 20, Batch 2600] loss: 0.012234444148562033
[Epoch 20, Batch 2700] loss: 0.022963140158935857
[Epoch 20, Batch 2800] loss: 0.01922807685150474
[Epoch 20, Batch 2900] loss: 0.01874205910728051
[Epoch 20, Batch 3000] loss: 0.037115632977656784
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0541
Validation Accuracy: 0.9852
Overfitting: 0.0541
[Epoch 21, Batch 100] loss: 0.015323083844123175
[Epoch 21, Batch 200] loss: 0.019902010168952985
[Epoch 21, Batch 300] loss: 0.01253519803063682
[Epoch 21, Batch 400] loss: 0.010780404358247325
[Epoch 21, Batch 500] loss: 0.012675186904698422
[Epoch 21, Batch 600] loss: 0.008803857955645072
[Epoch 21, Batch 700] loss: 0.012313419499987504
[Epoch 21, Batch 800] loss: 0.017341090711270227
[Epoch 21, Batch 900] loss: 0.02155403051972826
[Epoch 21, Batch 1000] loss: 0.021788752517459216
[Epoch 21, Batch 1100] loss: 0.021216498396606765
[Epoch 21, Batch 1200] loss: 0.016718324967332592
[Epoch 21, Batch 1300] loss: 0.017142406979983208
[Epoch 21, Batch 1400] loss: 0.018556265692786837
[Epoch 21, Batch 1500] loss: 0.013014419006813114
[Epoch 21, Batch 1600] loss: 0.016907399776282545
[Epoch 21, Batch 1700] loss: 0.012936455416565877
[Epoch 21, Batch 1800] loss: 0.030361795456919936
[Epoch 21, Batch 1900] loss: 0.02086324629824958
[Epoch 21, Batch 2000] loss: 0.024685000818572007
[Epoch 21, Batch 2100] loss: 0.014939475547062103
[Epoch 21, Batch 2200] loss: 0.012144966030045907
[Epoch 21, Batch 2300] loss: 0.018934627249400364
[Epoch 21, Batch 2400] loss: 0.01986987885538838
[Epoch 21, Batch 2500] loss: 0.016804740424850025
[Epoch 21, Batch 2600] loss: 0.014168892551606405
[Epoch 21, Batch 2700] loss: 0.0136305020904274
[Epoch 21, Batch 2800] loss: 0.02508041864139159
[Epoch 21, Batch 2900] loss: 0.012864705930669516
[Epoch 21, Batch 3000] loss: 0.021581486111117557
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0498
Validation Accuracy: 0.9860
Overfitting: 0.0498
Best model saved at epoch 21 with validation loss: 0.0498
[Epoch 22, Batch 100] loss: 0.013982733638358695
[Epoch 22, Batch 200] loss: 0.015208405947669234
[Epoch 22, Batch 300] loss: 0.020758411066126428
[Epoch 22, Batch 400] loss: 0.013278597818061826
[Epoch 22, Batch 500] loss: 0.012759806160793231
[Epoch 22, Batch 600] loss: 0.015366583860341052
[Epoch 22, Batch 700] loss: 0.014722233433058136
[Epoch 22, Batch 800] loss: 0.012406758920114953
[Epoch 22, Batch 900] loss: 0.01636341338737111
[Epoch 22, Batch 1000] loss: 0.020942322158807657
[Epoch 22, Batch 1100] loss: 0.015107079257431906
[Epoch 22, Batch 1200] loss: 0.01733330042035959
[Epoch 22, Batch 1300] loss: 0.010375892775355168
[Epoch 22, Batch 1400] loss: 0.012544524822405947
[Epoch 22, Batch 1500] loss: 0.015788522594357347
[Epoch 22, Batch 1600] loss: 0.005802000687690451
[Epoch 22, Batch 1700] loss: 0.017604249160976904
[Epoch 22, Batch 1800] loss: 0.02235745555779431
[Epoch 22, Batch 1900] loss: 0.011486043205077295
[Epoch 22, Batch 2000] loss: 0.01901147446642426
[Epoch 22, Batch 2100] loss: 0.010903513752455183
[Epoch 22, Batch 2200] loss: 0.013831027104806708
[Epoch 22, Batch 2300] loss: 0.0132715796552111
[Epoch 22, Batch 2400] loss: 0.027895896111876938
[Epoch 22, Batch 2500] loss: 0.005936712941111182
[Epoch 22, Batch 2600] loss: 0.02082760553206754
[Epoch 22, Batch 2700] loss: 0.018697425900822965
[Epoch 22, Batch 2800] loss: 0.02001066980379619
[Epoch 22, Batch 2900] loss: 0.014867070457985392
[Epoch 22, Batch 3000] loss: 0.027252611237636302
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9859
Overfitting: 0.0510
[Epoch 23, Batch 100] loss: 0.01686005725783616
[Epoch 23, Batch 200] loss: 0.016268415388658468
[Epoch 23, Batch 300] loss: 0.013785493522300385
[Epoch 23, Batch 400] loss: 0.014586860997151235
[Epoch 23, Batch 500] loss: 0.0101551104612372
[Epoch 23, Batch 600] loss: 0.01171537818516299
[Epoch 23, Batch 700] loss: 0.01375139408863106
[Epoch 23, Batch 800] loss: 0.0077160963513961175
[Epoch 23, Batch 900] loss: 0.023183595007449185
[Epoch 23, Batch 1000] loss: 0.012412860591102798
[Epoch 23, Batch 1100] loss: 0.015943588992954574
[Epoch 23, Batch 1200] loss: 0.015527509764579008
[Epoch 23, Batch 1300] loss: 0.01625943040009588
[Epoch 23, Batch 1400] loss: 0.01321449962537372
[Epoch 23, Batch 1500] loss: 0.020331872924107302
[Epoch 23, Batch 1600] loss: 0.0147851271242871
[Epoch 23, Batch 1700] loss: 0.0143211538561809
[Epoch 23, Batch 1800] loss: 0.012171137928708048
[Epoch 23, Batch 1900] loss: 0.017588920164598676
[Epoch 23, Batch 2000] loss: 0.012290706679377763
[Epoch 23, Batch 2100] loss: 0.024397669626159767
[Epoch 23, Batch 2200] loss: 0.019170057765677484
[Epoch 23, Batch 2300] loss: 0.011660511355530616
[Epoch 23, Batch 2400] loss: 0.00858454816032463
[Epoch 23, Batch 2500] loss: 0.015827261951435502
[Epoch 23, Batch 2600] loss: 0.015415885865195378
[Epoch 23, Batch 2700] loss: 0.011140878164824244
[Epoch 23, Batch 2800] loss: 0.010310054428955481
[Epoch 23, Batch 2900] loss: 0.010452960770126083
[Epoch 23, Batch 3000] loss: 0.023043789173461848
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9856
Overfitting: 0.0519
[Epoch 24, Batch 100] loss: 0.01046975092581306
[Epoch 24, Batch 200] loss: 0.011293678170941348
[Epoch 24, Batch 300] loss: 0.007250769324173234
[Epoch 24, Batch 400] loss: 0.016319766277028976
[Epoch 24, Batch 500] loss: 0.009015404800720717
[Epoch 24, Batch 600] loss: 0.008042946481746185
[Epoch 24, Batch 700] loss: 0.012022754012668883
[Epoch 24, Batch 800] loss: 0.020137006976337943
[Epoch 24, Batch 900] loss: 0.014827087652738555
[Epoch 24, Batch 1000] loss: 0.01571937648821631
[Epoch 24, Batch 1100] loss: 0.00983298757686498
[Epoch 24, Batch 1200] loss: 0.02315450131047328
[Epoch 24, Batch 1300] loss: 0.01845850669193169
[Epoch 24, Batch 1400] loss: 0.01226114080552179
[Epoch 24, Batch 1500] loss: 0.010890619920055543
[Epoch 24, Batch 1600] loss: 0.013272214789831196
[Epoch 24, Batch 1700] loss: 0.014840862652927172
[Epoch 24, Batch 1800] loss: 0.007234868993618875
[Epoch 24, Batch 1900] loss: 0.00960305414636423
[Epoch 24, Batch 2000] loss: 0.017669261188348172
[Epoch 24, Batch 2100] loss: 0.01256316409100691
[Epoch 24, Batch 2200] loss: 0.010626916969367812
[Epoch 24, Batch 2300] loss: 0.011680343560001347
[Epoch 24, Batch 2400] loss: 0.013037005117821536
[Epoch 24, Batch 2500] loss: 0.028800988839939236
[Epoch 24, Batch 2600] loss: 0.013782826744863997
[Epoch 24, Batch 2700] loss: 0.011666056268059038
[Epoch 24, Batch 2800] loss: 0.017730155551853387
[Epoch 24, Batch 2900] loss: 0.03106335732459229
[Epoch 24, Batch 3000] loss: 0.009581929320047493
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9867
Overfitting: 0.0524
Fold 2 validation loss: 0.0524
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.302553024291992
[Epoch 1, Batch 200] loss: 2.2884161949157713
[Epoch 1, Batch 300] loss: 2.275938286781311
[Epoch 1, Batch 400] loss: 2.257886369228363
[Epoch 1, Batch 500] loss: 2.225716154575348
[Epoch 1, Batch 600] loss: 2.1763038277626037
[Epoch 1, Batch 700] loss: 2.061687541007996
[Epoch 1, Batch 800] loss: 1.8345537829399108
[Epoch 1, Batch 900] loss: 1.3453392606973649
[Epoch 1, Batch 1000] loss: 0.901688771545887
[Epoch 1, Batch 1100] loss: 0.7243997415900231
[Epoch 1, Batch 1200] loss: 0.6430734184384346
[Epoch 1, Batch 1300] loss: 0.5560857474803924
[Epoch 1, Batch 1400] loss: 0.5565128491818905
[Epoch 1, Batch 1500] loss: 0.49371250823140145
[Epoch 1, Batch 1600] loss: 0.4955788926780224
[Epoch 1, Batch 1700] loss: 0.4622326023131609
[Epoch 1, Batch 1800] loss: 0.3898366682231426
[Epoch 1, Batch 1900] loss: 0.42116471126675603
[Epoch 1, Batch 2000] loss: 0.4396027848124504
[Epoch 1, Batch 2100] loss: 0.35776876874268054
[Epoch 1, Batch 2200] loss: 0.3832203959673643
[Epoch 1, Batch 2300] loss: 0.3481594032421708
[Epoch 1, Batch 2400] loss: 0.3172286516427994
[Epoch 1, Batch 2500] loss: 0.33232017412781717
[Epoch 1, Batch 2600] loss: 0.2763034289330244
[Epoch 1, Batch 2700] loss: 0.284803651869297
[Epoch 1, Batch 2800] loss: 0.2989985798485577
[Epoch 1, Batch 2900] loss: 0.2686808217316866
[Epoch 1, Batch 3000] loss: 0.28720602933317424
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2742
Validation Accuracy: 0.9197
Overfitting: 0.2742
Best model saved at epoch 1 with validation loss: 0.2742
[Epoch 2, Batch 100] loss: 0.24869644964113832
[Epoch 2, Batch 200] loss: 0.2591887595131993
[Epoch 2, Batch 300] loss: 0.25328230910003185
[Epoch 2, Batch 400] loss: 0.24273270765319466
[Epoch 2, Batch 500] loss: 0.2508934166654944
[Epoch 2, Batch 600] loss: 0.25166882798075674
[Epoch 2, Batch 700] loss: 0.23404910889454186
[Epoch 2, Batch 800] loss: 0.2057239749468863
[Epoch 2, Batch 900] loss: 0.22549901480786502
[Epoch 2, Batch 1000] loss: 0.20817391065880655
[Epoch 2, Batch 1100] loss: 0.21700906852260232
[Epoch 2, Batch 1200] loss: 0.19495416428893805
[Epoch 2, Batch 1300] loss: 0.18566698821261526
[Epoch 2, Batch 1400] loss: 0.17301216000691055
[Epoch 2, Batch 1500] loss: 0.14149283322505654
[Epoch 2, Batch 1600] loss: 0.18351272189989687
[Epoch 2, Batch 1700] loss: 0.18002131614834072
[Epoch 2, Batch 1800] loss: 0.22290943192318083
[Epoch 2, Batch 1900] loss: 0.17559793949127198
[Epoch 2, Batch 2000] loss: 0.19162927459925413
[Epoch 2, Batch 2100] loss: 0.15128159496933222
[Epoch 2, Batch 2200] loss: 0.15039285968989133
[Epoch 2, Batch 2300] loss: 0.1530495680309832
[Epoch 2, Batch 2400] loss: 0.15611170419491827
[Epoch 2, Batch 2500] loss: 0.14578958899248393
[Epoch 2, Batch 2600] loss: 0.15404511035420002
[Epoch 2, Batch 2700] loss: 0.1570155509142205
[Epoch 2, Batch 2800] loss: 0.15325779770035297
[Epoch 2, Batch 2900] loss: 0.1485728930030018
[Epoch 2, Batch 3000] loss: 0.18482576124370098
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1503
Validation Accuracy: 0.9560
Overfitting: 0.1503
Best model saved at epoch 2 with validation loss: 0.1503
[Epoch 3, Batch 100] loss: 0.15134443590417504
[Epoch 3, Batch 200] loss: 0.13453522935509682
[Epoch 3, Batch 300] loss: 0.14471830885857342
[Epoch 3, Batch 400] loss: 0.1467966731498018
[Epoch 3, Batch 500] loss: 0.12369905614759773
[Epoch 3, Batch 600] loss: 0.11066759607754648
[Epoch 3, Batch 700] loss: 0.15086522071622313
[Epoch 3, Batch 800] loss: 0.12899417172186076
[Epoch 3, Batch 900] loss: 0.1523546687839553
[Epoch 3, Batch 1000] loss: 0.09869170598685742
[Epoch 3, Batch 1100] loss: 0.1145553064532578
[Epoch 3, Batch 1200] loss: 0.132549917884171
[Epoch 3, Batch 1300] loss: 0.11034833094920032
[Epoch 3, Batch 1400] loss: 0.12887777007184922
[Epoch 3, Batch 1500] loss: 0.10223117045592517
[Epoch 3, Batch 1600] loss: 0.11816104589262977
[Epoch 3, Batch 1700] loss: 0.11451340443920344
[Epoch 3, Batch 1800] loss: 0.12785519556142388
[Epoch 3, Batch 1900] loss: 0.10758990998612716
[Epoch 3, Batch 2000] loss: 0.14483584830770269
[Epoch 3, Batch 2100] loss: 0.14444565677084029
[Epoch 3, Batch 2200] loss: 0.1294848545640707
[Epoch 3, Batch 2300] loss: 0.10007181006716565
[Epoch 3, Batch 2400] loss: 0.10635402142535895
[Epoch 3, Batch 2500] loss: 0.09343746868427844
[Epoch 3, Batch 2600] loss: 0.1158863756316714
[Epoch 3, Batch 2700] loss: 0.11190872053150087
[Epoch 3, Batch 2800] loss: 0.09870404563378543
[Epoch 3, Batch 2900] loss: 0.10227611719164997
[Epoch 3, Batch 3000] loss: 0.08882041677017696
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1094
Validation Accuracy: 0.9683
Overfitting: 0.1094
Best model saved at epoch 3 with validation loss: 0.1094
[Epoch 4, Batch 100] loss: 0.08973043330945074
[Epoch 4, Batch 200] loss: 0.09773278550826944
[Epoch 4, Batch 300] loss: 0.11094152826350183
[Epoch 4, Batch 400] loss: 0.0933306750189513
[Epoch 4, Batch 500] loss: 0.0988541134330444
[Epoch 4, Batch 600] loss: 0.10916604176396504
[Epoch 4, Batch 700] loss: 0.09510855329455808
[Epoch 4, Batch 800] loss: 0.1071105297608301
[Epoch 4, Batch 900] loss: 0.11316275110468269
[Epoch 4, Batch 1000] loss: 0.06447293902165256
[Epoch 4, Batch 1100] loss: 0.0814663049671799
[Epoch 4, Batch 1200] loss: 0.0816611374123022
[Epoch 4, Batch 1300] loss: 0.10105889671831392
[Epoch 4, Batch 1400] loss: 0.09651919325464405
[Epoch 4, Batch 1500] loss: 0.09093414010945708
[Epoch 4, Batch 1600] loss: 0.07884244418353774
[Epoch 4, Batch 1700] loss: 0.10900908971438185
[Epoch 4, Batch 1800] loss: 0.0840711630822625
[Epoch 4, Batch 1900] loss: 0.08527366078924388
[Epoch 4, Batch 2000] loss: 0.09311121056089178
[Epoch 4, Batch 2100] loss: 0.08856795642990618
[Epoch 4, Batch 2200] loss: 0.09120768050663174
[Epoch 4, Batch 2300] loss: 0.08968032348435372
[Epoch 4, Batch 2400] loss: 0.09800121422158554
[Epoch 4, Batch 2500] loss: 0.10364389046560973
[Epoch 4, Batch 2600] loss: 0.08449647198896855
[Epoch 4, Batch 2700] loss: 0.08812134353909641
[Epoch 4, Batch 2800] loss: 0.09081943107536063
[Epoch 4, Batch 2900] loss: 0.07362752750865184
[Epoch 4, Batch 3000] loss: 0.08930810031713918
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0952
Validation Accuracy: 0.9725
Overfitting: 0.0952
Best model saved at epoch 4 with validation loss: 0.0952
[Epoch 5, Batch 100] loss: 0.08071727073052898
[Epoch 5, Batch 200] loss: 0.08509976892033592
[Epoch 5, Batch 300] loss: 0.07696936478372664
[Epoch 5, Batch 400] loss: 0.07222135325078853
[Epoch 5, Batch 500] loss: 0.08508629005285911
[Epoch 5, Batch 600] loss: 0.07127295076847076
[Epoch 5, Batch 700] loss: 0.0855520880012773
[Epoch 5, Batch 800] loss: 0.07912615296896547
[Epoch 5, Batch 900] loss: 0.07517436778289266
[Epoch 5, Batch 1000] loss: 0.09775749206077307
[Epoch 5, Batch 1100] loss: 0.08247711996780709
[Epoch 5, Batch 1200] loss: 0.07331191930687055
[Epoch 5, Batch 1300] loss: 0.06386959557654336
[Epoch 5, Batch 1400] loss: 0.07022506457171403
[Epoch 5, Batch 1500] loss: 0.08071308040060103
[Epoch 5, Batch 1600] loss: 0.07388545978465118
[Epoch 5, Batch 1700] loss: 0.08625360337086022
[Epoch 5, Batch 1800] loss: 0.07513815852929838
[Epoch 5, Batch 1900] loss: 0.07770471171592362
[Epoch 5, Batch 2000] loss: 0.08285705312853679
[Epoch 5, Batch 2100] loss: 0.08483005337417125
[Epoch 5, Batch 2200] loss: 0.0785877926996909
[Epoch 5, Batch 2300] loss: 0.08261628272128291
[Epoch 5, Batch 2400] loss: 0.08432803019182757
[Epoch 5, Batch 2500] loss: 0.07183992416248657
[Epoch 5, Batch 2600] loss: 0.07904644118156284
[Epoch 5, Batch 2700] loss: 0.05607864758174401
[Epoch 5, Batch 2800] loss: 0.08106257705425378
[Epoch 5, Batch 2900] loss: 0.06288586456794291
[Epoch 5, Batch 3000] loss: 0.05622158426791429
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0826
Validation Accuracy: 0.9758
Overfitting: 0.0826
Best model saved at epoch 5 with validation loss: 0.0826
[Epoch 6, Batch 100] loss: 0.07733975300303428
[Epoch 6, Batch 200] loss: 0.066375219700858
[Epoch 6, Batch 300] loss: 0.0680198054970242
[Epoch 6, Batch 400] loss: 0.07829122057009955
[Epoch 6, Batch 500] loss: 0.07579176991654095
[Epoch 6, Batch 600] loss: 0.08659386034938507
[Epoch 6, Batch 700] loss: 0.0497798388346564
[Epoch 6, Batch 800] loss: 0.06430156720336527
[Epoch 6, Batch 900] loss: 0.06728177072363906
[Epoch 6, Batch 1000] loss: 0.06395503218984232
[Epoch 6, Batch 1100] loss: 0.061444972429890186
[Epoch 6, Batch 1200] loss: 0.06903566452674567
[Epoch 6, Batch 1300] loss: 0.06258872514590622
[Epoch 6, Batch 1400] loss: 0.05988156953710131
[Epoch 6, Batch 1500] loss: 0.0475619902566541
[Epoch 6, Batch 1600] loss: 0.06139771976624615
[Epoch 6, Batch 1700] loss: 0.0732304536330048
[Epoch 6, Batch 1800] loss: 0.07873629193403758
[Epoch 6, Batch 1900] loss: 0.06454756062594243
[Epoch 6, Batch 2000] loss: 0.06839123608544469
[Epoch 6, Batch 2100] loss: 0.06231144245364703
[Epoch 6, Batch 2200] loss: 0.06568563451524824
[Epoch 6, Batch 2300] loss: 0.06592544999439269
[Epoch 6, Batch 2400] loss: 0.06738508902373724
[Epoch 6, Batch 2500] loss: 0.06429737510741688
[Epoch 6, Batch 2600] loss: 0.0665428292483557
[Epoch 6, Batch 2700] loss: 0.04554628890007734
[Epoch 6, Batch 2800] loss: 0.05342938159941696
[Epoch 6, Batch 2900] loss: 0.05154636900057085
[Epoch 6, Batch 3000] loss: 0.09123718864982948
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0750
Validation Accuracy: 0.9784
Overfitting: 0.0750
Best model saved at epoch 6 with validation loss: 0.0750
[Epoch 7, Batch 100] loss: 0.05813893788174027
[Epoch 7, Batch 200] loss: 0.04997705374262296
[Epoch 7, Batch 300] loss: 0.05994937531184405
[Epoch 7, Batch 400] loss: 0.058491647344781086
[Epoch 7, Batch 500] loss: 0.06955999557045288
[Epoch 7, Batch 600] loss: 0.05992171619902365
[Epoch 7, Batch 700] loss: 0.05818719932693057
[Epoch 7, Batch 800] loss: 0.06319915787724312
[Epoch 7, Batch 900] loss: 0.05683204274857417
[Epoch 7, Batch 1000] loss: 0.06403883813705762
[Epoch 7, Batch 1100] loss: 0.06723405430908315
[Epoch 7, Batch 1200] loss: 0.06005067058547866
[Epoch 7, Batch 1300] loss: 0.06509779325220734
[Epoch 7, Batch 1400] loss: 0.04931459572981112
[Epoch 7, Batch 1500] loss: 0.051479306036490015
[Epoch 7, Batch 1600] loss: 0.05051613347081002
[Epoch 7, Batch 1700] loss: 0.038400454099173656
[Epoch 7, Batch 1800] loss: 0.048306069264071994
[Epoch 7, Batch 1900] loss: 0.057508172680391
[Epoch 7, Batch 2000] loss: 0.05611710766097531
[Epoch 7, Batch 2100] loss: 0.055941685698053335
[Epoch 7, Batch 2200] loss: 0.057737369362148454
[Epoch 7, Batch 2300] loss: 0.06835028698755195
[Epoch 7, Batch 2400] loss: 0.07267383564612828
[Epoch 7, Batch 2500] loss: 0.049333926533581686
[Epoch 7, Batch 2600] loss: 0.05659099435666576
[Epoch 7, Batch 2700] loss: 0.05972246461897157
[Epoch 7, Batch 2800] loss: 0.07521554522041697
[Epoch 7, Batch 2900] loss: 0.055362146768602544
[Epoch 7, Batch 3000] loss: 0.06426280684769153
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0689
Validation Accuracy: 0.9798
Overfitting: 0.0689
Best model saved at epoch 7 with validation loss: 0.0689
[Epoch 8, Batch 100] loss: 0.0621619397692848
[Epoch 8, Batch 200] loss: 0.032116610004450194
[Epoch 8, Batch 300] loss: 0.04687504945672117
[Epoch 8, Batch 400] loss: 0.05707250744715566
[Epoch 8, Batch 500] loss: 0.05790106745436788
[Epoch 8, Batch 600] loss: 0.040665741018601695
[Epoch 8, Batch 700] loss: 0.039390617489116264
[Epoch 8, Batch 800] loss: 0.04499339510512072
[Epoch 8, Batch 900] loss: 0.05836463831947185
[Epoch 8, Batch 1000] loss: 0.05588204670872074
[Epoch 8, Batch 1100] loss: 0.04956644906895235
[Epoch 8, Batch 1200] loss: 0.059480631006299516
[Epoch 8, Batch 1300] loss: 0.04314162471331656
[Epoch 8, Batch 1400] loss: 0.05285662806185428
[Epoch 8, Batch 1500] loss: 0.05846804731991142
[Epoch 8, Batch 1600] loss: 0.06129895654332358
[Epoch 8, Batch 1700] loss: 0.0497441876452649
[Epoch 8, Batch 1800] loss: 0.05906617024738807
[Epoch 8, Batch 1900] loss: 0.05653271822113311
[Epoch 8, Batch 2000] loss: 0.05861065977427643
[Epoch 8, Batch 2100] loss: 0.05184720061224653
[Epoch 8, Batch 2200] loss: 0.05254614320991095
[Epoch 8, Batch 2300] loss: 0.044729735973814966
[Epoch 8, Batch 2400] loss: 0.06841274337435607
[Epoch 8, Batch 2500] loss: 0.058328639038372786
[Epoch 8, Batch 2600] loss: 0.049760124555323276
[Epoch 8, Batch 2700] loss: 0.06559218746551779
[Epoch 8, Batch 2800] loss: 0.03956146106182132
[Epoch 8, Batch 2900] loss: 0.04943688623548951
[Epoch 8, Batch 3000] loss: 0.04422375066234963
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0612
Validation Accuracy: 0.9822
Overfitting: 0.0612
Best model saved at epoch 8 with validation loss: 0.0612
[Epoch 9, Batch 100] loss: 0.04728775841213064
[Epoch 9, Batch 200] loss: 0.05707858780049719
[Epoch 9, Batch 300] loss: 0.04966186354897218
[Epoch 9, Batch 400] loss: 0.05033790182962548
[Epoch 9, Batch 500] loss: 0.0641816346195992
[Epoch 9, Batch 600] loss: 0.04408917642344022
[Epoch 9, Batch 700] loss: 0.056597099674108906
[Epoch 9, Batch 800] loss: 0.05010236592439469
[Epoch 9, Batch 900] loss: 0.04000377755961381
[Epoch 9, Batch 1000] loss: 0.03408483373117633
[Epoch 9, Batch 1100] loss: 0.05485611260402948
[Epoch 9, Batch 1200] loss: 0.04046149965026416
[Epoch 9, Batch 1300] loss: 0.047582676802412606
[Epoch 9, Batch 1400] loss: 0.05015109474363271
[Epoch 9, Batch 1500] loss: 0.045563350941229146
[Epoch 9, Batch 1600] loss: 0.0470968065247871
[Epoch 9, Batch 1700] loss: 0.038993957604980096
[Epoch 9, Batch 1800] loss: 0.04275629926472902
[Epoch 9, Batch 1900] loss: 0.05986466497764922
[Epoch 9, Batch 2000] loss: 0.04253245184052503
[Epoch 9, Batch 2100] loss: 0.04072822473477572
[Epoch 9, Batch 2200] loss: 0.05723418278619647
[Epoch 9, Batch 2300] loss: 0.06806519108649808
[Epoch 9, Batch 2400] loss: 0.0353808588287211
[Epoch 9, Batch 2500] loss: 0.03521059303253424
[Epoch 9, Batch 2600] loss: 0.050315507365303345
[Epoch 9, Batch 2700] loss: 0.036524140266119505
[Epoch 9, Batch 2800] loss: 0.050560339330113495
[Epoch 9, Batch 2900] loss: 0.034490484453272074
[Epoch 9, Batch 3000] loss: 0.041816159751615484
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0587
Validation Accuracy: 0.9844
Overfitting: 0.0587
Best model saved at epoch 9 with validation loss: 0.0587
[Epoch 10, Batch 100] loss: 0.046194422730477525
[Epoch 10, Batch 200] loss: 0.03363386745215394
[Epoch 10, Batch 300] loss: 0.04056628488295246
[Epoch 10, Batch 400] loss: 0.05241148745029932
[Epoch 10, Batch 500] loss: 0.04025960019804188
[Epoch 10, Batch 600] loss: 0.03239328303534421
[Epoch 10, Batch 700] loss: 0.03414371288905386
[Epoch 10, Batch 800] loss: 0.03451894805737538
[Epoch 10, Batch 900] loss: 0.04471880019758828
[Epoch 10, Batch 1000] loss: 0.033157680873409846
[Epoch 10, Batch 1100] loss: 0.04358518154484045
[Epoch 10, Batch 1200] loss: 0.03715912448882591
[Epoch 10, Batch 1300] loss: 0.027888457078370267
[Epoch 10, Batch 1400] loss: 0.033139299403701444
[Epoch 10, Batch 1500] loss: 0.045599997962417545
[Epoch 10, Batch 1600] loss: 0.05247897437075153
[Epoch 10, Batch 1700] loss: 0.04487806075077969
[Epoch 10, Batch 1800] loss: 0.037024503641296176
[Epoch 10, Batch 1900] loss: 0.04269949922512751
[Epoch 10, Batch 2000] loss: 0.04722230759478407
[Epoch 10, Batch 2100] loss: 0.04952750714233844
[Epoch 10, Batch 2200] loss: 0.048879917350423054
[Epoch 10, Batch 2300] loss: 0.045947079628240316
[Epoch 10, Batch 2400] loss: 0.04154234647576231
[Epoch 10, Batch 2500] loss: 0.0450391873146873
[Epoch 10, Batch 2600] loss: 0.05223003172461176
[Epoch 10, Batch 2700] loss: 0.03746264863118995
[Epoch 10, Batch 2800] loss: 0.03898210565617774
[Epoch 10, Batch 2900] loss: 0.0526961975908489
[Epoch 10, Batch 3000] loss: 0.049270314313471314
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9845
Overfitting: 0.0570
Best model saved at epoch 10 with validation loss: 0.0570
[Epoch 11, Batch 100] loss: 0.02997047977143666
[Epoch 11, Batch 200] loss: 0.04016886164841708
[Epoch 11, Batch 300] loss: 0.03709600050438894
[Epoch 11, Batch 400] loss: 0.03703441554360325
[Epoch 11, Batch 500] loss: 0.03416800181235885
[Epoch 11, Batch 600] loss: 0.05064031763235107
[Epoch 11, Batch 700] loss: 0.044860026659443976
[Epoch 11, Batch 800] loss: 0.03171172203437891
[Epoch 11, Batch 900] loss: 0.04120339443034027
[Epoch 11, Batch 1000] loss: 0.03727454323321581
[Epoch 11, Batch 1100] loss: 0.03693845633213641
[Epoch 11, Batch 1200] loss: 0.03685644833312836
[Epoch 11, Batch 1300] loss: 0.03311349574782071
[Epoch 11, Batch 1400] loss: 0.03658318720321404
[Epoch 11, Batch 1500] loss: 0.03356422020035097
[Epoch 11, Batch 1600] loss: 0.03508828823978547
[Epoch 11, Batch 1700] loss: 0.044590276122180514
[Epoch 11, Batch 1800] loss: 0.041461858200782443
[Epoch 11, Batch 1900] loss: 0.045817027066659646
[Epoch 11, Batch 2000] loss: 0.034751248550601306
[Epoch 11, Batch 2100] loss: 0.03644517567139701
[Epoch 11, Batch 2200] loss: 0.053260065155700434
[Epoch 11, Batch 2300] loss: 0.035584012363106016
[Epoch 11, Batch 2400] loss: 0.028204967151978053
[Epoch 11, Batch 2500] loss: 0.035801975196809506
[Epoch 11, Batch 2600] loss: 0.032342256630654445
[Epoch 11, Batch 2700] loss: 0.052040648872207385
[Epoch 11, Batch 2800] loss: 0.04392190575657878
[Epoch 11, Batch 2900] loss: 0.041637957838829606
[Epoch 11, Batch 3000] loss: 0.04015555876743747
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0521
Validation Accuracy: 0.9852
Overfitting: 0.0521
Best model saved at epoch 11 with validation loss: 0.0521
[Epoch 12, Batch 100] loss: 0.027466193466680125
[Epoch 12, Batch 200] loss: 0.03577826222928707
[Epoch 12, Batch 300] loss: 0.03581042478464951
[Epoch 12, Batch 400] loss: 0.029143184602144174
[Epoch 12, Batch 500] loss: 0.029015663049067372
[Epoch 12, Batch 600] loss: 0.0391190720222221
[Epoch 12, Batch 700] loss: 0.04197820758883609
[Epoch 12, Batch 800] loss: 0.036090269526903286
[Epoch 12, Batch 900] loss: 0.038323981043358796
[Epoch 12, Batch 1000] loss: 0.03379314138845075
[Epoch 12, Batch 1100] loss: 0.039248863762768454
[Epoch 12, Batch 1200] loss: 0.02663101091005956
[Epoch 12, Batch 1300] loss: 0.041368220280710376
[Epoch 12, Batch 1400] loss: 0.036701721708814146
[Epoch 12, Batch 1500] loss: 0.026527824363438413
[Epoch 12, Batch 1600] loss: 0.043802626390533984
[Epoch 12, Batch 1700] loss: 0.026849402023362928
[Epoch 12, Batch 1800] loss: 0.033062939879309854
[Epoch 12, Batch 1900] loss: 0.03813986307242885
[Epoch 12, Batch 2000] loss: 0.031219382475828752
[Epoch 12, Batch 2100] loss: 0.02968614785524551
[Epoch 12, Batch 2200] loss: 0.04320992055654642
[Epoch 12, Batch 2300] loss: 0.031490806440342564
[Epoch 12, Batch 2400] loss: 0.04479278318060096
[Epoch 12, Batch 2500] loss: 0.04026263577339705
[Epoch 12, Batch 2600] loss: 0.03119291742099449
[Epoch 12, Batch 2700] loss: 0.053899176091654226
[Epoch 12, Batch 2800] loss: 0.049876836535695475
[Epoch 12, Batch 2900] loss: 0.03075549445980869
[Epoch 12, Batch 3000] loss: 0.037162483690335646
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9854
Overfitting: 0.0510
Best model saved at epoch 12 with validation loss: 0.0510
[Epoch 13, Batch 100] loss: 0.0252715883590281
[Epoch 13, Batch 200] loss: 0.03341191852465272
[Epoch 13, Batch 300] loss: 0.03405885743239196
[Epoch 13, Batch 400] loss: 0.03144242596928962
[Epoch 13, Batch 500] loss: 0.03146212000166997
[Epoch 13, Batch 600] loss: 0.03052991558026406
[Epoch 13, Batch 700] loss: 0.04029067269293592
[Epoch 13, Batch 800] loss: 0.035738263566599926
[Epoch 13, Batch 900] loss: 0.034384556256845826
[Epoch 13, Batch 1000] loss: 0.026673843436001335
[Epoch 13, Batch 1100] loss: 0.030349633238802198
[Epoch 13, Batch 1200] loss: 0.03411609329894418
[Epoch 13, Batch 1300] loss: 0.025826507753299664
[Epoch 13, Batch 1400] loss: 0.032426841483975295
[Epoch 13, Batch 1500] loss: 0.036322336329030806
[Epoch 13, Batch 1600] loss: 0.03433238370838808
[Epoch 13, Batch 1700] loss: 0.023196566435799468
[Epoch 13, Batch 1800] loss: 0.02910383418711717
[Epoch 13, Batch 1900] loss: 0.0401506184367463
[Epoch 13, Batch 2000] loss: 0.037771513049956414
[Epoch 13, Batch 2100] loss: 0.03852203475529677
[Epoch 13, Batch 2200] loss: 0.028385497051349375
[Epoch 13, Batch 2300] loss: 0.03557873346522683
[Epoch 13, Batch 2400] loss: 0.031295605493651235
[Epoch 13, Batch 2500] loss: 0.04736938921851106
[Epoch 13, Batch 2600] loss: 0.0218990598997334
[Epoch 13, Batch 2700] loss: 0.0338910479140759
[Epoch 13, Batch 2800] loss: 0.04736679483321495
[Epoch 13, Batch 2900] loss: 0.026398895106394774
[Epoch 13, Batch 3000] loss: 0.02425819451615098
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9851
Overfitting: 0.0506
Best model saved at epoch 13 with validation loss: 0.0506
[Epoch 14, Batch 100] loss: 0.03141108121722937
[Epoch 14, Batch 200] loss: 0.03358266138282488
[Epoch 14, Batch 300] loss: 0.03390257562081388
[Epoch 14, Batch 400] loss: 0.01970260061105364
[Epoch 14, Batch 500] loss: 0.02022789958573412
[Epoch 14, Batch 600] loss: 0.028384471641475104
[Epoch 14, Batch 700] loss: 0.03133107648522127
[Epoch 14, Batch 800] loss: 0.040367239979532316
[Epoch 14, Batch 900] loss: 0.02184535870561376
[Epoch 14, Batch 1000] loss: 0.027584038021304876
[Epoch 14, Batch 1100] loss: 0.026697095533527317
[Epoch 14, Batch 1200] loss: 0.0347888980616699
[Epoch 14, Batch 1300] loss: 0.023202804226311855
[Epoch 14, Batch 1400] loss: 0.029391275158995995
[Epoch 14, Batch 1500] loss: 0.022174568887785427
[Epoch 14, Batch 1600] loss: 0.025911115531635005
[Epoch 14, Batch 1700] loss: 0.05008524459422915
[Epoch 14, Batch 1800] loss: 0.02992900160883437
[Epoch 14, Batch 1900] loss: 0.017894946899905336
[Epoch 14, Batch 2000] loss: 0.020914140037057223
[Epoch 14, Batch 2100] loss: 0.02825951569902827
[Epoch 14, Batch 2200] loss: 0.041581659739895256
[Epoch 14, Batch 2300] loss: 0.03870494922564831
[Epoch 14, Batch 2400] loss: 0.038848109996906716
[Epoch 14, Batch 2500] loss: 0.0330521290381148
[Epoch 14, Batch 2600] loss: 0.02513131592713762
[Epoch 14, Batch 2700] loss: 0.04061261939961696
[Epoch 14, Batch 2800] loss: 0.030844725794158877
[Epoch 14, Batch 2900] loss: 0.03209270646853838
[Epoch 14, Batch 3000] loss: 0.032969206194684374
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9862
Overfitting: 0.0500
Best model saved at epoch 14 with validation loss: 0.0500
[Epoch 15, Batch 100] loss: 0.018186449687345885
[Epoch 15, Batch 200] loss: 0.029628960222617025
[Epoch 15, Batch 300] loss: 0.03610491751489462
[Epoch 15, Batch 400] loss: 0.02098490441494505
[Epoch 15, Batch 500] loss: 0.02001408133248333
[Epoch 15, Batch 600] loss: 0.02527168053886271
[Epoch 15, Batch 700] loss: 0.03169202135803061
[Epoch 15, Batch 800] loss: 0.022830323141242843
[Epoch 15, Batch 900] loss: 0.02361080178481643
[Epoch 15, Batch 1000] loss: 0.02696830205946753
[Epoch 15, Batch 1100] loss: 0.029560170890181325
[Epoch 15, Batch 1200] loss: 0.024842469465402247
[Epoch 15, Batch 1300] loss: 0.037645147068942605
[Epoch 15, Batch 1400] loss: 0.028724816282337997
[Epoch 15, Batch 1500] loss: 0.023773359152619376
[Epoch 15, Batch 1600] loss: 0.039138609052170065
[Epoch 15, Batch 1700] loss: 0.026037095780629897
[Epoch 15, Batch 1800] loss: 0.022053909865062452
[Epoch 15, Batch 1900] loss: 0.027022218379715923
[Epoch 15, Batch 2000] loss: 0.034659627160144736
[Epoch 15, Batch 2100] loss: 0.023211759924161014
[Epoch 15, Batch 2200] loss: 0.031311062748045515
[Epoch 15, Batch 2300] loss: 0.032622296120243845
[Epoch 15, Batch 2400] loss: 0.02400616154569434
[Epoch 15, Batch 2500] loss: 0.027521665151289197
[Epoch 15, Batch 2600] loss: 0.032215136079066724
[Epoch 15, Batch 2700] loss: 0.03486399330467975
[Epoch 15, Batch 2800] loss: 0.024268656831518454
[Epoch 15, Batch 2900] loss: 0.021635363447421695
[Epoch 15, Batch 3000] loss: 0.026396261308400427
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9858
Overfitting: 0.0519
[Epoch 16, Batch 100] loss: 0.03001499192905612
[Epoch 16, Batch 200] loss: 0.01704102321033133
[Epoch 16, Batch 300] loss: 0.01761428590180003
[Epoch 16, Batch 400] loss: 0.026890202109207166
[Epoch 16, Batch 500] loss: 0.018920499733430917
[Epoch 16, Batch 600] loss: 0.017758648017334053
[Epoch 16, Batch 700] loss: 0.016246775073886964
[Epoch 16, Batch 800] loss: 0.028562165692201234
[Epoch 16, Batch 900] loss: 0.02235166488251707
[Epoch 16, Batch 1000] loss: 0.02368137868004851
[Epoch 16, Batch 1100] loss: 0.02586753750903881
[Epoch 16, Batch 1200] loss: 0.04938524913734
[Epoch 16, Batch 1300] loss: 0.0291310574914678
[Epoch 16, Batch 1400] loss: 0.021220896942049875
[Epoch 16, Batch 1500] loss: 0.03335854747929261
[Epoch 16, Batch 1600] loss: 0.02763065476960037
[Epoch 16, Batch 1700] loss: 0.02055802320363
[Epoch 16, Batch 1800] loss: 0.029266180730701308
[Epoch 16, Batch 1900] loss: 0.021777783158577223
[Epoch 16, Batch 2000] loss: 0.035967456207581565
[Epoch 16, Batch 2100] loss: 0.022462302153071503
[Epoch 16, Batch 2200] loss: 0.01844559105567896
[Epoch 16, Batch 2300] loss: 0.027054288412546156
[Epoch 16, Batch 2400] loss: 0.03415193650522269
[Epoch 16, Batch 2500] loss: 0.032752987719504745
[Epoch 16, Batch 2600] loss: 0.016096574820985553
[Epoch 16, Batch 2700] loss: 0.020396104272585945
[Epoch 16, Batch 2800] loss: 0.03207968344693654
[Epoch 16, Batch 2900] loss: 0.030965333738786283
[Epoch 16, Batch 3000] loss: 0.024390145078214118
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9847
Overfitting: 0.0534
[Epoch 17, Batch 100] loss: 0.0186253782849235
[Epoch 17, Batch 200] loss: 0.025037498979691007
[Epoch 17, Batch 300] loss: 0.030222228978964268
[Epoch 17, Batch 400] loss: 0.026484629818733084
[Epoch 17, Batch 500] loss: 0.021822688040538198
[Epoch 17, Batch 600] loss: 0.017604976116890613
[Epoch 17, Batch 700] loss: 0.026090941658330848
[Epoch 17, Batch 800] loss: 0.017111343426513485
[Epoch 17, Batch 900] loss: 0.020928647647633625
[Epoch 17, Batch 1000] loss: 0.02060918943636352
[Epoch 17, Batch 1100] loss: 0.018776966164514308
[Epoch 17, Batch 1200] loss: 0.03688264178825193
[Epoch 17, Batch 1300] loss: 0.019838453744559958
[Epoch 17, Batch 1400] loss: 0.019205238160029694
[Epoch 17, Batch 1500] loss: 0.013765019892452983
[Epoch 17, Batch 1600] loss: 0.02533703727043758
[Epoch 17, Batch 1700] loss: 0.0349984471758944
[Epoch 17, Batch 1800] loss: 0.026439322034420912
[Epoch 17, Batch 1900] loss: 0.023085690081497887
[Epoch 17, Batch 2000] loss: 0.020586947929041345
[Epoch 17, Batch 2100] loss: 0.03896773406107968
[Epoch 17, Batch 2200] loss: 0.027055933671654202
[Epoch 17, Batch 2300] loss: 0.021302268141444074
[Epoch 17, Batch 2400] loss: 0.015196455627119576
[Epoch 17, Batch 2500] loss: 0.0397549913657349
[Epoch 17, Batch 2600] loss: 0.023258052257224337
[Epoch 17, Batch 2700] loss: 0.017609521757149197
[Epoch 17, Batch 2800] loss: 0.016006358734011884
[Epoch 17, Batch 2900] loss: 0.021098591803165617
[Epoch 17, Batch 3000] loss: 0.03835976374553866
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9848
Overfitting: 0.0510
[Epoch 18, Batch 100] loss: 0.019485890928990557
[Epoch 18, Batch 200] loss: 0.014715579840049032
[Epoch 18, Batch 300] loss: 0.02205731900783576
[Epoch 18, Batch 400] loss: 0.022791304984857562
[Epoch 18, Batch 500] loss: 0.01908565355144674
[Epoch 18, Batch 600] loss: 0.02234151208002004
[Epoch 18, Batch 700] loss: 0.02069241450525624
[Epoch 18, Batch 800] loss: 0.033164219743412104
[Epoch 18, Batch 900] loss: 0.01751088508994144
[Epoch 18, Batch 1000] loss: 0.022461689290430513
[Epoch 18, Batch 1100] loss: 0.02406242549117451
[Epoch 18, Batch 1200] loss: 0.023119460245216033
[Epoch 18, Batch 1300] loss: 0.028468602805078264
[Epoch 18, Batch 1400] loss: 0.020822056506822263
[Epoch 18, Batch 1500] loss: 0.01522937554778764
[Epoch 18, Batch 1600] loss: 0.0201373302499087
[Epoch 18, Batch 1700] loss: 0.029008492068242048
[Epoch 18, Batch 1800] loss: 0.026442359781158303
[Epoch 18, Batch 1900] loss: 0.022923488694959814
[Epoch 18, Batch 2000] loss: 0.0207243461109465
[Epoch 18, Batch 2100] loss: 0.025556327952363064
[Epoch 18, Batch 2200] loss: 0.01428389876436995
[Epoch 18, Batch 2300] loss: 0.023023557421984153
[Epoch 18, Batch 2400] loss: 0.0244646764951176
[Epoch 18, Batch 2500] loss: 0.018614603005553364
[Epoch 18, Batch 2600] loss: 0.02743470153949602
[Epoch 18, Batch 2700] loss: 0.018828705648484174
[Epoch 18, Batch 2800] loss: 0.02641445778979687
[Epoch 18, Batch 2900] loss: 0.01653049068932887
[Epoch 18, Batch 3000] loss: 0.023871961057375303
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9866
Overfitting: 0.0479
Best model saved at epoch 18 with validation loss: 0.0479
[Epoch 19, Batch 100] loss: 0.027054516760763363
[Epoch 19, Batch 200] loss: 0.014838858459988842
[Epoch 19, Batch 300] loss: 0.02675717239631922
[Epoch 19, Batch 400] loss: 0.013433460707601626
[Epoch 19, Batch 500] loss: 0.01803052585404657
[Epoch 19, Batch 600] loss: 0.02011768982018111
[Epoch 19, Batch 700] loss: 0.023109210987531697
[Epoch 19, Batch 800] loss: 0.020386049325197747
[Epoch 19, Batch 900] loss: 0.014170402651543554
[Epoch 19, Batch 1000] loss: 0.03540462994758855
[Epoch 19, Batch 1100] loss: 0.020967417696392657
[Epoch 19, Batch 1200] loss: 0.014099373840290355
[Epoch 19, Batch 1300] loss: 0.02055758948903531
[Epoch 19, Batch 1400] loss: 0.015575058805661684
[Epoch 19, Batch 1500] loss: 0.02607996456863475
[Epoch 19, Batch 1600] loss: 0.018706850132512044
[Epoch 19, Batch 1700] loss: 0.023952007870502712
[Epoch 19, Batch 1800] loss: 0.026287544063525275
[Epoch 19, Batch 1900] loss: 0.01669923923946044
[Epoch 19, Batch 2000] loss: 0.024703571286518126
[Epoch 19, Batch 2100] loss: 0.017352368254360043
[Epoch 19, Batch 2200] loss: 0.02691193004415254
[Epoch 19, Batch 2300] loss: 0.027012436840122972
[Epoch 19, Batch 2400] loss: 0.008421734157382161
[Epoch 19, Batch 2500] loss: 0.013330730624784338
[Epoch 19, Batch 2600] loss: 0.019400327741604998
[Epoch 19, Batch 2700] loss: 0.0150515545457165
[Epoch 19, Batch 2800] loss: 0.026811466157032556
[Epoch 19, Batch 2900] loss: 0.02379223627780448
[Epoch 19, Batch 3000] loss: 0.016703379588361714
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9864
Overfitting: 0.0482
[Epoch 20, Batch 100] loss: 0.018230285300196557
[Epoch 20, Batch 200] loss: 0.015761357495284754
[Epoch 20, Batch 300] loss: 0.012239325685513905
[Epoch 20, Batch 400] loss: 0.015058624612502172
[Epoch 20, Batch 500] loss: 0.020570734957946115
[Epoch 20, Batch 600] loss: 0.025794685174478218
[Epoch 20, Batch 700] loss: 0.01754198592767352
[Epoch 20, Batch 800] loss: 0.021081418584326456
[Epoch 20, Batch 900] loss: 0.021328711371606916
[Epoch 20, Batch 1000] loss: 0.012446419890657125
[Epoch 20, Batch 1100] loss: 0.01995558728813194
[Epoch 20, Batch 1200] loss: 0.018652683160471497
[Epoch 20, Batch 1300] loss: 0.021999238511853036
[Epoch 20, Batch 1400] loss: 0.019484487799891214
[Epoch 20, Batch 1500] loss: 0.013892377840747941
[Epoch 20, Batch 1600] loss: 0.014705203128614812
[Epoch 20, Batch 1700] loss: 0.012133755063896388
[Epoch 20, Batch 1800] loss: 0.01152053865713242
[Epoch 20, Batch 1900] loss: 0.015542923862958559
[Epoch 20, Batch 2000] loss: 0.019544671290163934
[Epoch 20, Batch 2100] loss: 0.021755275575924316
[Epoch 20, Batch 2200] loss: 0.010561977210054465
[Epoch 20, Batch 2300] loss: 0.016212360630561307
[Epoch 20, Batch 2400] loss: 0.027039779734423064
[Epoch 20, Batch 2500] loss: 0.0273369966573955
[Epoch 20, Batch 2600] loss: 0.01588787111100828
[Epoch 20, Batch 2700] loss: 0.02174582450230446
[Epoch 20, Batch 2800] loss: 0.020770568251318764
[Epoch 20, Batch 2900] loss: 0.02663175357538421
[Epoch 20, Batch 3000] loss: 0.027384552844123392
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9861
Overfitting: 0.0486
[Epoch 21, Batch 100] loss: 0.019607339319172752
[Epoch 21, Batch 200] loss: 0.027912280693890353
[Epoch 21, Batch 300] loss: 0.013707259003567743
[Epoch 21, Batch 400] loss: 0.01680259290151298
[Epoch 21, Batch 500] loss: 0.014179930553109444
[Epoch 21, Batch 600] loss: 0.0165404637762731
[Epoch 21, Batch 700] loss: 0.026236726393763093
[Epoch 21, Batch 800] loss: 0.011409796371917764
[Epoch 21, Batch 900] loss: 0.01084088298586721
[Epoch 21, Batch 1000] loss: 0.011685036732487789
[Epoch 21, Batch 1100] loss: 0.012338420851447153
[Epoch 21, Batch 1200] loss: 0.010838160613784566
[Epoch 21, Batch 1300] loss: 0.02559804919939779
[Epoch 21, Batch 1400] loss: 0.019436877756543253
[Epoch 21, Batch 1500] loss: 0.019554650031568598
[Epoch 21, Batch 1600] loss: 0.024087120074182167
[Epoch 21, Batch 1700] loss: 0.014726581866016204
[Epoch 21, Batch 1800] loss: 0.020677736724801433
[Epoch 21, Batch 1900] loss: 0.018089731834916165
[Epoch 21, Batch 2000] loss: 0.02561971097267815
[Epoch 21, Batch 2100] loss: 0.01935694906987919
[Epoch 21, Batch 2200] loss: 0.019364456217626867
[Epoch 21, Batch 2300] loss: 0.01956314087659848
[Epoch 21, Batch 2400] loss: 0.016731934252038626
[Epoch 21, Batch 2500] loss: 0.015782833628863954
[Epoch 21, Batch 2600] loss: 0.020784508243655183
[Epoch 21, Batch 2700] loss: 0.01628412334863242
[Epoch 21, Batch 2800] loss: 0.016626455613259167
[Epoch 21, Batch 2900] loss: 0.008176415754423943
[Epoch 21, Batch 3000] loss: 0.011290543676277593
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9870
Overfitting: 0.0455
Best model saved at epoch 21 with validation loss: 0.0455
[Epoch 22, Batch 100] loss: 0.012975819138118823
[Epoch 22, Batch 200] loss: 0.01633350470176083
[Epoch 22, Batch 300] loss: 0.016185927225124033
[Epoch 22, Batch 400] loss: 0.013114445146347862
[Epoch 22, Batch 500] loss: 0.020550188209035695
[Epoch 22, Batch 600] loss: 0.011864634192224912
[Epoch 22, Batch 700] loss: 0.013864458113530417
[Epoch 22, Batch 800] loss: 0.012999709377108957
[Epoch 22, Batch 900] loss: 0.01937720940259169
[Epoch 22, Batch 1000] loss: 0.014810286182000709
[Epoch 22, Batch 1100] loss: 0.02068937010180889
[Epoch 22, Batch 1200] loss: 0.01170563209681859
[Epoch 22, Batch 1300] loss: 0.01216137142117077
[Epoch 22, Batch 1400] loss: 0.01589179004291509
[Epoch 22, Batch 1500] loss: 0.017341223046132656
[Epoch 22, Batch 1600] loss: 0.024473423258004914
[Epoch 22, Batch 1700] loss: 0.01193208915698051
[Epoch 22, Batch 1800] loss: 0.01827862448797532
[Epoch 22, Batch 1900] loss: 0.013894016727790585
[Epoch 22, Batch 2000] loss: 0.013936291232748772
[Epoch 22, Batch 2100] loss: 0.022520634341490223
[Epoch 22, Batch 2200] loss: 0.013603048893237428
[Epoch 22, Batch 2300] loss: 0.019691757447862984
[Epoch 22, Batch 2400] loss: 0.018046240813164333
[Epoch 22, Batch 2500] loss: 0.014480541870689194
[Epoch 22, Batch 2600] loss: 0.015990862840480985
[Epoch 22, Batch 2700] loss: 0.01442374401845882
[Epoch 22, Batch 2800] loss: 0.02037619182116032
[Epoch 22, Batch 2900] loss: 0.017568765519026783
[Epoch 22, Batch 3000] loss: 0.017479935920928256
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9871
Overfitting: 0.0478
[Epoch 23, Batch 100] loss: 0.01407429800967293
[Epoch 23, Batch 200] loss: 0.008762979739640287
[Epoch 23, Batch 300] loss: 0.013322541204324807
[Epoch 23, Batch 400] loss: 0.010550437735173546
[Epoch 23, Batch 500] loss: 0.012508377747362829
[Epoch 23, Batch 600] loss: 0.010882838398465537
[Epoch 23, Batch 700] loss: 0.011218950599022719
[Epoch 23, Batch 800] loss: 0.012272980862981057
[Epoch 23, Batch 900] loss: 0.013152661503227137
[Epoch 23, Batch 1000] loss: 0.019403329595897956
[Epoch 23, Batch 1100] loss: 0.017824969543335102
[Epoch 23, Batch 1200] loss: 0.012637341004210611
[Epoch 23, Batch 1300] loss: 0.015206864348365344
[Epoch 23, Batch 1400] loss: 0.012881801488347264
[Epoch 23, Batch 1500] loss: 0.018655744367133593
[Epoch 23, Batch 1600] loss: 0.016798276171739415
[Epoch 23, Batch 1700] loss: 0.02062767998986601
[Epoch 23, Batch 1800] loss: 0.009283687323077175
[Epoch 23, Batch 1900] loss: 0.012005844969280588
[Epoch 23, Batch 2000] loss: 0.011951874730366399
[Epoch 23, Batch 2100] loss: 0.018633547896333768
[Epoch 23, Batch 2200] loss: 0.023599121581883084
[Epoch 23, Batch 2300] loss: 0.0154394225420765
[Epoch 23, Batch 2400] loss: 0.009819761493090481
[Epoch 23, Batch 2500] loss: 0.009662875513772633
[Epoch 23, Batch 2600] loss: 0.016871484566527217
[Epoch 23, Batch 2700] loss: 0.02133119294512653
[Epoch 23, Batch 2800] loss: 0.020288309278766972
[Epoch 23, Batch 2900] loss: 0.008278807227761718
[Epoch 23, Batch 3000] loss: 0.01700175174682954
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9869
Overfitting: 0.0487
[Epoch 24, Batch 100] loss: 0.017030636409435827
[Epoch 24, Batch 200] loss: 0.010987067419882805
[Epoch 24, Batch 300] loss: 0.014017321800893115
[Epoch 24, Batch 400] loss: 0.011225898773300286
[Epoch 24, Batch 500] loss: 0.006852225039929181
[Epoch 24, Batch 600] loss: 0.014264276023459388
[Epoch 24, Batch 700] loss: 0.011101765591527056
[Epoch 24, Batch 800] loss: 0.010261805913241915
[Epoch 24, Batch 900] loss: 0.014620804529613451
[Epoch 24, Batch 1000] loss: 0.009367358229992533
[Epoch 24, Batch 1100] loss: 0.005709087763807475
[Epoch 24, Batch 1200] loss: 0.009637566601031721
[Epoch 24, Batch 1300] loss: 0.011262080862288713
[Epoch 24, Batch 1400] loss: 0.015788514315263454
[Epoch 24, Batch 1500] loss: 0.009484442924640462
[Epoch 24, Batch 1600] loss: 0.015288679333443723
[Epoch 24, Batch 1700] loss: 0.01144294849191283
[Epoch 24, Batch 1800] loss: 0.013048886484612013
[Epoch 24, Batch 1900] loss: 0.01730971603306898
[Epoch 24, Batch 2000] loss: 0.011511290825474134
[Epoch 24, Batch 2100] loss: 0.017268948022365293
[Epoch 24, Batch 2200] loss: 0.01104394483066244
[Epoch 24, Batch 2300] loss: 0.01742741358499188
[Epoch 24, Batch 2400] loss: 0.013267382293342962
[Epoch 24, Batch 2500] loss: 0.01332832754469564
[Epoch 24, Batch 2600] loss: 0.017006464599658103
[Epoch 24, Batch 2700] loss: 0.01608333013688025
[Epoch 24, Batch 2800] loss: 0.020525714798859552
[Epoch 24, Batch 2900] loss: 0.013438145760464976
[Epoch 24, Batch 3000] loss: 0.01827507532978416
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9864
Overfitting: 0.0504
Fold 3 validation loss: 0.0504
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.302750289440155
[Epoch 1, Batch 200] loss: 2.297802166938782
[Epoch 1, Batch 300] loss: 2.285602490901947
[Epoch 1, Batch 400] loss: 2.27680447101593
[Epoch 1, Batch 500] loss: 2.258089520931244
[Epoch 1, Batch 600] loss: 2.237135350704193
[Epoch 1, Batch 700] loss: 2.1920043635368347
[Epoch 1, Batch 800] loss: 2.1000290191173554
[Epoch 1, Batch 900] loss: 1.8913665950298308
[Epoch 1, Batch 1000] loss: 1.5436798131465912
[Epoch 1, Batch 1100] loss: 1.160965283513069
[Epoch 1, Batch 1200] loss: 0.9494950914382935
[Epoch 1, Batch 1300] loss: 0.8260875985026359
[Epoch 1, Batch 1400] loss: 0.6917680135369301
[Epoch 1, Batch 1500] loss: 0.590101414769888
[Epoch 1, Batch 1600] loss: 0.5333857204020024
[Epoch 1, Batch 1700] loss: 0.4942205575108528
[Epoch 1, Batch 1800] loss: 0.4808943634480238
[Epoch 1, Batch 1900] loss: 0.4574158371984959
[Epoch 1, Batch 2000] loss: 0.42223170418292283
[Epoch 1, Batch 2100] loss: 0.44400356598198415
[Epoch 1, Batch 2200] loss: 0.3834816851466894
[Epoch 1, Batch 2300] loss: 0.3937123929709196
[Epoch 1, Batch 2400] loss: 0.38395734392106534
[Epoch 1, Batch 2500] loss: 0.39281530752778054
[Epoch 1, Batch 2600] loss: 0.32753512360155584
[Epoch 1, Batch 2700] loss: 0.3565382532775402
[Epoch 1, Batch 2800] loss: 0.34865362212061884
[Epoch 1, Batch 2900] loss: 0.3244829261675477
[Epoch 1, Batch 3000] loss: 0.3009953160583973
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3125
Validation Accuracy: 0.9018
Overfitting: 0.3125
Best model saved at epoch 1 with validation loss: 0.3125
[Epoch 2, Batch 100] loss: 0.2655052327178419
[Epoch 2, Batch 200] loss: 0.2938272367231548
[Epoch 2, Batch 300] loss: 0.26722073409706354
[Epoch 2, Batch 400] loss: 0.28536056317389014
[Epoch 2, Batch 500] loss: 0.2581616550683975
[Epoch 2, Batch 600] loss: 0.2737713151797652
[Epoch 2, Batch 700] loss: 0.24008732415735723
[Epoch 2, Batch 800] loss: 0.2873246030136943
[Epoch 2, Batch 900] loss: 0.24223686873912811
[Epoch 2, Batch 1000] loss: 0.2749410133995116
[Epoch 2, Batch 1100] loss: 0.22211107447743417
[Epoch 2, Batch 1200] loss: 0.22691084120422603
[Epoch 2, Batch 1300] loss: 0.2506657762266695
[Epoch 2, Batch 1400] loss: 0.203027572799474
[Epoch 2, Batch 1500] loss: 0.207889355616644
[Epoch 2, Batch 1600] loss: 0.207572800219059
[Epoch 2, Batch 1700] loss: 0.21464568575844167
[Epoch 2, Batch 1800] loss: 0.21574752558022736
[Epoch 2, Batch 1900] loss: 0.20237865869887173
[Epoch 2, Batch 2000] loss: 0.2286878546793014
[Epoch 2, Batch 2100] loss: 0.20807572221383452
[Epoch 2, Batch 2200] loss: 0.20229663520120084
[Epoch 2, Batch 2300] loss: 0.17378409439697862
[Epoch 2, Batch 2400] loss: 0.21458401577547193
[Epoch 2, Batch 2500] loss: 0.18207784047350287
[Epoch 2, Batch 2600] loss: 0.15952485408633948
[Epoch 2, Batch 2700] loss: 0.15142772998660803
[Epoch 2, Batch 2800] loss: 0.19908180866390468
[Epoch 2, Batch 2900] loss: 0.1702769201528281
[Epoch 2, Batch 3000] loss: 0.17590622848831117
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1706
Validation Accuracy: 0.9479
Overfitting: 0.1706
Best model saved at epoch 2 with validation loss: 0.1706
[Epoch 3, Batch 100] loss: 0.17023943001404404
[Epoch 3, Batch 200] loss: 0.1360067173372954
[Epoch 3, Batch 300] loss: 0.18686841124668718
[Epoch 3, Batch 400] loss: 0.15125620488543062
[Epoch 3, Batch 500] loss: 0.14444530447944998
[Epoch 3, Batch 600] loss: 0.18005010621622206
[Epoch 3, Batch 700] loss: 0.144916328182444
[Epoch 3, Batch 800] loss: 0.18871702741831542
[Epoch 3, Batch 900] loss: 0.1585591258574277
[Epoch 3, Batch 1000] loss: 0.16934290915727615
[Epoch 3, Batch 1100] loss: 0.1572453062236309
[Epoch 3, Batch 1200] loss: 0.14291716405190527
[Epoch 3, Batch 1300] loss: 0.13650650894735009
[Epoch 3, Batch 1400] loss: 0.15914846830070017
[Epoch 3, Batch 1500] loss: 0.15131348985712975
[Epoch 3, Batch 1600] loss: 0.11940132092218846
[Epoch 3, Batch 1700] loss: 0.15610819940222428
[Epoch 3, Batch 1800] loss: 0.1377710056817159
[Epoch 3, Batch 1900] loss: 0.14934878745116292
[Epoch 3, Batch 2000] loss: 0.12774550235830248
[Epoch 3, Batch 2100] loss: 0.13632356510031968
[Epoch 3, Batch 2200] loss: 0.1267617791472003
[Epoch 3, Batch 2300] loss: 0.11521835475694388
[Epoch 3, Batch 2400] loss: 0.13819414554629475
[Epoch 3, Batch 2500] loss: 0.10847174253314734
[Epoch 3, Batch 2600] loss: 0.13583328153938054
[Epoch 3, Batch 2700] loss: 0.13229725878685714
[Epoch 3, Batch 2800] loss: 0.1258070532232523
[Epoch 3, Batch 2900] loss: 0.11234133183024823
[Epoch 3, Batch 3000] loss: 0.13414545785170048
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1150
Validation Accuracy: 0.9643
Overfitting: 0.1150
Best model saved at epoch 3 with validation loss: 0.1150
[Epoch 4, Batch 100] loss: 0.11653619471006095
[Epoch 4, Batch 200] loss: 0.14157122321426868
[Epoch 4, Batch 300] loss: 0.1297960361558944
[Epoch 4, Batch 400] loss: 0.11450661999406293
[Epoch 4, Batch 500] loss: 0.14178257685620338
[Epoch 4, Batch 600] loss: 0.11237081305356696
[Epoch 4, Batch 700] loss: 0.09137700644554571
[Epoch 4, Batch 800] loss: 0.10231316789053381
[Epoch 4, Batch 900] loss: 0.13262944724410772
[Epoch 4, Batch 1000] loss: 0.08639001358067616
[Epoch 4, Batch 1100] loss: 0.08985337555175647
[Epoch 4, Batch 1200] loss: 0.10226073152269237
[Epoch 4, Batch 1300] loss: 0.09001057182787918
[Epoch 4, Batch 1400] loss: 0.11239691354800016
[Epoch 4, Batch 1500] loss: 0.0983244016347453
[Epoch 4, Batch 1600] loss: 0.1224327248847112
[Epoch 4, Batch 1700] loss: 0.09950609938241542
[Epoch 4, Batch 1800] loss: 0.10336326729215216
[Epoch 4, Batch 1900] loss: 0.10154404315399006
[Epoch 4, Batch 2000] loss: 0.08445504055125638
[Epoch 4, Batch 2100] loss: 0.08681988429510966
[Epoch 4, Batch 2200] loss: 0.09446206223452464
[Epoch 4, Batch 2300] loss: 0.11939567529130728
[Epoch 4, Batch 2400] loss: 0.11089421525830404
[Epoch 4, Batch 2500] loss: 0.1006846521073021
[Epoch 4, Batch 2600] loss: 0.10349672873853706
[Epoch 4, Batch 2700] loss: 0.10528162209433503
[Epoch 4, Batch 2800] loss: 0.0888758040778339
[Epoch 4, Batch 2900] loss: 0.12571138540748505
[Epoch 4, Batch 3000] loss: 0.11148608069168403
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1016
Validation Accuracy: 0.9679
Overfitting: 0.1016
Best model saved at epoch 4 with validation loss: 0.1016
[Epoch 5, Batch 100] loss: 0.0952238426823169
[Epoch 5, Batch 200] loss: 0.07359597206814214
[Epoch 5, Batch 300] loss: 0.09186286348849534
[Epoch 5, Batch 400] loss: 0.07706790814874694
[Epoch 5, Batch 500] loss: 0.09610483664553612
[Epoch 5, Batch 600] loss: 0.10560851682093926
[Epoch 5, Batch 700] loss: 0.07048895046813414
[Epoch 5, Batch 800] loss: 0.08041141852736473
[Epoch 5, Batch 900] loss: 0.09991918884916232
[Epoch 5, Batch 1000] loss: 0.08806737648090347
[Epoch 5, Batch 1100] loss: 0.11452660150593147
[Epoch 5, Batch 1200] loss: 0.10254729297477752
[Epoch 5, Batch 1300] loss: 0.07396262864582241
[Epoch 5, Batch 1400] loss: 0.08189957734080963
[Epoch 5, Batch 1500] loss: 0.08186211809981614
[Epoch 5, Batch 1600] loss: 0.09756293658399955
[Epoch 5, Batch 1700] loss: 0.07734828921500593
[Epoch 5, Batch 1800] loss: 0.06526762077002786
[Epoch 5, Batch 1900] loss: 0.09040663810214028
[Epoch 5, Batch 2000] loss: 0.10370114997960628
[Epoch 5, Batch 2100] loss: 0.0813533821166493
[Epoch 5, Batch 2200] loss: 0.10533899397123606
[Epoch 5, Batch 2300] loss: 0.06801951604313217
[Epoch 5, Batch 2400] loss: 0.08256612414610572
[Epoch 5, Batch 2500] loss: 0.0921112923824694
[Epoch 5, Batch 2600] loss: 0.08184116906486452
[Epoch 5, Batch 2700] loss: 0.10274347715312615
[Epoch 5, Batch 2800] loss: 0.07647335385205224
[Epoch 5, Batch 2900] loss: 0.0712448957900051
[Epoch 5, Batch 3000] loss: 0.0833452497702092
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0795
Validation Accuracy: 0.9758
Overfitting: 0.0795
Best model saved at epoch 5 with validation loss: 0.0795
[Epoch 6, Batch 100] loss: 0.07219789188820869
[Epoch 6, Batch 200] loss: 0.07407044246327132
[Epoch 6, Batch 300] loss: 0.09096261511091143
[Epoch 6, Batch 400] loss: 0.07620064722141251
[Epoch 6, Batch 500] loss: 0.08245715657481924
[Epoch 6, Batch 600] loss: 0.07846769355237485
[Epoch 6, Batch 700] loss: 0.08815416926285252
[Epoch 6, Batch 800] loss: 0.07312066066544504
[Epoch 6, Batch 900] loss: 0.06426890072412789
[Epoch 6, Batch 1000] loss: 0.07155184113653376
[Epoch 6, Batch 1100] loss: 0.0846800944057759
[Epoch 6, Batch 1200] loss: 0.08508162221871317
[Epoch 6, Batch 1300] loss: 0.07521529084537178
[Epoch 6, Batch 1400] loss: 0.07135853719431907
[Epoch 6, Batch 1500] loss: 0.07531796113820746
[Epoch 6, Batch 1600] loss: 0.07658039306057617
[Epoch 6, Batch 1700] loss: 0.06743557694542687
[Epoch 6, Batch 1800] loss: 0.07090551904402673
[Epoch 6, Batch 1900] loss: 0.09001558128977194
[Epoch 6, Batch 2000] loss: 0.06237665105843917
[Epoch 6, Batch 2100] loss: 0.06609848933527246
[Epoch 6, Batch 2200] loss: 0.07068971297820098
[Epoch 6, Batch 2300] loss: 0.07671306209551404
[Epoch 6, Batch 2400] loss: 0.055576786464080215
[Epoch 6, Batch 2500] loss: 0.07254400310222991
[Epoch 6, Batch 2600] loss: 0.07286880011903123
[Epoch 6, Batch 2700] loss: 0.07354746811528458
[Epoch 6, Batch 2800] loss: 0.08059872844896745
[Epoch 6, Batch 2900] loss: 0.07635454046423547
[Epoch 6, Batch 3000] loss: 0.06947145834565163
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0710
Validation Accuracy: 0.9773
Overfitting: 0.0710
Best model saved at epoch 6 with validation loss: 0.0710
[Epoch 7, Batch 100] loss: 0.056205694793025035
[Epoch 7, Batch 200] loss: 0.056776984486496075
[Epoch 7, Batch 300] loss: 0.06708343719714321
[Epoch 7, Batch 400] loss: 0.058715079575777054
[Epoch 7, Batch 500] loss: 0.07796922698500566
[Epoch 7, Batch 600] loss: 0.06681522966362535
[Epoch 7, Batch 700] loss: 0.08682751695392653
[Epoch 7, Batch 800] loss: 0.05807352988282219
[Epoch 7, Batch 900] loss: 0.05961841261188965
[Epoch 7, Batch 1000] loss: 0.060926111928420144
[Epoch 7, Batch 1100] loss: 0.07458746389835141
[Epoch 7, Batch 1200] loss: 0.07607451858231798
[Epoch 7, Batch 1300] loss: 0.053978298695292325
[Epoch 7, Batch 1400] loss: 0.06241660206578672
[Epoch 7, Batch 1500] loss: 0.06781488606415223
[Epoch 7, Batch 1600] loss: 0.07141431237396319
[Epoch 7, Batch 1700] loss: 0.07644881286716554
[Epoch 7, Batch 1800] loss: 0.07766379231587052
[Epoch 7, Batch 1900] loss: 0.06446229465771466
[Epoch 7, Batch 2000] loss: 0.06613803366781212
[Epoch 7, Batch 2100] loss: 0.0603717704518931
[Epoch 7, Batch 2200] loss: 0.04823593818233349
[Epoch 7, Batch 2300] loss: 0.05618004041374661
[Epoch 7, Batch 2400] loss: 0.06715834441885818
[Epoch 7, Batch 2500] loss: 0.06821638065273873
[Epoch 7, Batch 2600] loss: 0.06968524800322484
[Epoch 7, Batch 2700] loss: 0.08573251591995358
[Epoch 7, Batch 2800] loss: 0.05126408396521583
[Epoch 7, Batch 2900] loss: 0.05649546624801587
[Epoch 7, Batch 3000] loss: 0.060724230714840816
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0730
Validation Accuracy: 0.9766
Overfitting: 0.0730
[Epoch 8, Batch 100] loss: 0.05026927994971629
[Epoch 8, Batch 200] loss: 0.05070559859275818
[Epoch 8, Batch 300] loss: 0.05407940662931651
[Epoch 8, Batch 400] loss: 0.048688773161848074
[Epoch 8, Batch 500] loss: 0.06275245556927984
[Epoch 8, Batch 600] loss: 0.07103327673627063
[Epoch 8, Batch 700] loss: 0.04997740586055443
[Epoch 8, Batch 800] loss: 0.049390743405674585
[Epoch 8, Batch 900] loss: 0.04068339708406711
[Epoch 8, Batch 1000] loss: 0.04668859632569365
[Epoch 8, Batch 1100] loss: 0.06994892239279579
[Epoch 8, Batch 1200] loss: 0.06351573833264411
[Epoch 8, Batch 1300] loss: 0.056007184147601946
[Epoch 8, Batch 1400] loss: 0.06085377700044774
[Epoch 8, Batch 1500] loss: 0.05250957672134973
[Epoch 8, Batch 1600] loss: 0.06584823018987664
[Epoch 8, Batch 1700] loss: 0.05208345595165156
[Epoch 8, Batch 1800] loss: 0.05480821768491296
[Epoch 8, Batch 1900] loss: 0.05725854592572432
[Epoch 8, Batch 2000] loss: 0.06805983659462073
[Epoch 8, Batch 2100] loss: 0.06007451202487573
[Epoch 8, Batch 2200] loss: 0.07290328493691049
[Epoch 8, Batch 2300] loss: 0.05426058156823274
[Epoch 8, Batch 2400] loss: 0.0474313131213421
[Epoch 8, Batch 2500] loss: 0.0500127464835532
[Epoch 8, Batch 2600] loss: 0.042011880597565325
[Epoch 8, Batch 2700] loss: 0.07509026089624968
[Epoch 8, Batch 2800] loss: 0.05272828912420664
[Epoch 8, Batch 2900] loss: 0.061658548426348714
[Epoch 8, Batch 3000] loss: 0.07706409102771432
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0634
Validation Accuracy: 0.9811
Overfitting: 0.0634
Best model saved at epoch 8 with validation loss: 0.0634
[Epoch 9, Batch 100] loss: 0.05324741260265
[Epoch 9, Batch 200] loss: 0.04349633275327505
[Epoch 9, Batch 300] loss: 0.05410093177459203
[Epoch 9, Batch 400] loss: 0.042089314106851815
[Epoch 9, Batch 500] loss: 0.03813772429362871
[Epoch 9, Batch 600] loss: 0.059690747443237345
[Epoch 9, Batch 700] loss: 0.04687821629253449
[Epoch 9, Batch 800] loss: 0.036911868836614306
[Epoch 9, Batch 900] loss: 0.0610631128604291
[Epoch 9, Batch 1000] loss: 0.047342479708604515
[Epoch 9, Batch 1100] loss: 0.048256066250032745
[Epoch 9, Batch 1200] loss: 0.05016242557845544
[Epoch 9, Batch 1300] loss: 0.05402476637449581
[Epoch 9, Batch 1400] loss: 0.06768059695139528
[Epoch 9, Batch 1500] loss: 0.050109366080141625
[Epoch 9, Batch 1600] loss: 0.059252427471801636
[Epoch 9, Batch 1700] loss: 0.056620012138737366
[Epoch 9, Batch 1800] loss: 0.058115026141749695
[Epoch 9, Batch 1900] loss: 0.044916260183672424
[Epoch 9, Batch 2000] loss: 0.04130903526005568
[Epoch 9, Batch 2100] loss: 0.048661864713649264
[Epoch 9, Batch 2200] loss: 0.06631394822266884
[Epoch 9, Batch 2300] loss: 0.08065649374679197
[Epoch 9, Batch 2400] loss: 0.05067531251814216
[Epoch 9, Batch 2500] loss: 0.041690689375973304
[Epoch 9, Batch 2600] loss: 0.04171846629789797
[Epoch 9, Batch 2700] loss: 0.035338590455357914
[Epoch 9, Batch 2800] loss: 0.04438527703197906
[Epoch 9, Batch 2900] loss: 0.05289448256022297
[Epoch 9, Batch 3000] loss: 0.05278214936784934
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9817
Overfitting: 0.0593
Best model saved at epoch 9 with validation loss: 0.0593
[Epoch 10, Batch 100] loss: 0.05090592808992369
[Epoch 10, Batch 200] loss: 0.050917850295663813
[Epoch 10, Batch 300] loss: 0.041401770894299264
[Epoch 10, Batch 400] loss: 0.04003578614501748
[Epoch 10, Batch 500] loss: 0.0460843054385623
[Epoch 10, Batch 600] loss: 0.051398854863946325
[Epoch 10, Batch 700] loss: 0.03779756590520265
[Epoch 10, Batch 800] loss: 0.04710960822354537
[Epoch 10, Batch 900] loss: 0.03506489645806141
[Epoch 10, Batch 1000] loss: 0.05537849827451282
[Epoch 10, Batch 1100] loss: 0.0511908303713426
[Epoch 10, Batch 1200] loss: 0.04771838831467903
[Epoch 10, Batch 1300] loss: 0.04580944485962391
[Epoch 10, Batch 1400] loss: 0.05112308213720098
[Epoch 10, Batch 1500] loss: 0.03462694893227308
[Epoch 10, Batch 1600] loss: 0.04449083371058805
[Epoch 10, Batch 1700] loss: 0.048852488962002096
[Epoch 10, Batch 1800] loss: 0.0480163592894678
[Epoch 10, Batch 1900] loss: 0.03378234562755097
[Epoch 10, Batch 2000] loss: 0.06345553113613278
[Epoch 10, Batch 2100] loss: 0.047245894580264576
[Epoch 10, Batch 2200] loss: 0.04790539580630138
[Epoch 10, Batch 2300] loss: 0.035750471570063384
[Epoch 10, Batch 2400] loss: 0.0419148028944619
[Epoch 10, Batch 2500] loss: 0.032378877352457494
[Epoch 10, Batch 2600] loss: 0.04478409725852543
[Epoch 10, Batch 2700] loss: 0.05781021091039293
[Epoch 10, Batch 2800] loss: 0.04752038318605628
[Epoch 10, Batch 2900] loss: 0.04524500956642442
[Epoch 10, Batch 3000] loss: 0.03794343712565024
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9814
Overfitting: 0.0576
Best model saved at epoch 10 with validation loss: 0.0576
[Epoch 11, Batch 100] loss: 0.0454990136763081
[Epoch 11, Batch 200] loss: 0.035494959380303046
[Epoch 11, Batch 300] loss: 0.027464561352680904
[Epoch 11, Batch 400] loss: 0.044616126356413585
[Epoch 11, Batch 500] loss: 0.036581789045594636
[Epoch 11, Batch 600] loss: 0.05153019664547173
[Epoch 11, Batch 700] loss: 0.037267214325547686
[Epoch 11, Batch 800] loss: 0.04008035742037464
[Epoch 11, Batch 900] loss: 0.03697118345444324
[Epoch 11, Batch 1000] loss: 0.03930491605962743
[Epoch 11, Batch 1100] loss: 0.04185135531792184
[Epoch 11, Batch 1200] loss: 0.04248717089358252
[Epoch 11, Batch 1300] loss: 0.03875309914816171
[Epoch 11, Batch 1400] loss: 0.04235152378772909
[Epoch 11, Batch 1500] loss: 0.0563134253420867
[Epoch 11, Batch 1600] loss: 0.03751925283489982
[Epoch 11, Batch 1700] loss: 0.04446636099222814
[Epoch 11, Batch 1800] loss: 0.03746373188099824
[Epoch 11, Batch 1900] loss: 0.04456175070168683
[Epoch 11, Batch 2000] loss: 0.04866975507175084
[Epoch 11, Batch 2100] loss: 0.03877078685705783
[Epoch 11, Batch 2200] loss: 0.03580160765093751
[Epoch 11, Batch 2300] loss: 0.03362827911856584
[Epoch 11, Batch 2400] loss: 0.03726683776185382
[Epoch 11, Batch 2500] loss: 0.04429754791839514
[Epoch 11, Batch 2600] loss: 0.05863357457012171
[Epoch 11, Batch 2700] loss: 0.04779575009597466
[Epoch 11, Batch 2800] loss: 0.046376359373680315
[Epoch 11, Batch 2900] loss: 0.03800888797457446
[Epoch 11, Batch 3000] loss: 0.036771503984491576
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9850
Overfitting: 0.0483
Best model saved at epoch 11 with validation loss: 0.0483
[Epoch 12, Batch 100] loss: 0.03546265408396721
[Epoch 12, Batch 200] loss: 0.043959786127961704
[Epoch 12, Batch 300] loss: 0.03891075958788861
[Epoch 12, Batch 400] loss: 0.047445580459898336
[Epoch 12, Batch 500] loss: 0.028835235924925654
[Epoch 12, Batch 600] loss: 0.0384765989499283
[Epoch 12, Batch 700] loss: 0.03473534214368556
[Epoch 12, Batch 800] loss: 0.051258960690174715
[Epoch 12, Batch 900] loss: 0.03421553305583075
[Epoch 12, Batch 1000] loss: 0.048220498212613164
[Epoch 12, Batch 1100] loss: 0.041905632480047646
[Epoch 12, Batch 1200] loss: 0.029102160518232268
[Epoch 12, Batch 1300] loss: 0.0315107116883155
[Epoch 12, Batch 1400] loss: 0.04287556910232524
[Epoch 12, Batch 1500] loss: 0.04420952319109347
[Epoch 12, Batch 1600] loss: 0.041363561727048366
[Epoch 12, Batch 1700] loss: 0.0403391139121959
[Epoch 12, Batch 1800] loss: 0.037989846357668285
[Epoch 12, Batch 1900] loss: 0.03884366621743538
[Epoch 12, Batch 2000] loss: 0.03648430246947101
[Epoch 12, Batch 2100] loss: 0.036931026454549286
[Epoch 12, Batch 2200] loss: 0.04211098036408657
[Epoch 12, Batch 2300] loss: 0.024852100989664904
[Epoch 12, Batch 2400] loss: 0.03215968967386289
[Epoch 12, Batch 2500] loss: 0.02702438370193704
[Epoch 12, Batch 2600] loss: 0.043441474149149145
[Epoch 12, Batch 2700] loss: 0.026765434816188646
[Epoch 12, Batch 2800] loss: 0.03592039834300522
[Epoch 12, Batch 2900] loss: 0.03164360478578601
[Epoch 12, Batch 3000] loss: 0.03609166837413795
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9842
Overfitting: 0.0538
[Epoch 13, Batch 100] loss: 0.03401576792719425
[Epoch 13, Batch 200] loss: 0.02570354899333324
[Epoch 13, Batch 300] loss: 0.03817824146564817
[Epoch 13, Batch 400] loss: 0.03272498782142066
[Epoch 13, Batch 500] loss: 0.040301290360512214
[Epoch 13, Batch 600] loss: 0.04822243555710884
[Epoch 13, Batch 700] loss: 0.036717482738094984
[Epoch 13, Batch 800] loss: 0.03390577004625811
[Epoch 13, Batch 900] loss: 0.026148979134013643
[Epoch 13, Batch 1000] loss: 0.02069560765856295
[Epoch 13, Batch 1100] loss: 0.03584244476049207
[Epoch 13, Batch 1200] loss: 0.0376650737831369
[Epoch 13, Batch 1300] loss: 0.041243363720132035
[Epoch 13, Batch 1400] loss: 0.03707399265302229
[Epoch 13, Batch 1500] loss: 0.031784238810214444
[Epoch 13, Batch 1600] loss: 0.028901609217718942
[Epoch 13, Batch 1700] loss: 0.04056823155042366
[Epoch 13, Batch 1800] loss: 0.02824789436010178
[Epoch 13, Batch 1900] loss: 0.03742138697867631
[Epoch 13, Batch 2000] loss: 0.04170260545331985
[Epoch 13, Batch 2100] loss: 0.0228645699210756
[Epoch 13, Batch 2200] loss: 0.033570860835025085
[Epoch 13, Batch 2300] loss: 0.04313559751164576
[Epoch 13, Batch 2400] loss: 0.02924379256553948
[Epoch 13, Batch 2500] loss: 0.039306222966624775
[Epoch 13, Batch 2600] loss: 0.03804779675017926
[Epoch 13, Batch 2700] loss: 0.038993390907417054
[Epoch 13, Batch 2800] loss: 0.039463037247478495
[Epoch 13, Batch 2900] loss: 0.03489823626587167
[Epoch 13, Batch 3000] loss: 0.032402991759154245
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9838
Overfitting: 0.0524
[Epoch 14, Batch 100] loss: 0.029071941887377762
[Epoch 14, Batch 200] loss: 0.03206354421170545
[Epoch 14, Batch 300] loss: 0.029824394103197847
[Epoch 14, Batch 400] loss: 0.04700993029255187
[Epoch 14, Batch 500] loss: 0.03932291667762911
[Epoch 14, Batch 600] loss: 0.028676344677514863
[Epoch 14, Batch 700] loss: 0.03642024354398018
[Epoch 14, Batch 800] loss: 0.025674868948553923
[Epoch 14, Batch 900] loss: 0.03404051596997306
[Epoch 14, Batch 1000] loss: 0.030761842645151773
[Epoch 14, Batch 1100] loss: 0.03682102826656774
[Epoch 14, Batch 1200] loss: 0.02312582889397163
[Epoch 14, Batch 1300] loss: 0.03709225851907831
[Epoch 14, Batch 1400] loss: 0.025407986505451844
[Epoch 14, Batch 1500] loss: 0.0414902889651421
[Epoch 14, Batch 1600] loss: 0.03947642189901671
[Epoch 14, Batch 1700] loss: 0.02826347241469193
[Epoch 14, Batch 1800] loss: 0.030596428793651285
[Epoch 14, Batch 1900] loss: 0.02426729412356508
[Epoch 14, Batch 2000] loss: 0.026761378022201826
[Epoch 14, Batch 2100] loss: 0.03736200238839956
[Epoch 14, Batch 2200] loss: 0.03996528692834545
[Epoch 14, Batch 2300] loss: 0.028153306178573985
[Epoch 14, Batch 2400] loss: 0.027785536064548068
[Epoch 14, Batch 2500] loss: 0.03058906664926326
[Epoch 14, Batch 2600] loss: 0.02219424611001159
[Epoch 14, Batch 2700] loss: 0.04025872723490465
[Epoch 14, Batch 2800] loss: 0.028459998950565932
[Epoch 14, Batch 2900] loss: 0.03435760791733628
[Epoch 14, Batch 3000] loss: 0.029003237205397454
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9852
Overfitting: 0.0484
[Epoch 15, Batch 100] loss: 0.028983236632629996
[Epoch 15, Batch 200] loss: 0.028524452842830214
[Epoch 15, Batch 300] loss: 0.024071559683507077
[Epoch 15, Batch 400] loss: 0.02288709095228114
[Epoch 15, Batch 500] loss: 0.025892902116756888
[Epoch 15, Batch 600] loss: 0.05166667232711916
[Epoch 15, Batch 700] loss: 0.024823245879015302
[Epoch 15, Batch 800] loss: 0.03067077412728395
[Epoch 15, Batch 900] loss: 0.02147528005676577
[Epoch 15, Batch 1000] loss: 0.034150990757334514
[Epoch 15, Batch 1100] loss: 0.041370507621613796
[Epoch 15, Batch 1200] loss: 0.03983914085983997
[Epoch 15, Batch 1300] loss: 0.02321340653783409
[Epoch 15, Batch 1400] loss: 0.029031393930490593
[Epoch 15, Batch 1500] loss: 0.01971344023651909
[Epoch 15, Batch 1600] loss: 0.027741765735991065
[Epoch 15, Batch 1700] loss: 0.03909462761905161
[Epoch 15, Batch 1800] loss: 0.027078815535642207
[Epoch 15, Batch 1900] loss: 0.02099704138949164
[Epoch 15, Batch 2000] loss: 0.01865281811580644
[Epoch 15, Batch 2100] loss: 0.04433085208118428
[Epoch 15, Batch 2200] loss: 0.025516195153759327
[Epoch 15, Batch 2300] loss: 0.03173468616063474
[Epoch 15, Batch 2400] loss: 0.02897193185825017
[Epoch 15, Batch 2500] loss: 0.030802078033157158
[Epoch 15, Batch 2600] loss: 0.02327851240625023
[Epoch 15, Batch 2700] loss: 0.022711307051067706
[Epoch 15, Batch 2800] loss: 0.042791170634445735
[Epoch 15, Batch 2900] loss: 0.03306977333617397
[Epoch 15, Batch 3000] loss: 0.012468079819518607
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0460
Validation Accuracy: 0.9852
Overfitting: 0.0460
Best model saved at epoch 15 with validation loss: 0.0460
[Epoch 16, Batch 100] loss: 0.04045654593108338
[Epoch 16, Batch 200] loss: 0.03379226729906804
[Epoch 16, Batch 300] loss: 0.03451089382884675
[Epoch 16, Batch 400] loss: 0.02137347685820714
[Epoch 16, Batch 500] loss: 0.015683875676404568
[Epoch 16, Batch 600] loss: 0.024271871981036384
[Epoch 16, Batch 700] loss: 0.02928619368285581
[Epoch 16, Batch 800] loss: 0.0251277017072789
[Epoch 16, Batch 900] loss: 0.031917710802226794
[Epoch 16, Batch 1000] loss: 0.018648970236554305
[Epoch 16, Batch 1100] loss: 0.020532262373599224
[Epoch 16, Batch 1200] loss: 0.017876580180163727
[Epoch 16, Batch 1300] loss: 0.02631005036222632
[Epoch 16, Batch 1400] loss: 0.02850621970668726
[Epoch 16, Batch 1500] loss: 0.030592001648547012
[Epoch 16, Batch 1600] loss: 0.027237222936237232
[Epoch 16, Batch 1700] loss: 0.035232469009570194
[Epoch 16, Batch 1800] loss: 0.030800803031888792
[Epoch 16, Batch 1900] loss: 0.023287223601946606
[Epoch 16, Batch 2000] loss: 0.031371343328792135
[Epoch 16, Batch 2100] loss: 0.023599812946631573
[Epoch 16, Batch 2200] loss: 0.03661373585251568
[Epoch 16, Batch 2300] loss: 0.02077123581650085
[Epoch 16, Batch 2400] loss: 0.02122315655309649
[Epoch 16, Batch 2500] loss: 0.030082991035305894
[Epoch 16, Batch 2600] loss: 0.03300953130106791
[Epoch 16, Batch 2700] loss: 0.0300380150123965
[Epoch 16, Batch 2800] loss: 0.014650198795570758
[Epoch 16, Batch 2900] loss: 0.03350003896804992
[Epoch 16, Batch 3000] loss: 0.028650813191052293
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0562
Validation Accuracy: 0.9824
Overfitting: 0.0562
[Epoch 17, Batch 100] loss: 0.02383205603386159
[Epoch 17, Batch 200] loss: 0.025774390018632402
[Epoch 17, Batch 300] loss: 0.018504059546030474
[Epoch 17, Batch 400] loss: 0.030387791335651854
[Epoch 17, Batch 500] loss: 0.027672398511022038
[Epoch 17, Batch 600] loss: 0.02080991342998459
[Epoch 17, Batch 700] loss: 0.02433803706924664
[Epoch 17, Batch 800] loss: 0.027458204349386506
[Epoch 17, Batch 900] loss: 0.025830098479927982
[Epoch 17, Batch 1000] loss: 0.030764869356207782
[Epoch 17, Batch 1100] loss: 0.02584518010073225
[Epoch 17, Batch 1200] loss: 0.02174822724322439
[Epoch 17, Batch 1300] loss: 0.03032974195331917
[Epoch 17, Batch 1400] loss: 0.02934831191028934
[Epoch 17, Batch 1500] loss: 0.019868251017469446
[Epoch 17, Batch 1600] loss: 0.02323964175862784
[Epoch 17, Batch 1700] loss: 0.030273558648477774
[Epoch 17, Batch 1800] loss: 0.02723634191421297
[Epoch 17, Batch 1900] loss: 0.027776018449731054
[Epoch 17, Batch 2000] loss: 0.021686859453911893
[Epoch 17, Batch 2100] loss: 0.027444156675192063
[Epoch 17, Batch 2200] loss: 0.018313684613094666
[Epoch 17, Batch 2300] loss: 0.026078419292898617
[Epoch 17, Batch 2400] loss: 0.02916327567301778
[Epoch 17, Batch 2500] loss: 0.017793036774965004
[Epoch 17, Batch 2600] loss: 0.030552471199262073
[Epoch 17, Batch 2700] loss: 0.016688040196022484
[Epoch 17, Batch 2800] loss: 0.03309698827695683
[Epoch 17, Batch 2900] loss: 0.028103290230537824
[Epoch 17, Batch 3000] loss: 0.025589050908529316
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9854
Overfitting: 0.0492
[Epoch 18, Batch 100] loss: 0.016819885540317044
[Epoch 18, Batch 200] loss: 0.019702672079001785
[Epoch 18, Batch 300] loss: 0.01849047375111695
[Epoch 18, Batch 400] loss: 0.015205357786107924
[Epoch 18, Batch 500] loss: 0.04175869687576778
[Epoch 18, Batch 600] loss: 0.02584659365849802
[Epoch 18, Batch 700] loss: 0.027130421067922725
[Epoch 18, Batch 800] loss: 0.014628736811500858
[Epoch 18, Batch 900] loss: 0.011525346570851979
[Epoch 18, Batch 1000] loss: 0.02639109519028352
[Epoch 18, Batch 1100] loss: 0.027694165325083304
[Epoch 18, Batch 1200] loss: 0.04480929139062937
[Epoch 18, Batch 1300] loss: 0.01760585240641376
[Epoch 18, Batch 1400] loss: 0.025549753260274883
[Epoch 18, Batch 1500] loss: 0.0303963244206534
[Epoch 18, Batch 1600] loss: 0.030819523744066827
[Epoch 18, Batch 1700] loss: 0.01663619335682597
[Epoch 18, Batch 1800] loss: 0.013195425118756248
[Epoch 18, Batch 1900] loss: 0.01583977285234141
[Epoch 18, Batch 2000] loss: 0.01674588278248848
[Epoch 18, Batch 2100] loss: 0.022486545351712267
[Epoch 18, Batch 2200] loss: 0.030537479814956896
[Epoch 18, Batch 2300] loss: 0.016074290623382694
[Epoch 18, Batch 2400] loss: 0.029040640042840096
[Epoch 18, Batch 2500] loss: 0.030763555593803175
[Epoch 18, Batch 2600] loss: 0.02072269048920134
[Epoch 18, Batch 2700] loss: 0.02116155708252336
[Epoch 18, Batch 2800] loss: 0.030561326688330157
[Epoch 18, Batch 2900] loss: 0.0258446075161919
[Epoch 18, Batch 3000] loss: 0.017152259808553935
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9867
Overfitting: 0.0445
Best model saved at epoch 18 with validation loss: 0.0445
[Epoch 19, Batch 100] loss: 0.018368410686525748
[Epoch 19, Batch 200] loss: 0.008602932434296235
[Epoch 19, Batch 300] loss: 0.022752096819785947
[Epoch 19, Batch 400] loss: 0.024885331877085262
[Epoch 19, Batch 500] loss: 0.017260147418710403
[Epoch 19, Batch 600] loss: 0.02410305567933392
[Epoch 19, Batch 700] loss: 0.02569012183783343
[Epoch 19, Batch 800] loss: 0.03019370406451344
[Epoch 19, Batch 900] loss: 0.031590427248956984
[Epoch 19, Batch 1000] loss: 0.03202985581861867
[Epoch 19, Batch 1100] loss: 0.016334929763688708
[Epoch 19, Batch 1200] loss: 0.020213083807757357
[Epoch 19, Batch 1300] loss: 0.031721351823071016
[Epoch 19, Batch 1400] loss: 0.016488251782939188
[Epoch 19, Batch 1500] loss: 0.021953878058411647
[Epoch 19, Batch 1600] loss: 0.025266176933728277
[Epoch 19, Batch 1700] loss: 0.021556585170546896
[Epoch 19, Batch 1800] loss: 0.018782476418527948
[Epoch 19, Batch 1900] loss: 0.029709889916375687
[Epoch 19, Batch 2000] loss: 0.010221878772681521
[Epoch 19, Batch 2100] loss: 0.012540761714626569
[Epoch 19, Batch 2200] loss: 0.01793824324475281
[Epoch 19, Batch 2300] loss: 0.02068284044169559
[Epoch 19, Batch 2400] loss: 0.021583233509154524
[Epoch 19, Batch 2500] loss: 0.008953874152812204
[Epoch 19, Batch 2600] loss: 0.018038984798367894
[Epoch 19, Batch 2700] loss: 0.01777285058016787
[Epoch 19, Batch 2800] loss: 0.02295049214764731
[Epoch 19, Batch 2900] loss: 0.015454017166994162
[Epoch 19, Batch 3000] loss: 0.02081410147737188
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9863
Overfitting: 0.0439
Best model saved at epoch 19 with validation loss: 0.0439
[Epoch 20, Batch 100] loss: 0.011519277168554254
[Epoch 20, Batch 200] loss: 0.023491968292873935
[Epoch 20, Batch 300] loss: 0.019802433248842136
[Epoch 20, Batch 400] loss: 0.015044250448481762
[Epoch 20, Batch 500] loss: 0.024037659819150577
[Epoch 20, Batch 600] loss: 0.028130939399707133
[Epoch 20, Batch 700] loss: 0.02383062912580499
[Epoch 20, Batch 800] loss: 0.022123292931937613
[Epoch 20, Batch 900] loss: 0.02004776558278536
[Epoch 20, Batch 1000] loss: 0.013728218314936385
[Epoch 20, Batch 1100] loss: 0.02552569396459148
[Epoch 20, Batch 1200] loss: 0.01871766143511195
[Epoch 20, Batch 1300] loss: 0.013125129290674522
[Epoch 20, Batch 1400] loss: 0.014411512275801215
[Epoch 20, Batch 1500] loss: 0.020828789291008433
[Epoch 20, Batch 1600] loss: 0.01675703316661384
[Epoch 20, Batch 1700] loss: 0.022380557368087466
[Epoch 20, Batch 1800] loss: 0.02515339975230745
[Epoch 20, Batch 1900] loss: 0.02329839358837489
[Epoch 20, Batch 2000] loss: 0.01869316499243723
[Epoch 20, Batch 2100] loss: 0.02334560353869165
[Epoch 20, Batch 2200] loss: 0.02544557110599271
[Epoch 20, Batch 2300] loss: 0.018094493913231417
[Epoch 20, Batch 2400] loss: 0.015949537548294757
[Epoch 20, Batch 2500] loss: 0.014547089364714338
[Epoch 20, Batch 2600] loss: 0.020811277488237464
[Epoch 20, Batch 2700] loss: 0.01856162433472491
[Epoch 20, Batch 2800] loss: 0.022259748630895047
[Epoch 20, Batch 2900] loss: 0.010250203628311283
[Epoch 20, Batch 3000] loss: 0.015380190975229198
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0443
Validation Accuracy: 0.9868
Overfitting: 0.0443
[Epoch 21, Batch 100] loss: 0.01210931362473275
[Epoch 21, Batch 200] loss: 0.012300650647412113
[Epoch 21, Batch 300] loss: 0.0225485797534202
[Epoch 21, Batch 400] loss: 0.013297457115331781
[Epoch 21, Batch 500] loss: 0.018801131944928783
[Epoch 21, Batch 600] loss: 0.019915103463245033
[Epoch 21, Batch 700] loss: 0.027304927285949816
[Epoch 21, Batch 800] loss: 0.013159568049122754
[Epoch 21, Batch 900] loss: 0.014913810311700217
[Epoch 21, Batch 1000] loss: 0.020064965320671035
[Epoch 21, Batch 1100] loss: 0.020855047140357783
[Epoch 21, Batch 1200] loss: 0.021191483156380853
[Epoch 21, Batch 1300] loss: 0.019416335253081344
[Epoch 21, Batch 1400] loss: 0.024146903560649663
[Epoch 21, Batch 1500] loss: 0.01853268584683974
[Epoch 21, Batch 1600] loss: 0.012829302599238873
[Epoch 21, Batch 1700] loss: 0.01869950194191915
[Epoch 21, Batch 1800] loss: 0.02014020349834027
[Epoch 21, Batch 1900] loss: 0.019627931152972452
[Epoch 21, Batch 2000] loss: 0.010339823278154654
[Epoch 21, Batch 2100] loss: 0.016594481533429642
[Epoch 21, Batch 2200] loss: 0.023803531045850833
[Epoch 21, Batch 2300] loss: 0.02282610529429803
[Epoch 21, Batch 2400] loss: 0.015627551750330895
[Epoch 21, Batch 2500] loss: 0.018527236385416472
[Epoch 21, Batch 2600] loss: 0.016543541571845708
[Epoch 21, Batch 2700] loss: 0.01586637256047652
[Epoch 21, Batch 2800] loss: 0.022651836339209693
[Epoch 21, Batch 2900] loss: 0.0147738882377962
[Epoch 21, Batch 3000] loss: 0.026755640377523378
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9868
Overfitting: 0.0447
[Epoch 22, Batch 100] loss: 0.020591270649638317
[Epoch 22, Batch 200] loss: 0.013613121619237063
[Epoch 22, Batch 300] loss: 0.014346852392554866
[Epoch 22, Batch 400] loss: 0.012669311564468443
[Epoch 22, Batch 500] loss: 0.020735266113151737
[Epoch 22, Batch 600] loss: 0.016505086875331473
[Epoch 22, Batch 700] loss: 0.013610489918428358
[Epoch 22, Batch 800] loss: 0.014143408898526104
[Epoch 22, Batch 900] loss: 0.011124900860377238
[Epoch 22, Batch 1000] loss: 0.012117742724294658
[Epoch 22, Batch 1100] loss: 0.021994580882528682
[Epoch 22, Batch 1200] loss: 0.024190285594049784
[Epoch 22, Batch 1300] loss: 0.02252725712305619
[Epoch 22, Batch 1400] loss: 0.013431425148055495
[Epoch 22, Batch 1500] loss: 0.017106518104446876
[Epoch 22, Batch 1600] loss: 0.008358298367602402
[Epoch 22, Batch 1700] loss: 0.014609765069508285
[Epoch 22, Batch 1800] loss: 0.01180100151370425
[Epoch 22, Batch 1900] loss: 0.016881233243475437
[Epoch 22, Batch 2000] loss: 0.017583288534515306
[Epoch 22, Batch 2100] loss: 0.02239160599296156
[Epoch 22, Batch 2200] loss: 0.010822738291644783
[Epoch 22, Batch 2300] loss: 0.01894298159662867
[Epoch 22, Batch 2400] loss: 0.026030595351185185
[Epoch 22, Batch 2500] loss: 0.010852779251144966
[Epoch 22, Batch 2600] loss: 0.025759280240272346
[Epoch 22, Batch 2700] loss: 0.013405432967447268
[Epoch 22, Batch 2800] loss: 0.022911023181586644
[Epoch 22, Batch 2900] loss: 0.016381844496063423
[Epoch 22, Batch 3000] loss: 0.0221496428809769
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9854
Overfitting: 0.0485
[Epoch 23, Batch 100] loss: 0.01746153476728068
[Epoch 23, Batch 200] loss: 0.009028162333943329
[Epoch 23, Batch 300] loss: 0.013219473811441276
[Epoch 23, Batch 400] loss: 0.01035853391760611
[Epoch 23, Batch 500] loss: 0.019166776384754485
[Epoch 23, Batch 600] loss: 0.009595659802134832
[Epoch 23, Batch 700] loss: 0.012397535214367962
[Epoch 23, Batch 800] loss: 0.01692489642780856
[Epoch 23, Batch 900] loss: 0.01307272595113318
[Epoch 23, Batch 1000] loss: 0.007623532339730446
[Epoch 23, Batch 1100] loss: 0.01575475817955521
[Epoch 23, Batch 1200] loss: 0.013978253965879048
[Epoch 23, Batch 1300] loss: 0.014364399520782173
[Epoch 23, Batch 1400] loss: 0.016288649005546177
[Epoch 23, Batch 1500] loss: 0.014278780587374059
[Epoch 23, Batch 1600] loss: 0.010837270563970379
[Epoch 23, Batch 1700] loss: 0.021634008773544336
[Epoch 23, Batch 1800] loss: 0.021175656034392885
[Epoch 23, Batch 1900] loss: 0.014834270167812065
[Epoch 23, Batch 2000] loss: 0.01697523145510786
[Epoch 23, Batch 2100] loss: 0.016860771974570525
[Epoch 23, Batch 2200] loss: 0.011264154503164718
[Epoch 23, Batch 2300] loss: 0.020674260613395744
[Epoch 23, Batch 2400] loss: 0.021780507398962073
[Epoch 23, Batch 2500] loss: 0.016869365616075813
[Epoch 23, Batch 2600] loss: 0.027285820450924803
[Epoch 23, Batch 2700] loss: 0.0249012195798241
[Epoch 23, Batch 2800] loss: 0.019903395947712853
[Epoch 23, Batch 2900] loss: 0.015476329721041111
[Epoch 23, Batch 3000] loss: 0.017627112748814396
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9871
Overfitting: 0.0439
[Epoch 24, Batch 100] loss: 0.017853243757635938
[Epoch 24, Batch 200] loss: 0.01562602335581687
[Epoch 24, Batch 300] loss: 0.008457761341960577
[Epoch 24, Batch 400] loss: 0.018711903223666015
[Epoch 24, Batch 500] loss: 0.010888260245010314
[Epoch 24, Batch 600] loss: 0.022548994708413376
[Epoch 24, Batch 700] loss: 0.020188702904606545
[Epoch 24, Batch 800] loss: 0.016596557466509693
[Epoch 24, Batch 900] loss: 0.02181988315387571
[Epoch 24, Batch 1000] loss: 0.012104242329551198
[Epoch 24, Batch 1100] loss: 0.00768440474259478
[Epoch 24, Batch 1200] loss: 0.009588078993692762
[Epoch 24, Batch 1300] loss: 0.009293680498622052
[Epoch 24, Batch 1400] loss: 0.01347035256982963
[Epoch 24, Batch 1500] loss: 0.017136830889503473
[Epoch 24, Batch 1600] loss: 0.008982207878743794
[Epoch 24, Batch 1700] loss: 0.01359158185020533
[Epoch 24, Batch 1800] loss: 0.01842419945569418
[Epoch 24, Batch 1900] loss: 0.013828725305247645
[Epoch 24, Batch 2000] loss: 0.020391662671991072
[Epoch 24, Batch 2100] loss: 0.013897348061800586
[Epoch 24, Batch 2200] loss: 0.008637264010612853
[Epoch 24, Batch 2300] loss: 0.008626805890835386
[Epoch 24, Batch 2400] loss: 0.015372792192138149
[Epoch 24, Batch 2500] loss: 0.010332844960830699
[Epoch 24, Batch 2600] loss: 0.013658979567844653
[Epoch 24, Batch 2700] loss: 0.016990150955953142
[Epoch 24, Batch 2800] loss: 0.013005913940578467
[Epoch 24, Batch 2900] loss: 0.015364913796802285
[Epoch 24, Batch 3000] loss: 0.01325914880982964
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9865
Overfitting: 0.0447
Fold 4 validation loss: 0.0447
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.3008676505088808
[Epoch 1, Batch 200] loss: 2.292877640724182
[Epoch 1, Batch 300] loss: 2.2851769065856935
[Epoch 1, Batch 400] loss: 2.2730160045623777
[Epoch 1, Batch 500] loss: 2.2569565677642824
[Epoch 1, Batch 600] loss: 2.2402690720558165
[Epoch 1, Batch 700] loss: 2.2025870060920716
[Epoch 1, Batch 800] loss: 2.135357165336609
[Epoch 1, Batch 900] loss: 2.018106026649475
[Epoch 1, Batch 1000] loss: 1.7570667457580567
[Epoch 1, Batch 1100] loss: 1.2179748839139939
[Epoch 1, Batch 1200] loss: 0.8245706981420518
[Epoch 1, Batch 1300] loss: 0.635510872900486
[Epoch 1, Batch 1400] loss: 0.5099137192964553
[Epoch 1, Batch 1500] loss: 0.4412852334976196
[Epoch 1, Batch 1600] loss: 0.413263184055686
[Epoch 1, Batch 1700] loss: 0.367828331887722
[Epoch 1, Batch 1800] loss: 0.3449422332644463
[Epoch 1, Batch 1900] loss: 0.3166407333686948
[Epoch 1, Batch 2000] loss: 0.31193712648004296
[Epoch 1, Batch 2100] loss: 0.3122127841413021
[Epoch 1, Batch 2200] loss: 0.2626001522876322
[Epoch 1, Batch 2300] loss: 0.25828630149364473
[Epoch 1, Batch 2400] loss: 0.27172027722001074
[Epoch 1, Batch 2500] loss: 0.24998913122341038
[Epoch 1, Batch 2600] loss: 0.2644180116429925
[Epoch 1, Batch 2700] loss: 0.30541503060609104
[Epoch 1, Batch 2800] loss: 0.24494422379881142
[Epoch 1, Batch 2900] loss: 0.2308141583018005
[Epoch 1, Batch 3000] loss: 0.2844566915556788
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2290
Validation Accuracy: 0.9322
Overfitting: 0.2290
Best model saved at epoch 1 with validation loss: 0.2290
[Epoch 2, Batch 100] loss: 0.22461290242150425
[Epoch 2, Batch 200] loss: 0.21245947900228201
[Epoch 2, Batch 300] loss: 0.21862562566995622
[Epoch 2, Batch 400] loss: 0.2611122756265104
[Epoch 2, Batch 500] loss: 0.21667193693108858
[Epoch 2, Batch 600] loss: 0.15652273736894132
[Epoch 2, Batch 700] loss: 0.20403523020446301
[Epoch 2, Batch 800] loss: 0.1902441681921482
[Epoch 2, Batch 900] loss: 0.21139753382652998
[Epoch 2, Batch 1000] loss: 0.18347527753561735
[Epoch 2, Batch 1100] loss: 0.1672574201505631
[Epoch 2, Batch 1200] loss: 0.2021619868837297
[Epoch 2, Batch 1300] loss: 0.17438182406127453
[Epoch 2, Batch 1400] loss: 0.19702899508178234
[Epoch 2, Batch 1500] loss: 0.17135720426216722
[Epoch 2, Batch 1600] loss: 0.1483631413895637
[Epoch 2, Batch 1700] loss: 0.14730951288715005
[Epoch 2, Batch 1800] loss: 0.14021442549768837
[Epoch 2, Batch 1900] loss: 0.16235009948955847
[Epoch 2, Batch 2000] loss: 0.17367835137993098
[Epoch 2, Batch 2100] loss: 0.14105719078332185
[Epoch 2, Batch 2200] loss: 0.13748850169591606
[Epoch 2, Batch 2300] loss: 0.1686611731722951
[Epoch 2, Batch 2400] loss: 0.13151305802166463
[Epoch 2, Batch 2500] loss: 0.15451364025473593
[Epoch 2, Batch 2600] loss: 0.1399384226836264
[Epoch 2, Batch 2700] loss: 0.12947455179179088
[Epoch 2, Batch 2800] loss: 0.15145432165823877
[Epoch 2, Batch 2900] loss: 0.11331426420714706
[Epoch 2, Batch 3000] loss: 0.14020058108493685
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1316
Validation Accuracy: 0.9620
Overfitting: 0.1316
Best model saved at epoch 2 with validation loss: 0.1316
[Epoch 3, Batch 100] loss: 0.12518796153832226
[Epoch 3, Batch 200] loss: 0.143609960982576
[Epoch 3, Batch 300] loss: 0.13117215094622225
[Epoch 3, Batch 400] loss: 0.1186482949089259
[Epoch 3, Batch 500] loss: 0.14045344373676927
[Epoch 3, Batch 600] loss: 0.13500849488656969
[Epoch 3, Batch 700] loss: 0.10074231094680726
[Epoch 3, Batch 800] loss: 0.12195741434814408
[Epoch 3, Batch 900] loss: 0.14979907910805196
[Epoch 3, Batch 1000] loss: 0.11918111307546496
[Epoch 3, Batch 1100] loss: 0.1470319731393829
[Epoch 3, Batch 1200] loss: 0.10666819099802524
[Epoch 3, Batch 1300] loss: 0.12061575808562339
[Epoch 3, Batch 1400] loss: 0.12762245552614332
[Epoch 3, Batch 1500] loss: 0.12606400035321713
[Epoch 3, Batch 1600] loss: 0.12069093253929168
[Epoch 3, Batch 1700] loss: 0.15538205050863327
[Epoch 3, Batch 1800] loss: 0.1236040430655703
[Epoch 3, Batch 1900] loss: 0.09966813149396331
[Epoch 3, Batch 2000] loss: 0.10753626112826169
[Epoch 3, Batch 2100] loss: 0.12332837925991043
[Epoch 3, Batch 2200] loss: 0.09615044619888068
[Epoch 3, Batch 2300] loss: 0.10754475098568946
[Epoch 3, Batch 2400] loss: 0.11177351677557454
[Epoch 3, Batch 2500] loss: 0.08807892785174772
[Epoch 3, Batch 2600] loss: 0.09046003270894289
[Epoch 3, Batch 2700] loss: 0.10538101142272353
[Epoch 3, Batch 2800] loss: 0.10067980809835717
[Epoch 3, Batch 2900] loss: 0.09781227180734277
[Epoch 3, Batch 3000] loss: 0.10200441861758008
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1002
Validation Accuracy: 0.9714
Overfitting: 0.1002
Best model saved at epoch 3 with validation loss: 0.1002
[Epoch 4, Batch 100] loss: 0.09676219428423792
[Epoch 4, Batch 200] loss: 0.10787587301107124
[Epoch 4, Batch 300] loss: 0.10110102184698917
[Epoch 4, Batch 400] loss: 0.1141108147916384
[Epoch 4, Batch 500] loss: 0.10577908793464302
[Epoch 4, Batch 600] loss: 0.09718790939543397
[Epoch 4, Batch 700] loss: 0.08617142294999212
[Epoch 4, Batch 800] loss: 0.10584601022768765
[Epoch 4, Batch 900] loss: 0.08230150691466406
[Epoch 4, Batch 1000] loss: 0.10425920479930938
[Epoch 4, Batch 1100] loss: 0.09161338842241093
[Epoch 4, Batch 1200] loss: 0.06991590778809041
[Epoch 4, Batch 1300] loss: 0.09703156320378184
[Epoch 4, Batch 1400] loss: 0.086869018842699
[Epoch 4, Batch 1500] loss: 0.09258364879526199
[Epoch 4, Batch 1600] loss: 0.09193066975800321
[Epoch 4, Batch 1700] loss: 0.08929238516488112
[Epoch 4, Batch 1800] loss: 0.09864648056449368
[Epoch 4, Batch 1900] loss: 0.08274416326312348
[Epoch 4, Batch 2000] loss: 0.08767223987379111
[Epoch 4, Batch 2100] loss: 0.10732947579585016
[Epoch 4, Batch 2200] loss: 0.08269782985094935
[Epoch 4, Batch 2300] loss: 0.09725503973197192
[Epoch 4, Batch 2400] loss: 0.11364628922194242
[Epoch 4, Batch 2500] loss: 0.08790418325224891
[Epoch 4, Batch 2600] loss: 0.07792426467523911
[Epoch 4, Batch 2700] loss: 0.0837824102398008
[Epoch 4, Batch 2800] loss: 0.0675015307078138
[Epoch 4, Batch 2900] loss: 0.09309032650664449
[Epoch 4, Batch 3000] loss: 0.06508544714073651
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0949
Validation Accuracy: 0.9696
Overfitting: 0.0949
Best model saved at epoch 4 with validation loss: 0.0949
[Epoch 5, Batch 100] loss: 0.08045465039554983
[Epoch 5, Batch 200] loss: 0.10349802897078916
[Epoch 5, Batch 300] loss: 0.08492907297331839
[Epoch 5, Batch 400] loss: 0.07257820500642992
[Epoch 5, Batch 500] loss: 0.09363719931105152
[Epoch 5, Batch 600] loss: 0.07079482730943709
[Epoch 5, Batch 700] loss: 0.09302902233088389
[Epoch 5, Batch 800] loss: 0.07794133940595202
[Epoch 5, Batch 900] loss: 0.08535155313205905
[Epoch 5, Batch 1000] loss: 0.0776309938263148
[Epoch 5, Batch 1100] loss: 0.07127734111738392
[Epoch 5, Batch 1200] loss: 0.08198623662348836
[Epoch 5, Batch 1300] loss: 0.10084142501698806
[Epoch 5, Batch 1400] loss: 0.0563160737324506
[Epoch 5, Batch 1500] loss: 0.09141606329940259
[Epoch 5, Batch 1600] loss: 0.05947394793853164
[Epoch 5, Batch 1700] loss: 0.08491193173220381
[Epoch 5, Batch 1800] loss: 0.06474034251179546
[Epoch 5, Batch 1900] loss: 0.0792199244722724
[Epoch 5, Batch 2000] loss: 0.07931884407065809
[Epoch 5, Batch 2100] loss: 0.05587013746233424
[Epoch 5, Batch 2200] loss: 0.09151361734140664
[Epoch 5, Batch 2300] loss: 0.046932298445608464
[Epoch 5, Batch 2400] loss: 0.10211869205581024
[Epoch 5, Batch 2500] loss: 0.07302412246586755
[Epoch 5, Batch 2600] loss: 0.07331788808107376
[Epoch 5, Batch 2700] loss: 0.0635881920333486
[Epoch 5, Batch 2800] loss: 0.06722316138213501
[Epoch 5, Batch 2900] loss: 0.0649037687969394
[Epoch 5, Batch 3000] loss: 0.09006574008613825
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0810
Validation Accuracy: 0.9763
Overfitting: 0.0810
Best model saved at epoch 5 with validation loss: 0.0810
[Epoch 6, Batch 100] loss: 0.06533571483392735
[Epoch 6, Batch 200] loss: 0.0781832458684221
[Epoch 6, Batch 300] loss: 0.0581082238862291
[Epoch 6, Batch 400] loss: 0.07230445637833327
[Epoch 6, Batch 500] loss: 0.0727504049090203
[Epoch 6, Batch 600] loss: 0.07546001679555048
[Epoch 6, Batch 700] loss: 0.06428171903127805
[Epoch 6, Batch 800] loss: 0.10380594687128905
[Epoch 6, Batch 900] loss: 0.058241219272604214
[Epoch 6, Batch 1000] loss: 0.08130073311156594
[Epoch 6, Batch 1100] loss: 0.06586555853718892
[Epoch 6, Batch 1200] loss: 0.08268337899586185
[Epoch 6, Batch 1300] loss: 0.06264680473686894
[Epoch 6, Batch 1400] loss: 0.07190892515936867
[Epoch 6, Batch 1500] loss: 0.06913085011823568
[Epoch 6, Batch 1600] loss: 0.08493669627467171
[Epoch 6, Batch 1700] loss: 0.06990695843705907
[Epoch 6, Batch 1800] loss: 0.058418300324119626
[Epoch 6, Batch 1900] loss: 0.05901838319667149
[Epoch 6, Batch 2000] loss: 0.07444980381056666
[Epoch 6, Batch 2100] loss: 0.0618597369256895
[Epoch 6, Batch 2200] loss: 0.059485147279920055
[Epoch 6, Batch 2300] loss: 0.06734805830405094
[Epoch 6, Batch 2400] loss: 0.049066386877093464
[Epoch 6, Batch 2500] loss: 0.04536839074222371
[Epoch 6, Batch 2600] loss: 0.06524422165122815
[Epoch 6, Batch 2700] loss: 0.06854042583610863
[Epoch 6, Batch 2800] loss: 0.08039630815386772
[Epoch 6, Batch 2900] loss: 0.06062139803078025
[Epoch 6, Batch 3000] loss: 0.058147743579465894
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0705
Validation Accuracy: 0.9781
Overfitting: 0.0705
Best model saved at epoch 6 with validation loss: 0.0705
[Epoch 7, Batch 100] loss: 0.05792247691832017
[Epoch 7, Batch 200] loss: 0.07034058423247189
[Epoch 7, Batch 300] loss: 0.06502209882019087
[Epoch 7, Batch 400] loss: 0.05753861172765028
[Epoch 7, Batch 500] loss: 0.06271015883947256
[Epoch 7, Batch 600] loss: 0.06290367653477005
[Epoch 7, Batch 700] loss: 0.08618930727709084
[Epoch 7, Batch 800] loss: 0.062369528335984796
[Epoch 7, Batch 900] loss: 0.0638059414329473
[Epoch 7, Batch 1000] loss: 0.05338977302191779
[Epoch 7, Batch 1100] loss: 0.051843671785900367
[Epoch 7, Batch 1200] loss: 0.07663911712879781
[Epoch 7, Batch 1300] loss: 0.050536968880915085
[Epoch 7, Batch 1400] loss: 0.048866054185200486
[Epoch 7, Batch 1500] loss: 0.07036159789306112
[Epoch 7, Batch 1600] loss: 0.0408324009279022
[Epoch 7, Batch 1700] loss: 0.04766213401046116
[Epoch 7, Batch 1800] loss: 0.05798849944490939
[Epoch 7, Batch 1900] loss: 0.04358261984656565
[Epoch 7, Batch 2000] loss: 0.0772694101644447
[Epoch 7, Batch 2100] loss: 0.06322019104612991
[Epoch 7, Batch 2200] loss: 0.05756675764510874
[Epoch 7, Batch 2300] loss: 0.07727817133883946
[Epoch 7, Batch 2400] loss: 0.05143174367782194
[Epoch 7, Batch 2500] loss: 0.05484675291227177
[Epoch 7, Batch 2600] loss: 0.06052488494315185
[Epoch 7, Batch 2700] loss: 0.05836732101044618
[Epoch 7, Batch 2800] loss: 0.04594124612805899
[Epoch 7, Batch 2900] loss: 0.050910503300256094
[Epoch 7, Batch 3000] loss: 0.06114594053244218
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0641
Validation Accuracy: 0.9803
Overfitting: 0.0641
Best model saved at epoch 7 with validation loss: 0.0641
[Epoch 8, Batch 100] loss: 0.04175413688586559
[Epoch 8, Batch 200] loss: 0.07137828203500249
[Epoch 8, Batch 300] loss: 0.046009428167308214
[Epoch 8, Batch 400] loss: 0.038787775599048474
[Epoch 8, Batch 500] loss: 0.05881749534921255
[Epoch 8, Batch 600] loss: 0.052863381253264376
[Epoch 8, Batch 700] loss: 0.048109008245519364
[Epoch 8, Batch 800] loss: 0.06381305987335509
[Epoch 8, Batch 900] loss: 0.05600200447574025
[Epoch 8, Batch 1000] loss: 0.05760756123345345
[Epoch 8, Batch 1100] loss: 0.09506827299366705
[Epoch 8, Batch 1200] loss: 0.05618095796031412
[Epoch 8, Batch 1300] loss: 0.04429395646176999
[Epoch 8, Batch 1400] loss: 0.044289083982585
[Epoch 8, Batch 1500] loss: 0.04639830843138043
[Epoch 8, Batch 1600] loss: 0.05318760754249524
[Epoch 8, Batch 1700] loss: 0.054507522442145274
[Epoch 8, Batch 1800] loss: 0.03324859260639641
[Epoch 8, Batch 1900] loss: 0.05149774038756732
[Epoch 8, Batch 2000] loss: 0.04695624481071718
[Epoch 8, Batch 2100] loss: 0.06618179890909232
[Epoch 8, Batch 2200] loss: 0.037740421479393264
[Epoch 8, Batch 2300] loss: 0.050833654937450776
[Epoch 8, Batch 2400] loss: 0.04771755358116934
[Epoch 8, Batch 2500] loss: 0.04315050679142587
[Epoch 8, Batch 2600] loss: 0.0425917332523386
[Epoch 8, Batch 2700] loss: 0.045754058824677486
[Epoch 8, Batch 2800] loss: 0.049182166410028004
[Epoch 8, Batch 2900] loss: 0.08025085950386711
[Epoch 8, Batch 3000] loss: 0.04210465658572502
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0566
Validation Accuracy: 0.9830
Overfitting: 0.0566
Best model saved at epoch 8 with validation loss: 0.0566
[Epoch 9, Batch 100] loss: 0.04852664778125473
[Epoch 9, Batch 200] loss: 0.04723551507981028
[Epoch 9, Batch 300] loss: 0.0544528889155481
[Epoch 9, Batch 400] loss: 0.05598785387526732
[Epoch 9, Batch 500] loss: 0.04703835433698259
[Epoch 9, Batch 600] loss: 0.03736529733956559
[Epoch 9, Batch 700] loss: 0.0339543925866019
[Epoch 9, Batch 800] loss: 0.06355649087199708
[Epoch 9, Batch 900] loss: 0.05648581582820043
[Epoch 9, Batch 1000] loss: 0.04203789746447001
[Epoch 9, Batch 1100] loss: 0.051250216743792404
[Epoch 9, Batch 1200] loss: 0.048336187187815086
[Epoch 9, Batch 1300] loss: 0.05724106985726394
[Epoch 9, Batch 1400] loss: 0.03926272700889968
[Epoch 9, Batch 1500] loss: 0.056562605756043924
[Epoch 9, Batch 1600] loss: 0.04420909698324976
[Epoch 9, Batch 1700] loss: 0.04595745274447836
[Epoch 9, Batch 1800] loss: 0.038390702971955765
[Epoch 9, Batch 1900] loss: 0.04188963114051148
[Epoch 9, Batch 2000] loss: 0.05970604865171481
[Epoch 9, Batch 2100] loss: 0.055217046751640735
[Epoch 9, Batch 2200] loss: 0.058456035653944124
[Epoch 9, Batch 2300] loss: 0.03771531249745749
[Epoch 9, Batch 2400] loss: 0.045715307681821284
[Epoch 9, Batch 2500] loss: 0.04819336171844043
[Epoch 9, Batch 2600] loss: 0.04181658637477085
[Epoch 9, Batch 2700] loss: 0.04795851528266212
[Epoch 9, Batch 2800] loss: 0.04326540284222574
[Epoch 9, Batch 2900] loss: 0.05668419601599453
[Epoch 9, Batch 3000] loss: 0.036644660500751346
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9838
Overfitting: 0.0532
Best model saved at epoch 9 with validation loss: 0.0532
[Epoch 10, Batch 100] loss: 0.04048917752690613
[Epoch 10, Batch 200] loss: 0.0489487692900002
[Epoch 10, Batch 300] loss: 0.06084077842533588
[Epoch 10, Batch 400] loss: 0.04159150015708292
[Epoch 10, Batch 500] loss: 0.03951447682076832
[Epoch 10, Batch 600] loss: 0.03441530812589917
[Epoch 10, Batch 700] loss: 0.03230520506811445
[Epoch 10, Batch 800] loss: 0.04150412905903068
[Epoch 10, Batch 900] loss: 0.04812499684514478
[Epoch 10, Batch 1000] loss: 0.040447110496461394
[Epoch 10, Batch 1100] loss: 0.050874501039797904
[Epoch 10, Batch 1200] loss: 0.05789972272061277
[Epoch 10, Batch 1300] loss: 0.04944138551305514
[Epoch 10, Batch 1400] loss: 0.04750714553461876
[Epoch 10, Batch 1500] loss: 0.05085748289944604
[Epoch 10, Batch 1600] loss: 0.041250883228785826
[Epoch 10, Batch 1700] loss: 0.05604577025631443
[Epoch 10, Batch 1800] loss: 0.04647536230972037
[Epoch 10, Batch 1900] loss: 0.03647994990373263
[Epoch 10, Batch 2000] loss: 0.031084227974643
[Epoch 10, Batch 2100] loss: 0.03777345038834028
[Epoch 10, Batch 2200] loss: 0.041058139438391664
[Epoch 10, Batch 2300] loss: 0.05115506483023637
[Epoch 10, Batch 2400] loss: 0.03969360308808973
[Epoch 10, Batch 2500] loss: 0.03164103062736103
[Epoch 10, Batch 2600] loss: 0.036201884082111065
[Epoch 10, Batch 2700] loss: 0.0724801417265553
[Epoch 10, Batch 2800] loss: 0.04329464973241556
[Epoch 10, Batch 2900] loss: 0.03724688257614616
[Epoch 10, Batch 3000] loss: 0.048108900078223084
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9846
Overfitting: 0.0501
Best model saved at epoch 10 with validation loss: 0.0501
[Epoch 11, Batch 100] loss: 0.028460781701724044
[Epoch 11, Batch 200] loss: 0.033584719789505474
[Epoch 11, Batch 300] loss: 0.04488302799421945
[Epoch 11, Batch 400] loss: 0.03786945450789062
[Epoch 11, Batch 500] loss: 0.03238764436740894
[Epoch 11, Batch 600] loss: 0.053050400985521266
[Epoch 11, Batch 700] loss: 0.03983071781345643
[Epoch 11, Batch 800] loss: 0.037082429826259616
[Epoch 11, Batch 900] loss: 0.04647781505744206
[Epoch 11, Batch 1000] loss: 0.04667464654456126
[Epoch 11, Batch 1100] loss: 0.04338230017048773
[Epoch 11, Batch 1200] loss: 0.03677814867463894
[Epoch 11, Batch 1300] loss: 0.021771862105233596
[Epoch 11, Batch 1400] loss: 0.042978632763843054
[Epoch 11, Batch 1500] loss: 0.04745480455865618
[Epoch 11, Batch 1600] loss: 0.04090674088132801
[Epoch 11, Batch 1700] loss: 0.02148627998001757
[Epoch 11, Batch 1800] loss: 0.04029868517594878
[Epoch 11, Batch 1900] loss: 0.048055091821879614
[Epoch 11, Batch 2000] loss: 0.027510313209932066
[Epoch 11, Batch 2100] loss: 0.04807011244352907
[Epoch 11, Batch 2200] loss: 0.03224215090827784
[Epoch 11, Batch 2300] loss: 0.035663483514508695
[Epoch 11, Batch 2400] loss: 0.03344778340106132
[Epoch 11, Batch 2500] loss: 0.05319387333234772
[Epoch 11, Batch 2600] loss: 0.06428873077617027
[Epoch 11, Batch 2700] loss: 0.05504331243864726
[Epoch 11, Batch 2800] loss: 0.04185628945124335
[Epoch 11, Batch 2900] loss: 0.04732245890161721
[Epoch 11, Batch 3000] loss: 0.044027457269694426
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9828
Overfitting: 0.0564
[Epoch 12, Batch 100] loss: 0.031798096987913596
[Epoch 12, Batch 200] loss: 0.02985059225014993
[Epoch 12, Batch 300] loss: 0.04151862105412874
[Epoch 12, Batch 400] loss: 0.03844676715962123
[Epoch 12, Batch 500] loss: 0.03430447341292165
[Epoch 12, Batch 600] loss: 0.041617768529504245
[Epoch 12, Batch 700] loss: 0.036183799122518394
[Epoch 12, Batch 800] loss: 0.02998313710355433
[Epoch 12, Batch 900] loss: 0.045045662750635526
[Epoch 12, Batch 1000] loss: 0.03594059503870085
[Epoch 12, Batch 1100] loss: 0.029778075693175195
[Epoch 12, Batch 1200] loss: 0.027245012398052496
[Epoch 12, Batch 1300] loss: 0.03551422789139906
[Epoch 12, Batch 1400] loss: 0.036025408366404006
[Epoch 12, Batch 1500] loss: 0.03747007758327527
[Epoch 12, Batch 1600] loss: 0.04608370658941567
[Epoch 12, Batch 1700] loss: 0.03321270251763053
[Epoch 12, Batch 1800] loss: 0.0403578949382063
[Epoch 12, Batch 1900] loss: 0.029067101649707182
[Epoch 12, Batch 2000] loss: 0.030406234434631186
[Epoch 12, Batch 2100] loss: 0.04107879482791759
[Epoch 12, Batch 2200] loss: 0.05062346171675017
[Epoch 12, Batch 2300] loss: 0.03528025769104715
[Epoch 12, Batch 2400] loss: 0.03623487684119027
[Epoch 12, Batch 2500] loss: 0.03632750121585559
[Epoch 12, Batch 2600] loss: 0.04295570651796879
[Epoch 12, Batch 2700] loss: 0.03738674487452954
[Epoch 12, Batch 2800] loss: 0.05586495490570087
[Epoch 12, Batch 2900] loss: 0.03296014040708542
[Epoch 12, Batch 3000] loss: 0.020736455745936837
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9839
Overfitting: 0.0564
[Epoch 13, Batch 100] loss: 0.03247343140770681
[Epoch 13, Batch 200] loss: 0.03403478207881563
[Epoch 13, Batch 300] loss: 0.026607171528194157
[Epoch 13, Batch 400] loss: 0.03816552583535668
[Epoch 13, Batch 500] loss: 0.0296982501995808
[Epoch 13, Batch 600] loss: 0.032416749152398554
[Epoch 13, Batch 700] loss: 0.03125794418752775
[Epoch 13, Batch 800] loss: 0.035020329354447315
[Epoch 13, Batch 900] loss: 0.042703249787446114
[Epoch 13, Batch 1000] loss: 0.018495712964941048
[Epoch 13, Batch 1100] loss: 0.0359161327451875
[Epoch 13, Batch 1200] loss: 0.03256887737195939
[Epoch 13, Batch 1300] loss: 0.0315096197091043
[Epoch 13, Batch 1400] loss: 0.02508539074813598
[Epoch 13, Batch 1500] loss: 0.03630934141139733
[Epoch 13, Batch 1600] loss: 0.03307173730012437
[Epoch 13, Batch 1700] loss: 0.030476055808976527
[Epoch 13, Batch 1800] loss: 0.03179939003108302
[Epoch 13, Batch 1900] loss: 0.04920189463504357
[Epoch 13, Batch 2000] loss: 0.05080650632691686
[Epoch 13, Batch 2100] loss: 0.036528869764879346
[Epoch 13, Batch 2200] loss: 0.028722833264328073
[Epoch 13, Batch 2300] loss: 0.026590958258020693
[Epoch 13, Batch 2400] loss: 0.025281677761959144
[Epoch 13, Batch 2500] loss: 0.06126022160286084
[Epoch 13, Batch 2600] loss: 0.04820232568847132
[Epoch 13, Batch 2700] loss: 0.033856781974318434
[Epoch 13, Batch 2800] loss: 0.024907758757181
[Epoch 13, Batch 2900] loss: 0.036961301467963496
[Epoch 13, Batch 3000] loss: 0.04001927427190822
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0450
Validation Accuracy: 0.9865
Overfitting: 0.0450
Best model saved at epoch 13 with validation loss: 0.0450
[Epoch 14, Batch 100] loss: 0.027578961297840578
[Epoch 14, Batch 200] loss: 0.029846623897901735
[Epoch 14, Batch 300] loss: 0.027658057660155465
[Epoch 14, Batch 400] loss: 0.04898743269994157
[Epoch 14, Batch 500] loss: 0.04531333678532974
[Epoch 14, Batch 600] loss: 0.02376749278293573
[Epoch 14, Batch 700] loss: 0.031109445720212535
[Epoch 14, Batch 800] loss: 0.02707035049577826
[Epoch 14, Batch 900] loss: 0.03503060424613068
[Epoch 14, Batch 1000] loss: 0.033234352773579307
[Epoch 14, Batch 1100] loss: 0.036445103906589796
[Epoch 14, Batch 1200] loss: 0.0370115545365843
[Epoch 14, Batch 1300] loss: 0.025856542389519746
[Epoch 14, Batch 1400] loss: 0.04151166634052061
[Epoch 14, Batch 1500] loss: 0.019161266938317566
[Epoch 14, Batch 1600] loss: 0.029080533692322205
[Epoch 14, Batch 1700] loss: 0.026172688101360107
[Epoch 14, Batch 1800] loss: 0.03934862716560019
[Epoch 14, Batch 1900] loss: 0.02869832985015819
[Epoch 14, Batch 2000] loss: 0.037188469931425064
[Epoch 14, Batch 2100] loss: 0.037699909272632795
[Epoch 14, Batch 2200] loss: 0.024189023077924504
[Epoch 14, Batch 2300] loss: 0.02697758078845254
[Epoch 14, Batch 2400] loss: 0.030358411154520582
[Epoch 14, Batch 2500] loss: 0.04176384140519076
[Epoch 14, Batch 2600] loss: 0.030052381551213328
[Epoch 14, Batch 2700] loss: 0.0328075036307564
[Epoch 14, Batch 2800] loss: 0.03327842668746598
[Epoch 14, Batch 2900] loss: 0.03705723399034468
[Epoch 14, Batch 3000] loss: 0.027968717388721417
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9858
Overfitting: 0.0487
[Epoch 15, Batch 100] loss: 0.023006293314683717
[Epoch 15, Batch 200] loss: 0.020960977923386963
[Epoch 15, Batch 300] loss: 0.015607609460421373
[Epoch 15, Batch 400] loss: 0.022048904826660873
[Epoch 15, Batch 500] loss: 0.026383577742526542
[Epoch 15, Batch 600] loss: 0.02166129931800242
[Epoch 15, Batch 700] loss: 0.03335972366025089
[Epoch 15, Batch 800] loss: 0.030048365879010816
[Epoch 15, Batch 900] loss: 0.028306041355535855
[Epoch 15, Batch 1000] loss: 0.0344618474660092
[Epoch 15, Batch 1100] loss: 0.03106400263204705
[Epoch 15, Batch 1200] loss: 0.033806762883687044
[Epoch 15, Batch 1300] loss: 0.03302619163659983
[Epoch 15, Batch 1400] loss: 0.033427515020957796
[Epoch 15, Batch 1500] loss: 0.029283786748273997
[Epoch 15, Batch 1600] loss: 0.042101286093893575
[Epoch 15, Batch 1700] loss: 0.03540742851422692
[Epoch 15, Batch 1800] loss: 0.033812935138121246
[Epoch 15, Batch 1900] loss: 0.03414463821463869
[Epoch 15, Batch 2000] loss: 0.03060036373048206
[Epoch 15, Batch 2100] loss: 0.031057837181142533
[Epoch 15, Batch 2200] loss: 0.031738687867473345
[Epoch 15, Batch 2300] loss: 0.02558418258544407
[Epoch 15, Batch 2400] loss: 0.028614377175399566
[Epoch 15, Batch 2500] loss: 0.028052021953917573
[Epoch 15, Batch 2600] loss: 0.022534019563609037
[Epoch 15, Batch 2700] loss: 0.0316455880679132
[Epoch 15, Batch 2800] loss: 0.03376271087661735
[Epoch 15, Batch 2900] loss: 0.036800359478365866
[Epoch 15, Batch 3000] loss: 0.027069491541187745
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9862
Overfitting: 0.0469
[Epoch 16, Batch 100] loss: 0.018188016705971678
[Epoch 16, Batch 200] loss: 0.017499991613512976
[Epoch 16, Batch 300] loss: 0.03082551660889294
[Epoch 16, Batch 400] loss: 0.018709042465052336
[Epoch 16, Batch 500] loss: 0.03541848970533465
[Epoch 16, Batch 600] loss: 0.029867397061971133
[Epoch 16, Batch 700] loss: 0.032450425081333376
[Epoch 16, Batch 800] loss: 0.033605491004418585
[Epoch 16, Batch 900] loss: 0.03791683965740958
[Epoch 16, Batch 1000] loss: 0.025635701534338296
[Epoch 16, Batch 1100] loss: 0.029018525940628023
[Epoch 16, Batch 1200] loss: 0.025620730057635228
[Epoch 16, Batch 1300] loss: 0.027067013183987
[Epoch 16, Batch 1400] loss: 0.027359778617028496
[Epoch 16, Batch 1500] loss: 0.02818796693754848
[Epoch 16, Batch 1600] loss: 0.021590148417890306
[Epoch 16, Batch 1700] loss: 0.0274512786375999
[Epoch 16, Batch 1800] loss: 0.023800244499871042
[Epoch 16, Batch 1900] loss: 0.022682235926185967
[Epoch 16, Batch 2000] loss: 0.022708696651025092
[Epoch 16, Batch 2100] loss: 0.015915283157955856
[Epoch 16, Batch 2200] loss: 0.04848790315030783
[Epoch 16, Batch 2300] loss: 0.028014779715886107
[Epoch 16, Batch 2400] loss: 0.02219620293017215
[Epoch 16, Batch 2500] loss: 0.030042852478509303
[Epoch 16, Batch 2600] loss: 0.022058088795965887
[Epoch 16, Batch 2700] loss: 0.024772247424698433
[Epoch 16, Batch 2800] loss: 0.026386027606931747
[Epoch 16, Batch 2900] loss: 0.028937241947787698
[Epoch 16, Batch 3000] loss: 0.03665944334643427
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0420
Validation Accuracy: 0.9868
Overfitting: 0.0420
Best model saved at epoch 16 with validation loss: 0.0420
[Epoch 17, Batch 100] loss: 0.016068215388877434
[Epoch 17, Batch 200] loss: 0.023396750414394773
[Epoch 17, Batch 300] loss: 0.023163117622789286
[Epoch 17, Batch 400] loss: 0.024309043590765213
[Epoch 17, Batch 500] loss: 0.03615612940142455
[Epoch 17, Batch 600] loss: 0.023480704519170104
[Epoch 17, Batch 700] loss: 0.03131025502865668
[Epoch 17, Batch 800] loss: 0.01692550592302723
[Epoch 17, Batch 900] loss: 0.02206972054234939
[Epoch 17, Batch 1000] loss: 0.018504121579317145
[Epoch 17, Batch 1100] loss: 0.030226293940795585
[Epoch 17, Batch 1200] loss: 0.029558485992019996
[Epoch 17, Batch 1300] loss: 0.02730850861858926
[Epoch 17, Batch 1400] loss: 0.015983043327360065
[Epoch 17, Batch 1500] loss: 0.0184369207941927
[Epoch 17, Batch 1600] loss: 0.013560947880905587
[Epoch 17, Batch 1700] loss: 0.04285037424051552
[Epoch 17, Batch 1800] loss: 0.032853124883404236
[Epoch 17, Batch 1900] loss: 0.030464362523780437
[Epoch 17, Batch 2000] loss: 0.023083966886188138
[Epoch 17, Batch 2100] loss: 0.02876596818816324
[Epoch 17, Batch 2200] loss: 0.021850278970523506
[Epoch 17, Batch 2300] loss: 0.027150839080131845
[Epoch 17, Batch 2400] loss: 0.029155022845516215
[Epoch 17, Batch 2500] loss: 0.028499831314693438
[Epoch 17, Batch 2600] loss: 0.035693225747381804
[Epoch 17, Batch 2700] loss: 0.030884335760565592
[Epoch 17, Batch 2800] loss: 0.03119380429998273
[Epoch 17, Batch 2900] loss: 0.020658198403980352
[Epoch 17, Batch 3000] loss: 0.02698553085800086
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9865
Overfitting: 0.0430
[Epoch 18, Batch 100] loss: 0.018204597339426982
[Epoch 18, Batch 200] loss: 0.018823840118857335
[Epoch 18, Batch 300] loss: 0.020486311351851326
[Epoch 18, Batch 400] loss: 0.014783643653354375
[Epoch 18, Batch 500] loss: 0.02695813660739077
[Epoch 18, Batch 600] loss: 0.016823746279114857
[Epoch 18, Batch 700] loss: 0.030277069593503257
[Epoch 18, Batch 800] loss: 0.027527928454437644
[Epoch 18, Batch 900] loss: 0.017989388479763876
[Epoch 18, Batch 1000] loss: 0.018209066266717856
[Epoch 18, Batch 1100] loss: 0.02965347580437083
[Epoch 18, Batch 1200] loss: 0.020233972515561617
[Epoch 18, Batch 1300] loss: 0.02116445368483255
[Epoch 18, Batch 1400] loss: 0.025527425643012976
[Epoch 18, Batch 1500] loss: 0.021388272478361614
[Epoch 18, Batch 1600] loss: 0.024648308233663555
[Epoch 18, Batch 1700] loss: 0.01567575597007817
[Epoch 18, Batch 1800] loss: 0.026069988389135688
[Epoch 18, Batch 1900] loss: 0.03555588766321307
[Epoch 18, Batch 2000] loss: 0.03080740504548885
[Epoch 18, Batch 2100] loss: 0.027727886252687312
[Epoch 18, Batch 2200] loss: 0.025428525351162534
[Epoch 18, Batch 2300] loss: 0.02382301991703571
[Epoch 18, Batch 2400] loss: 0.016499146688875043
[Epoch 18, Batch 2500] loss: 0.028883873575396138
[Epoch 18, Batch 2600] loss: 0.030481914446354494
[Epoch 18, Batch 2700] loss: 0.017229457518915296
[Epoch 18, Batch 2800] loss: 0.026091605371111656
[Epoch 18, Batch 2900] loss: 0.029919829869322713
[Epoch 18, Batch 3000] loss: 0.030469413240534777
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9840
Overfitting: 0.0506
[Epoch 19, Batch 100] loss: 0.017961219405187877
[Epoch 19, Batch 200] loss: 0.01864741804172809
[Epoch 19, Batch 300] loss: 0.026660792750335532
[Epoch 19, Batch 400] loss: 0.01775482856457529
[Epoch 19, Batch 500] loss: 0.016963164984772447
[Epoch 19, Batch 600] loss: 0.02551686554463231
[Epoch 19, Batch 700] loss: 0.021455864746676524
[Epoch 19, Batch 800] loss: 0.014195311292023689
[Epoch 19, Batch 900] loss: 0.01927337393950438
[Epoch 19, Batch 1000] loss: 0.022553871234704273
[Epoch 19, Batch 1100] loss: 0.015208607176755323
[Epoch 19, Batch 1200] loss: 0.033676265793728816
[Epoch 19, Batch 1300] loss: 0.02318722654119483
[Epoch 19, Batch 1400] loss: 0.028796468302607535
[Epoch 19, Batch 1500] loss: 0.02468610666313907
[Epoch 19, Batch 1600] loss: 0.01937485932794516
[Epoch 19, Batch 1700] loss: 0.02238548708439339
[Epoch 19, Batch 1800] loss: 0.027097960906066875
[Epoch 19, Batch 1900] loss: 0.017462617606361162
[Epoch 19, Batch 2000] loss: 0.028719221692954308
[Epoch 19, Batch 2100] loss: 0.023978334929488483
[Epoch 19, Batch 2200] loss: 0.025443369920758414
[Epoch 19, Batch 2300] loss: 0.024883506885307726
[Epoch 19, Batch 2400] loss: 0.016587673419999192
[Epoch 19, Batch 2500] loss: 0.018779318034721656
[Epoch 19, Batch 2600] loss: 0.014319560433796142
[Epoch 19, Batch 2700] loss: 0.01543136102198332
[Epoch 19, Batch 2800] loss: 0.031378690924611874
[Epoch 19, Batch 2900] loss: 0.030357309493047067
[Epoch 19, Batch 3000] loss: 0.034136567834866585
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0407
Validation Accuracy: 0.9883
Overfitting: 0.0407
Best model saved at epoch 19 with validation loss: 0.0407
[Epoch 20, Batch 100] loss: 0.016762340638670138
[Epoch 20, Batch 200] loss: 0.009366661862077307
[Epoch 20, Batch 300] loss: 0.027401475666993066
[Epoch 20, Batch 400] loss: 0.011627056902143522
[Epoch 20, Batch 500] loss: 0.019812697706620384
[Epoch 20, Batch 600] loss: 0.016003899477836966
[Epoch 20, Batch 700] loss: 0.015904341231362196
[Epoch 20, Batch 800] loss: 0.02263676812115591
[Epoch 20, Batch 900] loss: 0.026721260164194974
[Epoch 20, Batch 1000] loss: 0.0253690980077954
[Epoch 20, Batch 1100] loss: 0.027009443953211303
[Epoch 20, Batch 1200] loss: 0.015938183230900904
[Epoch 20, Batch 1300] loss: 0.02495304484378721
[Epoch 20, Batch 1400] loss: 0.032907861126222994
[Epoch 20, Batch 1500] loss: 0.01651816546982445
[Epoch 20, Batch 1600] loss: 0.0174327367200749
[Epoch 20, Batch 1700] loss: 0.026467860341781488
[Epoch 20, Batch 1800] loss: 0.01892291829295573
[Epoch 20, Batch 1900] loss: 0.023350204906346334
[Epoch 20, Batch 2000] loss: 0.022231350671499967
[Epoch 20, Batch 2100] loss: 0.02703788533959596
[Epoch 20, Batch 2200] loss: 0.023348955631881836
[Epoch 20, Batch 2300] loss: 0.021509843679814365
[Epoch 20, Batch 2400] loss: 0.022941014421958242
[Epoch 20, Batch 2500] loss: 0.01729886136141431
[Epoch 20, Batch 2600] loss: 0.01802684472702822
[Epoch 20, Batch 2700] loss: 0.01661403842685104
[Epoch 20, Batch 2800] loss: 0.01058411463000084
[Epoch 20, Batch 2900] loss: 0.028298407510010292
[Epoch 20, Batch 3000] loss: 0.021250938839002628
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9871
Overfitting: 0.0447
[Epoch 21, Batch 100] loss: 0.012604154914588434
[Epoch 21, Batch 200] loss: 0.027720258058980107
[Epoch 21, Batch 300] loss: 0.016192156531687943
[Epoch 21, Batch 400] loss: 0.01665436599683744
[Epoch 21, Batch 500] loss: 0.01561601125918969
[Epoch 21, Batch 600] loss: 0.013848289924571872
[Epoch 21, Batch 700] loss: 0.018884966843561415
[Epoch 21, Batch 800] loss: 0.020939799888637936
[Epoch 21, Batch 900] loss: 0.03240677845446044
[Epoch 21, Batch 1000] loss: 0.018617321800120407
[Epoch 21, Batch 1100] loss: 0.014061720015743049
[Epoch 21, Batch 1200] loss: 0.019608855605183634
[Epoch 21, Batch 1300] loss: 0.01812456091574859
[Epoch 21, Batch 1400] loss: 0.03386727605524356
[Epoch 21, Batch 1500] loss: 0.024196314789151074
[Epoch 21, Batch 1600] loss: 0.013175838934294005
[Epoch 21, Batch 1700] loss: 0.015769131603010463
[Epoch 21, Batch 1800] loss: 0.020215685154234962
[Epoch 21, Batch 1900] loss: 0.012879106530672289
[Epoch 21, Batch 2000] loss: 0.013898207646489026
[Epoch 21, Batch 2100] loss: 0.01719630583309481
[Epoch 21, Batch 2200] loss: 0.022679704742204196
[Epoch 21, Batch 2300] loss: 0.01908271040971158
[Epoch 21, Batch 2400] loss: 0.01690231673481321
[Epoch 21, Batch 2500] loss: 0.02756983162880715
[Epoch 21, Batch 2600] loss: 0.020125154363813635
[Epoch 21, Batch 2700] loss: 0.02427090192490141
[Epoch 21, Batch 2800] loss: 0.01670157631209804
[Epoch 21, Batch 2900] loss: 0.018764571682859242
[Epoch 21, Batch 3000] loss: 0.02902621384451777
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0400
Validation Accuracy: 0.9880
Overfitting: 0.0400
Best model saved at epoch 21 with validation loss: 0.0400
[Epoch 22, Batch 100] loss: 0.01508974205939012
[Epoch 22, Batch 200] loss: 0.007821249302141951
[Epoch 22, Batch 300] loss: 0.01949188265391058
[Epoch 22, Batch 400] loss: 0.009241032018326222
[Epoch 22, Batch 500] loss: 0.017911019585808388
[Epoch 22, Batch 600] loss: 0.01779165520938477
[Epoch 22, Batch 700] loss: 0.022212466986256913
[Epoch 22, Batch 800] loss: 0.021646499719281564
[Epoch 22, Batch 900] loss: 0.02769440682575805
[Epoch 22, Batch 1000] loss: 0.0136960306349647
[Epoch 22, Batch 1100] loss: 0.013355209034489234
[Epoch 22, Batch 1200] loss: 0.02113093706466316
[Epoch 22, Batch 1300] loss: 0.023148769795225236
[Epoch 22, Batch 1400] loss: 0.025690678169048624
[Epoch 22, Batch 1500] loss: 0.013461968805022479
[Epoch 22, Batch 1600] loss: 0.01191946067923709
[Epoch 22, Batch 1700] loss: 0.015805553735863214
[Epoch 22, Batch 1800] loss: 0.014436839263998991
[Epoch 22, Batch 1900] loss: 0.023191660755910563
[Epoch 22, Batch 2000] loss: 0.022794424018647987
[Epoch 22, Batch 2100] loss: 0.014089963008791529
[Epoch 22, Batch 2200] loss: 0.023428711925589596
[Epoch 22, Batch 2300] loss: 0.024096912002423778
[Epoch 22, Batch 2400] loss: 0.020062422730406978
[Epoch 22, Batch 2500] loss: 0.015006035927472112
[Epoch 22, Batch 2600] loss: 0.02180587575530808
[Epoch 22, Batch 2700] loss: 0.01811512379143096
[Epoch 22, Batch 2800] loss: 0.022002143356039595
[Epoch 22, Batch 2900] loss: 0.022501098228240153
[Epoch 22, Batch 3000] loss: 0.025721548717883708
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0425
Validation Accuracy: 0.9872
Overfitting: 0.0425
[Epoch 23, Batch 100] loss: 0.017743640531625714
[Epoch 23, Batch 200] loss: 0.009962361556099496
[Epoch 23, Batch 300] loss: 0.011029354316451644
[Epoch 23, Batch 400] loss: 0.02501750956835167
[Epoch 23, Batch 500] loss: 0.02209068844334979
[Epoch 23, Batch 600] loss: 0.01063449429726461
[Epoch 23, Batch 700] loss: 0.02016648831333441
[Epoch 23, Batch 800] loss: 0.01267944709058611
[Epoch 23, Batch 900] loss: 0.007811855136587838
[Epoch 23, Batch 1000] loss: 0.015368244343680998
[Epoch 23, Batch 1100] loss: 0.018196099118995335
[Epoch 23, Batch 1200] loss: 0.014281280491286453
[Epoch 23, Batch 1300] loss: 0.013238994935964001
[Epoch 23, Batch 1400] loss: 0.02277388602560677
[Epoch 23, Batch 1500] loss: 0.020041771860451262
[Epoch 23, Batch 1600] loss: 0.011753631487990787
[Epoch 23, Batch 1700] loss: 0.02234724241105141
[Epoch 23, Batch 1800] loss: 0.013455450714172913
[Epoch 23, Batch 1900] loss: 0.018333611043490235
[Epoch 23, Batch 2000] loss: 0.02866259327381158
[Epoch 23, Batch 2100] loss: 0.025721815041470107
[Epoch 23, Batch 2200] loss: 0.01496110231277271
[Epoch 23, Batch 2300] loss: 0.010515708197890489
[Epoch 23, Batch 2400] loss: 0.022642920378639245
[Epoch 23, Batch 2500] loss: 0.015296506788872647
[Epoch 23, Batch 2600] loss: 0.012924163637571838
[Epoch 23, Batch 2700] loss: 0.010592821799382363
[Epoch 23, Batch 2800] loss: 0.01755149192457793
[Epoch 23, Batch 2900] loss: 0.01614089824797702
[Epoch 23, Batch 3000] loss: 0.03090957111955504
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0425
Validation Accuracy: 0.9884
Overfitting: 0.0425
[Epoch 24, Batch 100] loss: 0.016461565026038443
[Epoch 24, Batch 200] loss: 0.012281689605515567
[Epoch 24, Batch 300] loss: 0.017709808648105535
[Epoch 24, Batch 400] loss: 0.007246682802469877
[Epoch 24, Batch 500] loss: 0.013998052284077857
[Epoch 24, Batch 600] loss: 0.016119269977170916
[Epoch 24, Batch 700] loss: 0.011721268182582208
[Epoch 24, Batch 800] loss: 0.016487823890965956
[Epoch 24, Batch 900] loss: 0.015202908297360408
[Epoch 24, Batch 1000] loss: 0.01822162045908044
[Epoch 24, Batch 1100] loss: 0.02288202911411645
[Epoch 24, Batch 1200] loss: 0.020754617715920177
[Epoch 24, Batch 1300] loss: 0.026798238710434817
[Epoch 24, Batch 1400] loss: 0.017917605352995452
[Epoch 24, Batch 1500] loss: 0.020343492123465694
[Epoch 24, Batch 1600] loss: 0.01917137791744608
[Epoch 24, Batch 1700] loss: 0.017995777798751077
[Epoch 24, Batch 1800] loss: 0.012241169283879572
[Epoch 24, Batch 1900] loss: 0.01773863722999522
[Epoch 24, Batch 2000] loss: 0.012151835332879272
[Epoch 24, Batch 2100] loss: 0.011842992202691676
[Epoch 24, Batch 2200] loss: 0.022059341472686355
[Epoch 24, Batch 2300] loss: 0.017634259204169212
[Epoch 24, Batch 2400] loss: 0.012966400379664265
[Epoch 24, Batch 2500] loss: 0.014196613972308115
[Epoch 24, Batch 2600] loss: 0.01618794037593034
[Epoch 24, Batch 2700] loss: 0.020663562935442314
[Epoch 24, Batch 2800] loss: 0.017704767025170442
[Epoch 24, Batch 2900] loss: 0.012055037661211828
[Epoch 24, Batch 3000] loss: 0.01720865206446433
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0397
Validation Accuracy: 0.9885
Overfitting: 0.0397
Best model saved at epoch 24 with validation loss: 0.0397
Fold 5 validation loss: 0.0397
Mean validation loss across all folds for Trial 5 is 0.0454 with trial config:  l1: 256, l2: 128, lr: 0.00032927591344236165, batch_size: 16
[I 2024-12-10 06:44:52,584] Trial 4 finished with value: 0.045411968038914834 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16}. Best is trial 4 with value: 0.045411968038914834.

Selected Hyperparameters for Trial 6:
  l1: 128, l2: 64, lr: 0.0015696396388661157, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.301110827922821
[Epoch 1, Batch 200] loss: 2.278772120475769
[Epoch 1, Batch 300] loss: 2.1804357314109803
[Epoch 1, Batch 400] loss: 1.3469696885347366
[Epoch 1, Batch 500] loss: 0.6898197060823441
[Epoch 1, Batch 600] loss: 0.43839978650212286
[Epoch 1, Batch 700] loss: 0.4617343217134476
[Epoch 1, Batch 800] loss: 0.35948322124779225
[Epoch 1, Batch 900] loss: 0.29732633199542763
[Epoch 1, Batch 1000] loss: 0.22365928936749696
[Epoch 1, Batch 1100] loss: 0.22912798216566443
[Epoch 1, Batch 1200] loss: 0.22391122195869684
[Epoch 1, Batch 1300] loss: 0.22302317716181277
[Epoch 1, Batch 1400] loss: 0.18652459741570054
[Epoch 1, Batch 1500] loss: 0.20600800273008646
[Epoch 1, Batch 1600] loss: 0.16617328777443618
[Epoch 1, Batch 1700] loss: 0.18554486653767527
[Epoch 1, Batch 1800] loss: 0.1528421990480274
[Epoch 1, Batch 1900] loss: 0.14146759803174064
[Epoch 1, Batch 2000] loss: 0.13514999511186032
[Epoch 1, Batch 2100] loss: 0.17132493117358535
[Epoch 1, Batch 2200] loss: 0.13550372641533615
[Epoch 1, Batch 2300] loss: 0.12912520965095609
[Epoch 1, Batch 2400] loss: 0.1257738291285932
[Epoch 1, Batch 2500] loss: 0.13847335462924093
[Epoch 1, Batch 2600] loss: 0.11239866130519659
[Epoch 1, Batch 2700] loss: 0.1447477724822238
[Epoch 1, Batch 2800] loss: 0.12219673935323953
[Epoch 1, Batch 2900] loss: 0.11245957851177081
[Epoch 1, Batch 3000] loss: 0.11121271023992449
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1063
Validation Accuracy: 0.9667
Overfitting: 0.1063
Best model saved at epoch 1 with validation loss: 0.1063
[Epoch 2, Batch 100] loss: 0.12964574301149695
[Epoch 2, Batch 200] loss: 0.10871065422543325
[Epoch 2, Batch 300] loss: 0.08515718789305537
[Epoch 2, Batch 400] loss: 0.10259160159854218
[Epoch 2, Batch 500] loss: 0.0830859535082709
[Epoch 2, Batch 600] loss: 0.10639286787598394
[Epoch 2, Batch 700] loss: 0.0931451859488152
[Epoch 2, Batch 800] loss: 0.07907192592538195
[Epoch 2, Batch 900] loss: 0.08624195138807408
[Epoch 2, Batch 1000] loss: 0.07311841553193517
[Epoch 2, Batch 1100] loss: 0.08865801699692383
[Epoch 2, Batch 1200] loss: 0.10320409335370641
[Epoch 2, Batch 1300] loss: 0.09694639188121074
[Epoch 2, Batch 1400] loss: 0.11390876573510468
[Epoch 2, Batch 1500] loss: 0.07174393066205084
[Epoch 2, Batch 1600] loss: 0.08074339766055345
[Epoch 2, Batch 1700] loss: 0.08107595504494385
[Epoch 2, Batch 1800] loss: 0.0726401156524662
[Epoch 2, Batch 1900] loss: 0.08109311103005894
[Epoch 2, Batch 2000] loss: 0.08381506893900223
[Epoch 2, Batch 2100] loss: 0.08571982663183007
[Epoch 2, Batch 2200] loss: 0.09714934105752036
[Epoch 2, Batch 2300] loss: 0.09401879663346335
[Epoch 2, Batch 2400] loss: 0.09521508239209651
[Epoch 2, Batch 2500] loss: 0.08289232690120116
[Epoch 2, Batch 2600] loss: 0.07619513811485376
[Epoch 2, Batch 2700] loss: 0.06467991935322061
[Epoch 2, Batch 2800] loss: 0.08006481663440354
[Epoch 2, Batch 2900] loss: 0.07819131387746893
[Epoch 2, Batch 3000] loss: 0.08207705730455928
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0761
Validation Accuracy: 0.9766
Overfitting: 0.0761
Best model saved at epoch 2 with validation loss: 0.0761
[Epoch 3, Batch 100] loss: 0.05154524823010433
[Epoch 3, Batch 200] loss: 0.057794833408552224
[Epoch 3, Batch 300] loss: 0.06455128743487876
[Epoch 3, Batch 400] loss: 0.07504389423527755
[Epoch 3, Batch 500] loss: 0.0664760116522666
[Epoch 3, Batch 600] loss: 0.06909688864136115
[Epoch 3, Batch 700] loss: 0.05686976260825759
[Epoch 3, Batch 800] loss: 0.06419061021413654
[Epoch 3, Batch 900] loss: 0.08775442827201914
[Epoch 3, Batch 1000] loss: 0.07149760581203736
[Epoch 3, Batch 1100] loss: 0.0562081131990999
[Epoch 3, Batch 1200] loss: 0.043419371288036926
[Epoch 3, Batch 1300] loss: 0.07489685859181919
[Epoch 3, Batch 1400] loss: 0.05957083973713452
[Epoch 3, Batch 1500] loss: 0.07147306940518319
[Epoch 3, Batch 1600] loss: 0.055095381962601095
[Epoch 3, Batch 1700] loss: 0.08057036469399463
[Epoch 3, Batch 1800] loss: 0.06884060702985152
[Epoch 3, Batch 1900] loss: 0.06402602858142928
[Epoch 3, Batch 2000] loss: 0.054360046805231835
[Epoch 3, Batch 2100] loss: 0.04612550104735419
[Epoch 3, Batch 2200] loss: 0.054768546113045886
[Epoch 3, Batch 2300] loss: 0.061780768478056414
[Epoch 3, Batch 2400] loss: 0.0693659743689932
[Epoch 3, Batch 2500] loss: 0.047270994764985516
[Epoch 3, Batch 2600] loss: 0.04595583823451307
[Epoch 3, Batch 2700] loss: 0.06661231353326003
[Epoch 3, Batch 2800] loss: 0.07291261657053838
[Epoch 3, Batch 2900] loss: 0.04274302545643877
[Epoch 3, Batch 3000] loss: 0.03940439520258224
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0598
Validation Accuracy: 0.9809
Overfitting: 0.0598
Best model saved at epoch 3 with validation loss: 0.0598
[Epoch 4, Batch 100] loss: 0.06126659113928326
[Epoch 4, Batch 200] loss: 0.03860595305333845
[Epoch 4, Batch 300] loss: 0.05881120162957813
[Epoch 4, Batch 400] loss: 0.051390050023037474
[Epoch 4, Batch 500] loss: 0.04367330129898619
[Epoch 4, Batch 600] loss: 0.04966915768032777
[Epoch 4, Batch 700] loss: 0.059428679871489296
[Epoch 4, Batch 800] loss: 0.04620719003549311
[Epoch 4, Batch 900] loss: 0.03878135563863907
[Epoch 4, Batch 1000] loss: 0.04559675484779291
[Epoch 4, Batch 1100] loss: 0.04648253848965396
[Epoch 4, Batch 1200] loss: 0.056080894618935416
[Epoch 4, Batch 1300] loss: 0.06290750267420663
[Epoch 4, Batch 1400] loss: 0.038742413547297475
[Epoch 4, Batch 1500] loss: 0.04845439084252576
[Epoch 4, Batch 1600] loss: 0.05196982112160185
[Epoch 4, Batch 1700] loss: 0.04325482360465685
[Epoch 4, Batch 1800] loss: 0.04517508821154479
[Epoch 4, Batch 1900] loss: 0.05516189414309338
[Epoch 4, Batch 2000] loss: 0.029085933815513273
[Epoch 4, Batch 2100] loss: 0.03185587940941332
[Epoch 4, Batch 2200] loss: 0.03753904989112925
[Epoch 4, Batch 2300] loss: 0.051940541497533556
[Epoch 4, Batch 2400] loss: 0.0555062031376292
[Epoch 4, Batch 2500] loss: 0.047312689473328645
[Epoch 4, Batch 2600] loss: 0.06814401751878904
[Epoch 4, Batch 2700] loss: 0.03602045499021187
[Epoch 4, Batch 2800] loss: 0.0485804678327986
[Epoch 4, Batch 2900] loss: 0.04814685934528825
[Epoch 4, Batch 3000] loss: 0.04318842154563754
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9841
Overfitting: 0.0502
Best model saved at epoch 4 with validation loss: 0.0502
[Epoch 5, Batch 100] loss: 0.03694728677073726
[Epoch 5, Batch 200] loss: 0.027837051987735322
[Epoch 5, Batch 300] loss: 0.04316941049422894
[Epoch 5, Batch 400] loss: 0.03196072005564929
[Epoch 5, Batch 500] loss: 0.03434747291918029
[Epoch 5, Batch 600] loss: 0.0583927158881852
[Epoch 5, Batch 700] loss: 0.03326812656901893
[Epoch 5, Batch 800] loss: 0.03206259746104479
[Epoch 5, Batch 900] loss: 0.049600100264215144
[Epoch 5, Batch 1000] loss: 0.02802481715887552
[Epoch 5, Batch 1100] loss: 0.04864607053226791
[Epoch 5, Batch 1200] loss: 0.032218539913337736
[Epoch 5, Batch 1300] loss: 0.042019723968987815
[Epoch 5, Batch 1400] loss: 0.0377223324633087
[Epoch 5, Batch 1500] loss: 0.041602934403781544
[Epoch 5, Batch 1600] loss: 0.04940374830082874
[Epoch 5, Batch 1700] loss: 0.02514244279329432
[Epoch 5, Batch 1800] loss: 0.03183126813812123
[Epoch 5, Batch 1900] loss: 0.04422448481840547
[Epoch 5, Batch 2000] loss: 0.07473882341866556
[Epoch 5, Batch 2100] loss: 0.03368128752335906
[Epoch 5, Batch 2200] loss: 0.041472943015978675
[Epoch 5, Batch 2300] loss: 0.042701233073603365
[Epoch 5, Batch 2400] loss: 0.033319395142316355
[Epoch 5, Batch 2500] loss: 0.037195787118107546
[Epoch 5, Batch 2600] loss: 0.04585063789781998
[Epoch 5, Batch 2700] loss: 0.03190484947830555
[Epoch 5, Batch 2800] loss: 0.05568521912449796
[Epoch 5, Batch 2900] loss: 0.03522236866243475
[Epoch 5, Batch 3000] loss: 0.037543604202655845
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9852
Overfitting: 0.0464
Best model saved at epoch 5 with validation loss: 0.0464
[Epoch 6, Batch 100] loss: 0.03351287214674812
[Epoch 6, Batch 200] loss: 0.023956767009294708
[Epoch 6, Batch 300] loss: 0.029168901111843296
[Epoch 6, Batch 400] loss: 0.023306617216658197
[Epoch 6, Batch 500] loss: 0.03660934265462856
[Epoch 6, Batch 600] loss: 0.026378091797087107
[Epoch 6, Batch 700] loss: 0.022050259871029994
[Epoch 6, Batch 800] loss: 0.03343498487156467
[Epoch 6, Batch 900] loss: 0.04678363452636404
[Epoch 6, Batch 1000] loss: 0.03786247391035431
[Epoch 6, Batch 1100] loss: 0.03571840254793642
[Epoch 6, Batch 1200] loss: 0.035121779399632944
[Epoch 6, Batch 1300] loss: 0.024707198432515724
[Epoch 6, Batch 1400] loss: 0.03917547791701509
[Epoch 6, Batch 1500] loss: 0.03846511546067632
[Epoch 6, Batch 1600] loss: 0.028340441403561272
[Epoch 6, Batch 1700] loss: 0.03632984853087692
[Epoch 6, Batch 1800] loss: 0.04007180659878941
[Epoch 6, Batch 1900] loss: 0.023079943103111872
[Epoch 6, Batch 2000] loss: 0.03306993914004124
[Epoch 6, Batch 2100] loss: 0.028730306453508093
[Epoch 6, Batch 2200] loss: 0.03423566267592833
[Epoch 6, Batch 2300] loss: 0.035220735710609005
[Epoch 6, Batch 2400] loss: 0.024625889067465323
[Epoch 6, Batch 2500] loss: 0.02445183188896408
[Epoch 6, Batch 2600] loss: 0.040227871539173066
[Epoch 6, Batch 2700] loss: 0.038447401423036355
[Epoch 6, Batch 2800] loss: 0.028716096159478184
[Epoch 6, Batch 2900] loss: 0.04154994849814102
[Epoch 6, Batch 3000] loss: 0.03787957106873364
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0614
Validation Accuracy: 0.9804
Overfitting: 0.0614
[Epoch 7, Batch 100] loss: 0.02241682049465453
[Epoch 7, Batch 200] loss: 0.021343086793640397
[Epoch 7, Batch 300] loss: 0.025506795341752878
[Epoch 7, Batch 400] loss: 0.03064932216791931
[Epoch 7, Batch 500] loss: 0.021345472762041028
[Epoch 7, Batch 600] loss: 0.027572928228873934
[Epoch 7, Batch 700] loss: 0.03563253593300033
[Epoch 7, Batch 800] loss: 0.017633194842783268
[Epoch 7, Batch 900] loss: 0.01795906517209005
[Epoch 7, Batch 1000] loss: 0.031287759284168715
[Epoch 7, Batch 1100] loss: 0.019912926361830615
[Epoch 7, Batch 1200] loss: 0.03895984320144635
[Epoch 7, Batch 1300] loss: 0.030180845360337116
[Epoch 7, Batch 1400] loss: 0.03160948391756392
[Epoch 7, Batch 1500] loss: 0.03254916374113236
[Epoch 7, Batch 1600] loss: 0.03478959179559751
[Epoch 7, Batch 1700] loss: 0.030357601574687577
[Epoch 7, Batch 1800] loss: 0.035524046513892245
[Epoch 7, Batch 1900] loss: 0.03275830317274085
[Epoch 7, Batch 2000] loss: 0.02806414103790303
[Epoch 7, Batch 2100] loss: 0.029280518535597367
[Epoch 7, Batch 2200] loss: 0.038828770321852064
[Epoch 7, Batch 2300] loss: 0.029419759293959943
[Epoch 7, Batch 2400] loss: 0.022029099241590303
[Epoch 7, Batch 2500] loss: 0.02598252507064899
[Epoch 7, Batch 2600] loss: 0.029082793061570557
[Epoch 7, Batch 2700] loss: 0.03046225104815676
[Epoch 7, Batch 2800] loss: 0.030924263403067018
[Epoch 7, Batch 2900] loss: 0.0345656593138483
[Epoch 7, Batch 3000] loss: 0.038277650072996036
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0433
Validation Accuracy: 0.9861
Overfitting: 0.0433
Best model saved at epoch 7 with validation loss: 0.0433
[Epoch 8, Batch 100] loss: 0.02621998794224055
[Epoch 8, Batch 200] loss: 0.022495718819336617
[Epoch 8, Batch 300] loss: 0.01182899202533008
[Epoch 8, Batch 400] loss: 0.018604406334015947
[Epoch 8, Batch 500] loss: 0.022153156170497824
[Epoch 8, Batch 600] loss: 0.019447982713645614
[Epoch 8, Batch 700] loss: 0.0253977171916722
[Epoch 8, Batch 800] loss: 0.034480722129010245
[Epoch 8, Batch 900] loss: 0.016641301587205816
[Epoch 8, Batch 1000] loss: 0.018645837795193073
[Epoch 8, Batch 1100] loss: 0.029490964569195057
[Epoch 8, Batch 1200] loss: 0.024562830715585734
[Epoch 8, Batch 1300] loss: 0.02732058732985024
[Epoch 8, Batch 1400] loss: 0.02704177768300724
[Epoch 8, Batch 1500] loss: 0.040272487229958645
[Epoch 8, Batch 1600] loss: 0.025404230755448225
[Epoch 8, Batch 1700] loss: 0.037957473304195445
[Epoch 8, Batch 1800] loss: 0.024456931500208157
[Epoch 8, Batch 1900] loss: 0.0297671813092893
[Epoch 8, Batch 2000] loss: 0.02133978533795016
[Epoch 8, Batch 2100] loss: 0.022368628536423785
[Epoch 8, Batch 2200] loss: 0.016368906823590806
[Epoch 8, Batch 2300] loss: 0.015934185211153817
[Epoch 8, Batch 2400] loss: 0.012999340899705203
[Epoch 8, Batch 2500] loss: 0.027870686082424073
[Epoch 8, Batch 2600] loss: 0.029106903567871996
[Epoch 8, Batch 2700] loss: 0.030322248401062096
[Epoch 8, Batch 2800] loss: 0.032378076234167566
[Epoch 8, Batch 2900] loss: 0.013779987561356392
[Epoch 8, Batch 3000] loss: 0.030550273053777346
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9852
Overfitting: 0.0484
[Epoch 9, Batch 100] loss: 0.017114248220768787
[Epoch 9, Batch 200] loss: 0.016851480606928818
[Epoch 9, Batch 300] loss: 0.017076870234595844
[Epoch 9, Batch 400] loss: 0.017751540856224893
[Epoch 9, Batch 500] loss: 0.021369273530981444
[Epoch 9, Batch 600] loss: 0.019653079542404157
[Epoch 9, Batch 700] loss: 0.02087608459707553
[Epoch 9, Batch 800] loss: 0.02611431232675386
[Epoch 9, Batch 900] loss: 0.011254057321821165
[Epoch 9, Batch 1000] loss: 0.016242738312812435
[Epoch 9, Batch 1100] loss: 0.014681083269692863
[Epoch 9, Batch 1200] loss: 0.0223700269191977
[Epoch 9, Batch 1300] loss: 0.024473124108608316
[Epoch 9, Batch 1400] loss: 0.016144229379751778
[Epoch 9, Batch 1500] loss: 0.022230684086316614
[Epoch 9, Batch 1600] loss: 0.029562094026441627
[Epoch 9, Batch 1700] loss: 0.03588585772697115
[Epoch 9, Batch 1800] loss: 0.01843342558138829
[Epoch 9, Batch 1900] loss: 0.0226392602821943
[Epoch 9, Batch 2000] loss: 0.02406777505289938
[Epoch 9, Batch 2100] loss: 0.010973902954183358
[Epoch 9, Batch 2200] loss: 0.018889629374498326
[Epoch 9, Batch 2300] loss: 0.019963757562054527
[Epoch 9, Batch 2400] loss: 0.02366217622147815
[Epoch 9, Batch 2500] loss: 0.035935830572452684
[Epoch 9, Batch 2600] loss: 0.016673898860171902
[Epoch 9, Batch 2700] loss: 0.022932312009997985
[Epoch 9, Batch 2800] loss: 0.019560101799143012
[Epoch 9, Batch 2900] loss: 0.018213840962575886
[Epoch 9, Batch 3000] loss: 0.029392659878267294
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0419
Validation Accuracy: 0.9877
Overfitting: 0.0419
Best model saved at epoch 9 with validation loss: 0.0419
[Epoch 10, Batch 100] loss: 0.011681087670276612
[Epoch 10, Batch 200] loss: 0.01510933818488411
[Epoch 10, Batch 300] loss: 0.0135761278190148
[Epoch 10, Batch 400] loss: 0.014541980759840954
[Epoch 10, Batch 500] loss: 0.014628516327775287
[Epoch 10, Batch 600] loss: 0.01236010592265302
[Epoch 10, Batch 700] loss: 0.027054651982507495
[Epoch 10, Batch 800] loss: 0.009314014166420748
[Epoch 10, Batch 900] loss: 0.024900921417947756
[Epoch 10, Batch 1000] loss: 0.02699963103227674
[Epoch 10, Batch 1100] loss: 0.01933408004465491
[Epoch 10, Batch 1200] loss: 0.018885423844521937
[Epoch 10, Batch 1300] loss: 0.018440046654436628
[Epoch 10, Batch 1400] loss: 0.011983725124109697
[Epoch 10, Batch 1500] loss: 0.017668608499461697
[Epoch 10, Batch 1600] loss: 0.01612509518886327
[Epoch 10, Batch 1700] loss: 0.03140322249721066
[Epoch 10, Batch 1800] loss: 0.01713969592099602
[Epoch 10, Batch 1900] loss: 0.008445265468581056
[Epoch 10, Batch 2000] loss: 0.014026791121004863
[Epoch 10, Batch 2100] loss: 0.01000158048762387
[Epoch 10, Batch 2200] loss: 0.01743100842684953
[Epoch 10, Batch 2300] loss: 0.01640437090844898
[Epoch 10, Batch 2400] loss: 0.015230259125910379
[Epoch 10, Batch 2500] loss: 0.015664782635458323
[Epoch 10, Batch 2600] loss: 0.02795562287019493
[Epoch 10, Batch 2700] loss: 0.025403933994493855
[Epoch 10, Batch 2800] loss: 0.03662146250293517
[Epoch 10, Batch 2900] loss: 0.018320847817740286
[Epoch 10, Batch 3000] loss: 0.028993663956862294
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0521
Validation Accuracy: 0.9861
Overfitting: 0.0521
[Epoch 11, Batch 100] loss: 0.021977241933077495
[Epoch 11, Batch 200] loss: 0.010128939957839976
[Epoch 11, Batch 300] loss: 0.013797456220436289
[Epoch 11, Batch 400] loss: 0.009775493585239018
[Epoch 11, Batch 500] loss: 0.007322955962044944
[Epoch 11, Batch 600] loss: 0.021899370311339227
[Epoch 11, Batch 700] loss: 0.010552757139548704
[Epoch 11, Batch 800] loss: 0.014080393583753903
[Epoch 11, Batch 900] loss: 0.014710801610377758
[Epoch 11, Batch 1000] loss: 0.009504048209910252
[Epoch 11, Batch 1100] loss: 0.007747237541325376
[Epoch 11, Batch 1200] loss: 0.027964685530114365
[Epoch 11, Batch 1300] loss: 0.023600283033456435
[Epoch 11, Batch 1400] loss: 0.018068526636516254
[Epoch 11, Batch 1500] loss: 0.016873934844661563
[Epoch 11, Batch 1600] loss: 0.010812835855213053
[Epoch 11, Batch 1700] loss: 0.00835260513943922
[Epoch 11, Batch 1800] loss: 0.01986860185429805
[Epoch 11, Batch 1900] loss: 0.01782328520021224
[Epoch 11, Batch 2000] loss: 0.020834091025162708
[Epoch 11, Batch 2100] loss: 0.01551475224961905
[Epoch 11, Batch 2200] loss: 0.015112804915456763
[Epoch 11, Batch 2300] loss: 0.013661397592968569
[Epoch 11, Batch 2400] loss: 0.01653047085972503
[Epoch 11, Batch 2500] loss: 0.013545542505817139
[Epoch 11, Batch 2600] loss: 0.03138311593981598
[Epoch 11, Batch 2700] loss: 0.012740154523808087
[Epoch 11, Batch 2800] loss: 0.018396417020194348
[Epoch 11, Batch 2900] loss: 0.012380250559604065
[Epoch 11, Batch 3000] loss: 0.024695373860104154
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0693
Validation Accuracy: 0.9819
Overfitting: 0.0693
[Epoch 12, Batch 100] loss: 0.023762290906261113
[Epoch 12, Batch 200] loss: 0.014829255617696617
[Epoch 12, Batch 300] loss: 0.012534595576744323
[Epoch 12, Batch 400] loss: 0.012240435478947802
[Epoch 12, Batch 500] loss: 0.006057178342309726
[Epoch 12, Batch 600] loss: 0.007727388193097795
[Epoch 12, Batch 700] loss: 0.014343973436150464
[Epoch 12, Batch 800] loss: 0.015971953501239113
[Epoch 12, Batch 900] loss: 0.01350909345553191
[Epoch 12, Batch 1000] loss: 0.01576032705886746
[Epoch 12, Batch 1100] loss: 0.013531828607337957
[Epoch 12, Batch 1200] loss: 0.0169880345245474
[Epoch 12, Batch 1300] loss: 0.016317723187348747
[Epoch 12, Batch 1400] loss: 0.010350014394953177
[Epoch 12, Batch 1500] loss: 0.009580653769339732
[Epoch 12, Batch 1600] loss: 0.013114998124715385
[Epoch 12, Batch 1700] loss: 0.016957254176677452
[Epoch 12, Batch 1800] loss: 0.00991656882029929
[Epoch 12, Batch 1900] loss: 0.011379204318609481
[Epoch 12, Batch 2000] loss: 0.018714317377639417
[Epoch 12, Batch 2100] loss: 0.014523317710691118
[Epoch 12, Batch 2200] loss: 0.006653628495087105
[Epoch 12, Batch 2300] loss: 0.028224098876826247
[Epoch 12, Batch 2400] loss: 0.010906282879677747
[Epoch 12, Batch 2500] loss: 0.024776227716429275
[Epoch 12, Batch 2600] loss: 0.01016311094277171
[Epoch 12, Batch 2700] loss: 0.026903214702733748
[Epoch 12, Batch 2800] loss: 0.006550370498953271
[Epoch 12, Batch 2900] loss: 0.012450377811028375
[Epoch 12, Batch 3000] loss: 0.015789457328482966
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0521
Validation Accuracy: 0.9857
Overfitting: 0.0521
[Epoch 13, Batch 100] loss: 0.023540880986811317
[Epoch 13, Batch 200] loss: 0.01283251217253337
[Epoch 13, Batch 300] loss: 0.018091464622552848
[Epoch 13, Batch 400] loss: 0.007100901186718147
[Epoch 13, Batch 500] loss: 0.015211626255504597
[Epoch 13, Batch 600] loss: 0.014217117697417053
[Epoch 13, Batch 700] loss: 0.009643999262898433
[Epoch 13, Batch 800] loss: 0.009332909824245235
[Epoch 13, Batch 900] loss: 0.009790135234768514
[Epoch 13, Batch 1000] loss: 0.007784826521665309
[Epoch 13, Batch 1100] loss: 0.009505591832376013
[Epoch 13, Batch 1200] loss: 0.02280077621916462
[Epoch 13, Batch 1300] loss: 0.00945791922697481
[Epoch 13, Batch 1400] loss: 0.007156665748170781
[Epoch 13, Batch 1500] loss: 0.011349538723402474
[Epoch 13, Batch 1600] loss: 0.025255332005415312
[Epoch 13, Batch 1700] loss: 0.019134322350842014
[Epoch 13, Batch 1800] loss: 0.008174573593073546
[Epoch 13, Batch 1900] loss: 0.008359577963701667
[Epoch 13, Batch 2000] loss: 0.013593302508685384
[Epoch 13, Batch 2100] loss: 0.0056667971858155395
[Epoch 13, Batch 2200] loss: 0.014324405675162098
[Epoch 13, Batch 2300] loss: 0.015730584759782573
[Epoch 13, Batch 2400] loss: 0.014329059489459723
[Epoch 13, Batch 2500] loss: 0.006426275221206197
[Epoch 13, Batch 2600] loss: 0.01691270647088345
[Epoch 13, Batch 2700] loss: 0.020200501365811762
[Epoch 13, Batch 2800] loss: 0.0120504081542083
[Epoch 13, Batch 2900] loss: 0.011687475462615567
[Epoch 13, Batch 3000] loss: 0.0073874303071102074
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9875
Overfitting: 0.0513
[Epoch 14, Batch 100] loss: 0.009688787139159558
[Epoch 14, Batch 200] loss: 0.003643382947440159
[Epoch 14, Batch 300] loss: 0.00254872805241007
[Epoch 14, Batch 400] loss: 0.01381711226955872
[Epoch 14, Batch 500] loss: 0.006743340114894636
[Epoch 14, Batch 600] loss: 0.004975019596570291
[Epoch 14, Batch 700] loss: 0.011349462642671141
[Epoch 14, Batch 800] loss: 0.016634414786693696
[Epoch 14, Batch 900] loss: 0.01357370568516899
[Epoch 14, Batch 1000] loss: 0.019775955330051147
[Epoch 14, Batch 1100] loss: 0.007004792637565061
[Epoch 14, Batch 1200] loss: 0.008794238524674257
[Epoch 14, Batch 1300] loss: 0.0048708304825436245
[Epoch 14, Batch 1400] loss: 0.00733094611650813
[Epoch 14, Batch 1500] loss: 0.013139839427653897
[Epoch 14, Batch 1600] loss: 0.007829178695477595
[Epoch 14, Batch 1700] loss: 0.005852329955389451
[Epoch 14, Batch 1800] loss: 0.007857745483620419
[Epoch 14, Batch 1900] loss: 0.015451087456207801
[Epoch 14, Batch 2000] loss: 0.00836401661369564
[Epoch 14, Batch 2100] loss: 0.019496460168072646
[Epoch 14, Batch 2200] loss: 0.015388996891601892
[Epoch 14, Batch 2300] loss: 0.015085419946822186
[Epoch 14, Batch 2400] loss: 0.013546442714232398
[Epoch 14, Batch 2500] loss: 0.008941038456589468
[Epoch 14, Batch 2600] loss: 0.018656981194939134
[Epoch 14, Batch 2700] loss: 0.011826707358750355
[Epoch 14, Batch 2800] loss: 0.007243203508116949
[Epoch 14, Batch 2900] loss: 0.012433833271402364
[Epoch 14, Batch 3000] loss: 0.023644317172274897
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9862
Overfitting: 0.0514
[Epoch 15, Batch 100] loss: 0.008948876882443528
[Epoch 15, Batch 200] loss: 0.011284546145391232
[Epoch 15, Batch 300] loss: 0.015077638378852499
[Epoch 15, Batch 400] loss: 0.008254573626372804
[Epoch 15, Batch 500] loss: 0.003672675488542154
[Epoch 15, Batch 600] loss: 0.007330430524575604
[Epoch 15, Batch 700] loss: 0.006676234253718576
[Epoch 15, Batch 800] loss: 0.011882373006808394
[Epoch 15, Batch 900] loss: 0.007890203734820033
[Epoch 15, Batch 1000] loss: 0.012250766350325648
[Epoch 15, Batch 1100] loss: 0.008881896091825183
[Epoch 15, Batch 1200] loss: 0.008808117746097821
[Epoch 15, Batch 1300] loss: 0.018893445844385043
[Epoch 15, Batch 1400] loss: 0.0058346647467908495
[Epoch 15, Batch 1500] loss: 0.00356624503752073
[Epoch 15, Batch 1600] loss: 0.010421444377815305
[Epoch 15, Batch 1700] loss: 0.00655432453129606
[Epoch 15, Batch 1800] loss: 0.00942703677175473
[Epoch 15, Batch 1900] loss: 0.010966243944060351
[Epoch 15, Batch 2000] loss: 0.015346629838651324
[Epoch 15, Batch 2100] loss: 0.01610094161970892
[Epoch 15, Batch 2200] loss: 0.00892302403108488
[Epoch 15, Batch 2300] loss: 0.00967467586541261
[Epoch 15, Batch 2400] loss: 0.01771964792834524
[Epoch 15, Batch 2500] loss: 0.0194841376412478
[Epoch 15, Batch 2600] loss: 0.009516942281607044
[Epoch 15, Batch 2700] loss: 0.007875539576543815
[Epoch 15, Batch 2800] loss: 0.014176367685638524
[Epoch 15, Batch 2900] loss: 0.015620497457284728
[Epoch 15, Batch 3000] loss: 0.009837346918945968
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9857
Overfitting: 0.0534
[Epoch 16, Batch 100] loss: 0.004168372026542784
[Epoch 16, Batch 200] loss: 0.010876369992683977
[Epoch 16, Batch 300] loss: 0.01057361358399703
[Epoch 16, Batch 400] loss: 0.0053662190723215986
[Epoch 16, Batch 500] loss: 0.005740494920844981
[Epoch 16, Batch 600] loss: 0.006416213943061848
[Epoch 16, Batch 700] loss: 0.017081227891620757
[Epoch 16, Batch 800] loss: 0.010163865664480909
[Epoch 16, Batch 900] loss: 0.007919364796790092
[Epoch 16, Batch 1000] loss: 0.007243434159731805
[Epoch 16, Batch 1100] loss: 0.007930414500087864
[Epoch 16, Batch 1200] loss: 0.01022915167716519
[Epoch 16, Batch 1300] loss: 0.009839351857083898
[Epoch 16, Batch 1400] loss: 0.007675304100939684
[Epoch 16, Batch 1500] loss: 0.011679149843494087
[Epoch 16, Batch 1600] loss: 0.007792389191695293
[Epoch 16, Batch 1700] loss: 0.010209624877709302
[Epoch 16, Batch 1800] loss: 0.018854152490184788
[Epoch 16, Batch 1900] loss: 0.009004897422360046
[Epoch 16, Batch 2000] loss: 0.006675961296800779
[Epoch 16, Batch 2100] loss: 0.00661255259907648
[Epoch 16, Batch 2200] loss: 0.004493940750552383
[Epoch 16, Batch 2300] loss: 0.0031313949215143566
[Epoch 16, Batch 2400] loss: 0.01045424210973124
[Epoch 16, Batch 2500] loss: 0.00831330215609796
[Epoch 16, Batch 2600] loss: 0.02360875117882756
[Epoch 16, Batch 2700] loss: 0.013631148150968784
[Epoch 16, Batch 2800] loss: 0.0094352018241716
[Epoch 16, Batch 2900] loss: 0.007703841033167009
[Epoch 16, Batch 3000] loss: 0.008554258899175693
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9887
Overfitting: 0.0483
[Epoch 17, Batch 100] loss: 0.004965136283203719
[Epoch 17, Batch 200] loss: 0.009841537873542165
[Epoch 17, Batch 300] loss: 0.004078589251921585
[Epoch 17, Batch 400] loss: 0.005612351314211423
[Epoch 17, Batch 500] loss: 0.003513616439790894
[Epoch 17, Batch 600] loss: 0.002556409990223756
[Epoch 17, Batch 700] loss: 0.0019485673828717155
[Epoch 17, Batch 800] loss: 0.007196191275575074
[Epoch 17, Batch 900] loss: 0.003292506321714654
[Epoch 17, Batch 1000] loss: 0.003009604833429762
[Epoch 17, Batch 1100] loss: 0.011658321281261123
[Epoch 17, Batch 1200] loss: 0.007788569312269544
[Epoch 17, Batch 1300] loss: 0.007104976393025026
[Epoch 17, Batch 1400] loss: 0.008781641985192436
[Epoch 17, Batch 1500] loss: 0.007098935237378896
[Epoch 17, Batch 1600] loss: 0.016215523224058188
[Epoch 17, Batch 1700] loss: 0.004408272884777489
[Epoch 17, Batch 1800] loss: 0.00992988912189503
[Epoch 17, Batch 1900] loss: 0.005185421973746998
[Epoch 17, Batch 2000] loss: 0.010866331861195703
[Epoch 17, Batch 2100] loss: 0.015765795069669367
[Epoch 17, Batch 2200] loss: 0.011099548976565074
[Epoch 17, Batch 2300] loss: 0.00804710843369179
[Epoch 17, Batch 2400] loss: 0.0038903668800799097
[Epoch 17, Batch 2500] loss: 0.012069582368021657
[Epoch 17, Batch 2600] loss: 0.004766591217839959
[Epoch 17, Batch 2700] loss: 0.005216834532252506
[Epoch 17, Batch 2800] loss: 0.00813722736881914
[Epoch 17, Batch 2900] loss: 0.005909405094899398
[Epoch 17, Batch 3000] loss: 0.015456538726597273
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9878
Overfitting: 0.0556
[Epoch 18, Batch 100] loss: 0.005468711780008846
[Epoch 18, Batch 200] loss: 0.0057582053957793275
[Epoch 18, Batch 300] loss: 0.006608432920482982
[Epoch 18, Batch 400] loss: 0.008808167523175143
[Epoch 18, Batch 500] loss: 0.008817710466498454
[Epoch 18, Batch 600] loss: 0.00940686457781851
[Epoch 18, Batch 700] loss: 0.012487719896791987
[Epoch 18, Batch 800] loss: 0.007966032644392272
[Epoch 18, Batch 900] loss: 0.009282023835085055
[Epoch 18, Batch 1000] loss: 0.004610643511389298
[Epoch 18, Batch 1100] loss: 0.005786771524419691
[Epoch 18, Batch 1200] loss: 0.004271933141489086
[Epoch 18, Batch 1300] loss: 0.018568954154224004
[Epoch 18, Batch 1400] loss: 0.003355221014330709
[Epoch 18, Batch 1500] loss: 0.004499347442501858
[Epoch 18, Batch 1600] loss: 0.005692654714050747
[Epoch 18, Batch 1700] loss: 0.0073714105151941565
[Epoch 18, Batch 1800] loss: 0.009503451874993516
[Epoch 18, Batch 1900] loss: 0.006647043842572202
[Epoch 18, Batch 2000] loss: 0.008767878788501661
[Epoch 18, Batch 2100] loss: 0.018278736657046865
[Epoch 18, Batch 2200] loss: 0.014119342284423055
[Epoch 18, Batch 2300] loss: 0.008316171649275929
[Epoch 18, Batch 2400] loss: 0.005615047745436073
[Epoch 18, Batch 2500] loss: 0.015610144379056692
[Epoch 18, Batch 2600] loss: 0.00296648198548894
[Epoch 18, Batch 2700] loss: 0.0033413577281908146
[Epoch 18, Batch 2800] loss: 0.005846947041484327
[Epoch 18, Batch 2900] loss: 0.010050418762224638
[Epoch 18, Batch 3000] loss: 0.003135938650368644
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9877
Overfitting: 0.0531
[Epoch 19, Batch 100] loss: 0.0009357771707828988
[Epoch 19, Batch 200] loss: 0.003762768919012842
[Epoch 19, Batch 300] loss: 0.0028228696798032614
[Epoch 19, Batch 400] loss: 0.006569006584024919
[Epoch 19, Batch 500] loss: 0.007712015493297031
[Epoch 19, Batch 600] loss: 0.006081758514757212
[Epoch 19, Batch 700] loss: 0.0012805307975179404
[Epoch 19, Batch 800] loss: 0.002145757728044373
[Epoch 19, Batch 900] loss: 0.0030830008993152093
[Epoch 19, Batch 1000] loss: 0.005513206813378133
[Epoch 19, Batch 1100] loss: 0.0038829167704281533
[Epoch 19, Batch 1200] loss: 0.0031777754767242073
[Epoch 19, Batch 1300] loss: 0.0035834697856655853
[Epoch 19, Batch 1400] loss: 0.008609763723986816
[Epoch 19, Batch 1500] loss: 0.0017539500844767275
[Epoch 19, Batch 1600] loss: 0.006922634612616321
[Epoch 19, Batch 1700] loss: 0.005916322379388816
[Epoch 19, Batch 1800] loss: 0.004374812223899766
[Epoch 19, Batch 1900] loss: 0.0014690252912784275
[Epoch 19, Batch 2000] loss: 0.003814410184040753
[Epoch 19, Batch 2100] loss: 0.0010173896138147853
[Epoch 19, Batch 2200] loss: 0.005907390369969932
[Epoch 19, Batch 2300] loss: 0.009672208957652514
[Epoch 19, Batch 2400] loss: 0.005684324748060589
[Epoch 19, Batch 2500] loss: 0.0011634805859341668
[Epoch 19, Batch 2600] loss: 0.006269909764017134
[Epoch 19, Batch 2700] loss: 0.006485201461246675
[Epoch 19, Batch 2800] loss: 0.006468432464989746
[Epoch 19, Batch 2900] loss: 0.02020927784498838
[Epoch 19, Batch 3000] loss: 0.01894628567507368
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0689
Validation Accuracy: 0.9853
Overfitting: 0.0689
[Epoch 20, Batch 100] loss: 0.014128890979477546
[Epoch 20, Batch 200] loss: 0.005164786877866447
[Epoch 20, Batch 300] loss: 0.012868909431939057
[Epoch 20, Batch 400] loss: 0.017650958533076844
[Epoch 20, Batch 500] loss: 0.0045748586023393045
[Epoch 20, Batch 600] loss: 0.01082254977921707
[Epoch 20, Batch 700] loss: 0.005791522475410602
[Epoch 20, Batch 800] loss: 0.0018789477144935062
[Epoch 20, Batch 900] loss: 0.0021985732534955103
[Epoch 20, Batch 1000] loss: 0.007759489945345166
[Epoch 20, Batch 1100] loss: 0.00355603671650897
[Epoch 20, Batch 1200] loss: 0.003273126313137027
[Epoch 20, Batch 1300] loss: 0.002941734707156698
[Epoch 20, Batch 1400] loss: 0.004550234316173771
[Epoch 20, Batch 1500] loss: 0.004741290242695158
[Epoch 20, Batch 1600] loss: 0.0032510173654520715
[Epoch 20, Batch 1700] loss: 0.006238510073662127
[Epoch 20, Batch 1800] loss: 0.007867421419605858
[Epoch 20, Batch 1900] loss: 0.004645054774224775
[Epoch 20, Batch 2000] loss: 0.004315966075557185
[Epoch 20, Batch 2100] loss: 0.006385238009566478
[Epoch 20, Batch 2200] loss: 0.010330565351981135
[Epoch 20, Batch 2300] loss: 0.013422938077010187
[Epoch 20, Batch 2400] loss: 0.00816670003097272
[Epoch 20, Batch 2500] loss: 0.007045281317044214
[Epoch 20, Batch 2600] loss: 0.005694669264177037
[Epoch 20, Batch 2700] loss: 0.0010848930834190184
[Epoch 20, Batch 2800] loss: 0.012817213339990871
[Epoch 20, Batch 2900] loss: 0.008217799147372631
[Epoch 20, Batch 3000] loss: 0.0037070597097923043
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0558
Validation Accuracy: 0.9868
Overfitting: 0.0558
[Epoch 21, Batch 100] loss: 0.002939790885801017
[Epoch 21, Batch 200] loss: 0.0028694238155503628
[Epoch 21, Batch 300] loss: 0.006485181616046703
[Epoch 21, Batch 400] loss: 0.009799529197162524
[Epoch 21, Batch 500] loss: 0.01771413346366444
[Epoch 21, Batch 600] loss: 0.01099278555246542
[Epoch 21, Batch 700] loss: 0.0057923807481256515
[Epoch 21, Batch 800] loss: 0.004592742374117051
[Epoch 21, Batch 900] loss: 0.002534441536769805
[Epoch 21, Batch 1000] loss: 0.009884144247427002
[Epoch 21, Batch 1100] loss: 0.009553925215331277
[Epoch 21, Batch 1200] loss: 0.0065669226724301664
[Epoch 21, Batch 1300] loss: 0.0044295678074175275
[Epoch 21, Batch 1400] loss: 0.009662930559165091
[Epoch 21, Batch 1500] loss: 0.006048468659413402
[Epoch 21, Batch 1600] loss: 0.008589922983003363
[Epoch 21, Batch 1700] loss: 0.004932153599260119
[Epoch 21, Batch 1800] loss: 0.0017487478417976198
[Epoch 21, Batch 1900] loss: 0.003190447764183375
[Epoch 21, Batch 2000] loss: 0.004728237655860994
[Epoch 21, Batch 2100] loss: 0.0034395532297859786
[Epoch 21, Batch 2200] loss: 0.009671795414087114
[Epoch 21, Batch 2300] loss: 0.005766495603780477
[Epoch 21, Batch 2400] loss: 0.012103767155632852
[Epoch 21, Batch 2500] loss: 0.006895121506323072
[Epoch 21, Batch 2600] loss: 0.01039487711138575
[Epoch 21, Batch 2700] loss: 0.0029071066489535723
[Epoch 21, Batch 2800] loss: 0.0023355193246527507
[Epoch 21, Batch 2900] loss: 0.006555398257422098
[Epoch 21, Batch 3000] loss: 0.003228926325899124
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9895
Overfitting: 0.0516
[Epoch 22, Batch 100] loss: 0.0007544012438206949
[Epoch 22, Batch 200] loss: 0.011240102514794898
[Epoch 22, Batch 300] loss: 0.004032436523866636
[Epoch 22, Batch 400] loss: 0.004986869276241919
[Epoch 22, Batch 500] loss: 0.0023444250273729496
[Epoch 22, Batch 600] loss: 0.0028431423900261168
[Epoch 22, Batch 700] loss: 0.0016608752582644116
[Epoch 22, Batch 800] loss: 0.0008954914248127466
[Epoch 22, Batch 900] loss: 0.0016652743977698136
[Epoch 22, Batch 1000] loss: 0.004289012613626397
[Epoch 22, Batch 1100] loss: 0.003822500907408397
[Epoch 22, Batch 1200] loss: 0.0028720228968778373
[Epoch 22, Batch 1300] loss: 0.010822686247947218
[Epoch 22, Batch 1400] loss: 0.006323885674092509
[Epoch 22, Batch 1500] loss: 0.0024537582949182026
[Epoch 22, Batch 1600] loss: 0.0020952110135237945
[Epoch 22, Batch 1700] loss: 0.002827663401478162
[Epoch 22, Batch 1800] loss: 0.004620458538017829
[Epoch 22, Batch 1900] loss: 0.0023212266694100946
[Epoch 22, Batch 2000] loss: 0.0009420581239706394
[Epoch 22, Batch 2100] loss: 0.011527915737104166
[Epoch 22, Batch 2200] loss: 0.0038918845561514105
[Epoch 22, Batch 2300] loss: 0.0019978059275728554
[Epoch 22, Batch 2400] loss: 0.004607609257160377
[Epoch 22, Batch 2500] loss: 0.005136844392633257
[Epoch 22, Batch 2600] loss: 0.001826163626881776
[Epoch 22, Batch 2700] loss: 0.0020409473883047724
[Epoch 22, Batch 2800] loss: 0.011836014749389676
[Epoch 22, Batch 2900] loss: 0.0016907162934975872
[Epoch 22, Batch 3000] loss: 0.0095175986325048
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0607
Validation Accuracy: 0.9884
Overfitting: 0.0607
[Epoch 23, Batch 100] loss: 0.00461427269966661
[Epoch 23, Batch 200] loss: 0.002737018301431604
[Epoch 23, Batch 300] loss: 0.0038166765885029362
[Epoch 23, Batch 400] loss: 0.005157251523934559
[Epoch 23, Batch 500] loss: 0.00498350571160401
[Epoch 23, Batch 600] loss: 0.009629979631989869
[Epoch 23, Batch 700] loss: 0.005372901726018426
[Epoch 23, Batch 800] loss: 0.0023422070918059034
[Epoch 23, Batch 900] loss: 0.0020604018697042647
[Epoch 23, Batch 1000] loss: 0.0006308524478767819
[Epoch 23, Batch 1100] loss: 0.001960433129212156
[Epoch 23, Batch 1200] loss: 0.0026947501887909907
[Epoch 23, Batch 1300] loss: 0.010145464284102311
[Epoch 23, Batch 1400] loss: 0.005171059073343524
[Epoch 23, Batch 1500] loss: 0.008199702525670167
[Epoch 23, Batch 1600] loss: 0.004629453042329032
[Epoch 23, Batch 1700] loss: 0.0031880774962640855
[Epoch 23, Batch 1800] loss: 0.0025230514266969804
[Epoch 23, Batch 1900] loss: 0.0031581339541833842
[Epoch 23, Batch 2000] loss: 0.001770861634875498
[Epoch 23, Batch 2100] loss: 0.002061338277868785
[Epoch 23, Batch 2200] loss: 0.002803588845261089
[Epoch 23, Batch 2300] loss: 0.00548560963736831
[Epoch 23, Batch 2400] loss: 0.014936064898217473
[Epoch 23, Batch 2500] loss: 0.011838995693595105
[Epoch 23, Batch 2600] loss: 0.0034661151126718437
[Epoch 23, Batch 2700] loss: 0.0026182708100376574
[Epoch 23, Batch 2800] loss: 0.008609625055376853
[Epoch 23, Batch 2900] loss: 0.013820506111240007
[Epoch 23, Batch 3000] loss: 0.0033310633680889625
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9892
Overfitting: 0.0546
[Epoch 24, Batch 100] loss: 0.001902986287388444
[Epoch 24, Batch 200] loss: 0.0041855050813526876
[Epoch 24, Batch 300] loss: 0.004348932554870543
[Epoch 24, Batch 400] loss: 0.008105836451651385
[Epoch 24, Batch 500] loss: 0.002210496881244772
[Epoch 24, Batch 600] loss: 0.002574058534789856
[Epoch 24, Batch 700] loss: 0.0012680471352663858
[Epoch 24, Batch 800] loss: 0.0009007417131596185
[Epoch 24, Batch 900] loss: 0.00566093857693744
[Epoch 24, Batch 1000] loss: 0.0009929123789441973
[Epoch 24, Batch 1100] loss: 0.0015344476564257547
[Epoch 24, Batch 1200] loss: 0.002277990067944269
[Epoch 24, Batch 1300] loss: 0.006363839132772569
[Epoch 24, Batch 1400] loss: 0.0021782265400080904
[Epoch 24, Batch 1500] loss: 0.0010976888187875034
[Epoch 24, Batch 1600] loss: 0.0012538053864359
[Epoch 24, Batch 1700] loss: 0.0005134952761805067
[Epoch 24, Batch 1800] loss: 0.0018012906775303605
[Epoch 24, Batch 1900] loss: 0.0017971210321140064
[Epoch 24, Batch 2000] loss: 0.005009707830662364
[Epoch 24, Batch 2100] loss: 0.004647725556577882
[Epoch 24, Batch 2200] loss: 0.006111314726647663
[Epoch 24, Batch 2300] loss: 0.0065378054937386305
[Epoch 24, Batch 2400] loss: 0.001486758033743456
[Epoch 24, Batch 2500] loss: 0.0013510435822875787
[Epoch 24, Batch 2600] loss: 0.012473760007038948
[Epoch 24, Batch 2700] loss: 0.006952857664608949
[Epoch 24, Batch 2800] loss: 0.005104971015604036
[Epoch 24, Batch 2900] loss: 0.0031457313465840064
[Epoch 24, Batch 3000] loss: 0.002866112383118775
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0590
Validation Accuracy: 0.9872
Overfitting: 0.0590
Fold 1 validation loss: 0.0590
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.295763759613037
[Epoch 1, Batch 200] loss: 2.263561191558838
[Epoch 1, Batch 300] loss: 2.0199689245224
[Epoch 1, Batch 400] loss: 1.028765134215355
[Epoch 1, Batch 500] loss: 0.5853031723946333
[Epoch 1, Batch 600] loss: 0.47981160260736944
[Epoch 1, Batch 700] loss: 0.37548238717019555
[Epoch 1, Batch 800] loss: 0.36103681817650796
[Epoch 1, Batch 900] loss: 0.26906149528920653
[Epoch 1, Batch 1000] loss: 0.26587632048875093
[Epoch 1, Batch 1100] loss: 0.22467669820412994
[Epoch 1, Batch 1200] loss: 0.2054966391995549
[Epoch 1, Batch 1300] loss: 0.18953827874734996
[Epoch 1, Batch 1400] loss: 0.16888186465017496
[Epoch 1, Batch 1500] loss: 0.1610191515646875
[Epoch 1, Batch 1600] loss: 0.19239690465852619
[Epoch 1, Batch 1700] loss: 0.1428179545328021
[Epoch 1, Batch 1800] loss: 0.1900931569142267
[Epoch 1, Batch 1900] loss: 0.1715591931110248
[Epoch 1, Batch 2000] loss: 0.14509840040002017
[Epoch 1, Batch 2100] loss: 0.12539008844411
[Epoch 1, Batch 2200] loss: 0.11330899419030174
[Epoch 1, Batch 2300] loss: 0.12868381502572446
[Epoch 1, Batch 2400] loss: 0.10707927097799257
[Epoch 1, Batch 2500] loss: 0.10722440923331306
[Epoch 1, Batch 2600] loss: 0.11286414445843547
[Epoch 1, Batch 2700] loss: 0.09501328276004642
[Epoch 1, Batch 2800] loss: 0.11743475453928114
[Epoch 1, Batch 2900] loss: 0.0952634277078323
[Epoch 1, Batch 3000] loss: 0.10158089122967795
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1183
Validation Accuracy: 0.9652
Overfitting: 0.1183
Best model saved at epoch 1 with validation loss: 0.1183
[Epoch 2, Batch 100] loss: 0.11202866237377748
[Epoch 2, Batch 200] loss: 0.10578090555034578
[Epoch 2, Batch 300] loss: 0.10501172291929833
[Epoch 2, Batch 400] loss: 0.08369392988504842
[Epoch 2, Batch 500] loss: 0.09149495711084456
[Epoch 2, Batch 600] loss: 0.0842578116885852
[Epoch 2, Batch 700] loss: 0.10247566977050156
[Epoch 2, Batch 800] loss: 0.08811196006834507
[Epoch 2, Batch 900] loss: 0.07220737739931792
[Epoch 2, Batch 1000] loss: 0.07994237346894806
[Epoch 2, Batch 1100] loss: 0.08229220350214746
[Epoch 2, Batch 1200] loss: 0.11005319385556504
[Epoch 2, Batch 1300] loss: 0.08784281781525351
[Epoch 2, Batch 1400] loss: 0.08219336337177083
[Epoch 2, Batch 1500] loss: 0.07842197486665099
[Epoch 2, Batch 1600] loss: 0.07308250325033441
[Epoch 2, Batch 1700] loss: 0.06724062936729752
[Epoch 2, Batch 1800] loss: 0.07659695459122304
[Epoch 2, Batch 1900] loss: 0.05989415981515776
[Epoch 2, Batch 2000] loss: 0.06366873086197301
[Epoch 2, Batch 2100] loss: 0.07574603520100937
[Epoch 2, Batch 2200] loss: 0.07464578944491222
[Epoch 2, Batch 2300] loss: 0.05750939280493185
[Epoch 2, Batch 2400] loss: 0.06942130271985661
[Epoch 2, Batch 2500] loss: 0.04977318220830057
[Epoch 2, Batch 2600] loss: 0.06354865715664346
[Epoch 2, Batch 2700] loss: 0.0622710528637981
[Epoch 2, Batch 2800] loss: 0.06159821512352209
[Epoch 2, Batch 2900] loss: 0.07707568368408829
[Epoch 2, Batch 3000] loss: 0.08005387488461566
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0749
Validation Accuracy: 0.9766
Overfitting: 0.0749
Best model saved at epoch 2 with validation loss: 0.0749
[Epoch 3, Batch 100] loss: 0.0804223796032602
[Epoch 3, Batch 200] loss: 0.04605709835901507
[Epoch 3, Batch 300] loss: 0.07273512760584708
[Epoch 3, Batch 400] loss: 0.06735358689446003
[Epoch 3, Batch 500] loss: 0.057113818594662004
[Epoch 3, Batch 600] loss: 0.04595825533149764
[Epoch 3, Batch 700] loss: 0.05460068053624127
[Epoch 3, Batch 800] loss: 0.02825323442230001
[Epoch 3, Batch 900] loss: 0.06266410545562394
[Epoch 3, Batch 1000] loss: 0.07233007662434829
[Epoch 3, Batch 1100] loss: 0.06508709884772543
[Epoch 3, Batch 1200] loss: 0.06340653348830529
[Epoch 3, Batch 1300] loss: 0.05466168433136773
[Epoch 3, Batch 1400] loss: 0.06695126334670931
[Epoch 3, Batch 1500] loss: 0.04243888854223769
[Epoch 3, Batch 1600] loss: 0.05092310433072271
[Epoch 3, Batch 1700] loss: 0.0626340890735446
[Epoch 3, Batch 1800] loss: 0.06318636630254332
[Epoch 3, Batch 1900] loss: 0.048091454349341804
[Epoch 3, Batch 2000] loss: 0.05670692449013586
[Epoch 3, Batch 2100] loss: 0.08024339684518055
[Epoch 3, Batch 2200] loss: 0.06070676012444892
[Epoch 3, Batch 2300] loss: 0.06634586140397004
[Epoch 3, Batch 2400] loss: 0.04969022669189144
[Epoch 3, Batch 2500] loss: 0.03990141853195382
[Epoch 3, Batch 2600] loss: 0.056577046050224455
[Epoch 3, Batch 2700] loss: 0.04495589227983146
[Epoch 3, Batch 2800] loss: 0.04758576391846873
[Epoch 3, Batch 2900] loss: 0.05939602872997057
[Epoch 3, Batch 3000] loss: 0.04071411279190215
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9818
Overfitting: 0.0605
Best model saved at epoch 3 with validation loss: 0.0605
[Epoch 4, Batch 100] loss: 0.03592284253332764
[Epoch 4, Batch 200] loss: 0.035535979058622616
[Epoch 4, Batch 300] loss: 0.051514411810203456
[Epoch 4, Batch 400] loss: 0.05243490739085246
[Epoch 4, Batch 500] loss: 0.03174322018458042
[Epoch 4, Batch 600] loss: 0.036769488849386106
[Epoch 4, Batch 700] loss: 0.05297411318053492
[Epoch 4, Batch 800] loss: 0.04305464694887633
[Epoch 4, Batch 900] loss: 0.049872466841479765
[Epoch 4, Batch 1000] loss: 0.05311073372111423
[Epoch 4, Batch 1100] loss: 0.0439744576162775
[Epoch 4, Batch 1200] loss: 0.05045918080955744
[Epoch 4, Batch 1300] loss: 0.03693657006428111
[Epoch 4, Batch 1400] loss: 0.04640206239593681
[Epoch 4, Batch 1500] loss: 0.033349228623264934
[Epoch 4, Batch 1600] loss: 0.03142761616589269
[Epoch 4, Batch 1700] loss: 0.0463541997680295
[Epoch 4, Batch 1800] loss: 0.04987528119505441
[Epoch 4, Batch 1900] loss: 0.04823084122588625
[Epoch 4, Batch 2000] loss: 0.049912142677931114
[Epoch 4, Batch 2100] loss: 0.041979208959528475
[Epoch 4, Batch 2200] loss: 0.03925491799775045
[Epoch 4, Batch 2300] loss: 0.04020166624846752
[Epoch 4, Batch 2400] loss: 0.03578695126197999
[Epoch 4, Batch 2500] loss: 0.04785305913734192
[Epoch 4, Batch 2600] loss: 0.06454002148966538
[Epoch 4, Batch 2700] loss: 0.03940315512416419
[Epoch 4, Batch 2800] loss: 0.045044437085307434
[Epoch 4, Batch 2900] loss: 0.04485019546438707
[Epoch 4, Batch 3000] loss: 0.04420575612486573
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0666
Validation Accuracy: 0.9791
Overfitting: 0.0666
[Epoch 5, Batch 100] loss: 0.03923122429114301
[Epoch 5, Batch 200] loss: 0.04636428217985667
[Epoch 5, Batch 300] loss: 0.041611767995927945
[Epoch 5, Batch 400] loss: 0.025866117549448973
[Epoch 5, Batch 500] loss: 0.029020605073164916
[Epoch 5, Batch 600] loss: 0.02093384445317497
[Epoch 5, Batch 700] loss: 0.042574477632879276
[Epoch 5, Batch 800] loss: 0.02849829846020839
[Epoch 5, Batch 900] loss: 0.03662464545515832
[Epoch 5, Batch 1000] loss: 0.04110204604134196
[Epoch 5, Batch 1100] loss: 0.03958158633991843
[Epoch 5, Batch 1200] loss: 0.03450777046615258
[Epoch 5, Batch 1300] loss: 0.02761443802046415
[Epoch 5, Batch 1400] loss: 0.043591595783946106
[Epoch 5, Batch 1500] loss: 0.03112272496946389
[Epoch 5, Batch 1600] loss: 0.04772960699017858
[Epoch 5, Batch 1700] loss: 0.055768260226177514
[Epoch 5, Batch 1800] loss: 0.034686468355430405
[Epoch 5, Batch 1900] loss: 0.02601190354587743
[Epoch 5, Batch 2000] loss: 0.047625077453412816
[Epoch 5, Batch 2100] loss: 0.03155869576126861
[Epoch 5, Batch 2200] loss: 0.043133460423778164
[Epoch 5, Batch 2300] loss: 0.03403170095582027
[Epoch 5, Batch 2400] loss: 0.03553459644408576
[Epoch 5, Batch 2500] loss: 0.016609092974758825
[Epoch 5, Batch 2600] loss: 0.028476562478317646
[Epoch 5, Batch 2700] loss: 0.03881285401730565
[Epoch 5, Batch 2800] loss: 0.05087812199562904
[Epoch 5, Batch 2900] loss: 0.027439299093239243
[Epoch 5, Batch 3000] loss: 0.03167117324483115
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9812
Overfitting: 0.0619
[Epoch 6, Batch 100] loss: 0.018214878572871386
[Epoch 6, Batch 200] loss: 0.025598986422410236
[Epoch 6, Batch 300] loss: 0.028113535852753557
[Epoch 6, Batch 400] loss: 0.02454942782293074
[Epoch 6, Batch 500] loss: 0.027132555930656964
[Epoch 6, Batch 600] loss: 0.025657628347616993
[Epoch 6, Batch 700] loss: 0.036576717386633394
[Epoch 6, Batch 800] loss: 0.03395304255202063
[Epoch 6, Batch 900] loss: 0.03208744936622679
[Epoch 6, Batch 1000] loss: 0.03539350827915769
[Epoch 6, Batch 1100] loss: 0.03673435271237395
[Epoch 6, Batch 1200] loss: 0.013995933630358195
[Epoch 6, Batch 1300] loss: 0.019713370308418233
[Epoch 6, Batch 1400] loss: 0.029221948546619386
[Epoch 6, Batch 1500] loss: 0.027612529552716297
[Epoch 6, Batch 1600] loss: 0.020165895566951805
[Epoch 6, Batch 1700] loss: 0.025826117864471598
[Epoch 6, Batch 1800] loss: 0.039493170288533296
[Epoch 6, Batch 1900] loss: 0.04735132581765356
[Epoch 6, Batch 2000] loss: 0.05423943260320811
[Epoch 6, Batch 2100] loss: 0.032271759605791886
[Epoch 6, Batch 2200] loss: 0.025693480889531203
[Epoch 6, Batch 2300] loss: 0.030879105747007998
[Epoch 6, Batch 2400] loss: 0.039445611357041346
[Epoch 6, Batch 2500] loss: 0.025546572366947656
[Epoch 6, Batch 2600] loss: 0.045871205543662655
[Epoch 6, Batch 2700] loss: 0.02665026879229117
[Epoch 6, Batch 2800] loss: 0.026634726204210892
[Epoch 6, Batch 2900] loss: 0.03347629318705003
[Epoch 6, Batch 3000] loss: 0.033034192876366435
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9856
Overfitting: 0.0495
Best model saved at epoch 6 with validation loss: 0.0495
[Epoch 7, Batch 100] loss: 0.014916792042895395
[Epoch 7, Batch 200] loss: 0.03427571589983927
[Epoch 7, Batch 300] loss: 0.028869252619042527
[Epoch 7, Batch 400] loss: 0.02349808105154807
[Epoch 7, Batch 500] loss: 0.01979957281386305
[Epoch 7, Batch 600] loss: 0.019932824035322483
[Epoch 7, Batch 700] loss: 0.0308942319830021
[Epoch 7, Batch 800] loss: 0.023814370444233644
[Epoch 7, Batch 900] loss: 0.029694011392894026
[Epoch 7, Batch 1000] loss: 0.03850672522145032
[Epoch 7, Batch 1100] loss: 0.035001834708309615
[Epoch 7, Batch 1200] loss: 0.02665479872644937
[Epoch 7, Batch 1300] loss: 0.022305666872416623
[Epoch 7, Batch 1400] loss: 0.037266255855356575
[Epoch 7, Batch 1500] loss: 0.02249780171321618
[Epoch 7, Batch 1600] loss: 0.0241239369646064
[Epoch 7, Batch 1700] loss: 0.022290842445436283
[Epoch 7, Batch 1800] loss: 0.030809974622388835
[Epoch 7, Batch 1900] loss: 0.036585337728683956
[Epoch 7, Batch 2000] loss: 0.014215313944951048
[Epoch 7, Batch 2100] loss: 0.03699131551249593
[Epoch 7, Batch 2200] loss: 0.023094284410472028
[Epoch 7, Batch 2300] loss: 0.01910794499744952
[Epoch 7, Batch 2400] loss: 0.025787934689360553
[Epoch 7, Batch 2500] loss: 0.02664325893521891
[Epoch 7, Batch 2600] loss: 0.02369914155078732
[Epoch 7, Batch 2700] loss: 0.03007848672390537
[Epoch 7, Batch 2800] loss: 0.017133335846519913
[Epoch 7, Batch 2900] loss: 0.013254005833478005
[Epoch 7, Batch 3000] loss: 0.040884340870507005
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9840
Overfitting: 0.0543
[Epoch 8, Batch 100] loss: 0.03411205601732945
[Epoch 8, Batch 200] loss: 0.015212139208269946
[Epoch 8, Batch 300] loss: 0.018598348779341904
[Epoch 8, Batch 400] loss: 0.02036953724702471
[Epoch 8, Batch 500] loss: 0.014404603999355458
[Epoch 8, Batch 600] loss: 0.031857198053949105
[Epoch 8, Batch 700] loss: 0.02319442012863874
[Epoch 8, Batch 800] loss: 0.01632205534941022
[Epoch 8, Batch 900] loss: 0.016563459247918216
[Epoch 8, Batch 1000] loss: 0.011036619880146646
[Epoch 8, Batch 1100] loss: 0.023042794142093044
[Epoch 8, Batch 1200] loss: 0.0216226633682345
[Epoch 8, Batch 1300] loss: 0.018561707006347204
[Epoch 8, Batch 1400] loss: 0.011350052537213742
[Epoch 8, Batch 1500] loss: 0.016835436199980906
[Epoch 8, Batch 1600] loss: 0.009582099083327194
[Epoch 8, Batch 1700] loss: 0.008828987046035764
[Epoch 8, Batch 1800] loss: 0.034178228099854095
[Epoch 8, Batch 1900] loss: 0.029878642704252344
[Epoch 8, Batch 2000] loss: 0.011701940183174884
[Epoch 8, Batch 2100] loss: 0.026718180926582135
[Epoch 8, Batch 2200] loss: 0.02191947141844139
[Epoch 8, Batch 2300] loss: 0.016861121739930242
[Epoch 8, Batch 2400] loss: 0.014797873424540739
[Epoch 8, Batch 2500] loss: 0.01868183776832666
[Epoch 8, Batch 2600] loss: 0.018886070414628194
[Epoch 8, Batch 2700] loss: 0.02952475065913404
[Epoch 8, Batch 2800] loss: 0.03382012192887487
[Epoch 8, Batch 2900] loss: 0.037838667947835344
[Epoch 8, Batch 3000] loss: 0.03693251758064434
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9857
Overfitting: 0.0500
[Epoch 9, Batch 100] loss: 0.020003579797757992
[Epoch 9, Batch 200] loss: 0.012966334380835179
[Epoch 9, Batch 300] loss: 0.01664567798467033
[Epoch 9, Batch 400] loss: 0.011966068345700479
[Epoch 9, Batch 500] loss: 0.008216697756270151
[Epoch 9, Batch 600] loss: 0.005543463311387314
[Epoch 9, Batch 700] loss: 0.012051608359524835
[Epoch 9, Batch 800] loss: 0.018750287395951092
[Epoch 9, Batch 900] loss: 0.01615851717309397
[Epoch 9, Batch 1000] loss: 0.012034576944952278
[Epoch 9, Batch 1100] loss: 0.013924081742879934
[Epoch 9, Batch 1200] loss: 0.019051239265572804
[Epoch 9, Batch 1300] loss: 0.024100025252682827
[Epoch 9, Batch 1400] loss: 0.029232783088809812
[Epoch 9, Batch 1500] loss: 0.02107917349798299
[Epoch 9, Batch 1600] loss: 0.017386070584502703
[Epoch 9, Batch 1700] loss: 0.025578884027727327
[Epoch 9, Batch 1800] loss: 0.023957303355782642
[Epoch 9, Batch 1900] loss: 0.02879599327179676
[Epoch 9, Batch 2000] loss: 0.026130325216672644
[Epoch 9, Batch 2100] loss: 0.025989889463417057
[Epoch 9, Batch 2200] loss: 0.029756282766848018
[Epoch 9, Batch 2300] loss: 0.02280361645147423
[Epoch 9, Batch 2400] loss: 0.031020355128439404
[Epoch 9, Batch 2500] loss: 0.012022939366197534
[Epoch 9, Batch 2600] loss: 0.023807226892931795
[Epoch 9, Batch 2700] loss: 0.027101981502128183
[Epoch 9, Batch 2800] loss: 0.015787675261326514
[Epoch 9, Batch 2900] loss: 0.02404932578444459
[Epoch 9, Batch 3000] loss: 0.018722597567998493
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9843
Overfitting: 0.0544
[Epoch 10, Batch 100] loss: 0.01136631277106062
[Epoch 10, Batch 200] loss: 0.024927172188636177
[Epoch 10, Batch 300] loss: 0.02195256597096886
[Epoch 10, Batch 400] loss: 0.01819113490761083
[Epoch 10, Batch 500] loss: 0.014864274689971353
[Epoch 10, Batch 600] loss: 0.012127429949086945
[Epoch 10, Batch 700] loss: 0.01369209081709414
[Epoch 10, Batch 800] loss: 0.008697796787928383
[Epoch 10, Batch 900] loss: 0.019993385861689604
[Epoch 10, Batch 1000] loss: 0.01222827534955286
[Epoch 10, Batch 1100] loss: 0.006063590111771191
[Epoch 10, Batch 1200] loss: 0.015595214231216232
[Epoch 10, Batch 1300] loss: 0.022689401185875795
[Epoch 10, Batch 1400] loss: 0.017284899974583823
[Epoch 10, Batch 1500] loss: 0.021498586166053428
[Epoch 10, Batch 1600] loss: 0.008959066633806287
[Epoch 10, Batch 1700] loss: 0.015777700387661752
[Epoch 10, Batch 1800] loss: 0.00828427486376313
[Epoch 10, Batch 1900] loss: 0.010686317010677158
[Epoch 10, Batch 2000] loss: 0.024171765929536376
[Epoch 10, Batch 2100] loss: 0.028973914572372906
[Epoch 10, Batch 2200] loss: 0.013395354553413199
[Epoch 10, Batch 2300] loss: 0.034731902665680534
[Epoch 10, Batch 2400] loss: 0.014181336576220928
[Epoch 10, Batch 2500] loss: 0.026918739097909566
[Epoch 10, Batch 2600] loss: 0.01677831827859336
[Epoch 10, Batch 2700] loss: 0.017676281386225127
[Epoch 10, Batch 2800] loss: 0.012867984501199317
[Epoch 10, Batch 2900] loss: 0.010823978793168862
[Epoch 10, Batch 3000] loss: 0.023005129339517226
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9870
Overfitting: 0.0527
[Epoch 11, Batch 100] loss: 0.019437806479500067
[Epoch 11, Batch 200] loss: 0.017660242845197446
[Epoch 11, Batch 300] loss: 0.015972815211441685
[Epoch 11, Batch 400] loss: 0.012935458143219876
[Epoch 11, Batch 500] loss: 0.024230084183388952
[Epoch 11, Batch 600] loss: 0.009546624567810795
[Epoch 11, Batch 700] loss: 0.015109562825773536
[Epoch 11, Batch 800] loss: 0.02099204918434225
[Epoch 11, Batch 900] loss: 0.008933719693395688
[Epoch 11, Batch 1000] loss: 0.009504170723309925
[Epoch 11, Batch 1100] loss: 0.005072009732471088
[Epoch 11, Batch 1200] loss: 0.011518256363333422
[Epoch 11, Batch 1300] loss: 0.015554990425234791
[Epoch 11, Batch 1400] loss: 0.018223004782557835
[Epoch 11, Batch 1500] loss: 0.010385650544483269
[Epoch 11, Batch 1600] loss: 0.012325141373896713
[Epoch 11, Batch 1700] loss: 0.009098998079798548
[Epoch 11, Batch 1800] loss: 0.02504003145018487
[Epoch 11, Batch 1900] loss: 0.014282374963786424
[Epoch 11, Batch 2000] loss: 0.013538403079492127
[Epoch 11, Batch 2100] loss: 0.011150899036870214
[Epoch 11, Batch 2200] loss: 0.0047358717664064895
[Epoch 11, Batch 2300] loss: 0.004370440469315327
[Epoch 11, Batch 2400] loss: 0.009864740787952542
[Epoch 11, Batch 2500] loss: 0.013258683400872542
[Epoch 11, Batch 2600] loss: 0.0149476750596682
[Epoch 11, Batch 2700] loss: 0.02133267679078017
[Epoch 11, Batch 2800] loss: 0.011733119924174388
[Epoch 11, Batch 2900] loss: 0.004776171444800639
[Epoch 11, Batch 3000] loss: 0.011911832497476097
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9869
Overfitting: 0.0527
[Epoch 12, Batch 100] loss: 0.00791977685807069
[Epoch 12, Batch 200] loss: 0.005451802316865723
[Epoch 12, Batch 300] loss: 0.008369819610531976
[Epoch 12, Batch 400] loss: 0.009554215717282091
[Epoch 12, Batch 500] loss: 0.011763936037182248
[Epoch 12, Batch 600] loss: 0.015755832719410136
[Epoch 12, Batch 700] loss: 0.010079579614634895
[Epoch 12, Batch 800] loss: 0.013280127992129565
[Epoch 12, Batch 900] loss: 0.010336308963267128
[Epoch 12, Batch 1000] loss: 0.010167732993741083
[Epoch 12, Batch 1100] loss: 0.00977401427231598
[Epoch 12, Batch 1200] loss: 0.006155425656113493
[Epoch 12, Batch 1300] loss: 0.018221662674743584
[Epoch 12, Batch 1400] loss: 0.010492102154985332
[Epoch 12, Batch 1500] loss: 0.006695208846417699
[Epoch 12, Batch 1600] loss: 0.0026896067554162072
[Epoch 12, Batch 1700] loss: 0.008789682775623078
[Epoch 12, Batch 1800] loss: 0.018769824882176635
[Epoch 12, Batch 1900] loss: 0.018410656618998475
[Epoch 12, Batch 2000] loss: 0.010046714462323508
[Epoch 12, Batch 2100] loss: 0.007613351786621933
[Epoch 12, Batch 2200] loss: 0.007193441493493538
[Epoch 12, Batch 2300] loss: 0.009375608556555903
[Epoch 12, Batch 2400] loss: 0.01791819499878784
[Epoch 12, Batch 2500] loss: 0.01759410918849426
[Epoch 12, Batch 2600] loss: 0.025527209857787055
[Epoch 12, Batch 2700] loss: 0.01162480349847101
[Epoch 12, Batch 2800] loss: 0.011132463938747606
[Epoch 12, Batch 2900] loss: 0.013928849161729887
[Epoch 12, Batch 3000] loss: 0.015514517932842864
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9862
Overfitting: 0.0487
Best model saved at epoch 12 with validation loss: 0.0487
[Epoch 13, Batch 100] loss: 0.01080872448540049
[Epoch 13, Batch 200] loss: 0.017175090420037124
[Epoch 13, Batch 300] loss: 0.0087398719795533
[Epoch 13, Batch 400] loss: 0.00937598836482266
[Epoch 13, Batch 500] loss: 0.024373125574811638
[Epoch 13, Batch 600] loss: 0.01657354195611333
[Epoch 13, Batch 700] loss: 0.01420336960627992
[Epoch 13, Batch 800] loss: 0.005554110715934257
[Epoch 13, Batch 900] loss: 0.010662974419647071
[Epoch 13, Batch 1000] loss: 0.00981914159327971
[Epoch 13, Batch 1100] loss: 0.01682392007900944
[Epoch 13, Batch 1200] loss: 0.009200119943247955
[Epoch 13, Batch 1300] loss: 0.007261695480228809
[Epoch 13, Batch 1400] loss: 0.006526009155606971
[Epoch 13, Batch 1500] loss: 0.014536041064125128
[Epoch 13, Batch 1600] loss: 0.007583799094709321
[Epoch 13, Batch 1700] loss: 0.006026164568793319
[Epoch 13, Batch 1800] loss: 0.01625862872450398
[Epoch 13, Batch 1900] loss: 0.006957634678080922
[Epoch 13, Batch 2000] loss: 0.012287981102940649
[Epoch 13, Batch 2100] loss: 0.008957855191732166
[Epoch 13, Batch 2200] loss: 0.01414154487043561
[Epoch 13, Batch 2300] loss: 0.010245725939746535
[Epoch 13, Batch 2400] loss: 0.005482266640954094
[Epoch 13, Batch 2500] loss: 0.020782229802216536
[Epoch 13, Batch 2600] loss: 0.007901903631149025
[Epoch 13, Batch 2700] loss: 0.0071741555283006166
[Epoch 13, Batch 2800] loss: 0.00974576494273265
[Epoch 13, Batch 2900] loss: 0.010693806261817826
[Epoch 13, Batch 3000] loss: 0.014976851815688974
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9858
Overfitting: 0.0586
[Epoch 14, Batch 100] loss: 0.008698572930165937
[Epoch 14, Batch 200] loss: 0.01036171390625384
[Epoch 14, Batch 300] loss: 0.014114083161966846
[Epoch 14, Batch 400] loss: 0.008775274004688072
[Epoch 14, Batch 500] loss: 0.01737046118183116
[Epoch 14, Batch 600] loss: 0.007585418915250557
[Epoch 14, Batch 700] loss: 0.011191554350793921
[Epoch 14, Batch 800] loss: 0.008029162293937589
[Epoch 14, Batch 900] loss: 0.009773801921915038
[Epoch 14, Batch 1000] loss: 0.008249286367160949
[Epoch 14, Batch 1100] loss: 0.004141072890431588
[Epoch 14, Batch 1200] loss: 0.005374570283192952
[Epoch 14, Batch 1300] loss: 0.017231038712830014
[Epoch 14, Batch 1400] loss: 0.007021992484687871
[Epoch 14, Batch 1500] loss: 0.00975849057271148
[Epoch 14, Batch 1600] loss: 0.01285133252081323
[Epoch 14, Batch 1700] loss: 0.007828678983405552
[Epoch 14, Batch 1800] loss: 0.012886598878792484
[Epoch 14, Batch 1900] loss: 0.020790776270823697
[Epoch 14, Batch 2000] loss: 0.009964858251596525
[Epoch 14, Batch 2100] loss: 0.011335539395660135
[Epoch 14, Batch 2200] loss: 0.0030967383969505136
[Epoch 14, Batch 2300] loss: 0.008329339284646266
[Epoch 14, Batch 2400] loss: 0.0069720049978161565
[Epoch 14, Batch 2500] loss: 0.012536657430277955
[Epoch 14, Batch 2600] loss: 0.011035118328561567
[Epoch 14, Batch 2700] loss: 0.0046529843597977565
[Epoch 14, Batch 2800] loss: 0.008826430136548425
[Epoch 14, Batch 2900] loss: 0.013388976321236328
[Epoch 14, Batch 3000] loss: 0.013004099511288131
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9874
Overfitting: 0.0502
[Epoch 15, Batch 100] loss: 0.009240340259592585
[Epoch 15, Batch 200] loss: 0.005169971481088851
[Epoch 15, Batch 300] loss: 0.007683767122614427
[Epoch 15, Batch 400] loss: 0.008320976932809572
[Epoch 15, Batch 500] loss: 0.00464953039508714
[Epoch 15, Batch 600] loss: 0.004684342369575347
[Epoch 15, Batch 700] loss: 0.0044632347966387445
[Epoch 15, Batch 800] loss: 0.006376132035500177
[Epoch 15, Batch 900] loss: 0.005742419805045529
[Epoch 15, Batch 1000] loss: 0.016469148967539694
[Epoch 15, Batch 1100] loss: 0.01176058810577615
[Epoch 15, Batch 1200] loss: 0.007767345923422226
[Epoch 15, Batch 1300] loss: 0.005192893657695094
[Epoch 15, Batch 1400] loss: 0.004063877702437821
[Epoch 15, Batch 1500] loss: 0.013795886657605934
[Epoch 15, Batch 1600] loss: 0.030183000678869122
[Epoch 15, Batch 1700] loss: 0.00756588419062382
[Epoch 15, Batch 1800] loss: 0.007973637264435639
[Epoch 15, Batch 1900] loss: 0.007088333618246452
[Epoch 15, Batch 2000] loss: 0.009314149026081395
[Epoch 15, Batch 2100] loss: 0.006964906565790443
[Epoch 15, Batch 2200] loss: 0.005565786937362986
[Epoch 15, Batch 2300] loss: 0.004278739370176936
[Epoch 15, Batch 2400] loss: 0.00581628657274905
[Epoch 15, Batch 2500] loss: 0.00649813650439313
[Epoch 15, Batch 2600] loss: 0.007106230309974535
[Epoch 15, Batch 2700] loss: 0.014282375582570239
[Epoch 15, Batch 2800] loss: 0.02010018769883118
[Epoch 15, Batch 2900] loss: 0.021753471481110863
[Epoch 15, Batch 3000] loss: 0.015595465922563107
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0618
Validation Accuracy: 0.9872
Overfitting: 0.0618
[Epoch 16, Batch 100] loss: 0.00889404484396323
[Epoch 16, Batch 200] loss: 0.0066951089679469075
[Epoch 16, Batch 300] loss: 0.0067950400260974675
[Epoch 16, Batch 400] loss: 0.007708217176883636
[Epoch 16, Batch 500] loss: 0.0032438464786226006
[Epoch 16, Batch 600] loss: 0.005667313161695233
[Epoch 16, Batch 700] loss: 0.005862370638955099
[Epoch 16, Batch 800] loss: 0.0037567665393047635
[Epoch 16, Batch 900] loss: 0.006914462035958877
[Epoch 16, Batch 1000] loss: 0.009370714481815413
[Epoch 16, Batch 1100] loss: 0.009316413451396529
[Epoch 16, Batch 1200] loss: 0.006188405707900984
[Epoch 16, Batch 1300] loss: 0.007999182535011471
[Epoch 16, Batch 1400] loss: 0.010926858394120699
[Epoch 16, Batch 1500] loss: 0.016931520441863766
[Epoch 16, Batch 1600] loss: 0.005377249901725918
[Epoch 16, Batch 1700] loss: 0.01641566959452348
[Epoch 16, Batch 1800] loss: 0.022769818106198728
[Epoch 16, Batch 1900] loss: 0.011931428326354307
[Epoch 16, Batch 2000] loss: 0.009016345008386112
[Epoch 16, Batch 2100] loss: 0.006816954313256929
[Epoch 16, Batch 2200] loss: 0.005420008561627583
[Epoch 16, Batch 2300] loss: 0.005981689780074362
[Epoch 16, Batch 2400] loss: 0.0073036375132596735
[Epoch 16, Batch 2500] loss: 0.0044996435029281655
[Epoch 16, Batch 2600] loss: 0.007571905454733496
[Epoch 16, Batch 2700] loss: 0.01098493135425656
[Epoch 16, Batch 2800] loss: 0.0072122084203454055
[Epoch 16, Batch 2900] loss: 0.0050305313131400456
[Epoch 16, Batch 3000] loss: 0.007562711324674183
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9861
Overfitting: 0.0593
[Epoch 17, Batch 100] loss: 0.010694656122620928
[Epoch 17, Batch 200] loss: 0.008169327113186
[Epoch 17, Batch 300] loss: 0.0021397929772558654
[Epoch 17, Batch 400] loss: 0.0034941169346848254
[Epoch 17, Batch 500] loss: 0.005284358245512521
[Epoch 17, Batch 600] loss: 0.01055617756727429
[Epoch 17, Batch 700] loss: 0.005732571285527684
[Epoch 17, Batch 800] loss: 0.0033318863188253546
[Epoch 17, Batch 900] loss: 0.007853402415321682
[Epoch 17, Batch 1000] loss: 0.0035793071394607523
[Epoch 17, Batch 1100] loss: 0.005783084344573126
[Epoch 17, Batch 1200] loss: 0.01113336113020864
[Epoch 17, Batch 1300] loss: 0.013009210518226837
[Epoch 17, Batch 1400] loss: 0.009354386216141392
[Epoch 17, Batch 1500] loss: 0.0034190441338438405
[Epoch 17, Batch 1600] loss: 0.013350971622113548
[Epoch 17, Batch 1700] loss: 0.00557773297726925
[Epoch 17, Batch 1800] loss: 0.0055499522335276195
[Epoch 17, Batch 1900] loss: 0.012228553388709429
[Epoch 17, Batch 2000] loss: 0.006801711663197239
[Epoch 17, Batch 2100] loss: 0.00852011284513992
[Epoch 17, Batch 2200] loss: 0.01348267761879356
[Epoch 17, Batch 2300] loss: 0.017353135944982796
[Epoch 17, Batch 2400] loss: 0.01691473358921936
[Epoch 17, Batch 2500] loss: 0.006744056477737103
[Epoch 17, Batch 2600] loss: 0.0062069417819429875
[Epoch 17, Batch 2700] loss: 0.012732388774243758
[Epoch 17, Batch 2800] loss: 0.013354569755081229
[Epoch 17, Batch 2900] loss: 0.004508308988989711
[Epoch 17, Batch 3000] loss: 0.013846993372228554
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0577
Validation Accuracy: 0.9861
Overfitting: 0.0577
[Epoch 18, Batch 100] loss: 0.009160156540893923
[Epoch 18, Batch 200] loss: 0.0025361064077014817
[Epoch 18, Batch 300] loss: 0.0023654168898295325
[Epoch 18, Batch 400] loss: 0.0022886842522373742
[Epoch 18, Batch 500] loss: 0.003206971428139127
[Epoch 18, Batch 600] loss: 0.003705498470157522
[Epoch 18, Batch 700] loss: 0.012266779625773551
[Epoch 18, Batch 800] loss: 0.005591266589123052
[Epoch 18, Batch 900] loss: 0.002408616168107187
[Epoch 18, Batch 1000] loss: 0.007049747139264895
[Epoch 18, Batch 1100] loss: 0.00196290385688485
[Epoch 18, Batch 1200] loss: 0.006339585062382866
[Epoch 18, Batch 1300] loss: 0.009659240724871267
[Epoch 18, Batch 1400] loss: 0.005171962833901489
[Epoch 18, Batch 1500] loss: 0.011124202422253688
[Epoch 18, Batch 1600] loss: 0.005242709297921806
[Epoch 18, Batch 1700] loss: 0.005388201889230118
[Epoch 18, Batch 1800] loss: 0.01922146879114706
[Epoch 18, Batch 1900] loss: 0.007184610147869321
[Epoch 18, Batch 2000] loss: 0.005614526551085532
[Epoch 18, Batch 2100] loss: 0.0132808140170863
[Epoch 18, Batch 2200] loss: 0.006865574435724966
[Epoch 18, Batch 2300] loss: 0.018143613634786532
[Epoch 18, Batch 2400] loss: 0.01040686292321425
[Epoch 18, Batch 2500] loss: 0.005067905445884833
[Epoch 18, Batch 2600] loss: 0.004253644865342494
[Epoch 18, Batch 2700] loss: 0.0041489389803172115
[Epoch 18, Batch 2800] loss: 0.014339518827582366
[Epoch 18, Batch 2900] loss: 0.004647023478700873
[Epoch 18, Batch 3000] loss: 0.005867795549793869
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0557
Validation Accuracy: 0.9868
Overfitting: 0.0557
[Epoch 19, Batch 100] loss: 0.006707774151179251
[Epoch 19, Batch 200] loss: 0.00362011104306589
[Epoch 19, Batch 300] loss: 0.006064007636384758
[Epoch 19, Batch 400] loss: 0.0013334904526237778
[Epoch 19, Batch 500] loss: 0.0030626611703249295
[Epoch 19, Batch 600] loss: 0.0011319837238812625
[Epoch 19, Batch 700] loss: 0.0012732486563265867
[Epoch 19, Batch 800] loss: 0.0018884491255249714
[Epoch 19, Batch 900] loss: 0.0007021648378486134
[Epoch 19, Batch 1000] loss: 0.00544631823895827
[Epoch 19, Batch 1100] loss: 0.002975641776276774
[Epoch 19, Batch 1200] loss: 0.002944498225542702
[Epoch 19, Batch 1300] loss: 0.006338469554954429
[Epoch 19, Batch 1400] loss: 0.003987455685360142
[Epoch 19, Batch 1500] loss: 0.0031660594829980935
[Epoch 19, Batch 1600] loss: 0.002231091245324137
[Epoch 19, Batch 1700] loss: 0.002373054938371908
[Epoch 19, Batch 1800] loss: 0.004439788403716421
[Epoch 19, Batch 1900] loss: 0.0020420288081308513
[Epoch 19, Batch 2000] loss: 0.005550147560928736
[Epoch 19, Batch 2100] loss: 0.009361094656911319
[Epoch 19, Batch 2200] loss: 0.004410871535468175
[Epoch 19, Batch 2300] loss: 0.00578038625414905
[Epoch 19, Batch 2400] loss: 0.003219864877392382
[Epoch 19, Batch 2500] loss: 0.004092850795312444
[Epoch 19, Batch 2600] loss: 0.0051621987890166565
[Epoch 19, Batch 2700] loss: 0.012699444586599497
[Epoch 19, Batch 2800] loss: 0.00820382150560647
[Epoch 19, Batch 2900] loss: 0.017946909219873533
[Epoch 19, Batch 3000] loss: 0.0026761518100386185
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9871
Overfitting: 0.0576
[Epoch 20, Batch 100] loss: 0.0017789525663874884
[Epoch 20, Batch 200] loss: 0.004308258488479168
[Epoch 20, Batch 300] loss: 0.007864232789477227
[Epoch 20, Batch 400] loss: 0.0036316492534251665
[Epoch 20, Batch 500] loss: 0.0014044661440297545
[Epoch 20, Batch 600] loss: 0.0013797024535571723
[Epoch 20, Batch 700] loss: 0.0015302469180466004
[Epoch 20, Batch 800] loss: 0.004194431093895901
[Epoch 20, Batch 900] loss: 0.0006065557632769014
[Epoch 20, Batch 1000] loss: 0.003431974930640749
[Epoch 20, Batch 1100] loss: 0.007168574716084777
[Epoch 20, Batch 1200] loss: 0.0021484522585278752
[Epoch 20, Batch 1300] loss: 0.002244236347063975
[Epoch 20, Batch 1400] loss: 0.0008072934798468623
[Epoch 20, Batch 1500] loss: 0.005235440264959763
[Epoch 20, Batch 1600] loss: 0.003178912198911803
[Epoch 20, Batch 1700] loss: 0.004133822015174929
[Epoch 20, Batch 1800] loss: 0.002863244797216562
[Epoch 20, Batch 1900] loss: 0.0011568239314698303
[Epoch 20, Batch 2000] loss: 0.0076013405136990285
[Epoch 20, Batch 2100] loss: 0.001904800008876464
[Epoch 20, Batch 2200] loss: 0.001721846981584747
[Epoch 20, Batch 2300] loss: 0.0028643050950046245
[Epoch 20, Batch 2400] loss: 0.002174355169922819
[Epoch 20, Batch 2500] loss: 0.004177808026040566
[Epoch 20, Batch 2600] loss: 0.0011376524978130931
[Epoch 20, Batch 2700] loss: 0.0016272420207501881
[Epoch 20, Batch 2800] loss: 0.006424342998408577
[Epoch 20, Batch 2900] loss: 0.00832928319058837
[Epoch 20, Batch 3000] loss: 0.0025517005483773046
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9880
Overfitting: 0.0592
[Epoch 21, Batch 100] loss: 0.0017675441892566824
[Epoch 21, Batch 200] loss: 0.0014859500845813044
[Epoch 21, Batch 300] loss: 0.005052283286567914
[Epoch 21, Batch 400] loss: 0.0026463785556929053
[Epoch 21, Batch 500] loss: 0.0016719902334018854
[Epoch 21, Batch 600] loss: 0.005453562759043394
[Epoch 21, Batch 700] loss: 0.008742485730819921
[Epoch 21, Batch 800] loss: 0.003381786538996181
[Epoch 21, Batch 900] loss: 0.001029018023195647
[Epoch 21, Batch 1000] loss: 0.0008204379294582508
[Epoch 21, Batch 1100] loss: 0.0008559235114439012
[Epoch 21, Batch 1200] loss: 0.0006581723144811846
[Epoch 21, Batch 1300] loss: 0.001203793013232044
[Epoch 21, Batch 1400] loss: 0.0008861430814454252
[Epoch 21, Batch 1500] loss: 0.0017818923023755673
[Epoch 21, Batch 1600] loss: 0.005571240656872743
[Epoch 21, Batch 1700] loss: 0.001383813226409245
[Epoch 21, Batch 1800] loss: 0.0031303696251015365
[Epoch 21, Batch 1900] loss: 0.003212090863109154
[Epoch 21, Batch 2000] loss: 0.0016978644094524497
[Epoch 21, Batch 2100] loss: 0.002186752921982844
[Epoch 21, Batch 2200] loss: 0.002359613114488042
[Epoch 21, Batch 2300] loss: 0.00178096654379436
[Epoch 21, Batch 2400] loss: 0.0013523582444494764
[Epoch 21, Batch 2500] loss: 0.0018220717481193206
[Epoch 21, Batch 2600] loss: 0.0013611596582673968
[Epoch 21, Batch 2700] loss: 0.0006611732097571377
[Epoch 21, Batch 2800] loss: 0.0010467374524984051
[Epoch 21, Batch 2900] loss: 0.000979987789789405
[Epoch 21, Batch 3000] loss: 0.0012834144894615918
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0610
Validation Accuracy: 0.9887
Overfitting: 0.0610
[Epoch 22, Batch 100] loss: 0.0032628021836919176
[Epoch 22, Batch 200] loss: 0.004297236735747845
[Epoch 22, Batch 300] loss: 0.0017429827093864959
[Epoch 22, Batch 400] loss: 0.0012621282894817653
[Epoch 22, Batch 500] loss: 0.005332380412740672
[Epoch 22, Batch 600] loss: 0.0010890723010884783
[Epoch 22, Batch 700] loss: 0.001096507158856781
[Epoch 22, Batch 800] loss: 0.0006229594267239235
[Epoch 22, Batch 900] loss: 0.0026683071051260667
[Epoch 22, Batch 1000] loss: 0.001178328819504557
[Epoch 22, Batch 1100] loss: 0.0007464257857896684
[Epoch 22, Batch 1200] loss: 0.0011431757409694355
[Epoch 22, Batch 1300] loss: 0.0017437360234170995
[Epoch 22, Batch 1400] loss: 0.001326374519855875
[Epoch 22, Batch 1500] loss: 0.0014328372209524076
[Epoch 22, Batch 1600] loss: 0.0026741295380553077
[Epoch 22, Batch 1700] loss: 0.0013569222713008067
[Epoch 22, Batch 1800] loss: 0.001425041813258261
[Epoch 22, Batch 1900] loss: 0.001528705462298774
[Epoch 22, Batch 2000] loss: 0.002545324125031172
[Epoch 22, Batch 2100] loss: 0.005024348735684212
[Epoch 22, Batch 2200] loss: 0.0031728537865300145
[Epoch 22, Batch 2300] loss: 0.00377151112768118
[Epoch 22, Batch 2400] loss: 0.0023241488939150434
[Epoch 22, Batch 2500] loss: 0.0009111977479929046
[Epoch 22, Batch 2600] loss: 0.006278904363117732
[Epoch 22, Batch 2700] loss: 0.0018612955785174633
[Epoch 22, Batch 2800] loss: 0.0037812038532371163
[Epoch 22, Batch 2900] loss: 0.003967048366017778
[Epoch 22, Batch 3000] loss: 0.0018139413988777875
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0639
Validation Accuracy: 0.9874
Overfitting: 0.0639
[Epoch 23, Batch 100] loss: 0.0021481864384257678
[Epoch 23, Batch 200] loss: 0.0012848099314169837
[Epoch 23, Batch 300] loss: 0.0006329042172167787
[Epoch 23, Batch 400] loss: 0.0004681050168676748
[Epoch 23, Batch 500] loss: 0.0021207120836775227
[Epoch 23, Batch 600] loss: 0.001646909241688128
[Epoch 23, Batch 700] loss: 0.0032674441766914696
[Epoch 23, Batch 800] loss: 0.0005970753999332601
[Epoch 23, Batch 900] loss: 0.003922231616778333
[Epoch 23, Batch 1000] loss: 0.0010107066134914789
[Epoch 23, Batch 1100] loss: 0.00473449058557577
[Epoch 23, Batch 1200] loss: 0.0020195209378883307
[Epoch 23, Batch 1300] loss: 0.0011793130643357585
[Epoch 23, Batch 1400] loss: 0.007493569597263416
[Epoch 23, Batch 1500] loss: 0.004793014914710554
[Epoch 23, Batch 1600] loss: 0.008582377215465939
[Epoch 23, Batch 1700] loss: 0.0035173851486677422
[Epoch 23, Batch 1800] loss: 0.00894996103271808
[Epoch 23, Batch 1900] loss: 0.011468597455955774
[Epoch 23, Batch 2000] loss: 0.001982667895664605
[Epoch 23, Batch 2100] loss: 0.0009673479164012732
[Epoch 23, Batch 2200] loss: 0.0009354487171513526
[Epoch 23, Batch 2300] loss: 0.002016608462543834
[Epoch 23, Batch 2400] loss: 0.002854481572255736
[Epoch 23, Batch 2500] loss: 0.006117555760836062
[Epoch 23, Batch 2600] loss: 0.0008970664683334916
[Epoch 23, Batch 2700] loss: 0.0009151040169319913
[Epoch 23, Batch 2800] loss: 0.0008848257054693676
[Epoch 23, Batch 2900] loss: 0.0029998091969842557
[Epoch 23, Batch 3000] loss: 0.0007048692831804715
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0607
Validation Accuracy: 0.9878
Overfitting: 0.0607
[Epoch 24, Batch 100] loss: 0.002620506956219515
[Epoch 24, Batch 200] loss: 0.002226372579478095
[Epoch 24, Batch 300] loss: 0.005655548096830501
[Epoch 24, Batch 400] loss: 0.00681984353048577
[Epoch 24, Batch 500] loss: 0.002347235918656594
[Epoch 24, Batch 600] loss: 0.0013162724256559244
[Epoch 24, Batch 700] loss: 0.002713187955548051
[Epoch 24, Batch 800] loss: 0.0007823697619845049
[Epoch 24, Batch 900] loss: 0.0011282430172634861
[Epoch 24, Batch 1000] loss: 0.0013253045022094056
[Epoch 24, Batch 1100] loss: 0.0009744314505433494
[Epoch 24, Batch 1200] loss: 0.0007712283696617562
[Epoch 24, Batch 1300] loss: 0.0012667995490980033
[Epoch 24, Batch 1400] loss: 0.002141223962919696
[Epoch 24, Batch 1500] loss: 0.006805471907768772
[Epoch 24, Batch 1600] loss: 0.0013330651339538235
[Epoch 24, Batch 1700] loss: 0.0005079726116725425
[Epoch 24, Batch 1800] loss: 0.0023690726001087724
[Epoch 24, Batch 1900] loss: 0.00964710315830366
[Epoch 24, Batch 2000] loss: 0.0032137311219703644
[Epoch 24, Batch 2100] loss: 0.003976761024627535
[Epoch 24, Batch 2200] loss: 0.0042322086154959315
[Epoch 24, Batch 2300] loss: 0.0018611901020250342
[Epoch 24, Batch 2400] loss: 0.0008390318179986877
[Epoch 24, Batch 2500] loss: 0.0026950949154035974
[Epoch 24, Batch 2600] loss: 0.00516854930122534
[Epoch 24, Batch 2700] loss: 0.003996623037903291
[Epoch 24, Batch 2800] loss: 0.0021593575336335746
[Epoch 24, Batch 2900] loss: 0.006966894954772842
[Epoch 24, Batch 3000] loss: 0.009707413334510093
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0757
Validation Accuracy: 0.9852
Overfitting: 0.0757
Fold 2 validation loss: 0.0757
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.285516517162323
[Epoch 1, Batch 200] loss: 2.1026574206352233
[Epoch 1, Batch 300] loss: 1.070464164018631
[Epoch 1, Batch 400] loss: 0.6412454029917717
[Epoch 1, Batch 500] loss: 0.5480518390238285
[Epoch 1, Batch 600] loss: 0.4470092448592186
[Epoch 1, Batch 700] loss: 0.34547266937792304
[Epoch 1, Batch 800] loss: 0.32153786975890397
[Epoch 1, Batch 900] loss: 0.33112274069339037
[Epoch 1, Batch 1000] loss: 0.2944026578962803
[Epoch 1, Batch 1100] loss: 0.2739483442250639
[Epoch 1, Batch 1200] loss: 0.2265541566722095
[Epoch 1, Batch 1300] loss: 0.22949403399601578
[Epoch 1, Batch 1400] loss: 0.17158459704369305
[Epoch 1, Batch 1500] loss: 0.17081135771702974
[Epoch 1, Batch 1600] loss: 0.18700786498375238
[Epoch 1, Batch 1700] loss: 0.16864820879884065
[Epoch 1, Batch 1800] loss: 0.1526526313321665
[Epoch 1, Batch 1900] loss: 0.17501618310809136
[Epoch 1, Batch 2000] loss: 0.10080486223567277
[Epoch 1, Batch 2100] loss: 0.12633119814563543
[Epoch 1, Batch 2200] loss: 0.15700299261137843
[Epoch 1, Batch 2300] loss: 0.13043993895174935
[Epoch 1, Batch 2400] loss: 0.1182564089819789
[Epoch 1, Batch 2500] loss: 0.14251896707341075
[Epoch 1, Batch 2600] loss: 0.12299666606588289
[Epoch 1, Batch 2700] loss: 0.13754482698859646
[Epoch 1, Batch 2800] loss: 0.10644644604064524
[Epoch 1, Batch 2900] loss: 0.11318716426147148
[Epoch 1, Batch 3000] loss: 0.1033302139339503
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1138
Validation Accuracy: 0.9636
Overfitting: 0.1138
Best model saved at epoch 1 with validation loss: 0.1138
[Epoch 2, Batch 100] loss: 0.09176070676418022
[Epoch 2, Batch 200] loss: 0.11612894093384966
[Epoch 2, Batch 300] loss: 0.09505791544448584
[Epoch 2, Batch 400] loss: 0.08912627578363753
[Epoch 2, Batch 500] loss: 0.09352233115932904
[Epoch 2, Batch 600] loss: 0.09960580385639332
[Epoch 2, Batch 700] loss: 0.11658571836771443
[Epoch 2, Batch 800] loss: 0.09938814266468399
[Epoch 2, Batch 900] loss: 0.13373124197591096
[Epoch 2, Batch 1000] loss: 0.0976452348253224
[Epoch 2, Batch 1100] loss: 0.10350690264487639
[Epoch 2, Batch 1200] loss: 0.12318102240678855
[Epoch 2, Batch 1300] loss: 0.09659240061184392
[Epoch 2, Batch 1400] loss: 0.0754555790789891
[Epoch 2, Batch 1500] loss: 0.07786921468388755
[Epoch 2, Batch 1600] loss: 0.07539350345090497
[Epoch 2, Batch 1700] loss: 0.08391438372200355
[Epoch 2, Batch 1800] loss: 0.06282631774840411
[Epoch 2, Batch 1900] loss: 0.0841224856628105
[Epoch 2, Batch 2000] loss: 0.07784400980512146
[Epoch 2, Batch 2100] loss: 0.07240450673212763
[Epoch 2, Batch 2200] loss: 0.0654981852520723
[Epoch 2, Batch 2300] loss: 0.08689192904275841
[Epoch 2, Batch 2400] loss: 0.09641054228530266
[Epoch 2, Batch 2500] loss: 0.06342230929178186
[Epoch 2, Batch 2600] loss: 0.08963831476052292
[Epoch 2, Batch 2700] loss: 0.0922289766871836
[Epoch 2, Batch 2800] loss: 0.07443233935686294
[Epoch 2, Batch 2900] loss: 0.07987297905609012
[Epoch 2, Batch 3000] loss: 0.08587700674077496
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0822
Validation Accuracy: 0.9751
Overfitting: 0.0822
Best model saved at epoch 2 with validation loss: 0.0822
[Epoch 3, Batch 100] loss: 0.06502890481613577
[Epoch 3, Batch 200] loss: 0.07564702277071773
[Epoch 3, Batch 300] loss: 0.06174268704897259
[Epoch 3, Batch 400] loss: 0.06555618174985284
[Epoch 3, Batch 500] loss: 0.05968084936204832
[Epoch 3, Batch 600] loss: 0.07272573783644475
[Epoch 3, Batch 700] loss: 0.04639705659938045
[Epoch 3, Batch 800] loss: 0.050757438931323125
[Epoch 3, Batch 900] loss: 0.07012092425895389
[Epoch 3, Batch 1000] loss: 0.05898047936556395
[Epoch 3, Batch 1100] loss: 0.057965930542122804
[Epoch 3, Batch 1200] loss: 0.06221166111237835
[Epoch 3, Batch 1300] loss: 0.07541574114584364
[Epoch 3, Batch 1400] loss: 0.052915074672782794
[Epoch 3, Batch 1500] loss: 0.07057762662647292
[Epoch 3, Batch 1600] loss: 0.060032214111997745
[Epoch 3, Batch 1700] loss: 0.06744848498055944
[Epoch 3, Batch 1800] loss: 0.05391189296933589
[Epoch 3, Batch 1900] loss: 0.07730573497916339
[Epoch 3, Batch 2000] loss: 0.061181342208292334
[Epoch 3, Batch 2100] loss: 0.03518966795876622
[Epoch 3, Batch 2200] loss: 0.07962677122995956
[Epoch 3, Batch 2300] loss: 0.06353387408715207
[Epoch 3, Batch 2400] loss: 0.06428268854448106
[Epoch 3, Batch 2500] loss: 0.05789815624943003
[Epoch 3, Batch 2600] loss: 0.06418851325739525
[Epoch 3, Batch 2700] loss: 0.05267966430721572
[Epoch 3, Batch 2800] loss: 0.06268277552677319
[Epoch 3, Batch 2900] loss: 0.055367792266770265
[Epoch 3, Batch 3000] loss: 0.08132212948519736
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0714
Validation Accuracy: 0.9778
Overfitting: 0.0714
Best model saved at epoch 3 with validation loss: 0.0714
[Epoch 4, Batch 100] loss: 0.05386732134560589
[Epoch 4, Batch 200] loss: 0.053496282848063854
[Epoch 4, Batch 300] loss: 0.04308026795362821
[Epoch 4, Batch 400] loss: 0.04767622098777793
[Epoch 4, Batch 500] loss: 0.06678864326371695
[Epoch 4, Batch 600] loss: 0.04897819707781309
[Epoch 4, Batch 700] loss: 0.05212168443540577
[Epoch 4, Batch 800] loss: 0.055247183238388974
[Epoch 4, Batch 900] loss: 0.0619717870207387
[Epoch 4, Batch 1000] loss: 0.05107936869550031
[Epoch 4, Batch 1100] loss: 0.05338350943580736
[Epoch 4, Batch 1200] loss: 0.05287091058708029
[Epoch 4, Batch 1300] loss: 0.05734101762645878
[Epoch 4, Batch 1400] loss: 0.04333080704687745
[Epoch 4, Batch 1500] loss: 0.04237255171494326
[Epoch 4, Batch 1600] loss: 0.049915343207903785
[Epoch 4, Batch 1700] loss: 0.04468543527298607
[Epoch 4, Batch 1800] loss: 0.04005088890698971
[Epoch 4, Batch 1900] loss: 0.04520128805655986
[Epoch 4, Batch 2000] loss: 0.03692560503885033
[Epoch 4, Batch 2100] loss: 0.04727406406425871
[Epoch 4, Batch 2200] loss: 0.05305121000739746
[Epoch 4, Batch 2300] loss: 0.04353978958795778
[Epoch 4, Batch 2400] loss: 0.051307596932456366
[Epoch 4, Batch 2500] loss: 0.039916956206288885
[Epoch 4, Batch 2600] loss: 0.05018272615037858
[Epoch 4, Batch 2700] loss: 0.04682496277280734
[Epoch 4, Batch 2800] loss: 0.049217480272200194
[Epoch 4, Batch 2900] loss: 0.038987222679861586
[Epoch 4, Batch 3000] loss: 0.04421690274728462
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9838
Overfitting: 0.0538
Best model saved at epoch 4 with validation loss: 0.0538
[Epoch 5, Batch 100] loss: 0.0439171593215724
[Epoch 5, Batch 200] loss: 0.03899216881720349
[Epoch 5, Batch 300] loss: 0.04020860569624347
[Epoch 5, Batch 400] loss: 0.03258893078309484
[Epoch 5, Batch 500] loss: 0.041281001978641145
[Epoch 5, Batch 600] loss: 0.046016299727343724
[Epoch 5, Batch 700] loss: 0.04900486107333563
[Epoch 5, Batch 800] loss: 0.04646197540772846
[Epoch 5, Batch 900] loss: 0.04481511297344696
[Epoch 5, Batch 1000] loss: 0.045568772511032876
[Epoch 5, Batch 1100] loss: 0.04042228644269926
[Epoch 5, Batch 1200] loss: 0.03833660184667678
[Epoch 5, Batch 1300] loss: 0.027460218114429155
[Epoch 5, Batch 1400] loss: 0.03153072985849576
[Epoch 5, Batch 1500] loss: 0.04648756079899613
[Epoch 5, Batch 1600] loss: 0.03808193402219331
[Epoch 5, Batch 1700] loss: 0.05196249941687711
[Epoch 5, Batch 1800] loss: 0.05286138985189609
[Epoch 5, Batch 1900] loss: 0.05165475573114236
[Epoch 5, Batch 2000] loss: 0.028880274279799778
[Epoch 5, Batch 2100] loss: 0.03911945269472199
[Epoch 5, Batch 2200] loss: 0.0455566962705052
[Epoch 5, Batch 2300] loss: 0.02985341356818026
[Epoch 5, Batch 2400] loss: 0.03671852895175107
[Epoch 5, Batch 2500] loss: 0.035960900332866
[Epoch 5, Batch 2600] loss: 0.045345478506933434
[Epoch 5, Batch 2700] loss: 0.042135754704358985
[Epoch 5, Batch 2800] loss: 0.028814772010518935
[Epoch 5, Batch 2900] loss: 0.030364540036898688
[Epoch 5, Batch 3000] loss: 0.0316640321695013
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9839
Overfitting: 0.0526
Best model saved at epoch 5 with validation loss: 0.0526
[Epoch 6, Batch 100] loss: 0.042937623114557934
[Epoch 6, Batch 200] loss: 0.04332819832372479
[Epoch 6, Batch 300] loss: 0.028030648834173916
[Epoch 6, Batch 400] loss: 0.027326660194885336
[Epoch 6, Batch 500] loss: 0.03042944731270836
[Epoch 6, Batch 600] loss: 0.03530673564200697
[Epoch 6, Batch 700] loss: 0.029834868515317792
[Epoch 6, Batch 800] loss: 0.02932972816801339
[Epoch 6, Batch 900] loss: 0.032710621070546037
[Epoch 6, Batch 1000] loss: 0.02809512890649785
[Epoch 6, Batch 1100] loss: 0.03480023333853751
[Epoch 6, Batch 1200] loss: 0.038323863406658346
[Epoch 6, Batch 1300] loss: 0.030656974776866262
[Epoch 6, Batch 1400] loss: 0.018595590890181483
[Epoch 6, Batch 1500] loss: 0.03484752702759579
[Epoch 6, Batch 1600] loss: 0.0383093080076651
[Epoch 6, Batch 1700] loss: 0.04140147593861911
[Epoch 6, Batch 1800] loss: 0.02909861217318394
[Epoch 6, Batch 1900] loss: 0.03752866384918889
[Epoch 6, Batch 2000] loss: 0.04131781230193155
[Epoch 6, Batch 2100] loss: 0.034714934285802884
[Epoch 6, Batch 2200] loss: 0.03302251799115766
[Epoch 6, Batch 2300] loss: 0.024994134552034666
[Epoch 6, Batch 2400] loss: 0.0389997295136709
[Epoch 6, Batch 2500] loss: 0.03562240740582638
[Epoch 6, Batch 2600] loss: 0.027522226860164666
[Epoch 6, Batch 2700] loss: 0.03169554801592312
[Epoch 6, Batch 2800] loss: 0.040331945754005574
[Epoch 6, Batch 2900] loss: 0.034495959621590376
[Epoch 6, Batch 3000] loss: 0.03988074289125507
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0686
Validation Accuracy: 0.9796
Overfitting: 0.0686
[Epoch 7, Batch 100] loss: 0.024381113027229732
[Epoch 7, Batch 200] loss: 0.02637635742954444
[Epoch 7, Batch 300] loss: 0.024389842872442388
[Epoch 7, Batch 400] loss: 0.025943185842807
[Epoch 7, Batch 500] loss: 0.02479433182277717
[Epoch 7, Batch 600] loss: 0.030696218492521438
[Epoch 7, Batch 700] loss: 0.02572043338579533
[Epoch 7, Batch 800] loss: 0.027455618747699192
[Epoch 7, Batch 900] loss: 0.02241129543624993
[Epoch 7, Batch 1000] loss: 0.051078838164448824
[Epoch 7, Batch 1100] loss: 0.018566081142289477
[Epoch 7, Batch 1200] loss: 0.03179502347818925
[Epoch 7, Batch 1300] loss: 0.03411222647562681
[Epoch 7, Batch 1400] loss: 0.03645884527810267
[Epoch 7, Batch 1500] loss: 0.03394659087549371
[Epoch 7, Batch 1600] loss: 0.02377173086726543
[Epoch 7, Batch 1700] loss: 0.02402115319524455
[Epoch 7, Batch 1800] loss: 0.03017474048123404
[Epoch 7, Batch 1900] loss: 0.017207595003856112
[Epoch 7, Batch 2000] loss: 0.016173676353928385
[Epoch 7, Batch 2100] loss: 0.02927153611308313
[Epoch 7, Batch 2200] loss: 0.02799602274710196
[Epoch 7, Batch 2300] loss: 0.03974014274021101
[Epoch 7, Batch 2400] loss: 0.028560906659113244
[Epoch 7, Batch 2500] loss: 0.030904717366902333
[Epoch 7, Batch 2600] loss: 0.039519870462754625
[Epoch 7, Batch 2700] loss: 0.01891005875659175
[Epoch 7, Batch 2800] loss: 0.03244772455695056
[Epoch 7, Batch 2900] loss: 0.02689617405550962
[Epoch 7, Batch 3000] loss: 0.015438561905939422
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0498
Validation Accuracy: 0.9854
Overfitting: 0.0498
Best model saved at epoch 7 with validation loss: 0.0498
[Epoch 8, Batch 100] loss: 0.011855532296522142
[Epoch 8, Batch 200] loss: 0.021741907653249654
[Epoch 8, Batch 300] loss: 0.023189977630463546
[Epoch 8, Batch 400] loss: 0.025197284563801076
[Epoch 8, Batch 500] loss: 0.017030651822506116
[Epoch 8, Batch 600] loss: 0.017464219946195954
[Epoch 8, Batch 700] loss: 0.02033007813799486
[Epoch 8, Batch 800] loss: 0.013743328625896539
[Epoch 8, Batch 900] loss: 0.032413268071250056
[Epoch 8, Batch 1000] loss: 0.017846171171258904
[Epoch 8, Batch 1100] loss: 0.016821963777238123
[Epoch 8, Batch 1200] loss: 0.01347839546553587
[Epoch 8, Batch 1300] loss: 0.020771298570180077
[Epoch 8, Batch 1400] loss: 0.019964652652724908
[Epoch 8, Batch 1500] loss: 0.04008505081861585
[Epoch 8, Batch 1600] loss: 0.021093796718050725
[Epoch 8, Batch 1700] loss: 0.022030200068402336
[Epoch 8, Batch 1800] loss: 0.04114411208385718
[Epoch 8, Batch 1900] loss: 0.02747893849387765
[Epoch 8, Batch 2000] loss: 0.02570580055591563
[Epoch 8, Batch 2100] loss: 0.026936234905806485
[Epoch 8, Batch 2200] loss: 0.023376579591131305
[Epoch 8, Batch 2300] loss: 0.022789939904578206
[Epoch 8, Batch 2400] loss: 0.024610131993595134
[Epoch 8, Batch 2500] loss: 0.01839625743616125
[Epoch 8, Batch 2600] loss: 0.02552748950255591
[Epoch 8, Batch 2700] loss: 0.02649923389817559
[Epoch 8, Batch 2800] loss: 0.026880940667924732
[Epoch 8, Batch 2900] loss: 0.01635439684418088
[Epoch 8, Batch 3000] loss: 0.029460403298817255
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0609
Validation Accuracy: 0.9822
Overfitting: 0.0609
[Epoch 9, Batch 100] loss: 0.019633432184891716
[Epoch 9, Batch 200] loss: 0.01887309352394368
[Epoch 9, Batch 300] loss: 0.015585750876080056
[Epoch 9, Batch 400] loss: 0.01852280014339158
[Epoch 9, Batch 500] loss: 0.020399336057416805
[Epoch 9, Batch 600] loss: 0.02123350661866425
[Epoch 9, Batch 700] loss: 0.023962122575285322
[Epoch 9, Batch 800] loss: 0.025290527325169024
[Epoch 9, Batch 900] loss: 0.017213963839185453
[Epoch 9, Batch 1000] loss: 0.015353307723185026
[Epoch 9, Batch 1100] loss: 0.019779126111807273
[Epoch 9, Batch 1200] loss: 0.02157411196434623
[Epoch 9, Batch 1300] loss: 0.021053426520475114
[Epoch 9, Batch 1400] loss: 0.011857833094140915
[Epoch 9, Batch 1500] loss: 0.017397991757843557
[Epoch 9, Batch 1600] loss: 0.01746678927599078
[Epoch 9, Batch 1700] loss: 0.035347479544634554
[Epoch 9, Batch 1800] loss: 0.02354336168826194
[Epoch 9, Batch 1900] loss: 0.024139026147277035
[Epoch 9, Batch 2000] loss: 0.02059029549236584
[Epoch 9, Batch 2100] loss: 0.02174512743658852
[Epoch 9, Batch 2200] loss: 0.02904415963072097
[Epoch 9, Batch 2300] loss: 0.016217156602124305
[Epoch 9, Batch 2400] loss: 0.025249190094909862
[Epoch 9, Batch 2500] loss: 0.019474733935130644
[Epoch 9, Batch 2600] loss: 0.011697315859137233
[Epoch 9, Batch 2700] loss: 0.02972073853965412
[Epoch 9, Batch 2800] loss: 0.03579008092452568
[Epoch 9, Batch 2900] loss: 0.01161985724058468
[Epoch 9, Batch 3000] loss: 0.008907011240462453
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9868
Overfitting: 0.0475
Best model saved at epoch 9 with validation loss: 0.0475
[Epoch 10, Batch 100] loss: 0.008752070106784231
[Epoch 10, Batch 200] loss: 0.007529903421934705
[Epoch 10, Batch 300] loss: 0.012023154298099144
[Epoch 10, Batch 400] loss: 0.010240360480293021
[Epoch 10, Batch 500] loss: 0.015108463432097778
[Epoch 10, Batch 600] loss: 0.01802137682856937
[Epoch 10, Batch 700] loss: 0.016308955975473508
[Epoch 10, Batch 800] loss: 0.005884143634702923
[Epoch 10, Batch 900] loss: 0.024392679772677183
[Epoch 10, Batch 1000] loss: 0.017007160814091548
[Epoch 10, Batch 1100] loss: 0.008150453700977778
[Epoch 10, Batch 1200] loss: 0.01491807124767547
[Epoch 10, Batch 1300] loss: 0.008954200890766515
[Epoch 10, Batch 1400] loss: 0.02188882895714414
[Epoch 10, Batch 1500] loss: 0.013251285121959881
[Epoch 10, Batch 1600] loss: 0.01161546070776012
[Epoch 10, Batch 1700] loss: 0.020073856289823198
[Epoch 10, Batch 1800] loss: 0.017771750057472672
[Epoch 10, Batch 1900] loss: 0.013494508430267161
[Epoch 10, Batch 2000] loss: 0.023125165359415403
[Epoch 10, Batch 2100] loss: 0.01917691728704085
[Epoch 10, Batch 2200] loss: 0.01640278511406905
[Epoch 10, Batch 2300] loss: 0.017668086352641693
[Epoch 10, Batch 2400] loss: 0.022939281886319805
[Epoch 10, Batch 2500] loss: 0.011994958005880107
[Epoch 10, Batch 2600] loss: 0.019384363940657748
[Epoch 10, Batch 2700] loss: 0.02588046864473654
[Epoch 10, Batch 2800] loss: 0.01501949840121597
[Epoch 10, Batch 2900] loss: 0.0274065445326778
[Epoch 10, Batch 3000] loss: 0.022716845035270126
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9858
Overfitting: 0.0531
[Epoch 11, Batch 100] loss: 0.011959436748875306
[Epoch 11, Batch 200] loss: 0.013043435238905658
[Epoch 11, Batch 300] loss: 0.00999390840092019
[Epoch 11, Batch 400] loss: 0.018408672704345007
[Epoch 11, Batch 500] loss: 0.014132337832747907
[Epoch 11, Batch 600] loss: 0.02066598497729501
[Epoch 11, Batch 700] loss: 0.010263737152215527
[Epoch 11, Batch 800] loss: 0.011114801570136024
[Epoch 11, Batch 900] loss: 0.020917870234970905
[Epoch 11, Batch 1000] loss: 0.009563124371097728
[Epoch 11, Batch 1100] loss: 0.00953760173968476
[Epoch 11, Batch 1200] loss: 0.008583059021270855
[Epoch 11, Batch 1300] loss: 0.01694552288250634
[Epoch 11, Batch 1400] loss: 0.012250891290177606
[Epoch 11, Batch 1500] loss: 0.01211161463082135
[Epoch 11, Batch 1600] loss: 0.0239280214635437
[Epoch 11, Batch 1700] loss: 0.01172970266930406
[Epoch 11, Batch 1800] loss: 0.023779947172163248
[Epoch 11, Batch 1900] loss: 0.014087842890742195
[Epoch 11, Batch 2000] loss: 0.028190551476805013
[Epoch 11, Batch 2100] loss: 0.01635740567799985
[Epoch 11, Batch 2200] loss: 0.01805554433194402
[Epoch 11, Batch 2300] loss: 0.01601266596137066
[Epoch 11, Batch 2400] loss: 0.012593113665500368
[Epoch 11, Batch 2500] loss: 0.01020524997299276
[Epoch 11, Batch 2600] loss: 0.017757153572613333
[Epoch 11, Batch 2700] loss: 0.024898707104038065
[Epoch 11, Batch 2800] loss: 0.029139396700934413
[Epoch 11, Batch 2900] loss: 0.01878788314379335
[Epoch 11, Batch 3000] loss: 0.027057586024475312
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9872
Overfitting: 0.0469
Best model saved at epoch 11 with validation loss: 0.0469
[Epoch 12, Batch 100] loss: 0.004687500935224307
[Epoch 12, Batch 200] loss: 0.012775562103909123
[Epoch 12, Batch 300] loss: 0.00910267327293468
[Epoch 12, Batch 400] loss: 0.008602005709190053
[Epoch 12, Batch 500] loss: 0.015231902747577806
[Epoch 12, Batch 600] loss: 0.005949823554733485
[Epoch 12, Batch 700] loss: 0.00913127205788669
[Epoch 12, Batch 800] loss: 0.007443134602617647
[Epoch 12, Batch 900] loss: 0.009257691886077737
[Epoch 12, Batch 1000] loss: 0.01897776417368277
[Epoch 12, Batch 1100] loss: 0.019794906322003102
[Epoch 12, Batch 1200] loss: 0.013225136585701876
[Epoch 12, Batch 1300] loss: 0.014750677324332172
[Epoch 12, Batch 1400] loss: 0.011892209437455677
[Epoch 12, Batch 1500] loss: 0.01587244989178316
[Epoch 12, Batch 1600] loss: 0.02674682120916259
[Epoch 12, Batch 1700] loss: 0.01657096327002364
[Epoch 12, Batch 1800] loss: 0.017968344986074955
[Epoch 12, Batch 1900] loss: 0.014363959428301314
[Epoch 12, Batch 2000] loss: 0.011314436618099534
[Epoch 12, Batch 2100] loss: 0.02344896130168763
[Epoch 12, Batch 2200] loss: 0.018551607848867207
[Epoch 12, Batch 2300] loss: 0.01795483886843158
[Epoch 12, Batch 2400] loss: 0.015307366418865058
[Epoch 12, Batch 2500] loss: 0.02385544410919465
[Epoch 12, Batch 2600] loss: 0.00876274385724173
[Epoch 12, Batch 2700] loss: 0.011953443270531352
[Epoch 12, Batch 2800] loss: 0.013792391012948428
[Epoch 12, Batch 2900] loss: 0.016392981224908
[Epoch 12, Batch 3000] loss: 0.010349968523250937
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0571
Validation Accuracy: 0.9850
Overfitting: 0.0571
[Epoch 13, Batch 100] loss: 0.011741889799550336
[Epoch 13, Batch 200] loss: 0.005154335700626689
[Epoch 13, Batch 300] loss: 0.007789493575978667
[Epoch 13, Batch 400] loss: 0.012035339630206181
[Epoch 13, Batch 500] loss: 0.004359450872684647
[Epoch 13, Batch 600] loss: 0.006346750857146617
[Epoch 13, Batch 700] loss: 0.009295709013167652
[Epoch 13, Batch 800] loss: 0.010638653463731771
[Epoch 13, Batch 900] loss: 0.00895640307161102
[Epoch 13, Batch 1000] loss: 0.012343906194835767
[Epoch 13, Batch 1100] loss: 0.009498116606380336
[Epoch 13, Batch 1200] loss: 0.008543207581172822
[Epoch 13, Batch 1300] loss: 0.011751618404480269
[Epoch 13, Batch 1400] loss: 0.016889068202799534
[Epoch 13, Batch 1500] loss: 0.009346964585802198
[Epoch 13, Batch 1600] loss: 0.011041694893339126
[Epoch 13, Batch 1700] loss: 0.011699959365129188
[Epoch 13, Batch 1800] loss: 0.010173074605247053
[Epoch 13, Batch 1900] loss: 0.023902531989968452
[Epoch 13, Batch 2000] loss: 0.012965824895898663
[Epoch 13, Batch 2100] loss: 0.017052935647550383
[Epoch 13, Batch 2200] loss: 0.017773484805559292
[Epoch 13, Batch 2300] loss: 0.010398258903776422
[Epoch 13, Batch 2400] loss: 0.014088327866447798
[Epoch 13, Batch 2500] loss: 0.005535727150131607
[Epoch 13, Batch 2600] loss: 0.01167656505279865
[Epoch 13, Batch 2700] loss: 0.011058256773821995
[Epoch 13, Batch 2800] loss: 0.010297242339203053
[Epoch 13, Batch 2900] loss: 0.010423261993054211
[Epoch 13, Batch 3000] loss: 0.017127266281301557
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0503
Validation Accuracy: 0.9861
Overfitting: 0.0503
[Epoch 14, Batch 100] loss: 0.010642355343206874
[Epoch 14, Batch 200] loss: 0.0139258294922422
[Epoch 14, Batch 300] loss: 0.011078061983466796
[Epoch 14, Batch 400] loss: 0.008967076292227602
[Epoch 14, Batch 500] loss: 0.007356255056712371
[Epoch 14, Batch 600] loss: 0.005357183514373674
[Epoch 14, Batch 700] loss: 0.0076077129351801885
[Epoch 14, Batch 800] loss: 0.005606640120699922
[Epoch 14, Batch 900] loss: 0.006415101564845145
[Epoch 14, Batch 1000] loss: 0.009812831692929649
[Epoch 14, Batch 1100] loss: 0.0024522064840107305
[Epoch 14, Batch 1200] loss: 0.009728995663282945
[Epoch 14, Batch 1300] loss: 0.013214024814077447
[Epoch 14, Batch 1400] loss: 0.006982080164148101
[Epoch 14, Batch 1500] loss: 0.009506422100682812
[Epoch 14, Batch 1600] loss: 0.007136280559615927
[Epoch 14, Batch 1700] loss: 0.011182272821680782
[Epoch 14, Batch 1800] loss: 0.0066522145525414085
[Epoch 14, Batch 1900] loss: 0.01203084596481176
[Epoch 14, Batch 2000] loss: 0.014514925677656266
[Epoch 14, Batch 2100] loss: 0.005060767542654503
[Epoch 14, Batch 2200] loss: 0.008472395204287863
[Epoch 14, Batch 2300] loss: 0.02050025440820704
[Epoch 14, Batch 2400] loss: 0.014964808355180138
[Epoch 14, Batch 2500] loss: 0.009543809622595632
[Epoch 14, Batch 2600] loss: 0.014900763969024525
[Epoch 14, Batch 2700] loss: 0.004876617635595153
[Epoch 14, Batch 2800] loss: 0.013307605482428073
[Epoch 14, Batch 2900] loss: 0.011269784768483077
[Epoch 14, Batch 3000] loss: 0.015987656897403894
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9864
Overfitting: 0.0567
[Epoch 15, Batch 100] loss: 0.010088954903809082
[Epoch 15, Batch 200] loss: 0.008065375996979469
[Epoch 15, Batch 300] loss: 0.011493961766527718
[Epoch 15, Batch 400] loss: 0.019479961973665354
[Epoch 15, Batch 500] loss: 0.0060276932497117745
[Epoch 15, Batch 600] loss: 0.007896187886507278
[Epoch 15, Batch 700] loss: 0.005611873101140645
[Epoch 15, Batch 800] loss: 0.008395926256335997
[Epoch 15, Batch 900] loss: 0.005069836606587046
[Epoch 15, Batch 1000] loss: 0.005887407876583381
[Epoch 15, Batch 1100] loss: 0.006802031972390523
[Epoch 15, Batch 1200] loss: 0.009495330212566842
[Epoch 15, Batch 1300] loss: 0.019778322955500586
[Epoch 15, Batch 1400] loss: 0.011566856226799017
[Epoch 15, Batch 1500] loss: 0.01652547049933446
[Epoch 15, Batch 1600] loss: 0.00869877470455492
[Epoch 15, Batch 1700] loss: 0.0045136496024434794
[Epoch 15, Batch 1800] loss: 0.007740144439208052
[Epoch 15, Batch 1900] loss: 0.010065541107913988
[Epoch 15, Batch 2000] loss: 0.0056082178998951805
[Epoch 15, Batch 2100] loss: 0.01088724588325462
[Epoch 15, Batch 2200] loss: 0.01126825842776043
[Epoch 15, Batch 2300] loss: 0.008533215293559238
[Epoch 15, Batch 2400] loss: 0.022653781673213302
[Epoch 15, Batch 2500] loss: 0.02001603502172884
[Epoch 15, Batch 2600] loss: 0.017690081950206604
[Epoch 15, Batch 2700] loss: 0.013683367393898607
[Epoch 15, Batch 2800] loss: 0.012911046254893109
[Epoch 15, Batch 2900] loss: 0.025997832689763526
[Epoch 15, Batch 3000] loss: 0.00699390019850398
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9855
Overfitting: 0.0593
[Epoch 16, Batch 100] loss: 0.00632116708094145
[Epoch 16, Batch 200] loss: 0.008192060277071676
[Epoch 16, Batch 300] loss: 0.008286278549265945
[Epoch 16, Batch 400] loss: 0.0061359525243449295
[Epoch 16, Batch 500] loss: 0.010607061221821822
[Epoch 16, Batch 600] loss: 0.0027937704229850624
[Epoch 16, Batch 700] loss: 0.00878627025605283
[Epoch 16, Batch 800] loss: 0.0037629736362987387
[Epoch 16, Batch 900] loss: 0.004578117867345668
[Epoch 16, Batch 1000] loss: 0.007552450524007242
[Epoch 16, Batch 1100] loss: 0.004852365112782309
[Epoch 16, Batch 1200] loss: 0.0038643618287551363
[Epoch 16, Batch 1300] loss: 0.008731924910421754
[Epoch 16, Batch 1400] loss: 0.007491210708394647
[Epoch 16, Batch 1500] loss: 0.010078483706205076
[Epoch 16, Batch 1600] loss: 0.0031457951774063984
[Epoch 16, Batch 1700] loss: 0.004826906719518718
[Epoch 16, Batch 1800] loss: 0.011266064979998021
[Epoch 16, Batch 1900] loss: 0.004648243487419847
[Epoch 16, Batch 2000] loss: 0.008868978164080658
[Epoch 16, Batch 2100] loss: 0.01040450264779679
[Epoch 16, Batch 2200] loss: 0.005271448286009388
[Epoch 16, Batch 2300] loss: 0.011931567912709511
[Epoch 16, Batch 2400] loss: 0.017234173913639097
[Epoch 16, Batch 2500] loss: 0.01244189246689075
[Epoch 16, Batch 2600] loss: 0.010292608241261405
[Epoch 16, Batch 2700] loss: 0.02341979077063293
[Epoch 16, Batch 2800] loss: 0.010337167982683013
[Epoch 16, Batch 2900] loss: 0.011818280182803278
[Epoch 16, Batch 3000] loss: 0.017348573014869542
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9884
Overfitting: 0.0513
[Epoch 17, Batch 100] loss: 0.01067214409221151
[Epoch 17, Batch 200] loss: 0.003275809645519985
[Epoch 17, Batch 300] loss: 0.0051229300137265454
[Epoch 17, Batch 400] loss: 0.0087519189263719
[Epoch 17, Batch 500] loss: 0.009776579266090124
[Epoch 17, Batch 600] loss: 0.015733129932836862
[Epoch 17, Batch 700] loss: 0.0052685811391870625
[Epoch 17, Batch 800] loss: 0.004788631281006701
[Epoch 17, Batch 900] loss: 0.009204217174798827
[Epoch 17, Batch 1000] loss: 0.0034695350183625707
[Epoch 17, Batch 1100] loss: 0.004393522610097165
[Epoch 17, Batch 1200] loss: 0.007257554534458848
[Epoch 17, Batch 1300] loss: 0.004705411932856691
[Epoch 17, Batch 1400] loss: 0.002855238466068073
[Epoch 17, Batch 1500] loss: 0.0025196744017688386
[Epoch 17, Batch 1600] loss: 0.007317525822487312
[Epoch 17, Batch 1700] loss: 0.005490857733249878
[Epoch 17, Batch 1800] loss: 0.0024189617315482793
[Epoch 17, Batch 1900] loss: 0.003967638063506627
[Epoch 17, Batch 2000] loss: 0.006980826521752306
[Epoch 17, Batch 2100] loss: 0.0034854550597967202
[Epoch 17, Batch 2200] loss: 0.008091291984545421
[Epoch 17, Batch 2300] loss: 0.008529549053337178
[Epoch 17, Batch 2400] loss: 0.006929408586016304
[Epoch 17, Batch 2500] loss: 0.007554894512261949
[Epoch 17, Batch 2600] loss: 0.009136795472178818
[Epoch 17, Batch 2700] loss: 0.007794900107018634
[Epoch 17, Batch 2800] loss: 0.006661775420268015
[Epoch 17, Batch 2900] loss: 0.013901377260116447
[Epoch 17, Batch 3000] loss: 0.014034363040486823
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0640
Validation Accuracy: 0.9858
Overfitting: 0.0640
[Epoch 18, Batch 100] loss: 0.004147701414079279
[Epoch 18, Batch 200] loss: 0.009708464994180871
[Epoch 18, Batch 300] loss: 0.006846543436229098
[Epoch 18, Batch 400] loss: 0.0038861311685116106
[Epoch 18, Batch 500] loss: 0.003579687305203834
[Epoch 18, Batch 600] loss: 0.003004368631148395
[Epoch 18, Batch 700] loss: 0.005728476282470467
[Epoch 18, Batch 800] loss: 0.006616488585626712
[Epoch 18, Batch 900] loss: 0.0027614839169882543
[Epoch 18, Batch 1000] loss: 0.017759764321019063
[Epoch 18, Batch 1100] loss: 0.011491462524467123
[Epoch 18, Batch 1200] loss: 0.004172246109204707
[Epoch 18, Batch 1300] loss: 0.0033438055809949675
[Epoch 18, Batch 1400] loss: 0.00539943665482113
[Epoch 18, Batch 1500] loss: 0.002531946484583898
[Epoch 18, Batch 1600] loss: 0.007219782683787344
[Epoch 18, Batch 1700] loss: 0.0027428473111089603
[Epoch 18, Batch 1800] loss: 0.00504316371355344
[Epoch 18, Batch 1900] loss: 0.00588899671687038
[Epoch 18, Batch 2000] loss: 0.0020593465559670676
[Epoch 18, Batch 2100] loss: 0.006625626561673101
[Epoch 18, Batch 2200] loss: 0.004987002658420749
[Epoch 18, Batch 2300] loss: 0.0033053490984684686
[Epoch 18, Batch 2400] loss: 0.0030258492459491037
[Epoch 18, Batch 2500] loss: 0.005794037412513795
[Epoch 18, Batch 2600] loss: 0.0060916954713256645
[Epoch 18, Batch 2700] loss: 0.002415646004670862
[Epoch 18, Batch 2800] loss: 0.003632958442998984
[Epoch 18, Batch 2900] loss: 0.006149616602977375
[Epoch 18, Batch 3000] loss: 0.007288401541533176
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0683
Validation Accuracy: 0.9842
Overfitting: 0.0683
[Epoch 19, Batch 100] loss: 0.011088723608351891
[Epoch 19, Batch 200] loss: 0.002137397542689996
[Epoch 19, Batch 300] loss: 0.0022733298213780274
[Epoch 19, Batch 400] loss: 0.004547022932487437
[Epoch 19, Batch 500] loss: 0.0015148611724171523
[Epoch 19, Batch 600] loss: 0.005950615895193465
[Epoch 19, Batch 700] loss: 0.005124773238700158
[Epoch 19, Batch 800] loss: 0.002982077291633516
[Epoch 19, Batch 900] loss: 0.0021112043010059977
[Epoch 19, Batch 1000] loss: 0.008763302077870207
[Epoch 19, Batch 1100] loss: 0.0016426033237632964
[Epoch 19, Batch 1200] loss: 0.0013071319907146516
[Epoch 19, Batch 1300] loss: 0.00783486499776359
[Epoch 19, Batch 1400] loss: 0.01239214808525631
[Epoch 19, Batch 1500] loss: 0.009501043531759592
[Epoch 19, Batch 1600] loss: 0.008002180230856198
[Epoch 19, Batch 1700] loss: 0.00862062127464725
[Epoch 19, Batch 1800] loss: 0.006454120833509336
[Epoch 19, Batch 1900] loss: 0.0046007819425962285
[Epoch 19, Batch 2000] loss: 0.010977597560292693
[Epoch 19, Batch 2100] loss: 0.007369923909237883
[Epoch 19, Batch 2200] loss: 0.01517131952019838
[Epoch 19, Batch 2300] loss: 0.010973628057318621
[Epoch 19, Batch 2400] loss: 0.003718001508461839
[Epoch 19, Batch 2500] loss: 0.0048914913610991475
[Epoch 19, Batch 2600] loss: 0.008976675451955317
[Epoch 19, Batch 2700] loss: 0.004787559949775897
[Epoch 19, Batch 2800] loss: 0.01644739955466875
[Epoch 19, Batch 2900] loss: 0.014376522687465965
[Epoch 19, Batch 3000] loss: 0.017220191865716286
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9872
Overfitting: 0.0559
[Epoch 20, Batch 100] loss: 0.003090846531619604
[Epoch 20, Batch 200] loss: 0.004184549269064633
[Epoch 20, Batch 300] loss: 0.0021752967116854902
[Epoch 20, Batch 400] loss: 0.0020899028589039404
[Epoch 20, Batch 500] loss: 0.0026941040052008702
[Epoch 20, Batch 600] loss: 0.0025080521560573743
[Epoch 20, Batch 700] loss: 0.002864931393327126
[Epoch 20, Batch 800] loss: 0.008790475565922265
[Epoch 20, Batch 900] loss: 0.003991258219293954
[Epoch 20, Batch 1000] loss: 0.0029429600898177454
[Epoch 20, Batch 1100] loss: 0.004475670370963485
[Epoch 20, Batch 1200] loss: 0.007490934454627904
[Epoch 20, Batch 1300] loss: 0.0050087277572635
[Epoch 20, Batch 1400] loss: 0.006080642987025015
[Epoch 20, Batch 1500] loss: 0.002390802807536545
[Epoch 20, Batch 1600] loss: 0.003621725641388451
[Epoch 20, Batch 1700] loss: 0.01406608004373961
[Epoch 20, Batch 1800] loss: 0.005973143873023119
[Epoch 20, Batch 1900] loss: 0.0005050097537227316
[Epoch 20, Batch 2000] loss: 0.0015708130020783528
[Epoch 20, Batch 2100] loss: 0.0023939979533831135
[Epoch 20, Batch 2200] loss: 0.001887526250131657
[Epoch 20, Batch 2300] loss: 0.009150800867424742
[Epoch 20, Batch 2400] loss: 0.004404308135790061
[Epoch 20, Batch 2500] loss: 0.0059179772390603345
[Epoch 20, Batch 2600] loss: 0.0018707477788797177
[Epoch 20, Batch 2700] loss: 0.004243695078792911
[Epoch 20, Batch 2800] loss: 0.003650177575509641
[Epoch 20, Batch 2900] loss: 0.005831005915812675
[Epoch 20, Batch 3000] loss: 0.004670326620066128
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9890
Overfitting: 0.0536
[Epoch 21, Batch 100] loss: 0.0012218412587137052
[Epoch 21, Batch 200] loss: 0.0025035496429868507
[Epoch 21, Batch 300] loss: 0.003441155633905666
[Epoch 21, Batch 400] loss: 0.0022321941192478788
[Epoch 21, Batch 500] loss: 0.0039801202431092265
[Epoch 21, Batch 600] loss: 0.0014013330461762053
[Epoch 21, Batch 700] loss: 0.0011097196708558866
[Epoch 21, Batch 800] loss: 0.0025892967059259675
[Epoch 21, Batch 900] loss: 0.006490254763412722
[Epoch 21, Batch 1000] loss: 0.0015006540990368045
[Epoch 21, Batch 1100] loss: 0.0016172630531382781
[Epoch 21, Batch 1200] loss: 0.000695932421692369
[Epoch 21, Batch 1300] loss: 0.007689778010302106
[Epoch 21, Batch 1400] loss: 0.0028577778125791473
[Epoch 21, Batch 1500] loss: 0.000850219108428405
[Epoch 21, Batch 1600] loss: 0.0016663245020555894
[Epoch 21, Batch 1700] loss: 0.0009267597433823837
[Epoch 21, Batch 1800] loss: 0.004727950551282199
[Epoch 21, Batch 1900] loss: 0.0013135919299113662
[Epoch 21, Batch 2000] loss: 0.0007717343856202552
[Epoch 21, Batch 2100] loss: 0.0007375740649457186
[Epoch 21, Batch 2200] loss: 0.0033472840628801137
[Epoch 21, Batch 2300] loss: 0.0012201835068704093
[Epoch 21, Batch 2400] loss: 0.007304627946126177
[Epoch 21, Batch 2500] loss: 0.0050588120027610685
[Epoch 21, Batch 2600] loss: 0.012134255011245614
[Epoch 21, Batch 2700] loss: 0.007319663480346996
[Epoch 21, Batch 2800] loss: 0.0076615861382359094
[Epoch 21, Batch 2900] loss: 0.00632904575264206
[Epoch 21, Batch 3000] loss: 0.007821148284880905
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0602
Validation Accuracy: 0.9873
Overfitting: 0.0602
[Epoch 22, Batch 100] loss: 0.00098331366930962
[Epoch 22, Batch 200] loss: 0.006174672572815734
[Epoch 22, Batch 300] loss: 0.004143989812498603
[Epoch 22, Batch 400] loss: 0.006952936311366855
[Epoch 22, Batch 500] loss: 0.0023079014001441854
[Epoch 22, Batch 600] loss: 0.002009569113035572
[Epoch 22, Batch 700] loss: 0.004139837172274135
[Epoch 22, Batch 800] loss: 0.0014397644742811355
[Epoch 22, Batch 900] loss: 0.0019108129484839153
[Epoch 22, Batch 1000] loss: 0.0011628206221988612
[Epoch 22, Batch 1100] loss: 0.0009758839690694199
[Epoch 22, Batch 1200] loss: 0.0011531423894323822
[Epoch 22, Batch 1300] loss: 0.0009726491382100288
[Epoch 22, Batch 1400] loss: 0.0004270190908751026
[Epoch 22, Batch 1500] loss: 0.0007291269316535675
[Epoch 22, Batch 1600] loss: 0.0021025647332051987
[Epoch 22, Batch 1700] loss: 0.0014435045805324441
[Epoch 22, Batch 1800] loss: 0.00037057815285065134
[Epoch 22, Batch 1900] loss: 0.0009200898474665076
[Epoch 22, Batch 2000] loss: 0.0005791997163954931
[Epoch 22, Batch 2100] loss: 0.0008784947669682719
[Epoch 22, Batch 2200] loss: 0.010902426522430772
[Epoch 22, Batch 2300] loss: 0.005958306213843918
[Epoch 22, Batch 2400] loss: 0.007656549664995249
[Epoch 22, Batch 2500] loss: 0.0032437572768984737
[Epoch 22, Batch 2600] loss: 0.004709801314722028
[Epoch 22, Batch 2700] loss: 0.0013178805940790995
[Epoch 22, Batch 2800] loss: 0.0006420998938602906
[Epoch 22, Batch 2900] loss: 0.0008365433798979804
[Epoch 22, Batch 3000] loss: 0.0015583199401075732
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9898
Overfitting: 0.0515
[Epoch 23, Batch 100] loss: 0.0006302494797674107
[Epoch 23, Batch 200] loss: 0.0008665705173467586
[Epoch 23, Batch 300] loss: 0.0072073155996025574
[Epoch 23, Batch 400] loss: 0.002180648928009994
[Epoch 23, Batch 500] loss: 0.004461793019980429
[Epoch 23, Batch 600] loss: 0.0048703287025306
[Epoch 23, Batch 700] loss: 0.0009338669087560447
[Epoch 23, Batch 800] loss: 0.0008211649375996188
[Epoch 23, Batch 900] loss: 0.001226708871152442
[Epoch 23, Batch 1000] loss: 0.0006904605027794642
[Epoch 23, Batch 1100] loss: 0.0012647289733038036
[Epoch 23, Batch 1200] loss: 0.0013127571882026246
[Epoch 23, Batch 1300] loss: 0.0008695124464506421
[Epoch 23, Batch 1400] loss: 0.0013934879185395932
[Epoch 23, Batch 1500] loss: 0.0008534922711487525
[Epoch 23, Batch 1600] loss: 0.0006387590956281031
[Epoch 23, Batch 1700] loss: 0.001349096419563125
[Epoch 23, Batch 1800] loss: 0.0007393304587375038
[Epoch 23, Batch 1900] loss: 0.0013910797954178333
[Epoch 23, Batch 2000] loss: 0.001417956154631166
[Epoch 23, Batch 2100] loss: 0.0011588510521755423
[Epoch 23, Batch 2200] loss: 0.0005488471883133527
[Epoch 23, Batch 2300] loss: 0.0007346554350897171
[Epoch 23, Batch 2400] loss: 0.005604626233439909
[Epoch 23, Batch 2500] loss: 0.006450829818894022
[Epoch 23, Batch 2600] loss: 0.0029267478399246727
[Epoch 23, Batch 2700] loss: 0.0047687894108892695
[Epoch 23, Batch 2800] loss: 0.0020628288467142396
[Epoch 23, Batch 2900] loss: 0.0048698242975967745
[Epoch 23, Batch 3000] loss: 0.0015758558380246956
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9885
Overfitting: 0.0556
[Epoch 24, Batch 100] loss: 0.0029963736823924547
[Epoch 24, Batch 200] loss: 0.0006227857459026786
[Epoch 24, Batch 300] loss: 0.0007689143539673715
[Epoch 24, Batch 400] loss: 0.00030746061445239723
[Epoch 24, Batch 500] loss: 0.0006736721046362249
[Epoch 24, Batch 600] loss: 0.0005133234201149151
[Epoch 24, Batch 700] loss: 0.0004251974310991313
[Epoch 24, Batch 800] loss: 0.0016561827190467683
[Epoch 24, Batch 900] loss: 0.009452599277852905
[Epoch 24, Batch 1000] loss: 0.0014619682531001388
[Epoch 24, Batch 1100] loss: 0.0015529994648631718
[Epoch 24, Batch 1200] loss: 0.000782032980558891
[Epoch 24, Batch 1300] loss: 0.0015829700803024593
[Epoch 24, Batch 1400] loss: 0.000807333820487095
[Epoch 24, Batch 1500] loss: 0.0014076860839226059
[Epoch 24, Batch 1600] loss: 0.0009473707801307363
[Epoch 24, Batch 1700] loss: 0.0009178861030212726
[Epoch 24, Batch 1800] loss: 0.0007119840766168383
[Epoch 24, Batch 1900] loss: 0.0007566379215387675
[Epoch 24, Batch 2000] loss: 0.0004966754558668285
[Epoch 24, Batch 2100] loss: 0.0014047062034399894
[Epoch 24, Batch 2200] loss: 0.0011593864146332144
[Epoch 24, Batch 2300] loss: 0.00045993337873839746
[Epoch 24, Batch 2400] loss: 0.000522488102185914
[Epoch 24, Batch 2500] loss: 0.00026649033764503116
[Epoch 24, Batch 2600] loss: 0.0003374516507285463
[Epoch 24, Batch 2700] loss: 0.0011858687488577014
[Epoch 24, Batch 2800] loss: 0.0005884750712739217
[Epoch 24, Batch 2900] loss: 0.00813592599365414
[Epoch 24, Batch 3000] loss: 0.0003522492346662531
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9891
Overfitting: 0.0531
Fold 3 validation loss: 0.0531
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.300267996788025
[Epoch 1, Batch 200] loss: 2.285854151248932
[Epoch 1, Batch 300] loss: 2.241940577030182
[Epoch 1, Batch 400] loss: 1.8265796732902526
[Epoch 1, Batch 500] loss: 0.8494282722473144
[Epoch 1, Batch 600] loss: 0.609684965312481
[Epoch 1, Batch 700] loss: 0.45382888689637185
[Epoch 1, Batch 800] loss: 0.4075907464325428
[Epoch 1, Batch 900] loss: 0.31569046173244714
[Epoch 1, Batch 1000] loss: 0.3000566153228283
[Epoch 1, Batch 1100] loss: 0.28378955606371165
[Epoch 1, Batch 1200] loss: 0.26735915660858156
[Epoch 1, Batch 1300] loss: 0.2141873051971197
[Epoch 1, Batch 1400] loss: 0.23469509069807828
[Epoch 1, Batch 1500] loss: 0.1893540619686246
[Epoch 1, Batch 1600] loss: 0.1795408463664353
[Epoch 1, Batch 1700] loss: 0.1879075155220926
[Epoch 1, Batch 1800] loss: 0.17036182505078615
[Epoch 1, Batch 1900] loss: 0.1595996981486678
[Epoch 1, Batch 2000] loss: 0.15342330579413102
[Epoch 1, Batch 2100] loss: 0.1247470885142684
[Epoch 1, Batch 2200] loss: 0.16443346540443599
[Epoch 1, Batch 2300] loss: 0.1351018715882674
[Epoch 1, Batch 2400] loss: 0.14402559934649617
[Epoch 1, Batch 2500] loss: 0.14057329387404024
[Epoch 1, Batch 2600] loss: 0.1447204055264592
[Epoch 1, Batch 2700] loss: 0.13453267036005856
[Epoch 1, Batch 2800] loss: 0.11348803239059635
[Epoch 1, Batch 2900] loss: 0.10158396478742361
[Epoch 1, Batch 3000] loss: 0.1197870449803304
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1021
Validation Accuracy: 0.9671
Overfitting: 0.1021
Best model saved at epoch 1 with validation loss: 0.1021
[Epoch 2, Batch 100] loss: 0.09818518843501806
[Epoch 2, Batch 200] loss: 0.11058264036895707
[Epoch 2, Batch 300] loss: 0.10156510567758233
[Epoch 2, Batch 400] loss: 0.1231941891182214
[Epoch 2, Batch 500] loss: 0.10656047045136802
[Epoch 2, Batch 600] loss: 0.10848591033020057
[Epoch 2, Batch 700] loss: 0.09646396498661489
[Epoch 2, Batch 800] loss: 0.11886603720020503
[Epoch 2, Batch 900] loss: 0.11122471248963847
[Epoch 2, Batch 1000] loss: 0.09006763295270502
[Epoch 2, Batch 1100] loss: 0.08258207707549445
[Epoch 2, Batch 1200] loss: 0.10071228554763366
[Epoch 2, Batch 1300] loss: 0.0770486831641756
[Epoch 2, Batch 1400] loss: 0.10049574036849662
[Epoch 2, Batch 1500] loss: 0.08885426699649543
[Epoch 2, Batch 1600] loss: 0.07817017096444033
[Epoch 2, Batch 1700] loss: 0.08483207291923463
[Epoch 2, Batch 1800] loss: 0.0786884319409728
[Epoch 2, Batch 1900] loss: 0.08922835088218563
[Epoch 2, Batch 2000] loss: 0.07178648337896448
[Epoch 2, Batch 2100] loss: 0.05298924219678156
[Epoch 2, Batch 2200] loss: 0.07795592928538099
[Epoch 2, Batch 2300] loss: 0.0837353295867797
[Epoch 2, Batch 2400] loss: 0.10089245353941806
[Epoch 2, Batch 2500] loss: 0.07730374997132458
[Epoch 2, Batch 2600] loss: 0.07134134880267083
[Epoch 2, Batch 2700] loss: 0.06689069638377987
[Epoch 2, Batch 2800] loss: 0.08545215268735774
[Epoch 2, Batch 2900] loss: 0.09253966553602368
[Epoch 2, Batch 3000] loss: 0.06204491384793073
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0717
Validation Accuracy: 0.9766
Overfitting: 0.0717
Best model saved at epoch 2 with validation loss: 0.0717
[Epoch 3, Batch 100] loss: 0.03990561041980982
[Epoch 3, Batch 200] loss: 0.07108784711337648
[Epoch 3, Batch 300] loss: 0.0679563011979917
[Epoch 3, Batch 400] loss: 0.0988452640583273
[Epoch 3, Batch 500] loss: 0.06266720254672692
[Epoch 3, Batch 600] loss: 0.06598165163712111
[Epoch 3, Batch 700] loss: 0.07607218520599418
[Epoch 3, Batch 800] loss: 0.054701270830119025
[Epoch 3, Batch 900] loss: 0.06863927951810184
[Epoch 3, Batch 1000] loss: 0.05514085824543145
[Epoch 3, Batch 1100] loss: 0.06381911280099302
[Epoch 3, Batch 1200] loss: 0.06437247245456092
[Epoch 3, Batch 1300] loss: 0.06333637911360711
[Epoch 3, Batch 1400] loss: 0.07056172788725235
[Epoch 3, Batch 1500] loss: 0.06540642659325385
[Epoch 3, Batch 1600] loss: 0.05631945188972168
[Epoch 3, Batch 1700] loss: 0.06888227942952653
[Epoch 3, Batch 1800] loss: 0.040635351241799074
[Epoch 3, Batch 1900] loss: 0.08250493772677146
[Epoch 3, Batch 2000] loss: 0.10334428090136498
[Epoch 3, Batch 2100] loss: 0.06570464743534103
[Epoch 3, Batch 2200] loss: 0.06019190281454939
[Epoch 3, Batch 2300] loss: 0.05873576199548552
[Epoch 3, Batch 2400] loss: 0.060898721335688605
[Epoch 3, Batch 2500] loss: 0.055483496718807146
[Epoch 3, Batch 2600] loss: 0.06278253361117095
[Epoch 3, Batch 2700] loss: 0.05613933733140584
[Epoch 3, Batch 2800] loss: 0.05339929666777607
[Epoch 3, Batch 2900] loss: 0.02980506887222873
[Epoch 3, Batch 3000] loss: 0.06510121573228389
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9835
Overfitting: 0.0537
Best model saved at epoch 3 with validation loss: 0.0537
[Epoch 4, Batch 100] loss: 0.051960204445640555
[Epoch 4, Batch 200] loss: 0.050901834739779585
[Epoch 4, Batch 300] loss: 0.05421409647853579
[Epoch 4, Batch 400] loss: 0.043979989894578464
[Epoch 4, Batch 500] loss: 0.07271820179885254
[Epoch 4, Batch 600] loss: 0.033304995950311424
[Epoch 4, Batch 700] loss: 0.04978064626920968
[Epoch 4, Batch 800] loss: 0.05502724439953454
[Epoch 4, Batch 900] loss: 0.04702012078720145
[Epoch 4, Batch 1000] loss: 0.0487307431618683
[Epoch 4, Batch 1100] loss: 0.04268895656234235
[Epoch 4, Batch 1200] loss: 0.04352066131919855
[Epoch 4, Batch 1300] loss: 0.04180601544037927
[Epoch 4, Batch 1400] loss: 0.046402669285889715
[Epoch 4, Batch 1500] loss: 0.032822247361182236
[Epoch 4, Batch 1600] loss: 0.062306142863235436
[Epoch 4, Batch 1700] loss: 0.03837336995304213
[Epoch 4, Batch 1800] loss: 0.04846486019145232
[Epoch 4, Batch 1900] loss: 0.06056419817148708
[Epoch 4, Batch 2000] loss: 0.06327378168993164
[Epoch 4, Batch 2100] loss: 0.044039196420635564
[Epoch 4, Batch 2200] loss: 0.034740371339721604
[Epoch 4, Batch 2300] loss: 0.050449379978963406
[Epoch 4, Batch 2400] loss: 0.04796788755629677
[Epoch 4, Batch 2500] loss: 0.0412486133154016
[Epoch 4, Batch 2600] loss: 0.037281335846855654
[Epoch 4, Batch 2700] loss: 0.041090758767968506
[Epoch 4, Batch 2800] loss: 0.05865352144770441
[Epoch 4, Batch 2900] loss: 0.05193793962418567
[Epoch 4, Batch 3000] loss: 0.06035704679379705
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9844
Overfitting: 0.0484
Best model saved at epoch 4 with validation loss: 0.0484
[Epoch 5, Batch 100] loss: 0.037290420166100374
[Epoch 5, Batch 200] loss: 0.03196419993444579
[Epoch 5, Batch 300] loss: 0.039976992192678154
[Epoch 5, Batch 400] loss: 0.03264427812435315
[Epoch 5, Batch 500] loss: 0.0366731404834718
[Epoch 5, Batch 600] loss: 0.0377006469538901
[Epoch 5, Batch 700] loss: 0.048249803809740116
[Epoch 5, Batch 800] loss: 0.04154627760362928
[Epoch 5, Batch 900] loss: 0.03549529395007994
[Epoch 5, Batch 1000] loss: 0.042801827245857564
[Epoch 5, Batch 1100] loss: 0.03825082477036631
[Epoch 5, Batch 1200] loss: 0.018473152516671688
[Epoch 5, Batch 1300] loss: 0.03373471750979661
[Epoch 5, Batch 1400] loss: 0.05041028803389054
[Epoch 5, Batch 1500] loss: 0.03999841282842681
[Epoch 5, Batch 1600] loss: 0.03535363939452509
[Epoch 5, Batch 1700] loss: 0.03310215201236133
[Epoch 5, Batch 1800] loss: 0.03915124816900061
[Epoch 5, Batch 1900] loss: 0.03707463640879723
[Epoch 5, Batch 2000] loss: 0.054469242715204015
[Epoch 5, Batch 2100] loss: 0.04667143988481257
[Epoch 5, Batch 2200] loss: 0.040854599430022065
[Epoch 5, Batch 2300] loss: 0.03820895882890909
[Epoch 5, Batch 2400] loss: 0.033597929959069
[Epoch 5, Batch 2500] loss: 0.046649690075719265
[Epoch 5, Batch 2600] loss: 0.04109936926426599
[Epoch 5, Batch 2700] loss: 0.040103955375052465
[Epoch 5, Batch 2800] loss: 0.035194531534871204
[Epoch 5, Batch 2900] loss: 0.04574695315193821
[Epoch 5, Batch 3000] loss: 0.04875217256776523
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9831
Overfitting: 0.0522
[Epoch 6, Batch 100] loss: 0.04278311021087575
[Epoch 6, Batch 200] loss: 0.033712956577655856
[Epoch 6, Batch 300] loss: 0.02591147272119997
[Epoch 6, Batch 400] loss: 0.022478083166352008
[Epoch 6, Batch 500] loss: 0.02315540377603611
[Epoch 6, Batch 600] loss: 0.02218988703749346
[Epoch 6, Batch 700] loss: 0.051178777579625606
[Epoch 6, Batch 800] loss: 0.03274888054213079
[Epoch 6, Batch 900] loss: 0.03294588896111236
[Epoch 6, Batch 1000] loss: 0.022992036576397368
[Epoch 6, Batch 1100] loss: 0.04248829434225627
[Epoch 6, Batch 1200] loss: 0.020293212204705924
[Epoch 6, Batch 1300] loss: 0.03808102762355702
[Epoch 6, Batch 1400] loss: 0.04725793304605759
[Epoch 6, Batch 1500] loss: 0.039373589862516385
[Epoch 6, Batch 1600] loss: 0.0304098856964265
[Epoch 6, Batch 1700] loss: 0.033765323795960284
[Epoch 6, Batch 1800] loss: 0.03387936972721946
[Epoch 6, Batch 1900] loss: 0.030881510294602777
[Epoch 6, Batch 2000] loss: 0.02911242175301595
[Epoch 6, Batch 2100] loss: 0.023449106706975725
[Epoch 6, Batch 2200] loss: 0.030608858840278117
[Epoch 6, Batch 2300] loss: 0.03187295470524987
[Epoch 6, Batch 2400] loss: 0.04147397561362595
[Epoch 6, Batch 2500] loss: 0.03170043095102301
[Epoch 6, Batch 2600] loss: 0.030037001912423877
[Epoch 6, Batch 2700] loss: 0.019860150016465922
[Epoch 6, Batch 2800] loss: 0.04354980942021939
[Epoch 6, Batch 2900] loss: 0.043019622323845395
[Epoch 6, Batch 3000] loss: 0.02858100983168697
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0404
Validation Accuracy: 0.9870
Overfitting: 0.0404
Best model saved at epoch 6 with validation loss: 0.0404
[Epoch 7, Batch 100] loss: 0.02524240187900432
[Epoch 7, Batch 200] loss: 0.01636371747674275
[Epoch 7, Batch 300] loss: 0.015474512281853094
[Epoch 7, Batch 400] loss: 0.024916892195069523
[Epoch 7, Batch 500] loss: 0.02923797371906403
[Epoch 7, Batch 600] loss: 0.04310289497694612
[Epoch 7, Batch 700] loss: 0.027834692907417774
[Epoch 7, Batch 800] loss: 0.03362566807416442
[Epoch 7, Batch 900] loss: 0.03297278250947784
[Epoch 7, Batch 1000] loss: 0.031545303764505664
[Epoch 7, Batch 1100] loss: 0.03247718731217901
[Epoch 7, Batch 1200] loss: 0.022510505625177757
[Epoch 7, Batch 1300] loss: 0.012466276951163308
[Epoch 7, Batch 1400] loss: 0.029704319012671475
[Epoch 7, Batch 1500] loss: 0.022641812263464088
[Epoch 7, Batch 1600] loss: 0.040851140175873296
[Epoch 7, Batch 1700] loss: 0.024545273141920915
[Epoch 7, Batch 1800] loss: 0.027049018214456738
[Epoch 7, Batch 1900] loss: 0.031071628088830038
[Epoch 7, Batch 2000] loss: 0.037731655347415655
[Epoch 7, Batch 2100] loss: 0.0351877331770811
[Epoch 7, Batch 2200] loss: 0.023975559753744165
[Epoch 7, Batch 2300] loss: 0.02548459690216987
[Epoch 7, Batch 2400] loss: 0.01794360532236169
[Epoch 7, Batch 2500] loss: 0.05039542962651467
[Epoch 7, Batch 2600] loss: 0.02095309112286486
[Epoch 7, Batch 2700] loss: 0.021596466201881413
[Epoch 7, Batch 2800] loss: 0.024084201818259317
[Epoch 7, Batch 2900] loss: 0.02836202852002316
[Epoch 7, Batch 3000] loss: 0.02502315470854228
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0424
Validation Accuracy: 0.9869
Overfitting: 0.0424
[Epoch 8, Batch 100] loss: 0.023927229901164537
[Epoch 8, Batch 200] loss: 0.016714689953259948
[Epoch 8, Batch 300] loss: 0.021414502983461717
[Epoch 8, Batch 400] loss: 0.041518091599136824
[Epoch 8, Batch 500] loss: 0.022656631240461137
[Epoch 8, Batch 600] loss: 0.01609252642694628
[Epoch 8, Batch 700] loss: 0.017771326329384465
[Epoch 8, Batch 800] loss: 0.018164841798788984
[Epoch 8, Batch 900] loss: 0.0161264430121264
[Epoch 8, Batch 1000] loss: 0.015814477214444195
[Epoch 8, Batch 1100] loss: 0.0210284380264784
[Epoch 8, Batch 1200] loss: 0.01597447834592458
[Epoch 8, Batch 1300] loss: 0.0282486554240495
[Epoch 8, Batch 1400] loss: 0.021566710802944727
[Epoch 8, Batch 1500] loss: 0.014931576892122394
[Epoch 8, Batch 1600] loss: 0.020922108857762398
[Epoch 8, Batch 1700] loss: 0.028561286388539883
[Epoch 8, Batch 1800] loss: 0.025680048581780284
[Epoch 8, Batch 1900] loss: 0.026340935488406103
[Epoch 8, Batch 2000] loss: 0.033006050448821045
[Epoch 8, Batch 2100] loss: 0.021335383269724843
[Epoch 8, Batch 2200] loss: 0.020507480140258848
[Epoch 8, Batch 2300] loss: 0.046631641264284554
[Epoch 8, Batch 2400] loss: 0.02386529434203112
[Epoch 8, Batch 2500] loss: 0.020488858962344238
[Epoch 8, Batch 2600] loss: 0.021400438516229768
[Epoch 8, Batch 2700] loss: 0.03398559495442896
[Epoch 8, Batch 2800] loss: 0.03330292384729546
[Epoch 8, Batch 2900] loss: 0.030192058987340717
[Epoch 8, Batch 3000] loss: 0.021310967542194702
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0414
Validation Accuracy: 0.9872
Overfitting: 0.0414
[Epoch 9, Batch 100] loss: 0.022154467401633154
[Epoch 9, Batch 200] loss: 0.008537591190961393
[Epoch 9, Batch 300] loss: 0.007088809798660805
[Epoch 9, Batch 400] loss: 0.013851947757211746
[Epoch 9, Batch 500] loss: 0.01181685569410547
[Epoch 9, Batch 600] loss: 0.018791312003013445
[Epoch 9, Batch 700] loss: 0.013019440646567092
[Epoch 9, Batch 800] loss: 0.014680696292653011
[Epoch 9, Batch 900] loss: 0.020706303695437783
[Epoch 9, Batch 1000] loss: 0.02176134425582859
[Epoch 9, Batch 1100] loss: 0.027460525826973024
[Epoch 9, Batch 1200] loss: 0.01830465526214539
[Epoch 9, Batch 1300] loss: 0.023172606615498807
[Epoch 9, Batch 1400] loss: 0.02561625947462744
[Epoch 9, Batch 1500] loss: 0.017164969583081984
[Epoch 9, Batch 1600] loss: 0.023863989701476386
[Epoch 9, Batch 1700] loss: 0.023984365039577824
[Epoch 9, Batch 1800] loss: 0.015734263520535023
[Epoch 9, Batch 1900] loss: 0.02217753415916377
[Epoch 9, Batch 2000] loss: 0.020971633335211664
[Epoch 9, Batch 2100] loss: 0.02016243873289568
[Epoch 9, Batch 2200] loss: 0.014750101412428194
[Epoch 9, Batch 2300] loss: 0.026369619880861138
[Epoch 9, Batch 2400] loss: 0.029655103687218798
[Epoch 9, Batch 2500] loss: 0.018638652222743985
[Epoch 9, Batch 2600] loss: 0.02283616632788835
[Epoch 9, Batch 2700] loss: 0.01767484121102825
[Epoch 9, Batch 2800] loss: 0.0324325589383443
[Epoch 9, Batch 2900] loss: 0.016586318579247746
[Epoch 9, Batch 3000] loss: 0.022347771267995996
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9842
Overfitting: 0.0511
[Epoch 10, Batch 100] loss: 0.017003445057707723
[Epoch 10, Batch 200] loss: 0.015420435640771757
[Epoch 10, Batch 300] loss: 0.019488304391434213
[Epoch 10, Batch 400] loss: 0.017641195182895898
[Epoch 10, Batch 500] loss: 0.01887056703340022
[Epoch 10, Batch 600] loss: 0.01618164950699793
[Epoch 10, Batch 700] loss: 0.021178144304813032
[Epoch 10, Batch 800] loss: 0.009940367113949833
[Epoch 10, Batch 900] loss: 0.011003355662958257
[Epoch 10, Batch 1000] loss: 0.033036332617302835
[Epoch 10, Batch 1100] loss: 0.012787685141011024
[Epoch 10, Batch 1200] loss: 0.030045284692387212
[Epoch 10, Batch 1300] loss: 0.014431314952871617
[Epoch 10, Batch 1400] loss: 0.017603442599556728
[Epoch 10, Batch 1500] loss: 0.017300714719367533
[Epoch 10, Batch 1600] loss: 0.01735030002912026
[Epoch 10, Batch 1700] loss: 0.013976970605062889
[Epoch 10, Batch 1800] loss: 0.03174622904180069
[Epoch 10, Batch 1900] loss: 0.016669429031926485
[Epoch 10, Batch 2000] loss: 0.02152620663444395
[Epoch 10, Batch 2100] loss: 0.019039300191016083
[Epoch 10, Batch 2200] loss: 0.009437499941850547
[Epoch 10, Batch 2300] loss: 0.02437192964982387
[Epoch 10, Batch 2400] loss: 0.01592857222600287
[Epoch 10, Batch 2500] loss: 0.02749321122500078
[Epoch 10, Batch 2600] loss: 0.01377369936316427
[Epoch 10, Batch 2700] loss: 0.01991615380778967
[Epoch 10, Batch 2800] loss: 0.014520255479401384
[Epoch 10, Batch 2900] loss: 0.02647800536052273
[Epoch 10, Batch 3000] loss: 0.009211991595202562
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9837
Overfitting: 0.0592
[Epoch 11, Batch 100] loss: 0.015760671923517294
[Epoch 11, Batch 200] loss: 0.007578139474644558
[Epoch 11, Batch 300] loss: 0.01510094257953142
[Epoch 11, Batch 400] loss: 0.01221521110199319
[Epoch 11, Batch 500] loss: 0.022674539879972144
[Epoch 11, Batch 600] loss: 0.017042548465933578
[Epoch 11, Batch 700] loss: 0.012481186861987226
[Epoch 11, Batch 800] loss: 0.008616621412693348
[Epoch 11, Batch 900] loss: 0.013049937815967496
[Epoch 11, Batch 1000] loss: 0.007600547153251682
[Epoch 11, Batch 1100] loss: 0.016630721733977224
[Epoch 11, Batch 1200] loss: 0.029094358186930548
[Epoch 11, Batch 1300] loss: 0.021109289637161056
[Epoch 11, Batch 1400] loss: 0.016473893763604794
[Epoch 11, Batch 1500] loss: 0.012477290054957848
[Epoch 11, Batch 1600] loss: 0.01802337461823299
[Epoch 11, Batch 1700] loss: 0.02247713255263534
[Epoch 11, Batch 1800] loss: 0.012194652667312766
[Epoch 11, Batch 1900] loss: 0.011976474974489974
[Epoch 11, Batch 2000] loss: 0.0175200517448593
[Epoch 11, Batch 2100] loss: 0.01632421290749335
[Epoch 11, Batch 2200] loss: 0.020015860737312322
[Epoch 11, Batch 2300] loss: 0.018116661321123502
[Epoch 11, Batch 2400] loss: 0.01595294123162603
[Epoch 11, Batch 2500] loss: 0.014327547707162012
[Epoch 11, Batch 2600] loss: 0.010741132331013432
[Epoch 11, Batch 2700] loss: 0.01820808431666592
[Epoch 11, Batch 2800] loss: 0.00988683399283218
[Epoch 11, Batch 2900] loss: 0.015108082710112285
[Epoch 11, Batch 3000] loss: 0.013086469709533049
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0408
Validation Accuracy: 0.9888
Overfitting: 0.0408
[Epoch 12, Batch 100] loss: 0.009049764443961977
[Epoch 12, Batch 200] loss: 0.010006160028406158
[Epoch 12, Batch 300] loss: 0.012154359033584115
[Epoch 12, Batch 400] loss: 0.010075593792785185
[Epoch 12, Batch 500] loss: 0.012006972588606004
[Epoch 12, Batch 600] loss: 0.01267567184930499
[Epoch 12, Batch 700] loss: 0.01086588677103009
[Epoch 12, Batch 800] loss: 0.011217170660597731
[Epoch 12, Batch 900] loss: 0.021335484140040537
[Epoch 12, Batch 1000] loss: 0.01419745291474328
[Epoch 12, Batch 1100] loss: 0.008122638108516185
[Epoch 12, Batch 1200] loss: 0.012967430227129172
[Epoch 12, Batch 1300] loss: 0.017886776657505835
[Epoch 12, Batch 1400] loss: 0.02098018908979611
[Epoch 12, Batch 1500] loss: 0.014733659504581737
[Epoch 12, Batch 1600] loss: 0.0046656825140144065
[Epoch 12, Batch 1700] loss: 0.010583556019632852
[Epoch 12, Batch 1800] loss: 0.02363961030051996
[Epoch 12, Batch 1900] loss: 0.011853098215060526
[Epoch 12, Batch 2000] loss: 0.018810156524414198
[Epoch 12, Batch 2100] loss: 0.012021580095479293
[Epoch 12, Batch 2200] loss: 0.01462945692390349
[Epoch 12, Batch 2300] loss: 0.020745993522351684
[Epoch 12, Batch 2400] loss: 0.020961346473077357
[Epoch 12, Batch 2500] loss: 0.01914239299369001
[Epoch 12, Batch 2600] loss: 0.011545067030199333
[Epoch 12, Batch 2700] loss: 0.008677506641242871
[Epoch 12, Batch 2800] loss: 0.01676660824456576
[Epoch 12, Batch 2900] loss: 0.019710385798734933
[Epoch 12, Batch 3000] loss: 0.014910055674181421
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0411
Validation Accuracy: 0.9882
Overfitting: 0.0411
[Epoch 13, Batch 100] loss: 0.011784871884347013
[Epoch 13, Batch 200] loss: 0.014468856195799162
[Epoch 13, Batch 300] loss: 0.009478907616534115
[Epoch 13, Batch 400] loss: 0.022910811407728035
[Epoch 13, Batch 500] loss: 0.01652744346565669
[Epoch 13, Batch 600] loss: 0.008836803654703544
[Epoch 13, Batch 700] loss: 0.010430781494314943
[Epoch 13, Batch 800] loss: 0.01436301026660658
[Epoch 13, Batch 900] loss: 0.0051735492160423745
[Epoch 13, Batch 1000] loss: 0.0041025844996329395
[Epoch 13, Batch 1100] loss: 0.011216456972985043
[Epoch 13, Batch 1200] loss: 0.019255576939449383
[Epoch 13, Batch 1300] loss: 0.00816471279601501
[Epoch 13, Batch 1400] loss: 0.010313724176905908
[Epoch 13, Batch 1500] loss: 0.010803353130631877
[Epoch 13, Batch 1600] loss: 0.007489874367770426
[Epoch 13, Batch 1700] loss: 0.010603020387180776
[Epoch 13, Batch 1800] loss: 0.01681068015940582
[Epoch 13, Batch 1900] loss: 0.013988726070269877
[Epoch 13, Batch 2000] loss: 0.013960712238670112
[Epoch 13, Batch 2100] loss: 0.01580090108438526
[Epoch 13, Batch 2200] loss: 0.013759700506075206
[Epoch 13, Batch 2300] loss: 0.014382299647047602
[Epoch 13, Batch 2400] loss: 0.006489327683966622
[Epoch 13, Batch 2500] loss: 0.020231907744523596
[Epoch 13, Batch 2600] loss: 0.014603257042899713
[Epoch 13, Batch 2700] loss: 0.013827789138235857
[Epoch 13, Batch 2800] loss: 0.006725693489236164
[Epoch 13, Batch 2900] loss: 0.016813373853308347
[Epoch 13, Batch 3000] loss: 0.011676668216164216
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9861
Overfitting: 0.0493
[Epoch 14, Batch 100] loss: 0.012274968378260382
[Epoch 14, Batch 200] loss: 0.015151911460116026
[Epoch 14, Batch 300] loss: 0.014474483321864682
[Epoch 14, Batch 400] loss: 0.008429099637692162
[Epoch 14, Batch 500] loss: 0.023585695974342683
[Epoch 14, Batch 600] loss: 0.01831747779173497
[Epoch 14, Batch 700] loss: 0.01664693346077911
[Epoch 14, Batch 800] loss: 0.004608329827306079
[Epoch 14, Batch 900] loss: 0.010363452270635207
[Epoch 14, Batch 1000] loss: 0.007842888774921447
[Epoch 14, Batch 1100] loss: 0.004783971590609326
[Epoch 14, Batch 1200] loss: 0.009925490250570873
[Epoch 14, Batch 1300] loss: 0.01576600715141467
[Epoch 14, Batch 1400] loss: 0.013271743228781361
[Epoch 14, Batch 1500] loss: 0.011366726729946777
[Epoch 14, Batch 1600] loss: 0.009136681265663355
[Epoch 14, Batch 1700] loss: 0.004050724758581054
[Epoch 14, Batch 1800] loss: 0.008287949119769565
[Epoch 14, Batch 1900] loss: 0.008168314239677557
[Epoch 14, Batch 2000] loss: 0.0074622114895021244
[Epoch 14, Batch 2100] loss: 0.0071777528407835686
[Epoch 14, Batch 2200] loss: 0.013419830938460109
[Epoch 14, Batch 2300] loss: 0.009827774822221613
[Epoch 14, Batch 2400] loss: 0.010856020545019192
[Epoch 14, Batch 2500] loss: 0.004842067138652055
[Epoch 14, Batch 2600] loss: 0.008102673463836254
[Epoch 14, Batch 2700] loss: 0.01250800613482852
[Epoch 14, Batch 2800] loss: 0.007237465959062775
[Epoch 14, Batch 2900] loss: 0.013230752653926174
[Epoch 14, Batch 3000] loss: 0.01401709809412523
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9872
Overfitting: 0.0476
[Epoch 15, Batch 100] loss: 0.009818286940117105
[Epoch 15, Batch 200] loss: 0.00639561025209332
[Epoch 15, Batch 300] loss: 0.007232164107376775
[Epoch 15, Batch 400] loss: 0.010634785864067454
[Epoch 15, Batch 500] loss: 0.007376777551419309
[Epoch 15, Batch 600] loss: 0.013298458958656738
[Epoch 15, Batch 700] loss: 0.012381879266233681
[Epoch 15, Batch 800] loss: 0.011851065454750368
[Epoch 15, Batch 900] loss: 0.009234414204370297
[Epoch 15, Batch 1000] loss: 0.004033166879435157
[Epoch 15, Batch 1100] loss: 0.003539695071535789
[Epoch 15, Batch 1200] loss: 0.0059081195075305
[Epoch 15, Batch 1300] loss: 0.002281072397270236
[Epoch 15, Batch 1400] loss: 0.0049060191862986356
[Epoch 15, Batch 1500] loss: 0.005759983800966211
[Epoch 15, Batch 1600] loss: 0.005365027990585532
[Epoch 15, Batch 1700] loss: 0.004082516730883299
[Epoch 15, Batch 1800] loss: 0.011486978702046145
[Epoch 15, Batch 1900] loss: 0.015825939736653253
[Epoch 15, Batch 2000] loss: 0.00784812865472304
[Epoch 15, Batch 2100] loss: 0.007901699288240707
[Epoch 15, Batch 2200] loss: 0.005799217734440845
[Epoch 15, Batch 2300] loss: 0.0026595870301844115
[Epoch 15, Batch 2400] loss: 0.01425549727491898
[Epoch 15, Batch 2500] loss: 0.013071410648863094
[Epoch 15, Batch 2600] loss: 0.01265861689200392
[Epoch 15, Batch 2700] loss: 0.004285309298732045
[Epoch 15, Batch 2800] loss: 0.0075634529001945335
[Epoch 15, Batch 2900] loss: 0.010878929986083676
[Epoch 15, Batch 3000] loss: 0.011831043796719313
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0395
Validation Accuracy: 0.9891
Overfitting: 0.0395
Best model saved at epoch 15 with validation loss: 0.0395
[Epoch 16, Batch 100] loss: 0.004324097729993355
[Epoch 16, Batch 200] loss: 0.0022457564127125805
[Epoch 16, Batch 300] loss: 0.003065563918908083
[Epoch 16, Batch 400] loss: 0.019623220071027844
[Epoch 16, Batch 500] loss: 0.0028154774763652314
[Epoch 16, Batch 600] loss: 0.002811715406435269
[Epoch 16, Batch 700] loss: 0.01236228980603869
[Epoch 16, Batch 800] loss: 0.006715883950348598
[Epoch 16, Batch 900] loss: 0.003207038678046388
[Epoch 16, Batch 1000] loss: 0.002513482760079988
[Epoch 16, Batch 1100] loss: 0.00480326027719002
[Epoch 16, Batch 1200] loss: 0.0028062214488954853
[Epoch 16, Batch 1300] loss: 0.0026833205647136538
[Epoch 16, Batch 1400] loss: 0.015188535350042968
[Epoch 16, Batch 1500] loss: 0.0066216684902798304
[Epoch 16, Batch 1600] loss: 0.01829587774185086
[Epoch 16, Batch 1700] loss: 0.012224074838085243
[Epoch 16, Batch 1800] loss: 0.009325270394738254
[Epoch 16, Batch 1900] loss: 0.015002297350008575
[Epoch 16, Batch 2000] loss: 0.014449992626148288
[Epoch 16, Batch 2100] loss: 0.006404714555551436
[Epoch 16, Batch 2200] loss: 0.006097645192136269
[Epoch 16, Batch 2300] loss: 0.010626520896387319
[Epoch 16, Batch 2400] loss: 0.010419195792240998
[Epoch 16, Batch 2500] loss: 0.012368728738733807
[Epoch 16, Batch 2600] loss: 0.01365726369532922
[Epoch 16, Batch 2700] loss: 0.01260581071961724
[Epoch 16, Batch 2800] loss: 0.00848977563932749
[Epoch 16, Batch 2900] loss: 0.006607714600183101
[Epoch 16, Batch 3000] loss: 0.003226140889106546
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0460
Validation Accuracy: 0.9883
Overfitting: 0.0460
[Epoch 17, Batch 100] loss: 0.008460697031814561
[Epoch 17, Batch 200] loss: 0.0072875619987334515
[Epoch 17, Batch 300] loss: 0.004841109144430788
[Epoch 17, Batch 400] loss: 0.008528190256864718
[Epoch 17, Batch 500] loss: 0.006253084428167312
[Epoch 17, Batch 600] loss: 0.005736190088995841
[Epoch 17, Batch 700] loss: 0.002677567082432404
[Epoch 17, Batch 800] loss: 0.0024565992207544697
[Epoch 17, Batch 900] loss: 0.008280766433176155
[Epoch 17, Batch 1000] loss: 0.012909925502780197
[Epoch 17, Batch 1100] loss: 0.00815176399939844
[Epoch 17, Batch 1200] loss: 0.007808529988734563
[Epoch 17, Batch 1300] loss: 0.013565254259165159
[Epoch 17, Batch 1400] loss: 0.006213220168974658
[Epoch 17, Batch 1500] loss: 0.008433006332538753
[Epoch 17, Batch 1600] loss: 0.012805030892548076
[Epoch 17, Batch 1700] loss: 0.004013783910453412
[Epoch 17, Batch 1800] loss: 0.00874362415816904
[Epoch 17, Batch 1900] loss: 0.005326500512283019
[Epoch 17, Batch 2000] loss: 0.005925948661291755
[Epoch 17, Batch 2100] loss: 0.011014974039616163
[Epoch 17, Batch 2200] loss: 0.002735073440013025
[Epoch 17, Batch 2300] loss: 0.009726579631662275
[Epoch 17, Batch 2400] loss: 0.016289276608104045
[Epoch 17, Batch 2500] loss: 0.009115586188677298
[Epoch 17, Batch 2600] loss: 0.005351379953601736
[Epoch 17, Batch 2700] loss: 0.003449808424261391
[Epoch 17, Batch 2800] loss: 0.0025556404407268475
[Epoch 17, Batch 2900] loss: 0.002962283947783817
[Epoch 17, Batch 3000] loss: 0.011150289413577071
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0421
Validation Accuracy: 0.9888
Overfitting: 0.0421
[Epoch 18, Batch 100] loss: 0.004042341225951134
[Epoch 18, Batch 200] loss: 0.005835491493000404
[Epoch 18, Batch 300] loss: 0.00322638271548783
[Epoch 18, Batch 400] loss: 0.0038544908013784605
[Epoch 18, Batch 500] loss: 0.00467485007374222
[Epoch 18, Batch 600] loss: 0.0025679780217542714
[Epoch 18, Batch 700] loss: 0.00906526185553048
[Epoch 18, Batch 800] loss: 0.003125740713450682
[Epoch 18, Batch 900] loss: 0.006562633987738025
[Epoch 18, Batch 1000] loss: 0.005381885025710176
[Epoch 18, Batch 1100] loss: 0.002986448492619047
[Epoch 18, Batch 1200] loss: 0.002928589315993122
[Epoch 18, Batch 1300] loss: 0.006729646629265744
[Epoch 18, Batch 1400] loss: 0.003260715319321079
[Epoch 18, Batch 1500] loss: 0.003915669103503205
[Epoch 18, Batch 1600] loss: 0.013184843167383633
[Epoch 18, Batch 1700] loss: 0.011996738608476392
[Epoch 18, Batch 1800] loss: 0.009111422036471594
[Epoch 18, Batch 1900] loss: 0.008906254988680473
[Epoch 18, Batch 2000] loss: 0.004957176032025359
[Epoch 18, Batch 2100] loss: 0.002969492729932881
[Epoch 18, Batch 2200] loss: 0.002680095620058296
[Epoch 18, Batch 2300] loss: 0.003224550429546298
[Epoch 18, Batch 2400] loss: 0.007265550041148278
[Epoch 18, Batch 2500] loss: 0.008556004948388818
[Epoch 18, Batch 2600] loss: 0.0036199231998602956
[Epoch 18, Batch 2700] loss: 0.007269607881749778
[Epoch 18, Batch 2800] loss: 0.003970945363826104
[Epoch 18, Batch 2900] loss: 0.006438145356623863
[Epoch 18, Batch 3000] loss: 0.005495196186791418
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9876
Overfitting: 0.0464
[Epoch 19, Batch 100] loss: 0.0044227623580667345
[Epoch 19, Batch 200] loss: 0.007103193267947176
[Epoch 19, Batch 300] loss: 0.007831292427623211
[Epoch 19, Batch 400] loss: 0.004582738180815582
[Epoch 19, Batch 500] loss: 0.013438668749854514
[Epoch 19, Batch 600] loss: 0.0025066333918437067
[Epoch 19, Batch 700] loss: 0.0019708795898623066
[Epoch 19, Batch 800] loss: 0.004308433044841422
[Epoch 19, Batch 900] loss: 0.0011500965226150584
[Epoch 19, Batch 1000] loss: 0.0010143748040362865
[Epoch 19, Batch 1100] loss: 0.004797713200341605
[Epoch 19, Batch 1200] loss: 0.0013258406592224325
[Epoch 19, Batch 1300] loss: 0.0013767765218920757
[Epoch 19, Batch 1400] loss: 0.0013180781943728447
[Epoch 19, Batch 1500] loss: 0.005168704130010862
[Epoch 19, Batch 1600] loss: 0.0075601554279217
[Epoch 19, Batch 1700] loss: 0.0035399890217343
[Epoch 19, Batch 1800] loss: 0.002260133181291053
[Epoch 19, Batch 1900] loss: 0.006529102725631617
[Epoch 19, Batch 2000] loss: 0.01088173858560765
[Epoch 19, Batch 2100] loss: 0.010029217134341479
[Epoch 19, Batch 2200] loss: 0.009449333135327862
[Epoch 19, Batch 2300] loss: 0.008684031198503703
[Epoch 19, Batch 2400] loss: 0.019846908673033282
[Epoch 19, Batch 2500] loss: 0.003869518188673169
[Epoch 19, Batch 2600] loss: 0.004854895374393777
[Epoch 19, Batch 2700] loss: 0.005961984276087833
[Epoch 19, Batch 2800] loss: 0.003866172897896405
[Epoch 19, Batch 2900] loss: 0.012097392666993586
[Epoch 19, Batch 3000] loss: 0.02663543045444044
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0802
Validation Accuracy: 0.9806
Overfitting: 0.0802
[Epoch 20, Batch 100] loss: 0.009424568409999666
[Epoch 20, Batch 200] loss: 0.004135173439719609
[Epoch 20, Batch 300] loss: 0.01574276932922885
[Epoch 20, Batch 400] loss: 0.005517280521563635
[Epoch 20, Batch 500] loss: 0.005759560035989466
[Epoch 20, Batch 600] loss: 0.005064758740284567
[Epoch 20, Batch 700] loss: 0.005124677462158047
[Epoch 20, Batch 800] loss: 0.01099186834494331
[Epoch 20, Batch 900] loss: 0.006576029622747512
[Epoch 20, Batch 1000] loss: 0.003757684665461625
[Epoch 20, Batch 1100] loss: 0.003322832663791928
[Epoch 20, Batch 1200] loss: 0.007631850862198206
[Epoch 20, Batch 1300] loss: 0.0038388858967154603
[Epoch 20, Batch 1400] loss: 0.002740666417107036
[Epoch 20, Batch 1500] loss: 0.008684378279582176
[Epoch 20, Batch 1600] loss: 0.004812088156463403
[Epoch 20, Batch 1700] loss: 0.0033414057442629997
[Epoch 20, Batch 1800] loss: 0.007437176510272821
[Epoch 20, Batch 1900] loss: 0.003506113118481764
[Epoch 20, Batch 2000] loss: 0.001800159088007831
[Epoch 20, Batch 2100] loss: 0.0015884716132256926
[Epoch 20, Batch 2200] loss: 0.008628149220397887
[Epoch 20, Batch 2300] loss: 0.007111133692654192
[Epoch 20, Batch 2400] loss: 0.006199025215592826
[Epoch 20, Batch 2500] loss: 0.0023118046991010034
[Epoch 20, Batch 2600] loss: 0.008731745986222847
[Epoch 20, Batch 2700] loss: 0.006589292524410428
[Epoch 20, Batch 2800] loss: 0.001492242323326991
[Epoch 20, Batch 2900] loss: 0.015224956013161659
[Epoch 20, Batch 3000] loss: 0.0017365550889689985
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0436
Validation Accuracy: 0.9887
Overfitting: 0.0436
[Epoch 21, Batch 100] loss: 0.007695927241886693
[Epoch 21, Batch 200] loss: 0.0060443584302242925
[Epoch 21, Batch 300] loss: 0.002846249169751616
[Epoch 21, Batch 400] loss: 0.0040120152762079895
[Epoch 21, Batch 500] loss: 0.002591899986388313
[Epoch 21, Batch 600] loss: 0.0015640441577329512
[Epoch 21, Batch 700] loss: 0.0016502958508984023
[Epoch 21, Batch 800] loss: 0.001165190779667249
[Epoch 21, Batch 900] loss: 0.001265177524221741
[Epoch 21, Batch 1000] loss: 0.003113888222138712
[Epoch 21, Batch 1100] loss: 0.0035205965984717834
[Epoch 21, Batch 1200] loss: 0.006761092041515582
[Epoch 21, Batch 1300] loss: 0.0064201512020216
[Epoch 21, Batch 1400] loss: 0.006062953811863951
[Epoch 21, Batch 1500] loss: 0.0031466110821180495
[Epoch 21, Batch 1600] loss: 0.008875354304729726
[Epoch 21, Batch 1700] loss: 0.00523747647381029
[Epoch 21, Batch 1800] loss: 0.006254551823906809
[Epoch 21, Batch 1900] loss: 0.009311022759549132
[Epoch 21, Batch 2000] loss: 0.01906256295297439
[Epoch 21, Batch 2100] loss: 0.014247522496626032
[Epoch 21, Batch 2200] loss: 0.007286359365261888
[Epoch 21, Batch 2300] loss: 0.011379369742190306
[Epoch 21, Batch 2400] loss: 0.006618772881179211
[Epoch 21, Batch 2500] loss: 0.004593384050562151
[Epoch 21, Batch 2600] loss: 0.007221235118335017
[Epoch 21, Batch 2700] loss: 0.0048289727890764265
[Epoch 21, Batch 2800] loss: 0.0019665795240146624
[Epoch 21, Batch 2900] loss: 0.0023156601215202953
[Epoch 21, Batch 3000] loss: 0.011172501378381838
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0598
Validation Accuracy: 0.9858
Overfitting: 0.0598
[Epoch 22, Batch 100] loss: 0.00795532240085265
[Epoch 22, Batch 200] loss: 0.003876291927050772
[Epoch 22, Batch 300] loss: 0.005681586279805231
[Epoch 22, Batch 400] loss: 0.0022095685385741604
[Epoch 22, Batch 500] loss: 0.005930716769295685
[Epoch 22, Batch 600] loss: 0.002282423672384084
[Epoch 22, Batch 700] loss: 0.005035623344768609
[Epoch 22, Batch 800] loss: 0.0082450409651835
[Epoch 22, Batch 900] loss: 0.0026281750346450394
[Epoch 22, Batch 1000] loss: 0.006338200105696785
[Epoch 22, Batch 1100] loss: 0.003385047265813661
[Epoch 22, Batch 1200] loss: 0.00214009674982087
[Epoch 22, Batch 1300] loss: 0.012040441832194517
[Epoch 22, Batch 1400] loss: 0.008182632355466665
[Epoch 22, Batch 1500] loss: 0.004854212342483493
[Epoch 22, Batch 1600] loss: 0.005946264540592345
[Epoch 22, Batch 1700] loss: 0.0021682311654237906
[Epoch 22, Batch 1800] loss: 0.003287792998231107
[Epoch 22, Batch 1900] loss: 0.0017424818524322916
[Epoch 22, Batch 2000] loss: 0.01205112405130592
[Epoch 22, Batch 2100] loss: 0.002976973175967004
[Epoch 22, Batch 2200] loss: 0.004351486078047984
[Epoch 22, Batch 2300] loss: 0.007585410312534968
[Epoch 22, Batch 2400] loss: 0.0012908050905393509
[Epoch 22, Batch 2500] loss: 0.0019302546221418027
[Epoch 22, Batch 2600] loss: 0.0006913992391719504
[Epoch 22, Batch 2700] loss: 0.0049058899751552336
[Epoch 22, Batch 2800] loss: 0.004262638501419609
[Epoch 22, Batch 2900] loss: 0.0027738800040212476
[Epoch 22, Batch 3000] loss: 0.004079590435047322
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9888
Overfitting: 0.0470
[Epoch 23, Batch 100] loss: 0.0018578984441739977
[Epoch 23, Batch 200] loss: 0.0012526247891986486
[Epoch 23, Batch 300] loss: 0.0024141723712144624
[Epoch 23, Batch 400] loss: 0.0015526100824556366
[Epoch 23, Batch 500] loss: 0.0011295411089419006
[Epoch 23, Batch 600] loss: 0.004974757806573962
[Epoch 23, Batch 700] loss: 0.010429878884125615
[Epoch 23, Batch 800] loss: 0.0035315819251735547
[Epoch 23, Batch 900] loss: 0.0011717953573999295
[Epoch 23, Batch 1000] loss: 0.004310598051863135
[Epoch 23, Batch 1100] loss: 0.004749202979605674
[Epoch 23, Batch 1200] loss: 0.004811143783002194
[Epoch 23, Batch 1300] loss: 0.0022603563193518993
[Epoch 23, Batch 1400] loss: 0.001535228795253367
[Epoch 23, Batch 1500] loss: 0.0007783247875260457
[Epoch 23, Batch 1600] loss: 0.005146392331353393
[Epoch 23, Batch 1700] loss: 0.0012700071545426806
[Epoch 23, Batch 1800] loss: 0.002658410006517098
[Epoch 23, Batch 1900] loss: 0.006321424669822857
[Epoch 23, Batch 2000] loss: 0.0017102948740941315
[Epoch 23, Batch 2100] loss: 0.006189386790488954
[Epoch 23, Batch 2200] loss: 0.0037066168405178066
[Epoch 23, Batch 2300] loss: 0.0031348961807479013
[Epoch 23, Batch 2400] loss: 0.008481405953623167
[Epoch 23, Batch 2500] loss: 0.007895467550708232
[Epoch 23, Batch 2600] loss: 0.007103815451138758
[Epoch 23, Batch 2700] loss: 0.0023861052504550173
[Epoch 23, Batch 2800] loss: 0.002306093075527542
[Epoch 23, Batch 2900] loss: 0.004276287255198383
[Epoch 23, Batch 3000] loss: 0.006714442703572838
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9893
Overfitting: 0.0478
[Epoch 24, Batch 100] loss: 0.0020364701682149054
[Epoch 24, Batch 200] loss: 0.0022348748412630926
[Epoch 24, Batch 300] loss: 0.0011151938445735255
[Epoch 24, Batch 400] loss: 0.0007935795509444433
[Epoch 24, Batch 500] loss: 0.0007119638952786289
[Epoch 24, Batch 600] loss: 0.0009428554940667766
[Epoch 24, Batch 700] loss: 0.0006060554713125655
[Epoch 24, Batch 800] loss: 0.0008310343780913421
[Epoch 24, Batch 900] loss: 0.0025474111300326997
[Epoch 24, Batch 1000] loss: 0.0041345308965283325
[Epoch 24, Batch 1100] loss: 0.0008431118009700001
[Epoch 24, Batch 1200] loss: 0.0013616969786932698
[Epoch 24, Batch 1300] loss: 0.0011481411323651968
[Epoch 24, Batch 1400] loss: 0.002424624045475525
[Epoch 24, Batch 1500] loss: 0.003854721564923116
[Epoch 24, Batch 1600] loss: 0.005086192550925262
[Epoch 24, Batch 1700] loss: 0.0012769407702959868
[Epoch 24, Batch 1800] loss: 0.0015585959272358663
[Epoch 24, Batch 1900] loss: 0.0007887169296820673
[Epoch 24, Batch 2000] loss: 0.0013919005764390846
[Epoch 24, Batch 2100] loss: 0.003934031440889711
[Epoch 24, Batch 2200] loss: 0.0009642307194668654
[Epoch 24, Batch 2300] loss: 0.0005453573664666989
[Epoch 24, Batch 2400] loss: 0.0007613832607437842
[Epoch 24, Batch 2500] loss: 0.0017327560274497421
[Epoch 24, Batch 2600] loss: 0.007660073480186753
[Epoch 24, Batch 2700] loss: 0.00048572462226814217
[Epoch 24, Batch 2800] loss: 0.001252799107055278
[Epoch 24, Batch 2900] loss: 0.002197013239702912
[Epoch 24, Batch 3000] loss: 0.0010526516194464186
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9907
Overfitting: 0.0430
Fold 4 validation loss: 0.0430
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.300571801662445
[Epoch 1, Batch 200] loss: 2.287608437538147
[Epoch 1, Batch 300] loss: 2.2464568281173705
[Epoch 1, Batch 400] loss: 1.827524881362915
[Epoch 1, Batch 500] loss: 0.7512861186265946
[Epoch 1, Batch 600] loss: 0.5282311578840018
[Epoch 1, Batch 700] loss: 0.4220118718594313
[Epoch 1, Batch 800] loss: 0.3708161364868283
[Epoch 1, Batch 900] loss: 0.3363552260398865
[Epoch 1, Batch 1000] loss: 0.3100571024790406
[Epoch 1, Batch 1100] loss: 0.2567766046244651
[Epoch 1, Batch 1200] loss: 0.2078045323677361
[Epoch 1, Batch 1300] loss: 0.21710780491121112
[Epoch 1, Batch 1400] loss: 0.21499757569283248
[Epoch 1, Batch 1500] loss: 0.191483837030828
[Epoch 1, Batch 1600] loss: 0.16297362848185004
[Epoch 1, Batch 1700] loss: 0.18324617504142224
[Epoch 1, Batch 1800] loss: 0.14656502223107964
[Epoch 1, Batch 1900] loss: 0.17329104822594674
[Epoch 1, Batch 2000] loss: 0.12771508420817554
[Epoch 1, Batch 2100] loss: 0.15900510568637402
[Epoch 1, Batch 2200] loss: 0.1380254712328315
[Epoch 1, Batch 2300] loss: 0.12405924011720344
[Epoch 1, Batch 2400] loss: 0.15667772795073687
[Epoch 1, Batch 2500] loss: 0.12828740008641035
[Epoch 1, Batch 2600] loss: 0.11483943155035377
[Epoch 1, Batch 2700] loss: 0.1327509614499286
[Epoch 1, Batch 2800] loss: 0.0931784929416608
[Epoch 1, Batch 2900] loss: 0.15785491863731294
[Epoch 1, Batch 3000] loss: 0.11494088748004287
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1142
Validation Accuracy: 0.9647
Overfitting: 0.1142
Best model saved at epoch 1 with validation loss: 0.1142
[Epoch 2, Batch 100] loss: 0.0972914573107846
[Epoch 2, Batch 200] loss: 0.1182162966299802
[Epoch 2, Batch 300] loss: 0.1130942142312415
[Epoch 2, Batch 400] loss: 0.08494859474478289
[Epoch 2, Batch 500] loss: 0.10344836153497454
[Epoch 2, Batch 600] loss: 0.11579160259687342
[Epoch 2, Batch 700] loss: 0.08693043324456085
[Epoch 2, Batch 800] loss: 0.09249572881730274
[Epoch 2, Batch 900] loss: 0.10208340153098107
[Epoch 2, Batch 1000] loss: 0.09423799558309838
[Epoch 2, Batch 1100] loss: 0.09034239086089656
[Epoch 2, Batch 1200] loss: 0.08417999524855986
[Epoch 2, Batch 1300] loss: 0.07978832804830745
[Epoch 2, Batch 1400] loss: 0.08829120560898446
[Epoch 2, Batch 1500] loss: 0.08776345477555879
[Epoch 2, Batch 1600] loss: 0.05378591597895138
[Epoch 2, Batch 1700] loss: 0.0931318919255864
[Epoch 2, Batch 1800] loss: 0.10274577503907495
[Epoch 2, Batch 1900] loss: 0.08285844503436238
[Epoch 2, Batch 2000] loss: 0.081508381171152
[Epoch 2, Batch 2100] loss: 0.10386745738913306
[Epoch 2, Batch 2200] loss: 0.07940936654456891
[Epoch 2, Batch 2300] loss: 0.06837002579355612
[Epoch 2, Batch 2400] loss: 0.061497753415023906
[Epoch 2, Batch 2500] loss: 0.059923378756502645
[Epoch 2, Batch 2600] loss: 0.06519419973425102
[Epoch 2, Batch 2700] loss: 0.07720817390596495
[Epoch 2, Batch 2800] loss: 0.07006962288636714
[Epoch 2, Batch 2900] loss: 0.07589821832400048
[Epoch 2, Batch 3000] loss: 0.07799139498441945
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0693
Validation Accuracy: 0.9787
Overfitting: 0.0693
Best model saved at epoch 2 with validation loss: 0.0693
[Epoch 3, Batch 100] loss: 0.0589102879690472
[Epoch 3, Batch 200] loss: 0.05003463719098363
[Epoch 3, Batch 300] loss: 0.05483869051502552
[Epoch 3, Batch 400] loss: 0.0947724912542617
[Epoch 3, Batch 500] loss: 0.07553959585726261
[Epoch 3, Batch 600] loss: 0.07021678215824068
[Epoch 3, Batch 700] loss: 0.05925269938947167
[Epoch 3, Batch 800] loss: 0.04476141715713311
[Epoch 3, Batch 900] loss: 0.05158888485399075
[Epoch 3, Batch 1000] loss: 0.058772101075737736
[Epoch 3, Batch 1100] loss: 0.05419855702668428
[Epoch 3, Batch 1200] loss: 0.05426922940474469
[Epoch 3, Batch 1300] loss: 0.05298910534707829
[Epoch 3, Batch 1400] loss: 0.07133380775776459
[Epoch 3, Batch 1500] loss: 0.06410258430230897
[Epoch 3, Batch 1600] loss: 0.04837259830557741
[Epoch 3, Batch 1700] loss: 0.05697710392574663
[Epoch 3, Batch 1800] loss: 0.050880194305209445
[Epoch 3, Batch 1900] loss: 0.060625506399956064
[Epoch 3, Batch 2000] loss: 0.059303055576165206
[Epoch 3, Batch 2100] loss: 0.05597625609108945
[Epoch 3, Batch 2200] loss: 0.07651258975500241
[Epoch 3, Batch 2300] loss: 0.08494791285251267
[Epoch 3, Batch 2400] loss: 0.05657098349998705
[Epoch 3, Batch 2500] loss: 0.03973520258179633
[Epoch 3, Batch 2600] loss: 0.057486057395872196
[Epoch 3, Batch 2700] loss: 0.06603520470438524
[Epoch 3, Batch 2800] loss: 0.060526850746537096
[Epoch 3, Batch 2900] loss: 0.05898130146146286
[Epoch 3, Batch 3000] loss: 0.03797550886287354
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0613
Validation Accuracy: 0.9802
Overfitting: 0.0613
Best model saved at epoch 3 with validation loss: 0.0613
[Epoch 4, Batch 100] loss: 0.03379373936884804
[Epoch 4, Batch 200] loss: 0.053099582773284054
[Epoch 4, Batch 300] loss: 0.04978440729668364
[Epoch 4, Batch 400] loss: 0.041017665875842796
[Epoch 4, Batch 500] loss: 0.0510793343745172
[Epoch 4, Batch 600] loss: 0.06267047624685801
[Epoch 4, Batch 700] loss: 0.0397421631985344
[Epoch 4, Batch 800] loss: 0.05717837943433551
[Epoch 4, Batch 900] loss: 0.04429605763172731
[Epoch 4, Batch 1000] loss: 0.02412907439371338
[Epoch 4, Batch 1100] loss: 0.06966664516890887
[Epoch 4, Batch 1200] loss: 0.04667709661269328
[Epoch 4, Batch 1300] loss: 0.06248410327883903
[Epoch 4, Batch 1400] loss: 0.04780958796967752
[Epoch 4, Batch 1500] loss: 0.034867060497053896
[Epoch 4, Batch 1600] loss: 0.03941624146362301
[Epoch 4, Batch 1700] loss: 0.049847364185843616
[Epoch 4, Batch 1800] loss: 0.06394858211482642
[Epoch 4, Batch 1900] loss: 0.032483018102648205
[Epoch 4, Batch 2000] loss: 0.06337629862100584
[Epoch 4, Batch 2100] loss: 0.05143432997050695
[Epoch 4, Batch 2200] loss: 0.032630683628376574
[Epoch 4, Batch 2300] loss: 0.04356409985019127
[Epoch 4, Batch 2400] loss: 0.05022915519890375
[Epoch 4, Batch 2500] loss: 0.062171072726196146
[Epoch 4, Batch 2600] loss: 0.04273878446139861
[Epoch 4, Batch 2700] loss: 0.05369182596943574
[Epoch 4, Batch 2800] loss: 0.06698153744830052
[Epoch 4, Batch 2900] loss: 0.03954736183586647
[Epoch 4, Batch 3000] loss: 0.048295112127088945
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9845
Overfitting: 0.0478
Best model saved at epoch 4 with validation loss: 0.0478
[Epoch 5, Batch 100] loss: 0.03484415762126446
[Epoch 5, Batch 200] loss: 0.04306301636170247
[Epoch 5, Batch 300] loss: 0.03286338246980449
[Epoch 5, Batch 400] loss: 0.04551298720500199
[Epoch 5, Batch 500] loss: 0.034328200236777774
[Epoch 5, Batch 600] loss: 0.04344524337881012
[Epoch 5, Batch 700] loss: 0.049512265977682546
[Epoch 5, Batch 800] loss: 0.06096148080076091
[Epoch 5, Batch 900] loss: 0.04243892967700958
[Epoch 5, Batch 1000] loss: 0.051481925423722714
[Epoch 5, Batch 1100] loss: 0.04250371053596609
[Epoch 5, Batch 1200] loss: 0.034988048551313114
[Epoch 5, Batch 1300] loss: 0.048526362281118056
[Epoch 5, Batch 1400] loss: 0.03648770025436534
[Epoch 5, Batch 1500] loss: 0.03620500976088806
[Epoch 5, Batch 1600] loss: 0.02536504201729258
[Epoch 5, Batch 1700] loss: 0.03670430596801452
[Epoch 5, Batch 1800] loss: 0.03483074800238683
[Epoch 5, Batch 1900] loss: 0.043656683901062934
[Epoch 5, Batch 2000] loss: 0.03744378274306655
[Epoch 5, Batch 2100] loss: 0.05166580201737816
[Epoch 5, Batch 2200] loss: 0.0538955041024019
[Epoch 5, Batch 2300] loss: 0.049439898086275205
[Epoch 5, Batch 2400] loss: 0.03101391753720236
[Epoch 5, Batch 2500] loss: 0.030144997556781163
[Epoch 5, Batch 2600] loss: 0.02936675505276071
[Epoch 5, Batch 2700] loss: 0.03491917012099293
[Epoch 5, Batch 2800] loss: 0.03703148497472284
[Epoch 5, Batch 2900] loss: 0.042500218419882003
[Epoch 5, Batch 3000] loss: 0.038097549278027144
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9849
Overfitting: 0.0502
[Epoch 6, Batch 100] loss: 0.03299005170352757
[Epoch 6, Batch 200] loss: 0.026044423100247512
[Epoch 6, Batch 300] loss: 0.03157672645073035
[Epoch 6, Batch 400] loss: 0.02049912860209588
[Epoch 6, Batch 500] loss: 0.03450215882108751
[Epoch 6, Batch 600] loss: 0.028531087029550692
[Epoch 6, Batch 700] loss: 0.047545917502284284
[Epoch 6, Batch 800] loss: 0.02432911159048672
[Epoch 6, Batch 900] loss: 0.02503859591728542
[Epoch 6, Batch 1000] loss: 0.043391894882443015
[Epoch 6, Batch 1100] loss: 0.0497275156842079
[Epoch 6, Batch 1200] loss: 0.02877014834273723
[Epoch 6, Batch 1300] loss: 0.03688564434982254
[Epoch 6, Batch 1400] loss: 0.02499935196174192
[Epoch 6, Batch 1500] loss: 0.03521021825377829
[Epoch 6, Batch 1600] loss: 0.01933024902042234
[Epoch 6, Batch 1700] loss: 0.028759423968731424
[Epoch 6, Batch 1800] loss: 0.034460087371226106
[Epoch 6, Batch 1900] loss: 0.024573552975562053
[Epoch 6, Batch 2000] loss: 0.04220282348178443
[Epoch 6, Batch 2100] loss: 0.02651661140334909
[Epoch 6, Batch 2200] loss: 0.034021343492058806
[Epoch 6, Batch 2300] loss: 0.020722265878684993
[Epoch 6, Batch 2400] loss: 0.03144190493221686
[Epoch 6, Batch 2500] loss: 0.03564585224739858
[Epoch 6, Batch 2600] loss: 0.07014411685609957
[Epoch 6, Batch 2700] loss: 0.03786377022312081
[Epoch 6, Batch 2800] loss: 0.027476294702064478
[Epoch 6, Batch 2900] loss: 0.03199042993102921
[Epoch 6, Batch 3000] loss: 0.0359209528638894
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0420
Validation Accuracy: 0.9862
Overfitting: 0.0420
Best model saved at epoch 6 with validation loss: 0.0420
[Epoch 7, Batch 100] loss: 0.02290657969788299
[Epoch 7, Batch 200] loss: 0.020203343652610783
[Epoch 7, Batch 300] loss: 0.023297620260636906
[Epoch 7, Batch 400] loss: 0.021212907859699044
[Epoch 7, Batch 500] loss: 0.034799720497794624
[Epoch 7, Batch 600] loss: 0.021813907202667907
[Epoch 7, Batch 700] loss: 0.021244423371572337
[Epoch 7, Batch 800] loss: 0.021922933258138072
[Epoch 7, Batch 900] loss: 0.023589224957540865
[Epoch 7, Batch 1000] loss: 0.03490606148623556
[Epoch 7, Batch 1100] loss: 0.027303076208663696
[Epoch 7, Batch 1200] loss: 0.035145264853781555
[Epoch 7, Batch 1300] loss: 0.035788559105421884
[Epoch 7, Batch 1400] loss: 0.024154174724244512
[Epoch 7, Batch 1500] loss: 0.033972666349436624
[Epoch 7, Batch 1600] loss: 0.037274326950864634
[Epoch 7, Batch 1700] loss: 0.026268391198427707
[Epoch 7, Batch 1800] loss: 0.03297105760735576
[Epoch 7, Batch 1900] loss: 0.027341047444861034
[Epoch 7, Batch 2000] loss: 0.026738747246236018
[Epoch 7, Batch 2100] loss: 0.03557079414604232
[Epoch 7, Batch 2200] loss: 0.03221966863535272
[Epoch 7, Batch 2300] loss: 0.0221378418020322
[Epoch 7, Batch 2400] loss: 0.045581457695407154
[Epoch 7, Batch 2500] loss: 0.04087212724087294
[Epoch 7, Batch 2600] loss: 0.019040823702234776
[Epoch 7, Batch 2700] loss: 0.045245593582367294
[Epoch 7, Batch 2800] loss: 0.022523009863652986
[Epoch 7, Batch 2900] loss: 0.02506918100738403
[Epoch 7, Batch 3000] loss: 0.031545410502003504
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0411
Validation Accuracy: 0.9870
Overfitting: 0.0411
Best model saved at epoch 7 with validation loss: 0.0411
[Epoch 8, Batch 100] loss: 0.03036789112549741
[Epoch 8, Batch 200] loss: 0.02490213122611749
[Epoch 8, Batch 300] loss: 0.016485099117271602
[Epoch 8, Batch 400] loss: 0.016671803216740954
[Epoch 8, Batch 500] loss: 0.020451559922857996
[Epoch 8, Batch 600] loss: 0.043157613131479595
[Epoch 8, Batch 700] loss: 0.03283479020414234
[Epoch 8, Batch 800] loss: 0.028975570218462962
[Epoch 8, Batch 900] loss: 0.02437558051700762
[Epoch 8, Batch 1000] loss: 0.028912876275135203
[Epoch 8, Batch 1100] loss: 0.02260483793936146
[Epoch 8, Batch 1200] loss: 0.02721920396936184
[Epoch 8, Batch 1300] loss: 0.017577027700535836
[Epoch 8, Batch 1400] loss: 0.023340213882765967
[Epoch 8, Batch 1500] loss: 0.010660272406839795
[Epoch 8, Batch 1600] loss: 0.019579338045296026
[Epoch 8, Batch 1700] loss: 0.01496115220761567
[Epoch 8, Batch 1800] loss: 0.0410589084025878
[Epoch 8, Batch 1900] loss: 0.01402314617545926
[Epoch 8, Batch 2000] loss: 0.020551532046047215
[Epoch 8, Batch 2100] loss: 0.02768083606080836
[Epoch 8, Batch 2200] loss: 0.03265145262179431
[Epoch 8, Batch 2300] loss: 0.01771226524195299
[Epoch 8, Batch 2400] loss: 0.043099220795047584
[Epoch 8, Batch 2500] loss: 0.035451805302363935
[Epoch 8, Batch 2600] loss: 0.03313263955795264
[Epoch 8, Batch 2700] loss: 0.010770143126064795
[Epoch 8, Batch 2800] loss: 0.014864395972326748
[Epoch 8, Batch 2900] loss: 0.022984993200916504
[Epoch 8, Batch 3000] loss: 0.015319950547564076
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0387
Validation Accuracy: 0.9886
Overfitting: 0.0387
Best model saved at epoch 8 with validation loss: 0.0387
[Epoch 9, Batch 100] loss: 0.006670765004892019
[Epoch 9, Batch 200] loss: 0.013438954601151637
[Epoch 9, Batch 300] loss: 0.024055105904590163
[Epoch 9, Batch 400] loss: 0.023185905763530173
[Epoch 9, Batch 500] loss: 0.019442105361922587
[Epoch 9, Batch 600] loss: 0.02454847804339806
[Epoch 9, Batch 700] loss: 0.03435491674710647
[Epoch 9, Batch 800] loss: 0.0329946336535977
[Epoch 9, Batch 900] loss: 0.01297563822074153
[Epoch 9, Batch 1000] loss: 0.024254644002576244
[Epoch 9, Batch 1100] loss: 0.02551532570752897
[Epoch 9, Batch 1200] loss: 0.04098820774182968
[Epoch 9, Batch 1300] loss: 0.013533850513776997
[Epoch 9, Batch 1400] loss: 0.021905846438748995
[Epoch 9, Batch 1500] loss: 0.015553020381412352
[Epoch 9, Batch 1600] loss: 0.016398413679926307
[Epoch 9, Batch 1700] loss: 0.023939540449318883
[Epoch 9, Batch 1800] loss: 0.02088074019364285
[Epoch 9, Batch 1900] loss: 0.01456056819864898
[Epoch 9, Batch 2000] loss: 0.01736915999386838
[Epoch 9, Batch 2100] loss: 0.0255051052712588
[Epoch 9, Batch 2200] loss: 0.02772127411346446
[Epoch 9, Batch 2300] loss: 0.016744142065417692
[Epoch 9, Batch 2400] loss: 0.025865546773420647
[Epoch 9, Batch 2500] loss: 0.012999089232944244
[Epoch 9, Batch 2600] loss: 0.02822540077665053
[Epoch 9, Batch 2700] loss: 0.01409825615637601
[Epoch 9, Batch 2800] loss: 0.02929798181350634
[Epoch 9, Batch 2900] loss: 0.020677022164127267
[Epoch 9, Batch 3000] loss: 0.021807894554913217
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0428
Validation Accuracy: 0.9867
Overfitting: 0.0428
[Epoch 10, Batch 100] loss: 0.02066605910935323
[Epoch 10, Batch 200] loss: 0.011165558066531958
[Epoch 10, Batch 300] loss: 0.01070449055715926
[Epoch 10, Batch 400] loss: 0.0041250969714974415
[Epoch 10, Batch 500] loss: 0.022078409442965494
[Epoch 10, Batch 600] loss: 0.017438233441571357
[Epoch 10, Batch 700] loss: 0.021229180315986015
[Epoch 10, Batch 800] loss: 0.024437347600523934
[Epoch 10, Batch 900] loss: 0.011376429287247447
[Epoch 10, Batch 1000] loss: 0.014685031539547708
[Epoch 10, Batch 1100] loss: 0.020121172111430496
[Epoch 10, Batch 1200] loss: 0.014134701516923087
[Epoch 10, Batch 1300] loss: 0.017803857344460994
[Epoch 10, Batch 1400] loss: 0.03433661843849222
[Epoch 10, Batch 1500] loss: 0.01852199819724774
[Epoch 10, Batch 1600] loss: 0.012055100316192693
[Epoch 10, Batch 1700] loss: 0.01768718751354754
[Epoch 10, Batch 1800] loss: 0.020255531697948755
[Epoch 10, Batch 1900] loss: 0.010778752714595613
[Epoch 10, Batch 2000] loss: 0.017266005116216548
[Epoch 10, Batch 2100] loss: 0.023784223951934108
[Epoch 10, Batch 2200] loss: 0.021301880592818633
[Epoch 10, Batch 2300] loss: 0.03150283238229349
[Epoch 10, Batch 2400] loss: 0.0173386575251061
[Epoch 10, Batch 2500] loss: 0.019412846435407118
[Epoch 10, Batch 2600] loss: 0.02154318023518499
[Epoch 10, Batch 2700] loss: 0.02325812303854036
[Epoch 10, Batch 2800] loss: 0.04021359283430684
[Epoch 10, Batch 2900] loss: 0.019734030996514777
[Epoch 10, Batch 3000] loss: 0.016600673560449194
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0422
Validation Accuracy: 0.9876
Overfitting: 0.0422
[Epoch 11, Batch 100] loss: 0.018002160126725356
[Epoch 11, Batch 200] loss: 0.01335938520183845
[Epoch 11, Batch 300] loss: 0.01445473199866683
[Epoch 11, Batch 400] loss: 0.011916699839821377
[Epoch 11, Batch 500] loss: 0.016504162019555225
[Epoch 11, Batch 600] loss: 0.01459455093172437
[Epoch 11, Batch 700] loss: 0.010917306976176632
[Epoch 11, Batch 800] loss: 0.010302225171835743
[Epoch 11, Batch 900] loss: 0.011509535508830595
[Epoch 11, Batch 1000] loss: 0.02587014365582945
[Epoch 11, Batch 1100] loss: 0.017118085544170755
[Epoch 11, Batch 1200] loss: 0.017805086446369387
[Epoch 11, Batch 1300] loss: 0.01619622832929963
[Epoch 11, Batch 1400] loss: 0.014612675650023449
[Epoch 11, Batch 1500] loss: 0.023820180669572436
[Epoch 11, Batch 1600] loss: 0.010805302012308858
[Epoch 11, Batch 1700] loss: 0.015336198780742051
[Epoch 11, Batch 1800] loss: 0.010781830321884628
[Epoch 11, Batch 1900] loss: 0.01655007949757419
[Epoch 11, Batch 2000] loss: 0.01639197241554939
[Epoch 11, Batch 2100] loss: 0.021043485276813954
[Epoch 11, Batch 2200] loss: 0.017875558237014956
[Epoch 11, Batch 2300] loss: 0.0177621347069271
[Epoch 11, Batch 2400] loss: 0.013311525816770881
[Epoch 11, Batch 2500] loss: 0.017369385704701017
[Epoch 11, Batch 2600] loss: 0.018724456694153558
[Epoch 11, Batch 2700] loss: 0.02115082787805477
[Epoch 11, Batch 2800] loss: 0.013258547547748094
[Epoch 11, Batch 2900] loss: 0.01582206778239197
[Epoch 11, Batch 3000] loss: 0.03395603368598131
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0420
Validation Accuracy: 0.9873
Overfitting: 0.0420
[Epoch 12, Batch 100] loss: 0.023955244107291947
[Epoch 12, Batch 200] loss: 0.0203015661925383
[Epoch 12, Batch 300] loss: 0.01341053044259752
[Epoch 12, Batch 400] loss: 0.021301564156019595
[Epoch 12, Batch 500] loss: 0.011166765341890823
[Epoch 12, Batch 600] loss: 0.009963754961827363
[Epoch 12, Batch 700] loss: 0.009932696330756698
[Epoch 12, Batch 800] loss: 0.02281446745666699
[Epoch 12, Batch 900] loss: 0.009764622924753894
[Epoch 12, Batch 1000] loss: 0.008383823099902656
[Epoch 12, Batch 1100] loss: 0.009476483919415841
[Epoch 12, Batch 1200] loss: 0.006853535131822355
[Epoch 12, Batch 1300] loss: 0.011107393627098646
[Epoch 12, Batch 1400] loss: 0.00699483367026005
[Epoch 12, Batch 1500] loss: 0.0144342563790633
[Epoch 12, Batch 1600] loss: 0.013335169424353808
[Epoch 12, Batch 1700] loss: 0.021880710758173338
[Epoch 12, Batch 1800] loss: 0.01389312630970835
[Epoch 12, Batch 1900] loss: 0.019194465445416427
[Epoch 12, Batch 2000] loss: 0.00838303996306422
[Epoch 12, Batch 2100] loss: 0.015311684314206105
[Epoch 12, Batch 2200] loss: 0.015398840338643822
[Epoch 12, Batch 2300] loss: 0.01379035471858515
[Epoch 12, Batch 2400] loss: 0.013673898177012233
[Epoch 12, Batch 2500] loss: 0.008452552957023726
[Epoch 12, Batch 2600] loss: 0.012912884248848969
[Epoch 12, Batch 2700] loss: 0.02046683771658536
[Epoch 12, Batch 2800] loss: 0.018141812040639707
[Epoch 12, Batch 2900] loss: 0.011643656080582331
[Epoch 12, Batch 3000] loss: 0.008854247607314392
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9875
Overfitting: 0.0453
[Epoch 13, Batch 100] loss: 0.013525156448395137
[Epoch 13, Batch 200] loss: 0.01217912292294386
[Epoch 13, Batch 300] loss: 0.01074024578351782
[Epoch 13, Batch 400] loss: 0.010334371129481497
[Epoch 13, Batch 500] loss: 0.005060475171528651
[Epoch 13, Batch 600] loss: 0.017195698951718442
[Epoch 13, Batch 700] loss: 0.019079237771129555
[Epoch 13, Batch 800] loss: 0.009739753083922551
[Epoch 13, Batch 900] loss: 0.0097380863734179
[Epoch 13, Batch 1000] loss: 0.012657322059801572
[Epoch 13, Batch 1100] loss: 0.007100133790645486
[Epoch 13, Batch 1200] loss: 0.010004707785083156
[Epoch 13, Batch 1300] loss: 0.023681428251825308
[Epoch 13, Batch 1400] loss: 0.012183789100722606
[Epoch 13, Batch 1500] loss: 0.010160292934133395
[Epoch 13, Batch 1600] loss: 0.009971581966237864
[Epoch 13, Batch 1700] loss: 0.007675911412429741
[Epoch 13, Batch 1800] loss: 0.018199080687356855
[Epoch 13, Batch 1900] loss: 0.015500976031303253
[Epoch 13, Batch 2000] loss: 0.02074093661905863
[Epoch 13, Batch 2100] loss: 0.0064114813794367365
[Epoch 13, Batch 2200] loss: 0.010822179408514786
[Epoch 13, Batch 2300] loss: 0.011515231942903483
[Epoch 13, Batch 2400] loss: 0.020435213675532395
[Epoch 13, Batch 2500] loss: 0.01525193246935828
[Epoch 13, Batch 2600] loss: 0.006956781957810563
[Epoch 13, Batch 2700] loss: 0.014297628745862313
[Epoch 13, Batch 2800] loss: 0.013310176795192774
[Epoch 13, Batch 2900] loss: 0.009949992583399308
[Epoch 13, Batch 3000] loss: 0.013231461900713839
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0393
Validation Accuracy: 0.9888
Overfitting: 0.0393
[Epoch 14, Batch 100] loss: 0.012223314110258343
[Epoch 14, Batch 200] loss: 0.012307551104850063
[Epoch 14, Batch 300] loss: 0.006870094799955951
[Epoch 14, Batch 400] loss: 0.004006021130198861
[Epoch 14, Batch 500] loss: 0.005052824775220301
[Epoch 14, Batch 600] loss: 0.010095962220316324
[Epoch 14, Batch 700] loss: 0.01080470088424363
[Epoch 14, Batch 800] loss: 0.01792364085465124
[Epoch 14, Batch 900] loss: 0.02458928664553241
[Epoch 14, Batch 1000] loss: 0.011851961266988837
[Epoch 14, Batch 1100] loss: 0.007649810702600917
[Epoch 14, Batch 1200] loss: 0.017320232090442006
[Epoch 14, Batch 1300] loss: 0.007047076703656785
[Epoch 14, Batch 1400] loss: 0.007246057911997923
[Epoch 14, Batch 1500] loss: 0.015521137061947457
[Epoch 14, Batch 1600] loss: 0.008126400127271154
[Epoch 14, Batch 1700] loss: 0.01186513652465237
[Epoch 14, Batch 1800] loss: 0.010439199845222902
[Epoch 14, Batch 1900] loss: 0.01093715287121995
[Epoch 14, Batch 2000] loss: 0.0061579395869785
[Epoch 14, Batch 2100] loss: 0.00932461032667561
[Epoch 14, Batch 2200] loss: 0.008662407046713269
[Epoch 14, Batch 2300] loss: 0.010600638265584621
[Epoch 14, Batch 2400] loss: 0.012916177086353856
[Epoch 14, Batch 2500] loss: 0.012436039849194457
[Epoch 14, Batch 2600] loss: 0.011068964531198162
[Epoch 14, Batch 2700] loss: 0.013151049701359625
[Epoch 14, Batch 2800] loss: 0.014446973501990215
[Epoch 14, Batch 2900] loss: 0.017340427678454944
[Epoch 14, Batch 3000] loss: 0.012561072543819591
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0375
Validation Accuracy: 0.9889
Overfitting: 0.0375
Best model saved at epoch 14 with validation loss: 0.0375
[Epoch 15, Batch 100] loss: 0.005876702087241483
[Epoch 15, Batch 200] loss: 0.009630579088054673
[Epoch 15, Batch 300] loss: 0.014169318029303213
[Epoch 15, Batch 400] loss: 0.0032918690446365416
[Epoch 15, Batch 500] loss: 0.007889675477999845
[Epoch 15, Batch 600] loss: 0.010361144279813743
[Epoch 15, Batch 700] loss: 0.012829329069741107
[Epoch 15, Batch 800] loss: 0.007149766432917204
[Epoch 15, Batch 900] loss: 0.00643316420130759
[Epoch 15, Batch 1000] loss: 0.009792248801809933
[Epoch 15, Batch 1100] loss: 0.009560672590653211
[Epoch 15, Batch 1200] loss: 0.0080666469800326
[Epoch 15, Batch 1300] loss: 0.004914561058290019
[Epoch 15, Batch 1400] loss: 0.008154612045423164
[Epoch 15, Batch 1500] loss: 0.012777638722368465
[Epoch 15, Batch 1600] loss: 0.013370466155140547
[Epoch 15, Batch 1700] loss: 0.00537047218268981
[Epoch 15, Batch 1800] loss: 0.0128756237477171
[Epoch 15, Batch 1900] loss: 0.019848124573700263
[Epoch 15, Batch 2000] loss: 0.010381219516918918
[Epoch 15, Batch 2100] loss: 0.007532925484576935
[Epoch 15, Batch 2200] loss: 0.01044618761550737
[Epoch 15, Batch 2300] loss: 0.00998905543080184
[Epoch 15, Batch 2400] loss: 0.00814515141093466
[Epoch 15, Batch 2500] loss: 0.007135905386171544
[Epoch 15, Batch 2600] loss: 0.013054764174122511
[Epoch 15, Batch 2700] loss: 0.008695142921496882
[Epoch 15, Batch 2800] loss: 0.0066673153330827975
[Epoch 15, Batch 2900] loss: 0.02415767081498416
[Epoch 15, Batch 3000] loss: 0.0103647008620419
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9879
Overfitting: 0.0445
[Epoch 16, Batch 100] loss: 0.004431980702784131
[Epoch 16, Batch 200] loss: 0.008363728080071268
[Epoch 16, Batch 300] loss: 0.008599657175007564
[Epoch 16, Batch 400] loss: 0.006528875400901768
[Epoch 16, Batch 500] loss: 0.002827090984363778
[Epoch 16, Batch 600] loss: 0.012087141435710578
[Epoch 16, Batch 700] loss: 0.010956402511334317
[Epoch 16, Batch 800] loss: 0.015007476190667147
[Epoch 16, Batch 900] loss: 0.011884369896956742
[Epoch 16, Batch 1000] loss: 0.011455167505450845
[Epoch 16, Batch 1100] loss: 0.007595785339713074
[Epoch 16, Batch 1200] loss: 0.005870461269025782
[Epoch 16, Batch 1300] loss: 0.008436086553950872
[Epoch 16, Batch 1400] loss: 0.010536606315022255
[Epoch 16, Batch 1500] loss: 0.004765418725271502
[Epoch 16, Batch 1600] loss: 0.00765260919573393
[Epoch 16, Batch 1700] loss: 0.0030925009283151892
[Epoch 16, Batch 1800] loss: 0.008302994473519334
[Epoch 16, Batch 1900] loss: 0.010453693341394227
[Epoch 16, Batch 2000] loss: 0.004010275918643629
[Epoch 16, Batch 2100] loss: 0.004937865892085256
[Epoch 16, Batch 2200] loss: 0.0025348220958744607
[Epoch 16, Batch 2300] loss: 0.008614768731852677
[Epoch 16, Batch 2400] loss: 0.01723798780427387
[Epoch 16, Batch 2500] loss: 0.017715851534712782
[Epoch 16, Batch 2600] loss: 0.007111659880935122
[Epoch 16, Batch 2700] loss: 0.009733539315648158
[Epoch 16, Batch 2800] loss: 0.004350206141681383
[Epoch 16, Batch 2900] loss: 0.0018994952294087853
[Epoch 16, Batch 3000] loss: 0.0076175578460339465
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9878
Overfitting: 0.0474
[Epoch 17, Batch 100] loss: 0.009145027271784727
[Epoch 17, Batch 200] loss: 0.011949440829795321
[Epoch 17, Batch 300] loss: 0.0019559584107878437
[Epoch 17, Batch 400] loss: 0.004801207885492431
[Epoch 17, Batch 500] loss: 0.003951706789642344
[Epoch 17, Batch 600] loss: 0.003055005953824548
[Epoch 17, Batch 700] loss: 0.003007016682885251
[Epoch 17, Batch 800] loss: 0.021311249438825827
[Epoch 17, Batch 900] loss: 0.004436900650434836
[Epoch 17, Batch 1000] loss: 0.011007025783410711
[Epoch 17, Batch 1100] loss: 0.005207305596840115
[Epoch 17, Batch 1200] loss: 0.0098087965360034
[Epoch 17, Batch 1300] loss: 0.002473366193009099
[Epoch 17, Batch 1400] loss: 0.0063775904321568076
[Epoch 17, Batch 1500] loss: 0.00818284090603811
[Epoch 17, Batch 1600] loss: 0.01026460932639921
[Epoch 17, Batch 1700] loss: 0.00880185133462021
[Epoch 17, Batch 1800] loss: 0.008147143064874065
[Epoch 17, Batch 1900] loss: 0.0034274966140492324
[Epoch 17, Batch 2000] loss: 0.012344910347285918
[Epoch 17, Batch 2100] loss: 0.007935993161784154
[Epoch 17, Batch 2200] loss: 0.004281534707802166
[Epoch 17, Batch 2300] loss: 0.004293223913080339
[Epoch 17, Batch 2400] loss: 0.009045835446034971
[Epoch 17, Batch 2500] loss: 0.005963635594987693
[Epoch 17, Batch 2600] loss: 0.007859872173794429
[Epoch 17, Batch 2700] loss: 0.011450677979521231
[Epoch 17, Batch 2800] loss: 0.010630240956813282
[Epoch 17, Batch 2900] loss: 0.01599953697819785
[Epoch 17, Batch 3000] loss: 0.02351003994657276
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9882
Overfitting: 0.0439
[Epoch 18, Batch 100] loss: 0.005879657264368063
[Epoch 18, Batch 200] loss: 0.007703255688793434
[Epoch 18, Batch 300] loss: 0.004823778380548447
[Epoch 18, Batch 400] loss: 0.0027204371526289607
[Epoch 18, Batch 500] loss: 0.0028232463170843403
[Epoch 18, Batch 600] loss: 0.009698554271967624
[Epoch 18, Batch 700] loss: 0.0031951469268477694
[Epoch 18, Batch 800] loss: 0.005606824111695232
[Epoch 18, Batch 900] loss: 0.003631500101130314
[Epoch 18, Batch 1000] loss: 0.0033130100207961278
[Epoch 18, Batch 1100] loss: 0.005371593834134956
[Epoch 18, Batch 1200] loss: 0.012846620701945994
[Epoch 18, Batch 1300] loss: 0.007371294795378844
[Epoch 18, Batch 1400] loss: 0.0034871416309539428
[Epoch 18, Batch 1500] loss: 0.007696024853898962
[Epoch 18, Batch 1600] loss: 0.00462572480326287
[Epoch 18, Batch 1700] loss: 0.0030184411563524806
[Epoch 18, Batch 1800] loss: 0.005195504176638224
[Epoch 18, Batch 1900] loss: 0.002970054951089125
[Epoch 18, Batch 2000] loss: 0.006568667071450136
[Epoch 18, Batch 2100] loss: 0.00862761953896552
[Epoch 18, Batch 2200] loss: 0.009011842549272444
[Epoch 18, Batch 2300] loss: 0.006435947328324119
[Epoch 18, Batch 2400] loss: 0.004128892832231941
[Epoch 18, Batch 2500] loss: 0.004169497357842715
[Epoch 18, Batch 2600] loss: 0.0023693726488423295
[Epoch 18, Batch 2700] loss: 0.0019655786344733883
[Epoch 18, Batch 2800] loss: 0.006627107924659299
[Epoch 18, Batch 2900] loss: 0.00831602663696998
[Epoch 18, Batch 3000] loss: 0.00681126623605337
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9888
Overfitting: 0.0459
[Epoch 19, Batch 100] loss: 0.0019050166324797147
[Epoch 19, Batch 200] loss: 0.0068758457122362416
[Epoch 19, Batch 300] loss: 0.0027357906138450972
[Epoch 19, Batch 400] loss: 0.007588354362644054
[Epoch 19, Batch 500] loss: 0.002840458385683178
[Epoch 19, Batch 600] loss: 0.0115332890179954
[Epoch 19, Batch 700] loss: 0.006241746259585739
[Epoch 19, Batch 800] loss: 0.005121964528908621
[Epoch 19, Batch 900] loss: 0.006220253682069767
[Epoch 19, Batch 1000] loss: 0.004119555825000134
[Epoch 19, Batch 1100] loss: 0.0027644204915196723
[Epoch 19, Batch 1200] loss: 0.00732698695414598
[Epoch 19, Batch 1300] loss: 0.003983537139135507
[Epoch 19, Batch 1400] loss: 0.0013383961189957461
[Epoch 19, Batch 1500] loss: 0.0082070514277369
[Epoch 19, Batch 1600] loss: 0.003925950989969351
[Epoch 19, Batch 1700] loss: 0.0054525019343219586
[Epoch 19, Batch 1800] loss: 0.002208856119428333
[Epoch 19, Batch 1900] loss: 0.00172156201232609
[Epoch 19, Batch 2000] loss: 0.010607562786074992
[Epoch 19, Batch 2100] loss: 0.009237842383261068
[Epoch 19, Batch 2200] loss: 0.00347952969320346
[Epoch 19, Batch 2300] loss: 0.005401393050342449
[Epoch 19, Batch 2400] loss: 0.008457013760186385
[Epoch 19, Batch 2500] loss: 0.013155159563916073
[Epoch 19, Batch 2600] loss: 0.004232277341209567
[Epoch 19, Batch 2700] loss: 0.006565612438562312
[Epoch 19, Batch 2800] loss: 0.007202977738591017
[Epoch 19, Batch 2900] loss: 0.007088305416968979
[Epoch 19, Batch 3000] loss: 0.0021701047290295606
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0435
Validation Accuracy: 0.9900
Overfitting: 0.0435
[Epoch 20, Batch 100] loss: 0.00341694212248683
[Epoch 20, Batch 200] loss: 0.002122104125483304
[Epoch 20, Batch 300] loss: 0.002560155414339391
[Epoch 20, Batch 400] loss: 0.007839663581954426
[Epoch 20, Batch 500] loss: 0.0025680993743418413
[Epoch 20, Batch 600] loss: 0.007497201604786596
[Epoch 20, Batch 700] loss: 0.004605268454336624
[Epoch 20, Batch 800] loss: 0.0029989604854665686
[Epoch 20, Batch 900] loss: 0.0073930299075545495
[Epoch 20, Batch 1000] loss: 0.003060273609204387
[Epoch 20, Batch 1100] loss: 0.003781293879371468
[Epoch 20, Batch 1200] loss: 0.00187216658093746
[Epoch 20, Batch 1300] loss: 0.0027957801847924204
[Epoch 20, Batch 1400] loss: 0.0015949126461961781
[Epoch 20, Batch 1500] loss: 0.009772951436619479
[Epoch 20, Batch 1600] loss: 0.0038297978534532007
[Epoch 20, Batch 1700] loss: 0.00942448731551451
[Epoch 20, Batch 1800] loss: 0.006425529209061125
[Epoch 20, Batch 1900] loss: 0.00205769832816685
[Epoch 20, Batch 2000] loss: 0.002439474905286261
[Epoch 20, Batch 2100] loss: 0.00435806410617488
[Epoch 20, Batch 2200] loss: 0.01265344446150351
[Epoch 20, Batch 2300] loss: 0.008017781351294105
[Epoch 20, Batch 2400] loss: 0.006822626402381502
[Epoch 20, Batch 2500] loss: 0.0056316811735990764
[Epoch 20, Batch 2600] loss: 0.008695098067900631
[Epoch 20, Batch 2700] loss: 0.006461898733609246
[Epoch 20, Batch 2800] loss: 0.004026317971266735
[Epoch 20, Batch 2900] loss: 0.008162707396601264
[Epoch 20, Batch 3000] loss: 0.007703411409340788
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9876
Overfitting: 0.0539
[Epoch 21, Batch 100] loss: 0.004152977308361869
[Epoch 21, Batch 200] loss: 0.0027179976095135314
[Epoch 21, Batch 300] loss: 0.005924334571307383
[Epoch 21, Batch 400] loss: 0.008656857368359567
[Epoch 21, Batch 500] loss: 0.011164500805716671
[Epoch 21, Batch 600] loss: 0.005222006719897028
[Epoch 21, Batch 700] loss: 0.0023327058157661894
[Epoch 21, Batch 800] loss: 0.004277408617517154
[Epoch 21, Batch 900] loss: 0.0015492317616650553
[Epoch 21, Batch 1000] loss: 0.001527761513233017
[Epoch 21, Batch 1100] loss: 0.00852681961943972
[Epoch 21, Batch 1200] loss: 0.0035272927085767945
[Epoch 21, Batch 1300] loss: 0.012808044445749438
[Epoch 21, Batch 1400] loss: 0.0026781474765778766
[Epoch 21, Batch 1500] loss: 0.009565000774582017
[Epoch 21, Batch 1600] loss: 0.012352453613931828
[Epoch 21, Batch 1700] loss: 0.008334011385786653
[Epoch 21, Batch 1800] loss: 0.0013644187609272507
[Epoch 21, Batch 1900] loss: 0.006498928349524427
[Epoch 21, Batch 2000] loss: 0.004400390129937292
[Epoch 21, Batch 2100] loss: 0.0013447421337102127
[Epoch 21, Batch 2200] loss: 0.003437890961606769
[Epoch 21, Batch 2300] loss: 0.008943123901477178
[Epoch 21, Batch 2400] loss: 0.005591089149586708
[Epoch 21, Batch 2500] loss: 0.005064290613428568
[Epoch 21, Batch 2600] loss: 0.006331641481807324
[Epoch 21, Batch 2700] loss: 0.008669129485189088
[Epoch 21, Batch 2800] loss: 0.015543825639372528
[Epoch 21, Batch 2900] loss: 0.011547096399233396
[Epoch 21, Batch 3000] loss: 0.010627111477664925
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9868
Overfitting: 0.0544
[Epoch 22, Batch 100] loss: 0.004353628189490735
[Epoch 22, Batch 200] loss: 0.0030120187739083805
[Epoch 22, Batch 300] loss: 0.004019833668264425
[Epoch 22, Batch 400] loss: 0.0033010891893087545
[Epoch 22, Batch 500] loss: 0.0024253396735372233
[Epoch 22, Batch 600] loss: 0.003907097575373442
[Epoch 22, Batch 700] loss: 0.0029939208673762253
[Epoch 22, Batch 800] loss: 0.0070974317551907974
[Epoch 22, Batch 900] loss: 0.005955395712028206
[Epoch 22, Batch 1000] loss: 0.003117612641601397
[Epoch 22, Batch 1100] loss: 0.0028815244557455345
[Epoch 22, Batch 1200] loss: 0.0021466177754699343
[Epoch 22, Batch 1300] loss: 0.006621427422745114
[Epoch 22, Batch 1400] loss: 0.0019282570556514145
[Epoch 22, Batch 1500] loss: 0.004633838073526135
[Epoch 22, Batch 1600] loss: 0.0011634199358795173
[Epoch 22, Batch 1700] loss: 0.0025255284253137235
[Epoch 22, Batch 1800] loss: 0.0012774354016076473
[Epoch 22, Batch 1900] loss: 0.0008284838723807297
[Epoch 22, Batch 2000] loss: 0.000764427184032641
[Epoch 22, Batch 2100] loss: 0.0036867593686370982
[Epoch 22, Batch 2200] loss: 0.0010321435172150472
[Epoch 22, Batch 2300] loss: 0.006540320951883629
[Epoch 22, Batch 2400] loss: 0.005268578459527298
[Epoch 22, Batch 2500] loss: 0.004485748952576891
[Epoch 22, Batch 2600] loss: 0.0032555486057848524
[Epoch 22, Batch 2700] loss: 0.004638878081214837
[Epoch 22, Batch 2800] loss: 0.006386973645179239
[Epoch 22, Batch 2900] loss: 0.001968390587220341
[Epoch 22, Batch 3000] loss: 0.0092974985275724
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0459
Validation Accuracy: 0.9893
Overfitting: 0.0459
[Epoch 23, Batch 100] loss: 0.0022899744318670657
[Epoch 23, Batch 200] loss: 0.004015681049802708
[Epoch 23, Batch 300] loss: 0.0018019057957311979
[Epoch 23, Batch 400] loss: 0.0019058439174216347
[Epoch 23, Batch 500] loss: 0.0018984389501278543
[Epoch 23, Batch 600] loss: 0.0015699757998720544
[Epoch 23, Batch 700] loss: 0.0027217395098533357
[Epoch 23, Batch 800] loss: 0.001049044941779016
[Epoch 23, Batch 900] loss: 0.0006079546660966884
[Epoch 23, Batch 1000] loss: 0.0007337767301362419
[Epoch 23, Batch 1100] loss: 0.0032631091857933826
[Epoch 23, Batch 1200] loss: 0.001806266802079346
[Epoch 23, Batch 1300] loss: 0.0067191503020956845
[Epoch 23, Batch 1400] loss: 0.0024829265534690847
[Epoch 23, Batch 1500] loss: 0.0025658811456607112
[Epoch 23, Batch 1600] loss: 0.0012079207087945987
[Epoch 23, Batch 1700] loss: 0.0014670996132765879
[Epoch 23, Batch 1800] loss: 0.0018971420714185428
[Epoch 23, Batch 1900] loss: 0.0036711488020803175
[Epoch 23, Batch 2000] loss: 0.005743349074411377
[Epoch 23, Batch 2100] loss: 0.0030027047138825934
[Epoch 23, Batch 2200] loss: 0.0006126978839163399
[Epoch 23, Batch 2300] loss: 0.002891513141086932
[Epoch 23, Batch 2400] loss: 0.0007807338940783338
[Epoch 23, Batch 2500] loss: 0.0013096272501279317
[Epoch 23, Batch 2600] loss: 0.0010887009526976499
[Epoch 23, Batch 2700] loss: 0.0007485700865606049
[Epoch 23, Batch 2800] loss: 0.005058430377327454
[Epoch 23, Batch 2900] loss: 0.0005333390269117188
[Epoch 23, Batch 3000] loss: 0.0011485735886027015
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9907
Overfitting: 0.0441
[Epoch 24, Batch 100] loss: 0.0005331656818572128
[Epoch 24, Batch 200] loss: 0.0004224662966301196
[Epoch 24, Batch 300] loss: 0.0012814830084442975
[Epoch 24, Batch 400] loss: 0.002082455517723929
[Epoch 24, Batch 500] loss: 0.0002704460064622083
[Epoch 24, Batch 600] loss: 0.0006663412721181316
[Epoch 24, Batch 700] loss: 0.003776815774030773
[Epoch 24, Batch 800] loss: 0.000434126801370347
[Epoch 24, Batch 900] loss: 0.0007743169642966263
[Epoch 24, Batch 1000] loss: 0.0011557271609061814
[Epoch 24, Batch 1100] loss: 0.00025865126375265393
[Epoch 24, Batch 1200] loss: 0.0014631454467831872
[Epoch 24, Batch 1300] loss: 0.00046040121486063513
[Epoch 24, Batch 1400] loss: 0.00040990054948255585
[Epoch 24, Batch 1500] loss: 0.0021699903673350995
[Epoch 24, Batch 1600] loss: 0.0014296902911783605
[Epoch 24, Batch 1700] loss: 0.0013460607925241419
[Epoch 24, Batch 1800] loss: 0.0023238589432935087
[Epoch 24, Batch 1900] loss: 0.0007763693658755955
[Epoch 24, Batch 2000] loss: 0.001388593077191973
[Epoch 24, Batch 2100] loss: 0.0016037759680340713
[Epoch 24, Batch 2200] loss: 0.0011367668054304047
[Epoch 24, Batch 2300] loss: 0.004731677193199033
[Epoch 24, Batch 2400] loss: 0.0010405284759888644
[Epoch 24, Batch 2500] loss: 0.0011447113633084839
[Epoch 24, Batch 2600] loss: 0.0007896812892130355
[Epoch 24, Batch 2700] loss: 0.00040456956399756547
[Epoch 24, Batch 2800] loss: 0.0005829851510136974
[Epoch 24, Batch 2900] loss: 0.0005047816405518546
[Epoch 24, Batch 3000] loss: 0.0014884478242655418
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9893
Overfitting: 0.0532
Fold 5 validation loss: 0.0532
Mean validation loss across all folds for Trial 6 is 0.0568 with trial config:  l1: 128, l2: 64, lr: 0.0015696396388661157, batch_size: 16
[I 2024-12-10 07:16:08,956] Trial 5 finished with value: 0.05680256466540171 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.0015696396388661157, 'batch_size': 16}. Best is trial 4 with value: 0.045411968038914834.

Selected Hyperparameters for Trial 7:
  l1: 128, l2: 64, lr: 0.0003646439558980723, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3006295490264894
**STATS for Epoch 1** : 
Average training loss: 1.0705
Average validation loss: 2.2799
Validation Accuracy: 0.2096
Overfitting: 1.2094
Best model saved at epoch 1 with validation loss: 2.2799
[Epoch 2, Batch 100] loss: 2.270995421409607
**STATS for Epoch 2** : 
Average training loss: 1.0534
Average validation loss: 2.2372
Validation Accuracy: 0.3601
Overfitting: 1.1838
Best model saved at epoch 2 with validation loss: 2.2372
[Epoch 3, Batch 100] loss: 2.217117509841919
**STATS for Epoch 3** : 
Average training loss: 1.0125
Average validation loss: 2.1230
Validation Accuracy: 0.5452
Overfitting: 1.1105
Best model saved at epoch 3 with validation loss: 2.1230
[Epoch 4, Batch 100] loss: 2.0506989228725434
**STATS for Epoch 4** : 
Average training loss: 0.8520
Average validation loss: 1.6407
Validation Accuracy: 0.6550
Overfitting: 0.7888
Best model saved at epoch 4 with validation loss: 1.6407
[Epoch 5, Batch 100] loss: 1.3846338307857513
**STATS for Epoch 5** : 
Average training loss: 0.4416
Average validation loss: 0.7800
Validation Accuracy: 0.7983
Overfitting: 0.3384
Best model saved at epoch 5 with validation loss: 0.7800
[Epoch 6, Batch 100] loss: 0.6861526960134506
**STATS for Epoch 6** : 
Average training loss: 0.2571
Average validation loss: 0.4957
Validation Accuracy: 0.8601
Overfitting: 0.2386
Best model saved at epoch 6 with validation loss: 0.4957
[Epoch 7, Batch 100] loss: 0.4834730222821236
**STATS for Epoch 7** : 
Average training loss: 0.2006
Average validation loss: 0.3974
Validation Accuracy: 0.8848
Overfitting: 0.1969
Best model saved at epoch 7 with validation loss: 0.3974
[Epoch 8, Batch 100] loss: 0.39594816118478776
**STATS for Epoch 8** : 
Average training loss: 0.1754
Average validation loss: 0.3512
Validation Accuracy: 0.8963
Overfitting: 0.1758
Best model saved at epoch 8 with validation loss: 0.3512
[Epoch 9, Batch 100] loss: 0.350580176115036
**STATS for Epoch 9** : 
Average training loss: 0.1572
Average validation loss: 0.3115
Validation Accuracy: 0.9079
Overfitting: 0.1543
Best model saved at epoch 9 with validation loss: 0.3115
[Epoch 10, Batch 100] loss: 0.3191589967906475
**STATS for Epoch 10** : 
Average training loss: 0.1431
Average validation loss: 0.2850
Validation Accuracy: 0.9155
Overfitting: 0.1419
Best model saved at epoch 10 with validation loss: 0.2850
[Epoch 11, Batch 100] loss: 0.30049158826470374
**STATS for Epoch 11** : 
Average training loss: 0.1293
Average validation loss: 0.2612
Validation Accuracy: 0.9217
Overfitting: 0.1319
Best model saved at epoch 11 with validation loss: 0.2612
[Epoch 12, Batch 100] loss: 0.2745655789971352
**STATS for Epoch 12** : 
Average training loss: 0.1223
Average validation loss: 0.2470
Validation Accuracy: 0.9270
Overfitting: 0.1248
Best model saved at epoch 12 with validation loss: 0.2470
[Epoch 13, Batch 100] loss: 0.25648235097527505
**STATS for Epoch 13** : 
Average training loss: 0.1157
Average validation loss: 0.2338
Validation Accuracy: 0.9292
Overfitting: 0.1181
Best model saved at epoch 13 with validation loss: 0.2338
[Epoch 14, Batch 100] loss: 0.23797123700380327
**STATS for Epoch 14** : 
Average training loss: 0.1098
Average validation loss: 0.2174
Validation Accuracy: 0.9354
Overfitting: 0.1076
Best model saved at epoch 14 with validation loss: 0.2174
[Epoch 15, Batch 100] loss: 0.22853511661291123
**STATS for Epoch 15** : 
Average training loss: 0.1014
Average validation loss: 0.2038
Validation Accuracy: 0.9375
Overfitting: 0.1024
Best model saved at epoch 15 with validation loss: 0.2038
[Epoch 16, Batch 100] loss: 0.21411095753312112
**STATS for Epoch 16** : 
Average training loss: 0.0964
Average validation loss: 0.1911
Validation Accuracy: 0.9443
Overfitting: 0.0947
Best model saved at epoch 16 with validation loss: 0.1911
[Epoch 17, Batch 100] loss: 0.20360686250030993
**STATS for Epoch 17** : 
Average training loss: 0.0912
Average validation loss: 0.1892
Validation Accuracy: 0.9430
Overfitting: 0.0980
Best model saved at epoch 17 with validation loss: 0.1892
[Epoch 18, Batch 100] loss: 0.1909125078469515
**STATS for Epoch 18** : 
Average training loss: 0.0875
Average validation loss: 0.1724
Validation Accuracy: 0.9482
Overfitting: 0.0849
Best model saved at epoch 18 with validation loss: 0.1724
[Epoch 19, Batch 100] loss: 0.18379147216677666
**STATS for Epoch 19** : 
Average training loss: 0.0833
Average validation loss: 0.1665
Validation Accuracy: 0.9516
Overfitting: 0.0832
Best model saved at epoch 19 with validation loss: 0.1665
[Epoch 20, Batch 100] loss: 0.17267442092299462
**STATS for Epoch 20** : 
Average training loss: 0.0803
Average validation loss: 0.1590
Validation Accuracy: 0.9519
Overfitting: 0.0787
Best model saved at epoch 20 with validation loss: 0.1590
[Epoch 21, Batch 100] loss: 0.168088595867157
**STATS for Epoch 21** : 
Average training loss: 0.0748
Average validation loss: 0.1534
Validation Accuracy: 0.9547
Overfitting: 0.0786
Best model saved at epoch 21 with validation loss: 0.1534
[Epoch 22, Batch 100] loss: 0.15757612250745295
**STATS for Epoch 22** : 
Average training loss: 0.0755
Average validation loss: 0.1495
Validation Accuracy: 0.9555
Overfitting: 0.0740
Best model saved at epoch 22 with validation loss: 0.1495
[Epoch 23, Batch 100] loss: 0.15536658436059952
**STATS for Epoch 23** : 
Average training loss: 0.0693
Average validation loss: 0.1402
Validation Accuracy: 0.9575
Overfitting: 0.0709
Best model saved at epoch 23 with validation loss: 0.1402
[Epoch 24, Batch 100] loss: 0.1470029653608799
**STATS for Epoch 24** : 
Average training loss: 0.0678
Average validation loss: 0.1383
Validation Accuracy: 0.9575
Overfitting: 0.0705
Best model saved at epoch 24 with validation loss: 0.1383
Fold 1 validation loss: 0.1383
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.301116993427277
**STATS for Epoch 1** : 
Average training loss: 1.0717
Average validation loss: 2.2830
Validation Accuracy: 0.1076
Overfitting: 1.2113
Best model saved at epoch 1 with validation loss: 2.2830
[Epoch 2, Batch 100] loss: 2.2751660704612733
**STATS for Epoch 2** : 
Average training loss: 1.0555
Average validation loss: 2.2419
Validation Accuracy: 0.3029
Overfitting: 1.1864
Best model saved at epoch 2 with validation loss: 2.2419
[Epoch 3, Batch 100] loss: 2.2218482732772826
**STATS for Epoch 3** : 
Average training loss: 1.0112
Average validation loss: 2.1133
Validation Accuracy: 0.4436
Overfitting: 1.1021
Best model saved at epoch 3 with validation loss: 2.1133
[Epoch 4, Batch 100] loss: 2.0269641494750976
**STATS for Epoch 4** : 
Average training loss: 0.8234
Average validation loss: 1.5723
Validation Accuracy: 0.5863
Overfitting: 0.7489
Best model saved at epoch 4 with validation loss: 1.5723
[Epoch 5, Batch 100] loss: 1.3163688576221466
**STATS for Epoch 5** : 
Average training loss: 0.4262
Average validation loss: 0.7835
Validation Accuracy: 0.7969
Overfitting: 0.3572
Best model saved at epoch 5 with validation loss: 0.7835
[Epoch 6, Batch 100] loss: 0.6772968518733978
**STATS for Epoch 6** : 
Average training loss: 0.2677
Average validation loss: 0.5531
Validation Accuracy: 0.8377
Overfitting: 0.2854
Best model saved at epoch 6 with validation loss: 0.5531
[Epoch 7, Batch 100] loss: 0.49799592852592467
**STATS for Epoch 7** : 
Average training loss: 0.2280
Average validation loss: 0.4759
Validation Accuracy: 0.8598
Overfitting: 0.2479
Best model saved at epoch 7 with validation loss: 0.4759
[Epoch 8, Batch 100] loss: 0.4444090619683266
**STATS for Epoch 8** : 
Average training loss: 0.1964
Average validation loss: 0.4263
Validation Accuracy: 0.8730
Overfitting: 0.2298
Best model saved at epoch 8 with validation loss: 0.4263
[Epoch 9, Batch 100] loss: 0.39371135652065276
**STATS for Epoch 9** : 
Average training loss: 0.1828
Average validation loss: 0.3905
Validation Accuracy: 0.8857
Overfitting: 0.2077
Best model saved at epoch 9 with validation loss: 0.3905
[Epoch 10, Batch 100] loss: 0.3679022365808487
**STATS for Epoch 10** : 
Average training loss: 0.1664
Average validation loss: 0.3651
Validation Accuracy: 0.8912
Overfitting: 0.1987
Best model saved at epoch 10 with validation loss: 0.3651
[Epoch 11, Batch 100] loss: 0.3422688521444798
**STATS for Epoch 11** : 
Average training loss: 0.1560
Average validation loss: 0.3402
Validation Accuracy: 0.8990
Overfitting: 0.1842
Best model saved at epoch 11 with validation loss: 0.3402
[Epoch 12, Batch 100] loss: 0.32122770220041275
**STATS for Epoch 12** : 
Average training loss: 0.1457
Average validation loss: 0.3243
Validation Accuracy: 0.9038
Overfitting: 0.1787
Best model saved at epoch 12 with validation loss: 0.3243
[Epoch 13, Batch 100] loss: 0.29891118273139
**STATS for Epoch 13** : 
Average training loss: 0.1380
Average validation loss: 0.3021
Validation Accuracy: 0.9117
Overfitting: 0.1640
Best model saved at epoch 13 with validation loss: 0.3021
[Epoch 14, Batch 100] loss: 0.2864833678305149
**STATS for Epoch 14** : 
Average training loss: 0.1293
Average validation loss: 0.2900
Validation Accuracy: 0.9143
Overfitting: 0.1608
Best model saved at epoch 14 with validation loss: 0.2900
[Epoch 15, Batch 100] loss: 0.26491783678531644
**STATS for Epoch 15** : 
Average training loss: 0.1248
Average validation loss: 0.2781
Validation Accuracy: 0.9173
Overfitting: 0.1533
Best model saved at epoch 15 with validation loss: 0.2781
[Epoch 16, Batch 100] loss: 0.2550421324372292
**STATS for Epoch 16** : 
Average training loss: 0.1178
Average validation loss: 0.2615
Validation Accuracy: 0.9233
Overfitting: 0.1437
Best model saved at epoch 16 with validation loss: 0.2615
[Epoch 17, Batch 100] loss: 0.24090808749198914
**STATS for Epoch 17** : 
Average training loss: 0.1116
Average validation loss: 0.2533
Validation Accuracy: 0.9248
Overfitting: 0.1418
Best model saved at epoch 17 with validation loss: 0.2533
[Epoch 18, Batch 100] loss: 0.23236956164240838
**STATS for Epoch 18** : 
Average training loss: 0.1060
Average validation loss: 0.2382
Validation Accuracy: 0.9287
Overfitting: 0.1322
Best model saved at epoch 18 with validation loss: 0.2382
[Epoch 19, Batch 100] loss: 0.22204868704080583
**STATS for Epoch 19** : 
Average training loss: 0.0993
Average validation loss: 0.2266
Validation Accuracy: 0.9327
Overfitting: 0.1273
Best model saved at epoch 19 with validation loss: 0.2266
[Epoch 20, Batch 100] loss: 0.20870877861976622
**STATS for Epoch 20** : 
Average training loss: 0.0956
Average validation loss: 0.2201
Validation Accuracy: 0.9336
Overfitting: 0.1244
Best model saved at epoch 20 with validation loss: 0.2201
[Epoch 21, Batch 100] loss: 0.19958400398492812
**STATS for Epoch 21** : 
Average training loss: 0.0913
Average validation loss: 0.2092
Validation Accuracy: 0.9376
Overfitting: 0.1179
Best model saved at epoch 21 with validation loss: 0.2092
[Epoch 22, Batch 100] loss: 0.19053744465112687
**STATS for Epoch 22** : 
Average training loss: 0.0875
Average validation loss: 0.2008
Validation Accuracy: 0.9388
Overfitting: 0.1133
Best model saved at epoch 22 with validation loss: 0.2008
[Epoch 23, Batch 100] loss: 0.18359678670763968
**STATS for Epoch 23** : 
Average training loss: 0.0825
Average validation loss: 0.1949
Validation Accuracy: 0.9407
Overfitting: 0.1124
Best model saved at epoch 23 with validation loss: 0.1949
[Epoch 24, Batch 100] loss: 0.17185040928423403
**STATS for Epoch 24** : 
Average training loss: 0.0815
Average validation loss: 0.1888
Validation Accuracy: 0.9438
Overfitting: 0.1073
Best model saved at epoch 24 with validation loss: 0.1888
Fold 2 validation loss: 0.1888
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3070611453056333
**STATS for Epoch 1** : 
Average training loss: 1.0777
Average validation loss: 2.2996
Validation Accuracy: 0.1316
Overfitting: 1.2219
Best model saved at epoch 1 with validation loss: 2.2996
[Epoch 2, Batch 100] loss: 2.2969518065452577
**STATS for Epoch 2** : 
Average training loss: 1.0730
Average validation loss: 2.2899
Validation Accuracy: 0.1805
Overfitting: 1.2169
Best model saved at epoch 2 with validation loss: 2.2899
[Epoch 3, Batch 100] loss: 2.287160184383392
**STATS for Epoch 3** : 
Average training loss: 1.0675
Average validation loss: 2.2777
Validation Accuracy: 0.2183
Overfitting: 1.2102
Best model saved at epoch 3 with validation loss: 2.2777
[Epoch 4, Batch 100] loss: 2.2732211208343505
**STATS for Epoch 4** : 
Average training loss: 1.0598
Average validation loss: 2.2582
Validation Accuracy: 0.2355
Overfitting: 1.1985
Best model saved at epoch 4 with validation loss: 2.2582
[Epoch 5, Batch 100] loss: 2.2503458786010744
**STATS for Epoch 5** : 
Average training loss: 1.0441
Average validation loss: 2.2179
Validation Accuracy: 0.2884
Overfitting: 1.1738
Best model saved at epoch 5 with validation loss: 2.2179
[Epoch 6, Batch 100] loss: 2.1975984668731687
**STATS for Epoch 6** : 
Average training loss: 1.0025
Average validation loss: 2.0988
Validation Accuracy: 0.4656
Overfitting: 1.0963
Best model saved at epoch 6 with validation loss: 2.0988
[Epoch 7, Batch 100] loss: 2.0209379518032073
**STATS for Epoch 7** : 
Average training loss: 0.8230
Average validation loss: 1.5505
Validation Accuracy: 0.6837
Overfitting: 0.7274
Best model saved at epoch 7 with validation loss: 1.5505
[Epoch 8, Batch 100] loss: 1.2755911475419999
**STATS for Epoch 8** : 
Average training loss: 0.3946
Average validation loss: 0.7023
Validation Accuracy: 0.8192
Overfitting: 0.3077
Best model saved at epoch 8 with validation loss: 0.7023
[Epoch 9, Batch 100] loss: 0.6329674974083901
**STATS for Epoch 9** : 
Average training loss: 0.2471
Average validation loss: 0.4811
Validation Accuracy: 0.8663
Overfitting: 0.2340
Best model saved at epoch 9 with validation loss: 0.4811
[Epoch 10, Batch 100] loss: 0.46387406885623933
**STATS for Epoch 10** : 
Average training loss: 0.1996
Average validation loss: 0.4002
Validation Accuracy: 0.8876
Overfitting: 0.2006
Best model saved at epoch 10 with validation loss: 0.4002
[Epoch 11, Batch 100] loss: 0.39528713554143907
**STATS for Epoch 11** : 
Average training loss: 0.1706
Average validation loss: 0.3549
Validation Accuracy: 0.9014
Overfitting: 0.1842
Best model saved at epoch 11 with validation loss: 0.3549
[Epoch 12, Batch 100] loss: 0.35266996204853057
**STATS for Epoch 12** : 
Average training loss: 0.1509
Average validation loss: 0.3168
Validation Accuracy: 0.9098
Overfitting: 0.1659
Best model saved at epoch 12 with validation loss: 0.3168
[Epoch 13, Batch 100] loss: 0.31984654754400255
**STATS for Epoch 13** : 
Average training loss: 0.1373
Average validation loss: 0.2924
Validation Accuracy: 0.9166
Overfitting: 0.1551
Best model saved at epoch 13 with validation loss: 0.2924
[Epoch 14, Batch 100] loss: 0.2859560903906822
**STATS for Epoch 14** : 
Average training loss: 0.1303
Average validation loss: 0.2713
Validation Accuracy: 0.9233
Overfitting: 0.1410
Best model saved at epoch 14 with validation loss: 0.2713
[Epoch 15, Batch 100] loss: 0.2607112215459347
**STATS for Epoch 15** : 
Average training loss: 0.1218
Average validation loss: 0.2547
Validation Accuracy: 0.9256
Overfitting: 0.1329
Best model saved at epoch 15 with validation loss: 0.2547
[Epoch 16, Batch 100] loss: 0.2469161082804203
**STATS for Epoch 16** : 
Average training loss: 0.1105
Average validation loss: 0.2361
Validation Accuracy: 0.9336
Overfitting: 0.1256
Best model saved at epoch 16 with validation loss: 0.2361
[Epoch 17, Batch 100] loss: 0.22927661538124083
**STATS for Epoch 17** : 
Average training loss: 0.1038
Average validation loss: 0.2222
Validation Accuracy: 0.9373
Overfitting: 0.1184
Best model saved at epoch 17 with validation loss: 0.2222
[Epoch 18, Batch 100] loss: 0.2149904464185238
**STATS for Epoch 18** : 
Average training loss: 0.0972
Average validation loss: 0.2112
Validation Accuracy: 0.9392
Overfitting: 0.1140
Best model saved at epoch 18 with validation loss: 0.2112
[Epoch 19, Batch 100] loss: 0.20247262611985206
**STATS for Epoch 19** : 
Average training loss: 0.0924
Average validation loss: 0.2017
Validation Accuracy: 0.9425
Overfitting: 0.1093
Best model saved at epoch 19 with validation loss: 0.2017
[Epoch 20, Batch 100] loss: 0.19303072936832905
**STATS for Epoch 20** : 
Average training loss: 0.0867
Average validation loss: 0.1918
Validation Accuracy: 0.9435
Overfitting: 0.1051
Best model saved at epoch 20 with validation loss: 0.1918
[Epoch 21, Batch 100] loss: 0.18235961593687533
**STATS for Epoch 21** : 
Average training loss: 0.0834
Average validation loss: 0.1818
Validation Accuracy: 0.9474
Overfitting: 0.0984
Best model saved at epoch 21 with validation loss: 0.1818
[Epoch 22, Batch 100] loss: 0.17138116203248502
**STATS for Epoch 22** : 
Average training loss: 0.0802
Average validation loss: 0.1740
Validation Accuracy: 0.9499
Overfitting: 0.0938
Best model saved at epoch 22 with validation loss: 0.1740
[Epoch 23, Batch 100] loss: 0.15908073969185352
**STATS for Epoch 23** : 
Average training loss: 0.0790
Average validation loss: 0.1694
Validation Accuracy: 0.9503
Overfitting: 0.0904
Best model saved at epoch 23 with validation loss: 0.1694
[Epoch 24, Batch 100] loss: 0.15974375411868094
**STATS for Epoch 24** : 
Average training loss: 0.0720
Average validation loss: 0.1610
Validation Accuracy: 0.9521
Overfitting: 0.0890
Best model saved at epoch 24 with validation loss: 0.1610
Fold 3 validation loss: 0.1610
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.3029028844833372
**STATS for Epoch 1** : 
Average training loss: 1.0739
Average validation loss: 2.2903
Validation Accuracy: 0.1383
Overfitting: 1.2164
Best model saved at epoch 1 with validation loss: 2.2903
[Epoch 2, Batch 100] loss: 2.28497850894928
**STATS for Epoch 2** : 
Average training loss: 1.0641
Average validation loss: 2.2665
Validation Accuracy: 0.2067
Overfitting: 1.2024
Best model saved at epoch 2 with validation loss: 2.2665
[Epoch 3, Batch 100] loss: 2.2557199668884276
**STATS for Epoch 3** : 
Average training loss: 1.0437
Average validation loss: 2.2134
Validation Accuracy: 0.3650
Overfitting: 1.1698
Best model saved at epoch 3 with validation loss: 2.2134
[Epoch 4, Batch 100] loss: 2.182469606399536
**STATS for Epoch 4** : 
Average training loss: 0.9800
Average validation loss: 2.0296
Validation Accuracy: 0.5127
Overfitting: 1.0496
Best model saved at epoch 4 with validation loss: 2.0296
[Epoch 5, Batch 100] loss: 1.8898699080944061
**STATS for Epoch 5** : 
Average training loss: 0.7041
Average validation loss: 1.2714
Validation Accuracy: 0.6898
Overfitting: 0.5673
Best model saved at epoch 5 with validation loss: 1.2714
[Epoch 6, Batch 100] loss: 1.039432161450386
**STATS for Epoch 6** : 
Average training loss: 0.3510
Average validation loss: 0.6789
Validation Accuracy: 0.7953
Overfitting: 0.3279
Best model saved at epoch 6 with validation loss: 0.6789
[Epoch 7, Batch 100] loss: 0.6120068842172622
**STATS for Epoch 7** : 
Average training loss: 0.2489
Average validation loss: 0.5106
Validation Accuracy: 0.8439
Overfitting: 0.2617
Best model saved at epoch 7 with validation loss: 0.5106
[Epoch 8, Batch 100] loss: 0.4829349210858345
**STATS for Epoch 8** : 
Average training loss: 0.2045
Average validation loss: 0.4281
Validation Accuracy: 0.8676
Overfitting: 0.2236
Best model saved at epoch 8 with validation loss: 0.4281
[Epoch 9, Batch 100] loss: 0.4091222298145294
**STATS for Epoch 9** : 
Average training loss: 0.1789
Average validation loss: 0.3737
Validation Accuracy: 0.8838
Overfitting: 0.1948
Best model saved at epoch 9 with validation loss: 0.3737
[Epoch 10, Batch 100] loss: 0.36351490586996077
**STATS for Epoch 10** : 
Average training loss: 0.1581
Average validation loss: 0.3366
Validation Accuracy: 0.8949
Overfitting: 0.1784
Best model saved at epoch 10 with validation loss: 0.3366
[Epoch 11, Batch 100] loss: 0.32672348245978355
**STATS for Epoch 11** : 
Average training loss: 0.1439
Average validation loss: 0.3064
Validation Accuracy: 0.9030
Overfitting: 0.1625
Best model saved at epoch 11 with validation loss: 0.3064
[Epoch 12, Batch 100] loss: 0.30494535639882087
**STATS for Epoch 12** : 
Average training loss: 0.1284
Average validation loss: 0.2825
Validation Accuracy: 0.9099
Overfitting: 0.1541
Best model saved at epoch 12 with validation loss: 0.2825
[Epoch 13, Batch 100] loss: 0.270406324416399
**STATS for Epoch 13** : 
Average training loss: 0.1251
Average validation loss: 0.2626
Validation Accuracy: 0.9164
Overfitting: 0.1375
Best model saved at epoch 13 with validation loss: 0.2626
[Epoch 14, Batch 100] loss: 0.252903883010149
**STATS for Epoch 14** : 
Average training loss: 0.1152
Average validation loss: 0.2447
Validation Accuracy: 0.9223
Overfitting: 0.1295
Best model saved at epoch 14 with validation loss: 0.2447
[Epoch 15, Batch 100] loss: 0.23948307141661643
**STATS for Epoch 15** : 
Average training loss: 0.1071
Average validation loss: 0.2301
Validation Accuracy: 0.9272
Overfitting: 0.1230
Best model saved at epoch 15 with validation loss: 0.2301
[Epoch 16, Batch 100] loss: 0.22419795989990235
**STATS for Epoch 16** : 
Average training loss: 0.1008
Average validation loss: 0.2156
Validation Accuracy: 0.9316
Overfitting: 0.1147
Best model saved at epoch 16 with validation loss: 0.2156
[Epoch 17, Batch 100] loss: 0.21190567180514336
**STATS for Epoch 17** : 
Average training loss: 0.0949
Average validation loss: 0.2030
Validation Accuracy: 0.9356
Overfitting: 0.1082
Best model saved at epoch 17 with validation loss: 0.2030
[Epoch 18, Batch 100] loss: 0.1953570429980755
**STATS for Epoch 18** : 
Average training loss: 0.0921
Average validation loss: 0.1932
Validation Accuracy: 0.9398
Overfitting: 0.1012
Best model saved at epoch 18 with validation loss: 0.1932
[Epoch 19, Batch 100] loss: 0.18572874158620833
**STATS for Epoch 19** : 
Average training loss: 0.0871
Average validation loss: 0.1842
Validation Accuracy: 0.9438
Overfitting: 0.0972
Best model saved at epoch 19 with validation loss: 0.1842
[Epoch 20, Batch 100] loss: 0.18245318852365017
**STATS for Epoch 20** : 
Average training loss: 0.0796
Average validation loss: 0.1786
Validation Accuracy: 0.9448
Overfitting: 0.0990
Best model saved at epoch 20 with validation loss: 0.1786
[Epoch 21, Batch 100] loss: 0.16860109835863113
**STATS for Epoch 21** : 
Average training loss: 0.0796
Average validation loss: 0.1686
Validation Accuracy: 0.9475
Overfitting: 0.0890
Best model saved at epoch 21 with validation loss: 0.1686
[Epoch 22, Batch 100] loss: 0.16241251409053803
**STATS for Epoch 22** : 
Average training loss: 0.0759
Average validation loss: 0.1612
Validation Accuracy: 0.9499
Overfitting: 0.0853
Best model saved at epoch 22 with validation loss: 0.1612
[Epoch 23, Batch 100] loss: 0.15753892034292222
**STATS for Epoch 23** : 
Average training loss: 0.0716
Average validation loss: 0.1561
Validation Accuracy: 0.9513
Overfitting: 0.0845
Best model saved at epoch 23 with validation loss: 0.1561
[Epoch 24, Batch 100] loss: 0.14786163680255413
**STATS for Epoch 24** : 
Average training loss: 0.0707
Average validation loss: 0.1521
Validation Accuracy: 0.9536
Overfitting: 0.0814
Best model saved at epoch 24 with validation loss: 0.1521
Fold 4 validation loss: 0.1521
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.303742468357086
**STATS for Epoch 1** : 
Average training loss: 1.0748
Average validation loss: 2.2933
Validation Accuracy: 0.0908
Overfitting: 1.2185
Best model saved at epoch 1 with validation loss: 2.2933
[Epoch 2, Batch 100] loss: 2.2897165870666503
**STATS for Epoch 2** : 
Average training loss: 1.0664
Average validation loss: 2.2735
Validation Accuracy: 0.2530
Overfitting: 1.2070
Best model saved at epoch 2 with validation loss: 2.2735
[Epoch 3, Batch 100] loss: 2.2664209365844727
**STATS for Epoch 3** : 
Average training loss: 1.0514
Average validation loss: 2.2341
Validation Accuracy: 0.3781
Overfitting: 1.1828
Best model saved at epoch 3 with validation loss: 2.2341
[Epoch 4, Batch 100] loss: 2.2160340428352354
**STATS for Epoch 4** : 
Average training loss: 1.0098
Average validation loss: 2.1152
Validation Accuracy: 0.4610
Overfitting: 1.1055
Best model saved at epoch 4 with validation loss: 2.1152
[Epoch 5, Batch 100] loss: 2.039658133983612
**STATS for Epoch 5** : 
Average training loss: 0.8412
Average validation loss: 1.6245
Validation Accuracy: 0.6020
Overfitting: 0.7833
Best model saved at epoch 5 with validation loss: 1.6245
[Epoch 6, Batch 100] loss: 1.400405524969101
**STATS for Epoch 6** : 
Average training loss: 0.4637
Average validation loss: 0.8570
Validation Accuracy: 0.7721
Overfitting: 0.3934
Best model saved at epoch 6 with validation loss: 0.8570
[Epoch 7, Batch 100] loss: 0.751553561091423
**STATS for Epoch 7** : 
Average training loss: 0.2932
Average validation loss: 0.6001
Validation Accuracy: 0.8184
Overfitting: 0.3068
Best model saved at epoch 7 with validation loss: 0.6001
[Epoch 8, Batch 100] loss: 0.5488915130496025
**STATS for Epoch 8** : 
Average training loss: 0.2375
Average validation loss: 0.4950
Validation Accuracy: 0.8514
Overfitting: 0.2575
Best model saved at epoch 8 with validation loss: 0.4950
[Epoch 9, Batch 100] loss: 0.4641238033771515
**STATS for Epoch 9** : 
Average training loss: 0.2032
Average validation loss: 0.4306
Validation Accuracy: 0.8718
Overfitting: 0.2274
Best model saved at epoch 9 with validation loss: 0.4306
[Epoch 10, Batch 100] loss: 0.4077030384540558
**STATS for Epoch 10** : 
Average training loss: 0.1800
Average validation loss: 0.3872
Validation Accuracy: 0.8855
Overfitting: 0.2071
Best model saved at epoch 10 with validation loss: 0.3872
[Epoch 11, Batch 100] loss: 0.3636588326096535
**STATS for Epoch 11** : 
Average training loss: 0.1666
Average validation loss: 0.3554
Validation Accuracy: 0.8939
Overfitting: 0.1888
Best model saved at epoch 11 with validation loss: 0.3554
[Epoch 12, Batch 100] loss: 0.33327082335948943
**STATS for Epoch 12** : 
Average training loss: 0.1527
Average validation loss: 0.3302
Validation Accuracy: 0.9018
Overfitting: 0.1775
Best model saved at epoch 12 with validation loss: 0.3302
[Epoch 13, Batch 100] loss: 0.30959109485149383
**STATS for Epoch 13** : 
Average training loss: 0.1411
Average validation loss: 0.3057
Validation Accuracy: 0.9091
Overfitting: 0.1646
Best model saved at epoch 13 with validation loss: 0.3057
[Epoch 14, Batch 100] loss: 0.295713242739439
**STATS for Epoch 14** : 
Average training loss: 0.1281
Average validation loss: 0.2866
Validation Accuracy: 0.9151
Overfitting: 0.1585
Best model saved at epoch 14 with validation loss: 0.2866
[Epoch 15, Batch 100] loss: 0.27265144273638725
**STATS for Epoch 15** : 
Average training loss: 0.1217
Average validation loss: 0.2673
Validation Accuracy: 0.9187
Overfitting: 0.1455
Best model saved at epoch 15 with validation loss: 0.2673
[Epoch 16, Batch 100] loss: 0.2493364244699478
**STATS for Epoch 16** : 
Average training loss: 0.1175
Average validation loss: 0.2514
Validation Accuracy: 0.9226
Overfitting: 0.1339
Best model saved at epoch 16 with validation loss: 0.2514
[Epoch 17, Batch 100] loss: 0.2412778741121292
**STATS for Epoch 17** : 
Average training loss: 0.1082
Average validation loss: 0.2384
Validation Accuracy: 0.9262
Overfitting: 0.1302
Best model saved at epoch 17 with validation loss: 0.2384
[Epoch 18, Batch 100] loss: 0.22775331258773804
**STATS for Epoch 18** : 
Average training loss: 0.1023
Average validation loss: 0.2236
Validation Accuracy: 0.9326
Overfitting: 0.1214
Best model saved at epoch 18 with validation loss: 0.2236
[Epoch 19, Batch 100] loss: 0.2103341193497181
**STATS for Epoch 19** : 
Average training loss: 0.0993
Average validation loss: 0.2151
Validation Accuracy: 0.9343
Overfitting: 0.1158
Best model saved at epoch 19 with validation loss: 0.2151
[Epoch 20, Batch 100] loss: 0.2015264792740345
**STATS for Epoch 20** : 
Average training loss: 0.0933
Average validation loss: 0.1999
Validation Accuracy: 0.9389
Overfitting: 0.1066
Best model saved at epoch 20 with validation loss: 0.1999
[Epoch 21, Batch 100] loss: 0.19135435052216054
**STATS for Epoch 21** : 
Average training loss: 0.0898
Average validation loss: 0.1931
Validation Accuracy: 0.9414
Overfitting: 0.1033
Best model saved at epoch 21 with validation loss: 0.1931
[Epoch 22, Batch 100] loss: 0.18899889871478082
**STATS for Epoch 22** : 
Average training loss: 0.0828
Average validation loss: 0.1880
Validation Accuracy: 0.9445
Overfitting: 0.1052
Best model saved at epoch 22 with validation loss: 0.1880
[Epoch 23, Batch 100] loss: 0.1751678053289652
**STATS for Epoch 23** : 
Average training loss: 0.0818
Average validation loss: 0.1775
Validation Accuracy: 0.9477
Overfitting: 0.0957
Best model saved at epoch 23 with validation loss: 0.1775
[Epoch 24, Batch 100] loss: 0.17106039449572563
**STATS for Epoch 24** : 
Average training loss: 0.0768
Average validation loss: 0.1703
Validation Accuracy: 0.9496
Overfitting: 0.0936
Best model saved at epoch 24 with validation loss: 0.1703
Fold 5 validation loss: 0.1703
Mean validation loss across all folds for Trial 7 is 0.1621 with trial config:  l1: 128, l2: 64, lr: 0.0003646439558980723, batch_size: 256
[I 2024-12-10 07:34:50,076] Trial 6 finished with value: 0.16208937960736294 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.0003646439558980723, 'batch_size': 256}. Best is trial 4 with value: 0.045411968038914834.

Selected Hyperparameters for Trial 8:
  l1: 128, l2: 128, lr: 0.002592475660475161, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2729221844673155
[Epoch 1, Batch 200] loss: 1.5189623206853866
[Epoch 1, Batch 300] loss: 0.5534164337813854
[Epoch 1, Batch 400] loss: 0.36890178043395283
[Epoch 1, Batch 500] loss: 0.29602896675467494
[Epoch 1, Batch 600] loss: 0.22461708951741458
[Epoch 1, Batch 700] loss: 0.20237732622772456
[Epoch 1, Batch 800] loss: 0.19103419544175268
[Epoch 1, Batch 900] loss: 0.16531098198145627
[Epoch 1, Batch 1000] loss: 0.18093029774725436
[Epoch 1, Batch 1100] loss: 0.16592531172558667
[Epoch 1, Batch 1200] loss: 0.14480979915708303
[Epoch 1, Batch 1300] loss: 0.12719941949937494
[Epoch 1, Batch 1400] loss: 0.12386803496629
[Epoch 1, Batch 1500] loss: 0.11938987583387643
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1179
Validation Accuracy: 0.9623
Overfitting: 0.1179
Best model saved at epoch 1 with validation loss: 0.1179
[Epoch 2, Batch 100] loss: 0.09177559062838554
[Epoch 2, Batch 200] loss: 0.11777242039795965
[Epoch 2, Batch 300] loss: 0.10615174328442663
[Epoch 2, Batch 400] loss: 0.09986351665575058
[Epoch 2, Batch 500] loss: 0.10351549490820616
[Epoch 2, Batch 600] loss: 0.09104925952386111
[Epoch 2, Batch 700] loss: 0.08399721166584641
[Epoch 2, Batch 800] loss: 0.08896685559302568
[Epoch 2, Batch 900] loss: 0.07446875938680023
[Epoch 2, Batch 1000] loss: 0.07571782681625336
[Epoch 2, Batch 1100] loss: 0.1049454114306718
[Epoch 2, Batch 1200] loss: 0.08168098358903081
[Epoch 2, Batch 1300] loss: 0.08502885924419389
[Epoch 2, Batch 1400] loss: 0.08711639860179275
[Epoch 2, Batch 1500] loss: 0.08214984173886478
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0642
Validation Accuracy: 0.9799
Overfitting: 0.0642
Best model saved at epoch 2 with validation loss: 0.0642
[Epoch 3, Batch 100] loss: 0.07028380567207933
[Epoch 3, Batch 200] loss: 0.06757115379441529
[Epoch 3, Batch 300] loss: 0.060503943790681664
[Epoch 3, Batch 400] loss: 0.044803298768238166
[Epoch 3, Batch 500] loss: 0.07511541621293873
[Epoch 3, Batch 600] loss: 0.06768196583492682
[Epoch 3, Batch 700] loss: 0.06471959772054106
[Epoch 3, Batch 800] loss: 0.0561969375226181
[Epoch 3, Batch 900] loss: 0.05999899439513683
[Epoch 3, Batch 1000] loss: 0.05292159596923739
[Epoch 3, Batch 1100] loss: 0.05261436307337135
[Epoch 3, Batch 1200] loss: 0.06382504393346608
[Epoch 3, Batch 1300] loss: 0.05465578390751034
[Epoch 3, Batch 1400] loss: 0.060469219908118245
[Epoch 3, Batch 1500] loss: 0.06023816600907594
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9833
Overfitting: 0.0535
Best model saved at epoch 3 with validation loss: 0.0535
[Epoch 4, Batch 100] loss: 0.04097804754739627
[Epoch 4, Batch 200] loss: 0.06088255407579709
[Epoch 4, Batch 300] loss: 0.050838113146019166
[Epoch 4, Batch 400] loss: 0.053156538737239314
[Epoch 4, Batch 500] loss: 0.04951562859816477
[Epoch 4, Batch 600] loss: 0.033491484363621565
[Epoch 4, Batch 700] loss: 0.05946523698745296
[Epoch 4, Batch 800] loss: 0.04542815132066608
[Epoch 4, Batch 900] loss: 0.045773986583808435
[Epoch 4, Batch 1000] loss: 0.05695200090238359
[Epoch 4, Batch 1100] loss: 0.05156798687763512
[Epoch 4, Batch 1200] loss: 0.03840988917509094
[Epoch 4, Batch 1300] loss: 0.0522027404489927
[Epoch 4, Batch 1400] loss: 0.04935407396696974
[Epoch 4, Batch 1500] loss: 0.052162929921178144
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9832
Overfitting: 0.0528
Best model saved at epoch 4 with validation loss: 0.0528
[Epoch 5, Batch 100] loss: 0.04361105217016302
[Epoch 5, Batch 200] loss: 0.04145231788686942
[Epoch 5, Batch 300] loss: 0.043270914881140925
[Epoch 5, Batch 400] loss: 0.04561503652250394
[Epoch 5, Batch 500] loss: 0.03041781292296946
[Epoch 5, Batch 600] loss: 0.03146000019274652
[Epoch 5, Batch 700] loss: 0.04168193628138397
[Epoch 5, Batch 800] loss: 0.04384630252898205
[Epoch 5, Batch 900] loss: 0.04312112186220474
[Epoch 5, Batch 1000] loss: 0.035060721870395356
[Epoch 5, Batch 1100] loss: 0.043163204605807554
[Epoch 5, Batch 1200] loss: 0.03104403119737981
[Epoch 5, Batch 1300] loss: 0.040705455181887375
[Epoch 5, Batch 1400] loss: 0.04172556615842041
[Epoch 5, Batch 1500] loss: 0.04277026960917283
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9848
Overfitting: 0.0467
Best model saved at epoch 5 with validation loss: 0.0467
[Epoch 6, Batch 100] loss: 0.0309119483421091
[Epoch 6, Batch 200] loss: 0.03160677445295732
[Epoch 6, Batch 300] loss: 0.03810563399951206
[Epoch 6, Batch 400] loss: 0.03616519623377826
[Epoch 6, Batch 500] loss: 0.03490117463079514
[Epoch 6, Batch 600] loss: 0.029373709634237456
[Epoch 6, Batch 700] loss: 0.03299477661872516
[Epoch 6, Batch 800] loss: 0.028585119592025875
[Epoch 6, Batch 900] loss: 0.03061235961387865
[Epoch 6, Batch 1000] loss: 0.03762307522003539
[Epoch 6, Batch 1100] loss: 0.03001580250405823
[Epoch 6, Batch 1200] loss: 0.034856992131390145
[Epoch 6, Batch 1300] loss: 0.04230193923955085
[Epoch 6, Batch 1400] loss: 0.03594518615398556
[Epoch 6, Batch 1500] loss: 0.03554555745358812
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0426
Validation Accuracy: 0.9867
Overfitting: 0.0426
Best model saved at epoch 6 with validation loss: 0.0426
[Epoch 7, Batch 100] loss: 0.016605200437334135
[Epoch 7, Batch 200] loss: 0.017662417687970448
[Epoch 7, Batch 300] loss: 0.022123985895595978
[Epoch 7, Batch 400] loss: 0.033922630364832
[Epoch 7, Batch 500] loss: 0.029768152780889068
[Epoch 7, Batch 600] loss: 0.032095609882235296
[Epoch 7, Batch 700] loss: 0.0332796781793877
[Epoch 7, Batch 800] loss: 0.030831006861117203
[Epoch 7, Batch 900] loss: 0.03843056606681785
[Epoch 7, Batch 1000] loss: 0.029977194630773737
[Epoch 7, Batch 1100] loss: 0.03304264806851279
[Epoch 7, Batch 1200] loss: 0.028636066447361372
[Epoch 7, Batch 1300] loss: 0.029457582470349734
[Epoch 7, Batch 1400] loss: 0.023430882656757603
[Epoch 7, Batch 1500] loss: 0.02124210124995443
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9868
Overfitting: 0.0452
[Epoch 8, Batch 100] loss: 0.021352659930271328
[Epoch 8, Batch 200] loss: 0.017342714505066397
[Epoch 8, Batch 300] loss: 0.02422558324295096
[Epoch 8, Batch 400] loss: 0.022052024315053133
[Epoch 8, Batch 500] loss: 0.03028990478196647
[Epoch 8, Batch 600] loss: 0.022335676645161583
[Epoch 8, Batch 700] loss: 0.022678397422423585
[Epoch 8, Batch 800] loss: 0.040440514137153515
[Epoch 8, Batch 900] loss: 0.022973009987035765
[Epoch 8, Batch 1000] loss: 0.020809668746369425
[Epoch 8, Batch 1100] loss: 0.024792403205356094
[Epoch 8, Batch 1200] loss: 0.034098946157755564
[Epoch 8, Batch 1300] loss: 0.021075755666242913
[Epoch 8, Batch 1400] loss: 0.02792703991435701
[Epoch 8, Batch 1500] loss: 0.021804592090484222
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9874
Overfitting: 0.0430
[Epoch 9, Batch 100] loss: 0.01749848618521355
[Epoch 9, Batch 200] loss: 0.01915956771088531
[Epoch 9, Batch 300] loss: 0.01643245269500767
[Epoch 9, Batch 400] loss: 0.024043088775797514
[Epoch 9, Batch 500] loss: 0.025702468132076318
[Epoch 9, Batch 600] loss: 0.01724562826751935
[Epoch 9, Batch 700] loss: 0.014192311393999261
[Epoch 9, Batch 800] loss: 0.02109188269092556
[Epoch 9, Batch 900] loss: 0.029426085695959045
[Epoch 9, Batch 1000] loss: 0.02013084087971947
[Epoch 9, Batch 1100] loss: 0.01945630158734275
[Epoch 9, Batch 1200] loss: 0.02239871559373569
[Epoch 9, Batch 1300] loss: 0.031023214664746775
[Epoch 9, Batch 1400] loss: 0.017763490497454768
[Epoch 9, Batch 1500] loss: 0.028106774742773268
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9849
Overfitting: 0.0489
[Epoch 10, Batch 100] loss: 0.01565308429497236
[Epoch 10, Batch 200] loss: 0.017059406995031168
[Epoch 10, Batch 300] loss: 0.013095273345134046
[Epoch 10, Batch 400] loss: 0.015969057645852446
[Epoch 10, Batch 500] loss: 0.021237202670927217
[Epoch 10, Batch 600] loss: 0.0255854201434704
[Epoch 10, Batch 700] loss: 0.010372171580020222
[Epoch 10, Batch 800] loss: 0.019981257445615484
[Epoch 10, Batch 900] loss: 0.01583127793026506
[Epoch 10, Batch 1000] loss: 0.02522171455959324
[Epoch 10, Batch 1100] loss: 0.02098764273177949
[Epoch 10, Batch 1200] loss: 0.021733438963929076
[Epoch 10, Batch 1300] loss: 0.024023249770107214
[Epoch 10, Batch 1400] loss: 0.031281172874241744
[Epoch 10, Batch 1500] loss: 0.019093345462097205
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9862
Overfitting: 0.0468
[Epoch 11, Batch 100] loss: 0.013578581645779195
[Epoch 11, Batch 200] loss: 0.013252068480069283
[Epoch 11, Batch 300] loss: 0.019063036224979443
[Epoch 11, Batch 400] loss: 0.018094228626359836
[Epoch 11, Batch 500] loss: 0.014944729891285534
[Epoch 11, Batch 600] loss: 0.013729832055105362
[Epoch 11, Batch 700] loss: 0.012726145340056973
[Epoch 11, Batch 800] loss: 0.02101459998761129
[Epoch 11, Batch 900] loss: 0.01565711488332454
[Epoch 11, Batch 1000] loss: 0.017524916771671995
[Epoch 11, Batch 1100] loss: 0.010249915240710833
[Epoch 11, Batch 1200] loss: 0.014523778666261932
[Epoch 11, Batch 1300] loss: 0.01673697643818741
[Epoch 11, Batch 1400] loss: 0.01899042962533713
[Epoch 11, Batch 1500] loss: 0.016600349515720154
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0409
Validation Accuracy: 0.9880
Overfitting: 0.0409
Best model saved at epoch 11 with validation loss: 0.0409
[Epoch 12, Batch 100] loss: 0.012703169028100092
[Epoch 12, Batch 200] loss: 0.009660942582268035
[Epoch 12, Batch 300] loss: 0.011676256786086015
[Epoch 12, Batch 400] loss: 0.012583702669326157
[Epoch 12, Batch 500] loss: 0.008420584901523398
[Epoch 12, Batch 600] loss: 0.025651089074890478
[Epoch 12, Batch 700] loss: 0.01470745604048716
[Epoch 12, Batch 800] loss: 0.019301441340285237
[Epoch 12, Batch 900] loss: 0.019093193669395988
[Epoch 12, Batch 1000] loss: 0.013357608134792826
[Epoch 12, Batch 1100] loss: 0.014707508397132188
[Epoch 12, Batch 1200] loss: 0.013921019719527977
[Epoch 12, Batch 1300] loss: 0.02166437798729021
[Epoch 12, Batch 1400] loss: 0.015288757706039179
[Epoch 12, Batch 1500] loss: 0.014065994704360492
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0406
Validation Accuracy: 0.9892
Overfitting: 0.0406
Best model saved at epoch 12 with validation loss: 0.0406
[Epoch 13, Batch 100] loss: 0.0053900397615507245
[Epoch 13, Batch 200] loss: 0.007529067618706904
[Epoch 13, Batch 300] loss: 0.015536533617560053
[Epoch 13, Batch 400] loss: 0.009925763089104294
[Epoch 13, Batch 500] loss: 0.00747622729089926
[Epoch 13, Batch 600] loss: 0.00943111879432763
[Epoch 13, Batch 700] loss: 0.013729318978803348
[Epoch 13, Batch 800] loss: 0.02039749488092639
[Epoch 13, Batch 900] loss: 0.012212764070645789
[Epoch 13, Batch 1000] loss: 0.013566937935283931
[Epoch 13, Batch 1100] loss: 0.012437627144499856
[Epoch 13, Batch 1200] loss: 0.011033381912620826
[Epoch 13, Batch 1300] loss: 0.018623040324600878
[Epoch 13, Batch 1400] loss: 0.012807327682021424
[Epoch 13, Batch 1500] loss: 0.020169527304315125
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0434
Validation Accuracy: 0.9882
Overfitting: 0.0434
[Epoch 14, Batch 100] loss: 0.008110890836687758
[Epoch 14, Batch 200] loss: 0.009434677599601855
[Epoch 14, Batch 300] loss: 0.009695645061274263
[Epoch 14, Batch 400] loss: 0.009214141451793693
[Epoch 14, Batch 500] loss: 0.0081447034404664
[Epoch 14, Batch 600] loss: 0.008064174356040893
[Epoch 14, Batch 700] loss: 0.005357850714444794
[Epoch 14, Batch 800] loss: 0.008903374723249726
[Epoch 14, Batch 900] loss: 0.006613127947684916
[Epoch 14, Batch 1000] loss: 0.011000942915152336
[Epoch 14, Batch 1100] loss: 0.014670418496680214
[Epoch 14, Batch 1200] loss: 0.01036502498785012
[Epoch 14, Batch 1300] loss: 0.01957430482023483
[Epoch 14, Batch 1400] loss: 0.009516992249482428
[Epoch 14, Batch 1500] loss: 0.009983750487622274
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0428
Validation Accuracy: 0.9889
Overfitting: 0.0428
[Epoch 15, Batch 100] loss: 0.009445106486273289
[Epoch 15, Batch 200] loss: 0.005243420590049936
[Epoch 15, Batch 300] loss: 0.003843265602872634
[Epoch 15, Batch 400] loss: 0.006586874425483984
[Epoch 15, Batch 500] loss: 0.0064856646776843265
[Epoch 15, Batch 600] loss: 0.00782280046060805
[Epoch 15, Batch 700] loss: 0.013092338222504623
[Epoch 15, Batch 800] loss: 0.011339341618613616
[Epoch 15, Batch 900] loss: 0.01447296149180147
[Epoch 15, Batch 1000] loss: 0.011140184810374194
[Epoch 15, Batch 1100] loss: 0.010147007843479515
[Epoch 15, Batch 1200] loss: 0.01500398947222493
[Epoch 15, Batch 1300] loss: 0.01774366471974645
[Epoch 15, Batch 1400] loss: 0.00612968079141865
[Epoch 15, Batch 1500] loss: 0.01650202489709045
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9868
Overfitting: 0.0508
[Epoch 16, Batch 100] loss: 0.009149928868100687
[Epoch 16, Batch 200] loss: 0.006195367922250625
[Epoch 16, Batch 300] loss: 0.0037185534052741787
[Epoch 16, Batch 400] loss: 0.005980325527616515
[Epoch 16, Batch 500] loss: 0.007403951927763046
[Epoch 16, Batch 600] loss: 0.0077679291826098056
[Epoch 16, Batch 700] loss: 0.007476919848149919
[Epoch 16, Batch 800] loss: 0.005082036279973181
[Epoch 16, Batch 900] loss: 0.008173628562583418
[Epoch 16, Batch 1000] loss: 0.008919483346207926
[Epoch 16, Batch 1100] loss: 0.009753538497911905
[Epoch 16, Batch 1200] loss: 0.005853422955879068
[Epoch 16, Batch 1300] loss: 0.008946884824936205
[Epoch 16, Batch 1400] loss: 0.021666353902110132
[Epoch 16, Batch 1500] loss: 0.014209065646209638
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9866
Overfitting: 0.0477
[Epoch 17, Batch 100] loss: 0.005021852539694009
[Epoch 17, Batch 200] loss: 0.0033121051319449177
[Epoch 17, Batch 300] loss: 0.005826795127336482
[Epoch 17, Batch 400] loss: 0.004417065033976542
[Epoch 17, Batch 500] loss: 0.003479432798285416
[Epoch 17, Batch 600] loss: 0.009973907295134268
[Epoch 17, Batch 700] loss: 0.004392351738438265
[Epoch 17, Batch 800] loss: 0.006369688431145732
[Epoch 17, Batch 900] loss: 0.00482883777313873
[Epoch 17, Batch 1000] loss: 0.008512121310850489
[Epoch 17, Batch 1100] loss: 0.011146951583441478
[Epoch 17, Batch 1200] loss: 0.00522851252106193
[Epoch 17, Batch 1300] loss: 0.003249295307923603
[Epoch 17, Batch 1400] loss: 0.007689330490079555
[Epoch 17, Batch 1500] loss: 0.013640079109336511
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0557
Validation Accuracy: 0.9878
Overfitting: 0.0557
[Epoch 18, Batch 100] loss: 0.00454855585624955
[Epoch 18, Batch 200] loss: 0.005441932620769876
[Epoch 18, Batch 300] loss: 0.00851259225144304
[Epoch 18, Batch 400] loss: 0.002748259698212223
[Epoch 18, Batch 500] loss: 0.005906643488865484
[Epoch 18, Batch 600] loss: 0.015077750607424605
[Epoch 18, Batch 700] loss: 0.011616651695057954
[Epoch 18, Batch 800] loss: 0.008516656764870732
[Epoch 18, Batch 900] loss: 0.011786753915030203
[Epoch 18, Batch 1000] loss: 0.007913358814548702
[Epoch 18, Batch 1100] loss: 0.01720361566116935
[Epoch 18, Batch 1200] loss: 0.011633368195448383
[Epoch 18, Batch 1300] loss: 0.012003385032558071
[Epoch 18, Batch 1400] loss: 0.012341188355376289
[Epoch 18, Batch 1500] loss: 0.007005191589266815
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9889
Overfitting: 0.0439
[Epoch 19, Batch 100] loss: 0.006567070390410663
[Epoch 19, Batch 200] loss: 0.007053578209524858
[Epoch 19, Batch 300] loss: 0.004726882885352097
[Epoch 19, Batch 400] loss: 0.004938949570519071
[Epoch 19, Batch 500] loss: 0.0018855739153309514
[Epoch 19, Batch 600] loss: 0.006846229418151779
[Epoch 19, Batch 700] loss: 0.002260985838230454
[Epoch 19, Batch 800] loss: 0.005014268884801823
[Epoch 19, Batch 900] loss: 0.0026722821832413503
[Epoch 19, Batch 1000] loss: 0.002248549082007685
[Epoch 19, Batch 1100] loss: 0.001848973739770372
[Epoch 19, Batch 1200] loss: 0.0031720039389364274
[Epoch 19, Batch 1300] loss: 0.008674537820234036
[Epoch 19, Batch 1400] loss: 0.003640860636146499
[Epoch 19, Batch 1500] loss: 0.00696790756068367
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9888
Overfitting: 0.0475
[Epoch 20, Batch 100] loss: 0.006240367325624448
[Epoch 20, Batch 200] loss: 0.011237809892396627
[Epoch 20, Batch 300] loss: 0.006858320334017663
[Epoch 20, Batch 400] loss: 0.012831730772277297
[Epoch 20, Batch 500] loss: 0.0029973482963066545
[Epoch 20, Batch 600] loss: 0.007572205885558105
[Epoch 20, Batch 700] loss: 0.005136797507188931
[Epoch 20, Batch 800] loss: 0.003561911768844652
[Epoch 20, Batch 900] loss: 0.001715366285429809
[Epoch 20, Batch 1000] loss: 0.0036579386538630842
[Epoch 20, Batch 1100] loss: 0.007753587543090816
[Epoch 20, Batch 1200] loss: 0.004161346849318761
[Epoch 20, Batch 1300] loss: 0.0033845332855821655
[Epoch 20, Batch 1400] loss: 0.0035151257396695713
[Epoch 20, Batch 1500] loss: 0.001363848456217056
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0443
Validation Accuracy: 0.9906
Overfitting: 0.0443
[Epoch 21, Batch 100] loss: 0.003202019196035053
[Epoch 21, Batch 200] loss: 0.005147926023460059
[Epoch 21, Batch 300] loss: 0.0028806868093079175
[Epoch 21, Batch 400] loss: 0.0025497093953390504
[Epoch 21, Batch 500] loss: 0.002611978649219964
[Epoch 21, Batch 600] loss: 0.004982963878115925
[Epoch 21, Batch 700] loss: 0.001537695906609997
[Epoch 21, Batch 800] loss: 0.0034333257979142218
[Epoch 21, Batch 900] loss: 0.0015116344871648835
[Epoch 21, Batch 1000] loss: 0.0015930058705259853
[Epoch 21, Batch 1100] loss: 0.0022173954458600065
[Epoch 21, Batch 1200] loss: 0.0011113928023820563
[Epoch 21, Batch 1300] loss: 0.0016589968613470773
[Epoch 21, Batch 1400] loss: 0.008441105046365464
[Epoch 21, Batch 1500] loss: 0.007535963642458228
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9893
Overfitting: 0.0510
[Epoch 22, Batch 100] loss: 0.009531257690682651
[Epoch 22, Batch 200] loss: 0.0031726151632642543
[Epoch 22, Batch 300] loss: 0.01049976775745506
[Epoch 22, Batch 400] loss: 0.0033363959202890215
[Epoch 22, Batch 500] loss: 0.004309870126901387
[Epoch 22, Batch 600] loss: 0.007458360729245896
[Epoch 22, Batch 700] loss: 0.0058441626829289816
[Epoch 22, Batch 800] loss: 0.004650906054216648
[Epoch 22, Batch 900] loss: 0.004501990278822632
[Epoch 22, Batch 1000] loss: 0.0028019100390571337
[Epoch 22, Batch 1100] loss: 0.0017118060353232068
[Epoch 22, Batch 1200] loss: 0.004836158653631628
[Epoch 22, Batch 1300] loss: 0.0036435902058997273
[Epoch 22, Batch 1400] loss: 0.0039595644080174
[Epoch 22, Batch 1500] loss: 0.003986664579466606
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9891
Overfitting: 0.0480
[Epoch 23, Batch 100] loss: 0.0013121403677610033
[Epoch 23, Batch 200] loss: 0.0017117601358540924
[Epoch 23, Batch 300] loss: 0.0009912585001200114
[Epoch 23, Batch 400] loss: 0.0017512393112133395
[Epoch 23, Batch 500] loss: 0.002265137993948656
[Epoch 23, Batch 600] loss: 0.0010147399854622562
[Epoch 23, Batch 700] loss: 0.0007409748924129644
[Epoch 23, Batch 800] loss: 0.000502631720725617
[Epoch 23, Batch 900] loss: 0.000887338697901896
[Epoch 23, Batch 1000] loss: 0.0023085791860830793
[Epoch 23, Batch 1100] loss: 0.0011225616198908028
[Epoch 23, Batch 1200] loss: 0.0041017964107459195
[Epoch 23, Batch 1300] loss: 0.0020178025061068183
[Epoch 23, Batch 1400] loss: 0.004688066159056916
[Epoch 23, Batch 1500] loss: 0.0032139144845626786
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0498
Validation Accuracy: 0.9897
Overfitting: 0.0498
[Epoch 24, Batch 100] loss: 0.004295294667732037
[Epoch 24, Batch 200] loss: 0.0013003653647888315
[Epoch 24, Batch 300] loss: 0.00163338504619162
[Epoch 24, Batch 400] loss: 0.0008550814954742237
[Epoch 24, Batch 500] loss: 0.0032032122906014136
[Epoch 24, Batch 600] loss: 0.0007361304947266945
[Epoch 24, Batch 700] loss: 0.001171152119892156
[Epoch 24, Batch 800] loss: 0.0018851258257211612
[Epoch 24, Batch 900] loss: 0.001563821286918028
[Epoch 24, Batch 1000] loss: 0.0048176927021383875
[Epoch 24, Batch 1100] loss: 0.0035407071002805423
[Epoch 24, Batch 1200] loss: 0.0038313862627319395
[Epoch 24, Batch 1300] loss: 0.006581902107225233
[Epoch 24, Batch 1400] loss: 0.007149228479111116
[Epoch 24, Batch 1500] loss: 0.00515312834299948
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9902
Overfitting: 0.0502
Fold 1 validation loss: 0.0502
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2775397276878357
[Epoch 1, Batch 200] loss: 1.6356123197078705
[Epoch 1, Batch 300] loss: 0.45215889275074006
[Epoch 1, Batch 400] loss: 0.3238045993447304
[Epoch 1, Batch 500] loss: 0.25222619419917464
[Epoch 1, Batch 600] loss: 0.211233697719872
[Epoch 1, Batch 700] loss: 0.22361257798969747
[Epoch 1, Batch 800] loss: 0.2029528940655291
[Epoch 1, Batch 900] loss: 0.174201170373708
[Epoch 1, Batch 1000] loss: 0.16476032944396138
[Epoch 1, Batch 1100] loss: 0.13549412812106312
[Epoch 1, Batch 1200] loss: 0.13116978120524436
[Epoch 1, Batch 1300] loss: 0.13083565897773952
[Epoch 1, Batch 1400] loss: 0.11089552592020482
[Epoch 1, Batch 1500] loss: 0.12218698126729578
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1195
Validation Accuracy: 0.9641
Overfitting: 0.1195
Best model saved at epoch 1 with validation loss: 0.1195
[Epoch 2, Batch 100] loss: 0.11650812720414251
[Epoch 2, Batch 200] loss: 0.11438232879620046
[Epoch 2, Batch 300] loss: 0.10580634219571948
[Epoch 2, Batch 400] loss: 0.09083534040022641
[Epoch 2, Batch 500] loss: 0.09182779734022915
[Epoch 2, Batch 600] loss: 0.09509462587768212
[Epoch 2, Batch 700] loss: 0.09829476194921881
[Epoch 2, Batch 800] loss: 0.09720781998708844
[Epoch 2, Batch 900] loss: 0.10116939321160316
[Epoch 2, Batch 1000] loss: 0.08605317187961191
[Epoch 2, Batch 1100] loss: 0.08644647190812975
[Epoch 2, Batch 1200] loss: 0.08900730546563863
[Epoch 2, Batch 1300] loss: 0.08921120562124997
[Epoch 2, Batch 1400] loss: 0.08886588846798986
[Epoch 2, Batch 1500] loss: 0.08097927927970887
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0938
Validation Accuracy: 0.9696
Overfitting: 0.0938
Best model saved at epoch 2 with validation loss: 0.0938
[Epoch 3, Batch 100] loss: 0.07475503153167665
[Epoch 3, Batch 200] loss: 0.07926155231078155
[Epoch 3, Batch 300] loss: 0.08169338942505419
[Epoch 3, Batch 400] loss: 0.07092576527851634
[Epoch 3, Batch 500] loss: 0.0630144464271143
[Epoch 3, Batch 600] loss: 0.07517157802823932
[Epoch 3, Batch 700] loss: 0.07129531644051895
[Epoch 3, Batch 800] loss: 0.05654022248927504
[Epoch 3, Batch 900] loss: 0.0634167243493721
[Epoch 3, Batch 1000] loss: 0.06133551749982871
[Epoch 3, Batch 1100] loss: 0.07435814980650321
[Epoch 3, Batch 1200] loss: 0.07624106643954293
[Epoch 3, Batch 1300] loss: 0.0680267341248691
[Epoch 3, Batch 1400] loss: 0.0524677518918179
[Epoch 3, Batch 1500] loss: 0.0636313009710284
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0781
Validation Accuracy: 0.9751
Overfitting: 0.0781
Best model saved at epoch 3 with validation loss: 0.0781
[Epoch 4, Batch 100] loss: 0.05579062283446547
[Epoch 4, Batch 200] loss: 0.04347618678235449
[Epoch 4, Batch 300] loss: 0.07037415880709887
[Epoch 4, Batch 400] loss: 0.05653587069944479
[Epoch 4, Batch 500] loss: 0.05517133731162176
[Epoch 4, Batch 600] loss: 0.04731724450713955
[Epoch 4, Batch 700] loss: 0.056206537022953855
[Epoch 4, Batch 800] loss: 0.06351702057290823
[Epoch 4, Batch 900] loss: 0.043539827881613744
[Epoch 4, Batch 1000] loss: 0.058714979228097944
[Epoch 4, Batch 1100] loss: 0.04938272260129452
[Epoch 4, Batch 1200] loss: 0.05492911925772205
[Epoch 4, Batch 1300] loss: 0.0475548124947818
[Epoch 4, Batch 1400] loss: 0.05710896363249049
[Epoch 4, Batch 1500] loss: 0.047414219802012665
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0600
Validation Accuracy: 0.9808
Overfitting: 0.0600
Best model saved at epoch 4 with validation loss: 0.0600
[Epoch 5, Batch 100] loss: 0.036345055310521276
[Epoch 5, Batch 200] loss: 0.04164985070354305
[Epoch 5, Batch 300] loss: 0.03988193481462076
[Epoch 5, Batch 400] loss: 0.039486639634124
[Epoch 5, Batch 500] loss: 0.04936258496018127
[Epoch 5, Batch 600] loss: 0.03355538222123869
[Epoch 5, Batch 700] loss: 0.04983880290586967
[Epoch 5, Batch 800] loss: 0.03710669966443675
[Epoch 5, Batch 900] loss: 0.0558605911815539
[Epoch 5, Batch 1000] loss: 0.04148847232398111
[Epoch 5, Batch 1100] loss: 0.04592440340260509
[Epoch 5, Batch 1200] loss: 0.053937719637760895
[Epoch 5, Batch 1300] loss: 0.03931749772047624
[Epoch 5, Batch 1400] loss: 0.03865388654638082
[Epoch 5, Batch 1500] loss: 0.053072744388773574
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9833
Overfitting: 0.0573
Best model saved at epoch 5 with validation loss: 0.0573
[Epoch 6, Batch 100] loss: 0.03789309131738264
[Epoch 6, Batch 200] loss: 0.0369615080911899
[Epoch 6, Batch 300] loss: 0.026642413262743504
[Epoch 6, Batch 400] loss: 0.03018724903697148
[Epoch 6, Batch 500] loss: 0.04610736353730317
[Epoch 6, Batch 600] loss: 0.04960751284146681
[Epoch 6, Batch 700] loss: 0.03723737451247871
[Epoch 6, Batch 800] loss: 0.02900489523948636
[Epoch 6, Batch 900] loss: 0.03266318148293067
[Epoch 6, Batch 1000] loss: 0.0440189972956432
[Epoch 6, Batch 1100] loss: 0.031585572791227604
[Epoch 6, Batch 1200] loss: 0.04550058893742971
[Epoch 6, Batch 1300] loss: 0.029069785135798155
[Epoch 6, Batch 1400] loss: 0.035308249189984056
[Epoch 6, Batch 1500] loss: 0.036306131915189326
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0853
Validation Accuracy: 0.9755
Overfitting: 0.0853
[Epoch 7, Batch 100] loss: 0.023268844008271117
[Epoch 7, Batch 200] loss: 0.032562572890601583
[Epoch 7, Batch 300] loss: 0.028719116819556804
[Epoch 7, Batch 400] loss: 0.026226007270161063
[Epoch 7, Batch 500] loss: 0.02469803486485034
[Epoch 7, Batch 600] loss: 0.03935247689369135
[Epoch 7, Batch 700] loss: 0.027417552187107504
[Epoch 7, Batch 800] loss: 0.041908567651407796
[Epoch 7, Batch 900] loss: 0.04058594183647074
[Epoch 7, Batch 1000] loss: 0.03199453704204643
[Epoch 7, Batch 1100] loss: 0.041651786433067176
[Epoch 7, Batch 1200] loss: 0.029292371457995615
[Epoch 7, Batch 1300] loss: 0.037419662931934
[Epoch 7, Batch 1400] loss: 0.03728272891661618
[Epoch 7, Batch 1500] loss: 0.02582933448451513
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9839
Overfitting: 0.0542
Best model saved at epoch 7 with validation loss: 0.0542
[Epoch 8, Batch 100] loss: 0.021736883336270694
[Epoch 8, Batch 200] loss: 0.02403182223031763
[Epoch 8, Batch 300] loss: 0.025940684980596415
[Epoch 8, Batch 400] loss: 0.02760470786335645
[Epoch 8, Batch 500] loss: 0.02678871458134381
[Epoch 8, Batch 600] loss: 0.04305276042519836
[Epoch 8, Batch 700] loss: 0.026855658466520254
[Epoch 8, Batch 800] loss: 0.029471649574697948
[Epoch 8, Batch 900] loss: 0.018526023004087618
[Epoch 8, Batch 1000] loss: 0.021864275863481452
[Epoch 8, Batch 1100] loss: 0.023887535853282314
[Epoch 8, Batch 1200] loss: 0.023194048861187186
[Epoch 8, Batch 1300] loss: 0.036396331693104
[Epoch 8, Batch 1400] loss: 0.03367717997840373
[Epoch 8, Batch 1500] loss: 0.03148901032633148
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9849
Overfitting: 0.0518
Best model saved at epoch 8 with validation loss: 0.0518
[Epoch 9, Batch 100] loss: 0.019312538717058486
[Epoch 9, Batch 200] loss: 0.027827872082125397
[Epoch 9, Batch 300] loss: 0.01644765828299569
[Epoch 9, Batch 400] loss: 0.01810065907498938
[Epoch 9, Batch 500] loss: 0.038623194292304104
[Epoch 9, Batch 600] loss: 0.028867298853001558
[Epoch 9, Batch 700] loss: 0.019663738322669815
[Epoch 9, Batch 800] loss: 0.022236283590536914
[Epoch 9, Batch 900] loss: 0.02859568624677195
[Epoch 9, Batch 1000] loss: 0.025207775031230995
[Epoch 9, Batch 1100] loss: 0.025217345452620065
[Epoch 9, Batch 1200] loss: 0.018993085365218577
[Epoch 9, Batch 1300] loss: 0.02310406631877413
[Epoch 9, Batch 1400] loss: 0.02227646901010303
[Epoch 9, Batch 1500] loss: 0.0237784591934178
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9841
Overfitting: 0.0569
[Epoch 10, Batch 100] loss: 0.016624086159317812
[Epoch 10, Batch 200] loss: 0.026398043271765346
[Epoch 10, Batch 300] loss: 0.015545486705341317
[Epoch 10, Batch 400] loss: 0.018766941304129432
[Epoch 10, Batch 500] loss: 0.01124517191961786
[Epoch 10, Batch 600] loss: 0.01973480207434477
[Epoch 10, Batch 700] loss: 0.025650759744858077
[Epoch 10, Batch 800] loss: 0.02788692310481565
[Epoch 10, Batch 900] loss: 0.017660198554804083
[Epoch 10, Batch 1000] loss: 0.027015533409212367
[Epoch 10, Batch 1100] loss: 0.024743907766569463
[Epoch 10, Batch 1200] loss: 0.03058678341418272
[Epoch 10, Batch 1300] loss: 0.03092204329033848
[Epoch 10, Batch 1400] loss: 0.019733690899738577
[Epoch 10, Batch 1500] loss: 0.027513594704505522
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9865
Overfitting: 0.0493
Best model saved at epoch 10 with validation loss: 0.0493
[Epoch 11, Batch 100] loss: 0.017830437815282495
[Epoch 11, Batch 200] loss: 0.01655648336192826
[Epoch 11, Batch 300] loss: 0.013025325215494377
[Epoch 11, Batch 400] loss: 0.013754839055472985
[Epoch 11, Batch 500] loss: 0.021029609711840747
[Epoch 11, Batch 600] loss: 0.01804169287250261
[Epoch 11, Batch 700] loss: 0.01642536951949296
[Epoch 11, Batch 800] loss: 0.0203619885534863
[Epoch 11, Batch 900] loss: 0.017019002768211066
[Epoch 11, Batch 1000] loss: 0.0123130937721362
[Epoch 11, Batch 1100] loss: 0.016239747675244873
[Epoch 11, Batch 1200] loss: 0.01747453354191748
[Epoch 11, Batch 1300] loss: 0.022101170987443765
[Epoch 11, Batch 1400] loss: 0.024402679182239807
[Epoch 11, Batch 1500] loss: 0.014653955994363059
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9855
Overfitting: 0.0492
Best model saved at epoch 11 with validation loss: 0.0492
[Epoch 12, Batch 100] loss: 0.013152491798391565
[Epoch 12, Batch 200] loss: 0.011043666052282788
[Epoch 12, Batch 300] loss: 0.012657512002788281
[Epoch 12, Batch 400] loss: 0.016327216871759448
[Epoch 12, Batch 500] loss: 0.01140126634405533
[Epoch 12, Batch 600] loss: 0.012150857441229164
[Epoch 12, Batch 700] loss: 0.009522663102325168
[Epoch 12, Batch 800] loss: 0.013976219620035408
[Epoch 12, Batch 900] loss: 0.020303671842957557
[Epoch 12, Batch 1000] loss: 0.016545166799915023
[Epoch 12, Batch 1100] loss: 0.017791371207677
[Epoch 12, Batch 1200] loss: 0.007729288632963289
[Epoch 12, Batch 1300] loss: 0.017905572156396373
[Epoch 12, Batch 1400] loss: 0.024191458863642764
[Epoch 12, Batch 1500] loss: 0.022521979460507283
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9862
Overfitting: 0.0501
[Epoch 13, Batch 100] loss: 0.014103956762955932
[Epoch 13, Batch 200] loss: 0.010740028089858243
[Epoch 13, Batch 300] loss: 0.008313236468311516
[Epoch 13, Batch 400] loss: 0.012079866834246786
[Epoch 13, Batch 500] loss: 0.008694164251073744
[Epoch 13, Batch 600] loss: 0.010116364697350945
[Epoch 13, Batch 700] loss: 0.0110525543019412
[Epoch 13, Batch 800] loss: 0.017870527148261317
[Epoch 13, Batch 900] loss: 0.008613632939704985
[Epoch 13, Batch 1000] loss: 0.020250089171531725
[Epoch 13, Batch 1100] loss: 0.012875146657388542
[Epoch 13, Batch 1200] loss: 0.01554403808252573
[Epoch 13, Batch 1300] loss: 0.011829690592676342
[Epoch 13, Batch 1400] loss: 0.015493563541231197
[Epoch 13, Batch 1500] loss: 0.014865611321474716
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9871
Overfitting: 0.0510
[Epoch 14, Batch 100] loss: 0.016983001438948122
[Epoch 14, Batch 200] loss: 0.014053594520300977
[Epoch 14, Batch 300] loss: 0.009768806435458828
[Epoch 14, Batch 400] loss: 0.01622967847935797
[Epoch 14, Batch 500] loss: 0.007985427680614521
[Epoch 14, Batch 600] loss: 0.014743243482880643
[Epoch 14, Batch 700] loss: 0.010390471847877052
[Epoch 14, Batch 800] loss: 0.011657310841910658
[Epoch 14, Batch 900] loss: 0.013342349842405383
[Epoch 14, Batch 1000] loss: 0.010580914951860905
[Epoch 14, Batch 1100] loss: 0.013236690660087334
[Epoch 14, Batch 1200] loss: 0.00792626987604308
[Epoch 14, Batch 1300] loss: 0.004295758082071189
[Epoch 14, Batch 1400] loss: 0.016270190682698738
[Epoch 14, Batch 1500] loss: 0.01251452963482734
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9871
Overfitting: 0.0514
[Epoch 15, Batch 100] loss: 0.01359562976336747
[Epoch 15, Batch 200] loss: 0.007988949321515974
[Epoch 15, Batch 300] loss: 0.007903629698089389
[Epoch 15, Batch 400] loss: 0.008078732843569015
[Epoch 15, Batch 500] loss: 0.010260174785253184
[Epoch 15, Batch 600] loss: 0.009419882303445775
[Epoch 15, Batch 700] loss: 0.01145534719044008
[Epoch 15, Batch 800] loss: 0.011150967332741856
[Epoch 15, Batch 900] loss: 0.0200553190212122
[Epoch 15, Batch 1000] loss: 0.018175370549070067
[Epoch 15, Batch 1100] loss: 0.008537219008667307
[Epoch 15, Batch 1200] loss: 0.007403040023336871
[Epoch 15, Batch 1300] loss: 0.009590013718043338
[Epoch 15, Batch 1400] loss: 0.01551531601760871
[Epoch 15, Batch 1500] loss: 0.00871597962017404
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9870
Overfitting: 0.0560
[Epoch 16, Batch 100] loss: 0.008230473667790648
[Epoch 16, Batch 200] loss: 0.016936543388299016
[Epoch 16, Batch 300] loss: 0.008579051443348362
[Epoch 16, Batch 400] loss: 0.009368356917584607
[Epoch 16, Batch 500] loss: 0.005587405906535423
[Epoch 16, Batch 600] loss: 0.009921436694889962
[Epoch 16, Batch 700] loss: 0.010390646331852622
[Epoch 16, Batch 800] loss: 0.0074667230047816705
[Epoch 16, Batch 900] loss: 0.00885950689906167
[Epoch 16, Batch 1000] loss: 0.006705314863820604
[Epoch 16, Batch 1100] loss: 0.014147770976442188
[Epoch 16, Batch 1200] loss: 0.011059948225465632
[Epoch 16, Batch 1300] loss: 0.012310168496369442
[Epoch 16, Batch 1400] loss: 0.010682684259891176
[Epoch 16, Batch 1500] loss: 0.010716854053534917
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9870
Overfitting: 0.0504
[Epoch 17, Batch 100] loss: 0.005954032340105187
[Epoch 17, Batch 200] loss: 0.008560299033410957
[Epoch 17, Batch 300] loss: 0.003919143334555884
[Epoch 17, Batch 400] loss: 0.005473500653288284
[Epoch 17, Batch 500] loss: 0.004259600256141312
[Epoch 17, Batch 600] loss: 0.004757842406561395
[Epoch 17, Batch 700] loss: 0.00522589941875367
[Epoch 17, Batch 800] loss: 0.0062538301834774756
[Epoch 17, Batch 900] loss: 0.006984833447268102
[Epoch 17, Batch 1000] loss: 0.010719555765522273
[Epoch 17, Batch 1100] loss: 0.015484663291017569
[Epoch 17, Batch 1200] loss: 0.010969807179917553
[Epoch 17, Batch 1300] loss: 0.011416593782837482
[Epoch 17, Batch 1400] loss: 0.013508470671295071
[Epoch 17, Batch 1500] loss: 0.006433024701382237
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9870
Overfitting: 0.0540
[Epoch 18, Batch 100] loss: 0.013312203318528192
[Epoch 18, Batch 200] loss: 0.006022720709624991
[Epoch 18, Batch 300] loss: 0.005410079512527091
[Epoch 18, Batch 400] loss: 0.008749580765397695
[Epoch 18, Batch 500] loss: 0.010069458961996815
[Epoch 18, Batch 600] loss: 0.005448233356951278
[Epoch 18, Batch 700] loss: 0.009139868768104407
[Epoch 18, Batch 800] loss: 0.008837985042123363
[Epoch 18, Batch 900] loss: 0.005269593992152295
[Epoch 18, Batch 1000] loss: 0.005845389621072172
[Epoch 18, Batch 1100] loss: 0.012676713393457249
[Epoch 18, Batch 1200] loss: 0.012223542265951437
[Epoch 18, Batch 1300] loss: 0.020037880724958088
[Epoch 18, Batch 1400] loss: 0.004936441539102816
[Epoch 18, Batch 1500] loss: 0.005877644345364388
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0622
Validation Accuracy: 0.9861
Overfitting: 0.0622
[Epoch 19, Batch 100] loss: 0.007499574491375825
[Epoch 19, Batch 200] loss: 0.0033775049323185157
[Epoch 19, Batch 300] loss: 0.008561595084202053
[Epoch 19, Batch 400] loss: 0.005960750622930391
[Epoch 19, Batch 500] loss: 0.0047527040622208005
[Epoch 19, Batch 600] loss: 0.002792955911172612
[Epoch 19, Batch 700] loss: 0.002155468151299829
[Epoch 19, Batch 800] loss: 0.009193099203737348
[Epoch 19, Batch 900] loss: 0.011417018736465253
[Epoch 19, Batch 1000] loss: 0.00606374090810732
[Epoch 19, Batch 1100] loss: 0.0048593774589608075
[Epoch 19, Batch 1200] loss: 0.016915839321495697
[Epoch 19, Batch 1300] loss: 0.00647763964439946
[Epoch 19, Batch 1400] loss: 0.00550287016816128
[Epoch 19, Batch 1500] loss: 0.007930792418030706
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9877
Overfitting: 0.0550
[Epoch 20, Batch 100] loss: 0.003744631122121973
[Epoch 20, Batch 200] loss: 0.006165179305696711
[Epoch 20, Batch 300] loss: 0.004073217145323724
[Epoch 20, Batch 400] loss: 0.006931025820638297
[Epoch 20, Batch 500] loss: 0.006097113450366578
[Epoch 20, Batch 600] loss: 0.00204743489211296
[Epoch 20, Batch 700] loss: 0.006835347156493299
[Epoch 20, Batch 800] loss: 0.005806340354174608
[Epoch 20, Batch 900] loss: 0.005681962824374978
[Epoch 20, Batch 1000] loss: 0.004702124135797021
[Epoch 20, Batch 1100] loss: 0.006977181701579412
[Epoch 20, Batch 1200] loss: 0.007968230518017663
[Epoch 20, Batch 1300] loss: 0.007501458315489345
[Epoch 20, Batch 1400] loss: 0.007513863830877199
[Epoch 20, Batch 1500] loss: 0.0057469819292305145
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9882
Overfitting: 0.0550
[Epoch 21, Batch 100] loss: 0.003786498584593119
[Epoch 21, Batch 200] loss: 0.0024356261340471976
[Epoch 21, Batch 300] loss: 0.0021521159519261347
[Epoch 21, Batch 400] loss: 0.001066297845831059
[Epoch 21, Batch 500] loss: 0.0049284384079828665
[Epoch 21, Batch 600] loss: 0.004986746197218963
[Epoch 21, Batch 700] loss: 0.006130755551434958
[Epoch 21, Batch 800] loss: 0.0034210777256726034
[Epoch 21, Batch 900] loss: 0.006893951754387899
[Epoch 21, Batch 1000] loss: 0.007058025588779628
[Epoch 21, Batch 1100] loss: 0.006185201801930589
[Epoch 21, Batch 1200] loss: 0.006889844503576797
[Epoch 21, Batch 1300] loss: 0.007753865054010021
[Epoch 21, Batch 1400] loss: 0.00875276230332247
[Epoch 21, Batch 1500] loss: 0.008270793777974177
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0609
Validation Accuracy: 0.9873
Overfitting: 0.0609
[Epoch 22, Batch 100] loss: 0.002776047069700667
[Epoch 22, Batch 200] loss: 0.0033750074717997336
[Epoch 22, Batch 300] loss: 0.004510921434115289
[Epoch 22, Batch 400] loss: 0.0030128170661646437
[Epoch 22, Batch 500] loss: 0.0050616802662648295
[Epoch 22, Batch 600] loss: 0.0017723543046258782
[Epoch 22, Batch 700] loss: 0.0033992390995217646
[Epoch 22, Batch 800] loss: 0.004128169728601278
[Epoch 22, Batch 900] loss: 0.0025427292340862097
[Epoch 22, Batch 1000] loss: 0.0028389821732309885
[Epoch 22, Batch 1100] loss: 0.0038532592246792773
[Epoch 22, Batch 1200] loss: 0.002522191622999799
[Epoch 22, Batch 1300] loss: 0.0022706907626064777
[Epoch 22, Batch 1400] loss: 0.009027682180878856
[Epoch 22, Batch 1500] loss: 0.0084536716333605
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0672
Validation Accuracy: 0.9858
Overfitting: 0.0672
[Epoch 23, Batch 100] loss: 0.006399197202727009
[Epoch 23, Batch 200] loss: 0.003476058876121897
[Epoch 23, Batch 300] loss: 0.0019858701325324545
[Epoch 23, Batch 400] loss: 0.0038963911460712097
[Epoch 23, Batch 500] loss: 0.004632863452375204
[Epoch 23, Batch 600] loss: 0.00401617051434755
[Epoch 23, Batch 700] loss: 0.001860304705478484
[Epoch 23, Batch 800] loss: 0.003917858311367582
[Epoch 23, Batch 900] loss: 0.003980417011119357
[Epoch 23, Batch 1000] loss: 0.0056484580359028765
[Epoch 23, Batch 1100] loss: 0.0021403171271640532
[Epoch 23, Batch 1200] loss: 0.0040891882176583745
[Epoch 23, Batch 1300] loss: 0.004688374712575865
[Epoch 23, Batch 1400] loss: 0.003286197589807216
[Epoch 23, Batch 1500] loss: 0.004677787140241776
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0710
Validation Accuracy: 0.9842
Overfitting: 0.0710
[Epoch 24, Batch 100] loss: 0.0029332091836340624
[Epoch 24, Batch 200] loss: 0.004259502377458091
[Epoch 24, Batch 300] loss: 0.0011532808095174119
[Epoch 24, Batch 400] loss: 0.002281387689984058
[Epoch 24, Batch 500] loss: 0.002230843435859242
[Epoch 24, Batch 600] loss: 0.003463599743474219
[Epoch 24, Batch 700] loss: 0.003998147438760497
[Epoch 24, Batch 800] loss: 0.006586349270548908
[Epoch 24, Batch 900] loss: 0.0028301800689246193
[Epoch 24, Batch 1000] loss: 0.011301701128535341
[Epoch 24, Batch 1100] loss: 0.010070794354743385
[Epoch 24, Batch 1200] loss: 0.006143341929016515
[Epoch 24, Batch 1300] loss: 0.0067086678082551995
[Epoch 24, Batch 1400] loss: 0.0027360340383961556
[Epoch 24, Batch 1500] loss: 0.004617029763739993
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0615
Validation Accuracy: 0.9870
Overfitting: 0.0615
Fold 2 validation loss: 0.0615
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2738211369514465
[Epoch 1, Batch 200] loss: 1.5447920703887938
[Epoch 1, Batch 300] loss: 0.6202914726734161
[Epoch 1, Batch 400] loss: 0.4210410670936108
[Epoch 1, Batch 500] loss: 0.35754119500517845
[Epoch 1, Batch 600] loss: 0.2523501455411315
[Epoch 1, Batch 700] loss: 0.24676409408450126
[Epoch 1, Batch 800] loss: 0.2167083578929305
[Epoch 1, Batch 900] loss: 0.19103634886443616
[Epoch 1, Batch 1000] loss: 0.17573036548681556
[Epoch 1, Batch 1100] loss: 0.13591078583151103
[Epoch 1, Batch 1200] loss: 0.13366408677771688
[Epoch 1, Batch 1300] loss: 0.13711120080202818
[Epoch 1, Batch 1400] loss: 0.13264219412580133
[Epoch 1, Batch 1500] loss: 0.13040487700141967
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1252
Validation Accuracy: 0.9608
Overfitting: 0.1252
Best model saved at epoch 1 with validation loss: 0.1252
[Epoch 2, Batch 100] loss: 0.11216288906522096
[Epoch 2, Batch 200] loss: 0.11439510189928115
[Epoch 2, Batch 300] loss: 0.10715843699406832
[Epoch 2, Batch 400] loss: 0.12729922921862452
[Epoch 2, Batch 500] loss: 0.10980633938219399
[Epoch 2, Batch 600] loss: 0.10105011424515396
[Epoch 2, Batch 700] loss: 0.08347010104451329
[Epoch 2, Batch 800] loss: 0.10381336589343845
[Epoch 2, Batch 900] loss: 0.10592481246218086
[Epoch 2, Batch 1000] loss: 0.08163635012228042
[Epoch 2, Batch 1100] loss: 0.07940191531262826
[Epoch 2, Batch 1200] loss: 0.08030829206574708
[Epoch 2, Batch 1300] loss: 0.07728257585782558
[Epoch 2, Batch 1400] loss: 0.09268309332896024
[Epoch 2, Batch 1500] loss: 0.07577686147065833
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1016
Validation Accuracy: 0.9701
Overfitting: 0.1016
Best model saved at epoch 2 with validation loss: 0.1016
[Epoch 3, Batch 100] loss: 0.0883066880190745
[Epoch 3, Batch 200] loss: 0.0820894935913384
[Epoch 3, Batch 300] loss: 0.07043126756791025
[Epoch 3, Batch 400] loss: 0.06164654842112213
[Epoch 3, Batch 500] loss: 0.05799298556172289
[Epoch 3, Batch 600] loss: 0.06846784160472452
[Epoch 3, Batch 700] loss: 0.06427841698867269
[Epoch 3, Batch 800] loss: 0.06555108598433435
[Epoch 3, Batch 900] loss: 0.06818997358408524
[Epoch 3, Batch 1000] loss: 0.07654050424927845
[Epoch 3, Batch 1100] loss: 0.06725098405382596
[Epoch 3, Batch 1200] loss: 0.06474614351755008
[Epoch 3, Batch 1300] loss: 0.07028739941539243
[Epoch 3, Batch 1400] loss: 0.055704005878651514
[Epoch 3, Batch 1500] loss: 0.05584950871299952
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0717
Validation Accuracy: 0.9778
Overfitting: 0.0717
Best model saved at epoch 3 with validation loss: 0.0717
[Epoch 4, Batch 100] loss: 0.056887529154773804
[Epoch 4, Batch 200] loss: 0.0449609978380613
[Epoch 4, Batch 300] loss: 0.06111987108364701
[Epoch 4, Batch 400] loss: 0.051954087875201366
[Epoch 4, Batch 500] loss: 0.05809472353896126
[Epoch 4, Batch 600] loss: 0.05738249501446262
[Epoch 4, Batch 700] loss: 0.056879438370233404
[Epoch 4, Batch 800] loss: 0.04492527378839441
[Epoch 4, Batch 900] loss: 0.04935233741998672
[Epoch 4, Batch 1000] loss: 0.054150168914929964
[Epoch 4, Batch 1100] loss: 0.04060893640998984
[Epoch 4, Batch 1200] loss: 0.058960192983504384
[Epoch 4, Batch 1300] loss: 0.0440578628750518
[Epoch 4, Batch 1400] loss: 0.04987576664774679
[Epoch 4, Batch 1500] loss: 0.051031946309376505
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0754
Validation Accuracy: 0.9763
Overfitting: 0.0754
[Epoch 5, Batch 100] loss: 0.03518150630872697
[Epoch 5, Batch 200] loss: 0.04603092613280751
[Epoch 5, Batch 300] loss: 0.050419487851904705
[Epoch 5, Batch 400] loss: 0.047928806654526854
[Epoch 5, Batch 500] loss: 0.040615124909527366
[Epoch 5, Batch 600] loss: 0.04133275368541945
[Epoch 5, Batch 700] loss: 0.04981620670238044
[Epoch 5, Batch 800] loss: 0.041442378709325566
[Epoch 5, Batch 900] loss: 0.047941033304668965
[Epoch 5, Batch 1000] loss: 0.03930045852030162
[Epoch 5, Batch 1100] loss: 0.055108694894588556
[Epoch 5, Batch 1200] loss: 0.04252750116866082
[Epoch 5, Batch 1300] loss: 0.048395940298214556
[Epoch 5, Batch 1400] loss: 0.03673635456943884
[Epoch 5, Batch 1500] loss: 0.03993282566749258
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9848
Overfitting: 0.0500
Best model saved at epoch 5 with validation loss: 0.0500
[Epoch 6, Batch 100] loss: 0.031093494314700366
[Epoch 6, Batch 200] loss: 0.04021882242988795
[Epoch 6, Batch 300] loss: 0.03495572528685443
[Epoch 6, Batch 400] loss: 0.05328866800526157
[Epoch 6, Batch 500] loss: 0.03346042251272593
[Epoch 6, Batch 600] loss: 0.040823887887527235
[Epoch 6, Batch 700] loss: 0.03866494828806026
[Epoch 6, Batch 800] loss: 0.03627653458475834
[Epoch 6, Batch 900] loss: 0.04333002209023107
[Epoch 6, Batch 1000] loss: 0.03343388566514477
[Epoch 6, Batch 1100] loss: 0.03448828295600834
[Epoch 6, Batch 1200] loss: 0.0524973726819735
[Epoch 6, Batch 1300] loss: 0.03430289863084909
[Epoch 6, Batch 1400] loss: 0.031238572690053843
[Epoch 6, Batch 1500] loss: 0.032500456728448625
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9858
Overfitting: 0.0481
Best model saved at epoch 6 with validation loss: 0.0481
[Epoch 7, Batch 100] loss: 0.030360493912012315
[Epoch 7, Batch 200] loss: 0.042410556777031164
[Epoch 7, Batch 300] loss: 0.026316927290754393
[Epoch 7, Batch 400] loss: 0.02907544699686696
[Epoch 7, Batch 500] loss: 0.0340093553456245
[Epoch 7, Batch 600] loss: 0.03943365586572327
[Epoch 7, Batch 700] loss: 0.03282096079841722
[Epoch 7, Batch 800] loss: 0.0293231385704712
[Epoch 7, Batch 900] loss: 0.026960753503371963
[Epoch 7, Batch 1000] loss: 0.03449132944195298
[Epoch 7, Batch 1100] loss: 0.02350346280843951
[Epoch 7, Batch 1200] loss: 0.026114965984306765
[Epoch 7, Batch 1300] loss: 0.02809781485091662
[Epoch 7, Batch 1400] loss: 0.04459516670758603
[Epoch 7, Batch 1500] loss: 0.03888527027447708
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0440
Validation Accuracy: 0.9872
Overfitting: 0.0440
Best model saved at epoch 7 with validation loss: 0.0440
[Epoch 8, Batch 100] loss: 0.023422662093653342
[Epoch 8, Batch 200] loss: 0.023590621910407207
[Epoch 8, Batch 300] loss: 0.026512177079421235
[Epoch 8, Batch 400] loss: 0.03408886243356392
[Epoch 8, Batch 500] loss: 0.021896596368169412
[Epoch 8, Batch 600] loss: 0.030698166464426323
[Epoch 8, Batch 700] loss: 0.02865550305476063
[Epoch 8, Batch 800] loss: 0.022091502501280048
[Epoch 8, Batch 900] loss: 0.02993681773725257
[Epoch 8, Batch 1000] loss: 0.027797171544661978
[Epoch 8, Batch 1100] loss: 0.02814583719300572
[Epoch 8, Batch 1200] loss: 0.025844605313905047
[Epoch 8, Batch 1300] loss: 0.025525570464997146
[Epoch 8, Batch 1400] loss: 0.03341813119506696
[Epoch 8, Batch 1500] loss: 0.03254601631255355
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9851
Overfitting: 0.0493
[Epoch 9, Batch 100] loss: 0.014975872844370314
[Epoch 9, Batch 200] loss: 0.023182033200573642
[Epoch 9, Batch 300] loss: 0.01733173462744162
[Epoch 9, Batch 400] loss: 0.020351232314351365
[Epoch 9, Batch 500] loss: 0.02702958610301721
[Epoch 9, Batch 600] loss: 0.024200945139164105
[Epoch 9, Batch 700] loss: 0.01900822300973232
[Epoch 9, Batch 800] loss: 0.02395893586697639
[Epoch 9, Batch 900] loss: 0.01167753608446219
[Epoch 9, Batch 1000] loss: 0.024019769900041864
[Epoch 9, Batch 1100] loss: 0.029583616262098076
[Epoch 9, Batch 1200] loss: 0.021413536327308975
[Epoch 9, Batch 1300] loss: 0.0365756866754964
[Epoch 9, Batch 1400] loss: 0.024275559927045835
[Epoch 9, Batch 1500] loss: 0.029699690935376565
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9861
Overfitting: 0.0493
[Epoch 10, Batch 100] loss: 0.01666868013169733
[Epoch 10, Batch 200] loss: 0.018401023099868324
[Epoch 10, Batch 300] loss: 0.030064625231025276
[Epoch 10, Batch 400] loss: 0.025838961319532245
[Epoch 10, Batch 500] loss: 0.017665094015028443
[Epoch 10, Batch 600] loss: 0.021811993541778065
[Epoch 10, Batch 700] loss: 0.02153120492148446
[Epoch 10, Batch 800] loss: 0.02056047019264952
[Epoch 10, Batch 900] loss: 0.014893070698162774
[Epoch 10, Batch 1000] loss: 0.01806080646631017
[Epoch 10, Batch 1100] loss: 0.023590173103875713
[Epoch 10, Batch 1200] loss: 0.022016663074173267
[Epoch 10, Batch 1300] loss: 0.012177690305252327
[Epoch 10, Batch 1400] loss: 0.02140217137579384
[Epoch 10, Batch 1500] loss: 0.026356680440367198
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9858
Overfitting: 0.0502
[Epoch 11, Batch 100] loss: 0.01505665182339726
[Epoch 11, Batch 200] loss: 0.014047492600002442
[Epoch 11, Batch 300] loss: 0.01640071052395797
[Epoch 11, Batch 400] loss: 0.015986036817048445
[Epoch 11, Batch 500] loss: 0.018974870771198766
[Epoch 11, Batch 600] loss: 0.023354153559339466
[Epoch 11, Batch 700] loss: 0.017840147355891532
[Epoch 11, Batch 800] loss: 0.01693382993533305
[Epoch 11, Batch 900] loss: 0.01409448513884854
[Epoch 11, Batch 1000] loss: 0.014731820057349979
[Epoch 11, Batch 1100] loss: 0.014937060370102699
[Epoch 11, Batch 1200] loss: 0.014067930477613117
[Epoch 11, Batch 1300] loss: 0.020013641655996253
[Epoch 11, Batch 1400] loss: 0.01843631024028582
[Epoch 11, Batch 1500] loss: 0.019152717003962608
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9868
Overfitting: 0.0496
[Epoch 12, Batch 100] loss: 0.01594351385392656
[Epoch 12, Batch 200] loss: 0.01354760838535185
[Epoch 12, Batch 300] loss: 0.016665248200297356
[Epoch 12, Batch 400] loss: 0.014421410919021582
[Epoch 12, Batch 500] loss: 0.0127646278575412
[Epoch 12, Batch 600] loss: 0.023912201500061202
[Epoch 12, Batch 700] loss: 0.01073934735464718
[Epoch 12, Batch 800] loss: 0.010253192302770912
[Epoch 12, Batch 900] loss: 0.017292514238943114
[Epoch 12, Batch 1000] loss: 0.01947258291518665
[Epoch 12, Batch 1100] loss: 0.016862815298491114
[Epoch 12, Batch 1200] loss: 0.023997307179815835
[Epoch 12, Batch 1300] loss: 0.01638782988091407
[Epoch 12, Batch 1400] loss: 0.016932801903021755
[Epoch 12, Batch 1500] loss: 0.022920652197208256
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9862
Overfitting: 0.0493
[Epoch 13, Batch 100] loss: 0.01367654454968033
[Epoch 13, Batch 200] loss: 0.010582968150665693
[Epoch 13, Batch 300] loss: 0.015524621989352455
[Epoch 13, Batch 400] loss: 0.006984142361143313
[Epoch 13, Batch 500] loss: 0.014775768352628803
[Epoch 13, Batch 600] loss: 0.01800107199795093
[Epoch 13, Batch 700] loss: 0.017320642392878654
[Epoch 13, Batch 800] loss: 0.01548394569543234
[Epoch 13, Batch 900] loss: 0.015068055389274377
[Epoch 13, Batch 1000] loss: 0.014766391723387642
[Epoch 13, Batch 1100] loss: 0.014707223853692995
[Epoch 13, Batch 1200] loss: 0.016932827518503474
[Epoch 13, Batch 1300] loss: 0.011184251799895718
[Epoch 13, Batch 1400] loss: 0.010619135114829988
[Epoch 13, Batch 1500] loss: 0.02063290073769167
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9882
Overfitting: 0.0479
[Epoch 14, Batch 100] loss: 0.010921984715532745
[Epoch 14, Batch 200] loss: 0.011892842274864961
[Epoch 14, Batch 300] loss: 0.010431573543319245
[Epoch 14, Batch 400] loss: 0.009690938215753704
[Epoch 14, Batch 500] loss: 0.009031099834246561
[Epoch 14, Batch 600] loss: 0.011741756790361251
[Epoch 14, Batch 700] loss: 0.017954501927815728
[Epoch 14, Batch 800] loss: 0.01905645201310108
[Epoch 14, Batch 900] loss: 0.014483279314517858
[Epoch 14, Batch 1000] loss: 0.016204045529129872
[Epoch 14, Batch 1100] loss: 0.013317920714835054
[Epoch 14, Batch 1200] loss: 0.01921044084139794
[Epoch 14, Batch 1300] loss: 0.024028503403492323
[Epoch 14, Batch 1400] loss: 0.0174043803245695
[Epoch 14, Batch 1500] loss: 0.007143161891053751
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9883
Overfitting: 0.0456
[Epoch 15, Batch 100] loss: 0.006929323767690221
[Epoch 15, Batch 200] loss: 0.009059462476816407
[Epoch 15, Batch 300] loss: 0.005835032665618201
[Epoch 15, Batch 400] loss: 0.009610768115380778
[Epoch 15, Batch 500] loss: 0.006326706357513103
[Epoch 15, Batch 600] loss: 0.009606615825096015
[Epoch 15, Batch 700] loss: 0.009186840332122302
[Epoch 15, Batch 800] loss: 0.013794588306118384
[Epoch 15, Batch 900] loss: 0.014324325624511403
[Epoch 15, Batch 1000] loss: 0.01539323737396444
[Epoch 15, Batch 1100] loss: 0.011829174981849065
[Epoch 15, Batch 1200] loss: 0.014019084930441749
[Epoch 15, Batch 1300] loss: 0.009238510760060308
[Epoch 15, Batch 1400] loss: 0.008315916772116906
[Epoch 15, Batch 1500] loss: 0.013393305976223928
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9869
Overfitting: 0.0484
[Epoch 16, Batch 100] loss: 0.005384015057948091
[Epoch 16, Batch 200] loss: 0.005594873136560636
[Epoch 16, Batch 300] loss: 0.007374778237262945
[Epoch 16, Batch 400] loss: 0.00633071671600419
[Epoch 16, Batch 500] loss: 0.008713506973463155
[Epoch 16, Batch 600] loss: 0.014066847997182776
[Epoch 16, Batch 700] loss: 0.007977827471722775
[Epoch 16, Batch 800] loss: 0.013482150719937636
[Epoch 16, Batch 900] loss: 0.010078461222926762
[Epoch 16, Batch 1000] loss: 0.015554343722068893
[Epoch 16, Batch 1100] loss: 0.019086737855818683
[Epoch 16, Batch 1200] loss: 0.008737428081331019
[Epoch 16, Batch 1300] loss: 0.012684955875520244
[Epoch 16, Batch 1400] loss: 0.0097340383377923
[Epoch 16, Batch 1500] loss: 0.007345178753203072
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9876
Overfitting: 0.0515
[Epoch 17, Batch 100] loss: 0.013780954887179177
[Epoch 17, Batch 200] loss: 0.009489655516581479
[Epoch 17, Batch 300] loss: 0.01259377197336562
[Epoch 17, Batch 400] loss: 0.010682753002820391
[Epoch 17, Batch 500] loss: 0.013215414750357013
[Epoch 17, Batch 600] loss: 0.007712549428470083
[Epoch 17, Batch 700] loss: 0.005592342863910744
[Epoch 17, Batch 800] loss: 0.010027241241805313
[Epoch 17, Batch 900] loss: 0.007768503831332509
[Epoch 17, Batch 1000] loss: 0.006636053002480367
[Epoch 17, Batch 1100] loss: 0.009064269603436514
[Epoch 17, Batch 1200] loss: 0.008969384858601189
[Epoch 17, Batch 1300] loss: 0.014358438436102006
[Epoch 17, Batch 1400] loss: 0.011727926333096548
[Epoch 17, Batch 1500] loss: 0.014104123180795796
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9854
Overfitting: 0.0569
[Epoch 18, Batch 100] loss: 0.0073483738018330766
[Epoch 18, Batch 200] loss: 0.011566451758399125
[Epoch 18, Batch 300] loss: 0.007040224665979622
[Epoch 18, Batch 400] loss: 0.0069412881417520115
[Epoch 18, Batch 500] loss: 0.003135562815677986
[Epoch 18, Batch 600] loss: 0.00623406637131211
[Epoch 18, Batch 700] loss: 0.002763824355206452
[Epoch 18, Batch 800] loss: 0.004643612296088122
[Epoch 18, Batch 900] loss: 0.008511571380875011
[Epoch 18, Batch 1000] loss: 0.004777959632692727
[Epoch 18, Batch 1100] loss: 0.005794432440145556
[Epoch 18, Batch 1200] loss: 0.007538199921623345
[Epoch 18, Batch 1300] loss: 0.004988927819547371
[Epoch 18, Batch 1400] loss: 0.011941946919894236
[Epoch 18, Batch 1500] loss: 0.007016036451113905
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0563
Validation Accuracy: 0.9862
Overfitting: 0.0563
[Epoch 19, Batch 100] loss: 0.006020515582542884
[Epoch 19, Batch 200] loss: 0.005414565304257621
[Epoch 19, Batch 300] loss: 0.005968428591995689
[Epoch 19, Batch 400] loss: 0.0072305779050384445
[Epoch 19, Batch 500] loss: 0.0065497266433476396
[Epoch 19, Batch 600] loss: 0.009161670187797882
[Epoch 19, Batch 700] loss: 0.013224723007569992
[Epoch 19, Batch 800] loss: 0.009616003802702834
[Epoch 19, Batch 900] loss: 0.008375714478104328
[Epoch 19, Batch 1000] loss: 0.01125899099374351
[Epoch 19, Batch 1100] loss: 0.007431214296761936
[Epoch 19, Batch 1200] loss: 0.005681453835646266
[Epoch 19, Batch 1300] loss: 0.007138524838296121
[Epoch 19, Batch 1400] loss: 0.006879288586123949
[Epoch 19, Batch 1500] loss: 0.012368529638706605
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0583
Validation Accuracy: 0.9863
Overfitting: 0.0583
[Epoch 20, Batch 100] loss: 0.009291830863135146
[Epoch 20, Batch 200] loss: 0.0034099281233443434
[Epoch 20, Batch 300] loss: 0.007707631172934271
[Epoch 20, Batch 400] loss: 0.009583335733593686
[Epoch 20, Batch 500] loss: 0.008522026203027054
[Epoch 20, Batch 600] loss: 0.005843453609386416
[Epoch 20, Batch 700] loss: 0.005577770210280732
[Epoch 20, Batch 800] loss: 0.011299368470877197
[Epoch 20, Batch 900] loss: 0.009968823683423125
[Epoch 20, Batch 1000] loss: 0.00822405333886536
[Epoch 20, Batch 1100] loss: 0.004604339705879284
[Epoch 20, Batch 1200] loss: 0.010302123983337878
[Epoch 20, Batch 1300] loss: 0.004503983966924352
[Epoch 20, Batch 1400] loss: 0.004042130743021062
[Epoch 20, Batch 1500] loss: 0.009223839513510938
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9883
Overfitting: 0.0524
[Epoch 21, Batch 100] loss: 0.00547111191384829
[Epoch 21, Batch 200] loss: 0.005507796707485682
[Epoch 21, Batch 300] loss: 0.00698677653143477
[Epoch 21, Batch 400] loss: 0.005929350409508061
[Epoch 21, Batch 500] loss: 0.004024027429929902
[Epoch 21, Batch 600] loss: 0.0015674642761962332
[Epoch 21, Batch 700] loss: 0.0025028764310786756
[Epoch 21, Batch 800] loss: 0.003224955898514281
[Epoch 21, Batch 900] loss: 0.004886867765266061
[Epoch 21, Batch 1000] loss: 0.006548033815126928
[Epoch 21, Batch 1100] loss: 0.0046170094579338185
[Epoch 21, Batch 1200] loss: 0.0061672703634485515
[Epoch 21, Batch 1300] loss: 0.009422316087990339
[Epoch 21, Batch 1400] loss: 0.0032563876411171575
[Epoch 21, Batch 1500] loss: 0.00298861023262134
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9885
Overfitting: 0.0522
[Epoch 22, Batch 100] loss: 0.0030603837915805345
[Epoch 22, Batch 200] loss: 0.002232164830401189
[Epoch 22, Batch 300] loss: 0.007153861237631532
[Epoch 22, Batch 400] loss: 0.002826757575666363
[Epoch 22, Batch 500] loss: 0.0021326965091833473
[Epoch 22, Batch 600] loss: 0.0025306024573978902
[Epoch 22, Batch 700] loss: 0.006275833915876774
[Epoch 22, Batch 800] loss: 0.0035048224771003335
[Epoch 22, Batch 900] loss: 0.003184049925953332
[Epoch 22, Batch 1000] loss: 0.0051388507984293594
[Epoch 22, Batch 1100] loss: 0.003037504434668108
[Epoch 22, Batch 1200] loss: 0.0057846531485972715
[Epoch 22, Batch 1300] loss: 0.013797710437588649
[Epoch 22, Batch 1400] loss: 0.012272056425395021
[Epoch 22, Batch 1500] loss: 0.009697034894370517
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0600
Validation Accuracy: 0.9858
Overfitting: 0.0600
[Epoch 23, Batch 100] loss: 0.006304106828018803
[Epoch 23, Batch 200] loss: 0.006475703109708774
[Epoch 23, Batch 300] loss: 0.006630335255781574
[Epoch 23, Batch 400] loss: 0.006337157610305439
[Epoch 23, Batch 500] loss: 0.0019186145970513735
[Epoch 23, Batch 600] loss: 0.004922854685705147
[Epoch 23, Batch 700] loss: 0.002407969525038425
[Epoch 23, Batch 800] loss: 0.005495277647876833
[Epoch 23, Batch 900] loss: 0.005741996389668884
[Epoch 23, Batch 1000] loss: 0.002371796829036157
[Epoch 23, Batch 1100] loss: 0.0023755064366082477
[Epoch 23, Batch 1200] loss: 0.0028110715523644103
[Epoch 23, Batch 1300] loss: 0.003840298788571772
[Epoch 23, Batch 1400] loss: 0.0029319856224185514
[Epoch 23, Batch 1500] loss: 0.0024734263858999838
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9881
Overfitting: 0.0552
[Epoch 24, Batch 100] loss: 0.001407246490820171
[Epoch 24, Batch 200] loss: 0.0026877981009322126
[Epoch 24, Batch 300] loss: 0.0018720389811528548
[Epoch 24, Batch 400] loss: 0.0019499827108425904
[Epoch 24, Batch 500] loss: 0.000806316311585249
[Epoch 24, Batch 600] loss: 0.0018922400777020697
[Epoch 24, Batch 700] loss: 0.0036493876806514437
[Epoch 24, Batch 800] loss: 0.002197896787451441
[Epoch 24, Batch 900] loss: 0.003894960147469533
[Epoch 24, Batch 1000] loss: 0.0015204344363425547
[Epoch 24, Batch 1100] loss: 0.000848607154172214
[Epoch 24, Batch 1200] loss: 0.005087210896574561
[Epoch 24, Batch 1300] loss: 0.0027538332565183055
[Epoch 24, Batch 1400] loss: 0.0016898115267508728
[Epoch 24, Batch 1500] loss: 0.0030208992616502428
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0687
Validation Accuracy: 0.9851
Overfitting: 0.0687
Fold 3 validation loss: 0.0687
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2602530574798583
[Epoch 1, Batch 200] loss: 1.313482309281826
[Epoch 1, Batch 300] loss: 0.49096451602876184
[Epoch 1, Batch 400] loss: 0.3670512482523918
[Epoch 1, Batch 500] loss: 0.27065292857587336
[Epoch 1, Batch 600] loss: 0.24994551718235017
[Epoch 1, Batch 700] loss: 0.1900068199634552
[Epoch 1, Batch 800] loss: 0.1743974659591913
[Epoch 1, Batch 900] loss: 0.1928116985503584
[Epoch 1, Batch 1000] loss: 0.14303010636009275
[Epoch 1, Batch 1100] loss: 0.1477133579738438
[Epoch 1, Batch 1200] loss: 0.12766594924032687
[Epoch 1, Batch 1300] loss: 0.11098585593979805
[Epoch 1, Batch 1400] loss: 0.12234007785562426
[Epoch 1, Batch 1500] loss: 0.1098510462231934
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1017
Validation Accuracy: 0.9661
Overfitting: 0.1017
Best model saved at epoch 1 with validation loss: 0.1017
[Epoch 2, Batch 100] loss: 0.11694221014156937
[Epoch 2, Batch 200] loss: 0.11509395295754075
[Epoch 2, Batch 300] loss: 0.1199933132622391
[Epoch 2, Batch 400] loss: 0.09195802255766466
[Epoch 2, Batch 500] loss: 0.1110237857280299
[Epoch 2, Batch 600] loss: 0.07442066943040118
[Epoch 2, Batch 700] loss: 0.0673552986397408
[Epoch 2, Batch 800] loss: 0.08239652659278363
[Epoch 2, Batch 900] loss: 0.07674497749656439
[Epoch 2, Batch 1000] loss: 0.08546328452881426
[Epoch 2, Batch 1100] loss: 0.08363163893576711
[Epoch 2, Batch 1200] loss: 0.07306181343272328
[Epoch 2, Batch 1300] loss: 0.08827823074767366
[Epoch 2, Batch 1400] loss: 0.0840270543564111
[Epoch 2, Batch 1500] loss: 0.08145797298755497
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0882
Validation Accuracy: 0.9719
Overfitting: 0.0882
Best model saved at epoch 2 with validation loss: 0.0882
[Epoch 3, Batch 100] loss: 0.07178779885172844
[Epoch 3, Batch 200] loss: 0.06381600767141209
[Epoch 3, Batch 300] loss: 0.06322974959155545
[Epoch 3, Batch 400] loss: 0.06454213267192245
[Epoch 3, Batch 500] loss: 0.06929451206000521
[Epoch 3, Batch 600] loss: 0.06269745510304346
[Epoch 3, Batch 700] loss: 0.0628013477055356
[Epoch 3, Batch 800] loss: 0.06825111628277228
[Epoch 3, Batch 900] loss: 0.08378765083383768
[Epoch 3, Batch 1000] loss: 0.05836441981140524
[Epoch 3, Batch 1100] loss: 0.05551264451118186
[Epoch 3, Batch 1200] loss: 0.06033151221461594
[Epoch 3, Batch 1300] loss: 0.06118271776475012
[Epoch 3, Batch 1400] loss: 0.0570084484340623
[Epoch 3, Batch 1500] loss: 0.05714828397263773
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0682
Validation Accuracy: 0.9788
Overfitting: 0.0682
Best model saved at epoch 3 with validation loss: 0.0682
[Epoch 4, Batch 100] loss: 0.04648369252332486
[Epoch 4, Batch 200] loss: 0.043561316473642364
[Epoch 4, Batch 300] loss: 0.04596759439795278
[Epoch 4, Batch 400] loss: 0.050692861246643586
[Epoch 4, Batch 500] loss: 0.054928084120620044
[Epoch 4, Batch 600] loss: 0.05740042166202329
[Epoch 4, Batch 700] loss: 0.046391896686400286
[Epoch 4, Batch 800] loss: 0.04881133330054581
[Epoch 4, Batch 900] loss: 0.05317907689081039
[Epoch 4, Batch 1000] loss: 0.052266925671137866
[Epoch 4, Batch 1100] loss: 0.04519778843561653
[Epoch 4, Batch 1200] loss: 0.05035249050008133
[Epoch 4, Batch 1300] loss: 0.04532708573620767
[Epoch 4, Batch 1400] loss: 0.05817706265719608
[Epoch 4, Batch 1500] loss: 0.054700244719861076
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9840
Overfitting: 0.0536
Best model saved at epoch 4 with validation loss: 0.0536
[Epoch 5, Batch 100] loss: 0.047256282286252824
[Epoch 5, Batch 200] loss: 0.048527233560744204
[Epoch 5, Batch 300] loss: 0.034032828458584845
[Epoch 5, Batch 400] loss: 0.03194241283024894
[Epoch 5, Batch 500] loss: 0.04339790890633594
[Epoch 5, Batch 600] loss: 0.03436646223766729
[Epoch 5, Batch 700] loss: 0.054785420956322925
[Epoch 5, Batch 800] loss: 0.03486515281809261
[Epoch 5, Batch 900] loss: 0.04400646183406934
[Epoch 5, Batch 1000] loss: 0.040467604603036306
[Epoch 5, Batch 1100] loss: 0.050462797729414886
[Epoch 5, Batch 1200] loss: 0.03503483257722109
[Epoch 5, Batch 1300] loss: 0.03688813929678872
[Epoch 5, Batch 1400] loss: 0.03825168185867369
[Epoch 5, Batch 1500] loss: 0.03604469491838245
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0597
Validation Accuracy: 0.9827
Overfitting: 0.0597
[Epoch 6, Batch 100] loss: 0.03386814985598903
[Epoch 6, Batch 200] loss: 0.03464416933551547
[Epoch 6, Batch 300] loss: 0.03141064968018327
[Epoch 6, Batch 400] loss: 0.03807341005129274
[Epoch 6, Batch 500] loss: 0.029492100717907307
[Epoch 6, Batch 600] loss: 0.044864665407803844
[Epoch 6, Batch 700] loss: 0.032409920534410046
[Epoch 6, Batch 800] loss: 0.03454597427480621
[Epoch 6, Batch 900] loss: 0.0438316448230762
[Epoch 6, Batch 1000] loss: 0.03679015878413338
[Epoch 6, Batch 1100] loss: 0.041306057994952426
[Epoch 6, Batch 1200] loss: 0.025423670798772946
[Epoch 6, Batch 1300] loss: 0.03452049473358784
[Epoch 6, Batch 1400] loss: 0.03626980812579859
[Epoch 6, Batch 1500] loss: 0.04344281675759703
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9863
Overfitting: 0.0452
Best model saved at epoch 6 with validation loss: 0.0452
[Epoch 7, Batch 100] loss: 0.031039129403361586
[Epoch 7, Batch 200] loss: 0.026926542395958677
[Epoch 7, Batch 300] loss: 0.020199553222046234
[Epoch 7, Batch 400] loss: 0.04007979828602402
[Epoch 7, Batch 500] loss: 0.027172701695526484
[Epoch 7, Batch 600] loss: 0.031168398013687693
[Epoch 7, Batch 700] loss: 0.02215541338402545
[Epoch 7, Batch 800] loss: 0.03376900746166939
[Epoch 7, Batch 900] loss: 0.02776844719221117
[Epoch 7, Batch 1000] loss: 0.030250011135067326
[Epoch 7, Batch 1100] loss: 0.032025295915082096
[Epoch 7, Batch 1200] loss: 0.03353354555787519
[Epoch 7, Batch 1300] loss: 0.03116223109951534
[Epoch 7, Batch 1400] loss: 0.027359715418715496
[Epoch 7, Batch 1500] loss: 0.040086236262432066
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9868
Overfitting: 0.0457
[Epoch 8, Batch 100] loss: 0.018745295973931205
[Epoch 8, Batch 200] loss: 0.027890925732644973
[Epoch 8, Batch 300] loss: 0.01847324460541131
[Epoch 8, Batch 400] loss: 0.015074581358348951
[Epoch 8, Batch 500] loss: 0.02998635307638324
[Epoch 8, Batch 600] loss: 0.033556311675638426
[Epoch 8, Batch 700] loss: 0.018043787634815088
[Epoch 8, Batch 800] loss: 0.026194121302105487
[Epoch 8, Batch 900] loss: 0.016951010493503418
[Epoch 8, Batch 1000] loss: 0.019331553170050027
[Epoch 8, Batch 1100] loss: 0.020856935467309087
[Epoch 8, Batch 1200] loss: 0.031458746389398586
[Epoch 8, Batch 1300] loss: 0.025216954447969328
[Epoch 8, Batch 1400] loss: 0.030760987162211678
[Epoch 8, Batch 1500] loss: 0.034472008814336735
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9842
Overfitting: 0.0525
[Epoch 9, Batch 100] loss: 0.017259236999889252
[Epoch 9, Batch 200] loss: 0.026510651094431525
[Epoch 9, Batch 300] loss: 0.016607738997554407
[Epoch 9, Batch 400] loss: 0.018611717340900214
[Epoch 9, Batch 500] loss: 0.02166101426111709
[Epoch 9, Batch 600] loss: 0.02221605747647118
[Epoch 9, Batch 700] loss: 0.03357881376454316
[Epoch 9, Batch 800] loss: 0.02242686242942
[Epoch 9, Batch 900] loss: 0.024903520607040264
[Epoch 9, Batch 1000] loss: 0.0172950559828314
[Epoch 9, Batch 1100] loss: 0.02031659839543863
[Epoch 9, Batch 1200] loss: 0.023877215510292444
[Epoch 9, Batch 1300] loss: 0.022682944376319937
[Epoch 9, Batch 1400] loss: 0.020438685279223136
[Epoch 9, Batch 1500] loss: 0.02089579236751888
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0517
Validation Accuracy: 0.9855
Overfitting: 0.0517
[Epoch 10, Batch 100] loss: 0.010336773236194858
[Epoch 10, Batch 200] loss: 0.017700087565754075
[Epoch 10, Batch 300] loss: 0.015195612607276416
[Epoch 10, Batch 400] loss: 0.017417401863640408
[Epoch 10, Batch 500] loss: 0.016921366924725588
[Epoch 10, Batch 600] loss: 0.020861622692682432
[Epoch 10, Batch 700] loss: 0.014494164470524993
[Epoch 10, Batch 800] loss: 0.019433762863336597
[Epoch 10, Batch 900] loss: 0.013690502151148394
[Epoch 10, Batch 1000] loss: 0.014131965835731534
[Epoch 10, Batch 1100] loss: 0.020954251088987803
[Epoch 10, Batch 1200] loss: 0.014304488362104167
[Epoch 10, Batch 1300] loss: 0.024198827831278323
[Epoch 10, Batch 1400] loss: 0.021753161702072248
[Epoch 10, Batch 1500] loss: 0.031113799813028892
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0566
Validation Accuracy: 0.9838
Overfitting: 0.0566
[Epoch 11, Batch 100] loss: 0.01962958375836024
[Epoch 11, Batch 200] loss: 0.012878658001282019
[Epoch 11, Batch 300] loss: 0.011121598359022756
[Epoch 11, Batch 400] loss: 0.013393450469066011
[Epoch 11, Batch 500] loss: 0.022305311384006928
[Epoch 11, Batch 600] loss: 0.017061500355921452
[Epoch 11, Batch 700] loss: 0.02466806784941582
[Epoch 11, Batch 800] loss: 0.014696940780686419
[Epoch 11, Batch 900] loss: 0.013549640590063063
[Epoch 11, Batch 1000] loss: 0.017829643623845187
[Epoch 11, Batch 1100] loss: 0.011867424159681832
[Epoch 11, Batch 1200] loss: 0.014842993103266054
[Epoch 11, Batch 1300] loss: 0.03149665849894518
[Epoch 11, Batch 1400] loss: 0.016907785554503788
[Epoch 11, Batch 1500] loss: 0.024918483579676833
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9858
Overfitting: 0.0481
[Epoch 12, Batch 100] loss: 0.013329778074403293
[Epoch 12, Batch 200] loss: 0.008958928862411994
[Epoch 12, Batch 300] loss: 0.0121644967166867
[Epoch 12, Batch 400] loss: 0.012540016195598582
[Epoch 12, Batch 500] loss: 0.010678555528866127
[Epoch 12, Batch 600] loss: 0.014748611578434066
[Epoch 12, Batch 700] loss: 0.013817325277850614
[Epoch 12, Batch 800] loss: 0.011877780273352982
[Epoch 12, Batch 900] loss: 0.010083614005343406
[Epoch 12, Batch 1000] loss: 0.026764558957602276
[Epoch 12, Batch 1100] loss: 0.017045645121615962
[Epoch 12, Batch 1200] loss: 0.019253191175412212
[Epoch 12, Batch 1300] loss: 0.015892546255199706
[Epoch 12, Batch 1400] loss: 0.01817864742199163
[Epoch 12, Batch 1500] loss: 0.01669183382360643
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0395
Validation Accuracy: 0.9885
Overfitting: 0.0395
Best model saved at epoch 12 with validation loss: 0.0395
[Epoch 13, Batch 100] loss: 0.013878120704566755
[Epoch 13, Batch 200] loss: 0.010110787278608768
[Epoch 13, Batch 300] loss: 0.012597549010679358
[Epoch 13, Batch 400] loss: 0.005056337383812206
[Epoch 13, Batch 500] loss: 0.009745177284639795
[Epoch 13, Batch 600] loss: 0.00995888012499563
[Epoch 13, Batch 700] loss: 0.010294630581629462
[Epoch 13, Batch 800] loss: 0.013062930624400906
[Epoch 13, Batch 900] loss: 0.012579375315417564
[Epoch 13, Batch 1000] loss: 0.01049328384036926
[Epoch 13, Batch 1100] loss: 0.009604216587467818
[Epoch 13, Batch 1200] loss: 0.018339302144177054
[Epoch 13, Batch 1300] loss: 0.015563905555354722
[Epoch 13, Batch 1400] loss: 0.02484907452973857
[Epoch 13, Batch 1500] loss: 0.015561339595224126
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9873
Overfitting: 0.0462
[Epoch 14, Batch 100] loss: 0.012378219034126232
[Epoch 14, Batch 200] loss: 0.007783211588339327
[Epoch 14, Batch 300] loss: 0.015274889402771805
[Epoch 14, Batch 400] loss: 0.009988436002022354
[Epoch 14, Batch 500] loss: 0.00994456873042509
[Epoch 14, Batch 600] loss: 0.008006211262691068
[Epoch 14, Batch 700] loss: 0.012495430688950364
[Epoch 14, Batch 800] loss: 0.007295294740160898
[Epoch 14, Batch 900] loss: 0.013289775244829797
[Epoch 14, Batch 1000] loss: 0.011230967126448377
[Epoch 14, Batch 1100] loss: 0.015572069069821736
[Epoch 14, Batch 1200] loss: 0.013346811491082917
[Epoch 14, Batch 1300] loss: 0.009521296562743373
[Epoch 14, Batch 1400] loss: 0.010593638132522756
[Epoch 14, Batch 1500] loss: 0.014019811305979601
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0416
Validation Accuracy: 0.9882
Overfitting: 0.0416
[Epoch 15, Batch 100] loss: 0.011145986940682633
[Epoch 15, Batch 200] loss: 0.012017472830848419
[Epoch 15, Batch 300] loss: 0.00510041316339084
[Epoch 15, Batch 400] loss: 0.007480674309817914
[Epoch 15, Batch 500] loss: 0.007374511978769078
[Epoch 15, Batch 600] loss: 0.010832270015380346
[Epoch 15, Batch 700] loss: 0.013147206233516045
[Epoch 15, Batch 800] loss: 0.007009870676210994
[Epoch 15, Batch 900] loss: 0.01595143715647282
[Epoch 15, Batch 1000] loss: 0.014546041179528402
[Epoch 15, Batch 1100] loss: 0.00707499594449473
[Epoch 15, Batch 1200] loss: 0.007834648340394778
[Epoch 15, Batch 1300] loss: 0.011295623102855644
[Epoch 15, Batch 1400] loss: 0.010419164539498524
[Epoch 15, Batch 1500] loss: 0.00791507164529321
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9868
Overfitting: 0.0487
[Epoch 16, Batch 100] loss: 0.008473304764438581
[Epoch 16, Batch 200] loss: 0.005023567916996399
[Epoch 16, Batch 300] loss: 0.006481841365584841
[Epoch 16, Batch 400] loss: 0.0097270723578049
[Epoch 16, Batch 500] loss: 0.0024988294488593964
[Epoch 16, Batch 600] loss: 0.003975321004581929
[Epoch 16, Batch 700] loss: 0.006779472436546712
[Epoch 16, Batch 800] loss: 0.004295219263258332
[Epoch 16, Batch 900] loss: 0.008261006864458978
[Epoch 16, Batch 1000] loss: 0.0071753599456314985
[Epoch 16, Batch 1100] loss: 0.01026923722583888
[Epoch 16, Batch 1200] loss: 0.009614687159009918
[Epoch 16, Batch 1300] loss: 0.007733921348244621
[Epoch 16, Batch 1400] loss: 0.010227934618842482
[Epoch 16, Batch 1500] loss: 0.013831867547996807
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9868
Overfitting: 0.0511
[Epoch 17, Batch 100] loss: 0.006621652663834538
[Epoch 17, Batch 200] loss: 0.008112669087531686
[Epoch 17, Batch 300] loss: 0.008156154766311374
[Epoch 17, Batch 400] loss: 0.016019657921015097
[Epoch 17, Batch 500] loss: 0.014220624442768894
[Epoch 17, Batch 600] loss: 0.00852382423963718
[Epoch 17, Batch 700] loss: 0.010129647128778743
[Epoch 17, Batch 800] loss: 0.007699521460490359
[Epoch 17, Batch 900] loss: 0.008823809297186926
[Epoch 17, Batch 1000] loss: 0.004620414732926292
[Epoch 17, Batch 1100] loss: 0.007564307341681342
[Epoch 17, Batch 1200] loss: 0.0060801219582026535
[Epoch 17, Batch 1300] loss: 0.0068082478917585836
[Epoch 17, Batch 1400] loss: 0.010296132544467582
[Epoch 17, Batch 1500] loss: 0.00731814330448401
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9871
Overfitting: 0.0529
[Epoch 18, Batch 100] loss: 0.004165707628721975
[Epoch 18, Batch 200] loss: 0.006882730860525044
[Epoch 18, Batch 300] loss: 0.0037656034534484205
[Epoch 18, Batch 400] loss: 0.004934987587261617
[Epoch 18, Batch 500] loss: 0.00608167803872675
[Epoch 18, Batch 600] loss: 0.005525331707576697
[Epoch 18, Batch 700] loss: 0.006390668516653477
[Epoch 18, Batch 800] loss: 0.007904857900048228
[Epoch 18, Batch 900] loss: 0.0035449806443375565
[Epoch 18, Batch 1000] loss: 0.006368183338458948
[Epoch 18, Batch 1100] loss: 0.007490221283915161
[Epoch 18, Batch 1200] loss: 0.008610800315909727
[Epoch 18, Batch 1300] loss: 0.006682020258967896
[Epoch 18, Batch 1400] loss: 0.003899568130091211
[Epoch 18, Batch 1500] loss: 0.003701715055020713
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0461
Validation Accuracy: 0.9884
Overfitting: 0.0461
[Epoch 19, Batch 100] loss: 0.004736880813065909
[Epoch 19, Batch 200] loss: 0.00665989766882376
[Epoch 19, Batch 300] loss: 0.006893643728332109
[Epoch 19, Batch 400] loss: 0.004135190929914643
[Epoch 19, Batch 500] loss: 0.004003917024172097
[Epoch 19, Batch 600] loss: 0.004073075322249337
[Epoch 19, Batch 700] loss: 0.005017374431638473
[Epoch 19, Batch 800] loss: 0.003997569489135913
[Epoch 19, Batch 900] loss: 0.004579138201393107
[Epoch 19, Batch 1000] loss: 0.005622917984992455
[Epoch 19, Batch 1100] loss: 0.009741136497277694
[Epoch 19, Batch 1200] loss: 0.008770685769448505
[Epoch 19, Batch 1300] loss: 0.007338000126921997
[Epoch 19, Batch 1400] loss: 0.014458613606516338
[Epoch 19, Batch 1500] loss: 0.00789575806355515
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9882
Overfitting: 0.0516
[Epoch 20, Batch 100] loss: 0.004375982385479347
[Epoch 20, Batch 200] loss: 0.0033267759018735885
[Epoch 20, Batch 300] loss: 0.002602112624849724
[Epoch 20, Batch 400] loss: 0.005706844448670836
[Epoch 20, Batch 500] loss: 0.006901277162464794
[Epoch 20, Batch 600] loss: 0.002984036374750758
[Epoch 20, Batch 700] loss: 0.004299244930703026
[Epoch 20, Batch 800] loss: 0.006398424408195638
[Epoch 20, Batch 900] loss: 0.004990485467864118
[Epoch 20, Batch 1000] loss: 0.006260847510122858
[Epoch 20, Batch 1100] loss: 0.002418694913642412
[Epoch 20, Batch 1200] loss: 0.0042922956351856105
[Epoch 20, Batch 1300] loss: 0.007231709804354978
[Epoch 20, Batch 1400] loss: 0.008169658576921392
[Epoch 20, Batch 1500] loss: 0.011660731594347454
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9878
Overfitting: 0.0550
[Epoch 21, Batch 100] loss: 0.00272776257663736
[Epoch 21, Batch 200] loss: 0.005225347223009749
[Epoch 21, Batch 300] loss: 0.002533580037525098
[Epoch 21, Batch 400] loss: 0.0024488443478367116
[Epoch 21, Batch 500] loss: 0.003815690673873178
[Epoch 21, Batch 600] loss: 0.0040997739101226215
[Epoch 21, Batch 700] loss: 0.0016258687942399775
[Epoch 21, Batch 800] loss: 0.0047582356098928354
[Epoch 21, Batch 900] loss: 0.00308647818800182
[Epoch 21, Batch 1000] loss: 0.0032077682910323802
[Epoch 21, Batch 1100] loss: 0.002840295583715715
[Epoch 21, Batch 1200] loss: 0.005928084074683966
[Epoch 21, Batch 1300] loss: 0.008108680264649592
[Epoch 21, Batch 1400] loss: 0.007499242655317175
[Epoch 21, Batch 1500] loss: 0.00805351811861783
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9878
Overfitting: 0.0493
[Epoch 22, Batch 100] loss: 0.007819472102225973
[Epoch 22, Batch 200] loss: 0.002539210974159687
[Epoch 22, Batch 300] loss: 0.0032901145828645893
[Epoch 22, Batch 400] loss: 0.008313965209467825
[Epoch 22, Batch 500] loss: 0.008475026244132095
[Epoch 22, Batch 600] loss: 0.0052307970782638335
[Epoch 22, Batch 700] loss: 0.007100829204935053
[Epoch 22, Batch 800] loss: 0.007676887893582034
[Epoch 22, Batch 900] loss: 0.0043652743811799155
[Epoch 22, Batch 1000] loss: 0.0028345207958011542
[Epoch 22, Batch 1100] loss: 0.0033069037460444406
[Epoch 22, Batch 1200] loss: 0.0030506611382566007
[Epoch 22, Batch 1300] loss: 0.014293384040145156
[Epoch 22, Batch 1400] loss: 0.009703205885032276
[Epoch 22, Batch 1500] loss: 0.005909229474159474
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9880
Overfitting: 0.0502
[Epoch 23, Batch 100] loss: 0.006249122997653558
[Epoch 23, Batch 200] loss: 0.0037729269847466187
[Epoch 23, Batch 300] loss: 0.0038749733817348897
[Epoch 23, Batch 400] loss: 0.0015614377816029902
[Epoch 23, Batch 500] loss: 0.002793016894424909
[Epoch 23, Batch 600] loss: 0.0017976917548483584
[Epoch 23, Batch 700] loss: 0.002199446402959211
[Epoch 23, Batch 800] loss: 0.0013443365245274209
[Epoch 23, Batch 900] loss: 0.003518083533279537
[Epoch 23, Batch 1000] loss: 0.0048143357671187915
[Epoch 23, Batch 1100] loss: 0.001572627236235462
[Epoch 23, Batch 1200] loss: 0.0014186160841939
[Epoch 23, Batch 1300] loss: 0.002203822108610609
[Epoch 23, Batch 1400] loss: 0.0022232679123362687
[Epoch 23, Batch 1500] loss: 0.0033525689376676837
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9894
Overfitting: 0.0478
[Epoch 24, Batch 100] loss: 0.001045440971483913
[Epoch 24, Batch 200] loss: 0.0006787575349306962
[Epoch 24, Batch 300] loss: 0.00045316707363696196
[Epoch 24, Batch 400] loss: 0.0011108656176628529
[Epoch 24, Batch 500] loss: 0.0006599257040002726
[Epoch 24, Batch 600] loss: 0.0017417061771351427
[Epoch 24, Batch 700] loss: 0.0010474946278128526
[Epoch 24, Batch 800] loss: 0.0016318917328419502
[Epoch 24, Batch 900] loss: 0.0017342215541501105
[Epoch 24, Batch 1000] loss: 0.002012394914871436
[Epoch 24, Batch 1100] loss: 0.005825340556837091
[Epoch 24, Batch 1200] loss: 0.0034366416781347196
[Epoch 24, Batch 1300] loss: 0.001783214486468907
[Epoch 24, Batch 1400] loss: 0.002776307329717156
[Epoch 24, Batch 1500] loss: 0.0027548567806127268
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9888
Overfitting: 0.0489
Fold 4 validation loss: 0.0489
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2132036006450653
[Epoch 1, Batch 200] loss: 1.0956909173727036
[Epoch 1, Batch 300] loss: 0.45524177491664886
[Epoch 1, Batch 400] loss: 0.3412575781345367
[Epoch 1, Batch 500] loss: 0.29384879019111393
[Epoch 1, Batch 600] loss: 0.23472509099170566
[Epoch 1, Batch 700] loss: 0.21234187260270118
[Epoch 1, Batch 800] loss: 0.18721004523336887
[Epoch 1, Batch 900] loss: 0.15506323248147966
[Epoch 1, Batch 1000] loss: 0.15473937805742025
[Epoch 1, Batch 1100] loss: 0.14432254823856056
[Epoch 1, Batch 1200] loss: 0.12936848263721912
[Epoch 1, Batch 1300] loss: 0.10740862089209259
[Epoch 1, Batch 1400] loss: 0.11563832629006356
[Epoch 1, Batch 1500] loss: 0.11436670382507146
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1021
Validation Accuracy: 0.9697
Overfitting: 0.1021
Best model saved at epoch 1 with validation loss: 0.1021
[Epoch 2, Batch 100] loss: 0.08901954262983054
[Epoch 2, Batch 200] loss: 0.11804793794639408
[Epoch 2, Batch 300] loss: 0.08953149185748771
[Epoch 2, Batch 400] loss: 0.093966691554524
[Epoch 2, Batch 500] loss: 0.09969586961437017
[Epoch 2, Batch 600] loss: 0.0803033015714027
[Epoch 2, Batch 700] loss: 0.08410733175929636
[Epoch 2, Batch 800] loss: 0.0885100959148258
[Epoch 2, Batch 900] loss: 0.08298004354117439
[Epoch 2, Batch 1000] loss: 0.0841153455269523
[Epoch 2, Batch 1100] loss: 0.08039773327298462
[Epoch 2, Batch 1200] loss: 0.07725811092182994
[Epoch 2, Batch 1300] loss: 0.059855128469644116
[Epoch 2, Batch 1400] loss: 0.0770192455931101
[Epoch 2, Batch 1500] loss: 0.07348573036957533
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0752
Validation Accuracy: 0.9781
Overfitting: 0.0752
Best model saved at epoch 2 with validation loss: 0.0752
[Epoch 3, Batch 100] loss: 0.05574812916223891
[Epoch 3, Batch 200] loss: 0.07057273206999526
[Epoch 3, Batch 300] loss: 0.05546865857962985
[Epoch 3, Batch 400] loss: 0.06987687597516924
[Epoch 3, Batch 500] loss: 0.058581288580317054
[Epoch 3, Batch 600] loss: 0.06641893323743715
[Epoch 3, Batch 700] loss: 0.05104352603841107
[Epoch 3, Batch 800] loss: 0.06175222905934788
[Epoch 3, Batch 900] loss: 0.056202042715158315
[Epoch 3, Batch 1000] loss: 0.05405043890583329
[Epoch 3, Batch 1100] loss: 0.04954840754158795
[Epoch 3, Batch 1200] loss: 0.05561861815745942
[Epoch 3, Batch 1300] loss: 0.0457833905518055
[Epoch 3, Batch 1400] loss: 0.07448199672158808
[Epoch 3, Batch 1500] loss: 0.058610508013516666
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0607
Validation Accuracy: 0.9806
Overfitting: 0.0607
Best model saved at epoch 3 with validation loss: 0.0607
[Epoch 4, Batch 100] loss: 0.03297113574459218
[Epoch 4, Batch 200] loss: 0.055509271852206436
[Epoch 4, Batch 300] loss: 0.04556436984217726
[Epoch 4, Batch 400] loss: 0.06030613756156526
[Epoch 4, Batch 500] loss: 0.05236524631967768
[Epoch 4, Batch 600] loss: 0.0367341930733528
[Epoch 4, Batch 700] loss: 0.04680608012131415
[Epoch 4, Batch 800] loss: 0.05321746632806026
[Epoch 4, Batch 900] loss: 0.05425398142309859
[Epoch 4, Batch 1000] loss: 0.058329549976624546
[Epoch 4, Batch 1100] loss: 0.03804067823686637
[Epoch 4, Batch 1200] loss: 0.04130658682319335
[Epoch 4, Batch 1300] loss: 0.0467547847534297
[Epoch 4, Batch 1400] loss: 0.04240492301702034
[Epoch 4, Batch 1500] loss: 0.04461260854557622
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0503
Validation Accuracy: 0.9842
Overfitting: 0.0503
Best model saved at epoch 4 with validation loss: 0.0503
[Epoch 5, Batch 100] loss: 0.0283619907614775
[Epoch 5, Batch 200] loss: 0.04700052442378364
[Epoch 5, Batch 300] loss: 0.04101356715225848
[Epoch 5, Batch 400] loss: 0.03510856332955882
[Epoch 5, Batch 500] loss: 0.03602987830934581
[Epoch 5, Batch 600] loss: 0.050131470682099465
[Epoch 5, Batch 700] loss: 0.0532814076176146
[Epoch 5, Batch 800] loss: 0.03593152003770229
[Epoch 5, Batch 900] loss: 0.03552108811505605
[Epoch 5, Batch 1000] loss: 0.03494854743563337
[Epoch 5, Batch 1100] loss: 0.044326526160875804
[Epoch 5, Batch 1200] loss: 0.03601072557503358
[Epoch 5, Batch 1300] loss: 0.04674741257360438
[Epoch 5, Batch 1400] loss: 0.02948250355766504
[Epoch 5, Batch 1500] loss: 0.032021163542813154
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9844
Overfitting: 0.0511
[Epoch 6, Batch 100] loss: 0.03534300254425034
[Epoch 6, Batch 200] loss: 0.0239690246572718
[Epoch 6, Batch 300] loss: 0.0320218500764895
[Epoch 6, Batch 400] loss: 0.02760305259274901
[Epoch 6, Batch 500] loss: 0.03607739312021294
[Epoch 6, Batch 600] loss: 0.03468005050963256
[Epoch 6, Batch 700] loss: 0.033864240452239756
[Epoch 6, Batch 800] loss: 0.027497556127491406
[Epoch 6, Batch 900] loss: 0.025976040991954507
[Epoch 6, Batch 1000] loss: 0.03653575854958035
[Epoch 6, Batch 1100] loss: 0.03218837947497377
[Epoch 6, Batch 1200] loss: 0.03203828259749571
[Epoch 6, Batch 1300] loss: 0.045792917842627505
[Epoch 6, Batch 1400] loss: 0.028776030016306322
[Epoch 6, Batch 1500] loss: 0.029668598287389613
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9866
Overfitting: 0.0445
Best model saved at epoch 6 with validation loss: 0.0445
[Epoch 7, Batch 100] loss: 0.01827181246713735
[Epoch 7, Batch 200] loss: 0.03013739791320404
[Epoch 7, Batch 300] loss: 0.029464922603292507
[Epoch 7, Batch 400] loss: 0.028700382802344392
[Epoch 7, Batch 500] loss: 0.029382678220572417
[Epoch 7, Batch 600] loss: 0.02493403801767272
[Epoch 7, Batch 700] loss: 0.024819007377518573
[Epoch 7, Batch 800] loss: 0.022733757627283923
[Epoch 7, Batch 900] loss: 0.026475253987155157
[Epoch 7, Batch 1000] loss: 0.032860891180462204
[Epoch 7, Batch 1100] loss: 0.036854198317741976
[Epoch 7, Batch 1200] loss: 0.02832473806614871
[Epoch 7, Batch 1300] loss: 0.027084069039556197
[Epoch 7, Batch 1400] loss: 0.01990450265831896
[Epoch 7, Batch 1500] loss: 0.022607524326158455
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9862
Overfitting: 0.0471
[Epoch 8, Batch 100] loss: 0.024003267151492765
[Epoch 8, Batch 200] loss: 0.021575975192245096
[Epoch 8, Batch 300] loss: 0.02193926396805182
[Epoch 8, Batch 400] loss: 0.02463922130787978
[Epoch 8, Batch 500] loss: 0.021524322848708834
[Epoch 8, Batch 600] loss: 0.018871258088038304
[Epoch 8, Batch 700] loss: 0.02653421589770005
[Epoch 8, Batch 800] loss: 0.027123136313894066
[Epoch 8, Batch 900] loss: 0.026457151526992673
[Epoch 8, Batch 1000] loss: 0.023117493474273942
[Epoch 8, Batch 1100] loss: 0.02770943646231899
[Epoch 8, Batch 1200] loss: 0.016309683056751966
[Epoch 8, Batch 1300] loss: 0.023004101808037376
[Epoch 8, Batch 1400] loss: 0.018533430974493968
[Epoch 8, Batch 1500] loss: 0.023414856287272415
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0423
Validation Accuracy: 0.9878
Overfitting: 0.0423
Best model saved at epoch 8 with validation loss: 0.0423
[Epoch 9, Batch 100] loss: 0.018829940031573643
[Epoch 9, Batch 200] loss: 0.014203718374847085
[Epoch 9, Batch 300] loss: 0.018053461078598048
[Epoch 9, Batch 400] loss: 0.019960045538609847
[Epoch 9, Batch 500] loss: 0.028434654474913258
[Epoch 9, Batch 600] loss: 0.02598872668808326
[Epoch 9, Batch 700] loss: 0.029233839632506715
[Epoch 9, Batch 800] loss: 0.022703671544295503
[Epoch 9, Batch 900] loss: 0.02714976513001602
[Epoch 9, Batch 1000] loss: 0.019140037634206238
[Epoch 9, Batch 1100] loss: 0.0185864969206159
[Epoch 9, Batch 1200] loss: 0.019528804399888033
[Epoch 9, Batch 1300] loss: 0.02263842717889929
[Epoch 9, Batch 1400] loss: 0.0185783171201183
[Epoch 9, Batch 1500] loss: 0.020078259988222272
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9863
Overfitting: 0.0475
[Epoch 10, Batch 100] loss: 0.01098553750111023
[Epoch 10, Batch 200] loss: 0.011895699895831058
[Epoch 10, Batch 300] loss: 0.015429196597724513
[Epoch 10, Batch 400] loss: 0.017116977758560095
[Epoch 10, Batch 500] loss: 0.023056530685935286
[Epoch 10, Batch 600] loss: 0.015109533095092047
[Epoch 10, Batch 700] loss: 0.017974876609951024
[Epoch 10, Batch 800] loss: 0.02088988560535654
[Epoch 10, Batch 900] loss: 0.01831523916160222
[Epoch 10, Batch 1000] loss: 0.013465130128679448
[Epoch 10, Batch 1100] loss: 0.01741302902715688
[Epoch 10, Batch 1200] loss: 0.02003555873867299
[Epoch 10, Batch 1300] loss: 0.019210809532523854
[Epoch 10, Batch 1400] loss: 0.01919808225778979
[Epoch 10, Batch 1500] loss: 0.016996145486991736
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9879
Overfitting: 0.0430
[Epoch 11, Batch 100] loss: 0.013383391144816414
[Epoch 11, Batch 200] loss: 0.014938649274990895
[Epoch 11, Batch 300] loss: 0.012072705838800175
[Epoch 11, Batch 400] loss: 0.013375699638108926
[Epoch 11, Batch 500] loss: 0.011879964132895111
[Epoch 11, Batch 600] loss: 0.01648610920397914
[Epoch 11, Batch 700] loss: 0.017388180146699597
[Epoch 11, Batch 800] loss: 0.010889828014478553
[Epoch 11, Batch 900] loss: 0.02543733879374486
[Epoch 11, Batch 1000] loss: 0.011480327963545279
[Epoch 11, Batch 1100] loss: 0.016726804756108323
[Epoch 11, Batch 1200] loss: 0.015395828476321184
[Epoch 11, Batch 1300] loss: 0.01662822217784196
[Epoch 11, Batch 1400] loss: 0.013048724823529484
[Epoch 11, Batch 1500] loss: 0.02224564157095301
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9857
Overfitting: 0.0501
[Epoch 12, Batch 100] loss: 0.013594985020317836
[Epoch 12, Batch 200] loss: 0.011623341155864182
[Epoch 12, Batch 300] loss: 0.019130247736520688
[Epoch 12, Batch 400] loss: 0.009947015727047983
[Epoch 12, Batch 500] loss: 0.009894239704935899
[Epoch 12, Batch 600] loss: 0.01061419939784173
[Epoch 12, Batch 700] loss: 0.02090556764320354
[Epoch 12, Batch 800] loss: 0.01913435443160779
[Epoch 12, Batch 900] loss: 0.015259766965100426
[Epoch 12, Batch 1000] loss: 0.010568927109998185
[Epoch 12, Batch 1100] loss: 0.007323437219674815
[Epoch 12, Batch 1200] loss: 0.016981602810155892
[Epoch 12, Batch 1300] loss: 0.017104386075043294
[Epoch 12, Batch 1400] loss: 0.009807851647710777
[Epoch 12, Batch 1500] loss: 0.015642270190401177
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9872
Overfitting: 0.0474
[Epoch 13, Batch 100] loss: 0.006584625768264232
[Epoch 13, Batch 200] loss: 0.012620142341475002
[Epoch 13, Batch 300] loss: 0.009750487650853757
[Epoch 13, Batch 400] loss: 0.006725075724225462
[Epoch 13, Batch 500] loss: 0.015021198690665188
[Epoch 13, Batch 600] loss: 0.009029128257643605
[Epoch 13, Batch 700] loss: 0.015076535136113307
[Epoch 13, Batch 800] loss: 0.005545502917375416
[Epoch 13, Batch 900] loss: 0.01409180978902441
[Epoch 13, Batch 1000] loss: 0.012728478010030813
[Epoch 13, Batch 1100] loss: 0.006943580174356612
[Epoch 13, Batch 1200] loss: 0.011130563348679061
[Epoch 13, Batch 1300] loss: 0.011487230995844583
[Epoch 13, Batch 1400] loss: 0.011384023712453199
[Epoch 13, Batch 1500] loss: 0.011575815652049641
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9882
Overfitting: 0.0441
[Epoch 14, Batch 100] loss: 0.00940835728082675
[Epoch 14, Batch 200] loss: 0.010587158151975019
[Epoch 14, Batch 300] loss: 0.012112458493829763
[Epoch 14, Batch 400] loss: 0.009842337392951777
[Epoch 14, Batch 500] loss: 0.009874886328034335
[Epoch 14, Batch 600] loss: 0.00950784841010318
[Epoch 14, Batch 700] loss: 0.012110618394517587
[Epoch 14, Batch 800] loss: 0.006648478587676436
[Epoch 14, Batch 900] loss: 0.008775581381050869
[Epoch 14, Batch 1000] loss: 0.0137453198460571
[Epoch 14, Batch 1100] loss: 0.012778594814735698
[Epoch 14, Batch 1200] loss: 0.009495429464714107
[Epoch 14, Batch 1300] loss: 0.011114192144668777
[Epoch 14, Batch 1400] loss: 0.007957729415429639
[Epoch 14, Batch 1500] loss: 0.005740457085394155
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0428
Validation Accuracy: 0.9882
Overfitting: 0.0428
[Epoch 15, Batch 100] loss: 0.01466254610917531
[Epoch 15, Batch 200] loss: 0.011306724888336249
[Epoch 15, Batch 300] loss: 0.005005338449864212
[Epoch 15, Batch 400] loss: 0.010165243933161037
[Epoch 15, Batch 500] loss: 0.012560903429894098
[Epoch 15, Batch 600] loss: 0.00785734556029638
[Epoch 15, Batch 700] loss: 0.0083430408008644
[Epoch 15, Batch 800] loss: 0.007387225641268742
[Epoch 15, Batch 900] loss: 0.008231293868075227
[Epoch 15, Batch 1000] loss: 0.009460732055977132
[Epoch 15, Batch 1100] loss: 0.010719258593098857
[Epoch 15, Batch 1200] loss: 0.010135880067864492
[Epoch 15, Batch 1300] loss: 0.00904701562678838
[Epoch 15, Batch 1400] loss: 0.018638248455627036
[Epoch 15, Batch 1500] loss: 0.0054488598127136354
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9869
Overfitting: 0.0520
[Epoch 16, Batch 100] loss: 0.004275157530832985
[Epoch 16, Batch 200] loss: 0.004994348622640246
[Epoch 16, Batch 300] loss: 0.008623253762561945
[Epoch 16, Batch 400] loss: 0.004354142327676982
[Epoch 16, Batch 500] loss: 0.012068666966515594
[Epoch 16, Batch 600] loss: 0.009851040139774342
[Epoch 16, Batch 700] loss: 0.012228319026207827
[Epoch 16, Batch 800] loss: 0.007632266403029462
[Epoch 16, Batch 900] loss: 0.006458176422383986
[Epoch 16, Batch 1000] loss: 0.010378381090358744
[Epoch 16, Batch 1100] loss: 0.008631437358617404
[Epoch 16, Batch 1200] loss: 0.011718725231339704
[Epoch 16, Batch 1300] loss: 0.008941759924691723
[Epoch 16, Batch 1400] loss: 0.00793666148554621
[Epoch 16, Batch 1500] loss: 0.008562145394425897
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9887
Overfitting: 0.0447
[Epoch 17, Batch 100] loss: 0.007695971066168567
[Epoch 17, Batch 200] loss: 0.007146683483733795
[Epoch 17, Batch 300] loss: 0.0015173117449239727
[Epoch 17, Batch 400] loss: 0.0038566228757861156
[Epoch 17, Batch 500] loss: 0.002714865934071895
[Epoch 17, Batch 600] loss: 0.008519084890003796
[Epoch 17, Batch 700] loss: 0.008403067090284821
[Epoch 17, Batch 800] loss: 0.006729380102879077
[Epoch 17, Batch 900] loss: 0.00649973851465802
[Epoch 17, Batch 1000] loss: 0.004701386657909552
[Epoch 17, Batch 1100] loss: 0.0048717994463390825
[Epoch 17, Batch 1200] loss: 0.008776765037518999
[Epoch 17, Batch 1300] loss: 0.006520494383548794
[Epoch 17, Batch 1400] loss: 0.0075392565431502585
[Epoch 17, Batch 1500] loss: 0.007374293981361007
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9893
Overfitting: 0.0463
[Epoch 18, Batch 100] loss: 0.004668470538108522
[Epoch 18, Batch 200] loss: 0.009078627273220263
[Epoch 18, Batch 300] loss: 0.006834402310660153
[Epoch 18, Batch 400] loss: 0.0036057690675283995
[Epoch 18, Batch 500] loss: 0.007663629747398772
[Epoch 18, Batch 600] loss: 0.0038224084558260074
[Epoch 18, Batch 700] loss: 0.006473100511620942
[Epoch 18, Batch 800] loss: 0.004270243593682607
[Epoch 18, Batch 900] loss: 0.007793431220766252
[Epoch 18, Batch 1000] loss: 0.007943998044306682
[Epoch 18, Batch 1100] loss: 0.003676290720623001
[Epoch 18, Batch 1200] loss: 0.009167951927183822
[Epoch 18, Batch 1300] loss: 0.003669143403299131
[Epoch 18, Batch 1400] loss: 0.004254812365718408
[Epoch 18, Batch 1500] loss: 0.005469887673934863
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9898
Overfitting: 0.0441
[Epoch 19, Batch 100] loss: 0.0027425691804580767
[Epoch 19, Batch 200] loss: 0.0012947672563439028
[Epoch 19, Batch 300] loss: 0.004054510512377192
[Epoch 19, Batch 400] loss: 0.00974062371213222
[Epoch 19, Batch 500] loss: 0.0030178560160629784
[Epoch 19, Batch 600] loss: 0.00314193108356676
[Epoch 19, Batch 700] loss: 0.004842756717721386
[Epoch 19, Batch 800] loss: 0.0038496547111890322
[Epoch 19, Batch 900] loss: 0.0030713315343928117
[Epoch 19, Batch 1000] loss: 0.004078733960211594
[Epoch 19, Batch 1100] loss: 0.006593387682244156
[Epoch 19, Batch 1200] loss: 0.007167527628284915
[Epoch 19, Batch 1300] loss: 0.004276548585953606
[Epoch 19, Batch 1400] loss: 0.0037854964185567042
[Epoch 19, Batch 1500] loss: 0.004495355205378928
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9890
Overfitting: 0.0467
[Epoch 20, Batch 100] loss: 0.0034427489768114584
[Epoch 20, Batch 200] loss: 0.0021795731476913715
[Epoch 20, Batch 300] loss: 0.002627800058039611
[Epoch 20, Batch 400] loss: 0.002734260593445015
[Epoch 20, Batch 500] loss: 0.004081208168909711
[Epoch 20, Batch 600] loss: 0.00398250623414242
[Epoch 20, Batch 700] loss: 0.0036456505833939445
[Epoch 20, Batch 800] loss: 0.002788332052500948
[Epoch 20, Batch 900] loss: 0.0055285100944774965
[Epoch 20, Batch 1000] loss: 0.0023534677098723477
[Epoch 20, Batch 1100] loss: 0.0033075695180195906
[Epoch 20, Batch 1200] loss: 0.0023599001934258013
[Epoch 20, Batch 1300] loss: 0.0041051703221188516
[Epoch 20, Batch 1400] loss: 0.004893500062860312
[Epoch 20, Batch 1500] loss: 0.002887279136007237
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9890
Overfitting: 0.0480
[Epoch 21, Batch 100] loss: 0.0009416099916302301
[Epoch 21, Batch 200] loss: 0.0018733351786340792
[Epoch 21, Batch 300] loss: 0.0008217209224144995
[Epoch 21, Batch 400] loss: 0.0015570325587705724
[Epoch 21, Batch 500] loss: 0.002758970050415428
[Epoch 21, Batch 600] loss: 0.0030210465211462176
[Epoch 21, Batch 700] loss: 0.0009304891050845754
[Epoch 21, Batch 800] loss: 0.0023260705677114403
[Epoch 21, Batch 900] loss: 0.0037247152331633514
[Epoch 21, Batch 1000] loss: 0.003462696049420515
[Epoch 21, Batch 1100] loss: 0.003225274687167712
[Epoch 21, Batch 1200] loss: 0.00241920419737653
[Epoch 21, Batch 1300] loss: 0.0008042098591045033
[Epoch 21, Batch 1400] loss: 0.0023854920533506172
[Epoch 21, Batch 1500] loss: 0.003688216843787586
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9898
Overfitting: 0.0479
[Epoch 22, Batch 100] loss: 0.0034164585164319305
[Epoch 22, Batch 200] loss: 0.002022835366550453
[Epoch 22, Batch 300] loss: 0.0014542124796435019
[Epoch 22, Batch 400] loss: 0.004077754426466811
[Epoch 22, Batch 500] loss: 0.0016433121017143293
[Epoch 22, Batch 600] loss: 0.002524108903227216
[Epoch 22, Batch 700] loss: 0.001975103495884696
[Epoch 22, Batch 800] loss: 0.0015771457276345302
[Epoch 22, Batch 900] loss: 0.001570908891927445
[Epoch 22, Batch 1000] loss: 0.001723663803838349
[Epoch 22, Batch 1100] loss: 0.0013129860304269415
[Epoch 22, Batch 1200] loss: 0.002411383211166367
[Epoch 22, Batch 1300] loss: 0.0032952075994768393
[Epoch 22, Batch 1400] loss: 0.002418534983924019
[Epoch 22, Batch 1500] loss: 0.003769725672500499
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9892
Overfitting: 0.0501
[Epoch 23, Batch 100] loss: 0.0011008192029390784
[Epoch 23, Batch 200] loss: 0.001145819983425298
[Epoch 23, Batch 300] loss: 0.0006720713879445839
[Epoch 23, Batch 400] loss: 0.0022984189623298334
[Epoch 23, Batch 500] loss: 0.0019814345426743783
[Epoch 23, Batch 600] loss: 0.0006131042386908803
[Epoch 23, Batch 700] loss: 0.003837189479643257
[Epoch 23, Batch 800] loss: 0.003779982928975869
[Epoch 23, Batch 900] loss: 0.0018706035184118265
[Epoch 23, Batch 1000] loss: 0.0017016576999972699
[Epoch 23, Batch 1100] loss: 0.001390492518901283
[Epoch 23, Batch 1200] loss: 0.003703499683965816
[Epoch 23, Batch 1300] loss: 0.0029649896780560426
[Epoch 23, Batch 1400] loss: 0.006774056087168106
[Epoch 23, Batch 1500] loss: 0.004803786579800544
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9897
Overfitting: 0.0502
[Epoch 24, Batch 100] loss: 0.001761568092174457
[Epoch 24, Batch 200] loss: 0.009508333387067296
[Epoch 24, Batch 300] loss: 0.002424646447734631
[Epoch 24, Batch 400] loss: 0.003144169025296719
[Epoch 24, Batch 500] loss: 0.002425380574583187
[Epoch 24, Batch 600] loss: 0.0027690369876916063
[Epoch 24, Batch 700] loss: 0.0031266565122604105
[Epoch 24, Batch 800] loss: 0.002773728700271363
[Epoch 24, Batch 900] loss: 0.002342456979184533
[Epoch 24, Batch 1000] loss: 0.0010209325579739925
[Epoch 24, Batch 1100] loss: 0.0026948957298486677
[Epoch 24, Batch 1200] loss: 0.003431573253626823
[Epoch 24, Batch 1300] loss: 0.0022813644211339577
[Epoch 24, Batch 1400] loss: 0.0010340700388098867
[Epoch 24, Batch 1500] loss: 0.0006607828896130741
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9888
Overfitting: 0.0491
Fold 5 validation loss: 0.0491
Mean validation loss across all folds for Trial 8 is 0.0557 with trial config:  l1: 128, l2: 128, lr: 0.002592475660475161, batch_size: 32
[I 2024-12-10 07:59:10,284] Trial 7 finished with value: 0.05569988523067557 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.002592475660475161, 'batch_size': 32}. Best is trial 4 with value: 0.045411968038914834.

Selected Hyperparameters for Trial 9:
  l1: 256, l2: 128, lr: 0.00011348084525743877, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3054652571678163
[Epoch 1, Batch 200] loss: 2.2942503690719604
[Epoch 1, Batch 300] loss: 2.2858886551856994
[Epoch 1, Batch 400] loss: 2.2791864705085754
[Epoch 1, Batch 500] loss: 2.2799284052848816
[Epoch 1, Batch 600] loss: 2.2722969484329223
[Epoch 1, Batch 700] loss: 2.2620425248146057
[Epoch 1, Batch 800] loss: 2.2506276822090148
[Epoch 1, Batch 900] loss: 2.238378434181213
[Epoch 1, Batch 1000] loss: 2.223725335597992
[Epoch 1, Batch 1100] loss: 2.209980764389038
[Epoch 1, Batch 1200] loss: 2.194726572036743
[Epoch 1, Batch 1300] loss: 2.1635754466056825
[Epoch 1, Batch 1400] loss: 2.1328569078445434
[Epoch 1, Batch 1500] loss: 2.083513720035553
[Epoch 1, Batch 1600] loss: 2.0378753972053527
[Epoch 1, Batch 1700] loss: 1.9462313783168792
[Epoch 1, Batch 1800] loss: 1.8471646308898926
[Epoch 1, Batch 1900] loss: 1.693242757320404
[Epoch 1, Batch 2000] loss: 1.5286043000221252
[Epoch 1, Batch 2100] loss: 1.3090279000997542
[Epoch 1, Batch 2200] loss: 1.178754185438156
[Epoch 1, Batch 2300] loss: 0.9986516058444976
[Epoch 1, Batch 2400] loss: 0.9079162019491196
[Epoch 1, Batch 2500] loss: 0.7957728672027587
[Epoch 1, Batch 2600] loss: 0.7313912171125412
[Epoch 1, Batch 2700] loss: 0.6959182493388653
[Epoch 1, Batch 2800] loss: 0.6436124256253243
[Epoch 1, Batch 2900] loss: 0.5899645230174064
[Epoch 1, Batch 3000] loss: 0.5821658425033093
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.5659
Validation Accuracy: 0.8337
Overfitting: 0.5659
Best model saved at epoch 1 with validation loss: 0.5659
[Epoch 2, Batch 100] loss: 0.5326719665527344
[Epoch 2, Batch 200] loss: 0.5386473865807057
[Epoch 2, Batch 300] loss: 0.5412441238760948
[Epoch 2, Batch 400] loss: 0.46375322647392747
[Epoch 2, Batch 500] loss: 0.5175628417730331
[Epoch 2, Batch 600] loss: 0.5208243081718683
[Epoch 2, Batch 700] loss: 0.4354155343025923
[Epoch 2, Batch 800] loss: 0.430500473678112
[Epoch 2, Batch 900] loss: 0.48611707575619223
[Epoch 2, Batch 1000] loss: 0.42930126838386057
[Epoch 2, Batch 1100] loss: 0.4197227843850851
[Epoch 2, Batch 1200] loss: 0.43572574004530906
[Epoch 2, Batch 1300] loss: 0.44292945552617313
[Epoch 2, Batch 1400] loss: 0.4133188312500715
[Epoch 2, Batch 1500] loss: 0.376066691800952
[Epoch 2, Batch 1600] loss: 0.38201385229825974
[Epoch 2, Batch 1700] loss: 0.41173826839774846
[Epoch 2, Batch 1800] loss: 0.39018380977213385
[Epoch 2, Batch 1900] loss: 0.39955392099916937
[Epoch 2, Batch 2000] loss: 0.352129481639713
[Epoch 2, Batch 2100] loss: 0.36005967896431684
[Epoch 2, Batch 2200] loss: 0.3608342608809471
[Epoch 2, Batch 2300] loss: 0.3422376956790686
[Epoch 2, Batch 2400] loss: 0.39087745115160943
[Epoch 2, Batch 2500] loss: 0.3737586510926485
[Epoch 2, Batch 2600] loss: 0.3687202645093203
[Epoch 2, Batch 2700] loss: 0.33533317416906355
[Epoch 2, Batch 2800] loss: 0.32374203350394964
[Epoch 2, Batch 2900] loss: 0.3014199388772249
[Epoch 2, Batch 3000] loss: 0.31683622479438783
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.3062
Validation Accuracy: 0.9065
Overfitting: 0.3062
Best model saved at epoch 2 with validation loss: 0.3062
[Epoch 3, Batch 100] loss: 0.2947097262367606
[Epoch 3, Batch 200] loss: 0.30474990759044884
[Epoch 3, Batch 300] loss: 0.2803148153424263
[Epoch 3, Batch 400] loss: 0.3087828428670764
[Epoch 3, Batch 500] loss: 0.3002666609734297
[Epoch 3, Batch 600] loss: 0.3100557566806674
[Epoch 3, Batch 700] loss: 0.2684204989299178
[Epoch 3, Batch 800] loss: 0.3053697608411312
[Epoch 3, Batch 900] loss: 0.2951421480067074
[Epoch 3, Batch 1000] loss: 0.29151939233765006
[Epoch 3, Batch 1100] loss: 0.3000532093271613
[Epoch 3, Batch 1200] loss: 0.26722085248678923
[Epoch 3, Batch 1300] loss: 0.2577249345183372
[Epoch 3, Batch 1400] loss: 0.24982236184179782
[Epoch 3, Batch 1500] loss: 0.28876832470297814
[Epoch 3, Batch 1600] loss: 0.29194968357682227
[Epoch 3, Batch 1700] loss: 0.28070139441639186
[Epoch 3, Batch 1800] loss: 0.27570847697556017
[Epoch 3, Batch 1900] loss: 0.2568078526481986
[Epoch 3, Batch 2000] loss: 0.2714216544851661
[Epoch 3, Batch 2100] loss: 0.2797046753391623
[Epoch 3, Batch 2200] loss: 0.2865525480359793
[Epoch 3, Batch 2300] loss: 0.24559076726436616
[Epoch 3, Batch 2400] loss: 0.24325768971815706
[Epoch 3, Batch 2500] loss: 0.24763468977063893
[Epoch 3, Batch 2600] loss: 0.2629109412431717
[Epoch 3, Batch 2700] loss: 0.24876373015344144
[Epoch 3, Batch 2800] loss: 0.23126227978616953
[Epoch 3, Batch 2900] loss: 0.1978961036913097
[Epoch 3, Batch 3000] loss: 0.23736513681709767
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.2142
Validation Accuracy: 0.9371
Overfitting: 0.2142
Best model saved at epoch 3 with validation loss: 0.2142
[Epoch 4, Batch 100] loss: 0.21709425871260465
[Epoch 4, Batch 200] loss: 0.2125084444601089
[Epoch 4, Batch 300] loss: 0.2586161083355546
[Epoch 4, Batch 400] loss: 0.23792378000915052
[Epoch 4, Batch 500] loss: 0.2286493593081832
[Epoch 4, Batch 600] loss: 0.26488266039639713
[Epoch 4, Batch 700] loss: 0.2024812581948936
[Epoch 4, Batch 800] loss: 0.22416257685050367
[Epoch 4, Batch 900] loss: 0.21268332751467825
[Epoch 4, Batch 1000] loss: 0.2145127882901579
[Epoch 4, Batch 1100] loss: 0.2402958855032921
[Epoch 4, Batch 1200] loss: 0.21046894771978258
[Epoch 4, Batch 1300] loss: 0.2308302529901266
[Epoch 4, Batch 1400] loss: 0.2140842314250767
[Epoch 4, Batch 1500] loss: 0.22818579502403735
[Epoch 4, Batch 1600] loss: 0.17733691386878492
[Epoch 4, Batch 1700] loss: 0.20651370324194432
[Epoch 4, Batch 1800] loss: 0.19449701563455166
[Epoch 4, Batch 1900] loss: 0.2200901040341705
[Epoch 4, Batch 2000] loss: 0.18542595222592353
[Epoch 4, Batch 2100] loss: 0.18623630361631513
[Epoch 4, Batch 2200] loss: 0.21441146397963165
[Epoch 4, Batch 2300] loss: 0.18083305089734494
[Epoch 4, Batch 2400] loss: 0.19201473596505822
[Epoch 4, Batch 2500] loss: 0.19544283627532422
[Epoch 4, Batch 2600] loss: 0.17334736997261643
[Epoch 4, Batch 2700] loss: 0.181719591319561
[Epoch 4, Batch 2800] loss: 0.20934856563806534
[Epoch 4, Batch 2900] loss: 0.20332118372432886
[Epoch 4, Batch 3000] loss: 0.21687074700370432
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1725
Validation Accuracy: 0.9497
Overfitting: 0.1725
Best model saved at epoch 4 with validation loss: 0.1725
[Epoch 5, Batch 100] loss: 0.16201115872710944
[Epoch 5, Batch 200] loss: 0.19408967059105633
[Epoch 5, Batch 300] loss: 0.2046656714566052
[Epoch 5, Batch 400] loss: 0.17374777445569634
[Epoch 5, Batch 500] loss: 0.1978643649863079
[Epoch 5, Batch 600] loss: 0.18541995160281657
[Epoch 5, Batch 700] loss: 0.1868095610011369
[Epoch 5, Batch 800] loss: 0.17670391282066703
[Epoch 5, Batch 900] loss: 0.16762987162917853
[Epoch 5, Batch 1000] loss: 0.1692402968276292
[Epoch 5, Batch 1100] loss: 0.16530883557163178
[Epoch 5, Batch 1200] loss: 0.19138719546608626
[Epoch 5, Batch 1300] loss: 0.19937338854186237
[Epoch 5, Batch 1400] loss: 0.14382098221685738
[Epoch 5, Batch 1500] loss: 0.1824450486060232
[Epoch 5, Batch 1600] loss: 0.15224890514276923
[Epoch 5, Batch 1700] loss: 0.1822948898933828
[Epoch 5, Batch 1800] loss: 0.19323923410847782
[Epoch 5, Batch 1900] loss: 0.16057824936695397
[Epoch 5, Batch 2000] loss: 0.1800692756474018
[Epoch 5, Batch 2100] loss: 0.15030790032818914
[Epoch 5, Batch 2200] loss: 0.15876797880977392
[Epoch 5, Batch 2300] loss: 0.17474011729471386
[Epoch 5, Batch 2400] loss: 0.17608318788930774
[Epoch 5, Batch 2500] loss: 0.1938618591800332
[Epoch 5, Batch 2600] loss: 0.1381292726751417
[Epoch 5, Batch 2700] loss: 0.15308082248084248
[Epoch 5, Batch 2800] loss: 0.1552414606604725
[Epoch 5, Batch 2900] loss: 0.16563117822632192
[Epoch 5, Batch 3000] loss: 0.15186588499695064
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1470
Validation Accuracy: 0.9580
Overfitting: 0.1470
Best model saved at epoch 5 with validation loss: 0.1470
[Epoch 6, Batch 100] loss: 0.15329972283449023
[Epoch 6, Batch 200] loss: 0.17000651477836073
[Epoch 6, Batch 300] loss: 0.14278027546126396
[Epoch 6, Batch 400] loss: 0.17318380422890187
[Epoch 6, Batch 500] loss: 0.15697074313648046
[Epoch 6, Batch 600] loss: 0.1660307924170047
[Epoch 6, Batch 700] loss: 0.13444463550578803
[Epoch 6, Batch 800] loss: 0.13432640362530945
[Epoch 6, Batch 900] loss: 0.14864126653876156
[Epoch 6, Batch 1000] loss: 0.14237252401653677
[Epoch 6, Batch 1100] loss: 0.16264695533551277
[Epoch 6, Batch 1200] loss: 0.14649862789548934
[Epoch 6, Batch 1300] loss: 0.1222054114472121
[Epoch 6, Batch 1400] loss: 0.1309263650048524
[Epoch 6, Batch 1500] loss: 0.14403388632461428
[Epoch 6, Batch 1600] loss: 0.121877779411152
[Epoch 6, Batch 1700] loss: 0.14537109500728548
[Epoch 6, Batch 1800] loss: 0.15727876057382673
[Epoch 6, Batch 1900] loss: 0.13547499706503005
[Epoch 6, Batch 2000] loss: 0.13698453037068248
[Epoch 6, Batch 2100] loss: 0.19700563456863165
[Epoch 6, Batch 2200] loss: 0.15495232868939637
[Epoch 6, Batch 2300] loss: 0.133860550832469
[Epoch 6, Batch 2400] loss: 0.16413440055213868
[Epoch 6, Batch 2500] loss: 0.1606665846891701
[Epoch 6, Batch 2600] loss: 0.16252147851977497
[Epoch 6, Batch 2700] loss: 0.14533366080839186
[Epoch 6, Batch 2800] loss: 0.13041294649243354
[Epoch 6, Batch 2900] loss: 0.13812016899697482
[Epoch 6, Batch 3000] loss: 0.1461927464348264
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.1414
Validation Accuracy: 0.9548
Overfitting: 0.1414
Best model saved at epoch 6 with validation loss: 0.1414
[Epoch 7, Batch 100] loss: 0.18276656724512577
[Epoch 7, Batch 200] loss: 0.11352070706896483
[Epoch 7, Batch 300] loss: 0.14310483870096505
[Epoch 7, Batch 400] loss: 0.10253543852828444
[Epoch 7, Batch 500] loss: 0.11196320776827634
[Epoch 7, Batch 600] loss: 0.12390330208931118
[Epoch 7, Batch 700] loss: 0.14685289622284473
[Epoch 7, Batch 800] loss: 0.116591687342152
[Epoch 7, Batch 900] loss: 0.15141541450750082
[Epoch 7, Batch 1000] loss: 0.12154432525858283
[Epoch 7, Batch 1100] loss: 0.13024916905676945
[Epoch 7, Batch 1200] loss: 0.13091063600964845
[Epoch 7, Batch 1300] loss: 0.15365184910595417
[Epoch 7, Batch 1400] loss: 0.13226811488159002
[Epoch 7, Batch 1500] loss: 0.13830161680933087
[Epoch 7, Batch 1600] loss: 0.14299518215935678
[Epoch 7, Batch 1700] loss: 0.11240315484581515
[Epoch 7, Batch 1800] loss: 0.10410763654392213
[Epoch 7, Batch 1900] loss: 0.13986636825138704
[Epoch 7, Batch 2000] loss: 0.12777617880608885
[Epoch 7, Batch 2100] loss: 0.12085780663415789
[Epoch 7, Batch 2200] loss: 0.13515414658002556
[Epoch 7, Batch 2300] loss: 0.13649903903249652
[Epoch 7, Batch 2400] loss: 0.1500470305327326
[Epoch 7, Batch 2500] loss: 0.10931958891451359
[Epoch 7, Batch 2600] loss: 0.11551031505689024
[Epoch 7, Batch 2700] loss: 0.12143673231592401
[Epoch 7, Batch 2800] loss: 0.11988520588725805
[Epoch 7, Batch 2900] loss: 0.11026121256873012
[Epoch 7, Batch 3000] loss: 0.13978957696352154
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.1141
Validation Accuracy: 0.9651
Overfitting: 0.1141
Best model saved at epoch 7 with validation loss: 0.1141
[Epoch 8, Batch 100] loss: 0.11660864369710908
[Epoch 8, Batch 200] loss: 0.11595277084968984
[Epoch 8, Batch 300] loss: 0.13299139736685903
[Epoch 8, Batch 400] loss: 0.11240534509066492
[Epoch 8, Batch 500] loss: 0.11413170450832695
[Epoch 8, Batch 600] loss: 0.11402980074519292
[Epoch 8, Batch 700] loss: 0.11193063124548644
[Epoch 8, Batch 800] loss: 0.09842699520057067
[Epoch 8, Batch 900] loss: 0.08975093194749206
[Epoch 8, Batch 1000] loss: 0.11994244532426819
[Epoch 8, Batch 1100] loss: 0.12396244941861369
[Epoch 8, Batch 1200] loss: 0.10853998948354274
[Epoch 8, Batch 1300] loss: 0.10107330392464065
[Epoch 8, Batch 1400] loss: 0.13655193022917955
[Epoch 8, Batch 1500] loss: 0.11850653865374625
[Epoch 8, Batch 1600] loss: 0.11565157561097295
[Epoch 8, Batch 1700] loss: 0.13008553222985939
[Epoch 8, Batch 1800] loss: 0.12945109917316586
[Epoch 8, Batch 1900] loss: 0.12335947611136362
[Epoch 8, Batch 2000] loss: 0.10049860514234751
[Epoch 8, Batch 2100] loss: 0.10453717694152147
[Epoch 8, Batch 2200] loss: 0.12838898627553136
[Epoch 8, Batch 2300] loss: 0.12988092258106917
[Epoch 8, Batch 2400] loss: 0.10481058725621552
[Epoch 8, Batch 2500] loss: 0.12420247704838402
[Epoch 8, Batch 2600] loss: 0.12883809851948172
[Epoch 8, Batch 2700] loss: 0.10319717011880129
[Epoch 8, Batch 2800] loss: 0.13242474145721644
[Epoch 8, Batch 2900] loss: 0.10341363292187453
[Epoch 8, Batch 3000] loss: 0.11685104716569185
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.1101
Validation Accuracy: 0.9663
Overfitting: 0.1101
Best model saved at epoch 8 with validation loss: 0.1101
[Epoch 9, Batch 100] loss: 0.10634405247168616
[Epoch 9, Batch 200] loss: 0.09970180736854672
[Epoch 9, Batch 300] loss: 0.10575544799212366
[Epoch 9, Batch 400] loss: 0.08938645239919424
[Epoch 9, Batch 500] loss: 0.10116719468729571
[Epoch 9, Batch 600] loss: 0.10189705518074334
[Epoch 9, Batch 700] loss: 0.1090590176708065
[Epoch 9, Batch 800] loss: 0.10992426412180066
[Epoch 9, Batch 900] loss: 0.09847174520371482
[Epoch 9, Batch 1000] loss: 0.1132121062465012
[Epoch 9, Batch 1100] loss: 0.09298315519932658
[Epoch 9, Batch 1200] loss: 0.10879598070867359
[Epoch 9, Batch 1300] loss: 0.10845687948632986
[Epoch 9, Batch 1400] loss: 0.12594498256221415
[Epoch 9, Batch 1500] loss: 0.10093707688618452
[Epoch 9, Batch 1600] loss: 0.12023188644321635
[Epoch 9, Batch 1700] loss: 0.12160698894876987
[Epoch 9, Batch 1800] loss: 0.09915837418986484
[Epoch 9, Batch 1900] loss: 0.10219299161341042
[Epoch 9, Batch 2000] loss: 0.09072699219919741
[Epoch 9, Batch 2100] loss: 0.09119092682842166
[Epoch 9, Batch 2200] loss: 0.10923531161155552
[Epoch 9, Batch 2300] loss: 0.09330048604402691
[Epoch 9, Batch 2400] loss: 0.10870016562286765
[Epoch 9, Batch 2500] loss: 0.11050147524802015
[Epoch 9, Batch 2600] loss: 0.08236652449006215
[Epoch 9, Batch 2700] loss: 0.12468137137126177
[Epoch 9, Batch 2800] loss: 0.1127047450444661
[Epoch 9, Batch 2900] loss: 0.100915921125561
[Epoch 9, Batch 3000] loss: 0.10176887300796807
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0945
Validation Accuracy: 0.9709
Overfitting: 0.0945
[I 2024-12-10 08:01:32,623] Trial 8 pruned. 

Selected Hyperparameters for Trial 10:
  l1: 256, l2: 128, lr: 0.0004953077521155641, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.301385636329651
[Epoch 1, Batch 200] loss: 2.290565781593323
[Epoch 1, Batch 300] loss: 2.2805478882789614
**STATS for Epoch 1** : 
Average training loss: 0.4530
Average validation loss: 2.2573
Validation Accuracy: 0.2549
Overfitting: 1.8043
Best model saved at epoch 1 with validation loss: 2.2573
[Epoch 2, Batch 100] loss: 2.2404734921455383
[Epoch 2, Batch 200] loss: 2.177440416812897
[Epoch 2, Batch 300] loss: 1.9956846797466279
**STATS for Epoch 2** : 
Average training loss: 0.3115
Average validation loss: 1.2639
Validation Accuracy: 0.7281
Overfitting: 0.9524
Best model saved at epoch 2 with validation loss: 1.2639
[Epoch 3, Batch 100] loss: 0.9469808572530747
[Epoch 3, Batch 200] loss: 0.6278676402568817
[Epoch 3, Batch 300] loss: 0.5038588133454323
**STATS for Epoch 3** : 
Average training loss: 0.0930
Average validation loss: 0.4245
Validation Accuracy: 0.8745
Overfitting: 0.3314
Best model saved at epoch 3 with validation loss: 0.4245
[Epoch 4, Batch 100] loss: 0.4177761015295982
[Epoch 4, Batch 200] loss: 0.3800426092743874
[Epoch 4, Batch 300] loss: 0.3577261410653591
**STATS for Epoch 4** : 
Average training loss: 0.0690
Average validation loss: 0.3191
Validation Accuracy: 0.9008
Overfitting: 0.2501
Best model saved at epoch 4 with validation loss: 0.3191
[Epoch 5, Batch 100] loss: 0.3166539552807808
[Epoch 5, Batch 200] loss: 0.30932421416044237
[Epoch 5, Batch 300] loss: 0.3005604340136051
**STATS for Epoch 5** : 
Average training loss: 0.0573
Average validation loss: 0.2563
Validation Accuracy: 0.9241
Overfitting: 0.1989
Best model saved at epoch 5 with validation loss: 0.2563
[Epoch 6, Batch 100] loss: 0.2585312471538782
[Epoch 6, Batch 200] loss: 0.25729947999119757
[Epoch 6, Batch 300] loss: 0.2566514803469181
**STATS for Epoch 6** : 
Average training loss: 0.0515
Average validation loss: 0.2206
Validation Accuracy: 0.9333
Overfitting: 0.1692
Best model saved at epoch 6 with validation loss: 0.2206
[Epoch 7, Batch 100] loss: 0.23614715576171874
[Epoch 7, Batch 200] loss: 0.21589250229299067
[Epoch 7, Batch 300] loss: 0.2227638403326273
**STATS for Epoch 7** : 
Average training loss: 0.0461
Average validation loss: 0.1965
Validation Accuracy: 0.9408
Overfitting: 0.1504
Best model saved at epoch 7 with validation loss: 0.1965
[Epoch 8, Batch 100] loss: 0.20984223417937756
[Epoch 8, Batch 200] loss: 0.19881820000708103
[Epoch 8, Batch 300] loss: 0.20434841379523278
**STATS for Epoch 8** : 
Average training loss: 0.0352
Average validation loss: 0.1715
Validation Accuracy: 0.9499
Overfitting: 0.1363
Best model saved at epoch 8 with validation loss: 0.1715
[Epoch 9, Batch 100] loss: 0.18431991778314114
[Epoch 9, Batch 200] loss: 0.17042148880660535
[Epoch 9, Batch 300] loss: 0.18191939078271388
**STATS for Epoch 9** : 
Average training loss: 0.0361
Average validation loss: 0.1607
Validation Accuracy: 0.9514
Overfitting: 0.1246
[I 2024-12-10 08:03:01,271] Trial 9 pruned. 

Selected Hyperparameters for Trial 11:
  l1: 128, l2: 128, lr: 0.00011895148639558477, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.301752986907959
[Epoch 1, Batch 200] loss: 2.2990848088264464
[Epoch 1, Batch 300] loss: 2.297344274520874
[Epoch 1, Batch 400] loss: 2.2954966473579406
[Epoch 1, Batch 500] loss: 2.2943095898628236
[Epoch 1, Batch 600] loss: 2.2896215677261353
[Epoch 1, Batch 700] loss: 2.2881724405288697
[Epoch 1, Batch 800] loss: 2.283416612148285
[Epoch 1, Batch 900] loss: 2.282129340171814
[Epoch 1, Batch 1000] loss: 2.27668909072876
[Epoch 1, Batch 1100] loss: 2.2726142764091493
[Epoch 1, Batch 1200] loss: 2.2666728949546813
[Epoch 1, Batch 1300] loss: 2.2627628469467163
[Epoch 1, Batch 1400] loss: 2.256585419178009
[Epoch 1, Batch 1500] loss: 2.2459358954429627
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2403
Validation Accuracy: 0.3362
Overfitting: 2.2403
Best model saved at epoch 1 with validation loss: 2.2403
[Epoch 2, Batch 100] loss: 2.2351428723335265
[Epoch 2, Batch 200] loss: 2.2196541595458985
[Epoch 2, Batch 300] loss: 2.1983454203605652
[Epoch 2, Batch 400] loss: 2.175184102058411
[Epoch 2, Batch 500] loss: 2.1443358302116393
[Epoch 2, Batch 600] loss: 2.101444259881973
[Epoch 2, Batch 700] loss: 2.0462292528152464
[Epoch 2, Batch 800] loss: 1.9785380005836486
[Epoch 2, Batch 900] loss: 1.8851424086093902
[Epoch 2, Batch 1000] loss: 1.7685374975204469
[Epoch 2, Batch 1100] loss: 1.6576033449172973
[Epoch 2, Batch 1200] loss: 1.5338897001743317
[Epoch 2, Batch 1300] loss: 1.3806607818603516
[Epoch 2, Batch 1400] loss: 1.2598270714282989
[Epoch 2, Batch 1500] loss: 1.1350674426555634
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.0743
Validation Accuracy: 0.7149
Overfitting: 1.0743
Best model saved at epoch 2 with validation loss: 1.0743
[Epoch 3, Batch 100] loss: 1.0182519686222076
[Epoch 3, Batch 200] loss: 0.9252760440111161
[Epoch 3, Batch 300] loss: 0.8726306116580963
[Epoch 3, Batch 400] loss: 0.8057640689611435
[Epoch 3, Batch 500] loss: 0.7422962725162506
[Epoch 3, Batch 600] loss: 0.7012323695421219
[Epoch 3, Batch 700] loss: 0.6647793215513229
[Epoch 3, Batch 800] loss: 0.6240029221773148
[Epoch 3, Batch 900] loss: 0.6235220265388489
[Epoch 3, Batch 1000] loss: 0.6136419540643692
[Epoch 3, Batch 1100] loss: 0.568108519911766
[Epoch 3, Batch 1200] loss: 0.5609313127398491
[Epoch 3, Batch 1300] loss: 0.5318016117811203
[Epoch 3, Batch 1400] loss: 0.5360884875059128
[Epoch 3, Batch 1500] loss: 0.4991956603527069
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.4757
Validation Accuracy: 0.8577
Overfitting: 0.4757
Best model saved at epoch 3 with validation loss: 0.4757
[Epoch 4, Batch 100] loss: 0.49630662068724635
[Epoch 4, Batch 200] loss: 0.46093884855508804
[Epoch 4, Batch 300] loss: 0.4681686718761921
[Epoch 4, Batch 400] loss: 0.46213929370045664
[Epoch 4, Batch 500] loss: 0.44165788441896436
[Epoch 4, Batch 600] loss: 0.4523449677228928
[Epoch 4, Batch 700] loss: 0.46754513055086133
[Epoch 4, Batch 800] loss: 0.4259543152153492
[Epoch 4, Batch 900] loss: 0.4269302172958851
[Epoch 4, Batch 1000] loss: 0.4256832556426525
[Epoch 4, Batch 1100] loss: 0.42578444965183737
[Epoch 4, Batch 1200] loss: 0.43794316321611404
[Epoch 4, Batch 1300] loss: 0.3879538080096245
[Epoch 4, Batch 1400] loss: 0.38132561489939687
[Epoch 4, Batch 1500] loss: 0.37802399165928363
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3685
Validation Accuracy: 0.8883
Overfitting: 0.3685
Best model saved at epoch 4 with validation loss: 0.3685
[Epoch 5, Batch 100] loss: 0.383984644562006
[Epoch 5, Batch 200] loss: 0.3978749458491802
[Epoch 5, Batch 300] loss: 0.37843824483454225
[Epoch 5, Batch 400] loss: 0.3754728315770626
[Epoch 5, Batch 500] loss: 0.3424228622019291
[Epoch 5, Batch 600] loss: 0.376717227101326
[Epoch 5, Batch 700] loss: 0.3466314723342657
[Epoch 5, Batch 800] loss: 0.3498611640930176
[Epoch 5, Batch 900] loss: 0.34222509287297725
[Epoch 5, Batch 1000] loss: 0.3296476736664772
[Epoch 5, Batch 1100] loss: 0.3492601533234119
[Epoch 5, Batch 1200] loss: 0.35735442593693734
[Epoch 5, Batch 1300] loss: 0.32456820018589494
[Epoch 5, Batch 1400] loss: 0.30220216371119024
[Epoch 5, Batch 1500] loss: 0.3023404375463724
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3027
Validation Accuracy: 0.9079
Overfitting: 0.3027
Best model saved at epoch 5 with validation loss: 0.3027
[Epoch 6, Batch 100] loss: 0.29285064302384856
[Epoch 6, Batch 200] loss: 0.3113866254687309
[Epoch 6, Batch 300] loss: 0.3118061673641205
[Epoch 6, Batch 400] loss: 0.28813973665237425
[Epoch 6, Batch 500] loss: 0.3077458260953426
[Epoch 6, Batch 600] loss: 0.3030850660055876
[Epoch 6, Batch 700] loss: 0.31247259087860585
[Epoch 6, Batch 800] loss: 0.307304555028677
[Epoch 6, Batch 900] loss: 0.30685866236686704
[Epoch 6, Batch 1000] loss: 0.2760152032226324
[Epoch 6, Batch 1100] loss: 0.3256510250270367
[Epoch 6, Batch 1200] loss: 0.28199512891471384
[Epoch 6, Batch 1300] loss: 0.2869023647159338
[Epoch 6, Batch 1400] loss: 0.3005872995406389
[Epoch 6, Batch 1500] loss: 0.28876468405127526
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2775
Validation Accuracy: 0.9108
Overfitting: 0.2775
Best model saved at epoch 6 with validation loss: 0.2775
[Epoch 7, Batch 100] loss: 0.2817789140343666
[Epoch 7, Batch 200] loss: 0.2810046577453613
[Epoch 7, Batch 300] loss: 0.26112582728266714
[Epoch 7, Batch 400] loss: 0.2793949904292822
[Epoch 7, Batch 500] loss: 0.23988627459853887
[Epoch 7, Batch 600] loss: 0.26254049114882944
[Epoch 7, Batch 700] loss: 0.29683286637067796
[Epoch 7, Batch 800] loss: 0.26452070955187085
[Epoch 7, Batch 900] loss: 0.23791845507919787
[Epoch 7, Batch 1000] loss: 0.25631891686469316
[Epoch 7, Batch 1100] loss: 0.25883348848670723
[Epoch 7, Batch 1200] loss: 0.2720257679373026
[Epoch 7, Batch 1300] loss: 0.2650012230873108
[Epoch 7, Batch 1400] loss: 0.23101988609880209
[Epoch 7, Batch 1500] loss: 0.24613533645868302
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2331
Validation Accuracy: 0.9289
Overfitting: 0.2331
Best model saved at epoch 7 with validation loss: 0.2331
[Epoch 8, Batch 100] loss: 0.22890606142580508
[Epoch 8, Batch 200] loss: 0.24357896223664283
[Epoch 8, Batch 300] loss: 0.26829822055995467
[Epoch 8, Batch 400] loss: 0.23472058486193417
[Epoch 8, Batch 500] loss: 0.23354499477893115
[Epoch 8, Batch 600] loss: 0.23657394159585238
[Epoch 8, Batch 700] loss: 0.22000191159546376
[Epoch 8, Batch 800] loss: 0.24333562310785056
[Epoch 8, Batch 900] loss: 0.22828117277473212
[Epoch 8, Batch 1000] loss: 0.22180470902472735
[Epoch 8, Batch 1100] loss: 0.2431640024855733
[Epoch 8, Batch 1200] loss: 0.22732944063842297
[Epoch 8, Batch 1300] loss: 0.21932064220309258
[Epoch 8, Batch 1400] loss: 0.22193512953817846
[Epoch 8, Batch 1500] loss: 0.20049874544143675
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2113
Validation Accuracy: 0.9344
Overfitting: 0.2113
Best model saved at epoch 8 with validation loss: 0.2113
[Epoch 9, Batch 100] loss: 0.20939832175150513
[Epoch 9, Batch 200] loss: 0.22200641058385373
[Epoch 9, Batch 300] loss: 0.197675640322268
[Epoch 9, Batch 400] loss: 0.20860061772167682
[Epoch 9, Batch 500] loss: 0.21737435653805734
[Epoch 9, Batch 600] loss: 0.22334563586860895
[Epoch 9, Batch 700] loss: 0.21909041836857795
[Epoch 9, Batch 800] loss: 0.2199663746356964
[Epoch 9, Batch 900] loss: 0.1777734986692667
[Epoch 9, Batch 1000] loss: 0.20373248681426048
[Epoch 9, Batch 1100] loss: 0.19259422034025192
[Epoch 9, Batch 1200] loss: 0.2196992340683937
[Epoch 9, Batch 1300] loss: 0.19943466121330858
[Epoch 9, Batch 1400] loss: 0.1856122841872275
[Epoch 9, Batch 1500] loss: 0.19363967921584846
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1803
Validation Accuracy: 0.9430
Overfitting: 0.1803
[I 2024-12-10 08:04:52,884] Trial 10 pruned. 

Selected Hyperparameters for Trial 12:
  l1: 128, l2: 128, lr: 0.0004552621487933358, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.299556565284729
[Epoch 1, Batch 200] loss: 2.2890596413612365
[Epoch 1, Batch 300] loss: 2.277169737815857
[Epoch 1, Batch 400] loss: 2.2528131127357485
[Epoch 1, Batch 500] loss: 2.217105813026428
[Epoch 1, Batch 600] loss: 2.1304955661296843
[Epoch 1, Batch 700] loss: 1.9201504135131835
[Epoch 1, Batch 800] loss: 1.388550250530243
[Epoch 1, Batch 900] loss: 0.8531706005334854
[Epoch 1, Batch 1000] loss: 0.6788300044834614
[Epoch 1, Batch 1100] loss: 0.5356326510012149
[Epoch 1, Batch 1200] loss: 0.48014027751982213
[Epoch 1, Batch 1300] loss: 0.4878685078024864
[Epoch 1, Batch 1400] loss: 0.462508210465312
[Epoch 1, Batch 1500] loss: 0.4512180612236261
[Epoch 1, Batch 1600] loss: 0.3894871158152819
[Epoch 1, Batch 1700] loss: 0.37997541174292565
[Epoch 1, Batch 1800] loss: 0.3799075808376074
[Epoch 1, Batch 1900] loss: 0.3049064651876688
[Epoch 1, Batch 2000] loss: 0.298839548677206
[Epoch 1, Batch 2100] loss: 0.2964815555885434
[Epoch 1, Batch 2200] loss: 0.2834463048912585
[Epoch 1, Batch 2300] loss: 0.2514673081226647
[Epoch 1, Batch 2400] loss: 0.23925174966454507
[Epoch 1, Batch 2500] loss: 0.2619170974008739
[Epoch 1, Batch 2600] loss: 0.2639587508328259
[Epoch 1, Batch 2700] loss: 0.26487087566405537
[Epoch 1, Batch 2800] loss: 0.22100150654092432
[Epoch 1, Batch 2900] loss: 0.26059722796082496
[Epoch 1, Batch 3000] loss: 0.21123918865807353
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2094
Validation Accuracy: 0.9362
Overfitting: 0.2094
Best model saved at epoch 1 with validation loss: 0.2094
[Epoch 2, Batch 100] loss: 0.19329914296977221
[Epoch 2, Batch 200] loss: 0.2077077924925834
[Epoch 2, Batch 300] loss: 0.20231132538989186
[Epoch 2, Batch 400] loss: 0.21685516043566166
[Epoch 2, Batch 500] loss: 0.17119250571355224
[Epoch 2, Batch 600] loss: 0.1868553572706878
[Epoch 2, Batch 700] loss: 0.19527066570241003
[Epoch 2, Batch 800] loss: 0.20763241115957498
[Epoch 2, Batch 900] loss: 0.1928408424090594
[Epoch 2, Batch 1000] loss: 0.17269374357536435
[Epoch 2, Batch 1100] loss: 0.19058946749195457
[Epoch 2, Batch 1200] loss: 0.1625587622821331
[Epoch 2, Batch 1300] loss: 0.15007848726585507
[Epoch 2, Batch 1400] loss: 0.17095225995406507
[Epoch 2, Batch 1500] loss: 0.15236837569624184
[Epoch 2, Batch 1600] loss: 0.15321832959540188
[Epoch 2, Batch 1700] loss: 0.14858875771053134
[Epoch 2, Batch 1800] loss: 0.1504260465502739
[Epoch 2, Batch 1900] loss: 0.16114280129317193
[Epoch 2, Batch 2000] loss: 0.14765241445507854
[Epoch 2, Batch 2100] loss: 0.14255054891109467
[Epoch 2, Batch 2200] loss: 0.16290831167949363
[Epoch 2, Batch 2300] loss: 0.11362305589020252
[Epoch 2, Batch 2400] loss: 0.15533541029319167
[Epoch 2, Batch 2500] loss: 0.14293824130669236
[Epoch 2, Batch 2600] loss: 0.144626048929058
[Epoch 2, Batch 2700] loss: 0.12184240702074021
[Epoch 2, Batch 2800] loss: 0.12686392481438816
[Epoch 2, Batch 2900] loss: 0.11241673153359442
[Epoch 2, Batch 3000] loss: 0.1306238878518343
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1319
Validation Accuracy: 0.9597
Overfitting: 0.1319
Best model saved at epoch 2 with validation loss: 0.1319
[Epoch 3, Batch 100] loss: 0.1305878305621445
[Epoch 3, Batch 200] loss: 0.11552422527456656
[Epoch 3, Batch 300] loss: 0.09958086117170752
[Epoch 3, Batch 400] loss: 0.1277514551859349
[Epoch 3, Batch 500] loss: 0.12110460027586668
[Epoch 3, Batch 600] loss: 0.13386608167085798
[Epoch 3, Batch 700] loss: 0.11545343194156885
[Epoch 3, Batch 800] loss: 0.14006089919013903
[Epoch 3, Batch 900] loss: 0.1087934843217954
[Epoch 3, Batch 1000] loss: 0.12272750205360353
[Epoch 3, Batch 1100] loss: 0.10402945185545832
[Epoch 3, Batch 1200] loss: 0.10367937394883484
[Epoch 3, Batch 1300] loss: 0.08199414144037291
[Epoch 3, Batch 1400] loss: 0.12684449271298945
[Epoch 3, Batch 1500] loss: 0.10637717353412882
[Epoch 3, Batch 1600] loss: 0.1107871536910534
[Epoch 3, Batch 1700] loss: 0.10532910046400502
[Epoch 3, Batch 1800] loss: 0.10213707704097033
[Epoch 3, Batch 1900] loss: 0.10599704394349828
[Epoch 3, Batch 2000] loss: 0.10554991306504234
[Epoch 3, Batch 2100] loss: 0.10784788958029821
[Epoch 3, Batch 2200] loss: 0.11944974145852029
[Epoch 3, Batch 2300] loss: 0.10752382002770901
[Epoch 3, Batch 2400] loss: 0.11341746114892885
[Epoch 3, Batch 2500] loss: 0.09218464312609286
[Epoch 3, Batch 2600] loss: 0.11687303598504513
[Epoch 3, Batch 2700] loss: 0.09495326458010822
[Epoch 3, Batch 2800] loss: 0.08703520854469389
[Epoch 3, Batch 2900] loss: 0.1146775502699893
[Epoch 3, Batch 3000] loss: 0.1056340919341892
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0918
Validation Accuracy: 0.9723
Overfitting: 0.0918
Best model saved at epoch 3 with validation loss: 0.0918
[Epoch 4, Batch 100] loss: 0.0870090773026459
[Epoch 4, Batch 200] loss: 0.09204202456399799
[Epoch 4, Batch 300] loss: 0.07878281748387962
[Epoch 4, Batch 400] loss: 0.08078751286724582
[Epoch 4, Batch 500] loss: 0.08293810468167066
[Epoch 4, Batch 600] loss: 0.09201820871443488
[Epoch 4, Batch 700] loss: 0.08741944150300697
[Epoch 4, Batch 800] loss: 0.08846414221217856
[Epoch 4, Batch 900] loss: 0.09234450491960161
[Epoch 4, Batch 1000] loss: 0.08938956785481424
[Epoch 4, Batch 1100] loss: 0.10718564653419889
[Epoch 4, Batch 1200] loss: 0.08259668859303929
[Epoch 4, Batch 1300] loss: 0.08898731202178169
[Epoch 4, Batch 1400] loss: 0.08699077307712287
[Epoch 4, Batch 1500] loss: 0.09334036920685321
[Epoch 4, Batch 1600] loss: 0.07654545451980084
[Epoch 4, Batch 1700] loss: 0.07809933764394372
[Epoch 4, Batch 1800] loss: 0.07722917260951362
[Epoch 4, Batch 1900] loss: 0.07851960636791773
[Epoch 4, Batch 2000] loss: 0.09108861878281459
[Epoch 4, Batch 2100] loss: 0.10278426638047676
[Epoch 4, Batch 2200] loss: 0.09073457134887576
[Epoch 4, Batch 2300] loss: 0.07629405196290463
[Epoch 4, Batch 2400] loss: 0.06796113654156216
[Epoch 4, Batch 2500] loss: 0.09968597762286663
[Epoch 4, Batch 2600] loss: 0.10978488507214934
[Epoch 4, Batch 2700] loss: 0.08131475002272054
[Epoch 4, Batch 2800] loss: 0.09427652718266472
[Epoch 4, Batch 2900] loss: 0.09152334605692886
[Epoch 4, Batch 3000] loss: 0.08288645658059977
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0735
Validation Accuracy: 0.9768
Overfitting: 0.0735
Best model saved at epoch 4 with validation loss: 0.0735
[Epoch 5, Batch 100] loss: 0.06856196632608771
[Epoch 5, Batch 200] loss: 0.055366574005456644
[Epoch 5, Batch 300] loss: 0.05720249686622992
[Epoch 5, Batch 400] loss: 0.07681722720270046
[Epoch 5, Batch 500] loss: 0.0734848343365593
[Epoch 5, Batch 600] loss: 0.0763804768351838
[Epoch 5, Batch 700] loss: 0.07922753441496752
[Epoch 5, Batch 800] loss: 0.05582835978013463
[Epoch 5, Batch 900] loss: 0.06260685981193091
[Epoch 5, Batch 1000] loss: 0.0773961448634509
[Epoch 5, Batch 1100] loss: 0.07580978323589078
[Epoch 5, Batch 1200] loss: 0.0841503136837855
[Epoch 5, Batch 1300] loss: 0.06725054458598606
[Epoch 5, Batch 1400] loss: 0.07233963087550364
[Epoch 5, Batch 1500] loss: 0.07939569316455163
[Epoch 5, Batch 1600] loss: 0.07701475739479065
[Epoch 5, Batch 1700] loss: 0.07902549372054636
[Epoch 5, Batch 1800] loss: 0.07381693237286527
[Epoch 5, Batch 1900] loss: 0.06687180665088817
[Epoch 5, Batch 2000] loss: 0.06826458565425128
[Epoch 5, Batch 2100] loss: 0.0792127718118718
[Epoch 5, Batch 2200] loss: 0.07456333634327166
[Epoch 5, Batch 2300] loss: 0.07085931753390469
[Epoch 5, Batch 2400] loss: 0.06031891314429231
[Epoch 5, Batch 2500] loss: 0.08269197526737117
[Epoch 5, Batch 2600] loss: 0.07366201440629083
[Epoch 5, Batch 2700] loss: 0.0653174038301222
[Epoch 5, Batch 2800] loss: 0.07568241222470533
[Epoch 5, Batch 2900] loss: 0.07599801962205674
[Epoch 5, Batch 3000] loss: 0.07803671510890126
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0700
Validation Accuracy: 0.9776
Overfitting: 0.0700
Best model saved at epoch 5 with validation loss: 0.0700
[Epoch 6, Batch 100] loss: 0.07428900909260847
[Epoch 6, Batch 200] loss: 0.07157090714201331
[Epoch 6, Batch 300] loss: 0.06577855625539086
[Epoch 6, Batch 400] loss: 0.06165417426032946
[Epoch 6, Batch 500] loss: 0.06639475000440143
[Epoch 6, Batch 600] loss: 0.06377382391889114
[Epoch 6, Batch 700] loss: 0.0765913774567889
[Epoch 6, Batch 800] loss: 0.060166989028803075
[Epoch 6, Batch 900] loss: 0.05298900989233516
[Epoch 6, Batch 1000] loss: 0.04307199565693736
[Epoch 6, Batch 1100] loss: 0.05854473503830377
[Epoch 6, Batch 1200] loss: 0.055667072280775755
[Epoch 6, Batch 1300] loss: 0.05764867565245368
[Epoch 6, Batch 1400] loss: 0.06161039797705598
[Epoch 6, Batch 1500] loss: 0.04755505820445251
[Epoch 6, Batch 1600] loss: 0.050377403912134466
[Epoch 6, Batch 1700] loss: 0.04923589694102702
[Epoch 6, Batch 1800] loss: 0.054963072232931155
[Epoch 6, Batch 1900] loss: 0.051129926111898386
[Epoch 6, Batch 2000] loss: 0.06735899717590656
[Epoch 6, Batch 2100] loss: 0.09046990493137855
[Epoch 6, Batch 2200] loss: 0.053660408484283835
[Epoch 6, Batch 2300] loss: 0.09229537895007525
[Epoch 6, Batch 2400] loss: 0.06582591562299057
[Epoch 6, Batch 2500] loss: 0.07341283579124137
[Epoch 6, Batch 2600] loss: 0.05979890648741275
[Epoch 6, Batch 2700] loss: 0.05480527728097513
[Epoch 6, Batch 2800] loss: 0.07266014125256333
[Epoch 6, Batch 2900] loss: 0.05924290017108433
[Epoch 6, Batch 3000] loss: 0.08170004111743764
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0698
Validation Accuracy: 0.9778
Overfitting: 0.0698
Best model saved at epoch 6 with validation loss: 0.0698
[Epoch 7, Batch 100] loss: 0.05437848159926943
[Epoch 7, Batch 200] loss: 0.04962713176268153
[Epoch 7, Batch 300] loss: 0.05419340401072986
[Epoch 7, Batch 400] loss: 0.06461685090616812
[Epoch 7, Batch 500] loss: 0.05600063719728496
[Epoch 7, Batch 600] loss: 0.03902968620648608
[Epoch 7, Batch 700] loss: 0.05598883534723427
[Epoch 7, Batch 800] loss: 0.07115924310928676
[Epoch 7, Batch 900] loss: 0.0456075778597733
[Epoch 7, Batch 1000] loss: 0.04430966929940041
[Epoch 7, Batch 1100] loss: 0.07436852411134169
[Epoch 7, Batch 1200] loss: 0.07468650150694885
[Epoch 7, Batch 1300] loss: 0.06882916022615973
[Epoch 7, Batch 1400] loss: 0.05114980725513305
[Epoch 7, Batch 1500] loss: 0.039728933625738136
[Epoch 7, Batch 1600] loss: 0.052528187925054225
[Epoch 7, Batch 1700] loss: 0.052076434105983935
[Epoch 7, Batch 1800] loss: 0.06124589485407341
[Epoch 7, Batch 1900] loss: 0.05664907849859446
[Epoch 7, Batch 2000] loss: 0.0616168720042333
[Epoch 7, Batch 2100] loss: 0.04407020616112277
[Epoch 7, Batch 2200] loss: 0.0505477138934657
[Epoch 7, Batch 2300] loss: 0.05389933310856577
[Epoch 7, Batch 2400] loss: 0.056347523276344874
[Epoch 7, Batch 2500] loss: 0.04677640267123934
[Epoch 7, Batch 2600] loss: 0.06847952451324091
[Epoch 7, Batch 2700] loss: 0.03896956503856927
[Epoch 7, Batch 2800] loss: 0.04629238105553668
[Epoch 7, Batch 2900] loss: 0.05446006560639944
[Epoch 7, Batch 3000] loss: 0.05668047827668488
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0579
Validation Accuracy: 0.9814
Overfitting: 0.0579
Best model saved at epoch 7 with validation loss: 0.0579
[Epoch 8, Batch 100] loss: 0.047230709815048615
[Epoch 8, Batch 200] loss: 0.047603763678343965
[Epoch 8, Batch 300] loss: 0.046193005906534385
[Epoch 8, Batch 400] loss: 0.04473492753284518
[Epoch 8, Batch 500] loss: 0.04256802042538766
[Epoch 8, Batch 600] loss: 0.0393732044895296
[Epoch 8, Batch 700] loss: 0.05816709137958242
[Epoch 8, Batch 800] loss: 0.04507171119505074
[Epoch 8, Batch 900] loss: 0.05547393819957506
[Epoch 8, Batch 1000] loss: 0.05199565244780388
[Epoch 8, Batch 1100] loss: 0.04682962664403021
[Epoch 8, Batch 1200] loss: 0.048891076056170275
[Epoch 8, Batch 1300] loss: 0.040807592447963545
[Epoch 8, Batch 1400] loss: 0.053267496058542745
[Epoch 8, Batch 1500] loss: 0.04038035175006371
[Epoch 8, Batch 1600] loss: 0.04690436971199233
[Epoch 8, Batch 1700] loss: 0.04616775020287605
[Epoch 8, Batch 1800] loss: 0.060445459853799545
[Epoch 8, Batch 1900] loss: 0.05370869714708533
[Epoch 8, Batch 2000] loss: 0.0658881095139077
[Epoch 8, Batch 2100] loss: 0.05953616925471579
[Epoch 8, Batch 2200] loss: 0.03993526527599897
[Epoch 8, Batch 2300] loss: 0.05335338724049507
[Epoch 8, Batch 2400] loss: 0.04603151714021805
[Epoch 8, Batch 2500] loss: 0.03743007895813207
[Epoch 8, Batch 2600] loss: 0.045065136655612154
[Epoch 8, Batch 2700] loss: 0.051718659940815995
[Epoch 8, Batch 2800] loss: 0.05439745446667075
[Epoch 8, Batch 2900] loss: 0.05061863358365372
[Epoch 8, Batch 3000] loss: 0.05743496369861532
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0589
Validation Accuracy: 0.9812
Overfitting: 0.0589
[Epoch 9, Batch 100] loss: 0.04651792562042829
[Epoch 9, Batch 200] loss: 0.04465551242756192
[Epoch 9, Batch 300] loss: 0.03887679674488027
[Epoch 9, Batch 400] loss: 0.03831960377865471
[Epoch 9, Batch 500] loss: 0.03503403553710086
[Epoch 9, Batch 600] loss: 0.04404621989640873
[Epoch 9, Batch 700] loss: 0.04193838508945191
[Epoch 9, Batch 800] loss: 0.05787295956266462
[Epoch 9, Batch 900] loss: 0.04021800421876833
[Epoch 9, Batch 1000] loss: 0.05356716984795639
[Epoch 9, Batch 1100] loss: 0.052350099428731485
[Epoch 9, Batch 1200] loss: 0.04924094809917733
[Epoch 9, Batch 1300] loss: 0.034811776459391694
[Epoch 9, Batch 1400] loss: 0.044872232970956244
[Epoch 9, Batch 1500] loss: 0.0430314626544714
[Epoch 9, Batch 1600] loss: 0.0389678260445362
[Epoch 9, Batch 1700] loss: 0.04063644832582213
[Epoch 9, Batch 1800] loss: 0.03730790675705066
[Epoch 9, Batch 1900] loss: 0.04578205207915744
[Epoch 9, Batch 2000] loss: 0.03937228788738139
[Epoch 9, Batch 2100] loss: 0.05497279348026495
[Epoch 9, Batch 2200] loss: 0.044625817293126605
[Epoch 9, Batch 2300] loss: 0.05374790646805195
[Epoch 9, Batch 2400] loss: 0.04572316061341553
[Epoch 9, Batch 2500] loss: 0.03734153222001623
[Epoch 9, Batch 2600] loss: 0.04120947632778552
[Epoch 9, Batch 2700] loss: 0.035780616518168246
[Epoch 9, Batch 2800] loss: 0.04815115300531034
[Epoch 9, Batch 2900] loss: 0.03585902138263918
[Epoch 9, Batch 3000] loss: 0.05145762671774719
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9815
Overfitting: 0.0552
[I 2024-12-10 08:07:16,101] Trial 11 pruned. 

Selected Hyperparameters for Trial 13:
  l1: 256, l2: 128, lr: 0.0018063153279139915, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2851000571250917
**STATS for Epoch 1** : 
Average training loss: 1.0029
Average validation loss: 1.8330
Validation Accuracy: 0.7139
Overfitting: 0.8302
Best model saved at epoch 1 with validation loss: 1.8330
[Epoch 2, Batch 100] loss: 0.9216977882385254
**STATS for Epoch 2** : 
Average training loss: 0.2007
Average validation loss: 0.3783
Validation Accuracy: 0.8868
Overfitting: 0.1776
Best model saved at epoch 2 with validation loss: 0.3783
[Epoch 3, Batch 100] loss: 0.35704310357570646
**STATS for Epoch 3** : 
Average training loss: 0.1333
Average validation loss: 0.2439
Validation Accuracy: 0.9296
Overfitting: 0.1106
Best model saved at epoch 3 with validation loss: 0.2439
[Epoch 4, Batch 100] loss: 0.24530865237116814
**STATS for Epoch 4** : 
Average training loss: 0.1038
Average validation loss: 0.2112
Validation Accuracy: 0.9360
Overfitting: 0.1074
Best model saved at epoch 4 with validation loss: 0.2112
[Epoch 5, Batch 100] loss: 0.19281281977891923
**STATS for Epoch 5** : 
Average training loss: 0.0800
Average validation loss: 0.1514
Validation Accuracy: 0.9545
Overfitting: 0.0714
Best model saved at epoch 5 with validation loss: 0.1514
[Epoch 6, Batch 100] loss: 0.15328080505132674
**STATS for Epoch 6** : 
Average training loss: 0.0692
Average validation loss: 0.1305
Validation Accuracy: 0.9615
Overfitting: 0.0613
Best model saved at epoch 6 with validation loss: 0.1305
[Epoch 7, Batch 100] loss: 0.12866504646837712
**STATS for Epoch 7** : 
Average training loss: 0.0610
Average validation loss: 0.1151
Validation Accuracy: 0.9653
Overfitting: 0.0541
Best model saved at epoch 7 with validation loss: 0.1151
[Epoch 8, Batch 100] loss: 0.11248120345175266
**STATS for Epoch 8** : 
Average training loss: 0.0533
Average validation loss: 0.1037
Validation Accuracy: 0.9682
Overfitting: 0.0504
Best model saved at epoch 8 with validation loss: 0.1037
[Epoch 9, Batch 100] loss: 0.10459914214909077
**STATS for Epoch 9** : 
Average training loss: 0.0458
Average validation loss: 0.0949
Validation Accuracy: 0.9705
Overfitting: 0.0491
[I 2024-12-10 08:08:40,338] Trial 12 pruned. 

Selected Hyperparameters for Trial 14:
  l1: 256, l2: 128, lr: 0.0014098383604086698, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.289787971973419
[Epoch 1, Batch 200] loss: 2.219597351551056
[Epoch 1, Batch 300] loss: 1.5878853243589401
[Epoch 1, Batch 400] loss: 0.6795128509402275
[Epoch 1, Batch 500] loss: 0.47705151587724687
[Epoch 1, Batch 600] loss: 0.4032725083082914
[Epoch 1, Batch 700] loss: 0.3541322273388505
[Epoch 1, Batch 800] loss: 0.280630500279367
[Epoch 1, Batch 900] loss: 0.2796846179291606
[Epoch 1, Batch 1000] loss: 0.2557610418647528
[Epoch 1, Batch 1100] loss: 0.20876948177814483
[Epoch 1, Batch 1200] loss: 0.226897594910115
[Epoch 1, Batch 1300] loss: 0.18966024114750327
[Epoch 1, Batch 1400] loss: 0.210363303553313
[Epoch 1, Batch 1500] loss: 0.1940595543337986
[Epoch 1, Batch 1600] loss: 0.1619952142983675
[Epoch 1, Batch 1700] loss: 0.1316953421290964
[Epoch 1, Batch 1800] loss: 0.16858749468810857
[Epoch 1, Batch 1900] loss: 0.1350834780232981
[Epoch 1, Batch 2000] loss: 0.155230636165943
[Epoch 1, Batch 2100] loss: 0.14565898586064577
[Epoch 1, Batch 2200] loss: 0.12802499012090265
[Epoch 1, Batch 2300] loss: 0.164235835284926
[Epoch 1, Batch 2400] loss: 0.11355754124931991
[Epoch 1, Batch 2500] loss: 0.13531617439119145
[Epoch 1, Batch 2600] loss: 0.11860501116141677
[Epoch 1, Batch 2700] loss: 0.11624066391726956
[Epoch 1, Batch 2800] loss: 0.13010317855980247
[Epoch 1, Batch 2900] loss: 0.08722247260157019
[Epoch 1, Batch 3000] loss: 0.08359406580217182
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1006
Validation Accuracy: 0.9677
Overfitting: 0.1006
Best model saved at epoch 1 with validation loss: 0.1006
[Epoch 2, Batch 100] loss: 0.10816938046948053
[Epoch 2, Batch 200] loss: 0.12738939930452034
[Epoch 2, Batch 300] loss: 0.08223413263098336
[Epoch 2, Batch 400] loss: 0.07437243866268545
[Epoch 2, Batch 500] loss: 0.10500490984413773
[Epoch 2, Batch 600] loss: 0.09398561580339447
[Epoch 2, Batch 700] loss: 0.09633156801573932
[Epoch 2, Batch 800] loss: 0.07632379030284937
[Epoch 2, Batch 900] loss: 0.07988625988829881
[Epoch 2, Batch 1000] loss: 0.0747973407106474
[Epoch 2, Batch 1100] loss: 0.09187510514399037
[Epoch 2, Batch 1200] loss: 0.08494380112853833
[Epoch 2, Batch 1300] loss: 0.09970032205805182
[Epoch 2, Batch 1400] loss: 0.08428030412178486
[Epoch 2, Batch 1500] loss: 0.07678658065677155
[Epoch 2, Batch 1600] loss: 0.07460374698101077
[Epoch 2, Batch 1700] loss: 0.06866014776751399
[Epoch 2, Batch 1800] loss: 0.08117928869673051
[Epoch 2, Batch 1900] loss: 0.0766828483052086
[Epoch 2, Batch 2000] loss: 0.06779289375175722
[Epoch 2, Batch 2100] loss: 0.08569656712235883
[Epoch 2, Batch 2200] loss: 0.0804361055570189
[Epoch 2, Batch 2300] loss: 0.08848480367843876
[Epoch 2, Batch 2400] loss: 0.08126991777913645
[Epoch 2, Batch 2500] loss: 0.06645560114004184
[Epoch 2, Batch 2600] loss: 0.07566606802458409
[Epoch 2, Batch 2700] loss: 0.07373269204283134
[Epoch 2, Batch 2800] loss: 0.07448429038515314
[Epoch 2, Batch 2900] loss: 0.06859863618738019
[Epoch 2, Batch 3000] loss: 0.07767542170156957
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0922
Validation Accuracy: 0.9711
Overfitting: 0.0922
Best model saved at epoch 2 with validation loss: 0.0922
[Epoch 3, Batch 100] loss: 0.08306718484964222
[Epoch 3, Batch 200] loss: 0.04094286040635779
[Epoch 3, Batch 300] loss: 0.050325622789678164
[Epoch 3, Batch 400] loss: 0.06566850987961516
[Epoch 3, Batch 500] loss: 0.05581357397371903
[Epoch 3, Batch 600] loss: 0.0646982107963413
[Epoch 3, Batch 700] loss: 0.04053725412508356
[Epoch 3, Batch 800] loss: 0.042744766469695605
[Epoch 3, Batch 900] loss: 0.056894473930005914
[Epoch 3, Batch 1000] loss: 0.0627251807632274
[Epoch 3, Batch 1100] loss: 0.05287187131747487
[Epoch 3, Batch 1200] loss: 0.04532933083217358
[Epoch 3, Batch 1300] loss: 0.0684667294844985
[Epoch 3, Batch 1400] loss: 0.03956088908715174
[Epoch 3, Batch 1500] loss: 0.053705789147643374
[Epoch 3, Batch 1600] loss: 0.06820580483181402
[Epoch 3, Batch 1700] loss: 0.06378068936697673
[Epoch 3, Batch 1800] loss: 0.05973956173053011
[Epoch 3, Batch 1900] loss: 0.06712239357351792
[Epoch 3, Batch 2000] loss: 0.05945635983953253
[Epoch 3, Batch 2100] loss: 0.08217851848574355
[Epoch 3, Batch 2200] loss: 0.07055755189619958
[Epoch 3, Batch 2300] loss: 0.06295338309602812
[Epoch 3, Batch 2400] loss: 0.054753216521348805
[Epoch 3, Batch 2500] loss: 0.059134048164414706
[Epoch 3, Batch 2600] loss: 0.06195950701599941
[Epoch 3, Batch 2700] loss: 0.06583970635721925
[Epoch 3, Batch 2800] loss: 0.05167191014974378
[Epoch 3, Batch 2900] loss: 0.03976949540665373
[Epoch 3, Batch 3000] loss: 0.044270688351825814
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0507
Validation Accuracy: 0.9847
Overfitting: 0.0507
Best model saved at epoch 3 with validation loss: 0.0507
[Epoch 4, Batch 100] loss: 0.034667999869561754
[Epoch 4, Batch 200] loss: 0.0430154618184315
[Epoch 4, Batch 300] loss: 0.04216388600092614
[Epoch 4, Batch 400] loss: 0.04055147038423456
[Epoch 4, Batch 500] loss: 0.05123949148488464
[Epoch 4, Batch 600] loss: 0.04505893833411392
[Epoch 4, Batch 700] loss: 0.05215224203915568
[Epoch 4, Batch 800] loss: 0.04269269408774562
[Epoch 4, Batch 900] loss: 0.04148786866600858
[Epoch 4, Batch 1000] loss: 0.03733090113440994
[Epoch 4, Batch 1100] loss: 0.05611388591380091
[Epoch 4, Batch 1200] loss: 0.049000527739408425
[Epoch 4, Batch 1300] loss: 0.05157442717551021
[Epoch 4, Batch 1400] loss: 0.041403869384230345
[Epoch 4, Batch 1500] loss: 0.05313366020011017
[Epoch 4, Batch 1600] loss: 0.039865118961461124
[Epoch 4, Batch 1700] loss: 0.04103623177128611
[Epoch 4, Batch 1800] loss: 0.04667199566785712
[Epoch 4, Batch 1900] loss: 0.05312851669936208
[Epoch 4, Batch 2000] loss: 0.06576566500443733
[Epoch 4, Batch 2100] loss: 0.03881731819128618
[Epoch 4, Batch 2200] loss: 0.05517339810787234
[Epoch 4, Batch 2300] loss: 0.043666498995444274
[Epoch 4, Batch 2400] loss: 0.034698828199761916
[Epoch 4, Batch 2500] loss: 0.04237833343606326
[Epoch 4, Batch 2600] loss: 0.026548153345429454
[Epoch 4, Batch 2700] loss: 0.04665852636979253
[Epoch 4, Batch 2800] loss: 0.05273740312200971
[Epoch 4, Batch 2900] loss: 0.04910557716473704
[Epoch 4, Batch 3000] loss: 0.05265263181034243
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9833
Overfitting: 0.0508
[Epoch 5, Batch 100] loss: 0.025537826244253665
[Epoch 5, Batch 200] loss: 0.03195895861528698
[Epoch 5, Batch 300] loss: 0.02887828915765567
[Epoch 5, Batch 400] loss: 0.04150459009048063
[Epoch 5, Batch 500] loss: 0.0354140039140475
[Epoch 5, Batch 600] loss: 0.02928213579885778
[Epoch 5, Batch 700] loss: 0.03197274628822924
[Epoch 5, Batch 800] loss: 0.02963160090519523
[Epoch 5, Batch 900] loss: 0.046935841258673464
[Epoch 5, Batch 1000] loss: 0.032333199091372083
[Epoch 5, Batch 1100] loss: 0.039749921818292934
[Epoch 5, Batch 1200] loss: 0.04044522846626933
[Epoch 5, Batch 1300] loss: 0.050972574357001574
[Epoch 5, Batch 1400] loss: 0.031724777840427126
[Epoch 5, Batch 1500] loss: 0.03408455362179666
[Epoch 5, Batch 1600] loss: 0.025515696889342507
[Epoch 5, Batch 1700] loss: 0.04461757399811177
[Epoch 5, Batch 1800] loss: 0.029108306215639458
[Epoch 5, Batch 1900] loss: 0.030257205644593343
[Epoch 5, Batch 2000] loss: 0.030222992262861226
[Epoch 5, Batch 2100] loss: 0.030028754978593496
[Epoch 5, Batch 2200] loss: 0.038782660995202604
[Epoch 5, Batch 2300] loss: 0.05274188743089326
[Epoch 5, Batch 2400] loss: 0.057152882538794074
[Epoch 5, Batch 2500] loss: 0.03546247105230577
[Epoch 5, Batch 2600] loss: 0.025691495517239673
[Epoch 5, Batch 2700] loss: 0.04089847073930287
[Epoch 5, Batch 2800] loss: 0.03929335229142453
[Epoch 5, Batch 2900] loss: 0.02712407686325605
[Epoch 5, Batch 3000] loss: 0.031311371309129754
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9841
Overfitting: 0.0495
Best model saved at epoch 5 with validation loss: 0.0495
[Epoch 6, Batch 100] loss: 0.02773228307894897
[Epoch 6, Batch 200] loss: 0.04826053586395574
[Epoch 6, Batch 300] loss: 0.019033321573224384
[Epoch 6, Batch 400] loss: 0.011098006290994817
[Epoch 6, Batch 500] loss: 0.0419799034063908
[Epoch 6, Batch 600] loss: 0.03601263380114687
[Epoch 6, Batch 700] loss: 0.032509458694257774
[Epoch 6, Batch 800] loss: 0.03859350093174726
[Epoch 6, Batch 900] loss: 0.03899110967380693
[Epoch 6, Batch 1000] loss: 0.029754775672627146
[Epoch 6, Batch 1100] loss: 0.04258231343570515
[Epoch 6, Batch 1200] loss: 0.016975450475729303
[Epoch 6, Batch 1300] loss: 0.027858797561202665
[Epoch 6, Batch 1400] loss: 0.03198347630939679
[Epoch 6, Batch 1500] loss: 0.037469429855264025
[Epoch 6, Batch 1600] loss: 0.028373512574617052
[Epoch 6, Batch 1700] loss: 0.03679263374971924
[Epoch 6, Batch 1800] loss: 0.026034668799693465
[Epoch 6, Batch 1900] loss: 0.031703330598684264
[Epoch 6, Batch 2000] loss: 0.03588020233801217
[Epoch 6, Batch 2100] loss: 0.035281761992609975
[Epoch 6, Batch 2200] loss: 0.01905720304028364
[Epoch 6, Batch 2300] loss: 0.025664201174495246
[Epoch 6, Batch 2400] loss: 0.03346539775360725
[Epoch 6, Batch 2500] loss: 0.034580959060622266
[Epoch 6, Batch 2600] loss: 0.023298976564838085
[Epoch 6, Batch 2700] loss: 0.02321201017104613
[Epoch 6, Batch 2800] loss: 0.02087211727652175
[Epoch 6, Batch 2900] loss: 0.03626495695529229
[Epoch 6, Batch 3000] loss: 0.03409001350742983
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9868
Overfitting: 0.0476
Best model saved at epoch 6 with validation loss: 0.0476
[Epoch 7, Batch 100] loss: 0.021844403635550406
[Epoch 7, Batch 200] loss: 0.01549618725241089
[Epoch 7, Batch 300] loss: 0.02625921095461308
[Epoch 7, Batch 400] loss: 0.03154582675066195
[Epoch 7, Batch 500] loss: 0.028876862085926405
[Epoch 7, Batch 600] loss: 0.02564468230542843
[Epoch 7, Batch 700] loss: 0.0195409626266337
[Epoch 7, Batch 800] loss: 0.029413833987018734
[Epoch 7, Batch 900] loss: 0.03172520353225991
[Epoch 7, Batch 1000] loss: 0.024087757623710786
[Epoch 7, Batch 1100] loss: 0.027999324652846554
[Epoch 7, Batch 1200] loss: 0.025867043631351408
[Epoch 7, Batch 1300] loss: 0.019819819463446037
[Epoch 7, Batch 1400] loss: 0.04086087179784954
[Epoch 7, Batch 1500] loss: 0.03795779223422869
[Epoch 7, Batch 1600] loss: 0.02232313316915679
[Epoch 7, Batch 1700] loss: 0.01735942280953168
[Epoch 7, Batch 1800] loss: 0.01485602522665431
[Epoch 7, Batch 1900] loss: 0.023811050396470818
[Epoch 7, Batch 2000] loss: 0.02321836908507976
[Epoch 7, Batch 2100] loss: 0.01700526687425736
[Epoch 7, Batch 2200] loss: 0.031276976386798196
[Epoch 7, Batch 2300] loss: 0.02744563653250225
[Epoch 7, Batch 2400] loss: 0.02819049995174282
[Epoch 7, Batch 2500] loss: 0.0218860619032057
[Epoch 7, Batch 2600] loss: 0.03134629427040636
[Epoch 7, Batch 2700] loss: 0.026086548033490545
[Epoch 7, Batch 2800] loss: 0.016710788962591323
[Epoch 7, Batch 2900] loss: 0.024223395695807993
[Epoch 7, Batch 3000] loss: 0.0277460567187336
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9850
Overfitting: 0.0537
[Epoch 8, Batch 100] loss: 0.020586217303080048
[Epoch 8, Batch 200] loss: 0.013321086630385252
[Epoch 8, Batch 300] loss: 0.02519402618643653
[Epoch 8, Batch 400] loss: 0.013800346592906862
[Epoch 8, Batch 500] loss: 0.028130718834727304
[Epoch 8, Batch 600] loss: 0.020969786297064273
[Epoch 8, Batch 700] loss: 0.01886534672588823
[Epoch 8, Batch 800] loss: 0.02418929063003816
[Epoch 8, Batch 900] loss: 0.01589822317590915
[Epoch 8, Batch 1000] loss: 0.01199309717034339
[Epoch 8, Batch 1100] loss: 0.02928067182554514
[Epoch 8, Batch 1200] loss: 0.017171192751120543
[Epoch 8, Batch 1300] loss: 0.018884081876822164
[Epoch 8, Batch 1400] loss: 0.022085584933993232
[Epoch 8, Batch 1500] loss: 0.016963548823987366
[Epoch 8, Batch 1600] loss: 0.01817272131003847
[Epoch 8, Batch 1700] loss: 0.020801483569193806
[Epoch 8, Batch 1800] loss: 0.015906381807108117
[Epoch 8, Batch 1900] loss: 0.038353302010182236
[Epoch 8, Batch 2000] loss: 0.021194505819403277
[Epoch 8, Batch 2100] loss: 0.04296915082692067
[Epoch 8, Batch 2200] loss: 0.025479939045762876
[Epoch 8, Batch 2300] loss: 0.01475443324758089
[Epoch 8, Batch 2400] loss: 0.01205861399646892
[Epoch 8, Batch 2500] loss: 0.02271009613690694
[Epoch 8, Batch 2600] loss: 0.02778120205795858
[Epoch 8, Batch 2700] loss: 0.014443745779208256
[Epoch 8, Batch 2800] loss: 0.018367895451747246
[Epoch 8, Batch 2900] loss: 0.033383516719040926
[Epoch 8, Batch 3000] loss: 0.013066102628345106
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0435
Validation Accuracy: 0.9881
Overfitting: 0.0435
Best model saved at epoch 8 with validation loss: 0.0435
[Epoch 9, Batch 100] loss: 0.015411644882733526
[Epoch 9, Batch 200] loss: 0.02713854233144957
[Epoch 9, Batch 300] loss: 0.01677223241822503
[Epoch 9, Batch 400] loss: 0.017850628835876705
[Epoch 9, Batch 500] loss: 0.010360497039446272
[Epoch 9, Batch 600] loss: 0.02374246341398248
[Epoch 9, Batch 700] loss: 0.011110488721315051
[Epoch 9, Batch 800] loss: 0.016075851929817874
[Epoch 9, Batch 900] loss: 0.016256875053441037
[Epoch 9, Batch 1000] loss: 0.010172795862345083
[Epoch 9, Batch 1100] loss: 0.007181861650979044
[Epoch 9, Batch 1200] loss: 0.013258846266544423
[Epoch 9, Batch 1300] loss: 0.01974863794646808
[Epoch 9, Batch 1400] loss: 0.02091986604329577
[Epoch 9, Batch 1500] loss: 0.014298309512432751
[Epoch 9, Batch 1600] loss: 0.014455923504201565
[Epoch 9, Batch 1700] loss: 0.031397113817347416
[Epoch 9, Batch 1800] loss: 0.013655274023367383
[Epoch 9, Batch 1900] loss: 0.017850085506588585
[Epoch 9, Batch 2000] loss: 0.027900576895924588
[Epoch 9, Batch 2100] loss: 0.01736380468644711
[Epoch 9, Batch 2200] loss: 0.009374849923478906
[Epoch 9, Batch 2300] loss: 0.020422806895132907
[Epoch 9, Batch 2400] loss: 0.021950556834235614
[Epoch 9, Batch 2500] loss: 0.029202733015181365
[Epoch 9, Batch 2600] loss: 0.011618674873734563
[Epoch 9, Batch 2700] loss: 0.04401303998540243
[Epoch 9, Batch 2800] loss: 0.02105923291608633
[Epoch 9, Batch 2900] loss: 0.03238141911355342
[Epoch 9, Batch 3000] loss: 0.036251619652102815
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0423
Validation Accuracy: 0.9878
Overfitting: 0.0423
Best model saved at epoch 9 with validation loss: 0.0423
[Epoch 10, Batch 100] loss: 0.014224799005969544
[Epoch 10, Batch 200] loss: 0.006280883924237059
[Epoch 10, Batch 300] loss: 0.009780388020117244
[Epoch 10, Batch 400] loss: 0.006854316537755949
[Epoch 10, Batch 500] loss: 0.02460127630278748
[Epoch 10, Batch 600] loss: 0.009642744746470271
[Epoch 10, Batch 700] loss: 0.011660948521457612
[Epoch 10, Batch 800] loss: 0.010327408327366356
[Epoch 10, Batch 900] loss: 0.009366964266373543
[Epoch 10, Batch 1000] loss: 0.018747374841259445
[Epoch 10, Batch 1100] loss: 0.019224477998322984
[Epoch 10, Batch 1200] loss: 0.017332089622977945
[Epoch 10, Batch 1300] loss: 0.00894946921835981
[Epoch 10, Batch 1400] loss: 0.009302295102961579
[Epoch 10, Batch 1500] loss: 0.015386737045837436
[Epoch 10, Batch 1600] loss: 0.007544497107410279
[Epoch 10, Batch 1700] loss: 0.015275818130130575
[Epoch 10, Batch 1800] loss: 0.011592660331662046
[Epoch 10, Batch 1900] loss: 0.012801672286223038
[Epoch 10, Batch 2000] loss: 0.016193206936395654
[Epoch 10, Batch 2100] loss: 0.010446499288218548
[Epoch 10, Batch 2200] loss: 0.013486272919690236
[Epoch 10, Batch 2300] loss: 0.012868279500326025
[Epoch 10, Batch 2400] loss: 0.021871293920853532
[Epoch 10, Batch 2500] loss: 0.025059336948779674
[Epoch 10, Batch 2600] loss: 0.009164143244861407
[Epoch 10, Batch 2700] loss: 0.023748970981059755
[Epoch 10, Batch 2800] loss: 0.024794816826924942
[Epoch 10, Batch 2900] loss: 0.028851531408640767
[Epoch 10, Batch 3000] loss: 0.015125477595515803
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0421
Validation Accuracy: 0.9870
Overfitting: 0.0421
Best model saved at epoch 10 with validation loss: 0.0421
[Epoch 11, Batch 100] loss: 0.007888863515263437
[Epoch 11, Batch 200] loss: 0.010569119640404096
[Epoch 11, Batch 300] loss: 0.012246496250236305
[Epoch 11, Batch 400] loss: 0.017736531475566152
[Epoch 11, Batch 500] loss: 0.012913621669813437
[Epoch 11, Batch 600] loss: 0.016416073726013565
[Epoch 11, Batch 700] loss: 0.015663897130762054
[Epoch 11, Batch 800] loss: 0.011666849881394228
[Epoch 11, Batch 900] loss: 0.006467171402623535
[Epoch 11, Batch 1000] loss: 0.012410308232392708
[Epoch 11, Batch 1100] loss: 0.0071662014292724055
[Epoch 11, Batch 1200] loss: 0.006734972942695094
[Epoch 11, Batch 1300] loss: 0.006746103029936421
[Epoch 11, Batch 1400] loss: 0.011530954322879552
[Epoch 11, Batch 1500] loss: 0.014294050404377003
[Epoch 11, Batch 1600] loss: 0.01371379858770979
[Epoch 11, Batch 1700] loss: 0.006128646628312708
[Epoch 11, Batch 1800] loss: 0.009299064653569077
[Epoch 11, Batch 1900] loss: 0.01414492983130458
[Epoch 11, Batch 2000] loss: 0.014041510300530717
[Epoch 11, Batch 2100] loss: 0.009888789372998872
[Epoch 11, Batch 2200] loss: 0.007016552516424781
[Epoch 11, Batch 2300] loss: 0.020951231507683587
[Epoch 11, Batch 2400] loss: 0.0063849416830817065
[Epoch 11, Batch 2500] loss: 0.017939187980691714
[Epoch 11, Batch 2600] loss: 0.019064525006087935
[Epoch 11, Batch 2700] loss: 0.010112718624557714
[Epoch 11, Batch 2800] loss: 0.020278749396211423
[Epoch 11, Batch 2900] loss: 0.013330737827836857
[Epoch 11, Batch 3000] loss: 0.014921594323295722
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0440
Validation Accuracy: 0.9878
Overfitting: 0.0440
[Epoch 12, Batch 100] loss: 0.007781101980690437
[Epoch 12, Batch 200] loss: 0.008968722602696743
[Epoch 12, Batch 300] loss: 0.010007170275803218
[Epoch 12, Batch 400] loss: 0.009222947306029709
[Epoch 12, Batch 500] loss: 0.008091927760196994
[Epoch 12, Batch 600] loss: 0.018680010465159283
[Epoch 12, Batch 700] loss: 0.013535190487275486
[Epoch 12, Batch 800] loss: 0.011845458921225144
[Epoch 12, Batch 900] loss: 0.011567362347550443
[Epoch 12, Batch 1000] loss: 0.011317851151798095
[Epoch 12, Batch 1100] loss: 0.016306001683192337
[Epoch 12, Batch 1200] loss: 0.016546424287862464
[Epoch 12, Batch 1300] loss: 0.021230136144646396
[Epoch 12, Batch 1400] loss: 0.00901352594681157
[Epoch 12, Batch 1500] loss: 0.006023933618237152
[Epoch 12, Batch 1600] loss: 0.009111498559150277
[Epoch 12, Batch 1700] loss: 0.00765734679893967
[Epoch 12, Batch 1800] loss: 0.010356714698127689
[Epoch 12, Batch 1900] loss: 0.01275805442352521
[Epoch 12, Batch 2000] loss: 0.008096904471011612
[Epoch 12, Batch 2100] loss: 0.007045109813423096
[Epoch 12, Batch 2200] loss: 0.016877470928779986
[Epoch 12, Batch 2300] loss: 0.014441355280143852
[Epoch 12, Batch 2400] loss: 0.013437758454632558
[Epoch 12, Batch 2500] loss: 0.022786007423560475
[Epoch 12, Batch 2600] loss: 0.021538403265931264
[Epoch 12, Batch 2700] loss: 0.02010440396199556
[Epoch 12, Batch 2800] loss: 0.015622501712823578
[Epoch 12, Batch 2900] loss: 0.014899352949512376
[Epoch 12, Batch 3000] loss: 0.013171526917903974
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9873
Overfitting: 0.0468
[Epoch 13, Batch 100] loss: 0.013331652828028381
[Epoch 13, Batch 200] loss: 0.00889931484070985
[Epoch 13, Batch 300] loss: 0.0071255783483468345
[Epoch 13, Batch 400] loss: 0.004659869402405548
[Epoch 13, Batch 500] loss: 0.0038965007709384734
[Epoch 13, Batch 600] loss: 0.008038482931287944
[Epoch 13, Batch 700] loss: 0.010837132831802591
[Epoch 13, Batch 800] loss: 0.012922159243285023
[Epoch 13, Batch 900] loss: 0.007144873105376064
[Epoch 13, Batch 1000] loss: 0.009928229575718888
[Epoch 13, Batch 1100] loss: 0.008708404645731208
[Epoch 13, Batch 1200] loss: 0.01334610970761787
[Epoch 13, Batch 1300] loss: 0.005436448235439002
[Epoch 13, Batch 1400] loss: 0.024529408716553007
[Epoch 13, Batch 1500] loss: 0.01034300861319025
[Epoch 13, Batch 1600] loss: 0.014943721459221706
[Epoch 13, Batch 1700] loss: 0.006708053599404593
[Epoch 13, Batch 1800] loss: 0.007018498329666727
[Epoch 13, Batch 1900] loss: 0.009329923652958315
[Epoch 13, Batch 2000] loss: 0.008852807361145097
[Epoch 13, Batch 2100] loss: 0.003984634215059941
[Epoch 13, Batch 2200] loss: 0.006472282479734304
[Epoch 13, Batch 2300] loss: 0.012206237441469057
[Epoch 13, Batch 2400] loss: 0.011301502837591215
[Epoch 13, Batch 2500] loss: 0.014291801088800184
[Epoch 13, Batch 2600] loss: 0.005812803772855659
[Epoch 13, Batch 2700] loss: 0.006044360679719602
[Epoch 13, Batch 2800] loss: 0.01073891238533136
[Epoch 13, Batch 2900] loss: 0.008636827333693873
[Epoch 13, Batch 3000] loss: 0.011474170292385679
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9879
Overfitting: 0.0441
[Epoch 14, Batch 100] loss: 0.009226589318132028
[Epoch 14, Batch 200] loss: 0.004490518436064121
[Epoch 14, Batch 300] loss: 0.005540386042588921
[Epoch 14, Batch 400] loss: 0.0058589965739975014
[Epoch 14, Batch 500] loss: 0.00897286373231509
[Epoch 14, Batch 600] loss: 0.0053338619738838135
[Epoch 14, Batch 700] loss: 0.005620910038589955
[Epoch 14, Batch 800] loss: 0.009564761094429742
[Epoch 14, Batch 900] loss: 0.014959893677273612
[Epoch 14, Batch 1000] loss: 0.006199592444158952
[Epoch 14, Batch 1100] loss: 0.004196250915579185
[Epoch 14, Batch 1200] loss: 0.015177695932439974
[Epoch 14, Batch 1300] loss: 0.006417777493815038
[Epoch 14, Batch 1400] loss: 0.0076713045987185065
[Epoch 14, Batch 1500] loss: 0.00349315062779624
[Epoch 14, Batch 1600] loss: 0.0036377197082532575
[Epoch 14, Batch 1700] loss: 0.0037858674888366296
[Epoch 14, Batch 1800] loss: 0.007079134438434949
[Epoch 14, Batch 1900] loss: 0.019733443668046677
[Epoch 14, Batch 2000] loss: 0.0032745184143686858
[Epoch 14, Batch 2100] loss: 0.00585902199924476
[Epoch 14, Batch 2200] loss: 0.00374815498869566
[Epoch 14, Batch 2300] loss: 0.009171362836460447
[Epoch 14, Batch 2400] loss: 0.009711736225238781
[Epoch 14, Batch 2500] loss: 0.009015629695206827
[Epoch 14, Batch 2600] loss: 0.007369490739442881
[Epoch 14, Batch 2700] loss: 0.014734509308425459
[Epoch 14, Batch 2800] loss: 0.008486146759786949
[Epoch 14, Batch 2900] loss: 0.007673487331730939
[Epoch 14, Batch 3000] loss: 0.012412362035902617
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9879
Overfitting: 0.0509
[Epoch 15, Batch 100] loss: 0.00975605663202714
[Epoch 15, Batch 200] loss: 0.012351485928833198
[Epoch 15, Batch 300] loss: 0.018674519173082445
[Epoch 15, Batch 400] loss: 0.009053346639020673
[Epoch 15, Batch 500] loss: 0.006863354634448342
[Epoch 15, Batch 600] loss: 0.0048630994812037896
[Epoch 15, Batch 700] loss: 0.004683228522412719
[Epoch 15, Batch 800] loss: 0.0034445205053771134
[Epoch 15, Batch 900] loss: 0.006402072567043433
[Epoch 15, Batch 1000] loss: 0.008774836773850438
[Epoch 15, Batch 1100] loss: 0.006020811984755028
[Epoch 15, Batch 1200] loss: 0.012995113800883473
[Epoch 15, Batch 1300] loss: 0.008575886836456447
[Epoch 15, Batch 1400] loss: 0.0032422809841625624
[Epoch 15, Batch 1500] loss: 0.00235709750263311
[Epoch 15, Batch 1600] loss: 0.006736795359996109
[Epoch 15, Batch 1700] loss: 0.00490917007111193
[Epoch 15, Batch 1800] loss: 0.005926756069873136
[Epoch 15, Batch 1900] loss: 0.004140645226234483
[Epoch 15, Batch 2000] loss: 0.0048827821326517555
[Epoch 15, Batch 2100] loss: 0.010416921878018286
[Epoch 15, Batch 2200] loss: 0.006671963544312121
[Epoch 15, Batch 2300] loss: 0.009563120060279288
[Epoch 15, Batch 2400] loss: 0.00862559934635101
[Epoch 15, Batch 2500] loss: 0.004356285536271116
[Epoch 15, Batch 2600] loss: 0.0061804498786358405
[Epoch 15, Batch 2700] loss: 0.005550066198736658
[Epoch 15, Batch 2800] loss: 0.0038986863611938814
[Epoch 15, Batch 2900] loss: 0.010191560530744255
[Epoch 15, Batch 3000] loss: 0.007171141593962034
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0428
Validation Accuracy: 0.9897
Overfitting: 0.0428
[Epoch 16, Batch 100] loss: 0.004459749502485693
[Epoch 16, Batch 200] loss: 0.002870319632730798
[Epoch 16, Batch 300] loss: 0.0026934532634010112
[Epoch 16, Batch 400] loss: 0.002836381188798214
[Epoch 16, Batch 500] loss: 0.003871093571434585
[Epoch 16, Batch 600] loss: 0.00263281799244794
[Epoch 16, Batch 700] loss: 0.0034086909870632096
[Epoch 16, Batch 800] loss: 0.003315310318618003
[Epoch 16, Batch 900] loss: 0.002437170833445066
[Epoch 16, Batch 1000] loss: 0.0038828043725132487
[Epoch 16, Batch 1100] loss: 0.009170344369754274
[Epoch 16, Batch 1200] loss: 0.00353608727655228
[Epoch 16, Batch 1300] loss: 0.005262882721251856
[Epoch 16, Batch 1400] loss: 0.005132774271031053
[Epoch 16, Batch 1500] loss: 0.010363641773746223
[Epoch 16, Batch 1600] loss: 0.004876892161422148
[Epoch 16, Batch 1700] loss: 0.0063979773501995395
[Epoch 16, Batch 1800] loss: 0.017136814819506442
[Epoch 16, Batch 1900] loss: 0.002078114094630905
[Epoch 16, Batch 2000] loss: 0.011813791270583351
[Epoch 16, Batch 2100] loss: 0.011293368232768443
[Epoch 16, Batch 2200] loss: 0.004109329520110805
[Epoch 16, Batch 2300] loss: 0.00639738368236749
[Epoch 16, Batch 2400] loss: 0.008783842874768197
[Epoch 16, Batch 2500] loss: 0.00879710445654382
[Epoch 16, Batch 2600] loss: 0.004641084802527757
[Epoch 16, Batch 2700] loss: 0.00277735130121755
[Epoch 16, Batch 2800] loss: 0.008496323075626151
[Epoch 16, Batch 2900] loss: 0.009437772066584103
[Epoch 16, Batch 3000] loss: 0.015703005911761922
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9878
Overfitting: 0.0535
[Epoch 17, Batch 100] loss: 0.0049672692323031245
[Epoch 17, Batch 200] loss: 0.005329925131975983
[Epoch 17, Batch 300] loss: 0.0032899450887282455
[Epoch 17, Batch 400] loss: 0.002474107150772511
[Epoch 17, Batch 500] loss: 0.013076470299763514
[Epoch 17, Batch 600] loss: 0.0069554190919006945
[Epoch 17, Batch 700] loss: 0.004679724513162
[Epoch 17, Batch 800] loss: 0.0038248895608739984
[Epoch 17, Batch 900] loss: 0.003363333945426348
[Epoch 17, Batch 1000] loss: 0.0037831183145897286
[Epoch 17, Batch 1100] loss: 0.0021846206241070833
[Epoch 17, Batch 1200] loss: 0.006097614623755589
[Epoch 17, Batch 1300] loss: 0.010767870171650883
[Epoch 17, Batch 1400] loss: 0.0196297481241686
[Epoch 17, Batch 1500] loss: 0.008102439401337733
[Epoch 17, Batch 1600] loss: 0.0067351001163720526
[Epoch 17, Batch 1700] loss: 0.0040041136524553165
[Epoch 17, Batch 1800] loss: 0.016768944876920388
[Epoch 17, Batch 1900] loss: 0.0029138422238588644
[Epoch 17, Batch 2000] loss: 0.00228552237177837
[Epoch 17, Batch 2100] loss: 0.007601316157613383
[Epoch 17, Batch 2200] loss: 0.004082339969764917
[Epoch 17, Batch 2300] loss: 0.0026756419912436513
[Epoch 17, Batch 2400] loss: 0.005063697267689804
[Epoch 17, Batch 2500] loss: 0.0024723373527933746
[Epoch 17, Batch 2600] loss: 0.010193550403377003
[Epoch 17, Batch 2700] loss: 0.013293618626727266
[Epoch 17, Batch 2800] loss: 0.006446391283622006
[Epoch 17, Batch 2900] loss: 0.004982024447610911
[Epoch 17, Batch 3000] loss: 0.01186667647496904
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9897
Overfitting: 0.0455
[Epoch 18, Batch 100] loss: 0.0019843506227407203
[Epoch 18, Batch 200] loss: 0.0050094128899309
[Epoch 18, Batch 300] loss: 0.001166925346054768
[Epoch 18, Batch 400] loss: 0.0038436238201500572
[Epoch 18, Batch 500] loss: 0.0013962709133647877
[Epoch 18, Batch 600] loss: 0.0031841284605010857
[Epoch 18, Batch 700] loss: 0.008226990769347822
[Epoch 18, Batch 800] loss: 0.0037357604263047505
[Epoch 18, Batch 900] loss: 0.002018420828740091
[Epoch 18, Batch 1000] loss: 0.003832567665846227
[Epoch 18, Batch 1100] loss: 0.002897235699165606
[Epoch 18, Batch 1200] loss: 0.010142176847915607
[Epoch 18, Batch 1300] loss: 0.0044247135902210745
[Epoch 18, Batch 1400] loss: 0.006696657168308775
[Epoch 18, Batch 1500] loss: 0.007457631806938281
[Epoch 18, Batch 1600] loss: 0.005924557239835479
[Epoch 18, Batch 1700] loss: 0.005307019830366322
[Epoch 18, Batch 1800] loss: 0.0020871488995661026
[Epoch 18, Batch 1900] loss: 0.002537081486284194
[Epoch 18, Batch 2000] loss: 0.0014860161874430844
[Epoch 18, Batch 2100] loss: 0.0073728249201028
[Epoch 18, Batch 2200] loss: 0.005011495612450005
[Epoch 18, Batch 2300] loss: 0.007931149526788204
[Epoch 18, Batch 2400] loss: 0.011217013133029355
[Epoch 18, Batch 2500] loss: 0.0037468444807200285
[Epoch 18, Batch 2600] loss: 0.0039605090511335385
[Epoch 18, Batch 2700] loss: 0.012701952915802792
[Epoch 18, Batch 2800] loss: 0.013354979889538043
[Epoch 18, Batch 2900] loss: 0.004942840010201053
[Epoch 18, Batch 3000] loss: 0.006414636638990032
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9886
Overfitting: 0.0496
[Epoch 19, Batch 100] loss: 0.009099498713991351
[Epoch 19, Batch 200] loss: 0.004044611614550036
[Epoch 19, Batch 300] loss: 0.002842513484420124
[Epoch 19, Batch 400] loss: 0.0009189880426106356
[Epoch 19, Batch 500] loss: 0.004339117890829698
[Epoch 19, Batch 600] loss: 0.003993298778261192
[Epoch 19, Batch 700] loss: 0.0047776609837646335
[Epoch 19, Batch 800] loss: 0.004371025413877305
[Epoch 19, Batch 900] loss: 0.0013707868866111993
[Epoch 19, Batch 1000] loss: 0.0024586960545605052
[Epoch 19, Batch 1100] loss: 0.0009924308078802823
[Epoch 19, Batch 1200] loss: 0.0029608432494121926
[Epoch 19, Batch 1300] loss: 0.002380551115308549
[Epoch 19, Batch 1400] loss: 0.00331297875737107
[Epoch 19, Batch 1500] loss: 0.0016202756699931341
[Epoch 19, Batch 1600] loss: 0.00164539310138462
[Epoch 19, Batch 1700] loss: 0.0025662086513611373
[Epoch 19, Batch 1800] loss: 0.006578344038330784
[Epoch 19, Batch 1900] loss: 0.00425178045871796
[Epoch 19, Batch 2000] loss: 0.006715081926834046
[Epoch 19, Batch 2100] loss: 0.01043136975013823
[Epoch 19, Batch 2200] loss: 0.002799983038885472
[Epoch 19, Batch 2300] loss: 0.002287430112095308
[Epoch 19, Batch 2400] loss: 0.0013857557114010889
[Epoch 19, Batch 2500] loss: 0.0016676460923630999
[Epoch 19, Batch 2600] loss: 0.001327811309847533
[Epoch 19, Batch 2700] loss: 0.0015983235870244527
[Epoch 19, Batch 2800] loss: 0.002954979422516786
[Epoch 19, Batch 2900] loss: 0.005584092821048898
[Epoch 19, Batch 3000] loss: 0.002523169839884356
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9902
Overfitting: 0.0476
[Epoch 20, Batch 100] loss: 0.000982080616001042
[Epoch 20, Batch 200] loss: 0.000743843441965879
[Epoch 20, Batch 300] loss: 0.0006876801226960083
[Epoch 20, Batch 400] loss: 0.002718599151635885
[Epoch 20, Batch 500] loss: 0.004362336407692169
[Epoch 20, Batch 600] loss: 0.0006813043195397484
[Epoch 20, Batch 700] loss: 0.0024279080922150254
[Epoch 20, Batch 800] loss: 0.0026391461104361726
[Epoch 20, Batch 900] loss: 0.0012563027694295669
[Epoch 20, Batch 1000] loss: 0.002468070450804696
[Epoch 20, Batch 1100] loss: 0.006879547668241912
[Epoch 20, Batch 1200] loss: 0.002152048486963878
[Epoch 20, Batch 1300] loss: 0.002297748729759235
[Epoch 20, Batch 1400] loss: 0.0014480838324796253
[Epoch 20, Batch 1500] loss: 0.0008518409154073225
[Epoch 20, Batch 1600] loss: 0.001660416449018598
[Epoch 20, Batch 1700] loss: 0.0004898450241141816
[Epoch 20, Batch 1800] loss: 0.0012424321456970234
[Epoch 20, Batch 1900] loss: 0.0005517215335523674
[Epoch 20, Batch 2000] loss: 0.00469133935351234
[Epoch 20, Batch 2100] loss: 0.006945999275127548
[Epoch 20, Batch 2200] loss: 0.0009683962768554011
[Epoch 20, Batch 2300] loss: 0.002106009972628158
[Epoch 20, Batch 2400] loss: 0.0008975608556090719
[Epoch 20, Batch 2500] loss: 0.0015152765828241855
[Epoch 20, Batch 2600] loss: 0.0009153736647697031
[Epoch 20, Batch 2700] loss: 0.005034570819732274
[Epoch 20, Batch 2800] loss: 0.001200708832966768
[Epoch 20, Batch 2900] loss: 0.001964435239984894
[Epoch 20, Batch 3000] loss: 0.001281579789613545
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0443
Validation Accuracy: 0.9908
Overfitting: 0.0443
[Epoch 21, Batch 100] loss: 0.0005589748729190269
[Epoch 21, Batch 200] loss: 0.0024267832232175122
[Epoch 21, Batch 300] loss: 0.0010486406010602424
[Epoch 21, Batch 400] loss: 0.0011920251316317376
[Epoch 21, Batch 500] loss: 0.0010360772827599973
[Epoch 21, Batch 600] loss: 0.0006416996569321043
[Epoch 21, Batch 700] loss: 0.0014538876274752877
[Epoch 21, Batch 800] loss: 0.0006120945987773219
[Epoch 21, Batch 900] loss: 0.0039733232475249024
[Epoch 21, Batch 1000] loss: 0.0018381595209857693
[Epoch 21, Batch 1100] loss: 0.0004452580227133041
[Epoch 21, Batch 1200] loss: 0.0003023649817329632
[Epoch 21, Batch 1300] loss: 0.0025542489205601228
[Epoch 21, Batch 1400] loss: 0.008070094590128871
[Epoch 21, Batch 1500] loss: 0.001414205490737146
[Epoch 21, Batch 1600] loss: 0.0031098440757136815
[Epoch 21, Batch 1700] loss: 0.002370071428578413
[Epoch 21, Batch 1800] loss: 0.0009293077599167532
[Epoch 21, Batch 1900] loss: 0.0009107443818292849
[Epoch 21, Batch 2000] loss: 0.0017857757859146518
[Epoch 21, Batch 2100] loss: 0.0005978330151888401
[Epoch 21, Batch 2200] loss: 0.000679610664977659
[Epoch 21, Batch 2300] loss: 0.0017120035403158295
[Epoch 21, Batch 2400] loss: 0.00484033278714036
[Epoch 21, Batch 2500] loss: 0.0006542481620135732
[Epoch 21, Batch 2600] loss: 0.0036748092482772597
[Epoch 21, Batch 2700] loss: 0.0007059122902678894
[Epoch 21, Batch 2800] loss: 0.001259261598417787
[Epoch 21, Batch 2900] loss: 0.0003691313831077947
[Epoch 21, Batch 3000] loss: 0.002386701820780104
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9905
Overfitting: 0.0466
[Epoch 22, Batch 100] loss: 0.0034234433412012777
[Epoch 22, Batch 200] loss: 0.0005652527704933163
[Epoch 22, Batch 300] loss: 0.0008796994627446253
[Epoch 22, Batch 400] loss: 0.0017072422289272993
[Epoch 22, Batch 500] loss: 0.0006705601095427483
[Epoch 22, Batch 600] loss: 0.001900123477343243
[Epoch 22, Batch 700] loss: 0.0004771482365344326
[Epoch 22, Batch 800] loss: 0.0008385423720302754
[Epoch 22, Batch 900] loss: 0.0013859327777710996
[Epoch 22, Batch 1000] loss: 0.00032102202281052427
[Epoch 22, Batch 1100] loss: 0.0014042276739273517
[Epoch 22, Batch 1200] loss: 0.0008591601690115169
[Epoch 22, Batch 1300] loss: 0.0003502426775266265
[Epoch 22, Batch 1400] loss: 0.0003942268394626991
[Epoch 22, Batch 1500] loss: 0.0004599198191988663
[Epoch 22, Batch 1600] loss: 0.0003488432404822106
[Epoch 22, Batch 1700] loss: 0.0027640114763855194
[Epoch 22, Batch 1800] loss: 0.0014346869665883943
[Epoch 22, Batch 1900] loss: 0.0003170334465828928
[Epoch 22, Batch 2000] loss: 0.0009116313951243882
[Epoch 22, Batch 2100] loss: 0.0008428371941186086
[Epoch 22, Batch 2200] loss: 0.0028445324748307146
[Epoch 22, Batch 2300] loss: 0.006915003665353225
[Epoch 22, Batch 2400] loss: 0.0011434581229707419
[Epoch 22, Batch 2500] loss: 0.0007526880819217752
[Epoch 22, Batch 2600] loss: 0.0029606253859016008
[Epoch 22, Batch 2700] loss: 0.0007834117226805403
[Epoch 22, Batch 2800] loss: 0.0013210993857567343
[Epoch 22, Batch 2900] loss: 0.0007911284168177524
[Epoch 22, Batch 3000] loss: 0.0011323965466979048
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9904
Overfitting: 0.0486
[Epoch 23, Batch 100] loss: 0.0008929823737411979
[Epoch 23, Batch 200] loss: 0.0004071178527076569
[Epoch 23, Batch 300] loss: 0.00046097447132343206
[Epoch 23, Batch 400] loss: 0.00033263607133164006
[Epoch 23, Batch 500] loss: 0.0004742695825954968
[Epoch 23, Batch 600] loss: 0.00043599042729603355
[Epoch 23, Batch 700] loss: 0.0010091748467109696
[Epoch 23, Batch 800] loss: 0.0005461971689917178
[Epoch 23, Batch 900] loss: 0.004689185881828983
[Epoch 23, Batch 1000] loss: 0.0005456403340104954
[Epoch 23, Batch 1100] loss: 0.0010597883535277174
[Epoch 23, Batch 1200] loss: 0.0008587682624858317
[Epoch 23, Batch 1300] loss: 0.0005345116555990615
[Epoch 23, Batch 1400] loss: 0.0009681614943296957
[Epoch 23, Batch 1500] loss: 0.001242976645430498
[Epoch 23, Batch 1600] loss: 0.0004732741259645934
[Epoch 23, Batch 1700] loss: 0.0006641952848534061
[Epoch 23, Batch 1800] loss: 0.0012301225469357347
[Epoch 23, Batch 1900] loss: 0.00036287860294951455
[Epoch 23, Batch 2000] loss: 0.001308998954528775
[Epoch 23, Batch 2100] loss: 0.0004992079451635334
[Epoch 23, Batch 2200] loss: 0.0011909947773857254
[Epoch 23, Batch 2300] loss: 0.0005821824721327928
[Epoch 23, Batch 2400] loss: 0.0003916828824105423
[Epoch 23, Batch 2500] loss: 0.0009376698540443762
[Epoch 23, Batch 2600] loss: 0.0005818786506000251
[Epoch 23, Batch 2700] loss: 0.0010514940920903371
[Epoch 23, Batch 2800] loss: 0.00038163961700636405
[Epoch 23, Batch 2900] loss: 0.0005420639317082631
[Epoch 23, Batch 3000] loss: 0.0005359453493476707
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9918
Overfitting: 0.0462
[Epoch 24, Batch 100] loss: 0.000348420831659908
[Epoch 24, Batch 200] loss: 0.0016157628597358053
[Epoch 24, Batch 300] loss: 0.0012068953955756002
[Epoch 24, Batch 400] loss: 0.0008594119567132274
[Epoch 24, Batch 500] loss: 0.0009783322587329124
[Epoch 24, Batch 600] loss: 0.0009203549309496139
[Epoch 24, Batch 700] loss: 0.0002586873423971037
[Epoch 24, Batch 800] loss: 0.0004971854935710862
[Epoch 24, Batch 900] loss: 0.0009805469607082173
[Epoch 24, Batch 1000] loss: 0.00025588742593125603
[Epoch 24, Batch 1100] loss: 0.00019812406605502987
[Epoch 24, Batch 1200] loss: 0.00014970257511128792
[Epoch 24, Batch 1300] loss: 0.00042582898652407055
[Epoch 24, Batch 1400] loss: 0.0014510033910011088
[Epoch 24, Batch 1500] loss: 0.000295483429416068
[Epoch 24, Batch 1600] loss: 0.0004584337912297087
[Epoch 24, Batch 1700] loss: 0.0005374355776528717
[Epoch 24, Batch 1800] loss: 0.00045005401012609525
[Epoch 24, Batch 1900] loss: 0.00028385629023102154
[Epoch 24, Batch 2000] loss: 0.0003982334689780842
[Epoch 24, Batch 2100] loss: 0.0003707599824496999
[Epoch 24, Batch 2200] loss: 0.00038629571027673395
[Epoch 24, Batch 2300] loss: 0.002208875228362679
[Epoch 24, Batch 2400] loss: 0.0004839108475084819
[Epoch 24, Batch 2500] loss: 0.0004604385060326166
[Epoch 24, Batch 2600] loss: 0.0004183991550144839
[Epoch 24, Batch 2700] loss: 0.00038510804894944075
[Epoch 24, Batch 2800] loss: 0.00022332221072876023
[Epoch 24, Batch 2900] loss: 0.000621758526590046
[Epoch 24, Batch 3000] loss: 0.00020796174440849136
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9916
Overfitting: 0.0462
Fold 1 validation loss: 0.0462
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.270488178730011
[Epoch 1, Batch 200] loss: 1.9323286628723144
[Epoch 1, Batch 300] loss: 0.8508976075053215
[Epoch 1, Batch 400] loss: 0.5591041766107082
[Epoch 1, Batch 500] loss: 0.465807322524488
[Epoch 1, Batch 600] loss: 0.3384304714947939
[Epoch 1, Batch 700] loss: 0.3637017386034131
[Epoch 1, Batch 800] loss: 0.31194868937134745
[Epoch 1, Batch 900] loss: 0.2986072074621916
[Epoch 1, Batch 1000] loss: 0.21076321144588292
[Epoch 1, Batch 1100] loss: 0.21335189579054714
[Epoch 1, Batch 1200] loss: 0.21156616452150045
[Epoch 1, Batch 1300] loss: 0.1713576165307313
[Epoch 1, Batch 1400] loss: 0.17331914525479078
[Epoch 1, Batch 1500] loss: 0.15624543932266532
[Epoch 1, Batch 1600] loss: 0.18622248750180007
[Epoch 1, Batch 1700] loss: 0.15260341408429667
[Epoch 1, Batch 1800] loss: 0.13843019645195453
[Epoch 1, Batch 1900] loss: 0.16912579441908748
[Epoch 1, Batch 2000] loss: 0.12949140781536697
[Epoch 1, Batch 2100] loss: 0.1508584270742722
[Epoch 1, Batch 2200] loss: 0.1213306284090504
[Epoch 1, Batch 2300] loss: 0.12933982440503314
[Epoch 1, Batch 2400] loss: 0.13510988147929312
[Epoch 1, Batch 2500] loss: 0.15164702092297375
[Epoch 1, Batch 2600] loss: 0.10874611039413139
[Epoch 1, Batch 2700] loss: 0.11480909751611762
[Epoch 1, Batch 2800] loss: 0.09907432366162539
[Epoch 1, Batch 2900] loss: 0.09951761079835705
[Epoch 1, Batch 3000] loss: 0.11305130988825113
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1166
Validation Accuracy: 0.9627
Overfitting: 0.1166
Best model saved at epoch 1 with validation loss: 0.1166
[Epoch 2, Batch 100] loss: 0.09936732494272292
[Epoch 2, Batch 200] loss: 0.1045084102312103
[Epoch 2, Batch 300] loss: 0.0926255275728181
[Epoch 2, Batch 400] loss: 0.08935921393800526
[Epoch 2, Batch 500] loss: 0.07199547126307153
[Epoch 2, Batch 600] loss: 0.09866845567245036
[Epoch 2, Batch 700] loss: 0.11558890775893815
[Epoch 2, Batch 800] loss: 0.06817554127017501
[Epoch 2, Batch 900] loss: 0.07634509117691778
[Epoch 2, Batch 1000] loss: 0.1177291826182045
[Epoch 2, Batch 1100] loss: 0.09527805106015876
[Epoch 2, Batch 1200] loss: 0.09402628908166662
[Epoch 2, Batch 1300] loss: 0.06870585712953471
[Epoch 2, Batch 1400] loss: 0.08061820077477024
[Epoch 2, Batch 1500] loss: 0.09857062031282111
[Epoch 2, Batch 1600] loss: 0.07239102514693513
[Epoch 2, Batch 1700] loss: 0.08273605137714185
[Epoch 2, Batch 1800] loss: 0.09015777069493197
[Epoch 2, Batch 1900] loss: 0.08893388313357718
[Epoch 2, Batch 2000] loss: 0.1008115060563432
[Epoch 2, Batch 2100] loss: 0.07207931543467566
[Epoch 2, Batch 2200] loss: 0.10881064903689548
[Epoch 2, Batch 2300] loss: 0.07358885244291741
[Epoch 2, Batch 2400] loss: 0.07914400430279783
[Epoch 2, Batch 2500] loss: 0.09055683716607746
[Epoch 2, Batch 2600] loss: 0.07579014162532985
[Epoch 2, Batch 2700] loss: 0.07566788175317925
[Epoch 2, Batch 2800] loss: 0.06311621254833881
[Epoch 2, Batch 2900] loss: 0.07816950101667317
[Epoch 2, Batch 3000] loss: 0.07133318369742483
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0833
Validation Accuracy: 0.9752
Overfitting: 0.0833
Best model saved at epoch 2 with validation loss: 0.0833
[Epoch 3, Batch 100] loss: 0.06192352197598666
[Epoch 3, Batch 200] loss: 0.05730770476046018
[Epoch 3, Batch 300] loss: 0.06962080065510236
[Epoch 3, Batch 400] loss: 0.04615169201279059
[Epoch 3, Batch 500] loss: 0.04976341240835609
[Epoch 3, Batch 600] loss: 0.06220816439308692
[Epoch 3, Batch 700] loss: 0.06528250556846615
[Epoch 3, Batch 800] loss: 0.04924012569361366
[Epoch 3, Batch 900] loss: 0.05016452267722343
[Epoch 3, Batch 1000] loss: 0.06023380378494039
[Epoch 3, Batch 1100] loss: 0.07188812693784712
[Epoch 3, Batch 1200] loss: 0.04901746503892355
[Epoch 3, Batch 1300] loss: 0.08103019108209991
[Epoch 3, Batch 1400] loss: 0.06266541346849408
[Epoch 3, Batch 1500] loss: 0.06923298493493349
[Epoch 3, Batch 1600] loss: 0.06495366144750733
[Epoch 3, Batch 1700] loss: 0.06591489795217058
[Epoch 3, Batch 1800] loss: 0.07166846266482026
[Epoch 3, Batch 1900] loss: 0.06972330592077924
[Epoch 3, Batch 2000] loss: 0.07635340199572965
[Epoch 3, Batch 2100] loss: 0.05658361823298037
[Epoch 3, Batch 2200] loss: 0.06266037712455727
[Epoch 3, Batch 2300] loss: 0.04773628974508028
[Epoch 3, Batch 2400] loss: 0.04850008719309699
[Epoch 3, Batch 2500] loss: 0.0827024622540921
[Epoch 3, Batch 2600] loss: 0.05517120377917308
[Epoch 3, Batch 2700] loss: 0.05265217272739392
[Epoch 3, Batch 2800] loss: 0.039695985251746606
[Epoch 3, Batch 2900] loss: 0.060504062786058056
[Epoch 3, Batch 3000] loss: 0.052360414179129296
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0690
Validation Accuracy: 0.9788
Overfitting: 0.0690
Best model saved at epoch 3 with validation loss: 0.0690
[Epoch 4, Batch 100] loss: 0.03588678275293205
[Epoch 4, Batch 200] loss: 0.03605001814939897
[Epoch 4, Batch 300] loss: 0.03191492319689132
[Epoch 4, Batch 400] loss: 0.04724610168777872
[Epoch 4, Batch 500] loss: 0.04326071171904914
[Epoch 4, Batch 600] loss: 0.03260538260772591
[Epoch 4, Batch 700] loss: 0.05895804918240174
[Epoch 4, Batch 800] loss: 0.04292886462586466
[Epoch 4, Batch 900] loss: 0.0346064615996147
[Epoch 4, Batch 1000] loss: 0.04386244218389038
[Epoch 4, Batch 1100] loss: 0.03898188105609734
[Epoch 4, Batch 1200] loss: 0.05911912154551828
[Epoch 4, Batch 1300] loss: 0.05184950015369395
[Epoch 4, Batch 1400] loss: 0.0453516260375909
[Epoch 4, Batch 1500] loss: 0.054705839084926995
[Epoch 4, Batch 1600] loss: 0.04788837387604872
[Epoch 4, Batch 1700] loss: 0.05545550557464594
[Epoch 4, Batch 1800] loss: 0.03400782139768126
[Epoch 4, Batch 1900] loss: 0.03785172614327166
[Epoch 4, Batch 2000] loss: 0.056515436494955794
[Epoch 4, Batch 2100] loss: 0.03803297086633393
[Epoch 4, Batch 2200] loss: 0.03343233288149349
[Epoch 4, Batch 2300] loss: 0.06084989938957733
[Epoch 4, Batch 2400] loss: 0.04983832162572071
[Epoch 4, Batch 2500] loss: 0.05805933936251677
[Epoch 4, Batch 2600] loss: 0.036449170501146
[Epoch 4, Batch 2700] loss: 0.03434525408956688
[Epoch 4, Batch 2800] loss: 0.025021708839703935
[Epoch 4, Batch 2900] loss: 0.03979793710968806
[Epoch 4, Batch 3000] loss: 0.05713533442838525
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0594
Validation Accuracy: 0.9809
Overfitting: 0.0594
Best model saved at epoch 4 with validation loss: 0.0594
[Epoch 5, Batch 100] loss: 0.037727747663957416
[Epoch 5, Batch 200] loss: 0.03129321396263549
[Epoch 5, Batch 300] loss: 0.033521459661133124
[Epoch 5, Batch 400] loss: 0.02727643605117919
[Epoch 5, Batch 500] loss: 0.04473536789781065
[Epoch 5, Batch 600] loss: 0.0439170224533882
[Epoch 5, Batch 700] loss: 0.029149251933849884
[Epoch 5, Batch 800] loss: 0.04815242576718447
[Epoch 5, Batch 900] loss: 0.034134244379965824
[Epoch 5, Batch 1000] loss: 0.03430335301316518
[Epoch 5, Batch 1100] loss: 0.037835048711131095
[Epoch 5, Batch 1200] loss: 0.032857054623309526
[Epoch 5, Batch 1300] loss: 0.027837691835302394
[Epoch 5, Batch 1400] loss: 0.052805115033115725
[Epoch 5, Batch 1500] loss: 0.02490615212591365
[Epoch 5, Batch 1600] loss: 0.030570062424230854
[Epoch 5, Batch 1700] loss: 0.025523486151432736
[Epoch 5, Batch 1800] loss: 0.02996998855531274
[Epoch 5, Batch 1900] loss: 0.054433795662480404
[Epoch 5, Batch 2000] loss: 0.029557322117034344
[Epoch 5, Batch 2100] loss: 0.03469599541720527
[Epoch 5, Batch 2200] loss: 0.04439249857066898
[Epoch 5, Batch 2300] loss: 0.04476289805184933
[Epoch 5, Batch 2400] loss: 0.04060609669788391
[Epoch 5, Batch 2500] loss: 0.028185486414586194
[Epoch 5, Batch 2600] loss: 0.03409132723842049
[Epoch 5, Batch 2700] loss: 0.03118873177394562
[Epoch 5, Batch 2800] loss: 0.0330643318912189
[Epoch 5, Batch 2900] loss: 0.02884834941738518
[Epoch 5, Batch 3000] loss: 0.04972506387057365
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9826
Overfitting: 0.0564
Best model saved at epoch 5 with validation loss: 0.0564
[Epoch 6, Batch 100] loss: 0.0270499033662054
[Epoch 6, Batch 200] loss: 0.02118727585489978
[Epoch 6, Batch 300] loss: 0.03340752990901819
[Epoch 6, Batch 400] loss: 0.02506322928602458
[Epoch 6, Batch 500] loss: 0.025591126755862205
[Epoch 6, Batch 600] loss: 0.03662642840092303
[Epoch 6, Batch 700] loss: 0.01876337286477792
[Epoch 6, Batch 800] loss: 0.03644514905303367
[Epoch 6, Batch 900] loss: 0.03185140640805912
[Epoch 6, Batch 1000] loss: 0.03167799854010809
[Epoch 6, Batch 1100] loss: 0.028592634745000397
[Epoch 6, Batch 1200] loss: 0.025314678682989325
[Epoch 6, Batch 1300] loss: 0.026486964817740953
[Epoch 6, Batch 1400] loss: 0.024238074558234075
[Epoch 6, Batch 1500] loss: 0.015159876473999247
[Epoch 6, Batch 1600] loss: 0.045179623936055575
[Epoch 6, Batch 1700] loss: 0.032172639468990384
[Epoch 6, Batch 1800] loss: 0.034088495606847576
[Epoch 6, Batch 1900] loss: 0.02982889117718514
[Epoch 6, Batch 2000] loss: 0.014303580797950417
[Epoch 6, Batch 2100] loss: 0.03361776718691544
[Epoch 6, Batch 2200] loss: 0.04101132283365587
[Epoch 6, Batch 2300] loss: 0.03791242398743634
[Epoch 6, Batch 2400] loss: 0.024648565476600198
[Epoch 6, Batch 2500] loss: 0.023603059658780692
[Epoch 6, Batch 2600] loss: 0.023135159502235183
[Epoch 6, Batch 2700] loss: 0.03213218753513502
[Epoch 6, Batch 2800] loss: 0.037013819630155924
[Epoch 6, Batch 2900] loss: 0.02714324147789739
[Epoch 6, Batch 3000] loss: 0.016624616870903993
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0517
Validation Accuracy: 0.9835
Overfitting: 0.0517
Best model saved at epoch 6 with validation loss: 0.0517
[Epoch 7, Batch 100] loss: 0.018164941593167897
[Epoch 7, Batch 200] loss: 0.02109321442330838
[Epoch 7, Batch 300] loss: 0.02415347534693865
[Epoch 7, Batch 400] loss: 0.027593129458837212
[Epoch 7, Batch 500] loss: 0.015898574205930344
[Epoch 7, Batch 600] loss: 0.023400225963123376
[Epoch 7, Batch 700] loss: 0.02671521532953193
[Epoch 7, Batch 800] loss: 0.03202723402042466
[Epoch 7, Batch 900] loss: 0.02136591105707339
[Epoch 7, Batch 1000] loss: 0.017388095772657833
[Epoch 7, Batch 1100] loss: 0.016501188248184917
[Epoch 7, Batch 1200] loss: 0.025285397409097642
[Epoch 7, Batch 1300] loss: 0.027025880604123812
[Epoch 7, Batch 1400] loss: 0.028451894171739697
[Epoch 7, Batch 1500] loss: 0.010294847918994493
[Epoch 7, Batch 1600] loss: 0.0258080637659441
[Epoch 7, Batch 1700] loss: 0.021408751378257877
[Epoch 7, Batch 1800] loss: 0.014803676415594965
[Epoch 7, Batch 1900] loss: 0.027717847646599694
[Epoch 7, Batch 2000] loss: 0.027066172514823846
[Epoch 7, Batch 2100] loss: 0.017319488932298555
[Epoch 7, Batch 2200] loss: 0.03287478531816305
[Epoch 7, Batch 2300] loss: 0.02397904686462425
[Epoch 7, Batch 2400] loss: 0.022676417147740723
[Epoch 7, Batch 2500] loss: 0.02259137955847109
[Epoch 7, Batch 2600] loss: 0.029259207993145537
[Epoch 7, Batch 2700] loss: 0.021252057875681202
[Epoch 7, Batch 2800] loss: 0.02331023013246522
[Epoch 7, Batch 2900] loss: 0.02520210052443872
[Epoch 7, Batch 3000] loss: 0.027780358882409928
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0530
Validation Accuracy: 0.9856
Overfitting: 0.0530
[Epoch 8, Batch 100] loss: 0.013131222113170225
[Epoch 8, Batch 200] loss: 0.017265889190966846
[Epoch 8, Batch 300] loss: 0.011217228347195487
[Epoch 8, Batch 400] loss: 0.017411322128336907
[Epoch 8, Batch 500] loss: 0.017851698127224154
[Epoch 8, Batch 600] loss: 0.011962801435856818
[Epoch 8, Batch 700] loss: 0.017146293916357535
[Epoch 8, Batch 800] loss: 0.024695659081144187
[Epoch 8, Batch 900] loss: 0.009130933504238783
[Epoch 8, Batch 1000] loss: 0.01946359145193128
[Epoch 8, Batch 1100] loss: 0.02526977203473507
[Epoch 8, Batch 1200] loss: 0.020789675102182627
[Epoch 8, Batch 1300] loss: 0.019151232385411276
[Epoch 8, Batch 1400] loss: 0.02279680860501685
[Epoch 8, Batch 1500] loss: 0.024482698813735625
[Epoch 8, Batch 1600] loss: 0.021431285325525094
[Epoch 8, Batch 1700] loss: 0.019931213224772364
[Epoch 8, Batch 1800] loss: 0.01672624424259993
[Epoch 8, Batch 1900] loss: 0.01972088323203934
[Epoch 8, Batch 2000] loss: 0.01229933892031113
[Epoch 8, Batch 2100] loss: 0.023635419850297695
[Epoch 8, Batch 2200] loss: 0.028204779684765525
[Epoch 8, Batch 2300] loss: 0.017131949387294298
[Epoch 8, Batch 2400] loss: 0.013579813824044322
[Epoch 8, Batch 2500] loss: 0.013910526988256606
[Epoch 8, Batch 2600] loss: 0.03378451572272752
[Epoch 8, Batch 2700] loss: 0.01640054019939271
[Epoch 8, Batch 2800] loss: 0.02417561837559333
[Epoch 8, Batch 2900] loss: 0.02321563052450074
[Epoch 8, Batch 3000] loss: 0.021801510596778827
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9853
Overfitting: 0.0524
[Epoch 9, Batch 100] loss: 0.019093921277271875
[Epoch 9, Batch 200] loss: 0.01920977543664776
[Epoch 9, Batch 300] loss: 0.010477326490763517
[Epoch 9, Batch 400] loss: 0.019474609197432075
[Epoch 9, Batch 500] loss: 0.012247686156606506
[Epoch 9, Batch 600] loss: 0.017856669352850078
[Epoch 9, Batch 700] loss: 0.015728716774974602
[Epoch 9, Batch 800] loss: 0.014163265525294264
[Epoch 9, Batch 900] loss: 0.00967870402180779
[Epoch 9, Batch 1000] loss: 0.010925937374368004
[Epoch 9, Batch 1100] loss: 0.007222641265789207
[Epoch 9, Batch 1200] loss: 0.01992225942585719
[Epoch 9, Batch 1300] loss: 0.009691153288313216
[Epoch 9, Batch 1400] loss: 0.008273605094054802
[Epoch 9, Batch 1500] loss: 0.013226726600350958
[Epoch 9, Batch 1600] loss: 0.015535117010740578
[Epoch 9, Batch 1700] loss: 0.033055201690795004
[Epoch 9, Batch 1800] loss: 0.019386666403306663
[Epoch 9, Batch 1900] loss: 0.019651802999069334
[Epoch 9, Batch 2000] loss: 0.010672897119818572
[Epoch 9, Batch 2100] loss: 0.01655321780887789
[Epoch 9, Batch 2200] loss: 0.016485404408704198
[Epoch 9, Batch 2300] loss: 0.011750872517914103
[Epoch 9, Batch 2400] loss: 0.014308669611182268
[Epoch 9, Batch 2500] loss: 0.014334121725405567
[Epoch 9, Batch 2600] loss: 0.02096473170002355
[Epoch 9, Batch 2700] loss: 0.021009903030271743
[Epoch 9, Batch 2800] loss: 0.01631272826853092
[Epoch 9, Batch 2900] loss: 0.016802080771099098
[Epoch 9, Batch 3000] loss: 0.02916695114969116
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9866
Overfitting: 0.0508
Best model saved at epoch 9 with validation loss: 0.0508
[Epoch 10, Batch 100] loss: 0.019423306033095288
[Epoch 10, Batch 200] loss: 0.009147787262972997
[Epoch 10, Batch 300] loss: 0.004859637153494987
[Epoch 10, Batch 400] loss: 0.017108627923103085
[Epoch 10, Batch 500] loss: 0.010062096257197482
[Epoch 10, Batch 600] loss: 0.007785755136228545
[Epoch 10, Batch 700] loss: 0.024090915855922504
[Epoch 10, Batch 800] loss: 0.007713886493220344
[Epoch 10, Batch 900] loss: 0.017309967013170537
[Epoch 10, Batch 1000] loss: 0.01754804404963579
[Epoch 10, Batch 1100] loss: 0.011664027416172758
[Epoch 10, Batch 1200] loss: 0.023224317334734224
[Epoch 10, Batch 1300] loss: 0.010842030801813961
[Epoch 10, Batch 1400] loss: 0.010636215984623049
[Epoch 10, Batch 1500] loss: 0.018511354845522875
[Epoch 10, Batch 1600] loss: 0.009747586549692641
[Epoch 10, Batch 1700] loss: 0.015222001040045825
[Epoch 10, Batch 1800] loss: 0.018794282227045187
[Epoch 10, Batch 1900] loss: 0.014046815518418044
[Epoch 10, Batch 2000] loss: 0.01228134658138515
[Epoch 10, Batch 2100] loss: 0.011225196133373173
[Epoch 10, Batch 2200] loss: 0.02021635642757701
[Epoch 10, Batch 2300] loss: 0.019253469343439064
[Epoch 10, Batch 2400] loss: 0.014315408487154855
[Epoch 10, Batch 2500] loss: 0.009601055245911993
[Epoch 10, Batch 2600] loss: 0.024172191597372147
[Epoch 10, Batch 2700] loss: 0.015452113316478062
[Epoch 10, Batch 2800] loss: 0.012317873299596159
[Epoch 10, Batch 2900] loss: 0.018747159726681274
[Epoch 10, Batch 3000] loss: 0.008556497937320273
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9860
Overfitting: 0.0518
[Epoch 11, Batch 100] loss: 0.013107349885613075
[Epoch 11, Batch 200] loss: 0.01621004844181698
[Epoch 11, Batch 300] loss: 0.009600213948733654
[Epoch 11, Batch 400] loss: 0.01071091296911618
[Epoch 11, Batch 500] loss: 0.013522440517364202
[Epoch 11, Batch 600] loss: 0.008264329952257867
[Epoch 11, Batch 700] loss: 0.00818025397875317
[Epoch 11, Batch 800] loss: 0.01597844591255807
[Epoch 11, Batch 900] loss: 0.009461447182176244
[Epoch 11, Batch 1000] loss: 0.004600062156305285
[Epoch 11, Batch 1100] loss: 0.011738821784356333
[Epoch 11, Batch 1200] loss: 0.011665948888366983
[Epoch 11, Batch 1300] loss: 0.016736219886970504
[Epoch 11, Batch 1400] loss: 0.00648879365933908
[Epoch 11, Batch 1500] loss: 0.00990104068441724
[Epoch 11, Batch 1600] loss: 0.02248106579308569
[Epoch 11, Batch 1700] loss: 0.006927376926405486
[Epoch 11, Batch 1800] loss: 0.01621749388110402
[Epoch 11, Batch 1900] loss: 0.012076106412914669
[Epoch 11, Batch 2000] loss: 0.018236175951026324
[Epoch 11, Batch 2100] loss: 0.017455093826383744
[Epoch 11, Batch 2200] loss: 0.013480779434939905
[Epoch 11, Batch 2300] loss: 0.011964405544808869
[Epoch 11, Batch 2400] loss: 0.013554342821589672
[Epoch 11, Batch 2500] loss: 0.020464710024114083
[Epoch 11, Batch 2600] loss: 0.015436833465519157
[Epoch 11, Batch 2700] loss: 0.005509451484722376
[Epoch 11, Batch 2800] loss: 0.012504640649431166
[Epoch 11, Batch 2900] loss: 0.012727151287208471
[Epoch 11, Batch 3000] loss: 0.01609461284705503
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0597
Validation Accuracy: 0.9851
Overfitting: 0.0597
[Epoch 12, Batch 100] loss: 0.004733986261608152
[Epoch 12, Batch 200] loss: 0.009996451445935577
[Epoch 12, Batch 300] loss: 0.00832753340686395
[Epoch 12, Batch 400] loss: 0.011046402569845667
[Epoch 12, Batch 500] loss: 0.00732585265102216
[Epoch 12, Batch 600] loss: 0.004497708694243556
[Epoch 12, Batch 700] loss: 0.006232739500269417
[Epoch 12, Batch 800] loss: 0.012739177911544174
[Epoch 12, Batch 900] loss: 0.010905153288604197
[Epoch 12, Batch 1000] loss: 0.008525669909131466
[Epoch 12, Batch 1100] loss: 0.012525520409153614
[Epoch 12, Batch 1200] loss: 0.011292131304223858
[Epoch 12, Batch 1300] loss: 0.008928798340252796
[Epoch 12, Batch 1400] loss: 0.015285882684815988
[Epoch 12, Batch 1500] loss: 0.011720837530749578
[Epoch 12, Batch 1600] loss: 0.011626863796366252
[Epoch 12, Batch 1700] loss: 0.009260434882498884
[Epoch 12, Batch 1800] loss: 0.014629569784953276
[Epoch 12, Batch 1900] loss: 0.015350728543049854
[Epoch 12, Batch 2000] loss: 0.02222862014153179
[Epoch 12, Batch 2100] loss: 0.00858421077354251
[Epoch 12, Batch 2200] loss: 0.003896182982771279
[Epoch 12, Batch 2300] loss: 0.015214045205639196
[Epoch 12, Batch 2400] loss: 0.014058882079095837
[Epoch 12, Batch 2500] loss: 0.012291944064777453
[Epoch 12, Batch 2600] loss: 0.005990799036417229
[Epoch 12, Batch 2700] loss: 0.011948984754271806
[Epoch 12, Batch 2800] loss: 0.017104061084392014
[Epoch 12, Batch 2900] loss: 0.017028395092311258
[Epoch 12, Batch 3000] loss: 0.014512517234934422
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9856
Overfitting: 0.0581
[Epoch 13, Batch 100] loss: 0.007718630944086726
[Epoch 13, Batch 200] loss: 0.00728025041778892
[Epoch 13, Batch 300] loss: 0.005582330458964862
[Epoch 13, Batch 400] loss: 0.007407759915847692
[Epoch 13, Batch 500] loss: 0.003828007129930029
[Epoch 13, Batch 600] loss: 0.006915711316928537
[Epoch 13, Batch 700] loss: 0.015340857438063722
[Epoch 13, Batch 800] loss: 0.012596370695875976
[Epoch 13, Batch 900] loss: 0.008502362089263898
[Epoch 13, Batch 1000] loss: 0.0035590674947772525
[Epoch 13, Batch 1100] loss: 0.017918142282081818
[Epoch 13, Batch 1200] loss: 0.01227253894532396
[Epoch 13, Batch 1300] loss: 0.005323066861189432
[Epoch 13, Batch 1400] loss: 0.009961969810643723
[Epoch 13, Batch 1500] loss: 0.01135150534001923
[Epoch 13, Batch 1600] loss: 0.0074902799687561125
[Epoch 13, Batch 1700] loss: 0.009146999248450811
[Epoch 13, Batch 1800] loss: 0.022517107765377204
[Epoch 13, Batch 1900] loss: 0.006873852936714684
[Epoch 13, Batch 2000] loss: 0.004474385606608848
[Epoch 13, Batch 2100] loss: 0.005955149700321271
[Epoch 13, Batch 2200] loss: 0.006203819556997132
[Epoch 13, Batch 2300] loss: 0.010180736944565751
[Epoch 13, Batch 2400] loss: 0.0038262485375923916
[Epoch 13, Batch 2500] loss: 0.0017547333025092371
[Epoch 13, Batch 2600] loss: 0.006972357385009218
[Epoch 13, Batch 2700] loss: 0.007200524993884301
[Epoch 13, Batch 2800] loss: 0.010641581822508784
[Epoch 13, Batch 2900] loss: 0.011278764391283858
[Epoch 13, Batch 3000] loss: 0.017663523828784947
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9868
Overfitting: 0.0542
[Epoch 14, Batch 100] loss: 0.005272888338356552
[Epoch 14, Batch 200] loss: 0.008836605169736913
[Epoch 14, Batch 300] loss: 0.0038277162686824796
[Epoch 14, Batch 400] loss: 0.006183644364523388
[Epoch 14, Batch 500] loss: 0.009140626502995132
[Epoch 14, Batch 600] loss: 0.003430760803432804
[Epoch 14, Batch 700] loss: 0.004204152375486956
[Epoch 14, Batch 800] loss: 0.003297737597708874
[Epoch 14, Batch 900] loss: 0.0043884059860306475
[Epoch 14, Batch 1000] loss: 0.00555229263713727
[Epoch 14, Batch 1100] loss: 0.008048031901747094
[Epoch 14, Batch 1200] loss: 0.006045041331578887
[Epoch 14, Batch 1300] loss: 0.006513019733488363
[Epoch 14, Batch 1400] loss: 0.003778219048142546
[Epoch 14, Batch 1500] loss: 0.002206508681221067
[Epoch 14, Batch 1600] loss: 0.004984857495802828
[Epoch 14, Batch 1700] loss: 0.004308352500852947
[Epoch 14, Batch 1800] loss: 0.007165619395036629
[Epoch 14, Batch 1900] loss: 0.005955467616322494
[Epoch 14, Batch 2000] loss: 0.012569917192722642
[Epoch 14, Batch 2100] loss: 0.01040066430616207
[Epoch 14, Batch 2200] loss: 0.007450138204703762
[Epoch 14, Batch 2300] loss: 0.009136225147908022
[Epoch 14, Batch 2400] loss: 0.009120057567308777
[Epoch 14, Batch 2500] loss: 0.0158836189487306
[Epoch 14, Batch 2600] loss: 0.016075769797386102
[Epoch 14, Batch 2700] loss: 0.004156890884597714
[Epoch 14, Batch 2800] loss: 0.008381792404148882
[Epoch 14, Batch 2900] loss: 0.016036970758208327
[Epoch 14, Batch 3000] loss: 0.007765945993036212
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9855
Overfitting: 0.0586
[Epoch 15, Batch 100] loss: 0.004520825559814057
[Epoch 15, Batch 200] loss: 0.00965599179983542
[Epoch 15, Batch 300] loss: 0.003475140382801953
[Epoch 15, Batch 400] loss: 0.007456331430080354
[Epoch 15, Batch 500] loss: 0.006748631557445606
[Epoch 15, Batch 600] loss: 0.00930542585116882
[Epoch 15, Batch 700] loss: 0.00446470445483385
[Epoch 15, Batch 800] loss: 0.0037787378373553794
[Epoch 15, Batch 900] loss: 0.003974651056419702
[Epoch 15, Batch 1000] loss: 0.004027954408535379
[Epoch 15, Batch 1100] loss: 0.0043617406927710075
[Epoch 15, Batch 1200] loss: 0.005392758608566055
[Epoch 15, Batch 1300] loss: 0.004661032059129582
[Epoch 15, Batch 1400] loss: 0.008557530748314548
[Epoch 15, Batch 1500] loss: 0.008098109702495719
[Epoch 15, Batch 1600] loss: 0.006415384684426044
[Epoch 15, Batch 1700] loss: 0.008185613662420224
[Epoch 15, Batch 1800] loss: 0.008653235600353354
[Epoch 15, Batch 1900] loss: 0.008019720338314471
[Epoch 15, Batch 2000] loss: 0.009753299631706796
[Epoch 15, Batch 2100] loss: 0.009086796833062181
[Epoch 15, Batch 2200] loss: 0.007887677031876593
[Epoch 15, Batch 2300] loss: 0.0031570021665385186
[Epoch 15, Batch 2400] loss: 0.00400402574610709
[Epoch 15, Batch 2500] loss: 0.003313760040345528
[Epoch 15, Batch 2600] loss: 0.003240841519316291
[Epoch 15, Batch 2700] loss: 0.002034835333759872
[Epoch 15, Batch 2800] loss: 0.0024702561714843086
[Epoch 15, Batch 2900] loss: 0.002487563221828282
[Epoch 15, Batch 3000] loss: 0.006941409905992373
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0622
Validation Accuracy: 0.9868
Overfitting: 0.0622
[Epoch 16, Batch 100] loss: 0.008287502134331532
[Epoch 16, Batch 200] loss: 0.002168395474974432
[Epoch 16, Batch 300] loss: 0.0016580301346952099
[Epoch 16, Batch 400] loss: 0.0026909762423372287
[Epoch 16, Batch 500] loss: 0.001458167261864105
[Epoch 16, Batch 600] loss: 0.0027017425593197685
[Epoch 16, Batch 700] loss: 0.002226415861892406
[Epoch 16, Batch 800] loss: 0.004066454161758202
[Epoch 16, Batch 900] loss: 0.002595478414214227
[Epoch 16, Batch 1000] loss: 0.0014041548585652208
[Epoch 16, Batch 1100] loss: 0.0055925651740702164
[Epoch 16, Batch 1200] loss: 0.006270920877759032
[Epoch 16, Batch 1300] loss: 0.004376748954675733
[Epoch 16, Batch 1400] loss: 0.004827445922775837
[Epoch 16, Batch 1500] loss: 0.008986803116740135
[Epoch 16, Batch 1600] loss: 0.004493924133113758
[Epoch 16, Batch 1700] loss: 0.0065755725706122805
[Epoch 16, Batch 1800] loss: 0.0038648246071539914
[Epoch 16, Batch 1900] loss: 0.005909432018867165
[Epoch 16, Batch 2000] loss: 0.0020616098111479173
[Epoch 16, Batch 2100] loss: 0.004829284110649325
[Epoch 16, Batch 2200] loss: 0.003000628918313737
[Epoch 16, Batch 2300] loss: 0.001448744347443025
[Epoch 16, Batch 2400] loss: 0.004299117672610748
[Epoch 16, Batch 2500] loss: 0.015502258980317834
[Epoch 16, Batch 2600] loss: 0.0058901223247443115
[Epoch 16, Batch 2700] loss: 0.015387295845433257
[Epoch 16, Batch 2800] loss: 0.004977988692583608
[Epoch 16, Batch 2900] loss: 0.008462277302781445
[Epoch 16, Batch 3000] loss: 0.008557283442625874
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9852
Overfitting: 0.0632
[Epoch 17, Batch 100] loss: 0.009805295257104376
[Epoch 17, Batch 200] loss: 0.007718980798656503
[Epoch 17, Batch 300] loss: 0.0037973727438770765
[Epoch 17, Batch 400] loss: 0.0036620010648675816
[Epoch 17, Batch 500] loss: 0.003226029612668526
[Epoch 17, Batch 600] loss: 0.0023651119584314983
[Epoch 17, Batch 700] loss: 0.005816648699374127
[Epoch 17, Batch 800] loss: 0.0017833332885618348
[Epoch 17, Batch 900] loss: 0.0039036340006401815
[Epoch 17, Batch 1000] loss: 0.005528605534903903
[Epoch 17, Batch 1100] loss: 0.004218087152209477
[Epoch 17, Batch 1200] loss: 0.01217009749762667
[Epoch 17, Batch 1300] loss: 0.008525971678893143
[Epoch 17, Batch 1400] loss: 0.003256043804651512
[Epoch 17, Batch 1500] loss: 0.008953743690498754
[Epoch 17, Batch 1600] loss: 0.0035773739108219617
[Epoch 17, Batch 1700] loss: 0.01604009380661033
[Epoch 17, Batch 1800] loss: 0.0063895992154581905
[Epoch 17, Batch 1900] loss: 0.003752687148540872
[Epoch 17, Batch 2000] loss: 0.006505166563902094
[Epoch 17, Batch 2100] loss: 0.0037083102480562503
[Epoch 17, Batch 2200] loss: 0.0029916456347183385
[Epoch 17, Batch 2300] loss: 0.011445958298395453
[Epoch 17, Batch 2400] loss: 0.002594395867737944
[Epoch 17, Batch 2500] loss: 0.011947959455328592
[Epoch 17, Batch 2600] loss: 0.014509127369603903
[Epoch 17, Batch 2700] loss: 0.006881588446308342
[Epoch 17, Batch 2800] loss: 0.011310718896228877
[Epoch 17, Batch 2900] loss: 0.00420408412109623
[Epoch 17, Batch 3000] loss: 0.0024955986936367937
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9880
Overfitting: 0.0552
[Epoch 18, Batch 100] loss: 0.002168470581594306
[Epoch 18, Batch 200] loss: 0.0009955028771383922
[Epoch 18, Batch 300] loss: 0.0016811618982768195
[Epoch 18, Batch 400] loss: 0.0010875610373335576
[Epoch 18, Batch 500] loss: 0.006084331309110098
[Epoch 18, Batch 600] loss: 0.0029849829950134676
[Epoch 18, Batch 700] loss: 0.0010254564031490076
[Epoch 18, Batch 800] loss: 0.00468473025529363
[Epoch 18, Batch 900] loss: 0.002306359710754293
[Epoch 18, Batch 1000] loss: 0.0030050185952163132
[Epoch 18, Batch 1100] loss: 0.0013412558016314335
[Epoch 18, Batch 1200] loss: 0.001904101913275653
[Epoch 18, Batch 1300] loss: 0.002773327267836372
[Epoch 18, Batch 1400] loss: 0.003599576558234503
[Epoch 18, Batch 1500] loss: 0.006066213567080041
[Epoch 18, Batch 1600] loss: 0.0023558313865791546
[Epoch 18, Batch 1700] loss: 0.0018270574582388121
[Epoch 18, Batch 1800] loss: 0.0021054766851385407
[Epoch 18, Batch 1900] loss: 0.007943489550245885
[Epoch 18, Batch 2000] loss: 0.021595739752811483
[Epoch 18, Batch 2100] loss: 0.006550911839408382
[Epoch 18, Batch 2200] loss: 0.011452602129685375
[Epoch 18, Batch 2300] loss: 0.010911108041402712
[Epoch 18, Batch 2400] loss: 0.0147271229253775
[Epoch 18, Batch 2500] loss: 0.00298913690987888
[Epoch 18, Batch 2600] loss: 0.008282175774229756
[Epoch 18, Batch 2700] loss: 0.0029071085914900508
[Epoch 18, Batch 2800] loss: 0.007249775846726933
[Epoch 18, Batch 2900] loss: 0.0029101317849199405
[Epoch 18, Batch 3000] loss: 0.002998896330742724
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0625
Validation Accuracy: 0.9869
Overfitting: 0.0625
[Epoch 19, Batch 100] loss: 0.0020130239066876144
[Epoch 19, Batch 200] loss: 0.004308797564524909
[Epoch 19, Batch 300] loss: 0.003500676001780221
[Epoch 19, Batch 400] loss: 0.0032851736624317594
[Epoch 19, Batch 500] loss: 0.0013901595523176978
[Epoch 19, Batch 600] loss: 0.0009817370728217156
[Epoch 19, Batch 700] loss: 0.0022458045975135123
[Epoch 19, Batch 800] loss: 0.0013420838503621724
[Epoch 19, Batch 900] loss: 0.0004356116388142084
[Epoch 19, Batch 1000] loss: 0.0022408729424282115
[Epoch 19, Batch 1100] loss: 0.0020838922700408304
[Epoch 19, Batch 1200] loss: 0.0016950431246867481
[Epoch 19, Batch 1300] loss: 0.004758032519311186
[Epoch 19, Batch 1400] loss: 0.004825926280566364
[Epoch 19, Batch 1500] loss: 0.00115574338335108
[Epoch 19, Batch 1600] loss: 0.0011142933171264247
[Epoch 19, Batch 1700] loss: 0.0006773551283501434
[Epoch 19, Batch 1800] loss: 0.000668296958845076
[Epoch 19, Batch 1900] loss: 0.0011853242201296155
[Epoch 19, Batch 2000] loss: 0.004271928234247327
[Epoch 19, Batch 2100] loss: 0.003843339178132972
[Epoch 19, Batch 2200] loss: 0.0012574488109828507
[Epoch 19, Batch 2300] loss: 0.0021897785257330325
[Epoch 19, Batch 2400] loss: 0.002987706854271046
[Epoch 19, Batch 2500] loss: 0.011543245719012702
[Epoch 19, Batch 2600] loss: 0.003506169735748301
[Epoch 19, Batch 2700] loss: 0.002138651714744313
[Epoch 19, Batch 2800] loss: 0.002094095494194761
[Epoch 19, Batch 2900] loss: 0.0010829516247758875
[Epoch 19, Batch 3000] loss: 0.003232036382733834
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0669
Validation Accuracy: 0.9864
Overfitting: 0.0669
[Epoch 20, Batch 100] loss: 0.002651939781294459
[Epoch 20, Batch 200] loss: 0.004079907981904398
[Epoch 20, Batch 300] loss: 0.00199673309498122
[Epoch 20, Batch 400] loss: 0.0008079172676254842
[Epoch 20, Batch 500] loss: 0.0016001080624037734
[Epoch 20, Batch 600] loss: 0.0016908113414766035
[Epoch 20, Batch 700] loss: 0.000946782247920197
[Epoch 20, Batch 800] loss: 0.0011820116738974918
[Epoch 20, Batch 900] loss: 0.00046498749613412384
[Epoch 20, Batch 1000] loss: 0.0030574084369098388
[Epoch 20, Batch 1100] loss: 0.002049719183568186
[Epoch 20, Batch 1200] loss: 0.001674446557025604
[Epoch 20, Batch 1300] loss: 0.0005708067217915413
[Epoch 20, Batch 1400] loss: 0.0028549384522332842
[Epoch 20, Batch 1500] loss: 0.0011019729318503834
[Epoch 20, Batch 1600] loss: 0.004375048288987529
[Epoch 20, Batch 1700] loss: 0.0022888015682316974
[Epoch 20, Batch 1800] loss: 0.002393303561391198
[Epoch 20, Batch 1900] loss: 0.002272693326987927
[Epoch 20, Batch 2000] loss: 0.0033157098387379545
[Epoch 20, Batch 2100] loss: 0.0036924029453105334
[Epoch 20, Batch 2200] loss: 0.0027546502881315503
[Epoch 20, Batch 2300] loss: 0.0006764285029586858
[Epoch 20, Batch 2400] loss: 0.0011172297577858358
[Epoch 20, Batch 2500] loss: 0.0057059623371434305
[Epoch 20, Batch 2600] loss: 0.0032438886703721435
[Epoch 20, Batch 2700] loss: 0.005845662207538984
[Epoch 20, Batch 2800] loss: 0.0030670522380569307
[Epoch 20, Batch 2900] loss: 0.0016624577734619095
[Epoch 20, Batch 3000] loss: 0.0011832993288750826
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0594
Validation Accuracy: 0.9874
Overfitting: 0.0594
[Epoch 21, Batch 100] loss: 0.0021752025439550236
[Epoch 21, Batch 200] loss: 0.0007430466893973087
[Epoch 21, Batch 300] loss: 0.0004428310611872277
[Epoch 21, Batch 400] loss: 0.000769690285662783
[Epoch 21, Batch 500] loss: 0.0008081596108135259
[Epoch 21, Batch 600] loss: 0.0008790017657139515
[Epoch 21, Batch 700] loss: 0.0018137781541616605
[Epoch 21, Batch 800] loss: 0.0010350130834709858
[Epoch 21, Batch 900] loss: 0.001006234316668042
[Epoch 21, Batch 1000] loss: 0.0010764782460372401
[Epoch 21, Batch 1100] loss: 0.0023932906563282684
[Epoch 21, Batch 1200] loss: 0.0014817551950451245
[Epoch 21, Batch 1300] loss: 0.0017710626645573058
[Epoch 21, Batch 1400] loss: 0.0004941619293641963
[Epoch 21, Batch 1500] loss: 0.0015039162730790911
[Epoch 21, Batch 1600] loss: 0.005633050778597948
[Epoch 21, Batch 1700] loss: 0.0009641865852662823
[Epoch 21, Batch 1800] loss: 0.001209241922456874
[Epoch 21, Batch 1900] loss: 0.0013646698016624014
[Epoch 21, Batch 2000] loss: 0.0002775555701218302
[Epoch 21, Batch 2100] loss: 0.0005355039173001997
[Epoch 21, Batch 2200] loss: 0.0004103938387019213
[Epoch 21, Batch 2300] loss: 0.000811203012999755
[Epoch 21, Batch 2400] loss: 0.0007862151130848005
[Epoch 21, Batch 2500] loss: 0.00046309467419663797
[Epoch 21, Batch 2600] loss: 0.0009192743558783789
[Epoch 21, Batch 2700] loss: 0.0004866997401931883
[Epoch 21, Batch 2800] loss: 0.0005157642035273114
[Epoch 21, Batch 2900] loss: 0.0004865646798590717
[Epoch 21, Batch 3000] loss: 0.000918350106215371
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9882
Overfitting: 0.0608
[Epoch 22, Batch 100] loss: 0.0005125421564325538
[Epoch 22, Batch 200] loss: 0.0015854041057180978
[Epoch 22, Batch 300] loss: 0.0024107220835434618
[Epoch 22, Batch 400] loss: 0.0029498522790323634
[Epoch 22, Batch 500] loss: 0.000656873772425306
[Epoch 22, Batch 600] loss: 0.0009556755190095912
[Epoch 22, Batch 700] loss: 0.0006151089456783687
[Epoch 22, Batch 800] loss: 0.0009039505406329518
[Epoch 22, Batch 900] loss: 0.005687273996927327
[Epoch 22, Batch 1000] loss: 0.005041385257358782
[Epoch 22, Batch 1100] loss: 0.004700950273114212
[Epoch 22, Batch 1200] loss: 0.0012762645616701995
[Epoch 22, Batch 1300] loss: 0.0005462053635591912
[Epoch 22, Batch 1400] loss: 0.0030427250454108145
[Epoch 22, Batch 1500] loss: 0.0014525386270580042
[Epoch 22, Batch 1600] loss: 0.0006920682946670898
[Epoch 22, Batch 1700] loss: 0.0011673130549720323
[Epoch 22, Batch 1800] loss: 0.0020534393823251618
[Epoch 22, Batch 1900] loss: 0.0007123725383062585
[Epoch 22, Batch 2000] loss: 0.0007478677860371885
[Epoch 22, Batch 2100] loss: 0.0025410390410228966
[Epoch 22, Batch 2200] loss: 0.0025212885699339616
[Epoch 22, Batch 2300] loss: 0.002539610794632026
[Epoch 22, Batch 2400] loss: 0.0007523247004746736
[Epoch 22, Batch 2500] loss: 0.001050721131246064
[Epoch 22, Batch 2600] loss: 0.0011601095452762422
[Epoch 22, Batch 2700] loss: 0.0019326476913702972
[Epoch 22, Batch 2800] loss: 0.005108270382664486
[Epoch 22, Batch 2900] loss: 0.010726330117218765
[Epoch 22, Batch 3000] loss: 0.006532093209842173
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0937
Validation Accuracy: 0.9812
Overfitting: 0.0937
[Epoch 23, Batch 100] loss: 0.0042161748797930445
[Epoch 23, Batch 200] loss: 0.0007404672874421436
[Epoch 23, Batch 300] loss: 0.0005406425837967177
[Epoch 23, Batch 400] loss: 0.00046682908584468665
[Epoch 23, Batch 500] loss: 0.0010680029953422476
[Epoch 23, Batch 600] loss: 0.0007901330288638775
[Epoch 23, Batch 700] loss: 0.002273617438848472
[Epoch 23, Batch 800] loss: 0.0031837465539355492
[Epoch 23, Batch 900] loss: 0.0004892543687820439
[Epoch 23, Batch 1000] loss: 0.0006141630898882955
[Epoch 23, Batch 1100] loss: 0.0021036536545071625
[Epoch 23, Batch 1200] loss: 0.0014633955032690516
[Epoch 23, Batch 1300] loss: 0.0006446573587073345
[Epoch 23, Batch 1400] loss: 0.0023561964248979762
[Epoch 23, Batch 1500] loss: 0.001780742217835134
[Epoch 23, Batch 1600] loss: 0.002221041286221315
[Epoch 23, Batch 1700] loss: 0.008819343165986595
[Epoch 23, Batch 1800] loss: 0.0010665283656129398
[Epoch 23, Batch 1900] loss: 0.001114218238486977
[Epoch 23, Batch 2000] loss: 0.002489278596547151
[Epoch 23, Batch 2100] loss: 0.003930983316134289
[Epoch 23, Batch 2200] loss: 0.002984825646967586
[Epoch 23, Batch 2300] loss: 0.0019932901902479116
[Epoch 23, Batch 2400] loss: 0.002650974930773855
[Epoch 23, Batch 2500] loss: 0.002078694168027724
[Epoch 23, Batch 2600] loss: 0.0014907522176182074
[Epoch 23, Batch 2700] loss: 0.002163155500731455
[Epoch 23, Batch 2800] loss: 0.0012870205431150029
[Epoch 23, Batch 2900] loss: 0.00040856998908228803
[Epoch 23, Batch 3000] loss: 0.0013148567104702912
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0609
Validation Accuracy: 0.9879
Overfitting: 0.0609
[Epoch 24, Batch 100] loss: 0.0010845574224285094
[Epoch 24, Batch 200] loss: 0.0023401839717871998
[Epoch 24, Batch 300] loss: 0.00035544160513193644
[Epoch 24, Batch 400] loss: 0.008468171108847638
[Epoch 24, Batch 500] loss: 0.0006468852381404134
[Epoch 24, Batch 600] loss: 0.0008678307732240498
[Epoch 24, Batch 700] loss: 0.0006443501952082186
[Epoch 24, Batch 800] loss: 0.000827016291681062
[Epoch 24, Batch 900] loss: 0.0003552769688982016
[Epoch 24, Batch 1000] loss: 0.0005667070964594156
[Epoch 24, Batch 1100] loss: 0.0004028140133238978
[Epoch 24, Batch 1200] loss: 0.0006268043444759907
[Epoch 24, Batch 1300] loss: 0.00014488130042241475
[Epoch 24, Batch 1400] loss: 0.00038029722123045673
[Epoch 24, Batch 1500] loss: 0.001080419040964493
[Epoch 24, Batch 1600] loss: 0.0007102181044923128
[Epoch 24, Batch 1700] loss: 0.00047158864343341375
[Epoch 24, Batch 1800] loss: 0.0004447465422708419
[Epoch 24, Batch 1900] loss: 0.0004113368805571227
[Epoch 24, Batch 2000] loss: 0.00045189053828808667
[Epoch 24, Batch 2100] loss: 0.0009883058085049968
[Epoch 24, Batch 2200] loss: 0.0002692007679950992
[Epoch 24, Batch 2300] loss: 0.0003556839244718679
[Epoch 24, Batch 2400] loss: 0.0004969865148981167
[Epoch 24, Batch 2500] loss: 0.002051153062726878
[Epoch 24, Batch 2600] loss: 0.0011460443466660309
[Epoch 24, Batch 2700] loss: 0.00045277622811511263
[Epoch 24, Batch 2800] loss: 0.0010061013588292056
[Epoch 24, Batch 2900] loss: 0.000981079045650972
[Epoch 24, Batch 3000] loss: 0.0003716313040863639
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0647
Validation Accuracy: 0.9878
Overfitting: 0.0647
Fold 2 validation loss: 0.0647
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2936683750152587
[Epoch 1, Batch 200] loss: 2.206157032251358
[Epoch 1, Batch 300] loss: 1.4600778877735139
[Epoch 1, Batch 400] loss: 0.6860938961803913
[Epoch 1, Batch 500] loss: 0.4417543961852789
[Epoch 1, Batch 600] loss: 0.3849876493215561
[Epoch 1, Batch 700] loss: 0.3114843739196658
[Epoch 1, Batch 800] loss: 0.30457008302211763
[Epoch 1, Batch 900] loss: 0.2123796208947897
[Epoch 1, Batch 1000] loss: 0.2906656277179718
[Epoch 1, Batch 1100] loss: 0.23312761671841145
[Epoch 1, Batch 1200] loss: 0.2258311597816646
[Epoch 1, Batch 1300] loss: 0.19952344856224954
[Epoch 1, Batch 1400] loss: 0.20202292125672103
[Epoch 1, Batch 1500] loss: 0.1587003907142207
[Epoch 1, Batch 1600] loss: 0.1926134457346052
[Epoch 1, Batch 1700] loss: 0.15960031915456058
[Epoch 1, Batch 1800] loss: 0.14530661930562927
[Epoch 1, Batch 1900] loss: 0.1559005817398429
[Epoch 1, Batch 2000] loss: 0.1507663181051612
[Epoch 1, Batch 2100] loss: 0.12451571323908865
[Epoch 1, Batch 2200] loss: 0.13728363601258026
[Epoch 1, Batch 2300] loss: 0.13670974131207914
[Epoch 1, Batch 2400] loss: 0.13114179672906176
[Epoch 1, Batch 2500] loss: 0.11987699483986944
[Epoch 1, Batch 2600] loss: 0.13545684363460167
[Epoch 1, Batch 2700] loss: 0.11715613124892116
[Epoch 1, Batch 2800] loss: 0.11482920272741466
[Epoch 1, Batch 2900] loss: 0.11252072748262436
[Epoch 1, Batch 3000] loss: 0.1213608342059888
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1032
Validation Accuracy: 0.9678
Overfitting: 0.1032
Best model saved at epoch 1 with validation loss: 0.1032
[Epoch 2, Batch 100] loss: 0.12055508219171315
[Epoch 2, Batch 200] loss: 0.098586626307806
[Epoch 2, Batch 300] loss: 0.09444285575067625
[Epoch 2, Batch 400] loss: 0.08594627562153619
[Epoch 2, Batch 500] loss: 0.09869893166818657
[Epoch 2, Batch 600] loss: 0.11437375748064368
[Epoch 2, Batch 700] loss: 0.08539488248294219
[Epoch 2, Batch 800] loss: 0.07832284662290476
[Epoch 2, Batch 900] loss: 0.08369085246580653
[Epoch 2, Batch 1000] loss: 0.08623438284150325
[Epoch 2, Batch 1100] loss: 0.11349922735942528
[Epoch 2, Batch 1200] loss: 0.09460247930837795
[Epoch 2, Batch 1300] loss: 0.07412374368286692
[Epoch 2, Batch 1400] loss: 0.07805098359705881
[Epoch 2, Batch 1500] loss: 0.09310127325123176
[Epoch 2, Batch 1600] loss: 0.08868556754197926
[Epoch 2, Batch 1700] loss: 0.08194856194226303
[Epoch 2, Batch 1800] loss: 0.09500182536896318
[Epoch 2, Batch 1900] loss: 0.07841321533778682
[Epoch 2, Batch 2000] loss: 0.08628725239104824
[Epoch 2, Batch 2100] loss: 0.08074459735187701
[Epoch 2, Batch 2200] loss: 0.09323146663140505
[Epoch 2, Batch 2300] loss: 0.07044455294497311
[Epoch 2, Batch 2400] loss: 0.07131103035470004
[Epoch 2, Batch 2500] loss: 0.06604164594667963
[Epoch 2, Batch 2600] loss: 0.06636111251777038
[Epoch 2, Batch 2700] loss: 0.07939736517553683
[Epoch 2, Batch 2800] loss: 0.06666198137798346
[Epoch 2, Batch 2900] loss: 0.06631107612949563
[Epoch 2, Batch 3000] loss: 0.08268235619703773
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0782
Validation Accuracy: 0.9757
Overfitting: 0.0782
Best model saved at epoch 2 with validation loss: 0.0782
[Epoch 3, Batch 100] loss: 0.05405848605092615
[Epoch 3, Batch 200] loss: 0.09175817282753997
[Epoch 3, Batch 300] loss: 0.04751521960075479
[Epoch 3, Batch 400] loss: 0.064012281447649
[Epoch 3, Batch 500] loss: 0.060260767984436824
[Epoch 3, Batch 600] loss: 0.05974333939375356
[Epoch 3, Batch 700] loss: 0.0702703096694313
[Epoch 3, Batch 800] loss: 0.06656726083252579
[Epoch 3, Batch 900] loss: 0.048747897507855666
[Epoch 3, Batch 1000] loss: 0.0683783392130863
[Epoch 3, Batch 1100] loss: 0.050843472456326706
[Epoch 3, Batch 1200] loss: 0.05833634345501196
[Epoch 3, Batch 1300] loss: 0.05998267466493416
[Epoch 3, Batch 1400] loss: 0.06809548440622165
[Epoch 3, Batch 1500] loss: 0.06447563801702927
[Epoch 3, Batch 1600] loss: 0.07748888051894028
[Epoch 3, Batch 1700] loss: 0.0494526282523293
[Epoch 3, Batch 1800] loss: 0.03906068533251528
[Epoch 3, Batch 1900] loss: 0.059811270887730646
[Epoch 3, Batch 2000] loss: 0.05798557416652329
[Epoch 3, Batch 2100] loss: 0.06768305024248548
[Epoch 3, Batch 2200] loss: 0.0717915308632655
[Epoch 3, Batch 2300] loss: 0.05219009133754298
[Epoch 3, Batch 2400] loss: 0.05026104406977538
[Epoch 3, Batch 2500] loss: 0.06454766047128942
[Epoch 3, Batch 2600] loss: 0.04887747037690133
[Epoch 3, Batch 2700] loss: 0.05791810656955931
[Epoch 3, Batch 2800] loss: 0.062260569853242485
[Epoch 3, Batch 2900] loss: 0.06599335760809481
[Epoch 3, Batch 3000] loss: 0.05526010791771114
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9820
Overfitting: 0.0592
Best model saved at epoch 3 with validation loss: 0.0592
[Epoch 4, Batch 100] loss: 0.042213821091572755
[Epoch 4, Batch 200] loss: 0.04353976901926217
[Epoch 4, Batch 300] loss: 0.04291589415079215
[Epoch 4, Batch 400] loss: 0.03952281000703806
[Epoch 4, Batch 500] loss: 0.02178938876662869
[Epoch 4, Batch 600] loss: 0.04432644919375889
[Epoch 4, Batch 700] loss: 0.031094312020286452
[Epoch 4, Batch 800] loss: 0.04832298978639301
[Epoch 4, Batch 900] loss: 0.04659600591287017
[Epoch 4, Batch 1000] loss: 0.05266577281989157
[Epoch 4, Batch 1100] loss: 0.05817966405360494
[Epoch 4, Batch 1200] loss: 0.06193032452720217
[Epoch 4, Batch 1300] loss: 0.04926665746665094
[Epoch 4, Batch 1400] loss: 0.03644676800468005
[Epoch 4, Batch 1500] loss: 0.04450113169150427
[Epoch 4, Batch 1600] loss: 0.04736192593263695
[Epoch 4, Batch 1700] loss: 0.058997000058880075
[Epoch 4, Batch 1800] loss: 0.05801427244208753
[Epoch 4, Batch 1900] loss: 0.039845747928775384
[Epoch 4, Batch 2000] loss: 0.055248602892679625
[Epoch 4, Batch 2100] loss: 0.047500749131431805
[Epoch 4, Batch 2200] loss: 0.04371156334906118
[Epoch 4, Batch 2300] loss: 0.058470221578900236
[Epoch 4, Batch 2400] loss: 0.03146968044282403
[Epoch 4, Batch 2500] loss: 0.044674260655301626
[Epoch 4, Batch 2600] loss: 0.05084390406613238
[Epoch 4, Batch 2700] loss: 0.03803456374818779
[Epoch 4, Batch 2800] loss: 0.050265883924876104
[Epoch 4, Batch 2900] loss: 0.05587063966260757
[Epoch 4, Batch 3000] loss: 0.04324712566973176
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0562
Validation Accuracy: 0.9828
Overfitting: 0.0562
Best model saved at epoch 4 with validation loss: 0.0562
[Epoch 5, Batch 100] loss: 0.036587321320839694
[Epoch 5, Batch 200] loss: 0.035664771493757144
[Epoch 5, Batch 300] loss: 0.05426181262708269
[Epoch 5, Batch 400] loss: 0.03652276458858978
[Epoch 5, Batch 500] loss: 0.03632508237104048
[Epoch 5, Batch 600] loss: 0.043757514342141805
[Epoch 5, Batch 700] loss: 0.03614741562771087
[Epoch 5, Batch 800] loss: 0.04296516654605512
[Epoch 5, Batch 900] loss: 0.02926131962100044
[Epoch 5, Batch 1000] loss: 0.02531439887054148
[Epoch 5, Batch 1100] loss: 0.017690519681491424
[Epoch 5, Batch 1200] loss: 0.04728436297438748
[Epoch 5, Batch 1300] loss: 0.029059695501200623
[Epoch 5, Batch 1400] loss: 0.035966524602117717
[Epoch 5, Batch 1500] loss: 0.03246220814842673
[Epoch 5, Batch 1600] loss: 0.03795940757612698
[Epoch 5, Batch 1700] loss: 0.030064866830980464
[Epoch 5, Batch 1800] loss: 0.04577393173880409
[Epoch 5, Batch 1900] loss: 0.025993516280359473
[Epoch 5, Batch 2000] loss: 0.03151173791877227
[Epoch 5, Batch 2100] loss: 0.026283719435159583
[Epoch 5, Batch 2200] loss: 0.04138747075747233
[Epoch 5, Batch 2300] loss: 0.025044405078224374
[Epoch 5, Batch 2400] loss: 0.04244170773614314
[Epoch 5, Batch 2500] loss: 0.05144234515784774
[Epoch 5, Batch 2600] loss: 0.04357675153471064
[Epoch 5, Batch 2700] loss: 0.036048431151430124
[Epoch 5, Batch 2800] loss: 0.031101988093869295
[Epoch 5, Batch 2900] loss: 0.03915114610557793
[Epoch 5, Batch 3000] loss: 0.04996742784132948
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9840
Overfitting: 0.0581
[Epoch 6, Batch 100] loss: 0.0359250141641678
[Epoch 6, Batch 200] loss: 0.03594972443934239
[Epoch 6, Batch 300] loss: 0.02668689848665963
[Epoch 6, Batch 400] loss: 0.013743617813452147
[Epoch 6, Batch 500] loss: 0.03297704587923363
[Epoch 6, Batch 600] loss: 0.019544762274235836
[Epoch 6, Batch 700] loss: 0.031292264112271366
[Epoch 6, Batch 800] loss: 0.041993000567599664
[Epoch 6, Batch 900] loss: 0.014244599930389085
[Epoch 6, Batch 1000] loss: 0.03350279995604069
[Epoch 6, Batch 1100] loss: 0.05029849791288143
[Epoch 6, Batch 1200] loss: 0.02964746507219388
[Epoch 6, Batch 1300] loss: 0.025091294542362447
[Epoch 6, Batch 1400] loss: 0.023722936687772745
[Epoch 6, Batch 1500] loss: 0.03574848556010693
[Epoch 6, Batch 1600] loss: 0.046455025091418065
[Epoch 6, Batch 1700] loss: 0.022439637427960405
[Epoch 6, Batch 1800] loss: 0.03275093957709032
[Epoch 6, Batch 1900] loss: 0.027616499273281078
[Epoch 6, Batch 2000] loss: 0.021772180361149366
[Epoch 6, Batch 2100] loss: 0.02339753162836132
[Epoch 6, Batch 2200] loss: 0.05250736506073736
[Epoch 6, Batch 2300] loss: 0.026699849725700914
[Epoch 6, Batch 2400] loss: 0.025235517474284277
[Epoch 6, Batch 2500] loss: 0.03996919245379104
[Epoch 6, Batch 2600] loss: 0.029911730957755935
[Epoch 6, Batch 2700] loss: 0.032830266980381564
[Epoch 6, Batch 2800] loss: 0.02778374505935062
[Epoch 6, Batch 2900] loss: 0.03197673034926993
[Epoch 6, Batch 3000] loss: 0.0376790408265515
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9875
Overfitting: 0.0457
Best model saved at epoch 6 with validation loss: 0.0457
[Epoch 7, Batch 100] loss: 0.03101017984226928
[Epoch 7, Batch 200] loss: 0.021938588046323274
[Epoch 7, Batch 300] loss: 0.0339828457270778
[Epoch 7, Batch 400] loss: 0.024728232486922935
[Epoch 7, Batch 500] loss: 0.017953957776080644
[Epoch 7, Batch 600] loss: 0.027753516931006743
[Epoch 7, Batch 700] loss: 0.027289019657764584
[Epoch 7, Batch 800] loss: 0.028282304770182235
[Epoch 7, Batch 900] loss: 0.018397502291300043
[Epoch 7, Batch 1000] loss: 0.022291673164108943
[Epoch 7, Batch 1100] loss: 0.02069532883597276
[Epoch 7, Batch 1200] loss: 0.022292837191616854
[Epoch 7, Batch 1300] loss: 0.024811380864848617
[Epoch 7, Batch 1400] loss: 0.02643953779042931
[Epoch 7, Batch 1500] loss: 0.02691930600354681
[Epoch 7, Batch 1600] loss: 0.025112639556282373
[Epoch 7, Batch 1700] loss: 0.019120153683034005
[Epoch 7, Batch 1800] loss: 0.02124951548423269
[Epoch 7, Batch 1900] loss: 0.03122823728946969
[Epoch 7, Batch 2000] loss: 0.027491623658206663
[Epoch 7, Batch 2100] loss: 0.027556723629240876
[Epoch 7, Batch 2200] loss: 0.0485450553811097
[Epoch 7, Batch 2300] loss: 0.016505371950697737
[Epoch 7, Batch 2400] loss: 0.016510251549589156
[Epoch 7, Batch 2500] loss: 0.021229561478176038
[Epoch 7, Batch 2600] loss: 0.04192872075047489
[Epoch 7, Batch 2700] loss: 0.020374794042727445
[Epoch 7, Batch 2800] loss: 0.0278401539429251
[Epoch 7, Batch 2900] loss: 0.019149940652932854
[Epoch 7, Batch 3000] loss: 0.030522573494054087
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0432
Validation Accuracy: 0.9875
Overfitting: 0.0432
Best model saved at epoch 7 with validation loss: 0.0432
[Epoch 8, Batch 100] loss: 0.016919908464660693
[Epoch 8, Batch 200] loss: 0.02086910633908701
[Epoch 8, Batch 300] loss: 0.02088303835123952
[Epoch 8, Batch 400] loss: 0.016923277575297106
[Epoch 8, Batch 500] loss: 0.02357382299796882
[Epoch 8, Batch 600] loss: 0.01926571701300418
[Epoch 8, Batch 700] loss: 0.014200751430944365
[Epoch 8, Batch 800] loss: 0.009036650042398833
[Epoch 8, Batch 900] loss: 0.021887892114064014
[Epoch 8, Batch 1000] loss: 0.020166853630871628
[Epoch 8, Batch 1100] loss: 0.02217897390703001
[Epoch 8, Batch 1200] loss: 0.01756141282363387
[Epoch 8, Batch 1300] loss: 0.01885350166608987
[Epoch 8, Batch 1400] loss: 0.0268638792069396
[Epoch 8, Batch 1500] loss: 0.025946041167953807
[Epoch 8, Batch 1600] loss: 0.01465075299161981
[Epoch 8, Batch 1700] loss: 0.03372829700141665
[Epoch 8, Batch 1800] loss: 0.019906820736614463
[Epoch 8, Batch 1900] loss: 0.023516155120451004
[Epoch 8, Batch 2000] loss: 0.021459230275431763
[Epoch 8, Batch 2100] loss: 0.025526612073990693
[Epoch 8, Batch 2200] loss: 0.020818260432188252
[Epoch 8, Batch 2300] loss: 0.029020632225074224
[Epoch 8, Batch 2400] loss: 0.018589847303046553
[Epoch 8, Batch 2500] loss: 0.026585739356305566
[Epoch 8, Batch 2600] loss: 0.033110106288131644
[Epoch 8, Batch 2700] loss: 0.03530342023484991
[Epoch 8, Batch 2800] loss: 0.014231129403997329
[Epoch 8, Batch 2900] loss: 0.010355428709608532
[Epoch 8, Batch 3000] loss: 0.02146978688661875
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9865
Overfitting: 0.0490
[Epoch 9, Batch 100] loss: 0.0067998130813066385
[Epoch 9, Batch 200] loss: 0.017518210425369034
[Epoch 9, Batch 300] loss: 0.008947487239456677
[Epoch 9, Batch 400] loss: 0.024884030665416505
[Epoch 9, Batch 500] loss: 0.017845853571379848
[Epoch 9, Batch 600] loss: 0.011712596861525527
[Epoch 9, Batch 700] loss: 0.015015936679446895
[Epoch 9, Batch 800] loss: 0.015321647400651273
[Epoch 9, Batch 900] loss: 0.020206422585433755
[Epoch 9, Batch 1000] loss: 0.019717981265321215
[Epoch 9, Batch 1100] loss: 0.020777087874503195
[Epoch 9, Batch 1200] loss: 0.023772878408271934
[Epoch 9, Batch 1300] loss: 0.020597577886728686
[Epoch 9, Batch 1400] loss: 0.01868661788808822
[Epoch 9, Batch 1500] loss: 0.03445010826078942
[Epoch 9, Batch 1600] loss: 0.019635739582481618
[Epoch 9, Batch 1700] loss: 0.019205563814484777
[Epoch 9, Batch 1800] loss: 0.01607753841628437
[Epoch 9, Batch 1900] loss: 0.010578035856942733
[Epoch 9, Batch 2000] loss: 0.017746232966383103
[Epoch 9, Batch 2100] loss: 0.009726704710537888
[Epoch 9, Batch 2200] loss: 0.014007349075800448
[Epoch 9, Batch 2300] loss: 0.017895485770532106
[Epoch 9, Batch 2400] loss: 0.01976540186371494
[Epoch 9, Batch 2500] loss: 0.027261489431184602
[Epoch 9, Batch 2600] loss: 0.016853785650346252
[Epoch 9, Batch 2700] loss: 0.01500348655408743
[Epoch 9, Batch 2800] loss: 0.014723356833710568
[Epoch 9, Batch 2900] loss: 0.018670739648659947
[Epoch 9, Batch 3000] loss: 0.008739348908002285
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0432
Validation Accuracy: 0.9880
Overfitting: 0.0432
[Epoch 10, Batch 100] loss: 0.011028071106384232
[Epoch 10, Batch 200] loss: 0.019338622524028324
[Epoch 10, Batch 300] loss: 0.01187039999920671
[Epoch 10, Batch 400] loss: 0.01651226701824271
[Epoch 10, Batch 500] loss: 0.010362384142772497
[Epoch 10, Batch 600] loss: 0.01626032278763205
[Epoch 10, Batch 700] loss: 0.008026087660446136
[Epoch 10, Batch 800] loss: 0.013380468455707159
[Epoch 10, Batch 900] loss: 0.016425693880592007
[Epoch 10, Batch 1000] loss: 0.013072538274223007
[Epoch 10, Batch 1100] loss: 0.024230288176195245
[Epoch 10, Batch 1200] loss: 0.013228171070234112
[Epoch 10, Batch 1300] loss: 0.015126594446628587
[Epoch 10, Batch 1400] loss: 0.01733293583871273
[Epoch 10, Batch 1500] loss: 0.03411527856871089
[Epoch 10, Batch 1600] loss: 0.011048906400828855
[Epoch 10, Batch 1700] loss: 0.00929029923444432
[Epoch 10, Batch 1800] loss: 0.016980550127282185
[Epoch 10, Batch 1900] loss: 0.01626622269217478
[Epoch 10, Batch 2000] loss: 0.008939489737585973
[Epoch 10, Batch 2100] loss: 0.011745523433937706
[Epoch 10, Batch 2200] loss: 0.017693457799814495
[Epoch 10, Batch 2300] loss: 0.010341152040855377
[Epoch 10, Batch 2400] loss: 0.018865254588131392
[Epoch 10, Batch 2500] loss: 0.02417194251489491
[Epoch 10, Batch 2600] loss: 0.013689516511058174
[Epoch 10, Batch 2700] loss: 0.00958584044377858
[Epoch 10, Batch 2800] loss: 0.019190524498799277
[Epoch 10, Batch 2900] loss: 0.023221041721990333
[Epoch 10, Batch 3000] loss: 0.03130355595548053
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0638
Validation Accuracy: 0.9824
Overfitting: 0.0638
[Epoch 11, Batch 100] loss: 0.012772829939312941
[Epoch 11, Batch 200] loss: 0.010572899801304629
[Epoch 11, Batch 300] loss: 0.01587886573461219
[Epoch 11, Batch 400] loss: 0.007272758487542888
[Epoch 11, Batch 500] loss: 0.013797559389931848
[Epoch 11, Batch 600] loss: 0.009675823769139242
[Epoch 11, Batch 700] loss: 0.020456123952517374
[Epoch 11, Batch 800] loss: 0.011030922965092031
[Epoch 11, Batch 900] loss: 0.0176886943333011
[Epoch 11, Batch 1000] loss: 0.007977905532097793
[Epoch 11, Batch 1100] loss: 0.011752763164108728
[Epoch 11, Batch 1200] loss: 0.008045250891491378
[Epoch 11, Batch 1300] loss: 0.009186065585035976
[Epoch 11, Batch 1400] loss: 0.007755060142785624
[Epoch 11, Batch 1500] loss: 0.013827108907703405
[Epoch 11, Batch 1600] loss: 0.008372808303006423
[Epoch 11, Batch 1700] loss: 0.006699745846290171
[Epoch 11, Batch 1800] loss: 0.006689183194231419
[Epoch 11, Batch 1900] loss: 0.01531771845637195
[Epoch 11, Batch 2000] loss: 0.0193769817866405
[Epoch 11, Batch 2100] loss: 0.018243768377582226
[Epoch 11, Batch 2200] loss: 0.011123608494690415
[Epoch 11, Batch 2300] loss: 0.02049813368958894
[Epoch 11, Batch 2400] loss: 0.005533184877081112
[Epoch 11, Batch 2500] loss: 0.014100820106741595
[Epoch 11, Batch 2600] loss: 0.01472401364147572
[Epoch 11, Batch 2700] loss: 0.014257405235489386
[Epoch 11, Batch 2800] loss: 0.014719435414781401
[Epoch 11, Batch 2900] loss: 0.011392256089748117
[Epoch 11, Batch 3000] loss: 0.022344955465196107
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9878
Overfitting: 0.0462
[Epoch 12, Batch 100] loss: 0.008538654846656755
[Epoch 12, Batch 200] loss: 0.01420237034143156
[Epoch 12, Batch 300] loss: 0.015886630030418018
[Epoch 12, Batch 400] loss: 0.010784833746765799
[Epoch 12, Batch 500] loss: 0.015163150468270032
[Epoch 12, Batch 600] loss: 0.014337733100169316
[Epoch 12, Batch 700] loss: 0.009658602318631892
[Epoch 12, Batch 800] loss: 0.005053675849712818
[Epoch 12, Batch 900] loss: 0.006975366828817187
[Epoch 12, Batch 1000] loss: 0.009332073232606035
[Epoch 12, Batch 1100] loss: 0.0062323287569006425
[Epoch 12, Batch 1200] loss: 0.009533521551811646
[Epoch 12, Batch 1300] loss: 0.014938833104688456
[Epoch 12, Batch 1400] loss: 0.011363043132387247
[Epoch 12, Batch 1500] loss: 0.0072918260442202155
[Epoch 12, Batch 1600] loss: 0.009343515342520732
[Epoch 12, Batch 1700] loss: 0.013147588493800412
[Epoch 12, Batch 1800] loss: 0.01085893210542963
[Epoch 12, Batch 1900] loss: 0.007677776126565732
[Epoch 12, Batch 2000] loss: 0.012477168966906902
[Epoch 12, Batch 2100] loss: 0.01454779864970078
[Epoch 12, Batch 2200] loss: 0.00816312844449385
[Epoch 12, Batch 2300] loss: 0.009164254186001699
[Epoch 12, Batch 2400] loss: 0.011979100756957451
[Epoch 12, Batch 2500] loss: 0.011883692594641388
[Epoch 12, Batch 2600] loss: 0.010244486544247594
[Epoch 12, Batch 2700] loss: 0.01227567968276162
[Epoch 12, Batch 2800] loss: 0.014737492225967798
[Epoch 12, Batch 2900] loss: 0.0058221974217337906
[Epoch 12, Batch 3000] loss: 0.015751676324007348
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9876
Overfitting: 0.0519
[Epoch 13, Batch 100] loss: 0.007905032619760277
[Epoch 13, Batch 200] loss: 0.0031700541665259153
[Epoch 13, Batch 300] loss: 0.011169026931659118
[Epoch 13, Batch 400] loss: 0.009774433584225336
[Epoch 13, Batch 500] loss: 0.011467802812830996
[Epoch 13, Batch 600] loss: 0.008273738914482465
[Epoch 13, Batch 700] loss: 0.0067321880638019135
[Epoch 13, Batch 800] loss: 0.006085507130987935
[Epoch 13, Batch 900] loss: 0.011573135029884725
[Epoch 13, Batch 1000] loss: 0.010055327102886622
[Epoch 13, Batch 1100] loss: 0.019222088741862535
[Epoch 13, Batch 1200] loss: 0.010750434437172772
[Epoch 13, Batch 1300] loss: 0.005326018617156478
[Epoch 13, Batch 1400] loss: 0.011183845027260305
[Epoch 13, Batch 1500] loss: 0.006268075340813084
[Epoch 13, Batch 1600] loss: 0.006114265927521956
[Epoch 13, Batch 1700] loss: 0.002921093044808458
[Epoch 13, Batch 1800] loss: 0.004688382978863501
[Epoch 13, Batch 1900] loss: 0.007959955807796177
[Epoch 13, Batch 2000] loss: 0.004455015820103654
[Epoch 13, Batch 2100] loss: 0.0039000138264862014
[Epoch 13, Batch 2200] loss: 0.019521800994757543
[Epoch 13, Batch 2300] loss: 0.00793806413546008
[Epoch 13, Batch 2400] loss: 0.00616854406536504
[Epoch 13, Batch 2500] loss: 0.013914460147946102
[Epoch 13, Batch 2600] loss: 0.015251596857392542
[Epoch 13, Batch 2700] loss: 0.01396409461656731
[Epoch 13, Batch 2800] loss: 0.03181564270953459
[Epoch 13, Batch 2900] loss: 0.022333339432489083
[Epoch 13, Batch 3000] loss: 0.016909582843536556
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9875
Overfitting: 0.0476
[Epoch 14, Batch 100] loss: 0.011065622936657747
[Epoch 14, Batch 200] loss: 0.0024471836477187024
[Epoch 14, Batch 300] loss: 0.0037942818522878952
[Epoch 14, Batch 400] loss: 0.004879001631204574
[Epoch 14, Batch 500] loss: 0.00897148200270749
[Epoch 14, Batch 600] loss: 0.005217941190369402
[Epoch 14, Batch 700] loss: 0.00967271147714655
[Epoch 14, Batch 800] loss: 0.007631655193995357
[Epoch 14, Batch 900] loss: 0.01043286236456538
[Epoch 14, Batch 1000] loss: 0.004984456170403746
[Epoch 14, Batch 1100] loss: 0.005210308233654359
[Epoch 14, Batch 1200] loss: 0.005170596662574098
[Epoch 14, Batch 1300] loss: 0.005144664771246425
[Epoch 14, Batch 1400] loss: 0.004048288390958987
[Epoch 14, Batch 1500] loss: 0.0039413543374928394
[Epoch 14, Batch 1600] loss: 0.006858883604786569
[Epoch 14, Batch 1700] loss: 0.006089954060056471
[Epoch 14, Batch 1800] loss: 0.008965444312572117
[Epoch 14, Batch 1900] loss: 0.010328996578041937
[Epoch 14, Batch 2000] loss: 0.0063611450627468
[Epoch 14, Batch 2100] loss: 0.0072675343325465745
[Epoch 14, Batch 2200] loss: 0.010682195716806292
[Epoch 14, Batch 2300] loss: 0.009296266568815667
[Epoch 14, Batch 2400] loss: 0.009493885243396108
[Epoch 14, Batch 2500] loss: 0.006203757084693962
[Epoch 14, Batch 2600] loss: 0.017334996218298784
[Epoch 14, Batch 2700] loss: 0.016729517338596907
[Epoch 14, Batch 2800] loss: 0.009545946236705162
[Epoch 14, Batch 2900] loss: 0.00996613308382166
[Epoch 14, Batch 3000] loss: 0.016599021403378628
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9852
Overfitting: 0.0592
[Epoch 15, Batch 100] loss: 0.005440732617803406
[Epoch 15, Batch 200] loss: 0.0050770913987628315
[Epoch 15, Batch 300] loss: 0.00462057306585109
[Epoch 15, Batch 400] loss: 0.005346044761436133
[Epoch 15, Batch 500] loss: 0.0031885958078112253
[Epoch 15, Batch 600] loss: 0.002402802118606928
[Epoch 15, Batch 700] loss: 0.0018516912194795055
[Epoch 15, Batch 800] loss: 0.002509211651058081
[Epoch 15, Batch 900] loss: 0.002146586154954946
[Epoch 15, Batch 1000] loss: 0.0008392251695880759
[Epoch 15, Batch 1100] loss: 0.0014275187660473421
[Epoch 15, Batch 1200] loss: 0.005077344192408191
[Epoch 15, Batch 1300] loss: 0.004246849598365543
[Epoch 15, Batch 1400] loss: 0.018144598905037126
[Epoch 15, Batch 1500] loss: 0.009916580421279377
[Epoch 15, Batch 1600] loss: 0.006354150613332194
[Epoch 15, Batch 1700] loss: 0.0016136177125144968
[Epoch 15, Batch 1800] loss: 0.002125015440952893
[Epoch 15, Batch 1900] loss: 0.0026710952902453755
[Epoch 15, Batch 2000] loss: 0.004899312009287087
[Epoch 15, Batch 2100] loss: 0.015354829241439915
[Epoch 15, Batch 2200] loss: 0.007202988034780446
[Epoch 15, Batch 2300] loss: 0.0051324992314084735
[Epoch 15, Batch 2400] loss: 0.005805917156475288
[Epoch 15, Batch 2500] loss: 0.009956029800974875
[Epoch 15, Batch 2600] loss: 0.0046427948647232145
[Epoch 15, Batch 2700] loss: 0.004123769635804138
[Epoch 15, Batch 2800] loss: 0.007518609330974186
[Epoch 15, Batch 2900] loss: 0.002958166262352222
[Epoch 15, Batch 3000] loss: 0.013657145010046178
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9878
Overfitting: 0.0540
[Epoch 16, Batch 100] loss: 0.002320123749460663
[Epoch 16, Batch 200] loss: 0.003320231486460443
[Epoch 16, Batch 300] loss: 0.0030416345689542367
[Epoch 16, Batch 400] loss: 0.002282494238172603
[Epoch 16, Batch 500] loss: 0.0015235605807833964
[Epoch 16, Batch 600] loss: 0.001501722720083194
[Epoch 16, Batch 700] loss: 0.004095868881135516
[Epoch 16, Batch 800] loss: 0.005537703893630521
[Epoch 16, Batch 900] loss: 0.0040479691423198
[Epoch 16, Batch 1000] loss: 0.001835804329126205
[Epoch 16, Batch 1100] loss: 0.00529836300709178
[Epoch 16, Batch 1200] loss: 0.003132102249408604
[Epoch 16, Batch 1300] loss: 0.001901584373185301
[Epoch 16, Batch 1400] loss: 0.004277800282355599
[Epoch 16, Batch 1500] loss: 0.002860222133299999
[Epoch 16, Batch 1600] loss: 0.005274863544786115
[Epoch 16, Batch 1700] loss: 0.009268590012029848
[Epoch 16, Batch 1800] loss: 0.0026555298098264756
[Epoch 16, Batch 1900] loss: 0.0013173099124827558
[Epoch 16, Batch 2000] loss: 0.0034169806228629795
[Epoch 16, Batch 2100] loss: 0.0023997046718500312
[Epoch 16, Batch 2200] loss: 0.015426061142509866
[Epoch 16, Batch 2300] loss: 0.005365824800287555
[Epoch 16, Batch 2400] loss: 0.003613935285453067
[Epoch 16, Batch 2500] loss: 0.01162111072573822
[Epoch 16, Batch 2600] loss: 0.005751798771348007
[Epoch 16, Batch 2700] loss: 0.007774467863092696
[Epoch 16, Batch 2800] loss: 0.006744281200373621
[Epoch 16, Batch 2900] loss: 0.009050666110552753
[Epoch 16, Batch 3000] loss: 0.006297506580317247
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9883
Overfitting: 0.0510
[Epoch 17, Batch 100] loss: 0.0017001738130961285
[Epoch 17, Batch 200] loss: 0.0038071497792637387
[Epoch 17, Batch 300] loss: 0.0026806948395108068
[Epoch 17, Batch 400] loss: 0.0014141573821910924
[Epoch 17, Batch 500] loss: 0.005992409174126578
[Epoch 17, Batch 600] loss: 0.001562371674866938
[Epoch 17, Batch 700] loss: 0.004064533046127963
[Epoch 17, Batch 800] loss: 0.0035987073236043443
[Epoch 17, Batch 900] loss: 0.013150729649801463
[Epoch 17, Batch 1000] loss: 0.0033928525330497905
[Epoch 17, Batch 1100] loss: 0.0045820397115431885
[Epoch 17, Batch 1200] loss: 0.0061668175730102345
[Epoch 17, Batch 1300] loss: 0.0036265589017182263
[Epoch 17, Batch 1400] loss: 0.005038670166274208
[Epoch 17, Batch 1500] loss: 0.0025508866723131973
[Epoch 17, Batch 1600] loss: 0.002135841058711776
[Epoch 17, Batch 1700] loss: 0.002339229998930241
[Epoch 17, Batch 1800] loss: 0.0026474269655081175
[Epoch 17, Batch 1900] loss: 0.0019761942434263348
[Epoch 17, Batch 2000] loss: 0.002056149891708383
[Epoch 17, Batch 2100] loss: 0.0049743448674051645
[Epoch 17, Batch 2200] loss: 0.005545398648412885
[Epoch 17, Batch 2300] loss: 0.007712967554852242
[Epoch 17, Batch 2400] loss: 0.008059024390751119
[Epoch 17, Batch 2500] loss: 0.0030367536971237998
[Epoch 17, Batch 2600] loss: 0.005250600243744401
[Epoch 17, Batch 2700] loss: 0.003439318092804342
[Epoch 17, Batch 2800] loss: 0.008863760426890792
[Epoch 17, Batch 2900] loss: 0.01034231674537864
[Epoch 17, Batch 3000] loss: 0.007507029892539094
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9890
Overfitting: 0.0505
[Epoch 18, Batch 100] loss: 0.0015299107960194647
[Epoch 18, Batch 200] loss: 0.0019484292921112
[Epoch 18, Batch 300] loss: 0.004023882907669645
[Epoch 18, Batch 400] loss: 0.0061017010116057695
[Epoch 18, Batch 500] loss: 0.002026092604804717
[Epoch 18, Batch 600] loss: 0.0019720361042094227
[Epoch 18, Batch 700] loss: 0.0037121531934288044
[Epoch 18, Batch 800] loss: 0.002221634981817147
[Epoch 18, Batch 900] loss: 0.0011531142878786226
[Epoch 18, Batch 1000] loss: 0.0012525345511383535
[Epoch 18, Batch 1100] loss: 0.0008211513235079338
[Epoch 18, Batch 1200] loss: 0.0024294574693320215
[Epoch 18, Batch 1300] loss: 0.0012276470762788705
[Epoch 18, Batch 1400] loss: 0.0007212866638755599
[Epoch 18, Batch 1500] loss: 0.0006142704661235143
[Epoch 18, Batch 1600] loss: 0.0023563474598091005
[Epoch 18, Batch 1700] loss: 0.011941848332391487
[Epoch 18, Batch 1800] loss: 0.011554922260369836
[Epoch 18, Batch 1900] loss: 0.005873153480661202
[Epoch 18, Batch 2000] loss: 0.006459733641502936
[Epoch 18, Batch 2100] loss: 0.003886503151478564
[Epoch 18, Batch 2200] loss: 0.0035696277978932755
[Epoch 18, Batch 2300] loss: 0.0030153029845175184
[Epoch 18, Batch 2400] loss: 0.0035683954588748177
[Epoch 18, Batch 2500] loss: 0.005691987395254898
[Epoch 18, Batch 2600] loss: 0.005873595574761339
[Epoch 18, Batch 2700] loss: 0.005592275473848076
[Epoch 18, Batch 2800] loss: 0.0017238202336312724
[Epoch 18, Batch 2900] loss: 0.003973403563580291
[Epoch 18, Batch 3000] loss: 0.004241222772683386
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0581
Validation Accuracy: 0.9875
Overfitting: 0.0581
[Epoch 19, Batch 100] loss: 0.008977978531616486
[Epoch 19, Batch 200] loss: 0.0011863792070184332
[Epoch 19, Batch 300] loss: 0.00137496723044805
[Epoch 19, Batch 400] loss: 0.0020404451160921156
[Epoch 19, Batch 500] loss: 0.0019918305717411045
[Epoch 19, Batch 600] loss: 0.0011473086506470053
[Epoch 19, Batch 700] loss: 0.0017494291823943798
[Epoch 19, Batch 800] loss: 0.0010421681125070848
[Epoch 19, Batch 900] loss: 0.002733279731142275
[Epoch 19, Batch 1000] loss: 0.0043934998595631216
[Epoch 19, Batch 1100] loss: 0.0016455981749913917
[Epoch 19, Batch 1200] loss: 0.003908900668732258
[Epoch 19, Batch 1300] loss: 0.0024608580921868352
[Epoch 19, Batch 1400] loss: 0.0012959810768549574
[Epoch 19, Batch 1500] loss: 0.0009408572665432046
[Epoch 19, Batch 1600] loss: 0.0012833735157638416
[Epoch 19, Batch 1700] loss: 0.0012569783361456644
[Epoch 19, Batch 1800] loss: 0.0014917186010058136
[Epoch 19, Batch 1900] loss: 0.0006756330576330072
[Epoch 19, Batch 2000] loss: 0.0018586273310964253
[Epoch 19, Batch 2100] loss: 0.009002076570910837
[Epoch 19, Batch 2200] loss: 0.013093167021774902
[Epoch 19, Batch 2300] loss: 0.0058124182577348905
[Epoch 19, Batch 2400] loss: 0.004428478870765105
[Epoch 19, Batch 2500] loss: 0.005940231307870363
[Epoch 19, Batch 2600] loss: 0.004707842970247782
[Epoch 19, Batch 2700] loss: 0.004873993455889263
[Epoch 19, Batch 2800] loss: 0.005039209391840984
[Epoch 19, Batch 2900] loss: 0.00427221202763576
[Epoch 19, Batch 3000] loss: 0.001579894552597807
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9882
Overfitting: 0.0535
[Epoch 20, Batch 100] loss: 0.0031740670455178586
[Epoch 20, Batch 200] loss: 0.000736052269758538
[Epoch 20, Batch 300] loss: 0.0006034768719108285
[Epoch 20, Batch 400] loss: 0.0010232040720500634
[Epoch 20, Batch 500] loss: 0.0005676833191600395
[Epoch 20, Batch 600] loss: 0.0011464585181006725
[Epoch 20, Batch 700] loss: 0.0006988853549374596
[Epoch 20, Batch 800] loss: 0.0015540826539830732
[Epoch 20, Batch 900] loss: 0.0009215278435507912
[Epoch 20, Batch 1000] loss: 0.0007272226985457308
[Epoch 20, Batch 1100] loss: 0.0009858219912016962
[Epoch 20, Batch 1200] loss: 0.000568768268325428
[Epoch 20, Batch 1300] loss: 0.0005045727374303155
[Epoch 20, Batch 1400] loss: 0.0005823247986354119
[Epoch 20, Batch 1500] loss: 0.000842539773287534
[Epoch 20, Batch 1600] loss: 0.008485168392407373
[Epoch 20, Batch 1700] loss: 0.0007736900702763449
[Epoch 20, Batch 1800] loss: 0.0010908366796945667
[Epoch 20, Batch 1900] loss: 0.0006718826271786327
[Epoch 20, Batch 2000] loss: 0.0015508417061572998
[Epoch 20, Batch 2100] loss: 0.0056695317362345675
[Epoch 20, Batch 2200] loss: 0.0012449394229839328
[Epoch 20, Batch 2300] loss: 0.0006167881775854767
[Epoch 20, Batch 2400] loss: 0.0009549772614947294
[Epoch 20, Batch 2500] loss: 0.000667660369271772
[Epoch 20, Batch 2600] loss: 0.0025697956243333664
[Epoch 20, Batch 2700] loss: 0.001688492900965528
[Epoch 20, Batch 2800] loss: 0.0029343536455876773
[Epoch 20, Batch 2900] loss: 0.002232118854400653
[Epoch 20, Batch 3000] loss: 0.0009036089716931839
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9890
Overfitting: 0.0544
[Epoch 21, Batch 100] loss: 0.0006528332030844375
[Epoch 21, Batch 200] loss: 0.0005086412342228286
[Epoch 21, Batch 300] loss: 0.00176305609400373
[Epoch 21, Batch 400] loss: 0.0010814689406501543
[Epoch 21, Batch 500] loss: 0.0004800699706781586
[Epoch 21, Batch 600] loss: 0.0009689008849705516
[Epoch 21, Batch 700] loss: 0.0007825970507353475
[Epoch 21, Batch 800] loss: 0.0006157091977671314
[Epoch 21, Batch 900] loss: 0.0002794957757933414
[Epoch 21, Batch 1000] loss: 0.0004332715784070373
[Epoch 21, Batch 1100] loss: 0.00036563539035608275
[Epoch 21, Batch 1200] loss: 0.0007463808751824353
[Epoch 21, Batch 1300] loss: 0.00033081816297203303
[Epoch 21, Batch 1400] loss: 0.0006432493309340259
[Epoch 21, Batch 1500] loss: 0.0006282697032504191
[Epoch 21, Batch 1600] loss: 0.0021140356145389204
[Epoch 21, Batch 1700] loss: 0.001376351945200085
[Epoch 21, Batch 1800] loss: 0.0010779898181558422
[Epoch 21, Batch 1900] loss: 0.0007196329244921884
[Epoch 21, Batch 2000] loss: 0.0009313108962512473
[Epoch 21, Batch 2100] loss: 0.00927518110202349
[Epoch 21, Batch 2200] loss: 0.0009320822910171244
[Epoch 21, Batch 2300] loss: 0.000886051227082163
[Epoch 21, Batch 2400] loss: 0.00037837523084046867
[Epoch 21, Batch 2500] loss: 0.0016708964230578616
[Epoch 21, Batch 2600] loss: 0.0008770981053472581
[Epoch 21, Batch 2700] loss: 0.0008089139220031383
[Epoch 21, Batch 2800] loss: 0.001302869239007194
[Epoch 21, Batch 2900] loss: 0.0011050769577296915
[Epoch 21, Batch 3000] loss: 0.0005145994887233485
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9899
Overfitting: 0.0542
[Epoch 22, Batch 100] loss: 0.0008685668902941757
[Epoch 22, Batch 200] loss: 0.00031503749079687894
[Epoch 22, Batch 300] loss: 0.0003989686088814537
[Epoch 22, Batch 400] loss: 0.0014323357551016258
[Epoch 22, Batch 500] loss: 0.0009143283331290064
[Epoch 22, Batch 600] loss: 0.00040208712964442397
[Epoch 22, Batch 700] loss: 0.0003414113969035482
[Epoch 22, Batch 800] loss: 0.0005385708164585878
[Epoch 22, Batch 900] loss: 0.00032392074175552566
[Epoch 22, Batch 1000] loss: 0.0002918844392937814
[Epoch 22, Batch 1100] loss: 0.0007981561438054996
[Epoch 22, Batch 1200] loss: 0.0015540659190119753
[Epoch 22, Batch 1300] loss: 0.00040345045682621983
[Epoch 22, Batch 1400] loss: 0.00021308490518387568
[Epoch 22, Batch 1500] loss: 0.0004172972118352547
[Epoch 22, Batch 1600] loss: 0.00021586386555302094
[Epoch 22, Batch 1700] loss: 0.00019364855373707801
[Epoch 22, Batch 1800] loss: 0.0005066554788875522
[Epoch 22, Batch 1900] loss: 0.0002612046975779192
[Epoch 22, Batch 2000] loss: 0.0003964945585373725
[Epoch 22, Batch 2100] loss: 0.0005926784626824854
[Epoch 22, Batch 2200] loss: 0.0005643047512785948
[Epoch 22, Batch 2300] loss: 0.0003030270707664684
[Epoch 22, Batch 2400] loss: 0.0003034954767151987
[Epoch 22, Batch 2500] loss: 0.00040650926714821625
[Epoch 22, Batch 2600] loss: 0.00026311328791280177
[Epoch 22, Batch 2700] loss: 0.00036596178923430144
[Epoch 22, Batch 2800] loss: 0.0007168679669989597
[Epoch 22, Batch 2900] loss: 0.0005352002666475642
[Epoch 22, Batch 3000] loss: 0.0006654470413281022
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9897
Overfitting: 0.0561
[Epoch 23, Batch 100] loss: 0.000212528524908695
[Epoch 23, Batch 200] loss: 0.0003261309741998408
[Epoch 23, Batch 300] loss: 0.00019848762938700303
[Epoch 23, Batch 400] loss: 0.00022672149583526037
[Epoch 23, Batch 500] loss: 0.00019995783053460058
[Epoch 23, Batch 600] loss: 0.00027150804371741446
[Epoch 23, Batch 700] loss: 0.00032183201303323636
[Epoch 23, Batch 800] loss: 0.00026504404661643834
[Epoch 23, Batch 900] loss: 0.00020636187528287663
[Epoch 23, Batch 1000] loss: 0.00022109374610852938
[Epoch 23, Batch 1100] loss: 0.00020527157419768737
[Epoch 23, Batch 1200] loss: 0.0005509283704506495
[Epoch 23, Batch 1300] loss: 0.00036239922126958036
[Epoch 23, Batch 1400] loss: 0.00027764071587432326
[Epoch 23, Batch 1500] loss: 0.0004339093268133576
[Epoch 23, Batch 1600] loss: 0.00032701839892284923
[Epoch 23, Batch 1700] loss: 0.0001961441627370819
[Epoch 23, Batch 1800] loss: 0.00010816765399507489
[Epoch 23, Batch 1900] loss: 0.0002618755478977164
[Epoch 23, Batch 2000] loss: 0.00021737979218861448
[Epoch 23, Batch 2100] loss: 0.00026151974457000015
[Epoch 23, Batch 2200] loss: 0.0002434091686296469
[Epoch 23, Batch 2300] loss: 0.00021694247458698969
[Epoch 23, Batch 2400] loss: 0.00016364510253417564
[Epoch 23, Batch 2500] loss: 0.00040644749846053597
[Epoch 23, Batch 2600] loss: 0.0005110930636819333
[Epoch 23, Batch 2700] loss: 0.0006721612002696009
[Epoch 23, Batch 2800] loss: 0.00024284521504629452
[Epoch 23, Batch 2900] loss: 0.0003383844527201774
[Epoch 23, Batch 3000] loss: 0.00024549081563765454
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0563
Validation Accuracy: 0.9899
Overfitting: 0.0563
[Epoch 24, Batch 100] loss: 0.00021098168727550436
[Epoch 24, Batch 200] loss: 0.00014451285370834733
[Epoch 24, Batch 300] loss: 0.00012509544401310358
[Epoch 24, Batch 400] loss: 0.0002843451206598857
[Epoch 24, Batch 500] loss: 0.0001468472201305282
[Epoch 24, Batch 600] loss: 0.00019174611732577062
[Epoch 24, Batch 700] loss: 0.00019776304805450452
[Epoch 24, Batch 800] loss: 0.00016327344847281823
[Epoch 24, Batch 900] loss: 0.00010313077045498887
[Epoch 24, Batch 1000] loss: 0.00020735175238988823
[Epoch 24, Batch 1100] loss: 0.00019532983501171052
[Epoch 24, Batch 1200] loss: 0.0002156933752092538
[Epoch 24, Batch 1300] loss: 0.0002416010511829425
[Epoch 24, Batch 1400] loss: 0.000447260647468406
[Epoch 24, Batch 1500] loss: 0.00020940742509850007
[Epoch 24, Batch 1600] loss: 0.00012054139113413243
[Epoch 24, Batch 1700] loss: 0.0002294589300099581
[Epoch 24, Batch 1800] loss: 0.0001554480997406671
[Epoch 24, Batch 1900] loss: 0.00018554504457102272
[Epoch 24, Batch 2000] loss: 0.00046467238237336784
[Epoch 24, Batch 2100] loss: 0.0004995391198433107
[Epoch 24, Batch 2200] loss: 0.0001564406792459705
[Epoch 24, Batch 2300] loss: 0.000281935654398473
[Epoch 24, Batch 2400] loss: 0.00011879734623903016
[Epoch 24, Batch 2500] loss: 0.00015154041012811704
[Epoch 24, Batch 2600] loss: 0.0001779847129629175
[Epoch 24, Batch 2700] loss: 0.00014775582004101118
[Epoch 24, Batch 2800] loss: 0.00015780386570408034
[Epoch 24, Batch 2900] loss: 0.0002220789117951938
[Epoch 24, Batch 3000] loss: 0.00020730337811559975
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0574
Validation Accuracy: 0.9897
Overfitting: 0.0574
Fold 3 validation loss: 0.0574
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2957956051826476
[Epoch 1, Batch 200] loss: 2.2372105264663698
[Epoch 1, Batch 300] loss: 1.668454322218895
[Epoch 1, Batch 400] loss: 0.770669955611229
[Epoch 1, Batch 500] loss: 0.5138063858449459
[Epoch 1, Batch 600] loss: 0.3893957594037056
[Epoch 1, Batch 700] loss: 0.384824107773602
[Epoch 1, Batch 800] loss: 0.32514874927699566
[Epoch 1, Batch 900] loss: 0.3104261700063944
[Epoch 1, Batch 1000] loss: 0.2333146495372057
[Epoch 1, Batch 1100] loss: 0.24324511718936265
[Epoch 1, Batch 1200] loss: 0.20701118793338538
[Epoch 1, Batch 1300] loss: 0.20160713302902877
[Epoch 1, Batch 1400] loss: 0.17942989903502166
[Epoch 1, Batch 1500] loss: 0.1710607691016048
[Epoch 1, Batch 1600] loss: 0.18689756414853037
[Epoch 1, Batch 1700] loss: 0.17801403682678937
[Epoch 1, Batch 1800] loss: 0.15615123074967413
[Epoch 1, Batch 1900] loss: 0.13399302736856045
[Epoch 1, Batch 2000] loss: 0.1343532392056659
[Epoch 1, Batch 2100] loss: 0.12805065184365957
[Epoch 1, Batch 2200] loss: 0.14573679021093994
[Epoch 1, Batch 2300] loss: 0.12620592433493585
[Epoch 1, Batch 2400] loss: 0.14285339360591023
[Epoch 1, Batch 2500] loss: 0.13507841273443774
[Epoch 1, Batch 2600] loss: 0.1583473328873515
[Epoch 1, Batch 2700] loss: 0.1352285232488066
[Epoch 1, Batch 2800] loss: 0.11001331233186647
[Epoch 1, Batch 2900] loss: 0.12074304792098701
[Epoch 1, Batch 3000] loss: 0.09377080063568428
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1063
Validation Accuracy: 0.9656
Overfitting: 0.1063
Best model saved at epoch 1 with validation loss: 0.1063
[Epoch 2, Batch 100] loss: 0.11184108870802448
[Epoch 2, Batch 200] loss: 0.10572825725772418
[Epoch 2, Batch 300] loss: 0.11267685662955046
[Epoch 2, Batch 400] loss: 0.09012056303676218
[Epoch 2, Batch 500] loss: 0.09243542500189506
[Epoch 2, Batch 600] loss: 0.09164680577116087
[Epoch 2, Batch 700] loss: 0.09524533384479582
[Epoch 2, Batch 800] loss: 0.10049826644128189
[Epoch 2, Batch 900] loss: 0.0845367723191157
[Epoch 2, Batch 1000] loss: 0.09145018851966596
[Epoch 2, Batch 1100] loss: 0.0957982752029784
[Epoch 2, Batch 1200] loss: 0.10039338323636912
[Epoch 2, Batch 1300] loss: 0.07491826730081812
[Epoch 2, Batch 1400] loss: 0.0962782488646917
[Epoch 2, Batch 1500] loss: 0.08643423167290167
[Epoch 2, Batch 1600] loss: 0.08058122196584008
[Epoch 2, Batch 1700] loss: 0.08673425959132146
[Epoch 2, Batch 1800] loss: 0.09437645227590111
[Epoch 2, Batch 1900] loss: 0.07753972393111326
[Epoch 2, Batch 2000] loss: 0.08108482179697603
[Epoch 2, Batch 2100] loss: 0.06699542595189996
[Epoch 2, Batch 2200] loss: 0.08351913727528881
[Epoch 2, Batch 2300] loss: 0.0877442710683681
[Epoch 2, Batch 2400] loss: 0.06754150954890065
[Epoch 2, Batch 2500] loss: 0.06459785668790573
[Epoch 2, Batch 2600] loss: 0.09686784623481799
[Epoch 2, Batch 2700] loss: 0.08504040625004564
[Epoch 2, Batch 2800] loss: 0.0754022776405327
[Epoch 2, Batch 2900] loss: 0.06705275282554794
[Epoch 2, Batch 3000] loss: 0.08276144786563236
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0717
Validation Accuracy: 0.9773
Overfitting: 0.0717
Best model saved at epoch 2 with validation loss: 0.0717
[Epoch 3, Batch 100] loss: 0.05513223629794083
[Epoch 3, Batch 200] loss: 0.0785586901701754
[Epoch 3, Batch 300] loss: 0.05717243035789579
[Epoch 3, Batch 400] loss: 0.07792494962690398
[Epoch 3, Batch 500] loss: 0.06005206189234741
[Epoch 3, Batch 600] loss: 0.06703500667703338
[Epoch 3, Batch 700] loss: 0.057028207462863065
[Epoch 3, Batch 800] loss: 0.05959223783749621
[Epoch 3, Batch 900] loss: 0.05114671512477798
[Epoch 3, Batch 1000] loss: 0.09110433781781467
[Epoch 3, Batch 1100] loss: 0.044279206423088906
[Epoch 3, Batch 1200] loss: 0.056602122579060964
[Epoch 3, Batch 1300] loss: 0.07973356053582392
[Epoch 3, Batch 1400] loss: 0.07799073640373536
[Epoch 3, Batch 1500] loss: 0.07194011940329802
[Epoch 3, Batch 1600] loss: 0.05558630571496906
[Epoch 3, Batch 1700] loss: 0.06448740790947341
[Epoch 3, Batch 1800] loss: 0.08555466740624978
[Epoch 3, Batch 1900] loss: 0.052591210820828564
[Epoch 3, Batch 2000] loss: 0.049357081933703736
[Epoch 3, Batch 2100] loss: 0.06521400473662652
[Epoch 3, Batch 2200] loss: 0.05998692492896225
[Epoch 3, Batch 2300] loss: 0.0634515814005863
[Epoch 3, Batch 2400] loss: 0.03923055768071208
[Epoch 3, Batch 2500] loss: 0.04418260236881906
[Epoch 3, Batch 2600] loss: 0.05997276790483738
[Epoch 3, Batch 2700] loss: 0.06395056555746123
[Epoch 3, Batch 2800] loss: 0.04311977699981071
[Epoch 3, Batch 2900] loss: 0.0597220969828777
[Epoch 3, Batch 3000] loss: 0.04472565018804744
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0696
Validation Accuracy: 0.9792
Overfitting: 0.0696
Best model saved at epoch 3 with validation loss: 0.0696
[Epoch 4, Batch 100] loss: 0.05779672741773538
[Epoch 4, Batch 200] loss: 0.05424364390491974
[Epoch 4, Batch 300] loss: 0.05087079257165897
[Epoch 4, Batch 400] loss: 0.04321582312957616
[Epoch 4, Batch 500] loss: 0.04768750706876745
[Epoch 4, Batch 600] loss: 0.02913490681152325
[Epoch 4, Batch 700] loss: 0.038155401819385586
[Epoch 4, Batch 800] loss: 0.06119388851744589
[Epoch 4, Batch 900] loss: 0.05088625976888579
[Epoch 4, Batch 1000] loss: 0.06308498856960795
[Epoch 4, Batch 1100] loss: 0.03878084418654908
[Epoch 4, Batch 1200] loss: 0.04311261570226634
[Epoch 4, Batch 1300] loss: 0.06395726148009999
[Epoch 4, Batch 1400] loss: 0.043083167948934714
[Epoch 4, Batch 1500] loss: 0.027231999641662695
[Epoch 4, Batch 1600] loss: 0.050431852573965444
[Epoch 4, Batch 1700] loss: 0.0372316784368013
[Epoch 4, Batch 1800] loss: 0.047360715739487205
[Epoch 4, Batch 1900] loss: 0.033588245520368216
[Epoch 4, Batch 2000] loss: 0.06886918431380763
[Epoch 4, Batch 2100] loss: 0.047104337228956863
[Epoch 4, Batch 2200] loss: 0.04532536046768655
[Epoch 4, Batch 2300] loss: 0.0452427350304788
[Epoch 4, Batch 2400] loss: 0.03828594642633107
[Epoch 4, Batch 2500] loss: 0.038563100259634664
[Epoch 4, Batch 2600] loss: 0.047612456704082436
[Epoch 4, Batch 2700] loss: 0.040275977963174225
[Epoch 4, Batch 2800] loss: 0.04738713906292105
[Epoch 4, Batch 2900] loss: 0.04890895999458735
[Epoch 4, Batch 3000] loss: 0.057848610890869165
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9842
Overfitting: 0.0524
Best model saved at epoch 4 with validation loss: 0.0524
[Epoch 5, Batch 100] loss: 0.037395618782611564
[Epoch 5, Batch 200] loss: 0.027596923940218402
[Epoch 5, Batch 300] loss: 0.03172052346344571
[Epoch 5, Batch 400] loss: 0.046485692717687925
[Epoch 5, Batch 500] loss: 0.049220490439329294
[Epoch 5, Batch 600] loss: 0.028178218198299874
[Epoch 5, Batch 700] loss: 0.03649177270213841
[Epoch 5, Batch 800] loss: 0.04081420026763226
[Epoch 5, Batch 900] loss: 0.035918139177229025
[Epoch 5, Batch 1000] loss: 0.03204372661486559
[Epoch 5, Batch 1100] loss: 0.05584448211266135
[Epoch 5, Batch 1200] loss: 0.050167293547128795
[Epoch 5, Batch 1300] loss: 0.04729877186131489
[Epoch 5, Batch 1400] loss: 0.03806170187628595
[Epoch 5, Batch 1500] loss: 0.03453133753107977
[Epoch 5, Batch 1600] loss: 0.0461579639633419
[Epoch 5, Batch 1700] loss: 0.054710652652429415
[Epoch 5, Batch 1800] loss: 0.03651564852320007
[Epoch 5, Batch 1900] loss: 0.04269389258464798
[Epoch 5, Batch 2000] loss: 0.032888654781418156
[Epoch 5, Batch 2100] loss: 0.024389879801310597
[Epoch 5, Batch 2200] loss: 0.03273141661567933
[Epoch 5, Batch 2300] loss: 0.03609223917548661
[Epoch 5, Batch 2400] loss: 0.054079808467504334
[Epoch 5, Batch 2500] loss: 0.03518309093073185
[Epoch 5, Batch 2600] loss: 0.04650250659135054
[Epoch 5, Batch 2700] loss: 0.0351560082891956
[Epoch 5, Batch 2800] loss: 0.02839726239821175
[Epoch 5, Batch 2900] loss: 0.029823769203285336
[Epoch 5, Batch 3000] loss: 0.029106117072005874
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0441
Validation Accuracy: 0.9865
Overfitting: 0.0441
Best model saved at epoch 5 with validation loss: 0.0441
[Epoch 6, Batch 100] loss: 0.033057862722635036
[Epoch 6, Batch 200] loss: 0.048153917390445715
[Epoch 6, Batch 300] loss: 0.03259389840770382
[Epoch 6, Batch 400] loss: 0.020912864560450543
[Epoch 6, Batch 500] loss: 0.026788351864379365
[Epoch 6, Batch 600] loss: 0.028166247338449465
[Epoch 6, Batch 700] loss: 0.028374338477806304
[Epoch 6, Batch 800] loss: 0.025067727394980466
[Epoch 6, Batch 900] loss: 0.02150534750013321
[Epoch 6, Batch 1000] loss: 0.022138033054798143
[Epoch 6, Batch 1100] loss: 0.02780591451773944
[Epoch 6, Batch 1200] loss: 0.03376482021900301
[Epoch 6, Batch 1300] loss: 0.031560266404703725
[Epoch 6, Batch 1400] loss: 0.03648399797079037
[Epoch 6, Batch 1500] loss: 0.028358377673866925
[Epoch 6, Batch 1600] loss: 0.025392656240146607
[Epoch 6, Batch 1700] loss: 0.024565797653958724
[Epoch 6, Batch 1800] loss: 0.014608726738770202
[Epoch 6, Batch 1900] loss: 0.03252818054985255
[Epoch 6, Batch 2000] loss: 0.04476866961704218
[Epoch 6, Batch 2100] loss: 0.03032159051828785
[Epoch 6, Batch 2200] loss: 0.024493536554655294
[Epoch 6, Batch 2300] loss: 0.03138817498365824
[Epoch 6, Batch 2400] loss: 0.03276530924871622
[Epoch 6, Batch 2500] loss: 0.03512521869357443
[Epoch 6, Batch 2600] loss: 0.03708397622773191
[Epoch 6, Batch 2700] loss: 0.02775218682429113
[Epoch 6, Batch 2800] loss: 0.0482203751329871
[Epoch 6, Batch 2900] loss: 0.04874391970319266
[Epoch 6, Batch 3000] loss: 0.023927334034415253
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9854
Overfitting: 0.0468
[Epoch 7, Batch 100] loss: 0.020784641386053408
[Epoch 7, Batch 200] loss: 0.027827197042352054
[Epoch 7, Batch 300] loss: 0.015725904092596464
[Epoch 7, Batch 400] loss: 0.023678865105939622
[Epoch 7, Batch 500] loss: 0.018981707138518687
[Epoch 7, Batch 600] loss: 0.03329583493370592
[Epoch 7, Batch 700] loss: 0.020667211684340145
[Epoch 7, Batch 800] loss: 0.020168250929782517
[Epoch 7, Batch 900] loss: 0.03512089463434677
[Epoch 7, Batch 1000] loss: 0.019686192648623545
[Epoch 7, Batch 1100] loss: 0.03790239812260552
[Epoch 7, Batch 1200] loss: 0.028541678387628052
[Epoch 7, Batch 1300] loss: 0.029085410203151696
[Epoch 7, Batch 1400] loss: 0.03667379756814625
[Epoch 7, Batch 1500] loss: 0.025255023164427258
[Epoch 7, Batch 1600] loss: 0.01648967474604433
[Epoch 7, Batch 1700] loss: 0.02893817777890945
[Epoch 7, Batch 1800] loss: 0.027273844022965933
[Epoch 7, Batch 1900] loss: 0.01962596174722421
[Epoch 7, Batch 2000] loss: 0.014612273451966758
[Epoch 7, Batch 2100] loss: 0.021343357488331095
[Epoch 7, Batch 2200] loss: 0.037147100229885835
[Epoch 7, Batch 2300] loss: 0.022124103586320415
[Epoch 7, Batch 2400] loss: 0.023267512237289338
[Epoch 7, Batch 2500] loss: 0.01927687162777147
[Epoch 7, Batch 2600] loss: 0.048161532541525956
[Epoch 7, Batch 2700] loss: 0.026332056427709177
[Epoch 7, Batch 2800] loss: 0.019548071795361464
[Epoch 7, Batch 2900] loss: 0.02557500315946527
[Epoch 7, Batch 3000] loss: 0.03000583688917686
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9841
Overfitting: 0.0504
[Epoch 8, Batch 100] loss: 0.01979693410361506
[Epoch 8, Batch 200] loss: 0.039362082696679866
[Epoch 8, Batch 300] loss: 0.017841652882525524
[Epoch 8, Batch 400] loss: 0.030078950386960058
[Epoch 8, Batch 500] loss: 0.011858344548709283
[Epoch 8, Batch 600] loss: 0.02042717517404526
[Epoch 8, Batch 700] loss: 0.022437017448537516
[Epoch 8, Batch 800] loss: 0.024577270063382457
[Epoch 8, Batch 900] loss: 0.02167744951311761
[Epoch 8, Batch 1000] loss: 0.015916642087054244
[Epoch 8, Batch 1100] loss: 0.018881733237903972
[Epoch 8, Batch 1200] loss: 0.01663957970474257
[Epoch 8, Batch 1300] loss: 0.015367697953010975
[Epoch 8, Batch 1400] loss: 0.018736163388643944
[Epoch 8, Batch 1500] loss: 0.018845257675930042
[Epoch 8, Batch 1600] loss: 0.022138976924579765
[Epoch 8, Batch 1700] loss: 0.029996326891523494
[Epoch 8, Batch 1800] loss: 0.024123144829645754
[Epoch 8, Batch 1900] loss: 0.016868192442725558
[Epoch 8, Batch 2000] loss: 0.03405114524464807
[Epoch 8, Batch 2100] loss: 0.012585049438348506
[Epoch 8, Batch 2200] loss: 0.017625813195827504
[Epoch 8, Batch 2300] loss: 0.021949682012782433
[Epoch 8, Batch 2400] loss: 0.019622246168364655
[Epoch 8, Batch 2500] loss: 0.027075046704921987
[Epoch 8, Batch 2600] loss: 0.019480961193148686
[Epoch 8, Batch 2700] loss: 0.015282290363629727
[Epoch 8, Batch 2800] loss: 0.016718993990298258
[Epoch 8, Batch 2900] loss: 0.024430887551643535
[Epoch 8, Batch 3000] loss: 0.019886029825938747
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0428
Validation Accuracy: 0.9866
Overfitting: 0.0428
Best model saved at epoch 8 with validation loss: 0.0428
[Epoch 9, Batch 100] loss: 0.011694670038459663
[Epoch 9, Batch 200] loss: 0.014662618476922944
[Epoch 9, Batch 300] loss: 0.01653526959611554
[Epoch 9, Batch 400] loss: 0.01909831673325243
[Epoch 9, Batch 500] loss: 0.010518061162347294
[Epoch 9, Batch 600] loss: 0.020401450128797478
[Epoch 9, Batch 700] loss: 0.01811096396015273
[Epoch 9, Batch 800] loss: 0.021782771680664156
[Epoch 9, Batch 900] loss: 0.011505724694052333
[Epoch 9, Batch 1000] loss: 0.01025912275947121
[Epoch 9, Batch 1100] loss: 0.024887707469133602
[Epoch 9, Batch 1200] loss: 0.010953606460534502
[Epoch 9, Batch 1300] loss: 0.013118808224789972
[Epoch 9, Batch 1400] loss: 0.01745343369755574
[Epoch 9, Batch 1500] loss: 0.01758097912320409
[Epoch 9, Batch 1600] loss: 0.021301126551352353
[Epoch 9, Batch 1700] loss: 0.017161340908151034
[Epoch 9, Batch 1800] loss: 0.012259682212188636
[Epoch 9, Batch 1900] loss: 0.023123353886376208
[Epoch 9, Batch 2000] loss: 0.01438518796147946
[Epoch 9, Batch 2100] loss: 0.015423352418174545
[Epoch 9, Batch 2200] loss: 0.020849607249738257
[Epoch 9, Batch 2300] loss: 0.025228093023360997
[Epoch 9, Batch 2400] loss: 0.0160426054074901
[Epoch 9, Batch 2500] loss: 0.024495920932322404
[Epoch 9, Batch 2600] loss: 0.021938387569771293
[Epoch 9, Batch 2700] loss: 0.022825729747637524
[Epoch 9, Batch 2800] loss: 0.012860824383988074
[Epoch 9, Batch 2900] loss: 0.022264504400172882
[Epoch 9, Batch 3000] loss: 0.02004348575906988
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0432
Validation Accuracy: 0.9868
Overfitting: 0.0432
[Epoch 10, Batch 100] loss: 0.02254920310868329
[Epoch 10, Batch 200] loss: 0.014662358005170972
[Epoch 10, Batch 300] loss: 0.016602158953301114
[Epoch 10, Batch 400] loss: 0.013625489534942971
[Epoch 10, Batch 500] loss: 0.011840116391686023
[Epoch 10, Batch 600] loss: 0.009742244285498601
[Epoch 10, Batch 700] loss: 0.017182250461737568
[Epoch 10, Batch 800] loss: 0.014597239658141916
[Epoch 10, Batch 900] loss: 0.016717253513634206
[Epoch 10, Batch 1000] loss: 0.019548931329020434
[Epoch 10, Batch 1100] loss: 0.01567179112652411
[Epoch 10, Batch 1200] loss: 0.01742977308178524
[Epoch 10, Batch 1300] loss: 0.013336579699875983
[Epoch 10, Batch 1400] loss: 0.020776129685550586
[Epoch 10, Batch 1500] loss: 0.014355443053082126
[Epoch 10, Batch 1600] loss: 0.013547815915267165
[Epoch 10, Batch 1700] loss: 0.008555443020577513
[Epoch 10, Batch 1800] loss: 0.027018417667040922
[Epoch 10, Batch 1900] loss: 0.016590603748518333
[Epoch 10, Batch 2000] loss: 0.017179344632972972
[Epoch 10, Batch 2100] loss: 0.013497493190870955
[Epoch 10, Batch 2200] loss: 0.01456529969079952
[Epoch 10, Batch 2300] loss: 0.025403125280363384
[Epoch 10, Batch 2400] loss: 0.017272075090882025
[Epoch 10, Batch 2500] loss: 0.010671969405802884
[Epoch 10, Batch 2600] loss: 0.01652603207917764
[Epoch 10, Batch 2700] loss: 0.00864862515245477
[Epoch 10, Batch 2800] loss: 0.007456997463533526
[Epoch 10, Batch 2900] loss: 0.012149841231066603
[Epoch 10, Batch 3000] loss: 0.023776314897572773
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0449
Validation Accuracy: 0.9880
Overfitting: 0.0449
[Epoch 11, Batch 100] loss: 0.011835112697590376
[Epoch 11, Batch 200] loss: 0.00666060763898713
[Epoch 11, Batch 300] loss: 0.01030181692599399
[Epoch 11, Batch 400] loss: 0.0136458329971083
[Epoch 11, Batch 500] loss: 0.013822354267704213
[Epoch 11, Batch 600] loss: 0.0059245848728687635
[Epoch 11, Batch 700] loss: 0.008991260253537803
[Epoch 11, Batch 800] loss: 0.007172536891916934
[Epoch 11, Batch 900] loss: 0.015668229457965026
[Epoch 11, Batch 1000] loss: 0.0166881439029612
[Epoch 11, Batch 1100] loss: 0.010661802666545555
[Epoch 11, Batch 1200] loss: 0.014335202725769705
[Epoch 11, Batch 1300] loss: 0.011146427911862702
[Epoch 11, Batch 1400] loss: 0.014913225764730668
[Epoch 11, Batch 1500] loss: 0.012445757254349701
[Epoch 11, Batch 1600] loss: 0.009167484922470522
[Epoch 11, Batch 1700] loss: 0.01705645678950532
[Epoch 11, Batch 1800] loss: 0.012654353493499002
[Epoch 11, Batch 1900] loss: 0.01926296372954539
[Epoch 11, Batch 2000] loss: 0.007476173316320001
[Epoch 11, Batch 2100] loss: 0.019761798732602073
[Epoch 11, Batch 2200] loss: 0.021674777656976403
[Epoch 11, Batch 2300] loss: 0.020090016503418157
[Epoch 11, Batch 2400] loss: 0.009770818388537918
[Epoch 11, Batch 2500] loss: 0.011997316683682584
[Epoch 11, Batch 2600] loss: 0.01248166753790656
[Epoch 11, Batch 2700] loss: 0.022058516152737864
[Epoch 11, Batch 2800] loss: 0.012019466344477224
[Epoch 11, Batch 2900] loss: 0.015687444001896436
[Epoch 11, Batch 3000] loss: 0.008427441969975007
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9837
Overfitting: 0.0535
[Epoch 12, Batch 100] loss: 0.017229345222240226
[Epoch 12, Batch 200] loss: 0.0067773401327940515
[Epoch 12, Batch 300] loss: 0.012441340470065825
[Epoch 12, Batch 400] loss: 0.013059691703383579
[Epoch 12, Batch 500] loss: 0.014691162696553874
[Epoch 12, Batch 600] loss: 0.015931567783527497
[Epoch 12, Batch 700] loss: 0.015546203748321545
[Epoch 12, Batch 800] loss: 0.009291905356385542
[Epoch 12, Batch 900] loss: 0.005741852424480384
[Epoch 12, Batch 1000] loss: 0.01118218533291838
[Epoch 12, Batch 1100] loss: 0.008874502231628867
[Epoch 12, Batch 1200] loss: 0.007372362205951504
[Epoch 12, Batch 1300] loss: 0.008648223799687002
[Epoch 12, Batch 1400] loss: 0.004442924320472912
[Epoch 12, Batch 1500] loss: 0.009597467138916045
[Epoch 12, Batch 1600] loss: 0.018513817845241646
[Epoch 12, Batch 1700] loss: 0.013530983964174084
[Epoch 12, Batch 1800] loss: 0.00963724686166188
[Epoch 12, Batch 1900] loss: 0.009492151293968618
[Epoch 12, Batch 2000] loss: 0.01508305129385235
[Epoch 12, Batch 2100] loss: 0.011513418503394632
[Epoch 12, Batch 2200] loss: 0.018396372139775963
[Epoch 12, Batch 2300] loss: 0.012696446727800322
[Epoch 12, Batch 2400] loss: 0.010557878968243131
[Epoch 12, Batch 2500] loss: 0.0073517539545366615
[Epoch 12, Batch 2600] loss: 0.01308506812365522
[Epoch 12, Batch 2700] loss: 0.009097409238864883
[Epoch 12, Batch 2800] loss: 0.009945586537987765
[Epoch 12, Batch 2900] loss: 0.012310293797594341
[Epoch 12, Batch 3000] loss: 0.016653909865060542
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9855
Overfitting: 0.0542
[Epoch 13, Batch 100] loss: 0.014722656048425051
[Epoch 13, Batch 200] loss: 0.006900573096661446
[Epoch 13, Batch 300] loss: 0.012657769893075965
[Epoch 13, Batch 400] loss: 0.005884394864566502
[Epoch 13, Batch 500] loss: 0.004220861653329848
[Epoch 13, Batch 600] loss: 0.008455640311399292
[Epoch 13, Batch 700] loss: 0.0025585347492688014
[Epoch 13, Batch 800] loss: 0.009456576878183114
[Epoch 13, Batch 900] loss: 0.015819981119389013
[Epoch 13, Batch 1000] loss: 0.007721952844237876
[Epoch 13, Batch 1100] loss: 0.016457936754195542
[Epoch 13, Batch 1200] loss: 0.007202615044634513
[Epoch 13, Batch 1300] loss: 0.00472278845118808
[Epoch 13, Batch 1400] loss: 0.010027362348855604
[Epoch 13, Batch 1500] loss: 0.00842022880180025
[Epoch 13, Batch 1600] loss: 0.005861161730604181
[Epoch 13, Batch 1700] loss: 0.005082791611972084
[Epoch 13, Batch 1800] loss: 0.007423383295731583
[Epoch 13, Batch 1900] loss: 0.010175368376771986
[Epoch 13, Batch 2000] loss: 0.006547624202792122
[Epoch 13, Batch 2100] loss: 0.011526530329231833
[Epoch 13, Batch 2200] loss: 0.011154387560731607
[Epoch 13, Batch 2300] loss: 0.007640411498173307
[Epoch 13, Batch 2400] loss: 0.0037926966896839076
[Epoch 13, Batch 2500] loss: 0.004048850125878971
[Epoch 13, Batch 2600] loss: 0.010991691319806023
[Epoch 13, Batch 2700] loss: 0.011548674732784434
[Epoch 13, Batch 2800] loss: 0.006779948768342478
[Epoch 13, Batch 2900] loss: 0.01538799125589776
[Epoch 13, Batch 3000] loss: 0.008221681210529823
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9868
Overfitting: 0.0515
[Epoch 14, Batch 100] loss: 0.011005482147977546
[Epoch 14, Batch 200] loss: 0.005885592974398151
[Epoch 14, Batch 300] loss: 0.0051662524921584916
[Epoch 14, Batch 400] loss: 0.005518870734108319
[Epoch 14, Batch 500] loss: 0.0033032846242031155
[Epoch 14, Batch 600] loss: 0.003848579232051179
[Epoch 14, Batch 700] loss: 0.003370779986320258
[Epoch 14, Batch 800] loss: 0.008811588557559133
[Epoch 14, Batch 900] loss: 0.006881182295177837
[Epoch 14, Batch 1000] loss: 0.00754946697511798
[Epoch 14, Batch 1100] loss: 0.008534055293148128
[Epoch 14, Batch 1200] loss: 0.007568540354579909
[Epoch 14, Batch 1300] loss: 0.004039188158244329
[Epoch 14, Batch 1400] loss: 0.005620967389517091
[Epoch 14, Batch 1500] loss: 0.008378510204436793
[Epoch 14, Batch 1600] loss: 0.005879980692561162
[Epoch 14, Batch 1700] loss: 0.004775903844849836
[Epoch 14, Batch 1800] loss: 0.004826782414455693
[Epoch 14, Batch 1900] loss: 0.008603921910065537
[Epoch 14, Batch 2000] loss: 0.004796830514658268
[Epoch 14, Batch 2100] loss: 0.011118480386664941
[Epoch 14, Batch 2200] loss: 0.009026984281432534
[Epoch 14, Batch 2300] loss: 0.012086549485485988
[Epoch 14, Batch 2400] loss: 0.010104488629248181
[Epoch 14, Batch 2500] loss: 0.011878015168497314
[Epoch 14, Batch 2600] loss: 0.01225609405572584
[Epoch 14, Batch 2700] loss: 0.010595645779909261
[Epoch 14, Batch 2800] loss: 0.011962826084550215
[Epoch 14, Batch 2900] loss: 0.0065412403111122334
[Epoch 14, Batch 3000] loss: 0.011388744115744203
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9870
Overfitting: 0.0534
[Epoch 15, Batch 100] loss: 0.008016061087829485
[Epoch 15, Batch 200] loss: 0.005252093151859753
[Epoch 15, Batch 300] loss: 0.0025466478474913856
[Epoch 15, Batch 400] loss: 0.008876193708850906
[Epoch 15, Batch 500] loss: 0.014376140745259818
[Epoch 15, Batch 600] loss: 0.003782763791650723
[Epoch 15, Batch 700] loss: 0.0036937993570825257
[Epoch 15, Batch 800] loss: 0.007511519784168285
[Epoch 15, Batch 900] loss: 0.00906058446780662
[Epoch 15, Batch 1000] loss: 0.004003292322204288
[Epoch 15, Batch 1100] loss: 0.0024794318444051554
[Epoch 15, Batch 1200] loss: 0.0016439593839345434
[Epoch 15, Batch 1300] loss: 0.002644828717144492
[Epoch 15, Batch 1400] loss: 0.004036602104907274
[Epoch 15, Batch 1500] loss: 0.003808982281768749
[Epoch 15, Batch 1600] loss: 0.01100221486452142
[Epoch 15, Batch 1700] loss: 0.007474365210888721
[Epoch 15, Batch 1800] loss: 0.010219682542189048
[Epoch 15, Batch 1900] loss: 0.013199842129077979
[Epoch 15, Batch 2000] loss: 0.004221338994618122
[Epoch 15, Batch 2100] loss: 0.006286341196113199
[Epoch 15, Batch 2200] loss: 0.005252734331595548
[Epoch 15, Batch 2300] loss: 0.0054372423170025285
[Epoch 15, Batch 2400] loss: 0.006173997922862213
[Epoch 15, Batch 2500] loss: 0.004802554700065968
[Epoch 15, Batch 2600] loss: 0.005950093321212791
[Epoch 15, Batch 2700] loss: 0.006925617737666698
[Epoch 15, Batch 2800] loss: 0.009801286888190361
[Epoch 15, Batch 2900] loss: 0.007551882247241366
[Epoch 15, Batch 3000] loss: 0.016099393027598125
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0613
Validation Accuracy: 0.9853
Overfitting: 0.0613
[Epoch 16, Batch 100] loss: 0.0064092223799036676
[Epoch 16, Batch 200] loss: 0.004990075146256174
[Epoch 16, Batch 300] loss: 0.0022285175173345807
[Epoch 16, Batch 400] loss: 0.004516105227230583
[Epoch 16, Batch 500] loss: 0.007607360261982308
[Epoch 16, Batch 600] loss: 0.002952797026491396
[Epoch 16, Batch 700] loss: 0.0016435352060238982
[Epoch 16, Batch 800] loss: 0.002635198196371107
[Epoch 16, Batch 900] loss: 0.006518000298256794
[Epoch 16, Batch 1000] loss: 0.003868483567504768
[Epoch 16, Batch 1100] loss: 0.0019183835326645137
[Epoch 16, Batch 1200] loss: 0.008576814506743063
[Epoch 16, Batch 1300] loss: 0.008815030712663657
[Epoch 16, Batch 1400] loss: 0.004395759242420923
[Epoch 16, Batch 1500] loss: 0.005524007520478724
[Epoch 16, Batch 1600] loss: 0.007210184153965429
[Epoch 16, Batch 1700] loss: 0.012422986015853503
[Epoch 16, Batch 1800] loss: 0.005725149235941842
[Epoch 16, Batch 1900] loss: 0.0068115345560704555
[Epoch 16, Batch 2000] loss: 0.013128390180661427
[Epoch 16, Batch 2100] loss: 0.0067040306265840855
[Epoch 16, Batch 2200] loss: 0.009132948261915318
[Epoch 16, Batch 2300] loss: 0.0030277683024092996
[Epoch 16, Batch 2400] loss: 0.005493437644173582
[Epoch 16, Batch 2500] loss: 0.0046029849994981475
[Epoch 16, Batch 2600] loss: 0.004294407021615712
[Epoch 16, Batch 2700] loss: 0.01713291870489229
[Epoch 16, Batch 2800] loss: 0.015084121553935575
[Epoch 16, Batch 2900] loss: 0.004765387205457614
[Epoch 16, Batch 3000] loss: 0.009388296378519385
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9858
Overfitting: 0.0586
[Epoch 17, Batch 100] loss: 0.005200902395000639
[Epoch 17, Batch 200] loss: 0.006952358141421726
[Epoch 17, Batch 300] loss: 0.008977435513167223
[Epoch 17, Batch 400] loss: 0.00921011332391302
[Epoch 17, Batch 500] loss: 0.008390254284989851
[Epoch 17, Batch 600] loss: 0.005318782495847927
[Epoch 17, Batch 700] loss: 0.006480228174237937
[Epoch 17, Batch 800] loss: 0.020693673595872042
[Epoch 17, Batch 900] loss: 0.00405009597742687
[Epoch 17, Batch 1000] loss: 0.0029348808961552207
[Epoch 17, Batch 1100] loss: 0.004612288980458175
[Epoch 17, Batch 1200] loss: 0.00719391316522227
[Epoch 17, Batch 1300] loss: 0.0036802659124253977
[Epoch 17, Batch 1400] loss: 0.006365604952212607
[Epoch 17, Batch 1500] loss: 0.0028930246380681267
[Epoch 17, Batch 1600] loss: 0.004011591818837133
[Epoch 17, Batch 1700] loss: 0.005296166667926876
[Epoch 17, Batch 1800] loss: 0.007659076119044031
[Epoch 17, Batch 1900] loss: 0.0083804665827509
[Epoch 17, Batch 2000] loss: 0.0027964585131108597
[Epoch 17, Batch 2100] loss: 0.00417313968045363
[Epoch 17, Batch 2200] loss: 0.009912752535067284
[Epoch 17, Batch 2300] loss: 0.008852719670050248
[Epoch 17, Batch 2400] loss: 0.004348017580780948
[Epoch 17, Batch 2500] loss: 0.004649204014317263
[Epoch 17, Batch 2600] loss: 0.0022180152845203338
[Epoch 17, Batch 2700] loss: 0.0035377188349252717
[Epoch 17, Batch 2800] loss: 0.004819052053595527
[Epoch 17, Batch 2900] loss: 0.0038916555304669485
[Epoch 17, Batch 3000] loss: 0.005116395028784666
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9879
Overfitting: 0.0483
[Epoch 18, Batch 100] loss: 0.002694695098733746
[Epoch 18, Batch 200] loss: 0.0031627661786929905
[Epoch 18, Batch 300] loss: 0.005536991107827873
[Epoch 18, Batch 400] loss: 0.0016885327453418598
[Epoch 18, Batch 500] loss: 0.0010320917133452667
[Epoch 18, Batch 600] loss: 0.0014968828180117555
[Epoch 18, Batch 700] loss: 0.0009746094655963589
[Epoch 18, Batch 800] loss: 0.0028809763172664305
[Epoch 18, Batch 900] loss: 0.0037848756759889567
[Epoch 18, Batch 1000] loss: 0.0038292987251546153
[Epoch 18, Batch 1100] loss: 0.0016887020968523814
[Epoch 18, Batch 1200] loss: 0.0024901636842258766
[Epoch 18, Batch 1300] loss: 0.0032046242816372228
[Epoch 18, Batch 1400] loss: 0.002301060509194883
[Epoch 18, Batch 1500] loss: 0.002161109246112698
[Epoch 18, Batch 1600] loss: 0.002968387005191744
[Epoch 18, Batch 1700] loss: 0.0049295868571954315
[Epoch 18, Batch 1800] loss: 0.0011681022173162603
[Epoch 18, Batch 1900] loss: 0.0035755988351544765
[Epoch 18, Batch 2000] loss: 0.002215373469568469
[Epoch 18, Batch 2100] loss: 0.012285546794457787
[Epoch 18, Batch 2200] loss: 0.006571914419621337
[Epoch 18, Batch 2300] loss: 0.0032578402781316385
[Epoch 18, Batch 2400] loss: 0.0054164066251487595
[Epoch 18, Batch 2500] loss: 0.0020536663356647013
[Epoch 18, Batch 2600] loss: 0.0020879268346020298
[Epoch 18, Batch 2700] loss: 0.0010358368674373254
[Epoch 18, Batch 2800] loss: 0.0019653395527853947
[Epoch 18, Batch 2900] loss: 0.004772022003785708
[Epoch 18, Batch 3000] loss: 0.008811542463026002
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0624
Validation Accuracy: 0.9867
Overfitting: 0.0624
[Epoch 19, Batch 100] loss: 0.0028303330513070437
[Epoch 19, Batch 200] loss: 0.0012203964134285883
[Epoch 19, Batch 300] loss: 0.0019960660511920024
[Epoch 19, Batch 400] loss: 0.001021807669183925
[Epoch 19, Batch 500] loss: 0.0008863101905014048
[Epoch 19, Batch 600] loss: 0.001124377098744418
[Epoch 19, Batch 700] loss: 0.004596732163271167
[Epoch 19, Batch 800] loss: 0.00453220006874627
[Epoch 19, Batch 900] loss: 0.0009625218154011606
[Epoch 19, Batch 1000] loss: 0.0007445127490191794
[Epoch 19, Batch 1100] loss: 0.0012010326549449246
[Epoch 19, Batch 1200] loss: 0.0022820567654228087
[Epoch 19, Batch 1300] loss: 0.010156931795899134
[Epoch 19, Batch 1400] loss: 0.01725888367634866
[Epoch 19, Batch 1500] loss: 0.007569429479460581
[Epoch 19, Batch 1600] loss: 0.005177862228539709
[Epoch 19, Batch 1700] loss: 0.0029265420675230304
[Epoch 19, Batch 1800] loss: 0.0017624907099798293
[Epoch 19, Batch 1900] loss: 0.004700022351437099
[Epoch 19, Batch 2000] loss: 0.002894534424910944
[Epoch 19, Batch 2100] loss: 0.0021449292510408212
[Epoch 19, Batch 2200] loss: 0.0021897541023299994
[Epoch 19, Batch 2300] loss: 0.001666222477843391
[Epoch 19, Batch 2400] loss: 0.002167951516341162
[Epoch 19, Batch 2500] loss: 0.0018549097214649634
[Epoch 19, Batch 2600] loss: 0.000966623222977887
[Epoch 19, Batch 2700] loss: 0.0013323558805429592
[Epoch 19, Batch 2800] loss: 0.0032289197773957314
[Epoch 19, Batch 2900] loss: 0.001321487763000846
[Epoch 19, Batch 3000] loss: 0.0005140541215230599
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9894
Overfitting: 0.0481
[Epoch 20, Batch 100] loss: 0.0005977654436430412
[Epoch 20, Batch 200] loss: 0.0008249387672191189
[Epoch 20, Batch 300] loss: 0.0005711117711357572
[Epoch 20, Batch 400] loss: 0.0004735827198246767
[Epoch 20, Batch 500] loss: 0.0005253425408794321
[Epoch 20, Batch 600] loss: 0.0030310502270174265
[Epoch 20, Batch 700] loss: 0.00099366473754257
[Epoch 20, Batch 800] loss: 0.000795496064440071
[Epoch 20, Batch 900] loss: 0.0007019598434525242
[Epoch 20, Batch 1000] loss: 0.011826107677739506
[Epoch 20, Batch 1100] loss: 0.0026621185688070126
[Epoch 20, Batch 1200] loss: 0.0022235122385476204
[Epoch 20, Batch 1300] loss: 0.0015255503184389595
[Epoch 20, Batch 1400] loss: 0.0042876774538131365
[Epoch 20, Batch 1500] loss: 0.004703832830388119
[Epoch 20, Batch 1600] loss: 0.0008800173398907418
[Epoch 20, Batch 1700] loss: 0.0012573391138917512
[Epoch 20, Batch 1800] loss: 0.0013781396737691232
[Epoch 20, Batch 1900] loss: 0.0005273922783685237
[Epoch 20, Batch 2000] loss: 0.003388827937818064
[Epoch 20, Batch 2100] loss: 0.004881113894523566
[Epoch 20, Batch 2200] loss: 0.0013594761163873415
[Epoch 20, Batch 2300] loss: 0.001139076888713646
[Epoch 20, Batch 2400] loss: 0.004194528400577848
[Epoch 20, Batch 2500] loss: 0.0018663352059495252
[Epoch 20, Batch 2600] loss: 0.003029627348005377
[Epoch 20, Batch 2700] loss: 0.0005811154825675402
[Epoch 20, Batch 2800] loss: 0.0010051714281455659
[Epoch 20, Batch 2900] loss: 0.002639589384105383
[Epoch 20, Batch 3000] loss: 0.0015228683110359497
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9884
Overfitting: 0.0492
[Epoch 21, Batch 100] loss: 0.0010875212506280718
[Epoch 21, Batch 200] loss: 0.0012676303172774795
[Epoch 21, Batch 300] loss: 0.0008248244083222289
[Epoch 21, Batch 400] loss: 0.0008529989530714488
[Epoch 21, Batch 500] loss: 0.0005889488644595265
[Epoch 21, Batch 600] loss: 0.0013826641925353967
[Epoch 21, Batch 700] loss: 0.0011677412315445502
[Epoch 21, Batch 800] loss: 0.0014924053467005472
[Epoch 21, Batch 900] loss: 0.0010984516603089033
[Epoch 21, Batch 1000] loss: 0.00034418559354756353
[Epoch 21, Batch 1100] loss: 0.0006996365578643004
[Epoch 21, Batch 1200] loss: 0.0006576261030856356
[Epoch 21, Batch 1300] loss: 0.00027939659469481624
[Epoch 21, Batch 1400] loss: 0.0003803923580193569
[Epoch 21, Batch 1500] loss: 0.003896774951953077
[Epoch 21, Batch 1600] loss: 0.0004338558625589739
[Epoch 21, Batch 1700] loss: 0.005871621265543609
[Epoch 21, Batch 1800] loss: 0.0009715984889569728
[Epoch 21, Batch 1900] loss: 0.0006995049427576205
[Epoch 21, Batch 2000] loss: 0.0014874442369635864
[Epoch 21, Batch 2100] loss: 0.0006618232386603262
[Epoch 21, Batch 2200] loss: 0.0007519454810947934
[Epoch 21, Batch 2300] loss: 0.0008078929265906209
[Epoch 21, Batch 2400] loss: 0.00046798065927404763
[Epoch 21, Batch 2500] loss: 0.0015092663027000519
[Epoch 21, Batch 2600] loss: 0.0009594322372218711
[Epoch 21, Batch 2700] loss: 0.0012316900579735046
[Epoch 21, Batch 2800] loss: 0.002327902647222295
[Epoch 21, Batch 2900] loss: 0.0018175809308549518
[Epoch 21, Batch 3000] loss: 0.0007309919485959426
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9898
Overfitting: 0.0481
[Epoch 22, Batch 100] loss: 0.00034605561889824
[Epoch 22, Batch 200] loss: 0.0007169439885376506
[Epoch 22, Batch 300] loss: 0.00036626475264852856
[Epoch 22, Batch 400] loss: 0.0011437764658055417
[Epoch 22, Batch 500] loss: 0.00030398151038006914
[Epoch 22, Batch 600] loss: 0.002347797973666985
[Epoch 22, Batch 700] loss: 0.006283318580550765
[Epoch 22, Batch 800] loss: 0.0014490901226702402
[Epoch 22, Batch 900] loss: 0.001283262286933886
[Epoch 22, Batch 1000] loss: 0.0007587905088334246
[Epoch 22, Batch 1100] loss: 0.00042262813794611274
[Epoch 22, Batch 1200] loss: 0.0003880331219365996
[Epoch 22, Batch 1300] loss: 0.000768226509212715
[Epoch 22, Batch 1400] loss: 0.0006560211981894736
[Epoch 22, Batch 1500] loss: 0.00032179631008570907
[Epoch 22, Batch 1600] loss: 0.0006630323961557672
[Epoch 22, Batch 1700] loss: 0.0005207779706108439
[Epoch 22, Batch 1800] loss: 0.0003311230154552902
[Epoch 22, Batch 1900] loss: 0.0001550135272105102
[Epoch 22, Batch 2000] loss: 0.001596292044940113
[Epoch 22, Batch 2100] loss: 0.0006351504620715387
[Epoch 22, Batch 2200] loss: 0.00028943254973640365
[Epoch 22, Batch 2300] loss: 0.0005040406053020518
[Epoch 22, Batch 2400] loss: 0.0006229053318941879
[Epoch 22, Batch 2500] loss: 0.0005437873630745571
[Epoch 22, Batch 2600] loss: 0.000831161240492353
[Epoch 22, Batch 2700] loss: 0.00030260631431132444
[Epoch 22, Batch 2800] loss: 0.0003342067786996949
[Epoch 22, Batch 2900] loss: 0.0002871116532368978
[Epoch 22, Batch 3000] loss: 0.0008881318762553247
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9894
Overfitting: 0.0495
[Epoch 23, Batch 100] loss: 0.00044788427198234616
[Epoch 23, Batch 200] loss: 0.000297656934905941
[Epoch 23, Batch 300] loss: 0.002690319612810015
[Epoch 23, Batch 400] loss: 0.0007146642234069445
[Epoch 23, Batch 500] loss: 0.0008405553156872747
[Epoch 23, Batch 600] loss: 0.00048709282157171073
[Epoch 23, Batch 700] loss: 0.0006477906971481273
[Epoch 23, Batch 800] loss: 0.0005040462538424606
[Epoch 23, Batch 900] loss: 0.0003758390610474427
[Epoch 23, Batch 1000] loss: 0.00042849749600465614
[Epoch 23, Batch 1100] loss: 0.001266685766356712
[Epoch 23, Batch 1200] loss: 0.0005362714225729003
[Epoch 23, Batch 1300] loss: 0.0006798636372315769
[Epoch 23, Batch 1400] loss: 0.00026337983713714763
[Epoch 23, Batch 1500] loss: 0.00020108109576323142
[Epoch 23, Batch 1600] loss: 0.00017980793987822707
[Epoch 23, Batch 1700] loss: 0.0010334745475489538
[Epoch 23, Batch 1800] loss: 0.0005450781639691149
[Epoch 23, Batch 1900] loss: 0.00035280086032476456
[Epoch 23, Batch 2000] loss: 0.0002531663180422328
[Epoch 23, Batch 2100] loss: 0.0014067806333159004
[Epoch 23, Batch 2200] loss: 0.00028887042629229144
[Epoch 23, Batch 2300] loss: 0.0002757773444381151
[Epoch 23, Batch 2400] loss: 0.00017035787213145247
[Epoch 23, Batch 2500] loss: 0.0007855590886617092
[Epoch 23, Batch 2600] loss: 0.0005336590350075409
[Epoch 23, Batch 2700] loss: 0.00027347919819714406
[Epoch 23, Batch 2800] loss: 0.00022932060355612905
[Epoch 23, Batch 2900] loss: 0.0010738589448958135
[Epoch 23, Batch 3000] loss: 0.0003550930963762466
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0498
Validation Accuracy: 0.9899
Overfitting: 0.0498
[Epoch 24, Batch 100] loss: 0.0001816937268077723
[Epoch 24, Batch 200] loss: 0.00022598866147073072
[Epoch 24, Batch 300] loss: 0.00017949895308794873
[Epoch 24, Batch 400] loss: 0.0007781650262048068
[Epoch 24, Batch 500] loss: 0.001279967396821977
[Epoch 24, Batch 600] loss: 0.00045940257449008206
[Epoch 24, Batch 700] loss: 0.0003078324775744834
[Epoch 24, Batch 800] loss: 0.00018518506367300346
[Epoch 24, Batch 900] loss: 0.0003363490638599931
[Epoch 24, Batch 1000] loss: 0.00017544205923279322
[Epoch 24, Batch 1100] loss: 0.00012752274106045291
[Epoch 24, Batch 1200] loss: 0.00043465314920701823
[Epoch 24, Batch 1300] loss: 0.00020769097250084468
[Epoch 24, Batch 1400] loss: 0.0005795180364669328
[Epoch 24, Batch 1500] loss: 0.0003283587704465507
[Epoch 24, Batch 1600] loss: 0.0011080941811816914
[Epoch 24, Batch 1700] loss: 0.0016338020509039453
[Epoch 24, Batch 1800] loss: 0.0018026425355441233
[Epoch 24, Batch 1900] loss: 0.0022595017666075233
[Epoch 24, Batch 2000] loss: 0.0016432424844022896
[Epoch 24, Batch 2100] loss: 0.0013635351405184792
[Epoch 24, Batch 2200] loss: 0.0014204356850588162
[Epoch 24, Batch 2300] loss: 0.0003032185275878163
[Epoch 24, Batch 2400] loss: 0.0003297993378956487
[Epoch 24, Batch 2500] loss: 0.0009719879118436437
[Epoch 24, Batch 2600] loss: 0.00021670771252884968
[Epoch 24, Batch 2700] loss: 0.0002242626801810621
[Epoch 24, Batch 2800] loss: 0.00018128053345978223
[Epoch 24, Batch 2900] loss: 0.0002746914817696222
[Epoch 24, Batch 3000] loss: 0.00032921316343092143
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9900
Overfitting: 0.0495
Fold 4 validation loss: 0.0495
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2961469388008116
[Epoch 1, Batch 200] loss: 2.191811021566391
[Epoch 1, Batch 300] loss: 1.3755251806974411
[Epoch 1, Batch 400] loss: 0.6521442811191082
[Epoch 1, Batch 500] loss: 0.4418844024837017
[Epoch 1, Batch 600] loss: 0.39951803971081973
[Epoch 1, Batch 700] loss: 0.35732209160923956
[Epoch 1, Batch 800] loss: 0.2690231024287641
[Epoch 1, Batch 900] loss: 0.27016678286716345
[Epoch 1, Batch 1000] loss: 0.2614029251690954
[Epoch 1, Batch 1100] loss: 0.2421559226512909
[Epoch 1, Batch 1200] loss: 0.238710089745
[Epoch 1, Batch 1300] loss: 0.18513810164295136
[Epoch 1, Batch 1400] loss: 0.18937298065982758
[Epoch 1, Batch 1500] loss: 0.1775944778788835
[Epoch 1, Batch 1600] loss: 0.153357656262815
[Epoch 1, Batch 1700] loss: 0.17343914314638822
[Epoch 1, Batch 1800] loss: 0.19246789543889464
[Epoch 1, Batch 1900] loss: 0.13310712731210514
[Epoch 1, Batch 2000] loss: 0.1159588269283995
[Epoch 1, Batch 2100] loss: 0.12516484295832925
[Epoch 1, Batch 2200] loss: 0.1520774889457971
[Epoch 1, Batch 2300] loss: 0.12842235462972895
[Epoch 1, Batch 2400] loss: 0.14417456310475246
[Epoch 1, Batch 2500] loss: 0.10411230025580152
[Epoch 1, Batch 2600] loss: 0.13074419482145458
[Epoch 1, Batch 2700] loss: 0.11672627164516598
[Epoch 1, Batch 2800] loss: 0.12748613805975764
[Epoch 1, Batch 2900] loss: 0.09726453478448092
[Epoch 1, Batch 3000] loss: 0.11173491499153897
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1074
Validation Accuracy: 0.9683
Overfitting: 0.1074
Best model saved at epoch 1 with validation loss: 0.1074
[Epoch 2, Batch 100] loss: 0.10238182928995229
[Epoch 2, Batch 200] loss: 0.09610422702040523
[Epoch 2, Batch 300] loss: 0.10793620192329399
[Epoch 2, Batch 400] loss: 0.10082370582036675
[Epoch 2, Batch 500] loss: 0.0782860367395915
[Epoch 2, Batch 600] loss: 0.0949103761796141
[Epoch 2, Batch 700] loss: 0.07392808811389841
[Epoch 2, Batch 800] loss: 0.07807059010956437
[Epoch 2, Batch 900] loss: 0.07480372251477092
[Epoch 2, Batch 1000] loss: 0.09063713816402014
[Epoch 2, Batch 1100] loss: 0.09859229298657737
[Epoch 2, Batch 1200] loss: 0.09306746049202047
[Epoch 2, Batch 1300] loss: 0.10069505633320659
[Epoch 2, Batch 1400] loss: 0.08919778287701774
[Epoch 2, Batch 1500] loss: 0.0908092924032826
[Epoch 2, Batch 1600] loss: 0.0891052070679143
[Epoch 2, Batch 1700] loss: 0.06840446932066697
[Epoch 2, Batch 1800] loss: 0.0885963936522603
[Epoch 2, Batch 1900] loss: 0.06988256250391714
[Epoch 2, Batch 2000] loss: 0.09634499757550657
[Epoch 2, Batch 2100] loss: 0.06901074101333507
[Epoch 2, Batch 2200] loss: 0.062364492819324366
[Epoch 2, Batch 2300] loss: 0.07425687012029812
[Epoch 2, Batch 2400] loss: 0.06466473447275348
[Epoch 2, Batch 2500] loss: 0.06822538813285065
[Epoch 2, Batch 2600] loss: 0.0814807616226608
[Epoch 2, Batch 2700] loss: 0.0792763431055937
[Epoch 2, Batch 2800] loss: 0.0666956627019681
[Epoch 2, Batch 2900] loss: 0.08287159343832172
[Epoch 2, Batch 3000] loss: 0.04689113517408259
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0640
Validation Accuracy: 0.9798
Overfitting: 0.0640
Best model saved at epoch 2 with validation loss: 0.0640
[Epoch 3, Batch 100] loss: 0.07340425124159083
[Epoch 3, Batch 200] loss: 0.04689937489922159
[Epoch 3, Batch 300] loss: 0.05520634046057239
[Epoch 3, Batch 400] loss: 0.06574683220533188
[Epoch 3, Batch 500] loss: 0.05473057140596211
[Epoch 3, Batch 600] loss: 0.04855687338218559
[Epoch 3, Batch 700] loss: 0.05605177118413849
[Epoch 3, Batch 800] loss: 0.0429860578867374
[Epoch 3, Batch 900] loss: 0.05201425323728472
[Epoch 3, Batch 1000] loss: 0.050369855929457114
[Epoch 3, Batch 1100] loss: 0.046112716490933965
[Epoch 3, Batch 1200] loss: 0.058900520016031806
[Epoch 3, Batch 1300] loss: 0.07670890178938862
[Epoch 3, Batch 1400] loss: 0.06220686208689585
[Epoch 3, Batch 1500] loss: 0.04928522199013969
[Epoch 3, Batch 1600] loss: 0.05541884657228366
[Epoch 3, Batch 1700] loss: 0.048812102121446516
[Epoch 3, Batch 1800] loss: 0.06272007177612977
[Epoch 3, Batch 1900] loss: 0.08649760233063716
[Epoch 3, Batch 2000] loss: 0.05029764924780466
[Epoch 3, Batch 2100] loss: 0.05443760471593123
[Epoch 3, Batch 2200] loss: 0.06639114533143584
[Epoch 3, Batch 2300] loss: 0.0549770477891434
[Epoch 3, Batch 2400] loss: 0.048962655733630525
[Epoch 3, Batch 2500] loss: 0.06460247566981707
[Epoch 3, Batch 2600] loss: 0.056833542439271696
[Epoch 3, Batch 2700] loss: 0.06404079716128763
[Epoch 3, Batch 2800] loss: 0.048916799389699006
[Epoch 3, Batch 2900] loss: 0.06588161978725111
[Epoch 3, Batch 3000] loss: 0.06944937108171871
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0604
Validation Accuracy: 0.9804
Overfitting: 0.0604
Best model saved at epoch 3 with validation loss: 0.0604
[Epoch 4, Batch 100] loss: 0.04227958314004354
[Epoch 4, Batch 200] loss: 0.051179180975886994
[Epoch 4, Batch 300] loss: 0.052751224311359694
[Epoch 4, Batch 400] loss: 0.046214495847525544
[Epoch 4, Batch 500] loss: 0.04655885279702488
[Epoch 4, Batch 600] loss: 0.04459683907829458
[Epoch 4, Batch 700] loss: 0.053965957414038715
[Epoch 4, Batch 800] loss: 0.05515987748774933
[Epoch 4, Batch 900] loss: 0.05298008546989877
[Epoch 4, Batch 1000] loss: 0.04971350761596113
[Epoch 4, Batch 1100] loss: 0.04639343295159051
[Epoch 4, Batch 1200] loss: 0.03867246395624534
[Epoch 4, Batch 1300] loss: 0.04620513653761009
[Epoch 4, Batch 1400] loss: 0.05023961849772604
[Epoch 4, Batch 1500] loss: 0.05198329712555278
[Epoch 4, Batch 1600] loss: 0.06201955035270657
[Epoch 4, Batch 1700] loss: 0.02983210966718616
[Epoch 4, Batch 1800] loss: 0.029041296071663964
[Epoch 4, Batch 1900] loss: 0.028983528464159462
[Epoch 4, Batch 2000] loss: 0.04905240239269915
[Epoch 4, Batch 2100] loss: 0.03714069678375381
[Epoch 4, Batch 2200] loss: 0.048783876881643665
[Epoch 4, Batch 2300] loss: 0.04619673594483174
[Epoch 4, Batch 2400] loss: 0.04072658973513171
[Epoch 4, Batch 2500] loss: 0.04578263058778248
[Epoch 4, Batch 2600] loss: 0.033127884082423405
[Epoch 4, Batch 2700] loss: 0.039645399980436195
[Epoch 4, Batch 2800] loss: 0.04893205182277598
[Epoch 4, Batch 2900] loss: 0.0400640177942114
[Epoch 4, Batch 3000] loss: 0.02323037921516516
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9849
Overfitting: 0.0470
Best model saved at epoch 4 with validation loss: 0.0470
[Epoch 5, Batch 100] loss: 0.029476006740005688
[Epoch 5, Batch 200] loss: 0.02118880103167612
[Epoch 5, Batch 300] loss: 0.0400376033505745
[Epoch 5, Batch 400] loss: 0.0328748681867728
[Epoch 5, Batch 500] loss: 0.036764435154509556
[Epoch 5, Batch 600] loss: 0.05364009404700482
[Epoch 5, Batch 700] loss: 0.027516547803970753
[Epoch 5, Batch 800] loss: 0.0353089426617953
[Epoch 5, Batch 900] loss: 0.033102351953057225
[Epoch 5, Batch 1000] loss: 0.04355171434421209
[Epoch 5, Batch 1100] loss: 0.02827444267953979
[Epoch 5, Batch 1200] loss: 0.04976864961688989
[Epoch 5, Batch 1300] loss: 0.035181602945231136
[Epoch 5, Batch 1400] loss: 0.024667658482394474
[Epoch 5, Batch 1500] loss: 0.02882655595938559
[Epoch 5, Batch 1600] loss: 0.03730871892585128
[Epoch 5, Batch 1700] loss: 0.027491540518312832
[Epoch 5, Batch 1800] loss: 0.049744122290649104
[Epoch 5, Batch 1900] loss: 0.03428108949381567
[Epoch 5, Batch 2000] loss: 0.037346422693080965
[Epoch 5, Batch 2100] loss: 0.03210372744841152
[Epoch 5, Batch 2200] loss: 0.028544159559824037
[Epoch 5, Batch 2300] loss: 0.03643390521981928
[Epoch 5, Batch 2400] loss: 0.04293081297117169
[Epoch 5, Batch 2500] loss: 0.047273363855783825
[Epoch 5, Batch 2600] loss: 0.03485520841597463
[Epoch 5, Batch 2700] loss: 0.036122895916778364
[Epoch 5, Batch 2800] loss: 0.03520514195464784
[Epoch 5, Batch 2900] loss: 0.04805821626214311
[Epoch 5, Batch 3000] loss: 0.028297324220475276
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0419
Validation Accuracy: 0.9862
Overfitting: 0.0419
Best model saved at epoch 5 with validation loss: 0.0419
[Epoch 6, Batch 100] loss: 0.023365000495541608
[Epoch 6, Batch 200] loss: 0.014258925293652282
[Epoch 6, Batch 300] loss: 0.021013933588110375
[Epoch 6, Batch 400] loss: 0.018411231296195183
[Epoch 6, Batch 500] loss: 0.03320511783960683
[Epoch 6, Batch 600] loss: 0.03510518213239266
[Epoch 6, Batch 700] loss: 0.035093502179952336
[Epoch 6, Batch 800] loss: 0.02864365608773369
[Epoch 6, Batch 900] loss: 0.0182634582857645
[Epoch 6, Batch 1000] loss: 0.02760451981703227
[Epoch 6, Batch 1100] loss: 0.03474636688057217
[Epoch 6, Batch 1200] loss: 0.036729562646942215
[Epoch 6, Batch 1300] loss: 0.021002329877228477
[Epoch 6, Batch 1400] loss: 0.025826723305362974
[Epoch 6, Batch 1500] loss: 0.021890137690461414
[Epoch 6, Batch 1600] loss: 0.031709238596522485
[Epoch 6, Batch 1700] loss: 0.020312980927410535
[Epoch 6, Batch 1800] loss: 0.028978013189771445
[Epoch 6, Batch 1900] loss: 0.032493750389367054
[Epoch 6, Batch 2000] loss: 0.027344254290292157
[Epoch 6, Batch 2100] loss: 0.04072267742965778
[Epoch 6, Batch 2200] loss: 0.03370252893197176
[Epoch 6, Batch 2300] loss: 0.035322392908856276
[Epoch 6, Batch 2400] loss: 0.026591998448056983
[Epoch 6, Batch 2500] loss: 0.048850552356016125
[Epoch 6, Batch 2600] loss: 0.04709819032461383
[Epoch 6, Batch 2700] loss: 0.026172478843072895
[Epoch 6, Batch 2800] loss: 0.03202222764317412
[Epoch 6, Batch 2900] loss: 0.03627109399116307
[Epoch 6, Batch 3000] loss: 0.035459292404775626
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0417
Validation Accuracy: 0.9865
Overfitting: 0.0417
Best model saved at epoch 6 with validation loss: 0.0417
[Epoch 7, Batch 100] loss: 0.025489554134546778
[Epoch 7, Batch 200] loss: 0.025523062755091815
[Epoch 7, Batch 300] loss: 0.02184255302836391
[Epoch 7, Batch 400] loss: 0.03366113778327417
[Epoch 7, Batch 500] loss: 0.020966007171518867
[Epoch 7, Batch 600] loss: 0.029697297559323488
[Epoch 7, Batch 700] loss: 0.02550542846038297
[Epoch 7, Batch 800] loss: 0.029265403837343912
[Epoch 7, Batch 900] loss: 0.020438581689968486
[Epoch 7, Batch 1000] loss: 0.023687378694012294
[Epoch 7, Batch 1100] loss: 0.01730539290671004
[Epoch 7, Batch 1200] loss: 0.016828631763055456
[Epoch 7, Batch 1300] loss: 0.01676220353529061
[Epoch 7, Batch 1400] loss: 0.0314585916341457
[Epoch 7, Batch 1500] loss: 0.024530079381584073
[Epoch 7, Batch 1600] loss: 0.020299363108497347
[Epoch 7, Batch 1700] loss: 0.020587036592405638
[Epoch 7, Batch 1800] loss: 0.019555205703600222
[Epoch 7, Batch 1900] loss: 0.04559972304406983
[Epoch 7, Batch 2000] loss: 0.02330161201476585
[Epoch 7, Batch 2100] loss: 0.03275557452627254
[Epoch 7, Batch 2200] loss: 0.020751383391980197
[Epoch 7, Batch 2300] loss: 0.034141657310538
[Epoch 7, Batch 2400] loss: 0.022939178105607427
[Epoch 7, Batch 2500] loss: 0.029142889784088764
[Epoch 7, Batch 2600] loss: 0.01667142848487856
[Epoch 7, Batch 2700] loss: 0.016477085030310264
[Epoch 7, Batch 2800] loss: 0.015568103329824225
[Epoch 7, Batch 2900] loss: 0.02371089756168658
[Epoch 7, Batch 3000] loss: 0.026036861726097413
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0419
Validation Accuracy: 0.9875
Overfitting: 0.0419
[Epoch 8, Batch 100] loss: 0.03398507335623435
[Epoch 8, Batch 200] loss: 0.01469684556741413
[Epoch 8, Batch 300] loss: 0.01196608601884691
[Epoch 8, Batch 400] loss: 0.010647613702130911
[Epoch 8, Batch 500] loss: 0.020997659156237206
[Epoch 8, Batch 600] loss: 0.025595761989752646
[Epoch 8, Batch 700] loss: 0.020761195222803508
[Epoch 8, Batch 800] loss: 0.023225641165990966
[Epoch 8, Batch 900] loss: 0.01272986822965322
[Epoch 8, Batch 1000] loss: 0.02421350114134839
[Epoch 8, Batch 1100] loss: 0.01867085014969234
[Epoch 8, Batch 1200] loss: 0.023309567358628557
[Epoch 8, Batch 1300] loss: 0.02445611323345929
[Epoch 8, Batch 1400] loss: 0.021361917267809075
[Epoch 8, Batch 1500] loss: 0.016170588350905745
[Epoch 8, Batch 1600] loss: 0.009010242769509205
[Epoch 8, Batch 1700] loss: 0.017017876221325424
[Epoch 8, Batch 1800] loss: 0.021951330916263032
[Epoch 8, Batch 1900] loss: 0.01703839922840416
[Epoch 8, Batch 2000] loss: 0.01686998808876524
[Epoch 8, Batch 2100] loss: 0.02303388659518532
[Epoch 8, Batch 2200] loss: 0.0338215368877718
[Epoch 8, Batch 2300] loss: 0.018443758182220337
[Epoch 8, Batch 2400] loss: 0.013782706583451727
[Epoch 8, Batch 2500] loss: 0.013549211208028282
[Epoch 8, Batch 2600] loss: 0.03664872356603155
[Epoch 8, Batch 2700] loss: 0.035750778254005126
[Epoch 8, Batch 2800] loss: 0.019237618120532717
[Epoch 8, Batch 2900] loss: 0.021653324282960965
[Epoch 8, Batch 3000] loss: 0.017739143048402184
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9854
Overfitting: 0.0458
[Epoch 9, Batch 100] loss: 0.010684739261159848
[Epoch 9, Batch 200] loss: 0.011595927897305956
[Epoch 9, Batch 300] loss: 0.0176926527708747
[Epoch 9, Batch 400] loss: 0.018731969973978267
[Epoch 9, Batch 500] loss: 0.016677988598285082
[Epoch 9, Batch 600] loss: 0.011755980971056488
[Epoch 9, Batch 700] loss: 0.017250353155814083
[Epoch 9, Batch 800] loss: 0.00983548058924498
[Epoch 9, Batch 900] loss: 0.01905539508594302
[Epoch 9, Batch 1000] loss: 0.01575962768859881
[Epoch 9, Batch 1100] loss: 0.019744149117377673
[Epoch 9, Batch 1200] loss: 0.016073017317903577
[Epoch 9, Batch 1300] loss: 0.016340415203776503
[Epoch 9, Batch 1400] loss: 0.0185049050851012
[Epoch 9, Batch 1500] loss: 0.01761775679868151
[Epoch 9, Batch 1600] loss: 0.012230429990631819
[Epoch 9, Batch 1700] loss: 0.023794079969707126
[Epoch 9, Batch 1800] loss: 0.019463159092083515
[Epoch 9, Batch 1900] loss: 0.010142426896545658
[Epoch 9, Batch 2000] loss: 0.018397201885527466
[Epoch 9, Batch 2100] loss: 0.01595637291766252
[Epoch 9, Batch 2200] loss: 0.016664762524378603
[Epoch 9, Batch 2300] loss: 0.005219294553353393
[Epoch 9, Batch 2400] loss: 0.023107857092536505
[Epoch 9, Batch 2500] loss: 0.0208328919271662
[Epoch 9, Batch 2600] loss: 0.02364327163737471
[Epoch 9, Batch 2700] loss: 0.02532029374891863
[Epoch 9, Batch 2800] loss: 0.0231452842130966
[Epoch 9, Batch 2900] loss: 0.021517974348098504
[Epoch 9, Batch 3000] loss: 0.01871812541168765
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9861
Overfitting: 0.0494
[Epoch 10, Batch 100] loss: 0.021176383117235673
[Epoch 10, Batch 200] loss: 0.007565142400908371
[Epoch 10, Batch 300] loss: 0.018357782452585524
[Epoch 10, Batch 400] loss: 0.009984441747710661
[Epoch 10, Batch 500] loss: 0.019345625746300357
[Epoch 10, Batch 600] loss: 0.014983774760075903
[Epoch 10, Batch 700] loss: 0.013359374126998773
[Epoch 10, Batch 800] loss: 0.013852151912942645
[Epoch 10, Batch 900] loss: 0.013631234184549612
[Epoch 10, Batch 1000] loss: 0.017540524762971473
[Epoch 10, Batch 1100] loss: 0.008259632357276132
[Epoch 10, Batch 1200] loss: 0.018608701835401007
[Epoch 10, Batch 1300] loss: 0.02752991629367898
[Epoch 10, Batch 1400] loss: 0.022572842651097744
[Epoch 10, Batch 1500] loss: 0.015727939093849272
[Epoch 10, Batch 1600] loss: 0.014251408161271684
[Epoch 10, Batch 1700] loss: 0.010758302702097353
[Epoch 10, Batch 1800] loss: 0.015855302633492555
[Epoch 10, Batch 1900] loss: 0.01226229360348043
[Epoch 10, Batch 2000] loss: 0.008370738347730366
[Epoch 10, Batch 2100] loss: 0.016285065361648775
[Epoch 10, Batch 2200] loss: 0.008649707770259737
[Epoch 10, Batch 2300] loss: 0.00969771013702939
[Epoch 10, Batch 2400] loss: 0.011023948189863403
[Epoch 10, Batch 2500] loss: 0.007860830861127398
[Epoch 10, Batch 2600] loss: 0.015978768743420916
[Epoch 10, Batch 2700] loss: 0.017168268575769616
[Epoch 10, Batch 2800] loss: 0.016680938372273885
[Epoch 10, Batch 2900] loss: 0.029377175312474718
[Epoch 10, Batch 3000] loss: 0.014714355899168368
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0388
Validation Accuracy: 0.9888
Overfitting: 0.0388
Best model saved at epoch 10 with validation loss: 0.0388
[Epoch 11, Batch 100] loss: 0.008738283353050064
[Epoch 11, Batch 200] loss: 0.007826392467432015
[Epoch 11, Batch 300] loss: 0.018382489961181817
[Epoch 11, Batch 400] loss: 0.014366036751798674
[Epoch 11, Batch 500] loss: 0.009572747623338955
[Epoch 11, Batch 600] loss: 0.010151050344343276
[Epoch 11, Batch 700] loss: 0.011869151671617147
[Epoch 11, Batch 800] loss: 0.005911012077417581
[Epoch 11, Batch 900] loss: 0.006306253169541378
[Epoch 11, Batch 1000] loss: 0.004444873126708444
[Epoch 11, Batch 1100] loss: 0.018580093161072
[Epoch 11, Batch 1200] loss: 0.013996154337037296
[Epoch 11, Batch 1300] loss: 0.009763707987940507
[Epoch 11, Batch 1400] loss: 0.020850330286575628
[Epoch 11, Batch 1500] loss: 0.021184155171067687
[Epoch 11, Batch 1600] loss: 0.006072878348768427
[Epoch 11, Batch 1700] loss: 0.009693435363310528
[Epoch 11, Batch 1800] loss: 0.0038616723240386362
[Epoch 11, Batch 1900] loss: 0.01229182340679472
[Epoch 11, Batch 2000] loss: 0.021713138541658735
[Epoch 11, Batch 2100] loss: 0.006614256280508926
[Epoch 11, Batch 2200] loss: 0.015185450174112703
[Epoch 11, Batch 2300] loss: 0.007092754596687883
[Epoch 11, Batch 2400] loss: 0.00938742399084731
[Epoch 11, Batch 2500] loss: 0.011598208496843654
[Epoch 11, Batch 2600] loss: 0.014906726087874632
[Epoch 11, Batch 2700] loss: 0.01800850740817168
[Epoch 11, Batch 2800] loss: 0.020645300522783145
[Epoch 11, Batch 2900] loss: 0.013224601405570411
[Epoch 11, Batch 3000] loss: 0.005801092042352138
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0425
Validation Accuracy: 0.9886
Overfitting: 0.0425
[Epoch 12, Batch 100] loss: 0.00504692184194937
[Epoch 12, Batch 200] loss: 0.010073790587885014
[Epoch 12, Batch 300] loss: 0.007928268833343282
[Epoch 12, Batch 400] loss: 0.005498758313297003
[Epoch 12, Batch 500] loss: 0.006177621954584538
[Epoch 12, Batch 600] loss: 0.0018797978757493184
[Epoch 12, Batch 700] loss: 0.015551852988346581
[Epoch 12, Batch 800] loss: 0.013508038141142152
[Epoch 12, Batch 900] loss: 0.007733871396502536
[Epoch 12, Batch 1000] loss: 0.009915720875918623
[Epoch 12, Batch 1100] loss: 0.006885648052907527
[Epoch 12, Batch 1200] loss: 0.0058491560533639134
[Epoch 12, Batch 1300] loss: 0.006042350719990281
[Epoch 12, Batch 1400] loss: 0.01480985315105613
[Epoch 12, Batch 1500] loss: 0.005505338398163531
[Epoch 12, Batch 1600] loss: 0.014233008466865158
[Epoch 12, Batch 1700] loss: 0.013182150689208355
[Epoch 12, Batch 1800] loss: 0.011296303117783282
[Epoch 12, Batch 1900] loss: 0.0095307839609427
[Epoch 12, Batch 2000] loss: 0.014062972302704112
[Epoch 12, Batch 2100] loss: 0.00848355864755149
[Epoch 12, Batch 2200] loss: 0.007929024043951358
[Epoch 12, Batch 2300] loss: 0.011003220443817553
[Epoch 12, Batch 2400] loss: 0.008673550388557487
[Epoch 12, Batch 2500] loss: 0.01731057788696944
[Epoch 12, Batch 2600] loss: 0.015761352873682882
[Epoch 12, Batch 2700] loss: 0.012254057032987476
[Epoch 12, Batch 2800] loss: 0.015579643548844615
[Epoch 12, Batch 2900] loss: 0.021422513105653705
[Epoch 12, Batch 3000] loss: 0.01774657482109433
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9882
Overfitting: 0.0431
[Epoch 13, Batch 100] loss: 0.009010632042293309
[Epoch 13, Batch 200] loss: 0.015091680893219746
[Epoch 13, Batch 300] loss: 0.017054893521773237
[Epoch 13, Batch 400] loss: 0.007346606290138879
[Epoch 13, Batch 500] loss: 0.006610268461208761
[Epoch 13, Batch 600] loss: 0.007345761876922552
[Epoch 13, Batch 700] loss: 0.004521446853805173
[Epoch 13, Batch 800] loss: 0.0101091302974055
[Epoch 13, Batch 900] loss: 0.009244731456046793
[Epoch 13, Batch 1000] loss: 0.011662168510843002
[Epoch 13, Batch 1100] loss: 0.00865903979538416
[Epoch 13, Batch 1200] loss: 0.015031655887360102
[Epoch 13, Batch 1300] loss: 0.0048746843991102655
[Epoch 13, Batch 1400] loss: 0.009283391181731986
[Epoch 13, Batch 1500] loss: 0.005177300036511952
[Epoch 13, Batch 1600] loss: 0.00979373548942931
[Epoch 13, Batch 1700] loss: 0.0064537580552219255
[Epoch 13, Batch 1800] loss: 0.0034456467957988935
[Epoch 13, Batch 1900] loss: 0.006741635901334462
[Epoch 13, Batch 2000] loss: 0.009672045915515355
[Epoch 13, Batch 2100] loss: 0.01192777970041334
[Epoch 13, Batch 2200] loss: 0.00823300694993577
[Epoch 13, Batch 2300] loss: 0.009215630625342329
[Epoch 13, Batch 2400] loss: 0.011289797123422431
[Epoch 13, Batch 2500] loss: 0.006863383949182662
[Epoch 13, Batch 2600] loss: 0.00976982769002916
[Epoch 13, Batch 2700] loss: 0.006607963608445857
[Epoch 13, Batch 2800] loss: 0.008027706251968993
[Epoch 13, Batch 2900] loss: 0.014614329044675287
[Epoch 13, Batch 3000] loss: 0.013539512941622433
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9871
Overfitting: 0.0509
[Epoch 14, Batch 100] loss: 0.0069380492650321915
[Epoch 14, Batch 200] loss: 0.011696085040762227
[Epoch 14, Batch 300] loss: 0.0087344359258433
[Epoch 14, Batch 400] loss: 0.009177171407396259
[Epoch 14, Batch 500] loss: 0.012155921732716308
[Epoch 14, Batch 600] loss: 0.004683343750907625
[Epoch 14, Batch 700] loss: 0.006687825640629228
[Epoch 14, Batch 800] loss: 0.017382825288593723
[Epoch 14, Batch 900] loss: 0.010396505896355848
[Epoch 14, Batch 1000] loss: 0.004042476331653689
[Epoch 14, Batch 1100] loss: 0.003680241390321726
[Epoch 14, Batch 1200] loss: 0.0034325778356310366
[Epoch 14, Batch 1300] loss: 0.005563188432382162
[Epoch 14, Batch 1400] loss: 0.005222819303130563
[Epoch 14, Batch 1500] loss: 0.0024903261014071632
[Epoch 14, Batch 1600] loss: 0.004765084100519061
[Epoch 14, Batch 1700] loss: 0.00962681075287719
[Epoch 14, Batch 1800] loss: 0.008782328099159712
[Epoch 14, Batch 1900] loss: 0.00993774297332493
[Epoch 14, Batch 2000] loss: 0.004550969413796793
[Epoch 14, Batch 2100] loss: 0.012311453594722934
[Epoch 14, Batch 2200] loss: 0.012620345535409002
[Epoch 14, Batch 2300] loss: 0.0119543485495916
[Epoch 14, Batch 2400] loss: 0.009778992641274726
[Epoch 14, Batch 2500] loss: 0.016637163475634223
[Epoch 14, Batch 2600] loss: 0.012264412097134709
[Epoch 14, Batch 2700] loss: 0.009231780222858105
[Epoch 14, Batch 2800] loss: 0.011248770439431155
[Epoch 14, Batch 2900] loss: 0.016308543069485495
[Epoch 14, Batch 3000] loss: 0.008444212861891174
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0458
Validation Accuracy: 0.9878
Overfitting: 0.0458
[Epoch 15, Batch 100] loss: 0.006483535453903642
[Epoch 15, Batch 200] loss: 0.006149189448983634
[Epoch 15, Batch 300] loss: 0.004865560623838974
[Epoch 15, Batch 400] loss: 0.009152601618956736
[Epoch 15, Batch 500] loss: 0.008195079506524507
[Epoch 15, Batch 600] loss: 0.007240607180942788
[Epoch 15, Batch 700] loss: 0.0035570600936512165
[Epoch 15, Batch 800] loss: 0.005642026441507824
[Epoch 15, Batch 900] loss: 0.0027149996547302636
[Epoch 15, Batch 1000] loss: 0.004211095413496651
[Epoch 15, Batch 1100] loss: 0.003849373351823715
[Epoch 15, Batch 1200] loss: 0.005438756649361949
[Epoch 15, Batch 1300] loss: 0.004297566787265623
[Epoch 15, Batch 1400] loss: 0.007437219495771217
[Epoch 15, Batch 1500] loss: 0.005125776616332587
[Epoch 15, Batch 1600] loss: 0.007961917083176786
[Epoch 15, Batch 1700] loss: 0.0034158787647180586
[Epoch 15, Batch 1800] loss: 0.007641445838365826
[Epoch 15, Batch 1900] loss: 0.0056754694278367875
[Epoch 15, Batch 2000] loss: 0.008167918168744563
[Epoch 15, Batch 2100] loss: 0.0064479226056528205
[Epoch 15, Batch 2200] loss: 0.004314914906214611
[Epoch 15, Batch 2300] loss: 0.0025522278828802314
[Epoch 15, Batch 2400] loss: 0.005347781424307527
[Epoch 15, Batch 2500] loss: 0.0032549109421518094
[Epoch 15, Batch 2600] loss: 0.006720206743833615
[Epoch 15, Batch 2700] loss: 0.005095202818812368
[Epoch 15, Batch 2800] loss: 0.031137889610677122
[Epoch 15, Batch 2900] loss: 0.012637505890205602
[Epoch 15, Batch 3000] loss: 0.007981263760766523
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9862
Overfitting: 0.0538
[Epoch 16, Batch 100] loss: 0.004400375967736636
[Epoch 16, Batch 200] loss: 0.008821316974640468
[Epoch 16, Batch 300] loss: 0.0038855890107883794
[Epoch 16, Batch 400] loss: 0.009507847133332348
[Epoch 16, Batch 500] loss: 0.0032063769037752364
[Epoch 16, Batch 600] loss: 0.0042671866402751845
[Epoch 16, Batch 700] loss: 0.004508428124447619
[Epoch 16, Batch 800] loss: 0.0019082067479868669
[Epoch 16, Batch 900] loss: 0.004218928324700642
[Epoch 16, Batch 1000] loss: 0.013007586439737224
[Epoch 16, Batch 1100] loss: 0.005001636113261157
[Epoch 16, Batch 1200] loss: 0.001305909227705797
[Epoch 16, Batch 1300] loss: 0.004674677017472959
[Epoch 16, Batch 1400] loss: 0.004285761120546567
[Epoch 16, Batch 1500] loss: 0.003227207424504286
[Epoch 16, Batch 1600] loss: 0.007203820209906553
[Epoch 16, Batch 1700] loss: 0.010121077661248706
[Epoch 16, Batch 1800] loss: 0.0011403077393208605
[Epoch 16, Batch 1900] loss: 0.003120103157700669
[Epoch 16, Batch 2000] loss: 0.002125890308879832
[Epoch 16, Batch 2100] loss: 0.009077014075263606
[Epoch 16, Batch 2200] loss: 0.00652183788879654
[Epoch 16, Batch 2300] loss: 0.007060126520105143
[Epoch 16, Batch 2400] loss: 0.004900217820833746
[Epoch 16, Batch 2500] loss: 0.0034256284795657166
[Epoch 16, Batch 2600] loss: 0.012587823605716721
[Epoch 16, Batch 2700] loss: 0.010187728583948683
[Epoch 16, Batch 2800] loss: 0.005481571667246214
[Epoch 16, Batch 2900] loss: 0.008050874457831014
[Epoch 16, Batch 3000] loss: 0.012786346708963947
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0487
Validation Accuracy: 0.9876
Overfitting: 0.0487
[Epoch 17, Batch 100] loss: 0.015704002985207702
[Epoch 17, Batch 200] loss: 0.007705540619499303
[Epoch 17, Batch 300] loss: 0.004509059387252137
[Epoch 17, Batch 400] loss: 0.0026047326918933324
[Epoch 17, Batch 500] loss: 0.0032022288895620934
[Epoch 17, Batch 600] loss: 0.0023540448393117685
[Epoch 17, Batch 700] loss: 0.002921526763758209
[Epoch 17, Batch 800] loss: 0.0025328033465774526
[Epoch 17, Batch 900] loss: 0.0035140440759698775
[Epoch 17, Batch 1000] loss: 0.004464049007293341
[Epoch 17, Batch 1100] loss: 0.006298568287369335
[Epoch 17, Batch 1200] loss: 0.004027197954835344
[Epoch 17, Batch 1300] loss: 0.007553762525304251
[Epoch 17, Batch 1400] loss: 0.0026948694063611356
[Epoch 17, Batch 1500] loss: 0.014646239900661157
[Epoch 17, Batch 1600] loss: 0.005229325936863347
[Epoch 17, Batch 1700] loss: 0.0062295929322147
[Epoch 17, Batch 1800] loss: 0.005908930282929532
[Epoch 17, Batch 1900] loss: 0.009458218046429465
[Epoch 17, Batch 2000] loss: 0.016130470104831148
[Epoch 17, Batch 2100] loss: 0.00460463174923575
[Epoch 17, Batch 2200] loss: 0.006793885029289797
[Epoch 17, Batch 2300] loss: 0.0034431666876787404
[Epoch 17, Batch 2400] loss: 0.005579035729265911
[Epoch 17, Batch 2500] loss: 0.001961405665856546
[Epoch 17, Batch 2600] loss: 0.004237867275086699
[Epoch 17, Batch 2700] loss: 0.0066763476305291645
[Epoch 17, Batch 2800] loss: 0.010792816597497677
[Epoch 17, Batch 2900] loss: 0.017042324778558396
[Epoch 17, Batch 3000] loss: 0.00917642649038271
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9878
Overfitting: 0.0500
[Epoch 18, Batch 100] loss: 0.003334703997617083
[Epoch 18, Batch 200] loss: 0.0033228467663440142
[Epoch 18, Batch 300] loss: 0.004127172728528876
[Epoch 18, Batch 400] loss: 0.0015126520299997993
[Epoch 18, Batch 500] loss: 0.0035145345659464058
[Epoch 18, Batch 600] loss: 0.0017514423583327244
[Epoch 18, Batch 700] loss: 0.0018649275435154778
[Epoch 18, Batch 800] loss: 0.0030969098312812094
[Epoch 18, Batch 900] loss: 0.00177532623073148
[Epoch 18, Batch 1000] loss: 0.004771893613164764
[Epoch 18, Batch 1100] loss: 0.0033286750263286534
[Epoch 18, Batch 1200] loss: 0.0032176125171980274
[Epoch 18, Batch 1300] loss: 0.0013421902448399338
[Epoch 18, Batch 1400] loss: 0.002992243091613034
[Epoch 18, Batch 1500] loss: 0.0020593724984098926
[Epoch 18, Batch 1600] loss: 0.003295308120655278
[Epoch 18, Batch 1700] loss: 0.0034905977205762894
[Epoch 18, Batch 1800] loss: 0.0024639956945210883
[Epoch 18, Batch 1900] loss: 0.0030930800907773915
[Epoch 18, Batch 2000] loss: 0.002726242297008241
[Epoch 18, Batch 2100] loss: 0.006226377309336897
[Epoch 18, Batch 2200] loss: 0.0022959889637670016
[Epoch 18, Batch 2300] loss: 0.002799986314083611
[Epoch 18, Batch 2400] loss: 0.0017911315117044068
[Epoch 18, Batch 2500] loss: 0.005089820748408442
[Epoch 18, Batch 2600] loss: 0.005485494367173374
[Epoch 18, Batch 2700] loss: 0.006957177193650068
[Epoch 18, Batch 2800] loss: 0.0018782002396176267
[Epoch 18, Batch 2900] loss: 0.00393736977707647
[Epoch 18, Batch 3000] loss: 0.003736097034450836
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9888
Overfitting: 0.0477
[Epoch 19, Batch 100] loss: 0.0016137367138301783
[Epoch 19, Batch 200] loss: 0.0011083829711031256
[Epoch 19, Batch 300] loss: 0.00093745173390829
[Epoch 19, Batch 400] loss: 0.0018271791863159591
[Epoch 19, Batch 500] loss: 0.0063169367469498635
[Epoch 19, Batch 600] loss: 0.0009082765378519753
[Epoch 19, Batch 700] loss: 0.0009028105741312231
[Epoch 19, Batch 800] loss: 0.002265799903810972
[Epoch 19, Batch 900] loss: 0.0014154210353878938
[Epoch 19, Batch 1000] loss: 0.0006310348582930204
[Epoch 19, Batch 1100] loss: 0.0011165624239968964
[Epoch 19, Batch 1200] loss: 0.004748059241745182
[Epoch 19, Batch 1300] loss: 0.0010501632443575737
[Epoch 19, Batch 1400] loss: 0.0009694511761503577
[Epoch 19, Batch 1500] loss: 0.000673168746971129
[Epoch 19, Batch 1600] loss: 0.0006622812502146757
[Epoch 19, Batch 1700] loss: 0.001616123591478953
[Epoch 19, Batch 1800] loss: 0.00448379949839957
[Epoch 19, Batch 1900] loss: 0.007716639551342439
[Epoch 19, Batch 2000] loss: 0.0037254691274691254
[Epoch 19, Batch 2100] loss: 0.0010614444219211804
[Epoch 19, Batch 2200] loss: 0.0020017051247711495
[Epoch 19, Batch 2300] loss: 0.01401687518080479
[Epoch 19, Batch 2400] loss: 0.0022529536347877864
[Epoch 19, Batch 2500] loss: 0.004167373365733909
[Epoch 19, Batch 2600] loss: 0.0031866224495848885
[Epoch 19, Batch 2700] loss: 0.004733891702157109
[Epoch 19, Batch 2800] loss: 0.004394220921259944
[Epoch 19, Batch 2900] loss: 0.0020258456316965124
[Epoch 19, Batch 3000] loss: 0.0012810642321957743
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9883
Overfitting: 0.0483
[Epoch 20, Batch 100] loss: 0.0006728645821814139
[Epoch 20, Batch 200] loss: 0.0024626962745567483
[Epoch 20, Batch 300] loss: 0.0009358179902521613
[Epoch 20, Batch 400] loss: 0.00082124947036192
[Epoch 20, Batch 500] loss: 0.0005413499415584511
[Epoch 20, Batch 600] loss: 0.0021864402098421467
[Epoch 20, Batch 700] loss: 0.0019814553796081214
[Epoch 20, Batch 800] loss: 0.0014136292529230233
[Epoch 20, Batch 900] loss: 0.00730450222906013
[Epoch 20, Batch 1000] loss: 0.0042371976174725035
[Epoch 20, Batch 1100] loss: 0.004188337307817846
[Epoch 20, Batch 1200] loss: 0.004560963741179691
[Epoch 20, Batch 1300] loss: 0.0065761714394508885
[Epoch 20, Batch 1400] loss: 0.0024817138234774915
[Epoch 20, Batch 1500] loss: 0.0014160451802206354
[Epoch 20, Batch 1600] loss: 0.0010947481692343787
[Epoch 20, Batch 1700] loss: 0.001662274102866057
[Epoch 20, Batch 1800] loss: 0.0017128796702637317
[Epoch 20, Batch 1900] loss: 0.0021886927749130082
[Epoch 20, Batch 2000] loss: 0.0012679479569058572
[Epoch 20, Batch 2100] loss: 0.0017612364877862773
[Epoch 20, Batch 2200] loss: 0.0009395321088727826
[Epoch 20, Batch 2300] loss: 0.0014863562529382967
[Epoch 20, Batch 2400] loss: 0.0008189346122858865
[Epoch 20, Batch 2500] loss: 0.0012616212029959595
[Epoch 20, Batch 2600] loss: 0.003104232877900728
[Epoch 20, Batch 2700] loss: 0.0014469389075657268
[Epoch 20, Batch 2800] loss: 0.0025479080220683057
[Epoch 20, Batch 2900] loss: 0.0018982673860107014
[Epoch 20, Batch 3000] loss: 0.0021854926702057752
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9891
Overfitting: 0.0516
[Epoch 21, Batch 100] loss: 0.0034392312575620564
[Epoch 21, Batch 200] loss: 0.0013039306661454474
[Epoch 21, Batch 300] loss: 0.003278404876852932
[Epoch 21, Batch 400] loss: 0.0007559461583736748
[Epoch 21, Batch 500] loss: 0.004744995973179016
[Epoch 21, Batch 600] loss: 0.0016004192106193926
[Epoch 21, Batch 700] loss: 0.0011187467441420651
[Epoch 21, Batch 800] loss: 0.0016956206581497568
[Epoch 21, Batch 900] loss: 0.0036884193701563106
[Epoch 21, Batch 1000] loss: 0.0013337375505001958
[Epoch 21, Batch 1100] loss: 0.0027105692387645775
[Epoch 21, Batch 1200] loss: 0.002919961806079279
[Epoch 21, Batch 1300] loss: 0.00037048865297883537
[Epoch 21, Batch 1400] loss: 0.0011003831827258415
[Epoch 21, Batch 1500] loss: 0.002563676323522319
[Epoch 21, Batch 1600] loss: 0.005492646304814813
[Epoch 21, Batch 1700] loss: 0.002825602420355651
[Epoch 21, Batch 1800] loss: 0.00287378948901555
[Epoch 21, Batch 1900] loss: 0.0008196211645086749
[Epoch 21, Batch 2000] loss: 0.0014369685732917503
[Epoch 21, Batch 2100] loss: 0.000507026781191584
[Epoch 21, Batch 2200] loss: 0.000509010979659621
[Epoch 21, Batch 2300] loss: 0.000656934040422108
[Epoch 21, Batch 2400] loss: 0.00042248333804188574
[Epoch 21, Batch 2500] loss: 0.0006899458139200476
[Epoch 21, Batch 2600] loss: 0.0009255328626227132
[Epoch 21, Batch 2700] loss: 0.0010768312770377264
[Epoch 21, Batch 2800] loss: 0.0006206430203468472
[Epoch 21, Batch 2900] loss: 0.0035926906405408365
[Epoch 21, Batch 3000] loss: 0.0004309292880239113
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9900
Overfitting: 0.0472
[Epoch 22, Batch 100] loss: 0.0006256576113049083
[Epoch 22, Batch 200] loss: 0.0008837660838235096
[Epoch 22, Batch 300] loss: 0.00023191879498261515
[Epoch 22, Batch 400] loss: 0.00027366418466313826
[Epoch 22, Batch 500] loss: 0.00036084322248164824
[Epoch 22, Batch 600] loss: 0.0007337830758294928
[Epoch 22, Batch 700] loss: 0.0008170429373755627
[Epoch 22, Batch 800] loss: 0.0006224263565420429
[Epoch 22, Batch 900] loss: 0.0002172312543776478
[Epoch 22, Batch 1000] loss: 0.0004012080849688715
[Epoch 22, Batch 1100] loss: 0.0013450423005641721
[Epoch 22, Batch 1200] loss: 0.0004955005622581998
[Epoch 22, Batch 1300] loss: 0.0007882393451622205
[Epoch 22, Batch 1400] loss: 0.00035822779543245533
[Epoch 22, Batch 1500] loss: 0.0006075217373521725
[Epoch 22, Batch 1600] loss: 0.00062163328493972
[Epoch 22, Batch 1700] loss: 0.00038493610564930945
[Epoch 22, Batch 1800] loss: 0.0005918775847532975
[Epoch 22, Batch 1900] loss: 0.0007384853717599427
[Epoch 22, Batch 2000] loss: 0.001323434254108684
[Epoch 22, Batch 2100] loss: 0.0013638843042968762
[Epoch 22, Batch 2200] loss: 0.0035426862839200626
[Epoch 22, Batch 2300] loss: 0.01281064453336639
[Epoch 22, Batch 2400] loss: 0.0028968213725168823
[Epoch 22, Batch 2500] loss: 0.0004596768312996602
[Epoch 22, Batch 2600] loss: 0.0007127038000391029
[Epoch 22, Batch 2700] loss: 0.0006364137503339551
[Epoch 22, Batch 2800] loss: 0.0008850912581301528
[Epoch 22, Batch 2900] loss: 0.0017749351857543516
[Epoch 22, Batch 3000] loss: 0.00158180122212098
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9892
Overfitting: 0.0513
[Epoch 23, Batch 100] loss: 0.0023882121995472748
[Epoch 23, Batch 200] loss: 0.0004542298403546097
[Epoch 23, Batch 300] loss: 0.0010967758948764407
[Epoch 23, Batch 400] loss: 0.003907542444903305
[Epoch 23, Batch 500] loss: 0.0014335041552762818
[Epoch 23, Batch 600] loss: 0.0008740619280435525
[Epoch 23, Batch 700] loss: 0.0005916765013342439
[Epoch 23, Batch 800] loss: 0.001183469524491083
[Epoch 23, Batch 900] loss: 0.00047231359446938905
[Epoch 23, Batch 1000] loss: 0.00036138194145532323
[Epoch 23, Batch 1100] loss: 0.0016215695627281646
[Epoch 23, Batch 1200] loss: 0.0007720855514325642
[Epoch 23, Batch 1300] loss: 0.00029770864213965356
[Epoch 23, Batch 1400] loss: 0.0006735723990944109
[Epoch 23, Batch 1500] loss: 0.0003402775369533062
[Epoch 23, Batch 1600] loss: 0.0003181405129372683
[Epoch 23, Batch 1700] loss: 0.0009133926075786158
[Epoch 23, Batch 1800] loss: 0.00034981485167318027
[Epoch 23, Batch 1900] loss: 0.0004314670243634389
[Epoch 23, Batch 2000] loss: 0.0004087074490948783
[Epoch 23, Batch 2100] loss: 0.0005932517908391998
[Epoch 23, Batch 2200] loss: 0.0007482587409359587
[Epoch 23, Batch 2300] loss: 0.0005212422826126994
[Epoch 23, Batch 2400] loss: 0.0033638535007554315
[Epoch 23, Batch 2500] loss: 0.002066557495050887
[Epoch 23, Batch 2600] loss: 0.000983152067331332
[Epoch 23, Batch 2700] loss: 0.0019805283565716716
[Epoch 23, Batch 2800] loss: 0.0016022433783485957
[Epoch 23, Batch 2900] loss: 0.0006786984586960543
[Epoch 23, Batch 3000] loss: 0.00016018940391299808
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0495
Validation Accuracy: 0.9903
Overfitting: 0.0495
[Epoch 24, Batch 100] loss: 0.0023298270757016893
[Epoch 24, Batch 200] loss: 0.00048102150628187345
[Epoch 24, Batch 300] loss: 0.000453682888502378
[Epoch 24, Batch 400] loss: 0.000707895475229705
[Epoch 24, Batch 500] loss: 0.00034717245680875307
[Epoch 24, Batch 600] loss: 0.004013950760076721
[Epoch 24, Batch 700] loss: 0.0005705524672103479
[Epoch 24, Batch 800] loss: 0.00038301743723242245
[Epoch 24, Batch 900] loss: 0.0003609583535311334
[Epoch 24, Batch 1000] loss: 0.0004137335937620534
[Epoch 24, Batch 1100] loss: 0.0018368164434208677
[Epoch 24, Batch 1200] loss: 0.0004967317711541774
[Epoch 24, Batch 1300] loss: 0.00036771828224510636
[Epoch 24, Batch 1400] loss: 0.00033546766082963585
[Epoch 24, Batch 1500] loss: 0.00036448685422473925
[Epoch 24, Batch 1600] loss: 0.0016302847865686853
[Epoch 24, Batch 1700] loss: 0.003770005520570359
[Epoch 24, Batch 1800] loss: 0.0004980788415864267
[Epoch 24, Batch 1900] loss: 0.00020236266477503763
[Epoch 24, Batch 2000] loss: 0.001272472848301902
[Epoch 24, Batch 2100] loss: 0.0009729303806901113
[Epoch 24, Batch 2200] loss: 0.00017733084979056456
[Epoch 24, Batch 2300] loss: 0.0013116176922402367
[Epoch 24, Batch 2400] loss: 0.0008349962598529226
[Epoch 24, Batch 2500] loss: 0.00048747851510517304
[Epoch 24, Batch 2600] loss: 0.0003345923205437451
[Epoch 24, Batch 2700] loss: 0.00023584840179358135
[Epoch 24, Batch 2800] loss: 0.00048770195789184624
[Epoch 24, Batch 2900] loss: 0.00024333120997562573
[Epoch 24, Batch 3000] loss: 0.0003574463380150528
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9898
Overfitting: 0.0504
Fold 5 validation loss: 0.0504
Mean validation loss across all folds for Trial 14 is 0.0536 with trial config:  l1: 256, l2: 128, lr: 0.0014098383604086698, batch_size: 16
[I 2024-12-10 08:38:17,484] Trial 13 finished with value: 0.05363505446462432 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0014098383604086698, 'batch_size': 16}. Best is trial 4 with value: 0.045411968038914834.

Selected Hyperparameters for Trial 15:
  l1: 128, l2: 128, lr: 0.000930924895950669, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.292709195613861
[Epoch 1, Batch 200] loss: 2.261015446186066
[Epoch 1, Batch 300] loss: 2.1401302123069765
[Epoch 1, Batch 400] loss: 1.4192568159103394
[Epoch 1, Batch 500] loss: 0.6557554793357849
[Epoch 1, Batch 600] loss: 0.5081080371141433
[Epoch 1, Batch 700] loss: 0.419086646437645
**STATS for Epoch 1** : 
Average training loss: 0.0258
Average validation loss: 0.3615
Validation Accuracy: 0.8903
Overfitting: 0.3358
Best model saved at epoch 1 with validation loss: 0.3615
[Epoch 2, Batch 100] loss: 0.33010983318090437
[Epoch 2, Batch 200] loss: 0.3264778181910515
[Epoch 2, Batch 300] loss: 0.29995906189084054
[Epoch 2, Batch 400] loss: 0.2571294721215963
[Epoch 2, Batch 500] loss: 0.23974643640220164
[Epoch 2, Batch 600] loss: 0.23300088331103325
[Epoch 2, Batch 700] loss: 0.2192150118947029
**STATS for Epoch 2** : 
Average training loss: 0.0163
Average validation loss: 0.1824
Validation Accuracy: 0.9472
Overfitting: 0.1661
Best model saved at epoch 2 with validation loss: 0.1824
[Epoch 3, Batch 100] loss: 0.18928532272577286
[Epoch 3, Batch 200] loss: 0.17841235194355248
[Epoch 3, Batch 300] loss: 0.18639499764889478
[Epoch 3, Batch 400] loss: 0.18134085029363634
[Epoch 3, Batch 500] loss: 0.16611378006637095
[Epoch 3, Batch 600] loss: 0.14634778786450625
[Epoch 3, Batch 700] loss: 0.15525073297321795
**STATS for Epoch 3** : 
Average training loss: 0.0105
Average validation loss: 0.1349
Validation Accuracy: 0.9607
Overfitting: 0.1243
Best model saved at epoch 3 with validation loss: 0.1349
[Epoch 4, Batch 100] loss: 0.14305329501628875
[Epoch 4, Batch 200] loss: 0.13840644232928753
[Epoch 4, Batch 300] loss: 0.1203810048662126
[Epoch 4, Batch 400] loss: 0.12703618232160807
[Epoch 4, Batch 500] loss: 0.12462375743314624
[Epoch 4, Batch 600] loss: 0.1290499215759337
[Epoch 4, Batch 700] loss: 0.1305046215094626
**STATS for Epoch 4** : 
Average training loss: 0.0072
Average validation loss: 0.1026
Validation Accuracy: 0.9693
Overfitting: 0.0953
Best model saved at epoch 4 with validation loss: 0.1026
[Epoch 5, Batch 100] loss: 0.11992273155599832
[Epoch 5, Batch 200] loss: 0.11049984546378255
[Epoch 5, Batch 300] loss: 0.11501562542282046
[Epoch 5, Batch 400] loss: 0.10511335637420416
[Epoch 5, Batch 500] loss: 0.10178362304344774
[Epoch 5, Batch 600] loss: 0.09835005160421133
[Epoch 5, Batch 700] loss: 0.10175929790362716
**STATS for Epoch 5** : 
Average training loss: 0.0062
Average validation loss: 0.0874
Validation Accuracy: 0.9718
Overfitting: 0.0812
Best model saved at epoch 5 with validation loss: 0.0874
[Epoch 6, Batch 100] loss: 0.08953224982134998
[Epoch 6, Batch 200] loss: 0.10638108835555612
[Epoch 6, Batch 300] loss: 0.08484242699109018
[Epoch 6, Batch 400] loss: 0.09774480449035763
[Epoch 6, Batch 500] loss: 0.08757345867343247
[Epoch 6, Batch 600] loss: 0.08230824505910278
[Epoch 6, Batch 700] loss: 0.09683006686158478
**STATS for Epoch 6** : 
Average training loss: 0.0063
Average validation loss: 0.0807
Validation Accuracy: 0.9747
Overfitting: 0.0743
Best model saved at epoch 6 with validation loss: 0.0807
[Epoch 7, Batch 100] loss: 0.08700255824252963
[Epoch 7, Batch 200] loss: 0.07982003192417324
[Epoch 7, Batch 300] loss: 0.08399023430421948
[Epoch 7, Batch 400] loss: 0.07325220093596727
[Epoch 7, Batch 500] loss: 0.08760495315305888
[Epoch 7, Batch 600] loss: 0.08594975403975695
[Epoch 7, Batch 700] loss: 0.07545528259128333
**STATS for Epoch 7** : 
Average training loss: 0.0044
Average validation loss: 0.0726
Validation Accuracy: 0.9762
Overfitting: 0.0682
Best model saved at epoch 7 with validation loss: 0.0726
[Epoch 8, Batch 100] loss: 0.07102366791106761
[Epoch 8, Batch 200] loss: 0.0873521231347695
[Epoch 8, Batch 300] loss: 0.06833261953666807
[Epoch 8, Batch 400] loss: 0.06916342166252434
[Epoch 8, Batch 500] loss: 0.07844005501829088
[Epoch 8, Batch 600] loss: 0.0670938318548724
[Epoch 8, Batch 700] loss: 0.07129949730820954
**STATS for Epoch 8** : 
Average training loss: 0.0045
Average validation loss: 0.0705
Validation Accuracy: 0.9792
Overfitting: 0.0661
Best model saved at epoch 8 with validation loss: 0.0705
[Epoch 9, Batch 100] loss: 0.06649972799699753
[Epoch 9, Batch 200] loss: 0.07217359305359423
[Epoch 9, Batch 300] loss: 0.07528921954333782
[Epoch 9, Batch 400] loss: 0.07323552561923861
[Epoch 9, Batch 500] loss: 0.0602988999709487
[Epoch 9, Batch 600] loss: 0.05761328052496537
[Epoch 9, Batch 700] loss: 0.06271895818412304
**STATS for Epoch 9** : 
Average training loss: 0.0039
Average validation loss: 0.0685
Validation Accuracy: 0.9788
Overfitting: 0.0645
[I 2024-12-10 08:39:49,361] Trial 14 pruned. 

Selected Hyperparameters for Trial 16:
  l1: 256, l2: 64, lr: 0.0003345432049076793, batch_size: 16
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3033363938331606
[Epoch 1, Batch 200] loss: 2.2940722632408144
[Epoch 1, Batch 300] loss: 2.2752336263656616
[Epoch 1, Batch 400] loss: 2.2482955169677736
[Epoch 1, Batch 500] loss: 2.212580826282501
[Epoch 1, Batch 600] loss: 2.135184073448181
[Epoch 1, Batch 700] loss: 1.9469057404994965
[Epoch 1, Batch 800] loss: 1.6216917419433594
[Epoch 1, Batch 900] loss: 1.1616401821374893
[Epoch 1, Batch 1000] loss: 0.8802124091982841
[Epoch 1, Batch 1100] loss: 0.7317846673727035
[Epoch 1, Batch 1200] loss: 0.6150183486938476
[Epoch 1, Batch 1300] loss: 0.5212145812809468
[Epoch 1, Batch 1400] loss: 0.5027709385007619
[Epoch 1, Batch 1500] loss: 0.4845556502789259
[Epoch 1, Batch 1600] loss: 0.4780953074991703
[Epoch 1, Batch 1700] loss: 0.4587218088656664
[Epoch 1, Batch 1800] loss: 0.41377141572535037
[Epoch 1, Batch 1900] loss: 0.3765081862360239
[Epoch 1, Batch 2000] loss: 0.34425009295344355
[Epoch 1, Batch 2100] loss: 0.3708710915595293
[Epoch 1, Batch 2200] loss: 0.33014098152518273
[Epoch 1, Batch 2300] loss: 0.3325249067693949
[Epoch 1, Batch 2400] loss: 0.3421855450049043
[Epoch 1, Batch 2500] loss: 0.30857301883399485
[Epoch 1, Batch 2600] loss: 0.2919395438581705
[Epoch 1, Batch 2700] loss: 0.3095018389634788
[Epoch 1, Batch 2800] loss: 0.2981991911306977
[Epoch 1, Batch 2900] loss: 0.295156688131392
[Epoch 1, Batch 3000] loss: 0.29131319031119346
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2430
Validation Accuracy: 0.9285
Overfitting: 0.2430
Best model saved at epoch 1 with validation loss: 0.2430
[Epoch 2, Batch 100] loss: 0.24577320033684372
[Epoch 2, Batch 200] loss: 0.2695791322737932
[Epoch 2, Batch 300] loss: 0.27742585150524973
[Epoch 2, Batch 400] loss: 0.245941520370543
[Epoch 2, Batch 500] loss: 0.23845181580632924
[Epoch 2, Batch 600] loss: 0.2354824417643249
[Epoch 2, Batch 700] loss: 0.249190142583102
[Epoch 2, Batch 800] loss: 0.22348262149840592
[Epoch 2, Batch 900] loss: 0.1969223041459918
[Epoch 2, Batch 1000] loss: 0.24412370104342698
[Epoch 2, Batch 1100] loss: 0.2226283890195191
[Epoch 2, Batch 1200] loss: 0.24458193024620414
[Epoch 2, Batch 1300] loss: 0.2152888224646449
[Epoch 2, Batch 1400] loss: 0.20068801905959843
[Epoch 2, Batch 1500] loss: 0.19698181178420782
[Epoch 2, Batch 1600] loss: 0.16507167741656303
[Epoch 2, Batch 1700] loss: 0.17598493026569487
[Epoch 2, Batch 1800] loss: 0.18843741224147378
[Epoch 2, Batch 1900] loss: 0.1714077903702855
[Epoch 2, Batch 2000] loss: 0.20107057021930813
[Epoch 2, Batch 2100] loss: 0.15895797101315112
[Epoch 2, Batch 2200] loss: 0.1691732065193355
[Epoch 2, Batch 2300] loss: 0.1914489914942533
[Epoch 2, Batch 2400] loss: 0.14906729484908282
[Epoch 2, Batch 2500] loss: 0.16183561292942614
[Epoch 2, Batch 2600] loss: 0.15377128456253558
[Epoch 2, Batch 2700] loss: 0.15224320974200964
[Epoch 2, Batch 2800] loss: 0.14073369227349758
[Epoch 2, Batch 2900] loss: 0.16886967653408647
[Epoch 2, Batch 3000] loss: 0.14245949288830162
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1612
Validation Accuracy: 0.9500
Overfitting: 0.1612
Best model saved at epoch 2 with validation loss: 0.1612
[Epoch 3, Batch 100] loss: 0.1342915952578187
[Epoch 3, Batch 200] loss: 0.17387103440705687
[Epoch 3, Batch 300] loss: 0.15357253194786608
[Epoch 3, Batch 400] loss: 0.14888394551351666
[Epoch 3, Batch 500] loss: 0.1364137557381764
[Epoch 3, Batch 600] loss: 0.1634888022323139
[Epoch 3, Batch 700] loss: 0.09846066902857274
[Epoch 3, Batch 800] loss: 0.13684799439739437
[Epoch 3, Batch 900] loss: 0.1513456580741331
[Epoch 3, Batch 1000] loss: 0.13705584122799336
[Epoch 3, Batch 1100] loss: 0.17923206647858023
[Epoch 3, Batch 1200] loss: 0.12922120976261794
[Epoch 3, Batch 1300] loss: 0.11055638992227614
[Epoch 3, Batch 1400] loss: 0.12291174963116645
[Epoch 3, Batch 1500] loss: 0.1279227056656964
[Epoch 3, Batch 1600] loss: 0.13874236192554235
[Epoch 3, Batch 1700] loss: 0.136675231680274
[Epoch 3, Batch 1800] loss: 0.12964126797858624
[Epoch 3, Batch 1900] loss: 0.10956625904189422
[Epoch 3, Batch 2000] loss: 0.10133607551688328
[Epoch 3, Batch 2100] loss: 0.10627368245273829
[Epoch 3, Batch 2200] loss: 0.10259833295363933
[Epoch 3, Batch 2300] loss: 0.10983794442377985
[Epoch 3, Batch 2400] loss: 0.11674907847307622
[Epoch 3, Batch 2500] loss: 0.10602288658730685
[Epoch 3, Batch 2600] loss: 0.11150578506290913
[Epoch 3, Batch 2700] loss: 0.10676586786285043
[Epoch 3, Batch 2800] loss: 0.1019330185058061
[Epoch 3, Batch 2900] loss: 0.11300260270945728
[Epoch 3, Batch 3000] loss: 0.12034379305317998
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1036
Validation Accuracy: 0.9671
Overfitting: 0.1036
Best model saved at epoch 3 with validation loss: 0.1036
[Epoch 4, Batch 100] loss: 0.09924431972787716
[Epoch 4, Batch 200] loss: 0.09664542589336633
[Epoch 4, Batch 300] loss: 0.09945734125794843
[Epoch 4, Batch 400] loss: 0.09979198308195919
[Epoch 4, Batch 500] loss: 0.11596751142293214
[Epoch 4, Batch 600] loss: 0.1085208359034732
[Epoch 4, Batch 700] loss: 0.0830229287641123
[Epoch 4, Batch 800] loss: 0.10548395214602352
[Epoch 4, Batch 900] loss: 0.11314662330783903
[Epoch 4, Batch 1000] loss: 0.08933925350662321
[Epoch 4, Batch 1100] loss: 0.09117894117254764
[Epoch 4, Batch 1200] loss: 0.0932493209443055
[Epoch 4, Batch 1300] loss: 0.09141336847562342
[Epoch 4, Batch 1400] loss: 0.10480129746487364
[Epoch 4, Batch 1500] loss: 0.09087377005955205
[Epoch 4, Batch 1600] loss: 0.10570464578224346
[Epoch 4, Batch 1700] loss: 0.11280387120554224
[Epoch 4, Batch 1800] loss: 0.10126120598521084
[Epoch 4, Batch 1900] loss: 0.09999551501823589
[Epoch 4, Batch 2000] loss: 0.12725044898106716
[Epoch 4, Batch 2100] loss: 0.10772358612390236
[Epoch 4, Batch 2200] loss: 0.08203563251765444
[Epoch 4, Batch 2300] loss: 0.1158049136120826
[Epoch 4, Batch 2400] loss: 0.08007289046188816
[Epoch 4, Batch 2500] loss: 0.08932850908488035
[Epoch 4, Batch 2600] loss: 0.10307670522481203
[Epoch 4, Batch 2700] loss: 0.08710444735130295
[Epoch 4, Batch 2800] loss: 0.10103621527319774
[Epoch 4, Batch 2900] loss: 0.07641013516578823
[Epoch 4, Batch 3000] loss: 0.09483341382583603
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0868
Validation Accuracy: 0.9720
Overfitting: 0.0868
Best model saved at epoch 4 with validation loss: 0.0868
[Epoch 5, Batch 100] loss: 0.0806220811093226
[Epoch 5, Batch 200] loss: 0.08404429517220706
[Epoch 5, Batch 300] loss: 0.04941873183124699
[Epoch 5, Batch 400] loss: 0.09025624968810007
[Epoch 5, Batch 500] loss: 0.09440898577915505
[Epoch 5, Batch 600] loss: 0.10400901042157784
[Epoch 5, Batch 700] loss: 0.08155755439540371
[Epoch 5, Batch 800] loss: 0.08507575638825074
[Epoch 5, Batch 900] loss: 0.07002974710077979
[Epoch 5, Batch 1000] loss: 0.08838197638397105
[Epoch 5, Batch 1100] loss: 0.06899157551350071
[Epoch 5, Batch 1200] loss: 0.0977666360605508
[Epoch 5, Batch 1300] loss: 0.0790268543845741
[Epoch 5, Batch 1400] loss: 0.07158259206218645
[Epoch 5, Batch 1500] loss: 0.09513398732524365
[Epoch 5, Batch 1600] loss: 0.08419017693144269
[Epoch 5, Batch 1700] loss: 0.0760046888818033
[Epoch 5, Batch 1800] loss: 0.0740233695320785
[Epoch 5, Batch 1900] loss: 0.08751693081110716
[Epoch 5, Batch 2000] loss: 0.08384826945373788
[Epoch 5, Batch 2100] loss: 0.08975962103111669
[Epoch 5, Batch 2200] loss: 0.08315199288306757
[Epoch 5, Batch 2300] loss: 0.08145093529485166
[Epoch 5, Batch 2400] loss: 0.07943500296212733
[Epoch 5, Batch 2500] loss: 0.06697977971518412
[Epoch 5, Batch 2600] loss: 0.07753161145024932
[Epoch 5, Batch 2700] loss: 0.12177189394598827
[Epoch 5, Batch 2800] loss: 0.07083687036647461
[Epoch 5, Batch 2900] loss: 0.07004218895919621
[Epoch 5, Batch 3000] loss: 0.06668443678296171
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0730
Validation Accuracy: 0.9772
Overfitting: 0.0730
Best model saved at epoch 5 with validation loss: 0.0730
[Epoch 6, Batch 100] loss: 0.09602425296325237
[Epoch 6, Batch 200] loss: 0.04926898922305554
[Epoch 6, Batch 300] loss: 0.05751377942040563
[Epoch 6, Batch 400] loss: 0.0633194635109976
[Epoch 6, Batch 500] loss: 0.06316140562877991
[Epoch 6, Batch 600] loss: 0.05934019836073276
[Epoch 6, Batch 700] loss: 0.07040039524494204
[Epoch 6, Batch 800] loss: 0.07057506354176439
[Epoch 6, Batch 900] loss: 0.0734524198906729
[Epoch 6, Batch 1000] loss: 0.06602440213784576
[Epoch 6, Batch 1100] loss: 0.07522849058383145
[Epoch 6, Batch 1200] loss: 0.08053181461524218
[Epoch 6, Batch 1300] loss: 0.0781471870932728
[Epoch 6, Batch 1400] loss: 0.06110130340559408
[Epoch 6, Batch 1500] loss: 0.09083624038961716
[Epoch 6, Batch 1600] loss: 0.07806850163964554
[Epoch 6, Batch 1700] loss: 0.055022780222352595
[Epoch 6, Batch 1800] loss: 0.06496712464315352
[Epoch 6, Batch 1900] loss: 0.06633407558430918
[Epoch 6, Batch 2000] loss: 0.06653708250669296
[Epoch 6, Batch 2100] loss: 0.10030826845555567
[Epoch 6, Batch 2200] loss: 0.051543078907416204
[Epoch 6, Batch 2300] loss: 0.05961108517250977
[Epoch 6, Batch 2400] loss: 0.08422898989287204
[Epoch 6, Batch 2500] loss: 0.0709592157183215
[Epoch 6, Batch 2600] loss: 0.07287705024238676
[Epoch 6, Batch 2700] loss: 0.07315120330196806
[Epoch 6, Batch 2800] loss: 0.06397427995572798
[Epoch 6, Batch 2900] loss: 0.061455870305653665
[Epoch 6, Batch 3000] loss: 0.08246043946244754
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0687
Validation Accuracy: 0.9764
Overfitting: 0.0687
Best model saved at epoch 6 with validation loss: 0.0687
[Epoch 7, Batch 100] loss: 0.06926286445872393
[Epoch 7, Batch 200] loss: 0.0671425253455527
[Epoch 7, Batch 300] loss: 0.05528214871592354
[Epoch 7, Batch 400] loss: 0.06321894050692208
[Epoch 7, Batch 500] loss: 0.05082826856349129
[Epoch 7, Batch 600] loss: 0.06363340385840274
[Epoch 7, Batch 700] loss: 0.05222931872238405
[Epoch 7, Batch 800] loss: 0.06240362287207972
[Epoch 7, Batch 900] loss: 0.06970438754302449
[Epoch 7, Batch 1000] loss: 0.06615806015674025
[Epoch 7, Batch 1100] loss: 0.06913456150447019
[Epoch 7, Batch 1200] loss: 0.05778356588445604
[Epoch 7, Batch 1300] loss: 0.051616589217446746
[Epoch 7, Batch 1400] loss: 0.06582611637131777
[Epoch 7, Batch 1500] loss: 0.08900288174743765
[Epoch 7, Batch 1600] loss: 0.06349046740797348
[Epoch 7, Batch 1700] loss: 0.05168595384340733
[Epoch 7, Batch 1800] loss: 0.06393150673946366
[Epoch 7, Batch 1900] loss: 0.08185091850697063
[Epoch 7, Batch 2000] loss: 0.05538642104249448
[Epoch 7, Batch 2100] loss: 0.06418610208260361
[Epoch 7, Batch 2200] loss: 0.06605195131036452
[Epoch 7, Batch 2300] loss: 0.06743826614343561
[Epoch 7, Batch 2400] loss: 0.06340365695650689
[Epoch 7, Batch 2500] loss: 0.057787872013577726
[Epoch 7, Batch 2600] loss: 0.06174747874669265
[Epoch 7, Batch 2700] loss: 0.052028021723381244
[Epoch 7, Batch 2800] loss: 0.05701866011018865
[Epoch 7, Batch 2900] loss: 0.05866593769402243
[Epoch 7, Batch 3000] loss: 0.050892380182631314
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0609
Validation Accuracy: 0.9805
Overfitting: 0.0609
Best model saved at epoch 7 with validation loss: 0.0609
[Epoch 8, Batch 100] loss: 0.05350109886727296
[Epoch 8, Batch 200] loss: 0.058698798315599564
[Epoch 8, Batch 300] loss: 0.04331911580287851
[Epoch 8, Batch 400] loss: 0.05096432634716621
[Epoch 8, Batch 500] loss: 0.06771205094177275
[Epoch 8, Batch 600] loss: 0.05761244433990214
[Epoch 8, Batch 700] loss: 0.0652222322957823
[Epoch 8, Batch 800] loss: 0.04015409214043757
[Epoch 8, Batch 900] loss: 0.05429499922320247
[Epoch 8, Batch 1000] loss: 0.05229089151369408
[Epoch 8, Batch 1100] loss: 0.05260019476059824
[Epoch 8, Batch 1200] loss: 0.05476884037838317
[Epoch 8, Batch 1300] loss: 0.047251486897002905
[Epoch 8, Batch 1400] loss: 0.05420802698703483
[Epoch 8, Batch 1500] loss: 0.06837333673232933
[Epoch 8, Batch 1600] loss: 0.05516000103729311
[Epoch 8, Batch 1700] loss: 0.0433867153772735
[Epoch 8, Batch 1800] loss: 0.06485626395297003
[Epoch 8, Batch 1900] loss: 0.062020977214560846
[Epoch 8, Batch 2000] loss: 0.053152475856477394
[Epoch 8, Batch 2100] loss: 0.04441595580719877
[Epoch 8, Batch 2200] loss: 0.07279292142018676
[Epoch 8, Batch 2300] loss: 0.05928441712574568
[Epoch 8, Batch 2400] loss: 0.052784956001269166
[Epoch 8, Batch 2500] loss: 0.07114540145965292
[Epoch 8, Batch 2600] loss: 0.06440458557743113
[Epoch 8, Batch 2700] loss: 0.04830695737095084
[Epoch 8, Batch 2800] loss: 0.0543611237895675
[Epoch 8, Batch 2900] loss: 0.03720432258327491
[Epoch 8, Batch 3000] loss: 0.04913340122322552
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0583
Validation Accuracy: 0.9812
Overfitting: 0.0583
Best model saved at epoch 8 with validation loss: 0.0583
[Epoch 9, Batch 100] loss: 0.06278442382783396
[Epoch 9, Batch 200] loss: 0.045414681435067904
[Epoch 9, Batch 300] loss: 0.03746394301153486
[Epoch 9, Batch 400] loss: 0.04490022729733027
[Epoch 9, Batch 500] loss: 0.043534141201525926
[Epoch 9, Batch 600] loss: 0.04058213052747305
[Epoch 9, Batch 700] loss: 0.04098273109237198
[Epoch 9, Batch 800] loss: 0.0406272906891536
[Epoch 9, Batch 900] loss: 0.04542562974384055
[Epoch 9, Batch 1000] loss: 0.05236746668815613
[Epoch 9, Batch 1100] loss: 0.05276004674611613
[Epoch 9, Batch 1200] loss: 0.04813724738953169
[Epoch 9, Batch 1300] loss: 0.03598826179862954
[Epoch 9, Batch 1400] loss: 0.04696348879951984
[Epoch 9, Batch 1500] loss: 0.05093394855008228
[Epoch 9, Batch 1600] loss: 0.04563995867880294
[Epoch 9, Batch 1700] loss: 0.048381396789336575
[Epoch 9, Batch 1800] loss: 0.062022961603070144
[Epoch 9, Batch 1900] loss: 0.050515128672122954
[Epoch 9, Batch 2000] loss: 0.04308745221002028
[Epoch 9, Batch 2100] loss: 0.038508816972607746
[Epoch 9, Batch 2200] loss: 0.05568156838096911
[Epoch 9, Batch 2300] loss: 0.05237450012238696
[Epoch 9, Batch 2400] loss: 0.05297755360254087
[Epoch 9, Batch 2500] loss: 0.05824902068939991
[Epoch 9, Batch 2600] loss: 0.05730378000647761
[Epoch 9, Batch 2700] loss: 0.054364387868263295
[Epoch 9, Batch 2800] loss: 0.049111173061537554
[Epoch 9, Batch 2900] loss: 0.0665839864773443
[Epoch 9, Batch 3000] loss: 0.053716586490627376
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9829
Overfitting: 0.0540
[I 2024-12-10 08:42:03,671] Trial 15 pruned. 

Selected Hyperparameters for Trial 17:
  l1: 256, l2: 64, lr: 0.003317662028701678, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2371756267547607
[Epoch 1, Batch 200] loss: 0.8947622027993202
[Epoch 1, Batch 300] loss: 0.32183195784687996
**STATS for Epoch 1** : 
Average training loss: 0.0476
Average validation loss: 0.1843
Validation Accuracy: 0.9464
Overfitting: 0.1367
Best model saved at epoch 1 with validation loss: 0.1843
[Epoch 2, Batch 100] loss: 0.19312038153409958
[Epoch 2, Batch 200] loss: 0.16616211265325545
[Epoch 2, Batch 300] loss: 0.14806306093931199
**STATS for Epoch 2** : 
Average training loss: 0.0274
Average validation loss: 0.1077
Validation Accuracy: 0.9677
Overfitting: 0.0802
Best model saved at epoch 2 with validation loss: 0.1077
[Epoch 3, Batch 100] loss: 0.11333499703556299
[Epoch 3, Batch 200] loss: 0.10549271684139967
[Epoch 3, Batch 300] loss: 0.10030102835968137
**STATS for Epoch 3** : 
Average training loss: 0.0209
Average validation loss: 0.0821
Validation Accuracy: 0.9743
Overfitting: 0.0612
Best model saved at epoch 3 with validation loss: 0.0821
[Epoch 4, Batch 100] loss: 0.08210800293833018
[Epoch 4, Batch 200] loss: 0.0876493177935481
[Epoch 4, Batch 300] loss: 0.08456269511952996
**STATS for Epoch 4** : 
Average training loss: 0.0145
Average validation loss: 0.0709
Validation Accuracy: 0.9786
Overfitting: 0.0564
Best model saved at epoch 4 with validation loss: 0.0709
[Epoch 5, Batch 100] loss: 0.07583853457123041
[Epoch 5, Batch 200] loss: 0.06675696740858257
[Epoch 5, Batch 300] loss: 0.07014217839576303
**STATS for Epoch 5** : 
Average training loss: 0.0125
Average validation loss: 0.0637
Validation Accuracy: 0.9794
Overfitting: 0.0512
Best model saved at epoch 5 with validation loss: 0.0637
[Epoch 6, Batch 100] loss: 0.055701040122658016
[Epoch 6, Batch 200] loss: 0.05936283683404327
[Epoch 6, Batch 300] loss: 0.060664301915094254
**STATS for Epoch 6** : 
Average training loss: 0.0116
Average validation loss: 0.0583
Validation Accuracy: 0.9815
Overfitting: 0.0467
Best model saved at epoch 6 with validation loss: 0.0583
[Epoch 7, Batch 100] loss: 0.052915172753855585
[Epoch 7, Batch 200] loss: 0.04999545526690781
[Epoch 7, Batch 300] loss: 0.055316255670040844
**STATS for Epoch 7** : 
Average training loss: 0.0091
Average validation loss: 0.0528
Validation Accuracy: 0.9831
Overfitting: 0.0437
Best model saved at epoch 7 with validation loss: 0.0528
[Epoch 8, Batch 100] loss: 0.0442851583333686
[Epoch 8, Batch 200] loss: 0.050246278583072124
[Epoch 8, Batch 300] loss: 0.04555146883241832
**STATS for Epoch 8** : 
Average training loss: 0.0096
Average validation loss: 0.0591
Validation Accuracy: 0.9812
Overfitting: 0.0494
[Epoch 9, Batch 100] loss: 0.03802990920376033
[Epoch 9, Batch 200] loss: 0.04127217753324658
[Epoch 9, Batch 300] loss: 0.04683588410494849
**STATS for Epoch 9** : 
Average training loss: 0.0084
Average validation loss: 0.0466
Validation Accuracy: 0.9857
Overfitting: 0.0382
Best model saved at epoch 9 with validation loss: 0.0466
[Epoch 10, Batch 100] loss: 0.03763234348036349
[Epoch 10, Batch 200] loss: 0.038750016577541825
[Epoch 10, Batch 300] loss: 0.03574056371115148
**STATS for Epoch 10** : 
Average training loss: 0.0075
Average validation loss: 0.0478
Validation Accuracy: 0.9841
Overfitting: 0.0403
[Epoch 11, Batch 100] loss: 0.03495188939967193
[Epoch 11, Batch 200] loss: 0.03665500196628273
[Epoch 11, Batch 300] loss: 0.034602431657258424
**STATS for Epoch 11** : 
Average training loss: 0.0059
Average validation loss: 0.0473
Validation Accuracy: 0.9852
Overfitting: 0.0414
[Epoch 12, Batch 100] loss: 0.03308376610279083
[Epoch 12, Batch 200] loss: 0.02899591392138973
[Epoch 12, Batch 300] loss: 0.03245692216791213
**STATS for Epoch 12** : 
Average training loss: 0.0062
Average validation loss: 0.0414
Validation Accuracy: 0.9862
Overfitting: 0.0352
Best model saved at epoch 12 with validation loss: 0.0414
[Epoch 13, Batch 100] loss: 0.027335040997713805
[Epoch 13, Batch 200] loss: 0.031619245810434224
[Epoch 13, Batch 300] loss: 0.02986197974300012
**STATS for Epoch 13** : 
Average training loss: 0.0052
Average validation loss: 0.0434
Validation Accuracy: 0.9859
Overfitting: 0.0382
[Epoch 14, Batch 100] loss: 0.024743892763508482
[Epoch 14, Batch 200] loss: 0.026427982348250226
[Epoch 14, Batch 300] loss: 0.029043706834781916
**STATS for Epoch 14** : 
Average training loss: 0.0048
Average validation loss: 0.0412
Validation Accuracy: 0.9865
Overfitting: 0.0364
Best model saved at epoch 14 with validation loss: 0.0412
[Epoch 15, Batch 100] loss: 0.019843304546084253
[Epoch 15, Batch 200] loss: 0.027139735287055374
[Epoch 15, Batch 300] loss: 0.027839937263634054
**STATS for Epoch 15** : 
Average training loss: 0.0048
Average validation loss: 0.0375
Validation Accuracy: 0.9881
Overfitting: 0.0328
Best model saved at epoch 15 with validation loss: 0.0375
[Epoch 16, Batch 100] loss: 0.019169638258172198
[Epoch 16, Batch 200] loss: 0.0226152608031407
[Epoch 16, Batch 300] loss: 0.024784112675115468
**STATS for Epoch 16** : 
Average training loss: 0.0049
Average validation loss: 0.0406
Validation Accuracy: 0.9865
Overfitting: 0.0357
[Epoch 17, Batch 100] loss: 0.019685999788343907
[Epoch 17, Batch 200] loss: 0.01961116197053343
[Epoch 17, Batch 300] loss: 0.02435307318693958
**STATS for Epoch 17** : 
Average training loss: 0.0037
Average validation loss: 0.0400
Validation Accuracy: 0.9879
Overfitting: 0.0363
[Epoch 18, Batch 100] loss: 0.015144143229117618
[Epoch 18, Batch 200] loss: 0.017956988546065988
[Epoch 18, Batch 300] loss: 0.019550743512809277
**STATS for Epoch 18** : 
Average training loss: 0.0047
Average validation loss: 0.0429
Validation Accuracy: 0.9867
Overfitting: 0.0382
[Epoch 19, Batch 100] loss: 0.01526200446416624
[Epoch 19, Batch 200] loss: 0.01932989660766907
[Epoch 19, Batch 300] loss: 0.015818275805795565
**STATS for Epoch 19** : 
Average training loss: 0.0040
Average validation loss: 0.0465
Validation Accuracy: 0.9848
Overfitting: 0.0425
[Epoch 20, Batch 100] loss: 0.01764999454666395
[Epoch 20, Batch 200] loss: 0.014360503995558247
[Epoch 20, Batch 300] loss: 0.017085439958027564
**STATS for Epoch 20** : 
Average training loss: 0.0035
Average validation loss: 0.0402
Validation Accuracy: 0.9878
Overfitting: 0.0367
[Epoch 21, Batch 100] loss: 0.012762030481826513
[Epoch 21, Batch 200] loss: 0.011130482429871335
[Epoch 21, Batch 300] loss: 0.01704187321709469
**STATS for Epoch 21** : 
Average training loss: 0.0031
Average validation loss: 0.0406
Validation Accuracy: 0.9873
Overfitting: 0.0375
[Epoch 22, Batch 100] loss: 0.012405111209955067
[Epoch 22, Batch 200] loss: 0.01342618370661512
[Epoch 22, Batch 300] loss: 0.01464520712615922
**STATS for Epoch 22** : 
Average training loss: 0.0022
Average validation loss: 0.0381
Validation Accuracy: 0.9889
Overfitting: 0.0359
[Epoch 23, Batch 100] loss: 0.011710664730053395
[Epoch 23, Batch 200] loss: 0.011645382650312968
[Epoch 23, Batch 300] loss: 0.010284190626698546
**STATS for Epoch 23** : 
Average training loss: 0.0027
Average validation loss: 0.0388
Validation Accuracy: 0.9881
Overfitting: 0.0361
[Epoch 24, Batch 100] loss: 0.007905877994489855
[Epoch 24, Batch 200] loss: 0.012332851756946183
[Epoch 24, Batch 300] loss: 0.011849449939909391
**STATS for Epoch 24** : 
Average training loss: 0.0022
Average validation loss: 0.0415
Validation Accuracy: 0.9866
Overfitting: 0.0392
Fold 1 validation loss: 0.0415
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2341254591941833
[Epoch 1, Batch 200] loss: 1.027480835914612
[Epoch 1, Batch 300] loss: 0.42751975208520887
**STATS for Epoch 1** : 
Average training loss: 0.0614
Average validation loss: 0.2897
Validation Accuracy: 0.9137
Overfitting: 0.2283
Best model saved at epoch 1 with validation loss: 0.2897
[Epoch 2, Batch 100] loss: 0.24551312282681464
[Epoch 2, Batch 200] loss: 0.19577195025980473
[Epoch 2, Batch 300] loss: 0.1787346990406513
**STATS for Epoch 2** : 
Average training loss: 0.0331
Average validation loss: 0.1587
Validation Accuracy: 0.9526
Overfitting: 0.1256
Best model saved at epoch 2 with validation loss: 0.1587
[Epoch 3, Batch 100] loss: 0.1380196364596486
[Epoch 3, Batch 200] loss: 0.13549821458756925
[Epoch 3, Batch 300] loss: 0.11817622756585479
**STATS for Epoch 3** : 
Average training loss: 0.0210
Average validation loss: 0.1314
Validation Accuracy: 0.9604
Overfitting: 0.1104
Best model saved at epoch 3 with validation loss: 0.1314
[Epoch 4, Batch 100] loss: 0.10417514644563199
[Epoch 4, Batch 200] loss: 0.09845395553857088
[Epoch 4, Batch 300] loss: 0.09510401237756014
**STATS for Epoch 4** : 
Average training loss: 0.0151
Average validation loss: 0.0981
Validation Accuracy: 0.9707
Overfitting: 0.0829
Best model saved at epoch 4 with validation loss: 0.0981
[Epoch 5, Batch 100] loss: 0.07571370484307409
[Epoch 5, Batch 200] loss: 0.08318285008892418
[Epoch 5, Batch 300] loss: 0.08313206102699042
**STATS for Epoch 5** : 
Average training loss: 0.0149
Average validation loss: 0.0821
Validation Accuracy: 0.9761
Overfitting: 0.0672
Best model saved at epoch 5 with validation loss: 0.0821
[Epoch 6, Batch 100] loss: 0.07089384287595749
[Epoch 6, Batch 200] loss: 0.060846671890467406
[Epoch 6, Batch 300] loss: 0.06247473191469908
**STATS for Epoch 6** : 
Average training loss: 0.0128
Average validation loss: 0.0876
Validation Accuracy: 0.9744
Overfitting: 0.0748
[Epoch 7, Batch 100] loss: 0.055585837471298874
[Epoch 7, Batch 200] loss: 0.05170008785091341
[Epoch 7, Batch 300] loss: 0.06125359102152288
**STATS for Epoch 7** : 
Average training loss: 0.0131
Average validation loss: 0.0768
Validation Accuracy: 0.9768
Overfitting: 0.0637
Best model saved at epoch 7 with validation loss: 0.0768
[Epoch 8, Batch 100] loss: 0.05030775873921812
[Epoch 8, Batch 200] loss: 0.04623880328144878
[Epoch 8, Batch 300] loss: 0.04967151682823896
**STATS for Epoch 8** : 
Average training loss: 0.0110
Average validation loss: 0.0707
Validation Accuracy: 0.9773
Overfitting: 0.0597
Best model saved at epoch 8 with validation loss: 0.0707
[Epoch 9, Batch 100] loss: 0.04104265438392758
[Epoch 9, Batch 200] loss: 0.044904372836463154
[Epoch 9, Batch 300] loss: 0.05030398071743548
**STATS for Epoch 9** : 
Average training loss: 0.0091
Average validation loss: 0.0670
Validation Accuracy: 0.9792
Overfitting: 0.0578
Best model saved at epoch 9 with validation loss: 0.0670
[Epoch 10, Batch 100] loss: 0.04126852641347796
[Epoch 10, Batch 200] loss: 0.042189007787965235
[Epoch 10, Batch 300] loss: 0.03731214405270293
**STATS for Epoch 10** : 
Average training loss: 0.0073
Average validation loss: 0.0699
Validation Accuracy: 0.9785
Overfitting: 0.0627
[Epoch 11, Batch 100] loss: 0.03820867144037038
[Epoch 11, Batch 200] loss: 0.03541719552129507
[Epoch 11, Batch 300] loss: 0.04044927617534995
**STATS for Epoch 11** : 
Average training loss: 0.0066
Average validation loss: 0.0705
Validation Accuracy: 0.9798
Overfitting: 0.0639
[Epoch 12, Batch 100] loss: 0.030994298248551787
[Epoch 12, Batch 200] loss: 0.029035249557346106
[Epoch 12, Batch 300] loss: 0.03238603224046528
**STATS for Epoch 12** : 
Average training loss: 0.0079
Average validation loss: 0.0688
Validation Accuracy: 0.9812
Overfitting: 0.0609
[Epoch 13, Batch 100] loss: 0.027556844530627133
[Epoch 13, Batch 200] loss: 0.028734092416707425
[Epoch 13, Batch 300] loss: 0.03341036010766402
**STATS for Epoch 13** : 
Average training loss: 0.0061
Average validation loss: 0.0610
Validation Accuracy: 0.9818
Overfitting: 0.0549
Best model saved at epoch 13 with validation loss: 0.0610
[Epoch 14, Batch 100] loss: 0.026221497259102763
[Epoch 14, Batch 200] loss: 0.028467104895971717
[Epoch 14, Batch 300] loss: 0.025723229674622417
**STATS for Epoch 14** : 
Average training loss: 0.0051
Average validation loss: 0.0585
Validation Accuracy: 0.9824
Overfitting: 0.0533
Best model saved at epoch 14 with validation loss: 0.0585
[Epoch 15, Batch 100] loss: 0.021605402524583043
[Epoch 15, Batch 200] loss: 0.02339171546511352
[Epoch 15, Batch 300] loss: 0.028605043669231237
**STATS for Epoch 15** : 
Average training loss: 0.0047
Average validation loss: 0.0587
Validation Accuracy: 0.9832
Overfitting: 0.0540
[Epoch 16, Batch 100] loss: 0.02203111892566085
[Epoch 16, Batch 200] loss: 0.01994637939031236
[Epoch 16, Batch 300] loss: 0.024335957772564143
**STATS for Epoch 16** : 
Average training loss: 0.0050
Average validation loss: 0.0659
Validation Accuracy: 0.9805
Overfitting: 0.0609
[Epoch 17, Batch 100] loss: 0.018692883622134105
[Epoch 17, Batch 200] loss: 0.01836240450036712
[Epoch 17, Batch 300] loss: 0.022674715419416316
**STATS for Epoch 17** : 
Average training loss: 0.0046
Average validation loss: 0.0650
Validation Accuracy: 0.9809
Overfitting: 0.0604
[Epoch 18, Batch 100] loss: 0.021336745063308626
[Epoch 18, Batch 200] loss: 0.018666435942286626
[Epoch 18, Batch 300] loss: 0.016473316551418975
**STATS for Epoch 18** : 
Average training loss: 0.0037
Average validation loss: 0.0625
Validation Accuracy: 0.9825
Overfitting: 0.0588
[Epoch 19, Batch 100] loss: 0.01679397551517468
[Epoch 19, Batch 200] loss: 0.018243040629313326
[Epoch 19, Batch 300] loss: 0.018482584236189724
**STATS for Epoch 19** : 
Average training loss: 0.0041
Average validation loss: 0.0575
Validation Accuracy: 0.9836
Overfitting: 0.0534
Best model saved at epoch 19 with validation loss: 0.0575
[Epoch 20, Batch 100] loss: 0.01413672509486787
[Epoch 20, Batch 200] loss: 0.014714779436180834
[Epoch 20, Batch 300] loss: 0.016107832421548663
**STATS for Epoch 20** : 
Average training loss: 0.0028
Average validation loss: 0.0579
Validation Accuracy: 0.9846
Overfitting: 0.0551
[Epoch 21, Batch 100] loss: 0.011399317678879015
[Epoch 21, Batch 200] loss: 0.014821658484288491
[Epoch 21, Batch 300] loss: 0.014471213943324982
**STATS for Epoch 21** : 
Average training loss: 0.0043
Average validation loss: 0.0642
Validation Accuracy: 0.9832
Overfitting: 0.0599
[Epoch 22, Batch 100] loss: 0.011494188462093007
[Epoch 22, Batch 200] loss: 0.012145494249416515
[Epoch 22, Batch 300] loss: 0.015500588202266954
**STATS for Epoch 22** : 
Average training loss: 0.0031
Average validation loss: 0.0674
Validation Accuracy: 0.9822
Overfitting: 0.0643
[Epoch 23, Batch 100] loss: 0.008974710755283014
[Epoch 23, Batch 200] loss: 0.01208553632197436
[Epoch 23, Batch 300] loss: 0.011373905749351251
**STATS for Epoch 23** : 
Average training loss: 0.0026
Average validation loss: 0.0582
Validation Accuracy: 0.9841
Overfitting: 0.0556
[Epoch 24, Batch 100] loss: 0.01143415477417875
[Epoch 24, Batch 200] loss: 0.011573432293953374
[Epoch 24, Batch 300] loss: 0.010525621578563005
**STATS for Epoch 24** : 
Average training loss: 0.0018
Average validation loss: 0.0636
Validation Accuracy: 0.9838
Overfitting: 0.0618
Fold 2 validation loss: 0.0636
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.241871540546417
[Epoch 1, Batch 200] loss: 0.9645603176951408
[Epoch 1, Batch 300] loss: 0.3608072578907013
**STATS for Epoch 1** : 
Average training loss: 0.0481
Average validation loss: 0.2299
Validation Accuracy: 0.9303
Overfitting: 0.1818
Best model saved at epoch 1 with validation loss: 0.2299
[Epoch 2, Batch 100] loss: 0.1948765815794468
[Epoch 2, Batch 200] loss: 0.16920060221105815
[Epoch 2, Batch 300] loss: 0.1448980228230357
**STATS for Epoch 2** : 
Average training loss: 0.0294
Average validation loss: 0.1352
Validation Accuracy: 0.9591
Overfitting: 0.1057
Best model saved at epoch 2 with validation loss: 0.1352
[Epoch 3, Batch 100] loss: 0.12151400566101074
[Epoch 3, Batch 200] loss: 0.10492715584114194
[Epoch 3, Batch 300] loss: 0.10717505369335413
**STATS for Epoch 3** : 
Average training loss: 0.0195
Average validation loss: 0.1165
Validation Accuracy: 0.9653
Overfitting: 0.0969
Best model saved at epoch 3 with validation loss: 0.1165
[Epoch 4, Batch 100] loss: 0.09952311847358943
[Epoch 4, Batch 200] loss: 0.08539713708683848
[Epoch 4, Batch 300] loss: 0.08289517926052213
**STATS for Epoch 4** : 
Average training loss: 0.0143
Average validation loss: 0.0807
Validation Accuracy: 0.9758
Overfitting: 0.0664
Best model saved at epoch 4 with validation loss: 0.0807
[Epoch 5, Batch 100] loss: 0.07469669315963984
[Epoch 5, Batch 200] loss: 0.07556506158784032
[Epoch 5, Batch 300] loss: 0.0740366387180984
**STATS for Epoch 5** : 
Average training loss: 0.0127
Average validation loss: 0.0771
Validation Accuracy: 0.9767
Overfitting: 0.0644
Best model saved at epoch 5 with validation loss: 0.0771
[Epoch 6, Batch 100] loss: 0.058256289698183535
[Epoch 6, Batch 200] loss: 0.06257991370745003
[Epoch 6, Batch 300] loss: 0.06040658756159246
**STATS for Epoch 6** : 
Average training loss: 0.0125
Average validation loss: 0.0680
Validation Accuracy: 0.9800
Overfitting: 0.0555
Best model saved at epoch 6 with validation loss: 0.0680
[Epoch 7, Batch 100] loss: 0.05201702676713467
[Epoch 7, Batch 200] loss: 0.053491386529058216
[Epoch 7, Batch 300] loss: 0.057201085183769464
**STATS for Epoch 7** : 
Average training loss: 0.0102
Average validation loss: 0.0746
Validation Accuracy: 0.9781
Overfitting: 0.0644
[Epoch 8, Batch 100] loss: 0.04725706614553928
[Epoch 8, Batch 200] loss: 0.050205171946436165
[Epoch 8, Batch 300] loss: 0.04751921905670315
**STATS for Epoch 8** : 
Average training loss: 0.0102
Average validation loss: 0.0677
Validation Accuracy: 0.9788
Overfitting: 0.0575
Best model saved at epoch 8 with validation loss: 0.0677
[Epoch 9, Batch 100] loss: 0.039106297632679345
[Epoch 9, Batch 200] loss: 0.040313491418492046
[Epoch 9, Batch 300] loss: 0.04602394905872643
**STATS for Epoch 9** : 
Average training loss: 0.0092
Average validation loss: 0.0555
Validation Accuracy: 0.9833
Overfitting: 0.0463
Best model saved at epoch 9 with validation loss: 0.0555
[Epoch 10, Batch 100] loss: 0.04056198185775429
[Epoch 10, Batch 200] loss: 0.03888700927142054
[Epoch 10, Batch 300] loss: 0.04093496375251562
**STATS for Epoch 10** : 
Average training loss: 0.0070
Average validation loss: 0.0656
Validation Accuracy: 0.9789
Overfitting: 0.0586
[Epoch 11, Batch 100] loss: 0.0369824203196913
[Epoch 11, Batch 200] loss: 0.03447156054899096
[Epoch 11, Batch 300] loss: 0.03377417089533992
**STATS for Epoch 11** : 
Average training loss: 0.0073
Average validation loss: 0.0534
Validation Accuracy: 0.9848
Overfitting: 0.0461
Best model saved at epoch 11 with validation loss: 0.0534
[Epoch 12, Batch 100] loss: 0.026875290933530777
[Epoch 12, Batch 200] loss: 0.027075996971689165
[Epoch 12, Batch 300] loss: 0.03610014064703137
**STATS for Epoch 12** : 
Average training loss: 0.0076
Average validation loss: 0.0494
Validation Accuracy: 0.9853
Overfitting: 0.0419
Best model saved at epoch 12 with validation loss: 0.0494
[Epoch 13, Batch 100] loss: 0.02736234524520114
[Epoch 13, Batch 200] loss: 0.027675097761675715
[Epoch 13, Batch 300] loss: 0.026567066004499793
**STATS for Epoch 13** : 
Average training loss: 0.0075
Average validation loss: 0.0500
Validation Accuracy: 0.9848
Overfitting: 0.0425
[Epoch 14, Batch 100] loss: 0.0255718179885298
[Epoch 14, Batch 200] loss: 0.021485689260298386
[Epoch 14, Batch 300] loss: 0.03052808701642789
**STATS for Epoch 14** : 
Average training loss: 0.0057
Average validation loss: 0.0506
Validation Accuracy: 0.9849
Overfitting: 0.0449
[Epoch 15, Batch 100] loss: 0.023510078222025187
[Epoch 15, Batch 200] loss: 0.024337165525648744
[Epoch 15, Batch 300] loss: 0.024313849336467682
**STATS for Epoch 15** : 
Average training loss: 0.0042
Average validation loss: 0.0512
Validation Accuracy: 0.9846
Overfitting: 0.0470
[Epoch 16, Batch 100] loss: 0.020672054942697287
[Epoch 16, Batch 200] loss: 0.020714168936247005
[Epoch 16, Batch 300] loss: 0.023511341563425957
**STATS for Epoch 16** : 
Average training loss: 0.0050
Average validation loss: 0.0501
Validation Accuracy: 0.9852
Overfitting: 0.0451
[Epoch 17, Batch 100] loss: 0.019149871345143767
[Epoch 17, Batch 200] loss: 0.02031663186615333
[Epoch 17, Batch 300] loss: 0.019915755677502603
**STATS for Epoch 17** : 
Average training loss: 0.0040
Average validation loss: 0.0553
Validation Accuracy: 0.9837
Overfitting: 0.0512
[Epoch 18, Batch 100] loss: 0.018876732625067234
[Epoch 18, Batch 200] loss: 0.015990856896387413
[Epoch 18, Batch 300] loss: 0.02010410771006718
**STATS for Epoch 18** : 
Average training loss: 0.0036
Average validation loss: 0.0520
Validation Accuracy: 0.9838
Overfitting: 0.0483
[Epoch 19, Batch 100] loss: 0.015334557314636186
[Epoch 19, Batch 200] loss: 0.015287633584812284
[Epoch 19, Batch 300] loss: 0.019416433504084125
**STATS for Epoch 19** : 
Average training loss: 0.0034
Average validation loss: 0.0468
Validation Accuracy: 0.9867
Overfitting: 0.0434
Best model saved at epoch 19 with validation loss: 0.0468
[Epoch 20, Batch 100] loss: 0.013644118792144581
[Epoch 20, Batch 200] loss: 0.014304073193343356
[Epoch 20, Batch 300] loss: 0.015711126181995497
**STATS for Epoch 20** : 
Average training loss: 0.0036
Average validation loss: 0.0494
Validation Accuracy: 0.9860
Overfitting: 0.0458
[Epoch 21, Batch 100] loss: 0.010173891811282374
[Epoch 21, Batch 200] loss: 0.014379187092417851
[Epoch 21, Batch 300] loss: 0.013394611736875959
**STATS for Epoch 21** : 
Average training loss: 0.0031
Average validation loss: 0.0440
Validation Accuracy: 0.9878
Overfitting: 0.0408
Best model saved at epoch 21 with validation loss: 0.0440
[Epoch 22, Batch 100] loss: 0.010854691357817501
[Epoch 22, Batch 200] loss: 0.011863189336727373
[Epoch 22, Batch 300] loss: 0.012584118528175169
**STATS for Epoch 22** : 
Average training loss: 0.0024
Average validation loss: 0.0523
Validation Accuracy: 0.9852
Overfitting: 0.0499
[Epoch 23, Batch 100] loss: 0.011674407402751967
[Epoch 23, Batch 200] loss: 0.010241117192199454
[Epoch 23, Batch 300] loss: 0.009716150403546635
**STATS for Epoch 23** : 
Average training loss: 0.0031
Average validation loss: 0.0491
Validation Accuracy: 0.9859
Overfitting: 0.0460
[Epoch 24, Batch 100] loss: 0.01007462483481504
[Epoch 24, Batch 200] loss: 0.010947890387615188
[Epoch 24, Batch 300] loss: 0.011189452088437975
**STATS for Epoch 24** : 
Average training loss: 0.0017
Average validation loss: 0.0517
Validation Accuracy: 0.9862
Overfitting: 0.0499
Fold 3 validation loss: 0.0517
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.0471132147312163
[Epoch 1, Batch 200] loss: 0.6010954067111015
[Epoch 1, Batch 300] loss: 0.3584525360167026
**STATS for Epoch 1** : 
Average training loss: 0.0585
Average validation loss: 0.2671
Validation Accuracy: 0.9136
Overfitting: 0.2086
Best model saved at epoch 1 with validation loss: 0.2671
[Epoch 2, Batch 100] loss: 0.22793925270438195
[Epoch 2, Batch 200] loss: 0.1888458888232708
[Epoch 2, Batch 300] loss: 0.15965487085282803
**STATS for Epoch 2** : 
Average training loss: 0.0287
Average validation loss: 0.1281
Validation Accuracy: 0.9592
Overfitting: 0.0994
Best model saved at epoch 2 with validation loss: 0.1281
[Epoch 3, Batch 100] loss: 0.12671746138483286
[Epoch 3, Batch 200] loss: 0.11674573928117753
[Epoch 3, Batch 300] loss: 0.10457476457580923
**STATS for Epoch 3** : 
Average training loss: 0.0201
Average validation loss: 0.0917
Validation Accuracy: 0.9715
Overfitting: 0.0716
Best model saved at epoch 3 with validation loss: 0.0917
[Epoch 4, Batch 100] loss: 0.09953810047358275
[Epoch 4, Batch 200] loss: 0.08858024580404163
[Epoch 4, Batch 300] loss: 0.08596720835193991
**STATS for Epoch 4** : 
Average training loss: 0.0166
Average validation loss: 0.0878
Validation Accuracy: 0.9714
Overfitting: 0.0711
Best model saved at epoch 4 with validation loss: 0.0878
[Epoch 5, Batch 100] loss: 0.07432582108303905
[Epoch 5, Batch 200] loss: 0.07417928813025355
[Epoch 5, Batch 300] loss: 0.07116148201748729
**STATS for Epoch 5** : 
Average training loss: 0.0156
Average validation loss: 0.0769
Validation Accuracy: 0.9755
Overfitting: 0.0613
Best model saved at epoch 5 with validation loss: 0.0769
[Epoch 6, Batch 100] loss: 0.06814443502575158
[Epoch 6, Batch 200] loss: 0.061957875434309244
[Epoch 6, Batch 300] loss: 0.06524530978873372
**STATS for Epoch 6** : 
Average training loss: 0.0126
Average validation loss: 0.0670
Validation Accuracy: 0.9796
Overfitting: 0.0544
Best model saved at epoch 6 with validation loss: 0.0670
[Epoch 7, Batch 100] loss: 0.05385832894593477
[Epoch 7, Batch 200] loss: 0.053169378461316225
[Epoch 7, Batch 300] loss: 0.057682522051036356
**STATS for Epoch 7** : 
Average training loss: 0.0123
Average validation loss: 0.0649
Validation Accuracy: 0.9799
Overfitting: 0.0526
Best model saved at epoch 7 with validation loss: 0.0649
[Epoch 8, Batch 100] loss: 0.05239474838599563
[Epoch 8, Batch 200] loss: 0.041657077223062514
[Epoch 8, Batch 300] loss: 0.055078030601143836
**STATS for Epoch 8** : 
Average training loss: 0.0104
Average validation loss: 0.0571
Validation Accuracy: 0.9819
Overfitting: 0.0467
Best model saved at epoch 8 with validation loss: 0.0571
[Epoch 9, Batch 100] loss: 0.04125953047536313
[Epoch 9, Batch 200] loss: 0.039343364564701916
[Epoch 9, Batch 300] loss: 0.04824313401244581
**STATS for Epoch 9** : 
Average training loss: 0.0096
Average validation loss: 0.0546
Validation Accuracy: 0.9822
Overfitting: 0.0449
Best model saved at epoch 9 with validation loss: 0.0546
[Epoch 10, Batch 100] loss: 0.03835967517457903
[Epoch 10, Batch 200] loss: 0.042472430793568494
[Epoch 10, Batch 300] loss: 0.037596272248774765
**STATS for Epoch 10** : 
Average training loss: 0.0086
Average validation loss: 0.0500
Validation Accuracy: 0.9832
Overfitting: 0.0414
Best model saved at epoch 10 with validation loss: 0.0500
[Epoch 11, Batch 100] loss: 0.03791052222717553
[Epoch 11, Batch 200] loss: 0.032439889553934335
[Epoch 11, Batch 300] loss: 0.03841359459795058
**STATS for Epoch 11** : 
Average training loss: 0.0068
Average validation loss: 0.0520
Validation Accuracy: 0.9840
Overfitting: 0.0452
[Epoch 12, Batch 100] loss: 0.03582330579403788
[Epoch 12, Batch 200] loss: 0.029884870713576674
[Epoch 12, Batch 300] loss: 0.03478458850644529
**STATS for Epoch 12** : 
Average training loss: 0.0080
Average validation loss: 0.0456
Validation Accuracy: 0.9850
Overfitting: 0.0376
Best model saved at epoch 12 with validation loss: 0.0456
[Epoch 13, Batch 100] loss: 0.030029149148613214
[Epoch 13, Batch 200] loss: 0.03273454814683646
[Epoch 13, Batch 300] loss: 0.026899455131497232
**STATS for Epoch 13** : 
Average training loss: 0.0059
Average validation loss: 0.0525
Validation Accuracy: 0.9837
Overfitting: 0.0466
[Epoch 14, Batch 100] loss: 0.024961839830502867
[Epoch 14, Batch 200] loss: 0.026778650793712586
[Epoch 14, Batch 300] loss: 0.025709276958368717
**STATS for Epoch 14** : 
Average training loss: 0.0060
Average validation loss: 0.0539
Validation Accuracy: 0.9831
Overfitting: 0.0479
[Epoch 15, Batch 100] loss: 0.02608382987556979
[Epoch 15, Batch 200] loss: 0.025008419645018876
[Epoch 15, Batch 300] loss: 0.02532803779700771
**STATS for Epoch 15** : 
Average training loss: 0.0055
Average validation loss: 0.0512
Validation Accuracy: 0.9841
Overfitting: 0.0457
[Epoch 16, Batch 100] loss: 0.022107422947883607
[Epoch 16, Batch 200] loss: 0.01974118001293391
[Epoch 16, Batch 300] loss: 0.02595446107443422
**STATS for Epoch 16** : 
Average training loss: 0.0051
Average validation loss: 0.0440
Validation Accuracy: 0.9863
Overfitting: 0.0389
Best model saved at epoch 16 with validation loss: 0.0440
[Epoch 17, Batch 100] loss: 0.020686572236591018
[Epoch 17, Batch 200] loss: 0.023955636210739612
[Epoch 17, Batch 300] loss: 0.017333708849037066
**STATS for Epoch 17** : 
Average training loss: 0.0046
Average validation loss: 0.0435
Validation Accuracy: 0.9865
Overfitting: 0.0389
Best model saved at epoch 17 with validation loss: 0.0435
[Epoch 18, Batch 100] loss: 0.018273996804491616
[Epoch 18, Batch 200] loss: 0.020468856998486443
[Epoch 18, Batch 300] loss: 0.018351223699282854
**STATS for Epoch 18** : 
Average training loss: 0.0041
Average validation loss: 0.0428
Validation Accuracy: 0.9874
Overfitting: 0.0387
Best model saved at epoch 18 with validation loss: 0.0428
[Epoch 19, Batch 100] loss: 0.016866968024987727
[Epoch 19, Batch 200] loss: 0.017723672045394778
[Epoch 19, Batch 300] loss: 0.018092024149373175
**STATS for Epoch 19** : 
Average training loss: 0.0034
Average validation loss: 0.0412
Validation Accuracy: 0.9869
Overfitting: 0.0378
Best model saved at epoch 19 with validation loss: 0.0412
[Epoch 20, Batch 100] loss: 0.015136375998845325
[Epoch 20, Batch 200] loss: 0.017202627742663026
[Epoch 20, Batch 300] loss: 0.017719544988358392
**STATS for Epoch 20** : 
Average training loss: 0.0036
Average validation loss: 0.0418
Validation Accuracy: 0.9872
Overfitting: 0.0381
[Epoch 21, Batch 100] loss: 0.011859146409842652
[Epoch 21, Batch 200] loss: 0.013258147909655236
[Epoch 21, Batch 300] loss: 0.014034220778848977
**STATS for Epoch 21** : 
Average training loss: 0.0037
Average validation loss: 0.0486
Validation Accuracy: 0.9852
Overfitting: 0.0449
[Epoch 22, Batch 100] loss: 0.011058762009488418
[Epoch 22, Batch 200] loss: 0.012145898548187688
[Epoch 22, Batch 300] loss: 0.017302014525630512
**STATS for Epoch 22** : 
Average training loss: 0.0032
Average validation loss: 0.0435
Validation Accuracy: 0.9871
Overfitting: 0.0403
[Epoch 23, Batch 100] loss: 0.010909499964327551
[Epoch 23, Batch 200] loss: 0.012289113418664782
[Epoch 23, Batch 300] loss: 0.016185563951148653
**STATS for Epoch 23** : 
Average training loss: 0.0025
Average validation loss: 0.0443
Validation Accuracy: 0.9872
Overfitting: 0.0418
[Epoch 24, Batch 100] loss: 0.009079461450164672
[Epoch 24, Batch 200] loss: 0.013885447414941155
[Epoch 24, Batch 300] loss: 0.010730436653248035
**STATS for Epoch 24** : 
Average training loss: 0.0028
Average validation loss: 0.0474
Validation Accuracy: 0.9866
Overfitting: 0.0446
Fold 4 validation loss: 0.0474
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2815210747718813
[Epoch 1, Batch 200] loss: 1.4077326345443726
[Epoch 1, Batch 300] loss: 0.40892594620585443
**STATS for Epoch 1** : 
Average training loss: 0.0561
Average validation loss: 0.2713
Validation Accuracy: 0.9132
Overfitting: 0.2152
Best model saved at epoch 1 with validation loss: 0.2713
[Epoch 2, Batch 100] loss: 0.23481655262410642
[Epoch 2, Batch 200] loss: 0.1810084231197834
[Epoch 2, Batch 300] loss: 0.14503416374325753
**STATS for Epoch 2** : 
Average training loss: 0.0292
Average validation loss: 0.1390
Validation Accuracy: 0.9569
Overfitting: 0.1098
Best model saved at epoch 2 with validation loss: 0.1390
[Epoch 3, Batch 100] loss: 0.11858915723860264
[Epoch 3, Batch 200] loss: 0.11182214420288801
[Epoch 3, Batch 300] loss: 0.10493891522288322
**STATS for Epoch 3** : 
Average training loss: 0.0180
Average validation loss: 0.0928
Validation Accuracy: 0.9714
Overfitting: 0.0748
Best model saved at epoch 3 with validation loss: 0.0928
[Epoch 4, Batch 100] loss: 0.08746045528911055
[Epoch 4, Batch 200] loss: 0.08457828408107161
[Epoch 4, Batch 300] loss: 0.08389768423512578
**STATS for Epoch 4** : 
Average training loss: 0.0167
Average validation loss: 0.0863
Validation Accuracy: 0.9735
Overfitting: 0.0697
Best model saved at epoch 4 with validation loss: 0.0863
[Epoch 5, Batch 100] loss: 0.07427593015134334
[Epoch 5, Batch 200] loss: 0.07986675894819201
[Epoch 5, Batch 300] loss: 0.06849463506601751
**STATS for Epoch 5** : 
Average training loss: 0.0136
Average validation loss: 0.0717
Validation Accuracy: 0.9781
Overfitting: 0.0581
Best model saved at epoch 5 with validation loss: 0.0717
[Epoch 6, Batch 100] loss: 0.0661706897476688
[Epoch 6, Batch 200] loss: 0.05758703984320164
[Epoch 6, Batch 300] loss: 0.06332159208599478
**STATS for Epoch 6** : 
Average training loss: 0.0116
Average validation loss: 0.0669
Validation Accuracy: 0.9791
Overfitting: 0.0553
Best model saved at epoch 6 with validation loss: 0.0669
[Epoch 7, Batch 100] loss: 0.04863692228216678
[Epoch 7, Batch 200] loss: 0.050398959880694746
[Epoch 7, Batch 300] loss: 0.05538822151254862
**STATS for Epoch 7** : 
Average training loss: 0.0117
Average validation loss: 0.0570
Validation Accuracy: 0.9828
Overfitting: 0.0453
Best model saved at epoch 7 with validation loss: 0.0570
[Epoch 8, Batch 100] loss: 0.04835274836979806
[Epoch 8, Batch 200] loss: 0.04483329626265913
[Epoch 8, Batch 300] loss: 0.0492993267159909
**STATS for Epoch 8** : 
Average training loss: 0.0092
Average validation loss: 0.0528
Validation Accuracy: 0.9848
Overfitting: 0.0436
Best model saved at epoch 8 with validation loss: 0.0528
[Epoch 9, Batch 100] loss: 0.039566865260712805
[Epoch 9, Batch 200] loss: 0.04310448828153312
[Epoch 9, Batch 300] loss: 0.043421098315156996
**STATS for Epoch 9** : 
Average training loss: 0.0089
Average validation loss: 0.0516
Validation Accuracy: 0.9844
Overfitting: 0.0427
Best model saved at epoch 9 with validation loss: 0.0516
[Epoch 10, Batch 100] loss: 0.03915947631001473
[Epoch 10, Batch 200] loss: 0.03767699841875583
[Epoch 10, Batch 300] loss: 0.03996084581594914
**STATS for Epoch 10** : 
Average training loss: 0.0079
Average validation loss: 0.0578
Validation Accuracy: 0.9818
Overfitting: 0.0499
[Epoch 11, Batch 100] loss: 0.0332094154600054
[Epoch 11, Batch 200] loss: 0.03770456233527511
[Epoch 11, Batch 300] loss: 0.03627276953775436
**STATS for Epoch 11** : 
Average training loss: 0.0068
Average validation loss: 0.0506
Validation Accuracy: 0.9839
Overfitting: 0.0438
Best model saved at epoch 11 with validation loss: 0.0506
[Epoch 12, Batch 100] loss: 0.03241131723858416
[Epoch 12, Batch 200] loss: 0.03117707199184224
[Epoch 12, Batch 300] loss: 0.03454393226187676
**STATS for Epoch 12** : 
Average training loss: 0.0067
Average validation loss: 0.0449
Validation Accuracy: 0.9867
Overfitting: 0.0382
Best model saved at epoch 12 with validation loss: 0.0449
[Epoch 13, Batch 100] loss: 0.02690479115117341
[Epoch 13, Batch 200] loss: 0.026081694562453777
[Epoch 13, Batch 300] loss: 0.03005801162449643
**STATS for Epoch 13** : 
Average training loss: 0.0074
Average validation loss: 0.0422
Validation Accuracy: 0.9878
Overfitting: 0.0348
Best model saved at epoch 13 with validation loss: 0.0422
[Epoch 14, Batch 100] loss: 0.021975711479317397
[Epoch 14, Batch 200] loss: 0.024409782704897225
[Epoch 14, Batch 300] loss: 0.029054950308054685
**STATS for Epoch 14** : 
Average training loss: 0.0058
Average validation loss: 0.0430
Validation Accuracy: 0.9870
Overfitting: 0.0372
[Epoch 15, Batch 100] loss: 0.021457783509977162
[Epoch 15, Batch 200] loss: 0.025459716551704332
[Epoch 15, Batch 300] loss: 0.02578625686932355
**STATS for Epoch 15** : 
Average training loss: 0.0064
Average validation loss: 0.0469
Validation Accuracy: 0.9862
Overfitting: 0.0405
[Epoch 16, Batch 100] loss: 0.022831178422784433
[Epoch 16, Batch 200] loss: 0.023315920454915613
[Epoch 16, Batch 300] loss: 0.020570352969225495
**STATS for Epoch 16** : 
Average training loss: 0.0058
Average validation loss: 0.0439
Validation Accuracy: 0.9859
Overfitting: 0.0381
[Epoch 17, Batch 100] loss: 0.02212407443439588
[Epoch 17, Batch 200] loss: 0.024493772645946592
[Epoch 17, Batch 300] loss: 0.023828146171290428
**STATS for Epoch 17** : 
Average training loss: 0.0032
Average validation loss: 0.0384
Validation Accuracy: 0.9881
Overfitting: 0.0352
Best model saved at epoch 17 with validation loss: 0.0384
[Epoch 18, Batch 100] loss: 0.018535905590979382
[Epoch 18, Batch 200] loss: 0.019675054243998603
[Epoch 18, Batch 300] loss: 0.020082844073185696
**STATS for Epoch 18** : 
Average training loss: 0.0041
Average validation loss: 0.0380
Validation Accuracy: 0.9882
Overfitting: 0.0339
Best model saved at epoch 18 with validation loss: 0.0380
[Epoch 19, Batch 100] loss: 0.015801526427967474
[Epoch 19, Batch 200] loss: 0.018051818007370456
[Epoch 19, Batch 300] loss: 0.018169567353324964
**STATS for Epoch 19** : 
Average training loss: 0.0035
Average validation loss: 0.0391
Validation Accuracy: 0.9880
Overfitting: 0.0356
[Epoch 20, Batch 100] loss: 0.01517288054805249
[Epoch 20, Batch 200] loss: 0.016790710074710658
[Epoch 20, Batch 300] loss: 0.016907006576657294
**STATS for Epoch 20** : 
Average training loss: 0.0038
Average validation loss: 0.0418
Validation Accuracy: 0.9877
Overfitting: 0.0380
[Epoch 21, Batch 100] loss: 0.0152583413280081
[Epoch 21, Batch 200] loss: 0.01182881387299858
[Epoch 21, Batch 300] loss: 0.01933854516420979
**STATS for Epoch 21** : 
Average training loss: 0.0034
Average validation loss: 0.0413
Validation Accuracy: 0.9869
Overfitting: 0.0379
[Epoch 22, Batch 100] loss: 0.014301471257349476
[Epoch 22, Batch 200] loss: 0.014220113542396575
[Epoch 22, Batch 300] loss: 0.013759294789051637
**STATS for Epoch 22** : 
Average training loss: 0.0031
Average validation loss: 0.0386
Validation Accuracy: 0.9887
Overfitting: 0.0355
[Epoch 23, Batch 100] loss: 0.010662720443797298
[Epoch 23, Batch 200] loss: 0.01679150679963641
[Epoch 23, Batch 300] loss: 0.011838460202561692
**STATS for Epoch 23** : 
Average training loss: 0.0030
Average validation loss: 0.0395
Validation Accuracy: 0.9882
Overfitting: 0.0364
[Epoch 24, Batch 100] loss: 0.012855087695352268
[Epoch 24, Batch 200] loss: 0.011425825429032557
[Epoch 24, Batch 300] loss: 0.010629786951467395
**STATS for Epoch 24** : 
Average training loss: 0.0027
Average validation loss: 0.0455
Validation Accuracy: 0.9870
Overfitting: 0.0428
Fold 5 validation loss: 0.0455
Mean validation loss across all folds for Trial 17 is 0.0499 with trial config:  l1: 256, l2: 64, lr: 0.003317662028701678, batch_size: 128
[I 2024-12-10 09:00:51,071] Trial 16 finished with value: 0.049934810196406186 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.003317662028701678, 'batch_size': 128}. Best is trial 4 with value: 0.045411968038914834.

Selected Hyperparameters for Trial 18:
  l1: 256, l2: 64, lr: 0.00490214514230691, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2516506934165954
[Epoch 1, Batch 200] loss: 0.8191876882314681
[Epoch 1, Batch 300] loss: 0.30152703166007994
**STATS for Epoch 1** : 
Average training loss: 0.0448
Average validation loss: 0.1963
Validation Accuracy: 0.9393
Overfitting: 0.1515
Best model saved at epoch 1 with validation loss: 0.1963
[Epoch 2, Batch 100] loss: 0.16853008892387153
[Epoch 2, Batch 200] loss: 0.1484274547919631
[Epoch 2, Batch 300] loss: 0.13764809809625148
**STATS for Epoch 2** : 
Average training loss: 0.0238
Average validation loss: 0.1081
Validation Accuracy: 0.9667
Overfitting: 0.0842
Best model saved at epoch 2 with validation loss: 0.1081
[Epoch 3, Batch 100] loss: 0.10561450149863959
[Epoch 3, Batch 200] loss: 0.09619155891239643
[Epoch 3, Batch 300] loss: 0.09742900297045708
**STATS for Epoch 3** : 
Average training loss: 0.0202
Average validation loss: 0.0971
Validation Accuracy: 0.9676
Overfitting: 0.0770
Best model saved at epoch 3 with validation loss: 0.0971
[Epoch 4, Batch 100] loss: 0.08153166788630188
[Epoch 4, Batch 200] loss: 0.07963515527546405
[Epoch 4, Batch 300] loss: 0.07360881743952633
**STATS for Epoch 4** : 
Average training loss: 0.0161
Average validation loss: 0.0687
Validation Accuracy: 0.9780
Overfitting: 0.0526
Best model saved at epoch 4 with validation loss: 0.0687
[Epoch 5, Batch 100] loss: 0.06637450208887458
[Epoch 5, Batch 200] loss: 0.06785754727199673
[Epoch 5, Batch 300] loss: 0.06263641585595905
**STATS for Epoch 5** : 
Average training loss: 0.0130
Average validation loss: 0.0632
Validation Accuracy: 0.9792
Overfitting: 0.0502
Best model saved at epoch 5 with validation loss: 0.0632
[Epoch 6, Batch 100] loss: 0.0561123988032341
[Epoch 6, Batch 200] loss: 0.05437430638819933
[Epoch 6, Batch 300] loss: 0.052589331418275834
**STATS for Epoch 6** : 
Average training loss: 0.0097
Average validation loss: 0.0561
Validation Accuracy: 0.9822
Overfitting: 0.0465
Best model saved at epoch 6 with validation loss: 0.0561
[Epoch 7, Batch 100] loss: 0.047798153394833204
[Epoch 7, Batch 200] loss: 0.04230162711814046
[Epoch 7, Batch 300] loss: 0.045222129286266864
**STATS for Epoch 7** : 
Average training loss: 0.0088
Average validation loss: 0.0538
Validation Accuracy: 0.9828
Overfitting: 0.0450
Best model saved at epoch 7 with validation loss: 0.0538
[Epoch 8, Batch 100] loss: 0.042897877432405945
[Epoch 8, Batch 200] loss: 0.042575415940955284
[Epoch 8, Batch 300] loss: 0.040134984098840504
**STATS for Epoch 8** : 
Average training loss: 0.0073
Average validation loss: 0.0477
Validation Accuracy: 0.9852
Overfitting: 0.0404
Best model saved at epoch 8 with validation loss: 0.0477
[Epoch 9, Batch 100] loss: 0.03146420557051897
[Epoch 9, Batch 200] loss: 0.03922311444068328
[Epoch 9, Batch 300] loss: 0.032922266651876274
**STATS for Epoch 9** : 
Average training loss: 0.0074
Average validation loss: 0.0466
Validation Accuracy: 0.9856
Overfitting: 0.0392
Best model saved at epoch 9 with validation loss: 0.0466
[Epoch 10, Batch 100] loss: 0.03213761446531862
[Epoch 10, Batch 200] loss: 0.02693705428391695
[Epoch 10, Batch 300] loss: 0.03092568974243477
**STATS for Epoch 10** : 
Average training loss: 0.0063
Average validation loss: 0.0513
Validation Accuracy: 0.9849
Overfitting: 0.0450
[Epoch 11, Batch 100] loss: 0.02437306691892445
[Epoch 11, Batch 200] loss: 0.02681844403850846
[Epoch 11, Batch 300] loss: 0.029632338325027378
**STATS for Epoch 11** : 
Average training loss: 0.0067
Average validation loss: 0.0463
Validation Accuracy: 0.9862
Overfitting: 0.0395
Best model saved at epoch 11 with validation loss: 0.0463
[Epoch 12, Batch 100] loss: 0.02304258317220956
[Epoch 12, Batch 200] loss: 0.023925453575793655
[Epoch 12, Batch 300] loss: 0.023246361454948784
**STATS for Epoch 12** : 
Average training loss: 0.0059
Average validation loss: 0.0584
Validation Accuracy: 0.9819
Overfitting: 0.0525
[Epoch 13, Batch 100] loss: 0.021238421178422867
[Epoch 13, Batch 200] loss: 0.022605258086696268
[Epoch 13, Batch 300] loss: 0.025429324841825293
**STATS for Epoch 13** : 
Average training loss: 0.0040
Average validation loss: 0.0471
Validation Accuracy: 0.9860
Overfitting: 0.0431
[Epoch 14, Batch 100] loss: 0.019196349695557727
[Epoch 14, Batch 200] loss: 0.018783544236794115
[Epoch 14, Batch 300] loss: 0.022133558895438908
**STATS for Epoch 14** : 
Average training loss: 0.0041
Average validation loss: 0.0469
Validation Accuracy: 0.9860
Overfitting: 0.0428
[Epoch 15, Batch 100] loss: 0.01401917424518615
[Epoch 15, Batch 200] loss: 0.01756482138822321
[Epoch 15, Batch 300] loss: 0.0157799013244221
**STATS for Epoch 15** : 
Average training loss: 0.0034
Average validation loss: 0.0490
Validation Accuracy: 0.9858
Overfitting: 0.0456
[Epoch 16, Batch 100] loss: 0.012807135033654049
[Epoch 16, Batch 200] loss: 0.014365129932994023
[Epoch 16, Batch 300] loss: 0.0159454243874643
**STATS for Epoch 16** : 
Average training loss: 0.0037
Average validation loss: 0.0503
Validation Accuracy: 0.9847
Overfitting: 0.0466
[Epoch 17, Batch 100] loss: 0.011918626353144645
[Epoch 17, Batch 200] loss: 0.012518687482515816
[Epoch 17, Batch 300] loss: 0.013245713494252414
**STATS for Epoch 17** : 
Average training loss: 0.0031
Average validation loss: 0.0454
Validation Accuracy: 0.9867
Overfitting: 0.0423
Best model saved at epoch 17 with validation loss: 0.0454
[Epoch 18, Batch 100] loss: 0.010204510603798553
[Epoch 18, Batch 200] loss: 0.011296839296701364
[Epoch 18, Batch 300] loss: 0.012295896186260506
**STATS for Epoch 18** : 
Average training loss: 0.0026
Average validation loss: 0.0484
Validation Accuracy: 0.9862
Overfitting: 0.0457
[Epoch 19, Batch 100] loss: 0.008645828350272495
[Epoch 19, Batch 200] loss: 0.011631235576642212
[Epoch 19, Batch 300] loss: 0.009858746185200289
**STATS for Epoch 19** : 
Average training loss: 0.0034
Average validation loss: 0.0487
Validation Accuracy: 0.9866
Overfitting: 0.0453
[Epoch 20, Batch 100] loss: 0.010197503246017732
[Epoch 20, Batch 200] loss: 0.009532905928208492
[Epoch 20, Batch 300] loss: 0.011230065244017168
**STATS for Epoch 20** : 
Average training loss: 0.0027
Average validation loss: 0.0475
Validation Accuracy: 0.9866
Overfitting: 0.0448
[Epoch 21, Batch 100] loss: 0.00667888635158306
[Epoch 21, Batch 200] loss: 0.006388288939197082
[Epoch 21, Batch 300] loss: 0.007101761439553229
**STATS for Epoch 21** : 
Average training loss: 0.0019
Average validation loss: 0.0480
Validation Accuracy: 0.9872
Overfitting: 0.0461
[Epoch 22, Batch 100] loss: 0.0054379658581456165
[Epoch 22, Batch 200] loss: 0.005217534457042348
[Epoch 22, Batch 300] loss: 0.007553943351231282
**STATS for Epoch 22** : 
Average training loss: 0.0017
Average validation loss: 0.0485
Validation Accuracy: 0.9877
Overfitting: 0.0468
[Epoch 23, Batch 100] loss: 0.005136480357759865
[Epoch 23, Batch 200] loss: 0.00534814611193724
[Epoch 23, Batch 300] loss: 0.007269796942418907
**STATS for Epoch 23** : 
Average training loss: 0.0008
Average validation loss: 0.0491
Validation Accuracy: 0.9880
Overfitting: 0.0483
[Epoch 24, Batch 100] loss: 0.004604112423839979
[Epoch 24, Batch 200] loss: 0.005395798727113288
[Epoch 24, Batch 300] loss: 0.0058016614537336865
**STATS for Epoch 24** : 
Average training loss: 0.0013
Average validation loss: 0.0462
Validation Accuracy: 0.9881
Overfitting: 0.0450
Fold 1 validation loss: 0.0462
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.1147093272209165
[Epoch 1, Batch 200] loss: 0.5470206072926521
[Epoch 1, Batch 300] loss: 0.3165875528752804
**STATS for Epoch 1** : 
Average training loss: 0.0456
Average validation loss: 0.1965
Validation Accuracy: 0.9408
Overfitting: 0.1508
Best model saved at epoch 1 with validation loss: 0.1965
[Epoch 2, Batch 100] loss: 0.165860136449337
[Epoch 2, Batch 200] loss: 0.13178778879344463
[Epoch 2, Batch 300] loss: 0.12681544464081526
**STATS for Epoch 2** : 
Average training loss: 0.0213
Average validation loss: 0.1076
Validation Accuracy: 0.9665
Overfitting: 0.0863
Best model saved at epoch 2 with validation loss: 0.1076
[Epoch 3, Batch 100] loss: 0.08188273314386606
[Epoch 3, Batch 200] loss: 0.0896649725176394
[Epoch 3, Batch 300] loss: 0.08460787987336517
**STATS for Epoch 3** : 
Average training loss: 0.0162
Average validation loss: 0.0903
Validation Accuracy: 0.9740
Overfitting: 0.0742
Best model saved at epoch 3 with validation loss: 0.0903
[Epoch 4, Batch 100] loss: 0.06806428905576467
[Epoch 4, Batch 200] loss: 0.06772245537489653
[Epoch 4, Batch 300] loss: 0.06438311937265098
**STATS for Epoch 4** : 
Average training loss: 0.0130
Average validation loss: 0.0803
Validation Accuracy: 0.9762
Overfitting: 0.0673
Best model saved at epoch 4 with validation loss: 0.0803
[Epoch 5, Batch 100] loss: 0.054902602876536546
[Epoch 5, Batch 200] loss: 0.054963856926187875
[Epoch 5, Batch 300] loss: 0.05324306526686996
**STATS for Epoch 5** : 
Average training loss: 0.0116
Average validation loss: 0.0773
Validation Accuracy: 0.9754
Overfitting: 0.0658
Best model saved at epoch 5 with validation loss: 0.0773
[Epoch 6, Batch 100] loss: 0.04586593523621559
[Epoch 6, Batch 200] loss: 0.04097422898747027
[Epoch 6, Batch 300] loss: 0.05070998524315655
**STATS for Epoch 6** : 
Average training loss: 0.0112
Average validation loss: 0.0640
Validation Accuracy: 0.9808
Overfitting: 0.0528
Best model saved at epoch 6 with validation loss: 0.0640
[Epoch 7, Batch 100] loss: 0.043193284091539684
[Epoch 7, Batch 200] loss: 0.04210450361482799
[Epoch 7, Batch 300] loss: 0.04047176050953567
**STATS for Epoch 7** : 
Average training loss: 0.0077
Average validation loss: 0.0617
Validation Accuracy: 0.9807
Overfitting: 0.0540
Best model saved at epoch 7 with validation loss: 0.0617
[Epoch 8, Batch 100] loss: 0.035345037709921596
[Epoch 8, Batch 200] loss: 0.039056877265684305
[Epoch 8, Batch 300] loss: 0.03507115109823644
**STATS for Epoch 8** : 
Average training loss: 0.0080
Average validation loss: 0.0535
Validation Accuracy: 0.9832
Overfitting: 0.0455
Best model saved at epoch 8 with validation loss: 0.0535
[Epoch 9, Batch 100] loss: 0.025833395386580377
[Epoch 9, Batch 200] loss: 0.029580157704185695
[Epoch 9, Batch 300] loss: 0.031941085052676496
**STATS for Epoch 9** : 
Average training loss: 0.0074
Average validation loss: 0.0592
Validation Accuracy: 0.9824
Overfitting: 0.0518
[Epoch 10, Batch 100] loss: 0.02226009715348482
[Epoch 10, Batch 200] loss: 0.02863994212821126
[Epoch 10, Batch 300] loss: 0.027931370893493294
**STATS for Epoch 10** : 
Average training loss: 0.0060
Average validation loss: 0.0610
Validation Accuracy: 0.9818
Overfitting: 0.0550
[Epoch 11, Batch 100] loss: 0.02291704423725605
[Epoch 11, Batch 200] loss: 0.02379072613781318
[Epoch 11, Batch 300] loss: 0.026797895831987262
**STATS for Epoch 11** : 
Average training loss: 0.0048
Average validation loss: 0.0534
Validation Accuracy: 0.9842
Overfitting: 0.0486
Best model saved at epoch 11 with validation loss: 0.0534
[Epoch 12, Batch 100] loss: 0.020232934198575095
[Epoch 12, Batch 200] loss: 0.01781962701585144
[Epoch 12, Batch 300] loss: 0.024856472671381198
**STATS for Epoch 12** : 
Average training loss: 0.0053
Average validation loss: 0.0578
Validation Accuracy: 0.9826
Overfitting: 0.0526
[Epoch 13, Batch 100] loss: 0.018000036583980545
[Epoch 13, Batch 200] loss: 0.01954700540052727
[Epoch 13, Batch 300] loss: 0.01936236661160365
**STATS for Epoch 13** : 
Average training loss: 0.0041
Average validation loss: 0.0532
Validation Accuracy: 0.9849
Overfitting: 0.0490
Best model saved at epoch 13 with validation loss: 0.0532
[Epoch 14, Batch 100] loss: 0.016465915159787983
[Epoch 14, Batch 200] loss: 0.019453320156317205
[Epoch 14, Batch 300] loss: 0.01807991204201244
**STATS for Epoch 14** : 
Average training loss: 0.0039
Average validation loss: 0.0588
Validation Accuracy: 0.9826
Overfitting: 0.0549
[Epoch 15, Batch 100] loss: 0.01614098043413833
[Epoch 15, Batch 200] loss: 0.014538159201620146
[Epoch 15, Batch 300] loss: 0.017308016003808005
**STATS for Epoch 15** : 
Average training loss: 0.0026
Average validation loss: 0.0485
Validation Accuracy: 0.9861
Overfitting: 0.0460
Best model saved at epoch 15 with validation loss: 0.0485
[Epoch 16, Batch 100] loss: 0.014643238256685436
[Epoch 16, Batch 200] loss: 0.012360655629308895
[Epoch 16, Batch 300] loss: 0.01907203622860834
**STATS for Epoch 16** : 
Average training loss: 0.0027
Average validation loss: 0.0509
Validation Accuracy: 0.9857
Overfitting: 0.0482
[Epoch 17, Batch 100] loss: 0.010392236899933778
[Epoch 17, Batch 200] loss: 0.01329776119091548
[Epoch 17, Batch 300] loss: 0.00925244211597601
**STATS for Epoch 17** : 
Average training loss: 0.0033
Average validation loss: 0.0564
Validation Accuracy: 0.9860
Overfitting: 0.0531
[Epoch 18, Batch 100] loss: 0.010173014857282397
[Epoch 18, Batch 200] loss: 0.013543912233726587
[Epoch 18, Batch 300] loss: 0.010865705537144095
**STATS for Epoch 18** : 
Average training loss: 0.0024
Average validation loss: 0.0624
Validation Accuracy: 0.9835
Overfitting: 0.0600
[Epoch 19, Batch 100] loss: 0.009581522821681574
[Epoch 19, Batch 200] loss: 0.012108435106638353
[Epoch 19, Batch 300] loss: 0.012201078375801444
**STATS for Epoch 19** : 
Average training loss: 0.0022
Average validation loss: 0.0610
Validation Accuracy: 0.9836
Overfitting: 0.0588
[Epoch 20, Batch 100] loss: 0.007520657041604864
[Epoch 20, Batch 200] loss: 0.009511156519874931
[Epoch 20, Batch 300] loss: 0.010729440313880331
**STATS for Epoch 20** : 
Average training loss: 0.0023
Average validation loss: 0.0541
Validation Accuracy: 0.9862
Overfitting: 0.0518
[Epoch 21, Batch 100] loss: 0.0071475357533199715
[Epoch 21, Batch 200] loss: 0.008263078820891678
[Epoch 21, Batch 300] loss: 0.009493317967571784
**STATS for Epoch 21** : 
Average training loss: 0.0017
Average validation loss: 0.0561
Validation Accuracy: 0.9853
Overfitting: 0.0544
[Epoch 22, Batch 100] loss: 0.007431684857583605
[Epoch 22, Batch 200] loss: 0.007627433711895719
[Epoch 22, Batch 300] loss: 0.006884638432820793
**STATS for Epoch 22** : 
Average training loss: 0.0015
Average validation loss: 0.0612
Validation Accuracy: 0.9863
Overfitting: 0.0597
[Epoch 23, Batch 100] loss: 0.005945943341648672
[Epoch 23, Batch 200] loss: 0.006374916005588602
[Epoch 23, Batch 300] loss: 0.00699028762493981
**STATS for Epoch 23** : 
Average training loss: 0.0014
Average validation loss: 0.0553
Validation Accuracy: 0.9862
Overfitting: 0.0539
[Epoch 24, Batch 100] loss: 0.0044669272371538685
[Epoch 24, Batch 200] loss: 0.0047401595793053275
[Epoch 24, Batch 300] loss: 0.007370445290725911
**STATS for Epoch 24** : 
Average training loss: 0.0015
Average validation loss: 0.0589
Validation Accuracy: 0.9864
Overfitting: 0.0575
Fold 2 validation loss: 0.0589
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.182919739484787
[Epoch 1, Batch 200] loss: 0.5634163366258145
[Epoch 1, Batch 300] loss: 0.2854858462512493
**STATS for Epoch 1** : 
Average training loss: 0.0446
Average validation loss: 0.1875
Validation Accuracy: 0.9450
Overfitting: 0.1428
Best model saved at epoch 1 with validation loss: 0.1875
[Epoch 2, Batch 100] loss: 0.17759362921118738
[Epoch 2, Batch 200] loss: 0.13990197829902173
[Epoch 2, Batch 300] loss: 0.11778945818543435
**STATS for Epoch 2** : 
Average training loss: 0.0217
Average validation loss: 0.1012
Validation Accuracy: 0.9691
Overfitting: 0.0795
Best model saved at epoch 2 with validation loss: 0.1012
[Epoch 3, Batch 100] loss: 0.09726548550650477
[Epoch 3, Batch 200] loss: 0.0822136540338397
[Epoch 3, Batch 300] loss: 0.08778325609862804
**STATS for Epoch 3** : 
Average training loss: 0.0170
Average validation loss: 0.0841
Validation Accuracy: 0.9744
Overfitting: 0.0672
Best model saved at epoch 3 with validation loss: 0.0841
[Epoch 4, Batch 100] loss: 0.06923683495260775
[Epoch 4, Batch 200] loss: 0.07026908941566944
[Epoch 4, Batch 300] loss: 0.0688779803737998
**STATS for Epoch 4** : 
Average training loss: 0.0140
Average validation loss: 0.0884
Validation Accuracy: 0.9723
Overfitting: 0.0743
[Epoch 5, Batch 100] loss: 0.06233021916821599
[Epoch 5, Batch 200] loss: 0.06403501213062554
[Epoch 5, Batch 300] loss: 0.05571420873515308
**STATS for Epoch 5** : 
Average training loss: 0.0108
Average validation loss: 0.0642
Validation Accuracy: 0.9813
Overfitting: 0.0533
Best model saved at epoch 5 with validation loss: 0.0642
[Epoch 6, Batch 100] loss: 0.05097926973365247
[Epoch 6, Batch 200] loss: 0.04248401202727109
[Epoch 6, Batch 300] loss: 0.04852158433757722
**STATS for Epoch 6** : 
Average training loss: 0.0099
Average validation loss: 0.0594
Validation Accuracy: 0.9811
Overfitting: 0.0495
Best model saved at epoch 6 with validation loss: 0.0594
[Epoch 7, Batch 100] loss: 0.03806696671526879
[Epoch 7, Batch 200] loss: 0.042395136677660046
[Epoch 7, Batch 300] loss: 0.0450746630714275
**STATS for Epoch 7** : 
Average training loss: 0.0083
Average validation loss: 0.0593
Validation Accuracy: 0.9809
Overfitting: 0.0510
Best model saved at epoch 7 with validation loss: 0.0593
[Epoch 8, Batch 100] loss: 0.03556181111838669
[Epoch 8, Batch 200] loss: 0.037691763755865394
[Epoch 8, Batch 300] loss: 0.03195478122215718
**STATS for Epoch 8** : 
Average training loss: 0.0078
Average validation loss: 0.0537
Validation Accuracy: 0.9843
Overfitting: 0.0459
Best model saved at epoch 8 with validation loss: 0.0537
[Epoch 9, Batch 100] loss: 0.032177331522107125
[Epoch 9, Batch 200] loss: 0.03195755427470431
[Epoch 9, Batch 300] loss: 0.03163777186069638
**STATS for Epoch 9** : 
Average training loss: 0.0064
Average validation loss: 0.0543
Validation Accuracy: 0.9838
Overfitting: 0.0479
[Epoch 10, Batch 100] loss: 0.02789213534677401
[Epoch 10, Batch 200] loss: 0.02761387249920517
[Epoch 10, Batch 300] loss: 0.029770093976985663
**STATS for Epoch 10** : 
Average training loss: 0.0054
Average validation loss: 0.0552
Validation Accuracy: 0.9833
Overfitting: 0.0498
[Epoch 11, Batch 100] loss: 0.02333576750708744
[Epoch 11, Batch 200] loss: 0.024878812818787992
[Epoch 11, Batch 300] loss: 0.026330029072705655
**STATS for Epoch 11** : 
Average training loss: 0.0050
Average validation loss: 0.0475
Validation Accuracy: 0.9869
Overfitting: 0.0425
Best model saved at epoch 11 with validation loss: 0.0475
[Epoch 12, Batch 100] loss: 0.023587698579067364
[Epoch 12, Batch 200] loss: 0.021044706078246236
[Epoch 12, Batch 300] loss: 0.021023629658739083
**STATS for Epoch 12** : 
Average training loss: 0.0043
Average validation loss: 0.0488
Validation Accuracy: 0.9863
Overfitting: 0.0444
[Epoch 13, Batch 100] loss: 0.01571977087412961
[Epoch 13, Batch 200] loss: 0.01850827424961608
[Epoch 13, Batch 300] loss: 0.022343842566479
**STATS for Epoch 13** : 
Average training loss: 0.0038
Average validation loss: 0.0520
Validation Accuracy: 0.9854
Overfitting: 0.0482
[Epoch 14, Batch 100] loss: 0.017315194678958507
[Epoch 14, Batch 200] loss: 0.013786952742375434
[Epoch 14, Batch 300] loss: 0.019628392870072276
**STATS for Epoch 14** : 
Average training loss: 0.0038
Average validation loss: 0.0521
Validation Accuracy: 0.9853
Overfitting: 0.0482
[Epoch 15, Batch 100] loss: 0.01375754611537559
[Epoch 15, Batch 200] loss: 0.014911135460133665
[Epoch 15, Batch 300] loss: 0.014105414535151795
**STATS for Epoch 15** : 
Average training loss: 0.0028
Average validation loss: 0.0572
Validation Accuracy: 0.9836
Overfitting: 0.0543
[Epoch 16, Batch 100] loss: 0.012777447870466857
[Epoch 16, Batch 200] loss: 0.018667238134657965
[Epoch 16, Batch 300] loss: 0.013598353230627254
**STATS for Epoch 16** : 
Average training loss: 0.0028
Average validation loss: 0.0489
Validation Accuracy: 0.9872
Overfitting: 0.0462
[Epoch 17, Batch 100] loss: 0.009629181291093119
[Epoch 17, Batch 200] loss: 0.014631472759647294
[Epoch 17, Batch 300] loss: 0.01223106859368272
**STATS for Epoch 17** : 
Average training loss: 0.0023
Average validation loss: 0.0479
Validation Accuracy: 0.9871
Overfitting: 0.0455
[Epoch 18, Batch 100] loss: 0.008282163194380701
[Epoch 18, Batch 200] loss: 0.012513970212021377
[Epoch 18, Batch 300] loss: 0.010768898326787166
**STATS for Epoch 18** : 
Average training loss: 0.0022
Average validation loss: 0.0512
Validation Accuracy: 0.9876
Overfitting: 0.0490
[Epoch 19, Batch 100] loss: 0.006923418915248476
[Epoch 19, Batch 200] loss: 0.008446010019397363
[Epoch 19, Batch 300] loss: 0.00959126259171171
**STATS for Epoch 19** : 
Average training loss: 0.0020
Average validation loss: 0.0500
Validation Accuracy: 0.9874
Overfitting: 0.0480
[Epoch 20, Batch 100] loss: 0.008690039478824473
[Epoch 20, Batch 200] loss: 0.010487232488085283
[Epoch 20, Batch 300] loss: 0.007039520247781183
**STATS for Epoch 20** : 
Average training loss: 0.0012
Average validation loss: 0.0495
Validation Accuracy: 0.9872
Overfitting: 0.0483
[Epoch 21, Batch 100] loss: 0.005288411535439082
[Epoch 21, Batch 200] loss: 0.0062754971909453165
[Epoch 21, Batch 300] loss: 0.0062029036247986365
**STATS for Epoch 21** : 
Average training loss: 0.0016
Average validation loss: 0.0540
Validation Accuracy: 0.9865
Overfitting: 0.0524
[Epoch 22, Batch 100] loss: 0.006844665626849746
[Epoch 22, Batch 200] loss: 0.008462881509331055
[Epoch 22, Batch 300] loss: 0.006452016358962282
**STATS for Epoch 22** : 
Average training loss: 0.0015
Average validation loss: 0.0522
Validation Accuracy: 0.9873
Overfitting: 0.0507
[Epoch 23, Batch 100] loss: 0.0032969206505003967
[Epoch 23, Batch 200] loss: 0.005552010101018823
[Epoch 23, Batch 300] loss: 0.0074698328752128874
**STATS for Epoch 23** : 
Average training loss: 0.0013
Average validation loss: 0.0538
Validation Accuracy: 0.9871
Overfitting: 0.0525
[Epoch 24, Batch 100] loss: 0.005227013409021311
[Epoch 24, Batch 200] loss: 0.0040205747578875165
[Epoch 24, Batch 300] loss: 0.004290045586894848
**STATS for Epoch 24** : 
Average training loss: 0.0011
Average validation loss: 0.0562
Validation Accuracy: 0.9870
Overfitting: 0.0551
Fold 3 validation loss: 0.0562
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2183999931812286
[Epoch 1, Batch 200] loss: 0.6949835956096649
[Epoch 1, Batch 300] loss: 0.2876235916465521
**STATS for Epoch 1** : 
Average training loss: 0.0391
Average validation loss: 0.1729
Validation Accuracy: 0.9454
Overfitting: 0.1338
Best model saved at epoch 1 with validation loss: 0.1729
[Epoch 2, Batch 100] loss: 0.17202366281300782
[Epoch 2, Batch 200] loss: 0.14508865498006343
[Epoch 2, Batch 300] loss: 0.1364096688106656
**STATS for Epoch 2** : 
Average training loss: 0.0226
Average validation loss: 0.1048
Validation Accuracy: 0.9674
Overfitting: 0.0822
Best model saved at epoch 2 with validation loss: 0.1048
[Epoch 3, Batch 100] loss: 0.10616528898477555
[Epoch 3, Batch 200] loss: 0.09080405116081237
[Epoch 3, Batch 300] loss: 0.09900646375492216
**STATS for Epoch 3** : 
Average training loss: 0.0169
Average validation loss: 0.0957
Validation Accuracy: 0.9699
Overfitting: 0.0788
Best model saved at epoch 3 with validation loss: 0.0957
[Epoch 4, Batch 100] loss: 0.07635992217808962
[Epoch 4, Batch 200] loss: 0.07953561544418335
[Epoch 4, Batch 300] loss: 0.07148516817949713
**STATS for Epoch 4** : 
Average training loss: 0.0138
Average validation loss: 0.0644
Validation Accuracy: 0.9805
Overfitting: 0.0506
Best model saved at epoch 4 with validation loss: 0.0644
[Epoch 5, Batch 100] loss: 0.06745559644885361
[Epoch 5, Batch 200] loss: 0.061261262465268376
[Epoch 5, Batch 300] loss: 0.0642596872150898
**STATS for Epoch 5** : 
Average training loss: 0.0117
Average validation loss: 0.0623
Validation Accuracy: 0.9809
Overfitting: 0.0505
Best model saved at epoch 5 with validation loss: 0.0623
[Epoch 6, Batch 100] loss: 0.058124597147107125
[Epoch 6, Batch 200] loss: 0.05238354228902608
[Epoch 6, Batch 300] loss: 0.05657285465393216
**STATS for Epoch 6** : 
Average training loss: 0.0101
Average validation loss: 0.0578
Validation Accuracy: 0.9819
Overfitting: 0.0478
Best model saved at epoch 6 with validation loss: 0.0578
[Epoch 7, Batch 100] loss: 0.04665462945587933
[Epoch 7, Batch 200] loss: 0.043624410573393106
[Epoch 7, Batch 300] loss: 0.04486440725624561
**STATS for Epoch 7** : 
Average training loss: 0.0101
Average validation loss: 0.0513
Validation Accuracy: 0.9833
Overfitting: 0.0412
Best model saved at epoch 7 with validation loss: 0.0513
[Epoch 8, Batch 100] loss: 0.04041060677263886
[Epoch 8, Batch 200] loss: 0.03602835162077099
[Epoch 8, Batch 300] loss: 0.04287144511938095
**STATS for Epoch 8** : 
Average training loss: 0.0086
Average validation loss: 0.0521
Validation Accuracy: 0.9842
Overfitting: 0.0435
[Epoch 9, Batch 100] loss: 0.030934003298170865
[Epoch 9, Batch 200] loss: 0.03553553747478873
[Epoch 9, Batch 300] loss: 0.04293144552502781
**STATS for Epoch 9** : 
Average training loss: 0.0063
Average validation loss: 0.0469
Validation Accuracy: 0.9855
Overfitting: 0.0406
Best model saved at epoch 9 with validation loss: 0.0469
[Epoch 10, Batch 100] loss: 0.029239261008333416
[Epoch 10, Batch 200] loss: 0.030510144080035387
[Epoch 10, Batch 300] loss: 0.02992041123099625
**STATS for Epoch 10** : 
Average training loss: 0.0069
Average validation loss: 0.0489
Validation Accuracy: 0.9846
Overfitting: 0.0420
[Epoch 11, Batch 100] loss: 0.030889564673416317
[Epoch 11, Batch 200] loss: 0.029262603279203176
[Epoch 11, Batch 300] loss: 0.029710940236691387
**STATS for Epoch 11** : 
Average training loss: 0.0050
Average validation loss: 0.0543
Validation Accuracy: 0.9831
Overfitting: 0.0493
[Epoch 12, Batch 100] loss: 0.02173925171722658
[Epoch 12, Batch 200] loss: 0.02644643216743134
[Epoch 12, Batch 300] loss: 0.025387051719008014
**STATS for Epoch 12** : 
Average training loss: 0.0057
Average validation loss: 0.0476
Validation Accuracy: 0.9854
Overfitting: 0.0419
[Epoch 13, Batch 100] loss: 0.01782965787919238
[Epoch 13, Batch 200] loss: 0.02583508753217757
[Epoch 13, Batch 300] loss: 0.024926101331366225
**STATS for Epoch 13** : 
Average training loss: 0.0042
Average validation loss: 0.0484
Validation Accuracy: 0.9847
Overfitting: 0.0442
[Epoch 14, Batch 100] loss: 0.0180393342388561
[Epoch 14, Batch 200] loss: 0.0256968692864757
[Epoch 14, Batch 300] loss: 0.018773709306260572
**STATS for Epoch 14** : 
Average training loss: 0.0047
Average validation loss: 0.0496
Validation Accuracy: 0.9857
Overfitting: 0.0449
[Epoch 15, Batch 100] loss: 0.017527966992929578
[Epoch 15, Batch 200] loss: 0.016396520463749766
[Epoch 15, Batch 300] loss: 0.020159358835953753
**STATS for Epoch 15** : 
Average training loss: 0.0042
Average validation loss: 0.0497
Validation Accuracy: 0.9839
Overfitting: 0.0455
[Epoch 16, Batch 100] loss: 0.018164654010906816
[Epoch 16, Batch 200] loss: 0.014184236354194581
[Epoch 16, Batch 300] loss: 0.01736511630588211
**STATS for Epoch 16** : 
Average training loss: 0.0033
Average validation loss: 0.0412
Validation Accuracy: 0.9881
Overfitting: 0.0379
Best model saved at epoch 16 with validation loss: 0.0412
[Epoch 17, Batch 100] loss: 0.012642359319142997
[Epoch 17, Batch 200] loss: 0.013498744965763762
[Epoch 17, Batch 300] loss: 0.012685590762412175
**STATS for Epoch 17** : 
Average training loss: 0.0033
Average validation loss: 0.0459
Validation Accuracy: 0.9867
Overfitting: 0.0426
[Epoch 18, Batch 100] loss: 0.014306684490293264
[Epoch 18, Batch 200] loss: 0.013214251055032947
[Epoch 18, Batch 300] loss: 0.014518914133077487
**STATS for Epoch 18** : 
Average training loss: 0.0025
Average validation loss: 0.0447
Validation Accuracy: 0.9879
Overfitting: 0.0422
[Epoch 19, Batch 100] loss: 0.010514973202953115
[Epoch 19, Batch 200] loss: 0.011487915271427483
[Epoch 19, Batch 300] loss: 0.012642490117577836
**STATS for Epoch 19** : 
Average training loss: 0.0026
Average validation loss: 0.0481
Validation Accuracy: 0.9866
Overfitting: 0.0454
[Epoch 20, Batch 100] loss: 0.008102566313464194
[Epoch 20, Batch 200] loss: 0.009561291912978049
[Epoch 20, Batch 300] loss: 0.008583751836413285
**STATS for Epoch 20** : 
Average training loss: 0.0020
Average validation loss: 0.0560
Validation Accuracy: 0.9854
Overfitting: 0.0540
[Epoch 21, Batch 100] loss: 0.007560727853851859
[Epoch 21, Batch 200] loss: 0.008190764648024923
[Epoch 21, Batch 300] loss: 0.009779285725089721
**STATS for Epoch 21** : 
Average training loss: 0.0020
Average validation loss: 0.0499
Validation Accuracy: 0.9874
Overfitting: 0.0478
[Epoch 22, Batch 100] loss: 0.005914810613030568
[Epoch 22, Batch 200] loss: 0.011413999579381197
[Epoch 22, Batch 300] loss: 0.007414038055285346
**STATS for Epoch 22** : 
Average training loss: 0.0016
Average validation loss: 0.0479
Validation Accuracy: 0.9872
Overfitting: 0.0463
[Epoch 23, Batch 100] loss: 0.006343867998511996
[Epoch 23, Batch 200] loss: 0.006823941564944107
[Epoch 23, Batch 300] loss: 0.006228167549124919
**STATS for Epoch 23** : 
Average training loss: 0.0025
Average validation loss: 0.0510
Validation Accuracy: 0.9870
Overfitting: 0.0485
[Epoch 24, Batch 100] loss: 0.006734826220199466
[Epoch 24, Batch 200] loss: 0.00570521411311347
[Epoch 24, Batch 300] loss: 0.00854021201521391
**STATS for Epoch 24** : 
Average training loss: 0.0015
Average validation loss: 0.0472
Validation Accuracy: 0.9881
Overfitting: 0.0457
Fold 4 validation loss: 0.0472
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.113513879776001
[Epoch 1, Batch 200] loss: 0.5451477167010307
[Epoch 1, Batch 300] loss: 0.2679171735048294
**STATS for Epoch 1** : 
Average training loss: 0.0404
Average validation loss: 0.1906
Validation Accuracy: 0.9439
Overfitting: 0.1502
Best model saved at epoch 1 with validation loss: 0.1906
[Epoch 2, Batch 100] loss: 0.1683846951276064
[Epoch 2, Batch 200] loss: 0.13991325348615646
[Epoch 2, Batch 300] loss: 0.12281082697212696
**STATS for Epoch 2** : 
Average training loss: 0.0218
Average validation loss: 0.1052
Validation Accuracy: 0.9700
Overfitting: 0.0834
Best model saved at epoch 2 with validation loss: 0.1052
[Epoch 3, Batch 100] loss: 0.10479146759957075
[Epoch 3, Batch 200] loss: 0.08375432956963777
[Epoch 3, Batch 300] loss: 0.0852677301876247
**STATS for Epoch 3** : 
Average training loss: 0.0166
Average validation loss: 0.0951
Validation Accuracy: 0.9694
Overfitting: 0.0786
Best model saved at epoch 3 with validation loss: 0.0951
[Epoch 4, Batch 100] loss: 0.07243029524572193
[Epoch 4, Batch 200] loss: 0.07145214274525642
[Epoch 4, Batch 300] loss: 0.06236894407309592
**STATS for Epoch 4** : 
Average training loss: 0.0145
Average validation loss: 0.0727
Validation Accuracy: 0.9765
Overfitting: 0.0582
Best model saved at epoch 4 with validation loss: 0.0727
[Epoch 5, Batch 100] loss: 0.05355572263710201
[Epoch 5, Batch 200] loss: 0.06360312147065997
[Epoch 5, Batch 300] loss: 0.05443607669323683
**STATS for Epoch 5** : 
Average training loss: 0.0125
Average validation loss: 0.0555
Validation Accuracy: 0.9827
Overfitting: 0.0430
Best model saved at epoch 5 with validation loss: 0.0555
[Epoch 6, Batch 100] loss: 0.04635716119315475
[Epoch 6, Batch 200] loss: 0.05444365531206131
[Epoch 6, Batch 300] loss: 0.047786168111488225
**STATS for Epoch 6** : 
Average training loss: 0.0095
Average validation loss: 0.0581
Validation Accuracy: 0.9808
Overfitting: 0.0486
[Epoch 7, Batch 100] loss: 0.03327287745662034
[Epoch 7, Batch 200] loss: 0.04017541515175253
[Epoch 7, Batch 300] loss: 0.047153687253594395
**STATS for Epoch 7** : 
Average training loss: 0.0079
Average validation loss: 0.0504
Validation Accuracy: 0.9836
Overfitting: 0.0425
Best model saved at epoch 7 with validation loss: 0.0504
[Epoch 8, Batch 100] loss: 0.03406348703196272
[Epoch 8, Batch 200] loss: 0.03526081020478159
[Epoch 8, Batch 300] loss: 0.03816181167028845
**STATS for Epoch 8** : 
Average training loss: 0.0072
Average validation loss: 0.0553
Validation Accuracy: 0.9824
Overfitting: 0.0481
[Epoch 9, Batch 100] loss: 0.032710469206795094
[Epoch 9, Batch 200] loss: 0.03152895322069526
[Epoch 9, Batch 300] loss: 0.03505525522166863
**STATS for Epoch 9** : 
Average training loss: 0.0070
Average validation loss: 0.0429
Validation Accuracy: 0.9871
Overfitting: 0.0359
Best model saved at epoch 9 with validation loss: 0.0429
[Epoch 10, Batch 100] loss: 0.03018241309793666
[Epoch 10, Batch 200] loss: 0.028544751771260053
[Epoch 10, Batch 300] loss: 0.030854140755254774
**STATS for Epoch 10** : 
Average training loss: 0.0047
Average validation loss: 0.0449
Validation Accuracy: 0.9868
Overfitting: 0.0402
[Epoch 11, Batch 100] loss: 0.02554096545325592
[Epoch 11, Batch 200] loss: 0.02231132648186758
[Epoch 11, Batch 300] loss: 0.026889302793424576
**STATS for Epoch 11** : 
Average training loss: 0.0056
Average validation loss: 0.0452
Validation Accuracy: 0.9865
Overfitting: 0.0396
[Epoch 12, Batch 100] loss: 0.02126314091612585
[Epoch 12, Batch 200] loss: 0.02468076646211557
[Epoch 12, Batch 300] loss: 0.027192803857615216
**STATS for Epoch 12** : 
Average training loss: 0.0048
Average validation loss: 0.0451
Validation Accuracy: 0.9868
Overfitting: 0.0402
[Epoch 13, Batch 100] loss: 0.021024009218672292
[Epoch 13, Batch 200] loss: 0.024331197591964157
[Epoch 13, Batch 300] loss: 0.019227484022267163
**STATS for Epoch 13** : 
Average training loss: 0.0039
Average validation loss: 0.0464
Validation Accuracy: 0.9874
Overfitting: 0.0425
[Epoch 14, Batch 100] loss: 0.017925111445365474
[Epoch 14, Batch 200] loss: 0.016347415811615064
[Epoch 14, Batch 300] loss: 0.021925092755118385
**STATS for Epoch 14** : 
Average training loss: 0.0039
Average validation loss: 0.0427
Validation Accuracy: 0.9879
Overfitting: 0.0387
Best model saved at epoch 14 with validation loss: 0.0427
[Epoch 15, Batch 100] loss: 0.017160488180816173
[Epoch 15, Batch 200] loss: 0.01856585527420975
[Epoch 15, Batch 300] loss: 0.01653652605949901
**STATS for Epoch 15** : 
Average training loss: 0.0032
Average validation loss: 0.0396
Validation Accuracy: 0.9883
Overfitting: 0.0364
Best model saved at epoch 15 with validation loss: 0.0396
[Epoch 16, Batch 100] loss: 0.01630922148586251
[Epoch 16, Batch 200] loss: 0.015930026575224476
[Epoch 16, Batch 300] loss: 0.01587244997237576
**STATS for Epoch 16** : 
Average training loss: 0.0029
Average validation loss: 0.0451
Validation Accuracy: 0.9883
Overfitting: 0.0422
[Epoch 17, Batch 100] loss: 0.015117752425721847
[Epoch 17, Batch 200] loss: 0.013666861248202622
[Epoch 17, Batch 300] loss: 0.012896225507138297
**STATS for Epoch 17** : 
Average training loss: 0.0030
Average validation loss: 0.0403
Validation Accuracy: 0.9882
Overfitting: 0.0373
[Epoch 18, Batch 100] loss: 0.011423914351325948
[Epoch 18, Batch 200] loss: 0.011198600164498203
[Epoch 18, Batch 300] loss: 0.011696688321244438
**STATS for Epoch 18** : 
Average training loss: 0.0037
Average validation loss: 0.0384
Validation Accuracy: 0.9896
Overfitting: 0.0347
Best model saved at epoch 18 with validation loss: 0.0384
[Epoch 19, Batch 100] loss: 0.010606908539775759
[Epoch 19, Batch 200] loss: 0.011388814883830492
[Epoch 19, Batch 300] loss: 0.015314931916072964
**STATS for Epoch 19** : 
Average training loss: 0.0023
Average validation loss: 0.0391
Validation Accuracy: 0.9894
Overfitting: 0.0368
[Epoch 20, Batch 100] loss: 0.009795450341771357
[Epoch 20, Batch 200] loss: 0.011387143001775258
[Epoch 20, Batch 300] loss: 0.009807513221167028
**STATS for Epoch 20** : 
Average training loss: 0.0023
Average validation loss: 0.0385
Validation Accuracy: 0.9893
Overfitting: 0.0362
[Epoch 21, Batch 100] loss: 0.00663494650652865
[Epoch 21, Batch 200] loss: 0.009421346855669982
[Epoch 21, Batch 300] loss: 0.010752355900185648
**STATS for Epoch 21** : 
Average training loss: 0.0013
Average validation loss: 0.0410
Validation Accuracy: 0.9898
Overfitting: 0.0397
[Epoch 22, Batch 100] loss: 0.00791606453305576
[Epoch 22, Batch 200] loss: 0.009373531968158204
[Epoch 22, Batch 300] loss: 0.008626263133919565
**STATS for Epoch 22** : 
Average training loss: 0.0017
Average validation loss: 0.0410
Validation Accuracy: 0.9895
Overfitting: 0.0393
[Epoch 23, Batch 100] loss: 0.006107955024199327
[Epoch 23, Batch 200] loss: 0.008654718180623603
[Epoch 23, Batch 300] loss: 0.008705455869494472
**STATS for Epoch 23** : 
Average training loss: 0.0020
Average validation loss: 0.0466
Validation Accuracy: 0.9883
Overfitting: 0.0446
[Epoch 24, Batch 100] loss: 0.005532326340908184
[Epoch 24, Batch 200] loss: 0.013622103281959426
[Epoch 24, Batch 300] loss: 0.006284033812698908
**STATS for Epoch 24** : 
Average training loss: 0.0015
Average validation loss: 0.0430
Validation Accuracy: 0.9889
Overfitting: 0.0415
Fold 5 validation loss: 0.0430
Mean validation loss across all folds for Trial 18 is 0.0503 with trial config:  l1: 256, l2: 64, lr: 0.00490214514230691, batch_size: 128
[I 2024-12-10 09:19:27,884] Trial 17 finished with value: 0.050323023780266395 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.00490214514230691, 'batch_size': 128}. Best is trial 4 with value: 0.045411968038914834.

Selected Hyperparameters for Trial 19:
  l1: 256, l2: 64, lr: 0.002874012510496939, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.255440022945404
[Epoch 1, Batch 200] loss: 1.2372416374087334
[Epoch 1, Batch 300] loss: 0.5249397622048855
[Epoch 1, Batch 400] loss: 0.3598305045813322
[Epoch 1, Batch 500] loss: 0.2924527111649513
[Epoch 1, Batch 600] loss: 0.2505865153670311
[Epoch 1, Batch 700] loss: 0.20005558218806982
[Epoch 1, Batch 800] loss: 0.19807682577520608
[Epoch 1, Batch 900] loss: 0.15588382882531732
[Epoch 1, Batch 1000] loss: 0.1390667715575546
[Epoch 1, Batch 1100] loss: 0.13895212032832205
[Epoch 1, Batch 1200] loss: 0.1211148772900924
[Epoch 1, Batch 1300] loss: 0.11217840299475938
[Epoch 1, Batch 1400] loss: 0.11940859538502992
[Epoch 1, Batch 1500] loss: 0.10497262581251561
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1135
Validation Accuracy: 0.9639
Overfitting: 0.1135
Best model saved at epoch 1 with validation loss: 0.1135
[Epoch 2, Batch 100] loss: 0.09579584781080484
[Epoch 2, Batch 200] loss: 0.09175272524356842
[Epoch 2, Batch 300] loss: 0.08345848709344864
[Epoch 2, Batch 400] loss: 0.09185631537344306
[Epoch 2, Batch 500] loss: 0.09769620889797807
[Epoch 2, Batch 600] loss: 0.08684063180349767
[Epoch 2, Batch 700] loss: 0.08657995591405779
[Epoch 2, Batch 800] loss: 0.08198643188457937
[Epoch 2, Batch 900] loss: 0.08044816620647907
[Epoch 2, Batch 1000] loss: 0.06812236131168901
[Epoch 2, Batch 1100] loss: 0.07879332491196692
[Epoch 2, Batch 1200] loss: 0.08920244624838233
[Epoch 2, Batch 1300] loss: 0.05904562361305579
[Epoch 2, Batch 1400] loss: 0.07410140469204635
[Epoch 2, Batch 1500] loss: 0.06417577427928337
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0674
Validation Accuracy: 0.9785
Overfitting: 0.0674
Best model saved at epoch 2 with validation loss: 0.0674
[Epoch 3, Batch 100] loss: 0.05874533135793172
[Epoch 3, Batch 200] loss: 0.05424988761893473
[Epoch 3, Batch 300] loss: 0.05834948386996985
[Epoch 3, Batch 400] loss: 0.06088831709814258
[Epoch 3, Batch 500] loss: 0.06657064357888885
[Epoch 3, Batch 600] loss: 0.0489545603125589
[Epoch 3, Batch 700] loss: 0.0593760531040607
[Epoch 3, Batch 800] loss: 0.05723431157064624
[Epoch 3, Batch 900] loss: 0.06956362173426896
[Epoch 3, Batch 1000] loss: 0.04954306670115329
[Epoch 3, Batch 1100] loss: 0.07048149716574699
[Epoch 3, Batch 1200] loss: 0.056955461009638386
[Epoch 3, Batch 1300] loss: 0.05303873761906289
[Epoch 3, Batch 1400] loss: 0.0564554922201205
[Epoch 3, Batch 1500] loss: 0.04125340995960869
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9829
Overfitting: 0.0538
Best model saved at epoch 3 with validation loss: 0.0538
[Epoch 4, Batch 100] loss: 0.04389755643613171
[Epoch 4, Batch 200] loss: 0.041530572602059695
[Epoch 4, Batch 300] loss: 0.031482603949552865
[Epoch 4, Batch 400] loss: 0.049781138193793595
[Epoch 4, Batch 500] loss: 0.0489044573213323
[Epoch 4, Batch 600] loss: 0.03810241953120567
[Epoch 4, Batch 700] loss: 0.04903640822856687
[Epoch 4, Batch 800] loss: 0.038995908509532454
[Epoch 4, Batch 900] loss: 0.04351697813661303
[Epoch 4, Batch 1000] loss: 0.04987659331876784
[Epoch 4, Batch 1100] loss: 0.03927270605112426
[Epoch 4, Batch 1200] loss: 0.048048488481435926
[Epoch 4, Batch 1300] loss: 0.053277627818170005
[Epoch 4, Batch 1400] loss: 0.04041962033952586
[Epoch 4, Batch 1500] loss: 0.039553596693149305
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9833
Overfitting: 0.0534
Best model saved at epoch 4 with validation loss: 0.0534
[Epoch 5, Batch 100] loss: 0.028252338694292122
[Epoch 5, Batch 200] loss: 0.037350988933467305
[Epoch 5, Batch 300] loss: 0.02313366916088853
[Epoch 5, Batch 400] loss: 0.03193145390847349
[Epoch 5, Batch 500] loss: 0.02950712337566074
[Epoch 5, Batch 600] loss: 0.035695354971976484
[Epoch 5, Batch 700] loss: 0.036141410269483455
[Epoch 5, Batch 800] loss: 0.03728687178438122
[Epoch 5, Batch 900] loss: 0.04116961191088194
[Epoch 5, Batch 1000] loss: 0.04549409151950386
[Epoch 5, Batch 1100] loss: 0.024319517855910817
[Epoch 5, Batch 1200] loss: 0.03497639518114738
[Epoch 5, Batch 1300] loss: 0.04088099326181691
[Epoch 5, Batch 1400] loss: 0.029425217946409246
[Epoch 5, Batch 1500] loss: 0.03476270040933741
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9862
Overfitting: 0.0446
Best model saved at epoch 5 with validation loss: 0.0446
[Epoch 6, Batch 100] loss: 0.023334617028885986
[Epoch 6, Batch 200] loss: 0.025506814937398304
[Epoch 6, Batch 300] loss: 0.04026408315476147
[Epoch 6, Batch 400] loss: 0.030472753647190983
[Epoch 6, Batch 500] loss: 0.024616680182225535
[Epoch 6, Batch 600] loss: 0.02901642115903087
[Epoch 6, Batch 700] loss: 0.032963069066463506
[Epoch 6, Batch 800] loss: 0.028606042405008338
[Epoch 6, Batch 900] loss: 0.01551053617047728
[Epoch 6, Batch 1000] loss: 0.030789784174703527
[Epoch 6, Batch 1100] loss: 0.030628633801534307
[Epoch 6, Batch 1200] loss: 0.027990537936711916
[Epoch 6, Batch 1300] loss: 0.023407951496119496
[Epoch 6, Batch 1400] loss: 0.021602631621353795
[Epoch 6, Batch 1500] loss: 0.029371359377109912
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9858
Overfitting: 0.0468
[Epoch 7, Batch 100] loss: 0.016581442748138216
[Epoch 7, Batch 200] loss: 0.019043195470658247
[Epoch 7, Batch 300] loss: 0.0125296142471052
[Epoch 7, Batch 400] loss: 0.03120807213257649
[Epoch 7, Batch 500] loss: 0.022725917018833572
[Epoch 7, Batch 600] loss: 0.021354662270023254
[Epoch 7, Batch 700] loss: 0.02096640851596021
[Epoch 7, Batch 800] loss: 0.021321379874643755
[Epoch 7, Batch 900] loss: 0.02734048476224416
[Epoch 7, Batch 1000] loss: 0.021044236266316147
[Epoch 7, Batch 1100] loss: 0.027077397327047947
[Epoch 7, Batch 1200] loss: 0.020890591832794597
[Epoch 7, Batch 1300] loss: 0.028001982283603864
[Epoch 7, Batch 1400] loss: 0.030611822258579197
[Epoch 7, Batch 1500] loss: 0.030445878915925276
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9856
Overfitting: 0.0457
[Epoch 8, Batch 100] loss: 0.01346207772003254
[Epoch 8, Batch 200] loss: 0.02057975676114438
[Epoch 8, Batch 300] loss: 0.013238444068774698
[Epoch 8, Batch 400] loss: 0.016905168399789547
[Epoch 8, Batch 500] loss: 0.018636715520879078
[Epoch 8, Batch 600] loss: 0.02348422215116443
[Epoch 8, Batch 700] loss: 0.019696804174018326
[Epoch 8, Batch 800] loss: 0.02060292786285572
[Epoch 8, Batch 900] loss: 0.020063282232222264
[Epoch 8, Batch 1000] loss: 0.014713829201282351
[Epoch 8, Batch 1100] loss: 0.01782641970574332
[Epoch 8, Batch 1200] loss: 0.020979199678840814
[Epoch 8, Batch 1300] loss: 0.02805364445099258
[Epoch 8, Batch 1400] loss: 0.024064359004696598
[Epoch 8, Batch 1500] loss: 0.017783212541544344
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0390
Validation Accuracy: 0.9880
Overfitting: 0.0390
Best model saved at epoch 8 with validation loss: 0.0390
[Epoch 9, Batch 100] loss: 0.016084098622704913
[Epoch 9, Batch 200] loss: 0.009004642897925805
[Epoch 9, Batch 300] loss: 0.011294473686357378
[Epoch 9, Batch 400] loss: 0.00965204190921213
[Epoch 9, Batch 500] loss: 0.010757637902133865
[Epoch 9, Batch 600] loss: 0.014054909329533984
[Epoch 9, Batch 700] loss: 0.02392804907487516
[Epoch 9, Batch 800] loss: 0.013842615743196802
[Epoch 9, Batch 900] loss: 0.018628959829984523
[Epoch 9, Batch 1000] loss: 0.021044555534172105
[Epoch 9, Batch 1100] loss: 0.01979743852476531
[Epoch 9, Batch 1200] loss: 0.01655317055483465
[Epoch 9, Batch 1300] loss: 0.02527205481812416
[Epoch 9, Batch 1400] loss: 0.022928452665364602
[Epoch 9, Batch 1500] loss: 0.014551830870914273
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9868
Overfitting: 0.0430
[Epoch 10, Batch 100] loss: 0.008519070015281613
[Epoch 10, Batch 200] loss: 0.0082218699517216
[Epoch 10, Batch 300] loss: 0.00879623798202374
[Epoch 10, Batch 400] loss: 0.00643014411740296
[Epoch 10, Batch 500] loss: 0.017017901551444083
[Epoch 10, Batch 600] loss: 0.014121756877611915
[Epoch 10, Batch 700] loss: 0.022899520945429686
[Epoch 10, Batch 800] loss: 0.016416359023642146
[Epoch 10, Batch 900] loss: 0.014952827078232075
[Epoch 10, Batch 1000] loss: 0.01861488241178449
[Epoch 10, Batch 1100] loss: 0.01646572877652943
[Epoch 10, Batch 1200] loss: 0.015486781985964626
[Epoch 10, Batch 1300] loss: 0.01580173965798167
[Epoch 10, Batch 1400] loss: 0.010670389055158012
[Epoch 10, Batch 1500] loss: 0.014187194798323617
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9856
Overfitting: 0.0471
[Epoch 11, Batch 100] loss: 0.00995462429451436
[Epoch 11, Batch 200] loss: 0.007634485572507402
[Epoch 11, Batch 300] loss: 0.009777938086022004
[Epoch 11, Batch 400] loss: 0.007240718120719976
[Epoch 11, Batch 500] loss: 0.008920857791454182
[Epoch 11, Batch 600] loss: 0.0129077177482759
[Epoch 11, Batch 700] loss: 0.013069494945912084
[Epoch 11, Batch 800] loss: 0.007946656005533442
[Epoch 11, Batch 900] loss: 0.011983339773705666
[Epoch 11, Batch 1000] loss: 0.017731990002139354
[Epoch 11, Batch 1100] loss: 0.013315062710935308
[Epoch 11, Batch 1200] loss: 0.009022054788292735
[Epoch 11, Batch 1300] loss: 0.010748907737634
[Epoch 11, Batch 1400] loss: 0.015095602037454227
[Epoch 11, Batch 1500] loss: 0.010699463985529291
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9869
Overfitting: 0.0465
[Epoch 12, Batch 100] loss: 0.009827578999138496
[Epoch 12, Batch 200] loss: 0.008635046160070487
[Epoch 12, Batch 300] loss: 0.010510385174420663
[Epoch 12, Batch 400] loss: 0.007791726300165464
[Epoch 12, Batch 500] loss: 0.007828160472508899
[Epoch 12, Batch 600] loss: 0.009580615869917892
[Epoch 12, Batch 700] loss: 0.010266116303091622
[Epoch 12, Batch 800] loss: 0.009656803020197913
[Epoch 12, Batch 900] loss: 0.009402631532693703
[Epoch 12, Batch 1000] loss: 0.00903031688540068
[Epoch 12, Batch 1100] loss: 0.007820651469853602
[Epoch 12, Batch 1200] loss: 0.010242032754140382
[Epoch 12, Batch 1300] loss: 0.009363891307370977
[Epoch 12, Batch 1400] loss: 0.007394261743211245
[Epoch 12, Batch 1500] loss: 0.010625918976138564
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9882
Overfitting: 0.0484
[Epoch 13, Batch 100] loss: 0.008525485838763416
[Epoch 13, Batch 200] loss: 0.010038687023366038
[Epoch 13, Batch 300] loss: 0.008711946442417684
[Epoch 13, Batch 400] loss: 0.008032870739607461
[Epoch 13, Batch 500] loss: 0.007590112032430625
[Epoch 13, Batch 600] loss: 0.006804901746681935
[Epoch 13, Batch 700] loss: 0.0075142471522121924
[Epoch 13, Batch 800] loss: 0.011638028277920966
[Epoch 13, Batch 900] loss: 0.012519902130593437
[Epoch 13, Batch 1000] loss: 0.009515081768654454
[Epoch 13, Batch 1100] loss: 0.009112389351776074
[Epoch 13, Batch 1200] loss: 0.009670780064734572
[Epoch 13, Batch 1300] loss: 0.005981997616554508
[Epoch 13, Batch 1400] loss: 0.00542258779599706
[Epoch 13, Batch 1500] loss: 0.007047199855451254
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0454
Validation Accuracy: 0.9881
Overfitting: 0.0454
[Epoch 14, Batch 100] loss: 0.008649024388168981
[Epoch 14, Batch 200] loss: 0.007413793668024482
[Epoch 14, Batch 300] loss: 0.004237335016468933
[Epoch 14, Batch 400] loss: 0.008602555513562038
[Epoch 14, Batch 500] loss: 0.006068522565051353
[Epoch 14, Batch 600] loss: 0.0027766570965195568
[Epoch 14, Batch 700] loss: 0.006048832397891601
[Epoch 14, Batch 800] loss: 0.006223440531975939
[Epoch 14, Batch 900] loss: 0.006505688929905773
[Epoch 14, Batch 1000] loss: 0.005591423738796948
[Epoch 14, Batch 1100] loss: 0.007910286160263241
[Epoch 14, Batch 1200] loss: 0.008630276540829982
[Epoch 14, Batch 1300] loss: 0.00781774313617234
[Epoch 14, Batch 1400] loss: 0.007503450879401043
[Epoch 14, Batch 1500] loss: 0.012172510139371297
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0467
Validation Accuracy: 0.9878
Overfitting: 0.0467
[Epoch 15, Batch 100] loss: 0.0064949887797138214
[Epoch 15, Batch 200] loss: 0.004134837507112934
[Epoch 15, Batch 300] loss: 0.0034121990505605027
[Epoch 15, Batch 400] loss: 0.004176175311167754
[Epoch 15, Batch 500] loss: 0.009336996242082023
[Epoch 15, Batch 600] loss: 0.010224856245797583
[Epoch 15, Batch 700] loss: 0.0031203895326257225
[Epoch 15, Batch 800] loss: 0.005709412846242685
[Epoch 15, Batch 900] loss: 0.0072394799721632805
[Epoch 15, Batch 1000] loss: 0.009472088663619616
[Epoch 15, Batch 1100] loss: 0.01380503934105036
[Epoch 15, Batch 1200] loss: 0.010472255434392537
[Epoch 15, Batch 1300] loss: 0.006285969413970634
[Epoch 15, Batch 1400] loss: 0.006247810613355114
[Epoch 15, Batch 1500] loss: 0.0093683174969442
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0452
Validation Accuracy: 0.9889
Overfitting: 0.0452
[Epoch 16, Batch 100] loss: 0.0038492097906919296
[Epoch 16, Batch 200] loss: 0.004731072801646406
[Epoch 16, Batch 300] loss: 0.00538050228022712
[Epoch 16, Batch 400] loss: 0.003627675483303392
[Epoch 16, Batch 500] loss: 0.005756291125767348
[Epoch 16, Batch 600] loss: 0.0024081941572353573
[Epoch 16, Batch 700] loss: 0.0029390635085701435
[Epoch 16, Batch 800] loss: 0.002545810607994099
[Epoch 16, Batch 900] loss: 0.00381541130695382
[Epoch 16, Batch 1000] loss: 0.007660791225450794
[Epoch 16, Batch 1100] loss: 0.006430653957618233
[Epoch 16, Batch 1200] loss: 0.00826567038342091
[Epoch 16, Batch 1300] loss: 0.008816265306138575
[Epoch 16, Batch 1400] loss: 0.011207534756595123
[Epoch 16, Batch 1500] loss: 0.014624700698782363
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9859
Overfitting: 0.0513
[Epoch 17, Batch 100] loss: 0.004139311253704818
[Epoch 17, Batch 200] loss: 0.0021628004266767676
[Epoch 17, Batch 300] loss: 0.0014555701677755905
[Epoch 17, Batch 400] loss: 0.004380546370899765
[Epoch 17, Batch 500] loss: 0.0018793827386275551
[Epoch 17, Batch 600] loss: 0.006781220510565618
[Epoch 17, Batch 700] loss: 0.0072567884792329096
[Epoch 17, Batch 800] loss: 0.007450218676244731
[Epoch 17, Batch 900] loss: 0.00394231476960158
[Epoch 17, Batch 1000] loss: 0.003067394085321666
[Epoch 17, Batch 1100] loss: 0.0053265226169651216
[Epoch 17, Batch 1200] loss: 0.006618053211140023
[Epoch 17, Batch 1300] loss: 0.011469955590264362
[Epoch 17, Batch 1400] loss: 0.014592469211756907
[Epoch 17, Batch 1500] loss: 0.007347604778283312
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9873
Overfitting: 0.0528
[Epoch 18, Batch 100] loss: 0.004303397605870032
[Epoch 18, Batch 200] loss: 0.0032922653513298883
[Epoch 18, Batch 300] loss: 0.0028311893287207113
[Epoch 18, Batch 400] loss: 0.004031327603208865
[Epoch 18, Batch 500] loss: 0.005219575369849281
[Epoch 18, Batch 600] loss: 0.004871751877276438
[Epoch 18, Batch 700] loss: 0.011476852451792183
[Epoch 18, Batch 800] loss: 0.009799317925780997
[Epoch 18, Batch 900] loss: 0.011099757574193063
[Epoch 18, Batch 1000] loss: 0.004513837267709277
[Epoch 18, Batch 1100] loss: 0.0034910900338354623
[Epoch 18, Batch 1200] loss: 0.004910671240688771
[Epoch 18, Batch 1300] loss: 0.00325744163404579
[Epoch 18, Batch 1400] loss: 0.0053644111975768285
[Epoch 18, Batch 1500] loss: 0.012131100934493589
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0640
Validation Accuracy: 0.9854
Overfitting: 0.0640
[Epoch 19, Batch 100] loss: 0.003782140838302439
[Epoch 19, Batch 200] loss: 0.004616348522769726
[Epoch 19, Batch 300] loss: 0.0033410804921550153
[Epoch 19, Batch 400] loss: 0.0017318104868741101
[Epoch 19, Batch 500] loss: 0.0019859916508426067
[Epoch 19, Batch 600] loss: 0.0023485585624393934
[Epoch 19, Batch 700] loss: 0.0016197204822231016
[Epoch 19, Batch 800] loss: 0.0018141929310559134
[Epoch 19, Batch 900] loss: 0.001727947734886186
[Epoch 19, Batch 1000] loss: 0.0020667202146626095
[Epoch 19, Batch 1100] loss: 0.0019512106009557328
[Epoch 19, Batch 1200] loss: 0.004430425605204391
[Epoch 19, Batch 1300] loss: 0.00696286697145922
[Epoch 19, Batch 1400] loss: 0.007322989116332792
[Epoch 19, Batch 1500] loss: 0.009070329151059013
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9888
Overfitting: 0.0468
[Epoch 20, Batch 100] loss: 0.0017252887158770137
[Epoch 20, Batch 200] loss: 0.003970577427930948
[Epoch 20, Batch 300] loss: 0.0027608630815007017
[Epoch 20, Batch 400] loss: 0.0032148248428313765
[Epoch 20, Batch 500] loss: 0.002302779672183135
[Epoch 20, Batch 600] loss: 0.0037410690540923496
[Epoch 20, Batch 700] loss: 0.008427233405154767
[Epoch 20, Batch 800] loss: 0.004731393092524741
[Epoch 20, Batch 900] loss: 0.002918935558160456
[Epoch 20, Batch 1000] loss: 0.00533869593174245
[Epoch 20, Batch 1100] loss: 0.001024089748557344
[Epoch 20, Batch 1200] loss: 0.002862827732549249
[Epoch 20, Batch 1300] loss: 0.0031020166355665425
[Epoch 20, Batch 1400] loss: 0.001191357577361032
[Epoch 20, Batch 1500] loss: 0.001966843702582537
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0472
Validation Accuracy: 0.9898
Overfitting: 0.0472
[Epoch 21, Batch 100] loss: 0.0033844100678680888
[Epoch 21, Batch 200] loss: 0.001606289940949921
[Epoch 21, Batch 300] loss: 0.0014940540890484044
[Epoch 21, Batch 400] loss: 0.0012393678255592988
[Epoch 21, Batch 500] loss: 0.0008871734008516796
[Epoch 21, Batch 600] loss: 0.0026919747681790796
[Epoch 21, Batch 700] loss: 0.001780898768621455
[Epoch 21, Batch 800] loss: 0.0013292269175883575
[Epoch 21, Batch 900] loss: 0.0010740635745207783
[Epoch 21, Batch 1000] loss: 0.0009773977129316335
[Epoch 21, Batch 1100] loss: 0.0007250163271007181
[Epoch 21, Batch 1200] loss: 0.0032113004026861347
[Epoch 21, Batch 1300] loss: 0.0034020265786261915
[Epoch 21, Batch 1400] loss: 0.0006043564731044171
[Epoch 21, Batch 1500] loss: 0.001069095657347816
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0457
Validation Accuracy: 0.9898
Overfitting: 0.0457
[Epoch 22, Batch 100] loss: 0.0013403683401105582
[Epoch 22, Batch 200] loss: 0.0008449713234114142
[Epoch 22, Batch 300] loss: 0.0006026047017218161
[Epoch 22, Batch 400] loss: 0.003427855920920706
[Epoch 22, Batch 500] loss: 0.0009687607703503431
[Epoch 22, Batch 600] loss: 0.001200609879321064
[Epoch 22, Batch 700] loss: 0.0021709204003207104
[Epoch 22, Batch 800] loss: 0.0004921917188534053
[Epoch 22, Batch 900] loss: 0.0005166083789117693
[Epoch 22, Batch 1000] loss: 0.0007731295377109859
[Epoch 22, Batch 1100] loss: 0.0015425056851549356
[Epoch 22, Batch 1200] loss: 0.003939271359260488
[Epoch 22, Batch 1300] loss: 0.0019729320479439116
[Epoch 22, Batch 1400] loss: 0.001479304244817854
[Epoch 22, Batch 1500] loss: 0.0011111264634834583
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0444
Validation Accuracy: 0.9900
Overfitting: 0.0444
[Epoch 23, Batch 100] loss: 0.0005180366111164858
[Epoch 23, Batch 200] loss: 0.0004078940951671939
[Epoch 23, Batch 300] loss: 0.0003146063557145595
[Epoch 23, Batch 400] loss: 0.0005686958206044323
[Epoch 23, Batch 500] loss: 0.0009349220818972981
[Epoch 23, Batch 600] loss: 0.002509583115484304
[Epoch 23, Batch 700] loss: 0.000642495998118875
[Epoch 23, Batch 800] loss: 0.00040391337955298924
[Epoch 23, Batch 900] loss: 0.00035424687936597366
[Epoch 23, Batch 1000] loss: 0.0005612598652118095
[Epoch 23, Batch 1100] loss: 0.0016973840917534843
[Epoch 23, Batch 1200] loss: 0.00041457147199054135
[Epoch 23, Batch 1300] loss: 0.0007193880793110452
[Epoch 23, Batch 1400] loss: 0.0007818716499389211
[Epoch 23, Batch 1500] loss: 0.0029761314589545405
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9898
Overfitting: 0.0470
[Epoch 24, Batch 100] loss: 0.00045838423115444725
[Epoch 24, Batch 200] loss: 0.00043447942600174374
[Epoch 24, Batch 300] loss: 0.00041903723933359063
[Epoch 24, Batch 400] loss: 0.00031279866541765954
[Epoch 24, Batch 500] loss: 0.00024377327490981315
[Epoch 24, Batch 600] loss: 0.00024326446246149657
[Epoch 24, Batch 700] loss: 0.00028779360075858795
[Epoch 24, Batch 800] loss: 0.0011518400147119223
[Epoch 24, Batch 900] loss: 0.00034597537048973947
[Epoch 24, Batch 1000] loss: 0.0003182906062110646
[Epoch 24, Batch 1100] loss: 0.00017996694287499614
[Epoch 24, Batch 1200] loss: 0.00023623617831244559
[Epoch 24, Batch 1300] loss: 0.00016778916262751408
[Epoch 24, Batch 1400] loss: 0.000937086064683541
[Epoch 24, Batch 1500] loss: 0.0011886339783558242
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9902
Overfitting: 0.0478
Fold 1 validation loss: 0.0478
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.284072451591492
[Epoch 1, Batch 200] loss: 1.747175285220146
[Epoch 1, Batch 300] loss: 0.4829207101464272
[Epoch 1, Batch 400] loss: 0.33996197044849397
[Epoch 1, Batch 500] loss: 0.24093374684453012
[Epoch 1, Batch 600] loss: 0.19091157101094722
[Epoch 1, Batch 700] loss: 0.18462325489148498
[Epoch 1, Batch 800] loss: 0.16552874978631735
[Epoch 1, Batch 900] loss: 0.16326093712821602
[Epoch 1, Batch 1000] loss: 0.136053111422807
[Epoch 1, Batch 1100] loss: 0.13402889428660272
[Epoch 1, Batch 1200] loss: 0.12980956728570164
[Epoch 1, Batch 1300] loss: 0.11460128353908658
[Epoch 1, Batch 1400] loss: 0.11527897465508431
[Epoch 1, Batch 1500] loss: 0.0891530747897923
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1174
Validation Accuracy: 0.9622
Overfitting: 0.1174
Best model saved at epoch 1 with validation loss: 0.1174
[Epoch 2, Batch 100] loss: 0.10031948688672855
[Epoch 2, Batch 200] loss: 0.10050721248611807
[Epoch 2, Batch 300] loss: 0.09332944208290428
[Epoch 2, Batch 400] loss: 0.07508749964646995
[Epoch 2, Batch 500] loss: 0.08934010013472289
[Epoch 2, Batch 600] loss: 0.09091538354055956
[Epoch 2, Batch 700] loss: 0.07741976231103763
[Epoch 2, Batch 800] loss: 0.0922533483011648
[Epoch 2, Batch 900] loss: 0.08246932696551085
[Epoch 2, Batch 1000] loss: 0.08184153580572456
[Epoch 2, Batch 1100] loss: 0.060146018201485275
[Epoch 2, Batch 1200] loss: 0.07358576472382992
[Epoch 2, Batch 1300] loss: 0.08528822728432715
[Epoch 2, Batch 1400] loss: 0.060252636346267534
[Epoch 2, Batch 1500] loss: 0.07720842317561619
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0902
Validation Accuracy: 0.9716
Overfitting: 0.0902
Best model saved at epoch 2 with validation loss: 0.0902
[Epoch 3, Batch 100] loss: 0.06147947499062866
[Epoch 3, Batch 200] loss: 0.0499840788153233
[Epoch 3, Batch 300] loss: 0.07356234685285017
[Epoch 3, Batch 400] loss: 0.04867443101014942
[Epoch 3, Batch 500] loss: 0.06466848302108702
[Epoch 3, Batch 600] loss: 0.043031185695435854
[Epoch 3, Batch 700] loss: 0.06615995350875892
[Epoch 3, Batch 800] loss: 0.050163525147363545
[Epoch 3, Batch 900] loss: 0.05262650684511755
[Epoch 3, Batch 1000] loss: 0.054791104465257374
[Epoch 3, Batch 1100] loss: 0.05659514144062996
[Epoch 3, Batch 1200] loss: 0.05819057950866409
[Epoch 3, Batch 1300] loss: 0.06808798294398002
[Epoch 3, Batch 1400] loss: 0.06623415921116248
[Epoch 3, Batch 1500] loss: 0.041136336793424565
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0664
Validation Accuracy: 0.9810
Overfitting: 0.0664
Best model saved at epoch 3 with validation loss: 0.0664
[Epoch 4, Batch 100] loss: 0.04412985878065229
[Epoch 4, Batch 200] loss: 0.04725369443069212
[Epoch 4, Batch 300] loss: 0.04357564986334182
[Epoch 4, Batch 400] loss: 0.04070627785520628
[Epoch 4, Batch 500] loss: 0.04504303961875848
[Epoch 4, Batch 600] loss: 0.041283331045415254
[Epoch 4, Batch 700] loss: 0.04454376785666682
[Epoch 4, Batch 800] loss: 0.03687362620839849
[Epoch 4, Batch 900] loss: 0.047880901696626094
[Epoch 4, Batch 1000] loss: 0.04001687389682047
[Epoch 4, Batch 1100] loss: 0.06385050537763164
[Epoch 4, Batch 1200] loss: 0.04434968666580971
[Epoch 4, Batch 1300] loss: 0.028778138150810265
[Epoch 4, Batch 1400] loss: 0.04282268710783683
[Epoch 4, Batch 1500] loss: 0.04658239472657442
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0625
Validation Accuracy: 0.9808
Overfitting: 0.0625
Best model saved at epoch 4 with validation loss: 0.0625
[Epoch 5, Batch 100] loss: 0.03913128757558297
[Epoch 5, Batch 200] loss: 0.03684293129685102
[Epoch 5, Batch 300] loss: 0.03095712631009519
[Epoch 5, Batch 400] loss: 0.032940164846659174
[Epoch 5, Batch 500] loss: 0.032888158363639376
[Epoch 5, Batch 600] loss: 0.02945000879233703
[Epoch 5, Batch 700] loss: 0.03533106533257523
[Epoch 5, Batch 800] loss: 0.04183444081136258
[Epoch 5, Batch 900] loss: 0.0434000819711946
[Epoch 5, Batch 1000] loss: 0.04198396464606049
[Epoch 5, Batch 1100] loss: 0.033997400154476054
[Epoch 5, Batch 1200] loss: 0.038927595053100957
[Epoch 5, Batch 1300] loss: 0.04279591108643217
[Epoch 5, Batch 1400] loss: 0.03189304768515285
[Epoch 5, Batch 1500] loss: 0.04230387865012744
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0583
Validation Accuracy: 0.9827
Overfitting: 0.0583
Best model saved at epoch 5 with validation loss: 0.0583
[Epoch 6, Batch 100] loss: 0.027710914050694556
[Epoch 6, Batch 200] loss: 0.031952750180498694
[Epoch 6, Batch 300] loss: 0.035228791381960035
[Epoch 6, Batch 400] loss: 0.03603861945855897
[Epoch 6, Batch 500] loss: 0.029847998098703102
[Epoch 6, Batch 600] loss: 0.027875011362484655
[Epoch 6, Batch 700] loss: 0.02923047565971501
[Epoch 6, Batch 800] loss: 0.022228578889480557
[Epoch 6, Batch 900] loss: 0.025627207864890807
[Epoch 6, Batch 1000] loss: 0.05108545018694713
[Epoch 6, Batch 1100] loss: 0.02435887238709256
[Epoch 6, Batch 1200] loss: 0.021222100252925882
[Epoch 6, Batch 1300] loss: 0.03443113752102363
[Epoch 6, Batch 1400] loss: 0.028022868260813995
[Epoch 6, Batch 1500] loss: 0.021967132527861394
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9861
Overfitting: 0.0512
Best model saved at epoch 6 with validation loss: 0.0512
[Epoch 7, Batch 100] loss: 0.013224201114790049
[Epoch 7, Batch 200] loss: 0.01605920585032436
[Epoch 7, Batch 300] loss: 0.027165576552797575
[Epoch 7, Batch 400] loss: 0.03116898177060648
[Epoch 7, Batch 500] loss: 0.022465178527054378
[Epoch 7, Batch 600] loss: 0.020711671563767596
[Epoch 7, Batch 700] loss: 0.029368541644216747
[Epoch 7, Batch 800] loss: 0.027463296853820793
[Epoch 7, Batch 900] loss: 0.029886866816668772
[Epoch 7, Batch 1000] loss: 0.03145895541834762
[Epoch 7, Batch 1100] loss: 0.024980569149483926
[Epoch 7, Batch 1200] loss: 0.027128767841059016
[Epoch 7, Batch 1300] loss: 0.02275832070998149
[Epoch 7, Batch 1400] loss: 0.02435820988146588
[Epoch 7, Batch 1500] loss: 0.021063394364900886
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0479
Validation Accuracy: 0.9861
Overfitting: 0.0479
Best model saved at epoch 7 with validation loss: 0.0479
[Epoch 8, Batch 100] loss: 0.02205302181391744
[Epoch 8, Batch 200] loss: 0.018424989432096483
[Epoch 8, Batch 300] loss: 0.019778494301863247
[Epoch 8, Batch 400] loss: 0.020167326559239883
[Epoch 8, Batch 500] loss: 0.013750237708591158
[Epoch 8, Batch 600] loss: 0.026985138662712415
[Epoch 8, Batch 700] loss: 0.02187325085840712
[Epoch 8, Batch 800] loss: 0.022590146827787976
[Epoch 8, Batch 900] loss: 0.01891523493883142
[Epoch 8, Batch 1000] loss: 0.014320877732679947
[Epoch 8, Batch 1100] loss: 0.029104959937685634
[Epoch 8, Batch 1200] loss: 0.02310973743078648
[Epoch 8, Batch 1300] loss: 0.015935097045803558
[Epoch 8, Batch 1400] loss: 0.030810987009608652
[Epoch 8, Batch 1500] loss: 0.023737228264362784
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9861
Overfitting: 0.0524
[Epoch 9, Batch 100] loss: 0.018452686768869173
[Epoch 9, Batch 200] loss: 0.014022708625998349
[Epoch 9, Batch 300] loss: 0.014785325110024132
[Epoch 9, Batch 400] loss: 0.020775084602100834
[Epoch 9, Batch 500] loss: 0.019788359436934116
[Epoch 9, Batch 600] loss: 0.01248969589563785
[Epoch 9, Batch 700] loss: 0.021770554524882756
[Epoch 9, Batch 800] loss: 0.022364325693197316
[Epoch 9, Batch 900] loss: 0.01755034612622694
[Epoch 9, Batch 1000] loss: 0.01676101819619362
[Epoch 9, Batch 1100] loss: 0.018561154177441495
[Epoch 9, Batch 1200] loss: 0.013197107311352738
[Epoch 9, Batch 1300] loss: 0.013786553623504005
[Epoch 9, Batch 1400] loss: 0.019602780427558173
[Epoch 9, Batch 1500] loss: 0.020341816158797883
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0542
Validation Accuracy: 0.9850
Overfitting: 0.0542
[Epoch 10, Batch 100] loss: 0.017109457931728685
[Epoch 10, Batch 200] loss: 0.012900159476175758
[Epoch 10, Batch 300] loss: 0.01862346795052872
[Epoch 10, Batch 400] loss: 0.012233252361693304
[Epoch 10, Batch 500] loss: 0.014009165480310913
[Epoch 10, Batch 600] loss: 0.010898524386357166
[Epoch 10, Batch 700] loss: 0.00854597496241695
[Epoch 10, Batch 800] loss: 0.012992419646579947
[Epoch 10, Batch 900] loss: 0.01924810894051916
[Epoch 10, Batch 1000] loss: 0.010278014323266688
[Epoch 10, Batch 1100] loss: 0.0277997677762869
[Epoch 10, Batch 1200] loss: 0.02046456213472993
[Epoch 10, Batch 1300] loss: 0.01983336278688512
[Epoch 10, Batch 1400] loss: 0.009545444314790074
[Epoch 10, Batch 1500] loss: 0.017280317680633744
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9867
Overfitting: 0.0502
[Epoch 11, Batch 100] loss: 0.011935795536010119
[Epoch 11, Batch 200] loss: 0.011543038364216045
[Epoch 11, Batch 300] loss: 0.010953548340839916
[Epoch 11, Batch 400] loss: 0.014028005552409012
[Epoch 11, Batch 500] loss: 0.014186912910372485
[Epoch 11, Batch 600] loss: 0.008929031027801102
[Epoch 11, Batch 700] loss: 0.014791598283463827
[Epoch 11, Batch 800] loss: 0.010119982395044644
[Epoch 11, Batch 900] loss: 0.014400491680389678
[Epoch 11, Batch 1000] loss: 0.019659887693014754
[Epoch 11, Batch 1100] loss: 0.010012543478842418
[Epoch 11, Batch 1200] loss: 0.01150413446456696
[Epoch 11, Batch 1300] loss: 0.016112583419599105
[Epoch 11, Batch 1400] loss: 0.0214458696784277
[Epoch 11, Batch 1500] loss: 0.009485083989457053
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9872
Overfitting: 0.0470
Best model saved at epoch 11 with validation loss: 0.0470
[Epoch 12, Batch 100] loss: 0.012165520659491448
[Epoch 12, Batch 200] loss: 0.01077991018169996
[Epoch 12, Batch 300] loss: 0.0070233470373204905
[Epoch 12, Batch 400] loss: 0.013892615235727135
[Epoch 12, Batch 500] loss: 0.007297847297177213
[Epoch 12, Batch 600] loss: 0.013910350646856386
[Epoch 12, Batch 700] loss: 0.009018204493149823
[Epoch 12, Batch 800] loss: 0.017195873700311493
[Epoch 12, Batch 900] loss: 0.013235650523911317
[Epoch 12, Batch 1000] loss: 0.013001057383771695
[Epoch 12, Batch 1100] loss: 0.022356677355892317
[Epoch 12, Batch 1200] loss: 0.013441197565216499
[Epoch 12, Batch 1300] loss: 0.011464862786378944
[Epoch 12, Batch 1400] loss: 0.020906584911954268
[Epoch 12, Batch 1500] loss: 0.0053834474290215435
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9870
Overfitting: 0.0492
[Epoch 13, Batch 100] loss: 0.003586570684014987
[Epoch 13, Batch 200] loss: 0.005260431241085825
[Epoch 13, Batch 300] loss: 0.007321443846958573
[Epoch 13, Batch 400] loss: 0.009042407257611558
[Epoch 13, Batch 500] loss: 0.009561915777958348
[Epoch 13, Batch 600] loss: 0.004608030332296949
[Epoch 13, Batch 700] loss: 0.007424265910995018
[Epoch 13, Batch 800] loss: 0.012491999211342773
[Epoch 13, Batch 900] loss: 0.01252247740977964
[Epoch 13, Batch 1000] loss: 0.009014658915875771
[Epoch 13, Batch 1100] loss: 0.006443154633043378
[Epoch 13, Batch 1200] loss: 0.008501968129701254
[Epoch 13, Batch 1300] loss: 0.011310215160992811
[Epoch 13, Batch 1400] loss: 0.00824869853276141
[Epoch 13, Batch 1500] loss: 0.018724964632801856
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0482
Validation Accuracy: 0.9879
Overfitting: 0.0482
[Epoch 14, Batch 100] loss: 0.007232296621841669
[Epoch 14, Batch 200] loss: 0.009164611986816453
[Epoch 14, Batch 300] loss: 0.00684633422848492
[Epoch 14, Batch 400] loss: 0.005206029870660132
[Epoch 14, Batch 500] loss: 0.004884612156765797
[Epoch 14, Batch 600] loss: 0.005948794589812678
[Epoch 14, Batch 700] loss: 0.007005823151321238
[Epoch 14, Batch 800] loss: 0.005180578181125384
[Epoch 14, Batch 900] loss: 0.007033632147176831
[Epoch 14, Batch 1000] loss: 0.007459581005177824
[Epoch 14, Batch 1100] loss: 0.008408065790290494
[Epoch 14, Batch 1200] loss: 0.007331756934436271
[Epoch 14, Batch 1300] loss: 0.010074422954007787
[Epoch 14, Batch 1400] loss: 0.00821253360261835
[Epoch 14, Batch 1500] loss: 0.004873777263010197
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9882
Overfitting: 0.0504
[Epoch 15, Batch 100] loss: 0.004164893906777252
[Epoch 15, Batch 200] loss: 0.006588559720910325
[Epoch 15, Batch 300] loss: 0.003944811714163734
[Epoch 15, Batch 400] loss: 0.004215962850050801
[Epoch 15, Batch 500] loss: 0.007284218553843402
[Epoch 15, Batch 600] loss: 0.008701059527229518
[Epoch 15, Batch 700] loss: 0.004940083623537248
[Epoch 15, Batch 800] loss: 0.004860588977298903
[Epoch 15, Batch 900] loss: 0.006760631454171744
[Epoch 15, Batch 1000] loss: 0.00590497879153645
[Epoch 15, Batch 1100] loss: 0.00639421237788838
[Epoch 15, Batch 1200] loss: 0.006845829925450744
[Epoch 15, Batch 1300] loss: 0.005882047959380543
[Epoch 15, Batch 1400] loss: 0.007672152496693343
[Epoch 15, Batch 1500] loss: 0.010736573388835496
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9878
Overfitting: 0.0532
[Epoch 16, Batch 100] loss: 0.00815560364594603
[Epoch 16, Batch 200] loss: 0.002758221489712014
[Epoch 16, Batch 300] loss: 0.005938585041762963
[Epoch 16, Batch 400] loss: 0.003524158876175534
[Epoch 16, Batch 500] loss: 0.003798667930227566
[Epoch 16, Batch 600] loss: 0.004030087901696788
[Epoch 16, Batch 700] loss: 0.0029527236233570873
[Epoch 16, Batch 800] loss: 0.008665162464756121
[Epoch 16, Batch 900] loss: 0.006810688794139423
[Epoch 16, Batch 1000] loss: 0.013414159002541054
[Epoch 16, Batch 1100] loss: 0.006235284711551685
[Epoch 16, Batch 1200] loss: 0.013868764605663273
[Epoch 16, Batch 1300] loss: 0.011679763368256317
[Epoch 16, Batch 1400] loss: 0.013411806742092268
[Epoch 16, Batch 1500] loss: 0.007343096036843235
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0687
Validation Accuracy: 0.9847
Overfitting: 0.0687
[Epoch 17, Batch 100] loss: 0.006670066983078868
[Epoch 17, Batch 200] loss: 0.0033780829314832774
[Epoch 17, Batch 300] loss: 0.009281499408293712
[Epoch 17, Batch 400] loss: 0.0035128997282618
[Epoch 17, Batch 500] loss: 0.004942416095309455
[Epoch 17, Batch 600] loss: 0.004104702632187127
[Epoch 17, Batch 700] loss: 0.004772055930752686
[Epoch 17, Batch 800] loss: 0.006659381194099296
[Epoch 17, Batch 900] loss: 0.004225052019535269
[Epoch 17, Batch 1000] loss: 0.003278481352417657
[Epoch 17, Batch 1100] loss: 0.005012880945032521
[Epoch 17, Batch 1200] loss: 0.005123466191014359
[Epoch 17, Batch 1300] loss: 0.0034405989563038018
[Epoch 17, Batch 1400] loss: 0.003780434355116995
[Epoch 17, Batch 1500] loss: 0.005158635877082815
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9878
Overfitting: 0.0519
[Epoch 18, Batch 100] loss: 0.003547873267605155
[Epoch 18, Batch 200] loss: 0.003369014282129683
[Epoch 18, Batch 300] loss: 0.002373788926324778
[Epoch 18, Batch 400] loss: 0.0031577047943159185
[Epoch 18, Batch 500] loss: 0.001945661686809217
[Epoch 18, Batch 600] loss: 0.0036080432290248156
[Epoch 18, Batch 700] loss: 0.0020662085071057844
[Epoch 18, Batch 800] loss: 0.012139705233809082
[Epoch 18, Batch 900] loss: 0.003919589536453713
[Epoch 18, Batch 1000] loss: 0.004864046083289395
[Epoch 18, Batch 1100] loss: 0.0034488850645118417
[Epoch 18, Batch 1200] loss: 0.0015449486924541133
[Epoch 18, Batch 1300] loss: 0.0014630783621055344
[Epoch 18, Batch 1400] loss: 0.003551012258831179
[Epoch 18, Batch 1500] loss: 0.0033111058278507246
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9890
Overfitting: 0.0537
[Epoch 19, Batch 100] loss: 0.005000565323537103
[Epoch 19, Batch 200] loss: 0.0055653815614869016
[Epoch 19, Batch 300] loss: 0.0014365471333530877
[Epoch 19, Batch 400] loss: 0.0008153604150643901
[Epoch 19, Batch 500] loss: 0.002973602790495988
[Epoch 19, Batch 600] loss: 0.005583777373802263
[Epoch 19, Batch 700] loss: 0.004341943904458389
[Epoch 19, Batch 800] loss: 0.002778908475756623
[Epoch 19, Batch 900] loss: 0.0022585277108794345
[Epoch 19, Batch 1000] loss: 0.0014516314760703608
[Epoch 19, Batch 1100] loss: 0.002776492038468632
[Epoch 19, Batch 1200] loss: 0.0032028176659378003
[Epoch 19, Batch 1300] loss: 0.003354434913093769
[Epoch 19, Batch 1400] loss: 0.0023855544231935256
[Epoch 19, Batch 1500] loss: 0.006713014157402313
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9882
Overfitting: 0.0592
[Epoch 20, Batch 100] loss: 0.0008721960291836695
[Epoch 20, Batch 200] loss: 0.0012269573999640216
[Epoch 20, Batch 300] loss: 0.0024781351976344013
[Epoch 20, Batch 400] loss: 0.0026864568213210305
[Epoch 20, Batch 500] loss: 0.004576676740410335
[Epoch 20, Batch 600] loss: 0.0026757681553226578
[Epoch 20, Batch 700] loss: 0.0009201699770898131
[Epoch 20, Batch 800] loss: 0.003878704249129896
[Epoch 20, Batch 900] loss: 0.00283305098180108
[Epoch 20, Batch 1000] loss: 0.004373841655101955
[Epoch 20, Batch 1100] loss: 0.0024409168771188663
[Epoch 20, Batch 1200] loss: 0.0016845596235400251
[Epoch 20, Batch 1300] loss: 0.002513985856196541
[Epoch 20, Batch 1400] loss: 0.0030467131977661667
[Epoch 20, Batch 1500] loss: 0.0037867971343047203
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0589
Validation Accuracy: 0.9872
Overfitting: 0.0589
[Epoch 21, Batch 100] loss: 0.0029342643087633745
[Epoch 21, Batch 200] loss: 0.0017657516306883103
[Epoch 21, Batch 300] loss: 0.0007485814031524284
[Epoch 21, Batch 400] loss: 0.0008859742851660712
[Epoch 21, Batch 500] loss: 0.002330271675449467
[Epoch 21, Batch 600] loss: 0.0012744617811516435
[Epoch 21, Batch 700] loss: 0.0038749024150153844
[Epoch 21, Batch 800] loss: 0.00254199942569727
[Epoch 21, Batch 900] loss: 0.004885395346437349
[Epoch 21, Batch 1000] loss: 0.004281285049189592
[Epoch 21, Batch 1100] loss: 0.0010235123933264845
[Epoch 21, Batch 1200] loss: 0.002076549906012133
[Epoch 21, Batch 1300] loss: 0.004390335946879986
[Epoch 21, Batch 1400] loss: 0.001645849775047168
[Epoch 21, Batch 1500] loss: 0.0024055213364636073
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9878
Overfitting: 0.0576
[Epoch 22, Batch 100] loss: 0.0019200390967702675
[Epoch 22, Batch 200] loss: 0.0009314459228681926
[Epoch 22, Batch 300] loss: 0.0008285417205308931
[Epoch 22, Batch 400] loss: 0.0005790532952090644
[Epoch 22, Batch 500] loss: 0.0005582605886377223
[Epoch 22, Batch 600] loss: 0.0004270574618998424
[Epoch 22, Batch 700] loss: 0.0007249566456638945
[Epoch 22, Batch 800] loss: 0.001512843874696017
[Epoch 22, Batch 900] loss: 0.0023083947728366637
[Epoch 22, Batch 1000] loss: 0.001155817658979572
[Epoch 22, Batch 1100] loss: 0.0008921590978544458
[Epoch 22, Batch 1200] loss: 0.001161740777055371
[Epoch 22, Batch 1300] loss: 0.00376152452435079
[Epoch 22, Batch 1400] loss: 0.003115847538554135
[Epoch 22, Batch 1500] loss: 0.004909030295605703
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0692
Validation Accuracy: 0.9862
Overfitting: 0.0692
[Epoch 23, Batch 100] loss: 0.003135766833928528
[Epoch 23, Batch 200] loss: 0.004681244530348465
[Epoch 23, Batch 300] loss: 0.0012748144127829163
[Epoch 23, Batch 400] loss: 0.0029261803922037187
[Epoch 23, Batch 500] loss: 0.003521517644779948
[Epoch 23, Batch 600] loss: 0.003937093167244257
[Epoch 23, Batch 700] loss: 0.0014097579025010986
[Epoch 23, Batch 800] loss: 0.0007810964171162027
[Epoch 23, Batch 900] loss: 0.0027859884154148064
[Epoch 23, Batch 1000] loss: 0.0006995886148071406
[Epoch 23, Batch 1100] loss: 0.0013235339788082
[Epoch 23, Batch 1200] loss: 0.0024646618390772802
[Epoch 23, Batch 1300] loss: 0.002308280767787778
[Epoch 23, Batch 1400] loss: 0.003215881834143488
[Epoch 23, Batch 1500] loss: 0.0028735449149419876
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9879
Overfitting: 0.0630
[Epoch 24, Batch 100] loss: 0.006728071387339014
[Epoch 24, Batch 200] loss: 0.004648755606631312
[Epoch 24, Batch 300] loss: 0.002641851624284186
[Epoch 24, Batch 400] loss: 0.0012388222130021375
[Epoch 24, Batch 500] loss: 0.0009277201290143467
[Epoch 24, Batch 600] loss: 0.0014857931687140536
[Epoch 24, Batch 700] loss: 0.0017990165826267913
[Epoch 24, Batch 800] loss: 0.0013654219488839203
[Epoch 24, Batch 900] loss: 0.0007130796496443282
[Epoch 24, Batch 1000] loss: 0.0008382465878241874
[Epoch 24, Batch 1100] loss: 0.0007225085548316202
[Epoch 24, Batch 1200] loss: 0.000944088422668159
[Epoch 24, Batch 1300] loss: 0.0030495138995092572
[Epoch 24, Batch 1400] loss: 0.0010457362621859546
[Epoch 24, Batch 1500] loss: 0.0012226750688109967
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0616
Validation Accuracy: 0.9886
Overfitting: 0.0616
Fold 2 validation loss: 0.0616
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.269835903644562
[Epoch 1, Batch 200] loss: 1.4239053070545196
[Epoch 1, Batch 300] loss: 0.5206433912366628
[Epoch 1, Batch 400] loss: 0.4480775326490402
[Epoch 1, Batch 500] loss: 0.317061001136899
[Epoch 1, Batch 600] loss: 0.21767139172181488
[Epoch 1, Batch 700] loss: 0.20434678955003618
[Epoch 1, Batch 800] loss: 0.20642350491136313
[Epoch 1, Batch 900] loss: 0.18782468788325787
[Epoch 1, Batch 1000] loss: 0.16158818524330854
[Epoch 1, Batch 1100] loss: 0.1540304997190833
[Epoch 1, Batch 1200] loss: 0.12871857470832765
[Epoch 1, Batch 1300] loss: 0.13319883236661553
[Epoch 1, Batch 1400] loss: 0.11925282552838326
[Epoch 1, Batch 1500] loss: 0.1300832171086222
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1093
Validation Accuracy: 0.9687
Overfitting: 0.1093
Best model saved at epoch 1 with validation loss: 0.1093
[Epoch 2, Batch 100] loss: 0.10106097407639027
[Epoch 2, Batch 200] loss: 0.09605025715194643
[Epoch 2, Batch 300] loss: 0.0868712434079498
[Epoch 2, Batch 400] loss: 0.09400476505514234
[Epoch 2, Batch 500] loss: 0.08532964382320643
[Epoch 2, Batch 600] loss: 0.07877171136438847
[Epoch 2, Batch 700] loss: 0.10394345089793205
[Epoch 2, Batch 800] loss: 0.08822764674201608
[Epoch 2, Batch 900] loss: 0.07383943029330112
[Epoch 2, Batch 1000] loss: 0.0886720847315155
[Epoch 2, Batch 1100] loss: 0.07596941759227775
[Epoch 2, Batch 1200] loss: 0.07681301882956176
[Epoch 2, Batch 1300] loss: 0.08247435634257272
[Epoch 2, Batch 1400] loss: 0.0714159525395371
[Epoch 2, Batch 1500] loss: 0.06645601552212611
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0873
Validation Accuracy: 0.9721
Overfitting: 0.0873
Best model saved at epoch 2 with validation loss: 0.0873
[Epoch 3, Batch 100] loss: 0.05262113868491724
[Epoch 3, Batch 200] loss: 0.06187498172279447
[Epoch 3, Batch 300] loss: 0.05582184339640662
[Epoch 3, Batch 400] loss: 0.06805710162036122
[Epoch 3, Batch 500] loss: 0.05207214846392162
[Epoch 3, Batch 600] loss: 0.049115348681807516
[Epoch 3, Batch 700] loss: 0.06088701278669759
[Epoch 3, Batch 800] loss: 0.05590753575321287
[Epoch 3, Batch 900] loss: 0.06254684486833867
[Epoch 3, Batch 1000] loss: 0.06260583823837805
[Epoch 3, Batch 1100] loss: 0.050456077945418655
[Epoch 3, Batch 1200] loss: 0.06482372107682749
[Epoch 3, Batch 1300] loss: 0.045808987622149286
[Epoch 3, Batch 1400] loss: 0.047781087702605876
[Epoch 3, Batch 1500] loss: 0.0547090559505159
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0610
Validation Accuracy: 0.9808
Overfitting: 0.0610
Best model saved at epoch 3 with validation loss: 0.0610
[Epoch 4, Batch 100] loss: 0.03502610816736706
[Epoch 4, Batch 200] loss: 0.041863238203222866
[Epoch 4, Batch 300] loss: 0.04623092661844566
[Epoch 4, Batch 400] loss: 0.04032426324672997
[Epoch 4, Batch 500] loss: 0.0708776025136467
[Epoch 4, Batch 600] loss: 0.043202754548983646
[Epoch 4, Batch 700] loss: 0.044445638642500854
[Epoch 4, Batch 800] loss: 0.04692875820212066
[Epoch 4, Batch 900] loss: 0.031811715401127004
[Epoch 4, Batch 1000] loss: 0.03505444756912766
[Epoch 4, Batch 1100] loss: 0.053547660739859566
[Epoch 4, Batch 1200] loss: 0.04176452653366141
[Epoch 4, Batch 1300] loss: 0.05116987701971084
[Epoch 4, Batch 1400] loss: 0.042012464072322474
[Epoch 4, Batch 1500] loss: 0.039611401559668594
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9832
Overfitting: 0.0544
Best model saved at epoch 4 with validation loss: 0.0544
[Epoch 5, Batch 100] loss: 0.03492649447900476
[Epoch 5, Batch 200] loss: 0.036212873073527586
[Epoch 5, Batch 300] loss: 0.03110274783015484
[Epoch 5, Batch 400] loss: 0.041735815418651324
[Epoch 5, Batch 500] loss: 0.0354955312126549
[Epoch 5, Batch 600] loss: 0.04345355542842299
[Epoch 5, Batch 700] loss: 0.03143647963821422
[Epoch 5, Batch 800] loss: 0.036435491260053826
[Epoch 5, Batch 900] loss: 0.03766353145649191
[Epoch 5, Batch 1000] loss: 0.034570767646073364
[Epoch 5, Batch 1100] loss: 0.02849885364761576
[Epoch 5, Batch 1200] loss: 0.03766082261718111
[Epoch 5, Batch 1300] loss: 0.03475372544577113
[Epoch 5, Batch 1400] loss: 0.03453839044319466
[Epoch 5, Batch 1500] loss: 0.04392749822378392
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9850
Overfitting: 0.0514
Best model saved at epoch 5 with validation loss: 0.0514
[Epoch 6, Batch 100] loss: 0.01885936603124719
[Epoch 6, Batch 200] loss: 0.025884262017643777
[Epoch 6, Batch 300] loss: 0.026220329838979525
[Epoch 6, Batch 400] loss: 0.02714328518079128
[Epoch 6, Batch 500] loss: 0.02847073198092403
[Epoch 6, Batch 600] loss: 0.025909456506196873
[Epoch 6, Batch 700] loss: 0.02849525846657343
[Epoch 6, Batch 800] loss: 0.03300458304962376
[Epoch 6, Batch 900] loss: 0.027524332349421456
[Epoch 6, Batch 1000] loss: 0.027874579625204204
[Epoch 6, Batch 1100] loss: 0.031819533877715
[Epoch 6, Batch 1200] loss: 0.024305662689730525
[Epoch 6, Batch 1300] loss: 0.027833675187430344
[Epoch 6, Batch 1400] loss: 0.047045106903242415
[Epoch 6, Batch 1500] loss: 0.03294664543653198
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9868
Overfitting: 0.0464
Best model saved at epoch 6 with validation loss: 0.0464
[Epoch 7, Batch 100] loss: 0.028263341063284316
[Epoch 7, Batch 200] loss: 0.024733158624294448
[Epoch 7, Batch 300] loss: 0.025280604898289313
[Epoch 7, Batch 400] loss: 0.01915513993706554
[Epoch 7, Batch 500] loss: 0.02941098712341045
[Epoch 7, Batch 600] loss: 0.021241891492609286
[Epoch 7, Batch 700] loss: 0.02866333025536733
[Epoch 7, Batch 800] loss: 0.021929386958363467
[Epoch 7, Batch 900] loss: 0.024118131379946135
[Epoch 7, Batch 1000] loss: 0.026379247364529873
[Epoch 7, Batch 1100] loss: 0.021849459536315407
[Epoch 7, Batch 1200] loss: 0.02112608078372432
[Epoch 7, Batch 1300] loss: 0.017240081506897695
[Epoch 7, Batch 1400] loss: 0.03165298533203895
[Epoch 7, Batch 1500] loss: 0.022164080892762287
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9837
Overfitting: 0.0528
[Epoch 8, Batch 100] loss: 0.01336947746516671
[Epoch 8, Batch 200] loss: 0.012028390945342835
[Epoch 8, Batch 300] loss: 0.0228940656508712
[Epoch 8, Batch 400] loss: 0.02437140163528966
[Epoch 8, Batch 500] loss: 0.02636985783938144
[Epoch 8, Batch 600] loss: 0.020942193115261035
[Epoch 8, Batch 700] loss: 0.014505052978493041
[Epoch 8, Batch 800] loss: 0.016248216328967828
[Epoch 8, Batch 900] loss: 0.021686294229293707
[Epoch 8, Batch 1000] loss: 0.01741783076133288
[Epoch 8, Batch 1100] loss: 0.027355424327579383
[Epoch 8, Batch 1200] loss: 0.02346803448141145
[Epoch 8, Batch 1300] loss: 0.019732051475730258
[Epoch 8, Batch 1400] loss: 0.017969505959117667
[Epoch 8, Batch 1500] loss: 0.017821731764706784
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0425
Validation Accuracy: 0.9882
Overfitting: 0.0425
Best model saved at epoch 8 with validation loss: 0.0425
[Epoch 9, Batch 100] loss: 0.022167022224821267
[Epoch 9, Batch 200] loss: 0.010753281578799942
[Epoch 9, Batch 300] loss: 0.011184015532562626
[Epoch 9, Batch 400] loss: 0.01684456959977979
[Epoch 9, Batch 500] loss: 0.01641461587525555
[Epoch 9, Batch 600] loss: 0.010822934960815473
[Epoch 9, Batch 700] loss: 0.019551465713593643
[Epoch 9, Batch 800] loss: 0.016289516796350652
[Epoch 9, Batch 900] loss: 0.020674252015714954
[Epoch 9, Batch 1000] loss: 0.015336085012640978
[Epoch 9, Batch 1100] loss: 0.014978693832817953
[Epoch 9, Batch 1200] loss: 0.020357391631259814
[Epoch 9, Batch 1300] loss: 0.016291122590046142
[Epoch 9, Batch 1400] loss: 0.02285849244799465
[Epoch 9, Batch 1500] loss: 0.016387287120960537
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0499
Validation Accuracy: 0.9854
Overfitting: 0.0499
[Epoch 10, Batch 100] loss: 0.014445915016913204
[Epoch 10, Batch 200] loss: 0.010718461998931162
[Epoch 10, Batch 300] loss: 0.011547218716405041
[Epoch 10, Batch 400] loss: 0.017273054393881465
[Epoch 10, Batch 500] loss: 0.016496678201092435
[Epoch 10, Batch 600] loss: 0.01427256305643823
[Epoch 10, Batch 700] loss: 0.02763765165465884
[Epoch 10, Batch 800] loss: 0.009032471126738528
[Epoch 10, Batch 900] loss: 0.01133214513607527
[Epoch 10, Batch 1000] loss: 0.01613591185719997
[Epoch 10, Batch 1100] loss: 0.010121892164497694
[Epoch 10, Batch 1200] loss: 0.01280130241819279
[Epoch 10, Batch 1300] loss: 0.015311365462766844
[Epoch 10, Batch 1400] loss: 0.017676700014235394
[Epoch 10, Batch 1500] loss: 0.01734124377144326
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9865
Overfitting: 0.0484
[Epoch 11, Batch 100] loss: 0.012437671140942257
[Epoch 11, Batch 200] loss: 0.006864515460765688
[Epoch 11, Batch 300] loss: 0.00804136677785209
[Epoch 11, Batch 400] loss: 0.009142220564608578
[Epoch 11, Batch 500] loss: 0.007884195869683025
[Epoch 11, Batch 600] loss: 0.011260760532823042
[Epoch 11, Batch 700] loss: 0.012664946778677404
[Epoch 11, Batch 800] loss: 0.01256496881336716
[Epoch 11, Batch 900] loss: 0.009874072337183862
[Epoch 11, Batch 1000] loss: 0.015025825969114521
[Epoch 11, Batch 1100] loss: 0.011257570306297567
[Epoch 11, Batch 1200] loss: 0.01087590091079619
[Epoch 11, Batch 1300] loss: 0.01050513677543222
[Epoch 11, Batch 1400] loss: 0.015708140941023886
[Epoch 11, Batch 1500] loss: 0.013669296949901764
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0447
Validation Accuracy: 0.9882
Overfitting: 0.0447
[Epoch 12, Batch 100] loss: 0.005607500371097558
[Epoch 12, Batch 200] loss: 0.005890977709773324
[Epoch 12, Batch 300] loss: 0.00408182781728101
[Epoch 12, Batch 400] loss: 0.006427863280628117
[Epoch 12, Batch 500] loss: 0.012004575357204885
[Epoch 12, Batch 600] loss: 0.02221393798608915
[Epoch 12, Batch 700] loss: 0.013133148067754518
[Epoch 12, Batch 800] loss: 0.01865287530943533
[Epoch 12, Batch 900] loss: 0.010016988306251733
[Epoch 12, Batch 1000] loss: 0.016080186624094495
[Epoch 12, Batch 1100] loss: 0.011769375879212021
[Epoch 12, Batch 1200] loss: 0.007545933548094581
[Epoch 12, Batch 1300] loss: 0.009744855604167242
[Epoch 12, Batch 1400] loss: 0.016962655935349177
[Epoch 12, Batch 1500] loss: 0.010068637185031547
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0502
Validation Accuracy: 0.9860
Overfitting: 0.0502
[Epoch 13, Batch 100] loss: 0.005062832488147251
[Epoch 13, Batch 200] loss: 0.008239134848536197
[Epoch 13, Batch 300] loss: 0.009489023782589357
[Epoch 13, Batch 400] loss: 0.00827873291038486
[Epoch 13, Batch 500] loss: 0.009707133325618997
[Epoch 13, Batch 600] loss: 0.0040979085277649575
[Epoch 13, Batch 700] loss: 0.010244860158004486
[Epoch 13, Batch 800] loss: 0.010776486564818697
[Epoch 13, Batch 900] loss: 0.0075629608038525475
[Epoch 13, Batch 1000] loss: 0.012791847451946978
[Epoch 13, Batch 1100] loss: 0.006104072945513508
[Epoch 13, Batch 1200] loss: 0.010674602790213612
[Epoch 13, Batch 1300] loss: 0.011632546448527136
[Epoch 13, Batch 1400] loss: 0.0073352783016162
[Epoch 13, Batch 1500] loss: 0.012739214662797167
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0455
Validation Accuracy: 0.9883
Overfitting: 0.0455
[Epoch 14, Batch 100] loss: 0.005318636130195955
[Epoch 14, Batch 200] loss: 0.0025789523533148893
[Epoch 14, Batch 300] loss: 0.005590358854515216
[Epoch 14, Batch 400] loss: 0.00681816853932105
[Epoch 14, Batch 500] loss: 0.009917741027420561
[Epoch 14, Batch 600] loss: 0.008362916252858668
[Epoch 14, Batch 700] loss: 0.008328691960750803
[Epoch 14, Batch 800] loss: 0.004563280765323725
[Epoch 14, Batch 900] loss: 0.011512261425887118
[Epoch 14, Batch 1000] loss: 0.006586484720210137
[Epoch 14, Batch 1100] loss: 0.0038945702061391786
[Epoch 14, Batch 1200] loss: 0.006095016221597689
[Epoch 14, Batch 1300] loss: 0.008327974629410165
[Epoch 14, Batch 1400] loss: 0.006763950886797829
[Epoch 14, Batch 1500] loss: 0.002692203190690634
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0453
Validation Accuracy: 0.9892
Overfitting: 0.0453
[Epoch 15, Batch 100] loss: 0.007494953550340142
[Epoch 15, Batch 200] loss: 0.005455636618116841
[Epoch 15, Batch 300] loss: 0.007161817452397372
[Epoch 15, Batch 400] loss: 0.00678104555750906
[Epoch 15, Batch 500] loss: 0.002830133259485592
[Epoch 15, Batch 600] loss: 0.00700927948302251
[Epoch 15, Batch 700] loss: 0.004861066791854682
[Epoch 15, Batch 800] loss: 0.00546618348386346
[Epoch 15, Batch 900] loss: 0.00915262736972636
[Epoch 15, Batch 1000] loss: 0.01012005495077574
[Epoch 15, Batch 1100] loss: 0.008703029416710705
[Epoch 15, Batch 1200] loss: 0.0071841283382491385
[Epoch 15, Batch 1300] loss: 0.008538789233134593
[Epoch 15, Batch 1400] loss: 0.0029732172668809655
[Epoch 15, Batch 1500] loss: 0.009169788490643213
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0600
Validation Accuracy: 0.9849
Overfitting: 0.0600
[Epoch 16, Batch 100] loss: 0.005023473591600123
[Epoch 16, Batch 200] loss: 0.0038475493710211596
[Epoch 16, Batch 300] loss: 0.0032393503178104765
[Epoch 16, Batch 400] loss: 0.005621802381538146
[Epoch 16, Batch 500] loss: 0.002418735195733461
[Epoch 16, Batch 600] loss: 0.0031532893560267893
[Epoch 16, Batch 700] loss: 0.005099297702799959
[Epoch 16, Batch 800] loss: 0.005220888608926088
[Epoch 16, Batch 900] loss: 0.004186494993639371
[Epoch 16, Batch 1000] loss: 0.004940501322810178
[Epoch 16, Batch 1100] loss: 0.0046230726265275735
[Epoch 16, Batch 1200] loss: 0.0039018980698483576
[Epoch 16, Batch 1300] loss: 0.011726504320938603
[Epoch 16, Batch 1400] loss: 0.0054331740550833275
[Epoch 16, Batch 1500] loss: 0.010261627274790044
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9848
Overfitting: 0.0619
[Epoch 17, Batch 100] loss: 0.004985581978480695
[Epoch 17, Batch 200] loss: 0.003542667010956393
[Epoch 17, Batch 300] loss: 0.004414932265354991
[Epoch 17, Batch 400] loss: 0.0028412266143641317
[Epoch 17, Batch 500] loss: 0.0045474935097740855
[Epoch 17, Batch 600] loss: 0.004599341476259724
[Epoch 17, Batch 700] loss: 0.0037515500472051146
[Epoch 17, Batch 800] loss: 0.0025557894590428985
[Epoch 17, Batch 900] loss: 0.006022512900267429
[Epoch 17, Batch 1000] loss: 0.006924593279527471
[Epoch 17, Batch 1100] loss: 0.002320428934042411
[Epoch 17, Batch 1200] loss: 0.0021886298040362817
[Epoch 17, Batch 1300] loss: 0.007318903012241549
[Epoch 17, Batch 1400] loss: 0.009793095827867547
[Epoch 17, Batch 1500] loss: 0.005608534694201808
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0545
Validation Accuracy: 0.9884
Overfitting: 0.0545
[Epoch 18, Batch 100] loss: 0.0017225621968066207
[Epoch 18, Batch 200] loss: 0.002934112576122061
[Epoch 18, Batch 300] loss: 0.0026973457967585544
[Epoch 18, Batch 400] loss: 0.0032914345991093795
[Epoch 18, Batch 500] loss: 0.004069012040097277
[Epoch 18, Batch 600] loss: 0.005231505852277678
[Epoch 18, Batch 700] loss: 0.003277800675036815
[Epoch 18, Batch 800] loss: 0.0020438704663047246
[Epoch 18, Batch 900] loss: 0.005609673399666235
[Epoch 18, Batch 1000] loss: 0.0069130816425240485
[Epoch 18, Batch 1100] loss: 0.004975184548642915
[Epoch 18, Batch 1200] loss: 0.0035518831243712156
[Epoch 18, Batch 1300] loss: 0.005840972554801737
[Epoch 18, Batch 1400] loss: 0.007573136497043152
[Epoch 18, Batch 1500] loss: 0.006482635610655052
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9876
Overfitting: 0.0527
[Epoch 19, Batch 100] loss: 0.006233033986410774
[Epoch 19, Batch 200] loss: 0.002138760879898882
[Epoch 19, Batch 300] loss: 0.0017591077226097695
[Epoch 19, Batch 400] loss: 0.003980833007590263
[Epoch 19, Batch 500] loss: 0.0055385684162479265
[Epoch 19, Batch 600] loss: 0.0067803879861673974
[Epoch 19, Batch 700] loss: 0.0029449418239346414
[Epoch 19, Batch 800] loss: 0.004963458841928059
[Epoch 19, Batch 900] loss: 0.0018499047809604008
[Epoch 19, Batch 1000] loss: 0.0022273902856613857
[Epoch 19, Batch 1100] loss: 0.007001175455632165
[Epoch 19, Batch 1200] loss: 0.004340608924995877
[Epoch 19, Batch 1300] loss: 0.004194195076044025
[Epoch 19, Batch 1400] loss: 0.0071329779187624355
[Epoch 19, Batch 1500] loss: 0.005224331872270795
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9876
Overfitting: 0.0548
[Epoch 20, Batch 100] loss: 0.0035879453283632757
[Epoch 20, Batch 200] loss: 0.002018280636302734
[Epoch 20, Batch 300] loss: 0.001596272828377323
[Epoch 20, Batch 400] loss: 0.0020854457344671572
[Epoch 20, Batch 500] loss: 0.0024778149335526224
[Epoch 20, Batch 600] loss: 0.0023436020726632025
[Epoch 20, Batch 700] loss: 0.0009675830852633282
[Epoch 20, Batch 800] loss: 0.001985626059708068
[Epoch 20, Batch 900] loss: 0.0018710646538750097
[Epoch 20, Batch 1000] loss: 0.0030219214157625627
[Epoch 20, Batch 1100] loss: 0.0046206275742270006
[Epoch 20, Batch 1200] loss: 0.004121542997994538
[Epoch 20, Batch 1300] loss: 0.0012918677171694527
[Epoch 20, Batch 1400] loss: 0.004652202937984243
[Epoch 20, Batch 1500] loss: 0.004260382276402765
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0505
Validation Accuracy: 0.9891
Overfitting: 0.0505
[Epoch 21, Batch 100] loss: 0.00854969243340463
[Epoch 21, Batch 200] loss: 0.006448502467939079
[Epoch 21, Batch 300] loss: 0.003338978774085035
[Epoch 21, Batch 400] loss: 0.0037564138295999782
[Epoch 21, Batch 500] loss: 0.0024052826956557282
[Epoch 21, Batch 600] loss: 0.004523067749441552
[Epoch 21, Batch 700] loss: 0.0009621418509061641
[Epoch 21, Batch 800] loss: 0.0016886781653795424
[Epoch 21, Batch 900] loss: 0.0008409458850837837
[Epoch 21, Batch 1000] loss: 0.002798466822521277
[Epoch 21, Batch 1100] loss: 0.0009952919972889163
[Epoch 21, Batch 1200] loss: 0.002870774916331129
[Epoch 21, Batch 1300] loss: 0.0037276047058909965
[Epoch 21, Batch 1400] loss: 0.0033693786154223916
[Epoch 21, Batch 1500] loss: 0.0016645040240297249
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9886
Overfitting: 0.0506
[Epoch 22, Batch 100] loss: 0.0025593290762617473
[Epoch 22, Batch 200] loss: 0.0011714736776860235
[Epoch 22, Batch 300] loss: 0.0010143042409430337
[Epoch 22, Batch 400] loss: 0.0004464116181927125
[Epoch 22, Batch 500] loss: 0.0015220977664503722
[Epoch 22, Batch 600] loss: 0.0009841352587883988
[Epoch 22, Batch 700] loss: 0.0006536575971045977
[Epoch 22, Batch 800] loss: 0.004537298758026651
[Epoch 22, Batch 900] loss: 0.0011079259408086272
[Epoch 22, Batch 1000] loss: 0.0017405817306669746
[Epoch 22, Batch 1100] loss: 0.0010814496608746538
[Epoch 22, Batch 1200] loss: 0.001476191472926871
[Epoch 22, Batch 1300] loss: 0.001138655450794772
[Epoch 22, Batch 1400] loss: 0.0017977285758670547
[Epoch 22, Batch 1500] loss: 0.0010558767207083973
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9891
Overfitting: 0.0538
[Epoch 23, Batch 100] loss: 0.0009164820747605517
[Epoch 23, Batch 200] loss: 0.0003558743729035996
[Epoch 23, Batch 300] loss: 0.0003207873585569132
[Epoch 23, Batch 400] loss: 0.0006322012147398582
[Epoch 23, Batch 500] loss: 0.00022316231816830624
[Epoch 23, Batch 600] loss: 0.002672910922494651
[Epoch 23, Batch 700] loss: 0.0009275336845803395
[Epoch 23, Batch 800] loss: 0.0021665017437430835
[Epoch 23, Batch 900] loss: 0.0013161370748633772
[Epoch 23, Batch 1000] loss: 0.0004311850090702762
[Epoch 23, Batch 1100] loss: 0.0005418686558516583
[Epoch 23, Batch 1200] loss: 0.0016729429484777646
[Epoch 23, Batch 1300] loss: 0.0004508958760354176
[Epoch 23, Batch 1400] loss: 0.0006986561043834171
[Epoch 23, Batch 1500] loss: 0.0005216921246885064
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9894
Overfitting: 0.0515
[Epoch 24, Batch 100] loss: 0.0003766417922443566
[Epoch 24, Batch 200] loss: 0.00022898450720166609
[Epoch 24, Batch 300] loss: 0.0002856450176038372
[Epoch 24, Batch 400] loss: 0.00045694835637220875
[Epoch 24, Batch 500] loss: 0.0003767900088729448
[Epoch 24, Batch 600] loss: 0.0006862400294679105
[Epoch 24, Batch 700] loss: 0.00031392525912963263
[Epoch 24, Batch 800] loss: 0.0007250670324884822
[Epoch 24, Batch 900] loss: 0.0005596039028077371
[Epoch 24, Batch 1000] loss: 0.00023762909161277436
[Epoch 24, Batch 1100] loss: 0.0004056512088234143
[Epoch 24, Batch 1200] loss: 0.0008275107769560463
[Epoch 24, Batch 1300] loss: 0.0005013412029769882
[Epoch 24, Batch 1400] loss: 0.00031438546960060876
[Epoch 24, Batch 1500] loss: 0.00045558890739449964
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9896
Overfitting: 0.0552
Fold 3 validation loss: 0.0552
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2832704281806944
[Epoch 1, Batch 200] loss: 1.695071297287941
[Epoch 1, Batch 300] loss: 0.5238571617007256
[Epoch 1, Batch 400] loss: 0.3364643157273531
[Epoch 1, Batch 500] loss: 0.2612750805914402
[Epoch 1, Batch 600] loss: 0.21220235839486123
[Epoch 1, Batch 700] loss: 0.1923407146334648
[Epoch 1, Batch 800] loss: 0.17729541787877678
[Epoch 1, Batch 900] loss: 0.16233237819746138
[Epoch 1, Batch 1000] loss: 0.14121089215390384
[Epoch 1, Batch 1100] loss: 0.14143292628228665
[Epoch 1, Batch 1200] loss: 0.11030089182779193
[Epoch 1, Batch 1300] loss: 0.1122283153887838
[Epoch 1, Batch 1400] loss: 0.10806421264540404
[Epoch 1, Batch 1500] loss: 0.10578587628668173
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1027
Validation Accuracy: 0.9670
Overfitting: 0.1027
Best model saved at epoch 1 with validation loss: 0.1027
[Epoch 2, Batch 100] loss: 0.09132186865899712
[Epoch 2, Batch 200] loss: 0.09657237028703093
[Epoch 2, Batch 300] loss: 0.08834689893061295
[Epoch 2, Batch 400] loss: 0.08007581840734929
[Epoch 2, Batch 500] loss: 0.08127162401331589
[Epoch 2, Batch 600] loss: 0.08481667947489768
[Epoch 2, Batch 700] loss: 0.07764729614369571
[Epoch 2, Batch 800] loss: 0.0873238863889128
[Epoch 2, Batch 900] loss: 0.0894562432775274
[Epoch 2, Batch 1000] loss: 0.080161433594767
[Epoch 2, Batch 1100] loss: 0.08169018430635333
[Epoch 2, Batch 1200] loss: 0.06173307915218174
[Epoch 2, Batch 1300] loss: 0.07166071433923207
[Epoch 2, Batch 1400] loss: 0.0681613488518633
[Epoch 2, Batch 1500] loss: 0.05808993023121729
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9816
Overfitting: 0.0632
Best model saved at epoch 2 with validation loss: 0.0632
[Epoch 3, Batch 100] loss: 0.04790850169025362
[Epoch 3, Batch 200] loss: 0.05648138195567299
[Epoch 3, Batch 300] loss: 0.05677721780957654
[Epoch 3, Batch 400] loss: 0.053063425305299464
[Epoch 3, Batch 500] loss: 0.04409819330088794
[Epoch 3, Batch 600] loss: 0.04923394311335869
[Epoch 3, Batch 700] loss: 0.060652493592351676
[Epoch 3, Batch 800] loss: 0.045660892615560444
[Epoch 3, Batch 900] loss: 0.04989189050043933
[Epoch 3, Batch 1000] loss: 0.06145106020849198
[Epoch 3, Batch 1100] loss: 0.06479711590218358
[Epoch 3, Batch 1200] loss: 0.0513644110725727
[Epoch 3, Batch 1300] loss: 0.05834274115855806
[Epoch 3, Batch 1400] loss: 0.05571089681820013
[Epoch 3, Batch 1500] loss: 0.050542233986780045
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9844
Overfitting: 0.0514
Best model saved at epoch 3 with validation loss: 0.0514
[Epoch 4, Batch 100] loss: 0.0386369605967775
[Epoch 4, Batch 200] loss: 0.036784716801776085
[Epoch 4, Batch 300] loss: 0.033993299726862464
[Epoch 4, Batch 400] loss: 0.04091384651022963
[Epoch 4, Batch 500] loss: 0.03985158358933404
[Epoch 4, Batch 600] loss: 0.04168688811187167
[Epoch 4, Batch 700] loss: 0.052540664184489286
[Epoch 4, Batch 800] loss: 0.04695801884168759
[Epoch 4, Batch 900] loss: 0.051482077687978745
[Epoch 4, Batch 1000] loss: 0.040415026755654254
[Epoch 4, Batch 1100] loss: 0.04471007390297018
[Epoch 4, Batch 1200] loss: 0.04370905241637956
[Epoch 4, Batch 1300] loss: 0.035778648177802096
[Epoch 4, Batch 1400] loss: 0.03668073605222162
[Epoch 4, Batch 1500] loss: 0.04659768524783431
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0566
Validation Accuracy: 0.9827
Overfitting: 0.0566
[Epoch 5, Batch 100] loss: 0.032135438468540084
[Epoch 5, Batch 200] loss: 0.026134971977444365
[Epoch 5, Batch 300] loss: 0.025667668961104936
[Epoch 5, Batch 400] loss: 0.04313405788270756
[Epoch 5, Batch 500] loss: 0.03799618457444012
[Epoch 5, Batch 600] loss: 0.029168661311268808
[Epoch 5, Batch 700] loss: 0.03386599793215282
[Epoch 5, Batch 800] loss: 0.041649249665788375
[Epoch 5, Batch 900] loss: 0.03811356196005363
[Epoch 5, Batch 1000] loss: 0.022772371229948477
[Epoch 5, Batch 1100] loss: 0.0327664522579289
[Epoch 5, Batch 1200] loss: 0.03705023285234347
[Epoch 5, Batch 1300] loss: 0.03242461007263046
[Epoch 5, Batch 1400] loss: 0.03649407612567302
[Epoch 5, Batch 1500] loss: 0.03509463609167142
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9838
Overfitting: 0.0526
[Epoch 6, Batch 100] loss: 0.032724272786290386
[Epoch 6, Batch 200] loss: 0.026370603794348427
[Epoch 6, Batch 300] loss: 0.03378717815154232
[Epoch 6, Batch 400] loss: 0.027348501915694216
[Epoch 6, Batch 500] loss: 0.027258798401308012
[Epoch 6, Batch 600] loss: 0.025880009082902687
[Epoch 6, Batch 700] loss: 0.027239787670550866
[Epoch 6, Batch 800] loss: 0.024446326265169772
[Epoch 6, Batch 900] loss: 0.03578932331060059
[Epoch 6, Batch 1000] loss: 0.026438141088874545
[Epoch 6, Batch 1100] loss: 0.030724643053254112
[Epoch 6, Batch 1200] loss: 0.029861845413397533
[Epoch 6, Batch 1300] loss: 0.030702543417573905
[Epoch 6, Batch 1400] loss: 0.020048007465084082
[Epoch 6, Batch 1500] loss: 0.02541185994108673
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0454
Validation Accuracy: 0.9870
Overfitting: 0.0454
Best model saved at epoch 6 with validation loss: 0.0454
[Epoch 7, Batch 100] loss: 0.024611910926760173
[Epoch 7, Batch 200] loss: 0.016753653548366856
[Epoch 7, Batch 300] loss: 0.02068245189875597
[Epoch 7, Batch 400] loss: 0.023254540201160124
[Epoch 7, Batch 500] loss: 0.02414134524326073
[Epoch 7, Batch 600] loss: 0.022961936355859507
[Epoch 7, Batch 700] loss: 0.023123345874992082
[Epoch 7, Batch 800] loss: 0.02997874650391168
[Epoch 7, Batch 900] loss: 0.01793286068510497
[Epoch 7, Batch 1000] loss: 0.024599621300003493
[Epoch 7, Batch 1100] loss: 0.02449989334207203
[Epoch 7, Batch 1200] loss: 0.01967665683303494
[Epoch 7, Batch 1300] loss: 0.030930025268608007
[Epoch 7, Batch 1400] loss: 0.03136643542035017
[Epoch 7, Batch 1500] loss: 0.030607336702523753
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0470
Validation Accuracy: 0.9864
Overfitting: 0.0470
[Epoch 8, Batch 100] loss: 0.023263143358635715
[Epoch 8, Batch 200] loss: 0.022187442389986246
[Epoch 8, Batch 300] loss: 0.01866146694839699
[Epoch 8, Batch 400] loss: 0.0207632067418308
[Epoch 8, Batch 500] loss: 0.02208633108624781
[Epoch 8, Batch 600] loss: 0.014103330671896402
[Epoch 8, Batch 700] loss: 0.015473654436791549
[Epoch 8, Batch 800] loss: 0.026632202888431492
[Epoch 8, Batch 900] loss: 0.022481532024248737
[Epoch 8, Batch 1000] loss: 0.025366312916448804
[Epoch 8, Batch 1100] loss: 0.020199955295101973
[Epoch 8, Batch 1200] loss: 0.014490266410284676
[Epoch 8, Batch 1300] loss: 0.016046801316879283
[Epoch 8, Batch 1400] loss: 0.01784956512208737
[Epoch 8, Batch 1500] loss: 0.014052843297067739
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0418
Validation Accuracy: 0.9870
Overfitting: 0.0418
Best model saved at epoch 8 with validation loss: 0.0418
[Epoch 9, Batch 100] loss: 0.014164157776394858
[Epoch 9, Batch 200] loss: 0.01577762491237081
[Epoch 9, Batch 300] loss: 0.017295813430973795
[Epoch 9, Batch 400] loss: 0.018401438451110152
[Epoch 9, Batch 500] loss: 0.013700350859362515
[Epoch 9, Batch 600] loss: 0.023788129615277286
[Epoch 9, Batch 700] loss: 0.01409164133714512
[Epoch 9, Batch 800] loss: 0.01889830532381893
[Epoch 9, Batch 900] loss: 0.017112544492265444
[Epoch 9, Batch 1000] loss: 0.02361821578000672
[Epoch 9, Batch 1100] loss: 0.01640131403270061
[Epoch 9, Batch 1200] loss: 0.013891189245987335
[Epoch 9, Batch 1300] loss: 0.018542219163136905
[Epoch 9, Batch 1400] loss: 0.0090358770621242
[Epoch 9, Batch 1500] loss: 0.018991347194205446
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9875
Overfitting: 0.0456
[Epoch 10, Batch 100] loss: 0.014780164781332133
[Epoch 10, Batch 200] loss: 0.013141213371454796
[Epoch 10, Batch 300] loss: 0.016723296119525912
[Epoch 10, Batch 400] loss: 0.011799236994302192
[Epoch 10, Batch 500] loss: 0.010735184178411145
[Epoch 10, Batch 600] loss: 0.010387658903055126
[Epoch 10, Batch 700] loss: 0.01758719588908207
[Epoch 10, Batch 800] loss: 0.02118724859916256
[Epoch 10, Batch 900] loss: 0.015285786312088021
[Epoch 10, Batch 1000] loss: 0.013525431104717427
[Epoch 10, Batch 1100] loss: 0.012376397433763486
[Epoch 10, Batch 1200] loss: 0.018886885293541128
[Epoch 10, Batch 1300] loss: 0.012995306245684332
[Epoch 10, Batch 1400] loss: 0.013131624317866226
[Epoch 10, Batch 1500] loss: 0.02027065681049862
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9883
Overfitting: 0.0445
[Epoch 11, Batch 100] loss: 0.008859987985997577
[Epoch 11, Batch 200] loss: 0.011836317172292183
[Epoch 11, Batch 300] loss: 0.010249037168978247
[Epoch 11, Batch 400] loss: 0.016318820638207398
[Epoch 11, Batch 500] loss: 0.007716747069171106
[Epoch 11, Batch 600] loss: 0.012830288600889616
[Epoch 11, Batch 700] loss: 0.016038758152099035
[Epoch 11, Batch 800] loss: 0.010356744692762732
[Epoch 11, Batch 900] loss: 0.011035087329382805
[Epoch 11, Batch 1000] loss: 0.016044189960589393
[Epoch 11, Batch 1100] loss: 0.01572654820905882
[Epoch 11, Batch 1200] loss: 0.009723677837555442
[Epoch 11, Batch 1300] loss: 0.011140444988341188
[Epoch 11, Batch 1400] loss: 0.012185680429274726
[Epoch 11, Batch 1500] loss: 0.009677209161782229
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0454
Validation Accuracy: 0.9879
Overfitting: 0.0454
[Epoch 12, Batch 100] loss: 0.006944105917882553
[Epoch 12, Batch 200] loss: 0.007273956235185324
[Epoch 12, Batch 300] loss: 0.009249081837842822
[Epoch 12, Batch 400] loss: 0.012102534069308604
[Epoch 12, Batch 500] loss: 0.009074135790560831
[Epoch 12, Batch 600] loss: 0.010409211053629406
[Epoch 12, Batch 700] loss: 0.012674656778708595
[Epoch 12, Batch 800] loss: 0.011220467934490443
[Epoch 12, Batch 900] loss: 0.00749543023912338
[Epoch 12, Batch 1000] loss: 0.017676963763115054
[Epoch 12, Batch 1100] loss: 0.013961512755631702
[Epoch 12, Batch 1200] loss: 0.018878202912092093
[Epoch 12, Batch 1300] loss: 0.012927535761537
[Epoch 12, Batch 1400] loss: 0.011705490264985201
[Epoch 12, Batch 1500] loss: 0.0127699968080924
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9872
Overfitting: 0.0477
[Epoch 13, Batch 100] loss: 0.01156119721254072
[Epoch 13, Batch 200] loss: 0.007311389502610836
[Epoch 13, Batch 300] loss: 0.014929184385182452
[Epoch 13, Batch 400] loss: 0.007890367197669548
[Epoch 13, Batch 500] loss: 0.005053037480392959
[Epoch 13, Batch 600] loss: 0.007234921891867998
[Epoch 13, Batch 700] loss: 0.007222639918436471
[Epoch 13, Batch 800] loss: 0.00747562723880037
[Epoch 13, Batch 900] loss: 0.005156810348980798
[Epoch 13, Batch 1000] loss: 0.008032660105791366
[Epoch 13, Batch 1100] loss: 0.011532113893335917
[Epoch 13, Batch 1200] loss: 0.012500850101023388
[Epoch 13, Batch 1300] loss: 0.008505791553066046
[Epoch 13, Batch 1400] loss: 0.01088854135744441
[Epoch 13, Batch 1500] loss: 0.014173859394986721
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0417
Validation Accuracy: 0.9888
Overfitting: 0.0417
Best model saved at epoch 13 with validation loss: 0.0417
[Epoch 14, Batch 100] loss: 0.0069328908012630565
[Epoch 14, Batch 200] loss: 0.009410498615034157
[Epoch 14, Batch 300] loss: 0.00736945182981799
[Epoch 14, Batch 400] loss: 0.011792857739819737
[Epoch 14, Batch 500] loss: 0.011551476689282936
[Epoch 14, Batch 600] loss: 0.008793735574110428
[Epoch 14, Batch 700] loss: 0.008483774134419945
[Epoch 14, Batch 800] loss: 0.01537714052670708
[Epoch 14, Batch 900] loss: 0.0073847929053317786
[Epoch 14, Batch 1000] loss: 0.01023442116098522
[Epoch 14, Batch 1100] loss: 0.010950425719533996
[Epoch 14, Batch 1200] loss: 0.005108031499148637
[Epoch 14, Batch 1300] loss: 0.007773498154547269
[Epoch 14, Batch 1400] loss: 0.0059432134176881845
[Epoch 14, Batch 1500] loss: 0.005841830825202124
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0431
Validation Accuracy: 0.9901
Overfitting: 0.0431
[Epoch 15, Batch 100] loss: 0.008664515750006103
[Epoch 15, Batch 200] loss: 0.004917908630711736
[Epoch 15, Batch 300] loss: 0.0069449329227063575
[Epoch 15, Batch 400] loss: 0.006844965385625983
[Epoch 15, Batch 500] loss: 0.00516518377689863
[Epoch 15, Batch 600] loss: 0.007650329233611046
[Epoch 15, Batch 700] loss: 0.008820564125094278
[Epoch 15, Batch 800] loss: 0.008830920699419948
[Epoch 15, Batch 900] loss: 0.009829240740937167
[Epoch 15, Batch 1000] loss: 0.014173379189451225
[Epoch 15, Batch 1100] loss: 0.011278352452973196
[Epoch 15, Batch 1200] loss: 0.008589578515984613
[Epoch 15, Batch 1300] loss: 0.007225267349904243
[Epoch 15, Batch 1400] loss: 0.009168027680925662
[Epoch 15, Batch 1500] loss: 0.010024885666898626
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9884
Overfitting: 0.0492
[Epoch 16, Batch 100] loss: 0.00608082491757159
[Epoch 16, Batch 200] loss: 0.010075770509074574
[Epoch 16, Batch 300] loss: 0.006259960851066353
[Epoch 16, Batch 400] loss: 0.005899298843219185
[Epoch 16, Batch 500] loss: 0.012098243975851802
[Epoch 16, Batch 600] loss: 0.006469713953288192
[Epoch 16, Batch 700] loss: 0.008104413633118384
[Epoch 16, Batch 800] loss: 0.006961946258943499
[Epoch 16, Batch 900] loss: 0.006099545804972877
[Epoch 16, Batch 1000] loss: 0.005711199534835032
[Epoch 16, Batch 1100] loss: 0.009374216612995952
[Epoch 16, Batch 1200] loss: 0.00895910399989134
[Epoch 16, Batch 1300] loss: 0.006503406897982131
[Epoch 16, Batch 1400] loss: 0.00532628206400318
[Epoch 16, Batch 1500] loss: 0.004457816717917922
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0399
Validation Accuracy: 0.9897
Overfitting: 0.0399
Best model saved at epoch 16 with validation loss: 0.0399
[Epoch 17, Batch 100] loss: 0.0016569637017710193
[Epoch 17, Batch 200] loss: 0.0025729984152167164
[Epoch 17, Batch 300] loss: 0.0033037570349574706
[Epoch 17, Batch 400] loss: 0.004216127462931354
[Epoch 17, Batch 500] loss: 0.0049643818193123935
[Epoch 17, Batch 600] loss: 0.002308727169929625
[Epoch 17, Batch 700] loss: 0.0039361896999798775
[Epoch 17, Batch 800] loss: 0.0025059527346593313
[Epoch 17, Batch 900] loss: 0.007366324288227588
[Epoch 17, Batch 1000] loss: 0.003083705704825661
[Epoch 17, Batch 1100] loss: 0.003261858778618034
[Epoch 17, Batch 1200] loss: 0.003273125941094577
[Epoch 17, Batch 1300] loss: 0.0055037438899717015
[Epoch 17, Batch 1400] loss: 0.005283528914802673
[Epoch 17, Batch 1500] loss: 0.009673928316713045
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9872
Overfitting: 0.0532
[Epoch 18, Batch 100] loss: 0.004245373522790033
[Epoch 18, Batch 200] loss: 0.00899533548061754
[Epoch 18, Batch 300] loss: 0.005948261228672891
[Epoch 18, Batch 400] loss: 0.0019333110991510694
[Epoch 18, Batch 500] loss: 0.0035298468732781886
[Epoch 18, Batch 600] loss: 0.0031513816186748045
[Epoch 18, Batch 700] loss: 0.005492161446597948
[Epoch 18, Batch 800] loss: 0.006021190669202952
[Epoch 18, Batch 900] loss: 0.004286644481132953
[Epoch 18, Batch 1000] loss: 0.005579424181401009
[Epoch 18, Batch 1100] loss: 0.0035395901946208143
[Epoch 18, Batch 1200] loss: 0.003049783057642799
[Epoch 18, Batch 1300] loss: 0.0044437599339653385
[Epoch 18, Batch 1400] loss: 0.003436259124866865
[Epoch 18, Batch 1500] loss: 0.0057630494239231216
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9902
Overfitting: 0.0466
[Epoch 19, Batch 100] loss: 0.0053411433905114335
[Epoch 19, Batch 200] loss: 0.005073886173865958
[Epoch 19, Batch 300] loss: 0.007050546218242744
[Epoch 19, Batch 400] loss: 0.0028922459863952098
[Epoch 19, Batch 500] loss: 0.006524673017993337
[Epoch 19, Batch 600] loss: 0.003526018781597031
[Epoch 19, Batch 700] loss: 0.006464065518628104
[Epoch 19, Batch 800] loss: 0.004427331146053887
[Epoch 19, Batch 900] loss: 0.003346830965624008
[Epoch 19, Batch 1000] loss: 0.0032167995534285866
[Epoch 19, Batch 1100] loss: 0.006391726108198838
[Epoch 19, Batch 1200] loss: 0.0035471706510475085
[Epoch 19, Batch 1300] loss: 0.0026869456185067975
[Epoch 19, Batch 1400] loss: 0.006592697255268831
[Epoch 19, Batch 1500] loss: 0.0069301300853828705
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9890
Overfitting: 0.0504
[Epoch 20, Batch 100] loss: 0.00474281197880714
[Epoch 20, Batch 200] loss: 0.004286353045376928
[Epoch 20, Batch 300] loss: 0.005101453658699029
[Epoch 20, Batch 400] loss: 0.003795077995466727
[Epoch 20, Batch 500] loss: 0.002429884951982331
[Epoch 20, Batch 600] loss: 0.003438342754835162
[Epoch 20, Batch 700] loss: 0.00229390875733543
[Epoch 20, Batch 800] loss: 0.002951475022084651
[Epoch 20, Batch 900] loss: 0.004272296354385077
[Epoch 20, Batch 1000] loss: 0.007373467669502247
[Epoch 20, Batch 1100] loss: 0.005968909286316375
[Epoch 20, Batch 1200] loss: 0.005026254931981384
[Epoch 20, Batch 1300] loss: 0.00608167592034107
[Epoch 20, Batch 1400] loss: 0.0016506101575168941
[Epoch 20, Batch 1500] loss: 0.005406700988919511
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0468
Validation Accuracy: 0.9900
Overfitting: 0.0468
[Epoch 21, Batch 100] loss: 0.002358768332806278
[Epoch 21, Batch 200] loss: 0.0021346817707001264
[Epoch 21, Batch 300] loss: 0.0011108633268742097
[Epoch 21, Batch 400] loss: 0.002136075706059728
[Epoch 21, Batch 500] loss: 0.001964373496480221
[Epoch 21, Batch 600] loss: 0.001833695905370405
[Epoch 21, Batch 700] loss: 0.0007377433767842944
[Epoch 21, Batch 800] loss: 0.0011355821456609761
[Epoch 21, Batch 900] loss: 0.0015644654831191928
[Epoch 21, Batch 1000] loss: 0.006878953794935967
[Epoch 21, Batch 1100] loss: 0.0033126919091137096
[Epoch 21, Batch 1200] loss: 0.0019928532748679116
[Epoch 21, Batch 1300] loss: 0.0034010576058781795
[Epoch 21, Batch 1400] loss: 0.0013128303484910475
[Epoch 21, Batch 1500] loss: 0.002723882069205388
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0462
Validation Accuracy: 0.9902
Overfitting: 0.0462
[Epoch 22, Batch 100] loss: 0.0011770476661786234
[Epoch 22, Batch 200] loss: 0.0007386052572888957
[Epoch 22, Batch 300] loss: 0.0010613433679861827
[Epoch 22, Batch 400] loss: 0.004221290071039334
[Epoch 22, Batch 500] loss: 0.004124526413181115
[Epoch 22, Batch 600] loss: 0.002015980876029175
[Epoch 22, Batch 700] loss: 0.0017925652029543925
[Epoch 22, Batch 800] loss: 0.003524659011820859
[Epoch 22, Batch 900] loss: 0.0008929285553591626
[Epoch 22, Batch 1000] loss: 0.001498703001227355
[Epoch 22, Batch 1100] loss: 0.0009281114047215056
[Epoch 22, Batch 1200] loss: 0.0024978842381693767
[Epoch 22, Batch 1300] loss: 0.0014997613931799947
[Epoch 22, Batch 1400] loss: 0.0015398639700480742
[Epoch 22, Batch 1500] loss: 0.0030926550687553345
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9885
Overfitting: 0.0535
[Epoch 23, Batch 100] loss: 0.0024900391519912545
[Epoch 23, Batch 200] loss: 0.0013847977936347889
[Epoch 23, Batch 300] loss: 0.004179431458866247
[Epoch 23, Batch 400] loss: 0.001385433757064334
[Epoch 23, Batch 500] loss: 0.0011489548106887071
[Epoch 23, Batch 600] loss: 0.0005680445355156394
[Epoch 23, Batch 700] loss: 0.0015722995237311467
[Epoch 23, Batch 800] loss: 0.0029401416879001373
[Epoch 23, Batch 900] loss: 0.0014977515820553578
[Epoch 23, Batch 1000] loss: 0.0015517651967803657
[Epoch 23, Batch 1100] loss: 0.0009496778581853782
[Epoch 23, Batch 1200] loss: 0.0017193122042459662
[Epoch 23, Batch 1300] loss: 0.004973221283995315
[Epoch 23, Batch 1400] loss: 0.0018956832102534804
[Epoch 23, Batch 1500] loss: 0.0025556138388230744
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9904
Overfitting: 0.0473
[Epoch 24, Batch 100] loss: 0.0009640065065732273
[Epoch 24, Batch 200] loss: 0.0004679156716383659
[Epoch 24, Batch 300] loss: 0.0011713010950006719
[Epoch 24, Batch 400] loss: 0.0008492294225223418
[Epoch 24, Batch 500] loss: 0.001610166062345968
[Epoch 24, Batch 600] loss: 0.0010344905631108504
[Epoch 24, Batch 700] loss: 0.0005046194004470905
[Epoch 24, Batch 800] loss: 0.0005821696328084158
[Epoch 24, Batch 900] loss: 0.0003825922072248744
[Epoch 24, Batch 1000] loss: 0.0006575455705046807
[Epoch 24, Batch 1100] loss: 0.0004859302087919559
[Epoch 24, Batch 1200] loss: 0.00039341755991092244
[Epoch 24, Batch 1300] loss: 0.0008705570388758588
[Epoch 24, Batch 1400] loss: 0.0006760086510216467
[Epoch 24, Batch 1500] loss: 0.000678783103748799
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9902
Overfitting: 0.0465
Fold 4 validation loss: 0.0465
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2442686104774476
[Epoch 1, Batch 200] loss: 1.1267960119247435
[Epoch 1, Batch 300] loss: 0.3983107215166092
[Epoch 1, Batch 400] loss: 0.29212701693177223
[Epoch 1, Batch 500] loss: 0.24343924179673196
[Epoch 1, Batch 600] loss: 0.21699823413044214
[Epoch 1, Batch 700] loss: 0.1815758502855897
[Epoch 1, Batch 800] loss: 0.17667949633672833
[Epoch 1, Batch 900] loss: 0.12698077872395516
[Epoch 1, Batch 1000] loss: 0.145111449919641
[Epoch 1, Batch 1100] loss: 0.10845963458064943
[Epoch 1, Batch 1200] loss: 0.11780526611022651
[Epoch 1, Batch 1300] loss: 0.1306931505165994
[Epoch 1, Batch 1400] loss: 0.10988545218482614
[Epoch 1, Batch 1500] loss: 0.10092861163895578
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.0997
Validation Accuracy: 0.9700
Overfitting: 0.0997
Best model saved at epoch 1 with validation loss: 0.0997
[Epoch 2, Batch 100] loss: 0.09372442033607513
[Epoch 2, Batch 200] loss: 0.10617429934442044
[Epoch 2, Batch 300] loss: 0.09489366112276912
[Epoch 2, Batch 400] loss: 0.08356129245134071
[Epoch 2, Batch 500] loss: 0.07681340762996115
[Epoch 2, Batch 600] loss: 0.08065538186812773
[Epoch 2, Batch 700] loss: 0.0732940311380662
[Epoch 2, Batch 800] loss: 0.08996463636402041
[Epoch 2, Batch 900] loss: 0.06879603568464518
[Epoch 2, Batch 1000] loss: 0.0661754706199281
[Epoch 2, Batch 1100] loss: 0.08507093162741512
[Epoch 2, Batch 1200] loss: 0.06889084403403103
[Epoch 2, Batch 1300] loss: 0.06850704956566915
[Epoch 2, Batch 1400] loss: 0.07308961383067071
[Epoch 2, Batch 1500] loss: 0.0627763150865212
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.0704
Validation Accuracy: 0.9788
Overfitting: 0.0704
Best model saved at epoch 2 with validation loss: 0.0704
[Epoch 3, Batch 100] loss: 0.05436407530331053
[Epoch 3, Batch 200] loss: 0.054692509224405515
[Epoch 3, Batch 300] loss: 0.05530463984352536
[Epoch 3, Batch 400] loss: 0.05518608240352478
[Epoch 3, Batch 500] loss: 0.0503334484109655
[Epoch 3, Batch 600] loss: 0.051410905442317016
[Epoch 3, Batch 700] loss: 0.06427392118843273
[Epoch 3, Batch 800] loss: 0.047386224715737627
[Epoch 3, Batch 900] loss: 0.05646962616883684
[Epoch 3, Batch 1000] loss: 0.06709392587421462
[Epoch 3, Batch 1100] loss: 0.0559923731017625
[Epoch 3, Batch 1200] loss: 0.06414080716436729
[Epoch 3, Batch 1300] loss: 0.056092046280391515
[Epoch 3, Batch 1400] loss: 0.051197167426289526
[Epoch 3, Batch 1500] loss: 0.05445428831910249
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9840
Overfitting: 0.0543
Best model saved at epoch 3 with validation loss: 0.0543
[Epoch 4, Batch 100] loss: 0.03907715560402721
[Epoch 4, Batch 200] loss: 0.047767291975906116
[Epoch 4, Batch 300] loss: 0.039536667746142486
[Epoch 4, Batch 400] loss: 0.04240864418825367
[Epoch 4, Batch 500] loss: 0.046285081982496194
[Epoch 4, Batch 600] loss: 0.04650282855553087
[Epoch 4, Batch 700] loss: 0.042438408794696444
[Epoch 4, Batch 800] loss: 0.04293385434255469
[Epoch 4, Batch 900] loss: 0.04405556274577975
[Epoch 4, Batch 1000] loss: 0.053156499236356465
[Epoch 4, Batch 1100] loss: 0.030624678891617806
[Epoch 4, Batch 1200] loss: 0.033835845580906604
[Epoch 4, Batch 1300] loss: 0.04105389772274066
[Epoch 4, Batch 1400] loss: 0.04801210166420788
[Epoch 4, Batch 1500] loss: 0.043496974510489964
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0590
Validation Accuracy: 0.9823
Overfitting: 0.0590
[Epoch 5, Batch 100] loss: 0.02899480174877681
[Epoch 5, Batch 200] loss: 0.021942586636650958
[Epoch 5, Batch 300] loss: 0.03599560012749862
[Epoch 5, Batch 400] loss: 0.037002820289635564
[Epoch 5, Batch 500] loss: 0.032996897649136374
[Epoch 5, Batch 600] loss: 0.028080923896923196
[Epoch 5, Batch 700] loss: 0.03839590802730527
[Epoch 5, Batch 800] loss: 0.049967280523851514
[Epoch 5, Batch 900] loss: 0.039354554142337295
[Epoch 5, Batch 1000] loss: 0.030811898069223388
[Epoch 5, Batch 1100] loss: 0.041141667834017424
[Epoch 5, Batch 1200] loss: 0.037038708044565286
[Epoch 5, Batch 1300] loss: 0.04589046828914434
[Epoch 5, Batch 1400] loss: 0.027654239922994747
[Epoch 5, Batch 1500] loss: 0.033873030837858094
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0448
Validation Accuracy: 0.9855
Overfitting: 0.0448
Best model saved at epoch 5 with validation loss: 0.0448
[Epoch 6, Batch 100] loss: 0.03205611183220754
[Epoch 6, Batch 200] loss: 0.02423908592259977
[Epoch 6, Batch 300] loss: 0.03638051702233497
[Epoch 6, Batch 400] loss: 0.025412971215846483
[Epoch 6, Batch 500] loss: 0.035398803132993636
[Epoch 6, Batch 600] loss: 0.029794692039722577
[Epoch 6, Batch 700] loss: 0.027498297761485446
[Epoch 6, Batch 800] loss: 0.03281213608424878
[Epoch 6, Batch 900] loss: 0.03660086716306978
[Epoch 6, Batch 1000] loss: 0.03238412674167193
[Epoch 6, Batch 1100] loss: 0.02710403568838956
[Epoch 6, Batch 1200] loss: 0.02828090782277286
[Epoch 6, Batch 1300] loss: 0.02474206580314785
[Epoch 6, Batch 1400] loss: 0.029323805737658405
[Epoch 6, Batch 1500] loss: 0.020623394285503308
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0407
Validation Accuracy: 0.9872
Overfitting: 0.0407
Best model saved at epoch 6 with validation loss: 0.0407
[Epoch 7, Batch 100] loss: 0.030089333108626305
[Epoch 7, Batch 200] loss: 0.02204768669384066
[Epoch 7, Batch 300] loss: 0.02159773601066263
[Epoch 7, Batch 400] loss: 0.030077655810746364
[Epoch 7, Batch 500] loss: 0.02621058111428283
[Epoch 7, Batch 600] loss: 0.027997301549476106
[Epoch 7, Batch 700] loss: 0.021814224963745802
[Epoch 7, Batch 800] loss: 0.0251565034664236
[Epoch 7, Batch 900] loss: 0.028132151423196774
[Epoch 7, Batch 1000] loss: 0.020594960938906295
[Epoch 7, Batch 1100] loss: 0.032270738969673404
[Epoch 7, Batch 1200] loss: 0.025321288638515398
[Epoch 7, Batch 1300] loss: 0.022912471746240046
[Epoch 7, Batch 1400] loss: 0.03219518349564168
[Epoch 7, Batch 1500] loss: 0.02009282446175348
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0423
Validation Accuracy: 0.9882
Overfitting: 0.0423
[Epoch 8, Batch 100] loss: 0.01934349500501412
[Epoch 8, Batch 200] loss: 0.016588848973005953
[Epoch 8, Batch 300] loss: 0.012019751866664591
[Epoch 8, Batch 400] loss: 0.01953367900721787
[Epoch 8, Batch 500] loss: 0.020989137274082168
[Epoch 8, Batch 600] loss: 0.021346194481593556
[Epoch 8, Batch 700] loss: 0.023918266916371066
[Epoch 8, Batch 800] loss: 0.023785733391305255
[Epoch 8, Batch 900] loss: 0.030760422891398777
[Epoch 8, Batch 1000] loss: 0.023290969112858873
[Epoch 8, Batch 1100] loss: 0.01514687544957269
[Epoch 8, Batch 1200] loss: 0.030687307774351212
[Epoch 8, Batch 1300] loss: 0.026441884445230244
[Epoch 8, Batch 1400] loss: 0.016169687221045025
[Epoch 8, Batch 1500] loss: 0.021430662715938523
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0403
Validation Accuracy: 0.9892
Overfitting: 0.0403
Best model saved at epoch 8 with validation loss: 0.0403
[Epoch 9, Batch 100] loss: 0.011906553446751787
[Epoch 9, Batch 200] loss: 0.019961619954847264
[Epoch 9, Batch 300] loss: 0.014659695323935011
[Epoch 9, Batch 400] loss: 0.01742669211816974
[Epoch 9, Batch 500] loss: 0.020665339517181566
[Epoch 9, Batch 600] loss: 0.022283082842477597
[Epoch 9, Batch 700] loss: 0.016023045443507727
[Epoch 9, Batch 800] loss: 0.014327410510595655
[Epoch 9, Batch 900] loss: 0.016584877029090422
[Epoch 9, Batch 1000] loss: 0.01681793597537762
[Epoch 9, Batch 1100] loss: 0.02297391647211043
[Epoch 9, Batch 1200] loss: 0.02996370828943327
[Epoch 9, Batch 1300] loss: 0.01928463396630832
[Epoch 9, Batch 1400] loss: 0.018335012312963955
[Epoch 9, Batch 1500] loss: 0.028672479126398684
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0451
Validation Accuracy: 0.9865
Overfitting: 0.0451
[Epoch 10, Batch 100] loss: 0.01869586693683232
[Epoch 10, Batch 200] loss: 0.01410365352203371
[Epoch 10, Batch 300] loss: 0.013779963257111377
[Epoch 10, Batch 400] loss: 0.011860350024617218
[Epoch 10, Batch 500] loss: 0.014499095359096827
[Epoch 10, Batch 600] loss: 0.010180897070385981
[Epoch 10, Batch 700] loss: 0.010822496176242567
[Epoch 10, Batch 800] loss: 0.01349545995653898
[Epoch 10, Batch 900] loss: 0.017781140482438788
[Epoch 10, Batch 1000] loss: 0.017455417920136825
[Epoch 10, Batch 1100] loss: 0.025633214444460463
[Epoch 10, Batch 1200] loss: 0.01895188899437926
[Epoch 10, Batch 1300] loss: 0.024965383269591256
[Epoch 10, Batch 1400] loss: 0.011645521327591269
[Epoch 10, Batch 1500] loss: 0.013311671132178161
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9873
Overfitting: 0.0484
[Epoch 11, Batch 100] loss: 0.023576206421275857
[Epoch 11, Batch 200] loss: 0.017151434136321766
[Epoch 11, Batch 300] loss: 0.015898350954812485
[Epoch 11, Batch 400] loss: 0.01189729166086181
[Epoch 11, Batch 500] loss: 0.010278642034791119
[Epoch 11, Batch 600] loss: 0.009460863850745228
[Epoch 11, Batch 700] loss: 0.012528090172963857
[Epoch 11, Batch 800] loss: 0.012457254766850383
[Epoch 11, Batch 900] loss: 0.018068955721901148
[Epoch 11, Batch 1000] loss: 0.015843383635074135
[Epoch 11, Batch 1100] loss: 0.010065097337301267
[Epoch 11, Batch 1200] loss: 0.014374753533484181
[Epoch 11, Batch 1300] loss: 0.015752091763861244
[Epoch 11, Batch 1400] loss: 0.02346490121039096
[Epoch 11, Batch 1500] loss: 0.02066270344585064
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0399
Validation Accuracy: 0.9882
Overfitting: 0.0399
Best model saved at epoch 11 with validation loss: 0.0399
[Epoch 12, Batch 100] loss: 0.006030601259226387
[Epoch 12, Batch 200] loss: 0.00870928733661458
[Epoch 12, Batch 300] loss: 0.006627415672573989
[Epoch 12, Batch 400] loss: 0.009435158417563799
[Epoch 12, Batch 500] loss: 0.014961014446307673
[Epoch 12, Batch 600] loss: 0.012749453259020811
[Epoch 12, Batch 700] loss: 0.009411692459143523
[Epoch 12, Batch 800] loss: 0.010514195684918378
[Epoch 12, Batch 900] loss: 0.01392548266765516
[Epoch 12, Batch 1000] loss: 0.012691733411775203
[Epoch 12, Batch 1100] loss: 0.015140151250816416
[Epoch 12, Batch 1200] loss: 0.01239320318974933
[Epoch 12, Batch 1300] loss: 0.013059526250381169
[Epoch 12, Batch 1400] loss: 0.016338377085521643
[Epoch 12, Batch 1500] loss: 0.00805686416773824
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.0418
Validation Accuracy: 0.9895
Overfitting: 0.0418
[Epoch 13, Batch 100] loss: 0.009666505162313115
[Epoch 13, Batch 200] loss: 0.01019213806379412
[Epoch 13, Batch 300] loss: 0.01192699844672461
[Epoch 13, Batch 400] loss: 0.009293425160649349
[Epoch 13, Batch 500] loss: 0.00973894190698047
[Epoch 13, Batch 600] loss: 0.007976554158594808
[Epoch 13, Batch 700] loss: 0.01343238977195142
[Epoch 13, Batch 800] loss: 0.010076086980843684
[Epoch 13, Batch 900] loss: 0.008189441075128343
[Epoch 13, Batch 1000] loss: 0.006673401911866677
[Epoch 13, Batch 1100] loss: 0.005704248024057961
[Epoch 13, Batch 1200] loss: 0.010592348308910005
[Epoch 13, Batch 1300] loss: 0.01035105781573293
[Epoch 13, Batch 1400] loss: 0.007829975750337326
[Epoch 13, Batch 1500] loss: 0.012241534801460148
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0444
Validation Accuracy: 0.9887
Overfitting: 0.0444
[Epoch 14, Batch 100] loss: 0.009717289974323648
[Epoch 14, Batch 200] loss: 0.007719449609066942
[Epoch 14, Batch 300] loss: 0.008031961320302799
[Epoch 14, Batch 400] loss: 0.013514122853703157
[Epoch 14, Batch 500] loss: 0.011488292617505067
[Epoch 14, Batch 600] loss: 0.015025356079240737
[Epoch 14, Batch 700] loss: 0.014156589449885359
[Epoch 14, Batch 800] loss: 0.005018647838187462
[Epoch 14, Batch 900] loss: 0.007510484190725038
[Epoch 14, Batch 1000] loss: 0.007028721299780045
[Epoch 14, Batch 1100] loss: 0.012242111026266685
[Epoch 14, Batch 1200] loss: 0.01419583050559595
[Epoch 14, Batch 1300] loss: 0.013738247025103192
[Epoch 14, Batch 1400] loss: 0.015443283968706964
[Epoch 14, Batch 1500] loss: 0.011996755203945213
**STATS for Epoch 14** : 
Average training loss: 0.0000
Average validation loss: 0.0464
Validation Accuracy: 0.9882
Overfitting: 0.0464
[Epoch 15, Batch 100] loss: 0.0071246310454807825
[Epoch 15, Batch 200] loss: 0.00788767558867221
[Epoch 15, Batch 300] loss: 0.01174823896878479
[Epoch 15, Batch 400] loss: 0.011573389301120188
[Epoch 15, Batch 500] loss: 0.005879668701127229
[Epoch 15, Batch 600] loss: 0.010748366815896589
[Epoch 15, Batch 700] loss: 0.009331209900656176
[Epoch 15, Batch 800] loss: 0.006636685144003423
[Epoch 15, Batch 900] loss: 0.005101402654145204
[Epoch 15, Batch 1000] loss: 0.00459880535029697
[Epoch 15, Batch 1100] loss: 0.009544900737892022
[Epoch 15, Batch 1200] loss: 0.006161712871667078
[Epoch 15, Batch 1300] loss: 0.014554299614928823
[Epoch 15, Batch 1400] loss: 0.008131947413239686
[Epoch 15, Batch 1500] loss: 0.006823435138830974
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0471
Validation Accuracy: 0.9890
Overfitting: 0.0471
[Epoch 16, Batch 100] loss: 0.008056338300184507
[Epoch 16, Batch 200] loss: 0.009559514228058105
[Epoch 16, Batch 300] loss: 0.007662804595493071
[Epoch 16, Batch 400] loss: 0.010177756668347228
[Epoch 16, Batch 500] loss: 0.00656049938792421
[Epoch 16, Batch 600] loss: 0.008697853114517784
[Epoch 16, Batch 700] loss: 0.006467445556556868
[Epoch 16, Batch 800] loss: 0.01046230656728312
[Epoch 16, Batch 900] loss: 0.005473214537887543
[Epoch 16, Batch 1000] loss: 0.009978945437278525
[Epoch 16, Batch 1100] loss: 0.006772387519607719
[Epoch 16, Batch 1200] loss: 0.007818920439904104
[Epoch 16, Batch 1300] loss: 0.0030655746469415135
[Epoch 16, Batch 1400] loss: 0.0035523185315196313
[Epoch 16, Batch 1500] loss: 0.0052145693381135064
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0428
Validation Accuracy: 0.9898
Overfitting: 0.0428
[Epoch 17, Batch 100] loss: 0.0032141629312150144
[Epoch 17, Batch 200] loss: 0.0036338476672472097
[Epoch 17, Batch 300] loss: 0.002640822413932256
[Epoch 17, Batch 400] loss: 0.003827291956595218
[Epoch 17, Batch 500] loss: 0.003269235566419866
[Epoch 17, Batch 600] loss: 0.005032090737977342
[Epoch 17, Batch 700] loss: 0.0024924219484182687
[Epoch 17, Batch 800] loss: 0.00797170581833143
[Epoch 17, Batch 900] loss: 0.005713776937864168
[Epoch 17, Batch 1000] loss: 0.010476725254367238
[Epoch 17, Batch 1100] loss: 0.009104992421789575
[Epoch 17, Batch 1200] loss: 0.015744534972627663
[Epoch 17, Batch 1300] loss: 0.009903294174582697
[Epoch 17, Batch 1400] loss: 0.004022144205518999
[Epoch 17, Batch 1500] loss: 0.006102258172381881
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0444
Validation Accuracy: 0.9889
Overfitting: 0.0444
[Epoch 18, Batch 100] loss: 0.0041879476346900904
[Epoch 18, Batch 200] loss: 0.002440797520439446
[Epoch 18, Batch 300] loss: 0.003825490088420338
[Epoch 18, Batch 400] loss: 0.004656367829552437
[Epoch 18, Batch 500] loss: 0.003559000846835261
[Epoch 18, Batch 600] loss: 0.007555632332478126
[Epoch 18, Batch 700] loss: 0.003926502049198461
[Epoch 18, Batch 800] loss: 0.005211127460529497
[Epoch 18, Batch 900] loss: 0.006594970404330524
[Epoch 18, Batch 1000] loss: 0.0035869275431809912
[Epoch 18, Batch 1100] loss: 0.002494484281833138
[Epoch 18, Batch 1200] loss: 0.011118103994394914
[Epoch 18, Batch 1300] loss: 0.005919828026917457
[Epoch 18, Batch 1400] loss: 0.004809781570372138
[Epoch 18, Batch 1500] loss: 0.011552758641500986
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9896
Overfitting: 0.0478
[Epoch 19, Batch 100] loss: 0.004455472365066271
[Epoch 19, Batch 200] loss: 0.005519997386891191
[Epoch 19, Batch 300] loss: 0.002656817261913602
[Epoch 19, Batch 400] loss: 0.004365108874835642
[Epoch 19, Batch 500] loss: 0.006110874966411757
[Epoch 19, Batch 600] loss: 0.002426288273678665
[Epoch 19, Batch 700] loss: 0.004406527138539787
[Epoch 19, Batch 800] loss: 0.0067672372951415125
[Epoch 19, Batch 900] loss: 0.0076641796322587654
[Epoch 19, Batch 1000] loss: 0.0047921968653281515
[Epoch 19, Batch 1100] loss: 0.0026593080218708567
[Epoch 19, Batch 1200] loss: 0.0042152917202793105
[Epoch 19, Batch 1300] loss: 0.0038188223682209354
[Epoch 19, Batch 1400] loss: 0.01003879045967551
[Epoch 19, Batch 1500] loss: 0.009397742869577997
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9901
Overfitting: 0.0446
[Epoch 20, Batch 100] loss: 0.004246548710209481
[Epoch 20, Batch 200] loss: 0.00215210916527667
[Epoch 20, Batch 300] loss: 0.002823982908769267
[Epoch 20, Batch 400] loss: 0.002135868233099245
[Epoch 20, Batch 500] loss: 0.00199576793819233
[Epoch 20, Batch 600] loss: 0.0010642172629002288
[Epoch 20, Batch 700] loss: 0.0029619435403878923
[Epoch 20, Batch 800] loss: 0.0025403952523606675
[Epoch 20, Batch 900] loss: 0.0018164268962300412
[Epoch 20, Batch 1000] loss: 0.0037129244302605002
[Epoch 20, Batch 1100] loss: 0.006492769283754569
[Epoch 20, Batch 1200] loss: 0.002981650719283948
[Epoch 20, Batch 1300] loss: 0.004479065230535753
[Epoch 20, Batch 1400] loss: 0.005409596775862156
[Epoch 20, Batch 1500] loss: 0.006451653532640194
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9872
Overfitting: 0.0560
[Epoch 21, Batch 100] loss: 0.003313384552943717
[Epoch 21, Batch 200] loss: 0.004846490347990767
[Epoch 21, Batch 300] loss: 0.002758465749361676
[Epoch 21, Batch 400] loss: 0.0010855935725965083
[Epoch 21, Batch 500] loss: 0.0012934174984457058
[Epoch 21, Batch 600] loss: 0.002133058834716621
[Epoch 21, Batch 700] loss: 0.0017871396375471705
[Epoch 21, Batch 800] loss: 0.0012876410458261488
[Epoch 21, Batch 900] loss: 0.010073458252627461
[Epoch 21, Batch 1000] loss: 0.006638815640004622
[Epoch 21, Batch 1100] loss: 0.006340412620211566
[Epoch 21, Batch 1200] loss: 0.008400731655738127
[Epoch 21, Batch 1300] loss: 0.0021317137854953215
[Epoch 21, Batch 1400] loss: 0.0037924860504654134
[Epoch 21, Batch 1500] loss: 0.001990877525486212
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9878
Overfitting: 0.0546
[Epoch 22, Batch 100] loss: 0.0018800692757767478
[Epoch 22, Batch 200] loss: 0.001082867961478655
[Epoch 22, Batch 300] loss: 0.0015424585611367547
[Epoch 22, Batch 400] loss: 0.0007423312173966679
[Epoch 22, Batch 500] loss: 0.0007059343000810259
[Epoch 22, Batch 600] loss: 0.0009853785108043668
[Epoch 22, Batch 700] loss: 0.0019427803238329488
[Epoch 22, Batch 800] loss: 0.0005242569422705401
[Epoch 22, Batch 900] loss: 0.004353619459184301
[Epoch 22, Batch 1000] loss: 0.005981895802395343
[Epoch 22, Batch 1100] loss: 0.00604571108562368
[Epoch 22, Batch 1200] loss: 0.0019627904686478816
[Epoch 22, Batch 1300] loss: 0.0023718304531456626
[Epoch 22, Batch 1400] loss: 0.004789105760345365
[Epoch 22, Batch 1500] loss: 0.001509536415045112
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9890
Overfitting: 0.0506
[Epoch 23, Batch 100] loss: 0.0021911980421640467
[Epoch 23, Batch 200] loss: 0.003032150413805539
[Epoch 23, Batch 300] loss: 0.004231301283305129
[Epoch 23, Batch 400] loss: 0.00704804678573339
[Epoch 23, Batch 500] loss: 0.0028216593482193273
[Epoch 23, Batch 600] loss: 0.0018981938305361722
[Epoch 23, Batch 700] loss: 0.005409716805396556
[Epoch 23, Batch 800] loss: 0.0019719904715191205
[Epoch 23, Batch 900] loss: 0.0050410519256706724
[Epoch 23, Batch 1000] loss: 0.0016154717102051562
[Epoch 23, Batch 1100] loss: 0.0011517820153540016
[Epoch 23, Batch 1200] loss: 0.0008446590505434415
[Epoch 23, Batch 1300] loss: 0.0013531059172396454
[Epoch 23, Batch 1400] loss: 0.0018766037431464256
[Epoch 23, Batch 1500] loss: 0.0034577570381838997
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0579
Validation Accuracy: 0.9875
Overfitting: 0.0579
[Epoch 24, Batch 100] loss: 0.001494465655142676
[Epoch 24, Batch 200] loss: 0.0011569020637656991
[Epoch 24, Batch 300] loss: 0.0018269121913510845
[Epoch 24, Batch 400] loss: 0.003534462205580553
[Epoch 24, Batch 500] loss: 0.0005805153463768064
[Epoch 24, Batch 600] loss: 0.0007581686547621303
[Epoch 24, Batch 700] loss: 0.0006008729924417367
[Epoch 24, Batch 800] loss: 0.0038395269461631186
[Epoch 24, Batch 900] loss: 0.00500851071420584
[Epoch 24, Batch 1000] loss: 0.0034239173319133443
[Epoch 24, Batch 1100] loss: 0.0029188951183149927
[Epoch 24, Batch 1200] loss: 0.005187953822119198
[Epoch 24, Batch 1300] loss: 0.007802016490612687
[Epoch 24, Batch 1400] loss: 0.006115492139893064
[Epoch 24, Batch 1500] loss: 0.0037252053105333973
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9885
Overfitting: 0.0576
Fold 5 validation loss: 0.0576
Mean validation loss across all folds for Trial 19 is 0.0537 with trial config:  l1: 256, l2: 64, lr: 0.002874012510496939, batch_size: 32
[I 2024-12-10 09:42:08,025] Trial 18 finished with value: 0.053726936440715176 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.002874012510496939, 'batch_size': 32}. Best is trial 4 with value: 0.045411968038914834.

Selected Hyperparameters for Trial 20:
  l1: 128, l2: 64, lr: 0.005268065685894675, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.042901074290276
[Epoch 1, Batch 200] loss: 0.5637381464242935
[Epoch 1, Batch 300] loss: 0.3066268244385719
[Epoch 1, Batch 400] loss: 0.22591136917471885
[Epoch 1, Batch 500] loss: 0.17883941356092692
[Epoch 1, Batch 600] loss: 0.1518434665352106
[Epoch 1, Batch 700] loss: 0.1285834133811295
**STATS for Epoch 1** : 
Average training loss: 0.0101
Average validation loss: 0.1075
Validation Accuracy: 0.9672
Overfitting: 0.0974
Best model saved at epoch 1 with validation loss: 0.1075
[Epoch 2, Batch 100] loss: 0.11231986809521914
[Epoch 2, Batch 200] loss: 0.11076829381287098
[Epoch 2, Batch 300] loss: 0.09926818751730025
[Epoch 2, Batch 400] loss: 0.09792421196587384
[Epoch 2, Batch 500] loss: 0.09512980764731765
[Epoch 2, Batch 600] loss: 0.08075975384563208
[Epoch 2, Batch 700] loss: 0.0906733843870461
**STATS for Epoch 2** : 
Average training loss: 0.0049
Average validation loss: 0.0772
Validation Accuracy: 0.9742
Overfitting: 0.0723
Best model saved at epoch 2 with validation loss: 0.0772
[Epoch 3, Batch 100] loss: 0.0698049130756408
[Epoch 3, Batch 200] loss: 0.06677318676374852
[Epoch 3, Batch 300] loss: 0.05675421403953806
[Epoch 3, Batch 400] loss: 0.06726214688271284
[Epoch 3, Batch 500] loss: 0.06769480023998767
[Epoch 3, Batch 600] loss: 0.07069228930398821
[Epoch 3, Batch 700] loss: 0.0546989099541679
**STATS for Epoch 3** : 
Average training loss: 0.0043
Average validation loss: 0.0612
Validation Accuracy: 0.9813
Overfitting: 0.0569
Best model saved at epoch 3 with validation loss: 0.0612
[Epoch 4, Batch 100] loss: 0.0495653838745784
[Epoch 4, Batch 200] loss: 0.04541732432786375
[Epoch 4, Batch 300] loss: 0.049030638553667814
[Epoch 4, Batch 400] loss: 0.061373238291125745
[Epoch 4, Batch 500] loss: 0.049309698631986976
[Epoch 4, Batch 600] loss: 0.05224776345072314
[Epoch 4, Batch 700] loss: 0.043214189342688766
**STATS for Epoch 4** : 
Average training loss: 0.0031
Average validation loss: 0.0506
Validation Accuracy: 0.9838
Overfitting: 0.0475
Best model saved at epoch 4 with validation loss: 0.0506
[Epoch 5, Batch 100] loss: 0.04558261460624635
[Epoch 5, Batch 200] loss: 0.0471336464851629
[Epoch 5, Batch 300] loss: 0.04163395985029638
[Epoch 5, Batch 400] loss: 0.04225502275687177
[Epoch 5, Batch 500] loss: 0.04203626038390212
[Epoch 5, Batch 600] loss: 0.035816002674400806
[Epoch 5, Batch 700] loss: 0.030779217448434794
**STATS for Epoch 5** : 
Average training loss: 0.0030
Average validation loss: 0.0647
Validation Accuracy: 0.9781
Overfitting: 0.0617
[Epoch 6, Batch 100] loss: 0.028122365655726754
[Epoch 6, Batch 200] loss: 0.02999935466097668
[Epoch 6, Batch 300] loss: 0.036893095651757905
[Epoch 6, Batch 400] loss: 0.03115876893745735
[Epoch 6, Batch 500] loss: 0.04463843286735937
[Epoch 6, Batch 600] loss: 0.037062984379008415
[Epoch 6, Batch 700] loss: 0.041370486349333074
**STATS for Epoch 6** : 
Average training loss: 0.0032
Average validation loss: 0.0505
Validation Accuracy: 0.9855
Overfitting: 0.0473
Best model saved at epoch 6 with validation loss: 0.0505
[Epoch 7, Batch 100] loss: 0.033513831254094836
[Epoch 7, Batch 200] loss: 0.02956043992191553
[Epoch 7, Batch 300] loss: 0.03345901267370209
[Epoch 7, Batch 400] loss: 0.029658506655832754
[Epoch 7, Batch 500] loss: 0.026085907592787408
[Epoch 7, Batch 600] loss: 0.029830726872896774
[Epoch 7, Batch 700] loss: 0.03189948407642078
**STATS for Epoch 7** : 
Average training loss: 0.0011
Average validation loss: 0.0463
Validation Accuracy: 0.9861
Overfitting: 0.0452
Best model saved at epoch 7 with validation loss: 0.0463
[Epoch 8, Batch 100] loss: 0.023559171300730666
[Epoch 8, Batch 200] loss: 0.030766352151404136
[Epoch 8, Batch 300] loss: 0.02876332006882876
[Epoch 8, Batch 400] loss: 0.021901652843225747
[Epoch 8, Batch 500] loss: 0.025551347304135563
[Epoch 8, Batch 600] loss: 0.026350428647710943
[Epoch 8, Batch 700] loss: 0.022573879832052626
**STATS for Epoch 8** : 
Average training loss: 0.0014
Average validation loss: 0.0454
Validation Accuracy: 0.9862
Overfitting: 0.0439
Best model saved at epoch 8 with validation loss: 0.0454
[Epoch 9, Batch 100] loss: 0.021691272660391406
[Epoch 9, Batch 200] loss: 0.01994133876840351
[Epoch 9, Batch 300] loss: 0.0220673005329445
[Epoch 9, Batch 400] loss: 0.02820838057086803
[Epoch 9, Batch 500] loss: 0.020404724875697867
[Epoch 9, Batch 600] loss: 0.018980353571241722
[Epoch 9, Batch 700] loss: 0.0189239678834565
**STATS for Epoch 9** : 
Average training loss: 0.0019
Average validation loss: 0.0388
Validation Accuracy: 0.9894
Overfitting: 0.0369
Best model saved at epoch 9 with validation loss: 0.0388
[Epoch 10, Batch 100] loss: 0.015017360257625114
[Epoch 10, Batch 200] loss: 0.015361548798537114
[Epoch 10, Batch 300] loss: 0.01814929331303574
[Epoch 10, Batch 400] loss: 0.02150510016872431
[Epoch 10, Batch 500] loss: 0.019242953786742872
[Epoch 10, Batch 600] loss: 0.013882098366884747
[Epoch 10, Batch 700] loss: 0.023014998554135673
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0382
Validation Accuracy: 0.9881
Overfitting: 0.0369
Best model saved at epoch 10 with validation loss: 0.0382
[Epoch 11, Batch 100] loss: 0.013759855658136075
[Epoch 11, Batch 200] loss: 0.01558839833975071
[Epoch 11, Batch 300] loss: 0.016336415440309792
[Epoch 11, Batch 400] loss: 0.019222060092142782
[Epoch 11, Batch 500] loss: 0.013983057940204163
[Epoch 11, Batch 600] loss: 0.016535391190845985
[Epoch 11, Batch 700] loss: 0.015963707189948762
**STATS for Epoch 11** : 
Average training loss: 0.0010
Average validation loss: 0.0426
Validation Accuracy: 0.9880
Overfitting: 0.0416
[Epoch 12, Batch 100] loss: 0.015554589243256487
[Epoch 12, Batch 200] loss: 0.0121512002061354
[Epoch 12, Batch 300] loss: 0.013952890775399282
[Epoch 12, Batch 400] loss: 0.008210655630173279
[Epoch 12, Batch 500] loss: 0.021517008807277308
[Epoch 12, Batch 600] loss: 0.010869982016811264
[Epoch 12, Batch 700] loss: 0.013772882341727381
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0397
Validation Accuracy: 0.9882
Overfitting: 0.0388
[Epoch 13, Batch 100] loss: 0.00882407418132061
[Epoch 13, Batch 200] loss: 0.012463001438227365
[Epoch 13, Batch 300] loss: 0.011974408678870532
[Epoch 13, Batch 400] loss: 0.012402374744269765
[Epoch 13, Batch 500] loss: 0.016977849521645112
[Epoch 13, Batch 600] loss: 0.011247171789364074
[Epoch 13, Batch 700] loss: 0.01614508000027854
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0490
Validation Accuracy: 0.9859
Overfitting: 0.0481
[Epoch 14, Batch 100] loss: 0.006489387942128815
[Epoch 14, Batch 200] loss: 0.012037902871961706
[Epoch 14, Batch 300] loss: 0.02075169658392042
[Epoch 14, Batch 400] loss: 0.011533431351563195
[Epoch 14, Batch 500] loss: 0.01259554582524288
[Epoch 14, Batch 600] loss: 0.00916075363777054
[Epoch 14, Batch 700] loss: 0.009538403894330258
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0429
Validation Accuracy: 0.9882
Overfitting: 0.0420
[Epoch 15, Batch 100] loss: 0.0094082822855853
[Epoch 15, Batch 200] loss: 0.008962844913476146
[Epoch 15, Batch 300] loss: 0.010633966265886556
[Epoch 15, Batch 400] loss: 0.01090574583868147
[Epoch 15, Batch 500] loss: 0.004668559551646467
[Epoch 15, Batch 600] loss: 0.013808756251655722
[Epoch 15, Batch 700] loss: 0.014126924566862726
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0449
Validation Accuracy: 0.9882
Overfitting: 0.0440
[Epoch 16, Batch 100] loss: 0.005447292830067454
[Epoch 16, Batch 200] loss: 0.008224720527996396
[Epoch 16, Batch 300] loss: 0.011708426361656166
[Epoch 16, Batch 400] loss: 0.0067481529579526975
[Epoch 16, Batch 500] loss: 0.010202720282049995
[Epoch 16, Batch 600] loss: 0.007586183175371844
[Epoch 16, Batch 700] loss: 0.010801027935740422
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0503
Validation Accuracy: 0.9862
Overfitting: 0.0501
[Epoch 17, Batch 100] loss: 0.0058231026669818674
[Epoch 17, Batch 200] loss: 0.004993195476254186
[Epoch 17, Batch 300] loss: 0.009055378442753862
[Epoch 17, Batch 400] loss: 0.005248322756851848
[Epoch 17, Batch 500] loss: 0.007343142302124761
[Epoch 17, Batch 600] loss: 0.00848848485169583
[Epoch 17, Batch 700] loss: 0.007026670564628148
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0444
Validation Accuracy: 0.9888
Overfitting: 0.0437
[Epoch 18, Batch 100] loss: 0.003950104020968865
[Epoch 18, Batch 200] loss: 0.002625891974021215
[Epoch 18, Batch 300] loss: 0.002982744263126733
[Epoch 18, Batch 400] loss: 0.0044483264421432975
[Epoch 18, Batch 500] loss: 0.0035365779635503714
[Epoch 18, Batch 600] loss: 0.003469870674698541
[Epoch 18, Batch 700] loss: 0.00882598654145113
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0462
Validation Accuracy: 0.9881
Overfitting: 0.0455
[Epoch 19, Batch 100] loss: 0.0021395127660798607
[Epoch 19, Batch 200] loss: 0.002902118017154862
[Epoch 19, Batch 300] loss: 0.0028768958749242303
[Epoch 19, Batch 400] loss: 0.004844097134591721
[Epoch 19, Batch 500] loss: 0.0037373965177175707
[Epoch 19, Batch 600] loss: 0.0033763725888547925
[Epoch 19, Batch 700] loss: 0.005094392497121589
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0478
Validation Accuracy: 0.9893
Overfitting: 0.0476
[Epoch 20, Batch 100] loss: 0.0020450256359617926
[Epoch 20, Batch 200] loss: 0.0019083533151933807
[Epoch 20, Batch 300] loss: 0.002034331170234509
[Epoch 20, Batch 400] loss: 0.0073814071502238225
[Epoch 20, Batch 500] loss: 0.00557718984395251
[Epoch 20, Batch 600] loss: 0.011126370460460748
[Epoch 20, Batch 700] loss: 0.017078791687144986
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0494
Validation Accuracy: 0.9870
Overfitting: 0.0490
[Epoch 21, Batch 100] loss: 0.005820664815728378
[Epoch 21, Batch 200] loss: 0.0028956871020363907
[Epoch 21, Batch 300] loss: 0.006466641161678126
[Epoch 21, Batch 400] loss: 0.009000410875542002
[Epoch 21, Batch 500] loss: 0.003954471626093437
[Epoch 21, Batch 600] loss: 0.005828432681919366
[Epoch 21, Batch 700] loss: 0.0018753110883426415
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0501
Validation Accuracy: 0.9890
Overfitting: 0.0498
[Epoch 22, Batch 100] loss: 0.0027525419761195735
[Epoch 22, Batch 200] loss: 0.001962394222173316
[Epoch 22, Batch 300] loss: 0.0029344605942537784
[Epoch 22, Batch 400] loss: 0.002107668406048333
[Epoch 22, Batch 500] loss: 0.0023367381374919203
[Epoch 22, Batch 600] loss: 0.0034416631122803666
[Epoch 22, Batch 700] loss: 0.006470495700853007
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0506
Validation Accuracy: 0.9882
Overfitting: 0.0501
[Epoch 23, Batch 100] loss: 0.002982450594334409
[Epoch 23, Batch 200] loss: 0.00397089648885526
[Epoch 23, Batch 300] loss: 0.005220548767920263
[Epoch 23, Batch 400] loss: 0.006029017162804848
[Epoch 23, Batch 500] loss: 0.016952754728536093
[Epoch 23, Batch 600] loss: 0.004778988088733058
[Epoch 23, Batch 700] loss: 0.009474860668124165
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0579
Validation Accuracy: 0.9879
Overfitting: 0.0573
[Epoch 24, Batch 100] loss: 0.009072813040043003
[Epoch 24, Batch 200] loss: 0.012367066943461395
[Epoch 24, Batch 300] loss: 0.003934980556141454
[Epoch 24, Batch 400] loss: 0.003875427884263445
[Epoch 24, Batch 500] loss: 0.004302149993236526
[Epoch 24, Batch 600] loss: 0.003866941105798105
[Epoch 24, Batch 700] loss: 0.004766068544909103
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0513
Validation Accuracy: 0.9882
Overfitting: 0.0511
Fold 1 validation loss: 0.0513
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.8736988914012909
[Epoch 1, Batch 200] loss: 0.5153809203207493
[Epoch 1, Batch 300] loss: 0.30066873140633105
[Epoch 1, Batch 400] loss: 0.20247443847358226
[Epoch 1, Batch 500] loss: 0.1809341460466385
[Epoch 1, Batch 600] loss: 0.15409207798540592
[Epoch 1, Batch 700] loss: 0.1254245677962899
**STATS for Epoch 1** : 
Average training loss: 0.0082
Average validation loss: 0.1437
Validation Accuracy: 0.9583
Overfitting: 0.1355
Best model saved at epoch 1 with validation loss: 0.1437
[Epoch 2, Batch 100] loss: 0.10311528691090643
[Epoch 2, Batch 200] loss: 0.09487729632295668
[Epoch 2, Batch 300] loss: 0.08974255563691258
[Epoch 2, Batch 400] loss: 0.08791648302227259
[Epoch 2, Batch 500] loss: 0.08070122588425875
[Epoch 2, Batch 600] loss: 0.08124585941433907
[Epoch 2, Batch 700] loss: 0.09435734412632883
**STATS for Epoch 2** : 
Average training loss: 0.0052
Average validation loss: 0.0785
Validation Accuracy: 0.9752
Overfitting: 0.0733
Best model saved at epoch 2 with validation loss: 0.0785
[Epoch 3, Batch 100] loss: 0.06462165032047779
[Epoch 3, Batch 200] loss: 0.06172043064958416
[Epoch 3, Batch 300] loss: 0.06259702397044747
[Epoch 3, Batch 400] loss: 0.05909658152144402
[Epoch 3, Batch 500] loss: 0.06012914460618049
[Epoch 3, Batch 600] loss: 0.06517353953327984
[Epoch 3, Batch 700] loss: 0.05962666631676257
**STATS for Epoch 3** : 
Average training loss: 0.0035
Average validation loss: 0.0639
Validation Accuracy: 0.9808
Overfitting: 0.0604
Best model saved at epoch 3 with validation loss: 0.0639
[Epoch 4, Batch 100] loss: 0.04250620816135779
[Epoch 4, Batch 200] loss: 0.04343970963964239
[Epoch 4, Batch 300] loss: 0.05543698317371309
[Epoch 4, Batch 400] loss: 0.040582878375425936
[Epoch 4, Batch 500] loss: 0.053581571142422034
[Epoch 4, Batch 600] loss: 0.0458175219327677
[Epoch 4, Batch 700] loss: 0.04047651664004661
**STATS for Epoch 4** : 
Average training loss: 0.0045
Average validation loss: 0.0854
Validation Accuracy: 0.9745
Overfitting: 0.0809
[Epoch 5, Batch 100] loss: 0.03682256627595052
[Epoch 5, Batch 200] loss: 0.038473759097978476
[Epoch 5, Batch 300] loss: 0.04105243270343635
[Epoch 5, Batch 400] loss: 0.0395687069860287
[Epoch 5, Batch 500] loss: 0.04092058249982074
[Epoch 5, Batch 600] loss: 0.0382667149847839
[Epoch 5, Batch 700] loss: 0.037552962936460973
**STATS for Epoch 5** : 
Average training loss: 0.0031
Average validation loss: 0.0654
Validation Accuracy: 0.9813
Overfitting: 0.0622
[Epoch 6, Batch 100] loss: 0.035538920306134966
[Epoch 6, Batch 200] loss: 0.029009645963669756
[Epoch 6, Batch 300] loss: 0.025116641848580912
[Epoch 6, Batch 400] loss: 0.03502620282873977
[Epoch 6, Batch 500] loss: 0.035250187560450286
[Epoch 6, Batch 600] loss: 0.030929433818673715
[Epoch 6, Batch 700] loss: 0.033476252714172004
**STATS for Epoch 6** : 
Average training loss: 0.0023
Average validation loss: 0.0534
Validation Accuracy: 0.9842
Overfitting: 0.0512
Best model saved at epoch 6 with validation loss: 0.0534
[Epoch 7, Batch 100] loss: 0.026575045867357403
[Epoch 7, Batch 200] loss: 0.02582436426600907
[Epoch 7, Batch 300] loss: 0.026956025793915615
[Epoch 7, Batch 400] loss: 0.035904818600974976
[Epoch 7, Batch 500] loss: 0.0246732779184822
[Epoch 7, Batch 600] loss: 0.024039860870107076
[Epoch 7, Batch 700] loss: 0.029324813947314395
**STATS for Epoch 7** : 
Average training loss: 0.0018
Average validation loss: 0.0568
Validation Accuracy: 0.9836
Overfitting: 0.0549
[Epoch 8, Batch 100] loss: 0.017546734681236558
[Epoch 8, Batch 200] loss: 0.017206837764242665
[Epoch 8, Batch 300] loss: 0.025213430623407477
[Epoch 8, Batch 400] loss: 0.021413116951589473
[Epoch 8, Batch 500] loss: 0.021137805790058337
[Epoch 8, Batch 600] loss: 0.027458111617306713
[Epoch 8, Batch 700] loss: 0.029838753027433995
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0523
Validation Accuracy: 0.9855
Overfitting: 0.0504
Best model saved at epoch 8 with validation loss: 0.0523
[Epoch 9, Batch 100] loss: 0.016806011958396993
[Epoch 9, Batch 200] loss: 0.012617646875733045
[Epoch 9, Batch 300] loss: 0.017492530966410413
[Epoch 9, Batch 400] loss: 0.019407289598020724
[Epoch 9, Batch 500] loss: 0.018397624380595515
[Epoch 9, Batch 600] loss: 0.024846924785524607
[Epoch 9, Batch 700] loss: 0.027255875137925614
**STATS for Epoch 9** : 
Average training loss: 0.0012
Average validation loss: 0.0597
Validation Accuracy: 0.9831
Overfitting: 0.0586
[Epoch 10, Batch 100] loss: 0.019048378673032856
[Epoch 10, Batch 200] loss: 0.015082350402517477
[Epoch 10, Batch 300] loss: 0.01591216015192913
[Epoch 10, Batch 400] loss: 0.01879662119274144
[Epoch 10, Batch 500] loss: 0.018742759888118597
[Epoch 10, Batch 600] loss: 0.014101221138844267
[Epoch 10, Batch 700] loss: 0.01801788316020975
**STATS for Epoch 10** : 
Average training loss: 0.0014
Average validation loss: 0.0613
Validation Accuracy: 0.9842
Overfitting: 0.0600
[Epoch 11, Batch 100] loss: 0.0161354223912349
[Epoch 11, Batch 200] loss: 0.017396309574251062
[Epoch 11, Batch 300] loss: 0.014944040364644024
[Epoch 11, Batch 400] loss: 0.014152165243940544
[Epoch 11, Batch 500] loss: 0.014366895003622631
[Epoch 11, Batch 600] loss: 0.025568612582428613
[Epoch 11, Batch 700] loss: 0.01862948077119654
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0531
Validation Accuracy: 0.9858
Overfitting: 0.0522
[Epoch 12, Batch 100] loss: 0.009920169518372858
[Epoch 12, Batch 200] loss: 0.008326049555325881
[Epoch 12, Batch 300] loss: 0.016767721161595545
[Epoch 12, Batch 400] loss: 0.012075226549350192
[Epoch 12, Batch 500] loss: 0.014724726967033348
[Epoch 12, Batch 600] loss: 0.017140667724597734
[Epoch 12, Batch 700] loss: 0.013684221495059318
**STATS for Epoch 12** : 
Average training loss: 0.0014
Average validation loss: 0.0544
Validation Accuracy: 0.9858
Overfitting: 0.0530
[Epoch 13, Batch 100] loss: 0.01035590634070104
[Epoch 13, Batch 200] loss: 0.012643102231522789
[Epoch 13, Batch 300] loss: 0.009132465922375559
[Epoch 13, Batch 400] loss: 0.011363358863600298
[Epoch 13, Batch 500] loss: 0.009395542118727462
[Epoch 13, Batch 600] loss: 0.018722511551859496
[Epoch 13, Batch 700] loss: 0.021074942422274034
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0562
Validation Accuracy: 0.9859
Overfitting: 0.0548
[Epoch 14, Batch 100] loss: 0.011019987240433692
[Epoch 14, Batch 200] loss: 0.007084830495859933
[Epoch 14, Batch 300] loss: 0.010884922029799782
[Epoch 14, Batch 400] loss: 0.015560382544936146
[Epoch 14, Batch 500] loss: 0.009679511155118234
[Epoch 14, Batch 600] loss: 0.008571810920984716
[Epoch 14, Batch 700] loss: 0.010289951608792763
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0594
Validation Accuracy: 0.9861
Overfitting: 0.0585
[Epoch 15, Batch 100] loss: 0.00528739246303303
[Epoch 15, Batch 200] loss: 0.010391777518088929
[Epoch 15, Batch 300] loss: 0.010506303074289463
[Epoch 15, Batch 400] loss: 0.010068449225946097
[Epoch 15, Batch 500] loss: 0.010487214482454875
[Epoch 15, Batch 600] loss: 0.00724641114451515
[Epoch 15, Batch 700] loss: 0.016174379949534343
**STATS for Epoch 15** : 
Average training loss: 0.0011
Average validation loss: 0.0547
Validation Accuracy: 0.9868
Overfitting: 0.0536
[Epoch 16, Batch 100] loss: 0.009141926795891778
[Epoch 16, Batch 200] loss: 0.005863071657295223
[Epoch 16, Batch 300] loss: 0.005353760032303399
[Epoch 16, Batch 400] loss: 0.006650472081046246
[Epoch 16, Batch 500] loss: 0.009051692955727048
[Epoch 16, Batch 600] loss: 0.005635940546544589
[Epoch 16, Batch 700] loss: 0.005326702038764779
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0638
Validation Accuracy: 0.9857
Overfitting: 0.0628
[Epoch 17, Batch 100] loss: 0.0035699670497706393
[Epoch 17, Batch 200] loss: 0.007097498000412088
[Epoch 17, Batch 300] loss: 0.007549773442806326
[Epoch 17, Batch 400] loss: 0.009045019754175883
[Epoch 17, Batch 500] loss: 0.009630952577026619
[Epoch 17, Batch 600] loss: 0.002937966310601041
[Epoch 17, Batch 700] loss: 0.006229279737754041
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0614
Validation Accuracy: 0.9867
Overfitting: 0.0609
[Epoch 18, Batch 100] loss: 0.00952492368998719
[Epoch 18, Batch 200] loss: 0.006284383272686682
[Epoch 18, Batch 300] loss: 0.007477540059135208
[Epoch 18, Batch 400] loss: 0.009473912044377357
[Epoch 18, Batch 500] loss: 0.007841496665496378
[Epoch 18, Batch 600] loss: 0.0056395646960572775
[Epoch 18, Batch 700] loss: 0.0041670835591867215
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0548
Validation Accuracy: 0.9880
Overfitting: 0.0547
[Epoch 19, Batch 100] loss: 0.00374271664324624
[Epoch 19, Batch 200] loss: 0.0021047679149478428
[Epoch 19, Batch 300] loss: 0.0028248883997548544
[Epoch 19, Batch 400] loss: 0.004206916330622335
[Epoch 19, Batch 500] loss: 0.006050670763561357
[Epoch 19, Batch 600] loss: 0.007188770272932743
[Epoch 19, Batch 700] loss: 0.0031195218017273873
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0602
Validation Accuracy: 0.9878
Overfitting: 0.0600
[Epoch 20, Batch 100] loss: 0.0023869642579120408
[Epoch 20, Batch 200] loss: 0.005355178911522671
[Epoch 20, Batch 300] loss: 0.004167158963336987
[Epoch 20, Batch 400] loss: 0.0026674526624992723
[Epoch 20, Batch 500] loss: 0.007083356916373304
[Epoch 20, Batch 600] loss: 0.003675234102174727
[Epoch 20, Batch 700] loss: 0.00848132190261822
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0674
Validation Accuracy: 0.9854
Overfitting: 0.0672
[Epoch 21, Batch 100] loss: 0.0044155605750620455
[Epoch 21, Batch 200] loss: 0.002776860494959692
[Epoch 21, Batch 300] loss: 0.0033180016757523843
[Epoch 21, Batch 400] loss: 0.003139542306653311
[Epoch 21, Batch 500] loss: 0.005311139514542446
[Epoch 21, Batch 600] loss: 0.00758311268657053
[Epoch 21, Batch 700] loss: 0.004655318809964229
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0654
Validation Accuracy: 0.9871
Overfitting: 0.0650
[Epoch 22, Batch 100] loss: 0.0038675371880526653
[Epoch 22, Batch 200] loss: 0.003993631721732527
[Epoch 22, Batch 300] loss: 0.005205561213224428
[Epoch 22, Batch 400] loss: 0.003061719047509541
[Epoch 22, Batch 500] loss: 0.00653685761606539
[Epoch 22, Batch 600] loss: 0.006016481724964251
[Epoch 22, Batch 700] loss: 0.0032473348101234477
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0607
Validation Accuracy: 0.9868
Overfitting: 0.0605
[Epoch 23, Batch 100] loss: 0.0019181498002740227
[Epoch 23, Batch 200] loss: 0.0007669838223250735
[Epoch 23, Batch 300] loss: 0.0016749651888858352
[Epoch 23, Batch 400] loss: 0.0027014779792148146
[Epoch 23, Batch 500] loss: 0.0038959625634925033
[Epoch 23, Batch 600] loss: 0.0027003277163294113
[Epoch 23, Batch 700] loss: 0.002227699323861998
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0661
Validation Accuracy: 0.9873
Overfitting: 0.0659
[Epoch 24, Batch 100] loss: 0.0008198434257792542
[Epoch 24, Batch 200] loss: 0.0013252149182926586
[Epoch 24, Batch 300] loss: 0.0015920327901153542
[Epoch 24, Batch 400] loss: 0.0011111389584516473
[Epoch 24, Batch 500] loss: 0.0014174987142223472
[Epoch 24, Batch 600] loss: 0.0010100602668944702
[Epoch 24, Batch 700] loss: 0.0013571191594155608
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0616
Validation Accuracy: 0.9882
Overfitting: 0.0615
Fold 2 validation loss: 0.0616
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 1.9727125442028046
[Epoch 1, Batch 200] loss: 0.48757649049162866
[Epoch 1, Batch 300] loss: 0.2694459006935358
[Epoch 1, Batch 400] loss: 0.1860978404432535
[Epoch 1, Batch 500] loss: 0.14780050786212087
[Epoch 1, Batch 600] loss: 0.13291085629723967
[Epoch 1, Batch 700] loss: 0.11959590673446656
**STATS for Epoch 1** : 
Average training loss: 0.0099
Average validation loss: 0.1083
Validation Accuracy: 0.9647
Overfitting: 0.0984
Best model saved at epoch 1 with validation loss: 0.1083
[Epoch 2, Batch 100] loss: 0.09126088742166757
[Epoch 2, Batch 200] loss: 0.0920432355813682
[Epoch 2, Batch 300] loss: 0.07774487634189427
[Epoch 2, Batch 400] loss: 0.10334135742858053
[Epoch 2, Batch 500] loss: 0.08553235705941915
[Epoch 2, Batch 600] loss: 0.07821754205040633
[Epoch 2, Batch 700] loss: 0.07348426453769207
**STATS for Epoch 2** : 
Average training loss: 0.0050
Average validation loss: 0.0849
Validation Accuracy: 0.9736
Overfitting: 0.0799
Best model saved at epoch 2 with validation loss: 0.0849
[Epoch 3, Batch 100] loss: 0.05895909588318318
[Epoch 3, Batch 200] loss: 0.06242581510916352
[Epoch 3, Batch 300] loss: 0.06357260507531465
[Epoch 3, Batch 400] loss: 0.05585382510442287
[Epoch 3, Batch 500] loss: 0.06282746938522905
[Epoch 3, Batch 600] loss: 0.05604349377099425
[Epoch 3, Batch 700] loss: 0.06475966074503958
**STATS for Epoch 3** : 
Average training loss: 0.0051
Average validation loss: 0.0730
Validation Accuracy: 0.9764
Overfitting: 0.0678
Best model saved at epoch 3 with validation loss: 0.0730
[Epoch 4, Batch 100] loss: 0.058529068157076834
[Epoch 4, Batch 200] loss: 0.046877624726621436
[Epoch 4, Batch 300] loss: 0.047610265631228686
[Epoch 4, Batch 400] loss: 0.04467950926860795
[Epoch 4, Batch 500] loss: 0.04822924400796182
[Epoch 4, Batch 600] loss: 0.04393472936237231
[Epoch 4, Batch 700] loss: 0.03900752346846275
**STATS for Epoch 4** : 
Average training loss: 0.0032
Average validation loss: 0.0568
Validation Accuracy: 0.9826
Overfitting: 0.0536
Best model saved at epoch 4 with validation loss: 0.0568
[Epoch 5, Batch 100] loss: 0.037416271906113255
[Epoch 5, Batch 200] loss: 0.04340228020271752
[Epoch 5, Batch 300] loss: 0.04086114121018909
[Epoch 5, Batch 400] loss: 0.039856693594483655
[Epoch 5, Batch 500] loss: 0.03632399141904898
[Epoch 5, Batch 600] loss: 0.04445793205755763
[Epoch 5, Batch 700] loss: 0.041734904373297466
**STATS for Epoch 5** : 
Average training loss: 0.0025
Average validation loss: 0.0585
Validation Accuracy: 0.9815
Overfitting: 0.0560
[Epoch 6, Batch 100] loss: 0.03194648386037443
[Epoch 6, Batch 200] loss: 0.03416221765684895
[Epoch 6, Batch 300] loss: 0.0297698101750575
[Epoch 6, Batch 400] loss: 0.03068597439036239
[Epoch 6, Batch 500] loss: 0.030290840662783012
[Epoch 6, Batch 600] loss: 0.03901993124862201
[Epoch 6, Batch 700] loss: 0.03414678345550783
**STATS for Epoch 6** : 
Average training loss: 0.0029
Average validation loss: 0.0489
Validation Accuracy: 0.9852
Overfitting: 0.0461
Best model saved at epoch 6 with validation loss: 0.0489
[Epoch 7, Batch 100] loss: 0.028064452739199622
[Epoch 7, Batch 200] loss: 0.028898218389367684
[Epoch 7, Batch 300] loss: 0.026111838309734594
[Epoch 7, Batch 400] loss: 0.028733400031924247
[Epoch 7, Batch 500] loss: 0.03871042507700622
[Epoch 7, Batch 600] loss: 0.02298374044999946
[Epoch 7, Batch 700] loss: 0.03223338087671437
**STATS for Epoch 7** : 
Average training loss: 0.0027
Average validation loss: 0.0687
Validation Accuracy: 0.9790
Overfitting: 0.0659
[Epoch 8, Batch 100] loss: 0.02575987356947735
[Epoch 8, Batch 200] loss: 0.022727245595888235
[Epoch 8, Batch 300] loss: 0.028841427054139786
[Epoch 8, Batch 400] loss: 0.021885269944177707
[Epoch 8, Batch 500] loss: 0.024465905938413926
[Epoch 8, Batch 600] loss: 0.02530463730741758
[Epoch 8, Batch 700] loss: 0.026282262889144477
**STATS for Epoch 8** : 
Average training loss: 0.0018
Average validation loss: 0.0523
Validation Accuracy: 0.9841
Overfitting: 0.0505
[Epoch 9, Batch 100] loss: 0.014075343350996264
[Epoch 9, Batch 200] loss: 0.01900687240558909
[Epoch 9, Batch 300] loss: 0.021479691846179774
[Epoch 9, Batch 400] loss: 0.023000701440614647
[Epoch 9, Batch 500] loss: 0.027652957363170572
[Epoch 9, Batch 600] loss: 0.022057313910336232
[Epoch 9, Batch 700] loss: 0.028211228561704046
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0431
Validation Accuracy: 0.9869
Overfitting: 0.0415
Best model saved at epoch 9 with validation loss: 0.0431
[Epoch 10, Batch 100] loss: 0.021555720734177157
[Epoch 10, Batch 200] loss: 0.01777541188086616
[Epoch 10, Batch 300] loss: 0.017595310885226353
[Epoch 10, Batch 400] loss: 0.014324005703383592
[Epoch 10, Batch 500] loss: 0.01650365797308041
[Epoch 10, Batch 600] loss: 0.022468011719174685
[Epoch 10, Batch 700] loss: 0.019725446033116895
**STATS for Epoch 10** : 
Average training loss: 0.0009
Average validation loss: 0.0462
Validation Accuracy: 0.9873
Overfitting: 0.0453
[Epoch 11, Batch 100] loss: 0.014094573174370453
[Epoch 11, Batch 200] loss: 0.011790931237919721
[Epoch 11, Batch 300] loss: 0.014785802768019494
[Epoch 11, Batch 400] loss: 0.01918284069186484
[Epoch 11, Batch 500] loss: 0.016726831774867605
[Epoch 11, Batch 600] loss: 0.01992445665644482
[Epoch 11, Batch 700] loss: 0.019067126493464457
**STATS for Epoch 11** : 
Average training loss: 0.0016
Average validation loss: 0.0466
Validation Accuracy: 0.9864
Overfitting: 0.0451
[Epoch 12, Batch 100] loss: 0.014087734372005799
[Epoch 12, Batch 200] loss: 0.012205762790254085
[Epoch 12, Batch 300] loss: 0.013704126931042993
[Epoch 12, Batch 400] loss: 0.01321612165978877
[Epoch 12, Batch 500] loss: 0.013247902386210627
[Epoch 12, Batch 600] loss: 0.014784502970505854
[Epoch 12, Batch 700] loss: 0.013811587183336088
**STATS for Epoch 12** : 
Average training loss: 0.0015
Average validation loss: 0.0478
Validation Accuracy: 0.9878
Overfitting: 0.0462
[Epoch 13, Batch 100] loss: 0.009782178036039113
[Epoch 13, Batch 200] loss: 0.00751875307483715
[Epoch 13, Batch 300] loss: 0.01115771493390639
[Epoch 13, Batch 400] loss: 0.011553428726620041
[Epoch 13, Batch 500] loss: 0.008339016162499319
[Epoch 13, Batch 600] loss: 0.013289875059272163
[Epoch 13, Batch 700] loss: 0.014226249872808693
**STATS for Epoch 13** : 
Average training loss: 0.0012
Average validation loss: 0.0483
Validation Accuracy: 0.9876
Overfitting: 0.0471
[Epoch 14, Batch 100] loss: 0.009573048796737567
[Epoch 14, Batch 200] loss: 0.00937822864689224
[Epoch 14, Batch 300] loss: 0.006245314211446385
[Epoch 14, Batch 400] loss: 0.016955760944692883
[Epoch 14, Batch 500] loss: 0.016459455690710455
[Epoch 14, Batch 600] loss: 0.008498468460456933
[Epoch 14, Batch 700] loss: 0.013548703253909479
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0472
Validation Accuracy: 0.9881
Overfitting: 0.0467
[Epoch 15, Batch 100] loss: 0.00828461625482305
[Epoch 15, Batch 200] loss: 0.007361039583229285
[Epoch 15, Batch 300] loss: 0.005625251951132668
[Epoch 15, Batch 400] loss: 0.010113745057897177
[Epoch 15, Batch 500] loss: 0.012428211544920487
[Epoch 15, Batch 600] loss: 0.010613563461629383
[Epoch 15, Batch 700] loss: 0.01244180634203076
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0475
Validation Accuracy: 0.9891
Overfitting: 0.0469
[Epoch 16, Batch 100] loss: 0.0064765991324384235
[Epoch 16, Batch 200] loss: 0.007826236238761339
[Epoch 16, Batch 300] loss: 0.007010979353472066
[Epoch 16, Batch 400] loss: 0.005708771694371535
[Epoch 16, Batch 500] loss: 0.005649336099013453
[Epoch 16, Batch 600] loss: 0.011449210679113548
[Epoch 16, Batch 700] loss: 0.014225177867301682
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0558
Validation Accuracy: 0.9867
Overfitting: 0.0552
[Epoch 17, Batch 100] loss: 0.009939296628108423
[Epoch 17, Batch 200] loss: 0.007111718824889976
[Epoch 17, Batch 300] loss: 0.0033626523671409815
[Epoch 17, Batch 400] loss: 0.003972006744043029
[Epoch 17, Batch 500] loss: 0.006974978347989236
[Epoch 17, Batch 600] loss: 0.00798290556507709
[Epoch 17, Batch 700] loss: 0.00532950584871287
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0501
Validation Accuracy: 0.9876
Overfitting: 0.0494
[Epoch 18, Batch 100] loss: 0.004684177202179853
[Epoch 18, Batch 200] loss: 0.003403781039360183
[Epoch 18, Batch 300] loss: 0.003945832176505064
[Epoch 18, Batch 400] loss: 0.004272748111397959
[Epoch 18, Batch 500] loss: 0.004469563396341982
[Epoch 18, Batch 600] loss: 0.003883868039065419
[Epoch 18, Batch 700] loss: 0.00971507288162684
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0502
Validation Accuracy: 0.9870
Overfitting: 0.0499
[Epoch 19, Batch 100] loss: 0.002487668740450317
[Epoch 19, Batch 200] loss: 0.0032990354393041344
[Epoch 19, Batch 300] loss: 0.002383900795921363
[Epoch 19, Batch 400] loss: 0.003926698717186809
[Epoch 19, Batch 500] loss: 0.003366347620863053
[Epoch 19, Batch 600] loss: 0.010389467383211013
[Epoch 19, Batch 700] loss: 0.012475360418047785
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0526
Validation Accuracy: 0.9887
Overfitting: 0.0522
[Epoch 20, Batch 100] loss: 0.006832675474015559
[Epoch 20, Batch 200] loss: 0.0036865341140219243
[Epoch 20, Batch 300] loss: 0.004671248485537944
[Epoch 20, Batch 400] loss: 0.01001780968555977
[Epoch 20, Batch 500] loss: 0.0052720862381920594
[Epoch 20, Batch 600] loss: 0.004863321882203309
[Epoch 20, Batch 700] loss: 0.005542520655671979
**STATS for Epoch 20** : 
Average training loss: 0.0004
Average validation loss: 0.0595
Validation Accuracy: 0.9860
Overfitting: 0.0591
[Epoch 21, Batch 100] loss: 0.0029798101332926307
[Epoch 21, Batch 200] loss: 0.0034948293573233966
[Epoch 21, Batch 300] loss: 0.0032389615054489694
[Epoch 21, Batch 400] loss: 0.004220361560401216
[Epoch 21, Batch 500] loss: 0.004164624462346183
[Epoch 21, Batch 600] loss: 0.003716461540252567
[Epoch 21, Batch 700] loss: 0.008434676373826732
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0592
Validation Accuracy: 0.9873
Overfitting: 0.0589
[Epoch 22, Batch 100] loss: 0.00562516587522623
[Epoch 22, Batch 200] loss: 0.0016408516910905746
[Epoch 22, Batch 300] loss: 0.0013897434478349169
[Epoch 22, Batch 400] loss: 0.0022671918726882723
[Epoch 22, Batch 500] loss: 0.004417939095719703
[Epoch 22, Batch 600] loss: 0.005283971777830629
[Epoch 22, Batch 700] loss: 0.0066471850064181125
**STATS for Epoch 22** : 
Average training loss: 0.0007
Average validation loss: 0.0571
Validation Accuracy: 0.9882
Overfitting: 0.0564
[Epoch 23, Batch 100] loss: 0.006012474808449042
[Epoch 23, Batch 200] loss: 0.0027593215015804164
[Epoch 23, Batch 300] loss: 0.0029072449070190486
[Epoch 23, Batch 400] loss: 0.0034091243302555086
[Epoch 23, Batch 500] loss: 0.003373095042898058
[Epoch 23, Batch 600] loss: 0.006428552918223431
[Epoch 23, Batch 700] loss: 0.0038548900663272433
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0525
Validation Accuracy: 0.9884
Overfitting: 0.0520
[Epoch 24, Batch 100] loss: 0.0016917502427668295
[Epoch 24, Batch 200] loss: 0.0010642601733025004
[Epoch 24, Batch 300] loss: 0.001021601707471973
[Epoch 24, Batch 400] loss: 0.000943617019524936
[Epoch 24, Batch 500] loss: 0.000778645729942582
[Epoch 24, Batch 600] loss: 0.0007623219486754351
[Epoch 24, Batch 700] loss: 0.0018570453842465895
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0604
Validation Accuracy: 0.9882
Overfitting: 0.0601
Fold 3 validation loss: 0.0604
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.0020285725593565
[Epoch 1, Batch 200] loss: 0.524724932461977
[Epoch 1, Batch 300] loss: 0.2810321563482285
[Epoch 1, Batch 400] loss: 0.1931223613396287
[Epoch 1, Batch 500] loss: 0.16121592178940772
[Epoch 1, Batch 600] loss: 0.15389535769820215
[Epoch 1, Batch 700] loss: 0.1353665859811008
**STATS for Epoch 1** : 
Average training loss: 0.0078
Average validation loss: 0.0959
Validation Accuracy: 0.9684
Overfitting: 0.0881
Best model saved at epoch 1 with validation loss: 0.0959
[Epoch 2, Batch 100] loss: 0.10940590283833444
[Epoch 2, Batch 200] loss: 0.10658713534474373
[Epoch 2, Batch 300] loss: 0.10072529300116002
[Epoch 2, Batch 400] loss: 0.09227800975553692
[Epoch 2, Batch 500] loss: 0.08451125559397042
[Epoch 2, Batch 600] loss: 0.08024717366322875
[Epoch 2, Batch 700] loss: 0.08058592558372765
**STATS for Epoch 2** : 
Average training loss: 0.0048
Average validation loss: 0.0653
Validation Accuracy: 0.9798
Overfitting: 0.0604
Best model saved at epoch 2 with validation loss: 0.0653
[Epoch 3, Batch 100] loss: 0.060397833082824946
[Epoch 3, Batch 200] loss: 0.06744435756467283
[Epoch 3, Batch 300] loss: 0.0535555842705071
[Epoch 3, Batch 400] loss: 0.05723788394825533
[Epoch 3, Batch 500] loss: 0.07482237059623004
[Epoch 3, Batch 600] loss: 0.06497905019903555
[Epoch 3, Batch 700] loss: 0.06503917248221114
**STATS for Epoch 3** : 
Average training loss: 0.0039
Average validation loss: 0.0593
Validation Accuracy: 0.9812
Overfitting: 0.0554
Best model saved at epoch 3 with validation loss: 0.0593
[Epoch 4, Batch 100] loss: 0.046592950550839306
[Epoch 4, Batch 200] loss: 0.04830713025527075
[Epoch 4, Batch 300] loss: 0.054340632590465246
[Epoch 4, Batch 400] loss: 0.06161934719188139
[Epoch 4, Batch 500] loss: 0.04652760557248257
[Epoch 4, Batch 600] loss: 0.042237146195257085
[Epoch 4, Batch 700] loss: 0.05176792408456095
**STATS for Epoch 4** : 
Average training loss: 0.0027
Average validation loss: 0.0577
Validation Accuracy: 0.9830
Overfitting: 0.0550
Best model saved at epoch 4 with validation loss: 0.0577
[Epoch 5, Batch 100] loss: 0.044812517487443984
[Epoch 5, Batch 200] loss: 0.040878572301007804
[Epoch 5, Batch 300] loss: 0.04487840532325208
[Epoch 5, Batch 400] loss: 0.04287342904601246
[Epoch 5, Batch 500] loss: 0.04313117047888227
[Epoch 5, Batch 600] loss: 0.03280039080011193
[Epoch 5, Batch 700] loss: 0.03674904140876606
**STATS for Epoch 5** : 
Average training loss: 0.0035
Average validation loss: 0.0519
Validation Accuracy: 0.9840
Overfitting: 0.0483
Best model saved at epoch 5 with validation loss: 0.0519
[Epoch 6, Batch 100] loss: 0.035379607232753185
[Epoch 6, Batch 200] loss: 0.040905706709017976
[Epoch 6, Batch 300] loss: 0.028791521358070896
[Epoch 6, Batch 400] loss: 0.033154897039930804
[Epoch 6, Batch 500] loss: 0.03523529975442216
[Epoch 6, Batch 600] loss: 0.032555874220561234
[Epoch 6, Batch 700] loss: 0.030580189862521364
**STATS for Epoch 6** : 
Average training loss: 0.0020
Average validation loss: 0.0533
Validation Accuracy: 0.9829
Overfitting: 0.0513
[Epoch 7, Batch 100] loss: 0.02865658820141107
[Epoch 7, Batch 200] loss: 0.027921029122080655
[Epoch 7, Batch 300] loss: 0.026469907520804553
[Epoch 7, Batch 400] loss: 0.03111633333086502
[Epoch 7, Batch 500] loss: 0.03322420517448336
[Epoch 7, Batch 600] loss: 0.031189470021636224
[Epoch 7, Batch 700] loss: 0.03962829181808047
**STATS for Epoch 7** : 
Average training loss: 0.0017
Average validation loss: 0.0507
Validation Accuracy: 0.9851
Overfitting: 0.0490
Best model saved at epoch 7 with validation loss: 0.0507
[Epoch 8, Batch 100] loss: 0.019435034409398214
[Epoch 8, Batch 200] loss: 0.024194217767799273
[Epoch 8, Batch 300] loss: 0.02634473994083237
[Epoch 8, Batch 400] loss: 0.03242389693943551
[Epoch 8, Batch 500] loss: 0.023279496872564778
[Epoch 8, Batch 600] loss: 0.026421987723442727
[Epoch 8, Batch 700] loss: 0.02756021248991601
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0435
Validation Accuracy: 0.9870
Overfitting: 0.0415
Best model saved at epoch 8 with validation loss: 0.0435
[Epoch 9, Batch 100] loss: 0.020295407635858284
[Epoch 9, Batch 200] loss: 0.023108881299267522
[Epoch 9, Batch 300] loss: 0.023378422598470935
[Epoch 9, Batch 400] loss: 0.02588731112802634
[Epoch 9, Batch 500] loss: 0.022097132453345693
[Epoch 9, Batch 600] loss: 0.0199402476195246
[Epoch 9, Batch 700] loss: 0.024076279702130707
**STATS for Epoch 9** : 
Average training loss: 0.0011
Average validation loss: 0.0424
Validation Accuracy: 0.9879
Overfitting: 0.0414
Best model saved at epoch 9 with validation loss: 0.0424
[Epoch 10, Batch 100] loss: 0.01561927777249366
[Epoch 10, Batch 200] loss: 0.017745044775365384
[Epoch 10, Batch 300] loss: 0.017813549007987605
[Epoch 10, Batch 400] loss: 0.019219672061444724
[Epoch 10, Batch 500] loss: 0.013922210050805007
[Epoch 10, Batch 600] loss: 0.02179615755827399
[Epoch 10, Batch 700] loss: 0.020250445764395407
**STATS for Epoch 10** : 
Average training loss: 0.0031
Average validation loss: 0.0493
Validation Accuracy: 0.9852
Overfitting: 0.0462
[Epoch 11, Batch 100] loss: 0.02265421125164721
[Epoch 11, Batch 200] loss: 0.01725660244381288
[Epoch 11, Batch 300] loss: 0.01943014383025002
[Epoch 11, Batch 400] loss: 0.015119731798768044
[Epoch 11, Batch 500] loss: 0.01903576798024005
[Epoch 11, Batch 600] loss: 0.01598776221740991
[Epoch 11, Batch 700] loss: 0.01873613940202631
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0580
Validation Accuracy: 0.9840
Overfitting: 0.0568
[Epoch 12, Batch 100] loss: 0.013292545777949272
[Epoch 12, Batch 200] loss: 0.016772699442226438
[Epoch 12, Batch 300] loss: 0.014053865590540227
[Epoch 12, Batch 400] loss: 0.018553878540551523
[Epoch 12, Batch 500] loss: 0.01843123084574472
[Epoch 12, Batch 600] loss: 0.013362062553642317
[Epoch 12, Batch 700] loss: 0.016143366801552473
**STATS for Epoch 12** : 
Average training loss: 0.0006
Average validation loss: 0.0419
Validation Accuracy: 0.9878
Overfitting: 0.0412
Best model saved at epoch 12 with validation loss: 0.0419
[Epoch 13, Batch 100] loss: 0.00803211600985378
[Epoch 13, Batch 200] loss: 0.012707840037255664
[Epoch 13, Batch 300] loss: 0.017669763324302038
[Epoch 13, Batch 400] loss: 0.012285847206585458
[Epoch 13, Batch 500] loss: 0.01052610463964811
[Epoch 13, Batch 600] loss: 0.017352012288974948
[Epoch 13, Batch 700] loss: 0.02087621576181846
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0430
Validation Accuracy: 0.9882
Overfitting: 0.0421
[Epoch 14, Batch 100] loss: 0.010005816840493936
[Epoch 14, Batch 200] loss: 0.007646823995601153
[Epoch 14, Batch 300] loss: 0.009356394089918467
[Epoch 14, Batch 400] loss: 0.012835365840874146
[Epoch 14, Batch 500] loss: 0.012625705532191205
[Epoch 14, Batch 600] loss: 0.018991168267384638
[Epoch 14, Batch 700] loss: 0.015848862521525005
**STATS for Epoch 14** : 
Average training loss: 0.0011
Average validation loss: 0.0578
Validation Accuracy: 0.9849
Overfitting: 0.0566
[Epoch 15, Batch 100] loss: 0.010327403529954609
[Epoch 15, Batch 200] loss: 0.012210763311741176
[Epoch 15, Batch 300] loss: 0.01395559236916597
[Epoch 15, Batch 400] loss: 0.009653669779509074
[Epoch 15, Batch 500] loss: 0.008570419108873467
[Epoch 15, Batch 600] loss: 0.00948189711827581
[Epoch 15, Batch 700] loss: 0.007919798895491112
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0463
Validation Accuracy: 0.9881
Overfitting: 0.0456
[Epoch 16, Batch 100] loss: 0.0047050115692218245
[Epoch 16, Batch 200] loss: 0.005412479761071154
[Epoch 16, Batch 300] loss: 0.013023179777846963
[Epoch 16, Batch 400] loss: 0.008790151460416382
[Epoch 16, Batch 500] loss: 0.007417014692691737
[Epoch 16, Batch 600] loss: 0.010864156035895576
[Epoch 16, Batch 700] loss: 0.013122017923597013
**STATS for Epoch 16** : 
Average training loss: 0.0012
Average validation loss: 0.0424
Validation Accuracy: 0.9882
Overfitting: 0.0412
[Epoch 17, Batch 100] loss: 0.008842935717984802
[Epoch 17, Batch 200] loss: 0.004040871019606129
[Epoch 17, Batch 300] loss: 0.007708867664873651
[Epoch 17, Batch 400] loss: 0.008413604104280239
[Epoch 17, Batch 500] loss: 0.007985842892594519
[Epoch 17, Batch 600] loss: 0.006911837181578448
[Epoch 17, Batch 700] loss: 0.007773426510902936
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0491
Validation Accuracy: 0.9878
Overfitting: 0.0487
[Epoch 18, Batch 100] loss: 0.006956624049489619
[Epoch 18, Batch 200] loss: 0.008520033618879097
[Epoch 18, Batch 300] loss: 0.005007962928939378
[Epoch 18, Batch 400] loss: 0.007284157517133281
[Epoch 18, Batch 500] loss: 0.009582839357462944
[Epoch 18, Batch 600] loss: 0.004644831469377096
[Epoch 18, Batch 700] loss: 0.005849528533017292
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0421
Validation Accuracy: 0.9894
Overfitting: 0.0418
[Epoch 19, Batch 100] loss: 0.005152723513656383
[Epoch 19, Batch 200] loss: 0.0040527787492055725
[Epoch 19, Batch 300] loss: 0.008338002416203381
[Epoch 19, Batch 400] loss: 0.0059658070050318205
[Epoch 19, Batch 500] loss: 0.0035766601698924206
[Epoch 19, Batch 600] loss: 0.006693907483986549
[Epoch 19, Batch 700] loss: 0.009996381057826511
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0492
Validation Accuracy: 0.9887
Overfitting: 0.0486
[Epoch 20, Batch 100] loss: 0.003827594688991667
[Epoch 20, Batch 200] loss: 0.0027104644960854784
[Epoch 20, Batch 300] loss: 0.003745866924036818
[Epoch 20, Batch 400] loss: 0.004308012592164232
[Epoch 20, Batch 500] loss: 0.003125432080732935
[Epoch 20, Batch 600] loss: 0.00472452023124788
[Epoch 20, Batch 700] loss: 0.006691243311724975
**STATS for Epoch 20** : 
Average training loss: 0.0007
Average validation loss: 0.0444
Validation Accuracy: 0.9888
Overfitting: 0.0437
[Epoch 21, Batch 100] loss: 0.00926975375168695
[Epoch 21, Batch 200] loss: 0.00502907953945396
[Epoch 21, Batch 300] loss: 0.003347741902816779
[Epoch 21, Batch 400] loss: 0.004425895986078104
[Epoch 21, Batch 500] loss: 0.005504925071841171
[Epoch 21, Batch 600] loss: 0.004611101538102957
[Epoch 21, Batch 700] loss: 0.0030215931705970434
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0479
Validation Accuracy: 0.9884
Overfitting: 0.0478
[Epoch 22, Batch 100] loss: 0.0036542073026430443
[Epoch 22, Batch 200] loss: 0.0042083003117113545
[Epoch 22, Batch 300] loss: 0.00519092524993539
[Epoch 22, Batch 400] loss: 0.00276423671599332
[Epoch 22, Batch 500] loss: 0.002015287596859707
[Epoch 22, Batch 600] loss: 0.002708869205443989
[Epoch 22, Batch 700] loss: 0.0040351392200636835
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0507
Validation Accuracy: 0.9878
Overfitting: 0.0503
[Epoch 23, Batch 100] loss: 0.004204659502120194
[Epoch 23, Batch 200] loss: 0.0033862782380492716
[Epoch 23, Batch 300] loss: 0.0023857593176899172
[Epoch 23, Batch 400] loss: 0.0021180025406465574
[Epoch 23, Batch 500] loss: 0.0014902197468290978
[Epoch 23, Batch 600] loss: 0.004013715645673983
[Epoch 23, Batch 700] loss: 0.0020486197418097163
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0442
Validation Accuracy: 0.9896
Overfitting: 0.0441
[Epoch 24, Batch 100] loss: 0.0022269273958841042
[Epoch 24, Batch 200] loss: 0.0027295836450309707
[Epoch 24, Batch 300] loss: 0.003599942175983415
[Epoch 24, Batch 400] loss: 0.002799990866333246
[Epoch 24, Batch 500] loss: 0.0034816372911882355
[Epoch 24, Batch 600] loss: 0.0014600344400241738
[Epoch 24, Batch 700] loss: 0.0006632480924145057
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0460
Validation Accuracy: 0.9897
Overfitting: 0.0459
Fold 4 validation loss: 0.0460
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.067433308362961
[Epoch 1, Batch 200] loss: 0.5205309285223484
[Epoch 1, Batch 300] loss: 0.2973842103779316
[Epoch 1, Batch 400] loss: 0.23433456607162953
[Epoch 1, Batch 500] loss: 0.19981919825077057
[Epoch 1, Batch 600] loss: 0.1713207046687603
[Epoch 1, Batch 700] loss: 0.12712266154587268
**STATS for Epoch 1** : 
Average training loss: 0.0089
Average validation loss: 0.1362
Validation Accuracy: 0.9596
Overfitting: 0.1273
Best model saved at epoch 1 with validation loss: 0.1362
[Epoch 2, Batch 100] loss: 0.11981322878971695
[Epoch 2, Batch 200] loss: 0.11060482850298285
[Epoch 2, Batch 300] loss: 0.10225432526320219
[Epoch 2, Batch 400] loss: 0.10456900516059249
[Epoch 2, Batch 500] loss: 0.10255483078770339
[Epoch 2, Batch 600] loss: 0.08167046319693327
[Epoch 2, Batch 700] loss: 0.08073367360047996
**STATS for Epoch 2** : 
Average training loss: 0.0057
Average validation loss: 0.0797
Validation Accuracy: 0.9763
Overfitting: 0.0740
Best model saved at epoch 2 with validation loss: 0.0797
[Epoch 3, Batch 100] loss: 0.07805638113990426
[Epoch 3, Batch 200] loss: 0.07048179855570197
[Epoch 3, Batch 300] loss: 0.06874038587324321
[Epoch 3, Batch 400] loss: 0.07302490748465061
[Epoch 3, Batch 500] loss: 0.0720120056392625
[Epoch 3, Batch 600] loss: 0.06357406026683748
[Epoch 3, Batch 700] loss: 0.06979853133670985
**STATS for Epoch 3** : 
Average training loss: 0.0046
Average validation loss: 0.0748
Validation Accuracy: 0.9783
Overfitting: 0.0701
Best model saved at epoch 3 with validation loss: 0.0748
[Epoch 4, Batch 100] loss: 0.058013298567384484
[Epoch 4, Batch 200] loss: 0.05808695121435448
[Epoch 4, Batch 300] loss: 0.05296170189976692
[Epoch 4, Batch 400] loss: 0.05365545047679916
[Epoch 4, Batch 500] loss: 0.058471764572896066
[Epoch 4, Batch 600] loss: 0.052515889527276156
[Epoch 4, Batch 700] loss: 0.053851633635349574
**STATS for Epoch 4** : 
Average training loss: 0.0044
Average validation loss: 0.0593
Validation Accuracy: 0.9819
Overfitting: 0.0548
Best model saved at epoch 4 with validation loss: 0.0593
[Epoch 5, Batch 100] loss: 0.050999283399432896
[Epoch 5, Batch 200] loss: 0.04141743929125369
[Epoch 5, Batch 300] loss: 0.04957613623235375
[Epoch 5, Batch 400] loss: 0.05121499898144975
[Epoch 5, Batch 500] loss: 0.03611985232681036
[Epoch 5, Batch 600] loss: 0.04487196727190167
[Epoch 5, Batch 700] loss: 0.04788731548469514
**STATS for Epoch 5** : 
Average training loss: 0.0022
Average validation loss: 0.0551
Validation Accuracy: 0.9835
Overfitting: 0.0529
Best model saved at epoch 5 with validation loss: 0.0551
[Epoch 6, Batch 100] loss: 0.041756892307894304
[Epoch 6, Batch 200] loss: 0.03354585576569662
[Epoch 6, Batch 300] loss: 0.046816615343559534
[Epoch 6, Batch 400] loss: 0.04064502508146688
[Epoch 6, Batch 500] loss: 0.03193280520325061
[Epoch 6, Batch 600] loss: 0.03221410820027813
[Epoch 6, Batch 700] loss: 0.04546099946135655
**STATS for Epoch 6** : 
Average training loss: 0.0024
Average validation loss: 0.0470
Validation Accuracy: 0.9862
Overfitting: 0.0447
Best model saved at epoch 6 with validation loss: 0.0470
[Epoch 7, Batch 100] loss: 0.03312827166169882
[Epoch 7, Batch 200] loss: 0.032438597473083065
[Epoch 7, Batch 300] loss: 0.027352332318550908
[Epoch 7, Batch 400] loss: 0.037689237656304615
[Epoch 7, Batch 500] loss: 0.03491395742050372
[Epoch 7, Batch 600] loss: 0.026976620860514233
[Epoch 7, Batch 700] loss: 0.03032904080231674
**STATS for Epoch 7** : 
Average training loss: 0.0028
Average validation loss: 0.0474
Validation Accuracy: 0.9861
Overfitting: 0.0446
[Epoch 8, Batch 100] loss: 0.024963529082015157
[Epoch 8, Batch 200] loss: 0.02645960130437743
[Epoch 8, Batch 300] loss: 0.027497780810808763
[Epoch 8, Batch 400] loss: 0.025838652033999095
[Epoch 8, Batch 500] loss: 0.029721960665192455
[Epoch 8, Batch 600] loss: 0.03282912406604737
[Epoch 8, Batch 700] loss: 0.027292590228607878
**STATS for Epoch 8** : 
Average training loss: 0.0017
Average validation loss: 0.0495
Validation Accuracy: 0.9850
Overfitting: 0.0477
[Epoch 9, Batch 100] loss: 0.025693386954953892
[Epoch 9, Batch 200] loss: 0.023526239483180687
[Epoch 9, Batch 300] loss: 0.028809794163826154
[Epoch 9, Batch 400] loss: 0.022683978795248548
[Epoch 9, Batch 500] loss: 0.024102761363610625
[Epoch 9, Batch 600] loss: 0.02723733685008483
[Epoch 9, Batch 700] loss: 0.025086677135550416
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0538
Validation Accuracy: 0.9842
Overfitting: 0.0521
[Epoch 10, Batch 100] loss: 0.02159147731756093
[Epoch 10, Batch 200] loss: 0.02299763752234867
[Epoch 10, Batch 300] loss: 0.023218852073041488
[Epoch 10, Batch 400] loss: 0.02511170056561241
[Epoch 10, Batch 500] loss: 0.021675066717434674
[Epoch 10, Batch 600] loss: 0.02110382898768876
[Epoch 10, Batch 700] loss: 0.021563540981151163
**STATS for Epoch 10** : 
Average training loss: 0.0018
Average validation loss: 0.0440
Validation Accuracy: 0.9872
Overfitting: 0.0423
Best model saved at epoch 10 with validation loss: 0.0440
[Epoch 11, Batch 100] loss: 0.018561339352017966
[Epoch 11, Batch 200] loss: 0.022997116184560584
[Epoch 11, Batch 300] loss: 0.017695369850262068
[Epoch 11, Batch 400] loss: 0.019878330390056362
[Epoch 11, Batch 500] loss: 0.02110054799937643
[Epoch 11, Batch 600] loss: 0.016570030096627306
[Epoch 11, Batch 700] loss: 0.020605596877576317
**STATS for Epoch 11** : 
Average training loss: 0.0008
Average validation loss: 0.0388
Validation Accuracy: 0.9890
Overfitting: 0.0379
Best model saved at epoch 11 with validation loss: 0.0388
[Epoch 12, Batch 100] loss: 0.012095335006015374
[Epoch 12, Batch 200] loss: 0.011342067166697233
[Epoch 12, Batch 300] loss: 0.020601324011804537
[Epoch 12, Batch 400] loss: 0.02020244995917892
[Epoch 12, Batch 500] loss: 0.02372534676163923
[Epoch 12, Batch 600] loss: 0.015484983538044617
[Epoch 12, Batch 700] loss: 0.01858726230857428
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0443
Validation Accuracy: 0.9878
Overfitting: 0.0431
[Epoch 13, Batch 100] loss: 0.012300462356943171
[Epoch 13, Batch 200] loss: 0.012875877464102814
[Epoch 13, Batch 300] loss: 0.01481763027186389
[Epoch 13, Batch 400] loss: 0.018523112733237212
[Epoch 13, Batch 500] loss: 0.017741571906371975
[Epoch 13, Batch 600] loss: 0.016761938220224693
[Epoch 13, Batch 700] loss: 0.01587193502993614
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0510
Validation Accuracy: 0.9863
Overfitting: 0.0501
[Epoch 14, Batch 100] loss: 0.012453536493849242
[Epoch 14, Batch 200] loss: 0.012679285900521791
[Epoch 14, Batch 300] loss: 0.015686045791080686
[Epoch 14, Batch 400] loss: 0.012743487918778556
[Epoch 14, Batch 500] loss: 0.010397790196730056
[Epoch 14, Batch 600] loss: 0.011857876270405542
[Epoch 14, Batch 700] loss: 0.013540175149828429
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0517
Validation Accuracy: 0.9860
Overfitting: 0.0510
[Epoch 15, Batch 100] loss: 0.006250061664395616
[Epoch 15, Batch 200] loss: 0.007122690778269316
[Epoch 15, Batch 300] loss: 0.010504385763852042
[Epoch 15, Batch 400] loss: 0.011764539850701113
[Epoch 15, Batch 500] loss: 0.014022388436678739
[Epoch 15, Batch 600] loss: 0.010878289448955912
[Epoch 15, Batch 700] loss: 0.019535035210356
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0463
Validation Accuracy: 0.9885
Overfitting: 0.0452
[Epoch 16, Batch 100] loss: 0.012024758270708844
[Epoch 16, Batch 200] loss: 0.007864635043879388
[Epoch 16, Batch 300] loss: 0.006617935594695154
[Epoch 16, Batch 400] loss: 0.009255575579009018
[Epoch 16, Batch 500] loss: 0.012602710267128715
[Epoch 16, Batch 600] loss: 0.016222499505456654
[Epoch 16, Batch 700] loss: 0.012400649385890574
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0457
Validation Accuracy: 0.9878
Overfitting: 0.0452
[Epoch 17, Batch 100] loss: 0.006246388011022646
[Epoch 17, Batch 200] loss: 0.008211404197500088
[Epoch 17, Batch 300] loss: 0.005373706259924802
[Epoch 17, Batch 400] loss: 0.011412831350826309
[Epoch 17, Batch 500] loss: 0.012438019282435563
[Epoch 17, Batch 600] loss: 0.011088207697830511
[Epoch 17, Batch 700] loss: 0.010726925513226888
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0488
Validation Accuracy: 0.9880
Overfitting: 0.0479
[Epoch 18, Batch 100] loss: 0.008141529308195459
[Epoch 18, Batch 200] loss: 0.00392055051484931
[Epoch 18, Batch 300] loss: 0.0038119187068059546
[Epoch 18, Batch 400] loss: 0.005420120494964067
[Epoch 18, Batch 500] loss: 0.009617517722508637
[Epoch 18, Batch 600] loss: 0.0048643627573255795
[Epoch 18, Batch 700] loss: 0.006242809850627964
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0496
Validation Accuracy: 0.9875
Overfitting: 0.0489
[Epoch 19, Batch 100] loss: 0.009906812343251659
[Epoch 19, Batch 200] loss: 0.0042166090594764685
[Epoch 19, Batch 300] loss: 0.007413181015172085
[Epoch 19, Batch 400] loss: 0.004780024588308151
[Epoch 19, Batch 500] loss: 0.005531710126706457
[Epoch 19, Batch 600] loss: 0.006730710002884734
[Epoch 19, Batch 700] loss: 0.008230294383301952
**STATS for Epoch 19** : 
Average training loss: 0.0003
Average validation loss: 0.0516
Validation Accuracy: 0.9874
Overfitting: 0.0513
[Epoch 20, Batch 100] loss: 0.006274507070338586
[Epoch 20, Batch 200] loss: 0.0073136736844753615
[Epoch 20, Batch 300] loss: 0.007534507511154516
[Epoch 20, Batch 400] loss: 0.006939221853249364
[Epoch 20, Batch 500] loss: 0.004996490667745093
[Epoch 20, Batch 600] loss: 0.005931878756546212
[Epoch 20, Batch 700] loss: 0.005692435173168633
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0493
Validation Accuracy: 0.9884
Overfitting: 0.0491
[Epoch 21, Batch 100] loss: 0.004302462215464402
[Epoch 21, Batch 200] loss: 0.003224911552069898
[Epoch 21, Batch 300] loss: 0.005534624185420398
[Epoch 21, Batch 400] loss: 0.006579428923687374
[Epoch 21, Batch 500] loss: 0.004003340537292388
[Epoch 21, Batch 600] loss: 0.004121399584792016
[Epoch 21, Batch 700] loss: 0.007678091258421773
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0538
Validation Accuracy: 0.9876
Overfitting: 0.0535
[Epoch 22, Batch 100] loss: 0.004781503239628364
[Epoch 22, Batch 200] loss: 0.0025261904101307664
[Epoch 22, Batch 300] loss: 0.003377977502891554
[Epoch 22, Batch 400] loss: 0.006102907797958324
[Epoch 22, Batch 500] loss: 0.0054163593590783425
[Epoch 22, Batch 600] loss: 0.006047752829545061
[Epoch 22, Batch 700] loss: 0.007204440338528002
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0581
Validation Accuracy: 0.9869
Overfitting: 0.0576
[Epoch 23, Batch 100] loss: 0.006479184264226206
[Epoch 23, Batch 200] loss: 0.007210254491415071
[Epoch 23, Batch 300] loss: 0.007045138977409806
[Epoch 23, Batch 400] loss: 0.0035261505960443172
[Epoch 23, Batch 500] loss: 0.0037016762343137087
[Epoch 23, Batch 600] loss: 0.004491362905982896
[Epoch 23, Batch 700] loss: 0.004073981664951134
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0557
Validation Accuracy: 0.9881
Overfitting: 0.0553
[Epoch 24, Batch 100] loss: 0.002187136824281879
[Epoch 24, Batch 200] loss: 0.0019484401289446395
[Epoch 24, Batch 300] loss: 0.0023781319970021288
[Epoch 24, Batch 400] loss: 0.00121822393934508
[Epoch 24, Batch 500] loss: 0.001213708322027287
[Epoch 24, Batch 600] loss: 0.001986080677697828
[Epoch 24, Batch 700] loss: 0.0030239149028875546
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0571
Validation Accuracy: 0.9870
Overfitting: 0.0568
Fold 5 validation loss: 0.0571
Mean validation loss across all folds for Trial 20 is 0.0553 with trial config:  l1: 128, l2: 64, lr: 0.005268065685894675, batch_size: 64
[I 2024-12-10 10:01:19,513] Trial 19 finished with value: 0.05526996820326191 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.005268065685894675, 'batch_size': 64}. Best is trial 4 with value: 0.045411968038914834.

Selected Hyperparameters for Trial 21:
  l1: 256, l2: 64, lr: 0.008320236814708993, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.6740270745754242
**STATS for Epoch 1** : 
Average training loss: 0.1523
Average validation loss: 0.2259
Validation Accuracy: 0.9318
Overfitting: 0.0736
Best model saved at epoch 1 with validation loss: 0.2259
[Epoch 2, Batch 100] loss: 0.19286536522209644
**STATS for Epoch 2** : 
Average training loss: 0.0676
Average validation loss: 0.1304
Validation Accuracy: 0.9613
Overfitting: 0.0629
Best model saved at epoch 2 with validation loss: 0.1304
[Epoch 3, Batch 100] loss: 0.11445597924292088
**STATS for Epoch 3** : 
Average training loss: 0.0449
Average validation loss: 0.0861
Validation Accuracy: 0.9727
Overfitting: 0.0412
Best model saved at epoch 3 with validation loss: 0.0861
[Epoch 4, Batch 100] loss: 0.08315153662115335
**STATS for Epoch 4** : 
Average training loss: 0.0359
Average validation loss: 0.0767
Validation Accuracy: 0.9761
Overfitting: 0.0408
Best model saved at epoch 4 with validation loss: 0.0767
[Epoch 5, Batch 100] loss: 0.06130105556920171
**STATS for Epoch 5** : 
Average training loss: 0.0327
Average validation loss: 0.0766
Validation Accuracy: 0.9760
Overfitting: 0.0440
Best model saved at epoch 5 with validation loss: 0.0766
[Epoch 6, Batch 100] loss: 0.05524794149212539
**STATS for Epoch 6** : 
Average training loss: 0.0270
Average validation loss: 0.0585
Validation Accuracy: 0.9821
Overfitting: 0.0315
Best model saved at epoch 6 with validation loss: 0.0585
[Epoch 7, Batch 100] loss: 0.04501220565289259
**STATS for Epoch 7** : 
Average training loss: 0.0240
Average validation loss: 0.0549
Validation Accuracy: 0.9827
Overfitting: 0.0308
Best model saved at epoch 7 with validation loss: 0.0549
[Epoch 8, Batch 100] loss: 0.03945847989991307
**STATS for Epoch 8** : 
Average training loss: 0.0178
Average validation loss: 0.0523
Validation Accuracy: 0.9835
Overfitting: 0.0345
Best model saved at epoch 8 with validation loss: 0.0523
[Epoch 9, Batch 100] loss: 0.03834363729692995
**STATS for Epoch 9** : 
Average training loss: 0.0161
Average validation loss: 0.0466
Validation Accuracy: 0.9868
Overfitting: 0.0305
Best model saved at epoch 9 with validation loss: 0.0466
[Epoch 10, Batch 100] loss: 0.028199605979025363
**STATS for Epoch 10** : 
Average training loss: 0.0159
Average validation loss: 0.0471
Validation Accuracy: 0.9852
Overfitting: 0.0312
[Epoch 11, Batch 100] loss: 0.026382942595519127
**STATS for Epoch 11** : 
Average training loss: 0.0156
Average validation loss: 0.0448
Validation Accuracy: 0.9862
Overfitting: 0.0292
Best model saved at epoch 11 with validation loss: 0.0448
[Epoch 12, Batch 100] loss: 0.030213692034594716
**STATS for Epoch 12** : 
Average training loss: 0.0129
Average validation loss: 0.0479
Validation Accuracy: 0.9850
Overfitting: 0.0350
[Epoch 13, Batch 100] loss: 0.023200558330863714
**STATS for Epoch 13** : 
Average training loss: 0.0125
Average validation loss: 0.0421
Validation Accuracy: 0.9877
Overfitting: 0.0296
Best model saved at epoch 13 with validation loss: 0.0421
[Epoch 14, Batch 100] loss: 0.01802034197142348
**STATS for Epoch 14** : 
Average training loss: 0.0111
Average validation loss: 0.0431
Validation Accuracy: 0.9875
Overfitting: 0.0321
[Epoch 15, Batch 100] loss: 0.01679091753787361
**STATS for Epoch 15** : 
Average training loss: 0.0084
Average validation loss: 0.0425
Validation Accuracy: 0.9882
Overfitting: 0.0341
[Epoch 16, Batch 100] loss: 0.015051380291115492
**STATS for Epoch 16** : 
Average training loss: 0.0084
Average validation loss: 0.0428
Validation Accuracy: 0.9876
Overfitting: 0.0344
[Epoch 17, Batch 100] loss: 0.013785875046160072
**STATS for Epoch 17** : 
Average training loss: 0.0080
Average validation loss: 0.0399
Validation Accuracy: 0.9885
Overfitting: 0.0319
Best model saved at epoch 17 with validation loss: 0.0399
[Epoch 18, Batch 100] loss: 0.011385485767386854
**STATS for Epoch 18** : 
Average training loss: 0.0072
Average validation loss: 0.0396
Validation Accuracy: 0.9889
Overfitting: 0.0324
Best model saved at epoch 18 with validation loss: 0.0396
[Epoch 19, Batch 100] loss: 0.012860014667967334
**STATS for Epoch 19** : 
Average training loss: 0.0048
Average validation loss: 0.0404
Validation Accuracy: 0.9892
Overfitting: 0.0356
[Epoch 20, Batch 100] loss: 0.009337014922639355
**STATS for Epoch 20** : 
Average training loss: 0.0055
Average validation loss: 0.0433
Validation Accuracy: 0.9884
Overfitting: 0.0378
[Epoch 21, Batch 100] loss: 0.009403152896557004
**STATS for Epoch 21** : 
Average training loss: 0.0048
Average validation loss: 0.0462
Validation Accuracy: 0.9868
Overfitting: 0.0414
[Epoch 22, Batch 100] loss: 0.008047448203433305
**STATS for Epoch 22** : 
Average training loss: 0.0037
Average validation loss: 0.0422
Validation Accuracy: 0.9896
Overfitting: 0.0385
[Epoch 23, Batch 100] loss: 0.007371858046390116
**STATS for Epoch 23** : 
Average training loss: 0.0034
Average validation loss: 0.0415
Validation Accuracy: 0.9896
Overfitting: 0.0381
[Epoch 24, Batch 100] loss: 0.006745082752895541
**STATS for Epoch 24** : 
Average training loss: 0.0044
Average validation loss: 0.0437
Validation Accuracy: 0.9892
Overfitting: 0.0393
Fold 1 validation loss: 0.0437
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 1.8629815739393234
**STATS for Epoch 1** : 
Average training loss: 0.1526
Average validation loss: 0.2360
Validation Accuracy: 0.9271
Overfitting: 0.0834
Best model saved at epoch 1 with validation loss: 0.2360
[Epoch 2, Batch 100] loss: 0.19104541927576066
**STATS for Epoch 2** : 
Average training loss: 0.0627
Average validation loss: 0.1300
Validation Accuracy: 0.9601
Overfitting: 0.0672
Best model saved at epoch 2 with validation loss: 0.1300
[Epoch 3, Batch 100] loss: 0.10516229558736086
**STATS for Epoch 3** : 
Average training loss: 0.0434
Average validation loss: 0.0907
Validation Accuracy: 0.9728
Overfitting: 0.0472
Best model saved at epoch 3 with validation loss: 0.0907
[Epoch 4, Batch 100] loss: 0.07464136211201548
**STATS for Epoch 4** : 
Average training loss: 0.0337
Average validation loss: 0.1083
Validation Accuracy: 0.9656
Overfitting: 0.0746
[Epoch 5, Batch 100] loss: 0.0609349031560123
**STATS for Epoch 5** : 
Average training loss: 0.0303
Average validation loss: 0.0754
Validation Accuracy: 0.9782
Overfitting: 0.0450
Best model saved at epoch 5 with validation loss: 0.0754
[Epoch 6, Batch 100] loss: 0.052458852268755435
**STATS for Epoch 6** : 
Average training loss: 0.0243
Average validation loss: 0.0687
Validation Accuracy: 0.9796
Overfitting: 0.0444
Best model saved at epoch 6 with validation loss: 0.0687
[Epoch 7, Batch 100] loss: 0.0478046902269125
**STATS for Epoch 7** : 
Average training loss: 0.0204
Average validation loss: 0.0664
Validation Accuracy: 0.9797
Overfitting: 0.0460
Best model saved at epoch 7 with validation loss: 0.0664
[Epoch 8, Batch 100] loss: 0.0413127973023802
**STATS for Epoch 8** : 
Average training loss: 0.0175
Average validation loss: 0.0635
Validation Accuracy: 0.9812
Overfitting: 0.0460
Best model saved at epoch 8 with validation loss: 0.0635
[Epoch 9, Batch 100] loss: 0.03514789013657719
**STATS for Epoch 9** : 
Average training loss: 0.0161
Average validation loss: 0.0558
Validation Accuracy: 0.9838
Overfitting: 0.0397
Best model saved at epoch 9 with validation loss: 0.0558
[Epoch 10, Batch 100] loss: 0.032391109680756924
**STATS for Epoch 10** : 
Average training loss: 0.0144
Average validation loss: 0.0556
Validation Accuracy: 0.9845
Overfitting: 0.0412
Best model saved at epoch 10 with validation loss: 0.0556
[Epoch 11, Batch 100] loss: 0.026655117850750684
**STATS for Epoch 11** : 
Average training loss: 0.0130
Average validation loss: 0.0522
Validation Accuracy: 0.9852
Overfitting: 0.0392
Best model saved at epoch 11 with validation loss: 0.0522
[Epoch 12, Batch 100] loss: 0.024512153593823315
**STATS for Epoch 12** : 
Average training loss: 0.0126
Average validation loss: 0.0488
Validation Accuracy: 0.9859
Overfitting: 0.0362
Best model saved at epoch 12 with validation loss: 0.0488
[Epoch 13, Batch 100] loss: 0.02111770286690444
**STATS for Epoch 13** : 
Average training loss: 0.0110
Average validation loss: 0.0509
Validation Accuracy: 0.9855
Overfitting: 0.0399
[Epoch 14, Batch 100] loss: 0.018406534758396445
**STATS for Epoch 14** : 
Average training loss: 0.0090
Average validation loss: 0.0550
Validation Accuracy: 0.9856
Overfitting: 0.0459
[Epoch 15, Batch 100] loss: 0.022584956204518676
**STATS for Epoch 15** : 
Average training loss: 0.0086
Average validation loss: 0.0664
Validation Accuracy: 0.9813
Overfitting: 0.0578
[Epoch 16, Batch 100] loss: 0.017530771063175053
**STATS for Epoch 16** : 
Average training loss: 0.0070
Average validation loss: 0.0524
Validation Accuracy: 0.9858
Overfitting: 0.0455
[Epoch 17, Batch 100] loss: 0.01388512275996618
**STATS for Epoch 17** : 
Average training loss: 0.0072
Average validation loss: 0.0492
Validation Accuracy: 0.9858
Overfitting: 0.0420
[Epoch 18, Batch 100] loss: 0.01405095835449174
**STATS for Epoch 18** : 
Average training loss: 0.0059
Average validation loss: 0.0565
Validation Accuracy: 0.9858
Overfitting: 0.0506
[Epoch 19, Batch 100] loss: 0.012040686355321668
**STATS for Epoch 19** : 
Average training loss: 0.0064
Average validation loss: 0.0547
Validation Accuracy: 0.9846
Overfitting: 0.0483
[Epoch 20, Batch 100] loss: 0.008876364645548165
**STATS for Epoch 20** : 
Average training loss: 0.0057
Average validation loss: 0.0562
Validation Accuracy: 0.9852
Overfitting: 0.0504
[Epoch 21, Batch 100] loss: 0.008314634923590348
**STATS for Epoch 21** : 
Average training loss: 0.0053
Average validation loss: 0.0536
Validation Accuracy: 0.9859
Overfitting: 0.0483
[Epoch 22, Batch 100] loss: 0.008093577771214768
**STATS for Epoch 22** : 
Average training loss: 0.0047
Average validation loss: 0.0523
Validation Accuracy: 0.9862
Overfitting: 0.0476
[Epoch 23, Batch 100] loss: 0.007541335244895891
**STATS for Epoch 23** : 
Average training loss: 0.0037
Average validation loss: 0.0610
Validation Accuracy: 0.9846
Overfitting: 0.0574
[Epoch 24, Batch 100] loss: 0.007243045035866089
**STATS for Epoch 24** : 
Average training loss: 0.0039
Average validation loss: 0.0527
Validation Accuracy: 0.9863
Overfitting: 0.0488
Fold 2 validation loss: 0.0527
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 1.649336841404438
**STATS for Epoch 1** : 
Average training loss: 0.1278
Average validation loss: 0.2044
Validation Accuracy: 0.9412
Overfitting: 0.0765
Best model saved at epoch 1 with validation loss: 0.2044
[Epoch 2, Batch 100] loss: 0.15995819441974163
**STATS for Epoch 2** : 
Average training loss: 0.0590
Average validation loss: 0.1061
Validation Accuracy: 0.9680
Overfitting: 0.0471
Best model saved at epoch 2 with validation loss: 0.1061
[Epoch 3, Batch 100] loss: 0.0977350953221321
**STATS for Epoch 3** : 
Average training loss: 0.0391
Average validation loss: 0.0849
Validation Accuracy: 0.9747
Overfitting: 0.0457
Best model saved at epoch 3 with validation loss: 0.0849
[Epoch 4, Batch 100] loss: 0.0735887585580349
**STATS for Epoch 4** : 
Average training loss: 0.0322
Average validation loss: 0.0743
Validation Accuracy: 0.9778
Overfitting: 0.0421
Best model saved at epoch 4 with validation loss: 0.0743
[Epoch 5, Batch 100] loss: 0.06071214256808162
**STATS for Epoch 5** : 
Average training loss: 0.0277
Average validation loss: 0.0660
Validation Accuracy: 0.9798
Overfitting: 0.0382
Best model saved at epoch 5 with validation loss: 0.0660
[Epoch 6, Batch 100] loss: 0.0506412941031158
**STATS for Epoch 6** : 
Average training loss: 0.0253
Average validation loss: 0.0696
Validation Accuracy: 0.9782
Overfitting: 0.0443
[Epoch 7, Batch 100] loss: 0.04390378907322884
**STATS for Epoch 7** : 
Average training loss: 0.0209
Average validation loss: 0.0571
Validation Accuracy: 0.9824
Overfitting: 0.0362
Best model saved at epoch 7 with validation loss: 0.0571
[Epoch 8, Batch 100] loss: 0.041528623988851904
**STATS for Epoch 8** : 
Average training loss: 0.0181
Average validation loss: 0.0618
Validation Accuracy: 0.9811
Overfitting: 0.0437
[Epoch 9, Batch 100] loss: 0.03686121724545956
**STATS for Epoch 9** : 
Average training loss: 0.0185
Average validation loss: 0.0511
Validation Accuracy: 0.9844
Overfitting: 0.0326
Best model saved at epoch 9 with validation loss: 0.0511
[Epoch 10, Batch 100] loss: 0.03512872757390142
**STATS for Epoch 10** : 
Average training loss: 0.0133
Average validation loss: 0.0486
Validation Accuracy: 0.9852
Overfitting: 0.0353
Best model saved at epoch 10 with validation loss: 0.0486
[Epoch 11, Batch 100] loss: 0.02679480943828821
**STATS for Epoch 11** : 
Average training loss: 0.0134
Average validation loss: 0.0468
Validation Accuracy: 0.9859
Overfitting: 0.0335
Best model saved at epoch 11 with validation loss: 0.0468
[Epoch 12, Batch 100] loss: 0.0261717869900167
**STATS for Epoch 12** : 
Average training loss: 0.0121
Average validation loss: 0.0479
Validation Accuracy: 0.9858
Overfitting: 0.0359
[Epoch 13, Batch 100] loss: 0.02271434053312987
**STATS for Epoch 13** : 
Average training loss: 0.0104
Average validation loss: 0.0434
Validation Accuracy: 0.9873
Overfitting: 0.0330
Best model saved at epoch 13 with validation loss: 0.0434
[Epoch 14, Batch 100] loss: 0.01895936670014635
**STATS for Epoch 14** : 
Average training loss: 0.0107
Average validation loss: 0.0715
Validation Accuracy: 0.9788
Overfitting: 0.0608
[Epoch 15, Batch 100] loss: 0.021149381704162806
**STATS for Epoch 15** : 
Average training loss: 0.0105
Average validation loss: 0.0546
Validation Accuracy: 0.9844
Overfitting: 0.0441
[Epoch 16, Batch 100] loss: 0.017119156308472157
**STATS for Epoch 16** : 
Average training loss: 0.0092
Average validation loss: 0.0444
Validation Accuracy: 0.9868
Overfitting: 0.0352
[Epoch 17, Batch 100] loss: 0.0168840856757015
**STATS for Epoch 17** : 
Average training loss: 0.0074
Average validation loss: 0.0475
Validation Accuracy: 0.9866
Overfitting: 0.0401
[Epoch 18, Batch 100] loss: 0.012989424418192357
**STATS for Epoch 18** : 
Average training loss: 0.0073
Average validation loss: 0.0476
Validation Accuracy: 0.9859
Overfitting: 0.0404
[Epoch 19, Batch 100] loss: 0.010938700848491863
**STATS for Epoch 19** : 
Average training loss: 0.0066
Average validation loss: 0.0550
Validation Accuracy: 0.9849
Overfitting: 0.0483
[Epoch 20, Batch 100] loss: 0.011933071753010154
**STATS for Epoch 20** : 
Average training loss: 0.0049
Average validation loss: 0.0449
Validation Accuracy: 0.9872
Overfitting: 0.0400
[Epoch 21, Batch 100] loss: 0.007280085142701865
**STATS for Epoch 21** : 
Average training loss: 0.0061
Average validation loss: 0.0515
Validation Accuracy: 0.9868
Overfitting: 0.0454
[Epoch 22, Batch 100] loss: 0.010270868133520707
**STATS for Epoch 22** : 
Average training loss: 0.0045
Average validation loss: 0.0474
Validation Accuracy: 0.9878
Overfitting: 0.0429
[Epoch 23, Batch 100] loss: 0.007688367647933774
**STATS for Epoch 23** : 
Average training loss: 0.0047
Average validation loss: 0.0459
Validation Accuracy: 0.9876
Overfitting: 0.0412
[Epoch 24, Batch 100] loss: 0.00906438180943951
**STATS for Epoch 24** : 
Average training loss: 0.0025
Average validation loss: 0.0448
Validation Accuracy: 0.9886
Overfitting: 0.0423
Fold 3 validation loss: 0.0448
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 1.79899807035923
**STATS for Epoch 1** : 
Average training loss: 0.1707
Average validation loss: 0.2623
Validation Accuracy: 0.9164
Overfitting: 0.0916
Best model saved at epoch 1 with validation loss: 0.2623
[Epoch 2, Batch 100] loss: 0.20232383333146572
**STATS for Epoch 2** : 
Average training loss: 0.0645
Average validation loss: 0.1369
Validation Accuracy: 0.9566
Overfitting: 0.0724
Best model saved at epoch 2 with validation loss: 0.1369
[Epoch 3, Batch 100] loss: 0.10966287326067686
**STATS for Epoch 3** : 
Average training loss: 0.0449
Average validation loss: 0.0877
Validation Accuracy: 0.9727
Overfitting: 0.0428
Best model saved at epoch 3 with validation loss: 0.0877
[Epoch 4, Batch 100] loss: 0.08617001682519913
**STATS for Epoch 4** : 
Average training loss: 0.0348
Average validation loss: 0.0753
Validation Accuracy: 0.9758
Overfitting: 0.0405
Best model saved at epoch 4 with validation loss: 0.0753
[Epoch 5, Batch 100] loss: 0.059787948541343214
**STATS for Epoch 5** : 
Average training loss: 0.0302
Average validation loss: 0.0726
Validation Accuracy: 0.9759
Overfitting: 0.0424
Best model saved at epoch 5 with validation loss: 0.0726
[Epoch 6, Batch 100] loss: 0.053238670630380514
**STATS for Epoch 6** : 
Average training loss: 0.0242
Average validation loss: 0.0580
Validation Accuracy: 0.9819
Overfitting: 0.0339
Best model saved at epoch 6 with validation loss: 0.0580
[Epoch 7, Batch 100] loss: 0.044893525186926124
**STATS for Epoch 7** : 
Average training loss: 0.0217
Average validation loss: 0.0608
Validation Accuracy: 0.9811
Overfitting: 0.0391
[Epoch 8, Batch 100] loss: 0.037696521724574265
**STATS for Epoch 8** : 
Average training loss: 0.0211
Average validation loss: 0.0520
Validation Accuracy: 0.9838
Overfitting: 0.0309
Best model saved at epoch 8 with validation loss: 0.0520
[Epoch 9, Batch 100] loss: 0.03598287572618574
**STATS for Epoch 9** : 
Average training loss: 0.0173
Average validation loss: 0.0482
Validation Accuracy: 0.9844
Overfitting: 0.0309
Best model saved at epoch 9 with validation loss: 0.0482
[Epoch 10, Batch 100] loss: 0.030643510166555643
**STATS for Epoch 10** : 
Average training loss: 0.0152
Average validation loss: 0.0611
Validation Accuracy: 0.9805
Overfitting: 0.0459
[Epoch 11, Batch 100] loss: 0.027452613022178413
**STATS for Epoch 11** : 
Average training loss: 0.0143
Average validation loss: 0.0494
Validation Accuracy: 0.9837
Overfitting: 0.0351
[Epoch 12, Batch 100] loss: 0.024942776651587336
**STATS for Epoch 12** : 
Average training loss: 0.0124
Average validation loss: 0.0453
Validation Accuracy: 0.9858
Overfitting: 0.0329
Best model saved at epoch 12 with validation loss: 0.0453
[Epoch 13, Batch 100] loss: 0.023770742234773934
**STATS for Epoch 13** : 
Average training loss: 0.0104
Average validation loss: 0.0556
Validation Accuracy: 0.9823
Overfitting: 0.0452
[Epoch 14, Batch 100] loss: 0.020165631965501234
**STATS for Epoch 14** : 
Average training loss: 0.0092
Average validation loss: 0.0458
Validation Accuracy: 0.9856
Overfitting: 0.0365
[Epoch 15, Batch 100] loss: 0.017240879884921016
**STATS for Epoch 15** : 
Average training loss: 0.0093
Average validation loss: 0.0448
Validation Accuracy: 0.9862
Overfitting: 0.0355
Best model saved at epoch 15 with validation loss: 0.0448
[Epoch 16, Batch 100] loss: 0.018504233255516738
**STATS for Epoch 16** : 
Average training loss: 0.0085
Average validation loss: 0.0474
Validation Accuracy: 0.9858
Overfitting: 0.0389
[Epoch 17, Batch 100] loss: 0.015214612495619804
**STATS for Epoch 17** : 
Average training loss: 0.0075
Average validation loss: 0.0485
Validation Accuracy: 0.9852
Overfitting: 0.0411
[Epoch 18, Batch 100] loss: 0.01318318908335641
**STATS for Epoch 18** : 
Average training loss: 0.0065
Average validation loss: 0.0495
Validation Accuracy: 0.9849
Overfitting: 0.0431
[Epoch 19, Batch 100] loss: 0.013757405506912618
**STATS for Epoch 19** : 
Average training loss: 0.0061
Average validation loss: 0.0448
Validation Accuracy: 0.9873
Overfitting: 0.0387
Best model saved at epoch 19 with validation loss: 0.0448
[Epoch 20, Batch 100] loss: 0.010381058166967706
**STATS for Epoch 20** : 
Average training loss: 0.0074
Average validation loss: 0.0499
Validation Accuracy: 0.9853
Overfitting: 0.0425
[Epoch 21, Batch 100] loss: 0.01370336340391077
**STATS for Epoch 21** : 
Average training loss: 0.0054
Average validation loss: 0.0500
Validation Accuracy: 0.9868
Overfitting: 0.0446
[Epoch 22, Batch 100] loss: 0.008964504788746126
**STATS for Epoch 22** : 
Average training loss: 0.0050
Average validation loss: 0.0469
Validation Accuracy: 0.9868
Overfitting: 0.0419
[Epoch 23, Batch 100] loss: 0.00743004510353785
**STATS for Epoch 23** : 
Average training loss: 0.0047
Average validation loss: 0.0498
Validation Accuracy: 0.9862
Overfitting: 0.0451
[Epoch 24, Batch 100] loss: 0.006851550116552971
**STATS for Epoch 24** : 
Average training loss: 0.0041
Average validation loss: 0.0467
Validation Accuracy: 0.9870
Overfitting: 0.0426
Fold 4 validation loss: 0.0467
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 1.4667952460050584
**STATS for Epoch 1** : 
Average training loss: 0.1327
Average validation loss: 0.2327
Validation Accuracy: 0.9247
Overfitting: 0.0999
Best model saved at epoch 1 with validation loss: 0.2327
[Epoch 2, Batch 100] loss: 0.1646725656837225
**STATS for Epoch 2** : 
Average training loss: 0.0592
Average validation loss: 0.1136
Validation Accuracy: 0.9663
Overfitting: 0.0544
Best model saved at epoch 2 with validation loss: 0.1136
[Epoch 3, Batch 100] loss: 0.10243427217006683
**STATS for Epoch 3** : 
Average training loss: 0.0404
Average validation loss: 0.0960
Validation Accuracy: 0.9712
Overfitting: 0.0555
Best model saved at epoch 3 with validation loss: 0.0960
[Epoch 4, Batch 100] loss: 0.07287007769569755
**STATS for Epoch 4** : 
Average training loss: 0.0323
Average validation loss: 0.0734
Validation Accuracy: 0.9782
Overfitting: 0.0411
Best model saved at epoch 4 with validation loss: 0.0734
[Epoch 5, Batch 100] loss: 0.058217606600373985
**STATS for Epoch 5** : 
Average training loss: 0.0287
Average validation loss: 0.0645
Validation Accuracy: 0.9813
Overfitting: 0.0358
Best model saved at epoch 5 with validation loss: 0.0645
[Epoch 6, Batch 100] loss: 0.05644103981554508
**STATS for Epoch 6** : 
Average training loss: 0.0219
Average validation loss: 0.0558
Validation Accuracy: 0.9828
Overfitting: 0.0340
Best model saved at epoch 6 with validation loss: 0.0558
[Epoch 7, Batch 100] loss: 0.04540971829555929
**STATS for Epoch 7** : 
Average training loss: 0.0208
Average validation loss: 0.0569
Validation Accuracy: 0.9818
Overfitting: 0.0361
[Epoch 8, Batch 100] loss: 0.03742799254134297
**STATS for Epoch 8** : 
Average training loss: 0.0204
Average validation loss: 0.0516
Validation Accuracy: 0.9842
Overfitting: 0.0312
Best model saved at epoch 8 with validation loss: 0.0516
[Epoch 9, Batch 100] loss: 0.03508362390100956
**STATS for Epoch 9** : 
Average training loss: 0.0178
Average validation loss: 0.0489
Validation Accuracy: 0.9852
Overfitting: 0.0311
Best model saved at epoch 9 with validation loss: 0.0489
[Epoch 10, Batch 100] loss: 0.031045548864640296
**STATS for Epoch 10** : 
Average training loss: 0.0173
Average validation loss: 0.0537
Validation Accuracy: 0.9836
Overfitting: 0.0363
[Epoch 11, Batch 100] loss: 0.02960281367879361
**STATS for Epoch 11** : 
Average training loss: 0.0157
Average validation loss: 0.0509
Validation Accuracy: 0.9852
Overfitting: 0.0352
[Epoch 12, Batch 100] loss: 0.0274756424408406
**STATS for Epoch 12** : 
Average training loss: 0.0123
Average validation loss: 0.0506
Validation Accuracy: 0.9844
Overfitting: 0.0383
[Epoch 13, Batch 100] loss: 0.026190172964707017
**STATS for Epoch 13** : 
Average training loss: 0.0120
Average validation loss: 0.0434
Validation Accuracy: 0.9868
Overfitting: 0.0313
Best model saved at epoch 13 with validation loss: 0.0434
[Epoch 14, Batch 100] loss: 0.023777750954031944
**STATS for Epoch 14** : 
Average training loss: 0.0111
Average validation loss: 0.0413
Validation Accuracy: 0.9871
Overfitting: 0.0301
Best model saved at epoch 14 with validation loss: 0.0413
[Epoch 15, Batch 100] loss: 0.019104813877493142
**STATS for Epoch 15** : 
Average training loss: 0.0099
Average validation loss: 0.0381
Validation Accuracy: 0.9878
Overfitting: 0.0283
Best model saved at epoch 15 with validation loss: 0.0381
[Epoch 16, Batch 100] loss: 0.01671073732897639
**STATS for Epoch 16** : 
Average training loss: 0.0094
Average validation loss: 0.0412
Validation Accuracy: 0.9881
Overfitting: 0.0317
[Epoch 17, Batch 100] loss: 0.015138953265268356
**STATS for Epoch 17** : 
Average training loss: 0.0088
Average validation loss: 0.0399
Validation Accuracy: 0.9886
Overfitting: 0.0311
[Epoch 18, Batch 100] loss: 0.014594305416103452
**STATS for Epoch 18** : 
Average training loss: 0.0077
Average validation loss: 0.0425
Validation Accuracy: 0.9887
Overfitting: 0.0348
[Epoch 19, Batch 100] loss: 0.012699188109254465
**STATS for Epoch 19** : 
Average training loss: 0.0076
Average validation loss: 0.0387
Validation Accuracy: 0.9889
Overfitting: 0.0311
[Epoch 20, Batch 100] loss: 0.01251789536443539
**STATS for Epoch 20** : 
Average training loss: 0.0059
Average validation loss: 0.0415
Validation Accuracy: 0.9888
Overfitting: 0.0356
[Epoch 21, Batch 100] loss: 0.015281710948329419
**STATS for Epoch 21** : 
Average training loss: 0.0057
Average validation loss: 0.0455
Validation Accuracy: 0.9877
Overfitting: 0.0397
[Epoch 22, Batch 100] loss: 0.009212360904784873
**STATS for Epoch 22** : 
Average training loss: 0.0050
Average validation loss: 0.0405
Validation Accuracy: 0.9886
Overfitting: 0.0355
[Epoch 23, Batch 100] loss: 0.009306206692708657
**STATS for Epoch 23** : 
Average training loss: 0.0063
Average validation loss: 0.0414
Validation Accuracy: 0.9889
Overfitting: 0.0351
[Epoch 24, Batch 100] loss: 0.00915630679577589
**STATS for Epoch 24** : 
Average training loss: 0.0039
Average validation loss: 0.0413
Validation Accuracy: 0.9884
Overfitting: 0.0374
Fold 5 validation loss: 0.0413
Mean validation loss across all folds for Trial 21 is 0.0458 with trial config:  l1: 256, l2: 64, lr: 0.008320236814708993, batch_size: 256
[I 2024-12-10 10:18:09,454] Trial 20 finished with value: 0.045844244124229126 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.008320236814708993, 'batch_size': 256}. Best is trial 4 with value: 0.045411968038914834.

Selected Hyperparameters for Trial 22:
  l1: 256, l2: 64, lr: 0.003241071743420379, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2814703130722047
**STATS for Epoch 1** : 
Average training loss: 0.7346
Average validation loss: 0.5668
Validation Accuracy: 0.8267
Overfitting: -0.1678
Best model saved at epoch 1 with validation loss: 0.5668
[Epoch 2, Batch 100] loss: 0.39623342111706733
**STATS for Epoch 2** : 
Average training loss: 0.1204
Average validation loss: 0.1922
Validation Accuracy: 0.9432
Overfitting: 0.0718
Best model saved at epoch 2 with validation loss: 0.1922
[Epoch 3, Batch 100] loss: 0.1907023488730192
**STATS for Epoch 3** : 
Average training loss: 0.0723
Average validation loss: 0.1287
Validation Accuracy: 0.9611
Overfitting: 0.0564
Best model saved at epoch 3 with validation loss: 0.1287
[Epoch 4, Batch 100] loss: 0.1347917366027832
**STATS for Epoch 4** : 
Average training loss: 0.0556
Average validation loss: 0.1126
Validation Accuracy: 0.9636
Overfitting: 0.0571
Best model saved at epoch 4 with validation loss: 0.1126
[Epoch 5, Batch 100] loss: 0.10673479910939931
**STATS for Epoch 5** : 
Average training loss: 0.0464
Average validation loss: 0.0952
Validation Accuracy: 0.9717
Overfitting: 0.0488
Best model saved at epoch 5 with validation loss: 0.0952
[Epoch 6, Batch 100] loss: 0.08782260652631521
**STATS for Epoch 6** : 
Average training loss: 0.0401
Average validation loss: 0.0775
Validation Accuracy: 0.9753
Overfitting: 0.0374
Best model saved at epoch 6 with validation loss: 0.0775
[Epoch 7, Batch 100] loss: 0.0741760329902172
**STATS for Epoch 7** : 
Average training loss: 0.0365
Average validation loss: 0.0761
Validation Accuracy: 0.9752
Overfitting: 0.0396
Best model saved at epoch 7 with validation loss: 0.0761
[Epoch 8, Batch 100] loss: 0.07257532617077231
**STATS for Epoch 8** : 
Average training loss: 0.0323
Average validation loss: 0.0681
Validation Accuracy: 0.9790
Overfitting: 0.0358
Best model saved at epoch 8 with validation loss: 0.0681
[Epoch 9, Batch 100] loss: 0.06602879056707024
**STATS for Epoch 9** : 
Average training loss: 0.0288
Average validation loss: 0.0650
Validation Accuracy: 0.9788
Overfitting: 0.0362
[I 2024-12-10 10:19:25,478] Trial 21 pruned. 

Selected Hyperparameters for Trial 23:
  l1: 256, l2: 64, lr: 0.0008111705113771299, batch_size: 128
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2938136219978333
[Epoch 1, Batch 200] loss: 2.2524047327041625
[Epoch 1, Batch 300] loss: 2.120745486021042
**STATS for Epoch 1** : 
Average training loss: 0.3272
Average validation loss: 1.2354
Validation Accuracy: 0.6915
Overfitting: 0.9082
Best model saved at epoch 1 with validation loss: 1.2354
[Epoch 2, Batch 100] loss: 0.8699279767274857
[Epoch 2, Batch 200] loss: 0.5697117984294892
[Epoch 2, Batch 300] loss: 0.4665133616328239
**STATS for Epoch 2** : 
Average training loss: 0.0819
Average validation loss: 0.3813
Validation Accuracy: 0.8857
Overfitting: 0.2994
Best model saved at epoch 2 with validation loss: 0.3813
[Epoch 3, Batch 100] loss: 0.3727774009108543
[Epoch 3, Batch 200] loss: 0.33593296855688093
[Epoch 3, Batch 300] loss: 0.3047323688864708
**STATS for Epoch 3** : 
Average training loss: 0.0575
Average validation loss: 0.2593
Validation Accuracy: 0.9197
Overfitting: 0.2019
Best model saved at epoch 3 with validation loss: 0.2593
[Epoch 4, Batch 100] loss: 0.26698240160942077
[Epoch 4, Batch 200] loss: 0.22985924169421196
[Epoch 4, Batch 300] loss: 0.23556934386491776
**STATS for Epoch 4** : 
Average training loss: 0.0407
Average validation loss: 0.1887
Validation Accuracy: 0.9437
Overfitting: 0.1480
Best model saved at epoch 4 with validation loss: 0.1887
[Epoch 5, Batch 100] loss: 0.1928307566791773
[Epoch 5, Batch 200] loss: 0.18330001533031465
[Epoch 5, Batch 300] loss: 0.18013424940407277
**STATS for Epoch 5** : 
Average training loss: 0.0323
Average validation loss: 0.1520
Validation Accuracy: 0.9536
Overfitting: 0.1196
Best model saved at epoch 5 with validation loss: 0.1520
[Epoch 6, Batch 100] loss: 0.16028884042054414
[Epoch 6, Batch 200] loss: 0.1478244448453188
[Epoch 6, Batch 300] loss: 0.14876229539513589
**STATS for Epoch 6** : 
Average training loss: 0.0285
Average validation loss: 0.1322
Validation Accuracy: 0.9583
Overfitting: 0.1037
Best model saved at epoch 6 with validation loss: 0.1322
[Epoch 7, Batch 100] loss: 0.13085893541574478
[Epoch 7, Batch 200] loss: 0.12938842125236988
[Epoch 7, Batch 300] loss: 0.1302737246081233
**STATS for Epoch 7** : 
Average training loss: 0.0240
Average validation loss: 0.1214
Validation Accuracy: 0.9635
Overfitting: 0.0974
Best model saved at epoch 7 with validation loss: 0.1214
[Epoch 8, Batch 100] loss: 0.11896312773227692
[Epoch 8, Batch 200] loss: 0.11297983583062887
[Epoch 8, Batch 300] loss: 0.11090319212526083
**STATS for Epoch 8** : 
Average training loss: 0.0227
Average validation loss: 0.0990
Validation Accuracy: 0.9701
Overfitting: 0.0763
Best model saved at epoch 8 with validation loss: 0.0990
[Epoch 9, Batch 100] loss: 0.1049734365195036
[Epoch 9, Batch 200] loss: 0.10212969964370132
[Epoch 9, Batch 300] loss: 0.10851232383400201
**STATS for Epoch 9** : 
Average training loss: 0.0210
Average validation loss: 0.0937
Validation Accuracy: 0.9700
Overfitting: 0.0727
[I 2024-12-10 10:20:45,105] Trial 22 pruned. 

Selected Hyperparameters for Trial 24:
  l1: 256, l2: 64, lr: 0.009447171373227188, batch_size: 256
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 1.6917025750875474
**STATS for Epoch 1** : 
Average training loss: 0.1644
Average validation loss: 0.2322
Validation Accuracy: 0.9274
Overfitting: 0.0678
Best model saved at epoch 1 with validation loss: 0.2322
[Epoch 2, Batch 100] loss: 0.19680779956281186
**STATS for Epoch 2** : 
Average training loss: 0.0641
Average validation loss: 0.1138
Validation Accuracy: 0.9640
Overfitting: 0.0497
Best model saved at epoch 2 with validation loss: 0.1138
[Epoch 3, Batch 100] loss: 0.10705471687018871
**STATS for Epoch 3** : 
Average training loss: 0.0516
Average validation loss: 0.0990
Validation Accuracy: 0.9696
Overfitting: 0.0475
Best model saved at epoch 3 with validation loss: 0.0990
[Epoch 4, Batch 100] loss: 0.08599735543131828
**STATS for Epoch 4** : 
Average training loss: 0.0390
Average validation loss: 0.0831
Validation Accuracy: 0.9730
Overfitting: 0.0441
Best model saved at epoch 4 with validation loss: 0.0831
[Epoch 5, Batch 100] loss: 0.0719062015414238
**STATS for Epoch 5** : 
Average training loss: 0.0279
Average validation loss: 0.0644
Validation Accuracy: 0.9805
Overfitting: 0.0364
Best model saved at epoch 5 with validation loss: 0.0644
[Epoch 6, Batch 100] loss: 0.05994350312277675
**STATS for Epoch 6** : 
Average training loss: 0.0254
Average validation loss: 0.0620
Validation Accuracy: 0.9803
Overfitting: 0.0366
Best model saved at epoch 6 with validation loss: 0.0620
[Epoch 7, Batch 100] loss: 0.047144681978970766
**STATS for Epoch 7** : 
Average training loss: 0.0228
Average validation loss: 0.0575
Validation Accuracy: 0.9814
Overfitting: 0.0347
Best model saved at epoch 7 with validation loss: 0.0575
[Epoch 8, Batch 100] loss: 0.041638563498854635
**STATS for Epoch 8** : 
Average training loss: 0.0206
Average validation loss: 0.0485
Validation Accuracy: 0.9848
Overfitting: 0.0279
Best model saved at epoch 8 with validation loss: 0.0485
[Epoch 9, Batch 100] loss: 0.03881451170425862
**STATS for Epoch 9** : 
Average training loss: 0.0190
Average validation loss: 0.0543
Validation Accuracy: 0.9827
Overfitting: 0.0353
[I 2024-12-10 10:22:01,122] Trial 23 pruned. 
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  10
  Number of complete trials:  14
Best hyperparameters found:
{'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16}
Best trial:
  Value:  0.045411968038914834
Loaded best model checkpoint from: instances/1162927_20241210/best_checkpoint_trial_4/model.pth
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 2.3004072594642637
[Epoch 1, Batch 200] loss: 2.290223937034607
[Epoch 1, Batch 300] loss: 2.2778706431388853
[Epoch 1, Batch 400] loss: 2.259122979640961
[Epoch 1, Batch 500] loss: 2.2320628476142885
[Epoch 1, Batch 600] loss: 2.1916176962852476
[Epoch 1, Batch 700] loss: 2.10311230301857
[Epoch 1, Batch 800] loss: 1.9167358088493347
[Epoch 1, Batch 900] loss: 1.535149358510971
[Epoch 1, Batch 1000] loss: 1.0881995928287507
[Epoch 1, Batch 1100] loss: 0.83408726811409
[Epoch 1, Batch 1200] loss: 0.6821916034817695
[Epoch 1, Batch 1300] loss: 0.6150267179310321
[Epoch 1, Batch 1400] loss: 0.555097203552723
[Epoch 1, Batch 1500] loss: 0.4809056743979454
[Epoch 1, Batch 1600] loss: 0.48236551649868487
[Epoch 1, Batch 1700] loss: 0.46119617342948915
[Epoch 1, Batch 1800] loss: 0.39137806355953214
[Epoch 1, Batch 1900] loss: 0.3824627301841974
[Epoch 1, Batch 2000] loss: 0.38955609321594237
[Epoch 1, Batch 2100] loss: 0.34747754499316214
[Epoch 1, Batch 2200] loss: 0.39701625663787127
[Epoch 1, Batch 2300] loss: 0.3415412126854062
[Epoch 1, Batch 2400] loss: 0.3029078428633511
[Epoch 1, Batch 2500] loss: 0.28307643067091703
[Epoch 1, Batch 2600] loss: 0.3175227358192205
[Epoch 1, Batch 2700] loss: 0.25919311732053757
[Epoch 1, Batch 2800] loss: 0.31665201801806686
[Epoch 1, Batch 2900] loss: 0.2778161057643592
[Epoch 1, Batch 3000] loss: 0.2588719605654478
[Epoch 1, Batch 3100] loss: 0.2726774563640356
[Epoch 1, Batch 3200] loss: 0.267871792819351
[Epoch 1, Batch 3300] loss: 0.24952817043289544
[Epoch 1, Batch 3400] loss: 0.24032688409090042
[Epoch 1, Batch 3500] loss: 0.23880755148828028
[Epoch 1, Batch 3600] loss: 0.20390495451167226
[Epoch 1, Batch 3700] loss: 0.2166134605742991
**STATS for Epoch 1** : 
Average training loss: 0.0031
Average validation loss: 0.2175
Overfitting: 0.2145
Best model saved at epoch 1 with training loss: 0.0031
[Epoch 2, Batch 100] loss: 0.2454466042853892
[Epoch 2, Batch 200] loss: 0.257107596360147
[Epoch 2, Batch 300] loss: 0.2154979212768376
[Epoch 2, Batch 400] loss: 0.2206608747690916
[Epoch 2, Batch 500] loss: 0.2039694668352604
[Epoch 2, Batch 600] loss: 0.19506864869967103
[Epoch 2, Batch 700] loss: 0.18227538871578872
[Epoch 2, Batch 800] loss: 0.20838276298716665
[Epoch 2, Batch 900] loss: 0.2072933560423553
[Epoch 2, Batch 1000] loss: 0.18060177378356457
[Epoch 2, Batch 1100] loss: 0.17156478308141232
[Epoch 2, Batch 1200] loss: 0.18909804680384695
[Epoch 2, Batch 1300] loss: 0.188257551654242
[Epoch 2, Batch 1400] loss: 0.1458660229947418
[Epoch 2, Batch 1500] loss: 0.18832365986891092
[Epoch 2, Batch 1600] loss: 0.17400949959177525
[Epoch 2, Batch 1700] loss: 0.1799915274279192
[Epoch 2, Batch 1800] loss: 0.1498787840362638
[Epoch 2, Batch 1900] loss: 0.14091418117983268
[Epoch 2, Batch 2000] loss: 0.15285733846016228
[Epoch 2, Batch 2100] loss: 0.17806743242777884
[Epoch 2, Batch 2200] loss: 0.16777536643669008
[Epoch 2, Batch 2300] loss: 0.15450658616609872
[Epoch 2, Batch 2400] loss: 0.15050112752243877
[Epoch 2, Batch 2500] loss: 0.1635598326381296
[Epoch 2, Batch 2600] loss: 0.1598818523529917
[Epoch 2, Batch 2700] loss: 0.14186975273303687
[Epoch 2, Batch 2800] loss: 0.11040272393263877
[Epoch 2, Batch 2900] loss: 0.15784723684191704
[Epoch 2, Batch 3000] loss: 0.13957082171691582
[Epoch 2, Batch 3100] loss: 0.1395145395491272
[Epoch 2, Batch 3200] loss: 0.13511825289111584
[Epoch 2, Batch 3300] loss: 0.1533311760891229
[Epoch 2, Batch 3400] loss: 0.14632092128042132
[Epoch 2, Batch 3500] loss: 0.1253517947345972
[Epoch 2, Batch 3600] loss: 0.1501550382375717
[Epoch 2, Batch 3700] loss: 0.11052052126266063
**STATS for Epoch 2** : 
Average training loss: 0.0016
Average validation loss: 0.1156
Overfitting: 0.1140
Best model saved at epoch 2 with training loss: 0.0016
[Epoch 3, Batch 100] loss: 0.12694199141580612
[Epoch 3, Batch 200] loss: 0.1258645211812109
[Epoch 3, Batch 300] loss: 0.1206188155291602
[Epoch 3, Batch 400] loss: 0.09894065930508077
[Epoch 3, Batch 500] loss: 0.10668761167675257
[Epoch 3, Batch 600] loss: 0.10438681588042527
[Epoch 3, Batch 700] loss: 0.1339596134214662
[Epoch 3, Batch 800] loss: 0.13848302341997623
[Epoch 3, Batch 900] loss: 0.100816133255139
[Epoch 3, Batch 1000] loss: 0.13159892636584117
[Epoch 3, Batch 1100] loss: 0.10016333974897862
[Epoch 3, Batch 1200] loss: 0.12016944877337664
[Epoch 3, Batch 1300] loss: 0.09989612360484898
[Epoch 3, Batch 1400] loss: 0.11457796820439398
[Epoch 3, Batch 1500] loss: 0.08922924917656928
[Epoch 3, Batch 1600] loss: 0.0848098495346494
[Epoch 3, Batch 1700] loss: 0.1306650090776384
[Epoch 3, Batch 1800] loss: 0.09371934074908495
[Epoch 3, Batch 1900] loss: 0.1358435942325741
[Epoch 3, Batch 2000] loss: 0.0963615230191499
[Epoch 3, Batch 2100] loss: 0.11258190412307158
[Epoch 3, Batch 2200] loss: 0.10368536301655695
[Epoch 3, Batch 2300] loss: 0.11812765310052782
[Epoch 3, Batch 2400] loss: 0.10865291522117332
[Epoch 3, Batch 2500] loss: 0.09704893392976373
[Epoch 3, Batch 2600] loss: 0.10276653096545488
[Epoch 3, Batch 2700] loss: 0.11644360626814887
[Epoch 3, Batch 2800] loss: 0.12112040924839676
[Epoch 3, Batch 2900] loss: 0.1020625549077522
[Epoch 3, Batch 3000] loss: 0.10772759915329516
[Epoch 3, Batch 3100] loss: 0.08785481054103002
[Epoch 3, Batch 3200] loss: 0.09925621350295842
[Epoch 3, Batch 3300] loss: 0.10407989983214065
[Epoch 3, Batch 3400] loss: 0.08844878466101364
[Epoch 3, Batch 3500] loss: 0.07548005762044341
[Epoch 3, Batch 3600] loss: 0.10501767038367689
[Epoch 3, Batch 3700] loss: 0.11840727382339537
**STATS for Epoch 3** : 
Average training loss: 0.0012
Average validation loss: 0.0912
Overfitting: 0.0900
Best model saved at epoch 3 with training loss: 0.0012
[Epoch 4, Batch 100] loss: 0.0782101230486296
[Epoch 4, Batch 200] loss: 0.08770017347298563
[Epoch 4, Batch 300] loss: 0.08820436797803267
[Epoch 4, Batch 400] loss: 0.08932173909852281
[Epoch 4, Batch 500] loss: 0.10794514440232889
[Epoch 4, Batch 600] loss: 0.07871217579231597
[Epoch 4, Batch 700] loss: 0.09557040894404054
[Epoch 4, Batch 800] loss: 0.0946953384578228
[Epoch 4, Batch 900] loss: 0.0875285491393879
[Epoch 4, Batch 1000] loss: 0.10855299851391464
[Epoch 4, Batch 1100] loss: 0.08550983084365725
[Epoch 4, Batch 1200] loss: 0.0954218686465174
[Epoch 4, Batch 1300] loss: 0.08734965856187045
[Epoch 4, Batch 1400] loss: 0.08485431273351424
[Epoch 4, Batch 1500] loss: 0.08150282639544457
[Epoch 4, Batch 1600] loss: 0.09025992875220254
[Epoch 4, Batch 1700] loss: 0.08708440281101502
[Epoch 4, Batch 1800] loss: 0.08896826712414622
[Epoch 4, Batch 1900] loss: 0.08480236464180052
[Epoch 4, Batch 2000] loss: 0.077651001077611
[Epoch 4, Batch 2100] loss: 0.08033818807452917
[Epoch 4, Batch 2200] loss: 0.09955807097489014
[Epoch 4, Batch 2300] loss: 0.07837021304760128
[Epoch 4, Batch 2400] loss: 0.0712747144792229
[Epoch 4, Batch 2500] loss: 0.07950305496808141
[Epoch 4, Batch 2600] loss: 0.06618602376664057
[Epoch 4, Batch 2700] loss: 0.07931366023840383
[Epoch 4, Batch 2800] loss: 0.07351128573063762
[Epoch 4, Batch 2900] loss: 0.06338828632840887
[Epoch 4, Batch 3000] loss: 0.07679013534681872
[Epoch 4, Batch 3100] loss: 0.08793896933435462
[Epoch 4, Batch 3200] loss: 0.08120463692583144
[Epoch 4, Batch 3300] loss: 0.07360896333353593
[Epoch 4, Batch 3400] loss: 0.06871368215885014
[Epoch 4, Batch 3500] loss: 0.07932055542594753
[Epoch 4, Batch 3600] loss: 0.07150338061677758
[Epoch 4, Batch 3700] loss: 0.06522030333173462
**STATS for Epoch 4** : 
Average training loss: 0.0010
Average validation loss: 0.0685
Overfitting: 0.0675
Best model saved at epoch 4 with training loss: 0.0010
[Epoch 5, Batch 100] loss: 0.09325814881944097
[Epoch 5, Batch 200] loss: 0.07001265164464712
[Epoch 5, Batch 300] loss: 0.07641637527034618
[Epoch 5, Batch 400] loss: 0.07951696560368873
[Epoch 5, Batch 500] loss: 0.07411632973700762
[Epoch 5, Batch 600] loss: 0.05788671717280522
[Epoch 5, Batch 700] loss: 0.07522111110389233
[Epoch 5, Batch 800] loss: 0.0771492470242083
[Epoch 5, Batch 900] loss: 0.0693693716218695
[Epoch 5, Batch 1000] loss: 0.0807368817506358
[Epoch 5, Batch 1100] loss: 0.06682747337850742
[Epoch 5, Batch 1200] loss: 0.059682782107265665
[Epoch 5, Batch 1300] loss: 0.06923032140708528
[Epoch 5, Batch 1400] loss: 0.053269295706413686
[Epoch 5, Batch 1500] loss: 0.06467879365431145
[Epoch 5, Batch 1600] loss: 0.07164752086333465
[Epoch 5, Batch 1700] loss: 0.06802244503400288
[Epoch 5, Batch 1800] loss: 0.07072442629025318
[Epoch 5, Batch 1900] loss: 0.0612341748632025
[Epoch 5, Batch 2000] loss: 0.09140877910540439
[Epoch 5, Batch 2100] loss: 0.053070862386375664
[Epoch 5, Batch 2200] loss: 0.07520571692672093
[Epoch 5, Batch 2300] loss: 0.05070377036230639
[Epoch 5, Batch 2400] loss: 0.0837468260107562
[Epoch 5, Batch 2500] loss: 0.07460198347631376
[Epoch 5, Batch 2600] loss: 0.06241564243216999
[Epoch 5, Batch 2700] loss: 0.06507828681380488
[Epoch 5, Batch 2800] loss: 0.06330597643333022
[Epoch 5, Batch 2900] loss: 0.06574810095946304
[Epoch 5, Batch 3000] loss: 0.057158418216276916
[Epoch 5, Batch 3100] loss: 0.056231848520692435
[Epoch 5, Batch 3200] loss: 0.08065697870217264
[Epoch 5, Batch 3300] loss: 0.07542711839312688
[Epoch 5, Batch 3400] loss: 0.06317399586550891
[Epoch 5, Batch 3500] loss: 0.0673390967946034
[Epoch 5, Batch 3600] loss: 0.052775472147041
[Epoch 5, Batch 3700] loss: 0.07262879839516245
**STATS for Epoch 5** : 
Average training loss: 0.0006
Average validation loss: 0.0633
Overfitting: 0.0627
Best model saved at epoch 5 with training loss: 0.0006
[Epoch 6, Batch 100] loss: 0.05385537084192037
[Epoch 6, Batch 200] loss: 0.06312673813605216
[Epoch 6, Batch 300] loss: 0.06963897614507004
[Epoch 6, Batch 400] loss: 0.06386575236392673
[Epoch 6, Batch 500] loss: 0.06217618279042654
[Epoch 6, Batch 600] loss: 0.04179070547106676
[Epoch 6, Batch 700] loss: 0.059377227977965956
[Epoch 6, Batch 800] loss: 0.07210039492871147
[Epoch 6, Batch 900] loss: 0.05834855395747582
[Epoch 6, Batch 1000] loss: 0.0685429811704671
[Epoch 6, Batch 1100] loss: 0.07570685077982489
[Epoch 6, Batch 1200] loss: 0.05492985575867351
[Epoch 6, Batch 1300] loss: 0.057392601830651986
[Epoch 6, Batch 1400] loss: 0.04893865512742195
[Epoch 6, Batch 1500] loss: 0.0730738881562138
[Epoch 6, Batch 1600] loss: 0.06731086048763245
[Epoch 6, Batch 1700] loss: 0.05102023607119918
[Epoch 6, Batch 1800] loss: 0.05495026578486431
[Epoch 6, Batch 1900] loss: 0.0507576134824194
[Epoch 6, Batch 2000] loss: 0.05539684771094471
[Epoch 6, Batch 2100] loss: 0.05135412414791062
[Epoch 6, Batch 2200] loss: 0.04640282576496247
[Epoch 6, Batch 2300] loss: 0.05988805328379385
[Epoch 6, Batch 2400] loss: 0.05197737058741041
[Epoch 6, Batch 2500] loss: 0.07382040440686978
[Epoch 6, Batch 2600] loss: 0.060494119009235875
[Epoch 6, Batch 2700] loss: 0.07331005427695345
[Epoch 6, Batch 2800] loss: 0.06627806998731103
[Epoch 6, Batch 2900] loss: 0.05397767946764361
[Epoch 6, Batch 3000] loss: 0.051623985775513574
[Epoch 6, Batch 3100] loss: 0.04356643155333586
[Epoch 6, Batch 3200] loss: 0.05380983788287267
[Epoch 6, Batch 3300] loss: 0.07074820385256317
[Epoch 6, Batch 3400] loss: 0.06190844327677041
[Epoch 6, Batch 3500] loss: 0.059335671544540676
[Epoch 6, Batch 3600] loss: 0.050653742083522954
[Epoch 6, Batch 3700] loss: 0.04558895889145788
**STATS for Epoch 6** : 
Average training loss: 0.0011
Average validation loss: 0.0504
Overfitting: 0.0493
[Epoch 7, Batch 100] loss: 0.032190305092372
[Epoch 7, Batch 200] loss: 0.05611762615677435
[Epoch 7, Batch 300] loss: 0.051923879070091064
[Epoch 7, Batch 400] loss: 0.0506736338470364
[Epoch 7, Batch 500] loss: 0.04457752588321455
[Epoch 7, Batch 600] loss: 0.04688038323132787
[Epoch 7, Batch 700] loss: 0.044659281579806705
[Epoch 7, Batch 800] loss: 0.048197030783630905
[Epoch 7, Batch 900] loss: 0.06295653559122001
[Epoch 7, Batch 1000] loss: 0.055921941418200734
[Epoch 7, Batch 1100] loss: 0.05539133026846685
[Epoch 7, Batch 1200] loss: 0.0645744585711509
[Epoch 7, Batch 1300] loss: 0.06263082650839351
[Epoch 7, Batch 1400] loss: 0.0479038600838976
[Epoch 7, Batch 1500] loss: 0.04396129731554538
[Epoch 7, Batch 1600] loss: 0.041267867946298796
[Epoch 7, Batch 1700] loss: 0.05846600355114788
[Epoch 7, Batch 1800] loss: 0.05012080525993952
[Epoch 7, Batch 1900] loss: 0.08644012978649698
[Epoch 7, Batch 2000] loss: 0.05654231954133138
[Epoch 7, Batch 2100] loss: 0.04991467947460478
[Epoch 7, Batch 2200] loss: 0.05095480468764436
[Epoch 7, Batch 2300] loss: 0.05313820792536717
[Epoch 7, Batch 2400] loss: 0.06600391950283666
[Epoch 7, Batch 2500] loss: 0.0445246145821875
[Epoch 7, Batch 2600] loss: 0.0582212143909419
[Epoch 7, Batch 2700] loss: 0.04223170258163009
[Epoch 7, Batch 2800] loss: 0.04357074020314031
[Epoch 7, Batch 2900] loss: 0.06013910345209297
[Epoch 7, Batch 3000] loss: 0.04003846679115668
[Epoch 7, Batch 3100] loss: 0.05480951900841319
[Epoch 7, Batch 3200] loss: 0.05333917424082756
[Epoch 7, Batch 3300] loss: 0.0428682147472864
[Epoch 7, Batch 3400] loss: 0.04740988141449634
[Epoch 7, Batch 3500] loss: 0.05752050131413853
[Epoch 7, Batch 3600] loss: 0.045953284582064956
[Epoch 7, Batch 3700] loss: 0.04510475647402927
**STATS for Epoch 7** : 
Average training loss: 0.0009
Average validation loss: 0.0490
Overfitting: 0.0481
[Epoch 8, Batch 100] loss: 0.0347279086249182
[Epoch 8, Batch 200] loss: 0.05517019108578097
[Epoch 8, Batch 300] loss: 0.043597897500148974
[Epoch 8, Batch 400] loss: 0.05146888699615374
[Epoch 8, Batch 500] loss: 0.03151324013626436
[Epoch 8, Batch 600] loss: 0.04315907867407077
[Epoch 8, Batch 700] loss: 0.05442533749737777
[Epoch 8, Batch 800] loss: 0.0472377860249253
[Epoch 8, Batch 900] loss: 0.05244995052111335
[Epoch 8, Batch 1000] loss: 0.04645799282210646
[Epoch 8, Batch 1100] loss: 0.04695010437455494
[Epoch 8, Batch 1200] loss: 0.038932673730014355
[Epoch 8, Batch 1300] loss: 0.04928003274719231
[Epoch 8, Batch 1400] loss: 0.04456787578354124
[Epoch 8, Batch 1500] loss: 0.05541120923997369
[Epoch 8, Batch 1600] loss: 0.053206358011229894
[Epoch 8, Batch 1700] loss: 0.03932785397468251
[Epoch 8, Batch 1800] loss: 0.05857820625009481
[Epoch 8, Batch 1900] loss: 0.033921338691725395
[Epoch 8, Batch 2000] loss: 0.059135086499445606
[Epoch 8, Batch 2100] loss: 0.06153476584819145
[Epoch 8, Batch 2200] loss: 0.050468775219342205
[Epoch 8, Batch 2300] loss: 0.04040675686148461
[Epoch 8, Batch 2400] loss: 0.0431804565503262
[Epoch 8, Batch 2500] loss: 0.039073211830691436
[Epoch 8, Batch 2600] loss: 0.04402352568518836
[Epoch 8, Batch 2700] loss: 0.04304019194794819
[Epoch 8, Batch 2800] loss: 0.04599595265870448
[Epoch 8, Batch 2900] loss: 0.07287449195224326
[Epoch 8, Batch 3000] loss: 0.02801309532515006
[Epoch 8, Batch 3100] loss: 0.028370957346342037
[Epoch 8, Batch 3200] loss: 0.052209555825102144
[Epoch 8, Batch 3300] loss: 0.032982739497965666
[Epoch 8, Batch 3400] loss: 0.03916546026623109
[Epoch 8, Batch 3500] loss: 0.05106613540148828
[Epoch 8, Batch 3600] loss: 0.029625292830751278
[Epoch 8, Batch 3700] loss: 0.04269088436441962
**STATS for Epoch 8** : 
Average training loss: 0.0007
Average validation loss: 0.0510
Overfitting: 0.0503
[Epoch 9, Batch 100] loss: 0.04596712782804389
[Epoch 9, Batch 200] loss: 0.03419393786112778
[Epoch 9, Batch 300] loss: 0.04668819109501783
[Epoch 9, Batch 400] loss: 0.062080531804531346
[Epoch 9, Batch 500] loss: 0.039323123976064384
[Epoch 9, Batch 600] loss: 0.03262119841820095
[Epoch 9, Batch 700] loss: 0.04005906499922276
[Epoch 9, Batch 800] loss: 0.03666749269003049
[Epoch 9, Batch 900] loss: 0.036436489558254834
[Epoch 9, Batch 1000] loss: 0.04479076863382943
[Epoch 9, Batch 1100] loss: 0.05176983187717269
[Epoch 9, Batch 1200] loss: 0.04779934564838186
[Epoch 9, Batch 1300] loss: 0.037425221775483804
[Epoch 9, Batch 1400] loss: 0.04706483819376445
[Epoch 9, Batch 1500] loss: 0.03961059884779388
[Epoch 9, Batch 1600] loss: 0.037064053569338284
[Epoch 9, Batch 1700] loss: 0.03513602730352432
[Epoch 9, Batch 1800] loss: 0.051788749345869294
[Epoch 9, Batch 1900] loss: 0.034611651721934325
[Epoch 9, Batch 2000] loss: 0.0308678724168567
[Epoch 9, Batch 2100] loss: 0.062222531472652914
[Epoch 9, Batch 2200] loss: 0.041899445293965984
[Epoch 9, Batch 2300] loss: 0.052743695541284975
[Epoch 9, Batch 2400] loss: 0.03738659122958779
[Epoch 9, Batch 2500] loss: 0.041443748688616326
[Epoch 9, Batch 2600] loss: 0.03130647634679917
[Epoch 9, Batch 2700] loss: 0.03901012808200903
[Epoch 9, Batch 2800] loss: 0.05335445950739086
[Epoch 9, Batch 2900] loss: 0.037272830158181024
[Epoch 9, Batch 3000] loss: 0.05573046026518568
[Epoch 9, Batch 3100] loss: 0.045613797600672114
[Epoch 9, Batch 3200] loss: 0.037094811180140824
[Epoch 9, Batch 3300] loss: 0.03333261862106156
[Epoch 9, Batch 3400] loss: 0.02837091890483862
[Epoch 9, Batch 3500] loss: 0.052639327588840386
[Epoch 9, Batch 3600] loss: 0.03860409493849147
[Epoch 9, Batch 3700] loss: 0.039224764202954246
**STATS for Epoch 9** : 
Average training loss: 0.0007
Average validation loss: 0.0499
Overfitting: 0.0492
[Epoch 10, Batch 100] loss: 0.048478862725896764
[Epoch 10, Batch 200] loss: 0.034974788785038985
[Epoch 10, Batch 300] loss: 0.041364302227448205
[Epoch 10, Batch 400] loss: 0.03461408117378596
[Epoch 10, Batch 500] loss: 0.03771034208475612
[Epoch 10, Batch 600] loss: 0.0306600945640821
[Epoch 10, Batch 700] loss: 0.02833344610291533
[Epoch 10, Batch 800] loss: 0.028055435781279812
[Epoch 10, Batch 900] loss: 0.03146573312304099
[Epoch 10, Batch 1000] loss: 0.05591813876759261
[Epoch 10, Batch 1100] loss: 0.046448889672174115
[Epoch 10, Batch 1200] loss: 0.05346740082168253
[Epoch 10, Batch 1300] loss: 0.030431254945870023
[Epoch 10, Batch 1400] loss: 0.028620431758463384
[Epoch 10, Batch 1500] loss: 0.03679421079606982
[Epoch 10, Batch 1600] loss: 0.057262373605917676
[Epoch 10, Batch 1700] loss: 0.03532480228575878
[Epoch 10, Batch 1800] loss: 0.030266986055939925
[Epoch 10, Batch 1900] loss: 0.053914012840250505
[Epoch 10, Batch 2000] loss: 0.04413723459467292
[Epoch 10, Batch 2100] loss: 0.033670063679455776
[Epoch 10, Batch 2200] loss: 0.03553123547448195
[Epoch 10, Batch 2300] loss: 0.04481580228050006
[Epoch 10, Batch 2400] loss: 0.02756442364945542
[Epoch 10, Batch 2500] loss: 0.04376880877302028
[Epoch 10, Batch 2600] loss: 0.04547487745876424
[Epoch 10, Batch 2700] loss: 0.025291023209138074
[Epoch 10, Batch 2800] loss: 0.02172311067537521
[Epoch 10, Batch 2900] loss: 0.03798652858182322
[Epoch 10, Batch 3000] loss: 0.02893638164619915
[Epoch 10, Batch 3100] loss: 0.03347049448173493
[Epoch 10, Batch 3200] loss: 0.03509911898159771
[Epoch 10, Batch 3300] loss: 0.04618757909163833
[Epoch 10, Batch 3400] loss: 0.03955754253795021
[Epoch 10, Batch 3500] loss: 0.04345396844379138
[Epoch 10, Batch 3600] loss: 0.039454510198556815
[Epoch 10, Batch 3700] loss: 0.027982540429511572
**STATS for Epoch 10** : 
Average training loss: 0.0007
Average validation loss: 0.0442
Overfitting: 0.0435
[Epoch 11, Batch 100] loss: 0.04853937439242145
[Epoch 11, Batch 200] loss: 0.03547499252192211
[Epoch 11, Batch 300] loss: 0.041892157480760944
[Epoch 11, Batch 400] loss: 0.025383418347337282
[Epoch 11, Batch 500] loss: 0.032350679409573785
[Epoch 11, Batch 600] loss: 0.026380734540580306
[Epoch 11, Batch 700] loss: 0.0278105285478523
[Epoch 11, Batch 800] loss: 0.027439825063338502
[Epoch 11, Batch 900] loss: 0.035034356800751995
[Epoch 11, Batch 1000] loss: 0.04782001952720748
[Epoch 11, Batch 1100] loss: 0.029849442718550563
[Epoch 11, Batch 1200] loss: 0.025046949415118435
[Epoch 11, Batch 1300] loss: 0.03741008837707341
[Epoch 11, Batch 1400] loss: 0.026427716916950884
[Epoch 11, Batch 1500] loss: 0.03186785246951331
[Epoch 11, Batch 1600] loss: 0.034733360802056266
[Epoch 11, Batch 1700] loss: 0.035813732479000465
[Epoch 11, Batch 1800] loss: 0.03418549096008064
[Epoch 11, Batch 1900] loss: 0.041025466010032687
[Epoch 11, Batch 2000] loss: 0.04614271834434476
[Epoch 11, Batch 2100] loss: 0.043269765968434515
[Epoch 11, Batch 2200] loss: 0.038615354566718454
[Epoch 11, Batch 2300] loss: 0.0392597219068557
[Epoch 11, Batch 2400] loss: 0.025708730900514638
[Epoch 11, Batch 2500] loss: 0.042348173145728654
[Epoch 11, Batch 2600] loss: 0.0335913431760855
[Epoch 11, Batch 2700] loss: 0.03826163069956237
[Epoch 11, Batch 2800] loss: 0.03156698797538411
[Epoch 11, Batch 2900] loss: 0.03389431463248911
[Epoch 11, Batch 3000] loss: 0.02378930849110475
[Epoch 11, Batch 3100] loss: 0.024254499022499657
[Epoch 11, Batch 3200] loss: 0.04056087294367899
[Epoch 11, Batch 3300] loss: 0.044623508316872174
[Epoch 11, Batch 3400] loss: 0.02672170780788292
[Epoch 11, Batch 3500] loss: 0.04505690266785677
[Epoch 11, Batch 3600] loss: 0.034998135115965855
[Epoch 11, Batch 3700] loss: 0.03349160735320766
**STATS for Epoch 11** : 
Average training loss: 0.0002
Average validation loss: 0.0393
Overfitting: 0.0391
Best model saved at epoch 11 with training loss: 0.0002
[Epoch 12, Batch 100] loss: 0.025795808757611668
[Epoch 12, Batch 200] loss: 0.04311677222576691
[Epoch 12, Batch 300] loss: 0.02755256472795736
[Epoch 12, Batch 400] loss: 0.029371819668158425
[Epoch 12, Batch 500] loss: 0.022143656995613128
[Epoch 12, Batch 600] loss: 0.03325060807241243
[Epoch 12, Batch 700] loss: 0.035453328334842805
[Epoch 12, Batch 800] loss: 0.03166332206179504
[Epoch 12, Batch 900] loss: 0.03674722951473086
[Epoch 12, Batch 1000] loss: 0.031173050344805234
[Epoch 12, Batch 1100] loss: 0.03117809334784397
[Epoch 12, Batch 1200] loss: 0.023070019042133936
[Epoch 12, Batch 1300] loss: 0.024356081773585173
[Epoch 12, Batch 1400] loss: 0.032018737040561976
[Epoch 12, Batch 1500] loss: 0.03309296783401806
[Epoch 12, Batch 1600] loss: 0.047544026416435375
[Epoch 12, Batch 1700] loss: 0.029924172175087735
[Epoch 12, Batch 1800] loss: 0.027014413281831365
[Epoch 12, Batch 1900] loss: 0.03508902044719434
[Epoch 12, Batch 2000] loss: 0.023095819595328068
[Epoch 12, Batch 2100] loss: 0.03615022432786645
[Epoch 12, Batch 2200] loss: 0.031683793024421904
[Epoch 12, Batch 2300] loss: 0.030295109049475286
[Epoch 12, Batch 2400] loss: 0.037884907298284816
[Epoch 12, Batch 2500] loss: 0.03893372126738541
[Epoch 12, Batch 2600] loss: 0.02952670744722127
[Epoch 12, Batch 2700] loss: 0.029445768117147962
[Epoch 12, Batch 2800] loss: 0.02995590557839023
[Epoch 12, Batch 2900] loss: 0.04010246235469822
[Epoch 12, Batch 3000] loss: 0.03264460698410403
[Epoch 12, Batch 3100] loss: 0.03934791190637043
[Epoch 12, Batch 3200] loss: 0.01866450050896674
[Epoch 12, Batch 3300] loss: 0.031688835966779155
[Epoch 12, Batch 3400] loss: 0.056411995108937844
[Epoch 12, Batch 3500] loss: 0.03421304337622132
[Epoch 12, Batch 3600] loss: 0.027522728667536286
[Epoch 12, Batch 3700] loss: 0.017898779213428497
**STATS for Epoch 12** : 
Average training loss: 0.0003
Average validation loss: 0.0366
Overfitting: 0.0363
[Epoch 13, Batch 100] loss: 0.027002297340659426
[Epoch 13, Batch 200] loss: 0.033005419399705714
[Epoch 13, Batch 300] loss: 0.02066651229040872
[Epoch 13, Batch 400] loss: 0.030467217696059378
[Epoch 13, Batch 500] loss: 0.028343609857547563
[Epoch 13, Batch 600] loss: 0.022925026691809763
[Epoch 13, Batch 700] loss: 0.033603903713519685
[Epoch 13, Batch 800] loss: 0.03246905867112218
[Epoch 13, Batch 900] loss: 0.026986841778561938
[Epoch 13, Batch 1000] loss: 0.037946846807026306
[Epoch 13, Batch 1100] loss: 0.024570954286609777
[Epoch 13, Batch 1200] loss: 0.02279802702825691
[Epoch 13, Batch 1300] loss: 0.02972903965594014
[Epoch 13, Batch 1400] loss: 0.03635475931660039
[Epoch 13, Batch 1500] loss: 0.030579119878238997
[Epoch 13, Batch 1600] loss: 0.022902523244410986
[Epoch 13, Batch 1700] loss: 0.02752032862888882
[Epoch 13, Batch 1800] loss: 0.021998116954491706
[Epoch 13, Batch 1900] loss: 0.03278110289502365
[Epoch 13, Batch 2000] loss: 0.035793270097929056
[Epoch 13, Batch 2100] loss: 0.01931115874031093
[Epoch 13, Batch 2200] loss: 0.031247730864415645
[Epoch 13, Batch 2300] loss: 0.02060805594890553
[Epoch 13, Batch 2400] loss: 0.026012112129392334
[Epoch 13, Batch 2500] loss: 0.02934315341277397
[Epoch 13, Batch 2600] loss: 0.02760095145262312
[Epoch 13, Batch 2700] loss: 0.03672604837687686
[Epoch 13, Batch 2800] loss: 0.02381392412025889
[Epoch 13, Batch 2900] loss: 0.017965254221198847
[Epoch 13, Batch 3000] loss: 0.021345066469075392
[Epoch 13, Batch 3100] loss: 0.04073410188342677
[Epoch 13, Batch 3200] loss: 0.029653808123548515
[Epoch 13, Batch 3300] loss: 0.02584389407405979
[Epoch 13, Batch 3400] loss: 0.04288201087736525
[Epoch 13, Batch 3500] loss: 0.030986763409528065
[Epoch 13, Batch 3600] loss: 0.020896240092988592
[Epoch 13, Batch 3700] loss: 0.03279209811618784
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0382
Overfitting: 0.0375
[Epoch 14, Batch 100] loss: 0.0256007872193004
[Epoch 14, Batch 200] loss: 0.025467487021232957
[Epoch 14, Batch 300] loss: 0.02747436834142718
[Epoch 14, Batch 400] loss: 0.027813289632322265
[Epoch 14, Batch 500] loss: 0.03494299397483701
[Epoch 14, Batch 600] loss: 0.027103992541815388
[Epoch 14, Batch 700] loss: 0.02993525265424978
[Epoch 14, Batch 800] loss: 0.025823755645214986
[Epoch 14, Batch 900] loss: 0.024413615238445346
[Epoch 14, Batch 1000] loss: 0.029815963651635684
[Epoch 14, Batch 1100] loss: 0.03545370018517133
[Epoch 14, Batch 1200] loss: 0.026250328933238053
[Epoch 14, Batch 1300] loss: 0.031123229991062543
[Epoch 14, Batch 1400] loss: 0.02129479615832679
[Epoch 14, Batch 1500] loss: 0.02676830978161888
[Epoch 14, Batch 1600] loss: 0.018861524882086086
[Epoch 14, Batch 1700] loss: 0.028719058549322652
[Epoch 14, Batch 1800] loss: 0.02981453761647572
[Epoch 14, Batch 1900] loss: 0.014447747655649436
[Epoch 14, Batch 2000] loss: 0.01682819263842248
[Epoch 14, Batch 2100] loss: 0.026472315567662007
[Epoch 14, Batch 2200] loss: 0.03711210016757832
[Epoch 14, Batch 2300] loss: 0.034276336578768676
[Epoch 14, Batch 2400] loss: 0.015353793875547125
[Epoch 14, Batch 2500] loss: 0.027428203393064905
[Epoch 14, Batch 2600] loss: 0.023883174912189133
[Epoch 14, Batch 2700] loss: 0.031800313979038035
[Epoch 14, Batch 2800] loss: 0.028744089710598927
[Epoch 14, Batch 2900] loss: 0.02473530588700669
[Epoch 14, Batch 3000] loss: 0.03943168975703884
[Epoch 14, Batch 3100] loss: 0.017516672015335643
[Epoch 14, Batch 3200] loss: 0.020965761946863493
[Epoch 14, Batch 3300] loss: 0.04049716163179255
[Epoch 14, Batch 3400] loss: 0.03458633945127076
[Epoch 14, Batch 3500] loss: 0.016330939891777235
[Epoch 14, Batch 3600] loss: 0.024950183705223027
[Epoch 14, Batch 3700] loss: 0.016389478977944235
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0368
Overfitting: 0.0362
[Epoch 15, Batch 100] loss: 0.03163955137250014
[Epoch 15, Batch 200] loss: 0.022000694726448274
[Epoch 15, Batch 300] loss: 0.018878832312475426
[Epoch 15, Batch 400] loss: 0.028647519007718072
[Epoch 15, Batch 500] loss: 0.013883267724886537
[Epoch 15, Batch 600] loss: 0.024193472908227705
[Epoch 15, Batch 700] loss: 0.02764539198265993
[Epoch 15, Batch 800] loss: 0.023050938817614223
[Epoch 15, Batch 900] loss: 0.01981256011073128
[Epoch 15, Batch 1000] loss: 0.031130928045895415
[Epoch 15, Batch 1100] loss: 0.032860370115377006
[Epoch 15, Batch 1200] loss: 0.02411304602861492
[Epoch 15, Batch 1300] loss: 0.01905317731543619
[Epoch 15, Batch 1400] loss: 0.023169635371959884
[Epoch 15, Batch 1500] loss: 0.023724023669492455
[Epoch 15, Batch 1600] loss: 0.024126013490968035
[Epoch 15, Batch 1700] loss: 0.019837189938261873
[Epoch 15, Batch 1800] loss: 0.0253863787924638
[Epoch 15, Batch 1900] loss: 0.03597412640785478
[Epoch 15, Batch 2000] loss: 0.021479396180220645
[Epoch 15, Batch 2100] loss: 0.016119754711617133
[Epoch 15, Batch 2200] loss: 0.020094483225329897
[Epoch 15, Batch 2300] loss: 0.03209868917663698
[Epoch 15, Batch 2400] loss: 0.030406988401082344
[Epoch 15, Batch 2500] loss: 0.03508250611062977
[Epoch 15, Batch 2600] loss: 0.03861345296681975
[Epoch 15, Batch 2700] loss: 0.018461870193859795
[Epoch 15, Batch 2800] loss: 0.021681192482283222
[Epoch 15, Batch 2900] loss: 0.026448076698652585
[Epoch 15, Batch 3000] loss: 0.014559703947088564
[Epoch 15, Batch 3100] loss: 0.02153639005126024
[Epoch 15, Batch 3200] loss: 0.03650752781941265
[Epoch 15, Batch 3300] loss: 0.02040207109756011
[Epoch 15, Batch 3400] loss: 0.027335675982176327
[Epoch 15, Batch 3500] loss: 0.022268036763634882
[Epoch 15, Batch 3600] loss: 0.030548050151774076
[Epoch 15, Batch 3700] loss: 0.028387251425592695
**STATS for Epoch 15** : 
Average training loss: 0.0003
Average validation loss: 0.0357
Overfitting: 0.0354
[Epoch 16, Batch 100] loss: 0.02265046606888063
[Epoch 16, Batch 200] loss: 0.01770779447258974
[Epoch 16, Batch 300] loss: 0.028813090947442107
[Epoch 16, Batch 400] loss: 0.020797867654982836
[Epoch 16, Batch 500] loss: 0.023829214067482098
[Epoch 16, Batch 600] loss: 0.020868671879143222
[Epoch 16, Batch 700] loss: 0.029380882389014006
[Epoch 16, Batch 800] loss: 0.019024008001215408
[Epoch 16, Batch 900] loss: 0.01872416629368672
[Epoch 16, Batch 1000] loss: 0.026720199523551855
[Epoch 16, Batch 1100] loss: 0.017308832707785767
[Epoch 16, Batch 1200] loss: 0.04718293074387475
[Epoch 16, Batch 1300] loss: 0.01647041860378522
[Epoch 16, Batch 1400] loss: 0.026730860339284845
[Epoch 16, Batch 1500] loss: 0.022760204166661423
[Epoch 16, Batch 1600] loss: 0.01518880085357523
[Epoch 16, Batch 1700] loss: 0.02432128576670948
[Epoch 16, Batch 1800] loss: 0.02493372717508464
[Epoch 16, Batch 1900] loss: 0.017846443304042624
[Epoch 16, Batch 2000] loss: 0.015100356510083656
[Epoch 16, Batch 2100] loss: 0.016109314696768705
[Epoch 16, Batch 2200] loss: 0.019486786642464723
[Epoch 16, Batch 2300] loss: 0.03732693360529083
[Epoch 16, Batch 2400] loss: 0.0307606299744657
[Epoch 16, Batch 2500] loss: 0.024735562302084874
[Epoch 16, Batch 2600] loss: 0.019502925862325354
[Epoch 16, Batch 2700] loss: 0.019910467901136143
[Epoch 16, Batch 2800] loss: 0.02482550591994368
[Epoch 16, Batch 2900] loss: 0.026337944746483117
[Epoch 16, Batch 3000] loss: 0.0241106861813023
[Epoch 16, Batch 3100] loss: 0.03151259052385285
[Epoch 16, Batch 3200] loss: 0.023365060086580344
[Epoch 16, Batch 3300] loss: 0.027368733446237456
[Epoch 16, Batch 3400] loss: 0.016924724761993276
[Epoch 16, Batch 3500] loss: 0.022069248918087397
[Epoch 16, Batch 3600] loss: 0.02849310945675825
[Epoch 16, Batch 3700] loss: 0.030184408118439022
**STATS for Epoch 16** : 
Average training loss: 0.0002
Average validation loss: 0.0348
Overfitting: 0.0346
[Epoch 17, Batch 100] loss: 0.01728751625028963
[Epoch 17, Batch 200] loss: 0.028122392147815846
[Epoch 17, Batch 300] loss: 0.019625405275874072
[Epoch 17, Batch 400] loss: 0.02601868473844661
[Epoch 17, Batch 500] loss: 0.01674826699178084
[Epoch 17, Batch 600] loss: 0.018632016991468846
[Epoch 17, Batch 700] loss: 0.02244370527434512
[Epoch 17, Batch 800] loss: 0.02066443475574488
[Epoch 17, Batch 900] loss: 0.020528474289822043
[Epoch 17, Batch 1000] loss: 0.014271422969541163
[Epoch 17, Batch 1100] loss: 0.019833227701310532
[Epoch 17, Batch 1200] loss: 0.02366386076559138
[Epoch 17, Batch 1300] loss: 0.022003826538057183
[Epoch 17, Batch 1400] loss: 0.020140742134681203
[Epoch 17, Batch 1500] loss: 0.02135169967343245
[Epoch 17, Batch 1600] loss: 0.013886780169268604
[Epoch 17, Batch 1700] loss: 0.018437525761946745
[Epoch 17, Batch 1800] loss: 0.02201027322174923
[Epoch 17, Batch 1900] loss: 0.029860494857693994
[Epoch 17, Batch 2000] loss: 0.02631188262057549
[Epoch 17, Batch 2100] loss: 0.02204935559129808
[Epoch 17, Batch 2200] loss: 0.01536039482220076
[Epoch 17, Batch 2300] loss: 0.026804956581181615
[Epoch 17, Batch 2400] loss: 0.038054766647255746
[Epoch 17, Batch 2500] loss: 0.018819558432005577
[Epoch 17, Batch 2600] loss: 0.03106727662467165
[Epoch 17, Batch 2700] loss: 0.024580134718198678
[Epoch 17, Batch 2800] loss: 0.017507962831514304
[Epoch 17, Batch 2900] loss: 0.012179675370080077
[Epoch 17, Batch 3000] loss: 0.03561124350610043
[Epoch 17, Batch 3100] loss: 0.024194041429873324
[Epoch 17, Batch 3200] loss: 0.013808116088948736
[Epoch 17, Batch 3300] loss: 0.01828420412966807
[Epoch 17, Batch 3400] loss: 0.022688326719362523
[Epoch 17, Batch 3500] loss: 0.021270218696154187
[Epoch 17, Batch 3600] loss: 0.019657502440059035
[Epoch 17, Batch 3700] loss: 0.026116213561253973
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0336
Overfitting: 0.0333
[Epoch 18, Batch 100] loss: 0.021854330097557977
[Epoch 18, Batch 200] loss: 0.012930620955085032
[Epoch 18, Batch 300] loss: 0.017028223332526977
[Epoch 18, Batch 400] loss: 0.01991969003051054
[Epoch 18, Batch 500] loss: 0.019233363914609072
[Epoch 18, Batch 600] loss: 0.014369862108796951
[Epoch 18, Batch 700] loss: 0.01565222524332057
[Epoch 18, Batch 800] loss: 0.012997411539472523
[Epoch 18, Batch 900] loss: 0.01872812827827147
[Epoch 18, Batch 1000] loss: 0.017994429945465528
[Epoch 18, Batch 1100] loss: 0.025369788418975078
[Epoch 18, Batch 1200] loss: 0.017596230585404556
[Epoch 18, Batch 1300] loss: 0.017730998473489308
[Epoch 18, Batch 1400] loss: 0.026671726108688745
[Epoch 18, Batch 1500] loss: 0.037335894549396474
[Epoch 18, Batch 1600] loss: 0.01963460218605178
[Epoch 18, Batch 1700] loss: 0.01898068614762451
[Epoch 18, Batch 1800] loss: 0.019961580054005026
[Epoch 18, Batch 1900] loss: 0.02184849172081158
[Epoch 18, Batch 2000] loss: 0.017168879479868338
[Epoch 18, Batch 2100] loss: 0.015116766420178465
[Epoch 18, Batch 2200] loss: 0.025705533902619208
[Epoch 18, Batch 2300] loss: 0.011988782347398228
[Epoch 18, Batch 2400] loss: 0.01724133913030073
[Epoch 18, Batch 2500] loss: 0.019916763594956137
[Epoch 18, Batch 2600] loss: 0.016782730469876696
[Epoch 18, Batch 2700] loss: 0.02894478696245642
[Epoch 18, Batch 2800] loss: 0.022784947331310833
[Epoch 18, Batch 2900] loss: 0.02286375356183271
[Epoch 18, Batch 3000] loss: 0.028115238988611964
[Epoch 18, Batch 3100] loss: 0.018322458757320418
[Epoch 18, Batch 3200] loss: 0.022738868589840422
[Epoch 18, Batch 3300] loss: 0.014936782259246684
[Epoch 18, Batch 3400] loss: 0.027935113115017885
[Epoch 18, Batch 3500] loss: 0.019301999937633808
[Epoch 18, Batch 3600] loss: 0.023362258172219298
[Epoch 18, Batch 3700] loss: 0.02698998570776894
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0362
Overfitting: 0.0359
[Epoch 19, Batch 100] loss: 0.018079537690973667
[Epoch 19, Batch 200] loss: 0.010680698151700198
[Epoch 19, Batch 300] loss: 0.015318783436887315
[Epoch 19, Batch 400] loss: 0.020719432202713505
[Epoch 19, Batch 500] loss: 0.03071037638463167
[Epoch 19, Batch 600] loss: 0.019883913929515985
[Epoch 19, Batch 700] loss: 0.019905684034893057
[Epoch 19, Batch 800] loss: 0.016712628550376394
[Epoch 19, Batch 900] loss: 0.013904845834767912
[Epoch 19, Batch 1000] loss: 0.028208837834717997
[Epoch 19, Batch 1100] loss: 0.011641002302931157
[Epoch 19, Batch 1200] loss: 0.019953641282336322
[Epoch 19, Batch 1300] loss: 0.011003705635521327
[Epoch 19, Batch 1400] loss: 0.01616218358845799
[Epoch 19, Batch 1500] loss: 0.014364302720241539
[Epoch 19, Batch 1600] loss: 0.01394648455123388
[Epoch 19, Batch 1700] loss: 0.01717507277200639
[Epoch 19, Batch 1800] loss: 0.02129816915083211
[Epoch 19, Batch 1900] loss: 0.018217356632230803
[Epoch 19, Batch 2000] loss: 0.015264906075099133
[Epoch 19, Batch 2100] loss: 0.015382616959759616
[Epoch 19, Batch 2200] loss: 0.013183104546405956
[Epoch 19, Batch 2300] loss: 0.01690866490769622
[Epoch 19, Batch 2400] loss: 0.01713265801576199
[Epoch 19, Batch 2500] loss: 0.019853079359963884
[Epoch 19, Batch 2600] loss: 0.019902334400139807
[Epoch 19, Batch 2700] loss: 0.013189372075758002
[Epoch 19, Batch 2800] loss: 0.025371663745190745
[Epoch 19, Batch 2900] loss: 0.016374939816159895
[Epoch 19, Batch 3000] loss: 0.023222400303220637
[Epoch 19, Batch 3100] loss: 0.030352969094601577
[Epoch 19, Batch 3200] loss: 0.017302580771738577
[Epoch 19, Batch 3300] loss: 0.028763584587140942
[Epoch 19, Batch 3400] loss: 0.021318609779700636
[Epoch 19, Batch 3500] loss: 0.016504612470889697
[Epoch 19, Batch 3600] loss: 0.020041893694178727
[Epoch 19, Batch 3700] loss: 0.02100979778002511
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0330
Overfitting: 0.0328
Best model saved at epoch 19 with training loss: 0.0002
[Epoch 20, Batch 100] loss: 0.01385269016995153
[Epoch 20, Batch 200] loss: 0.013179026924190112
[Epoch 20, Batch 300] loss: 0.02062323542391823
[Epoch 20, Batch 400] loss: 0.015445296764992235
[Epoch 20, Batch 500] loss: 0.014590214688942069
[Epoch 20, Batch 600] loss: 0.017527595517894953
[Epoch 20, Batch 700] loss: 0.015474107592963264
[Epoch 20, Batch 800] loss: 0.015517656273441389
[Epoch 20, Batch 900] loss: 0.021709127174690365
[Epoch 20, Batch 1000] loss: 0.02359878950705024
[Epoch 20, Batch 1100] loss: 0.01492609287299274
[Epoch 20, Batch 1200] loss: 0.033564828598573515
[Epoch 20, Batch 1300] loss: 0.017621366295315966
[Epoch 20, Batch 1400] loss: 0.01005063375701866
[Epoch 20, Batch 1500] loss: 0.016366695970573344
[Epoch 20, Batch 1600] loss: 0.01659362289487035
[Epoch 20, Batch 1700] loss: 0.017758588004980994
[Epoch 20, Batch 1800] loss: 0.014100900475268645
[Epoch 20, Batch 1900] loss: 0.013026301533209335
[Epoch 20, Batch 2000] loss: 0.015993970705130776
[Epoch 20, Batch 2100] loss: 0.01649014817750867
[Epoch 20, Batch 2200] loss: 0.021120835770343547
[Epoch 20, Batch 2300] loss: 0.0207059106568704
[Epoch 20, Batch 2400] loss: 0.02281741494909511
[Epoch 20, Batch 2500] loss: 0.01820605152126518
[Epoch 20, Batch 2600] loss: 0.015609560799675818
[Epoch 20, Batch 2700] loss: 0.01485506957356847
[Epoch 20, Batch 2800] loss: 0.00907435033674119
[Epoch 20, Batch 2900] loss: 0.01798997564401361
[Epoch 20, Batch 3000] loss: 0.020584756468724662
[Epoch 20, Batch 3100] loss: 0.027304016134003177
[Epoch 20, Batch 3200] loss: 0.011981546494280338
[Epoch 20, Batch 3300] loss: 0.011156014776897791
[Epoch 20, Batch 3400] loss: 0.018475316178992215
[Epoch 20, Batch 3500] loss: 0.018740372122811096
[Epoch 20, Batch 3600] loss: 0.017748780532456293
[Epoch 20, Batch 3700] loss: 0.023416115431173237
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0350
Overfitting: 0.0347
[Epoch 21, Batch 100] loss: 0.01250078183162259
[Epoch 21, Batch 200] loss: 0.012230017110996414
[Epoch 21, Batch 300] loss: 0.013695753023303042
[Epoch 21, Batch 400] loss: 0.01311954703724041
[Epoch 21, Batch 500] loss: 0.009696412065932237
[Epoch 21, Batch 600] loss: 0.017050714637480268
[Epoch 21, Batch 700] loss: 0.0201067906391836
[Epoch 21, Batch 800] loss: 0.009866597436966914
[Epoch 21, Batch 900] loss: 0.018148115695948944
[Epoch 21, Batch 1000] loss: 0.013693142448337312
[Epoch 21, Batch 1100] loss: 0.017855000010022194
[Epoch 21, Batch 1200] loss: 0.009199683180304419
[Epoch 21, Batch 1300] loss: 0.016763611805363326
[Epoch 21, Batch 1400] loss: 0.012728459077798106
[Epoch 21, Batch 1500] loss: 0.01638026945260208
[Epoch 21, Batch 1600] loss: 0.017361870558179362
[Epoch 21, Batch 1700] loss: 0.017159872809643276
[Epoch 21, Batch 1800] loss: 0.019466660855687223
[Epoch 21, Batch 1900] loss: 0.022455684064880188
[Epoch 21, Batch 2000] loss: 0.016049891694565305
[Epoch 21, Batch 2100] loss: 0.02052736435092811
[Epoch 21, Batch 2200] loss: 0.02079297276570287
[Epoch 21, Batch 2300] loss: 0.010273901071159344
[Epoch 21, Batch 2400] loss: 0.014441742564777087
[Epoch 21, Batch 2500] loss: 0.008331043699072324
[Epoch 21, Batch 2600] loss: 0.013105705050638789
[Epoch 21, Batch 2700] loss: 0.020335573804513844
[Epoch 21, Batch 2800] loss: 0.026677239121818276
[Epoch 21, Batch 2900] loss: 0.017606037689911317
[Epoch 21, Batch 3000] loss: 0.014635758113945485
[Epoch 21, Batch 3100] loss: 0.018406410295147
[Epoch 21, Batch 3200] loss: 0.02342069062175142
[Epoch 21, Batch 3300] loss: 0.024931135602782886
[Epoch 21, Batch 3400] loss: 0.01857002775934234
[Epoch 21, Batch 3500] loss: 0.012941026508706273
[Epoch 21, Batch 3600] loss: 0.01977922303939522
[Epoch 21, Batch 3700] loss: 0.012864415828044002
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0310
Overfitting: 0.0307
[Epoch 22, Batch 100] loss: 0.025556719936794252
[Epoch 22, Batch 200] loss: 0.02149779052597296
[Epoch 22, Batch 300] loss: 0.0158121810852208
[Epoch 22, Batch 400] loss: 0.015860916131750856
[Epoch 22, Batch 500] loss: 0.022847141006222954
[Epoch 22, Batch 600] loss: 0.013432100507598079
[Epoch 22, Batch 700] loss: 0.010429892373740585
[Epoch 22, Batch 800] loss: 0.018971933206848916
[Epoch 22, Batch 900] loss: 0.011750237486921833
[Epoch 22, Batch 1000] loss: 0.012837583962282224
[Epoch 22, Batch 1100] loss: 0.013569552207554807
[Epoch 22, Batch 1200] loss: 0.02006504435390525
[Epoch 22, Batch 1300] loss: 0.011668905896658543
[Epoch 22, Batch 1400] loss: 0.012339043283136562
[Epoch 22, Batch 1500] loss: 0.006961576123849227
[Epoch 22, Batch 1600] loss: 0.019389075648214203
[Epoch 22, Batch 1700] loss: 0.015332224526828213
[Epoch 22, Batch 1800] loss: 0.013089458033500706
[Epoch 22, Batch 1900] loss: 0.011261568734335014
[Epoch 22, Batch 2000] loss: 0.007334145934344179
[Epoch 22, Batch 2100] loss: 0.015836013226762587
[Epoch 22, Batch 2200] loss: 0.01299738502180844
[Epoch 22, Batch 2300] loss: 0.0156459432615884
[Epoch 22, Batch 2400] loss: 0.015663119709388412
[Epoch 22, Batch 2500] loss: 0.015551079189472149
[Epoch 22, Batch 2600] loss: 0.016431752093631076
[Epoch 22, Batch 2700] loss: 0.02346115651580476
[Epoch 22, Batch 2800] loss: 0.021555417998961275
[Epoch 22, Batch 2900] loss: 0.010926626469317852
[Epoch 22, Batch 3000] loss: 0.016462635395546387
[Epoch 22, Batch 3100] loss: 0.01220982424889371
[Epoch 22, Batch 3200] loss: 0.007862060213992663
[Epoch 22, Batch 3300] loss: 0.01340493411060379
[Epoch 22, Batch 3400] loss: 0.011376773354350007
[Epoch 22, Batch 3500] loss: 0.015292859651199251
[Epoch 22, Batch 3600] loss: 0.020898300857916184
[Epoch 22, Batch 3700] loss: 0.011695430073341413
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0354
Overfitting: 0.0352
[Epoch 23, Batch 100] loss: 0.01449534190025588
[Epoch 23, Batch 200] loss: 0.0171314851592615
[Epoch 23, Batch 300] loss: 0.024560534104311957
[Epoch 23, Batch 400] loss: 0.01184368664478825
[Epoch 23, Batch 500] loss: 0.016374273652854755
[Epoch 23, Batch 600] loss: 0.0074249143126326085
[Epoch 23, Batch 700] loss: 0.009038986601071884
[Epoch 23, Batch 800] loss: 0.013959584170761445
[Epoch 23, Batch 900] loss: 0.009267909135942318
[Epoch 23, Batch 1000] loss: 0.009140902250783256
[Epoch 23, Batch 1100] loss: 0.014660997153114294
[Epoch 23, Batch 1200] loss: 0.01801049752610197
[Epoch 23, Batch 1300] loss: 0.012720119432469802
[Epoch 23, Batch 1400] loss: 0.009130385397456848
[Epoch 23, Batch 1500] loss: 0.01462876153711477
[Epoch 23, Batch 1600] loss: 0.007523202800284707
[Epoch 23, Batch 1700] loss: 0.016852495661587454
[Epoch 23, Batch 1800] loss: 0.015079394768126803
[Epoch 23, Batch 1900] loss: 0.009123622587540013
[Epoch 23, Batch 2000] loss: 0.009199323781494968
[Epoch 23, Batch 2100] loss: 0.007920957543417444
[Epoch 23, Batch 2200] loss: 0.010305887486465508
[Epoch 23, Batch 2300] loss: 0.010967964987376035
[Epoch 23, Batch 2400] loss: 0.023376346651548374
[Epoch 23, Batch 2500] loss: 0.016706477803854796
[Epoch 23, Batch 2600] loss: 0.011684385354146797
[Epoch 23, Batch 2700] loss: 0.011363127328277187
[Epoch 23, Batch 2800] loss: 0.013882276832209755
[Epoch 23, Batch 2900] loss: 0.019254426247480295
[Epoch 23, Batch 3000] loss: 0.026686272660517717
[Epoch 23, Batch 3100] loss: 0.020127839742126525
[Epoch 23, Batch 3200] loss: 0.015476162193117489
[Epoch 23, Batch 3300] loss: 0.020791824032844488
[Epoch 23, Batch 3400] loss: 0.013636302055856505
[Epoch 23, Batch 3500] loss: 0.01583363319223281
[Epoch 23, Batch 3600] loss: 0.015423889784724452
[Epoch 23, Batch 3700] loss: 0.014492138013920339
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0317
Overfitting: 0.0315
[Epoch 24, Batch 100] loss: 0.006241697857494728
[Epoch 24, Batch 200] loss: 0.013845146481326082
[Epoch 24, Batch 300] loss: 0.009819250008449671
[Epoch 24, Batch 400] loss: 0.008613378491209005
[Epoch 24, Batch 500] loss: 0.01129986388062207
[Epoch 24, Batch 600] loss: 0.009222592296955554
[Epoch 24, Batch 700] loss: 0.00904421525181533
[Epoch 24, Batch 800] loss: 0.007361589646752691
[Epoch 24, Batch 900] loss: 0.005908782667984269
[Epoch 24, Batch 1000] loss: 0.018435768572908275
[Epoch 24, Batch 1100] loss: 0.013142077285779123
[Epoch 24, Batch 1200] loss: 0.01641469272469294
[Epoch 24, Batch 1300] loss: 0.00962893369775884
[Epoch 24, Batch 1400] loss: 0.012126917758587296
[Epoch 24, Batch 1500] loss: 0.012533170217920997
[Epoch 24, Batch 1600] loss: 0.015502689337881747
[Epoch 24, Batch 1700] loss: 0.011619461630107252
[Epoch 24, Batch 1800] loss: 0.01284271632088803
[Epoch 24, Batch 1900] loss: 0.012734615856134042
[Epoch 24, Batch 2000] loss: 0.010911920877588273
[Epoch 24, Batch 2100] loss: 0.010812468701642501
[Epoch 24, Batch 2200] loss: 0.02328362759157244
[Epoch 24, Batch 2300] loss: 0.021185192932553037
[Epoch 24, Batch 2400] loss: 0.007789028561041959
[Epoch 24, Batch 2500] loss: 0.009699214938382283
[Epoch 24, Batch 2600] loss: 0.009063555760344571
[Epoch 24, Batch 2700] loss: 0.02854285363064264
[Epoch 24, Batch 2800] loss: 0.012504999235534341
[Epoch 24, Batch 2900] loss: 0.017662329349705033
[Epoch 24, Batch 3000] loss: 0.023222343793604522
[Epoch 24, Batch 3100] loss: 0.015870331566497954
[Epoch 24, Batch 3200] loss: 0.011206561348335526
[Epoch 24, Batch 3300] loss: 0.01471460094617214
[Epoch 24, Batch 3400] loss: 0.010820897556041018
[Epoch 24, Batch 3500] loss: 0.015056505967932026
[Epoch 24, Batch 3600] loss: 0.020698776820145214
[Epoch 24, Batch 3700] loss: 0.009707656360451438
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0325
Overfitting: 0.0324
qt.qpa.xcb: X server does not support XInput 2
+++FINAL STATS++++
Training Loss 0.00018143289074699473
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Test set to find Test loss for overfitting
 Testing loss : 0.0325
Calculated Overfitting : 0.0324
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.00032927591344236165, 'batch_size': 16} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9889
Total time taken for hyperparameter tuning and evaluation: 5:54:12
/home/ahussain/PycharmProjects/optunaNew/Median_pruner_Testing.py:493: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.

Traceback (most recent call last):
  File "/home/ahussain/PycharmProjects/optunaNew/Median_pruner_Testing.py", line 500, in <module>
    run_optuna(num_samples=NUM_SAMPLES)
  File "/home/ahussain/PycharmProjects/optunaNew/Median_pruner_Testing.py", line 495, in run_optuna
    fig2.write_image("IResults/TPE/Ranges_dec_10/timeline_Split5_median_ranges_AAG.png")
  File "/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/plotly/basedatatypes.py", line 3835, in write_image
    return pio.write_image(self, *args, **kwargs)
  File "/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/plotly/io/_kaleido.py", line 296, in write_image
    path.write_bytes(img_data)
  File "/usr/lib/python3.8/pathlib.py", line 1245, in write_bytes
    with self.open(mode='wb') as f:
  File "/usr/lib/python3.8/pathlib.py", line 1222, in open
    return io.open(self, mode, buffering, encoding, errors, newline,
  File "/usr/lib/python3.8/pathlib.py", line 1078, in _opener
    return self._accessor.open(self, flags, mode)
FileNotFoundError: [Errno 2] No such file or directory: 'IResults/TPE/Ranges_dec_10/timeline_Split5_median_ranges.png'

Process finished with exit code 1

