
EPOCHS = 24
CLASSES = 10
INNER_FOLD = 2
NUM_SAMPLES = 24
DIR = os.getcwd()

#---------PRUNER SETTINGS--------------
N_STARTUP_TRIALS_PRUNNER = 8 
N_WARMUP_STEPS = 8           .
INTERVAL_STEPS = 1           

N_MIN_TRIALS = 8             
#---------TPE SETTINGS-----------------
N_STARTUP_TRIALS = 8    

---------------------------------------------------------------------------

[I 2024-11-19 03:12:08,356] Trial 23 pruned. 
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  5
  Number of complete trials:  19
Best hyperparameters found:
{'l1': 224, 'l2': 224, 'lr': 0.008471801418819975, 'batch_size': 256}
Best trial:
  Value:  0.05886771301817843
--------------------------------------------------------------------------
Average training loss: 0.0008
Best model saved at epoch 24 with training loss: 0.0008
Using best hyperparameters {'l1': 224, 'l2': 224, 'lr': 0.008471801418819975, 'batch_size': 256} on final Test set to find Test loss for overfitting
Testing loss : 0.0418
Calculated Overfitting : 0.0410
Using best hyperparameters {'l1': 224, 'l2': 224, 'lr': 0.008471801418819975, 'batch_size': 256} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9869
Total time taken for hyperparameter tuning and evaluation: 3:14:56
------------------------------------------------------------------------


[I 2024-11-18 23:59:59,279] A new study created in RDB with name: MedianPruner_ranges

Selected Hyperparameters for Trial 1:
  l1: 224, l2: 224, lr: 0.008471801418819975, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.580664322078228
**STATS for Epoch 1** : 
Average training loss: 0.0555
Average validation loss: 0.3233
Validation Accuracy: 0.9002
Overfitting: 0.2678
Best model saved at epoch 1 with validation loss: 0.3233
[Epoch 2, Batch 100] loss: 0.22961926087737083
**STATS for Epoch 2** : 
Average training loss: 0.0211
Average validation loss: 0.1543
Validation Accuracy: 0.9523
Overfitting: 0.1332
Best model saved at epoch 2 with validation loss: 0.1543
[Epoch 3, Batch 100] loss: 0.12785292454063893
**STATS for Epoch 3** : 
Average training loss: 0.0154
Average validation loss: 0.1066
Validation Accuracy: 0.9675
Overfitting: 0.0912
Best model saved at epoch 3 with validation loss: 0.1066
[Epoch 4, Batch 100] loss: 0.09565693758428097
**STATS for Epoch 4** : 
Average training loss: 0.0138
Average validation loss: 0.0951
Validation Accuracy: 0.9696
Overfitting: 0.0813
Best model saved at epoch 4 with validation loss: 0.0951
[Epoch 5, Batch 100] loss: 0.07705986412242055
**STATS for Epoch 5** : 
Average training loss: 0.0130
Average validation loss: 0.0839
Validation Accuracy: 0.9738
Overfitting: 0.0709
Best model saved at epoch 5 with validation loss: 0.0839
[Epoch 6, Batch 100] loss: 0.0677388141490519
**STATS for Epoch 6** : 
Average training loss: 0.0111
Average validation loss: 0.0745
Validation Accuracy: 0.9764
Overfitting: 0.0634
Best model saved at epoch 6 with validation loss: 0.0745
[Epoch 7, Batch 100] loss: 0.06019387064501643
**STATS for Epoch 7** : 
Average training loss: 0.0076
Average validation loss: 0.0755
Validation Accuracy: 0.9758
Overfitting: 0.0679
[Epoch 8, Batch 100] loss: 0.05328584061935544
**STATS for Epoch 8** : 
Average training loss: 0.0078
Average validation loss: 0.0674
Validation Accuracy: 0.9789
Overfitting: 0.0597
Best model saved at epoch 8 with validation loss: 0.0674
[Epoch 9, Batch 100] loss: 0.04564619437791407
**STATS for Epoch 9** : 
Average training loss: 0.0070
Average validation loss: 0.0606
Validation Accuracy: 0.9814
Overfitting: 0.0536
Best model saved at epoch 9 with validation loss: 0.0606
[Epoch 10, Batch 100] loss: 0.039746004538610574
**STATS for Epoch 10** : 
Average training loss: 0.0067
Average validation loss: 0.0687
Validation Accuracy: 0.9784
Overfitting: 0.0620
[Epoch 11, Batch 100] loss: 0.04250285779125988
**STATS for Epoch 11** : 
Average training loss: 0.0062
Average validation loss: 0.0577
Validation Accuracy: 0.9820
Overfitting: 0.0515
Best model saved at epoch 11 with validation loss: 0.0577
[Epoch 12, Batch 100] loss: 0.034206300638616086
**STATS for Epoch 12** : 
Average training loss: 0.0051
Average validation loss: 0.0572
Validation Accuracy: 0.9831
Overfitting: 0.0521
Best model saved at epoch 12 with validation loss: 0.0572
[Epoch 13, Batch 100] loss: 0.02834750697016716
**STATS for Epoch 13** : 
Average training loss: 0.0045
Average validation loss: 0.0565
Validation Accuracy: 0.9836
Overfitting: 0.0520
Best model saved at epoch 13 with validation loss: 0.0565
[Epoch 14, Batch 100] loss: 0.02779213708359748
**STATS for Epoch 14** : 
Average training loss: 0.0050
Average validation loss: 0.0659
Validation Accuracy: 0.9799
Overfitting: 0.0609
[Epoch 15, Batch 100] loss: 0.025573172741569578
**STATS for Epoch 15** : 
Average training loss: 0.0032
Average validation loss: 0.0620
Validation Accuracy: 0.9819
Overfitting: 0.0588
[Epoch 16, Batch 100] loss: 0.0238215568754822
**STATS for Epoch 16** : 
Average training loss: 0.0050
Average validation loss: 0.0577
Validation Accuracy: 0.9831
Overfitting: 0.0526
[Epoch 17, Batch 100] loss: 0.0236114582978189
**STATS for Epoch 17** : 
Average training loss: 0.0034
Average validation loss: 0.0577
Validation Accuracy: 0.9832
Overfitting: 0.0542
[Epoch 18, Batch 100] loss: 0.017787929074838758
**STATS for Epoch 18** : 
Average training loss: 0.0033
Average validation loss: 0.0604
Validation Accuracy: 0.9827
Overfitting: 0.0571
[Epoch 19, Batch 100] loss: 0.01739074645796791
**STATS for Epoch 19** : 
Average training loss: 0.0033
Average validation loss: 0.0640
Validation Accuracy: 0.9806
Overfitting: 0.0607
[Epoch 20, Batch 100] loss: 0.014101334086153655
**STATS for Epoch 20** : 
Average training loss: 0.0029
Average validation loss: 0.0580
Validation Accuracy: 0.9840
Overfitting: 0.0551
[Epoch 21, Batch 100] loss: 0.013404580927453936
**STATS for Epoch 21** : 
Average training loss: 0.0015
Average validation loss: 0.0549
Validation Accuracy: 0.9849
Overfitting: 0.0534
Best model saved at epoch 21 with validation loss: 0.0549
[Epoch 22, Batch 100] loss: 0.011436475533409976
**STATS for Epoch 22** : 
Average training loss: 0.0018
Average validation loss: 0.0561
Validation Accuracy: 0.9845
Overfitting: 0.0543
[Epoch 23, Batch 100] loss: 0.011847267793491482
**STATS for Epoch 23** : 
Average training loss: 0.0016
Average validation loss: 0.0571
Validation Accuracy: 0.9848
Overfitting: 0.0555
[Epoch 24, Batch 100] loss: 0.010222992352209985
**STATS for Epoch 24** : 
Average training loss: 0.0017
Average validation loss: 0.0597
Validation Accuracy: 0.9840
Overfitting: 0.0580
Fold 1 validation loss: 0.0597
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.3693165582418443
**STATS for Epoch 1** : 
Average training loss: 0.0588
Average validation loss: 0.3360
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
Validation Accuracy: 0.9008
Overfitting: 0.2772
Best model saved at epoch 1 with validation loss: 0.3360
[Epoch 2, Batch 100] loss: 0.24040359683334828
**STATS for Epoch 2** : 
Average training loss: 0.0270
Average validation loss: 0.1750
Validation Accuracy: 0.9469
Overfitting: 0.1480
Best model saved at epoch 2 with validation loss: 0.1750
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 1 is already reported.
  warnings.warn(
[Epoch 3, Batch 100] loss: 0.14364072248339654
**STATS for Epoch 3** : 
Average training loss: 0.0212
Average validation loss: 0.1338
Validation Accuracy: 0.9594
Overfitting: 0.1127
Best model saved at epoch 3 with validation loss: 0.1338
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 2 is already reported.
  warnings.warn(
[Epoch 4, Batch 100] loss: 0.10892371084541082
**STATS for Epoch 4** : 
Average training loss: 0.0161
Average validation loss: 0.1181
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 3 is already reported.
  warnings.warn(
Validation Accuracy: 0.9659
Overfitting: 0.1020
Best model saved at epoch 4 with validation loss: 0.1181
[Epoch 5, Batch 100] loss: 0.08976466102525592
**STATS for Epoch 5** : 
Average training loss: 0.0127
Average validation loss: 0.1028
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 4 is already reported.
  warnings.warn(
Validation Accuracy: 0.9678
Overfitting: 0.0901
Best model saved at epoch 5 with validation loss: 0.1028
[Epoch 6, Batch 100] loss: 0.07435274574905634
**STATS for Epoch 6** : 
Average training loss: 0.0120
Average validation loss: 0.0844
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 5 is already reported.
  warnings.warn(
Validation Accuracy: 0.9745
Overfitting: 0.0724
Best model saved at epoch 6 with validation loss: 0.0844
[Epoch 7, Batch 100] loss: 0.06468775298446416
**STATS for Epoch 7** : 
Average training loss: 0.0094
Average validation loss: 0.0789
Validation Accuracy: 0.9758
Overfitting: 0.0695
Best model saved at epoch 7 with validation loss: 0.0789
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 6 is already reported.
  warnings.warn(
[Epoch 8, Batch 100] loss: 0.059123902004212144
**STATS for Epoch 8** : 
Average training loss: 0.0088
Average validation loss: 0.0716
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 7 is already reported.
  warnings.warn(
Validation Accuracy: 0.9790
Overfitting: 0.0628
Best model saved at epoch 8 with validation loss: 0.0716
[Epoch 9, Batch 100] loss: 0.05417422115802765
**STATS for Epoch 9** : 
Average training loss: 0.0072
Average validation loss: 0.0703
Validation Accuracy: 0.9787
Overfitting: 0.0630
Best model saved at epoch 9 with validation loss: 0.0703
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 8 is already reported.
  warnings.warn(
[Epoch 10, Batch 100] loss: 0.04481691092252731
**STATS for Epoch 10** : 
Average training loss: 0.0086
Average validation loss: 0.0896
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 9 is already reported.
  warnings.warn(
Validation Accuracy: 0.9725
Overfitting: 0.0809
[Epoch 11, Batch 100] loss: 0.04250792738981545
**STATS for Epoch 11** : 
Average training loss: 0.0069
Average validation loss: 0.0660
Validation Accuracy: 0.9796
Overfitting: 0.0591
Best model saved at epoch 11 with validation loss: 0.0660
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 10 is already reported.
  warnings.warn(
[Epoch 12, Batch 100] loss: 0.037706134663894775
**STATS for Epoch 12** : 
Average training loss: 0.0055
Average validation loss: 0.0577
Validation Accuracy: 0.9835
Overfitting: 0.0522
Best model saved at epoch 12 with validation loss: 0.0577
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 11 is already reported.
  warnings.warn(
[Epoch 13, Batch 100] loss: 0.032688402542844414
**STATS for Epoch 13** : 
Average training loss: 0.0059
Average validation loss: 0.0647
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 12 is already reported.
  warnings.warn(
Validation Accuracy: 0.9808
Overfitting: 0.0588
[Epoch 14, Batch 100] loss: 0.029005845203064384
**STATS for Epoch 14** : 
Average training loss: 0.0048
Average validation loss: 0.0594
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 13 is already reported.
  warnings.warn(
Validation Accuracy: 0.9827
Overfitting: 0.0546
[Epoch 15, Batch 100] loss: 0.026264438428916036
**STATS for Epoch 15** : 
Average training loss: 0.0041
Average validation loss: 0.0612
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 14 is already reported.
  warnings.warn(
Validation Accuracy: 0.9813
Overfitting: 0.0571
[Epoch 16, Batch 100] loss: 0.024722195412032306
**STATS for Epoch 16** : 
Average training loss: 0.0035
Average validation loss: 0.0564
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 15 is already reported.
  warnings.warn(
Validation Accuracy: 0.9837
Overfitting: 0.0529
Best model saved at epoch 16 with validation loss: 0.0564
[Epoch 17, Batch 100] loss: 0.020354065215215086
**STATS for Epoch 17** : 
Average training loss: 0.0034
Average validation loss: 0.0566
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 16 is already reported.
  warnings.warn(
Validation Accuracy: 0.9839
Overfitting: 0.0532
[Epoch 18, Batch 100] loss: 0.020573155716992916
**STATS for Epoch 18** : 
Average training loss: 0.0036
Average validation loss: 0.0613
Validation Accuracy: 0.9819
Overfitting: 0.0577
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 17 is already reported.
  warnings.warn(
[Epoch 19, Batch 100] loss: 0.01719288538908586
**STATS for Epoch 19** : 
Average training loss: 0.0020
Average validation loss: 0.0547
Validation Accuracy: 0.9843
Overfitting: 0.0527
Best model saved at epoch 19 with validation loss: 0.0547
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 18 is already reported.
  warnings.warn(
[Epoch 20, Batch 100] loss: 0.014770401127170771
**STATS for Epoch 20** : 
Average training loss: 0.0018
Average validation loss: 0.0554
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 19 is already reported.
  warnings.warn(
Validation Accuracy: 0.9843
Overfitting: 0.0536
[Epoch 21, Batch 100] loss: 0.011752861016429961
**STATS for Epoch 21** : 
Average training loss: 0.0026
Average validation loss: 0.0554
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 20 is already reported.
  warnings.warn(
Validation Accuracy: 0.9844
Overfitting: 0.0529
[Epoch 22, Batch 100] loss: 0.01162736074300483
**STATS for Epoch 22** : 
Average training loss: 0.0015
Average validation loss: 0.0565
Validation Accuracy: 0.9846
Overfitting: 0.0549
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 21 is already reported.
  warnings.warn(
[Epoch 23, Batch 100] loss: 0.011432702341116964
**STATS for Epoch 23** : 
Average training loss: 0.0022
Average validation loss: 0.0643
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 22 is already reported.
  warnings.warn(
Validation Accuracy: 0.9828
Overfitting: 0.0621
[Epoch 24, Batch 100] loss: 0.010388280433835462
**STATS for Epoch 24** : 
Average training loss: 0.0011
Average validation loss: 0.0581
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 23 is already reported.
  warnings.warn(
Validation Accuracy: 0.9847
Overfitting: 0.0570
Fold 2 validation loss: 0.0581
Mean validation loss across all folds for Trial 1 is 0.0589 with trial config:  l1: 224, l2: 224, lr: 0.008471801418819975, batch_size: 256
[I 2024-11-19 00:08:36,161] Trial 0 finished with value: 0.05886771301817843 and parameters: {'l1': 224, 'l2': 224, 'lr': 0.008471801418819975, 'batch_size': 256}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 2:
  l1: 352, l2: 256, lr: 1.2087541473056957e-05, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3054881930351256
[Epoch 1, Batch 200] loss: 2.3040704202651976
[Epoch 1, Batch 300] loss: 2.3036332082748414
[Epoch 1, Batch 400] loss: 2.3045704698562623
[Epoch 1, Batch 500] loss: 2.3040950202941897
[Epoch 1, Batch 600] loss: 2.3048598742485047
[Epoch 1, Batch 700] loss: 2.3034872937202455
[Epoch 1, Batch 800] loss: 2.3029174971580506
[Epoch 1, Batch 900] loss: 2.303027420043945
[Epoch 1, Batch 1000] loss: 2.302058444023132
[Epoch 1, Batch 1100] loss: 2.301860091686249
[Epoch 1, Batch 1200] loss: 2.30290598154068
[Epoch 1, Batch 1300] loss: 2.3005780816078185
[Epoch 1, Batch 1400] loss: 2.3001007866859435
[Epoch 1, Batch 1500] loss: 2.3031134557724
[Epoch 1, Batch 1600] loss: 2.3008742141723633
[Epoch 1, Batch 1700] loss: 2.3004950404167177
[Epoch 1, Batch 1800] loss: 2.300157940387726
**STATS for Epoch 1** : 
Average training loss: 0.0920
Average validation loss: 2.2999
Validation Accuracy: 0.1051
Overfitting: 2.2079
Best model saved at epoch 1 with validation loss: 2.2999
[Epoch 2, Batch 100] loss: 2.29911465883255
[Epoch 2, Batch 200] loss: 2.2986357617378235
[Epoch 2, Batch 300] loss: 2.2998853945732116
[Epoch 2, Batch 400] loss: 2.2989827966690064
[Epoch 2, Batch 500] loss: 2.2976582741737364
[Epoch 2, Batch 600] loss: 2.296600754261017
[Epoch 2, Batch 700] loss: 2.2969313883781433
[Epoch 2, Batch 800] loss: 2.2979063487052915
[Epoch 2, Batch 900] loss: 2.298662145137787
[Epoch 2, Batch 1000] loss: 2.295215768814087
[Epoch 2, Batch 1100] loss: 2.2962672686576844
[Epoch 2, Batch 1200] loss: 2.295498998165131
[Epoch 2, Batch 1300] loss: 2.295945255756378
[Epoch 2, Batch 1400] loss: 2.2973721623420715
[Epoch 2, Batch 1500] loss: 2.2965232586860655
[Epoch 2, Batch 1600] loss: 2.295148513317108
[Epoch 2, Batch 1700] loss: 2.296278228759766
[Epoch 2, Batch 1800] loss: 2.295433077812195
**STATS for Epoch 2** : 
Average training loss: 0.0917
Average validation loss: 2.2942
Validation Accuracy: 0.1177
Overfitting: 2.2024
Best model saved at epoch 2 with validation loss: 2.2942
[Epoch 3, Batch 100] loss: 2.293903796672821
[Epoch 3, Batch 200] loss: 2.2947856545448304
[Epoch 3, Batch 300] loss: 2.29266357421875
[Epoch 3, Batch 400] loss: 2.2951720190048217
[Epoch 3, Batch 500] loss: 2.2918858098983765
[Epoch 3, Batch 600] loss: 2.293592598438263
[Epoch 3, Batch 700] loss: 2.2918053531646727
[Epoch 3, Batch 800] loss: 2.292578942775726
[Epoch 3, Batch 900] loss: 2.291945095062256
[Epoch 3, Batch 1000] loss: 2.2923283624649047
[Epoch 3, Batch 1100] loss: 2.2889697456359865
[Epoch 3, Batch 1200] loss: 2.290403141975403
[Epoch 3, Batch 1300] loss: 2.289984269142151
[Epoch 3, Batch 1400] loss: 2.2903454065322877
[Epoch 3, Batch 1500] loss: 2.2899675250053404
[Epoch 3, Batch 1600] loss: 2.2866035103797913
[Epoch 3, Batch 1700] loss: 2.2869303321838377
[Epoch 3, Batch 1800] loss: 2.286989448070526
**STATS for Epoch 3** : 
Average training loss: 0.0914
Average validation loss: 2.2878
Validation Accuracy: 0.1446
Overfitting: 2.1963
Best model saved at epoch 3 with validation loss: 2.2878
[Epoch 4, Batch 100] loss: 2.286663556098938
[Epoch 4, Batch 200] loss: 2.2880407977104187
[Epoch 4, Batch 300] loss: 2.2854387736320496
[Epoch 4, Batch 400] loss: 2.2867327332496643
[Epoch 4, Batch 500] loss: 2.286454691886902
[Epoch 4, Batch 600] loss: 2.284337615966797
[Epoch 4, Batch 700] loss: 2.283640468120575
[Epoch 4, Batch 800] loss: 2.2842419242858885
[Epoch 4, Batch 900] loss: 2.2862600302696228
[Epoch 4, Batch 1000] loss: 2.2857394313812254
[Epoch 4, Batch 1100] loss: 2.2858510041236877
[Epoch 4, Batch 1200] loss: 2.283517997264862
[Epoch 4, Batch 1300] loss: 2.283746120929718
[Epoch 4, Batch 1400] loss: 2.283505744934082
[Epoch 4, Batch 1500] loss: 2.282426311969757
[Epoch 4, Batch 1600] loss: 2.2797488021850585
[Epoch 4, Batch 1700] loss: 2.28038547039032
[Epoch 4, Batch 1800] loss: 2.2798608350753784
**STATS for Epoch 4** : 
Average training loss: 0.0911
Average validation loss: 2.2802
Validation Accuracy: 0.1811
Overfitting: 2.1890
Best model saved at epoch 4 with validation loss: 2.2802
[Epoch 5, Batch 100] loss: 2.278719758987427
[Epoch 5, Batch 200] loss: 2.280000376701355
[Epoch 5, Batch 300] loss: 2.279980871677399
[Epoch 5, Batch 400] loss: 2.2784179186820985
[Epoch 5, Batch 500] loss: 2.2787446093559267
[Epoch 5, Batch 600] loss: 2.275773060321808
[Epoch 5, Batch 700] loss: 2.2767892265319825
[Epoch 5, Batch 800] loss: 2.276055691242218
[Epoch 5, Batch 900] loss: 2.2741547346115114
[Epoch 5, Batch 1000] loss: 2.2773738002777097
[Epoch 5, Batch 1100] loss: 2.275582251548767
[Epoch 5, Batch 1200] loss: 2.2759368991851807
[Epoch 5, Batch 1300] loss: 2.274328305721283
[Epoch 5, Batch 1400] loss: 2.273276562690735
[Epoch 5, Batch 1500] loss: 2.273317449092865
[Epoch 5, Batch 1600] loss: 2.2728705430030822
[Epoch 5, Batch 1700] loss: 2.271809768676758
[Epoch 5, Batch 1800] loss: 2.269029633998871
**STATS for Epoch 5** : 
Average training loss: 0.0909
Average validation loss: 2.2706
Validation Accuracy: 0.2585
Overfitting: 2.1797
Best model saved at epoch 5 with validation loss: 2.2706
[Epoch 6, Batch 100] loss: 2.270072422027588
[Epoch 6, Batch 200] loss: 2.2690878033638002
[Epoch 6, Batch 300] loss: 2.2698530292510988
[Epoch 6, Batch 400] loss: 2.267315299510956
[Epoch 6, Batch 500] loss: 2.2663370609283446
[Epoch 6, Batch 600] loss: 2.2664960265159606
[Epoch 6, Batch 700] loss: 2.2665923404693604
[Epoch 6, Batch 800] loss: 2.2653540062904356
[Epoch 6, Batch 900] loss: 2.266659815311432
[Epoch 6, Batch 1000] loss: 2.2653010296821594
[Epoch 6, Batch 1100] loss: 2.2622333765029907
[Epoch 6, Batch 1200] loss: 2.260939209461212
[Epoch 6, Batch 1300] loss: 2.26454149723053
[Epoch 6, Batch 1400] loss: 2.2625902891159058
[Epoch 6, Batch 1500] loss: 2.2627223134040833
[Epoch 6, Batch 1600] loss: 2.2601975655555724
[Epoch 6, Batch 1700] loss: 2.2609725189208985
[Epoch 6, Batch 1800] loss: 2.2590413188934324
**STATS for Epoch 6** : 
Average training loss: 0.0903
Average validation loss: 2.2577
Validation Accuracy: 0.3122
Overfitting: 2.1674
Best model saved at epoch 6 with validation loss: 2.2577
[Epoch 7, Batch 100] loss: 2.257553205490112
[Epoch 7, Batch 200] loss: 2.2566073536872864
[Epoch 7, Batch 300] loss: 2.2538363432884214
[Epoch 7, Batch 400] loss: 2.252941572666168
[Epoch 7, Batch 500] loss: 2.254414396286011
[Epoch 7, Batch 600] loss: 2.253777098655701
[Epoch 7, Batch 700] loss: 2.2525527596473696
[Epoch 7, Batch 800] loss: 2.250575294494629
[Epoch 7, Batch 900] loss: 2.2494831490516662
[Epoch 7, Batch 1000] loss: 2.248484404087067
[Epoch 7, Batch 1100] loss: 2.2485730266571045
[Epoch 7, Batch 1200] loss: 2.2454309463500977
[Epoch 7, Batch 1300] loss: 2.247394814491272
[Epoch 7, Batch 1400] loss: 2.2438094282150267
[Epoch 7, Batch 1500] loss: 2.2430116152763366
[Epoch 7, Batch 1600] loss: 2.24321298122406
[Epoch 7, Batch 1700] loss: 2.2426427030563354
[Epoch 7, Batch 1800] loss: 2.245812542438507
**STATS for Epoch 7** : 
Average training loss: 0.0897
Average validation loss: 2.2393
Validation Accuracy: 0.3583
Overfitting: 2.1496
Best model saved at epoch 7 with validation loss: 2.2393
[Epoch 8, Batch 100] loss: 2.2402616286277772
[Epoch 8, Batch 200] loss: 2.2368198323249815
[Epoch 8, Batch 300] loss: 2.2347484278678893
[Epoch 8, Batch 400] loss: 2.238663077354431
[Epoch 8, Batch 500] loss: 2.236321647167206
[Epoch 8, Batch 600] loss: 2.2308030581474303
[Epoch 8, Batch 700] loss: 2.227641303539276
[Epoch 8, Batch 800] loss: 2.2283042240142823
[Epoch 8, Batch 900] loss: 2.2287097549438477
[Epoch 8, Batch 1000] loss: 2.2256387519836425
[Epoch 8, Batch 1100] loss: 2.2265205669403074
[Epoch 8, Batch 1200] loss: 2.22644686460495
[Epoch 8, Batch 1300] loss: 2.2203780794143677
[Epoch 8, Batch 1400] loss: 2.219742159843445
[Epoch 8, Batch 1500] loss: 2.215656816959381
[Epoch 8, Batch 1600] loss: 2.2202872037887573
[Epoch 8, Batch 1700] loss: 2.2145052409172057
[Epoch 8, Batch 1800] loss: 2.215642502307892
**STATS for Epoch 8** : 
Average training loss: 0.0884
Average validation loss: 2.2111
Validation Accuracy: 0.4033
Overfitting: 2.1227
Best model saved at epoch 8 with validation loss: 2.2111
[Epoch 9, Batch 100] loss: 2.2125335812568663
[Epoch 9, Batch 200] loss: 2.208253309726715
[Epoch 9, Batch 300] loss: 2.203149755001068
[Epoch 9, Batch 400] loss: 2.205537040233612
[Epoch 9, Batch 500] loss: 2.2016301417350768
[Epoch 9, Batch 600] loss: 2.1996740531921386
[Epoch 9, Batch 700] loss: 2.198616144657135
[Epoch 9, Batch 800] loss: 2.1983100819587706
[Epoch 9, Batch 900] loss: 2.192825675010681
[Epoch 9, Batch 1000] loss: 2.1917482876777648
[Epoch 9, Batch 1100] loss: 2.189921088218689
[Epoch 9, Batch 1200] loss: 2.1879130840301513
[Epoch 9, Batch 1300] loss: 2.1848311495780943
[Epoch 9, Batch 1400] loss: 2.1748830103874206
[Epoch 9, Batch 1500] loss: 2.179996871948242
[Epoch 9, Batch 1600] loss: 2.176943075656891
[Epoch 9, Batch 1700] loss: 2.172353491783142
[Epoch 9, Batch 1800] loss: 2.1681407952308653
**STATS for Epoch 9** : 
Average training loss: 0.0863
Average validation loss: 2.1646
Validation Accuracy: 0.4698
Overfitting: 2.0783
Best model saved at epoch 9 with validation loss: 2.1646
[Epoch 10, Batch 100] loss: 2.1722291350364684
[Epoch 10, Batch 200] loss: 2.1564445185661314
[Epoch 10, Batch 300] loss: 2.155090982913971
[Epoch 10, Batch 400] loss: 2.1517334508895876
[Epoch 10, Batch 500] loss: 2.1480029082298278
[Epoch 10, Batch 600] loss: 2.150812168121338
[Epoch 10, Batch 700] loss: 2.1392438769340516
[Epoch 10, Batch 800] loss: 2.1402008152008056
[Epoch 10, Batch 900] loss: 2.137596709728241
[Epoch 10, Batch 1000] loss: 2.127855100631714
[Epoch 10, Batch 1100] loss: 2.1299362540245057
[Epoch 10, Batch 1200] loss: 2.1224950432777403
[Epoch 10, Batch 1300] loss: 2.1088914477825167
[Epoch 10, Batch 1400] loss: 2.1146065306663515
[Epoch 10, Batch 1500] loss: 2.1073092830181124
[Epoch 10, Batch 1600] loss: 2.0905465829372405
[Epoch 10, Batch 1700] loss: 2.0975490474700926
[Epoch 10, Batch 1800] loss: 2.0881366789340974
**STATS for Epoch 10** : 
Average training loss: 0.0832
Average validation loss: 2.0818
Validation Accuracy: 0.5495
Overfitting: 1.9987
Best model saved at epoch 10 with validation loss: 2.0818
[Epoch 11, Batch 100] loss: 2.0896839475631714
[Epoch 11, Batch 200] loss: 2.0752534425258635
[Epoch 11, Batch 300] loss: 2.06987695813179
[Epoch 11, Batch 400] loss: 2.0576480901241303
[Epoch 11, Batch 500] loss: 2.0455053794384
[Epoch 11, Batch 600] loss: 2.0440783059597014
[Epoch 11, Batch 700] loss: 2.038407324552536
[Epoch 11, Batch 800] loss: 2.0335958218574524
[Epoch 11, Batch 900] loss: 2.015432578325272
[Epoch 11, Batch 1000] loss: 2.012917238473892
[Epoch 11, Batch 1100] loss: 2.0126879715919497
[Epoch 11, Batch 1200] loss: 1.995829508304596
[Epoch 11, Batch 1300] loss: 1.9926897931098937
[Epoch 11, Batch 1400] loss: 1.989112207889557
[Epoch 11, Batch 1500] loss: 1.9760703086853026
[Epoch 11, Batch 1600] loss: 1.9592167711257935
[Epoch 11, Batch 1700] loss: 1.9564556574821472
[Epoch 11, Batch 1800] loss: 1.937230234146118
**STATS for Epoch 11** : 
Average training loss: 0.0766
Average validation loss: 1.9260
Validation Accuracy: 0.5949
Overfitting: 1.8494
Best model saved at epoch 11 with validation loss: 1.9260
[Epoch 12, Batch 100] loss: 1.9182595467567445
[Epoch 12, Batch 200] loss: 1.897215086221695
[Epoch 12, Batch 300] loss: 1.9014680588245392
[Epoch 12, Batch 400] loss: 1.8888937103748322
[Epoch 12, Batch 500] loss: 1.8715247893333435
[Epoch 12, Batch 600] loss: 1.8784126877784728
[Epoch 12, Batch 700] loss: 1.8480849492549896
[Epoch 12, Batch 800] loss: 1.840196716785431
[Epoch 12, Batch 900] loss: 1.8202558314800263
[Epoch 12, Batch 1000] loss: 1.7972392594814302
[Epoch 12, Batch 1100] loss: 1.8007694292068481
[Epoch 12, Batch 1200] loss: 1.7707537591457367
[Epoch 12, Batch 1300] loss: 1.7753160583972931
[Epoch 12, Batch 1400] loss: 1.7532936692237855
[Epoch 12, Batch 1500] loss: 1.714120502471924
[Epoch 12, Batch 1600] loss: 1.7136054158210754
[Epoch 12, Batch 1700] loss: 1.6905921924114227
[Epoch 12, Batch 1800] loss: 1.6751249325275421
**STATS for Epoch 12** : 
Average training loss: 0.0661
Average validation loss: 1.6573
Validation Accuracy: 0.6237
Overfitting: 1.5912
Best model saved at epoch 12 with validation loss: 1.6573
[Epoch 13, Batch 100] loss: 1.6652904188632964
[Epoch 13, Batch 200] loss: 1.6356063055992127
[Epoch 13, Batch 300] loss: 1.605172485113144
[Epoch 13, Batch 400] loss: 1.591075748205185
[Epoch 13, Batch 500] loss: 1.5933125472068788
[Epoch 13, Batch 600] loss: 1.5582724726200103
[Epoch 13, Batch 700] loss: 1.5719801092147827
[Epoch 13, Batch 800] loss: 1.5103109407424926
[Epoch 13, Batch 900] loss: 1.5075833213329315
[Epoch 13, Batch 1000] loss: 1.4993916702270509
[Epoch 13, Batch 1100] loss: 1.4384491980075835
[Epoch 13, Batch 1200] loss: 1.4463294196128844
[Epoch 13, Batch 1300] loss: 1.4486732506752014
[Epoch 13, Batch 1400] loss: 1.3996660172939301
[Epoch 13, Batch 1500] loss: 1.3651475071907044
[Epoch 13, Batch 1600] loss: 1.377174552679062
[Epoch 13, Batch 1700] loss: 1.3505593401193619
[Epoch 13, Batch 1800] loss: 1.3132603138685226
**STATS for Epoch 13** : 
Average training loss: 0.0531
Average validation loss: 1.3091
Validation Accuracy: 0.6871
Overfitting: 1.2560
Best model saved at epoch 13 with validation loss: 1.3091
[Epoch 14, Batch 100] loss: 1.3067810207605361
[Epoch 14, Batch 200] loss: 1.2894680017232896
[Epoch 14, Batch 300] loss: 1.2628605753183364
[Epoch 14, Batch 400] loss: 1.2402870452404022
[Epoch 14, Batch 500] loss: 1.2127217239141463
[Epoch 14, Batch 600] loss: 1.1957700800895692
[Epoch 14, Batch 700] loss: 1.1956728041172027
[Epoch 14, Batch 800] loss: 1.1796423894166947
[Epoch 14, Batch 900] loss: 1.179328557252884
[Epoch 14, Batch 1000] loss: 1.1422180116176606
[Epoch 14, Batch 1100] loss: 1.1060852080583572
[Epoch 14, Batch 1200] loss: 1.1292958480119706
[Epoch 14, Batch 1300] loss: 1.0837880563735962
[Epoch 14, Batch 1400] loss: 1.066606610417366
[Epoch 14, Batch 1500] loss: 1.0802339845895768
[Epoch 14, Batch 1600] loss: 1.0327423900365829
[Epoch 14, Batch 1700] loss: 1.0301599216461181
[Epoch 14, Batch 1800] loss: 1.0357131612300874
**STATS for Epoch 14** : 
Average training loss: 0.0401
Average validation loss: 1.0004
Validation Accuracy: 0.7544
Overfitting: 0.9603
Best model saved at epoch 14 with validation loss: 1.0004
[Epoch 15, Batch 100] loss: 0.9829535353183746
[Epoch 15, Batch 200] loss: 0.9811233925819397
[Epoch 15, Batch 300] loss: 0.9770726335048675
[Epoch 15, Batch 400] loss: 0.9509432601928711
[Epoch 15, Batch 500] loss: 0.9530676400661469
[Epoch 15, Batch 600] loss: 0.9370471525192261
[Epoch 15, Batch 700] loss: 0.932871715426445
[Epoch 15, Batch 800] loss: 0.8926556104421616
[Epoch 15, Batch 900] loss: 0.8855900910496711
[Epoch 15, Batch 1000] loss: 0.8638306391239167
[Epoch 15, Batch 1100] loss: 0.871252566576004
[Epoch 15, Batch 1200] loss: 0.8389231914281845
[Epoch 15, Batch 1300] loss: 0.8574614995718002
[Epoch 15, Batch 1400] loss: 0.8524555474519729
[Epoch 15, Batch 1500] loss: 0.8365431952476502
[Epoch 15, Batch 1600] loss: 0.8472464418411255
[Epoch 15, Batch 1700] loss: 0.83929068505764
[Epoch 15, Batch 1800] loss: 0.8036689895391464
**STATS for Epoch 15** : 
Average training loss: 0.0320
Average validation loss: 0.7942
Validation Accuracy: 0.7862
Overfitting: 0.7622
Best model saved at epoch 15 with validation loss: 0.7942
[Epoch 16, Batch 100] loss: 0.7781446096301079
[Epoch 16, Batch 200] loss: 0.7916541782021522
[Epoch 16, Batch 300] loss: 0.7998516649007797
[Epoch 16, Batch 400] loss: 0.7852512815594673
[Epoch 16, Batch 500] loss: 0.7709657207131386
[Epoch 16, Batch 600] loss: 0.7453578665852547
[Epoch 16, Batch 700] loss: 0.7333389648795128
[Epoch 16, Batch 800] loss: 0.7367369048297405
[Epoch 16, Batch 900] loss: 0.7245153793692589
[Epoch 16, Batch 1000] loss: 0.7364984801411629
[Epoch 16, Batch 1100] loss: 0.7041215467453003
[Epoch 16, Batch 1200] loss: 0.726190399825573
[Epoch 16, Batch 1300] loss: 0.6947336196899414
[Epoch 16, Batch 1400] loss: 0.7132140144705772
[Epoch 16, Batch 1500] loss: 0.6935148477554322
[Epoch 16, Batch 1600] loss: 0.6774832132458687
[Epoch 16, Batch 1700] loss: 0.7091636100411415
[Epoch 16, Batch 1800] loss: 0.683206953406334
**STATS for Epoch 16** : 
Average training loss: 0.0278
Average validation loss: 0.6733
Validation Accuracy: 0.8123
Overfitting: 0.6455
Best model saved at epoch 16 with validation loss: 0.6733
[Epoch 17, Batch 100] loss: 0.6499011936783791
[Epoch 17, Batch 200] loss: 0.6787368339300156
[Epoch 17, Batch 300] loss: 0.6626115304231643
[Epoch 17, Batch 400] loss: 0.6460058021545411
[Epoch 17, Batch 500] loss: 0.6815629357099533
[Epoch 17, Batch 600] loss: 0.6478950497508049
[Epoch 17, Batch 700] loss: 0.6756981652975083
[Epoch 17, Batch 800] loss: 0.6616993510723114
[Epoch 17, Batch 900] loss: 0.5945255297422409
[Epoch 17, Batch 1000] loss: 0.6150395062565803
[Epoch 17, Batch 1100] loss: 0.647458111345768
[Epoch 17, Batch 1200] loss: 0.626319745182991
[Epoch 17, Batch 1300] loss: 0.620552870631218
[Epoch 17, Batch 1400] loss: 0.6455564284324646
[Epoch 17, Batch 1500] loss: 0.6171666561067104
[Epoch 17, Batch 1600] loss: 0.5922404444217682
[Epoch 17, Batch 1700] loss: 0.6118364511430263
[Epoch 17, Batch 1800] loss: 0.60581338763237
**STATS for Epoch 17** : 
Average training loss: 0.0241
Average validation loss: 0.5978
Validation Accuracy: 0.8265
Overfitting: 0.5737
Best model saved at epoch 17 with validation loss: 0.5978
[Epoch 18, Batch 100] loss: 0.621415122449398
[Epoch 18, Batch 200] loss: 0.6022456243634224
[Epoch 18, Batch 300] loss: 0.5935301432013511
[Epoch 18, Batch 400] loss: 0.5852352453768254
[Epoch 18, Batch 500] loss: 0.5932934480905533
[Epoch 18, Batch 600] loss: 0.5497633947432041
[Epoch 18, Batch 700] loss: 0.6071732640266418
[Epoch 18, Batch 800] loss: 0.5882997956871986
[Epoch 18, Batch 900] loss: 0.5731619408726693
[Epoch 18, Batch 1000] loss: 0.5875236117839813
[Epoch 18, Batch 1100] loss: 0.5572499127686024
[Epoch 18, Batch 1200] loss: 0.6098835885524749
[Epoch 18, Batch 1300] loss: 0.5424374277889729
[Epoch 18, Batch 1400] loss: 0.5441403540968895
[Epoch 18, Batch 1500] loss: 0.5408067315816879
[Epoch 18, Batch 1600] loss: 0.5459711879491806
[Epoch 18, Batch 1700] loss: 0.5408835230767727
[Epoch 18, Batch 1800] loss: 0.5865288031101227
**STATS for Epoch 18** : 
Average training loss: 0.0208
Average validation loss: 0.5468
Validation Accuracy: 0.8398
Overfitting: 0.5260
Best model saved at epoch 18 with validation loss: 0.5468
[Epoch 19, Batch 100] loss: 0.5682411368191242
[Epoch 19, Batch 200] loss: 0.5398040592670441
[Epoch 19, Batch 300] loss: 0.5534429994225502
[Epoch 19, Batch 400] loss: 0.5551548829674721
[Epoch 19, Batch 500] loss: 0.5334543247520923
[Epoch 19, Batch 600] loss: 0.5309153407812118
[Epoch 19, Batch 700] loss: 0.4855734820663929
[Epoch 19, Batch 800] loss: 0.5495864473283291
[Epoch 19, Batch 900] loss: 0.529191961735487
[Epoch 19, Batch 1000] loss: 0.5252752263844013
[Epoch 19, Batch 1100] loss: 0.5279436997324228
[Epoch 19, Batch 1200] loss: 0.5058876410126686
[Epoch 19, Batch 1300] loss: 0.5405695976316929
[Epoch 19, Batch 1400] loss: 0.5270488503575325
[Epoch 19, Batch 1500] loss: 0.5329150865972042
[Epoch 19, Batch 1600] loss: 0.48515533745288847
[Epoch 19, Batch 1700] loss: 0.5207767821848392
[Epoch 19, Batch 1800] loss: 0.515049284696579
**STATS for Epoch 19** : 
Average training loss: 0.0208
Average validation loss: 0.5060
Validation Accuracy: 0.8520
Overfitting: 0.4852
Best model saved at epoch 19 with validation loss: 0.5060
[Epoch 20, Batch 100] loss: 0.5270304946601391
[Epoch 20, Batch 200] loss: 0.5006753298640251
[Epoch 20, Batch 300] loss: 0.5108296617865562
[Epoch 20, Batch 400] loss: 0.4816873915493488
[Epoch 20, Batch 500] loss: 0.5226134157180786
[Epoch 20, Batch 600] loss: 0.5077965427935124
[Epoch 20, Batch 700] loss: 0.49675191834568977
[Epoch 20, Batch 800] loss: 0.5025737220048905
[Epoch 20, Batch 900] loss: 0.49557719185948373
[Epoch 20, Batch 1000] loss: 0.48981548950076104
[Epoch 20, Batch 1100] loss: 0.4974547605961561
[Epoch 20, Batch 1200] loss: 0.48767209589481353
[Epoch 20, Batch 1300] loss: 0.46871132761240003
[Epoch 20, Batch 1400] loss: 0.47731923282146455
[Epoch 20, Batch 1500] loss: 0.4797572723031044
[Epoch 20, Batch 1600] loss: 0.5054927276074886
[Epoch 20, Batch 1700] loss: 0.48097326353192327
[Epoch 20, Batch 1800] loss: 0.4653141875565052
**STATS for Epoch 20** : 
Average training loss: 0.0196
Average validation loss: 0.4748
Validation Accuracy: 0.8613
Overfitting: 0.4552
Best model saved at epoch 20 with validation loss: 0.4748
[Epoch 21, Batch 100] loss: 0.44881943613290787
[Epoch 21, Batch 200] loss: 0.45608941704034806
[Epoch 21, Batch 300] loss: 0.478599960654974
[Epoch 21, Batch 400] loss: 0.5109863039851189
[Epoch 21, Batch 500] loss: 0.4995641885697842
[Epoch 21, Batch 600] loss: 0.4550290076434612
[Epoch 21, Batch 700] loss: 0.5035873253643512
[Epoch 21, Batch 800] loss: 0.46613172098994254
[Epoch 21, Batch 900] loss: 0.49466511741280556
[Epoch 21, Batch 1000] loss: 0.4485132095217705
[Epoch 21, Batch 1100] loss: 0.48762717202305794
[Epoch 21, Batch 1200] loss: 0.4689940935373306
[Epoch 21, Batch 1300] loss: 0.45688948206603525
[Epoch 21, Batch 1400] loss: 0.4789227595180273
[Epoch 21, Batch 1500] loss: 0.4677045455574989
[Epoch 21, Batch 1600] loss: 0.4664254979044199
[Epoch 21, Batch 1700] loss: 0.41707047194242475
[Epoch 21, Batch 1800] loss: 0.41642788916826246
**STATS for Epoch 21** : 
Average training loss: 0.0169
Average validation loss: 0.4510
Validation Accuracy: 0.8673
Overfitting: 0.4341
Best model saved at epoch 21 with validation loss: 0.4510
[Epoch 22, Batch 100] loss: 0.4545401613414288
[Epoch 22, Batch 200] loss: 0.39348983436822893
[Epoch 22, Batch 300] loss: 0.4056041404604912
[Epoch 22, Batch 400] loss: 0.4510027788579464
[Epoch 22, Batch 500] loss: 0.46377552300691605
[Epoch 22, Batch 600] loss: 0.4327438007295132
[Epoch 22, Batch 700] loss: 0.4528154480457306
[Epoch 22, Batch 800] loss: 0.4445893434435129
[Epoch 22, Batch 900] loss: 0.4226656263321638
[Epoch 22, Batch 1000] loss: 0.4823586320132017
[Epoch 22, Batch 1100] loss: 0.4537818560004234
[Epoch 22, Batch 1200] loss: 0.4673180736601353
[Epoch 22, Batch 1300] loss: 0.4446242117881775
[Epoch 22, Batch 1400] loss: 0.43034557312726973
[Epoch 22, Batch 1500] loss: 0.4415827871859074
[Epoch 22, Batch 1600] loss: 0.4414059417694807
[Epoch 22, Batch 1700] loss: 0.4474904339015484
[Epoch 22, Batch 1800] loss: 0.4159870094060898
**STATS for Epoch 22** : 
Average training loss: 0.0181
Average validation loss: 0.4282
Validation Accuracy: 0.8743
Overfitting: 0.4101
Best model saved at epoch 22 with validation loss: 0.4282
[Epoch 23, Batch 100] loss: 0.4367056992650032
[Epoch 23, Batch 200] loss: 0.4345892908424139
[Epoch 23, Batch 300] loss: 0.4450223160535097
[Epoch 23, Batch 400] loss: 0.4128611189872026
[Epoch 23, Batch 500] loss: 0.4500032852590084
[Epoch 23, Batch 600] loss: 0.4495822097361088
[Epoch 23, Batch 700] loss: 0.39446351014077663
[Epoch 23, Batch 800] loss: 0.42999706462025644
[Epoch 23, Batch 900] loss: 0.41134639233350756
[Epoch 23, Batch 1000] loss: 0.4107934866845608
[Epoch 23, Batch 1100] loss: 0.41388307712972167
[Epoch 23, Batch 1200] loss: 0.40041670359671117
[Epoch 23, Batch 1300] loss: 0.43784623958170416
[Epoch 23, Batch 1400] loss: 0.431788354255259
[Epoch 23, Batch 1500] loss: 0.39127727650105953
[Epoch 23, Batch 1600] loss: 0.42127270691096785
[Epoch 23, Batch 1700] loss: 0.3929453092068434
[Epoch 23, Batch 1800] loss: 0.4355141753703356
**STATS for Epoch 23** : 
Average training loss: 0.0155
Average validation loss: 0.4108
Validation Accuracy: 0.8787
Overfitting: 0.3952
Best model saved at epoch 23 with validation loss: 0.4108
[Epoch 24, Batch 100] loss: 0.38746817331761124
[Epoch 24, Batch 200] loss: 0.4030499943345785
[Epoch 24, Batch 300] loss: 0.4366157066822052
[Epoch 24, Batch 400] loss: 0.37420074790716173
[Epoch 24, Batch 500] loss: 0.4026496357470751
[Epoch 24, Batch 600] loss: 0.3778113479167223
[Epoch 24, Batch 700] loss: 0.40646160192787645
[Epoch 24, Batch 800] loss: 0.3932798179984093
[Epoch 24, Batch 900] loss: 0.4227366282790899
[Epoch 24, Batch 1000] loss: 0.39078308917582033
[Epoch 24, Batch 1100] loss: 0.44793225184082985
[Epoch 24, Batch 1200] loss: 0.4277135957032442
[Epoch 24, Batch 1300] loss: 0.3872893150150776
[Epoch 24, Batch 1400] loss: 0.4024633917957544
[Epoch 24, Batch 1500] loss: 0.3915846811234951
[Epoch 24, Batch 1600] loss: 0.4004617200046778
[Epoch 24, Batch 1700] loss: 0.40095482746139166
[Epoch 24, Batch 1800] loss: 0.41342516150325537
**STATS for Epoch 24** : 
Average training loss: 0.0154
Average validation loss: 0.3904
Validation Accuracy: 0.8858
Overfitting: 0.3750
Best model saved at epoch 24 with validation loss: 0.3904
Fold 1 validation loss: 0.3904
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.3033250188827514
[Epoch 1, Batch 200] loss: 2.303390340805054
[Epoch 1, Batch 300] loss: 2.3030600214004515
[Epoch 1, Batch 400] loss: 2.3016503930091856
[Epoch 1, Batch 500] loss: 2.3027676701545716
[Epoch 1, Batch 600] loss: 2.303946623802185
[Epoch 1, Batch 700] loss: 2.3003688788414003
[Epoch 1, Batch 800] loss: 2.300439839363098
[Epoch 1, Batch 900] loss: 2.301295313835144
[Epoch 1, Batch 1000] loss: 2.301521942615509
[Epoch 1, Batch 1100] loss: 2.299699001312256
[Epoch 1, Batch 1200] loss: 2.3017479515075685
[Epoch 1, Batch 1300] loss: 2.299612510204315
[Epoch 1, Batch 1400] loss: 2.299903347492218
[Epoch 1, Batch 1500] loss: 2.299835343360901
[Epoch 1, Batch 1600] loss: 2.2983668994903566
[Epoch 1, Batch 1700] loss: 2.2991114687919616
[Epoch 1, Batch 1800] loss: 2.3002370595932007
**STATS for Epoch 1** : 
Average training loss: 0.0919
Average validation loss: 2.2988
Validation Accuracy: 0.1197
Overfitting: 2.2069
Best model saved at epoch 1 with validation loss: 2.2988
[Epoch 2, Batch 100] loss: 2.2964869260787966
[Epoch 2, Batch 200] loss: 2.2994054460525515
[Epoch 2, Batch 300] loss: 2.297054200172424
[Epoch 2, Batch 400] loss: 2.297333793640137
[Epoch 2, Batch 500] loss: 2.2982122707366943
[Epoch 2, Batch 600] loss: 2.298929762840271
[Epoch 2, Batch 700] loss: 2.298150026798248
[Epoch 2, Batch 800] loss: 2.296315257549286
[Epoch 2, Batch 900] loss: 2.295528039932251
[Epoch 2, Batch 1000] loss: 2.2961971592903136
[Epoch 2, Batch 1100] loss: 2.2964253997802735
[Epoch 2, Batch 1200] loss: 2.2953564357757568
[Epoch 2, Batch 1300] loss: 2.294463996887207
[Epoch 2, Batch 1400] loss: 2.2951570916175843
[Epoch 2, Batch 1500] loss: 2.295062708854675
[Epoch 2, Batch 1600] loss: 2.294164535999298
[Epoch 2, Batch 1700] loss: 2.29464567899704
[Epoch 2, Batch 1800] loss: 2.2929201889038087
**STATS for Epoch 2** : 
Average training loss: 0.0918
Average validation loss: 2.2938
Validation Accuracy: 0.1795
Overfitting: 2.2020
Best model saved at epoch 2 with validation loss: 2.2938
[Epoch 3, Batch 100] loss: 2.2934708976745606
[Epoch 3, Batch 200] loss: 2.2937609934806824
[Epoch 3, Batch 300] loss: 2.2920634889602662
[Epoch 3, Batch 400] loss: 2.293063428401947
[Epoch 3, Batch 500] loss: 2.293168351650238
[Epoch 3, Batch 600] loss: 2.29243243932724
[Epoch 3, Batch 700] loss: 2.292860631942749
[Epoch 3, Batch 800] loss: 2.2894042348861694
[Epoch 3, Batch 900] loss: 2.2910208463668824
[Epoch 3, Batch 1000] loss: 2.2893605923652647
[Epoch 3, Batch 1100] loss: 2.29059002161026
[Epoch 3, Batch 1200] loss: 2.291210391521454
[Epoch 3, Batch 1300] loss: 2.291117730140686
[Epoch 3, Batch 1400] loss: 2.2893818950653078
[Epoch 3, Batch 1500] loss: 2.2880757570266725
[Epoch 3, Batch 1600] loss: 2.2881365394592286
[Epoch 3, Batch 1700] loss: 2.2903772830963134
[Epoch 3, Batch 1800] loss: 2.2897280788421632
**STATS for Epoch 3** : 
Average training loss: 0.0915
Average validation loss: 2.2883
Validation Accuracy: 0.2438
Overfitting: 2.1967
Best model saved at epoch 3 with validation loss: 2.2883
[Epoch 4, Batch 100] loss: 2.2888814878463744
[Epoch 4, Batch 200] loss: 2.2877137541770933
[Epoch 4, Batch 300] loss: 2.2872227478027343
[Epoch 4, Batch 400] loss: 2.286409389972687
[Epoch 4, Batch 500] loss: 2.286488926410675
[Epoch 4, Batch 600] loss: 2.28612904548645
[Epoch 4, Batch 700] loss: 2.284268386363983
[Epoch 4, Batch 800] loss: 2.2869806933403014
[Epoch 4, Batch 900] loss: 2.284933023452759
[Epoch 4, Batch 1000] loss: 2.285972809791565
[Epoch 4, Batch 1100] loss: 2.284907841682434
[Epoch 4, Batch 1200] loss: 2.2828138732910155
[Epoch 4, Batch 1300] loss: 2.284909572601318
[Epoch 4, Batch 1400] loss: 2.2834661984443665
[Epoch 4, Batch 1500] loss: 2.282371003627777
[Epoch 4, Batch 1600] loss: 2.283994421958923
[Epoch 4, Batch 1700] loss: 2.2818710160255433
[Epoch 4, Batch 1800] loss: 2.282091851234436
**STATS for Epoch 4** : 
Average training loss: 0.0913
Average validation loss: 2.2817
Validation Accuracy: 0.3160
Overfitting: 2.1904
Best model saved at epoch 4 with validation loss: 2.2817
[Epoch 5, Batch 100] loss: 2.2809769773483275
[Epoch 5, Batch 200] loss: 2.280391788482666
[Epoch 5, Batch 300] loss: 2.2814423656463623
[Epoch 5, Batch 400] loss: 2.2793183755874633
[Epoch 5, Batch 500] loss: 2.27962233543396
[Epoch 5, Batch 600] loss: 2.279936900138855
[Epoch 5, Batch 700] loss: 2.2776859283447264
[Epoch 5, Batch 800] loss: 2.277928280830383
[Epoch 5, Batch 900] loss: 2.279043188095093
[Epoch 5, Batch 1000] loss: 2.2773557090759278
[Epoch 5, Batch 1100] loss: 2.276920635700226
[Epoch 5, Batch 1200] loss: 2.2756257033348084
[Epoch 5, Batch 1300] loss: 2.2763162899017333
[Epoch 5, Batch 1400] loss: 2.2754359292984008
[Epoch 5, Batch 1500] loss: 2.2766175150871275
[Epoch 5, Batch 1600] loss: 2.2755636310577394
[Epoch 5, Batch 1700] loss: 2.275165948867798
[Epoch 5, Batch 1800] loss: 2.2736078810691835
**STATS for Epoch 5** : 
Average training loss: 0.0910
Average validation loss: 2.2734
Validation Accuracy: 0.3863
Overfitting: 2.1824
Best model saved at epoch 5 with validation loss: 2.2734
[Epoch 6, Batch 100] loss: 2.273181827068329
[Epoch 6, Batch 200] loss: 2.2707989525794985
[Epoch 6, Batch 300] loss: 2.2731768608093263
[Epoch 6, Batch 400] loss: 2.272366771697998
[Epoch 6, Batch 500] loss: 2.2724811458587646
[Epoch 6, Batch 600] loss: 2.2703179621696474
[Epoch 6, Batch 700] loss: 2.2691686725616456
[Epoch 6, Batch 800] loss: 2.268615243434906
[Epoch 6, Batch 900] loss: 2.2695545530319214
[Epoch 6, Batch 1000] loss: 2.267126319408417
[Epoch 6, Batch 1100] loss: 2.265675117969513
[Epoch 6, Batch 1200] loss: 2.2665981459617615
[Epoch 6, Batch 1300] loss: 2.266737866401672
[Epoch 6, Batch 1400] loss: 2.266871967315674
[Epoch 6, Batch 1500] loss: 2.2661691093444825
[Epoch 6, Batch 1600] loss: 2.265549714565277
[Epoch 6, Batch 1700] loss: 2.263186028003693
[Epoch 6, Batch 1800] loss: 2.261499352455139
**STATS for Epoch 6** : 
Average training loss: 0.0906
Average validation loss: 2.2624
Validation Accuracy: 0.4540
Overfitting: 2.1718
Best model saved at epoch 6 with validation loss: 2.2624
[Epoch 7, Batch 100] loss: 2.2632850050926208
[Epoch 7, Batch 200] loss: 2.2615136909484863
[Epoch 7, Batch 300] loss: 2.2589262032508852
[Epoch 7, Batch 400] loss: 2.2584486913681032
[Epoch 7, Batch 500] loss: 2.258685564994812
[Epoch 7, Batch 600] loss: 2.25953941822052
[Epoch 7, Batch 700] loss: 2.259748010635376
[Epoch 7, Batch 800] loss: 2.2574282813072206
[Epoch 7, Batch 900] loss: 2.2547581434249877
[Epoch 7, Batch 1000] loss: 2.255956242084503
[Epoch 7, Batch 1100] loss: 2.254685850143433
[Epoch 7, Batch 1200] loss: 2.2553871417045595
[Epoch 7, Batch 1300] loss: 2.2539584946632387
[Epoch 7, Batch 1400] loss: 2.252905511856079
[Epoch 7, Batch 1500] loss: 2.2501133465766907
[Epoch 7, Batch 1600] loss: 2.249793915748596
[Epoch 7, Batch 1700] loss: 2.248413107395172
[Epoch 7, Batch 1800] loss: 2.247606394290924
**STATS for Epoch 7** : 
Average training loss: 0.0899
Average validation loss: 2.2473
Validation Accuracy: 0.5134
Overfitting: 2.1574
Best model saved at epoch 7 with validation loss: 2.2473
[Epoch 8, Batch 100] loss: 2.2455034351348875
[Epoch 8, Batch 200] loss: 2.246847057342529
[Epoch 8, Batch 300] loss: 2.242499539852142
[Epoch 8, Batch 400] loss: 2.243906443119049
[Epoch 8, Batch 500] loss: 2.2430988693237306
[Epoch 8, Batch 600] loss: 2.2412950158119203
[Epoch 8, Batch 700] loss: 2.2398965668678286
[Epoch 8, Batch 800] loss: 2.239688365459442
[Epoch 8, Batch 900] loss: 2.240541970729828
[Epoch 8, Batch 1000] loss: 2.2370647501945498
[Epoch 8, Batch 1100] loss: 2.2352668333053587
[Epoch 8, Batch 1200] loss: 2.234829058647156
[Epoch 8, Batch 1300] loss: 2.234351317882538
[Epoch 8, Batch 1400] loss: 2.2328748083114625
[Epoch 8, Batch 1500] loss: 2.2305255246162417
[Epoch 8, Batch 1600] loss: 2.23069917678833
[Epoch 8, Batch 1700] loss: 2.2275863790512087
[Epoch 8, Batch 1800] loss: 2.228679349422455
**STATS for Epoch 8** : 
Average training loss: 0.0891
Average validation loss: 2.2252
Validation Accuracy: 0.5549
Overfitting: 2.1362
Best model saved at epoch 8 with validation loss: 2.2252
[Epoch 9, Batch 100] loss: 2.2230956506729127
[Epoch 9, Batch 200] loss: 2.221470739841461
[Epoch 9, Batch 300] loss: 2.2241999888420105
[Epoch 9, Batch 400] loss: 2.2223478865623476
[Epoch 9, Batch 500] loss: 2.2190608954429627
[Epoch 9, Batch 600] loss: 2.2132644271850586
[Epoch 9, Batch 700] loss: 2.213436164855957
[Epoch 9, Batch 800] loss: 2.214671378135681
[Epoch 9, Batch 900] loss: 2.2114265155792237
[Epoch 9, Batch 1000] loss: 2.2076825976371763
[Epoch 9, Batch 1100] loss: 2.21124813079834
[Epoch 9, Batch 1200] loss: 2.2099618172645568
[Epoch 9, Batch 1300] loss: 2.2050801944732665
[Epoch 9, Batch 1400] loss: 2.2016653394699097
[Epoch 9, Batch 1500] loss: 2.1992338919639587
[Epoch 9, Batch 1600] loss: 2.2004037833213808
[Epoch 9, Batch 1700] loss: 2.19692969083786
[Epoch 9, Batch 1800] loss: 2.1935236167907717
**STATS for Epoch 9** : 
Average training loss: 0.0876
Average validation loss: 2.1911
Validation Accuracy: 0.5778
Overfitting: 2.1035
Best model saved at epoch 9 with validation loss: 2.1911
[Epoch 10, Batch 100] loss: 2.1919806838035583
[Epoch 10, Batch 200] loss: 2.1859364914894104
[Epoch 10, Batch 300] loss: 2.187597770690918
[Epoch 10, Batch 400] loss: 2.186166648864746
[Epoch 10, Batch 500] loss: 2.1832235264778137
[Epoch 10, Batch 600] loss: 2.179298439025879
[Epoch 10, Batch 700] loss: 2.1760050415992738
[Epoch 10, Batch 800] loss: 2.172328095436096
[Epoch 10, Batch 900] loss: 2.1724764752388
[Epoch 10, Batch 1000] loss: 2.1661407995224
[Epoch 10, Batch 1100] loss: 2.1613852477073667
[Epoch 10, Batch 1200] loss: 2.156626813411713
[Epoch 10, Batch 1300] loss: 2.156792757511139
[Epoch 10, Batch 1400] loss: 2.14917769908905
[Epoch 10, Batch 1500] loss: 2.144773397445679
[Epoch 10, Batch 1600] loss: 2.1473678588867187
[Epoch 10, Batch 1700] loss: 2.145172030925751
[Epoch 10, Batch 1800] loss: 2.142765805721283
**STATS for Epoch 10** : 
Average training loss: 0.0855
Average validation loss: 2.1350
Validation Accuracy: 0.5867
Overfitting: 2.0495
Best model saved at epoch 10 with validation loss: 2.1350
[Epoch 11, Batch 100] loss: 2.135387864112854
[Epoch 11, Batch 200] loss: 2.129460141658783
[Epoch 11, Batch 300] loss: 2.125223937034607
[Epoch 11, Batch 400] loss: 2.119319939613342
[Epoch 11, Batch 500] loss: 2.1166850340366365
[Epoch 11, Batch 600] loss: 2.115322241783142
[Epoch 11, Batch 700] loss: 2.1112868690490725
[Epoch 11, Batch 800] loss: 2.0964785861968993
[Epoch 11, Batch 900] loss: 2.104734363555908
[Epoch 11, Batch 1000] loss: 2.0909173238277434
[Epoch 11, Batch 1100] loss: 2.083676804304123
[Epoch 11, Batch 1200] loss: 2.0909183967113494
[Epoch 11, Batch 1300] loss: 2.0825488448143004
[Epoch 11, Batch 1400] loss: 2.0706358778476717
[Epoch 11, Batch 1500] loss: 2.054619334936142
[Epoch 11, Batch 1600] loss: 2.0485804045200346
[Epoch 11, Batch 1700] loss: 2.0558392643928527
[Epoch 11, Batch 1800] loss: 2.034236928224564
**STATS for Epoch 11** : 
Average training loss: 0.0818
Average validation loss: 2.0355
Validation Accuracy: 0.5949
Overfitting: 1.9537
Best model saved at epoch 11 with validation loss: 2.0355
[Epoch 12, Batch 100] loss: 2.0322593021392823
[Epoch 12, Batch 200] loss: 2.017593826055527
[Epoch 12, Batch 300] loss: 2.0210463905334475
[Epoch 12, Batch 400] loss: 2.002487703561783
[Epoch 12, Batch 500] loss: 1.9912132000923157
[Epoch 12, Batch 600] loss: 1.995961185693741
[Epoch 12, Batch 700] loss: 1.986416655778885
[Epoch 12, Batch 800] loss: 1.9843685984611512
[Epoch 12, Batch 900] loss: 1.9638902187347411
[Epoch 12, Batch 1000] loss: 1.9612433838844299
[Epoch 12, Batch 1100] loss: 1.958277155160904
[Epoch 12, Batch 1200] loss: 1.9367903518676757
[Epoch 12, Batch 1300] loss: 1.9366318738460542
[Epoch 12, Batch 1400] loss: 1.9125699019432068
[Epoch 12, Batch 1500] loss: 1.9049404120445252
[Epoch 12, Batch 1600] loss: 1.88704638838768
[Epoch 12, Batch 1700] loss: 1.879498791694641
[Epoch 12, Batch 1800] loss: 1.8645387232303618
**STATS for Epoch 12** : 
Average training loss: 0.0742
Average validation loss: 1.8506
Validation Accuracy: 0.6447
Overfitting: 1.7765
Best model saved at epoch 12 with validation loss: 1.8506
[Epoch 13, Batch 100] loss: 1.8299211597442626
[Epoch 13, Batch 200] loss: 1.828882942199707
[Epoch 13, Batch 300] loss: 1.8232014858722687
[Epoch 13, Batch 400] loss: 1.8073423564434052
[Epoch 13, Batch 500] loss: 1.7988911879062652
[Epoch 13, Batch 600] loss: 1.7837112736701966
[Epoch 13, Batch 700] loss: 1.7598465228080749
[Epoch 13, Batch 800] loss: 1.7562367975711823
[Epoch 13, Batch 900] loss: 1.7287790763378144
[Epoch 13, Batch 1000] loss: 1.7008097672462463
[Epoch 13, Batch 1100] loss: 1.6885805439949035
[Epoch 13, Batch 1200] loss: 1.677843257188797
[Epoch 13, Batch 1300] loss: 1.6518047320842744
[Epoch 13, Batch 1400] loss: 1.6312559294700621
[Epoch 13, Batch 1500] loss: 1.6198096692562103
[Epoch 13, Batch 1600] loss: 1.5938393771648407
[Epoch 13, Batch 1700] loss: 1.563046452999115
[Epoch 13, Batch 1800] loss: 1.5605309236049651
**STATS for Epoch 13** : 
Average training loss: 0.0620
Average validation loss: 1.5344
Validation Accuracy: 0.7269
Overfitting: 1.4724
Best model saved at epoch 13 with validation loss: 1.5344
[Epoch 14, Batch 100] loss: 1.5246912574768066
[Epoch 14, Batch 200] loss: 1.505568529367447
[Epoch 14, Batch 300] loss: 1.4987494790554046
[Epoch 14, Batch 400] loss: 1.4711788928508758
[Epoch 14, Batch 500] loss: 1.4431510245800019
[Epoch 14, Batch 600] loss: 1.4559572875499724
[Epoch 14, Batch 700] loss: 1.378861560821533
[Epoch 14, Batch 800] loss: 1.396988525390625
[Epoch 14, Batch 900] loss: 1.3559008169174194
[Epoch 14, Batch 1000] loss: 1.3390582227706909
[Epoch 14, Batch 1100] loss: 1.2998720932006835
[Epoch 14, Batch 1200] loss: 1.3235002595186234
[Epoch 14, Batch 1300] loss: 1.294156600832939
[Epoch 14, Batch 1400] loss: 1.2710082232952118
[Epoch 14, Batch 1500] loss: 1.2633850294351578
[Epoch 14, Batch 1600] loss: 1.2340624916553498
[Epoch 14, Batch 1700] loss: 1.1953232449293136
[Epoch 14, Batch 1800] loss: 1.156390830874443
**STATS for Epoch 14** : 
Average training loss: 0.0465
Average validation loss: 1.1633
Validation Accuracy: 0.7665
Overfitting: 1.1168
Best model saved at epoch 14 with validation loss: 1.1633
[Epoch 15, Batch 100] loss: 1.1468596798181534
[Epoch 15, Batch 200] loss: 1.1748748683929444
[Epoch 15, Batch 300] loss: 1.110856875181198
[Epoch 15, Batch 400] loss: 1.1019351923465728
[Epoch 15, Batch 500] loss: 1.085960147380829
[Epoch 15, Batch 600] loss: 1.053009479045868
[Epoch 15, Batch 700] loss: 1.0475426268577577
[Epoch 15, Batch 800] loss: 1.0354879695177077
[Epoch 15, Batch 900] loss: 1.035178153514862
[Epoch 15, Batch 1000] loss: 0.9928851705789566
[Epoch 15, Batch 1100] loss: 0.9922909367084504
[Epoch 15, Batch 1200] loss: 0.9731953114271163
[Epoch 15, Batch 1300] loss: 0.9811256003379821
[Epoch 15, Batch 1400] loss: 0.9559314024448394
[Epoch 15, Batch 1500] loss: 0.9475243431329727
[Epoch 15, Batch 1600] loss: 0.9296991282701492
[Epoch 15, Batch 1700] loss: 0.9145053225755692
[Epoch 15, Batch 1800] loss: 0.9025253564119339
**STATS for Epoch 15** : 
Average training loss: 0.0345
Average validation loss: 0.8844
Validation Accuracy: 0.7963
Overfitting: 0.8499
Best model saved at epoch 15 with validation loss: 0.8844
[Epoch 16, Batch 100] loss: 0.8830474036931991
[Epoch 16, Batch 200] loss: 0.8847742736339569
[Epoch 16, Batch 300] loss: 0.8432458662986755
[Epoch 16, Batch 400] loss: 0.849374925494194
[Epoch 16, Batch 500] loss: 0.8171314570307732
[Epoch 16, Batch 600] loss: 0.7851706451177597
[Epoch 16, Batch 700] loss: 0.8194647961854935
[Epoch 16, Batch 800] loss: 0.8288054823875427
[Epoch 16, Batch 900] loss: 0.8011509490013122
[Epoch 16, Batch 1000] loss: 0.8025704577565194
[Epoch 16, Batch 1100] loss: 0.7777895525097847
[Epoch 16, Batch 1200] loss: 0.7845040711760521
[Epoch 16, Batch 1300] loss: 0.7611266273260117
[Epoch 16, Batch 1400] loss: 0.7811692932248115
[Epoch 16, Batch 1500] loss: 0.7426302391290664
[Epoch 16, Batch 1600] loss: 0.7607538792490959
[Epoch 16, Batch 1700] loss: 0.7422913575172424
[Epoch 16, Batch 1800] loss: 0.6980364385247231
**STATS for Epoch 16** : 
Average training loss: 0.0280
Average validation loss: 0.7168
Validation Accuracy: 0.8159
Overfitting: 0.6888
Best model saved at epoch 16 with validation loss: 0.7168
[Epoch 17, Batch 100] loss: 0.7239325356483459
[Epoch 17, Batch 200] loss: 0.7034142094850541
[Epoch 17, Batch 300] loss: 0.6883073118329048
[Epoch 17, Batch 400] loss: 0.6772447979450226
[Epoch 17, Batch 500] loss: 0.6896242520213127
[Epoch 17, Batch 600] loss: 0.6626045796275138
[Epoch 17, Batch 700] loss: 0.6795996454358101
[Epoch 17, Batch 800] loss: 0.715662172138691
[Epoch 17, Batch 900] loss: 0.6741426676511765
[Epoch 17, Batch 1000] loss: 0.6315848782658577
[Epoch 17, Batch 1100] loss: 0.6674430787563324
[Epoch 17, Batch 1200] loss: 0.6558234384655952
[Epoch 17, Batch 1300] loss: 0.6514209923148155
[Epoch 17, Batch 1400] loss: 0.643176794052124
[Epoch 17, Batch 1500] loss: 0.6324421001970768
[Epoch 17, Batch 1600] loss: 0.585172019302845
[Epoch 17, Batch 1700] loss: 0.6094255809485912
[Epoch 17, Batch 1800] loss: 0.6366033416986465
**STATS for Epoch 17** : 
Average training loss: 0.0234
Average validation loss: 0.6124
Validation Accuracy: 0.8342
Overfitting: 0.5891
Best model saved at epoch 17 with validation loss: 0.6124
[Epoch 18, Batch 100] loss: 0.5960076946020126
[Epoch 18, Batch 200] loss: 0.6283276677131653
[Epoch 18, Batch 300] loss: 0.5635203033685684
[Epoch 18, Batch 400] loss: 0.59359817430377
[Epoch 18, Batch 500] loss: 0.6053994666039944
[Epoch 18, Batch 600] loss: 0.5892040394246578
[Epoch 18, Batch 700] loss: 0.5950307783484459
[Epoch 18, Batch 800] loss: 0.5865034775435924
[Epoch 18, Batch 900] loss: 0.5623946219682694
[Epoch 18, Batch 1000] loss: 0.577695653885603
[Epoch 18, Batch 1100] loss: 0.6026269462704659
[Epoch 18, Batch 1200] loss: 0.5866823607683181
[Epoch 18, Batch 1300] loss: 0.5552474063634872
[Epoch 18, Batch 1400] loss: 0.5440790393948555
[Epoch 18, Batch 1500] loss: 0.5781350982189178
[Epoch 18, Batch 1600] loss: 0.53798873975873
[Epoch 18, Batch 1700] loss: 0.5206054672598839
[Epoch 18, Batch 1800] loss: 0.5360933843255044
**STATS for Epoch 18** : 
Average training loss: 0.0203
Average validation loss: 0.5428
Validation Accuracy: 0.8501
Overfitting: 0.5225
Best model saved at epoch 18 with validation loss: 0.5428
[Epoch 19, Batch 100] loss: 0.5273567925393582
[Epoch 19, Batch 200] loss: 0.5436474221944809
[Epoch 19, Batch 300] loss: 0.5257243838906288
[Epoch 19, Batch 400] loss: 0.5731297671794892
[Epoch 19, Batch 500] loss: 0.5238079185783863
[Epoch 19, Batch 600] loss: 0.5097580049932003
[Epoch 19, Batch 700] loss: 0.5365189209580421
[Epoch 19, Batch 800] loss: 0.4906552517414093
[Epoch 19, Batch 900] loss: 0.5286601975560188
[Epoch 19, Batch 1000] loss: 0.48232699409127233
[Epoch 19, Batch 1100] loss: 0.5145581698417664
[Epoch 19, Batch 1200] loss: 0.48589934974908827
[Epoch 19, Batch 1300] loss: 0.5215328969061375
[Epoch 19, Batch 1400] loss: 0.505489794909954
[Epoch 19, Batch 1500] loss: 0.48532623633742333
[Epoch 19, Batch 1600] loss: 0.5164478518813849
[Epoch 19, Batch 1700] loss: 0.49255014076828957
[Epoch 19, Batch 1800] loss: 0.4813185864686966
**STATS for Epoch 19** : 
Average training loss: 0.0197
Average validation loss: 0.4934
Validation Accuracy: 0.8595
Overfitting: 0.4737
Best model saved at epoch 19 with validation loss: 0.4934
[Epoch 20, Batch 100] loss: 0.48951316766440867
[Epoch 20, Batch 200] loss: 0.5014264899492263
[Epoch 20, Batch 300] loss: 0.46271684862673285
[Epoch 20, Batch 400] loss: 0.4522219666838646
[Epoch 20, Batch 500] loss: 0.46285135835409164
[Epoch 20, Batch 600] loss: 0.44479266442358495
[Epoch 20, Batch 700] loss: 0.4402720686793327
[Epoch 20, Batch 800] loss: 0.4940030266344547
[Epoch 20, Batch 900] loss: 0.47458711624145505
[Epoch 20, Batch 1000] loss: 0.46856726609170435
[Epoch 20, Batch 1100] loss: 0.4307910852134228
[Epoch 20, Batch 1200] loss: 0.47711729258298874
[Epoch 20, Batch 1300] loss: 0.46778500095009806
[Epoch 20, Batch 1400] loss: 0.45006110310554504
[Epoch 20, Batch 1500] loss: 0.4536615818738937
[Epoch 20, Batch 1600] loss: 0.5000296665728092
[Epoch 20, Batch 1700] loss: 0.4941012893617153
[Epoch 20, Batch 1800] loss: 0.46335620790719984
**STATS for Epoch 20** : 
Average training loss: 0.0196
Average validation loss: 0.4553
Validation Accuracy: 0.8709
Overfitting: 0.4357
Best model saved at epoch 20 with validation loss: 0.4553
[Epoch 21, Batch 100] loss: 0.43314714878797533
[Epoch 21, Batch 200] loss: 0.44120710909366606
[Epoch 21, Batch 300] loss: 0.4464819856733084
[Epoch 21, Batch 400] loss: 0.4206712272763252
[Epoch 21, Batch 500] loss: 0.428283861130476
[Epoch 21, Batch 600] loss: 0.45288959562778475
[Epoch 21, Batch 700] loss: 0.43795967489480975
[Epoch 21, Batch 800] loss: 0.44988814897835255
[Epoch 21, Batch 900] loss: 0.4631588013470173
[Epoch 21, Batch 1000] loss: 0.4467169424146414
[Epoch 21, Batch 1100] loss: 0.40930932596325875
[Epoch 21, Batch 1200] loss: 0.42379483610391616
[Epoch 21, Batch 1300] loss: 0.41280779741704465
[Epoch 21, Batch 1400] loss: 0.4373824606835842
[Epoch 21, Batch 1500] loss: 0.4580757048726082
[Epoch 21, Batch 1600] loss: 0.44157324664294717
[Epoch 21, Batch 1700] loss: 0.43947247713804244
[Epoch 21, Batch 1800] loss: 0.4391043549031019
**STATS for Epoch 21** : 
Average training loss: 0.0155
Average validation loss: 0.4279
Validation Accuracy: 0.8779
Overfitting: 0.4124
Best model saved at epoch 21 with validation loss: 0.4279
[Epoch 22, Batch 100] loss: 0.4218950344622135
[Epoch 22, Batch 200] loss: 0.41074742428958416
[Epoch 22, Batch 300] loss: 0.4227420724928379
[Epoch 22, Batch 400] loss: 0.4518125479668379
[Epoch 22, Batch 500] loss: 0.4114264177531004
[Epoch 22, Batch 600] loss: 0.4048050547391176
[Epoch 22, Batch 700] loss: 0.4166812098026276
[Epoch 22, Batch 800] loss: 0.41661573022603987
[Epoch 22, Batch 900] loss: 0.4118578766286373
[Epoch 22, Batch 1000] loss: 0.4000710754841566
[Epoch 22, Batch 1100] loss: 0.429368260204792
[Epoch 22, Batch 1200] loss: 0.38133786782622336
[Epoch 22, Batch 1300] loss: 0.3955227632820606
[Epoch 22, Batch 1400] loss: 0.3731038796901703
[Epoch 22, Batch 1500] loss: 0.4008172437548637
[Epoch 22, Batch 1600] loss: 0.44877741143107414
[Epoch 22, Batch 1700] loss: 0.40074981287121775
[Epoch 22, Batch 1800] loss: 0.38089274235069753
**STATS for Epoch 22** : 
Average training loss: 0.0154
Average validation loss: 0.4050
Validation Accuracy: 0.8832
Overfitting: 0.3897
Best model saved at epoch 22 with validation loss: 0.4050
[Epoch 23, Batch 100] loss: 0.40587994784116743
[Epoch 23, Batch 200] loss: 0.3854868449270725
[Epoch 23, Batch 300] loss: 0.4151080525666475
[Epoch 23, Batch 400] loss: 0.39258215146139264
[Epoch 23, Batch 500] loss: 0.3681422882527113
[Epoch 23, Batch 600] loss: 0.40381267994642256
[Epoch 23, Batch 700] loss: 0.36651374205946924
[Epoch 23, Batch 800] loss: 0.39122203685343265
[Epoch 23, Batch 900] loss: 0.3591346921771765
[Epoch 23, Batch 1000] loss: 0.40586594827473166
[Epoch 23, Batch 1100] loss: 0.42175886534154416
[Epoch 23, Batch 1200] loss: 0.39082701861858365
[Epoch 23, Batch 1300] loss: 0.38537466935813425
[Epoch 23, Batch 1400] loss: 0.3960978002846241
[Epoch 23, Batch 1500] loss: 0.38033653780817983
[Epoch 23, Batch 1600] loss: 0.3733734765648842
[Epoch 23, Batch 1700] loss: 0.3902673118561506
[Epoch 23, Batch 1800] loss: 0.36768690817058086
**STATS for Epoch 23** : 
Average training loss: 0.0138
Average validation loss: 0.3856
Validation Accuracy: 0.8872
Overfitting: 0.3718
Best model saved at epoch 23 with validation loss: 0.3856
[Epoch 24, Batch 100] loss: 0.36822002843022344
[Epoch 24, Batch 200] loss: 0.36796615317463877
[Epoch 24, Batch 300] loss: 0.39627191685140134
[Epoch 24, Batch 400] loss: 0.38158441737294196
[Epoch 24, Batch 500] loss: 0.3681317295134068
[Epoch 24, Batch 600] loss: 0.38712874010205267
[Epoch 24, Batch 700] loss: 0.39533126056194307
[Epoch 24, Batch 800] loss: 0.37365581274032594
[Epoch 24, Batch 900] loss: 0.35297791469842194
[Epoch 24, Batch 1000] loss: 0.37077504247426984
[Epoch 24, Batch 1100] loss: 0.36378355640918014
[Epoch 24, Batch 1200] loss: 0.36844785176217554
[Epoch 24, Batch 1300] loss: 0.3378702443093061
[Epoch 24, Batch 1400] loss: 0.3587575495243073
[Epoch 24, Batch 1500] loss: 0.3574674241244793
[Epoch 24, Batch 1600] loss: 0.34876857899129393
[Epoch 24, Batch 1700] loss: 0.3742045809701085
[Epoch 24, Batch 1800] loss: 0.37423526860773565
**STATS for Epoch 24** : 
Average training loss: 0.0147
Average validation loss: 0.3667
Validation Accuracy: 0.8931
Overfitting: 0.3520
Best model saved at epoch 24 with validation loss: 0.3667
Fold 2 validation loss: 0.3667
Mean validation loss across all folds for Trial 2 is 0.3786 with trial config:  l1: 352, l2: 256, lr: 1.2087541473056957e-05, batch_size: 16
[I 2024-11-19 00:20:47,234] Trial 1 finished with value: 0.37856520828108 and parameters: {'l1': 352, 'l2': 256, 'lr': 1.2087541473056957e-05, 'batch_size': 16}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 3:
  l1: 192, l2: 128, lr: 0.0005342937261279777, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.293813681602478
[Epoch 1, Batch 200] loss: 2.259632995128632
[Epoch 1, Batch 300] loss: 2.2000299954414366
[Epoch 1, Batch 400] loss: 2.0334614014625547
[Epoch 1, Batch 500] loss: 1.5467145144939423
[Epoch 1, Batch 600] loss: 0.9499274420738221
[Epoch 1, Batch 700] loss: 0.7046590679883957
[Epoch 1, Batch 800] loss: 0.6211537864804267
[Epoch 1, Batch 900] loss: 0.5214494854211807
**STATS for Epoch 1** : 
Average training loss: 0.0215
Average validation loss: 0.4706
Validation Accuracy: 0.8593
Overfitting: 0.4490
Best model saved at epoch 1 with validation loss: 0.4706
[Epoch 2, Batch 100] loss: 0.46456942304968835
[Epoch 2, Batch 200] loss: 0.45724555268883704
[Epoch 2, Batch 300] loss: 0.3878854323923588
[Epoch 2, Batch 400] loss: 0.35007608845829963
[Epoch 2, Batch 500] loss: 0.3795946537703276
[Epoch 2, Batch 600] loss: 0.3245552522689104
[Epoch 2, Batch 700] loss: 0.3262434847652912
[Epoch 2, Batch 800] loss: 0.3317085214704275
[Epoch 2, Batch 900] loss: 0.26923625588417055
**STATS for Epoch 2** : 
Average training loss: 0.0118
Average validation loss: 0.2716
Validation Accuracy: 0.9193
Overfitting: 0.2598
Best model saved at epoch 2 with validation loss: 0.2716
[Epoch 3, Batch 100] loss: 0.3015081275254488
[Epoch 3, Batch 200] loss: 0.2459335231035948
[Epoch 3, Batch 300] loss: 0.2611182277277112
[Epoch 3, Batch 400] loss: 0.21590285655111074
[Epoch 3, Batch 500] loss: 0.2128647265955806
[Epoch 3, Batch 600] loss: 0.23075842898339033
[Epoch 3, Batch 700] loss: 0.20527094904333354
[Epoch 3, Batch 800] loss: 0.207426218688488
[Epoch 3, Batch 900] loss: 0.19631352996453644
**STATS for Epoch 3** : 
Average training loss: 0.0080
Average validation loss: 0.1920
Validation Accuracy: 0.9405
Overfitting: 0.1839
Best model saved at epoch 3 with validation loss: 0.1920
[Epoch 4, Batch 100] loss: 0.18799853667616845
[Epoch 4, Batch 200] loss: 0.17632330469787122
[Epoch 4, Batch 300] loss: 0.1983132792264223
[Epoch 4, Batch 400] loss: 0.1715471578761935
[Epoch 4, Batch 500] loss: 0.16694261034950614
[Epoch 4, Batch 600] loss: 0.17363060779869557
[Epoch 4, Batch 700] loss: 0.14730937550775708
[Epoch 4, Batch 800] loss: 0.14369865017011763
[Epoch 4, Batch 900] loss: 0.14962202462367713
**STATS for Epoch 4** : 
Average training loss: 0.0072
Average validation loss: 0.1470
Validation Accuracy: 0.9554
Overfitting: 0.1398
Best model saved at epoch 4 with validation loss: 0.1470
[Epoch 5, Batch 100] loss: 0.14470070637762547
[Epoch 5, Batch 200] loss: 0.13304227147251368
[Epoch 5, Batch 300] loss: 0.14604909371584654
[Epoch 5, Batch 400] loss: 0.15265426820144057
[Epoch 5, Batch 500] loss: 0.11891867003869265
[Epoch 5, Batch 600] loss: 0.1490656010247767
[Epoch 5, Batch 700] loss: 0.13019538138061762
[Epoch 5, Batch 800] loss: 0.13445426354184747
[Epoch 5, Batch 900] loss: 0.11431006890721619
**STATS for Epoch 5** : 
Average training loss: 0.0046
Average validation loss: 0.1256
Validation Accuracy: 0.9623
Overfitting: 0.1211
Best model saved at epoch 5 with validation loss: 0.1256
[Epoch 6, Batch 100] loss: 0.12270426865667104
[Epoch 6, Batch 200] loss: 0.11567753493785858
[Epoch 6, Batch 300] loss: 0.12098580277524888
[Epoch 6, Batch 400] loss: 0.10840133449994027
[Epoch 6, Batch 500] loss: 0.10869848569389433
[Epoch 6, Batch 600] loss: 0.10528144530020654
[Epoch 6, Batch 700] loss: 0.0889253891305998
[Epoch 6, Batch 800] loss: 0.11854102279990912
[Epoch 6, Batch 900] loss: 0.12282955957576633
**STATS for Epoch 6** : 
Average training loss: 0.0042
Average validation loss: 0.1165
Validation Accuracy: 0.9645
Overfitting: 0.1123
Best model saved at epoch 6 with validation loss: 0.1165
[Epoch 7, Batch 100] loss: 0.10958185525145382
[Epoch 7, Batch 200] loss: 0.11218167879618704
[Epoch 7, Batch 300] loss: 0.09364446382969618
[Epoch 7, Batch 400] loss: 0.10236579404212534
[Epoch 7, Batch 500] loss: 0.09929551239125431
[Epoch 7, Batch 600] loss: 0.08656193466391414
[Epoch 7, Batch 700] loss: 0.10339278443716467
[Epoch 7, Batch 800] loss: 0.09472325678681955
[Epoch 7, Batch 900] loss: 0.10245118405204266
**STATS for Epoch 7** : 
Average training loss: 0.0034
Average validation loss: 0.1210
Validation Accuracy: 0.9616
Overfitting: 0.1175
[Epoch 8, Batch 100] loss: 0.08366288549266755
[Epoch 8, Batch 200] loss: 0.10188822119496763
[Epoch 8, Batch 300] loss: 0.08481218898668885
[Epoch 8, Batch 400] loss: 0.08570796287152917
[Epoch 8, Batch 500] loss: 0.1030650370568037
[Epoch 8, Batch 600] loss: 0.08616358617786318
[Epoch 8, Batch 700] loss: 0.08648057939950377
[Epoch 8, Batch 800] loss: 0.09551116443239152
[Epoch 8, Batch 900] loss: 0.0787677500071004
**STATS for Epoch 8** : 
Average training loss: 0.0040
Average validation loss: 0.0904
Validation Accuracy: 0.9726
Overfitting: 0.0864
Best model saved at epoch 8 with validation loss: 0.0904
[Epoch 9, Batch 100] loss: 0.07852337030228228
[Epoch 9, Batch 200] loss: 0.06995651657227427
[Epoch 9, Batch 300] loss: 0.087702681934461
[Epoch 9, Batch 400] loss: 0.071111284554936
[Epoch 9, Batch 500] loss: 0.07248830370837822
[Epoch 9, Batch 600] loss: 0.0909742530132644
[Epoch 9, Batch 700] loss: 0.08463736564852298
[Epoch 9, Batch 800] loss: 0.07625985969789326
[Epoch 9, Batch 900] loss: 0.09179637144319713
**STATS for Epoch 9** : 
Average training loss: 0.0029
Average validation loss: 0.0831
Validation Accuracy: 0.9747
Overfitting: 0.0803
Best model saved at epoch 9 with validation loss: 0.0831
[Epoch 10, Batch 100] loss: 0.07649030599743128
[Epoch 10, Batch 200] loss: 0.07426880836253985
[Epoch 10, Batch 300] loss: 0.08403491015546023
[Epoch 10, Batch 400] loss: 0.06664625334087759
[Epoch 10, Batch 500] loss: 0.06452285615261644
[Epoch 10, Batch 600] loss: 0.07492416434222832
[Epoch 10, Batch 700] loss: 0.07437628047540784
[Epoch 10, Batch 800] loss: 0.07345558078261093
[Epoch 10, Batch 900] loss: 0.07122283724602312
**STATS for Epoch 10** : 
Average training loss: 0.0024
Average validation loss: 0.0825
Validation Accuracy: 0.9743
Overfitting: 0.0801
Best model saved at epoch 10 with validation loss: 0.0825
[Epoch 11, Batch 100] loss: 0.06619162923190743
[Epoch 11, Batch 200] loss: 0.06245341054629534
[Epoch 11, Batch 300] loss: 0.07578138100448996
[Epoch 11, Batch 400] loss: 0.06392348947236315
[Epoch 11, Batch 500] loss: 0.063922658264637
[Epoch 11, Batch 600] loss: 0.07859538696007803
[Epoch 11, Batch 700] loss: 0.05199769855244085
[Epoch 11, Batch 800] loss: 0.06271971662295982
[Epoch 11, Batch 900] loss: 0.07594239064492285
**STATS for Epoch 11** : 
Average training loss: 0.0030
Average validation loss: 0.0853
Validation Accuracy: 0.9738
Overfitting: 0.0823
[Epoch 12, Batch 100] loss: 0.06055925330147147
[Epoch 12, Batch 200] loss: 0.05121945264283568
[Epoch 12, Batch 300] loss: 0.06367662922479213
[Epoch 12, Batch 400] loss: 0.057211450028698894
[Epoch 12, Batch 500] loss: 0.06284476747270673
[Epoch 12, Batch 600] loss: 0.0671193487639539
[Epoch 12, Batch 700] loss: 0.07039174834266305
[Epoch 12, Batch 800] loss: 0.07829065488651395
[Epoch 12, Batch 900] loss: 0.052667114585638046
**STATS for Epoch 12** : 
Average training loss: 0.0025
Average validation loss: 0.0795
Validation Accuracy: 0.9754
Overfitting: 0.0771
Best model saved at epoch 12 with validation loss: 0.0795
[Epoch 13, Batch 100] loss: 0.053432123381644485
[Epoch 13, Batch 200] loss: 0.05616323646507226
[Epoch 13, Batch 300] loss: 0.06346378354122863
[Epoch 13, Batch 400] loss: 0.056918884166516366
[Epoch 13, Batch 500] loss: 0.06996140630566515
[Epoch 13, Batch 600] loss: 0.04654131268383935
[Epoch 13, Batch 700] loss: 0.060690176468342544
[Epoch 13, Batch 800] loss: 0.051189772780053315
[Epoch 13, Batch 900] loss: 0.05713203803286888
**STATS for Epoch 13** : 
Average training loss: 0.0028
Average validation loss: 0.0757
Validation Accuracy: 0.9770
Overfitting: 0.0730
Best model saved at epoch 13 with validation loss: 0.0757
[Epoch 14, Batch 100] loss: 0.04982606845442206
[Epoch 14, Batch 200] loss: 0.057589692436158656
[Epoch 14, Batch 300] loss: 0.05342794718104415
[Epoch 14, Batch 400] loss: 0.04681107256328687
[Epoch 14, Batch 500] loss: 0.06207671476528048
[Epoch 14, Batch 600] loss: 0.05370567318983376
[Epoch 14, Batch 700] loss: 0.056874107450712474
[Epoch 14, Batch 800] loss: 0.051729349695378915
[Epoch 14, Batch 900] loss: 0.06746519425534643
**STATS for Epoch 14** : 
Average training loss: 0.0019
Average validation loss: 0.0719
Validation Accuracy: 0.9787
Overfitting: 0.0700
Best model saved at epoch 14 with validation loss: 0.0719
[Epoch 15, Batch 100] loss: 0.05172484488226473
[Epoch 15, Batch 200] loss: 0.046919338628649714
[Epoch 15, Batch 300] loss: 0.05295211296761408
[Epoch 15, Batch 400] loss: 0.04554165760753676
[Epoch 15, Batch 500] loss: 0.05037252570269629
[Epoch 15, Batch 600] loss: 0.04392736911540851
[Epoch 15, Batch 700] loss: 0.051597894278820604
[Epoch 15, Batch 800] loss: 0.04892965324921533
[Epoch 15, Batch 900] loss: 0.05020260822609998
**STATS for Epoch 15** : 
Average training loss: 0.0031
Average validation loss: 0.0718
Validation Accuracy: 0.9791
Overfitting: 0.0686
Best model saved at epoch 15 with validation loss: 0.0718
[Epoch 16, Batch 100] loss: 0.049005557270720604
[Epoch 16, Batch 200] loss: 0.04805911087431013
[Epoch 16, Batch 300] loss: 0.05720049304421991
[Epoch 16, Batch 400] loss: 0.05019075796124525
[Epoch 16, Batch 500] loss: 0.04394681429490447
[Epoch 16, Batch 600] loss: 0.0440723864780739
[Epoch 16, Batch 700] loss: 0.040239004221512005
[Epoch 16, Batch 800] loss: 0.04679049266735092
[Epoch 16, Batch 900] loss: 0.05347977929050103
**STATS for Epoch 16** : 
Average training loss: 0.0019
Average validation loss: 0.0690
Validation Accuracy: 0.9794
Overfitting: 0.0672
Best model saved at epoch 16 with validation loss: 0.0690
[Epoch 17, Batch 100] loss: 0.04283912166953087
[Epoch 17, Batch 200] loss: 0.036802773870294916
[Epoch 17, Batch 300] loss: 0.03953145916748326
[Epoch 17, Batch 400] loss: 0.05190351684344932
[Epoch 17, Batch 500] loss: 0.04726128803798929
[Epoch 17, Batch 600] loss: 0.043210360809462146
[Epoch 17, Batch 700] loss: 0.03661921642604284
[Epoch 17, Batch 800] loss: 0.043287166773807256
[Epoch 17, Batch 900] loss: 0.04452010713517666
**STATS for Epoch 17** : 
Average training loss: 0.0020
Average validation loss: 0.0634
Validation Accuracy: 0.9815
Overfitting: 0.0614
Best model saved at epoch 17 with validation loss: 0.0634
[Epoch 18, Batch 100] loss: 0.034343830459401946
[Epoch 18, Batch 200] loss: 0.03477444488089532
[Epoch 18, Batch 300] loss: 0.04006082180596422
[Epoch 18, Batch 400] loss: 0.04703757224720903
[Epoch 18, Batch 500] loss: 0.04450053197215311
[Epoch 18, Batch 600] loss: 0.04111704735842068
[Epoch 18, Batch 700] loss: 0.03919801470823586
[Epoch 18, Batch 800] loss: 0.04312369829043746
[Epoch 18, Batch 900] loss: 0.04476345678791404
**STATS for Epoch 18** : 
Average training loss: 0.0022
Average validation loss: 0.0674
Validation Accuracy: 0.9801
Overfitting: 0.0653
[Epoch 19, Batch 100] loss: 0.04066495706734713
[Epoch 19, Batch 200] loss: 0.032596416496671735
[Epoch 19, Batch 300] loss: 0.04317524268932175
[Epoch 19, Batch 400] loss: 0.040550699139712376
[Epoch 19, Batch 500] loss: 0.039099352735793215
[Epoch 19, Batch 600] loss: 0.04201140279503306
[Epoch 19, Batch 700] loss: 0.04084206731058657
[Epoch 19, Batch 800] loss: 0.03707450751797296
[Epoch 19, Batch 900] loss: 0.04148136878851801
**STATS for Epoch 19** : 
Average training loss: 0.0020
Average validation loss: 0.0610
Validation Accuracy: 0.9814
Overfitting: 0.0590
Best model saved at epoch 19 with validation loss: 0.0610
[Epoch 20, Batch 100] loss: 0.028448556932853534
[Epoch 20, Batch 200] loss: 0.037570134309353305
[Epoch 20, Batch 300] loss: 0.04447201312985271
[Epoch 20, Batch 400] loss: 0.026886815892066807
[Epoch 20, Batch 500] loss: 0.03865704406285658
[Epoch 20, Batch 600] loss: 0.039573610303923486
[Epoch 20, Batch 700] loss: 0.0256771609315183
[Epoch 20, Batch 800] loss: 0.05030828054266749
[Epoch 20, Batch 900] loss: 0.03940657176892273
**STATS for Epoch 20** : 
Average training loss: 0.0018
Average validation loss: 0.0624
Validation Accuracy: 0.9815
Overfitting: 0.0606
[Epoch 21, Batch 100] loss: 0.034210016567958516
[Epoch 21, Batch 200] loss: 0.034213936821033714
[Epoch 21, Batch 300] loss: 0.0319028153445106
[Epoch 21, Batch 400] loss: 0.027621469047735447
[Epoch 21, Batch 500] loss: 0.04032636820629705
[Epoch 21, Batch 600] loss: 0.03481319814512972
[Epoch 21, Batch 700] loss: 0.030038193934015
[Epoch 21, Batch 800] loss: 0.03809235993481707
[Epoch 21, Batch 900] loss: 0.03784351432113908
**STATS for Epoch 21** : 
Average training loss: 0.0018
Average validation loss: 0.0619
Validation Accuracy: 0.9814
Overfitting: 0.0600
[Epoch 22, Batch 100] loss: 0.025997756049619056
[Epoch 22, Batch 200] loss: 0.028796075672726146
[Epoch 22, Batch 300] loss: 0.033015406916383654
[Epoch 22, Batch 400] loss: 0.028600756622327025
[Epoch 22, Batch 500] loss: 0.036870169171888845
[Epoch 22, Batch 600] loss: 0.03940405482746428
[Epoch 22, Batch 700] loss: 0.029888083807891236
[Epoch 22, Batch 800] loss: 0.042180978838005104
[Epoch 22, Batch 900] loss: 0.029599084863439203
**STATS for Epoch 22** : 
Average training loss: 0.0017
Average validation loss: 0.0615
Validation Accuracy: 0.9821
Overfitting: 0.0598
[Epoch 23, Batch 100] loss: 0.025308223754982463
[Epoch 23, Batch 200] loss: 0.03995875737338792
[Epoch 23, Batch 300] loss: 0.030000616203178652
[Epoch 23, Batch 400] loss: 0.031191447770106608
[Epoch 23, Batch 500] loss: 0.03153113607666455
[Epoch 23, Batch 600] loss: 0.02530483404698316
[Epoch 23, Batch 700] loss: 0.0249526451760903
[Epoch 23, Batch 800] loss: 0.03547180311201373
[Epoch 23, Batch 900] loss: 0.027847821196191943
**STATS for Epoch 23** : 
Average training loss: 0.0010
Average validation loss: 0.0630
Validation Accuracy: 0.9816
Overfitting: 0.0620
[Epoch 24, Batch 100] loss: 0.027495958479703403
[Epoch 24, Batch 200] loss: 0.02581856233999133
[Epoch 24, Batch 300] loss: 0.02505404235620517
[Epoch 24, Batch 400] loss: 0.022506523857882713
[Epoch 24, Batch 500] loss: 0.03747140508319717
[Epoch 24, Batch 600] loss: 0.026382677303627134
[Epoch 24, Batch 700] loss: 0.02412893499364145
[Epoch 24, Batch 800] loss: 0.025478542050987017
[Epoch 24, Batch 900] loss: 0.0350741333613405
**STATS for Epoch 24** : 
Average training loss: 0.0012
Average validation loss: 0.0665
Validation Accuracy: 0.9798
Overfitting: 0.0653
Fold 1 validation loss: 0.0665
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.296449007987976
[Epoch 1, Batch 200] loss: 2.275401463508606
[Epoch 1, Batch 300] loss: 2.2445093822479247
[Epoch 1, Batch 400] loss: 2.185337450504303
[Epoch 1, Batch 500] loss: 2.0167412400245666
[Epoch 1, Batch 600] loss: 1.4244553196430205
[Epoch 1, Batch 700] loss: 0.8000352209806443
[Epoch 1, Batch 800] loss: 0.5403833612799644
[Epoch 1, Batch 900] loss: 0.48419748708605764
**STATS for Epoch 1** : 
Average training loss: 0.0169
Average validation loss: 0.4254
Validation Accuracy: 0.8687
Overfitting: 0.4085
Best model saved at epoch 1 with validation loss: 0.4254
[Epoch 2, Batch 100] loss: 0.39242307119071485
[Epoch 2, Batch 200] loss: 0.32115383982658385
[Epoch 2, Batch 300] loss: 0.31687895573675634
[Epoch 2, Batch 400] loss: 0.291705671697855
[Epoch 2, Batch 500] loss: 0.30296758987009526
[Epoch 2, Batch 600] loss: 0.2796445395424962
[Epoch 2, Batch 700] loss: 0.2885974318534136
[Epoch 2, Batch 800] loss: 0.24846060656011104
[Epoch 2, Batch 900] loss: 0.24160720005631448
**STATS for Epoch 2** : 
Average training loss: 0.0092
Average validation loss: 0.2245
Validation Accuracy: 0.9318
Overfitting: 0.2153
Best model saved at epoch 2 with validation loss: 0.2245
[Epoch 3, Batch 100] loss: 0.21830300375819206
[Epoch 3, Batch 200] loss: 0.2101796768605709
[Epoch 3, Batch 300] loss: 0.1908454742655158
[Epoch 3, Batch 400] loss: 0.19290454043075442
[Epoch 3, Batch 500] loss: 0.20273445026949047
[Epoch 3, Batch 600] loss: 0.17381706956773996
[Epoch 3, Batch 700] loss: 0.1789028981886804
[Epoch 3, Batch 800] loss: 0.18946111472323537
[Epoch 3, Batch 900] loss: 0.17195575512945652
**STATS for Epoch 3** : 
Average training loss: 0.0065
Average validation loss: 0.1772
Validation Accuracy: 0.9451
Overfitting: 0.1707
Best model saved at epoch 3 with validation loss: 0.1772
[Epoch 4, Batch 100] loss: 0.14127426935359835
[Epoch 4, Batch 200] loss: 0.16391458945348858
[Epoch 4, Batch 300] loss: 0.14600185984745623
[Epoch 4, Batch 400] loss: 0.17357650028541685
[Epoch 4, Batch 500] loss: 0.1500268999580294
[Epoch 4, Batch 600] loss: 0.14188406724482774
[Epoch 4, Batch 700] loss: 0.13069595736451448
[Epoch 4, Batch 800] loss: 0.12823032511398197
[Epoch 4, Batch 900] loss: 0.13276666012592614
**STATS for Epoch 4** : 
Average training loss: 0.0054
Average validation loss: 0.1321
Validation Accuracy: 0.9600
Overfitting: 0.1266
Best model saved at epoch 4 with validation loss: 0.1321
[Epoch 5, Batch 100] loss: 0.1318496575206518
[Epoch 5, Batch 200] loss: 0.13082447916269302
[Epoch 5, Batch 300] loss: 0.11203801698982715
[Epoch 5, Batch 400] loss: 0.12655337454751134
[Epoch 5, Batch 500] loss: 0.12018515419680625
[Epoch 5, Batch 600] loss: 0.12206495312973857
[Epoch 5, Batch 700] loss: 0.1192225349880755
[Epoch 5, Batch 800] loss: 0.09778112829662859
[Epoch 5, Batch 900] loss: 0.11384603475220502
**STATS for Epoch 5** : 
Average training loss: 0.0038
Average validation loss: 0.1113
Validation Accuracy: 0.9661
Overfitting: 0.1075
Best model saved at epoch 5 with validation loss: 0.1113
[Epoch 6, Batch 100] loss: 0.10436714500654488
[Epoch 6, Batch 200] loss: 0.11187542207539082
[Epoch 6, Batch 300] loss: 0.09588138263672591
[Epoch 6, Batch 400] loss: 0.11379916300997138
[Epoch 6, Batch 500] loss: 0.08926758475601673
[Epoch 6, Batch 600] loss: 0.09528569780290126
[Epoch 6, Batch 700] loss: 0.10036721565760671
[Epoch 6, Batch 800] loss: 0.09824309558607638
[Epoch 6, Batch 900] loss: 0.0975334213115275
**STATS for Epoch 6** : 
Average training loss: 0.0033
Average validation loss: 0.0997
Validation Accuracy: 0.9694
Overfitting: 0.0964
Best model saved at epoch 6 with validation loss: 0.0997
[Epoch 7, Batch 100] loss: 0.08079136709682644
[Epoch 7, Batch 200] loss: 0.09211246869759634
[Epoch 7, Batch 300] loss: 0.09933319727890194
[Epoch 7, Batch 400] loss: 0.08858559482730925
[Epoch 7, Batch 500] loss: 0.10078620603308082
[Epoch 7, Batch 600] loss: 0.09505567116197199
[Epoch 7, Batch 700] loss: 0.07677988311275839
[Epoch 7, Batch 800] loss: 0.0725618591462262
[Epoch 7, Batch 900] loss: 0.10314024346414953
**STATS for Epoch 7** : 
Average training loss: 0.0038
Average validation loss: 0.0968
Validation Accuracy: 0.9713
Overfitting: 0.0930
Best model saved at epoch 7 with validation loss: 0.0968
[Epoch 8, Batch 100] loss: 0.07970469136256725
[Epoch 8, Batch 200] loss: 0.08210475124651566
[Epoch 8, Batch 300] loss: 0.1009317649807781
[Epoch 8, Batch 400] loss: 0.07770893068052828
[Epoch 8, Batch 500] loss: 0.07927834513131529
[Epoch 8, Batch 600] loss: 0.08219495572615415
[Epoch 8, Batch 700] loss: 0.07816197866108268
[Epoch 8, Batch 800] loss: 0.06713187491288408
[Epoch 8, Batch 900] loss: 0.07425501798279584
**STATS for Epoch 8** : 
Average training loss: 0.0037
Average validation loss: 0.0885
Validation Accuracy: 0.9726
Overfitting: 0.0848
Best model saved at epoch 8 with validation loss: 0.0885
[Epoch 9, Batch 100] loss: 0.06624581599375233
[Epoch 9, Batch 200] loss: 0.07317409206647425
[Epoch 9, Batch 300] loss: 0.06599182594567538
[Epoch 9, Batch 400] loss: 0.07442916369996964
[Epoch 9, Batch 500] loss: 0.07383857115637511
[Epoch 9, Batch 600] loss: 0.06503395834472031
[Epoch 9, Batch 700] loss: 0.09266785407671704
[Epoch 9, Batch 800] loss: 0.07696083965478465
[Epoch 9, Batch 900] loss: 0.08837970398017206
**STATS for Epoch 9** : 
Average training loss: 0.0029
Average validation loss: 0.0832
Validation Accuracy: 0.9746
Overfitting: 0.0803
Best model saved at epoch 9 with validation loss: 0.0832
[Epoch 10, Batch 100] loss: 0.058466502064839006
[Epoch 10, Batch 200] loss: 0.06102424333803356
[Epoch 10, Batch 300] loss: 0.06815468507120385
[Epoch 10, Batch 400] loss: 0.06525138237513602
[Epoch 10, Batch 500] loss: 0.08168894606991671
[Epoch 10, Batch 600] loss: 0.07234362687915563
[Epoch 10, Batch 700] loss: 0.06467361871851608
[Epoch 10, Batch 800] loss: 0.06333023574901744
[Epoch 10, Batch 900] loss: 0.07033738832455129
**STATS for Epoch 10** : 
Average training loss: 0.0034
Average validation loss: 0.0887
Validation Accuracy: 0.9730
Overfitting: 0.0853
[Epoch 11, Batch 100] loss: 0.07226069436175749
[Epoch 11, Batch 200] loss: 0.056775992545299234
[Epoch 11, Batch 300] loss: 0.0754104890441522
[Epoch 11, Batch 400] loss: 0.05809280721470714
[Epoch 11, Batch 500] loss: 0.06539474382298067
[Epoch 11, Batch 600] loss: 0.05609403861686588
[Epoch 11, Batch 700] loss: 0.061898584694135936
[Epoch 11, Batch 800] loss: 0.0664377842482645
[Epoch 11, Batch 900] loss: 0.06930808041244746
**STATS for Epoch 11** : 
Average training loss: 0.0020
Average validation loss: 0.0750
Validation Accuracy: 0.9773
Overfitting: 0.0730
Best model saved at epoch 11 with validation loss: 0.0750
[Epoch 12, Batch 100] loss: 0.052303113739471885
[Epoch 12, Batch 200] loss: 0.05920981813455001
[Epoch 12, Batch 300] loss: 0.06685948237078264
[Epoch 12, Batch 400] loss: 0.057708570277318356
[Epoch 12, Batch 500] loss: 0.054957999740727244
[Epoch 12, Batch 600] loss: 0.05929484631633386
[Epoch 12, Batch 700] loss: 0.05832749088760465
[Epoch 12, Batch 800] loss: 0.06245726076886058
[Epoch 12, Batch 900] loss: 0.048219159386353565
**STATS for Epoch 12** : 
Average training loss: 0.0022
Average validation loss: 0.0731
Validation Accuracy: 0.9779
Overfitting: 0.0710
Best model saved at epoch 12 with validation loss: 0.0731
[Epoch 13, Batch 100] loss: 0.051621970623964446
[Epoch 13, Batch 200] loss: 0.050016826711362226
[Epoch 13, Batch 300] loss: 0.05999703367589973
[Epoch 13, Batch 400] loss: 0.05095976626849733
[Epoch 13, Batch 500] loss: 0.06534275591373444
[Epoch 13, Batch 600] loss: 0.043322398316813636
[Epoch 13, Batch 700] loss: 0.054335829427582215
[Epoch 13, Batch 800] loss: 0.059863474676385524
[Epoch 13, Batch 900] loss: 0.06251141868764534
**STATS for Epoch 13** : 
Average training loss: 0.0019
Average validation loss: 0.0715
Validation Accuracy: 0.9772
Overfitting: 0.0696
Best model saved at epoch 13 with validation loss: 0.0715
[Epoch 14, Batch 100] loss: 0.04871669023646973
[Epoch 14, Batch 200] loss: 0.048350750895915555
[Epoch 14, Batch 300] loss: 0.0476140994974412
[Epoch 14, Batch 400] loss: 0.05326432471862063
[Epoch 14, Batch 500] loss: 0.04246549443341792
[Epoch 14, Batch 600] loss: 0.07299931371118873
[Epoch 14, Batch 700] loss: 0.060423395882826296
[Epoch 14, Batch 800] loss: 0.0505655679188203
[Epoch 14, Batch 900] loss: 0.048813265939243136
**STATS for Epoch 14** : 
Average training loss: 0.0018
Average validation loss: 0.0662
Validation Accuracy: 0.9802
Overfitting: 0.0644
Best model saved at epoch 14 with validation loss: 0.0662
[Epoch 15, Batch 100] loss: 0.039018653413513675
[Epoch 15, Batch 200] loss: 0.05049579654121771
[Epoch 15, Batch 300] loss: 0.04649646692443639
[Epoch 15, Batch 400] loss: 0.05192441639956087
[Epoch 15, Batch 500] loss: 0.039109798069112
[Epoch 15, Batch 600] loss: 0.051736018297960984
[Epoch 15, Batch 700] loss: 0.05430158973438665
[Epoch 15, Batch 800] loss: 0.05284328889218159
[Epoch 15, Batch 900] loss: 0.040165758323855695
**STATS for Epoch 15** : 
Average training loss: 0.0022
Average validation loss: 0.0735
Validation Accuracy: 0.9780
Overfitting: 0.0712
[Epoch 16, Batch 100] loss: 0.039203446321189404
[Epoch 16, Batch 200] loss: 0.038315671105519866
[Epoch 16, Batch 300] loss: 0.04155131669191178
[Epoch 16, Batch 400] loss: 0.04993775399052538
[Epoch 16, Batch 500] loss: 0.04636399122653529
[Epoch 16, Batch 600] loss: 0.04224180484074168
[Epoch 16, Batch 700] loss: 0.05400496188900433
[Epoch 16, Batch 800] loss: 0.0442549357865937
[Epoch 16, Batch 900] loss: 0.0427547885972308
**STATS for Epoch 16** : 
Average training loss: 0.0020
Average validation loss: 0.0693
Validation Accuracy: 0.9794
Overfitting: 0.0673
[Epoch 17, Batch 100] loss: 0.035240858582546934
[Epoch 17, Batch 200] loss: 0.04509474231512286
[Epoch 17, Batch 300] loss: 0.047734727533534166
[Epoch 17, Batch 400] loss: 0.043401932519627734
[Epoch 17, Batch 500] loss: 0.04506503354525194
[Epoch 17, Batch 600] loss: 0.036910426065442155
[Epoch 17, Batch 700] loss: 0.02960339180805022
[Epoch 17, Batch 800] loss: 0.047217330434068575
[Epoch 17, Batch 900] loss: 0.05028606787789613
**STATS for Epoch 17** : 
Average training loss: 0.0022
Average validation loss: 0.0661
Validation Accuracy: 0.9802
Overfitting: 0.0640
Best model saved at epoch 17 with validation loss: 0.0661
[Epoch 18, Batch 100] loss: 0.04970734388218261
[Epoch 18, Batch 200] loss: 0.04674659699317999
[Epoch 18, Batch 300] loss: 0.041973109699902124
[Epoch 18, Batch 400] loss: 0.03468768510734663
[Epoch 18, Batch 500] loss: 0.032797476083505896
[Epoch 18, Batch 600] loss: 0.044261371696484274
[Epoch 18, Batch 700] loss: 0.03512900993635412
[Epoch 18, Batch 800] loss: 0.03956959987524897
[Epoch 18, Batch 900] loss: 0.03687685963930562
**STATS for Epoch 18** : 
Average training loss: 0.0018
Average validation loss: 0.0662
Validation Accuracy: 0.9806
Overfitting: 0.0644
[Epoch 19, Batch 100] loss: 0.03596362128853798
[Epoch 19, Batch 200] loss: 0.03229410886298865
[Epoch 19, Batch 300] loss: 0.03336187644628808
[Epoch 19, Batch 400] loss: 0.0492915795231238
[Epoch 19, Batch 500] loss: 0.048169414285803215
[Epoch 19, Batch 600] loss: 0.03181401504261885
[Epoch 19, Batch 700] loss: 0.04180830011551734
[Epoch 19, Batch 800] loss: 0.042215790610061955
[Epoch 19, Batch 900] loss: 0.03015875264100032
**STATS for Epoch 19** : 
Average training loss: 0.0013
Average validation loss: 0.0607
Validation Accuracy: 0.9822
Overfitting: 0.0594
Best model saved at epoch 19 with validation loss: 0.0607
[Epoch 20, Batch 100] loss: 0.03361200260173064
[Epoch 20, Batch 200] loss: 0.031245486571278888
[Epoch 20, Batch 300] loss: 0.035970782757503914
[Epoch 20, Batch 400] loss: 0.03255422056477983
[Epoch 20, Batch 500] loss: 0.0287423907534685
[Epoch 20, Batch 600] loss: 0.03611841671925504
[Epoch 20, Batch 700] loss: 0.039537538092117755
[Epoch 20, Batch 800] loss: 0.03793053806759417
[Epoch 20, Batch 900] loss: 0.037804907661047764
**STATS for Epoch 20** : 
Average training loss: 0.0020
Average validation loss: 0.0604
Validation Accuracy: 0.9823
Overfitting: 0.0584
Best model saved at epoch 20 with validation loss: 0.0604
[Epoch 21, Batch 100] loss: 0.026629386965651064
[Epoch 21, Batch 200] loss: 0.03656663671630667
[Epoch 21, Batch 300] loss: 0.03588528247841168
[Epoch 21, Batch 400] loss: 0.04096410005586222
[Epoch 21, Batch 500] loss: 0.0336334045836702
[Epoch 21, Batch 600] loss: 0.03180900340434164
[Epoch 21, Batch 700] loss: 0.04094070820021443
[Epoch 21, Batch 800] loss: 0.029944715043529867
[Epoch 21, Batch 900] loss: 0.03383082456828561
**STATS for Epoch 21** : 
Average training loss: 0.0018
Average validation loss: 0.0577
Validation Accuracy: 0.9821
Overfitting: 0.0559
Best model saved at epoch 21 with validation loss: 0.0577
[Epoch 22, Batch 100] loss: 0.02372150713286828
[Epoch 22, Batch 200] loss: 0.03846635051886551
[Epoch 22, Batch 300] loss: 0.030287694761063903
[Epoch 22, Batch 400] loss: 0.03427669901284389
[Epoch 22, Batch 500] loss: 0.02942075138562359
[Epoch 22, Batch 600] loss: 0.032727790986537005
[Epoch 22, Batch 700] loss: 0.03162036437308416
[Epoch 22, Batch 800] loss: 0.029406566448742524
[Epoch 22, Batch 900] loss: 0.03339021805732045
**STATS for Epoch 22** : 
Average training loss: 0.0016
Average validation loss: 0.0581
Validation Accuracy: 0.9825
Overfitting: 0.0566
[Epoch 23, Batch 100] loss: 0.030588233954622412
[Epoch 23, Batch 200] loss: 0.02920812266296707
[Epoch 23, Batch 300] loss: 0.02651171244273428
[Epoch 23, Batch 400] loss: 0.023795170754310674
[Epoch 23, Batch 500] loss: 0.02786528234835714
[Epoch 23, Batch 600] loss: 0.03636555007178686
[Epoch 23, Batch 700] loss: 0.035395353643107225
[Epoch 23, Batch 800] loss: 0.028071059269132094
[Epoch 23, Batch 900] loss: 0.03610190020641312
**STATS for Epoch 23** : 
Average training loss: 0.0011
Average validation loss: 0.0566
Validation Accuracy: 0.9827
Overfitting: 0.0555
Best model saved at epoch 23 with validation loss: 0.0566
[Epoch 24, Batch 100] loss: 0.030444155414006673
[Epoch 24, Batch 200] loss: 0.03138168542704079
[Epoch 24, Batch 300] loss: 0.03218850053206552
[Epoch 24, Batch 400] loss: 0.024818831323063933
[Epoch 24, Batch 500] loss: 0.029146599891828374
[Epoch 24, Batch 600] loss: 0.02722629404743202
[Epoch 24, Batch 700] loss: 0.035230256815557366
[Epoch 24, Batch 800] loss: 0.02304092088364996
[Epoch 24, Batch 900] loss: 0.028204070401843636
**STATS for Epoch 24** : 
Average training loss: 0.0009
Average validation loss: 0.0537
Validation Accuracy: 0.9841
Overfitting: 0.0527
Best model saved at epoch 24 with validation loss: 0.0537
Fold 2 validation loss: 0.0537
Mean validation loss across all folds for Trial 3 is 0.0601 with trial config:  l1: 192, l2: 128, lr: 0.0005342937261279777, batch_size: 32
[I 2024-11-19 00:30:43,687] Trial 2 finished with value: 0.06005044300869478 and parameters: {'l1': 192, 'l2': 128, 'lr': 0.0005342937261279777, 'batch_size': 32}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 4:
  l1: 256, l2: 224, lr: 6.290644294586152e-05, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3012822318077086
[Epoch 1, Batch 200] loss: 2.2996537041664125
**STATS for Epoch 1** : 
Average training loss: 0.3424
Average validation loss: 2.2979
Validation Accuracy: 0.1299
Overfitting: 1.9556
Best model saved at epoch 1 with validation loss: 2.2979
[Epoch 2, Batch 100] loss: 2.2973611617088316
[Epoch 2, Batch 200] loss: 2.295244755744934
**STATS for Epoch 2** : 
Average training loss: 0.3418
Average validation loss: 2.2938
Validation Accuracy: 0.1471
Overfitting: 1.9520
Best model saved at epoch 2 with validation loss: 2.2938
[Epoch 3, Batch 100] loss: 2.2936494088172914
[Epoch 3, Batch 200] loss: 2.290572028160095
**STATS for Epoch 3** : 
Average training loss: 0.3412
Average validation loss: 2.2895
Validation Accuracy: 0.1789
Overfitting: 1.9484
Best model saved at epoch 3 with validation loss: 2.2895
[Epoch 4, Batch 100] loss: 2.288097786903381
[Epoch 4, Batch 200] loss: 2.287038679122925
**STATS for Epoch 4** : 
Average training loss: 0.3406
Average validation loss: 2.2848
Validation Accuracy: 0.2242
Overfitting: 1.9442
Best model saved at epoch 4 with validation loss: 2.2848
[Epoch 5, Batch 100] loss: 2.2840860724449157
[Epoch 5, Batch 200] loss: 2.2817833495140074
**STATS for Epoch 5** : 
Average training loss: 0.3395
Average validation loss: 2.2795
Validation Accuracy: 0.2756
Overfitting: 1.9401
Best model saved at epoch 5 with validation loss: 2.2795
[Epoch 6, Batch 100] loss: 2.2788812494277955
[Epoch 6, Batch 200] loss: 2.275282597541809
**STATS for Epoch 6** : 
Average training loss: 0.3388
Average validation loss: 2.2735
Validation Accuracy: 0.3140
Overfitting: 1.9347
Best model saved at epoch 6 with validation loss: 2.2735
[Epoch 7, Batch 100] loss: 2.2726380467414855
[Epoch 7, Batch 200] loss: 2.269266746044159
**STATS for Epoch 7** : 
Average training loss: 0.3375
Average validation loss: 2.2664
Validation Accuracy: 0.3400
Overfitting: 1.9289
Best model saved at epoch 7 with validation loss: 2.2664
[Epoch 8, Batch 100] loss: 2.2646825766563414
[Epoch 8, Batch 200] loss: 2.2612310099601745
**STATS for Epoch 8** : 
Average training loss: 0.3366
Average validation loss: 2.2580
Validation Accuracy: 0.3516
Overfitting: 1.9214
Best model saved at epoch 8 with validation loss: 2.2580
[Epoch 9, Batch 100] loss: 2.2562731313705444
[Epoch 9, Batch 200] loss: 2.251951422691345
**STATS for Epoch 9** : 
Average training loss: 0.3347
Average validation loss: 2.2476
Validation Accuracy: 0.3603
Overfitting: 1.9128
Best model saved at epoch 9 with validation loss: 2.2476
[Epoch 10, Batch 100] loss: 2.245368785858154
[Epoch 10, Batch 200] loss: 2.24028028011322
**STATS for Epoch 10** : 
Average training loss: 0.3328
Average validation loss: 2.2346
Validation Accuracy: 0.3668
Overfitting: 1.9018
Best model saved at epoch 10 with validation loss: 2.2346
[Epoch 11, Batch 100] loss: 2.2322557258605955
[Epoch 11, Batch 200] loss: 2.2243393778800966
**STATS for Epoch 11** : 
Average training loss: 0.3306
Average validation loss: 2.2181
Validation Accuracy: 0.3760
Overfitting: 1.8875
Best model saved at epoch 11 with validation loss: 2.2181
[Epoch 12, Batch 100] loss: 2.214124367237091
[Epoch 12, Batch 200] loss: 2.205318338871002
**STATS for Epoch 12** : 
Average training loss: 0.3275
Average validation loss: 2.1965
Validation Accuracy: 0.3903
Overfitting: 1.8689
Best model saved at epoch 12 with validation loss: 2.1965
[Epoch 13, Batch 100] loss: 2.190418875217438
[Epoch 13, Batch 200] loss: 2.180217831134796
**STATS for Epoch 13** : 
Average training loss: 0.3235
Average validation loss: 2.1676
Validation Accuracy: 0.4277
Overfitting: 1.8441
Best model saved at epoch 13 with validation loss: 2.1676
[Epoch 14, Batch 100] loss: 2.1596117877960204
[Epoch 14, Batch 200] loss: 2.1449889087677003
**STATS for Epoch 14** : 
Average training loss: 0.3171
Average validation loss: 2.1270
Validation Accuracy: 0.4890
Overfitting: 1.8098
Best model saved at epoch 14 with validation loss: 2.1270
[Epoch 15, Batch 100] loss: 2.1166815614700316
[Epoch 15, Batch 200] loss: 2.092974233627319
**STATS for Epoch 15** : 
Average training loss: 0.3085
Average validation loss: 2.0677
Validation Accuracy: 0.5572
Overfitting: 1.7592
Best model saved at epoch 15 with validation loss: 2.0677
[Epoch 16, Batch 100] loss: 2.052492125034332
[Epoch 16, Batch 200] loss: 2.0165354692935944
**STATS for Epoch 16** : 
Average training loss: 0.2958
Average validation loss: 1.9794
Validation Accuracy: 0.6257
Overfitting: 1.6836
Best model saved at epoch 16 with validation loss: 1.9794
[Epoch 17, Batch 100] loss: 1.9544051265716553
[Epoch 17, Batch 200] loss: 1.8985672390460968
**STATS for Epoch 17** : 
Average training loss: 0.2779
Average validation loss: 1.8447
Validation Accuracy: 0.6750
Overfitting: 1.5668
Best model saved at epoch 17 with validation loss: 1.8447
[Epoch 18, Batch 100] loss: 1.8117975246906282
[Epoch 18, Batch 200] loss: 1.7252712881565093
**STATS for Epoch 18** : 
Average training loss: 0.2474
Average validation loss: 1.6475
Validation Accuracy: 0.7104
Overfitting: 1.4001
Best model saved at epoch 18 with validation loss: 1.6475
[Epoch 19, Batch 100] loss: 1.6024093651771545
[Epoch 19, Batch 200] loss: 1.486917552947998
**STATS for Epoch 19** : 
Average training loss: 0.2103
Average validation loss: 1.3959
Validation Accuracy: 0.7377
Overfitting: 1.1856
Best model saved at epoch 19 with validation loss: 1.3959
[Epoch 20, Batch 100] loss: 1.3386430060863495
[Epoch 20, Batch 200] loss: 1.2326101243495942
**STATS for Epoch 20** : 
Average training loss: 0.1735
Average validation loss: 1.1432
Validation Accuracy: 0.7698
Overfitting: 0.9697
Best model saved at epoch 20 with validation loss: 1.1432
[Epoch 21, Batch 100] loss: 1.0950939631462098
[Epoch 21, Batch 200] loss: 1.012756906747818
**STATS for Epoch 21** : 
Average training loss: 0.1425
Average validation loss: 0.9429
Validation Accuracy: 0.7878
Overfitting: 0.8004
Best model saved at epoch 21 with validation loss: 0.9429
[Epoch 22, Batch 100] loss: 0.9125840950012207
[Epoch 22, Batch 200] loss: 0.8511973994970322
**STATS for Epoch 22** : 
Average training loss: 0.1218
Average validation loss: 0.8055
Validation Accuracy: 0.8019
Overfitting: 0.6836
Best model saved at epoch 22 with validation loss: 0.8055
[Epoch 23, Batch 100] loss: 0.7876040548086166
[Epoch 23, Batch 200] loss: 0.740083082318306
**STATS for Epoch 23** : 
Average training loss: 0.1082
Average validation loss: 0.7103
Validation Accuracy: 0.8170
Overfitting: 0.6021
Best model saved at epoch 23 with validation loss: 0.7103
[Epoch 24, Batch 100] loss: 0.703930150270462
[Epoch 24, Batch 200] loss: 0.6662927317619324
**STATS for Epoch 24** : 
Average training loss: 0.0949
Average validation loss: 0.6422
Validation Accuracy: 0.8281
Overfitting: 0.5473
Best model saved at epoch 24 with validation loss: 0.6422
Fold 1 validation loss: 0.6422
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.3053492879867554
[Epoch 1, Batch 200] loss: 2.303086905479431
**STATS for Epoch 1** : 
Average training loss: 0.3429
Average validation loss: 2.3016
Validation Accuracy: 0.0977
Overfitting: 1.9587
Best model saved at epoch 1 with validation loss: 2.3016
[Epoch 2, Batch 100] loss: 2.3009209036827087
[Epoch 2, Batch 200] loss: 2.298627047538757
**STATS for Epoch 2** : 
Average training loss: 0.3423
Average validation loss: 2.2973
Validation Accuracy: 0.1014
Overfitting: 1.9550
Best model saved at epoch 2 with validation loss: 2.2973
[Epoch 3, Batch 100] loss: 2.2967349076271057
[Epoch 3, Batch 200] loss: 2.2943291068077087
**STATS for Epoch 3** : 
Average training loss: 0.3416
Average validation loss: 2.2931
Validation Accuracy: 0.1063
Overfitting: 1.9515
Best model saved at epoch 3 with validation loss: 2.2931
[Epoch 4, Batch 100] loss: 2.292147123813629
[Epoch 4, Batch 200] loss: 2.2905917501449586
**STATS for Epoch 4** : 
Average training loss: 0.3409
Average validation loss: 2.2888
Validation Accuracy: 0.1204
Overfitting: 1.9479
Best model saved at epoch 4 with validation loss: 2.2888
[Epoch 5, Batch 100] loss: 2.2879726696014404
[Epoch 5, Batch 200] loss: 2.2856265330314636
**STATS for Epoch 5** : 
Average training loss: 0.3404
Average validation loss: 2.2843
Validation Accuracy: 0.1458
Overfitting: 1.9439
Best model saved at epoch 5 with validation loss: 2.2843
[Epoch 6, Batch 100] loss: 2.283017642498016
[Epoch 6, Batch 200] loss: 2.2814279103279116
**STATS for Epoch 6** : 
Average training loss: 0.3396
Average validation loss: 2.2793
Validation Accuracy: 0.1856
Overfitting: 1.9397
Best model saved at epoch 6 with validation loss: 2.2793
[Epoch 7, Batch 100] loss: 2.2778155827522277
[Epoch 7, Batch 200] loss: 2.275985822677612
**STATS for Epoch 7** : 
Average training loss: 0.3387
Average validation loss: 2.2736
Validation Accuracy: 0.2361
Overfitting: 1.9349
Best model saved at epoch 7 with validation loss: 2.2736
[Epoch 8, Batch 100] loss: 2.2722493052482604
[Epoch 8, Batch 200] loss: 2.269245889186859
**STATS for Epoch 8** : 
Average training loss: 0.3378
Average validation loss: 2.2668
Validation Accuracy: 0.2796
Overfitting: 1.9291
Best model saved at epoch 8 with validation loss: 2.2668
[Epoch 9, Batch 100] loss: 2.265178151130676
[Epoch 9, Batch 200] loss: 2.2620122170448305
**STATS for Epoch 9** : 
Average training loss: 0.3364
Average validation loss: 2.2586
Validation Accuracy: 0.3104
Overfitting: 1.9222
Best model saved at epoch 9 with validation loss: 2.2586
[Epoch 10, Batch 100] loss: 2.2562495470046997
[Epoch 10, Batch 200] loss: 2.252443964481354
**STATS for Epoch 10** : 
Average training loss: 0.3350
Average validation loss: 2.2481
Validation Accuracy: 0.3342
Overfitting: 1.9131
Best model saved at epoch 10 with validation loss: 2.2481
[Epoch 11, Batch 100] loss: 2.245419986248016
[Epoch 11, Batch 200] loss: 2.2409589195251467
**STATS for Epoch 11** : 
Average training loss: 0.3326
Average validation loss: 2.2348
Validation Accuracy: 0.3532
Overfitting: 1.9022
Best model saved at epoch 11 with validation loss: 2.2348
[Epoch 12, Batch 100] loss: 2.2305787706375124
[Epoch 12, Batch 200] loss: 2.22496661901474
**STATS for Epoch 12** : 
Average training loss: 0.3304
Average validation loss: 2.2173
Validation Accuracy: 0.3750
Overfitting: 1.8869
Best model saved at epoch 12 with validation loss: 2.2173
[Epoch 13, Batch 100] loss: 2.21362774848938
[Epoch 13, Batch 200] loss: 2.201989471912384
**STATS for Epoch 13** : 
Average training loss: 0.3271
Average validation loss: 2.1939
Validation Accuracy: 0.4066
Overfitting: 1.8668
Best model saved at epoch 13 with validation loss: 2.1939
[Epoch 14, Batch 100] loss: 2.1883895921707155
[Epoch 14, Batch 200] loss: 2.174258234500885
**STATS for Epoch 14** : 
Average training loss: 0.3222
Average validation loss: 2.1621
Validation Accuracy: 0.4581
Overfitting: 1.8399
Best model saved at epoch 14 with validation loss: 2.1621
[Epoch 15, Batch 100] loss: 2.1540840578079226
[Epoch 15, Batch 200] loss: 2.1352796936035157
**STATS for Epoch 15** : 
Average training loss: 0.3156
Average validation loss: 2.1174
Validation Accuracy: 0.5297
Overfitting: 1.8018
Best model saved at epoch 15 with validation loss: 2.1174
[Epoch 16, Batch 100] loss: 2.102872734069824
[Epoch 16, Batch 200] loss: 2.081962411403656
**STATS for Epoch 16** : 
Average training loss: 0.3059
Average validation loss: 2.0522
Validation Accuracy: 0.6099
Overfitting: 1.7462
Best model saved at epoch 16 with validation loss: 2.0522
[Epoch 17, Batch 100] loss: 2.0323488020896914
[Epoch 17, Batch 200] loss: 1.9951923239231109
**STATS for Epoch 17** : 
Average training loss: 0.2924
Average validation loss: 1.9540
Validation Accuracy: 0.6646
Overfitting: 1.6616
Best model saved at epoch 17 with validation loss: 1.9540
[Epoch 18, Batch 100] loss: 1.924819403886795
[Epoch 18, Batch 200] loss: 1.866250445842743
**STATS for Epoch 18** : 
Average training loss: 0.2725
Average validation loss: 1.8080
Validation Accuracy: 0.6975
Overfitting: 1.5355
Best model saved at epoch 18 with validation loss: 1.8080
[Epoch 19, Batch 100] loss: 1.7693568253517151
[Epoch 19, Batch 200] loss: 1.6819070720672606
**STATS for Epoch 19** : 
Average training loss: 0.2413
Average validation loss: 1.6006
Validation Accuracy: 0.7155
Overfitting: 1.3593
Best model saved at epoch 19 with validation loss: 1.6006
[Epoch 20, Batch 100] loss: 1.5550814855098725
[Epoch 20, Batch 200] loss: 1.4377730333805083
**STATS for Epoch 20** : 
Average training loss: 0.2023
Average validation loss: 1.3445
Validation Accuracy: 0.7442
Overfitting: 1.1422
Best model saved at epoch 20 with validation loss: 1.3445
[Epoch 21, Batch 100] loss: 1.2817199289798737
[Epoch 21, Batch 200] loss: 1.1843210935592652
**STATS for Epoch 21** : 
Average training loss: 0.1666
Average validation loss: 1.0907
Validation Accuracy: 0.7769
Overfitting: 0.9241
Best model saved at epoch 21 with validation loss: 1.0907
[Epoch 22, Batch 100] loss: 1.0519876724481583
[Epoch 22, Batch 200] loss: 0.9495252513885498
**STATS for Epoch 22** : 
Average training loss: 0.1348
Average validation loss: 0.8917
Validation Accuracy: 0.7977
Overfitting: 0.7569
Best model saved at epoch 22 with validation loss: 0.8917
[Epoch 23, Batch 100] loss: 0.863055345416069
[Epoch 23, Batch 200] loss: 0.7933165001869201
**STATS for Epoch 23** : 
Average training loss: 0.1135
Average validation loss: 0.7546
Validation Accuracy: 0.8174
Overfitting: 0.6411
Best model saved at epoch 23 with validation loss: 0.7546
[Epoch 24, Batch 100] loss: 0.7315142756700516
[Epoch 24, Batch 200] loss: 0.6952784663438797
**STATS for Epoch 24** : 
Average training loss: 0.0968
Average validation loss: 0.6633
Validation Accuracy: 0.8292
Overfitting: 0.5665
Best model saved at epoch 24 with validation loss: 0.6633
Fold 2 validation loss: 0.6633
Mean validation loss across all folds for Trial 4 is 0.6528 with trial config:  l1: 256, l2: 224, lr: 6.290644294586152e-05, batch_size: 128
[I 2024-11-19 00:39:24,146] Trial 3 finished with value: 0.6527514528720937 and parameters: {'l1': 256, 'l2': 224, 'lr': 6.290644294586152e-05, 'batch_size': 128}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 5:
  l1: 64, l2: 64, lr: 0.07286653737491042, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.155742756128311
[Epoch 1, Batch 200] loss: 2.208294153213501
[Epoch 1, Batch 300] loss: 1.8635315120220184
[Epoch 1, Batch 400] loss: 2.0514229130744934
[Epoch 1, Batch 500] loss: 2.0649502861499784
[Epoch 1, Batch 600] loss: 2.0105121111869813
[Epoch 1, Batch 700] loss: 1.9554451203346253
[Epoch 1, Batch 800] loss: 1.8415414142608642
[Epoch 1, Batch 900] loss: 1.8150711250305176
[Epoch 1, Batch 1000] loss: 1.891516033411026
[Epoch 1, Batch 1100] loss: 2.1381865894794463
[Epoch 1, Batch 1200] loss: 2.3123703455924987
[Epoch 1, Batch 1300] loss: 2.316391956806183
[Epoch 1, Batch 1400] loss: 2.311741976737976
[Epoch 1, Batch 1500] loss: 2.3134749960899352
[Epoch 1, Batch 1600] loss: 2.3135998106002806
[Epoch 1, Batch 1700] loss: 2.3161441707611083
[Epoch 1, Batch 1800] loss: 2.307311215400696
**STATS for Epoch 1** : 
Average training loss: 0.0923
Average validation loss: 2.3088
Validation Accuracy: 0.1122
Overfitting: 2.2165
Best model saved at epoch 1 with validation loss: 2.3088
[Epoch 2, Batch 100] loss: 2.3114160823822023
[Epoch 2, Batch 200] loss: 2.3123131513595583
[Epoch 2, Batch 300] loss: 2.3104401326179502
[Epoch 2, Batch 400] loss: 2.3104394602775575
[Epoch 2, Batch 500] loss: 2.314255154132843
[Epoch 2, Batch 600] loss: 2.3119216752052307
[Epoch 2, Batch 700] loss: 2.309418332576752
[Epoch 2, Batch 800] loss: 2.3077613639831545
[Epoch 2, Batch 900] loss: 2.3108766627311708
[Epoch 2, Batch 1000] loss: 2.3106582736968995
[Epoch 2, Batch 1100] loss: 2.313791584968567
[Epoch 2, Batch 1200] loss: 2.308830955028534
[Epoch 2, Batch 1300] loss: 2.3152938580513
[Epoch 2, Batch 1400] loss: 2.3101815462112425
[Epoch 2, Batch 1500] loss: 2.3115110921859743
[Epoch 2, Batch 1600] loss: 2.30881422996521
[Epoch 2, Batch 1700] loss: 2.3112248539924622
[Epoch 2, Batch 1800] loss: 2.3112083506584167
**STATS for Epoch 2** : 
Average training loss: 0.0925
Average validation loss: 2.3073
Validation Accuracy: 0.1007
Overfitting: 2.2149
Best model saved at epoch 2 with validation loss: 2.3073
[Epoch 3, Batch 100] loss: 2.3115371894836425
[Epoch 3, Batch 200] loss: 2.3106670117378236
[Epoch 3, Batch 300] loss: 2.311985695362091
[Epoch 3, Batch 400] loss: 2.310934624671936
[Epoch 3, Batch 500] loss: 2.3169909071922303
[Epoch 3, Batch 600] loss: 2.312837998867035
[Epoch 3, Batch 700] loss: 2.309279944896698
[Epoch 3, Batch 800] loss: 2.312468490600586
[Epoch 3, Batch 900] loss: 2.3127605676651
[Epoch 3, Batch 1000] loss: 2.309452996253967
[Epoch 3, Batch 1100] loss: 2.309038565158844
[Epoch 3, Batch 1200] loss: 2.311499969959259
[Epoch 3, Batch 1300] loss: 2.305444576740265
[Epoch 3, Batch 1400] loss: 2.3089969992637633
[Epoch 3, Batch 1500] loss: 2.3117451763153074
[Epoch 3, Batch 1600] loss: 2.3141550469398497
[Epoch 3, Batch 1700] loss: 2.3123222398757934
[Epoch 3, Batch 1800] loss: 2.3106738352775573
**STATS for Epoch 3** : 
Average training loss: 0.0924
Average validation loss: 2.3102
Validation Accuracy: 0.1122
Overfitting: 2.2178
[Epoch 4, Batch 100] loss: 2.314541893005371
[Epoch 4, Batch 200] loss: 2.315138499736786
[Epoch 4, Batch 300] loss: 2.311403150558472
[Epoch 4, Batch 400] loss: 2.3112048292160035
[Epoch 4, Batch 500] loss: 2.3066881465911866
[Epoch 4, Batch 600] loss: 2.31792414188385
[Epoch 4, Batch 700] loss: 2.3101065135002137
[Epoch 4, Batch 800] loss: 2.3133192324638365
[Epoch 4, Batch 900] loss: 2.308719596862793
[Epoch 4, Batch 1000] loss: 2.3156919574737547
[Epoch 4, Batch 1100] loss: 2.3096394300460816
[Epoch 4, Batch 1200] loss: 2.3127242350578308
[Epoch 4, Batch 1300] loss: 2.310074508190155
[Epoch 4, Batch 1400] loss: 2.311202208995819
[Epoch 4, Batch 1500] loss: 2.3105400729179384
[Epoch 4, Batch 1600] loss: 2.311922855377197
[Epoch 4, Batch 1700] loss: 2.3087132716178895
[Epoch 4, Batch 1800] loss: 2.3067763876914977
**STATS for Epoch 4** : 
Average training loss: 0.0927
Average validation loss: 2.3053
Validation Accuracy: 0.1007
Overfitting: 2.2126
Best model saved at epoch 4 with validation loss: 2.3053
[Epoch 5, Batch 100] loss: 2.309122614860535
[Epoch 5, Batch 200] loss: 2.307116913795471
[Epoch 5, Batch 300] loss: 2.3124938106536863
[Epoch 5, Batch 400] loss: 2.3065015864372254
[Epoch 5, Batch 500] loss: 2.313198642730713
[Epoch 5, Batch 600] loss: 2.315392816066742
[Epoch 5, Batch 700] loss: 2.31154283285141
[Epoch 5, Batch 800] loss: 2.315814163684845
[Epoch 5, Batch 900] loss: 2.310625982284546
[Epoch 5, Batch 1000] loss: 2.3122323536872864
[Epoch 5, Batch 1100] loss: 2.3089021611213685
[Epoch 5, Batch 1200] loss: 2.3129925966262816
[Epoch 5, Batch 1300] loss: 2.3141014409065246
[Epoch 5, Batch 1400] loss: 2.312494122982025
[Epoch 5, Batch 1500] loss: 2.3122634100914
[Epoch 5, Batch 1600] loss: 2.3146615409851075
[Epoch 5, Batch 1700] loss: 2.3127002000808714
[Epoch 5, Batch 1800] loss: 2.3085171699523928
**STATS for Epoch 5** : 
Average training loss: 0.0924
Average validation loss: 2.3188
Validation Accuracy: 0.1122
Overfitting: 2.2264
[Epoch 6, Batch 100] loss: 2.313820254802704
[Epoch 6, Batch 200] loss: 2.3104437613487243
[Epoch 6, Batch 300] loss: 2.3083987736701967
[Epoch 6, Batch 400] loss: 2.3133761382102964
[Epoch 6, Batch 500] loss: 2.3078061723709107
[Epoch 6, Batch 600] loss: 2.3137501001358034
[Epoch 6, Batch 700] loss: 2.3103479099273683
[Epoch 6, Batch 800] loss: 2.313133592605591
[Epoch 6, Batch 900] loss: 2.3130987310409545
[Epoch 6, Batch 1000] loss: 2.3145309019088747
[Epoch 6, Batch 1100] loss: 2.3082158088684084
[Epoch 6, Batch 1200] loss: 2.3138677072525025
[Epoch 6, Batch 1300] loss: 2.309233539104462
[Epoch 6, Batch 1400] loss: 2.3045016860961915
[Epoch 6, Batch 1500] loss: 2.313699152469635
[Epoch 6, Batch 1600] loss: 2.30465106010437
[Epoch 6, Batch 1700] loss: 2.3115874195098876
[Epoch 6, Batch 1800] loss: 2.30838082075119
**STATS for Epoch 6** : 
Average training loss: 0.0926
Average validation loss: 2.3091
Validation Accuracy: 0.1036
Overfitting: 2.2164
[Epoch 7, Batch 100] loss: 2.3085286355018617
[Epoch 7, Batch 200] loss: 2.310759539604187
[Epoch 7, Batch 300] loss: 2.314681951999664
[Epoch 7, Batch 400] loss: 2.311536717414856
[Epoch 7, Batch 500] loss: 2.309803893566132
[Epoch 7, Batch 600] loss: 2.3127712035179138
[Epoch 7, Batch 700] loss: 2.313593029975891
[Epoch 7, Batch 800] loss: 2.3092924904823304
[Epoch 7, Batch 900] loss: 2.309250626564026
[Epoch 7, Batch 1000] loss: 2.306963496208191
[Epoch 7, Batch 1100] loss: 2.309040563106537
[Epoch 7, Batch 1200] loss: 2.314650783538818
[Epoch 7, Batch 1300] loss: 2.312233023643494
[Epoch 7, Batch 1400] loss: 2.30971253156662
[Epoch 7, Batch 1500] loss: 2.314967532157898
[Epoch 7, Batch 1600] loss: 2.3107643795013426
[Epoch 7, Batch 1700] loss: 2.308025119304657
[Epoch 7, Batch 1800] loss: 2.3072237610816955
**STATS for Epoch 7** : 
Average training loss: 0.0924
Average validation loss: 2.3105
Validation Accuracy: 0.1036
Overfitting: 2.2181
[Epoch 8, Batch 100] loss: 2.3120775604248047
[Epoch 8, Batch 200] loss: 2.313315198421478
[Epoch 8, Batch 300] loss: 2.3071902108192446
[Epoch 8, Batch 400] loss: 2.309955930709839
[Epoch 8, Batch 500] loss: 2.305170338153839
[Epoch 8, Batch 600] loss: 2.313155128955841
[Epoch 8, Batch 700] loss: 2.3120370936393737
[Epoch 8, Batch 800] loss: 2.311452066898346
[Epoch 8, Batch 900] loss: 2.3118605828285217
[Epoch 8, Batch 1000] loss: 2.3160050320625305
[Epoch 8, Batch 1100] loss: 2.310517363548279
[Epoch 8, Batch 1200] loss: 2.3067666339874267
[Epoch 8, Batch 1300] loss: 2.3175342416763307
[Epoch 8, Batch 1400] loss: 2.3127960562705994
[Epoch 8, Batch 1500] loss: 2.3108139777183534
[Epoch 8, Batch 1600] loss: 2.311951096057892
[Epoch 8, Batch 1700] loss: 2.3114673471450806
[Epoch 8, Batch 1800] loss: 2.316566200256348
**STATS for Epoch 8** : 
Average training loss: 0.0926
Average validation loss: 2.3059
Validation Accuracy: 0.0982
Overfitting: 2.2133
[Epoch 9, Batch 100] loss: 2.310708673000336
[Epoch 9, Batch 200] loss: 2.3050105381011963
[Epoch 9, Batch 300] loss: 2.3130694103240965
[Epoch 9, Batch 400] loss: 2.3131514811515808
[Epoch 9, Batch 500] loss: 2.310563440322876
[Epoch 9, Batch 600] loss: 2.314707181453705
[Epoch 9, Batch 700] loss: 2.310956590175629
[Epoch 9, Batch 800] loss: 2.3120560169219972
[Epoch 9, Batch 900] loss: 2.311014437675476
[Epoch 9, Batch 1000] loss: 2.3093212985992433
[Epoch 9, Batch 1100] loss: 2.310745701789856
[Epoch 9, Batch 1200] loss: 2.3094707489013673
[Epoch 9, Batch 1300] loss: 2.3111323952674865
[Epoch 9, Batch 1400] loss: 2.3155165100097657
[Epoch 9, Batch 1500] loss: 2.3155643153190613
[Epoch 9, Batch 1600] loss: 2.3072369265556336
[Epoch 9, Batch 1700] loss: 2.3064264035224915
[Epoch 9, Batch 1800] loss: 2.310681612491608
**STATS for Epoch 9** : 
Average training loss: 0.0926
Average validation loss: 2.3108
Validation Accuracy: 0.1122
Overfitting: 2.2182
[Epoch 10, Batch 100] loss: 2.3089795660972596
[Epoch 10, Batch 200] loss: 2.3153855419158935
[Epoch 10, Batch 300] loss: 2.3127671551704405
[Epoch 10, Batch 400] loss: 2.3101246786117553
[Epoch 10, Batch 500] loss: 2.306815264225006
[Epoch 10, Batch 600] loss: 2.3094885993003844
[Epoch 10, Batch 700] loss: 2.3127225065231323
[Epoch 10, Batch 800] loss: 2.306960289478302
[Epoch 10, Batch 900] loss: 2.309705832004547
[Epoch 10, Batch 1000] loss: 2.3145091414451597
[Epoch 10, Batch 1100] loss: 2.3077733159065246
[Epoch 10, Batch 1200] loss: 2.3086993384361265
[Epoch 10, Batch 1300] loss: 2.3123987102508545
[Epoch 10, Batch 1400] loss: 2.3132219171524047
[Epoch 10, Batch 1500] loss: 2.311810386180878
[Epoch 10, Batch 1600] loss: 2.3161192202568053
[Epoch 10, Batch 1700] loss: 2.3097621107101443
[Epoch 10, Batch 1800] loss: 2.307889657020569
**STATS for Epoch 10** : 
Average training loss: 0.0924
Average validation loss: 2.3135
Validation Accuracy: 0.0986
Overfitting: 2.2210
[Epoch 11, Batch 100] loss: 2.312260916233063
[Epoch 11, Batch 200] loss: 2.311142189502716
[Epoch 11, Batch 300] loss: 2.306293487548828
[Epoch 11, Batch 400] loss: 2.309255518913269
[Epoch 11, Batch 500] loss: 2.3103366470336915
[Epoch 11, Batch 600] loss: 2.3152979373931886
[Epoch 11, Batch 700] loss: 2.3133952951431276
[Epoch 11, Batch 800] loss: 2.310330381393433
[Epoch 11, Batch 900] loss: 2.315845205783844
[Epoch 11, Batch 1000] loss: 2.3101176524162295
[Epoch 11, Batch 1100] loss: 2.3009300422668457
[Epoch 11, Batch 1200] loss: 2.305398869514465
[Epoch 11, Batch 1300] loss: 2.3123474407196043
[Epoch 11, Batch 1400] loss: 2.3153457021713257
[Epoch 11, Batch 1500] loss: 2.308156259059906
[Epoch 11, Batch 1600] loss: 2.314484872817993
[Epoch 11, Batch 1700] loss: 2.311005072593689
[Epoch 11, Batch 1800] loss: 2.3095956659317016
**STATS for Epoch 11** : 
Average training loss: 0.0923
Average validation loss: 2.3120
Validation Accuracy: 0.1036
Overfitting: 2.2197
[Epoch 12, Batch 100] loss: 2.310038273334503
[Epoch 12, Batch 200] loss: 2.3105026292800903
[Epoch 12, Batch 300] loss: 2.318212351799011
[Epoch 12, Batch 400] loss: 2.311741418838501
[Epoch 12, Batch 500] loss: 2.3108990502357485
[Epoch 12, Batch 600] loss: 2.3132707834243775
[Epoch 12, Batch 700] loss: 2.3113755917549135
[Epoch 12, Batch 800] loss: 2.311008675098419
[Epoch 12, Batch 900] loss: 2.30944664478302
[Epoch 12, Batch 1000] loss: 2.316787505149841
[Epoch 12, Batch 1100] loss: 2.3087775182723997
[Epoch 12, Batch 1200] loss: 2.309777841567993
[Epoch 12, Batch 1300] loss: 2.307135524749756
[Epoch 12, Batch 1400] loss: 2.31054794549942
[Epoch 12, Batch 1500] loss: 2.3125665640830992
[Epoch 12, Batch 1600] loss: 2.315156433582306
[Epoch 12, Batch 1700] loss: 2.313107597827911
[Epoch 12, Batch 1800] loss: 2.312465314865112
**STATS for Epoch 12** : 
Average training loss: 0.0925
Average validation loss: 2.3079
Validation Accuracy: 0.1122
Overfitting: 2.2154
[Epoch 13, Batch 100] loss: 2.311559498310089
[Epoch 13, Batch 200] loss: 2.311714241504669
[Epoch 13, Batch 300] loss: 2.3112288308143616
[Epoch 13, Batch 400] loss: 2.308286581039429
[Epoch 13, Batch 500] loss: 2.306190094947815
[Epoch 13, Batch 600] loss: 2.308166708946228
[Epoch 13, Batch 700] loss: 2.3116568112373352
[Epoch 13, Batch 800] loss: 2.307764389514923
[Epoch 13, Batch 900] loss: 2.314640214443207
[Epoch 13, Batch 1000] loss: 2.3098501777648925
[Epoch 13, Batch 1100] loss: 2.3118749928474425
[Epoch 13, Batch 1200] loss: 2.309199001789093
[Epoch 13, Batch 1300] loss: 2.3103626418113707
[Epoch 13, Batch 1400] loss: 2.3126579093933106
[Epoch 13, Batch 1500] loss: 2.3146976256370544
[Epoch 13, Batch 1600] loss: 2.3135606694221496
[Epoch 13, Batch 1700] loss: 2.3138200426101685
[Epoch 13, Batch 1800] loss: 2.3087331533432005
**STATS for Epoch 13** : 
Average training loss: 0.0924
Average validation loss: 2.3042
Validation Accuracy: 0.1036
Overfitting: 2.2118
Best model saved at epoch 13 with validation loss: 2.3042
[Epoch 14, Batch 100] loss: 2.3115930938720703
[Epoch 14, Batch 200] loss: 2.3098046255111693
[Epoch 14, Batch 300] loss: 2.3131181168556214
[Epoch 14, Batch 400] loss: 2.3107452845573424
[Epoch 14, Batch 500] loss: 2.3185941433906554
[Epoch 14, Batch 600] loss: 2.3159924030303953
[Epoch 14, Batch 700] loss: 2.3137069725990296
[Epoch 14, Batch 800] loss: 2.311721820831299
[Epoch 14, Batch 900] loss: 2.3100739550590514
[Epoch 14, Batch 1000] loss: 2.31250479221344
[Epoch 14, Batch 1100] loss: 2.313784158229828
[Epoch 14, Batch 1200] loss: 2.3163086867332456
[Epoch 14, Batch 1300] loss: 2.3080881786346437
[Epoch 14, Batch 1400] loss: 2.312982141971588
[Epoch 14, Batch 1500] loss: 2.311133964061737
[Epoch 14, Batch 1600] loss: 2.3104251265525817
[Epoch 14, Batch 1700] loss: 2.3146802234649657
[Epoch 14, Batch 1800] loss: 2.3114044785499575
**STATS for Epoch 14** : 
Average training loss: 0.0925
Average validation loss: 2.3038
Validation Accuracy: 0.1122
Overfitting: 2.2113
Best model saved at epoch 14 with validation loss: 2.3038
[Epoch 15, Batch 100] loss: 2.3098655843734743
[Epoch 15, Batch 200] loss: 2.3154303932189944
[Epoch 15, Batch 300] loss: 2.311302516460419
[Epoch 15, Batch 400] loss: 2.304577162265778
[Epoch 15, Batch 500] loss: 2.31231463432312
[Epoch 15, Batch 600] loss: 2.3081257796287535
[Epoch 15, Batch 700] loss: 2.3119151282310484
[Epoch 15, Batch 800] loss: 2.309837071895599
[Epoch 15, Batch 900] loss: 2.3159351682662965
[Epoch 15, Batch 1000] loss: 2.310919318199158
[Epoch 15, Batch 1100] loss: 2.312751317024231
[Epoch 15, Batch 1200] loss: 2.312559039592743
[Epoch 15, Batch 1300] loss: 2.3098550963401796
[Epoch 15, Batch 1400] loss: 2.310867350101471
[Epoch 15, Batch 1500] loss: 2.308078019618988
[Epoch 15, Batch 1600] loss: 2.3127832508087156
[Epoch 15, Batch 1700] loss: 2.311102657318115
[Epoch 15, Batch 1800] loss: 2.3110052871704103
**STATS for Epoch 15** : 
Average training loss: 0.0921
Average validation loss: 2.3139
Validation Accuracy: 0.0982
Overfitting: 2.2218
[Epoch 16, Batch 100] loss: 2.312625572681427
[Epoch 16, Batch 200] loss: 2.3136672043800353
[Epoch 16, Batch 300] loss: 2.311305000782013
[Epoch 16, Batch 400] loss: 2.31050422668457
[Epoch 16, Batch 500] loss: 2.310672655105591
[Epoch 16, Batch 600] loss: 2.310135152339935
[Epoch 16, Batch 700] loss: 2.303238506317139
[Epoch 16, Batch 800] loss: 2.31494948387146
[Epoch 16, Batch 900] loss: 2.306652445793152
[Epoch 16, Batch 1000] loss: 2.312497079372406
[Epoch 16, Batch 1100] loss: 2.3098481607437136
[Epoch 16, Batch 1200] loss: 2.3103901290893556
[Epoch 16, Batch 1300] loss: 2.314565258026123
[Epoch 16, Batch 1400] loss: 2.3077119302749636
[Epoch 16, Batch 1500] loss: 2.313631982803345
[Epoch 16, Batch 1600] loss: 2.313796253204346
[Epoch 16, Batch 1700] loss: 2.3113395500183107
[Epoch 16, Batch 1800] loss: 2.3113894867897034
**STATS for Epoch 16** : 
Average training loss: 0.0927
Average validation loss: 2.3054
Validation Accuracy: 0.1122
Overfitting: 2.2127
[Epoch 17, Batch 100] loss: 2.306700506210327
[Epoch 17, Batch 200] loss: 2.3140094971656797
[Epoch 17, Batch 300] loss: 2.3172098326683046
[Epoch 17, Batch 400] loss: 2.3126619172096254
[Epoch 17, Batch 500] loss: 2.3159242630004884
[Epoch 17, Batch 600] loss: 2.3049665570259092
[Epoch 17, Batch 700] loss: 2.3107177233695984
[Epoch 17, Batch 800] loss: 2.3087734746932984
[Epoch 17, Batch 900] loss: 2.3110448718070984
[Epoch 17, Batch 1000] loss: 2.308724660873413
[Epoch 17, Batch 1100] loss: 2.312742121219635
[Epoch 17, Batch 1200] loss: 2.312348895072937
[Epoch 17, Batch 1300] loss: 2.3128043746948244
[Epoch 17, Batch 1400] loss: 2.3156108593940736
[Epoch 17, Batch 1500] loss: 2.3139861106872557
[Epoch 17, Batch 1600] loss: 2.31085045337677
[Epoch 17, Batch 1700] loss: 2.311304349899292
[Epoch 17, Batch 1800] loss: 2.3089644289016724
**STATS for Epoch 17** : 
Average training loss: 0.0924
Average validation loss: 2.3068
Validation Accuracy: 0.0987
Overfitting: 2.2145
[Epoch 18, Batch 100] loss: 2.3117139506340028
[Epoch 18, Batch 200] loss: 2.312856526374817
[Epoch 18, Batch 300] loss: 2.3111744713783264
[Epoch 18, Batch 400] loss: 2.3123000931739806
[Epoch 18, Batch 500] loss: 2.307705261707306
[Epoch 18, Batch 600] loss: 2.306606323719025
[Epoch 18, Batch 700] loss: 2.3142520642280577
[Epoch 18, Batch 800] loss: 2.311317162513733
[Epoch 18, Batch 900] loss: 2.314104509353638
[Epoch 18, Batch 1000] loss: 2.3078042578697207
[Epoch 18, Batch 1100] loss: 2.3135830664634707
[Epoch 18, Batch 1200] loss: 2.310398530960083
[Epoch 18, Batch 1300] loss: 2.3124688720703124
[Epoch 18, Batch 1400] loss: 2.3100007152557374
[Epoch 18, Batch 1500] loss: 2.309204306602478
[Epoch 18, Batch 1600] loss: 2.3140975069999694
[Epoch 18, Batch 1700] loss: 2.3168084359169008
[Epoch 18, Batch 1800] loss: 2.306218407154083
**STATS for Epoch 18** : 
Average training loss: 0.0926
Average validation loss: 2.3094
Validation Accuracy: 0.1036
Overfitting: 2.2169
[Epoch 19, Batch 100] loss: 2.317325656414032
[Epoch 19, Batch 200] loss: 2.3120528435707093
[Epoch 19, Batch 300] loss: 2.3148195242881773
[Epoch 19, Batch 400] loss: 2.309419183731079
[Epoch 19, Batch 500] loss: 2.315100166797638
[Epoch 19, Batch 600] loss: 2.3100447964668276
[Epoch 19, Batch 700] loss: 2.3107958245277405
[Epoch 19, Batch 800] loss: 2.312238087654114
[Epoch 19, Batch 900] loss: 2.3115645384788515
[Epoch 19, Batch 1000] loss: 2.3092747807502745
[Epoch 19, Batch 1100] loss: 2.311418869495392
[Epoch 19, Batch 1200] loss: 2.3094613432884215
[Epoch 19, Batch 1300] loss: 2.3111909294128417
[Epoch 19, Batch 1400] loss: 2.3133852219581605
[Epoch 19, Batch 1500] loss: 2.3146449089050294
[Epoch 19, Batch 1600] loss: 2.3064677810668943
[Epoch 19, Batch 1700] loss: 2.312438154220581
[Epoch 19, Batch 1800] loss: 2.3127716636657714
**STATS for Epoch 19** : 
Average training loss: 0.0925
Average validation loss: 2.3080
Validation Accuracy: 0.1122
Overfitting: 2.2156
[Epoch 20, Batch 100] loss: 2.3118093943595888
[Epoch 20, Batch 200] loss: 2.311202354431152
[Epoch 20, Batch 300] loss: 2.306144380569458
[Epoch 20, Batch 400] loss: 2.3097622752189637
[Epoch 20, Batch 500] loss: 2.3077967739105225
[Epoch 20, Batch 600] loss: 2.3136684846878053
[Epoch 20, Batch 700] loss: 2.3155288910865783
[Epoch 20, Batch 800] loss: 2.3139333319664
[Epoch 20, Batch 900] loss: 2.311029863357544
[Epoch 20, Batch 1000] loss: 2.3097749376296997
[Epoch 20, Batch 1100] loss: 2.3104955649375913
[Epoch 20, Batch 1200] loss: 2.3138719987869263
[Epoch 20, Batch 1300] loss: 2.3181031060218813
[Epoch 20, Batch 1400] loss: 2.3115397119522094
[Epoch 20, Batch 1500] loss: 2.311422028541565
[Epoch 20, Batch 1600] loss: 2.3160594487190247
[Epoch 20, Batch 1700] loss: 2.315693256855011
[Epoch 20, Batch 1800] loss: 2.3114273858070375
**STATS for Epoch 20** : 
Average training loss: 0.0925
Average validation loss: 2.3204
Validation Accuracy: 0.0982
Overfitting: 2.2279
[Epoch 21, Batch 100] loss: 2.308876430988312
[Epoch 21, Batch 200] loss: 2.311409876346588
[Epoch 21, Batch 300] loss: 2.309751489162445
[Epoch 21, Batch 400] loss: 2.3108844447135923
[Epoch 21, Batch 500] loss: 2.313086757659912
[Epoch 21, Batch 600] loss: 2.312625911235809
[Epoch 21, Batch 700] loss: 2.3103077697753904
[Epoch 21, Batch 800] loss: 2.313043143749237
[Epoch 21, Batch 900] loss: 2.307675292491913
[Epoch 21, Batch 1000] loss: 2.308737525939941
[Epoch 21, Batch 1100] loss: 2.310727608203888
[Epoch 21, Batch 1200] loss: 2.313956561088562
[Epoch 21, Batch 1300] loss: 2.3106539845466614
[Epoch 21, Batch 1400] loss: 2.3122178292274476
[Epoch 21, Batch 1500] loss: 2.3074545001983644
[Epoch 21, Batch 1600] loss: 2.3111829280853273
[Epoch 21, Batch 1700] loss: 2.3133944296836852
[Epoch 21, Batch 1800] loss: 2.307837302684784
**STATS for Epoch 21** : 
Average training loss: 0.0927
Average validation loss: 2.3093
Validation Accuracy: 0.0998
Overfitting: 2.2166
[Epoch 22, Batch 100] loss: 2.3090894746780397
[Epoch 22, Batch 200] loss: 2.3129881906509397
[Epoch 22, Batch 300] loss: 2.3109963822364805
[Epoch 22, Batch 400] loss: 2.3134997606277468
[Epoch 22, Batch 500] loss: 2.3135998034477234
[Epoch 22, Batch 600] loss: 2.311444797515869
[Epoch 22, Batch 700] loss: 2.3158610129356383
[Epoch 22, Batch 800] loss: 2.31548410654068
[Epoch 22, Batch 900] loss: 2.312025442123413
[Epoch 22, Batch 1000] loss: 2.3101531291007995
[Epoch 22, Batch 1100] loss: 2.3131216955184937
[Epoch 22, Batch 1200] loss: 2.3058223724365234
[Epoch 22, Batch 1300] loss: 2.3145796990394594
[Epoch 22, Batch 1400] loss: 2.3124360609054566
[Epoch 22, Batch 1500] loss: 2.3110636043548585
[Epoch 22, Batch 1600] loss: 2.3055169105529787
[Epoch 22, Batch 1700] loss: 2.309783682823181
[Epoch 22, Batch 1800] loss: 2.3122268652915956
**STATS for Epoch 22** : 
Average training loss: 0.0923
Average validation loss: 2.3085
Validation Accuracy: 0.1036
Overfitting: 2.2162
[Epoch 23, Batch 100] loss: 2.31089275598526
[Epoch 23, Batch 200] loss: 2.306636703014374
[Epoch 23, Batch 300] loss: 2.307722647190094
[Epoch 23, Batch 400] loss: 2.315407247543335
[Epoch 23, Batch 500] loss: 2.3169201898574827
[Epoch 23, Batch 600] loss: 2.307270052433014
[Epoch 23, Batch 700] loss: 2.311411347389221
[Epoch 23, Batch 800] loss: 2.313308770656586
[Epoch 23, Batch 900] loss: 2.308519604206085
[Epoch 23, Batch 1000] loss: 2.314404227733612
[Epoch 23, Batch 1100] loss: 2.30736168384552
[Epoch 23, Batch 1200] loss: 2.3021192169189453
[Epoch 23, Batch 1300] loss: 2.3114867353439332
[Epoch 23, Batch 1400] loss: 2.310359015464783
[Epoch 23, Batch 1500] loss: 2.3117579579353333
[Epoch 23, Batch 1600] loss: 2.3089686608314515
[Epoch 23, Batch 1700] loss: 2.3118068838119505
[Epoch 23, Batch 1800] loss: 2.309319932460785
**STATS for Epoch 23** : 
Average training loss: 0.0925
Average validation loss: 2.3146
Validation Accuracy: 0.1007
Overfitting: 2.2221
[Epoch 24, Batch 100] loss: 2.3121032333374023
[Epoch 24, Batch 200] loss: 2.308808495998383
[Epoch 24, Batch 300] loss: 2.3188723349571227
[Epoch 24, Batch 400] loss: 2.308702368736267
[Epoch 24, Batch 500] loss: 2.3117191576957703
[Epoch 24, Batch 600] loss: 2.312328634262085
[Epoch 24, Batch 700] loss: 2.3118569016456605
[Epoch 24, Batch 800] loss: 2.3097460412979127
[Epoch 24, Batch 900] loss: 2.3097954297065737
[Epoch 24, Batch 1000] loss: 2.312108016014099
[Epoch 24, Batch 1100] loss: 2.3111004614830017
[Epoch 24, Batch 1200] loss: 2.3140717196464538
[Epoch 24, Batch 1300] loss: 2.3108969855308534
[Epoch 24, Batch 1400] loss: 2.311329388618469
[Epoch 24, Batch 1500] loss: 2.3112878942489625
[Epoch 24, Batch 1600] loss: 2.3138889360427854
[Epoch 24, Batch 1700] loss: 2.3122253370285035
[Epoch 24, Batch 1800] loss: 2.310314989089966
**STATS for Epoch 24** : 
Average training loss: 0.0924
Average validation loss: 2.3101
Validation Accuracy: 0.1036
Overfitting: 2.2177
Fold 1 validation loss: 2.3101
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.844437183737755
[Epoch 1, Batch 200] loss: 1.8175823664665223
[Epoch 1, Batch 300] loss: 1.7706404721736908
[Epoch 1, Batch 400] loss: 2.300023443698883
[Epoch 1, Batch 500] loss: 2.276892546415329
[Epoch 1, Batch 600] loss: 2.311805081367493
[Epoch 1, Batch 700] loss: 2.315784659385681
[Epoch 1, Batch 800] loss: 2.311969699859619
[Epoch 1, Batch 900] loss: 2.3103704714775084
[Epoch 1, Batch 1000] loss: 2.309413442611694
[Epoch 1, Batch 1100] loss: 2.3110555028915405
[Epoch 1, Batch 1200] loss: 2.3134376001358032
[Epoch 1, Batch 1300] loss: 2.314500775337219
[Epoch 1, Batch 1400] loss: 2.3137532901763915
[Epoch 1, Batch 1500] loss: 2.310665054321289
[Epoch 1, Batch 1600] loss: 2.3093148827552796
[Epoch 1, Batch 1700] loss: 2.3125433826446535
[Epoch 1, Batch 1800] loss: 2.3102394938468933
**STATS for Epoch 1** : 
Average training loss: 0.0924
Average validation loss: 2.3046
Validation Accuracy: 0.1126
Overfitting: 2.2122
Best model saved at epoch 1 with validation loss: 2.3046
[Epoch 2, Batch 100] loss: 2.309154396057129
[Epoch 2, Batch 200] loss: 2.310602779388428
[Epoch 2, Batch 300] loss: 2.309171190261841
[Epoch 2, Batch 400] loss: 2.310278775691986
[Epoch 2, Batch 500] loss: 2.3132926774024964
[Epoch 2, Batch 600] loss: 2.311802625656128
[Epoch 2, Batch 700] loss: 2.3142947912216187
[Epoch 2, Batch 800] loss: 2.3096186971664427
[Epoch 2, Batch 900] loss: 2.3152477717399598
[Epoch 2, Batch 1000] loss: 2.3091192936897276
[Epoch 2, Batch 1100] loss: 2.310546817779541
[Epoch 2, Batch 1200] loss: 2.312210030555725
[Epoch 2, Batch 1300] loss: 2.3135708236694335
[Epoch 2, Batch 1400] loss: 2.3105819821357727
[Epoch 2, Batch 1500] loss: 2.3123745942115783
[Epoch 2, Batch 1600] loss: 2.3127874326705933
[Epoch 2, Batch 1700] loss: 2.314769322872162
[Epoch 2, Batch 1800] loss: 2.312018132209778
**STATS for Epoch 2** : 
Average training loss: 0.0926
Average validation loss: 2.3090
Validation Accuracy: 0.1052
Overfitting: 2.2164
[Epoch 3, Batch 100] loss: 2.3111089515686034
[Epoch 3, Batch 200] loss: 2.3128474879264833
[Epoch 3, Batch 300] loss: 2.312950429916382
[Epoch 3, Batch 400] loss: 2.312127525806427
[Epoch 3, Batch 500] loss: 2.308052513599396
[Epoch 3, Batch 600] loss: 2.310425672531128
[Epoch 3, Batch 700] loss: 2.3111938714981077
[Epoch 3, Batch 800] loss: 2.3174496722221374
[Epoch 3, Batch 900] loss: 2.3147150707244872
[Epoch 3, Batch 1000] loss: 2.3089392805099487
[Epoch 3, Batch 1100] loss: 2.3065285801887514
[Epoch 3, Batch 1200] loss: 2.313486337661743
[Epoch 3, Batch 1300] loss: 2.309196093082428
[Epoch 3, Batch 1400] loss: 2.312630708217621
[Epoch 3, Batch 1500] loss: 2.3098922204971313
[Epoch 3, Batch 1600] loss: 2.3125162982940672
[Epoch 3, Batch 1700] loss: 2.3158883237838745
[Epoch 3, Batch 1800] loss: 2.310330810546875
**STATS for Epoch 3** : 
Average training loss: 0.0927
Average validation loss: 2.3146
Validation Accuracy: 0.1052
Overfitting: 2.2219
[Epoch 4, Batch 100] loss: 2.312800705432892
[Epoch 4, Batch 200] loss: 2.310052065849304
[Epoch 4, Batch 300] loss: 2.3107329034805297
[Epoch 4, Batch 400] loss: 2.3121137738227846
[Epoch 4, Batch 500] loss: 2.310804536342621
[Epoch 4, Batch 600] loss: 2.309556369781494
[Epoch 4, Batch 700] loss: 2.3123661494255066
[Epoch 4, Batch 800] loss: 2.3098131275177
[Epoch 4, Batch 900] loss: 2.311922698020935
[Epoch 4, Batch 1000] loss: 2.313351244926453
[Epoch 4, Batch 1100] loss: 2.3095255517959594
[Epoch 4, Batch 1200] loss: 2.3132303977012634
[Epoch 4, Batch 1300] loss: 2.3102009987831114
[Epoch 4, Batch 1400] loss: 2.307439079284668
[Epoch 4, Batch 1500] loss: 2.3146149158477782
[Epoch 4, Batch 1600] loss: 2.3155295181274416
[Epoch 4, Batch 1700] loss: 2.3078655314445498
[Epoch 4, Batch 1800] loss: 2.310544440746307
**STATS for Epoch 4** : 
Average training loss: 0.0924
Average validation loss: 2.3161
Validation Accuracy: 0.1126
Overfitting: 2.2238
[Epoch 5, Batch 100] loss: 2.3094498753547668
[Epoch 5, Batch 200] loss: 2.3113002228736876
[Epoch 5, Batch 300] loss: 2.311279320716858
[Epoch 5, Batch 400] loss: 2.314065809249878
[Epoch 5, Batch 500] loss: 2.3156491255760194
[Epoch 5, Batch 600] loss: 2.3095371460914613
[Epoch 5, Batch 700] loss: 2.3158982038497924
[Epoch 5, Batch 800] loss: 2.312582244873047
[Epoch 5, Batch 900] loss: 2.3102242398262023
[Epoch 5, Batch 1000] loss: 2.314014115333557
[Epoch 5, Batch 1100] loss: 2.314950125217438
[Epoch 5, Batch 1200] loss: 2.3118295812606813
[Epoch 5, Batch 1300] loss: 2.3070821738243104
[Epoch 5, Batch 1400] loss: 2.309169373512268
[Epoch 5, Batch 1500] loss: 2.313313431739807
[Epoch 5, Batch 1600] loss: 2.3138619923591612
[Epoch 5, Batch 1700] loss: 2.306951506137848
[Epoch 5, Batch 1800] loss: 2.3106546926498415
**STATS for Epoch 5** : 
Average training loss: 0.0924
Average validation loss: 2.3066
Validation Accuracy: 0.0903
Overfitting: 2.2142
[Epoch 6, Batch 100] loss: 2.31635035276413
[Epoch 6, Batch 200] loss: 2.3106279253959654
[Epoch 6, Batch 300] loss: 2.312657241821289
[Epoch 6, Batch 400] loss: 2.312667922973633
[Epoch 6, Batch 500] loss: 2.3071750235557555
[Epoch 6, Batch 600] loss: 2.3114186263084413
[Epoch 6, Batch 700] loss: 2.3113668179512024
[Epoch 6, Batch 800] loss: 2.308783972263336
[Epoch 6, Batch 900] loss: 2.313704319000244
[Epoch 6, Batch 1000] loss: 2.313782892227173
[Epoch 6, Batch 1100] loss: 2.314648971557617
[Epoch 6, Batch 1200] loss: 2.312373640537262
[Epoch 6, Batch 1300] loss: 2.314277381896973
[Epoch 6, Batch 1400] loss: 2.3123504018783567
[Epoch 6, Batch 1500] loss: 2.3086572217941286
[Epoch 6, Batch 1600] loss: 2.3095684695243834
[Epoch 6, Batch 1700] loss: 2.3134339380264284
[Epoch 6, Batch 1800] loss: 2.3112511038780212
**STATS for Epoch 6** : 
Average training loss: 0.0924
Average validation loss: 2.3180
Validation Accuracy: 0.0976
Overfitting: 2.2257
[Epoch 7, Batch 100] loss: 2.313514175415039
[Epoch 7, Batch 200] loss: 2.315076804161072
[Epoch 7, Batch 300] loss: 2.312355284690857
[Epoch 7, Batch 400] loss: 2.3125546097755434
[Epoch 7, Batch 500] loss: 2.311206057071686
[Epoch 7, Batch 600] loss: 2.305278763771057
[Epoch 7, Batch 700] loss: 2.3121985936164857
[Epoch 7, Batch 800] loss: 2.3107849025726317
[Epoch 7, Batch 900] loss: 2.314400243759155
[Epoch 7, Batch 1000] loss: 2.31117636680603
[Epoch 7, Batch 1100] loss: 2.3124563980102537
[Epoch 7, Batch 1200] loss: 2.312397062778473
[Epoch 7, Batch 1300] loss: 2.3099702262878417
[Epoch 7, Batch 1400] loss: 2.3132106971740725
[Epoch 7, Batch 1500] loss: 2.309144146442413
[Epoch 7, Batch 1600] loss: 2.307647089958191
[Epoch 7, Batch 1700] loss: 2.314123854637146
[Epoch 7, Batch 1800] loss: 2.3088163900375367
**STATS for Epoch 7** : 
Average training loss: 0.0925
Average validation loss: 2.3114
Validation Accuracy: 0.0964
Overfitting: 2.2189
[Epoch 8, Batch 100] loss: 2.3072138810157776
[Epoch 8, Batch 200] loss: 2.3132532024383545
[Epoch 8, Batch 300] loss: 2.311586422920227
[Epoch 8, Batch 400] loss: 2.3141054034233095
[Epoch 8, Batch 500] loss: 2.3037478947639465
[Epoch 8, Batch 600] loss: 2.311248867511749
[Epoch 8, Batch 700] loss: 2.3110904335975646
[Epoch 8, Batch 800] loss: 2.3142400932312013
[Epoch 8, Batch 900] loss: 2.3110714769363403
[Epoch 8, Batch 1000] loss: 2.313659815788269
[Epoch 8, Batch 1100] loss: 2.3149071621894834
[Epoch 8, Batch 1200] loss: 2.311976201534271
[Epoch 8, Batch 1300] loss: 2.315267474651337
[Epoch 8, Batch 1400] loss: 2.308785147666931
[Epoch 8, Batch 1500] loss: 2.3102861261367797
[Epoch 8, Batch 1600] loss: 2.3114752411842345
[Epoch 8, Batch 1700] loss: 2.311559593677521
[Epoch 8, Batch 1800] loss: 2.307464108467102
**STATS for Epoch 8** : 
Average training loss: 0.0924
Average validation loss: 2.3073
Validation Accuracy: 0.1000
Overfitting: 2.2149
[Epoch 9, Batch 100] loss: 2.3132909965515136
[Epoch 9, Batch 200] loss: 2.310712790489197
[Epoch 9, Batch 300] loss: 2.3116363739967345
[Epoch 9, Batch 400] loss: 2.3129802250862124
[Epoch 9, Batch 500] loss: 2.3097062945365905
[Epoch 9, Batch 600] loss: 2.315035285949707
[Epoch 9, Batch 700] loss: 2.31385333776474
[Epoch 9, Batch 800] loss: 2.30353178024292
[Epoch 9, Batch 900] loss: 2.3100442934036254
[Epoch 9, Batch 1000] loss: 2.3156057667732237
[Epoch 9, Batch 1100] loss: 2.3078175616264343
[Epoch 9, Batch 1200] loss: 2.3107040333747864
[Epoch 9, Batch 1300] loss: 2.3111462020874023
[Epoch 9, Batch 1400] loss: 2.309430778026581
[Epoch 9, Batch 1500] loss: 2.3120492362976073
[Epoch 9, Batch 1600] loss: 2.3080301690101623
[Epoch 9, Batch 1700] loss: 2.3077104592323305
[Epoch 9, Batch 1800] loss: 2.3145507264137266
**STATS for Epoch 9** : 
Average training loss: 0.0924
Average validation loss: 2.3154
Validation Accuracy: 0.1126
Overfitting: 2.2229
[Epoch 10, Batch 100] loss: 2.3117466807365417
[Epoch 10, Batch 200] loss: 2.311793565750122
[Epoch 10, Batch 300] loss: 2.3148828840255735
[Epoch 10, Batch 400] loss: 2.308399128913879
[Epoch 10, Batch 500] loss: 2.314104473590851
[Epoch 10, Batch 600] loss: 2.3103033256530763
[Epoch 10, Batch 700] loss: 2.315409095287323
[Epoch 10, Batch 800] loss: 2.31708615064621
[Epoch 10, Batch 900] loss: 2.3098541688919068
[Epoch 10, Batch 1000] loss: 2.315828790664673
[Epoch 10, Batch 1100] loss: 2.311641733646393
[Epoch 10, Batch 1200] loss: 2.310612678527832
[Epoch 10, Batch 1300] loss: 2.3109832906723025
[Epoch 10, Batch 1400] loss: 2.3121524691581725
[Epoch 10, Batch 1500] loss: 2.3124888062477114
[Epoch 10, Batch 1600] loss: 2.31199369430542
[Epoch 10, Batch 1700] loss: 2.3111922216415404
[Epoch 10, Batch 1800] loss: 2.3066565418243408
**STATS for Epoch 10** : 
Average training loss: 0.0926
Average validation loss: 2.3051
Validation Accuracy: 0.1000
Overfitting: 2.2125
[Epoch 11, Batch 100] loss: 2.314745261669159
[Epoch 11, Batch 200] loss: 2.3103464245796204
[Epoch 11, Batch 300] loss: 2.308181490898132
[Epoch 11, Batch 400] loss: 2.316583094596863
[Epoch 11, Batch 500] loss: 2.3120022583007813
[Epoch 11, Batch 600] loss: 2.3091825103759764
[Epoch 11, Batch 700] loss: 2.3111825466156004
[Epoch 11, Batch 800] loss: 2.3092435359954835
[Epoch 11, Batch 900] loss: 2.3140422916412353
[Epoch 11, Batch 1000] loss: 2.3137286853790284
[Epoch 11, Batch 1100] loss: 2.311797912120819
[Epoch 11, Batch 1200] loss: 2.310707759857178
[Epoch 11, Batch 1300] loss: 2.3154596519470214
[Epoch 11, Batch 1400] loss: 2.3065336990356444
[Epoch 11, Batch 1500] loss: 2.312884182929993
[Epoch 11, Batch 1600] loss: 2.312991216182709
[Epoch 11, Batch 1700] loss: 2.3152802324295045
[Epoch 11, Batch 1800] loss: 2.312254178524017
**STATS for Epoch 11** : 
Average training loss: 0.0924
Average validation loss: 2.3115
Validation Accuracy: 0.1037
Overfitting: 2.2191
[Epoch 12, Batch 100] loss: 2.312475724220276
[Epoch 12, Batch 200] loss: 2.3087069439888
[Epoch 12, Batch 300] loss: 2.3159550476074218
[Epoch 12, Batch 400] loss: 2.3094109678268433
[Epoch 12, Batch 500] loss: 2.3131560397148134
[Epoch 12, Batch 600] loss: 2.3097492480278015
[Epoch 12, Batch 700] loss: 2.3111203694343567
[Epoch 12, Batch 800] loss: 2.31407870054245
[Epoch 12, Batch 900] loss: 2.309117157459259
[Epoch 12, Batch 1000] loss: 2.3136737632751463
[Epoch 12, Batch 1100] loss: 2.314577529430389
[Epoch 12, Batch 1200] loss: 2.3138884353637694
[Epoch 12, Batch 1300] loss: 2.3119949197769163
[Epoch 12, Batch 1400] loss: 2.310437858104706
[Epoch 12, Batch 1500] loss: 2.308137559890747
[Epoch 12, Batch 1600] loss: 2.314134964942932
[Epoch 12, Batch 1700] loss: 2.3109075140953066
[Epoch 12, Batch 1800] loss: 2.309765179157257
**STATS for Epoch 12** : 
Average training loss: 0.0924
Average validation loss: 2.3088
Validation Accuracy: 0.1126
Overfitting: 2.2164
[Epoch 13, Batch 100] loss: 2.3110409569740296
[Epoch 13, Batch 200] loss: 2.3101922249794007
[Epoch 13, Batch 300] loss: 2.3154804921150207
[Epoch 13, Batch 400] loss: 2.3103514337539672
[Epoch 13, Batch 500] loss: 2.31159717798233
[Epoch 13, Batch 600] loss: 2.3156300520896913
[Epoch 13, Batch 700] loss: 2.311850919723511
[Epoch 13, Batch 800] loss: 2.3170828652381896
[Epoch 13, Batch 900] loss: 2.311468844413757
[Epoch 13, Batch 1000] loss: 2.3121174216270446
[Epoch 13, Batch 1100] loss: 2.3096787977218627
[Epoch 13, Batch 1200] loss: 2.311427617073059
[Epoch 13, Batch 1300] loss: 2.308661046028137
[Epoch 13, Batch 1400] loss: 2.307784914970398
[Epoch 13, Batch 1500] loss: 2.3128430533409117
[Epoch 13, Batch 1600] loss: 2.3091333603858946
[Epoch 13, Batch 1700] loss: 2.3102290868759154
[Epoch 13, Batch 1800] loss: 2.310233082771301
**STATS for Epoch 13** : 
Average training loss: 0.0926
Average validation loss: 2.3033
Validation Accuracy: 0.1126
Overfitting: 2.2107
Best model saved at epoch 13 with validation loss: 2.3033
[Epoch 14, Batch 100] loss: 2.3130614280700685
[Epoch 14, Batch 200] loss: 2.3142666673660277
[Epoch 14, Batch 300] loss: 2.3127740454673766
[Epoch 14, Batch 400] loss: 2.3144141101837157
[Epoch 14, Batch 500] loss: 2.3111910367012025
[Epoch 14, Batch 600] loss: 2.3110769987106323
[Epoch 14, Batch 700] loss: 2.316773920059204
[Epoch 14, Batch 800] loss: 2.3070289993286135
[Epoch 14, Batch 900] loss: 2.313397343158722
[Epoch 14, Batch 1000] loss: 2.3086737060546874
[Epoch 14, Batch 1100] loss: 2.3126246881484986
[Epoch 14, Batch 1200] loss: 2.310686857700348
[Epoch 14, Batch 1300] loss: 2.307794075012207
[Epoch 14, Batch 1400] loss: 2.317065646648407
[Epoch 14, Batch 1500] loss: 2.3069494104385377
[Epoch 14, Batch 1600] loss: 2.312360942363739
[Epoch 14, Batch 1700] loss: 2.311283507347107
[Epoch 14, Batch 1800] loss: 2.309263296127319
**STATS for Epoch 14** : 
Average training loss: 0.0925
Average validation loss: 2.3188
Validation Accuracy: 0.1052
Overfitting: 2.2264
[Epoch 15, Batch 100] loss: 2.313562970161438
[Epoch 15, Batch 200] loss: 2.3103718876838686
[Epoch 15, Batch 300] loss: 2.3147886753082276
[Epoch 15, Batch 400] loss: 2.314281313419342
[Epoch 15, Batch 500] loss: 2.3102198314666746
[Epoch 15, Batch 600] loss: 2.3117114996910093
[Epoch 15, Batch 700] loss: 2.3119872975349427
[Epoch 15, Batch 800] loss: 2.312845461368561
[Epoch 15, Batch 900] loss: 2.313013174533844
[Epoch 15, Batch 1000] loss: 2.3079971981048586
[Epoch 15, Batch 1100] loss: 2.31568372964859
[Epoch 15, Batch 1200] loss: 2.3116233801841735
[Epoch 15, Batch 1300] loss: 2.3129681587219237
[Epoch 15, Batch 1400] loss: 2.31093638420105
[Epoch 15, Batch 1500] loss: 2.311414909362793
[Epoch 15, Batch 1600] loss: 2.312679102420807
[Epoch 15, Batch 1700] loss: 2.3132574439048765
[Epoch 15, Batch 1800] loss: 2.306340639591217
**STATS for Epoch 15** : 
Average training loss: 0.0926
Average validation loss: 2.3133
Validation Accuracy: 0.0992
Overfitting: 2.2207
[Epoch 16, Batch 100] loss: 2.3141157960891725
[Epoch 16, Batch 200] loss: 2.311342549324036
[Epoch 16, Batch 300] loss: 2.3132810282707212
[Epoch 16, Batch 400] loss: 2.310328462123871
[Epoch 16, Batch 500] loss: 2.3135895681381227
[Epoch 16, Batch 600] loss: 2.311295073032379
[Epoch 16, Batch 700] loss: 2.311954925060272
[Epoch 16, Batch 800] loss: 2.310485146045685
[Epoch 16, Batch 900] loss: 2.3094218397140502
[Epoch 16, Batch 1000] loss: 2.3155347061157228
[Epoch 16, Batch 1100] loss: 2.305934717655182
[Epoch 16, Batch 1200] loss: 2.3080098748207094
[Epoch 16, Batch 1300] loss: 2.3169481134414673
[Epoch 16, Batch 1400] loss: 2.312200200557709
[Epoch 16, Batch 1500] loss: 2.3079147720336914
[Epoch 16, Batch 1600] loss: 2.311720066070557
[Epoch 16, Batch 1700] loss: 2.3145887947082517
[Epoch 16, Batch 1800] loss: 2.313920259475708
**STATS for Epoch 16** : 
Average training loss: 0.0925
Average validation loss: 2.3084
Validation Accuracy: 0.1126
Overfitting: 2.2160
[Epoch 17, Batch 100] loss: 2.3086441683769228
[Epoch 17, Batch 200] loss: 2.309083306789398
[Epoch 17, Batch 300] loss: 2.3112847304344175
[Epoch 17, Batch 400] loss: 2.3148840403556825
[Epoch 17, Batch 500] loss: 2.3124592757225035
[Epoch 17, Batch 600] loss: 2.3105642127990724
[Epoch 17, Batch 700] loss: 2.3098043394088745
[Epoch 17, Batch 800] loss: 2.3138995289802553
[Epoch 17, Batch 900] loss: 2.3112399411201476
[Epoch 17, Batch 1000] loss: 2.309672627449036
[Epoch 17, Batch 1100] loss: 2.3113661932945253
[Epoch 17, Batch 1200] loss: 2.3087687492370605
[Epoch 17, Batch 1300] loss: 2.3106081748008727
[Epoch 17, Batch 1400] loss: 2.312370762825012
[Epoch 17, Batch 1500] loss: 2.3102952909469603
[Epoch 17, Batch 1600] loss: 2.3144093418121336
[Epoch 17, Batch 1700] loss: 2.3057736349105835
[Epoch 17, Batch 1800] loss: 2.3173461818695067
**STATS for Epoch 17** : 
Average training loss: 0.0924
Average validation loss: 2.3058
Validation Accuracy: 0.0976
Overfitting: 2.2133
[Epoch 18, Batch 100] loss: 2.314039785861969
[Epoch 18, Batch 200] loss: 2.3108070373535154
[Epoch 18, Batch 300] loss: 2.310202383995056
[Epoch 18, Batch 400] loss: 2.311160733699799
[Epoch 18, Batch 500] loss: 2.3084817242622377
[Epoch 18, Batch 600] loss: 2.3053820371627807
[Epoch 18, Batch 700] loss: 2.322401342391968
[Epoch 18, Batch 800] loss: 2.30989538192749
[Epoch 18, Batch 900] loss: 2.3108039617538454
[Epoch 18, Batch 1000] loss: 2.310509684085846
[Epoch 18, Batch 1100] loss: 2.3137969946861268
[Epoch 18, Batch 1200] loss: 2.308705282211304
[Epoch 18, Batch 1300] loss: 2.3065612936019897
[Epoch 18, Batch 1400] loss: 2.3135961389541624
[Epoch 18, Batch 1500] loss: 2.313618655204773
[Epoch 18, Batch 1600] loss: 2.3120129895210266
[Epoch 18, Batch 1700] loss: 2.307563290596008
[Epoch 18, Batch 1800] loss: 2.3134206342697143
**STATS for Epoch 18** : 
Average training loss: 0.0921
Average validation loss: 2.3113
Validation Accuracy: 0.1126
Overfitting: 2.2193
[Epoch 19, Batch 100] loss: 2.3080031442642213
[Epoch 19, Batch 200] loss: 2.31122074842453
[Epoch 19, Batch 300] loss: 2.312611389160156
[Epoch 19, Batch 400] loss: 2.3120324087142943
[Epoch 19, Batch 500] loss: 2.3124568819999696
[Epoch 19, Batch 600] loss: 2.3139532303810117
[Epoch 19, Batch 700] loss: 2.307797176837921
[Epoch 19, Batch 800] loss: 2.3130866646766663
[Epoch 19, Batch 900] loss: 2.312346887588501
[Epoch 19, Batch 1000] loss: 2.311189019680023
[Epoch 19, Batch 1100] loss: 2.3108295702934267
[Epoch 19, Batch 1200] loss: 2.307548508644104
[Epoch 19, Batch 1300] loss: 2.3159073209762573
[Epoch 19, Batch 1400] loss: 2.3063852071762083
[Epoch 19, Batch 1500] loss: 2.309540657997131
[Epoch 19, Batch 1600] loss: 2.307383642196655
[Epoch 19, Batch 1700] loss: 2.311155948638916
[Epoch 19, Batch 1800] loss: 2.3124813199043275
**STATS for Epoch 19** : 
Average training loss: 0.0924
Average validation loss: 2.3070
Validation Accuracy: 0.0976
Overfitting: 2.2146
[Epoch 20, Batch 100] loss: 2.311185383796692
[Epoch 20, Batch 200] loss: 2.3105423188209535
[Epoch 20, Batch 300] loss: 2.309427573680878
[Epoch 20, Batch 400] loss: 2.3080375599861145
[Epoch 20, Batch 500] loss: 2.3158113241195677
[Epoch 20, Batch 600] loss: 2.3077721047401427
[Epoch 20, Batch 700] loss: 2.304444229602814
[Epoch 20, Batch 800] loss: 2.313831858634949
[Epoch 20, Batch 900] loss: 2.3139389729499817
[Epoch 20, Batch 1000] loss: 2.3129949283599855
[Epoch 20, Batch 1100] loss: 2.311806082725525
[Epoch 20, Batch 1200] loss: 2.3071996545791627
[Epoch 20, Batch 1300] loss: 2.3090715980529786
[Epoch 20, Batch 1400] loss: 2.316266255378723
[Epoch 20, Batch 1500] loss: 2.3138006258010866
[Epoch 20, Batch 1600] loss: 2.3118231987953184
[Epoch 20, Batch 1700] loss: 2.317579870223999
[Epoch 20, Batch 1800] loss: 2.3064933466911315
**STATS for Epoch 20** : 
Average training loss: 0.0926
Average validation loss: 2.3077
Validation Accuracy: 0.0992
Overfitting: 2.2151
[Epoch 21, Batch 100] loss: 2.3101085567474366
[Epoch 21, Batch 200] loss: 2.3132986783981324
[Epoch 21, Batch 300] loss: 2.313854224681854
[Epoch 21, Batch 400] loss: 2.3107175755500795
[Epoch 21, Batch 500] loss: 2.310654785633087
[Epoch 21, Batch 600] loss: 2.313059809207916
[Epoch 21, Batch 700] loss: 2.3088739800453184
[Epoch 21, Batch 800] loss: 2.3142520499229433
[Epoch 21, Batch 900] loss: 2.311170525550842
[Epoch 21, Batch 1000] loss: 2.314044678211212
[Epoch 21, Batch 1100] loss: 2.310832772254944
[Epoch 21, Batch 1200] loss: 2.311331865787506
[Epoch 21, Batch 1300] loss: 2.3112399435043334
[Epoch 21, Batch 1400] loss: 2.3093367552757265
[Epoch 21, Batch 1500] loss: 2.31039710521698
[Epoch 21, Batch 1600] loss: 2.311620969772339
[Epoch 21, Batch 1700] loss: 2.313358919620514
[Epoch 21, Batch 1800] loss: 2.311213421821594
**STATS for Epoch 21** : 
Average training loss: 0.0924
Average validation loss: 2.3069
Validation Accuracy: 0.1037
Overfitting: 2.2145
[Epoch 22, Batch 100] loss: 2.3134223651885986
[Epoch 22, Batch 200] loss: 2.3101580238342283
[Epoch 22, Batch 300] loss: 2.3082831954956053
[Epoch 22, Batch 400] loss: 2.3163747715950014
[Epoch 22, Batch 500] loss: 2.311855320930481
[Epoch 22, Batch 600] loss: 2.308953251838684
[Epoch 22, Batch 700] loss: 2.3092381668090822
[Epoch 22, Batch 800] loss: 2.309318404197693
[Epoch 22, Batch 900] loss: 2.3107072067260743
[Epoch 22, Batch 1000] loss: 2.3132947063446045
[Epoch 22, Batch 1100] loss: 2.3095274662971494
[Epoch 22, Batch 1200] loss: 2.3103948831558228
[Epoch 22, Batch 1300] loss: 2.310744833946228
[Epoch 22, Batch 1400] loss: 2.307755949497223
[Epoch 22, Batch 1500] loss: 2.3103850364685057
[Epoch 22, Batch 1600] loss: 2.3067936539649962
[Epoch 22, Batch 1700] loss: 2.3098650121688844
[Epoch 22, Batch 1800] loss: 2.311318380832672
**STATS for Epoch 22** : 
Average training loss: 0.0925
Average validation loss: 2.3083
Validation Accuracy: 0.0965
Overfitting: 2.2158
[Epoch 23, Batch 100] loss: 2.3116323828697203
[Epoch 23, Batch 200] loss: 2.311394395828247
[Epoch 23, Batch 300] loss: 2.3163961124420167
[Epoch 23, Batch 400] loss: 2.312666747570038
[Epoch 23, Batch 500] loss: 2.3089156413078307
[Epoch 23, Batch 600] loss: 2.311157877445221
[Epoch 23, Batch 700] loss: 2.3057093954086305
[Epoch 23, Batch 800] loss: 2.3073544025421144
[Epoch 23, Batch 900] loss: 2.3086510634422304
[Epoch 23, Batch 1000] loss: 2.307504885196686
[Epoch 23, Batch 1100] loss: 2.309155559539795
[Epoch 23, Batch 1200] loss: 2.3145678496360778
[Epoch 23, Batch 1300] loss: 2.312885830402374
[Epoch 23, Batch 1400] loss: 2.3121663546562194
[Epoch 23, Batch 1500] loss: 2.313520052433014
[Epoch 23, Batch 1600] loss: 2.31060391664505
[Epoch 23, Batch 1700] loss: 2.3158340787887575
[Epoch 23, Batch 1800] loss: 2.310324854850769
**STATS for Epoch 23** : 
Average training loss: 0.0927
Average validation loss: 2.3124
Validation Accuracy: 0.1126
Overfitting: 2.2197
[Epoch 24, Batch 100] loss: 2.313792362213135
[Epoch 24, Batch 200] loss: 2.308671545982361
[Epoch 24, Batch 300] loss: 2.311823000907898
[Epoch 24, Batch 400] loss: 2.3144656300544737
[Epoch 24, Batch 500] loss: 2.3107731318473816
[Epoch 24, Batch 600] loss: 2.3143372797966
[Epoch 24, Batch 700] loss: 2.312282600402832
[Epoch 24, Batch 800] loss: 2.308429992198944
[Epoch 24, Batch 900] loss: 2.3129444479942323
[Epoch 24, Batch 1000] loss: 2.3095813298225405
[Epoch 24, Batch 1100] loss: 2.31413334608078
[Epoch 24, Batch 1200] loss: 2.3158602809906004
[Epoch 24, Batch 1300] loss: 2.3113519525527955
[Epoch 24, Batch 1400] loss: 2.3145593881607054
[Epoch 24, Batch 1500] loss: 2.3128008818626404
[Epoch 24, Batch 1600] loss: 2.310767912864685
[Epoch 24, Batch 1700] loss: 2.3098562264442446
[Epoch 24, Batch 1800] loss: 2.306707103252411
**STATS for Epoch 24** : 
Average training loss: 0.0924
Average validation loss: 2.3063
Validation Accuracy: 0.1037
Overfitting: 2.2139
Fold 2 validation loss: 2.3063
Mean validation loss across all folds for Trial 5 is 2.3082 with trial config:  l1: 64, l2: 64, lr: 0.07286653737491042, batch_size: 16
[I 2024-11-19 00:51:29,512] Trial 4 finished with value: 2.308191444842021 and parameters: {'l1': 64, 'l2': 64, 'lr': 0.07286653737491042, 'batch_size': 16}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 6:
  l1: 96, l2: 64, lr: 1.3726318898045866e-05, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.301241607666016
[Epoch 1, Batch 200] loss: 2.298575749397278
[Epoch 1, Batch 300] loss: 2.302108552455902
[Epoch 1, Batch 400] loss: 2.3012693095207215
[Epoch 1, Batch 500] loss: 2.302035644054413
[Epoch 1, Batch 600] loss: 2.304095251560211
[Epoch 1, Batch 700] loss: 2.2994738602638245
[Epoch 1, Batch 800] loss: 2.2979328560829164
[Epoch 1, Batch 900] loss: 2.298743636608124
[Epoch 1, Batch 1000] loss: 2.296958029270172
[Epoch 1, Batch 1100] loss: 2.293839831352234
[Epoch 1, Batch 1200] loss: 2.29661550283432
[Epoch 1, Batch 1300] loss: 2.293569722175598
[Epoch 1, Batch 1400] loss: 2.2953436279296877
[Epoch 1, Batch 1500] loss: 2.293262310028076
[Epoch 1, Batch 1600] loss: 2.297651572227478
[Epoch 1, Batch 1700] loss: 2.296593956947327
[Epoch 1, Batch 1800] loss: 2.2918624258041382
**STATS for Epoch 1** : 
Average training loss: 0.0917
Average validation loss: 2.2940
Validation Accuracy: 0.1003
Overfitting: 2.2023
Best model saved at epoch 1 with validation loss: 2.2940
[Epoch 2, Batch 100] loss: 2.293450791835785
[Epoch 2, Batch 200] loss: 2.2936467909812928
[Epoch 2, Batch 300] loss: 2.292540113925934
[Epoch 2, Batch 400] loss: 2.2898887681961058
[Epoch 2, Batch 500] loss: 2.2917058181762697
[Epoch 2, Batch 600] loss: 2.292905237674713
[Epoch 2, Batch 700] loss: 2.2914167618751526
[Epoch 2, Batch 800] loss: 2.2918291211128237
[Epoch 2, Batch 900] loss: 2.288596577644348
[Epoch 2, Batch 1000] loss: 2.2907569575309754
[Epoch 2, Batch 1100] loss: 2.288594272136688
[Epoch 2, Batch 1200] loss: 2.2900997734069826
[Epoch 2, Batch 1300] loss: 2.2877067160606384
[Epoch 2, Batch 1400] loss: 2.286182818412781
[Epoch 2, Batch 1500] loss: 2.2836411356925965
[Epoch 2, Batch 1600] loss: 2.2871101546287536
[Epoch 2, Batch 1700] loss: 2.286161904335022
[Epoch 2, Batch 1800] loss: 2.28231427192688
**STATS for Epoch 2** : 
Average training loss: 0.0913
Average validation loss: 2.2848
Validation Accuracy: 0.1063
Overfitting: 2.1935
Best model saved at epoch 2 with validation loss: 2.2848
[Epoch 3, Batch 100] loss: 2.2860253143310545
[Epoch 3, Batch 200] loss: 2.2854298305511476
[Epoch 3, Batch 300] loss: 2.282290127277374
[Epoch 3, Batch 400] loss: 2.280490744113922
[Epoch 3, Batch 500] loss: 2.281761906147003
[Epoch 3, Batch 600] loss: 2.2799310278892517
[Epoch 3, Batch 700] loss: 2.280014925003052
[Epoch 3, Batch 800] loss: 2.280294737815857
[Epoch 3, Batch 900] loss: 2.2792460680007935
[Epoch 3, Batch 1000] loss: 2.2803525257110597
[Epoch 3, Batch 1100] loss: 2.2793068313598632
[Epoch 3, Batch 1200] loss: 2.278795847892761
[Epoch 3, Batch 1300] loss: 2.276448218822479
[Epoch 3, Batch 1400] loss: 2.2774521684646607
[Epoch 3, Batch 1500] loss: 2.2773585653305055
[Epoch 3, Batch 1600] loss: 2.2739678502082823
[Epoch 3, Batch 1700] loss: 2.2753445529937744
[Epoch 3, Batch 1800] loss: 2.271905846595764
**STATS for Epoch 3** : 
Average training loss: 0.0909
Average validation loss: 2.2733
Validation Accuracy: 0.1423
Overfitting: 2.1824
Best model saved at epoch 3 with validation loss: 2.2733
[Epoch 4, Batch 100] loss: 2.2711466121673585
[Epoch 4, Batch 200] loss: 2.274015727043152
[Epoch 4, Batch 300] loss: 2.2724406361579894
[Epoch 4, Batch 400] loss: 2.26938570022583
[Epoch 4, Batch 500] loss: 2.268851161003113
[Epoch 4, Batch 600] loss: 2.2689722204208373
[Epoch 4, Batch 700] loss: 2.2682331562042237
[Epoch 4, Batch 800] loss: 2.2682932162284852
[Epoch 4, Batch 900] loss: 2.2698200607299803
[Epoch 4, Batch 1000] loss: 2.2660852766036985
[Epoch 4, Batch 1100] loss: 2.2622043228149415
[Epoch 4, Batch 1200] loss: 2.265511474609375
[Epoch 4, Batch 1300] loss: 2.2636876201629637
[Epoch 4, Batch 1400] loss: 2.259214997291565
[Epoch 4, Batch 1500] loss: 2.2625078320503236
[Epoch 4, Batch 1600] loss: 2.260266342163086
[Epoch 4, Batch 1700] loss: 2.2606774091720583
[Epoch 4, Batch 1800] loss: 2.259170072078705
**STATS for Epoch 4** : 
Average training loss: 0.0902
Average validation loss: 2.2575
Validation Accuracy: 0.2987
Overfitting: 2.1672
Best model saved at epoch 4 with validation loss: 2.2575
[Epoch 5, Batch 100] loss: 2.254965043067932
[Epoch 5, Batch 200] loss: 2.257348642349243
[Epoch 5, Batch 300] loss: 2.2558109951019287
[Epoch 5, Batch 400] loss: 2.2577615928649903
[Epoch 5, Batch 500] loss: 2.253102173805237
[Epoch 5, Batch 600] loss: 2.2516452050209046
[Epoch 5, Batch 700] loss: 2.252055265903473
[Epoch 5, Batch 800] loss: 2.2478820300102234
[Epoch 5, Batch 900] loss: 2.2493142604827883
[Epoch 5, Batch 1000] loss: 2.245394582748413
[Epoch 5, Batch 1100] loss: 2.24452122926712
[Epoch 5, Batch 1200] loss: 2.24152752161026
[Epoch 5, Batch 1300] loss: 2.2435204434394835
[Epoch 5, Batch 1400] loss: 2.242700047492981
[Epoch 5, Batch 1500] loss: 2.2397717905044554
[Epoch 5, Batch 1600] loss: 2.23672789812088
[Epoch 5, Batch 1700] loss: 2.2332132053375244
[Epoch 5, Batch 1800] loss: 2.23873393535614
**STATS for Epoch 5** : 
Average training loss: 0.0894
Average validation loss: 2.2337
Validation Accuracy: 0.4089
Overfitting: 2.1443
Best model saved at epoch 5 with validation loss: 2.2337
[Epoch 6, Batch 100] loss: 2.230982391834259
[Epoch 6, Batch 200] loss: 2.229223601818085
[Epoch 6, Batch 300] loss: 2.227383060455322
[Epoch 6, Batch 400] loss: 2.2263801670074463
[Epoch 6, Batch 500] loss: 2.227768557071686
[Epoch 6, Batch 600] loss: 2.226568295955658
[Epoch 6, Batch 700] loss: 2.224233136177063
[Epoch 6, Batch 800] loss: 2.2221448397636414
[Epoch 6, Batch 900] loss: 2.216655533313751
[Epoch 6, Batch 1000] loss: 2.2221064615249633
[Epoch 6, Batch 1100] loss: 2.214023506641388
[Epoch 6, Batch 1200] loss: 2.2148412585258486
[Epoch 6, Batch 1300] loss: 2.212757384777069
[Epoch 6, Batch 1400] loss: 2.2060239815711977
[Epoch 6, Batch 1500] loss: 2.2047981214523316
[Epoch 6, Batch 1600] loss: 2.203529393672943
[Epoch 6, Batch 1700] loss: 2.2022808241844176
[Epoch 6, Batch 1800] loss: 2.197338616847992
**STATS for Epoch 6** : 
Average training loss: 0.0879
Average validation loss: 2.1952
Validation Accuracy: 0.4588
Overfitting: 2.1073
Best model saved at epoch 6 with validation loss: 2.1952
[Epoch 7, Batch 100] loss: 2.1931545829772947
[Epoch 7, Batch 200] loss: 2.191037096977234
[Epoch 7, Batch 300] loss: 2.1905726909637453
[Epoch 7, Batch 400] loss: 2.1887671613693236
[Epoch 7, Batch 500] loss: 2.1799275255203248
[Epoch 7, Batch 600] loss: 2.1838224840164187
[Epoch 7, Batch 700] loss: 2.175964388847351
[Epoch 7, Batch 800] loss: 2.169953100681305
[Epoch 7, Batch 900] loss: 2.1711133098602295
[Epoch 7, Batch 1000] loss: 2.1636708116531373
[Epoch 7, Batch 1100] loss: 2.165312466621399
[Epoch 7, Batch 1200] loss: 2.159333710670471
[Epoch 7, Batch 1300] loss: 2.158243935108185
[Epoch 7, Batch 1400] loss: 2.153794438838959
[Epoch 7, Batch 1500] loss: 2.153942413330078
[Epoch 7, Batch 1600] loss: 2.145500855445862
[Epoch 7, Batch 1700] loss: 2.1371772408485414
[Epoch 7, Batch 1800] loss: 2.1327463173866272
**STATS for Epoch 7** : 
Average training loss: 0.0849
Average validation loss: 2.1284
Validation Accuracy: 0.4787
Overfitting: 2.0434
Best model saved at epoch 7 with validation loss: 2.1284
[Epoch 8, Batch 100] loss: 2.1280000019073486
[Epoch 8, Batch 200] loss: 2.120515375137329
[Epoch 8, Batch 300] loss: 2.1172983193397523
[Epoch 8, Batch 400] loss: 2.114895377159119
[Epoch 8, Batch 500] loss: 2.103299415111542
[Epoch 8, Batch 600] loss: 2.099615426063538
[Epoch 8, Batch 700] loss: 2.1001504492759704
[Epoch 8, Batch 800] loss: 2.0872213566303253
[Epoch 8, Batch 900] loss: 2.0833951556682586
[Epoch 8, Batch 1000] loss: 2.0819650852680205
[Epoch 8, Batch 1100] loss: 2.075841084718704
[Epoch 8, Batch 1200] loss: 2.0554084038734435
[Epoch 8, Batch 1300] loss: 2.059282855987549
[Epoch 8, Batch 1400] loss: 2.0432954478263854
[Epoch 8, Batch 1500] loss: 2.03936891913414
[Epoch 8, Batch 1600] loss: 2.037648092508316
[Epoch 8, Batch 1700] loss: 2.023259803056717
[Epoch 8, Batch 1800] loss: 2.016503289937973
**STATS for Epoch 8** : 
Average training loss: 0.0803
Average validation loss: 2.0056
Validation Accuracy: 0.5225
Overfitting: 1.9253
Best model saved at epoch 8 with validation loss: 2.0056
[Epoch 9, Batch 100] loss: 2.001414394378662
[Epoch 9, Batch 200] loss: 1.9928423321247102
[Epoch 9, Batch 300] loss: 1.987814543247223
[Epoch 9, Batch 400] loss: 1.9718189167976379
[Epoch 9, Batch 500] loss: 1.9693253242969513
[Epoch 9, Batch 600] loss: 1.9672093319892883
[Epoch 9, Batch 700] loss: 1.9456543159484863
[Epoch 9, Batch 800] loss: 1.9332414305210113
[Epoch 9, Batch 900] loss: 1.9178713583946227
[Epoch 9, Batch 1000] loss: 1.9152181184291839
[Epoch 9, Batch 1100] loss: 1.8992288279533387
[Epoch 9, Batch 1200] loss: 1.8935931515693665
[Epoch 9, Batch 1300] loss: 1.8669065868854522
[Epoch 9, Batch 1400] loss: 1.8561477088928222
[Epoch 9, Batch 1500] loss: 1.8468606066703797
[Epoch 9, Batch 1600] loss: 1.8317196309566497
[Epoch 9, Batch 1700] loss: 1.8176552188396453
[Epoch 9, Batch 1800] loss: 1.8057180094718932
**STATS for Epoch 9** : 
Average training loss: 0.0712
Average validation loss: 1.7859
Validation Accuracy: 0.6244
Overfitting: 1.7147
Best model saved at epoch 9 with validation loss: 1.7859
[Epoch 10, Batch 100] loss: 1.7632704961299897
[Epoch 10, Batch 200] loss: 1.7696500432491302
[Epoch 10, Batch 300] loss: 1.7681897974014282
[Epoch 10, Batch 400] loss: 1.7326609086990357
[Epoch 10, Batch 500] loss: 1.7270683610439301
[Epoch 10, Batch 600] loss: 1.683733388185501
[Epoch 10, Batch 700] loss: 1.6881116926670074
[Epoch 10, Batch 800] loss: 1.654061793088913
[Epoch 10, Batch 900] loss: 1.6448012590408325
[Epoch 10, Batch 1000] loss: 1.612746036052704
[Epoch 10, Batch 1100] loss: 1.629558629989624
[Epoch 10, Batch 1200] loss: 1.6217377305030822
[Epoch 10, Batch 1300] loss: 1.5731012940406799
[Epoch 10, Batch 1400] loss: 1.568882554769516
[Epoch 10, Batch 1500] loss: 1.5251986610889434
[Epoch 10, Batch 1600] loss: 1.504225902557373
[Epoch 10, Batch 1700] loss: 1.5245447671413421
[Epoch 10, Batch 1800] loss: 1.4791271471977234
**STATS for Epoch 10** : 
Average training loss: 0.0588
Average validation loss: 1.4568
Validation Accuracy: 0.7030
Overfitting: 1.3980
Best model saved at epoch 10 with validation loss: 1.4568
[Epoch 11, Batch 100] loss: 1.4607679843902588
[Epoch 11, Batch 200] loss: 1.4260545027256013
[Epoch 11, Batch 300] loss: 1.4318781864643098
[Epoch 11, Batch 400] loss: 1.3786705648899078
[Epoch 11, Batch 500] loss: 1.3591725158691406
[Epoch 11, Batch 600] loss: 1.3500677967071533
[Epoch 11, Batch 700] loss: 1.3319770801067352
[Epoch 11, Batch 800] loss: 1.3218752187490463
[Epoch 11, Batch 900] loss: 1.293418643474579
[Epoch 11, Batch 1000] loss: 1.292146527171135
[Epoch 11, Batch 1100] loss: 1.2464248847961426
[Epoch 11, Batch 1200] loss: 1.2488062483072282
[Epoch 11, Batch 1300] loss: 1.2178984361886978
[Epoch 11, Batch 1400] loss: 1.2165783208608627
[Epoch 11, Batch 1500] loss: 1.179157057404518
[Epoch 11, Batch 1600] loss: 1.1680471539497375
[Epoch 11, Batch 1700] loss: 1.1469635307788848
[Epoch 11, Batch 1800] loss: 1.0919115817546845
**STATS for Epoch 11** : 
Average training loss: 0.0442
Average validation loss: 1.1056
Validation Accuracy: 0.7482
Overfitting: 1.0614
Best model saved at epoch 11 with validation loss: 1.1056
[Epoch 12, Batch 100] loss: 1.0840589547157287
[Epoch 12, Batch 200] loss: 1.0646123665571212
[Epoch 12, Batch 300] loss: 1.0703745996952057
[Epoch 12, Batch 400] loss: 1.0453075820207596
[Epoch 12, Batch 500] loss: 1.0200292044878005
[Epoch 12, Batch 600] loss: 1.0285682994127274
[Epoch 12, Batch 700] loss: 0.9878457337617874
[Epoch 12, Batch 800] loss: 0.9971334266662598
[Epoch 12, Batch 900] loss: 0.9715783178806305
[Epoch 12, Batch 1000] loss: 1.002209387421608
[Epoch 12, Batch 1100] loss: 0.9559160208702088
[Epoch 12, Batch 1200] loss: 0.9362702840566635
[Epoch 12, Batch 1300] loss: 0.9245730358362197
[Epoch 12, Batch 1400] loss: 0.9141570395231247
[Epoch 12, Batch 1500] loss: 0.9175439602136612
[Epoch 12, Batch 1600] loss: 0.9031131118535995
[Epoch 12, Batch 1700] loss: 0.9050839215517044
[Epoch 12, Batch 1800] loss: 0.8865399253368378
**STATS for Epoch 12** : 
Average training loss: 0.0352
Average validation loss: 0.8550
Validation Accuracy: 0.7811
Overfitting: 0.8199
Best model saved at epoch 12 with validation loss: 0.8550
[Epoch 13, Batch 100] loss: 0.8508379423618316
[Epoch 13, Batch 200] loss: 0.8483250778913498
[Epoch 13, Batch 300] loss: 0.810999910235405
[Epoch 13, Batch 400] loss: 0.8037431797385216
[Epoch 13, Batch 500] loss: 0.7942843756079674
[Epoch 13, Batch 600] loss: 0.7945389252901077
[Epoch 13, Batch 700] loss: 0.8005115237832069
[Epoch 13, Batch 800] loss: 0.7812463048100472
[Epoch 13, Batch 900] loss: 0.7886488351225853
[Epoch 13, Batch 1000] loss: 0.7648698410391808
[Epoch 13, Batch 1100] loss: 0.7592789927124977
[Epoch 13, Batch 1200] loss: 0.7602634319663047
[Epoch 13, Batch 1300] loss: 0.7458188149333
[Epoch 13, Batch 1400] loss: 0.7723596835136414
[Epoch 13, Batch 1500] loss: 0.7470291715860367
[Epoch 13, Batch 1600] loss: 0.7665201443433761
[Epoch 13, Batch 1700] loss: 0.7067699185013772
[Epoch 13, Batch 1800] loss: 0.7307566818594933
**STATS for Epoch 13** : 
Average training loss: 0.0293
Average validation loss: 0.7011
Validation Accuracy: 0.8098
Overfitting: 0.6718
Best model saved at epoch 13 with validation loss: 0.7011
[Epoch 14, Batch 100] loss: 0.6924832120537758
[Epoch 14, Batch 200] loss: 0.7389289149641991
[Epoch 14, Batch 300] loss: 0.6771362343430519
[Epoch 14, Batch 400] loss: 0.6297256031632423
[Epoch 14, Batch 500] loss: 0.6813252428174019
[Epoch 14, Batch 600] loss: 0.6667279797792435
[Epoch 14, Batch 700] loss: 0.6149282190203667
[Epoch 14, Batch 800] loss: 0.6950541454553604
[Epoch 14, Batch 900] loss: 0.692934563755989
[Epoch 14, Batch 1000] loss: 0.6684636473655701
[Epoch 14, Batch 1100] loss: 0.6568484508991241
[Epoch 14, Batch 1200] loss: 0.6391158160567284
[Epoch 14, Batch 1300] loss: 0.630032989680767
[Epoch 14, Batch 1400] loss: 0.641180171072483
[Epoch 14, Batch 1500] loss: 0.6527183228731155
[Epoch 14, Batch 1600] loss: 0.6291477850079537
[Epoch 14, Batch 1700] loss: 0.6375385400652885
[Epoch 14, Batch 1800] loss: 0.6170572045445443
**STATS for Epoch 14** : 
Average training loss: 0.0236
Average validation loss: 0.6053
Validation Accuracy: 0.8314
Overfitting: 0.5816
Best model saved at epoch 14 with validation loss: 0.6053
[Epoch 15, Batch 100] loss: 0.584851389080286
[Epoch 15, Batch 200] loss: 0.6052661016583443
[Epoch 15, Batch 300] loss: 0.5753517125546932
[Epoch 15, Batch 400] loss: 0.6356109452247619
[Epoch 15, Batch 500] loss: 0.6184306868910789
[Epoch 15, Batch 600] loss: 0.5914298141002655
[Epoch 15, Batch 700] loss: 0.5833129617571831
[Epoch 15, Batch 800] loss: 0.5710260589420796
[Epoch 15, Batch 900] loss: 0.5322195670008659
[Epoch 15, Batch 1000] loss: 0.5969824424386024
[Epoch 15, Batch 1100] loss: 0.5675329811871052
[Epoch 15, Batch 1200] loss: 0.5947991143167018
[Epoch 15, Batch 1300] loss: 0.5702554528415203
[Epoch 15, Batch 1400] loss: 0.5999321523308754
[Epoch 15, Batch 1500] loss: 0.5122922533750534
[Epoch 15, Batch 1600] loss: 0.5564452289044857
[Epoch 15, Batch 1700] loss: 0.5859653426706791
[Epoch 15, Batch 1800] loss: 0.5460565842688083
**STATS for Epoch 15** : 
Average training loss: 0.0214
Average validation loss: 0.5413
Validation Accuracy: 0.8466
Overfitting: 0.5198
Best model saved at epoch 15 with validation loss: 0.5413
[Epoch 16, Batch 100] loss: 0.5471179196238518
[Epoch 16, Batch 200] loss: 0.5449483630061149
[Epoch 16, Batch 300] loss: 0.561647557914257
[Epoch 16, Batch 400] loss: 0.5323696936666965
[Epoch 16, Batch 500] loss: 0.5348542520403862
[Epoch 16, Batch 600] loss: 0.48614601224660875
[Epoch 16, Batch 700] loss: 0.5334103792905808
[Epoch 16, Batch 800] loss: 0.5464961805939674
[Epoch 16, Batch 900] loss: 0.5350470159947872
[Epoch 16, Batch 1000] loss: 0.555146554261446
[Epoch 16, Batch 1100] loss: 0.5398546129465103
[Epoch 16, Batch 1200] loss: 0.5174788130819797
[Epoch 16, Batch 1300] loss: 0.5184114295244217
[Epoch 16, Batch 1400] loss: 0.4968540808558464
[Epoch 16, Batch 1500] loss: 0.46289078682661056
[Epoch 16, Batch 1600] loss: 0.5083783347904682
[Epoch 16, Batch 1700] loss: 0.5298901718854904
[Epoch 16, Batch 1800] loss: 0.5123786832392215
**STATS for Epoch 16** : 
Average training loss: 0.0191
Average validation loss: 0.4952
Validation Accuracy: 0.8577
Overfitting: 0.4761
Best model saved at epoch 16 with validation loss: 0.4952
[Epoch 17, Batch 100] loss: 0.4815701422095299
[Epoch 17, Batch 200] loss: 0.4923134791851044
[Epoch 17, Batch 300] loss: 0.5279119603335858
[Epoch 17, Batch 400] loss: 0.5066642551124096
[Epoch 17, Batch 500] loss: 0.48999042727053166
[Epoch 17, Batch 600] loss: 0.5124868702888489
[Epoch 17, Batch 700] loss: 0.4766493386030197
[Epoch 17, Batch 800] loss: 0.4760960800945759
[Epoch 17, Batch 900] loss: 0.42175265192985534
[Epoch 17, Batch 1000] loss: 0.5102403873205185
[Epoch 17, Batch 1100] loss: 0.49942130386829375
[Epoch 17, Batch 1200] loss: 0.48459446370601655
[Epoch 17, Batch 1300] loss: 0.4904584939777851
[Epoch 17, Batch 1400] loss: 0.4803242637217045
[Epoch 17, Batch 1500] loss: 0.49787579268217086
[Epoch 17, Batch 1600] loss: 0.4466438828408718
[Epoch 17, Batch 1700] loss: 0.45827479667961596
[Epoch 17, Batch 1800] loss: 0.4738531558215618
**STATS for Epoch 17** : 
Average training loss: 0.0179
Average validation loss: 0.4600
Validation Accuracy: 0.8670
Overfitting: 0.4422
Best model saved at epoch 17 with validation loss: 0.4600
[Epoch 18, Batch 100] loss: 0.464461025968194
[Epoch 18, Batch 200] loss: 0.46287274472415446
[Epoch 18, Batch 300] loss: 0.4903393240272999
[Epoch 18, Batch 400] loss: 0.4690145196765661
[Epoch 18, Batch 500] loss: 0.45810298949480055
[Epoch 18, Batch 600] loss: 0.4456002077460289
[Epoch 18, Batch 700] loss: 0.44909788206219675
[Epoch 18, Batch 800] loss: 0.4429096119105816
[Epoch 18, Batch 900] loss: 0.4614464970678091
[Epoch 18, Batch 1000] loss: 0.43442080572247505
[Epoch 18, Batch 1100] loss: 0.42250182673335074
[Epoch 18, Batch 1200] loss: 0.48251596331596375
[Epoch 18, Batch 1300] loss: 0.47459028266370296
[Epoch 18, Batch 1400] loss: 0.4602198126912117
[Epoch 18, Batch 1500] loss: 0.4398560406267643
[Epoch 18, Batch 1600] loss: 0.4609597150981426
[Epoch 18, Batch 1700] loss: 0.40168664887547495
[Epoch 18, Batch 1800] loss: 0.42725926615297793
**STATS for Epoch 18** : 
Average training loss: 0.0176
Average validation loss: 0.4341
Validation Accuracy: 0.8741
Overfitting: 0.4164
Best model saved at epoch 18 with validation loss: 0.4341
[Epoch 19, Batch 100] loss: 0.43504954628646375
[Epoch 19, Batch 200] loss: 0.45151122495532037
[Epoch 19, Batch 300] loss: 0.46225952461361886
[Epoch 19, Batch 400] loss: 0.4306315556168556
[Epoch 19, Batch 500] loss: 0.43954670190811157
[Epoch 19, Batch 600] loss: 0.4135566732287407
[Epoch 19, Batch 700] loss: 0.455857455804944
[Epoch 19, Batch 800] loss: 0.3698189824819565
[Epoch 19, Batch 900] loss: 0.4171404454857111
[Epoch 19, Batch 1000] loss: 0.3892586604505777
[Epoch 19, Batch 1100] loss: 0.42900594756007193
[Epoch 19, Batch 1200] loss: 0.4492154631018639
[Epoch 19, Batch 1300] loss: 0.3992561250925064
[Epoch 19, Batch 1400] loss: 0.41599183857440947
[Epoch 19, Batch 1500] loss: 0.3996349406987429
[Epoch 19, Batch 1600] loss: 0.4430773688852787
[Epoch 19, Batch 1700] loss: 0.4441107516735792
[Epoch 19, Batch 1800] loss: 0.44906175836920736
**STATS for Epoch 19** : 
Average training loss: 0.0175
Average validation loss: 0.4132
Validation Accuracy: 0.8785
Overfitting: 0.3957
Best model saved at epoch 19 with validation loss: 0.4132
[Epoch 20, Batch 100] loss: 0.4086096366122365
[Epoch 20, Batch 200] loss: 0.44406030274927616
[Epoch 20, Batch 300] loss: 0.4283492347598076
[Epoch 20, Batch 400] loss: 0.43042761102318766
[Epoch 20, Batch 500] loss: 0.39289904192090036
[Epoch 20, Batch 600] loss: 0.39745628386735915
[Epoch 20, Batch 700] loss: 0.40450396604835986
[Epoch 20, Batch 800] loss: 0.38583376083523035
[Epoch 20, Batch 900] loss: 0.4124614330381155
[Epoch 20, Batch 1000] loss: 0.4019573146849871
[Epoch 20, Batch 1100] loss: 0.4193065893650055
[Epoch 20, Batch 1200] loss: 0.38531689032912253
[Epoch 20, Batch 1300] loss: 0.42677815064787866
[Epoch 20, Batch 1400] loss: 0.43250763848423956
[Epoch 20, Batch 1500] loss: 0.3806747104972601
[Epoch 20, Batch 1600] loss: 0.3796259807050228
[Epoch 20, Batch 1700] loss: 0.3941986571252346
[Epoch 20, Batch 1800] loss: 0.4225729566812515
**STATS for Epoch 20** : 
Average training loss: 0.0159
Average validation loss: 0.3935
Validation Accuracy: 0.8846
Overfitting: 0.3776
Best model saved at epoch 20 with validation loss: 0.3935
[Epoch 21, Batch 100] loss: 0.38849325977265836
[Epoch 21, Batch 200] loss: 0.38606963232159613
[Epoch 21, Batch 300] loss: 0.42071885347366333
[Epoch 21, Batch 400] loss: 0.3785982770472765
[Epoch 21, Batch 500] loss: 0.4162994593381882
[Epoch 21, Batch 600] loss: 0.3771282333880663
[Epoch 21, Batch 700] loss: 0.43356683149933817
[Epoch 21, Batch 800] loss: 0.39613269656896594
[Epoch 21, Batch 900] loss: 0.37353370640426875
[Epoch 21, Batch 1000] loss: 0.35266284227371214
[Epoch 21, Batch 1100] loss: 0.4239416614919901
[Epoch 21, Batch 1200] loss: 0.3904072526842356
[Epoch 21, Batch 1300] loss: 0.36899089999496937
[Epoch 21, Batch 1400] loss: 0.3818165944516659
[Epoch 21, Batch 1500] loss: 0.3682597509771586
[Epoch 21, Batch 1600] loss: 0.4070175588130951
[Epoch 21, Batch 1700] loss: 0.39937599800527096
[Epoch 21, Batch 1800] loss: 0.38634396757930517
**STATS for Epoch 21** : 
Average training loss: 0.0148
Average validation loss: 0.3791
Validation Accuracy: 0.8881
Overfitting: 0.3643
Best model saved at epoch 21 with validation loss: 0.3791
[Epoch 22, Batch 100] loss: 0.39345950827002524
[Epoch 22, Batch 200] loss: 0.3828356491029263
[Epoch 22, Batch 300] loss: 0.33657830908894537
[Epoch 22, Batch 400] loss: 0.40071292489767074
[Epoch 22, Batch 500] loss: 0.3614305799454451
[Epoch 22, Batch 600] loss: 0.39921502947807314
[Epoch 22, Batch 700] loss: 0.3666359593719244
[Epoch 22, Batch 800] loss: 0.3597660890966654
[Epoch 22, Batch 900] loss: 0.3937812675535679
[Epoch 22, Batch 1000] loss: 0.3645035456866026
[Epoch 22, Batch 1100] loss: 0.3918877973407507
[Epoch 22, Batch 1200] loss: 0.3787627502530813
[Epoch 22, Batch 1300] loss: 0.3664858408272266
[Epoch 22, Batch 1400] loss: 0.400880383476615
[Epoch 22, Batch 1500] loss: 0.38667825251817706
[Epoch 22, Batch 1600] loss: 0.3449570683389902
[Epoch 22, Batch 1700] loss: 0.3556797856837511
[Epoch 22, Batch 1800] loss: 0.39390053987503054
**STATS for Epoch 22** : 
Average training loss: 0.0141
Average validation loss: 0.3655
Validation Accuracy: 0.8921
Overfitting: 0.3515
Best model saved at epoch 22 with validation loss: 0.3655
[Epoch 23, Batch 100] loss: 0.3771162525564432
[Epoch 23, Batch 200] loss: 0.3568051775544882
[Epoch 23, Batch 300] loss: 0.3628342390805483
[Epoch 23, Batch 400] loss: 0.3746673994511366
[Epoch 23, Batch 500] loss: 0.374753454066813
[Epoch 23, Batch 600] loss: 0.36418166659772394
[Epoch 23, Batch 700] loss: 0.34249338053166867
[Epoch 23, Batch 800] loss: 0.34587644595652817
[Epoch 23, Batch 900] loss: 0.38934676300734283
[Epoch 23, Batch 1000] loss: 0.3695450136065483
[Epoch 23, Batch 1100] loss: 0.36733134180307386
[Epoch 23, Batch 1200] loss: 0.3445783639699221
[Epoch 23, Batch 1300] loss: 0.35328512854874133
[Epoch 23, Batch 1400] loss: 0.3807087717205286
[Epoch 23, Batch 1500] loss: 0.3579657684266567
[Epoch 23, Batch 1600] loss: 0.37243469528853895
[Epoch 23, Batch 1700] loss: 0.3528155601769686
[Epoch 23, Batch 1800] loss: 0.3580078322440386
**STATS for Epoch 23** : 
Average training loss: 0.0133
Average validation loss: 0.3523
Validation Accuracy: 0.8953
Overfitting: 0.3389
Best model saved at epoch 23 with validation loss: 0.3523
[Epoch 24, Batch 100] loss: 0.3298314507678151
[Epoch 24, Batch 200] loss: 0.3125827381014824
[Epoch 24, Batch 300] loss: 0.36231274612247943
[Epoch 24, Batch 400] loss: 0.3760243475809693
[Epoch 24, Batch 500] loss: 0.38030279606580736
[Epoch 24, Batch 600] loss: 0.33942459549754855
[Epoch 24, Batch 700] loss: 0.35586773671209815
[Epoch 24, Batch 800] loss: 0.3635583022981882
[Epoch 24, Batch 900] loss: 0.33673703093081714
[Epoch 24, Batch 1000] loss: 0.3309364380687475
[Epoch 24, Batch 1100] loss: 0.3477942482382059
[Epoch 24, Batch 1200] loss: 0.3697058767080307
[Epoch 24, Batch 1300] loss: 0.3292411644756794
[Epoch 24, Batch 1400] loss: 0.3380124753341079
[Epoch 24, Batch 1500] loss: 0.36517462275922297
[Epoch 24, Batch 1600] loss: 0.3723133747279644
[Epoch 24, Batch 1700] loss: 0.3520317278429866
[Epoch 24, Batch 1800] loss: 0.3519940247386694
**STATS for Epoch 24** : 
Average training loss: 0.0136
Average validation loss: 0.3437
Validation Accuracy: 0.8972
Overfitting: 0.3301
Best model saved at epoch 24 with validation loss: 0.3437
Fold 1 validation loss: 0.3437
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.302559838294983
[Epoch 1, Batch 200] loss: 2.3028008365631103
[Epoch 1, Batch 300] loss: 2.3056719946861266
[Epoch 1, Batch 400] loss: 2.3042733478546142
[Epoch 1, Batch 500] loss: 2.3041916418075563
[Epoch 1, Batch 600] loss: 2.305267152786255
[Epoch 1, Batch 700] loss: 2.3032242107391356
[Epoch 1, Batch 800] loss: 2.304633400440216
[Epoch 1, Batch 900] loss: 2.3025153851509095
[Epoch 1, Batch 1000] loss: 2.303065719604492
[Epoch 1, Batch 1100] loss: 2.3031356859207155
[Epoch 1, Batch 1200] loss: 2.3011523056030274
[Epoch 1, Batch 1300] loss: 2.3017124819755552
[Epoch 1, Batch 1400] loss: 2.3036435198783876
[Epoch 1, Batch 1500] loss: 2.3015521025657653
[Epoch 1, Batch 1600] loss: 2.3005932092666628
[Epoch 1, Batch 1700] loss: 2.3029247403144835
[Epoch 1, Batch 1800] loss: 2.302743411064148
**STATS for Epoch 1** : 
Average training loss: 0.0921
Average validation loss: 2.3018
Validation Accuracy: 0.1258
Overfitting: 2.2097
Best model saved at epoch 1 with validation loss: 2.3018
[Epoch 2, Batch 100] loss: 2.2981702709197998
[Epoch 2, Batch 200] loss: 2.303697507381439
[Epoch 2, Batch 300] loss: 2.302294068336487
[Epoch 2, Batch 400] loss: 2.298968071937561
[Epoch 2, Batch 500] loss: 2.30083190202713
[Epoch 2, Batch 600] loss: 2.300945484638214
[Epoch 2, Batch 700] loss: 2.301082034111023
[Epoch 2, Batch 800] loss: 2.30086168050766
[Epoch 2, Batch 900] loss: 2.2989327788352965
[Epoch 2, Batch 1000] loss: 2.3004086422920227
[Epoch 2, Batch 1100] loss: 2.3009500026702883
[Epoch 2, Batch 1200] loss: 2.3017027735710145
[Epoch 2, Batch 1300] loss: 2.3013770532608033
[Epoch 2, Batch 1400] loss: 2.3010784649848937
[Epoch 2, Batch 1500] loss: 2.301962261199951
[Epoch 2, Batch 1600] loss: 2.299382219314575
[Epoch 2, Batch 1700] loss: 2.299832091331482
[Epoch 2, Batch 1800] loss: 2.300810360908508
**STATS for Epoch 2** : 
Average training loss: 0.0920
Average validation loss: 2.2994
Validation Accuracy: 0.1380
Overfitting: 2.2074
Best model saved at epoch 2 with validation loss: 2.2994
[Epoch 3, Batch 100] loss: 2.300957667827606
[Epoch 3, Batch 200] loss: 2.298170123100281
[Epoch 3, Batch 300] loss: 2.301730947494507
[Epoch 3, Batch 400] loss: 2.2991011548042297
[Epoch 3, Batch 500] loss: 2.3002902603149415
[Epoch 3, Batch 600] loss: 2.2983551740646364
[Epoch 3, Batch 700] loss: 2.2986121916770936
[Epoch 3, Batch 800] loss: 2.2982959842681883
[Epoch 3, Batch 900] loss: 2.299143373966217
[Epoch 3, Batch 1000] loss: 2.3005256128311156
[Epoch 3, Batch 1100] loss: 2.2982204866409304
[Epoch 3, Batch 1200] loss: 2.295949296951294
[Epoch 3, Batch 1300] loss: 2.2973250579833984
[Epoch 3, Batch 1400] loss: 2.2980924010276795
[Epoch 3, Batch 1500] loss: 2.295033936500549
[Epoch 3, Batch 1600] loss: 2.2964520692825316
[Epoch 3, Batch 1700] loss: 2.2963258266448974
[Epoch 3, Batch 1800] loss: 2.2961601758003236
**STATS for Epoch 3** : 
Average training loss: 0.0918
Average validation loss: 2.2968
Validation Accuracy: 0.1472
Overfitting: 2.2049
Best model saved at epoch 3 with validation loss: 2.2968
[Epoch 4, Batch 100] loss: 2.2981374955177305
[Epoch 4, Batch 200] loss: 2.296150004863739
[Epoch 4, Batch 300] loss: 2.296324384212494
[Epoch 4, Batch 400] loss: 2.2970120096206665
[Epoch 4, Batch 500] loss: 2.294861116409302
[Epoch 4, Batch 600] loss: 2.2948450684547423
[Epoch 4, Batch 700] loss: 2.295802609920502
[Epoch 4, Batch 800] loss: 2.296084072589874
[Epoch 4, Batch 900] loss: 2.2951986813545227
[Epoch 4, Batch 1000] loss: 2.2966870164871214
[Epoch 4, Batch 1100] loss: 2.296584107875824
[Epoch 4, Batch 1200] loss: 2.2940375638008117
[Epoch 4, Batch 1300] loss: 2.29605304479599
[Epoch 4, Batch 1400] loss: 2.295808835029602
[Epoch 4, Batch 1500] loss: 2.295398750305176
[Epoch 4, Batch 1600] loss: 2.2937639141082764
[Epoch 4, Batch 1700] loss: 2.293905715942383
[Epoch 4, Batch 1800] loss: 2.293037784099579
**STATS for Epoch 4** : 
Average training loss: 0.0917
Average validation loss: 2.2940
Validation Accuracy: 0.1543
Overfitting: 2.2022
Best model saved at epoch 4 with validation loss: 2.2940
[Epoch 5, Batch 100] loss: 2.2955806398391725
[Epoch 5, Batch 200] loss: 2.294524049758911
[Epoch 5, Batch 300] loss: 2.2929399466514586
[Epoch 5, Batch 400] loss: 2.295713331699371
[Epoch 5, Batch 500] loss: 2.2955831241607667
[Epoch 5, Batch 600] loss: 2.2920762205123903
[Epoch 5, Batch 700] loss: 2.292743947505951
[Epoch 5, Batch 800] loss: 2.2925956892967223
[Epoch 5, Batch 900] loss: 2.2904488468170165
[Epoch 5, Batch 1000] loss: 2.293103075027466
[Epoch 5, Batch 1100] loss: 2.292245147228241
[Epoch 5, Batch 1200] loss: 2.294040298461914
[Epoch 5, Batch 1300] loss: 2.2910958194732665
[Epoch 5, Batch 1400] loss: 2.2920913672447205
[Epoch 5, Batch 1500] loss: 2.289084713459015
[Epoch 5, Batch 1600] loss: 2.29026992559433
[Epoch 5, Batch 1700] loss: 2.291887900829315
[Epoch 5, Batch 1800] loss: 2.2917648935317994
**STATS for Epoch 5** : 
Average training loss: 0.0916
Average validation loss: 2.2909
Validation Accuracy: 0.1617
Overfitting: 2.1993
Best model saved at epoch 5 with validation loss: 2.2909
[Epoch 6, Batch 100] loss: 2.289437572956085
[Epoch 6, Batch 200] loss: 2.28832364320755
[Epoch 6, Batch 300] loss: 2.2902838730812074
[Epoch 6, Batch 400] loss: 2.2900330066680907
[Epoch 6, Batch 500] loss: 2.292720015048981
[Epoch 6, Batch 600] loss: 2.291837728023529
[Epoch 6, Batch 700] loss: 2.288325707912445
[Epoch 6, Batch 800] loss: 2.288608555793762
[Epoch 6, Batch 900] loss: 2.288626811504364
[Epoch 6, Batch 1000] loss: 2.2903202605247497
[Epoch 6, Batch 1100] loss: 2.28854368686676
[Epoch 6, Batch 1200] loss: 2.2869661688804626
[Epoch 6, Batch 1300] loss: 2.288500714302063
[Epoch 6, Batch 1400] loss: 2.287696080207825
[Epoch 6, Batch 1500] loss: 2.290032479763031
[Epoch 6, Batch 1600] loss: 2.2893928408622743
[Epoch 6, Batch 1700] loss: 2.2884941625595094
[Epoch 6, Batch 1800] loss: 2.2880147910118103
**STATS for Epoch 6** : 
Average training loss: 0.0915
Average validation loss: 2.2874
Validation Accuracy: 0.1752
Overfitting: 2.1959
Best model saved at epoch 6 with validation loss: 2.2874
[Epoch 7, Batch 100] loss: 2.2881602382659914
[Epoch 7, Batch 200] loss: 2.2889298176765442
[Epoch 7, Batch 300] loss: 2.2883249354362487
[Epoch 7, Batch 400] loss: 2.2852723741531373
[Epoch 7, Batch 500] loss: 2.285408275127411
[Epoch 7, Batch 600] loss: 2.2870791697502137
[Epoch 7, Batch 700] loss: 2.284629843235016
[Epoch 7, Batch 800] loss: 2.2856205534934997
[Epoch 7, Batch 900] loss: 2.2853048253059387
[Epoch 7, Batch 1000] loss: 2.28563036441803
[Epoch 7, Batch 1100] loss: 2.2859695029258726
[Epoch 7, Batch 1200] loss: 2.2830334949493407
[Epoch 7, Batch 1300] loss: 2.284484121799469
[Epoch 7, Batch 1400] loss: 2.284397804737091
[Epoch 7, Batch 1500] loss: 2.2848483180999755
[Epoch 7, Batch 1600] loss: 2.28689023733139
[Epoch 7, Batch 1700] loss: 2.281812150478363
[Epoch 7, Batch 1800] loss: 2.2837204337120056
**STATS for Epoch 7** : 
Average training loss: 0.0913
Average validation loss: 2.2833
Validation Accuracy: 0.1936
Overfitting: 2.1920
Best model saved at epoch 7 with validation loss: 2.2833
[Epoch 8, Batch 100] loss: 2.2840301108360292
[Epoch 8, Batch 200] loss: 2.284922552108765
[Epoch 8, Batch 300] loss: 2.283646032810211
[Epoch 8, Batch 400] loss: 2.281055488586426
[Epoch 8, Batch 500] loss: 2.281055054664612
[Epoch 8, Batch 600] loss: 2.280220670700073
[Epoch 8, Batch 700] loss: 2.281185517311096
[Epoch 8, Batch 800] loss: 2.2792150139808656
[Epoch 8, Batch 900] loss: 2.2831909012794496
[Epoch 8, Batch 1000] loss: 2.2798508739471437
[Epoch 8, Batch 1100] loss: 2.2834316182136534
[Epoch 8, Batch 1200] loss: 2.280544538497925
[Epoch 8, Batch 1300] loss: 2.2792513036727904
[Epoch 8, Batch 1400] loss: 2.2794025111198426
[Epoch 8, Batch 1500] loss: 2.2797769832611086
[Epoch 8, Batch 1600] loss: 2.2788208675384523
[Epoch 8, Batch 1700] loss: 2.276737401485443
[Epoch 8, Batch 1800] loss: 2.279512903690338
**STATS for Epoch 8** : 
Average training loss: 0.0911
Average validation loss: 2.2782
Validation Accuracy: 0.2135
Overfitting: 2.1871
Best model saved at epoch 8 with validation loss: 2.2782
[Epoch 9, Batch 100] loss: 2.277881202697754
[Epoch 9, Batch 200] loss: 2.277793469429016
[Epoch 9, Batch 300] loss: 2.2765028953552244
[Epoch 9, Batch 400] loss: 2.2785575461387633
[Epoch 9, Batch 500] loss: 2.2745163679122924
[Epoch 9, Batch 600] loss: 2.275956428050995
[Epoch 9, Batch 700] loss: 2.277822515964508
[Epoch 9, Batch 800] loss: 2.2762475419044494
[Epoch 9, Batch 900] loss: 2.277373797893524
[Epoch 9, Batch 1000] loss: 2.274630751609802
[Epoch 9, Batch 1100] loss: 2.2731312084198
[Epoch 9, Batch 1200] loss: 2.2754457092285154
[Epoch 9, Batch 1300] loss: 2.2723296809196474
[Epoch 9, Batch 1400] loss: 2.272656545639038
[Epoch 9, Batch 1500] loss: 2.2737594175338747
[Epoch 9, Batch 1600] loss: 2.2721345472335814
[Epoch 9, Batch 1700] loss: 2.274497411251068
[Epoch 9, Batch 1800] loss: 2.273478772640228
**STATS for Epoch 9** : 
Average training loss: 0.0908
Average validation loss: 2.2718
Validation Accuracy: 0.2513
Overfitting: 2.1810
Best model saved at epoch 9 with validation loss: 2.2718
[Epoch 10, Batch 100] loss: 2.2704109382629394
[Epoch 10, Batch 200] loss: 2.269867572784424
[Epoch 10, Batch 300] loss: 2.2710937523841856
[Epoch 10, Batch 400] loss: 2.2698803830146788
[Epoch 10, Batch 500] loss: 2.270319149494171
[Epoch 10, Batch 600] loss: 2.2722076988220214
[Epoch 10, Batch 700] loss: 2.268126723766327
[Epoch 10, Batch 800] loss: 2.269276695251465
[Epoch 10, Batch 900] loss: 2.2685360980033873
[Epoch 10, Batch 1000] loss: 2.266399586200714
[Epoch 10, Batch 1100] loss: 2.2677732610702517
[Epoch 10, Batch 1200] loss: 2.2643838763237
[Epoch 10, Batch 1300] loss: 2.269339933395386
[Epoch 10, Batch 1400] loss: 2.2614890265464784
[Epoch 10, Batch 1500] loss: 2.2659140467643737
[Epoch 10, Batch 1600] loss: 2.2657990789413454
[Epoch 10, Batch 1700] loss: 2.2644997215270997
[Epoch 10, Batch 1800] loss: 2.26453245639801
**STATS for Epoch 10** : 
Average training loss: 0.0905
Average validation loss: 2.2633
Validation Accuracy: 0.3297
Overfitting: 2.1727
Best model saved at epoch 10 with validation loss: 2.2633
[Epoch 11, Batch 100] loss: 2.263087272644043
[Epoch 11, Batch 200] loss: 2.2636227130889894
[Epoch 11, Batch 300] loss: 2.2601496887207033
[Epoch 11, Batch 400] loss: 2.2590426278114317
[Epoch 11, Batch 500] loss: 2.2607604575157167
[Epoch 11, Batch 600] loss: 2.260195581912994
[Epoch 11, Batch 700] loss: 2.258226766586304
[Epoch 11, Batch 800] loss: 2.2603209471702574
[Epoch 11, Batch 900] loss: 2.257439363002777
[Epoch 11, Batch 1000] loss: 2.2578610825538634
[Epoch 11, Batch 1100] loss: 2.2562874817848204
[Epoch 11, Batch 1200] loss: 2.255820336341858
[Epoch 11, Batch 1300] loss: 2.2541932487487792
[Epoch 11, Batch 1400] loss: 2.255985951423645
[Epoch 11, Batch 1500] loss: 2.256429057121277
[Epoch 11, Batch 1600] loss: 2.2560276556015015
[Epoch 11, Batch 1700] loss: 2.252500898838043
[Epoch 11, Batch 1800] loss: 2.2522868371009825
**STATS for Epoch 11** : 
Average training loss: 0.0901
Average validation loss: 2.2516
Validation Accuracy: 0.3780
Overfitting: 2.1615
Best model saved at epoch 11 with validation loss: 2.2516
[Epoch 12, Batch 100] loss: 2.2469179964065553
[Epoch 12, Batch 200] loss: 2.2496988105773927
[Epoch 12, Batch 300] loss: 2.2477052211761475
[Epoch 12, Batch 400] loss: 2.2494988107681273
[Epoch 12, Batch 500] loss: 2.243988320827484
[Epoch 12, Batch 600] loss: 2.248339216709137
[Epoch 12, Batch 700] loss: 2.2480218243598937
[Epoch 12, Batch 800] loss: 2.244775059223175
[Epoch 12, Batch 900] loss: 2.2450412797927854
[Epoch 12, Batch 1000] loss: 2.242364227771759
[Epoch 12, Batch 1100] loss: 2.2406476855278017
[Epoch 12, Batch 1200] loss: 2.246423673629761
[Epoch 12, Batch 1300] loss: 2.245237808227539
[Epoch 12, Batch 1400] loss: 2.240081481933594
[Epoch 12, Batch 1500] loss: 2.2370843863487244
[Epoch 12, Batch 1600] loss: 2.2362186670303346
[Epoch 12, Batch 1700] loss: 2.2374680519104
[Epoch 12, Batch 1800] loss: 2.237515959739685
**STATS for Epoch 12** : 
Average training loss: 0.0894
Average validation loss: 2.2347
Validation Accuracy: 0.4062
Overfitting: 2.1454
Best model saved at epoch 12 with validation loss: 2.2347
[Epoch 13, Batch 100] loss: 2.235195758342743
[Epoch 13, Batch 200] loss: 2.23316700220108
[Epoch 13, Batch 300] loss: 2.230781021118164
[Epoch 13, Batch 400] loss: 2.232472321987152
[Epoch 13, Batch 500] loss: 2.230714511871338
[Epoch 13, Batch 600] loss: 2.2278329586982726
[Epoch 13, Batch 700] loss: 2.225815017223358
[Epoch 13, Batch 800] loss: 2.2208355021476747
[Epoch 13, Batch 900] loss: 2.22356782913208
[Epoch 13, Batch 1000] loss: 2.2257803010940553
[Epoch 13, Batch 1100] loss: 2.220663800239563
[Epoch 13, Batch 1200] loss: 2.219333415031433
[Epoch 13, Batch 1300] loss: 2.222433874607086
[Epoch 13, Batch 1400] loss: 2.214083471298218
[Epoch 13, Batch 1500] loss: 2.2175709652900695
[Epoch 13, Batch 1600] loss: 2.21455543756485
[Epoch 13, Batch 1700] loss: 2.2098900842666627
[Epoch 13, Batch 1800] loss: 2.2069936561584473
**STATS for Epoch 13** : 
Average training loss: 0.0882
Average validation loss: 2.2089
Validation Accuracy: 0.4380
Overfitting: 2.1207
Best model saved at epoch 13 with validation loss: 2.2089
[Epoch 14, Batch 100] loss: 2.2051904153823854
[Epoch 14, Batch 200] loss: 2.2091621708869935
[Epoch 14, Batch 300] loss: 2.200849561691284
[Epoch 14, Batch 400] loss: 2.2016511034965514
[Epoch 14, Batch 500] loss: 2.199453201293945
[Epoch 14, Batch 600] loss: 2.1926722002029417
[Epoch 14, Batch 700] loss: 2.199678432941437
[Epoch 14, Batch 800] loss: 2.1916181588172914
[Epoch 14, Batch 900] loss: 2.1962459015846254
[Epoch 14, Batch 1000] loss: 2.1930692195892334
[Epoch 14, Batch 1100] loss: 2.188997826576233
[Epoch 14, Batch 1200] loss: 2.179004349708557
[Epoch 14, Batch 1300] loss: 2.1793530941009522
[Epoch 14, Batch 1400] loss: 2.1832978558540344
[Epoch 14, Batch 1500] loss: 2.1793289470672605
[Epoch 14, Batch 1600] loss: 2.1776199245452883
[Epoch 14, Batch 1700] loss: 2.1691838312149048
[Epoch 14, Batch 1800] loss: 2.166935291290283
**STATS for Epoch 14** : 
Average training loss: 0.0866
Average validation loss: 2.1665
Validation Accuracy: 0.4803
Overfitting: 2.0798
Best model saved at epoch 14 with validation loss: 2.1665
[Epoch 15, Batch 100] loss: 2.1700339126586914
[Epoch 15, Batch 200] loss: 2.164512209892273
[Epoch 15, Batch 300] loss: 2.1541798591613768
[Epoch 15, Batch 400] loss: 2.148965265750885
[Epoch 15, Batch 500] loss: 2.1548801708221434
[Epoch 15, Batch 600] loss: 2.1440174198150634
[Epoch 15, Batch 700] loss: 2.1385517501831055
[Epoch 15, Batch 800] loss: 2.1343046903610228
[Epoch 15, Batch 900] loss: 2.1432814264297484
[Epoch 15, Batch 1000] loss: 2.1308144092559815
[Epoch 15, Batch 1100] loss: 2.1266189432144165
[Epoch 15, Batch 1200] loss: 2.1292740893363953
[Epoch 15, Batch 1300] loss: 2.113412882089615
[Epoch 15, Batch 1400] loss: 2.1089456391334536
[Epoch 15, Batch 1500] loss: 2.1122591876983643
[Epoch 15, Batch 1600] loss: 2.1039783322811125
[Epoch 15, Batch 1700] loss: 2.0996003484725954
[Epoch 15, Batch 1800] loss: 2.100576401948929
**STATS for Epoch 15** : 
Average training loss: 0.0838
Average validation loss: 2.0893
Validation Accuracy: 0.5119
Overfitting: 2.0054
Best model saved at epoch 15 with validation loss: 2.0893
[Epoch 16, Batch 100] loss: 2.0817307233810425
[Epoch 16, Batch 200] loss: 2.0832171177864076
[Epoch 16, Batch 300] loss: 2.0701468706130983
[Epoch 16, Batch 400] loss: 2.0652318274974824
[Epoch 16, Batch 500] loss: 2.063814355134964
[Epoch 16, Batch 600] loss: 2.048520351648331
[Epoch 16, Batch 700] loss: 2.0443610191345214
[Epoch 16, Batch 800] loss: 2.034388475418091
[Epoch 16, Batch 900] loss: 2.034268341064453
[Epoch 16, Batch 1000] loss: 2.0224992644786837
[Epoch 16, Batch 1100] loss: 2.0075576543807983
[Epoch 16, Batch 1200] loss: 2.005315132141113
[Epoch 16, Batch 1300] loss: 1.9986686050891875
[Epoch 16, Batch 1400] loss: 1.9889370012283325
[Epoch 16, Batch 1500] loss: 1.9961877715587617
[Epoch 16, Batch 1600] loss: 1.9753083884716034
[Epoch 16, Batch 1700] loss: 1.957175337076187
[Epoch 16, Batch 1800] loss: 1.9534988176822663
**STATS for Epoch 16** : 
Average training loss: 0.0779
Average validation loss: 1.9415
Validation Accuracy: 0.5293
Overfitting: 1.8636
Best model saved at epoch 16 with validation loss: 1.9415
[Epoch 17, Batch 100] loss: 1.934881285429001
[Epoch 17, Batch 200] loss: 1.9226285183429719
[Epoch 17, Batch 300] loss: 1.9187364435195924
[Epoch 17, Batch 400] loss: 1.9060229992866515
[Epoch 17, Batch 500] loss: 1.8908154296875
[Epoch 17, Batch 600] loss: 1.8741170358657837
[Epoch 17, Batch 700] loss: 1.8627375674247741
[Epoch 17, Batch 800] loss: 1.8604646372795104
[Epoch 17, Batch 900] loss: 1.8145485198497773
[Epoch 17, Batch 1000] loss: 1.808371922969818
[Epoch 17, Batch 1100] loss: 1.808649972677231
[Epoch 17, Batch 1200] loss: 1.7866108214855194
[Epoch 17, Batch 1300] loss: 1.7489577770233153
[Epoch 17, Batch 1400] loss: 1.7461745834350586
[Epoch 17, Batch 1500] loss: 1.7303843796253204
[Epoch 17, Batch 1600] loss: 1.723983838558197
[Epoch 17, Batch 1700] loss: 1.6844805765151978
[Epoch 17, Batch 1800] loss: 1.6977707958221435
**STATS for Epoch 17** : 
Average training loss: 0.0677
Average validation loss: 1.6652
Validation Accuracy: 0.5836
Overfitting: 1.5976
Best model saved at epoch 17 with validation loss: 1.6652
[Epoch 18, Batch 100] loss: 1.65124871134758
[Epoch 18, Batch 200] loss: 1.6255760657787324
[Epoch 18, Batch 300] loss: 1.599215327501297
[Epoch 18, Batch 400] loss: 1.5927973127365112
[Epoch 18, Batch 500] loss: 1.5756139183044433
[Epoch 18, Batch 600] loss: 1.532424679994583
[Epoch 18, Batch 700] loss: 1.5278623723983764
[Epoch 18, Batch 800] loss: 1.5586696922779084
[Epoch 18, Batch 900] loss: 1.4929330408573152
[Epoch 18, Batch 1000] loss: 1.4591494953632356
[Epoch 18, Batch 1100] loss: 1.4494550025463104
[Epoch 18, Batch 1200] loss: 1.4323586773872377
[Epoch 18, Batch 1300] loss: 1.4029716086387634
[Epoch 18, Batch 1400] loss: 1.3866311204433441
[Epoch 18, Batch 1500] loss: 1.3427307164669038
[Epoch 18, Batch 1600] loss: 1.3317653810977936
[Epoch 18, Batch 1700] loss: 1.3371874171495437
[Epoch 18, Batch 1800] loss: 1.2826129472255707
**STATS for Epoch 18** : 
Average training loss: 0.0498
Average validation loss: 1.2730
Validation Accuracy: 0.6966
Overfitting: 1.2232
Best model saved at epoch 18 with validation loss: 1.2730
[Epoch 19, Batch 100] loss: 1.2760325253009797
[Epoch 19, Batch 200] loss: 1.2245470064878463
[Epoch 19, Batch 300] loss: 1.212143445611
[Epoch 19, Batch 400] loss: 1.20557783305645
[Epoch 19, Batch 500] loss: 1.1497032731771468
[Epoch 19, Batch 600] loss: 1.1440940243005753
[Epoch 19, Batch 700] loss: 1.1583472353219986
[Epoch 19, Batch 800] loss: 1.139309557080269
[Epoch 19, Batch 900] loss: 1.1196109026670455
[Epoch 19, Batch 1000] loss: 1.094799222946167
[Epoch 19, Batch 1100] loss: 1.0411758935451507
[Epoch 19, Batch 1200] loss: 1.0351566743850709
[Epoch 19, Batch 1300] loss: 1.0233843141794206
[Epoch 19, Batch 1400] loss: 1.0094119518995286
[Epoch 19, Batch 1500] loss: 0.979823123216629
[Epoch 19, Batch 1600] loss: 0.988288266658783
[Epoch 19, Batch 1700] loss: 0.9764343005418777
[Epoch 19, Batch 1800] loss: 0.9759965455532074
**STATS for Epoch 19** : 
Average training loss: 0.0374
Average validation loss: 0.9466
Validation Accuracy: 0.7549
Overfitting: 0.9092
Best model saved at epoch 19 with validation loss: 0.9466
[Epoch 20, Batch 100] loss: 0.9242804026603699
[Epoch 20, Batch 200] loss: 0.921031442284584
[Epoch 20, Batch 300] loss: 0.9104564517736435
[Epoch 20, Batch 400] loss: 0.8970578908920288
[Epoch 20, Batch 500] loss: 0.9010629427433013
[Epoch 20, Batch 600] loss: 0.8695234298706055
[Epoch 20, Batch 700] loss: 0.8825390994548797
[Epoch 20, Batch 800] loss: 0.8484739735722542
[Epoch 20, Batch 900] loss: 0.8033294013142586
[Epoch 20, Batch 1000] loss: 0.886526951789856
[Epoch 20, Batch 1100] loss: 0.814580442905426
[Epoch 20, Batch 1200] loss: 0.7990226331353187
[Epoch 20, Batch 1300] loss: 0.842053408920765
[Epoch 20, Batch 1400] loss: 0.7796541038155556
[Epoch 20, Batch 1500] loss: 0.7663314226269722
[Epoch 20, Batch 1600] loss: 0.7621132656931877
[Epoch 20, Batch 1700] loss: 0.7510321179032325
[Epoch 20, Batch 1800] loss: 0.769486868083477
**STATS for Epoch 20** : 
Average training loss: 0.0304
Average validation loss: 0.7636
Validation Accuracy: 0.7824
Overfitting: 0.7332
Best model saved at epoch 20 with validation loss: 0.7636
[Epoch 21, Batch 100] loss: 0.7516152781248092
[Epoch 21, Batch 200] loss: 0.7938685503602028
[Epoch 21, Batch 300] loss: 0.7604949080944061
[Epoch 21, Batch 400] loss: 0.6894983208179474
[Epoch 21, Batch 500] loss: 0.7173592564463616
[Epoch 21, Batch 600] loss: 0.7137955382466317
[Epoch 21, Batch 700] loss: 0.6752871695160866
[Epoch 21, Batch 800] loss: 0.6936036521196365
[Epoch 21, Batch 900] loss: 0.6682011049985885
[Epoch 21, Batch 1000] loss: 0.6854404443502427
[Epoch 21, Batch 1100] loss: 0.6555153685808182
[Epoch 21, Batch 1200] loss: 0.7277681928873062
[Epoch 21, Batch 1300] loss: 0.6920322701334953
[Epoch 21, Batch 1400] loss: 0.6902191171050072
[Epoch 21, Batch 1500] loss: 0.7086009865999222
[Epoch 21, Batch 1600] loss: 0.6743564546108246
[Epoch 21, Batch 1700] loss: 0.6582614603638649
[Epoch 21, Batch 1800] loss: 0.6617453250288964
**STATS for Epoch 21** : 
Average training loss: 0.0253
Average validation loss: 0.6619
Validation Accuracy: 0.8036
Overfitting: 0.6366
Best model saved at epoch 21 with validation loss: 0.6619
[Epoch 22, Batch 100] loss: 0.6461536973714829
[Epoch 22, Batch 200] loss: 0.6609475345909596
[Epoch 22, Batch 300] loss: 0.6623388741910458
[Epoch 22, Batch 400] loss: 0.616830048263073
[Epoch 22, Batch 500] loss: 0.6479433384537697
[Epoch 22, Batch 600] loss: 0.6429091021418571
[Epoch 22, Batch 700] loss: 0.6373084333539009
[Epoch 22, Batch 800] loss: 0.5992255698144436
[Epoch 22, Batch 900] loss: 0.595823360979557
[Epoch 22, Batch 1000] loss: 0.6252473983168602
[Epoch 22, Batch 1100] loss: 0.5978487184643746
[Epoch 22, Batch 1200] loss: 0.6358527100086212
[Epoch 22, Batch 1300] loss: 0.5881621530652046
[Epoch 22, Batch 1400] loss: 0.6055862185359001
[Epoch 22, Batch 1500] loss: 0.5881491881608963
[Epoch 22, Batch 1600] loss: 0.550142396390438
[Epoch 22, Batch 1700] loss: 0.5686061286926269
[Epoch 22, Batch 1800] loss: 0.6219498562812805
**STATS for Epoch 22** : 
Average training loss: 0.0251
Average validation loss: 0.5973
Validation Accuracy: 0.8191
Overfitting: 0.5722
Best model saved at epoch 22 with validation loss: 0.5973
[Epoch 23, Batch 100] loss: 0.6072807221114636
[Epoch 23, Batch 200] loss: 0.574241706430912
[Epoch 23, Batch 300] loss: 0.5419227942824364
[Epoch 23, Batch 400] loss: 0.5610693190991879
[Epoch 23, Batch 500] loss: 0.6141720794141292
[Epoch 23, Batch 600] loss: 0.5549644966423511
[Epoch 23, Batch 700] loss: 0.5500804747641087
[Epoch 23, Batch 800] loss: 0.5417203518748284
[Epoch 23, Batch 900] loss: 0.5604163236916065
[Epoch 23, Batch 1000] loss: 0.5836682817339898
[Epoch 23, Batch 1100] loss: 0.5667231664061546
[Epoch 23, Batch 1200] loss: 0.5480940800905227
[Epoch 23, Batch 1300] loss: 0.5819335225224495
[Epoch 23, Batch 1400] loss: 0.5521646384894848
[Epoch 23, Batch 1500] loss: 0.5330932316184044
[Epoch 23, Batch 1600] loss: 0.5244327183067798
[Epoch 23, Batch 1700] loss: 0.567211259007454
[Epoch 23, Batch 1800] loss: 0.5188382625579834
**STATS for Epoch 23** : 
Average training loss: 0.0241
Average validation loss: 0.5493
Validation Accuracy: 0.8338
Overfitting: 0.5252
Best model saved at epoch 23 with validation loss: 0.5493
[Epoch 24, Batch 100] loss: 0.5294688284397125
[Epoch 24, Batch 200] loss: 0.5067717052996159
[Epoch 24, Batch 300] loss: 0.5359511560201645
[Epoch 24, Batch 400] loss: 0.509549418836832
[Epoch 24, Batch 500] loss: 0.5407815435528756
[Epoch 24, Batch 600] loss: 0.526272618919611
[Epoch 24, Batch 700] loss: 0.5557455363869667
[Epoch 24, Batch 800] loss: 0.5255567564070225
[Epoch 24, Batch 900] loss: 0.5445333547890187
[Epoch 24, Batch 1000] loss: 0.5261569702625275
[Epoch 24, Batch 1100] loss: 0.499877400547266
[Epoch 24, Batch 1200] loss: 0.5028705967962742
[Epoch 24, Batch 1300] loss: 0.5135270869731903
[Epoch 24, Batch 1400] loss: 0.5168873624503613
[Epoch 24, Batch 1500] loss: 0.501690169274807
[Epoch 24, Batch 1600] loss: 0.5384071645140648
[Epoch 24, Batch 1700] loss: 0.5382620191574097
[Epoch 24, Batch 1800] loss: 0.4985718108713627
**STATS for Epoch 24** : 
Average training loss: 0.0192
Average validation loss: 0.5138
Validation Accuracy: 0.8440
Overfitting: 0.4946
Best model saved at epoch 24 with validation loss: 0.5138
Fold 2 validation loss: 0.5138
Mean validation loss across all folds for Trial 6 is 0.4288 with trial config:  l1: 96, l2: 64, lr: 1.3726318898045866e-05, batch_size: 16
[I 2024-11-19 01:03:15,803] Trial 5 finished with value: 0.42877587377776705 and parameters: {'l1': 96, 'l2': 64, 'lr': 1.3726318898045866e-05, 'batch_size': 16}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 7:
  l1: 320, l2: 64, lr: 0.07556810141274425, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.3469488063454629
[Epoch 1, Batch 200] loss: 1.081719590574503
[Epoch 1, Batch 300] loss: 0.8609497784078122
[Epoch 1, Batch 400] loss: 0.6670506598055362
[Epoch 1, Batch 500] loss: 0.9072445297241211
[Epoch 1, Batch 600] loss: 0.7087844099104404
[Epoch 1, Batch 700] loss: 0.7672813121974468
[Epoch 1, Batch 800] loss: 0.7091480879485608
[Epoch 1, Batch 900] loss: 0.8391905033960938
**STATS for Epoch 1** : 
Average training loss: 0.0256
Average validation loss: 0.7179
Validation Accuracy: 0.8620
Overfitting: 0.6923
Best model saved at epoch 1 with validation loss: 0.7179
[Epoch 2, Batch 100] loss: 0.5850255240499973
[Epoch 2, Batch 200] loss: 0.7270777118206024
[Epoch 2, Batch 300] loss: 0.5899776161462068
[Epoch 2, Batch 400] loss: 0.502234873175621
[Epoch 2, Batch 500] loss: 0.7079331810772419
[Epoch 2, Batch 600] loss: 0.7771199415624142
[Epoch 2, Batch 700] loss: 0.614818787202239
[Epoch 2, Batch 800] loss: 0.5060397072881461
[Epoch 2, Batch 900] loss: 0.48715379033237693
**STATS for Epoch 2** : 
Average training loss: 0.0284
Average validation loss: 1.0960
Validation Accuracy: 0.8062
Overfitting: 1.0677
[Epoch 3, Batch 100] loss: 1.0599348324537277
[Epoch 3, Batch 200] loss: 0.8861320340633392
[Epoch 3, Batch 300] loss: 0.8084868863224983
[Epoch 3, Batch 400] loss: 0.8752121672034263
[Epoch 3, Batch 500] loss: 0.9956324934959412
[Epoch 3, Batch 600] loss: 0.7226004967093468
[Epoch 3, Batch 700] loss: 0.9020152732729911
[Epoch 3, Batch 800] loss: 1.6136081022024156
[Epoch 3, Batch 900] loss: 2.3155626463890076
**STATS for Epoch 3** : 
Average training loss: 0.0935
Average validation loss: 2.3100
Validation Accuracy: 0.1122
Overfitting: 2.2166
[Epoch 4, Batch 100] loss: 2.3067316937446596
[Epoch 4, Batch 200] loss: 2.3060372829437257
[Epoch 4, Batch 300] loss: 2.303786964416504
[Epoch 4, Batch 400] loss: 2.305702414512634
[Epoch 4, Batch 500] loss: 2.308933207988739
[Epoch 4, Batch 600] loss: 2.3059944772720335
[Epoch 4, Batch 700] loss: 2.3054720163345337
[Epoch 4, Batch 800] loss: 2.308874671459198
[Epoch 4, Batch 900] loss: 2.3036698937416076
**STATS for Epoch 4** : 
Average training loss: 0.0931
Average validation loss: 2.3123
Validation Accuracy: 0.1122
Overfitting: 2.2192
[Epoch 5, Batch 100] loss: 2.3073686265945437
[Epoch 5, Batch 200] loss: 2.3070882892608644
[Epoch 5, Batch 300] loss: 2.305137047767639
[Epoch 5, Batch 400] loss: 2.3071601247787474
[Epoch 5, Batch 500] loss: 2.3070255184173583
[Epoch 5, Batch 600] loss: 2.306102497577667
[Epoch 5, Batch 700] loss: 2.3091694283485413
[Epoch 5, Batch 800] loss: 2.303174078464508
[Epoch 5, Batch 900] loss: 2.305804200172424
**STATS for Epoch 5** : 
Average training loss: 0.0934
Average validation loss: 2.3055
Validation Accuracy: 0.1007
Overfitting: 2.2121
[Epoch 6, Batch 100] loss: 2.3101263570785524
[Epoch 6, Batch 200] loss: 2.3070892572402952
[Epoch 6, Batch 300] loss: 2.306036021709442
[Epoch 6, Batch 400] loss: 2.303581352233887
[Epoch 6, Batch 500] loss: 2.307554202079773
[Epoch 6, Batch 600] loss: 2.305677831172943
[Epoch 6, Batch 700] loss: 2.3091246819496156
[Epoch 6, Batch 800] loss: 2.302893354892731
[Epoch 6, Batch 900] loss: 2.306004102230072
**STATS for Epoch 6** : 
Average training loss: 0.0931
Average validation loss: 2.3096
Validation Accuracy: 0.1122
Overfitting: 2.2165
[Epoch 7, Batch 100] loss: 2.3086532974243164
[Epoch 7, Batch 200] loss: 2.3065468502044677
[Epoch 7, Batch 300] loss: 2.3084463906288146
[Epoch 7, Batch 400] loss: 2.3068806433677675
[Epoch 7, Batch 500] loss: 2.3058940029144286
[Epoch 7, Batch 600] loss: 2.3061483001708982
[Epoch 7, Batch 700] loss: 2.3054208970069885
[Epoch 7, Batch 800] loss: 2.3067438340187074
[Epoch 7, Batch 900] loss: 2.301959686279297
**STATS for Epoch 7** : 
Average training loss: 0.0934
Average validation loss: 2.3043
Validation Accuracy: 0.1036
Overfitting: 2.2109
[Epoch 8, Batch 100] loss: 2.3043383502960206
[Epoch 8, Batch 200] loss: 2.3054629802703857
[Epoch 8, Batch 300] loss: 2.305809597969055
[Epoch 8, Batch 400] loss: 2.3066368103027344
[Epoch 8, Batch 500] loss: 2.3046063709259035
[Epoch 8, Batch 600] loss: 2.3054844117164612
[Epoch 8, Batch 700] loss: 2.3060694336891174
[Epoch 8, Batch 800] loss: 2.3067441725730897
[Epoch 8, Batch 900] loss: 2.3050212502479552
**STATS for Epoch 8** : 
Average training loss: 0.0932
Average validation loss: 2.3141
Validation Accuracy: 0.0991
Overfitting: 2.2209
[Epoch 9, Batch 100] loss: 2.3075158286094664
[Epoch 9, Batch 200] loss: 2.3040229892730713
[Epoch 9, Batch 300] loss: 2.3075968861579894
[Epoch 9, Batch 400] loss: 2.3050589966773987
[Epoch 9, Batch 500] loss: 2.3067531394958496
[Epoch 9, Batch 600] loss: 2.3066489458084107
[Epoch 9, Batch 700] loss: 2.3048721861839296
[Epoch 9, Batch 800] loss: 2.306631042957306
[Epoch 9, Batch 900] loss: 2.307277488708496
**STATS for Epoch 9** : 
Average training loss: 0.0933
Average validation loss: 2.3068
Validation Accuracy: 0.1122
Overfitting: 2.2135
[Epoch 10, Batch 100] loss: 2.306661911010742
[Epoch 10, Batch 200] loss: 2.306268405914307
[Epoch 10, Batch 300] loss: 2.3082816004753113
[Epoch 10, Batch 400] loss: 2.3071787357330322
[Epoch 10, Batch 500] loss: 2.3068249583244325
[Epoch 10, Batch 600] loss: 2.3061842489242554
[Epoch 10, Batch 700] loss: 2.306402838230133
[Epoch 10, Batch 800] loss: 2.3070709323883056
[Epoch 10, Batch 900] loss: 2.3076112818717958
**STATS for Epoch 10** : 
Average training loss: 0.0934
Average validation loss: 2.3039
Validation Accuracy: 0.1122
Overfitting: 2.2105
[Epoch 11, Batch 100] loss: 2.30679379940033
[Epoch 11, Batch 200] loss: 2.308118441104889
[Epoch 11, Batch 300] loss: 2.303784103393555
[Epoch 11, Batch 400] loss: 2.305380837917328
[Epoch 11, Batch 500] loss: 2.3063431429862975
[Epoch 11, Batch 600] loss: 2.304277081489563
[Epoch 11, Batch 700] loss: 2.3063835954666136
[Epoch 11, Batch 800] loss: 2.30382346868515
[Epoch 11, Batch 900] loss: 2.3068193697929384
**STATS for Epoch 11** : 
Average training loss: 0.0933
Average validation loss: 2.3092
Validation Accuracy: 0.0986
Overfitting: 2.2159
[Epoch 12, Batch 100] loss: 2.3029022789001465
[Epoch 12, Batch 200] loss: 2.3050567579269408
[Epoch 12, Batch 300] loss: 2.3083490324020386
[Epoch 12, Batch 400] loss: 2.3060585951805113
[Epoch 12, Batch 500] loss: 2.3047432279586793
[Epoch 12, Batch 600] loss: 2.3063030505180357
[Epoch 12, Batch 700] loss: 2.3083335399627685
[Epoch 12, Batch 800] loss: 2.303510401248932
[Epoch 12, Batch 900] loss: 2.3097476887702943
**STATS for Epoch 12** : 
Average training loss: 0.0933
Average validation loss: 2.3138
Validation Accuracy: 0.0998
Overfitting: 2.2205
[Epoch 13, Batch 100] loss: 2.308615701198578
[Epoch 13, Batch 200] loss: 2.308069064617157
[Epoch 13, Batch 300] loss: 2.307375388145447
[Epoch 13, Batch 400] loss: 2.307694818973541
[Epoch 13, Batch 500] loss: 2.3072967195510863
[Epoch 13, Batch 600] loss: 2.3037164282798765
[Epoch 13, Batch 700] loss: 2.307053036689758
[Epoch 13, Batch 800] loss: 2.3084001898765565
[Epoch 13, Batch 900] loss: 2.308723661899567
**STATS for Epoch 13** : 
Average training loss: 0.0933
Average validation loss: 2.3052
Validation Accuracy: 0.1036
Overfitting: 2.2119
[Epoch 14, Batch 100] loss: 2.308471441268921
[Epoch 14, Batch 200] loss: 2.305100665092468
[Epoch 14, Batch 300] loss: 2.3030556869506835
[Epoch 14, Batch 400] loss: 2.3107637190818786
[Epoch 14, Batch 500] loss: 2.3057539367675783
[Epoch 14, Batch 600] loss: 2.305493886470795
[Epoch 14, Batch 700] loss: 2.3126776099205015
[Epoch 14, Batch 800] loss: 2.304839391708374
[Epoch 14, Batch 900] loss: 2.3035974407196047
**STATS for Epoch 14** : 
Average training loss: 0.0936
Average validation loss: 2.3041
Validation Accuracy: 0.1122
Overfitting: 2.2106
[Epoch 15, Batch 100] loss: 2.305030484199524
[Epoch 15, Batch 200] loss: 2.305107533931732
[Epoch 15, Batch 300] loss: 2.305685374736786
[Epoch 15, Batch 400] loss: 2.3071227526664733
[Epoch 15, Batch 500] loss: 2.3046491074562074
[Epoch 15, Batch 600] loss: 2.3063961672782898
[Epoch 15, Batch 700] loss: 2.3066640496253967
[Epoch 15, Batch 800] loss: 2.3102463984489443
[Epoch 15, Batch 900] loss: 2.3057491636276244
**STATS for Epoch 15** : 
Average training loss: 0.0937
Average validation loss: 2.3050
Validation Accuracy: 0.0987
Overfitting: 2.2114
[Epoch 16, Batch 100] loss: 2.304356400966644
[Epoch 16, Batch 200] loss: 2.3076365208625793
[Epoch 16, Batch 300] loss: 2.3071202564239504
[Epoch 16, Batch 400] loss: 2.3045005202293396
[Epoch 16, Batch 500] loss: 2.3020298409461977
[Epoch 16, Batch 600] loss: 2.3054798150062563
[Epoch 16, Batch 700] loss: 2.3076714134216307
[Epoch 16, Batch 800] loss: 2.30662855386734
[Epoch 16, Batch 900] loss: 2.3068988704681397
**STATS for Epoch 16** : 
Average training loss: 0.0936
Average validation loss: 2.3042
Validation Accuracy: 0.1122
Overfitting: 2.2107
[Epoch 17, Batch 100] loss: 2.3067689824104307
[Epoch 17, Batch 200] loss: 2.3067028594017027
[Epoch 17, Batch 300] loss: 2.307687830924988
[Epoch 17, Batch 400] loss: 2.3059130024909975
[Epoch 17, Batch 500] loss: 2.305179660320282
[Epoch 17, Batch 600] loss: 2.3058431243896482
[Epoch 17, Batch 700] loss: 2.3070513153076173
[Epoch 17, Batch 800] loss: 2.305521183013916
[Epoch 17, Batch 900] loss: 2.30611180305481
**STATS for Epoch 17** : 
Average training loss: 0.0935
Average validation loss: 2.3069
Validation Accuracy: 0.0986
Overfitting: 2.2134
[Epoch 18, Batch 100] loss: 2.3075930190086367
[Epoch 18, Batch 200] loss: 2.3052829480171204
[Epoch 18, Batch 300] loss: 2.30671373128891
[Epoch 18, Batch 400] loss: 2.3076926183700563
[Epoch 18, Batch 500] loss: 2.3071692752838135
[Epoch 18, Batch 600] loss: 2.307677359580994
[Epoch 18, Batch 700] loss: 2.308117506504059
[Epoch 18, Batch 800] loss: 2.304592134952545
[Epoch 18, Batch 900] loss: 2.3052738809585573
**STATS for Epoch 18** : 
Average training loss: 0.0934
Average validation loss: 2.3043
Validation Accuracy: 0.1122
Overfitting: 2.2109
[Epoch 19, Batch 100] loss: 2.3071838641166686
[Epoch 19, Batch 200] loss: 2.306634919643402
[Epoch 19, Batch 300] loss: 2.305349204540253
[Epoch 19, Batch 400] loss: 2.3077784609794616
[Epoch 19, Batch 500] loss: 2.303066008090973
[Epoch 19, Batch 600] loss: 2.3067903232574465
[Epoch 19, Batch 700] loss: 2.3059061121940614
[Epoch 19, Batch 800] loss: 2.3074361944198607
[Epoch 19, Batch 900] loss: 2.3082302713394167
**STATS for Epoch 19** : 
Average training loss: 0.0934
Average validation loss: 2.3074
Validation Accuracy: 0.1122
Overfitting: 2.2140
[Epoch 20, Batch 100] loss: 2.3057128977775574
[Epoch 20, Batch 200] loss: 2.303885359764099
[Epoch 20, Batch 300] loss: 2.3053234148025514
[Epoch 20, Batch 400] loss: 2.306350791454315
[Epoch 20, Batch 500] loss: 2.3075498223304747
[Epoch 20, Batch 600] loss: 2.3063719844818116
[Epoch 20, Batch 700] loss: 2.3053231716156004
[Epoch 20, Batch 800] loss: 2.3069217228889465
[Epoch 20, Batch 900] loss: 2.304972310066223
**STATS for Epoch 20** : 
Average training loss: 0.0934
Average validation loss: 2.3100
Validation Accuracy: 0.0991
Overfitting: 2.2166
[Epoch 21, Batch 100] loss: 2.307908606529236
[Epoch 21, Batch 200] loss: 2.307339744567871
[Epoch 21, Batch 300] loss: 2.306611723899841
[Epoch 21, Batch 400] loss: 2.3054121470451356
[Epoch 21, Batch 500] loss: 2.30563702583313
[Epoch 21, Batch 600] loss: 2.3067578506469726
[Epoch 21, Batch 700] loss: 2.3096374225616456
[Epoch 21, Batch 800] loss: 2.3085364508628845
[Epoch 21, Batch 900] loss: 2.308962800502777
**STATS for Epoch 21** : 
Average training loss: 0.0934
Average validation loss: 2.3062
Validation Accuracy: 0.1007
Overfitting: 2.2127
[Epoch 22, Batch 100] loss: 2.3044038152694704
[Epoch 22, Batch 200] loss: 2.3066613602638246
[Epoch 22, Batch 300] loss: 2.310212035179138
[Epoch 22, Batch 400] loss: 2.3088201975822447
[Epoch 22, Batch 500] loss: 2.3046517181396484
[Epoch 22, Batch 600] loss: 2.30568852186203
[Epoch 22, Batch 700] loss: 2.306778268814087
[Epoch 22, Batch 800] loss: 2.307106204032898
[Epoch 22, Batch 900] loss: 2.30470472574234
**STATS for Epoch 22** : 
Average training loss: 0.0935
Average validation loss: 2.3069
Validation Accuracy: 0.1007
Overfitting: 2.2133
[Epoch 23, Batch 100] loss: 2.306726546287537
[Epoch 23, Batch 200] loss: 2.308801395893097
[Epoch 23, Batch 300] loss: 2.308784217834473
[Epoch 23, Batch 400] loss: 2.307824745178223
[Epoch 23, Batch 500] loss: 2.3057152676582335
[Epoch 23, Batch 600] loss: 2.307241303920746
[Epoch 23, Batch 700] loss: 2.3031591725349427
[Epoch 23, Batch 800] loss: 2.310140221118927
[Epoch 23, Batch 900] loss: 2.3074345993995666
**STATS for Epoch 23** : 
Average training loss: 0.0934
Average validation loss: 2.3071
Validation Accuracy: 0.1036
Overfitting: 2.2137
[Epoch 24, Batch 100] loss: 2.304313549995422
[Epoch 24, Batch 200] loss: 2.310915434360504
[Epoch 24, Batch 300] loss: 2.3061139392852783
[Epoch 24, Batch 400] loss: 2.30408819437027
[Epoch 24, Batch 500] loss: 2.306519241333008
[Epoch 24, Batch 600] loss: 2.3065677070617676
[Epoch 24, Batch 700] loss: 2.307309286594391
[Epoch 24, Batch 800] loss: 2.3071803498268126
[Epoch 24, Batch 900] loss: 2.3041296768188477
**STATS for Epoch 24** : 
Average training loss: 0.0933
Average validation loss: 2.3078
Validation Accuracy: 0.0998
Overfitting: 2.2145
Fold 1 validation loss: 2.3078
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.4310184487700461
[Epoch 1, Batch 200] loss: 0.8307111755013465
[Epoch 1, Batch 300] loss: 0.7820492705702782
[Epoch 1, Batch 400] loss: 0.651918930709362
[Epoch 1, Batch 500] loss: 0.6871452125906944
[Epoch 1, Batch 600] loss: 0.8150861246883869
[Epoch 1, Batch 700] loss: 0.7399904166907072
[Epoch 1, Batch 800] loss: 0.6947159977257251
[Epoch 1, Batch 900] loss: 0.8123367150127888
**STATS for Epoch 1** : 
Average training loss: 0.0269
Average validation loss: 0.6246
Validation Accuracy: 0.8577
Overfitting: 0.5977
Best model saved at epoch 1 with validation loss: 0.6246
[Epoch 2, Batch 100] loss: 1.1859699992835522
[Epoch 2, Batch 200] loss: 1.7558159446716308
[Epoch 2, Batch 300] loss: 1.6405715411901474
[Epoch 2, Batch 400] loss: 2.3322708523273468
[Epoch 2, Batch 500] loss: 2.3051291608810427
[Epoch 2, Batch 600] loss: 2.3086084938049316
[Epoch 2, Batch 700] loss: 2.3046685433387757
[Epoch 2, Batch 800] loss: 2.30813453912735
[Epoch 2, Batch 900] loss: 2.3056358695030212
**STATS for Epoch 2** : 
Average training loss: 0.0934
Average validation loss: 2.3103
Validation Accuracy: 0.1126
Overfitting: 2.2169
[Epoch 3, Batch 100] loss: 2.3057404804229735
[Epoch 3, Batch 200] loss: 2.3080377912521364
[Epoch 3, Batch 300] loss: 2.30447438955307
[Epoch 3, Batch 400] loss: 2.306263406276703
[Epoch 3, Batch 500] loss: 2.3067214679718018
[Epoch 3, Batch 600] loss: 2.305409770011902
[Epoch 3, Batch 700] loss: 2.3063118696212768
[Epoch 3, Batch 800] loss: 2.305149576663971
[Epoch 3, Batch 900] loss: 2.3051232719421386
**STATS for Epoch 3** : 
Average training loss: 0.0937
Average validation loss: 2.3072
Validation Accuracy: 0.1037
Overfitting: 2.2135
[Epoch 4, Batch 100] loss: 2.307505521774292
[Epoch 4, Batch 200] loss: 2.3065547585487365
[Epoch 4, Batch 300] loss: 2.3059028339385987
[Epoch 4, Batch 400] loss: 2.3036709332466128
[Epoch 4, Batch 500] loss: 2.3057935357093813
[Epoch 4, Batch 600] loss: 2.3095176362991334
[Epoch 4, Batch 700] loss: 2.306263854503632
[Epoch 4, Batch 800] loss: 2.308739128112793
[Epoch 4, Batch 900] loss: 2.3070473313331603
**STATS for Epoch 4** : 
Average training loss: 0.0936
Average validation loss: 2.3023
Validation Accuracy: 0.1126
Overfitting: 2.2087
[Epoch 5, Batch 100] loss: 2.303844864368439
[Epoch 5, Batch 200] loss: 2.3071653008461
[Epoch 5, Batch 300] loss: 2.3054454207420347
[Epoch 5, Batch 400] loss: 2.307367031574249
[Epoch 5, Batch 500] loss: 2.307471528053284
[Epoch 5, Batch 600] loss: 2.3045330929756163
[Epoch 5, Batch 700] loss: 2.308563680648804
[Epoch 5, Batch 800] loss: 2.3050995206832887
[Epoch 5, Batch 900] loss: 2.3055436968803407
**STATS for Epoch 5** : 
Average training loss: 0.0935
Average validation loss: 2.3096
Validation Accuracy: 0.0992
Overfitting: 2.2161
[Epoch 6, Batch 100] loss: 2.3071165227890016
[Epoch 6, Batch 200] loss: 2.3086437606811523
[Epoch 6, Batch 300] loss: 2.3072349619865418
[Epoch 6, Batch 400] loss: 2.3068786787986757
[Epoch 6, Batch 500] loss: 2.3037698245048523
[Epoch 6, Batch 600] loss: 2.3080490756034853
[Epoch 6, Batch 700] loss: 2.3080541276931763
[Epoch 6, Batch 800] loss: 2.3053746223449707
[Epoch 6, Batch 900] loss: 2.3090313148498534
**STATS for Epoch 6** : 
Average training loss: 0.0937
Average validation loss: 2.3039
Validation Accuracy: 0.0976
Overfitting: 2.2102
[Epoch 7, Batch 100] loss: 2.307480347156525
[Epoch 7, Batch 200] loss: 2.307589135169983
[Epoch 7, Batch 300] loss: 2.3055085253715517
[Epoch 7, Batch 400] loss: 2.309110527038574
[Epoch 7, Batch 500] loss: 2.3055592465400694
[Epoch 7, Batch 600] loss: 2.3074177360534667
[Epoch 7, Batch 700] loss: 2.306244742870331
[Epoch 7, Batch 800] loss: 2.304430842399597
[Epoch 7, Batch 900] loss: 2.3080368781089784
**STATS for Epoch 7** : 
Average training loss: 0.0934
Average validation loss: 2.3072
Validation Accuracy: 0.1126
Overfitting: 2.2138
[Epoch 8, Batch 100] loss: 2.306095507144928
[Epoch 8, Batch 200] loss: 2.3050941681861876
[Epoch 8, Batch 300] loss: 2.304788362979889
[Epoch 8, Batch 400] loss: 2.3087767934799195
[Epoch 8, Batch 500] loss: 2.305799169540405
[Epoch 8, Batch 600] loss: 2.304981987476349
[Epoch 8, Batch 700] loss: 2.3068419313430786
[Epoch 8, Batch 800] loss: 2.308244082927704
[Epoch 8, Batch 900] loss: 2.306958694458008
**STATS for Epoch 8** : 
Average training loss: 0.0937
Average validation loss: 2.3062
Validation Accuracy: 0.1052
Overfitting: 2.2125
[Epoch 9, Batch 100] loss: 2.3074964547157286
[Epoch 9, Batch 200] loss: 2.3086093926429747
[Epoch 9, Batch 300] loss: 2.306636834144592
[Epoch 9, Batch 400] loss: 2.3074438905715944
[Epoch 9, Batch 500] loss: 2.3073192119598387
[Epoch 9, Batch 600] loss: 2.3074827289581297
[Epoch 9, Batch 700] loss: 2.307950394153595
[Epoch 9, Batch 800] loss: 2.30632714509964
[Epoch 9, Batch 900] loss: 2.3058077597618105
**STATS for Epoch 9** : 
Average training loss: 0.0936
Average validation loss: 2.3043
Validation Accuracy: 0.0964
Overfitting: 2.2107
[Epoch 10, Batch 100] loss: 2.306129152774811
[Epoch 10, Batch 200] loss: 2.306951949596405
[Epoch 10, Batch 300] loss: 2.3022644567489623
[Epoch 10, Batch 400] loss: 2.3058962273597716
[Epoch 10, Batch 500] loss: 2.3065893983840944
[Epoch 10, Batch 600] loss: 2.3081829714775086
[Epoch 10, Batch 700] loss: 2.307438929080963
[Epoch 10, Batch 800] loss: 2.306165461540222
[Epoch 10, Batch 900] loss: 2.308196268081665
**STATS for Epoch 10** : 
Average training loss: 0.0934
Average validation loss: 2.3118
Validation Accuracy: 0.0976
Overfitting: 2.2184
[Epoch 11, Batch 100] loss: 2.3080269074440003
[Epoch 11, Batch 200] loss: 2.3065339803695677
[Epoch 11, Batch 300] loss: 2.307854495048523
[Epoch 11, Batch 400] loss: 2.305319652557373
[Epoch 11, Batch 500] loss: 2.307112467288971
[Epoch 11, Batch 600] loss: 2.3071981406211854
[Epoch 11, Batch 700] loss: 2.307582004070282
[Epoch 11, Batch 800] loss: 2.310644733905792
[Epoch 11, Batch 900] loss: 2.302769021987915
**STATS for Epoch 11** : 
Average training loss: 0.0934
Average validation loss: 2.3054
Validation Accuracy: 0.1052
Overfitting: 2.2120
[Epoch 12, Batch 100] loss: 2.3059802150726316
[Epoch 12, Batch 200] loss: 2.3082103300094605
[Epoch 12, Batch 300] loss: 2.3064904499053953
[Epoch 12, Batch 400] loss: 2.3048225903511046
[Epoch 12, Batch 500] loss: 2.3077608513832093
[Epoch 12, Batch 600] loss: 2.307166142463684
[Epoch 12, Batch 700] loss: 2.308298020362854
[Epoch 12, Batch 800] loss: 2.304747576713562
[Epoch 12, Batch 900] loss: 2.310143346786499
**STATS for Epoch 12** : 
Average training loss: 0.0936
Average validation loss: 2.3046
Validation Accuracy: 0.1126
Overfitting: 2.2110
[Epoch 13, Batch 100] loss: 2.3055346989631653
[Epoch 13, Batch 200] loss: 2.307903130054474
[Epoch 13, Batch 300] loss: 2.3064921164512633
[Epoch 13, Batch 400] loss: 2.310350034236908
[Epoch 13, Batch 500] loss: 2.308716127872467
[Epoch 13, Batch 600] loss: 2.306127805709839
[Epoch 13, Batch 700] loss: 2.3029786777496337
[Epoch 13, Batch 800] loss: 2.3073338508605956
[Epoch 13, Batch 900] loss: 2.3060598874092104
**STATS for Epoch 13** : 
Average training loss: 0.0935
Average validation loss: 2.3038
Validation Accuracy: 0.0976
Overfitting: 2.2103
[Epoch 14, Batch 100] loss: 2.3067219161987307
[Epoch 14, Batch 200] loss: 2.3077390384674072
[Epoch 14, Batch 300] loss: 2.30591272354126
[Epoch 14, Batch 400] loss: 2.3064516830444335
[Epoch 14, Batch 500] loss: 2.3075705742836
[Epoch 14, Batch 600] loss: 2.307329158782959
[Epoch 14, Batch 700] loss: 2.3064069509506226
[Epoch 14, Batch 800] loss: 2.3087637996673585
[Epoch 14, Batch 900] loss: 2.306889822483063
**STATS for Epoch 14** : 
Average training loss: 0.0934
Average validation loss: 2.3040
Validation Accuracy: 0.1126
Overfitting: 2.2106
[Epoch 15, Batch 100] loss: 2.3031778144836426
[Epoch 15, Batch 200] loss: 2.306551649570465
[Epoch 15, Batch 300] loss: 2.3028269243240356
[Epoch 15, Batch 400] loss: 2.3074534845352175
[Epoch 15, Batch 500] loss: 2.307286570072174
[Epoch 15, Batch 600] loss: 2.308521845340729
[Epoch 15, Batch 700] loss: 2.3067115926742554
[Epoch 15, Batch 800] loss: 2.3066528606414796
[Epoch 15, Batch 900] loss: 2.306791467666626
**STATS for Epoch 15** : 
Average training loss: 0.0934
Average validation loss: 2.3049
Validation Accuracy: 0.1037
Overfitting: 2.2115
[Epoch 16, Batch 100] loss: 2.310046591758728
[Epoch 16, Batch 200] loss: 2.3060921478271483
[Epoch 16, Batch 300] loss: 2.3028799152374266
[Epoch 16, Batch 400] loss: 2.307829947471619
[Epoch 16, Batch 500] loss: 2.30814640045166
[Epoch 16, Batch 600] loss: 2.306262559890747
[Epoch 16, Batch 700] loss: 2.3066067552566527
[Epoch 16, Batch 800] loss: 2.305696964263916
[Epoch 16, Batch 900] loss: 2.30855676651001
**STATS for Epoch 16** : 
Average training loss: 0.0936
Average validation loss: 2.3045
Validation Accuracy: 0.1126
Overfitting: 2.2110
[Epoch 17, Batch 100] loss: 2.306265711784363
[Epoch 17, Batch 200] loss: 2.305452904701233
[Epoch 17, Batch 300] loss: 2.3063834953308104
[Epoch 17, Batch 400] loss: 2.3069368481636046
[Epoch 17, Batch 500] loss: 2.3082413840293885
[Epoch 17, Batch 600] loss: 2.308299174308777
[Epoch 17, Batch 700] loss: 2.3069748663902283
[Epoch 17, Batch 800] loss: 2.3066493892669677
[Epoch 17, Batch 900] loss: 2.3070909929275514
**STATS for Epoch 17** : 
Average training loss: 0.0936
Average validation loss: 2.3076
Validation Accuracy: 0.1000
Overfitting: 2.2140
[Epoch 18, Batch 100] loss: 2.307268433570862
[Epoch 18, Batch 200] loss: 2.3047298979759216
[Epoch 18, Batch 300] loss: 2.306925666332245
[Epoch 18, Batch 400] loss: 2.3070948553085326
[Epoch 18, Batch 500] loss: 2.306244282722473
[Epoch 18, Batch 600] loss: 2.3049450397491453
[Epoch 18, Batch 700] loss: 2.3078936743736267
[Epoch 18, Batch 800] loss: 2.3073459815979005
[Epoch 18, Batch 900] loss: 2.3068795704841616
**STATS for Epoch 18** : 
Average training loss: 0.0935
Average validation loss: 2.3052
Validation Accuracy: 0.1126
Overfitting: 2.2117
[Epoch 19, Batch 100] loss: 2.307558629512787
[Epoch 19, Batch 200] loss: 2.3053337597846983
[Epoch 19, Batch 300] loss: 2.308179078102112
[Epoch 19, Batch 400] loss: 2.306589846611023
[Epoch 19, Batch 500] loss: 2.307101426124573
[Epoch 19, Batch 600] loss: 2.307370617389679
[Epoch 19, Batch 700] loss: 2.304922761917114
[Epoch 19, Batch 800] loss: 2.306511628627777
[Epoch 19, Batch 900] loss: 2.307066593170166
**STATS for Epoch 19** : 
Average training loss: 0.0934
Average validation loss: 2.3032
Validation Accuracy: 0.1126
Overfitting: 2.2098
[Epoch 20, Batch 100] loss: 2.3038483381271364
[Epoch 20, Batch 200] loss: 2.306782910823822
[Epoch 20, Batch 300] loss: 2.307847549915314
[Epoch 20, Batch 400] loss: 2.3058179211616516
[Epoch 20, Batch 500] loss: 2.3066063261032106
[Epoch 20, Batch 600] loss: 2.3092162871360777
[Epoch 20, Batch 700] loss: 2.3064904403686524
[Epoch 20, Batch 800] loss: 2.309148840904236
[Epoch 20, Batch 900] loss: 2.305745708942413
**STATS for Epoch 20** : 
Average training loss: 0.0934
Average validation loss: 2.3042
Validation Accuracy: 0.1037
Overfitting: 2.2108
[Epoch 21, Batch 100] loss: 2.305913116931915
[Epoch 21, Batch 200] loss: 2.304935290813446
[Epoch 21, Batch 300] loss: 2.3037544512748718
[Epoch 21, Batch 400] loss: 2.3072629261016844
[Epoch 21, Batch 500] loss: 2.308591923713684
[Epoch 21, Batch 600] loss: 2.305811529159546
[Epoch 21, Batch 700] loss: 2.3078747487068174
[Epoch 21, Batch 800] loss: 2.3072114968299866
[Epoch 21, Batch 900] loss: 2.304512574672699
**STATS for Epoch 21** : 
Average training loss: 0.0933
Average validation loss: 2.3058
Validation Accuracy: 0.0992
Overfitting: 2.2125
[Epoch 22, Batch 100] loss: 2.3085192918777464
[Epoch 22, Batch 200] loss: 2.3044428706169127
[Epoch 22, Batch 300] loss: 2.3075434494018556
[Epoch 22, Batch 400] loss: 2.306260530948639
[Epoch 22, Batch 500] loss: 2.30584094285965
[Epoch 22, Batch 600] loss: 2.3094675827026365
[Epoch 22, Batch 700] loss: 2.307658679485321
[Epoch 22, Batch 800] loss: 2.3089485454559324
[Epoch 22, Batch 900] loss: 2.3053546738624573
**STATS for Epoch 22** : 
Average training loss: 0.0934
Average validation loss: 2.3065
Validation Accuracy: 0.1052
Overfitting: 2.2131
[Epoch 23, Batch 100] loss: 2.308327651023865
[Epoch 23, Batch 200] loss: 2.3083722162246705
[Epoch 23, Batch 300] loss: 2.3069539976119997
[Epoch 23, Batch 400] loss: 2.3040581345558167
[Epoch 23, Batch 500] loss: 2.308851354122162
[Epoch 23, Batch 600] loss: 2.3070320749282835
[Epoch 23, Batch 700] loss: 2.3083161306381226
[Epoch 23, Batch 800] loss: 2.304159896373749
[Epoch 23, Batch 900] loss: 2.3073552441596985
**STATS for Epoch 23** : 
Average training loss: 0.0934
Average validation loss: 2.3051
Validation Accuracy: 0.1000
Overfitting: 2.2117
[Epoch 24, Batch 100] loss: 2.308021161556244
[Epoch 24, Batch 200] loss: 2.3059459257125856
[Epoch 24, Batch 300] loss: 2.3080972242355347
[Epoch 24, Batch 400] loss: 2.3037524032592773
[Epoch 24, Batch 500] loss: 2.3065660786628723
[Epoch 24, Batch 600] loss: 2.306656777858734
[Epoch 24, Batch 700] loss: 2.306827137470245
[Epoch 24, Batch 800] loss: 2.307383055686951
[Epoch 24, Batch 900] loss: 2.305468804836273
**STATS for Epoch 24** : 
Average training loss: 0.0938
Average validation loss: 2.3027
Validation Accuracy: 0.1126
Overfitting: 2.2089
Fold 2 validation loss: 2.3027
Mean validation loss across all folds for Trial 7 is 2.3053 with trial config:  l1: 320, l2: 64, lr: 0.07556810141274425, batch_size: 32
[I 2024-11-19 01:13:00,320] Trial 6 finished with value: 2.305256747360677 and parameters: {'l1': 320, 'l2': 64, 'lr': 0.07556810141274425, 'batch_size': 32}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 8:
  l1: 96, l2: 32, lr: 1.5167330688076188e-05, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.304313311576843
[Epoch 1, Batch 200] loss: 2.305083041191101
**STATS for Epoch 1** : 
Average training loss: 0.3432
Average validation loss: 2.3040
Validation Accuracy: 0.0594
Overfitting: 1.9608
Best model saved at epoch 1 with validation loss: 2.3040
[Epoch 2, Batch 100] loss: 2.303878264427185
[Epoch 2, Batch 200] loss: 2.303475270271301
**STATS for Epoch 2** : 
Average training loss: 0.3432
Average validation loss: 2.3031
Validation Accuracy: 0.0627
Overfitting: 1.9599
Best model saved at epoch 2 with validation loss: 2.3031
[Epoch 3, Batch 100] loss: 2.3028238892555235
[Epoch 3, Batch 200] loss: 2.3028934717178347
**STATS for Epoch 3** : 
Average training loss: 0.3429
Average validation loss: 2.3021
Validation Accuracy: 0.0665
Overfitting: 1.9592
Best model saved at epoch 3 with validation loss: 2.3021
[Epoch 4, Batch 100] loss: 2.30209272146225
[Epoch 4, Batch 200] loss: 2.301781668663025
**STATS for Epoch 4** : 
Average training loss: 0.3428
Average validation loss: 2.3011
Validation Accuracy: 0.0710
Overfitting: 1.9584
Best model saved at epoch 4 with validation loss: 2.3011
[Epoch 5, Batch 100] loss: 2.3010265469551086
[Epoch 5, Batch 200] loss: 2.3012473440170287
**STATS for Epoch 5** : 
Average training loss: 0.3425
Average validation loss: 2.3002
Validation Accuracy: 0.0751
Overfitting: 1.9577
Best model saved at epoch 5 with validation loss: 2.3002
[Epoch 6, Batch 100] loss: 2.299975357055664
[Epoch 6, Batch 200] loss: 2.300304892063141
**STATS for Epoch 6** : 
Average training loss: 0.3423
Average validation loss: 2.2992
Validation Accuracy: 0.0785
Overfitting: 1.9568
Best model saved at epoch 6 with validation loss: 2.2992
[Epoch 7, Batch 100] loss: 2.299398276805878
[Epoch 7, Batch 200] loss: 2.2986028742790223
**STATS for Epoch 7** : 
Average training loss: 0.3422
Average validation loss: 2.2980
Validation Accuracy: 0.0821
Overfitting: 1.9558
Best model saved at epoch 7 with validation loss: 2.2980
[Epoch 8, Batch 100] loss: 2.2975362038612364
[Epoch 8, Batch 200] loss: 2.297976813316345
**STATS for Epoch 8** : 
Average training loss: 0.3422
Average validation loss: 2.2970
Validation Accuracy: 0.0850
Overfitting: 1.9548
Best model saved at epoch 8 with validation loss: 2.2970
[Epoch 9, Batch 100] loss: 2.2978364062309264
[Epoch 9, Batch 200] loss: 2.2954759407043457
**STATS for Epoch 9** : 
Average training loss: 0.3420
Average validation loss: 2.2958
Validation Accuracy: 0.0884
Overfitting: 1.9538
Best model saved at epoch 9 with validation loss: 2.2958
[Epoch 10, Batch 100] loss: 2.295955035686493
[Epoch 10, Batch 200] loss: 2.295155897140503
**STATS for Epoch 10** : 
Average training loss: 0.3419
Average validation loss: 2.2948
Validation Accuracy: 0.0908
Overfitting: 1.9529
Best model saved at epoch 10 with validation loss: 2.2948
[Epoch 11, Batch 100] loss: 2.2951162528991698
[Epoch 11, Batch 200] loss: 2.2942688846588135
**STATS for Epoch 11** : 
Average training loss: 0.3416
Average validation loss: 2.2937
Validation Accuracy: 0.0936
Overfitting: 1.9521
Best model saved at epoch 11 with validation loss: 2.2937
[Epoch 12, Batch 100] loss: 2.293739445209503
[Epoch 12, Batch 200] loss: 2.2932906579971313
**STATS for Epoch 12** : 
Average training loss: 0.3416
Average validation loss: 2.2927
Validation Accuracy: 0.0955
Overfitting: 1.9511
Best model saved at epoch 12 with validation loss: 2.2927
[Epoch 13, Batch 100] loss: 2.292604730129242
[Epoch 13, Batch 200] loss: 2.292376070022583
**STATS for Epoch 13** : 
Average training loss: 0.3414
Average validation loss: 2.2916
Validation Accuracy: 0.0972
Overfitting: 1.9502
Best model saved at epoch 13 with validation loss: 2.2916
[Epoch 14, Batch 100] loss: 2.2919451928138734
[Epoch 14, Batch 200] loss: 2.2908046650886535
**STATS for Epoch 14** : 
Average training loss: 0.3412
Average validation loss: 2.2906
Validation Accuracy: 0.0989
Overfitting: 1.9493
Best model saved at epoch 14 with validation loss: 2.2906
[Epoch 15, Batch 100] loss: 2.290450782775879
[Epoch 15, Batch 200] loss: 2.2899381732940673
**STATS for Epoch 15** : 
Average training loss: 0.3412
Average validation loss: 2.2895
Validation Accuracy: 0.1001
Overfitting: 1.9482
Best model saved at epoch 15 with validation loss: 2.2895
[Epoch 16, Batch 100] loss: 2.289358067512512
[Epoch 16, Batch 200] loss: 2.289870545864105
**STATS for Epoch 16** : 
Average training loss: 0.3407
Average validation loss: 2.2884
Validation Accuracy: 0.1015
Overfitting: 1.9477
Best model saved at epoch 16 with validation loss: 2.2884
[Epoch 17, Batch 100] loss: 2.288734266757965
[Epoch 17, Batch 200] loss: 2.2874638271331786
**STATS for Epoch 17** : 
Average training loss: 0.3409
Average validation loss: 2.2873
Validation Accuracy: 0.1021
Overfitting: 1.9465
Best model saved at epoch 17 with validation loss: 2.2873
[Epoch 18, Batch 100] loss: 2.2873669505119323
[Epoch 18, Batch 200] loss: 2.2864879393577575
**STATS for Epoch 18** : 
Average training loss: 0.3407
Average validation loss: 2.2862
Validation Accuracy: 0.1026
Overfitting: 1.9454
Best model saved at epoch 18 with validation loss: 2.2862
[Epoch 19, Batch 100] loss: 2.2862173247337343
[Epoch 19, Batch 200] loss: 2.285984501838684
**STATS for Epoch 19** : 
Average training loss: 0.3403
Average validation loss: 2.2850
Validation Accuracy: 0.1037
Overfitting: 1.9448
Best model saved at epoch 19 with validation loss: 2.2850
[Epoch 20, Batch 100] loss: 2.2845751571655275
[Epoch 20, Batch 200] loss: 2.284872169494629
**STATS for Epoch 20** : 
Average training loss: 0.3404
Average validation loss: 2.2839
Validation Accuracy: 0.1045
Overfitting: 1.9435
Best model saved at epoch 20 with validation loss: 2.2839
[Epoch 21, Batch 100] loss: 2.28351185798645
[Epoch 21, Batch 200] loss: 2.2838567066192628
**STATS for Epoch 21** : 
Average training loss: 0.3400
Average validation loss: 2.2827
Validation Accuracy: 0.1048
Overfitting: 1.9426
Best model saved at epoch 21 with validation loss: 2.2827
[Epoch 22, Batch 100] loss: 2.2820203471183778
[Epoch 22, Batch 200] loss: 2.2823036241531374
**STATS for Epoch 22** : 
Average training loss: 0.3401
Average validation loss: 2.2814
Validation Accuracy: 0.1062
Overfitting: 1.9413
Best model saved at epoch 22 with validation loss: 2.2814
[Epoch 23, Batch 100] loss: 2.2819488191604616
[Epoch 23, Batch 200] loss: 2.2808881902694704
**STATS for Epoch 23** : 
Average training loss: 0.3395
Average validation loss: 2.2802
Validation Accuracy: 0.1069
Overfitting: 1.9407
Best model saved at epoch 23 with validation loss: 2.2802
[Epoch 24, Batch 100] loss: 2.2801005101203917
[Epoch 24, Batch 200] loss: 2.2801366448402405
**STATS for Epoch 24** : 
Average training loss: 0.3394
Average validation loss: 2.2790
Validation Accuracy: 0.1082
Overfitting: 1.9396
Best model saved at epoch 24 with validation loss: 2.2790
Fold 1 validation loss: 2.2790
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.3087939381599427
[Epoch 1, Batch 200] loss: 2.3101131772994994
**STATS for Epoch 1** : 
Average training loss: 0.3437
Average validation loss: 2.3081
Validation Accuracy: 0.0896
Overfitting: 1.9644
Best model saved at epoch 1 with validation loss: 2.3081
[Epoch 2, Batch 100] loss: 2.309720604419708
[Epoch 2, Batch 200] loss: 2.3076130509376527
**STATS for Epoch 2** : 
Average training loss: 0.3438
Average validation loss: 2.3075
Validation Accuracy: 0.0903
Overfitting: 1.9637
Best model saved at epoch 2 with validation loss: 2.3075
[Epoch 3, Batch 100] loss: 2.3095562052726746
[Epoch 3, Batch 200] loss: 2.3071427488327028
**STATS for Epoch 3** : 
Average training loss: 0.3434
Average validation loss: 2.3069
Validation Accuracy: 0.0907
Overfitting: 1.9635
Best model saved at epoch 3 with validation loss: 2.3069
[Epoch 4, Batch 100] loss: 2.3081302070617675
[Epoch 4, Batch 200] loss: 2.307623658180237
**STATS for Epoch 4** : 
Average training loss: 0.3432
Average validation loss: 2.3062
Validation Accuracy: 0.0911
Overfitting: 1.9630
Best model saved at epoch 4 with validation loss: 2.3062
[Epoch 5, Batch 100] loss: 2.305814995765686
[Epoch 5, Batch 200] loss: 2.307227635383606
**STATS for Epoch 5** : 
Average training loss: 0.3437
Average validation loss: 2.3056
Validation Accuracy: 0.0921
Overfitting: 1.9619
Best model saved at epoch 5 with validation loss: 2.3056
[Epoch 6, Batch 100] loss: 2.30574951171875
[Epoch 6, Batch 200] loss: 2.305677695274353
**STATS for Epoch 6** : 
Average training loss: 0.3437
Average validation loss: 2.3049
Validation Accuracy: 0.0925
Overfitting: 1.9612
Best model saved at epoch 6 with validation loss: 2.3049
[Epoch 7, Batch 100] loss: 2.304799721240997
[Epoch 7, Batch 200] loss: 2.3046336579322815
**STATS for Epoch 7** : 
Average training loss: 0.3439
Average validation loss: 2.3043
Validation Accuracy: 0.0929
Overfitting: 1.9604
Best model saved at epoch 7 with validation loss: 2.3043
[Epoch 8, Batch 100] loss: 2.306092200279236
[Epoch 8, Batch 200] loss: 2.3035352492332457
**STATS for Epoch 8** : 
Average training loss: 0.3433
Average validation loss: 2.3036
Validation Accuracy: 0.0932
Overfitting: 1.9604
Best model saved at epoch 8 with validation loss: 2.3036
[Epoch 9, Batch 100] loss: 2.303731462955475
[Epoch 9, Batch 200] loss: 2.304768776893616
**STATS for Epoch 9** : 
Average training loss: 0.3430
Average validation loss: 2.3029
Validation Accuracy: 0.0942
Overfitting: 1.9599
Best model saved at epoch 9 with validation loss: 2.3029
[Epoch 10, Batch 100] loss: 2.3044522523880007
[Epoch 10, Batch 200] loss: 2.302232303619385
**STATS for Epoch 10** : 
Average training loss: 0.3432
Average validation loss: 2.3023
Validation Accuracy: 0.0950
Overfitting: 1.9591
Best model saved at epoch 10 with validation loss: 2.3023
[Epoch 11, Batch 100] loss: 2.3038981556892395
[Epoch 11, Batch 200] loss: 2.301962203979492
**STATS for Epoch 11** : 
Average training loss: 0.3427
Average validation loss: 2.3016
Validation Accuracy: 0.0957
Overfitting: 1.9589
Best model saved at epoch 11 with validation loss: 2.3016
[Epoch 12, Batch 100] loss: 2.30138667345047
[Epoch 12, Batch 200] loss: 2.3031399703025817
**STATS for Epoch 12** : 
Average training loss: 0.3427
Average validation loss: 2.3009
Validation Accuracy: 0.0974
Overfitting: 1.9582
Best model saved at epoch 12 with validation loss: 2.3009
[Epoch 13, Batch 100] loss: 2.302872648239136
[Epoch 13, Batch 200] loss: 2.3001968121528624
**STATS for Epoch 13** : 
Average training loss: 0.3427
Average validation loss: 2.3003
Validation Accuracy: 0.0987
Overfitting: 1.9577
Best model saved at epoch 13 with validation loss: 2.3003
[Epoch 14, Batch 100] loss: 2.300970573425293
[Epoch 14, Batch 200] loss: 2.3001358127593994
**STATS for Epoch 14** : 
Average training loss: 0.3427
Average validation loss: 2.2995
Validation Accuracy: 0.1006
Overfitting: 1.9568
Best model saved at epoch 14 with validation loss: 2.2995
[Epoch 15, Batch 100] loss: 2.300933494567871
[Epoch 15, Batch 200] loss: 2.2979767107963562
**STATS for Epoch 15** : 
Average training loss: 0.3429
Average validation loss: 2.2987
Validation Accuracy: 0.1025
Overfitting: 1.9558
Best model saved at epoch 15 with validation loss: 2.2987
[Epoch 16, Batch 100] loss: 2.301711127758026
[Epoch 16, Batch 200] loss: 2.2966239261627197
**STATS for Epoch 16** : 
Average training loss: 0.3424
Average validation loss: 2.2980
Validation Accuracy: 0.1049
Overfitting: 1.9556
Best model saved at epoch 16 with validation loss: 2.2980
[Epoch 17, Batch 100] loss: 2.2976110887527468
[Epoch 17, Batch 200] loss: 2.2993235349655152
**STATS for Epoch 17** : 
Average training loss: 0.3421
Average validation loss: 2.2972
Validation Accuracy: 0.1081
Overfitting: 1.9550
Best model saved at epoch 17 with validation loss: 2.2972
[Epoch 18, Batch 100] loss: 2.2968795895576477
[Epoch 18, Batch 200] loss: 2.2976206135749817
**STATS for Epoch 18** : 
Average training loss: 0.3424
Average validation loss: 2.2963
Validation Accuracy: 0.1106
Overfitting: 1.9540
Best model saved at epoch 18 with validation loss: 2.2963
[Epoch 19, Batch 100] loss: 2.2960490942001344
[Epoch 19, Batch 200] loss: 2.29688462972641
**STATS for Epoch 19** : 
Average training loss: 0.3422
Average validation loss: 2.2955
Validation Accuracy: 0.1135
Overfitting: 1.9533
Best model saved at epoch 19 with validation loss: 2.2955
[Epoch 20, Batch 100] loss: 2.2962557768821714
[Epoch 20, Batch 200] loss: 2.2956978273391724
**STATS for Epoch 20** : 
Average training loss: 0.3418
Average validation loss: 2.2947
Validation Accuracy: 0.1159
Overfitting: 1.9529
Best model saved at epoch 20 with validation loss: 2.2947
[Epoch 21, Batch 100] loss: 2.295191178321838
[Epoch 21, Batch 200] loss: 2.2947732615470886
**STATS for Epoch 21** : 
Average training loss: 0.3419
Average validation loss: 2.2939
Validation Accuracy: 0.1183
Overfitting: 1.9520
Best model saved at epoch 21 with validation loss: 2.2939
[Epoch 22, Batch 100] loss: 2.2947181153297422
[Epoch 22, Batch 200] loss: 2.293385610580444
**STATS for Epoch 22** : 
Average training loss: 0.3418
Average validation loss: 2.2930
Validation Accuracy: 0.1191
Overfitting: 1.9512
Best model saved at epoch 22 with validation loss: 2.2930
[Epoch 23, Batch 100] loss: 2.295053071975708
[Epoch 23, Batch 200] loss: 2.292316744327545
**STATS for Epoch 23** : 
Average training loss: 0.3411
Average validation loss: 2.2921
Validation Accuracy: 0.1210
Overfitting: 1.9510
Best model saved at epoch 23 with validation loss: 2.2921
[Epoch 24, Batch 100] loss: 2.2925474357604982
[Epoch 24, Batch 200] loss: 2.2917456078529357
**STATS for Epoch 24** : 
Average training loss: 0.3417
Average validation loss: 2.2913
Validation Accuracy: 0.1226
Overfitting: 1.9496
Best model saved at epoch 24 with validation loss: 2.2913
Fold 2 validation loss: 2.2913
Mean validation loss across all folds for Trial 8 is 2.2851 with trial config:  l1: 96, l2: 32, lr: 1.5167330688076188e-05, batch_size: 128
[I 2024-11-19 01:21:28,045] Trial 7 finished with value: 2.2851222773815723 and parameters: {'l1': 96, 'l2': 32, 'lr': 1.5167330688076188e-05, 'batch_size': 128}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 9:
  l1: 352, l2: 224, lr: 0.03870856382081391, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.9239533084630966
**STATS for Epoch 1** : 
Average training loss: 0.1074
Average validation loss: 0.6715
Validation Accuracy: 0.7798
Overfitting: 0.5642
Best model saved at epoch 1 with validation loss: 0.6715
[Epoch 2, Batch 100] loss: 0.3706047849357128
**STATS for Epoch 2** : 
Average training loss: 0.0326
Average validation loss: 0.2055
Validation Accuracy: 0.9336
Overfitting: 0.1728
Best model saved at epoch 2 with validation loss: 0.2055
[Epoch 3, Batch 100] loss: 0.14101586241275071
**STATS for Epoch 3** : 
Average training loss: 0.0178
Average validation loss: 0.1442
Validation Accuracy: 0.9548
Overfitting: 0.1264
Best model saved at epoch 3 with validation loss: 0.1442
[Epoch 4, Batch 100] loss: 0.09307587299495935
**STATS for Epoch 4** : 
Average training loss: 0.0123
Average validation loss: 0.1153
Validation Accuracy: 0.9642
Overfitting: 0.1030
Best model saved at epoch 4 with validation loss: 0.1153
[Epoch 5, Batch 100] loss: 0.06508027479052543
**STATS for Epoch 5** : 
Average training loss: 0.0089
Average validation loss: 0.0800
Validation Accuracy: 0.9762
Overfitting: 0.0711
Best model saved at epoch 5 with validation loss: 0.0800
[Epoch 6, Batch 100] loss: 0.054887415249831976
**STATS for Epoch 6** : 
Average training loss: 0.0086
Average validation loss: 0.0736
Validation Accuracy: 0.9780
Overfitting: 0.0649
Best model saved at epoch 6 with validation loss: 0.0736
[Epoch 7, Batch 100] loss: 0.04424717627465725
**STATS for Epoch 7** : 
Average training loss: 0.0077
Average validation loss: 0.0803
Validation Accuracy: 0.9770
Overfitting: 0.0727
[Epoch 8, Batch 100] loss: 0.03728726400062442
**STATS for Epoch 8** : 
Average training loss: 0.0056
Average validation loss: 0.0641
Validation Accuracy: 0.9812
Overfitting: 0.0586
Best model saved at epoch 8 with validation loss: 0.0641
[Epoch 9, Batch 100] loss: 0.03125456591602415
**STATS for Epoch 9** : 
Average training loss: 0.0058
Average validation loss: 0.0614
Validation Accuracy: 0.9831
Overfitting: 0.0556
Best model saved at epoch 9 with validation loss: 0.0614
[Epoch 10, Batch 100] loss: 0.03562569757457822
**STATS for Epoch 10** : 
Average training loss: 0.0047
Average validation loss: 0.0724
Validation Accuracy: 0.9791
Overfitting: 0.0678
[Epoch 11, Batch 100] loss: 0.02611628796439618
**STATS for Epoch 11** : 
Average training loss: 0.0053
Average validation loss: 0.0750
Validation Accuracy: 0.9797
Overfitting: 0.0697
[Epoch 12, Batch 100] loss: 0.02679476798279211
**STATS for Epoch 12** : 
Average training loss: 0.0040
Average validation loss: 0.0786
Validation Accuracy: 0.9795
Overfitting: 0.0747
[Epoch 13, Batch 100] loss: 0.021201293864287436
**STATS for Epoch 13** : 
Average training loss: 0.0030
Average validation loss: 0.0677
Validation Accuracy: 0.9831
Overfitting: 0.0648
[Epoch 14, Batch 100] loss: 0.01631823248346336
**STATS for Epoch 14** : 
Average training loss: 0.0029
Average validation loss: 0.0738
Validation Accuracy: 0.9819
Overfitting: 0.0709
[Epoch 15, Batch 100] loss: 0.014925479721277952
**STATS for Epoch 15** : 
Average training loss: 0.0028
Average validation loss: 0.0776
Validation Accuracy: 0.9815
Overfitting: 0.0748
[Epoch 16, Batch 100] loss: 0.010471124000032432
**STATS for Epoch 16** : 
Average training loss: 0.0022
Average validation loss: 0.0731
Validation Accuracy: 0.9818
Overfitting: 0.0709
[Epoch 17, Batch 100] loss: 0.0074340017914073546
**STATS for Epoch 17** : 
Average training loss: 0.0020
Average validation loss: 0.0720
Validation Accuracy: 0.9835
Overfitting: 0.0700
[Epoch 18, Batch 100] loss: 0.011005681577371433
**STATS for Epoch 18** : 
Average training loss: 0.0013
Average validation loss: 0.0838
Validation Accuracy: 0.9817
Overfitting: 0.0825
[Epoch 19, Batch 100] loss: 0.00772698361746734
**STATS for Epoch 19** : 
Average training loss: 0.0013
Average validation loss: 0.0745
Validation Accuracy: 0.9832
Overfitting: 0.0733
[Epoch 20, Batch 100] loss: 0.009180124123813584
**STATS for Epoch 20** : 
Average training loss: 0.0028
Average validation loss: 0.0841
Validation Accuracy: 0.9819
Overfitting: 0.0813
[Epoch 21, Batch 100] loss: 0.010163402305333875
**STATS for Epoch 21** : 
Average training loss: 0.0022
Average validation loss: 0.0741
Validation Accuracy: 0.9832
Overfitting: 0.0718
[Epoch 22, Batch 100] loss: 0.009136198949709068
**STATS for Epoch 22** : 
Average training loss: 0.0010
Average validation loss: 0.1001
Validation Accuracy: 0.9799
Overfitting: 0.0991
[Epoch 23, Batch 100] loss: 0.004643241658777697
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0786
Validation Accuracy: 0.9839
Overfitting: 0.0781
[Epoch 24, Batch 100] loss: 0.0030152150118374268
**STATS for Epoch 24** : 
Average training loss: 0.0007
Average validation loss: 0.1072
Validation Accuracy: 0.9806
Overfitting: 0.1065
Fold 1 validation loss: 0.1072
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 0.9248480804264545
**STATS for Epoch 1** : 
Average training loss: 0.0214
Average validation loss: 0.1431
Validation Accuracy: 0.9577
Overfitting: 0.1217
Best model saved at epoch 1 with validation loss: 0.1431
[Epoch 2, Batch 100] loss: 0.11153232548385858
**STATS for Epoch 2** : 
Average training loss: 0.0157
Average validation loss: 0.0978
Validation Accuracy: 0.9695
Overfitting: 0.0822
Best model saved at epoch 2 with validation loss: 0.0978
[Epoch 3, Batch 100] loss: 0.07807410903275012
**STATS for Epoch 3** : 
Average training loss: 0.0093
Average validation loss: 0.0804
Validation Accuracy: 0.9756
Overfitting: 0.0711
Best model saved at epoch 3 with validation loss: 0.0804
[Epoch 4, Batch 100] loss: 0.052128385175019505
**STATS for Epoch 4** : 
Average training loss: 0.0068
Average validation loss: 0.0720
Validation Accuracy: 0.9775
Overfitting: 0.0652
Best model saved at epoch 4 with validation loss: 0.0720
[Epoch 5, Batch 100] loss: 0.040655266372486946
**STATS for Epoch 5** : 
Average training loss: 0.0049
Average validation loss: 0.0787
Validation Accuracy: 0.9766
Overfitting: 0.0739
[Epoch 6, Batch 100] loss: 0.03227694591507316
**STATS for Epoch 6** : 
Average training loss: 0.0048
Average validation loss: 0.0590
Validation Accuracy: 0.9825
Overfitting: 0.0542
Best model saved at epoch 6 with validation loss: 0.0590
[Epoch 7, Batch 100] loss: 0.029648492499254643
**STATS for Epoch 7** : 
Average training loss: 0.0055
Average validation loss: 0.0717
Validation Accuracy: 0.9808
Overfitting: 0.0662
[Epoch 8, Batch 100] loss: 0.02070679489057511
**STATS for Epoch 8** : 
Average training loss: 0.0042
Average validation loss: 0.0659
Validation Accuracy: 0.9813
Overfitting: 0.0617
[Epoch 9, Batch 100] loss: 0.02954138587228954
**STATS for Epoch 9** : 
Average training loss: 0.0041
Average validation loss: 0.0689
Validation Accuracy: 0.9817
Overfitting: 0.0649
[Epoch 10, Batch 100] loss: 0.015720185674726963
**STATS for Epoch 10** : 
Average training loss: 0.0020
Average validation loss: 0.0647
Validation Accuracy: 0.9829
Overfitting: 0.0627
[Epoch 11, Batch 100] loss: 0.010589390018722042
**STATS for Epoch 11** : 
Average training loss: 0.0019
Average validation loss: 0.0615
Validation Accuracy: 0.9840
Overfitting: 0.0596
[Epoch 12, Batch 100] loss: 0.009698683310998603
**STATS for Epoch 12** : 
Average training loss: 0.0016
Average validation loss: 0.0633
Validation Accuracy: 0.9852
Overfitting: 0.0617
[Epoch 13, Batch 100] loss: 0.01021385915344581
**STATS for Epoch 13** : 
Average training loss: 0.0012
Average validation loss: 0.0645
Validation Accuracy: 0.9858
Overfitting: 0.0632
[Epoch 14, Batch 100] loss: 0.010622030924278079
**STATS for Epoch 14** : 
Average training loss: 0.0019
Average validation loss: 0.0669
Validation Accuracy: 0.9842
Overfitting: 0.0650
[Epoch 15, Batch 100] loss: 0.005572494833468227
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0638
Validation Accuracy: 0.9860
Overfitting: 0.0631
[Epoch 16, Batch 100] loss: 0.003783994124896708
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0645
Validation Accuracy: 0.9866
Overfitting: 0.0637
[Epoch 17, Batch 100] loss: 0.0024665801010269207
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0686
Validation Accuracy: 0.9858
Overfitting: 0.0680
[Epoch 18, Batch 100] loss: 0.002712799829132564
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0778
Validation Accuracy: 0.9853
Overfitting: 0.0776
[Epoch 19, Batch 100] loss: 0.0020954755824641323
**STATS for Epoch 19** : 
Average training loss: 0.0015
Average validation loss: 0.0843
Validation Accuracy: 0.9833
Overfitting: 0.0828
[Epoch 20, Batch 100] loss: 0.00790765490150079
**STATS for Epoch 20** : 
Average training loss: 0.0012
Average validation loss: 0.0790
Validation Accuracy: 0.9852
Overfitting: 0.0778
[Epoch 21, Batch 100] loss: 0.011298796836344991
**STATS for Epoch 21** : 
Average training loss: 0.0010
Average validation loss: 0.0764
Validation Accuracy: 0.9846
Overfitting: 0.0754
[Epoch 22, Batch 100] loss: 0.004764591171697248
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0683
Validation Accuracy: 0.9867
Overfitting: 0.0679
[Epoch 23, Batch 100] loss: 0.0017350728174642426
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0668
Validation Accuracy: 0.9871
Overfitting: 0.0666
[Epoch 24, Batch 100] loss: 0.0004164861640401796
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0758
Validation Accuracy: 0.9859
Overfitting: 0.0754
Fold 2 validation loss: 0.0758
Mean validation loss across all folds for Trial 9 is 0.0915 with trial config:  l1: 352, l2: 224, lr: 0.03870856382081391, batch_size: 256
[I 2024-11-19 01:29:35,898] Trial 8 finished with value: 0.09145822434615092 and parameters: {'l1': 352, 'l2': 224, 'lr': 0.03870856382081391, 'batch_size': 256}. Best is trial 0 with value: 0.05886771301817843.
[W 2024-11-19 01:29:35,931] The parameter 'l2' in trial#9 is sampled independently instead of being sampled by multivariate TPE sampler. (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler`, if this independent sampling is intended behavior.

Selected Hyperparameters for Trial 10:
  l1: 96, l2: 96, lr: 0.00946889520909023, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.9389704820513725
[Epoch 1, Batch 200] loss: 0.42655423656105995
[Epoch 1, Batch 300] loss: 0.21129930272698402
[Epoch 1, Batch 400] loss: 0.17665661653503775
**STATS for Epoch 1** : 
Average training loss: 0.0188
Average validation loss: 0.1323
Validation Accuracy: 0.9576
Overfitting: 0.1135
Best model saved at epoch 1 with validation loss: 0.1323
[Epoch 2, Batch 100] loss: 0.11111401330213994
[Epoch 2, Batch 200] loss: 0.09961853072978556
[Epoch 2, Batch 300] loss: 0.10879495558328926
[Epoch 2, Batch 400] loss: 0.08252071246504783
**STATS for Epoch 2** : 
Average training loss: 0.0143
Average validation loss: 0.0949
Validation Accuracy: 0.9686
Overfitting: 0.0807
Best model saved at epoch 2 with validation loss: 0.0949
[Epoch 3, Batch 100] loss: 0.0674980860389769
[Epoch 3, Batch 200] loss: 0.06938557615503668
[Epoch 3, Batch 300] loss: 0.07287032393272966
[Epoch 3, Batch 400] loss: 0.07077694916632027
**STATS for Epoch 3** : 
Average training loss: 0.0112
Average validation loss: 0.0725
Validation Accuracy: 0.9776
Overfitting: 0.0613
Best model saved at epoch 3 with validation loss: 0.0725
[Epoch 4, Batch 100] loss: 0.05583342222846113
[Epoch 4, Batch 200] loss: 0.058906040354631845
[Epoch 4, Batch 300] loss: 0.052643065951997414
[Epoch 4, Batch 400] loss: 0.05468828260549344
**STATS for Epoch 4** : 
Average training loss: 0.0072
Average validation loss: 0.0675
Validation Accuracy: 0.9788
Overfitting: 0.0603
Best model saved at epoch 4 with validation loss: 0.0675
[Epoch 5, Batch 100] loss: 0.04337742114556022
[Epoch 5, Batch 200] loss: 0.04587798583321273
[Epoch 5, Batch 300] loss: 0.05031120885163545
[Epoch 5, Batch 400] loss: 0.040482005913509055
**STATS for Epoch 5** : 
Average training loss: 0.0079
Average validation loss: 0.0685
Validation Accuracy: 0.9799
Overfitting: 0.0607
[Epoch 6, Batch 100] loss: 0.03500589156174101
[Epoch 6, Batch 200] loss: 0.03557264880219009
[Epoch 6, Batch 300] loss: 0.04487116297124885
[Epoch 6, Batch 400] loss: 0.03531347716925666
**STATS for Epoch 6** : 
Average training loss: 0.0059
Average validation loss: 0.0641
Validation Accuracy: 0.9812
Overfitting: 0.0583
Best model saved at epoch 6 with validation loss: 0.0641
[Epoch 7, Batch 100] loss: 0.029099060790613293
[Epoch 7, Batch 200] loss: 0.024788276058388875
[Epoch 7, Batch 300] loss: 0.02763358187919948
[Epoch 7, Batch 400] loss: 0.03292704084771685
**STATS for Epoch 7** : 
Average training loss: 0.0047
Average validation loss: 0.0632
Validation Accuracy: 0.9813
Overfitting: 0.0585
Best model saved at epoch 7 with validation loss: 0.0632
[Epoch 8, Batch 100] loss: 0.026641571008949542
[Epoch 8, Batch 200] loss: 0.023276596184296068
[Epoch 8, Batch 300] loss: 0.02505422414804343
[Epoch 8, Batch 400] loss: 0.026914584095648023
**STATS for Epoch 8** : 
Average training loss: 0.0043
Average validation loss: 0.0574
Validation Accuracy: 0.9838
Overfitting: 0.0531
Best model saved at epoch 8 with validation loss: 0.0574
[Epoch 9, Batch 100] loss: 0.015516655192768666
[Epoch 9, Batch 200] loss: 0.01489084848522907
[Epoch 9, Batch 300] loss: 0.02667401203594636
[Epoch 9, Batch 400] loss: 0.028326916925143452
**STATS for Epoch 9** : 
Average training loss: 0.0031
Average validation loss: 0.0668
Validation Accuracy: 0.9818
Overfitting: 0.0637
[Epoch 10, Batch 100] loss: 0.014972185861552134
[Epoch 10, Batch 200] loss: 0.019108914756798184
[Epoch 10, Batch 300] loss: 0.018623557647224516
[Epoch 10, Batch 400] loss: 0.023485687686043092
**STATS for Epoch 10** : 
Average training loss: 0.0025
Average validation loss: 0.0670
Validation Accuracy: 0.9829
Overfitting: 0.0645
[Epoch 11, Batch 100] loss: 0.011913880324573255
[Epoch 11, Batch 200] loss: 0.016436783944809578
[Epoch 11, Batch 300] loss: 0.017965922678631615
[Epoch 11, Batch 400] loss: 0.012842205759370699
**STATS for Epoch 11** : 
Average training loss: 0.0026
Average validation loss: 0.0673
Validation Accuracy: 0.9821
Overfitting: 0.0647
[Epoch 12, Batch 100] loss: 0.01085567534682923
[Epoch 12, Batch 200] loss: 0.009566308653011219
[Epoch 12, Batch 300] loss: 0.019136399983399315
[Epoch 12, Batch 400] loss: 0.013435645959689282
**STATS for Epoch 12** : 
Average training loss: 0.0025
Average validation loss: 0.0681
Validation Accuracy: 0.9839
Overfitting: 0.0656
[Epoch 13, Batch 100] loss: 0.009447923260540846
[Epoch 13, Batch 200] loss: 0.011322817818872864
[Epoch 13, Batch 300] loss: 0.017978924090130022
[Epoch 13, Batch 400] loss: 0.01416790941861109
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0692
Validation Accuracy: 0.9835
Overfitting: 0.0677
[Epoch 14, Batch 100] loss: 0.008229092028341257
[Epoch 14, Batch 200] loss: 0.00893721235828707
[Epoch 14, Batch 300] loss: 0.014600150486003258
[Epoch 14, Batch 400] loss: 0.011798277696652804
**STATS for Epoch 14** : 
Average training loss: 0.0017
Average validation loss: 0.0613
Validation Accuracy: 0.9851
Overfitting: 0.0596
[Epoch 15, Batch 100] loss: 0.005415308552619536
[Epoch 15, Batch 200] loss: 0.0046283580474482736
[Epoch 15, Batch 300] loss: 0.006183261822880013
[Epoch 15, Batch 400] loss: 0.0073065017536282535
**STATS for Epoch 15** : 
Average training loss: 0.0016
Average validation loss: 0.0754
Validation Accuracy: 0.9829
Overfitting: 0.0739
[Epoch 16, Batch 100] loss: 0.0032769405656290474
[Epoch 16, Batch 200] loss: 0.005941008687004796
[Epoch 16, Batch 300] loss: 0.010200292713088857
[Epoch 16, Batch 400] loss: 0.010817702048443607
**STATS for Epoch 16** : 
Average training loss: 0.0013
Average validation loss: 0.0736
Validation Accuracy: 0.9838
Overfitting: 0.0723
[Epoch 17, Batch 100] loss: 0.011582206129205588
[Epoch 17, Batch 200] loss: 0.0074098546560162504
[Epoch 17, Batch 300] loss: 0.0041626229647681616
[Epoch 17, Batch 400] loss: 0.004751616594849111
**STATS for Epoch 17** : 
Average training loss: 0.0010
Average validation loss: 0.0710
Validation Accuracy: 0.9852
Overfitting: 0.0700
[Epoch 18, Batch 100] loss: 0.0058559866062205404
[Epoch 18, Batch 200] loss: 0.00587867968768478
[Epoch 18, Batch 300] loss: 0.007993283900868847
[Epoch 18, Batch 400] loss: 0.005227234493222568
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0755
Validation Accuracy: 0.9852
Overfitting: 0.0748
[Epoch 19, Batch 100] loss: 0.014675836578198868
[Epoch 19, Batch 200] loss: 0.012421365901900572
[Epoch 19, Batch 300] loss: 0.01252336356894375
[Epoch 19, Batch 400] loss: 0.00906809095027711
**STATS for Epoch 19** : 
Average training loss: 0.0014
Average validation loss: 0.0678
Validation Accuracy: 0.9850
Overfitting: 0.0664
[Epoch 20, Batch 100] loss: 0.004645173301760223
[Epoch 20, Batch 200] loss: 0.003036741942438539
[Epoch 20, Batch 300] loss: 0.009336021753797467
[Epoch 20, Batch 400] loss: 0.014932293531965115
**STATS for Epoch 20** : 
Average training loss: 0.0016
Average validation loss: 0.0779
Validation Accuracy: 0.9841
Overfitting: 0.0764
[Epoch 21, Batch 100] loss: 0.007195051488924947
[Epoch 21, Batch 200] loss: 0.0045617572688070145
[Epoch 21, Batch 300] loss: 0.0028548458333125383
[Epoch 21, Batch 400] loss: 0.002967044595116022
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0742
Validation Accuracy: 0.9857
Overfitting: 0.0740
[Epoch 22, Batch 100] loss: 0.0016714727985402077
[Epoch 22, Batch 200] loss: 0.00180232419266531
[Epoch 22, Batch 300] loss: 0.003912825870620509
[Epoch 22, Batch 400] loss: 0.004009736703485487
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0759
Validation Accuracy: 0.9854
Overfitting: 0.0756
[Epoch 23, Batch 100] loss: 0.0021273245617157953
[Epoch 23, Batch 200] loss: 0.0019809163954096222
[Epoch 23, Batch 300] loss: 0.0007968048338307199
[Epoch 23, Batch 400] loss: 0.001306995236440116
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0779
Validation Accuracy: 0.9862
Overfitting: 0.0778
[Epoch 24, Batch 100] loss: 0.001510168117312105
[Epoch 24, Batch 200] loss: 0.0004557916775911508
[Epoch 24, Batch 300] loss: 0.0009924888652805919
[Epoch 24, Batch 400] loss: 0.0013993931914660607
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0753
Validation Accuracy: 0.9868
Overfitting: 0.0753
Fold 1 validation loss: 0.0753
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.593832096159458
[Epoch 1, Batch 200] loss: 0.41163446366786954
[Epoch 1, Batch 300] loss: 0.2581895747408271
[Epoch 1, Batch 400] loss: 0.1754645911604166
**STATS for Epoch 1** : 
Average training loss: 0.0208
Average validation loss: 0.1330
Validation Accuracy: 0.9577
Overfitting: 0.1122
Best model saved at epoch 1 with validation loss: 0.1330
[Epoch 2, Batch 100] loss: 0.13396749187260867
[Epoch 2, Batch 200] loss: 0.11362574445083737
[Epoch 2, Batch 300] loss: 0.10122151329182089
[Epoch 2, Batch 400] loss: 0.09330317163374274
**STATS for Epoch 2** : 
Average training loss: 0.0120
Average validation loss: 0.0945
Validation Accuracy: 0.9708
Overfitting: 0.0825
Best model saved at epoch 2 with validation loss: 0.0945
[Epoch 3, Batch 100] loss: 0.06376579043921084
[Epoch 3, Batch 200] loss: 0.07372682204004377
[Epoch 3, Batch 300] loss: 0.0722433306882158
[Epoch 3, Batch 400] loss: 0.07086723504588008
**STATS for Epoch 3** : 
Average training loss: 0.0123
Average validation loss: 0.0709
Validation Accuracy: 0.9781
Overfitting: 0.0586
Best model saved at epoch 3 with validation loss: 0.0709
[Epoch 4, Batch 100] loss: 0.0523707524035126
[Epoch 4, Batch 200] loss: 0.05769226692733355
[Epoch 4, Batch 300] loss: 0.05787053864682093
[Epoch 4, Batch 400] loss: 0.05094959662295878
**STATS for Epoch 4** : 
Average training loss: 0.0079
Average validation loss: 0.0628
Validation Accuracy: 0.9813
Overfitting: 0.0549
Best model saved at epoch 4 with validation loss: 0.0628
[Epoch 5, Batch 100] loss: 0.039794986881315705
[Epoch 5, Batch 200] loss: 0.04320129744242877
[Epoch 5, Batch 300] loss: 0.044637513300403955
[Epoch 5, Batch 400] loss: 0.05412968811695464
**STATS for Epoch 5** : 
Average training loss: 0.0063
Average validation loss: 0.0666
Validation Accuracy: 0.9806
Overfitting: 0.0603
[Epoch 6, Batch 100] loss: 0.03256018452928402
[Epoch 6, Batch 200] loss: 0.02711789437831612
[Epoch 6, Batch 300] loss: 0.03954555348027498
[Epoch 6, Batch 400] loss: 0.04083233330631628
**STATS for Epoch 6** : 
Average training loss: 0.0048
Average validation loss: 0.0669
Validation Accuracy: 0.9803
Overfitting: 0.0620
[Epoch 7, Batch 100] loss: 0.025488882607314734
[Epoch 7, Batch 200] loss: 0.03280183666560333
[Epoch 7, Batch 300] loss: 0.029529440391343087
[Epoch 7, Batch 400] loss: 0.025067318752408026
**STATS for Epoch 7** : 
Average training loss: 0.0051
Average validation loss: 0.0633
Validation Accuracy: 0.9825
Overfitting: 0.0582
[Epoch 8, Batch 100] loss: 0.02832592665508855
[Epoch 8, Batch 200] loss: 0.02447414467053022
[Epoch 8, Batch 300] loss: 0.026023736018687488
[Epoch 8, Batch 400] loss: 0.023356593228236307
**STATS for Epoch 8** : 
Average training loss: 0.0040
Average validation loss: 0.0651
Validation Accuracy: 0.9822
Overfitting: 0.0611
[Epoch 9, Batch 100] loss: 0.02498780145208002
[Epoch 9, Batch 200] loss: 0.01836413347744383
[Epoch 9, Batch 300] loss: 0.021654203767102444
[Epoch 9, Batch 400] loss: 0.022019349100010004
**STATS for Epoch 9** : 
Average training loss: 0.0047
Average validation loss: 0.0633
Validation Accuracy: 0.9823
Overfitting: 0.0586
[Epoch 10, Batch 100] loss: 0.012867692698200699
[Epoch 10, Batch 200] loss: 0.01671587193821324
[Epoch 10, Batch 300] loss: 0.01944127446884522
[Epoch 10, Batch 400] loss: 0.019236280768673168
**STATS for Epoch 10** : 
Average training loss: 0.0021
Average validation loss: 0.0559
Validation Accuracy: 0.9855
Overfitting: 0.0538
Best model saved at epoch 10 with validation loss: 0.0559
[Epoch 11, Batch 100] loss: 0.011730562551529147
[Epoch 11, Batch 200] loss: 0.01215360701244208
[Epoch 11, Batch 300] loss: 0.01918901332668611
[Epoch 11, Batch 400] loss: 0.018245321829308523
**STATS for Epoch 11** : 
Average training loss: 0.0022
Average validation loss: 0.0586
Validation Accuracy: 0.9845
Overfitting: 0.0564
[Epoch 12, Batch 100] loss: 0.011767365476625855
[Epoch 12, Batch 200] loss: 0.00827397871777066
[Epoch 12, Batch 300] loss: 0.013223402403018553
[Epoch 12, Batch 400] loss: 0.011592066928878922
**STATS for Epoch 12** : 
Average training loss: 0.0048
Average validation loss: 0.0856
Validation Accuracy: 0.9786
Overfitting: 0.0808
[Epoch 13, Batch 100] loss: 0.014525459481519646
[Epoch 13, Batch 200] loss: 0.012156014323845738
[Epoch 13, Batch 300] loss: 0.00962995324073745
[Epoch 13, Batch 400] loss: 0.017400504109682514
**STATS for Epoch 13** : 
Average training loss: 0.0016
Average validation loss: 0.0581
Validation Accuracy: 0.9856
Overfitting: 0.0565
[Epoch 14, Batch 100] loss: 0.005155990458151791
[Epoch 14, Batch 200] loss: 0.00896568651751295
[Epoch 14, Batch 300] loss: 0.009964041560688202
[Epoch 14, Batch 400] loss: 0.008339703338970139
**STATS for Epoch 14** : 
Average training loss: 0.0014
Average validation loss: 0.0623
Validation Accuracy: 0.9857
Overfitting: 0.0609
[Epoch 15, Batch 100] loss: 0.0055057935964850915
[Epoch 15, Batch 200] loss: 0.006746851438510931
[Epoch 15, Batch 300] loss: 0.01777871108184627
[Epoch 15, Batch 400] loss: 0.015797008109548188
**STATS for Epoch 15** : 
Average training loss: 0.0015
Average validation loss: 0.0737
Validation Accuracy: 0.9833
Overfitting: 0.0722
[Epoch 16, Batch 100] loss: 0.010676586036133813
[Epoch 16, Batch 200] loss: 0.012911334962918773
[Epoch 16, Batch 300] loss: 0.014205433271890798
[Epoch 16, Batch 400] loss: 0.008645354100699477
**STATS for Epoch 16** : 
Average training loss: 0.0011
Average validation loss: 0.0641
Validation Accuracy: 0.9852
Overfitting: 0.0631
[Epoch 17, Batch 100] loss: 0.0034543428752294857
[Epoch 17, Batch 200] loss: 0.002678536802641247
[Epoch 17, Batch 300] loss: 0.006835197842437992
[Epoch 17, Batch 400] loss: 0.012411026682602824
**STATS for Epoch 17** : 
Average training loss: 0.0012
Average validation loss: 0.0668
Validation Accuracy: 0.9848
Overfitting: 0.0657
[Epoch 18, Batch 100] loss: 0.006929118856050991
[Epoch 18, Batch 200] loss: 0.004593972739712626
[Epoch 18, Batch 300] loss: 0.006009683877800853
[Epoch 18, Batch 400] loss: 0.0066065300582704364
**STATS for Epoch 18** : 
Average training loss: 0.0011
Average validation loss: 0.0648
Validation Accuracy: 0.9856
Overfitting: 0.0638
[Epoch 19, Batch 100] loss: 0.004005923197491938
[Epoch 19, Batch 200] loss: 0.004842048534774221
[Epoch 19, Batch 300] loss: 0.002888560151573074
[Epoch 19, Batch 400] loss: 0.002004932017371175
**STATS for Epoch 19** : 
Average training loss: 0.0009
Average validation loss: 0.0694
Validation Accuracy: 0.9858
Overfitting: 0.0685
[Epoch 20, Batch 100] loss: 0.0036159373929240245
[Epoch 20, Batch 200] loss: 0.002247452123947369
[Epoch 20, Batch 300] loss: 0.002471249463796994
[Epoch 20, Batch 400] loss: 0.007287428860236105
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0611
Validation Accuracy: 0.9876
Overfitting: 0.0609
[Epoch 21, Batch 100] loss: 0.0009342264685096779
[Epoch 21, Batch 200] loss: 0.0014564955494921605
[Epoch 21, Batch 300] loss: 0.0007517853048966572
[Epoch 21, Batch 400] loss: 0.0007340586676627936
**STATS for Epoch 21** : 
Average training loss: 0.0005
Average validation loss: 0.0738
Validation Accuracy: 0.9855
Overfitting: 0.0734
[Epoch 22, Batch 100] loss: 0.0007334112376790359
[Epoch 22, Batch 200] loss: 0.0008066408080048859
[Epoch 22, Batch 300] loss: 0.0005858954588433107
[Epoch 22, Batch 400] loss: 0.0004399798935787658
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0663
Validation Accuracy: 0.9882
Overfitting: 0.0663
[Epoch 23, Batch 100] loss: 0.00023350540729325076
[Epoch 23, Batch 200] loss: 0.0003641126666866512
[Epoch 23, Batch 300] loss: 0.0002465626119385433
[Epoch 23, Batch 400] loss: 0.00019947603805547942
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0668
Validation Accuracy: 0.9878
Overfitting: 0.0667
[Epoch 24, Batch 100] loss: 0.00013198344845022803
[Epoch 24, Batch 200] loss: 0.00014087978419183856
[Epoch 24, Batch 300] loss: 0.0001331124023294805
[Epoch 24, Batch 400] loss: 0.0002674012165067552
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0684
Validation Accuracy: 0.9880
Overfitting: 0.0684
Fold 2 validation loss: 0.0684
Mean validation loss across all folds for Trial 10 is 0.0719 with trial config:  l1: 96, l2: 96, lr: 0.00946889520909023, batch_size: 64
[I 2024-11-19 01:38:19,684] Trial 9 finished with value: 0.07187800962378403 and parameters: {'l1': 96, 'l2': 96, 'lr': 0.00946889520909023, 'batch_size': 64}. Best is trial 0 with value: 0.05886771301817843.
[W 2024-11-19 01:38:19,715] The parameter 'l2' in trial#10 is sampled independently instead of being sampled by multivariate TPE sampler. (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler`, if this independent sampling is intended behavior.

Selected Hyperparameters for Trial 11:
  l1: 128, l2: 128, lr: 0.09254459835550848, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.955748079419136
[Epoch 1, Batch 200] loss: 1.854347380399704
[Epoch 1, Batch 300] loss: 1.318407123684883
[Epoch 1, Batch 400] loss: 0.9971888595819474
[Epoch 1, Batch 500] loss: 0.9486653938889503
[Epoch 1, Batch 600] loss: 1.1672618129849435
[Epoch 1, Batch 700] loss: 0.9605645623803138
[Epoch 1, Batch 800] loss: 1.135485228151083
[Epoch 1, Batch 900] loss: 0.7661621910333634
**STATS for Epoch 1** : 
Average training loss: 0.0301
Average validation loss: 0.7848
Validation Accuracy: 0.8028
Overfitting: 0.7548
Best model saved at epoch 1 with validation loss: 0.7848
[Epoch 2, Batch 100] loss: 0.7787228707969188
[Epoch 2, Batch 200] loss: 0.7523782141506672
[Epoch 2, Batch 300] loss: 1.1762059126794338
[Epoch 2, Batch 400] loss: 1.1495020812749863
[Epoch 2, Batch 500] loss: 1.7037284189462663
[Epoch 2, Batch 600] loss: 1.4672375816106795
[Epoch 2, Batch 700] loss: 1.5313549131155013
[Epoch 2, Batch 800] loss: 1.2196260786056519
[Epoch 2, Batch 900] loss: 1.211115567088127
**STATS for Epoch 2** : 
Average training loss: 0.0483
Average validation loss: 1.1364
Validation Accuracy: 0.6204
Overfitting: 1.0881
[Epoch 3, Batch 100] loss: 1.067777281999588
[Epoch 3, Batch 200] loss: 1.2966721695661545
[Epoch 3, Batch 300] loss: 1.4600674104690552
[Epoch 3, Batch 400] loss: 1.6403412508964539
[Epoch 3, Batch 500] loss: 2.1120716166496276
[Epoch 3, Batch 600] loss: 1.6146454787254334
[Epoch 3, Batch 700] loss: 1.5250254034996034
[Epoch 3, Batch 800] loss: 1.5778321397304536
[Epoch 3, Batch 900] loss: 1.3199443107843398
**STATS for Epoch 3** : 
Average training loss: 0.0598
Average validation loss: 1.4768
Validation Accuracy: 0.6388
Overfitting: 1.4170
[Epoch 4, Batch 100] loss: 1.4923101902008056
[Epoch 4, Batch 200] loss: 1.431091663837433
[Epoch 4, Batch 300] loss: 1.3800653344392777
[Epoch 4, Batch 400] loss: 1.3141608595848084
[Epoch 4, Batch 500] loss: 1.4004510653018951
[Epoch 4, Batch 600] loss: 1.47342113673687
[Epoch 4, Batch 700] loss: 1.4415639239549636
[Epoch 4, Batch 800] loss: 1.6168660348653794
[Epoch 4, Batch 900] loss: 1.7628587538003921
**STATS for Epoch 4** : 
Average training loss: 0.0948
Average validation loss: 2.3140
Validation Accuracy: 0.1005
Overfitting: 2.2191
[Epoch 5, Batch 100] loss: 2.318257191181183
[Epoch 5, Batch 200] loss: 2.3153641867637633
[Epoch 5, Batch 300] loss: 2.3117124247550964
[Epoch 5, Batch 400] loss: 2.3170198345184327
[Epoch 5, Batch 500] loss: 2.3115029764175414
[Epoch 5, Batch 600] loss: 2.3148033595085145
[Epoch 5, Batch 700] loss: 2.31013062953949
[Epoch 5, Batch 800] loss: 2.3076172280311584
[Epoch 5, Batch 900] loss: 2.305282394886017
**STATS for Epoch 5** : 
Average training loss: 0.0934
Average validation loss: 2.3049
Validation Accuracy: 0.1036
Overfitting: 2.2115
[Epoch 6, Batch 100] loss: 2.305759463310242
[Epoch 6, Batch 200] loss: 2.30884761095047
[Epoch 6, Batch 300] loss: 2.306390354633331
[Epoch 6, Batch 400] loss: 2.3046630144119264
[Epoch 6, Batch 500] loss: 2.306889498233795
[Epoch 6, Batch 600] loss: 2.3084820532798767
[Epoch 6, Batch 700] loss: 2.3073122310638428
[Epoch 6, Batch 800] loss: 2.306444628238678
[Epoch 6, Batch 900] loss: 2.308413245677948
**STATS for Epoch 6** : 
Average training loss: 0.0935
Average validation loss: 2.3053
Validation Accuracy: 0.0986
Overfitting: 2.2118
[Epoch 7, Batch 100] loss: 2.3094332933425905
[Epoch 7, Batch 200] loss: 2.308191545009613
[Epoch 7, Batch 300] loss: 2.3090510177612305
[Epoch 7, Batch 400] loss: 2.306322238445282
[Epoch 7, Batch 500] loss: 2.3105285596847533
[Epoch 7, Batch 600] loss: 2.3052526688575745
[Epoch 7, Batch 700] loss: 2.3074768471717833
[Epoch 7, Batch 800] loss: 2.3078477692604067
[Epoch 7, Batch 900] loss: 2.309206414222717
**STATS for Epoch 7** : 
Average training loss: 0.0936
Average validation loss: 2.3040
Validation Accuracy: 0.1122
Overfitting: 2.2104
[Epoch 8, Batch 100] loss: 2.3053841304779055
[Epoch 8, Batch 200] loss: 2.305988826751709
[Epoch 8, Batch 300] loss: 2.3101321864128113
[Epoch 8, Batch 400] loss: 2.306189000606537
[Epoch 8, Batch 500] loss: 2.3044661140441893
[Epoch 8, Batch 600] loss: 2.3094237542152403
[Epoch 8, Batch 700] loss: 2.308822875022888
[Epoch 8, Batch 800] loss: 2.3046939039230345
[Epoch 8, Batch 900] loss: 2.307685067653656
**STATS for Epoch 8** : 
Average training loss: 0.0937
Average validation loss: 2.3089
Validation Accuracy: 0.0987
Overfitting: 2.2152
[Epoch 9, Batch 100] loss: 2.308007764816284
[Epoch 9, Batch 200] loss: 2.30572016954422
[Epoch 9, Batch 300] loss: 2.3072034454345705
[Epoch 9, Batch 400] loss: 2.309238920211792
[Epoch 9, Batch 500] loss: 2.3093248128890993
[Epoch 9, Batch 600] loss: 2.2893006014823913
[Epoch 9, Batch 700] loss: 2.255706403255463
[Epoch 9, Batch 800] loss: 2.296803660392761
[Epoch 9, Batch 900] loss: 2.296807680130005
**STATS for Epoch 9** : 
Average training loss: 0.0922
Average validation loss: 2.3164
Validation Accuracy: 0.1544
Overfitting: 2.2241
[Epoch 10, Batch 100] loss: 1.8095648789405823
[Epoch 10, Batch 200] loss: 2.334575229883194
[Epoch 10, Batch 300] loss: 2.3168313884735108
[Epoch 10, Batch 400] loss: 2.3215896344184874
[Epoch 10, Batch 500] loss: 2.3129031085968017
[Epoch 10, Batch 600] loss: 2.3149993443489074
[Epoch 10, Batch 700] loss: 2.316722187995911
[Epoch 10, Batch 800] loss: 2.3124556159973144
[Epoch 10, Batch 900] loss: 2.313554549217224
**STATS for Epoch 10** : 
Average training loss: 0.0938
Average validation loss: 2.3084
Validation Accuracy: 0.0986
Overfitting: 2.2146
[Epoch 11, Batch 100] loss: 2.3103706097602843
[Epoch 11, Batch 200] loss: 2.307206811904907
[Epoch 11, Batch 300] loss: 2.303185181617737
[Epoch 11, Batch 400] loss: 2.308217515945435
[Epoch 11, Batch 500] loss: 2.3097173166275025
[Epoch 11, Batch 600] loss: 2.3080092549324034
[Epoch 11, Batch 700] loss: 2.3059353280067443
[Epoch 11, Batch 800] loss: 2.309513409137726
[Epoch 11, Batch 900] loss: 2.30804496049881
**STATS for Epoch 11** : 
Average training loss: 0.0934
Average validation loss: 2.3090
Validation Accuracy: 0.1122
Overfitting: 2.2156
[Epoch 12, Batch 100] loss: 2.308349599838257
[Epoch 12, Batch 200] loss: 2.3073878836631776
[Epoch 12, Batch 300] loss: 2.30975750207901
[Epoch 12, Batch 400] loss: 2.3061977195739747
[Epoch 12, Batch 500] loss: 2.3066866254806517
[Epoch 12, Batch 600] loss: 2.308120083808899
[Epoch 12, Batch 700] loss: 2.306697814464569
[Epoch 12, Batch 800] loss: 2.3074151730537413
[Epoch 12, Batch 900] loss: 2.3075496053695677
**STATS for Epoch 12** : 
Average training loss: 0.0933
Average validation loss: 2.3178
Validation Accuracy: 0.0991
Overfitting: 2.2246
[Epoch 13, Batch 100] loss: 2.309856460094452
[Epoch 13, Batch 200] loss: 2.305029482841492
[Epoch 13, Batch 300] loss: 2.3065999722480774
[Epoch 13, Batch 400] loss: 2.3050405836105345
[Epoch 13, Batch 500] loss: 2.3052892112731933
[Epoch 13, Batch 600] loss: 2.307920594215393
[Epoch 13, Batch 700] loss: 2.307903335094452
[Epoch 13, Batch 800] loss: 2.304956107139587
[Epoch 13, Batch 900] loss: 2.3085038590431215
**STATS for Epoch 13** : 
Average training loss: 0.0936
Average validation loss: 2.3073
Validation Accuracy: 0.0986
Overfitting: 2.2137
[Epoch 14, Batch 100] loss: 2.3083882260322572
[Epoch 14, Batch 200] loss: 2.308346862792969
[Epoch 14, Batch 300] loss: 2.3085475540161133
[Epoch 14, Batch 400] loss: 2.306253592967987
[Epoch 14, Batch 500] loss: 2.3048974466323853
[Epoch 14, Batch 600] loss: 2.307085700035095
[Epoch 14, Batch 700] loss: 2.3090101170539854
[Epoch 14, Batch 800] loss: 2.305327320098877
[Epoch 14, Batch 900] loss: 2.305862901210785
**STATS for Epoch 14** : 
Average training loss: 0.0936
Average validation loss: 2.3084
Validation Accuracy: 0.1007
Overfitting: 2.2148
[Epoch 15, Batch 100] loss: 2.3086294889450074
[Epoch 15, Batch 200] loss: 2.3083877992630004
[Epoch 15, Batch 300] loss: 2.307035822868347
[Epoch 15, Batch 400] loss: 2.3086155533790587
[Epoch 15, Batch 500] loss: 2.3054688692092897
[Epoch 15, Batch 600] loss: 2.3070905017852783
[Epoch 15, Batch 700] loss: 2.3084540438652037
[Epoch 15, Batch 800] loss: 2.3071291780471803
[Epoch 15, Batch 900] loss: 2.3077800035476685
**STATS for Epoch 15** : 
Average training loss: 0.0935
Average validation loss: 2.3087
Validation Accuracy: 0.0987
Overfitting: 2.2153
[I 2024-11-19 01:41:23,132] Trial 10 pruned. 
[W 2024-11-19 01:41:23,169] The parameter 'l2' in trial#11 is sampled independently instead of being sampled by multivariate TPE sampler. (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler`, if this independent sampling is intended behavior.

Selected Hyperparameters for Trial 12:
  l1: 128, l2: 128, lr: 0.0005751707844202106, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2958330082893372
[Epoch 1, Batch 200] loss: 2.2721173644065855
[Epoch 1, Batch 300] loss: 2.236805703639984
[Epoch 1, Batch 400] loss: 2.1403049242496492
[Epoch 1, Batch 500] loss: 1.7512325644493103
[Epoch 1, Batch 600] loss: 0.9820005631446839
[Epoch 1, Batch 700] loss: 0.6511528453230858
[Epoch 1, Batch 800] loss: 0.5302443778514863
[Epoch 1, Batch 900] loss: 0.49365783363580706
**STATS for Epoch 1** : 
Average training loss: 0.0181
Average validation loss: 0.4529
Validation Accuracy: 0.8594
Overfitting: 0.4348
Best model saved at epoch 1 with validation loss: 0.4529
[Epoch 2, Batch 100] loss: 0.4224550294876099
[Epoch 2, Batch 200] loss: 0.40183283790946006
[Epoch 2, Batch 300] loss: 0.3558396384119987
[Epoch 2, Batch 400] loss: 0.37282400965690615
[Epoch 2, Batch 500] loss: 0.34087214499711993
[Epoch 2, Batch 600] loss: 0.32931060671806334
[Epoch 2, Batch 700] loss: 0.2810505472123623
[Epoch 2, Batch 800] loss: 0.28387913323938846
[Epoch 2, Batch 900] loss: 0.2890858068689704
**STATS for Epoch 2** : 
Average training loss: 0.0132
Average validation loss: 0.2744
Validation Accuracy: 0.9156
Overfitting: 0.2611
Best model saved at epoch 2 with validation loss: 0.2744
[Epoch 3, Batch 100] loss: 0.24825290158391
[Epoch 3, Batch 200] loss: 0.2846850833669305
[Epoch 3, Batch 300] loss: 0.23633322544395924
[Epoch 3, Batch 400] loss: 0.2178951271623373
[Epoch 3, Batch 500] loss: 0.2115997998788953
[Epoch 3, Batch 600] loss: 0.2091165688633919
[Epoch 3, Batch 700] loss: 0.1998761050030589
[Epoch 3, Batch 800] loss: 0.17955874720588327
[Epoch 3, Batch 900] loss: 0.20624399958178402
**STATS for Epoch 3** : 
Average training loss: 0.0076
Average validation loss: 0.1886
Validation Accuracy: 0.9425
Overfitting: 0.1810
Best model saved at epoch 3 with validation loss: 0.1886
[Epoch 4, Batch 100] loss: 0.17500098576769232
[Epoch 4, Batch 200] loss: 0.1771392460167408
[Epoch 4, Batch 300] loss: 0.16486898632720112
[Epoch 4, Batch 400] loss: 0.1595726971141994
[Epoch 4, Batch 500] loss: 0.15862160585820675
[Epoch 4, Batch 600] loss: 0.1700954991299659
[Epoch 4, Batch 700] loss: 0.15283694176003337
[Epoch 4, Batch 800] loss: 0.15799845119938255
[Epoch 4, Batch 900] loss: 0.1513340221531689
**STATS for Epoch 4** : 
Average training loss: 0.0056
Average validation loss: 0.1623
Validation Accuracy: 0.9504
Overfitting: 0.1567
Best model saved at epoch 4 with validation loss: 0.1623
[Epoch 5, Batch 100] loss: 0.14029298212379218
[Epoch 5, Batch 200] loss: 0.1530420184135437
[Epoch 5, Batch 300] loss: 0.1529764213040471
[Epoch 5, Batch 400] loss: 0.13322249699383973
[Epoch 5, Batch 500] loss: 0.12800703957676887
[Epoch 5, Batch 600] loss: 0.13274374904111028
[Epoch 5, Batch 700] loss: 0.11224606004543602
[Epoch 5, Batch 800] loss: 0.12821592291351408
[Epoch 5, Batch 900] loss: 0.11314656842499972
**STATS for Epoch 5** : 
Average training loss: 0.0036
Average validation loss: 0.1609
Validation Accuracy: 0.9480
Overfitting: 0.1572
Best model saved at epoch 5 with validation loss: 0.1609
[Epoch 6, Batch 100] loss: 0.12021828070282936
[Epoch 6, Batch 200] loss: 0.10477902418933809
[Epoch 6, Batch 300] loss: 0.10954825483262538
[Epoch 6, Batch 400] loss: 0.11365280805155635
[Epoch 6, Batch 500] loss: 0.10240139553323388
[Epoch 6, Batch 600] loss: 0.1110540006030351
[Epoch 6, Batch 700] loss: 0.1050626061623916
[Epoch 6, Batch 800] loss: 0.11651350143365562
[Epoch 6, Batch 900] loss: 0.10180874754209071
**STATS for Epoch 6** : 
Average training loss: 0.0041
Average validation loss: 0.1339
Validation Accuracy: 0.9570
Overfitting: 0.1298
Best model saved at epoch 6 with validation loss: 0.1339
[Epoch 7, Batch 100] loss: 0.10247097307350486
[Epoch 7, Batch 200] loss: 0.0928514326363802
[Epoch 7, Batch 300] loss: 0.08698456072248519
[Epoch 7, Batch 400] loss: 0.09985447301529347
[Epoch 7, Batch 500] loss: 0.08570190135855228
[Epoch 7, Batch 600] loss: 0.1209605207387358
[Epoch 7, Batch 700] loss: 0.08069832605309785
[Epoch 7, Batch 800] loss: 0.09375336555764079
[Epoch 7, Batch 900] loss: 0.09780050666537136
**STATS for Epoch 7** : 
Average training loss: 0.0030
Average validation loss: 0.0943
Validation Accuracy: 0.9705
Overfitting: 0.0913
Best model saved at epoch 7 with validation loss: 0.0943
[Epoch 8, Batch 100] loss: 0.08116971054114401
[Epoch 8, Batch 200] loss: 0.08575997862964868
[Epoch 8, Batch 300] loss: 0.09485978023614734
[Epoch 8, Batch 400] loss: 0.08742085383273661
[Epoch 8, Batch 500] loss: 0.09912722462788225
[Epoch 8, Batch 600] loss: 0.08003666812554001
[Epoch 8, Batch 700] loss: 0.08765815626364201
[Epoch 8, Batch 800] loss: 0.06974894873797893
[Epoch 8, Batch 900] loss: 0.0838649674365297
**STATS for Epoch 8** : 
Average training loss: 0.0030
Average validation loss: 0.0936
Validation Accuracy: 0.9710
Overfitting: 0.0906
Best model saved at epoch 8 with validation loss: 0.0936
[Epoch 9, Batch 100] loss: 0.06581113805994392
[Epoch 9, Batch 200] loss: 0.07800276124384255
[Epoch 9, Batch 300] loss: 0.07762654737569391
[Epoch 9, Batch 400] loss: 0.0800437697255984
[Epoch 9, Batch 500] loss: 0.07621683073230087
[Epoch 9, Batch 600] loss: 0.07153734662570059
[Epoch 9, Batch 700] loss: 0.07599923179019243
[Epoch 9, Batch 800] loss: 0.08079789153300226
[Epoch 9, Batch 900] loss: 0.06638279148843139
**STATS for Epoch 9** : 
Average training loss: 0.0037
Average validation loss: 0.0852
Validation Accuracy: 0.9741
Overfitting: 0.0815
Best model saved at epoch 9 with validation loss: 0.0852
[Epoch 10, Batch 100] loss: 0.06106845434755087
[Epoch 10, Batch 200] loss: 0.06445379642071203
[Epoch 10, Batch 300] loss: 0.07175489163491874
[Epoch 10, Batch 400] loss: 0.07467909041326493
[Epoch 10, Batch 500] loss: 0.0654395103873685
[Epoch 10, Batch 600] loss: 0.07164712907746434
[Epoch 10, Batch 700] loss: 0.09005015462753363
[Epoch 10, Batch 800] loss: 0.06630011409288272
[Epoch 10, Batch 900] loss: 0.05384878361364827
**STATS for Epoch 10** : 
Average training loss: 0.0029
Average validation loss: 0.0848
Validation Accuracy: 0.9732
Overfitting: 0.0819
Best model saved at epoch 10 with validation loss: 0.0848
[Epoch 11, Batch 100] loss: 0.06550372124649584
[Epoch 11, Batch 200] loss: 0.06317977220285684
[Epoch 11, Batch 300] loss: 0.05509106989018619
[Epoch 11, Batch 400] loss: 0.06896126237232238
[Epoch 11, Batch 500] loss: 0.06693112566368654
[Epoch 11, Batch 600] loss: 0.06396050342591479
[Epoch 11, Batch 700] loss: 0.05386612057220191
[Epoch 11, Batch 800] loss: 0.06590701967710628
[Epoch 11, Batch 900] loss: 0.061700872879009695
**STATS for Epoch 11** : 
Average training loss: 0.0040
Average validation loss: 0.0897
Validation Accuracy: 0.9720
Overfitting: 0.0857
[Epoch 12, Batch 100] loss: 0.052513589792652055
[Epoch 12, Batch 200] loss: 0.07354016036028042
[Epoch 12, Batch 300] loss: 0.06995409415569157
[Epoch 12, Batch 400] loss: 0.04446035661851056
[Epoch 12, Batch 500] loss: 0.04625703019089997
[Epoch 12, Batch 600] loss: 0.06907952070701867
[Epoch 12, Batch 700] loss: 0.05653727706987411
[Epoch 12, Batch 800] loss: 0.05292273343075067
[Epoch 12, Batch 900] loss: 0.06540878078434616
**STATS for Epoch 12** : 
Average training loss: 0.0018
Average validation loss: 0.0729
Validation Accuracy: 0.9771
Overfitting: 0.0711
Best model saved at epoch 12 with validation loss: 0.0729
[Epoch 13, Batch 100] loss: 0.05312815013108775
[Epoch 13, Batch 200] loss: 0.04936704462161288
[Epoch 13, Batch 300] loss: 0.03875192404957488
[Epoch 13, Batch 400] loss: 0.0514959862222895
[Epoch 13, Batch 500] loss: 0.07625742018106393
[Epoch 13, Batch 600] loss: 0.045734818803612146
[Epoch 13, Batch 700] loss: 0.05679909817874432
[Epoch 13, Batch 800] loss: 0.05696251829853281
[Epoch 13, Batch 900] loss: 0.06347030217759311
**STATS for Epoch 13** : 
Average training loss: 0.0025
Average validation loss: 0.0808
Validation Accuracy: 0.9738
Overfitting: 0.0784
[Epoch 14, Batch 100] loss: 0.04225405458593741
[Epoch 14, Batch 200] loss: 0.04901671887026168
[Epoch 14, Batch 300] loss: 0.04567211332265288
[Epoch 14, Batch 400] loss: 0.05628950497484766
[Epoch 14, Batch 500] loss: 0.05131476855778601
[Epoch 14, Batch 600] loss: 0.05618727922206745
[Epoch 14, Batch 700] loss: 0.0522725109953899
[Epoch 14, Batch 800] loss: 0.04792584396782331
[Epoch 14, Batch 900] loss: 0.045856906942790376
**STATS for Epoch 14** : 
Average training loss: 0.0024
Average validation loss: 0.0712
Validation Accuracy: 0.9785
Overfitting: 0.0689
Best model saved at epoch 14 with validation loss: 0.0712
[Epoch 15, Batch 100] loss: 0.041117128590121864
[Epoch 15, Batch 200] loss: 0.04421352314762771
[Epoch 15, Batch 300] loss: 0.044482702886452896
[Epoch 15, Batch 400] loss: 0.050683234917814846
[Epoch 15, Batch 500] loss: 0.04693988943006843
[Epoch 15, Batch 600] loss: 0.04640276462305337
[Epoch 15, Batch 700] loss: 0.048111119735985995
[Epoch 15, Batch 800] loss: 0.04194942770292982
[Epoch 15, Batch 900] loss: 0.045647921768249944
**STATS for Epoch 15** : 
Average training loss: 0.0023
Average validation loss: 0.0698
Validation Accuracy: 0.9784
Overfitting: 0.0675
Best model saved at epoch 15 with validation loss: 0.0698
[Epoch 16, Batch 100] loss: 0.03686736564268358
[Epoch 16, Batch 200] loss: 0.03673710260423832
[Epoch 16, Batch 300] loss: 0.047151016069110485
[Epoch 16, Batch 400] loss: 0.03746735107677523
[Epoch 16, Batch 500] loss: 0.04868423623847775
[Epoch 16, Batch 600] loss: 0.03735818221932277
[Epoch 16, Batch 700] loss: 0.04288030614668969
[Epoch 16, Batch 800] loss: 0.06739276598789729
[Epoch 16, Batch 900] loss: 0.043578027068870144
**STATS for Epoch 16** : 
Average training loss: 0.0018
Average validation loss: 0.0666
Validation Accuracy: 0.9796
Overfitting: 0.0648
Best model saved at epoch 16 with validation loss: 0.0666
[Epoch 17, Batch 100] loss: 0.04052476929849945
[Epoch 17, Batch 200] loss: 0.04001050016260706
[Epoch 17, Batch 300] loss: 0.04607717189821415
[Epoch 17, Batch 400] loss: 0.037726559301372614
[Epoch 17, Batch 500] loss: 0.03950416028383188
[Epoch 17, Batch 600] loss: 0.039901192609104325
[Epoch 17, Batch 700] loss: 0.03951343485503458
[Epoch 17, Batch 800] loss: 0.04463561571785249
[Epoch 17, Batch 900] loss: 0.046455437756958415
**STATS for Epoch 17** : 
Average training loss: 0.0015
Average validation loss: 0.0708
Validation Accuracy: 0.9791
Overfitting: 0.0693
[Epoch 18, Batch 100] loss: 0.039347751381574196
[Epoch 18, Batch 200] loss: 0.03958150190883316
[Epoch 18, Batch 300] loss: 0.04409816789557226
[Epoch 18, Batch 400] loss: 0.03221838138415478
[Epoch 18, Batch 500] loss: 0.037758666065055874
[Epoch 18, Batch 600] loss: 0.037192381646309516
[Epoch 18, Batch 700] loss: 0.03494740207504947
[Epoch 18, Batch 800] loss: 0.037839110864442776
[Epoch 18, Batch 900] loss: 0.0369769967533648
**STATS for Epoch 18** : 
Average training loss: 0.0019
Average validation loss: 0.0759
Validation Accuracy: 0.9773
Overfitting: 0.0740
[Epoch 19, Batch 100] loss: 0.0339035508595407
[Epoch 19, Batch 200] loss: 0.030166857749572954
[Epoch 19, Batch 300] loss: 0.0368125534086721
[Epoch 19, Batch 400] loss: 0.030057977038668467
[Epoch 19, Batch 500] loss: 0.04045006397238467
[Epoch 19, Batch 600] loss: 0.04044903645466547
[Epoch 19, Batch 700] loss: 0.035266642746282745
[Epoch 19, Batch 800] loss: 0.02982103583170101
[Epoch 19, Batch 900] loss: 0.035924571366049346
**STATS for Epoch 19** : 
Average training loss: 0.0029
Average validation loss: 0.0720
Validation Accuracy: 0.9780
Overfitting: 0.0691
[Epoch 20, Batch 100] loss: 0.023524151507299394
[Epoch 20, Batch 200] loss: 0.03738415988860652
[Epoch 20, Batch 300] loss: 0.040208425746532155
[Epoch 20, Batch 400] loss: 0.03810038575727958
[Epoch 20, Batch 500] loss: 0.0296356535499217
[Epoch 20, Batch 600] loss: 0.03338972309487872
[Epoch 20, Batch 700] loss: 0.03407092583278427
[Epoch 20, Batch 800] loss: 0.03526827806956135
[Epoch 20, Batch 900] loss: 0.03244337309151888
**STATS for Epoch 20** : 
Average training loss: 0.0015
Average validation loss: 0.0645
Validation Accuracy: 0.9809
Overfitting: 0.0630
Best model saved at epoch 20 with validation loss: 0.0645
[Epoch 21, Batch 100] loss: 0.029257971923216247
[Epoch 21, Batch 200] loss: 0.03277384360437281
[Epoch 21, Batch 300] loss: 0.03357608893129509
[Epoch 21, Batch 400] loss: 0.03344595316564664
[Epoch 21, Batch 500] loss: 0.03236762339656707
[Epoch 21, Batch 600] loss: 0.030971578357857653
[Epoch 21, Batch 700] loss: 0.025704058458504733
[Epoch 21, Batch 800] loss: 0.024734833375550807
[Epoch 21, Batch 900] loss: 0.030732975393766536
**STATS for Epoch 21** : 
Average training loss: 0.0014
Average validation loss: 0.0689
Validation Accuracy: 0.9799
Overfitting: 0.0676
[Epoch 22, Batch 100] loss: 0.021540896865481045
[Epoch 22, Batch 200] loss: 0.026771394136594608
[Epoch 22, Batch 300] loss: 0.026818301882012747
[Epoch 22, Batch 400] loss: 0.026910544809070416
[Epoch 22, Batch 500] loss: 0.02638928068394307
[Epoch 22, Batch 600] loss: 0.025527866344782525
[Epoch 22, Batch 700] loss: 0.0353240933152847
[Epoch 22, Batch 800] loss: 0.03687235602876172
[Epoch 22, Batch 900] loss: 0.035676569862989706
**STATS for Epoch 22** : 
Average training loss: 0.0017
Average validation loss: 0.0653
Validation Accuracy: 0.9805
Overfitting: 0.0636
[Epoch 23, Batch 100] loss: 0.024336590902530587
[Epoch 23, Batch 200] loss: 0.03100505902431905
[Epoch 23, Batch 300] loss: 0.02398755205940688
[Epoch 23, Batch 400] loss: 0.02317511559056584
[Epoch 23, Batch 500] loss: 0.02488553269780823
[Epoch 23, Batch 600] loss: 0.03479332721733954
[Epoch 23, Batch 700] loss: 0.033187290342757476
[Epoch 23, Batch 800] loss: 0.026762930123950354
[Epoch 23, Batch 900] loss: 0.027217336051398887
**STATS for Epoch 23** : 
Average training loss: 0.0012
Average validation loss: 0.0640
Validation Accuracy: 0.9803
Overfitting: 0.0627
Best model saved at epoch 23 with validation loss: 0.0640
[Epoch 24, Batch 100] loss: 0.021614491335349158
[Epoch 24, Batch 200] loss: 0.02894086556712864
[Epoch 24, Batch 300] loss: 0.026302006342739333
[Epoch 24, Batch 400] loss: 0.0291849423761596
[Epoch 24, Batch 500] loss: 0.028084090826450848
[Epoch 24, Batch 600] loss: 0.030134698800975458
[Epoch 24, Batch 700] loss: 0.025652388253365643
[Epoch 24, Batch 800] loss: 0.021603107796254337
[Epoch 24, Batch 900] loss: 0.027578427541884595
**STATS for Epoch 24** : 
Average training loss: 0.0008
Average validation loss: 0.0584
Validation Accuracy: 0.9831
Overfitting: 0.0576
Best model saved at epoch 24 with validation loss: 0.0584
Fold 1 validation loss: 0.0584
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.2917218375205994
[Epoch 1, Batch 200] loss: 2.2679932832717897
[Epoch 1, Batch 300] loss: 2.21842458486557
[Epoch 1, Batch 400] loss: 2.0950143921375273
[Epoch 1, Batch 500] loss: 1.777864396572113
[Epoch 1, Batch 600] loss: 1.302359082698822
[Epoch 1, Batch 700] loss: 0.8837518918514252
[Epoch 1, Batch 800] loss: 0.6241361406445504
[Epoch 1, Batch 900] loss: 0.5382585310935974
**STATS for Epoch 1** : 
Average training loss: 0.0188
Average validation loss: 0.4551
Validation Accuracy: 0.8633
Overfitting: 0.4363
Best model saved at epoch 1 with validation loss: 0.4551
[Epoch 2, Batch 100] loss: 0.43016994789242746
[Epoch 2, Batch 200] loss: 0.40710006043314934
[Epoch 2, Batch 300] loss: 0.3760823513567448
[Epoch 2, Batch 400] loss: 0.32812407195568083
[Epoch 2, Batch 500] loss: 0.3222063338756561
[Epoch 2, Batch 600] loss: 0.32115074172616004
[Epoch 2, Batch 700] loss: 0.2814330646768212
[Epoch 2, Batch 800] loss: 0.2663153199106455
[Epoch 2, Batch 900] loss: 0.26381960555911066
**STATS for Epoch 2** : 
Average training loss: 0.0093
Average validation loss: 0.2469
Validation Accuracy: 0.9257
Overfitting: 0.2376
Best model saved at epoch 2 with validation loss: 0.2469
[Epoch 3, Batch 100] loss: 0.24291624449193477
[Epoch 3, Batch 200] loss: 0.20676362602040171
[Epoch 3, Batch 300] loss: 0.21243449088186026
[Epoch 3, Batch 400] loss: 0.20622087752446533
[Epoch 3, Batch 500] loss: 0.2095497591048479
[Epoch 3, Batch 600] loss: 0.20664491452276706
[Epoch 3, Batch 700] loss: 0.19831183975562452
[Epoch 3, Batch 800] loss: 0.1679262204095721
[Epoch 3, Batch 900] loss: 0.16800154319033025
**STATS for Epoch 3** : 
Average training loss: 0.0072
Average validation loss: 0.1779
Validation Accuracy: 0.9466
Overfitting: 0.1707
Best model saved at epoch 3 with validation loss: 0.1779
[Epoch 4, Batch 100] loss: 0.17477172696962953
[Epoch 4, Batch 200] loss: 0.16358692318201065
[Epoch 4, Batch 300] loss: 0.16183795794844627
[Epoch 4, Batch 400] loss: 0.15651765182614327
[Epoch 4, Batch 500] loss: 0.16182010658085347
[Epoch 4, Batch 600] loss: 0.13905369749292731
[Epoch 4, Batch 700] loss: 0.12518479444086553
[Epoch 4, Batch 800] loss: 0.1487296288087964
[Epoch 4, Batch 900] loss: 0.13293691204860805
**STATS for Epoch 4** : 
Average training loss: 0.0051
Average validation loss: 0.1523
Validation Accuracy: 0.9538
Overfitting: 0.1472
Best model saved at epoch 4 with validation loss: 0.1523
[Epoch 5, Batch 100] loss: 0.13512425748631357
[Epoch 5, Batch 200] loss: 0.13312506426125764
[Epoch 5, Batch 300] loss: 0.12379615668207407
[Epoch 5, Batch 400] loss: 0.1247376585751772
[Epoch 5, Batch 500] loss: 0.1275183538161218
[Epoch 5, Batch 600] loss: 0.11177146549336613
[Epoch 5, Batch 700] loss: 0.11584540890529751
[Epoch 5, Batch 800] loss: 0.1242842933209613
[Epoch 5, Batch 900] loss: 0.11808425633236766
**STATS for Epoch 5** : 
Average training loss: 0.0046
Average validation loss: 0.1254
Validation Accuracy: 0.9609
Overfitting: 0.1207
Best model saved at epoch 5 with validation loss: 0.1254
[Epoch 6, Batch 100] loss: 0.08940304160118102
[Epoch 6, Batch 200] loss: 0.0969865805003792
[Epoch 6, Batch 300] loss: 0.1116060907021165
[Epoch 6, Batch 400] loss: 0.10331631794106215
[Epoch 6, Batch 500] loss: 0.10892918500117958
[Epoch 6, Batch 600] loss: 0.12057874497957527
[Epoch 6, Batch 700] loss: 0.11600804672576487
[Epoch 6, Batch 800] loss: 0.10094376279972493
[Epoch 6, Batch 900] loss: 0.1034801735682413
**STATS for Epoch 6** : 
Average training loss: 0.0042
Average validation loss: 0.1183
Validation Accuracy: 0.9641
Overfitting: 0.1141
Best model saved at epoch 6 with validation loss: 0.1183
[Epoch 7, Batch 100] loss: 0.09453114368952811
[Epoch 7, Batch 200] loss: 0.10469484751112759
[Epoch 7, Batch 300] loss: 0.09036111562978476
[Epoch 7, Batch 400] loss: 0.0853081512125209
[Epoch 7, Batch 500] loss: 0.09101630638353526
[Epoch 7, Batch 600] loss: 0.08478785040788353
[Epoch 7, Batch 700] loss: 0.09764362752437591
[Epoch 7, Batch 800] loss: 0.08738238448742777
[Epoch 7, Batch 900] loss: 0.09315928235650063
**STATS for Epoch 7** : 
Average training loss: 0.0037
Average validation loss: 0.0962
Validation Accuracy: 0.9702
Overfitting: 0.0924
Best model saved at epoch 7 with validation loss: 0.0962
[Epoch 8, Batch 100] loss: 0.0880279055563733
[Epoch 8, Batch 200] loss: 0.0729312683781609
[Epoch 8, Batch 300] loss: 0.09175860186107457
[Epoch 8, Batch 400] loss: 0.08221454030834138
[Epoch 8, Batch 500] loss: 0.09376673909369856
[Epoch 8, Batch 600] loss: 0.08483020880259573
[Epoch 8, Batch 700] loss: 0.09043702934868633
[Epoch 8, Batch 800] loss: 0.07573006169404835
[Epoch 8, Batch 900] loss: 0.07192179313395172
**STATS for Epoch 8** : 
Average training loss: 0.0037
Average validation loss: 0.0945
Validation Accuracy: 0.9707
Overfitting: 0.0908
Best model saved at epoch 8 with validation loss: 0.0945
[Epoch 9, Batch 100] loss: 0.07198042069561779
[Epoch 9, Batch 200] loss: 0.07834512735484168
[Epoch 9, Batch 300] loss: 0.08685203635832295
[Epoch 9, Batch 400] loss: 0.06016248769825325
[Epoch 9, Batch 500] loss: 0.07475184740498662
[Epoch 9, Batch 600] loss: 0.07217444485984742
[Epoch 9, Batch 700] loss: 0.07678495804779231
[Epoch 9, Batch 800] loss: 0.08519390884554014
[Epoch 9, Batch 900] loss: 0.07014292708598077
**STATS for Epoch 9** : 
Average training loss: 0.0023
Average validation loss: 0.0846
Validation Accuracy: 0.9729
Overfitting: 0.0823
Best model saved at epoch 9 with validation loss: 0.0846
[Epoch 10, Batch 100] loss: 0.061482973797246813
[Epoch 10, Batch 200] loss: 0.07043480553198606
[Epoch 10, Batch 300] loss: 0.06612349366536364
[Epoch 10, Batch 400] loss: 0.06315951485186816
[Epoch 10, Batch 500] loss: 0.07247260507196188
[Epoch 10, Batch 600] loss: 0.06815144545398652
[Epoch 10, Batch 700] loss: 0.07950144814327359
[Epoch 10, Batch 800] loss: 0.06668504344765097
[Epoch 10, Batch 900] loss: 0.0695139304222539
**STATS for Epoch 10** : 
Average training loss: 0.0027
Average validation loss: 0.0800
Validation Accuracy: 0.9748
Overfitting: 0.0773
Best model saved at epoch 10 with validation loss: 0.0800
[Epoch 11, Batch 100] loss: 0.05892373089212924
[Epoch 11, Batch 200] loss: 0.06653367094113491
[Epoch 11, Batch 300] loss: 0.05493615549290553
[Epoch 11, Batch 400] loss: 0.07400015719700605
[Epoch 11, Batch 500] loss: 0.05270216221921146
[Epoch 11, Batch 600] loss: 0.06788418265874498
[Epoch 11, Batch 700] loss: 0.059592123520560564
[Epoch 11, Batch 800] loss: 0.05461348674027249
[Epoch 11, Batch 900] loss: 0.07237682084785774
**STATS for Epoch 11** : 
Average training loss: 0.0028
Average validation loss: 0.0731
Validation Accuracy: 0.9772
Overfitting: 0.0702
Best model saved at epoch 11 with validation loss: 0.0731
[Epoch 12, Batch 100] loss: 0.0536912666936405
[Epoch 12, Batch 200] loss: 0.07682953430572524
[Epoch 12, Batch 300] loss: 0.05344721980043687
[Epoch 12, Batch 400] loss: 0.06497121560620144
[Epoch 12, Batch 500] loss: 0.04867664352292195
[Epoch 12, Batch 600] loss: 0.06532251031836495
[Epoch 12, Batch 700] loss: 0.054804575757589194
[Epoch 12, Batch 800] loss: 0.05696254385635257
[Epoch 12, Batch 900] loss: 0.05105529123567976
**STATS for Epoch 12** : 
Average training loss: 0.0023
Average validation loss: 0.0774
Validation Accuracy: 0.9758
Overfitting: 0.0752
[Epoch 13, Batch 100] loss: 0.05352150109130889
[Epoch 13, Batch 200] loss: 0.06251236155279911
[Epoch 13, Batch 300] loss: 0.059701874286402015
[Epoch 13, Batch 400] loss: 0.052693342096172276
[Epoch 13, Batch 500] loss: 0.057657115968177096
[Epoch 13, Batch 600] loss: 0.060267215615604074
[Epoch 13, Batch 700] loss: 0.052826284694019704
[Epoch 13, Batch 800] loss: 0.044263040039222684
[Epoch 13, Batch 900] loss: 0.05340165358036757
**STATS for Epoch 13** : 
Average training loss: 0.0017
Average validation loss: 0.0755
Validation Accuracy: 0.9763
Overfitting: 0.0738
[Epoch 14, Batch 100] loss: 0.047005623476579786
[Epoch 14, Batch 200] loss: 0.051830535575281826
[Epoch 14, Batch 300] loss: 0.04291255089570768
[Epoch 14, Batch 400] loss: 0.05069366038427688
[Epoch 14, Batch 500] loss: 0.05189278302248567
[Epoch 14, Batch 600] loss: 0.055443840090301816
[Epoch 14, Batch 700] loss: 0.05811519108887296
[Epoch 14, Batch 800] loss: 0.04019390759989619
[Epoch 14, Batch 900] loss: 0.050769824713934215
**STATS for Epoch 14** : 
Average training loss: 0.0020
Average validation loss: 0.0715
Validation Accuracy: 0.9776
Overfitting: 0.0695
Best model saved at epoch 14 with validation loss: 0.0715
[Epoch 15, Batch 100] loss: 0.040003991285339
[Epoch 15, Batch 200] loss: 0.04075260844663717
[Epoch 15, Batch 300] loss: 0.040251027880003676
[Epoch 15, Batch 400] loss: 0.052936704448075036
[Epoch 15, Batch 500] loss: 0.05597334586782381
[Epoch 15, Batch 600] loss: 0.048291586771374566
[Epoch 15, Batch 700] loss: 0.04575078400084749
[Epoch 15, Batch 800] loss: 0.046763032707385715
[Epoch 15, Batch 900] loss: 0.04085257546044886
**STATS for Epoch 15** : 
Average training loss: 0.0020
Average validation loss: 0.0752
Validation Accuracy: 0.9774
Overfitting: 0.0733
[Epoch 16, Batch 100] loss: 0.034648156316252426
[Epoch 16, Batch 200] loss: 0.04318488273769617
[Epoch 16, Batch 300] loss: 0.046834344879025595
[Epoch 16, Batch 400] loss: 0.05156060599954799
[Epoch 16, Batch 500] loss: 0.04776100887334905
[Epoch 16, Batch 600] loss: 0.03615537215373479
[Epoch 16, Batch 700] loss: 0.04614237453555688
[Epoch 16, Batch 800] loss: 0.050814646877115593
[Epoch 16, Batch 900] loss: 0.04220718710275832
**STATS for Epoch 16** : 
Average training loss: 0.0014
Average validation loss: 0.0643
Validation Accuracy: 0.9803
Overfitting: 0.0629
Best model saved at epoch 16 with validation loss: 0.0643
[Epoch 17, Batch 100] loss: 0.03812348081031814
[Epoch 17, Batch 200] loss: 0.03839579061488621
[Epoch 17, Batch 300] loss: 0.037595412972732445
[Epoch 17, Batch 400] loss: 0.045020720617030746
[Epoch 17, Batch 500] loss: 0.04290223919902928
[Epoch 17, Batch 600] loss: 0.03446706226910465
[Epoch 17, Batch 700] loss: 0.0328523773571942
[Epoch 17, Batch 800] loss: 0.049267738203052434
[Epoch 17, Batch 900] loss: 0.05101103622233495
**STATS for Epoch 17** : 
Average training loss: 0.0018
Average validation loss: 0.0633
Validation Accuracy: 0.9808
Overfitting: 0.0615
Best model saved at epoch 17 with validation loss: 0.0633
[Epoch 18, Batch 100] loss: 0.02984192334813997
[Epoch 18, Batch 200] loss: 0.0390981099079363
[Epoch 18, Batch 300] loss: 0.036157036204822364
[Epoch 18, Batch 400] loss: 0.03966249326826073
[Epoch 18, Batch 500] loss: 0.037557765196543184
[Epoch 18, Batch 600] loss: 0.04280087613733485
[Epoch 18, Batch 700] loss: 0.03929094735532999
[Epoch 18, Batch 800] loss: 0.041221454076003285
[Epoch 18, Batch 900] loss: 0.03987495493085589
**STATS for Epoch 18** : 
Average training loss: 0.0010
Average validation loss: 0.0647
Validation Accuracy: 0.9808
Overfitting: 0.0637
[Epoch 19, Batch 100] loss: 0.03275681043160148
[Epoch 19, Batch 200] loss: 0.03849081449967343
[Epoch 19, Batch 300] loss: 0.030484542506746946
[Epoch 19, Batch 400] loss: 0.0371852293657139
[Epoch 19, Batch 500] loss: 0.028960606885375453
[Epoch 19, Batch 600] loss: 0.04025726087682415
[Epoch 19, Batch 700] loss: 0.04064606233965606
[Epoch 19, Batch 800] loss: 0.035773756708949805
[Epoch 19, Batch 900] loss: 0.036746679982752536
**STATS for Epoch 19** : 
Average training loss: 0.0014
Average validation loss: 0.0600
Validation Accuracy: 0.9823
Overfitting: 0.0586
Best model saved at epoch 19 with validation loss: 0.0600
[Epoch 20, Batch 100] loss: 0.031416342884185725
[Epoch 20, Batch 200] loss: 0.043729892384726556
[Epoch 20, Batch 300] loss: 0.030204272988485173
[Epoch 20, Batch 400] loss: 0.030049292217590846
[Epoch 20, Batch 500] loss: 0.041178282467881216
[Epoch 20, Batch 600] loss: 0.036938931256590875
[Epoch 20, Batch 700] loss: 0.032937042582198046
[Epoch 20, Batch 800] loss: 0.039328031637123784
[Epoch 20, Batch 900] loss: 0.02666552776878234
**STATS for Epoch 20** : 
Average training loss: 0.0008
Average validation loss: 0.0617
Validation Accuracy: 0.9814
Overfitting: 0.0609
[Epoch 21, Batch 100] loss: 0.03433606248290744
[Epoch 21, Batch 200] loss: 0.024674242812907324
[Epoch 21, Batch 300] loss: 0.03285952131205704
[Epoch 21, Batch 400] loss: 0.03146163127559703
[Epoch 21, Batch 500] loss: 0.0408672369539272
[Epoch 21, Batch 600] loss: 0.026755487004993483
[Epoch 21, Batch 700] loss: 0.03789304126868956
[Epoch 21, Batch 800] loss: 0.029926736203779
[Epoch 21, Batch 900] loss: 0.030168492761440575
**STATS for Epoch 21** : 
Average training loss: 0.0017
Average validation loss: 0.0620
Validation Accuracy: 0.9817
Overfitting: 0.0603
[Epoch 22, Batch 100] loss: 0.025203702098224312
[Epoch 22, Batch 200] loss: 0.0230643634108128
[Epoch 22, Batch 300] loss: 0.029834969867370092
[Epoch 22, Batch 400] loss: 0.03488021308556199
[Epoch 22, Batch 500] loss: 0.03340104898321442
[Epoch 22, Batch 600] loss: 0.021548522425291594
[Epoch 22, Batch 700] loss: 0.03129113719711313
[Epoch 22, Batch 800] loss: 0.02625716142967576
[Epoch 22, Batch 900] loss: 0.0389026826574991
**STATS for Epoch 22** : 
Average training loss: 0.0015
Average validation loss: 0.0606
Validation Accuracy: 0.9824
Overfitting: 0.0592
[Epoch 23, Batch 100] loss: 0.023346744032460266
[Epoch 23, Batch 200] loss: 0.02214021381281782
[Epoch 23, Batch 300] loss: 0.022214838687214068
[Epoch 23, Batch 400] loss: 0.03131168917927425
[Epoch 23, Batch 500] loss: 0.033038287582458
[Epoch 23, Batch 600] loss: 0.029294509178580484
[Epoch 23, Batch 700] loss: 0.036309300909924784
[Epoch 23, Batch 800] loss: 0.02169252574938582
[Epoch 23, Batch 900] loss: 0.03132204135967186
**STATS for Epoch 23** : 
Average training loss: 0.0010
Average validation loss: 0.0601
Validation Accuracy: 0.9818
Overfitting: 0.0591
[Epoch 24, Batch 100] loss: 0.02444473899086006
[Epoch 24, Batch 200] loss: 0.01815746969426982
[Epoch 24, Batch 300] loss: 0.03150485592486803
[Epoch 24, Batch 400] loss: 0.0251691432739608
[Epoch 24, Batch 500] loss: 0.024224681048071944
[Epoch 24, Batch 600] loss: 0.01955395294295158
[Epoch 24, Batch 700] loss: 0.026625899851787836
[Epoch 24, Batch 800] loss: 0.02689100316609256
[Epoch 24, Batch 900] loss: 0.027881055508623832
**STATS for Epoch 24** : 
Average training loss: 0.0018
Average validation loss: 0.0635
Validation Accuracy: 0.9816
Overfitting: 0.0617
Fold 2 validation loss: 0.0635
Mean validation loss across all folds for Trial 12 is 0.0610 with trial config:  l1: 128, l2: 128, lr: 0.0005751707844202106, batch_size: 32
[I 2024-11-19 01:50:59,919] Trial 11 finished with value: 0.06097253228592099 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0005751707844202106, 'batch_size': 32}. Best is trial 0 with value: 0.05886771301817843.
[W 2024-11-19 01:50:59,951] The parameter 'l2' in trial#12 is sampled independently instead of being sampled by multivariate TPE sampler. (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler`, if this independent sampling is intended behavior.

Selected Hyperparameters for Trial 13:
  l1: 96, l2: 96, lr: 0.008169619653037311, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.7373600536584854
**STATS for Epoch 1** : 
Average training loss: 0.0694
Average validation loss: 0.4239
Validation Accuracy: 0.8665
Overfitting: 0.3545
Best model saved at epoch 1 with validation loss: 0.4239
[Epoch 2, Batch 100] loss: 0.27800302356481554
**STATS for Epoch 2** : 
Average training loss: 0.0293
Average validation loss: 0.1826
Validation Accuracy: 0.9434
Overfitting: 0.1533
Best model saved at epoch 2 with validation loss: 0.1826
[Epoch 3, Batch 100] loss: 0.1530636700242758
**STATS for Epoch 3** : 
Average training loss: 0.0205
Average validation loss: 0.1427
Validation Accuracy: 0.9550
Overfitting: 0.1221
Best model saved at epoch 3 with validation loss: 0.1427
[Epoch 4, Batch 100] loss: 0.11445208791643381
**STATS for Epoch 4** : 
Average training loss: 0.0156
Average validation loss: 0.1082
Validation Accuracy: 0.9660
Overfitting: 0.0927
Best model saved at epoch 4 with validation loss: 0.1082
[Epoch 5, Batch 100] loss: 0.09576257675886155
**STATS for Epoch 5** : 
Average training loss: 0.0126
Average validation loss: 0.0889
Validation Accuracy: 0.9720
Overfitting: 0.0763
Best model saved at epoch 5 with validation loss: 0.0889
[Epoch 6, Batch 100] loss: 0.07219599964097143
**STATS for Epoch 6** : 
Average training loss: 0.0127
Average validation loss: 0.0825
Validation Accuracy: 0.9748
Overfitting: 0.0698
Best model saved at epoch 6 with validation loss: 0.0825
[Epoch 7, Batch 100] loss: 0.06353872884064912
**STATS for Epoch 7** : 
Average training loss: 0.0110
Average validation loss: 0.0774
Validation Accuracy: 0.9756
Overfitting: 0.0664
Best model saved at epoch 7 with validation loss: 0.0774
[Epoch 8, Batch 100] loss: 0.058185667609795926
**STATS for Epoch 8** : 
Average training loss: 0.0091
Average validation loss: 0.0758
Validation Accuracy: 0.9767
Overfitting: 0.0667
Best model saved at epoch 8 with validation loss: 0.0758
[Epoch 9, Batch 100] loss: 0.056559148216620087
**STATS for Epoch 9** : 
Average training loss: 0.0079
Average validation loss: 0.0689
Validation Accuracy: 0.9785
Overfitting: 0.0610
Best model saved at epoch 9 with validation loss: 0.0689
[Epoch 10, Batch 100] loss: 0.04649950560182333
**STATS for Epoch 10** : 
Average training loss: 0.0062
Average validation loss: 0.0679
Validation Accuracy: 0.9787
Overfitting: 0.0616
Best model saved at epoch 10 with validation loss: 0.0679
[Epoch 11, Batch 100] loss: 0.04082510699518025
**STATS for Epoch 11** : 
Average training loss: 0.0072
Average validation loss: 0.0666
Validation Accuracy: 0.9801
Overfitting: 0.0594
Best model saved at epoch 11 with validation loss: 0.0666
[Epoch 12, Batch 100] loss: 0.035643945094197986
**STATS for Epoch 12** : 
Average training loss: 0.0070
Average validation loss: 0.0636
Validation Accuracy: 0.9815
Overfitting: 0.0567
Best model saved at epoch 12 with validation loss: 0.0636
[Epoch 13, Batch 100] loss: 0.03642175172455609
**STATS for Epoch 13** : 
Average training loss: 0.0055
Average validation loss: 0.0609
Validation Accuracy: 0.9818
Overfitting: 0.0554
Best model saved at epoch 13 with validation loss: 0.0609
[Epoch 14, Batch 100] loss: 0.029277245504781602
**STATS for Epoch 14** : 
Average training loss: 0.0063
Average validation loss: 0.0605
Validation Accuracy: 0.9821
Overfitting: 0.0543
Best model saved at epoch 14 with validation loss: 0.0605
[Epoch 15, Batch 100] loss: 0.029891295731067656
**STATS for Epoch 15** : 
Average training loss: 0.0069
Average validation loss: 0.0611
Validation Accuracy: 0.9816
Overfitting: 0.0541
[Epoch 16, Batch 100] loss: 0.027249439680017532
**STATS for Epoch 16** : 
Average training loss: 0.0031
Average validation loss: 0.0576
Validation Accuracy: 0.9832
Overfitting: 0.0545
Best model saved at epoch 16 with validation loss: 0.0576
[Epoch 17, Batch 100] loss: 0.024788011615164578
**STATS for Epoch 17** : 
Average training loss: 0.0039
Average validation loss: 0.0565
Validation Accuracy: 0.9833
Overfitting: 0.0526
Best model saved at epoch 17 with validation loss: 0.0565
[Epoch 18, Batch 100] loss: 0.021577612538821997
**STATS for Epoch 18** : 
Average training loss: 0.0032
Average validation loss: 0.0597
Validation Accuracy: 0.9838
Overfitting: 0.0565
[Epoch 19, Batch 100] loss: 0.020316541553474964
**STATS for Epoch 19** : 
Average training loss: 0.0038
Average validation loss: 0.0648
Validation Accuracy: 0.9817
Overfitting: 0.0609
[Epoch 20, Batch 100] loss: 0.01939200420398265
**STATS for Epoch 20** : 
Average training loss: 0.0025
Average validation loss: 0.0615
Validation Accuracy: 0.9839
Overfitting: 0.0590
[Epoch 21, Batch 100] loss: 0.01599466030020267
**STATS for Epoch 21** : 
Average training loss: 0.0026
Average validation loss: 0.0611
Validation Accuracy: 0.9833
Overfitting: 0.0586
[Epoch 22, Batch 100] loss: 0.014647683815564961
**STATS for Epoch 22** : 
Average training loss: 0.0027
Average validation loss: 0.0669
Validation Accuracy: 0.9828
Overfitting: 0.0642
[Epoch 23, Batch 100] loss: 0.01478031708393246
**STATS for Epoch 23** : 
Average training loss: 0.0026
Average validation loss: 0.0672
Validation Accuracy: 0.9823
Overfitting: 0.0646
[Epoch 24, Batch 100] loss: 0.01174113990040496
**STATS for Epoch 24** : 
Average training loss: 0.0023
Average validation loss: 0.0651
Validation Accuracy: 0.9837
Overfitting: 0.0627
Fold 1 validation loss: 0.0651
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.73648478358984
**STATS for Epoch 1** : 
Average training loss: 0.0755
Average validation loss: 0.5992
Validation Accuracy: 0.8155
Overfitting: 0.5237
Best model saved at epoch 1 with validation loss: 0.5992
[Epoch 2, Batch 100] loss: 0.2974236460030079
**STATS for Epoch 2** : 
Average training loss: 0.0331
Average validation loss: 0.2032
Validation Accuracy: 0.9365
Overfitting: 0.1701
Best model saved at epoch 2 with validation loss: 0.2032
[Epoch 3, Batch 100] loss: 0.17093972682952882
**STATS for Epoch 3** : 
Average training loss: 0.0201
Average validation loss: 0.1442
Validation Accuracy: 0.9566
Overfitting: 0.1241
Best model saved at epoch 3 with validation loss: 0.1442
[Epoch 4, Batch 100] loss: 0.11662053301930428
**STATS for Epoch 4** : 
Average training loss: 0.0192
Average validation loss: 0.1213
Validation Accuracy: 0.9627
Overfitting: 0.1021
Best model saved at epoch 4 with validation loss: 0.1213
[Epoch 5, Batch 100] loss: 0.09679714471101761
**STATS for Epoch 5** : 
Average training loss: 0.0150
Average validation loss: 0.1012
Validation Accuracy: 0.9691
Overfitting: 0.0863
Best model saved at epoch 5 with validation loss: 0.1012
[Epoch 6, Batch 100] loss: 0.07844477571547032
**STATS for Epoch 6** : 
Average training loss: 0.0115
Average validation loss: 0.0796
Validation Accuracy: 0.9761
Overfitting: 0.0681
Best model saved at epoch 6 with validation loss: 0.0796
[Epoch 7, Batch 100] loss: 0.06747477913275361
**STATS for Epoch 7** : 
Average training loss: 0.0118
Average validation loss: 0.1027
Validation Accuracy: 0.9691
Overfitting: 0.0910
[Epoch 8, Batch 100] loss: 0.06187716037034988
**STATS for Epoch 8** : 
Average training loss: 0.0100
Average validation loss: 0.0845
Validation Accuracy: 0.9746
Overfitting: 0.0746
[Epoch 9, Batch 100] loss: 0.05647320220246911
**STATS for Epoch 9** : 
Average training loss: 0.0079
Average validation loss: 0.0722
Validation Accuracy: 0.9791
Overfitting: 0.0643
Best model saved at epoch 9 with validation loss: 0.0722
[Epoch 10, Batch 100] loss: 0.0481392121873796
**STATS for Epoch 10** : 
Average training loss: 0.0075
Average validation loss: 0.0734
Validation Accuracy: 0.9781
Overfitting: 0.0659
[Epoch 11, Batch 100] loss: 0.045742739257402715
**STATS for Epoch 11** : 
Average training loss: 0.0062
Average validation loss: 0.0620
Validation Accuracy: 0.9815
Overfitting: 0.0558
Best model saved at epoch 11 with validation loss: 0.0620
[Epoch 12, Batch 100] loss: 0.04165336037054658
**STATS for Epoch 12** : 
Average training loss: 0.0063
Average validation loss: 0.0758
Validation Accuracy: 0.9776
Overfitting: 0.0695
[Epoch 13, Batch 100] loss: 0.03489585681818426
**STATS for Epoch 13** : 
Average training loss: 0.0064
Average validation loss: 0.0692
Validation Accuracy: 0.9788
Overfitting: 0.0628
[Epoch 14, Batch 100] loss: 0.03130117913242429
**STATS for Epoch 14** : 
Average training loss: 0.0043
Average validation loss: 0.0655
Validation Accuracy: 0.9808
Overfitting: 0.0612
[Epoch 15, Batch 100] loss: 0.03383885817136616
**STATS for Epoch 15** : 
Average training loss: 0.0035
Average validation loss: 0.0594
Validation Accuracy: 0.9822
Overfitting: 0.0559
Best model saved at epoch 15 with validation loss: 0.0594
[Epoch 16, Batch 100] loss: 0.02746549267321825
**STATS for Epoch 16** : 
Average training loss: 0.0033
Average validation loss: 0.0560
Validation Accuracy: 0.9837
Overfitting: 0.0526
Best model saved at epoch 16 with validation loss: 0.0560
[Epoch 17, Batch 100] loss: 0.024125627279281615
**STATS for Epoch 17** : 
Average training loss: 0.0031
Average validation loss: 0.0582
Validation Accuracy: 0.9838
Overfitting: 0.0550
[Epoch 18, Batch 100] loss: 0.0213146128016524
**STATS for Epoch 18** : 
Average training loss: 0.0037
Average validation loss: 0.0593
Validation Accuracy: 0.9834
Overfitting: 0.0556
[Epoch 19, Batch 100] loss: 0.019666133830323815
**STATS for Epoch 19** : 
Average training loss: 0.0033
Average validation loss: 0.0549
Validation Accuracy: 0.9846
Overfitting: 0.0516
Best model saved at epoch 19 with validation loss: 0.0549
[Epoch 20, Batch 100] loss: 0.019970439285971225
**STATS for Epoch 20** : 
Average training loss: 0.0037
Average validation loss: 0.0614
Validation Accuracy: 0.9826
Overfitting: 0.0577
[Epoch 21, Batch 100] loss: 0.017556918121408673
**STATS for Epoch 21** : 
Average training loss: 0.0035
Average validation loss: 0.0770
Validation Accuracy: 0.9789
Overfitting: 0.0735
[Epoch 22, Batch 100] loss: 0.017350266647990793
**STATS for Epoch 22** : 
Average training loss: 0.0029
Average validation loss: 0.0587
Validation Accuracy: 0.9841
Overfitting: 0.0558
[Epoch 23, Batch 100] loss: 0.016451395999174567
**STATS for Epoch 23** : 
Average training loss: 0.0022
Average validation loss: 0.0592
Validation Accuracy: 0.9837
Overfitting: 0.0570
[Epoch 24, Batch 100] loss: 0.012439604096580298
**STATS for Epoch 24** : 
Average training loss: 0.0021
Average validation loss: 0.0573
Validation Accuracy: 0.9846
Overfitting: 0.0553
Fold 2 validation loss: 0.0573
Mean validation loss across all folds for Trial 13 is 0.0612 with trial config:  l1: 96, l2: 96, lr: 0.008169619653037311, batch_size: 256
[I 2024-11-19 01:59:09,910] Trial 12 finished with value: 0.0611825771807393 and parameters: {'l1': 96, 'l2': 96, 'lr': 0.008169619653037311, 'batch_size': 256}. Best is trial 0 with value: 0.05886771301817843.
[W 2024-11-19 01:59:09,941] The parameter 'l2' in trial#13 is sampled independently instead of being sampled by multivariate TPE sampler. (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler`, if this independent sampling is intended behavior.

Selected Hyperparameters for Trial 14:
  l1: 128, l2: 128, lr: 0.0194919910098972, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.2139567324519158
**STATS for Epoch 1** : 
Average training loss: 0.0335
Average validation loss: 0.2176
Validation Accuracy: 0.9314
Overfitting: 0.1842
Best model saved at epoch 1 with validation loss: 0.2176
[Epoch 2, Batch 100] loss: 0.16100780360400677
**STATS for Epoch 2** : 
Average training loss: 0.0161
Average validation loss: 0.1045
Validation Accuracy: 0.9679
Overfitting: 0.0883
Best model saved at epoch 2 with validation loss: 0.1045
[Epoch 3, Batch 100] loss: 0.08920582480728627
**STATS for Epoch 3** : 
Average training loss: 0.0125
Average validation loss: 0.0921
Validation Accuracy: 0.9693
Overfitting: 0.0796
Best model saved at epoch 3 with validation loss: 0.0921
[Epoch 4, Batch 100] loss: 0.06887741221114993
**STATS for Epoch 4** : 
Average training loss: 0.0114
Average validation loss: 0.0944
Validation Accuracy: 0.9694
Overfitting: 0.0830
[Epoch 5, Batch 100] loss: 0.056994144143536686
**STATS for Epoch 5** : 
Average training loss: 0.0079
Average validation loss: 0.0692
Validation Accuracy: 0.9787
Overfitting: 0.0614
Best model saved at epoch 5 with validation loss: 0.0692
[Epoch 6, Batch 100] loss: 0.047052078759297726
**STATS for Epoch 6** : 
Average training loss: 0.0060
Average validation loss: 0.0693
Validation Accuracy: 0.9792
Overfitting: 0.0633
[Epoch 7, Batch 100] loss: 0.040633603325113656
**STATS for Epoch 7** : 
Average training loss: 0.0059
Average validation loss: 0.0590
Validation Accuracy: 0.9818
Overfitting: 0.0531
Best model saved at epoch 7 with validation loss: 0.0590
[Epoch 8, Batch 100] loss: 0.03865945446304977
**STATS for Epoch 8** : 
Average training loss: 0.0050
Average validation loss: 0.0701
Validation Accuracy: 0.9799
Overfitting: 0.0651
[Epoch 9, Batch 100] loss: 0.033195044570602475
**STATS for Epoch 9** : 
Average training loss: 0.0032
Average validation loss: 0.0574
Validation Accuracy: 0.9833
Overfitting: 0.0542
Best model saved at epoch 9 with validation loss: 0.0574
[Epoch 10, Batch 100] loss: 0.022523318254388868
**STATS for Epoch 10** : 
Average training loss: 0.0039
Average validation loss: 0.0560
Validation Accuracy: 0.9834
Overfitting: 0.0521
Best model saved at epoch 10 with validation loss: 0.0560
[Epoch 11, Batch 100] loss: 0.022094625832978637
**STATS for Epoch 11** : 
Average training loss: 0.0041
Average validation loss: 0.0566
Validation Accuracy: 0.9835
Overfitting: 0.0525
[Epoch 12, Batch 100] loss: 0.019777646942529828
**STATS for Epoch 12** : 
Average training loss: 0.0029
Average validation loss: 0.0624
Validation Accuracy: 0.9824
Overfitting: 0.0595
[Epoch 13, Batch 100] loss: 0.016996190291829406
**STATS for Epoch 13** : 
Average training loss: 0.0027
Average validation loss: 0.0600
Validation Accuracy: 0.9824
Overfitting: 0.0573
[Epoch 14, Batch 100] loss: 0.013764779742341488
**STATS for Epoch 14** : 
Average training loss: 0.0023
Average validation loss: 0.0569
Validation Accuracy: 0.9844
Overfitting: 0.0546
[Epoch 15, Batch 100] loss: 0.01123058516648598
**STATS for Epoch 15** : 
Average training loss: 0.0019
Average validation loss: 0.0601
Validation Accuracy: 0.9844
Overfitting: 0.0582
[Epoch 16, Batch 100] loss: 0.0109084951155819
**STATS for Epoch 16** : 
Average training loss: 0.0016
Average validation loss: 0.0581
Validation Accuracy: 0.9851
Overfitting: 0.0564
[Epoch 17, Batch 100] loss: 0.010492037605727091
**STATS for Epoch 17** : 
Average training loss: 0.0016
Average validation loss: 0.0649
Validation Accuracy: 0.9835
Overfitting: 0.0634
[Epoch 18, Batch 100] loss: 0.008980364045128227
**STATS for Epoch 18** : 
Average training loss: 0.0023
Average validation loss: 0.0583
Validation Accuracy: 0.9848
Overfitting: 0.0560
[Epoch 19, Batch 100] loss: 0.011488339128554799
**STATS for Epoch 19** : 
Average training loss: 0.0017
Average validation loss: 0.0621
Validation Accuracy: 0.9852
Overfitting: 0.0604
[Epoch 20, Batch 100] loss: 0.007929515722789802
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0583
Validation Accuracy: 0.9861
Overfitting: 0.0576
[Epoch 21, Batch 100] loss: 0.003975499619846232
**STATS for Epoch 21** : 
Average training loss: 0.0007
Average validation loss: 0.0594
Validation Accuracy: 0.9859
Overfitting: 0.0587
[Epoch 22, Batch 100] loss: 0.005396510325372219
**STATS for Epoch 22** : 
Average training loss: 0.0010
Average validation loss: 0.0623
Validation Accuracy: 0.9861
Overfitting: 0.0613
[Epoch 23, Batch 100] loss: 0.0029213730819174087
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0620
Validation Accuracy: 0.9862
Overfitting: 0.0617
[Epoch 24, Batch 100] loss: 0.0034865418821573256
**STATS for Epoch 24** : 
Average training loss: 0.0011
Average validation loss: 0.0689
Validation Accuracy: 0.9842
Overfitting: 0.0678
Fold 1 validation loss: 0.0689
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.0423804597556592
**STATS for Epoch 1** : 
Average training loss: 0.0332
Average validation loss: 0.1953
Validation Accuracy: 0.9394
Overfitting: 0.1621
Best model saved at epoch 1 with validation loss: 0.1953
[Epoch 2, Batch 100] loss: 0.14206731684505938
**STATS for Epoch 2** : 
Average training loss: 0.0206
Average validation loss: 0.1338
Validation Accuracy: 0.9593
Overfitting: 0.1132
Best model saved at epoch 2 with validation loss: 0.1338
[Epoch 3, Batch 100] loss: 0.0968598821759224
**STATS for Epoch 3** : 
Average training loss: 0.0137
Average validation loss: 0.0927
Validation Accuracy: 0.9708
Overfitting: 0.0790
Best model saved at epoch 3 with validation loss: 0.0927
[Epoch 4, Batch 100] loss: 0.07492037447169424
**STATS for Epoch 4** : 
Average training loss: 0.0095
Average validation loss: 0.0772
Validation Accuracy: 0.9757
Overfitting: 0.0677
Best model saved at epoch 4 with validation loss: 0.0772
[Epoch 5, Batch 100] loss: 0.058857141230255365
**STATS for Epoch 5** : 
Average training loss: 0.0104
Average validation loss: 0.0703
Validation Accuracy: 0.9796
Overfitting: 0.0599
Best model saved at epoch 5 with validation loss: 0.0703
[Epoch 6, Batch 100] loss: 0.049062643107026814
**STATS for Epoch 6** : 
Average training loss: 0.0071
Average validation loss: 0.0612
Validation Accuracy: 0.9817
Overfitting: 0.0541
Best model saved at epoch 6 with validation loss: 0.0612
[Epoch 7, Batch 100] loss: 0.03902225110679865
**STATS for Epoch 7** : 
Average training loss: 0.0065
Average validation loss: 0.0548
Validation Accuracy: 0.9832
Overfitting: 0.0483
Best model saved at epoch 7 with validation loss: 0.0548
[Epoch 8, Batch 100] loss: 0.033565222667530176
**STATS for Epoch 8** : 
Average training loss: 0.0044
Average validation loss: 0.0642
Validation Accuracy: 0.9821
Overfitting: 0.0598
[Epoch 9, Batch 100] loss: 0.0324883703654632
**STATS for Epoch 9** : 
Average training loss: 0.0043
Average validation loss: 0.0566
Validation Accuracy: 0.9828
Overfitting: 0.0523
[Epoch 10, Batch 100] loss: 0.023555163578130305
**STATS for Epoch 10** : 
Average training loss: 0.0031
Average validation loss: 0.0564
Validation Accuracy: 0.9841
Overfitting: 0.0533
[Epoch 11, Batch 100] loss: 0.022235541283153
**STATS for Epoch 11** : 
Average training loss: 0.0032
Average validation loss: 0.0581
Validation Accuracy: 0.9833
Overfitting: 0.0549
[Epoch 12, Batch 100] loss: 0.017288306280970573
**STATS for Epoch 12** : 
Average training loss: 0.0032
Average validation loss: 0.0705
Validation Accuracy: 0.9811
Overfitting: 0.0673
[Epoch 13, Batch 100] loss: 0.018145787678658962
**STATS for Epoch 13** : 
Average training loss: 0.0037
Average validation loss: 0.0775
Validation Accuracy: 0.9784
Overfitting: 0.0738
[Epoch 14, Batch 100] loss: 0.017855693664168937
**STATS for Epoch 14** : 
Average training loss: 0.0023
Average validation loss: 0.0555
Validation Accuracy: 0.9848
Overfitting: 0.0532
[Epoch 15, Batch 100] loss: 0.014956947087193839
**STATS for Epoch 15** : 
Average training loss: 0.0030
Average validation loss: 0.0725
Validation Accuracy: 0.9818
Overfitting: 0.0695
[Epoch 16, Batch 100] loss: 0.014033998578088357
**STATS for Epoch 16** : 
Average training loss: 0.0022
Average validation loss: 0.0665
Validation Accuracy: 0.9832
Overfitting: 0.0642
[Epoch 17, Batch 100] loss: 0.008270686044706963
**STATS for Epoch 17** : 
Average training loss: 0.0014
Average validation loss: 0.0632
Validation Accuracy: 0.9839
Overfitting: 0.0618
[Epoch 18, Batch 100] loss: 0.007921933690086006
**STATS for Epoch 18** : 
Average training loss: 0.0010
Average validation loss: 0.0596
Validation Accuracy: 0.9854
Overfitting: 0.0587
[Epoch 19, Batch 100] loss: 0.006084056189865805
**STATS for Epoch 19** : 
Average training loss: 0.0012
Average validation loss: 0.0613
Validation Accuracy: 0.9856
Overfitting: 0.0601
[Epoch 20, Batch 100] loss: 0.007503212235169485
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0703
Validation Accuracy: 0.9843
Overfitting: 0.0694
[Epoch 21, Batch 100] loss: 0.00589959462871775
**STATS for Epoch 21** : 
Average training loss: 0.0011
Average validation loss: 0.0627
Validation Accuracy: 0.9860
Overfitting: 0.0616
[Epoch 22, Batch 100] loss: 0.004504641373350751
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0662
Validation Accuracy: 0.9858
Overfitting: 0.0656
[Epoch 23, Batch 100] loss: 0.0038909055515250657
**STATS for Epoch 23** : 
Average training loss: 0.0007
Average validation loss: 0.0691
Validation Accuracy: 0.9858
Overfitting: 0.0684
[Epoch 24, Batch 100] loss: 0.002877248253353173
**STATS for Epoch 24** : 
Average training loss: 0.0009
Average validation loss: 0.0731
Validation Accuracy: 0.9845
Overfitting: 0.0723
Fold 2 validation loss: 0.0731
Mean validation loss across all folds for Trial 14 is 0.0710 with trial config:  l1: 128, l2: 128, lr: 0.0194919910098972, batch_size: 256
[I 2024-11-19 02:07:09,682] Trial 13 finished with value: 0.07102813519415607 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0194919910098972, 'batch_size': 256}. Best is trial 0 with value: 0.05886771301817843.
[W 2024-11-19 02:07:09,714] The parameter 'l2' in trial#14 is sampled independently instead of being sampled by multivariate TPE sampler. (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler`, if this independent sampling is intended behavior.

Selected Hyperparameters for Trial 15:
  l1: 64, l2: 32, lr: 0.0011091980796438998, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2986862468719482
**STATS for Epoch 1** : 
Average training loss: 0.3494
Average validation loss: 2.2890
Validation Accuracy: 0.1265
Overfitting: 1.9396
Best model saved at epoch 1 with validation loss: 2.2890
[Epoch 2, Batch 100] loss: 2.2794477415084837
**STATS for Epoch 2** : 
Average training loss: 0.3454
Average validation loss: 2.2599
Validation Accuracy: 0.3213
Overfitting: 1.9145
Best model saved at epoch 2 with validation loss: 2.2599
[Epoch 3, Batch 100] loss: 2.2284214973449705
**STATS for Epoch 3** : 
Average training loss: 0.3293
Average validation loss: 2.1384
Validation Accuracy: 0.3942
Overfitting: 1.8090
Best model saved at epoch 3 with validation loss: 2.1384
[Epoch 4, Batch 100] loss: 1.9023872005939484
**STATS for Epoch 4** : 
Average training loss: 0.2261
Average validation loss: 1.4027
Validation Accuracy: 0.5604
Overfitting: 1.1767
Best model saved at epoch 4 with validation loss: 1.4027
[Epoch 5, Batch 100] loss: 1.1272586649656295
**STATS for Epoch 5** : 
Average training loss: 0.1336
Average validation loss: 0.8290
Validation Accuracy: 0.7417
Overfitting: 0.6954
Best model saved at epoch 5 with validation loss: 0.8290
[Epoch 6, Batch 100] loss: 0.6735136613249779
**STATS for Epoch 6** : 
Average training loss: 0.0853
Average validation loss: 0.5343
Validation Accuracy: 0.8346
Overfitting: 0.4490
Best model saved at epoch 6 with validation loss: 0.5343
[Epoch 7, Batch 100] loss: 0.4844625633955002
**STATS for Epoch 7** : 
Average training loss: 0.0709
Average validation loss: 0.4332
Validation Accuracy: 0.8678
Overfitting: 0.3623
Best model saved at epoch 7 with validation loss: 0.4332
[Epoch 8, Batch 100] loss: 0.4079273754358292
**STATS for Epoch 8** : 
Average training loss: 0.0564
Average validation loss: 0.3686
Validation Accuracy: 0.8838
Overfitting: 0.3122
Best model saved at epoch 8 with validation loss: 0.3686
[Epoch 9, Batch 100] loss: 0.3428240756690502
**STATS for Epoch 9** : 
Average training loss: 0.0487
Average validation loss: 0.3181
Validation Accuracy: 0.9035
Overfitting: 0.2694
[I 2024-11-19 02:08:39,707] Trial 14 pruned. 
[W 2024-11-19 02:08:39,738] The parameter 'l2' in trial#15 is sampled independently instead of being sampled by multivariate TPE sampler. (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler`, if this independent sampling is intended behavior.

Selected Hyperparameters for Trial 16:
  l1: 192, l2: 160, lr: 0.0035382786079189905, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.1002520763874055
**STATS for Epoch 1** : 
Average training loss: 0.1577
Average validation loss: 0.8250
Validation Accuracy: 0.7408
Overfitting: 0.6674
Best model saved at epoch 1 with validation loss: 0.8250
[Epoch 2, Batch 100] loss: 0.4894374069571495
**STATS for Epoch 2** : 
Average training loss: 0.0510
Average validation loss: 0.3941
Validation Accuracy: 0.8790
Overfitting: 0.3432
Best model saved at epoch 2 with validation loss: 0.3941
[Epoch 3, Batch 100] loss: 0.2791182494163513
**STATS for Epoch 3** : 
Average training loss: 0.0356
Average validation loss: 0.2166
Validation Accuracy: 0.9356
Overfitting: 0.1811
Best model saved at epoch 3 with validation loss: 0.2166
[Epoch 4, Batch 100] loss: 0.19190906606614588
**STATS for Epoch 4** : 
Average training loss: 0.0246
Average validation loss: 0.1688
Validation Accuracy: 0.9479
Overfitting: 0.1441
Best model saved at epoch 4 with validation loss: 0.1688
[Epoch 5, Batch 100] loss: 0.1519524382799864
**STATS for Epoch 5** : 
Average training loss: 0.0206
Average validation loss: 0.1367
Validation Accuracy: 0.9573
Overfitting: 0.1161
Best model saved at epoch 5 with validation loss: 0.1367
[Epoch 6, Batch 100] loss: 0.1281616910174489
**STATS for Epoch 6** : 
Average training loss: 0.0192
Average validation loss: 0.1339
Validation Accuracy: 0.9586
Overfitting: 0.1147
Best model saved at epoch 6 with validation loss: 0.1339
[Epoch 7, Batch 100] loss: 0.11506191797554494
**STATS for Epoch 7** : 
Average training loss: 0.0155
Average validation loss: 0.1416
Validation Accuracy: 0.9551
Overfitting: 0.1262
[Epoch 8, Batch 100] loss: 0.10021542504429817
**STATS for Epoch 8** : 
Average training loss: 0.0139
Average validation loss: 0.0978
Validation Accuracy: 0.9694
Overfitting: 0.0840
Best model saved at epoch 8 with validation loss: 0.0978
[Epoch 9, Batch 100] loss: 0.08894015051424503
**STATS for Epoch 9** : 
Average training loss: 0.0137
Average validation loss: 0.0995
Validation Accuracy: 0.9684
Overfitting: 0.0857
[I 2024-11-19 02:10:09,681] Trial 15 pruned. 

Selected Hyperparameters for Trial 17:
  l1: 352, l2: 160, lr: 0.0009350705458597145, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.293777034282684
[Epoch 1, Batch 200] loss: 2.260069305896759
[Epoch 1, Batch 300] loss: 2.14676687002182
[Epoch 1, Batch 400] loss: 1.4358523744344711
[Epoch 1, Batch 500] loss: 0.6588651475310325
[Epoch 1, Batch 600] loss: 0.5031698815524578
[Epoch 1, Batch 700] loss: 0.41893565490841866
[Epoch 1, Batch 800] loss: 0.42863923028111456
[Epoch 1, Batch 900] loss: 0.3185969976335764
**STATS for Epoch 1** : 
Average training loss: 0.0124
Average validation loss: 0.2907
Validation Accuracy: 0.9130
Overfitting: 0.2783
Best model saved at epoch 1 with validation loss: 0.2907
[Epoch 2, Batch 100] loss: 0.3045559702068567
[Epoch 2, Batch 200] loss: 0.28113869920372964
[Epoch 2, Batch 300] loss: 0.24116311281919478
[Epoch 2, Batch 400] loss: 0.21614393137395382
[Epoch 2, Batch 500] loss: 0.22817816331982613
[Epoch 2, Batch 600] loss: 0.20214506890624762
[Epoch 2, Batch 700] loss: 0.19356165133416653
[Epoch 2, Batch 800] loss: 0.17104213951155545
[Epoch 2, Batch 900] loss: 0.17636504478752613
**STATS for Epoch 2** : 
Average training loss: 0.0062
Average validation loss: 0.1669
Validation Accuracy: 0.9480
Overfitting: 0.1607
Best model saved at epoch 2 with validation loss: 0.1669
[Epoch 3, Batch 100] loss: 0.14667117614299058
[Epoch 3, Batch 200] loss: 0.14653317453339695
[Epoch 3, Batch 300] loss: 0.14497325415723025
[Epoch 3, Batch 400] loss: 0.1188866135198623
[Epoch 3, Batch 500] loss: 0.14721786074340343
[Epoch 3, Batch 600] loss: 0.1363616402540356
[Epoch 3, Batch 700] loss: 0.13483994358219206
[Epoch 3, Batch 800] loss: 0.1216422002017498
[Epoch 3, Batch 900] loss: 0.11588258156552911
**STATS for Epoch 3** : 
Average training loss: 0.0048
Average validation loss: 0.1123
Validation Accuracy: 0.9652
Overfitting: 0.1075
Best model saved at epoch 3 with validation loss: 0.1123
[Epoch 4, Batch 100] loss: 0.10899884390644729
[Epoch 4, Batch 200] loss: 0.11556124715134501
[Epoch 4, Batch 300] loss: 0.09456566831795499
[Epoch 4, Batch 400] loss: 0.09117678402923048
[Epoch 4, Batch 500] loss: 0.10830301575362683
[Epoch 4, Batch 600] loss: 0.10752025098074228
[Epoch 4, Batch 700] loss: 0.0878802821901627
[Epoch 4, Batch 800] loss: 0.08770616541616619
[Epoch 4, Batch 900] loss: 0.08455524194752798
**STATS for Epoch 4** : 
Average training loss: 0.0045
Average validation loss: 0.1043
Validation Accuracy: 0.9677
Overfitting: 0.0998
Best model saved at epoch 4 with validation loss: 0.1043
[Epoch 5, Batch 100] loss: 0.09147598239593208
[Epoch 5, Batch 200] loss: 0.08236126993317157
[Epoch 5, Batch 300] loss: 0.07428060591220856
[Epoch 5, Batch 400] loss: 0.07519618763588369
[Epoch 5, Batch 500] loss: 0.0793200604338199
[Epoch 5, Batch 600] loss: 0.07173589762765914
[Epoch 5, Batch 700] loss: 0.08102143505588173
[Epoch 5, Batch 800] loss: 0.07910885168006644
[Epoch 5, Batch 900] loss: 0.09235953318420798
**STATS for Epoch 5** : 
Average training loss: 0.0029
Average validation loss: 0.0864
Validation Accuracy: 0.9733
Overfitting: 0.0835
Best model saved at epoch 5 with validation loss: 0.0864
[Epoch 6, Batch 100] loss: 0.06471527002751827
[Epoch 6, Batch 200] loss: 0.07363115502055734
[Epoch 6, Batch 300] loss: 0.06660719427280128
[Epoch 6, Batch 400] loss: 0.07767128548352048
[Epoch 6, Batch 500] loss: 0.07145157207036391
[Epoch 6, Batch 600] loss: 0.06517750093713402
[Epoch 6, Batch 700] loss: 0.07015466078417376
[Epoch 6, Batch 800] loss: 0.07408745220396667
[Epoch 6, Batch 900] loss: 0.06500434330198913
**STATS for Epoch 6** : 
Average training loss: 0.0023
Average validation loss: 0.0799
Validation Accuracy: 0.9756
Overfitting: 0.0776
Best model saved at epoch 6 with validation loss: 0.0799
[Epoch 7, Batch 100] loss: 0.07242914867121726
[Epoch 7, Batch 200] loss: 0.058633663116488606
[Epoch 7, Batch 300] loss: 0.057249295234214514
[Epoch 7, Batch 400] loss: 0.056824684459716085
[Epoch 7, Batch 500] loss: 0.06149691762169823
[Epoch 7, Batch 600] loss: 0.060192033345811066
[Epoch 7, Batch 700] loss: 0.061866841684095564
[Epoch 7, Batch 800] loss: 0.05353241173550487
[Epoch 7, Batch 900] loss: 0.06768072640988976
**STATS for Epoch 7** : 
Average training loss: 0.0020
Average validation loss: 0.0717
Validation Accuracy: 0.9776
Overfitting: 0.0697
Best model saved at epoch 7 with validation loss: 0.0717
[Epoch 8, Batch 100] loss: 0.04526215167483315
[Epoch 8, Batch 200] loss: 0.055948347736848515
[Epoch 8, Batch 300] loss: 0.04775043150410056
[Epoch 8, Batch 400] loss: 0.0447450156067498
[Epoch 8, Batch 500] loss: 0.05791001809295267
[Epoch 8, Batch 600] loss: 0.058431943599134686
[Epoch 8, Batch 700] loss: 0.051441914029419424
[Epoch 8, Batch 800] loss: 0.049608616641489786
[Epoch 8, Batch 900] loss: 0.045661693200236185
**STATS for Epoch 8** : 
Average training loss: 0.0030
Average validation loss: 0.0702
Validation Accuracy: 0.9784
Overfitting: 0.0672
Best model saved at epoch 8 with validation loss: 0.0702
[Epoch 9, Batch 100] loss: 0.043694544172612954
[Epoch 9, Batch 200] loss: 0.04223485335591249
[Epoch 9, Batch 300] loss: 0.05029095523059368
[Epoch 9, Batch 400] loss: 0.04672580853337422
[Epoch 9, Batch 500] loss: 0.0518799970112741
[Epoch 9, Batch 600] loss: 0.05976842617383227
[Epoch 9, Batch 700] loss: 0.03683636618545279
[Epoch 9, Batch 800] loss: 0.04540140523226
[Epoch 9, Batch 900] loss: 0.03389090854674578
**STATS for Epoch 9** : 
Average training loss: 0.0029
Average validation loss: 0.0799
Validation Accuracy: 0.9748
Overfitting: 0.0770
[Epoch 10, Batch 100] loss: 0.040971426436735785
[Epoch 10, Batch 200] loss: 0.03724157422780991
[Epoch 10, Batch 300] loss: 0.041376454280107285
[Epoch 10, Batch 400] loss: 0.043587124756304545
[Epoch 10, Batch 500] loss: 0.04401833081501536
[Epoch 10, Batch 600] loss: 0.044325939679984
[Epoch 10, Batch 700] loss: 0.03263178554887418
[Epoch 10, Batch 800] loss: 0.040840683616697786
[Epoch 10, Batch 900] loss: 0.04932757955626585
**STATS for Epoch 10** : 
Average training loss: 0.0018
Average validation loss: 0.0624
Validation Accuracy: 0.9804
Overfitting: 0.0606
Best model saved at epoch 10 with validation loss: 0.0624
[Epoch 11, Batch 100] loss: 0.03935795698780566
[Epoch 11, Batch 200] loss: 0.03671760324970819
[Epoch 11, Batch 300] loss: 0.03583186953910626
[Epoch 11, Batch 400] loss: 0.03419771024142392
[Epoch 11, Batch 500] loss: 0.029608142362558282
[Epoch 11, Batch 600] loss: 0.04395626537851058
[Epoch 11, Batch 700] loss: 0.03863891599699855
[Epoch 11, Batch 800] loss: 0.04350812909484375
[Epoch 11, Batch 900] loss: 0.04263719939946895
**STATS for Epoch 11** : 
Average training loss: 0.0015
Average validation loss: 0.0561
Validation Accuracy: 0.9829
Overfitting: 0.0546
Best model saved at epoch 11 with validation loss: 0.0561
[Epoch 12, Batch 100] loss: 0.023569692607270553
[Epoch 12, Batch 200] loss: 0.041236425004899505
[Epoch 12, Batch 300] loss: 0.034002249752520586
[Epoch 12, Batch 400] loss: 0.03247640588378999
[Epoch 12, Batch 500] loss: 0.03514064526068978
[Epoch 12, Batch 600] loss: 0.04584036952583119
[Epoch 12, Batch 700] loss: 0.029913409724249506
[Epoch 12, Batch 800] loss: 0.0312640475932858
[Epoch 12, Batch 900] loss: 0.0377493832440814
**STATS for Epoch 12** : 
Average training loss: 0.0014
Average validation loss: 0.0577
Validation Accuracy: 0.9827
Overfitting: 0.0563
[Epoch 13, Batch 100] loss: 0.023576398587611038
[Epoch 13, Batch 200] loss: 0.03176359808538109
[Epoch 13, Batch 300] loss: 0.031025422673556024
[Epoch 13, Batch 400] loss: 0.031123146071913653
[Epoch 13, Batch 500] loss: 0.023837137308582897
[Epoch 13, Batch 600] loss: 0.03246057974814903
[Epoch 13, Batch 700] loss: 0.03474054481717758
[Epoch 13, Batch 800] loss: 0.03128536281990819
[Epoch 13, Batch 900] loss: 0.030315868336474525
**STATS for Epoch 13** : 
Average training loss: 0.0012
Average validation loss: 0.0543
Validation Accuracy: 0.9839
Overfitting: 0.0531
Best model saved at epoch 13 with validation loss: 0.0543
[Epoch 14, Batch 100] loss: 0.025557975587435066
[Epoch 14, Batch 200] loss: 0.02416066805482842
[Epoch 14, Batch 300] loss: 0.02006727884610882
[Epoch 14, Batch 400] loss: 0.03312043262878433
[Epoch 14, Batch 500] loss: 0.031195977610186675
[Epoch 14, Batch 600] loss: 0.027896748221246527
[Epoch 14, Batch 700] loss: 0.027465857981005683
[Epoch 14, Batch 800] loss: 0.030763790711935145
[Epoch 14, Batch 900] loss: 0.029290409469394943
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0586
Validation Accuracy: 0.9832
Overfitting: 0.0576
[Epoch 15, Batch 100] loss: 0.01872398712701397
[Epoch 15, Batch 200] loss: 0.017266061097034255
[Epoch 15, Batch 300] loss: 0.02556992052705027
[Epoch 15, Batch 400] loss: 0.026905560543527825
[Epoch 15, Batch 500] loss: 0.02579230873612687
[Epoch 15, Batch 600] loss: 0.018689742165297504
[Epoch 15, Batch 700] loss: 0.02164193179574795
[Epoch 15, Batch 800] loss: 0.033663650784874335
[Epoch 15, Batch 900] loss: 0.03730538351999712
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0559
Validation Accuracy: 0.9834
Overfitting: 0.0553
[Epoch 16, Batch 100] loss: 0.024354253518686163
[Epoch 16, Batch 200] loss: 0.02439865187043324
[Epoch 16, Batch 300] loss: 0.018702682694856775
[Epoch 16, Batch 400] loss: 0.0249020249187015
[Epoch 16, Batch 500] loss: 0.015734896487556396
[Epoch 16, Batch 600] loss: 0.020616410342627206
[Epoch 16, Batch 700] loss: 0.02255969030316919
[Epoch 16, Batch 800] loss: 0.022279724420513958
[Epoch 16, Batch 900] loss: 0.025263524614128983
**STATS for Epoch 16** : 
Average training loss: 0.0013
Average validation loss: 0.0589
Validation Accuracy: 0.9828
Overfitting: 0.0577
[Epoch 17, Batch 100] loss: 0.02010094797369675
[Epoch 17, Batch 200] loss: 0.016204120383481495
[Epoch 17, Batch 300] loss: 0.019906470064888708
[Epoch 17, Batch 400] loss: 0.020463308876933296
[Epoch 17, Batch 500] loss: 0.029422570165188518
[Epoch 17, Batch 600] loss: 0.01773318362014834
[Epoch 17, Batch 700] loss: 0.020012476322299334
[Epoch 17, Batch 800] loss: 0.019222347549221013
[Epoch 17, Batch 900] loss: 0.027830460298573598
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0552
Validation Accuracy: 0.9841
Overfitting: 0.0547
[Epoch 18, Batch 100] loss: 0.012075943753297907
[Epoch 18, Batch 200] loss: 0.009445372040499934
[Epoch 18, Batch 300] loss: 0.025391025041317336
[Epoch 18, Batch 400] loss: 0.020434483379940502
[Epoch 18, Batch 500] loss: 0.02011466332405689
[Epoch 18, Batch 600] loss: 0.023851823124714427
[Epoch 18, Batch 700] loss: 0.021677160549297695
[Epoch 18, Batch 800] loss: 0.017392095028189943
[Epoch 18, Batch 900] loss: 0.013897785357257816
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0573
Validation Accuracy: 0.9833
Overfitting: 0.0568
[Epoch 19, Batch 100] loss: 0.016997436768433544
[Epoch 19, Batch 200] loss: 0.01313240436691558
[Epoch 19, Batch 300] loss: 0.014691783882299206
[Epoch 19, Batch 400] loss: 0.022230330465681618
[Epoch 19, Batch 500] loss: 0.010601182982645696
[Epoch 19, Batch 600] loss: 0.02027797667797131
[Epoch 19, Batch 700] loss: 0.021842878230963834
[Epoch 19, Batch 800] loss: 0.015535860946765751
[Epoch 19, Batch 900] loss: 0.010099481473807827
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0556
Validation Accuracy: 0.9845
Overfitting: 0.0550
[Epoch 20, Batch 100] loss: 0.011902504286372278
[Epoch 20, Batch 200] loss: 0.017649302954014276
[Epoch 20, Batch 300] loss: 0.022566475369676483
[Epoch 20, Batch 400] loss: 0.012031734208285343
[Epoch 20, Batch 500] loss: 0.011512112251948566
[Epoch 20, Batch 600] loss: 0.013041986297539552
[Epoch 20, Batch 700] loss: 0.01242619960954471
[Epoch 20, Batch 800] loss: 0.013162254864437273
[Epoch 20, Batch 900] loss: 0.01456584894003754
**STATS for Epoch 20** : 
Average training loss: 0.0007
Average validation loss: 0.0596
Validation Accuracy: 0.9843
Overfitting: 0.0589
[Epoch 21, Batch 100] loss: 0.01239444183782325
[Epoch 21, Batch 200] loss: 0.01039704170623736
[Epoch 21, Batch 300] loss: 0.008130909662540944
[Epoch 21, Batch 400] loss: 0.015555157104281535
[Epoch 21, Batch 500] loss: 0.013236017997696763
[Epoch 21, Batch 600] loss: 0.013947400338147418
[Epoch 21, Batch 700] loss: 0.011110949217254529
[Epoch 21, Batch 800] loss: 0.014034392768371618
[Epoch 21, Batch 900] loss: 0.013337507023097715
**STATS for Epoch 21** : 
Average training loss: 0.0007
Average validation loss: 0.0626
Validation Accuracy: 0.9830
Overfitting: 0.0619
[Epoch 22, Batch 100] loss: 0.010568456384717137
[Epoch 22, Batch 200] loss: 0.007574414637565497
[Epoch 22, Batch 300] loss: 0.013984245391657168
[Epoch 22, Batch 400] loss: 0.01578626881899254
[Epoch 22, Batch 500] loss: 0.010931939733782202
[Epoch 22, Batch 600] loss: 0.011445921864487901
[Epoch 22, Batch 700] loss: 0.01159560684900498
[Epoch 22, Batch 800] loss: 0.009784310583072511
[Epoch 22, Batch 900] loss: 0.012079554759911843
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0573
Validation Accuracy: 0.9841
Overfitting: 0.0568
[Epoch 23, Batch 100] loss: 0.010164131164419814
[Epoch 23, Batch 200] loss: 0.006317067832060275
[Epoch 23, Batch 300] loss: 0.008129982230893801
[Epoch 23, Batch 400] loss: 0.007236715696963074
[Epoch 23, Batch 500] loss: 0.008475594697483758
[Epoch 23, Batch 600] loss: 0.009965120388951618
[Epoch 23, Batch 700] loss: 0.008482900662347675
[Epoch 23, Batch 800] loss: 0.012846138464519754
[Epoch 23, Batch 900] loss: 0.010391894484782824
**STATS for Epoch 23** : 
Average training loss: 0.0007
Average validation loss: 0.0584
Validation Accuracy: 0.9840
Overfitting: 0.0578
[Epoch 24, Batch 100] loss: 0.007415807020661305
[Epoch 24, Batch 200] loss: 0.0062936605584764035
[Epoch 24, Batch 300] loss: 0.007996560849096567
[Epoch 24, Batch 400] loss: 0.006633270736201667
[Epoch 24, Batch 500] loss: 0.009692906844284152
[Epoch 24, Batch 600] loss: 0.007591954740928486
[Epoch 24, Batch 700] loss: 0.005935742346337065
[Epoch 24, Batch 800] loss: 0.011800317657907726
[Epoch 24, Batch 900] loss: 0.008154666683622054
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0610
Validation Accuracy: 0.9837
Overfitting: 0.0606
Fold 1 validation loss: 0.0610
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.2929825735092164
[Epoch 1, Batch 200] loss: 2.2514575052261354
[Epoch 1, Batch 300] loss: 2.064239555597305
[Epoch 1, Batch 400] loss: 1.1341840359568596
[Epoch 1, Batch 500] loss: 0.5508662408590317
[Epoch 1, Batch 600] loss: 0.47344247341156004
[Epoch 1, Batch 700] loss: 0.39404020115733146
[Epoch 1, Batch 800] loss: 0.35274640761315823
[Epoch 1, Batch 900] loss: 0.31559653595089915
**STATS for Epoch 1** : 
Average training loss: 0.0118
Average validation loss: 0.2916
Validation Accuracy: 0.9110
Overfitting: 0.2798
Best model saved at epoch 1 with validation loss: 0.2916
[Epoch 2, Batch 100] loss: 0.2754376814514399
[Epoch 2, Batch 200] loss: 0.2723312531039119
[Epoch 2, Batch 300] loss: 0.27097031485289336
[Epoch 2, Batch 400] loss: 0.21910566911101342
[Epoch 2, Batch 500] loss: 0.23153881914913654
[Epoch 2, Batch 600] loss: 0.19119466070085764
[Epoch 2, Batch 700] loss: 0.17495025236159564
[Epoch 2, Batch 800] loss: 0.173505476731807
[Epoch 2, Batch 900] loss: 0.20179970735684039
**STATS for Epoch 2** : 
Average training loss: 0.0070
Average validation loss: 0.1789
Validation Accuracy: 0.9462
Overfitting: 0.1718
Best model saved at epoch 2 with validation loss: 0.1789
[Epoch 3, Batch 100] loss: 0.1663789239525795
[Epoch 3, Batch 200] loss: 0.15078770460560917
[Epoch 3, Batch 300] loss: 0.16225675063207745
[Epoch 3, Batch 400] loss: 0.15804678920656443
[Epoch 3, Batch 500] loss: 0.1257145537249744
[Epoch 3, Batch 600] loss: 0.15448539493605495
[Epoch 3, Batch 700] loss: 0.14332986694760622
[Epoch 3, Batch 800] loss: 0.10902152050286532
[Epoch 3, Batch 900] loss: 0.13667827080003916
**STATS for Epoch 3** : 
Average training loss: 0.0047
Average validation loss: 0.1677
Validation Accuracy: 0.9453
Overfitting: 0.1630
Best model saved at epoch 3 with validation loss: 0.1677
[Epoch 4, Batch 100] loss: 0.1105292906658724
[Epoch 4, Batch 200] loss: 0.12129020809195935
[Epoch 4, Batch 300] loss: 0.12964711159467698
[Epoch 4, Batch 400] loss: 0.12011424764059483
[Epoch 4, Batch 500] loss: 0.0931524169165641
[Epoch 4, Batch 600] loss: 0.10590676997788251
[Epoch 4, Batch 700] loss: 0.10413393116090447
[Epoch 4, Batch 800] loss: 0.09687742808368056
[Epoch 4, Batch 900] loss: 0.09433768588118255
**STATS for Epoch 4** : 
Average training loss: 0.0038
Average validation loss: 0.1007
Validation Accuracy: 0.9685
Overfitting: 0.0969
Best model saved at epoch 4 with validation loss: 0.1007
[Epoch 5, Batch 100] loss: 0.09213082160800695
[Epoch 5, Batch 200] loss: 0.08606276879785582
[Epoch 5, Batch 300] loss: 0.08606057886965574
[Epoch 5, Batch 400] loss: 0.08386308887507767
[Epoch 5, Batch 500] loss: 0.09121695695444941
[Epoch 5, Batch 600] loss: 0.10620993088465185
[Epoch 5, Batch 700] loss: 0.08943330028094351
[Epoch 5, Batch 800] loss: 0.06508039427921176
[Epoch 5, Batch 900] loss: 0.0806019542599097
**STATS for Epoch 5** : 
Average training loss: 0.0029
Average validation loss: 0.0873
Validation Accuracy: 0.9732
Overfitting: 0.0844
Best model saved at epoch 5 with validation loss: 0.0873
[Epoch 6, Batch 100] loss: 0.08475557468831539
[Epoch 6, Batch 200] loss: 0.07834646301809699
[Epoch 6, Batch 300] loss: 0.08567099411273375
[Epoch 6, Batch 400] loss: 0.07442817715462297
[Epoch 6, Batch 500] loss: 0.07970145211089402
[Epoch 6, Batch 600] loss: 0.06904220700729638
[Epoch 6, Batch 700] loss: 0.07329388862475752
[Epoch 6, Batch 800] loss: 0.06501781340572052
[Epoch 6, Batch 900] loss: 0.07281272993423045
**STATS for Epoch 6** : 
Average training loss: 0.0033
Average validation loss: 0.0798
Validation Accuracy: 0.9759
Overfitting: 0.0764
Best model saved at epoch 6 with validation loss: 0.0798
[Epoch 7, Batch 100] loss: 0.05806305404519662
[Epoch 7, Batch 200] loss: 0.07554990369826556
[Epoch 7, Batch 300] loss: 0.05971672645071521
[Epoch 7, Batch 400] loss: 0.06414877619827167
[Epoch 7, Batch 500] loss: 0.06560257373843342
[Epoch 7, Batch 600] loss: 0.06134094961918891
[Epoch 7, Batch 700] loss: 0.06923349524848163
[Epoch 7, Batch 800] loss: 0.05381232500774786
[Epoch 7, Batch 900] loss: 0.0723181667434983
**STATS for Epoch 7** : 
Average training loss: 0.0026
Average validation loss: 0.0815
Validation Accuracy: 0.9736
Overfitting: 0.0789
[Epoch 8, Batch 100] loss: 0.05906254626112059
[Epoch 8, Batch 200] loss: 0.06152659852523357
[Epoch 8, Batch 300] loss: 0.044005301957949994
[Epoch 8, Batch 400] loss: 0.04783409630181268
[Epoch 8, Batch 500] loss: 0.06230197068769485
[Epoch 8, Batch 600] loss: 0.05112566358409822
[Epoch 8, Batch 700] loss: 0.06564631679677405
[Epoch 8, Batch 800] loss: 0.05423003440373577
[Epoch 8, Batch 900] loss: 0.06596421671565622
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0701
Validation Accuracy: 0.9782
Overfitting: 0.0677
Best model saved at epoch 8 with validation loss: 0.0701
[Epoch 9, Batch 100] loss: 0.048526835573138666
[Epoch 9, Batch 200] loss: 0.04088354556355625
[Epoch 9, Batch 300] loss: 0.05366685284068808
[Epoch 9, Batch 400] loss: 0.045085658888565375
[Epoch 9, Batch 500] loss: 0.0518009222013643
[Epoch 9, Batch 600] loss: 0.045823403467657044
[Epoch 9, Batch 700] loss: 0.05085910139954649
[Epoch 9, Batch 800] loss: 0.05220127921085805
[Epoch 9, Batch 900] loss: 0.05627257015788928
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0664
Validation Accuracy: 0.9799
Overfitting: 0.0649
Best model saved at epoch 9 with validation loss: 0.0664
[Epoch 10, Batch 100] loss: 0.04557274097111076
[Epoch 10, Batch 200] loss: 0.037529173310613256
[Epoch 10, Batch 300] loss: 0.03199218379100785
[Epoch 10, Batch 400] loss: 0.040276232917094604
[Epoch 10, Batch 500] loss: 0.05083007096487563
[Epoch 10, Batch 600] loss: 0.05555339954211377
[Epoch 10, Batch 700] loss: 0.04210183007642627
[Epoch 10, Batch 800] loss: 0.04715994872152805
[Epoch 10, Batch 900] loss: 0.044223657369730066
**STATS for Epoch 10** : 
Average training loss: 0.0022
Average validation loss: 0.0906
Validation Accuracy: 0.9718
Overfitting: 0.0884
[Epoch 11, Batch 100] loss: 0.05484658263274469
[Epoch 11, Batch 200] loss: 0.04599315719678998
[Epoch 11, Batch 300] loss: 0.038467533454531806
[Epoch 11, Batch 400] loss: 0.03514053287683055
[Epoch 11, Batch 500] loss: 0.039003315877052955
[Epoch 11, Batch 600] loss: 0.03700214556301944
[Epoch 11, Batch 700] loss: 0.036679198996862394
[Epoch 11, Batch 800] loss: 0.03562793082150165
[Epoch 11, Batch 900] loss: 0.049430232228478414
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0631
Validation Accuracy: 0.9803
Overfitting: 0.0619
Best model saved at epoch 11 with validation loss: 0.0631
[Epoch 12, Batch 100] loss: 0.03525716553966049
[Epoch 12, Batch 200] loss: 0.02987106303218752
[Epoch 12, Batch 300] loss: 0.039804252249596175
[Epoch 12, Batch 400] loss: 0.04089272403041832
[Epoch 12, Batch 500] loss: 0.03854242741363123
[Epoch 12, Batch 600] loss: 0.029766270737163723
[Epoch 12, Batch 700] loss: 0.029930171830928883
[Epoch 12, Batch 800] loss: 0.036530828173272314
[Epoch 12, Batch 900] loss: 0.03729651909263339
**STATS for Epoch 12** : 
Average training loss: 0.0015
Average validation loss: 0.0590
Validation Accuracy: 0.9825
Overfitting: 0.0576
Best model saved at epoch 12 with validation loss: 0.0590
[Epoch 13, Batch 100] loss: 0.028503519220394083
[Epoch 13, Batch 200] loss: 0.038488203067681755
[Epoch 13, Batch 300] loss: 0.025504364506341515
[Epoch 13, Batch 400] loss: 0.028214511619880797
[Epoch 13, Batch 500] loss: 0.03575693111371948
[Epoch 13, Batch 600] loss: 0.03311128569985158
[Epoch 13, Batch 700] loss: 0.04282650207809638
[Epoch 13, Batch 800] loss: 0.0339820687379688
[Epoch 13, Batch 900] loss: 0.034530530784395524
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0599
Validation Accuracy: 0.9816
Overfitting: 0.0589
[Epoch 14, Batch 100] loss: 0.028633069799398073
[Epoch 14, Batch 200] loss: 0.030089263841509818
[Epoch 14, Batch 300] loss: 0.021757046884449665
[Epoch 14, Batch 400] loss: 0.025946966015617363
[Epoch 14, Batch 500] loss: 0.029012715662829577
[Epoch 14, Batch 600] loss: 0.03333445158030372
[Epoch 14, Batch 700] loss: 0.033677559407660734
[Epoch 14, Batch 800] loss: 0.03647436931496486
[Epoch 14, Batch 900] loss: 0.04029291089158505
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0569
Validation Accuracy: 0.9822
Overfitting: 0.0557
Best model saved at epoch 14 with validation loss: 0.0569
[Epoch 15, Batch 100] loss: 0.02234653350082226
[Epoch 15, Batch 200] loss: 0.027647665195981972
[Epoch 15, Batch 300] loss: 0.025392147649545223
[Epoch 15, Batch 400] loss: 0.021884823356522247
[Epoch 15, Batch 500] loss: 0.035033410740143156
[Epoch 15, Batch 600] loss: 0.0359180948586436
[Epoch 15, Batch 700] loss: 0.03396878208382986
[Epoch 15, Batch 800] loss: 0.016607344707590527
[Epoch 15, Batch 900] loss: 0.023291616726783104
**STATS for Epoch 15** : 
Average training loss: 0.0012
Average validation loss: 0.0554
Validation Accuracy: 0.9841
Overfitting: 0.0543
Best model saved at epoch 15 with validation loss: 0.0554
[Epoch 16, Batch 100] loss: 0.021479002599662636
[Epoch 16, Batch 200] loss: 0.02272333467117278
[Epoch 16, Batch 300] loss: 0.021202685494790784
[Epoch 16, Batch 400] loss: 0.02161748876387719
[Epoch 16, Batch 500] loss: 0.027735542758600785
[Epoch 16, Batch 600] loss: 0.01869411276478786
[Epoch 16, Batch 700] loss: 0.026090646932716482
[Epoch 16, Batch 800] loss: 0.02208502213936299
[Epoch 16, Batch 900] loss: 0.02634730631369166
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0586
Validation Accuracy: 0.9829
Overfitting: 0.0576
[Epoch 17, Batch 100] loss: 0.025007504156674257
[Epoch 17, Batch 200] loss: 0.01671918603067752
[Epoch 17, Batch 300] loss: 0.02488630992709659
[Epoch 17, Batch 400] loss: 0.02258444892737316
[Epoch 17, Batch 500] loss: 0.021994984073680824
[Epoch 17, Batch 600] loss: 0.02784810219804058
[Epoch 17, Batch 700] loss: 0.016928611302864736
[Epoch 17, Batch 800] loss: 0.02234961260081036
[Epoch 17, Batch 900] loss: 0.01942434338867315
**STATS for Epoch 17** : 
Average training loss: 0.0013
Average validation loss: 0.0633
Validation Accuracy: 0.9809
Overfitting: 0.0621
[Epoch 18, Batch 100] loss: 0.0150762696210586
[Epoch 18, Batch 200] loss: 0.016167687520210167
[Epoch 18, Batch 300] loss: 0.021050577182031703
[Epoch 18, Batch 400] loss: 0.025779309902573003
[Epoch 18, Batch 500] loss: 0.02154328123200685
[Epoch 18, Batch 600] loss: 0.024274462398461764
[Epoch 18, Batch 700] loss: 0.02597280556859914
[Epoch 18, Batch 800] loss: 0.019481458585651125
[Epoch 18, Batch 900] loss: 0.018104144649551016
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0583
Validation Accuracy: 0.9831
Overfitting: 0.0574
[Epoch 19, Batch 100] loss: 0.012620090436394093
[Epoch 19, Batch 200] loss: 0.012987749542153324
[Epoch 19, Batch 300] loss: 0.010721752348472365
[Epoch 19, Batch 400] loss: 0.016229954889713554
[Epoch 19, Batch 500] loss: 0.018983642014063662
[Epoch 19, Batch 600] loss: 0.028552903588279152
[Epoch 19, Batch 700] loss: 0.016223089711857028
[Epoch 19, Batch 800] loss: 0.022480435314209898
[Epoch 19, Batch 900] loss: 0.024274139017652487
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0696
Validation Accuracy: 0.9799
Overfitting: 0.0691
[Epoch 20, Batch 100] loss: 0.019828179488249588
[Epoch 20, Batch 200] loss: 0.014046848703292198
[Epoch 20, Batch 300] loss: 0.019488688960991568
[Epoch 20, Batch 400] loss: 0.01170912957561086
[Epoch 20, Batch 500] loss: 0.016015212056227027
[Epoch 20, Batch 600] loss: 0.02009073822526261
[Epoch 20, Batch 700] loss: 0.0166284185796394
[Epoch 20, Batch 800] loss: 0.014920483449968743
[Epoch 20, Batch 900] loss: 0.01575656875502318
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0556
Validation Accuracy: 0.9838
Overfitting: 0.0550
[Epoch 21, Batch 100] loss: 0.01351248828410462
[Epoch 21, Batch 200] loss: 0.015181366210017587
[Epoch 21, Batch 300] loss: 0.015720298850210382
[Epoch 21, Batch 400] loss: 0.020150544286916556
[Epoch 21, Batch 500] loss: 0.0180580785885104
[Epoch 21, Batch 600] loss: 0.014727120058960281
[Epoch 21, Batch 700] loss: 0.011352817486331332
[Epoch 21, Batch 800] loss: 0.010384589129716914
[Epoch 21, Batch 900] loss: 0.015176451947772875
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0548
Validation Accuracy: 0.9838
Overfitting: 0.0545
Best model saved at epoch 21 with validation loss: 0.0548
[Epoch 22, Batch 100] loss: 0.011752718850075325
[Epoch 22, Batch 200] loss: 0.0101825077067042
[Epoch 22, Batch 300] loss: 0.022482803521852474
[Epoch 22, Batch 400] loss: 0.014199080375619814
[Epoch 22, Batch 500] loss: 0.01501901862458908
[Epoch 22, Batch 600] loss: 0.012513031753187534
[Epoch 22, Batch 700] loss: 0.017816567515546923
[Epoch 22, Batch 800] loss: 0.011543603167374385
[Epoch 22, Batch 900] loss: 0.010072511393173045
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0562
Validation Accuracy: 0.9838
Overfitting: 0.0557
[Epoch 23, Batch 100] loss: 0.007714402638375759
[Epoch 23, Batch 200] loss: 0.010602555167715765
[Epoch 23, Batch 300] loss: 0.01210256918649975
[Epoch 23, Batch 400] loss: 0.014703340606938581
[Epoch 23, Batch 500] loss: 0.01191577782326931
[Epoch 23, Batch 600] loss: 0.014382351944877882
[Epoch 23, Batch 700] loss: 0.010758845095624565
[Epoch 23, Batch 800] loss: 0.012782685301426682
[Epoch 23, Batch 900] loss: 0.01513401997013716
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0557
Validation Accuracy: 0.9843
Overfitting: 0.0555
[Epoch 24, Batch 100] loss: 0.01199224007261364
[Epoch 24, Batch 200] loss: 0.006965509286928863
[Epoch 24, Batch 300] loss: 0.004772952113999054
[Epoch 24, Batch 400] loss: 0.009439558622325421
[Epoch 24, Batch 500] loss: 0.01706440870228107
[Epoch 24, Batch 600] loss: 0.0141466138362739
[Epoch 24, Batch 700] loss: 0.017122043515264522
[Epoch 24, Batch 800] loss: 0.008244815286670927
[Epoch 24, Batch 900] loss: 0.007320455730659887
**STATS for Epoch 24** : 
Average training loss: 0.0006
Average validation loss: 0.0577
Validation Accuracy: 0.9830
Overfitting: 0.0571
Fold 2 validation loss: 0.0577
Mean validation loss across all folds for Trial 17 is 0.0594 with trial config:  l1: 352, l2: 160, lr: 0.0009350705458597145, batch_size: 32
[I 2024-11-19 02:19:44,941] Trial 16 finished with value: 0.0593506690521273 and parameters: {'l1': 352, 'l2': 160, 'lr': 0.0009350705458597145, 'batch_size': 32}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 18:
  l1: 448, l2: 160, lr: 0.0008729467733840443, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2863908052444457
[Epoch 1, Batch 200] loss: 2.225083546638489
**STATS for Epoch 1** : 
Average training loss: 0.3120
Average validation loss: 2.0215
Validation Accuracy: 0.5559
Overfitting: 1.7095
Best model saved at epoch 1 with validation loss: 2.0215
[Epoch 2, Batch 100] loss: 1.5203895306587218
[Epoch 2, Batch 200] loss: 0.7102901193499566
**STATS for Epoch 2** : 
Average training loss: 0.0796
Average validation loss: 0.5152
Validation Accuracy: 0.8505
Overfitting: 0.4356
Best model saved at epoch 2 with validation loss: 0.5152
[Epoch 3, Batch 100] loss: 0.4820062816143036
[Epoch 3, Batch 200] loss: 0.3998002381622791
**STATS for Epoch 3** : 
Average training loss: 0.0561
Average validation loss: 0.3583
Validation Accuracy: 0.8936
Overfitting: 0.3022
Best model saved at epoch 3 with validation loss: 0.3583
[Epoch 4, Batch 100] loss: 0.34755073219537735
[Epoch 4, Batch 200] loss: 0.31482148468494414
**STATS for Epoch 4** : 
Average training loss: 0.0418
Average validation loss: 0.2870
Validation Accuracy: 0.9148
Overfitting: 0.2452
Best model saved at epoch 4 with validation loss: 0.2870
[Epoch 5, Batch 100] loss: 0.27770767122507095
[Epoch 5, Batch 200] loss: 0.2572933554649353
**STATS for Epoch 5** : 
Average training loss: 0.0344
Average validation loss: 0.2439
Validation Accuracy: 0.9278
Overfitting: 0.2095
Best model saved at epoch 5 with validation loss: 0.2439
[Epoch 6, Batch 100] loss: 0.22056640848517417
[Epoch 6, Batch 200] loss: 0.21630699023604394
**STATS for Epoch 6** : 
Average training loss: 0.0309
Average validation loss: 0.1938
Validation Accuracy: 0.9437
Overfitting: 0.1628
Best model saved at epoch 6 with validation loss: 0.1938
[Epoch 7, Batch 100] loss: 0.1877132348716259
[Epoch 7, Batch 200] loss: 0.1909701566770673
**STATS for Epoch 7** : 
Average training loss: 0.0234
Average validation loss: 0.1761
Validation Accuracy: 0.9470
Overfitting: 0.1527
Best model saved at epoch 7 with validation loss: 0.1761
[Epoch 8, Batch 100] loss: 0.1609314579516649
[Epoch 8, Batch 200] loss: 0.15605771269649268
**STATS for Epoch 8** : 
Average training loss: 0.0240
Average validation loss: 0.1561
Validation Accuracy: 0.9523
Overfitting: 0.1320
Best model saved at epoch 8 with validation loss: 0.1561
[Epoch 9, Batch 100] loss: 0.1436440396308899
[Epoch 9, Batch 200] loss: 0.13793244659900666
**STATS for Epoch 9** : 
Average training loss: 0.0225
Average validation loss: 0.1406
Validation Accuracy: 0.9582
Overfitting: 0.1181
[I 2024-11-19 02:21:19,350] Trial 17 pruned. 

Selected Hyperparameters for Trial 19:
  l1: 352, l2: 192, lr: 0.0018839979784049522, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.278641698360443
[Epoch 1, Batch 200] loss: 1.7935877603292465
[Epoch 1, Batch 300] loss: 0.6496732388436794
[Epoch 1, Batch 400] loss: 0.4364583998918533
[Epoch 1, Batch 500] loss: 0.3480020789057016
[Epoch 1, Batch 600] loss: 0.3122732005640864
[Epoch 1, Batch 700] loss: 0.25040965728461745
[Epoch 1, Batch 800] loss: 0.22459892701357603
[Epoch 1, Batch 900] loss: 0.2034453311190009
**STATS for Epoch 1** : 
Average training loss: 0.0063
Average validation loss: 0.1682
Validation Accuracy: 0.9491
Overfitting: 0.1619
Best model saved at epoch 1 with validation loss: 0.1682
[Epoch 2, Batch 100] loss: 0.15575796458870173
[Epoch 2, Batch 200] loss: 0.15532356202602388
[Epoch 2, Batch 300] loss: 0.1550867549702525
[Epoch 2, Batch 400] loss: 0.12465757384896278
[Epoch 2, Batch 500] loss: 0.12337468277662993
[Epoch 2, Batch 600] loss: 0.12242957739625127
[Epoch 2, Batch 700] loss: 0.13807378497906028
[Epoch 2, Batch 800] loss: 0.11197157356888056
[Epoch 2, Batch 900] loss: 0.12083457198459654
**STATS for Epoch 2** : 
Average training loss: 0.0049
Average validation loss: 0.1042
Validation Accuracy: 0.9676
Overfitting: 0.0994
Best model saved at epoch 2 with validation loss: 0.1042
[Epoch 3, Batch 100] loss: 0.107164057334885
[Epoch 3, Batch 200] loss: 0.09850190052762628
[Epoch 3, Batch 300] loss: 0.08637670462485403
[Epoch 3, Batch 400] loss: 0.07783997017890215
[Epoch 3, Batch 500] loss: 0.07555842390749604
[Epoch 3, Batch 600] loss: 0.09100944767706096
[Epoch 3, Batch 700] loss: 0.08650606757029891
[Epoch 3, Batch 800] loss: 0.08932478322181851
[Epoch 3, Batch 900] loss: 0.07455859985435381
**STATS for Epoch 3** : 
Average training loss: 0.0033
Average validation loss: 0.0972
Validation Accuracy: 0.9710
Overfitting: 0.0939
Best model saved at epoch 3 with validation loss: 0.0972
[Epoch 4, Batch 100] loss: 0.07368158373981715
[Epoch 4, Batch 200] loss: 0.06040682975202799
[Epoch 4, Batch 300] loss: 0.07248452321277
[Epoch 4, Batch 400] loss: 0.05737161354394629
[Epoch 4, Batch 500] loss: 0.07428872329415753
[Epoch 4, Batch 600] loss: 0.0719323649769649
[Epoch 4, Batch 700] loss: 0.06849868362303824
[Epoch 4, Batch 800] loss: 0.07069320658454671
[Epoch 4, Batch 900] loss: 0.05497361303772777
**STATS for Epoch 4** : 
Average training loss: 0.0029
Average validation loss: 0.0691
Validation Accuracy: 0.9784
Overfitting: 0.0661
Best model saved at epoch 4 with validation loss: 0.0691
[Epoch 5, Batch 100] loss: 0.05075153690762818
[Epoch 5, Batch 200] loss: 0.05195739808026701
[Epoch 5, Batch 300] loss: 0.0466395408147946
[Epoch 5, Batch 400] loss: 0.04960610439651646
[Epoch 5, Batch 500] loss: 0.05994502215879038
[Epoch 5, Batch 600] loss: 0.052842858873773366
[Epoch 5, Batch 700] loss: 0.06406037511536851
[Epoch 5, Batch 800] loss: 0.04992205960210413
[Epoch 5, Batch 900] loss: 0.04596094234380871
**STATS for Epoch 5** : 
Average training loss: 0.0026
Average validation loss: 0.0798
Validation Accuracy: 0.9756
Overfitting: 0.0772
[Epoch 6, Batch 100] loss: 0.04114469934545923
[Epoch 6, Batch 200] loss: 0.04023753111250698
[Epoch 6, Batch 300] loss: 0.04832124806707725
[Epoch 6, Batch 400] loss: 0.04431053067790344
[Epoch 6, Batch 500] loss: 0.04437644858495332
[Epoch 6, Batch 600] loss: 0.04706066375743831
[Epoch 6, Batch 700] loss: 0.040796207531820984
[Epoch 6, Batch 800] loss: 0.050261477729072794
[Epoch 6, Batch 900] loss: 0.04642535801976919
**STATS for Epoch 6** : 
Average training loss: 0.0018
Average validation loss: 0.0670
Validation Accuracy: 0.9799
Overfitting: 0.0652
Best model saved at epoch 6 with validation loss: 0.0670
[Epoch 7, Batch 100] loss: 0.03344047322170809
[Epoch 7, Batch 200] loss: 0.03671742340520723
[Epoch 7, Batch 300] loss: 0.032563710045360496
[Epoch 7, Batch 400] loss: 0.04474512982997112
[Epoch 7, Batch 500] loss: 0.035557775715133175
[Epoch 7, Batch 600] loss: 0.04222404798230855
[Epoch 7, Batch 700] loss: 0.03416557623364497
[Epoch 7, Batch 800] loss: 0.04322769425460137
[Epoch 7, Batch 900] loss: 0.036568080338765865
**STATS for Epoch 7** : 
Average training loss: 0.0013
Average validation loss: 0.0594
Validation Accuracy: 0.9820
Overfitting: 0.0581
Best model saved at epoch 7 with validation loss: 0.0594
[Epoch 8, Batch 100] loss: 0.029130401499569417
[Epoch 8, Batch 200] loss: 0.027054530885070562
[Epoch 8, Batch 300] loss: 0.03439853946736548
[Epoch 8, Batch 400] loss: 0.02934432666981593
[Epoch 8, Batch 500] loss: 0.021495941710309125
[Epoch 8, Batch 600] loss: 0.029650125782645774
[Epoch 8, Batch 700] loss: 0.027282302115345373
[Epoch 8, Batch 800] loss: 0.04246885040338384
[Epoch 8, Batch 900] loss: 0.034346968506579284
**STATS for Epoch 8** : 
Average training loss: 0.0021
Average validation loss: 0.0568
Validation Accuracy: 0.9823
Overfitting: 0.0546
Best model saved at epoch 8 with validation loss: 0.0568
[Epoch 9, Batch 100] loss: 0.027662991217221135
[Epoch 9, Batch 200] loss: 0.019952247857581824
[Epoch 9, Batch 300] loss: 0.02453558053035522
[Epoch 9, Batch 400] loss: 0.026284168244164904
[Epoch 9, Batch 500] loss: 0.02765241158893332
[Epoch 9, Batch 600] loss: 0.02896279430773575
[Epoch 9, Batch 700] loss: 0.026765575678437018
[Epoch 9, Batch 800] loss: 0.021830159797827944
[Epoch 9, Batch 900] loss: 0.023528534362703794
**STATS for Epoch 9** : 
Average training loss: 0.0009
Average validation loss: 0.0530
Validation Accuracy: 0.9845
Overfitting: 0.0521
Best model saved at epoch 9 with validation loss: 0.0530
[Epoch 10, Batch 100] loss: 0.017207577604858672
[Epoch 10, Batch 200] loss: 0.01855570563406218
[Epoch 10, Batch 300] loss: 0.02011738710454665
[Epoch 10, Batch 400] loss: 0.02588357505577733
[Epoch 10, Batch 500] loss: 0.02035157948732376
[Epoch 10, Batch 600] loss: 0.016906479856043006
[Epoch 10, Batch 700] loss: 0.019271027036884335
[Epoch 10, Batch 800] loss: 0.02459156459241058
[Epoch 10, Batch 900] loss: 0.026035375843348446
**STATS for Epoch 10** : 
Average training loss: 0.0013
Average validation loss: 0.0622
Validation Accuracy: 0.9828
Overfitting: 0.0609
[Epoch 11, Batch 100] loss: 0.01575093687133631
[Epoch 11, Batch 200] loss: 0.014957053407269995
[Epoch 11, Batch 300] loss: 0.019145937657376634
[Epoch 11, Batch 400] loss: 0.019747071961319307
[Epoch 11, Batch 500] loss: 0.019002271139906952
[Epoch 11, Batch 600] loss: 0.021641068694043496
[Epoch 11, Batch 700] loss: 0.01809113791299751
[Epoch 11, Batch 800] loss: 0.017119630415254505
[Epoch 11, Batch 900] loss: 0.024556632605672347
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0549
Validation Accuracy: 0.9839
Overfitting: 0.0540
[Epoch 12, Batch 100] loss: 0.01223299559482257
[Epoch 12, Batch 200] loss: 0.014482801297926926
[Epoch 12, Batch 300] loss: 0.015622722278640139
[Epoch 12, Batch 400] loss: 0.020643352096521995
[Epoch 12, Batch 500] loss: 0.016734334371649312
[Epoch 12, Batch 600] loss: 0.015928198567853543
[Epoch 12, Batch 700] loss: 0.01446761780331144
[Epoch 12, Batch 800] loss: 0.016381696774915327
[Epoch 12, Batch 900] loss: 0.0160393268268308
**STATS for Epoch 12** : 
Average training loss: 0.0014
Average validation loss: 0.0551
Validation Accuracy: 0.9849
Overfitting: 0.0538
[Epoch 13, Batch 100] loss: 0.010859009699124726
[Epoch 13, Batch 200] loss: 0.009747079183143796
[Epoch 13, Batch 300] loss: 0.011473468731928733
[Epoch 13, Batch 400] loss: 0.010314198239793768
[Epoch 13, Batch 500] loss: 0.011914754829122102
[Epoch 13, Batch 600] loss: 0.018225839243386874
[Epoch 13, Batch 700] loss: 0.01243001219118014
[Epoch 13, Batch 800] loss: 0.01776693043051637
[Epoch 13, Batch 900] loss: 0.01353226253282628
**STATS for Epoch 13** : 
Average training loss: 0.0006
Average validation loss: 0.0593
Validation Accuracy: 0.9840
Overfitting: 0.0587
[Epoch 14, Batch 100] loss: 0.011479300283608608
[Epoch 14, Batch 200] loss: 0.00958786011862685
[Epoch 14, Batch 300] loss: 0.0074543383245327275
[Epoch 14, Batch 400] loss: 0.010093970294292376
[Epoch 14, Batch 500] loss: 0.012934761790529593
[Epoch 14, Batch 600] loss: 0.010963555355738208
[Epoch 14, Batch 700] loss: 0.007599204048547108
[Epoch 14, Batch 800] loss: 0.011658878880916745
[Epoch 14, Batch 900] loss: 0.01707236232014111
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0608
Validation Accuracy: 0.9843
Overfitting: 0.0604
[Epoch 15, Batch 100] loss: 0.006462479573110613
[Epoch 15, Batch 200] loss: 0.0077292066480004
[Epoch 15, Batch 300] loss: 0.006352496252384298
[Epoch 15, Batch 400] loss: 0.0038164808188048483
[Epoch 15, Batch 500] loss: 0.00833892766480858
[Epoch 15, Batch 600] loss: 0.006480082581801981
[Epoch 15, Batch 700] loss: 0.006031537320195639
[Epoch 15, Batch 800] loss: 0.005914062675874448
[Epoch 15, Batch 900] loss: 0.013165287505762535
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0594
Validation Accuracy: 0.9836
Overfitting: 0.0589
[Epoch 16, Batch 100] loss: 0.011850352316014324
[Epoch 16, Batch 200] loss: 0.006924595748459978
[Epoch 16, Batch 300] loss: 0.004105357697071667
[Epoch 16, Batch 400] loss: 0.004661487210178165
[Epoch 16, Batch 500] loss: 0.008925856954447227
[Epoch 16, Batch 600] loss: 0.007182333243727044
[Epoch 16, Batch 700] loss: 0.014221943493357685
[Epoch 16, Batch 800] loss: 0.011238589239183057
[Epoch 16, Batch 900] loss: 0.007227396632588352
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0526
Validation Accuracy: 0.9866
Overfitting: 0.0523
Best model saved at epoch 16 with validation loss: 0.0526
[Epoch 17, Batch 100] loss: 0.004885559641879808
[Epoch 17, Batch 200] loss: 0.006849675345692958
[Epoch 17, Batch 300] loss: 0.0036638588236746726
[Epoch 17, Batch 400] loss: 0.004474737065802401
[Epoch 17, Batch 500] loss: 0.006754863271598879
[Epoch 17, Batch 600] loss: 0.007756354295270285
[Epoch 17, Batch 700] loss: 0.005161336408900752
[Epoch 17, Batch 800] loss: 0.006751445258214517
[Epoch 17, Batch 900] loss: 0.008949743478442542
**STATS for Epoch 17** : 
Average training loss: 0.0002
Average validation loss: 0.0616
Validation Accuracy: 0.9852
Overfitting: 0.0614
[Epoch 18, Batch 100] loss: 0.006036480349994235
[Epoch 18, Batch 200] loss: 0.0022927977183280746
[Epoch 18, Batch 300] loss: 0.003803515976505878
[Epoch 18, Batch 400] loss: 0.005907928993774476
[Epoch 18, Batch 500] loss: 0.0038369678832941645
[Epoch 18, Batch 600] loss: 0.0036235118117474486
[Epoch 18, Batch 700] loss: 0.0044434916619911745
[Epoch 18, Batch 800] loss: 0.0052843243857023485
[Epoch 18, Batch 900] loss: 0.006420987776500624
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0608
Validation Accuracy: 0.9856
Overfitting: 0.0607
[Epoch 19, Batch 100] loss: 0.003709551484353142
[Epoch 19, Batch 200] loss: 0.004542805013779798
[Epoch 19, Batch 300] loss: 0.0019516560446027143
[Epoch 19, Batch 400] loss: 0.002849697932470008
[Epoch 19, Batch 500] loss: 0.0020840710286529427
[Epoch 19, Batch 600] loss: 0.003194944573472185
[Epoch 19, Batch 700] loss: 0.003236175287701144
[Epoch 19, Batch 800] loss: 0.0043247302371855765
[Epoch 19, Batch 900] loss: 0.0046091740754991405
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0601
Validation Accuracy: 0.9865
Overfitting: 0.0599
[Epoch 20, Batch 100] loss: 0.0020941504203619843
[Epoch 20, Batch 200] loss: 0.0018576914270943235
[Epoch 20, Batch 300] loss: 0.003100712870882489
[Epoch 20, Batch 400] loss: 0.0034501273976650284
[Epoch 20, Batch 500] loss: 0.0032571829913285912
[Epoch 20, Batch 600] loss: 0.0029911607792996618
[Epoch 20, Batch 700] loss: 0.00449500239414192
[Epoch 20, Batch 800] loss: 0.004234575327236598
[Epoch 20, Batch 900] loss: 0.0025550341675398157
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0577
Validation Accuracy: 0.9867
Overfitting: 0.0576
[Epoch 21, Batch 100] loss: 0.0036613124034602152
[Epoch 21, Batch 200] loss: 0.001692564233972007
[Epoch 21, Batch 300] loss: 0.0019969990948811756
[Epoch 21, Batch 400] loss: 0.004822969286603893
[Epoch 21, Batch 500] loss: 0.0022299804114845755
[Epoch 21, Batch 600] loss: 0.00230736994295512
[Epoch 21, Batch 700] loss: 0.0017073361561551791
[Epoch 21, Batch 800] loss: 0.002107050188269568
[Epoch 21, Batch 900] loss: 0.0026092814154435474
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0580
Validation Accuracy: 0.9874
Overfitting: 0.0579
[Epoch 22, Batch 100] loss: 0.0012602475018184123
[Epoch 22, Batch 200] loss: 0.0015694261996759451
[Epoch 22, Batch 300] loss: 0.0010735693945957791
[Epoch 22, Batch 400] loss: 0.00169618104600886
[Epoch 22, Batch 500] loss: 0.0018717371396223825
[Epoch 22, Batch 600] loss: 0.00131151176433832
[Epoch 22, Batch 700] loss: 0.001007968389006919
[Epoch 22, Batch 800] loss: 0.0012188362383153616
[Epoch 22, Batch 900] loss: 0.001638937078786853
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0608
Validation Accuracy: 0.9869
Overfitting: 0.0606
[Epoch 23, Batch 100] loss: 0.001372533259136617
[Epoch 23, Batch 200] loss: 0.0011603120684350189
[Epoch 23, Batch 300] loss: 0.000855832718797842
[Epoch 23, Batch 400] loss: 0.0012645135714228672
[Epoch 23, Batch 500] loss: 0.0019036303768370998
[Epoch 23, Batch 600] loss: 0.001421106054062875
[Epoch 23, Batch 700] loss: 0.0012447207331615572
[Epoch 23, Batch 800] loss: 0.0006903213254315688
[Epoch 23, Batch 900] loss: 0.0008728572338100093
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9876
Overfitting: 0.0592
[Epoch 24, Batch 100] loss: 0.001036473343006037
[Epoch 24, Batch 200] loss: 0.0016202717039914204
[Epoch 24, Batch 300] loss: 0.0011113720470211773
[Epoch 24, Batch 400] loss: 0.0007732615008808352
[Epoch 24, Batch 500] loss: 0.0011042323675027887
[Epoch 24, Batch 600] loss: 0.0009219328693774286
[Epoch 24, Batch 700] loss: 0.0012108114654324708
[Epoch 24, Batch 800] loss: 0.0006925930010061166
[Epoch 24, Batch 900] loss: 0.0008464133511728278
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9876
Overfitting: 0.0606
Fold 1 validation loss: 0.0606
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.276406097412109
[Epoch 1, Batch 200] loss: 1.8368738853931428
[Epoch 1, Batch 300] loss: 0.6077321417629719
[Epoch 1, Batch 400] loss: 0.428950439542532
[Epoch 1, Batch 500] loss: 0.3524414115399122
[Epoch 1, Batch 600] loss: 0.2673325539752841
[Epoch 1, Batch 700] loss: 0.264612328633666
[Epoch 1, Batch 800] loss: 0.22764662384986878
[Epoch 1, Batch 900] loss: 0.1839534306898713
**STATS for Epoch 1** : 
Average training loss: 0.0089
Average validation loss: 0.1870
Validation Accuracy: 0.9403
Overfitting: 0.1781
Best model saved at epoch 1 with validation loss: 0.1870
[Epoch 2, Batch 100] loss: 0.17794529549777507
[Epoch 2, Batch 200] loss: 0.15186496555805207
[Epoch 2, Batch 300] loss: 0.1345516739040613
[Epoch 2, Batch 400] loss: 0.1466508077085018
[Epoch 2, Batch 500] loss: 0.1479031447134912
[Epoch 2, Batch 600] loss: 0.1288499241322279
[Epoch 2, Batch 700] loss: 0.12842422351241112
[Epoch 2, Batch 800] loss: 0.11114671749062836
[Epoch 2, Batch 900] loss: 0.12453075436875224
**STATS for Epoch 2** : 
Average training loss: 0.0040
Average validation loss: 0.1226
Validation Accuracy: 0.9610
Overfitting: 0.1187
Best model saved at epoch 2 with validation loss: 0.1226
[Epoch 3, Batch 100] loss: 0.09260495292022825
[Epoch 3, Batch 200] loss: 0.09595739462878555
[Epoch 3, Batch 300] loss: 0.088513014158234
[Epoch 3, Batch 400] loss: 0.11521750641986728
[Epoch 3, Batch 500] loss: 0.08457923520356417
[Epoch 3, Batch 600] loss: 0.09387570740189403
[Epoch 3, Batch 700] loss: 0.07859578593634069
[Epoch 3, Batch 800] loss: 0.08221755892038346
[Epoch 3, Batch 900] loss: 0.0930119331087917
**STATS for Epoch 3** : 
Average training loss: 0.0037
Average validation loss: 0.0836
Validation Accuracy: 0.9742
Overfitting: 0.0798
Best model saved at epoch 3 with validation loss: 0.0836
[Epoch 4, Batch 100] loss: 0.08367879421450197
[Epoch 4, Batch 200] loss: 0.07978591253980995
[Epoch 4, Batch 300] loss: 0.06491626889677718
[Epoch 4, Batch 400] loss: 0.07667033234145493
[Epoch 4, Batch 500] loss: 0.0673157011566218
[Epoch 4, Batch 600] loss: 0.051042188592255115
[Epoch 4, Batch 700] loss: 0.06319915883475914
[Epoch 4, Batch 800] loss: 0.07822969601955265
[Epoch 4, Batch 900] loss: 0.06197716707363725
**STATS for Epoch 4** : 
Average training loss: 0.0019
Average validation loss: 0.0814
Validation Accuracy: 0.9734
Overfitting: 0.0795
Best model saved at epoch 4 with validation loss: 0.0814
[Epoch 5, Batch 100] loss: 0.052751626315293836
[Epoch 5, Batch 200] loss: 0.05103599045658484
[Epoch 5, Batch 300] loss: 0.06310250131064095
[Epoch 5, Batch 400] loss: 0.05726271319319494
[Epoch 5, Batch 500] loss: 0.06117581213475205
[Epoch 5, Batch 600] loss: 0.05547255728044547
[Epoch 5, Batch 700] loss: 0.05267653877614066
[Epoch 5, Batch 800] loss: 0.05969357690773904
[Epoch 5, Batch 900] loss: 0.04845022308407351
**STATS for Epoch 5** : 
Average training loss: 0.0020
Average validation loss: 0.0754
Validation Accuracy: 0.9769
Overfitting: 0.0734
Best model saved at epoch 5 with validation loss: 0.0754
[Epoch 6, Batch 100] loss: 0.046009604438440876
[Epoch 6, Batch 200] loss: 0.049095563457813116
[Epoch 6, Batch 300] loss: 0.03980864736833609
[Epoch 6, Batch 400] loss: 0.05007907122024335
[Epoch 6, Batch 500] loss: 0.05278981524403207
[Epoch 6, Batch 600] loss: 0.037569824089005124
[Epoch 6, Batch 700] loss: 0.041413345345063135
[Epoch 6, Batch 800] loss: 0.04730486683954951
[Epoch 6, Batch 900] loss: 0.04636629920220003
**STATS for Epoch 6** : 
Average training loss: 0.0017
Average validation loss: 0.0746
Validation Accuracy: 0.9767
Overfitting: 0.0730
Best model saved at epoch 6 with validation loss: 0.0746
[Epoch 7, Batch 100] loss: 0.03810729242744856
[Epoch 7, Batch 200] loss: 0.027074700825614854
[Epoch 7, Batch 300] loss: 0.040993079585023226
[Epoch 7, Batch 400] loss: 0.03682844224458677
[Epoch 7, Batch 500] loss: 0.03759339296957478
[Epoch 7, Batch 600] loss: 0.03835584767337423
[Epoch 7, Batch 700] loss: 0.0453460352277034
[Epoch 7, Batch 800] loss: 0.03665236031927634
[Epoch 7, Batch 900] loss: 0.043802587285172195
**STATS for Epoch 7** : 
Average training loss: 0.0020
Average validation loss: 0.0613
Validation Accuracy: 0.9812
Overfitting: 0.0594
Best model saved at epoch 7 with validation loss: 0.0613
[Epoch 8, Batch 100] loss: 0.025472634180041497
[Epoch 8, Batch 200] loss: 0.037405590628040955
[Epoch 8, Batch 300] loss: 0.02566583132429514
[Epoch 8, Batch 400] loss: 0.030421705598419068
[Epoch 8, Batch 500] loss: 0.03491978040750837
[Epoch 8, Batch 600] loss: 0.029179715718782973
[Epoch 8, Batch 700] loss: 0.03633584879717091
[Epoch 8, Batch 800] loss: 0.0282780193653889
[Epoch 8, Batch 900] loss: 0.03669480008364189
**STATS for Epoch 8** : 
Average training loss: 0.0015
Average validation loss: 0.0729
Validation Accuracy: 0.9785
Overfitting: 0.0714
[Epoch 9, Batch 100] loss: 0.025687966289115138
[Epoch 9, Batch 200] loss: 0.021113189436146058
[Epoch 9, Batch 300] loss: 0.028230266927566847
[Epoch 9, Batch 400] loss: 0.024202049074228852
[Epoch 9, Batch 500] loss: 0.02282299660218996
[Epoch 9, Batch 600] loss: 0.02416079286718741
[Epoch 9, Batch 700] loss: 0.02946241692872718
[Epoch 9, Batch 800] loss: 0.033784152641601395
[Epoch 9, Batch 900] loss: 0.030285538284661014
**STATS for Epoch 9** : 
Average training loss: 0.0012
Average validation loss: 0.0629
Validation Accuracy: 0.9814
Overfitting: 0.0618
[Epoch 10, Batch 100] loss: 0.034604142021853475
[Epoch 10, Batch 200] loss: 0.021024317005649207
[Epoch 10, Batch 300] loss: 0.022554048109159338
[Epoch 10, Batch 400] loss: 0.022621770574114634
[Epoch 10, Batch 500] loss: 0.030433331592066678
[Epoch 10, Batch 600] loss: 0.020237032060394997
[Epoch 10, Batch 700] loss: 0.01064529990835581
[Epoch 10, Batch 800] loss: 0.03207895945088239
[Epoch 10, Batch 900] loss: 0.018294939219340448
**STATS for Epoch 10** : 
Average training loss: 0.0007
Average validation loss: 0.0565
Validation Accuracy: 0.9835
Overfitting: 0.0558
Best model saved at epoch 10 with validation loss: 0.0565
[Epoch 11, Batch 100] loss: 0.017968981395388255
[Epoch 11, Batch 200] loss: 0.019506282296788413
[Epoch 11, Batch 300] loss: 0.019285073420105617
[Epoch 11, Batch 400] loss: 0.015772959135938437
[Epoch 11, Batch 500] loss: 0.013667245761607773
[Epoch 11, Batch 600] loss: 0.02188514780253172
[Epoch 11, Batch 700] loss: 0.020570358159020544
[Epoch 11, Batch 800] loss: 0.026987082026607823
[Epoch 11, Batch 900] loss: 0.023360705765662716
**STATS for Epoch 11** : 
Average training loss: 0.0011
Average validation loss: 0.0579
Validation Accuracy: 0.9831
Overfitting: 0.0569
[Epoch 12, Batch 100] loss: 0.017759556960954798
[Epoch 12, Batch 200] loss: 0.014976390509400517
[Epoch 12, Batch 300] loss: 0.018962647750449833
[Epoch 12, Batch 400] loss: 0.016382258751254996
[Epoch 12, Batch 500] loss: 0.016571389281743905
[Epoch 12, Batch 600] loss: 0.018340197845027432
[Epoch 12, Batch 700] loss: 0.013648984392930288
[Epoch 12, Batch 800] loss: 0.012484661901835352
[Epoch 12, Batch 900] loss: 0.018430963835180593
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0588
Validation Accuracy: 0.9826
Overfitting: 0.0576
[Epoch 13, Batch 100] loss: 0.013768312818283448
[Epoch 13, Batch 200] loss: 0.012675956156854226
[Epoch 13, Batch 300] loss: 0.009005215252982453
[Epoch 13, Batch 400] loss: 0.01374715533995186
[Epoch 13, Batch 500] loss: 0.013437824528591592
[Epoch 13, Batch 600] loss: 0.014245813954621553
[Epoch 13, Batch 700] loss: 0.011870130359020549
[Epoch 13, Batch 800] loss: 0.012147563587132027
[Epoch 13, Batch 900] loss: 0.013236982880862343
**STATS for Epoch 13** : 
Average training loss: 0.0011
Average validation loss: 0.0601
Validation Accuracy: 0.9830
Overfitting: 0.0590
[Epoch 14, Batch 100] loss: 0.008042679263380705
[Epoch 14, Batch 200] loss: 0.01367436022766924
[Epoch 14, Batch 300] loss: 0.01314920513646939
[Epoch 14, Batch 400] loss: 0.012633897123523639
[Epoch 14, Batch 500] loss: 0.008066889893016196
[Epoch 14, Batch 600] loss: 0.011955702193445177
[Epoch 14, Batch 700] loss: 0.009211702406901168
[Epoch 14, Batch 800] loss: 0.010039181554493553
[Epoch 14, Batch 900] loss: 0.018353388689465646
**STATS for Epoch 14** : 
Average training loss: 0.0003
Average validation loss: 0.0556
Validation Accuracy: 0.9851
Overfitting: 0.0553
Best model saved at epoch 14 with validation loss: 0.0556
[Epoch 15, Batch 100] loss: 0.008518915673776065
[Epoch 15, Batch 200] loss: 0.012733715112954087
[Epoch 15, Batch 300] loss: 0.0053282366923667725
[Epoch 15, Batch 400] loss: 0.007208688909213379
[Epoch 15, Batch 500] loss: 0.006643275361566339
[Epoch 15, Batch 600] loss: 0.010914851445049863
[Epoch 15, Batch 700] loss: 0.009710662494471762
[Epoch 15, Batch 800] loss: 0.011652769400716351
[Epoch 15, Batch 900] loss: 0.014812531059069442
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0541
Validation Accuracy: 0.9847
Overfitting: 0.0536
Best model saved at epoch 15 with validation loss: 0.0541
[Epoch 16, Batch 100] loss: 0.007330408344187162
[Epoch 16, Batch 200] loss: 0.005794303460061201
[Epoch 16, Batch 300] loss: 0.005843594550442504
[Epoch 16, Batch 400] loss: 0.006335343736609502
[Epoch 16, Batch 500] loss: 0.008497407999875577
[Epoch 16, Batch 600] loss: 0.005710291414725361
[Epoch 16, Batch 700] loss: 0.011741674568329473
[Epoch 16, Batch 800] loss: 0.016115675661058048
[Epoch 16, Batch 900] loss: 0.011083026420892565
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0523
Validation Accuracy: 0.9863
Overfitting: 0.0516
Best model saved at epoch 16 with validation loss: 0.0523
[Epoch 17, Batch 100] loss: 0.007204602435613197
[Epoch 17, Batch 200] loss: 0.005990830491318775
[Epoch 17, Batch 300] loss: 0.007422214696416632
[Epoch 17, Batch 400] loss: 0.00944190634501865
[Epoch 17, Batch 500] loss: 0.009715261637538788
[Epoch 17, Batch 600] loss: 0.009712280286721579
[Epoch 17, Batch 700] loss: 0.004899862311613106
[Epoch 17, Batch 800] loss: 0.007020231545420756
[Epoch 17, Batch 900] loss: 0.010365875105890154
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0535
Validation Accuracy: 0.9860
Overfitting: 0.0532
[Epoch 18, Batch 100] loss: 0.003319763320432685
[Epoch 18, Batch 200] loss: 0.004608535600673349
[Epoch 18, Batch 300] loss: 0.0036408872745960254
[Epoch 18, Batch 400] loss: 0.0037868091425843887
[Epoch 18, Batch 500] loss: 0.0024434660447150234
[Epoch 18, Batch 600] loss: 0.0034732942010123223
[Epoch 18, Batch 700] loss: 0.00190619232285826
[Epoch 18, Batch 800] loss: 0.003576921958292587
[Epoch 18, Batch 900] loss: 0.007550490827620706
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0589
Validation Accuracy: 0.9854
Overfitting: 0.0585
[Epoch 19, Batch 100] loss: 0.003019298121371321
[Epoch 19, Batch 200] loss: 0.004638970113464893
[Epoch 19, Batch 300] loss: 0.003127456882921251
[Epoch 19, Batch 400] loss: 0.0041144005034220756
[Epoch 19, Batch 500] loss: 0.004452882140149086
[Epoch 19, Batch 600] loss: 0.0031945606650151605
[Epoch 19, Batch 700] loss: 0.003727471837119083
[Epoch 19, Batch 800] loss: 0.0036506003266140396
[Epoch 19, Batch 900] loss: 0.003208386543328743
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0594
Validation Accuracy: 0.9857
Overfitting: 0.0593
[Epoch 20, Batch 100] loss: 0.004670330837202527
[Epoch 20, Batch 200] loss: 0.002763040939844359
[Epoch 20, Batch 300] loss: 0.0020193580442719396
[Epoch 20, Batch 400] loss: 0.0016440987579881038
[Epoch 20, Batch 500] loss: 0.0020536285783555285
[Epoch 20, Batch 600] loss: 0.0018316723058615025
[Epoch 20, Batch 700] loss: 0.0026672230121857865
[Epoch 20, Batch 800] loss: 0.002351941038627956
[Epoch 20, Batch 900] loss: 0.0033405330302366566
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0574
Validation Accuracy: 0.9861
Overfitting: 0.0572
[Epoch 21, Batch 100] loss: 0.0012179916199329456
[Epoch 21, Batch 200] loss: 0.001285072416208095
[Epoch 21, Batch 300] loss: 0.0014986873312136594
[Epoch 21, Batch 400] loss: 0.0019318160473039824
[Epoch 21, Batch 500] loss: 0.001228933803884047
[Epoch 21, Batch 600] loss: 0.001273941860308696
[Epoch 21, Batch 700] loss: 0.0019213073835680917
[Epoch 21, Batch 800] loss: 0.0012638195542638187
[Epoch 21, Batch 900] loss: 0.001809274313475271
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0557
Validation Accuracy: 0.9868
Overfitting: 0.0557
[Epoch 22, Batch 100] loss: 0.0010255899692492676
[Epoch 22, Batch 200] loss: 0.0006435159137254231
[Epoch 22, Batch 300] loss: 0.0008862104317370268
[Epoch 22, Batch 400] loss: 0.0016324714726385992
[Epoch 22, Batch 500] loss: 0.0015741234975348562
[Epoch 22, Batch 600] loss: 0.0012856091459207163
[Epoch 22, Batch 700] loss: 0.0010470103420004762
[Epoch 22, Batch 800] loss: 0.0012276574793304463
[Epoch 22, Batch 900] loss: 0.001416992265915269
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0590
Validation Accuracy: 0.9864
Overfitting: 0.0589
[Epoch 23, Batch 100] loss: 0.000730492858863272
[Epoch 23, Batch 200] loss: 0.0009163866219624594
[Epoch 23, Batch 300] loss: 0.0007593549026660185
[Epoch 23, Batch 400] loss: 0.0007366138177212633
[Epoch 23, Batch 500] loss: 0.0007178735944989966
[Epoch 23, Batch 600] loss: 0.001988285535484806
[Epoch 23, Batch 700] loss: 0.004635434444430757
[Epoch 23, Batch 800] loss: 0.0038728407858889115
[Epoch 23, Batch 900] loss: 0.009551517799081921
**STATS for Epoch 23** : 
Average training loss: 0.0006
Average validation loss: 0.0626
Validation Accuracy: 0.9858
Overfitting: 0.0619
[Epoch 24, Batch 100] loss: 0.0027666281672190964
[Epoch 24, Batch 200] loss: 0.002007194232696747
[Epoch 24, Batch 300] loss: 0.0012897881772050823
[Epoch 24, Batch 400] loss: 0.0038874871718780923
[Epoch 24, Batch 500] loss: 0.002511789388499892
[Epoch 24, Batch 600] loss: 0.003291055946447159
[Epoch 24, Batch 700] loss: 0.00773539830562413
[Epoch 24, Batch 800] loss: 0.0027711830181078767
[Epoch 24, Batch 900] loss: 0.0014909539458432164
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0579
Validation Accuracy: 0.9861
Overfitting: 0.0578
Fold 2 validation loss: 0.0579
Mean validation loss across all folds for Trial 19 is 0.0593 with trial config:  l1: 352, l2: 192, lr: 0.0018839979784049522, batch_size: 32
[I 2024-11-19 02:30:53,425] Trial 18 finished with value: 0.05926131519956121 and parameters: {'l1': 352, 'l2': 192, 'lr': 0.0018839979784049522, 'batch_size': 32}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 20:
  l1: 512, l2: 224, lr: 0.00670065004252065, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.5812437590956687
[Epoch 1, Batch 200] loss: 0.3408908416330814
[Epoch 1, Batch 300] loss: 0.24331724785268308
[Epoch 1, Batch 400] loss: 0.16234355208463966
[Epoch 1, Batch 500] loss: 0.16835867084562778
[Epoch 1, Batch 600] loss: 0.11850862213876098
[Epoch 1, Batch 700] loss: 0.12585981332696974
[Epoch 1, Batch 800] loss: 0.12630890879780055
[Epoch 1, Batch 900] loss: 0.08641909575555473
**STATS for Epoch 1** : 
Average training loss: 0.0038
Average validation loss: 0.0995
Validation Accuracy: 0.9682
Overfitting: 0.0957
Best model saved at epoch 1 with validation loss: 0.0995
[Epoch 2, Batch 100] loss: 0.07786348318913952
[Epoch 2, Batch 200] loss: 0.06248564704903401
[Epoch 2, Batch 300] loss: 0.08859927199780941
[Epoch 2, Batch 400] loss: 0.07259916765615344
[Epoch 2, Batch 500] loss: 0.0659252167469822
[Epoch 2, Batch 600] loss: 0.07694219176191837
[Epoch 2, Batch 700] loss: 0.06398876070044934
[Epoch 2, Batch 800] loss: 0.05830488326959312
[Epoch 2, Batch 900] loss: 0.07408214109018445
**STATS for Epoch 2** : 
Average training loss: 0.0026
Average validation loss: 0.0709
Validation Accuracy: 0.9775
Overfitting: 0.0683
Best model saved at epoch 2 with validation loss: 0.0709
[Epoch 3, Batch 100] loss: 0.0471359518810641
[Epoch 3, Batch 200] loss: 0.04635781255085021
[Epoch 3, Batch 300] loss: 0.05827251424489077
[Epoch 3, Batch 400] loss: 0.04496057841926813
[Epoch 3, Batch 500] loss: 0.039225916386349126
[Epoch 3, Batch 600] loss: 0.045832314937142654
[Epoch 3, Batch 700] loss: 0.050002660392201505
[Epoch 3, Batch 800] loss: 0.054340755988960154
[Epoch 3, Batch 900] loss: 0.042683627226797395
**STATS for Epoch 3** : 
Average training loss: 0.0018
Average validation loss: 0.0582
Validation Accuracy: 0.9828
Overfitting: 0.0564
Best model saved at epoch 3 with validation loss: 0.0582
[Epoch 4, Batch 100] loss: 0.0364107784893713
[Epoch 4, Batch 200] loss: 0.031836494579329154
[Epoch 4, Batch 300] loss: 0.039012002305025814
[Epoch 4, Batch 400] loss: 0.030607138360501267
[Epoch 4, Batch 500] loss: 0.038664594784495424
[Epoch 4, Batch 600] loss: 0.03392940262427146
[Epoch 4, Batch 700] loss: 0.0346140675470815
[Epoch 4, Batch 800] loss: 0.03913141496755998
[Epoch 4, Batch 900] loss: 0.032751750411698595
**STATS for Epoch 4** : 
Average training loss: 0.0015
Average validation loss: 0.0682
Validation Accuracy: 0.9809
Overfitting: 0.0667
[Epoch 5, Batch 100] loss: 0.02833534581004642
[Epoch 5, Batch 200] loss: 0.0285239385200839
[Epoch 5, Batch 300] loss: 0.01903981579369429
[Epoch 5, Batch 400] loss: 0.018202346638281595
[Epoch 5, Batch 500] loss: 0.03279281876501045
[Epoch 5, Batch 600] loss: 0.024958455584201147
[Epoch 5, Batch 700] loss: 0.028606338916433743
[Epoch 5, Batch 800] loss: 0.027914559047130753
[Epoch 5, Batch 900] loss: 0.028233698525145883
**STATS for Epoch 5** : 
Average training loss: 0.0016
Average validation loss: 0.0626
Validation Accuracy: 0.9821
Overfitting: 0.0610
[Epoch 6, Batch 100] loss: 0.020283688261115457
[Epoch 6, Batch 200] loss: 0.013124128227282199
[Epoch 6, Batch 300] loss: 0.02333749833138427
[Epoch 6, Batch 400] loss: 0.024816825967936895
[Epoch 6, Batch 500] loss: 0.019653558088029967
[Epoch 6, Batch 600] loss: 0.0273236564907711
[Epoch 6, Batch 700] loss: 0.019561357548082015
[Epoch 6, Batch 800] loss: 0.026466901383537335
[Epoch 6, Batch 900] loss: 0.025827244496904312
**STATS for Epoch 6** : 
Average training loss: 0.0009
Average validation loss: 0.0609
Validation Accuracy: 0.9841
Overfitting: 0.0600
[Epoch 7, Batch 100] loss: 0.011602942627869197
[Epoch 7, Batch 200] loss: 0.009022501605331855
[Epoch 7, Batch 300] loss: 0.010542595048609655
[Epoch 7, Batch 400] loss: 0.019375502696784678
[Epoch 7, Batch 500] loss: 0.01720502028649207
[Epoch 7, Batch 600] loss: 0.01030027858174435
[Epoch 7, Batch 700] loss: 0.012001657452055952
[Epoch 7, Batch 800] loss: 0.017258276485663374
[Epoch 7, Batch 900] loss: 0.02094755790767522
**STATS for Epoch 7** : 
Average training loss: 0.0005
Average validation loss: 0.0589
Validation Accuracy: 0.9842
Overfitting: 0.0585
[Epoch 8, Batch 100] loss: 0.015614063598877691
[Epoch 8, Batch 200] loss: 0.0075266837137314725
[Epoch 8, Batch 300] loss: 0.007559158693584323
[Epoch 8, Batch 400] loss: 0.007488375400898803
[Epoch 8, Batch 500] loss: 0.015996627918138984
[Epoch 8, Batch 600] loss: 0.017989818590067444
[Epoch 8, Batch 700] loss: 0.013642062852122763
[Epoch 8, Batch 800] loss: 0.020948695212318853
[Epoch 8, Batch 900] loss: 0.009274998040664286
**STATS for Epoch 8** : 
Average training loss: 0.0011
Average validation loss: 0.0514
Validation Accuracy: 0.9870
Overfitting: 0.0503
Best model saved at epoch 8 with validation loss: 0.0514
[Epoch 9, Batch 100] loss: 0.009254694932023995
[Epoch 9, Batch 200] loss: 0.008352016229259789
[Epoch 9, Batch 300] loss: 0.014827171617562272
[Epoch 9, Batch 400] loss: 0.014832207780636963
[Epoch 9, Batch 500] loss: 0.026966696296130976
[Epoch 9, Batch 600] loss: 0.011820855374735402
[Epoch 9, Batch 700] loss: 0.018185379155693227
[Epoch 9, Batch 800] loss: 0.011431537549724454
[Epoch 9, Batch 900] loss: 0.012680913049844094
**STATS for Epoch 9** : 
Average training loss: 0.0005
Average validation loss: 0.0575
Validation Accuracy: 0.9857
Overfitting: 0.0570
[Epoch 10, Batch 100] loss: 0.007688625336604673
[Epoch 10, Batch 200] loss: 0.009514384121721377
[Epoch 10, Batch 300] loss: 0.005956573657031185
[Epoch 10, Batch 400] loss: 0.012439327928136663
[Epoch 10, Batch 500] loss: 0.019198683186104973
[Epoch 10, Batch 600] loss: 0.018576402605121986
[Epoch 10, Batch 700] loss: 0.012318879633266989
[Epoch 10, Batch 800] loss: 0.007630362520771996
[Epoch 10, Batch 900] loss: 0.01966344134024439
**STATS for Epoch 10** : 
Average training loss: 0.0006
Average validation loss: 0.0780
Validation Accuracy: 0.9819
Overfitting: 0.0773
[Epoch 11, Batch 100] loss: 0.008380949835736829
[Epoch 11, Batch 200] loss: 0.004609084118860665
[Epoch 11, Batch 300] loss: 0.008007997530403372
[Epoch 11, Batch 400] loss: 0.007023289399458008
[Epoch 11, Batch 500] loss: 0.007641850657732902
[Epoch 11, Batch 600] loss: 0.014234918316842595
[Epoch 11, Batch 700] loss: 0.0068453984333609694
[Epoch 11, Batch 800] loss: 0.008278655076692303
[Epoch 11, Batch 900] loss: 0.013961589018235828
**STATS for Epoch 11** : 
Average training loss: 0.0002
Average validation loss: 0.0596
Validation Accuracy: 0.9854
Overfitting: 0.0594
[Epoch 12, Batch 100] loss: 0.012886770495260862
[Epoch 12, Batch 200] loss: 0.0057109346118818394
[Epoch 12, Batch 300] loss: 0.003997937060084951
[Epoch 12, Batch 400] loss: 0.002319193490290559
[Epoch 12, Batch 500] loss: 0.010635674970253604
[Epoch 12, Batch 600] loss: 0.02074243030267098
[Epoch 12, Batch 700] loss: 0.005749298950238426
[Epoch 12, Batch 800] loss: 0.007033476199076176
[Epoch 12, Batch 900] loss: 0.012072307486396311
**STATS for Epoch 12** : 
Average training loss: 0.0001
Average validation loss: 0.0565
Validation Accuracy: 0.9872
Overfitting: 0.0564
[Epoch 13, Batch 100] loss: 0.00448644306141432
[Epoch 13, Batch 200] loss: 0.0024066406332894984
[Epoch 13, Batch 300] loss: 0.0022637675276519077
[Epoch 13, Batch 400] loss: 0.0010659822392449314
[Epoch 13, Batch 500] loss: 0.0028619429598984425
[Epoch 13, Batch 600] loss: 0.0035821001471302337
[Epoch 13, Batch 700] loss: 0.0028376573201558133
[Epoch 13, Batch 800] loss: 0.00320880670401948
[Epoch 13, Batch 900] loss: 0.0006409884014846056
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9888
Overfitting: 0.0561
[Epoch 14, Batch 100] loss: 0.00044947324078577824
[Epoch 14, Batch 200] loss: 0.0010595992293221457
[Epoch 14, Batch 300] loss: 0.000512149451816697
[Epoch 14, Batch 400] loss: 0.0006751962223285091
[Epoch 14, Batch 500] loss: 0.0012953423522355934
[Epoch 14, Batch 600] loss: 0.0009849038526866139
[Epoch 14, Batch 700] loss: 0.0004648208803143916
[Epoch 14, Batch 800] loss: 0.0034011069334292186
[Epoch 14, Batch 900] loss: 0.0026590072957856136
**STATS for Epoch 14** : 
Average training loss: 0.0001
Average validation loss: 0.0615
Validation Accuracy: 0.9874
Overfitting: 0.0615
[Epoch 15, Batch 100] loss: 0.0012535155619332271
[Epoch 15, Batch 200] loss: 0.0010391495395055018
[Epoch 15, Batch 300] loss: 0.0012052380981515398
[Epoch 15, Batch 400] loss: 0.000493536633910594
[Epoch 15, Batch 500] loss: 0.0010192109996624765
[Epoch 15, Batch 600] loss: 0.0005975780956180188
[Epoch 15, Batch 700] loss: 0.0004343716355752747
[Epoch 15, Batch 800] loss: 0.00018795476393217213
[Epoch 15, Batch 900] loss: 0.0002554139375531861
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0588
Validation Accuracy: 0.9891
Overfitting: 0.0588
[Epoch 16, Batch 100] loss: 0.00014987959556890475
[Epoch 16, Batch 200] loss: 0.00013823649900075453
[Epoch 16, Batch 300] loss: 0.00017868350337561624
[Epoch 16, Batch 400] loss: 0.0005464085976123533
[Epoch 16, Batch 500] loss: 0.00021981352806957233
[Epoch 16, Batch 600] loss: 0.00017268443888944772
[Epoch 16, Batch 700] loss: 0.00017326479438276366
[Epoch 16, Batch 800] loss: 9.148114573036991e-05
[Epoch 16, Batch 900] loss: 0.0008003568661717964
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0622
Validation Accuracy: 0.9890
Overfitting: 0.0622
[Epoch 17, Batch 100] loss: 0.00012637082668007338
[Epoch 17, Batch 200] loss: 0.00012562174130280822
[Epoch 17, Batch 300] loss: 8.574028986227945e-05
[Epoch 17, Batch 400] loss: 0.00016120426569859347
[Epoch 17, Batch 500] loss: 8.588292362233573e-05
[Epoch 17, Batch 600] loss: 0.00010921090574598225
[Epoch 17, Batch 700] loss: 0.0002025884040915038
[Epoch 17, Batch 800] loss: 0.0003765007808609511
[Epoch 17, Batch 900] loss: 0.0002190826237914223
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0612
Validation Accuracy: 0.9894
Overfitting: 0.0612
[Epoch 18, Batch 100] loss: 9.457215010776566e-05
[Epoch 18, Batch 200] loss: 0.00011375631684160226
[Epoch 18, Batch 300] loss: 8.01711000126204e-05
[Epoch 18, Batch 400] loss: 8.576732794335129e-05
[Epoch 18, Batch 500] loss: 8.570337595308785e-05
[Epoch 18, Batch 600] loss: 0.00011011595474356817
[Epoch 18, Batch 700] loss: 0.00010048989335921021
[Epoch 18, Batch 800] loss: 0.00020465371112393882
[Epoch 18, Batch 900] loss: 6.605312677123499e-05
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0627
Validation Accuracy: 0.9894
Overfitting: 0.0627
[Epoch 19, Batch 100] loss: 9.280858881666632e-05
[Epoch 19, Batch 200] loss: 0.00014911921309220587
[Epoch 19, Batch 300] loss: 9.318797172454652e-05
[Epoch 19, Batch 400] loss: 6.996129223928449e-05
[Epoch 19, Batch 500] loss: 7.000793022680086e-05
[Epoch 19, Batch 600] loss: 6.9930065662831e-05
[Epoch 19, Batch 700] loss: 5.460897237468565e-05
[Epoch 19, Batch 800] loss: 6.214243987560763e-05
[Epoch 19, Batch 900] loss: 6.974429431622298e-05
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0644
Validation Accuracy: 0.9893
Overfitting: 0.0644
[Epoch 20, Batch 100] loss: 0.00010064622648179977
[Epoch 20, Batch 200] loss: 7.798927275452172e-05
[Epoch 20, Batch 300] loss: 5.445125921543337e-05
[Epoch 20, Batch 400] loss: 4.7343811790152566e-05
[Epoch 20, Batch 500] loss: 6.332799724751537e-05
[Epoch 20, Batch 600] loss: 7.134925635201128e-05
[Epoch 20, Batch 700] loss: 7.476659230334581e-05
[Epoch 20, Batch 800] loss: 5.7300205596026996e-05
[Epoch 20, Batch 900] loss: 4.526995279251267e-05
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0647
Validation Accuracy: 0.9893
Overfitting: 0.0647
[Epoch 21, Batch 100] loss: 9.399449623823664e-05
[Epoch 21, Batch 200] loss: 4.571751988839079e-05
[Epoch 21, Batch 300] loss: 4.8369612187624254e-05
[Epoch 21, Batch 400] loss: 4.3954552891953825e-05
[Epoch 21, Batch 500] loss: 5.497636213216417e-05
[Epoch 21, Batch 600] loss: 5.195806315695606e-05
[Epoch 21, Batch 700] loss: 7.116374064262133e-05
[Epoch 21, Batch 800] loss: 0.00010894383135346075
[Epoch 21, Batch 900] loss: 5.048897221954007e-05
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0653
Validation Accuracy: 0.9896
Overfitting: 0.0653
[Epoch 22, Batch 100] loss: 6.145356101603384e-05
[Epoch 22, Batch 200] loss: 5.568534169690054e-05
[Epoch 22, Batch 300] loss: 4.3408266198685655e-05
[Epoch 22, Batch 400] loss: 4.136070312256379e-05
[Epoch 22, Batch 500] loss: 4.3826531370108054e-05
[Epoch 22, Batch 600] loss: 3.496170063845838e-05
[Epoch 22, Batch 700] loss: 9.889682783366994e-05
[Epoch 22, Batch 800] loss: 6.704321288643511e-05
[Epoch 22, Batch 900] loss: 3.592385530345687e-05
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0662
Validation Accuracy: 0.9894
Overfitting: 0.0662
[Epoch 23, Batch 100] loss: 3.798862073765674e-05
[Epoch 23, Batch 200] loss: 5.4578169028827174e-05
[Epoch 23, Batch 300] loss: 4.550554308909937e-05
[Epoch 23, Batch 400] loss: 4.033599053443027e-05
[Epoch 23, Batch 500] loss: 4.135376781520428e-05
[Epoch 23, Batch 600] loss: 8.492761229621947e-05
[Epoch 23, Batch 700] loss: 3.9678483269935946e-05
[Epoch 23, Batch 800] loss: 4.5145180824994744e-05
[Epoch 23, Batch 900] loss: 5.6399987043036504e-05
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0670
Validation Accuracy: 0.9894
Overfitting: 0.0670
[Epoch 24, Batch 100] loss: 3.278085460912683e-05
[Epoch 24, Batch 200] loss: 7.25492382843207e-05
[Epoch 24, Batch 300] loss: 4.812870268199099e-05
[Epoch 24, Batch 400] loss: 3.0337765274310868e-05
[Epoch 24, Batch 500] loss: 4.964692347828592e-05
[Epoch 24, Batch 600] loss: 3.7071011013551925e-05
[Epoch 24, Batch 700] loss: 5.399622741718346e-05
[Epoch 24, Batch 800] loss: 3.9946998804900604e-05
[Epoch 24, Batch 900] loss: 4.5696576919525e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0676
Validation Accuracy: 0.9895
Overfitting: 0.0676
Fold 1 validation loss: 0.0676
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.5009905549883842
[Epoch 1, Batch 200] loss: 0.403412929661572
[Epoch 1, Batch 300] loss: 0.25268492836505174
[Epoch 1, Batch 400] loss: 0.2063173902966082
[Epoch 1, Batch 500] loss: 0.18922526815906168
[Epoch 1, Batch 600] loss: 0.15664338448783383
[Epoch 1, Batch 700] loss: 0.13184295915067196
[Epoch 1, Batch 800] loss: 0.12344063621014356
[Epoch 1, Batch 900] loss: 0.12369769126875325
**STATS for Epoch 1** : 
Average training loss: 0.0048
Average validation loss: 0.1344
Validation Accuracy: 0.9577
Overfitting: 0.1296
Best model saved at epoch 1 with validation loss: 0.1344
[Epoch 2, Batch 100] loss: 0.11147140467073768
[Epoch 2, Batch 200] loss: 0.09780558848520741
[Epoch 2, Batch 300] loss: 0.0948017390887253
[Epoch 2, Batch 400] loss: 0.09948050294071437
[Epoch 2, Batch 500] loss: 0.08251380843576044
[Epoch 2, Batch 600] loss: 0.08238866789266468
[Epoch 2, Batch 700] loss: 0.0844743895076681
[Epoch 2, Batch 800] loss: 0.07454661537194625
[Epoch 2, Batch 900] loss: 0.07240223728818819
**STATS for Epoch 2** : 
Average training loss: 0.0022
Average validation loss: 0.0938
Validation Accuracy: 0.9705
Overfitting: 0.0916
Best model saved at epoch 2 with validation loss: 0.0938
[Epoch 3, Batch 100] loss: 0.061607874991605055
[Epoch 3, Batch 200] loss: 0.05036522558424622
[Epoch 3, Batch 300] loss: 0.055483126281760636
[Epoch 3, Batch 400] loss: 0.056891276201349684
[Epoch 3, Batch 500] loss: 0.050104675614275035
[Epoch 3, Batch 600] loss: 0.06455319735920056
[Epoch 3, Batch 700] loss: 0.050783638781867924
[Epoch 3, Batch 800] loss: 0.06639671588083729
[Epoch 3, Batch 900] loss: 0.05231921861995943
**STATS for Epoch 3** : 
Average training loss: 0.0023
Average validation loss: 0.0581
Validation Accuracy: 0.9827
Overfitting: 0.0558
Best model saved at epoch 3 with validation loss: 0.0581
[Epoch 4, Batch 100] loss: 0.03356140064744977
[Epoch 4, Batch 200] loss: 0.028108318149170374
[Epoch 4, Batch 300] loss: 0.04169485327482107
[Epoch 4, Batch 400] loss: 0.04449791498715058
[Epoch 4, Batch 500] loss: 0.041178988985484465
[Epoch 4, Batch 600] loss: 0.052466935124248264
[Epoch 4, Batch 700] loss: 0.04625068133464083
[Epoch 4, Batch 800] loss: 0.05082205630140379
[Epoch 4, Batch 900] loss: 0.03362938348873286
**STATS for Epoch 4** : 
Average training loss: 0.0019
Average validation loss: 0.0649
Validation Accuracy: 0.9798
Overfitting: 0.0630
[Epoch 5, Batch 100] loss: 0.028662892894935794
[Epoch 5, Batch 200] loss: 0.032652012303005906
[Epoch 5, Batch 300] loss: 0.03719070205072057
[Epoch 5, Batch 400] loss: 0.03607534463983029
[Epoch 5, Batch 500] loss: 0.03154633402802574
[Epoch 5, Batch 600] loss: 0.027803658818447728
[Epoch 5, Batch 700] loss: 0.03654410799652396
[Epoch 5, Batch 800] loss: 0.035288543593342186
[Epoch 5, Batch 900] loss: 0.03151806465102709
**STATS for Epoch 5** : 
Average training loss: 0.0011
Average validation loss: 0.0593
Validation Accuracy: 0.9825
Overfitting: 0.0582
[Epoch 6, Batch 100] loss: 0.02017678226889984
[Epoch 6, Batch 200] loss: 0.013838184662163258
[Epoch 6, Batch 300] loss: 0.015566124014239903
[Epoch 6, Batch 400] loss: 0.023359308747894828
[Epoch 6, Batch 500] loss: 0.018192163252460886
[Epoch 6, Batch 600] loss: 0.03819327707227785
[Epoch 6, Batch 700] loss: 0.018076454862530227
[Epoch 6, Batch 800] loss: 0.03656545348087093
[Epoch 6, Batch 900] loss: 0.020088496632743046
**STATS for Epoch 6** : 
Average training loss: 0.0013
Average validation loss: 0.0834
Validation Accuracy: 0.9767
Overfitting: 0.0821
[Epoch 7, Batch 100] loss: 0.017159980723699845
[Epoch 7, Batch 200] loss: 0.016013751154314377
[Epoch 7, Batch 300] loss: 0.017880298386880895
[Epoch 7, Batch 400] loss: 0.018600905910352593
[Epoch 7, Batch 500] loss: 0.0239215963971219
[Epoch 7, Batch 600] loss: 0.023244576177967248
[Epoch 7, Batch 700] loss: 0.02535288703511469
[Epoch 7, Batch 800] loss: 0.024693519099600963
[Epoch 7, Batch 900] loss: 0.02112563134774973
**STATS for Epoch 7** : 
Average training loss: 0.0012
Average validation loss: 0.0511
Validation Accuracy: 0.9862
Overfitting: 0.0499
Best model saved at epoch 7 with validation loss: 0.0511
[Epoch 8, Batch 100] loss: 0.013785967513176728
[Epoch 8, Batch 200] loss: 0.012206334995280486
[Epoch 8, Batch 300] loss: 0.014362218653113814
[Epoch 8, Batch 400] loss: 0.015604225542592758
[Epoch 8, Batch 500] loss: 0.016357472287236306
[Epoch 8, Batch 600] loss: 0.012571891487095855
[Epoch 8, Batch 700] loss: 0.01173776530475152
[Epoch 8, Batch 800] loss: 0.02024793696562483
[Epoch 8, Batch 900] loss: 0.020533098883533968
**STATS for Epoch 8** : 
Average training loss: 0.0006
Average validation loss: 0.0540
Validation Accuracy: 0.9847
Overfitting: 0.0535
[Epoch 9, Batch 100] loss: 0.00982690930796707
[Epoch 9, Batch 200] loss: 0.009518011168129305
[Epoch 9, Batch 300] loss: 0.013454117316314296
[Epoch 9, Batch 400] loss: 0.008637120814673835
[Epoch 9, Batch 500] loss: 0.011528630888251427
[Epoch 9, Batch 600] loss: 0.021144886443830727
[Epoch 9, Batch 700] loss: 0.01402100326271011
[Epoch 9, Batch 800] loss: 0.009711108685742147
[Epoch 9, Batch 900] loss: 0.0132992362549885
**STATS for Epoch 9** : 
Average training loss: 0.0004
Average validation loss: 0.0622
Validation Accuracy: 0.9838
Overfitting: 0.0617
[Epoch 10, Batch 100] loss: 0.0056565820119976705
[Epoch 10, Batch 200] loss: 0.009352380882501166
[Epoch 10, Batch 300] loss: 0.011248311850690697
[Epoch 10, Batch 400] loss: 0.009112848463209956
[Epoch 10, Batch 500] loss: 0.008037075677725625
[Epoch 10, Batch 600] loss: 0.007214276570703077
[Epoch 10, Batch 700] loss: 0.011317058130271108
[Epoch 10, Batch 800] loss: 0.017963875795667262
[Epoch 10, Batch 900] loss: 0.011048687092197725
**STATS for Epoch 10** : 
Average training loss: 0.0010
Average validation loss: 0.0649
Validation Accuracy: 0.9828
Overfitting: 0.0639
[Epoch 11, Batch 100] loss: 0.01370794687056332
[Epoch 11, Batch 200] loss: 0.00478462110619148
[Epoch 11, Batch 300] loss: 0.004694931616395479
[Epoch 11, Batch 400] loss: 0.009408693899113132
[Epoch 11, Batch 500] loss: 0.011842233504912656
[Epoch 11, Batch 600] loss: 0.008036927200964782
[Epoch 11, Batch 700] loss: 0.005366991196660819
[Epoch 11, Batch 800] loss: 0.011993450555528397
[Epoch 11, Batch 900] loss: 0.00968630572134316
**STATS for Epoch 11** : 
Average training loss: 0.0003
Average validation loss: 0.0742
Validation Accuracy: 0.9843
Overfitting: 0.0739
[Epoch 12, Batch 100] loss: 0.010595934005414165
[Epoch 12, Batch 200] loss: 0.011312285683407025
[Epoch 12, Batch 300] loss: 0.00988143813012357
[Epoch 12, Batch 400] loss: 0.004917077128075107
[Epoch 12, Batch 500] loss: 0.004056196722556252
[Epoch 12, Batch 600] loss: 0.003947533955897598
[Epoch 12, Batch 700] loss: 0.0023660706020086765
[Epoch 12, Batch 800] loss: 0.0044890406324498144
[Epoch 12, Batch 900] loss: 0.00610946358779529
**STATS for Epoch 12** : 
Average training loss: 0.0013
Average validation loss: 0.0743
Validation Accuracy: 0.9836
Overfitting: 0.0730
[Epoch 13, Batch 100] loss: 0.023246294751670574
[Epoch 13, Batch 200] loss: 0.01040880404553036
[Epoch 13, Batch 300] loss: 0.009978498720215612
[Epoch 13, Batch 400] loss: 0.01136977362219568
[Epoch 13, Batch 500] loss: 0.018297716149829737
[Epoch 13, Batch 600] loss: 0.006083436087924383
[Epoch 13, Batch 700] loss: 0.0116756524612083
[Epoch 13, Batch 800] loss: 0.01080802726019101
[Epoch 13, Batch 900] loss: 0.00889876322611599
**STATS for Epoch 13** : 
Average training loss: 0.0002
Average validation loss: 0.0538
Validation Accuracy: 0.9876
Overfitting: 0.0536
[Epoch 14, Batch 100] loss: 0.0034428591131268147
[Epoch 14, Batch 200] loss: 0.010878561409651866
[Epoch 14, Batch 300] loss: 0.006124547762287875
[Epoch 14, Batch 400] loss: 0.0012345851576651512
[Epoch 14, Batch 500] loss: 0.0012975679609621693
[Epoch 14, Batch 600] loss: 0.0008222042901337545
[Epoch 14, Batch 700] loss: 0.0013058886205743647
[Epoch 14, Batch 800] loss: 0.005284539610165666
[Epoch 14, Batch 900] loss: 0.0044089337296554735
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0786
Validation Accuracy: 0.9829
Overfitting: 0.0780
[Epoch 15, Batch 100] loss: 0.007906988139616829
[Epoch 15, Batch 200] loss: 0.003860449044389895
[Epoch 15, Batch 300] loss: 0.007957107685107302
[Epoch 15, Batch 400] loss: 0.0027256230229227183
[Epoch 15, Batch 500] loss: 0.004792523658860546
[Epoch 15, Batch 600] loss: 0.0011793332977538284
[Epoch 15, Batch 700] loss: 0.0008011393711359461
[Epoch 15, Batch 800] loss: 0.0065176350294325405
[Epoch 15, Batch 900] loss: 0.002089525909061649
**STATS for Epoch 15** : 
Average training loss: 0.0002
Average validation loss: 0.0607
Validation Accuracy: 0.9872
Overfitting: 0.0605
[Epoch 16, Batch 100] loss: 0.0012332396599805406
[Epoch 16, Batch 200] loss: 0.0021955199650085435
[Epoch 16, Batch 300] loss: 0.001078319030945636
[Epoch 16, Batch 400] loss: 0.0012151863178749523
[Epoch 16, Batch 500] loss: 0.001063350386855575
[Epoch 16, Batch 600] loss: 0.0016014321366267835
[Epoch 16, Batch 700] loss: 0.001906985476107934
[Epoch 16, Batch 800] loss: 0.0050524478630202905
[Epoch 16, Batch 900] loss: 0.009946312152151223
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.0677
Validation Accuracy: 0.9864
Overfitting: 0.0671
[Epoch 17, Batch 100] loss: 0.005796487187228933
[Epoch 17, Batch 200] loss: 0.0011659585985572107
[Epoch 17, Batch 300] loss: 0.003471323067402068
[Epoch 17, Batch 400] loss: 0.002637848401439271
[Epoch 17, Batch 500] loss: 0.0006618434242805904
[Epoch 17, Batch 600] loss: 0.0033214986833785074
[Epoch 17, Batch 700] loss: 0.0006825897103146849
[Epoch 17, Batch 800] loss: 0.0036953200384044747
[Epoch 17, Batch 900] loss: 0.0018324673829761195
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0618
Validation Accuracy: 0.9878
Overfitting: 0.0617
[Epoch 18, Batch 100] loss: 0.0016015713253653985
[Epoch 18, Batch 200] loss: 0.0026544160554333018
[Epoch 18, Batch 300] loss: 0.00044199363067846774
[Epoch 18, Batch 400] loss: 0.00035112819040158174
[Epoch 18, Batch 500] loss: 0.0002637799556346465
[Epoch 18, Batch 600] loss: 0.001450659320809109
[Epoch 18, Batch 700] loss: 0.00038776000840863746
[Epoch 18, Batch 800] loss: 0.0004905193474306202
[Epoch 18, Batch 900] loss: 0.0003381146899802445
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9880
Overfitting: 0.0635
[Epoch 19, Batch 100] loss: 0.00031890145702050175
[Epoch 19, Batch 200] loss: 0.00015289987959128836
[Epoch 19, Batch 300] loss: 7.578402761623693e-05
[Epoch 19, Batch 400] loss: 0.00016597561595268928
[Epoch 19, Batch 500] loss: 0.00012499359094917395
[Epoch 19, Batch 600] loss: 5.672598495518599e-05
[Epoch 19, Batch 700] loss: 0.00012249915019967971
[Epoch 19, Batch 800] loss: 0.0001977830344434395
[Epoch 19, Batch 900] loss: 0.0003106412196515862
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0598
Validation Accuracy: 0.9891
Overfitting: 0.0598
[Epoch 20, Batch 100] loss: 7.900733941667681e-05
[Epoch 20, Batch 200] loss: 8.126205224145977e-05
[Epoch 20, Batch 300] loss: 0.00011499232373786583
[Epoch 20, Batch 400] loss: 8.317816067375361e-05
[Epoch 20, Batch 500] loss: 7.259860539429397e-05
[Epoch 20, Batch 600] loss: 8.00929388663718e-05
[Epoch 20, Batch 700] loss: 7.820736374322123e-05
[Epoch 20, Batch 800] loss: 0.00010873167162002595
[Epoch 20, Batch 900] loss: 6.729387039207335e-05
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0610
Validation Accuracy: 0.9891
Overfitting: 0.0610
[Epoch 21, Batch 100] loss: 7.717825419696567e-05
[Epoch 21, Batch 200] loss: 6.483168190965394e-05
[Epoch 21, Batch 300] loss: 5.7352734665379044e-05
[Epoch 21, Batch 400] loss: 6.779239105092927e-05
[Epoch 21, Batch 500] loss: 4.737417497480578e-05
[Epoch 21, Batch 600] loss: 6.60850896453935e-05
[Epoch 21, Batch 700] loss: 4.137656882287288e-05
[Epoch 21, Batch 800] loss: 7.67198995843188e-05
[Epoch 21, Batch 900] loss: 5.642647957099456e-05
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9893
Overfitting: 0.0619
[Epoch 22, Batch 100] loss: 6.357746191188341e-05
[Epoch 22, Batch 200] loss: 5.5487117226533655e-05
[Epoch 22, Batch 300] loss: 5.508851934948211e-05
[Epoch 22, Batch 400] loss: 6.547657976383902e-05
[Epoch 22, Batch 500] loss: 4.9483254248943175e-05
[Epoch 22, Batch 600] loss: 3.8629176232483073e-05
[Epoch 22, Batch 700] loss: 4.5668349781431416e-05
[Epoch 22, Batch 800] loss: 5.068944688460197e-05
[Epoch 22, Batch 900] loss: 4.8601774349392724e-05
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0625
Validation Accuracy: 0.9893
Overfitting: 0.0625
[Epoch 23, Batch 100] loss: 5.675132941099781e-05
[Epoch 23, Batch 200] loss: 5.6005247621353506e-05
[Epoch 23, Batch 300] loss: 3.799609870943854e-05
[Epoch 23, Batch 400] loss: 4.88650036497873e-05
[Epoch 23, Batch 500] loss: 5.5057952548907e-05
[Epoch 23, Batch 600] loss: 4.018732594546215e-05
[Epoch 23, Batch 700] loss: 3.909845086830899e-05
[Epoch 23, Batch 800] loss: 4.523067708865014e-05
[Epoch 23, Batch 900] loss: 3.6120118333919926e-05
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9893
Overfitting: 0.0632
[Epoch 24, Batch 100] loss: 3.8550962968812995e-05
[Epoch 24, Batch 200] loss: 2.962129748286024e-05
[Epoch 24, Batch 300] loss: 4.727581392376834e-05
[Epoch 24, Batch 400] loss: 4.4860931714652e-05
[Epoch 24, Batch 500] loss: 4.121890011785645e-05
[Epoch 24, Batch 600] loss: 2.9288207633069163e-05
[Epoch 24, Batch 700] loss: 4.601779738898415e-05
[Epoch 24, Batch 800] loss: 3.756884622517997e-05
[Epoch 24, Batch 900] loss: 5.087838560689839e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0637
Validation Accuracy: 0.9895
Overfitting: 0.0637
Fold 2 validation loss: 0.0637
Mean validation loss across all folds for Trial 20 is 0.0657 with trial config:  l1: 512, l2: 224, lr: 0.00670065004252065, batch_size: 32
[I 2024-11-19 02:40:26,581] Trial 19 finished with value: 0.06565507791651809 and parameters: {'l1': 512, 'l2': 224, 'lr': 0.00670065004252065, 'batch_size': 32}. Best is trial 0 with value: 0.05886771301817843.
[W 2024-11-19 02:40:26,612] The parameter 'l2' in trial#20 is sampled independently instead of being sampled by multivariate TPE sampler. (optimization performance may be degraded). You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `TPESampler`, if this independent sampling is intended behavior.

Selected Hyperparameters for Trial 21:
  l1: 160, l2: 160, lr: 0.000997693382448528, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.293279275894165
[Epoch 1, Batch 200] loss: 2.2570191836357116
[Epoch 1, Batch 300] loss: 2.1545134317874908
[Epoch 1, Batch 400] loss: 1.4979581373929978
[Epoch 1, Batch 500] loss: 0.6230019956827164
[Epoch 1, Batch 600] loss: 0.46355486281216146
[Epoch 1, Batch 700] loss: 0.41139053501188755
[Epoch 1, Batch 800] loss: 0.3568407407402992
[Epoch 1, Batch 900] loss: 0.3234738301113248
[Epoch 1, Batch 1000] loss: 0.300900121293962
[Epoch 1, Batch 1100] loss: 0.2825639456883073
[Epoch 1, Batch 1200] loss: 0.25163715742528436
[Epoch 1, Batch 1300] loss: 0.2605630298145115
[Epoch 1, Batch 1400] loss: 0.2263770068436861
[Epoch 1, Batch 1500] loss: 0.23047039417549967
[Epoch 1, Batch 1600] loss: 0.23265454405918717
[Epoch 1, Batch 1700] loss: 0.21022108122706412
[Epoch 1, Batch 1800] loss: 0.17222118145786225
**STATS for Epoch 1** : 
Average training loss: 0.0067
Average validation loss: 0.1648
Validation Accuracy: 0.9489
Overfitting: 0.1582
Best model saved at epoch 1 with validation loss: 0.1648
[Epoch 2, Batch 100] loss: 0.16177642110735177
[Epoch 2, Batch 200] loss: 0.15767036547884344
[Epoch 2, Batch 300] loss: 0.14264694099314512
[Epoch 2, Batch 400] loss: 0.17824561572633685
[Epoch 2, Batch 500] loss: 0.1520087327901274
[Epoch 2, Batch 600] loss: 0.1396220432780683
[Epoch 2, Batch 700] loss: 0.1340074225049466
[Epoch 2, Batch 800] loss: 0.11394005760084838
[Epoch 2, Batch 900] loss: 0.11972508434206247
[Epoch 2, Batch 1000] loss: 0.11910234682727605
[Epoch 2, Batch 1100] loss: 0.09948303484823555
[Epoch 2, Batch 1200] loss: 0.12204173900652676
[Epoch 2, Batch 1300] loss: 0.09809964665677398
[Epoch 2, Batch 1400] loss: 0.12977955946465955
[Epoch 2, Batch 1500] loss: 0.09209986767265946
[Epoch 2, Batch 1600] loss: 0.09595137785654514
[Epoch 2, Batch 1700] loss: 0.11041219729697332
[Epoch 2, Batch 1800] loss: 0.10494168932549655
**STATS for Epoch 2** : 
Average training loss: 0.0040
Average validation loss: 0.1068
Validation Accuracy: 0.9664
Overfitting: 0.1028
Best model saved at epoch 2 with validation loss: 0.1068
[Epoch 3, Batch 100] loss: 0.11809410235611723
[Epoch 3, Batch 200] loss: 0.08706587876193225
[Epoch 3, Batch 300] loss: 0.08557749526575208
[Epoch 3, Batch 400] loss: 0.06934028062736615
[Epoch 3, Batch 500] loss: 0.07795137357956264
[Epoch 3, Batch 600] loss: 0.07268834789632819
[Epoch 3, Batch 700] loss: 0.08985460521886125
[Epoch 3, Batch 800] loss: 0.08506184510653839
[Epoch 3, Batch 900] loss: 0.06718198995804414
[Epoch 3, Batch 1000] loss: 0.0687596308416687
[Epoch 3, Batch 1100] loss: 0.11037486592307687
[Epoch 3, Batch 1200] loss: 0.10081170094199479
[Epoch 3, Batch 1300] loss: 0.0988941747113131
[Epoch 3, Batch 1400] loss: 0.0668314669211395
[Epoch 3, Batch 1500] loss: 0.09659040328580887
[Epoch 3, Batch 1600] loss: 0.06732649731216953
[Epoch 3, Batch 1700] loss: 0.06357326405181084
[Epoch 3, Batch 1800] loss: 0.06948307194237714
**STATS for Epoch 3** : 
Average training loss: 0.0021
Average validation loss: 0.0891
Validation Accuracy: 0.9724
Overfitting: 0.0870
Best model saved at epoch 3 with validation loss: 0.0891
[Epoch 4, Batch 100] loss: 0.060320476985070856
[Epoch 4, Batch 200] loss: 0.06905197274230886
[Epoch 4, Batch 300] loss: 0.08768968715390656
[Epoch 4, Batch 400] loss: 0.0758993591577746
[Epoch 4, Batch 500] loss: 0.06303407750558108
[Epoch 4, Batch 600] loss: 0.06339891470270231
[Epoch 4, Batch 700] loss: 0.05713147503673099
[Epoch 4, Batch 800] loss: 0.06512452788534574
[Epoch 4, Batch 900] loss: 0.07413358790625352
[Epoch 4, Batch 1000] loss: 0.05338579457078595
[Epoch 4, Batch 1100] loss: 0.05958962194970809
[Epoch 4, Batch 1200] loss: 0.06621813789592125
[Epoch 4, Batch 1300] loss: 0.06356970582390203
[Epoch 4, Batch 1400] loss: 0.07180788063909858
[Epoch 4, Batch 1500] loss: 0.062460727737052364
[Epoch 4, Batch 1600] loss: 0.047303210225363726
[Epoch 4, Batch 1700] loss: 0.05225848766422132
[Epoch 4, Batch 1800] loss: 0.059784585561137644
**STATS for Epoch 4** : 
Average training loss: 0.0022
Average validation loss: 0.0714
Validation Accuracy: 0.9781
Overfitting: 0.0692
Best model saved at epoch 4 with validation loss: 0.0714
[Epoch 5, Batch 100] loss: 0.03597794058034196
[Epoch 5, Batch 200] loss: 0.05233479365764651
[Epoch 5, Batch 300] loss: 0.058500028681592084
[Epoch 5, Batch 400] loss: 0.04687059952499112
[Epoch 5, Batch 500] loss: 0.06293113531181006
[Epoch 5, Batch 600] loss: 0.036516962905880065
[Epoch 5, Batch 700] loss: 0.06286886723595671
[Epoch 5, Batch 800] loss: 0.06410955634026322
[Epoch 5, Batch 900] loss: 0.05508093958022073
[Epoch 5, Batch 1000] loss: 0.04555428673498682
[Epoch 5, Batch 1100] loss: 0.04327664049254963
[Epoch 5, Batch 1200] loss: 0.06526392935891635
[Epoch 5, Batch 1300] loss: 0.056184702049940825
[Epoch 5, Batch 1400] loss: 0.04514705645851791
[Epoch 5, Batch 1500] loss: 0.06397944111959078
[Epoch 5, Batch 1600] loss: 0.035332879848429005
[Epoch 5, Batch 1700] loss: 0.06618846568511799
[Epoch 5, Batch 1800] loss: 0.057654066627292194
**STATS for Epoch 5** : 
Average training loss: 0.0021
Average validation loss: 0.0687
Validation Accuracy: 0.9786
Overfitting: 0.0666
Best model saved at epoch 5 with validation loss: 0.0687
[Epoch 6, Batch 100] loss: 0.03817928965232568
[Epoch 6, Batch 200] loss: 0.05483992227207637
[Epoch 6, Batch 300] loss: 0.05898859798558988
[Epoch 6, Batch 400] loss: 0.03840216023483663
[Epoch 6, Batch 500] loss: 0.033938084451656324
[Epoch 6, Batch 600] loss: 0.032914923461794386
[Epoch 6, Batch 700] loss: 0.020802303758537165
[Epoch 6, Batch 800] loss: 0.05391385845941841
[Epoch 6, Batch 900] loss: 0.04618278037101845
[Epoch 6, Batch 1000] loss: 0.053599065156304276
[Epoch 6, Batch 1100] loss: 0.05554722731554648
[Epoch 6, Batch 1200] loss: 0.03234884123085067
[Epoch 6, Batch 1300] loss: 0.037303489930636716
[Epoch 6, Batch 1400] loss: 0.057969809756759784
[Epoch 6, Batch 1500] loss: 0.04460850051036687
[Epoch 6, Batch 1600] loss: 0.060915462838311216
[Epoch 6, Batch 1700] loss: 0.04513240394415334
[Epoch 6, Batch 1800] loss: 0.04569930007943185
**STATS for Epoch 6** : 
Average training loss: 0.0022
Average validation loss: 0.0567
Validation Accuracy: 0.9826
Overfitting: 0.0545
Best model saved at epoch 6 with validation loss: 0.0567
[Epoch 7, Batch 100] loss: 0.03634915278031258
[Epoch 7, Batch 200] loss: 0.03700107069744263
[Epoch 7, Batch 300] loss: 0.04607406782277394
[Epoch 7, Batch 400] loss: 0.03660098634980386
[Epoch 7, Batch 500] loss: 0.025984190453891644
[Epoch 7, Batch 600] loss: 0.03267589744682482
[Epoch 7, Batch 700] loss: 0.03879995863127988
[Epoch 7, Batch 800] loss: 0.038961641688656526
[Epoch 7, Batch 900] loss: 0.033083187177835496
[Epoch 7, Batch 1000] loss: 0.0432857444928959
[Epoch 7, Batch 1100] loss: 0.033234227452630875
[Epoch 7, Batch 1200] loss: 0.03896555170431384
[Epoch 7, Batch 1300] loss: 0.047343028153118215
[Epoch 7, Batch 1400] loss: 0.038741938019120424
[Epoch 7, Batch 1500] loss: 0.03711071774276206
[Epoch 7, Batch 1600] loss: 0.04343774041793949
[Epoch 7, Batch 1700] loss: 0.04014301325310953
[Epoch 7, Batch 1800] loss: 0.040794022099580614
**STATS for Epoch 7** : 
Average training loss: 0.0013
Average validation loss: 0.0558
Validation Accuracy: 0.9826
Overfitting: 0.0545
Best model saved at epoch 7 with validation loss: 0.0558
[Epoch 8, Batch 100] loss: 0.04046235094210715
[Epoch 8, Batch 200] loss: 0.03391027946941904
[Epoch 8, Batch 300] loss: 0.029462191883503693
[Epoch 8, Batch 400] loss: 0.02574453594221268
[Epoch 8, Batch 500] loss: 0.03860280841079657
[Epoch 8, Batch 600] loss: 0.025504163900623097
[Epoch 8, Batch 700] loss: 0.03136781510769651
[Epoch 8, Batch 800] loss: 0.022536547546333167
[Epoch 8, Batch 900] loss: 0.03542194730885967
[Epoch 8, Batch 1000] loss: 0.04465305875128252
[Epoch 8, Batch 1100] loss: 0.043730420768333715
[Epoch 8, Batch 1200] loss: 0.020356251416960732
[Epoch 8, Batch 1300] loss: 0.03112793196662096
[Epoch 8, Batch 1400] loss: 0.027583630155932043
[Epoch 8, Batch 1500] loss: 0.024502263343165395
[Epoch 8, Batch 1600] loss: 0.050189407167054015
[Epoch 8, Batch 1700] loss: 0.046783013418244083
[Epoch 8, Batch 1800] loss: 0.03567658508123714
**STATS for Epoch 8** : 
Average training loss: 0.0010
Average validation loss: 0.0593
Validation Accuracy: 0.9821
Overfitting: 0.0584
[Epoch 9, Batch 100] loss: 0.023227812535187697
[Epoch 9, Batch 200] loss: 0.0265066797019972
[Epoch 9, Batch 300] loss: 0.031185052174987505
[Epoch 9, Batch 400] loss: 0.021371059181692544
[Epoch 9, Batch 500] loss: 0.022615693230764008
[Epoch 9, Batch 600] loss: 0.029081986531127767
[Epoch 9, Batch 700] loss: 0.03169171732137329
[Epoch 9, Batch 800] loss: 0.0202079388590937
[Epoch 9, Batch 900] loss: 0.028097926027403446
[Epoch 9, Batch 1000] loss: 0.02129589256413965
[Epoch 9, Batch 1100] loss: 0.02863307716907002
[Epoch 9, Batch 1200] loss: 0.03585429824986932
[Epoch 9, Batch 1300] loss: 0.025415476466951078
[Epoch 9, Batch 1400] loss: 0.03822963960807101
[Epoch 9, Batch 1500] loss: 0.028168484558191268
[Epoch 9, Batch 1600] loss: 0.03295430630671035
[Epoch 9, Batch 1700] loss: 0.025193571365307435
[Epoch 9, Batch 1800] loss: 0.03391142323365784
**STATS for Epoch 9** : 
Average training loss: 0.0010
Average validation loss: 0.0590
Validation Accuracy: 0.9817
Overfitting: 0.0580
[Epoch 10, Batch 100] loss: 0.013827445876668207
[Epoch 10, Batch 200] loss: 0.01251988991516555
[Epoch 10, Batch 300] loss: 0.01324709817999974
[Epoch 10, Batch 400] loss: 0.018499495129108253
[Epoch 10, Batch 500] loss: 0.020398862257279687
[Epoch 10, Batch 600] loss: 0.026762025089774398
[Epoch 10, Batch 700] loss: 0.010452833629133238
[Epoch 10, Batch 800] loss: 0.02426925338946603
[Epoch 10, Batch 900] loss: 0.03003869920537909
[Epoch 10, Batch 1000] loss: 0.03669007333155605
[Epoch 10, Batch 1100] loss: 0.028947380583595077
[Epoch 10, Batch 1200] loss: 0.024261830946015833
[Epoch 10, Batch 1300] loss: 0.04072832130012102
[Epoch 10, Batch 1400] loss: 0.017790296567691256
[Epoch 10, Batch 1500] loss: 0.022949765800440218
[Epoch 10, Batch 1600] loss: 0.025539068489015337
[Epoch 10, Batch 1700] loss: 0.03889992434176747
[Epoch 10, Batch 1800] loss: 0.037300065522722435
**STATS for Epoch 10** : 
Average training loss: 0.0010
Average validation loss: 0.0553
Validation Accuracy: 0.9846
Overfitting: 0.0543
Best model saved at epoch 10 with validation loss: 0.0553
[Epoch 11, Batch 100] loss: 0.022235706308638328
[Epoch 11, Batch 200] loss: 0.019514454356976785
[Epoch 11, Batch 300] loss: 0.025391944232032983
[Epoch 11, Batch 400] loss: 0.025111688066317583
[Epoch 11, Batch 500] loss: 0.02324926757504727
[Epoch 11, Batch 600] loss: 0.01748979140415031
[Epoch 11, Batch 700] loss: 0.013340396164167032
[Epoch 11, Batch 800] loss: 0.016742360977114002
[Epoch 11, Batch 900] loss: 0.022319840372256296
[Epoch 11, Batch 1000] loss: 0.021254626023946913
[Epoch 11, Batch 1100] loss: 0.010878535844240105
[Epoch 11, Batch 1200] loss: 0.023927400045940884
[Epoch 11, Batch 1300] loss: 0.01523555394513096
[Epoch 11, Batch 1400] loss: 0.032535505365585776
[Epoch 11, Batch 1500] loss: 0.038011434597610784
[Epoch 11, Batch 1600] loss: 0.026235271122022823
[Epoch 11, Batch 1700] loss: 0.01873905937100062
[Epoch 11, Batch 1800] loss: 0.024174024111907784
**STATS for Epoch 11** : 
Average training loss: 0.0006
Average validation loss: 0.0553
Validation Accuracy: 0.9842
Overfitting: 0.0547
[Epoch 12, Batch 100] loss: 0.021582629611457377
[Epoch 12, Batch 200] loss: 0.015261076935166784
[Epoch 12, Batch 300] loss: 0.01834443401028693
[Epoch 12, Batch 400] loss: 0.03044308003900369
[Epoch 12, Batch 500] loss: 0.02592919448044995
[Epoch 12, Batch 600] loss: 0.016089350051479413
[Epoch 12, Batch 700] loss: 0.015627000307049457
[Epoch 12, Batch 800] loss: 0.014967296119466482
[Epoch 12, Batch 900] loss: 0.01604583636690222
[Epoch 12, Batch 1000] loss: 0.014149605299862741
[Epoch 12, Batch 1100] loss: 0.014466187147190794
[Epoch 12, Batch 1200] loss: 0.027088344365874945
[Epoch 12, Batch 1300] loss: 0.019676699642932362
[Epoch 12, Batch 1400] loss: 0.014937725650233914
[Epoch 12, Batch 1500] loss: 0.013654820757819834
[Epoch 12, Batch 1600] loss: 0.021014372814279342
[Epoch 12, Batch 1700] loss: 0.018475891920352296
[Epoch 12, Batch 1800] loss: 0.016692624431198056
**STATS for Epoch 12** : 
Average training loss: 0.0005
Average validation loss: 0.0589
Validation Accuracy: 0.9839
Overfitting: 0.0584
[Epoch 13, Batch 100] loss: 0.017134673235777883
[Epoch 13, Batch 200] loss: 0.013263048738008366
[Epoch 13, Batch 300] loss: 0.014775859800647596
[Epoch 13, Batch 400] loss: 0.014722610232929582
[Epoch 13, Batch 500] loss: 0.0117896209161745
[Epoch 13, Batch 600] loss: 0.01641433258788311
[Epoch 13, Batch 700] loss: 0.016848289901354292
[Epoch 13, Batch 800] loss: 0.019750214336218052
[Epoch 13, Batch 900] loss: 0.011625026787964999
[Epoch 13, Batch 1000] loss: 0.011811238747959578
[Epoch 13, Batch 1100] loss: 0.021540861769681216
[Epoch 13, Batch 1200] loss: 0.008115605669918296
[Epoch 13, Batch 1300] loss: 0.013089748366273852
[Epoch 13, Batch 1400] loss: 0.015487198847813488
[Epoch 13, Batch 1500] loss: 0.011635334048005461
[Epoch 13, Batch 1600] loss: 0.023127523864386604
[Epoch 13, Batch 1700] loss: 0.02142924484815012
[Epoch 13, Batch 1800] loss: 0.029268262838868395
**STATS for Epoch 13** : 
Average training loss: 0.0004
Average validation loss: 0.0494
Validation Accuracy: 0.9861
Overfitting: 0.0490
Best model saved at epoch 13 with validation loss: 0.0494
[Epoch 14, Batch 100] loss: 0.004982990827422782
[Epoch 14, Batch 200] loss: 0.010242638432555396
[Epoch 14, Batch 300] loss: 0.008984826662363048
[Epoch 14, Batch 400] loss: 0.01393857682775888
[Epoch 14, Batch 500] loss: 0.01381168462889491
[Epoch 14, Batch 600] loss: 0.01530928331719224
[Epoch 14, Batch 700] loss: 0.01308014208878376
[Epoch 14, Batch 800] loss: 0.010659251366341778
[Epoch 14, Batch 900] loss: 0.008234688849156555
[Epoch 14, Batch 1000] loss: 0.013351926113637091
[Epoch 14, Batch 1100] loss: 0.009435886033679708
[Epoch 14, Batch 1200] loss: 0.017718303361455127
[Epoch 14, Batch 1300] loss: 0.012670657669514186
[Epoch 14, Batch 1400] loss: 0.01692780058155222
[Epoch 14, Batch 1500] loss: 0.021142504190747785
[Epoch 14, Batch 1600] loss: 0.018418159987486433
[Epoch 14, Batch 1700] loss: 0.013469928900776721
[Epoch 14, Batch 1800] loss: 0.01219488324581107
**STATS for Epoch 14** : 
Average training loss: 0.0006
Average validation loss: 0.0558
Validation Accuracy: 0.9847
Overfitting: 0.0552
[Epoch 15, Batch 100] loss: 0.00846086256644412
[Epoch 15, Batch 200] loss: 0.006418547223875066
[Epoch 15, Batch 300] loss: 0.00870419667056467
[Epoch 15, Batch 400] loss: 0.008094724935199337
[Epoch 15, Batch 500] loss: 0.005018419682010063
[Epoch 15, Batch 600] loss: 0.011407972766373859
[Epoch 15, Batch 700] loss: 0.006766426265453446
[Epoch 15, Batch 800] loss: 0.009850135506239895
[Epoch 15, Batch 900] loss: 0.006229139926454082
[Epoch 15, Batch 1000] loss: 0.013380933809576162
[Epoch 15, Batch 1100] loss: 0.013668903322177357
[Epoch 15, Batch 1200] loss: 0.013562044796362898
[Epoch 15, Batch 1300] loss: 0.011589726263014199
[Epoch 15, Batch 1400] loss: 0.023389361454205754
[Epoch 15, Batch 1500] loss: 0.016192996013469383
[Epoch 15, Batch 1600] loss: 0.013205113914755201
[Epoch 15, Batch 1700] loss: 0.009698509081936209
[Epoch 15, Batch 1800] loss: 0.011814693072917635
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0566
Validation Accuracy: 0.9851
Overfitting: 0.0560
[Epoch 16, Batch 100] loss: 0.00944601375228558
[Epoch 16, Batch 200] loss: 0.008788508414472745
[Epoch 16, Batch 300] loss: 0.00951224596637985
[Epoch 16, Batch 400] loss: 0.009396980723931848
[Epoch 16, Batch 500] loss: 0.006965227657838113
[Epoch 16, Batch 600] loss: 0.0076530712059457075
[Epoch 16, Batch 700] loss: 0.01058470282072676
[Epoch 16, Batch 800] loss: 0.014180928045643668
[Epoch 16, Batch 900] loss: 0.009877470988261621
[Epoch 16, Batch 1000] loss: 0.0078024885159675254
[Epoch 16, Batch 1100] loss: 0.019054528206690974
[Epoch 16, Batch 1200] loss: 0.016324310900772618
[Epoch 16, Batch 1300] loss: 0.01261596288288274
[Epoch 16, Batch 1400] loss: 0.011061735896637401
[Epoch 16, Batch 1500] loss: 0.010005139824884282
[Epoch 16, Batch 1600] loss: 0.005738940569792703
[Epoch 16, Batch 1700] loss: 0.007251409419243373
[Epoch 16, Batch 1800] loss: 0.01029416379840768
**STATS for Epoch 16** : 
Average training loss: 0.0004
Average validation loss: 0.0606
Validation Accuracy: 0.9840
Overfitting: 0.0602
[Epoch 17, Batch 100] loss: 0.006314286861904748
[Epoch 17, Batch 200] loss: 0.0055203860548647295
[Epoch 17, Batch 300] loss: 0.012891106300636467
[Epoch 17, Batch 400] loss: 0.007033552992688783
[Epoch 17, Batch 500] loss: 0.003438256723434279
[Epoch 17, Batch 600] loss: 0.010527827539490317
[Epoch 17, Batch 700] loss: 0.004869937325645423
[Epoch 17, Batch 800] loss: 0.013824076927219266
[Epoch 17, Batch 900] loss: 0.0059208866975268394
[Epoch 17, Batch 1000] loss: 0.006748587095353286
[Epoch 17, Batch 1100] loss: 0.0053183262619268135
[Epoch 17, Batch 1200] loss: 0.004940076009302174
[Epoch 17, Batch 1300] loss: 0.008675062856807471
[Epoch 17, Batch 1400] loss: 0.007404689105638909
[Epoch 17, Batch 1500] loss: 0.007176449870462421
[Epoch 17, Batch 1600] loss: 0.009604846285237728
[Epoch 17, Batch 1700] loss: 0.018412340261688767
[Epoch 17, Batch 1800] loss: 0.012509691521162268
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0581
Validation Accuracy: 0.9855
Overfitting: 0.0577
[Epoch 18, Batch 100] loss: 0.00594132054495276
[Epoch 18, Batch 200] loss: 0.01554161561730325
[Epoch 18, Batch 300] loss: 0.013400739687203895
[Epoch 18, Batch 400] loss: 0.007323396336350925
[Epoch 18, Batch 500] loss: 0.008039675182390056
[Epoch 18, Batch 600] loss: 0.005582045492296857
[Epoch 18, Batch 700] loss: 0.0039039904320998177
[Epoch 18, Batch 800] loss: 0.005294233557929146
[Epoch 18, Batch 900] loss: 0.010601850278683288
[Epoch 18, Batch 1000] loss: 0.009369738169033326
[Epoch 18, Batch 1100] loss: 0.00955042776896903
[Epoch 18, Batch 1200] loss: 0.007259150386971669
[Epoch 18, Batch 1300] loss: 0.0059142318385011095
[Epoch 18, Batch 1400] loss: 0.0038491685420058274
[Epoch 18, Batch 1500] loss: 0.009801734939792368
[Epoch 18, Batch 1600] loss: 0.008549571599887713
[Epoch 18, Batch 1700] loss: 0.006375049462287734
[Epoch 18, Batch 1800] loss: 0.0029156900165872913
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0556
Validation Accuracy: 0.9869
Overfitting: 0.0554
[Epoch 19, Batch 100] loss: 0.004855042985755062
[Epoch 19, Batch 200] loss: 0.0034956924669211275
[Epoch 19, Batch 300] loss: 0.00362227245203826
[Epoch 19, Batch 400] loss: 0.0021456859948921192
[Epoch 19, Batch 500] loss: 0.00427398940051944
[Epoch 19, Batch 600] loss: 0.00287959845414548
[Epoch 19, Batch 700] loss: 0.0018486014530390094
[Epoch 19, Batch 800] loss: 0.0024103444890909032
[Epoch 19, Batch 900] loss: 0.0042842533901284695
[Epoch 19, Batch 1000] loss: 0.002562946775913133
[Epoch 19, Batch 1100] loss: 0.0037695414389182246
[Epoch 19, Batch 1200] loss: 0.007575158685622192
[Epoch 19, Batch 1300] loss: 0.005607339984180726
[Epoch 19, Batch 1400] loss: 0.0052557007818302285
[Epoch 19, Batch 1500] loss: 0.008059012123453613
[Epoch 19, Batch 1600] loss: 0.008857018384562708
[Epoch 19, Batch 1700] loss: 0.014127388358976986
[Epoch 19, Batch 1800] loss: 0.01899276535145873
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0811
Validation Accuracy: 0.9795
Overfitting: 0.0805
[Epoch 20, Batch 100] loss: 0.010288554939822916
[Epoch 20, Batch 200] loss: 0.007501034780798364
[Epoch 20, Batch 300] loss: 0.007605863328482201
[Epoch 20, Batch 400] loss: 0.011931135507250019
[Epoch 20, Batch 500] loss: 0.0064085301815248385
[Epoch 20, Batch 600] loss: 0.00678950391094304
[Epoch 20, Batch 700] loss: 0.008986495493531947
[Epoch 20, Batch 800] loss: 0.008503439071507728
[Epoch 20, Batch 900] loss: 0.004371882758862284
[Epoch 20, Batch 1000] loss: 0.004741670986015833
[Epoch 20, Batch 1100] loss: 0.0027276819475991945
[Epoch 20, Batch 1200] loss: 0.004222568561601747
[Epoch 20, Batch 1300] loss: 0.0020543255816494366
[Epoch 20, Batch 1400] loss: 0.003636043086704035
[Epoch 20, Batch 1500] loss: 0.003120925528917837
[Epoch 20, Batch 1600] loss: 0.003039319283723785
[Epoch 20, Batch 1700] loss: 0.007232756837653369
[Epoch 20, Batch 1800] loss: 0.007077849688103015
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0595
Validation Accuracy: 0.9862
Overfitting: 0.0592
[Epoch 21, Batch 100] loss: 0.001932783968709373
[Epoch 21, Batch 200] loss: 0.004466569874318793
[Epoch 21, Batch 300] loss: 0.0039823416209515015
[Epoch 21, Batch 400] loss: 0.011731770931604615
[Epoch 21, Batch 500] loss: 0.010386730068955786
[Epoch 21, Batch 600] loss: 0.005179783599185441
[Epoch 21, Batch 700] loss: 0.0028037646972802577
[Epoch 21, Batch 800] loss: 0.01832630361415795
[Epoch 21, Batch 900] loss: 0.003677908214162926
[Epoch 21, Batch 1000] loss: 0.008723627544731017
[Epoch 21, Batch 1100] loss: 0.005154759526496946
[Epoch 21, Batch 1200] loss: 0.0048464011358299785
[Epoch 21, Batch 1300] loss: 0.004474428442671296
[Epoch 21, Batch 1400] loss: 0.006146241012637006
[Epoch 21, Batch 1500] loss: 0.0055592410232043225
[Epoch 21, Batch 1600] loss: 0.005713209019852457
[Epoch 21, Batch 1700] loss: 0.009196113321947337
[Epoch 21, Batch 1800] loss: 0.005676759099437163
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0576
Validation Accuracy: 0.9871
Overfitting: 0.0575
[Epoch 22, Batch 100] loss: 0.00532155824322956
[Epoch 22, Batch 200] loss: 0.002035416181665255
[Epoch 22, Batch 300] loss: 0.002588133905117047
[Epoch 22, Batch 400] loss: 0.002186891609267718
[Epoch 22, Batch 500] loss: 0.006546245142651301
[Epoch 22, Batch 600] loss: 0.0016892425061166706
[Epoch 22, Batch 700] loss: 0.0017011832009029603
[Epoch 22, Batch 800] loss: 0.0025460159488329736
[Epoch 22, Batch 900] loss: 0.0027286174610960503
[Epoch 22, Batch 1000] loss: 0.002237398728213691
[Epoch 22, Batch 1100] loss: 0.002938769655986988
[Epoch 22, Batch 1200] loss: 0.005202603587111412
[Epoch 22, Batch 1300] loss: 0.0013582043226709572
[Epoch 22, Batch 1400] loss: 0.004246222861269757
[Epoch 22, Batch 1500] loss: 0.004418894345860167
[Epoch 22, Batch 1600] loss: 0.0035014878581006315
[Epoch 22, Batch 1700] loss: 0.0071776798126308
[Epoch 22, Batch 1800] loss: 0.003648055245010937
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0604
Validation Accuracy: 0.9859
Overfitting: 0.0601
[Epoch 23, Batch 100] loss: 0.008740401457015387
[Epoch 23, Batch 200] loss: 0.0021954567367856725
[Epoch 23, Batch 300] loss: 0.002762504133177117
[Epoch 23, Batch 400] loss: 0.004010831549405794
[Epoch 23, Batch 500] loss: 0.0020760620011782294
[Epoch 23, Batch 600] loss: 0.0017712371632359236
[Epoch 23, Batch 700] loss: 0.0016647849967532124
[Epoch 23, Batch 800] loss: 0.001030462979427398
[Epoch 23, Batch 900] loss: 0.0016716494582829
[Epoch 23, Batch 1000] loss: 0.002977434627052844
[Epoch 23, Batch 1100] loss: 0.003693719906165782
[Epoch 23, Batch 1200] loss: 0.0033150612946113256
[Epoch 23, Batch 1300] loss: 0.00221762924748532
[Epoch 23, Batch 1400] loss: 0.0012700878802795045
[Epoch 23, Batch 1500] loss: 0.0020020130915527545
[Epoch 23, Batch 1600] loss: 0.003553994013134343
[Epoch 23, Batch 1700] loss: 0.004773798764392723
[Epoch 23, Batch 1800] loss: 0.0024020155114519073
**STATS for Epoch 23** : 
Average training loss: 0.0003
Average validation loss: 0.0600
Validation Accuracy: 0.9872
Overfitting: 0.0597
[Epoch 24, Batch 100] loss: 0.0007760004178564373
[Epoch 24, Batch 200] loss: 0.0023616603036628447
[Epoch 24, Batch 300] loss: 0.0008127620197586794
[Epoch 24, Batch 400] loss: 0.0009784859769993658
[Epoch 24, Batch 500] loss: 0.0012149028780572735
[Epoch 24, Batch 600] loss: 0.006457113279307123
[Epoch 24, Batch 700] loss: 0.0020658663672463717
[Epoch 24, Batch 800] loss: 0.0010223726402449529
[Epoch 24, Batch 900] loss: 0.0010056238070691138
[Epoch 24, Batch 1000] loss: 0.0023097027429201944
[Epoch 24, Batch 1100] loss: 0.0006306452411666896
[Epoch 24, Batch 1200] loss: 0.0017407235670172838
[Epoch 24, Batch 1300] loss: 0.0011980640291562672
[Epoch 24, Batch 1400] loss: 0.0018896164454824138
[Epoch 24, Batch 1500] loss: 0.0034687891219746803
[Epoch 24, Batch 1600] loss: 0.0012425584322318173
[Epoch 24, Batch 1700] loss: 0.001993094121884269
[Epoch 24, Batch 1800] loss: 0.0009408451610772062
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0624
Validation Accuracy: 0.9867
Overfitting: 0.0622
Fold 1 validation loss: 0.0624
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.2946601128578186
[Epoch 1, Batch 200] loss: 2.253233096599579
[Epoch 1, Batch 300] loss: 2.0840552711486815
[Epoch 1, Batch 400] loss: 1.2563551837205886
[Epoch 1, Batch 500] loss: 0.667304250150919
[Epoch 1, Batch 600] loss: 0.5205349586904049
[Epoch 1, Batch 700] loss: 0.43655249357223513
[Epoch 1, Batch 800] loss: 0.3785569304227829
[Epoch 1, Batch 900] loss: 0.37593169659376147
[Epoch 1, Batch 1000] loss: 0.3234003683924675
[Epoch 1, Batch 1100] loss: 0.2650714017264545
[Epoch 1, Batch 1200] loss: 0.28067342400550843
[Epoch 1, Batch 1300] loss: 0.25053679013624786
[Epoch 1, Batch 1400] loss: 0.20768926959484815
[Epoch 1, Batch 1500] loss: 0.1931440632045269
[Epoch 1, Batch 1600] loss: 0.22018753909505903
[Epoch 1, Batch 1700] loss: 0.16567218746989965
[Epoch 1, Batch 1800] loss: 0.18493565115146338
**STATS for Epoch 1** : 
Average training loss: 0.0090
Average validation loss: 0.1854
Validation Accuracy: 0.9444
Overfitting: 0.1764
Best model saved at epoch 1 with validation loss: 0.1854
[Epoch 2, Batch 100] loss: 0.17478376744315027
[Epoch 2, Batch 200] loss: 0.15214390257373453
[Epoch 2, Batch 300] loss: 0.1597066073771566
[Epoch 2, Batch 400] loss: 0.14235622166190295
[Epoch 2, Batch 500] loss: 0.1548277561366558
[Epoch 2, Batch 600] loss: 0.14797628513537348
[Epoch 2, Batch 700] loss: 0.13143516183830797
[Epoch 2, Batch 800] loss: 0.1286858246102929
[Epoch 2, Batch 900] loss: 0.1369161381199956
[Epoch 2, Batch 1000] loss: 0.13976727231172845
[Epoch 2, Batch 1100] loss: 0.14456807408016176
[Epoch 2, Batch 1200] loss: 0.13202609036583454
[Epoch 2, Batch 1300] loss: 0.09993447364773601
[Epoch 2, Batch 1400] loss: 0.11218934364384041
[Epoch 2, Batch 1500] loss: 0.14013124343939126
[Epoch 2, Batch 1600] loss: 0.10869014852214605
[Epoch 2, Batch 1700] loss: 0.10523718450218439
[Epoch 2, Batch 1800] loss: 0.12518469701521098
**STATS for Epoch 2** : 
Average training loss: 0.0048
Average validation loss: 0.1055
Validation Accuracy: 0.9663
Overfitting: 0.1007
Best model saved at epoch 2 with validation loss: 0.1055
[Epoch 3, Batch 100] loss: 0.10056299284100532
[Epoch 3, Batch 200] loss: 0.08517599288374185
[Epoch 3, Batch 300] loss: 0.11257288685301318
[Epoch 3, Batch 400] loss: 0.09639372256584465
[Epoch 3, Batch 500] loss: 0.09726897210814059
[Epoch 3, Batch 600] loss: 0.12175506202038378
[Epoch 3, Batch 700] loss: 0.08782869060058146
[Epoch 3, Batch 800] loss: 0.11300510135944933
[Epoch 3, Batch 900] loss: 0.09753736220300198
[Epoch 3, Batch 1000] loss: 0.08527866862947121
[Epoch 3, Batch 1100] loss: 0.09526589565328322
[Epoch 3, Batch 1200] loss: 0.0798718904913403
[Epoch 3, Batch 1300] loss: 0.09091230902355164
[Epoch 3, Batch 1400] loss: 0.06505879738251678
[Epoch 3, Batch 1500] loss: 0.0728850990475621
[Epoch 3, Batch 1600] loss: 0.081995495056035
[Epoch 3, Batch 1700] loss: 0.1037910671334248
[Epoch 3, Batch 1800] loss: 0.0708508940343745
**STATS for Epoch 3** : 
Average training loss: 0.0029
Average validation loss: 0.0981
Validation Accuracy: 0.9699
Overfitting: 0.0953
Best model saved at epoch 3 with validation loss: 0.0981
[Epoch 4, Batch 100] loss: 0.06625994038768113
[Epoch 4, Batch 200] loss: 0.06536093407310545
[Epoch 4, Batch 300] loss: 0.08286688674474135
[Epoch 4, Batch 400] loss: 0.061267600712599235
[Epoch 4, Batch 500] loss: 0.06766785851912573
[Epoch 4, Batch 600] loss: 0.08519722003489733
[Epoch 4, Batch 700] loss: 0.07042552972212433
[Epoch 4, Batch 800] loss: 0.08452350820414722
[Epoch 4, Batch 900] loss: 0.07148846064228565
[Epoch 4, Batch 1000] loss: 0.06432695777184563
[Epoch 4, Batch 1100] loss: 0.07190708784968593
[Epoch 4, Batch 1200] loss: 0.06446360540459864
[Epoch 4, Batch 1300] loss: 0.09823286614264362
[Epoch 4, Batch 1400] loss: 0.06071735748904757
[Epoch 4, Batch 1500] loss: 0.059683172648656184
[Epoch 4, Batch 1600] loss: 0.053014638106687925
[Epoch 4, Batch 1700] loss: 0.06481135399080813
[Epoch 4, Batch 1800] loss: 0.0769643269071821
**STATS for Epoch 4** : 
Average training loss: 0.0026
Average validation loss: 0.0763
Validation Accuracy: 0.9778
Overfitting: 0.0737
Best model saved at epoch 4 with validation loss: 0.0763
[Epoch 5, Batch 100] loss: 0.053484133928432126
[Epoch 5, Batch 200] loss: 0.06522431786579545
[Epoch 5, Batch 300] loss: 0.046152390790230126
[Epoch 5, Batch 400] loss: 0.04972026828501839
[Epoch 5, Batch 500] loss: 0.047893758115242234
[Epoch 5, Batch 600] loss: 0.06973521049774717
[Epoch 5, Batch 700] loss: 0.05380075488501461
[Epoch 5, Batch 800] loss: 0.05331587891152594
[Epoch 5, Batch 900] loss: 0.050110389125766236
[Epoch 5, Batch 1000] loss: 0.06397203766275197
[Epoch 5, Batch 1100] loss: 0.05655935210408643
[Epoch 5, Batch 1200] loss: 0.05039737390325172
[Epoch 5, Batch 1300] loss: 0.055625753687345424
[Epoch 5, Batch 1400] loss: 0.06625085211591795
[Epoch 5, Batch 1500] loss: 0.06936175275535789
[Epoch 5, Batch 1600] loss: 0.08268378117587417
[Epoch 5, Batch 1700] loss: 0.05678169984021224
[Epoch 5, Batch 1800] loss: 0.0478974952979479
**STATS for Epoch 5** : 
Average training loss: 0.0025
Average validation loss: 0.0631
Validation Accuracy: 0.9812
Overfitting: 0.0606
Best model saved at epoch 5 with validation loss: 0.0631
[Epoch 6, Batch 100] loss: 0.06779183186183219
[Epoch 6, Batch 200] loss: 0.03579505858011544
[Epoch 6, Batch 300] loss: 0.03018886878795456
[Epoch 6, Batch 400] loss: 0.05083781502267812
[Epoch 6, Batch 500] loss: 0.04935537099925568
[Epoch 6, Batch 600] loss: 0.039754805358243175
[Epoch 6, Batch 700] loss: 0.05844937572604977
[Epoch 6, Batch 800] loss: 0.03981961820594734
[Epoch 6, Batch 900] loss: 0.06253277033130872
[Epoch 6, Batch 1000] loss: 0.08317990134528372
[Epoch 6, Batch 1100] loss: 0.03161548968986608
[Epoch 6, Batch 1200] loss: 0.04180454417015426
[Epoch 6, Batch 1300] loss: 0.04527411982679041
[Epoch 6, Batch 1400] loss: 0.055260602649650534
[Epoch 6, Batch 1500] loss: 0.04692657348001376
[Epoch 6, Batch 1600] loss: 0.05591153653280344
[Epoch 6, Batch 1700] loss: 0.048614325782400554
[Epoch 6, Batch 1800] loss: 0.04876497747201938
**STATS for Epoch 6** : 
Average training loss: 0.0014
Average validation loss: 0.0598
Validation Accuracy: 0.9821
Overfitting: 0.0583
Best model saved at epoch 6 with validation loss: 0.0598
[Epoch 7, Batch 100] loss: 0.03121303693682421
[Epoch 7, Batch 200] loss: 0.03239554581363336
[Epoch 7, Batch 300] loss: 0.038060324137622954
[Epoch 7, Batch 400] loss: 0.03734460810519522
[Epoch 7, Batch 500] loss: 0.0452342266307096
[Epoch 7, Batch 600] loss: 0.030861998461186885
[Epoch 7, Batch 700] loss: 0.04893117991305189
[Epoch 7, Batch 800] loss: 0.03773952267656568
[Epoch 7, Batch 900] loss: 0.03366743406601017
[Epoch 7, Batch 1000] loss: 0.048588949573750144
[Epoch 7, Batch 1100] loss: 0.05710127058293438
[Epoch 7, Batch 1200] loss: 0.04180923916079337
[Epoch 7, Batch 1300] loss: 0.04567182065482484
[Epoch 7, Batch 1400] loss: 0.029980161956045775
[Epoch 7, Batch 1500] loss: 0.04539213157899212
[Epoch 7, Batch 1600] loss: 0.059601417300582396
[Epoch 7, Batch 1700] loss: 0.038192341516842136
[Epoch 7, Batch 1800] loss: 0.04822854319194448
**STATS for Epoch 7** : 
Average training loss: 0.0014
Average validation loss: 0.0621
Validation Accuracy: 0.9807
Overfitting: 0.0607
[Epoch 8, Batch 100] loss: 0.027229709703824483
[Epoch 8, Batch 200] loss: 0.0403379922498425
[Epoch 8, Batch 300] loss: 0.02932871830140357
[Epoch 8, Batch 400] loss: 0.04327626120561035
[Epoch 8, Batch 500] loss: 0.031509765856171726
[Epoch 8, Batch 600] loss: 0.029966186702658888
[Epoch 8, Batch 700] loss: 0.04103415451489127
[Epoch 8, Batch 800] loss: 0.036833141202369
[Epoch 8, Batch 900] loss: 0.035024547668435844
[Epoch 8, Batch 1000] loss: 0.029126238664466654
[Epoch 8, Batch 1100] loss: 0.025303839216212508
[Epoch 8, Batch 1200] loss: 0.03755519104510313
[Epoch 8, Batch 1300] loss: 0.05214097979478538
[Epoch 8, Batch 1400] loss: 0.02400632335811679
[Epoch 8, Batch 1500] loss: 0.03059398037228675
[Epoch 8, Batch 1600] loss: 0.05014187694636348
[Epoch 8, Batch 1700] loss: 0.029171344674323335
[Epoch 8, Batch 1800] loss: 0.03525064769390156
**STATS for Epoch 8** : 
Average training loss: 0.0021
Average validation loss: 0.0720
Validation Accuracy: 0.9785
Overfitting: 0.0699
[Epoch 9, Batch 100] loss: 0.03195358453405788
[Epoch 9, Batch 200] loss: 0.03722430518879264
[Epoch 9, Batch 300] loss: 0.024689265867491487
[Epoch 9, Batch 400] loss: 0.029486757701088207
[Epoch 9, Batch 500] loss: 0.022088016801862977
[Epoch 9, Batch 600] loss: 0.030917263273440767
[Epoch 9, Batch 700] loss: 0.02912077508022776
[Epoch 9, Batch 800] loss: 0.014543438961882203
[Epoch 9, Batch 900] loss: 0.01798942492907372
[Epoch 9, Batch 1000] loss: 0.03284382947182166
[Epoch 9, Batch 1100] loss: 0.03869044536822912
[Epoch 9, Batch 1200] loss: 0.033906418524420584
[Epoch 9, Batch 1300] loss: 0.028852093867171788
[Epoch 9, Batch 1400] loss: 0.03954074746841798
[Epoch 9, Batch 1500] loss: 0.024498995042813478
[Epoch 9, Batch 1600] loss: 0.03956046485367551
[Epoch 9, Batch 1700] loss: 0.02909838620282244
[Epoch 9, Batch 1800] loss: 0.04191915191098815
**STATS for Epoch 9** : 
Average training loss: 0.0009
Average validation loss: 0.0590
Validation Accuracy: 0.9826
Overfitting: 0.0581
Best model saved at epoch 9 with validation loss: 0.0590
[Epoch 10, Batch 100] loss: 0.017018750633360467
[Epoch 10, Batch 200] loss: 0.03322164015247836
[Epoch 10, Batch 300] loss: 0.02444634082425182
[Epoch 10, Batch 400] loss: 0.036581096047448226
[Epoch 10, Batch 500] loss: 0.013910305691097165
[Epoch 10, Batch 600] loss: 0.027708907689739135
[Epoch 10, Batch 700] loss: 0.020400172629670123
[Epoch 10, Batch 800] loss: 0.017950226796456262
[Epoch 10, Batch 900] loss: 0.02430186476172821
[Epoch 10, Batch 1000] loss: 0.028182755188099692
[Epoch 10, Batch 1100] loss: 0.03591235315883751
[Epoch 10, Batch 1200] loss: 0.022680591624448423
[Epoch 10, Batch 1300] loss: 0.04005097121073049
[Epoch 10, Batch 1400] loss: 0.02966227893186442
[Epoch 10, Batch 1500] loss: 0.01990828880767367
[Epoch 10, Batch 1600] loss: 0.040559360343031585
[Epoch 10, Batch 1700] loss: 0.01705851059337874
[Epoch 10, Batch 1800] loss: 0.024268332476494833
**STATS for Epoch 10** : 
Average training loss: 0.0012
Average validation loss: 0.0562
Validation Accuracy: 0.9832
Overfitting: 0.0550
Best model saved at epoch 10 with validation loss: 0.0562
[Epoch 11, Batch 100] loss: 0.01640986301965313
[Epoch 11, Batch 200] loss: 0.022602146318076846
[Epoch 11, Batch 300] loss: 0.02063837255031103
[Epoch 11, Batch 400] loss: 0.009408775717893149
[Epoch 11, Batch 500] loss: 0.03573231475329521
[Epoch 11, Batch 600] loss: 0.026219083374271576
[Epoch 11, Batch 700] loss: 0.017912962000482365
[Epoch 11, Batch 800] loss: 0.03174906168314919
[Epoch 11, Batch 900] loss: 0.017139801569646805
[Epoch 11, Batch 1000] loss: 0.019955347453797
[Epoch 11, Batch 1100] loss: 0.028191095374058932
[Epoch 11, Batch 1200] loss: 0.024711885262186116
[Epoch 11, Batch 1300] loss: 0.03221321527202235
[Epoch 11, Batch 1400] loss: 0.028859146992435854
[Epoch 11, Batch 1500] loss: 0.024796654182573548
[Epoch 11, Batch 1600] loss: 0.014294624747453782
[Epoch 11, Batch 1700] loss: 0.0405919483902835
[Epoch 11, Batch 1800] loss: 0.027271706131432438
**STATS for Epoch 11** : 
Average training loss: 0.0014
Average validation loss: 0.0565
Validation Accuracy: 0.9834
Overfitting: 0.0551
[Epoch 12, Batch 100] loss: 0.019964849181742465
[Epoch 12, Batch 200] loss: 0.015612861443732981
[Epoch 12, Batch 300] loss: 0.012145810857546166
[Epoch 12, Batch 400] loss: 0.01247956327506472
[Epoch 12, Batch 500] loss: 0.025792580381912556
[Epoch 12, Batch 600] loss: 0.020435592673857174
[Epoch 12, Batch 700] loss: 0.012308839366742177
[Epoch 12, Batch 800] loss: 0.019897811495211498
[Epoch 12, Batch 900] loss: 0.01788982539430435
[Epoch 12, Batch 1000] loss: 0.02480700646941841
[Epoch 12, Batch 1100] loss: 0.025007333411704167
[Epoch 12, Batch 1200] loss: 0.026411258458865633
[Epoch 12, Batch 1300] loss: 0.02716836298936869
[Epoch 12, Batch 1400] loss: 0.018926733118423727
[Epoch 12, Batch 1500] loss: 0.013352366909066405
[Epoch 12, Batch 1600] loss: 0.02448112090864015
[Epoch 12, Batch 1700] loss: 0.036836400032370875
[Epoch 12, Batch 1800] loss: 0.022787732674478322
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0558
Validation Accuracy: 0.9836
Overfitting: 0.0550
Best model saved at epoch 12 with validation loss: 0.0558
[Epoch 13, Batch 100] loss: 0.028192275677793078
[Epoch 13, Batch 200] loss: 0.01590142614848446
[Epoch 13, Batch 300] loss: 0.00918240858552963
[Epoch 13, Batch 400] loss: 0.013088324229102
[Epoch 13, Batch 500] loss: 0.011346712396680232
[Epoch 13, Batch 600] loss: 0.011665059516635665
[Epoch 13, Batch 700] loss: 0.02148916968735648
[Epoch 13, Batch 800] loss: 0.016740686358389212
[Epoch 13, Batch 900] loss: 0.014171421767205174
[Epoch 13, Batch 1000] loss: 0.02438163379550133
[Epoch 13, Batch 1100] loss: 0.019071888802391187
[Epoch 13, Batch 1200] loss: 0.011577582254822118
[Epoch 13, Batch 1300] loss: 0.022566899059647767
[Epoch 13, Batch 1400] loss: 0.019139730284186952
[Epoch 13, Batch 1500] loss: 0.023948451230608042
[Epoch 13, Batch 1600] loss: 0.027137826725065678
[Epoch 13, Batch 1700] loss: 0.01572458878152247
[Epoch 13, Batch 1800] loss: 0.025023831428061385
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0732
Validation Accuracy: 0.9797
Overfitting: 0.0723
[Epoch 14, Batch 100] loss: 0.010524962112722278
[Epoch 14, Batch 200] loss: 0.009540472768767358
[Epoch 14, Batch 300] loss: 0.014840533965834766
[Epoch 14, Batch 400] loss: 0.025903956976762857
[Epoch 14, Batch 500] loss: 0.012395626699221793
[Epoch 14, Batch 600] loss: 0.016042656157924284
[Epoch 14, Batch 700] loss: 0.011143751696363325
[Epoch 14, Batch 800] loss: 0.01648204631950648
[Epoch 14, Batch 900] loss: 0.020816314126677754
[Epoch 14, Batch 1000] loss: 0.007834466494514344
[Epoch 14, Batch 1100] loss: 0.014986470430558256
[Epoch 14, Batch 1200] loss: 0.019636030732744985
[Epoch 14, Batch 1300] loss: 0.020001839832730184
[Epoch 14, Batch 1400] loss: 0.023086073076210595
[Epoch 14, Batch 1500] loss: 0.020151380506067653
[Epoch 14, Batch 1600] loss: 0.02932695876224898
[Epoch 14, Batch 1700] loss: 0.01740336756207398
[Epoch 14, Batch 1800] loss: 0.027741692028666876
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0546
Validation Accuracy: 0.9851
Overfitting: 0.0541
Best model saved at epoch 14 with validation loss: 0.0546
[Epoch 15, Batch 100] loss: 0.008868938534706104
[Epoch 15, Batch 200] loss: 0.0218281887308558
[Epoch 15, Batch 300] loss: 0.018258001783660802
[Epoch 15, Batch 400] loss: 0.01255569552155066
[Epoch 15, Batch 500] loss: 0.02003598977231377
[Epoch 15, Batch 600] loss: 0.008205515114987065
[Epoch 15, Batch 700] loss: 0.00909767567027302
[Epoch 15, Batch 800] loss: 0.006704982766259491
[Epoch 15, Batch 900] loss: 0.016340145914909954
[Epoch 15, Batch 1000] loss: 0.010064605091606608
[Epoch 15, Batch 1100] loss: 0.015861814514246363
[Epoch 15, Batch 1200] loss: 0.011779840634826542
[Epoch 15, Batch 1300] loss: 0.01169117199762468
[Epoch 15, Batch 1400] loss: 0.01917136825344869
[Epoch 15, Batch 1500] loss: 0.016312212778721004
[Epoch 15, Batch 1600] loss: 0.01510692817716972
[Epoch 15, Batch 1700] loss: 0.021111717591802515
[Epoch 15, Batch 1800] loss: 0.011413917904947083
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0582
Validation Accuracy: 0.9843
Overfitting: 0.0575
[Epoch 16, Batch 100] loss: 0.010085910726211296
[Epoch 16, Batch 200] loss: 0.013802453820271694
[Epoch 16, Batch 300] loss: 0.0140189600728786
[Epoch 16, Batch 400] loss: 0.0054702336702666795
[Epoch 16, Batch 500] loss: 0.02303865733186285
[Epoch 16, Batch 600] loss: 0.009572431088599842
[Epoch 16, Batch 700] loss: 0.01579993522123914
[Epoch 16, Batch 800] loss: 0.011055024351276189
[Epoch 16, Batch 900] loss: 0.008238846387466765
[Epoch 16, Batch 1000] loss: 0.008740012350740472
[Epoch 16, Batch 1100] loss: 0.01403750052815667
[Epoch 16, Batch 1200] loss: 0.01564603196889948
[Epoch 16, Batch 1300] loss: 0.008675444263762983
[Epoch 16, Batch 1400] loss: 0.008385993880583555
[Epoch 16, Batch 1500] loss: 0.014980049241985397
[Epoch 16, Batch 1600] loss: 0.01263727546454902
[Epoch 16, Batch 1700] loss: 0.005181045696585898
[Epoch 16, Batch 1800] loss: 0.01902208677732233
**STATS for Epoch 16** : 
Average training loss: 0.0008
Average validation loss: 0.0598
Validation Accuracy: 0.9844
Overfitting: 0.0590
[Epoch 17, Batch 100] loss: 0.005354071951296646
[Epoch 17, Batch 200] loss: 0.009069534689459716
[Epoch 17, Batch 300] loss: 0.012337450513477961
[Epoch 17, Batch 400] loss: 0.009865011801280162
[Epoch 17, Batch 500] loss: 0.007610742551196381
[Epoch 17, Batch 600] loss: 0.013368508727189692
[Epoch 17, Batch 700] loss: 0.007442904000888575
[Epoch 17, Batch 800] loss: 0.0065714973917852144
[Epoch 17, Batch 900] loss: 0.004778431701524823
[Epoch 17, Batch 1000] loss: 0.004940188282230338
[Epoch 17, Batch 1100] loss: 0.006605233907694128
[Epoch 17, Batch 1200] loss: 0.005771967050363856
[Epoch 17, Batch 1300] loss: 0.01203503357716727
[Epoch 17, Batch 1400] loss: 0.010831665851187609
[Epoch 17, Batch 1500] loss: 0.014719728766376648
[Epoch 17, Batch 1600] loss: 0.009954006556276908
[Epoch 17, Batch 1700] loss: 0.01675090675613319
[Epoch 17, Batch 1800] loss: 0.018834403876812757
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0594
Validation Accuracy: 0.9837
Overfitting: 0.0587
[Epoch 18, Batch 100] loss: 0.009081583794104517
[Epoch 18, Batch 200] loss: 0.007024736828343521
[Epoch 18, Batch 300] loss: 0.005854919158232406
[Epoch 18, Batch 400] loss: 0.007826646966704516
[Epoch 18, Batch 500] loss: 0.003444638949831642
[Epoch 18, Batch 600] loss: 0.008518765194285152
[Epoch 18, Batch 700] loss: 0.015317759934023343
[Epoch 18, Batch 800] loss: 0.014958625909548573
[Epoch 18, Batch 900] loss: 0.014625656204452752
[Epoch 18, Batch 1000] loss: 0.006965822714628303
[Epoch 18, Batch 1100] loss: 0.008819257957720766
[Epoch 18, Batch 1200] loss: 0.011378588525358281
[Epoch 18, Batch 1300] loss: 0.005995124894075161
[Epoch 18, Batch 1400] loss: 0.011098694437207542
[Epoch 18, Batch 1500] loss: 0.011090970863958773
[Epoch 18, Batch 1600] loss: 0.008220425210565737
[Epoch 18, Batch 1700] loss: 0.008878173371253979
[Epoch 18, Batch 1800] loss: 0.0064918897015286345
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0648
Validation Accuracy: 0.9838
Overfitting: 0.0645
[Epoch 19, Batch 100] loss: 0.004938917931728781
[Epoch 19, Batch 200] loss: 0.008173586387936211
[Epoch 19, Batch 300] loss: 0.003661948952030798
[Epoch 19, Batch 400] loss: 0.009892041741040884
[Epoch 19, Batch 500] loss: 0.012912759836485748
[Epoch 19, Batch 600] loss: 0.006982273380459674
[Epoch 19, Batch 700] loss: 0.0066591327356053396
[Epoch 19, Batch 800] loss: 0.010821555904549172
[Epoch 19, Batch 900] loss: 0.005612999086697528
[Epoch 19, Batch 1000] loss: 0.004567363154101258
[Epoch 19, Batch 1100] loss: 0.004685228774885104
[Epoch 19, Batch 1200] loss: 0.004904948661142043
[Epoch 19, Batch 1300] loss: 0.015568731115076844
[Epoch 19, Batch 1400] loss: 0.00677048026335342
[Epoch 19, Batch 1500] loss: 0.009539879131059479
[Epoch 19, Batch 1600] loss: 0.003468213700190859
[Epoch 19, Batch 1700] loss: 0.0071888905297100795
[Epoch 19, Batch 1800] loss: 0.006628640674935013
**STATS for Epoch 19** : 
Average training loss: 0.0007
Average validation loss: 0.0643
Validation Accuracy: 0.9847
Overfitting: 0.0636
[Epoch 20, Batch 100] loss: 0.007217782799507404
[Epoch 20, Batch 200] loss: 0.00609675066619161
[Epoch 20, Batch 300] loss: 0.004516412951224993
[Epoch 20, Batch 400] loss: 0.004009622490900711
[Epoch 20, Batch 500] loss: 0.0029849446734021966
[Epoch 20, Batch 600] loss: 0.010174430050442424
[Epoch 20, Batch 700] loss: 0.003236770259845798
[Epoch 20, Batch 800] loss: 0.002093772852736038
[Epoch 20, Batch 900] loss: 0.00604998910603399
[Epoch 20, Batch 1000] loss: 0.0059650545611759755
[Epoch 20, Batch 1100] loss: 0.004162868068849548
[Epoch 20, Batch 1200] loss: 0.017491506775427296
[Epoch 20, Batch 1300] loss: 0.012690933613866947
[Epoch 20, Batch 1400] loss: 0.006365148707981803
[Epoch 20, Batch 1500] loss: 0.004522819896691317
[Epoch 20, Batch 1600] loss: 0.010752006980337682
[Epoch 20, Batch 1700] loss: 0.004772470883842743
[Epoch 20, Batch 1800] loss: 0.012230743767604508
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0610
Validation Accuracy: 0.9854
Overfitting: 0.0608
[Epoch 21, Batch 100] loss: 0.0036984488436837635
[Epoch 21, Batch 200] loss: 0.00596565099684426
[Epoch 21, Batch 300] loss: 0.006524757487648003
[Epoch 21, Batch 400] loss: 0.004316013255415783
[Epoch 21, Batch 500] loss: 0.0061981774326318375
[Epoch 21, Batch 600] loss: 0.004389318897004842
[Epoch 21, Batch 700] loss: 0.005848035817439268
[Epoch 21, Batch 800] loss: 0.0038914095135970683
[Epoch 21, Batch 900] loss: 0.004011554102552281
[Epoch 21, Batch 1000] loss: 0.006997220018242842
[Epoch 21, Batch 1100] loss: 0.006732575574480961
[Epoch 21, Batch 1200] loss: 0.00457969057744549
[Epoch 21, Batch 1300] loss: 0.0021602319222415647
[Epoch 21, Batch 1400] loss: 0.005140244966968339
[Epoch 21, Batch 1500] loss: 0.01044149639538432
[Epoch 21, Batch 1600] loss: 0.008035503025063236
[Epoch 21, Batch 1700] loss: 0.0027604293612590427
[Epoch 21, Batch 1800] loss: 0.0023323326895018683
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0590
Validation Accuracy: 0.9862
Overfitting: 0.0589
[Epoch 22, Batch 100] loss: 0.005150193849471521
[Epoch 22, Batch 200] loss: 0.0018188906789794147
[Epoch 22, Batch 300] loss: 0.002172358753346657
[Epoch 22, Batch 400] loss: 0.0026673580489455164
[Epoch 22, Batch 500] loss: 0.0012423808263991986
[Epoch 22, Batch 600] loss: 0.001964103768106611
[Epoch 22, Batch 700] loss: 0.0035047848452359177
[Epoch 22, Batch 800] loss: 0.004990746855947634
[Epoch 22, Batch 900] loss: 0.004016086456360881
[Epoch 22, Batch 1000] loss: 0.00693680012423556
[Epoch 22, Batch 1100] loss: 0.006137338845800287
[Epoch 22, Batch 1200] loss: 0.008353779690150987
[Epoch 22, Batch 1300] loss: 0.007726267335087868
[Epoch 22, Batch 1400] loss: 0.008409650466142012
[Epoch 22, Batch 1500] loss: 0.006664337230733963
[Epoch 22, Batch 1600] loss: 0.004875865141107152
[Epoch 22, Batch 1700] loss: 0.004762901698057646
[Epoch 22, Batch 1800] loss: 0.00448837263082396
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0597
Validation Accuracy: 0.9865
Overfitting: 0.0596
[Epoch 23, Batch 100] loss: 0.004259480722991782
[Epoch 23, Batch 200] loss: 0.0027691861358130152
[Epoch 23, Batch 300] loss: 0.0023052805248050846
[Epoch 23, Batch 400] loss: 0.0030070063643177036
[Epoch 23, Batch 500] loss: 0.00171465544872774
[Epoch 23, Batch 600] loss: 0.0022513116209128725
[Epoch 23, Batch 700] loss: 0.00328533554441492
[Epoch 23, Batch 800] loss: 0.004079907056386674
[Epoch 23, Batch 900] loss: 0.009204589174493094
[Epoch 23, Batch 1000] loss: 0.002185777225084848
[Epoch 23, Batch 1100] loss: 0.0035954726568280648
[Epoch 23, Batch 1200] loss: 0.0015069469616901187
[Epoch 23, Batch 1300] loss: 0.004499181637301888
[Epoch 23, Batch 1400] loss: 0.0035632638612275967
[Epoch 23, Batch 1500] loss: 0.003648379808381601
[Epoch 23, Batch 1600] loss: 0.001452978541726111
[Epoch 23, Batch 1700] loss: 0.003179093377639788
[Epoch 23, Batch 1800] loss: 0.0015661047233777481
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0602
Validation Accuracy: 0.9870
Overfitting: 0.0602
[Epoch 24, Batch 100] loss: 0.006721691740328879
[Epoch 24, Batch 200] loss: 0.0072224015924872735
[Epoch 24, Batch 300] loss: 0.002670765323747375
[Epoch 24, Batch 400] loss: 0.0019761840807518637
[Epoch 24, Batch 500] loss: 0.0026537292957560864
[Epoch 24, Batch 600] loss: 0.0021069905085990114
[Epoch 24, Batch 700] loss: 0.0022314257619851217
[Epoch 24, Batch 800] loss: 0.0021980743118899682
[Epoch 24, Batch 900] loss: 0.004098120909424381
[Epoch 24, Batch 1000] loss: 0.003438861382090579
[Epoch 24, Batch 1100] loss: 0.0031569205464575135
[Epoch 24, Batch 1200] loss: 0.0021850701521447034
[Epoch 24, Batch 1300] loss: 0.003989151847183585
[Epoch 24, Batch 1400] loss: 0.002795098598750592
[Epoch 24, Batch 1500] loss: 0.0022922817183550137
[Epoch 24, Batch 1600] loss: 0.004096883285575075
[Epoch 24, Batch 1700] loss: 0.004918449146660464
[Epoch 24, Batch 1800] loss: 0.004409945347723863
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0628
Validation Accuracy: 0.9858
Overfitting: 0.0627
Fold 2 validation loss: 0.0628
Mean validation loss across all folds for Trial 21 is 0.0626 with trial config:  l1: 160, l2: 160, lr: 0.000997693382448528, batch_size: 16
[I 2024-11-19 02:51:36,647] Trial 20 finished with value: 0.06259184460012111 and parameters: {'l1': 160, 'l2': 160, 'lr': 0.000997693382448528, 'batch_size': 16}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 22:
  l1: 352, l2: 160, lr: 0.011512830624060836, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.3826309019327163
[Epoch 1, Batch 200] loss: 0.31022306237369773
[Epoch 1, Batch 300] loss: 0.21850357339717447
[Epoch 1, Batch 400] loss: 0.16898890749551357
[Epoch 1, Batch 500] loss: 0.14912795224692674
[Epoch 1, Batch 600] loss: 0.11297697104630061
[Epoch 1, Batch 700] loss: 0.11109477791236713
[Epoch 1, Batch 800] loss: 0.10029620651621371
[Epoch 1, Batch 900] loss: 0.10709549247287214
**STATS for Epoch 1** : 
Average training loss: 0.0035
Average validation loss: 0.0801
Validation Accuracy: 0.9751
Overfitting: 0.0765
Best model saved at epoch 1 with validation loss: 0.0801
[Epoch 2, Batch 100] loss: 0.06146703921840526
[Epoch 2, Batch 200] loss: 0.07323645217344164
[Epoch 2, Batch 300] loss: 0.0760169841744937
[Epoch 2, Batch 400] loss: 0.08574887018883601
[Epoch 2, Batch 500] loss: 0.0819278906926047
[Epoch 2, Batch 600] loss: 0.0662927780119935
[Epoch 2, Batch 700] loss: 0.08720606284681708
[Epoch 2, Batch 800] loss: 0.07781033018603921
[Epoch 2, Batch 900] loss: 0.06297106732352403
**STATS for Epoch 2** : 
Average training loss: 0.0029
Average validation loss: 0.0737
Validation Accuracy: 0.9775
Overfitting: 0.0708
Best model saved at epoch 2 with validation loss: 0.0737
[Epoch 3, Batch 100] loss: 0.052059876608254854
[Epoch 3, Batch 200] loss: 0.05667763686156832
[Epoch 3, Batch 300] loss: 0.03875765525328461
[Epoch 3, Batch 400] loss: 0.056031042311224154
[Epoch 3, Batch 500] loss: 0.053925623283721504
[Epoch 3, Batch 600] loss: 0.04028610348032089
[Epoch 3, Batch 700] loss: 0.04844978468681802
[Epoch 3, Batch 800] loss: 0.04564478438522201
[Epoch 3, Batch 900] loss: 0.05598188416479388
**STATS for Epoch 3** : 
Average training loss: 0.0016
Average validation loss: 0.0592
Validation Accuracy: 0.9828
Overfitting: 0.0576
Best model saved at epoch 3 with validation loss: 0.0592
[Epoch 4, Batch 100] loss: 0.02967510938993655
[Epoch 4, Batch 200] loss: 0.036247052718535996
[Epoch 4, Batch 300] loss: 0.023338695248530713
[Epoch 4, Batch 400] loss: 0.029473786609305535
[Epoch 4, Batch 500] loss: 0.04890791936777532
[Epoch 4, Batch 600] loss: 0.04312550289330829
[Epoch 4, Batch 700] loss: 0.03543981278955471
[Epoch 4, Batch 800] loss: 0.032066318395663984
[Epoch 4, Batch 900] loss: 0.029532177002110985
**STATS for Epoch 4** : 
Average training loss: 0.0014
Average validation loss: 0.0629
Validation Accuracy: 0.9829
Overfitting: 0.0614
[Epoch 5, Batch 100] loss: 0.02730281233700225
[Epoch 5, Batch 200] loss: 0.025787187778842053
[Epoch 5, Batch 300] loss: 0.04069727605499793
[Epoch 5, Batch 400] loss: 0.02112962189678001
[Epoch 5, Batch 500] loss: 0.02128280614118921
[Epoch 5, Batch 600] loss: 0.031307791045692285
[Epoch 5, Batch 700] loss: 0.02778750815505191
[Epoch 5, Batch 800] loss: 0.02623522681373288
[Epoch 5, Batch 900] loss: 0.03177767894565477
**STATS for Epoch 5** : 
Average training loss: 0.0014
Average validation loss: 0.0721
Validation Accuracy: 0.9812
Overfitting: 0.0707
[Epoch 6, Batch 100] loss: 0.016083309665937122
[Epoch 6, Batch 200] loss: 0.029777740348763473
[Epoch 6, Batch 300] loss: 0.027591092156144442
[Epoch 6, Batch 400] loss: 0.022290530761674743
[Epoch 6, Batch 500] loss: 0.024201803369069238
[Epoch 6, Batch 600] loss: 0.015779295877218828
[Epoch 6, Batch 700] loss: 0.025119273218770104
[Epoch 6, Batch 800] loss: 0.022016888890357224
[Epoch 6, Batch 900] loss: 0.025019389030312596
**STATS for Epoch 6** : 
Average training loss: 0.0006
Average validation loss: 0.0544
Validation Accuracy: 0.9864
Overfitting: 0.0538
Best model saved at epoch 6 with validation loss: 0.0544
[Epoch 7, Batch 100] loss: 0.014401470771881577
[Epoch 7, Batch 200] loss: 0.01693783982266723
[Epoch 7, Batch 300] loss: 0.011526608917611156
[Epoch 7, Batch 400] loss: 0.018013104692217893
[Epoch 7, Batch 500] loss: 0.030881970196278415
[Epoch 7, Batch 600] loss: 0.021397076705979998
[Epoch 7, Batch 700] loss: 0.01338601023388037
[Epoch 7, Batch 800] loss: 0.014727640156088455
[Epoch 7, Batch 900] loss: 0.020442101317603375
**STATS for Epoch 7** : 
Average training loss: 0.0009
Average validation loss: 0.0672
Validation Accuracy: 0.9830
Overfitting: 0.0664
[Epoch 8, Batch 100] loss: 0.015583807269954376
[Epoch 8, Batch 200] loss: 0.015206844130111676
[Epoch 8, Batch 300] loss: 0.014282159801405214
[Epoch 8, Batch 400] loss: 0.009593338852396301
[Epoch 8, Batch 500] loss: 0.012448687091646206
[Epoch 8, Batch 600] loss: 0.007936464395497752
[Epoch 8, Batch 700] loss: 0.026766226126601397
[Epoch 8, Batch 800] loss: 0.020586157178559005
[Epoch 8, Batch 900] loss: 0.017695639527228194
**STATS for Epoch 8** : 
Average training loss: 0.0003
Average validation loss: 0.0557
Validation Accuracy: 0.9865
Overfitting: 0.0555
[Epoch 9, Batch 100] loss: 0.004518383583390459
[Epoch 9, Batch 200] loss: 0.00608034567406321
[Epoch 9, Batch 300] loss: 0.010733938287082766
[Epoch 9, Batch 400] loss: 0.013719002819148046
[Epoch 9, Batch 500] loss: 0.00837399024878323
[Epoch 9, Batch 600] loss: 0.008836013291513609
[Epoch 9, Batch 700] loss: 0.01759853348305114
[Epoch 9, Batch 800] loss: 0.010761379806776859
[Epoch 9, Batch 900] loss: 0.013481503734319632
**STATS for Epoch 9** : 
Average training loss: 0.0008
Average validation loss: 0.0758
Validation Accuracy: 0.9829
Overfitting: 0.0750
[Epoch 10, Batch 100] loss: 0.018889220586197554
[Epoch 10, Batch 200] loss: 0.018431651092550964
[Epoch 10, Batch 300] loss: 0.013905448256129488
[Epoch 10, Batch 400] loss: 0.010996157509644035
[Epoch 10, Batch 500] loss: 0.013608288813147738
[Epoch 10, Batch 600] loss: 0.013401360242780243
[Epoch 10, Batch 700] loss: 0.024819749379339555
[Epoch 10, Batch 800] loss: 0.015663077543022156
[Epoch 10, Batch 900] loss: 0.008033168765523442
**STATS for Epoch 10** : 
Average training loss: 0.0007
Average validation loss: 0.0802
Validation Accuracy: 0.9819
Overfitting: 0.0795
[Epoch 11, Batch 100] loss: 0.010899073143023089
[Epoch 11, Batch 200] loss: 0.009266953534743152
[Epoch 11, Batch 300] loss: 0.005026482029875296
[Epoch 11, Batch 400] loss: 0.008334834764659717
[Epoch 11, Batch 500] loss: 0.011730746156426903
[Epoch 11, Batch 600] loss: 0.01940326194093359
[Epoch 11, Batch 700] loss: 0.02948775405258857
[Epoch 11, Batch 800] loss: 0.014250904264863494
[Epoch 11, Batch 900] loss: 0.010790077783785818
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0825
Validation Accuracy: 0.9820
Overfitting: 0.0816
[Epoch 12, Batch 100] loss: 0.009448975296802473
[Epoch 12, Batch 200] loss: 0.006516188730511203
[Epoch 12, Batch 300] loss: 0.01090005022816058
[Epoch 12, Batch 400] loss: 0.01530249029025299
[Epoch 12, Batch 500] loss: 0.0037727225576804813
[Epoch 12, Batch 600] loss: 0.012984842303727645
[Epoch 12, Batch 700] loss: 0.00778808737944928
[Epoch 12, Batch 800] loss: 0.018885651685725407
[Epoch 12, Batch 900] loss: 0.024226973906015702
**STATS for Epoch 12** : 
Average training loss: 0.0007
Average validation loss: 0.0757
Validation Accuracy: 0.9837
Overfitting: 0.0750
[Epoch 13, Batch 100] loss: 0.012731189562855435
[Epoch 13, Batch 200] loss: 0.010230705918875174
[Epoch 13, Batch 300] loss: 0.014118357502313756
[Epoch 13, Batch 400] loss: 0.009960971072086978
[Epoch 13, Batch 500] loss: 0.002815932431899455
[Epoch 13, Batch 600] loss: 0.003805221412085302
[Epoch 13, Batch 700] loss: 0.00981397286539277
[Epoch 13, Batch 800] loss: 0.0062072702504951845
[Epoch 13, Batch 900] loss: 0.004746362651950449
**STATS for Epoch 13** : 
Average training loss: 0.0001
Average validation loss: 0.0600
Validation Accuracy: 0.9879
Overfitting: 0.0599
[Epoch 14, Batch 100] loss: 0.011723282714781362
[Epoch 14, Batch 200] loss: 0.0031703292526628958
[Epoch 14, Batch 300] loss: 0.010581017685601636
[Epoch 14, Batch 400] loss: 0.0074095323164465295
[Epoch 14, Batch 500] loss: 0.008503153329561428
[Epoch 14, Batch 600] loss: 0.002506266161693702
[Epoch 14, Batch 700] loss: 0.0018626317248822489
[Epoch 14, Batch 800] loss: 0.0037996465391319134
[Epoch 14, Batch 900] loss: 0.004057809582380401
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0725
Validation Accuracy: 0.9864
Overfitting: 0.0721
[Epoch 15, Batch 100] loss: 0.0012592834973750655
[Epoch 15, Batch 200] loss: 0.002287977334959237
[Epoch 15, Batch 300] loss: 0.002657207065296632
[Epoch 15, Batch 400] loss: 0.002294873809873934
[Epoch 15, Batch 500] loss: 0.004225747151837993
[Epoch 15, Batch 600] loss: 0.0019382851536167323
[Epoch 15, Batch 700] loss: 0.003148311225820066
[Epoch 15, Batch 800] loss: 0.0023420825298527603
[Epoch 15, Batch 900] loss: 0.00220543326001021
**STATS for Epoch 15** : 
Average training loss: 0.0000
Average validation loss: 0.0695
Validation Accuracy: 0.9887
Overfitting: 0.0694
[Epoch 16, Batch 100] loss: 0.0008857544024495212
[Epoch 16, Batch 200] loss: 0.0034172544493384295
[Epoch 16, Batch 300] loss: 0.006698483915295412
[Epoch 16, Batch 400] loss: 0.0032460988929672394
[Epoch 16, Batch 500] loss: 0.007956307129210386
[Epoch 16, Batch 600] loss: 0.004601143712131943
[Epoch 16, Batch 700] loss: 0.007753666980423474
[Epoch 16, Batch 800] loss: 0.010772224502976258
[Epoch 16, Batch 900] loss: 0.014422153516743919
**STATS for Epoch 16** : 
Average training loss: 0.0006
Average validation loss: 0.1020
Validation Accuracy: 0.9827
Overfitting: 0.1014
[Epoch 17, Batch 100] loss: 0.00810297945912552
[Epoch 17, Batch 200] loss: 0.021445093140011976
[Epoch 17, Batch 300] loss: 0.004696177320591914
[Epoch 17, Batch 400] loss: 0.0029309984511024824
[Epoch 17, Batch 500] loss: 0.00724671878172046
[Epoch 17, Batch 600] loss: 0.004103326260134903
[Epoch 17, Batch 700] loss: 0.005609164448505197
[Epoch 17, Batch 800] loss: 0.004074001932658289
[Epoch 17, Batch 900] loss: 0.005397932208757439
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0786
Validation Accuracy: 0.9862
Overfitting: 0.0783
[Epoch 18, Batch 100] loss: 0.0034413049597461056
[Epoch 18, Batch 200] loss: 0.0015067485795986358
[Epoch 18, Batch 300] loss: 0.0014305998713517454
[Epoch 18, Batch 400] loss: 0.000788443093930411
[Epoch 18, Batch 500] loss: 0.0003388920231145676
[Epoch 18, Batch 600] loss: 0.001428032375191961
[Epoch 18, Batch 700] loss: 0.00069604454050463
[Epoch 18, Batch 800] loss: 0.0002723888795605944
[Epoch 18, Batch 900] loss: 0.0015840523472854429
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0693
Validation Accuracy: 0.9880
Overfitting: 0.0692
[Epoch 19, Batch 100] loss: 0.0008116924799598024
[Epoch 19, Batch 200] loss: 0.0005338405065144513
[Epoch 19, Batch 300] loss: 0.0002452166495371166
[Epoch 19, Batch 400] loss: 6.496740186636706e-05
[Epoch 19, Batch 500] loss: 0.00012040312577056511
[Epoch 19, Batch 600] loss: 0.001080972418444972
[Epoch 19, Batch 700] loss: 0.00018072928353191742
[Epoch 19, Batch 800] loss: 0.00013141390069314695
[Epoch 19, Batch 900] loss: 0.00010576792361384868
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0685
Validation Accuracy: 0.9894
Overfitting: 0.0685
[Epoch 20, Batch 100] loss: 8.150600733507928e-05
[Epoch 20, Batch 200] loss: 0.00017091705818181424
[Epoch 20, Batch 300] loss: 7.561017471299891e-05
[Epoch 20, Batch 400] loss: 8.190764663822846e-05
[Epoch 20, Batch 500] loss: 5.650217244400402e-05
[Epoch 20, Batch 600] loss: 0.0004417850102235121
[Epoch 20, Batch 700] loss: 0.00012364503663259808
[Epoch 20, Batch 800] loss: 5.091867513979054e-05
[Epoch 20, Batch 900] loss: 8.342677336883986e-05
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0699
Validation Accuracy: 0.9895
Overfitting: 0.0699
[Epoch 21, Batch 100] loss: 0.00010154770736622965
[Epoch 21, Batch 200] loss: 4.7503957683829865e-05
[Epoch 21, Batch 300] loss: 4.869002102699582e-05
[Epoch 21, Batch 400] loss: 0.0001099601910318615
[Epoch 21, Batch 500] loss: 0.0001677543921612723
[Epoch 21, Batch 600] loss: 6.732677674869513e-05
[Epoch 21, Batch 700] loss: 8.339393970377529e-05
[Epoch 21, Batch 800] loss: 5.433040161612723e-05
[Epoch 21, Batch 900] loss: 3.071002125093258e-05
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0708
Validation Accuracy: 0.9895
Overfitting: 0.0708
[Epoch 22, Batch 100] loss: 3.0032274340832112e-05
[Epoch 22, Batch 200] loss: 4.13604367327336e-05
[Epoch 22, Batch 300] loss: 0.00014672813431077848
[Epoch 22, Batch 400] loss: 3.928750931250002e-05
[Epoch 22, Batch 500] loss: 4.404475584874223e-05
[Epoch 22, Batch 600] loss: 3.935937712409299e-05
[Epoch 22, Batch 700] loss: 3.50444725347776e-05
[Epoch 22, Batch 800] loss: 3.431238443240225e-05
[Epoch 22, Batch 900] loss: 8.483447853478765e-05
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0722
Validation Accuracy: 0.9895
Overfitting: 0.0722
[Epoch 23, Batch 100] loss: 4.636699985523629e-05
[Epoch 23, Batch 200] loss: 3.389594683973263e-05
[Epoch 23, Batch 300] loss: 9.050389246746615e-05
[Epoch 23, Batch 400] loss: 5.554458392859729e-05
[Epoch 23, Batch 500] loss: 3.4009528570879685e-05
[Epoch 23, Batch 600] loss: 4.0293387965268935e-05
[Epoch 23, Batch 700] loss: 2.700419650215835e-05
[Epoch 23, Batch 800] loss: 3.1074541038367266e-05
[Epoch 23, Batch 900] loss: 1.9090446760383627e-05
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0731
Validation Accuracy: 0.9895
Overfitting: 0.0731
[Epoch 24, Batch 100] loss: 6.357749895576026e-05
[Epoch 24, Batch 200] loss: 2.7375979082506775e-05
[Epoch 24, Batch 300] loss: 2.0815413556716233e-05
[Epoch 24, Batch 400] loss: 4.486094119686257e-05
[Epoch 24, Batch 500] loss: 3.193714492450317e-05
[Epoch 24, Batch 600] loss: 3.1595754974316216e-05
[Epoch 24, Batch 700] loss: 2.1920985862569074e-05
[Epoch 24, Batch 800] loss: 4.580025078823713e-05
[Epoch 24, Batch 900] loss: 1.6076383439869167e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0738
Validation Accuracy: 0.9895
Overfitting: 0.0738
Fold 1 validation loss: 0.0738
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.4656080085039138
[Epoch 1, Batch 200] loss: 0.3218857990577817
[Epoch 1, Batch 300] loss: 0.21420804493129253
[Epoch 1, Batch 400] loss: 0.19236558264121414
[Epoch 1, Batch 500] loss: 0.14931307902559637
[Epoch 1, Batch 600] loss: 0.12314118427224457
[Epoch 1, Batch 700] loss: 0.12815687005408108
[Epoch 1, Batch 800] loss: 0.11723216504324227
[Epoch 1, Batch 900] loss: 0.10185263041872532
**STATS for Epoch 1** : 
Average training loss: 0.0047
Average validation loss: 0.1266
Validation Accuracy: 0.9612
Overfitting: 0.1219
Best model saved at epoch 1 with validation loss: 0.1266
[Epoch 2, Batch 100] loss: 0.0848806552728638
[Epoch 2, Batch 200] loss: 0.08151971569517627
[Epoch 2, Batch 300] loss: 0.08998407362960278
[Epoch 2, Batch 400] loss: 0.08019140173564665
[Epoch 2, Batch 500] loss: 0.07824900269712089
[Epoch 2, Batch 600] loss: 0.08260629576048814
[Epoch 2, Batch 700] loss: 0.07766997210215777
[Epoch 2, Batch 800] loss: 0.06805562147288584
[Epoch 2, Batch 900] loss: 0.06069392079603858
**STATS for Epoch 2** : 
Average training loss: 0.0021
Average validation loss: 0.0711
Validation Accuracy: 0.9779
Overfitting: 0.0690
Best model saved at epoch 2 with validation loss: 0.0711
[Epoch 3, Batch 100] loss: 0.065838920539245
[Epoch 3, Batch 200] loss: 0.05395675957784988
[Epoch 3, Batch 300] loss: 0.05098712739592884
[Epoch 3, Batch 400] loss: 0.05838352770369966
[Epoch 3, Batch 500] loss: 0.05581192470854148
[Epoch 3, Batch 600] loss: 0.04781148096284596
[Epoch 3, Batch 700] loss: 0.04533412894568755
[Epoch 3, Batch 800] loss: 0.051753408838558244
[Epoch 3, Batch 900] loss: 0.05216242275724653
**STATS for Epoch 3** : 
Average training loss: 0.0027
Average validation loss: 0.0784
Validation Accuracy: 0.9774
Overfitting: 0.0756
[Epoch 4, Batch 100] loss: 0.0337719966682198
[Epoch 4, Batch 200] loss: 0.032139627305296015
[Epoch 4, Batch 300] loss: 0.03497227809682954
[Epoch 4, Batch 400] loss: 0.04014653574311524
[Epoch 4, Batch 500] loss: 0.02886441178197856
[Epoch 4, Batch 600] loss: 0.04647050871513784
[Epoch 4, Batch 700] loss: 0.044204241596744395
[Epoch 4, Batch 800] loss: 0.04681013014924247
[Epoch 4, Batch 900] loss: 0.042806387503514995
**STATS for Epoch 4** : 
Average training loss: 0.0009
Average validation loss: 0.0578
Validation Accuracy: 0.9840
Overfitting: 0.0569
Best model saved at epoch 4 with validation loss: 0.0578
[Epoch 5, Batch 100] loss: 0.03473080162279075
[Epoch 5, Batch 200] loss: 0.019936309155964407
[Epoch 5, Batch 300] loss: 0.02296345120666956
[Epoch 5, Batch 400] loss: 0.032314156356442254
[Epoch 5, Batch 500] loss: 0.030369724817282985
[Epoch 5, Batch 600] loss: 0.017707874434854602
[Epoch 5, Batch 700] loss: 0.03209352095531358
[Epoch 5, Batch 800] loss: 0.03278551713563502
[Epoch 5, Batch 900] loss: 0.028434076875273603
**STATS for Epoch 5** : 
Average training loss: 0.0008
Average validation loss: 0.0680
Validation Accuracy: 0.9804
Overfitting: 0.0672
[Epoch 6, Batch 100] loss: 0.008695505513787793
[Epoch 6, Batch 200] loss: 0.025218691310001304
[Epoch 6, Batch 300] loss: 0.016173719843718574
[Epoch 6, Batch 400] loss: 0.019389144021824904
[Epoch 6, Batch 500] loss: 0.03878933239433536
[Epoch 6, Batch 600] loss: 0.016763769236640656
[Epoch 6, Batch 700] loss: 0.036045693363121245
[Epoch 6, Batch 800] loss: 0.02123274247845984
[Epoch 6, Batch 900] loss: 0.0207494800609129
**STATS for Epoch 6** : 
Average training loss: 0.0009
Average validation loss: 0.0579
Validation Accuracy: 0.9847
Overfitting: 0.0570
[Epoch 7, Batch 100] loss: 0.016250300746305582
[Epoch 7, Batch 200] loss: 0.019924129270511914
[Epoch 7, Batch 300] loss: 0.012575361675499153
[Epoch 7, Batch 400] loss: 0.02184763586457848
[Epoch 7, Batch 500] loss: 0.02477580873428451
[Epoch 7, Batch 600] loss: 0.018466460464551346
[Epoch 7, Batch 700] loss: 0.03206887230087887
[Epoch 7, Batch 800] loss: 0.03654259165850817
[Epoch 7, Batch 900] loss: 0.02222249016354908
**STATS for Epoch 7** : 
Average training loss: 0.0007
Average validation loss: 0.0483
Validation Accuracy: 0.9873
Overfitting: 0.0476
Best model saved at epoch 7 with validation loss: 0.0483
[Epoch 8, Batch 100] loss: 0.008975232923367002
[Epoch 8, Batch 200] loss: 0.01809228866135527
[Epoch 8, Batch 300] loss: 0.015368720852129626
[Epoch 8, Batch 400] loss: 0.01208799167226971
[Epoch 8, Batch 500] loss: 0.019269198154083823
[Epoch 8, Batch 600] loss: 0.024842499378883075
[Epoch 8, Batch 700] loss: 0.015469190582880401
[Epoch 8, Batch 800] loss: 0.013815437144639873
[Epoch 8, Batch 900] loss: 0.017432091736072835
**STATS for Epoch 8** : 
Average training loss: 0.0014
Average validation loss: 0.0680
Validation Accuracy: 0.9838
Overfitting: 0.0666
[Epoch 9, Batch 100] loss: 0.014184622829652653
[Epoch 9, Batch 200] loss: 0.014011480394419778
[Epoch 9, Batch 300] loss: 0.00894522408132616
[Epoch 9, Batch 400] loss: 0.02476529091523844
[Epoch 9, Batch 500] loss: 0.006042070388211869
[Epoch 9, Batch 600] loss: 0.007844444166312314
[Epoch 9, Batch 700] loss: 0.016928102728916202
[Epoch 9, Batch 800] loss: 0.011386519674802002
[Epoch 9, Batch 900] loss: 0.01159945403962297
**STATS for Epoch 9** : 
Average training loss: 0.0007
Average validation loss: 0.0573
Validation Accuracy: 0.9860
Overfitting: 0.0566
[Epoch 10, Batch 100] loss: 0.0050412265619016235
[Epoch 10, Batch 200] loss: 0.006835522291694361
[Epoch 10, Batch 300] loss: 0.008421657594917633
[Epoch 10, Batch 400] loss: 0.020987687451640796
[Epoch 10, Batch 500] loss: 0.02948451636604659
[Epoch 10, Batch 600] loss: 0.013939844068563616
[Epoch 10, Batch 700] loss: 0.01036392105055711
[Epoch 10, Batch 800] loss: 0.01047096949914021
[Epoch 10, Batch 900] loss: 0.016000942833250063
**STATS for Epoch 10** : 
Average training loss: 0.0008
Average validation loss: 0.0676
Validation Accuracy: 0.9847
Overfitting: 0.0668
[Epoch 11, Batch 100] loss: 0.013660041921075389
[Epoch 11, Batch 200] loss: 0.009376390771712977
[Epoch 11, Batch 300] loss: 0.014302504197007692
[Epoch 11, Batch 400] loss: 0.00655831900868634
[Epoch 11, Batch 500] loss: 0.00680475999133364
[Epoch 11, Batch 600] loss: 0.004736985813605657
[Epoch 11, Batch 700] loss: 0.007582143726906452
[Epoch 11, Batch 800] loss: 0.018501403844308015
[Epoch 11, Batch 900] loss: 0.0150317309298498
**STATS for Epoch 11** : 
Average training loss: 0.0005
Average validation loss: 0.0647
Validation Accuracy: 0.9857
Overfitting: 0.0642
[Epoch 12, Batch 100] loss: 0.010582986673376808
[Epoch 12, Batch 200] loss: 0.01336537163604362
[Epoch 12, Batch 300] loss: 0.018892165419313187
[Epoch 12, Batch 400] loss: 0.01365974706366842
[Epoch 12, Batch 500] loss: 0.009901412007175169
[Epoch 12, Batch 600] loss: 0.01473746784759328
[Epoch 12, Batch 700] loss: 0.011427633516245806
[Epoch 12, Batch 800] loss: 0.004354087657859509
[Epoch 12, Batch 900] loss: 0.013837313885206868
**STATS for Epoch 12** : 
Average training loss: 0.0001
Average validation loss: 0.0504
Validation Accuracy: 0.9882
Overfitting: 0.0503
[Epoch 13, Batch 100] loss: 0.0015836951924120513
[Epoch 13, Batch 200] loss: 0.00682607310931246
[Epoch 13, Batch 300] loss: 0.006269460954863462
[Epoch 13, Batch 400] loss: 0.0017208695919521233
[Epoch 13, Batch 500] loss: 0.004798552790436474
[Epoch 13, Batch 600] loss: 0.005859040626740466
[Epoch 13, Batch 700] loss: 0.004581014885739023
[Epoch 13, Batch 800] loss: 0.01157424601673256
[Epoch 13, Batch 900] loss: 0.016438331588195753
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0912
Validation Accuracy: 0.9833
Overfitting: 0.0904
[Epoch 14, Batch 100] loss: 0.0047400723809062125
[Epoch 14, Batch 200] loss: 0.014511435485167113
[Epoch 14, Batch 300] loss: 0.012007789101873384
[Epoch 14, Batch 400] loss: 0.017486469076193317
[Epoch 14, Batch 500] loss: 0.013244755153118603
[Epoch 14, Batch 600] loss: 0.0048532652128039895
[Epoch 14, Batch 700] loss: 0.004686806381500901
[Epoch 14, Batch 800] loss: 0.006901348402586791
[Epoch 14, Batch 900] loss: 0.004516877305352978
**STATS for Epoch 14** : 
Average training loss: 0.0002
Average validation loss: 0.0598
Validation Accuracy: 0.9876
Overfitting: 0.0596
[Epoch 15, Batch 100] loss: 0.0041765476532084735
[Epoch 15, Batch 200] loss: 0.006604022726784819
[Epoch 15, Batch 300] loss: 0.02598230732951606
[Epoch 15, Batch 400] loss: 0.017903424029732377
[Epoch 15, Batch 500] loss: 0.012113151686695573
[Epoch 15, Batch 600] loss: 0.0092357096464184
[Epoch 15, Batch 700] loss: 0.010704431605237232
[Epoch 15, Batch 800] loss: 0.005665477569375525
[Epoch 15, Batch 900] loss: 0.004337950780141
**STATS for Epoch 15** : 
Average training loss: 0.0002
Average validation loss: 0.0637
Validation Accuracy: 0.9871
Overfitting: 0.0636
[Epoch 16, Batch 100] loss: 0.0010178643671824262
[Epoch 16, Batch 200] loss: 0.0009047695261662625
[Epoch 16, Batch 300] loss: 0.0006359993188411294
[Epoch 16, Batch 400] loss: 0.0005537208955745143
[Epoch 16, Batch 500] loss: 0.003378633521394754
[Epoch 16, Batch 600] loss: 0.002937202881267069
[Epoch 16, Batch 700] loss: 0.0073814541716996016
[Epoch 16, Batch 800] loss: 0.0060757272164295275
[Epoch 16, Batch 900] loss: 0.005754801455300367
**STATS for Epoch 16** : 
Average training loss: 0.0002
Average validation loss: 0.0593
Validation Accuracy: 0.9882
Overfitting: 0.0591
[Epoch 17, Batch 100] loss: 0.009593889468613953
[Epoch 17, Batch 200] loss: 0.00957393500534863
[Epoch 17, Batch 300] loss: 0.0012316721647778906
[Epoch 17, Batch 400] loss: 0.0016982365144428968
[Epoch 17, Batch 500] loss: 0.0031789958240580063
[Epoch 17, Batch 600] loss: 0.0033161559914526607
[Epoch 17, Batch 700] loss: 0.0037435642816188875
[Epoch 17, Batch 800] loss: 0.005542377237451035
[Epoch 17, Batch 900] loss: 0.007062900527755858
**STATS for Epoch 17** : 
Average training loss: 0.0005
Average validation loss: 0.0990
Validation Accuracy: 0.9818
Overfitting: 0.0985
[Epoch 18, Batch 100] loss: 0.006962477381354688
[Epoch 18, Batch 200] loss: 0.004467023808125816
[Epoch 18, Batch 300] loss: 0.004377516498609566
[Epoch 18, Batch 400] loss: 0.009787713873016912
[Epoch 18, Batch 500] loss: 0.009702214529330035
[Epoch 18, Batch 600] loss: 0.004881948578145057
[Epoch 18, Batch 700] loss: 0.01011604888147815
[Epoch 18, Batch 800] loss: 0.01752316830221588
[Epoch 18, Batch 900] loss: 0.011176411037090474
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0670
Validation Accuracy: 0.9859
Overfitting: 0.0668
[Epoch 19, Batch 100] loss: 0.0019288094742523753
[Epoch 19, Batch 200] loss: 0.0016614287750266498
[Epoch 19, Batch 300] loss: 0.004747216255863407
[Epoch 19, Batch 400] loss: 0.0028927878927501637
[Epoch 19, Batch 500] loss: 0.0006043515020730972
[Epoch 19, Batch 600] loss: 0.0034198507218440354
[Epoch 19, Batch 700] loss: 0.002720880440298856
[Epoch 19, Batch 800] loss: 0.0014520811204613438
[Epoch 19, Batch 900] loss: 0.011430298283255525
**STATS for Epoch 19** : 
Average training loss: 0.0010
Average validation loss: 0.0750
Validation Accuracy: 0.9850
Overfitting: 0.0739
[Epoch 20, Batch 100] loss: 0.0076140877997737276
[Epoch 20, Batch 200] loss: 0.00569864703298748
[Epoch 20, Batch 300] loss: 0.002787576808197514
[Epoch 20, Batch 400] loss: 0.0020567033075315068
[Epoch 20, Batch 500] loss: 0.0012349020314437098
[Epoch 20, Batch 600] loss: 0.0016393837098969755
[Epoch 20, Batch 700] loss: 0.0008624728177145969
[Epoch 20, Batch 800] loss: 0.00037166601799746955
[Epoch 20, Batch 900] loss: 0.002196612078269311
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0602
Validation Accuracy: 0.9888
Overfitting: 0.0600
[Epoch 21, Batch 100] loss: 0.0007913753629273224
[Epoch 21, Batch 200] loss: 0.0006630683598562115
[Epoch 21, Batch 300] loss: 0.0029615294237579403
[Epoch 21, Batch 400] loss: 0.005069775947354313
[Epoch 21, Batch 500] loss: 0.006713453221282748
[Epoch 21, Batch 600] loss: 0.005229856846363176
[Epoch 21, Batch 700] loss: 0.004377016621448884
[Epoch 21, Batch 800] loss: 0.0029207288781869776
[Epoch 21, Batch 900] loss: 0.0010521308494312364
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0569
Validation Accuracy: 0.9891
Overfitting: 0.0569
[Epoch 22, Batch 100] loss: 0.00021393600512219278
[Epoch 22, Batch 200] loss: 0.0023684303115705774
[Epoch 22, Batch 300] loss: 0.0010835113512397143
[Epoch 22, Batch 400] loss: 0.00035650570403802375
[Epoch 22, Batch 500] loss: 0.005380051837257121
[Epoch 22, Batch 600] loss: 0.0007314268677428526
[Epoch 22, Batch 700] loss: 0.0004033252789969133
[Epoch 22, Batch 800] loss: 0.0003096997498302212
[Epoch 22, Batch 900] loss: 0.004379179503464741
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0752
Validation Accuracy: 0.9867
Overfitting: 0.0750
[Epoch 23, Batch 100] loss: 0.0017961244719347748
[Epoch 23, Batch 200] loss: 0.0014096404173641352
[Epoch 23, Batch 300] loss: 0.0015224940262894648
[Epoch 23, Batch 400] loss: 0.000569742116770513
[Epoch 23, Batch 500] loss: 0.0004658840019476873
[Epoch 23, Batch 600] loss: 0.0004354807878267386
[Epoch 23, Batch 700] loss: 0.000537704869628246
[Epoch 23, Batch 800] loss: 0.0019194150846844594
[Epoch 23, Batch 900] loss: 0.0018488574107293943
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0626
Validation Accuracy: 0.9886
Overfitting: 0.0626
[Epoch 24, Batch 100] loss: 0.00022507454849509
[Epoch 24, Batch 200] loss: 0.00012876685749070306
[Epoch 24, Batch 300] loss: 0.00014907012402992414
[Epoch 24, Batch 400] loss: 0.0001810203089424256
[Epoch 24, Batch 500] loss: 0.00021084131313541476
[Epoch 24, Batch 600] loss: 5.3433574444603506e-05
[Epoch 24, Batch 700] loss: 0.0007099917887456342
[Epoch 24, Batch 800] loss: 0.00012054183065316692
[Epoch 24, Batch 900] loss: 0.0003228134741920741
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0645
Validation Accuracy: 0.9892
Overfitting: 0.0645
Fold 2 validation loss: 0.0645
Mean validation loss across all folds for Trial 22 is 0.0692 with trial config:  l1: 352, l2: 160, lr: 0.011512830624060836, batch_size: 32
[I 2024-11-19 03:01:30,906] Trial 21 finished with value: 0.06916771803702523 and parameters: {'l1': 352, 'l2': 160, 'lr': 0.011512830624060836, 'batch_size': 32}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 23:
  l1: 224, l2: 224, lr: 0.012581150560738311, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.3058714778721332
[Epoch 1, Batch 200] loss: 0.27364094734191896
[Epoch 1, Batch 300] loss: 0.17377289675176144
[Epoch 1, Batch 400] loss: 0.14844306414946914
**STATS for Epoch 1** : 
Average training loss: 0.0166
Average validation loss: 0.1178
Validation Accuracy: 0.9640
Overfitting: 0.1012
Best model saved at epoch 1 with validation loss: 0.1178
[Epoch 2, Batch 100] loss: 0.0978787016775459
[Epoch 2, Batch 200] loss: 0.09250028112903237
[Epoch 2, Batch 300] loss: 0.08782728547230363
[Epoch 2, Batch 400] loss: 0.07430111260153353
**STATS for Epoch 2** : 
Average training loss: 0.0107
Average validation loss: 0.0865
Validation Accuracy: 0.9729
Overfitting: 0.0758
Best model saved at epoch 2 with validation loss: 0.0865
[Epoch 3, Batch 100] loss: 0.060074708291795106
[Epoch 3, Batch 200] loss: 0.06620816171867773
[Epoch 3, Batch 300] loss: 0.05560556517913937
[Epoch 3, Batch 400] loss: 0.057816106146201494
**STATS for Epoch 3** : 
Average training loss: 0.0089
Average validation loss: 0.0641
Validation Accuracy: 0.9802
Overfitting: 0.0552
Best model saved at epoch 3 with validation loss: 0.0641
[Epoch 4, Batch 100] loss: 0.03517381906160153
[Epoch 4, Batch 200] loss: 0.036797424713149667
[Epoch 4, Batch 300] loss: 0.04041188564733602
[Epoch 4, Batch 400] loss: 0.05693491449579596
**STATS for Epoch 4** : 
Average training loss: 0.0053
Average validation loss: 0.0615
Validation Accuracy: 0.9816
Overfitting: 0.0562
Best model saved at epoch 4 with validation loss: 0.0615
[Epoch 5, Batch 100] loss: 0.03506687096785754
[Epoch 5, Batch 200] loss: 0.031730407422292044
[Epoch 5, Batch 300] loss: 0.02793264477601042
[Epoch 5, Batch 400] loss: 0.026921942877524998
**STATS for Epoch 5** : 
Average training loss: 0.0037
Average validation loss: 0.0657
Validation Accuracy: 0.9826
Overfitting: 0.0620
[Epoch 6, Batch 100] loss: 0.02577241573308129
[Epoch 6, Batch 200] loss: 0.022471464236150495
[Epoch 6, Batch 300] loss: 0.02140292267096811
[Epoch 6, Batch 400] loss: 0.026822610298913786
**STATS for Epoch 6** : 
Average training loss: 0.0042
Average validation loss: 0.0524
Validation Accuracy: 0.9846
Overfitting: 0.0482
Best model saved at epoch 6 with validation loss: 0.0524
[Epoch 7, Batch 100] loss: 0.017624028889695182
[Epoch 7, Batch 200] loss: 0.02149183589441236
[Epoch 7, Batch 300] loss: 0.020701005620067006
[Epoch 7, Batch 400] loss: 0.023069476221862714
**STATS for Epoch 7** : 
Average training loss: 0.0034
Average validation loss: 0.0579
Validation Accuracy: 0.9848
Overfitting: 0.0544
[Epoch 8, Batch 100] loss: 0.014970774926041486
[Epoch 8, Batch 200] loss: 0.012306057456735289
[Epoch 8, Batch 300] loss: 0.01617156073654769
[Epoch 8, Batch 400] loss: 0.01548961054184474
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0571
Validation Accuracy: 0.9849
Overfitting: 0.0547
[Epoch 9, Batch 100] loss: 0.011808673776540672
[Epoch 9, Batch 200] loss: 0.010052905956908944
[Epoch 9, Batch 300] loss: 0.019982304741351983
[Epoch 9, Batch 400] loss: 0.01637131130315538
**STATS for Epoch 9** : 
Average training loss: 0.0024
Average validation loss: 0.0655
Validation Accuracy: 0.9840
Overfitting: 0.0632
[Epoch 10, Batch 100] loss: 0.012591683303180617
[Epoch 10, Batch 200] loss: 0.013452442209018044
[Epoch 10, Batch 300] loss: 0.009097197306837189
[Epoch 10, Batch 400] loss: 0.013239531297949724
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0598
Validation Accuracy: 0.9855
Overfitting: 0.0583
[Epoch 11, Batch 100] loss: 0.007458126987112337
[Epoch 11, Batch 200] loss: 0.01334177822991478
[Epoch 11, Batch 300] loss: 0.01110643905478355
[Epoch 11, Batch 400] loss: 0.009546972750313217
**STATS for Epoch 11** : 
Average training loss: 0.0031
Average validation loss: 0.0846
Validation Accuracy: 0.9800
Overfitting: 0.0815
[Epoch 12, Batch 100] loss: 0.007928431628388353
[Epoch 12, Batch 200] loss: 0.008553839499254536
[Epoch 12, Batch 300] loss: 0.005781173821142147
[Epoch 12, Batch 400] loss: 0.012580065631227625
**STATS for Epoch 12** : 
Average training loss: 0.0021
Average validation loss: 0.0621
Validation Accuracy: 0.9857
Overfitting: 0.0600
[Epoch 13, Batch 100] loss: 0.0033812292291077028
[Epoch 13, Batch 200] loss: 0.007136115317734948
[Epoch 13, Batch 300] loss: 0.005753160953099723
[Epoch 13, Batch 400] loss: 0.010397557701453479
**STATS for Epoch 13** : 
Average training loss: 0.0007
Average validation loss: 0.0599
Validation Accuracy: 0.9865
Overfitting: 0.0592
[Epoch 14, Batch 100] loss: 0.006909461314699002
[Epoch 14, Batch 200] loss: 0.007360085170366801
[Epoch 14, Batch 300] loss: 0.014253855017777824
[Epoch 14, Batch 400] loss: 0.008220173431036528
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0608
Validation Accuracy: 0.9865
Overfitting: 0.0601
[Epoch 15, Batch 100] loss: 0.005396015918167904
[Epoch 15, Batch 200] loss: 0.0020133505926719407
[Epoch 15, Batch 300] loss: 0.0029094439005029928
[Epoch 15, Batch 400] loss: 0.006167341599752945
**STATS for Epoch 15** : 
Average training loss: 0.0011
Average validation loss: 0.0615
Validation Accuracy: 0.9871
Overfitting: 0.0604
[Epoch 16, Batch 100] loss: 0.004169084162940635
[Epoch 16, Batch 200] loss: 0.002352774218907143
[Epoch 16, Batch 300] loss: 0.004296709317100067
[Epoch 16, Batch 400] loss: 0.0031261106534122974
**STATS for Epoch 16** : 
Average training loss: 0.0002
Average validation loss: 0.0643
Validation Accuracy: 0.9878
Overfitting: 0.0641
[Epoch 17, Batch 100] loss: 0.0020526800451949614
[Epoch 17, Batch 200] loss: 0.004716509343195412
[Epoch 17, Batch 300] loss: 0.012298020211246694
[Epoch 17, Batch 400] loss: 0.010258827465977447
**STATS for Epoch 17** : 
Average training loss: 0.0017
Average validation loss: 0.0773
Validation Accuracy: 0.9837
Overfitting: 0.0756
[Epoch 18, Batch 100] loss: 0.008907758473069407
[Epoch 18, Batch 200] loss: 0.0021600752152698987
[Epoch 18, Batch 300] loss: 0.008545881692962212
[Epoch 18, Batch 400] loss: 0.005439222626318951
**STATS for Epoch 18** : 
Average training loss: 0.0007
Average validation loss: 0.0620
Validation Accuracy: 0.9871
Overfitting: 0.0613
[Epoch 19, Batch 100] loss: 0.0011176090172182285
[Epoch 19, Batch 200] loss: 0.0006865856751983302
[Epoch 19, Batch 300] loss: 0.002338279160003367
[Epoch 19, Batch 400] loss: 0.002000235831314967
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0589
Validation Accuracy: 0.9888
Overfitting: 0.0589
[Epoch 20, Batch 100] loss: 0.000882679311728225
[Epoch 20, Batch 200] loss: 0.0005314446766283254
[Epoch 20, Batch 300] loss: 0.0006264099314978466
[Epoch 20, Batch 400] loss: 0.00028669870403405187
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0615
Validation Accuracy: 0.9888
Overfitting: 0.0614
[Epoch 21, Batch 100] loss: 0.000307237928530526
[Epoch 21, Batch 200] loss: 0.00019422238419394944
[Epoch 21, Batch 300] loss: 0.00016426949689105186
[Epoch 21, Batch 400] loss: 0.00023575761296228847
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9887
Overfitting: 0.0635
[Epoch 22, Batch 100] loss: 0.00015149451071238217
[Epoch 22, Batch 200] loss: 0.00010743049761231304
[Epoch 22, Batch 300] loss: 8.522507532063628e-05
[Epoch 22, Batch 400] loss: 7.916627847862401e-05
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0646
Validation Accuracy: 0.9887
Overfitting: 0.0646
[Epoch 23, Batch 100] loss: 0.00014187674935982385
[Epoch 23, Batch 200] loss: 4.832951244139849e-05
[Epoch 23, Batch 300] loss: 8.508824769705825e-05
[Epoch 23, Batch 400] loss: 7.012440349399185e-05
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0655
Validation Accuracy: 0.9888
Overfitting: 0.0655
[Epoch 24, Batch 100] loss: 6.428169879399092e-05
[Epoch 24, Batch 200] loss: 7.430609624748286e-05
[Epoch 24, Batch 300] loss: 0.00010148460724252573
[Epoch 24, Batch 400] loss: 6.277589930277828e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0664
Validation Accuracy: 0.9889
Overfitting: 0.0664
Fold 1 validation loss: 0.0664
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.2552011463046073
[Epoch 1, Batch 200] loss: 0.23705108605325223
[Epoch 1, Batch 300] loss: 0.15689628839492797
[Epoch 1, Batch 400] loss: 0.13622330505400895
**STATS for Epoch 1** : 
Average training loss: 0.0166
Average validation loss: 0.1007
Validation Accuracy: 0.9683
Overfitting: 0.0841
Best model saved at epoch 1 with validation loss: 0.1007
[Epoch 2, Batch 100] loss: 0.08833729022182524
[Epoch 2, Batch 200] loss: 0.0800398656912148
[Epoch 2, Batch 300] loss: 0.07820963635807857
[Epoch 2, Batch 400] loss: 0.06976626735646278
**STATS for Epoch 2** : 
Average training loss: 0.0090
Average validation loss: 0.0747
Validation Accuracy: 0.9774
Overfitting: 0.0657
Best model saved at epoch 2 with validation loss: 0.0747
[Epoch 3, Batch 100] loss: 0.0541485025989823
[Epoch 3, Batch 200] loss: 0.05129415065748617
[Epoch 3, Batch 300] loss: 0.05857623751508072
[Epoch 3, Batch 400] loss: 0.05448609331389889
**STATS for Epoch 3** : 
Average training loss: 0.0097
Average validation loss: 0.0569
Validation Accuracy: 0.9821
Overfitting: 0.0472
Best model saved at epoch 3 with validation loss: 0.0569
[Epoch 4, Batch 100] loss: 0.039929646631935614
[Epoch 4, Batch 200] loss: 0.03843640130420681
[Epoch 4, Batch 300] loss: 0.037943559665000064
[Epoch 4, Batch 400] loss: 0.05246746333548799
**STATS for Epoch 4** : 
Average training loss: 0.0061
Average validation loss: 0.0573
Validation Accuracy: 0.9828
Overfitting: 0.0512
[Epoch 5, Batch 100] loss: 0.035149131125072015
[Epoch 5, Batch 200] loss: 0.03519169693812728
[Epoch 5, Batch 300] loss: 0.031721325641847216
[Epoch 5, Batch 400] loss: 0.029959666256909257
**STATS for Epoch 5** : 
Average training loss: 0.0053
Average validation loss: 0.0656
Validation Accuracy: 0.9811
Overfitting: 0.0604
[Epoch 6, Batch 100] loss: 0.021377826823008945
[Epoch 6, Batch 200] loss: 0.0327891576976981
[Epoch 6, Batch 300] loss: 0.0315822597022634
[Epoch 6, Batch 400] loss: 0.027824061409337447
**STATS for Epoch 6** : 
Average training loss: 0.0032
Average validation loss: 0.0496
Validation Accuracy: 0.9847
Overfitting: 0.0464
Best model saved at epoch 6 with validation loss: 0.0496
[Epoch 7, Batch 100] loss: 0.017156903520371997
[Epoch 7, Batch 200] loss: 0.01825582621546346
[Epoch 7, Batch 300] loss: 0.027844968514691572
[Epoch 7, Batch 400] loss: 0.023765506029303652
**STATS for Epoch 7** : 
Average training loss: 0.0034
Average validation loss: 0.0484
Validation Accuracy: 0.9856
Overfitting: 0.0450
Best model saved at epoch 7 with validation loss: 0.0484
[Epoch 8, Batch 100] loss: 0.015483049095928436
[Epoch 8, Batch 200] loss: 0.017990800182451493
[Epoch 8, Batch 300] loss: 0.018543788600800325
[Epoch 8, Batch 400] loss: 0.017162355598411522
**STATS for Epoch 8** : 
Average training loss: 0.0020
Average validation loss: 0.0564
Validation Accuracy: 0.9848
Overfitting: 0.0544
[Epoch 9, Batch 100] loss: 0.014177908014971763
[Epoch 9, Batch 200] loss: 0.013230185410648118
[Epoch 9, Batch 300] loss: 0.010902624512709735
[Epoch 9, Batch 400] loss: 0.022786409843465662
**STATS for Epoch 9** : 
Average training loss: 0.0029
Average validation loss: 0.0517
Validation Accuracy: 0.9860
Overfitting: 0.0488
[Epoch 10, Batch 100] loss: 0.012986316675960553
[Epoch 10, Batch 200] loss: 0.01048667158887838
[Epoch 10, Batch 300] loss: 0.011130869039698154
[Epoch 10, Batch 400] loss: 0.013071108209405793
**STATS for Epoch 10** : 
Average training loss: 0.0017
Average validation loss: 0.0591
Validation Accuracy: 0.9851
Overfitting: 0.0574
[Epoch 11, Batch 100] loss: 0.010855745379594738
[Epoch 11, Batch 200] loss: 0.010870379357438651
[Epoch 11, Batch 300] loss: 0.01139335618532641
[Epoch 11, Batch 400] loss: 0.012372375807917706
**STATS for Epoch 11** : 
Average training loss: 0.0011
Average validation loss: 0.0485
Validation Accuracy: 0.9876
Overfitting: 0.0474
[Epoch 12, Batch 100] loss: 0.009687849212168658
[Epoch 12, Batch 200] loss: 0.01197059962192725
[Epoch 12, Batch 300] loss: 0.007953577403230837
[Epoch 12, Batch 400] loss: 0.010003504904316287
**STATS for Epoch 12** : 
Average training loss: 0.0023
Average validation loss: 0.0600
Validation Accuracy: 0.9856
Overfitting: 0.0577
[Epoch 13, Batch 100] loss: 0.011379722970982584
[Epoch 13, Batch 200] loss: 0.004540241208142106
[Epoch 13, Batch 300] loss: 0.016784093299265807
[Epoch 13, Batch 400] loss: 0.008263055492843705
**STATS for Epoch 13** : 
Average training loss: 0.0023
Average validation loss: 0.0660
Validation Accuracy: 0.9840
Overfitting: 0.0636
[Epoch 14, Batch 100] loss: 0.0073468692467758955
[Epoch 14, Batch 200] loss: 0.006589392380774371
[Epoch 14, Batch 300] loss: 0.00839062828643364
[Epoch 14, Batch 400] loss: 0.002696840190274088
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0568
Validation Accuracy: 0.9868
Overfitting: 0.0559
[Epoch 15, Batch 100] loss: 0.007310943425188725
[Epoch 15, Batch 200] loss: 0.01355164845035688
[Epoch 15, Batch 300] loss: 0.01747478372803016
[Epoch 15, Batch 400] loss: 0.008763536060105253
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0603
Validation Accuracy: 0.9859
Overfitting: 0.0595
[Epoch 16, Batch 100] loss: 0.004144136625509418
[Epoch 16, Batch 200] loss: 0.001871763497547363
[Epoch 16, Batch 300] loss: 0.002867460864201803
[Epoch 16, Batch 400] loss: 0.004327908480440783
**STATS for Epoch 16** : 
Average training loss: 0.0010
Average validation loss: 0.0539
Validation Accuracy: 0.9877
Overfitting: 0.0529
[Epoch 17, Batch 100] loss: 0.004430529593937535
[Epoch 17, Batch 200] loss: 0.0036642329599862935
[Epoch 17, Batch 300] loss: 0.001417169179621851
[Epoch 17, Batch 400] loss: 0.0018629080541268195
**STATS for Epoch 17** : 
Average training loss: 0.0002
Average validation loss: 0.0566
Validation Accuracy: 0.9888
Overfitting: 0.0564
[Epoch 18, Batch 100] loss: 0.0005262113199523811
[Epoch 18, Batch 200] loss: 0.0007878726312537765
[Epoch 18, Batch 300] loss: 0.002443042602302512
[Epoch 18, Batch 400] loss: 0.0038253676881964795
**STATS for Epoch 18** : 
Average training loss: 0.0020
Average validation loss: 0.0586
Validation Accuracy: 0.9872
Overfitting: 0.0566
[Epoch 19, Batch 100] loss: 0.008004005582306491
[Epoch 19, Batch 200] loss: 0.0028653339426477943
[Epoch 19, Batch 300] loss: 0.006948532094397706
[Epoch 19, Batch 400] loss: 0.004501407180277965
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0562
Validation Accuracy: 0.9881
Overfitting: 0.0561
[Epoch 20, Batch 100] loss: 0.0015254752848601427
[Epoch 20, Batch 200] loss: 0.0011131119971810222
[Epoch 20, Batch 300] loss: 0.0006113662147481592
[Epoch 20, Batch 400] loss: 0.0010275447489044608
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0546
Validation Accuracy: 0.9890
Overfitting: 0.0545
[Epoch 21, Batch 100] loss: 0.00017379603261360899
[Epoch 21, Batch 200] loss: 0.00017866245511982015
[Epoch 21, Batch 300] loss: 0.00017926639789834554
[Epoch 21, Batch 400] loss: 0.00012092246424117548
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0566
Validation Accuracy: 0.9889
Overfitting: 0.0565
[Epoch 22, Batch 100] loss: 9.899804790080679e-05
[Epoch 22, Batch 200] loss: 0.00014284242688177072
[Epoch 22, Batch 300] loss: 0.00012326316834958108
[Epoch 22, Batch 400] loss: 0.0001049472075907687
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0575
Validation Accuracy: 0.9894
Overfitting: 0.0575
[Epoch 23, Batch 100] loss: 9.564786567352713e-05
[Epoch 23, Batch 200] loss: 9.54615161839456e-05
[Epoch 23, Batch 300] loss: 7.314201118106211e-05
[Epoch 23, Batch 400] loss: 7.049930877343513e-05
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0584
Validation Accuracy: 0.9895
Overfitting: 0.0584
[Epoch 24, Batch 100] loss: 6.3353929578156e-05
[Epoch 24, Batch 200] loss: 7.185110866593903e-05
[Epoch 24, Batch 300] loss: 5.820142599333167e-05
[Epoch 24, Batch 400] loss: 8.299261651075085e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9895
Overfitting: 0.0592
Fold 2 validation loss: 0.0592
Mean validation loss across all folds for Trial 23 is 0.0628 with trial config:  l1: 224, l2: 224, lr: 0.012581150560738311, batch_size: 64
[I 2024-11-19 03:10:19,477] Trial 22 finished with value: 0.06281288497694261 and parameters: {'l1': 224, 'l2': 224, 'lr': 0.012581150560738311, 'batch_size': 64}. Best is trial 0 with value: 0.05886771301817843.

Selected Hyperparameters for Trial 24:
  l1: 448, l2: 160, lr: 1.6706859120148424e-05, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3041545605659484
[Epoch 1, Batch 200] loss: 2.305057201385498
[Epoch 1, Batch 300] loss: 2.3050804948806762
[Epoch 1, Batch 400] loss: 2.3042842864990236
[Epoch 1, Batch 500] loss: 2.3041012358665465
[Epoch 1, Batch 600] loss: 2.3035593366622926
[Epoch 1, Batch 700] loss: 2.302074053287506
[Epoch 1, Batch 800] loss: 2.3015539932250975
[Epoch 1, Batch 900] loss: 2.301990466117859
**STATS for Epoch 1** : 
Average training loss: 0.0933
Average validation loss: 2.3022
Validation Accuracy: 0.1033
Overfitting: 2.2090
Best model saved at epoch 1 with validation loss: 2.3022
[Epoch 2, Batch 100] loss: 2.302161078453064
[Epoch 2, Batch 200] loss: 2.3018424892425537
[Epoch 2, Batch 300] loss: 2.302208080291748
[Epoch 2, Batch 400] loss: 2.299985580444336
[Epoch 2, Batch 500] loss: 2.3023653841018676
[Epoch 2, Batch 600] loss: 2.2987137174606325
[Epoch 2, Batch 700] loss: 2.2997991681098937
[Epoch 2, Batch 800] loss: 2.3005932354927063
[Epoch 2, Batch 900] loss: 2.2992513251304625
**STATS for Epoch 2** : 
Average training loss: 0.0931
Average validation loss: 2.2994
Validation Accuracy: 0.1198
Overfitting: 2.2063
Best model saved at epoch 2 with validation loss: 2.2994
[Epoch 3, Batch 100] loss: 2.299387602806091
[Epoch 3, Batch 200] loss: 2.297234683036804
[Epoch 3, Batch 300] loss: 2.2979912424087523
[Epoch 3, Batch 400] loss: 2.296433854103088
[Epoch 3, Batch 500] loss: 2.297870593070984
[Epoch 3, Batch 600] loss: 2.297984573841095
[Epoch 3, Batch 700] loss: 2.298448944091797
[Epoch 3, Batch 800] loss: 2.2979528188705443
[Epoch 3, Batch 900] loss: 2.2966813683509826
**STATS for Epoch 3** : 
Average training loss: 0.0930
Average validation loss: 2.2963
Validation Accuracy: 0.1431
Overfitting: 2.2033
Best model saved at epoch 3 with validation loss: 2.2963
[Epoch 4, Batch 100] loss: 2.2964445471763613
[Epoch 4, Batch 200] loss: 2.2945682430267333
[Epoch 4, Batch 300] loss: 2.2962593412399293
[Epoch 4, Batch 400] loss: 2.293778431415558
[Epoch 4, Batch 500] loss: 2.2944352412223816
[Epoch 4, Batch 600] loss: 2.293990511894226
[Epoch 4, Batch 700] loss: 2.294956862926483
[Epoch 4, Batch 800] loss: 2.2942928814888
[Epoch 4, Batch 900] loss: 2.29189325094223
**STATS for Epoch 4** : 
Average training loss: 0.0929
Average validation loss: 2.2929
Validation Accuracy: 0.1823
Overfitting: 2.2000
Best model saved at epoch 4 with validation loss: 2.2929
[Epoch 5, Batch 100] loss: 2.291782398223877
[Epoch 5, Batch 200] loss: 2.2910852932929995
[Epoch 5, Batch 300] loss: 2.292189919948578
[Epoch 5, Batch 400] loss: 2.2929582691192625
[Epoch 5, Batch 500] loss: 2.289821243286133
[Epoch 5, Batch 600] loss: 2.291442632675171
[Epoch 5, Batch 700] loss: 2.2876521801948546
[Epoch 5, Batch 800] loss: 2.2904876017570497
[Epoch 5, Batch 900] loss: 2.2902547836303713
**STATS for Epoch 5** : 
Average training loss: 0.0929
Average validation loss: 2.2892
Validation Accuracy: 0.2219
Overfitting: 2.1963
Best model saved at epoch 5 with validation loss: 2.2892
[Epoch 6, Batch 100] loss: 2.2887960696220397
[Epoch 6, Batch 200] loss: 2.2889966320991517
[Epoch 6, Batch 300] loss: 2.288070311546326
[Epoch 6, Batch 400] loss: 2.2874453115463256
[Epoch 6, Batch 500] loss: 2.28612699508667
[Epoch 6, Batch 600] loss: 2.2870852756500244
[Epoch 6, Batch 700] loss: 2.285421016216278
[Epoch 6, Batch 800] loss: 2.2851690602302552
[Epoch 6, Batch 900] loss: 2.2849010396003724
**STATS for Epoch 6** : 
Average training loss: 0.0926
Average validation loss: 2.2848
Validation Accuracy: 0.2860
Overfitting: 2.1922
Best model saved at epoch 6 with validation loss: 2.2848
[Epoch 7, Batch 100] loss: 2.2841382670402526
[Epoch 7, Batch 200] loss: 2.283965826034546
[Epoch 7, Batch 300] loss: 2.2829080629348755
[Epoch 7, Batch 400] loss: 2.28311633348465
[Epoch 7, Batch 500] loss: 2.2811797976493837
[Epoch 7, Batch 600] loss: 2.2822723507881166
[Epoch 7, Batch 700] loss: 2.280904755592346
[Epoch 7, Batch 800] loss: 2.2799608969688414
[Epoch 7, Batch 900] loss: 2.2815859723091125
**STATS for Epoch 7** : 
Average training loss: 0.0923
Average validation loss: 2.2795
Validation Accuracy: 0.3600
Overfitting: 2.1873
Best model saved at epoch 7 with validation loss: 2.2795
[Epoch 8, Batch 100] loss: 2.2780760812759397
[Epoch 8, Batch 200] loss: 2.2774970006942747
[Epoch 8, Batch 300] loss: 2.2781826305389403
[Epoch 8, Batch 400] loss: 2.276993098258972
[Epoch 8, Batch 500] loss: 2.275894756317139
[Epoch 8, Batch 600] loss: 2.275380268096924
[Epoch 8, Batch 700] loss: 2.275379927158356
[Epoch 8, Batch 800] loss: 2.2752546739578245
[Epoch 8, Batch 900] loss: 2.2744972109794617
**STATS for Epoch 8** : 
Average training loss: 0.0922
Average validation loss: 2.2732
Validation Accuracy: 0.3927
Overfitting: 2.1811
Best model saved at epoch 8 with validation loss: 2.2732
[Epoch 9, Batch 100] loss: 2.2724662113189695
[Epoch 9, Batch 200] loss: 2.271997015476227
[Epoch 9, Batch 300] loss: 2.2716612458229064
[Epoch 9, Batch 400] loss: 2.2703752613067625
[Epoch 9, Batch 500] loss: 2.2707792997360228
[Epoch 9, Batch 600] loss: 2.268719644546509
[Epoch 9, Batch 700] loss: 2.267901968955994
[Epoch 9, Batch 800] loss: 2.2659898686408995
[Epoch 9, Batch 900] loss: 2.2638287568092346
**STATS for Epoch 9** : 
Average training loss: 0.0918
Average validation loss: 2.2654
Validation Accuracy: 0.4105
Overfitting: 2.1735
[I 2024-11-19 03:12:08,356] Trial 23 pruned. 
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  5
  Number of complete trials:  19
Best hyperparameters found:
{'l1': 224, 'l2': 224, 'lr': 0.008471801418819975, 'batch_size': 256}
Best trial:
  Value:  0.05886771301817843
Loaded best model checkpoint from: best_checkpoint_trial_0/model.pth
Using best hyperparameters {'l1': 224, 'l2': 224, 'lr': 0.008471801418819975, 'batch_size': 256} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 1.480254558622837
[Epoch 1, Batch 200] loss: 0.26979768365621565
**STATS for Epoch 1** : 
Average training loss: 0.0295
Best model saved at epoch 1 with training loss: 0.0295
[Epoch 2, Batch 100] loss: 0.14433519974350928
[Epoch 2, Batch 200] loss: 0.1093235456943512
**STATS for Epoch 2** : 
Average training loss: 0.0159
Best model saved at epoch 2 with training loss: 0.0159
[Epoch 3, Batch 100] loss: 0.09873728793114424
[Epoch 3, Batch 200] loss: 0.07551166076213121
**STATS for Epoch 3** : 
Average training loss: 0.0122
Best model saved at epoch 3 with training loss: 0.0122
[Epoch 4, Batch 100] loss: 0.06516760550439357
[Epoch 4, Batch 200] loss: 0.06673027589917183
**STATS for Epoch 4** : 
Average training loss: 0.0087
Best model saved at epoch 4 with training loss: 0.0087
[Epoch 5, Batch 100] loss: 0.0536175598949194
[Epoch 5, Batch 200] loss: 0.05156560997478664
**STATS for Epoch 5** : 
Average training loss: 0.0089
[Epoch 6, Batch 100] loss: 0.04772621788084507
[Epoch 6, Batch 200] loss: 0.04301843228749931
**STATS for Epoch 6** : 
Average training loss: 0.0068
Best model saved at epoch 6 with training loss: 0.0068
[Epoch 7, Batch 100] loss: 0.042364029241725804
[Epoch 7, Batch 200] loss: 0.03943794711958617
**STATS for Epoch 7** : 
Average training loss: 0.0065
Best model saved at epoch 7 with training loss: 0.0065
[Epoch 8, Batch 100] loss: 0.03419484766200185
[Epoch 8, Batch 200] loss: 0.03418144294060767
**STATS for Epoch 8** : 
Average training loss: 0.0070
[Epoch 9, Batch 100] loss: 0.03186781676486135
[Epoch 9, Batch 200] loss: 0.03315892452374101
**STATS for Epoch 9** : 
Average training loss: 0.0045
Best model saved at epoch 9 with training loss: 0.0045
[Epoch 10, Batch 100] loss: 0.025635068817064167
[Epoch 10, Batch 200] loss: 0.02862148451153189
**STATS for Epoch 10** : 
Average training loss: 0.0047
[Epoch 11, Batch 100] loss: 0.02478820018004626
[Epoch 11, Batch 200] loss: 0.025238462314009665
**STATS for Epoch 11** : 
Average training loss: 0.0035
Best model saved at epoch 11 with training loss: 0.0035
[Epoch 12, Batch 100] loss: 0.021682787016034127
[Epoch 12, Batch 200] loss: 0.023896946946624666
**STATS for Epoch 12** : 
Average training loss: 0.0038
[Epoch 13, Batch 100] loss: 0.021659849288407713
[Epoch 13, Batch 200] loss: 0.019354541306383907
**STATS for Epoch 13** : 
Average training loss: 0.0027
Best model saved at epoch 13 with training loss: 0.0027
[Epoch 14, Batch 100] loss: 0.015656097824685276
[Epoch 14, Batch 200] loss: 0.01887415842153132
**STATS for Epoch 14** : 
Average training loss: 0.0033
[Epoch 15, Batch 100] loss: 0.016838688966818154
[Epoch 15, Batch 200] loss: 0.0185448565450497
**STATS for Epoch 15** : 
Average training loss: 0.0027
[Epoch 16, Batch 100] loss: 0.015519824046641588
[Epoch 16, Batch 200] loss: 0.015326358475722373
**STATS for Epoch 16** : 
Average training loss: 0.0021
Best model saved at epoch 16 with training loss: 0.0021
[Epoch 17, Batch 100] loss: 0.014146347385831178
[Epoch 17, Batch 200] loss: 0.013463799601886421
**STATS for Epoch 17** : 
Average training loss: 0.0025
[Epoch 18, Batch 100] loss: 0.009917012804653496
[Epoch 18, Batch 200] loss: 0.012821719396160915
**STATS for Epoch 18** : 
Average training loss: 0.0022
[Epoch 19, Batch 100] loss: 0.012562454760773107
[Epoch 19, Batch 200] loss: 0.011267181078437716
**STATS for Epoch 19** : 
Average training loss: 0.0021
Best model saved at epoch 19 with training loss: 0.0021
[Epoch 20, Batch 100] loss: 0.009495079055195674
[Epoch 20, Batch 200] loss: 0.010429998122854158
**STATS for Epoch 20** : 
Average training loss: 0.0014
Best model saved at epoch 20 with training loss: 0.0014
[Epoch 21, Batch 100] loss: 0.009468399619217962
[Epoch 21, Batch 200] loss: 0.009894301476306282
**STATS for Epoch 21** : 
Average training loss: 0.0012
Best model saved at epoch 21 with training loss: 0.0012
[Epoch 22, Batch 100] loss: 0.007937280520563946
[Epoch 22, Batch 200] loss: 0.007645963527611457
**STATS for Epoch 22** : 
Average training loss: 0.0018
[Epoch 23, Batch 100] loss: 0.008252377362223342
[Epoch 23, Batch 200] loss: 0.008234109753975644
**STATS for Epoch 23** : 
Average training loss: 0.0010
Best model saved at epoch 23 with training loss: 0.0010
[Epoch 24, Batch 100] loss: 0.004634222145541571
[Epoch 24, Batch 200] loss: 0.006978902231203392
**STATS for Epoch 24** : 
Average training loss: 0.0008
Best model saved at epoch 24 with training loss: 0.0008
Using best hyperparameters {'l1': 224, 'l2': 224, 'lr': 0.008471801418819975, 'batch_size': 256} on final Test set to find Test loss for overfitting
Testing loss : 0.0418
Calculated Overfitting : 0.0410
Using best hyperparameters {'l1': 224, 'l2': 224, 'lr': 0.008471801418819975, 'batch_size': 256} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9869
Total time taken for hyperparameter tuning and evaluation: 3:14:56
/home/ahussain/PycharmProjects/optunaNew/optuna_MedianPruner.py:453: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.


Process finished with exit code 0

