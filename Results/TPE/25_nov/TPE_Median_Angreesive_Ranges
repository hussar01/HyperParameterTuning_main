
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  10
  Number of complete trials:  14
Best hyperparameters found:
{'l1': 256, 'l2': 64, 'lr': 0.0040894420414321975, 'batch_size': 256}
Best trial:
  Value:  0.0582443055690866
------------------------------------------------------------
**STATS for Epoch 24** : 
Average training loss: 0.0021
Best model saved at epoch 24 with training loss: 0.0021
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0040894420414321975, 'batch_size': 256} on final Test set to find Test loss for overfitting
Testing loss : 0.0469
Calculated Overfitting : 0.0448
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0040894420414321975, 'batch_size': 256} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9842
Total time taken for hyperparameter tuning and evaluation: 2:34:32
-----------------------------------------------------------

EPOCHS = 24
CLASSES = 10
INNER_FOLD = 2
NUM_SAMPLES = 24
DIR = os.getcwd()

#---------PRUNER SETTINGS--------------
N_STARTUP_TRIALS_PRUNNER = 5 #The pruner will not prune any trials until n trials have been completed  unlike asha pruning start from 1 or 2 trials
N_WARMUP_STEPS = 5           #Each trial must reach at least n epochs before it becomes eligible for pruning.
INTERVAL_STEPS = 1           #The pruner will check for pruning opportunities after every epoch following the warm-up period

N_MIN_TRIALS = 5             #At least n trials must have reported intermediate results at the same step, but since n_start_up trial have this covered
                             #Ensures that the median is calculated from a minimum of n data points at each epoch.
#---------TPE SETTINGS-----------------
N_STARTUP_TRIALS = 5 
------------------------------------------





[I 2024-11-25 14:43:24,255] A new study created in RDB with name: MedianPruner_ranges_25_nov

Selected Hyperparameters for Trial 1:
  l1: 256, l2: 64, lr: 4.207988669606632e-05, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3102280378341673
[Epoch 1, Batch 200] loss: 2.3086241602897646
[Epoch 1, Batch 300] loss: 2.309034173488617
[Epoch 1, Batch 400] loss: 2.308521809577942
**STATS for Epoch 1** : 
Average training loss: 0.3394
Average validation loss: 2.3079
Validation Accuracy: 0.0994
Overfitting: 1.9685
Best model saved at epoch 1 with validation loss: 2.3079
[Epoch 2, Batch 100] loss: 2.307593970298767
[Epoch 2, Batch 200] loss: 2.3072999548912048
[Epoch 2, Batch 300] loss: 2.3065522480010987
[Epoch 2, Batch 400] loss: 2.306058096885681
**STATS for Epoch 2** : 
Average training loss: 0.3393
Average validation loss: 2.3059
Validation Accuracy: 0.0995
Overfitting: 1.9666
Best model saved at epoch 2 with validation loss: 2.3059
[Epoch 3, Batch 100] loss: 2.305188899040222
[Epoch 3, Batch 200] loss: 2.305578393936157
[Epoch 3, Batch 300] loss: 2.304318106174469
[Epoch 3, Batch 400] loss: 2.3053622388839723
**STATS for Epoch 3** : 
Average training loss: 0.3388
Average validation loss: 2.3039
Validation Accuracy: 0.0997
Overfitting: 1.9651
Best model saved at epoch 3 with validation loss: 2.3039
[Epoch 4, Batch 100] loss: 2.303993365764618
[Epoch 4, Batch 200] loss: 2.302361741065979
[Epoch 4, Batch 300] loss: 2.3042076134681704
[Epoch 4, Batch 400] loss: 2.3012133836746216
**STATS for Epoch 4** : 
Average training loss: 0.3387
Average validation loss: 2.3020
Validation Accuracy: 0.0999
Overfitting: 1.9633
Best model saved at epoch 4 with validation loss: 2.3020
[Epoch 5, Batch 100] loss: 2.301697161197662
[Epoch 5, Batch 200] loss: 2.301455180644989
[Epoch 5, Batch 300] loss: 2.3007209157943724
[Epoch 5, Batch 400] loss: 2.299566526412964
**STATS for Epoch 5** : 
Average training loss: 0.3385
Average validation loss: 2.3000
Validation Accuracy: 0.0999
Overfitting: 1.9615
Best model saved at epoch 5 with validation loss: 2.3000
[Epoch 6, Batch 100] loss: 2.300202100276947
[Epoch 6, Batch 200] loss: 2.298455502986908
[Epoch 6, Batch 300] loss: 2.299042477607727
[Epoch 6, Batch 400] loss: 2.2977373886108396
**STATS for Epoch 6** : 
Average training loss: 0.3381
Average validation loss: 2.2978
Validation Accuracy: 0.1001
Overfitting: 1.9597
Best model saved at epoch 6 with validation loss: 2.2978
[Epoch 7, Batch 100] loss: 2.2974775528907774
[Epoch 7, Batch 200] loss: 2.296990005970001
[Epoch 7, Batch 300] loss: 2.2961002731323243
[Epoch 7, Batch 400] loss: 2.296827573776245
**STATS for Epoch 7** : 
Average training loss: 0.3375
Average validation loss: 2.2954
Validation Accuracy: 0.1005
Overfitting: 1.9578
Best model saved at epoch 7 with validation loss: 2.2954
[Epoch 8, Batch 100] loss: 2.294516248703003
[Epoch 8, Batch 200] loss: 2.294430441856384
[Epoch 8, Batch 300] loss: 2.2944520044326784
[Epoch 8, Batch 400] loss: 2.2931913471221925
**STATS for Epoch 8** : 
Average training loss: 0.3372
Average validation loss: 2.2926
Validation Accuracy: 0.1008
Overfitting: 1.9554
Best model saved at epoch 8 with validation loss: 2.2926
[Epoch 9, Batch 100] loss: 2.2920221304893493
[Epoch 9, Batch 200] loss: 2.291952836513519
[Epoch 9, Batch 300] loss: 2.290296814441681
[Epoch 9, Batch 400] loss: 2.2897229194641113
**STATS for Epoch 9** : 
Average training loss: 0.3369
Average validation loss: 2.2893
Validation Accuracy: 0.1018
Overfitting: 1.9524
Best model saved at epoch 9 with validation loss: 2.2893
[Epoch 10, Batch 100] loss: 2.288889620304108
[Epoch 10, Batch 200] loss: 2.2873012900352476
[Epoch 10, Batch 300] loss: 2.2872466397285462
[Epoch 10, Batch 400] loss: 2.2864584875106813
**STATS for Epoch 10** : 
Average training loss: 0.3363
Average validation loss: 2.2854
Validation Accuracy: 0.1070
Overfitting: 1.9491
Best model saved at epoch 10 with validation loss: 2.2854
[Epoch 11, Batch 100] loss: 2.2840830278396607
[Epoch 11, Batch 200] loss: 2.2846073079109193
[Epoch 11, Batch 300] loss: 2.2826805782318114
[Epoch 11, Batch 400] loss: 2.28181636095047
**STATS for Epoch 11** : 
Average training loss: 0.3356
Average validation loss: 2.2806
Validation Accuracy: 0.1255
Overfitting: 1.9451
Best model saved at epoch 11 with validation loss: 2.2806
[Epoch 12, Batch 100] loss: 2.2792741560935976
[Epoch 12, Batch 200] loss: 2.279235987663269
[Epoch 12, Batch 300] loss: 2.2775202417373657
[Epoch 12, Batch 400] loss: 2.275956385135651
**STATS for Epoch 12** : 
Average training loss: 0.3349
Average validation loss: 2.2749
Validation Accuracy: 0.1863
Overfitting: 1.9400
Best model saved at epoch 12 with validation loss: 2.2749
[Epoch 13, Batch 100] loss: 2.274869592189789
[Epoch 13, Batch 200] loss: 2.2726225423812867
[Epoch 13, Batch 300] loss: 2.271565783023834
[Epoch 13, Batch 400] loss: 2.2687058448791504
**STATS for Epoch 13** : 
Average training loss: 0.3336
Average validation loss: 2.2676
Validation Accuracy: 0.2533
Overfitting: 1.9340
Best model saved at epoch 13 with validation loss: 2.2676
[Epoch 14, Batch 100] loss: 2.2667499732971192
[Epoch 14, Batch 200] loss: 2.265104594230652
[Epoch 14, Batch 300] loss: 2.2624517917633056
[Epoch 14, Batch 400] loss: 2.260825209617615
**STATS for Epoch 14** : 
Average training loss: 0.3324
Average validation loss: 2.2583
Validation Accuracy: 0.3377
Overfitting: 1.9259
Best model saved at epoch 14 with validation loss: 2.2583
[Epoch 15, Batch 100] loss: 2.2573060131073
[Epoch 15, Batch 200] loss: 2.255740132331848
[Epoch 15, Batch 300] loss: 2.2521075558662416
[Epoch 15, Batch 400] loss: 2.2487188005447387
**STATS for Epoch 15** : 
Average training loss: 0.3306
Average validation loss: 2.2462
Validation Accuracy: 0.4351
Overfitting: 1.9155
Best model saved at epoch 15 with validation loss: 2.2462
[Epoch 16, Batch 100] loss: 2.244942922592163
[Epoch 16, Batch 200] loss: 2.2413443160057067
[Epoch 16, Batch 300] loss: 2.2390838146209715
[Epoch 16, Batch 400] loss: 2.234375994205475
**STATS for Epoch 16** : 
Average training loss: 0.3281
Average validation loss: 2.2299
Validation Accuracy: 0.4922
Overfitting: 1.9017
Best model saved at epoch 16 with validation loss: 2.2299
[Epoch 17, Batch 100] loss: 2.2279213786125185
[Epoch 17, Batch 200] loss: 2.2234083938598634
[Epoch 17, Batch 300] loss: 2.2182067394256593
[Epoch 17, Batch 400] loss: 2.2140486812591553
**STATS for Epoch 17** : 
Average training loss: 0.3252
Average validation loss: 2.2071
Validation Accuracy: 0.5037
Overfitting: 1.8819
Best model saved at epoch 17 with validation loss: 2.2071
[Epoch 18, Batch 100] loss: 2.2055930304527283
[Epoch 18, Batch 200] loss: 2.1970701789855958
[Epoch 18, Batch 300] loss: 2.191159131526947
[Epoch 18, Batch 400] loss: 2.182444884777069
**STATS for Epoch 18** : 
Average training loss: 0.3208
Average validation loss: 2.1740
Validation Accuracy: 0.4936
Overfitting: 1.8532
Best model saved at epoch 18 with validation loss: 2.1740
[Epoch 19, Batch 100] loss: 2.1699644422531126
[Epoch 19, Batch 200] loss: 2.1616405558586123
[Epoch 19, Batch 300] loss: 2.1486974787712096
[Epoch 19, Batch 400] loss: 2.1427372026443483
**STATS for Epoch 19** : 
Average training loss: 0.3129
Average validation loss: 2.1242
Validation Accuracy: 0.4773
Overfitting: 1.8112
Best model saved at epoch 19 with validation loss: 2.1242
[Epoch 20, Batch 100] loss: 2.117172598838806
[Epoch 20, Batch 200] loss: 2.1009029722213746
[Epoch 20, Batch 300] loss: 2.0910191249847414
[Epoch 20, Batch 400] loss: 2.0722962379455567
**STATS for Epoch 20** : 
Average training loss: 0.3019
Average validation loss: 2.0458
Validation Accuracy: 0.4700
Overfitting: 1.7439
Best model saved at epoch 20 with validation loss: 2.0458
[Epoch 21, Batch 100] loss: 2.034932450056076
[Epoch 21, Batch 200] loss: 2.0098489439487457
[Epoch 21, Batch 300] loss: 1.9873259091377258
[Epoch 21, Batch 400] loss: 1.962399549484253
**STATS for Epoch 21** : 
Average training loss: 0.2860
Average validation loss: 1.9234
Validation Accuracy: 0.4901
Overfitting: 1.6374
Best model saved at epoch 21 with validation loss: 1.9234
[Epoch 22, Batch 100] loss: 1.9113126587867737
[Epoch 22, Batch 200] loss: 1.878641266822815
[Epoch 22, Batch 300] loss: 1.8340207076072692
[Epoch 22, Batch 400] loss: 1.801422803401947
**STATS for Epoch 22** : 
Average training loss: 0.2588
Average validation loss: 1.7461
Validation Accuracy: 0.5462
Overfitting: 1.4873
Best model saved at epoch 22 with validation loss: 1.7461
[Epoch 23, Batch 100] loss: 1.724459080696106
[Epoch 23, Batch 200] loss: 1.678096705675125
[Epoch 23, Batch 300] loss: 1.6374641096591949
[Epoch 23, Batch 400] loss: 1.580210793018341
**STATS for Epoch 23** : 
Average training loss: 0.2266
Average validation loss: 1.5167
Validation Accuracy: 0.6366
Overfitting: 1.2901
Best model saved at epoch 23 with validation loss: 1.5167
[Epoch 24, Batch 100] loss: 1.4969078087806702
[Epoch 24, Batch 200] loss: 1.4351185715198518
[Epoch 24, Batch 300] loss: 1.3862164580821992
[Epoch 24, Batch 400] loss: 1.3240798723697662
**STATS for Epoch 24** : 
Average training loss: 0.1897
Average validation loss: 1.2606
Validation Accuracy: 0.7105
Overfitting: 1.0709
Best model saved at epoch 24 with validation loss: 1.2606
Fold 1 validation loss: 1.2606
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.303778522014618
[Epoch 1, Batch 200] loss: 2.3028446531295774
[Epoch 1, Batch 300] loss: 2.3015297079086303
[Epoch 1, Batch 400] loss: 2.2993813514709474
**STATS for Epoch 1** : 
Average training loss: 0.3383
Average validation loss: 2.2965
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
Validation Accuracy: 0.0994
Overfitting: 1.9582
Best model saved at epoch 1 with validation loss: 2.2965
[Epoch 2, Batch 100] loss: 2.2953826069831846
[Epoch 2, Batch 200] loss: 2.2940068316459654
[Epoch 2, Batch 300] loss: 2.2924390721321104
[Epoch 2, Batch 400] loss: 2.2902908730506897
**STATS for Epoch 2** : 
Average training loss: 0.3367
Average validation loss: 2.2874
Validation Accuracy: 0.1177
Overfitting: 1.9507
Best model saved at epoch 2 with validation loss: 2.2874
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 1 is already reported.
  warnings.warn(
[Epoch 3, Batch 100] loss: 2.2867143964767456
[Epoch 3, Batch 200] loss: 2.283868143558502
[Epoch 3, Batch 300] loss: 2.2834370350837707
[Epoch 3, Batch 400] loss: 2.2803879594802856
**STATS for Epoch 3** : 
Average training loss: 0.3354
Average validation loss: 2.2777
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 2 is already reported.
  warnings.warn(
Validation Accuracy: 0.1582
Overfitting: 1.9423
Best model saved at epoch 3 with validation loss: 2.2777
[Epoch 4, Batch 100] loss: 2.2771817421913148
[Epoch 4, Batch 200] loss: 2.2754077458381654
[Epoch 4, Batch 300] loss: 2.2720849251747133
[Epoch 4, Batch 400] loss: 2.2685319662094114
**STATS for Epoch 4** : 
Average training loss: 0.3335
Average validation loss: 2.2659
Validation Accuracy: 0.2099
Overfitting: 1.9324
Best model saved at epoch 4 with validation loss: 2.2659
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 3 is already reported.
  warnings.warn(
[Epoch 5, Batch 100] loss: 2.2642216873168945
[Epoch 5, Batch 200] loss: 2.2621780014038086
[Epoch 5, Batch 300] loss: 2.2594198894500734
[Epoch 5, Batch 400] loss: 2.2545820450782776
**STATS for Epoch 5** : 
Average training loss: 0.3313
Average validation loss: 2.2507
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 4 is already reported.
  warnings.warn(
Validation Accuracy: 0.3498
Overfitting: 1.9194
Best model saved at epoch 5 with validation loss: 2.2507
[Epoch 6, Batch 100] loss: 2.2500555515289307
[Epoch 6, Batch 200] loss: 2.244630949497223
[Epoch 6, Batch 300] loss: 2.2404806065559386
[Epoch 6, Batch 400] loss: 2.236771845817566
**STATS for Epoch 6** : 
Average training loss: 0.3283
Average validation loss: 2.2303
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 5 is already reported.
  warnings.warn(
Validation Accuracy: 0.4813
Overfitting: 1.9020
Best model saved at epoch 6 with validation loss: 2.2303
[Epoch 7, Batch 100] loss: 2.2273284697532656
[Epoch 7, Batch 200] loss: 2.2215707182884215
[Epoch 7, Batch 300] loss: 2.217305085659027
[Epoch 7, Batch 400] loss: 2.209407079219818
**STATS for Epoch 7** : 
Average training loss: 0.3244
Average validation loss: 2.2013
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 6 is already reported.
  warnings.warn(
Validation Accuracy: 0.5498
Overfitting: 1.8769
Best model saved at epoch 7 with validation loss: 2.2013
[Epoch 8, Batch 100] loss: 2.19847829580307
[Epoch 8, Batch 200] loss: 2.1892512106895445
[Epoch 8, Batch 300] loss: 2.1794094133377073
[Epoch 8, Batch 400] loss: 2.172359402179718
**STATS for Epoch 8** : 
Average training loss: 0.3178
Average validation loss: 2.1578
Validation Accuracy: 0.5788
Overfitting: 1.8400
Best model saved at epoch 8 with validation loss: 2.1578
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 7 is already reported.
  warnings.warn(
[Epoch 9, Batch 100] loss: 2.1518663454055784
[Epoch 9, Batch 200] loss: 2.1396219658851625
[Epoch 9, Batch 300] loss: 2.12283673286438
[Epoch 9, Batch 400] loss: 2.109763922691345
**STATS for Epoch 9** : 
Average training loss: 0.3085
Average validation loss: 2.0881
Validation Accuracy: 0.6009
Overfitting: 1.7797
Best model saved at epoch 9 with validation loss: 2.0881
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 8 is already reported.
  warnings.warn(
[Epoch 10, Batch 100] loss: 2.0791789507865905
[Epoch 10, Batch 200] loss: 2.057596565485001
[Epoch 10, Batch 300] loss: 2.0345960104465486
[Epoch 10, Batch 400] loss: 2.0001664423942564
**STATS for Epoch 10** : 
Average training loss: 0.2915
Average validation loss: 1.9677
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 9 is already reported.
  warnings.warn(
Validation Accuracy: 0.6279
Overfitting: 1.6761
Best model saved at epoch 10 with validation loss: 1.9677
[Epoch 11, Batch 100] loss: 1.9514060163497924
[Epoch 11, Batch 200] loss: 1.9124266624450683
[Epoch 11, Batch 300] loss: 1.867058823108673
[Epoch 11, Batch 400] loss: 1.8221819484233857
**STATS for Epoch 11** : 
Average training loss: 0.2626
Average validation loss: 1.7620
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 10 is already reported.
  warnings.warn(
Validation Accuracy: 0.6568
Overfitting: 1.4994
Best model saved at epoch 11 with validation loss: 1.7620
[Epoch 12, Batch 100] loss: 1.7373262572288513
[Epoch 12, Batch 200] loss: 1.6743958914279937
[Epoch 12, Batch 300] loss: 1.6149729704856872
[Epoch 12, Batch 400] loss: 1.5421221554279327
**STATS for Epoch 12** : 
Average training loss: 0.2196
Average validation loss: 1.4671
Validation Accuracy: 0.6894
Overfitting: 1.2475
Best model saved at epoch 12 with validation loss: 1.4671
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 11 is already reported.
  warnings.warn(
[Epoch 13, Batch 100] loss: 1.447108416557312
[Epoch 13, Batch 200] loss: 1.3544422936439515
[Epoch 13, Batch 300] loss: 1.3046961152553558
[Epoch 13, Batch 400] loss: 1.2263809752464294
**STATS for Epoch 13** : 
Average training loss: 0.1757
Average validation loss: 1.1662
Validation Accuracy: 0.7336
Overfitting: 0.9905
Best model saved at epoch 13 with validation loss: 1.1662
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 12 is already reported.
  warnings.warn(
[Epoch 14, Batch 100] loss: 1.1453455048799515
[Epoch 14, Batch 200] loss: 1.084530593752861
[Epoch 14, Batch 300] loss: 1.0288455712795257
[Epoch 14, Batch 400] loss: 0.9785785585641861
**STATS for Epoch 14** : 
Average training loss: 0.1393
Average validation loss: 0.9338
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 13 is already reported.
  warnings.warn(
Validation Accuracy: 0.7744
Overfitting: 0.7945
Best model saved at epoch 14 with validation loss: 0.9338
[Epoch 15, Batch 100] loss: 0.9064124608039856
[Epoch 15, Batch 200] loss: 0.8727860474586486
[Epoch 15, Batch 300] loss: 0.8440892976522446
[Epoch 15, Batch 400] loss: 0.8128885942697525
**STATS for Epoch 15** : 
Average training loss: 0.1156
Average validation loss: 0.7760
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 14 is already reported.
  warnings.warn(
Validation Accuracy: 0.7990
Overfitting: 0.6604
Best model saved at epoch 15 with validation loss: 0.7760
[Epoch 16, Batch 100] loss: 0.7513128906488419
[Epoch 16, Batch 200] loss: 0.7450394290685654
[Epoch 16, Batch 300] loss: 0.7134274411201477
[Epoch 16, Batch 400] loss: 0.7021755588054657
**STATS for Epoch 16** : 
Average training loss: 0.0979
Average validation loss: 0.6730
Validation Accuracy: 0.8154
Overfitting: 0.5751
Best model saved at epoch 16 with validation loss: 0.6730
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 15 is already reported.
  warnings.warn(
[Epoch 17, Batch 100] loss: 0.6483412852883339
[Epoch 17, Batch 200] loss: 0.6446257045865059
[Epoch 17, Batch 300] loss: 0.6373317855596542
[Epoch 17, Batch 400] loss: 0.6143874445557594
**STATS for Epoch 17** : 
Average training loss: 0.0909
Average validation loss: 0.6036
Validation Accuracy: 0.8309
Overfitting: 0.5127
Best model saved at epoch 17 with validation loss: 0.6036
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 16 is already reported.
  warnings.warn(
[Epoch 18, Batch 100] loss: 0.6005987930297851
[Epoch 18, Batch 200] loss: 0.585487831234932
[Epoch 18, Batch 300] loss: 0.5826104953885078
[Epoch 18, Batch 400] loss: 0.5498215785622597
**STATS for Epoch 18** : 
Average training loss: 0.0808
Average validation loss: 0.5568
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 17 is already reported.
  warnings.warn(
Validation Accuracy: 0.8402
Overfitting: 0.4760
Best model saved at epoch 18 with validation loss: 0.5568
[Epoch 19, Batch 100] loss: 0.537095685005188
[Epoch 19, Batch 200] loss: 0.5457482758164406
[Epoch 19, Batch 300] loss: 0.5344018822908402
[Epoch 19, Batch 400] loss: 0.5325099337100982
**STATS for Epoch 19** : 
Average training loss: 0.0746
Average validation loss: 0.5203
Validation Accuracy: 0.8498
Overfitting: 0.4457
Best model saved at epoch 19 with validation loss: 0.5203
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 18 is already reported.
  warnings.warn(
[Epoch 20, Batch 100] loss: 0.5261378520727158
[Epoch 20, Batch 200] loss: 0.5012039741873742
[Epoch 20, Batch 300] loss: 0.4959483379125595
[Epoch 20, Batch 400] loss: 0.5010201305150985
**STATS for Epoch 20** : 
Average training loss: 0.0695
Average validation loss: 0.4914
Validation Accuracy: 0.8560
Overfitting: 0.4219
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 19 is already reported.
  warnings.warn(
Best model saved at epoch 20 with validation loss: 0.4914
[Epoch 21, Batch 100] loss: 0.49610291332006456
[Epoch 21, Batch 200] loss: 0.4816847404837608
[Epoch 21, Batch 300] loss: 0.46618308514356616
[Epoch 21, Batch 400] loss: 0.46359647423028943
**STATS for Epoch 21** : 
Average training loss: 0.0688
Average validation loss: 0.4687
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 20 is already reported.
  warnings.warn(
Validation Accuracy: 0.8612
Overfitting: 0.3999
Best model saved at epoch 21 with validation loss: 0.4687
[Epoch 22, Batch 100] loss: 0.4581556749343872
[Epoch 22, Batch 200] loss: 0.46843511164188384
[Epoch 22, Batch 300] loss: 0.4556209468841553
[Epoch 22, Batch 400] loss: 0.4459641669690609
**STATS for Epoch 22** : 
Average training loss: 0.0646
Average validation loss: 0.4498
Validation Accuracy: 0.8677
Overfitting: 0.3852
Best model saved at epoch 22 with validation loss: 0.4498
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 21 is already reported.
  warnings.warn(
[Epoch 23, Batch 100] loss: 0.4302742128074169
[Epoch 23, Batch 200] loss: 0.439236458837986
[Epoch 23, Batch 300] loss: 0.44215954571962357
[Epoch 23, Batch 400] loss: 0.4321638095378876
**STATS for Epoch 23** : 
Average training loss: 0.0650
Average validation loss: 0.4345
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 22 is already reported.
  warnings.warn(
Validation Accuracy: 0.8728
Overfitting: 0.3694
Best model saved at epoch 23 with validation loss: 0.4345
[Epoch 24, Batch 100] loss: 0.4272718696296215
[Epoch 24, Batch 200] loss: 0.40353221103549003
[Epoch 24, Batch 300] loss: 0.4171951474249363
[Epoch 24, Batch 400] loss: 0.4163821433484554
**STATS for Epoch 24** : 
Average training loss: 0.0660
Average validation loss: 0.4194
Validation Accuracy: 0.8767
Overfitting: 0.3534
Best model saved at epoch 24 with validation loss: 0.4194
Fold 2 validation loss: 0.4194
Mean validation loss across all folds for Trial 1 is 0.8400 with trial config:  l1: 256, l2: 64, lr: 4.207988669606632e-05, batch_size: 64
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 23 is already reported.
  warnings.warn(
[I 2024-11-25 14:52:26,801] Trial 0 finished with value: 0.8400006662966855 and parameters: {'l1': 256, 'l2': 64, 'lr': 4.207988669606632e-05, 'batch_size': 64}. Best is trial 0 with value: 0.8400006662966855.

Selected Hyperparameters for Trial 2:
  l1: 256, l2: 64, lr: 5.3370327626039544e-05, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3051392602920533
[Epoch 1, Batch 200] loss: 2.303325216770172
[Epoch 1, Batch 300] loss: 2.304677519798279
[Epoch 1, Batch 400] loss: 2.3006421303749085
**STATS for Epoch 1** : 
Average training loss: 0.3386
Average validation loss: 2.3001
Validation Accuracy: 0.0827
Overfitting: 1.9615
Best model saved at epoch 1 with validation loss: 2.3001
[Epoch 2, Batch 100] loss: 2.3014583134651185
[Epoch 2, Batch 200] loss: 2.2989903140068053
[Epoch 2, Batch 300] loss: 2.2979519867897036
[Epoch 2, Batch 400] loss: 2.297252013683319
**STATS for Epoch 2** : 
Average training loss: 0.3377
Average validation loss: 2.2952
Validation Accuracy: 0.0996
Overfitting: 1.9576
Best model saved at epoch 2 with validation loss: 2.2952
[Epoch 3, Batch 100] loss: 2.295759952068329
[Epoch 3, Batch 200] loss: 2.2938339161872863
[Epoch 3, Batch 300] loss: 2.2948251700401308
[Epoch 3, Batch 400] loss: 2.28999942779541
**STATS for Epoch 3** : 
Average training loss: 0.3370
Average validation loss: 2.2899
Validation Accuracy: 0.1128
Overfitting: 1.9528
Best model saved at epoch 3 with validation loss: 2.2899
[Epoch 4, Batch 100] loss: 2.288905584812164
[Epoch 4, Batch 200] loss: 2.288514988422394
[Epoch 4, Batch 300] loss: 2.288152048587799
[Epoch 4, Batch 400] loss: 2.285849509239197
**STATS for Epoch 4** : 
Average training loss: 0.3359
Average validation loss: 2.2833
Validation Accuracy: 0.1285
Overfitting: 1.9473
Best model saved at epoch 4 with validation loss: 2.2833
[Epoch 5, Batch 100] loss: 2.283200044631958
[Epoch 5, Batch 200] loss: 2.282797164916992
[Epoch 5, Batch 300] loss: 2.278854637145996
[Epoch 5, Batch 400] loss: 2.277415475845337
**STATS for Epoch 5** : 
Average training loss: 0.3345
Average validation loss: 2.2745
Validation Accuracy: 0.1454
Overfitting: 1.9400
Best model saved at epoch 5 with validation loss: 2.2745
[Epoch 6, Batch 100] loss: 2.2743867087364196
[Epoch 6, Batch 200] loss: 2.2709832215309143
[Epoch 6, Batch 300] loss: 2.269261612892151
[Epoch 6, Batch 400] loss: 2.265179781913757
**STATS for Epoch 6** : 
Average training loss: 0.3331
Average validation loss: 2.2623
Validation Accuracy: 0.1668
Overfitting: 1.9292
Best model saved at epoch 6 with validation loss: 2.2623
[Epoch 7, Batch 100] loss: 2.259643454551697
[Epoch 7, Batch 200] loss: 2.2585327792167664
[Epoch 7, Batch 300] loss: 2.2533743381500244
[Epoch 7, Batch 400] loss: 2.250738117694855
**STATS for Epoch 7** : 
Average training loss: 0.3305
Average validation loss: 2.2447
Validation Accuracy: 0.2201
Overfitting: 1.9142
Best model saved at epoch 7 with validation loss: 2.2447
[Epoch 8, Batch 100] loss: 2.2438128089904783
[Epoch 8, Batch 200] loss: 2.237578239440918
[Epoch 8, Batch 300] loss: 2.2303067588806154
[Epoch 8, Batch 400] loss: 2.224366235733032
**STATS for Epoch 8** : 
Average training loss: 0.3266
Average validation loss: 2.2171
Validation Accuracy: 0.3320
Overfitting: 1.8905
Best model saved at epoch 8 with validation loss: 2.2171
[Epoch 9, Batch 100] loss: 2.2126280784606935
[Epoch 9, Batch 200] loss: 2.2032978749275207
[Epoch 9, Batch 300] loss: 2.1958107328414918
[Epoch 9, Batch 400] loss: 2.186064672470093
**STATS for Epoch 9** : 
Average training loss: 0.3200
Average validation loss: 2.1711
Validation Accuracy: 0.4057
Overfitting: 1.8511
Best model saved at epoch 9 with validation loss: 2.1711
[Epoch 10, Batch 100] loss: 2.1629603505134583
[Epoch 10, Batch 200] loss: 2.1496786952018736
[Epoch 10, Batch 300] loss: 2.132479901313782
[Epoch 10, Batch 400] loss: 2.115213074684143
**STATS for Epoch 10** : 
Average training loss: 0.3081
Average validation loss: 2.0884
Validation Accuracy: 0.4669
Overfitting: 1.7803
Best model saved at epoch 10 with validation loss: 2.0884
[Epoch 11, Batch 100] loss: 2.0751764750480652
[Epoch 11, Batch 200] loss: 2.0448617267608644
[Epoch 11, Batch 300] loss: 2.021512223482132
[Epoch 11, Batch 400] loss: 1.9788410043716431
**STATS for Epoch 11** : 
Average training loss: 0.2858
Average validation loss: 1.9329
Validation Accuracy: 0.5058
Overfitting: 1.6471
Best model saved at epoch 11 with validation loss: 1.9329
[Epoch 12, Batch 100] loss: 1.9036591410636903
[Epoch 12, Batch 200] loss: 1.853254576921463
[Epoch 12, Batch 300] loss: 1.8053943407535553
[Epoch 12, Batch 400] loss: 1.7415949833393096
**STATS for Epoch 12** : 
Average training loss: 0.2491
Average validation loss: 1.6630
Validation Accuracy: 0.6253
Overfitting: 1.4139
Best model saved at epoch 12 with validation loss: 1.6630
[Epoch 13, Batch 100] loss: 1.6208602201938629
[Epoch 13, Batch 200] loss: 1.5458135199546814
[Epoch 13, Batch 300] loss: 1.4700998091697692
[Epoch 13, Batch 400] loss: 1.3910761296749115
**STATS for Epoch 13** : 
Average training loss: 0.1953
Average validation loss: 1.2941
Validation Accuracy: 0.7354
Overfitting: 1.0988
Best model saved at epoch 13 with validation loss: 1.2941
[Epoch 14, Batch 100] loss: 1.248388568162918
[Epoch 14, Batch 200] loss: 1.1806437784433366
[Epoch 14, Batch 300] loss: 1.103417711853981
[Epoch 14, Batch 400] loss: 1.0319827646017075
**STATS for Epoch 14** : 
Average training loss: 0.1439
Average validation loss: 0.9633
Validation Accuracy: 0.7779
Overfitting: 0.8194
Best model saved at epoch 14 with validation loss: 0.9633
[Epoch 15, Batch 100] loss: 0.93743910074234
[Epoch 15, Batch 200] loss: 0.8887163656949997
[Epoch 15, Batch 300] loss: 0.8384251034259796
[Epoch 15, Batch 400] loss: 0.7985799390077591
**STATS for Epoch 15** : 
Average training loss: 0.1131
Average validation loss: 0.7581
Validation Accuracy: 0.8068
Overfitting: 0.6450
Best model saved at epoch 15 with validation loss: 0.7581
[Epoch 16, Batch 100] loss: 0.7466449648141861
[Epoch 16, Batch 200] loss: 0.7020302104949951
[Epoch 16, Batch 300] loss: 0.6943896299600602
[Epoch 16, Batch 400] loss: 0.6732753738760948
**STATS for Epoch 16** : 
Average training loss: 0.0936
Average validation loss: 0.6369
Validation Accuracy: 0.8298
Overfitting: 0.5432
Best model saved at epoch 16 with validation loss: 0.6369
[Epoch 17, Batch 100] loss: 0.6187807080149651
[Epoch 17, Batch 200] loss: 0.615956554710865
[Epoch 17, Batch 300] loss: 0.5952576249837875
[Epoch 17, Batch 400] loss: 0.5798595589399338
**STATS for Epoch 17** : 
Average training loss: 0.0854
Average validation loss: 0.5600
Validation Accuracy: 0.8455
Overfitting: 0.4745
Best model saved at epoch 17 with validation loss: 0.5600
[Epoch 18, Batch 100] loss: 0.5537789610028266
[Epoch 18, Batch 200] loss: 0.5595584884285927
[Epoch 18, Batch 300] loss: 0.5371235510706902
[Epoch 18, Batch 400] loss: 0.5112232708930969
**STATS for Epoch 18** : 
Average training loss: 0.0749
Average validation loss: 0.5063
Validation Accuracy: 0.8596
Overfitting: 0.4315
Best model saved at epoch 18 with validation loss: 0.5063
[Epoch 19, Batch 100] loss: 0.5094135922193527
[Epoch 19, Batch 200] loss: 0.503765558898449
[Epoch 19, Batch 300] loss: 0.4934088572859764
[Epoch 19, Batch 400] loss: 0.4714403708279133
**STATS for Epoch 19** : 
Average training loss: 0.0681
Average validation loss: 0.4678
Validation Accuracy: 0.8675
Overfitting: 0.3996
Best model saved at epoch 19 with validation loss: 0.4678
[Epoch 20, Batch 100] loss: 0.45868970215320587
[Epoch 20, Batch 200] loss: 0.47912841796875
[Epoch 20, Batch 300] loss: 0.452817240357399
[Epoch 20, Batch 400] loss: 0.43903428241610526
**STATS for Epoch 20** : 
Average training loss: 0.0653
Average validation loss: 0.4365
Validation Accuracy: 0.8756
Overfitting: 0.3712
Best model saved at epoch 20 with validation loss: 0.4365
[Epoch 21, Batch 100] loss: 0.4366567921638489
[Epoch 21, Batch 200] loss: 0.4255920845270157
[Epoch 21, Batch 300] loss: 0.4215392817556858
[Epoch 21, Batch 400] loss: 0.43452662020921706
**STATS for Epoch 21** : 
Average training loss: 0.0616
Average validation loss: 0.4128
Validation Accuracy: 0.8814
Overfitting: 0.3511
Best model saved at epoch 21 with validation loss: 0.4128
[Epoch 22, Batch 100] loss: 0.41366795539855955
[Epoch 22, Batch 200] loss: 0.4065945076942444
[Epoch 22, Batch 300] loss: 0.39856808915734293
[Epoch 22, Batch 400] loss: 0.4030395647883415
**STATS for Epoch 22** : 
Average training loss: 0.0596
Average validation loss: 0.3918
Validation Accuracy: 0.8879
Overfitting: 0.3321
Best model saved at epoch 22 with validation loss: 0.3918
[Epoch 23, Batch 100] loss: 0.3898050065338612
[Epoch 23, Batch 200] loss: 0.3840512050688267
[Epoch 23, Batch 300] loss: 0.3962939538061619
[Epoch 23, Batch 400] loss: 0.388767564445734
**STATS for Epoch 23** : 
Average training loss: 0.0538
Average validation loss: 0.3754
Validation Accuracy: 0.8912
Overfitting: 0.3216
Best model saved at epoch 23 with validation loss: 0.3754
[Epoch 24, Batch 100] loss: 0.36077447682619096
[Epoch 24, Batch 200] loss: 0.384483150690794
[Epoch 24, Batch 300] loss: 0.37012873753905295
[Epoch 24, Batch 400] loss: 0.37363027915358543
**STATS for Epoch 24** : 
Average training loss: 0.0520
Average validation loss: 0.3603
Validation Accuracy: 0.8953
Overfitting: 0.3083
Best model saved at epoch 24 with validation loss: 0.3603
Fold 1 validation loss: 0.3603
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.305051896572113
[Epoch 1, Batch 200] loss: 2.3038506865501405
[Epoch 1, Batch 300] loss: 2.303040063381195
[Epoch 1, Batch 400] loss: 2.3018796467781066
**STATS for Epoch 1** : 
Average training loss: 0.3385
Average validation loss: 2.3007
Validation Accuracy: 0.1251
Overfitting: 1.9622
Best model saved at epoch 1 with validation loss: 2.3007
[Epoch 2, Batch 100] loss: 2.301184983253479
[Epoch 2, Batch 200] loss: 2.2995148849487306
[Epoch 2, Batch 300] loss: 2.298169991970062
[Epoch 2, Batch 400] loss: 2.2958167481422422
**STATS for Epoch 2** : 
Average training loss: 0.3378
Average validation loss: 2.2961
Validation Accuracy: 0.1509
Overfitting: 1.9582
Best model saved at epoch 2 with validation loss: 2.2961
[Epoch 3, Batch 100] loss: 2.295811266899109
[Epoch 3, Batch 200] loss: 2.2952444100379945
[Epoch 3, Batch 300] loss: 2.2934959626197813
[Epoch 3, Batch 400] loss: 2.2924247360229493
**STATS for Epoch 3** : 
Average training loss: 0.3369
Average validation loss: 2.2912
Validation Accuracy: 0.1759
Overfitting: 1.9543
Best model saved at epoch 3 with validation loss: 2.2912
[Epoch 4, Batch 100] loss: 2.290821089744568
[Epoch 4, Batch 200] loss: 2.29010005235672
[Epoch 4, Batch 300] loss: 2.289066209793091
[Epoch 4, Batch 400] loss: 2.28512366771698
**STATS for Epoch 4** : 
Average training loss: 0.3366
Average validation loss: 2.2859
Validation Accuracy: 0.1984
Overfitting: 1.9493
Best model saved at epoch 4 with validation loss: 2.2859
[Epoch 5, Batch 100] loss: 2.2842131543159483
[Epoch 5, Batch 200] loss: 2.283758635520935
[Epoch 5, Batch 300] loss: 2.283597853183746
[Epoch 5, Batch 400] loss: 2.2816419076919554
**STATS for Epoch 5** : 
Average training loss: 0.3354
Average validation loss: 2.2795
Validation Accuracy: 0.2245
Overfitting: 1.9441
Best model saved at epoch 5 with validation loss: 2.2795
[Epoch 6, Batch 100] loss: 2.279074330329895
[Epoch 6, Batch 200] loss: 2.27823162317276
[Epoch 6, Batch 300] loss: 2.274856266975403
[Epoch 6, Batch 400] loss: 2.2738410592079163
**STATS for Epoch 6** : 
Average training loss: 0.3342
Average validation loss: 2.2716
Validation Accuracy: 0.2583
Overfitting: 1.9375
Best model saved at epoch 6 with validation loss: 2.2716
[Epoch 7, Batch 100] loss: 2.271761360168457
[Epoch 7, Batch 200] loss: 2.2683996772766113
[Epoch 7, Batch 300] loss: 2.265723729133606
[Epoch 7, Batch 400] loss: 2.264310200214386
**STATS for Epoch 7** : 
Average training loss: 0.3329
Average validation loss: 2.2615
Validation Accuracy: 0.3013
Overfitting: 1.9286
Best model saved at epoch 7 with validation loss: 2.2615
[Epoch 8, Batch 100] loss: 2.2605450129508973
[Epoch 8, Batch 200] loss: 2.257599239349365
[Epoch 8, Batch 300] loss: 2.2548946571350097
[Epoch 8, Batch 400] loss: 2.2517144775390623
**STATS for Epoch 8** : 
Average training loss: 0.3309
Average validation loss: 2.2480
Validation Accuracy: 0.3694
Overfitting: 1.9170
Best model saved at epoch 8 with validation loss: 2.2480
[Epoch 9, Batch 100] loss: 2.246429054737091
[Epoch 9, Batch 200] loss: 2.2435777974128723
[Epoch 9, Batch 300] loss: 2.2375224447250366
[Epoch 9, Batch 400] loss: 2.2346040272712706
**STATS for Epoch 9** : 
Average training loss: 0.3282
Average validation loss: 2.2289
Validation Accuracy: 0.4373
Overfitting: 1.9007
Best model saved at epoch 9 with validation loss: 2.2289
[Epoch 10, Batch 100] loss: 2.2253545475006105
[Epoch 10, Batch 200] loss: 2.2206530666351316
[Epoch 10, Batch 300] loss: 2.2163808703422547
[Epoch 10, Batch 400] loss: 2.208735537528992
**STATS for Epoch 10** : 
Average training loss: 0.3245
Average validation loss: 2.2007
Validation Accuracy: 0.4732
Overfitting: 1.8763
Best model saved at epoch 10 with validation loss: 2.2007
[Epoch 11, Batch 100] loss: 2.1973784804344176
[Epoch 11, Batch 200] loss: 2.1875922775268553
[Epoch 11, Batch 300] loss: 2.181172664165497
[Epoch 11, Batch 400] loss: 2.1684735870361327
**STATS for Epoch 11** : 
Average training loss: 0.3182
Average validation loss: 2.1565
Validation Accuracy: 0.4862
Overfitting: 1.8383
Best model saved at epoch 11 with validation loss: 2.1565
[Epoch 12, Batch 100] loss: 2.1500708484649658
[Epoch 12, Batch 200] loss: 2.1378403401374815
[Epoch 12, Batch 300] loss: 2.122008376121521
[Epoch 12, Batch 400] loss: 2.1049313855171206
**STATS for Epoch 12** : 
Average training loss: 0.3078
Average validation loss: 2.0828
Validation Accuracy: 0.4995
Overfitting: 1.7749
Best model saved at epoch 12 with validation loss: 2.0828
[Epoch 13, Batch 100] loss: 2.070662875175476
[Epoch 13, Batch 200] loss: 2.0454101085662844
[Epoch 13, Batch 300] loss: 2.026829252243042
[Epoch 13, Batch 400] loss: 1.9978561317920684
**STATS for Epoch 13** : 
Average training loss: 0.2881
Average validation loss: 1.9512
Validation Accuracy: 0.5464
Overfitting: 1.6630
Best model saved at epoch 13 with validation loss: 1.9512
[Epoch 14, Batch 100] loss: 1.9297876143455506
[Epoch 14, Batch 200] loss: 1.8934813630580902
[Epoch 14, Batch 300] loss: 1.841519558429718
[Epoch 14, Batch 400] loss: 1.787233999967575
**STATS for Epoch 14** : 
Average training loss: 0.2556
Average validation loss: 1.7164
Validation Accuracy: 0.6480
Overfitting: 1.4608
Best model saved at epoch 14 with validation loss: 1.7164
[Epoch 15, Batch 100] loss: 1.6726975059509277
[Epoch 15, Batch 200] loss: 1.6175315976142883
[Epoch 15, Batch 300] loss: 1.545723705291748
[Epoch 15, Batch 400] loss: 1.4623050212860107
**STATS for Epoch 15** : 
Average training loss: 0.2055
Average validation loss: 1.3670
Validation Accuracy: 0.7615
Overfitting: 1.1615
Best model saved at epoch 15 with validation loss: 1.3670
[Epoch 16, Batch 100] loss: 1.3236167442798614
[Epoch 16, Batch 200] loss: 1.251085729598999
[Epoch 16, Batch 300] loss: 1.1535104125738145
[Epoch 16, Batch 400] loss: 1.0981965696811675
**STATS for Epoch 16** : 
Average training loss: 0.1523
Average validation loss: 1.0121
Validation Accuracy: 0.8114
Overfitting: 0.8598
Best model saved at epoch 16 with validation loss: 1.0121
[Epoch 17, Batch 100] loss: 0.9751447570323944
[Epoch 17, Batch 200] loss: 0.9085197007656097
[Epoch 17, Batch 300] loss: 0.8549423778057098
[Epoch 17, Batch 400] loss: 0.8073460006713867
**STATS for Epoch 17** : 
Average training loss: 0.1140
Average validation loss: 0.7583
Validation Accuracy: 0.8350
Overfitting: 0.6443
Best model saved at epoch 17 with validation loss: 0.7583
[Epoch 18, Batch 100] loss: 0.7422799038887024
[Epoch 18, Batch 200] loss: 0.6848501664400101
[Epoch 18, Batch 300] loss: 0.6646029618382454
[Epoch 18, Batch 400] loss: 0.624489731490612
**STATS for Epoch 18** : 
Average training loss: 0.0883
Average validation loss: 0.6036
Validation Accuracy: 0.8547
Overfitting: 0.5153
Best model saved at epoch 18 with validation loss: 0.6036
[Epoch 19, Batch 100] loss: 0.5879282376170158
[Epoch 19, Batch 200] loss: 0.5679528337717056
[Epoch 19, Batch 300] loss: 0.5337153413891792
[Epoch 19, Batch 400] loss: 0.5272737500071526
**STATS for Epoch 19** : 
Average training loss: 0.0739
Average validation loss: 0.5119
Validation Accuracy: 0.8685
Overfitting: 0.4380
Best model saved at epoch 19 with validation loss: 0.5119
[Epoch 20, Batch 100] loss: 0.4919955477118492
[Epoch 20, Batch 200] loss: 0.4827513384819031
[Epoch 20, Batch 300] loss: 0.47516454458236695
[Epoch 20, Batch 400] loss: 0.44879752174019816
**STATS for Epoch 20** : 
Average training loss: 0.0665
Average validation loss: 0.4527
Validation Accuracy: 0.8786
Overfitting: 0.3862
Best model saved at epoch 20 with validation loss: 0.4527
[Epoch 21, Batch 100] loss: 0.4422870662808418
[Epoch 21, Batch 200] loss: 0.4318811073899269
[Epoch 21, Batch 300] loss: 0.41806200459599496
[Epoch 21, Batch 400] loss: 0.40500175431370733
**STATS for Epoch 21** : 
Average training loss: 0.0594
Average validation loss: 0.4102
Validation Accuracy: 0.8876
Overfitting: 0.3508
Best model saved at epoch 21 with validation loss: 0.4102
[Epoch 22, Batch 100] loss: 0.3982148043811321
[Epoch 22, Batch 200] loss: 0.401419448107481
[Epoch 22, Batch 300] loss: 0.3850629717111588
[Epoch 22, Batch 400] loss: 0.37610203608870507
**STATS for Epoch 22** : 
Average training loss: 0.0523
Average validation loss: 0.3798
Validation Accuracy: 0.8946
Overfitting: 0.3275
Best model saved at epoch 22 with validation loss: 0.3798
[Epoch 23, Batch 100] loss: 0.37561028644442557
[Epoch 23, Batch 200] loss: 0.3515065860748291
[Epoch 23, Batch 300] loss: 0.34743338480591773
[Epoch 23, Batch 400] loss: 0.3592057529091835
**STATS for Epoch 23** : 
Average training loss: 0.0517
Average validation loss: 0.3536
Validation Accuracy: 0.9017
Overfitting: 0.3019
Best model saved at epoch 23 with validation loss: 0.3536
[Epoch 24, Batch 100] loss: 0.34388808503746987
[Epoch 24, Batch 200] loss: 0.3307855634391308
[Epoch 24, Batch 300] loss: 0.33792023837566376
[Epoch 24, Batch 400] loss: 0.3361641734838486
**STATS for Epoch 24** : 
Average training loss: 0.0480
Average validation loss: 0.3341
Validation Accuracy: 0.9060
Overfitting: 0.2861
Best model saved at epoch 24 with validation loss: 0.3341
Fold 2 validation loss: 0.3341
Mean validation loss across all folds for Trial 2 is 0.3472 with trial config:  l1: 256, l2: 64, lr: 5.3370327626039544e-05, batch_size: 64
[I 2024-11-25 15:01:27,915] Trial 1 finished with value: 0.3472399961973813 and parameters: {'l1': 256, 'l2': 64, 'lr': 5.3370327626039544e-05, 'batch_size': 64}. Best is trial 1 with value: 0.3472399961973813.

Selected Hyperparameters for Trial 3:
  l1: 128, l2: 128, lr: 0.0006672367170464204, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3023355555534364
[Epoch 1, Batch 200] loss: 2.2885483837127687
[Epoch 1, Batch 300] loss: 2.269343543052673
[Epoch 1, Batch 400] loss: 2.2359094214439392
[Epoch 1, Batch 500] loss: 2.133689135313034
[Epoch 1, Batch 600] loss: 1.7220145905017852
[Epoch 1, Batch 700] loss: 0.9121587008237839
[Epoch 1, Batch 800] loss: 0.630955001860857
[Epoch 1, Batch 900] loss: 0.5552061526477337
[Epoch 1, Batch 1000] loss: 0.48368909806013105
[Epoch 1, Batch 1100] loss: 0.4249630621820688
[Epoch 1, Batch 1200] loss: 0.3535983310639858
[Epoch 1, Batch 1300] loss: 0.28876114673912523
[Epoch 1, Batch 1400] loss: 0.32076486920937897
[Epoch 1, Batch 1500] loss: 0.2671401097625494
[Epoch 1, Batch 1600] loss: 0.28408267328515646
[Epoch 1, Batch 1700] loss: 0.23857581762596966
[Epoch 1, Batch 1800] loss: 0.24393377589061857
**STATS for Epoch 1** : 
Average training loss: 0.0082
Average validation loss: 0.2057
Validation Accuracy: 0.9384
Overfitting: 0.1976
Best model saved at epoch 1 with validation loss: 0.2057
[Epoch 2, Batch 100] loss: 0.21732664197683335
[Epoch 2, Batch 200] loss: 0.22527654698118568
[Epoch 2, Batch 300] loss: 0.18026679091155529
[Epoch 2, Batch 400] loss: 0.16835103609599172
[Epoch 2, Batch 500] loss: 0.19221627102233468
[Epoch 2, Batch 600] loss: 0.17419483015313744
[Epoch 2, Batch 700] loss: 0.15610715500079095
[Epoch 2, Batch 800] loss: 0.20461836773902178
[Epoch 2, Batch 900] loss: 0.16782391258515417
[Epoch 2, Batch 1000] loss: 0.14225083125755192
[Epoch 2, Batch 1100] loss: 0.15741877540014684
[Epoch 2, Batch 1200] loss: 0.15387187791988255
[Epoch 2, Batch 1300] loss: 0.13776732646860182
[Epoch 2, Batch 1400] loss: 0.14058119018562137
[Epoch 2, Batch 1500] loss: 0.14721040142234415
[Epoch 2, Batch 1600] loss: 0.1221808169875294
[Epoch 2, Batch 1700] loss: 0.1452796075353399
[Epoch 2, Batch 1800] loss: 0.1364577507530339
**STATS for Epoch 2** : 
Average training loss: 0.0060
Average validation loss: 0.1556
Validation Accuracy: 0.9521
Overfitting: 0.1496
Best model saved at epoch 2 with validation loss: 0.1556
[Epoch 3, Batch 100] loss: 0.10647949334932491
[Epoch 3, Batch 200] loss: 0.10904426767490805
[Epoch 3, Batch 300] loss: 0.11828604059293867
[Epoch 3, Batch 400] loss: 0.12381030567921698
[Epoch 3, Batch 500] loss: 0.1648527683969587
[Epoch 3, Batch 600] loss: 0.08830250110244378
[Epoch 3, Batch 700] loss: 0.13282306420616805
[Epoch 3, Batch 800] loss: 0.12267920708749443
[Epoch 3, Batch 900] loss: 0.09440818037372083
[Epoch 3, Batch 1000] loss: 0.09471167300594971
[Epoch 3, Batch 1100] loss: 0.10028542757732793
[Epoch 3, Batch 1200] loss: 0.12433317585382611
[Epoch 3, Batch 1300] loss: 0.10036203832365573
[Epoch 3, Batch 1400] loss: 0.11555853724479676
[Epoch 3, Batch 1500] loss: 0.11169879342895
[Epoch 3, Batch 1600] loss: 0.0809305247082375
[Epoch 3, Batch 1700] loss: 0.08204367633210495
[Epoch 3, Batch 1800] loss: 0.09320464533753693
**STATS for Epoch 3** : 
Average training loss: 0.0044
Average validation loss: 0.1090
Validation Accuracy: 0.9662
Overfitting: 0.1046
Best model saved at epoch 3 with validation loss: 0.1090
[Epoch 4, Batch 100] loss: 0.07804298032075167
[Epoch 4, Batch 200] loss: 0.1022766003862489
[Epoch 4, Batch 300] loss: 0.07700936431530864
[Epoch 4, Batch 400] loss: 0.07465432197204791
[Epoch 4, Batch 500] loss: 0.10243507704231888
[Epoch 4, Batch 600] loss: 0.11470055773563217
[Epoch 4, Batch 700] loss: 0.08499648324213922
[Epoch 4, Batch 800] loss: 0.08770724628237075
[Epoch 4, Batch 900] loss: 0.06646376510441769
[Epoch 4, Batch 1000] loss: 0.09767781107337214
[Epoch 4, Batch 1100] loss: 0.09749926049495115
[Epoch 4, Batch 1200] loss: 0.08358801711816341
[Epoch 4, Batch 1300] loss: 0.06997790356050246
[Epoch 4, Batch 1400] loss: 0.06575542731676251
[Epoch 4, Batch 1500] loss: 0.07758150905370713
[Epoch 4, Batch 1600] loss: 0.07612144842743873
[Epoch 4, Batch 1700] loss: 0.10579062638455071
[Epoch 4, Batch 1800] loss: 0.06496080290176906
**STATS for Epoch 4** : 
Average training loss: 0.0032
Average validation loss: 0.0863
Validation Accuracy: 0.9728
Overfitting: 0.0830
Best model saved at epoch 4 with validation loss: 0.0863
[Epoch 5, Batch 100] loss: 0.07344740195199848
[Epoch 5, Batch 200] loss: 0.07591549946344457
[Epoch 5, Batch 300] loss: 0.07280200558947399
[Epoch 5, Batch 400] loss: 0.05578865900984965
[Epoch 5, Batch 500] loss: 0.06738696786982473
[Epoch 5, Batch 600] loss: 0.07357581368181855
[Epoch 5, Batch 700] loss: 0.07928336364682764
[Epoch 5, Batch 800] loss: 0.06657162087154575
[Epoch 5, Batch 900] loss: 0.06833017886208836
[Epoch 5, Batch 1000] loss: 0.07182465473655611
[Epoch 5, Batch 1100] loss: 0.0826889211195521
[Epoch 5, Batch 1200] loss: 0.062484209324466064
[Epoch 5, Batch 1300] loss: 0.07590114831691608
[Epoch 5, Batch 1400] loss: 0.06415368540503551
[Epoch 5, Batch 1500] loss: 0.0681188160617603
[Epoch 5, Batch 1600] loss: 0.06968329337309115
[Epoch 5, Batch 1700] loss: 0.07259315266041085
[Epoch 5, Batch 1800] loss: 0.06628866664133966
**STATS for Epoch 5** : 
Average training loss: 0.0025
Average validation loss: 0.0765
Validation Accuracy: 0.9768
Overfitting: 0.0739
Best model saved at epoch 5 with validation loss: 0.0765
[Epoch 6, Batch 100] loss: 0.053773648387286814
[Epoch 6, Batch 200] loss: 0.04656123019754887
[Epoch 6, Batch 300] loss: 0.06944571960018947
[Epoch 6, Batch 400] loss: 0.07620637730811723
[Epoch 6, Batch 500] loss: 0.04912231794267427
[Epoch 6, Batch 600] loss: 0.05091523181356024
[Epoch 6, Batch 700] loss: 0.06940656670485623
[Epoch 6, Batch 800] loss: 0.06554334772983567
[Epoch 6, Batch 900] loss: 0.06454225606285036
[Epoch 6, Batch 1000] loss: 0.05680580956977792
[Epoch 6, Batch 1100] loss: 0.04129695356823504
[Epoch 6, Batch 1200] loss: 0.054296980329672805
[Epoch 6, Batch 1300] loss: 0.06842563680489548
[Epoch 6, Batch 1400] loss: 0.06998987555271015
[Epoch 6, Batch 1500] loss: 0.06483948944020085
[Epoch 6, Batch 1600] loss: 0.05350634094356792
[Epoch 6, Batch 1700] loss: 0.0519741453952156
[Epoch 6, Batch 1800] loss: 0.07096759692532942
**STATS for Epoch 6** : 
Average training loss: 0.0019
Average validation loss: 0.0670
Validation Accuracy: 0.9795
Overfitting: 0.0651
Best model saved at epoch 6 with validation loss: 0.0670
[Epoch 7, Batch 100] loss: 0.047538097272627054
[Epoch 7, Batch 200] loss: 0.05967938352958299
[Epoch 7, Batch 300] loss: 0.05648194199369755
[Epoch 7, Batch 400] loss: 0.04714598718623165
[Epoch 7, Batch 500] loss: 0.06177394087018911
[Epoch 7, Batch 600] loss: 0.053173202134203165
[Epoch 7, Batch 700] loss: 0.044416501957166475
[Epoch 7, Batch 800] loss: 0.06797901191923302
[Epoch 7, Batch 900] loss: 0.04163213328894926
[Epoch 7, Batch 1000] loss: 0.047428609409253114
[Epoch 7, Batch 1100] loss: 0.046405901187099516
[Epoch 7, Batch 1200] loss: 0.048741644176188856
[Epoch 7, Batch 1300] loss: 0.05441472301230533
[Epoch 7, Batch 1400] loss: 0.058654738983605056
[Epoch 7, Batch 1500] loss: 0.052120606614043934
[Epoch 7, Batch 1600] loss: 0.042940092164062665
[Epoch 7, Batch 1700] loss: 0.05767197956913151
[Epoch 7, Batch 1800] loss: 0.04654807825019816
**STATS for Epoch 7** : 
Average training loss: 0.0027
Average validation loss: 0.0698
Validation Accuracy: 0.9776
Overfitting: 0.0671
[Epoch 8, Batch 100] loss: 0.04814909668348264
[Epoch 8, Batch 200] loss: 0.025216892599710262
[Epoch 8, Batch 300] loss: 0.037095983387553134
[Epoch 8, Batch 400] loss: 0.034675602711795366
[Epoch 8, Batch 500] loss: 0.03320783175266115
[Epoch 8, Batch 600] loss: 0.06144318037215271
[Epoch 8, Batch 700] loss: 0.04967048209335189
[Epoch 8, Batch 800] loss: 0.03891569830360822
[Epoch 8, Batch 900] loss: 0.041752714919712164
[Epoch 8, Batch 1000] loss: 0.053645082433940845
[Epoch 8, Batch 1100] loss: 0.050356294849189
[Epoch 8, Batch 1200] loss: 0.0536146707640728
[Epoch 8, Batch 1300] loss: 0.04933041753392899
[Epoch 8, Batch 1400] loss: 0.04974047043069731
[Epoch 8, Batch 1500] loss: 0.06366287948767421
[Epoch 8, Batch 1600] loss: 0.045722440122626724
[Epoch 8, Batch 1700] loss: 0.04730064309667796
[Epoch 8, Batch 1800] loss: 0.03814733807055745
**STATS for Epoch 8** : 
Average training loss: 0.0019
Average validation loss: 0.0649
Validation Accuracy: 0.9803
Overfitting: 0.0630
Best model saved at epoch 8 with validation loss: 0.0649
[Epoch 9, Batch 100] loss: 0.030504243005416355
[Epoch 9, Batch 200] loss: 0.03723150688922033
[Epoch 9, Batch 300] loss: 0.0393277724244399
[Epoch 9, Batch 400] loss: 0.05302081998626818
[Epoch 9, Batch 500] loss: 0.035249764657346534
[Epoch 9, Batch 600] loss: 0.054258199234027416
[Epoch 9, Batch 700] loss: 0.038014379855594596
[Epoch 9, Batch 800] loss: 0.05331110892351717
[Epoch 9, Batch 900] loss: 0.03475632496614708
[Epoch 9, Batch 1000] loss: 0.03796921602304792
[Epoch 9, Batch 1100] loss: 0.04609784623753512
[Epoch 9, Batch 1200] loss: 0.035500458571186756
[Epoch 9, Batch 1300] loss: 0.037903077917871994
[Epoch 9, Batch 1400] loss: 0.028052818492578808
[Epoch 9, Batch 1500] loss: 0.040274576299416366
[Epoch 9, Batch 1600] loss: 0.060486278441167086
[Epoch 9, Batch 1700] loss: 0.042536860171239824
[Epoch 9, Batch 1800] loss: 0.039814176947547825
**STATS for Epoch 9** : 
Average training loss: 0.0018
Average validation loss: 0.0635
Validation Accuracy: 0.9807
Overfitting: 0.0617
Best model saved at epoch 9 with validation loss: 0.0635
[Epoch 10, Batch 100] loss: 0.0411947120615514
[Epoch 10, Batch 200] loss: 0.04415119621407939
[Epoch 10, Batch 300] loss: 0.03872783662431175
[Epoch 10, Batch 400] loss: 0.03402623003901681
[Epoch 10, Batch 500] loss: 0.03167114984287764
[Epoch 10, Batch 600] loss: 0.043273381258186416
[Epoch 10, Batch 700] loss: 0.03971098941692617
[Epoch 10, Batch 800] loss: 0.04070179194328375
[Epoch 10, Batch 900] loss: 0.03923856539251574
[Epoch 10, Batch 1000] loss: 0.030288015585683753
[Epoch 10, Batch 1100] loss: 0.03882474285957869
[Epoch 10, Batch 1200] loss: 0.034822189354454164
[Epoch 10, Batch 1300] loss: 0.028969362680072663
[Epoch 10, Batch 1400] loss: 0.03138835679666954
[Epoch 10, Batch 1500] loss: 0.02880332673463272
[Epoch 10, Batch 1600] loss: 0.03649181544897147
[Epoch 10, Batch 1700] loss: 0.03637809289662983
[Epoch 10, Batch 1800] loss: 0.03547880470112432
**STATS for Epoch 10** : 
Average training loss: 0.0009
Average validation loss: 0.0583
Validation Accuracy: 0.9826
Overfitting: 0.0574
Best model saved at epoch 10 with validation loss: 0.0583
[Epoch 11, Batch 100] loss: 0.037584389551557254
[Epoch 11, Batch 200] loss: 0.023794796238435084
[Epoch 11, Batch 300] loss: 0.024650296029576566
[Epoch 11, Batch 400] loss: 0.04663833619299112
[Epoch 11, Batch 500] loss: 0.023453696502474485
[Epoch 11, Batch 600] loss: 0.03691322909435257
[Epoch 11, Batch 700] loss: 0.02990297718170041
[Epoch 11, Batch 800] loss: 0.04380328474449925
[Epoch 11, Batch 900] loss: 0.038954837824494465
[Epoch 11, Batch 1000] loss: 0.03349153351358836
[Epoch 11, Batch 1100] loss: 0.040006328257877616
[Epoch 11, Batch 1200] loss: 0.03491457681178872
[Epoch 11, Batch 1300] loss: 0.026375341053499143
[Epoch 11, Batch 1400] loss: 0.027221015658724354
[Epoch 11, Batch 1500] loss: 0.024453308629272214
[Epoch 11, Batch 1600] loss: 0.031051330069167306
[Epoch 11, Batch 1700] loss: 0.031144388752436497
[Epoch 11, Batch 1800] loss: 0.040502308908908165
**STATS for Epoch 11** : 
Average training loss: 0.0016
Average validation loss: 0.0607
Validation Accuracy: 0.9818
Overfitting: 0.0592
[Epoch 12, Batch 100] loss: 0.03223241958177823
[Epoch 12, Batch 200] loss: 0.01968070771312341
[Epoch 12, Batch 300] loss: 0.029169101896550274
[Epoch 12, Batch 400] loss: 0.05323356214168598
[Epoch 12, Batch 500] loss: 0.030592577319475824
[Epoch 12, Batch 600] loss: 0.023844132220037863
[Epoch 12, Batch 700] loss: 0.031500720531767
[Epoch 12, Batch 800] loss: 0.019506615780483117
[Epoch 12, Batch 900] loss: 0.01773053140990669
[Epoch 12, Batch 1000] loss: 0.031570094372145835
[Epoch 12, Batch 1100] loss: 0.032508527874815625
[Epoch 12, Batch 1200] loss: 0.02611881246957637
[Epoch 12, Batch 1300] loss: 0.023920797379978466
[Epoch 12, Batch 1400] loss: 0.022852311452734284
[Epoch 12, Batch 1500] loss: 0.03374305053810531
[Epoch 12, Batch 1600] loss: 0.04313755481995031
[Epoch 12, Batch 1700] loss: 0.024968387363187503
[Epoch 12, Batch 1800] loss: 0.03445654365867085
**STATS for Epoch 12** : 
Average training loss: 0.0014
Average validation loss: 0.0602
Validation Accuracy: 0.9822
Overfitting: 0.0588
[Epoch 13, Batch 100] loss: 0.02010071530705318
[Epoch 13, Batch 200] loss: 0.02422118854308792
[Epoch 13, Batch 300] loss: 0.028339671580979484
[Epoch 13, Batch 400] loss: 0.03437323303340236
[Epoch 13, Batch 500] loss: 0.0333508470239758
[Epoch 13, Batch 600] loss: 0.02559912994991464
[Epoch 13, Batch 700] loss: 0.02280861969135003
[Epoch 13, Batch 800] loss: 0.035988101780894795
[Epoch 13, Batch 900] loss: 0.019502678505959922
[Epoch 13, Batch 1000] loss: 0.032493752868031155
[Epoch 13, Batch 1100] loss: 0.028455144085710343
[Epoch 13, Batch 1200] loss: 0.025939443084498633
[Epoch 13, Batch 1300] loss: 0.035642144869125335
[Epoch 13, Batch 1400] loss: 0.029195683853322406
[Epoch 13, Batch 1500] loss: 0.021877541515841585
[Epoch 13, Batch 1600] loss: 0.03636714920638042
[Epoch 13, Batch 1700] loss: 0.023375502876588142
[Epoch 13, Batch 1800] loss: 0.023656027003016788
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0532
Validation Accuracy: 0.9847
Overfitting: 0.0524
Best model saved at epoch 13 with validation loss: 0.0532
[Epoch 14, Batch 100] loss: 0.025559931262760075
[Epoch 14, Batch 200] loss: 0.029182706306892216
[Epoch 14, Batch 300] loss: 0.017288522670278327
[Epoch 14, Batch 400] loss: 0.024946557822622707
[Epoch 14, Batch 500] loss: 0.02147535418291227
[Epoch 14, Batch 600] loss: 0.018705430446425454
[Epoch 14, Batch 700] loss: 0.013717144327474671
[Epoch 14, Batch 800] loss: 0.020051169797661715
[Epoch 14, Batch 900] loss: 0.019230264972538862
[Epoch 14, Batch 1000] loss: 0.028956494888261658
[Epoch 14, Batch 1100] loss: 0.024816405158344424
[Epoch 14, Batch 1200] loss: 0.023733894575307203
[Epoch 14, Batch 1300] loss: 0.021524668818237842
[Epoch 14, Batch 1400] loss: 0.032992763064466996
[Epoch 14, Batch 1500] loss: 0.03649827520323015
[Epoch 14, Batch 1600] loss: 0.03144976617917564
[Epoch 14, Batch 1700] loss: 0.02844328393068281
[Epoch 14, Batch 1800] loss: 0.012500064318501244
**STATS for Epoch 14** : 
Average training loss: 0.0010
Average validation loss: 0.0610
Validation Accuracy: 0.9823
Overfitting: 0.0600
[Epoch 15, Batch 100] loss: 0.0216915393940144
[Epoch 15, Batch 200] loss: 0.024090756230289116
[Epoch 15, Batch 300] loss: 0.02343595912818273
[Epoch 15, Batch 400] loss: 0.016599349743737547
[Epoch 15, Batch 500] loss: 0.029700395018953715
[Epoch 15, Batch 600] loss: 0.027073265887011075
[Epoch 15, Batch 700] loss: 0.012771254963154207
[Epoch 15, Batch 800] loss: 0.014188247636411688
[Epoch 15, Batch 900] loss: 0.04582617397496506
[Epoch 15, Batch 1000] loss: 0.015727650684730178
[Epoch 15, Batch 1100] loss: 0.018366606538984344
[Epoch 15, Batch 1200] loss: 0.02066731107639498
[Epoch 15, Batch 1300] loss: 0.017700786922978294
[Epoch 15, Batch 1400] loss: 0.01732885171295493
[Epoch 15, Batch 1500] loss: 0.020498638626231695
[Epoch 15, Batch 1600] loss: 0.024168524503329535
[Epoch 15, Batch 1700] loss: 0.027437069256120595
[Epoch 15, Batch 1800] loss: 0.020824144423640972
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0608
Validation Accuracy: 0.9821
Overfitting: 0.0601
[Epoch 16, Batch 100] loss: 0.021328845666939742
[Epoch 16, Batch 200] loss: 0.014137074021273293
[Epoch 16, Batch 300] loss: 0.014041149635413603
[Epoch 16, Batch 400] loss: 0.018277703316889528
[Epoch 16, Batch 500] loss: 0.023012013928200757
[Epoch 16, Batch 600] loss: 0.011927952953446947
[Epoch 16, Batch 700] loss: 0.02053438711736817
[Epoch 16, Batch 800] loss: 0.014095001055138709
[Epoch 16, Batch 900] loss: 0.03753433356205278
[Epoch 16, Batch 1000] loss: 0.022729563272841913
[Epoch 16, Batch 1100] loss: 0.025457715300326526
[Epoch 16, Batch 1200] loss: 0.015586995867743099
[Epoch 16, Batch 1300] loss: 0.020609703852387612
[Epoch 16, Batch 1400] loss: 0.01780534562556568
[Epoch 16, Batch 1500] loss: 0.01808678123401478
[Epoch 16, Batch 1600] loss: 0.020084049079887336
[Epoch 16, Batch 1700] loss: 0.017767603500542465
[Epoch 16, Batch 1800] loss: 0.01520982003366953
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0571
Validation Accuracy: 0.9849
Overfitting: 0.0562
[Epoch 17, Batch 100] loss: 0.017640267365532054
[Epoch 17, Batch 200] loss: 0.013577294745045947
[Epoch 17, Batch 300] loss: 0.02321303932927549
[Epoch 17, Batch 400] loss: 0.02012932931584146
[Epoch 17, Batch 500] loss: 0.016282426483994642
[Epoch 17, Batch 600] loss: 0.011530243027591496
[Epoch 17, Batch 700] loss: 0.01336214119777651
[Epoch 17, Batch 800] loss: 0.030358021666097558
[Epoch 17, Batch 900] loss: 0.01816205881870701
[Epoch 17, Batch 1000] loss: 0.015099228652761667
[Epoch 17, Batch 1100] loss: 0.019607060901034857
[Epoch 17, Batch 1200] loss: 0.027186543709249236
[Epoch 17, Batch 1300] loss: 0.019496094310197803
[Epoch 17, Batch 1400] loss: 0.02609827288571978
[Epoch 17, Batch 1500] loss: 0.020053449431434275
[Epoch 17, Batch 1600] loss: 0.025169776425755117
[Epoch 17, Batch 1700] loss: 0.01877337030840863
[Epoch 17, Batch 1800] loss: 0.015403525471010654
**STATS for Epoch 17** : 
Average training loss: 0.0007
Average validation loss: 0.0522
Validation Accuracy: 0.9848
Overfitting: 0.0516
Best model saved at epoch 17 with validation loss: 0.0522
[Epoch 18, Batch 100] loss: 0.023080717144330264
[Epoch 18, Batch 200] loss: 0.0108672752073835
[Epoch 18, Batch 300] loss: 0.013265853266984777
[Epoch 18, Batch 400] loss: 0.005360593939185492
[Epoch 18, Batch 500] loss: 0.02550782519123459
[Epoch 18, Batch 600] loss: 0.010637047695563524
[Epoch 18, Batch 700] loss: 0.013033588891194086
[Epoch 18, Batch 800] loss: 0.01706690768848148
[Epoch 18, Batch 900] loss: 0.007793483996101714
[Epoch 18, Batch 1000] loss: 0.022407153768472198
[Epoch 18, Batch 1100] loss: 0.018649755419955907
[Epoch 18, Batch 1200] loss: 0.019277539901595447
[Epoch 18, Batch 1300] loss: 0.020175571533618496
[Epoch 18, Batch 1400] loss: 0.009369206592195952
[Epoch 18, Batch 1500] loss: 0.013270342735413578
[Epoch 18, Batch 1600] loss: 0.014939753062171802
[Epoch 18, Batch 1700] loss: 0.014016227845240791
[Epoch 18, Batch 1800] loss: 0.015668022326699428
**STATS for Epoch 18** : 
Average training loss: 0.0006
Average validation loss: 0.0555
Validation Accuracy: 0.9854
Overfitting: 0.0549
[Epoch 19, Batch 100] loss: 0.010925039063258736
[Epoch 19, Batch 200] loss: 0.015679884763176232
[Epoch 19, Batch 300] loss: 0.013728916731906793
[Epoch 19, Batch 400] loss: 0.006024636089459818
[Epoch 19, Batch 500] loss: 0.020205041123408592
[Epoch 19, Batch 600] loss: 0.013743210332531817
[Epoch 19, Batch 700] loss: 0.00812581860296632
[Epoch 19, Batch 800] loss: 0.02162165796802583
[Epoch 19, Batch 900] loss: 0.011924114475095848
[Epoch 19, Batch 1000] loss: 0.015524327112798346
[Epoch 19, Batch 1100] loss: 0.014271232079909168
[Epoch 19, Batch 1200] loss: 0.007784812131176295
[Epoch 19, Batch 1300] loss: 0.013530122262127407
[Epoch 19, Batch 1400] loss: 0.015348435114055974
[Epoch 19, Batch 1500] loss: 0.011585213876505804
[Epoch 19, Batch 1600] loss: 0.017917878989401288
[Epoch 19, Batch 1700] loss: 0.0141593261582193
[Epoch 19, Batch 1800] loss: 0.009744067639130662
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0553
Validation Accuracy: 0.9859
Overfitting: 0.0549
[Epoch 20, Batch 100] loss: 0.010779087758137393
[Epoch 20, Batch 200] loss: 0.012055150906826384
[Epoch 20, Batch 300] loss: 0.016060087259429565
[Epoch 20, Batch 400] loss: 0.006240483519686677
[Epoch 20, Batch 500] loss: 0.009788712013605618
[Epoch 20, Batch 600] loss: 0.007013042942628544
[Epoch 20, Batch 700] loss: 0.013427653751687103
[Epoch 20, Batch 800] loss: 0.011370744938340067
[Epoch 20, Batch 900] loss: 0.021497093071357085
[Epoch 20, Batch 1000] loss: 0.020654717153029196
[Epoch 20, Batch 1100] loss: 0.017081794492823973
[Epoch 20, Batch 1200] loss: 0.009410508412511263
[Epoch 20, Batch 1300] loss: 0.007945597457858184
[Epoch 20, Batch 1400] loss: 0.008934667153916963
[Epoch 20, Batch 1500] loss: 0.010921858264582624
[Epoch 20, Batch 1600] loss: 0.01358761505855
[Epoch 20, Batch 1700] loss: 0.012869754653220298
[Epoch 20, Batch 1800] loss: 0.011300614391698218
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0613
Validation Accuracy: 0.9838
Overfitting: 0.0610
[Epoch 21, Batch 100] loss: 0.005147226409362702
[Epoch 21, Batch 200] loss: 0.01024239158879027
[Epoch 21, Batch 300] loss: 0.012056646481996723
[Epoch 21, Batch 400] loss: 0.007692364987078691
[Epoch 21, Batch 500] loss: 0.008809292624721365
[Epoch 21, Batch 600] loss: 0.008260841575088307
[Epoch 21, Batch 700] loss: 0.015550140483946961
[Epoch 21, Batch 800] loss: 0.0182248347037239
[Epoch 21, Batch 900] loss: 0.011275364872126374
[Epoch 21, Batch 1000] loss: 0.006766759339807322
[Epoch 21, Batch 1100] loss: 0.022242179213026247
[Epoch 21, Batch 1200] loss: 0.013964564236562182
[Epoch 21, Batch 1300] loss: 0.015121582451683935
[Epoch 21, Batch 1400] loss: 0.01685575038605748
[Epoch 21, Batch 1500] loss: 0.014506989966475885
[Epoch 21, Batch 1600] loss: 0.013463494171719503
[Epoch 21, Batch 1700] loss: 0.008136242171640334
[Epoch 21, Batch 1800] loss: 0.009965422638811106
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0586
Validation Accuracy: 0.9845
Overfitting: 0.0583
[Epoch 22, Batch 100] loss: 0.013619086206509791
[Epoch 22, Batch 200] loss: 0.011515061765221617
[Epoch 22, Batch 300] loss: 0.011127492586235235
[Epoch 22, Batch 400] loss: 0.009269756212761422
[Epoch 22, Batch 500] loss: 0.01443493055561703
[Epoch 22, Batch 600] loss: 0.00888031423348366
[Epoch 22, Batch 700] loss: 0.007984731480596564
[Epoch 22, Batch 800] loss: 0.012067791147803746
[Epoch 22, Batch 900] loss: 0.007128888911365721
[Epoch 22, Batch 1000] loss: 0.007260544153064074
[Epoch 22, Batch 1100] loss: 0.008670180661847554
[Epoch 22, Batch 1200] loss: 0.0072858607019816194
[Epoch 22, Batch 1300] loss: 0.0068172780797249284
[Epoch 22, Batch 1400] loss: 0.014660627118455522
[Epoch 22, Batch 1500] loss: 0.008243647272840916
[Epoch 22, Batch 1600] loss: 0.013765106564005692
[Epoch 22, Batch 1700] loss: 0.011722277548105921
[Epoch 22, Batch 1800] loss: 0.00514608879277148
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0594
Validation Accuracy: 0.9846
Overfitting: 0.0590
[Epoch 23, Batch 100] loss: 0.00738570136987164
[Epoch 23, Batch 200] loss: 0.01027090242898339
[Epoch 23, Batch 300] loss: 0.004241390594352197
[Epoch 23, Batch 400] loss: 0.005970470482282053
[Epoch 23, Batch 500] loss: 0.0062810677249854055
[Epoch 23, Batch 600] loss: 0.008488587367544369
[Epoch 23, Batch 700] loss: 0.005853472499675263
[Epoch 23, Batch 800] loss: 0.004619410584851948
[Epoch 23, Batch 900] loss: 0.004827101782204864
[Epoch 23, Batch 1000] loss: 0.008446140398843909
[Epoch 23, Batch 1100] loss: 0.007920436430404153
[Epoch 23, Batch 1200] loss: 0.008664384722710566
[Epoch 23, Batch 1300] loss: 0.014234196476991201
[Epoch 23, Batch 1400] loss: 0.025877074137065394
[Epoch 23, Batch 1500] loss: 0.0071644229045068645
[Epoch 23, Batch 1600] loss: 0.0190424273794315
[Epoch 23, Batch 1700] loss: 0.00999821470230927
[Epoch 23, Batch 1800] loss: 0.008391191043738217
**STATS for Epoch 23** : 
Average training loss: 0.0008
Average validation loss: 0.0562
Validation Accuracy: 0.9852
Overfitting: 0.0554
[Epoch 24, Batch 100] loss: 0.004997421710568233
[Epoch 24, Batch 200] loss: 0.007204878605780323
[Epoch 24, Batch 300] loss: 0.004917807526717297
[Epoch 24, Batch 400] loss: 0.005101222694484022
[Epoch 24, Batch 500] loss: 0.007472351914016144
[Epoch 24, Batch 600] loss: 0.012518388033190603
[Epoch 24, Batch 700] loss: 0.011691327926837403
[Epoch 24, Batch 800] loss: 0.007846637572160944
[Epoch 24, Batch 900] loss: 0.01390272140527486
[Epoch 24, Batch 1000] loss: 0.009335486791781023
[Epoch 24, Batch 1100] loss: 0.00990768612196007
[Epoch 24, Batch 1200] loss: 0.01989543560162474
[Epoch 24, Batch 1300] loss: 0.009263231021368484
[Epoch 24, Batch 1400] loss: 0.006940600162884039
[Epoch 24, Batch 1500] loss: 0.005224618524430298
[Epoch 24, Batch 1600] loss: 0.007768697923197578
[Epoch 24, Batch 1700] loss: 0.0038251866847917883
[Epoch 24, Batch 1800] loss: 0.006608430619035061
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0612
Validation Accuracy: 0.9849
Overfitting: 0.0609
Fold 1 validation loss: 0.0612
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.300748543739319
[Epoch 1, Batch 200] loss: 2.2924476265907288
[Epoch 1, Batch 300] loss: 2.276554191112518
[Epoch 1, Batch 400] loss: 2.244214563369751
[Epoch 1, Batch 500] loss: 2.1621554279327393
[Epoch 1, Batch 600] loss: 1.8055937337875365
[Epoch 1, Batch 700] loss: 0.995088347196579
[Epoch 1, Batch 800] loss: 0.6513473452627658
[Epoch 1, Batch 900] loss: 0.5393556739389896
[Epoch 1, Batch 1000] loss: 0.4651738767325878
[Epoch 1, Batch 1100] loss: 0.41663983799517157
[Epoch 1, Batch 1200] loss: 0.3694594565778971
[Epoch 1, Batch 1300] loss: 0.38555074580013754
[Epoch 1, Batch 1400] loss: 0.36299670457839966
[Epoch 1, Batch 1500] loss: 0.35621239118278025
[Epoch 1, Batch 1600] loss: 0.3228886694088578
[Epoch 1, Batch 1700] loss: 0.2944378353655338
[Epoch 1, Batch 1800] loss: 0.26760394174605606
**STATS for Epoch 1** : 
Average training loss: 0.0132
Average validation loss: 0.2964
Validation Accuracy: 0.9053
Overfitting: 0.2832
Best model saved at epoch 1 with validation loss: 0.2964
[Epoch 2, Batch 100] loss: 0.27311884220689536
[Epoch 2, Batch 200] loss: 0.25207930071279405
[Epoch 2, Batch 300] loss: 0.22631324804387987
[Epoch 2, Batch 400] loss: 0.2180433099064976
[Epoch 2, Batch 500] loss: 0.20113827465102077
[Epoch 2, Batch 600] loss: 0.2356188586819917
[Epoch 2, Batch 700] loss: 0.16826694878749549
[Epoch 2, Batch 800] loss: 0.18451303709298372
[Epoch 2, Batch 900] loss: 0.23152009019628167
[Epoch 2, Batch 1000] loss: 0.167567018866539
[Epoch 2, Batch 1100] loss: 0.16546691074967385
[Epoch 2, Batch 1200] loss: 0.19976802956312895
[Epoch 2, Batch 1300] loss: 0.20733129173517229
[Epoch 2, Batch 1400] loss: 0.1940249013900757
[Epoch 2, Batch 1500] loss: 0.14199308467563243
[Epoch 2, Batch 1600] loss: 0.1486787434341386
[Epoch 2, Batch 1700] loss: 0.1536968010198325
[Epoch 2, Batch 1800] loss: 0.16875244685914367
**STATS for Epoch 2** : 
Average training loss: 0.0055
Average validation loss: 0.1784
Validation Accuracy: 0.9446
Overfitting: 0.1729
Best model saved at epoch 2 with validation loss: 0.1784
[Epoch 3, Batch 100] loss: 0.12465252877213061
[Epoch 3, Batch 200] loss: 0.168986631995067
[Epoch 3, Batch 300] loss: 0.11276571728289127
[Epoch 3, Batch 400] loss: 0.13455303786788136
[Epoch 3, Batch 500] loss: 0.12583409518469124
[Epoch 3, Batch 600] loss: 0.13793021723628043
[Epoch 3, Batch 700] loss: 0.1332339663989842
[Epoch 3, Batch 800] loss: 0.11325537039898335
[Epoch 3, Batch 900] loss: 0.10814658391987905
[Epoch 3, Batch 1000] loss: 0.11864605442155153
[Epoch 3, Batch 1100] loss: 0.13516270698979496
[Epoch 3, Batch 1200] loss: 0.12396116764750331
[Epoch 3, Batch 1300] loss: 0.1277378392405808
[Epoch 3, Batch 1400] loss: 0.10431724572787061
[Epoch 3, Batch 1500] loss: 0.09436736545991152
[Epoch 3, Batch 1600] loss: 0.12314693396445364
[Epoch 3, Batch 1700] loss: 0.1150585368135944
[Epoch 3, Batch 1800] loss: 0.10979420122224838
**STATS for Epoch 3** : 
Average training loss: 0.0035
Average validation loss: 0.1044
Validation Accuracy: 0.9689
Overfitting: 0.1009
Best model saved at epoch 3 with validation loss: 0.1044
[Epoch 4, Batch 100] loss: 0.10109601250151172
[Epoch 4, Batch 200] loss: 0.0798561846173834
[Epoch 4, Batch 300] loss: 0.0986847865418531
[Epoch 4, Batch 400] loss: 0.09345180641394109
[Epoch 4, Batch 500] loss: 0.09778072964050807
[Epoch 4, Batch 600] loss: 0.11705769207328558
[Epoch 4, Batch 700] loss: 0.08438999071484432
[Epoch 4, Batch 800] loss: 0.07935086388024501
[Epoch 4, Batch 900] loss: 0.09147894283756614
[Epoch 4, Batch 1000] loss: 0.08832157246768474
[Epoch 4, Batch 1100] loss: 0.09988379482878372
[Epoch 4, Batch 1200] loss: 0.09657253817887977
[Epoch 4, Batch 1300] loss: 0.08756089871923906
[Epoch 4, Batch 1400] loss: 0.1032209260086529
[Epoch 4, Batch 1500] loss: 0.09656926946714521
[Epoch 4, Batch 1600] loss: 0.09213232547277585
[Epoch 4, Batch 1700] loss: 0.10695501625770704
[Epoch 4, Batch 1800] loss: 0.08717792574083433
**STATS for Epoch 4** : 
Average training loss: 0.0034
Average validation loss: 0.0915
Validation Accuracy: 0.9717
Overfitting: 0.0880
Best model saved at epoch 4 with validation loss: 0.0915
[Epoch 5, Batch 100] loss: 0.07358377884374931
[Epoch 5, Batch 200] loss: 0.07761167743010447
[Epoch 5, Batch 300] loss: 0.0769385240226984
[Epoch 5, Batch 400] loss: 0.07711844032863155
[Epoch 5, Batch 500] loss: 0.09138710385479498
[Epoch 5, Batch 600] loss: 0.08961310163256712
[Epoch 5, Batch 700] loss: 0.06158320329384878
[Epoch 5, Batch 800] loss: 0.10030511506367475
[Epoch 5, Batch 900] loss: 0.08561307481606491
[Epoch 5, Batch 1000] loss: 0.06203014503931627
[Epoch 5, Batch 1100] loss: 0.07357002015924081
[Epoch 5, Batch 1200] loss: 0.07604432646709029
[Epoch 5, Batch 1300] loss: 0.07821116790641099
[Epoch 5, Batch 1400] loss: 0.09058840929181315
[Epoch 5, Batch 1500] loss: 0.06555690808861982
[Epoch 5, Batch 1600] loss: 0.07042667939793318
[Epoch 5, Batch 1700] loss: 0.07386638031690382
[Epoch 5, Batch 1800] loss: 0.07516485995380208
**STATS for Epoch 5** : 
Average training loss: 0.0029
Average validation loss: 0.0849
Validation Accuracy: 0.9745
Overfitting: 0.0820
Best model saved at epoch 5 with validation loss: 0.0849
[Epoch 6, Batch 100] loss: 0.07069878397742287
[Epoch 6, Batch 200] loss: 0.05929300921736285
[Epoch 6, Batch 300] loss: 0.07265683729958256
[Epoch 6, Batch 400] loss: 0.06917500823386945
[Epoch 6, Batch 500] loss: 0.07588214001967572
[Epoch 6, Batch 600] loss: 0.07963347860379144
[Epoch 6, Batch 700] loss: 0.06397144153481349
[Epoch 6, Batch 800] loss: 0.07695240955566987
[Epoch 6, Batch 900] loss: 0.0855374594492605
[Epoch 6, Batch 1000] loss: 0.07194174183299765
[Epoch 6, Batch 1100] loss: 0.04458096020272933
[Epoch 6, Batch 1200] loss: 0.05582376449368894
[Epoch 6, Batch 1300] loss: 0.06702471174940001
[Epoch 6, Batch 1400] loss: 0.05528280987928156
[Epoch 6, Batch 1500] loss: 0.0532938535627909
[Epoch 6, Batch 1600] loss: 0.05506262958107982
[Epoch 6, Batch 1700] loss: 0.06345960116246716
[Epoch 6, Batch 1800] loss: 0.06576395681651775
**STATS for Epoch 6** : 
Average training loss: 0.0022
Average validation loss: 0.0741
Validation Accuracy: 0.9773
Overfitting: 0.0719
Best model saved at epoch 6 with validation loss: 0.0741
[Epoch 7, Batch 100] loss: 0.03820808565680636
[Epoch 7, Batch 200] loss: 0.04325802092324011
[Epoch 7, Batch 300] loss: 0.048534649604698644
[Epoch 7, Batch 400] loss: 0.05651101266616024
[Epoch 7, Batch 500] loss: 0.07669712558155879
[Epoch 7, Batch 600] loss: 0.0740695293166209
[Epoch 7, Batch 700] loss: 0.06498589631577488
[Epoch 7, Batch 800] loss: 0.06783941081026569
[Epoch 7, Batch 900] loss: 0.05658573458262253
[Epoch 7, Batch 1000] loss: 0.04698259994271212
[Epoch 7, Batch 1100] loss: 0.0616060273651965
[Epoch 7, Batch 1200] loss: 0.06496842046355596
[Epoch 7, Batch 1300] loss: 0.06334888752433471
[Epoch 7, Batch 1400] loss: 0.07094101112976205
[Epoch 7, Batch 1500] loss: 0.06888237204169854
[Epoch 7, Batch 1600] loss: 0.07054788786481367
[Epoch 7, Batch 1700] loss: 0.04839462247560732
[Epoch 7, Batch 1800] loss: 0.045140166524215604
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0667
Validation Accuracy: 0.9800
Overfitting: 0.0649
Best model saved at epoch 7 with validation loss: 0.0667
[Epoch 8, Batch 100] loss: 0.04261075884423917
[Epoch 8, Batch 200] loss: 0.04897757848899346
[Epoch 8, Batch 300] loss: 0.0440935775503749
[Epoch 8, Batch 400] loss: 0.05964082271093503
[Epoch 8, Batch 500] loss: 0.0597774255805416
[Epoch 8, Batch 600] loss: 0.058766287767211906
[Epoch 8, Batch 700] loss: 0.04694980248517822
[Epoch 8, Batch 800] loss: 0.054439846842433325
[Epoch 8, Batch 900] loss: 0.049078319146065044
[Epoch 8, Batch 1000] loss: 0.041553673923772294
[Epoch 8, Batch 1100] loss: 0.03893418512889184
[Epoch 8, Batch 1200] loss: 0.055379769664723424
[Epoch 8, Batch 1300] loss: 0.04933403646253282
[Epoch 8, Batch 1400] loss: 0.053153240341343916
[Epoch 8, Batch 1500] loss: 0.04969820493424777
[Epoch 8, Batch 1600] loss: 0.058717494479496965
[Epoch 8, Batch 1700] loss: 0.04914912809850648
[Epoch 8, Batch 1800] loss: 0.053162107015377845
**STATS for Epoch 8** : 
Average training loss: 0.0023
Average validation loss: 0.0791
Validation Accuracy: 0.9770
Overfitting: 0.0768
[Epoch 9, Batch 100] loss: 0.03799861993233208
[Epoch 9, Batch 200] loss: 0.05681549146014731
[Epoch 9, Batch 300] loss: 0.0352558372929343
[Epoch 9, Batch 400] loss: 0.034103956107283014
[Epoch 9, Batch 500] loss: 0.0404188066846109
[Epoch 9, Batch 600] loss: 0.05999421003856696
[Epoch 9, Batch 700] loss: 0.0465469191421289
[Epoch 9, Batch 800] loss: 0.04152154416049598
[Epoch 9, Batch 900] loss: 0.04022534545802046
[Epoch 9, Batch 1000] loss: 0.058546055677288676
[Epoch 9, Batch 1100] loss: 0.059496228545322084
[Epoch 9, Batch 1200] loss: 0.06629449104017113
[Epoch 9, Batch 1300] loss: 0.04743165552034043
[Epoch 9, Batch 1400] loss: 0.035872985835012514
[Epoch 9, Batch 1500] loss: 0.044853154952579646
[Epoch 9, Batch 1600] loss: 0.04522662178205792
[Epoch 9, Batch 1700] loss: 0.047529936562641525
[Epoch 9, Batch 1800] loss: 0.03270612107109628
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0647
Validation Accuracy: 0.9794
Overfitting: 0.0631
Best model saved at epoch 9 with validation loss: 0.0647
[Epoch 10, Batch 100] loss: 0.032188032175108676
[Epoch 10, Batch 200] loss: 0.032515581307816316
[Epoch 10, Batch 300] loss: 0.03839787015604088
[Epoch 10, Batch 400] loss: 0.0488466826005606
[Epoch 10, Batch 500] loss: 0.06347364633576945
[Epoch 10, Batch 600] loss: 0.03155146550925565
[Epoch 10, Batch 700] loss: 0.03389671845274279
[Epoch 10, Batch 800] loss: 0.04156752520764712
[Epoch 10, Batch 900] loss: 0.033178479533817154
[Epoch 10, Batch 1000] loss: 0.0273046823265031
[Epoch 10, Batch 1100] loss: 0.05660528308901121
[Epoch 10, Batch 1200] loss: 0.05166079496731982
[Epoch 10, Batch 1300] loss: 0.040076797844085375
[Epoch 10, Batch 1400] loss: 0.03711384894617367
[Epoch 10, Batch 1500] loss: 0.04318913593451725
[Epoch 10, Batch 1600] loss: 0.04698301525932038
[Epoch 10, Batch 1700] loss: 0.03717424450005637
[Epoch 10, Batch 1800] loss: 0.03500266973751422
**STATS for Epoch 10** : 
Average training loss: 0.0023
Average validation loss: 0.0638
Validation Accuracy: 0.9816
Overfitting: 0.0616
Best model saved at epoch 10 with validation loss: 0.0638
[Epoch 11, Batch 100] loss: 0.026843929988681337
[Epoch 11, Batch 200] loss: 0.03750958114309469
[Epoch 11, Batch 300] loss: 0.029670717665867416
[Epoch 11, Batch 400] loss: 0.044196911991457456
[Epoch 11, Batch 500] loss: 0.028611078522662866
[Epoch 11, Batch 600] loss: 0.04027151312897331
[Epoch 11, Batch 700] loss: 0.03706281912396662
[Epoch 11, Batch 800] loss: 0.031213838556723203
[Epoch 11, Batch 900] loss: 0.030834923193615395
[Epoch 11, Batch 1000] loss: 0.031619164994626775
[Epoch 11, Batch 1100] loss: 0.04904598927634652
[Epoch 11, Batch 1200] loss: 0.037428945112187646
[Epoch 11, Batch 1300] loss: 0.04269454554814729
[Epoch 11, Batch 1400] loss: 0.03473583182494622
[Epoch 11, Batch 1500] loss: 0.04703359994586208
[Epoch 11, Batch 1600] loss: 0.04232803911552765
[Epoch 11, Batch 1700] loss: 0.028607617320813006
[Epoch 11, Batch 1800] loss: 0.039490989928308406
**STATS for Epoch 11** : 
Average training loss: 0.0024
Average validation loss: 0.0784
Validation Accuracy: 0.9759
Overfitting: 0.0760
[Epoch 12, Batch 100] loss: 0.03376678887769231
[Epoch 12, Batch 200] loss: 0.03549674148714985
[Epoch 12, Batch 300] loss: 0.038856023420958084
[Epoch 12, Batch 400] loss: 0.028513643882761244
[Epoch 12, Batch 500] loss: 0.03377549141150667
[Epoch 12, Batch 600] loss: 0.033494097078510095
[Epoch 12, Batch 700] loss: 0.03126126122409914
[Epoch 12, Batch 800] loss: 0.03258649298120872
[Epoch 12, Batch 900] loss: 0.03524866154533811
[Epoch 12, Batch 1000] loss: 0.03154170580673963
[Epoch 12, Batch 1100] loss: 0.0418300004403136
[Epoch 12, Batch 1200] loss: 0.041094578147312856
[Epoch 12, Batch 1300] loss: 0.021113169607851888
[Epoch 12, Batch 1400] loss: 0.03138148091820767
[Epoch 12, Batch 1500] loss: 0.028609545794024596
[Epoch 12, Batch 1600] loss: 0.028997891148537746
[Epoch 12, Batch 1700] loss: 0.02134104513344937
[Epoch 12, Batch 1800] loss: 0.03939577327459119
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0638
Validation Accuracy: 0.9820
Overfitting: 0.0628
Best model saved at epoch 12 with validation loss: 0.0638
[Epoch 13, Batch 100] loss: 0.019809951584611553
[Epoch 13, Batch 200] loss: 0.02407800975473947
[Epoch 13, Batch 300] loss: 0.02823152192959242
[Epoch 13, Batch 400] loss: 0.026874536334362348
[Epoch 13, Batch 500] loss: 0.03221047037528479
[Epoch 13, Batch 600] loss: 0.027565451232076158
[Epoch 13, Batch 700] loss: 0.02570259355023154
[Epoch 13, Batch 800] loss: 0.02413116218885989
[Epoch 13, Batch 900] loss: 0.024141744278022088
[Epoch 13, Batch 1000] loss: 0.02532661172655935
[Epoch 13, Batch 1100] loss: 0.02932125620893203
[Epoch 13, Batch 1200] loss: 0.030099858620269516
[Epoch 13, Batch 1300] loss: 0.02136481298846775
[Epoch 13, Batch 1400] loss: 0.0425343753593188
[Epoch 13, Batch 1500] loss: 0.03830968987749657
[Epoch 13, Batch 1600] loss: 0.03398559235130961
[Epoch 13, Batch 1700] loss: 0.04473741698362574
[Epoch 13, Batch 1800] loss: 0.02969631301049958
**STATS for Epoch 13** : 
Average training loss: 0.0014
Average validation loss: 0.0568
Validation Accuracy: 0.9838
Overfitting: 0.0554
Best model saved at epoch 13 with validation loss: 0.0568
[Epoch 14, Batch 100] loss: 0.022330043979472976
[Epoch 14, Batch 200] loss: 0.023596480322739807
[Epoch 14, Batch 300] loss: 0.02374761775492516
[Epoch 14, Batch 400] loss: 0.017830504881021624
[Epoch 14, Batch 500] loss: 0.019673166468637645
[Epoch 14, Batch 600] loss: 0.02554991576282191
[Epoch 14, Batch 700] loss: 0.023978350720572052
[Epoch 14, Batch 800] loss: 0.034799110578460385
[Epoch 14, Batch 900] loss: 0.019442180127880418
[Epoch 14, Batch 1000] loss: 0.03305840668064775
[Epoch 14, Batch 1100] loss: 0.03392066109525331
[Epoch 14, Batch 1200] loss: 0.02290244213269034
[Epoch 14, Batch 1300] loss: 0.030700535418000073
[Epoch 14, Batch 1400] loss: 0.02692696395213716
[Epoch 14, Batch 1500] loss: 0.02002053470525425
[Epoch 14, Batch 1600] loss: 0.027130026938102673
[Epoch 14, Batch 1700] loss: 0.03163410303764977
[Epoch 14, Batch 1800] loss: 0.03863064486406074
**STATS for Epoch 14** : 
Average training loss: 0.0011
Average validation loss: 0.0565
Validation Accuracy: 0.9835
Overfitting: 0.0554
Best model saved at epoch 14 with validation loss: 0.0565
[Epoch 15, Batch 100] loss: 0.03311631773984118
[Epoch 15, Batch 200] loss: 0.02747044214673224
[Epoch 15, Batch 300] loss: 0.019237362202693474
[Epoch 15, Batch 400] loss: 0.02506810832157498
[Epoch 15, Batch 500] loss: 0.028195437944668812
[Epoch 15, Batch 600] loss: 0.02745150619579363
[Epoch 15, Batch 700] loss: 0.018101900058973115
[Epoch 15, Batch 800] loss: 0.02100907905793065
[Epoch 15, Batch 900] loss: 0.013346326770042652
[Epoch 15, Batch 1000] loss: 0.0259487253338375
[Epoch 15, Batch 1100] loss: 0.022672352434092317
[Epoch 15, Batch 1200] loss: 0.021199263252565288
[Epoch 15, Batch 1300] loss: 0.023520839302145758
[Epoch 15, Batch 1400] loss: 0.02234189353279362
[Epoch 15, Batch 1500] loss: 0.030026012553935288
[Epoch 15, Batch 1600] loss: 0.027221620418931707
[Epoch 15, Batch 1700] loss: 0.02371045316031086
[Epoch 15, Batch 1800] loss: 0.025520666005795646
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0614
Validation Accuracy: 0.9833
Overfitting: 0.0607
[Epoch 16, Batch 100] loss: 0.025619462646427563
[Epoch 16, Batch 200] loss: 0.014596310383058152
[Epoch 16, Batch 300] loss: 0.01976675638150482
[Epoch 16, Batch 400] loss: 0.01648166274644609
[Epoch 16, Batch 500] loss: 0.021377780747407087
[Epoch 16, Batch 600] loss: 0.019739452084031654
[Epoch 16, Batch 700] loss: 0.016453298413398442
[Epoch 16, Batch 800] loss: 0.020778293435978413
[Epoch 16, Batch 900] loss: 0.011733518353976251
[Epoch 16, Batch 1000] loss: 0.026884660200812503
[Epoch 16, Batch 1100] loss: 0.016547262492022128
[Epoch 16, Batch 1200] loss: 0.0206295519593823
[Epoch 16, Batch 1300] loss: 0.041516031415740146
[Epoch 16, Batch 1400] loss: 0.018160971177276223
[Epoch 16, Batch 1500] loss: 0.019855485496409527
[Epoch 16, Batch 1600] loss: 0.03158286316438534
[Epoch 16, Batch 1700] loss: 0.021159580069579534
[Epoch 16, Batch 1800] loss: 0.03495666014750896
**STATS for Epoch 16** : 
Average training loss: 0.0008
Average validation loss: 0.0555
Validation Accuracy: 0.9836
Overfitting: 0.0547
Best model saved at epoch 16 with validation loss: 0.0555
[Epoch 17, Batch 100] loss: 0.018081575123069342
[Epoch 17, Batch 200] loss: 0.02616759369695501
[Epoch 17, Batch 300] loss: 0.011709636121377116
[Epoch 17, Batch 400] loss: 0.025427205733340088
[Epoch 17, Batch 500] loss: 0.025815163768129423
[Epoch 17, Batch 600] loss: 0.01165971093767439
[Epoch 17, Batch 700] loss: 0.02219465406618838
[Epoch 17, Batch 800] loss: 0.014923554775195953
[Epoch 17, Batch 900] loss: 0.013624662108923076
[Epoch 17, Batch 1000] loss: 0.020576387640430766
[Epoch 17, Batch 1100] loss: 0.02512132540485254
[Epoch 17, Batch 1200] loss: 0.017467002428456908
[Epoch 17, Batch 1300] loss: 0.018195143898738025
[Epoch 17, Batch 1400] loss: 0.015506828865509305
[Epoch 17, Batch 1500] loss: 0.013775174163347401
[Epoch 17, Batch 1600] loss: 0.02913294657082588
[Epoch 17, Batch 1700] loss: 0.02219540293175669
[Epoch 17, Batch 1800] loss: 0.025108724979509132
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0640
Validation Accuracy: 0.9827
Overfitting: 0.0632
[Epoch 18, Batch 100] loss: 0.015142838517685959
[Epoch 18, Batch 200] loss: 0.021569829750242207
[Epoch 18, Batch 300] loss: 0.030847140653022506
[Epoch 18, Batch 400] loss: 0.012722407326073153
[Epoch 18, Batch 500] loss: 0.012915642292318808
[Epoch 18, Batch 600] loss: 0.01377745058029177
[Epoch 18, Batch 700] loss: 0.011514513980655465
[Epoch 18, Batch 800] loss: 0.01760560533050011
[Epoch 18, Batch 900] loss: 0.0206317244550155
[Epoch 18, Batch 1000] loss: 0.022750280936998026
[Epoch 18, Batch 1100] loss: 0.019019026165224204
[Epoch 18, Batch 1200] loss: 0.015344244390362291
[Epoch 18, Batch 1300] loss: 0.011862983411210734
[Epoch 18, Batch 1400] loss: 0.014797260782797821
[Epoch 18, Batch 1500] loss: 0.0119030007220681
[Epoch 18, Batch 1600] loss: 0.026341397600735946
[Epoch 18, Batch 1700] loss: 0.028459801516546576
[Epoch 18, Batch 1800] loss: 0.024116118147030647
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0539
Validation Accuracy: 0.9852
Overfitting: 0.0536
Best model saved at epoch 18 with validation loss: 0.0539
[Epoch 19, Batch 100] loss: 0.010677220309444237
[Epoch 19, Batch 200] loss: 0.02340254171365814
[Epoch 19, Batch 300] loss: 0.009206428473480627
[Epoch 19, Batch 400] loss: 0.011619174340648897
[Epoch 19, Batch 500] loss: 0.023953623173365485
[Epoch 19, Batch 600] loss: 0.012323260277771624
[Epoch 19, Batch 700] loss: 0.009472529020058573
[Epoch 19, Batch 800] loss: 0.02387577713851897
[Epoch 19, Batch 900] loss: 0.018292212242922688
[Epoch 19, Batch 1000] loss: 0.019702363456617605
[Epoch 19, Batch 1100] loss: 0.013963619420446776
[Epoch 19, Batch 1200] loss: 0.020638339786673895
[Epoch 19, Batch 1300] loss: 0.0097894074389842
[Epoch 19, Batch 1400] loss: 0.019367878758994265
[Epoch 19, Batch 1500] loss: 0.010851631349360104
[Epoch 19, Batch 1600] loss: 0.01369602511098492
[Epoch 19, Batch 1700] loss: 0.013107015823725305
[Epoch 19, Batch 1800] loss: 0.01635049154436274
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0572
Validation Accuracy: 0.9848
Overfitting: 0.0567
[Epoch 20, Batch 100] loss: 0.013492411659626669
[Epoch 20, Batch 200] loss: 0.012700669809473765
[Epoch 20, Batch 300] loss: 0.019187410781196377
[Epoch 20, Batch 400] loss: 0.015192221804618385
[Epoch 20, Batch 500] loss: 0.015631731268649675
[Epoch 20, Batch 600] loss: 0.006860390493666273
[Epoch 20, Batch 700] loss: 0.01127393784623564
[Epoch 20, Batch 800] loss: 0.012099025530951622
[Epoch 20, Batch 900] loss: 0.016594443841427164
[Epoch 20, Batch 1000] loss: 0.021178079464607435
[Epoch 20, Batch 1100] loss: 0.009354716226844174
[Epoch 20, Batch 1200] loss: 0.019056317128579393
[Epoch 20, Batch 1300] loss: 0.016290825992246027
[Epoch 20, Batch 1400] loss: 0.023546647923940327
[Epoch 20, Batch 1500] loss: 0.011052761399187148
[Epoch 20, Batch 1600] loss: 0.009072034787423036
[Epoch 20, Batch 1700] loss: 0.01110774867962391
[Epoch 20, Batch 1800] loss: 0.018182870421296685
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0622
Validation Accuracy: 0.9839
Overfitting: 0.0616
[Epoch 21, Batch 100] loss: 0.00916921585901946
[Epoch 21, Batch 200] loss: 0.00693202947242753
[Epoch 21, Batch 300] loss: 0.014776764023697524
[Epoch 21, Batch 400] loss: 0.009606938870838348
[Epoch 21, Batch 500] loss: 0.010023366565819742
[Epoch 21, Batch 600] loss: 0.014828599841348478
[Epoch 21, Batch 700] loss: 0.013690497968718773
[Epoch 21, Batch 800] loss: 0.010258507706594174
[Epoch 21, Batch 900] loss: 0.01948134752248734
[Epoch 21, Batch 1000] loss: 0.011416639808649051
[Epoch 21, Batch 1100] loss: 0.007849546880106573
[Epoch 21, Batch 1200] loss: 0.012406946984056049
[Epoch 21, Batch 1300] loss: 0.005918458097257826
[Epoch 21, Batch 1400] loss: 0.01709623007033315
[Epoch 21, Batch 1500] loss: 0.010444425825116923
[Epoch 21, Batch 1600] loss: 0.015627517965949664
[Epoch 21, Batch 1700] loss: 0.011342172780878172
[Epoch 21, Batch 1800] loss: 0.027763672489782038
**STATS for Epoch 21** : 
Average training loss: 0.0009
Average validation loss: 0.0638
Validation Accuracy: 0.9835
Overfitting: 0.0629
[Epoch 22, Batch 100] loss: 0.006326415126750362
[Epoch 22, Batch 200] loss: 0.016147579988546566
[Epoch 22, Batch 300] loss: 0.006755631737596559
[Epoch 22, Batch 400] loss: 0.009920672030657442
[Epoch 22, Batch 500] loss: 0.0068372685205088145
[Epoch 22, Batch 600] loss: 0.007350471128856953
[Epoch 22, Batch 700] loss: 0.018125993098237814
[Epoch 22, Batch 800] loss: 0.011464441505722789
[Epoch 22, Batch 900] loss: 0.018902135485268444
[Epoch 22, Batch 1000] loss: 0.025760202315141215
[Epoch 22, Batch 1100] loss: 0.019038149154321216
[Epoch 22, Batch 1200] loss: 0.009652984665008262
[Epoch 22, Batch 1300] loss: 0.010349023210992528
[Epoch 22, Batch 1400] loss: 0.013613503386441152
[Epoch 22, Batch 1500] loss: 0.014987764534516827
[Epoch 22, Batch 1600] loss: 0.009494107764717229
[Epoch 22, Batch 1700] loss: 0.01599691341775724
[Epoch 22, Batch 1800] loss: 0.01725577186593
**STATS for Epoch 22** : 
Average training loss: 0.0007
Average validation loss: 0.0635
Validation Accuracy: 0.9838
Overfitting: 0.0628
[Epoch 23, Batch 100] loss: 0.00943421135927565
[Epoch 23, Batch 200] loss: 0.006848245504525039
[Epoch 23, Batch 300] loss: 0.006552427558046929
[Epoch 23, Batch 400] loss: 0.006465740910276736
[Epoch 23, Batch 500] loss: 0.009608087113192595
[Epoch 23, Batch 600] loss: 0.014103093145222375
[Epoch 23, Batch 700] loss: 0.006898079223788045
[Epoch 23, Batch 800] loss: 0.006250066824968599
[Epoch 23, Batch 900] loss: 0.006352405537272716
[Epoch 23, Batch 1000] loss: 0.007250911092960451
[Epoch 23, Batch 1100] loss: 0.007296721331604203
[Epoch 23, Batch 1200] loss: 0.004944369143129279
[Epoch 23, Batch 1300] loss: 0.007166371556913873
[Epoch 23, Batch 1400] loss: 0.011871285658908165
[Epoch 23, Batch 1500] loss: 0.012192141621603696
[Epoch 23, Batch 1600] loss: 0.015574976134348616
[Epoch 23, Batch 1700] loss: 0.00808590532834387
[Epoch 23, Batch 1800] loss: 0.013553448516147456
**STATS for Epoch 23** : 
Average training loss: 0.0009
Average validation loss: 0.0757
Validation Accuracy: 0.9808
Overfitting: 0.0748
[Epoch 24, Batch 100] loss: 0.006967475723340613
[Epoch 24, Batch 200] loss: 0.014224701567927696
[Epoch 24, Batch 300] loss: 0.005295319285505684
[Epoch 24, Batch 400] loss: 0.008316484806646257
[Epoch 24, Batch 500] loss: 0.005885165872723519
[Epoch 24, Batch 600] loss: 0.01007847562279494
[Epoch 24, Batch 700] loss: 0.014848012745287633
[Epoch 24, Batch 800] loss: 0.010133314947611325
[Epoch 24, Batch 900] loss: 0.018103400580130255
[Epoch 24, Batch 1000] loss: 0.012252799460620736
[Epoch 24, Batch 1100] loss: 0.009081180606563067
[Epoch 24, Batch 1200] loss: 0.007978691365665327
[Epoch 24, Batch 1300] loss: 0.010579553144561942
[Epoch 24, Batch 1400] loss: 0.003118105378493965
[Epoch 24, Batch 1500] loss: 0.015134789448061382
[Epoch 24, Batch 1600] loss: 0.010496192835727242
[Epoch 24, Batch 1700] loss: 0.005768105855718204
[Epoch 24, Batch 1800] loss: 0.01131037477767677
**STATS for Epoch 24** : 
Average training loss: 0.0005
Average validation loss: 0.0597
Validation Accuracy: 0.9857
Overfitting: 0.0593
Fold 2 validation loss: 0.0597
Mean validation loss across all folds for Trial 3 is 0.0605 with trial config:  l1: 128, l2: 128, lr: 0.0006672367170464204, batch_size: 16
[I 2024-11-25 15:12:55,038] Trial 2 finished with value: 0.06046210698719751 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0006672367170464204, 'batch_size': 16}. Best is trial 2 with value: 0.06046210698719751.

Selected Hyperparameters for Trial 4:
  l1: 128, l2: 128, lr: 0.07286653737491042, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.9029653054475784
[Epoch 1, Batch 200] loss: 1.939046367406845
[Epoch 1, Batch 300] loss: 1.670870486497879
[Epoch 1, Batch 400] loss: 1.4522090829908847
[Epoch 1, Batch 500] loss: 1.8212971025705338
[Epoch 1, Batch 600] loss: 2.31511421918869
[Epoch 1, Batch 700] loss: 2.30938987493515
[Epoch 1, Batch 800] loss: 2.3073679041862487
[Epoch 1, Batch 900] loss: 2.306848819255829
[Epoch 1, Batch 1000] loss: 2.314516909122467
[Epoch 1, Batch 1100] loss: 2.3088367080688474
[Epoch 1, Batch 1200] loss: 2.3073110580444336
[Epoch 1, Batch 1300] loss: 2.3151078605651856
[Epoch 1, Batch 1400] loss: 2.3055250072479248
[Epoch 1, Batch 1500] loss: 2.3144742178916933
[Epoch 1, Batch 1600] loss: 2.3141982889175416
[Epoch 1, Batch 1700] loss: 2.3091021084785464
[Epoch 1, Batch 1800] loss: 2.3135269594192507
**STATS for Epoch 1** : 
Average training loss: 0.0925
Average validation loss: 2.3162
Validation Accuracy: 0.0982
Overfitting: 2.2237
Best model saved at epoch 1 with validation loss: 2.3162
[Epoch 2, Batch 100] loss: 2.3140003633499147
[Epoch 2, Batch 200] loss: 2.3086901617050173
[Epoch 2, Batch 300] loss: 2.3161706042289736
[Epoch 2, Batch 400] loss: 2.3157745480537413
[Epoch 2, Batch 500] loss: 2.31166298866272
[Epoch 2, Batch 600] loss: 2.30970205783844
[Epoch 2, Batch 700] loss: 2.313056664466858
[Epoch 2, Batch 800] loss: 2.312658660411835
[Epoch 2, Batch 900] loss: 2.3153486585617067
[Epoch 2, Batch 1000] loss: 2.311678159236908
[Epoch 2, Batch 1100] loss: 2.311224343776703
[Epoch 2, Batch 1200] loss: 2.307378361225128
[Epoch 2, Batch 1300] loss: 2.3109681820869445
[Epoch 2, Batch 1400] loss: 2.3147517919540403
[Epoch 2, Batch 1500] loss: 2.3124324250221253
[Epoch 2, Batch 1600] loss: 2.309997673034668
[Epoch 2, Batch 1700] loss: 2.31198899269104
[Epoch 2, Batch 1800] loss: 2.314766938686371
**STATS for Epoch 2** : 
Average training loss: 0.0924
Average validation loss: 2.3155
Validation Accuracy: 0.1036
Overfitting: 2.2232
Best model saved at epoch 2 with validation loss: 2.3155
[Epoch 3, Batch 100] loss: 2.3106713676452637
[Epoch 3, Batch 200] loss: 2.3118794441223143
[Epoch 3, Batch 300] loss: 2.3083957839012146
[Epoch 3, Batch 400] loss: 2.3128388571739196
[Epoch 3, Batch 500] loss: 2.3082697200775146
[Epoch 3, Batch 600] loss: 2.309755494594574
[Epoch 3, Batch 700] loss: 2.3144740724563597
[Epoch 3, Batch 800] loss: 2.3098806285858156
[Epoch 3, Batch 900] loss: 2.30881281375885
[Epoch 3, Batch 1000] loss: 2.3111079621315
[Epoch 3, Batch 1100] loss: 2.313348751068115
[Epoch 3, Batch 1200] loss: 2.3161490869522097
[Epoch 3, Batch 1300] loss: 2.3106426095962522
[Epoch 3, Batch 1400] loss: 2.3128167462348936
[Epoch 3, Batch 1500] loss: 2.3065286111831664
[Epoch 3, Batch 1600] loss: 2.31428302526474
[Epoch 3, Batch 1700] loss: 2.3098692440986635
[Epoch 3, Batch 1800] loss: 2.3130374145507813
**STATS for Epoch 3** : 
Average training loss: 0.0924
Average validation loss: 2.3153
Validation Accuracy: 0.1007
Overfitting: 2.2229
Best model saved at epoch 3 with validation loss: 2.3153
[Epoch 4, Batch 100] loss: 2.3180348110198974
[Epoch 4, Batch 200] loss: 2.3110949635505675
[Epoch 4, Batch 300] loss: 2.309052381515503
[Epoch 4, Batch 400] loss: 2.3095749974250794
[Epoch 4, Batch 500] loss: 2.3108840012550353
[Epoch 4, Batch 600] loss: 2.313768301010132
[Epoch 4, Batch 700] loss: 2.3123417782783506
[Epoch 4, Batch 800] loss: 2.306475429534912
[Epoch 4, Batch 900] loss: 2.3120552825927736
[Epoch 4, Batch 1000] loss: 2.310156216621399
[Epoch 4, Batch 1100] loss: 2.3099165463447573
[Epoch 4, Batch 1200] loss: 2.313335862159729
[Epoch 4, Batch 1300] loss: 2.3102103900909423
[Epoch 4, Batch 1400] loss: 2.312228877544403
[Epoch 4, Batch 1500] loss: 2.313552448749542
[Epoch 4, Batch 1600] loss: 2.3075738620758055
[Epoch 4, Batch 1700] loss: 2.3106061148643495
[Epoch 4, Batch 1800] loss: 2.307318375110626
**STATS for Epoch 4** : 
Average training loss: 0.0925
Average validation loss: 2.3084
Validation Accuracy: 0.1122
Overfitting: 2.2159
Best model saved at epoch 4 with validation loss: 2.3084
[Epoch 5, Batch 100] loss: 2.3126805520057676
[Epoch 5, Batch 200] loss: 2.3137524485588075
[Epoch 5, Batch 300] loss: 2.3162123370170593
[Epoch 5, Batch 400] loss: 2.3079740381240845
[Epoch 5, Batch 500] loss: 2.3127314496040343
[Epoch 5, Batch 600] loss: 2.308438060283661
[Epoch 5, Batch 700] loss: 2.305789442062378
[Epoch 5, Batch 800] loss: 2.3112109661102296
[Epoch 5, Batch 900] loss: 2.313043818473816
[Epoch 5, Batch 1000] loss: 2.317504858970642
[Epoch 5, Batch 1100] loss: 2.312493381500244
[Epoch 5, Batch 1200] loss: 2.311501111984253
[Epoch 5, Batch 1300] loss: 2.310524888038635
[Epoch 5, Batch 1400] loss: 2.309843602180481
[Epoch 5, Batch 1500] loss: 2.316420876979828
[Epoch 5, Batch 1600] loss: 2.311553738117218
[Epoch 5, Batch 1700] loss: 2.3144586205482485
[Epoch 5, Batch 1800] loss: 2.308182680606842
**STATS for Epoch 5** : 
Average training loss: 0.0923
Average validation loss: 2.3173
Validation Accuracy: 0.1122
Overfitting: 2.2250
[Epoch 6, Batch 100] loss: 2.30826491355896
[Epoch 6, Batch 200] loss: 2.309225380420685
[Epoch 6, Batch 300] loss: 2.3097888255119323
[Epoch 6, Batch 400] loss: 2.3139331364631652
[Epoch 6, Batch 500] loss: 2.3094954180717466
[Epoch 6, Batch 600] loss: 2.3118008470535276
[Epoch 6, Batch 700] loss: 2.3099949860572817
[Epoch 6, Batch 800] loss: 2.3138811492919924
[Epoch 6, Batch 900] loss: 2.3124230790138243
[Epoch 6, Batch 1000] loss: 2.3069927048683168
[Epoch 6, Batch 1100] loss: 2.3152725887298584
[Epoch 6, Batch 1200] loss: 2.311318395137787
[Epoch 6, Batch 1300] loss: 2.308331353664398
[Epoch 6, Batch 1400] loss: 2.3122719144821167
[Epoch 6, Batch 1500] loss: 2.313270556926727
[Epoch 6, Batch 1600] loss: 2.312013533115387
[Epoch 6, Batch 1700] loss: 2.31170583486557
[Epoch 6, Batch 1800] loss: 2.3094742035865785
**STATS for Epoch 6** : 
Average training loss: 0.0925
Average validation loss: 2.3058
Validation Accuracy: 0.1122
Overfitting: 2.2133
Best model saved at epoch 6 with validation loss: 2.3058
[Epoch 7, Batch 100] loss: 2.314218239784241
[Epoch 7, Batch 200] loss: 2.3121613025665284
[Epoch 7, Batch 300] loss: 2.311542820930481
[Epoch 7, Batch 400] loss: 2.315680830478668
[Epoch 7, Batch 500] loss: 2.310302937030792
[Epoch 7, Batch 600] loss: 2.3120813751220703
[Epoch 7, Batch 700] loss: 2.31734881401062
[Epoch 7, Batch 800] loss: 2.3117819929122927
[Epoch 7, Batch 900] loss: 2.3137030482292174
[Epoch 7, Batch 1000] loss: 2.3112201046943666
[Epoch 7, Batch 1100] loss: 2.3157022356987
[Epoch 7, Batch 1200] loss: 2.3128776574134826
[Epoch 7, Batch 1300] loss: 2.3111957192420958
[Epoch 7, Batch 1400] loss: 2.3101901698112486
[Epoch 7, Batch 1500] loss: 2.3075297045707703
[Epoch 7, Batch 1600] loss: 2.315156137943268
[Epoch 7, Batch 1700] loss: 2.3079829621315002
[Epoch 7, Batch 1800] loss: 2.3109837555885315
**STATS for Epoch 7** : 
Average training loss: 0.0924
Average validation loss: 2.3089
Validation Accuracy: 0.1122
Overfitting: 2.2165
[Epoch 8, Batch 100] loss: 2.312537295818329
[Epoch 8, Batch 200] loss: 2.3135576701164244
[Epoch 8, Batch 300] loss: 2.3098005771636965
[Epoch 8, Batch 400] loss: 2.3143532061576844
[Epoch 8, Batch 500] loss: 2.312480571269989
[Epoch 8, Batch 600] loss: 2.3122339725494383
[Epoch 8, Batch 700] loss: 2.309803342819214
[Epoch 8, Batch 800] loss: 2.3103480768203735
[Epoch 8, Batch 900] loss: 2.311274855136871
[Epoch 8, Batch 1000] loss: 2.309333825111389
[Epoch 8, Batch 1100] loss: 2.312202723026276
[Epoch 8, Batch 1200] loss: 2.30457733631134
[Epoch 8, Batch 1300] loss: 2.3132950615882875
[Epoch 8, Batch 1400] loss: 2.3079606223106386
[Epoch 8, Batch 1500] loss: 2.309143350124359
[Epoch 8, Batch 1600] loss: 2.3093199348449707
[Epoch 8, Batch 1700] loss: 2.3181142163276673
[Epoch 8, Batch 1800] loss: 2.3114109563827516
**STATS for Epoch 8** : 
Average training loss: 0.0924
Average validation loss: 2.3058
Validation Accuracy: 0.1122
Overfitting: 2.2134
[Epoch 9, Batch 100] loss: 2.309835660457611
[Epoch 9, Batch 200] loss: 2.3131095576286316
[Epoch 9, Batch 300] loss: 2.311137840747833
[Epoch 9, Batch 400] loss: 2.3142878222465515
[Epoch 9, Batch 500] loss: 2.3120574927330018
[Epoch 9, Batch 600] loss: 2.3105687379837034
[Epoch 9, Batch 700] loss: 2.3085809111595155
[Epoch 9, Batch 800] loss: 2.3113875865936278
[Epoch 9, Batch 900] loss: 2.3069822502136232
[Epoch 9, Batch 1000] loss: 2.3125554847717287
[Epoch 9, Batch 1100] loss: 2.3121886539459227
[Epoch 9, Batch 1200] loss: 2.307754695415497
[Epoch 9, Batch 1300] loss: 2.3117032194137574
[Epoch 9, Batch 1400] loss: 2.3050654792785643
[Epoch 9, Batch 1500] loss: 2.311769485473633
[Epoch 9, Batch 1600] loss: 2.304051125049591
[Epoch 9, Batch 1700] loss: 2.3082151341438295
[Epoch 9, Batch 1800] loss: 2.312788074016571
**STATS for Epoch 9** : 
Average training loss: 0.0924
Average validation loss: 2.3244
Validation Accuracy: 0.1122
Overfitting: 2.2320
[Epoch 10, Batch 100] loss: 2.3139963603019713
[Epoch 10, Batch 200] loss: 2.311759057044983
[Epoch 10, Batch 300] loss: 2.311243669986725
[Epoch 10, Batch 400] loss: 2.309346327781677
[Epoch 10, Batch 500] loss: 2.317964630126953
[Epoch 10, Batch 600] loss: 2.311097617149353
[Epoch 10, Batch 700] loss: 2.310403814315796
[Epoch 10, Batch 800] loss: 2.3147779273986817
[Epoch 10, Batch 900] loss: 2.312645115852356
[Epoch 10, Batch 1000] loss: 2.3094932198524476
[Epoch 10, Batch 1100] loss: 2.3111911392211915
[Epoch 10, Batch 1200] loss: 2.315253083705902
[Epoch 10, Batch 1300] loss: 2.312915823459625
[Epoch 10, Batch 1400] loss: 2.3144403314590454
[Epoch 10, Batch 1500] loss: 2.311241183280945
[Epoch 10, Batch 1600] loss: 2.312411201000214
[Epoch 10, Batch 1700] loss: 2.313789975643158
[Epoch 10, Batch 1800] loss: 2.3101269698143003
**STATS for Epoch 10** : 
Average training loss: 0.0924
Average validation loss: 2.3159
Validation Accuracy: 0.1036
Overfitting: 2.2235
[Epoch 11, Batch 100] loss: 2.313858380317688
[Epoch 11, Batch 200] loss: 2.3140702629089356
[Epoch 11, Batch 300] loss: 2.3181540417671203
[Epoch 11, Batch 400] loss: 2.3072218322753906
[Epoch 11, Batch 500] loss: 2.311307191848755
[Epoch 11, Batch 600] loss: 2.3115502548217775
[Epoch 11, Batch 700] loss: 2.3093285393714904
[Epoch 11, Batch 800] loss: 2.307423379421234
[Epoch 11, Batch 900] loss: 2.310921769142151
[Epoch 11, Batch 1000] loss: 2.3092924213409423
[Epoch 11, Batch 1100] loss: 2.30900066614151
[Epoch 11, Batch 1200] loss: 2.3117873311042785
[Epoch 11, Batch 1300] loss: 2.3147565650939943
[Epoch 11, Batch 1400] loss: 2.3125487971305847
[Epoch 11, Batch 1500] loss: 2.311779019832611
[Epoch 11, Batch 1600] loss: 2.311751358509064
[Epoch 11, Batch 1700] loss: 2.3087612318992616
[Epoch 11, Batch 1800] loss: 2.3078506851196288
**STATS for Epoch 11** : 
Average training loss: 0.0924
Average validation loss: 2.3091
Validation Accuracy: 0.1007
Overfitting: 2.2166
[Epoch 12, Batch 100] loss: 2.3119598054885864
[Epoch 12, Batch 200] loss: 2.3150663137435914
[Epoch 12, Batch 300] loss: 2.312907702922821
[Epoch 12, Batch 400] loss: 2.309394509792328
[Epoch 12, Batch 500] loss: 2.3163750624656676
[Epoch 12, Batch 600] loss: 2.313588707447052
[Epoch 12, Batch 700] loss: 2.3127109217643738
[Epoch 12, Batch 800] loss: 2.313633782863617
[Epoch 12, Batch 900] loss: 2.3154225659370424
[Epoch 12, Batch 1000] loss: 2.3112190985679626
[Epoch 12, Batch 1100] loss: 2.31358824968338
[Epoch 12, Batch 1200] loss: 2.310605273246765
[Epoch 12, Batch 1300] loss: 2.310615375041962
[Epoch 12, Batch 1400] loss: 2.309620432853699
[Epoch 12, Batch 1500] loss: 2.312613205909729
[Epoch 12, Batch 1600] loss: 2.3121707034111023
[Epoch 12, Batch 1700] loss: 2.3082108211517336
[Epoch 12, Batch 1800] loss: 2.311296362876892
**STATS for Epoch 12** : 
Average training loss: 0.0925
Average validation loss: 2.3113
Validation Accuracy: 0.0987
Overfitting: 2.2188
[Epoch 13, Batch 100] loss: 2.308636276721954
[Epoch 13, Batch 200] loss: 2.304026463031769
[Epoch 13, Batch 300] loss: 2.3148603725433348
[Epoch 13, Batch 400] loss: 2.312808244228363
[Epoch 13, Batch 500] loss: 2.310970687866211
[Epoch 13, Batch 600] loss: 2.3084298276901247
[Epoch 13, Batch 700] loss: 2.3053561353683474
[Epoch 13, Batch 800] loss: 2.3109076285362242
[Epoch 13, Batch 900] loss: 2.313224151134491
[Epoch 13, Batch 1000] loss: 2.3100199723243713
[Epoch 13, Batch 1100] loss: 2.3106380200386045
[Epoch 13, Batch 1200] loss: 2.3140245127677916
[Epoch 13, Batch 1300] loss: 2.310892789363861
[Epoch 13, Batch 1400] loss: 2.311809618473053
[Epoch 13, Batch 1500] loss: 2.314001009464264
[Epoch 13, Batch 1600] loss: 2.3088536047935486
[Epoch 13, Batch 1700] loss: 2.310079834461212
[Epoch 13, Batch 1800] loss: 2.311694152355194
**STATS for Epoch 13** : 
Average training loss: 0.0926
Average validation loss: 2.3045
Validation Accuracy: 0.1122
Overfitting: 2.2119
Best model saved at epoch 13 with validation loss: 2.3045
[Epoch 14, Batch 100] loss: 2.306865322589874
[Epoch 14, Batch 200] loss: 2.3104487895965575
[Epoch 14, Batch 300] loss: 2.304819324016571
[Epoch 14, Batch 400] loss: 2.3103135204315186
[Epoch 14, Batch 500] loss: 2.3159692096710205
[Epoch 14, Batch 600] loss: 2.306670627593994
[Epoch 14, Batch 700] loss: 2.308519585132599
[Epoch 14, Batch 800] loss: 2.310614895820618
[Epoch 14, Batch 900] loss: 2.31400771856308
[Epoch 14, Batch 1000] loss: 2.309302864074707
[Epoch 14, Batch 1100] loss: 2.31257892370224
[Epoch 14, Batch 1200] loss: 2.307450177669525
[Epoch 14, Batch 1300] loss: 2.308868589401245
[Epoch 14, Batch 1400] loss: 2.3126018381118776
[Epoch 14, Batch 1500] loss: 2.3140672254562378
[Epoch 14, Batch 1600] loss: 2.3121250295639038
[Epoch 14, Batch 1700] loss: 2.315175471305847
[Epoch 14, Batch 1800] loss: 2.3133753061294557
**STATS for Epoch 14** : 
Average training loss: 0.0925
Average validation loss: 2.3089
Validation Accuracy: 0.1036
Overfitting: 2.2164
[Epoch 15, Batch 100] loss: 2.3098486113548278
[Epoch 15, Batch 200] loss: 2.305657320022583
[Epoch 15, Batch 300] loss: 2.314355664253235
[Epoch 15, Batch 400] loss: 2.3180926036834717
[Epoch 15, Batch 500] loss: 2.3093302059173584
[Epoch 15, Batch 600] loss: 2.3103769421577454
[Epoch 15, Batch 700] loss: 2.307248613834381
[Epoch 15, Batch 800] loss: 2.3058456420898437
[Epoch 15, Batch 900] loss: 2.313172104358673
[Epoch 15, Batch 1000] loss: 2.3149742102622985
[Epoch 15, Batch 1100] loss: 2.311998927593231
[Epoch 15, Batch 1200] loss: 2.3142606735229494
[Epoch 15, Batch 1300] loss: 2.3049633955955504
[Epoch 15, Batch 1400] loss: 2.3147826409339904
[Epoch 15, Batch 1500] loss: 2.3118586921691895
[Epoch 15, Batch 1600] loss: 2.3091113424301146
[Epoch 15, Batch 1700] loss: 2.313293640613556
[Epoch 15, Batch 1800] loss: 2.3100371098518373
**STATS for Epoch 15** : 
Average training loss: 0.0925
Average validation loss: 2.3134
Validation Accuracy: 0.1007
Overfitting: 2.2209
[Epoch 16, Batch 100] loss: 2.3122279715538023
[Epoch 16, Batch 200] loss: 2.3074233412742613
[Epoch 16, Batch 300] loss: 2.3141028904914855
[Epoch 16, Batch 400] loss: 2.3084325408935547
[Epoch 16, Batch 500] loss: 2.3097825598716737
[Epoch 16, Batch 600] loss: 2.3140191411972046
[Epoch 16, Batch 700] loss: 2.312575023174286
[Epoch 16, Batch 800] loss: 2.3139634275436403
[Epoch 16, Batch 900] loss: 2.31071254491806
[Epoch 16, Batch 1000] loss: 2.311000232696533
[Epoch 16, Batch 1100] loss: 2.305068538188934
[Epoch 16, Batch 1200] loss: 2.3088830423355104
[Epoch 16, Batch 1300] loss: 2.3107858967781065
[Epoch 16, Batch 1400] loss: 2.311438443660736
[Epoch 16, Batch 1500] loss: 2.3100772356987
[Epoch 16, Batch 1600] loss: 2.3172097110748293
[Epoch 16, Batch 1700] loss: 2.313676414489746
[Epoch 16, Batch 1800] loss: 2.3121096467971802
**STATS for Epoch 16** : 
Average training loss: 0.0923
Average validation loss: 2.3221
Validation Accuracy: 0.1122
Overfitting: 2.2298
[Epoch 17, Batch 100] loss: 2.310272297859192
[Epoch 17, Batch 200] loss: 2.315456531047821
[Epoch 17, Batch 300] loss: 2.3082976388931273
[Epoch 17, Batch 400] loss: 2.316405358314514
[Epoch 17, Batch 500] loss: 2.310639045238495
[Epoch 17, Batch 600] loss: 2.3129920601844787
[Epoch 17, Batch 700] loss: 2.3097124481201172
[Epoch 17, Batch 800] loss: 2.3060672807693483
[Epoch 17, Batch 900] loss: 2.3131122899055483
[Epoch 17, Batch 1000] loss: 2.313228437900543
[Epoch 17, Batch 1100] loss: 2.310859498977661
[Epoch 17, Batch 1200] loss: 2.307658705711365
[Epoch 17, Batch 1300] loss: 2.3083572149276734
[Epoch 17, Batch 1400] loss: 2.3085796546936037
[Epoch 17, Batch 1500] loss: 2.313015241622925
[Epoch 17, Batch 1600] loss: 2.313324167728424
[Epoch 17, Batch 1700] loss: 2.3141911029815674
[Epoch 17, Batch 1800] loss: 2.3106019616127016
**STATS for Epoch 17** : 
Average training loss: 0.0927
Average validation loss: 2.3081
Validation Accuracy: 0.0998
Overfitting: 2.2154
[Epoch 18, Batch 100] loss: 2.3108277320861816
[Epoch 18, Batch 200] loss: 2.3131654596328737
[Epoch 18, Batch 300] loss: 2.3144371032714846
[Epoch 18, Batch 400] loss: 2.3081564140319824
[Epoch 18, Batch 500] loss: 2.312580325603485
[Epoch 18, Batch 600] loss: 2.3136288642883303
[Epoch 18, Batch 700] loss: 2.311131467819214
[Epoch 18, Batch 800] loss: 2.311814157962799
[Epoch 18, Batch 900] loss: 2.3142510080337524
[Epoch 18, Batch 1000] loss: 2.3169533467292784
[Epoch 18, Batch 1100] loss: 2.3136153268814086
[Epoch 18, Batch 1200] loss: 2.30968425989151
[Epoch 18, Batch 1300] loss: 2.310921802520752
[Epoch 18, Batch 1400] loss: 2.311973669528961
[Epoch 18, Batch 1500] loss: 2.3121149492263795
[Epoch 18, Batch 1600] loss: 2.3077848505973817
[Epoch 18, Batch 1700] loss: 2.3114480328559877
[Epoch 18, Batch 1800] loss: 2.31364994764328
**STATS for Epoch 18** : 
Average training loss: 0.0924
Average validation loss: 2.3121
Validation Accuracy: 0.1007
Overfitting: 2.2198
[Epoch 19, Batch 100] loss: 2.310871212482452
[Epoch 19, Batch 200] loss: 2.3084635233879087
[Epoch 19, Batch 300] loss: 2.3113168048858643
[Epoch 19, Batch 400] loss: 2.312944781780243
[Epoch 19, Batch 500] loss: 2.312550401687622
[Epoch 19, Batch 600] loss: 2.308181688785553
[Epoch 19, Batch 700] loss: 2.305531075000763
[Epoch 19, Batch 800] loss: 2.310242772102356
[Epoch 19, Batch 900] loss: 2.3125895500183105
[Epoch 19, Batch 1000] loss: 2.311886763572693
[Epoch 19, Batch 1100] loss: 2.313888280391693
[Epoch 19, Batch 1200] loss: 2.31613477230072
[Epoch 19, Batch 1300] loss: 2.3029926466941832
[Epoch 19, Batch 1400] loss: 2.317025535106659
[Epoch 19, Batch 1500] loss: 2.3156425380706787
[Epoch 19, Batch 1600] loss: 2.309845652580261
[Epoch 19, Batch 1700] loss: 2.310041079521179
[Epoch 19, Batch 1800] loss: 2.3113961029052734
**STATS for Epoch 19** : 
Average training loss: 0.0924
Average validation loss: 2.3120
Validation Accuracy: 0.1122
Overfitting: 2.2196
[Epoch 20, Batch 100] loss: 2.3096086478233335
[Epoch 20, Batch 200] loss: 2.307934813499451
[Epoch 20, Batch 300] loss: 2.3148074531555176
[Epoch 20, Batch 400] loss: 2.311041474342346
[Epoch 20, Batch 500] loss: 2.314153072834015
[Epoch 20, Batch 600] loss: 2.3079248237609864
[Epoch 20, Batch 700] loss: 2.3099925923347473
[Epoch 20, Batch 800] loss: 2.310723211765289
[Epoch 20, Batch 900] loss: 2.3094804286956787
[Epoch 20, Batch 1000] loss: 2.3140290498733522
[Epoch 20, Batch 1100] loss: 2.313467483520508
[Epoch 20, Batch 1200] loss: 2.312653610706329
[Epoch 20, Batch 1300] loss: 2.317459964752197
[Epoch 20, Batch 1400] loss: 2.3139388394355773
[Epoch 20, Batch 1500] loss: 2.305579092502594
[Epoch 20, Batch 1600] loss: 2.313043475151062
[Epoch 20, Batch 1700] loss: 2.3124284410476683
[Epoch 20, Batch 1800] loss: 2.3094002866744994
**STATS for Epoch 20** : 
Average training loss: 0.0926
Average validation loss: 2.3147
Validation Accuracy: 0.0987
Overfitting: 2.2221
[Epoch 21, Batch 100] loss: 2.3125776076316833
[Epoch 21, Batch 200] loss: 2.310771129131317
[Epoch 21, Batch 300] loss: 2.3126051878929137
[Epoch 21, Batch 400] loss: 2.309716818332672
[Epoch 21, Batch 500] loss: 2.3124649786949156
[Epoch 21, Batch 600] loss: 2.3073925733566285
[Epoch 21, Batch 700] loss: 2.3153903484344482
[Epoch 21, Batch 800] loss: 2.3101765608787534
[Epoch 21, Batch 900] loss: 2.311785933971405
[Epoch 21, Batch 1000] loss: 2.310843875408173
[Epoch 21, Batch 1100] loss: 2.312451431751251
[Epoch 21, Batch 1200] loss: 2.311164975166321
[Epoch 21, Batch 1300] loss: 2.313470771312714
[Epoch 21, Batch 1400] loss: 2.3093255066871645
[Epoch 21, Batch 1500] loss: 2.311654319763184
[Epoch 21, Batch 1600] loss: 2.3067667651176453
[Epoch 21, Batch 1700] loss: 2.316293888092041
[Epoch 21, Batch 1800] loss: 2.3064847779273987
**STATS for Epoch 21** : 
Average training loss: 0.0927
Average validation loss: 2.3091
Validation Accuracy: 0.1007
Overfitting: 2.2164
[Epoch 22, Batch 100] loss: 2.3115004467964173
[Epoch 22, Batch 200] loss: 2.3058083295822143
[Epoch 22, Batch 300] loss: 2.3110062646865845
[Epoch 22, Batch 400] loss: 2.3125991511344908
[Epoch 22, Batch 500] loss: 2.3086852192878724
[Epoch 22, Batch 600] loss: 2.31251517534256
[Epoch 22, Batch 700] loss: 2.3050310683250426
[Epoch 22, Batch 800] loss: 2.31340145111084
[Epoch 22, Batch 900] loss: 2.313269832134247
[Epoch 22, Batch 1000] loss: 2.315782971382141
[Epoch 22, Batch 1100] loss: 2.3147640299797057
[Epoch 22, Batch 1200] loss: 2.3107456517219545
[Epoch 22, Batch 1300] loss: 2.306403224468231
[Epoch 22, Batch 1400] loss: 2.313344430923462
[Epoch 22, Batch 1500] loss: 2.312587697505951
[Epoch 22, Batch 1600] loss: 2.3128128123283385
[Epoch 22, Batch 1700] loss: 2.3152284669876098
[Epoch 22, Batch 1800] loss: 2.3086338448524475
**STATS for Epoch 22** : 
Average training loss: 0.0923
Average validation loss: 2.3065
Validation Accuracy: 0.0986
Overfitting: 2.2142
[Epoch 23, Batch 100] loss: 2.3136275029182434
[Epoch 23, Batch 200] loss: 2.3105273175239565
[Epoch 23, Batch 300] loss: 2.307531282901764
[Epoch 23, Batch 400] loss: 2.3120702147483825
[Epoch 23, Batch 500] loss: 2.307687838077545
[Epoch 23, Batch 600] loss: 2.3141187810897828
[Epoch 23, Batch 700] loss: 2.316152637004852
[Epoch 23, Batch 800] loss: 2.3087117648124695
[Epoch 23, Batch 900] loss: 2.3113174343109133
[Epoch 23, Batch 1000] loss: 2.313369116783142
[Epoch 23, Batch 1100] loss: 2.3103855872154235
[Epoch 23, Batch 1200] loss: 2.30444792509079
[Epoch 23, Batch 1300] loss: 2.3091544318199158
[Epoch 23, Batch 1400] loss: 2.3155098509788514
[Epoch 23, Batch 1500] loss: 2.309266731739044
[Epoch 23, Batch 1600] loss: 2.3085871744155884
[Epoch 23, Batch 1700] loss: 2.3067121076583863
[Epoch 23, Batch 1800] loss: 2.314934513568878
**STATS for Epoch 23** : 
Average training loss: 0.0922
Average validation loss: 2.3092
Validation Accuracy: 0.1007
Overfitting: 2.2170
[Epoch 24, Batch 100] loss: 2.3104256987571716
[Epoch 24, Batch 200] loss: 2.310355715751648
[Epoch 24, Batch 300] loss: 2.31368159532547
[Epoch 24, Batch 400] loss: 2.3155880331993104
[Epoch 24, Batch 500] loss: 2.3130433559417725
[Epoch 24, Batch 600] loss: 2.308399128913879
[Epoch 24, Batch 700] loss: 2.3123214507102965
[Epoch 24, Batch 800] loss: 2.3095090341567994
[Epoch 24, Batch 900] loss: 2.317239763736725
[Epoch 24, Batch 1000] loss: 2.3057156729698183
[Epoch 24, Batch 1100] loss: 2.3135246872901916
[Epoch 24, Batch 1200] loss: 2.3103162336349485
[Epoch 24, Batch 1300] loss: 2.3107282423973086
[Epoch 24, Batch 1400] loss: 2.309151756763458
[Epoch 24, Batch 1500] loss: 2.315400722026825
[Epoch 24, Batch 1600] loss: 2.3137714719772338
[Epoch 24, Batch 1700] loss: 2.3081928062438966
[Epoch 24, Batch 1800] loss: 2.3132741689682006
**STATS for Epoch 24** : 
Average training loss: 0.0924
Average validation loss: 2.3098
Validation Accuracy: 0.0991
Overfitting: 2.2173
Fold 1 validation loss: 2.3098
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.0292642378807066
[Epoch 1, Batch 200] loss: 2.331396133899689
[Epoch 1, Batch 300] loss: 2.3136044549942016
[Epoch 1, Batch 400] loss: 2.3143660378456117
[Epoch 1, Batch 500] loss: 2.3112379837036134
[Epoch 1, Batch 600] loss: 2.307704734802246
[Epoch 1, Batch 700] loss: 2.3076234555244444
[Epoch 1, Batch 800] loss: 2.318449673652649
[Epoch 1, Batch 900] loss: 2.3124968457221984
[Epoch 1, Batch 1000] loss: 2.3115115904808046
[Epoch 1, Batch 1100] loss: 2.3124545288085936
[Epoch 1, Batch 1200] loss: 2.310925977230072
[Epoch 1, Batch 1300] loss: 2.315057187080383
[Epoch 1, Batch 1400] loss: 2.3069723725318907
[Epoch 1, Batch 1500] loss: 2.3073144435882567
[Epoch 1, Batch 1600] loss: 2.314139802455902
[Epoch 1, Batch 1700] loss: 2.3072332906723023
[Epoch 1, Batch 1800] loss: 2.3134818983078005
**STATS for Epoch 1** : 
Average training loss: 0.0925
Average validation loss: 2.3056
Validation Accuracy: 0.1052
Overfitting: 2.2132
Best model saved at epoch 1 with validation loss: 2.3056
[Epoch 2, Batch 100] loss: 2.30999671459198
[Epoch 2, Batch 200] loss: 2.311492962837219
[Epoch 2, Batch 300] loss: 2.314894359111786
[Epoch 2, Batch 400] loss: 2.31132173538208
[Epoch 2, Batch 500] loss: 2.315735523700714
[Epoch 2, Batch 600] loss: 2.312422716617584
[Epoch 2, Batch 700] loss: 2.31143070936203
[Epoch 2, Batch 800] loss: 2.3118535327911376
[Epoch 2, Batch 900] loss: 2.313218870162964
[Epoch 2, Batch 1000] loss: 2.3101224184036253
[Epoch 2, Batch 1100] loss: 2.3106317591667174
[Epoch 2, Batch 1200] loss: 2.3114087176322937
[Epoch 2, Batch 1300] loss: 2.3103669142723082
[Epoch 2, Batch 1400] loss: 2.3089366602897643
[Epoch 2, Batch 1500] loss: 2.3135405659675596
[Epoch 2, Batch 1600] loss: 2.3117670392990113
[Epoch 2, Batch 1700] loss: 2.3098518228530884
[Epoch 2, Batch 1800] loss: 2.3106786751747133
**STATS for Epoch 2** : 
Average training loss: 0.0921
Average validation loss: 2.3222
Validation Accuracy: 0.0964
Overfitting: 2.2301
[Epoch 3, Batch 100] loss: 2.3162595319747923
[Epoch 3, Batch 200] loss: 2.3122721791267393
[Epoch 3, Batch 300] loss: 2.311897189617157
[Epoch 3, Batch 400] loss: 2.311811554431915
[Epoch 3, Batch 500] loss: 2.3134814882278443
[Epoch 3, Batch 600] loss: 2.30889853477478
[Epoch 3, Batch 700] loss: 2.3119832563400267
[Epoch 3, Batch 800] loss: 2.312115635871887
[Epoch 3, Batch 900] loss: 2.311276557445526
[Epoch 3, Batch 1000] loss: 2.3112398862838743
[Epoch 3, Batch 1100] loss: 2.3126904439926146
[Epoch 3, Batch 1200] loss: 2.313564121723175
[Epoch 3, Batch 1300] loss: 2.3093497157096863
[Epoch 3, Batch 1400] loss: 2.3100114464759827
[Epoch 3, Batch 1500] loss: 2.310146300792694
[Epoch 3, Batch 1600] loss: 2.3130601978302003
[Epoch 3, Batch 1700] loss: 2.3092544627189637
[Epoch 3, Batch 1800] loss: 2.311375901699066
**STATS for Epoch 3** : 
Average training loss: 0.0923
Average validation loss: 2.3055
Validation Accuracy: 0.1126
Overfitting: 2.2131
Best model saved at epoch 3 with validation loss: 2.3055
[Epoch 4, Batch 100] loss: 2.3081265926361083
[Epoch 4, Batch 200] loss: 2.3133951210975647
[Epoch 4, Batch 300] loss: 2.31333291053772
[Epoch 4, Batch 400] loss: 2.309914917945862
[Epoch 4, Batch 500] loss: 2.3098781156539916
[Epoch 4, Batch 600] loss: 2.311456770896912
[Epoch 4, Batch 700] loss: 2.3125283336639404
[Epoch 4, Batch 800] loss: 2.3115557765960695
[Epoch 4, Batch 900] loss: 2.3052943968772888
[Epoch 4, Batch 1000] loss: 2.308794052600861
[Epoch 4, Batch 1100] loss: 2.311677052974701
[Epoch 4, Batch 1200] loss: 2.3129526352882386
[Epoch 4, Batch 1300] loss: 2.3127528333663943
[Epoch 4, Batch 1400] loss: 2.3109615349769594
[Epoch 4, Batch 1500] loss: 2.314586935043335
[Epoch 4, Batch 1600] loss: 2.314791066646576
[Epoch 4, Batch 1700] loss: 2.3097062301635742
[Epoch 4, Batch 1800] loss: 2.310549404621124
**STATS for Epoch 4** : 
Average training loss: 0.0925
Average validation loss: 2.3100
Validation Accuracy: 0.1126
Overfitting: 2.2176
[Epoch 5, Batch 100] loss: 2.3127416229248046
[Epoch 5, Batch 200] loss: 2.3102649903297423
[Epoch 5, Batch 300] loss: 2.3092529153823853
[Epoch 5, Batch 400] loss: 2.3091043758392336
[Epoch 5, Batch 500] loss: 2.3100738620758055
[Epoch 5, Batch 600] loss: 2.310162696838379
[Epoch 5, Batch 700] loss: 2.3096641206741335
[Epoch 5, Batch 800] loss: 2.3165813994407656
[Epoch 5, Batch 900] loss: 2.3108005285263062
[Epoch 5, Batch 1000] loss: 2.3139699482917786
[Epoch 5, Batch 1100] loss: 2.3101386618614197
[Epoch 5, Batch 1200] loss: 2.312780511379242
[Epoch 5, Batch 1300] loss: 2.312645444869995
[Epoch 5, Batch 1400] loss: 2.3116856813430786
[Epoch 5, Batch 1500] loss: 2.3157849526405334
[Epoch 5, Batch 1600] loss: 2.315167155265808
[Epoch 5, Batch 1700] loss: 2.3137658619880677
[Epoch 5, Batch 1800] loss: 2.302646722793579
**STATS for Epoch 5** : 
Average training loss: 0.0924
Average validation loss: 2.3055
Validation Accuracy: 0.1126
Overfitting: 2.2131
[Epoch 6, Batch 100] loss: 2.315083441734314
[Epoch 6, Batch 200] loss: 2.3084735679626465
[Epoch 6, Batch 300] loss: 2.3113678598403933
[Epoch 6, Batch 400] loss: 2.3161290311813354
[Epoch 6, Batch 500] loss: 2.309272601604462
[Epoch 6, Batch 600] loss: 2.312832672595978
[Epoch 6, Batch 700] loss: 2.3124694299697874
[Epoch 6, Batch 800] loss: 2.317336959838867
[Epoch 6, Batch 900] loss: 2.3130927228927614
[Epoch 6, Batch 1000] loss: 2.312883825302124
[Epoch 6, Batch 1100] loss: 2.313375997543335
[Epoch 6, Batch 1200] loss: 2.3104365706443786
[Epoch 6, Batch 1300] loss: 2.3105124831199646
[Epoch 6, Batch 1400] loss: 2.313108539581299
[Epoch 6, Batch 1500] loss: 2.3141186833381653
[Epoch 6, Batch 1600] loss: 2.3111615490913393
[Epoch 6, Batch 1700] loss: 2.312187185287476
[Epoch 6, Batch 1800] loss: 2.311292254924774
**STATS for Epoch 6** : 
Average training loss: 0.0926
Average validation loss: 2.3074
Validation Accuracy: 0.0992
Overfitting: 2.2148
[Epoch 7, Batch 100] loss: 2.313064384460449
[Epoch 7, Batch 200] loss: 2.3117147493362427
[Epoch 7, Batch 300] loss: 2.3129151272773742
[Epoch 7, Batch 400] loss: 2.3122164535522463
[Epoch 7, Batch 500] loss: 2.3154122376441957
[Epoch 7, Batch 600] loss: 2.3099405694007875
[Epoch 7, Batch 700] loss: 2.3110456371307375
[Epoch 7, Batch 800] loss: 2.315468757152557
[Epoch 7, Batch 900] loss: 2.309886865615845
[Epoch 7, Batch 1000] loss: 2.310538105964661
[Epoch 7, Batch 1100] loss: 2.309486520290375
[Epoch 7, Batch 1200] loss: 2.313736333847046
[Epoch 7, Batch 1300] loss: 2.3094472455978394
[Epoch 7, Batch 1400] loss: 2.313629722595215
[Epoch 7, Batch 1500] loss: 2.310909504890442
[Epoch 7, Batch 1600] loss: 2.3134017062187193
[Epoch 7, Batch 1700] loss: 2.3110943269729614
[Epoch 7, Batch 1800] loss: 2.3100298929214476
**STATS for Epoch 7** : 
Average training loss: 0.0926
Average validation loss: 2.3045
Validation Accuracy: 0.0965
Overfitting: 2.2119
Best model saved at epoch 7 with validation loss: 2.3045
[Epoch 8, Batch 100] loss: 2.3149936985969544
[Epoch 8, Batch 200] loss: 2.3105056357383726
[Epoch 8, Batch 300] loss: 2.3137563943862913
[Epoch 8, Batch 400] loss: 2.3126346707344054
[Epoch 8, Batch 500] loss: 2.315095362663269
[Epoch 8, Batch 600] loss: 2.3121188139915465
[Epoch 8, Batch 700] loss: 2.309704942703247
[Epoch 8, Batch 800] loss: 2.310583381652832
[Epoch 8, Batch 900] loss: 2.3149136686325074
[Epoch 8, Batch 1000] loss: 2.3125070571899413
[Epoch 8, Batch 1100] loss: 2.3113462376594542
[Epoch 8, Batch 1200] loss: 2.3125612330436707
[Epoch 8, Batch 1300] loss: 2.3069787788391114
[Epoch 8, Batch 1400] loss: 2.315716803073883
[Epoch 8, Batch 1500] loss: 2.312081334590912
[Epoch 8, Batch 1600] loss: 2.312707796096802
[Epoch 8, Batch 1700] loss: 2.310322163105011
[Epoch 8, Batch 1800] loss: 2.3057228398323057
**STATS for Epoch 8** : 
Average training loss: 0.0924
Average validation loss: 2.3124
Validation Accuracy: 0.1037
Overfitting: 2.2200
[Epoch 9, Batch 100] loss: 2.3099621629714964
[Epoch 9, Batch 200] loss: 2.3105034947395326
[Epoch 9, Batch 300] loss: 2.312445197105408
[Epoch 9, Batch 400] loss: 2.3120225405693056
[Epoch 9, Batch 500] loss: 2.314733829498291
[Epoch 9, Batch 600] loss: 2.313510248661041
[Epoch 9, Batch 700] loss: 2.3140924620628356
[Epoch 9, Batch 800] loss: 2.308698921203613
[Epoch 9, Batch 900] loss: 2.3115106296539305
[Epoch 9, Batch 1000] loss: 2.3079968523979186
[Epoch 9, Batch 1100] loss: 2.3130887579917907
[Epoch 9, Batch 1200] loss: 2.312311198711395
[Epoch 9, Batch 1300] loss: 2.3099593234062197
[Epoch 9, Batch 1400] loss: 2.316841654777527
[Epoch 9, Batch 1500] loss: 2.315648763179779
[Epoch 9, Batch 1600] loss: 2.3074617266654966
[Epoch 9, Batch 1700] loss: 2.3113379287719726
[Epoch 9, Batch 1800] loss: 2.3136051654815675
**STATS for Epoch 9** : 
Average training loss: 0.0925
Average validation loss: 2.3066
Validation Accuracy: 0.0965
Overfitting: 2.2140
[Epoch 10, Batch 100] loss: 2.3119618773460386
[Epoch 10, Batch 200] loss: 2.313024220466614
[Epoch 10, Batch 300] loss: 2.3141799068450926
[Epoch 10, Batch 400] loss: 2.3177967357635496
[Epoch 10, Batch 500] loss: 2.3039046239852907
[Epoch 10, Batch 600] loss: 2.3156991815567016
[Epoch 10, Batch 700] loss: 2.3090295386314392
[Epoch 10, Batch 800] loss: 2.3137281799316405
[Epoch 10, Batch 900] loss: 2.3101360774040223
[Epoch 10, Batch 1000] loss: 2.3079971957206724
[Epoch 10, Batch 1100] loss: 2.3119227623939516
[Epoch 10, Batch 1200] loss: 2.3067013597488404
[Epoch 10, Batch 1300] loss: 2.3104091000556948
[Epoch 10, Batch 1400] loss: 2.313706121444702
[Epoch 10, Batch 1500] loss: 2.3134614992141724
[Epoch 10, Batch 1600] loss: 2.3132965922355653
[Epoch 10, Batch 1700] loss: 2.3095635032653807
[Epoch 10, Batch 1800] loss: 2.3106826090812684
**STATS for Epoch 10** : 
Average training loss: 0.0925
Average validation loss: 2.3108
Validation Accuracy: 0.1037
Overfitting: 2.2182
[Epoch 11, Batch 100] loss: 2.3118398904800417
[Epoch 11, Batch 200] loss: 2.3105483841896057
[Epoch 11, Batch 300] loss: 2.3114919757843015
[Epoch 11, Batch 400] loss: 2.3132891845703125
[Epoch 11, Batch 500] loss: 2.3143468952178954
[Epoch 11, Batch 600] loss: 2.3131295585632325
[Epoch 11, Batch 700] loss: 2.3097115325927735
[Epoch 11, Batch 800] loss: 2.31922926902771
[Epoch 11, Batch 900] loss: 2.31353077173233
[Epoch 11, Batch 1000] loss: 2.3128225898742674
[Epoch 11, Batch 1100] loss: 2.3151771903038023
[Epoch 11, Batch 1200] loss: 2.309274082183838
[Epoch 11, Batch 1300] loss: 2.315468008518219
[Epoch 11, Batch 1400] loss: 2.310203056335449
[Epoch 11, Batch 1500] loss: 2.3144121527671815
[Epoch 11, Batch 1600] loss: 2.3113974356651306
[Epoch 11, Batch 1700] loss: 2.31102801322937
[Epoch 11, Batch 1800] loss: 2.311218023300171
**STATS for Epoch 11** : 
Average training loss: 0.0924
Average validation loss: 2.3033
Validation Accuracy: 0.1126
Overfitting: 2.2109
Best model saved at epoch 11 with validation loss: 2.3033
[Epoch 12, Batch 100] loss: 2.3084964847564695
[Epoch 12, Batch 200] loss: 2.3102326822280883
[Epoch 12, Batch 300] loss: 2.308504753112793
[Epoch 12, Batch 400] loss: 2.313800549507141
[Epoch 12, Batch 500] loss: 2.3117466592788696
[Epoch 12, Batch 600] loss: 2.307056636810303
[Epoch 12, Batch 700] loss: 2.3143932485580443
[Epoch 12, Batch 800] loss: 2.3111754703521727
[Epoch 12, Batch 900] loss: 2.312159836292267
[Epoch 12, Batch 1000] loss: 2.3075917172431946
[Epoch 12, Batch 1100] loss: 2.3153865242004397
[Epoch 12, Batch 1200] loss: 2.3146556711196897
[Epoch 12, Batch 1300] loss: 2.310847296714783
[Epoch 12, Batch 1400] loss: 2.3091772603988647
[Epoch 12, Batch 1500] loss: 2.3110773038864134
[Epoch 12, Batch 1600] loss: 2.3129727363586428
[Epoch 12, Batch 1700] loss: 2.308265578746796
[Epoch 12, Batch 1800] loss: 2.3135510730743407
**STATS for Epoch 12** : 
Average training loss: 0.0924
Average validation loss: 2.3146
Validation Accuracy: 0.0976
Overfitting: 2.2222
[Epoch 13, Batch 100] loss: 2.3102979922294615
[Epoch 13, Batch 200] loss: 2.310840201377869
[Epoch 13, Batch 300] loss: 2.310914752483368
[Epoch 13, Batch 400] loss: 2.310587863922119
[Epoch 13, Batch 500] loss: 2.313137309551239
[Epoch 13, Batch 600] loss: 2.3121812677383424
[Epoch 13, Batch 700] loss: 2.313947582244873
[Epoch 13, Batch 800] loss: 2.3139767122268675
[Epoch 13, Batch 900] loss: 2.30831134557724
[Epoch 13, Batch 1000] loss: 2.312188677787781
[Epoch 13, Batch 1100] loss: 2.3112366938591005
[Epoch 13, Batch 1200] loss: 2.3113323783874513
[Epoch 13, Batch 1300] loss: 2.3095489263534548
[Epoch 13, Batch 1400] loss: 2.3096422934532166
[Epoch 13, Batch 1500] loss: 2.3121236419677733
[Epoch 13, Batch 1600] loss: 2.312413425445557
[Epoch 13, Batch 1700] loss: 2.311353828907013
[Epoch 13, Batch 1800] loss: 2.3149280738830567
**STATS for Epoch 13** : 
Average training loss: 0.0924
Average validation loss: 2.3141
Validation Accuracy: 0.0903
Overfitting: 2.2217
[Epoch 14, Batch 100] loss: 2.3178534579277037
[Epoch 14, Batch 200] loss: 2.309885277748108
[Epoch 14, Batch 300] loss: 2.3160717463493348
[Epoch 14, Batch 400] loss: 2.312707107067108
[Epoch 14, Batch 500] loss: 2.311602063179016
[Epoch 14, Batch 600] loss: 2.305857458114624
[Epoch 14, Batch 700] loss: 2.3152483606338503
[Epoch 14, Batch 800] loss: 2.310273976325989
[Epoch 14, Batch 900] loss: 2.313859312534332
[Epoch 14, Batch 1000] loss: 2.309110040664673
[Epoch 14, Batch 1100] loss: 2.3111274075508117
[Epoch 14, Batch 1200] loss: 2.3092955422401427
[Epoch 14, Batch 1300] loss: 2.3139594745635987
[Epoch 14, Batch 1400] loss: 2.306816506385803
[Epoch 14, Batch 1500] loss: 2.3146529936790468
[Epoch 14, Batch 1600] loss: 2.3090340232849123
[Epoch 14, Batch 1700] loss: 2.3143274354934693
[Epoch 14, Batch 1800] loss: 2.308819694519043
**STATS for Epoch 14** : 
Average training loss: 0.0925
Average validation loss: 2.3108
Validation Accuracy: 0.1052
Overfitting: 2.2183
[Epoch 15, Batch 100] loss: 2.313062403202057
[Epoch 15, Batch 200] loss: 2.3113813996315002
[Epoch 15, Batch 300] loss: 2.3136443853378297
[Epoch 15, Batch 400] loss: 2.309056034088135
[Epoch 15, Batch 500] loss: 2.3093516397476197
[Epoch 15, Batch 600] loss: 2.318349266052246
[Epoch 15, Batch 700] loss: 2.3104179239273073
[Epoch 15, Batch 800] loss: 2.3059938788414
[Epoch 15, Batch 900] loss: 2.311919116973877
[Epoch 15, Batch 1000] loss: 2.3128869223594664
[Epoch 15, Batch 1100] loss: 2.3131843519210817
[Epoch 15, Batch 1200] loss: 2.3110744619369505
[Epoch 15, Batch 1300] loss: 2.310594778060913
[Epoch 15, Batch 1400] loss: 2.314870181083679
[Epoch 15, Batch 1500] loss: 2.3105048322677613
[Epoch 15, Batch 1600] loss: 2.3098817372322085
[Epoch 15, Batch 1700] loss: 2.3123088121414184
[Epoch 15, Batch 1800] loss: 2.313489012718201
**STATS for Epoch 15** : 
Average training loss: 0.0924
Average validation loss: 2.3080
Validation Accuracy: 0.1052
Overfitting: 2.2156
[Epoch 16, Batch 100] loss: 2.311546106338501
[Epoch 16, Batch 200] loss: 2.3153663587570192
[Epoch 16, Batch 300] loss: 2.3075944685935976
[Epoch 16, Batch 400] loss: 2.3101194167137145
[Epoch 16, Batch 500] loss: 2.310454273223877
[Epoch 16, Batch 600] loss: 2.3086906909942626
[Epoch 16, Batch 700] loss: 2.309538230895996
[Epoch 16, Batch 800] loss: 2.310024766921997
[Epoch 16, Batch 900] loss: 2.31153635263443
[Epoch 16, Batch 1000] loss: 2.3113058185577393
[Epoch 16, Batch 1100] loss: 2.3138814043998717
[Epoch 16, Batch 1200] loss: 2.312777485847473
[Epoch 16, Batch 1300] loss: 2.3100591135025024
[Epoch 16, Batch 1400] loss: 2.309181520938873
[Epoch 16, Batch 1500] loss: 2.3133254051208496
[Epoch 16, Batch 1600] loss: 2.31392578125
[Epoch 16, Batch 1700] loss: 2.3137424063682555
[Epoch 16, Batch 1800] loss: 2.3110833740234376
**STATS for Epoch 16** : 
Average training loss: 0.0925
Average validation loss: 2.3139
Validation Accuracy: 0.0976
Overfitting: 2.2214
[Epoch 17, Batch 100] loss: 2.313616604804993
[Epoch 17, Batch 200] loss: 2.312514841556549
[Epoch 17, Batch 300] loss: 2.312557520866394
[Epoch 17, Batch 400] loss: 2.3088051509857177
[Epoch 17, Batch 500] loss: 2.313320653438568
[Epoch 17, Batch 600] loss: 2.3086125874519348
[Epoch 17, Batch 700] loss: 2.312433795928955
[Epoch 17, Batch 800] loss: 2.310921919345856
[Epoch 17, Batch 900] loss: 2.3127522826194764
[Epoch 17, Batch 1000] loss: 2.3082327008247376
[Epoch 17, Batch 1100] loss: 2.312754952907562
[Epoch 17, Batch 1200] loss: 2.3130515146255495
[Epoch 17, Batch 1300] loss: 2.316888074874878
[Epoch 17, Batch 1400] loss: 2.3081198263168337
[Epoch 17, Batch 1500] loss: 2.3151354026794433
[Epoch 17, Batch 1600] loss: 2.3071019005775453
[Epoch 17, Batch 1700] loss: 2.315545015335083
[Epoch 17, Batch 1800] loss: 2.312190499305725
**STATS for Epoch 17** : 
Average training loss: 0.0925
Average validation loss: 2.3095
Validation Accuracy: 0.1126
Overfitting: 2.2170
[Epoch 18, Batch 100] loss: 2.314672772884369
[Epoch 18, Batch 200] loss: 2.3131215167045593
[Epoch 18, Batch 300] loss: 2.3154729771614075
[Epoch 18, Batch 400] loss: 2.3083793997764586
[Epoch 18, Batch 500] loss: 2.3111845016479493
[Epoch 18, Batch 600] loss: 2.31321839094162
[Epoch 18, Batch 700] loss: 2.311177110671997
[Epoch 18, Batch 800] loss: 2.31239883184433
[Epoch 18, Batch 900] loss: 2.3116442346572876
[Epoch 18, Batch 1000] loss: 2.3135637712478636
[Epoch 18, Batch 1100] loss: 2.310776319503784
[Epoch 18, Batch 1200] loss: 2.3132290601730348
[Epoch 18, Batch 1300] loss: 2.3114904975891113
[Epoch 18, Batch 1400] loss: 2.3114441418647766
[Epoch 18, Batch 1500] loss: 2.3147469043731688
[Epoch 18, Batch 1600] loss: 2.3129480981826784
[Epoch 18, Batch 1700] loss: 2.3144620203971864
[Epoch 18, Batch 1800] loss: 2.3129791378974915
**STATS for Epoch 18** : 
Average training loss: 0.0926
Average validation loss: 2.3058
Validation Accuracy: 0.1052
Overfitting: 2.2132
[Epoch 19, Batch 100] loss: 2.311360433101654
[Epoch 19, Batch 200] loss: 2.3139312481880188
[Epoch 19, Batch 300] loss: 2.309643979072571
[Epoch 19, Batch 400] loss: 2.3120058250427244
[Epoch 19, Batch 500] loss: 2.3120823335647582
[Epoch 19, Batch 600] loss: 2.310812010765076
[Epoch 19, Batch 700] loss: 2.3132154655456545
[Epoch 19, Batch 800] loss: 2.311816623210907
[Epoch 19, Batch 900] loss: 2.317408118247986
[Epoch 19, Batch 1000] loss: 2.313519058227539
[Epoch 19, Batch 1100] loss: 2.3109509468078615
[Epoch 19, Batch 1200] loss: 2.3124494218826293
[Epoch 19, Batch 1300] loss: 2.3126140904426573
[Epoch 19, Batch 1400] loss: 2.3150811839103698
[Epoch 19, Batch 1500] loss: 2.316269316673279
[Epoch 19, Batch 1600] loss: 2.3089330053329467
[Epoch 19, Batch 1700] loss: 2.310738227367401
[Epoch 19, Batch 1800] loss: 2.310905563831329
**STATS for Epoch 19** : 
Average training loss: 0.0922
Average validation loss: 2.3169
Validation Accuracy: 0.0903
Overfitting: 2.2247
[Epoch 20, Batch 100] loss: 2.3162679147720335
[Epoch 20, Batch 200] loss: 2.3090327334403993
[Epoch 20, Batch 300] loss: 2.311704123020172
[Epoch 20, Batch 400] loss: 2.3114532017707825
[Epoch 20, Batch 500] loss: 2.308859441280365
[Epoch 20, Batch 600] loss: 2.313213653564453
[Epoch 20, Batch 700] loss: 2.309919579029083
[Epoch 20, Batch 800] loss: 2.310082538127899
[Epoch 20, Batch 900] loss: 2.316815016269684
[Epoch 20, Batch 1000] loss: 2.3118037223815917
[Epoch 20, Batch 1100] loss: 2.3121465754508974
[Epoch 20, Batch 1200] loss: 2.311359086036682
[Epoch 20, Batch 1300] loss: 2.3091590762138368
[Epoch 20, Batch 1400] loss: 2.309868624210358
[Epoch 20, Batch 1500] loss: 2.316231601238251
[Epoch 20, Batch 1600] loss: 2.309531548023224
[Epoch 20, Batch 1700] loss: 2.3148918771743774
[Epoch 20, Batch 1800] loss: 2.3144187760353088
**STATS for Epoch 20** : 
Average training loss: 0.0923
Average validation loss: 2.3147
Validation Accuracy: 0.0965
Overfitting: 2.2223
[Epoch 21, Batch 100] loss: 2.30936137676239
[Epoch 21, Batch 200] loss: 2.3066418194770812
[Epoch 21, Batch 300] loss: 2.310354335308075
[Epoch 21, Batch 400] loss: 2.3112885332107544
[Epoch 21, Batch 500] loss: 2.3057823276519773
[Epoch 21, Batch 600] loss: 2.3165857553482057
[Epoch 21, Batch 700] loss: 2.3137294459342956
[Epoch 21, Batch 800] loss: 2.3104755544662474
[Epoch 21, Batch 900] loss: 2.3162173008918763
[Epoch 21, Batch 1000] loss: 2.309143812656403
[Epoch 21, Batch 1100] loss: 2.31012154340744
[Epoch 21, Batch 1200] loss: 2.307191643714905
[Epoch 21, Batch 1300] loss: 2.31182653427124
[Epoch 21, Batch 1400] loss: 2.3118062686920164
[Epoch 21, Batch 1500] loss: 2.3100014400482176
[Epoch 21, Batch 1600] loss: 2.314119462966919
[Epoch 21, Batch 1700] loss: 2.311893126964569
[Epoch 21, Batch 1800] loss: 2.313598163127899
**STATS for Epoch 21** : 
Average training loss: 0.0925
Average validation loss: 2.3082
Validation Accuracy: 0.1037
Overfitting: 2.2157
[Epoch 22, Batch 100] loss: 2.314827573299408
[Epoch 22, Batch 200] loss: 2.3112513279914855
[Epoch 22, Batch 300] loss: 2.311560754776001
[Epoch 22, Batch 400] loss: 2.3149291133880614
[Epoch 22, Batch 500] loss: 2.3116206765174865
[Epoch 22, Batch 600] loss: 2.312870862483978
[Epoch 22, Batch 700] loss: 2.3121422147750854
[Epoch 22, Batch 800] loss: 2.309513342380524
[Epoch 22, Batch 900] loss: 2.312150900363922
[Epoch 22, Batch 1000] loss: 2.3121709489822386
[Epoch 22, Batch 1100] loss: 2.3116295027732847
[Epoch 22, Batch 1200] loss: 2.311251575946808
[Epoch 22, Batch 1300] loss: 2.3106774950027464
[Epoch 22, Batch 1400] loss: 2.309098172187805
[Epoch 22, Batch 1500] loss: 2.3113086104393004
[Epoch 22, Batch 1600] loss: 2.3110482239723207
[Epoch 22, Batch 1700] loss: 2.307895381450653
[Epoch 22, Batch 1800] loss: 2.314700860977173
**STATS for Epoch 22** : 
Average training loss: 0.0924
Average validation loss: 2.3127
Validation Accuracy: 0.1126
Overfitting: 2.2203
[Epoch 23, Batch 100] loss: 2.313367712497711
[Epoch 23, Batch 200] loss: 2.3136891961097716
[Epoch 23, Batch 300] loss: 2.3125905275344847
[Epoch 23, Batch 400] loss: 2.3113994336128236
[Epoch 23, Batch 500] loss: 2.3129686307907105
[Epoch 23, Batch 600] loss: 2.307267122268677
[Epoch 23, Batch 700] loss: 2.3110752177238463
[Epoch 23, Batch 800] loss: 2.315531885623932
[Epoch 23, Batch 900] loss: 2.3129627656936647
[Epoch 23, Batch 1000] loss: 2.3113883352279663
[Epoch 23, Batch 1100] loss: 2.3137241530418398
[Epoch 23, Batch 1200] loss: 2.31260098695755
[Epoch 23, Batch 1300] loss: 2.3105508637428285
[Epoch 23, Batch 1400] loss: 2.313048737049103
[Epoch 23, Batch 1500] loss: 2.3161452484130858
[Epoch 23, Batch 1600] loss: 2.3083721566200257
[Epoch 23, Batch 1700] loss: 2.309618685245514
[Epoch 23, Batch 1800] loss: 2.31667197227478
**STATS for Epoch 23** : 
Average training loss: 0.0926
Average validation loss: 2.3047
Validation Accuracy: 0.1052
Overfitting: 2.2121
[Epoch 24, Batch 100] loss: 2.315154263973236
[Epoch 24, Batch 200] loss: 2.3103092551231383
[Epoch 24, Batch 300] loss: 2.3133645343780516
[Epoch 24, Batch 400] loss: 2.3078746247291564
[Epoch 24, Batch 500] loss: 2.3107966423034667
[Epoch 24, Batch 600] loss: 2.3058193945884704
[Epoch 24, Batch 700] loss: 2.3119834756851194
[Epoch 24, Batch 800] loss: 2.310004460811615
[Epoch 24, Batch 900] loss: 2.3115801334381105
[Epoch 24, Batch 1000] loss: 2.313099980354309
[Epoch 24, Batch 1100] loss: 2.3120227122306822
[Epoch 24, Batch 1200] loss: 2.3099323463439942
[Epoch 24, Batch 1300] loss: 2.308544318675995
[Epoch 24, Batch 1400] loss: 2.3122087621688845
[Epoch 24, Batch 1500] loss: 2.3109113073348997
[Epoch 24, Batch 1600] loss: 2.314599623680115
[Epoch 24, Batch 1700] loss: 2.3113350009918214
[Epoch 24, Batch 1800] loss: 2.3043362140655517
**STATS for Epoch 24** : 
Average training loss: 0.0925
Average validation loss: 2.3116
Validation Accuracy: 0.1052
Overfitting: 2.2191
Fold 2 validation loss: 2.3116
Mean validation loss across all folds for Trial 4 is 2.3107 with trial config:  l1: 128, l2: 128, lr: 0.07286653737491042, batch_size: 16
[I 2024-11-25 15:24:28,199] Trial 3 finished with value: 2.3106758379618326 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.07286653737491042, 'batch_size': 16}. Best is trial 2 with value: 0.06046210698719751.

Selected Hyperparameters for Trial 5:
  l1: 256, l2: 128, lr: 0.00010842262717330161, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.298046061992645
[Epoch 1, Batch 200] loss: 2.2991427636146544
[Epoch 1, Batch 300] loss: 2.296909875869751
[Epoch 1, Batch 400] loss: 2.294909164905548
[Epoch 1, Batch 500] loss: 2.2932220578193663
[Epoch 1, Batch 600] loss: 2.290594120025635
[Epoch 1, Batch 700] loss: 2.290548288822174
[Epoch 1, Batch 800] loss: 2.2874924778938293
[Epoch 1, Batch 900] loss: 2.2857083010673525
[Epoch 1, Batch 1000] loss: 2.284360828399658
[Epoch 1, Batch 1100] loss: 2.2817309617996218
[Epoch 1, Batch 1200] loss: 2.276780953407288
[Epoch 1, Batch 1300] loss: 2.275456175804138
[Epoch 1, Batch 1400] loss: 2.272224464416504
[Epoch 1, Batch 1500] loss: 2.270290501117706
[Epoch 1, Batch 1600] loss: 2.2649996733665465
[Epoch 1, Batch 1700] loss: 2.258960225582123
[Epoch 1, Batch 1800] loss: 2.257836031913757
**STATS for Epoch 1** : 
Average training loss: 0.0901
Average validation loss: 2.2508
Validation Accuracy: 0.3973
Overfitting: 2.1607
Best model saved at epoch 1 with validation loss: 2.2508
[Epoch 2, Batch 100] loss: 2.2494889211654665
[Epoch 2, Batch 200] loss: 2.2416088247299193
[Epoch 2, Batch 300] loss: 2.2352947759628297
[Epoch 2, Batch 400] loss: 2.2254914593696595
[Epoch 2, Batch 500] loss: 2.2109917402267456
[Epoch 2, Batch 600] loss: 2.2016054368019105
[Epoch 2, Batch 700] loss: 2.186194064617157
[Epoch 2, Batch 800] loss: 2.16418555021286
[Epoch 2, Batch 900] loss: 2.1436319851875307
[Epoch 2, Batch 1000] loss: 2.1082849287986756
[Epoch 2, Batch 1100] loss: 2.0713006818294524
[Epoch 2, Batch 1200] loss: 2.030019382238388
[Epoch 2, Batch 1300] loss: 1.9519827353954315
[Epoch 2, Batch 1400] loss: 1.8690140795707704
[Epoch 2, Batch 1500] loss: 1.767124626636505
[Epoch 2, Batch 1600] loss: 1.6536015367507935
[Epoch 2, Batch 1700] loss: 1.5241189503669739
[Epoch 2, Batch 1800] loss: 1.3387932974100112
**STATS for Epoch 2** : 
Average training loss: 0.0493
Average validation loss: 1.1771
Validation Accuracy: 0.7140
Overfitting: 1.1278
Best model saved at epoch 2 with validation loss: 1.1771
[Epoch 3, Batch 100] loss: 1.1264415389299394
[Epoch 3, Batch 200] loss: 1.0064732027053833
[Epoch 3, Batch 300] loss: 0.9059303921461105
[Epoch 3, Batch 400] loss: 0.8148950266838074
[Epoch 3, Batch 500] loss: 0.7518704026937485
[Epoch 3, Batch 600] loss: 0.7365273743867874
[Epoch 3, Batch 700] loss: 0.6306749606132507
[Epoch 3, Batch 800] loss: 0.5779778811335564
[Epoch 3, Batch 900] loss: 0.5870661121606827
[Epoch 3, Batch 1000] loss: 0.574379945397377
[Epoch 3, Batch 1100] loss: 0.5426633755862713
[Epoch 3, Batch 1200] loss: 0.48656500831246374
[Epoch 3, Batch 1300] loss: 0.4955371557176113
[Epoch 3, Batch 1400] loss: 0.4799649742990732
[Epoch 3, Batch 1500] loss: 0.45254081264138224
[Epoch 3, Batch 1600] loss: 0.4587674102932215
[Epoch 3, Batch 1700] loss: 0.42535455591976645
[Epoch 3, Batch 1800] loss: 0.3875013051182032
**STATS for Epoch 3** : 
Average training loss: 0.0163
Average validation loss: 0.4156
Validation Accuracy: 0.8779
Overfitting: 0.3992
Best model saved at epoch 3 with validation loss: 0.4156
[Epoch 4, Batch 100] loss: 0.43565439008176327
[Epoch 4, Batch 200] loss: 0.393721724525094
[Epoch 4, Batch 300] loss: 0.38140490047633646
[Epoch 4, Batch 400] loss: 0.4260071240365505
[Epoch 4, Batch 500] loss: 0.3921194350719452
[Epoch 4, Batch 600] loss: 0.33334017485380174
[Epoch 4, Batch 700] loss: 0.3436906206607819
[Epoch 4, Batch 800] loss: 0.3282633876055479
[Epoch 4, Batch 900] loss: 0.360460188947618
[Epoch 4, Batch 1000] loss: 0.3514066454768181
[Epoch 4, Batch 1100] loss: 0.3487965424731374
[Epoch 4, Batch 1200] loss: 0.3485811648517847
[Epoch 4, Batch 1300] loss: 0.3127199976146221
[Epoch 4, Batch 1400] loss: 0.3035424426570535
[Epoch 4, Batch 1500] loss: 0.29773373566567896
[Epoch 4, Batch 1600] loss: 0.3158555556088686
[Epoch 4, Batch 1700] loss: 0.28549770802259444
[Epoch 4, Batch 1800] loss: 0.3212068664841354
**STATS for Epoch 4** : 
Average training loss: 0.0122
Average validation loss: 0.2897
Validation Accuracy: 0.9156
Overfitting: 0.2775
Best model saved at epoch 4 with validation loss: 0.2897
[Epoch 5, Batch 100] loss: 0.2923500598780811
[Epoch 5, Batch 200] loss: 0.2828130659461021
[Epoch 5, Batch 300] loss: 0.2864506324008107
[Epoch 5, Batch 400] loss: 0.2700425698794425
[Epoch 5, Batch 500] loss: 0.28662216749042274
[Epoch 5, Batch 600] loss: 0.30121777445077896
[Epoch 5, Batch 700] loss: 0.24986008347943425
[Epoch 5, Batch 800] loss: 0.2904667473956943
[Epoch 5, Batch 900] loss: 0.2777918722480536
[Epoch 5, Batch 1000] loss: 0.25949204616248606
[Epoch 5, Batch 1100] loss: 0.2504347025603056
[Epoch 5, Batch 1200] loss: 0.27575489684939386
[Epoch 5, Batch 1300] loss: 0.24484222756698729
[Epoch 5, Batch 1400] loss: 0.2507087990269065
[Epoch 5, Batch 1500] loss: 0.23082612436264754
[Epoch 5, Batch 1600] loss: 0.22381740590557456
[Epoch 5, Batch 1700] loss: 0.25744563203305004
[Epoch 5, Batch 1800] loss: 0.28569428749382497
**STATS for Epoch 5** : 
Average training loss: 0.0089
Average validation loss: 0.2420
Validation Accuracy: 0.9286
Overfitting: 0.2331
Best model saved at epoch 5 with validation loss: 0.2420
[Epoch 6, Batch 100] loss: 0.2294573437795043
[Epoch 6, Batch 200] loss: 0.23160638509318232
[Epoch 6, Batch 300] loss: 0.1947553686797619
[Epoch 6, Batch 400] loss: 0.22645045801065863
[Epoch 6, Batch 500] loss: 0.1879126201570034
[Epoch 6, Batch 600] loss: 0.24540717517025767
[Epoch 6, Batch 700] loss: 0.25152246015146373
[Epoch 6, Batch 800] loss: 0.20938313772901893
[Epoch 6, Batch 900] loss: 0.2053103183582425
[Epoch 6, Batch 1000] loss: 0.1896030761115253
[Epoch 6, Batch 1100] loss: 0.25730365416035056
[Epoch 6, Batch 1200] loss: 0.24053946281783284
[Epoch 6, Batch 1300] loss: 0.20801716431044043
[Epoch 6, Batch 1400] loss: 0.17966659208759667
[Epoch 6, Batch 1500] loss: 0.2038142533786595
[Epoch 6, Batch 1600] loss: 0.2353744452446699
[Epoch 6, Batch 1700] loss: 0.2222940026037395
[Epoch 6, Batch 1800] loss: 0.18953767048195005
**STATS for Epoch 6** : 
Average training loss: 0.0078
Average validation loss: 0.1944
Validation Accuracy: 0.9414
Overfitting: 0.1866
Best model saved at epoch 6 with validation loss: 0.1944
[Epoch 7, Batch 100] loss: 0.19913646096363663
[Epoch 7, Batch 200] loss: 0.21356347849592566
[Epoch 7, Batch 300] loss: 0.19928977431729436
[Epoch 7, Batch 400] loss: 0.17608221529051662
[Epoch 7, Batch 500] loss: 0.1999370921216905
[Epoch 7, Batch 600] loss: 0.16890593993477523
[Epoch 7, Batch 700] loss: 0.1812391118798405
[Epoch 7, Batch 800] loss: 0.20322352478280664
[Epoch 7, Batch 900] loss: 0.19924526274204254
[Epoch 7, Batch 1000] loss: 0.190871313046664
[Epoch 7, Batch 1100] loss: 0.18017988302744925
[Epoch 7, Batch 1200] loss: 0.16722099860664458
[Epoch 7, Batch 1300] loss: 0.1776831803843379
[Epoch 7, Batch 1400] loss: 0.20297080324962735
[Epoch 7, Batch 1500] loss: 0.17695142613723874
[Epoch 7, Batch 1600] loss: 0.1602466842252761
[Epoch 7, Batch 1700] loss: 0.1635882917139679
[Epoch 7, Batch 1800] loss: 0.1411832907330245
**STATS for Epoch 7** : 
Average training loss: 0.0065
Average validation loss: 0.1666
Validation Accuracy: 0.9499
Overfitting: 0.1600
Best model saved at epoch 7 with validation loss: 0.1666
[Epoch 8, Batch 100] loss: 0.1752951165754348
[Epoch 8, Batch 200] loss: 0.1636656648851931
[Epoch 8, Batch 300] loss: 0.1463888049032539
[Epoch 8, Batch 400] loss: 0.16140686695463954
[Epoch 8, Batch 500] loss: 0.14917667154222727
[Epoch 8, Batch 600] loss: 0.1400753817241639
[Epoch 8, Batch 700] loss: 0.15156692422926427
[Epoch 8, Batch 800] loss: 0.16785123982466757
[Epoch 8, Batch 900] loss: 0.14344739146530627
[Epoch 8, Batch 1000] loss: 0.1657050426956266
[Epoch 8, Batch 1100] loss: 0.15701993870083242
[Epoch 8, Batch 1200] loss: 0.1339879180677235
[Epoch 8, Batch 1300] loss: 0.15271113820374013
[Epoch 8, Batch 1400] loss: 0.14978841810487212
[Epoch 8, Batch 1500] loss: 0.1589114245865494
[Epoch 8, Batch 1600] loss: 0.18154762025922536
[Epoch 8, Batch 1700] loss: 0.14741815037094055
[Epoch 8, Batch 1800] loss: 0.1587906629173085
**STATS for Epoch 8** : 
Average training loss: 0.0072
Average validation loss: 0.1605
Validation Accuracy: 0.9503
Overfitting: 0.1533
Best model saved at epoch 8 with validation loss: 0.1605
[Epoch 9, Batch 100] loss: 0.14757566828280688
[Epoch 9, Batch 200] loss: 0.15284071306698024
[Epoch 9, Batch 300] loss: 0.1442942180321552
[Epoch 9, Batch 400] loss: 0.14236625212244688
[Epoch 9, Batch 500] loss: 0.15437580507714302
[Epoch 9, Batch 600] loss: 0.16336925255134702
[Epoch 9, Batch 700] loss: 0.12133972015697508
[Epoch 9, Batch 800] loss: 0.12029488839209079
[Epoch 9, Batch 900] loss: 0.14117461833637207
[Epoch 9, Batch 1000] loss: 0.1259007929218933
[Epoch 9, Batch 1100] loss: 0.14806924015283585
[Epoch 9, Batch 1200] loss: 0.13693072831258177
[Epoch 9, Batch 1300] loss: 0.15496791675686836
[Epoch 9, Batch 1400] loss: 0.1503017927519977
[Epoch 9, Batch 1500] loss: 0.14884936618618666
[Epoch 9, Batch 1600] loss: 0.11821705870795995
[Epoch 9, Batch 1700] loss: 0.10612287786323576
[Epoch 9, Batch 1800] loss: 0.12274350638501347
**STATS for Epoch 9** : 
Average training loss: 0.0042
Average validation loss: 0.1329
Validation Accuracy: 0.9598
Overfitting: 0.1287
Best model saved at epoch 9 with validation loss: 0.1329
[Epoch 10, Batch 100] loss: 0.12194664248730987
[Epoch 10, Batch 200] loss: 0.110484236497432
[Epoch 10, Batch 300] loss: 0.11664110569981859
[Epoch 10, Batch 400] loss: 0.12097697712946683
[Epoch 10, Batch 500] loss: 0.10756315137725324
[Epoch 10, Batch 600] loss: 0.1293671225523576
[Epoch 10, Batch 700] loss: 0.12357804023660719
[Epoch 10, Batch 800] loss: 0.13952567264437676
[Epoch 10, Batch 900] loss: 0.11405002184677869
[Epoch 10, Batch 1000] loss: 0.12154993925243616
[Epoch 10, Batch 1100] loss: 0.11952286122832448
[Epoch 10, Batch 1200] loss: 0.13089456977322697
[Epoch 10, Batch 1300] loss: 0.12005179969593882
[Epoch 10, Batch 1400] loss: 0.12390409944113344
[Epoch 10, Batch 1500] loss: 0.14799644694663583
[Epoch 10, Batch 1600] loss: 0.12205775099340826
[Epoch 10, Batch 1700] loss: 0.1320524394325912
[Epoch 10, Batch 1800] loss: 0.13532337378710507
**STATS for Epoch 10** : 
Average training loss: 0.0051
Average validation loss: 0.1272
Validation Accuracy: 0.9619
Overfitting: 0.1221
Best model saved at epoch 10 with validation loss: 0.1272
[Epoch 11, Batch 100] loss: 0.09422710097162053
[Epoch 11, Batch 200] loss: 0.11142667754087597
[Epoch 11, Batch 300] loss: 0.13252554076723755
[Epoch 11, Batch 400] loss: 0.134032533634454
[Epoch 11, Batch 500] loss: 0.1378784428117797
[Epoch 11, Batch 600] loss: 0.12534577086567877
[Epoch 11, Batch 700] loss: 0.10675146906170994
[Epoch 11, Batch 800] loss: 0.1065421252977103
[Epoch 11, Batch 900] loss: 0.11072309677023441
[Epoch 11, Batch 1000] loss: 0.12377498649992048
[Epoch 11, Batch 1100] loss: 0.11448247624794021
[Epoch 11, Batch 1200] loss: 0.09525154442992062
[Epoch 11, Batch 1300] loss: 0.09626790302805603
[Epoch 11, Batch 1400] loss: 0.11711339055094867
[Epoch 11, Batch 1500] loss: 0.10562224894296378
[Epoch 11, Batch 1600] loss: 0.1067385111702606
[Epoch 11, Batch 1700] loss: 0.12680935649201275
[Epoch 11, Batch 1800] loss: 0.11642550119198859
**STATS for Epoch 11** : 
Average training loss: 0.0038
Average validation loss: 0.1126
Validation Accuracy: 0.9654
Overfitting: 0.1087
Best model saved at epoch 11 with validation loss: 0.1126
[Epoch 12, Batch 100] loss: 0.11510465163213666
[Epoch 12, Batch 200] loss: 0.12900497801834718
[Epoch 12, Batch 300] loss: 0.10469062233809381
[Epoch 12, Batch 400] loss: 0.12357639850117266
[Epoch 12, Batch 500] loss: 0.11032263532280923
[Epoch 12, Batch 600] loss: 0.10911652454175055
[Epoch 12, Batch 700] loss: 0.0963488233438693
[Epoch 12, Batch 800] loss: 0.11527482873527334
[Epoch 12, Batch 900] loss: 0.09212408825289459
[Epoch 12, Batch 1000] loss: 0.1107096416456625
[Epoch 12, Batch 1100] loss: 0.09939514638623223
[Epoch 12, Batch 1200] loss: 0.09854824608191848
[Epoch 12, Batch 1300] loss: 0.09600051867542789
[Epoch 12, Batch 1400] loss: 0.10073916919762269
[Epoch 12, Batch 1500] loss: 0.09721758865518496
[Epoch 12, Batch 1600] loss: 0.08749689741991461
[Epoch 12, Batch 1700] loss: 0.1032698210887611
[Epoch 12, Batch 1800] loss: 0.10775978990364819
**STATS for Epoch 12** : 
Average training loss: 0.0042
Average validation loss: 0.1053
Validation Accuracy: 0.9667
Overfitting: 0.1011
Best model saved at epoch 12 with validation loss: 0.1053
[Epoch 13, Batch 100] loss: 0.09107879929477349
[Epoch 13, Batch 200] loss: 0.11481467341305689
[Epoch 13, Batch 300] loss: 0.09003588712774217
[Epoch 13, Batch 400] loss: 0.10974548465572298
[Epoch 13, Batch 500] loss: 0.1115191283589229
[Epoch 13, Batch 600] loss: 0.08341719663003459
[Epoch 13, Batch 700] loss: 0.09609134903876111
[Epoch 13, Batch 800] loss: 0.11497623050119728
[Epoch 13, Batch 900] loss: 0.10302188084460795
[Epoch 13, Batch 1000] loss: 0.11380687477532775
[Epoch 13, Batch 1100] loss: 0.07202839286997914
[Epoch 13, Batch 1200] loss: 0.10044592827558517
[Epoch 13, Batch 1300] loss: 0.09892937765689566
[Epoch 13, Batch 1400] loss: 0.11388073379872367
[Epoch 13, Batch 1500] loss: 0.0944674039655365
[Epoch 13, Batch 1600] loss: 0.1178955777734518
[Epoch 13, Batch 1700] loss: 0.08956010908121242
[Epoch 13, Batch 1800] loss: 0.09608318148646504
**STATS for Epoch 13** : 
Average training loss: 0.0032
Average validation loss: 0.1017
Validation Accuracy: 0.9682
Overfitting: 0.0985
Best model saved at epoch 13 with validation loss: 0.1017
[Epoch 14, Batch 100] loss: 0.1015606421395205
[Epoch 14, Batch 200] loss: 0.07681770402006804
[Epoch 14, Batch 300] loss: 0.12758729391731322
[Epoch 14, Batch 400] loss: 0.08718167696380988
[Epoch 14, Batch 500] loss: 0.06841121937497519
[Epoch 14, Batch 600] loss: 0.0960007687145844
[Epoch 14, Batch 700] loss: 0.09827732887817547
[Epoch 14, Batch 800] loss: 0.08420035891700536
[Epoch 14, Batch 900] loss: 0.07939905442064628
[Epoch 14, Batch 1000] loss: 0.12206431398983114
[Epoch 14, Batch 1100] loss: 0.09624783601146192
[Epoch 14, Batch 1200] loss: 0.10121857772581279
[Epoch 14, Batch 1300] loss: 0.0844217964191921
[Epoch 14, Batch 1400] loss: 0.07736327129648998
[Epoch 14, Batch 1500] loss: 0.10184385149506853
[Epoch 14, Batch 1600] loss: 0.08365921120159328
[Epoch 14, Batch 1700] loss: 0.09408833361230791
[Epoch 14, Batch 1800] loss: 0.07702849922236055
**STATS for Epoch 14** : 
Average training loss: 0.0043
Average validation loss: 0.0991
Validation Accuracy: 0.9679
Overfitting: 0.0948
Best model saved at epoch 14 with validation loss: 0.0991
[Epoch 15, Batch 100] loss: 0.09734879418741911
[Epoch 15, Batch 200] loss: 0.06580892390222289
[Epoch 15, Batch 300] loss: 0.08418246303452179
[Epoch 15, Batch 400] loss: 0.08837744454387575
[Epoch 15, Batch 500] loss: 0.0716592384967953
[Epoch 15, Batch 600] loss: 0.08489264422794804
[Epoch 15, Batch 700] loss: 0.10547110426123255
[Epoch 15, Batch 800] loss: 0.07869155736872926
[Epoch 15, Batch 900] loss: 0.08348602045094594
[Epoch 15, Batch 1000] loss: 0.09586879251990467
[Epoch 15, Batch 1100] loss: 0.07411416785325856
[Epoch 15, Batch 1200] loss: 0.09633087550057098
[Epoch 15, Batch 1300] loss: 0.08418732534511947
[Epoch 15, Batch 1400] loss: 0.09497027029981836
[Epoch 15, Batch 1500] loss: 0.07711298018810339
[Epoch 15, Batch 1600] loss: 0.10427678498439491
[Epoch 15, Batch 1700] loss: 0.10063757499679923
[Epoch 15, Batch 1800] loss: 0.10026981302769855
**STATS for Epoch 15** : 
Average training loss: 0.0033
Average validation loss: 0.0916
Validation Accuracy: 0.9715
Overfitting: 0.0883
Best model saved at epoch 15 with validation loss: 0.0916
[Epoch 16, Batch 100] loss: 0.08217137599363923
[Epoch 16, Batch 200] loss: 0.09652114669792354
[Epoch 16, Batch 300] loss: 0.08210642033955082
[Epoch 16, Batch 400] loss: 0.09984686079435051
[Epoch 16, Batch 500] loss: 0.07824901839485392
[Epoch 16, Batch 600] loss: 0.08432894226396456
[Epoch 16, Batch 700] loss: 0.08936015521176159
[Epoch 16, Batch 800] loss: 0.06597723264014349
[Epoch 16, Batch 900] loss: 0.09768642183276825
[Epoch 16, Batch 1000] loss: 0.07466957938740962
[Epoch 16, Batch 1100] loss: 0.08584644804242998
[Epoch 16, Batch 1200] loss: 0.09671940212720073
[Epoch 16, Batch 1300] loss: 0.06372878592228517
[Epoch 16, Batch 1400] loss: 0.07501356170047074
[Epoch 16, Batch 1500] loss: 0.07751331072999164
[Epoch 16, Batch 1600] loss: 0.084868567683734
[Epoch 16, Batch 1700] loss: 0.07252357177203521
[Epoch 16, Batch 1800] loss: 0.08428866137517615
**STATS for Epoch 16** : 
Average training loss: 0.0038
Average validation loss: 0.0929
Validation Accuracy: 0.9707
Overfitting: 0.0891
[Epoch 17, Batch 100] loss: 0.08622868019912858
[Epoch 17, Batch 200] loss: 0.07110723208170384
[Epoch 17, Batch 300] loss: 0.09616061508189887
[Epoch 17, Batch 400] loss: 0.07887915896601044
[Epoch 17, Batch 500] loss: 0.06426332200877369
[Epoch 17, Batch 600] loss: 0.08564864331157879
[Epoch 17, Batch 700] loss: 0.09908004323719069
[Epoch 17, Batch 800] loss: 0.06916003920021467
[Epoch 17, Batch 900] loss: 0.07123249058611691
[Epoch 17, Batch 1000] loss: 0.0770485926256515
[Epoch 17, Batch 1100] loss: 0.07898708558641374
[Epoch 17, Batch 1200] loss: 0.07500175064546057
[Epoch 17, Batch 1300] loss: 0.0758393979788525
[Epoch 17, Batch 1400] loss: 0.06721581312129274
[Epoch 17, Batch 1500] loss: 0.06958345610066317
[Epoch 17, Batch 1600] loss: 0.07172627695719712
[Epoch 17, Batch 1700] loss: 0.0782838511141017
[Epoch 17, Batch 1800] loss: 0.10455897921230645
**STATS for Epoch 17** : 
Average training loss: 0.0037
Average validation loss: 0.0938
Validation Accuracy: 0.9697
Overfitting: 0.0901
[Epoch 18, Batch 100] loss: 0.07517626451561227
[Epoch 18, Batch 200] loss: 0.08937647092505357
[Epoch 18, Batch 300] loss: 0.05827403524774127
[Epoch 18, Batch 400] loss: 0.06833857977995648
[Epoch 18, Batch 500] loss: 0.06622605384793133
[Epoch 18, Batch 600] loss: 0.06665792528772727
[Epoch 18, Batch 700] loss: 0.07450478163314983
[Epoch 18, Batch 800] loss: 0.09236616576323285
[Epoch 18, Batch 900] loss: 0.07225959500065074
[Epoch 18, Batch 1000] loss: 0.09318105861719232
[Epoch 18, Batch 1100] loss: 0.07394985685416032
[Epoch 18, Batch 1200] loss: 0.082666194899939
[Epoch 18, Batch 1300] loss: 0.07946427635033615
[Epoch 18, Batch 1400] loss: 0.08200910762767308
[Epoch 18, Batch 1500] loss: 0.08224495219765231
[Epoch 18, Batch 1600] loss: 0.068096647876082
[Epoch 18, Batch 1700] loss: 0.07437098164577037
[Epoch 18, Batch 1800] loss: 0.07421877891058103
**STATS for Epoch 18** : 
Average training loss: 0.0031
Average validation loss: 0.0827
Validation Accuracy: 0.9741
Overfitting: 0.0795
Best model saved at epoch 18 with validation loss: 0.0827
[Epoch 19, Batch 100] loss: 0.06598686078912579
[Epoch 19, Batch 200] loss: 0.05628142762638163
[Epoch 19, Batch 300] loss: 0.08572004491463303
[Epoch 19, Batch 400] loss: 0.05696094067301601
[Epoch 19, Batch 500] loss: 0.06976947034941987
[Epoch 19, Batch 600] loss: 0.08112451646127739
[Epoch 19, Batch 700] loss: 0.08221708170836792
[Epoch 19, Batch 800] loss: 0.0787692009541206
[Epoch 19, Batch 900] loss: 0.07469579050783068
[Epoch 19, Batch 1000] loss: 0.08765219480963424
[Epoch 19, Batch 1100] loss: 0.06785213078110246
[Epoch 19, Batch 1200] loss: 0.06850430753198453
[Epoch 19, Batch 1300] loss: 0.0709446682559792
[Epoch 19, Batch 1400] loss: 0.07139657950494438
[Epoch 19, Batch 1500] loss: 0.07804816646268592
[Epoch 19, Batch 1600] loss: 0.08726510722422973
[Epoch 19, Batch 1700] loss: 0.07486982032074593
[Epoch 19, Batch 1800] loss: 0.07321652357815765
**STATS for Epoch 19** : 
Average training loss: 0.0023
Average validation loss: 0.0843
Validation Accuracy: 0.9737
Overfitting: 0.0820
[Epoch 20, Batch 100] loss: 0.08562495317892171
[Epoch 20, Batch 200] loss: 0.074520002938807
[Epoch 20, Batch 300] loss: 0.07393834854126907
[Epoch 20, Batch 400] loss: 0.06453747524064965
[Epoch 20, Batch 500] loss: 0.07506715169642121
[Epoch 20, Batch 600] loss: 0.05060184125555679
[Epoch 20, Batch 700] loss: 0.06736144488910213
[Epoch 20, Batch 800] loss: 0.05647236557444558
[Epoch 20, Batch 900] loss: 0.07478375442849938
[Epoch 20, Batch 1000] loss: 0.06948960873822216
[Epoch 20, Batch 1100] loss: 0.06825823131541256
[Epoch 20, Batch 1200] loss: 0.08036566945083905
[Epoch 20, Batch 1300] loss: 0.08012552936910651
[Epoch 20, Batch 1400] loss: 0.07921741615165956
[Epoch 20, Batch 1500] loss: 0.06671704407082871
[Epoch 20, Batch 1600] loss: 0.06377214383333922
[Epoch 20, Batch 1700] loss: 0.07790081349550747
[Epoch 20, Batch 1800] loss: 0.05718928896239959
**STATS for Epoch 20** : 
Average training loss: 0.0026
Average validation loss: 0.0795
Validation Accuracy: 0.9749
Overfitting: 0.0769
Best model saved at epoch 20 with validation loss: 0.0795
[Epoch 21, Batch 100] loss: 0.037575302614131945
[Epoch 21, Batch 200] loss: 0.0653099848504644
[Epoch 21, Batch 300] loss: 0.07674083844409324
[Epoch 21, Batch 400] loss: 0.07096709453267977
[Epoch 21, Batch 500] loss: 0.06827440079301596
[Epoch 21, Batch 600] loss: 0.08176008048001676
[Epoch 21, Batch 700] loss: 0.05860827745753341
[Epoch 21, Batch 800] loss: 0.06227681297576055
[Epoch 21, Batch 900] loss: 0.05794627347757341
[Epoch 21, Batch 1000] loss: 0.0658713733559125
[Epoch 21, Batch 1100] loss: 0.07088020615861751
[Epoch 21, Batch 1200] loss: 0.06735777837689966
[Epoch 21, Batch 1300] loss: 0.09242841877741739
[Epoch 21, Batch 1400] loss: 0.07674008814239641
[Epoch 21, Batch 1500] loss: 0.05625793777988292
[Epoch 21, Batch 1600] loss: 0.07623998031369411
[Epoch 21, Batch 1700] loss: 0.07040971027687191
[Epoch 21, Batch 1800] loss: 0.058241074880352246
**STATS for Epoch 21** : 
Average training loss: 0.0029
Average validation loss: 0.0799
Validation Accuracy: 0.9750
Overfitting: 0.0770
[Epoch 22, Batch 100] loss: 0.06749579963157885
[Epoch 22, Batch 200] loss: 0.0672908398148138
[Epoch 22, Batch 300] loss: 0.06650797233567574
[Epoch 22, Batch 400] loss: 0.07746482596499846
[Epoch 22, Batch 500] loss: 0.08217963952571154
[Epoch 22, Batch 600] loss: 0.05852769846562296
[Epoch 22, Batch 700] loss: 0.0835126181517262
[Epoch 22, Batch 800] loss: 0.05281141820829362
[Epoch 22, Batch 900] loss: 0.06051916265510954
[Epoch 22, Batch 1000] loss: 0.07128311980864964
[Epoch 22, Batch 1100] loss: 0.05556800256716087
[Epoch 22, Batch 1200] loss: 0.06995413508731872
[Epoch 22, Batch 1300] loss: 0.06266835209447891
[Epoch 22, Batch 1400] loss: 0.07157501423265784
[Epoch 22, Batch 1500] loss: 0.058947562664980066
[Epoch 22, Batch 1600] loss: 0.06836097356514075
[Epoch 22, Batch 1700] loss: 0.055472819893620906
[Epoch 22, Batch 1800] loss: 0.060222174298251045
**STATS for Epoch 22** : 
Average training loss: 0.0017
Average validation loss: 0.0768
Validation Accuracy: 0.9759
Overfitting: 0.0751
Best model saved at epoch 22 with validation loss: 0.0768
[Epoch 23, Batch 100] loss: 0.05911033471347764
[Epoch 23, Batch 200] loss: 0.05942987643415108
[Epoch 23, Batch 300] loss: 0.05856339294346981
[Epoch 23, Batch 400] loss: 0.04804493876057677
[Epoch 23, Batch 500] loss: 0.06282256236416288
[Epoch 23, Batch 600] loss: 0.05421555883047404
[Epoch 23, Batch 700] loss: 0.07802101685781963
[Epoch 23, Batch 800] loss: 0.06470685457083164
[Epoch 23, Batch 900] loss: 0.05351148433517665
[Epoch 23, Batch 1000] loss: 0.059991397712146864
[Epoch 23, Batch 1100] loss: 0.07239875814993865
[Epoch 23, Batch 1200] loss: 0.07842355753062293
[Epoch 23, Batch 1300] loss: 0.07762067478965036
[Epoch 23, Batch 1400] loss: 0.059611668298312
[Epoch 23, Batch 1500] loss: 0.05467743789427914
[Epoch 23, Batch 1600] loss: 0.07563020407687873
[Epoch 23, Batch 1700] loss: 0.07251033081207424
[Epoch 23, Batch 1800] loss: 0.04794333338737488
**STATS for Epoch 23** : 
Average training loss: 0.0021
Average validation loss: 0.0750
Validation Accuracy: 0.9764
Overfitting: 0.0729
Best model saved at epoch 23 with validation loss: 0.0750
[Epoch 24, Batch 100] loss: 0.07453307021030924
[Epoch 24, Batch 200] loss: 0.07000040662358514
[Epoch 24, Batch 300] loss: 0.05693551559583284
[Epoch 24, Batch 400] loss: 0.059505389570258554
[Epoch 24, Batch 500] loss: 0.0613759366015438
[Epoch 24, Batch 600] loss: 0.04445130522712134
[Epoch 24, Batch 700] loss: 0.06657220326247625
[Epoch 24, Batch 800] loss: 0.045454549368587324
[Epoch 24, Batch 900] loss: 0.04922298032208346
[Epoch 24, Batch 1000] loss: 0.06409758031775709
[Epoch 24, Batch 1100] loss: 0.08403693027212285
[Epoch 24, Batch 1200] loss: 0.061870065398979934
[Epoch 24, Batch 1300] loss: 0.0657585889362963
[Epoch 24, Batch 1400] loss: 0.06021606366848573
[Epoch 24, Batch 1500] loss: 0.0627997164381668
[Epoch 24, Batch 1600] loss: 0.04892510553763714
[Epoch 24, Batch 1700] loss: 0.058310136809013785
[Epoch 24, Batch 1800] loss: 0.0639080294262385
**STATS for Epoch 24** : 
Average training loss: 0.0021
Average validation loss: 0.0771
Validation Accuracy: 0.9763
Overfitting: 0.0750
Fold 1 validation loss: 0.0771
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.3008030796051027
[Epoch 1, Batch 200] loss: 2.2984946012496947
[Epoch 1, Batch 300] loss: 2.297708282470703
[Epoch 1, Batch 400] loss: 2.2905724573135378
[Epoch 1, Batch 500] loss: 2.2885115814208983
[Epoch 1, Batch 600] loss: 2.286371922492981
[Epoch 1, Batch 700] loss: 2.2783002066612243
[Epoch 1, Batch 800] loss: 2.276123502254486
[Epoch 1, Batch 900] loss: 2.269708127975464
[Epoch 1, Batch 1000] loss: 2.2659379863739013
[Epoch 1, Batch 1100] loss: 2.2579272198677063
[Epoch 1, Batch 1200] loss: 2.2515567541122437
[Epoch 1, Batch 1300] loss: 2.2441310334205626
[Epoch 1, Batch 1400] loss: 2.2352806305885315
[Epoch 1, Batch 1500] loss: 2.221053328514099
[Epoch 1, Batch 1600] loss: 2.204196846485138
[Epoch 1, Batch 1700] loss: 2.1851825857162477
[Epoch 1, Batch 1800] loss: 2.162324903011322
**STATS for Epoch 1** : 
Average training loss: 0.0856
Average validation loss: 2.1217
Validation Accuracy: 0.6153
Overfitting: 2.0361
Best model saved at epoch 1 with validation loss: 2.1217
[Epoch 2, Batch 100] loss: 2.102125222682953
[Epoch 2, Batch 200] loss: 2.0535447335243227
[Epoch 2, Batch 300] loss: 1.994928230047226
[Epoch 2, Batch 400] loss: 1.9131152415275574
[Epoch 2, Batch 500] loss: 1.812306067943573
[Epoch 2, Batch 600] loss: 1.6698836123943328
[Epoch 2, Batch 700] loss: 1.481406751871109
[Epoch 2, Batch 800] loss: 1.305029439330101
[Epoch 2, Batch 900] loss: 1.1268548303842545
[Epoch 2, Batch 1000] loss: 0.9729005289077759
[Epoch 2, Batch 1100] loss: 0.8725206178426742
[Epoch 2, Batch 1200] loss: 0.7881080600619316
[Epoch 2, Batch 1300] loss: 0.7033393901586532
[Epoch 2, Batch 1400] loss: 0.683629932999611
[Epoch 2, Batch 1500] loss: 0.651561359167099
[Epoch 2, Batch 1600] loss: 0.5577967423200607
[Epoch 2, Batch 1700] loss: 0.5431634436547756
[Epoch 2, Batch 1800] loss: 0.5427112156152725
**STATS for Epoch 2** : 
Average training loss: 0.0201
Average validation loss: 0.5098
Validation Accuracy: 0.8538
Overfitting: 0.4897
Best model saved at epoch 2 with validation loss: 0.5098
[Epoch 3, Batch 100] loss: 0.47383654668927194
[Epoch 3, Batch 200] loss: 0.4617087612301111
[Epoch 3, Batch 300] loss: 0.44202689759433267
[Epoch 3, Batch 400] loss: 0.42486392736434936
[Epoch 3, Batch 500] loss: 0.45059856727719305
[Epoch 3, Batch 600] loss: 0.42791678696870805
[Epoch 3, Batch 700] loss: 0.4320328536629677
[Epoch 3, Batch 800] loss: 0.3882250937074423
[Epoch 3, Batch 900] loss: 0.43831869706511495
[Epoch 3, Batch 1000] loss: 0.3776356453448534
[Epoch 3, Batch 1100] loss: 0.39927369795739653
[Epoch 3, Batch 1200] loss: 0.3819700253009796
[Epoch 3, Batch 1300] loss: 0.3579576437920332
[Epoch 3, Batch 1400] loss: 0.3617506922036409
[Epoch 3, Batch 1500] loss: 0.3763143103942275
[Epoch 3, Batch 1600] loss: 0.32842066589742896
[Epoch 3, Batch 1700] loss: 0.34174256470054387
[Epoch 3, Batch 1800] loss: 0.3047816886007786
**STATS for Epoch 3** : 
Average training loss: 0.0139
Average validation loss: 0.3393
Validation Accuracy: 0.8982
Overfitting: 0.3254
Best model saved at epoch 3 with validation loss: 0.3393
[Epoch 4, Batch 100] loss: 0.3165054211765528
[Epoch 4, Batch 200] loss: 0.2978099999576807
[Epoch 4, Batch 300] loss: 0.3075896053761244
[Epoch 4, Batch 400] loss: 0.29717762775719164
[Epoch 4, Batch 500] loss: 0.29130982507020237
[Epoch 4, Batch 600] loss: 0.26008855901658534
[Epoch 4, Batch 700] loss: 0.30599961295723915
[Epoch 4, Batch 800] loss: 0.28740164674818514
[Epoch 4, Batch 900] loss: 0.27300245594233274
[Epoch 4, Batch 1000] loss: 0.28137993354350327
[Epoch 4, Batch 1100] loss: 0.27689036041498183
[Epoch 4, Batch 1200] loss: 0.2750001187250018
[Epoch 4, Batch 1300] loss: 0.25286813946440817
[Epoch 4, Batch 1400] loss: 0.2879055074602366
[Epoch 4, Batch 1500] loss: 0.26924968784675
[Epoch 4, Batch 1600] loss: 0.2750468811020255
[Epoch 4, Batch 1700] loss: 0.2801569256931543
[Epoch 4, Batch 1800] loss: 0.27810233693569897
**STATS for Epoch 4** : 
Average training loss: 0.0114
Average validation loss: 0.2507
Validation Accuracy: 0.9251
Overfitting: 0.2394
Best model saved at epoch 4 with validation loss: 0.2507
[Epoch 5, Batch 100] loss: 0.24771882198750972
[Epoch 5, Batch 200] loss: 0.2238819831609726
[Epoch 5, Batch 300] loss: 0.23030739106237888
[Epoch 5, Batch 400] loss: 0.23152619119733572
[Epoch 5, Batch 500] loss: 0.24692234449088574
[Epoch 5, Batch 600] loss: 0.2702581844292581
[Epoch 5, Batch 700] loss: 0.21706843335181475
[Epoch 5, Batch 800] loss: 0.2271241094917059
[Epoch 5, Batch 900] loss: 0.2473908745869994
[Epoch 5, Batch 1000] loss: 0.20335892856121063
[Epoch 5, Batch 1100] loss: 0.25101158091798426
[Epoch 5, Batch 1200] loss: 0.22787775963544846
[Epoch 5, Batch 1300] loss: 0.22154436588287355
[Epoch 5, Batch 1400] loss: 0.2267907213792205
[Epoch 5, Batch 1500] loss: 0.2233404461108148
[Epoch 5, Batch 1600] loss: 0.22619236854836344
[Epoch 5, Batch 1700] loss: 0.1961487329378724
[Epoch 5, Batch 1800] loss: 0.19190787453204394
**STATS for Epoch 5** : 
Average training loss: 0.0093
Average validation loss: 0.2197
Validation Accuracy: 0.9341
Overfitting: 0.2104
Best model saved at epoch 5 with validation loss: 0.2197
[Epoch 6, Batch 100] loss: 0.21790103491395713
[Epoch 6, Batch 200] loss: 0.2242865239456296
[Epoch 6, Batch 300] loss: 0.20268263574689627
[Epoch 6, Batch 400] loss: 0.1925588479731232
[Epoch 6, Batch 500] loss: 0.17326600713655352
[Epoch 6, Batch 600] loss: 0.18126295471563936
[Epoch 6, Batch 700] loss: 0.18248445553705095
[Epoch 6, Batch 800] loss: 0.19995161650702356
[Epoch 6, Batch 900] loss: 0.23119634707458317
[Epoch 6, Batch 1000] loss: 0.21076242929324507
[Epoch 6, Batch 1100] loss: 0.17123525034636258
[Epoch 6, Batch 1200] loss: 0.20437826218083502
[Epoch 6, Batch 1300] loss: 0.18298248426057398
[Epoch 6, Batch 1400] loss: 0.19109531052410603
[Epoch 6, Batch 1500] loss: 0.17305784862488507
[Epoch 6, Batch 1600] loss: 0.16362940855324268
[Epoch 6, Batch 1700] loss: 0.19000849820673466
[Epoch 6, Batch 1800] loss: 0.1822733047232032
**STATS for Epoch 6** : 
Average training loss: 0.0071
Average validation loss: 0.1908
Validation Accuracy: 0.9419
Overfitting: 0.1837
Best model saved at epoch 6 with validation loss: 0.1908
[Epoch 7, Batch 100] loss: 0.17232052626088262
[Epoch 7, Batch 200] loss: 0.1900288309622556
[Epoch 7, Batch 300] loss: 0.19711994750425219
[Epoch 7, Batch 400] loss: 0.17232468417845667
[Epoch 7, Batch 500] loss: 0.16239377080462872
[Epoch 7, Batch 600] loss: 0.17439531937707214
[Epoch 7, Batch 700] loss: 0.18405953506939113
[Epoch 7, Batch 800] loss: 0.1480330708809197
[Epoch 7, Batch 900] loss: 0.15713695174083114
[Epoch 7, Batch 1000] loss: 0.17816798899322747
[Epoch 7, Batch 1100] loss: 0.16021738298237323
[Epoch 7, Batch 1200] loss: 0.17376518943347036
[Epoch 7, Batch 1300] loss: 0.17917856205254792
[Epoch 7, Batch 1400] loss: 0.14562669355422259
[Epoch 7, Batch 1500] loss: 0.14993784921243786
[Epoch 7, Batch 1600] loss: 0.1723402812704444
[Epoch 7, Batch 1700] loss: 0.17543072234839202
[Epoch 7, Batch 1800] loss: 0.14571841393131763
**STATS for Epoch 7** : 
Average training loss: 0.0056
Average validation loss: 0.1696
Validation Accuracy: 0.9492
Overfitting: 0.1640
Best model saved at epoch 7 with validation loss: 0.1696
[Epoch 8, Batch 100] loss: 0.13923611625796184
[Epoch 8, Batch 200] loss: 0.151065431390889
[Epoch 8, Batch 300] loss: 0.15444031370803712
[Epoch 8, Batch 400] loss: 0.1577328794170171
[Epoch 8, Batch 500] loss: 0.176078011803329
[Epoch 8, Batch 600] loss: 0.1448543701414019
[Epoch 8, Batch 700] loss: 0.1307915260642767
[Epoch 8, Batch 800] loss: 0.18745732633396983
[Epoch 8, Batch 900] loss: 0.1381777270976454
[Epoch 8, Batch 1000] loss: 0.1711771174054593
[Epoch 8, Batch 1100] loss: 0.15154469237662851
[Epoch 8, Batch 1200] loss: 0.12512908629141747
[Epoch 8, Batch 1300] loss: 0.14624141082167624
[Epoch 8, Batch 1400] loss: 0.13751647154800595
[Epoch 8, Batch 1500] loss: 0.15570483868010343
[Epoch 8, Batch 1600] loss: 0.15898510626051576
[Epoch 8, Batch 1700] loss: 0.13940368875861167
[Epoch 8, Batch 1800] loss: 0.14623793063685298
**STATS for Epoch 8** : 
Average training loss: 0.0052
Average validation loss: 0.1459
Validation Accuracy: 0.9572
Overfitting: 0.1407
Best model saved at epoch 8 with validation loss: 0.1459
[Epoch 9, Batch 100] loss: 0.1395148487901315
[Epoch 9, Batch 200] loss: 0.12901291768066586
[Epoch 9, Batch 300] loss: 0.11807024748530238
[Epoch 9, Batch 400] loss: 0.1577280583488755
[Epoch 9, Batch 500] loss: 0.14739090687595308
[Epoch 9, Batch 600] loss: 0.13091998357791454
[Epoch 9, Batch 700] loss: 0.12959314278326928
[Epoch 9, Batch 800] loss: 0.14083973543252795
[Epoch 9, Batch 900] loss: 0.11934463248588145
[Epoch 9, Batch 1000] loss: 0.1258193187881261
[Epoch 9, Batch 1100] loss: 0.14811169342137873
[Epoch 9, Batch 1200] loss: 0.13646852461155504
[Epoch 9, Batch 1300] loss: 0.11456744115799665
[Epoch 9, Batch 1400] loss: 0.14759840649552644
[Epoch 9, Batch 1500] loss: 0.1491140744648874
[Epoch 9, Batch 1600] loss: 0.14541115436237306
[Epoch 9, Batch 1700] loss: 0.13845495196757837
[Epoch 9, Batch 1800] loss: 0.13127799599897116
**STATS for Epoch 9** : 
Average training loss: 0.0056
Average validation loss: 0.1320
Validation Accuracy: 0.9602
Overfitting: 0.1264
Best model saved at epoch 9 with validation loss: 0.1320
[Epoch 10, Batch 100] loss: 0.12461776413023472
[Epoch 10, Batch 200] loss: 0.12818091127090156
[Epoch 10, Batch 300] loss: 0.10398070332594216
[Epoch 10, Batch 400] loss: 0.15177031415514647
[Epoch 10, Batch 500] loss: 0.09728648896794766
[Epoch 10, Batch 600] loss: 0.12251301430165767
[Epoch 10, Batch 700] loss: 0.1158091183565557
[Epoch 10, Batch 800] loss: 0.11305692783091217
[Epoch 10, Batch 900] loss: 0.153237951581832
[Epoch 10, Batch 1000] loss: 0.12324317458551377
[Epoch 10, Batch 1100] loss: 0.12114230616949499
[Epoch 10, Batch 1200] loss: 0.12698504821397363
[Epoch 10, Batch 1300] loss: 0.10598882647231221
[Epoch 10, Batch 1400] loss: 0.12134600111283361
[Epoch 10, Batch 1500] loss: 0.14276093195658177
[Epoch 10, Batch 1600] loss: 0.11536166228586808
[Epoch 10, Batch 1700] loss: 0.12043882075231523
[Epoch 10, Batch 1800] loss: 0.15803601718507707
**STATS for Epoch 10** : 
Average training loss: 0.0054
Average validation loss: 0.1301
Validation Accuracy: 0.9613
Overfitting: 0.1247
Best model saved at epoch 10 with validation loss: 0.1301
[Epoch 11, Batch 100] loss: 0.12500214874744414
[Epoch 11, Batch 200] loss: 0.11230637841392309
[Epoch 11, Batch 300] loss: 0.1307164284796454
[Epoch 11, Batch 400] loss: 0.10009612572845071
[Epoch 11, Batch 500] loss: 0.1167494567669928
[Epoch 11, Batch 600] loss: 0.1574395441263914
[Epoch 11, Batch 700] loss: 0.11282765135634691
[Epoch 11, Batch 800] loss: 0.11608456343412399
[Epoch 11, Batch 900] loss: 0.11786821315530688
[Epoch 11, Batch 1000] loss: 0.12500964059494435
[Epoch 11, Batch 1100] loss: 0.11930457188282162
[Epoch 11, Batch 1200] loss: 0.09186345555819571
[Epoch 11, Batch 1300] loss: 0.09534771219128743
[Epoch 11, Batch 1400] loss: 0.11551639722660184
[Epoch 11, Batch 1500] loss: 0.11830369393574074
[Epoch 11, Batch 1600] loss: 0.1231514577800408
[Epoch 11, Batch 1700] loss: 0.10868778481613844
[Epoch 11, Batch 1800] loss: 0.10213991408236325
**STATS for Epoch 11** : 
Average training loss: 0.0041
Average validation loss: 0.1194
Validation Accuracy: 0.9640
Overfitting: 0.1153
Best model saved at epoch 11 with validation loss: 0.1194
[Epoch 12, Batch 100] loss: 0.11344217936974019
[Epoch 12, Batch 200] loss: 0.09320198564790189
[Epoch 12, Batch 300] loss: 0.10412629462778568
[Epoch 12, Batch 400] loss: 0.12108781111426652
[Epoch 12, Batch 500] loss: 0.12255413209786639
[Epoch 12, Batch 600] loss: 0.11801975941751153
[Epoch 12, Batch 700] loss: 0.11220521643292158
[Epoch 12, Batch 800] loss: 0.0885272513201926
[Epoch 12, Batch 900] loss: 0.09907691753236576
[Epoch 12, Batch 1000] loss: 0.11371553036384284
[Epoch 12, Batch 1100] loss: 0.12031986991176381
[Epoch 12, Batch 1200] loss: 0.11062484280439094
[Epoch 12, Batch 1300] loss: 0.11495446824468672
[Epoch 12, Batch 1400] loss: 0.09762188928667456
[Epoch 12, Batch 1500] loss: 0.09173990313895047
[Epoch 12, Batch 1600] loss: 0.10038573235273361
[Epoch 12, Batch 1700] loss: 0.1254191113449633
[Epoch 12, Batch 1800] loss: 0.12855081907473503
**STATS for Epoch 12** : 
Average training loss: 0.0043
Average validation loss: 0.1077
Validation Accuracy: 0.9677
Overfitting: 0.1034
Best model saved at epoch 12 with validation loss: 0.1077
[Epoch 13, Batch 100] loss: 0.10544004008173942
[Epoch 13, Batch 200] loss: 0.10804945627693087
[Epoch 13, Batch 300] loss: 0.11399095115368255
[Epoch 13, Batch 400] loss: 0.1162115522660315
[Epoch 13, Batch 500] loss: 0.11101269794278779
[Epoch 13, Batch 600] loss: 0.09904989088419824
[Epoch 13, Batch 700] loss: 0.0822565714456141
[Epoch 13, Batch 800] loss: 0.09345854738960042
[Epoch 13, Batch 900] loss: 0.09675327301723882
[Epoch 13, Batch 1000] loss: 0.10313736470416188
[Epoch 13, Batch 1100] loss: 0.09764160989085212
[Epoch 13, Batch 1200] loss: 0.11129417709656991
[Epoch 13, Batch 1300] loss: 0.10723902605939656
[Epoch 13, Batch 1400] loss: 0.10789122275542468
[Epoch 13, Batch 1500] loss: 0.10379593054298311
[Epoch 13, Batch 1600] loss: 0.08526628168532625
[Epoch 13, Batch 1700] loss: 0.11394630161812529
[Epoch 13, Batch 1800] loss: 0.07162418528925628
**STATS for Epoch 13** : 
Average training loss: 0.0041
Average validation loss: 0.1049
Validation Accuracy: 0.9683
Overfitting: 0.1009
Best model saved at epoch 13 with validation loss: 0.1049
[Epoch 14, Batch 100] loss: 0.11413087895140052
[Epoch 14, Batch 200] loss: 0.08977514484664426
[Epoch 14, Batch 300] loss: 0.10131379118538461
[Epoch 14, Batch 400] loss: 0.09616472939494997
[Epoch 14, Batch 500] loss: 0.10170601855963468
[Epoch 14, Batch 600] loss: 0.11011571645969526
[Epoch 14, Batch 700] loss: 0.0860068316035904
[Epoch 14, Batch 800] loss: 0.09776576320989988
[Epoch 14, Batch 900] loss: 0.08383467617910355
[Epoch 14, Batch 1000] loss: 0.09126785455271602
[Epoch 14, Batch 1100] loss: 0.10828388947993517
[Epoch 14, Batch 1200] loss: 0.08368391481461003
[Epoch 14, Batch 1300] loss: 0.10208046469604597
[Epoch 14, Batch 1400] loss: 0.09666888071224093
[Epoch 14, Batch 1500] loss: 0.10312868484295905
[Epoch 14, Batch 1600] loss: 0.09692255475092679
[Epoch 14, Batch 1700] loss: 0.08899573707021773
[Epoch 14, Batch 1800] loss: 0.08128768519498408
**STATS for Epoch 14** : 
Average training loss: 0.0032
Average validation loss: 0.1004
Validation Accuracy: 0.9693
Overfitting: 0.0972
Best model saved at epoch 14 with validation loss: 0.1004
[Epoch 15, Batch 100] loss: 0.10434556479332968
[Epoch 15, Batch 200] loss: 0.09149759134044871
[Epoch 15, Batch 300] loss: 0.09642645039130002
[Epoch 15, Batch 400] loss: 0.12365752787562087
[Epoch 15, Batch 500] loss: 0.10829709217417985
[Epoch 15, Batch 600] loss: 0.0987807819340378
[Epoch 15, Batch 700] loss: 0.08739191817352548
[Epoch 15, Batch 800] loss: 0.09436546811251902
[Epoch 15, Batch 900] loss: 0.08743041146779433
[Epoch 15, Batch 1000] loss: 0.06675113329198211
[Epoch 15, Batch 1100] loss: 0.08278598024975509
[Epoch 15, Batch 1200] loss: 0.07308081075549126
[Epoch 15, Batch 1300] loss: 0.09131362440530211
[Epoch 15, Batch 1400] loss: 0.1038281047786586
[Epoch 15, Batch 1500] loss: 0.09874503661645577
[Epoch 15, Batch 1600] loss: 0.06256756320595741
[Epoch 15, Batch 1700] loss: 0.07589923731749877
[Epoch 15, Batch 1800] loss: 0.10339455222245306
**STATS for Epoch 15** : 
Average training loss: 0.0032
Average validation loss: 0.0947
Validation Accuracy: 0.9707
Overfitting: 0.0915
Best model saved at epoch 15 with validation loss: 0.0947
[Epoch 16, Batch 100] loss: 0.09229601458529942
[Epoch 16, Batch 200] loss: 0.08973506902926602
[Epoch 16, Batch 300] loss: 0.054406425692141054
[Epoch 16, Batch 400] loss: 0.09247296405956149
[Epoch 16, Batch 500] loss: 0.09252670779824257
[Epoch 16, Batch 600] loss: 0.0712813471071422
[Epoch 16, Batch 700] loss: 0.0866319195809774
[Epoch 16, Batch 800] loss: 0.08375980002456344
[Epoch 16, Batch 900] loss: 0.10600420204922557
[Epoch 16, Batch 1000] loss: 0.08890303750173188
[Epoch 16, Batch 1100] loss: 0.09063374057062902
[Epoch 16, Batch 1200] loss: 0.08000451323343441
[Epoch 16, Batch 1300] loss: 0.12744488418800756
[Epoch 16, Batch 1400] loss: 0.06841119121265365
[Epoch 16, Batch 1500] loss: 0.08027894579921849
[Epoch 16, Batch 1600] loss: 0.09926077547483146
[Epoch 16, Batch 1700] loss: 0.08366534575005062
[Epoch 16, Batch 1800] loss: 0.07814134014770388
**STATS for Epoch 16** : 
Average training loss: 0.0038
Average validation loss: 0.0916
Validation Accuracy: 0.9718
Overfitting: 0.0878
Best model saved at epoch 16 with validation loss: 0.0916
[Epoch 17, Batch 100] loss: 0.06453538155998104
[Epoch 17, Batch 200] loss: 0.09212301615974866
[Epoch 17, Batch 300] loss: 0.08697552456287667
[Epoch 17, Batch 400] loss: 0.07508781189331785
[Epoch 17, Batch 500] loss: 0.08558090553968213
[Epoch 17, Batch 600] loss: 0.09229916907497682
[Epoch 17, Batch 700] loss: 0.08354771108366549
[Epoch 17, Batch 800] loss: 0.07945138888666406
[Epoch 17, Batch 900] loss: 0.07222823123680427
[Epoch 17, Batch 1000] loss: 0.08899846751359292
[Epoch 17, Batch 1100] loss: 0.08981150849955157
[Epoch 17, Batch 1200] loss: 0.08708767832722515
[Epoch 17, Batch 1300] loss: 0.0971554950857535
[Epoch 17, Batch 1400] loss: 0.0744488444714807
[Epoch 17, Batch 1500] loss: 0.09802989097428508
[Epoch 17, Batch 1600] loss: 0.07349803118035197
[Epoch 17, Batch 1700] loss: 0.09019335908349603
[Epoch 17, Batch 1800] loss: 0.07594620940159075
**STATS for Epoch 17** : 
Average training loss: 0.0029
Average validation loss: 0.0947
Validation Accuracy: 0.9704
Overfitting: 0.0918
[Epoch 18, Batch 100] loss: 0.06259684521588497
[Epoch 18, Batch 200] loss: 0.09659065229585394
[Epoch 18, Batch 300] loss: 0.08627403374644928
[Epoch 18, Batch 400] loss: 0.07036733989836648
[Epoch 18, Batch 500] loss: 0.07793417036999017
[Epoch 18, Batch 600] loss: 0.085979952190537
[Epoch 18, Batch 700] loss: 0.0836236419522902
[Epoch 18, Batch 800] loss: 0.08478554981178604
[Epoch 18, Batch 900] loss: 0.07244305296684615
[Epoch 18, Batch 1000] loss: 0.06640517087187618
[Epoch 18, Batch 1100] loss: 0.06447432927321643
[Epoch 18, Batch 1200] loss: 0.08251862347824498
[Epoch 18, Batch 1300] loss: 0.06540887952782214
[Epoch 18, Batch 1400] loss: 0.10199507319252006
[Epoch 18, Batch 1500] loss: 0.07684368814749178
[Epoch 18, Batch 1600] loss: 0.08623517352854833
[Epoch 18, Batch 1700] loss: 0.08223000070312991
[Epoch 18, Batch 1800] loss: 0.09463971730670892
**STATS for Epoch 18** : 
Average training loss: 0.0025
Average validation loss: 0.0893
Validation Accuracy: 0.9724
Overfitting: 0.0868
Best model saved at epoch 18 with validation loss: 0.0893
[Epoch 19, Batch 100] loss: 0.07216234727296979
[Epoch 19, Batch 200] loss: 0.08749795510899276
[Epoch 19, Batch 300] loss: 0.07268512165173888
[Epoch 19, Batch 400] loss: 0.07918655034154654
[Epoch 19, Batch 500] loss: 0.0813756527286023
[Epoch 19, Batch 600] loss: 0.0703786923061125
[Epoch 19, Batch 700] loss: 0.07715336461435073
[Epoch 19, Batch 800] loss: 0.063742267038906
[Epoch 19, Batch 900] loss: 0.08556691145524382
[Epoch 19, Batch 1000] loss: 0.06599405840504914
[Epoch 19, Batch 1100] loss: 0.09346394412685186
[Epoch 19, Batch 1200] loss: 0.08791465451125986
[Epoch 19, Batch 1300] loss: 0.06928597528254614
[Epoch 19, Batch 1400] loss: 0.07978273096727208
[Epoch 19, Batch 1500] loss: 0.07256369309732691
[Epoch 19, Batch 1600] loss: 0.06995544282719493
[Epoch 19, Batch 1700] loss: 0.08057429348817095
[Epoch 19, Batch 1800] loss: 0.07226972710690462
**STATS for Epoch 19** : 
Average training loss: 0.0027
Average validation loss: 0.0855
Validation Accuracy: 0.9736
Overfitting: 0.0828
Best model saved at epoch 19 with validation loss: 0.0855
[Epoch 20, Batch 100] loss: 0.08262202852987684
[Epoch 20, Batch 200] loss: 0.07323647130047903
[Epoch 20, Batch 300] loss: 0.06596735337981954
[Epoch 20, Batch 400] loss: 0.0600902604451403
[Epoch 20, Batch 500] loss: 0.09962907461682334
[Epoch 20, Batch 600] loss: 0.08289647126104682
[Epoch 20, Batch 700] loss: 0.07037806998938322
[Epoch 20, Batch 800] loss: 0.08103042592993007
[Epoch 20, Batch 900] loss: 0.06727335856878199
[Epoch 20, Batch 1000] loss: 0.06352606776403263
[Epoch 20, Batch 1100] loss: 0.07756316601531581
[Epoch 20, Batch 1200] loss: 0.06768291249522009
[Epoch 20, Batch 1300] loss: 0.07418687723809853
[Epoch 20, Batch 1400] loss: 0.06665341114974581
[Epoch 20, Batch 1500] loss: 0.07946943368995563
[Epoch 20, Batch 1600] loss: 0.06821454900782556
[Epoch 20, Batch 1700] loss: 0.06985820864792913
[Epoch 20, Batch 1800] loss: 0.08532116518355906
**STATS for Epoch 20** : 
Average training loss: 0.0031
Average validation loss: 0.0832
Validation Accuracy: 0.9752
Overfitting: 0.0801
Best model saved at epoch 20 with validation loss: 0.0832
[Epoch 21, Batch 100] loss: 0.06844197096885182
[Epoch 21, Batch 200] loss: 0.06652645288500934
[Epoch 21, Batch 300] loss: 0.07053936860698741
[Epoch 21, Batch 400] loss: 0.05943389502936043
[Epoch 21, Batch 500] loss: 0.06014491069712676
[Epoch 21, Batch 600] loss: 0.08018170143361203
[Epoch 21, Batch 700] loss: 0.08763530772412195
[Epoch 21, Batch 800] loss: 0.0722070707194507
[Epoch 21, Batch 900] loss: 0.06678446576814168
[Epoch 21, Batch 1000] loss: 0.058848790827905756
[Epoch 21, Batch 1100] loss: 0.07973446483258158
[Epoch 21, Batch 1200] loss: 0.05084761280624662
[Epoch 21, Batch 1300] loss: 0.0807167501951335
[Epoch 21, Batch 1400] loss: 0.07585946440231055
[Epoch 21, Batch 1500] loss: 0.07185798142687418
[Epoch 21, Batch 1600] loss: 0.08021277870284393
[Epoch 21, Batch 1700] loss: 0.06942012546001934
[Epoch 21, Batch 1800] loss: 0.062283425061032176
**STATS for Epoch 21** : 
Average training loss: 0.0023
Average validation loss: 0.0850
Validation Accuracy: 0.9732
Overfitting: 0.0826
[Epoch 22, Batch 100] loss: 0.060458234276156875
[Epoch 22, Batch 200] loss: 0.0808794642938301
[Epoch 22, Batch 300] loss: 0.09521190000697971
[Epoch 22, Batch 400] loss: 0.07263473398284986
[Epoch 22, Batch 500] loss: 0.057427104010712354
[Epoch 22, Batch 600] loss: 0.05474834128282964
[Epoch 22, Batch 700] loss: 0.08158331145416015
[Epoch 22, Batch 800] loss: 0.05786971128196455
[Epoch 22, Batch 900] loss: 0.0486620250280248
[Epoch 22, Batch 1000] loss: 0.07444985233072657
[Epoch 22, Batch 1100] loss: 0.07878510518581607
[Epoch 22, Batch 1200] loss: 0.07315758038836066
[Epoch 22, Batch 1300] loss: 0.0713622831646353
[Epoch 22, Batch 1400] loss: 0.06703899674583226
[Epoch 22, Batch 1500] loss: 0.06642762754461728
[Epoch 22, Batch 1600] loss: 0.07416704174946062
[Epoch 22, Batch 1700] loss: 0.060662117650499565
[Epoch 22, Batch 1800] loss: 0.062488068029051644
**STATS for Epoch 22** : 
Average training loss: 0.0027
Average validation loss: 0.0837
Validation Accuracy: 0.9746
Overfitting: 0.0810
[Epoch 23, Batch 100] loss: 0.06327623888268136
[Epoch 23, Batch 200] loss: 0.06611112331273034
[Epoch 23, Batch 300] loss: 0.06797351301880554
[Epoch 23, Batch 400] loss: 0.07935604712896747
[Epoch 23, Batch 500] loss: 0.07115382911288179
[Epoch 23, Batch 600] loss: 0.06439743946655653
[Epoch 23, Batch 700] loss: 0.07108525654301047
[Epoch 23, Batch 800] loss: 0.07157257085782476
[Epoch 23, Batch 900] loss: 0.06355243304918985
[Epoch 23, Batch 1000] loss: 0.06695105650695041
[Epoch 23, Batch 1100] loss: 0.06742628291889559
[Epoch 23, Batch 1200] loss: 0.0631905019923579
[Epoch 23, Batch 1300] loss: 0.07295859178062529
[Epoch 23, Batch 1400] loss: 0.05526480864151381
[Epoch 23, Batch 1500] loss: 0.06534492079576011
[Epoch 23, Batch 1600] loss: 0.05779480636701919
[Epoch 23, Batch 1700] loss: 0.0604332972317934
[Epoch 23, Batch 1800] loss: 0.0563232771854382
**STATS for Epoch 23** : 
Average training loss: 0.0029
Average validation loss: 0.0792
Validation Accuracy: 0.9751
Overfitting: 0.0763
Best model saved at epoch 23 with validation loss: 0.0792
[Epoch 24, Batch 100] loss: 0.06652525692479686
[Epoch 24, Batch 200] loss: 0.042810420014429834
[Epoch 24, Batch 300] loss: 0.07060183402267285
[Epoch 24, Batch 400] loss: 0.07170047111867461
[Epoch 24, Batch 500] loss: 0.053149358604568986
[Epoch 24, Batch 600] loss: 0.05191773136262782
[Epoch 24, Batch 700] loss: 0.07088905084179714
[Epoch 24, Batch 800] loss: 0.08613612953398843
[Epoch 24, Batch 900] loss: 0.06002536266751122
[Epoch 24, Batch 1000] loss: 0.06480190149741247
[Epoch 24, Batch 1100] loss: 0.05487273086677305
[Epoch 24, Batch 1200] loss: 0.07755990157602355
[Epoch 24, Batch 1300] loss: 0.07240284035331569
[Epoch 24, Batch 1400] loss: 0.06410790729743894
[Epoch 24, Batch 1500] loss: 0.059780389990191904
[Epoch 24, Batch 1600] loss: 0.07171658387640491
[Epoch 24, Batch 1700] loss: 0.05071881966199726
[Epoch 24, Batch 1800] loss: 0.046173532730899754
**STATS for Epoch 24** : 
Average training loss: 0.0029
Average validation loss: 0.0813
Validation Accuracy: 0.9756
Overfitting: 0.0785
Fold 2 validation loss: 0.0813
Mean validation loss across all folds for Trial 5 is 0.0792 with trial config:  l1: 256, l2: 128, lr: 0.00010842262717330161, batch_size: 16
[I 2024-11-25 15:35:47,938] Trial 4 finished with value: 0.07920952932920772 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.00010842262717330161, 'batch_size': 16}. Best is trial 2 with value: 0.06046210698719751.

Selected Hyperparameters for Trial 6:
  l1: 128, l2: 128, lr: 0.0009896447606083916, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.294459283351898
[Epoch 1, Batch 200] loss: 2.251319954395294
[Epoch 1, Batch 300] loss: 2.0581191885471344
[Epoch 1, Batch 400] loss: 1.2651555454730987
[Epoch 1, Batch 500] loss: 0.7502036902308464
[Epoch 1, Batch 600] loss: 0.5574792367219925
[Epoch 1, Batch 700] loss: 0.46095034599304197
[Epoch 1, Batch 800] loss: 0.4218430819362402
[Epoch 1, Batch 900] loss: 0.3616096120327711
**STATS for Epoch 1** : 
Average training loss: 0.0159
Average validation loss: 0.4178
Validation Accuracy: 0.8662
Overfitting: 0.4019
Best model saved at epoch 1 with validation loss: 0.4178
[Epoch 2, Batch 100] loss: 0.33748445235192776
[Epoch 2, Batch 200] loss: 0.3217610193043947
[Epoch 2, Batch 300] loss: 0.2889541659504175
[Epoch 2, Batch 400] loss: 0.2555122916027904
[Epoch 2, Batch 500] loss: 0.2805191536992788
[Epoch 2, Batch 600] loss: 0.23459124222397804
[Epoch 2, Batch 700] loss: 0.21532395333051682
[Epoch 2, Batch 800] loss: 0.2011054674349725
[Epoch 2, Batch 900] loss: 0.21568338308483362
**STATS for Epoch 2** : 
Average training loss: 0.0082
Average validation loss: 0.1679
Validation Accuracy: 0.9499
Overfitting: 0.1597
Best model saved at epoch 2 with validation loss: 0.1679
[Epoch 3, Batch 100] loss: 0.18541930679231883
[Epoch 3, Batch 200] loss: 0.17597404502332212
[Epoch 3, Batch 300] loss: 0.16046012826263906
[Epoch 3, Batch 400] loss: 0.15560532798990606
[Epoch 3, Batch 500] loss: 0.17423987593501805
[Epoch 3, Batch 600] loss: 0.16632233830168844
[Epoch 3, Batch 700] loss: 0.16305124182254077
[Epoch 3, Batch 800] loss: 0.1250529061816633
[Epoch 3, Batch 900] loss: 0.12548098504543304
**STATS for Epoch 3** : 
Average training loss: 0.0058
Average validation loss: 0.1252
Validation Accuracy: 0.9611
Overfitting: 0.1194
Best model saved at epoch 3 with validation loss: 0.1252
[Epoch 4, Batch 100] loss: 0.14474782111123205
[Epoch 4, Batch 200] loss: 0.1119367012847215
[Epoch 4, Batch 300] loss: 0.12899719641543925
[Epoch 4, Batch 400] loss: 0.12303301954641938
[Epoch 4, Batch 500] loss: 0.10351399538107216
[Epoch 4, Batch 600] loss: 0.10415946284774691
[Epoch 4, Batch 700] loss: 0.13292258828878403
[Epoch 4, Batch 800] loss: 0.12231227623298764
[Epoch 4, Batch 900] loss: 0.10615384742850438
**STATS for Epoch 4** : 
Average training loss: 0.0049
Average validation loss: 0.1150
Validation Accuracy: 0.9649
Overfitting: 0.1101
Best model saved at epoch 4 with validation loss: 0.1150
[Epoch 5, Batch 100] loss: 0.09896312828641385
[Epoch 5, Batch 200] loss: 0.09860718603245915
[Epoch 5, Batch 300] loss: 0.10466444753110409
[Epoch 5, Batch 400] loss: 0.10631635066587478
[Epoch 5, Batch 500] loss: 0.09757133926730603
[Epoch 5, Batch 600] loss: 0.09941162861417979
[Epoch 5, Batch 700] loss: 0.08866398926824332
[Epoch 5, Batch 800] loss: 0.08027857867069542
[Epoch 5, Batch 900] loss: 0.08895884163212031
**STATS for Epoch 5** : 
Average training loss: 0.0046
Average validation loss: 0.1092
Validation Accuracy: 0.9657
Overfitting: 0.1046
Best model saved at epoch 5 with validation loss: 0.1092
[Epoch 6, Batch 100] loss: 0.07753854375332594
[Epoch 6, Batch 200] loss: 0.06641365154879168
[Epoch 6, Batch 300] loss: 0.09168301505967974
[Epoch 6, Batch 400] loss: 0.08857427070615813
[Epoch 6, Batch 500] loss: 0.08437273470219225
[Epoch 6, Batch 600] loss: 0.06874494916759431
[Epoch 6, Batch 700] loss: 0.07189302454935387
[Epoch 6, Batch 800] loss: 0.0767120918026194
[Epoch 6, Batch 900] loss: 0.10332354118581862
**STATS for Epoch 6** : 
Average training loss: 0.0033
Average validation loss: 0.0855
Validation Accuracy: 0.9736
Overfitting: 0.0822
Best model saved at epoch 6 with validation loss: 0.0855
[Epoch 7, Batch 100] loss: 0.07378358929883688
[Epoch 7, Batch 200] loss: 0.0809118562657386
[Epoch 7, Batch 300] loss: 0.06708946547005326
[Epoch 7, Batch 400] loss: 0.07004604436922818
[Epoch 7, Batch 500] loss: 0.0654214552603662
[Epoch 7, Batch 600] loss: 0.05472381480038166
[Epoch 7, Batch 700] loss: 0.06654974598670378
[Epoch 7, Batch 800] loss: 0.06579641519114375
[Epoch 7, Batch 900] loss: 0.08343980824807659
**STATS for Epoch 7** : 
Average training loss: 0.0027
Average validation loss: 0.0762
Validation Accuracy: 0.9770
Overfitting: 0.0735
Best model saved at epoch 7 with validation loss: 0.0762
[Epoch 8, Batch 100] loss: 0.05983198329806328
[Epoch 8, Batch 200] loss: 0.06527557688648812
[Epoch 8, Batch 300] loss: 0.06751109689008444
[Epoch 8, Batch 400] loss: 0.055322166220285
[Epoch 8, Batch 500] loss: 0.06896397249191068
[Epoch 8, Batch 600] loss: 0.06065715045435354
[Epoch 8, Batch 700] loss: 0.06530875886790455
[Epoch 8, Batch 800] loss: 0.04960222801193595
[Epoch 8, Batch 900] loss: 0.06199923199601472
**STATS for Epoch 8** : 
Average training loss: 0.0022
Average validation loss: 0.0796
Validation Accuracy: 0.9748
Overfitting: 0.0774
[Epoch 9, Batch 100] loss: 0.051078867343021556
[Epoch 9, Batch 200] loss: 0.05982002535369247
[Epoch 9, Batch 300] loss: 0.054424267804715785
[Epoch 9, Batch 400] loss: 0.04626113383332267
[Epoch 9, Batch 500] loss: 0.05240540731931105
[Epoch 9, Batch 600] loss: 0.05604551056050695
[Epoch 9, Batch 700] loss: 0.0734661304554902
[Epoch 9, Batch 800] loss: 0.05953756759641692
[Epoch 9, Batch 900] loss: 0.053065792710985986
**STATS for Epoch 9** : 
Average training loss: 0.0020
Average validation loss: 0.0750
Validation Accuracy: 0.9772
Overfitting: 0.0731
Best model saved at epoch 9 with validation loss: 0.0750
[Epoch 10, Batch 100] loss: 0.04188333480153233
[Epoch 10, Batch 200] loss: 0.05002499689115211
[Epoch 10, Batch 300] loss: 0.042073784391395745
[Epoch 10, Batch 400] loss: 0.052630534762283784
[Epoch 10, Batch 500] loss: 0.052814272440737116
[Epoch 10, Batch 600] loss: 0.04571004340599757
[Epoch 10, Batch 700] loss: 0.04789152499637567
[Epoch 10, Batch 800] loss: 0.05808696012070868
[Epoch 10, Batch 900] loss: 0.05126793652423658
**STATS for Epoch 10** : 
Average training loss: 0.0016
Average validation loss: 0.0682
Validation Accuracy: 0.9798
Overfitting: 0.0666
Best model saved at epoch 10 with validation loss: 0.0682
[Epoch 11, Batch 100] loss: 0.044085459451889616
[Epoch 11, Batch 200] loss: 0.051860635234043
[Epoch 11, Batch 300] loss: 0.03750162479293067
[Epoch 11, Batch 400] loss: 0.035219628876075146
[Epoch 11, Batch 500] loss: 0.04663038653088734
[Epoch 11, Batch 600] loss: 0.04697177755413577
[Epoch 11, Batch 700] loss: 0.04387717096658889
[Epoch 11, Batch 800] loss: 0.04325224091648124
[Epoch 11, Batch 900] loss: 0.04506394640891813
**STATS for Epoch 11** : 
Average training loss: 0.0016
Average validation loss: 0.0821
Validation Accuracy: 0.9739
Overfitting: 0.0805
[Epoch 12, Batch 100] loss: 0.043366798702045344
[Epoch 12, Batch 200] loss: 0.03320642867358401
[Epoch 12, Batch 300] loss: 0.03191281352308579
[Epoch 12, Batch 400] loss: 0.040727440317859874
[Epoch 12, Batch 500] loss: 0.039954828782356344
[Epoch 12, Batch 600] loss: 0.039772568594780754
[Epoch 12, Batch 700] loss: 0.03999771059025079
[Epoch 12, Batch 800] loss: 0.04239357358077541
[Epoch 12, Batch 900] loss: 0.04154720998601988
**STATS for Epoch 12** : 
Average training loss: 0.0025
Average validation loss: 0.0730
Validation Accuracy: 0.9774
Overfitting: 0.0705
[Epoch 13, Batch 100] loss: 0.03088571444619447
[Epoch 13, Batch 200] loss: 0.03722967900685035
[Epoch 13, Batch 300] loss: 0.02827076314482838
[Epoch 13, Batch 400] loss: 0.039255131855607035
[Epoch 13, Batch 500] loss: 0.040105243345024064
[Epoch 13, Batch 600] loss: 0.030281518572592175
[Epoch 13, Batch 700] loss: 0.03974658994236961
[Epoch 13, Batch 800] loss: 0.03123137410264462
[Epoch 13, Batch 900] loss: 0.04462579765357077
**STATS for Epoch 13** : 
Average training loss: 0.0015
Average validation loss: 0.0618
Validation Accuracy: 0.9812
Overfitting: 0.0603
Best model saved at epoch 13 with validation loss: 0.0618
[Epoch 14, Batch 100] loss: 0.02522113752900623
[Epoch 14, Batch 200] loss: 0.03052035852946574
[Epoch 14, Batch 300] loss: 0.0345420541006024
[Epoch 14, Batch 400] loss: 0.03607481657876633
[Epoch 14, Batch 500] loss: 0.02879540405323496
[Epoch 14, Batch 600] loss: 0.034629790656617844
[Epoch 14, Batch 700] loss: 0.03373919014353305
[Epoch 14, Batch 800] loss: 0.04242033084970899
[Epoch 14, Batch 900] loss: 0.03471299462369643
**STATS for Epoch 14** : 
Average training loss: 0.0014
Average validation loss: 0.0716
Validation Accuracy: 0.9776
Overfitting: 0.0702
[Epoch 15, Batch 100] loss: 0.0322295988042606
[Epoch 15, Batch 200] loss: 0.02937051337925368
[Epoch 15, Batch 300] loss: 0.0281025437975768
[Epoch 15, Batch 400] loss: 0.02993382660788484
[Epoch 15, Batch 500] loss: 0.03344081110175466
[Epoch 15, Batch 600] loss: 0.02261777235486079
[Epoch 15, Batch 700] loss: 0.03103286353405565
[Epoch 15, Batch 800] loss: 0.031320267947157844
[Epoch 15, Batch 900] loss: 0.02709877921908628
**STATS for Epoch 15** : 
Average training loss: 0.0018
Average validation loss: 0.0777
Validation Accuracy: 0.9782
Overfitting: 0.0759
[Epoch 16, Batch 100] loss: 0.020443383494421142
[Epoch 16, Batch 200] loss: 0.0254267873011122
[Epoch 16, Batch 300] loss: 0.023157848609844222
[Epoch 16, Batch 400] loss: 0.015173623138689436
[Epoch 16, Batch 500] loss: 0.02403432239560061
[Epoch 16, Batch 600] loss: 0.03209725969121791
[Epoch 16, Batch 700] loss: 0.0362134426512057
[Epoch 16, Batch 800] loss: 0.027787596656999085
[Epoch 16, Batch 900] loss: 0.03211911331716692
**STATS for Epoch 16** : 
Average training loss: 0.0009
Average validation loss: 0.0608
Validation Accuracy: 0.9817
Overfitting: 0.0599
Best model saved at epoch 16 with validation loss: 0.0608
[Epoch 17, Batch 100] loss: 0.016265459915739484
[Epoch 17, Batch 200] loss: 0.022485431461100235
[Epoch 17, Batch 300] loss: 0.02579550133406883
[Epoch 17, Batch 400] loss: 0.022024808295536786
[Epoch 17, Batch 500] loss: 0.029301709730352742
[Epoch 17, Batch 600] loss: 0.02859410097647924
[Epoch 17, Batch 700] loss: 0.02434540113899857
[Epoch 17, Batch 800] loss: 0.020937182774650863
[Epoch 17, Batch 900] loss: 0.022389774557377676
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0739
Validation Accuracy: 0.9789
Overfitting: 0.0728
[Epoch 18, Batch 100] loss: 0.016612067622918402
[Epoch 18, Batch 200] loss: 0.019087617690092883
[Epoch 18, Batch 300] loss: 0.021161800749832763
[Epoch 18, Batch 400] loss: 0.015632646825761185
[Epoch 18, Batch 500] loss: 0.021871191491227363
[Epoch 18, Batch 600] loss: 0.022685266427870374
[Epoch 18, Batch 700] loss: 0.02377012361714151
[Epoch 18, Batch 800] loss: 0.0247356366776512
[Epoch 18, Batch 900] loss: 0.024358956566866253
**STATS for Epoch 18** : 
Average training loss: 0.0012
Average validation loss: 0.0601
Validation Accuracy: 0.9824
Overfitting: 0.0589
Best model saved at epoch 18 with validation loss: 0.0601
[Epoch 19, Batch 100] loss: 0.016607212090748363
[Epoch 19, Batch 200] loss: 0.01648810772021534
[Epoch 19, Batch 300] loss: 0.0230709911257145
[Epoch 19, Batch 400] loss: 0.021723549493181053
[Epoch 19, Batch 500] loss: 0.02494965836289339
[Epoch 19, Batch 600] loss: 0.02117480142333079
[Epoch 19, Batch 700] loss: 0.016377746729122008
[Epoch 19, Batch 800] loss: 0.019879349077527877
[Epoch 19, Batch 900] loss: 0.019850645206461195
**STATS for Epoch 19** : 
Average training loss: 0.0012
Average validation loss: 0.0628
Validation Accuracy: 0.9826
Overfitting: 0.0616
[Epoch 20, Batch 100] loss: 0.013391905241151107
[Epoch 20, Batch 200] loss: 0.01946658190106973
[Epoch 20, Batch 300] loss: 0.020345062355772825
[Epoch 20, Batch 400] loss: 0.011724358961801044
[Epoch 20, Batch 500] loss: 0.021551067457185127
[Epoch 20, Batch 600] loss: 0.018030801198401603
[Epoch 20, Batch 700] loss: 0.018338992038625292
[Epoch 20, Batch 800] loss: 0.022200508612950216
[Epoch 20, Batch 900] loss: 0.018310709012584993
**STATS for Epoch 20** : 
Average training loss: 0.0010
Average validation loss: 0.0668
Validation Accuracy: 0.9819
Overfitting: 0.0658
[Epoch 21, Batch 100] loss: 0.010157094560054248
[Epoch 21, Batch 200] loss: 0.016426346120570087
[Epoch 21, Batch 300] loss: 0.018732833114336246
[Epoch 21, Batch 400] loss: 0.011298573953681626
[Epoch 21, Batch 500] loss: 0.014738668116624467
[Epoch 21, Batch 600] loss: 0.014702311512373854
[Epoch 21, Batch 700] loss: 0.015834400096500757
[Epoch 21, Batch 800] loss: 0.02599574286985444
[Epoch 21, Batch 900] loss: 0.015195190919330344
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0586
Validation Accuracy: 0.9839
Overfitting: 0.0582
Best model saved at epoch 21 with validation loss: 0.0586
[Epoch 22, Batch 100] loss: 0.014216712689194538
[Epoch 22, Batch 200] loss: 0.01668361754120269
[Epoch 22, Batch 300] loss: 0.015001251163776033
[Epoch 22, Batch 400] loss: 0.01552400539338123
[Epoch 22, Batch 500] loss: 0.008756490837258752
[Epoch 22, Batch 600] loss: 0.01242455820502073
[Epoch 22, Batch 700] loss: 0.01516127028287883
[Epoch 22, Batch 800] loss: 0.01709727712201129
[Epoch 22, Batch 900] loss: 0.018269597052785684
**STATS for Epoch 22** : 
Average training loss: 0.0006
Average validation loss: 0.0650
Validation Accuracy: 0.9819
Overfitting: 0.0644
[Epoch 23, Batch 100] loss: 0.014850543894499423
[Epoch 23, Batch 200] loss: 0.00817911791804363
[Epoch 23, Batch 300] loss: 0.015516144907342095
[Epoch 23, Batch 400] loss: 0.01941860391292721
[Epoch 23, Batch 500] loss: 0.01084700447623618
[Epoch 23, Batch 600] loss: 0.011465484164618829
[Epoch 23, Batch 700] loss: 0.018499467154179
[Epoch 23, Batch 800] loss: 0.01233475930053828
[Epoch 23, Batch 900] loss: 0.020161337504760013
**STATS for Epoch 23** : 
Average training loss: 0.0011
Average validation loss: 0.0689
Validation Accuracy: 0.9809
Overfitting: 0.0678
[Epoch 24, Batch 100] loss: 0.016592897206719498
[Epoch 24, Batch 200] loss: 0.008238197000609944
[Epoch 24, Batch 300] loss: 0.0070973157823755175
[Epoch 24, Batch 400] loss: 0.010353333538660081
[Epoch 24, Batch 500] loss: 0.009697434953923221
[Epoch 24, Batch 600] loss: 0.009084629340031824
[Epoch 24, Batch 700] loss: 0.01711828345867616
[Epoch 24, Batch 800] loss: 0.016813771813767742
[Epoch 24, Batch 900] loss: 0.02038759347749874
**STATS for Epoch 24** : 
Average training loss: 0.0004
Average validation loss: 0.0624
Validation Accuracy: 0.9835
Overfitting: 0.0620
Fold 1 validation loss: 0.0624
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.298321175575256
[Epoch 1, Batch 200] loss: 2.283070845603943
[Epoch 1, Batch 300] loss: 2.256663362979889
[Epoch 1, Batch 400] loss: 2.1504472351074218
[Epoch 1, Batch 500] loss: 1.6133231139183044
[Epoch 1, Batch 600] loss: 0.8395967185497284
[Epoch 1, Batch 700] loss: 0.5810426276922226
[Epoch 1, Batch 800] loss: 0.41816630378365516
[Epoch 1, Batch 900] loss: 0.40251288175582883
**STATS for Epoch 1** : 
Average training loss: 0.0143
Average validation loss: 0.3421
Validation Accuracy: 0.8990
Overfitting: 0.3278
Best model saved at epoch 1 with validation loss: 0.3421
[Epoch 2, Batch 100] loss: 0.32621686391532423
[Epoch 2, Batch 200] loss: 0.30228666357696055
[Epoch 2, Batch 300] loss: 0.2736503929272294
[Epoch 2, Batch 400] loss: 0.2576790899410844
[Epoch 2, Batch 500] loss: 0.24740606971085072
[Epoch 2, Batch 600] loss: 0.20856203854084016
[Epoch 2, Batch 700] loss: 0.19650256467983127
[Epoch 2, Batch 800] loss: 0.21910427328199147
[Epoch 2, Batch 900] loss: 0.18219183826819063
**STATS for Epoch 2** : 
Average training loss: 0.0072
Average validation loss: 0.2000
Validation Accuracy: 0.9374
Overfitting: 0.1929
Best model saved at epoch 2 with validation loss: 0.2000
[Epoch 3, Batch 100] loss: 0.15308357287198304
[Epoch 3, Batch 200] loss: 0.16950346475467085
[Epoch 3, Batch 300] loss: 0.17790498167276383
[Epoch 3, Batch 400] loss: 0.15699392061680556
[Epoch 3, Batch 500] loss: 0.14232009837403894
[Epoch 3, Batch 600] loss: 0.16632220159284772
[Epoch 3, Batch 700] loss: 0.12892370751127602
[Epoch 3, Batch 800] loss: 0.14047092768363656
[Epoch 3, Batch 900] loss: 0.1456729959975928
**STATS for Epoch 3** : 
Average training loss: 0.0053
Average validation loss: 0.1373
Validation Accuracy: 0.9585
Overfitting: 0.1320
Best model saved at epoch 3 with validation loss: 0.1373
[Epoch 4, Batch 100] loss: 0.13941738879308105
[Epoch 4, Batch 200] loss: 0.11769855271559208
[Epoch 4, Batch 300] loss: 0.11871991448104381
[Epoch 4, Batch 400] loss: 0.11713995123282075
[Epoch 4, Batch 500] loss: 0.105456150919199
[Epoch 4, Batch 600] loss: 0.11584985685534775
[Epoch 4, Batch 700] loss: 0.11365871736779809
[Epoch 4, Batch 800] loss: 0.10785539460368454
[Epoch 4, Batch 900] loss: 0.10933468396309763
**STATS for Epoch 4** : 
Average training loss: 0.0039
Average validation loss: 0.1155
Validation Accuracy: 0.9650
Overfitting: 0.1116
Best model saved at epoch 4 with validation loss: 0.1155
[Epoch 5, Batch 100] loss: 0.09675020131282508
[Epoch 5, Batch 200] loss: 0.09811036290600895
[Epoch 5, Batch 300] loss: 0.1007462014630437
[Epoch 5, Batch 400] loss: 0.10162654151674361
[Epoch 5, Batch 500] loss: 0.08505884347483515
[Epoch 5, Batch 600] loss: 0.10252768584527075
[Epoch 5, Batch 700] loss: 0.09639281773474068
[Epoch 5, Batch 800] loss: 0.08340641565155238
[Epoch 5, Batch 900] loss: 0.09059605368878693
**STATS for Epoch 5** : 
Average training loss: 0.0032
Average validation loss: 0.1074
Validation Accuracy: 0.9676
Overfitting: 0.1042
Best model saved at epoch 5 with validation loss: 0.1074
[Epoch 6, Batch 100] loss: 0.0796272382256575
[Epoch 6, Batch 200] loss: 0.08507305900100619
[Epoch 6, Batch 300] loss: 0.09412904910743236
[Epoch 6, Batch 400] loss: 0.0794455054635182
[Epoch 6, Batch 500] loss: 0.08730921722017229
[Epoch 6, Batch 600] loss: 0.07794118375983089
[Epoch 6, Batch 700] loss: 0.06879765353631229
[Epoch 6, Batch 800] loss: 0.07809506737161427
[Epoch 6, Batch 900] loss: 0.0830935114948079
**STATS for Epoch 6** : 
Average training loss: 0.0035
Average validation loss: 0.0877
Validation Accuracy: 0.9729
Overfitting: 0.0842
Best model saved at epoch 6 with validation loss: 0.0877
[Epoch 7, Batch 100] loss: 0.07193996870424599
[Epoch 7, Batch 200] loss: 0.07598665360128506
[Epoch 7, Batch 300] loss: 0.07005240906495601
[Epoch 7, Batch 400] loss: 0.07011130444705486
[Epoch 7, Batch 500] loss: 0.07258308192715049
[Epoch 7, Batch 600] loss: 0.0607089651376009
[Epoch 7, Batch 700] loss: 0.07151433953549713
[Epoch 7, Batch 800] loss: 0.06676823724294081
[Epoch 7, Batch 900] loss: 0.06881683924235403
**STATS for Epoch 7** : 
Average training loss: 0.0031
Average validation loss: 0.0908
Validation Accuracy: 0.9711
Overfitting: 0.0877
[Epoch 8, Batch 100] loss: 0.06886981025338174
[Epoch 8, Batch 200] loss: 0.07133587499149144
[Epoch 8, Batch 300] loss: 0.04985744993202388
[Epoch 8, Batch 400] loss: 0.07235109293367714
[Epoch 8, Batch 500] loss: 0.054826042817439885
[Epoch 8, Batch 600] loss: 0.05722090262803249
[Epoch 8, Batch 700] loss: 0.06689092858345248
[Epoch 8, Batch 800] loss: 0.06734458643011748
[Epoch 8, Batch 900] loss: 0.06159735020017251
**STATS for Epoch 8** : 
Average training loss: 0.0025
Average validation loss: 0.0830
Validation Accuracy: 0.9758
Overfitting: 0.0805
Best model saved at epoch 8 with validation loss: 0.0830
[Epoch 9, Batch 100] loss: 0.06006290261633694
[Epoch 9, Batch 200] loss: 0.05819362930720672
[Epoch 9, Batch 300] loss: 0.0607034174259752
[Epoch 9, Batch 400] loss: 0.053913301256252454
[Epoch 9, Batch 500] loss: 0.05363470887299627
[Epoch 9, Batch 600] loss: 0.04878081730566919
[Epoch 9, Batch 700] loss: 0.05409188673831523
[Epoch 9, Batch 800] loss: 0.05726070945733227
[Epoch 9, Batch 900] loss: 0.05628663412411697
**STATS for Epoch 9** : 
Average training loss: 0.0026
Average validation loss: 0.0689
Validation Accuracy: 0.9783
Overfitting: 0.0663
Best model saved at epoch 9 with validation loss: 0.0689
[Epoch 10, Batch 100] loss: 0.04890210010344163
[Epoch 10, Batch 200] loss: 0.060564877637661996
[Epoch 10, Batch 300] loss: 0.05974322131369263
[Epoch 10, Batch 400] loss: 0.04666465090820566
[Epoch 10, Batch 500] loss: 0.05550533875240944
[Epoch 10, Batch 600] loss: 0.047215299147646876
[Epoch 10, Batch 700] loss: 0.0435453425871674
[Epoch 10, Batch 800] loss: 0.05741451023030095
[Epoch 10, Batch 900] loss: 0.04699584267451428
**STATS for Epoch 10** : 
Average training loss: 0.0020
Average validation loss: 0.0649
Validation Accuracy: 0.9807
Overfitting: 0.0629
Best model saved at epoch 10 with validation loss: 0.0649
[Epoch 11, Batch 100] loss: 0.05243881138856523
[Epoch 11, Batch 200] loss: 0.03873967783642002
[Epoch 11, Batch 300] loss: 0.052252083383500576
[Epoch 11, Batch 400] loss: 0.04382997121312655
[Epoch 11, Batch 500] loss: 0.04602243502391502
[Epoch 11, Batch 600] loss: 0.05205367228831165
[Epoch 11, Batch 700] loss: 0.0373650131339673
[Epoch 11, Batch 800] loss: 0.04815945455105975
[Epoch 11, Batch 900] loss: 0.04882481580134481
**STATS for Epoch 11** : 
Average training loss: 0.0021
Average validation loss: 0.0642
Validation Accuracy: 0.9810
Overfitting: 0.0621
Best model saved at epoch 11 with validation loss: 0.0642
[Epoch 12, Batch 100] loss: 0.036169247949146666
[Epoch 12, Batch 200] loss: 0.0385695688042324
[Epoch 12, Batch 300] loss: 0.0427428012539167
[Epoch 12, Batch 400] loss: 0.044668498729006384
[Epoch 12, Batch 500] loss: 0.05164504338405095
[Epoch 12, Batch 600] loss: 0.04049419272923842
[Epoch 12, Batch 700] loss: 0.033045196471503
[Epoch 12, Batch 800] loss: 0.044969129752134906
[Epoch 12, Batch 900] loss: 0.04408536790229846
**STATS for Epoch 12** : 
Average training loss: 0.0018
Average validation loss: 0.0637
Validation Accuracy: 0.9803
Overfitting: 0.0619
Best model saved at epoch 12 with validation loss: 0.0637
[Epoch 13, Batch 100] loss: 0.03672138770867605
[Epoch 13, Batch 200] loss: 0.03780153833795339
[Epoch 13, Batch 300] loss: 0.03503755821206141
[Epoch 13, Batch 400] loss: 0.03455762418743689
[Epoch 13, Batch 500] loss: 0.0429678353224881
[Epoch 13, Batch 600] loss: 0.031461249798885545
[Epoch 13, Batch 700] loss: 0.03805110528162913
[Epoch 13, Batch 800] loss: 0.0477816494111903
[Epoch 13, Batch 900] loss: 0.04765297269623261
**STATS for Epoch 13** : 
Average training loss: 0.0012
Average validation loss: 0.0591
Validation Accuracy: 0.9826
Overfitting: 0.0579
Best model saved at epoch 13 with validation loss: 0.0591
[Epoch 14, Batch 100] loss: 0.030151010715635494
[Epoch 14, Batch 200] loss: 0.03223134693573229
[Epoch 14, Batch 300] loss: 0.0357925839239033
[Epoch 14, Batch 400] loss: 0.039434163141995666
[Epoch 14, Batch 500] loss: 0.03825954956817441
[Epoch 14, Batch 600] loss: 0.03123700324213132
[Epoch 14, Batch 700] loss: 0.038093095783042374
[Epoch 14, Batch 800] loss: 0.0307550268311752
[Epoch 14, Batch 900] loss: 0.035802544179314284
**STATS for Epoch 14** : 
Average training loss: 0.0015
Average validation loss: 0.0633
Validation Accuracy: 0.9805
Overfitting: 0.0618
[Epoch 15, Batch 100] loss: 0.03503098312532529
[Epoch 15, Batch 200] loss: 0.02351966099871788
[Epoch 15, Batch 300] loss: 0.03253300423093606
[Epoch 15, Batch 400] loss: 0.03236807279055938
[Epoch 15, Batch 500] loss: 0.02609823597362265
[Epoch 15, Batch 600] loss: 0.039188661937078
[Epoch 15, Batch 700] loss: 0.02925376435247017
[Epoch 15, Batch 800] loss: 0.03266033146646805
[Epoch 15, Batch 900] loss: 0.043185142571164764
**STATS for Epoch 15** : 
Average training loss: 0.0013
Average validation loss: 0.0641
Validation Accuracy: 0.9809
Overfitting: 0.0627
[Epoch 16, Batch 100] loss: 0.023983679205994122
[Epoch 16, Batch 200] loss: 0.03025621249980759
[Epoch 16, Batch 300] loss: 0.029330518257338553
[Epoch 16, Batch 400] loss: 0.031260756962001326
[Epoch 16, Batch 500] loss: 0.02269426447164733
[Epoch 16, Batch 600] loss: 0.023052552114240826
[Epoch 16, Batch 700] loss: 0.02896210237493506
[Epoch 16, Batch 800] loss: 0.04376341736875475
[Epoch 16, Batch 900] loss: 0.026722915941500103
**STATS for Epoch 16** : 
Average training loss: 0.0012
Average validation loss: 0.0553
Validation Accuracy: 0.9833
Overfitting: 0.0540
Best model saved at epoch 16 with validation loss: 0.0553
[Epoch 17, Batch 100] loss: 0.024136567362002096
[Epoch 17, Batch 200] loss: 0.036398656931123693
[Epoch 17, Batch 300] loss: 0.02992391435749596
[Epoch 17, Batch 400] loss: 0.024591424301615917
[Epoch 17, Batch 500] loss: 0.015109333909349517
[Epoch 17, Batch 600] loss: 0.02659712611173745
[Epoch 17, Batch 700] loss: 0.04239066279085819
[Epoch 17, Batch 800] loss: 0.0316948625119403
[Epoch 17, Batch 900] loss: 0.023801080162811558
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0598
Validation Accuracy: 0.9826
Overfitting: 0.0586
[Epoch 18, Batch 100] loss: 0.021697588549868668
[Epoch 18, Batch 200] loss: 0.018639301486255134
[Epoch 18, Batch 300] loss: 0.029750647124892567
[Epoch 18, Batch 400] loss: 0.024022755847836377
[Epoch 18, Batch 500] loss: 0.031450114997278435
[Epoch 18, Batch 600] loss: 0.0266995078191394
[Epoch 18, Batch 700] loss: 0.029040567730553447
[Epoch 18, Batch 800] loss: 0.027522679200628772
[Epoch 18, Batch 900] loss: 0.030691922998812515
**STATS for Epoch 18** : 
Average training loss: 0.0015
Average validation loss: 0.0541
Validation Accuracy: 0.9840
Overfitting: 0.0526
Best model saved at epoch 18 with validation loss: 0.0541
[Epoch 19, Batch 100] loss: 0.026186717129312455
[Epoch 19, Batch 200] loss: 0.0313117289514048
[Epoch 19, Batch 300] loss: 0.024814656799717342
[Epoch 19, Batch 400] loss: 0.02074336216421216
[Epoch 19, Batch 500] loss: 0.02096818739461014
[Epoch 19, Batch 600] loss: 0.021906796834955458
[Epoch 19, Batch 700] loss: 0.016871801168599633
[Epoch 19, Batch 800] loss: 0.023568032954353838
[Epoch 19, Batch 900] loss: 0.03065080882777693
**STATS for Epoch 19** : 
Average training loss: 0.0011
Average validation loss: 0.0527
Validation Accuracy: 0.9843
Overfitting: 0.0516
Best model saved at epoch 19 with validation loss: 0.0527
[Epoch 20, Batch 100] loss: 0.01749669909637305
[Epoch 20, Batch 200] loss: 0.021894142165547237
[Epoch 20, Batch 300] loss: 0.027745450371876357
[Epoch 20, Batch 400] loss: 0.021397694818733725
[Epoch 20, Batch 500] loss: 0.025778439140703994
[Epoch 20, Batch 600] loss: 0.027179657969099935
[Epoch 20, Batch 700] loss: 0.028019116046780253
[Epoch 20, Batch 800] loss: 0.023187925234087744
[Epoch 20, Batch 900] loss: 0.016446180199054652
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0504
Validation Accuracy: 0.9852
Overfitting: 0.0499
Best model saved at epoch 20 with validation loss: 0.0504
[Epoch 21, Batch 100] loss: 0.025720891987730282
[Epoch 21, Batch 200] loss: 0.01527913640049519
[Epoch 21, Batch 300] loss: 0.018073352700157558
[Epoch 21, Batch 400] loss: 0.01732365527997899
[Epoch 21, Batch 500] loss: 0.013874469365691765
[Epoch 21, Batch 600] loss: 0.02509106380850426
[Epoch 21, Batch 700] loss: 0.02172323914608569
[Epoch 21, Batch 800] loss: 0.02541211498188204
[Epoch 21, Batch 900] loss: 0.018756923573964742
**STATS for Epoch 21** : 
Average training loss: 0.0012
Average validation loss: 0.0607
Validation Accuracy: 0.9823
Overfitting: 0.0595
[Epoch 22, Batch 100] loss: 0.017248878804966807
[Epoch 22, Batch 200] loss: 0.01855959572319989
[Epoch 22, Batch 300] loss: 0.017579915835376596
[Epoch 22, Batch 400] loss: 0.020987324884627016
[Epoch 22, Batch 500] loss: 0.019239660446037306
[Epoch 22, Batch 600] loss: 0.019727154472493565
[Epoch 22, Batch 700] loss: 0.0193252776150257
[Epoch 22, Batch 800] loss: 0.01875945267820498
[Epoch 22, Batch 900] loss: 0.025785275652160634
**STATS for Epoch 22** : 
Average training loss: 0.0005
Average validation loss: 0.0562
Validation Accuracy: 0.9839
Overfitting: 0.0558
[Epoch 23, Batch 100] loss: 0.01594913528766483
[Epoch 23, Batch 200] loss: 0.017030744101775783
[Epoch 23, Batch 300] loss: 0.014056015539099463
[Epoch 23, Batch 400] loss: 0.01660954971652245
[Epoch 23, Batch 500] loss: 0.020859167830931256
[Epoch 23, Batch 600] loss: 0.022996965437487235
[Epoch 23, Batch 700] loss: 0.008830760800046846
[Epoch 23, Batch 800] loss: 0.0218943389254855
[Epoch 23, Batch 900] loss: 0.01892757025110768
**STATS for Epoch 23** : 
Average training loss: 0.0007
Average validation loss: 0.0513
Validation Accuracy: 0.9852
Overfitting: 0.0506
[Epoch 24, Batch 100] loss: 0.014336525281105423
[Epoch 24, Batch 200] loss: 0.014781227544590365
[Epoch 24, Batch 300] loss: 0.02891986524744425
[Epoch 24, Batch 400] loss: 0.01702904230391141
[Epoch 24, Batch 500] loss: 0.015308691666868981
[Epoch 24, Batch 600] loss: 0.013781492245470872
[Epoch 24, Batch 700] loss: 0.011527453163143946
[Epoch 24, Batch 800] loss: 0.011387753736053129
[Epoch 24, Batch 900] loss: 0.023864170202286913
**STATS for Epoch 24** : 
Average training loss: 0.0006
Average validation loss: 0.0593
Validation Accuracy: 0.9838
Overfitting: 0.0587
Fold 2 validation loss: 0.0593
Mean validation loss across all folds for Trial 6 is 0.0608 with trial config:  l1: 128, l2: 128, lr: 0.0009896447606083916, batch_size: 32
[I 2024-11-25 15:45:29,992] Trial 5 finished with value: 0.06084135174347536 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0009896447606083916, 'batch_size': 32}. Best is trial 2 with value: 0.06046210698719751.

Selected Hyperparameters for Trial 7:
  l1: 128, l2: 128, lr: 0.0012025975346676469, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3020008492469786
[Epoch 1, Batch 200] loss: 2.287942605018616
[Epoch 1, Batch 300] loss: 2.2583578515052793
[Epoch 1, Batch 400] loss: 2.1337807822227477
[Epoch 1, Batch 500] loss: 1.3821938899159432
[Epoch 1, Batch 600] loss: 0.6795219688117504
[Epoch 1, Batch 700] loss: 0.5288177579641342
[Epoch 1, Batch 800] loss: 0.45047753147780895
[Epoch 1, Batch 900] loss: 0.3989420548826456
[Epoch 1, Batch 1000] loss: 0.2979350024461746
[Epoch 1, Batch 1100] loss: 0.2756189921498299
[Epoch 1, Batch 1200] loss: 0.2902219194173813
[Epoch 1, Batch 1300] loss: 0.24840238550677896
[Epoch 1, Batch 1400] loss: 0.22540649630129336
[Epoch 1, Batch 1500] loss: 0.21132424699142574
[Epoch 1, Batch 1600] loss: 0.2166531789302826
[Epoch 1, Batch 1700] loss: 0.20035649174824358
[Epoch 1, Batch 1800] loss: 0.1614649727009237
**STATS for Epoch 1** : 
Average training loss: 0.0082
Average validation loss: 0.2212
Validation Accuracy: 0.9293
Overfitting: 0.2130
Best model saved at epoch 1 with validation loss: 0.2212
[Epoch 2, Batch 100] loss: 0.15760828255675732
[Epoch 2, Batch 200] loss: 0.16241048546507955
[Epoch 2, Batch 300] loss: 0.1393078881315887
[Epoch 2, Batch 400] loss: 0.1754181469976902
[Epoch 2, Batch 500] loss: 0.14240075622918083
[Epoch 2, Batch 600] loss: 0.14956802184693516
[Epoch 2, Batch 700] loss: 0.14433563877362757
[Epoch 2, Batch 800] loss: 0.1163339964300394
[Epoch 2, Batch 900] loss: 0.11782396769616753
[Epoch 2, Batch 1000] loss: 0.1144283870048821
[Epoch 2, Batch 1100] loss: 0.13989501303993165
[Epoch 2, Batch 1200] loss: 0.1239225205173716
[Epoch 2, Batch 1300] loss: 0.10012049009092153
[Epoch 2, Batch 1400] loss: 0.12858594497200102
[Epoch 2, Batch 1500] loss: 0.11943443799857051
[Epoch 2, Batch 1600] loss: 0.09407642859208863
[Epoch 2, Batch 1700] loss: 0.10606810393743217
[Epoch 2, Batch 1800] loss: 0.11338919325498864
**STATS for Epoch 2** : 
Average training loss: 0.0055
Average validation loss: 0.1003
Validation Accuracy: 0.9690
Overfitting: 0.0947
Best model saved at epoch 2 with validation loss: 0.1003
[Epoch 3, Batch 100] loss: 0.10444821342360228
[Epoch 3, Batch 200] loss: 0.09725967745296657
[Epoch 3, Batch 300] loss: 0.07664102114737034
[Epoch 3, Batch 400] loss: 0.09217375968582928
[Epoch 3, Batch 500] loss: 0.07231792760780081
[Epoch 3, Batch 600] loss: 0.08149414874787908
[Epoch 3, Batch 700] loss: 0.0983966905507259
[Epoch 3, Batch 800] loss: 0.08996151964645832
[Epoch 3, Batch 900] loss: 0.09312476495164447
[Epoch 3, Batch 1000] loss: 0.07861508516129107
[Epoch 3, Batch 1100] loss: 0.06456445675343275
[Epoch 3, Batch 1200] loss: 0.09444040008937009
[Epoch 3, Batch 1300] loss: 0.07912877356167883
[Epoch 3, Batch 1400] loss: 0.09101358385989443
[Epoch 3, Batch 1500] loss: 0.076641176242847
[Epoch 3, Batch 1600] loss: 0.07247697865765076
[Epoch 3, Batch 1700] loss: 0.07282587594818324
[Epoch 3, Batch 1800] loss: 0.07390960606920999
**STATS for Epoch 3** : 
Average training loss: 0.0038
Average validation loss: 0.0804
Validation Accuracy: 0.9760
Overfitting: 0.0767
Best model saved at epoch 3 with validation loss: 0.0804
[Epoch 4, Batch 100] loss: 0.07098722548456862
[Epoch 4, Batch 200] loss: 0.06976716584991664
[Epoch 4, Batch 300] loss: 0.06435731406148988
[Epoch 4, Batch 400] loss: 0.06383591209276346
[Epoch 4, Batch 500] loss: 0.06689656122529414
[Epoch 4, Batch 600] loss: 0.06234133085468784
[Epoch 4, Batch 700] loss: 0.06091478707850911
[Epoch 4, Batch 800] loss: 0.05844173565041274
[Epoch 4, Batch 900] loss: 0.07668036459479481
[Epoch 4, Batch 1000] loss: 0.033525875412597085
[Epoch 4, Batch 1100] loss: 0.06466463092328922
[Epoch 4, Batch 1200] loss: 0.07437580731173511
[Epoch 4, Batch 1300] loss: 0.0689195355155971
[Epoch 4, Batch 1400] loss: 0.05529541493044235
[Epoch 4, Batch 1500] loss: 0.08281146130757407
[Epoch 4, Batch 1600] loss: 0.06327934403088875
[Epoch 4, Batch 1700] loss: 0.05775037197308848
[Epoch 4, Batch 1800] loss: 0.051314212880097326
**STATS for Epoch 4** : 
Average training loss: 0.0027
Average validation loss: 0.0923
Validation Accuracy: 0.9709
Overfitting: 0.0895
[Epoch 5, Batch 100] loss: 0.05491162282240111
[Epoch 5, Batch 200] loss: 0.04977060913079186
[Epoch 5, Batch 300] loss: 0.050190958365274124
[Epoch 5, Batch 400] loss: 0.057957079235347916
[Epoch 5, Batch 500] loss: 0.04992925259983167
[Epoch 5, Batch 600] loss: 0.0690564985794481
[Epoch 5, Batch 700] loss: 0.05059771258354886
[Epoch 5, Batch 800] loss: 0.07882838519813959
[Epoch 5, Batch 900] loss: 0.048246000880317295
[Epoch 5, Batch 1000] loss: 0.03796088606468402
[Epoch 5, Batch 1100] loss: 0.06510673008975573
[Epoch 5, Batch 1200] loss: 0.04529112469987012
[Epoch 5, Batch 1300] loss: 0.06464217415079475
[Epoch 5, Batch 1400] loss: 0.04302876054600347
[Epoch 5, Batch 1500] loss: 0.058030064516642596
[Epoch 5, Batch 1600] loss: 0.04414510168688139
[Epoch 5, Batch 1700] loss: 0.0449776150190155
[Epoch 5, Batch 1800] loss: 0.05297505074428045
**STATS for Epoch 5** : 
Average training loss: 0.0016
Average validation loss: 0.0681
Validation Accuracy: 0.9792
Overfitting: 0.0665
Best model saved at epoch 5 with validation loss: 0.0681
[Epoch 6, Batch 100] loss: 0.04361205318607972
[Epoch 6, Batch 200] loss: 0.05135044460417703
[Epoch 6, Batch 300] loss: 0.038459708189038794
[Epoch 6, Batch 400] loss: 0.028236880423064575
[Epoch 6, Batch 500] loss: 0.058869917176489255
[Epoch 6, Batch 600] loss: 0.05979149054037407
[Epoch 6, Batch 700] loss: 0.044695842092623936
[Epoch 6, Batch 800] loss: 0.03231413168279687
[Epoch 6, Batch 900] loss: 0.022090025649085875
[Epoch 6, Batch 1000] loss: 0.0632123746504658
[Epoch 6, Batch 1100] loss: 0.03981529394310201
[Epoch 6, Batch 1200] loss: 0.04800123574852478
[Epoch 6, Batch 1300] loss: 0.03151202970344457
[Epoch 6, Batch 1400] loss: 0.04519178012997145
[Epoch 6, Batch 1500] loss: 0.04759371531807119
[Epoch 6, Batch 1600] loss: 0.038897576266463146
[Epoch 6, Batch 1700] loss: 0.04240619921387406
[Epoch 6, Batch 1800] loss: 0.049944836591021155
**STATS for Epoch 6** : 
Average training loss: 0.0017
Average validation loss: 0.0665
Validation Accuracy: 0.9792
Overfitting: 0.0648
Best model saved at epoch 6 with validation loss: 0.0665
[Epoch 7, Batch 100] loss: 0.026187059721414697
[Epoch 7, Batch 200] loss: 0.026910882172560376
[Epoch 7, Batch 300] loss: 0.04470067457354162
[Epoch 7, Batch 400] loss: 0.028412503074796404
[Epoch 7, Batch 500] loss: 0.03238160068664001
[Epoch 7, Batch 600] loss: 0.05212125037287478
[Epoch 7, Batch 700] loss: 0.03962798487744294
[Epoch 7, Batch 800] loss: 0.029079814238357357
[Epoch 7, Batch 900] loss: 0.041817290254257386
[Epoch 7, Batch 1000] loss: 0.030856785916112132
[Epoch 7, Batch 1100] loss: 0.03076640747167403
[Epoch 7, Batch 1200] loss: 0.0352458813006524
[Epoch 7, Batch 1300] loss: 0.039700907261285466
[Epoch 7, Batch 1400] loss: 0.03291341488424223
[Epoch 7, Batch 1500] loss: 0.036992866135842635
[Epoch 7, Batch 1600] loss: 0.03704536507051671
[Epoch 7, Batch 1700] loss: 0.032656280159426385
[Epoch 7, Batch 1800] loss: 0.04700158108797041
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0610
Validation Accuracy: 0.9823
Overfitting: 0.0591
Best model saved at epoch 7 with validation loss: 0.0610
[Epoch 8, Batch 100] loss: 0.024880570694513153
[Epoch 8, Batch 200] loss: 0.027414214200616696
[Epoch 8, Batch 300] loss: 0.0217785359438858
[Epoch 8, Batch 400] loss: 0.03856763931078604
[Epoch 8, Batch 500] loss: 0.015308243712061085
[Epoch 8, Batch 600] loss: 0.02851965533936891
[Epoch 8, Batch 700] loss: 0.04114288003191177
[Epoch 8, Batch 800] loss: 0.029874947811767926
[Epoch 8, Batch 900] loss: 0.038053884812252366
[Epoch 8, Batch 1000] loss: 0.031210223695525202
[Epoch 8, Batch 1100] loss: 0.02774638038543344
[Epoch 8, Batch 1200] loss: 0.03226949413350667
[Epoch 8, Batch 1300] loss: 0.034256834322441136
[Epoch 8, Batch 1400] loss: 0.036824603469431165
[Epoch 8, Batch 1500] loss: 0.043378926970690374
[Epoch 8, Batch 1600] loss: 0.036754881917586316
[Epoch 8, Batch 1700] loss: 0.03602052811336762
[Epoch 8, Batch 1800] loss: 0.02872230721783126
**STATS for Epoch 8** : 
Average training loss: 0.0011
Average validation loss: 0.0617
Validation Accuracy: 0.9815
Overfitting: 0.0606
[Epoch 9, Batch 100] loss: 0.03125648684072076
[Epoch 9, Batch 200] loss: 0.023322317404308707
[Epoch 9, Batch 300] loss: 0.022543599227865342
[Epoch 9, Batch 400] loss: 0.024876659893925533
[Epoch 9, Batch 500] loss: 0.03549416412235587
[Epoch 9, Batch 600] loss: 0.030390821069449885
[Epoch 9, Batch 700] loss: 0.021242829710063235
[Epoch 9, Batch 800] loss: 0.022942420785693685
[Epoch 9, Batch 900] loss: 0.03878639723116066
[Epoch 9, Batch 1000] loss: 0.023681536382573542
[Epoch 9, Batch 1100] loss: 0.03120143138585263
[Epoch 9, Batch 1200] loss: 0.03053570647149172
[Epoch 9, Batch 1300] loss: 0.0224753096231143
[Epoch 9, Batch 1400] loss: 0.028556168030881963
[Epoch 9, Batch 1500] loss: 0.020731539286643966
[Epoch 9, Batch 1600] loss: 0.012191699006871204
[Epoch 9, Batch 1700] loss: 0.03272070757942856
[Epoch 9, Batch 1800] loss: 0.034772743438516045
**STATS for Epoch 9** : 
Average training loss: 0.0011
Average validation loss: 0.0574
Validation Accuracy: 0.9839
Overfitting: 0.0563
Best model saved at epoch 9 with validation loss: 0.0574
[Epoch 10, Batch 100] loss: 0.02685575565734325
[Epoch 10, Batch 200] loss: 0.013766762920713518
[Epoch 10, Batch 300] loss: 0.017653610437118914
[Epoch 10, Batch 400] loss: 0.01701605581718468
[Epoch 10, Batch 500] loss: 0.024547807190101592
[Epoch 10, Batch 600] loss: 0.017279007394899962
[Epoch 10, Batch 700] loss: 0.024670943996316055
[Epoch 10, Batch 800] loss: 0.025092977954700474
[Epoch 10, Batch 900] loss: 0.022262327700227614
[Epoch 10, Batch 1000] loss: 0.034254327725066105
[Epoch 10, Batch 1100] loss: 0.01468980401805311
[Epoch 10, Batch 1200] loss: 0.025285326447810803
[Epoch 10, Batch 1300] loss: 0.026203267880628118
[Epoch 10, Batch 1400] loss: 0.02220994248189527
[Epoch 10, Batch 1500] loss: 0.032363630445688615
[Epoch 10, Batch 1600] loss: 0.016291749273550524
[Epoch 10, Batch 1700] loss: 0.024588407349656335
[Epoch 10, Batch 1800] loss: 0.01868709915499494
**STATS for Epoch 10** : 
Average training loss: 0.0014
Average validation loss: 0.0618
Validation Accuracy: 0.9823
Overfitting: 0.0605
[Epoch 11, Batch 100] loss: 0.012747535517064534
[Epoch 11, Batch 200] loss: 0.010322502745548263
[Epoch 11, Batch 300] loss: 0.021311299443332245
[Epoch 11, Batch 400] loss: 0.012540146962237486
[Epoch 11, Batch 500] loss: 0.0198774218048311
[Epoch 11, Batch 600] loss: 0.017409614114876605
[Epoch 11, Batch 700] loss: 0.013473850507252791
[Epoch 11, Batch 800] loss: 0.015790499812574126
[Epoch 11, Batch 900] loss: 0.01583799072981492
[Epoch 11, Batch 1000] loss: 0.024152347636136256
[Epoch 11, Batch 1100] loss: 0.02070975627164444
[Epoch 11, Batch 1200] loss: 0.014034123812307371
[Epoch 11, Batch 1300] loss: 0.016692193022008722
[Epoch 11, Batch 1400] loss: 0.02419379917821061
[Epoch 11, Batch 1500] loss: 0.027476533772714903
[Epoch 11, Batch 1600] loss: 0.022565717046090866
[Epoch 11, Batch 1700] loss: 0.03457511199887449
[Epoch 11, Batch 1800] loss: 0.01996910690664663
**STATS for Epoch 11** : 
Average training loss: 0.0014
Average validation loss: 0.0670
Validation Accuracy: 0.9811
Overfitting: 0.0657
[Epoch 12, Batch 100] loss: 0.016578984064908583
[Epoch 12, Batch 200] loss: 0.016272973868472037
[Epoch 12, Batch 300] loss: 0.010572599517436174
[Epoch 12, Batch 400] loss: 0.012374487666438654
[Epoch 12, Batch 500] loss: 0.024957900178033014
[Epoch 12, Batch 600] loss: 0.011920083793916092
[Epoch 12, Batch 700] loss: 0.013059470140269695
[Epoch 12, Batch 800] loss: 0.012088485605547704
[Epoch 12, Batch 900] loss: 0.008918703024037314
[Epoch 12, Batch 1000] loss: 0.014040440245971696
[Epoch 12, Batch 1100] loss: 0.01504380486449918
[Epoch 12, Batch 1200] loss: 0.012910185300934246
[Epoch 12, Batch 1300] loss: 0.02133846364200508
[Epoch 12, Batch 1400] loss: 0.013197010227595457
[Epoch 12, Batch 1500] loss: 0.021460767189819308
[Epoch 12, Batch 1600] loss: 0.03401599957373037
[Epoch 12, Batch 1700] loss: 0.01701303151457978
[Epoch 12, Batch 1800] loss: 0.013894072965395026
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0618
Validation Accuracy: 0.9829
Overfitting: 0.0610
[Epoch 13, Batch 100] loss: 0.009803313375796279
[Epoch 13, Batch 200] loss: 0.014294160014178487
[Epoch 13, Batch 300] loss: 0.011016787001581178
[Epoch 13, Batch 400] loss: 0.00888242589217043
[Epoch 13, Batch 500] loss: 0.012893260253204062
[Epoch 13, Batch 600] loss: 0.013992230746680434
[Epoch 13, Batch 700] loss: 0.011402086654270534
[Epoch 13, Batch 800] loss: 0.011157476974271958
[Epoch 13, Batch 900] loss: 0.013770390979716466
[Epoch 13, Batch 1000] loss: 0.015226883531495332
[Epoch 13, Batch 1100] loss: 0.015164816975343456
[Epoch 13, Batch 1200] loss: 0.015590767376943404
[Epoch 13, Batch 1300] loss: 0.008205748243199196
[Epoch 13, Batch 1400] loss: 0.01099774705400705
[Epoch 13, Batch 1500] loss: 0.009514796923667745
[Epoch 13, Batch 1600] loss: 0.020544187401019372
[Epoch 13, Batch 1700] loss: 0.008419357201692037
[Epoch 13, Batch 1800] loss: 0.03049733876983737
**STATS for Epoch 13** : 
Average training loss: 0.0012
Average validation loss: 0.0590
Validation Accuracy: 0.9841
Overfitting: 0.0578
[Epoch 14, Batch 100] loss: 0.01652809232147774
[Epoch 14, Batch 200] loss: 0.012753811238835623
[Epoch 14, Batch 300] loss: 0.012662746510804936
[Epoch 14, Batch 400] loss: 0.009398865550210758
[Epoch 14, Batch 500] loss: 0.007464493262232281
[Epoch 14, Batch 600] loss: 0.01131046482470083
[Epoch 14, Batch 700] loss: 0.011480687567882342
[Epoch 14, Batch 800] loss: 0.012973871075937496
[Epoch 14, Batch 900] loss: 0.014950281924811862
[Epoch 14, Batch 1000] loss: 0.019587640727950204
[Epoch 14, Batch 1100] loss: 0.00913435016049334
[Epoch 14, Batch 1200] loss: 0.011456568418434471
[Epoch 14, Batch 1300] loss: 0.006902978642701782
[Epoch 14, Batch 1400] loss: 0.013928640072865619
[Epoch 14, Batch 1500] loss: 0.009836175176733377
[Epoch 14, Batch 1600] loss: 0.027157572427336164
[Epoch 14, Batch 1700] loss: 0.009431424767244607
[Epoch 14, Batch 1800] loss: 0.016907316259462277
**STATS for Epoch 14** : 
Average training loss: 0.0003
Average validation loss: 0.0578
Validation Accuracy: 0.9851
Overfitting: 0.0575
[Epoch 15, Batch 100] loss: 0.00810721866345375
[Epoch 15, Batch 200] loss: 0.00865599850727449
[Epoch 15, Batch 300] loss: 0.01257534519228102
[Epoch 15, Batch 400] loss: 0.011757731080506347
[Epoch 15, Batch 500] loss: 0.01504871994617133
[Epoch 15, Batch 600] loss: 0.014349234399987835
[Epoch 15, Batch 700] loss: 0.015119358928859582
[Epoch 15, Batch 800] loss: 0.008538210182568945
[Epoch 15, Batch 900] loss: 0.008452295626580054
[Epoch 15, Batch 1000] loss: 0.007242843465362512
[Epoch 15, Batch 1100] loss: 0.018542530067134067
[Epoch 15, Batch 1200] loss: 0.008515675555731832
[Epoch 15, Batch 1300] loss: 0.005172036780768394
[Epoch 15, Batch 1400] loss: 0.014443023146891392
[Epoch 15, Batch 1500] loss: 0.011811237524425451
[Epoch 15, Batch 1600] loss: 0.006735563435668155
[Epoch 15, Batch 1700] loss: 0.009689880067280682
[Epoch 15, Batch 1800] loss: 0.011013647648160258
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0654
Validation Accuracy: 0.9838
Overfitting: 0.0650
[Epoch 16, Batch 100] loss: 0.005446797269516992
[Epoch 16, Batch 200] loss: 0.015651111893521374
[Epoch 16, Batch 300] loss: 0.005194373362010083
[Epoch 16, Batch 400] loss: 0.0031518030506686046
[Epoch 16, Batch 500] loss: 0.008085404103762812
[Epoch 16, Batch 600] loss: 0.009088374382336041
[Epoch 16, Batch 700] loss: 0.011983633693389492
[Epoch 16, Batch 800] loss: 0.008941866040408968
[Epoch 16, Batch 900] loss: 0.005609548939628439
[Epoch 16, Batch 1000] loss: 0.009900874331117393
[Epoch 16, Batch 1100] loss: 0.005938819780558333
[Epoch 16, Batch 1200] loss: 0.021565614385993966
[Epoch 16, Batch 1300] loss: 0.01651877318663992
[Epoch 16, Batch 1400] loss: 0.014597410343085357
[Epoch 16, Batch 1500] loss: 0.006004123941020225
[Epoch 16, Batch 1600] loss: 0.009770097422806429
[Epoch 16, Batch 1700] loss: 0.015459857699519262
[Epoch 16, Batch 1800] loss: 0.01374295918378266
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0615
Validation Accuracy: 0.9854
Overfitting: 0.0611
[Epoch 17, Batch 100] loss: 0.00640944945337651
[Epoch 17, Batch 200] loss: 0.00666964139271613
[Epoch 17, Batch 300] loss: 0.014209670862805978
[Epoch 17, Batch 400] loss: 0.007645631380223676
[Epoch 17, Batch 500] loss: 0.01314073554596689
[Epoch 17, Batch 600] loss: 0.011983246565259833
[Epoch 17, Batch 700] loss: 0.005859717789289789
[Epoch 17, Batch 800] loss: 0.004392727812164594
[Epoch 17, Batch 900] loss: 0.011077388766645982
[Epoch 17, Batch 1000] loss: 0.01286813106110003
[Epoch 17, Batch 1100] loss: 0.0046582580713970855
[Epoch 17, Batch 1200] loss: 0.006571460679469965
[Epoch 17, Batch 1300] loss: 0.005650996623744504
[Epoch 17, Batch 1400] loss: 0.00809037836186235
[Epoch 17, Batch 1500] loss: 0.006391449116927106
[Epoch 17, Batch 1600] loss: 0.012903245492743735
[Epoch 17, Batch 1700] loss: 0.0071705780124011655
[Epoch 17, Batch 1800] loss: 0.0046813937559727495
**STATS for Epoch 17** : 
Average training loss: 0.0002
Average validation loss: 0.0599
Validation Accuracy: 0.9856
Overfitting: 0.0596
[Epoch 18, Batch 100] loss: 0.006364118269257233
[Epoch 18, Batch 200] loss: 0.005935090785060311
[Epoch 18, Batch 300] loss: 0.004400969533032821
[Epoch 18, Batch 400] loss: 0.00421826221733113
[Epoch 18, Batch 500] loss: 0.006074109493827109
[Epoch 18, Batch 600] loss: 0.0035516822959334605
[Epoch 18, Batch 700] loss: 0.007739848521162003
[Epoch 18, Batch 800] loss: 0.011134076654968794
[Epoch 18, Batch 900] loss: 0.0075500807047274065
[Epoch 18, Batch 1000] loss: 0.006829707569334004
[Epoch 18, Batch 1100] loss: 0.009632668157182707
[Epoch 18, Batch 1200] loss: 0.007325968811683197
[Epoch 18, Batch 1300] loss: 0.004409759646147222
[Epoch 18, Batch 1400] loss: 0.0029754217867775878
[Epoch 18, Batch 1500] loss: 0.004920293688728634
[Epoch 18, Batch 1600] loss: 0.009104823249301716
[Epoch 18, Batch 1700] loss: 0.006234465971119789
[Epoch 18, Batch 1800] loss: 0.003192657725379604
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0586
Validation Accuracy: 0.9868
Overfitting: 0.0585
[Epoch 19, Batch 100] loss: 0.0013938796891966377
[Epoch 19, Batch 200] loss: 0.0021046154095029123
[Epoch 19, Batch 300] loss: 0.003460776506968841
[Epoch 19, Batch 400] loss: 0.0044727176596006755
[Epoch 19, Batch 500] loss: 0.002652567021173127
[Epoch 19, Batch 600] loss: 0.0029039256323721927
[Epoch 19, Batch 700] loss: 0.005953375890535426
[Epoch 19, Batch 800] loss: 0.002678180811792572
[Epoch 19, Batch 900] loss: 0.004715186538708167
[Epoch 19, Batch 1000] loss: 0.0037302982080905166
[Epoch 19, Batch 1100] loss: 0.0021986515529010832
[Epoch 19, Batch 1200] loss: 0.007249600778015975
[Epoch 19, Batch 1300] loss: 0.006029841957997633
[Epoch 19, Batch 1400] loss: 0.014880763486400496
[Epoch 19, Batch 1500] loss: 0.01269742880206195
[Epoch 19, Batch 1600] loss: 0.005039607669393717
[Epoch 19, Batch 1700] loss: 0.0018548188650401797
[Epoch 19, Batch 1800] loss: 0.001649533111250321
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0730
Validation Accuracy: 0.9841
Overfitting: 0.0728
[Epoch 20, Batch 100] loss: 0.006663131701851617
[Epoch 20, Batch 200] loss: 0.002795528071268336
[Epoch 20, Batch 300] loss: 0.006621821237024506
[Epoch 20, Batch 400] loss: 0.003375251207838801
[Epoch 20, Batch 500] loss: 0.007082534033447701
[Epoch 20, Batch 600] loss: 0.005093854690628632
[Epoch 20, Batch 700] loss: 0.005839349046881353
[Epoch 20, Batch 800] loss: 0.0024116082623629608
[Epoch 20, Batch 900] loss: 0.004098023352095197
[Epoch 20, Batch 1000] loss: 0.0042007969553222325
[Epoch 20, Batch 1100] loss: 0.002235882735263033
[Epoch 20, Batch 1200] loss: 0.0025841693823609544
[Epoch 20, Batch 1300] loss: 0.007807505414818366
[Epoch 20, Batch 1400] loss: 0.009756324148390262
[Epoch 20, Batch 1500] loss: 0.00590630522546121
[Epoch 20, Batch 1600] loss: 0.010986269405639177
[Epoch 20, Batch 1700] loss: 0.004056464952716396
[Epoch 20, Batch 1800] loss: 0.010625114074284738
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0651
Validation Accuracy: 0.9856
Overfitting: 0.0649
[Epoch 21, Batch 100] loss: 0.006423751427994375
[Epoch 21, Batch 200] loss: 0.0029370622551232375
[Epoch 21, Batch 300] loss: 0.003083450082178274
[Epoch 21, Batch 400] loss: 0.0012916232074593381
[Epoch 21, Batch 500] loss: 0.0028564499524327404
[Epoch 21, Batch 600] loss: 0.0018440307929927257
[Epoch 21, Batch 700] loss: 0.0022139824919702278
[Epoch 21, Batch 800] loss: 0.005865009088284978
[Epoch 21, Batch 900] loss: 0.0018745117893689666
[Epoch 21, Batch 1000] loss: 0.003638164707136866
[Epoch 21, Batch 1100] loss: 0.002866702144096962
[Epoch 21, Batch 1200] loss: 0.002643806130978419
[Epoch 21, Batch 1300] loss: 0.007018865145554969
[Epoch 21, Batch 1400] loss: 0.008134973394151075
[Epoch 21, Batch 1500] loss: 0.0020767322332727644
[Epoch 21, Batch 1600] loss: 0.0018768985354151368
[Epoch 21, Batch 1700] loss: 0.0022164928975666955
[Epoch 21, Batch 1800] loss: 0.0018027363574105947
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0639
Validation Accuracy: 0.9865
Overfitting: 0.0636
[Epoch 22, Batch 100] loss: 0.0033273522117605123
[Epoch 22, Batch 200] loss: 0.002044445155845551
[Epoch 22, Batch 300] loss: 0.0016938566594706117
[Epoch 22, Batch 400] loss: 0.00475267845644396
[Epoch 22, Batch 500] loss: 0.002367827044599835
[Epoch 22, Batch 600] loss: 0.000833082491700452
[Epoch 22, Batch 700] loss: 0.0014773687984671823
[Epoch 22, Batch 800] loss: 0.0017538317656135404
[Epoch 22, Batch 900] loss: 0.0035384405578011524
[Epoch 22, Batch 1000] loss: 0.0014416171457290261
[Epoch 22, Batch 1100] loss: 0.007550339123340564
[Epoch 22, Batch 1200] loss: 0.003956216625575167
[Epoch 22, Batch 1300] loss: 0.0023315590482684456
[Epoch 22, Batch 1400] loss: 0.0018015831336617794
[Epoch 22, Batch 1500] loss: 0.008341720474166436
[Epoch 22, Batch 1600] loss: 0.0022380437595893453
[Epoch 22, Batch 1700] loss: 0.0052221117577119
[Epoch 22, Batch 1800] loss: 0.006713886607078052
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0690
Validation Accuracy: 0.9860
Overfitting: 0.0689
[Epoch 23, Batch 100] loss: 0.005561157467281533
[Epoch 23, Batch 200] loss: 0.004788394703959966
[Epoch 23, Batch 300] loss: 0.004118586760566814
[Epoch 23, Batch 400] loss: 0.004359188267219451
[Epoch 23, Batch 500] loss: 0.0017404072648946568
[Epoch 23, Batch 600] loss: 0.004052080945376417
[Epoch 23, Batch 700] loss: 0.0036138920230575876
[Epoch 23, Batch 800] loss: 0.002423675848434641
[Epoch 23, Batch 900] loss: 0.0044085586404492005
[Epoch 23, Batch 1000] loss: 0.0030902530000679464
[Epoch 23, Batch 1100] loss: 0.0022958410846591806
[Epoch 23, Batch 1200] loss: 0.0015767081741612542
[Epoch 23, Batch 1300] loss: 0.000950970454707658
[Epoch 23, Batch 1400] loss: 0.0027836365502002993
[Epoch 23, Batch 1500] loss: 0.0020483203218745415
[Epoch 23, Batch 1600] loss: 0.0013798178822850104
[Epoch 23, Batch 1700] loss: 0.0030762674417172775
[Epoch 23, Batch 1800] loss: 0.0021386313040028426
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0680
Validation Accuracy: 0.9865
Overfitting: 0.0679
[Epoch 24, Batch 100] loss: 0.0012713158835998683
[Epoch 24, Batch 200] loss: 0.0010499666363793382
[Epoch 24, Batch 300] loss: 0.0010376386985694807
[Epoch 24, Batch 400] loss: 0.0005986775061903415
[Epoch 24, Batch 500] loss: 0.0007263877646290239
[Epoch 24, Batch 600] loss: 0.0007143998241369332
[Epoch 24, Batch 700] loss: 0.0016968522100352956
[Epoch 24, Batch 800] loss: 0.00301483425246424
[Epoch 24, Batch 900] loss: 0.004347098484739127
[Epoch 24, Batch 1000] loss: 0.0047731835855620375
[Epoch 24, Batch 1100] loss: 0.0034270499750653017
[Epoch 24, Batch 1200] loss: 0.001728051758752258
[Epoch 24, Batch 1300] loss: 0.0015589930224821557
[Epoch 24, Batch 1400] loss: 0.0013370665471758513
[Epoch 24, Batch 1500] loss: 0.003968876455352586
[Epoch 24, Batch 1600] loss: 0.001296249623684531
[Epoch 24, Batch 1700] loss: 0.0011792879111561661
[Epoch 24, Batch 1800] loss: 0.00257373381284566
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0704
Validation Accuracy: 0.9864
Overfitting: 0.0704
Fold 1 validation loss: 0.0704
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.290035135746002
[Epoch 1, Batch 200] loss: 2.1976584935188295
[Epoch 1, Batch 300] loss: 1.5942839252948762
[Epoch 1, Batch 400] loss: 0.7730677828192711
[Epoch 1, Batch 500] loss: 0.5775844161212444
[Epoch 1, Batch 600] loss: 0.44441275544464587
[Epoch 1, Batch 700] loss: 0.4075140383467078
[Epoch 1, Batch 800] loss: 0.3681586100533605
[Epoch 1, Batch 900] loss: 0.32138905581086874
[Epoch 1, Batch 1000] loss: 0.28735799800604583
[Epoch 1, Batch 1100] loss: 0.24300186777487398
[Epoch 1, Batch 1200] loss: 0.24868624735623598
[Epoch 1, Batch 1300] loss: 0.2530371190235019
[Epoch 1, Batch 1400] loss: 0.230708860270679
[Epoch 1, Batch 1500] loss: 0.22933986507356166
[Epoch 1, Batch 1600] loss: 0.20920697858557105
[Epoch 1, Batch 1700] loss: 0.17884165722876788
[Epoch 1, Batch 1800] loss: 0.19188552998006345
**STATS for Epoch 1** : 
Average training loss: 0.0079
Average validation loss: 0.1906
Validation Accuracy: 0.9386
Overfitting: 0.1826
Best model saved at epoch 1 with validation loss: 0.1906
[Epoch 2, Batch 100] loss: 0.15904987088404596
[Epoch 2, Batch 200] loss: 0.13404833321459592
[Epoch 2, Batch 300] loss: 0.15991575995460153
[Epoch 2, Batch 400] loss: 0.15300223048776387
[Epoch 2, Batch 500] loss: 0.14331139128655196
[Epoch 2, Batch 600] loss: 0.12834718747064472
[Epoch 2, Batch 700] loss: 0.15134192395024001
[Epoch 2, Batch 800] loss: 0.12486911043990404
[Epoch 2, Batch 900] loss: 0.11293563129846007
[Epoch 2, Batch 1000] loss: 0.12457703340332955
[Epoch 2, Batch 1100] loss: 0.11819070290541277
[Epoch 2, Batch 1200] loss: 0.10571153154596687
[Epoch 2, Batch 1300] loss: 0.10641746094450355
[Epoch 2, Batch 1400] loss: 0.10226898214779795
[Epoch 2, Batch 1500] loss: 0.11078779128845781
[Epoch 2, Batch 1600] loss: 0.11979047359898687
[Epoch 2, Batch 1700] loss: 0.11594829904846847
[Epoch 2, Batch 1800] loss: 0.08546904237708076
**STATS for Epoch 2** : 
Average training loss: 0.0047
Average validation loss: 0.1269
Validation Accuracy: 0.9605
Overfitting: 0.1222
Best model saved at epoch 2 with validation loss: 0.1269
[Epoch 3, Batch 100] loss: 0.1006131781032309
[Epoch 3, Batch 200] loss: 0.10076026601484045
[Epoch 3, Batch 300] loss: 0.0880727117578499
[Epoch 3, Batch 400] loss: 0.07628760461579077
[Epoch 3, Batch 500] loss: 0.10294518425595016
[Epoch 3, Batch 600] loss: 0.08118859141948633
[Epoch 3, Batch 700] loss: 0.08374141829903238
[Epoch 3, Batch 800] loss: 0.07789844973420258
[Epoch 3, Batch 900] loss: 0.08650132923154161
[Epoch 3, Batch 1000] loss: 0.07623513749567792
[Epoch 3, Batch 1100] loss: 0.0732171719498001
[Epoch 3, Batch 1200] loss: 0.11193206312600523
[Epoch 3, Batch 1300] loss: 0.07500605904962868
[Epoch 3, Batch 1400] loss: 0.0893701022863388
[Epoch 3, Batch 1500] loss: 0.07447979197138921
[Epoch 3, Batch 1600] loss: 0.08072830422664992
[Epoch 3, Batch 1700] loss: 0.0686289583076723
[Epoch 3, Batch 1800] loss: 0.07005956159788183
**STATS for Epoch 3** : 
Average training loss: 0.0023
Average validation loss: 0.0819
Validation Accuracy: 0.9750
Overfitting: 0.0796
Best model saved at epoch 3 with validation loss: 0.0819
[Epoch 4, Batch 100] loss: 0.06131301149027422
[Epoch 4, Batch 200] loss: 0.06073251597408671
[Epoch 4, Batch 300] loss: 0.07395823827246203
[Epoch 4, Batch 400] loss: 0.06436154583701864
[Epoch 4, Batch 500] loss: 0.0682059918466257
[Epoch 4, Batch 600] loss: 0.061340832299320025
[Epoch 4, Batch 700] loss: 0.06498783825954887
[Epoch 4, Batch 800] loss: 0.09166249003028497
[Epoch 4, Batch 900] loss: 0.05707303165749181
[Epoch 4, Batch 1000] loss: 0.06022844522842206
[Epoch 4, Batch 1100] loss: 0.07177313911204691
[Epoch 4, Batch 1200] loss: 0.057858228710247206
[Epoch 4, Batch 1300] loss: 0.07717284845479298
[Epoch 4, Batch 1400] loss: 0.07275288010860095
[Epoch 4, Batch 1500] loss: 0.0686969200836029
[Epoch 4, Batch 1600] loss: 0.0493050770170521
[Epoch 4, Batch 1700] loss: 0.06442303228541277
[Epoch 4, Batch 1800] loss: 0.06233283420791849
**STATS for Epoch 4** : 
Average training loss: 0.0024
Average validation loss: 0.0772
Validation Accuracy: 0.9761
Overfitting: 0.0748
Best model saved at epoch 4 with validation loss: 0.0772
[Epoch 5, Batch 100] loss: 0.058267634807125435
[Epoch 5, Batch 200] loss: 0.04861930646176916
[Epoch 5, Batch 300] loss: 0.045042552027734925
[Epoch 5, Batch 400] loss: 0.04512676242826274
[Epoch 5, Batch 500] loss: 0.05906411186297191
[Epoch 5, Batch 600] loss: 0.059815928989555685
[Epoch 5, Batch 700] loss: 0.047048864868120294
[Epoch 5, Batch 800] loss: 0.06724701704282779
[Epoch 5, Batch 900] loss: 0.05777222604956478
[Epoch 5, Batch 1000] loss: 0.0493501557566924
[Epoch 5, Batch 1100] loss: 0.06227065756043885
[Epoch 5, Batch 1200] loss: 0.059684896417311395
[Epoch 5, Batch 1300] loss: 0.044003279173048214
[Epoch 5, Batch 1400] loss: 0.061966438653180377
[Epoch 5, Batch 1500] loss: 0.054056189248804
[Epoch 5, Batch 1600] loss: 0.04907704683893826
[Epoch 5, Batch 1700] loss: 0.05621415730798617
[Epoch 5, Batch 1800] loss: 0.03910204958578106
**STATS for Epoch 5** : 
Average training loss: 0.0022
Average validation loss: 0.0728
Validation Accuracy: 0.9779
Overfitting: 0.0706
Best model saved at epoch 5 with validation loss: 0.0728
[Epoch 6, Batch 100] loss: 0.03637832755222917
[Epoch 6, Batch 200] loss: 0.03595050886040554
[Epoch 6, Batch 300] loss: 0.046142787946446336
[Epoch 6, Batch 400] loss: 0.05685843481187476
[Epoch 6, Batch 500] loss: 0.04432825801472063
[Epoch 6, Batch 600] loss: 0.043627532679965955
[Epoch 6, Batch 700] loss: 0.04075208484355244
[Epoch 6, Batch 800] loss: 0.051396672816190404
[Epoch 6, Batch 900] loss: 0.051024924006778744
[Epoch 6, Batch 1000] loss: 0.04964812722580973
[Epoch 6, Batch 1100] loss: 0.03086704536777688
[Epoch 6, Batch 1200] loss: 0.04546018119639484
[Epoch 6, Batch 1300] loss: 0.05625433614099165
[Epoch 6, Batch 1400] loss: 0.03847392192896223
[Epoch 6, Batch 1500] loss: 0.058001456753117964
[Epoch 6, Batch 1600] loss: 0.043008612940320746
[Epoch 6, Batch 1700] loss: 0.04703288268472534
[Epoch 6, Batch 1800] loss: 0.039231491305399685
**STATS for Epoch 6** : 
Average training loss: 0.0011
Average validation loss: 0.0689
Validation Accuracy: 0.9795
Overfitting: 0.0677
Best model saved at epoch 6 with validation loss: 0.0689
[Epoch 7, Batch 100] loss: 0.02879642675325158
[Epoch 7, Batch 200] loss: 0.040523884793146864
[Epoch 7, Batch 300] loss: 0.042631452206260294
[Epoch 7, Batch 400] loss: 0.042473631854954876
[Epoch 7, Batch 500] loss: 0.050759177685686156
[Epoch 7, Batch 600] loss: 0.03325257481541485
[Epoch 7, Batch 700] loss: 0.036330891788820735
[Epoch 7, Batch 800] loss: 0.04030864497413859
[Epoch 7, Batch 900] loss: 0.01995592045415833
[Epoch 7, Batch 1000] loss: 0.0471475690677471
[Epoch 7, Batch 1100] loss: 0.0347438767721178
[Epoch 7, Batch 1200] loss: 0.03025496852795186
[Epoch 7, Batch 1300] loss: 0.055495785556558985
[Epoch 7, Batch 1400] loss: 0.031045156914042308
[Epoch 7, Batch 1500] loss: 0.03185690334881656
[Epoch 7, Batch 1600] loss: 0.03922150560771115
[Epoch 7, Batch 1700] loss: 0.03579066523074289
[Epoch 7, Batch 1800] loss: 0.048447560344357044
**STATS for Epoch 7** : 
Average training loss: 0.0019
Average validation loss: 0.0695
Validation Accuracy: 0.9779
Overfitting: 0.0676
[Epoch 8, Batch 100] loss: 0.030941779795248293
[Epoch 8, Batch 200] loss: 0.026344905796140666
[Epoch 8, Batch 300] loss: 0.03855986128502991
[Epoch 8, Batch 400] loss: 0.03232012968495837
[Epoch 8, Batch 500] loss: 0.03194373745966004
[Epoch 8, Batch 600] loss: 0.028266146329406182
[Epoch 8, Batch 700] loss: 0.03584713952310267
[Epoch 8, Batch 800] loss: 0.04163844766517286
[Epoch 8, Batch 900] loss: 0.02291017291441676
[Epoch 8, Batch 1000] loss: 0.04000364291874575
[Epoch 8, Batch 1100] loss: 0.03164183699802379
[Epoch 8, Batch 1200] loss: 0.038855275140231245
[Epoch 8, Batch 1300] loss: 0.03512865766635514
[Epoch 8, Batch 1400] loss: 0.0385779304584139
[Epoch 8, Batch 1500] loss: 0.028387782363279258
[Epoch 8, Batch 1600] loss: 0.019179845376966112
[Epoch 8, Batch 1700] loss: 0.028406544635508908
[Epoch 8, Batch 1800] loss: 0.042907420183219074
**STATS for Epoch 8** : 
Average training loss: 0.0022
Average validation loss: 0.0585
Validation Accuracy: 0.9820
Overfitting: 0.0563
Best model saved at epoch 8 with validation loss: 0.0585
[Epoch 9, Batch 100] loss: 0.03397938677066122
[Epoch 9, Batch 200] loss: 0.018619686950551113
[Epoch 9, Batch 300] loss: 0.03678507455260842
[Epoch 9, Batch 400] loss: 0.025589465992234182
[Epoch 9, Batch 500] loss: 0.03458501130946388
[Epoch 9, Batch 600] loss: 0.03848613977781497
[Epoch 9, Batch 700] loss: 0.030191484049209974
[Epoch 9, Batch 800] loss: 0.023815700064114934
[Epoch 9, Batch 900] loss: 0.015800577459885973
[Epoch 9, Batch 1000] loss: 0.030899680320435437
[Epoch 9, Batch 1100] loss: 0.02202147185413196
[Epoch 9, Batch 1200] loss: 0.03289931477702339
[Epoch 9, Batch 1300] loss: 0.04821449285813287
[Epoch 9, Batch 1400] loss: 0.02323659737754497
[Epoch 9, Batch 1500] loss: 0.03169596126390388
[Epoch 9, Batch 1600] loss: 0.026445845801281394
[Epoch 9, Batch 1700] loss: 0.024395825527790294
[Epoch 9, Batch 1800] loss: 0.02023988077802642
**STATS for Epoch 9** : 
Average training loss: 0.0010
Average validation loss: 0.0684
Validation Accuracy: 0.9802
Overfitting: 0.0675
[Epoch 10, Batch 100] loss: 0.020657819742700666
[Epoch 10, Batch 200] loss: 0.01442834167057299
[Epoch 10, Batch 300] loss: 0.0158575015399947
[Epoch 10, Batch 400] loss: 0.016757154450024247
[Epoch 10, Batch 500] loss: 0.014106011335825315
[Epoch 10, Batch 600] loss: 0.01203579511904536
[Epoch 10, Batch 700] loss: 0.02679806043583085
[Epoch 10, Batch 800] loss: 0.01584890366633772
[Epoch 10, Batch 900] loss: 0.027541499524941174
[Epoch 10, Batch 1000] loss: 0.03107558452167723
[Epoch 10, Batch 1100] loss: 0.026770390848323587
[Epoch 10, Batch 1200] loss: 0.035164502392944996
[Epoch 10, Batch 1300] loss: 0.017904993783540702
[Epoch 10, Batch 1400] loss: 0.02369712888092181
[Epoch 10, Batch 1500] loss: 0.03680969402372284
[Epoch 10, Batch 1600] loss: 0.03341888253526122
[Epoch 10, Batch 1700] loss: 0.024850821865748003
[Epoch 10, Batch 1800] loss: 0.029649959117814432
**STATS for Epoch 10** : 
Average training loss: 0.0020
Average validation loss: 0.0568
Validation Accuracy: 0.9838
Overfitting: 0.0548
Best model saved at epoch 10 with validation loss: 0.0568
[Epoch 11, Batch 100] loss: 0.0249770646734396
[Epoch 11, Batch 200] loss: 0.01148542187831481
[Epoch 11, Batch 300] loss: 0.019683708305019535
[Epoch 11, Batch 400] loss: 0.019524130533245625
[Epoch 11, Batch 500] loss: 0.02238992881597369
[Epoch 11, Batch 600] loss: 0.016050330791340457
[Epoch 11, Batch 700] loss: 0.02484915968934729
[Epoch 11, Batch 800] loss: 0.022159986015758477
[Epoch 11, Batch 900] loss: 0.02416060437062697
[Epoch 11, Batch 1000] loss: 0.019387952139768457
[Epoch 11, Batch 1100] loss: 0.0182632091607411
[Epoch 11, Batch 1200] loss: 0.028982060656844624
[Epoch 11, Batch 1300] loss: 0.014157537552746362
[Epoch 11, Batch 1400] loss: 0.029591508204066485
[Epoch 11, Batch 1500] loss: 0.03207955615915125
[Epoch 11, Batch 1600] loss: 0.012927978445368353
[Epoch 11, Batch 1700] loss: 0.025603373143858334
[Epoch 11, Batch 1800] loss: 0.02501442262182536
**STATS for Epoch 11** : 
Average training loss: 0.0012
Average validation loss: 0.0604
Validation Accuracy: 0.9827
Overfitting: 0.0593
[Epoch 12, Batch 100] loss: 0.012024548349327233
[Epoch 12, Batch 200] loss: 0.014816690528241451
[Epoch 12, Batch 300] loss: 0.017628470657527942
[Epoch 12, Batch 400] loss: 0.018960357657379065
[Epoch 12, Batch 500] loss: 0.008447672844304178
[Epoch 12, Batch 600] loss: 0.014472343846164222
[Epoch 12, Batch 700] loss: 0.012747988864903163
[Epoch 12, Batch 800] loss: 0.010144794652715063
[Epoch 12, Batch 900] loss: 0.016798706048284658
[Epoch 12, Batch 1000] loss: 0.02582329042512356
[Epoch 12, Batch 1100] loss: 0.023503090715703365
[Epoch 12, Batch 1200] loss: 0.019149697364427995
[Epoch 12, Batch 1300] loss: 0.019940051728099206
[Epoch 12, Batch 1400] loss: 0.020360955565338373
[Epoch 12, Batch 1500] loss: 0.02960629148525186
[Epoch 12, Batch 1600] loss: 0.01822950782447151
[Epoch 12, Batch 1700] loss: 0.014908440791750764
[Epoch 12, Batch 1800] loss: 0.034145482207459284
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0540
Validation Accuracy: 0.9848
Overfitting: 0.0530
Best model saved at epoch 12 with validation loss: 0.0540
[Epoch 13, Batch 100] loss: 0.02114939395294641
[Epoch 13, Batch 200] loss: 0.014500187978846953
[Epoch 13, Batch 300] loss: 0.008522452228644397
[Epoch 13, Batch 400] loss: 0.015927756791552384
[Epoch 13, Batch 500] loss: 0.009300204399187351
[Epoch 13, Batch 600] loss: 0.009739555475307497
[Epoch 13, Batch 700] loss: 0.02201626287576801
[Epoch 13, Batch 800] loss: 0.014851624282364355
[Epoch 13, Batch 900] loss: 0.011471872004131
[Epoch 13, Batch 1000] loss: 0.007784813469097571
[Epoch 13, Batch 1100] loss: 0.01913517735994901
[Epoch 13, Batch 1200] loss: 0.014673345981527745
[Epoch 13, Batch 1300] loss: 0.010863280113826477
[Epoch 13, Batch 1400] loss: 0.012551918209683209
[Epoch 13, Batch 1500] loss: 0.02414682642036496
[Epoch 13, Batch 1600] loss: 0.03404527133963711
[Epoch 13, Batch 1700] loss: 0.013725527105161745
[Epoch 13, Batch 1800] loss: 0.012090508668197799
**STATS for Epoch 13** : 
Average training loss: 0.0010
Average validation loss: 0.0524
Validation Accuracy: 0.9857
Overfitting: 0.0514
Best model saved at epoch 13 with validation loss: 0.0524
[Epoch 14, Batch 100] loss: 0.016402334567501384
[Epoch 14, Batch 200] loss: 0.012017169658379316
[Epoch 14, Batch 300] loss: 0.007084764544442805
[Epoch 14, Batch 400] loss: 0.005867639292664535
[Epoch 14, Batch 500] loss: 0.010369564876345976
[Epoch 14, Batch 600] loss: 0.009948104629606859
[Epoch 14, Batch 700] loss: 0.013232428037913451
[Epoch 14, Batch 800] loss: 0.014109046494013455
[Epoch 14, Batch 900] loss: 0.015404756442721919
[Epoch 14, Batch 1000] loss: 0.008812259962824101
[Epoch 14, Batch 1100] loss: 0.012879721495896774
[Epoch 14, Batch 1200] loss: 0.012900919146013622
[Epoch 14, Batch 1300] loss: 0.011023651233381315
[Epoch 14, Batch 1400] loss: 0.008288138239247473
[Epoch 14, Batch 1500] loss: 0.04073706248381313
[Epoch 14, Batch 1600] loss: 0.029341981218567525
[Epoch 14, Batch 1700] loss: 0.024455672283947932
[Epoch 14, Batch 1800] loss: 0.018441568160669705
**STATS for Epoch 14** : 
Average training loss: 0.0005
Average validation loss: 0.0555
Validation Accuracy: 0.9853
Overfitting: 0.0550
[Epoch 15, Batch 100] loss: 0.007010609456629026
[Epoch 15, Batch 200] loss: 0.013997952291392722
[Epoch 15, Batch 300] loss: 0.00989588968129283
[Epoch 15, Batch 400] loss: 0.008099312115264183
[Epoch 15, Batch 500] loss: 0.008060715830879417
[Epoch 15, Batch 600] loss: 0.014261849735589749
[Epoch 15, Batch 700] loss: 0.016014400383628526
[Epoch 15, Batch 800] loss: 0.011845637483415885
[Epoch 15, Batch 900] loss: 0.013075023939254606
[Epoch 15, Batch 1000] loss: 0.00937141360050191
[Epoch 15, Batch 1100] loss: 0.011946101526766596
[Epoch 15, Batch 1200] loss: 0.004807316080937199
[Epoch 15, Batch 1300] loss: 0.007412871011108563
[Epoch 15, Batch 1400] loss: 0.017420118550298867
[Epoch 15, Batch 1500] loss: 0.00829788458837811
[Epoch 15, Batch 1600] loss: 0.008098156508747251
[Epoch 15, Batch 1700] loss: 0.019366313428386094
[Epoch 15, Batch 1800] loss: 0.018209637310492327
**STATS for Epoch 15** : 
Average training loss: 0.0005
Average validation loss: 0.0588
Validation Accuracy: 0.9848
Overfitting: 0.0582
[Epoch 16, Batch 100] loss: 0.011792274862928024
[Epoch 16, Batch 200] loss: 0.006560258001691181
[Epoch 16, Batch 300] loss: 0.00948529533764031
[Epoch 16, Batch 400] loss: 0.004902756611388667
[Epoch 16, Batch 500] loss: 0.006920231105618768
[Epoch 16, Batch 600] loss: 0.010775162386862576
[Epoch 16, Batch 700] loss: 0.00598953741869991
[Epoch 16, Batch 800] loss: 0.01137667885234805
[Epoch 16, Batch 900] loss: 0.013700355870005296
[Epoch 16, Batch 1000] loss: 0.00930356235624913
[Epoch 16, Batch 1100] loss: 0.006381286206654409
[Epoch 16, Batch 1200] loss: 0.014516166427042662
[Epoch 16, Batch 1300] loss: 0.007612373869337716
[Epoch 16, Batch 1400] loss: 0.009327756640432198
[Epoch 16, Batch 1500] loss: 0.014557849237521623
[Epoch 16, Batch 1600] loss: 0.015137836324747696
[Epoch 16, Batch 1700] loss: 0.01130855404408976
[Epoch 16, Batch 1800] loss: 0.011476034814295417
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0758
Validation Accuracy: 0.9806
Overfitting: 0.0751
[Epoch 17, Batch 100] loss: 0.007322397844618535
[Epoch 17, Batch 200] loss: 0.006390923213939459
[Epoch 17, Batch 300] loss: 0.00750436081177213
[Epoch 17, Batch 400] loss: 0.004935252401273829
[Epoch 17, Batch 500] loss: 0.008003305050215204
[Epoch 17, Batch 600] loss: 0.0073689843924830715
[Epoch 17, Batch 700] loss: 0.004634102506598197
[Epoch 17, Batch 800] loss: 0.007975549922998653
[Epoch 17, Batch 900] loss: 0.0072803936373702525
[Epoch 17, Batch 1000] loss: 0.007462745796830177
[Epoch 17, Batch 1100] loss: 0.008470101405500828
[Epoch 17, Batch 1200] loss: 0.010019964876671566
[Epoch 17, Batch 1300] loss: 0.007148374438246492
[Epoch 17, Batch 1400] loss: 0.005517798071147126
[Epoch 17, Batch 1500] loss: 0.00659271260751666
[Epoch 17, Batch 1600] loss: 0.005845195037738904
[Epoch 17, Batch 1700] loss: 0.009291279499286702
[Epoch 17, Batch 1800] loss: 0.010068230956995307
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0593
Validation Accuracy: 0.9859
Overfitting: 0.0589
[Epoch 18, Batch 100] loss: 0.00593117156649896
[Epoch 18, Batch 200] loss: 0.0032694266327212063
[Epoch 18, Batch 300] loss: 0.010554435301812645
[Epoch 18, Batch 400] loss: 0.013686094864278858
[Epoch 18, Batch 500] loss: 0.006554266577016961
[Epoch 18, Batch 600] loss: 0.009455758262903942
[Epoch 18, Batch 700] loss: 0.009332118160137383
[Epoch 18, Batch 800] loss: 0.006556349337040501
[Epoch 18, Batch 900] loss: 0.0070468644112452235
[Epoch 18, Batch 1000] loss: 0.004691459474785944
[Epoch 18, Batch 1100] loss: 0.002739550235137358
[Epoch 18, Batch 1200] loss: 0.00471758835136825
[Epoch 18, Batch 1300] loss: 0.011175759480273655
[Epoch 18, Batch 1400] loss: 0.006789207742477856
[Epoch 18, Batch 1500] loss: 0.007637306052471331
[Epoch 18, Batch 1600] loss: 0.006859297828054878
[Epoch 18, Batch 1700] loss: 0.00781466049024857
[Epoch 18, Batch 1800] loss: 0.00948735979562116
**STATS for Epoch 18** : 
Average training loss: 0.0004
Average validation loss: 0.0686
Validation Accuracy: 0.9837
Overfitting: 0.0682
[Epoch 19, Batch 100] loss: 0.007357954288249857
[Epoch 19, Batch 200] loss: 0.004191610890532047
[Epoch 19, Batch 300] loss: 0.005081252073946416
[Epoch 19, Batch 400] loss: 0.0060805959297670145
[Epoch 19, Batch 500] loss: 0.014355447528296282
[Epoch 19, Batch 600] loss: 0.006441935482816916
[Epoch 19, Batch 700] loss: 0.0029747194233550544
[Epoch 19, Batch 800] loss: 0.004898641519250759
[Epoch 19, Batch 900] loss: 0.007808070567627965
[Epoch 19, Batch 1000] loss: 0.008265303486728043
[Epoch 19, Batch 1100] loss: 0.0037932344491269985
[Epoch 19, Batch 1200] loss: 0.005601274039411237
[Epoch 19, Batch 1300] loss: 0.005698398910949436
[Epoch 19, Batch 1400] loss: 0.013559016557475162
[Epoch 19, Batch 1500] loss: 0.011779474225186277
[Epoch 19, Batch 1600] loss: 0.007770767991846696
[Epoch 19, Batch 1700] loss: 0.007344353877963386
[Epoch 19, Batch 1800] loss: 0.004442248449594217
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0621
Validation Accuracy: 0.9856
Overfitting: 0.0619
[Epoch 20, Batch 100] loss: 0.005209877124242439
[Epoch 20, Batch 200] loss: 0.0020640548788162503
[Epoch 20, Batch 300] loss: 0.0017708700796117683
[Epoch 20, Batch 400] loss: 0.0029694482977932067
[Epoch 20, Batch 500] loss: 0.0015850684437043582
[Epoch 20, Batch 600] loss: 0.0019494479912805218
[Epoch 20, Batch 700] loss: 0.004005982218392887
[Epoch 20, Batch 800] loss: 0.0015084684634450697
[Epoch 20, Batch 900] loss: 0.0066248097688878715
[Epoch 20, Batch 1000] loss: 0.0035367661586815304
[Epoch 20, Batch 1100] loss: 0.007222199369957707
[Epoch 20, Batch 1200] loss: 0.007966490265430934
[Epoch 20, Batch 1300] loss: 0.005741760539977463
[Epoch 20, Batch 1400] loss: 0.00821846705790449
[Epoch 20, Batch 1500] loss: 0.005457349861688385
[Epoch 20, Batch 1600] loss: 0.009673586909927962
[Epoch 20, Batch 1700] loss: 0.011638192234236157
[Epoch 20, Batch 1800] loss: 0.009251806817733268
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0618
Validation Accuracy: 0.9863
Overfitting: 0.0616
[Epoch 21, Batch 100] loss: 0.0030741025808015366
[Epoch 21, Batch 200] loss: 0.002339251537290181
[Epoch 21, Batch 300] loss: 0.003946373472563991
[Epoch 21, Batch 400] loss: 0.0033564032862068416
[Epoch 21, Batch 500] loss: 0.004550387091929835
[Epoch 21, Batch 600] loss: 0.0036475362980263526
[Epoch 21, Batch 700] loss: 0.0009211444023446802
[Epoch 21, Batch 800] loss: 0.0015955193960326141
[Epoch 21, Batch 900] loss: 0.0023369604143414335
[Epoch 21, Batch 1000] loss: 0.005932074497183564
[Epoch 21, Batch 1100] loss: 0.0027210904080419594
[Epoch 21, Batch 1200] loss: 0.003178415112008537
[Epoch 21, Batch 1300] loss: 0.004417068767358856
[Epoch 21, Batch 1400] loss: 0.005063236425467608
[Epoch 21, Batch 1500] loss: 0.0016248816832870007
[Epoch 21, Batch 1600] loss: 0.0020922787840558497
[Epoch 21, Batch 1700] loss: 0.0034686742280950968
[Epoch 21, Batch 1800] loss: 0.005936314510865372
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0740
Validation Accuracy: 0.9839
Overfitting: 0.0737
[Epoch 22, Batch 100] loss: 0.01567634096290817
[Epoch 22, Batch 200] loss: 0.0022417895710725587
[Epoch 22, Batch 300] loss: 0.002309243371503271
[Epoch 22, Batch 400] loss: 0.003447039416695361
[Epoch 22, Batch 500] loss: 0.000977017164612164
[Epoch 22, Batch 600] loss: 0.0012972561954262573
[Epoch 22, Batch 700] loss: 0.002765479646101596
[Epoch 22, Batch 800] loss: 0.0018853639347605267
[Epoch 22, Batch 900] loss: 0.002364773836529821
[Epoch 22, Batch 1000] loss: 0.0026395953412237817
[Epoch 22, Batch 1100] loss: 0.0037796589657244617
[Epoch 22, Batch 1200] loss: 0.006091337008745086
[Epoch 22, Batch 1300] loss: 0.00378422216704962
[Epoch 22, Batch 1400] loss: 0.005162048700079254
[Epoch 22, Batch 1500] loss: 0.006374072651879885
[Epoch 22, Batch 1600] loss: 0.0026366279023957873
[Epoch 22, Batch 1700] loss: 0.0022241503046085145
[Epoch 22, Batch 1800] loss: 0.006613943680756478
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0651
Validation Accuracy: 0.9861
Overfitting: 0.0648
[Epoch 23, Batch 100] loss: 0.0023627697941674343
[Epoch 23, Batch 200] loss: 0.0059836919663763056
[Epoch 23, Batch 300] loss: 0.017338751646528792
[Epoch 23, Batch 400] loss: 0.004573740946043472
[Epoch 23, Batch 500] loss: 0.0017415251222081451
[Epoch 23, Batch 600] loss: 0.0034897516280882
[Epoch 23, Batch 700] loss: 0.002966529936711595
[Epoch 23, Batch 800] loss: 0.005828793028230592
[Epoch 23, Batch 900] loss: 0.006847214209068966
[Epoch 23, Batch 1000] loss: 0.0008345580873502456
[Epoch 23, Batch 1100] loss: 0.007143861685991269
[Epoch 23, Batch 1200] loss: 0.008822798743903206
[Epoch 23, Batch 1300] loss: 0.002617244682109572
[Epoch 23, Batch 1400] loss: 0.00625102228862005
[Epoch 23, Batch 1500] loss: 0.006917417550006348
[Epoch 23, Batch 1600] loss: 0.002602619037720615
[Epoch 23, Batch 1700] loss: 0.004794605015193838
[Epoch 23, Batch 1800] loss: 0.009456548118231467
**STATS for Epoch 23** : 
Average training loss: 0.0004
Average validation loss: 0.0681
Validation Accuracy: 0.9853
Overfitting: 0.0677
[Epoch 24, Batch 100] loss: 0.00933049200792766
[Epoch 24, Batch 200] loss: 0.0014098359220565725
[Epoch 24, Batch 300] loss: 0.0010639969105761793
[Epoch 24, Batch 400] loss: 0.0014890040011848527
[Epoch 24, Batch 500] loss: 0.00206930873050311
[Epoch 24, Batch 600] loss: 0.0014319139226319066
[Epoch 24, Batch 700] loss: 0.00523572942431656
[Epoch 24, Batch 800] loss: 0.00436710773579847
[Epoch 24, Batch 900] loss: 0.0034648949826133445
[Epoch 24, Batch 1000] loss: 0.004964766351284595
[Epoch 24, Batch 1100] loss: 0.0054146892442537365
[Epoch 24, Batch 1200] loss: 0.00457169169722583
[Epoch 24, Batch 1300] loss: 0.0016807120928521613
[Epoch 24, Batch 1400] loss: 0.0022909506864002083
[Epoch 24, Batch 1500] loss: 0.007296012965240379
[Epoch 24, Batch 1600] loss: 0.0024965910892093745
[Epoch 24, Batch 1700] loss: 0.0013528321564209023
[Epoch 24, Batch 1800] loss: 0.0014417168406622239
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0671
Validation Accuracy: 0.9860
Overfitting: 0.0669
Fold 2 validation loss: 0.0671
Mean validation loss across all folds for Trial 7 is 0.0688 with trial config:  l1: 128, l2: 128, lr: 0.0012025975346676469, batch_size: 16
[I 2024-11-25 15:56:50,789] Trial 6 finished with value: 0.06877959452315303 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0012025975346676469, 'batch_size': 16}. Best is trial 2 with value: 0.06046210698719751.

Selected Hyperparameters for Trial 8:
  l1: 256, l2: 64, lr: 0.0040894420414321975, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.195406827926636
**STATS for Epoch 1** : 
Average training loss: 0.2003
Average validation loss: 0.9209
Validation Accuracy: 0.7473
Overfitting: 0.7207
Best model saved at epoch 1 with validation loss: 0.9209
[Epoch 2, Batch 100] loss: 0.503514524102211
**STATS for Epoch 2** : 
Average training loss: 0.0522
Average validation loss: 0.3157
Validation Accuracy: 0.9049
Overfitting: 0.2635
Best model saved at epoch 2 with validation loss: 0.3157
[Epoch 3, Batch 100] loss: 0.2693017116189003
**STATS for Epoch 3** : 
Average training loss: 0.0305
Average validation loss: 0.2023
Validation Accuracy: 0.9389
Overfitting: 0.1718
Best model saved at epoch 3 with validation loss: 0.2023
[Epoch 4, Batch 100] loss: 0.18790029093623162
**STATS for Epoch 4** : 
Average training loss: 0.0233
Average validation loss: 0.1531
Validation Accuracy: 0.9529
Overfitting: 0.1297
Best model saved at epoch 4 with validation loss: 0.1531
[Epoch 5, Batch 100] loss: 0.1368924570083618
**STATS for Epoch 5** : 
Average training loss: 0.0228
Average validation loss: 0.1388
Validation Accuracy: 0.9571
Overfitting: 0.1160
Best model saved at epoch 5 with validation loss: 0.1388
[Epoch 6, Batch 100] loss: 0.11498829215765
**STATS for Epoch 6** : 
Average training loss: 0.0210
Average validation loss: 0.1436
Validation Accuracy: 0.9561
Overfitting: 0.1225
[Epoch 7, Batch 100] loss: 0.10147094868123531
**STATS for Epoch 7** : 
Average training loss: 0.0148
Average validation loss: 0.1110
Validation Accuracy: 0.9648
Overfitting: 0.0962
Best model saved at epoch 7 with validation loss: 0.1110
[Epoch 8, Batch 100] loss: 0.08916865222156048
**STATS for Epoch 8** : 
Average training loss: 0.0134
Average validation loss: 0.0894
Validation Accuracy: 0.9724
Overfitting: 0.0760
Best model saved at epoch 8 with validation loss: 0.0894
[Epoch 9, Batch 100] loss: 0.08038138542324305
**STATS for Epoch 9** : 
Average training loss: 0.0110
Average validation loss: 0.0976
Validation Accuracy: 0.9685
Overfitting: 0.0866
[Epoch 10, Batch 100] loss: 0.07337075447663664
**STATS for Epoch 10** : 
Average training loss: 0.0125
Average validation loss: 0.0854
Validation Accuracy: 0.9739
Overfitting: 0.0728
Best model saved at epoch 10 with validation loss: 0.0854
[Epoch 11, Batch 100] loss: 0.06426423586905003
**STATS for Epoch 11** : 
Average training loss: 0.0118
Average validation loss: 0.0806
Validation Accuracy: 0.9755
Overfitting: 0.0688
Best model saved at epoch 11 with validation loss: 0.0806
[Epoch 12, Batch 100] loss: 0.06155221110209823
**STATS for Epoch 12** : 
Average training loss: 0.0099
Average validation loss: 0.0698
Validation Accuracy: 0.9788
Overfitting: 0.0599
Best model saved at epoch 12 with validation loss: 0.0698
[Epoch 13, Batch 100] loss: 0.05676054835319519
**STATS for Epoch 13** : 
Average training loss: 0.0093
Average validation loss: 0.0782
Validation Accuracy: 0.9757
Overfitting: 0.0689
[Epoch 14, Batch 100] loss: 0.05174691710621118
**STATS for Epoch 14** : 
Average training loss: 0.0084
Average validation loss: 0.0715
Validation Accuracy: 0.9786
Overfitting: 0.0631
[Epoch 15, Batch 100] loss: 0.04970353480428457
**STATS for Epoch 15** : 
Average training loss: 0.0076
Average validation loss: 0.0704
Validation Accuracy: 0.9788
Overfitting: 0.0628
[Epoch 16, Batch 100] loss: 0.04596399829722941
**STATS for Epoch 16** : 
Average training loss: 0.0066
Average validation loss: 0.0690
Validation Accuracy: 0.9791
Overfitting: 0.0623
Best model saved at epoch 16 with validation loss: 0.0690
[Epoch 17, Batch 100] loss: 0.042581214429810645
**STATS for Epoch 17** : 
Average training loss: 0.0059
Average validation loss: 0.0647
Validation Accuracy: 0.9812
Overfitting: 0.0588
Best model saved at epoch 17 with validation loss: 0.0647
[Epoch 18, Batch 100] loss: 0.04136352310888469
**STATS for Epoch 18** : 
Average training loss: 0.0067
Average validation loss: 0.0613
Validation Accuracy: 0.9819
Overfitting: 0.0546
Best model saved at epoch 18 with validation loss: 0.0613
[Epoch 19, Batch 100] loss: 0.0409722051396966
**STATS for Epoch 19** : 
Average training loss: 0.0054
Average validation loss: 0.0691
Validation Accuracy: 0.9783
Overfitting: 0.0637
[Epoch 20, Batch 100] loss: 0.03477647923864424
**STATS for Epoch 20** : 
Average training loss: 0.0060
Average validation loss: 0.0611
Validation Accuracy: 0.9821
Overfitting: 0.0551
Best model saved at epoch 20 with validation loss: 0.0611
[Epoch 21, Batch 100] loss: 0.03436358504462987
**STATS for Epoch 21** : 
Average training loss: 0.0055
Average validation loss: 0.0608
Validation Accuracy: 0.9824
Overfitting: 0.0553
Best model saved at epoch 21 with validation loss: 0.0608
[Epoch 22, Batch 100] loss: 0.031136670988053082
**STATS for Epoch 22** : 
Average training loss: 0.0042
Average validation loss: 0.0561
Validation Accuracy: 0.9841
Overfitting: 0.0518
Best model saved at epoch 22 with validation loss: 0.0561
[Epoch 23, Batch 100] loss: 0.02823147430084646
**STATS for Epoch 23** : 
Average training loss: 0.0042
Average validation loss: 0.0555
Validation Accuracy: 0.9835
Overfitting: 0.0513
Best model saved at epoch 23 with validation loss: 0.0555
[Epoch 24, Batch 100] loss: 0.025856193015351893
**STATS for Epoch 24** : 
Average training loss: 0.0050
Average validation loss: 0.0559
Validation Accuracy: 0.9837
Overfitting: 0.0509
Fold 1 validation loss: 0.0559
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.289110200405121
**STATS for Epoch 1** : 
Average training loss: 0.3415
Average validation loss: 2.2144
Validation Accuracy: 0.5079
Overfitting: 1.8730
Best model saved at epoch 1 with validation loss: 2.2144
[Epoch 2, Batch 100] loss: 1.278138816654682
**STATS for Epoch 2** : 
Average training loss: 0.0667
Average validation loss: 0.4021
Validation Accuracy: 0.8737
Overfitting: 0.3353
Best model saved at epoch 2 with validation loss: 0.4021
[Epoch 3, Batch 100] loss: 0.2929230970144272
**STATS for Epoch 3** : 
Average training loss: 0.0326
Average validation loss: 0.2375
Validation Accuracy: 0.9286
Overfitting: 0.2049
Best model saved at epoch 3 with validation loss: 0.2375
[Epoch 4, Batch 100] loss: 0.19299998097121715
**STATS for Epoch 4** : 
Average training loss: 0.0274
Average validation loss: 0.1690
Validation Accuracy: 0.9486
Overfitting: 0.1416
Best model saved at epoch 4 with validation loss: 0.1690
[Epoch 5, Batch 100] loss: 0.14821277901530266
**STATS for Epoch 5** : 
Average training loss: 0.0217
Average validation loss: 0.1626
Validation Accuracy: 0.9509
Overfitting: 0.1410
Best model saved at epoch 5 with validation loss: 0.1626
[Epoch 6, Batch 100] loss: 0.1253458784893155
**STATS for Epoch 6** : 
Average training loss: 0.0192
Average validation loss: 0.1373
Validation Accuracy: 0.9590
Overfitting: 0.1181
Best model saved at epoch 6 with validation loss: 0.1373
[Epoch 7, Batch 100] loss: 0.10559497527778149
**STATS for Epoch 7** : 
Average training loss: 0.0178
Average validation loss: 0.1017
Validation Accuracy: 0.9696
Overfitting: 0.0839
Best model saved at epoch 7 with validation loss: 0.1017
[Epoch 8, Batch 100] loss: 0.09344198729842901
**STATS for Epoch 8** : 
Average training loss: 0.0142
Average validation loss: 0.1177
Validation Accuracy: 0.9653
Overfitting: 0.1035
[Epoch 9, Batch 100] loss: 0.09060369662940503
**STATS for Epoch 9** : 
Average training loss: 0.0118
Average validation loss: 0.0867
Validation Accuracy: 0.9743
Overfitting: 0.0748
Best model saved at epoch 9 with validation loss: 0.0867
[Epoch 10, Batch 100] loss: 0.07694082845002413
**STATS for Epoch 10** : 
Average training loss: 0.0119
Average validation loss: 0.0875
Validation Accuracy: 0.9741
Overfitting: 0.0756
[Epoch 11, Batch 100] loss: 0.07507023628801107
**STATS for Epoch 11** : 
Average training loss: 0.0113
Average validation loss: 0.0845
Validation Accuracy: 0.9754
Overfitting: 0.0732
Best model saved at epoch 11 with validation loss: 0.0845
[Epoch 12, Batch 100] loss: 0.06541421493515372
**STATS for Epoch 12** : 
Average training loss: 0.0091
Average validation loss: 0.0759
Validation Accuracy: 0.9784
Overfitting: 0.0669
Best model saved at epoch 12 with validation loss: 0.0759
[Epoch 13, Batch 100] loss: 0.05935506006702781
**STATS for Epoch 13** : 
Average training loss: 0.0111
Average validation loss: 0.0761
Validation Accuracy: 0.9775
Overfitting: 0.0650
[Epoch 14, Batch 100] loss: 0.0588617111183703
**STATS for Epoch 14** : 
Average training loss: 0.0101
Average validation loss: 0.0742
Validation Accuracy: 0.9778
Overfitting: 0.0641
Best model saved at epoch 14 with validation loss: 0.0742
[Epoch 15, Batch 100] loss: 0.057200816301628946
**STATS for Epoch 15** : 
Average training loss: 0.0074
Average validation loss: 0.0684
Validation Accuracy: 0.9791
Overfitting: 0.0610
Best model saved at epoch 15 with validation loss: 0.0684
[Epoch 16, Batch 100] loss: 0.049799082204699516
**STATS for Epoch 16** : 
Average training loss: 0.0075
Average validation loss: 0.0645
Validation Accuracy: 0.9811
Overfitting: 0.0571
Best model saved at epoch 16 with validation loss: 0.0645
[Epoch 17, Batch 100] loss: 0.04544996201992035
**STATS for Epoch 17** : 
Average training loss: 0.0078
Average validation loss: 0.0721
Validation Accuracy: 0.9781
Overfitting: 0.0644
[Epoch 18, Batch 100] loss: 0.043991194711998104
**STATS for Epoch 18** : 
Average training loss: 0.0065
Average validation loss: 0.0619
Validation Accuracy: 0.9817
Overfitting: 0.0554
Best model saved at epoch 18 with validation loss: 0.0619
[Epoch 19, Batch 100] loss: 0.040550933573395016
**STATS for Epoch 19** : 
Average training loss: 0.0067
Average validation loss: 0.0601
Validation Accuracy: 0.9827
Overfitting: 0.0534
Best model saved at epoch 19 with validation loss: 0.0601
[Epoch 20, Batch 100] loss: 0.03841305735521019
**STATS for Epoch 20** : 
Average training loss: 0.0062
Average validation loss: 0.0617
Validation Accuracy: 0.9823
Overfitting: 0.0555
[Epoch 21, Batch 100] loss: 0.03991387760266662
**STATS for Epoch 21** : 
Average training loss: 0.0049
Average validation loss: 0.0585
Validation Accuracy: 0.9832
Overfitting: 0.0536
Best model saved at epoch 21 with validation loss: 0.0585
[Epoch 22, Batch 100] loss: 0.0357864429987967
**STATS for Epoch 22** : 
Average training loss: 0.0057
Average validation loss: 0.0635
Validation Accuracy: 0.9819
Overfitting: 0.0578
[Epoch 23, Batch 100] loss: 0.03538536810316145
**STATS for Epoch 23** : 
Average training loss: 0.0058
Average validation loss: 0.0618
Validation Accuracy: 0.9820
Overfitting: 0.0560
[Epoch 24, Batch 100] loss: 0.034078437685966495
**STATS for Epoch 24** : 
Average training loss: 0.0037
Average validation loss: 0.0606
Validation Accuracy: 0.9825
Overfitting: 0.0570
Fold 2 validation loss: 0.0606
Mean validation loss across all folds for Trial 8 is 0.0582 with trial config:  l1: 256, l2: 64, lr: 0.0040894420414321975, batch_size: 256
[I 2024-11-25 16:05:04,296] Trial 7 finished with value: 0.0582443055690866 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0040894420414321975, 'batch_size': 256}. Best is trial 7 with value: 0.0582443055690866.

Selected Hyperparameters for Trial 9:
  l1: 256, l2: 64, lr: 0.030204972267161442, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.0515741589665413
**STATS for Epoch 1** : 
Average training loss: 0.0271
Average validation loss: 0.1639
Validation Accuracy: 0.9466
Overfitting: 0.1368
Best model saved at epoch 1 with validation loss: 0.1639
[Epoch 2, Batch 100] loss: 0.11607268594205379
**STATS for Epoch 2** : 
Average training loss: 0.0146
Average validation loss: 0.0956
Validation Accuracy: 0.9715
Overfitting: 0.0810
Best model saved at epoch 2 with validation loss: 0.0956
[Epoch 3, Batch 100] loss: 0.071761973220855
**STATS for Epoch 3** : 
Average training loss: 0.0118
Average validation loss: 0.0678
Validation Accuracy: 0.9790
Overfitting: 0.0559
Best model saved at epoch 3 with validation loss: 0.0678
[Epoch 4, Batch 100] loss: 0.05178387359715998
**STATS for Epoch 4** : 
Average training loss: 0.0085
Average validation loss: 0.0726
Validation Accuracy: 0.9778
Overfitting: 0.0641
[Epoch 5, Batch 100] loss: 0.0420554309990257
**STATS for Epoch 5** : 
Average training loss: 0.0068
Average validation loss: 0.0679
Validation Accuracy: 0.9799
Overfitting: 0.0612
[Epoch 6, Batch 100] loss: 0.03341953148599714
**STATS for Epoch 6** : 
Average training loss: 0.0043
Average validation loss: 0.0642
Validation Accuracy: 0.9801
Overfitting: 0.0600
Best model saved at epoch 6 with validation loss: 0.0642
[Epoch 7, Batch 100] loss: 0.027210796694271268
**STATS for Epoch 7** : 
Average training loss: 0.0063
Average validation loss: 0.0622
Validation Accuracy: 0.9817
Overfitting: 0.0559
Best model saved at epoch 7 with validation loss: 0.0622
[Epoch 8, Batch 100] loss: 0.031397497297730295
**STATS for Epoch 8** : 
Average training loss: 0.0038
Average validation loss: 0.0506
Validation Accuracy: 0.9856
Overfitting: 0.0467
Best model saved at epoch 8 with validation loss: 0.0506
[Epoch 9, Batch 100] loss: 0.019501521566417067
**STATS for Epoch 9** : 
Average training loss: 0.0023
Average validation loss: 0.0572
Validation Accuracy: 0.9846
Overfitting: 0.0549
[Epoch 10, Batch 100] loss: 0.015310656846268103
**STATS for Epoch 10** : 
Average training loss: 0.0021
Average validation loss: 0.0567
Validation Accuracy: 0.9850
Overfitting: 0.0546
[Epoch 11, Batch 100] loss: 0.011821399249020032
**STATS for Epoch 11** : 
Average training loss: 0.0022
Average validation loss: 0.0614
Validation Accuracy: 0.9845
Overfitting: 0.0592
[Epoch 12, Batch 100] loss: 0.017740127928555012
**STATS for Epoch 12** : 
Average training loss: 0.0020
Average validation loss: 0.0639
Validation Accuracy: 0.9831
Overfitting: 0.0619
[Epoch 13, Batch 100] loss: 0.011713944700313733
**STATS for Epoch 13** : 
Average training loss: 0.0019
Average validation loss: 0.0656
Validation Accuracy: 0.9846
Overfitting: 0.0637
[Epoch 14, Batch 100] loss: 0.008928870111121796
**STATS for Epoch 14** : 
Average training loss: 0.0013
Average validation loss: 0.0627
Validation Accuracy: 0.9846
Overfitting: 0.0613
[Epoch 15, Batch 100] loss: 0.006629955541866366
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0606
Validation Accuracy: 0.9858
Overfitting: 0.0597
[Epoch 16, Batch 100] loss: 0.004319302589137806
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0581
Validation Accuracy: 0.9868
Overfitting: 0.0573
[Epoch 17, Batch 100] loss: 0.004147806095934356
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0581
Validation Accuracy: 0.9873
Overfitting: 0.0578
[Epoch 18, Batch 100] loss: 0.003980905930220615
**STATS for Epoch 18** : 
Average training loss: 0.0009
Average validation loss: 0.0726
Validation Accuracy: 0.9849
Overfitting: 0.0717
[Epoch 19, Batch 100] loss: 0.0027390862327592914
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0628
Validation Accuracy: 0.9872
Overfitting: 0.0623
[Epoch 20, Batch 100] loss: 0.0023860527727447333
**STATS for Epoch 20** : 
Average training loss: 0.0003
Average validation loss: 0.0615
Validation Accuracy: 0.9866
Overfitting: 0.0612
[Epoch 21, Batch 100] loss: 0.0013291748470874154
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0624
Validation Accuracy: 0.9877
Overfitting: 0.0621
[Epoch 22, Batch 100] loss: 0.0004930873843113658
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0633
Validation Accuracy: 0.9879
Overfitting: 0.0633
[Epoch 23, Batch 100] loss: 0.0004218361975290463
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0642
Validation Accuracy: 0.9878
Overfitting: 0.0642
[Epoch 24, Batch 100] loss: 0.00033804053238782215
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0658
Validation Accuracy: 0.9877
Overfitting: 0.0658
Fold 1 validation loss: 0.0658
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.1317535892128945
**STATS for Epoch 1** : 
Average training loss: 0.0302
Average validation loss: 0.1788
Validation Accuracy: 0.9461
Overfitting: 0.1487
Best model saved at epoch 1 with validation loss: 0.1788
[Epoch 2, Batch 100] loss: 0.13193252831697463
**STATS for Epoch 2** : 
Average training loss: 0.0151
Average validation loss: 0.1027
Validation Accuracy: 0.9673
Overfitting: 0.0876
Best model saved at epoch 2 with validation loss: 0.1027
[Epoch 3, Batch 100] loss: 0.07835516557097436
**STATS for Epoch 3** : 
Average training loss: 0.0114
Average validation loss: 0.0732
Validation Accuracy: 0.9776
Overfitting: 0.0619
Best model saved at epoch 3 with validation loss: 0.0732
[Epoch 4, Batch 100] loss: 0.06314682594500481
**STATS for Epoch 4** : 
Average training loss: 0.0101
Average validation loss: 0.0677
Validation Accuracy: 0.9795
Overfitting: 0.0576
Best model saved at epoch 4 with validation loss: 0.0677
[Epoch 5, Batch 100] loss: 0.046832792488858105
**STATS for Epoch 5** : 
Average training loss: 0.0064
Average validation loss: 0.0576
Validation Accuracy: 0.9826
Overfitting: 0.0512
Best model saved at epoch 5 with validation loss: 0.0576
[Epoch 6, Batch 100] loss: 0.03662577911280095
**STATS for Epoch 6** : 
Average training loss: 0.0056
Average validation loss: 0.0671
Validation Accuracy: 0.9813
Overfitting: 0.0616
[Epoch 7, Batch 100] loss: 0.03227300956845283
**STATS for Epoch 7** : 
Average training loss: 0.0056
Average validation loss: 0.0614
Validation Accuracy: 0.9818
Overfitting: 0.0558
[Epoch 8, Batch 100] loss: 0.026070246882736684
**STATS for Epoch 8** : 
Average training loss: 0.0063
Average validation loss: 0.0663
Validation Accuracy: 0.9806
Overfitting: 0.0600
[Epoch 9, Batch 100] loss: 0.02342034557135776
**STATS for Epoch 9** : 
Average training loss: 0.0026
Average validation loss: 0.0581
Validation Accuracy: 0.9846
Overfitting: 0.0554
[Epoch 10, Batch 100] loss: 0.020656269332394003
**STATS for Epoch 10** : 
Average training loss: 0.0026
Average validation loss: 0.0571
Validation Accuracy: 0.9842
Overfitting: 0.0545
Best model saved at epoch 10 with validation loss: 0.0571
[Epoch 11, Batch 100] loss: 0.017141135351266712
**STATS for Epoch 11** : 
Average training loss: 0.0024
Average validation loss: 0.0581
Validation Accuracy: 0.9845
Overfitting: 0.0557
[Epoch 12, Batch 100] loss: 0.012916371921310201
**STATS for Epoch 12** : 
Average training loss: 0.0022
Average validation loss: 0.0550
Validation Accuracy: 0.9854
Overfitting: 0.0528
Best model saved at epoch 12 with validation loss: 0.0550
[Epoch 13, Batch 100] loss: 0.008586732176481746
**STATS for Epoch 13** : 
Average training loss: 0.0018
Average validation loss: 0.0655
Validation Accuracy: 0.9837
Overfitting: 0.0637
[Epoch 14, Batch 100] loss: 0.007660093268495985
**STATS for Epoch 14** : 
Average training loss: 0.0010
Average validation loss: 0.0645
Validation Accuracy: 0.9850
Overfitting: 0.0635
[Epoch 15, Batch 100] loss: 0.006655139902723022
**STATS for Epoch 15** : 
Average training loss: 0.0019
Average validation loss: 0.0666
Validation Accuracy: 0.9841
Overfitting: 0.0646
[Epoch 16, Batch 100] loss: 0.010637639269698412
**STATS for Epoch 16** : 
Average training loss: 0.0011
Average validation loss: 0.0602
Validation Accuracy: 0.9853
Overfitting: 0.0592
[Epoch 17, Batch 100] loss: 0.004918201059044804
**STATS for Epoch 17** : 
Average training loss: 0.0012
Average validation loss: 0.0670
Validation Accuracy: 0.9843
Overfitting: 0.0658
[Epoch 18, Batch 100] loss: 0.004697173674940131
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0667
Validation Accuracy: 0.9859
Overfitting: 0.0659
[Epoch 19, Batch 100] loss: 0.0023925025569769788
**STATS for Epoch 19** : 
Average training loss: 0.0009
Average validation loss: 0.0675
Validation Accuracy: 0.9850
Overfitting: 0.0665
[Epoch 20, Batch 100] loss: 0.0023881515188259074
**STATS for Epoch 20** : 
Average training loss: 0.0001
Average validation loss: 0.0674
Validation Accuracy: 0.9862
Overfitting: 0.0673
[Epoch 21, Batch 100] loss: 0.0012066529005096526
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0685
Validation Accuracy: 0.9865
Overfitting: 0.0684
[Epoch 22, Batch 100] loss: 0.0006300346020725556
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0713
Validation Accuracy: 0.9859
Overfitting: 0.0712
[Epoch 23, Batch 100] loss: 0.0006613307571205951
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0716
Validation Accuracy: 0.9861
Overfitting: 0.0715
[Epoch 24, Batch 100] loss: 0.0004878755044774152
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0759
Validation Accuracy: 0.9859
Overfitting: 0.0758
Fold 2 validation loss: 0.0759
Mean validation loss across all folds for Trial 9 is 0.0708 with trial config:  l1: 256, l2: 64, lr: 0.030204972267161442, batch_size: 256
[I 2024-11-25 16:13:18,253] Trial 8 finished with value: 0.07084149351486319 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.030204972267161442, 'batch_size': 256}. Best is trial 7 with value: 0.0582443055690866.

Selected Hyperparameters for Trial 10:
  l1: 256, l2: 64, lr: 0.0006967315855877383, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3012780499458314
**STATS for Epoch 1** : 
Average training loss: 0.3497
Average validation loss: 2.2913
Validation Accuracy: 0.1216
Overfitting: 1.9416
Best model saved at epoch 1 with validation loss: 2.2913
[Epoch 2, Batch 100] loss: 2.283317201137543
**STATS for Epoch 2** : 
Average training loss: 0.3461
Average validation loss: 2.2670
Validation Accuracy: 0.2488
Overfitting: 1.9209
Best model saved at epoch 2 with validation loss: 2.2670
[Epoch 3, Batch 100] loss: 2.2462898206710817
**STATS for Epoch 3** : 
Average training loss: 0.3370
Average validation loss: 2.1985
Validation Accuracy: 0.4557
Overfitting: 1.8615
Best model saved at epoch 3 with validation loss: 2.1985
[Epoch 4, Batch 100] loss: 2.1080062448978425
**STATS for Epoch 4** : 
Average training loss: 0.2922
Average validation loss: 1.8481
Validation Accuracy: 0.6434
Overfitting: 1.5559
Best model saved at epoch 4 with validation loss: 1.8481
[Epoch 5, Batch 100] loss: 1.3813366103172302
**STATS for Epoch 5** : 
Average training loss: 0.1289
Average validation loss: 0.8052
Validation Accuracy: 0.7860
Overfitting: 0.6763
Best model saved at epoch 5 with validation loss: 0.8052
[Epoch 6, Batch 100] loss: 0.6599369841814041
**STATS for Epoch 6** : 
Average training loss: 0.0849
Average validation loss: 0.5280
Validation Accuracy: 0.8482
Overfitting: 0.4430
[I 2024-11-25 16:14:23,067] Trial 9 pruned. 

Selected Hyperparameters for Trial 11:
  l1: 256, l2: 128, lr: 0.016137610321187143, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.260883174687624
[Epoch 1, Batch 200] loss: 0.2260370710864663
[Epoch 1, Batch 300] loss: 0.16016475412994624
[Epoch 1, Batch 400] loss: 0.11996415006462485
**STATS for Epoch 1** : 
Average training loss: 0.0161
Average validation loss: 0.1169
Validation Accuracy: 0.9630
Overfitting: 0.1008
Best model saved at epoch 1 with validation loss: 0.1169
[Epoch 2, Batch 100] loss: 0.09155823342502117
[Epoch 2, Batch 200] loss: 0.09369260933250188
[Epoch 2, Batch 300] loss: 0.08023496340028942
[Epoch 2, Batch 400] loss: 0.06034056423697621
**STATS for Epoch 2** : 
Average training loss: 0.0093
Average validation loss: 0.0841
Validation Accuracy: 0.9744
Overfitting: 0.0748
Best model saved at epoch 2 with validation loss: 0.0841
[Epoch 3, Batch 100] loss: 0.05448442726628855
[Epoch 3, Batch 200] loss: 0.046585308579960835
[Epoch 3, Batch 300] loss: 0.05388040835736319
[Epoch 3, Batch 400] loss: 0.055306346289580685
**STATS for Epoch 3** : 
Average training loss: 0.0065
Average validation loss: 0.0889
Validation Accuracy: 0.9726
Overfitting: 0.0824
[Epoch 4, Batch 100] loss: 0.0351509040716337
[Epoch 4, Batch 200] loss: 0.04354695569491014
[Epoch 4, Batch 300] loss: 0.033412677145679484
[Epoch 4, Batch 400] loss: 0.05146798390545882
**STATS for Epoch 4** : 
Average training loss: 0.0060
Average validation loss: 0.0727
Validation Accuracy: 0.9784
Overfitting: 0.0667
Best model saved at epoch 4 with validation loss: 0.0727
[Epoch 5, Batch 100] loss: 0.024353299005888403
[Epoch 5, Batch 200] loss: 0.03246269936760655
[Epoch 5, Batch 300] loss: 0.03029226826824015
[Epoch 5, Batch 400] loss: 0.026429247980122455
**STATS for Epoch 5** : 
Average training loss: 0.0042
Average validation loss: 0.0587
Validation Accuracy: 0.9834
Overfitting: 0.0545
Best model saved at epoch 5 with validation loss: 0.0587
[Epoch 6, Batch 100] loss: 0.016495807210449128
[Epoch 6, Batch 200] loss: 0.020660988510935566
[Epoch 6, Batch 300] loss: 0.031441788935335356
[Epoch 6, Batch 400] loss: 0.02409951115230797
**STATS for Epoch 6** : 
Average training loss: 0.0046
Average validation loss: 0.0494
Validation Accuracy: 0.9852
Overfitting: 0.0449
Best model saved at epoch 6 with validation loss: 0.0494
[Epoch 7, Batch 100] loss: 0.017171362879598747
[Epoch 7, Batch 200] loss: 0.016728188921988477
[Epoch 7, Batch 300] loss: 0.016976458637946053
[Epoch 7, Batch 400] loss: 0.024717566986510064
**STATS for Epoch 7** : 
Average training loss: 0.0034
Average validation loss: 0.0795
Validation Accuracy: 0.9804
Overfitting: 0.0761
[Epoch 8, Batch 100] loss: 0.016017886348927278
[Epoch 8, Batch 200] loss: 0.020356293076329166
[Epoch 8, Batch 300] loss: 0.013575678793276893
[Epoch 8, Batch 400] loss: 0.019118401911364345
**STATS for Epoch 8** : 
Average training loss: 0.0024
Average validation loss: 0.0538
Validation Accuracy: 0.9849
Overfitting: 0.0514
[Epoch 9, Batch 100] loss: 0.010260574042913504
[Epoch 9, Batch 200] loss: 0.014060029738466255
[Epoch 9, Batch 300] loss: 0.014124017554440798
[Epoch 9, Batch 400] loss: 0.015153409957638359
**STATS for Epoch 9** : 
Average training loss: 0.0024
Average validation loss: 0.0628
Validation Accuracy: 0.9833
Overfitting: 0.0604
[Epoch 10, Batch 100] loss: 0.0155553489715021
[Epoch 10, Batch 200] loss: 0.012311523723692517
[Epoch 10, Batch 300] loss: 0.014980237470008434
[Epoch 10, Batch 400] loss: 0.01754140053104493
**STATS for Epoch 10** : 
Average training loss: 0.0024
Average validation loss: 0.0595
Validation Accuracy: 0.9851
Overfitting: 0.0570
[Epoch 11, Batch 100] loss: 0.007750399662254495
[Epoch 11, Batch 200] loss: 0.004035943195585787
[Epoch 11, Batch 300] loss: 0.01013540506118261
[Epoch 11, Batch 400] loss: 0.013745612174534471
**STATS for Epoch 11** : 
Average training loss: 0.0017
Average validation loss: 0.0629
Validation Accuracy: 0.9855
Overfitting: 0.0612
[Epoch 12, Batch 100] loss: 0.014438445247069467
[Epoch 12, Batch 200] loss: 0.007446679865952319
[Epoch 12, Batch 300] loss: 0.008747029180558457
[Epoch 12, Batch 400] loss: 0.013774443927140965
**STATS for Epoch 12** : 
Average training loss: 0.0022
Average validation loss: 0.0727
Validation Accuracy: 0.9834
Overfitting: 0.0706
[Epoch 13, Batch 100] loss: 0.012825617790585966
[Epoch 13, Batch 200] loss: 0.00920048645125462
[Epoch 13, Batch 300] loss: 0.011800669862241193
[Epoch 13, Batch 400] loss: 0.01196660915670691
**STATS for Epoch 13** : 
Average training loss: 0.0017
Average validation loss: 0.0651
Validation Accuracy: 0.9848
Overfitting: 0.0634
[Epoch 14, Batch 100] loss: 0.01020530965166472
[Epoch 14, Batch 200] loss: 0.009486501579303877
[Epoch 14, Batch 300] loss: 0.005806651618813703
[Epoch 14, Batch 400] loss: 0.014927948135255064
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0589
Validation Accuracy: 0.9857
Overfitting: 0.0581
[Epoch 15, Batch 100] loss: 0.013811270548376341
[Epoch 15, Batch 200] loss: 0.01009242195108527
[Epoch 15, Batch 300] loss: 0.009710564703664205
[Epoch 15, Batch 400] loss: 0.004887652615998377
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0554
Validation Accuracy: 0.9870
Overfitting: 0.0547
[Epoch 16, Batch 100] loss: 0.003241370588955306
[Epoch 16, Batch 200] loss: 0.001496072239001478
[Epoch 16, Batch 300] loss: 0.004153955805049918
[Epoch 16, Batch 400] loss: 0.009332535712296704
**STATS for Epoch 16** : 
Average training loss: 0.0014
Average validation loss: 0.0820
Validation Accuracy: 0.9824
Overfitting: 0.0806
[Epoch 17, Batch 100] loss: 0.013935625545327639
[Epoch 17, Batch 200] loss: 0.008701106132684799
[Epoch 17, Batch 300] loss: 0.004206416197810085
[Epoch 17, Batch 400] loss: 0.007211446400469867
**STATS for Epoch 17** : 
Average training loss: 0.0008
Average validation loss: 0.0618
Validation Accuracy: 0.9868
Overfitting: 0.0610
[Epoch 18, Batch 100] loss: 0.003722898361052103
[Epoch 18, Batch 200] loss: 0.0021836285050494553
[Epoch 18, Batch 300] loss: 0.0009291569637684915
[Epoch 18, Batch 400] loss: 0.0011652753143937388
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0633
Validation Accuracy: 0.9879
Overfitting: 0.0632
[Epoch 19, Batch 100] loss: 0.00037231642886524695
[Epoch 19, Batch 200] loss: 0.00025342512665019965
[Epoch 19, Batch 300] loss: 0.0001395244843370591
[Epoch 19, Batch 400] loss: 0.0004327578026845913
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0623
Validation Accuracy: 0.9884
Overfitting: 0.0622
[Epoch 20, Batch 100] loss: 0.0003811961932234453
[Epoch 20, Batch 200] loss: 0.0002625555930376322
[Epoch 20, Batch 300] loss: 0.00036663314819975314
[Epoch 20, Batch 400] loss: 0.00019176405698473787
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0645
Validation Accuracy: 0.9884
Overfitting: 0.0644
[Epoch 21, Batch 100] loss: 0.0001614498934455355
[Epoch 21, Batch 200] loss: 7.674984489597136e-05
[Epoch 21, Batch 300] loss: 0.00012266285536512102
[Epoch 21, Batch 400] loss: 7.418009419900784e-05
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0645
Validation Accuracy: 0.9886
Overfitting: 0.0645
[Epoch 22, Batch 100] loss: 4.186764116269615e-05
[Epoch 22, Batch 200] loss: 4.169070524692842e-05
[Epoch 22, Batch 300] loss: 5.266072472963401e-05
[Epoch 22, Batch 400] loss: 8.83949729937683e-05
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0647
Validation Accuracy: 0.9886
Overfitting: 0.0647
[Epoch 23, Batch 100] loss: 4.3942046856342286e-05
[Epoch 23, Batch 200] loss: 5.1483954137410135e-05
[Epoch 23, Batch 300] loss: 4.986532079882977e-05
[Epoch 23, Batch 400] loss: 2.8542254381056508e-05
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0655
Validation Accuracy: 0.9886
Overfitting: 0.0655
[Epoch 24, Batch 100] loss: 4.102618012126413e-05
[Epoch 24, Batch 200] loss: 3.990616303923389e-05
[Epoch 24, Batch 300] loss: 3.9500427887730894e-05
[Epoch 24, Batch 400] loss: 3.884168369893359e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0662
Validation Accuracy: 0.9886
Overfitting: 0.0662
Fold 1 validation loss: 0.0662
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.21253933057189
[Epoch 1, Batch 200] loss: 0.24107416708022356
[Epoch 1, Batch 300] loss: 0.1434863371029496
[Epoch 1, Batch 400] loss: 0.11924649808555841
**STATS for Epoch 1** : 
Average training loss: 0.0159
Average validation loss: 0.1028
Validation Accuracy: 0.9683
Overfitting: 0.0869
Best model saved at epoch 1 with validation loss: 0.1028
[Epoch 2, Batch 100] loss: 0.08182710741646587
[Epoch 2, Batch 200] loss: 0.08465126515831799
[Epoch 2, Batch 300] loss: 0.07451320218853652
[Epoch 2, Batch 400] loss: 0.07067998087033629
**STATS for Epoch 2** : 
Average training loss: 0.0097
Average validation loss: 0.0719
Validation Accuracy: 0.9784
Overfitting: 0.0622
Best model saved at epoch 2 with validation loss: 0.0719
[Epoch 3, Batch 100] loss: 0.05868831464787945
[Epoch 3, Batch 200] loss: 0.05025049277581275
[Epoch 3, Batch 300] loss: 0.05825238112360239
[Epoch 3, Batch 400] loss: 0.05216371285030618
**STATS for Epoch 3** : 
Average training loss: 0.0078
Average validation loss: 0.0601
Validation Accuracy: 0.9822
Overfitting: 0.0523
Best model saved at epoch 3 with validation loss: 0.0601
[Epoch 4, Batch 100] loss: 0.04295665924029891
[Epoch 4, Batch 200] loss: 0.0506295776355546
[Epoch 4, Batch 300] loss: 0.031615904016653075
[Epoch 4, Batch 400] loss: 0.05031564679229632
**STATS for Epoch 4** : 
Average training loss: 0.0068
Average validation loss: 0.0640
Validation Accuracy: 0.9815
Overfitting: 0.0572
[Epoch 5, Batch 100] loss: 0.03119542309679673
[Epoch 5, Batch 200] loss: 0.03884140359936282
[Epoch 5, Batch 300] loss: 0.03628253883915022
[Epoch 5, Batch 400] loss: 0.03831959215807729
**STATS for Epoch 5** : 
Average training loss: 0.0054
Average validation loss: 0.0547
Validation Accuracy: 0.9847
Overfitting: 0.0493
Best model saved at epoch 5 with validation loss: 0.0547
[Epoch 6, Batch 100] loss: 0.018723066713428126
[Epoch 6, Batch 200] loss: 0.021120696275611407
[Epoch 6, Batch 300] loss: 0.025508602297632025
[Epoch 6, Batch 400] loss: 0.028789535862160848
**STATS for Epoch 6** : 
Average training loss: 0.0045
Average validation loss: 0.0543
Validation Accuracy: 0.9852
Overfitting: 0.0497
Best model saved at epoch 6 with validation loss: 0.0543
[Epoch 7, Batch 100] loss: 0.01992849140748149
[Epoch 7, Batch 200] loss: 0.01821730047260644
[Epoch 7, Batch 300] loss: 0.027593459000927398
[Epoch 7, Batch 400] loss: 0.02342758155282354
**STATS for Epoch 7** : 
Average training loss: 0.0035
Average validation loss: 0.0616
Validation Accuracy: 0.9845
Overfitting: 0.0581
[Epoch 8, Batch 100] loss: 0.0150890022826934
[Epoch 8, Batch 200] loss: 0.027729886418092063
[Epoch 8, Batch 300] loss: 0.02715170526993461
[Epoch 8, Batch 400] loss: 0.017821174807322676
**STATS for Epoch 8** : 
Average training loss: 0.0021
Average validation loss: 0.0496
Validation Accuracy: 0.9869
Overfitting: 0.0475
Best model saved at epoch 8 with validation loss: 0.0496
[Epoch 9, Batch 100] loss: 0.012799452522012872
[Epoch 9, Batch 200] loss: 0.014217130906763487
[Epoch 9, Batch 300] loss: 0.010062500341155101
[Epoch 9, Batch 400] loss: 0.016987291903060395
**STATS for Epoch 9** : 
Average training loss: 0.0023
Average validation loss: 0.0742
Validation Accuracy: 0.9834
Overfitting: 0.0719
[Epoch 10, Batch 100] loss: 0.0097457039062283
[Epoch 10, Batch 200] loss: 0.010080176992232737
[Epoch 10, Batch 300] loss: 0.01548881402341067
[Epoch 10, Batch 400] loss: 0.018308470381598455
**STATS for Epoch 10** : 
Average training loss: 0.0030
Average validation loss: 0.0906
Validation Accuracy: 0.9782
Overfitting: 0.0877
[Epoch 11, Batch 100] loss: 0.012285394330465351
[Epoch 11, Batch 200] loss: 0.0165265936099604
[Epoch 11, Batch 300] loss: 0.013455818079673918
[Epoch 11, Batch 400] loss: 0.012102392668566608
**STATS for Epoch 11** : 
Average training loss: 0.0024
Average validation loss: 0.0640
Validation Accuracy: 0.9852
Overfitting: 0.0616
[Epoch 12, Batch 100] loss: 0.010384402152194525
[Epoch 12, Batch 200] loss: 0.006691396553360391
[Epoch 12, Batch 300] loss: 0.014578303706439328
[Epoch 12, Batch 400] loss: 0.012198011426153243
**STATS for Epoch 12** : 
Average training loss: 0.0012
Average validation loss: 0.0646
Validation Accuracy: 0.9865
Overfitting: 0.0634
[Epoch 13, Batch 100] loss: 0.009929143371318788
[Epoch 13, Batch 200] loss: 0.006425913877592393
[Epoch 13, Batch 300] loss: 0.013695091732497531
[Epoch 13, Batch 400] loss: 0.012331409534763225
**STATS for Epoch 13** : 
Average training loss: 0.0017
Average validation loss: 0.0679
Validation Accuracy: 0.9851
Overfitting: 0.0662
[Epoch 14, Batch 100] loss: 0.008281606112932422
[Epoch 14, Batch 200] loss: 0.0052044702698503895
[Epoch 14, Batch 300] loss: 0.006950994811295459
[Epoch 14, Batch 400] loss: 0.01768254104874359
**STATS for Epoch 14** : 
Average training loss: 0.0015
Average validation loss: 0.0651
Validation Accuracy: 0.9868
Overfitting: 0.0635
[Epoch 15, Batch 100] loss: 0.010347846838940314
[Epoch 15, Batch 200] loss: 0.0028631767790670893
[Epoch 15, Batch 300] loss: 0.0029231498189074044
[Epoch 15, Batch 400] loss: 0.005593273983135987
**STATS for Epoch 15** : 
Average training loss: 0.0017
Average validation loss: 0.0690
Validation Accuracy: 0.9856
Overfitting: 0.0673
[Epoch 16, Batch 100] loss: 0.007950862749057706
[Epoch 16, Batch 200] loss: 0.009629546434152871
[Epoch 16, Batch 300] loss: 0.0028151531620278546
[Epoch 16, Batch 400] loss: 0.003256774431310987
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0570
Validation Accuracy: 0.9891
Overfitting: 0.0563
[Epoch 17, Batch 100] loss: 0.0014402156502114848
[Epoch 17, Batch 200] loss: 0.001306467197357506
[Epoch 17, Batch 300] loss: 0.0036407199936866162
[Epoch 17, Batch 400] loss: 0.005673722474266469
**STATS for Epoch 17** : 
Average training loss: 0.0009
Average validation loss: 0.0610
Validation Accuracy: 0.9879
Overfitting: 0.0601
[Epoch 18, Batch 100] loss: 0.00461779431117975
[Epoch 18, Batch 200] loss: 0.005231890500706413
[Epoch 18, Batch 300] loss: 0.005053896315143902
[Epoch 18, Batch 400] loss: 0.00604598051028006
**STATS for Epoch 18** : 
Average training loss: 0.0017
Average validation loss: 0.0687
Validation Accuracy: 0.9859
Overfitting: 0.0671
[Epoch 19, Batch 100] loss: 0.003494644138240801
[Epoch 19, Batch 200] loss: 0.005365692117914022
[Epoch 19, Batch 300] loss: 0.007234614865294589
[Epoch 19, Batch 400] loss: 0.002759918558940626
**STATS for Epoch 19** : 
Average training loss: 0.0030
Average validation loss: 0.1095
Validation Accuracy: 0.9780
Overfitting: 0.1065
[Epoch 20, Batch 100] loss: 0.009805514467116154
[Epoch 20, Batch 200] loss: 0.010430256986714993
[Epoch 20, Batch 300] loss: 0.0055292138976665225
[Epoch 20, Batch 400] loss: 0.006163166778242158
**STATS for Epoch 20** : 
Average training loss: 0.0012
Average validation loss: 0.0702
Validation Accuracy: 0.9864
Overfitting: 0.0690
[Epoch 21, Batch 100] loss: 0.006190892469265634
[Epoch 21, Batch 200] loss: 0.002062581111995314
[Epoch 21, Batch 300] loss: 0.0055227202280929075
[Epoch 21, Batch 400] loss: 0.004875358627477908
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0563
Validation Accuracy: 0.9887
Overfitting: 0.0561
[Epoch 22, Batch 100] loss: 0.0009288103215249066
[Epoch 22, Batch 200] loss: 0.0005728697616507361
[Epoch 22, Batch 300] loss: 0.00044707015540069507
[Epoch 22, Batch 400] loss: 0.00046251108074216066
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9898
Overfitting: 0.0567
[Epoch 23, Batch 100] loss: 0.0001845390670197844
[Epoch 23, Batch 200] loss: 0.00012433267755454836
[Epoch 23, Batch 300] loss: 0.00011860465022834887
[Epoch 23, Batch 400] loss: 0.0001331415775445066
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0584
Validation Accuracy: 0.9896
Overfitting: 0.0584
[Epoch 24, Batch 100] loss: 0.00010986139092665326
[Epoch 24, Batch 200] loss: 7.582638241615314e-05
[Epoch 24, Batch 300] loss: 7.467470932027709e-05
[Epoch 24, Batch 400] loss: 7.856389792237906e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0597
Validation Accuracy: 0.9896
Overfitting: 0.0597
Fold 2 validation loss: 0.0597
Mean validation loss across all folds for Trial 11 is 0.0630 with trial config:  l1: 256, l2: 128, lr: 0.016137610321187143, batch_size: 64
[I 2024-11-25 16:23:43,074] Trial 10 finished with value: 0.06295775258920805 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.016137610321187143, 'batch_size': 64}. Best is trial 7 with value: 0.0582443055690866.

Selected Hyperparameters for Trial 12:
  l1: 128, l2: 128, lr: 1.0474345163897545e-05, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3057275295257567
[Epoch 1, Batch 200] loss: 2.3042252039909363
**STATS for Epoch 1** : 
Average training loss: 0.3433
Average validation loss: 2.3046
Validation Accuracy: 0.0715
Overfitting: 1.9613
Best model saved at epoch 1 with validation loss: 2.3046
[Epoch 2, Batch 100] loss: 2.3038177561759947
[Epoch 2, Batch 200] loss: 2.3048820161819457
**STATS for Epoch 2** : 
Average training loss: 0.3432
Average validation loss: 2.3040
Validation Accuracy: 0.0727
Overfitting: 1.9608
Best model saved at epoch 2 with validation loss: 2.3040
[Epoch 3, Batch 100] loss: 2.3032006096839903
[Epoch 3, Batch 200] loss: 2.304070279598236
**STATS for Epoch 3** : 
Average training loss: 0.3431
Average validation loss: 2.3033
Validation Accuracy: 0.0733
Overfitting: 1.9602
Best model saved at epoch 3 with validation loss: 2.3033
[Epoch 4, Batch 100] loss: 2.303535614013672
[Epoch 4, Batch 200] loss: 2.3025957131385804
**STATS for Epoch 4** : 
Average training loss: 0.3429
Average validation loss: 2.3026
Validation Accuracy: 0.0743
Overfitting: 1.9597
Best model saved at epoch 4 with validation loss: 2.3026
[Epoch 5, Batch 100] loss: 2.302466552257538
[Epoch 5, Batch 200] loss: 2.302318835258484
**STATS for Epoch 5** : 
Average training loss: 0.3429
Average validation loss: 2.3019
Validation Accuracy: 0.0753
Overfitting: 1.9590
Best model saved at epoch 5 with validation loss: 2.3019
[Epoch 6, Batch 100] loss: 2.301766402721405
[Epoch 6, Batch 200] loss: 2.3017300581932068
**STATS for Epoch 6** : 
Average training loss: 0.3427
Average validation loss: 2.3014
Validation Accuracy: 0.0759
Overfitting: 1.9586
[I 2024-11-25 16:24:49,653] Trial 11 pruned. 

Selected Hyperparameters for Trial 13:
  l1: 128, l2: 64, lr: 0.002368943363113869, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2737633848190306
[Epoch 1, Batch 200] loss: 1.5888912671804427
**STATS for Epoch 1** : 
Average training loss: 0.0854
Average validation loss: 0.5626
Validation Accuracy: 0.8128
Overfitting: 0.4773
Best model saved at epoch 1 with validation loss: 0.5626
[Epoch 2, Batch 100] loss: 0.4678846648335457
[Epoch 2, Batch 200] loss: 0.32885470271110534
**STATS for Epoch 2** : 
Average training loss: 0.0407
Average validation loss: 0.2614
Validation Accuracy: 0.9222
Overfitting: 0.2207
Best model saved at epoch 2 with validation loss: 0.2614
[Epoch 3, Batch 100] loss: 0.2514337637275457
[Epoch 3, Batch 200] loss: 0.2135198451578617
**STATS for Epoch 3** : 
Average training loss: 0.0266
Average validation loss: 0.1888
Validation Accuracy: 0.9440
Overfitting: 0.1622
Best model saved at epoch 3 with validation loss: 0.1888
[Epoch 4, Batch 100] loss: 0.17613684467971324
[Epoch 4, Batch 200] loss: 0.15530155774205923
**STATS for Epoch 4** : 
Average training loss: 0.0235
Average validation loss: 0.1458
Validation Accuracy: 0.9554
Overfitting: 0.1224
Best model saved at epoch 4 with validation loss: 0.1458
[Epoch 5, Batch 100] loss: 0.1450746977701783
[Epoch 5, Batch 200] loss: 0.14600337170064448
**STATS for Epoch 5** : 
Average training loss: 0.0159
Average validation loss: 0.1265
Validation Accuracy: 0.9602
Overfitting: 0.1106
Best model saved at epoch 5 with validation loss: 0.1265
[Epoch 6, Batch 100] loss: 0.11602175006642938
[Epoch 6, Batch 200] loss: 0.11983840744942427
**STATS for Epoch 6** : 
Average training loss: 0.0154
Average validation loss: 0.1138
Validation Accuracy: 0.9645
Overfitting: 0.0983
Best model saved at epoch 6 with validation loss: 0.1138
[Epoch 7, Batch 100] loss: 0.10426575865596532
[Epoch 7, Batch 200] loss: 0.10364172520115972
**STATS for Epoch 7** : 
Average training loss: 0.0131
Average validation loss: 0.1099
Validation Accuracy: 0.9669
Overfitting: 0.0968
[I 2024-11-25 16:26:07,275] Trial 12 pruned. 

Selected Hyperparameters for Trial 14:
  l1: 256, l2: 128, lr: 0.0017411913258030666, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.280769197940826
**STATS for Epoch 1** : 
Average training loss: 0.3415
Average validation loss: 2.2246
Validation Accuracy: 0.2920
Overfitting: 1.8831
Best model saved at epoch 1 with validation loss: 2.2246
[Epoch 2, Batch 100] loss: 1.9505076670646668
**STATS for Epoch 2** : 
Average training loss: 0.1611
Average validation loss: 0.8706
Validation Accuracy: 0.7824
Overfitting: 0.7095
Best model saved at epoch 2 with validation loss: 0.8706
[Epoch 3, Batch 100] loss: 0.57370401263237
**STATS for Epoch 3** : 
Average training loss: 0.0634
Average validation loss: 0.4068
Validation Accuracy: 0.8792
Overfitting: 0.3434
Best model saved at epoch 3 with validation loss: 0.4068
[Epoch 4, Batch 100] loss: 0.3748498582839966
**STATS for Epoch 4** : 
Average training loss: 0.0475
Average validation loss: 0.3142
Validation Accuracy: 0.9062
Overfitting: 0.2667
Best model saved at epoch 4 with validation loss: 0.3142
[Epoch 5, Batch 100] loss: 0.2982371073961258
**STATS for Epoch 5** : 
Average training loss: 0.0425
Average validation loss: 0.2670
Validation Accuracy: 0.9213
Overfitting: 0.2245
Best model saved at epoch 5 with validation loss: 0.2670
[Epoch 6, Batch 100] loss: 0.2538748335838318
**STATS for Epoch 6** : 
Average training loss: 0.0332
Average validation loss: 0.2316
Validation Accuracy: 0.9302
Overfitting: 0.1983
[I 2024-11-25 16:27:12,133] Trial 13 pruned. 

Selected Hyperparameters for Trial 15:
  l1: 128, l2: 128, lr: 5.308131075945622e-05, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.301274826526642
[Epoch 1, Batch 200] loss: 2.3002477741241454
[Epoch 1, Batch 300] loss: 2.297257511615753
[Epoch 1, Batch 400] loss: 2.2966774559020995
[Epoch 1, Batch 500] loss: 2.298213925361633
[Epoch 1, Batch 600] loss: 2.294544367790222
[Epoch 1, Batch 700] loss: 2.2932050156593324
[Epoch 1, Batch 800] loss: 2.2934428000450136
[Epoch 1, Batch 900] loss: 2.293586549758911
[Epoch 1, Batch 1000] loss: 2.2890824341773985
[Epoch 1, Batch 1100] loss: 2.2885505414009093
[Epoch 1, Batch 1200] loss: 2.286409246921539
[Epoch 1, Batch 1300] loss: 2.2871170330047605
[Epoch 1, Batch 1400] loss: 2.285502460002899
[Epoch 1, Batch 1500] loss: 2.283831226825714
[Epoch 1, Batch 1600] loss: 2.2837685346603394
[Epoch 1, Batch 1700] loss: 2.280961298942566
[Epoch 1, Batch 1800] loss: 2.2804795932769775
**STATS for Epoch 1** : 
Average training loss: 0.0911
Average validation loss: 2.2765
Validation Accuracy: 0.1981
Overfitting: 2.1854
Best model saved at epoch 1 with validation loss: 2.2765
[Epoch 2, Batch 100] loss: 2.2739727973937987
[Epoch 2, Batch 200] loss: 2.2735162568092346
[Epoch 2, Batch 300] loss: 2.2720479273796084
[Epoch 2, Batch 400] loss: 2.267979063987732
[Epoch 2, Batch 500] loss: 2.2661463809013367
[Epoch 2, Batch 600] loss: 2.2620939588546753
[Epoch 2, Batch 700] loss: 2.261689920425415
[Epoch 2, Batch 800] loss: 2.263117470741272
[Epoch 2, Batch 900] loss: 2.2570508098602295
[Epoch 2, Batch 1000] loss: 2.2539907026290895
[Epoch 2, Batch 1100] loss: 2.25134560585022
[Epoch 2, Batch 1200] loss: 2.2466150403022764
[Epoch 2, Batch 1300] loss: 2.247096199989319
[Epoch 2, Batch 1400] loss: 2.240917356014252
[Epoch 2, Batch 1500] loss: 2.235849561691284
[Epoch 2, Batch 1600] loss: 2.232513566017151
[Epoch 2, Batch 1700] loss: 2.2225878119468687
[Epoch 2, Batch 1800] loss: 2.216480939388275
**STATS for Epoch 2** : 
Average training loss: 0.0886
Average validation loss: 2.2103
Validation Accuracy: 0.3041
Overfitting: 2.1217
Best model saved at epoch 2 with validation loss: 2.2103
[Epoch 3, Batch 100] loss: 2.2086238360404966
[Epoch 3, Batch 200] loss: 2.2025848269462585
[Epoch 3, Batch 300] loss: 2.187450797557831
[Epoch 3, Batch 400] loss: 2.1845648455619813
[Epoch 3, Batch 500] loss: 2.171423432826996
[Epoch 3, Batch 600] loss: 2.1598607778549193
[Epoch 3, Batch 700] loss: 2.147175416946411
[Epoch 3, Batch 800] loss: 2.1348163795471193
[Epoch 3, Batch 900] loss: 2.1188732099533083
[Epoch 3, Batch 1000] loss: 2.09565025806427
[Epoch 3, Batch 1100] loss: 2.0760409581661223
[Epoch 3, Batch 1200] loss: 2.048724389076233
[Epoch 3, Batch 1300] loss: 2.020130308866501
[Epoch 3, Batch 1400] loss: 1.9917037892341614
[Epoch 3, Batch 1500] loss: 1.942560783624649
[Epoch 3, Batch 1600] loss: 1.9268034052848817
[Epoch 3, Batch 1700] loss: 1.8598907101154327
[Epoch 3, Batch 1800] loss: 1.8083003151416779
**STATS for Epoch 3** : 
Average training loss: 0.0709
Average validation loss: 1.7281
Validation Accuracy: 0.6200
Overfitting: 1.6572
Best model saved at epoch 3 with validation loss: 1.7281
[Epoch 4, Batch 100] loss: 1.7118554246425628
[Epoch 4, Batch 200] loss: 1.6078791296482087
[Epoch 4, Batch 300] loss: 1.5286425864696502
[Epoch 4, Batch 400] loss: 1.46576469540596
[Epoch 4, Batch 500] loss: 1.3657220673561097
[Epoch 4, Batch 600] loss: 1.2666521286964416
[Epoch 4, Batch 700] loss: 1.206521902680397
[Epoch 4, Batch 800] loss: 1.1256666332483292
[Epoch 4, Batch 900] loss: 1.046487767100334
[Epoch 4, Batch 1000] loss: 0.9747506201267242
[Epoch 4, Batch 1100] loss: 0.9493983209133148
[Epoch 4, Batch 1200] loss: 0.8581950798630714
[Epoch 4, Batch 1300] loss: 0.8446480980515481
[Epoch 4, Batch 1400] loss: 0.7916809540987014
[Epoch 4, Batch 1500] loss: 0.7754333734512329
[Epoch 4, Batch 1600] loss: 0.7065611419081688
[Epoch 4, Batch 1700] loss: 0.6795294630527496
[Epoch 4, Batch 1800] loss: 0.6947762069106102
**STATS for Epoch 4** : 
Average training loss: 0.0262
Average validation loss: 0.6418
Validation Accuracy: 0.8187
Overfitting: 0.6156
Best model saved at epoch 4 with validation loss: 0.6418
[Epoch 5, Batch 100] loss: 0.6170152512192726
[Epoch 5, Batch 200] loss: 0.5909808132052422
[Epoch 5, Batch 300] loss: 0.5933214235305786
[Epoch 5, Batch 400] loss: 0.5920639589428902
[Epoch 5, Batch 500] loss: 0.5910404676198959
[Epoch 5, Batch 600] loss: 0.5243202698230743
[Epoch 5, Batch 700] loss: 0.5747017456591129
[Epoch 5, Batch 800] loss: 0.5337967520952225
[Epoch 5, Batch 900] loss: 0.5701554509997367
[Epoch 5, Batch 1000] loss: 0.5533622160553933
[Epoch 5, Batch 1100] loss: 0.5230729849636555
[Epoch 5, Batch 1200] loss: 0.5201295414566993
[Epoch 5, Batch 1300] loss: 0.47508365139365194
[Epoch 5, Batch 1400] loss: 0.5130937574803829
[Epoch 5, Batch 1500] loss: 0.4931402103602886
[Epoch 5, Batch 1600] loss: 0.47530920058488846
[Epoch 5, Batch 1700] loss: 0.48454159691929816
[Epoch 5, Batch 1800] loss: 0.4274861840903759
**STATS for Epoch 5** : 
Average training loss: 0.0162
Average validation loss: 0.4485
Validation Accuracy: 0.8673
Overfitting: 0.4324
Best model saved at epoch 5 with validation loss: 0.4485
[Epoch 6, Batch 100] loss: 0.44802250638604163
[Epoch 6, Batch 200] loss: 0.4601528612524271
[Epoch 6, Batch 300] loss: 0.45086619436740877
[Epoch 6, Batch 400] loss: 0.43850188091397285
[Epoch 6, Batch 500] loss: 0.43075112663209436
[Epoch 6, Batch 600] loss: 0.4182420724630356
[Epoch 6, Batch 700] loss: 0.4296159825474024
[Epoch 6, Batch 800] loss: 0.42231595151126383
[Epoch 6, Batch 900] loss: 0.3959211854636669
[Epoch 6, Batch 1000] loss: 0.4049221390485764
[Epoch 6, Batch 1100] loss: 0.4106857288628817
[Epoch 6, Batch 1200] loss: 0.41585338927805426
[Epoch 6, Batch 1300] loss: 0.389579122364521
[Epoch 6, Batch 1400] loss: 0.38298643693327905
[Epoch 6, Batch 1500] loss: 0.3948608075082302
[Epoch 6, Batch 1600] loss: 0.3666040767729282
[Epoch 6, Batch 1700] loss: 0.4039059539884329
[Epoch 6, Batch 1800] loss: 0.3580519647151232
**STATS for Epoch 6** : 
Average training loss: 0.0171
Average validation loss: 0.3814
Validation Accuracy: 0.8866
Overfitting: 0.3643
[I 2024-11-25 16:28:39,511] Trial 14 pruned. 

Selected Hyperparameters for Trial 16:
  l1: 256, l2: 64, lr: 0.004058790736670006, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.0769453829526903
[Epoch 1, Batch 200] loss: 0.6190076318383216
[Epoch 1, Batch 300] loss: 0.3585880017280579
[Epoch 1, Batch 400] loss: 0.27174271129071714
[Epoch 1, Batch 500] loss: 0.22935659049078821
[Epoch 1, Batch 600] loss: 0.18327299565076827
[Epoch 1, Batch 700] loss: 0.15252571960911154
[Epoch 1, Batch 800] loss: 0.16469454320147633
[Epoch 1, Batch 900] loss: 0.1517315711081028
**STATS for Epoch 1** : 
Average training loss: 0.0050
Average validation loss: 0.1202
Validation Accuracy: 0.9635
Overfitting: 0.1152
Best model saved at epoch 1 with validation loss: 0.1202
[Epoch 2, Batch 100] loss: 0.11022323637735099
[Epoch 2, Batch 200] loss: 0.13731863501481711
[Epoch 2, Batch 300] loss: 0.1162342482432723
[Epoch 2, Batch 400] loss: 0.11676349363289773
[Epoch 2, Batch 500] loss: 0.09064830777235329
[Epoch 2, Batch 600] loss: 0.0928132970444858
[Epoch 2, Batch 700] loss: 0.08820416323142126
[Epoch 2, Batch 800] loss: 0.08272346075158567
[Epoch 2, Batch 900] loss: 0.08010670432588085
**STATS for Epoch 2** : 
Average training loss: 0.0039
Average validation loss: 0.0792
Validation Accuracy: 0.9740
Overfitting: 0.0753
Best model saved at epoch 2 with validation loss: 0.0792
[Epoch 3, Batch 100] loss: 0.08060280193574726
[Epoch 3, Batch 200] loss: 0.0789832666493021
[Epoch 3, Batch 300] loss: 0.07173364038928412
[Epoch 3, Batch 400] loss: 0.056509548090398314
[Epoch 3, Batch 500] loss: 0.07494291224749759
[Epoch 3, Batch 600] loss: 0.059147977381944654
[Epoch 3, Batch 700] loss: 0.05131571698118933
[Epoch 3, Batch 800] loss: 0.06972402276936919
[Epoch 3, Batch 900] loss: 0.049880017441464586
**STATS for Epoch 3** : 
Average training loss: 0.0022
Average validation loss: 0.0905
Validation Accuracy: 0.9715
Overfitting: 0.0883
[Epoch 4, Batch 100] loss: 0.05952304460457526
[Epoch 4, Batch 200] loss: 0.03791328163351863
[Epoch 4, Batch 300] loss: 0.05907371356384829
[Epoch 4, Batch 400] loss: 0.04643855195841752
[Epoch 4, Batch 500] loss: 0.04800679949228652
[Epoch 4, Batch 600] loss: 0.05240819509373978
[Epoch 4, Batch 700] loss: 0.05256189315929077
[Epoch 4, Batch 800] loss: 0.045060420230438464
[Epoch 4, Batch 900] loss: 0.045412909297738224
**STATS for Epoch 4** : 
Average training loss: 0.0025
Average validation loss: 0.0657
Validation Accuracy: 0.9783
Overfitting: 0.0632
Best model saved at epoch 4 with validation loss: 0.0657
[Epoch 5, Batch 100] loss: 0.040759146050550046
[Epoch 5, Batch 200] loss: 0.035791187474969774
[Epoch 5, Batch 300] loss: 0.03736216146047809
[Epoch 5, Batch 400] loss: 0.03302743444211956
[Epoch 5, Batch 500] loss: 0.03988831656286493
[Epoch 5, Batch 600] loss: 0.04834315644577145
[Epoch 5, Batch 700] loss: 0.026884850134374572
[Epoch 5, Batch 800] loss: 0.046926280963234604
[Epoch 5, Batch 900] loss: 0.03673779354227008
**STATS for Epoch 5** : 
Average training loss: 0.0015
Average validation loss: 0.0505
Validation Accuracy: 0.9839
Overfitting: 0.0489
Best model saved at epoch 5 with validation loss: 0.0505
[Epoch 6, Batch 100] loss: 0.02500831887620734
[Epoch 6, Batch 200] loss: 0.025416499988350553
[Epoch 6, Batch 300] loss: 0.030661743778618984
[Epoch 6, Batch 400] loss: 0.029393421321583447
[Epoch 6, Batch 500] loss: 0.02684704975457862
[Epoch 6, Batch 600] loss: 0.03816666271712165
[Epoch 6, Batch 700] loss: 0.030690499283373356
[Epoch 6, Batch 800] loss: 0.03572739913943224
[Epoch 6, Batch 900] loss: 0.026855747527442873
**STATS for Epoch 6** : 
Average training loss: 0.0007
Average validation loss: 0.0560
Validation Accuracy: 0.9832
Overfitting: 0.0553
[Epoch 7, Batch 100] loss: 0.021291301201417808
[Epoch 7, Batch 200] loss: 0.019629226627002935
[Epoch 7, Batch 300] loss: 0.013059103579143994
[Epoch 7, Batch 400] loss: 0.015002377469427302
[Epoch 7, Batch 500] loss: 0.03007100841077772
[Epoch 7, Batch 600] loss: 0.021734098752203862
[Epoch 7, Batch 700] loss: 0.03238582596641208
[Epoch 7, Batch 800] loss: 0.016921810101630397
[Epoch 7, Batch 900] loss: 0.02977129043196328
**STATS for Epoch 7** : 
Average training loss: 0.0018
Average validation loss: 0.0549
Validation Accuracy: 0.9836
Overfitting: 0.0531
[Epoch 8, Batch 100] loss: 0.01719254186260514
[Epoch 8, Batch 200] loss: 0.020896594606456348
[Epoch 8, Batch 300] loss: 0.015016668706812198
[Epoch 8, Batch 400] loss: 0.02058287303087127
[Epoch 8, Batch 500] loss: 0.01649702300244826
[Epoch 8, Batch 600] loss: 0.018976143680993117
[Epoch 8, Batch 700] loss: 0.02121504564289353
[Epoch 8, Batch 800] loss: 0.013068934673574404
[Epoch 8, Batch 900] loss: 0.02030217920877476
**STATS for Epoch 8** : 
Average training loss: 0.0014
Average validation loss: 0.0520
Validation Accuracy: 0.9859
Overfitting: 0.0506
[Epoch 9, Batch 100] loss: 0.015574015790807607
[Epoch 9, Batch 200] loss: 0.012639157445009914
[Epoch 9, Batch 300] loss: 0.014365239369617484
[Epoch 9, Batch 400] loss: 0.017897381098664483
[Epoch 9, Batch 500] loss: 0.012898544773797767
[Epoch 9, Batch 600] loss: 0.015020128083851886
[Epoch 9, Batch 700] loss: 0.014302082286121731
[Epoch 9, Batch 800] loss: 0.01759670163919509
[Epoch 9, Batch 900] loss: 0.012452297109048232
**STATS for Epoch 9** : 
Average training loss: 0.0009
Average validation loss: 0.0557
Validation Accuracy: 0.9845
Overfitting: 0.0548
[Epoch 10, Batch 100] loss: 0.01317409673869406
[Epoch 10, Batch 200] loss: 0.010412165117959376
[Epoch 10, Batch 300] loss: 0.009588051432729117
[Epoch 10, Batch 400] loss: 0.0153730043656833
[Epoch 10, Batch 500] loss: 0.01220696042120835
[Epoch 10, Batch 600] loss: 0.017732384462997287
[Epoch 10, Batch 700] loss: 0.01748342709415738
[Epoch 10, Batch 800] loss: 0.01522120554054709
[Epoch 10, Batch 900] loss: 0.016899522359253752
**STATS for Epoch 10** : 
Average training loss: 0.0003
Average validation loss: 0.0495
Validation Accuracy: 0.9870
Overfitting: 0.0491
Best model saved at epoch 10 with validation loss: 0.0495
[Epoch 11, Batch 100] loss: 0.004681714910257142
[Epoch 11, Batch 200] loss: 0.006295062568533467
[Epoch 11, Batch 300] loss: 0.007345488185428621
[Epoch 11, Batch 400] loss: 0.00609444111175435
[Epoch 11, Batch 500] loss: 0.008368797681659998
[Epoch 11, Batch 600] loss: 0.01079041604055419
[Epoch 11, Batch 700] loss: 0.012258881123689207
[Epoch 11, Batch 800] loss: 0.021499487658911676
[Epoch 11, Batch 900] loss: 0.015245572529383935
**STATS for Epoch 11** : 
Average training loss: 0.0002
Average validation loss: 0.0515
Validation Accuracy: 0.9866
Overfitting: 0.0513
[Epoch 12, Batch 100] loss: 0.005672188463831844
[Epoch 12, Batch 200] loss: 0.011855954343045596
[Epoch 12, Batch 300] loss: 0.00910575538597186
[Epoch 12, Batch 400] loss: 0.006792740257333207
[Epoch 12, Batch 500] loss: 0.015669228499809833
[Epoch 12, Batch 600] loss: 0.011590597640861233
[Epoch 12, Batch 700] loss: 0.0037107680520239226
[Epoch 12, Batch 800] loss: 0.005737554736724632
[Epoch 12, Batch 900] loss: 0.006684170062346766
**STATS for Epoch 12** : 
Average training loss: 0.0003
Average validation loss: 0.0560
Validation Accuracy: 0.9868
Overfitting: 0.0556
[Epoch 13, Batch 100] loss: 0.008507752954174067
[Epoch 13, Batch 200] loss: 0.010141466047957692
[Epoch 13, Batch 300] loss: 0.0036605613862229804
[Epoch 13, Batch 400] loss: 0.005736803089921523
[Epoch 13, Batch 500] loss: 0.010581192813369854
[Epoch 13, Batch 600] loss: 0.01429146818283698
[Epoch 13, Batch 700] loss: 0.00932871661304489
[Epoch 13, Batch 800] loss: 0.006313277684057539
[Epoch 13, Batch 900] loss: 0.007038108005363028
**STATS for Epoch 13** : 
Average training loss: 0.0001
Average validation loss: 0.0529
Validation Accuracy: 0.9871
Overfitting: 0.0528
[Epoch 14, Batch 100] loss: 0.003484117630732726
[Epoch 14, Batch 200] loss: 0.003301378909231971
[Epoch 14, Batch 300] loss: 0.010396095996591158
[Epoch 14, Batch 400] loss: 0.0029714823473113937
[Epoch 14, Batch 500] loss: 0.00518673434629818
[Epoch 14, Batch 600] loss: 0.00384820422618418
[Epoch 14, Batch 700] loss: 0.006289299124073295
[Epoch 14, Batch 800] loss: 0.005397798666970175
[Epoch 14, Batch 900] loss: 0.009171005135021915
**STATS for Epoch 14** : 
Average training loss: 0.0004
Average validation loss: 0.0815
Validation Accuracy: 0.9815
Overfitting: 0.0810
[Epoch 15, Batch 100] loss: 0.01007162827791035
[Epoch 15, Batch 200] loss: 0.00494292600227709
[Epoch 15, Batch 300] loss: 0.0028547774893650057
[Epoch 15, Batch 400] loss: 0.0037697745628383927
[Epoch 15, Batch 500] loss: 0.002087347084443536
[Epoch 15, Batch 600] loss: 0.0050077392515777315
[Epoch 15, Batch 700] loss: 0.004374143476616155
[Epoch 15, Batch 800] loss: 0.001115992725608521
[Epoch 15, Batch 900] loss: 0.0034739931151921157
**STATS for Epoch 15** : 
Average training loss: 0.0003
Average validation loss: 0.0604
Validation Accuracy: 0.9855
Overfitting: 0.0601
[Epoch 16, Batch 100] loss: 0.004451132357107781
[Epoch 16, Batch 200] loss: 0.0037759000420373922
[Epoch 16, Batch 300] loss: 0.0034082831860212082
[Epoch 16, Batch 400] loss: 0.005933547265342441
[Epoch 16, Batch 500] loss: 0.005530018484839729
[Epoch 16, Batch 600] loss: 0.0011517756634498255
[Epoch 16, Batch 700] loss: 0.0043358458383181645
[Epoch 16, Batch 800] loss: 0.0037028730617930704
[Epoch 16, Batch 900] loss: 0.0031848728256431967
**STATS for Epoch 16** : 
Average training loss: 0.0000
Average validation loss: 0.0531
Validation Accuracy: 0.9880
Overfitting: 0.0530
[Epoch 17, Batch 100] loss: 0.002705814323303457
[Epoch 17, Batch 200] loss: 0.000838637287063193
[Epoch 17, Batch 300] loss: 0.0007356598196906816
[Epoch 17, Batch 400] loss: 0.0020881820501153924
[Epoch 17, Batch 500] loss: 0.0037743821658750678
[Epoch 17, Batch 600] loss: 0.002218458641880261
[Epoch 17, Batch 700] loss: 0.000986291340191201
[Epoch 17, Batch 800] loss: 0.0016912790060223414
[Epoch 17, Batch 900] loss: 0.004036660816187805
**STATS for Epoch 17** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9885
Overfitting: 0.0564
[Epoch 18, Batch 100] loss: 0.0010633042252493397
[Epoch 18, Batch 200] loss: 0.0013417473811972514
[Epoch 18, Batch 300] loss: 0.000711535218427457
[Epoch 18, Batch 400] loss: 0.0004250824405818321
[Epoch 18, Batch 500] loss: 0.0004027159204247255
[Epoch 18, Batch 600] loss: 0.001042761227525091
[Epoch 18, Batch 700] loss: 0.0009126026033817425
[Epoch 18, Batch 800] loss: 0.004347323042291009
[Epoch 18, Batch 900] loss: 0.0052334325619222
**STATS for Epoch 18** : 
Average training loss: 0.0001
Average validation loss: 0.0576
Validation Accuracy: 0.9879
Overfitting: 0.0576
[Epoch 19, Batch 100] loss: 0.001266313245542392
[Epoch 19, Batch 200] loss: 0.0026834024873829774
[Epoch 19, Batch 300] loss: 0.00505260393692879
[Epoch 19, Batch 400] loss: 0.0029430686713556044
[Epoch 19, Batch 500] loss: 0.010870053785313303
[Epoch 19, Batch 600] loss: 0.021074059431016395
[Epoch 19, Batch 700] loss: 0.010588249416521194
[Epoch 19, Batch 800] loss: 0.006343216210943865
[Epoch 19, Batch 900] loss: 0.0095934823085463
**STATS for Epoch 19** : 
Average training loss: 0.0001
Average validation loss: 0.0522
Validation Accuracy: 0.9882
Overfitting: 0.0521
[Epoch 20, Batch 100] loss: 0.000995294344756985
[Epoch 20, Batch 200] loss: 0.0008415113222048375
[Epoch 20, Batch 300] loss: 0.001753628731507888
[Epoch 20, Batch 400] loss: 0.0008352798376199644
[Epoch 20, Batch 500] loss: 0.0010631020567211636
[Epoch 20, Batch 600] loss: 0.0005893495504932389
[Epoch 20, Batch 700] loss: 0.0016191467771614044
[Epoch 20, Batch 800] loss: 0.0013303175795658718
[Epoch 20, Batch 900] loss: 0.0017128241709457371
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9880
Overfitting: 0.0576
[Epoch 21, Batch 100] loss: 0.002272295809523257
[Epoch 21, Batch 200] loss: 0.0031254540746746785
[Epoch 21, Batch 300] loss: 0.001029889210352053
[Epoch 21, Batch 400] loss: 0.0009831533313479212
[Epoch 21, Batch 500] loss: 0.0005933614123728149
[Epoch 21, Batch 600] loss: 0.0004977243182656821
[Epoch 21, Batch 700] loss: 0.0022051648845325643
[Epoch 21, Batch 800] loss: 0.0008041597182210581
[Epoch 21, Batch 900] loss: 0.0017582174948219632
**STATS for Epoch 21** : 
Average training loss: 0.0002
Average validation loss: 0.0590
Validation Accuracy: 0.9881
Overfitting: 0.0588
[Epoch 22, Batch 100] loss: 0.0009821736588514795
[Epoch 22, Batch 200] loss: 0.0010630896712245886
[Epoch 22, Batch 300] loss: 0.0006598225547955394
[Epoch 22, Batch 400] loss: 0.0005030196810513133
[Epoch 22, Batch 500] loss: 0.00026023279548311964
[Epoch 22, Batch 600] loss: 0.0007900993216088636
[Epoch 22, Batch 700] loss: 0.00043062190215664486
[Epoch 22, Batch 800] loss: 0.0002426960852400839
[Epoch 22, Batch 900] loss: 0.0003180281697297005
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0562
Validation Accuracy: 0.9891
Overfitting: 0.0562
[Epoch 23, Batch 100] loss: 0.00016371978945414867
[Epoch 23, Batch 200] loss: 0.00017297348696445169
[Epoch 23, Batch 300] loss: 0.0002101669752570956
[Epoch 23, Batch 400] loss: 0.0002080489013138731
[Epoch 23, Batch 500] loss: 0.00026699988022471643
[Epoch 23, Batch 600] loss: 0.0003610304500642769
[Epoch 23, Batch 700] loss: 0.000151820921988417
[Epoch 23, Batch 800] loss: 0.00020449075108615488
[Epoch 23, Batch 900] loss: 0.000243943932265438
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0578
Validation Accuracy: 0.9890
Overfitting: 0.0578
[Epoch 24, Batch 100] loss: 0.00015462887528883585
[Epoch 24, Batch 200] loss: 0.0001402246862225809
[Epoch 24, Batch 300] loss: 0.00016847510328204862
[Epoch 24, Batch 400] loss: 0.00014827607723418622
[Epoch 24, Batch 500] loss: 0.00021698311691537242
[Epoch 24, Batch 600] loss: 0.00014182192651929882
[Epoch 24, Batch 700] loss: 0.00019056572909178726
[Epoch 24, Batch 800] loss: 0.00013774556616311885
[Epoch 24, Batch 900] loss: 0.0001307431541319204
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0582
Validation Accuracy: 0.9891
Overfitting: 0.0581
Fold 1 validation loss: 0.0582
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.2671385979652405
[Epoch 1, Batch 200] loss: 1.1270447793602942
[Epoch 1, Batch 300] loss: 0.3885818282514811
[Epoch 1, Batch 400] loss: 0.2927818689495325
[Epoch 1, Batch 500] loss: 0.2346546148508787
[Epoch 1, Batch 600] loss: 0.18548974867910148
[Epoch 1, Batch 700] loss: 0.16779937331564723
[Epoch 1, Batch 800] loss: 0.1506965071335435
[Epoch 1, Batch 900] loss: 0.1381776086613536
**STATS for Epoch 1** : 
Average training loss: 0.0062
Average validation loss: 0.1276
Validation Accuracy: 0.9620
Overfitting: 0.1214
Best model saved at epoch 1 with validation loss: 0.1276
[Epoch 2, Batch 100] loss: 0.10593139599543065
[Epoch 2, Batch 200] loss: 0.1094003796344623
[Epoch 2, Batch 300] loss: 0.11108480169437826
[Epoch 2, Batch 400] loss: 0.09298109467839823
[Epoch 2, Batch 500] loss: 0.11196332558523864
[Epoch 2, Batch 600] loss: 0.08752790710888803
[Epoch 2, Batch 700] loss: 0.0884693483170122
[Epoch 2, Batch 800] loss: 0.08754254981409758
[Epoch 2, Batch 900] loss: 0.08970918085426093
**STATS for Epoch 2** : 
Average training loss: 0.0036
Average validation loss: 0.0845
Validation Accuracy: 0.9745
Overfitting: 0.0809
Best model saved at epoch 2 with validation loss: 0.0845
[Epoch 3, Batch 100] loss: 0.06765317892190069
[Epoch 3, Batch 200] loss: 0.08200663111871108
[Epoch 3, Batch 300] loss: 0.06859677827393171
[Epoch 3, Batch 400] loss: 0.05663193620159291
[Epoch 3, Batch 500] loss: 0.06336213669506834
[Epoch 3, Batch 600] loss: 0.07452003127196803
[Epoch 3, Batch 700] loss: 0.051741893546422946
[Epoch 3, Batch 800] loss: 0.04985659755591769
[Epoch 3, Batch 900] loss: 0.05763336212839931
**STATS for Epoch 3** : 
Average training loss: 0.0029
Average validation loss: 0.0749
Validation Accuracy: 0.9771
Overfitting: 0.0720
Best model saved at epoch 3 with validation loss: 0.0749
[Epoch 4, Batch 100] loss: 0.053857944648480045
[Epoch 4, Batch 200] loss: 0.04867623936850578
[Epoch 4, Batch 300] loss: 0.045562730815727266
[Epoch 4, Batch 400] loss: 0.05830441725149285
[Epoch 4, Batch 500] loss: 0.05397814238735009
[Epoch 4, Batch 600] loss: 0.054014151369337925
[Epoch 4, Batch 700] loss: 0.04695643350481987
[Epoch 4, Batch 800] loss: 0.04969679072790314
[Epoch 4, Batch 900] loss: 0.05287154686753638
**STATS for Epoch 4** : 
Average training loss: 0.0021
Average validation loss: 0.0696
Validation Accuracy: 0.9785
Overfitting: 0.0675
Best model saved at epoch 4 with validation loss: 0.0696
[Epoch 5, Batch 100] loss: 0.0300365607830463
[Epoch 5, Batch 200] loss: 0.0410277107427828
[Epoch 5, Batch 300] loss: 0.03861668030323926
[Epoch 5, Batch 400] loss: 0.041934812519466506
[Epoch 5, Batch 500] loss: 0.043612667209818025
[Epoch 5, Batch 600] loss: 0.035488782141183034
[Epoch 5, Batch 700] loss: 0.035656044103088785
[Epoch 5, Batch 800] loss: 0.05440096009639092
[Epoch 5, Batch 900] loss: 0.038007177117106036
**STATS for Epoch 5** : 
Average training loss: 0.0020
Average validation loss: 0.0603
Validation Accuracy: 0.9819
Overfitting: 0.0584
Best model saved at epoch 5 with validation loss: 0.0603
[Epoch 6, Batch 100] loss: 0.02490666778292507
[Epoch 6, Batch 200] loss: 0.04008966765948571
[Epoch 6, Batch 300] loss: 0.03572348906425759
[Epoch 6, Batch 400] loss: 0.029994214451289736
[Epoch 6, Batch 500] loss: 0.031905088144994806
[Epoch 6, Batch 600] loss: 0.03878695991152199
[Epoch 6, Batch 700] loss: 0.03453446805069689
[Epoch 6, Batch 800] loss: 0.03398552517144708
[Epoch 6, Batch 900] loss: 0.03902914371981751
**STATS for Epoch 6** : 
Average training loss: 0.0019
Average validation loss: 0.0798
Validation Accuracy: 0.9766
Overfitting: 0.0779
[Epoch 7, Batch 100] loss: 0.028388741192175077
[Epoch 7, Batch 200] loss: 0.03563968752729124
[Epoch 7, Batch 300] loss: 0.0215989180575707
[Epoch 7, Batch 400] loss: 0.019843865945877042
[Epoch 7, Batch 500] loss: 0.02797979690563807
[Epoch 7, Batch 600] loss: 0.025483499254769414
[Epoch 7, Batch 700] loss: 0.0250541582837468
[Epoch 7, Batch 800] loss: 0.02805268239666475
[Epoch 7, Batch 900] loss: 0.02717231117494521
**STATS for Epoch 7** : 
Average training loss: 0.0014
Average validation loss: 0.0574
Validation Accuracy: 0.9828
Overfitting: 0.0560
Best model saved at epoch 7 with validation loss: 0.0574
[Epoch 8, Batch 100] loss: 0.01701325244648615
[Epoch 8, Batch 200] loss: 0.017669024222850566
[Epoch 8, Batch 300] loss: 0.022093375886470312
[Epoch 8, Batch 400] loss: 0.021958533359866125
[Epoch 8, Batch 500] loss: 0.015462558763538255
[Epoch 8, Batch 600] loss: 0.02344055536654196
[Epoch 8, Batch 700] loss: 0.029096131892874837
[Epoch 8, Batch 800] loss: 0.04108450972838909
[Epoch 8, Batch 900] loss: 0.02530660352000268
**STATS for Epoch 8** : 
Average training loss: 0.0009
Average validation loss: 0.0650
Validation Accuracy: 0.9818
Overfitting: 0.0641
[Epoch 9, Batch 100] loss: 0.019618616563093383
[Epoch 9, Batch 200] loss: 0.017586297461602955
[Epoch 9, Batch 300] loss: 0.008400889851691318
[Epoch 9, Batch 400] loss: 0.01975012975290156
[Epoch 9, Batch 500] loss: 0.027161056969489436
[Epoch 9, Batch 600] loss: 0.021456191795114137
[Epoch 9, Batch 700] loss: 0.025765456612280104
[Epoch 9, Batch 800] loss: 0.02114461511155241
[Epoch 9, Batch 900] loss: 0.021628705781913594
**STATS for Epoch 9** : 
Average training loss: 0.0005
Average validation loss: 0.0569
Validation Accuracy: 0.9848
Overfitting: 0.0564
Best model saved at epoch 9 with validation loss: 0.0569
[Epoch 10, Batch 100] loss: 0.017939734642422992
[Epoch 10, Batch 200] loss: 0.015322831671874156
[Epoch 10, Batch 300] loss: 0.020998119816431425
[Epoch 10, Batch 400] loss: 0.013353969678719295
[Epoch 10, Batch 500] loss: 0.011285950270030298
[Epoch 10, Batch 600] loss: 0.018830377922677145
[Epoch 10, Batch 700] loss: 0.013409383428224828
[Epoch 10, Batch 800] loss: 0.008291932931424526
[Epoch 10, Batch 900] loss: 0.015467249875546258
**STATS for Epoch 10** : 
Average training loss: 0.0006
Average validation loss: 0.0584
Validation Accuracy: 0.9853
Overfitting: 0.0579
[Epoch 11, Batch 100] loss: 0.005161533429891278
[Epoch 11, Batch 200] loss: 0.0160257876529613
[Epoch 11, Batch 300] loss: 0.00816099582733841
[Epoch 11, Batch 400] loss: 0.008649768631930782
[Epoch 11, Batch 500] loss: 0.011068967890078057
[Epoch 11, Batch 600] loss: 0.01091842354491746
[Epoch 11, Batch 700] loss: 0.009539959102967259
[Epoch 11, Batch 800] loss: 0.013240011530415359
[Epoch 11, Batch 900] loss: 0.019113664331744076
**STATS for Epoch 11** : 
Average training loss: 0.0005
Average validation loss: 0.0657
Validation Accuracy: 0.9835
Overfitting: 0.0651
[Epoch 12, Batch 100] loss: 0.005737609246170905
[Epoch 12, Batch 200] loss: 0.009342783414504084
[Epoch 12, Batch 300] loss: 0.01106629727010386
[Epoch 12, Batch 400] loss: 0.014148617484024725
[Epoch 12, Batch 500] loss: 0.013920659020295717
[Epoch 12, Batch 600] loss: 0.017159668557596888
[Epoch 12, Batch 700] loss: 0.018231724187171495
[Epoch 12, Batch 800] loss: 0.017623992644912503
[Epoch 12, Batch 900] loss: 0.01396052092572063
**STATS for Epoch 12** : 
Average training loss: 0.0006
Average validation loss: 0.0625
Validation Accuracy: 0.9850
Overfitting: 0.0620
[Epoch 13, Batch 100] loss: 0.008812642295433762
[Epoch 13, Batch 200] loss: 0.015282608812740364
[Epoch 13, Batch 300] loss: 0.00870801065919295
[Epoch 13, Batch 400] loss: 0.017246053221933833
[Epoch 13, Batch 500] loss: 0.014102732576648123
[Epoch 13, Batch 600] loss: 0.005332991091472649
[Epoch 13, Batch 700] loss: 0.01021079494517835
[Epoch 13, Batch 800] loss: 0.013695945577601377
[Epoch 13, Batch 900] loss: 0.006793239104190434
**STATS for Epoch 13** : 
Average training loss: 0.0005
Average validation loss: 0.0610
Validation Accuracy: 0.9858
Overfitting: 0.0605
[Epoch 14, Batch 100] loss: 0.008010585293995974
[Epoch 14, Batch 200] loss: 0.009104187036537042
[Epoch 14, Batch 300] loss: 0.007437706877060464
[Epoch 14, Batch 400] loss: 0.005777788511531981
[Epoch 14, Batch 500] loss: 0.006198484117994667
[Epoch 14, Batch 600] loss: 0.003940298792472276
[Epoch 14, Batch 700] loss: 0.005726930181645003
[Epoch 14, Batch 800] loss: 0.007909410235084806
[Epoch 14, Batch 900] loss: 0.003807133512545988
**STATS for Epoch 14** : 
Average training loss: 0.0002
Average validation loss: 0.0710
Validation Accuracy: 0.9837
Overfitting: 0.0708
[Epoch 15, Batch 100] loss: 0.0074791882536032975
[Epoch 15, Batch 200] loss: 0.007394351726088644
[Epoch 15, Batch 300] loss: 0.0023891384837770604
[Epoch 15, Batch 400] loss: 0.0016260933495914286
[Epoch 15, Batch 500] loss: 0.00825963910610426
[Epoch 15, Batch 600] loss: 0.011788331927818944
[Epoch 15, Batch 700] loss: 0.008466474181377635
[Epoch 15, Batch 800] loss: 0.00867345444449711
[Epoch 15, Batch 900] loss: 0.006061322879404542
**STATS for Epoch 15** : 
Average training loss: 0.0006
Average validation loss: 0.0747
Validation Accuracy: 0.9847
Overfitting: 0.0741
[Epoch 16, Batch 100] loss: 0.011547470243056069
[Epoch 16, Batch 200] loss: 0.011768856494563806
[Epoch 16, Batch 300] loss: 0.00904399273385934
[Epoch 16, Batch 400] loss: 0.006354676435921647
[Epoch 16, Batch 500] loss: 0.02429201266957534
[Epoch 16, Batch 600] loss: 0.01291958605760101
[Epoch 16, Batch 700] loss: 0.009905460592508462
[Epoch 16, Batch 800] loss: 0.013521966839894048
[Epoch 16, Batch 900] loss: 0.005042884128622518
**STATS for Epoch 16** : 
Average training loss: 0.0003
Average validation loss: 0.0654
Validation Accuracy: 0.9847
Overfitting: 0.0651
[Epoch 17, Batch 100] loss: 0.012251219807312736
[Epoch 17, Batch 200] loss: 0.009783364873310347
[Epoch 17, Batch 300] loss: 0.008746636535270226
[Epoch 17, Batch 400] loss: 0.004435759967632294
[Epoch 17, Batch 500] loss: 0.003976606259111008
[Epoch 17, Batch 600] loss: 0.008073542974675546
[Epoch 17, Batch 700] loss: 0.008149307588187184
[Epoch 17, Batch 800] loss: 0.00818840849417029
[Epoch 17, Batch 900] loss: 0.0065897920614588655
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0606
Validation Accuracy: 0.9866
Overfitting: 0.0605
[Epoch 18, Batch 100] loss: 0.003523155884065545
[Epoch 18, Batch 200] loss: 0.004967010961231608
[Epoch 18, Batch 300] loss: 0.006210421915689039
[Epoch 18, Batch 400] loss: 0.005509663647638945
[Epoch 18, Batch 500] loss: 0.009624925718205475
[Epoch 18, Batch 600] loss: 0.006254497245570292
[Epoch 18, Batch 700] loss: 0.010269568793612507
[Epoch 18, Batch 800] loss: 0.005668693692041415
[Epoch 18, Batch 900] loss: 0.005852191838121143
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0638
Validation Accuracy: 0.9859
Overfitting: 0.0636
[Epoch 19, Batch 100] loss: 0.002375331335815645
[Epoch 19, Batch 200] loss: 0.003886421755192373
[Epoch 19, Batch 300] loss: 0.0010815714204272808
[Epoch 19, Batch 400] loss: 0.0022171651743832397
[Epoch 19, Batch 500] loss: 0.0021415353373629388
[Epoch 19, Batch 600] loss: 0.00213734256493467
[Epoch 19, Batch 700] loss: 0.0020264041227164853
[Epoch 19, Batch 800] loss: 0.0006460857030606348
[Epoch 19, Batch 900] loss: 0.0013876624136506166
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0625
Validation Accuracy: 0.9866
Overfitting: 0.0623
[Epoch 20, Batch 100] loss: 0.0013092715179220703
[Epoch 20, Batch 200] loss: 0.0012689238887583088
[Epoch 20, Batch 300] loss: 0.001599947195227287
[Epoch 20, Batch 400] loss: 0.0017635133652467517
[Epoch 20, Batch 500] loss: 0.0013944559780821918
[Epoch 20, Batch 600] loss: 0.0019506083234127657
[Epoch 20, Batch 700] loss: 0.0016568145131947176
[Epoch 20, Batch 800] loss: 0.0007320187392579669
[Epoch 20, Batch 900] loss: 0.0005304171544594283
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0607
Validation Accuracy: 0.9879
Overfitting: 0.0607
[Epoch 21, Batch 100] loss: 0.00036125364406753847
[Epoch 21, Batch 200] loss: 0.00027506616738492084
[Epoch 21, Batch 300] loss: 0.0006172273976247311
[Epoch 21, Batch 400] loss: 0.0002683968438071815
[Epoch 21, Batch 500] loss: 0.000345939738459009
[Epoch 21, Batch 600] loss: 0.0004358212653576032
[Epoch 21, Batch 700] loss: 0.00028353103689710224
[Epoch 21, Batch 800] loss: 0.00022062750792116502
[Epoch 21, Batch 900] loss: 0.00026466459843319965
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0618
Validation Accuracy: 0.9882
Overfitting: 0.0618
[Epoch 22, Batch 100] loss: 0.00016535416988858743
[Epoch 22, Batch 200] loss: 0.00016292474003591905
[Epoch 22, Batch 300] loss: 0.0001313139566516952
[Epoch 22, Batch 400] loss: 0.0004046281402915497
[Epoch 22, Batch 500] loss: 0.00017685848671419535
[Epoch 22, Batch 600] loss: 0.00017437608018440188
[Epoch 22, Batch 700] loss: 0.00019181142624830728
[Epoch 22, Batch 800] loss: 0.00012921085779254326
[Epoch 22, Batch 900] loss: 0.00016715142694636142
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0637
Validation Accuracy: 0.9881
Overfitting: 0.0637
[Epoch 23, Batch 100] loss: 0.0001456559039152694
[Epoch 23, Batch 200] loss: 0.00017596521616212614
[Epoch 23, Batch 300] loss: 0.00023195634948706357
[Epoch 23, Batch 400] loss: 0.00020498625449803852
[Epoch 23, Batch 500] loss: 0.00012488248792600132
[Epoch 23, Batch 600] loss: 0.00015115966647556435
[Epoch 23, Batch 700] loss: 0.00018310428241118614
[Epoch 23, Batch 800] loss: 0.00013476991379079094
[Epoch 23, Batch 900] loss: 0.00015100857609500195
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0645
Validation Accuracy: 0.9880
Overfitting: 0.0645
[Epoch 24, Batch 100] loss: 0.00011205502101027776
[Epoch 24, Batch 200] loss: 0.0001464112313475141
[Epoch 24, Batch 300] loss: 0.00014397401948421874
[Epoch 24, Batch 400] loss: 0.00013801034566711224
[Epoch 24, Batch 500] loss: 0.00011637788184454045
[Epoch 24, Batch 600] loss: 0.00014992942022827195
[Epoch 24, Batch 700] loss: 0.00011958890038492598
[Epoch 24, Batch 800] loss: 7.713083766304863e-05
[Epoch 24, Batch 900] loss: 0.00014994750135679524
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0658
Validation Accuracy: 0.9882
Overfitting: 0.0658
Fold 2 validation loss: 0.0658
Mean validation loss across all folds for Trial 16 is 0.0620 with trial config:  l1: 256, l2: 64, lr: 0.004058790736670006, batch_size: 32
[I 2024-11-25 16:38:30,998] Trial 15 finished with value: 0.06199897463466665 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.004058790736670006, 'batch_size': 32}. Best is trial 7 with value: 0.0582443055690866.

Selected Hyperparameters for Trial 17:
  l1: 128, l2: 64, lr: 0.02775251607090081, batch_size: 64
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.1456739948689938
[Epoch 1, Batch 200] loss: 0.23405040964484214
[Epoch 1, Batch 300] loss: 0.15875057505443693
[Epoch 1, Batch 400] loss: 0.12748811327852308
**STATS for Epoch 1** : 
Average training loss: 0.0180
Average validation loss: 0.1427
Validation Accuracy: 0.9563
Overfitting: 0.1248
Best model saved at epoch 1 with validation loss: 0.1427
[Epoch 2, Batch 100] loss: 0.09147537090349943
[Epoch 2, Batch 200] loss: 0.07720492206281052
[Epoch 2, Batch 300] loss: 0.0834436304261908
[Epoch 2, Batch 400] loss: 0.09084838160546496
**STATS for Epoch 2** : 
Average training loss: 0.0109
Average validation loss: 0.0761
Validation Accuracy: 0.9778
Overfitting: 0.0651
Best model saved at epoch 2 with validation loss: 0.0761
[Epoch 3, Batch 100] loss: 0.050558196302736176
[Epoch 3, Batch 200] loss: 0.06237250766484067
[Epoch 3, Batch 300] loss: 0.05326355763361789
[Epoch 3, Batch 400] loss: 0.060449127444298936
**STATS for Epoch 3** : 
Average training loss: 0.0075
Average validation loss: 0.0967
Validation Accuracy: 0.9718
Overfitting: 0.0892
[Epoch 4, Batch 100] loss: 0.03945461796582094
[Epoch 4, Batch 200] loss: 0.04484777712495998
[Epoch 4, Batch 300] loss: 0.047944390711927555
[Epoch 4, Batch 400] loss: 0.049871896371478215
**STATS for Epoch 4** : 
Average training loss: 0.0068
Average validation loss: 0.0708
Validation Accuracy: 0.9798
Overfitting: 0.0640
Best model saved at epoch 4 with validation loss: 0.0708
[Epoch 5, Batch 100] loss: 0.027946842998935607
[Epoch 5, Batch 200] loss: 0.029901047821622343
[Epoch 5, Batch 300] loss: 0.036307353690208405
[Epoch 5, Batch 400] loss: 0.03383237813381129
**STATS for Epoch 5** : 
Average training loss: 0.0052
Average validation loss: 0.0662
Validation Accuracy: 0.9826
Overfitting: 0.0610
Best model saved at epoch 5 with validation loss: 0.0662
[Epoch 6, Batch 100] loss: 0.029222985448432156
[Epoch 6, Batch 200] loss: 0.03954407048993744
[Epoch 6, Batch 300] loss: 0.026228447533067082
[Epoch 6, Batch 400] loss: 0.03074257294894778
**STATS for Epoch 6** : 
Average training loss: 0.0039
Average validation loss: 0.0710
Validation Accuracy: 0.9821
Overfitting: 0.0671
[Epoch 7, Batch 100] loss: 0.02795943147561047
[Epoch 7, Batch 200] loss: 0.024937554311763963
[Epoch 7, Batch 300] loss: 0.02593874343801872
[Epoch 7, Batch 400] loss: 0.03094894754118286
**STATS for Epoch 7** : 
Average training loss: 0.0047
Average validation loss: 0.0690
Validation Accuracy: 0.9823
Overfitting: 0.0643
[Epoch 8, Batch 100] loss: 0.02001228347333381
[Epoch 8, Batch 200] loss: 0.01838334237894742
[Epoch 8, Batch 300] loss: 0.018190382865213905
[Epoch 8, Batch 400] loss: 0.016989457836243674
**STATS for Epoch 8** : 
Average training loss: 0.0045
Average validation loss: 0.0863
Validation Accuracy: 0.9790
Overfitting: 0.0818
[Epoch 9, Batch 100] loss: 0.017602191927144305
[Epoch 9, Batch 200] loss: 0.0182608251349302
[Epoch 9, Batch 300] loss: 0.033970584117196265
[Epoch 9, Batch 400] loss: 0.020361914478999096
**STATS for Epoch 9** : 
Average training loss: 0.0032
Average validation loss: 0.0589
Validation Accuracy: 0.9861
Overfitting: 0.0557
Best model saved at epoch 9 with validation loss: 0.0589
[Epoch 10, Batch 100] loss: 0.01525018702755915
[Epoch 10, Batch 200] loss: 0.015423790475579154
[Epoch 10, Batch 300] loss: 0.029498539894229906
[Epoch 10, Batch 400] loss: 0.02117074008583586
**STATS for Epoch 10** : 
Average training loss: 0.0037
Average validation loss: 0.0729
Validation Accuracy: 0.9834
Overfitting: 0.0692
[Epoch 11, Batch 100] loss: 0.014090861813092487
[Epoch 11, Batch 200] loss: 0.02110893405409115
[Epoch 11, Batch 300] loss: 0.015727012911629572
[Epoch 11, Batch 400] loss: 0.01364936127934925
**STATS for Epoch 11** : 
Average training loss: 0.0039
Average validation loss: 0.0755
Validation Accuracy: 0.9831
Overfitting: 0.0715
[Epoch 12, Batch 100] loss: 0.009620044279836292
[Epoch 12, Batch 200] loss: 0.01659176883758846
[Epoch 12, Batch 300] loss: 0.015959813864028546
[Epoch 12, Batch 400] loss: 0.01749787088465382
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0642
Validation Accuracy: 0.9864
Overfitting: 0.0632
[Epoch 13, Batch 100] loss: 0.007989960813374638
[Epoch 13, Batch 200] loss: 0.015814703131400164
[Epoch 13, Batch 300] loss: 0.012558210845127179
[Epoch 13, Batch 400] loss: 0.013995761371588741
**STATS for Epoch 13** : 
Average training loss: 0.0024
Average validation loss: 0.0734
Validation Accuracy: 0.9847
Overfitting: 0.0710
[Epoch 14, Batch 100] loss: 0.00773194371140562
[Epoch 14, Batch 200] loss: 0.011511828189268271
[Epoch 14, Batch 300] loss: 0.010670058046871418
[Epoch 14, Batch 400] loss: 0.0181741214903991
**STATS for Epoch 14** : 
Average training loss: 0.0027
Average validation loss: 0.0737
Validation Accuracy: 0.9846
Overfitting: 0.0710
[Epoch 15, Batch 100] loss: 0.005246288339667444
[Epoch 15, Batch 200] loss: 0.009613379510192317
[Epoch 15, Batch 300] loss: 0.00615788655823053
[Epoch 15, Batch 400] loss: 0.009300657501594287
**STATS for Epoch 15** : 
Average training loss: 0.0008
Average validation loss: 0.0722
Validation Accuracy: 0.9869
Overfitting: 0.0714
[Epoch 16, Batch 100] loss: 0.008583564195650978
[Epoch 16, Batch 200] loss: 0.0057717663956725574
[Epoch 16, Batch 300] loss: 0.020377907166766532
[Epoch 16, Batch 400] loss: 0.02517234776445548
**STATS for Epoch 16** : 
Average training loss: 0.0023
Average validation loss: 0.0702
Validation Accuracy: 0.9846
Overfitting: 0.0680
[Epoch 17, Batch 100] loss: 0.006491600512099467
[Epoch 17, Batch 200] loss: 0.008938082085333008
[Epoch 17, Batch 300] loss: 0.010221531472916467
[Epoch 17, Batch 400] loss: 0.01318445749516286
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0710
Validation Accuracy: 0.9865
Overfitting: 0.0699
[Epoch 18, Batch 100] loss: 0.006150478073552676
[Epoch 18, Batch 200] loss: 0.0027864878276022864
[Epoch 18, Batch 300] loss: 0.008172672410868245
[Epoch 18, Batch 400] loss: 0.019096624859939765
**STATS for Epoch 18** : 
Average training loss: 0.0028
Average validation loss: 0.0870
Validation Accuracy: 0.9824
Overfitting: 0.0842
[Epoch 19, Batch 100] loss: 0.013131273983744904
[Epoch 19, Batch 200] loss: 0.012992422868724134
[Epoch 19, Batch 300] loss: 0.013028247185811779
[Epoch 19, Batch 400] loss: 0.015606501511210808
**STATS for Epoch 19** : 
Average training loss: 0.0019
Average validation loss: 0.1106
Validation Accuracy: 0.9794
Overfitting: 0.1087
[Epoch 20, Batch 100] loss: 0.012724934343546011
[Epoch 20, Batch 200] loss: 0.013276145344052566
[Epoch 20, Batch 300] loss: 0.0035928099590864806
[Epoch 20, Batch 400] loss: 0.007910910617829926
**STATS for Epoch 20** : 
Average training loss: 0.0006
Average validation loss: 0.0761
Validation Accuracy: 0.9859
Overfitting: 0.0755
[Epoch 21, Batch 100] loss: 0.011570266561382141
[Epoch 21, Batch 200] loss: 0.012764004392842025
[Epoch 21, Batch 300] loss: 0.016290461374956065
[Epoch 21, Batch 400] loss: 0.010423598520505948
**STATS for Epoch 21** : 
Average training loss: 0.0009
Average validation loss: 0.0797
Validation Accuracy: 0.9856
Overfitting: 0.0788
[Epoch 22, Batch 100] loss: 0.004212805836914413
[Epoch 22, Batch 200] loss: 0.002116615553090924
[Epoch 22, Batch 300] loss: 0.004873974572361704
[Epoch 22, Batch 400] loss: 0.0021828103045550052
**STATS for Epoch 22** : 
Average training loss: 0.0002
Average validation loss: 0.0691
Validation Accuracy: 0.9883
Overfitting: 0.0689
[Epoch 23, Batch 100] loss: 0.0009068625675104159
[Epoch 23, Batch 200] loss: 0.00031375072450941845
[Epoch 23, Batch 300] loss: 0.0004199249486341472
[Epoch 23, Batch 400] loss: 0.0010422754378290834
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0762
Validation Accuracy: 0.9886
Overfitting: 0.0760
[Epoch 24, Batch 100] loss: 0.0022929222468478904
[Epoch 24, Batch 200] loss: 0.0004284440674382495
[Epoch 24, Batch 300] loss: 0.0003826229267511394
[Epoch 24, Batch 400] loss: 0.0001593992095732233
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0840
Validation Accuracy: 0.9881
Overfitting: 0.0839
Fold 1 validation loss: 0.0840
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.2465089462697505
[Epoch 1, Batch 200] loss: 0.23210707008838655
[Epoch 1, Batch 300] loss: 0.15069114062935113
[Epoch 1, Batch 400] loss: 0.12344664931297303
**STATS for Epoch 1** : 
Average training loss: 0.0180
Average validation loss: 0.1166
Validation Accuracy: 0.9631
Overfitting: 0.0986
Best model saved at epoch 1 with validation loss: 0.1166
[Epoch 2, Batch 100] loss: 0.09285915598738939
[Epoch 2, Batch 200] loss: 0.08823303184472024
[Epoch 2, Batch 300] loss: 0.0851278544543311
[Epoch 2, Batch 400] loss: 0.0868824875028804
**STATS for Epoch 2** : 
Average training loss: 0.0121
Average validation loss: 0.0754
Validation Accuracy: 0.9777
Overfitting: 0.0633
Best model saved at epoch 2 with validation loss: 0.0754
[Epoch 3, Batch 100] loss: 0.06425375539809465
[Epoch 3, Batch 200] loss: 0.06739814429311082
[Epoch 3, Batch 300] loss: 0.06797501848544925
[Epoch 3, Batch 400] loss: 0.06156485220533796
**STATS for Epoch 3** : 
Average training loss: 0.0102
Average validation loss: 0.0697
Validation Accuracy: 0.9800
Overfitting: 0.0595
Best model saved at epoch 3 with validation loss: 0.0697
[Epoch 4, Batch 100] loss: 0.046503052103798834
[Epoch 4, Batch 200] loss: 0.045002982625737785
[Epoch 4, Batch 300] loss: 0.046434127656975764
[Epoch 4, Batch 400] loss: 0.04439591911184834
**STATS for Epoch 4** : 
Average training loss: 0.0075
Average validation loss: 0.0606
Validation Accuracy: 0.9827
Overfitting: 0.0532
Best model saved at epoch 4 with validation loss: 0.0606
[Epoch 5, Batch 100] loss: 0.02964757420355454
[Epoch 5, Batch 200] loss: 0.041121990365973034
[Epoch 5, Batch 300] loss: 0.038291165027185346
[Epoch 5, Batch 400] loss: 0.042448783762520176
**STATS for Epoch 5** : 
Average training loss: 0.0070
Average validation loss: 0.0622
Validation Accuracy: 0.9821
Overfitting: 0.0552
[Epoch 6, Batch 100] loss: 0.029427434284589254
[Epoch 6, Batch 200] loss: 0.035675359400338495
[Epoch 6, Batch 300] loss: 0.033465945632196965
[Epoch 6, Batch 400] loss: 0.035758039533975536
**STATS for Epoch 6** : 
Average training loss: 0.0039
Average validation loss: 0.0557
Validation Accuracy: 0.9852
Overfitting: 0.0517
Best model saved at epoch 6 with validation loss: 0.0557
[Epoch 7, Batch 100] loss: 0.024417116893455385
[Epoch 7, Batch 200] loss: 0.02680757847323548
[Epoch 7, Batch 300] loss: 0.025337996308808217
[Epoch 7, Batch 400] loss: 0.02615684781529126
**STATS for Epoch 7** : 
Average training loss: 0.0052
Average validation loss: 0.0646
Validation Accuracy: 0.9838
Overfitting: 0.0594
[Epoch 8, Batch 100] loss: 0.018929968242009636
[Epoch 8, Batch 200] loss: 0.021401951345760607
[Epoch 8, Batch 300] loss: 0.026524766142392762
[Epoch 8, Batch 400] loss: 0.024443721585412276
**STATS for Epoch 8** : 
Average training loss: 0.0051
Average validation loss: 0.0895
Validation Accuracy: 0.9785
Overfitting: 0.0843
[Epoch 9, Batch 100] loss: 0.026682499819980877
[Epoch 9, Batch 200] loss: 0.01895096408748941
[Epoch 9, Batch 300] loss: 0.027247127108712448
[Epoch 9, Batch 400] loss: 0.029415902001346694
**STATS for Epoch 9** : 
Average training loss: 0.0023
Average validation loss: 0.0687
Validation Accuracy: 0.9848
Overfitting: 0.0664
[Epoch 10, Batch 100] loss: 0.016769653425362775
[Epoch 10, Batch 200] loss: 0.02179637223386635
[Epoch 10, Batch 300] loss: 0.028884787129354664
[Epoch 10, Batch 400] loss: 0.025766284845158225
**STATS for Epoch 10** : 
Average training loss: 0.0046
Average validation loss: 0.0686
Validation Accuracy: 0.9826
Overfitting: 0.0640
[Epoch 11, Batch 100] loss: 0.012202931967076438
[Epoch 11, Batch 200] loss: 0.016489607610637905
[Epoch 11, Batch 300] loss: 0.0215018032752414
[Epoch 11, Batch 400] loss: 0.02681490505070542
**STATS for Epoch 11** : 
Average training loss: 0.0032
Average validation loss: 0.0704
Validation Accuracy: 0.9836
Overfitting: 0.0672
[Epoch 12, Batch 100] loss: 0.01210011433573527
[Epoch 12, Batch 200] loss: 0.013449405372939508
[Epoch 12, Batch 300] loss: 0.01660164536377124
[Epoch 12, Batch 400] loss: 0.011979740878268785
**STATS for Epoch 12** : 
Average training loss: 0.0023
Average validation loss: 0.0776
Validation Accuracy: 0.9832
Overfitting: 0.0754
[Epoch 13, Batch 100] loss: 0.019454293558883364
[Epoch 13, Batch 200] loss: 0.018016356411535525
[Epoch 13, Batch 300] loss: 0.020801925656342063
[Epoch 13, Batch 400] loss: 0.01735962287610164
**STATS for Epoch 13** : 
Average training loss: 0.0033
Average validation loss: 0.0903
Validation Accuracy: 0.9812
Overfitting: 0.0870
[Epoch 14, Batch 100] loss: 0.02370617725806369
[Epoch 14, Batch 200] loss: 0.013309425749303045
[Epoch 14, Batch 300] loss: 0.021056277850693732
[Epoch 14, Batch 400] loss: 0.02242258413167292
**STATS for Epoch 14** : 
Average training loss: 0.0029
Average validation loss: 0.0731
Validation Accuracy: 0.9837
Overfitting: 0.0702
[Epoch 15, Batch 100] loss: 0.014619621243132314
[Epoch 15, Batch 200] loss: 0.015708050427419948
[Epoch 15, Batch 300] loss: 0.021556377181514107
[Epoch 15, Batch 400] loss: 0.021849734306833853
**STATS for Epoch 15** : 
Average training loss: 0.0036
Average validation loss: 0.0713
Validation Accuracy: 0.9846
Overfitting: 0.0677
[Epoch 16, Batch 100] loss: 0.015642979986805586
[Epoch 16, Batch 200] loss: 0.025230962830864883
[Epoch 16, Batch 300] loss: 0.027838746077413816
[Epoch 16, Batch 400] loss: 0.015069575857196468
**STATS for Epoch 16** : 
Average training loss: 0.0021
Average validation loss: 0.0710
Validation Accuracy: 0.9841
Overfitting: 0.0688
[Epoch 17, Batch 100] loss: 0.013773451007391486
[Epoch 17, Batch 200] loss: 0.0069198773998050455
[Epoch 17, Batch 300] loss: 0.003548378875784692
[Epoch 17, Batch 400] loss: 0.008029757801414234
**STATS for Epoch 17** : 
Average training loss: 0.0015
Average validation loss: 0.0709
Validation Accuracy: 0.9860
Overfitting: 0.0694
[Epoch 18, Batch 100] loss: 0.005774489088801147
[Epoch 18, Batch 200] loss: 0.005658918434868383
[Epoch 18, Batch 300] loss: 0.015243018269757158
[Epoch 18, Batch 400] loss: 0.014723940161311476
**STATS for Epoch 18** : 
Average training loss: 0.0017
Average validation loss: 0.0656
Validation Accuracy: 0.9866
Overfitting: 0.0640
[Epoch 19, Batch 100] loss: 0.00655112016876501
[Epoch 19, Batch 200] loss: 0.004257192036814104
[Epoch 19, Batch 300] loss: 0.003379940763809941
[Epoch 19, Batch 400] loss: 0.012524773489504355
**STATS for Epoch 19** : 
Average training loss: 0.0050
Average validation loss: 0.1008
Validation Accuracy: 0.9841
Overfitting: 0.0958
[Epoch 20, Batch 100] loss: 0.015402694414506186
[Epoch 20, Batch 200] loss: 0.015382855043471864
[Epoch 20, Batch 300] loss: 0.024410189122791054
[Epoch 20, Batch 400] loss: 0.008263964916693567
**STATS for Epoch 20** : 
Average training loss: 0.0023
Average validation loss: 0.0745
Validation Accuracy: 0.9851
Overfitting: 0.0722
[Epoch 21, Batch 100] loss: 0.009585698897408292
[Epoch 21, Batch 200] loss: 0.007143082947131916
[Epoch 21, Batch 300] loss: 0.0037935267498119176
[Epoch 21, Batch 400] loss: 0.004904790877362473
**STATS for Epoch 21** : 
Average training loss: 0.0010
Average validation loss: 0.0702
Validation Accuracy: 0.9881
Overfitting: 0.0692
[Epoch 22, Batch 100] loss: 0.004532095700774334
[Epoch 22, Batch 200] loss: 0.0021948000046255346
[Epoch 22, Batch 300] loss: 0.0010306737492899298
[Epoch 22, Batch 400] loss: 0.014390332662328547
**STATS for Epoch 22** : 
Average training loss: 0.0031
Average validation loss: 0.1084
Validation Accuracy: 0.9801
Overfitting: 0.1053
[Epoch 23, Batch 100] loss: 0.01769032933229937
[Epoch 23, Batch 200] loss: 0.017175056688083713
[Epoch 23, Batch 300] loss: 0.039023794320382874
[Epoch 23, Batch 400] loss: 0.01967633181193378
**STATS for Epoch 23** : 
Average training loss: 0.0013
Average validation loss: 0.0774
Validation Accuracy: 0.9856
Overfitting: 0.0762
[Epoch 24, Batch 100] loss: 0.006153928156575148
[Epoch 24, Batch 200] loss: 0.008075307884563471
[Epoch 24, Batch 300] loss: 0.02055309052953362
[Epoch 24, Batch 400] loss: 0.03421314916155097
**STATS for Epoch 24** : 
Average training loss: 0.0024
Average validation loss: 0.0942
Validation Accuracy: 0.9823
Overfitting: 0.0918
Fold 2 validation loss: 0.0942
Mean validation loss across all folds for Trial 17 is 0.0891 with trial config:  l1: 128, l2: 64, lr: 0.02775251607090081, batch_size: 64
[I 2024-11-25 16:47:46,009] Trial 16 finished with value: 0.08909761244804504 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.02775251607090081, 'batch_size': 64}. Best is trial 7 with value: 0.0582443055690866.

Selected Hyperparameters for Trial 18:
  l1: 128, l2: 64, lr: 5.717481805031274e-05, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.306257417201996
**STATS for Epoch 1** : 
Average training loss: 0.3515
Average validation loss: 2.3055
Validation Accuracy: 0.0952
Overfitting: 1.9540
Best model saved at epoch 1 with validation loss: 2.3055
[Epoch 2, Batch 100] loss: 2.3050577354431154
**STATS for Epoch 2** : 
Average training loss: 0.3516
Average validation loss: 2.3047
Validation Accuracy: 0.0975
Overfitting: 1.9531
Best model saved at epoch 2 with validation loss: 2.3047
[Epoch 3, Batch 100] loss: 2.303926215171814
**STATS for Epoch 3** : 
Average training loss: 0.3517
Average validation loss: 2.3038
Validation Accuracy: 0.1006
Overfitting: 1.9521
Best model saved at epoch 3 with validation loss: 2.3038
[Epoch 4, Batch 100] loss: 2.3029940819740293
**STATS for Epoch 4** : 
Average training loss: 0.3515
Average validation loss: 2.3028
Validation Accuracy: 0.1046
Overfitting: 1.9514
Best model saved at epoch 4 with validation loss: 2.3028
[Epoch 5, Batch 100] loss: 2.3022117233276367
**STATS for Epoch 5** : 
Average training loss: 0.3512
Average validation loss: 2.3020
Validation Accuracy: 0.1089
Overfitting: 1.9508
Best model saved at epoch 5 with validation loss: 2.3020
[Epoch 6, Batch 100] loss: 2.301291105747223
**STATS for Epoch 6** : 
Average training loss: 0.3511
Average validation loss: 2.3011
Validation Accuracy: 0.1123
Overfitting: 1.9501
[I 2024-11-25 16:48:49,135] Trial 17 pruned. 

Selected Hyperparameters for Trial 19:
  l1: 128, l2: 64, lr: 0.00036374108581062233, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2980059719085695
[Epoch 1, Batch 200] loss: 2.289279587268829
[Epoch 1, Batch 300] loss: 2.2815784072875975
[Epoch 1, Batch 400] loss: 2.2745517325401305
[Epoch 1, Batch 500] loss: 2.259014954566956
[Epoch 1, Batch 600] loss: 2.234823052883148
[Epoch 1, Batch 700] loss: 2.1965459322929384
[Epoch 1, Batch 800] loss: 2.118834127187729
[Epoch 1, Batch 900] loss: 1.9430147087574006
[Epoch 1, Batch 1000] loss: 1.536031494140625
[Epoch 1, Batch 1100] loss: 1.0600477558374406
[Epoch 1, Batch 1200] loss: 0.797098131775856
[Epoch 1, Batch 1300] loss: 0.6783679184317589
[Epoch 1, Batch 1400] loss: 0.6579528875648976
[Epoch 1, Batch 1500] loss: 0.5087397067248821
[Epoch 1, Batch 1600] loss: 0.4879436641931534
[Epoch 1, Batch 1700] loss: 0.46539935521781445
[Epoch 1, Batch 1800] loss: 0.43926552720367906
**STATS for Epoch 1** : 
Average training loss: 0.0157
Average validation loss: 0.4059
Validation Accuracy: 0.8764
Overfitting: 0.3902
Best model saved at epoch 1 with validation loss: 0.4059
[Epoch 2, Batch 100] loss: 0.40910838313400744
[Epoch 2, Batch 200] loss: 0.3931699518859386
[Epoch 2, Batch 300] loss: 0.35413564905524253
[Epoch 2, Batch 400] loss: 0.33107802662998437
[Epoch 2, Batch 500] loss: 0.35885928992182015
[Epoch 2, Batch 600] loss: 0.3401707991957664
[Epoch 2, Batch 700] loss: 0.31257075801491735
[Epoch 2, Batch 800] loss: 0.3122471132315695
[Epoch 2, Batch 900] loss: 0.2997414361685514
[Epoch 2, Batch 1000] loss: 0.2975548735819757
[Epoch 2, Batch 1100] loss: 0.24262683965265752
[Epoch 2, Batch 1200] loss: 0.2819421470724046
[Epoch 2, Batch 1300] loss: 0.2593109899200499
[Epoch 2, Batch 1400] loss: 0.23279046149924398
[Epoch 2, Batch 1500] loss: 0.2567057481780648
[Epoch 2, Batch 1600] loss: 0.2765326501429081
[Epoch 2, Batch 1700] loss: 0.26382446233183143
[Epoch 2, Batch 1800] loss: 0.24447760662063955
**STATS for Epoch 2** : 
Average training loss: 0.0095
Average validation loss: 0.2234
Validation Accuracy: 0.9335
Overfitting: 0.2139
Best model saved at epoch 2 with validation loss: 0.2234
[Epoch 3, Batch 100] loss: 0.2186062242742628
[Epoch 3, Batch 200] loss: 0.18872904159128667
[Epoch 3, Batch 300] loss: 0.19396989029832185
[Epoch 3, Batch 400] loss: 0.1897913547977805
[Epoch 3, Batch 500] loss: 0.19218220522627236
[Epoch 3, Batch 600] loss: 0.19019221931695937
[Epoch 3, Batch 700] loss: 0.20059316750615835
[Epoch 3, Batch 800] loss: 0.21659257082268596
[Epoch 3, Batch 900] loss: 0.17005446286872028
[Epoch 3, Batch 1000] loss: 0.17642432982102035
[Epoch 3, Batch 1100] loss: 0.17418158937245606
[Epoch 3, Batch 1200] loss: 0.1529757294850424
[Epoch 3, Batch 1300] loss: 0.19437150782905518
[Epoch 3, Batch 1400] loss: 0.1944087131880224
[Epoch 3, Batch 1500] loss: 0.16970697741955518
[Epoch 3, Batch 1600] loss: 0.15057407380547375
[Epoch 3, Batch 1700] loss: 0.15514014351181685
[Epoch 3, Batch 1800] loss: 0.18485105075873434
**STATS for Epoch 3** : 
Average training loss: 0.0065
Average validation loss: 0.1584
Validation Accuracy: 0.9524
Overfitting: 0.1519
Best model saved at epoch 3 with validation loss: 0.1584
[Epoch 4, Batch 100] loss: 0.1432891345070675
[Epoch 4, Batch 200] loss: 0.12499046723823995
[Epoch 4, Batch 300] loss: 0.13702142131049186
[Epoch 4, Batch 400] loss: 0.14334593123756348
[Epoch 4, Batch 500] loss: 0.14287637404631823
[Epoch 4, Batch 600] loss: 0.15487006774172188
[Epoch 4, Batch 700] loss: 0.1378796863183379
[Epoch 4, Batch 800] loss: 0.12203029203694314
[Epoch 4, Batch 900] loss: 0.1329033830575645
[Epoch 4, Batch 1000] loss: 0.14851399712730198
[Epoch 4, Batch 1100] loss: 0.10774850178509951
[Epoch 4, Batch 1200] loss: 0.10225192273501307
[Epoch 4, Batch 1300] loss: 0.1273604583926499
[Epoch 4, Batch 1400] loss: 0.15533809241838753
[Epoch 4, Batch 1500] loss: 0.11709038763772696
[Epoch 4, Batch 1600] loss: 0.12745007683057338
[Epoch 4, Batch 1700] loss: 0.14536676233634352
[Epoch 4, Batch 1800] loss: 0.12998563305474817
**STATS for Epoch 4** : 
Average training loss: 0.0057
Average validation loss: 0.1205
Validation Accuracy: 0.9636
Overfitting: 0.1149
Best model saved at epoch 4 with validation loss: 0.1205
[Epoch 5, Batch 100] loss: 0.09571407889947295
[Epoch 5, Batch 200] loss: 0.12428693318739534
[Epoch 5, Batch 300] loss: 0.10352130273822695
[Epoch 5, Batch 400] loss: 0.08432968940818682
[Epoch 5, Batch 500] loss: 0.12000084384344518
[Epoch 5, Batch 600] loss: 0.1006572305597365
[Epoch 5, Batch 700] loss: 0.10631656820885838
[Epoch 5, Batch 800] loss: 0.10682241520378738
[Epoch 5, Batch 900] loss: 0.11620517041301355
[Epoch 5, Batch 1000] loss: 0.1046495412173681
[Epoch 5, Batch 1100] loss: 0.11842019975651055
[Epoch 5, Batch 1200] loss: 0.09069109805859625
[Epoch 5, Batch 1300] loss: 0.09356212353333831
[Epoch 5, Batch 1400] loss: 0.09781642795307562
[Epoch 5, Batch 1500] loss: 0.10859617845155299
[Epoch 5, Batch 1600] loss: 0.11228411228163168
[Epoch 5, Batch 1700] loss: 0.10893227183609269
[Epoch 5, Batch 1800] loss: 0.11908165759406984
**STATS for Epoch 5** : 
Average training loss: 0.0034
Average validation loss: 0.1028
Validation Accuracy: 0.9681
Overfitting: 0.0994
Best model saved at epoch 5 with validation loss: 0.1028
[Epoch 6, Batch 100] loss: 0.09509493075078353
[Epoch 6, Batch 200] loss: 0.09448801283724606
[Epoch 6, Batch 300] loss: 0.09545009448658676
[Epoch 6, Batch 400] loss: 0.10382369669154286
[Epoch 6, Batch 500] loss: 0.07295909456675873
[Epoch 6, Batch 600] loss: 0.10582293515792117
[Epoch 6, Batch 700] loss: 0.058459696851205084
[Epoch 6, Batch 800] loss: 0.07434486091719009
[Epoch 6, Batch 900] loss: 0.11745730206603185
[Epoch 6, Batch 1000] loss: 0.07389442403335124
[Epoch 6, Batch 1100] loss: 0.10829248374095186
[Epoch 6, Batch 1200] loss: 0.07789328397484496
[Epoch 6, Batch 1300] loss: 0.11384296876611188
[Epoch 6, Batch 1400] loss: 0.10202502266503871
[Epoch 6, Batch 1500] loss: 0.08981549706310034
[Epoch 6, Batch 1600] loss: 0.11092212280200328
[Epoch 6, Batch 1700] loss: 0.06968055660836399
[Epoch 6, Batch 1800] loss: 0.07202234883327037
**STATS for Epoch 6** : 
Average training loss: 0.0041
Average validation loss: 0.0906
Validation Accuracy: 0.9726
Overfitting: 0.0865
[I 2024-11-25 16:50:17,642] Trial 18 pruned. 

Selected Hyperparameters for Trial 20:
  l1: 256, l2: 64, lr: 0.0067544158230576, batch_size: 16
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.8997342658042908
[Epoch 1, Batch 200] loss: 0.5555689836293459
[Epoch 1, Batch 300] loss: 0.3320529945939779
[Epoch 1, Batch 400] loss: 0.24521801836788654
[Epoch 1, Batch 500] loss: 0.23023556004278362
[Epoch 1, Batch 600] loss: 0.16316749760881066
[Epoch 1, Batch 700] loss: 0.1394155658991076
[Epoch 1, Batch 800] loss: 0.17220103031140752
[Epoch 1, Batch 900] loss: 0.14764185578154865
[Epoch 1, Batch 1000] loss: 0.12656874986423644
[Epoch 1, Batch 1100] loss: 0.09347458564152475
[Epoch 1, Batch 1200] loss: 0.09836451375216711
[Epoch 1, Batch 1300] loss: 0.14012953324709088
[Epoch 1, Batch 1400] loss: 0.10371483668393922
[Epoch 1, Batch 1500] loss: 0.0807849918876309
[Epoch 1, Batch 1600] loss: 0.12830733861890622
[Epoch 1, Batch 1700] loss: 0.101479276381433
[Epoch 1, Batch 1800] loss: 0.08491172925219871
**STATS for Epoch 1** : 
Average training loss: 0.0040
Average validation loss: 0.0921
Validation Accuracy: 0.9730
Overfitting: 0.0880
Best model saved at epoch 1 with validation loss: 0.0921
[Epoch 2, Batch 100] loss: 0.08746247579241753
[Epoch 2, Batch 200] loss: 0.06888798226893414
[Epoch 2, Batch 300] loss: 0.08187881781661417
[Epoch 2, Batch 400] loss: 0.08124839833952137
[Epoch 2, Batch 500] loss: 0.07382591919486003
[Epoch 2, Batch 600] loss: 0.09077947005571332
[Epoch 2, Batch 700] loss: 0.07767219850677065
[Epoch 2, Batch 800] loss: 0.07697517173015513
[Epoch 2, Batch 900] loss: 0.06079951720574172
[Epoch 2, Batch 1000] loss: 0.05872235940973042
[Epoch 2, Batch 1100] loss: 0.0732383286798722
[Epoch 2, Batch 1200] loss: 0.06647188029979588
[Epoch 2, Batch 1300] loss: 0.06644869248964824
[Epoch 2, Batch 1400] loss: 0.08494769763259682
[Epoch 2, Batch 1500] loss: 0.08459006926947041
[Epoch 2, Batch 1600] loss: 0.07318661573517601
[Epoch 2, Batch 1700] loss: 0.07698069734295132
[Epoch 2, Batch 1800] loss: 0.059882941565156216
**STATS for Epoch 2** : 
Average training loss: 0.0021
Average validation loss: 0.0839
Validation Accuracy: 0.9762
Overfitting: 0.0817
Best model saved at epoch 2 with validation loss: 0.0839
[Epoch 3, Batch 100] loss: 0.05067762908685836
[Epoch 3, Batch 200] loss: 0.0581675932824146
[Epoch 3, Batch 300] loss: 0.04496477374683309
[Epoch 3, Batch 400] loss: 0.0425265045811102
[Epoch 3, Batch 500] loss: 0.05232011387954117
[Epoch 3, Batch 600] loss: 0.057515031451457616
[Epoch 3, Batch 700] loss: 0.04143018453418335
[Epoch 3, Batch 800] loss: 0.05231855964811984
[Epoch 3, Batch 900] loss: 0.08247927823184
[Epoch 3, Batch 1000] loss: 0.05169860609985335
[Epoch 3, Batch 1100] loss: 0.04562204265297623
[Epoch 3, Batch 1200] loss: 0.04979803198679292
[Epoch 3, Batch 1300] loss: 0.04890224607399432
[Epoch 3, Batch 1400] loss: 0.053607294626563086
[Epoch 3, Batch 1500] loss: 0.04306023932731477
[Epoch 3, Batch 1600] loss: 0.03036289303592639
[Epoch 3, Batch 1700] loss: 0.053465514919080304
[Epoch 3, Batch 1800] loss: 0.06035660932713654
**STATS for Epoch 3** : 
Average training loss: 0.0021
Average validation loss: 0.0565
Validation Accuracy: 0.9833
Overfitting: 0.0544
Best model saved at epoch 3 with validation loss: 0.0565
[Epoch 4, Batch 100] loss: 0.028306948823046695
[Epoch 4, Batch 200] loss: 0.0270048681246044
[Epoch 4, Batch 300] loss: 0.035400633873650805
[Epoch 4, Batch 400] loss: 0.02446554722422661
[Epoch 4, Batch 500] loss: 0.03381813034384322
[Epoch 4, Batch 600] loss: 0.05477942300349241
[Epoch 4, Batch 700] loss: 0.038414699537133855
[Epoch 4, Batch 800] loss: 0.03224942831631779
[Epoch 4, Batch 900] loss: 0.03903968155496841
[Epoch 4, Batch 1000] loss: 0.04470060994812229
[Epoch 4, Batch 1100] loss: 0.0341972367517883
[Epoch 4, Batch 1200] loss: 0.03695980836830131
[Epoch 4, Batch 1300] loss: 0.06123195511881931
[Epoch 4, Batch 1400] loss: 0.039542145159939535
[Epoch 4, Batch 1500] loss: 0.044870205937477294
[Epoch 4, Batch 1600] loss: 0.04721946469857358
[Epoch 4, Batch 1700] loss: 0.036630279816727125
[Epoch 4, Batch 1800] loss: 0.047938097588048546
**STATS for Epoch 4** : 
Average training loss: 0.0025
Average validation loss: 0.0616
Validation Accuracy: 0.9812
Overfitting: 0.0590
[Epoch 5, Batch 100] loss: 0.02632101044349838
[Epoch 5, Batch 200] loss: 0.008399405173367996
[Epoch 5, Batch 300] loss: 0.018458768233995216
[Epoch 5, Batch 400] loss: 0.020241257845154906
[Epoch 5, Batch 500] loss: 0.043430837583282485
[Epoch 5, Batch 600] loss: 0.04283635550307736
[Epoch 5, Batch 700] loss: 0.029806036521440548
[Epoch 5, Batch 800] loss: 0.03414549461784191
[Epoch 5, Batch 900] loss: 0.026889907957302058
[Epoch 5, Batch 1000] loss: 0.02103172738725334
[Epoch 5, Batch 1100] loss: 0.040488760222769996
[Epoch 5, Batch 1200] loss: 0.0298651368590572
[Epoch 5, Batch 1300] loss: 0.027892789103771066
[Epoch 5, Batch 1400] loss: 0.02177261319621266
[Epoch 5, Batch 1500] loss: 0.04315494852721713
[Epoch 5, Batch 1600] loss: 0.04645967951542843
[Epoch 5, Batch 1700] loss: 0.039710527093775455
[Epoch 5, Batch 1800] loss: 0.044062018941913264
**STATS for Epoch 5** : 
Average training loss: 0.0011
Average validation loss: 0.0655
Validation Accuracy: 0.9817
Overfitting: 0.0643
[Epoch 6, Batch 100] loss: 0.019577872051777377
[Epoch 6, Batch 200] loss: 0.006695592885389488
[Epoch 6, Batch 300] loss: 0.029999269965449004
[Epoch 6, Batch 400] loss: 0.010557891238058802
[Epoch 6, Batch 500] loss: 0.03469332120978152
[Epoch 6, Batch 600] loss: 0.024472308579543096
[Epoch 6, Batch 700] loss: 0.03172925423517654
[Epoch 6, Batch 800] loss: 0.017882882234475803
[Epoch 6, Batch 900] loss: 0.024442409110561128
[Epoch 6, Batch 1000] loss: 0.020866373812077656
[Epoch 6, Batch 1100] loss: 0.04242737414185285
[Epoch 6, Batch 1200] loss: 0.027183272366974053
[Epoch 6, Batch 1300] loss: 0.026987160827243315
[Epoch 6, Batch 1400] loss: 0.037013858405534845
[Epoch 6, Batch 1500] loss: 0.026917525212475084
[Epoch 6, Batch 1600] loss: 0.04932278629901703
[Epoch 6, Batch 1700] loss: 0.024659199745128715
[Epoch 6, Batch 1800] loss: 0.03470859116867359
**STATS for Epoch 6** : 
Average training loss: 0.0008
Average validation loss: 0.0565
Validation Accuracy: 0.9859
Overfitting: 0.0557
Best model saved at epoch 6 with validation loss: 0.0565
[Epoch 7, Batch 100] loss: 0.016135439278386912
[Epoch 7, Batch 200] loss: 0.01970998985823371
[Epoch 7, Batch 300] loss: 0.014582339979106108
[Epoch 7, Batch 400] loss: 0.02105962822854508
[Epoch 7, Batch 500] loss: 0.014246513909370151
[Epoch 7, Batch 600] loss: 0.009903959811230151
[Epoch 7, Batch 700] loss: 0.026339420622416582
[Epoch 7, Batch 800] loss: 0.011563028282012056
[Epoch 7, Batch 900] loss: 0.01146344165887058
[Epoch 7, Batch 1000] loss: 0.019521117789524284
[Epoch 7, Batch 1100] loss: 0.02384018091328471
[Epoch 7, Batch 1200] loss: 0.02484006323643712
[Epoch 7, Batch 1300] loss: 0.04554501859540437
[Epoch 7, Batch 1400] loss: 0.04565434943718174
[Epoch 7, Batch 1500] loss: 0.034568751289007195
[Epoch 7, Batch 1600] loss: 0.030518285357557032
[Epoch 7, Batch 1700] loss: 0.023287720717132743
[Epoch 7, Batch 1800] loss: 0.018148448346555598
**STATS for Epoch 7** : 
Average training loss: 0.0009
Average validation loss: 0.0608
Validation Accuracy: 0.9852
Overfitting: 0.0599
[Epoch 8, Batch 100] loss: 0.01131803586303704
[Epoch 8, Batch 200] loss: 0.01790575050206826
[Epoch 8, Batch 300] loss: 0.012172302987837611
[Epoch 8, Batch 400] loss: 0.013642269287431645
[Epoch 8, Batch 500] loss: 0.028469594329108075
[Epoch 8, Batch 600] loss: 0.009400470960973734
[Epoch 8, Batch 700] loss: 0.02222288857620697
[Epoch 8, Batch 800] loss: 0.01676375963458099
[Epoch 8, Batch 900] loss: 0.020620224070801215
[Epoch 8, Batch 1000] loss: 0.016103267091611997
[Epoch 8, Batch 1100] loss: 0.008491959945285999
[Epoch 8, Batch 1200] loss: 0.006796699297121904
[Epoch 8, Batch 1300] loss: 0.01438791536633289
[Epoch 8, Batch 1400] loss: 0.013211396396060025
[Epoch 8, Batch 1500] loss: 0.007387793268178271
[Epoch 8, Batch 1600] loss: 0.03671365120282871
[Epoch 8, Batch 1700] loss: 0.018059301195129364
[Epoch 8, Batch 1800] loss: 0.012172354406902173
**STATS for Epoch 8** : 
Average training loss: 0.0016
Average validation loss: 0.0712
Validation Accuracy: 0.9841
Overfitting: 0.0696
[Epoch 9, Batch 100] loss: 0.021574660295606236
[Epoch 9, Batch 200] loss: 0.008325479707344811
[Epoch 9, Batch 300] loss: 0.022340481128118768
[Epoch 9, Batch 400] loss: 0.008577134901114789
[Epoch 9, Batch 500] loss: 0.01479124124629493
[Epoch 9, Batch 600] loss: 0.00536448836658792
[Epoch 9, Batch 700] loss: 0.005031432795406942
[Epoch 9, Batch 800] loss: 0.017829344136180224
[Epoch 9, Batch 900] loss: 0.02039876600964362
[Epoch 9, Batch 1000] loss: 0.014654654304117685
[Epoch 9, Batch 1100] loss: 0.02034263553269227
[Epoch 9, Batch 1200] loss: 0.014014852493144759
[Epoch 9, Batch 1300] loss: 0.006746679033787473
[Epoch 9, Batch 1400] loss: 0.011957307950235467
[Epoch 9, Batch 1500] loss: 0.029676197653828923
[Epoch 9, Batch 1600] loss: 0.016924124139683555
[Epoch 9, Batch 1700] loss: 0.03289464494400136
[Epoch 9, Batch 1800] loss: 0.013060448439437095
**STATS for Epoch 9** : 
Average training loss: 0.0004
Average validation loss: 0.0609
Validation Accuracy: 0.9855
Overfitting: 0.0606
[Epoch 10, Batch 100] loss: 0.007045661028852237
[Epoch 10, Batch 200] loss: 0.015068131097173136
[Epoch 10, Batch 300] loss: 0.02891658123603065
[Epoch 10, Batch 400] loss: 0.005536841510601675
[Epoch 10, Batch 500] loss: 0.005074342112711747
[Epoch 10, Batch 600] loss: 0.016196967787280983
[Epoch 10, Batch 700] loss: 0.02084996844318624
[Epoch 10, Batch 800] loss: 0.01604727534025642
[Epoch 10, Batch 900] loss: 0.024664973502831346
[Epoch 10, Batch 1000] loss: 0.030224090299615796
[Epoch 10, Batch 1100] loss: 0.013405999751817034
[Epoch 10, Batch 1200] loss: 0.012465182932523931
[Epoch 10, Batch 1300] loss: 0.01824445166656915
[Epoch 10, Batch 1400] loss: 0.020371179904235533
[Epoch 10, Batch 1500] loss: 0.015001086372913051
[Epoch 10, Batch 1600] loss: 0.01883756587550579
[Epoch 10, Batch 1700] loss: 0.009811736047989825
[Epoch 10, Batch 1800] loss: 0.006089065384751109
**STATS for Epoch 10** : 
Average training loss: 0.0004
Average validation loss: 0.0572
Validation Accuracy: 0.9882
Overfitting: 0.0569
[Epoch 11, Batch 100] loss: 0.0015786276272388023
[Epoch 11, Batch 200] loss: 0.004757162044974877
[Epoch 11, Batch 300] loss: 0.003579994702820386
[Epoch 11, Batch 400] loss: 0.008357536182132606
[Epoch 11, Batch 500] loss: 0.009580890474832699
[Epoch 11, Batch 600] loss: 0.0037868913497649715
[Epoch 11, Batch 700] loss: 0.004006273769159234
[Epoch 11, Batch 800] loss: 0.00527787962194338
[Epoch 11, Batch 900] loss: 0.018867297111743717
[Epoch 11, Batch 1000] loss: 0.00682890196385074
[Epoch 11, Batch 1100] loss: 0.013888515156948743
[Epoch 11, Batch 1200] loss: 0.022815861626370407
[Epoch 11, Batch 1300] loss: 0.03671537784146182
[Epoch 11, Batch 1400] loss: 0.02113820066749014
[Epoch 11, Batch 1500] loss: 0.028304894404848256
[Epoch 11, Batch 1600] loss: 0.028123043301532105
[Epoch 11, Batch 1700] loss: 0.014478792069353404
[Epoch 11, Batch 1800] loss: 0.011696970959225155
**STATS for Epoch 11** : 
Average training loss: 0.0016
Average validation loss: 0.0608
Validation Accuracy: 0.9852
Overfitting: 0.0591
[Epoch 12, Batch 100] loss: 0.005512654008256277
[Epoch 12, Batch 200] loss: 0.004603083153171213
[Epoch 12, Batch 300] loss: 0.0044244752599563245
[Epoch 12, Batch 400] loss: 0.006177203502029442
[Epoch 12, Batch 500] loss: 0.0059330204394493795
[Epoch 12, Batch 600] loss: 0.00792825964723022
[Epoch 12, Batch 700] loss: 0.0025009929724033953
[Epoch 12, Batch 800] loss: 0.007644076667829438
[Epoch 12, Batch 900] loss: 0.013730038526870061
[Epoch 12, Batch 1000] loss: 0.01582709176668466
[Epoch 12, Batch 1100] loss: 0.025958652288509666
[Epoch 12, Batch 1200] loss: 0.012907320136611134
[Epoch 12, Batch 1300] loss: 0.009081158677755994
[Epoch 12, Batch 1400] loss: 0.010727120785084025
[Epoch 12, Batch 1500] loss: 0.006115519491331431
[Epoch 12, Batch 1600] loss: 0.013606300979405218
[Epoch 12, Batch 1700] loss: 0.006511052516944744
[Epoch 12, Batch 1800] loss: 0.01630377708441756
**STATS for Epoch 12** : 
Average training loss: 0.0002
Average validation loss: 0.0717
Validation Accuracy: 0.9864
Overfitting: 0.0714
[Epoch 13, Batch 100] loss: 0.014377318859662864
[Epoch 13, Batch 200] loss: 0.006309006375546025
[Epoch 13, Batch 300] loss: 0.015846242793018633
[Epoch 13, Batch 400] loss: 0.008906864442053575
[Epoch 13, Batch 500] loss: 0.01729287342275768
[Epoch 13, Batch 600] loss: 0.010669358830999726
[Epoch 13, Batch 700] loss: 0.00868812102910681
[Epoch 13, Batch 800] loss: 0.007139791730375577
[Epoch 13, Batch 900] loss: 0.01341002246562752
[Epoch 13, Batch 1000] loss: 0.01052904558555781
[Epoch 13, Batch 1100] loss: 0.01202028295411452
[Epoch 13, Batch 1200] loss: 0.008847352227940917
[Epoch 13, Batch 1300] loss: 0.016811980416639435
[Epoch 13, Batch 1400] loss: 0.006375494289960919
[Epoch 13, Batch 1500] loss: 0.035066939340167094
[Epoch 13, Batch 1600] loss: 0.00790090329706203
[Epoch 13, Batch 1700] loss: 0.011054507431600661
[Epoch 13, Batch 1800] loss: 0.01063247487517657
**STATS for Epoch 13** : 
Average training loss: 0.0007
Average validation loss: 0.0767
Validation Accuracy: 0.9844
Overfitting: 0.0760
[Epoch 14, Batch 100] loss: 0.0158179092235207
[Epoch 14, Batch 200] loss: 0.008689602505546823
[Epoch 14, Batch 300] loss: 0.008421680705301355
[Epoch 14, Batch 400] loss: 0.010645587803377907
[Epoch 14, Batch 500] loss: 0.009647476581306762
[Epoch 14, Batch 600] loss: 0.004509876481416981
[Epoch 14, Batch 700] loss: 0.01816417328350352
[Epoch 14, Batch 800] loss: 0.008693089193466931
[Epoch 14, Batch 900] loss: 0.005083436066395279
[Epoch 14, Batch 1000] loss: 0.003802913643946937
[Epoch 14, Batch 1100] loss: 0.0064216765361979
[Epoch 14, Batch 1200] loss: 0.007941125092908284
[Epoch 14, Batch 1300] loss: 0.006226163437656283
[Epoch 14, Batch 1400] loss: 0.018055920556038815
[Epoch 14, Batch 1500] loss: 0.003847919481294606
[Epoch 14, Batch 1600] loss: 0.015807144654172163
[Epoch 14, Batch 1700] loss: 0.0061004864955820845
[Epoch 14, Batch 1800] loss: 0.01442780438965222
**STATS for Epoch 14** : 
Average training loss: 0.0012
Average validation loss: 0.0682
Validation Accuracy: 0.9863
Overfitting: 0.0670
[Epoch 15, Batch 100] loss: 0.005484173349426556
[Epoch 15, Batch 200] loss: 0.006317285775209882
[Epoch 15, Batch 300] loss: 0.014533235589939011
[Epoch 15, Batch 400] loss: 0.010157993229822884
[Epoch 15, Batch 500] loss: 0.013154814447804454
[Epoch 15, Batch 600] loss: 0.002100075886769428
[Epoch 15, Batch 700] loss: 0.0037924112268974144
[Epoch 15, Batch 800] loss: 0.0021420089587343405
[Epoch 15, Batch 900] loss: 0.006051716565213745
[Epoch 15, Batch 1000] loss: 0.0035628159457695217
[Epoch 15, Batch 1100] loss: 0.0023672438659254657
[Epoch 15, Batch 1200] loss: 0.015294568050362329
[Epoch 15, Batch 1300] loss: 0.008997100256461988
[Epoch 15, Batch 1400] loss: 0.03636105535723202
[Epoch 15, Batch 1500] loss: 0.04330314486489442
[Epoch 15, Batch 1600] loss: 0.014044440877137276
[Epoch 15, Batch 1700] loss: 0.006557941342312859
[Epoch 15, Batch 1800] loss: 0.018794704368650342
**STATS for Epoch 15** : 
Average training loss: 0.0004
Average validation loss: 0.0708
Validation Accuracy: 0.9855
Overfitting: 0.0704
[Epoch 16, Batch 100] loss: 0.003717953882012637
[Epoch 16, Batch 200] loss: 0.0033780208733986683
[Epoch 16, Batch 300] loss: 0.009218267286944979
[Epoch 16, Batch 400] loss: 0.0024504842444480345
[Epoch 16, Batch 500] loss: 0.0016848568276671295
[Epoch 16, Batch 600] loss: 0.0028924893504202265
[Epoch 16, Batch 700] loss: 0.0022331257901227275
[Epoch 16, Batch 800] loss: 0.0018957652387703305
[Epoch 16, Batch 900] loss: 0.001990992038380486
[Epoch 16, Batch 1000] loss: 0.012714482723262565
[Epoch 16, Batch 1100] loss: 0.0031531540755329337
[Epoch 16, Batch 1200] loss: 0.01142016570794421
[Epoch 16, Batch 1300] loss: 0.002846833616312647
[Epoch 16, Batch 1400] loss: 0.0027699526440117506
[Epoch 16, Batch 1500] loss: 0.0008232559688373087
[Epoch 16, Batch 1600] loss: 0.0009212271097075097
[Epoch 16, Batch 1700] loss: 0.0014599821899948706
[Epoch 16, Batch 1800] loss: 0.0002775776393500573
**STATS for Epoch 16** : 
Average training loss: 0.0001
Average validation loss: 0.0646
Validation Accuracy: 0.9892
Overfitting: 0.0646
[Epoch 17, Batch 100] loss: 0.0006939582964444435
[Epoch 17, Batch 200] loss: 0.0001359887018215833
[Epoch 17, Batch 300] loss: 9.262339110602814e-05
[Epoch 17, Batch 400] loss: 0.00037252570131689476
[Epoch 17, Batch 500] loss: 0.00018553073900521522
[Epoch 17, Batch 600] loss: 0.0001511891850464009
[Epoch 17, Batch 700] loss: 0.00012119988138404647
[Epoch 17, Batch 800] loss: 0.00022990212241627006
[Epoch 17, Batch 900] loss: 0.0001372498333674521
[Epoch 17, Batch 1000] loss: 0.00024252429360387405
[Epoch 17, Batch 1100] loss: 0.004759352636284584
[Epoch 17, Batch 1200] loss: 0.0010393835648612139
[Epoch 17, Batch 1300] loss: 0.0004203279014598449
[Epoch 17, Batch 1400] loss: 0.0005440846605601202
[Epoch 17, Batch 1500] loss: 0.0002465873890627668
[Epoch 17, Batch 1600] loss: 0.00027344586383641454
[Epoch 17, Batch 1700] loss: 0.00015856774073082835
[Epoch 17, Batch 1800] loss: 0.0013516881705593331
**STATS for Epoch 17** : 
Average training loss: 0.0001
Average validation loss: 0.0691
Validation Accuracy: 0.9883
Overfitting: 0.0689
[Epoch 18, Batch 100] loss: 0.0006985492526488634
[Epoch 18, Batch 200] loss: 0.00014589850930352366
[Epoch 18, Batch 300] loss: 0.00018480862171042832
[Epoch 18, Batch 400] loss: 0.0002621837917023839
[Epoch 18, Batch 500] loss: 0.0001691971724928454
[Epoch 18, Batch 600] loss: 7.34178263435048e-05
[Epoch 18, Batch 700] loss: 0.00010360755694528212
[Epoch 18, Batch 800] loss: 9.618364207286234e-05
[Epoch 18, Batch 900] loss: 0.00018767811988003037
[Epoch 18, Batch 1000] loss: 0.00044457017617217877
[Epoch 18, Batch 1100] loss: 0.0003099627662864579
[Epoch 18, Batch 1200] loss: 0.0009150677898732651
[Epoch 18, Batch 1300] loss: 0.0003654254086422348
[Epoch 18, Batch 1400] loss: 0.00018326145299447206
[Epoch 18, Batch 1500] loss: 0.00047503873715931455
[Epoch 18, Batch 1600] loss: 8.50130103403668e-05
[Epoch 18, Batch 1700] loss: 0.00016306401213218803
[Epoch 18, Batch 1800] loss: 6.027215036706224e-05
**STATS for Epoch 18** : 
Average training loss: 0.0000
Average validation loss: 0.0694
Validation Accuracy: 0.9896
Overfitting: 0.0694
[Epoch 19, Batch 100] loss: 5.9387640907719866e-05
[Epoch 19, Batch 200] loss: 6.280546377539941e-05
[Epoch 19, Batch 300] loss: 7.85278868649808e-05
[Epoch 19, Batch 400] loss: 6.84673004702585e-05
[Epoch 19, Batch 500] loss: 7.759925439131177e-05
[Epoch 19, Batch 600] loss: 0.00029791752228049086
[Epoch 19, Batch 700] loss: 5.4451160655224486e-05
[Epoch 19, Batch 800] loss: 0.00010247004107868829
[Epoch 19, Batch 900] loss: 8.82465427232404e-05
[Epoch 19, Batch 1000] loss: 0.00016861731741394604
[Epoch 19, Batch 1100] loss: 7.218296036223038e-05
[Epoch 19, Batch 1200] loss: 9.944366498280122e-05
[Epoch 19, Batch 1300] loss: 5.6463552502998835e-05
[Epoch 19, Batch 1400] loss: 0.0001251024827782743
[Epoch 19, Batch 1500] loss: 8.247666056076407e-05
[Epoch 19, Batch 1600] loss: 2.7308996308477163e-05
[Epoch 19, Batch 1700] loss: 2.1696963291941707e-05
[Epoch 19, Batch 1800] loss: 4.5934839344434767e-05
**STATS for Epoch 19** : 
Average training loss: 0.0000
Average validation loss: 0.0701
Validation Accuracy: 0.9899
Overfitting: 0.0701
[Epoch 20, Batch 100] loss: 3.751928026093587e-05
[Epoch 20, Batch 200] loss: 6.302217461068071e-05
[Epoch 20, Batch 300] loss: 2.8860627034439367e-05
[Epoch 20, Batch 400] loss: 2.6164544399982504e-05
[Epoch 20, Batch 500] loss: 4.613118306540098e-05
[Epoch 20, Batch 600] loss: 3.9777730810124367e-05
[Epoch 20, Batch 700] loss: 2.9172025266692714e-05
[Epoch 20, Batch 800] loss: 3.285389200564204e-05
[Epoch 20, Batch 900] loss: 5.8624888620615324e-05
[Epoch 20, Batch 1000] loss: 4.7918949964351754e-05
[Epoch 20, Batch 1100] loss: 2.107565868332273e-05
[Epoch 20, Batch 1200] loss: 3.025043001078309e-05
[Epoch 20, Batch 1300] loss: 3.7504224623883254e-05
[Epoch 20, Batch 1400] loss: 9.91955249871257e-05
[Epoch 20, Batch 1500] loss: 3.557042675090383e-05
[Epoch 20, Batch 1600] loss: 0.00021650215395686346
[Epoch 20, Batch 1700] loss: 5.444428468103446e-05
[Epoch 20, Batch 1800] loss: 3.546933635188765e-05
**STATS for Epoch 20** : 
Average training loss: 0.0000
Average validation loss: 0.0721
Validation Accuracy: 0.9898
Overfitting: 0.0721
[Epoch 21, Batch 100] loss: 0.00011580973551281293
[Epoch 21, Batch 200] loss: 5.352834864118528e-05
[Epoch 21, Batch 300] loss: 4.971978267048538e-05
[Epoch 21, Batch 400] loss: 1.5548790155497372e-05
[Epoch 21, Batch 500] loss: 3.093258404223587e-05
[Epoch 21, Batch 600] loss: 3.2656335217762233e-05
[Epoch 21, Batch 700] loss: 0.00010937604758920916
[Epoch 21, Batch 800] loss: 2.996481917157734e-05
[Epoch 21, Batch 900] loss: 5.2640568941724195e-05
[Epoch 21, Batch 1000] loss: 2.4437334503262244e-05
[Epoch 21, Batch 1100] loss: 2.5001788056657758e-05
[Epoch 21, Batch 1200] loss: 3.03132659102312e-05
[Epoch 21, Batch 1300] loss: 3.435192121237218e-05
[Epoch 21, Batch 1400] loss: 4.146496554260803e-05
[Epoch 21, Batch 1500] loss: 0.00015125197895714314
[Epoch 21, Batch 1600] loss: 3.75777161316293e-05
[Epoch 21, Batch 1700] loss: 3.440031551422251e-05
[Epoch 21, Batch 1800] loss: 3.3976367050825296e-05
**STATS for Epoch 21** : 
Average training loss: 0.0000
Average validation loss: 0.0727
Validation Accuracy: 0.9899
Overfitting: 0.0727
[Epoch 22, Batch 100] loss: 1.9113734414037964e-05
[Epoch 22, Batch 200] loss: 3.6303384958347176e-05
[Epoch 22, Batch 300] loss: 1.9754422066053935e-05
[Epoch 22, Batch 400] loss: 2.8032448357029338e-05
[Epoch 22, Batch 500] loss: 4.134780701763763e-05
[Epoch 22, Batch 600] loss: 4.861903602867201e-05
[Epoch 22, Batch 700] loss: 2.9677239406047386e-05
[Epoch 22, Batch 800] loss: 3.4384649266874234e-05
[Epoch 22, Batch 900] loss: 7.565649571454447e-05
[Epoch 22, Batch 1000] loss: 5.05454465218147e-05
[Epoch 22, Batch 1100] loss: 5.958536588078101e-05
[Epoch 22, Batch 1200] loss: 2.5119342741826146e-05
[Epoch 22, Batch 1300] loss: 2.0650979785301615e-05
[Epoch 22, Batch 1400] loss: 2.452635031224837e-05
[Epoch 22, Batch 1500] loss: 2.1977845574427944e-05
[Epoch 22, Batch 1600] loss: 3.288296147134773e-05
[Epoch 22, Batch 1700] loss: 1.8359022141223315e-05
[Epoch 22, Batch 1800] loss: 2.2694004004017997e-05
**STATS for Epoch 22** : 
Average training loss: 0.0000
Average validation loss: 0.0734
Validation Accuracy: 0.9899
Overfitting: 0.0734
[Epoch 23, Batch 100] loss: 1.349602862327437e-05
[Epoch 23, Batch 200] loss: 1.772527677224911e-05
[Epoch 23, Batch 300] loss: 2.2074302498134024e-05
[Epoch 23, Batch 400] loss: 3.58964311493537e-05
[Epoch 23, Batch 500] loss: 3.622468055926031e-05
[Epoch 23, Batch 600] loss: 1.2189036871337323e-05
[Epoch 23, Batch 700] loss: 1.47861308111219e-05
[Epoch 23, Batch 800] loss: 2.4607618396492725e-05
[Epoch 23, Batch 900] loss: 2.507309831536464e-05
[Epoch 23, Batch 1000] loss: 3.817327680089466e-05
[Epoch 23, Batch 1100] loss: 2.1272863360035643e-05
[Epoch 23, Batch 1200] loss: 1.0865279138116967e-05
[Epoch 23, Batch 1300] loss: 2.0992860582595974e-05
[Epoch 23, Batch 1400] loss: 4.4888408608052546e-05
[Epoch 23, Batch 1500] loss: 3.47394747499763e-05
[Epoch 23, Batch 1600] loss: 3.337788975982914e-05
[Epoch 23, Batch 1700] loss: 4.21903656002165e-05
[Epoch 23, Batch 1800] loss: 2.9466338935173475e-05
**STATS for Epoch 23** : 
Average training loss: 0.0000
Average validation loss: 0.0741
Validation Accuracy: 0.9899
Overfitting: 0.0741
[Epoch 24, Batch 100] loss: 2.1471726133523994e-05
[Epoch 24, Batch 200] loss: 4.020384986709313e-05
[Epoch 24, Batch 300] loss: 1.711739427618042e-05
[Epoch 24, Batch 400] loss: 2.13869795828181e-05
[Epoch 24, Batch 500] loss: 1.9911586337890695e-05
[Epoch 24, Batch 600] loss: 3.436865405202827e-05
[Epoch 24, Batch 700] loss: 1.3583085368722437e-05
[Epoch 24, Batch 800] loss: 2.7220221481996097e-05
[Epoch 24, Batch 900] loss: 3.5712921850943325e-05
[Epoch 24, Batch 1000] loss: 2.8915281151462578e-05
[Epoch 24, Batch 1100] loss: 4.440935823057046e-05
[Epoch 24, Batch 1200] loss: 2.9729668949989297e-05
[Epoch 24, Batch 1300] loss: 1.7128298816486697e-05
[Epoch 24, Batch 1400] loss: 2.1695947421700447e-05
[Epoch 24, Batch 1500] loss: 2.197809804290074e-05
[Epoch 24, Batch 1600] loss: 1.5645791150902254e-05
[Epoch 24, Batch 1700] loss: 1.8419179986670642e-05
[Epoch 24, Batch 1800] loss: 1.661577204332243e-05
**STATS for Epoch 24** : 
Average training loss: 0.0000
Average validation loss: 0.0747
Validation Accuracy: 0.9899
Overfitting: 0.0747
Fold 1 validation loss: 0.0747
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 1.7540818679332733
[Epoch 1, Batch 200] loss: 0.5997626956924796
[Epoch 1, Batch 300] loss: 0.3594993272796273
[Epoch 1, Batch 400] loss: 0.2521660243719816
[Epoch 1, Batch 500] loss: 0.2044851763546467
[Epoch 1, Batch 600] loss: 0.19877494333311915
[Epoch 1, Batch 700] loss: 0.23845164055237547
[Epoch 1, Batch 800] loss: 0.16803512685000896
[Epoch 1, Batch 900] loss: 0.16550111746881158
[Epoch 1, Batch 1000] loss: 0.12851872454280966
[Epoch 1, Batch 1100] loss: 0.1394447494717315
[Epoch 1, Batch 1200] loss: 0.14635088107548655
[Epoch 1, Batch 1300] loss: 0.13520443101180718
[Epoch 1, Batch 1400] loss: 0.14261587701970713
[Epoch 1, Batch 1500] loss: 0.0817712461319752
[Epoch 1, Batch 1600] loss: 0.10698330396320671
[Epoch 1, Batch 1700] loss: 0.09013728601159528
[Epoch 1, Batch 1800] loss: 0.09095967204324552
**STATS for Epoch 1** : 
Average training loss: 0.0037
Average validation loss: 0.1091
Validation Accuracy: 0.9653
Overfitting: 0.1054
Best model saved at epoch 1 with validation loss: 0.1091
[Epoch 2, Batch 100] loss: 0.08357508601038717
[Epoch 2, Batch 200] loss: 0.09470032360797631
[Epoch 2, Batch 300] loss: 0.09005957392801064
[Epoch 2, Batch 400] loss: 0.09133734879549593
[Epoch 2, Batch 500] loss: 0.07146398914890596
[Epoch 2, Batch 600] loss: 0.07603691344615073
[Epoch 2, Batch 700] loss: 0.07828893817728386
[Epoch 2, Batch 800] loss: 0.0816399887308944
[Epoch 2, Batch 900] loss: 0.058980577226320746
[Epoch 2, Batch 1000] loss: 0.05177459592348896
[Epoch 2, Batch 1100] loss: 0.07987596244915039
[Epoch 2, Batch 1200] loss: 0.08326783460332081
[Epoch 2, Batch 1300] loss: 0.07008697849931195
[Epoch 2, Batch 1400] loss: 0.07534876086807345
[Epoch 2, Batch 1500] loss: 0.05970674287586007
[Epoch 2, Batch 1600] loss: 0.08555210601101862
[Epoch 2, Batch 1700] loss: 0.05877220950613264
[Epoch 2, Batch 1800] loss: 0.06440552981192013
**STATS for Epoch 2** : 
Average training loss: 0.0022
Average validation loss: 0.0617
Validation Accuracy: 0.9815
Overfitting: 0.0595
Best model saved at epoch 2 with validation loss: 0.0617
[Epoch 3, Batch 100] loss: 0.06606920015750802
[Epoch 3, Batch 200] loss: 0.04920935900241602
[Epoch 3, Batch 300] loss: 0.054441249976080144
[Epoch 3, Batch 400] loss: 0.04087375844723283
[Epoch 3, Batch 500] loss: 0.04617828780799755
[Epoch 3, Batch 600] loss: 0.0540794964019733
[Epoch 3, Batch 700] loss: 0.06804858369636349
[Epoch 3, Batch 800] loss: 0.049485935041157066
[Epoch 3, Batch 900] loss: 0.03614292638791085
[Epoch 3, Batch 1000] loss: 0.05298823332792381
[Epoch 3, Batch 1100] loss: 0.05237108000699663
[Epoch 3, Batch 1200] loss: 0.06750328497568261
[Epoch 3, Batch 1300] loss: 0.06684144872255274
[Epoch 3, Batch 1400] loss: 0.04830603880996932
[Epoch 3, Batch 1500] loss: 0.061477294795622583
[Epoch 3, Batch 1600] loss: 0.0396696866810089
[Epoch 3, Batch 1700] loss: 0.06267759862450475
[Epoch 3, Batch 1800] loss: 0.049603174926596695
**STATS for Epoch 3** : 
Average training loss: 0.0020
Average validation loss: 0.0572
Validation Accuracy: 0.9831
Overfitting: 0.0553
Best model saved at epoch 3 with validation loss: 0.0572
[Epoch 4, Batch 100] loss: 0.035073308112478115
[Epoch 4, Batch 200] loss: 0.0530467542299084
[Epoch 4, Batch 300] loss: 0.034669528148078825
[Epoch 4, Batch 400] loss: 0.03377903836010773
[Epoch 4, Batch 500] loss: 0.0323167178759104
[Epoch 4, Batch 600] loss: 0.033573110511642884
[Epoch 4, Batch 700] loss: 0.043235431704106306
[Epoch 4, Batch 800] loss: 0.037305277708364885
[Epoch 4, Batch 900] loss: 0.06161271700733778
[Epoch 4, Batch 1000] loss: 0.0338474834328008
[Epoch 4, Batch 1100] loss: 0.05280818726587313
[Epoch 4, Batch 1200] loss: 0.03310351873100444
[Epoch 4, Batch 1300] loss: 0.03721109223039093
[Epoch 4, Batch 1400] loss: 0.04121805164992111
[Epoch 4, Batch 1500] loss: 0.05615709619356494
[Epoch 4, Batch 1600] loss: 0.042051924392508225
[Epoch 4, Batch 1700] loss: 0.04186816135344998
[Epoch 4, Batch 1800] loss: 0.0427815211944835
**STATS for Epoch 4** : 
Average training loss: 0.0013
Average validation loss: 0.0529
Validation Accuracy: 0.9842
Overfitting: 0.0517
Best model saved at epoch 4 with validation loss: 0.0529
[Epoch 5, Batch 100] loss: 0.03534063533312292
[Epoch 5, Batch 200] loss: 0.024393296401394763
[Epoch 5, Batch 300] loss: 0.02580632872928618
[Epoch 5, Batch 400] loss: 0.030924367753759726
[Epoch 5, Batch 500] loss: 0.02722832869247668
[Epoch 5, Batch 600] loss: 0.021191908151104145
[Epoch 5, Batch 700] loss: 0.027270695092229288
[Epoch 5, Batch 800] loss: 0.05698746908383327
[Epoch 5, Batch 900] loss: 0.02307307598879561
[Epoch 5, Batch 1000] loss: 0.04870978955157625
[Epoch 5, Batch 1100] loss: 0.03066773772340639
[Epoch 5, Batch 1200] loss: 0.017685593255064306
[Epoch 5, Batch 1300] loss: 0.0456405713179629
[Epoch 5, Batch 1400] loss: 0.0191007783576606
[Epoch 5, Batch 1500] loss: 0.03325608106861182
[Epoch 5, Batch 1600] loss: 0.028622995233199618
[Epoch 5, Batch 1700] loss: 0.04634862846913165
[Epoch 5, Batch 1800] loss: 0.038212859761915755
**STATS for Epoch 5** : 
Average training loss: 0.0014
Average validation loss: 0.0494
Validation Accuracy: 0.9860
Overfitting: 0.0480
Best model saved at epoch 5 with validation loss: 0.0494
[Epoch 6, Batch 100] loss: 0.017729793007438276
[Epoch 6, Batch 200] loss: 0.014638885631702578
[Epoch 6, Batch 300] loss: 0.013362145177529783
[Epoch 6, Batch 400] loss: 0.02818189018529665
[Epoch 6, Batch 500] loss: 0.01642386840846484
[Epoch 6, Batch 600] loss: 0.026165220494935967
[Epoch 6, Batch 700] loss: 0.009248769568480385
[Epoch 6, Batch 800] loss: 0.01144254275637877
[Epoch 6, Batch 900] loss: 0.021554980882415295
[Epoch 6, Batch 1000] loss: 0.031234284692920937
[Epoch 6, Batch 1100] loss: 0.031085776048994377
[Epoch 6, Batch 1200] loss: 0.014358944477016848
[Epoch 6, Batch 1300] loss: 0.02623536156753289
[Epoch 6, Batch 1400] loss: 0.027523785446428518
[Epoch 6, Batch 1500] loss: 0.02153306040177995
[Epoch 6, Batch 1600] loss: 0.019524167491458685
[Epoch 6, Batch 1700] loss: 0.033870679217297944
[Epoch 6, Batch 1800] loss: 0.030677051128368476
**STATS for Epoch 6** : 
Average training loss: 0.0019
Average validation loss: 0.0557
Validation Accuracy: 0.9854
Overfitting: 0.0538
[Epoch 7, Batch 100] loss: 0.021599744866616675
[Epoch 7, Batch 200] loss: 0.016485776851168338
[Epoch 7, Batch 300] loss: 0.010254933857431751
[Epoch 7, Batch 400] loss: 0.018269367709151538
[Epoch 7, Batch 500] loss: 0.015284608710257998
[Epoch 7, Batch 600] loss: 0.010169640853507644
[Epoch 7, Batch 700] loss: 0.013143601850360937
[Epoch 7, Batch 800] loss: 0.01682560716610624
[Epoch 7, Batch 900] loss: 0.014371983204418938
[Epoch 7, Batch 1000] loss: 0.025649172561904833
[Epoch 7, Batch 1100] loss: 0.037365739982583364
[Epoch 7, Batch 1200] loss: 0.019328045818153897
[Epoch 7, Batch 1300] loss: 0.04053880833113908
[Epoch 7, Batch 1400] loss: 0.01941905253922414
[Epoch 7, Batch 1500] loss: 0.04805805477963531
[Epoch 7, Batch 1600] loss: 0.040574591326367225
[Epoch 7, Batch 1700] loss: 0.02588007260188533
[Epoch 7, Batch 1800] loss: 0.015003588184054024
**STATS for Epoch 7** : 
Average training loss: 0.0016
Average validation loss: 0.0569
Validation Accuracy: 0.9846
Overfitting: 0.0552
[Epoch 8, Batch 100] loss: 0.013405726372811842
[Epoch 8, Batch 200] loss: 0.019443980941377958
[Epoch 8, Batch 300] loss: 0.023871162928003287
[Epoch 8, Batch 400] loss: 0.019511201268210245
[Epoch 8, Batch 500] loss: 0.018391515836065082
[Epoch 8, Batch 600] loss: 0.032010756279973976
[Epoch 8, Batch 700] loss: 0.03191269014154386
[Epoch 8, Batch 800] loss: 0.008854552702226784
[Epoch 8, Batch 900] loss: 0.0302009650736386
[Epoch 8, Batch 1000] loss: 0.01818272727853355
[Epoch 8, Batch 1100] loss: 0.020471922794949932
[Epoch 8, Batch 1200] loss: 0.01865323066705059
[Epoch 8, Batch 1300] loss: 0.013858683935416139
[Epoch 8, Batch 1400] loss: 0.012647982610108102
[Epoch 8, Batch 1500] loss: 0.013204612286970133
[Epoch 8, Batch 1600] loss: 0.014837211943276998
[Epoch 8, Batch 1700] loss: 0.016612873476710775
[Epoch 8, Batch 1800] loss: 0.04780638162849755
**STATS for Epoch 8** : 
Average training loss: 0.0013
Average validation loss: 0.0591
Validation Accuracy: 0.9838
Overfitting: 0.0578
[Epoch 9, Batch 100] loss: 0.011869693707492388
[Epoch 9, Batch 200] loss: 0.01716101788643982
[Epoch 9, Batch 300] loss: 0.0042964446213608195
[Epoch 9, Batch 400] loss: 0.01896125134531985
[Epoch 9, Batch 500] loss: 0.012324677308538413
[Epoch 9, Batch 600] loss: 0.007667600469162607
[Epoch 9, Batch 700] loss: 0.009022721455927467
[Epoch 9, Batch 800] loss: 0.018740038973600263
[Epoch 9, Batch 900] loss: 0.02487952504326927
[Epoch 9, Batch 1000] loss: 0.012734175056417598
[Epoch 9, Batch 1100] loss: 0.01910615264123919
[Epoch 9, Batch 1200] loss: 0.011190279964552588
[Epoch 9, Batch 1300] loss: 0.021596386193132276
[Epoch 9, Batch 1400] loss: 0.03243445752714706
[Epoch 9, Batch 1500] loss: 0.01926301067706845
[Epoch 9, Batch 1600] loss: 0.034003113020681895
[Epoch 9, Batch 1700] loss: 0.017215064308797993
[Epoch 9, Batch 1800] loss: 0.01192772860434161
**STATS for Epoch 9** : 
Average training loss: 0.0008
Average validation loss: 0.0602
Validation Accuracy: 0.9857
Overfitting: 0.0594
[Epoch 10, Batch 100] loss: 0.0075000161435571045
[Epoch 10, Batch 200] loss: 0.016244616785257335
[Epoch 10, Batch 300] loss: 0.002784426432869509
[Epoch 10, Batch 400] loss: 0.021512123106474518
[Epoch 10, Batch 500] loss: 0.016475287774310347
[Epoch 10, Batch 600] loss: 0.01420042924104564
[Epoch 10, Batch 700] loss: 0.010438209939927532
[Epoch 10, Batch 800] loss: 0.020287393434299476
[Epoch 10, Batch 900] loss: 0.035456490854413686
[Epoch 10, Batch 1000] loss: 0.026319671348755947
[Epoch 10, Batch 1100] loss: 0.009417288793900412
[Epoch 10, Batch 1200] loss: 0.010305644061610338
[Epoch 10, Batch 1300] loss: 0.008354320047433248
[Epoch 10, Batch 1400] loss: 0.019407504534576674
[Epoch 10, Batch 1500] loss: 0.02611312320057378
[Epoch 10, Batch 1600] loss: 0.02263061751540988
[Epoch 10, Batch 1700] loss: 0.025205084610937546
[Epoch 10, Batch 1800] loss: 0.016809368228796303
**STATS for Epoch 10** : 
Average training loss: 0.0003
Average validation loss: 0.0575
Validation Accuracy: 0.9861
Overfitting: 0.0571
[Epoch 11, Batch 100] loss: 0.002978182331442838
[Epoch 11, Batch 200] loss: 0.002691143348706007
[Epoch 11, Batch 300] loss: 0.0020922938441087524
[Epoch 11, Batch 400] loss: 0.007572725864324017
[Epoch 11, Batch 500] loss: 0.004970070662014301
[Epoch 11, Batch 600] loss: 0.01865367757945478
[Epoch 11, Batch 700] loss: 0.011961014389357842
[Epoch 11, Batch 800] loss: 0.013893874390869882
[Epoch 11, Batch 900] loss: 0.005856792205801753
[Epoch 11, Batch 1000] loss: 0.0159244002498437
[Epoch 11, Batch 1100] loss: 0.015550594188800915
[Epoch 11, Batch 1200] loss: 0.008792809082086706
[Epoch 11, Batch 1300] loss: 0.01874680999116947
[Epoch 11, Batch 1400] loss: 0.018425509819934262
[Epoch 11, Batch 1500] loss: 0.011403642700939827
[Epoch 11, Batch 1600] loss: 0.011318181866523674
[Epoch 11, Batch 1700] loss: 0.02599750838871671
[Epoch 11, Batch 1800] loss: 0.004926665075903998
**STATS for Epoch 11** : 
Average training loss: 0.0005
Average validation loss: 0.0595
Validation Accuracy: 0.9865
Overfitting: 0.0590
[Epoch 12, Batch 100] loss: 0.015977455406125784
[Epoch 12, Batch 200] loss: 0.004340012972992753
[Epoch 12, Batch 300] loss: 0.0072908232941966845
[Epoch 12, Batch 400] loss: 0.008786463852057978
[Epoch 12, Batch 500] loss: 0.005169060423737655
[Epoch 12, Batch 600] loss: 0.015554944343966924
[Epoch 12, Batch 700] loss: 0.02472615951582867
[Epoch 12, Batch 800] loss: 0.014859049847121924
[Epoch 12, Batch 900] loss: 0.020403042393064653
[Epoch 12, Batch 1000] loss: 0.03282055550911536
[Epoch 12, Batch 1100] loss: 0.03594270488363236
[Epoch 12, Batch 1200] loss: 0.02157166317415431
[Epoch 12, Batch 1300] loss: 0.025678499415864735
[Epoch 12, Batch 1400] loss: 0.0179021733072193
[Epoch 12, Batch 1500] loss: 0.002967896840274449
[Epoch 12, Batch 1600] loss: 0.008275954787271757
[Epoch 12, Batch 1700] loss: 0.02415753623776709
[Epoch 12, Batch 1800] loss: 0.021251409714259352
**STATS for Epoch 12** : 
Average training loss: 0.0011
Average validation loss: 0.0693
Validation Accuracy: 0.9844
Overfitting: 0.0682
[Epoch 13, Batch 100] loss: 0.011757607065301273
[Epoch 13, Batch 200] loss: 0.005884244004806476
[Epoch 13, Batch 300] loss: 0.012103422805337232
[Epoch 13, Batch 400] loss: 0.003812197652377307
[Epoch 13, Batch 500] loss: 0.004416915763441835
[Epoch 13, Batch 600] loss: 0.009552081311236976
[Epoch 13, Batch 700] loss: 0.018180087138040476
[Epoch 13, Batch 800] loss: 0.007973156009446996
[Epoch 13, Batch 900] loss: 0.0045372483212628364
[Epoch 13, Batch 1000] loss: 0.00917628659001366
[Epoch 13, Batch 1100] loss: 0.006079709001722762
[Epoch 13, Batch 1200] loss: 0.010848430201122632
[Epoch 13, Batch 1300] loss: 0.0067893204469123706
[Epoch 13, Batch 1400] loss: 0.0069315234054363375
[Epoch 13, Batch 1500] loss: 0.018349687461426924
[Epoch 13, Batch 1600] loss: 0.020156807620270438
[Epoch 13, Batch 1700] loss: 0.012094601372644433
[Epoch 13, Batch 1800] loss: 0.01122506121810659
**STATS for Epoch 13** : 
Average training loss: 0.0001
Average validation loss: 0.0571
Validation Accuracy: 0.9873
Overfitting: 0.0570
[Epoch 14, Batch 100] loss: 0.005549561645104859
[Epoch 14, Batch 200] loss: 0.007958725212401986
[Epoch 14, Batch 300] loss: 0.00529218689709694
[Epoch 14, Batch 400] loss: 0.015097288358381889
[Epoch 14, Batch 500] loss: 0.0008556432085517684
[Epoch 14, Batch 600] loss: 0.007965319570634222
[Epoch 14, Batch 700] loss: 0.01429751733998387
[Epoch 14, Batch 800] loss: 0.010438432315967177
[Epoch 14, Batch 900] loss: 0.013470886971986572
[Epoch 14, Batch 1000] loss: 0.028349399787457513
[Epoch 14, Batch 1100] loss: 0.01202723789204299
[Epoch 14, Batch 1200] loss: 0.014706565036183577
[Epoch 14, Batch 1300] loss: 0.027345361827647706
[Epoch 14, Batch 1400] loss: 0.013306543529236024
[Epoch 14, Batch 1500] loss: 0.010482111616067762
[Epoch 14, Batch 1600] loss: 0.01715704214971538
[Epoch 14, Batch 1700] loss: 0.02069400686748395
[Epoch 14, Batch 1800] loss: 0.020458676147218854
**STATS for Epoch 14** : 
Average training loss: 0.0007
Average validation loss: 0.0628
Validation Accuracy: 0.9854
Overfitting: 0.0621
[Epoch 15, Batch 100] loss: 0.011736047791750935
[Epoch 15, Batch 200] loss: 0.008506231931997803
[Epoch 15, Batch 300] loss: 0.006184510002642405
[Epoch 15, Batch 400] loss: 0.017669651611765928
[Epoch 15, Batch 500] loss: 0.012832204213810882
[Epoch 15, Batch 600] loss: 0.012598603669601117
[Epoch 15, Batch 700] loss: 0.011351984767165604
[Epoch 15, Batch 800] loss: 0.004396951791403012
[Epoch 15, Batch 900] loss: 0.008129193847670564
[Epoch 15, Batch 1000] loss: 0.004644368837340025
[Epoch 15, Batch 1100] loss: 0.00139217738138381
[Epoch 15, Batch 1200] loss: 0.0016654654685644265
[Epoch 15, Batch 1300] loss: 0.003902268653733358
[Epoch 15, Batch 1400] loss: 0.0014320196432687205
[Epoch 15, Batch 1500] loss: 0.001380672482320655
[Epoch 15, Batch 1600] loss: 0.001705485558996962
[Epoch 15, Batch 1700] loss: 0.015077497770361296
[Epoch 15, Batch 1800] loss: 0.011363356113974703
**STATS for Epoch 15** : 
Average training loss: 0.0002
Average validation loss: 0.0683
Validation Accuracy: 0.9867
Overfitting: 0.0681
[Epoch 16, Batch 100] loss: 0.00559847061192162
[Epoch 16, Batch 200] loss: 0.01033049495769946
[Epoch 16, Batch 300] loss: 0.018481854840972218
[Epoch 16, Batch 400] loss: 0.007343873493119872
[Epoch 16, Batch 500] loss: 0.00928381891956228
[Epoch 16, Batch 600] loss: 0.006585760569959467
[Epoch 16, Batch 700] loss: 0.005181817571417895
[Epoch 16, Batch 800] loss: 0.0231933579500901
[Epoch 16, Batch 900] loss: 0.0067733185493767676
[Epoch 16, Batch 1000] loss: 0.007060423194856753
[Epoch 16, Batch 1100] loss: 0.007809674050949549
[Epoch 16, Batch 1200] loss: 0.006180868252874911
[Epoch 16, Batch 1300] loss: 0.013162780143054817
[Epoch 16, Batch 1400] loss: 0.016752070714306053
[Epoch 16, Batch 1500] loss: 0.046054499974975016
[Epoch 16, Batch 1600] loss: 0.024399201824385555
[Epoch 16, Batch 1700] loss: 0.01535226908327047
[Epoch 16, Batch 1800] loss: 0.017086621399319598
**STATS for Epoch 16** : 
Average training loss: 0.0008
Average validation loss: 0.0775
Validation Accuracy: 0.9833
Overfitting: 0.0767
[Epoch 17, Batch 100] loss: 0.011487650034805555
[Epoch 17, Batch 200] loss: 0.008033950747952332
[Epoch 17, Batch 300] loss: 0.006883767268131394
[Epoch 17, Batch 400] loss: 0.01034729340134647
[Epoch 17, Batch 500] loss: 0.009848894509839496
[Epoch 17, Batch 600] loss: 0.010515798005900532
[Epoch 17, Batch 700] loss: 0.008540728872692612
[Epoch 17, Batch 800] loss: 0.015068089355775883
[Epoch 17, Batch 900] loss: 0.01168548998095929
[Epoch 17, Batch 1000] loss: 0.010553193733914555
[Epoch 17, Batch 1100] loss: 0.012100937333668753
[Epoch 17, Batch 1200] loss: 0.01620437617887684
[Epoch 17, Batch 1300] loss: 0.02160684656147847
[Epoch 17, Batch 1400] loss: 0.01953173779677769
[Epoch 17, Batch 1500] loss: 0.012724278314435794
[Epoch 17, Batch 1600] loss: 0.003572056422499088
[Epoch 17, Batch 1700] loss: 0.024192504558031444
[Epoch 17, Batch 1800] loss: 0.01911271144617402
**STATS for Epoch 17** : 
Average training loss: 0.0004
Average validation loss: 0.0734
Validation Accuracy: 0.9847
Overfitting: 0.0730
[Epoch 18, Batch 100] loss: 0.009933737187519682
[Epoch 18, Batch 200] loss: 0.00240424284427732
[Epoch 18, Batch 300] loss: 0.009002166596931128
[Epoch 18, Batch 400] loss: 0.003103897096090691
[Epoch 18, Batch 500] loss: 0.006093793203251891
[Epoch 18, Batch 600] loss: 0.003938595106610663
[Epoch 18, Batch 700] loss: 0.005625238316309371
[Epoch 18, Batch 800] loss: 0.009914285024181381
[Epoch 18, Batch 900] loss: 0.004644327385341707
[Epoch 18, Batch 1000] loss: 0.011097664809046953
[Epoch 18, Batch 1100] loss: 0.009705957630372838
[Epoch 18, Batch 1200] loss: 0.020112351641425826
[Epoch 18, Batch 1300] loss: 0.024457343694884674
[Epoch 18, Batch 1400] loss: 0.01880448176274312
[Epoch 18, Batch 1500] loss: 0.03632936200425945
[Epoch 18, Batch 1600] loss: 0.007890799241708279
[Epoch 18, Batch 1700] loss: 0.007281412784120192
[Epoch 18, Batch 1800] loss: 0.009329887790718501
**STATS for Epoch 18** : 
Average training loss: 0.0008
Average validation loss: 0.0729
Validation Accuracy: 0.9846
Overfitting: 0.0721
[Epoch 19, Batch 100] loss: 0.006695631612210598
[Epoch 19, Batch 200] loss: 0.006530233985253595
[Epoch 19, Batch 300] loss: 0.015383523715829517
[Epoch 19, Batch 400] loss: 0.006277062566355482
[Epoch 19, Batch 500] loss: 0.027141218536845972
[Epoch 19, Batch 600] loss: 0.004331405989861797
[Epoch 19, Batch 700] loss: 0.020358864591884632
[Epoch 19, Batch 800] loss: 0.02329194139027656
[Epoch 19, Batch 900] loss: 0.0073321366215787975
[Epoch 19, Batch 1000] loss: 0.012487162557276292
[Epoch 19, Batch 1100] loss: 0.010936892858491304
[Epoch 19, Batch 1200] loss: 0.012728781009282032
[Epoch 19, Batch 1300] loss: 0.0023348869852638596
[Epoch 19, Batch 1400] loss: 0.0012613215103942465
[Epoch 19, Batch 1500] loss: 0.0012627010533515426
[Epoch 19, Batch 1600] loss: 0.005675575577264152
[Epoch 19, Batch 1700] loss: 0.012978772199538469
[Epoch 19, Batch 1800] loss: 0.007371810521979771
**STATS for Epoch 19** : 
Average training loss: 0.0005
Average validation loss: 0.0920
Validation Accuracy: 0.9822
Overfitting: 0.0915
[Epoch 20, Batch 100] loss: 0.02025263656382925
[Epoch 20, Batch 200] loss: 0.007386512732495482
[Epoch 20, Batch 300] loss: 0.004779699684420038
[Epoch 20, Batch 400] loss: 0.003647075290564259
[Epoch 20, Batch 500] loss: 0.004218876991306546
[Epoch 20, Batch 600] loss: 0.00449851613277449
[Epoch 20, Batch 700] loss: 0.01087694899595686
[Epoch 20, Batch 800] loss: 0.024294907927969688
[Epoch 20, Batch 900] loss: 0.008379589768407242
[Epoch 20, Batch 1000] loss: 0.005678785654403508
[Epoch 20, Batch 1100] loss: 0.004481634657409188
[Epoch 20, Batch 1200] loss: 0.007941851756468696
[Epoch 20, Batch 1300] loss: 0.019353527477015034
[Epoch 20, Batch 1400] loss: 0.002094514061625379
[Epoch 20, Batch 1500] loss: 0.0036192274776908383
[Epoch 20, Batch 1600] loss: 0.001380566254150075
[Epoch 20, Batch 1700] loss: 0.002641495399335376
[Epoch 20, Batch 1800] loss: 0.0007545346061937153
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0683
Validation Accuracy: 0.9874
Overfitting: 0.0681
[Epoch 21, Batch 100] loss: 0.0008676663881504165
[Epoch 21, Batch 200] loss: 0.005240556385976838
[Epoch 21, Batch 300] loss: 0.007020317607024924
[Epoch 21, Batch 400] loss: 0.012086544325562758
[Epoch 21, Batch 500] loss: 0.002825466940976744
[Epoch 21, Batch 600] loss: 0.001640580821667177
[Epoch 21, Batch 700] loss: 0.012700736141220829
[Epoch 21, Batch 800] loss: 0.010352694868364303
[Epoch 21, Batch 900] loss: 0.003501744719969224
[Epoch 21, Batch 1000] loss: 0.006536104197626873
[Epoch 21, Batch 1100] loss: 0.00342296205974312
[Epoch 21, Batch 1200] loss: 0.0022575872106561333
[Epoch 21, Batch 1300] loss: 0.0019724317040215487
[Epoch 21, Batch 1400] loss: 0.0035450572668002155
[Epoch 21, Batch 1500] loss: 0.007069271199003326
[Epoch 21, Batch 1600] loss: 0.007648694995959167
[Epoch 21, Batch 1700] loss: 0.003488870448139032
[Epoch 21, Batch 1800] loss: 0.005969011539162654
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0660
Validation Accuracy: 0.9882
Overfitting: 0.0660
[Epoch 22, Batch 100] loss: 0.011841435612510848
[Epoch 22, Batch 200] loss: 0.0051998421077451605
[Epoch 22, Batch 300] loss: 0.0036629638563537227
[Epoch 22, Batch 400] loss: 0.0009528007276339512
[Epoch 22, Batch 500] loss: 0.000362314145392193
[Epoch 22, Batch 600] loss: 0.00041960481248535684
[Epoch 22, Batch 700] loss: 0.0007420850078249907
[Epoch 22, Batch 800] loss: 0.0004045744415578989
[Epoch 22, Batch 900] loss: 0.0002877260964101369
[Epoch 22, Batch 1000] loss: 0.00010972150053003559
[Epoch 22, Batch 1100] loss: 0.006544299645446694
[Epoch 22, Batch 1200] loss: 0.0021104667837888247
[Epoch 22, Batch 1300] loss: 0.005186873750454719
[Epoch 22, Batch 1400] loss: 0.008833660404232595
[Epoch 22, Batch 1500] loss: 0.008232237284148503
[Epoch 22, Batch 1600] loss: 0.005066315391852849
[Epoch 22, Batch 1700] loss: 0.001790746213595522
[Epoch 22, Batch 1800] loss: 0.007269236742426659
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0947
Validation Accuracy: 0.9849
Overfitting: 0.0944
[Epoch 23, Batch 100] loss: 0.012610577800203191
[Epoch 23, Batch 200] loss: 0.012280212153079928
[Epoch 23, Batch 300] loss: 0.007734068624632493
[Epoch 23, Batch 400] loss: 0.0014734889717180578
[Epoch 23, Batch 500] loss: 0.00165280697008102
[Epoch 23, Batch 600] loss: 0.0039541407786887195
[Epoch 23, Batch 700] loss: 0.00285789721606835
[Epoch 23, Batch 800] loss: 0.005662814051058831
[Epoch 23, Batch 900] loss: 0.004707229653089109
[Epoch 23, Batch 1000] loss: 0.0010461442575504742
[Epoch 23, Batch 1100] loss: 0.004423118944804711
[Epoch 23, Batch 1200] loss: 0.004157952307539365
[Epoch 23, Batch 1300] loss: 0.012005374799596367
[Epoch 23, Batch 1400] loss: 0.002495550855965436
[Epoch 23, Batch 1500] loss: 0.006722909808682829
[Epoch 23, Batch 1600] loss: 0.011446849038402904
[Epoch 23, Batch 1700] loss: 0.009685633996789225
[Epoch 23, Batch 1800] loss: 0.018143202663386485
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0703
Validation Accuracy: 0.9868
Overfitting: 0.0701
[Epoch 24, Batch 100] loss: 0.0017116707153801514
[Epoch 24, Batch 200] loss: 0.002187303207049327
[Epoch 24, Batch 300] loss: 0.004243042275477746
[Epoch 24, Batch 400] loss: 0.009561213037975231
[Epoch 24, Batch 500] loss: 0.004995820721565618
[Epoch 24, Batch 600] loss: 0.0131567523527508
[Epoch 24, Batch 700] loss: 0.0032576551668009523
[Epoch 24, Batch 800] loss: 0.0018234963774258306
[Epoch 24, Batch 900] loss: 0.00161202478973002
[Epoch 24, Batch 1000] loss: 0.0005842289526180178
[Epoch 24, Batch 1100] loss: 0.00031698670154685084
[Epoch 24, Batch 1200] loss: 0.002213495095184026
[Epoch 24, Batch 1300] loss: 0.0011695016402479652
[Epoch 24, Batch 1400] loss: 0.002377707779140441
[Epoch 24, Batch 1500] loss: 0.0075797308638402595
[Epoch 24, Batch 1600] loss: 0.047028156258522066
[Epoch 24, Batch 1700] loss: 0.00788342064267412
[Epoch 24, Batch 1800] loss: 0.036013378007145214
**STATS for Epoch 24** : 
Average training loss: 0.0003
Average validation loss: 0.0826
Validation Accuracy: 0.9849
Overfitting: 0.0823
Fold 2 validation loss: 0.0826
Mean validation loss across all folds for Trial 20 is 0.0787 with trial config:  l1: 256, l2: 64, lr: 0.0067544158230576, batch_size: 16
[I 2024-11-25 17:02:02,395] Trial 19 finished with value: 0.0786643258952388 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0067544158230576, 'batch_size': 16}. Best is trial 7 with value: 0.0582443055690866.

Selected Hyperparameters for Trial 21:
  l1: 128, l2: 128, lr: 0.009643481843156065, batch_size: 256
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 1.5936658668518067
**STATS for Epoch 1** : 
Average training loss: 0.0711
Average validation loss: 0.3611
Validation Accuracy: 0.8937
Overfitting: 0.2900
Best model saved at epoch 1 with validation loss: 0.3611
[Epoch 2, Batch 100] loss: 0.25450190782547
**STATS for Epoch 2** : 
Average training loss: 0.0275
Average validation loss: 0.1911
Validation Accuracy: 0.9391
Overfitting: 0.1636
Best model saved at epoch 2 with validation loss: 0.1911
[Epoch 3, Batch 100] loss: 0.14115991316735743
**STATS for Epoch 3** : 
Average training loss: 0.0175
Average validation loss: 0.1254
Validation Accuracy: 0.9611
Overfitting: 0.1079
Best model saved at epoch 3 with validation loss: 0.1254
[Epoch 4, Batch 100] loss: 0.10687829099595547
**STATS for Epoch 4** : 
Average training loss: 0.0157
Average validation loss: 0.0948
Validation Accuracy: 0.9698
Overfitting: 0.0791
Best model saved at epoch 4 with validation loss: 0.0948
[Epoch 5, Batch 100] loss: 0.08006579108536244
**STATS for Epoch 5** : 
Average training loss: 0.0123
Average validation loss: 0.0911
Validation Accuracy: 0.9707
Overfitting: 0.0788
Best model saved at epoch 5 with validation loss: 0.0911
[Epoch 6, Batch 100] loss: 0.0708191236667335
**STATS for Epoch 6** : 
Average training loss: 0.0098
Average validation loss: 0.0735
Validation Accuracy: 0.9760
Overfitting: 0.0637
[I 2024-11-25 17:03:05,448] Trial 20 pruned. 

Selected Hyperparameters for Trial 22:
  l1: 128, l2: 128, lr: 0.0021355157041571433, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.2922439098358156
[Epoch 1, Batch 200] loss: 2.1934975707530975
[Epoch 1, Batch 300] loss: 1.1537780559062958
[Epoch 1, Batch 400] loss: 0.533025014102459
[Epoch 1, Batch 500] loss: 0.45628589257597924
[Epoch 1, Batch 600] loss: 0.34783558078110216
[Epoch 1, Batch 700] loss: 0.2932073608785868
[Epoch 1, Batch 800] loss: 0.24991352342069148
[Epoch 1, Batch 900] loss: 0.2291274994239211
**STATS for Epoch 1** : 
Average training loss: 0.0086
Average validation loss: 0.1901
Validation Accuracy: 0.9420
Overfitting: 0.1815
Best model saved at epoch 1 with validation loss: 0.1901
[Epoch 2, Batch 100] loss: 0.1788771315664053
[Epoch 2, Batch 200] loss: 0.1582928092032671
[Epoch 2, Batch 300] loss: 0.1724541003536433
[Epoch 2, Batch 400] loss: 0.14655477682128548
[Epoch 2, Batch 500] loss: 0.13093978002667428
[Epoch 2, Batch 600] loss: 0.12463707600254566
[Epoch 2, Batch 700] loss: 0.1462945662345737
[Epoch 2, Batch 800] loss: 0.11545722262002528
[Epoch 2, Batch 900] loss: 0.12245084438938647
**STATS for Epoch 2** : 
Average training loss: 0.0049
Average validation loss: 0.1138
Validation Accuracy: 0.9651
Overfitting: 0.1088
Best model saved at epoch 2 with validation loss: 0.1138
[Epoch 3, Batch 100] loss: 0.10661775567568839
[Epoch 3, Batch 200] loss: 0.10433576628565788
[Epoch 3, Batch 300] loss: 0.08815986419096589
[Epoch 3, Batch 400] loss: 0.0905567350774072
[Epoch 3, Batch 500] loss: 0.08736951744183898
[Epoch 3, Batch 600] loss: 0.10462860109750181
[Epoch 3, Batch 700] loss: 0.09817367720417679
[Epoch 3, Batch 800] loss: 0.08192515534348786
[Epoch 3, Batch 900] loss: 0.09476448738947511
**STATS for Epoch 3** : 
Average training loss: 0.0044
Average validation loss: 0.0880
Validation Accuracy: 0.9721
Overfitting: 0.0836
Best model saved at epoch 3 with validation loss: 0.0880
[Epoch 4, Batch 100] loss: 0.07393983018584549
[Epoch 4, Batch 200] loss: 0.0700693508819677
[Epoch 4, Batch 300] loss: 0.08219558314187453
[Epoch 4, Batch 400] loss: 0.06820871119736693
[Epoch 4, Batch 500] loss: 0.07833449390949682
[Epoch 4, Batch 600] loss: 0.08024900682736189
[Epoch 4, Batch 700] loss: 0.0681542116543278
[Epoch 4, Batch 800] loss: 0.07106823511421681
[Epoch 4, Batch 900] loss: 0.07719757268205285
**STATS for Epoch 4** : 
Average training loss: 0.0030
Average validation loss: 0.0716
Validation Accuracy: 0.9779
Overfitting: 0.0687
Best model saved at epoch 4 with validation loss: 0.0716
[Epoch 5, Batch 100] loss: 0.06308033946435898
[Epoch 5, Batch 200] loss: 0.05733585379552096
[Epoch 5, Batch 300] loss: 0.05479724473902024
[Epoch 5, Batch 400] loss: 0.0667998900078237
[Epoch 5, Batch 500] loss: 0.06722295369021594
[Epoch 5, Batch 600] loss: 0.05433962789364159
[Epoch 5, Batch 700] loss: 0.05375891731237061
[Epoch 5, Batch 800] loss: 0.05768515039351769
[Epoch 5, Batch 900] loss: 0.05876010260777548
**STATS for Epoch 5** : 
Average training loss: 0.0016
Average validation loss: 0.0703
Validation Accuracy: 0.9779
Overfitting: 0.0687
Best model saved at epoch 5 with validation loss: 0.0703
[Epoch 6, Batch 100] loss: 0.05181527884677053
[Epoch 6, Batch 200] loss: 0.05011756676365622
[Epoch 6, Batch 300] loss: 0.040095384623855354
[Epoch 6, Batch 400] loss: 0.04443768404657021
[Epoch 6, Batch 500] loss: 0.042316372942586895
[Epoch 6, Batch 600] loss: 0.04478516103408765
[Epoch 6, Batch 700] loss: 0.04993993077427149
[Epoch 6, Batch 800] loss: 0.05545210279989988
[Epoch 6, Batch 900] loss: 0.050598665000870825
**STATS for Epoch 6** : 
Average training loss: 0.0018
Average validation loss: 0.0582
Validation Accuracy: 0.9816
Overfitting: 0.0564
Best model saved at epoch 6 with validation loss: 0.0582
[Epoch 7, Batch 100] loss: 0.04893477413454093
[Epoch 7, Batch 200] loss: 0.03664224574808031
[Epoch 7, Batch 300] loss: 0.04593610735872062
[Epoch 7, Batch 400] loss: 0.03656319747038651
[Epoch 7, Batch 500] loss: 0.041835241643711926
[Epoch 7, Batch 600] loss: 0.03742973035128671
[Epoch 7, Batch 700] loss: 0.041224173360533314
[Epoch 7, Batch 800] loss: 0.03624547497136518
[Epoch 7, Batch 900] loss: 0.038049652549962044
**STATS for Epoch 7** : 
Average training loss: 0.0016
Average validation loss: 0.0653
Validation Accuracy: 0.9802
Overfitting: 0.0637
[Epoch 8, Batch 100] loss: 0.02943249092262704
[Epoch 8, Batch 200] loss: 0.02971265322295949
[Epoch 8, Batch 300] loss: 0.03336938462482067
[Epoch 8, Batch 400] loss: 0.03506574831320904
[Epoch 8, Batch 500] loss: 0.042220030240132475
[Epoch 8, Batch 600] loss: 0.03240249270456843
[Epoch 8, Batch 700] loss: 0.03693709903222043
[Epoch 8, Batch 800] loss: 0.04252388423774391
[Epoch 8, Batch 900] loss: 0.03132111870945664
**STATS for Epoch 8** : 
Average training loss: 0.0016
Average validation loss: 0.0656
Validation Accuracy: 0.9800
Overfitting: 0.0640
[Epoch 9, Batch 100] loss: 0.027645397075393704
[Epoch 9, Batch 200] loss: 0.023140081946912687
[Epoch 9, Batch 300] loss: 0.021022916571382666
[Epoch 9, Batch 400] loss: 0.03658846561564132
[Epoch 9, Batch 500] loss: 0.029610809913720004
[Epoch 9, Batch 600] loss: 0.021625313242257107
[Epoch 9, Batch 700] loss: 0.02465078921057284
[Epoch 9, Batch 800] loss: 0.02673876974993618
[Epoch 9, Batch 900] loss: 0.044027676611440254
**STATS for Epoch 9** : 
Average training loss: 0.0009
Average validation loss: 0.0578
Validation Accuracy: 0.9826
Overfitting: 0.0569
Best model saved at epoch 9 with validation loss: 0.0578
[Epoch 10, Batch 100] loss: 0.020651498758234084
[Epoch 10, Batch 200] loss: 0.01824244810821256
[Epoch 10, Batch 300] loss: 0.027263237522129204
[Epoch 10, Batch 400] loss: 0.027259517284692267
[Epoch 10, Batch 500] loss: 0.020834124217071804
[Epoch 10, Batch 600] loss: 0.02415603344750707
[Epoch 10, Batch 700] loss: 0.027488665067066903
[Epoch 10, Batch 800] loss: 0.01913260074215941
[Epoch 10, Batch 900] loss: 0.03722748979460448
**STATS for Epoch 10** : 
Average training loss: 0.0008
Average validation loss: 0.0542
Validation Accuracy: 0.9839
Overfitting: 0.0533
Best model saved at epoch 10 with validation loss: 0.0542
[Epoch 11, Batch 100] loss: 0.016220617731451056
[Epoch 11, Batch 200] loss: 0.015688997464203568
[Epoch 11, Batch 300] loss: 0.028002901862273576
[Epoch 11, Batch 400] loss: 0.026575311113301723
[Epoch 11, Batch 500] loss: 0.023199521875940262
[Epoch 11, Batch 600] loss: 0.024243161949707426
[Epoch 11, Batch 700] loss: 0.024376179871178464
[Epoch 11, Batch 800] loss: 0.018732565461868945
[Epoch 11, Batch 900] loss: 0.028539266463194508
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0596
Validation Accuracy: 0.9826
Overfitting: 0.0587
[Epoch 12, Batch 100] loss: 0.020685345442325344
[Epoch 12, Batch 200] loss: 0.012064295545351343
[Epoch 12, Batch 300] loss: 0.02240097131085349
[Epoch 12, Batch 400] loss: 0.02212582419422688
[Epoch 12, Batch 500] loss: 0.021068327745269927
[Epoch 12, Batch 600] loss: 0.020735460536379834
[Epoch 12, Batch 700] loss: 0.02202474903780967
[Epoch 12, Batch 800] loss: 0.012659920533842524
[Epoch 12, Batch 900] loss: 0.017057512180836055
**STATS for Epoch 12** : 
Average training loss: 0.0008
Average validation loss: 0.0599
Validation Accuracy: 0.9831
Overfitting: 0.0590
[Epoch 13, Batch 100] loss: 0.01398271942147403
[Epoch 13, Batch 200] loss: 0.01319355041050585
[Epoch 13, Batch 300] loss: 0.014390650917193852
[Epoch 13, Batch 400] loss: 0.018578838495704984
[Epoch 13, Batch 500] loss: 0.013384604593302356
[Epoch 13, Batch 600] loss: 0.017840986949267973
[Epoch 13, Batch 700] loss: 0.01375770512429881
[Epoch 13, Batch 800] loss: 0.01816967080514587
[Epoch 13, Batch 900] loss: 0.015398741046483337
**STATS for Epoch 13** : 
Average training loss: 0.0008
Average validation loss: 0.0695
Validation Accuracy: 0.9812
Overfitting: 0.0687
[Epoch 14, Batch 100] loss: 0.012454996198539448
[Epoch 14, Batch 200] loss: 0.012494448626202938
[Epoch 14, Batch 300] loss: 0.008820001129333833
[Epoch 14, Batch 400] loss: 0.012207303566028713
[Epoch 14, Batch 500] loss: 0.009596294669336203
[Epoch 14, Batch 600] loss: 0.021562141413160135
[Epoch 14, Batch 700] loss: 0.013100201391425799
[Epoch 14, Batch 800] loss: 0.009323541665253288
[Epoch 14, Batch 900] loss: 0.01187585150502855
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0568
Validation Accuracy: 0.9850
Overfitting: 0.0558
[Epoch 15, Batch 100] loss: 0.011982197429024382
[Epoch 15, Batch 200] loss: 0.009069124199595536
[Epoch 15, Batch 300] loss: 0.0114795181064801
[Epoch 15, Batch 400] loss: 0.008280471133857645
[Epoch 15, Batch 500] loss: 0.008239074559805886
[Epoch 15, Batch 600] loss: 0.011910892720043193
[Epoch 15, Batch 700] loss: 0.016742067087943725
[Epoch 15, Batch 800] loss: 0.00968091004921007
[Epoch 15, Batch 900] loss: 0.016278839467713625
**STATS for Epoch 15** : 
Average training loss: 0.0009
Average validation loss: 0.0695
Validation Accuracy: 0.9830
Overfitting: 0.0685
[Epoch 16, Batch 100] loss: 0.012264380856940989
[Epoch 16, Batch 200] loss: 0.010537162458995226
[Epoch 16, Batch 300] loss: 0.012060016026844096
[Epoch 16, Batch 400] loss: 0.007791405209482036
[Epoch 16, Batch 500] loss: 0.014388208899108577
[Epoch 16, Batch 600] loss: 0.009706161681460799
[Epoch 16, Batch 700] loss: 0.008581909554286539
[Epoch 16, Batch 800] loss: 0.008949619342793085
[Epoch 16, Batch 900] loss: 0.008374019766597485
**STATS for Epoch 16** : 
Average training loss: 0.0008
Average validation loss: 0.0559
Validation Accuracy: 0.9851
Overfitting: 0.0551
[Epoch 17, Batch 100] loss: 0.005598093953849457
[Epoch 17, Batch 200] loss: 0.007593203317846928
[Epoch 17, Batch 300] loss: 0.005167357749051007
[Epoch 17, Batch 400] loss: 0.011676492817641701
[Epoch 17, Batch 500] loss: 0.006180664077728579
[Epoch 17, Batch 600] loss: 0.005367846523508888
[Epoch 17, Batch 700] loss: 0.01632852413906221
[Epoch 17, Batch 800] loss: 0.012723954432640312
[Epoch 17, Batch 900] loss: 0.008087064453029598
**STATS for Epoch 17** : 
Average training loss: 0.0003
Average validation loss: 0.0676
Validation Accuracy: 0.9834
Overfitting: 0.0674
[Epoch 18, Batch 100] loss: 0.010086409681352961
[Epoch 18, Batch 200] loss: 0.005673475381845492
[Epoch 18, Batch 300] loss: 0.004877323249193068
[Epoch 18, Batch 400] loss: 0.0029633508996812453
[Epoch 18, Batch 500] loss: 0.00588712521060188
[Epoch 18, Batch 600] loss: 0.009671515586323948
[Epoch 18, Batch 700] loss: 0.006855843873936464
[Epoch 18, Batch 800] loss: 0.006699155246715236
[Epoch 18, Batch 900] loss: 0.011077001351736726
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0684
Validation Accuracy: 0.9844
Overfitting: 0.0682
[Epoch 19, Batch 100] loss: 0.009021914122577072
[Epoch 19, Batch 200] loss: 0.005024220565928772
[Epoch 19, Batch 300] loss: 0.0031712860550396726
[Epoch 19, Batch 400] loss: 0.0029388344345306905
[Epoch 19, Batch 500] loss: 0.00763994204750361
[Epoch 19, Batch 600] loss: 0.007146936392571206
[Epoch 19, Batch 700] loss: 0.003155717443200956
[Epoch 19, Batch 800] loss: 0.007965321059809866
[Epoch 19, Batch 900] loss: 0.005098284084556326
**STATS for Epoch 19** : 
Average training loss: 0.0002
Average validation loss: 0.0685
Validation Accuracy: 0.9847
Overfitting: 0.0683
[Epoch 20, Batch 100] loss: 0.004834134924390127
[Epoch 20, Batch 200] loss: 0.0027861194059778426
[Epoch 20, Batch 300] loss: 0.006074959726784073
[Epoch 20, Batch 400] loss: 0.0051337323729421765
[Epoch 20, Batch 500] loss: 0.0022282062127646895
[Epoch 20, Batch 600] loss: 0.002752438155584969
[Epoch 20, Batch 700] loss: 0.004697059752461427
[Epoch 20, Batch 800] loss: 0.0050674182228385685
[Epoch 20, Batch 900] loss: 0.007108424354555609
**STATS for Epoch 20** : 
Average training loss: 0.0002
Average validation loss: 0.0606
Validation Accuracy: 0.9858
Overfitting: 0.0604
[Epoch 21, Batch 100] loss: 0.003777145575695613
[Epoch 21, Batch 200] loss: 0.0017352910281715594
[Epoch 21, Batch 300] loss: 0.001968393393817678
[Epoch 21, Batch 400] loss: 0.003646962801069549
[Epoch 21, Batch 500] loss: 0.0015925442622392438
[Epoch 21, Batch 600] loss: 0.002154677997368708
[Epoch 21, Batch 700] loss: 0.0016534042396324368
[Epoch 21, Batch 800] loss: 0.003868771558823028
[Epoch 21, Batch 900] loss: 0.0019302630550419053
**STATS for Epoch 21** : 
Average training loss: 0.0001
Average validation loss: 0.0638
Validation Accuracy: 0.9853
Overfitting: 0.0637
[Epoch 22, Batch 100] loss: 0.0012706307686141827
[Epoch 22, Batch 200] loss: 0.0007024334018115041
[Epoch 22, Batch 300] loss: 0.0027644588701525663
[Epoch 22, Batch 400] loss: 0.0029977057350231463
[Epoch 22, Batch 500] loss: 0.004596325358182867
[Epoch 22, Batch 600] loss: 0.002917856889182531
[Epoch 22, Batch 700] loss: 0.0017450970898426022
[Epoch 22, Batch 800] loss: 0.0016807412614332406
[Epoch 22, Batch 900] loss: 0.0032288276107010462
**STATS for Epoch 22** : 
Average training loss: 0.0001
Average validation loss: 0.0650
Validation Accuracy: 0.9859
Overfitting: 0.0649
[Epoch 23, Batch 100] loss: 0.0019314817453323484
[Epoch 23, Batch 200] loss: 0.0010060631788803675
[Epoch 23, Batch 300] loss: 0.001109802421879067
[Epoch 23, Batch 400] loss: 0.0008220718211532585
[Epoch 23, Batch 500] loss: 0.001260937888010858
[Epoch 23, Batch 600] loss: 0.0017633892332929691
[Epoch 23, Batch 700] loss: 0.0025987878511853067
[Epoch 23, Batch 800] loss: 0.0015516232989455148
[Epoch 23, Batch 900] loss: 0.0016047978997562496
**STATS for Epoch 23** : 
Average training loss: 0.0001
Average validation loss: 0.0716
Validation Accuracy: 0.9848
Overfitting: 0.0715
[Epoch 24, Batch 100] loss: 0.00384001038238182
[Epoch 24, Batch 200] loss: 0.0012929916942221098
[Epoch 24, Batch 300] loss: 0.0009419972219393458
[Epoch 24, Batch 400] loss: 0.001894756489638212
[Epoch 24, Batch 500] loss: 0.00105830053560112
[Epoch 24, Batch 600] loss: 0.0015038058856930547
[Epoch 24, Batch 700] loss: 0.000778263318018162
[Epoch 24, Batch 800] loss: 0.0023632401698978358
[Epoch 24, Batch 900] loss: 0.003234569869673578
**STATS for Epoch 24** : 
Average training loss: 0.0001
Average validation loss: 0.0695
Validation Accuracy: 0.9854
Overfitting: 0.0695
Fold 1 validation loss: 0.0695
Fold 2/2
Inner Training set size for fold 2 is 30000
 Inner Validation set size for fold 2 is 30000
[Epoch 1, Batch 100] loss: 2.293172540664673
[Epoch 1, Batch 200] loss: 2.2066849625110625
[Epoch 1, Batch 300] loss: 1.1891641527414323
[Epoch 1, Batch 400] loss: 0.4623513527214527
[Epoch 1, Batch 500] loss: 0.38199921436607837
[Epoch 1, Batch 600] loss: 0.2868432180583477
[Epoch 1, Batch 700] loss: 0.2657442371919751
[Epoch 1, Batch 800] loss: 0.23343215528875588
[Epoch 1, Batch 900] loss: 0.19203097557649015
**STATS for Epoch 1** : 
Average training loss: 0.0073
Average validation loss: 0.1814
Validation Accuracy: 0.9435
Overfitting: 0.1741
Best model saved at epoch 1 with validation loss: 0.1814
[Epoch 2, Batch 100] loss: 0.16732532178983092
[Epoch 2, Batch 200] loss: 0.18160435846075415
[Epoch 2, Batch 300] loss: 0.16469795402139425
[Epoch 2, Batch 400] loss: 0.15598824377171694
[Epoch 2, Batch 500] loss: 0.1444271184876561
[Epoch 2, Batch 600] loss: 0.13359220087528229
[Epoch 2, Batch 700] loss: 0.12616108420304953
[Epoch 2, Batch 800] loss: 0.11482218873221427
[Epoch 2, Batch 900] loss: 0.0980111439852044
**STATS for Epoch 2** : 
Average training loss: 0.0043
Average validation loss: 0.1149
Validation Accuracy: 0.9650
Overfitting: 0.1107
Best model saved at epoch 2 with validation loss: 0.1149
[Epoch 3, Batch 100] loss: 0.09975185075309127
[Epoch 3, Batch 200] loss: 0.10704173262696713
[Epoch 3, Batch 300] loss: 0.10001438522711396
[Epoch 3, Batch 400] loss: 0.10037105387775228
[Epoch 3, Batch 500] loss: 0.10109072340652346
[Epoch 3, Batch 600] loss: 0.09002551693934947
[Epoch 3, Batch 700] loss: 0.08344018073752522
[Epoch 3, Batch 800] loss: 0.0957990948529914
[Epoch 3, Batch 900] loss: 0.08945326822809875
**STATS for Epoch 3** : 
Average training loss: 0.0037
Average validation loss: 0.0951
Validation Accuracy: 0.9698
Overfitting: 0.0914
Best model saved at epoch 3 with validation loss: 0.0951
[Epoch 4, Batch 100] loss: 0.07073506231885403
[Epoch 4, Batch 200] loss: 0.07351070486474783
[Epoch 4, Batch 300] loss: 0.07353741994826123
[Epoch 4, Batch 400] loss: 0.07959943655878306
[Epoch 4, Batch 500] loss: 0.08799428158206865
[Epoch 4, Batch 600] loss: 0.0756349610700272
[Epoch 4, Batch 700] loss: 0.057105663686525074
[Epoch 4, Batch 800] loss: 0.07285363256465643
[Epoch 4, Batch 900] loss: 0.07098115674336442
**STATS for Epoch 4** : 
Average training loss: 0.0030
Average validation loss: 0.0711
Validation Accuracy: 0.9784
Overfitting: 0.0681
Best model saved at epoch 4 with validation loss: 0.0711
[Epoch 5, Batch 100] loss: 0.06385887019801885
[Epoch 5, Batch 200] loss: 0.06155348969390616
[Epoch 5, Batch 300] loss: 0.06487282946472987
[Epoch 5, Batch 400] loss: 0.057686956995166835
[Epoch 5, Batch 500] loss: 0.0590990948677063
[Epoch 5, Batch 600] loss: 0.05956976882356685
[Epoch 5, Batch 700] loss: 0.06117202382767573
[Epoch 5, Batch 800] loss: 0.045559124290011827
[Epoch 5, Batch 900] loss: 0.05037730944692157
**STATS for Epoch 5** : 
Average training loss: 0.0021
Average validation loss: 0.0663
Validation Accuracy: 0.9799
Overfitting: 0.0641
Best model saved at epoch 5 with validation loss: 0.0663
[Epoch 6, Batch 100] loss: 0.038444245156133545
[Epoch 6, Batch 200] loss: 0.04803570864023641
[Epoch 6, Batch 300] loss: 0.04780929743428715
[Epoch 6, Batch 400] loss: 0.04643259180651512
[Epoch 6, Batch 500] loss: 0.05537501535087358
[Epoch 6, Batch 600] loss: 0.04149905395053793
[Epoch 6, Batch 700] loss: 0.05881294859631453
[Epoch 6, Batch 800] loss: 0.052370433686301114
[Epoch 6, Batch 900] loss: 0.048270247984910385
**STATS for Epoch 6** : 
Average training loss: 0.0021
Average validation loss: 0.0595
Validation Accuracy: 0.9819
Overfitting: 0.0574
Best model saved at epoch 6 with validation loss: 0.0595
[Epoch 7, Batch 100] loss: 0.03951220776536502
[Epoch 7, Batch 200] loss: 0.04327564457023982
[Epoch 7, Batch 300] loss: 0.038635738086304626
[Epoch 7, Batch 400] loss: 0.04716482545947656
[Epoch 7, Batch 500] loss: 0.039485152550041674
[Epoch 7, Batch 600] loss: 0.0364166471833596
[Epoch 7, Batch 700] loss: 0.04086223244026769
[Epoch 7, Batch 800] loss: 0.030132422023743857
[Epoch 7, Batch 900] loss: 0.04775358856946696
**STATS for Epoch 7** : 
Average training loss: 0.0023
Average validation loss: 0.0580
Validation Accuracy: 0.9820
Overfitting: 0.0557
Best model saved at epoch 7 with validation loss: 0.0580
[Epoch 8, Batch 100] loss: 0.02933482142223511
[Epoch 8, Batch 200] loss: 0.03191515354730654
[Epoch 8, Batch 300] loss: 0.03980247113853693
[Epoch 8, Batch 400] loss: 0.03806178437138442
[Epoch 8, Batch 500] loss: 0.03283445160894189
[Epoch 8, Batch 600] loss: 0.048366601890302265
[Epoch 8, Batch 700] loss: 0.030829312187270263
[Epoch 8, Batch 800] loss: 0.03516921782895224
[Epoch 8, Batch 900] loss: 0.02765569135081023
**STATS for Epoch 8** : 
Average training loss: 0.0017
Average validation loss: 0.0571
Validation Accuracy: 0.9824
Overfitting: 0.0554
Best model saved at epoch 8 with validation loss: 0.0571
[Epoch 9, Batch 100] loss: 0.028803734423127024
[Epoch 9, Batch 200] loss: 0.0323260275166831
[Epoch 9, Batch 300] loss: 0.03215218200348317
[Epoch 9, Batch 400] loss: 0.029001512897084466
[Epoch 9, Batch 500] loss: 0.02815155034943018
[Epoch 9, Batch 600] loss: 0.018671282893628814
[Epoch 9, Batch 700] loss: 0.035622692445467695
[Epoch 9, Batch 800] loss: 0.032534302986168766
[Epoch 9, Batch 900] loss: 0.0267796928374446
**STATS for Epoch 9** : 
Average training loss: 0.0016
Average validation loss: 0.0676
Validation Accuracy: 0.9802
Overfitting: 0.0660
[Epoch 10, Batch 100] loss: 0.02567493146925699
[Epoch 10, Batch 200] loss: 0.027166250014852268
[Epoch 10, Batch 300] loss: 0.02544479677686468
[Epoch 10, Batch 400] loss: 0.024275526575220283
[Epoch 10, Batch 500] loss: 0.023556393903854767
[Epoch 10, Batch 600] loss: 0.02435980144480709
[Epoch 10, Batch 700] loss: 0.02937652800246724
[Epoch 10, Batch 800] loss: 0.03421280121401651
[Epoch 10, Batch 900] loss: 0.03010446619038703
**STATS for Epoch 10** : 
Average training loss: 0.0013
Average validation loss: 0.0528
Validation Accuracy: 0.9844
Overfitting: 0.0515
Best model saved at epoch 10 with validation loss: 0.0528
[Epoch 11, Batch 100] loss: 0.024070494020706976
[Epoch 11, Batch 200] loss: 0.020420291245973204
[Epoch 11, Batch 300] loss: 0.02316305210464634
[Epoch 11, Batch 400] loss: 0.01715042342497327
[Epoch 11, Batch 500] loss: 0.01743548945618386
[Epoch 11, Batch 600] loss: 0.02789886593265692
[Epoch 11, Batch 700] loss: 0.029577385813754516
[Epoch 11, Batch 800] loss: 0.022865782464796213
[Epoch 11, Batch 900] loss: 0.015545733944018139
**STATS for Epoch 11** : 
Average training loss: 0.0009
Average validation loss: 0.0639
Validation Accuracy: 0.9823
Overfitting: 0.0630
[Epoch 12, Batch 100] loss: 0.015159055226686178
[Epoch 12, Batch 200] loss: 0.022135890070931055
[Epoch 12, Batch 300] loss: 0.020639553542205247
[Epoch 12, Batch 400] loss: 0.02437681320050615
[Epoch 12, Batch 500] loss: 0.0234643753914861
[Epoch 12, Batch 600] loss: 0.02317428160509735
[Epoch 12, Batch 700] loss: 0.014493897390930216
[Epoch 12, Batch 800] loss: 0.01614136150034028
[Epoch 12, Batch 900] loss: 0.028020831333415118
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0562
Validation Accuracy: 0.9840
Overfitting: 0.0553
[Epoch 13, Batch 100] loss: 0.011789887047052616
[Epoch 13, Batch 200] loss: 0.015583207167946967
[Epoch 13, Batch 300] loss: 0.016253776098164963
[Epoch 13, Batch 400] loss: 0.02221371512867336
[Epoch 13, Batch 500] loss: 0.01830266817647498
[Epoch 13, Batch 600] loss: 0.01951506515750225
[Epoch 13, Batch 700] loss: 0.018873876777433907
[Epoch 13, Batch 800] loss: 0.02171663330125739
[Epoch 13, Batch 900] loss: 0.011634262731677154
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0583
Validation Accuracy: 0.9834
Overfitting: 0.0574
[Epoch 14, Batch 100] loss: 0.017469487857670173
[Epoch 14, Batch 200] loss: 0.010217970736848657
[Epoch 14, Batch 300] loss: 0.01068301039547805
[Epoch 14, Batch 400] loss: 0.012227786167386512
[Epoch 14, Batch 500] loss: 0.012034252705580001
[Epoch 14, Batch 600] loss: 0.016009454824452405
[Epoch 14, Batch 700] loss: 0.015089451350468153
[Epoch 14, Batch 800] loss: 0.013176145916586392
[Epoch 14, Batch 900] loss: 0.024828360106766922
**STATS for Epoch 14** : 
Average training loss: 0.0008
Average validation loss: 0.0569
Validation Accuracy: 0.9840
Overfitting: 0.0561
[Epoch 15, Batch 100] loss: 0.012802397734958504
[Epoch 15, Batch 200] loss: 0.0117090416616702
[Epoch 15, Batch 300] loss: 0.01254548170742055
[Epoch 15, Batch 400] loss: 0.02182085756237939
[Epoch 15, Batch 500] loss: 0.015423691305040848
[Epoch 15, Batch 600] loss: 0.013561511862026237
[Epoch 15, Batch 700] loss: 0.007701625078625512
[Epoch 15, Batch 800] loss: 0.014905027840577532
[Epoch 15, Batch 900] loss: 0.016065111149655423
**STATS for Epoch 15** : 
Average training loss: 0.0010
Average validation loss: 0.0564
Validation Accuracy: 0.9841
Overfitting: 0.0555
[Epoch 16, Batch 100] loss: 0.010869178993525566
[Epoch 16, Batch 200] loss: 0.011616861140300899
[Epoch 16, Batch 300] loss: 0.006980274659690621
[Epoch 16, Batch 400] loss: 0.014519300829633722
[Epoch 16, Batch 500] loss: 0.005844874586109654
[Epoch 16, Batch 600] loss: 0.010079231323270505
[Epoch 16, Batch 700] loss: 0.014105783470658934
[Epoch 16, Batch 800] loss: 0.009078021528985118
[Epoch 16, Batch 900] loss: 0.01073872204113286
**STATS for Epoch 16** : 
Average training loss: 0.0005
Average validation loss: 0.0710
Validation Accuracy: 0.9809
Overfitting: 0.0705
[Epoch 17, Batch 100] loss: 0.006907822489447426
[Epoch 17, Batch 200] loss: 0.007332776981838833
[Epoch 17, Batch 300] loss: 0.009426029084006587
[Epoch 17, Batch 400] loss: 0.00842409520300862
[Epoch 17, Batch 500] loss: 0.008844863798130972
[Epoch 17, Batch 600] loss: 0.008631835056858108
[Epoch 17, Batch 700] loss: 0.015056748923598207
[Epoch 17, Batch 800] loss: 0.009751427010069164
[Epoch 17, Batch 900] loss: 0.012902415154148911
**STATS for Epoch 17** : 
Average training loss: 0.0011
Average validation loss: 0.0582
Validation Accuracy: 0.9842
Overfitting: 0.0570
[Epoch 18, Batch 100] loss: 0.009327874938517198
[Epoch 18, Batch 200] loss: 0.01011469794488221
[Epoch 18, Batch 300] loss: 0.006539711927543977
[Epoch 18, Batch 400] loss: 0.008556296958968233
[Epoch 18, Batch 500] loss: 0.011572812296944903
[Epoch 18, Batch 600] loss: 0.008590604508626712
[Epoch 18, Batch 700] loss: 0.009601122701969871
[Epoch 18, Batch 800] loss: 0.009379582511173793
[Epoch 18, Batch 900] loss: 0.00979080437004086
**STATS for Epoch 18** : 
Average training loss: 0.0002
Average validation loss: 0.0634
Validation Accuracy: 0.9846
Overfitting: 0.0632
[Epoch 19, Batch 100] loss: 0.015144717853108886
[Epoch 19, Batch 200] loss: 0.0036217243608371065
[Epoch 19, Batch 300] loss: 0.007609628802329098
[Epoch 19, Batch 400] loss: 0.006297683475495432
[Epoch 19, Batch 500] loss: 0.005259385028857651
[Epoch 19, Batch 600] loss: 0.0056751530864676165
[Epoch 19, Batch 700] loss: 0.007523155102353485
[Epoch 19, Batch 800] loss: 0.009488854596811506
[Epoch 19, Batch 900] loss: 0.008004137580937822
**STATS for Epoch 19** : 
Average training loss: 0.0004
Average validation loss: 0.0606
Validation Accuracy: 0.9852
Overfitting: 0.0602
[Epoch 20, Batch 100] loss: 0.006920282588762348
[Epoch 20, Batch 200] loss: 0.006615885923492897
[Epoch 20, Batch 300] loss: 0.00394781888298894
[Epoch 20, Batch 400] loss: 0.0022358358292308366
[Epoch 20, Batch 500] loss: 0.005125710755175987
[Epoch 20, Batch 600] loss: 0.007998051829263204
[Epoch 20, Batch 700] loss: 0.00964765274423371
[Epoch 20, Batch 800] loss: 0.015703053499883025
[Epoch 20, Batch 900] loss: 0.009390666928893551
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0620
Validation Accuracy: 0.9843
Overfitting: 0.0614
[Epoch 21, Batch 100] loss: 0.004977565407352813
[Epoch 21, Batch 200] loss: 0.004142028492201462
[Epoch 21, Batch 300] loss: 0.0034005842022088472
[Epoch 21, Batch 400] loss: 0.008552271548487624
[Epoch 21, Batch 500] loss: 0.007160852817073646
[Epoch 21, Batch 600] loss: 0.009264812715946391
[Epoch 21, Batch 700] loss: 0.011226902280632202
[Epoch 21, Batch 800] loss: 0.012119827873038957
[Epoch 21, Batch 900] loss: 0.008627751435087703
**STATS for Epoch 21** : 
Average training loss: 0.0004
Average validation loss: 0.0623
Validation Accuracy: 0.9842
Overfitting: 0.0620
[Epoch 22, Batch 100] loss: 0.00785495181998158
[Epoch 22, Batch 200] loss: 0.008179253855196293
[Epoch 22, Batch 300] loss: 0.007399749453406912
[Epoch 22, Batch 400] loss: 0.0061018917772616985
[Epoch 22, Batch 500] loss: 0.0052123663935708464
[Epoch 22, Batch 600] loss: 0.004595094012101981
[Epoch 22, Batch 700] loss: 0.007836861767868868
[Epoch 22, Batch 800] loss: 0.006959690434038066
[Epoch 22, Batch 900] loss: 0.006156626850242901
**STATS for Epoch 22** : 
Average training loss: 0.0004
Average validation loss: 0.0628
Validation Accuracy: 0.9853
Overfitting: 0.0624
[Epoch 23, Batch 100] loss: 0.001255649624167745
[Epoch 23, Batch 200] loss: 0.0025542871589493642
[Epoch 23, Batch 300] loss: 0.0045581818083428515
[Epoch 23, Batch 400] loss: 0.0024510474348426216
[Epoch 23, Batch 500] loss: 0.0032565014505485123
[Epoch 23, Batch 600] loss: 0.006246496467065299
[Epoch 23, Batch 700] loss: 0.0023233501381241693
[Epoch 23, Batch 800] loss: 0.006181681787443267
[Epoch 23, Batch 900] loss: 0.0050581062840183225
**STATS for Epoch 23** : 
Average training loss: 0.0002
Average validation loss: 0.0606
Validation Accuracy: 0.9857
Overfitting: 0.0604
[Epoch 24, Batch 100] loss: 0.002228438468098375
[Epoch 24, Batch 200] loss: 0.007585515862999727
[Epoch 24, Batch 300] loss: 0.0031904536668116634
[Epoch 24, Batch 400] loss: 0.0023876088163069654
[Epoch 24, Batch 500] loss: 0.001806387092035493
[Epoch 24, Batch 600] loss: 0.0036438594493711208
[Epoch 24, Batch 700] loss: 0.0015815337425567578
[Epoch 24, Batch 800] loss: 0.004594799559845342
[Epoch 24, Batch 900] loss: 0.0033949989611130604
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0651
Validation Accuracy: 0.9858
Overfitting: 0.0649
Fold 2 validation loss: 0.0651
Mean validation loss across all folds for Trial 22 is 0.0673 with trial config:  l1: 128, l2: 128, lr: 0.0021355157041571433, batch_size: 32
[I 2024-11-25 17:12:53,571] Trial 21 finished with value: 0.06733910888275652 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0021355157041571433, 'batch_size': 32}. Best is trial 7 with value: 0.0582443055690866.

Selected Hyperparameters for Trial 23:
  l1: 128, l2: 128, lr: 0.0005104964927399648, batch_size: 128
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.3038182520866393
[Epoch 1, Batch 200] loss: 2.297463641166687
**STATS for Epoch 1** : 
Average training loss: 0.3412
Average validation loss: 2.2901
Validation Accuracy: 0.1549
Overfitting: 1.9489
Best model saved at epoch 1 with validation loss: 2.2901
[Epoch 2, Batch 100] loss: 2.284774806499481
[Epoch 2, Batch 200] loss: 2.274577615261078
**STATS for Epoch 2** : 
Average training loss: 0.3368
Average validation loss: 2.2587
Validation Accuracy: 0.2198
Overfitting: 1.9220
Best model saved at epoch 2 with validation loss: 2.2587
[Epoch 3, Batch 100] loss: 2.2433438801765444
[Epoch 3, Batch 200] loss: 2.197572877407074
**STATS for Epoch 3** : 
Average training loss: 0.3184
Average validation loss: 2.1086
Validation Accuracy: 0.4438
Overfitting: 1.7902
Best model saved at epoch 3 with validation loss: 2.1086
[Epoch 4, Batch 100] loss: 1.992003960609436
[Epoch 4, Batch 200] loss: 1.514923813343048
**STATS for Epoch 4** : 
Average training loss: 0.1602
Average validation loss: 0.9491
Validation Accuracy: 0.7712
Overfitting: 0.7889
Best model saved at epoch 4 with validation loss: 0.9491
[Epoch 5, Batch 100] loss: 0.7566823947429657
[Epoch 5, Batch 200] loss: 0.5577034795284271
**STATS for Epoch 5** : 
Average training loss: 0.0776
Average validation loss: 0.4750
Validation Accuracy: 0.8649
Overfitting: 0.3974
Best model saved at epoch 5 with validation loss: 0.4750
[Epoch 6, Batch 100] loss: 0.4527454453706741
[Epoch 6, Batch 200] loss: 0.4082330730557442
**STATS for Epoch 6** : 
Average training loss: 0.0596
Average validation loss: 0.3821
Validation Accuracy: 0.8883
Overfitting: 0.3225
[I 2024-11-25 17:13:56,578] Trial 22 pruned. 

Selected Hyperparameters for Trial 24:
  l1: 128, l2: 128, lr: 0.0003594848185394003, batch_size: 32
Training set size: 60000
Fold 1/2
Inner Training set size for fold 1 is 30000
 Inner Validation set size for fold 1 is 30000
[Epoch 1, Batch 100] loss: 2.302559187412262
[Epoch 1, Batch 200] loss: 2.2995876836776734
[Epoch 1, Batch 300] loss: 2.296846206188202
[Epoch 1, Batch 400] loss: 2.2911672806739807
[Epoch 1, Batch 500] loss: 2.2870562982559206
[Epoch 1, Batch 600] loss: 2.2835337257385255
[Epoch 1, Batch 700] loss: 2.2768583917617797
[Epoch 1, Batch 800] loss: 2.269985716342926
[Epoch 1, Batch 900] loss: 2.2599853587150576
**STATS for Epoch 1** : 
Average training loss: 0.0909
Average validation loss: 2.2431
Validation Accuracy: 0.4150
Overfitting: 2.1522
Best model saved at epoch 1 with validation loss: 2.2431
[Epoch 2, Batch 100] loss: 2.2304452776908876
[Epoch 2, Batch 200] loss: 2.193997039794922
[Epoch 2, Batch 300] loss: 2.1242096281051634
[Epoch 2, Batch 400] loss: 1.9751554107666016
[Epoch 2, Batch 500] loss: 1.6444800114631652
[Epoch 2, Batch 600] loss: 1.2005516636371611
[Epoch 2, Batch 700] loss: 0.8531724768877029
[Epoch 2, Batch 800] loss: 0.6924104696512222
[Epoch 2, Batch 900] loss: 0.5198892810940743
**STATS for Epoch 2** : 
Average training loss: 0.0188
Average validation loss: 0.4732
Validation Accuracy: 0.8599
Overfitting: 0.4544
Best model saved at epoch 2 with validation loss: 0.4732
[Epoch 3, Batch 100] loss: 0.4669340378046036
[Epoch 3, Batch 200] loss: 0.44257381796836853
[Epoch 3, Batch 300] loss: 0.38297689482569697
[Epoch 3, Batch 400] loss: 0.35949252858757974
[Epoch 3, Batch 500] loss: 0.3512306171655655
[Epoch 3, Batch 600] loss: 0.3745948241651058
[Epoch 3, Batch 700] loss: 0.3353803923726082
[Epoch 3, Batch 800] loss: 0.3037157996743918
[Epoch 3, Batch 900] loss: 0.29485158421099184
**STATS for Epoch 3** : 
Average training loss: 0.0103
Average validation loss: 0.2725
Validation Accuracy: 0.9181
Overfitting: 0.2622
Best model saved at epoch 3 with validation loss: 0.2725
[Epoch 4, Batch 100] loss: 0.25792108178138734
[Epoch 4, Batch 200] loss: 0.2787913200259209
[Epoch 4, Batch 300] loss: 0.2559448594972491
[Epoch 4, Batch 400] loss: 0.23965436547994615
[Epoch 4, Batch 500] loss: 0.2476713450998068
[Epoch 4, Batch 600] loss: 0.24098933830857278
[Epoch 4, Batch 700] loss: 0.2267571209743619
[Epoch 4, Batch 800] loss: 0.20745729822665454
[Epoch 4, Batch 900] loss: 0.20611999977380038
**STATS for Epoch 4** : 
Average training loss: 0.0085
Average validation loss: 0.2026
Validation Accuracy: 0.9411
Overfitting: 0.1941
Best model saved at epoch 4 with validation loss: 0.2026
[Epoch 5, Batch 100] loss: 0.21509740486741066
[Epoch 5, Batch 200] loss: 0.1675070133805275
[Epoch 5, Batch 300] loss: 0.1839599229954183
[Epoch 5, Batch 400] loss: 0.1867265198007226
[Epoch 5, Batch 500] loss: 0.18925515949726104
[Epoch 5, Batch 600] loss: 0.1695110946893692
[Epoch 5, Batch 700] loss: 0.16933962397277355
[Epoch 5, Batch 800] loss: 0.17362127788364887
[Epoch 5, Batch 900] loss: 0.16669257946312427
**STATS for Epoch 5** : 
Average training loss: 0.0075
Average validation loss: 0.1631
Validation Accuracy: 0.9506
Overfitting: 0.1556
Best model saved at epoch 5 with validation loss: 0.1631
[Epoch 6, Batch 100] loss: 0.16362141640856862
[Epoch 6, Batch 200] loss: 0.14779987622052432
[Epoch 6, Batch 300] loss: 0.1583940127491951
[Epoch 6, Batch 400] loss: 0.15391085214912892
[Epoch 6, Batch 500] loss: 0.1523925879970193
[Epoch 6, Batch 600] loss: 0.14381399016827345
[Epoch 6, Batch 700] loss: 0.1404772406630218
[Epoch 6, Batch 800] loss: 0.12974763625301422
[Epoch 6, Batch 900] loss: 0.13032312532886864
**STATS for Epoch 6** : 
Average training loss: 0.0058
Average validation loss: 0.1369
Validation Accuracy: 0.9576
Overfitting: 0.1311
[I 2024-11-25 17:15:09,365] Trial 23 pruned. 
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  10
  Number of complete trials:  14
Best hyperparameters found:
{'l1': 256, 'l2': 64, 'lr': 0.0040894420414321975, 'batch_size': 256}
Best trial:
  Value:  0.0582443055690866
Loaded best model checkpoint from: best_checkpoint_trial_7/model.pth
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0040894420414321975, 'batch_size': 256} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 2.2538270354270935
[Epoch 1, Batch 200] loss: 0.8849965551495552
**STATS for Epoch 1** : 
Average training loss: 0.0511
Best model saved at epoch 1 with training loss: 0.0511
[Epoch 2, Batch 100] loss: 0.26992388188838956
[Epoch 2, Batch 200] loss: 0.20275544039905072
**STATS for Epoch 2** : 
Average training loss: 0.0244
Best model saved at epoch 2 with training loss: 0.0244
[Epoch 3, Batch 100] loss: 0.14099183212965727
[Epoch 3, Batch 200] loss: 0.13699289582669735
**STATS for Epoch 3** : 
Average training loss: 0.0177
Best model saved at epoch 3 with training loss: 0.0177
[Epoch 4, Batch 100] loss: 0.10668018966913223
[Epoch 4, Batch 200] loss: 0.09671238791197538
**STATS for Epoch 4** : 
Average training loss: 0.0146
Best model saved at epoch 4 with training loss: 0.0146
[Epoch 5, Batch 100] loss: 0.08687108021229506
[Epoch 5, Batch 200] loss: 0.07888615254312753
**STATS for Epoch 5** : 
Average training loss: 0.0122
Best model saved at epoch 5 with training loss: 0.0122
[Epoch 6, Batch 100] loss: 0.07582494301721454
[Epoch 6, Batch 200] loss: 0.07279904244467617
**STATS for Epoch 6** : 
Average training loss: 0.0098
Best model saved at epoch 6 with training loss: 0.0098
[Epoch 7, Batch 100] loss: 0.06035298982635141
[Epoch 7, Batch 200] loss: 0.06395449912175537
**STATS for Epoch 7** : 
Average training loss: 0.0095
Best model saved at epoch 7 with training loss: 0.0095
[Epoch 8, Batch 100] loss: 0.05576829310506582
[Epoch 8, Batch 200] loss: 0.05955637839622795
**STATS for Epoch 8** : 
Average training loss: 0.0077
Best model saved at epoch 8 with training loss: 0.0077
[Epoch 9, Batch 100] loss: 0.0517538452334702
[Epoch 9, Batch 200] loss: 0.051059115137904884
**STATS for Epoch 9** : 
Average training loss: 0.0075
Best model saved at epoch 9 with training loss: 0.0075
[Epoch 10, Batch 100] loss: 0.04763231609947979
[Epoch 10, Batch 200] loss: 0.046299303751438856
**STATS for Epoch 10** : 
Average training loss: 0.0068
Best model saved at epoch 10 with training loss: 0.0068
[Epoch 11, Batch 100] loss: 0.04291679502464831
[Epoch 11, Batch 200] loss: 0.04461970154196024
**STATS for Epoch 11** : 
Average training loss: 0.0070
[Epoch 12, Batch 100] loss: 0.03716985359787941
[Epoch 12, Batch 200] loss: 0.038774121711030604
**STATS for Epoch 12** : 
Average training loss: 0.0066
Best model saved at epoch 12 with training loss: 0.0066
[Epoch 13, Batch 100] loss: 0.036146163693629205
[Epoch 13, Batch 200] loss: 0.036607855418697
**STATS for Epoch 13** : 
Average training loss: 0.0057
Best model saved at epoch 13 with training loss: 0.0057
[Epoch 14, Batch 100] loss: 0.03242714702151716
[Epoch 14, Batch 200] loss: 0.036189088877290485
**STATS for Epoch 14** : 
Average training loss: 0.0047
Best model saved at epoch 14 with training loss: 0.0047
[Epoch 15, Batch 100] loss: 0.02983907173387706
[Epoch 15, Batch 200] loss: 0.03224869314581156
**STATS for Epoch 15** : 
Average training loss: 0.0050
[Epoch 16, Batch 100] loss: 0.03076797428075224
[Epoch 16, Batch 200] loss: 0.028730427282862365
**STATS for Epoch 16** : 
Average training loss: 0.0042
Best model saved at epoch 16 with training loss: 0.0042
[Epoch 17, Batch 100] loss: 0.027918621385470032
[Epoch 17, Batch 200] loss: 0.027614012667909263
**STATS for Epoch 17** : 
Average training loss: 0.0039
Best model saved at epoch 17 with training loss: 0.0039
[Epoch 18, Batch 100] loss: 0.02577704961877316
[Epoch 18, Batch 200] loss: 0.024526991415768862
**STATS for Epoch 18** : 
Average training loss: 0.0042
[Epoch 19, Batch 100] loss: 0.024692943692207335
[Epoch 19, Batch 200] loss: 0.022850624290294944
**STATS for Epoch 19** : 
Average training loss: 0.0040
[Epoch 20, Batch 100] loss: 0.020879611980635673
[Epoch 20, Batch 200] loss: 0.02184416165808216
**STATS for Epoch 20** : 
Average training loss: 0.0036
Best model saved at epoch 20 with training loss: 0.0036
[Epoch 21, Batch 100] loss: 0.01841160889947787
[Epoch 21, Batch 200] loss: 0.022098138555884363
**STATS for Epoch 21** : 
Average training loss: 0.0039
[Epoch 22, Batch 100] loss: 0.01780099323252216
[Epoch 22, Batch 200] loss: 0.01810639930423349
**STATS for Epoch 22** : 
Average training loss: 0.0036
[Epoch 23, Batch 100] loss: 0.01666442013694905
[Epoch 23, Batch 200] loss: 0.019988471900578588
**STATS for Epoch 23** : 
Average training loss: 0.0030
Best model saved at epoch 23 with training loss: 0.0030
[Epoch 24, Batch 100] loss: 0.017151352523360402
[Epoch 24, Batch 200] loss: 0.0169681608886458
**STATS for Epoch 24** : 
Average training loss: 0.0021
Best model saved at epoch 24 with training loss: 0.0021
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0040894420414321975, 'batch_size': 256} on final Test set to find Test loss for overfitting
Testing loss : 0.0469
Calculated Overfitting : 0.0448
Using best hyperparameters {'l1': 256, 'l2': 64, 'lr': 0.0040894420414321975, 'batch_size': 256} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9842
Total time taken for hyperparameter tuning and evaluation: 2:34:32
/home/ahussain/PycharmProjects/optunaNew/optuna_MedianPruner.py:455: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.


Process finished with exit code 0

