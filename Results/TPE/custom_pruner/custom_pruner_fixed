alidation loss: 0.0681
[Epoch 10, Batch 100] loss: 0.057771989873144775
[Epoch 10, Batch 200] loss: 0.05927023948635906
[Epoch 10, Batch 300] loss: 0.0597478256188333
[Epoch 10, Batch 400] loss: 0.06119673137553036
[Epoch 10, Batch 500] loss: 0.06504720329772681
[Epoch 10, Batch 600] loss: 0.062227208230178806
[Epoch 10, Batch 700] loss: 0.05967613791115582
**STATS for Epoch 10** : 
Average training loss: 0.0030
Average validation loss: 0.0639
Validation Accuracy: 0.9788
Overfitting: 0.0609
[Epoch 11, Batch 100] loss: 0.06712362690363079
[Epoch 11, Batch 200] loss: 0.05397527777124196
[Epoch 11, Batch 300] loss: 0.05237952841445804
[Epoch 11, Batch 400] loss: 0.06097240486647934
[Epoch 11, Batch 500] loss: 0.04812221718486399
[Epoch 11, Batch 600] loss: 0.056201584180817006
[Epoch 11, Batch 700] loss: 0.058626745771616695
**STATS for Epoch 11** : 
Average training loss: 0.0044
Average validation loss: 0.0663
Validation Accuracy: 0.9802
Overfitting: 0.0619
Early stopping epoch 11 for trial 2. Moving to next fold.
Fold 1 validation loss: 0.0663
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2988683652877806
[Epoch 1, Batch 200] loss: 2.2849666404724123
[Epoch 1, Batch 300] loss: 2.2529655265808106
[Epoch 1, Batch 400] loss: 2.1388956868648528
[Epoch 1, Batch 500] loss: 1.5417526227235794
[Epoch 1, Batch 600] loss: 0.6815930098295212
[Epoch 1, Batch 700] loss: 0.47525227069854736
**STATS for Epoch 1** : 
Average training loss: 0.0274
Average validation loss: 0.4534
Validation Accuracy: 0.8548
Overfitting: 0.4259
[Epoch 2, Batch 100] loss: 0.36949713721871374
[Epoch 2, Batch 200] loss: 0.3209816213697195
[Epoch 2, Batch 300] loss: 0.2906877742707729
[Epoch 2, Batch 400] loss: 0.26290844596922397
[Epoch 2, Batch 500] loss: 0.23739292681217194
[Epoch 2, Batch 600] loss: 0.23344342093914747
[Epoch 2, Batch 700] loss: 0.2184934253245592
**STATS for Epoch 2** : 
Average training loss: 0.0140
Average validation loss: 0.1986
Validation Accuracy: 0.9413
Overfitting: 0.1846
[Epoch 3, Batch 100] loss: 0.18077818810939789
[Epoch 3, Batch 200] loss: 0.1778292202949524
[Epoch 3, Batch 300] loss: 0.17891808960586786
[Epoch 3, Batch 400] loss: 0.16349182823672892
[Epoch 3, Batch 500] loss: 0.15961290415376425
[Epoch 3, Batch 600] loss: 0.15627116322517395
[Epoch 3, Batch 700] loss: 0.13487611509859562
**STATS for Epoch 3** : 
Average training loss: 0.0102
Average validation loss: 0.1574
Validation Accuracy: 0.9516
Overfitting: 0.1473
[Epoch 4, Batch 100] loss: 0.15321199391037227
[Epoch 4, Batch 200] loss: 0.12220906795933843
[Epoch 4, Batch 300] loss: 0.11968786893412471
[Epoch 4, Batch 400] loss: 0.12393269608728588
[Epoch 4, Batch 500] loss: 0.11085883993655443
[Epoch 4, Batch 600] loss: 0.11410749547183513
[Epoch 4, Batch 700] loss: 0.11704118639230728
**STATS for Epoch 4** : 
Average training loss: 0.0068
Average validation loss: 0.1239
Validation Accuracy: 0.9612
Overfitting: 0.1171
[Epoch 5, Batch 100] loss: 0.08939318841323257
[Epoch 5, Batch 200] loss: 0.11004664626903832
[Epoch 5, Batch 300] loss: 0.10644475433975459
[Epoch 5, Batch 400] loss: 0.10966408686712384
[Epoch 5, Batch 500] loss: 0.10961671914905309
[Epoch 5, Batch 600] loss: 0.09650971494615078
[Epoch 5, Batch 700] loss: 0.08679043661803007
**STATS for Epoch 5** : 
Average training loss: 0.0061
Average validation loss: 0.0993
Validation Accuracy: 0.9692
Overfitting: 0.0932
[Epoch 6, Batch 100] loss: 0.09196179907768964
[Epoch 6, Batch 200] loss: 0.0895439419709146
[Epoch 6, Batch 300] loss: 0.08896815435960889
[Epoch 6, Batch 400] loss: 0.08728387264534831
[Epoch 6, Batch 500] loss: 0.08231261010281742
[Epoch 6, Batch 600] loss: 0.08422592461109162
[Epoch 6, Batch 700] loss: 0.08323578923009337
**STATS for Epoch 6** : 
Average training loss: 0.0054
Average validation loss: 0.0959
Validation Accuracy: 0.9692
Overfitting: 0.0904
[Epoch 7, Batch 100] loss: 0.06943558304803446
[Epoch 7, Batch 200] loss: 0.0781253896933049
[Epoch 7, Batch 300] loss: 0.08230670277960599
[Epoch 7, Batch 400] loss: 0.07865850317291916
[Epoch 7, Batch 500] loss: 0.07775010888464749
[Epoch 7, Batch 600] loss: 0.08100148111581802
[Epoch 7, Batch 700] loss: 0.06684314576908947
**STATS for Epoch 7** : 
Average training loss: 0.0050
Average validation loss: 0.0925
Validation Accuracy: 0.9704
Overfitting: 0.0876
[Epoch 8, Batch 100] loss: 0.06624507893808186
[Epoch 8, Batch 200] loss: 0.07275700126308948
[Epoch 8, Batch 300] loss: 0.07515621501486748
[Epoch 8, Batch 400] loss: 0.055725234658457336
[Epoch 8, Batch 500] loss: 0.07936075240373612
[Epoch 8, Batch 600] loss: 0.069025908424519
[Epoch 8, Batch 700] loss: 0.06744340254925191
**STATS for Epoch 8** : 
Average training loss: 0.0047
Average validation loss: 0.0891
Validation Accuracy: 0.9722
Overfitting: 0.0844
[Epoch 9, Batch 100] loss: 0.06222606549039483
[Epoch 9, Batch 200] loss: 0.05844138720072806
[Epoch 9, Batch 300] loss: 0.06490685889031739
[Epoch 9, Batch 400] loss: 0.069385743024759
[Epoch 9, Batch 500] loss: 0.06657412215601653
[Epoch 9, Batch 600] loss: 0.06021293998230249
[Epoch 9, Batch 700] loss: 0.064100435776636
**STATS for Epoch 9** : 
Average training loss: 0.0048
Average validation loss: 0.0828
Validation Accuracy: 0.9723
Overfitting: 0.0780
Best model saved at epoch 9 with validation loss: 0.0828
[Epoch 10, Batch 100] loss: 0.06767814055085182
[Epoch 10, Batch 200] loss: 0.061252940390259025
[Epoch 10, Batch 300] loss: 0.05855362039990723
[Epoch 10, Batch 400] loss: 0.06807929906994105
[Epoch 10, Batch 500] loss: 0.05889402750413865
[Epoch 10, Batch 600] loss: 0.05142760013230145
[Epoch 10, Batch 700] loss: 0.05884850909467786
**STATS for Epoch 10** : 
Average training loss: 0.0036
Average validation loss: 0.0728
Validation Accuracy: 0.9778
Overfitting: 0.0691
[Epoch 11, Batch 100] loss: 0.05941215450875461
[Epoch 11, Batch 200] loss: 0.05728822208708152
[Epoch 11, Batch 300] loss: 0.05596931332722306
[Epoch 11, Batch 400] loss: 0.05448693265672773
[Epoch 11, Batch 500] loss: 0.053552923209499566
[Epoch 11, Batch 600] loss: 0.04798562353011221
[Epoch 11, Batch 700] loss: 0.05249180037295446
**STATS for Epoch 11** : 
Average training loss: 0.0040
Average validation loss: 0.0756
Validation Accuracy: 0.9762
Overfitting: 0.0716
Early stopping epoch 11 for trial 2. Moving to next fold.
Fold 2 validation loss: 0.0756
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.296894471645355
[Epoch 1, Batch 200] loss: 2.271557447910309
[Epoch 1, Batch 300] loss: 2.1868229866027833
[Epoch 1, Batch 400] loss: 1.722080934047699
[Epoch 1, Batch 500] loss: 0.7651588472723961
[Epoch 1, Batch 600] loss: 0.5352217081189156
[Epoch 1, Batch 700] loss: 0.4182133370637894
**STATS for Epoch 1** : 
Average training loss: 0.0268
Average validation loss: 0.3613
Validation Accuracy: 0.8883
Overfitting: 0.3344
[Epoch 2, Batch 100] loss: 0.34453254580497744
[Epoch 2, Batch 200] loss: 0.31417495444417
[Epoch 2, Batch 300] loss: 0.2794066385179758
[Epoch 2, Batch 400] loss: 0.28136776059865953
[Epoch 2, Batch 500] loss: 0.2365177169442177
[Epoch 2, Batch 600] loss: 0.20702185176312923
[Epoch 2, Batch 700] loss: 0.20467442192137242
**STATS for Epoch 2** : 
Average training loss: 0.0137
Average validation loss: 0.1953
Validation Accuracy: 0.9403
Overfitting: 0.1816
[Epoch 3, Batch 100] loss: 0.1831032394245267
[Epoch 3, Batch 200] loss: 0.17967289090156555
[Epoch 3, Batch 300] loss: 0.17092544745653868
[Epoch 3, Batch 400] loss: 0.15904440734535455
[Epoch 3, Batch 500] loss: 0.15655822541564704
[Epoch 3, Batch 600] loss: 0.13965616554021834
[Epoch 3, Batch 700] loss: 0.13734169162809848
**STATS for Epoch 3** : 
Average training loss: 0.0085
Average validation loss: 0.1500
Validation Accuracy: 0.9527
Overfitting: 0.1415
[Epoch 4, Batch 100] loss: 0.1379506733827293
[Epoch 4, Batch 200] loss: 0.12177810207009315
[Epoch 4, Batch 300] loss: 0.1331828945502639
[Epoch 4, Batch 400] loss: 0.10813416834920644
[Epoch 4, Batch 500] loss: 0.10093681314960122
[Epoch 4, Batch 600] loss: 0.11063261972740293
[Epoch 4, Batch 700] loss: 0.10880954880267382
**STATS for Epoch 4** : 
Average training loss: 0.0077
Average validation loss: 0.1126
Validation Accuracy: 0.9660
Overfitting: 0.1048
[Epoch 5, Batch 100] loss: 0.09802138468250632
[Epoch 5, Batch 200] loss: 0.10478831050917506
[Epoch 5, Batch 300] loss: 0.09368667075410485
[Epoch 5, Batch 400] loss: 0.10290441043674946
[Epoch 5, Batch 500] loss: 0.10158794121816754
[Epoch 5, Batch 600] loss: 0.09227391896769405
[Epoch 5, Batch 700] loss: 0.09233812196180224
**STATS for Epoch 5** : 
Average training loss: 0.0059
Average validation loss: 0.0914
Validation Accuracy: 0.9718
Overfitting: 0.0855
[Epoch 6, Batch 100] loss: 0.09705482090823353
[Epoch 6, Batch 200] loss: 0.0793752303905785
[Epoch 6, Batch 300] loss: 0.07904678594321013
[Epoch 6, Batch 400] loss: 0.08869353727437555
[Epoch 6, Batch 500] loss: 0.07199361546896398
[Epoch 6, Batch 600] loss: 0.08396912644617259
[Epoch 6, Batch 700] loss: 0.0811670333519578
**STATS for Epoch 6** : 
Average training loss: 0.0064
Average validation loss: 0.0867
Validation Accuracy: 0.9738
Overfitting: 0.0802
[Epoch 7, Batch 100] loss: 0.08213605675846339
[Epoch 7, Batch 200] loss: 0.07338157135061919
[Epoch 7, Batch 300] loss: 0.0926789870345965
[Epoch 7, Batch 400] loss: 0.06585865474306046
[Epoch 7, Batch 500] loss: 0.07508137323893607
[Epoch 7, Batch 600] loss: 0.0743213055934757
[Epoch 7, Batch 700] loss: 0.0725555633706972
**STATS for Epoch 7** : 
Average training loss: 0.0057
Average validation loss: 0.0744
Validation Accuracy: 0.9771
Overfitting: 0.0687
[Epoch 8, Batch 100] loss: 0.06665822219569235
[Epoch 8, Batch 200] loss: 0.06523742028046399
[Epoch 8, Batch 300] loss: 0.07421975020319223
[Epoch 8, Batch 400] loss: 0.0673717498825863
[Epoch 8, Batch 500] loss: 0.06406621675938368
[Epoch 8, Batch 600] loss: 0.07063744871644304
[Epoch 8, Batch 700] loss: 0.06351434772368521
**STATS for Epoch 8** : 
Average training loss: 0.0049
Average validation loss: 0.0724
Validation Accuracy: 0.9769
Overfitting: 0.0675
[Epoch 9, Batch 100] loss: 0.06541091904044151
[Epoch 9, Batch 200] loss: 0.06656048175413161
[Epoch 9, Batch 300] loss: 0.06515053452923894
[Epoch 9, Batch 400] loss: 0.06956407038960606
[Epoch 9, Batch 500] loss: 0.06180617596954107
[Epoch 9, Batch 600] loss: 0.05993919985368848
[Epoch 9, Batch 700] loss: 0.05606015021912754
**STATS for Epoch 9** : 
Average training loss: 0.0038
Average validation loss: 0.0788
Validation Accuracy: 0.9758
Overfitting: 0.0750
Best model saved at epoch 9 with validation loss: 0.0788
[Epoch 10, Batch 100] loss: 0.06854049102403223
[Epoch 10, Batch 200] loss: 0.059521685931831596
[Epoch 10, Batch 300] loss: 0.0571160813071765
[Epoch 10, Batch 400] loss: 0.06359741960652172
[Epoch 10, Batch 500] loss: 0.053680535824969414
[Epoch 10, Batch 600] loss: 0.058578627314418555
[Epoch 10, Batch 700] loss: 0.05126004827674478
**STATS for Epoch 10** : 
Average training loss: 0.0037
Average validation loss: 0.0645
Validation Accuracy: 0.9799
Overfitting: 0.0608
[Epoch 11, Batch 100] loss: 0.055591637869365516
[Epoch 11, Batch 200] loss: 0.05660236987750977
[Epoch 11, Batch 300] loss: 0.05373311829986051
[Epoch 11, Batch 400] loss: 0.05916692079976201
[Epoch 11, Batch 500] loss: 0.048163444129750134
[Epoch 11, Batch 600] loss: 0.05189407237106934
[Epoch 11, Batch 700] loss: 0.048613922083750365
**STATS for Epoch 11** : 
Average training loss: 0.0036
Average validation loss: 0.0659
Validation Accuracy: 0.9796
Overfitting: 0.0623
Early stopping epoch 11 for trial 2. Moving to next fold.
Fold 3 validation loss: 0.0659
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2972806477546692
[Epoch 1, Batch 200] loss: 2.2661280131340025
[Epoch 1, Batch 300] loss: 2.173069460391998
[Epoch 1, Batch 400] loss: 1.6649348485469817
[Epoch 1, Batch 500] loss: 0.7507660928368568
[Epoch 1, Batch 600] loss: 0.500563060939312
[Epoch 1, Batch 700] loss: 0.399503712952137
**STATS for Epoch 1** : 
Average training loss: 0.0243
Average validation loss: 0.3293
Validation Accuracy: 0.9033
Overfitting: 0.3050
[Epoch 2, Batch 100] loss: 0.33166015475988386
[Epoch 2, Batch 200] loss: 0.3154043723642826
[Epoch 2, Batch 300] loss: 0.2757931676506996
[Epoch 2, Batch 400] loss: 0.2605241148173809
[Epoch 2, Batch 500] loss: 0.23766023963689803
[Epoch 2, Batch 600] loss: 0.2173358166217804
[Epoch 2, Batch 700] loss: 0.2230257562547922
**STATS for Epoch 2** : 
Average training loss: 0.0121
Average validation loss: 0.1890
Validation Accuracy: 0.9392
Overfitting: 0.1769
[Epoch 3, Batch 100] loss: 0.18578709606081248
[Epoch 3, Batch 200] loss: 0.17363263372331858
[Epoch 3, Batch 300] loss: 0.1692786133289337
[Epoch 3, Batch 400] loss: 0.16232474151998758
[Epoch 3, Batch 500] loss: 0.1546410688571632
[Epoch 3, Batch 600] loss: 0.14770471980795263
[Epoch 3, Batch 700] loss: 0.15081666301935912
**STATS for Epoch 3** : 
Average training loss: 0.0081
Average validation loss: 0.1299
Validation Accuracy: 0.9584
Overfitting: 0.1218
[Epoch 4, Batch 100] loss: 0.13126571813598276
[Epoch 4, Batch 200] loss: 0.12370493605732918
[Epoch 4, Batch 300] loss: 0.11765968259423971
[Epoch 4, Batch 400] loss: 0.1318989694863558
[Epoch 4, Batch 500] loss: 0.1287389414012432
[Epoch 4, Batch 600] loss: 0.11588503582403063
[Epoch 4, Batch 700] loss: 0.11499241685494781
**STATS for Epoch 4** : 
Average training loss: 0.0084
Average validation loss: 0.1062
Validation Accuracy: 0.9657
Overfitting: 0.0978
[Epoch 5, Batch 100] loss: 0.1088620195351541
[Epoch 5, Batch 200] loss: 0.10553730586543679
[Epoch 5, Batch 300] loss: 0.10899999555200339
[Epoch 5, Batch 400] loss: 0.10078924968838691
[Epoch 5, Batch 500] loss: 0.10197007002308965
[Epoch 5, Batch 600] loss: 0.09990866096690297
[Epoch 5, Batch 700] loss: 0.09969907943159342
**STATS for Epoch 5** : 
Average training loss: 0.0063
Average validation loss: 0.0948
Validation Accuracy: 0.9692
Overfitting: 0.0885
[Epoch 6, Batch 100] loss: 0.10669837057590485
[Epoch 6, Batch 200] loss: 0.09722844219766558
[Epoch 6, Batch 300] loss: 0.0824859088845551
[Epoch 6, Batch 400] loss: 0.08779852667823435
[Epoch 6, Batch 500] loss: 0.08772270205430686
[Epoch 6, Batch 600] loss: 0.07441861365921795
[Epoch 6, Batch 700] loss: 0.08513335788156837
**STATS for Epoch 6** : 
Average training loss: 0.0053
Average validation loss: 0.0839
Validation Accuracy: 0.9732
Overfitting: 0.0785
[Epoch 7, Batch 100] loss: 0.071597656365484
[Epoch 7, Batch 200] loss: 0.07445257375016809
[Epoch 7, Batch 300] loss: 0.08015118325129152
[Epoch 7, Batch 400] loss: 0.08359067869372666
[Epoch 7, Batch 500] loss: 0.08533902513794601
[Epoch 7, Batch 600] loss: 0.06887953655794263
[Epoch 7, Batch 700] loss: 0.08092067088000476
**STATS for Epoch 7** : 
Average training loss: 0.0052
Average validation loss: 0.0733
Validation Accuracy: 0.9762
Overfitting: 0.0680
[Epoch 8, Batch 100] loss: 0.05855152208823711
[Epoch 8, Batch 200] loss: 0.06642495282460004
[Epoch 8, Batch 300] loss: 0.07184681166894734
[Epoch 8, Batch 400] loss: 0.06884817801881582
[Epoch 8, Batch 500] loss: 0.06262464933097363
[Epoch 8, Batch 600] loss: 0.07558646677061916
[Epoch 8, Batch 700] loss: 0.07029625592753291
**STATS for Epoch 8** : 
Average training loss: 0.0045
Average validation loss: 0.0718
Validation Accuracy: 0.9767
Overfitting: 0.0674
[Epoch 9, Batch 100] loss: 0.062171180178411306
[Epoch 9, Batch 200] loss: 0.0606776013597846
[Epoch 9, Batch 300] loss: 0.059416578193195166
[Epoch 9, Batch 400] loss: 0.06252155757509172
[Epoch 9, Batch 500] loss: 0.06913633515592664
[Epoch 9, Batch 600] loss: 0.06814081396441907
[Epoch 9, Batch 700] loss: 0.06289268879219889
**STATS for Epoch 9** : 
Average training loss: 0.0043
Average validation loss: 0.0665
Validation Accuracy: 0.9797
Overfitting: 0.0622
Best model saved at epoch 9 with validation loss: 0.0665
[Epoch 10, Batch 100] loss: 0.05983830715063959
[Epoch 10, Batch 200] loss: 0.058727808608673514
[Epoch 10, Batch 300] loss: 0.05614040382672101
[Epoch 10, Batch 400] loss: 0.059167872918769716
[Epoch 10, Batch 500] loss: 0.056433149143122134
[Epoch 10, Batch 600] loss: 0.06611459189094603
[Epoch 10, Batch 700] loss: 0.04862305393908173
**STATS for Epoch 10** : 
Average training loss: 0.0038
Average validation loss: 0.0619
Validation Accuracy: 0.9807
Overfitting: 0.0581
[Epoch 11, Batch 100] loss: 0.04620059334672987
[Epoch 11, Batch 200] loss: 0.06300211063586175
[Epoch 11, Batch 300] loss: 0.05721647041849792
[Epoch 11, Batch 400] loss: 0.0644587692595087
[Epoch 11, Batch 500] loss: 0.04948389157652855
[Epoch 11, Batch 600] loss: 0.04576949730049819
[Epoch 11, Batch 700] loss: 0.05442533503752202
**STATS for Epoch 11** : 
Average training loss: 0.0034
Average validation loss: 0.0603
Validation Accuracy: 0.9807
Overfitting: 0.0569
Early stopping epoch 11 for trial 2. Moving to next fold.
Fold 4 validation loss: 0.0603
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.3032197737693787
[Epoch 1, Batch 200] loss: 2.2851497769355773
[Epoch 1, Batch 300] loss: 2.249898657798767
[Epoch 1, Batch 400] loss: 2.078840107917786
[Epoch 1, Batch 500] loss: 1.1966019159555434
[Epoch 1, Batch 600] loss: 0.5891588541865349
[Epoch 1, Batch 700] loss: 0.45934546455740927
**STATS for Epoch 1** : 
Average training loss: 0.0266
Average validation loss: 0.3903
Validation Accuracy: 0.8852
Overfitting: 0.3637
[Epoch 2, Batch 100] loss: 0.3725099352747202
[Epoch 2, Batch 200] loss: 0.3158749915659428
[Epoch 2, Batch 300] loss: 0.32316582426428797
[Epoch 2, Batch 400] loss: 0.2929979740083218
[Epoch 2, Batch 500] loss: 0.2567925933748484
[Epoch 2, Batch 600] loss: 0.23139765068888665
[Epoch 2, Batch 700] loss: 0.23073105320334433
**STATS for Epoch 2** : 
Average training loss: 0.0128
Average validation loss: 0.2088
Validation Accuracy: 0.9389
Overfitting: 0.1960
[Epoch 3, Batch 100] loss: 0.2071484237536788
[Epoch 3, Batch 200] loss: 0.1971060426533222
[Epoch 3, Batch 300] loss: 0.175144514888525
[Epoch 3, Batch 400] loss: 0.1649131690710783
[Epoch 3, Batch 500] loss: 0.15411374367773534
[Epoch 3, Batch 600] loss: 0.15394673958420754
[Epoch 3, Batch 700] loss: 0.1561303524672985
**STATS for Epoch 3** : 
Average training loss: 0.0087
Average validation loss: 0.1402
Validation Accuracy: 0.9595
Overfitting: 0.1315
[Epoch 4, Batch 100] loss: 0.13653453117236494
[Epoch 4, Batch 200] loss: 0.14103809349238872
[Epoch 4, Batch 300] loss: 0.12295389676466584
[Epoch 4, Batch 400] loss: 0.1252304792776704
[Epoch 4, Batch 500] loss: 0.11848519442602992
[Epoch 4, Batch 600] loss: 0.12046059207990766
[Epoch 4, Batch 700] loss: 0.11637734400108457
**STATS for Epoch 4** : 
Average training loss: 0.0075
Average validation loss: 0.1077
Validation Accuracy: 0.9708
Overfitting: 0.1002
[Epoch 5, Batch 100] loss: 0.10121971726417542
[Epoch 5, Batch 200] loss: 0.10099314345046878
[Epoch 5, Batch 300] loss: 0.10383968582376837
[Epoch 5, Batch 400] loss: 0.10390258872881532
[Epoch 5, Batch 500] loss: 0.10727075817063451
[Epoch 5, Batch 600] loss: 0.10258377181366087
[Epoch 5, Batch 700] loss: 0.09520747788250446
**STATS for Epoch 5** : 
Average training loss: 0.0061
Average validation loss: 0.1033
Validation Accuracy: 0.9702
Overfitting: 0.0972
[Epoch 6, Batch 100] loss: 0.08175772078335285
[Epoch 6, Batch 200] loss: 0.08149914446752518
[Epoch 6, Batch 300] loss: 0.09567333306185902
[Epoch 6, Batch 400] loss: 0.09232489527203143
[Epoch 6, Batch 500] loss: 0.09203603125642985
[Epoch 6, Batch 600] loss: 0.09815925192087889
[Epoch 6, Batch 700] loss: 0.08747363462112843
**STATS for Epoch 6** : 
Average training loss: 0.0042
Average validation loss: 0.0897
Validation Accuracy: 0.9732
Overfitting: 0.0854
[Epoch 7, Batch 100] loss: 0.07354263282380998
[Epoch 7, Batch 200] loss: 0.06983470126055182
[Epoch 7, Batch 300] loss: 0.08284816310741007
[Epoch 7, Batch 400] loss: 0.07646415987052023
[Epoch 7, Batch 500] loss: 0.08036260990425945
[Epoch 7, Batch 600] loss: 0.08507687457837164
[Epoch 7, Batch 700] loss: 0.07952847513835877
**STATS for Epoch 7** : 
Average training loss: 0.0044
Average validation loss: 0.0781
Validation Accuracy: 0.9758
Overfitting: 0.0736
[Epoch 8, Batch 100] loss: 0.07336874371394515
[Epoch 8, Batch 200] loss: 0.07233325238339602
[Epoch 8, Batch 300] loss: 0.07377699018456042
[Epoch 8, Batch 400] loss: 0.06307842140085995
[Epoch 8, Batch 500] loss: 0.07115191923454404
[Epoch 8, Batch 600] loss: 0.06886544269975275
[Epoch 8, Batch 700] loss: 0.0676020242786035
**STATS for Epoch 8** : 
Average training loss: 0.0047
Average validation loss: 0.0748
Validation Accuracy: 0.9770
Overfitting: 0.0702
[Epoch 9, Batch 100] loss: 0.0687733095092699
[Epoch 9, Batch 200] loss: 0.061890021217986944
[Epoch 9, Batch 300] loss: 0.06570947841275483
[Epoch 9, Batch 400] loss: 0.0712526943301782
[Epoch 9, Batch 500] loss: 0.06261342449579388
[Epoch 9, Batch 600] loss: 0.05597457253374159
[Epoch 9, Batch 700] loss: 0.06123007747344673
**STATS for Epoch 9** : 
Average training loss: 0.0045
Average validation loss: 0.0698
Validation Accuracy: 0.9796
Overfitting: 0.0653
Best model saved at epoch 9 with validation loss: 0.0698
[Epoch 10, Batch 100] loss: 0.062281975829973815
[Epoch 10, Batch 200] loss: 0.05532919086981565
[Epoch 10, Batch 300] loss: 0.0604863956803456
[Epoch 10, Batch 400] loss: 0.05771780156996101
[Epoch 10, Batch 500] loss: 0.05510457569267601
[Epoch 10, Batch 600] loss: 0.05666773741599172
[Epoch 10, Batch 700] loss: 0.07028723257593811
**STATS for Epoch 10** : 
Average training loss: 0.0026
Average validation loss: 0.0658
Validation Accuracy: 0.9785
Overfitting: 0.0632
[Epoch 11, Batch 100] loss: 0.05179086894961074
[Epoch 11, Batch 200] loss: 0.060530279215890916
[Epoch 11, Batch 300] loss: 0.04720425354782492
[Epoch 11, Batch 400] loss: 0.058333259653300044
[Epoch 11, Batch 500] loss: 0.05590942514594644
[Epoch 11, Batch 600] loss: 0.055549441094044597
[Epoch 11, Batch 700] loss: 0.06386377144604921
**STATS for Epoch 11** : 
Average training loss: 0.0035
Average validation loss: 0.0693
Validation Accuracy: 0.9792
Overfitting: 0.0659
Early stopping epoch 11 for trial 2. Moving to next fold.
Fold 5 validation loss: 0.0693
Mean validation loss across all folds for Trial 2 is 0.0675 with trial config:  l1: 128, l2: 64, lr: 0.001, batch_size: 64
[I 2024-12-10 04:02:05,811] Trial 1 finished with value: 0.06747833264352596 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 64}. Best is trial 0 with value: 0.05093086766599445.

Selected Hyperparameters for Trial 3:
  l1: 128, l2: 64, lr: 0.0001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.30569064617157
[Epoch 1, Batch 200] loss: 2.302686622142792
[Epoch 1, Batch 300] loss: 2.303448133468628
[Epoch 1, Batch 400] loss: 2.3010342383384703
[Epoch 1, Batch 500] loss: 2.300574083328247
[Epoch 1, Batch 600] loss: 2.298163492679596
[Epoch 1, Batch 700] loss: 2.295165247917175
[Epoch 1, Batch 800] loss: 2.294808790683746
[Epoch 1, Batch 900] loss: 2.2910408759117127
[Epoch 1, Batch 1000] loss: 2.2902482104301454
[Epoch 1, Batch 1100] loss: 2.289583203792572
[Epoch 1, Batch 1200] loss: 2.2872068643569947
[Epoch 1, Batch 1300] loss: 2.284661149978638
[Epoch 1, Batch 1400] loss: 2.2809584879875184
[Epoch 1, Batch 1500] loss: 2.2795566177368163
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2772
Validation Accuracy: 0.2325
Overfitting: 2.2772
[Epoch 2, Batch 100] loss: 2.2764521431922913
[Epoch 2, Batch 200] loss: 2.2715539169311523
[Epoch 2, Batch 300] loss: 2.2693183708190916
[Epoch 2, Batch 400] loss: 2.2629164600372316
[Epoch 2, Batch 500] loss: 2.261259617805481
[Epoch 2, Batch 600] loss: 2.253851237297058
[Epoch 2, Batch 700] loss: 2.248619954586029
[Epoch 2, Batch 800] loss: 2.2417642736434935
[Epoch 2, Batch 900] loss: 2.233534862995148
[Epoch 2, Batch 1000] loss: 2.22005316734314
[Epoch 2, Batch 1100] loss: 2.2098265528678893
[Epoch 2, Batch 1200] loss: 2.19184645652771
[Epoch 2, Batch 1300] loss: 2.171086869239807
[Epoch 2, Batch 1400] loss: 2.1470608353614806
[Epoch 2, Batch 1500] loss: 2.116548891067505
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 2.0994
Validation Accuracy: 0.4535
Overfitting: 2.0994
[Epoch 3, Batch 100] loss: 2.077005845308304
[Epoch 3, Batch 200] loss: 2.0202254068851473
[Epoch 3, Batch 300] loss: 1.966417942047119
[Epoch 3, Batch 400] loss: 1.8714645040035247
[Epoch 3, Batch 500] loss: 1.7876685309410094
[Epoch 3, Batch 600] loss: 1.6584347021579742
[Epoch 3, Batch 700] loss: 1.5435267746448518
[Epoch 3, Batch 800] loss: 1.3987464940547942
[Epoch 3, Batch 900] loss: 1.2748611003160477
[Epoch 3, Batch 1000] loss: 1.1649497538805007
[Epoch 3, Batch 1100] loss: 1.063083273768425
[Epoch 3, Batch 1200] loss: 0.9846585589647293
[Epoch 3, Batch 1300] loss: 0.8754796785116196
[Epoch 3, Batch 1400] loss: 0.823404751420021
[Epoch 3, Batch 1500] loss: 0.7524830281734467
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.7260
Validation Accuracy: 0.7974
Overfitting: 0.7260
[Epoch 4, Batch 100] loss: 0.7279244154691696
[Epoch 4, Batch 200] loss: 0.6936500403285026
[Epoch 4, Batch 300] loss: 0.6603589767217636
[Epoch 4, Batch 400] loss: 0.6232607126235962
[Epoch 4, Batch 500] loss: 0.6192258417606353
[Epoch 4, Batch 600] loss: 0.5678510725498199
[Epoch 4, Batch 700] loss: 0.5696359384059906
[Epoch 4, Batch 800] loss: 0.5534765437245369
[Epoch 4, Batch 900] loss: 0.5175135564804078
[Epoch 4, Batch 1000] loss: 0.4984896060824394
[Epoch 4, Batch 1100] loss: 0.5282225129008293
[Epoch 4, Batch 1200] loss: 0.4927813215553761
[Epoch 4, Batch 1300] loss: 0.47767814457416535
[Epoch 4, Batch 1400] loss: 0.48115210369229316
[Epoch 4, Batch 1500] loss: 0.44747901931405065
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.4343
Validation Accuracy: 0.8708
Overfitting: 0.4343
[Epoch 5, Batch 100] loss: 0.4450331561267376
[Epoch 5, Batch 200] loss: 0.4667623427510261
[Epoch 5, Batch 300] loss: 0.45942271754145625
[Epoch 5, Batch 400] loss: 0.43505929946899413
[Epoch 5, Batch 500] loss: 0.4061992837488651
[Epoch 5, Batch 600] loss: 0.41490339130163195
[Epoch 5, Batch 700] loss: 0.41114014193415643
[Epoch 5, Batch 800] loss: 0.38937549129128457
[Epoch 5, Batch 900] loss: 0.39627616450190545
[Epoch 5, Batch 1000] loss: 0.3685026389360428
[Epoch 5, Batch 1100] loss: 0.37672216340899467
[Epoch 5, Batch 1200] loss: 0.38699254892766477
[Epoch 5, Batch 1300] loss: 0.40090141966938975
[Epoch 5, Batch 1400] loss: 0.3657363606989384
[Epoch 5, Batch 1500] loss: 0.3911490447819233
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3479
Validation Accuracy: 0.8962
Overfitting: 0.3479
[Epoch 6, Batch 100] loss: 0.36889876425266266
[Epoch 6, Batch 200] loss: 0.34228873774409296
[Epoch 6, Batch 300] loss: 0.37052933804690835
[Epoch 6, Batch 400] loss: 0.3468726028501987
[Epoch 6, Batch 500] loss: 0.3349468718469143
[Epoch 6, Batch 600] loss: 0.34105270117521286
[Epoch 6, Batch 700] loss: 0.3409917502105236
[Epoch 6, Batch 800] loss: 0.33211804322898386
[Epoch 6, Batch 900] loss: 0.3416987308859825
[Epoch 6, Batch 1000] loss: 0.3317431079596281
[Epoch 6, Batch 1100] loss: 0.33562587715685366
[Epoch 6, Batch 1200] loss: 0.3159660956263542
[Epoch 6, Batch 1300] loss: 0.34070259928703306
[Epoch 6, Batch 1400] loss: 0.3100691043958068
[Epoch 6, Batch 1500] loss: 0.2990688306465745
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2918
Validation Accuracy: 0.9122
Overfitting: 0.2918
[Epoch 7, Batch 100] loss: 0.297139351516962
[Epoch 7, Batch 200] loss: 0.2926116191595793
[Epoch 7, Batch 300] loss: 0.32051846504211423
[Epoch 7, Batch 400] loss: 0.3057369017601013
[Epoch 7, Batch 500] loss: 0.2758240270614624
[Epoch 7, Batch 600] loss: 0.2892563879489899
[Epoch 7, Batch 700] loss: 0.28803035244345665
[Epoch 7, Batch 800] loss: 0.2855919159948826
[Epoch 7, Batch 900] loss: 0.2986416921392083
[Epoch 7, Batch 1000] loss: 0.2765534772723913
[Epoch 7, Batch 1100] loss: 0.2896428119391203
[Epoch 7, Batch 1200] loss: 0.2821216708421707
[Epoch 7, Batch 1300] loss: 0.2679625610262156
[Epoch 7, Batch 1400] loss: 0.3151991616934538
[Epoch 7, Batch 1500] loss: 0.27583278067409994
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2546
Validation Accuracy: 0.9247
Overfitting: 0.2546
[Epoch 8, Batch 100] loss: 0.26530918426811695
[Epoch 8, Batch 200] loss: 0.2734357548505068
[Epoch 8, Batch 300] loss: 0.2768071695417166
[Epoch 8, Batch 400] loss: 0.25126464050263164
[Epoch 8, Batch 500] loss: 0.257867768779397
[Epoch 8, Batch 600] loss: 0.263158446252346
[Epoch 8, Batch 700] loss: 0.26073305778205397
[Epoch 8, Batch 800] loss: 0.2431065419688821
[Epoch 8, Batch 900] loss: 0.23740656251087786
[Epoch 8, Batch 1000] loss: 0.24701501429080963
[Epoch 8, Batch 1100] loss: 0.26427243582904336
[Epoch 8, Batch 1200] loss: 0.2585528247058392
[Epoch 8, Batch 1300] loss: 0.23690946314483882
[Epoch 8, Batch 1400] loss: 0.23999031897634268
[Epoch 8, Batch 1500] loss: 0.2656777113303542
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2352
Validation Accuracy: 0.9302
Overfitting: 0.2352
[Epoch 9, Batch 100] loss: 0.245874067209661
[Epoch 9, Batch 200] loss: 0.24284105472266673
[Epoch 9, Batch 300] loss: 0.23913906570523977
[Epoch 9, Batch 400] loss: 0.22665578981861473
[Epoch 9, Batch 500] loss: 0.23616440452635287
[Epoch 9, Batch 600] loss: 0.23647933721542358
[Epoch 9, Batch 700] loss: 0.21327237375080585
[Epoch 9, Batch 800] loss: 0.25980331655591726
[Epoch 9, Batch 900] loss: 0.2302737406268716
[Epoch 9, Batch 1000] loss: 0.20590465750545264
[Epoch 9, Batch 1100] loss: 0.22984443578869104
[Epoch 9, Batch 1200] loss: 0.22263442747294904
[Epoch 9, Batch 1300] loss: 0.22326045367866754
[Epoch 9, Batch 1400] loss: 0.2044036179035902
[Epoch 9, Batch 1500] loss: 0.204507290571928
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1967
Validation Accuracy: 0.9417
Overfitting: 0.1967
Best model saved at epoch 9 with validation loss: 0.1967
[Epoch 10, Batch 100] loss: 0.21917906627058983
[Epoch 10, Batch 200] loss: 0.20581041242927312
[Epoch 10, Batch 300] loss: 0.22296786930412055
[Epoch 10, Batch 400] loss: 0.21186970200389624
[Epoch 10, Batch 500] loss: 0.2100510999560356
[Epoch 10, Batch 600] loss: 0.2046827406808734
[Epoch 10, Batch 700] loss: 0.18013810336589814
[Epoch 10, Batch 800] loss: 0.21233329236507414
[Epoch 10, Batch 900] loss: 0.20506988171488047
[Epoch 10, Batch 1000] loss: 0.20575473558157684
[Epoch 10, Batch 1100] loss: 0.20599427111446858
[Epoch 10, Batch 1200] loss: 0.2090402846597135
[Epoch 10, Batch 1300] loss: 0.1908410704880953
[Epoch 10, Batch 1400] loss: 0.19085640035569668
[Epoch 10, Batch 1500] loss: 0.20677732376381755
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1865
Validation Accuracy: 0.9441
Overfitting: 0.1865
[Epoch 11, Batch 100] loss: 0.2044241700693965
[Epoch 11, Batch 200] loss: 0.1743487160280347
[Epoch 11, Batch 300] loss: 0.1725694089755416
[Epoch 11, Batch 400] loss: 0.20186015140265226
[Epoch 11, Batch 500] loss: 0.18664937937632203
[Epoch 11, Batch 600] loss: 0.1851730838418007
[Epoch 11, Batch 700] loss: 0.20612587839365004
[Epoch 11, Batch 800] loss: 0.20121808748692274
[Epoch 11, Batch 900] loss: 0.18904076866805553
[Epoch 11, Batch 1000] loss: 0.19084288336336613
[Epoch 11, Batch 1100] loss: 0.18126966767013072
[Epoch 11, Batch 1200] loss: 0.16917391296476125
[Epoch 11, Batch 1300] loss: 0.16569275494664906
[Epoch 11, Batch 1400] loss: 0.18047517467290164
[Epoch 11, Batch 1500] loss: 0.19246517680585384
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1627
Validation Accuracy: 0.9502
Overfitting: 0.1627
Best model saved at epoch 11 with validation loss: 0.1627
[Epoch 12, Batch 100] loss: 0.16806697331368922
[Epoch 12, Batch 200] loss: 0.17367831209674478
[Epoch 12, Batch 300] loss: 0.1873362996801734
[Epoch 12, Batch 400] loss: 0.17778352042660117
[Epoch 12, Batch 500] loss: 0.18250678768381476
[Epoch 12, Batch 600] loss: 0.15898246128112078
[Epoch 12, Batch 700] loss: 0.1734575203433633
[Epoch 12, Batch 800] loss: 0.16818916138261555
[Epoch 12, Batch 900] loss: 0.18313098460435867
[Epoch 12, Batch 1000] loss: 0.16202190661802887
[Epoch 12, Batch 1100] loss: 0.16207061011344195
[Epoch 12, Batch 1200] loss: 0.15741435308009386
[Epoch 12, Batch 1300] loss: 0.1737635306082666
[Epoch 12, Batch 1400] loss: 0.17128332491964102
[Epoch 12, Batch 1500] loss: 0.17693846683949233
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1521
Validation Accuracy: 0.9555
Overfitting: 0.1521
[Epoch 13, Batch 100] loss: 0.1559879506751895
[Epoch 13, Batch 200] loss: 0.17137916935607792
[Epoch 13, Batch 300] loss: 0.16215997513383626
[Epoch 13, Batch 400] loss: 0.16804088556207716
[Epoch 13, Batch 500] loss: 0.15840475780889393
[Epoch 13, Batch 600] loss: 0.1622587944753468
[Epoch 13, Batch 700] loss: 0.16215652046725154
[Epoch 13, Batch 800] loss: 0.15106042966246605
[Epoch 13, Batch 900] loss: 0.16124439679086208
[Epoch 13, Batch 1000] loss: 0.1676999606192112
[Epoch 13, Batch 1100] loss: 0.15255347818136214
[Epoch 13, Batch 1200] loss: 0.15646663391962648
[Epoch 13, Batch 1300] loss: 0.16425444047898055
[Epoch 13, Batch 1400] loss: 0.13660955293104052
[Epoch 13, Batch 1500] loss: 0.15716582899913192
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1394
Validation Accuracy: 0.9591
Overfitting: 0.1394
Early stopping epoch 13 for trial 3. Moving to next fold.
Fold 1 validation loss: 0.1394
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.302643048763275
[Epoch 1, Batch 200] loss: 2.3010971784591674
[Epoch 1, Batch 300] loss: 2.298705494403839
[Epoch 1, Batch 400] loss: 2.2952518844604493
[Epoch 1, Batch 500] loss: 2.292572469711304
[Epoch 1, Batch 600] loss: 2.28723429441452
[Epoch 1, Batch 700] loss: 2.2868145942687987
[Epoch 1, Batch 800] loss: 2.2803035831451415
[Epoch 1, Batch 900] loss: 2.2765100407600403
[Epoch 1, Batch 1000] loss: 2.2716775870323183
[Epoch 1, Batch 1100] loss: 2.266115427017212
[Epoch 1, Batch 1200] loss: 2.2594510436058046
[Epoch 1, Batch 1300] loss: 2.25215918302536
[Epoch 1, Batch 1400] loss: 2.245221860408783
[Epoch 1, Batch 1500] loss: 2.234109778404236
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2300
Validation Accuracy: 0.2949
Overfitting: 2.2300
[Epoch 2, Batch 100] loss: 2.2239099025726317
[Epoch 2, Batch 200] loss: 2.206965148448944
[Epoch 2, Batch 300] loss: 2.1910398769378663
[Epoch 2, Batch 400] loss: 2.1768584871292114
[Epoch 2, Batch 500] loss: 2.151719446182251
[Epoch 2, Batch 600] loss: 2.1259758472442627
[Epoch 2, Batch 700] loss: 2.09039000749588
[Epoch 2, Batch 800] loss: 2.0480361866950987
[Epoch 2, Batch 900] loss: 1.9825208401679992
[Epoch 2, Batch 1000] loss: 1.9113234508037567
[Epoch 2, Batch 1100] loss: 1.8106304538249969
[Epoch 2, Batch 1200] loss: 1.7127786266803742
[Epoch 2, Batch 1300] loss: 1.5723200714588166
[Epoch 2, Batch 1400] loss: 1.4312877333164216
[Epoch 2, Batch 1500] loss: 1.268615608215332
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.2151
Validation Accuracy: 0.7173
Overfitting: 1.2151
[Epoch 3, Batch 100] loss: 1.130494584441185
[Epoch 3, Batch 200] loss: 1.0133610838651657
[Epoch 3, Batch 300] loss: 0.920942360162735
[Epoch 3, Batch 400] loss: 0.8207586330175399
[Epoch 3, Batch 500] loss: 0.7707447785139084
[Epoch 3, Batch 600] loss: 0.7221119669079781
[Epoch 3, Batch 700] loss: 0.6499949243664741
[Epoch 3, Batch 800] loss: 0.6349600034952164
[Epoch 3, Batch 900] loss: 0.6242465570569038
[Epoch 3, Batch 1000] loss: 0.5553367099165917
[Epoch 3, Batch 1100] loss: 0.5943017897009849
[Epoch 3, Batch 1200] loss: 0.5502943496406079
[Epoch 3, Batch 1300] loss: 0.5239486649632454
[Epoch 3, Batch 1400] loss: 0.5213587871193885
[Epoch 3, Batch 1500] loss: 0.49032749235630035
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.5124
Validation Accuracy: 0.8484
Overfitting: 0.5124
[Epoch 4, Batch 100] loss: 0.4981615450978279
[Epoch 4, Batch 200] loss: 0.49018043085932733
[Epoch 4, Batch 300] loss: 0.4840909533202648
[Epoch 4, Batch 400] loss: 0.47487853333353996
[Epoch 4, Batch 500] loss: 0.45595459192991256
[Epoch 4, Batch 600] loss: 0.4588292543590069
[Epoch 4, Batch 700] loss: 0.4509320892393589
[Epoch 4, Batch 800] loss: 0.4419390481710434
[Epoch 4, Batch 900] loss: 0.4447052100300789
[Epoch 4, Batch 1000] loss: 0.4100664809346199
[Epoch 4, Batch 1100] loss: 0.37737766474485396
[Epoch 4, Batch 1200] loss: 0.41877269446849824
[Epoch 4, Batch 1300] loss: 0.41862862959504127
[Epoch 4, Batch 1400] loss: 0.4071870058774948
[Epoch 4, Batch 1500] loss: 0.4025826321542263
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.4075
Validation Accuracy: 0.8760
Overfitting: 0.4075
[Epoch 5, Batch 100] loss: 0.38364826440811156
[Epoch 5, Batch 200] loss: 0.4098708866536617
[Epoch 5, Batch 300] loss: 0.42268739961087703
[Epoch 5, Batch 400] loss: 0.3840196031332016
[Epoch 5, Batch 500] loss: 0.3796801522374153
[Epoch 5, Batch 600] loss: 0.3753330396860838
[Epoch 5, Batch 700] loss: 0.37116036340594294
[Epoch 5, Batch 800] loss: 0.3723233471810818
[Epoch 5, Batch 900] loss: 0.363103219345212
[Epoch 5, Batch 1000] loss: 0.3413073503226042
[Epoch 5, Batch 1100] loss: 0.3541671338677406
[Epoch 5, Batch 1200] loss: 0.3270273212343454
[Epoch 5, Batch 1300] loss: 0.32828061252832413
[Epoch 5, Batch 1400] loss: 0.3307049214094877
[Epoch 5, Batch 1500] loss: 0.319687140211463
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3454
Validation Accuracy: 0.8934
Overfitting: 0.3454
[Epoch 6, Batch 100] loss: 0.3295101009309292
[Epoch 6, Batch 200] loss: 0.3293432451039553
[Epoch 6, Batch 300] loss: 0.3220139130949974
[Epoch 6, Batch 400] loss: 0.3097296568006277
[Epoch 6, Batch 500] loss: 0.2882345508411527
[Epoch 6, Batch 600] loss: 0.3201626291126013
[Epoch 6, Batch 700] loss: 0.33974426656961443
[Epoch 6, Batch 800] loss: 0.3139863979071379
[Epoch 6, Batch 900] loss: 0.33427705787122247
[Epoch 6, Batch 1000] loss: 0.30962705753743647
[Epoch 6, Batch 1100] loss: 0.29489466302096845
[Epoch 6, Batch 1200] loss: 0.2723484900593758
[Epoch 6, Batch 1300] loss: 0.28128735747188327
[Epoch 6, Batch 1400] loss: 0.30310401603579523
[Epoch 6, Batch 1500] loss: 0.31400421261787415
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2972
Validation Accuracy: 0.9092
Overfitting: 0.2972
[Epoch 7, Batch 100] loss: 0.2738497818261385
[Epoch 7, Batch 200] loss: 0.2669191813468933
[Epoch 7, Batch 300] loss: 0.28918470308184624
[Epoch 7, Batch 400] loss: 0.26141503419727086
[Epoch 7, Batch 500] loss: 0.2718834561482072
[Epoch 7, Batch 600] loss: 0.28621311508119107
[Epoch 7, Batch 700] loss: 0.2825150074064732
[Epoch 7, Batch 800] loss: 0.2728849912807345
[Epoch 7, Batch 900] loss: 0.2579324558004737
[Epoch 7, Batch 1000] loss: 0.2576504702121019
[Epoch 7, Batch 1100] loss: 0.2768293250352144
[Epoch 7, Batch 1200] loss: 0.27278768476098775
[Epoch 7, Batch 1300] loss: 0.24024129144847392
[Epoch 7, Batch 1400] loss: 0.27110318463295696
[Epoch 7, Batch 1500] loss: 0.2768704991042614
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2710
Validation Accuracy: 0.9189
Overfitting: 0.2710
[Epoch 8, Batch 100] loss: 0.24830865200608968
[Epoch 8, Batch 200] loss: 0.2311175353080034
[Epoch 8, Batch 300] loss: 0.23981154352426529
[Epoch 8, Batch 400] loss: 0.2892030932381749
[Epoch 8, Batch 500] loss: 0.24893080029636622
[Epoch 8, Batch 600] loss: 0.23099467877298593
[Epoch 8, Batch 700] loss: 0.23753097385168076
[Epoch 8, Batch 800] loss: 0.22786221716552973
[Epoch 8, Batch 900] loss: 0.21410996317863465
[Epoch 8, Batch 1000] loss: 0.21289319943636656
[Epoch 8, Batch 1100] loss: 0.24305862214416266
[Epoch 8, Batch 1200] loss: 0.24221834369003772
[Epoch 8, Batch 1300] loss: 0.2201348904147744
[Epoch 8, Batch 1400] loss: 0.23223772037774323
[Epoch 8, Batch 1500] loss: 0.24697100944817066
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2348
Validation Accuracy: 0.9304
Overfitting: 0.2348
[Epoch 9, Batch 100] loss: 0.22919599305838345
[Epoch 9, Batch 200] loss: 0.23562837393954397
[Epoch 9, Batch 300] loss: 0.23268405694514513
[Epoch 9, Batch 400] loss: 0.20202942498028278
[Epoch 9, Batch 500] loss: 0.2234324287995696
[Epoch 9, Batch 600] loss: 0.2249421614781022
[Epoch 9, Batch 700] loss: 0.2052352012321353
[Epoch 9, Batch 800] loss: 0.22211186833679675
[Epoch 9, Batch 900] loss: 0.19815194126218558
[Epoch 9, Batch 1000] loss: 0.205048273652792
[Epoch 9, Batch 1100] loss: 0.1924515401571989
[Epoch 9, Batch 1200] loss: 0.20779324680566788
[Epoch 9, Batch 1300] loss: 0.20616155540570616
[Epoch 9, Batch 1400] loss: 0.20312953129410743
[Epoch 9, Batch 1500] loss: 0.19386906392872333
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.2177
Validation Accuracy: 0.9334
Overfitting: 0.2177
Best model saved at epoch 9 with validation loss: 0.2177
[Epoch 10, Batch 100] loss: 0.19769478373229504
[Epoch 10, Batch 200] loss: 0.1962037291005254
[Epoch 10, Batch 300] loss: 0.18318012706935405
[Epoch 10, Batch 400] loss: 0.21624803114682437
[Epoch 10, Batch 500] loss: 0.20697345919907092
[Epoch 10, Batch 600] loss: 0.21251017265021802
[Epoch 10, Batch 700] loss: 0.18520021386444568
[Epoch 10, Batch 800] loss: 0.1873502355068922
[Epoch 10, Batch 900] loss: 0.18206510554999114
[Epoch 10, Batch 1000] loss: 0.17109996143728495
[Epoch 10, Batch 1100] loss: 0.175101797580719
[Epoch 10, Batch 1200] loss: 0.16021244205534457
[Epoch 10, Batch 1300] loss: 0.19798756066709758
[Epoch 10, Batch 1400] loss: 0.19589292272925377
[Epoch 10, Batch 1500] loss: 0.20081579932942986
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1968
Validation Accuracy: 0.9398
Overfitting: 0.1968
[Epoch 11, Batch 100] loss: 0.1918314895965159
[Epoch 11, Batch 200] loss: 0.17961796514689923
[Epoch 11, Batch 300] loss: 0.17545765187591314
[Epoch 11, Batch 400] loss: 0.1532104061730206
[Epoch 11, Batch 500] loss: 0.19502005010843276
[Epoch 11, Batch 600] loss: 0.1851158399321139
[Epoch 11, Batch 700] loss: 0.18285255383700133
[Epoch 11, Batch 800] loss: 0.1756288243457675
[Epoch 11, Batch 900] loss: 0.16704587925225498
[Epoch 11, Batch 1000] loss: 0.16200040735304355
[Epoch 11, Batch 1100] loss: 0.16583700522780417
[Epoch 11, Batch 1200] loss: 0.18001404335722326
[Epoch 11, Batch 1300] loss: 0.1590118476189673
[Epoch 11, Batch 1400] loss: 0.16099519819021224
[Epoch 11, Batch 1500] loss: 0.1695196445658803
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1816
Validation Accuracy: 0.9449
Overfitting: 0.1816
Best model saved at epoch 11 with validation loss: 0.1816
[Epoch 12, Batch 100] loss: 0.16368069015443326
[Epoch 12, Batch 200] loss: 0.17711792193353176
[Epoch 12, Batch 300] loss: 0.17358897253870964
[Epoch 12, Batch 400] loss: 0.17009034741669893
[Epoch 12, Batch 500] loss: 0.17036248601973056
[Epoch 12, Batch 600] loss: 0.16758120821788908
[Epoch 12, Batch 700] loss: 0.15691937485709787
[Epoch 12, Batch 800] loss: 0.14321760285645724
[Epoch 12, Batch 900] loss: 0.16544549990445376
[Epoch 12, Batch 1000] loss: 0.14605183040723205
[Epoch 12, Batch 1100] loss: 0.15664904592558743
[Epoch 12, Batch 1200] loss: 0.1638064566254616
[Epoch 12, Batch 1300] loss: 0.14812579318881036
[Epoch 12, Batch 1400] loss: 0.16355912048369647
[Epoch 12, Batch 1500] loss: 0.13681217854842542
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1659
Validation Accuracy: 0.9516
Overfitting: 0.1659
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 11 is already reported.
  warnings.warn(
[Epoch 13, Batch 100] loss: 0.1454801693931222
[Epoch 13, Batch 200] loss: 0.1535612270794809
[Epoch 13, Batch 300] loss: 0.13367575857788325
[Epoch 13, Batch 400] loss: 0.1791434177942574
[Epoch 13, Batch 500] loss: 0.15583218885585665
[Epoch 13, Batch 600] loss: 0.13400748196523637
[Epoch 13, Batch 700] loss: 0.13942400390282272
[Epoch 13, Batch 800] loss: 0.1671199445053935
[Epoch 13, Batch 900] loss: 0.15996913131326437
[Epoch 13, Batch 1000] loss: 0.1451068944297731
[Epoch 13, Batch 1100] loss: 0.14911943396553398
[Epoch 13, Batch 1200] loss: 0.1551341674104333
[Epoch 13, Batch 1300] loss: 0.1305374705977738
[Epoch 13, Batch 1400] loss: 0.14621092414483428
[Epoch 13, Batch 1500] loss: 0.12853261321783066
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1550
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 12 is already reported.
  warnings.warn(
Validation Accuracy: 0.9527
Overfitting: 0.1550
Early stopping epoch 13 for trial 3. Moving to next fold.
Fold 2 validation loss: 0.1550
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3063513946533205
[Epoch 1, Batch 200] loss: 2.3051177430152894
[Epoch 1, Batch 300] loss: 2.3025830578804016
[Epoch 1, Batch 400] loss: 2.302885365486145
[Epoch 1, Batch 500] loss: 2.2994959950447083
[Epoch 1, Batch 600] loss: 2.298784663677216
[Epoch 1, Batch 700] loss: 2.295672037601471
[Epoch 1, Batch 800] loss: 2.2956097745895385
[Epoch 1, Batch 900] loss: 2.2953587675094607
[Epoch 1, Batch 1000] loss: 2.292488558292389
[Epoch 1, Batch 1100] loss: 2.2883956265449523
[Epoch 1, Batch 1200] loss: 2.288645691871643
[Epoch 1, Batch 1300] loss: 2.2867746424674986
[Epoch 1, Batch 1400] loss: 2.282149200439453
[Epoch 1, Batch 1500] loss: 2.280276308059692
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2802
Validation Accuracy: 0.0982
Overfitting: 2.2802
[Epoch 2, Batch 100] loss: 2.277068247795105
[Epoch 2, Batch 200] loss: 2.2785081386566164
[Epoch 2, Batch 300] loss: 2.271202564239502
[Epoch 2, Batch 400] loss: 2.2649398851394653
[Epoch 2, Batch 500] loss: 2.2624771904945375
[Epoch 2, Batch 600] loss: 2.2580007791519163
[Epoch 2, Batch 700] loss: 2.253647825717926
[Epoch 2, Batch 800] loss: 2.2450944447517394
[Epoch 2, Batch 900] loss: 2.2377177357673643
[Epoch 2, Batch 1000] loss: 2.2299764251708982
[Epoch 2, Batch 1100] loss: 2.2190817189216614
[Epoch 2, Batch 1200] loss: 2.2074496746063232
[Epoch 2, Batch 1300] loss: 2.187007339000702
[Epoch 2, Batch 1400] loss: 2.172509860992432
[Epoch 2, Batch 1500] loss: 2.149864354133606
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 2.1335
Validation Accuracy: 0.3332
Overfitting: 2.1335
[Epoch 3, Batch 100] loss: 2.1215427112579346
[Epoch 3, Batch 200] loss: 2.08433390378952
[Epoch 3, Batch 300] loss: 2.036315817832947
[Epoch 3, Batch 400] loss: 1.9797497224807739
[Epoch 3, Batch 500] loss: 1.9021940994262696
[Epoch 3, Batch 600] loss: 1.8133006501197815
[Epoch 3, Batch 700] loss: 1.694973850250244
[Epoch 3, Batch 800] loss: 1.5529784321784974
[Epoch 3, Batch 900] loss: 1.4065077900886536
[Epoch 3, Batch 1000] loss: 1.263812609910965
[Epoch 3, Batch 1100] loss: 1.117928512096405
[Epoch 3, Batch 1200] loss: 0.9989365535974503
[Epoch 3, Batch 1300] loss: 0.9118016076087951
[Epoch 3, Batch 1400] loss: 0.8552778369188309
[Epoch 3, Batch 1500] loss: 0.789663288295269
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.7484
Validation Accuracy: 0.7915
Overfitting: 0.7484
[Epoch 4, Batch 100] loss: 0.7313951992988587
[Epoch 4, Batch 200] loss: 0.71462766289711
[Epoch 4, Batch 300] loss: 0.6902199977636337
[Epoch 4, Batch 400] loss: 0.6520372441411019
[Epoch 4, Batch 500] loss: 0.6308871170878411
[Epoch 4, Batch 600] loss: 0.6134786561131478
[Epoch 4, Batch 700] loss: 0.593038224875927
[Epoch 4, Batch 800] loss: 0.5447894744575024
[Epoch 4, Batch 900] loss: 0.5524631948769092
[Epoch 4, Batch 1000] loss: 0.5267090752720833
[Epoch 4, Batch 1100] loss: 0.5161560334265232
[Epoch 4, Batch 1200] loss: 0.47063696339726446
[Epoch 4, Batch 1300] loss: 0.5135288871824741
[Epoch 4, Batch 1400] loss: 0.4933754850924015
[Epoch 4, Batch 1500] loss: 0.5094703194499016
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.4659
Validation Accuracy: 0.8589
Overfitting: 0.4659
[Epoch 5, Batch 100] loss: 0.4604994869232178
[Epoch 5, Batch 200] loss: 0.47155096143484115
[Epoch 5, Batch 300] loss: 0.4726632130146027
[Epoch 5, Batch 400] loss: 0.4453690129518509
[Epoch 5, Batch 500] loss: 0.47112069860100747
[Epoch 5, Batch 600] loss: 0.454893057346344
[Epoch 5, Batch 700] loss: 0.4186269035935402
[Epoch 5, Batch 800] loss: 0.43123411282896995
[Epoch 5, Batch 900] loss: 0.4196749998629093
[Epoch 5, Batch 1000] loss: 0.3976468390226364
[Epoch 5, Batch 1100] loss: 0.41623791873455046
[Epoch 5, Batch 1200] loss: 0.4059189331531525
[Epoch 5, Batch 1300] loss: 0.3629302165657282
[Epoch 5, Batch 1400] loss: 0.37875770434737205
[Epoch 5, Batch 1500] loss: 0.3975317372381687
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3807
Validation Accuracy: 0.8868
Overfitting: 0.3807
[Epoch 6, Batch 100] loss: 0.381968150138855
[Epoch 6, Batch 200] loss: 0.38292307801544667
[Epoch 6, Batch 300] loss: 0.3381670708954334
[Epoch 6, Batch 400] loss: 0.36741264671087265
[Epoch 6, Batch 500] loss: 0.3539431747794151
[Epoch 6, Batch 600] loss: 0.39853627488017085
[Epoch 6, Batch 700] loss: 0.35631276622414587
[Epoch 6, Batch 800] loss: 0.34493100695312023
[Epoch 6, Batch 900] loss: 0.3444505985826254
[Epoch 6, Batch 1000] loss: 0.3486176124960184
[Epoch 6, Batch 1100] loss: 0.35698001079261305
[Epoch 6, Batch 1200] loss: 0.33343288615345956
[Epoch 6, Batch 1300] loss: 0.33852516889572143
[Epoch 6, Batch 1400] loss: 0.3289495839178562
[Epoch 6, Batch 1500] loss: 0.33735745832324027
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.3260
Validation Accuracy: 0.9048
Overfitting: 0.3260
[Epoch 7, Batch 100] loss: 0.3557836156338453
[Epoch 7, Batch 200] loss: 0.3114911153167486
[Epoch 7, Batch 300] loss: 0.31554482743144036
[Epoch 7, Batch 400] loss: 0.3159261370450258
[Epoch 7, Batch 500] loss: 0.27958137936890126
[Epoch 7, Batch 600] loss: 0.29580881088972094
[Epoch 7, Batch 700] loss: 0.2883587326109409
[Epoch 7, Batch 800] loss: 0.30056772626936434
[Epoch 7, Batch 900] loss: 0.3264985324069858
[Epoch 7, Batch 1000] loss: 0.3194367953389883
[Epoch 7, Batch 1100] loss: 0.2848596598207951
[Epoch 7, Batch 1200] loss: 0.2951205679774284
[Epoch 7, Batch 1300] loss: 0.2932786317169666
[Epoch 7, Batch 1400] loss: 0.3100684404373169
[Epoch 7, Batch 1500] loss: 0.3005908916890621
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2888
Validation Accuracy: 0.9149
Overfitting: 0.2888
[Epoch 8, Batch 100] loss: 0.31629959054291246
[Epoch 8, Batch 200] loss: 0.271510174870491
[Epoch 8, Batch 300] loss: 0.2750938494503498
[Epoch 8, Batch 400] loss: 0.25166408710181715
[Epoch 8, Batch 500] loss: 0.282126477137208
[Epoch 8, Batch 600] loss: 0.26657211013138293
[Epoch 8, Batch 700] loss: 0.2697050654888153
[Epoch 8, Batch 800] loss: 0.2941861073672771
[Epoch 8, Batch 900] loss: 0.26717846550047397
[Epoch 8, Batch 1000] loss: 0.26851679414510726
[Epoch 8, Batch 1100] loss: 0.25135281674563886
[Epoch 8, Batch 1200] loss: 0.267620936781168
[Epoch 8, Batch 1300] loss: 0.2709735096991062
[Epoch 8, Batch 1400] loss: 0.2511225491762161
[Epoch 8, Batch 1500] loss: 0.25403242856264113
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2627
Validation Accuracy: 0.9226
Overfitting: 0.2627
[Epoch 9, Batch 100] loss: 0.24841983553022146
[Epoch 9, Batch 200] loss: 0.2598010131716728
[Epoch 9, Batch 300] loss: 0.2558798679709435
[Epoch 9, Batch 400] loss: 0.242522382363677
[Epoch 9, Batch 500] loss: 0.22962548464536667
[Epoch 9, Batch 600] loss: 0.23606323581188918
[Epoch 9, Batch 700] loss: 0.2622806939482689
[Epoch 9, Batch 800] loss: 0.22100200396031142
[Epoch 9, Batch 900] loss: 0.249260408654809
[Epoch 9, Batch 1000] loss: 0.26019191756844523
[Epoch 9, Batch 1100] loss: 0.24669294528663158
[Epoch 9, Batch 1200] loss: 0.2314418387785554
[Epoch 9, Batch 1300] loss: 0.2325953646749258
[Epoch 9, Batch 1400] loss: 0.23941221218556166
[Epoch 9, Batch 1500] loss: 0.21731618769466876
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.2422
Validation Accuracy: 0.9290
Overfitting: 0.2422
Best model saved at epoch 9 with validation loss: 0.2422
[Epoch 10, Batch 100] loss: 0.2309689176082611
[Epoch 10, Batch 200] loss: 0.23428530361503364
[Epoch 10, Batch 300] loss: 0.2440073250606656
[Epoch 10, Batch 400] loss: 0.19913177333772183
[Epoch 10, Batch 500] loss: 0.23053537417203188
[Epoch 10, Batch 600] loss: 0.23485898781567813
[Epoch 10, Batch 700] loss: 0.21354873333126306
[Epoch 10, Batch 800] loss: 0.21162886435166
[Epoch 10, Batch 900] loss: 0.21818748325109483
[Epoch 10, Batch 1000] loss: 0.2186921126767993
[Epoch 10, Batch 1100] loss: 0.21115571526810528
[Epoch 10, Batch 1200] loss: 0.20897285487502815
[Epoch 10, Batch 1300] loss: 0.2259378607943654
[Epoch 10, Batch 1400] loss: 0.21329147446900606
[Epoch 10, Batch 1500] loss: 0.19440127130597828
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.2159
Validation Accuracy: 0.9345
Overfitting: 0.2159
[Epoch 11, Batch 100] loss: 0.20171555116772652
[Epoch 11, Batch 200] loss: 0.22217584699392318
[Epoch 11, Batch 300] loss: 0.19177337616682053
[Epoch 11, Batch 400] loss: 0.20622487530112266
[Epoch 11, Batch 500] loss: 0.20827762685716153
[Epoch 11, Batch 600] loss: 0.20725477453321217
[Epoch 11, Batch 700] loss: 0.19525810122489928
[Epoch 11, Batch 800] loss: 0.20140050942078233
[Epoch 11, Batch 900] loss: 0.20798451777547597
[Epoch 11, Batch 1000] loss: 0.19160751145333052
[Epoch 11, Batch 1100] loss: 0.20070233479142188
[Epoch 11, Batch 1200] loss: 0.1987123478204012
[Epoch 11, Batch 1300] loss: 0.17716711174696684
[Epoch 11, Batch 1400] loss: 0.19955022517591714
[Epoch 11, Batch 1500] loss: 0.17650378316640855
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1957
Validation Accuracy: 0.9404
Overfitting: 0.1957
Best model saved at epoch 11 with validation loss: 0.1957
[Epoch 12, Batch 100] loss: 0.19093977633863687
[Epoch 12, Batch 200] loss: 0.18432315384969114
[Epoch 12, Batch 300] loss: 0.1837359539978206
[Epoch 12, Batch 400] loss: 0.1696223277412355
[Epoch 12, Batch 500] loss: 0.19930049762129784
[Epoch 12, Batch 600] loss: 0.1624336497671902
[Epoch 12, Batch 700] loss: 0.19110289258882404
[Epoch 12, Batch 800] loss: 0.1936976819485426
[Epoch 12, Batch 900] loss: 0.175516670756042
[Epoch 12, Batch 1000] loss: 0.18795258451253175
[Epoch 12, Batch 1100] loss: 0.18155240155756475
[Epoch 12, Batch 1200] loss: 0.19560053089633583
[Epoch 12, Batch 1300] loss: 0.16531277652829884
[Epoch 12, Batch 1400] loss: 0.17410640966147184
[Epoch 12, Batch 1500] loss: 0.18284039912745356
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1859
Validation Accuracy: 0.9422
Overfitting: 0.1859
[Epoch 13, Batch 100] loss: 0.1868211467936635
[Epoch 13, Batch 200] loss: 0.16762131061404945
[Epoch 13, Batch 300] loss: 0.17093058332800865
[Epoch 13, Batch 400] loss: 0.16101974932476878
[Epoch 13, Batch 500] loss: 0.16326649386435746
[Epoch 13, Batch 600] loss: 0.1592833162099123
[Epoch 13, Batch 700] loss: 0.15106051351875066
[Epoch 13, Batch 800] loss: 0.19149197792634368
[Epoch 13, Batch 900] loss: 0.18573989998549223
[Epoch 13, Batch 1000] loss: 0.1686368364840746
[Epoch 13, Batch 1100] loss: 0.17200124576687814
[Epoch 13, Batch 1200] loss: 0.16895616844296454
[Epoch 13, Batch 1300] loss: 0.14902425015345216
[Epoch 13, Batch 1400] loss: 0.1694402218423784
[Epoch 13, Batch 1500] loss: 0.1612082977220416
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1687
Validation Accuracy: 0.9497
Overfitting: 0.1687
Early stopping epoch 13 for trial 3. Moving to next fold.
Fold 3 validation loss: 0.1687
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.302609853744507
[Epoch 1, Batch 200] loss: 2.2974979639053346
[Epoch 1, Batch 300] loss: 2.2895590591430666
[Epoch 1, Batch 400] loss: 2.282879765033722
[Epoch 1, Batch 500] loss: 2.2744751739501954
[Epoch 1, Batch 600] loss: 2.2654359459877016
[Epoch 1, Batch 700] loss: 2.2590557742118835
[Epoch 1, Batch 800] loss: 2.2517778778076174
[Epoch 1, Batch 900] loss: 2.2416987204551697
[Epoch 1, Batch 1000] loss: 2.2274686765670775
[Epoch 1, Batch 1100] loss: 2.2114434957504274
[Epoch 1, Batch 1200] loss: 2.1985881614685057
[Epoch 1, Batch 1300] loss: 2.162386169433594
[Epoch 1, Batch 1400] loss: 2.1461338353157045
[Epoch 1, Batch 1500] loss: 2.098937782049179
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.0809
Validation Accuracy: 0.4356
Overfitting: 2.0809
[Epoch 2, Batch 100] loss: 2.0517772483825683
[Epoch 2, Batch 200] loss: 1.9991771709918975
[Epoch 2, Batch 300] loss: 1.919616597890854
[Epoch 2, Batch 400] loss: 1.8194092285633088
[Epoch 2, Batch 500] loss: 1.7130268406867981
[Epoch 2, Batch 600] loss: 1.5695556890964508
[Epoch 2, Batch 700] loss: 1.4029625964164734
[Epoch 2, Batch 800] loss: 1.2495906192064286
[Epoch 2, Batch 900] loss: 1.1054120975732804
[Epoch 2, Batch 1000] loss: 0.97348069190979
[Epoch 2, Batch 1100] loss: 0.8404106050729752
[Epoch 2, Batch 1200] loss: 0.7757956981658936
[Epoch 2, Batch 1300] loss: 0.7156471312046051
[Epoch 2, Batch 1400] loss: 0.6659095722436905
[Epoch 2, Batch 1500] loss: 0.6232740312814713
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.6145
Validation Accuracy: 0.8202
Overfitting: 0.6145
[Epoch 3, Batch 100] loss: 0.57962884247303
[Epoch 3, Batch 200] loss: 0.536957879960537
[Epoch 3, Batch 300] loss: 0.5299439203739166
[Epoch 3, Batch 400] loss: 0.5091574826836586
[Epoch 3, Batch 500] loss: 0.4974231007695198
[Epoch 3, Batch 600] loss: 0.4985454134643078
[Epoch 3, Batch 700] loss: 0.48650836512446405
[Epoch 3, Batch 800] loss: 0.47502764105796813
[Epoch 3, Batch 900] loss: 0.46753688365221024
[Epoch 3, Batch 1000] loss: 0.41492813333868983
[Epoch 3, Batch 1100] loss: 0.4297477415204048
[Epoch 3, Batch 1200] loss: 0.4457397708296776
[Epoch 3, Batch 1300] loss: 0.41690962135791776
[Epoch 3, Batch 1400] loss: 0.4358586856722832
[Epoch 3, Batch 1500] loss: 0.3911306384205818
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.4016
Validation Accuracy: 0.8792
Overfitting: 0.4016
[Epoch 4, Batch 100] loss: 0.3710265438258648
[Epoch 4, Batch 200] loss: 0.3902360987663269
[Epoch 4, Batch 300] loss: 0.3750662009418011
[Epoch 4, Batch 400] loss: 0.40233535051345826
[Epoch 4, Batch 500] loss: 0.37984518937766554
[Epoch 4, Batch 600] loss: 0.33115646824240685
[Epoch 4, Batch 700] loss: 0.3719259023666382
[Epoch 4, Batch 800] loss: 0.37487064093351363
[Epoch 4, Batch 900] loss: 0.3769265379011631
[Epoch 4, Batch 1000] loss: 0.3619346042722464
[Epoch 4, Batch 1100] loss: 0.3448532625287771
[Epoch 4, Batch 1200] loss: 0.3661885793507099
[Epoch 4, Batch 1300] loss: 0.3410056299716234
[Epoch 4, Batch 1400] loss: 0.3403585812449455
[Epoch 4, Batch 1500] loss: 0.3163899041712284
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3312
Validation Accuracy: 0.8991
Overfitting: 0.3312
[Epoch 5, Batch 100] loss: 0.3210721006244421
[Epoch 5, Batch 200] loss: 0.35118414886295796
[Epoch 5, Batch 300] loss: 0.33413246743381025
[Epoch 5, Batch 400] loss: 0.3133909848332405
[Epoch 5, Batch 500] loss: 0.33248044349253175
[Epoch 5, Batch 600] loss: 0.330888804346323
[Epoch 5, Batch 700] loss: 0.3022465509921312
[Epoch 5, Batch 800] loss: 0.30958859592676163
[Epoch 5, Batch 900] loss: 0.313185064047575
[Epoch 5, Batch 1000] loss: 0.2779799147695303
[Epoch 5, Batch 1100] loss: 0.29118616595864294
[Epoch 5, Batch 1200] loss: 0.28162997648119925
[Epoch 5, Batch 1300] loss: 0.28581376761198046
[Epoch 5, Batch 1400] loss: 0.275865556076169
[Epoch 5, Batch 1500] loss: 0.2920917607843876
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.2889
Validation Accuracy: 0.9104
Overfitting: 0.2889
[Epoch 6, Batch 100] loss: 0.28628620244562625
[Epoch 6, Batch 200] loss: 0.2633238694816828
[Epoch 6, Batch 300] loss: 0.28675960093736647
[Epoch 6, Batch 400] loss: 0.2706193400174379
[Epoch 6, Batch 500] loss: 0.2719186233356595
[Epoch 6, Batch 600] loss: 0.275499520637095
[Epoch 6, Batch 700] loss: 0.2631498488038778
[Epoch 6, Batch 800] loss: 0.2641684522107244
[Epoch 6, Batch 900] loss: 0.2714073291048408
[Epoch 6, Batch 1000] loss: 0.26673884071409704
[Epoch 6, Batch 1100] loss: 0.2857626002654433
[Epoch 6, Batch 1200] loss: 0.24042628046125172
[Epoch 6, Batch 1300] loss: 0.2714078284054995
[Epoch 6, Batch 1400] loss: 0.2646454079076648
[Epoch 6, Batch 1500] loss: 0.253551622107625
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2495
Validation Accuracy: 0.9242
Overfitting: 0.2495
[Epoch 7, Batch 100] loss: 0.24311634484678507
[Epoch 7, Batch 200] loss: 0.25853538086637856
[Epoch 7, Batch 300] loss: 0.2717534474283457
[Epoch 7, Batch 400] loss: 0.2503515999391675
[Epoch 7, Batch 500] loss: 0.24641657344996928
[Epoch 7, Batch 600] loss: 0.24356229342520236
[Epoch 7, Batch 700] loss: 0.2354807660728693
[Epoch 7, Batch 800] loss: 0.22586509492248297
[Epoch 7, Batch 900] loss: 0.2557765835896134
[Epoch 7, Batch 1000] loss: 0.23767626397311686
[Epoch 7, Batch 1100] loss: 0.24257818538695575
[Epoch 7, Batch 1200] loss: 0.23427313283085824
[Epoch 7, Batch 1300] loss: 0.21407645929604768
[Epoch 7, Batch 1400] loss: 0.211650074981153
[Epoch 7, Batch 1500] loss: 0.21846987098455428
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2305
Validation Accuracy: 0.9301
Overfitting: 0.2305
[Epoch 8, Batch 100] loss: 0.22221488021314145
[Epoch 8, Batch 200] loss: 0.2382204531133175
[Epoch 8, Batch 300] loss: 0.2184300059452653
[Epoch 8, Batch 400] loss: 0.22908177562057971
[Epoch 8, Batch 500] loss: 0.22358123928308488
[Epoch 8, Batch 600] loss: 0.23757405560463668
[Epoch 8, Batch 700] loss: 0.20867072448134422
[Epoch 8, Batch 800] loss: 0.21570988377556205
[Epoch 8, Batch 900] loss: 0.19872835014015436
[Epoch 8, Batch 1000] loss: 0.2132831609621644
[Epoch 8, Batch 1100] loss: 0.22908569891005753
[Epoch 8, Batch 1200] loss: 0.23237637661397456
[Epoch 8, Batch 1300] loss: 0.18628865525126456
[Epoch 8, Batch 1400] loss: 0.18719455521553754
[Epoch 8, Batch 1500] loss: 0.20039599426090718
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2049
Validation Accuracy: 0.9369
Overfitting: 0.2049
[Epoch 9, Batch 100] loss: 0.20734301894903184
[Epoch 9, Batch 200] loss: 0.19056874327361584
[Epoch 9, Batch 300] loss: 0.20383854027837514
[Epoch 9, Batch 400] loss: 0.19096413426101208
[Epoch 9, Batch 500] loss: 0.19214936304837466
[Epoch 9, Batch 600] loss: 0.17980444082990288
[Epoch 9, Batch 700] loss: 0.21871765080839395
[Epoch 9, Batch 800] loss: 0.2108577661216259
[Epoch 9, Batch 900] loss: 0.1922767334803939
[Epoch 9, Batch 1000] loss: 0.1883363791741431
[Epoch 9, Batch 1100] loss: 0.17502131786197425
[Epoch 9, Batch 1200] loss: 0.19180599147453903
[Epoch 9, Batch 1300] loss: 0.19400928318500518
[Epoch 9, Batch 1400] loss: 0.20434890007600187
[Epoch 9, Batch 1500] loss: 0.2097072722017765
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1841
Validation Accuracy: 0.9426
Overfitting: 0.1841
Best model saved at epoch 9 with validation loss: 0.1841
[Epoch 10, Batch 100] loss: 0.18470063488930463
[Epoch 10, Batch 200] loss: 0.18099110782146455
[Epoch 10, Batch 300] loss: 0.18200534978881477
[Epoch 10, Batch 400] loss: 0.17336223425343633
[Epoch 10, Batch 500] loss: 0.18817644152790308
[Epoch 10, Batch 600] loss: 0.18684330632910132
[Epoch 10, Batch 700] loss: 0.18552238307893276
[Epoch 10, Batch 800] loss: 0.19248388888314366
[Epoch 10, Batch 900] loss: 0.16812437936663627
[Epoch 10, Batch 1000] loss: 0.16745039526373148
[Epoch 10, Batch 1100] loss: 0.1810946387797594
[Epoch 10, Batch 1200] loss: 0.180196130592376
[Epoch 10, Batch 1300] loss: 0.17927916457876564
[Epoch 10, Batch 1400] loss: 0.15313674161210655
[Epoch 10, Batch 1500] loss: 0.19060082087293267
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1694
Validation Accuracy: 0.9470
Overfitting: 0.1694
[Epoch 11, Batch 100] loss: 0.16872953698039056
[Epoch 11, Batch 200] loss: 0.18072435220703484
[Epoch 11, Batch 300] loss: 0.1716367586515844
[Epoch 11, Batch 400] loss: 0.14931416163221
[Epoch 11, Batch 500] loss: 0.16934493735432624
[Epoch 11, Batch 600] loss: 0.17365946734324098
[Epoch 11, Batch 700] loss: 0.1771985636651516
[Epoch 11, Batch 800] loss: 0.15814405653625727
[Epoch 11, Batch 900] loss: 0.16996298477053642
[Epoch 11, Batch 1000] loss: 0.15811460243538022
[Epoch 11, Batch 1100] loss: 0.1746792885661125
[Epoch 11, Batch 1200] loss: 0.15937055058777333
[Epoch 11, Batch 1300] loss: 0.16855659030377865
[Epoch 11, Batch 1400] loss: 0.15712084405124188
[Epoch 11, Batch 1500] loss: 0.15742448518052699
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1602
Validation Accuracy: 0.9495
Overfitting: 0.1602
Early stopping epoch 11 for trial 3. Moving to next fold.
Fold 4 validation loss: 0.1602
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.307320816516876
[Epoch 1, Batch 200] loss: 2.304193994998932
[Epoch 1, Batch 300] loss: 2.303641953468323
[Epoch 1, Batch 400] loss: 2.301329872608185
[Epoch 1, Batch 500] loss: 2.30089061498642
[Epoch 1, Batch 600] loss: 2.300171146392822
[Epoch 1, Batch 700] loss: 2.2976172041893004
[Epoch 1, Batch 800] loss: 2.2983635306358337
[Epoch 1, Batch 900] loss: 2.29537789106369
[Epoch 1, Batch 1000] loss: 2.2938843369483948
[Epoch 1, Batch 1100] loss: 2.293931128978729
[Epoch 1, Batch 1200] loss: 2.2913189148902893
[Epoch 1, Batch 1300] loss: 2.28819135427475
[Epoch 1, Batch 1400] loss: 2.286686270236969
[Epoch 1, Batch 1500] loss: 2.2846643853187563
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2839
Validation Accuracy: 0.1629
Overfitting: 2.2839
[Epoch 2, Batch 100] loss: 2.2845754075050353
[Epoch 2, Batch 200] loss: 2.2817439603805543
[Epoch 2, Batch 300] loss: 2.278486182689667
[Epoch 2, Batch 400] loss: 2.276195261478424
[Epoch 2, Batch 500] loss: 2.2706806373596193
[Epoch 2, Batch 600] loss: 2.2695856928825378
[Epoch 2, Batch 700] loss: 2.265089612007141
[Epoch 2, Batch 800] loss: 2.2615372228622435
[Epoch 2, Batch 900] loss: 2.2587474012374877
[Epoch 2, Batch 1000] loss: 2.2529405903816224
[Epoch 2, Batch 1100] loss: 2.2431341457366942
[Epoch 2, Batch 1200] loss: 2.2420441055297853
[Epoch 2, Batch 1300] loss: 2.2325942969322203
[Epoch 2, Batch 1400] loss: 2.2192556118965148
[Epoch 2, Batch 1500] loss: 2.2135677218437193
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 2.2035
Validation Accuracy: 0.3596
Overfitting: 2.2035
[Epoch 3, Batch 100] loss: 2.1968172335624696
[Epoch 3, Batch 200] loss: 2.184593026638031
[Epoch 3, Batch 300] loss: 2.1657690095901487
[Epoch 3, Batch 400] loss: 2.137976486682892
[Epoch 3, Batch 500] loss: 2.110280774831772
[Epoch 3, Batch 600] loss: 2.0747661459445954
[Epoch 3, Batch 700] loss: 2.037497169971466
[Epoch 3, Batch 800] loss: 1.9722187197208405
[Epoch 3, Batch 900] loss: 1.9300684642791748
[Epoch 3, Batch 1000] loss: 1.840250699520111
[Epoch 3, Batch 1100] loss: 1.777171424627304
[Epoch 3, Batch 1200] loss: 1.6795360243320465
[Epoch 3, Batch 1300] loss: 1.5966845333576203
[Epoch 3, Batch 1400] loss: 1.4824065828323365
[Epoch 3, Batch 1500] loss: 1.36237974524498
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 1.3119
Validation Accuracy: 0.6403
Overfitting: 1.3119
[Epoch 4, Batch 100] loss: 1.2509566980600357
[Epoch 4, Batch 200] loss: 1.1815858513116837
[Epoch 4, Batch 300] loss: 1.0723106890916825
[Epoch 4, Batch 400] loss: 0.9895282828807831
[Epoch 4, Batch 500] loss: 0.9355381733179092
[Epoch 4, Batch 600] loss: 0.851052749156952
[Epoch 4, Batch 700] loss: 0.7914821055531501
[Epoch 4, Batch 800] loss: 0.7622555360198021
[Epoch 4, Batch 900] loss: 0.7468271714448929
[Epoch 4, Batch 1000] loss: 0.7211390146613121
[Epoch 4, Batch 1100] loss: 0.6729579100012779
[Epoch 4, Batch 1200] loss: 0.6552572998404503
[Epoch 4, Batch 1300] loss: 0.6166423687338829
[Epoch 4, Batch 1400] loss: 0.6017960566282272
[Epoch 4, Batch 1500] loss: 0.6025744959712028
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.5810
Validation Accuracy: 0.8177
Overfitting: 0.5810
[Epoch 5, Batch 100] loss: 0.5638102641701699
[Epoch 5, Batch 200] loss: 0.554654720723629
[Epoch 5, Batch 300] loss: 0.5438728708028794
[Epoch 5, Batch 400] loss: 0.5433156904578209
[Epoch 5, Batch 500] loss: 0.5114769667387009
[Epoch 5, Batch 600] loss: 0.5090732741355896
[Epoch 5, Batch 700] loss: 0.4925992691516876
[Epoch 5, Batch 800] loss: 0.4845911328494549
[Epoch 5, Batch 900] loss: 0.4819018241763115
[Epoch 5, Batch 1000] loss: 0.46659060165286065
[Epoch 5, Batch 1100] loss: 0.47304089680314065
[Epoch 5, Batch 1200] loss: 0.44845582559704783
[Epoch 5, Batch 1300] loss: 0.433712936937809
[Epoch 5, Batch 1400] loss: 0.42890635162591934
[Epoch 5, Batch 1500] loss: 0.41876547247171403
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.4284
Validation Accuracy: 0.8729
Overfitting: 0.4284
[Epoch 6, Batch 100] loss: 0.38594542533159254
[Epoch 6, Batch 200] loss: 0.4238685157895088
[Epoch 6, Batch 300] loss: 0.4279091627895832
[Epoch 6, Batch 400] loss: 0.3833761063218117
[Epoch 6, Batch 500] loss: 0.4081534956395626
[Epoch 6, Batch 600] loss: 0.4119477398693562
[Epoch 6, Batch 700] loss: 0.3862944583594799
[Epoch 6, Batch 800] loss: 0.36570390954613685
[Epoch 6, Batch 900] loss: 0.371725434884429
[Epoch 6, Batch 1000] loss: 0.3708764424175024
[Epoch 6, Batch 1100] loss: 0.3912789262831211
[Epoch 6, Batch 1200] loss: 0.35426363117992876
[Epoch 6, Batch 1300] loss: 0.365874949619174
[Epoch 6, Batch 1400] loss: 0.36628863543272017
[Epoch 6, Batch 1500] loss: 0.3512013125419617
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.3533
Validation Accuracy: 0.8922
Overfitting: 0.3533
[Epoch 7, Batch 100] loss: 0.3499370870739222
[Epoch 7, Batch 200] loss: 0.3336182352900505
[Epoch 7, Batch 300] loss: 0.36094628639519216
[Epoch 7, Batch 400] loss: 0.326924195215106
[Epoch 7, Batch 500] loss: 0.33415244936943056
[Epoch 7, Batch 600] loss: 0.3273319397866726
[Epoch 7, Batch 700] loss: 0.3195368967205286
[Epoch 7, Batch 800] loss: 0.3294631730020046
[Epoch 7, Batch 900] loss: 0.3123027027398348
[Epoch 7, Batch 1000] loss: 0.3431861638277769
[Epoch 7, Batch 1100] loss: 0.291611797362566
[Epoch 7, Batch 1200] loss: 0.3098761337995529
[Epoch 7, Batch 1300] loss: 0.3009325075149536
[Epoch 7, Batch 1400] loss: 0.2968877465650439
[Epoch 7, Batch 1500] loss: 0.31555966041982175
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.3025
Validation Accuracy: 0.9079
Overfitting: 0.3025
[Epoch 8, Batch 100] loss: 0.2758703953772783
[Epoch 8, Batch 200] loss: 0.2886166159063578
[Epoch 8, Batch 300] loss: 0.3177141546458006
[Epoch 8, Batch 400] loss: 0.2915342105180025
[Epoch 8, Batch 500] loss: 0.27225328467786314
[Epoch 8, Batch 600] loss: 0.27743824407458306
[Epoch 8, Batch 700] loss: 0.27113176554441454
[Epoch 8, Batch 800] loss: 0.28554172957316043
[Epoch 8, Batch 900] loss: 0.28426357358694077
[Epoch 8, Batch 1000] loss: 0.28128971260040997
[Epoch 8, Batch 1100] loss: 0.28618459023535253
[Epoch 8, Batch 1200] loss: 0.257436336800456
[Epoch 8, Batch 1300] loss: 0.26233172878623007
[Epoch 8, Batch 1400] loss: 0.28061073053628205
[Epoch 8, Batch 1500] loss: 0.27204440284520387
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2661
Validation Accuracy: 0.9217
Overfitting: 0.2661
[Epoch 9, Batch 100] loss: 0.24470875687897206
[Epoch 9, Batch 200] loss: 0.2633415888622403
[Epoch 9, Batch 300] loss: 0.27304203517735004
[Epoch 9, Batch 400] loss: 0.2541786915808916
[Epoch 9, Batch 500] loss: 0.25666611596941946
[Epoch 9, Batch 600] loss: 0.2553785782307386
[Epoch 9, Batch 700] loss: 0.24640497084707022
[Epoch 9, Batch 800] loss: 0.2600772980600595
[Epoch 9, Batch 900] loss: 0.2582026491686702
[Epoch 9, Batch 1000] loss: 0.24850573286414146
[Epoch 9, Batch 1100] loss: 0.25479972425848246
[Epoch 9, Batch 1200] loss: 0.23272541780024766
[Epoch 9, Batch 1300] loss: 0.2402846749871969
[Epoch 9, Batch 1400] loss: 0.22456409741193056
[Epoch 9, Batch 1500] loss: 0.2296769543737173
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.2383
Validation Accuracy: 0.9272
Overfitting: 0.2383
Best model saved at epoch 9 with validation loss: 0.2383
[Epoch 10, Batch 100] loss: 0.24855971649289132
[Epoch 10, Batch 200] loss: 0.24806647263467313
[Epoch 10, Batch 300] loss: 0.2356627960689366
[Epoch 10, Batch 400] loss: 0.24052546661347152
[Epoch 10, Batch 500] loss: 0.20162168715149165
[Epoch 10, Batch 600] loss: 0.2345982777327299
[Epoch 10, Batch 700] loss: 0.22190711908042432
[Epoch 10, Batch 800] loss: 0.23330420155078171
[Epoch 10, Batch 900] loss: 0.2298135993629694
[Epoch 10, Batch 1000] loss: 0.2042356251552701
[Epoch 10, Batch 1100] loss: 0.21194884836673736
[Epoch 10, Batch 1200] loss: 0.2146494960784912
[Epoch 10, Batch 1300] loss: 0.2140966024622321
[Epoch 10, Batch 1400] loss: 0.22966158282011748
[Epoch 10, Batch 1500] loss: 0.20877518460154534
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.2237
Validation Accuracy: 0.9347
Overfitting: 0.2237
[Epoch 11, Batch 100] loss: 0.21948779836297036
[Epoch 11, Batch 200] loss: 0.21250453040003778
[Epoch 11, Batch 300] loss: 0.21096584994345904
[Epoch 11, Batch 400] loss: 0.20231757789850235
[Epoch 11, Batch 500] loss: 0.22136604048311712
[Epoch 11, Batch 600] loss: 0.2043982771039009
[Epoch 11, Batch 700] loss: 0.2248991047590971
[Epoch 11, Batch 800] loss: 0.23037766505032778
[Epoch 11, Batch 900] loss: 0.1967736978828907
[Epoch 11, Batch 1000] loss: 0.18802748261019586
[Epoch 11, Batch 1100] loss: 0.18600136894732713
[Epoch 11, Batch 1200] loss: 0.1848819912970066
[Epoch 11, Batch 1300] loss: 0.2156035304442048
[Epoch 11, Batch 1400] loss: 0.1914261343702674
[Epoch 11, Batch 1500] loss: 0.19009096875786782
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1994
Validation Accuracy: 0.9417
Overfitting: 0.1994
Best model saved at epoch 11 with validation loss: 0.1994
[Epoch 12, Batch 100] loss: 0.1880496047064662
[Epoch 12, Batch 200] loss: 0.18862678710371256
[Epoch 12, Batch 300] loss: 0.18446019118651746
[Epoch 12, Batch 400] loss: 0.18736552231013776
[Epoch 12, Batch 500] loss: 0.2092998917400837
[Epoch 12, Batch 600] loss: 0.20849111495539546
[Epoch 12, Batch 700] loss: 0.20963171208277345
[Epoch 12, Batch 800] loss: 0.186227986253798
[Epoch 12, Batch 900] loss: 0.1767637475207448
[Epoch 12, Batch 1000] loss: 0.17266723562031985
[Epoch 12, Batch 1100] loss: 0.17039221081882716
[Epoch 12, Batch 1200] loss: 0.1951840952783823
[Epoch 12, Batch 1300] loss: 0.17737158169969916
[Epoch 12, Batch 1400] loss: 0.1768656075000763
[Epoch 12, Batch 1500] loss: 0.1791019406542182
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1834
Validation Accuracy: 0.9444
Overfitting: 0.1834
[Epoch 13, Batch 100] loss: 0.16567600112408398
[Epoch 13, Batch 200] loss: 0.16166030123829842
[Epoch 13, Batch 300] loss: 0.15932597076520325
[Epoch 13, Batch 400] loss: 0.20385053867474198
[Epoch 13, Batch 500] loss: 0.1720279469527304
[Epoch 13, Batch 600] loss: 0.17502431031316518
[Epoch 13, Batch 700] loss: 0.15250793005339802
[Epoch 13, Batch 800] loss: 0.1742733758315444
[Epoch 13, Batch 900] loss: 0.16550015611574054
[Epoch 13, Batch 1000] loss: 0.18269859051331877
[Epoch 13, Batch 1100] loss: 0.19630294371396304
[Epoch 13, Batch 1200] loss: 0.16853116231039167
[Epoch 13, Batch 1300] loss: 0.17639791022986173
[Epoch 13, Batch 1400] loss: 0.15552952960133554
[Epoch 13, Batch 1500] loss: 0.19704920902848244
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1720
Validation Accuracy: 0.9495
Overfitting: 0.1720
Early stopping epoch 13 for trial 3. Moving to next fold.
Fold 5 validation loss: 0.1720
Mean validation loss across all folds for Trial 3 is 0.1590 with trial config:  l1: 128, l2: 64, lr: 0.0001, batch_size: 32
[I 2024-12-10 04:13:16,134] Trial 2 finished with value: 0.15904881551166375 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.0001, 'batch_size': 32}. Best is trial 0 with value: 0.05093086766599445.

Selected Hyperparameters for Trial 4:
  l1: 256, l2: 128, lr: 0.0001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3026983547210693
[Epoch 1, Batch 200] loss: 2.3020753049850464
[Epoch 1, Batch 300] loss: 2.2984072303771974
[Epoch 1, Batch 400] loss: 2.2961993932724
[Epoch 1, Batch 500] loss: 2.2976182007789614
[Epoch 1, Batch 600] loss: 2.296098458766937
[Epoch 1, Batch 700] loss: 2.2946280956268312
[Epoch 1, Batch 800] loss: 2.294353713989258
[Epoch 1, Batch 900] loss: 2.291998405456543
[Epoch 1, Batch 1000] loss: 2.29089412689209
[Epoch 1, Batch 1100] loss: 2.2901502561569216
[Epoch 1, Batch 1200] loss: 2.2889189386367796
[Epoch 1, Batch 1300] loss: 2.288165602684021
[Epoch 1, Batch 1400] loss: 2.2850761365890504
[Epoch 1, Batch 1500] loss: 2.2830126547813414
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2825
Validation Accuracy: 0.1131
Overfitting: 2.2825
[Epoch 2, Batch 100] loss: 2.2809801578521727
[Epoch 2, Batch 200] loss: 2.279347779750824
[Epoch 2, Batch 300] loss: 2.2778116917610167
[Epoch 2, Batch 400] loss: 2.2744700932502746
[Epoch 2, Batch 500] loss: 2.2720397305488587
[Epoch 2, Batch 600] loss: 2.2693287897109986
[Epoch 2, Batch 700] loss: 2.2644953608512877
[Epoch 2, Batch 800] loss: 2.2601143670082093
[Epoch 2, Batch 900] loss: 2.256724090576172
[Epoch 2, Batch 1000] loss: 2.251876935958862
[Epoch 2, Batch 1100] loss: 2.2470224595069883
[Epoch 2, Batch 1200] loss: 2.2378352546691893
[Epoch 2, Batch 1300] loss: 2.230186893939972
[Epoch 2, Batch 1400] loss: 2.220761730670929
[Epoch 2, Batch 1500] loss: 2.207611975669861
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 2.1995
Validation Accuracy: 0.6305
Overfitting: 2.1995
[Epoch 3, Batch 100] loss: 2.193490092754364
[Epoch 3, Batch 200] loss: 2.170893893241882
[Epoch 3, Batch 300] loss: 2.147341310977936
[Epoch 3, Batch 400] loss: 2.116581401824951
[Epoch 3, Batch 500] loss: 2.0862801480293274
[Epoch 3, Batch 600] loss: 2.0348898327350615
[Epoch 3, Batch 700] loss: 1.9659921777248384
[Epoch 3, Batch 800] loss: 1.8789946341514587
[Epoch 3, Batch 900] loss: 1.776756182909012
[Epoch 3, Batch 1000] loss: 1.6440318393707276
[Epoch 3, Batch 1100] loss: 1.4884127056598664
[Epoch 3, Batch 1200] loss: 1.3276448833942414
[Epoch 3, Batch 1300] loss: 1.1867746216058732
[Epoch 3, Batch 1400] loss: 1.0512067478895188
[Epoch 3, Batch 1500] loss: 0.9373085224628448
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.8745
Validation Accuracy: 0.7752
Overfitting: 0.8745
[Epoch 4, Batch 100] loss: 0.847877054810524
[Epoch 4, Batch 200] loss: 0.7739955061674118
[Epoch 4, Batch 300] loss: 0.7111233448982239
[Epoch 4, Batch 400] loss: 0.6576268526911736
[Epoch 4, Batch 500] loss: 0.6335050702095032
[Epoch 4, Batch 600] loss: 0.5902125149965286
[Epoch 4, Batch 700] loss: 0.5455132322013378
[Epoch 4, Batch 800] loss: 0.5325315648317337
[Epoch 4, Batch 900] loss: 0.5202356764674186
[Epoch 4, Batch 1000] loss: 0.4771551702916622
[Epoch 4, Batch 1100] loss: 0.4803023345768452
[Epoch 4, Batch 1200] loss: 0.5131738765537739
[Epoch 4, Batch 1300] loss: 0.455839159488678
[Epoch 4, Batch 1400] loss: 0.4590618343651295
[Epoch 4, Batch 1500] loss: 0.4507233706116676
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.4265
Validation Accuracy: 0.8779
Overfitting: 0.4265
[Epoch 5, Batch 100] loss: 0.4205462245643139
[Epoch 5, Batch 200] loss: 0.44906954556703566
[Epoch 5, Batch 300] loss: 0.4157633538544178
[Epoch 5, Batch 400] loss: 0.4127879522740841
[Epoch 5, Batch 500] loss: 0.37976525619626045
[Epoch 5, Batch 600] loss: 0.39916980773210525
[Epoch 5, Batch 700] loss: 0.37692556910216807
[Epoch 5, Batch 800] loss: 0.38693915359675884
[Epoch 5, Batch 900] loss: 0.38099937900900843
[Epoch 5, Batch 1000] loss: 0.379386186003685
[Epoch 5, Batch 1100] loss: 0.3745940703898668
[Epoch 5, Batch 1200] loss: 0.3415305592864752
[Epoch 5, Batch 1300] loss: 0.3395513743162155
[Epoch 5, Batch 1400] loss: 0.36565164566040037
[Epoch 5, Batch 1500] loss: 0.3724065687507391
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3277
Validation Accuracy: 0.9032
Overfitting: 0.3277
[Epoch 6, Batch 100] loss: 0.3268400891125202
[Epoch 6, Batch 200] loss: 0.3405575214326382
[Epoch 6, Batch 300] loss: 0.3184360732883215
[Epoch 6, Batch 400] loss: 0.3215840911865234
[Epoch 6, Batch 500] loss: 0.34261184714734555
[Epoch 6, Batch 600] loss: 0.33673819914460185
[Epoch 6, Batch 700] loss: 0.28858973301947116
[Epoch 6, Batch 800] loss: 0.30933111876249314
[Epoch 6, Batch 900] loss: 0.33838750280439855
[Epoch 6, Batch 1000] loss: 0.30647532440721986
[Epoch 6, Batch 1100] loss: 0.29425441347062586
[Epoch 6, Batch 1200] loss: 0.2934002041816711
[Epoch 6, Batch 1300] loss: 0.29110852859914305
[Epoch 6, Batch 1400] loss: 0.29881188057363034
[Epoch 6, Batch 1500] loss: 0.2837601640447974
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2794
Validation Accuracy: 0.9145
Overfitting: 0.2794
[Epoch 7, Batch 100] loss: 0.2871356916427612
[Epoch 7, Batch 200] loss: 0.29953407384455205
[Epoch 7, Batch 300] loss: 0.28649366810917853
[Epoch 7, Batch 400] loss: 0.27640970222651956
[Epoch 7, Batch 500] loss: 0.24632626108825206
[Epoch 7, Batch 600] loss: 0.2795708893239498
[Epoch 7, Batch 700] loss: 0.2659628453105688
[Epoch 7, Batch 800] loss: 0.2976785984635353
[Epoch 7, Batch 900] loss: 0.27112921338528395
[Epoch 7, Batch 1000] loss: 0.23882722567766904
[Epoch 7, Batch 1100] loss: 0.2649572937935591
[Epoch 7, Batch 1200] loss: 0.24693566150963306
[Epoch 7, Batch 1300] loss: 0.23950081620365382
[Epoch 7, Batch 1400] loss: 0.249453106559813
[Epoch 7, Batch 1500] loss: 0.24637105351313948
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2384
Validation Accuracy: 0.9291
Overfitting: 0.2384
[Epoch 8, Batch 100] loss: 0.2421744503825903
[Epoch 8, Batch 200] loss: 0.2196589943394065
[Epoch 8, Batch 300] loss: 0.23576638612896203
[Epoch 8, Batch 400] loss: 0.2362195932865143
[Epoch 8, Batch 500] loss: 0.26679454419761894
[Epoch 8, Batch 600] loss: 0.2228875681757927
[Epoch 8, Batch 700] loss: 0.21937227521091698
[Epoch 8, Batch 800] loss: 0.2515813037008047
[Epoch 8, Batch 900] loss: 0.22974385295063257
[Epoch 8, Batch 1000] loss: 0.22843834098428487
[Epoch 8, Batch 1100] loss: 0.21962293952703477
[Epoch 8, Batch 1200] loss: 0.22799767650663852
[Epoch 8, Batch 1300] loss: 0.2411197495087981
[Epoch 8, Batch 1400] loss: 0.23266187343746425
[Epoch 8, Batch 1500] loss: 0.2309103012830019
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2114
Validation Accuracy: 0.9366
Overfitting: 0.2114
[Epoch 9, Batch 100] loss: 0.2360681425780058
[Epoch 9, Batch 200] loss: 0.2103945256769657
[Epoch 9, Batch 300] loss: 0.21251203324645757
[Epoch 9, Batch 400] loss: 0.20895080409944058
[Epoch 9, Batch 500] loss: 0.20342341646552087
[Epoch 9, Batch 600] loss: 0.2183427446335554
[Epoch 9, Batch 700] loss: 0.20555064775049686
[Epoch 9, Batch 800] loss: 0.21565957486629486
[Epoch 9, Batch 900] loss: 0.21054027393460273
[Epoch 9, Batch 1000] loss: 0.19640639731660486
[Epoch 9, Batch 1100] loss: 0.16935309309512378
[Epoch 9, Batch 1200] loss: 0.20596852473914623
[Epoch 9, Batch 1300] loss: 0.2157034271210432
[Epoch 9, Batch 1400] loss: 0.1893590009957552
[Epoch 9, Batch 1500] loss: 0.215670512560755
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1797
Validation Accuracy: 0.9443
Overfitting: 0.1797
Best model saved at epoch 9 with validation loss: 0.1797
[Epoch 10, Batch 100] loss: 0.1894902640581131
[Epoch 10, Batch 200] loss: 0.20162288814783097
[Epoch 10, Batch 300] loss: 0.18710726603865624
[Epoch 10, Batch 400] loss: 0.18879046116024256
[Epoch 10, Batch 500] loss: 0.1823184785246849
[Epoch 10, Batch 600] loss: 0.2002513949200511
[Epoch 10, Batch 700] loss: 0.2060277182236314
[Epoch 10, Batch 800] loss: 0.18870526237413288
[Epoch 10, Batch 900] loss: 0.18986472932621837
[Epoch 10, Batch 1000] loss: 0.17404619369655847
[Epoch 10, Batch 1100] loss: 0.18035462323576212
[Epoch 10, Batch 1200] loss: 0.18444842549040913
[Epoch 10, Batch 1300] loss: 0.1857139919884503
[Epoch 10, Batch 1400] loss: 0.16936247432604432
[Epoch 10, Batch 1500] loss: 0.17978891622275114
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1678
Validation Accuracy: 0.9512
Overfitting: 0.1678
[Epoch 11, Batch 100] loss: 0.17861621838063002
[Epoch 11, Batch 200] loss: 0.18353640340268612
[Epoch 11, Batch 300] loss: 0.18190666446462272
[Epoch 11, Batch 400] loss: 0.16220795303583146
[Epoch 11, Batch 500] loss: 0.188558862619102
[Epoch 11, Batch 600] loss: 0.16796715192496778
[Epoch 11, Batch 700] loss: 0.16355290826410054
[Epoch 11, Batch 800] loss: 0.16988750286400317
[Epoch 11, Batch 900] loss: 0.1628974203299731
[Epoch 11, Batch 1000] loss: 0.16672071564942598
[Epoch 11, Batch 1100] loss: 0.17313290540128945
[Epoch 11, Batch 1200] loss: 0.17645975954830648
[Epoch 11, Batch 1300] loss: 0.16476592529565096
[Epoch 11, Batch 1400] loss: 0.16452625958248973
[Epoch 11, Batch 1500] loss: 0.16208601832389832
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1516
Validation Accuracy: 0.9539
Overfitting: 0.1516
Early stopping epoch 11 for trial 4. Moving to next fold.
Fold 1 validation loss: 0.1516
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.3023413848876952
[Epoch 1, Batch 200] loss: 2.30092830657959
[Epoch 1, Batch 300] loss: 2.299120669364929
[Epoch 1, Batch 400] loss: 2.2984531474113465
[Epoch 1, Batch 500] loss: 2.2958937907218933
[Epoch 1, Batch 600] loss: 2.2959640192985535
[Epoch 1, Batch 700] loss: 2.2943146514892576
[Epoch 1, Batch 800] loss: 2.291231617927551
[Epoch 1, Batch 900] loss: 2.290402367115021
[Epoch 1, Batch 1000] loss: 2.2869762206077575
[Epoch 1, Batch 1100] loss: 2.285352623462677
[Epoch 1, Batch 1200] loss: 2.2831716537475586
[Epoch 1, Batch 1300] loss: 2.2802872538566588
[Epoch 1, Batch 1400] loss: 2.2779174137115477
[Epoch 1, Batch 1500] loss: 2.274023804664612
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2727
Validation Accuracy: 0.1583
Overfitting: 2.2727
[Epoch 2, Batch 100] loss: 2.2697800040245055
[Epoch 2, Batch 200] loss: 2.2665095567703246
[Epoch 2, Batch 300] loss: 2.2611878085136414
[Epoch 2, Batch 400] loss: 2.2561562991142274
[Epoch 2, Batch 500] loss: 2.250927498340607
[Epoch 2, Batch 600] loss: 2.2429559063911437
[Epoch 2, Batch 700] loss: 2.2315130615234375
[Epoch 2, Batch 800] loss: 2.2219125270843505
[Epoch 2, Batch 900] loss: 2.2074980759620666
[Epoch 2, Batch 1000] loss: 2.191723790168762
[Epoch 2, Batch 1100] loss: 2.172792432308197
[Epoch 2, Batch 1200] loss: 2.14435950756073
[Epoch 2, Batch 1300] loss: 2.114554841518402
[Epoch 2, Batch 1400] loss: 2.0673234283924105
[Epoch 2, Batch 1500] loss: 2.0159838819503784
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.9794
Validation Accuracy: 0.7003
Overfitting: 1.9794
[Epoch 3, Batch 100] loss: 1.9303089988231659
[Epoch 3, Batch 200] loss: 1.8284970569610595
[Epoch 3, Batch 300] loss: 1.686912168264389
[Epoch 3, Batch 400] loss: 1.523972144126892
[Epoch 3, Batch 500] loss: 1.3594720780849456
[Epoch 3, Batch 600] loss: 1.1754610508680343
[Epoch 3, Batch 700] loss: 1.0233844512701034
[Epoch 3, Batch 800] loss: 0.9040912389755249
[Epoch 3, Batch 900] loss: 0.7842344498634338
[Epoch 3, Batch 1000] loss: 0.7413055005669594
[Epoch 3, Batch 1100] loss: 0.6611348876357078
[Epoch 3, Batch 1200] loss: 0.5965558531880378
[Epoch 3, Batch 1300] loss: 0.594582476913929
[Epoch 3, Batch 1400] loss: 0.5873183652758598
[Epoch 3, Batch 1500] loss: 0.5586283433437348
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.5446
Validation Accuracy: 0.8492
Overfitting: 0.5446
[Epoch 4, Batch 100] loss: 0.5434484893083572
[Epoch 4, Batch 200] loss: 0.5011839243769646
[Epoch 4, Batch 300] loss: 0.4933157616853714
[Epoch 4, Batch 400] loss: 0.4613681536912918
[Epoch 4, Batch 500] loss: 0.47966626077890395
[Epoch 4, Batch 600] loss: 0.4654236976802349
[Epoch 4, Batch 700] loss: 0.4277569837123156
[Epoch 4, Batch 800] loss: 0.43973167791962625
[Epoch 4, Batch 900] loss: 0.4270759965479374
[Epoch 4, Batch 1000] loss: 0.43782272934913635
[Epoch 4, Batch 1100] loss: 0.42310175582766535
[Epoch 4, Batch 1200] loss: 0.39899214923381804
[Epoch 4, Batch 1300] loss: 0.3787322436273098
[Epoch 4, Batch 1400] loss: 0.3856671164929867
[Epoch 4, Batch 1500] loss: 0.36158632501959803
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3900
Validation Accuracy: 0.8890
Overfitting: 0.3900
[Epoch 5, Batch 100] loss: 0.3641082438826561
[Epoch 5, Batch 200] loss: 0.3542673829197884
[Epoch 5, Batch 300] loss: 0.35238750152289866
[Epoch 5, Batch 400] loss: 0.3928234154731035
[Epoch 5, Batch 500] loss: 0.35955383293330667
[Epoch 5, Batch 600] loss: 0.3405543790012598
[Epoch 5, Batch 700] loss: 0.32699127957224844
[Epoch 5, Batch 800] loss: 0.3507436503469944
[Epoch 5, Batch 900] loss: 0.34604857362806796
[Epoch 5, Batch 1000] loss: 0.36031915605068204
[Epoch 5, Batch 1100] loss: 0.33211988642811774
[Epoch 5, Batch 1200] loss: 0.29721243135631087
[Epoch 5, Batch 1300] loss: 0.33257293976843355
[Epoch 5, Batch 1400] loss: 0.33152417838573456
[Epoch 5, Batch 1500] loss: 0.3250960246473551
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3352
Validation Accuracy: 0.8990
Overfitting: 0.3352
[Epoch 6, Batch 100] loss: 0.33216758772730826
[Epoch 6, Batch 200] loss: 0.30511541441082957
[Epoch 6, Batch 300] loss: 0.32490461118519304
[Epoch 6, Batch 400] loss: 0.3192976926267147
[Epoch 6, Batch 500] loss: 0.2916806358844042
[Epoch 6, Batch 600] loss: 0.27369291715323923
[Epoch 6, Batch 700] loss: 0.2766745001077652
[Epoch 6, Batch 800] loss: 0.28793084777891637
[Epoch 6, Batch 900] loss: 0.2931555546075106
[Epoch 6, Batch 1000] loss: 0.3170521588623524
[Epoch 6, Batch 1100] loss: 0.27444431722164153
[Epoch 6, Batch 1200] loss: 0.265230398401618
[Epoch 6, Batch 1300] loss: 0.2527401168644428
[Epoch 6, Batch 1400] loss: 0.28376357052475215
[Epoch 6, Batch 1500] loss: 0.2623732289671898
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2853
Validation Accuracy: 0.9151
Overfitting: 0.2853
[Epoch 7, Batch 100] loss: 0.2523884265497327
[Epoch 7, Batch 200] loss: 0.2692917111515999
[Epoch 7, Batch 300] loss: 0.2497175792977214
[Epoch 7, Batch 400] loss: 0.25789833288639785
[Epoch 7, Batch 500] loss: 0.2738880391418934
[Epoch 7, Batch 600] loss: 0.25694949563592673
[Epoch 7, Batch 700] loss: 0.26012129336595535
[Epoch 7, Batch 800] loss: 0.23644897889345884
[Epoch 7, Batch 900] loss: 0.25354479886591436
[Epoch 7, Batch 1000] loss: 0.22994499400258064
[Epoch 7, Batch 1100] loss: 0.25900376357138155
[Epoch 7, Batch 1200] loss: 0.2660898324847221
[Epoch 7, Batch 1300] loss: 0.2264921935647726
[Epoch 7, Batch 1400] loss: 0.2639208010584116
[Epoch 7, Batch 1500] loss: 0.2455221014469862
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2540
Validation Accuracy: 0.9243
Overfitting: 0.2540
[Epoch 8, Batch 100] loss: 0.23784172631800174
[Epoch 8, Batch 200] loss: 0.21093340538442135
[Epoch 8, Batch 300] loss: 0.24013149593025446
[Epoch 8, Batch 400] loss: 0.22809096589684486
[Epoch 8, Batch 500] loss: 0.2265634274482727
[Epoch 8, Batch 600] loss: 0.22740208746865392
[Epoch 8, Batch 700] loss: 0.24823284979909657
[Epoch 8, Batch 800] loss: 0.23431039709597826
[Epoch 8, Batch 900] loss: 0.2109424339607358
[Epoch 8, Batch 1000] loss: 0.2146122620999813
[Epoch 8, Batch 1100] loss: 0.24000140964984895
[Epoch 8, Batch 1200] loss: 0.21888606261461974
[Epoch 8, Batch 1300] loss: 0.23074890978634358
[Epoch 8, Batch 1400] loss: 0.20601653963327407
[Epoch 8, Batch 1500] loss: 0.2056564098969102
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2261
Validation Accuracy: 0.9328
Overfitting: 0.2261
[Epoch 9, Batch 100] loss: 0.22849073527380825
[Epoch 9, Batch 200] loss: 0.2001270791888237
[Epoch 9, Batch 300] loss: 0.2099569570273161
[Epoch 9, Batch 400] loss: 0.2160732015967369
[Epoch 9, Batch 500] loss: 0.20614842738956213
[Epoch 9, Batch 600] loss: 0.22237377058714627
[Epoch 9, Batch 700] loss: 0.20859715599566697
[Epoch 9, Batch 800] loss: 0.22298663299530744
[Epoch 9, Batch 900] loss: 0.19003394581377506
[Epoch 9, Batch 1000] loss: 0.19253857839852573
[Epoch 9, Batch 1100] loss: 0.191778219640255
[Epoch 9, Batch 1200] loss: 0.19541569739580156
[Epoch 9, Batch 1300] loss: 0.19124934144318104
[Epoch 9, Batch 1400] loss: 0.1836278222501278
[Epoch 9, Batch 1500] loss: 0.1828576941601932
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.2056
Validation Accuracy: 0.9382
Overfitting: 0.2056
Best model saved at epoch 9 with validation loss: 0.2056
[Epoch 10, Batch 100] loss: 0.18866713345050812
[Epoch 10, Batch 200] loss: 0.1808034622296691
[Epoch 10, Batch 300] loss: 0.19406118012964726
[Epoch 10, Batch 400] loss: 0.198546694945544
[Epoch 10, Batch 500] loss: 0.2037922065332532
[Epoch 10, Batch 600] loss: 0.18613800648599862
[Epoch 10, Batch 700] loss: 0.18498422808945178
[Epoch 10, Batch 800] loss: 0.18979763071984052
[Epoch 10, Batch 900] loss: 0.16966733932495118
[Epoch 10, Batch 1000] loss: 0.18633553195744754
[Epoch 10, Batch 1100] loss: 0.1886877790093422
[Epoch 10, Batch 1200] loss: 0.1753201886638999
[Epoch 10, Batch 1300] loss: 0.175113425552845
[Epoch 10, Batch 1400] loss: 0.17851069631054997
[Epoch 10, Batch 1500] loss: 0.17262400867417454
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1891
Validation Accuracy: 0.9431
Overfitting: 0.1891
[Epoch 11, Batch 100] loss: 0.15435577685013413
[Epoch 11, Batch 200] loss: 0.18682447446510195
[Epoch 11, Batch 300] loss: 0.17320385381579398
[Epoch 11, Batch 400] loss: 0.17099995069205762
[Epoch 11, Batch 500] loss: 0.1655280302837491
[Epoch 11, Batch 600] loss: 0.1878208632580936
[Epoch 11, Batch 700] loss: 0.16109828742220997
[Epoch 11, Batch 800] loss: 0.17395869079977275
[Epoch 11, Batch 900] loss: 0.1557509471848607
[Epoch 11, Batch 1000] loss: 0.16998411163687707
[Epoch 11, Batch 1100] loss: 0.1694334452226758
[Epoch 11, Batch 1200] loss: 0.15907861545681953
[Epoch 11, Batch 1300] loss: 0.17237792834639548
[Epoch 11, Batch 1400] loss: 0.15909274467267095
[Epoch 11, Batch 1500] loss: 0.16412820413708687
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1729
Validation Accuracy: 0.9493
Overfitting: 0.1729
Best model saved at epoch 11 with validation loss: 0.1729
[Epoch 12, Batch 100] loss: 0.1518054415844381
[Epoch 12, Batch 200] loss: 0.17518905209377408
[Epoch 12, Batch 300] loss: 0.1522613601759076
[Epoch 12, Batch 400] loss: 0.15301561830565333
[Epoch 12, Batch 500] loss: 0.16791864812374116
[Epoch 12, Batch 600] loss: 0.15945355990901589
[Epoch 12, Batch 700] loss: 0.16659015584737064
[Epoch 12, Batch 800] loss: 0.13790240056812764
[Epoch 12, Batch 900] loss: 0.16956783341243864
[Epoch 12, Batch 1000] loss: 0.14543588280677797
[Epoch 12, Batch 1100] loss: 0.15373307328671218
[Epoch 12, Batch 1200] loss: 0.15286972371861338
[Epoch 12, Batch 1300] loss: 0.1518808694370091
[Epoch 12, Batch 1400] loss: 0.15260593693703414
[Epoch 12, Batch 1500] loss: 0.13850238092243672
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1614
Validation Accuracy: 0.9518
Overfitting: 0.1614
[Epoch 13, Batch 100] loss: 0.13569112101569772
[Epoch 13, Batch 200] loss: 0.16160052735358477
[Epoch 13, Batch 300] loss: 0.14757528875023126
[Epoch 13, Batch 400] loss: 0.16150251940824092
[Epoch 13, Batch 500] loss: 0.142607340272516
[Epoch 13, Batch 600] loss: 0.132917433232069
[Epoch 13, Batch 700] loss: 0.14478947738185524
[Epoch 13, Batch 800] loss: 0.14643606680445373
[Epoch 13, Batch 900] loss: 0.15197154586203396
[Epoch 13, Batch 1000] loss: 0.14427434580400586
[Epoch 13, Batch 1100] loss: 0.13507109732367098
[Epoch 13, Batch 1200] loss: 0.14144917741417884
[Epoch 13, Batch 1300] loss: 0.14056981301866472
[Epoch 13, Batch 1400] loss: 0.1490360206272453
[Epoch 13, Batch 1500] loss: 0.12673402052372695
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1527
Validation Accuracy: 0.9557
Overfitting: 0.1527
Early stopping epoch 13 for trial 4. Moving to next fold.
Fold 2 validation loss: 0.1527
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.299699878692627
[Epoch 1, Batch 200] loss: 2.2983645224571227
[Epoch 1, Batch 300] loss: 2.2977795362472535
[Epoch 1, Batch 400] loss: 2.2949846601486206
[Epoch 1, Batch 500] loss: 2.293108069896698
[Epoch 1, Batch 600] loss: 2.291681663990021
[Epoch 1, Batch 700] loss: 2.2884902811050414
[Epoch 1, Batch 800] loss: 2.2862408852577207
[Epoch 1, Batch 900] loss: 2.2831188821792603
[Epoch 1, Batch 1000] loss: 2.2809862971305845
[Epoch 1, Batch 1100] loss: 2.276092326641083
[Epoch 1, Batch 1200] loss: 2.2721925592422485
[Epoch 1, Batch 1300] loss: 2.268598635196686
[Epoch 1, Batch 1400] loss: 2.263213927745819
[Epoch 1, Batch 1500] loss: 2.258577835559845
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2557
Validation Accuracy: 0.3372
Overfitting: 2.2557
[Epoch 2, Batch 100] loss: 2.252546923160553
[Epoch 2, Batch 200] loss: 2.2413587379455566
[Epoch 2, Batch 300] loss: 2.2362875080108644
[Epoch 2, Batch 400] loss: 2.2267683649063112
[Epoch 2, Batch 500] loss: 2.216368730068207
[Epoch 2, Batch 600] loss: 2.200030891895294
[Epoch 2, Batch 700] loss: 2.1836999607086183
[Epoch 2, Batch 800] loss: 2.1641061067581178
[Epoch 2, Batch 900] loss: 2.138967502117157
[Epoch 2, Batch 1000] loss: 2.1027541184425353
[Epoch 2, Batch 1100] loss: 2.0665821075439452
[Epoch 2, Batch 1200] loss: 2.0109425950050355
[Epoch 2, Batch 1300] loss: 1.9386725294589997
[Epoch 2, Batch 1400] loss: 1.8377139627933503
[Epoch 2, Batch 1500] loss: 1.733634123802185
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.6682
Validation Accuracy: 0.6282
Overfitting: 1.6682
[Epoch 3, Batch 100] loss: 1.604459354877472
[Epoch 3, Batch 200] loss: 1.4670669782161712
[Epoch 3, Batch 300] loss: 1.29593275308609
[Epoch 3, Batch 400] loss: 1.1546473151445389
[Epoch 3, Batch 500] loss: 1.0320640814304352
[Epoch 3, Batch 600] loss: 0.9375279003381729
[Epoch 3, Batch 700] loss: 0.8370483201742173
[Epoch 3, Batch 800] loss: 0.7822961348295212
[Epoch 3, Batch 900] loss: 0.7355815976858139
[Epoch 3, Batch 1000] loss: 0.6701945754885673
[Epoch 3, Batch 1100] loss: 0.6054485592246056
[Epoch 3, Batch 1200] loss: 0.585097382068634
[Epoch 3, Batch 1300] loss: 0.5506693986058235
[Epoch 3, Batch 1400] loss: 0.5559185644984246
[Epoch 3, Batch 1500] loss: 0.5354615467786789
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.5087
Validation Accuracy: 0.8510
Overfitting: 0.5087
[Epoch 4, Batch 100] loss: 0.5151246044039727
[Epoch 4, Batch 200] loss: 0.5413001954555512
[Epoch 4, Batch 300] loss: 0.4759391044080257
[Epoch 4, Batch 400] loss: 0.4947054634988308
[Epoch 4, Batch 500] loss: 0.43737978875637057
[Epoch 4, Batch 600] loss: 0.45508851408958434
[Epoch 4, Batch 700] loss: 0.44685221284627913
[Epoch 4, Batch 800] loss: 0.4305118565261364
[Epoch 4, Batch 900] loss: 0.44464721992611883
[Epoch 4, Batch 1000] loss: 0.40399048656225206
[Epoch 4, Batch 1100] loss: 0.4075200869143009
[Epoch 4, Batch 1200] loss: 0.4009410226345062
[Epoch 4, Batch 1300] loss: 0.38836699768900873
[Epoch 4, Batch 1400] loss: 0.42560132548213003
[Epoch 4, Batch 1500] loss: 0.4150170500576496
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3925
Validation Accuracy: 0.8814
Overfitting: 0.3925
[Epoch 5, Batch 100] loss: 0.4125266829878092
[Epoch 5, Batch 200] loss: 0.3945975261926651
[Epoch 5, Batch 300] loss: 0.3802664737403393
[Epoch 5, Batch 400] loss: 0.36996209636330607
[Epoch 5, Batch 500] loss: 0.36146330505609514
[Epoch 5, Batch 600] loss: 0.34342604734003546
[Epoch 5, Batch 700] loss: 0.37115639835596087
[Epoch 5, Batch 800] loss: 0.34555268913507464
[Epoch 5, Batch 900] loss: 0.33775632858276367
[Epoch 5, Batch 1000] loss: 0.34242116525769234
[Epoch 5, Batch 1100] loss: 0.34123973675072194
[Epoch 5, Batch 1200] loss: 0.3444369013607502
[Epoch 5, Batch 1300] loss: 0.3405101341754198
[Epoch 5, Batch 1400] loss: 0.34836150750517847
[Epoch 5, Batch 1500] loss: 0.33725434392690656
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3260
Validation Accuracy: 0.9047
Overfitting: 0.3260
[Epoch 6, Batch 100] loss: 0.33038594663143156
[Epoch 6, Batch 200] loss: 0.31408171623945236
[Epoch 6, Batch 300] loss: 0.3080718429759145
[Epoch 6, Batch 400] loss: 0.3157988920807838
[Epoch 6, Batch 500] loss: 0.3345665508508682
[Epoch 6, Batch 600] loss: 0.32014344207942486
[Epoch 6, Batch 700] loss: 0.2983539391309023
[Epoch 6, Batch 800] loss: 0.2847882489860058
[Epoch 6, Batch 900] loss: 0.30714471116662023
[Epoch 6, Batch 1000] loss: 0.2995460783690214
[Epoch 6, Batch 1100] loss: 0.2750799367576838
[Epoch 6, Batch 1200] loss: 0.2723697277903557
[Epoch 6, Batch 1300] loss: 0.3087032758444548
[Epoch 6, Batch 1400] loss: 0.287529329136014
[Epoch 6, Batch 1500] loss: 0.30083591092377904
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2845
Validation Accuracy: 0.9143
Overfitting: 0.2845
[Epoch 7, Batch 100] loss: 0.2824818975478411
[Epoch 7, Batch 200] loss: 0.29726449612528083
[Epoch 7, Batch 300] loss: 0.2500301466882229
[Epoch 7, Batch 400] loss: 0.2630080781504512
[Epoch 7, Batch 500] loss: 0.28453378435224297
[Epoch 7, Batch 600] loss: 0.26860120125114917
[Epoch 7, Batch 700] loss: 0.2647848822176456
[Epoch 7, Batch 800] loss: 0.26697422966361045
[Epoch 7, Batch 900] loss: 0.267649402692914
[Epoch 7, Batch 1000] loss: 0.26479585021734237
[Epoch 7, Batch 1100] loss: 0.24118986748158933
[Epoch 7, Batch 1200] loss: 0.2436648129671812
[Epoch 7, Batch 1300] loss: 0.25878839001059534
[Epoch 7, Batch 1400] loss: 0.2455850686877966
[Epoch 7, Batch 1500] loss: 0.2541966822370887
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2557
Validation Accuracy: 0.9239
Overfitting: 0.2557
[Epoch 8, Batch 100] loss: 0.23451595731079578
[Epoch 8, Batch 200] loss: 0.22985360700637103
[Epoch 8, Batch 300] loss: 0.21465704288333654
[Epoch 8, Batch 400] loss: 0.2549647498130798
[Epoch 8, Batch 500] loss: 0.23233410868793725
[Epoch 8, Batch 600] loss: 0.24026309102773666
[Epoch 8, Batch 700] loss: 0.2388771629333496
[Epoch 8, Batch 800] loss: 0.24257860105484724
[Epoch 8, Batch 900] loss: 0.24523908719420434
[Epoch 8, Batch 1000] loss: 0.22980000026524067
[Epoch 8, Batch 1100] loss: 0.24371713005006312
[Epoch 8, Batch 1200] loss: 0.22223167397081853
[Epoch 8, Batch 1300] loss: 0.21636816613376142
[Epoch 8, Batch 1400] loss: 0.2265571140125394
[Epoch 8, Batch 1500] loss: 0.21860992219299077
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2237
Validation Accuracy: 0.9327
Overfitting: 0.2237
[Epoch 9, Batch 100] loss: 0.2163793867081404
[Epoch 9, Batch 200] loss: 0.22485282560810446
[Epoch 9, Batch 300] loss: 0.2162649418413639
[Epoch 9, Batch 400] loss: 0.18996828163042664
[Epoch 9, Batch 500] loss: 0.1908845404908061
[Epoch 9, Batch 600] loss: 0.2088298511877656
[Epoch 9, Batch 700] loss: 0.21829436853528023
[Epoch 9, Batch 800] loss: 0.20351760812103747
[Epoch 9, Batch 900] loss: 0.23753297574818133
[Epoch 9, Batch 1000] loss: 0.20058846820145845
[Epoch 9, Batch 1100] loss: 0.2090528888069093
[Epoch 9, Batch 1200] loss: 0.19951093066483735
[Epoch 9, Batch 1300] loss: 0.18893922708928584
[Epoch 9, Batch 1400] loss: 0.1938279592245817
[Epoch 9, Batch 1500] loss: 0.21263352040201425
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.2030
Validation Accuracy: 0.9385
Overfitting: 0.2030
Best model saved at epoch 9 with validation loss: 0.2030
[Epoch 10, Batch 100] loss: 0.1827432786487043
[Epoch 10, Batch 200] loss: 0.18396797571331264
[Epoch 10, Batch 300] loss: 0.19912116844207048
[Epoch 10, Batch 400] loss: 0.19365919768810272
[Epoch 10, Batch 500] loss: 0.20863967370241882
[Epoch 10, Batch 600] loss: 0.19627836138010024
[Epoch 10, Batch 700] loss: 0.18413262639194727
[Epoch 10, Batch 800] loss: 0.18683559083379805
[Epoch 10, Batch 900] loss: 0.17541371185332535
[Epoch 10, Batch 1000] loss: 0.18036959256976842
[Epoch 10, Batch 1100] loss: 0.17144204093143345
[Epoch 10, Batch 1200] loss: 0.18740151900798083
[Epoch 10, Batch 1300] loss: 0.18691368663683533
[Epoch 10, Batch 1400] loss: 0.16796945866197346
[Epoch 10, Batch 1500] loss: 0.1871751712076366
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1823
Validation Accuracy: 0.9451
Overfitting: 0.1823
[Epoch 11, Batch 100] loss: 0.15903225727379322
[Epoch 11, Batch 200] loss: 0.16913983529433607
[Epoch 11, Batch 300] loss: 0.1873202681541443
[Epoch 11, Batch 400] loss: 0.17103456046432255
[Epoch 11, Batch 500] loss: 0.16640616908669473
[Epoch 11, Batch 600] loss: 0.17499723510816692
[Epoch 11, Batch 700] loss: 0.15927512051537632
[Epoch 11, Batch 800] loss: 0.18744507582858205
[Epoch 11, Batch 900] loss: 0.16021626714617013
[Epoch 11, Batch 1000] loss: 0.17050252489745618
[Epoch 11, Batch 1100] loss: 0.16868282161653042
[Epoch 11, Batch 1200] loss: 0.15058409508317708
[Epoch 11, Batch 1300] loss: 0.18013520712964237
[Epoch 11, Batch 1400] loss: 0.17510097714141012
[Epoch 11, Batch 1500] loss: 0.15857016233727336
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1693
Validation Accuracy: 0.9485
Overfitting: 0.1693
Best model saved at epoch 11 with validation loss: 0.1693
[Epoch 12, Batch 100] loss: 0.16065819554030894
[Epoch 12, Batch 200] loss: 0.1691575994156301
[Epoch 12, Batch 300] loss: 0.15585405688732862
[Epoch 12, Batch 400] loss: 0.17306768530979752
[Epoch 12, Batch 500] loss: 0.14457928197458386
[Epoch 12, Batch 600] loss: 0.15676443135365845
[Epoch 12, Batch 700] loss: 0.15404443822801114
[Epoch 12, Batch 800] loss: 0.1701780813001096
[Epoch 12, Batch 900] loss: 0.15071087411604822
[Epoch 12, Batch 1000] loss: 0.1437987948767841
[Epoch 12, Batch 1100] loss: 0.1532956263050437
[Epoch 12, Batch 1200] loss: 0.15009839268401265
[Epoch 12, Batch 1300] loss: 0.1427648403123021
[Epoch 12, Batch 1400] loss: 0.13643494497984648
[Epoch 12, Batch 1500] loss: 0.14743435204029084
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1665
Validation Accuracy: 0.9497
Overfitting: 0.1665
[Epoch 13, Batch 100] loss: 0.14798208583146333
[Epoch 13, Batch 200] loss: 0.14868372776545585
[Epoch 13, Batch 300] loss: 0.15492953084409236
[Epoch 13, Batch 400] loss: 0.14301709225401282
[Epoch 13, Batch 500] loss: 0.14126431863754987
[Epoch 13, Batch 600] loss: 0.13878671418875455
[Epoch 13, Batch 700] loss: 0.12984388489276172
[Epoch 13, Batch 800] loss: 0.14491251682862638
[Epoch 13, Batch 900] loss: 0.145920064849779
[Epoch 13, Batch 1000] loss: 0.14308214213699103
[Epoch 13, Batch 1100] loss: 0.12663942215964197
[Epoch 13, Batch 1200] loss: 0.1384713975712657
[Epoch 13, Batch 1300] loss: 0.13635647703893483
[Epoch 13, Batch 1400] loss: 0.13967160526663064
[Epoch 13, Batch 1500] loss: 0.15670799759216605
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1539
Validation Accuracy: 0.9538
Overfitting: 0.1539
Early stopping epoch 13 for trial 4. Moving to next fold.
Fold 3 validation loss: 0.1539
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.3076696586608887
[Epoch 1, Batch 200] loss: 2.3043552446365356
[Epoch 1, Batch 300] loss: 2.3025785446166993
[Epoch 1, Batch 400] loss: 2.297832024097443
[Epoch 1, Batch 500] loss: 2.296532442569733
[Epoch 1, Batch 600] loss: 2.29400582075119
[Epoch 1, Batch 700] loss: 2.2901661872863768
[Epoch 1, Batch 800] loss: 2.2879575157165526
[Epoch 1, Batch 900] loss: 2.282922525405884
[Epoch 1, Batch 1000] loss: 2.2802488589286805
[Epoch 1, Batch 1100] loss: 2.2776904845237733
[Epoch 1, Batch 1200] loss: 2.271976902484894
[Epoch 1, Batch 1300] loss: 2.265730452537537
[Epoch 1, Batch 1400] loss: 2.2601297187805174
[Epoch 1, Batch 1500] loss: 2.252518057823181
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2503
Validation Accuracy: 0.3105
Overfitting: 2.2503
[Epoch 2, Batch 100] loss: 2.245777771472931
[Epoch 2, Batch 200] loss: 2.237204365730286
[Epoch 2, Batch 300] loss: 2.2247106075286864
[Epoch 2, Batch 400] loss: 2.2140258312225343
[Epoch 2, Batch 500] loss: 2.19801620721817
[Epoch 2, Batch 600] loss: 2.1794130301475523
[Epoch 2, Batch 700] loss: 2.156774365901947
[Epoch 2, Batch 800] loss: 2.1271026587486266
[Epoch 2, Batch 900] loss: 2.0920289063453676
[Epoch 2, Batch 1000] loss: 2.047066874504089
[Epoch 2, Batch 1100] loss: 1.9881228125095367
[Epoch 2, Batch 1200] loss: 1.908640090227127
[Epoch 2, Batch 1300] loss: 1.8182571303844453
[Epoch 2, Batch 1400] loss: 1.6960681653022767
[Epoch 2, Batch 1500] loss: 1.549651015996933
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.4737
Validation Accuracy: 0.7638
Overfitting: 1.4737
[Epoch 3, Batch 100] loss: 1.385386381149292
[Epoch 3, Batch 200] loss: 1.2148851972818375
[Epoch 3, Batch 300] loss: 1.0508014130592347
[Epoch 3, Batch 400] loss: 0.9556538325548172
[Epoch 3, Batch 500] loss: 0.8538165885210037
[Epoch 3, Batch 600] loss: 0.7771721655130386
[Epoch 3, Batch 700] loss: 0.6975793507695198
[Epoch 3, Batch 800] loss: 0.6443233704566955
[Epoch 3, Batch 900] loss: 0.5979208573698997
[Epoch 3, Batch 1000] loss: 0.5561537820100785
[Epoch 3, Batch 1100] loss: 0.5318079322576523
[Epoch 3, Batch 1200] loss: 0.5225202539563178
[Epoch 3, Batch 1300] loss: 0.49546850576996804
[Epoch 3, Batch 1400] loss: 0.4686547999083996
[Epoch 3, Batch 1500] loss: 0.43923646107316017
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.4573
Validation Accuracy: 0.8668
Overfitting: 0.4573
[Epoch 4, Batch 100] loss: 0.43306495681405066
[Epoch 4, Batch 200] loss: 0.4096668240427971
[Epoch 4, Batch 300] loss: 0.39864969089627267
[Epoch 4, Batch 400] loss: 0.40994432896375654
[Epoch 4, Batch 500] loss: 0.4160024440288544
[Epoch 4, Batch 600] loss: 0.384601658731699
[Epoch 4, Batch 700] loss: 0.38951527774333955
[Epoch 4, Batch 800] loss: 0.3863202579319477
[Epoch 4, Batch 900] loss: 0.379463979229331
[Epoch 4, Batch 1000] loss: 0.35152535393834117
[Epoch 4, Batch 1100] loss: 0.385682816952467
[Epoch 4, Batch 1200] loss: 0.3564457505941391
[Epoch 4, Batch 1300] loss: 0.34773860514163973
[Epoch 4, Batch 1400] loss: 0.3366388189792633
[Epoch 4, Batch 1500] loss: 0.32762042962014676
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3374
Validation Accuracy: 0.8992
Overfitting: 0.3374
[Epoch 5, Batch 100] loss: 0.3171438756585121
[Epoch 5, Batch 200] loss: 0.3169266352057457
[Epoch 5, Batch 300] loss: 0.31603077284991743
[Epoch 5, Batch 400] loss: 0.33513478890061377
[Epoch 5, Batch 500] loss: 0.3227378551661968
[Epoch 5, Batch 600] loss: 0.3017596146464348
[Epoch 5, Batch 700] loss: 0.3048087801039219
[Epoch 5, Batch 800] loss: 0.30344064138829707
[Epoch 5, Batch 900] loss: 0.29691636621952056
[Epoch 5, Batch 1000] loss: 0.3020733927190304
[Epoch 5, Batch 1100] loss: 0.2881866950541735
[Epoch 5, Batch 1200] loss: 0.2775805776566267
[Epoch 5, Batch 1300] loss: 0.3025254487991333
[Epoch 5, Batch 1400] loss: 0.29654011502861977
[Epoch 5, Batch 1500] loss: 0.2718822947517037
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.2745
Validation Accuracy: 0.9180
Overfitting: 0.2745
[Epoch 6, Batch 100] loss: 0.274869835190475
[Epoch 6, Batch 200] loss: 0.264280811175704
[Epoch 6, Batch 300] loss: 0.27737522080540655
[Epoch 6, Batch 400] loss: 0.2848362049460411
[Epoch 6, Batch 500] loss: 0.27577950567007065
[Epoch 6, Batch 600] loss: 0.2830726288631558
[Epoch 6, Batch 700] loss: 0.2543171276152134
[Epoch 6, Batch 800] loss: 0.22944155026227236
[Epoch 6, Batch 900] loss: 0.2557948098704219
[Epoch 6, Batch 1000] loss: 0.2612675281614065
[Epoch 6, Batch 1100] loss: 0.2682566310465336
[Epoch 6, Batch 1200] loss: 0.24043306307867168
[Epoch 6, Batch 1300] loss: 0.2438331051543355
[Epoch 6, Batch 1400] loss: 0.24039981327950954
[Epoch 6, Batch 1500] loss: 0.2298281453549862
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2412
Validation Accuracy: 0.9270
Overfitting: 0.2412
[Epoch 7, Batch 100] loss: 0.23765642434358597
[Epoch 7, Batch 200] loss: 0.23528248563408852
[Epoch 7, Batch 300] loss: 0.2268676844984293
[Epoch 7, Batch 400] loss: 0.23890546645969152
[Epoch 7, Batch 500] loss: 0.25143362261354923
[Epoch 7, Batch 600] loss: 0.23508458200842142
[Epoch 7, Batch 700] loss: 0.21294254176318644
[Epoch 7, Batch 800] loss: 0.2091495693102479
[Epoch 7, Batch 900] loss: 0.25879249431192874
[Epoch 7, Batch 1000] loss: 0.2256079902127385
[Epoch 7, Batch 1100] loss: 0.2146956385113299
[Epoch 7, Batch 1200] loss: 0.21845289738848805
[Epoch 7, Batch 1300] loss: 0.21376085612922907
[Epoch 7, Batch 1400] loss: 0.21668292071670295
[Epoch 7, Batch 1500] loss: 0.2305507313646376
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2162
Validation Accuracy: 0.9327
Overfitting: 0.2162
[Epoch 8, Batch 100] loss: 0.198707107976079
[Epoch 8, Batch 200] loss: 0.19458436828106643
[Epoch 8, Batch 300] loss: 0.24246586386114358
[Epoch 8, Batch 400] loss: 0.1965847453288734
[Epoch 8, Batch 500] loss: 0.20557544365525246
[Epoch 8, Batch 600] loss: 0.20718732934445142
[Epoch 8, Batch 700] loss: 0.2161902391165495
[Epoch 8, Batch 800] loss: 0.19663689117878674
[Epoch 8, Batch 900] loss: 0.2034281735494733
[Epoch 8, Batch 1000] loss: 0.17969186164438725
[Epoch 8, Batch 1100] loss: 0.20857564380392432
[Epoch 8, Batch 1200] loss: 0.1880734596401453
[Epoch 8, Batch 1300] loss: 0.18920718476176263
[Epoch 8, Batch 1400] loss: 0.20657883781939745
[Epoch 8, Batch 1500] loss: 0.22123832792043685
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.1966
Validation Accuracy: 0.9403
Overfitting: 0.1966
[Epoch 9, Batch 100] loss: 0.18029038067907094
[Epoch 9, Batch 200] loss: 0.19177491072565317
[Epoch 9, Batch 300] loss: 0.20804926756769418
[Epoch 9, Batch 400] loss: 0.18312930466607213
[Epoch 9, Batch 500] loss: 0.20379564486443996
[Epoch 9, Batch 600] loss: 0.1834144200757146
[Epoch 9, Batch 700] loss: 0.19636493796482682
[Epoch 9, Batch 800] loss: 0.17050808105617762
[Epoch 9, Batch 900] loss: 0.1817015526071191
[Epoch 9, Batch 1000] loss: 0.19377581981942057
[Epoch 9, Batch 1100] loss: 0.1634923162870109
[Epoch 9, Batch 1200] loss: 0.17721443094313144
[Epoch 9, Batch 1300] loss: 0.18218863010406494
[Epoch 9, Batch 1400] loss: 0.1887277205660939
[Epoch 9, Batch 1500] loss: 0.16711240859702228
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1740
Validation Accuracy: 0.9468
Overfitting: 0.1740
Best model saved at epoch 9 with validation loss: 0.1740
[Epoch 10, Batch 100] loss: 0.17557943189516664
[Epoch 10, Batch 200] loss: 0.17390818223357202
[Epoch 10, Batch 300] loss: 0.1710828747227788
[Epoch 10, Batch 400] loss: 0.16800735000520944
[Epoch 10, Batch 500] loss: 0.16714510352350773
[Epoch 10, Batch 600] loss: 0.178445827011019
[Epoch 10, Batch 700] loss: 0.1775676910020411
[Epoch 10, Batch 800] loss: 0.16829222228378057
[Epoch 10, Batch 900] loss: 0.1624238637648523
[Epoch 10, Batch 1000] loss: 0.17279964176937937
[Epoch 10, Batch 1100] loss: 0.15275597295723856
[Epoch 10, Batch 1200] loss: 0.15054554367437958
[Epoch 10, Batch 1300] loss: 0.16431888069957495
[Epoch 10, Batch 1400] loss: 0.17838499926030635
[Epoch 10, Batch 1500] loss: 0.16996537460014224
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1707
Validation Accuracy: 0.9467
Overfitting: 0.1707
[Epoch 11, Batch 100] loss: 0.16063723083585502
[Epoch 11, Batch 200] loss: 0.15873341675847769
[Epoch 11, Batch 300] loss: 0.16652574336156248
[Epoch 11, Batch 400] loss: 0.15614205257035793
[Epoch 11, Batch 500] loss: 0.15147080335766078
[Epoch 11, Batch 600] loss: 0.14478360274806618
[Epoch 11, Batch 700] loss: 0.15537622263655065
[Epoch 11, Batch 800] loss: 0.1512886118888855
[Epoch 11, Batch 900] loss: 0.14902999721467494
[Epoch 11, Batch 1000] loss: 0.1497661011479795
[Epoch 11, Batch 1100] loss: 0.16530794858932496
[Epoch 11, Batch 1200] loss: 0.15680845139548183
[Epoch 11, Batch 1300] loss: 0.15652495061978697
[Epoch 11, Batch 1400] loss: 0.15881887642666698
[Epoch 11, Batch 1500] loss: 0.1551004088111222
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1458
Validation Accuracy: 0.9556
Overfitting: 0.1458
Early stopping epoch 11 for trial 4. Moving to next fold.
Fold 4 validation loss: 0.1458
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.296926975250244
[Epoch 1, Batch 200] loss: 2.293137686252594
[Epoch 1, Batch 300] loss: 2.2875891160964965
[Epoch 1, Batch 400] loss: 2.286109664440155
[Epoch 1, Batch 500] loss: 2.2787954139709474
[Epoch 1, Batch 600] loss: 2.2734610295295714
[Epoch 1, Batch 700] loss: 2.2667524886131285
[Epoch 1, Batch 800] loss: 2.2566377472877504
[Epoch 1, Batch 900] loss: 2.2515739154815675
[Epoch 1, Batch 1000] loss: 2.2441071915626525
[Epoch 1, Batch 1100] loss: 2.225593616962433
[Epoch 1, Batch 1200] loss: 2.2160393357276917
[Epoch 1, Batch 1300] loss: 2.1962359952926636
[Epoch 1, Batch 1400] loss: 2.1776092219352723
[Epoch 1, Batch 1500] loss: 2.1452987957000733
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.1275
Validation Accuracy: 0.5313
Overfitting: 2.1275
[Epoch 2, Batch 100] loss: 2.112704315185547
[Epoch 2, Batch 200] loss: 2.0637097787857055
[Epoch 2, Batch 300] loss: 2.007508385181427
[Epoch 2, Batch 400] loss: 1.919107152223587
[Epoch 2, Batch 500] loss: 1.8114840495586395
[Epoch 2, Batch 600] loss: 1.6951261055469513
[Epoch 2, Batch 700] loss: 1.537426664829254
[Epoch 2, Batch 800] loss: 1.3965932548046112
[Epoch 2, Batch 900] loss: 1.2252900004386902
[Epoch 2, Batch 1000] loss: 1.0814865386486054
[Epoch 2, Batch 1100] loss: 0.9813035207986832
[Epoch 2, Batch 1200] loss: 0.8805681544542313
[Epoch 2, Batch 1300] loss: 0.7950530543923378
[Epoch 2, Batch 1400] loss: 0.7248895636200905
[Epoch 2, Batch 1500] loss: 0.714554141163826
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.6690
Validation Accuracy: 0.8087
Overfitting: 0.6690
[Epoch 3, Batch 100] loss: 0.6495290902256966
[Epoch 3, Batch 200] loss: 0.6035055127739907
[Epoch 3, Batch 300] loss: 0.5718424892425538
[Epoch 3, Batch 400] loss: 0.5822716329991817
[Epoch 3, Batch 500] loss: 0.5408647927641869
[Epoch 3, Batch 600] loss: 0.5282167513668538
[Epoch 3, Batch 700] loss: 0.5128485724329949
[Epoch 3, Batch 800] loss: 0.5118976005911827
[Epoch 3, Batch 900] loss: 0.4962031787633896
[Epoch 3, Batch 1000] loss: 0.4708856534957886
[Epoch 3, Batch 1100] loss: 0.4603896138072014
[Epoch 3, Batch 1200] loss: 0.4708075228333473
[Epoch 3, Batch 1300] loss: 0.50861990660429
[Epoch 3, Batch 1400] loss: 0.4582024908065796
[Epoch 3, Batch 1500] loss: 0.4515062689781189
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.4449
Validation Accuracy: 0.8682
Overfitting: 0.4449
[Epoch 4, Batch 100] loss: 0.4433558496832848
[Epoch 4, Batch 200] loss: 0.4189586149156094
[Epoch 4, Batch 300] loss: 0.4160803781449795
[Epoch 4, Batch 400] loss: 0.41167708203196524
[Epoch 4, Batch 500] loss: 0.4087414778769016
[Epoch 4, Batch 600] loss: 0.405225460678339
[Epoch 4, Batch 700] loss: 0.42243283867836
[Epoch 4, Batch 800] loss: 0.38958564184606076
[Epoch 4, Batch 900] loss: 0.3683192750811577
[Epoch 4, Batch 1000] loss: 0.4006038634479046
[Epoch 4, Batch 1100] loss: 0.38616199642419813
[Epoch 4, Batch 1200] loss: 0.37571737423539164
[Epoch 4, Batch 1300] loss: 0.3565890300273895
[Epoch 4, Batch 1400] loss: 0.35723960980772973
[Epoch 4, Batch 1500] loss: 0.36988005027174947
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3714
Validation Accuracy: 0.8891
Overfitting: 0.3714
[Epoch 5, Batch 100] loss: 0.3596631145477295
[Epoch 5, Batch 200] loss: 0.3569191264361143
[Epoch 5, Batch 300] loss: 0.33994730457663536
[Epoch 5, Batch 400] loss: 0.3594371373951435
[Epoch 5, Batch 500] loss: 0.32236171029508115
[Epoch 5, Batch 600] loss: 0.3324584197252989
[Epoch 5, Batch 700] loss: 0.3444619780778885
[Epoch 5, Batch 800] loss: 0.31210770457983017
[Epoch 5, Batch 900] loss: 0.3286863473057747
[Epoch 5, Batch 1000] loss: 0.31580056212842467
[Epoch 5, Batch 1100] loss: 0.31794486738741395
[Epoch 5, Batch 1200] loss: 0.33792962446808816
[Epoch 5, Batch 1300] loss: 0.31664321474730966
[Epoch 5, Batch 1400] loss: 0.3136472709476948
[Epoch 5, Batch 1500] loss: 0.32643054544925687
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3102
Validation Accuracy: 0.9062
Overfitting: 0.3102
[Epoch 6, Batch 100] loss: 0.2980541305989027
[Epoch 6, Batch 200] loss: 0.3149452390521765
[Epoch 6, Batch 300] loss: 0.2976447157561779
[Epoch 6, Batch 400] loss: 0.2955953250080347
[Epoch 6, Batch 500] loss: 0.26927844405174256
[Epoch 6, Batch 600] loss: 0.297594550922513
[Epoch 6, Batch 700] loss: 0.2934822522476315
[Epoch 6, Batch 800] loss: 0.2851637218892574
[Epoch 6, Batch 900] loss: 0.2872437399625778
[Epoch 6, Batch 1000] loss: 0.27779478296637533
[Epoch 6, Batch 1100] loss: 0.27902947075664997
[Epoch 6, Batch 1200] loss: 0.29468991089612245
[Epoch 6, Batch 1300] loss: 0.26400949239730837
[Epoch 6, Batch 1400] loss: 0.27154249224811794
[Epoch 6, Batch 1500] loss: 0.2623851189389825
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2740
Validation Accuracy: 0.9178
Overfitting: 0.2740
[Epoch 7, Batch 100] loss: 0.2666442062705755
[Epoch 7, Batch 200] loss: 0.2577655963227153
[Epoch 7, Batch 300] loss: 0.2473395749926567
[Epoch 7, Batch 400] loss: 0.2399288161844015
[Epoch 7, Batch 500] loss: 0.2626957256346941
[Epoch 7, Batch 600] loss: 0.24144672460854052
[Epoch 7, Batch 700] loss: 0.24623001828789712
[Epoch 7, Batch 800] loss: 0.2621477083861828
[Epoch 7, Batch 900] loss: 0.24704443577677013
[Epoch 7, Batch 1000] loss: 0.24333848502486943
[Epoch 7, Batch 1100] loss: 0.23646597132086755
[Epoch 7, Batch 1200] loss: 0.265041743516922
[Epoch 7, Batch 1300] loss: 0.2656748304888606
[Epoch 7, Batch 1400] loss: 0.22883538726717234
[Epoch 7, Batch 1500] loss: 0.23832455940544606
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2353
Validation Accuracy: 0.9299
Overfitting: 0.2353
[Epoch 8, Batch 100] loss: 0.23136916229501367
[Epoch 8, Batch 200] loss: 0.22964122608304025
[Epoch 8, Batch 300] loss: 0.2175404204055667
[Epoch 8, Batch 400] loss: 0.20784489434212447
[Epoch 8, Batch 500] loss: 0.23986299574375153
[Epoch 8, Batch 600] loss: 0.22282668858766555
[Epoch 8, Batch 700] loss: 0.2263160502910614
[Epoch 8, Batch 800] loss: 0.2247859464585781
[Epoch 8, Batch 900] loss: 0.2141744175925851
[Epoch 8, Batch 1000] loss: 0.23292272202670575
[Epoch 8, Batch 1100] loss: 0.20809869036078454
[Epoch 8, Batch 1200] loss: 0.20963037777692078
[Epoch 8, Batch 1300] loss: 0.229341155923903
[Epoch 8, Batch 1400] loss: 0.2176853380911052
[Epoch 8, Batch 1500] loss: 0.20409667115658522
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2121
Validation Accuracy: 0.9359
Overfitting: 0.2121
[Epoch 9, Batch 100] loss: 0.19906515222042798
[Epoch 9, Batch 200] loss: 0.18336372019723057
[Epoch 9, Batch 300] loss: 0.19724705200642348
[Epoch 9, Batch 400] loss: 0.19390456061810254
[Epoch 9, Batch 500] loss: 0.20397353325039147
[Epoch 9, Batch 600] loss: 0.18547226892784238
[Epoch 9, Batch 700] loss: 0.2068106332048774
[Epoch 9, Batch 800] loss: 0.1962291963212192
[Epoch 9, Batch 900] loss: 0.22806746639311315
[Epoch 9, Batch 1000] loss: 0.21949248561635615
[Epoch 9, Batch 1100] loss: 0.18040358547121285
[Epoch 9, Batch 1200] loss: 0.19542568419128656
[Epoch 9, Batch 1300] loss: 0.20036807483062147
[Epoch 9, Batch 1400] loss: 0.18045301485806703
[Epoch 9, Batch 1500] loss: 0.19679169662296772
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1901
Validation Accuracy: 0.9440
Overfitting: 0.1901
Best model saved at epoch 9 with validation loss: 0.1901
[Epoch 10, Batch 100] loss: 0.19965073473751546
[Epoch 10, Batch 200] loss: 0.1691848391480744
[Epoch 10, Batch 300] loss: 0.18217857118695974
[Epoch 10, Batch 400] loss: 0.17023802280426026
[Epoch 10, Batch 500] loss: 0.18314067013561725
[Epoch 10, Batch 600] loss: 0.19968721825629474
[Epoch 10, Batch 700] loss: 0.18641516607254743
[Epoch 10, Batch 800] loss: 0.18987240143120288
[Epoch 10, Batch 900] loss: 0.17315100129693747
[Epoch 10, Batch 1000] loss: 0.1705925074778497
[Epoch 10, Batch 1100] loss: 0.1734326777048409
[Epoch 10, Batch 1200] loss: 0.17753392903134227
[Epoch 10, Batch 1300] loss: 0.18718401465564966
[Epoch 10, Batch 1400] loss: 0.17306355480104685
[Epoch 10, Batch 1500] loss: 0.15481663247570396
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1780
Validation Accuracy: 0.9482
Overfitting: 0.1780
[Epoch 11, Batch 100] loss: 0.16678928598761558
[Epoch 11, Batch 200] loss: 0.17567600071430206
[Epoch 11, Batch 300] loss: 0.16158288780599833
[Epoch 11, Batch 400] loss: 0.1690180360339582
[Epoch 11, Batch 500] loss: 0.16266743861138822
[Epoch 11, Batch 600] loss: 0.16507489547133447
[Epoch 11, Batch 700] loss: 0.16295059302821754
[Epoch 11, Batch 800] loss: 0.16133984338492155
[Epoch 11, Batch 900] loss: 0.16722614858299495
[Epoch 11, Batch 1000] loss: 0.15024723263457418
[Epoch 11, Batch 1100] loss: 0.1495388799160719
[Epoch 11, Batch 1200] loss: 0.19900778343901038
[Epoch 11, Batch 1300] loss: 0.14771423825994134
[Epoch 11, Batch 1400] loss: 0.15203734271228314
[Epoch 11, Batch 1500] loss: 0.1670792351476848
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1660
Validation Accuracy: 0.9524
Overfitting: 0.1660
Early stopping epoch 11 for trial 4. Moving to next fold.
Fold 5 validation loss: 0.1660
Mean validation loss across all folds for Trial 4 is 0.1540 with trial config:  l1: 256, l2: 128, lr: 0.0001, batch_size: 32
[I 2024-12-10 04:23:45,030] Trial 3 finished with value: 0.1540181314294537 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0001, 'batch_size': 32}. Best is trial 0 with value: 0.05093086766599445.

Selected Hyperparameters for Trial 5:
  l1: 128, l2: 64, lr: 0.0005, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3015183639526366
[Epoch 1, Batch 200] loss: 2.297140693664551
[Epoch 1, Batch 300] loss: 2.28799622297287
[Epoch 1, Batch 400] loss: 2.285164613723755
[Epoch 1, Batch 500] loss: 2.2730228304862976
[Epoch 1, Batch 600] loss: 2.2550422143936157
[Epoch 1, Batch 700] loss: 2.2242678570747376
[Epoch 1, Batch 800] loss: 2.1578330898284914
[Epoch 1, Batch 900] loss: 1.9796265351772309
[Epoch 1, Batch 1000] loss: 1.5148965215682983
[Epoch 1, Batch 1100] loss: 0.94450239777565
[Epoch 1, Batch 1200] loss: 0.6819343137741088
[Epoch 1, Batch 1300] loss: 0.5601093995571137
[Epoch 1, Batch 1400] loss: 0.5151465946435928
[Epoch 1, Batch 1500] loss: 0.4411705447733402
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.4167
Validation Accuracy: 0.8732
Overfitting: 0.4167
[Epoch 2, Batch 100] loss: 0.39538430362939836
[Epoch 2, Batch 200] loss: 0.3732789933681488
[Epoch 2, Batch 300] loss: 0.39201894015073774
[Epoch 2, Batch 400] loss: 0.3655386478453875
[Epoch 2, Batch 500] loss: 0.3318187237530947
[Epoch 2, Batch 600] loss: 0.3426424466073513
[Epoch 2, Batch 700] loss: 0.30702106673270463
[Epoch 2, Batch 800] loss: 0.2842782175540924
[Epoch 2, Batch 900] loss: 0.27019000343978405
[Epoch 2, Batch 1000] loss: 0.2515174032002687
[Epoch 2, Batch 1100] loss: 0.25860654659569265
[Epoch 2, Batch 1200] loss: 0.25753526579588654
[Epoch 2, Batch 1300] loss: 0.21768068060278892
[Epoch 2, Batch 1400] loss: 0.21637777142226697
[Epoch 2, Batch 1500] loss: 0.2195262585952878
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2187
Validation Accuracy: 0.9337
Overfitting: 0.2187
[Epoch 3, Batch 100] loss: 0.19917301643639804
[Epoch 3, Batch 200] loss: 0.19638527728617192
[Epoch 3, Batch 300] loss: 0.18868595452979206
[Epoch 3, Batch 400] loss: 0.18758418128825724
[Epoch 3, Batch 500] loss: 0.17370201878249644
[Epoch 3, Batch 600] loss: 0.15301930235698818
[Epoch 3, Batch 700] loss: 0.1656921399012208
[Epoch 3, Batch 800] loss: 0.16663160406053065
[Epoch 3, Batch 900] loss: 0.14440941391512752
[Epoch 3, Batch 1000] loss: 0.16024651687592267
[Epoch 3, Batch 1100] loss: 0.15009209098294377
[Epoch 3, Batch 1200] loss: 0.16027534153312445
[Epoch 3, Batch 1300] loss: 0.13309863566420974
[Epoch 3, Batch 1400] loss: 0.1412396601215005
[Epoch 3, Batch 1500] loss: 0.16390048151835798
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1201
Validation Accuracy: 0.9626
Overfitting: 0.1201
[Epoch 4, Batch 100] loss: 0.1401892441883683
[Epoch 4, Batch 200] loss: 0.12495885679498314
[Epoch 4, Batch 300] loss: 0.13082061678171159
[Epoch 4, Batch 400] loss: 0.11905696501024067
[Epoch 4, Batch 500] loss: 0.12820736025460064
[Epoch 4, Batch 600] loss: 0.10207656435668469
[Epoch 4, Batch 700] loss: 0.11858923998661339
[Epoch 4, Batch 800] loss: 0.1269300026539713
[Epoch 4, Batch 900] loss: 0.10505890871863813
[Epoch 4, Batch 1000] loss: 0.11473604059312492
[Epoch 4, Batch 1100] loss: 0.11445665761828422
[Epoch 4, Batch 1200] loss: 0.12308619365096092
[Epoch 4, Batch 1300] loss: 0.10506604691501707
[Epoch 4, Batch 1400] loss: 0.10541260336525739
[Epoch 4, Batch 1500] loss: 0.0931325238989666
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0931
Validation Accuracy: 0.9705
Overfitting: 0.0931
[Epoch 5, Batch 100] loss: 0.08956085447687656
[Epoch 5, Batch 200] loss: 0.10856018371880055
[Epoch 5, Batch 300] loss: 0.11394699997268617
[Epoch 5, Batch 400] loss: 0.10128955180291087
[Epoch 5, Batch 500] loss: 0.10140567225404083
[Epoch 5, Batch 600] loss: 0.08549899023957551
[Epoch 5, Batch 700] loss: 0.09694015914574265
[Epoch 5, Batch 800] loss: 0.09317511255852878
[Epoch 5, Batch 900] loss: 0.0856710734218359
[Epoch 5, Batch 1000] loss: 0.07202558383345604
[Epoch 5, Batch 1100] loss: 0.11142129776068031
[Epoch 5, Batch 1200] loss: 0.08237312020733953
[Epoch 5, Batch 1300] loss: 0.0795295059774071
[Epoch 5, Batch 1400] loss: 0.09243080744985491
[Epoch 5, Batch 1500] loss: 0.08227540406398476
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0792
Validation Accuracy: 0.9761
Overfitting: 0.0792
[Epoch 6, Batch 100] loss: 0.08741167596541345
[Epoch 6, Batch 200] loss: 0.09610512257553637
[Epoch 6, Batch 300] loss: 0.07772103382274509
[Epoch 6, Batch 400] loss: 0.0880204858398065
[Epoch 6, Batch 500] loss: 0.07860231214668602
[Epoch 6, Batch 600] loss: 0.06347824450116604
[Epoch 6, Batch 700] loss: 0.0778793467162177
[Epoch 6, Batch 800] loss: 0.08365073455031961
[Epoch 6, Batch 900] loss: 0.08311501322546974
[Epoch 6, Batch 1000] loss: 0.07125469652703031
[Epoch 6, Batch 1100] loss: 0.08821389112155885
[Epoch 6, Batch 1200] loss: 0.07296379760373384
[Epoch 6, Batch 1300] loss: 0.07822512491839007
[Epoch 6, Batch 1400] loss: 0.07964019834296777
[Epoch 6, Batch 1500] loss: 0.07258119258563965
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0746
Validation Accuracy: 0.9768
Overfitting: 0.0746
[Epoch 7, Batch 100] loss: 0.07537949301302432
[Epoch 7, Batch 200] loss: 0.05227010750444606
[Epoch 7, Batch 300] loss: 0.07701999568380416
[Epoch 7, Batch 400] loss: 0.07924271137220786
[Epoch 7, Batch 500] loss: 0.07465807143133134
[Epoch 7, Batch 600] loss: 0.057269980879500505
[Epoch 7, Batch 700] loss: 0.06701941778883339
[Epoch 7, Batch 800] loss: 0.06477184400195256
[Epoch 7, Batch 900] loss: 0.07908834791276603
[Epoch 7, Batch 1000] loss: 0.0680839758226648
[Epoch 7, Batch 1100] loss: 0.0672226931201294
[Epoch 7, Batch 1200] loss: 0.07697490685386583
[Epoch 7, Batch 1300] loss: 0.06252809081692248
[Epoch 7, Batch 1400] loss: 0.07278497147839516
[Epoch 7, Batch 1500] loss: 0.06892711696214975
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0669
Validation Accuracy: 0.9788
Overfitting: 0.0669
[Epoch 8, Batch 100] loss: 0.06016535040456802
[Epoch 8, Batch 200] loss: 0.06835680019459688
[Epoch 8, Batch 300] loss: 0.06578705984866247
[Epoch 8, Batch 400] loss: 0.05922877931036055
[Epoch 8, Batch 500] loss: 0.06520918782800436
[Epoch 8, Batch 600] loss: 0.051017974819988016
[Epoch 8, Batch 700] loss: 0.05800834609661251
[Epoch 8, Batch 800] loss: 0.057951170834712684
[Epoch 8, Batch 900] loss: 0.06301204277202486
[Epoch 8, Batch 1000] loss: 0.06522711881319992
[Epoch 8, Batch 1100] loss: 0.07758007784606889
[Epoch 8, Batch 1200] loss: 0.06568479173001833
[Epoch 8, Batch 1300] loss: 0.05886921416269615
[Epoch 8, Batch 1400] loss: 0.07235950986854732
[Epoch 8, Batch 1500] loss: 0.05593806483084336
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0595
Validation Accuracy: 0.9804
Overfitting: 0.0595
[Epoch 9, Batch 100] loss: 0.044553357413969936
[Epoch 9, Batch 200] loss: 0.04608815178507939
[Epoch 9, Batch 300] loss: 0.051522922314470636
[Epoch 9, Batch 400] loss: 0.07702369964215905
[Epoch 9, Batch 500] loss: 0.06324430854525417
[Epoch 9, Batch 600] loss: 0.06162152128526941
[Epoch 9, Batch 700] loss: 0.056321795438416304
[Epoch 9, Batch 800] loss: 0.06087140444898978
[Epoch 9, Batch 900] loss: 0.05666928856866434
[Epoch 9, Batch 1000] loss: 0.06592038735048845
[Epoch 9, Batch 1100] loss: 0.049747126614674925
[Epoch 9, Batch 1200] loss: 0.059660520057659594
[Epoch 9, Batch 1300] loss: 0.0742668825131841
[Epoch 9, Batch 1400] loss: 0.05043179154512473
[Epoch 9, Batch 1500] loss: 0.04488770545925945
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0567
Validation Accuracy: 0.9821
Overfitting: 0.0567
Best model saved at epoch 9 with validation loss: 0.0567
[Epoch 10, Batch 100] loss: 0.04823213273077272
[Epoch 10, Batch 200] loss: 0.04342712561832741
[Epoch 10, Batch 300] loss: 0.0581576194264926
[Epoch 10, Batch 400] loss: 0.0519475323241204
[Epoch 10, Batch 500] loss: 0.056337292636744675
[Epoch 10, Batch 600] loss: 0.05978406644659117
[Epoch 10, Batch 700] loss: 0.051648712705355135
[Epoch 10, Batch 800] loss: 0.0476774037652649
[Epoch 10, Batch 900] loss: 0.05185227844747715
[Epoch 10, Batch 1000] loss: 0.04937005578307435
[Epoch 10, Batch 1100] loss: 0.06291498874779791
[Epoch 10, Batch 1200] loss: 0.05148266421980224
[Epoch 10, Batch 1300] loss: 0.050061523984186354
[Epoch 10, Batch 1400] loss: 0.05749549486790784
[Epoch 10, Batch 1500] loss: 0.04361675722757354
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9824
Overfitting: 0.0554
[Epoch 11, Batch 100] loss: 0.04361909420927987
[Epoch 11, Batch 200] loss: 0.05040497527108528
[Epoch 11, Batch 300] loss: 0.045011434417683634
[Epoch 11, Batch 400] loss: 0.04360294459504075
[Epoch 11, Batch 500] loss: 0.043879315233789386
[Epoch 11, Batch 600] loss: 0.05718189796665683
[Epoch 11, Batch 700] loss: 0.04000235642044572
[Epoch 11, Batch 800] loss: 0.06805713853391353
[Epoch 11, Batch 900] loss: 0.03878791073919274
[Epoch 11, Batch 1000] loss: 0.055006857027765366
[Epoch 11, Batch 1100] loss: 0.046754413495073095
[Epoch 11, Batch 1200] loss: 0.058818400747841226
[Epoch 11, Batch 1300] loss: 0.04224957788479514
[Epoch 11, Batch 1400] loss: 0.036991623048088514
[Epoch 11, Batch 1500] loss: 0.052111286644358185
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9814
Overfitting: 0.0603
Early stopping epoch 11 for trial 5. Moving to next fold.
Fold 1 validation loss: 0.0603
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.3045241975784303
[Epoch 1, Batch 200] loss: 2.293420658111572
[Epoch 1, Batch 300] loss: 2.285293040275574
[Epoch 1, Batch 400] loss: 2.272457706928253
[Epoch 1, Batch 500] loss: 2.2511795210838317
[Epoch 1, Batch 600] loss: 2.2116147327423095
[Epoch 1, Batch 700] loss: 2.102685546875
[Epoch 1, Batch 800] loss: 1.7694935524463653
[Epoch 1, Batch 900] loss: 1.1032171607017518
[Epoch 1, Batch 1000] loss: 0.7222425630688667
[Epoch 1, Batch 1100] loss: 0.5893888819217682
[Epoch 1, Batch 1200] loss: 0.5079826284945012
[Epoch 1, Batch 1300] loss: 0.43364697992801665
[Epoch 1, Batch 1400] loss: 0.46066073685884473
[Epoch 1, Batch 1500] loss: 0.38359577640891074
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3870
Validation Accuracy: 0.8856
Overfitting: 0.3870
[Epoch 2, Batch 100] loss: 0.3986144754290581
[Epoch 2, Batch 200] loss: 0.35138512291014196
[Epoch 2, Batch 300] loss: 0.32436550192534924
[Epoch 2, Batch 400] loss: 0.30255630061030386
[Epoch 2, Batch 500] loss: 0.31965451411902907
[Epoch 2, Batch 600] loss: 0.2836714144796133
[Epoch 2, Batch 700] loss: 0.26731132827699183
[Epoch 2, Batch 800] loss: 0.2593891404569149
[Epoch 2, Batch 900] loss: 0.26139701902866364
[Epoch 2, Batch 1000] loss: 0.24879185296595097
[Epoch 2, Batch 1100] loss: 0.25913590032607314
[Epoch 2, Batch 1200] loss: 0.2290392557159066
[Epoch 2, Batch 1300] loss: 0.2555982144549489
[Epoch 2, Batch 1400] loss: 0.2448565308749676
[Epoch 2, Batch 1500] loss: 0.22416627379134296
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2261
Validation Accuracy: 0.9311
Overfitting: 0.2261
[Epoch 3, Batch 100] loss: 0.19619996204972268
[Epoch 3, Batch 200] loss: 0.21139976788312198
[Epoch 3, Batch 300] loss: 0.20006269585341216
[Epoch 3, Batch 400] loss: 0.173751321118325
[Epoch 3, Batch 500] loss: 0.18214335085824132
[Epoch 3, Batch 600] loss: 0.19527974719181657
[Epoch 3, Batch 700] loss: 0.1834709057956934
[Epoch 3, Batch 800] loss: 0.18950999781489372
[Epoch 3, Batch 900] loss: 0.173489260841161
[Epoch 3, Batch 1000] loss: 0.1522970503009856
[Epoch 3, Batch 1100] loss: 0.15518356786109508
[Epoch 3, Batch 1200] loss: 0.16014402877539397
[Epoch 3, Batch 1300] loss: 0.1505744937993586
[Epoch 3, Batch 1400] loss: 0.14789903001859783
[Epoch 3, Batch 1500] loss: 0.17448233429342508
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1540
Validation Accuracy: 0.9525
Overfitting: 0.1540
[Epoch 4, Batch 100] loss: 0.14340802554041146
[Epoch 4, Batch 200] loss: 0.16252781667746605
[Epoch 4, Batch 300] loss: 0.1330664415284991
[Epoch 4, Batch 400] loss: 0.11890083506703376
[Epoch 4, Batch 500] loss: 0.1438620504550636
[Epoch 4, Batch 600] loss: 0.1691773830819875
[Epoch 4, Batch 700] loss: 0.12902937348932028
[Epoch 4, Batch 800] loss: 0.11617522817105055
[Epoch 4, Batch 900] loss: 0.1361047247517854
[Epoch 4, Batch 1000] loss: 0.12267155434004963
[Epoch 4, Batch 1100] loss: 0.12309440568089486
[Epoch 4, Batch 1200] loss: 0.12793805683031678
[Epoch 4, Batch 1300] loss: 0.11190191608853638
[Epoch 4, Batch 1400] loss: 0.13587618116289377
[Epoch 4, Batch 1500] loss: 0.11965227354317903
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1312
Validation Accuracy: 0.9597
Overfitting: 0.1312
[Epoch 5, Batch 100] loss: 0.11349774218164384
[Epoch 5, Batch 200] loss: 0.11733848384581506
[Epoch 5, Batch 300] loss: 0.09845069866627455
[Epoch 5, Batch 400] loss: 0.11937920729629696
[Epoch 5, Batch 500] loss: 0.12534526023082435
[Epoch 5, Batch 600] loss: 0.10097635078709573
[Epoch 5, Batch 700] loss: 0.11541383787989616
[Epoch 5, Batch 800] loss: 0.11155179608147592
[Epoch 5, Batch 900] loss: 0.101996406391263
[Epoch 5, Batch 1000] loss: 0.11083097977098078
[Epoch 5, Batch 1100] loss: 0.10170207333751023
[Epoch 5, Batch 1200] loss: 0.09850421910174191
[Epoch 5, Batch 1300] loss: 0.08396593213547021
[Epoch 5, Batch 1400] loss: 0.10866849916055799
[Epoch 5, Batch 1500] loss: 0.11661585546331481
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1134
Validation Accuracy: 0.9657
Overfitting: 0.1134
[Epoch 6, Batch 100] loss: 0.08976832297630608
[Epoch 6, Batch 200] loss: 0.10256008835043758
[Epoch 6, Batch 300] loss: 0.0958711928036064
[Epoch 6, Batch 400] loss: 0.09228515747003257
[Epoch 6, Batch 500] loss: 0.09323497779667378
[Epoch 6, Batch 600] loss: 0.0841461132117547
[Epoch 6, Batch 700] loss: 0.09910883121658116
[Epoch 6, Batch 800] loss: 0.08540066335815936
[Epoch 6, Batch 900] loss: 0.09225583282299339
[Epoch 6, Batch 1000] loss: 0.09643582401797175
[Epoch 6, Batch 1100] loss: 0.10013468529097735
[Epoch 6, Batch 1200] loss: 0.08480546575039626
[Epoch 6, Batch 1300] loss: 0.09646948853973299
[Epoch 6, Batch 1400] loss: 0.09173206018283964
[Epoch 6, Batch 1500] loss: 0.079716791738756
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0980
Validation Accuracy: 0.9708
Overfitting: 0.0980
[Epoch 7, Batch 100] loss: 0.07353973285062239
[Epoch 7, Batch 200] loss: 0.08224604761227966
[Epoch 7, Batch 300] loss: 0.09610958298202604
[Epoch 7, Batch 400] loss: 0.0860507279727608
[Epoch 7, Batch 500] loss: 0.07998011903604492
[Epoch 7, Batch 600] loss: 0.08296229932457208
[Epoch 7, Batch 700] loss: 0.07970126817235723
[Epoch 7, Batch 800] loss: 0.07344099478796125
[Epoch 7, Batch 900] loss: 0.07435871737776324
[Epoch 7, Batch 1000] loss: 0.07955698393750936
[Epoch 7, Batch 1100] loss: 0.0868184923985973
[Epoch 7, Batch 1200] loss: 0.07400459307944401
[Epoch 7, Batch 1300] loss: 0.07886255655204877
[Epoch 7, Batch 1400] loss: 0.0808347250893712
[Epoch 7, Batch 1500] loss: 0.0832313191704452
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0982
Validation Accuracy: 0.9698
Overfitting: 0.0982
[Epoch 8, Batch 100] loss: 0.07704892365494743
[Epoch 8, Batch 200] loss: 0.07324766873614863
[Epoch 8, Batch 300] loss: 0.07500987239181996
[Epoch 8, Batch 400] loss: 0.0673672200657893
[Epoch 8, Batch 500] loss: 0.08294778797659091
[Epoch 8, Batch 600] loss: 0.06629037003498524
[Epoch 8, Batch 700] loss: 0.06547105464036576
[Epoch 8, Batch 800] loss: 0.06267066189553588
[Epoch 8, Batch 900] loss: 0.06798277105670422
[Epoch 8, Batch 1000] loss: 0.0752519335760735
[Epoch 8, Batch 1100] loss: 0.07268033172935247
[Epoch 8, Batch 1200] loss: 0.06611875631380826
[Epoch 8, Batch 1300] loss: 0.07181882290868088
[Epoch 8, Batch 1400] loss: 0.08705280947498978
[Epoch 8, Batch 1500] loss: 0.05919407893437892
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0843
Validation Accuracy: 0.9737
Overfitting: 0.0843
[Epoch 9, Batch 100] loss: 0.05993661740794778
[Epoch 9, Batch 200] loss: 0.059791818542871626
[Epoch 9, Batch 300] loss: 0.060216450812295076
[Epoch 9, Batch 400] loss: 0.06796388403861783
[Epoch 9, Batch 500] loss: 0.0740902124682907
[Epoch 9, Batch 600] loss: 0.06829659536015242
[Epoch 9, Batch 700] loss: 0.05519548429874703
[Epoch 9, Batch 800] loss: 0.062335134188178924
[Epoch 9, Batch 900] loss: 0.06801245126640425
[Epoch 9, Batch 1000] loss: 0.06116148867644369
[Epoch 9, Batch 1100] loss: 0.06865854388102889
[Epoch 9, Batch 1200] loss: 0.06473222342086955
[Epoch 9, Batch 1300] loss: 0.06875997838098556
[Epoch 9, Batch 1400] loss: 0.06209293223451823
[Epoch 9, Batch 1500] loss: 0.0665898265875876
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0786
Validation Accuracy: 0.9767
Overfitting: 0.0786
Best model saved at epoch 9 with validation loss: 0.0786
[Epoch 10, Batch 100] loss: 0.06456387638347223
[Epoch 10, Batch 200] loss: 0.053363297043833885
[Epoch 10, Batch 300] loss: 0.07775316506857052
[Epoch 10, Batch 400] loss: 0.056372692680452016
[Epoch 10, Batch 500] loss: 0.06821285309502854
[Epoch 10, Batch 600] loss: 0.060546217940282074
[Epoch 10, Batch 700] loss: 0.05983589037437923
[Epoch 10, Batch 800] loss: 0.05281399619881995
[Epoch 10, Batch 900] loss: 0.0533817654568702
[Epoch 10, Batch 1000] loss: 0.04606032838462852
[Epoch 10, Batch 1100] loss: 0.06664395014871843
[Epoch 10, Batch 1200] loss: 0.04722326084971428
[Epoch 10, Batch 1300] loss: 0.06193575563956984
[Epoch 10, Batch 1400] loss: 0.057178166867233815
[Epoch 10, Batch 1500] loss: 0.05913982106605545
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0800
Validation Accuracy: 0.9750
Overfitting: 0.0800
[Epoch 11, Batch 100] loss: 0.041973847478511746
[Epoch 11, Batch 200] loss: 0.06029760378296487
[Epoch 11, Batch 300] loss: 0.06538524605799466
[Epoch 11, Batch 400] loss: 0.055192783190868795
[Epoch 11, Batch 500] loss: 0.05385835187276825
[Epoch 11, Batch 600] loss: 0.057648381805047395
[Epoch 11, Batch 700] loss: 0.05824004509486258
[Epoch 11, Batch 800] loss: 0.06210993895772845
[Epoch 11, Batch 900] loss: 0.05698128584539518
[Epoch 11, Batch 1000] loss: 0.04882970449631102
[Epoch 11, Batch 1100] loss: 0.055323884275276215
[Epoch 11, Batch 1200] loss: 0.04990959317889065
[Epoch 11, Batch 1300] loss: 0.058311866216827185
[Epoch 11, Batch 1400] loss: 0.04362529199803248
[Epoch 11, Batch 1500] loss: 0.05893305461853743
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0723
Validation Accuracy: 0.9763
Overfitting: 0.0723
Early stopping epoch 11 for trial 5. Moving to next fold.
Fold 2 validation loss: 0.0723
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3024551820755006
[Epoch 1, Batch 200] loss: 2.2918562579154966
[Epoch 1, Batch 300] loss: 2.2774685263633727
[Epoch 1, Batch 400] loss: 2.2613694930076598
[Epoch 1, Batch 500] loss: 2.2301671528816223
[Epoch 1, Batch 600] loss: 2.1710538721084593
[Epoch 1, Batch 700] loss: 2.0085834395885467
[Epoch 1, Batch 800] loss: 1.5920825684070588
[Epoch 1, Batch 900] loss: 1.0205756944417954
[Epoch 1, Batch 1000] loss: 0.7148799622058868
[Epoch 1, Batch 1100] loss: 0.5690559235215187
[Epoch 1, Batch 1200] loss: 0.48193822607398035
[Epoch 1, Batch 1300] loss: 0.4186940956115723
[Epoch 1, Batch 1400] loss: 0.40615585543215277
[Epoch 1, Batch 1500] loss: 0.3913217906653881
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3384
Validation Accuracy: 0.8999
Overfitting: 0.3384
[Epoch 2, Batch 100] loss: 0.3294990272819996
[Epoch 2, Batch 200] loss: 0.3326694116741419
[Epoch 2, Batch 300] loss: 0.32479371689260006
[Epoch 2, Batch 400] loss: 0.2787087233364582
[Epoch 2, Batch 500] loss: 0.2614072821289301
[Epoch 2, Batch 600] loss: 0.25445728328078987
[Epoch 2, Batch 700] loss: 0.25039107900112867
[Epoch 2, Batch 800] loss: 0.24230488732457162
[Epoch 2, Batch 900] loss: 0.2387109938263893
[Epoch 2, Batch 1000] loss: 0.22634809851646423
[Epoch 2, Batch 1100] loss: 0.2245500024035573
[Epoch 2, Batch 1200] loss: 0.18702115096151828
[Epoch 2, Batch 1300] loss: 0.19808169674128295
[Epoch 2, Batch 1400] loss: 0.19414819598197938
[Epoch 2, Batch 1500] loss: 0.17123093467205763
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1821
Validation Accuracy: 0.9459
Overfitting: 0.1821
[Epoch 3, Batch 100] loss: 0.16788884088397027
[Epoch 3, Batch 200] loss: 0.1598326637223363
[Epoch 3, Batch 300] loss: 0.166610947586596
[Epoch 3, Batch 400] loss: 0.1567327134311199
[Epoch 3, Batch 500] loss: 0.19159472279250622
[Epoch 3, Batch 600] loss: 0.1552697353065014
[Epoch 3, Batch 700] loss: 0.15069303559139371
[Epoch 3, Batch 800] loss: 0.16801954247057438
[Epoch 3, Batch 900] loss: 0.13473881201818586
[Epoch 3, Batch 1000] loss: 0.13410281823016704
[Epoch 3, Batch 1100] loss: 0.1298138616979122
[Epoch 3, Batch 1200] loss: 0.14537764633074401
[Epoch 3, Batch 1300] loss: 0.14635090391151606
[Epoch 3, Batch 1400] loss: 0.11101123828440905
[Epoch 3, Batch 1500] loss: 0.11829571371898055
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1295
Validation Accuracy: 0.9603
Overfitting: 0.1295
[Epoch 4, Batch 100] loss: 0.1109516080468893
[Epoch 4, Batch 200] loss: 0.13784417633898557
[Epoch 4, Batch 300] loss: 0.11471723756752908
[Epoch 4, Batch 400] loss: 0.11228734211996198
[Epoch 4, Batch 500] loss: 0.12073359898291529
[Epoch 4, Batch 600] loss: 0.13319389301352202
[Epoch 4, Batch 700] loss: 0.1015035799657926
[Epoch 4, Batch 800] loss: 0.10238273164257407
[Epoch 4, Batch 900] loss: 0.1090866800956428
[Epoch 4, Batch 1000] loss: 0.1164028718136251
[Epoch 4, Batch 1100] loss: 0.10116074533201753
[Epoch 4, Batch 1200] loss: 0.11730095859151334
[Epoch 4, Batch 1300] loss: 0.10047000042162836
[Epoch 4, Batch 1400] loss: 0.08505325882229954
[Epoch 4, Batch 1500] loss: 0.11105957026593387
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1294
Validation Accuracy: 0.9591
Overfitting: 0.1294
[Epoch 5, Batch 100] loss: 0.10240538124460727
[Epoch 5, Batch 200] loss: 0.09363923625089228
[Epoch 5, Batch 300] loss: 0.08681452387478203
[Epoch 5, Batch 400] loss: 0.09519590409938246
[Epoch 5, Batch 500] loss: 0.09950215584598482
[Epoch 5, Batch 600] loss: 0.10251646462827921
[Epoch 5, Batch 700] loss: 0.09584632669575513
[Epoch 5, Batch 800] loss: 0.0924885881319642
[Epoch 5, Batch 900] loss: 0.08085754594765604
[Epoch 5, Batch 1000] loss: 0.106743437750265
[Epoch 5, Batch 1100] loss: 0.07966366989538073
[Epoch 5, Batch 1200] loss: 0.09689502615015953
[Epoch 5, Batch 1300] loss: 0.08616708020213991
[Epoch 5, Batch 1400] loss: 0.10128579127602279
[Epoch 5, Batch 1500] loss: 0.09091204409720376
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1023
Validation Accuracy: 0.9694
Overfitting: 0.1023
[Epoch 6, Batch 100] loss: 0.0809316947683692
[Epoch 6, Batch 200] loss: 0.0850656706164591
[Epoch 6, Batch 300] loss: 0.07634905281011015
[Epoch 6, Batch 400] loss: 0.09420900270342827
[Epoch 6, Batch 500] loss: 0.07640213603386656
[Epoch 6, Batch 600] loss: 0.08860437232535333
[Epoch 6, Batch 700] loss: 0.08230421570129692
[Epoch 6, Batch 800] loss: 0.0711400678800419
[Epoch 6, Batch 900] loss: 0.07484370612539351
[Epoch 6, Batch 1000] loss: 0.08220275207655504
[Epoch 6, Batch 1100] loss: 0.07851837186142802
[Epoch 6, Batch 1200] loss: 0.08441864722874015
[Epoch 6, Batch 1300] loss: 0.10032731957035139
[Epoch 6, Batch 1400] loss: 0.09714690518099815
[Epoch 6, Batch 1500] loss: 0.06866347622592002
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0870
Validation Accuracy: 0.9742
Overfitting: 0.0870
[Epoch 7, Batch 100] loss: 0.07827022045501508
[Epoch 7, Batch 200] loss: 0.06622269930783659
[Epoch 7, Batch 300] loss: 0.07511587517452427
[Epoch 7, Batch 400] loss: 0.06868210601620377
[Epoch 7, Batch 500] loss: 0.07665008052252233
[Epoch 7, Batch 600] loss: 0.08172882017912343
[Epoch 7, Batch 700] loss: 0.0710450496635167
[Epoch 7, Batch 800] loss: 0.07511070772074163
[Epoch 7, Batch 900] loss: 0.06608239752240479
[Epoch 7, Batch 1000] loss: 0.0690400070976466
[Epoch 7, Batch 1100] loss: 0.06655704643577337
[Epoch 7, Batch 1200] loss: 0.0639017896540463
[Epoch 7, Batch 1300] loss: 0.07548114311415702
[Epoch 7, Batch 1400] loss: 0.06245732907322235
[Epoch 7, Batch 1500] loss: 0.08576701987767592
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0811
Validation Accuracy: 0.9751
Overfitting: 0.0811
[Epoch 8, Batch 100] loss: 0.07629828558303416
[Epoch 8, Batch 200] loss: 0.06756720254663379
[Epoch 8, Batch 300] loss: 0.06719296063762158
[Epoch 8, Batch 400] loss: 0.05860170887317508
[Epoch 8, Batch 500] loss: 0.07644833442522213
[Epoch 8, Batch 600] loss: 0.05984488753601909
[Epoch 8, Batch 700] loss: 0.06725164094939828
[Epoch 8, Batch 800] loss: 0.06736406722571701
[Epoch 8, Batch 900] loss: 0.06886658967938274
[Epoch 8, Batch 1000] loss: 0.07518747862428427
[Epoch 8, Batch 1100] loss: 0.06027481561526656
[Epoch 8, Batch 1200] loss: 0.06645346422912553
[Epoch 8, Batch 1300] loss: 0.06253951942548155
[Epoch 8, Batch 1400] loss: 0.06690258445451036
[Epoch 8, Batch 1500] loss: 0.06026046753395349
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0779
Validation Accuracy: 0.9762
Overfitting: 0.0779
[Epoch 9, Batch 100] loss: 0.06101338113076053
[Epoch 9, Batch 200] loss: 0.06479894620948472
[Epoch 9, Batch 300] loss: 0.05304202278610319
[Epoch 9, Batch 400] loss: 0.05671739766490646
[Epoch 9, Batch 500] loss: 0.06540927939815447
[Epoch 9, Batch 600] loss: 0.05664182269829325
[Epoch 9, Batch 700] loss: 0.0682779429270886
[Epoch 9, Batch 800] loss: 0.06942046968499199
[Epoch 9, Batch 900] loss: 0.06468735723756254
[Epoch 9, Batch 1000] loss: 0.05603248968720436
[Epoch 9, Batch 1100] loss: 0.06176289239199832
[Epoch 9, Batch 1200] loss: 0.04716327522881329
[Epoch 9, Batch 1300] loss: 0.04984238439006731
[Epoch 9, Batch 1400] loss: 0.06594164443318733
[Epoch 9, Batch 1500] loss: 0.0652211275161244
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0676
Validation Accuracy: 0.9798
Overfitting: 0.0676
Best model saved at epoch 9 with validation loss: 0.0676
[Epoch 10, Batch 100] loss: 0.054982327955076474
[Epoch 10, Batch 200] loss: 0.05645873761968687
[Epoch 10, Batch 300] loss: 0.05692758261691779
[Epoch 10, Batch 400] loss: 0.05590549180633388
[Epoch 10, Batch 500] loss: 0.06500251077814027
[Epoch 10, Batch 600] loss: 0.06168993532424793
[Epoch 10, Batch 700] loss: 0.04970063319196925
[Epoch 10, Batch 800] loss: 0.05797757391352207
[Epoch 10, Batch 900] loss: 0.05816566309193149
[Epoch 10, Batch 1000] loss: 0.05176922088372521
[Epoch 10, Batch 1100] loss: 0.052783146912697705
[Epoch 10, Batch 1200] loss: 0.05956041082506999
[Epoch 10, Batch 1300] loss: 0.052215266703860834
[Epoch 10, Batch 1400] loss: 0.0555358976777643
[Epoch 10, Batch 1500] loss: 0.04486344855977222
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0653
Validation Accuracy: 0.9802
Overfitting: 0.0653
[Epoch 11, Batch 100] loss: 0.0472352709074039
[Epoch 11, Batch 200] loss: 0.04356035613338463
[Epoch 11, Batch 300] loss: 0.046562818789388984
[Epoch 11, Batch 400] loss: 0.05876977711450308
[Epoch 11, Batch 500] loss: 0.043313663806766274
[Epoch 11, Batch 600] loss: 0.048177815767121504
[Epoch 11, Batch 700] loss: 0.054004858054686335
[Epoch 11, Batch 800] loss: 0.05436696241493337
[Epoch 11, Batch 900] loss: 0.05629153077723458
[Epoch 11, Batch 1000] loss: 0.04954638086259365
[Epoch 11, Batch 1100] loss: 0.057560350191779436
[Epoch 11, Batch 1200] loss: 0.054417691605631265
[Epoch 11, Batch 1300] loss: 0.05995457529556006
[Epoch 11, Batch 1400] loss: 0.04522027001017705
[Epoch 11, Batch 1500] loss: 0.05105427762959153
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0669
Validation Accuracy: 0.9798
Overfitting: 0.0669
Early stopping epoch 11 for trial 5. Moving to next fold.
Fold 3 validation loss: 0.0669
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2950449848175047
[Epoch 1, Batch 200] loss: 2.281780431270599
[Epoch 1, Batch 300] loss: 2.2553125762939454
[Epoch 1, Batch 400] loss: 2.207161567211151
[Epoch 1, Batch 500] loss: 2.083271688222885
[Epoch 1, Batch 600] loss: 1.7058984875679015
[Epoch 1, Batch 700] loss: 1.0981547188758851
[Epoch 1, Batch 800] loss: 0.7354147928953171
[Epoch 1, Batch 900] loss: 0.5818656796216964
[Epoch 1, Batch 1000] loss: 0.5202274599671364
[Epoch 1, Batch 1100] loss: 0.4801027578115463
[Epoch 1, Batch 1200] loss: 0.43115406453609467
[Epoch 1, Batch 1300] loss: 0.4197560776770115
[Epoch 1, Batch 1400] loss: 0.3838147632777691
[Epoch 1, Batch 1500] loss: 0.3646187960356474
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3453
Validation Accuracy: 0.8962
Overfitting: 0.3453
[Epoch 2, Batch 100] loss: 0.3544527817517519
[Epoch 2, Batch 200] loss: 0.32033428467810154
[Epoch 2, Batch 300] loss: 0.3073529979586601
[Epoch 2, Batch 400] loss: 0.31151045329868793
[Epoch 2, Batch 500] loss: 0.28510950449854133
[Epoch 2, Batch 600] loss: 0.25671724751591685
[Epoch 2, Batch 700] loss: 0.2536984867602587
[Epoch 2, Batch 800] loss: 0.24349032305181026
[Epoch 2, Batch 900] loss: 0.2577265451475978
[Epoch 2, Batch 1000] loss: 0.25002529509365556
[Epoch 2, Batch 1100] loss: 0.261771150752902
[Epoch 2, Batch 1200] loss: 0.21251781165599823
[Epoch 2, Batch 1300] loss: 0.22325830658897758
[Epoch 2, Batch 1400] loss: 0.2176807003095746
[Epoch 2, Batch 1500] loss: 0.214209612198174
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1917
Validation Accuracy: 0.9407
Overfitting: 0.1917
[Epoch 3, Batch 100] loss: 0.19215540494769812
[Epoch 3, Batch 200] loss: 0.180766737498343
[Epoch 3, Batch 300] loss: 0.2124113230034709
[Epoch 3, Batch 400] loss: 0.18358874086290597
[Epoch 3, Batch 500] loss: 0.16571662588045
[Epoch 3, Batch 600] loss: 0.1851681089401245
[Epoch 3, Batch 700] loss: 0.16536979226395487
[Epoch 3, Batch 800] loss: 0.17410201411694287
[Epoch 3, Batch 900] loss: 0.16355790582485497
[Epoch 3, Batch 1000] loss: 0.1702376476675272
[Epoch 3, Batch 1100] loss: 0.15598051551729442
[Epoch 3, Batch 1200] loss: 0.1538743709307164
[Epoch 3, Batch 1300] loss: 0.14746114995330573
[Epoch 3, Batch 1400] loss: 0.13771457088179886
[Epoch 3, Batch 1500] loss: 0.13313135562464595
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1396
Validation Accuracy: 0.9569
Overfitting: 0.1396
[Epoch 4, Batch 100] loss: 0.13587423726916315
[Epoch 4, Batch 200] loss: 0.12103233800269664
[Epoch 4, Batch 300] loss: 0.13046451477333904
[Epoch 4, Batch 400] loss: 0.1336602327413857
[Epoch 4, Batch 500] loss: 0.12861237425357103
[Epoch 4, Batch 600] loss: 0.1459233315102756
[Epoch 4, Batch 700] loss: 0.1250410484522581
[Epoch 4, Batch 800] loss: 0.11666808588430286
[Epoch 4, Batch 900] loss: 0.13712427125312387
[Epoch 4, Batch 1000] loss: 0.12057681523263454
[Epoch 4, Batch 1100] loss: 0.13233717505820095
[Epoch 4, Batch 1200] loss: 0.11534218487329781
[Epoch 4, Batch 1300] loss: 0.09241740301251411
[Epoch 4, Batch 1400] loss: 0.1273253767658025
[Epoch 4, Batch 1500] loss: 0.12292395289056003
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1176
Validation Accuracy: 0.9639
Overfitting: 0.1176
[Epoch 5, Batch 100] loss: 0.11640747906640173
[Epoch 5, Batch 200] loss: 0.11424735276028514
[Epoch 5, Batch 300] loss: 0.10536235728301108
[Epoch 5, Batch 400] loss: 0.1109033174905926
[Epoch 5, Batch 500] loss: 0.0962624684162438
[Epoch 5, Batch 600] loss: 0.09763033190742135
[Epoch 5, Batch 700] loss: 0.08793176248436793
[Epoch 5, Batch 800] loss: 0.0981532784877345
[Epoch 5, Batch 900] loss: 0.10005056104622781
[Epoch 5, Batch 1000] loss: 0.10555868015158922
[Epoch 5, Batch 1100] loss: 0.09696997417602687
[Epoch 5, Batch 1200] loss: 0.09989032686688006
[Epoch 5, Batch 1300] loss: 0.10495860295370221
[Epoch 5, Batch 1400] loss: 0.08551586715504528
[Epoch 5, Batch 1500] loss: 0.11477326398482546
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0947
Validation Accuracy: 0.9696
Overfitting: 0.0947
[Epoch 6, Batch 100] loss: 0.0908512262115255
[Epoch 6, Batch 200] loss: 0.09715936167165637
[Epoch 6, Batch 300] loss: 0.08165988235268742
[Epoch 6, Batch 400] loss: 0.09041010695509613
[Epoch 6, Batch 500] loss: 0.0902201212849468
[Epoch 6, Batch 600] loss: 0.07622412749100477
[Epoch 6, Batch 700] loss: 0.07401097391266376
[Epoch 6, Batch 800] loss: 0.09213524709455669
[Epoch 6, Batch 900] loss: 0.08834189156070352
[Epoch 6, Batch 1000] loss: 0.09777568913530559
[Epoch 6, Batch 1100] loss: 0.09033323375973851
[Epoch 6, Batch 1200] loss: 0.08110413667978719
[Epoch 6, Batch 1300] loss: 0.08354566196678206
[Epoch 6, Batch 1400] loss: 0.08037623696494847
[Epoch 6, Batch 1500] loss: 0.07945013936143369
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0774
Validation Accuracy: 0.9762
Overfitting: 0.0774
[Epoch 7, Batch 100] loss: 0.07471494141733274
[Epoch 7, Batch 200] loss: 0.07807039509527386
[Epoch 7, Batch 300] loss: 0.08035836937837303
[Epoch 7, Batch 400] loss: 0.08329017819603905
[Epoch 7, Batch 500] loss: 0.06878196274861693
[Epoch 7, Batch 600] loss: 0.06644829841796308
[Epoch 7, Batch 700] loss: 0.08091774479253218
[Epoch 7, Batch 800] loss: 0.06974121609702706
[Epoch 7, Batch 900] loss: 0.06940469217021018
[Epoch 7, Batch 1000] loss: 0.06341317408951
[Epoch 7, Batch 1100] loss: 0.07730253456160426
[Epoch 7, Batch 1200] loss: 0.07579501923173666
[Epoch 7, Batch 1300] loss: 0.0804842450027354
[Epoch 7, Batch 1400] loss: 0.07027407309506088
[Epoch 7, Batch 1500] loss: 0.08819186971755698
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0759
Validation Accuracy: 0.9772
Overfitting: 0.0759
[Epoch 8, Batch 100] loss: 0.07542753725778312
[Epoch 8, Batch 200] loss: 0.07464937989832833
[Epoch 8, Batch 300] loss: 0.07148892471799627
[Epoch 8, Batch 400] loss: 0.06918473190395162
[Epoch 8, Batch 500] loss: 0.05579703281167894
[Epoch 8, Batch 600] loss: 0.07986952380277217
[Epoch 8, Batch 700] loss: 0.06902909544296562
[Epoch 8, Batch 800] loss: 0.07702377685811371
[Epoch 8, Batch 900] loss: 0.06164118071086705
[Epoch 8, Batch 1000] loss: 0.06636184205999598
[Epoch 8, Batch 1100] loss: 0.06992281527025625
[Epoch 8, Batch 1200] loss: 0.07140280133346096
[Epoch 8, Batch 1300] loss: 0.06292088354472071
[Epoch 8, Batch 1400] loss: 0.057892970812972636
[Epoch 8, Batch 1500] loss: 0.05275719059631229
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0744
Validation Accuracy: 0.9762
Overfitting: 0.0744
[Epoch 9, Batch 100] loss: 0.05308860580436885
[Epoch 9, Batch 200] loss: 0.06583955987123773
[Epoch 9, Batch 300] loss: 0.05638695063535124
[Epoch 9, Batch 400] loss: 0.05802595671149902
[Epoch 9, Batch 500] loss: 0.07843330352101475
[Epoch 9, Batch 600] loss: 0.06045682186726481
[Epoch 9, Batch 700] loss: 0.07225725904572755
[Epoch 9, Batch 800] loss: 0.05985886006150395
[Epoch 9, Batch 900] loss: 0.05112327944021672
[Epoch 9, Batch 1000] loss: 0.0664380276016891
[Epoch 9, Batch 1100] loss: 0.06098088094033301
[Epoch 9, Batch 1200] loss: 0.05644816411077045
[Epoch 9, Batch 1300] loss: 0.06097368465270847
[Epoch 9, Batch 1400] loss: 0.06139384096488357
[Epoch 9, Batch 1500] loss: 0.06223097871756181
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0666
Validation Accuracy: 0.9805
Overfitting: 0.0666
Best model saved at epoch 9 with validation loss: 0.0666
[Epoch 10, Batch 100] loss: 0.05480453592725098
[Epoch 10, Batch 200] loss: 0.044092066835146396
[Epoch 10, Batch 300] loss: 0.054444645296316596
[Epoch 10, Batch 400] loss: 0.05161495339940302
[Epoch 10, Batch 500] loss: 0.04222338400199078
[Epoch 10, Batch 600] loss: 0.061979628519620744
[Epoch 10, Batch 700] loss: 0.046458738471847026
[Epoch 10, Batch 800] loss: 0.07576359634986148
[Epoch 10, Batch 900] loss: 0.06265109700150788
[Epoch 10, Batch 1000] loss: 0.06877328324946574
[Epoch 10, Batch 1100] loss: 0.046169016904896124
[Epoch 10, Batch 1200] loss: 0.057151051070541144
[Epoch 10, Batch 1300] loss: 0.060663567046867685
[Epoch 10, Batch 1400] loss: 0.06587955857627094
[Epoch 10, Batch 1500] loss: 0.06012834830558859
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0679
Validation Accuracy: 0.9777
Overfitting: 0.0679
[Epoch 11, Batch 100] loss: 0.04768230068089906
[Epoch 11, Batch 200] loss: 0.05231153169646859
[Epoch 11, Batch 300] loss: 0.05389835019246675
[Epoch 11, Batch 400] loss: 0.054031929617049175
[Epoch 11, Batch 500] loss: 0.05115610125474632
[Epoch 11, Batch 600] loss: 0.05558960835915059
[Epoch 11, Batch 700] loss: 0.042805390985449776
[Epoch 11, Batch 800] loss: 0.05121466245269403
[Epoch 11, Batch 900] loss: 0.05576999093987979
[Epoch 11, Batch 1000] loss: 0.06449045226676389
[Epoch 11, Batch 1100] loss: 0.05233290437026881
[Epoch 11, Batch 1200] loss: 0.06038763483520597
[Epoch 11, Batch 1300] loss: 0.048982016562949864
[Epoch 11, Batch 1400] loss: 0.05415364838379901
[Epoch 11, Batch 1500] loss: 0.05345195804722607
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0625
Validation Accuracy: 0.9813
Overfitting: 0.0625
Early stopping epoch 11 for trial 5. Moving to next fold.
Fold 4 validation loss: 0.0625
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.3009424352645875
[Epoch 1, Batch 200] loss: 2.288323149681091
[Epoch 1, Batch 300] loss: 2.272273237705231
[Epoch 1, Batch 400] loss: 2.2462954139709472
[Epoch 1, Batch 500] loss: 2.1801989603042604
[Epoch 1, Batch 600] loss: 2.013963601589203
[Epoch 1, Batch 700] loss: 1.5202034372091293
[Epoch 1, Batch 800] loss: 0.908774603009224
[Epoch 1, Batch 900] loss: 0.6599212148785591
[Epoch 1, Batch 1000] loss: 0.5393009993433953
[Epoch 1, Batch 1100] loss: 0.49688074737787247
[Epoch 1, Batch 1200] loss: 0.4231843410432339
[Epoch 1, Batch 1300] loss: 0.4473481038212776
[Epoch 1, Batch 1400] loss: 0.3752944365143776
[Epoch 1, Batch 1500] loss: 0.36712597697973254
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3503
Validation Accuracy: 0.8962
Overfitting: 0.3503
[Epoch 2, Batch 100] loss: 0.3397721388936043
[Epoch 2, Batch 200] loss: 0.340267232991755
[Epoch 2, Batch 300] loss: 0.3165618544816971
[Epoch 2, Batch 400] loss: 0.28206511184573174
[Epoch 2, Batch 500] loss: 0.29043948501348493
[Epoch 2, Batch 600] loss: 0.2910081167146564
[Epoch 2, Batch 700] loss: 0.25064472123980525
[Epoch 2, Batch 800] loss: 0.23039386067539452
[Epoch 2, Batch 900] loss: 0.23829941071569918
[Epoch 2, Batch 1000] loss: 0.23416040115058423
[Epoch 2, Batch 1100] loss: 0.23854299254715441
[Epoch 2, Batch 1200] loss: 0.21693330492824317
[Epoch 2, Batch 1300] loss: 0.24156150169670582
[Epoch 2, Batch 1400] loss: 0.21951348908245563
[Epoch 2, Batch 1500] loss: 0.20955532737076282
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1939
Validation Accuracy: 0.9423
Overfitting: 0.1939
[Epoch 3, Batch 100] loss: 0.19193646712228657
[Epoch 3, Batch 200] loss: 0.1785530428402126
[Epoch 3, Batch 300] loss: 0.1757500160112977
[Epoch 3, Batch 400] loss: 0.19678335953503848
[Epoch 3, Batch 500] loss: 0.1863403122127056
[Epoch 3, Batch 600] loss: 0.17208061832934618
[Epoch 3, Batch 700] loss: 0.16998960569500923
[Epoch 3, Batch 800] loss: 0.1658659426588565
[Epoch 3, Batch 900] loss: 0.1742738618887961
[Epoch 3, Batch 1000] loss: 0.16609184622764586
[Epoch 3, Batch 1100] loss: 0.15443519610911607
[Epoch 3, Batch 1200] loss: 0.1532120612077415
[Epoch 3, Batch 1300] loss: 0.14885221485979855
[Epoch 3, Batch 1400] loss: 0.15696231732144952
[Epoch 3, Batch 1500] loss: 0.14973117534071206
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1453
Validation Accuracy: 0.9573
Overfitting: 0.1453
[Epoch 4, Batch 100] loss: 0.14315598557703196
[Epoch 4, Batch 200] loss: 0.12891198989935218
[Epoch 4, Batch 300] loss: 0.1410833291709423
[Epoch 4, Batch 400] loss: 0.14558152746409178
[Epoch 4, Batch 500] loss: 0.12401049189269543
[Epoch 4, Batch 600] loss: 0.14213393750600517
[Epoch 4, Batch 700] loss: 0.12390750644728542
[Epoch 4, Batch 800] loss: 0.13108713313005865
[Epoch 4, Batch 900] loss: 0.1356207716744393
[Epoch 4, Batch 1000] loss: 0.12506089854054153
[Epoch 4, Batch 1100] loss: 0.1324440614040941
[Epoch 4, Batch 1200] loss: 0.12180370893329381
[Epoch 4, Batch 1300] loss: 0.11531407658010721
[Epoch 4, Batch 1400] loss: 0.1161322999931872
[Epoch 4, Batch 1500] loss: 0.11440542050637305
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1247
Validation Accuracy: 0.9615
Overfitting: 0.1247
[Epoch 5, Batch 100] loss: 0.12307967441156506
[Epoch 5, Batch 200] loss: 0.10565151144284755
[Epoch 5, Batch 300] loss: 0.101085609854199
[Epoch 5, Batch 400] loss: 0.10436837940011173
[Epoch 5, Batch 500] loss: 0.117238332554698
[Epoch 5, Batch 600] loss: 0.11369680128060282
[Epoch 5, Batch 700] loss: 0.10431437800638378
[Epoch 5, Batch 800] loss: 0.11065274750813842
[Epoch 5, Batch 900] loss: 0.09020435631275177
[Epoch 5, Batch 1000] loss: 0.09693254534620792
[Epoch 5, Batch 1100] loss: 0.10217258743010461
[Epoch 5, Batch 1200] loss: 0.09269051517359912
[Epoch 5, Batch 1300] loss: 0.10389784601517021
[Epoch 5, Batch 1400] loss: 0.10487802662421018
[Epoch 5, Batch 1500] loss: 0.09762468005530536
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0989
Validation Accuracy: 0.9701
Overfitting: 0.0989
[Epoch 6, Batch 100] loss: 0.11027174088172614
[Epoch 6, Batch 200] loss: 0.09381837429711595
[Epoch 6, Batch 300] loss: 0.09602522439789027
[Epoch 6, Batch 400] loss: 0.08339458016213029
[Epoch 6, Batch 500] loss: 0.08983432567678391
[Epoch 6, Batch 600] loss: 0.09080106226727366
[Epoch 6, Batch 700] loss: 0.08346691198181361
[Epoch 6, Batch 800] loss: 0.09808310625725426
[Epoch 6, Batch 900] loss: 0.08023869574535639
[Epoch 6, Batch 1000] loss: 0.09490811520256102
[Epoch 6, Batch 1100] loss: 0.07620735377073289
[Epoch 6, Batch 1200] loss: 0.08911237011896446
[Epoch 6, Batch 1300] loss: 0.0774427016172558
[Epoch 6, Batch 1400] loss: 0.08318386018276215
[Epoch 6, Batch 1500] loss: 0.09000612078700215
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0873
Validation Accuracy: 0.9731
Overfitting: 0.0873
[Epoch 7, Batch 100] loss: 0.07142530684359372
[Epoch 7, Batch 200] loss: 0.06667683092877269
[Epoch 7, Batch 300] loss: 0.08320090583525598
[Epoch 7, Batch 400] loss: 0.07402311643585563
[Epoch 7, Batch 500] loss: 0.07855237438809126
[Epoch 7, Batch 600] loss: 0.08997419375926256
[Epoch 7, Batch 700] loss: 0.07339536287356169
[Epoch 7, Batch 800] loss: 0.08391509832348674
[Epoch 7, Batch 900] loss: 0.08923929315526039
[Epoch 7, Batch 1000] loss: 0.08216484883800149
[Epoch 7, Batch 1100] loss: 0.08342325031291693
[Epoch 7, Batch 1200] loss: 0.07650841958355159
[Epoch 7, Batch 1300] loss: 0.06519351582741365
[Epoch 7, Batch 1400] loss: 0.0705321048060432
[Epoch 7, Batch 1500] loss: 0.08536054816562683
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0836
Validation Accuracy: 0.9758
Overfitting: 0.0836
[Epoch 8, Batch 100] loss: 0.07251125884242356
[Epoch 8, Batch 200] loss: 0.06682485804893076
[Epoch 8, Batch 300] loss: 0.0669445403572172
[Epoch 8, Batch 400] loss: 0.0655752877611667
[Epoch 8, Batch 500] loss: 0.09165985309984535
[Epoch 8, Batch 600] loss: 0.07594953860156238
[Epoch 8, Batch 700] loss: 0.06492117641726508
[Epoch 8, Batch 800] loss: 0.06342974589439108
[Epoch 8, Batch 900] loss: 0.06578466616105288
[Epoch 8, Batch 1000] loss: 0.07214746130863205
[Epoch 8, Batch 1100] loss: 0.06373849364579655
[Epoch 8, Batch 1200] loss: 0.07207668947987259
[Epoch 8, Batch 1300] loss: 0.06454168270342052
[Epoch 8, Batch 1400] loss: 0.07922322895377874
[Epoch 8, Batch 1500] loss: 0.05620054025901482
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0717
Validation Accuracy: 0.9782
Overfitting: 0.0717
[Epoch 9, Batch 100] loss: 0.05925961957778782
[Epoch 9, Batch 200] loss: 0.05163965715561062
[Epoch 9, Batch 300] loss: 0.06416026771301403
[Epoch 9, Batch 400] loss: 0.062059026057831944
[Epoch 9, Batch 500] loss: 0.06383146462030709
[Epoch 9, Batch 600] loss: 0.06206862158374861
[Epoch 9, Batch 700] loss: 0.06457607854390517
[Epoch 9, Batch 800] loss: 0.06317989265080541
[Epoch 9, Batch 900] loss: 0.07227418242837302
[Epoch 9, Batch 1000] loss: 0.06553002164233476
[Epoch 9, Batch 1100] loss: 0.04158428694470786
[Epoch 9, Batch 1200] loss: 0.05532391607412137
[Epoch 9, Batch 1300] loss: 0.05705716146621853
[Epoch 9, Batch 1400] loss: 0.06601549066603184
[Epoch 9, Batch 1500] loss: 0.06961182059952989
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0737
Validation Accuracy: 0.9776
Overfitting: 0.0737
Best model saved at epoch 9 with validation loss: 0.0737
[Epoch 10, Batch 100] loss: 0.05497713065007701
[Epoch 10, Batch 200] loss: 0.04856807758333161
[Epoch 10, Batch 300] loss: 0.05668110788043123
[Epoch 10, Batch 400] loss: 0.055060109007172287
[Epoch 10, Batch 500] loss: 0.04567557415459305
[Epoch 10, Batch 600] loss: 0.04570443798787892
[Epoch 10, Batch 700] loss: 0.06446274698129856
[Epoch 10, Batch 800] loss: 0.055765983116580174
[Epoch 10, Batch 900] loss: 0.06414061833405867
[Epoch 10, Batch 1000] loss: 0.05220848881173879
[Epoch 10, Batch 1100] loss: 0.06932019295170903
[Epoch 10, Batch 1200] loss: 0.05047980122093577
[Epoch 10, Batch 1300] loss: 0.06566535227932035
[Epoch 10, Batch 1400] loss: 0.057962680445052685
[Epoch 10, Batch 1500] loss: 0.0624237465695478
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0657
Validation Accuracy: 0.9792
Overfitting: 0.0657
[Epoch 11, Batch 100] loss: 0.05153932380490005
[Epoch 11, Batch 200] loss: 0.04779919672058895
[Epoch 11, Batch 300] loss: 0.05042909795884043
[Epoch 11, Batch 400] loss: 0.04979870778974146
[Epoch 11, Batch 500] loss: 0.051306292919907716
[Epoch 11, Batch 600] loss: 0.05221548794186674
[Epoch 11, Batch 700] loss: 0.051427616269793364
[Epoch 11, Batch 800] loss: 0.04029361734865233
[Epoch 11, Batch 900] loss: 0.04517847109003924
[Epoch 11, Batch 1000] loss: 0.047098351378226655
[Epoch 11, Batch 1100] loss: 0.05978873025160283
[Epoch 11, Batch 1200] loss: 0.05228914689156227
[Epoch 11, Batch 1300] loss: 0.06242655194364488
[Epoch 11, Batch 1400] loss: 0.058873075513402
[Epoch 11, Batch 1500] loss: 0.05133067712187767
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0639
Validation Accuracy: 0.9796
Overfitting: 0.0639
Early stopping epoch 11 for trial 5. Moving to next fold.
Fold 5 validation loss: 0.0639
Mean validation loss across all folds for Trial 5 is 0.0652 with trial config:  l1: 128, l2: 64, lr: 0.0005, batch_size: 32
[I 2024-12-10 04:33:33,209] Trial 4 finished with value: 0.06517864855801066 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.0005, 'batch_size': 32}. Best is trial 0 with value: 0.05093086766599445.

Selected Hyperparameters for Trial 6:
  l1: 128, l2: 128, lr: 0.0005, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.304501163959503
[Epoch 1, Batch 200] loss: 2.297869985103607
[Epoch 1, Batch 300] loss: 2.2927958512306215
[Epoch 1, Batch 400] loss: 2.2837524032592773
[Epoch 1, Batch 500] loss: 2.2715325808525084
[Epoch 1, Batch 600] loss: 2.2511828684806825
[Epoch 1, Batch 700] loss: 2.202220857143402
[Epoch 1, Batch 800] loss: 2.0776514506340025
[Epoch 1, Batch 900] loss: 1.6655600035190583
[Epoch 1, Batch 1000] loss: 1.0261893111467362
[Epoch 1, Batch 1100] loss: 0.7082870119810104
[Epoch 1, Batch 1200] loss: 0.5691855731606483
[Epoch 1, Batch 1300] loss: 0.5353124645352364
[Epoch 1, Batch 1400] loss: 0.49995088413357736
[Epoch 1, Batch 1500] loss: 0.43070200324058533
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.4124
Validation Accuracy: 0.8798
Overfitting: 0.4124
[Epoch 2, Batch 100] loss: 0.3772260320186615
[Epoch 2, Batch 200] loss: 0.39022904112935064
[Epoch 2, Batch 300] loss: 0.33416322723031044
[Epoch 2, Batch 400] loss: 0.3340956895053387
[Epoch 2, Batch 500] loss: 0.32796801850199697
[Epoch 2, Batch 600] loss: 0.27898220635950566
[Epoch 2, Batch 700] loss: 0.3272060226276517
[Epoch 2, Batch 800] loss: 0.30885197207331655
[Epoch 2, Batch 900] loss: 0.2467045511677861
[Epoch 2, Batch 1000] loss: 0.26287010438740255
[Epoch 2, Batch 1100] loss: 0.2633164279907942
[Epoch 2, Batch 1200] loss: 0.25716461896896364
[Epoch 2, Batch 1300] loss: 0.2332618571817875
[Epoch 2, Batch 1400] loss: 0.2638570429012179
[Epoch 2, Batch 1500] loss: 0.219481880068779
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2117
Validation Accuracy: 0.9328
Overfitting: 0.2117
[Epoch 3, Batch 100] loss: 0.19622381120920182
[Epoch 3, Batch 200] loss: 0.1891140142083168
[Epoch 3, Batch 300] loss: 0.20927044369280337
[Epoch 3, Batch 400] loss: 0.19378308564424515
[Epoch 3, Batch 500] loss: 0.21323555368930103
[Epoch 3, Batch 600] loss: 0.1823020514845848
[Epoch 3, Batch 700] loss: 0.1676038675568998
[Epoch 3, Batch 800] loss: 0.18228519270196558
[Epoch 3, Batch 900] loss: 0.18855978466570378
[Epoch 3, Batch 1000] loss: 0.18118026595562697
[Epoch 3, Batch 1100] loss: 0.1553451032936573
[Epoch 3, Batch 1200] loss: 0.17222370700910689
[Epoch 3, Batch 1300] loss: 0.1549396997317672
[Epoch 3, Batch 1400] loss: 0.1326324486080557
[Epoch 3, Batch 1500] loss: 0.14526687283068895
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1216
Validation Accuracy: 0.9636
Overfitting: 0.1216
[Epoch 4, Batch 100] loss: 0.1462816694378853
[Epoch 4, Batch 200] loss: 0.14241175369359552
[Epoch 4, Batch 300] loss: 0.14675023714080454
[Epoch 4, Batch 400] loss: 0.13881737938150762
[Epoch 4, Batch 500] loss: 0.13188929322175683
[Epoch 4, Batch 600] loss: 0.13003184948116542
[Epoch 4, Batch 700] loss: 0.1265293088648468
[Epoch 4, Batch 800] loss: 0.12867484440095722
[Epoch 4, Batch 900] loss: 0.13025057269260287
[Epoch 4, Batch 1000] loss: 0.12639735591597856
[Epoch 4, Batch 1100] loss: 0.12175525881350041
[Epoch 4, Batch 1200] loss: 0.12192068327218294
[Epoch 4, Batch 1300] loss: 0.12248764608055353
[Epoch 4, Batch 1400] loss: 0.10525716071948409
[Epoch 4, Batch 1500] loss: 0.1047036171797663
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0995
Validation Accuracy: 0.9697
Overfitting: 0.0995
[Epoch 5, Batch 100] loss: 0.11996487753465772
[Epoch 5, Batch 200] loss: 0.11806084172800184
[Epoch 5, Batch 300] loss: 0.10961966491304338
[Epoch 5, Batch 400] loss: 0.11616675750352443
[Epoch 5, Batch 500] loss: 0.1014791657961905
[Epoch 5, Batch 600] loss: 0.10589947432279587
[Epoch 5, Batch 700] loss: 0.11041853362694383
[Epoch 5, Batch 800] loss: 0.09514036783017218
[Epoch 5, Batch 900] loss: 0.09260050968732685
[Epoch 5, Batch 1000] loss: 0.12048951060045511
[Epoch 5, Batch 1100] loss: 0.08500838513020426
[Epoch 5, Batch 1200] loss: 0.09262310754042119
[Epoch 5, Batch 1300] loss: 0.0998968483414501
[Epoch 5, Batch 1400] loss: 0.09178396536037325
[Epoch 5, Batch 1500] loss: 0.08867472032085061
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0811
Validation Accuracy: 0.9755
Overfitting: 0.0811
[Epoch 6, Batch 100] loss: 0.10510228808969259
[Epoch 6, Batch 200] loss: 0.09494834262877702
[Epoch 6, Batch 300] loss: 0.10077692694030702
[Epoch 6, Batch 400] loss: 0.06777567993383854
[Epoch 6, Batch 500] loss: 0.09571438932791353
[Epoch 6, Batch 600] loss: 0.08803258534986526
[Epoch 6, Batch 700] loss: 0.07981020360486582
[Epoch 6, Batch 800] loss: 0.08333494700491428
[Epoch 6, Batch 900] loss: 0.08055581825785339
[Epoch 6, Batch 1000] loss: 0.07518287951475941
[Epoch 6, Batch 1100] loss: 0.07990589545108379
[Epoch 6, Batch 1200] loss: 0.0888614951632917
[Epoch 6, Batch 1300] loss: 0.09205968586262316
[Epoch 6, Batch 1400] loss: 0.08107197601348162
[Epoch 6, Batch 1500] loss: 0.08339598152786493
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0791
Validation Accuracy: 0.9752
Overfitting: 0.0791
[Epoch 7, Batch 100] loss: 0.07384410754544661
[Epoch 7, Batch 200] loss: 0.08294846173841507
[Epoch 7, Batch 300] loss: 0.07388103307690472
[Epoch 7, Batch 400] loss: 0.06899786845780909
[Epoch 7, Batch 500] loss: 0.07581891513429583
[Epoch 7, Batch 600] loss: 0.07732749722432346
[Epoch 7, Batch 700] loss: 0.07587782034184784
[Epoch 7, Batch 800] loss: 0.07144523998489603
[Epoch 7, Batch 900] loss: 0.0803473634691909
[Epoch 7, Batch 1000] loss: 0.06553975110407918
[Epoch 7, Batch 1100] loss: 0.07773607338778675
[Epoch 7, Batch 1200] loss: 0.07361271673813462
[Epoch 7, Batch 1300] loss: 0.06403752688318491
[Epoch 7, Batch 1400] loss: 0.08112251913640649
[Epoch 7, Batch 1500] loss: 0.08595396097982302
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0733
Validation Accuracy: 0.9757
Overfitting: 0.0733
[Epoch 8, Batch 100] loss: 0.06728157347301021
[Epoch 8, Batch 200] loss: 0.07588267770130187
[Epoch 8, Batch 300] loss: 0.06366608247393742
[Epoch 8, Batch 400] loss: 0.08507016038522125
[Epoch 8, Batch 500] loss: 0.0687136218836531
[Epoch 8, Batch 600] loss: 0.0638068915088661
[Epoch 8, Batch 700] loss: 0.06077885815408081
[Epoch 8, Batch 800] loss: 0.06404191461391746
[Epoch 8, Batch 900] loss: 0.06915705305989832
[Epoch 8, Batch 1000] loss: 0.07225006426218897
[Epoch 8, Batch 1100] loss: 0.06834625623654574
[Epoch 8, Batch 1200] loss: 0.06922015247866511
[Epoch 8, Batch 1300] loss: 0.056822386062704025
[Epoch 8, Batch 1400] loss: 0.07820833037490957
[Epoch 8, Batch 1500] loss: 0.06605096469633281
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9791
Overfitting: 0.0665
[Epoch 9, Batch 100] loss: 0.07427131020696834
[Epoch 9, Batch 200] loss: 0.06924378454685211
[Epoch 9, Batch 300] loss: 0.058221972878091034
[Epoch 9, Batch 400] loss: 0.06063041591551155
[Epoch 9, Batch 500] loss: 0.06034667363390327
[Epoch 9, Batch 600] loss: 0.06161074731266126
[Epoch 9, Batch 700] loss: 0.06954664420569316
[Epoch 9, Batch 800] loss: 0.05382679251371883
[Epoch 9, Batch 900] loss: 0.05616854888619855
[Epoch 9, Batch 1000] loss: 0.05621323786908761
[Epoch 9, Batch 1100] loss: 0.06274669216945768
[Epoch 9, Batch 1200] loss: 0.06366598370485008
[Epoch 9, Batch 1300] loss: 0.05563741069054231
[Epoch 9, Batch 1400] loss: 0.07699994528316893
[Epoch 9, Batch 1500] loss: 0.04929090261925012
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0628
Validation Accuracy: 0.9803
Overfitting: 0.0628
Best model saved at epoch 9 with validation loss: 0.0628
[Epoch 10, Batch 100] loss: 0.0697127868689131
[Epoch 10, Batch 200] loss: 0.054016235768795016
[Epoch 10, Batch 300] loss: 0.061980827888473866
[Epoch 10, Batch 400] loss: 0.04333339313743636
[Epoch 10, Batch 500] loss: 0.059422392211854455
[Epoch 10, Batch 600] loss: 0.052220404397230594
[Epoch 10, Batch 700] loss: 0.046857413288671525
[Epoch 10, Batch 800] loss: 0.05416951802093536
[Epoch 10, Batch 900] loss: 0.07376607043901458
[Epoch 10, Batch 1000] loss: 0.0524848623201251
[Epoch 10, Batch 1100] loss: 0.0559795323619619
[Epoch 10, Batch 1200] loss: 0.05831604062812403
[Epoch 10, Batch 1300] loss: 0.0584782293648459
[Epoch 10, Batch 1400] loss: 0.05269022278720513
[Epoch 10, Batch 1500] loss: 0.05572859841166064
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0789
Validation Accuracy: 0.9766
Overfitting: 0.0789
[Epoch 11, Batch 100] loss: 0.05305906045483425
[Epoch 11, Batch 200] loss: 0.0452156026638113
[Epoch 11, Batch 300] loss: 0.0427955105912406
[Epoch 11, Batch 400] loss: 0.05978079688618891
[Epoch 11, Batch 500] loss: 0.05481023261905648
[Epoch 11, Batch 600] loss: 0.0562077903887257
[Epoch 11, Batch 700] loss: 0.04869703664910048
[Epoch 11, Batch 800] loss: 0.04144372627139092
[Epoch 11, Batch 900] loss: 0.0646317465766333
[Epoch 11, Batch 1000] loss: 0.04898708005901426
[Epoch 11, Batch 1100] loss: 0.053873268633615225
[Epoch 11, Batch 1200] loss: 0.050710078788688405
[Epoch 11, Batch 1300] loss: 0.05400463671889156
[Epoch 11, Batch 1400] loss: 0.060417201770469546
[Epoch 11, Batch 1500] loss: 0.046476517657283695
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9811
Overfitting: 0.0619
Early stopping epoch 11 for trial 6. Moving to next fold.
Fold 1 validation loss: 0.0619
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.294288167953491
[Epoch 1, Batch 200] loss: 2.276815505027771
[Epoch 1, Batch 300] loss: 2.2471801805496217
[Epoch 1, Batch 400] loss: 2.180668787956238
[Epoch 1, Batch 500] loss: 1.9918981873989106
[Epoch 1, Batch 600] loss: 1.4645951187610626
[Epoch 1, Batch 700] loss: 0.8523390960693359
[Epoch 1, Batch 800] loss: 0.5947335171699524
[Epoch 1, Batch 900] loss: 0.4892029544711113
[Epoch 1, Batch 1000] loss: 0.4336648292839527
[Epoch 1, Batch 1100] loss: 0.4261152337491512
[Epoch 1, Batch 1200] loss: 0.3714663514494896
[Epoch 1, Batch 1300] loss: 0.38302905023097994
[Epoch 1, Batch 1400] loss: 0.3153786650300026
[Epoch 1, Batch 1500] loss: 0.3106837151199579
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3167
Validation Accuracy: 0.9058
Overfitting: 0.3167
[Epoch 2, Batch 100] loss: 0.2945576388388872
[Epoch 2, Batch 200] loss: 0.287447240576148
[Epoch 2, Batch 300] loss: 0.27773535273969174
[Epoch 2, Batch 400] loss: 0.2548698892444372
[Epoch 2, Batch 500] loss: 0.23854707926511765
[Epoch 2, Batch 600] loss: 0.27444298135116696
[Epoch 2, Batch 700] loss: 0.2021680111438036
[Epoch 2, Batch 800] loss: 0.22583673622459174
[Epoch 2, Batch 900] loss: 0.2210355247184634
[Epoch 2, Batch 1000] loss: 0.20247425239533187
[Epoch 2, Batch 1100] loss: 0.18155863692983984
[Epoch 2, Batch 1200] loss: 0.16797056749463082
[Epoch 2, Batch 1300] loss: 0.17152503557503224
[Epoch 2, Batch 1400] loss: 0.17557986130937933
[Epoch 2, Batch 1500] loss: 0.1501735481619835
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1848
Validation Accuracy: 0.9429
Overfitting: 0.1848
[Epoch 3, Batch 100] loss: 0.17553623035550117
[Epoch 3, Batch 200] loss: 0.16061106372624637
[Epoch 3, Batch 300] loss: 0.154845565687865
[Epoch 3, Batch 400] loss: 0.1515485199354589
[Epoch 3, Batch 500] loss: 0.14065067859366537
[Epoch 3, Batch 600] loss: 0.15749950544908642
[Epoch 3, Batch 700] loss: 0.15008797930553555
[Epoch 3, Batch 800] loss: 0.14061115123331547
[Epoch 3, Batch 900] loss: 0.1492345211841166
[Epoch 3, Batch 1000] loss: 0.1351473169401288
[Epoch 3, Batch 1100] loss: 0.13019817375577986
[Epoch 3, Batch 1200] loss: 0.12308062828145921
[Epoch 3, Batch 1300] loss: 0.12482511791400612
[Epoch 3, Batch 1400] loss: 0.14466391250491142
[Epoch 3, Batch 1500] loss: 0.1187061816547066
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1373
Validation Accuracy: 0.9597
Overfitting: 0.1373
[Epoch 4, Batch 100] loss: 0.11474259665701539
[Epoch 4, Batch 200] loss: 0.1333381078299135
[Epoch 4, Batch 300] loss: 0.10889005518518388
[Epoch 4, Batch 400] loss: 0.13836281797848643
[Epoch 4, Batch 500] loss: 0.13147596889175475
[Epoch 4, Batch 600] loss: 0.10808373593725264
[Epoch 4, Batch 700] loss: 0.10791063928976655
[Epoch 4, Batch 800] loss: 0.09970753064379095
[Epoch 4, Batch 900] loss: 0.10500462978612632
[Epoch 4, Batch 1000] loss: 0.10833827294874937
[Epoch 4, Batch 1100] loss: 0.09508488009683788
[Epoch 4, Batch 1200] loss: 0.10410451458767056
[Epoch 4, Batch 1300] loss: 0.10973045502789319
[Epoch 4, Batch 1400] loss: 0.09763652642257512
[Epoch 4, Batch 1500] loss: 0.11763279836624861
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1150
Validation Accuracy: 0.9647
Overfitting: 0.1150
[Epoch 5, Batch 100] loss: 0.0917774161323905
[Epoch 5, Batch 200] loss: 0.09373093698639423
[Epoch 5, Batch 300] loss: 0.11676399095915257
[Epoch 5, Batch 400] loss: 0.10196675843093544
[Epoch 5, Batch 500] loss: 0.07703435057308525
[Epoch 5, Batch 600] loss: 0.0910469248984009
[Epoch 5, Batch 700] loss: 0.09746220611035823
[Epoch 5, Batch 800] loss: 0.09337337803095579
[Epoch 5, Batch 900] loss: 0.08784412962850183
[Epoch 5, Batch 1000] loss: 0.10261647202074528
[Epoch 5, Batch 1100] loss: 0.08469881718046963
[Epoch 5, Batch 1200] loss: 0.09832771110581234
[Epoch 5, Batch 1300] loss: 0.0878012906620279
[Epoch 5, Batch 1400] loss: 0.08259897883981467
[Epoch 5, Batch 1500] loss: 0.08975725709460676
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0991
Validation Accuracy: 0.9688
Overfitting: 0.0991
[Epoch 6, Batch 100] loss: 0.08834695797180757
[Epoch 6, Batch 200] loss: 0.07921858344227076
[Epoch 6, Batch 300] loss: 0.08146627694368362
[Epoch 6, Batch 400] loss: 0.09905613771174103
[Epoch 6, Batch 500] loss: 0.07043448372278363
[Epoch 6, Batch 600] loss: 0.07149518858175724
[Epoch 6, Batch 700] loss: 0.09060274622403085
[Epoch 6, Batch 800] loss: 0.07204730506520718
[Epoch 6, Batch 900] loss: 0.08760605361545458
[Epoch 6, Batch 1000] loss: 0.07548502014717087
[Epoch 6, Batch 1100] loss: 0.0794530570320785
[Epoch 6, Batch 1200] loss: 0.07074773046188057
[Epoch 6, Batch 1300] loss: 0.08272583053912967
[Epoch 6, Batch 1400] loss: 0.09021668216213584
[Epoch 6, Batch 1500] loss: 0.07093470956664533
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0950
Validation Accuracy: 0.9708
Overfitting: 0.0950
[Epoch 7, Batch 100] loss: 0.08757318920921535
[Epoch 7, Batch 200] loss: 0.07397332528373227
[Epoch 7, Batch 300] loss: 0.07344136058702133
[Epoch 7, Batch 400] loss: 0.07428921716520563
[Epoch 7, Batch 500] loss: 0.09467638937290758
[Epoch 7, Batch 600] loss: 0.07361159713007509
[Epoch 7, Batch 700] loss: 0.07798379202838987
[Epoch 7, Batch 800] loss: 0.07256876660510897
[Epoch 7, Batch 900] loss: 0.0733385697612539
[Epoch 7, Batch 1000] loss: 0.07672155466629192
[Epoch 7, Batch 1100] loss: 0.06514959387015551
[Epoch 7, Batch 1200] loss: 0.06725717114983126
[Epoch 7, Batch 1300] loss: 0.06642335155745968
[Epoch 7, Batch 1400] loss: 0.06511043936014176
[Epoch 7, Batch 1500] loss: 0.06395549135748296
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0834
Validation Accuracy: 0.9737
Overfitting: 0.0834
[Epoch 8, Batch 100] loss: 0.06570168637554161
[Epoch 8, Batch 200] loss: 0.053888069507665934
[Epoch 8, Batch 300] loss: 0.06616642585722729
[Epoch 8, Batch 400] loss: 0.0652287109021563
[Epoch 8, Batch 500] loss: 0.07162624054821208
[Epoch 8, Batch 600] loss: 0.06422644709120505
[Epoch 8, Batch 700] loss: 0.06483455990441143
[Epoch 8, Batch 800] loss: 0.06623666671104729
[Epoch 8, Batch 900] loss: 0.06048234761925414
[Epoch 8, Batch 1000] loss: 0.05917587789706886
[Epoch 8, Batch 1100] loss: 0.06011864804197103
[Epoch 8, Batch 1200] loss: 0.06721338303061203
[Epoch 8, Batch 1300] loss: 0.06592297045164741
[Epoch 8, Batch 1400] loss: 0.08147596132475883
[Epoch 8, Batch 1500] loss: 0.06981784281786531
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0797
Validation Accuracy: 0.9755
Overfitting: 0.0797
[Epoch 9, Batch 100] loss: 0.0705701909295749
[Epoch 9, Batch 200] loss: 0.0573376610444393
[Epoch 9, Batch 300] loss: 0.059126679860055445
[Epoch 9, Batch 400] loss: 0.06061799145536497
[Epoch 9, Batch 500] loss: 0.05148526690201834
[Epoch 9, Batch 600] loss: 0.05444982258137315
[Epoch 9, Batch 700] loss: 0.05999180706450716
[Epoch 9, Batch 800] loss: 0.0658973809145391
[Epoch 9, Batch 900] loss: 0.07079125477466733
[Epoch 9, Batch 1000] loss: 0.06356285761692561
[Epoch 9, Batch 1100] loss: 0.05602112025022507
[Epoch 9, Batch 1200] loss: 0.05068942962097935
[Epoch 9, Batch 1300] loss: 0.06620727912522853
[Epoch 9, Batch 1400] loss: 0.060708750349003825
[Epoch 9, Batch 1500] loss: 0.05296489745611325
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0747
Validation Accuracy: 0.9780
Overfitting: 0.0747
Best model saved at epoch 9 with validation loss: 0.0747
[Epoch 10, Batch 100] loss: 0.0577184028015472
[Epoch 10, Batch 200] loss: 0.04961161802755669
[Epoch 10, Batch 300] loss: 0.04829945481615141
[Epoch 10, Batch 400] loss: 0.05644272962701507
[Epoch 10, Batch 500] loss: 0.062129897736012935
[Epoch 10, Batch 600] loss: 0.04610652680741623
[Epoch 10, Batch 700] loss: 0.05199621704407036
[Epoch 10, Batch 800] loss: 0.054117872130591424
[Epoch 10, Batch 900] loss: 0.049259868650697175
[Epoch 10, Batch 1000] loss: 0.054104209096403795
[Epoch 10, Batch 1100] loss: 0.06174095945665613
[Epoch 10, Batch 1200] loss: 0.0810885819233954
[Epoch 10, Batch 1300] loss: 0.05261544137261808
[Epoch 10, Batch 1400] loss: 0.0459713977877982
[Epoch 10, Batch 1500] loss: 0.0577093495707959
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0774
Validation Accuracy: 0.9770
Overfitting: 0.0774
[Epoch 11, Batch 100] loss: 0.04992249851929955
[Epoch 11, Batch 200] loss: 0.05266723070293665
[Epoch 11, Batch 300] loss: 0.055704303466482086
[Epoch 11, Batch 400] loss: 0.04082603445276618
[Epoch 11, Batch 500] loss: 0.049756968804867935
[Epoch 11, Batch 600] loss: 0.0432748760166578
[Epoch 11, Batch 700] loss: 0.057823616109089926
[Epoch 11, Batch 800] loss: 0.04714149886160158
[Epoch 11, Batch 900] loss: 0.051580438506789505
[Epoch 11, Batch 1000] loss: 0.04975252689328045
[Epoch 11, Batch 1100] loss: 0.04471360323135741
[Epoch 11, Batch 1200] loss: 0.04653280328144319
[Epoch 11, Batch 1300] loss: 0.0718478934536688
[Epoch 11, Batch 1400] loss: 0.06301135467365385
[Epoch 11, Batch 1500] loss: 0.040136013915762304
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0685
Validation Accuracy: 0.9792
Overfitting: 0.0685
Early stopping epoch 11 for trial 6. Moving to next fold.
Fold 2 validation loss: 0.0685
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.300850360393524
[Epoch 1, Batch 200] loss: 2.297800688743591
[Epoch 1, Batch 300] loss: 2.2905933833122254
[Epoch 1, Batch 400] loss: 2.2813091325759887
[Epoch 1, Batch 500] loss: 2.2690184211730955
[Epoch 1, Batch 600] loss: 2.250195481777191
[Epoch 1, Batch 700] loss: 2.2113587641716004
[Epoch 1, Batch 800] loss: 2.121376407146454
[Epoch 1, Batch 900] loss: 1.8597201561927796
[Epoch 1, Batch 1000] loss: 1.3061363637447356
[Epoch 1, Batch 1100] loss: 0.8040015494823456
[Epoch 1, Batch 1200] loss: 0.5919132316112519
[Epoch 1, Batch 1300] loss: 0.4853942674398422
[Epoch 1, Batch 1400] loss: 0.4538664174079895
[Epoch 1, Batch 1500] loss: 0.44072182834148405
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.4357
Validation Accuracy: 0.8680
Overfitting: 0.4357
[Epoch 2, Batch 100] loss: 0.37786073356866834
[Epoch 2, Batch 200] loss: 0.37584161415696143
[Epoch 2, Batch 300] loss: 0.35450461626052854
[Epoch 2, Batch 400] loss: 0.3386163561046123
[Epoch 2, Batch 500] loss: 0.3130168775469065
[Epoch 2, Batch 600] loss: 0.3080853621289134
[Epoch 2, Batch 700] loss: 0.27506047531962396
[Epoch 2, Batch 800] loss: 0.28329107515513896
[Epoch 2, Batch 900] loss: 0.2726616130024195
[Epoch 2, Batch 1000] loss: 0.23129748560488225
[Epoch 2, Batch 1100] loss: 0.23981700843200088
[Epoch 2, Batch 1200] loss: 0.23748514894396067
[Epoch 2, Batch 1300] loss: 0.22789606124162673
[Epoch 2, Batch 1400] loss: 0.22877043463289737
[Epoch 2, Batch 1500] loss: 0.22031510394066572
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2058
Validation Accuracy: 0.9400
Overfitting: 0.2058
[Epoch 3, Batch 100] loss: 0.20575313787907362
[Epoch 3, Batch 200] loss: 0.1987205531820655
[Epoch 3, Batch 300] loss: 0.19835691716521978
[Epoch 3, Batch 400] loss: 0.1828286259993911
[Epoch 3, Batch 500] loss: 0.18458213672041893
[Epoch 3, Batch 600] loss: 0.15169803727418185
[Epoch 3, Batch 700] loss: 0.1797498320043087
[Epoch 3, Batch 800] loss: 0.17634978916496039
[Epoch 3, Batch 900] loss: 0.17629373425617814
[Epoch 3, Batch 1000] loss: 0.15418628755956887
[Epoch 3, Batch 1100] loss: 0.14797044988721608
[Epoch 3, Batch 1200] loss: 0.15096625078469514
[Epoch 3, Batch 1300] loss: 0.15326759612187743
[Epoch 3, Batch 1400] loss: 0.1395866293273866
[Epoch 3, Batch 1500] loss: 0.15782465228810907
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1530
Validation Accuracy: 0.9554
Overfitting: 0.1530
[Epoch 4, Batch 100] loss: 0.12808265476487576
[Epoch 4, Batch 200] loss: 0.14752309593372048
[Epoch 4, Batch 300] loss: 0.1486087209172547
[Epoch 4, Batch 400] loss: 0.13998100109398365
[Epoch 4, Batch 500] loss: 0.1452985701803118
[Epoch 4, Batch 600] loss: 0.11679641116410494
[Epoch 4, Batch 700] loss: 0.11400950972922147
[Epoch 4, Batch 800] loss: 0.14773861970752478
[Epoch 4, Batch 900] loss: 0.12223255869932473
[Epoch 4, Batch 1000] loss: 0.11930258229374885
[Epoch 4, Batch 1100] loss: 0.11266574870795011
[Epoch 4, Batch 1200] loss: 0.1270385105255991
[Epoch 4, Batch 1300] loss: 0.11476122920401394
[Epoch 4, Batch 1400] loss: 0.11325688977725804
[Epoch 4, Batch 1500] loss: 0.11252159724943339
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1199
Validation Accuracy: 0.9657
Overfitting: 0.1199
[Epoch 5, Batch 100] loss: 0.11168866061605513
[Epoch 5, Batch 200] loss: 0.10686833003070205
[Epoch 5, Batch 300] loss: 0.10545591323636472
[Epoch 5, Batch 400] loss: 0.11024398515932261
[Epoch 5, Batch 500] loss: 0.10611263546161354
[Epoch 5, Batch 600] loss: 0.09826618879102171
[Epoch 5, Batch 700] loss: 0.10114384539425374
[Epoch 5, Batch 800] loss: 0.09603946215473115
[Epoch 5, Batch 900] loss: 0.10067013673717157
[Epoch 5, Batch 1000] loss: 0.1049069032818079
[Epoch 5, Batch 1100] loss: 0.10972852111794054
[Epoch 5, Batch 1200] loss: 0.08818784723989666
[Epoch 5, Batch 1300] loss: 0.10149873334914446
[Epoch 5, Batch 1400] loss: 0.09376022106502205
[Epoch 5, Batch 1500] loss: 0.118602706650272
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1109
Validation Accuracy: 0.9683
Overfitting: 0.1109
[Epoch 6, Batch 100] loss: 0.08543548399815336
[Epoch 6, Batch 200] loss: 0.1004001663485542
[Epoch 6, Batch 300] loss: 0.09091086330357939
[Epoch 6, Batch 400] loss: 0.0887194937095046
[Epoch 6, Batch 500] loss: 0.09791500314604491
[Epoch 6, Batch 600] loss: 0.09346169247524813
[Epoch 6, Batch 700] loss: 0.08158441664651037
[Epoch 6, Batch 800] loss: 0.07339977599680424
[Epoch 6, Batch 900] loss: 0.07503985040821134
[Epoch 6, Batch 1000] loss: 0.09454268267843872
[Epoch 6, Batch 1100] loss: 0.07775787317426876
[Epoch 6, Batch 1200] loss: 0.08092194098280743
[Epoch 6, Batch 1300] loss: 0.10103868282400072
[Epoch 6, Batch 1400] loss: 0.09224034176208079
[Epoch 6, Batch 1500] loss: 0.08403568384237588
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0950
Validation Accuracy: 0.9711
Overfitting: 0.0950
[Epoch 7, Batch 100] loss: 0.0796963533340022
[Epoch 7, Batch 200] loss: 0.07820911659393459
[Epoch 7, Batch 300] loss: 0.07022824193583801
[Epoch 7, Batch 400] loss: 0.07558082528412342
[Epoch 7, Batch 500] loss: 0.08329780161846428
[Epoch 7, Batch 600] loss: 0.10102765992982313
[Epoch 7, Batch 700] loss: 0.062289088126271965
[Epoch 7, Batch 800] loss: 0.08527333968319
[Epoch 7, Batch 900] loss: 0.06712553978897631
[Epoch 7, Batch 1000] loss: 0.08367776396917179
[Epoch 7, Batch 1100] loss: 0.08249605162069201
[Epoch 7, Batch 1200] loss: 0.07503312963293865
[Epoch 7, Batch 1300] loss: 0.08012309794779866
[Epoch 7, Batch 1400] loss: 0.07335446775890887
[Epoch 7, Batch 1500] loss: 0.07605006996542216
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0802
Validation Accuracy: 0.9756
Overfitting: 0.0802
[Epoch 8, Batch 100] loss: 0.07119554167613387
[Epoch 8, Batch 200] loss: 0.08570342473685741
[Epoch 8, Batch 300] loss: 0.08002929864916951
[Epoch 8, Batch 400] loss: 0.07081376460846514
[Epoch 8, Batch 500] loss: 0.06779098191764206
[Epoch 8, Batch 600] loss: 0.05716178981820121
[Epoch 8, Batch 700] loss: 0.06622749282978475
[Epoch 8, Batch 800] loss: 0.06269457509508357
[Epoch 8, Batch 900] loss: 0.07196202956140041
[Epoch 8, Batch 1000] loss: 0.07216777415480465
[Epoch 8, Batch 1100] loss: 0.06761492620687931
[Epoch 8, Batch 1200] loss: 0.057556276886025444
[Epoch 8, Batch 1300] loss: 0.06722912127152085
[Epoch 8, Batch 1400] loss: 0.06718728370033204
[Epoch 8, Batch 1500] loss: 0.08072656649630516
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0868
Validation Accuracy: 0.9738
Overfitting: 0.0868
[Epoch 9, Batch 100] loss: 0.0703609191882424
[Epoch 9, Batch 200] loss: 0.0637916579307057
[Epoch 9, Batch 300] loss: 0.07679963835515081
[Epoch 9, Batch 400] loss: 0.07302383910631761
[Epoch 9, Batch 500] loss: 0.06754278096370399
[Epoch 9, Batch 600] loss: 0.05882649929495529
[Epoch 9, Batch 700] loss: 0.06100323028396815
[Epoch 9, Batch 800] loss: 0.05729714923305437
[Epoch 9, Batch 900] loss: 0.06134433583589271
[Epoch 9, Batch 1000] loss: 0.06722858445020392
[Epoch 9, Batch 1100] loss: 0.06272032384062186
[Epoch 9, Batch 1200] loss: 0.06523916648235172
[Epoch 9, Batch 1300] loss: 0.05885484900791198
[Epoch 9, Batch 1400] loss: 0.056352966299746184
[Epoch 9, Batch 1500] loss: 0.06608346273307689
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0686
Validation Accuracy: 0.9804
Overfitting: 0.0686
Best model saved at epoch 9 with validation loss: 0.0686
[Epoch 10, Batch 100] loss: 0.05795607833890244
[Epoch 10, Batch 200] loss: 0.05017656124429777
[Epoch 10, Batch 300] loss: 0.058090446835849435
[Epoch 10, Batch 400] loss: 0.05572679142002016
[Epoch 10, Batch 500] loss: 0.05857272611465305
[Epoch 10, Batch 600] loss: 0.053332694750279186
[Epoch 10, Batch 700] loss: 0.05182571501703933
[Epoch 10, Batch 800] loss: 0.06384328702581116
[Epoch 10, Batch 900] loss: 0.059704152741469445
[Epoch 10, Batch 1000] loss: 0.061964714876376094
[Epoch 10, Batch 1100] loss: 0.05807835788000375
[Epoch 10, Batch 1200] loss: 0.05636958758812398
[Epoch 10, Batch 1300] loss: 0.046977436356246474
[Epoch 10, Batch 1400] loss: 0.060427262276643884
[Epoch 10, Batch 1500] loss: 0.07921642749337479
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0684
Validation Accuracy: 0.9799
Overfitting: 0.0684
[Epoch 11, Batch 100] loss: 0.054288037780206654
[Epoch 11, Batch 200] loss: 0.0561253375839442
[Epoch 11, Batch 300] loss: 0.05364029177231714
[Epoch 11, Batch 400] loss: 0.05583188405260444
[Epoch 11, Batch 500] loss: 0.05074743618490175
[Epoch 11, Batch 600] loss: 0.0552262081950903
[Epoch 11, Batch 700] loss: 0.052897943885764104
[Epoch 11, Batch 800] loss: 0.053833942472701894
[Epoch 11, Batch 900] loss: 0.053073389854980633
[Epoch 11, Batch 1000] loss: 0.04865315063856542
[Epoch 11, Batch 1100] loss: 0.05720163871766999
[Epoch 11, Batch 1200] loss: 0.04321783587685786
[Epoch 11, Batch 1300] loss: 0.04877906913054176
[Epoch 11, Batch 1400] loss: 0.06266611489118076
[Epoch 11, Batch 1500] loss: 0.06274526938097552
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0654
Validation Accuracy: 0.9812
Overfitting: 0.0654
Early stopping epoch 11 for trial 6. Moving to next fold.
Fold 3 validation loss: 0.0654
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.300946600437164
[Epoch 1, Batch 200] loss: 2.2894809293746947
[Epoch 1, Batch 300] loss: 2.2780007123947144
[Epoch 1, Batch 400] loss: 2.2568077063560485
[Epoch 1, Batch 500] loss: 2.220036954879761
[Epoch 1, Batch 600] loss: 2.1400925087928773
[Epoch 1, Batch 700] loss: 1.9187337386608123
[Epoch 1, Batch 800] loss: 1.400032125711441
[Epoch 1, Batch 900] loss: 0.8939328175783158
[Epoch 1, Batch 1000] loss: 0.6651828640699387
[Epoch 1, Batch 1100] loss: 0.5059306508302689
[Epoch 1, Batch 1200] loss: 0.4588976803421974
[Epoch 1, Batch 1300] loss: 0.40004037648439406
[Epoch 1, Batch 1400] loss: 0.3644038576632738
[Epoch 1, Batch 1500] loss: 0.3478951898962259
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3357
Validation Accuracy: 0.9020
Overfitting: 0.3357
[Epoch 2, Batch 100] loss: 0.31181137561798095
[Epoch 2, Batch 200] loss: 0.3057640491425991
[Epoch 2, Batch 300] loss: 0.30197511821985246
[Epoch 2, Batch 400] loss: 0.2812102032452822
[Epoch 2, Batch 500] loss: 0.2705546274036169
[Epoch 2, Batch 600] loss: 0.2345025158673525
[Epoch 2, Batch 700] loss: 0.22784400530159474
[Epoch 2, Batch 800] loss: 0.24126476112753154
[Epoch 2, Batch 900] loss: 0.21519621200859546
[Epoch 2, Batch 1000] loss: 0.2218204817175865
[Epoch 2, Batch 1100] loss: 0.210344810038805
[Epoch 2, Batch 1200] loss: 0.2064387041144073
[Epoch 2, Batch 1300] loss: 0.1783374335244298
[Epoch 2, Batch 1400] loss: 0.18829827604815363
[Epoch 2, Batch 1500] loss: 0.18972532473504544
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1697
Validation Accuracy: 0.9477
Overfitting: 0.1697
[Epoch 3, Batch 100] loss: 0.16827326675876975
[Epoch 3, Batch 200] loss: 0.15144905232824385
[Epoch 3, Batch 300] loss: 0.17321681644767523
[Epoch 3, Batch 400] loss: 0.16253591421991587
[Epoch 3, Batch 500] loss: 0.15862561708316206
[Epoch 3, Batch 600] loss: 0.15365384876728058
[Epoch 3, Batch 700] loss: 0.14313070282340049
[Epoch 3, Batch 800] loss: 0.15664276240393518
[Epoch 3, Batch 900] loss: 0.14647005785256625
[Epoch 3, Batch 1000] loss: 0.14520821928977967
[Epoch 3, Batch 1100] loss: 0.1558009607065469
[Epoch 3, Batch 1200] loss: 0.1288476705364883
[Epoch 3, Batch 1300] loss: 0.1320966328214854
[Epoch 3, Batch 1400] loss: 0.13385393558070063
[Epoch 3, Batch 1500] loss: 0.1369444255437702
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1310
Validation Accuracy: 0.9601
Overfitting: 0.1310
[Epoch 4, Batch 100] loss: 0.12263118140399457
[Epoch 4, Batch 200] loss: 0.12009027367457747
[Epoch 4, Batch 300] loss: 0.12317605729214848
[Epoch 4, Batch 400] loss: 0.11151304089929909
[Epoch 4, Batch 500] loss: 0.11640633699018509
[Epoch 4, Batch 600] loss: 0.11622648918069899
[Epoch 4, Batch 700] loss: 0.10916994682513177
[Epoch 4, Batch 800] loss: 0.1281602493999526
[Epoch 4, Batch 900] loss: 0.13290472323074937
[Epoch 4, Batch 1000] loss: 0.10108175066299736
[Epoch 4, Batch 1100] loss: 0.1061663522478193
[Epoch 4, Batch 1200] loss: 0.10922257876954973
[Epoch 4, Batch 1300] loss: 0.10987164141610264
[Epoch 4, Batch 1400] loss: 0.11739951342344285
[Epoch 4, Batch 1500] loss: 0.10522670003585517
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0984
Validation Accuracy: 0.9692
Overfitting: 0.0984
[Epoch 5, Batch 100] loss: 0.10474288356956095
[Epoch 5, Batch 200] loss: 0.10428555085323751
[Epoch 5, Batch 300] loss: 0.0931319500040263
[Epoch 5, Batch 400] loss: 0.09818199498578906
[Epoch 5, Batch 500] loss: 0.09180410880129784
[Epoch 5, Batch 600] loss: 0.10171681995969266
[Epoch 5, Batch 700] loss: 0.08920379822608084
[Epoch 5, Batch 800] loss: 0.08678896345198155
[Epoch 5, Batch 900] loss: 0.10301066644024104
[Epoch 5, Batch 1000] loss: 0.08488768995273858
[Epoch 5, Batch 1100] loss: 0.10002116976305843
[Epoch 5, Batch 1200] loss: 0.09453282265458256
[Epoch 5, Batch 1300] loss: 0.07826608501840383
[Epoch 5, Batch 1400] loss: 0.1121814094716683
[Epoch 5, Batch 1500] loss: 0.09209544436540455
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0881
Validation Accuracy: 0.9726
Overfitting: 0.0881
[Epoch 6, Batch 100] loss: 0.08902401754632593
[Epoch 6, Batch 200] loss: 0.07620336335152388
[Epoch 6, Batch 300] loss: 0.09503038935828954
[Epoch 6, Batch 400] loss: 0.09972667902708053
[Epoch 6, Batch 500] loss: 0.09095020432025194
[Epoch 6, Batch 600] loss: 0.0734449580591172
[Epoch 6, Batch 700] loss: 0.07424978291150182
[Epoch 6, Batch 800] loss: 0.0755693032220006
[Epoch 6, Batch 900] loss: 0.08314749017823488
[Epoch 6, Batch 1000] loss: 0.08264703823253512
[Epoch 6, Batch 1100] loss: 0.09243640397209674
[Epoch 6, Batch 1200] loss: 0.08354962039622478
[Epoch 6, Batch 1300] loss: 0.08323126137256623
[Epoch 6, Batch 1400] loss: 0.06921135630924255
[Epoch 6, Batch 1500] loss: 0.07755417314823716
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0811
Validation Accuracy: 0.9743
Overfitting: 0.0811
[Epoch 7, Batch 100] loss: 0.08261733659775927
[Epoch 7, Batch 200] loss: 0.06701020437059924
[Epoch 7, Batch 300] loss: 0.07507830616319552
[Epoch 7, Batch 400] loss: 0.07390017798636109
[Epoch 7, Batch 500] loss: 0.08057197358226403
[Epoch 7, Batch 600] loss: 0.06565537629183382
[Epoch 7, Batch 700] loss: 0.08438729966059327
[Epoch 7, Batch 800] loss: 0.07517958335578441
[Epoch 7, Batch 900] loss: 0.06169361341744661
[Epoch 7, Batch 1000] loss: 0.0589099296159111
[Epoch 7, Batch 1100] loss: 0.07458971057552845
[Epoch 7, Batch 1200] loss: 0.07572610689559951
[Epoch 7, Batch 1300] loss: 0.08237924715969712
[Epoch 7, Batch 1400] loss: 0.0763860879978165
[Epoch 7, Batch 1500] loss: 0.07097984322346747
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0741
Validation Accuracy: 0.9772
Overfitting: 0.0741
[Epoch 8, Batch 100] loss: 0.0750692055746913
[Epoch 8, Batch 200] loss: 0.07424205923220142
[Epoch 8, Batch 300] loss: 0.06695180003298447
[Epoch 8, Batch 400] loss: 0.06199404513929039
[Epoch 8, Batch 500] loss: 0.06829736384563148
[Epoch 8, Batch 600] loss: 0.05335286418790929
[Epoch 8, Batch 700] loss: 0.07365092050749808
[Epoch 8, Batch 800] loss: 0.0693168964306824
[Epoch 8, Batch 900] loss: 0.06815206468105316
[Epoch 8, Batch 1000] loss: 0.06956669293344021
[Epoch 8, Batch 1100] loss: 0.05933243213454262
[Epoch 8, Batch 1200] loss: 0.05747052746475674
[Epoch 8, Batch 1300] loss: 0.06323527911910787
[Epoch 8, Batch 1400] loss: 0.05952295857248828
[Epoch 8, Batch 1500] loss: 0.06610319823492318
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0692
Validation Accuracy: 0.9776
Overfitting: 0.0692
[Epoch 9, Batch 100] loss: 0.04915537917753682
[Epoch 9, Batch 200] loss: 0.04993488143431023
[Epoch 9, Batch 300] loss: 0.06002991772955284
[Epoch 9, Batch 400] loss: 0.0729857096541673
[Epoch 9, Batch 500] loss: 0.0599732259393204
[Epoch 9, Batch 600] loss: 0.06322345351334661
[Epoch 9, Batch 700] loss: 0.0707023462408688
[Epoch 9, Batch 800] loss: 0.0752806651731953
[Epoch 9, Batch 900] loss: 0.05865441740257665
[Epoch 9, Batch 1000] loss: 0.05748428643797524
[Epoch 9, Batch 1100] loss: 0.06860575020778924
[Epoch 9, Batch 1200] loss: 0.046267599596176295
[Epoch 9, Batch 1300] loss: 0.06074812170350924
[Epoch 9, Batch 1400] loss: 0.05421078375307843
[Epoch 9, Batch 1500] loss: 0.059390986466314646
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0624
Validation Accuracy: 0.9813
Overfitting: 0.0624
Best model saved at epoch 9 with validation loss: 0.0624
[Epoch 10, Batch 100] loss: 0.04316936586983502
[Epoch 10, Batch 200] loss: 0.05019857576582581
[Epoch 10, Batch 300] loss: 0.04777482619509101
[Epoch 10, Batch 400] loss: 0.08402165555628016
[Epoch 10, Batch 500] loss: 0.06639418287668378
[Epoch 10, Batch 600] loss: 0.05331037502037361
[Epoch 10, Batch 700] loss: 0.05672281623468734
[Epoch 10, Batch 800] loss: 0.0484489049075637
[Epoch 10, Batch 900] loss: 0.05504269272321835
[Epoch 10, Batch 1000] loss: 0.05740541990497149
[Epoch 10, Batch 1100] loss: 0.05449659639969468
[Epoch 10, Batch 1200] loss: 0.052759810271672904
[Epoch 10, Batch 1300] loss: 0.05778402687981725
[Epoch 10, Batch 1400] loss: 0.05102698657021392
[Epoch 10, Batch 1500] loss: 0.05816889646346681
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9787
Overfitting: 0.0636
[Epoch 11, Batch 100] loss: 0.055731774241430686
[Epoch 11, Batch 200] loss: 0.054388805541675536
[Epoch 11, Batch 300] loss: 0.05746765776653774
[Epoch 11, Batch 400] loss: 0.043965163083048535
[Epoch 11, Batch 500] loss: 0.042793671676481605
[Epoch 11, Batch 600] loss: 0.055941428760997954
[Epoch 11, Batch 700] loss: 0.06366707335226238
[Epoch 11, Batch 800] loss: 0.05415925022913143
[Epoch 11, Batch 900] loss: 0.05130562012200244
[Epoch 11, Batch 1000] loss: 0.04107621962670237
[Epoch 11, Batch 1100] loss: 0.03814109069062397
[Epoch 11, Batch 1200] loss: 0.051768467479851095
[Epoch 11, Batch 1300] loss: 0.06098221422522329
[Epoch 11, Batch 1400] loss: 0.05461019164184108
[Epoch 11, Batch 1500] loss: 0.050369749647798015
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0604
Validation Accuracy: 0.9808
Overfitting: 0.0604
Early stopping epoch 11 for trial 6. Moving to next fold.
Fold 4 validation loss: 0.0604
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2951016926765444
[Epoch 1, Batch 200] loss: 2.2669822549819947
[Epoch 1, Batch 300] loss: 2.2050355815887452
[Epoch 1, Batch 400] loss: 2.031721261739731
[Epoch 1, Batch 500] loss: 1.4842104458808898
[Epoch 1, Batch 600] loss: 0.8450320601463318
[Epoch 1, Batch 700] loss: 0.5864878669381142
[Epoch 1, Batch 800] loss: 0.5335630314052104
[Epoch 1, Batch 900] loss: 0.4645620134472847
[Epoch 1, Batch 1000] loss: 0.41409090258181097
[Epoch 1, Batch 1100] loss: 0.4100372196733952
[Epoch 1, Batch 1200] loss: 0.35738855637609956
[Epoch 1, Batch 1300] loss: 0.3562795126438141
[Epoch 1, Batch 1400] loss: 0.3427452622354031
[Epoch 1, Batch 1500] loss: 0.2879210662841797
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2917
Validation Accuracy: 0.9083
Overfitting: 0.2917
[Epoch 2, Batch 100] loss: 0.27541000574827196
[Epoch 2, Batch 200] loss: 0.24311018779873847
[Epoch 2, Batch 300] loss: 0.31691550254821776
[Epoch 2, Batch 400] loss: 0.26625724606215956
[Epoch 2, Batch 500] loss: 0.2546803852170706
[Epoch 2, Batch 600] loss: 0.23613637499511242
[Epoch 2, Batch 700] loss: 0.2340075871348381
[Epoch 2, Batch 800] loss: 0.2293587714806199
[Epoch 2, Batch 900] loss: 0.22677952937781812
[Epoch 2, Batch 1000] loss: 0.2094193972274661
[Epoch 2, Batch 1100] loss: 0.19699473090469838
[Epoch 2, Batch 1200] loss: 0.17052589651197195
[Epoch 2, Batch 1300] loss: 0.17062661262229084
[Epoch 2, Batch 1400] loss: 0.2015217457152903
[Epoch 2, Batch 1500] loss: 0.17265650810673833
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1744
Validation Accuracy: 0.9461
Overfitting: 0.1744
[Epoch 3, Batch 100] loss: 0.16776629267260432
[Epoch 3, Batch 200] loss: 0.17224859165027737
[Epoch 3, Batch 300] loss: 0.16268577618524432
[Epoch 3, Batch 400] loss: 0.16567955097183584
[Epoch 3, Batch 500] loss: 0.15708767056465148
[Epoch 3, Batch 600] loss: 0.15398858322761952
[Epoch 3, Batch 700] loss: 0.1580800405703485
[Epoch 3, Batch 800] loss: 0.1678417750634253
[Epoch 3, Batch 900] loss: 0.15174353084526956
[Epoch 3, Batch 1000] loss: 0.13943607957102358
[Epoch 3, Batch 1100] loss: 0.1347936149779707
[Epoch 3, Batch 1200] loss: 0.14488499423488974
[Epoch 3, Batch 1300] loss: 0.14857326554134487
[Epoch 3, Batch 1400] loss: 0.13520245181396603
[Epoch 3, Batch 1500] loss: 0.13655918654054403
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1573
Validation Accuracy: 0.9534
Overfitting: 0.1573
[Epoch 4, Batch 100] loss: 0.12165771883912385
[Epoch 4, Batch 200] loss: 0.11825845933519304
[Epoch 4, Batch 300] loss: 0.11024001590907574
[Epoch 4, Batch 400] loss: 0.12315710829570889
[Epoch 4, Batch 500] loss: 0.11067518149502575
[Epoch 4, Batch 600] loss: 0.12049659060314298
[Epoch 4, Batch 700] loss: 0.13942665107548236
[Epoch 4, Batch 800] loss: 0.12147831104695797
[Epoch 4, Batch 900] loss: 0.11907306604087353
[Epoch 4, Batch 1000] loss: 0.10268026974983513
[Epoch 4, Batch 1100] loss: 0.12966252271085976
[Epoch 4, Batch 1200] loss: 0.10929291854612529
[Epoch 4, Batch 1300] loss: 0.12132305971812457
[Epoch 4, Batch 1400] loss: 0.11128658360801637
[Epoch 4, Batch 1500] loss: 0.11782190196216107
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1024
Validation Accuracy: 0.9707
Overfitting: 0.1024
[Epoch 5, Batch 100] loss: 0.10597159707918763
[Epoch 5, Batch 200] loss: 0.09518282185308635
[Epoch 5, Batch 300] loss: 0.09985871610697358
[Epoch 5, Batch 400] loss: 0.11142261179164052
[Epoch 5, Batch 500] loss: 0.09089638245292007
[Epoch 5, Batch 600] loss: 0.11749169868882746
[Epoch 5, Batch 700] loss: 0.10587234158534557
[Epoch 5, Batch 800] loss: 0.07905893798917532
[Epoch 5, Batch 900] loss: 0.1034585349354893
[Epoch 5, Batch 1000] loss: 0.08407264046836645
[Epoch 5, Batch 1100] loss: 0.08677661091089249
[Epoch 5, Batch 1200] loss: 0.09044495969079434
[Epoch 5, Batch 1300] loss: 0.08785010556690395
[Epoch 5, Batch 1400] loss: 0.08593133288901299
[Epoch 5, Batch 1500] loss: 0.12164875481277704
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1008
Validation Accuracy: 0.9707
Overfitting: 0.1008
[Epoch 6, Batch 100] loss: 0.08316994913853705
[Epoch 6, Batch 200] loss: 0.0849167076870799
[Epoch 6, Batch 300] loss: 0.0841366218146868
[Epoch 6, Batch 400] loss: 0.08747571052284911
[Epoch 6, Batch 500] loss: 0.08071627689991147
[Epoch 6, Batch 600] loss: 0.08651774597819895
[Epoch 6, Batch 700] loss: 0.08681221588049085
[Epoch 6, Batch 800] loss: 0.09183506564237177
[Epoch 6, Batch 900] loss: 0.07485305389389396
[Epoch 6, Batch 1000] loss: 0.09975381082156673
[Epoch 6, Batch 1100] loss: 0.08066304087173194
[Epoch 6, Batch 1200] loss: 0.08192598247434944
[Epoch 6, Batch 1300] loss: 0.07821406518109143
[Epoch 6, Batch 1400] loss: 0.08522580381017178
[Epoch 6, Batch 1500] loss: 0.08089861652813851
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0905
Validation Accuracy: 0.9715
Overfitting: 0.0905
[Epoch 7, Batch 100] loss: 0.07820339281111956
[Epoch 7, Batch 200] loss: 0.08359488689806312
[Epoch 7, Batch 300] loss: 0.057954327827319504
[Epoch 7, Batch 400] loss: 0.07050172357819974
[Epoch 7, Batch 500] loss: 0.0862701631197706
[Epoch 7, Batch 600] loss: 0.07309364310931414
[Epoch 7, Batch 700] loss: 0.07734053349588066
[Epoch 7, Batch 800] loss: 0.06054255115799606
[Epoch 7, Batch 900] loss: 0.07070211440091953
[Epoch 7, Batch 1000] loss: 0.08265189161757007
[Epoch 7, Batch 1100] loss: 0.0813153287069872
[Epoch 7, Batch 1200] loss: 0.07406077238265425
[Epoch 7, Batch 1300] loss: 0.08159469623118638
[Epoch 7, Batch 1400] loss: 0.07605714140459895
[Epoch 7, Batch 1500] loss: 0.0735851818753872
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0808
Validation Accuracy: 0.9749
Overfitting: 0.0808
[Epoch 8, Batch 100] loss: 0.06308060504030437
[Epoch 8, Batch 200] loss: 0.07206063259392977
[Epoch 8, Batch 300] loss: 0.06338256004499271
[Epoch 8, Batch 400] loss: 0.07336533000227063
[Epoch 8, Batch 500] loss: 0.06993142109131441
[Epoch 8, Batch 600] loss: 0.06329024862032384
[Epoch 8, Batch 700] loss: 0.06385659693973139
[Epoch 8, Batch 800] loss: 0.07548894274514169
[Epoch 8, Batch 900] loss: 0.07933402380091138
[Epoch 8, Batch 1000] loss: 0.07433225070359185
[Epoch 8, Batch 1100] loss: 0.07392680282704532
[Epoch 8, Batch 1200] loss: 0.056486540958285335
[Epoch 8, Batch 1300] loss: 0.057842075498774646
[Epoch 8, Batch 1400] loss: 0.06432722221594304
[Epoch 8, Batch 1500] loss: 0.05135955831850879
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0667
Validation Accuracy: 0.9794
Overfitting: 0.0667
[Epoch 9, Batch 100] loss: 0.06750094827497378
[Epoch 9, Batch 200] loss: 0.061809615175588986
[Epoch 9, Batch 300] loss: 0.05063291628146544
[Epoch 9, Batch 400] loss: 0.05411742396652699
[Epoch 9, Batch 500] loss: 0.06033376178704202
[Epoch 9, Batch 600] loss: 0.05609947153832764
[Epoch 9, Batch 700] loss: 0.06728721490595489
[Epoch 9, Batch 800] loss: 0.07225056846509688
[Epoch 9, Batch 900] loss: 0.05945283419336192
[Epoch 9, Batch 1000] loss: 0.06532442617928609
[Epoch 9, Batch 1100] loss: 0.061481040818616745
[Epoch 9, Batch 1200] loss: 0.05653892669128254
[Epoch 9, Batch 1300] loss: 0.05395631527411751
[Epoch 9, Batch 1400] loss: 0.06081428751116619
[Epoch 9, Batch 1500] loss: 0.05449819440953434
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0747
Validation Accuracy: 0.9771
Overfitting: 0.0747
Best model saved at epoch 9 with validation loss: 0.0747
[Epoch 10, Batch 100] loss: 0.06778101166244596
[Epoch 10, Batch 200] loss: 0.05290769264101982
[Epoch 10, Batch 300] loss: 0.05011238008970395
[Epoch 10, Batch 400] loss: 0.06284725281060673
[Epoch 10, Batch 500] loss: 0.04775901194661856
[Epoch 10, Batch 600] loss: 0.04828617704799399
[Epoch 10, Batch 700] loss: 0.04836339546134696
[Epoch 10, Batch 800] loss: 0.0610442571900785
[Epoch 10, Batch 900] loss: 0.05649892758927308
[Epoch 10, Batch 1000] loss: 0.05649504030589014
[Epoch 10, Batch 1100] loss: 0.05218615599442274
[Epoch 10, Batch 1200] loss: 0.06988455776008777
[Epoch 10, Batch 1300] loss: 0.0436377293523401
[Epoch 10, Batch 1400] loss: 0.053612672925228255
[Epoch 10, Batch 1500] loss: 0.06323776353849098
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0594
Validation Accuracy: 0.9821
Overfitting: 0.0594
[Epoch 11, Batch 100] loss: 0.05106535509345122
[Epoch 11, Batch 200] loss: 0.05692356095532887
[Epoch 11, Batch 300] loss: 0.04991582967806608
[Epoch 11, Batch 400] loss: 0.05105062476708554
[Epoch 11, Batch 500] loss: 0.05186439967015758
[Epoch 11, Batch 600] loss: 0.04329747589072212
[Epoch 11, Batch 700] loss: 0.04961350638186559
[Epoch 11, Batch 800] loss: 0.04934326986083761
[Epoch 11, Batch 900] loss: 0.05667812717205379
[Epoch 11, Batch 1000] loss: 0.056330161630176005
[Epoch 11, Batch 1100] loss: 0.04885466166422702
[Epoch 11, Batch 1200] loss: 0.047504374611889943
[Epoch 11, Batch 1300] loss: 0.05680594963254407
[Epoch 11, Batch 1400] loss: 0.04775532241794281
[Epoch 11, Batch 1500] loss: 0.043209038751665506
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0610
Validation Accuracy: 0.9813
Overfitting: 0.0610
Early stopping epoch 11 for trial 6. Moving to next fold.
Fold 5 validation loss: 0.0610
Mean validation loss across all folds for Trial 6 is 0.0634 with trial config:  l1: 128, l2: 128, lr: 0.0005, batch_size: 32
[I 2024-12-10 04:43:50,525] Trial 5 finished with value: 0.06341862833097889 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0005, 'batch_size': 32}. Best is trial 0 with value: 0.05093086766599445.

Selected Hyperparameters for Trial 7:
  l1: 256, l2: 128, lr: 0.0001, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.303898825645447
[Epoch 1, Batch 200] loss: 2.3018392634391787
[Epoch 1, Batch 300] loss: 2.2981547331809997
[Epoch 1, Batch 400] loss: 2.296270823478699
[Epoch 1, Batch 500] loss: 2.296677086353302
[Epoch 1, Batch 600] loss: 2.2924244093894957
[Epoch 1, Batch 700] loss: 2.289535360336304
**STATS for Epoch 1** : 
Average training loss: 0.1525
Average validation loss: 2.2874
Validation Accuracy: 0.1027
Overfitting: 2.1349
[Epoch 2, Batch 100] loss: 2.2854306864738465
[Epoch 2, Batch 200] loss: 2.2842369508743285
[Epoch 2, Batch 300] loss: 2.2810543298721315
[Epoch 2, Batch 400] loss: 2.276999306678772
[Epoch 2, Batch 500] loss: 2.2735844349861143
[Epoch 2, Batch 600] loss: 2.2702392745018005
[Epoch 2, Batch 700] loss: 2.265397171974182
**STATS for Epoch 2** : 
Average training loss: 0.1508
Average validation loss: 2.2590
Validation Accuracy: 0.3519
Overfitting: 2.1082
[Epoch 3, Batch 100] loss: 2.255711941719055
[Epoch 3, Batch 200] loss: 2.2497137689590456
[Epoch 3, Batch 300] loss: 2.2424878120422362
[Epoch 3, Batch 400] loss: 2.2321994733810424
[Epoch 3, Batch 500] loss: 2.221768479347229
[Epoch 3, Batch 600] loss: 2.2064526176452635
[Epoch 3, Batch 700] loss: 2.194608001708984
**STATS for Epoch 3** : 
Average training loss: 0.1454
Average validation loss: 2.1726
Validation Accuracy: 0.5243
Overfitting: 2.0272
[Epoch 4, Batch 100] loss: 2.1615330505371095
[Epoch 4, Batch 200] loss: 2.1359567856788635
[Epoch 4, Batch 300] loss: 2.100806336402893
[Epoch 4, Batch 400] loss: 2.0547306656837465
[Epoch 4, Batch 500] loss: 1.995605856180191
[Epoch 4, Batch 600] loss: 1.917205991744995
[Epoch 4, Batch 700] loss: 1.8138083350658416
**STATS for Epoch 4** : 
Average training loss: 0.1148
Average validation loss: 1.6821
Validation Accuracy: 0.7245
Overfitting: 1.5673
[Epoch 5, Batch 100] loss: 1.606933090686798
[Epoch 5, Batch 200] loss: 1.4474316728115082
[Epoch 5, Batch 300] loss: 1.2608746373653412
[Epoch 5, Batch 400] loss: 1.106846975684166
[Epoch 5, Batch 500] loss: 0.9873981541395187
[Epoch 5, Batch 600] loss: 0.8712652987241745
[Epoch 5, Batch 700] loss: 0.7921818095445633
**STATS for Epoch 5** : 
Average training loss: 0.0491
Average validation loss: 0.7116
Validation Accuracy: 0.8145
Overfitting: 0.6625
[Epoch 6, Batch 100] loss: 0.7003654387593269
[Epoch 6, Batch 200] loss: 0.6668596425652504
[Epoch 6, Batch 300] loss: 0.610288493335247
[Epoch 6, Batch 400] loss: 0.6008796662092208
[Epoch 6, Batch 500] loss: 0.5825725716352462
[Epoch 6, Batch 600] loss: 0.5244925013184547
[Epoch 6, Batch 700] loss: 0.5342676043510437
**STATS for Epoch 6** : 
Average training loss: 0.0341
Average validation loss: 0.4901
Validation Accuracy: 0.8581
Overfitting: 0.4560
[Epoch 7, Batch 100] loss: 0.5081675776839256
[Epoch 7, Batch 200] loss: 0.4882435268163681
[Epoch 7, Batch 300] loss: 0.480025389790535
[Epoch 7, Batch 400] loss: 0.46576729536056516
[Epoch 7, Batch 500] loss: 0.45872731029987335
[Epoch 7, Batch 600] loss: 0.4288298773765564
[Epoch 7, Batch 700] loss: 0.4302150397002697
**STATS for Epoch 7** : 
Average training loss: 0.0301
Average validation loss: 0.4036
Validation Accuracy: 0.8797
Overfitting: 0.3736
[Epoch 8, Batch 100] loss: 0.4172653678059578
[Epoch 8, Batch 200] loss: 0.4164627452194691
[Epoch 8, Batch 300] loss: 0.39094023540616035
[Epoch 8, Batch 400] loss: 0.3974803902208805
[Epoch 8, Batch 500] loss: 0.40234861984848974
[Epoch 8, Batch 600] loss: 0.385304134786129
[Epoch 8, Batch 700] loss: 0.37597492069005967
**STATS for Epoch 8** : 
Average training loss: 0.0259
Average validation loss: 0.3541
Validation Accuracy: 0.8942
Overfitting: 0.3282
[Epoch 9, Batch 100] loss: 0.3677390056848526
[Epoch 9, Batch 200] loss: 0.3750106234848499
[Epoch 9, Batch 300] loss: 0.3631448256224394
[Epoch 9, Batch 400] loss: 0.34878810092806817
[Epoch 9, Batch 500] loss: 0.3426990804076195
[Epoch 9, Batch 600] loss: 0.3393777497112751
[Epoch 9, Batch 700] loss: 0.34262950636446476
**STATS for Epoch 9** : 
Average training loss: 0.0223
Average validation loss: 0.3153
Validation Accuracy: 0.9048
Overfitting: 0.2930
Best model saved at epoch 9 with validation loss: 0.3153
[Epoch 10, Batch 100] loss: 0.33636210426688196
[Epoch 10, Batch 200] loss: 0.3481200709939003
[Epoch 10, Batch 300] loss: 0.32092823877930643
[Epoch 10, Batch 400] loss: 0.32078622296452525
[Epoch 10, Batch 500] loss: 0.3019953475892544
[Epoch 10, Batch 600] loss: 0.29822123527526856
[Epoch 10, Batch 700] loss: 0.31960368536412714
**STATS for Epoch 10** : 
Average training loss: 0.0198
Average validation loss: 0.2858
Validation Accuracy: 0.9166
Overfitting: 0.2661
[Epoch 11, Batch 100] loss: 0.29450932398438456
[Epoch 11, Batch 200] loss: 0.28194939859211443
[Epoch 11, Batch 300] loss: 0.3094986318051815
[Epoch 11, Batch 400] loss: 0.28308398500084875
[Epoch 11, Batch 500] loss: 0.29640212163329127
[Epoch 11, Batch 600] loss: 0.30046856284141543
[Epoch 11, Batch 700] loss: 0.2882594150304794
**STATS for Epoch 11** : 
Average training loss: 0.0190
Average validation loss: 0.2640
Validation Accuracy: 0.9223
Overfitting: 0.2449
Best model saved at epoch 11 with validation loss: 0.2640
[Epoch 12, Batch 100] loss: 0.27054650112986567
[Epoch 12, Batch 200] loss: 0.30230218172073364
[Epoch 12, Batch 300] loss: 0.28489886127412317
[Epoch 12, Batch 400] loss: 0.2494684923440218
[Epoch 12, Batch 500] loss: 0.2710659770667553
[Epoch 12, Batch 600] loss: 0.2597891903668642
[Epoch 12, Batch 700] loss: 0.2651863893121481
**STATS for Epoch 12** : 
Average training loss: 0.0173
Average validation loss: 0.2452
Validation Accuracy: 0.9285
Overfitting: 0.2279
[Epoch 13, Batch 100] loss: 0.26649217426776883
[Epoch 13, Batch 200] loss: 0.2554767023772001
[Epoch 13, Batch 300] loss: 0.25944249629974364
[Epoch 13, Batch 400] loss: 0.24762026853859426
[Epoch 13, Batch 500] loss: 0.2518825636804104
[Epoch 13, Batch 600] loss: 0.24209902331233024
[Epoch 13, Batch 700] loss: 0.25053599998354914
**STATS for Epoch 13** : 
Average training loss: 0.0162
Average validation loss: 0.2275
Validation Accuracy: 0.9327
Overfitting: 0.2113
Best model saved at epoch 13 with validation loss: 0.2275
[Epoch 14, Batch 100] loss: 0.2314471733570099
[Epoch 14, Batch 200] loss: 0.24466676361858844
[Epoch 14, Batch 300] loss: 0.23709443863481283
[Epoch 14, Batch 400] loss: 0.2577764807641506
[Epoch 14, Batch 500] loss: 0.22306126479059457
[Epoch 14, Batch 600] loss: 0.2317632508277893
[Epoch 14, Batch 700] loss: 0.24151433855295182
**STATS for Epoch 14** : 
Average training loss: 0.0147
Average validation loss: 0.2150
Validation Accuracy: 0.9362
Overfitting: 0.2003
[Epoch 15, Batch 100] loss: 0.24278971895575524
[Epoch 15, Batch 200] loss: 0.22244453877210618
[Epoch 15, Batch 300] loss: 0.21901491060853004
[Epoch 15, Batch 400] loss: 0.22455923683941365
[Epoch 15, Batch 500] loss: 0.21009251933544873
[Epoch 15, Batch 600] loss: 0.2275245140492916
[Epoch 15, Batch 700] loss: 0.2114274224638939
**STATS for Epoch 15** : 
Average training loss: 0.0151
Average validation loss: 0.2023
Validation Accuracy: 0.9409
Overfitting: 0.1872
Early stopping epoch 15 for trial 7. Moving to next fold.
Fold 1 validation loss: 0.2023
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.306439573764801
[Epoch 1, Batch 200] loss: 2.302993068695068
[Epoch 1, Batch 300] loss: 2.298815462589264
[Epoch 1, Batch 400] loss: 2.2945815825462343
[Epoch 1, Batch 500] loss: 2.2902904462814333
[Epoch 1, Batch 600] loss: 2.2874109816551207
[Epoch 1, Batch 700] loss: 2.2843781518936157
**STATS for Epoch 1** : 
Average training loss: 0.1519
Average validation loss: 2.2779
Validation Accuracy: 0.1945
Overfitting: 2.1260
[Epoch 2, Batch 100] loss: 2.2761754155158997
[Epoch 2, Batch 200] loss: 2.2702584767341616
[Epoch 2, Batch 300] loss: 2.2656722259521485
[Epoch 2, Batch 400] loss: 2.2590986824035646
[Epoch 2, Batch 500] loss: 2.248321924209595
[Epoch 2, Batch 600] loss: 2.2403302788734436
[Epoch 2, Batch 700] loss: 2.230955510139465
**STATS for Epoch 2** : 
Average training loss: 0.1480
Average validation loss: 2.2175
Validation Accuracy: 0.2375
Overfitting: 2.0695
[Epoch 3, Batch 100] loss: 2.214049437046051
[Epoch 3, Batch 200] loss: 2.1928588461875917
[Epoch 3, Batch 300] loss: 2.176203112602234
[Epoch 3, Batch 400] loss: 2.152268371582031
[Epoch 3, Batch 500] loss: 2.1190515255928037
[Epoch 3, Batch 600] loss: 2.077197892665863
[Epoch 3, Batch 700] loss: 2.0296936058998107
**STATS for Epoch 3** : 
Average training loss: 0.1322
Average validation loss: 1.9667
Validation Accuracy: 0.4258
Overfitting: 1.8345
[Epoch 4, Batch 100] loss: 1.931253708600998
[Epoch 4, Batch 200] loss: 1.8329984903335572
[Epoch 4, Batch 300] loss: 1.7317797875404357
[Epoch 4, Batch 400] loss: 1.6116047239303588
[Epoch 4, Batch 500] loss: 1.4578692424297333
[Epoch 4, Batch 600] loss: 1.3096608638763427
[Epoch 4, Batch 700] loss: 1.1667093515396119
**STATS for Epoch 4** : 
Average training loss: 0.0710
Average validation loss: 1.0539
Validation Accuracy: 0.7335
Overfitting: 0.9828
[Epoch 5, Batch 100] loss: 1.0069975697994231
[Epoch 5, Batch 200] loss: 0.8873293113708496
[Epoch 5, Batch 300] loss: 0.8032710212469101
[Epoch 5, Batch 400] loss: 0.7557531535625458
[Epoch 5, Batch 500] loss: 0.7094933244585991
[Epoch 5, Batch 600] loss: 0.6592873972654343
[Epoch 5, Batch 700] loss: 0.6208137986063957
**STATS for Epoch 5** : 
Average training loss: 0.0401
Average validation loss: 0.6137
Validation Accuracy: 0.8232
Overfitting: 0.5737
[Epoch 6, Batch 100] loss: 0.5802088892459869
[Epoch 6, Batch 200] loss: 0.5610076999664306
[Epoch 6, Batch 300] loss: 0.5417682418227195
[Epoch 6, Batch 400] loss: 0.5393964567780495
[Epoch 6, Batch 500] loss: 0.49880931317806243
[Epoch 6, Batch 600] loss: 0.49707176834344863
[Epoch 6, Batch 700] loss: 0.479727218747139
**STATS for Epoch 6** : 
Average training loss: 0.0310
Average validation loss: 0.4870
Validation Accuracy: 0.8576
Overfitting: 0.4560
[Epoch 7, Batch 100] loss: 0.46355211108922956
[Epoch 7, Batch 200] loss: 0.451056105196476
[Epoch 7, Batch 300] loss: 0.4315972538292408
[Epoch 7, Batch 400] loss: 0.44629566356539724
[Epoch 7, Batch 500] loss: 0.4215010114014149
[Epoch 7, Batch 600] loss: 0.4278717924654484
[Epoch 7, Batch 700] loss: 0.4107602429389954
**STATS for Epoch 7** : 
Average training loss: 0.0272
Average validation loss: 0.4266
Validation Accuracy: 0.8732
Overfitting: 0.3994
[Epoch 8, Batch 100] loss: 0.4161791789531708
[Epoch 8, Batch 200] loss: 0.392529369443655
[Epoch 8, Batch 300] loss: 0.3976400962471962
[Epoch 8, Batch 400] loss: 0.38641954377293586
[Epoch 8, Batch 500] loss: 0.3684079709649086
[Epoch 8, Batch 600] loss: 0.3634773571789265
[Epoch 8, Batch 700] loss: 0.3509078270196915
**STATS for Epoch 8** : 
Average training loss: 0.0243
Average validation loss: 0.3797
Validation Accuracy: 0.8874
Overfitting: 0.3554
[Epoch 9, Batch 100] loss: 0.35854200638830663
[Epoch 9, Batch 200] loss: 0.3647294655442238
[Epoch 9, Batch 300] loss: 0.37001893773674965
[Epoch 9, Batch 400] loss: 0.3545850500464439
[Epoch 9, Batch 500] loss: 0.3193793098628521
[Epoch 9, Batch 600] loss: 0.3147671864926815
[Epoch 9, Batch 700] loss: 0.3278068698942661
**STATS for Epoch 9** : 
Average training loss: 0.0208
Average validation loss: 0.3451
Validation Accuracy: 0.8976
Overfitting: 0.3243
Best model saved at epoch 9 with validation loss: 0.3451
[Epoch 10, Batch 100] loss: 0.32624447233974935
[Epoch 10, Batch 200] loss: 0.32961603105068205
[Epoch 10, Batch 300] loss: 0.31862688273191453
[Epoch 10, Batch 400] loss: 0.3025512655079365
[Epoch 10, Batch 500] loss: 0.3087467271089554
[Epoch 10, Batch 600] loss: 0.31050320237874984
[Epoch 10, Batch 700] loss: 0.2951072582602501
**STATS for Epoch 10** : 
Average training loss: 0.0195
Average validation loss: 0.3162
Validation Accuracy: 0.9044
Overfitting: 0.2967
[Epoch 11, Batch 100] loss: 0.30994802951812744
[Epoch 11, Batch 200] loss: 0.28645931169390676
[Epoch 11, Batch 300] loss: 0.2947749887406826
[Epoch 11, Batch 400] loss: 0.2892351695150137
[Epoch 11, Batch 500] loss: 0.28365779638290406
[Epoch 11, Batch 600] loss: 0.2719121881574392
[Epoch 11, Batch 700] loss: 0.2815341201424599
**STATS for Epoch 11** : 
Average training loss: 0.0185
Average validation loss: 0.2981
Validation Accuracy: 0.9087
Overfitting: 0.2796
Best model saved at epoch 11 with validation loss: 0.2981
[Epoch 12, Batch 100] loss: 0.26805643990635875
[Epoch 12, Batch 200] loss: 0.2792437162995338
[Epoch 12, Batch 300] loss: 0.2786343252658844
[Epoch 12, Batch 400] loss: 0.2625199005007744
[Epoch 12, Batch 500] loss: 0.26631598845124244
[Epoch 12, Batch 600] loss: 0.2741048690676689
[Epoch 12, Batch 700] loss: 0.2471763449907303
**STATS for Epoch 12** : 
Average training loss: 0.0159
Average validation loss: 0.2745
Validation Accuracy: 0.9171
Overfitting: 0.2586
[Epoch 13, Batch 100] loss: 0.2526793721318245
[Epoch 13, Batch 200] loss: 0.2456228317320347
[Epoch 13, Batch 300] loss: 0.24621007055044175
[Epoch 13, Batch 400] loss: 0.25255959600210187
[Epoch 13, Batch 500] loss: 0.2578576534241438
[Epoch 13, Batch 600] loss: 0.2355510915070772
[Epoch 13, Batch 700] loss: 0.2518757224082947
**STATS for Epoch 13** : 
Average training loss: 0.0153
Average validation loss: 0.2562
Validation Accuracy: 0.9233
Overfitting: 0.2409
Best model saved at epoch 13 with validation loss: 0.2562
[Epoch 14, Batch 100] loss: 0.24507711172103883
[Epoch 14, Batch 200] loss: 0.23639011867344378
[Epoch 14, Batch 300] loss: 0.2316860604286194
[Epoch 14, Batch 400] loss: 0.23586002260446548
[Epoch 14, Batch 500] loss: 0.22523057974874974
[Epoch 14, Batch 600] loss: 0.22543308641761542
[Epoch 14, Batch 700] loss: 0.23085788436233998
**STATS for Epoch 14** : 
Average training loss: 0.0136
Average validation loss: 0.2425
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 13 is already reported.
  warnings.warn(
Validation Accuracy: 0.9269
Overfitting: 0.2288
[Epoch 15, Batch 100] loss: 0.21750616498291492
[Epoch 15, Batch 200] loss: 0.2196725109219551
[Epoch 15, Batch 300] loss: 0.2186544232815504
[Epoch 15, Batch 400] loss: 0.2063937257602811
[Epoch 15, Batch 500] loss: 0.23547954827547074
[Epoch 15, Batch 600] loss: 0.21019268214702605
[Epoch 15, Batch 700] loss: 0.2136862797662616
**STATS for Epoch 15** : 
Average training loss: 0.0142
Average validation loss: 0.2305
Validation Accuracy: 0.9314
Overfitting: 0.2163
Early stopping epoch 15 for trial 7. Moving to next fold.
Fold 2 validation loss: 0.2305
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 14 is already reported.
  warnings.warn(
[Epoch 1, Batch 100] loss: 2.3052613306045533
[Epoch 1, Batch 200] loss: 2.3018783140182495
[Epoch 1, Batch 300] loss: 2.2963839673995974
[Epoch 1, Batch 400] loss: 2.292587239742279
[Epoch 1, Batch 500] loss: 2.2883812260627745
[Epoch 1, Batch 600] loss: 2.2872690391540527
[Epoch 1, Batch 700] loss: 2.2818114614486693
**STATS for Epoch 1** : 
Average training loss: 0.1519
Average validation loss: 2.2774
Validation Accuracy: 0.1767
Overfitting: 2.1255
[Epoch 2, Batch 100] loss: 2.274614055156708
[Epoch 2, Batch 200] loss: 2.2680735635757445
[Epoch 2, Batch 300] loss: 2.2628996920585633
[Epoch 2, Batch 400] loss: 2.2540770196914672
[Epoch 2, Batch 500] loss: 2.2481449317932127
[Epoch 2, Batch 600] loss: 2.239997375011444
[Epoch 2, Batch 700] loss: 2.225955033302307
**STATS for Epoch 2** : 
Average training loss: 0.1477
Average validation loss: 2.2131
Validation Accuracy: 0.2283
Overfitting: 2.0654
[Epoch 3, Batch 100] loss: 2.204751741886139
[Epoch 3, Batch 200] loss: 2.185510241985321
[Epoch 3, Batch 300] loss: 2.1629738450050353
[Epoch 3, Batch 400] loss: 2.1404385948181153
[Epoch 3, Batch 500] loss: 2.099415535926819
[Epoch 3, Batch 600] loss: 2.0517905700206756
[Epoch 3, Batch 700] loss: 1.9962181127071381
**STATS for Epoch 3** : 
Average training loss: 0.1286
Average validation loss: 1.9060
Validation Accuracy: 0.6016
Overfitting: 1.7775
[Epoch 4, Batch 100] loss: 1.8625974309444429
[Epoch 4, Batch 200] loss: 1.7357967472076417
[Epoch 4, Batch 300] loss: 1.5855364942550658
[Epoch 4, Batch 400] loss: 1.4356058883666991
[Epoch 4, Batch 500] loss: 1.2566035294532776
[Epoch 4, Batch 600] loss: 1.0945985233783722
[Epoch 4, Batch 700] loss: 0.9766268557310105
**STATS for Epoch 4** : 
Average training loss: 0.0603
Average validation loss: 0.8525
Validation Accuracy: 0.7862
Overfitting: 0.7922
[Epoch 5, Batch 100] loss: 0.8287037199735642
[Epoch 5, Batch 200] loss: 0.7610030961036682
[Epoch 5, Batch 300] loss: 0.6976154381036759
[Epoch 5, Batch 400] loss: 0.6647793012857437
[Epoch 5, Batch 500] loss: 0.6212182402610779
[Epoch 5, Batch 600] loss: 0.6105402371287346
[Epoch 5, Batch 700] loss: 0.5754058447480201
**STATS for Epoch 5** : 
Average training loss: 0.0375
Average validation loss: 0.5455
Validation Accuracy: 0.8411
Overfitting: 0.5081
[Epoch 6, Batch 100] loss: 0.5264426988363266
[Epoch 6, Batch 200] loss: 0.5352324169874191
[Epoch 6, Batch 300] loss: 0.4969968613982201
[Epoch 6, Batch 400] loss: 0.4808966362476349
[Epoch 6, Batch 500] loss: 0.49321801990270614
[Epoch 6, Batch 600] loss: 0.5007512587308883
[Epoch 6, Batch 700] loss: 0.48880556523799895
**STATS for Epoch 6** : 
Average training loss: 0.0302
Average validation loss: 0.4470
Validation Accuracy: 0.8683
Overfitting: 0.4168
[Epoch 7, Batch 100] loss: 0.44682657182216645
[Epoch 7, Batch 200] loss: 0.44139634355902674
[Epoch 7, Batch 300] loss: 0.4282485371828079
[Epoch 7, Batch 400] loss: 0.43491641119122504
[Epoch 7, Batch 500] loss: 0.42661049231886866
[Epoch 7, Batch 600] loss: 0.41428521677851676
[Epoch 7, Batch 700] loss: 0.40851319923996926
**STATS for Epoch 7** : 
Average training loss: 0.0274
Average validation loss: 0.3963
Validation Accuracy: 0.8811
Overfitting: 0.3689
[Epoch 8, Batch 100] loss: 0.3991048313677311
[Epoch 8, Batch 200] loss: 0.3810348929464817
[Epoch 8, Batch 300] loss: 0.3734880667924881
[Epoch 8, Batch 400] loss: 0.399894534945488
[Epoch 8, Batch 500] loss: 0.38453739292919636
[Epoch 8, Batch 600] loss: 0.377998950779438
[Epoch 8, Batch 700] loss: 0.38464363977313043
**STATS for Epoch 8** : 
Average training loss: 0.0230
Average validation loss: 0.3638
Validation Accuracy: 0.8908
Overfitting: 0.3407
[Epoch 9, Batch 100] loss: 0.36939697712659836
[Epoch 9, Batch 200] loss: 0.35551664873957634
[Epoch 9, Batch 300] loss: 0.3446117781102657
[Epoch 9, Batch 400] loss: 0.3505873155593872
[Epoch 9, Batch 500] loss: 0.3527491970360279
[Epoch 9, Batch 600] loss: 0.33816960602998736
[Epoch 9, Batch 700] loss: 0.34612244606018067
**STATS for Epoch 9** : 
Average training loss: 0.0231
Average validation loss: 0.3324
Validation Accuracy: 0.9005
Overfitting: 0.3093
Best model saved at epoch 9 with validation loss: 0.3324
[Epoch 10, Batch 100] loss: 0.3364544813334942
[Epoch 10, Batch 200] loss: 0.3335907608270645
[Epoch 10, Batch 300] loss: 0.3271453720331192
[Epoch 10, Batch 400] loss: 0.3147905062139034
[Epoch 10, Batch 500] loss: 0.3280023468285799
[Epoch 10, Batch 600] loss: 0.3122849504649639
[Epoch 10, Batch 700] loss: 0.324512233287096
**STATS for Epoch 10** : 
Average training loss: 0.0217
Average validation loss: 0.3217
Validation Accuracy: 0.9026
Overfitting: 0.3001
[Epoch 11, Batch 100] loss: 0.28419050440192223
[Epoch 11, Batch 200] loss: 0.3044692017883062
[Epoch 11, Batch 300] loss: 0.296913158595562
[Epoch 11, Batch 400] loss: 0.31406884372234345
[Epoch 11, Batch 500] loss: 0.31179971441626547
[Epoch 11, Batch 600] loss: 0.30005097448825835
[Epoch 11, Batch 700] loss: 0.3122589508444071
**STATS for Epoch 11** : 
Average training loss: 0.0207
Average validation loss: 0.2939
Validation Accuracy: 0.9121
Overfitting: 0.2732
Best model saved at epoch 11 with validation loss: 0.2939
[Epoch 12, Batch 100] loss: 0.28651579171419145
[Epoch 12, Batch 200] loss: 0.2927263608574867
[Epoch 12, Batch 300] loss: 0.2807226050645113
[Epoch 12, Batch 400] loss: 0.2722477392107248
[Epoch 12, Batch 500] loss: 0.29646540716290476
[Epoch 12, Batch 600] loss: 0.27616002701222897
[Epoch 12, Batch 700] loss: 0.30159437902271746
**STATS for Epoch 12** : 
Average training loss: 0.0173
Average validation loss: 0.2800
Validation Accuracy: 0.9156
Overfitting: 0.2627
[Epoch 13, Batch 100] loss: 0.26698848575353623
[Epoch 13, Batch 200] loss: 0.2669379853457212
[Epoch 13, Batch 300] loss: 0.2626094887405634
[Epoch 13, Batch 400] loss: 0.2727251391857862
[Epoch 13, Batch 500] loss: 0.2670116234570742
[Epoch 13, Batch 600] loss: 0.2663387744873762
[Epoch 13, Batch 700] loss: 0.27949590906500815
**STATS for Epoch 13** : 
Average training loss: 0.0173
Average validation loss: 0.2677
Validation Accuracy: 0.9224
Overfitting: 0.2504
Early stopping epoch 13 for trial 7. Moving to next fold.
Fold 3 validation loss: 0.2677
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.302804193496704
[Epoch 1, Batch 200] loss: 2.3019157075881957
[Epoch 1, Batch 300] loss: 2.3007895731925965
[Epoch 1, Batch 400] loss: 2.2991521167755127
[Epoch 1, Batch 500] loss: 2.2980310416221617
[Epoch 1, Batch 600] loss: 2.295924332141876
[Epoch 1, Batch 700] loss: 2.293340938091278
**STATS for Epoch 1** : 
Average training loss: 0.1528
Average validation loss: 2.2929
Validation Accuracy: 0.1919
Overfitting: 2.1401
[Epoch 2, Batch 100] loss: 2.291461379528046
[Epoch 2, Batch 200] loss: 2.288959107398987
[Epoch 2, Batch 300] loss: 2.286909558773041
[Epoch 2, Batch 400] loss: 2.284499819278717
[Epoch 2, Batch 500] loss: 2.2814683866500856
[Epoch 2, Batch 600] loss: 2.2784371399879455
[Epoch 2, Batch 700] loss: 2.275747456550598
**STATS for Epoch 2** : 
Average training loss: 0.1516
Average validation loss: 2.2740
Validation Accuracy: 0.2779
Overfitting: 2.1224
[Epoch 3, Batch 100] loss: 2.2710184693336486
[Epoch 3, Batch 200] loss: 2.2662865805625914
[Epoch 3, Batch 300] loss: 2.2599647092819213
[Epoch 3, Batch 400] loss: 2.2554433512687684
[Epoch 3, Batch 500] loss: 2.2519953441619873
[Epoch 3, Batch 600] loss: 2.2408178353309633
[Epoch 3, Batch 700] loss: 2.2328870272636414
**STATS for Epoch 3** : 
Average training loss: 0.1485
Average validation loss: 2.2251
Validation Accuracy: 0.3907
Overfitting: 2.0766
[Epoch 4, Batch 100] loss: 2.2160635471343992
[Epoch 4, Batch 200] loss: 2.2001482796669007
[Epoch 4, Batch 300] loss: 2.183041424751282
[Epoch 4, Batch 400] loss: 2.1597142100334166
[Epoch 4, Batch 500] loss: 2.135055341720581
[Epoch 4, Batch 600] loss: 2.0997295784950256
[Epoch 4, Batch 700] loss: 2.0487320697307587
**STATS for Epoch 4** : 
Average training loss: 0.1337
Average validation loss: 1.9962
Validation Accuracy: 0.5134
Overfitting: 1.8625
[Epoch 5, Batch 100] loss: 1.953086520433426
[Epoch 5, Batch 200] loss: 1.858246577978134
[Epoch 5, Batch 300] loss: 1.769394736289978
[Epoch 5, Batch 400] loss: 1.6486268079280852
[Epoch 5, Batch 500] loss: 1.518922837972641
[Epoch 5, Batch 600] loss: 1.3902290666103363
[Epoch 5, Batch 700] loss: 1.2762283706665039
**STATS for Epoch 5** : 
Average training loss: 0.0795
Average validation loss: 1.1738
Validation Accuracy: 0.6793
Overfitting: 1.0943
[Epoch 6, Batch 100] loss: 1.0967836004495621
[Epoch 6, Batch 200] loss: 1.0074816358089447
[Epoch 6, Batch 300] loss: 0.9450361275672913
[Epoch 6, Batch 400] loss: 0.8635430645942688
[Epoch 6, Batch 500] loss: 0.7927382338047028
[Epoch 6, Batch 600] loss: 0.7255599248409271
[Epoch 6, Batch 700] loss: 0.7012135088443756
**STATS for Epoch 6** : 
Average training loss: 0.0444
Average validation loss: 0.6714
Validation Accuracy: 0.8028
Overfitting: 0.6270
[Epoch 7, Batch 100] loss: 0.6458744680881501
[Epoch 7, Batch 200] loss: 0.5920611211657524
[Epoch 7, Batch 300] loss: 0.5683517101407051
[Epoch 7, Batch 400] loss: 0.5601459363102913
[Epoch 7, Batch 500] loss: 0.521729753613472
[Epoch 7, Batch 600] loss: 0.5203543674945831
[Epoch 7, Batch 700] loss: 0.5102034389972687
**STATS for Epoch 7** : 
Average training loss: 0.0327
Average validation loss: 0.4956
Validation Accuracy: 0.8469
Overfitting: 0.4628
[Epoch 8, Batch 100] loss: 0.46951371371746065
[Epoch 8, Batch 200] loss: 0.4717389553785324
[Epoch 8, Batch 300] loss: 0.4647885364294052
[Epoch 8, Batch 400] loss: 0.4248462747037411
[Epoch 8, Batch 500] loss: 0.4110435700416565
[Epoch 8, Batch 600] loss: 0.44164831697940826
[Epoch 8, Batch 700] loss: 0.4194671116769314
**STATS for Epoch 8** : 
Average training loss: 0.0292
Average validation loss: 0.4214
Validation Accuracy: 0.8708
Overfitting: 0.3922
[Epoch 9, Batch 100] loss: 0.399821308106184
[Epoch 9, Batch 200] loss: 0.40380616679787634
[Epoch 9, Batch 300] loss: 0.3977053855359554
[Epoch 9, Batch 400] loss: 0.38726028680801394
[Epoch 9, Batch 500] loss: 0.38645989015698434
[Epoch 9, Batch 600] loss: 0.38003890693187714
[Epoch 9, Batch 700] loss: 0.3610443660616875
**STATS for Epoch 9** : 
Average training loss: 0.0236
Average validation loss: 0.3735
Validation Accuracy: 0.8826
Overfitting: 0.3499
Best model saved at epoch 9 with validation loss: 0.3735
[Epoch 10, Batch 100] loss: 0.37958585083484647
[Epoch 10, Batch 200] loss: 0.34734835997223856
[Epoch 10, Batch 300] loss: 0.3438967254757881
[Epoch 10, Batch 400] loss: 0.347713004052639
[Epoch 10, Batch 500] loss: 0.34667790934443476
[Epoch 10, Batch 600] loss: 0.35565563559532165
[Epoch 10, Batch 700] loss: 0.3197201706469059
**STATS for Epoch 10** : 
Average training loss: 0.0224
Average validation loss: 0.3376
Validation Accuracy: 0.8936
Overfitting: 0.3152
Best model saved at epoch 10 with validation loss: 0.3376
[Epoch 11, Batch 100] loss: 0.32474056094884873
[Epoch 11, Batch 200] loss: 0.3121963474154472
[Epoch 11, Batch 300] loss: 0.33503086492419243
[Epoch 11, Batch 400] loss: 0.3226249331235886
[Epoch 11, Batch 500] loss: 0.3089305752515793
[Epoch 11, Batch 600] loss: 0.3237279996275902
[Epoch 11, Batch 700] loss: 0.31063137903809546
**STATS for Epoch 11** : 
Average training loss: 0.0195
Average validation loss: 0.3127
Validation Accuracy: 0.9020
Overfitting: 0.2931
[Epoch 12, Batch 100] loss: 0.28886948511004445
[Epoch 12, Batch 200] loss: 0.29838639065623285
[Epoch 12, Batch 300] loss: 0.2971027635037899
[Epoch 12, Batch 400] loss: 0.2913729254156351
[Epoch 12, Batch 500] loss: 0.29420862905681133
[Epoch 12, Batch 600] loss: 0.3011447797715664
[Epoch 12, Batch 700] loss: 0.2912517684698105
**STATS for Epoch 12** : 
Average training loss: 0.0183
Average validation loss: 0.2872
Validation Accuracy: 0.9082
Overfitting: 0.2689
Best model saved at epoch 12 with validation loss: 0.2872
[Epoch 13, Batch 100] loss: 0.28380387216806413
[Epoch 13, Batch 200] loss: 0.2722547140717506
[Epoch 13, Batch 300] loss: 0.2630309171229601
[Epoch 13, Batch 400] loss: 0.28797711193561554
[Epoch 13, Batch 500] loss: 0.25797898940742015
[Epoch 13, Batch 600] loss: 0.27784046575427057
[Epoch 13, Batch 700] loss: 0.2628219533711672
**STATS for Epoch 13** : 
Average training loss: 0.0188
Average validation loss: 0.2706
Validation Accuracy: 0.9148
Overfitting: 0.2518
[Epoch 14, Batch 100] loss: 0.2574902255833149
[Epoch 14, Batch 200] loss: 0.258827505633235
[Epoch 14, Batch 300] loss: 0.2510789044946432
[Epoch 14, Batch 400] loss: 0.24520545065402985
[Epoch 14, Batch 500] loss: 0.2524013751745224
[Epoch 14, Batch 600] loss: 0.25900887526571753
[Epoch 14, Batch 700] loss: 0.25971817269921305
**STATS for Epoch 14** : 
Average training loss: 0.0171
Average validation loss: 0.2542
Validation Accuracy: 0.9201
Overfitting: 0.2371
Best model saved at epoch 14 with validation loss: 0.2542
[Epoch 15, Batch 100] loss: 0.2382056463509798
[Epoch 15, Batch 200] loss: 0.2452955125272274
[Epoch 15, Batch 300] loss: 0.2462340460717678
[Epoch 15, Batch 400] loss: 0.2317056368291378
[Epoch 15, Batch 500] loss: 0.237715705037117
[Epoch 15, Batch 600] loss: 0.23816897943615914
[Epoch 15, Batch 700] loss: 0.23889815665781497
**STATS for Epoch 15** : 
Average training loss: 0.0160
Average validation loss: 0.2381
Validation Accuracy: 0.9256
Overfitting: 0.2221
[Epoch 16, Batch 100] loss: 0.21797453194856645
[Epoch 16, Batch 200] loss: 0.22093709751963617
[Epoch 16, Batch 300] loss: 0.22751936167478562
[Epoch 16, Batch 400] loss: 0.2181465219706297
[Epoch 16, Batch 500] loss: 0.2316137997061014
[Epoch 16, Batch 600] loss: 0.22780351184308528
[Epoch 16, Batch 700] loss: 0.23291506633162498
**STATS for Epoch 16** : 
Average training loss: 0.0153
Average validation loss: 0.2280
Validation Accuracy: 0.9288
Overfitting: 0.2127
Early stopping epoch 16 for trial 7. Moving to next fold.
Fold 4 validation loss: 0.2280
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.3102586531639098
[Epoch 1, Batch 200] loss: 2.3062684535980225
[Epoch 1, Batch 300] loss: 2.3042409229278564
[Epoch 1, Batch 400] loss: 2.3013880825042725
[Epoch 1, Batch 500] loss: 2.297840223312378
[Epoch 1, Batch 600] loss: 2.2955132365226745
[Epoch 1, Batch 700] loss: 2.2928706073760985
**STATS for Epoch 1** : 
Average training loss: 0.1528
Average validation loss: 2.2908
Validation Accuracy: 0.1398
Overfitting: 2.1381
[Epoch 2, Batch 100] loss: 2.2892914485931395
[Epoch 2, Batch 200] loss: 2.2854808568954468
[Epoch 2, Batch 300] loss: 2.283598072528839
[Epoch 2, Batch 400] loss: 2.281308100223541
[Epoch 2, Batch 500] loss: 2.2754732823371886
[Epoch 2, Batch 600] loss: 2.2719147181510926
[Epoch 2, Batch 700] loss: 2.2673954725265504
**STATS for Epoch 2** : 
Average training loss: 0.1509
Average validation loss: 2.2623
Validation Accuracy: 0.2699
Overfitting: 2.1114
[Epoch 3, Batch 100] loss: 2.260273427963257
[Epoch 3, Batch 200] loss: 2.253611104488373
[Epoch 3, Batch 300] loss: 2.2464731121063233
[Epoch 3, Batch 400] loss: 2.2373134422302248
[Epoch 3, Batch 500] loss: 2.2285987520217896
[Epoch 3, Batch 600] loss: 2.2169628047943117
[Epoch 3, Batch 700] loss: 2.2013645935058594
**STATS for Epoch 3** : 
Average training loss: 0.1459
Average validation loss: 2.1851
Validation Accuracy: 0.4759
Overfitting: 2.0392
[Epoch 4, Batch 100] loss: 2.178234627246857
[Epoch 4, Batch 200] loss: 2.1504915356636047
[Epoch 4, Batch 300] loss: 2.121388461589813
[Epoch 4, Batch 400] loss: 2.0793496775627136
[Epoch 4, Batch 500] loss: 2.0274749755859376
[Epoch 4, Batch 600] loss: 1.9566593754291535
[Epoch 4, Batch 700] loss: 1.8571683692932128
**STATS for Epoch 4** : 
Average training loss: 0.1186
Average validation loss: 1.7368
Validation Accuracy: 0.7277
Overfitting: 1.6182
[Epoch 5, Batch 100] loss: 1.6648460114002228
[Epoch 5, Batch 200] loss: 1.4951710164546967
[Epoch 5, Batch 300] loss: 1.318851351737976
[Epoch 5, Batch 400] loss: 1.1464541167020799
[Epoch 5, Batch 500] loss: 0.9863892829418183
[Epoch 5, Batch 600] loss: 0.8659001994132995
[Epoch 5, Batch 700] loss: 0.7882996392250061
**STATS for Epoch 5** : 
Average training loss: 0.0494
Average validation loss: 0.7177
Validation Accuracy: 0.8162
Overfitting: 0.6682
[Epoch 6, Batch 100] loss: 0.6835701012611389
[Epoch 6, Batch 200] loss: 0.6351335740089417
[Epoch 6, Batch 300] loss: 0.5934916964173317
[Epoch 6, Batch 400] loss: 0.5735278844833374
[Epoch 6, Batch 500] loss: 0.5401067674160004
[Epoch 6, Batch 600] loss: 0.5357808670401574
[Epoch 6, Batch 700] loss: 0.4966860374808311
**STATS for Epoch 6** : 
Average training loss: 0.0326
Average validation loss: 0.4912
Validation Accuracy: 0.8614
Overfitting: 0.4586
[Epoch 7, Batch 100] loss: 0.4759402567148209
[Epoch 7, Batch 200] loss: 0.46203216671943664
[Epoch 7, Batch 300] loss: 0.4482642929255962
[Epoch 7, Batch 400] loss: 0.4509856888651848
[Epoch 7, Batch 500] loss: 0.42208313196897507
[Epoch 7, Batch 600] loss: 0.41537762731313704
[Epoch 7, Batch 700] loss: 0.3986829917132855
**STATS for Epoch 7** : 
Average training loss: 0.0278
Average validation loss: 0.4055
Validation Accuracy: 0.8835
Overfitting: 0.3777
[Epoch 8, Batch 100] loss: 0.39268960878252984
[Epoch 8, Batch 200] loss: 0.39975999504327775
[Epoch 8, Batch 300] loss: 0.38732767298817633
[Epoch 8, Batch 400] loss: 0.3797887149453163
[Epoch 8, Batch 500] loss: 0.37502276882529256
[Epoch 8, Batch 600] loss: 0.34499323755502703
[Epoch 8, Batch 700] loss: 0.36876173987984656
**STATS for Epoch 8** : 
Average training loss: 0.0230
Average validation loss: 0.3586
Validation Accuracy: 0.8968
Overfitting: 0.3356
[Epoch 9, Batch 100] loss: 0.3697603714466095
[Epoch 9, Batch 200] loss: 0.35040756419301033
[Epoch 9, Batch 300] loss: 0.34253975659608843
[Epoch 9, Batch 400] loss: 0.3262210927903652
[Epoch 9, Batch 500] loss: 0.32873935349285605
[Epoch 9, Batch 600] loss: 0.32291378572583196
[Epoch 9, Batch 700] loss: 0.32396807640790937
**STATS for Epoch 9** : 
Average training loss: 0.0209
Average validation loss: 0.3241
Validation Accuracy: 0.9058
Overfitting: 0.3032
Best model saved at epoch 9 with validation loss: 0.3241
[Epoch 10, Batch 100] loss: 0.30655389368534086
[Epoch 10, Batch 200] loss: 0.30667510464787484
[Epoch 10, Batch 300] loss: 0.3169245906174183
[Epoch 10, Batch 400] loss: 0.2955998685210943
[Epoch 10, Batch 500] loss: 0.31380699783563615
[Epoch 10, Batch 600] loss: 0.3025912971049547
[Epoch 10, Batch 700] loss: 0.3078335499018431
**STATS for Epoch 10** : 
Average training loss: 0.0208
Average validation loss: 0.2983
Validation Accuracy: 0.9150
Overfitting: 0.2775
[Epoch 11, Batch 100] loss: 0.28111871317028997
[Epoch 11, Batch 200] loss: 0.2849116522073746
[Epoch 11, Batch 300] loss: 0.3035564012825489
[Epoch 11, Batch 400] loss: 0.2727363462001085
[Epoch 11, Batch 500] loss: 0.27864313527941703
[Epoch 11, Batch 600] loss: 0.2821393896639347
[Epoch 11, Batch 700] loss: 0.282713638395071
**STATS for Epoch 11** : 
Average training loss: 0.0185
Average validation loss: 0.2788
Validation Accuracy: 0.9190
Overfitting: 0.2603
Best model saved at epoch 11 with validation loss: 0.2788
[Epoch 12, Batch 100] loss: 0.2792775499075651
[Epoch 12, Batch 200] loss: 0.27793617799878123
[Epoch 12, Batch 300] loss: 0.25617428101599216
[Epoch 12, Batch 400] loss: 0.28106469243764876
[Epoch 12, Batch 500] loss: 0.25443574599921703
[Epoch 12, Batch 600] loss: 0.2701193128526211
[Epoch 12, Batch 700] loss: 0.23955979235470296
**STATS for Epoch 12** : 
Average training loss: 0.0155
Average validation loss: 0.2582
Validation Accuracy: 0.9249
Overfitting: 0.2427
[Epoch 13, Batch 100] loss: 0.24587256900966167
[Epoch 13, Batch 200] loss: 0.25746297918260097
[Epoch 13, Batch 300] loss: 0.2555956372618675
[Epoch 13, Batch 400] loss: 0.2363075166940689
[Epoch 13, Batch 500] loss: 0.24374633356928826
[Epoch 13, Batch 600] loss: 0.23602688878774644
[Epoch 13, Batch 700] loss: 0.24935136027634144
**STATS for Epoch 13** : 
Average training loss: 0.0164
Average validation loss: 0.2409
Validation Accuracy: 0.9297
Overfitting: 0.2246
Best model saved at epoch 13 with validation loss: 0.2409
[Epoch 14, Batch 100] loss: 0.2409780789911747
[Epoch 14, Batch 200] loss: 0.24896746024489402
[Epoch 14, Batch 300] loss: 0.21930874593555927
[Epoch 14, Batch 400] loss: 0.22934575460851192
[Epoch 14, Batch 500] loss: 0.2391926647722721
[Epoch 14, Batch 600] loss: 0.20795762941241264
[Epoch 14, Batch 700] loss: 0.23808115750551223
**STATS for Epoch 14** : 
Average training loss: 0.0144
Average validation loss: 0.2260
Validation Accuracy: 0.9342
Overfitting: 0.2116
[Epoch 15, Batch 100] loss: 0.21940039128065109
[Epoch 15, Batch 200] loss: 0.22908835746347905
[Epoch 15, Batch 300] loss: 0.22214496083557606
[Epoch 15, Batch 400] loss: 0.22275939896702768
[Epoch 15, Batch 500] loss: 0.21022884488105775
[Epoch 15, Batch 600] loss: 0.21740323685109617
[Epoch 15, Batch 700] loss: 0.21202257417142392
**STATS for Epoch 15** : 
Average training loss: 0.0138
Average validation loss: 0.2185
Validation Accuracy: 0.9368
Overfitting: 0.2048
Early stopping epoch 15 for trial 7. Moving to next fold.
Fold 5 validation loss: 0.2185
Mean validation loss across all folds for Trial 7 is 0.2294 with trial config:  l1: 256, l2: 128, lr: 0.0001, batch_size: 64
[I 2024-12-10 04:56:07,443] Trial 6 finished with value: 0.2294139894993698 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0001, 'batch_size': 64}. Best is trial 0 with value: 0.05093086766599445.

Selected Hyperparameters for Trial 8:
  l1: 128, l2: 64, lr: 0.0001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.305241253376007
[Epoch 1, Batch 200] loss: 2.303965392112732
[Epoch 1, Batch 300] loss: 2.3014538049697877
[Epoch 1, Batch 400] loss: 2.2996765112876894
[Epoch 1, Batch 500] loss: 2.2956839537620546
[Epoch 1, Batch 600] loss: 2.2939531326293947
[Epoch 1, Batch 700] loss: 2.2943571734428407
[Epoch 1, Batch 800] loss: 2.290975844860077
[Epoch 1, Batch 900] loss: 2.2888160371780395
[Epoch 1, Batch 1000] loss: 2.2856529211997985
[Epoch 1, Batch 1100] loss: 2.2833433055877688
[Epoch 1, Batch 1200] loss: 2.2802603697776793
[Epoch 1, Batch 1300] loss: 2.2775991201400756
[Epoch 1, Batch 1400] loss: 2.2710905337333678
[Epoch 1, Batch 1500] loss: 2.2704021382331847
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2676
Validation Accuracy: 0.2863
Overfitting: 2.2676
[Epoch 2, Batch 100] loss: 2.2643408393859863
[Epoch 2, Batch 200] loss: 2.2603320145606993
[Epoch 2, Batch 300] loss: 2.2561213994026184
[Epoch 2, Batch 400] loss: 2.2496249866485596
[Epoch 2, Batch 500] loss: 2.2414570593833925
[Epoch 2, Batch 600] loss: 2.2393611311912536
[Epoch 2, Batch 700] loss: 2.22903085231781
[Epoch 2, Batch 800] loss: 2.21622163772583
[Epoch 2, Batch 900] loss: 2.2064091753959656
[Epoch 2, Batch 1000] loss: 2.191873161792755
[Epoch 2, Batch 1100] loss: 2.1716672873497007
[Epoch 2, Batch 1200] loss: 2.156170918941498
[Epoch 2, Batch 1300] loss: 2.1256806659698486
[Epoch 2, Batch 1400] loss: 2.084135160446167
[Epoch 2, Batch 1500] loss: 2.0520968329906464
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 2.0254
Validation Accuracy: 0.5014
Overfitting: 2.0254
[Epoch 3, Batch 100] loss: 1.9965933799743651
[Epoch 3, Batch 200] loss: 1.9346245002746583
[Epoch 3, Batch 300] loss: 1.8676620435714721
[Epoch 3, Batch 400] loss: 1.7770957732200623
[Epoch 3, Batch 500] loss: 1.6716981720924378
[Epoch 3, Batch 600] loss: 1.5555241549015044
[Epoch 3, Batch 700] loss: 1.4320012652873992
[Epoch 3, Batch 800] loss: 1.2975330877304077
[Epoch 3, Batch 900] loss: 1.1684571236371994
[Epoch 3, Batch 1000] loss: 1.062895240187645
[Epoch 3, Batch 1100] loss: 0.9472442698478699
[Epoch 3, Batch 1200] loss: 0.8451348406076431
[Epoch 3, Batch 1300] loss: 0.7635023039579392
[Epoch 3, Batch 1400] loss: 0.7096693220734597
[Epoch 3, Batch 1500] loss: 0.6495412409305572
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.6268
Validation Accuracy: 0.8243
Overfitting: 0.6268
[Epoch 4, Batch 100] loss: 0.5933298015594483
[Epoch 4, Batch 200] loss: 0.5752014330029488
[Epoch 4, Batch 300] loss: 0.5702272140979767
[Epoch 4, Batch 400] loss: 0.5371209143102169
[Epoch 4, Batch 500] loss: 0.5058296531438827
[Epoch 4, Batch 600] loss: 0.5028398561477662
[Epoch 4, Batch 700] loss: 0.5171873323619366
[Epoch 4, Batch 800] loss: 0.4821624232828617
[Epoch 4, Batch 900] loss: 0.4493423624336719
[Epoch 4, Batch 1000] loss: 0.482828553467989
[Epoch 4, Batch 1100] loss: 0.42362314343452456
[Epoch 4, Batch 1200] loss: 0.41298200815916064
[Epoch 4, Batch 1300] loss: 0.3906427262723446
[Epoch 4, Batch 1400] loss: 0.4316388688981533
[Epoch 4, Batch 1500] loss: 0.4213752753287554
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3920
Validation Accuracy: 0.8828
Overfitting: 0.3920
[Epoch 5, Batch 100] loss: 0.4061748231202364
[Epoch 5, Batch 200] loss: 0.3583586387336254
[Epoch 5, Batch 300] loss: 0.41802474707365034
[Epoch 5, Batch 400] loss: 0.353871343806386
[Epoch 5, Batch 500] loss: 0.3936208176612854
[Epoch 5, Batch 600] loss: 0.3729975326359272
[Epoch 5, Batch 700] loss: 0.37512163653969766
[Epoch 5, Batch 800] loss: 0.3766463802754879
[Epoch 5, Batch 900] loss: 0.3707450890541077
[Epoch 5, Batch 1000] loss: 0.3564500457048416
[Epoch 5, Batch 1100] loss: 0.3606584247946739
[Epoch 5, Batch 1200] loss: 0.3765972964465618
[Epoch 5, Batch 1300] loss: 0.3233858912810683
[Epoch 5, Batch 1400] loss: 0.3265043359994888
[Epoch 5, Batch 1500] loss: 0.3224251617491245
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3177
Validation Accuracy: 0.9057
Overfitting: 0.3177
[Epoch 6, Batch 100] loss: 0.3177439404278994
[Epoch 6, Batch 200] loss: 0.33630291290581227
[Epoch 6, Batch 300] loss: 0.32096189364790917
[Epoch 6, Batch 400] loss: 0.31454760529100895
[Epoch 6, Batch 500] loss: 0.32682836771011353
[Epoch 6, Batch 600] loss: 0.34568489618599413
[Epoch 6, Batch 700] loss: 0.30107565768063066
[Epoch 6, Batch 800] loss: 0.30426710814237595
[Epoch 6, Batch 900] loss: 0.3033414589613676
[Epoch 6, Batch 1000] loss: 0.3109907892346382
[Epoch 6, Batch 1100] loss: 0.28118060864508154
[Epoch 6, Batch 1200] loss: 0.3143481275439262
[Epoch 6, Batch 1300] loss: 0.2999228882044554
[Epoch 6, Batch 1400] loss: 0.2949460010975599
[Epoch 6, Batch 1500] loss: 0.3035929579287767
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2804
Validation Accuracy: 0.9157
Overfitting: 0.2804
[Epoch 7, Batch 100] loss: 0.2939819625392556
[Epoch 7, Batch 200] loss: 0.28218620471656325
[Epoch 7, Batch 300] loss: 0.2927113877236843
[Epoch 7, Batch 400] loss: 0.26324193030595777
[Epoch 7, Batch 500] loss: 0.27808135610073803
[Epoch 7, Batch 600] loss: 0.2999925523996353
[Epoch 7, Batch 700] loss: 0.29270621776580813
[Epoch 7, Batch 800] loss: 0.2752859840914607
[Epoch 7, Batch 900] loss: 0.24204523872584105
[Epoch 7, Batch 1000] loss: 0.2768424707651138
[Epoch 7, Batch 1100] loss: 0.2792828267067671
[Epoch 7, Batch 1200] loss: 0.27170099508017304
[Epoch 7, Batch 1300] loss: 0.244228680357337
[Epoch 7, Batch 1400] loss: 0.26196595080196855
[Epoch 7, Batch 1500] loss: 0.23317133270204068
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2474
Validation Accuracy: 0.9257
Overfitting: 0.2474
[Epoch 8, Batch 100] loss: 0.2498683175817132
[Epoch 8, Batch 200] loss: 0.26622637443244457
[Epoch 8, Batch 300] loss: 0.2572167629748583
[Epoch 8, Batch 400] loss: 0.25511259291321037
[Epoch 8, Batch 500] loss: 0.2489251120388508
[Epoch 8, Batch 600] loss: 0.23719155628234148
[Epoch 8, Batch 700] loss: 0.24865940179675816
[Epoch 8, Batch 800] loss: 0.20648251723498107
[Epoch 8, Batch 900] loss: 0.23841259337961673
[Epoch 8, Batch 1000] loss: 0.23673957601189613
[Epoch 8, Batch 1100] loss: 0.2494268473982811
[Epoch 8, Batch 1200] loss: 0.23058946017175913
[Epoch 8, Batch 1300] loss: 0.22937326218932866
[Epoch 8, Batch 1400] loss: 0.22214456133544444
[Epoch 8, Batch 1500] loss: 0.24524259634315967
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2152
Validation Accuracy: 0.9362
Overfitting: 0.2152
[Epoch 9, Batch 100] loss: 0.2263703428953886
[Epoch 9, Batch 200] loss: 0.2189583232998848
[Epoch 9, Batch 300] loss: 0.23133602537214756
[Epoch 9, Batch 400] loss: 0.19944953825324774
[Epoch 9, Batch 500] loss: 0.20721877012401818
[Epoch 9, Batch 600] loss: 0.23258631974458693
[Epoch 9, Batch 700] loss: 0.2077598199993372
[Epoch 9, Batch 800] loss: 0.22120851691812277
[Epoch 9, Batch 900] loss: 0.21148005861788988
[Epoch 9, Batch 1000] loss: 0.21383615382015705
[Epoch 9, Batch 1100] loss: 0.2111476618424058
[Epoch 9, Batch 1200] loss: 0.20941649191081524
[Epoch 9, Batch 1300] loss: 0.20939471233636142
[Epoch 9, Batch 1400] loss: 0.20010153964161873
[Epoch 9, Batch 1500] loss: 0.2229476172849536
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1941
Validation Accuracy: 0.9432
Overfitting: 0.1941
Best model saved at epoch 9 with validation loss: 0.1941
[Epoch 10, Batch 100] loss: 0.2204361940920353
[Epoch 10, Batch 200] loss: 0.18460741624236107
[Epoch 10, Batch 300] loss: 0.21167714152485131
[Epoch 10, Batch 400] loss: 0.19191345866769552
[Epoch 10, Batch 500] loss: 0.19811547324061393
[Epoch 10, Batch 600] loss: 0.18163114711642264
[Epoch 10, Batch 700] loss: 0.1960141434893012
[Epoch 10, Batch 800] loss: 0.17140900369733572
[Epoch 10, Batch 900] loss: 0.20335119271650912
[Epoch 10, Batch 1000] loss: 0.18776700042188169
[Epoch 10, Batch 1100] loss: 0.20022317316383123
[Epoch 10, Batch 1200] loss: 0.1838869332522154
[Epoch 10, Batch 1300] loss: 0.17551506154239177
[Epoch 10, Batch 1400] loss: 0.1845572742074728
[Epoch 10, Batch 1500] loss: 0.18625835310667754
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1699
Validation Accuracy: 0.9496
Overfitting: 0.1699
[Epoch 11, Batch 100] loss: 0.17718266693875193
[Epoch 11, Batch 200] loss: 0.190454316213727
[Epoch 11, Batch 300] loss: 0.15700966654345394
[Epoch 11, Batch 400] loss: 0.1723517877794802
[Epoch 11, Batch 500] loss: 0.16618212314322592
[Epoch 11, Batch 600] loss: 0.16749096799641847
[Epoch 11, Batch 700] loss: 0.18793731996789576
[Epoch 11, Batch 800] loss: 0.17019840190187097
[Epoch 11, Batch 900] loss: 0.17869675802066923
[Epoch 11, Batch 1000] loss: 0.1632699073664844
[Epoch 11, Batch 1100] loss: 0.1754725006222725
[Epoch 11, Batch 1200] loss: 0.17034225538372993
[Epoch 11, Batch 1300] loss: 0.16439815405756236
[Epoch 11, Batch 1400] loss: 0.17969435591250657
[Epoch 11, Batch 1500] loss: 0.18177746009081602
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1563
Validation Accuracy: 0.9544
Overfitting: 0.1563
Best model saved at epoch 11 with validation loss: 0.1563
[Epoch 12, Batch 100] loss: 0.15618761733174324
[Epoch 12, Batch 200] loss: 0.17561943395063281
[Epoch 12, Batch 300] loss: 0.15968347262591123
[Epoch 12, Batch 400] loss: 0.15126940671354533
[Epoch 12, Batch 500] loss: 0.15850970389321448
[Epoch 12, Batch 600] loss: 0.15854461075738072
[Epoch 12, Batch 700] loss: 0.15789126751944424
[Epoch 12, Batch 800] loss: 0.16335842525586486
[Epoch 12, Batch 900] loss: 0.1667600435204804
[Epoch 12, Batch 1000] loss: 0.15313303818926216
[Epoch 12, Batch 1100] loss: 0.1689559311978519
[Epoch 12, Batch 1200] loss: 0.1508456108160317
[Epoch 12, Batch 1300] loss: 0.16210095262154936
[Epoch 12, Batch 1400] loss: 0.14551481056958437
[Epoch 12, Batch 1500] loss: 0.14197807740420104
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1455
Validation Accuracy: 0.9557
Overfitting: 0.1455
[Epoch 13, Batch 100] loss: 0.15147757448256016
[Epoch 13, Batch 200] loss: 0.15553167425096034
[Epoch 13, Batch 300] loss: 0.15525925474241375
[Epoch 13, Batch 400] loss: 0.14581058463081717
[Epoch 13, Batch 500] loss: 0.15203528359532356
[Epoch 13, Batch 600] loss: 0.1368826607428491
[Epoch 13, Batch 700] loss: 0.14022595282644035
[Epoch 13, Batch 800] loss: 0.14176726998761296
[Epoch 13, Batch 900] loss: 0.13864956002682446
[Epoch 13, Batch 1000] loss: 0.14584123292937876
[Epoch 13, Batch 1100] loss: 0.14185899214819073
[Epoch 13, Batch 1200] loss: 0.13774335252121092
[Epoch 13, Batch 1300] loss: 0.13984188973903655
[Epoch 13, Batch 1400] loss: 0.13281787106767295
[Epoch 13, Batch 1500] loss: 0.1722547734156251
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1393
Validation Accuracy: 0.9582
Overfitting: 0.1393
Early stopping epoch 13 for trial 8. Moving to next fold.
Fold 1 validation loss: 0.1393
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.3015109753608702
[Epoch 1, Batch 200] loss: 2.3018197512626646
[Epoch 1, Batch 300] loss: 2.298756568431854
[Epoch 1, Batch 400] loss: 2.296608769893646
[Epoch 1, Batch 500] loss: 2.296786949634552
[Epoch 1, Batch 600] loss: 2.2941646075248716
[Epoch 1, Batch 700] loss: 2.2941438961029053
[Epoch 1, Batch 800] loss: 2.2900547432899474
[Epoch 1, Batch 900] loss: 2.28958984375
[Epoch 1, Batch 1000] loss: 2.2897856068611144
[Epoch 1, Batch 1100] loss: 2.2860951948165895
[Epoch 1, Batch 1200] loss: 2.2842781281471254
[Epoch 1, Batch 1300] loss: 2.284170343875885
[Epoch 1, Batch 1400] loss: 2.2799972033500673
[Epoch 1, Batch 1500] loss: 2.278560929298401
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2764
Validation Accuracy: 0.2466
Overfitting: 2.2764
[Epoch 2, Batch 100] loss: 2.2744022250175475
[Epoch 2, Batch 200] loss: 2.2710458397865296
[Epoch 2, Batch 300] loss: 2.2678057098388673
[Epoch 2, Batch 400] loss: 2.2636283922195433
[Epoch 2, Batch 500] loss: 2.2591388463974
[Epoch 2, Batch 600] loss: 2.2537005972862243
[Epoch 2, Batch 700] loss: 2.2460131573677065
[Epoch 2, Batch 800] loss: 2.2381439876556395
[Epoch 2, Batch 900] loss: 2.2291280674934386
[Epoch 2, Batch 1000] loss: 2.2176734733581545
[Epoch 2, Batch 1100] loss: 2.205383267402649
[Epoch 2, Batch 1200] loss: 2.187829439640045
[Epoch 2, Batch 1300] loss: 2.1727356481552125
[Epoch 2, Batch 1400] loss: 2.1439710378646852
[Epoch 2, Batch 1500] loss: 2.1160984349250795
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 2.0982
Validation Accuracy: 0.4354
Overfitting: 2.0982
[Epoch 3, Batch 100] loss: 2.076287958621979
[Epoch 3, Batch 200] loss: 2.0390408504009248
[Epoch 3, Batch 300] loss: 1.9754979872703553
[Epoch 3, Batch 400] loss: 1.9022099053859711
[Epoch 3, Batch 500] loss: 1.8105462157726289
[Epoch 3, Batch 600] loss: 1.7170171773433685
[Epoch 3, Batch 700] loss: 1.5833227336406708
[Epoch 3, Batch 800] loss: 1.4536798202991486
[Epoch 3, Batch 900] loss: 1.3398866176605224
[Epoch 3, Batch 1000] loss: 1.193423753976822
[Epoch 3, Batch 1100] loss: 1.0509878319501877
[Epoch 3, Batch 1200] loss: 0.945205859541893
[Epoch 3, Batch 1300] loss: 0.8784380710124969
[Epoch 3, Batch 1400] loss: 0.8398897528648377
[Epoch 3, Batch 1500] loss: 0.759881574511528
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.7495
Validation Accuracy: 0.7896
Overfitting: 0.7495
[Epoch 4, Batch 100] loss: 0.7336842983961105
[Epoch 4, Batch 200] loss: 0.6784867429733277
[Epoch 4, Batch 300] loss: 0.652348954975605
[Epoch 4, Batch 400] loss: 0.6104785719513893
[Epoch 4, Batch 500] loss: 0.5887622931599616
[Epoch 4, Batch 600] loss: 0.5726296404004096
[Epoch 4, Batch 700] loss: 0.5430337527394294
[Epoch 4, Batch 800] loss: 0.5360128045082092
[Epoch 4, Batch 900] loss: 0.5269363924860955
[Epoch 4, Batch 1000] loss: 0.5128055383265019
[Epoch 4, Batch 1100] loss: 0.4817527498304844
[Epoch 4, Batch 1200] loss: 0.46323581635951994
[Epoch 4, Batch 1300] loss: 0.4520057637989521
[Epoch 4, Batch 1400] loss: 0.43993160881102084
[Epoch 4, Batch 1500] loss: 0.44896439716219905
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.4538
Validation Accuracy: 0.8663
Overfitting: 0.4538
[Epoch 5, Batch 100] loss: 0.4410930067300797
[Epoch 5, Batch 200] loss: 0.4222119577229023
[Epoch 5, Batch 300] loss: 0.43838205710053446
[Epoch 5, Batch 400] loss: 0.40996326468884947
[Epoch 5, Batch 500] loss: 0.4098308809101582
[Epoch 5, Batch 600] loss: 0.3960844051837921
[Epoch 5, Batch 700] loss: 0.4038278299570084
[Epoch 5, Batch 800] loss: 0.38224406719207765
[Epoch 5, Batch 900] loss: 0.3911197321861982
[Epoch 5, Batch 1000] loss: 0.37961255803704264
[Epoch 5, Batch 1100] loss: 0.3798268772661686
[Epoch 5, Batch 1200] loss: 0.3675965155661106
[Epoch 5, Batch 1300] loss: 0.35440308943390847
[Epoch 5, Batch 1400] loss: 0.35764288187026977
[Epoch 5, Batch 1500] loss: 0.3607816268503666
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3636
Validation Accuracy: 0.8942
Overfitting: 0.3636
[Epoch 6, Batch 100] loss: 0.3594194580614567
[Epoch 6, Batch 200] loss: 0.346038771122694
[Epoch 6, Batch 300] loss: 0.34942926600575447
[Epoch 6, Batch 400] loss: 0.3371593114733696
[Epoch 6, Batch 500] loss: 0.3177284990251064
[Epoch 6, Batch 600] loss: 0.33260564476251603
[Epoch 6, Batch 700] loss: 0.3437057871371508
[Epoch 6, Batch 800] loss: 0.3183516799286008
[Epoch 6, Batch 900] loss: 0.31189710058271886
[Epoch 6, Batch 1000] loss: 0.29416959136724474
[Epoch 6, Batch 1100] loss: 0.3335278666764498
[Epoch 6, Batch 1200] loss: 0.30694936215877533
[Epoch 6, Batch 1300] loss: 0.3014479748159647
[Epoch 6, Batch 1400] loss: 0.29118531595915553
[Epoch 6, Batch 1500] loss: 0.3028452317416668
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.3090
Validation Accuracy: 0.9102
Overfitting: 0.3090
[Epoch 7, Batch 100] loss: 0.2897737881541252
[Epoch 7, Batch 200] loss: 0.29764468617737294
[Epoch 7, Batch 300] loss: 0.2939063438028097
[Epoch 7, Batch 400] loss: 0.28290977224707603
[Epoch 7, Batch 500] loss: 0.28065859880298377
[Epoch 7, Batch 600] loss: 0.29321648811921475
[Epoch 7, Batch 700] loss: 0.2771053207665682
[Epoch 7, Batch 800] loss: 0.28351386852562427
[Epoch 7, Batch 900] loss: 0.2823503809422255
[Epoch 7, Batch 1000] loss: 0.2755317649245262
[Epoch 7, Batch 1100] loss: 0.283871566131711
[Epoch 7, Batch 1200] loss: 0.2605616946518421
[Epoch 7, Batch 1300] loss: 0.2552991634234786
[Epoch 7, Batch 1400] loss: 0.2647905106842518
[Epoch 7, Batch 1500] loss: 0.2569738690927625
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2718
Validation Accuracy: 0.9193
Overfitting: 0.2718
[Epoch 8, Batch 100] loss: 0.28931391060352324
[Epoch 8, Batch 200] loss: 0.2430191718041897
[Epoch 8, Batch 300] loss: 0.24731884613633157
[Epoch 8, Batch 400] loss: 0.2413560803234577
[Epoch 8, Batch 500] loss: 0.25259152088314296
[Epoch 8, Batch 600] loss: 0.25057924412190913
[Epoch 8, Batch 700] loss: 0.2328505366295576
[Epoch 8, Batch 800] loss: 0.24302664443850516
[Epoch 8, Batch 900] loss: 0.2336413623765111
[Epoch 8, Batch 1000] loss: 0.2255785407871008
[Epoch 8, Batch 1100] loss: 0.25542992535978554
[Epoch 8, Batch 1200] loss: 0.24266972813755275
[Epoch 8, Batch 1300] loss: 0.243629619628191
[Epoch 8, Batch 1400] loss: 0.2058208853006363
[Epoch 8, Batch 1500] loss: 0.25231429006904366
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2554
Validation Accuracy: 0.9243
Overfitting: 0.2554
[Epoch 9, Batch 100] loss: 0.21807592106983065
[Epoch 9, Batch 200] loss: 0.2056353710591793
[Epoch 9, Batch 300] loss: 0.22679345790296793
[Epoch 9, Batch 400] loss: 0.20550156854093074
[Epoch 9, Batch 500] loss: 0.23946081206202507
[Epoch 9, Batch 600] loss: 0.23157724760472775
[Epoch 9, Batch 700] loss: 0.236372094117105
[Epoch 9, Batch 800] loss: 0.2285825072042644
[Epoch 9, Batch 900] loss: 0.21681984912604094
[Epoch 9, Batch 1000] loss: 0.23185148579999804
[Epoch 9, Batch 1100] loss: 0.2222477501258254
[Epoch 9, Batch 1200] loss: 0.1828101683408022
[Epoch 9, Batch 1300] loss: 0.1995203134417534
[Epoch 9, Batch 1400] loss: 0.1977678089775145
[Epoch 9, Batch 1500] loss: 0.19383852634578944
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.2147
Validation Accuracy: 0.9357
Overfitting: 0.2147
Best model saved at epoch 9 with validation loss: 0.2147
[Epoch 10, Batch 100] loss: 0.20280301682651042
[Epoch 10, Batch 200] loss: 0.19747497875243425
[Epoch 10, Batch 300] loss: 0.21623617868870496
[Epoch 10, Batch 400] loss: 0.20197432808578014
[Epoch 10, Batch 500] loss: 0.18514809725806117
[Epoch 10, Batch 600] loss: 0.21155749840661883
[Epoch 10, Batch 700] loss: 0.19649832464754582
[Epoch 10, Batch 800] loss: 0.17421417636796832
[Epoch 10, Batch 900] loss: 0.200120382681489
[Epoch 10, Batch 1000] loss: 0.17921165011823179
[Epoch 10, Batch 1100] loss: 0.17487579999491573
[Epoch 10, Batch 1200] loss: 0.18493164401501416
[Epoch 10, Batch 1300] loss: 0.19243787484243513
[Epoch 10, Batch 1400] loss: 0.20867437429726124
[Epoch 10, Batch 1500] loss: 0.1726184963621199
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1989
Validation Accuracy: 0.9393
Overfitting: 0.1989
[Epoch 11, Batch 100] loss: 0.17383259488269687
[Epoch 11, Batch 200] loss: 0.18125099807046355
[Epoch 11, Batch 300] loss: 0.17416706338524818
[Epoch 11, Batch 400] loss: 0.1901271410100162
[Epoch 11, Batch 500] loss: 0.1777750768698752
[Epoch 11, Batch 600] loss: 0.18233395259827376
[Epoch 11, Batch 700] loss: 0.1653118879906833
[Epoch 11, Batch 800] loss: 0.1778873276337981
[Epoch 11, Batch 900] loss: 0.16250245874747635
[Epoch 11, Batch 1000] loss: 0.18491331931203603
[Epoch 11, Batch 1100] loss: 0.16572995375841856
[Epoch 11, Batch 1200] loss: 0.1756015600450337
[Epoch 11, Batch 1300] loss: 0.17208110945299268
[Epoch 11, Batch 1400] loss: 0.18743223898112774
[Epoch 11, Batch 1500] loss: 0.14876916382461786
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1804
Validation Accuracy: 0.9455
Overfitting: 0.1804
Best model saved at epoch 11 with validation loss: 0.1804
[Epoch 12, Batch 100] loss: 0.15479262940585614
[Epoch 12, Batch 200] loss: 0.15715979505330324
[Epoch 12, Batch 300] loss: 0.16436826266348362
[Epoch 12, Batch 400] loss: 0.15535872180014848
[Epoch 12, Batch 500] loss: 0.1603658297471702
[Epoch 12, Batch 600] loss: 0.14297099504619837
[Epoch 12, Batch 700] loss: 0.15821369860321283
[Epoch 12, Batch 800] loss: 0.17265538338571787
[Epoch 12, Batch 900] loss: 0.18328166350722314
[Epoch 12, Batch 1000] loss: 0.16006061853840947
[Epoch 12, Batch 1100] loss: 0.1501753378100693
[Epoch 12, Batch 1200] loss: 0.17236554289236664
[Epoch 12, Batch 1300] loss: 0.15728532372042536
[Epoch 12, Batch 1400] loss: 0.16309513345360757
[Epoch 12, Batch 1500] loss: 0.14762558843940496
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1693
Validation Accuracy: 0.9491
Overfitting: 0.1693
[Epoch 13, Batch 100] loss: 0.15840993857011199
[Epoch 13, Batch 200] loss: 0.14559440637007356
[Epoch 13, Batch 300] loss: 0.1556901482306421
[Epoch 13, Batch 400] loss: 0.15786700826138259
[Epoch 13, Batch 500] loss: 0.14228313772007822
[Epoch 13, Batch 600] loss: 0.15410435754805804
[Epoch 13, Batch 700] loss: 0.14872348997741938
[Epoch 13, Batch 800] loss: 0.14657132435590028
[Epoch 13, Batch 900] loss: 0.12704753873869776
[Epoch 13, Batch 1000] loss: 0.15456769548356533
[Epoch 13, Batch 1100] loss: 0.14425396239385008
[Epoch 13, Batch 1200] loss: 0.144912241268903
[Epoch 13, Batch 1300] loss: 0.15478604004718363
[Epoch 13, Batch 1400] loss: 0.12709342662245035
[Epoch 13, Batch 1500] loss: 0.1566870363522321
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1599
Validation Accuracy: 0.9513
Overfitting: 0.1599
Early stopping epoch 13 for trial 8. Moving to next fold.
Fold 2 validation loss: 0.1599
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3047301173210144
[Epoch 1, Batch 200] loss: 2.301572721004486
[Epoch 1, Batch 300] loss: 2.2986500120162963
[Epoch 1, Batch 400] loss: 2.297351648807526
[Epoch 1, Batch 500] loss: 2.291680908203125
[Epoch 1, Batch 600] loss: 2.2915360355377197
[Epoch 1, Batch 700] loss: 2.286066825389862
[Epoch 1, Batch 800] loss: 2.2855003809928895
[Epoch 1, Batch 900] loss: 2.2811801719665525
[Epoch 1, Batch 1000] loss: 2.2781910824775697
[Epoch 1, Batch 1100] loss: 2.273461813926697
[Epoch 1, Batch 1200] loss: 2.270955033302307
[Epoch 1, Batch 1300] loss: 2.2648580074310303
[Epoch 1, Batch 1400] loss: 2.2578492760658264
[Epoch 1, Batch 1500] loss: 2.252166488170624
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2490
Validation Accuracy: 0.2997
Overfitting: 2.2490
[Epoch 2, Batch 100] loss: 2.247126820087433
[Epoch 2, Batch 200] loss: 2.2354391503334043
[Epoch 2, Batch 300] loss: 2.229925262928009
[Epoch 2, Batch 400] loss: 2.213309087753296
[Epoch 2, Batch 500] loss: 2.202595684528351
[Epoch 2, Batch 600] loss: 2.184698441028595
[Epoch 2, Batch 700] loss: 2.1632525873184205
[Epoch 2, Batch 800] loss: 2.1388249611854553
[Epoch 2, Batch 900] loss: 2.1071742606163024
[Epoch 2, Batch 1000] loss: 2.071291197538376
[Epoch 2, Batch 1100] loss: 2.0220475709438324
[Epoch 2, Batch 1200] loss: 1.9597150576114655
[Epoch 2, Batch 1300] loss: 1.8832613015174866
[Epoch 2, Batch 1400] loss: 1.790522518157959
[Epoch 2, Batch 1500] loss: 1.6837875902652741
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.6445
Validation Accuracy: 0.5767
Overfitting: 1.6445
[Epoch 3, Batch 100] loss: 1.6047847867012024
[Epoch 3, Batch 200] loss: 1.4832567977905273
[Epoch 3, Batch 300] loss: 1.3522065365314484
[Epoch 3, Batch 400] loss: 1.2131056010723114
[Epoch 3, Batch 500] loss: 1.1008703297376632
[Epoch 3, Batch 600] loss: 0.984537529349327
[Epoch 3, Batch 700] loss: 0.8984495794773102
[Epoch 3, Batch 800] loss: 0.8239851754903793
[Epoch 3, Batch 900] loss: 0.7783206862211227
[Epoch 3, Batch 1000] loss: 0.7189649790525436
[Epoch 3, Batch 1100] loss: 0.6661860108375549
[Epoch 3, Batch 1200] loss: 0.6570447525382042
[Epoch 3, Batch 1300] loss: 0.6049514463543892
[Epoch 3, Batch 1400] loss: 0.5612287093698979
[Epoch 3, Batch 1500] loss: 0.5787646785378456
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.5444
Validation Accuracy: 0.8358
Overfitting: 0.5444
[Epoch 4, Batch 100] loss: 0.5443735155463219
[Epoch 4, Batch 200] loss: 0.5102210319042206
[Epoch 4, Batch 300] loss: 0.5092652660608291
[Epoch 4, Batch 400] loss: 0.4943627795577049
[Epoch 4, Batch 500] loss: 0.46210236236453056
[Epoch 4, Batch 600] loss: 0.4669106265902519
[Epoch 4, Batch 700] loss: 0.48763633012771607
[Epoch 4, Batch 800] loss: 0.46704927921295164
[Epoch 4, Batch 900] loss: 0.42618280187249186
[Epoch 4, Batch 1000] loss: 0.4447023229300976
[Epoch 4, Batch 1100] loss: 0.4504426933825016
[Epoch 4, Batch 1200] loss: 0.42372403889894483
[Epoch 4, Batch 1300] loss: 0.4262829631567001
[Epoch 4, Batch 1400] loss: 0.411904913187027
[Epoch 4, Batch 1500] loss: 0.39662433132529257
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3905
Validation Accuracy: 0.8862
Overfitting: 0.3905
[Epoch 5, Batch 100] loss: 0.38880017325282096
[Epoch 5, Batch 200] loss: 0.3918578681349754
[Epoch 5, Batch 300] loss: 0.3851221764087677
[Epoch 5, Batch 400] loss: 0.3684976887702942
[Epoch 5, Batch 500] loss: 0.39882945001125336
[Epoch 5, Batch 600] loss: 0.35975321173667907
[Epoch 5, Batch 700] loss: 0.36020608685910704
[Epoch 5, Batch 800] loss: 0.3713919098675251
[Epoch 5, Batch 900] loss: 0.3568764764815569
[Epoch 5, Batch 1000] loss: 0.3652486478537321
[Epoch 5, Batch 1100] loss: 0.3622006440907717
[Epoch 5, Batch 1200] loss: 0.3607415626943111
[Epoch 5, Batch 1300] loss: 0.33809712149202825
[Epoch 5, Batch 1400] loss: 0.3306340618431568
[Epoch 5, Batch 1500] loss: 0.3405592275410891
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3288
Validation Accuracy: 0.9062
Overfitting: 0.3288
[Epoch 6, Batch 100] loss: 0.3162629722058773
[Epoch 6, Batch 200] loss: 0.31144423186779024
[Epoch 6, Batch 300] loss: 0.3421252416819334
[Epoch 6, Batch 400] loss: 0.328071563616395
[Epoch 6, Batch 500] loss: 0.29496129784733055
[Epoch 6, Batch 600] loss: 0.3106155301630497
[Epoch 6, Batch 700] loss: 0.3111833820864558
[Epoch 6, Batch 800] loss: 0.31689169885590673
[Epoch 6, Batch 900] loss: 0.29979645378887654
[Epoch 6, Batch 1000] loss: 0.2903779902309179
[Epoch 6, Batch 1100] loss: 0.30476680167019365
[Epoch 6, Batch 1200] loss: 0.2917670999467373
[Epoch 6, Batch 1300] loss: 0.3147627894207835
[Epoch 6, Batch 1400] loss: 0.32384892769157886
[Epoch 6, Batch 1500] loss: 0.30022049620747565
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2854
Validation Accuracy: 0.9169
Overfitting: 0.2854
[Epoch 7, Batch 100] loss: 0.28314434483647344
[Epoch 7, Batch 200] loss: 0.28415329053997995
[Epoch 7, Batch 300] loss: 0.2871265050023794
[Epoch 7, Batch 400] loss: 0.26922568671405317
[Epoch 7, Batch 500] loss: 0.2869739434123039
[Epoch 7, Batch 600] loss: 0.2744173013791442
[Epoch 7, Batch 700] loss: 0.25375358112156393
[Epoch 7, Batch 800] loss: 0.26941957682371137
[Epoch 7, Batch 900] loss: 0.289576932489872
[Epoch 7, Batch 1000] loss: 0.25514817129820583
[Epoch 7, Batch 1100] loss: 0.29702312719076873
[Epoch 7, Batch 1200] loss: 0.2616619395464659
[Epoch 7, Batch 1300] loss: 0.2619750213995576
[Epoch 7, Batch 1400] loss: 0.2519852289184928
[Epoch 7, Batch 1500] loss: 0.2357073390856385
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2535
Validation Accuracy: 0.9263
Overfitting: 0.2535
[Epoch 8, Batch 100] loss: 0.25259758412837985
[Epoch 8, Batch 200] loss: 0.26989671409130095
[Epoch 8, Batch 300] loss: 0.262483197376132
[Epoch 8, Batch 400] loss: 0.2708428194001317
[Epoch 8, Batch 500] loss: 0.23449427969753742
[Epoch 8, Batch 600] loss: 0.22434742793440818
[Epoch 8, Batch 700] loss: 0.23222135949879885
[Epoch 8, Batch 800] loss: 0.2505080882832408
[Epoch 8, Batch 900] loss: 0.22810505144298077
[Epoch 8, Batch 1000] loss: 0.23550733774900437
[Epoch 8, Batch 1100] loss: 0.24391052275896072
[Epoch 8, Batch 1200] loss: 0.21037148669362069
[Epoch 8, Batch 1300] loss: 0.23197542149573563
[Epoch 8, Batch 1400] loss: 0.20023854285478593
[Epoch 8, Batch 1500] loss: 0.23881494207307696
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2256
Validation Accuracy: 0.9352
Overfitting: 0.2256
[Epoch 9, Batch 100] loss: 0.22438026182353496
[Epoch 9, Batch 200] loss: 0.2317874388024211
[Epoch 9, Batch 300] loss: 0.22503625631332397
[Epoch 9, Batch 400] loss: 0.21733862712979315
[Epoch 9, Batch 500] loss: 0.20230533752590418
[Epoch 9, Batch 600] loss: 0.2197158256173134
[Epoch 9, Batch 700] loss: 0.21850204553455113
[Epoch 9, Batch 800] loss: 0.2114496547356248
[Epoch 9, Batch 900] loss: 0.22830784533172846
[Epoch 9, Batch 1000] loss: 0.22014688149094583
[Epoch 9, Batch 1100] loss: 0.20705702513456345
[Epoch 9, Batch 1200] loss: 0.20296770056709648
[Epoch 9, Batch 1300] loss: 0.19993925884366034
[Epoch 9, Batch 1400] loss: 0.19214012760668994
[Epoch 9, Batch 1500] loss: 0.18360728153958916
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.2071
Validation Accuracy: 0.9407
Overfitting: 0.2071
Best model saved at epoch 9 with validation loss: 0.2071
[Epoch 10, Batch 100] loss: 0.2060868614912033
[Epoch 10, Batch 200] loss: 0.19693062640726566
[Epoch 10, Batch 300] loss: 0.20564828170463442
[Epoch 10, Batch 400] loss: 0.19782610043883322
[Epoch 10, Batch 500] loss: 0.19007177328690886
[Epoch 10, Batch 600] loss: 0.1736566730029881
[Epoch 10, Batch 700] loss: 0.2015225108526647
[Epoch 10, Batch 800] loss: 0.20348290048539638
[Epoch 10, Batch 900] loss: 0.18213336452841758
[Epoch 10, Batch 1000] loss: 0.1782529116049409
[Epoch 10, Batch 1100] loss: 0.19190312810242177
[Epoch 10, Batch 1200] loss: 0.18499217681586744
[Epoch 10, Batch 1300] loss: 0.1770543532818556
[Epoch 10, Batch 1400] loss: 0.18451370112597942
[Epoch 10, Batch 1500] loss: 0.19034087393432855
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1841
Validation Accuracy: 0.9468
Overfitting: 0.1841
[Epoch 11, Batch 100] loss: 0.17058638837188483
[Epoch 11, Batch 200] loss: 0.17203839283436537
[Epoch 11, Batch 300] loss: 0.1884972335025668
[Epoch 11, Batch 400] loss: 0.1798006037250161
[Epoch 11, Batch 500] loss: 0.1760937988385558
[Epoch 11, Batch 600] loss: 0.16493386086076497
[Epoch 11, Batch 700] loss: 0.1762153455428779
[Epoch 11, Batch 800] loss: 0.19727064836770297
[Epoch 11, Batch 900] loss: 0.17052697136998177
[Epoch 11, Batch 1000] loss: 0.19578518714755774
[Epoch 11, Batch 1100] loss: 0.16705829361453653
[Epoch 11, Batch 1200] loss: 0.15638781283050776
[Epoch 11, Batch 1300] loss: 0.15101877856999635
[Epoch 11, Batch 1400] loss: 0.16031652357429266
[Epoch 11, Batch 1500] loss: 0.16555423639714717
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1700
Validation Accuracy: 0.9503
Overfitting: 0.1700
Best model saved at epoch 11 with validation loss: 0.1700
[Epoch 12, Batch 100] loss: 0.16037268597632648
[Epoch 12, Batch 200] loss: 0.18023225516080857
[Epoch 12, Batch 300] loss: 0.16973529271781446
[Epoch 12, Batch 400] loss: 0.17060483176261187
[Epoch 12, Batch 500] loss: 0.15907338806428015
[Epoch 12, Batch 600] loss: 0.16395629089325667
[Epoch 12, Batch 700] loss: 0.15956590473651885
[Epoch 12, Batch 800] loss: 0.14511387687176466
[Epoch 12, Batch 900] loss: 0.15329903874546288
[Epoch 12, Batch 1000] loss: 0.15265207815915346
[Epoch 12, Batch 1100] loss: 0.16525705400854349
[Epoch 12, Batch 1200] loss: 0.14607660297304392
[Epoch 12, Batch 1300] loss: 0.14753977013751865
[Epoch 12, Batch 1400] loss: 0.15853578297421336
[Epoch 12, Batch 1500] loss: 0.1486391217261553
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1616
Validation Accuracy: 0.9517
Overfitting: 0.1616
[Epoch 13, Batch 100] loss: 0.1555656550079584
[Epoch 13, Batch 200] loss: 0.15282568249851466
[Epoch 13, Batch 300] loss: 0.15218155620619656
[Epoch 13, Batch 400] loss: 0.1512460364960134
[Epoch 13, Batch 500] loss: 0.13407862826250494
[Epoch 13, Batch 600] loss: 0.1364368429221213
[Epoch 13, Batch 700] loss: 0.1431112350150943
[Epoch 13, Batch 800] loss: 0.14812534576281905
[Epoch 13, Batch 900] loss: 0.1437655727751553
[Epoch 13, Batch 1000] loss: 0.14206577110104263
[Epoch 13, Batch 1100] loss: 0.16312881655991077
[Epoch 13, Batch 1200] loss: 0.1386218386143446
[Epoch 13, Batch 1300] loss: 0.14764650660566986
[Epoch 13, Batch 1400] loss: 0.13549545706249774
[Epoch 13, Batch 1500] loss: 0.14456770151853562
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1478
Validation Accuracy: 0.9584
Overfitting: 0.1478
Early stopping epoch 13 for trial 8. Moving to next fold.
Fold 3 validation loss: 0.1478
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.303831646442413
[Epoch 1, Batch 200] loss: 2.30202228307724
[Epoch 1, Batch 300] loss: 2.2998719692230223
[Epoch 1, Batch 400] loss: 2.296813418865204
[Epoch 1, Batch 500] loss: 2.2963237667083742
[Epoch 1, Batch 600] loss: 2.29662353515625
[Epoch 1, Batch 700] loss: 2.293354549407959
[Epoch 1, Batch 800] loss: 2.292983765602112
[Epoch 1, Batch 900] loss: 2.288992536067963
[Epoch 1, Batch 1000] loss: 2.2862805414199827
[Epoch 1, Batch 1100] loss: 2.2861669707298278
[Epoch 1, Batch 1200] loss: 2.2840921902656555
[Epoch 1, Batch 1300] loss: 2.280258038043976
[Epoch 1, Batch 1400] loss: 2.277753427028656
[Epoch 1, Batch 1500] loss: 2.276622214317322
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2752
Validation Accuracy: 0.2407
Overfitting: 2.2752
[Epoch 2, Batch 100] loss: 2.2752025270462037
[Epoch 2, Batch 200] loss: 2.266654918193817
[Epoch 2, Batch 300] loss: 2.2643258690834047
[Epoch 2, Batch 400] loss: 2.26226345539093
[Epoch 2, Batch 500] loss: 2.2561312770843505
[Epoch 2, Batch 600] loss: 2.250029420852661
[Epoch 2, Batch 700] loss: 2.242276682853699
[Epoch 2, Batch 800] loss: 2.230512375831604
[Epoch 2, Batch 900] loss: 2.2257569074630736
[Epoch 2, Batch 1000] loss: 2.215876588821411
[Epoch 2, Batch 1100] loss: 2.2018891286849978
[Epoch 2, Batch 1200] loss: 2.184250519275665
[Epoch 2, Batch 1300] loss: 2.1672722458839417
[Epoch 2, Batch 1400] loss: 2.1405792689323424
[Epoch 2, Batch 1500] loss: 2.1112379312515257
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 2.0960
Validation Accuracy: 0.4672
Overfitting: 2.0960
[Epoch 3, Batch 100] loss: 2.0701871013641355
[Epoch 3, Batch 200] loss: 2.0213954770565032
[Epoch 3, Batch 300] loss: 1.954072505235672
[Epoch 3, Batch 400] loss: 1.8784080731868744
[Epoch 3, Batch 500] loss: 1.769849158525467
[Epoch 3, Batch 600] loss: 1.6467021954059602
[Epoch 3, Batch 700] loss: 1.5122424209117888
[Epoch 3, Batch 800] loss: 1.381472234725952
[Epoch 3, Batch 900] loss: 1.2364193785190583
[Epoch 3, Batch 1000] loss: 1.1025650656223298
[Epoch 3, Batch 1100] loss: 1.0339899557828902
[Epoch 3, Batch 1200] loss: 0.9289859527349472
[Epoch 3, Batch 1300] loss: 0.8508109605312347
[Epoch 3, Batch 1400] loss: 0.7843098241090775
[Epoch 3, Batch 1500] loss: 0.7231437638401985
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.7374
Validation Accuracy: 0.7802
Overfitting: 0.7374
[Epoch 4, Batch 100] loss: 0.7243435108661651
[Epoch 4, Batch 200] loss: 0.6856078982353211
[Epoch 4, Batch 300] loss: 0.6381493833661079
[Epoch 4, Batch 400] loss: 0.6494083690643311
[Epoch 4, Batch 500] loss: 0.6213128620386124
[Epoch 4, Batch 600] loss: 0.5928395906090737
[Epoch 4, Batch 700] loss: 0.5612087938189506
[Epoch 4, Batch 800] loss: 0.5305347660183907
[Epoch 4, Batch 900] loss: 0.5279969453811646
[Epoch 4, Batch 1000] loss: 0.4854862357676029
[Epoch 4, Batch 1100] loss: 0.5229129144549369
[Epoch 4, Batch 1200] loss: 0.4826803705096245
[Epoch 4, Batch 1300] loss: 0.47504842534661296
[Epoch 4, Batch 1400] loss: 0.493770285397768
[Epoch 4, Batch 1500] loss: 0.4599219603836536
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.4603
Validation Accuracy: 0.8570
Overfitting: 0.4603
[Epoch 5, Batch 100] loss: 0.4608608722686768
[Epoch 5, Batch 200] loss: 0.44047699570655824
[Epoch 5, Batch 300] loss: 0.4495201052725315
[Epoch 5, Batch 400] loss: 0.4356620272994041
[Epoch 5, Batch 500] loss: 0.4248504076898098
[Epoch 5, Batch 600] loss: 0.3950228162109852
[Epoch 5, Batch 700] loss: 0.3954850149154663
[Epoch 5, Batch 800] loss: 0.3925520599633455
[Epoch 5, Batch 900] loss: 0.3808009642362595
[Epoch 5, Batch 1000] loss: 0.4094834212958813
[Epoch 5, Batch 1100] loss: 0.3852096500992775
[Epoch 5, Batch 1200] loss: 0.363190141916275
[Epoch 5, Batch 1300] loss: 0.38836111187934874
[Epoch 5, Batch 1400] loss: 0.34201122701168063
[Epoch 5, Batch 1500] loss: 0.3711460946500301
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3656
Validation Accuracy: 0.8865
Overfitting: 0.3656
[Epoch 6, Batch 100] loss: 0.3403348561376333
[Epoch 6, Batch 200] loss: 0.348490639552474
[Epoch 6, Batch 300] loss: 0.32740175679326056
[Epoch 6, Batch 400] loss: 0.34865356869995595
[Epoch 6, Batch 500] loss: 0.3383670438826084
[Epoch 6, Batch 600] loss: 0.32877827271819116
[Epoch 6, Batch 700] loss: 0.32970283441245557
[Epoch 6, Batch 800] loss: 0.3013060111552477
[Epoch 6, Batch 900] loss: 0.3438752164691687
[Epoch 6, Batch 1000] loss: 0.349046114385128
[Epoch 6, Batch 1100] loss: 0.31155666887760164
[Epoch 6, Batch 1200] loss: 0.3113370559364557
[Epoch 6, Batch 1300] loss: 0.3052320709824562
[Epoch 6, Batch 1400] loss: 0.3112170953303576
[Epoch 6, Batch 1500] loss: 0.29730976216495036
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.3035
Validation Accuracy: 0.9069
Overfitting: 0.3035
[Epoch 7, Batch 100] loss: 0.27696431189775467
[Epoch 7, Batch 200] loss: 0.2957928413897753
[Epoch 7, Batch 300] loss: 0.3010429364070296
[Epoch 7, Batch 400] loss: 0.2746162520349026
[Epoch 7, Batch 500] loss: 0.2925034990906715
[Epoch 7, Batch 600] loss: 0.28716444328427315
[Epoch 7, Batch 700] loss: 0.286403883472085
[Epoch 7, Batch 800] loss: 0.30642399795353414
[Epoch 7, Batch 900] loss: 0.27342368379235266
[Epoch 7, Batch 1000] loss: 0.27858239836990834
[Epoch 7, Batch 1100] loss: 0.25530723422765733
[Epoch 7, Batch 1200] loss: 0.25587612606585025
[Epoch 7, Batch 1300] loss: 0.25342466071248054
[Epoch 7, Batch 1400] loss: 0.2734282694756985
[Epoch 7, Batch 1500] loss: 0.251549474298954
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2590
Validation Accuracy: 0.9198
Overfitting: 0.2590
[Epoch 8, Batch 100] loss: 0.27106937184929847
[Epoch 8, Batch 200] loss: 0.25431796550750735
[Epoch 8, Batch 300] loss: 0.26646747440099716
[Epoch 8, Batch 400] loss: 0.24168835330754518
[Epoch 8, Batch 500] loss: 0.2551554238423705
[Epoch 8, Batch 600] loss: 0.23526284281164409
[Epoch 8, Batch 700] loss: 0.2394620905071497
[Epoch 8, Batch 800] loss: 0.2221770914271474
[Epoch 8, Batch 900] loss: 0.22826281916350127
[Epoch 8, Batch 1000] loss: 0.2526937425136566
[Epoch 8, Batch 1100] loss: 0.22377217411994935
[Epoch 8, Batch 1200] loss: 0.21819712582975626
[Epoch 8, Batch 1300] loss: 0.23997191283851863
[Epoch 8, Batch 1400] loss: 0.24266754312440753
[Epoch 8, Batch 1500] loss: 0.2334265534207225
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2281
Validation Accuracy: 0.9297
Overfitting: 0.2281
[Epoch 9, Batch 100] loss: 0.2313861320912838
[Epoch 9, Batch 200] loss: 0.2362095931172371
[Epoch 9, Batch 300] loss: 0.2112348370626569
[Epoch 9, Batch 400] loss: 0.23268587622791528
[Epoch 9, Batch 500] loss: 0.19623050600290298
[Epoch 9, Batch 600] loss: 0.22489550918340684
[Epoch 9, Batch 700] loss: 0.23428123416379093
[Epoch 9, Batch 800] loss: 0.19384258039295674
[Epoch 9, Batch 900] loss: 0.23374408725649118
[Epoch 9, Batch 1000] loss: 0.19751532815396786
[Epoch 9, Batch 1100] loss: 0.21163444593548775
[Epoch 9, Batch 1200] loss: 0.21561919510364533
[Epoch 9, Batch 1300] loss: 0.17906519277021288
[Epoch 9, Batch 1400] loss: 0.1973248090222478
[Epoch 9, Batch 1500] loss: 0.20447153314948083
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.2078
Validation Accuracy: 0.9337
Overfitting: 0.2078
Best model saved at epoch 9 with validation loss: 0.2078
[Epoch 10, Batch 100] loss: 0.20471474085003138
[Epoch 10, Batch 200] loss: 0.18805850949138403
[Epoch 10, Batch 300] loss: 0.20535445973277092
[Epoch 10, Batch 400] loss: 0.21719546414911747
[Epoch 10, Batch 500] loss: 0.20123345186933875
[Epoch 10, Batch 600] loss: 0.2198845837637782
[Epoch 10, Batch 700] loss: 0.18490206638351084
[Epoch 10, Batch 800] loss: 0.18179820138961078
[Epoch 10, Batch 900] loss: 0.175224232301116
[Epoch 10, Batch 1000] loss: 0.18246106948703528
[Epoch 10, Batch 1100] loss: 0.18234110288321972
[Epoch 10, Batch 1200] loss: 0.19075056249275804
[Epoch 10, Batch 1300] loss: 0.18449246471747757
[Epoch 10, Batch 1400] loss: 0.1766620847582817
[Epoch 10, Batch 1500] loss: 0.17962296061217786
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1800
Validation Accuracy: 0.9447
Overfitting: 0.1800
[Epoch 11, Batch 100] loss: 0.18768493246287107
[Epoch 11, Batch 200] loss: 0.17427423784509302
[Epoch 11, Batch 300] loss: 0.182875720821321
[Epoch 11, Batch 400] loss: 0.1923407393321395
[Epoch 11, Batch 500] loss: 0.18430891882628203
[Epoch 11, Batch 600] loss: 0.15537926126271487
[Epoch 11, Batch 700] loss: 0.17856990590691565
[Epoch 11, Batch 800] loss: 0.16898355909623206
[Epoch 11, Batch 900] loss: 0.17592886213213205
[Epoch 11, Batch 1000] loss: 0.17768975768238307
[Epoch 11, Batch 1100] loss: 0.172590197250247
[Epoch 11, Batch 1200] loss: 0.16411815265193583
[Epoch 11, Batch 1300] loss: 0.16895768450573087
[Epoch 11, Batch 1400] loss: 0.15761920031160115
[Epoch 11, Batch 1500] loss: 0.168064393568784
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1673
Validation Accuracy: 0.9477
Overfitting: 0.1673
Best model saved at epoch 11 with validation loss: 0.1673
[Epoch 12, Batch 100] loss: 0.1612064418569207
[Epoch 12, Batch 200] loss: 0.16227911900728942
[Epoch 12, Batch 300] loss: 0.17779581120237709
[Epoch 12, Batch 400] loss: 0.15107016675174237
[Epoch 12, Batch 500] loss: 0.1480378545075655
[Epoch 12, Batch 600] loss: 0.13947399128228427
[Epoch 12, Batch 700] loss: 0.17404255483299494
[Epoch 12, Batch 800] loss: 0.14976466484367848
[Epoch 12, Batch 900] loss: 0.16314664114266633
[Epoch 12, Batch 1000] loss: 0.1595112515706569
[Epoch 12, Batch 1100] loss: 0.1771257954183966
[Epoch 12, Batch 1200] loss: 0.15868350064381956
[Epoch 12, Batch 1300] loss: 0.1622490351460874
[Epoch 12, Batch 1400] loss: 0.1474567747488618
[Epoch 12, Batch 1500] loss: 0.16692108016461135
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1567
Validation Accuracy: 0.9522
Overfitting: 0.1567
[Epoch 13, Batch 100] loss: 0.1721573229506612
[Epoch 13, Batch 200] loss: 0.1600076327379793
[Epoch 13, Batch 300] loss: 0.16108496714383364
[Epoch 13, Batch 400] loss: 0.15280624855309724
[Epoch 13, Batch 500] loss: 0.14055631387978793
[Epoch 13, Batch 600] loss: 0.1499638369306922
[Epoch 13, Batch 700] loss: 0.1510616211593151
[Epoch 13, Batch 800] loss: 0.13999663582071661
[Epoch 13, Batch 900] loss: 0.14280480653047561
[Epoch 13, Batch 1000] loss: 0.14423472015187144
[Epoch 13, Batch 1100] loss: 0.14847307227551937
[Epoch 13, Batch 1200] loss: 0.14527355439960957
[Epoch 13, Batch 1300] loss: 0.13294924669899047
[Epoch 13, Batch 1400] loss: 0.13393462954089044
[Epoch 13, Batch 1500] loss: 0.14068036373704673
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1424
Validation Accuracy: 0.9552
Overfitting: 0.1424
Early stopping epoch 13 for trial 8. Moving to next fold.
Fold 4 validation loss: 0.1424
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.3001829624176025
[Epoch 1, Batch 200] loss: 2.3000845456123353
[Epoch 1, Batch 300] loss: 2.2954946422576903
[Epoch 1, Batch 400] loss: 2.2938208293914797
[Epoch 1, Batch 500] loss: 2.29183256149292
[Epoch 1, Batch 600] loss: 2.291164481639862
[Epoch 1, Batch 700] loss: 2.283134160041809
[Epoch 1, Batch 800] loss: 2.2815393805503845
[Epoch 1, Batch 900] loss: 2.2764300441741945
[Epoch 1, Batch 1000] loss: 2.271603055000305
[Epoch 1, Batch 1100] loss: 2.268415403366089
[Epoch 1, Batch 1200] loss: 2.2626177883148193
[Epoch 1, Batch 1300] loss: 2.254265162944794
[Epoch 1, Batch 1400] loss: 2.2482686614990235
[Epoch 1, Batch 1500] loss: 2.236968870162964
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2316
Validation Accuracy: 0.3791
Overfitting: 2.2316
[Epoch 2, Batch 100] loss: 2.224727909564972
[Epoch 2, Batch 200] loss: 2.214532506465912
[Epoch 2, Batch 300] loss: 2.193922758102417
[Epoch 2, Batch 400] loss: 2.1717523622512815
[Epoch 2, Batch 500] loss: 2.151112997531891
[Epoch 2, Batch 600] loss: 2.11709082365036
[Epoch 2, Batch 700] loss: 2.0702840983867645
[Epoch 2, Batch 800] loss: 2.026757539510727
[Epoch 2, Batch 900] loss: 1.9456482923030853
[Epoch 2, Batch 1000] loss: 1.8642524993419647
[Epoch 2, Batch 1100] loss: 1.7557072389125823
[Epoch 2, Batch 1200] loss: 1.6230110383033753
[Epoch 2, Batch 1300] loss: 1.4757854461669921
[Epoch 2, Batch 1400] loss: 1.3367667734622954
[Epoch 2, Batch 1500] loss: 1.1993179088830948
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.1242
Validation Accuracy: 0.7387
Overfitting: 1.1242
[Epoch 3, Batch 100] loss: 1.0702480977773667
[Epoch 3, Batch 200] loss: 0.9529611891508103
[Epoch 3, Batch 300] loss: 0.8422279393672943
[Epoch 3, Batch 400] loss: 0.8130795198678971
[Epoch 3, Batch 500] loss: 0.7281749248504639
[Epoch 3, Batch 600] loss: 0.6896045690774918
[Epoch 3, Batch 700] loss: 0.6128729289770126
[Epoch 3, Batch 800] loss: 0.5933341240882873
[Epoch 3, Batch 900] loss: 0.6005556082725525
[Epoch 3, Batch 1000] loss: 0.5256776314973831
[Epoch 3, Batch 1100] loss: 0.5337624317407608
[Epoch 3, Batch 1200] loss: 0.5208374716341495
[Epoch 3, Batch 1300] loss: 0.5079255516827107
[Epoch 3, Batch 1400] loss: 0.4808952099084854
[Epoch 3, Batch 1500] loss: 0.4695695349574089
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.4853
Validation Accuracy: 0.8592
Overfitting: 0.4853
[Epoch 4, Batch 100] loss: 0.46158971294760703
[Epoch 4, Batch 200] loss: 0.47542248472571375
[Epoch 4, Batch 300] loss: 0.4585572668910027
[Epoch 4, Batch 400] loss: 0.41717936798930166
[Epoch 4, Batch 500] loss: 0.39758203595876696
[Epoch 4, Batch 600] loss: 0.4338107106089592
[Epoch 4, Batch 700] loss: 0.4221913976967335
[Epoch 4, Batch 800] loss: 0.39921640142798426
[Epoch 4, Batch 900] loss: 0.3993006691336632
[Epoch 4, Batch 1000] loss: 0.40477330654859545
[Epoch 4, Batch 1100] loss: 0.3924958049505949
[Epoch 4, Batch 1200] loss: 0.3646912265568972
[Epoch 4, Batch 1300] loss: 0.374207167327404
[Epoch 4, Batch 1400] loss: 0.374831278026104
[Epoch 4, Batch 1500] loss: 0.3554951399564743
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3624
Validation Accuracy: 0.8930
Overfitting: 0.3624
[Epoch 5, Batch 100] loss: 0.3402754957973957
[Epoch 5, Batch 200] loss: 0.37099305547773836
[Epoch 5, Batch 300] loss: 0.35253123097121714
[Epoch 5, Batch 400] loss: 0.3329391574859619
[Epoch 5, Batch 500] loss: 0.3307609762996435
[Epoch 5, Batch 600] loss: 0.3441619650274515
[Epoch 5, Batch 700] loss: 0.3419331730902195
[Epoch 5, Batch 800] loss: 0.3199273383617401
[Epoch 5, Batch 900] loss: 0.3245497253537178
[Epoch 5, Batch 1000] loss: 0.3092072617262602
[Epoch 5, Batch 1100] loss: 0.30952650353312494
[Epoch 5, Batch 1200] loss: 0.315170416906476
[Epoch 5, Batch 1300] loss: 0.30792276449501516
[Epoch 5, Batch 1400] loss: 0.2841900008916855
[Epoch 5, Batch 1500] loss: 0.3267954370379448
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3030
Validation Accuracy: 0.9097
Overfitting: 0.3030
[Epoch 6, Batch 100] loss: 0.29475053049623967
[Epoch 6, Batch 200] loss: 0.2859572571516037
[Epoch 6, Batch 300] loss: 0.32351840905845164
[Epoch 6, Batch 400] loss: 0.2921319127082825
[Epoch 6, Batch 500] loss: 0.2686207717657089
[Epoch 6, Batch 600] loss: 0.27624399721622467
[Epoch 6, Batch 700] loss: 0.2722156040370464
[Epoch 6, Batch 800] loss: 0.28889402613043785
[Epoch 6, Batch 900] loss: 0.25915418338030577
[Epoch 6, Batch 1000] loss: 0.29119845550507306
[Epoch 6, Batch 1100] loss: 0.2817183716595173
[Epoch 6, Batch 1200] loss: 0.2593639446794987
[Epoch 6, Batch 1300] loss: 0.2757781077176332
[Epoch 6, Batch 1400] loss: 0.255600287206471
[Epoch 6, Batch 1500] loss: 0.27758538581430914
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2739
Validation Accuracy: 0.9178
Overfitting: 0.2739
[Epoch 7, Batch 100] loss: 0.26996426098048687
[Epoch 7, Batch 200] loss: 0.27115653436630965
[Epoch 7, Batch 300] loss: 0.25398039400577543
[Epoch 7, Batch 400] loss: 0.2506634580716491
[Epoch 7, Batch 500] loss: 0.2484764400497079
[Epoch 7, Batch 600] loss: 0.22591647576540708
[Epoch 7, Batch 700] loss: 0.23818330585956574
[Epoch 7, Batch 800] loss: 0.24233327496796847
[Epoch 7, Batch 900] loss: 0.24521065600216388
[Epoch 7, Batch 1000] loss: 0.23601395696401595
[Epoch 7, Batch 1100] loss: 0.2485963560640812
[Epoch 7, Batch 1200] loss: 0.24021629799157382
[Epoch 7, Batch 1300] loss: 0.23236996550112962
[Epoch 7, Batch 1400] loss: 0.2259138437360525
[Epoch 7, Batch 1500] loss: 0.2405492638796568
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2338
Validation Accuracy: 0.9302
Overfitting: 0.2338
[Epoch 8, Batch 100] loss: 0.23389375921338795
[Epoch 8, Batch 200] loss: 0.22762474305927755
[Epoch 8, Batch 300] loss: 0.23452899686992168
[Epoch 8, Batch 400] loss: 0.23534402791410686
[Epoch 8, Batch 500] loss: 0.21338174931704998
[Epoch 8, Batch 600] loss: 0.2233332286402583
[Epoch 8, Batch 700] loss: 0.21002267986536027
[Epoch 8, Batch 800] loss: 0.2168398281186819
[Epoch 8, Batch 900] loss: 0.2220805874466896
[Epoch 8, Batch 1000] loss: 0.2304469070956111
[Epoch 8, Batch 1100] loss: 0.19475792206823825
[Epoch 8, Batch 1200] loss: 0.21619622264057398
[Epoch 8, Batch 1300] loss: 0.2278723882138729
[Epoch 8, Batch 1400] loss: 0.2024659313634038
[Epoch 8, Batch 1500] loss: 0.20689665380865335
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2136
Validation Accuracy: 0.9366
Overfitting: 0.2136
[Epoch 9, Batch 100] loss: 0.20331003919243812
[Epoch 9, Batch 200] loss: 0.19442258268594742
[Epoch 9, Batch 300] loss: 0.22384829964488745
[Epoch 9, Batch 400] loss: 0.20390491019934415
[Epoch 9, Batch 500] loss: 0.2304399961233139
[Epoch 9, Batch 600] loss: 0.18953802455216645
[Epoch 9, Batch 700] loss: 0.19453244676813483
[Epoch 9, Batch 800] loss: 0.20132207579910755
[Epoch 9, Batch 900] loss: 0.1842921789176762
[Epoch 9, Batch 1000] loss: 0.20284990102052688
[Epoch 9, Batch 1100] loss: 0.18554259575903415
[Epoch 9, Batch 1200] loss: 0.19556548818945885
[Epoch 9, Batch 1300] loss: 0.20963100131601095
[Epoch 9, Batch 1400] loss: 0.18943694405257702
[Epoch 9, Batch 1500] loss: 0.18820641584694386
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1958
Validation Accuracy: 0.9423
Overfitting: 0.1958
Best model saved at epoch 9 with validation loss: 0.1958
[Epoch 10, Batch 100] loss: 0.20519468920305373
[Epoch 10, Batch 200] loss: 0.17182556295767426
[Epoch 10, Batch 300] loss: 0.18685097739100456
[Epoch 10, Batch 400] loss: 0.18389900468289852
[Epoch 10, Batch 500] loss: 0.19739523701369763
[Epoch 10, Batch 600] loss: 0.16918913811445235
[Epoch 10, Batch 700] loss: 0.17697689577937126
[Epoch 10, Batch 800] loss: 0.16273356093093752
[Epoch 10, Batch 900] loss: 0.2193658045679331
[Epoch 10, Batch 1000] loss: 0.17288133271038533
[Epoch 10, Batch 1100] loss: 0.1775420948304236
[Epoch 10, Batch 1200] loss: 0.20121030893176794
[Epoch 10, Batch 1300] loss: 0.1711096823401749
[Epoch 10, Batch 1400] loss: 0.18129492100328207
[Epoch 10, Batch 1500] loss: 0.16972633078694344
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1742
Validation Accuracy: 0.9483
Overfitting: 0.1742
[Epoch 11, Batch 100] loss: 0.1772821897082031
[Epoch 11, Batch 200] loss: 0.16781572435051204
[Epoch 11, Batch 300] loss: 0.17580986499786377
[Epoch 11, Batch 400] loss: 0.18452456381171942
[Epoch 11, Batch 500] loss: 0.16320042088627815
[Epoch 11, Batch 600] loss: 0.17841492043808102
[Epoch 11, Batch 700] loss: 0.18537749651819468
[Epoch 11, Batch 800] loss: 0.15793155647814275
[Epoch 11, Batch 900] loss: 0.14598904302343726
[Epoch 11, Batch 1000] loss: 0.16142688475549222
[Epoch 11, Batch 1100] loss: 0.16893491184338927
[Epoch 11, Batch 1200] loss: 0.15730390276759862
[Epoch 11, Batch 1300] loss: 0.17902610387653112
[Epoch 11, Batch 1400] loss: 0.17001459142193198
[Epoch 11, Batch 1500] loss: 0.17164107859134675
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1672
Validation Accuracy: 0.9503
Overfitting: 0.1672
Early stopping epoch 11 for trial 8. Moving to next fold.
Fold 5 validation loss: 0.1672
Mean validation loss across all folds for Trial 8 is 0.1513 with trial config:  l1: 128, l2: 64, lr: 0.0001, batch_size: 32
[I 2024-12-10 05:08:13,683] Trial 7 finished with value: 0.1513290396352609 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.0001, 'batch_size': 32}. Best is trial 0 with value: 0.05093086766599445.

Selected Hyperparameters for Trial 9:
  l1: 256, l2: 64, lr: 0.001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.294933922290802
[Epoch 1, Batch 200] loss: 2.268744337558746
[Epoch 1, Batch 300] loss: 2.187728159427643
[Epoch 1, Batch 400] loss: 1.6907067561149598
[Epoch 1, Batch 500] loss: 0.7933382561802864
[Epoch 1, Batch 600] loss: 0.5444170260429382
[Epoch 1, Batch 700] loss: 0.45669722348451613
[Epoch 1, Batch 800] loss: 0.40729693867266176
[Epoch 1, Batch 900] loss: 0.33572885029017924
[Epoch 1, Batch 1000] loss: 0.34045566491782664
[Epoch 1, Batch 1100] loss: 0.30659315928816794
[Epoch 1, Batch 1200] loss: 0.2725892984867096
[Epoch 1, Batch 1300] loss: 0.28553837809711696
[Epoch 1, Batch 1400] loss: 0.23920747108757495
[Epoch 1, Batch 1500] loss: 0.23960708167403935
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2239
Validation Accuracy: 0.9318
Overfitting: 0.2239
[Epoch 2, Batch 100] loss: 0.20582334455102683
[Epoch 2, Batch 200] loss: 0.2326351098716259
[Epoch 2, Batch 300] loss: 0.19329525601118802
[Epoch 2, Batch 400] loss: 0.1739245998673141
[Epoch 2, Batch 500] loss: 0.17721946647390724
[Epoch 2, Batch 600] loss: 0.15426805147901176
[Epoch 2, Batch 700] loss: 0.17693028124980628
[Epoch 2, Batch 800] loss: 0.16956851089373232
[Epoch 2, Batch 900] loss: 0.1600959761440754
[Epoch 2, Batch 1000] loss: 0.15021671967580916
[Epoch 2, Batch 1100] loss: 0.13948932355269789
[Epoch 2, Batch 1200] loss: 0.14862735193222762
[Epoch 2, Batch 1300] loss: 0.12733780555427074
[Epoch 2, Batch 1400] loss: 0.12200229473412037
[Epoch 2, Batch 1500] loss: 0.11836693059653043
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1228
Validation Accuracy: 0.9597
Overfitting: 0.1228
[Epoch 3, Batch 100] loss: 0.11697553946636617
[Epoch 3, Batch 200] loss: 0.10727184458635747
[Epoch 3, Batch 300] loss: 0.10830784957855939
[Epoch 3, Batch 400] loss: 0.12867965783458202
[Epoch 3, Batch 500] loss: 0.12315189926885069
[Epoch 3, Batch 600] loss: 0.10034838536288589
[Epoch 3, Batch 700] loss: 0.10223463662434369
[Epoch 3, Batch 800] loss: 0.08404840990435332
[Epoch 3, Batch 900] loss: 0.08888411388732492
[Epoch 3, Batch 1000] loss: 0.10549198255408555
[Epoch 3, Batch 1100] loss: 0.10508684309199452
[Epoch 3, Batch 1200] loss: 0.10802090128418058
[Epoch 3, Batch 1300] loss: 0.10948153777979314
[Epoch 3, Batch 1400] loss: 0.09730067607481033
[Epoch 3, Batch 1500] loss: 0.08630627326667309
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0873
Validation Accuracy: 0.9733
Overfitting: 0.0873
[Epoch 4, Batch 100] loss: 0.08814398106886073
[Epoch 4, Batch 200] loss: 0.075872788480483
[Epoch 4, Batch 300] loss: 0.09078745399136096
[Epoch 4, Batch 400] loss: 0.06865115592256188
[Epoch 4, Batch 500] loss: 0.10751721111126245
[Epoch 4, Batch 600] loss: 0.07062289582565427
[Epoch 4, Batch 700] loss: 0.07730620614020153
[Epoch 4, Batch 800] loss: 0.08574675604701042
[Epoch 4, Batch 900] loss: 0.07992807087954133
[Epoch 4, Batch 1000] loss: 0.08377114628441631
[Epoch 4, Batch 1100] loss: 0.07462576834252105
[Epoch 4, Batch 1200] loss: 0.07122551620937884
[Epoch 4, Batch 1300] loss: 0.07610396057600155
[Epoch 4, Batch 1400] loss: 0.0808135892637074
[Epoch 4, Batch 1500] loss: 0.06200686078518629
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0749
Validation Accuracy: 0.9767
Overfitting: 0.0749
[Epoch 5, Batch 100] loss: 0.07841150388820096
[Epoch 5, Batch 200] loss: 0.06730196565156803
[Epoch 5, Batch 300] loss: 0.06889671793673187
[Epoch 5, Batch 400] loss: 0.07381771218497306
[Epoch 5, Batch 500] loss: 0.07960248530609533
[Epoch 5, Batch 600] loss: 0.057452478385530414
[Epoch 5, Batch 700] loss: 0.058955481078010054
[Epoch 5, Batch 800] loss: 0.06105194557690993
[Epoch 5, Batch 900] loss: 0.06985171431209893
[Epoch 5, Batch 1000] loss: 0.06353650744771584
[Epoch 5, Batch 1100] loss: 0.060431364242685956
[Epoch 5, Batch 1200] loss: 0.049806619415758174
[Epoch 5, Batch 1300] loss: 0.06525784683646635
[Epoch 5, Batch 1400] loss: 0.04960962454788387
[Epoch 5, Batch 1500] loss: 0.05923751550028101
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9792
Overfitting: 0.0605
[Epoch 6, Batch 100] loss: 0.06915158667601645
[Epoch 6, Batch 200] loss: 0.04156282039824873
[Epoch 6, Batch 300] loss: 0.04905933407309931
[Epoch 6, Batch 400] loss: 0.04964112132205628
[Epoch 6, Batch 500] loss: 0.04621935939299874
[Epoch 6, Batch 600] loss: 0.057760949711082504
[Epoch 6, Batch 700] loss: 0.05535388646880165
[Epoch 6, Batch 800] loss: 0.049337066296720876
[Epoch 6, Batch 900] loss: 0.06375083268154412
[Epoch 6, Batch 1000] loss: 0.06371419870760292
[Epoch 6, Batch 1100] loss: 0.06371433419408276
[Epoch 6, Batch 1200] loss: 0.052813365191686897
[Epoch 6, Batch 1300] loss: 0.05546884210663847
[Epoch 6, Batch 1400] loss: 0.04600893919356167
[Epoch 6, Batch 1500] loss: 0.05566444993717596
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0630
Validation Accuracy: 0.9804
Overfitting: 0.0630
[Epoch 7, Batch 100] loss: 0.050120392505778
[Epoch 7, Batch 200] loss: 0.050925922193564475
[Epoch 7, Batch 300] loss: 0.047656097080325706
[Epoch 7, Batch 400] loss: 0.04781535707879812
[Epoch 7, Batch 500] loss: 0.04449447245686315
[Epoch 7, Batch 600] loss: 0.04066440256370697
[Epoch 7, Batch 700] loss: 0.04658629378303886
[Epoch 7, Batch 800] loss: 0.04216225549345836
[Epoch 7, Batch 900] loss: 0.050674632345326244
[Epoch 7, Batch 1000] loss: 0.04290679821628146
[Epoch 7, Batch 1100] loss: 0.04766073111211881
[Epoch 7, Batch 1200] loss: 0.04367530057963449
[Epoch 7, Batch 1300] loss: 0.04707373148528859
[Epoch 7, Batch 1400] loss: 0.05787638375535607
[Epoch 7, Batch 1500] loss: 0.051353371808072555
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0551
Validation Accuracy: 0.9825
Overfitting: 0.0551
[Epoch 8, Batch 100] loss: 0.04432460385025479
[Epoch 8, Batch 200] loss: 0.03678367229527794
[Epoch 8, Batch 300] loss: 0.03523911729163956
[Epoch 8, Batch 400] loss: 0.035620703186723404
[Epoch 8, Batch 500] loss: 0.038088517112191765
[Epoch 8, Batch 600] loss: 0.038944759780424644
[Epoch 8, Batch 700] loss: 0.046651120696915314
[Epoch 8, Batch 800] loss: 0.041015712808002716
[Epoch 8, Batch 900] loss: 0.04749383824993856
[Epoch 8, Batch 1000] loss: 0.04947222120827064
[Epoch 8, Batch 1100] loss: 0.04272382413502782
[Epoch 8, Batch 1200] loss: 0.04488503469270654
[Epoch 8, Batch 1300] loss: 0.03902380431711208
[Epoch 8, Batch 1400] loss: 0.04336147544468986
[Epoch 8, Batch 1500] loss: 0.04449475997709669
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9834
Overfitting: 0.0486
[Epoch 9, Batch 100] loss: 0.030245341728441417
[Epoch 9, Batch 200] loss: 0.029801486879587172
[Epoch 9, Batch 300] loss: 0.0476283481460996
[Epoch 9, Batch 400] loss: 0.05284883668762632
[Epoch 9, Batch 500] loss: 0.04420653262757696
[Epoch 9, Batch 600] loss: 0.037515180968330245
[Epoch 9, Batch 700] loss: 0.028960864569526165
[Epoch 9, Batch 800] loss: 0.034037341623334216
[Epoch 9, Batch 900] loss: 0.03668867165106349
[Epoch 9, Batch 1000] loss: 0.032902514349552804
[Epoch 9, Batch 1100] loss: 0.03794902916299179
[Epoch 9, Batch 1200] loss: 0.03964487739780452
[Epoch 9, Batch 1300] loss: 0.03787953360064421
[Epoch 9, Batch 1400] loss: 0.03347116138611454
[Epoch 9, Batch 1500] loss: 0.03189245256537106
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0600
Validation Accuracy: 0.9818
Overfitting: 0.0600
Best model saved at epoch 9 with validation loss: 0.0600
[Epoch 10, Batch 100] loss: 0.033133707633678566
[Epoch 10, Batch 200] loss: 0.029548309639794754
[Epoch 10, Batch 300] loss: 0.03247499418677762
[Epoch 10, Batch 400] loss: 0.032507890979759396
[Epoch 10, Batch 500] loss: 0.033918116632266904
[Epoch 10, Batch 600] loss: 0.03399241386912763
[Epoch 10, Batch 700] loss: 0.037666220200480896
[Epoch 10, Batch 800] loss: 0.024417412591865285
[Epoch 10, Batch 900] loss: 0.04018501104292227
[Epoch 10, Batch 1000] loss: 0.03447894827462733
[Epoch 10, Batch 1100] loss: 0.031942246595863255
[Epoch 10, Batch 1200] loss: 0.03312559433921706
[Epoch 10, Batch 1300] loss: 0.03481950249522924
[Epoch 10, Batch 1400] loss: 0.035187562381033786
[Epoch 10, Batch 1500] loss: 0.02848539949627593
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0610
Validation Accuracy: 0.9800
Overfitting: 0.0610
[Epoch 11, Batch 100] loss: 0.030840336017135997
[Epoch 11, Batch 200] loss: 0.034964978415227964
[Epoch 11, Batch 300] loss: 0.02508818729314953
[Epoch 11, Batch 400] loss: 0.029276194650446997
[Epoch 11, Batch 500] loss: 0.019650288168340923
[Epoch 11, Batch 600] loss: 0.02124367251119111
[Epoch 11, Batch 700] loss: 0.021022926794394152
[Epoch 11, Batch 800] loss: 0.028582670096075163
[Epoch 11, Batch 900] loss: 0.030957168821478264
[Epoch 11, Batch 1000] loss: 0.033404141996288675
[Epoch 11, Batch 1100] loss: 0.026828718174656388
[Epoch 11, Batch 1200] loss: 0.03104614214214962
[Epoch 11, Batch 1300] loss: 0.03756593350524781
[Epoch 11, Batch 1400] loss: 0.03374579365132377
[Epoch 11, Batch 1500] loss: 0.035595363060710955
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0411
Validation Accuracy: 0.9866
Overfitting: 0.0411
Early stopping epoch 11 for trial 9. Moving to next fold.
Fold 1 validation loss: 0.0411
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2943490386009215
[Epoch 1, Batch 200] loss: 2.2511478996276857
[Epoch 1, Batch 300] loss: 2.037705758810043
[Epoch 1, Batch 400] loss: 1.0431790101528167
[Epoch 1, Batch 500] loss: 0.5882573607563972
[Epoch 1, Batch 600] loss: 0.47000657916069033
[Epoch 1, Batch 700] loss: 0.37758439060300586
[Epoch 1, Batch 800] loss: 0.3213547607511282
[Epoch 1, Batch 900] loss: 0.31641875866800545
[Epoch 1, Batch 1000] loss: 0.26922125071287156
[Epoch 1, Batch 1100] loss: 0.29440613102167845
[Epoch 1, Batch 1200] loss: 0.23414662666618824
[Epoch 1, Batch 1300] loss: 0.22242620758712292
[Epoch 1, Batch 1400] loss: 0.2253217169828713
[Epoch 1, Batch 1500] loss: 0.17854952849447728
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1943
Validation Accuracy: 0.9417
Overfitting: 0.1943
[Epoch 2, Batch 100] loss: 0.18522809887304903
[Epoch 2, Batch 200] loss: 0.16598315693438054
[Epoch 2, Batch 300] loss: 0.18147028557956218
[Epoch 2, Batch 400] loss: 0.17604054529219865
[Epoch 2, Batch 500] loss: 0.1411828221194446
[Epoch 2, Batch 600] loss: 0.16066244173794986
[Epoch 2, Batch 700] loss: 0.16080675940960645
[Epoch 2, Batch 800] loss: 0.15314279086887836
[Epoch 2, Batch 900] loss: 0.14048834746703506
[Epoch 2, Batch 1000] loss: 0.1325095457956195
[Epoch 2, Batch 1100] loss: 0.13332894113846122
[Epoch 2, Batch 1200] loss: 0.11813310188241304
[Epoch 2, Batch 1300] loss: 0.1022071204893291
[Epoch 2, Batch 1400] loss: 0.12479044826701284
[Epoch 2, Batch 1500] loss: 0.09896548263728619
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1154
Validation Accuracy: 0.9646
Overfitting: 0.1154
[Epoch 3, Batch 100] loss: 0.08287550811190159
[Epoch 3, Batch 200] loss: 0.11641031076200306
[Epoch 3, Batch 300] loss: 0.10589237939566373
[Epoch 3, Batch 400] loss: 0.09526396971195936
[Epoch 3, Batch 500] loss: 0.10998266075737774
[Epoch 3, Batch 600] loss: 0.0947652655467391
[Epoch 3, Batch 700] loss: 0.09660609515383839
[Epoch 3, Batch 800] loss: 0.08592004831880332
[Epoch 3, Batch 900] loss: 0.10257499636150896
[Epoch 3, Batch 1000] loss: 0.10323919598944485
[Epoch 3, Batch 1100] loss: 0.1015428476780653
[Epoch 3, Batch 1200] loss: 0.08252641363535076
[Epoch 3, Batch 1300] loss: 0.08707224917598069
[Epoch 3, Batch 1400] loss: 0.08623118446208537
[Epoch 3, Batch 1500] loss: 0.08041719314642251
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0994
Validation Accuracy: 0.9702
Overfitting: 0.0994
[Epoch 4, Batch 100] loss: 0.0766851672064513
[Epoch 4, Batch 200] loss: 0.07501138932071626
[Epoch 4, Batch 300] loss: 0.07810730305034667
[Epoch 4, Batch 400] loss: 0.0850977673381567
[Epoch 4, Batch 500] loss: 0.08067718400619923
[Epoch 4, Batch 600] loss: 0.061349512437591326
[Epoch 4, Batch 700] loss: 0.07716439163777977
[Epoch 4, Batch 800] loss: 0.08390982564073056
[Epoch 4, Batch 900] loss: 0.0728381117596291
[Epoch 4, Batch 1000] loss: 0.07790848530363291
[Epoch 4, Batch 1100] loss: 0.07668375425506384
[Epoch 4, Batch 1200] loss: 0.07171415059827269
[Epoch 4, Batch 1300] loss: 0.06546725464053452
[Epoch 4, Batch 1400] loss: 0.06673428399721161
[Epoch 4, Batch 1500] loss: 0.05641103877685964
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0862
Validation Accuracy: 0.9735
Overfitting: 0.0862
[Epoch 5, Batch 100] loss: 0.055052498946897684
[Epoch 5, Batch 200] loss: 0.05942680005449802
[Epoch 5, Batch 300] loss: 0.04614152878522873
[Epoch 5, Batch 400] loss: 0.07466343156062066
[Epoch 5, Batch 500] loss: 0.06606150463456288
[Epoch 5, Batch 600] loss: 0.059431441142223776
[Epoch 5, Batch 700] loss: 0.055643883063457904
[Epoch 5, Batch 800] loss: 0.06004550759214908
[Epoch 5, Batch 900] loss: 0.07190837409580127
[Epoch 5, Batch 1000] loss: 0.06706991251092403
[Epoch 5, Batch 1100] loss: 0.06788680296158418
[Epoch 5, Batch 1200] loss: 0.0558601947221905
[Epoch 5, Batch 1300] loss: 0.060761862394865605
[Epoch 5, Batch 1400] loss: 0.05012784786958946
[Epoch 5, Batch 1500] loss: 0.06464802129077725
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0701
Validation Accuracy: 0.9779
Overfitting: 0.0701
[Epoch 6, Batch 100] loss: 0.04283697443315759
[Epoch 6, Batch 200] loss: 0.03868476535426453
[Epoch 6, Batch 300] loss: 0.053907433117274195
[Epoch 6, Batch 400] loss: 0.0565066595247481
[Epoch 6, Batch 500] loss: 0.07305150555330328
[Epoch 6, Batch 600] loss: 0.06431306107202545
[Epoch 6, Batch 700] loss: 0.05113388150231913
[Epoch 6, Batch 800] loss: 0.0436252431262983
[Epoch 6, Batch 900] loss: 0.05874549198895693
[Epoch 6, Batch 1000] loss: 0.050421831809799186
[Epoch 6, Batch 1100] loss: 0.04663686629151925
[Epoch 6, Batch 1200] loss: 0.05285192392533645
[Epoch 6, Batch 1300] loss: 0.050509120649658144
[Epoch 6, Batch 1400] loss: 0.051650348184630275
[Epoch 6, Batch 1500] loss: 0.04803148488805164
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0666
Validation Accuracy: 0.9792
Overfitting: 0.0666
[Epoch 7, Batch 100] loss: 0.05031876954657491
[Epoch 7, Batch 200] loss: 0.03479905582615175
[Epoch 7, Batch 300] loss: 0.049848438818007705
[Epoch 7, Batch 400] loss: 0.03207266468089074
[Epoch 7, Batch 500] loss: 0.04531329661840573
[Epoch 7, Batch 600] loss: 0.048930635405122304
[Epoch 7, Batch 700] loss: 0.04679523802944459
[Epoch 7, Batch 800] loss: 0.05038467227597721
[Epoch 7, Batch 900] loss: 0.04733311296789907
[Epoch 7, Batch 1000] loss: 0.0524302530195564
[Epoch 7, Batch 1100] loss: 0.044935510845389215
[Epoch 7, Batch 1200] loss: 0.04522536841221154
[Epoch 7, Batch 1300] loss: 0.04436305712733883
[Epoch 7, Batch 1400] loss: 0.04385464092949405
[Epoch 7, Batch 1500] loss: 0.04070797684951685
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0592
Validation Accuracy: 0.9809
Overfitting: 0.0592
[Epoch 8, Batch 100] loss: 0.0412625684926752
[Epoch 8, Batch 200] loss: 0.04101002694282215
[Epoch 8, Batch 300] loss: 0.04070006433175877
[Epoch 8, Batch 400] loss: 0.034186581150861456
[Epoch 8, Batch 500] loss: 0.03671177041600458
[Epoch 8, Batch 600] loss: 0.04257673034095205
[Epoch 8, Batch 700] loss: 0.04468160422286019
[Epoch 8, Batch 800] loss: 0.05148484643199481
[Epoch 8, Batch 900] loss: 0.03838227274361998
[Epoch 8, Batch 1000] loss: 0.04595977021963336
[Epoch 8, Batch 1100] loss: 0.04455388333881274
[Epoch 8, Batch 1200] loss: 0.03324082612351049
[Epoch 8, Batch 1300] loss: 0.031349239881965335
[Epoch 8, Batch 1400] loss: 0.03790158310555853
[Epoch 8, Batch 1500] loss: 0.04269669102155604
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0574
Validation Accuracy: 0.9822
Overfitting: 0.0574
[Epoch 9, Batch 100] loss: 0.031706835466320624
[Epoch 9, Batch 200] loss: 0.025491667187015992
[Epoch 9, Batch 300] loss: 0.03935426707903389
[Epoch 9, Batch 400] loss: 0.029966247995616868
[Epoch 9, Batch 500] loss: 0.037120825949241404
[Epoch 9, Batch 600] loss: 0.02768588731298223
[Epoch 9, Batch 700] loss: 0.04242230423173168
[Epoch 9, Batch 800] loss: 0.052414520034362796
[Epoch 9, Batch 900] loss: 0.04596255350159481
[Epoch 9, Batch 1000] loss: 0.03242764486116357
[Epoch 9, Batch 1100] loss: 0.036672338781645525
[Epoch 9, Batch 1200] loss: 0.03563358350133058
[Epoch 9, Batch 1300] loss: 0.03487621121326811
[Epoch 9, Batch 1400] loss: 0.03924847463029437
[Epoch 9, Batch 1500] loss: 0.04167334434983786
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9841
Overfitting: 0.0539
Best model saved at epoch 9 with validation loss: 0.0539
[Epoch 10, Batch 100] loss: 0.0338963474414777
[Epoch 10, Batch 200] loss: 0.03439079216506798
[Epoch 10, Batch 300] loss: 0.03298272131796694
[Epoch 10, Batch 400] loss: 0.035138381949509495
[Epoch 10, Batch 500] loss: 0.024814899574266747
[Epoch 10, Batch 600] loss: 0.03143617248570081
[Epoch 10, Batch 700] loss: 0.035025611824239605
[Epoch 10, Batch 800] loss: 0.02416584996273741
[Epoch 10, Batch 900] loss: 0.031041696495958605
[Epoch 10, Batch 1000] loss: 0.03034317913290579
[Epoch 10, Batch 1100] loss: 0.023401087446545718
[Epoch 10, Batch 1200] loss: 0.026530379032774363
[Epoch 10, Batch 1300] loss: 0.03214063268816972
[Epoch 10, Batch 1400] loss: 0.044992236325051636
[Epoch 10, Batch 1500] loss: 0.038164019379764796
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0620
Validation Accuracy: 0.9813
Overfitting: 0.0620
[Epoch 11, Batch 100] loss: 0.021347991786606145
[Epoch 11, Batch 200] loss: 0.03140499539440498
[Epoch 11, Batch 300] loss: 0.025067662697401828
[Epoch 11, Batch 400] loss: 0.024974316246516536
[Epoch 11, Batch 500] loss: 0.025952673183928708
[Epoch 11, Batch 600] loss: 0.025202002746518702
[Epoch 11, Batch 700] loss: 0.02074240203932277
[Epoch 11, Batch 800] loss: 0.023493861944880335
[Epoch 11, Batch 900] loss: 0.03024895718845073
[Epoch 11, Batch 1000] loss: 0.03448790180758806
[Epoch 11, Batch 1100] loss: 0.026910117246443405
[Epoch 11, Batch 1200] loss: 0.02979262694803765
[Epoch 11, Batch 1300] loss: 0.02750592541968217
[Epoch 11, Batch 1400] loss: 0.04510340331238694
[Epoch 11, Batch 1500] loss: 0.031823720934335144
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9847
Overfitting: 0.0526
Early stopping epoch 11 for trial 9. Moving to next fold.
Fold 2 validation loss: 0.0526
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2966965889930724
[Epoch 1, Batch 200] loss: 2.2429676032066346
[Epoch 1, Batch 300] loss: 1.9665561044216155
[Epoch 1, Batch 400] loss: 1.0723849925398827
[Epoch 1, Batch 500] loss: 0.6404166060686112
[Epoch 1, Batch 600] loss: 0.5229998660087586
[Epoch 1, Batch 700] loss: 0.4178127950429916
[Epoch 1, Batch 800] loss: 0.4142796468734741
[Epoch 1, Batch 900] loss: 0.3707622654736042
[Epoch 1, Batch 1000] loss: 0.34186893090605736
[Epoch 1, Batch 1100] loss: 0.29584831684827806
[Epoch 1, Batch 1200] loss: 0.2924999160319567
[Epoch 1, Batch 1300] loss: 0.2845032523944974
[Epoch 1, Batch 1400] loss: 0.2517266313359141
[Epoch 1, Batch 1500] loss: 0.26443669643253087
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2620
Validation Accuracy: 0.9182
Overfitting: 0.2620
[Epoch 2, Batch 100] loss: 0.2218926127254963
[Epoch 2, Batch 200] loss: 0.20702418260276317
[Epoch 2, Batch 300] loss: 0.2100027909129858
[Epoch 2, Batch 400] loss: 0.1930513240210712
[Epoch 2, Batch 500] loss: 0.1942354793474078
[Epoch 2, Batch 600] loss: 0.16397356068715452
[Epoch 2, Batch 700] loss: 0.16594269772991538
[Epoch 2, Batch 800] loss: 0.15713494246825577
[Epoch 2, Batch 900] loss: 0.15447748266160488
[Epoch 2, Batch 1000] loss: 0.16213860318996012
[Epoch 2, Batch 1100] loss: 0.1522990738879889
[Epoch 2, Batch 1200] loss: 0.15294400162994862
[Epoch 2, Batch 1300] loss: 0.14147963722236453
[Epoch 2, Batch 1400] loss: 0.1309834347292781
[Epoch 2, Batch 1500] loss: 0.12264930414035917
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1237
Validation Accuracy: 0.9626
Overfitting: 0.1237
[Epoch 3, Batch 100] loss: 0.12231820125132799
[Epoch 3, Batch 200] loss: 0.12991057762876154
[Epoch 3, Batch 300] loss: 0.12686613176018
[Epoch 3, Batch 400] loss: 0.11772017525509
[Epoch 3, Batch 500] loss: 0.11179422977380454
[Epoch 3, Batch 600] loss: 0.11512439986690878
[Epoch 3, Batch 700] loss: 0.10303438520990311
[Epoch 3, Batch 800] loss: 0.11654294644482434
[Epoch 3, Batch 900] loss: 0.10049858432263135
[Epoch 3, Batch 1000] loss: 0.10756803366355598
[Epoch 3, Batch 1100] loss: 0.09220177207607776
[Epoch 3, Batch 1200] loss: 0.09807778458110988
[Epoch 3, Batch 1300] loss: 0.0822821445390582
[Epoch 3, Batch 1400] loss: 0.07943992018233985
[Epoch 3, Batch 1500] loss: 0.08800658954307437
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1318
Validation Accuracy: 0.9593
Overfitting: 0.1318
[Epoch 4, Batch 100] loss: 0.09081337217707187
[Epoch 4, Batch 200] loss: 0.09094772822223604
[Epoch 4, Batch 300] loss: 0.08093940916471183
[Epoch 4, Batch 400] loss: 0.07930796707980335
[Epoch 4, Batch 500] loss: 0.08289223008323461
[Epoch 4, Batch 600] loss: 0.08508384928805754
[Epoch 4, Batch 700] loss: 0.08510999135905876
[Epoch 4, Batch 800] loss: 0.07906829457264393
[Epoch 4, Batch 900] loss: 0.06371799467829987
[Epoch 4, Batch 1000] loss: 0.07948241052683443
[Epoch 4, Batch 1100] loss: 0.07238775232573971
[Epoch 4, Batch 1200] loss: 0.0779621195886284
[Epoch 4, Batch 1300] loss: 0.08191548679722473
[Epoch 4, Batch 1400] loss: 0.07182273847516626
[Epoch 4, Batch 1500] loss: 0.07519434571266174
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0811
Validation Accuracy: 0.9751
Overfitting: 0.0811
[Epoch 5, Batch 100] loss: 0.062110282336361705
[Epoch 5, Batch 200] loss: 0.0672877419507131
[Epoch 5, Batch 300] loss: 0.07674726407974958
[Epoch 5, Batch 400] loss: 0.05969359251554124
[Epoch 5, Batch 500] loss: 0.05959156380733475
[Epoch 5, Batch 600] loss: 0.07884180181892589
[Epoch 5, Batch 700] loss: 0.06413205064600333
[Epoch 5, Batch 800] loss: 0.06492811462841928
[Epoch 5, Batch 900] loss: 0.061443671341985466
[Epoch 5, Batch 1000] loss: 0.06491682801861316
[Epoch 5, Batch 1100] loss: 0.06296694752527401
[Epoch 5, Batch 1200] loss: 0.06515113574452698
[Epoch 5, Batch 1300] loss: 0.06322108961641788
[Epoch 5, Batch 1400] loss: 0.0641660400602268
[Epoch 5, Batch 1500] loss: 0.06277215976500884
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0806
Validation Accuracy: 0.9746
Overfitting: 0.0806
[Epoch 6, Batch 100] loss: 0.055117849740199745
[Epoch 6, Batch 200] loss: 0.050490287635475396
[Epoch 6, Batch 300] loss: 0.04905959473690018
[Epoch 6, Batch 400] loss: 0.052935040851589295
[Epoch 6, Batch 500] loss: 0.051181812464492396
[Epoch 6, Batch 600] loss: 0.055674622926162556
[Epoch 6, Batch 700] loss: 0.05919740588171408
[Epoch 6, Batch 800] loss: 0.054945637506898494
[Epoch 6, Batch 900] loss: 0.05238752651493996
[Epoch 6, Batch 1000] loss: 0.06893952602753416
[Epoch 6, Batch 1100] loss: 0.0640626385208452
[Epoch 6, Batch 1200] loss: 0.05594848219538107
[Epoch 6, Batch 1300] loss: 0.062480720159364865
[Epoch 6, Batch 1400] loss: 0.04419764675432816
[Epoch 6, Batch 1500] loss: 0.05752727445913479
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0680
Validation Accuracy: 0.9789
Overfitting: 0.0680
[Epoch 7, Batch 100] loss: 0.04044900587759912
[Epoch 7, Batch 200] loss: 0.04203797952155583
[Epoch 7, Batch 300] loss: 0.04601224987069145
[Epoch 7, Batch 400] loss: 0.045625459525035696
[Epoch 7, Batch 500] loss: 0.05191985104844207
[Epoch 7, Batch 600] loss: 0.05734433592879214
[Epoch 7, Batch 700] loss: 0.03839541125576943
[Epoch 7, Batch 800] loss: 0.05012258758069947
[Epoch 7, Batch 900] loss: 0.043010207570623606
[Epoch 7, Batch 1000] loss: 0.04994893152150325
[Epoch 7, Batch 1100] loss: 0.05452596859307959
[Epoch 7, Batch 1200] loss: 0.05356707609025761
[Epoch 7, Batch 1300] loss: 0.05495210196240805
[Epoch 7, Batch 1400] loss: 0.05557494029751979
[Epoch 7, Batch 1500] loss: 0.0458053270552773
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0562
Validation Accuracy: 0.9831
Overfitting: 0.0562
[Epoch 8, Batch 100] loss: 0.037211130182258786
[Epoch 8, Batch 200] loss: 0.030671838827547617
[Epoch 8, Batch 300] loss: 0.040207539506955076
[Epoch 8, Batch 400] loss: 0.03958133032429032
[Epoch 8, Batch 500] loss: 0.03769064645399339
[Epoch 8, Batch 600] loss: 0.05291793796583079
[Epoch 8, Batch 700] loss: 0.04606047159526497
[Epoch 8, Batch 800] loss: 0.03710897587356157
[Epoch 8, Batch 900] loss: 0.0339386728417594
[Epoch 8, Batch 1000] loss: 0.046637346401112154
[Epoch 8, Batch 1100] loss: 0.056850565299391746
[Epoch 8, Batch 1200] loss: 0.048269042640458795
[Epoch 8, Batch 1300] loss: 0.04756302564172074
[Epoch 8, Batch 1400] loss: 0.03913557286199648
[Epoch 8, Batch 1500] loss: 0.0372459922923008
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9831
Overfitting: 0.0552
[Epoch 9, Batch 100] loss: 0.03502875583522837
[Epoch 9, Batch 200] loss: 0.039107777170138434
[Epoch 9, Batch 300] loss: 0.03420305368257687
[Epoch 9, Batch 400] loss: 0.03750629380170722
[Epoch 9, Batch 500] loss: 0.03296180894161807
[Epoch 9, Batch 600] loss: 0.036563025205396116
[Epoch 9, Batch 700] loss: 0.031213623582734728
[Epoch 9, Batch 800] loss: 0.03707034829712939
[Epoch 9, Batch 900] loss: 0.03625561266613658
[Epoch 9, Batch 1000] loss: 0.033720794902474156
[Epoch 9, Batch 1100] loss: 0.03903496561804786
[Epoch 9, Batch 1200] loss: 0.0466752203379292
[Epoch 9, Batch 1300] loss: 0.04920198858017102
[Epoch 9, Batch 1400] loss: 0.03892261142609641
[Epoch 9, Batch 1500] loss: 0.037118128297734074
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0547
Validation Accuracy: 0.9836
Overfitting: 0.0547
Best model saved at epoch 9 with validation loss: 0.0547
[Epoch 10, Batch 100] loss: 0.028743920747074297
[Epoch 10, Batch 200] loss: 0.03417092485266039
[Epoch 10, Batch 300] loss: 0.03059325205074856
[Epoch 10, Batch 400] loss: 0.034707159242243504
[Epoch 10, Batch 500] loss: 0.03253216473851353
[Epoch 10, Batch 600] loss: 0.03159102044708561
[Epoch 10, Batch 700] loss: 0.02514141105741146
[Epoch 10, Batch 800] loss: 0.036611130505334585
[Epoch 10, Batch 900] loss: 0.02491052561555989
[Epoch 10, Batch 1000] loss: 0.04189268991787685
[Epoch 10, Batch 1100] loss: 0.03579909199819667
[Epoch 10, Batch 1200] loss: 0.03578696678683627
[Epoch 10, Batch 1300] loss: 0.03318938829936087
[Epoch 10, Batch 1400] loss: 0.028833989850245417
[Epoch 10, Batch 1500] loss: 0.03548278278060025
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0490
Validation Accuracy: 0.9851
Overfitting: 0.0490
[Epoch 11, Batch 100] loss: 0.023423595507338177
[Epoch 11, Batch 200] loss: 0.021700238259654725
[Epoch 11, Batch 300] loss: 0.024299128986895083
[Epoch 11, Batch 400] loss: 0.028464616389246657
[Epoch 11, Batch 500] loss: 0.037267303647240624
[Epoch 11, Batch 600] loss: 0.029786982407385948
[Epoch 11, Batch 700] loss: 0.028033710048766806
[Epoch 11, Batch 800] loss: 0.0257679573414498
[Epoch 11, Batch 900] loss: 0.019852466424054
[Epoch 11, Batch 1000] loss: 0.027501932060113178
[Epoch 11, Batch 1100] loss: 0.040064235360478054
[Epoch 11, Batch 1200] loss: 0.0277588929788908
[Epoch 11, Batch 1300] loss: 0.03488071865751408
[Epoch 11, Batch 1400] loss: 0.030291561094927602
[Epoch 11, Batch 1500] loss: 0.03627850391363609
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0530
Validation Accuracy: 0.9831
Overfitting: 0.0530
Early stopping epoch 11 for trial 9. Moving to next fold.
Fold 3 validation loss: 0.0530
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.3026289916038514
[Epoch 1, Batch 200] loss: 2.2938530921936033
[Epoch 1, Batch 300] loss: 2.2785327506065367
[Epoch 1, Batch 400] loss: 2.24572639465332
[Epoch 1, Batch 500] loss: 2.1065954852104185
[Epoch 1, Batch 600] loss: 1.2754837781190873
[Epoch 1, Batch 700] loss: 0.5988548916578292
[Epoch 1, Batch 800] loss: 0.44679578244686124
[Epoch 1, Batch 900] loss: 0.37628940992057325
[Epoch 1, Batch 1000] loss: 0.3645773556083441
[Epoch 1, Batch 1100] loss: 0.30450651459395883
[Epoch 1, Batch 1200] loss: 0.2936742660030723
[Epoch 1, Batch 1300] loss: 0.2775047529488802
[Epoch 1, Batch 1400] loss: 0.23418441575020552
[Epoch 1, Batch 1500] loss: 0.23140413768589496
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2114
Validation Accuracy: 0.9346
Overfitting: 0.2114
[Epoch 2, Batch 100] loss: 0.22632405515760184
[Epoch 2, Batch 200] loss: 0.2063578860461712
[Epoch 2, Batch 300] loss: 0.18145592376589775
[Epoch 2, Batch 400] loss: 0.1972691143490374
[Epoch 2, Batch 500] loss: 0.1544371364451945
[Epoch 2, Batch 600] loss: 0.17233253484591843
[Epoch 2, Batch 700] loss: 0.15288331353105605
[Epoch 2, Batch 800] loss: 0.15599891366437077
[Epoch 2, Batch 900] loss: 0.1506147415470332
[Epoch 2, Batch 1000] loss: 0.14251251520588995
[Epoch 2, Batch 1100] loss: 0.1530469024553895
[Epoch 2, Batch 1200] loss: 0.15307912037707866
[Epoch 2, Batch 1300] loss: 0.14528501853812487
[Epoch 2, Batch 1400] loss: 0.13607754351571202
[Epoch 2, Batch 1500] loss: 0.12337272861972451
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1201
Validation Accuracy: 0.9627
Overfitting: 0.1201
[Epoch 3, Batch 100] loss: 0.1097908120090142
[Epoch 3, Batch 200] loss: 0.12815603621304036
[Epoch 3, Batch 300] loss: 0.1139932557567954
[Epoch 3, Batch 400] loss: 0.10164658227469772
[Epoch 3, Batch 500] loss: 0.11492649509105832
[Epoch 3, Batch 600] loss: 0.11827904826961458
[Epoch 3, Batch 700] loss: 0.10258510652929545
[Epoch 3, Batch 800] loss: 0.1098776222486049
[Epoch 3, Batch 900] loss: 0.11048454291187226
[Epoch 3, Batch 1000] loss: 0.11099193468689919
[Epoch 3, Batch 1100] loss: 0.10048609434161335
[Epoch 3, Batch 1200] loss: 0.08945212827995419
[Epoch 3, Batch 1300] loss: 0.106192734898068
[Epoch 3, Batch 1400] loss: 0.0984798632748425
[Epoch 3, Batch 1500] loss: 0.10327648185193539
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1060
Validation Accuracy: 0.9657
Overfitting: 0.1060
[Epoch 4, Batch 100] loss: 0.08756365308305249
[Epoch 4, Batch 200] loss: 0.08931897208560258
[Epoch 4, Batch 300] loss: 0.07455653904471546
[Epoch 4, Batch 400] loss: 0.09054770288523287
[Epoch 4, Batch 500] loss: 0.0954795149108395
[Epoch 4, Batch 600] loss: 0.08975895953830332
[Epoch 4, Batch 700] loss: 0.08120177149772644
[Epoch 4, Batch 800] loss: 0.08444582538213581
[Epoch 4, Batch 900] loss: 0.0850568553688936
[Epoch 4, Batch 1000] loss: 0.07523594257887453
[Epoch 4, Batch 1100] loss: 0.08941281266743317
[Epoch 4, Batch 1200] loss: 0.06605335799045861
[Epoch 4, Batch 1300] loss: 0.07694800303666853
[Epoch 4, Batch 1400] loss: 0.09434463819488884
[Epoch 4, Batch 1500] loss: 0.08081622216384858
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0738
Validation Accuracy: 0.9782
Overfitting: 0.0738
[Epoch 5, Batch 100] loss: 0.07013863336760551
[Epoch 5, Batch 200] loss: 0.06768657269887626
[Epoch 5, Batch 300] loss: 0.076262838402763
[Epoch 5, Batch 400] loss: 0.09517173555446788
[Epoch 5, Batch 500] loss: 0.06406986005837098
[Epoch 5, Batch 600] loss: 0.06430761179421098
[Epoch 5, Batch 700] loss: 0.07535788680659607
[Epoch 5, Batch 800] loss: 0.07905114050256089
[Epoch 5, Batch 900] loss: 0.07262772281421348
[Epoch 5, Batch 1000] loss: 0.05868365050293505
[Epoch 5, Batch 1100] loss: 0.05710778694599867
[Epoch 5, Batch 1200] loss: 0.0631137027835939
[Epoch 5, Batch 1300] loss: 0.06890063268132508
[Epoch 5, Batch 1400] loss: 0.05633568738005124
[Epoch 5, Batch 1500] loss: 0.06196198421297595
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0713
Validation Accuracy: 0.9766
Overfitting: 0.0713
[Epoch 6, Batch 100] loss: 0.06738517158781178
[Epoch 6, Batch 200] loss: 0.060828997388016434
[Epoch 6, Batch 300] loss: 0.0644114430854097
[Epoch 6, Batch 400] loss: 0.06590443891007453
[Epoch 6, Batch 500] loss: 0.05407455652020872
[Epoch 6, Batch 600] loss: 0.051660333323525265
[Epoch 6, Batch 700] loss: 0.06707289146492258
[Epoch 6, Batch 800] loss: 0.048279113164753654
[Epoch 6, Batch 900] loss: 0.06215394847095013
[Epoch 6, Batch 1000] loss: 0.06632703515817412
[Epoch 6, Batch 1100] loss: 0.05725748451892287
[Epoch 6, Batch 1200] loss: 0.04671542121563107
[Epoch 6, Batch 1300] loss: 0.060828239073744045
[Epoch 6, Batch 1400] loss: 0.04996922408230603
[Epoch 6, Batch 1500] loss: 0.06474077443592251
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0610
Validation Accuracy: 0.9810
Overfitting: 0.0610
[Epoch 7, Batch 100] loss: 0.03497057632135693
[Epoch 7, Batch 200] loss: 0.056065213293768464
[Epoch 7, Batch 300] loss: 0.057199279587948695
[Epoch 7, Batch 400] loss: 0.05312266671913676
[Epoch 7, Batch 500] loss: 0.05430061678867787
[Epoch 7, Batch 600] loss: 0.04888126969803125
[Epoch 7, Batch 700] loss: 0.05280777926091105
[Epoch 7, Batch 800] loss: 0.051394094431307165
[Epoch 7, Batch 900] loss: 0.05486320027615875
[Epoch 7, Batch 1000] loss: 0.05136187618598342
[Epoch 7, Batch 1100] loss: 0.06166229118476622
[Epoch 7, Batch 1200] loss: 0.047854926207801324
[Epoch 7, Batch 1300] loss: 0.043362977114738896
[Epoch 7, Batch 1400] loss: 0.04657702560769394
[Epoch 7, Batch 1500] loss: 0.0468000110425055
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9808
Overfitting: 0.0636
[Epoch 8, Batch 100] loss: 0.04543490848736838
[Epoch 8, Batch 200] loss: 0.04374477260396816
[Epoch 8, Batch 300] loss: 0.037525335524696855
[Epoch 8, Batch 400] loss: 0.04532740788650699
[Epoch 8, Batch 500] loss: 0.04382149764569476
[Epoch 8, Batch 600] loss: 0.044222167790867385
[Epoch 8, Batch 700] loss: 0.05704995058709755
[Epoch 8, Batch 800] loss: 0.06416400794521905
[Epoch 8, Batch 900] loss: 0.040387658863328395
[Epoch 8, Batch 1000] loss: 0.049186951269512065
[Epoch 8, Batch 1100] loss: 0.04833581198588945
[Epoch 8, Batch 1200] loss: 0.04705529201193712
[Epoch 8, Batch 1300] loss: 0.04314467444201
[Epoch 8, Batch 1400] loss: 0.038081919073592874
[Epoch 8, Batch 1500] loss: 0.042558284664992244
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9838
Overfitting: 0.0528
[Epoch 9, Batch 100] loss: 0.03120425232918933
[Epoch 9, Batch 200] loss: 0.0420121310884133
[Epoch 9, Batch 300] loss: 0.04321158568840474
[Epoch 9, Batch 400] loss: 0.04274552246730309
[Epoch 9, Batch 500] loss: 0.04303318271762691
[Epoch 9, Batch 600] loss: 0.04591111693182029
[Epoch 9, Batch 700] loss: 0.03481813841732219
[Epoch 9, Batch 800] loss: 0.04230482103652321
[Epoch 9, Batch 900] loss: 0.033880276482668704
[Epoch 9, Batch 1000] loss: 0.03624383107002359
[Epoch 9, Batch 1100] loss: 0.040121873600874096
[Epoch 9, Batch 1200] loss: 0.044436045937472954
[Epoch 9, Batch 1300] loss: 0.05017886118177557
[Epoch 9, Batch 1400] loss: 0.04002583146560937
[Epoch 9, Batch 1500] loss: 0.032843707021092995
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9827
Overfitting: 0.0554
Best model saved at epoch 9 with validation loss: 0.0554
[Epoch 10, Batch 100] loss: 0.026485416960786098
[Epoch 10, Batch 200] loss: 0.04051235516672023
[Epoch 10, Batch 300] loss: 0.03231268069939688
[Epoch 10, Batch 400] loss: 0.0337327651376836
[Epoch 10, Batch 500] loss: 0.0442958869272843
[Epoch 10, Batch 600] loss: 0.0301133984408807
[Epoch 10, Batch 700] loss: 0.04517417140130419
[Epoch 10, Batch 800] loss: 0.028726097535109147
[Epoch 10, Batch 900] loss: 0.04815810051339213
[Epoch 10, Batch 1000] loss: 0.03239097132172901
[Epoch 10, Batch 1100] loss: 0.03682858505519107
[Epoch 10, Batch 1200] loss: 0.03330211339751259
[Epoch 10, Batch 1300] loss: 0.03910653597675264
[Epoch 10, Batch 1400] loss: 0.03354037352488376
[Epoch 10, Batch 1500] loss: 0.036681479865801524
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9812
Overfitting: 0.0606
[Epoch 11, Batch 100] loss: 0.03898123604652937
[Epoch 11, Batch 200] loss: 0.027829148688470015
[Epoch 11, Batch 300] loss: 0.03960805549519136
[Epoch 11, Batch 400] loss: 0.048627689223503696
[Epoch 11, Batch 500] loss: 0.030224209130974487
[Epoch 11, Batch 600] loss: 0.028809396831784396
[Epoch 11, Batch 700] loss: 0.02825450413452927
[Epoch 11, Batch 800] loss: 0.03613647014426533
[Epoch 11, Batch 900] loss: 0.03039322213619016
[Epoch 11, Batch 1000] loss: 0.03411546813149471
[Epoch 11, Batch 1100] loss: 0.037730407744529654
[Epoch 11, Batch 1200] loss: 0.02187211778771598
[Epoch 11, Batch 1300] loss: 0.03249199945072178
[Epoch 11, Batch 1400] loss: 0.034346542253042574
[Epoch 11, Batch 1500] loss: 0.02085191807986121
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0557
Validation Accuracy: 0.9816
Overfitting: 0.0557
Early stopping epoch 11 for trial 9. Moving to next fold.
Fold 4 validation loss: 0.0557
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.3005171990394593
[Epoch 1, Batch 200] loss: 2.293147602081299
[Epoch 1, Batch 300] loss: 2.2797339177131652
[Epoch 1, Batch 400] loss: 2.246772861480713
[Epoch 1, Batch 500] loss: 2.1397191429138185
[Epoch 1, Batch 600] loss: 1.5249334520101547
[Epoch 1, Batch 700] loss: 0.6386075168848038
[Epoch 1, Batch 800] loss: 0.4710899221897125
[Epoch 1, Batch 900] loss: 0.3709929444640875
[Epoch 1, Batch 1000] loss: 0.33891700096428395
[Epoch 1, Batch 1100] loss: 0.2872476240247488
[Epoch 1, Batch 1200] loss: 0.2557756051793694
[Epoch 1, Batch 1300] loss: 0.2605500415712595
[Epoch 1, Batch 1400] loss: 0.2413255549967289
[Epoch 1, Batch 1500] loss: 0.21055963788181542
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2262
Validation Accuracy: 0.9312
Overfitting: 0.2262
[Epoch 2, Batch 100] loss: 0.19035431881435216
[Epoch 2, Batch 200] loss: 0.18446895495057106
[Epoch 2, Batch 300] loss: 0.16947812386788427
[Epoch 2, Batch 400] loss: 0.1871940728649497
[Epoch 2, Batch 500] loss: 0.162877958342433
[Epoch 2, Batch 600] loss: 0.152876282222569
[Epoch 2, Batch 700] loss: 0.15364937745034696
[Epoch 2, Batch 800] loss: 0.1448425128031522
[Epoch 2, Batch 900] loss: 0.1268731853365898
[Epoch 2, Batch 1000] loss: 0.1455400043912232
[Epoch 2, Batch 1100] loss: 0.14039663930423557
[Epoch 2, Batch 1200] loss: 0.14124284347519278
[Epoch 2, Batch 1300] loss: 0.127008609585464
[Epoch 2, Batch 1400] loss: 0.12058657946996391
[Epoch 2, Batch 1500] loss: 0.12044214056804776
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1146
Validation Accuracy: 0.9663
Overfitting: 0.1146
[Epoch 3, Batch 100] loss: 0.10306170578114689
[Epoch 3, Batch 200] loss: 0.11287578377872705
[Epoch 3, Batch 300] loss: 0.10609142094384878
[Epoch 3, Batch 400] loss: 0.0919948775973171
[Epoch 3, Batch 500] loss: 0.09450566479936243
[Epoch 3, Batch 600] loss: 0.11431274369359017
[Epoch 3, Batch 700] loss: 0.0959087850432843
[Epoch 3, Batch 800] loss: 0.10703959438484162
[Epoch 3, Batch 900] loss: 0.1028779189195484
[Epoch 3, Batch 1000] loss: 0.08986817722208798
[Epoch 3, Batch 1100] loss: 0.09679416563827545
[Epoch 3, Batch 1200] loss: 0.09861670435871929
[Epoch 3, Batch 1300] loss: 0.09494116281159222
[Epoch 3, Batch 1400] loss: 0.0872017626138404
[Epoch 3, Batch 1500] loss: 0.10763877493329346
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0827
Validation Accuracy: 0.9765
Overfitting: 0.0827
[Epoch 4, Batch 100] loss: 0.07341109282802791
[Epoch 4, Batch 200] loss: 0.0751567910099402
[Epoch 4, Batch 300] loss: 0.08337925603846089
[Epoch 4, Batch 400] loss: 0.08592002964112908
[Epoch 4, Batch 500] loss: 0.0664385248022154
[Epoch 4, Batch 600] loss: 0.08558129644021392
[Epoch 4, Batch 700] loss: 0.0745605315733701
[Epoch 4, Batch 800] loss: 0.07536524730967357
[Epoch 4, Batch 900] loss: 0.08331486254697666
[Epoch 4, Batch 1000] loss: 0.07051492128521204
[Epoch 4, Batch 1100] loss: 0.07208015784388408
[Epoch 4, Batch 1200] loss: 0.08042327422881498
[Epoch 4, Batch 1300] loss: 0.08421012273058295
[Epoch 4, Batch 1400] loss: 0.07576257403939962
[Epoch 4, Batch 1500] loss: 0.06939894409151748
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0760
Validation Accuracy: 0.9773
Overfitting: 0.0760
[Epoch 5, Batch 100] loss: 0.061954080963041634
[Epoch 5, Batch 200] loss: 0.06129450806882233
[Epoch 5, Batch 300] loss: 0.06718852174002678
[Epoch 5, Batch 400] loss: 0.06452324517420494
[Epoch 5, Batch 500] loss: 0.06352151990984567
[Epoch 5, Batch 600] loss: 0.06672316604759544
[Epoch 5, Batch 700] loss: 0.07848037653369828
[Epoch 5, Batch 800] loss: 0.05597145402105525
[Epoch 5, Batch 900] loss: 0.07602898296434432
[Epoch 5, Batch 1000] loss: 0.05939624585793354
[Epoch 5, Batch 1100] loss: 0.07542669875081628
[Epoch 5, Batch 1200] loss: 0.06737253786996007
[Epoch 5, Batch 1300] loss: 0.06152650482719764
[Epoch 5, Batch 1400] loss: 0.07197986257029697
[Epoch 5, Batch 1500] loss: 0.058596169435186314
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0648
Validation Accuracy: 0.9800
Overfitting: 0.0648
[Epoch 6, Batch 100] loss: 0.050506430662353524
[Epoch 6, Batch 200] loss: 0.06496187023120001
[Epoch 6, Batch 300] loss: 0.056244320885743944
[Epoch 6, Batch 400] loss: 0.053106180254835635
[Epoch 6, Batch 500] loss: 0.0635551309888251
[Epoch 6, Batch 600] loss: 0.060537118037464095
[Epoch 6, Batch 700] loss: 0.058477543393382805
[Epoch 6, Batch 800] loss: 0.07496078538242727
[Epoch 6, Batch 900] loss: 0.04628975396160968
[Epoch 6, Batch 1000] loss: 0.06285531394649296
[Epoch 6, Batch 1100] loss: 0.06068728668615222
[Epoch 6, Batch 1200] loss: 0.0474677753157448
[Epoch 6, Batch 1300] loss: 0.05655074515147135
[Epoch 6, Batch 1400] loss: 0.051024895628215744
[Epoch 6, Batch 1500] loss: 0.055633098649559544
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0614
Validation Accuracy: 0.9821
Overfitting: 0.0614
[Epoch 7, Batch 100] loss: 0.04524775392375886
[Epoch 7, Batch 200] loss: 0.06316210547694937
[Epoch 7, Batch 300] loss: 0.04628193254233338
[Epoch 7, Batch 400] loss: 0.04330712634488009
[Epoch 7, Batch 500] loss: 0.05161508123739623
[Epoch 7, Batch 600] loss: 0.04460137172834948
[Epoch 7, Batch 700] loss: 0.04205037638428621
[Epoch 7, Batch 800] loss: 0.05514381409797352
[Epoch 7, Batch 900] loss: 0.043321209128480406
[Epoch 7, Batch 1000] loss: 0.05469794715521857
[Epoch 7, Batch 1100] loss: 0.04645229167770595
[Epoch 7, Batch 1200] loss: 0.05226028196193511
[Epoch 7, Batch 1300] loss: 0.046824049167335034
[Epoch 7, Batch 1400] loss: 0.05561935790698044
[Epoch 7, Batch 1500] loss: 0.05629425955121405
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0632
Validation Accuracy: 0.9804
Overfitting: 0.0632
[Epoch 8, Batch 100] loss: 0.05427270627580583
[Epoch 8, Batch 200] loss: 0.04406235061062034
[Epoch 8, Batch 300] loss: 0.03728322529233992
[Epoch 8, Batch 400] loss: 0.04872290730942041
[Epoch 8, Batch 500] loss: 0.05671889026183635
[Epoch 8, Batch 600] loss: 0.0508905567904003
[Epoch 8, Batch 700] loss: 0.0405967392353341
[Epoch 8, Batch 800] loss: 0.040568184199510145
[Epoch 8, Batch 900] loss: 0.048370443197200075
[Epoch 8, Batch 1000] loss: 0.04347878909728024
[Epoch 8, Batch 1100] loss: 0.04669129853718914
[Epoch 8, Batch 1200] loss: 0.03460653749934863
[Epoch 8, Batch 1300] loss: 0.05528009313857183
[Epoch 8, Batch 1400] loss: 0.03803767876524944
[Epoch 8, Batch 1500] loss: 0.03682513545383699
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0557
Validation Accuracy: 0.9842
Overfitting: 0.0557
[Epoch 9, Batch 100] loss: 0.04327588487882167
[Epoch 9, Batch 200] loss: 0.03486904815887101
[Epoch 9, Batch 300] loss: 0.04207569946593139
[Epoch 9, Batch 400] loss: 0.038204212473210646
[Epoch 9, Batch 500] loss: 0.03796481473371387
[Epoch 9, Batch 600] loss: 0.04005121955706272
[Epoch 9, Batch 700] loss: 0.0417552625737153
[Epoch 9, Batch 800] loss: 0.03902642077649943
[Epoch 9, Batch 900] loss: 0.03794278799672611
[Epoch 9, Batch 1000] loss: 0.04406754347670358
[Epoch 9, Batch 1100] loss: 0.04968256890308112
[Epoch 9, Batch 1200] loss: 0.037483303630142475
[Epoch 9, Batch 1300] loss: 0.04338793994684238
[Epoch 9, Batch 1400] loss: 0.032737146441359076
[Epoch 9, Batch 1500] loss: 0.035635682846186685
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9829
Overfitting: 0.0548
Best model saved at epoch 9 with validation loss: 0.0548
[Epoch 10, Batch 100] loss: 0.027874529493565205
[Epoch 10, Batch 200] loss: 0.03779457444092259
[Epoch 10, Batch 300] loss: 0.028411120121600106
[Epoch 10, Batch 400] loss: 0.03111852303321939
[Epoch 10, Batch 500] loss: 0.03800270157982595
[Epoch 10, Batch 600] loss: 0.044914159316685985
[Epoch 10, Batch 700] loss: 0.03734389687306248
[Epoch 10, Batch 800] loss: 0.036147861631179695
[Epoch 10, Batch 900] loss: 0.032320143865654245
[Epoch 10, Batch 1000] loss: 0.04302487048553303
[Epoch 10, Batch 1100] loss: 0.03346322108409368
[Epoch 10, Batch 1200] loss: 0.02969622995238751
[Epoch 10, Batch 1300] loss: 0.04364391512935981
[Epoch 10, Batch 1400] loss: 0.03165429754939396
[Epoch 10, Batch 1500] loss: 0.04195205150230322
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0480
Validation Accuracy: 0.9850
Overfitting: 0.0480
[Epoch 11, Batch 100] loss: 0.034068322780658494
[Epoch 11, Batch 200] loss: 0.03562627342180349
[Epoch 11, Batch 300] loss: 0.044601953828241676
[Epoch 11, Batch 400] loss: 0.030702977019827812
[Epoch 11, Batch 500] loss: 0.03001798320969101
[Epoch 11, Batch 600] loss: 0.02566688049584627
[Epoch 11, Batch 700] loss: 0.03146193370281253
[Epoch 11, Batch 800] loss: 0.026873310785740612
[Epoch 11, Batch 900] loss: 0.029179651859158183
[Epoch 11, Batch 1000] loss: 0.03858913368312642
[Epoch 11, Batch 1100] loss: 0.03676435885980027
[Epoch 11, Batch 1200] loss: 0.03619107177830301
[Epoch 11, Batch 1300] loss: 0.03411420479271328
[Epoch 11, Batch 1400] loss: 0.03672857772326097
[Epoch 11, Batch 1500] loss: 0.036931281884899365
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0439
Validation Accuracy: 0.9870
Overfitting: 0.0439
Early stopping epoch 11 for trial 9. Moving to next fold.
Fold 5 validation loss: 0.0439
Mean validation loss across all folds for Trial 9 is 0.0493 with trial config:  l1: 256, l2: 64, lr: 0.001, batch_size: 32
[I 2024-12-10 05:18:39,118] Trial 8 finished with value: 0.049267951299149224 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.001, 'batch_size': 32}. Best is trial 8 with value: 0.049267951299149224.

Selected Hyperparameters for Trial 10:
  l1: 256, l2: 64, lr: 0.0005, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3035766673088074
[Epoch 1, Batch 200] loss: 2.2867769169807435
[Epoch 1, Batch 300] loss: 2.2688374662399293
[Epoch 1, Batch 400] loss: 2.2342539978027345
[Epoch 1, Batch 500] loss: 2.1515993642807008
[Epoch 1, Batch 600] loss: 1.8820432913303375
[Epoch 1, Batch 700] loss: 1.2374178808927536
**STATS for Epoch 1** : 
Average training loss: 0.0539
Average validation loss: 0.7014
Validation Accuracy: 0.8153
Overfitting: 0.6475
[Epoch 2, Batch 100] loss: 0.6197128450870514
[Epoch 2, Batch 200] loss: 0.5135060635209083
[Epoch 2, Batch 300] loss: 0.47164860367774963
[Epoch 2, Batch 400] loss: 0.42348660990595816
[Epoch 2, Batch 500] loss: 0.40386109679937365
[Epoch 2, Batch 600] loss: 0.3548747420310974
[Epoch 2, Batch 700] loss: 0.3106517319381237
**STATS for Epoch 2** : 
Average training loss: 0.0207
Average validation loss: 0.2994
Validation Accuracy: 0.9104
Overfitting: 0.2787
[Epoch 3, Batch 100] loss: 0.29208336405456065
[Epoch 3, Batch 200] loss: 0.29811991699039936
[Epoch 3, Batch 300] loss: 0.2636635663360357
[Epoch 3, Batch 400] loss: 0.25596420392394065
[Epoch 3, Batch 500] loss: 0.22876690968871116
[Epoch 3, Batch 600] loss: 0.2496338703483343
[Epoch 3, Batch 700] loss: 0.2359280341863632
**STATS for Epoch 3** : 
Average training loss: 0.0154
Average validation loss: 0.1981
Validation Accuracy: 0.9413
Overfitting: 0.1827
[Epoch 4, Batch 100] loss: 0.21498287685215473
[Epoch 4, Batch 200] loss: 0.19135191034525634
[Epoch 4, Batch 300] loss: 0.20088230982422828
[Epoch 4, Batch 400] loss: 0.19264679566025733
[Epoch 4, Batch 500] loss: 0.1915475056692958
[Epoch 4, Batch 600] loss: 0.1824208836629987
[Epoch 4, Batch 700] loss: 0.1691639893874526
**STATS for Epoch 4** : 
Average training loss: 0.0122
Average validation loss: 0.1684
Validation Accuracy: 0.9488
Overfitting: 0.1562
[Epoch 5, Batch 100] loss: 0.17104044862091541
[Epoch 5, Batch 200] loss: 0.16827704049646855
[Epoch 5, Batch 300] loss: 0.16552153538912534
[Epoch 5, Batch 400] loss: 0.14438733730465173
[Epoch 5, Batch 500] loss: 0.15680595640093087
[Epoch 5, Batch 600] loss: 0.1471792573109269
[Epoch 5, Batch 700] loss: 0.1284936747327447
**STATS for Epoch 5** : 
Average training loss: 0.0094
Average validation loss: 0.1277
Validation Accuracy: 0.9612
Overfitting: 0.1183
[Epoch 6, Batch 100] loss: 0.140571254119277
[Epoch 6, Batch 200] loss: 0.1332515923306346
[Epoch 6, Batch 300] loss: 0.12153105242177845
[Epoch 6, Batch 400] loss: 0.1344609177298844
[Epoch 6, Batch 500] loss: 0.13446885684505105
[Epoch 6, Batch 600] loss: 0.11939172204583884
[Epoch 6, Batch 700] loss: 0.12418929049745202
**STATS for Epoch 6** : 
Average training loss: 0.0095
Average validation loss: 0.1184
Validation Accuracy: 0.9652
Overfitting: 0.1089
[Epoch 7, Batch 100] loss: 0.11657854918390513
[Epoch 7, Batch 200] loss: 0.12248865650966763
[Epoch 7, Batch 300] loss: 0.10760041881352662
[Epoch 7, Batch 400] loss: 0.1075164819508791
[Epoch 7, Batch 500] loss: 0.12210870613344013
[Epoch 7, Batch 600] loss: 0.11790787242352962
[Epoch 7, Batch 700] loss: 0.11613444447517395
**STATS for Epoch 7** : 
Average training loss: 0.0078
Average validation loss: 0.0999
Validation Accuracy: 0.9698
Overfitting: 0.0921
[Epoch 8, Batch 100] loss: 0.11412786250934005
[Epoch 8, Batch 200] loss: 0.10079642202705145
[Epoch 8, Batch 300] loss: 0.10602528545074165
[Epoch 8, Batch 400] loss: 0.10041783144697547
[Epoch 8, Batch 500] loss: 0.10460264267399907
[Epoch 8, Batch 600] loss: 0.10650558380410075
[Epoch 8, Batch 700] loss: 0.10449120781384408
**STATS for Epoch 8** : 
Average training loss: 0.0061
Average validation loss: 0.0993
Validation Accuracy: 0.9690
Overfitting: 0.0932
[Epoch 9, Batch 100] loss: 0.09197915451601148
[Epoch 9, Batch 200] loss: 0.09519957188516855
[Epoch 9, Batch 300] loss: 0.08786825397983193
[Epoch 9, Batch 400] loss: 0.09046338558197022
[Epoch 9, Batch 500] loss: 0.10037296984344721
[Epoch 9, Batch 600] loss: 0.09701696596108376
[Epoch 9, Batch 700] loss: 0.09357085665687918
**STATS for Epoch 9** : 
Average training loss: 0.0062
Average validation loss: 0.0883
Validation Accuracy: 0.9710
Overfitting: 0.0821
Best model saved at epoch 9 with validation loss: 0.0883
[Epoch 10, Batch 100] loss: 0.09395843720063567
[Epoch 10, Batch 200] loss: 0.08371453732252121
[Epoch 10, Batch 300] loss: 0.0841248053405434
[Epoch 10, Batch 400] loss: 0.08097195478156209
[Epoch 10, Batch 500] loss: 0.083875574124977
[Epoch 10, Batch 600] loss: 0.09305347157642245
[Epoch 10, Batch 700] loss: 0.09201702266000211
**STATS for Epoch 10** : 
Average training loss: 0.0058
Average validation loss: 0.0778
Validation Accuracy: 0.9750
Overfitting: 0.0720
[Epoch 11, Batch 100] loss: 0.08245169799774885
[Epoch 11, Batch 200] loss: 0.07669106374494732
[Epoch 11, Batch 300] loss: 0.08459777744486928
[Epoch 11, Batch 400] loss: 0.06740093604195863
[Epoch 11, Batch 500] loss: 0.08619500797241926
[Epoch 11, Batch 600] loss: 0.08592490998096763
[Epoch 11, Batch 700] loss: 0.07979032534174621
**STATS for Epoch 11** : 
Average training loss: 0.0048
Average validation loss: 0.0827
Validation Accuracy: 0.9733
Overfitting: 0.0779
Early stopping epoch 11 for trial 10. Moving to next fold.
Fold 1 validation loss: 0.0827
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.302954578399658
[Epoch 1, Batch 200] loss: 2.2963986873626707
[Epoch 1, Batch 300] loss: 2.28990478515625
[Epoch 1, Batch 400] loss: 2.282313804626465
[Epoch 1, Batch 500] loss: 2.2671466422080995
[Epoch 1, Batch 600] loss: 2.2434396982192992
[Epoch 1, Batch 700] loss: 2.1965349674224854
**STATS for Epoch 1** : 
Average training loss: 0.1419
Average validation loss: 2.0968
Validation Accuracy: 0.4532
Overfitting: 1.9549
[Epoch 2, Batch 100] loss: 1.9730532312393187
[Epoch 2, Batch 200] loss: 1.4627351456880568
[Epoch 2, Batch 300] loss: 0.8334675830602646
[Epoch 2, Batch 400] loss: 0.5484352374076843
[Epoch 2, Batch 500] loss: 0.4481342872977257
[Epoch 2, Batch 600] loss: 0.39804404392838477
[Epoch 2, Batch 700] loss: 0.3759016714990139
**STATS for Epoch 2** : 
Average training loss: 0.0258
Average validation loss: 0.3619
Validation Accuracy: 0.8934
Overfitting: 0.3362
[Epoch 3, Batch 100] loss: 0.3208255757391453
[Epoch 3, Batch 200] loss: 0.29614376738667486
[Epoch 3, Batch 300] loss: 0.2937593456357718
[Epoch 3, Batch 400] loss: 0.2701116835325956
[Epoch 3, Batch 500] loss: 0.2680262506753206
[Epoch 3, Batch 600] loss: 0.2345113606750965
[Epoch 3, Batch 700] loss: 0.2412294328212738
**STATS for Epoch 3** : 
Average training loss: 0.0140
Average validation loss: 0.2260
Validation Accuracy: 0.9323
Overfitting: 0.2120
[Epoch 4, Batch 100] loss: 0.20887210689485072
[Epoch 4, Batch 200] loss: 0.2037470079958439
[Epoch 4, Batch 300] loss: 0.20701320201158524
[Epoch 4, Batch 400] loss: 0.1816472015529871
[Epoch 4, Batch 500] loss: 0.18320153549313545
[Epoch 4, Batch 600] loss: 0.1838852009922266
[Epoch 4, Batch 700] loss: 0.1672393685951829
**STATS for Epoch 4** : 
Average training loss: 0.0113
Average validation loss: 0.1727
Validation Accuracy: 0.9477
Overfitting: 0.1613
[Epoch 5, Batch 100] loss: 0.14600897923111916
[Epoch 5, Batch 200] loss: 0.1497954463213682
[Epoch 5, Batch 300] loss: 0.16486282426863907
[Epoch 5, Batch 400] loss: 0.13635392712429165
[Epoch 5, Batch 500] loss: 0.14565423108637332
[Epoch 5, Batch 600] loss: 0.1559002763032913
[Epoch 5, Batch 700] loss: 0.14234846234321594
**STATS for Epoch 5** : 
Average training loss: 0.0098
Average validation loss: 0.1526
Validation Accuracy: 0.9528
Overfitting: 0.1428
[Epoch 6, Batch 100] loss: 0.12050015481188893
[Epoch 6, Batch 200] loss: 0.12639314731582998
[Epoch 6, Batch 300] loss: 0.12476013980805874
[Epoch 6, Batch 400] loss: 0.12499513171613216
[Epoch 6, Batch 500] loss: 0.1207508467696607
[Epoch 6, Batch 600] loss: 0.1330313017591834
[Epoch 6, Batch 700] loss: 0.12270597824826837
**STATS for Epoch 6** : 
Average training loss: 0.0084
Average validation loss: 0.1313
Validation Accuracy: 0.9586
Overfitting: 0.1229
[Epoch 7, Batch 100] loss: 0.11461636036634446
[Epoch 7, Batch 200] loss: 0.11417698360979557
[Epoch 7, Batch 300] loss: 0.11033419845625758
[Epoch 7, Batch 400] loss: 0.10957947641611099
[Epoch 7, Batch 500] loss: 0.11272483015432953
[Epoch 7, Batch 600] loss: 0.09979304253123701
[Epoch 7, Batch 700] loss: 0.10537648905068636
**STATS for Epoch 7** : 
Average training loss: 0.0060
Average validation loss: 0.1198
Validation Accuracy: 0.9640
Overfitting: 0.1138
[Epoch 8, Batch 100] loss: 0.10929291563108563
[Epoch 8, Batch 200] loss: 0.09092243301682174
[Epoch 8, Batch 300] loss: 0.09318423089571297
[Epoch 8, Batch 400] loss: 0.09833367720246315
[Epoch 8, Batch 500] loss: 0.09926556998863817
[Epoch 8, Batch 600] loss: 0.09298736887052655
[Epoch 8, Batch 700] loss: 0.10264378171414137
**STATS for Epoch 8** : 
Average training loss: 0.0052
Average validation loss: 0.1077
Validation Accuracy: 0.9677
Overfitting: 0.1024
[Epoch 9, Batch 100] loss: 0.09223480676300824
[Epoch 9, Batch 200] loss: 0.09599333110265434
[Epoch 9, Batch 300] loss: 0.09027634453028441
[Epoch 9, Batch 400] loss: 0.08831113121472299
[Epoch 9, Batch 500] loss: 0.08475971885956823
[Epoch 9, Batch 600] loss: 0.09054170003160834
[Epoch 9, Batch 700] loss: 0.08535775277763605
**STATS for Epoch 9** : 
Average training loss: 0.0044
Average validation loss: 0.1003
Validation Accuracy: 0.9695
Overfitting: 0.0959
Best model saved at epoch 9 with validation loss: 0.1003
[Epoch 10, Batch 100] loss: 0.08647539338096977
[Epoch 10, Batch 200] loss: 0.07717231462709606
[Epoch 10, Batch 300] loss: 0.08164829222485423
[Epoch 10, Batch 400] loss: 0.08689049747772515
[Epoch 10, Batch 500] loss: 0.07920572970528156
[Epoch 10, Batch 600] loss: 0.07600628001615405
[Epoch 10, Batch 700] loss: 0.08562928293831647
**STATS for Epoch 10** : 
Average training loss: 0.0061
Average validation loss: 0.0946
Validation Accuracy: 0.9707
Overfitting: 0.0885
[Epoch 11, Batch 100] loss: 0.08053249949589372
[Epoch 11, Batch 200] loss: 0.0766035947855562
[Epoch 11, Batch 300] loss: 0.0757021667342633
[Epoch 11, Batch 400] loss: 0.06444914161227644
[Epoch 11, Batch 500] loss: 0.0797749681957066
[Epoch 11, Batch 600] loss: 0.07281711813062429
[Epoch 11, Batch 700] loss: 0.08361178138293326
**STATS for Epoch 11** : 
Average training loss: 0.0041
Average validation loss: 0.0907
Validation Accuracy: 0.9712
Overfitting: 0.0866
Early stopping epoch 11 for trial 10. Moving to next fold.
Fold 2 validation loss: 0.0907
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.29908650636673
[Epoch 1, Batch 200] loss: 2.2899200415611265
[Epoch 1, Batch 300] loss: 2.2799642729759215
[Epoch 1, Batch 400] loss: 2.260024120807648
[Epoch 1, Batch 500] loss: 2.2193217206001283
[Epoch 1, Batch 600] loss: 2.115552945137024
[Epoch 1, Batch 700] loss: 1.7715748703479768
**STATS for Epoch 1** : 
Average training loss: 0.0807
Average validation loss: 1.0276
Validation Accuracy: 0.7472
Overfitting: 0.9469
[Epoch 2, Batch 100] loss: 0.8028706550598145
[Epoch 2, Batch 200] loss: 0.6095674547553063
[Epoch 2, Batch 300] loss: 0.5054861882328987
[Epoch 2, Batch 400] loss: 0.4368586361408234
[Epoch 2, Batch 500] loss: 0.38968010142445564
[Epoch 2, Batch 600] loss: 0.3722395721077919
[Epoch 2, Batch 700] loss: 0.34911884903907775
**STATS for Epoch 2** : 
Average training loss: 0.0223
Average validation loss: 0.3329
Validation Accuracy: 0.8985
Overfitting: 0.3106
[Epoch 3, Batch 100] loss: 0.323363630771637
[Epoch 3, Batch 200] loss: 0.2973674619197845
[Epoch 3, Batch 300] loss: 0.29281025104224684
[Epoch 3, Batch 400] loss: 0.28047656804323196
[Epoch 3, Batch 500] loss: 0.2557703191041946
[Epoch 3, Batch 600] loss: 0.2756228812783956
[Epoch 3, Batch 700] loss: 0.253724871352315
**STATS for Epoch 3** : 
Average training loss: 0.0159
Average validation loss: 0.2440
Validation Accuracy: 0.9283
Overfitting: 0.2281
[Epoch 4, Batch 100] loss: 0.22129174135625362
[Epoch 4, Batch 200] loss: 0.21421186834573747
[Epoch 4, Batch 300] loss: 0.22388831540942192
[Epoch 4, Batch 400] loss: 0.21774081900715828
[Epoch 4, Batch 500] loss: 0.19564788714051246
[Epoch 4, Batch 600] loss: 0.1997592994943261
[Epoch 4, Batch 700] loss: 0.17458087276667356
**STATS for Epoch 4** : 
Average training loss: 0.0131
Average validation loss: 0.1869
Validation Accuracy: 0.9425
Overfitting: 0.1737
[Epoch 5, Batch 100] loss: 0.1819885416328907
[Epoch 5, Batch 200] loss: 0.1726273823529482
[Epoch 5, Batch 300] loss: 0.1722648335620761
[Epoch 5, Batch 400] loss: 0.1508846329897642
[Epoch 5, Batch 500] loss: 0.15812351908534766
[Epoch 5, Batch 600] loss: 0.1545911154150963
[Epoch 5, Batch 700] loss: 0.15286733366549016
**STATS for Epoch 5** : 
Average training loss: 0.0089
Average validation loss: 0.1500
Validation Accuracy: 0.9546
Overfitting: 0.1411
[Epoch 6, Batch 100] loss: 0.14365884598344564
[Epoch 6, Batch 200] loss: 0.139170297421515
[Epoch 6, Batch 300] loss: 0.1276571636274457
[Epoch 6, Batch 400] loss: 0.13115602971985937
[Epoch 6, Batch 500] loss: 0.13894550915807485
[Epoch 6, Batch 600] loss: 0.12921852823346852
[Epoch 6, Batch 700] loss: 0.12971589867025612
**STATS for Epoch 6** : 
Average training loss: 0.0090
Average validation loss: 0.1337
Validation Accuracy: 0.9596
Overfitting: 0.1247
[Epoch 7, Batch 100] loss: 0.11770414292812348
[Epoch 7, Batch 200] loss: 0.12508705392479896
[Epoch 7, Batch 300] loss: 0.11115590866655112
[Epoch 7, Batch 400] loss: 0.10756424654275179
[Epoch 7, Batch 500] loss: 0.12140653353184462
[Epoch 7, Batch 600] loss: 0.1140414271876216
[Epoch 7, Batch 700] loss: 0.11342772854492068
**STATS for Epoch 7** : 
Average training loss: 0.0070
Average validation loss: 0.1162
Validation Accuracy: 0.9643
Overfitting: 0.1091
[Epoch 8, Batch 100] loss: 0.10256258403882385
[Epoch 8, Batch 200] loss: 0.10896936541423202
[Epoch 8, Batch 300] loss: 0.10154499929398299
[Epoch 8, Batch 400] loss: 0.11167662619613111
[Epoch 8, Batch 500] loss: 0.10095766781829298
[Epoch 8, Batch 600] loss: 0.10514364613220095
[Epoch 8, Batch 700] loss: 0.08940828806720674
**STATS for Epoch 8** : 
Average training loss: 0.0063
Average validation loss: 0.1077
Validation Accuracy: 0.9679
Overfitting: 0.1014
[Epoch 9, Batch 100] loss: 0.1040433795005083
[Epoch 9, Batch 200] loss: 0.0922993147931993
[Epoch 9, Batch 300] loss: 0.09161945015192031
[Epoch 9, Batch 400] loss: 0.09337208120152354
[Epoch 9, Batch 500] loss: 0.09024342481046915
[Epoch 9, Batch 600] loss: 0.09582592326216399
[Epoch 9, Batch 700] loss: 0.0885960656311363
**STATS for Epoch 9** : 
Average training loss: 0.0051
Average validation loss: 0.1028
Validation Accuracy: 0.9697
Overfitting: 0.0977
Best model saved at epoch 9 with validation loss: 0.1028
[Epoch 10, Batch 100] loss: 0.09512172548100352
[Epoch 10, Batch 200] loss: 0.09497042969800532
[Epoch 10, Batch 300] loss: 0.08186540838330984
[Epoch 10, Batch 400] loss: 0.08021870639175177
[Epoch 10, Batch 500] loss: 0.08943863831460476
[Epoch 10, Batch 600] loss: 0.08607602713629603
[Epoch 10, Batch 700] loss: 0.07779996591620147
**STATS for Epoch 10** : 
Average training loss: 0.0051
Average validation loss: 0.0912
Validation Accuracy: 0.9724
Overfitting: 0.0861
[Epoch 11, Batch 100] loss: 0.08578317791223526
[Epoch 11, Batch 200] loss: 0.07242547539994121
[Epoch 11, Batch 300] loss: 0.07641040047630668
[Epoch 11, Batch 400] loss: 0.08138246575370431
[Epoch 11, Batch 500] loss: 0.07680477869696915
[Epoch 11, Batch 600] loss: 0.07907780141569674
[Epoch 11, Batch 700] loss: 0.08211939685046672
**STATS for Epoch 11** : 
Average training loss: 0.0056
Average validation loss: 0.0895
Validation Accuracy: 0.9730
Overfitting: 0.0839
Early stopping epoch 11 for trial 10. Moving to next fold.
Fold 3 validation loss: 0.0895
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.3055322122573854
[Epoch 1, Batch 200] loss: 2.2984459400177
[Epoch 1, Batch 300] loss: 2.2880802369117736
[Epoch 1, Batch 400] loss: 2.273297219276428
[Epoch 1, Batch 500] loss: 2.2455352759361267
[Epoch 1, Batch 600] loss: 2.1899555826187136
[Epoch 1, Batch 700] loss: 2.031471552848816
**STATS for Epoch 1** : 
Average training loss: 0.1146
Average validation loss: 1.5394
Validation Accuracy: 0.7088
Overfitting: 1.4248
[Epoch 2, Batch 100] loss: 1.1350610423088074
[Epoch 2, Batch 200] loss: 0.6910622107982636
[Epoch 2, Batch 300] loss: 0.5715382006764412
[Epoch 2, Batch 400] loss: 0.49838868886232374
[Epoch 2, Batch 500] loss: 0.40941589668393136
[Epoch 2, Batch 600] loss: 0.4075043997168541
[Epoch 2, Batch 700] loss: 0.3747362649440765
**STATS for Epoch 2** : 
Average training loss: 0.0237
Average validation loss: 0.3401
Validation Accuracy: 0.8972
Overfitting: 0.3164
[Epoch 3, Batch 100] loss: 0.3312504503130913
[Epoch 3, Batch 200] loss: 0.325654074549675
[Epoch 3, Batch 300] loss: 0.30762497618794443
[Epoch 3, Batch 400] loss: 0.29925667941570283
[Epoch 3, Batch 500] loss: 0.25934286385774613
[Epoch 3, Batch 600] loss: 0.2576197671890259
[Epoch 3, Batch 700] loss: 0.2418791002780199
**STATS for Epoch 3** : 
Average training loss: 0.0161
Average validation loss: 0.2315
Validation Accuracy: 0.9295
Overfitting: 0.2154
[Epoch 4, Batch 100] loss: 0.2378958100825548
[Epoch 4, Batch 200] loss: 0.22632086388766764
[Epoch 4, Batch 300] loss: 0.21386324256658554
[Epoch 4, Batch 400] loss: 0.20258666157722474
[Epoch 4, Batch 500] loss: 0.19260852746665477
[Epoch 4, Batch 600] loss: 0.1890688081085682
[Epoch 4, Batch 700] loss: 0.18779579613357783
**STATS for Epoch 4** : 
Average training loss: 0.0118
Average validation loss: 0.1796
Validation Accuracy: 0.9446
Overfitting: 0.1679
[Epoch 5, Batch 100] loss: 0.17615976389497517
[Epoch 5, Batch 200] loss: 0.16069014847278595
[Epoch 5, Batch 300] loss: 0.16981288205832243
[Epoch 5, Batch 400] loss: 0.1667900387942791
[Epoch 5, Batch 500] loss: 0.15541380032896995
[Epoch 5, Batch 600] loss: 0.15640619304031134
[Epoch 5, Batch 700] loss: 0.14699800861999393
**STATS for Epoch 5** : 
Average training loss: 0.0100
Average validation loss: 0.1397
Validation Accuracy: 0.9579
Overfitting: 0.1297
[Epoch 6, Batch 100] loss: 0.14056704992428423
[Epoch 6, Batch 200] loss: 0.12688260082155467
[Epoch 6, Batch 300] loss: 0.14160590017214417
[Epoch 6, Batch 400] loss: 0.13966348268091677
[Epoch 6, Batch 500] loss: 0.11930969500914217
[Epoch 6, Batch 600] loss: 0.1286823978088796
[Epoch 6, Batch 700] loss: 0.1254750837944448
**STATS for Epoch 6** : 
Average training loss: 0.0089
Average validation loss: 0.1199
Validation Accuracy: 0.9633
Overfitting: 0.1111
[Epoch 7, Batch 100] loss: 0.12909578392282128
[Epoch 7, Batch 200] loss: 0.11371531691402197
[Epoch 7, Batch 300] loss: 0.11470121372491121
[Epoch 7, Batch 400] loss: 0.11375713201239705
[Epoch 7, Batch 500] loss: 0.10843425180763006
[Epoch 7, Batch 600] loss: 0.10588001580908894
[Epoch 7, Batch 700] loss: 0.1109852204285562
**STATS for Epoch 7** : 
Average training loss: 0.0082
Average validation loss: 0.1067
Validation Accuracy: 0.9660
Overfitting: 0.0985
[Epoch 8, Batch 100] loss: 0.10565023289062082
[Epoch 8, Batch 200] loss: 0.09816931383684277
[Epoch 8, Batch 300] loss: 0.10081009042449296
[Epoch 8, Batch 400] loss: 0.10291569516062736
[Epoch 8, Batch 500] loss: 0.09182457791641355
[Epoch 8, Batch 600] loss: 0.09750223466195167
[Epoch 8, Batch 700] loss: 0.11628825094550849
**STATS for Epoch 8** : 
Average training loss: 0.0060
Average validation loss: 0.1045
Validation Accuracy: 0.9664
Overfitting: 0.0985
[Epoch 9, Batch 100] loss: 0.10599452266469597
[Epoch 9, Batch 200] loss: 0.09942823246121407
[Epoch 9, Batch 300] loss: 0.08625273546203971
[Epoch 9, Batch 400] loss: 0.09978018457069993
[Epoch 9, Batch 500] loss: 0.09399771948345005
[Epoch 9, Batch 600] loss: 0.08604717444628478
[Epoch 9, Batch 700] loss: 0.08227514926344157
**STATS for Epoch 9** : 
Average training loss: 0.0058
Average validation loss: 0.1007
Validation Accuracy: 0.9676
Overfitting: 0.0949
Best model saved at epoch 9 with validation loss: 0.1007
[Epoch 10, Batch 100] loss: 0.08482900281436741
[Epoch 10, Batch 200] loss: 0.09052052659913898
[Epoch 10, Batch 300] loss: 0.09133982245810329
[Epoch 10, Batch 400] loss: 0.09217876628041267
[Epoch 10, Batch 500] loss: 0.07907460713759065
[Epoch 10, Batch 600] loss: 0.07826354563236236
[Epoch 10, Batch 700] loss: 0.08555571475997567
**STATS for Epoch 10** : 
Average training loss: 0.0054
Average validation loss: 0.0879
Validation Accuracy: 0.9738
Overfitting: 0.0825
[Epoch 11, Batch 100] loss: 0.08055682036094368
[Epoch 11, Batch 200] loss: 0.07562578241340816
[Epoch 11, Batch 300] loss: 0.0673150620330125
[Epoch 11, Batch 400] loss: 0.08720742091536522
[Epoch 11, Batch 500] loss: 0.07704135486856103
[Epoch 11, Batch 600] loss: 0.0865793989924714
[Epoch 11, Batch 700] loss: 0.08104778673499823
**STATS for Epoch 11** : 
Average training loss: 0.0046
Average validation loss: 0.0787
Validation Accuracy: 0.9770
Overfitting: 0.0741
Early stopping epoch 11 for trial 10. Moving to next fold.
Fold 4 validation loss: 0.0787
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.305265200138092
[Epoch 1, Batch 200] loss: 2.2983815693855285
[Epoch 1, Batch 300] loss: 2.286283164024353
[Epoch 1, Batch 400] loss: 2.2691027688980103
[Epoch 1, Batch 500] loss: 2.23995046377182
[Epoch 1, Batch 600] loss: 2.1625385093688965
[Epoch 1, Batch 700] loss: 1.9384382796287536
**STATS for Epoch 1** : 
Average training loss: 0.1020
Average validation loss: 1.3296
Validation Accuracy: 0.7101
Overfitting: 1.2275
[Epoch 2, Batch 100] loss: 1.0063815522193909
[Epoch 2, Batch 200] loss: 0.680955739915371
[Epoch 2, Batch 300] loss: 0.5393798217177391
[Epoch 2, Batch 400] loss: 0.4810325142741203
[Epoch 2, Batch 500] loss: 0.46234740361571314
[Epoch 2, Batch 600] loss: 0.3721293258666992
[Epoch 2, Batch 700] loss: 0.3863239444792271
**STATS for Epoch 2** : 
Average training loss: 0.0231
Average validation loss: 0.3769
Validation Accuracy: 0.8877
Overfitting: 0.3538
[Epoch 3, Batch 100] loss: 0.3367836545407772
[Epoch 3, Batch 200] loss: 0.32930631808936595
[Epoch 3, Batch 300] loss: 0.3194932061433792
[Epoch 3, Batch 400] loss: 0.28917217671871187
[Epoch 3, Batch 500] loss: 0.27059145852923394
[Epoch 3, Batch 600] loss: 0.2754676987975836
[Epoch 3, Batch 700] loss: 0.2628547954559326
**STATS for Epoch 3** : 
Average training loss: 0.0172
Average validation loss: 0.2547
Validation Accuracy: 0.9263
Overfitting: 0.2375
[Epoch 4, Batch 100] loss: 0.2438202551752329
[Epoch 4, Batch 200] loss: 0.22210446044802665
[Epoch 4, Batch 300] loss: 0.20958377085626126
[Epoch 4, Batch 400] loss: 0.22116435877978802
[Epoch 4, Batch 500] loss: 0.2019770472124219
[Epoch 4, Batch 600] loss: 0.1995860582217574
[Epoch 4, Batch 700] loss: 0.19607798878103494
**STATS for Epoch 4** : 
Average training loss: 0.0132
Average validation loss: 0.1800
Validation Accuracy: 0.9477
Overfitting: 0.1667
[Epoch 5, Batch 100] loss: 0.18074605740606786
[Epoch 5, Batch 200] loss: 0.18152797024697065
[Epoch 5, Batch 300] loss: 0.15526056732982396
[Epoch 5, Batch 400] loss: 0.1507900358736515
[Epoch 5, Batch 500] loss: 0.15794827047735452
[Epoch 5, Batch 600] loss: 0.16611431881785393
[Epoch 5, Batch 700] loss: 0.1682452545315027
**STATS for Epoch 5** : 
Average training loss: 0.0113
Average validation loss: 0.1529
Validation Accuracy: 0.9558
Overfitting: 0.1416
[Epoch 6, Batch 100] loss: 0.150839852578938
[Epoch 6, Batch 200] loss: 0.1425201839953661
[Epoch 6, Batch 300] loss: 0.14935245588421822
[Epoch 6, Batch 400] loss: 0.1410671839118004
[Epoch 6, Batch 500] loss: 0.13026895316317677
[Epoch 6, Batch 600] loss: 0.13039268426597117
[Epoch 6, Batch 700] loss: 0.12981662359088658
**STATS for Epoch 6** : 
Average training loss: 0.0087
Average validation loss: 0.1295
Validation Accuracy: 0.9623
Overfitting: 0.1208
[Epoch 7, Batch 100] loss: 0.12026148395612836
[Epoch 7, Batch 200] loss: 0.12040382016450167
[Epoch 7, Batch 300] loss: 0.11870226310566068
[Epoch 7, Batch 400] loss: 0.1209569464251399
[Epoch 7, Batch 500] loss: 0.11436229752376675
[Epoch 7, Batch 600] loss: 0.12683681530877947
[Epoch 7, Batch 700] loss: 0.11062366520985961
**STATS for Epoch 7** : 
Average training loss: 0.0086
Average validation loss: 0.1135
Validation Accuracy: 0.9658
Overfitting: 0.1049
[Epoch 8, Batch 100] loss: 0.11664936601184309
[Epoch 8, Batch 200] loss: 0.11906412923708558
[Epoch 8, Batch 300] loss: 0.10871220003813505
[Epoch 8, Batch 400] loss: 0.10240213092416525
[Epoch 8, Batch 500] loss: 0.09367639652453363
[Epoch 8, Batch 600] loss: 0.10581590432673693
[Epoch 8, Batch 700] loss: 0.10184571309015154
**STATS for Epoch 8** : 
Average training loss: 0.0076
Average validation loss: 0.1043
Validation Accuracy: 0.9686
Overfitting: 0.0967
[Epoch 9, Batch 100] loss: 0.0975937070325017
[Epoch 9, Batch 200] loss: 0.09972855167463422
[Epoch 9, Batch 300] loss: 0.10217925481498241
[Epoch 9, Batch 400] loss: 0.10519087776541709
[Epoch 9, Batch 500] loss: 0.09439326584339142
[Epoch 9, Batch 600] loss: 0.08736610843800008
[Epoch 9, Batch 700] loss: 0.09391850212588906
**STATS for Epoch 9** : 
Average training loss: 0.0058
Average validation loss: 0.1000
Validation Accuracy: 0.9692
Overfitting: 0.0942
Best model saved at epoch 9 with validation loss: 0.1000
[Epoch 10, Batch 100] loss: 0.08519116027280688
[Epoch 10, Batch 200] loss: 0.09046021929942072
[Epoch 10, Batch 300] loss: 0.09850943779572845
[Epoch 10, Batch 400] loss: 0.08680186977609992
[Epoch 10, Batch 500] loss: 0.08893821312580258
[Epoch 10, Batch 600] loss: 0.09229841355234385
[Epoch 10, Batch 700] loss: 0.08620865420438349
**STATS for Epoch 10** : 
Average training loss: 0.0053
Average validation loss: 0.0895
Validation Accuracy: 0.9725
Overfitting: 0.0841
[Epoch 11, Batch 100] loss: 0.0868442443292588
[Epoch 11, Batch 200] loss: 0.08224674130324275
[Epoch 11, Batch 300] loss: 0.08108736850321292
[Epoch 11, Batch 400] loss: 0.08690661913715303
[Epoch 11, Batch 500] loss: 0.07679061939474195
[Epoch 11, Batch 600] loss: 0.08724958143197
[Epoch 11, Batch 700] loss: 0.0828104500938207
**STATS for Epoch 11** : 
Average training loss: 0.0055
Average validation loss: 0.0903
Validation Accuracy: 0.9728
Overfitting: 0.0848
Early stopping epoch 11 for trial 10. Moving to next fold.
Fold 5 validation loss: 0.0903
Mean validation loss across all folds for Trial 10 is 0.0864 with trial config:  l1: 256, l2: 64, lr: 0.0005, batch_size: 64
[I 2024-12-10 05:27:58,720] Trial 9 finished with value: 0.08638042196571986 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0005, 'batch_size': 64}. Best is trial 8 with value: 0.049267951299149224.

Selected Hyperparameters for Trial 11:
  l1: 256, l2: 64, lr: 0.001, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2888943552970886
[Epoch 1, Batch 200] loss: 2.222358930110931
[Epoch 1, Batch 300] loss: 1.8207541286945343
[Epoch 1, Batch 400] loss: 0.7964332628250123
[Epoch 1, Batch 500] loss: 0.4799725747108459
[Epoch 1, Batch 600] loss: 0.4122545041143894
[Epoch 1, Batch 700] loss: 0.33083177320659163
**STATS for Epoch 1** : 
Average training loss: 0.0215
Average validation loss: 0.2887
Validation Accuracy: 0.9128
Overfitting: 0.2672
[Epoch 2, Batch 100] loss: 0.3066267338395119
[Epoch 2, Batch 200] loss: 0.28209216848015783
[Epoch 2, Batch 300] loss: 0.2644160554558039
[Epoch 2, Batch 400] loss: 0.2395427969843149
[Epoch 2, Batch 500] loss: 0.22786642737686635
[Epoch 2, Batch 600] loss: 0.21299864448606967
[Epoch 2, Batch 700] loss: 0.20262046135962009
**STATS for Epoch 2** : 
Average training loss: 0.0116
Average validation loss: 0.1738
Validation Accuracy: 0.9473
Overfitting: 0.1622
[Epoch 3, Batch 100] loss: 0.17096566319465636
[Epoch 3, Batch 200] loss: 0.17931901529431343
[Epoch 3, Batch 300] loss: 0.17982957806438207
[Epoch 3, Batch 400] loss: 0.14323129922151565
[Epoch 3, Batch 500] loss: 0.1636096001788974
[Epoch 3, Batch 600] loss: 0.14399546589702367
[Epoch 3, Batch 700] loss: 0.1395997180789709
**STATS for Epoch 3** : 
Average training loss: 0.0081
Average validation loss: 0.1222
Validation Accuracy: 0.9620
Overfitting: 0.1141
[Epoch 4, Batch 100] loss: 0.1345139910466969
[Epoch 4, Batch 200] loss: 0.12353873308748006
[Epoch 4, Batch 300] loss: 0.12510618276894092
[Epoch 4, Batch 400] loss: 0.12452505459077656
[Epoch 4, Batch 500] loss: 0.11512408429756761
[Epoch 4, Batch 600] loss: 0.09745687548071146
[Epoch 4, Batch 700] loss: 0.1058467566408217
**STATS for Epoch 4** : 
Average training loss: 0.0071
Average validation loss: 0.0899
Validation Accuracy: 0.9699
Overfitting: 0.0829
[Epoch 5, Batch 100] loss: 0.11240939527750016
[Epoch 5, Batch 200] loss: 0.09367121892049908
[Epoch 5, Batch 300] loss: 0.09927169917151332
[Epoch 5, Batch 400] loss: 0.10098146314732731
[Epoch 5, Batch 500] loss: 0.09134087326005101
[Epoch 5, Batch 600] loss: 0.0903178116120398
[Epoch 5, Batch 700] loss: 0.0857911470439285
**STATS for Epoch 5** : 
Average training loss: 0.0048
Average validation loss: 0.0763
Validation Accuracy: 0.9760
Overfitting: 0.0714
[Epoch 6, Batch 100] loss: 0.07783159608952701
[Epoch 6, Batch 200] loss: 0.07234626218676567
[Epoch 6, Batch 300] loss: 0.07290215017739683
[Epoch 6, Batch 400] loss: 0.0929913841933012
[Epoch 6, Batch 500] loss: 0.08637168535962701
[Epoch 6, Batch 600] loss: 0.07450154992751777
[Epoch 6, Batch 700] loss: 0.07499305333942174
**STATS for Epoch 6** : 
Average training loss: 0.0050
Average validation loss: 0.0700
Validation Accuracy: 0.9777
Overfitting: 0.0650
[Epoch 7, Batch 100] loss: 0.07028655500151217
[Epoch 7, Batch 200] loss: 0.07182138677686453
[Epoch 7, Batch 300] loss: 0.07665909827686847
[Epoch 7, Batch 400] loss: 0.06843251976650208
[Epoch 7, Batch 500] loss: 0.0710568368062377
[Epoch 7, Batch 600] loss: 0.07145743456669151
[Epoch 7, Batch 700] loss: 0.06989338159095496
**STATS for Epoch 7** : 
Average training loss: 0.0039
Average validation loss: 0.0649
Validation Accuracy: 0.9790
Overfitting: 0.0610
[Epoch 8, Batch 100] loss: 0.058267957628704604
[Epoch 8, Batch 200] loss: 0.05917714895680547
[Epoch 8, Batch 300] loss: 0.0708525044983253
[Epoch 8, Batch 400] loss: 0.06315712318290025
[Epoch 8, Batch 500] loss: 0.06466552533674985
[Epoch 8, Batch 600] loss: 0.0606906335009262
[Epoch 8, Batch 700] loss: 0.059947522138245404
**STATS for Epoch 8** : 
Average training loss: 0.0044
Average validation loss: 0.0604
Validation Accuracy: 0.9808
Overfitting: 0.0560
[Epoch 9, Batch 100] loss: 0.05473824477288872
[Epoch 9, Batch 200] loss: 0.04856494055129588
[Epoch 9, Batch 300] loss: 0.05778265410568565
[Epoch 9, Batch 400] loss: 0.057029151879251005
[Epoch 9, Batch 500] loss: 0.05689886112813838
[Epoch 9, Batch 600] loss: 0.0578858638368547
[Epoch 9, Batch 700] loss: 0.06100071134511381
**STATS for Epoch 9** : 
Average training loss: 0.0039
Average validation loss: 0.0620
Validation Accuracy: 0.9790
Overfitting: 0.0582
Best model saved at epoch 9 with validation loss: 0.0620
[Epoch 10, Batch 100] loss: 0.039938799710944294
[Epoch 10, Batch 200] loss: 0.05007331332890317
[Epoch 10, Batch 300] loss: 0.04666486097034067
[Epoch 10, Batch 400] loss: 0.05546147974673658
[Epoch 10, Batch 500] loss: 0.05706269353395328
[Epoch 10, Batch 600] loss: 0.05118572857230902
[Epoch 10, Batch 700] loss: 0.05804099411703646
**STATS for Epoch 10** : 
Average training loss: 0.0040
Average validation loss: 0.0585
Validation Accuracy: 0.9814
Overfitting: 0.0544
[Epoch 11, Batch 100] loss: 0.04398227889556438
[Epoch 11, Batch 200] loss: 0.042763346331194045
[Epoch 11, Batch 300] loss: 0.043377179568633434
[Epoch 11, Batch 400] loss: 0.0468472595885396
[Epoch 11, Batch 500] loss: 0.0456746396003291
[Epoch 11, Batch 600] loss: 0.04857498454977758
[Epoch 11, Batch 700] loss: 0.054112265552394095
**STATS for Epoch 11** : 
Average training loss: 0.0041
Average validation loss: 0.0512
Validation Accuracy: 0.9842
Overfitting: 0.0471
Early stopping epoch 11 for trial 11. Moving to next fold.
Fold 1 validation loss: 0.0512
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2974598383903504
[Epoch 1, Batch 200] loss: 2.2716665649414063
[Epoch 1, Batch 300] loss: 2.190513834953308
[Epoch 1, Batch 400] loss: 1.6787874603271484
[Epoch 1, Batch 500] loss: 0.7325393307209015
[Epoch 1, Batch 600] loss: 0.5031891249120235
[Epoch 1, Batch 700] loss: 0.41717273607850075
**STATS for Epoch 1** : 
Average training loss: 0.0260
Average validation loss: 0.3825
Validation Accuracy: 0.8898
Overfitting: 0.3565
[Epoch 2, Batch 100] loss: 0.35898258566856384
[Epoch 2, Batch 200] loss: 0.2982242000848055
[Epoch 2, Batch 300] loss: 0.31239070795476437
[Epoch 2, Batch 400] loss: 0.29576166793704034
[Epoch 2, Batch 500] loss: 0.240465716868639
[Epoch 2, Batch 600] loss: 0.25511344742029907
[Epoch 2, Batch 700] loss: 0.20401658035814763
**STATS for Epoch 2** : 
Average training loss: 0.0143
Average validation loss: 0.2440
Validation Accuracy: 0.9261
Overfitting: 0.2297
[Epoch 3, Batch 100] loss: 0.19786252602934837
[Epoch 3, Batch 200] loss: 0.198545224070549
[Epoch 3, Batch 300] loss: 0.16029244974255563
[Epoch 3, Batch 400] loss: 0.17915199648588895
[Epoch 3, Batch 500] loss: 0.15800262574106455
[Epoch 3, Batch 600] loss: 0.16601344130933285
[Epoch 3, Batch 700] loss: 0.15040512312203647
**STATS for Epoch 3** : 
Average training loss: 0.0092
Average validation loss: 0.1583
Validation Accuracy: 0.9509
Overfitting: 0.1491
[Epoch 4, Batch 100] loss: 0.14507612265646458
[Epoch 4, Batch 200] loss: 0.1335739604383707
[Epoch 4, Batch 300] loss: 0.12534812245517968
[Epoch 4, Batch 400] loss: 0.12422035666182638
[Epoch 4, Batch 500] loss: 0.11768507843837142
[Epoch 4, Batch 600] loss: 0.1316328379139304
[Epoch 4, Batch 700] loss: 0.11853450110182166
**STATS for Epoch 4** : 
Average training loss: 0.0073
Average validation loss: 0.1280
Validation Accuracy: 0.9592
Overfitting: 0.1207
[Epoch 5, Batch 100] loss: 0.10483775856904685
[Epoch 5, Batch 200] loss: 0.10138879971578717
[Epoch 5, Batch 300] loss: 0.10829661954194307
[Epoch 5, Batch 400] loss: 0.11195988984778524
[Epoch 5, Batch 500] loss: 0.09599994744174183
[Epoch 5, Batch 600] loss: 0.09647156408056617
[Epoch 5, Batch 700] loss: 0.0912334577087313
**STATS for Epoch 5** : 
Average training loss: 0.0066
Average validation loss: 0.1043
Validation Accuracy: 0.9677
Overfitting: 0.0977
[Epoch 6, Batch 100] loss: 0.09497410609386861
[Epoch 6, Batch 200] loss: 0.08479977509006859
[Epoch 6, Batch 300] loss: 0.08953074184246361
[Epoch 6, Batch 400] loss: 0.0797039463184774
[Epoch 6, Batch 500] loss: 0.08602946932893246
[Epoch 6, Batch 600] loss: 0.08345683007501066
[Epoch 6, Batch 700] loss: 0.0952110261656344
**STATS for Epoch 6** : 
Average training loss: 0.0056
Average validation loss: 0.1085
Validation Accuracy: 0.9655
Overfitting: 0.1029
[Epoch 7, Batch 100] loss: 0.07475764644797891
[Epoch 7, Batch 200] loss: 0.07829772413242608
[Epoch 7, Batch 300] loss: 0.07898767484351993
[Epoch 7, Batch 400] loss: 0.07312037420459092
[Epoch 7, Batch 500] loss: 0.07541038865223527
[Epoch 7, Batch 600] loss: 0.07508844166994094
[Epoch 7, Batch 700] loss: 0.07268904268741608
**STATS for Epoch 7** : 
Average training loss: 0.0042
Average validation loss: 0.0916
Validation Accuracy: 0.9704
Overfitting: 0.0875
[Epoch 8, Batch 100] loss: 0.06259372877888382
[Epoch 8, Batch 200] loss: 0.062394267288036646
[Epoch 8, Batch 300] loss: 0.08351704227738083
[Epoch 8, Batch 400] loss: 0.06807071133516729
[Epoch 8, Batch 500] loss: 0.0732881411164999
[Epoch 8, Batch 600] loss: 0.06540726612322033
[Epoch 8, Batch 700] loss: 0.057212685816921294
**STATS for Epoch 8** : 
Average training loss: 0.0041
Average validation loss: 0.0745
Validation Accuracy: 0.9776
Overfitting: 0.0704
[Epoch 9, Batch 100] loss: 0.05350987738929689
[Epoch 9, Batch 200] loss: 0.06329108733683825
[Epoch 9, Batch 300] loss: 0.06105780075071379
[Epoch 9, Batch 400] loss: 0.05832585837226361
[Epoch 9, Batch 500] loss: 0.057298114420846105
[Epoch 9, Batch 600] loss: 0.0633435512566939
[Epoch 9, Batch 700] loss: 0.0578214916633442
**STATS for Epoch 9** : 
Average training loss: 0.0046
Average validation loss: 0.0778
Validation Accuracy: 0.9758
Overfitting: 0.0732
Best model saved at epoch 9 with validation loss: 0.0778
[Epoch 10, Batch 100] loss: 0.049233232890255746
[Epoch 10, Batch 200] loss: 0.048507320815697315
[Epoch 10, Batch 300] loss: 0.0560507085500285
[Epoch 10, Batch 400] loss: 0.05941805928945541
[Epoch 10, Batch 500] loss: 0.047522594281472263
[Epoch 10, Batch 600] loss: 0.0664294842025265
[Epoch 10, Batch 700] loss: 0.05288459765724838
**STATS for Epoch 10** : 
Average training loss: 0.0038
Average validation loss: 0.0724
Validation Accuracy: 0.9778
Overfitting: 0.0686
[Epoch 11, Batch 100] loss: 0.04707071636337787
[Epoch 11, Batch 200] loss: 0.048483668633271006
[Epoch 11, Batch 300] loss: 0.056342823719605806
[Epoch 11, Batch 400] loss: 0.046980358238797634
[Epoch 11, Batch 500] loss: 0.04913818356115371
[Epoch 11, Batch 600] loss: 0.05406321122311056
[Epoch 11, Batch 700] loss: 0.053167762593366204
**STATS for Epoch 11** : 
Average training loss: 0.0028
Average validation loss: 0.0683
Validation Accuracy: 0.9791
Overfitting: 0.0655
Early stopping epoch 11 for trial 11. Moving to next fold.
Fold 2 validation loss: 0.0683
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3004680037498475
[Epoch 1, Batch 200] loss: 2.2767863988876345
[Epoch 1, Batch 300] loss: 2.2140941762924196
[Epoch 1, Batch 400] loss: 1.8425535237789155
[Epoch 1, Batch 500] loss: 0.9837424516677856
[Epoch 1, Batch 600] loss: 0.5862702023983002
[Epoch 1, Batch 700] loss: 0.4629386268556118
**STATS for Epoch 1** : 
Average training loss: 0.0255
Average validation loss: 0.3846
Validation Accuracy: 0.8838
Overfitting: 0.3591
[Epoch 2, Batch 100] loss: 0.3401286841928959
[Epoch 2, Batch 200] loss: 0.336173021197319
[Epoch 2, Batch 300] loss: 0.290443165153265
[Epoch 2, Batch 400] loss: 0.26559075377881525
[Epoch 2, Batch 500] loss: 0.2279926038533449
[Epoch 2, Batch 600] loss: 0.21155994169414044
[Epoch 2, Batch 700] loss: 0.20399484626948833
**STATS for Epoch 2** : 
Average training loss: 0.0140
Average validation loss: 0.2007
Validation Accuracy: 0.9385
Overfitting: 0.1867
[Epoch 3, Batch 100] loss: 0.18839908882975578
[Epoch 3, Batch 200] loss: 0.16792748272418975
[Epoch 3, Batch 300] loss: 0.18076488776132466
[Epoch 3, Batch 400] loss: 0.15291384793817997
[Epoch 3, Batch 500] loss: 0.14609576359391213
[Epoch 3, Batch 600] loss: 0.14964556232094764
[Epoch 3, Batch 700] loss: 0.13822605088353157
**STATS for Epoch 3** : 
Average training loss: 0.0093
Average validation loss: 0.1318
Validation Accuracy: 0.9599
Overfitting: 0.1225
[Epoch 4, Batch 100] loss: 0.12497529586777091
[Epoch 4, Batch 200] loss: 0.12916561579331756
[Epoch 4, Batch 300] loss: 0.11964352395385504
[Epoch 4, Batch 400] loss: 0.1312171249091625
[Epoch 4, Batch 500] loss: 0.1103068420290947
[Epoch 4, Batch 600] loss: 0.1121044457424432
[Epoch 4, Batch 700] loss: 0.11353445964399725
**STATS for Epoch 4** : 
Average training loss: 0.0076
Average validation loss: 0.1207
Validation Accuracy: 0.9640
Overfitting: 0.1132
[Epoch 5, Batch 100] loss: 0.10371952140703797
[Epoch 5, Batch 200] loss: 0.09263825867325068
[Epoch 5, Batch 300] loss: 0.08774518832564354
[Epoch 5, Batch 400] loss: 0.09600842870771885
[Epoch 5, Batch 500] loss: 0.09932742256205529
[Epoch 5, Batch 600] loss: 0.09586961968801916
[Epoch 5, Batch 700] loss: 0.10110797710716725
**STATS for Epoch 5** : 
Average training loss: 0.0071
Average validation loss: 0.0953
Validation Accuracy: 0.9715
Overfitting: 0.0882
[Epoch 6, Batch 100] loss: 0.09708647252991795
[Epoch 6, Batch 200] loss: 0.09121420160867273
[Epoch 6, Batch 300] loss: 0.08199030021205544
[Epoch 6, Batch 400] loss: 0.08369286492466926
[Epoch 6, Batch 500] loss: 0.08183153426274657
[Epoch 6, Batch 600] loss: 0.08260108878836035
[Epoch 6, Batch 700] loss: 0.07702087737154216
**STATS for Epoch 6** : 
Average training loss: 0.0048
Average validation loss: 0.0841
Validation Accuracy: 0.9747
Overfitting: 0.0792
[Epoch 7, Batch 100] loss: 0.07514291475526988
[Epoch 7, Batch 200] loss: 0.07045600885525345
[Epoch 7, Batch 300] loss: 0.0796675338409841
[Epoch 7, Batch 400] loss: 0.07273113131523132
[Epoch 7, Batch 500] loss: 0.06954518356826156
[Epoch 7, Batch 600] loss: 0.0805373724270612
[Epoch 7, Batch 700] loss: 0.06764194395393133
**STATS for Epoch 7** : 
Average training loss: 0.0044
Average validation loss: 0.0796
Validation Accuracy: 0.9766
Overfitting: 0.0752
[Epoch 8, Batch 100] loss: 0.0643965252302587
[Epoch 8, Batch 200] loss: 0.07227878383360803
[Epoch 8, Batch 300] loss: 0.06251964827999473
[Epoch 8, Batch 400] loss: 0.07424829975701869
[Epoch 8, Batch 500] loss: 0.06181945729535073
[Epoch 8, Batch 600] loss: 0.0654327043145895
[Epoch 8, Batch 700] loss: 0.06497029833495617
**STATS for Epoch 8** : 
Average training loss: 0.0046
Average validation loss: 0.0792
Validation Accuracy: 0.9752
Overfitting: 0.0746
[Epoch 9, Batch 100] loss: 0.06776837442070245
[Epoch 9, Batch 200] loss: 0.05806148345582187
[Epoch 9, Batch 300] loss: 0.05891267922241241
[Epoch 9, Batch 400] loss: 0.05900602355133742
[Epoch 9, Batch 500] loss: 0.06238780067302287
[Epoch 9, Batch 600] loss: 0.05981287828180939
[Epoch 9, Batch 700] loss: 0.06330021786969155
**STATS for Epoch 9** : 
Average training loss: 0.0036
Average validation loss: 0.0666
Validation Accuracy: 0.9810
Overfitting: 0.0629
Best model saved at epoch 9 with validation loss: 0.0666
[Epoch 10, Batch 100] loss: 0.05573408983182162
[Epoch 10, Batch 200] loss: 0.06254149651620537
[Epoch 10, Batch 300] loss: 0.058720832760445776
[Epoch 10, Batch 400] loss: 0.05550215950235724
[Epoch 10, Batch 500] loss: 0.05441382007440552
[Epoch 10, Batch 600] loss: 0.06209160685073584
[Epoch 10, Batch 700] loss: 0.050822109498549255
**STATS for Epoch 10** : 
Average training loss: 0.0026
Average validation loss: 0.0721
Validation Accuracy: 0.9767
Overfitting: 0.0695
[Epoch 11, Batch 100] loss: 0.048524501877836884
[Epoch 11, Batch 200] loss: 0.052042225340846925
[Epoch 11, Batch 300] loss: 0.052916017372626814
[Epoch 11, Batch 400] loss: 0.05045058269519359
[Epoch 11, Batch 500] loss: 0.04882838463410735
[Epoch 11, Batch 600] loss: 0.0531254932214506
[Epoch 11, Batch 700] loss: 0.05007311732741073
**STATS for Epoch 11** : 
Average training loss: 0.0040
Average validation loss: 0.0735
Validation Accuracy: 0.9774
Overfitting: 0.0694
Early stopping epoch 11 for trial 11. Moving to next fold.
Fold 3 validation loss: 0.0735
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2977750635147096
[Epoch 1, Batch 200] loss: 2.2730400705337526
[Epoch 1, Batch 300] loss: 2.1882840490341184
[Epoch 1, Batch 400] loss: 1.6571978199481965
[Epoch 1, Batch 500] loss: 0.723128069639206
[Epoch 1, Batch 600] loss: 0.4868837769329548
[Epoch 1, Batch 700] loss: 0.3991225190460682
**STATS for Epoch 1** : 
Average training loss: 0.0247
Average validation loss: 0.3633
Validation Accuracy: 0.8854
Overfitting: 0.3385
[Epoch 2, Batch 100] loss: 0.3375258855521679
[Epoch 2, Batch 200] loss: 0.3142218659818172
[Epoch 2, Batch 300] loss: 0.2708121770620346
[Epoch 2, Batch 400] loss: 0.2545940212905407
[Epoch 2, Batch 500] loss: 0.21544021405279637
[Epoch 2, Batch 600] loss: 0.20852278016507625
[Epoch 2, Batch 700] loss: 0.1936496602743864
**STATS for Epoch 2** : 
Average training loss: 0.0117
Average validation loss: 0.1753
Validation Accuracy: 0.9450
Overfitting: 0.1635
[Epoch 3, Batch 100] loss: 0.17074115037918092
[Epoch 3, Batch 200] loss: 0.17678139425814152
[Epoch 3, Batch 300] loss: 0.17196931194514037
[Epoch 3, Batch 400] loss: 0.15791577260941267
[Epoch 3, Batch 500] loss: 0.13940006159245968
[Epoch 3, Batch 600] loss: 0.14471598986536263
[Epoch 3, Batch 700] loss: 0.13763621341437102
**STATS for Epoch 3** : 
Average training loss: 0.0101
Average validation loss: 0.1349
Validation Accuracy: 0.9578
Overfitting: 0.1248
[Epoch 4, Batch 100] loss: 0.1328123052045703
[Epoch 4, Batch 200] loss: 0.1337959106080234
[Epoch 4, Batch 300] loss: 0.11035248976200819
[Epoch 4, Batch 400] loss: 0.11998413789086043
[Epoch 4, Batch 500] loss: 0.11558937465772033
[Epoch 4, Batch 600] loss: 0.11087074335664511
[Epoch 4, Batch 700] loss: 0.11386715300381184
**STATS for Epoch 4** : 
Average training loss: 0.0072
Average validation loss: 0.0989
Validation Accuracy: 0.9688
Overfitting: 0.0917
[Epoch 5, Batch 100] loss: 0.10677560554817318
[Epoch 5, Batch 200] loss: 0.10696990501601249
[Epoch 5, Batch 300] loss: 0.09494041434489191
[Epoch 5, Batch 400] loss: 0.0999753867648542
[Epoch 5, Batch 500] loss: 0.09957371681928634
[Epoch 5, Batch 600] loss: 0.08578390885144473
[Epoch 5, Batch 700] loss: 0.0893597384216264
**STATS for Epoch 5** : 
Average training loss: 0.0060
Average validation loss: 0.0927
Validation Accuracy: 0.9702
Overfitting: 0.0867
[Epoch 6, Batch 100] loss: 0.08560186514630913
[Epoch 6, Batch 200] loss: 0.07869128067977726
[Epoch 6, Batch 300] loss: 0.07853704875335098
[Epoch 6, Batch 400] loss: 0.08970223380252719
[Epoch 6, Batch 500] loss: 0.09494883943349124
[Epoch 6, Batch 600] loss: 0.07962353144772351
[Epoch 6, Batch 700] loss: 0.08868248591199518
**STATS for Epoch 6** : 
Average training loss: 0.0059
Average validation loss: 0.0783
Validation Accuracy: 0.9756
Overfitting: 0.0725
[Epoch 7, Batch 100] loss: 0.08064651340246201
[Epoch 7, Batch 200] loss: 0.07034389769658446
[Epoch 7, Batch 300] loss: 0.07887172016315162
[Epoch 7, Batch 400] loss: 0.08012014056555927
[Epoch 7, Batch 500] loss: 0.07270535981282591
[Epoch 7, Batch 600] loss: 0.07437340138945729
[Epoch 7, Batch 700] loss: 0.06527033941354603
**STATS for Epoch 7** : 
Average training loss: 0.0051
Average validation loss: 0.0766
Validation Accuracy: 0.9754
Overfitting: 0.0716
[Epoch 8, Batch 100] loss: 0.06694038278888911
[Epoch 8, Batch 200] loss: 0.06540577071718871
[Epoch 8, Batch 300] loss: 0.06448851506691426
[Epoch 8, Batch 400] loss: 0.06737573616206646
[Epoch 8, Batch 500] loss: 0.07125816303305328
[Epoch 8, Batch 600] loss: 0.06933043519034982
[Epoch 8, Batch 700] loss: 0.06321721021085977
**STATS for Epoch 8** : 
Average training loss: 0.0050
Average validation loss: 0.0692
Validation Accuracy: 0.9791
Overfitting: 0.0642
[Epoch 9, Batch 100] loss: 0.06937534734606743
[Epoch 9, Batch 200] loss: 0.06073397757485509
[Epoch 9, Batch 300] loss: 0.05706936498172581
[Epoch 9, Batch 400] loss: 0.05999233554583043
[Epoch 9, Batch 500] loss: 0.06513893139082938
[Epoch 9, Batch 600] loss: 0.06198565069120377
[Epoch 9, Batch 700] loss: 0.05280050267232582
**STATS for Epoch 9** : 
Average training loss: 0.0038
Average validation loss: 0.0662
Validation Accuracy: 0.9792
Overfitting: 0.0624
Best model saved at epoch 9 with validation loss: 0.0662
[Epoch 10, Batch 100] loss: 0.04803689995314926
[Epoch 10, Batch 200] loss: 0.063445209171623
[Epoch 10, Batch 300] loss: 0.061509228176437315
[Epoch 10, Batch 400] loss: 0.05673491701716557
[Epoch 10, Batch 500] loss: 0.05848619101103395
[Epoch 10, Batch 600] loss: 0.05290543877054006
[Epoch 10, Batch 700] loss: 0.0615406896173954
**STATS for Epoch 10** : 
Average training loss: 0.0030
Average validation loss: 0.0582
Validation Accuracy: 0.9832
Overfitting: 0.0551
[Epoch 11, Batch 100] loss: 0.04738582101650536
[Epoch 11, Batch 200] loss: 0.05354624046711251
[Epoch 11, Batch 300] loss: 0.04954218594823032
[Epoch 11, Batch 400] loss: 0.05008839117828757
[Epoch 11, Batch 500] loss: 0.04908666419330984
[Epoch 11, Batch 600] loss: 0.05707155435811728
[Epoch 11, Batch 700] loss: 0.043660514359362426
**STATS for Epoch 11** : 
Average training loss: 0.0033
Average validation loss: 0.0589
Validation Accuracy: 0.9823
Overfitting: 0.0556
Early stopping epoch 11 for trial 11. Moving to next fold.
Fold 4 validation loss: 0.0589
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2948369193077087
[Epoch 1, Batch 200] loss: 2.2560122537612917
[Epoch 1, Batch 300] loss: 2.079193124771118
[Epoch 1, Batch 400] loss: 1.1420955294370652
[Epoch 1, Batch 500] loss: 0.5494158458709717
[Epoch 1, Batch 600] loss: 0.4425762963294983
[Epoch 1, Batch 700] loss: 0.3666175499558449
**STATS for Epoch 1** : 
Average training loss: 0.0237
Average validation loss: 0.3522
Validation Accuracy: 0.8908
Overfitting: 0.3286
[Epoch 2, Batch 100] loss: 0.3205393159389496
[Epoch 2, Batch 200] loss: 0.2976989993453026
[Epoch 2, Batch 300] loss: 0.2865602220594883
[Epoch 2, Batch 400] loss: 0.27821483872830866
[Epoch 2, Batch 500] loss: 0.23472022645175458
[Epoch 2, Batch 600] loss: 0.2202912174910307
[Epoch 2, Batch 700] loss: 0.22752969585359095
**STATS for Epoch 2** : 
Average training loss: 0.0142
Average validation loss: 0.2140
Validation Accuracy: 0.9343
Overfitting: 0.1998
[Epoch 3, Batch 100] loss: 0.2106517992913723
[Epoch 3, Batch 200] loss: 0.18549537632614374
[Epoch 3, Batch 300] loss: 0.17218434557318688
[Epoch 3, Batch 400] loss: 0.18538977015763522
[Epoch 3, Batch 500] loss: 0.15352000208571553
[Epoch 3, Batch 600] loss: 0.1672935789078474
[Epoch 3, Batch 700] loss: 0.15393728408962487
**STATS for Epoch 3** : 
Average training loss: 0.0099
Average validation loss: 0.1503
Validation Accuracy: 0.9549
Overfitting: 0.1403
[Epoch 4, Batch 100] loss: 0.13304503535851836
[Epoch 4, Batch 200] loss: 0.135645271576941
[Epoch 4, Batch 300] loss: 0.1260560781881213
[Epoch 4, Batch 400] loss: 0.14137773064896464
[Epoch 4, Batch 500] loss: 0.12590099316090345
[Epoch 4, Batch 600] loss: 0.1293829195294529
[Epoch 4, Batch 700] loss: 0.1212589074112475
**STATS for Epoch 4** : 
Average training loss: 0.0076
Average validation loss: 0.1218
Validation Accuracy: 0.9630
Overfitting: 0.1141
[Epoch 5, Batch 100] loss: 0.11211769826710224
[Epoch 5, Batch 200] loss: 0.09919380158185959
[Epoch 5, Batch 300] loss: 0.10269800821319222
[Epoch 5, Batch 400] loss: 0.1093734347075224
[Epoch 5, Batch 500] loss: 0.11540774986147881
[Epoch 5, Batch 600] loss: 0.09567882278934121
[Epoch 5, Batch 700] loss: 0.0931006739102304
**STATS for Epoch 5** : 
Average training loss: 0.0067
Average validation loss: 0.1042
Validation Accuracy: 0.9663
Overfitting: 0.0975
[Epoch 6, Batch 100] loss: 0.09081747933290898
[Epoch 6, Batch 200] loss: 0.09894023088738323
[Epoch 6, Batch 300] loss: 0.08995170576497913
[Epoch 6, Batch 400] loss: 0.08689367278479039
[Epoch 6, Batch 500] loss: 0.10714588167145848
[Epoch 6, Batch 600] loss: 0.08194029539823532
[Epoch 6, Batch 700] loss: 0.07914824226871132
**STATS for Epoch 6** : 
Average training loss: 0.0057
Average validation loss: 0.0909
Validation Accuracy: 0.9712
Overfitting: 0.0852
[Epoch 7, Batch 100] loss: 0.08328810915350914
[Epoch 7, Batch 200] loss: 0.07382937063463033
[Epoch 7, Batch 300] loss: 0.08057645373046399
[Epoch 7, Batch 400] loss: 0.07808436931110918
[Epoch 7, Batch 500] loss: 0.07905100550502539
[Epoch 7, Batch 600] loss: 0.07144952135160565
[Epoch 7, Batch 700] loss: 0.07348399964161217
**STATS for Epoch 7** : 
Average training loss: 0.0058
Average validation loss: 0.0909
Validation Accuracy: 0.9732
Overfitting: 0.0850
[Epoch 8, Batch 100] loss: 0.07573693846352399
[Epoch 8, Batch 200] loss: 0.07406913333572447
[Epoch 8, Batch 300] loss: 0.07133391117677093
[Epoch 8, Batch 400] loss: 0.06606593140400946
[Epoch 8, Batch 500] loss: 0.07834215076640248
[Epoch 8, Batch 600] loss: 0.06796976964455098
[Epoch 8, Batch 700] loss: 0.06734078589361162
**STATS for Epoch 8** : 
Average training loss: 0.0038
Average validation loss: 0.0754
Validation Accuracy: 0.9762
Overfitting: 0.0716
[Epoch 9, Batch 100] loss: 0.06649313016794622
[Epoch 9, Batch 200] loss: 0.06463448252528906
[Epoch 9, Batch 300] loss: 0.06273884213529528
[Epoch 9, Batch 400] loss: 0.060946694104932246
[Epoch 9, Batch 500] loss: 0.0644624831294641
[Epoch 9, Batch 600] loss: 0.06188512619584799
[Epoch 9, Batch 700] loss: 0.06308225856628269
**STATS for Epoch 9** : 
Average training loss: 0.0042
Average validation loss: 0.0711
Validation Accuracy: 0.9779
Overfitting: 0.0669
Best model saved at epoch 9 with validation loss: 0.0711
[Epoch 10, Batch 100] loss: 0.056096658408641815
[Epoch 10, Batch 200] loss: 0.06046777659561485
[Epoch 10, Batch 300] loss: 0.06389236622024327
[Epoch 10, Batch 400] loss: 0.05520920948125422
[Epoch 10, Batch 500] loss: 0.05975777506828308
[Epoch 10, Batch 600] loss: 0.057730730432085695
[Epoch 10, Batch 700] loss: 0.054128329744562505
**STATS for Epoch 10** : 
Average training loss: 0.0039
Average validation loss: 0.0645
Validation Accuracy: 0.9807
Overfitting: 0.0606
[Epoch 11, Batch 100] loss: 0.05500763828400523
[Epoch 11, Batch 200] loss: 0.06192923557711765
[Epoch 11, Batch 300] loss: 0.046855708446819334
[Epoch 11, Batch 400] loss: 0.05039068610407412
[Epoch 11, Batch 500] loss: 0.0576025928882882
[Epoch 11, Batch 600] loss: 0.04965298510622233
[Epoch 11, Batch 700] loss: 0.0498651703633368
**STATS for Epoch 11** : 
Average training loss: 0.0032
Average validation loss: 0.0747
Validation Accuracy: 0.9762
Overfitting: 0.0715
Early stopping epoch 11 for trial 11. Moving to next fold.
Fold 5 validation loss: 0.0747
Mean validation loss across all folds for Trial 11 is 0.0653 with trial config:  l1: 256, l2: 64, lr: 0.001, batch_size: 64
[I 2024-12-10 05:37:13,741] Trial 10 finished with value: 0.06533532576360541 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.001, 'batch_size': 64}. Best is trial 8 with value: 0.049267951299149224.

Selected Hyperparameters for Trial 12:
  l1: 256, l2: 64, lr: 0.001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.291067020893097
[Epoch 1, Batch 200] loss: 2.238556053638458
[Epoch 1, Batch 300] loss: 1.9763867616653443
[Epoch 1, Batch 400] loss: 1.0796796202659606
[Epoch 1, Batch 500] loss: 0.5989041036367416
[Epoch 1, Batch 600] loss: 0.49356490969657896
[Epoch 1, Batch 700] loss: 0.4223190240561962
[Epoch 1, Batch 800] loss: 0.399613815844059
[Epoch 1, Batch 900] loss: 0.30750238105654715
[Epoch 1, Batch 1000] loss: 0.36801976822316645
[Epoch 1, Batch 1100] loss: 0.2889372338354588
[Epoch 1, Batch 1200] loss: 0.2799755844473839
[Epoch 1, Batch 1300] loss: 0.2400432674959302
[Epoch 1, Batch 1400] loss: 0.22255816485732793
[Epoch 1, Batch 1500] loss: 0.22394982393831014
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1911
Validation Accuracy: 0.9432
Overfitting: 0.1911
[Epoch 2, Batch 100] loss: 0.20751877803355456
[Epoch 2, Batch 200] loss: 0.18285985553637146
[Epoch 2, Batch 300] loss: 0.17918076964095234
[Epoch 2, Batch 400] loss: 0.15230342924594878
[Epoch 2, Batch 500] loss: 0.16719857033342123
[Epoch 2, Batch 600] loss: 0.1694907091371715
[Epoch 2, Batch 700] loss: 0.16707365859299897
[Epoch 2, Batch 800] loss: 0.14953531365841627
[Epoch 2, Batch 900] loss: 0.1369648224301636
[Epoch 2, Batch 1000] loss: 0.1441415324062109
[Epoch 2, Batch 1100] loss: 0.1382502885721624
[Epoch 2, Batch 1200] loss: 0.13804306912235917
[Epoch 2, Batch 1300] loss: 0.12269894168712199
[Epoch 2, Batch 1400] loss: 0.12852520598098635
[Epoch 2, Batch 1500] loss: 0.13387003181502222
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1126
Validation Accuracy: 0.9657
Overfitting: 0.1126
[Epoch 3, Batch 100] loss: 0.11487618257291615
[Epoch 3, Batch 200] loss: 0.11385273066349327
[Epoch 3, Batch 300] loss: 0.12505865415558218
[Epoch 3, Batch 400] loss: 0.11367497341707349
[Epoch 3, Batch 500] loss: 0.11305409829132258
[Epoch 3, Batch 600] loss: 0.110595130501315
[Epoch 3, Batch 700] loss: 0.09798300156369805
[Epoch 3, Batch 800] loss: 0.09701783183496446
[Epoch 3, Batch 900] loss: 0.09873879192164167
[Epoch 3, Batch 1000] loss: 0.08873221634421498
[Epoch 3, Batch 1100] loss: 0.0918624635366723
[Epoch 3, Batch 1200] loss: 0.07654158047866076
[Epoch 3, Batch 1300] loss: 0.09269638292025775
[Epoch 3, Batch 1400] loss: 0.09719397433102131
[Epoch 3, Batch 1500] loss: 0.08522219637874513
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0830
Validation Accuracy: 0.9735
Overfitting: 0.0830
[Epoch 4, Batch 100] loss: 0.08889891633763909
[Epoch 4, Batch 200] loss: 0.08801048948895186
[Epoch 4, Batch 300] loss: 0.08160859690513461
[Epoch 4, Batch 400] loss: 0.07747792168054729
[Epoch 4, Batch 500] loss: 0.08541676523629577
[Epoch 4, Batch 600] loss: 0.0751178971142508
[Epoch 4, Batch 700] loss: 0.08843725259415805
[Epoch 4, Batch 800] loss: 0.06422875555697828
[Epoch 4, Batch 900] loss: 0.07318009802140296
[Epoch 4, Batch 1000] loss: 0.08922356191789732
[Epoch 4, Batch 1100] loss: 0.07829893671907484
[Epoch 4, Batch 1200] loss: 0.0721967302262783
[Epoch 4, Batch 1300] loss: 0.08020588824525475
[Epoch 4, Batch 1400] loss: 0.06654133742675185
[Epoch 4, Batch 1500] loss: 0.05481504987226799
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0631
Validation Accuracy: 0.9802
Overfitting: 0.0631
[Epoch 5, Batch 100] loss: 0.05945253993966617
[Epoch 5, Batch 200] loss: 0.05895715083926916
[Epoch 5, Batch 300] loss: 0.07655782226473093
[Epoch 5, Batch 400] loss: 0.07318804614944384
[Epoch 5, Batch 500] loss: 0.06241548345889896
[Epoch 5, Batch 600] loss: 0.05825410294579342
[Epoch 5, Batch 700] loss: 0.0643848663312383
[Epoch 5, Batch 800] loss: 0.06148458923678845
[Epoch 5, Batch 900] loss: 0.06670668749371543
[Epoch 5, Batch 1000] loss: 0.05979143469943665
[Epoch 5, Batch 1100] loss: 0.05955466340994462
[Epoch 5, Batch 1200] loss: 0.06442710313014686
[Epoch 5, Batch 1300] loss: 0.061435893797315656
[Epoch 5, Batch 1400] loss: 0.0623220494936686
[Epoch 5, Batch 1500] loss: 0.06075844903010875
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0611
Validation Accuracy: 0.9803
Overfitting: 0.0611
[Epoch 6, Batch 100] loss: 0.05066332032438368
[Epoch 6, Batch 200] loss: 0.06281974112382159
[Epoch 6, Batch 300] loss: 0.04898563876980916
[Epoch 6, Batch 400] loss: 0.06254799956805072
[Epoch 6, Batch 500] loss: 0.04739748952211812
[Epoch 6, Batch 600] loss: 0.04901839097728953
[Epoch 6, Batch 700] loss: 0.05550407342845574
[Epoch 6, Batch 800] loss: 0.059319548929343
[Epoch 6, Batch 900] loss: 0.0454240169073455
[Epoch 6, Batch 1000] loss: 0.04852166631259024
[Epoch 6, Batch 1100] loss: 0.054962933292263184
[Epoch 6, Batch 1200] loss: 0.058334369191434234
[Epoch 6, Batch 1300] loss: 0.05534165154327639
[Epoch 6, Batch 1400] loss: 0.05735474587185308
[Epoch 6, Batch 1500] loss: 0.04984020346077159
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0796
Validation Accuracy: 0.9757
Overfitting: 0.0796
[Epoch 7, Batch 100] loss: 0.046561699009034785
[Epoch 7, Batch 200] loss: 0.05236501473234966
[Epoch 7, Batch 300] loss: 0.038027288375305945
[Epoch 7, Batch 400] loss: 0.043055877617443915
[Epoch 7, Batch 500] loss: 0.04236453779914882
[Epoch 7, Batch 600] loss: 0.05546923125279136
[Epoch 7, Batch 700] loss: 0.04735219181748107
[Epoch 7, Batch 800] loss: 0.04377438263152726
[Epoch 7, Batch 900] loss: 0.04156202050042339
[Epoch 7, Batch 1000] loss: 0.043648637352744116
[Epoch 7, Batch 1100] loss: 0.043547778280917555
[Epoch 7, Batch 1200] loss: 0.05726515319547616
[Epoch 7, Batch 1300] loss: 0.04544238778471481
[Epoch 7, Batch 1400] loss: 0.06349362856242806
[Epoch 7, Batch 1500] loss: 0.04109663198702038
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9827
Overfitting: 0.0538
[Epoch 8, Batch 100] loss: 0.03835707806865685
[Epoch 8, Batch 200] loss: 0.03534469120495487
[Epoch 8, Batch 300] loss: 0.03755233066156507
[Epoch 8, Batch 400] loss: 0.03736850330256857
[Epoch 8, Batch 500] loss: 0.052246999598573894
[Epoch 8, Batch 600] loss: 0.04392067245033104
[Epoch 8, Batch 700] loss: 0.03825878877018113
[Epoch 8, Batch 800] loss: 0.0433293776283972
[Epoch 8, Batch 900] loss: 0.038390226984629405
[Epoch 8, Batch 1000] loss: 0.04658681290165987
[Epoch 8, Batch 1100] loss: 0.033760979959042745
[Epoch 8, Batch 1200] loss: 0.04112072600342799
[Epoch 8, Batch 1300] loss: 0.0375652265327517
[Epoch 8, Batch 1400] loss: 0.0391733021553955
[Epoch 8, Batch 1500] loss: 0.0512296062085079
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9832
Overfitting: 0.0556
[Epoch 9, Batch 100] loss: 0.03997621096903458
[Epoch 9, Batch 200] loss: 0.03649093671469018
[Epoch 9, Batch 300] loss: 0.036745558694237845
[Epoch 9, Batch 400] loss: 0.03420582452410599
[Epoch 9, Batch 500] loss: 0.04753619779658038
[Epoch 9, Batch 600] loss: 0.033010973548516634
[Epoch 9, Batch 700] loss: 0.04402914189733565
[Epoch 9, Batch 800] loss: 0.03547405339544639
[Epoch 9, Batch 900] loss: 0.029116978747188115
[Epoch 9, Batch 1000] loss: 0.03537438438390381
[Epoch 9, Batch 1100] loss: 0.031944974126381566
[Epoch 9, Batch 1200] loss: 0.03375407259940402
[Epoch 9, Batch 1300] loss: 0.032576932945521546
[Epoch 9, Batch 1400] loss: 0.03237318006053101
[Epoch 9, Batch 1500] loss: 0.046017284074332566
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9821
Overfitting: 0.0564
Best model saved at epoch 9 with validation loss: 0.0564
[Epoch 10, Batch 100] loss: 0.034715892247040754
[Epoch 10, Batch 200] loss: 0.024482300183153713
[Epoch 10, Batch 300] loss: 0.028922554945456796
[Epoch 10, Batch 400] loss: 0.04987033897603396
[Epoch 10, Batch 500] loss: 0.0361185969345388
[Epoch 10, Batch 600] loss: 0.029508364212233573
[Epoch 10, Batch 700] loss: 0.031371774086146616
[Epoch 10, Batch 800] loss: 0.03554401659464929
[Epoch 10, Batch 900] loss: 0.037585015597287566
[Epoch 10, Batch 1000] loss: 0.030861536880838685
[Epoch 10, Batch 1100] loss: 0.029449565820978022
[Epoch 10, Batch 1200] loss: 0.035051175262779
[Epoch 10, Batch 1300] loss: 0.030391922640847044
[Epoch 10, Batch 1400] loss: 0.031926589086069726
[Epoch 10, Batch 1500] loss: 0.026214880457846448
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9833
Overfitting: 0.0506
[Epoch 11, Batch 100] loss: 0.030213982069835766
[Epoch 11, Batch 200] loss: 0.03340216080658138
[Epoch 11, Batch 300] loss: 0.025991417545301373
[Epoch 11, Batch 400] loss: 0.030657847148686416
[Epoch 11, Batch 500] loss: 0.021931643321877345
[Epoch 11, Batch 600] loss: 0.02403067236591596
[Epoch 11, Batch 700] loss: 0.03592958843975794
[Epoch 11, Batch 800] loss: 0.029673376077553257
[Epoch 11, Batch 900] loss: 0.03385622842994053
[Epoch 11, Batch 1000] loss: 0.026276550741749817
[Epoch 11, Batch 1100] loss: 0.034602700222749264
[Epoch 11, Batch 1200] loss: 0.03229107438732171
[Epoch 11, Batch 1300] loss: 0.03431392808677629
[Epoch 11, Batch 1400] loss: 0.025180441174888983
[Epoch 11, Batch 1500] loss: 0.02483897181635257
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9841
Overfitting: 0.0528
Early stopping epoch 11 for trial 12. Moving to next fold.
Fold 1 validation loss: 0.0528
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2935842180252077
[Epoch 1, Batch 200] loss: 2.2664015102386474
[Epoch 1, Batch 300] loss: 2.1795894730091097
[Epoch 1, Batch 400] loss: 1.6393567079305649
[Epoch 1, Batch 500] loss: 0.6623895478248596
[Epoch 1, Batch 600] loss: 0.47253586336970327
[Epoch 1, Batch 700] loss: 0.4174741992354393
[Epoch 1, Batch 800] loss: 0.3630994475632906
[Epoch 1, Batch 900] loss: 0.3074163180962205
[Epoch 1, Batch 1000] loss: 0.2881201624497771
[Epoch 1, Batch 1100] loss: 0.24568113327026367
[Epoch 1, Batch 1200] loss: 0.24559039793908596
[Epoch 1, Batch 1300] loss: 0.2223034070432186
[Epoch 1, Batch 1400] loss: 0.21868964668363333
[Epoch 1, Batch 1500] loss: 0.20305777676403522
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1909
Validation Accuracy: 0.9423
Overfitting: 0.1909
[Epoch 2, Batch 100] loss: 0.18423416594043374
[Epoch 2, Batch 200] loss: 0.1815237052552402
[Epoch 2, Batch 300] loss: 0.17216309506446123
[Epoch 2, Batch 400] loss: 0.1462542662769556
[Epoch 2, Batch 500] loss: 0.14088170471601189
[Epoch 2, Batch 600] loss: 0.15480849182233214
[Epoch 2, Batch 700] loss: 0.1365307854861021
[Epoch 2, Batch 800] loss: 0.13127188387326896
[Epoch 2, Batch 900] loss: 0.12150806506164372
[Epoch 2, Batch 1000] loss: 0.11838782810606062
[Epoch 2, Batch 1100] loss: 0.10763445549644529
[Epoch 2, Batch 1200] loss: 0.11715955277904869
[Epoch 2, Batch 1300] loss: 0.10436710780952126
[Epoch 2, Batch 1400] loss: 0.12507731075398623
[Epoch 2, Batch 1500] loss: 0.10403215856524184
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1124
Validation Accuracy: 0.9646
Overfitting: 0.1124
[Epoch 3, Batch 100] loss: 0.0998045527562499
[Epoch 3, Batch 200] loss: 0.1083645632583648
[Epoch 3, Batch 300] loss: 0.09420778798870742
[Epoch 3, Batch 400] loss: 0.08980976989027113
[Epoch 3, Batch 500] loss: 0.08952338938368484
[Epoch 3, Batch 600] loss: 0.08577647448750213
[Epoch 3, Batch 700] loss: 0.08537216272205114
[Epoch 3, Batch 800] loss: 0.0864090069802478
[Epoch 3, Batch 900] loss: 0.10580336458981038
[Epoch 3, Batch 1000] loss: 0.08499453461263329
[Epoch 3, Batch 1100] loss: 0.0792268459033221
[Epoch 3, Batch 1200] loss: 0.08895919759757817
[Epoch 3, Batch 1300] loss: 0.07208726662443951
[Epoch 3, Batch 1400] loss: 0.08783663318492473
[Epoch 3, Batch 1500] loss: 0.08047030325047672
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0851
Validation Accuracy: 0.9738
Overfitting: 0.0851
[Epoch 4, Batch 100] loss: 0.069975667395629
[Epoch 4, Batch 200] loss: 0.07269075190648437
[Epoch 4, Batch 300] loss: 0.06267920826096088
[Epoch 4, Batch 400] loss: 0.059764264225959776
[Epoch 4, Batch 500] loss: 0.07130342883057893
[Epoch 4, Batch 600] loss: 0.07033728715498
[Epoch 4, Batch 700] loss: 0.07021085184067488
[Epoch 4, Batch 800] loss: 0.07160605798242614
[Epoch 4, Batch 900] loss: 0.07086226721992717
[Epoch 4, Batch 1000] loss: 0.057600597543641927
[Epoch 4, Batch 1100] loss: 0.07504640226718039
[Epoch 4, Batch 1200] loss: 0.07062697306042537
[Epoch 4, Batch 1300] loss: 0.0672622452606447
[Epoch 4, Batch 1400] loss: 0.05522080026101321
[Epoch 4, Batch 1500] loss: 0.07129360069520771
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0920
Validation Accuracy: 0.9711
Overfitting: 0.0920
[Epoch 5, Batch 100] loss: 0.056141712416429075
[Epoch 5, Batch 200] loss: 0.059883856598753483
[Epoch 5, Batch 300] loss: 0.06369449317222461
[Epoch 5, Batch 400] loss: 0.06830026821000501
[Epoch 5, Batch 500] loss: 0.05762504054931924
[Epoch 5, Batch 600] loss: 0.06688156737945974
[Epoch 5, Batch 700] loss: 0.055622899582376706
[Epoch 5, Batch 800] loss: 0.053134274964686486
[Epoch 5, Batch 900] loss: 0.04366405535605736
[Epoch 5, Batch 1000] loss: 0.05615300787379965
[Epoch 5, Batch 1100] loss: 0.05399543282808736
[Epoch 5, Batch 1200] loss: 0.06522577047115191
[Epoch 5, Batch 1300] loss: 0.05575252594193444
[Epoch 5, Batch 1400] loss: 0.05911706214188598
[Epoch 5, Batch 1500] loss: 0.04715368907782249
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0664
Validation Accuracy: 0.9785
Overfitting: 0.0664
[Epoch 6, Batch 100] loss: 0.048610884634545076
[Epoch 6, Batch 200] loss: 0.04296867305180058
[Epoch 6, Batch 300] loss: 0.054086136273108425
[Epoch 6, Batch 400] loss: 0.052791788482572884
[Epoch 6, Batch 500] loss: 0.04630219129321631
[Epoch 6, Batch 600] loss: 0.04683071670762729
[Epoch 6, Batch 700] loss: 0.047834045237395914
[Epoch 6, Batch 800] loss: 0.04195485033560544
[Epoch 6, Batch 900] loss: 0.0585837878100574
[Epoch 6, Batch 1000] loss: 0.05577861885656603
[Epoch 6, Batch 1100] loss: 0.04003568997140974
[Epoch 6, Batch 1200] loss: 0.048964959075674414
[Epoch 6, Batch 1300] loss: 0.04279692510375753
[Epoch 6, Batch 1400] loss: 0.06088795941032003
[Epoch 6, Batch 1500] loss: 0.04452598327945452
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0643
Validation Accuracy: 0.9797
Overfitting: 0.0643
[Epoch 7, Batch 100] loss: 0.04208436204760801
[Epoch 7, Batch 200] loss: 0.04679313293425366
[Epoch 7, Batch 300] loss: 0.04781731934403069
[Epoch 7, Batch 400] loss: 0.04823498988465871
[Epoch 7, Batch 500] loss: 0.032889513249974696
[Epoch 7, Batch 600] loss: 0.038651487029856074
[Epoch 7, Batch 700] loss: 0.04091022287553642
[Epoch 7, Batch 800] loss: 0.04776247253408655
[Epoch 7, Batch 900] loss: 0.040638237826060505
[Epoch 7, Batch 1000] loss: 0.04457136300567072
[Epoch 7, Batch 1100] loss: 0.039683969127945605
[Epoch 7, Batch 1200] loss: 0.03861032803484704
[Epoch 7, Batch 1300] loss: 0.04284752899198793
[Epoch 7, Batch 1400] loss: 0.04712067862972617
[Epoch 7, Batch 1500] loss: 0.03971425784402527
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0613
Validation Accuracy: 0.9815
Overfitting: 0.0613
[Epoch 8, Batch 100] loss: 0.03953580596018583
[Epoch 8, Batch 200] loss: 0.037858140514581466
[Epoch 8, Batch 300] loss: 0.055709618468536067
[Epoch 8, Batch 400] loss: 0.039831582263577726
[Epoch 8, Batch 500] loss: 0.03785050665144809
[Epoch 8, Batch 600] loss: 0.032969357245019634
[Epoch 8, Batch 700] loss: 0.038804072095663285
[Epoch 8, Batch 800] loss: 0.034262569050770256
[Epoch 8, Batch 900] loss: 0.03672107313061133
[Epoch 8, Batch 1000] loss: 0.039161727140308356
[Epoch 8, Batch 1100] loss: 0.0430943845375441
[Epoch 8, Batch 1200] loss: 0.04660040457500145
[Epoch 8, Batch 1300] loss: 0.032783609505277124
[Epoch 8, Batch 1400] loss: 0.03197350100090261
[Epoch 8, Batch 1500] loss: 0.04127365832857322
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0537
Validation Accuracy: 0.9829
Overfitting: 0.0537
[Epoch 9, Batch 100] loss: 0.02696118316031061
[Epoch 9, Batch 200] loss: 0.04075928885722533
[Epoch 9, Batch 300] loss: 0.028866954146069476
[Epoch 9, Batch 400] loss: 0.029304963963804765
[Epoch 9, Batch 500] loss: 0.03805322226719
[Epoch 9, Batch 600] loss: 0.034731079780030996
[Epoch 9, Batch 700] loss: 0.038505840918514875
[Epoch 9, Batch 800] loss: 0.0408295823878143
[Epoch 9, Batch 900] loss: 0.033053273600817196
[Epoch 9, Batch 1000] loss: 0.03790790633531287
[Epoch 9, Batch 1100] loss: 0.033313734225812366
[Epoch 9, Batch 1200] loss: 0.03381136311218143
[Epoch 9, Batch 1300] loss: 0.035709598017856475
[Epoch 9, Batch 1400] loss: 0.03306760031846352
[Epoch 9, Batch 1500] loss: 0.03105835019145161
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9851
Overfitting: 0.0493
Best model saved at epoch 9 with validation loss: 0.0493
[Epoch 10, Batch 100] loss: 0.0270150434577954
[Epoch 10, Batch 200] loss: 0.02489376855955925
[Epoch 10, Batch 300] loss: 0.03746272824413609
[Epoch 10, Batch 400] loss: 0.034153127708123066
[Epoch 10, Batch 500] loss: 0.03482094397069886
[Epoch 10, Batch 600] loss: 0.028120828548562713
[Epoch 10, Batch 700] loss: 0.025025690135662443
[Epoch 10, Batch 800] loss: 0.03257827060529962
[Epoch 10, Batch 900] loss: 0.03044007242482621
[Epoch 10, Batch 1000] loss: 0.03516358508320991
[Epoch 10, Batch 1100] loss: 0.030125153913977555
[Epoch 10, Batch 1200] loss: 0.030112929998431355
[Epoch 10, Batch 1300] loss: 0.03897976352658589
[Epoch 10, Batch 1400] loss: 0.029993060753913597
[Epoch 10, Batch 1500] loss: 0.035512249201710804
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9847
Overfitting: 0.0500
[Epoch 11, Batch 100] loss: 0.02601172669616062
[Epoch 11, Batch 200] loss: 0.027909844375099056
[Epoch 11, Batch 300] loss: 0.026127658695331776
[Epoch 11, Batch 400] loss: 0.01991784064739477
[Epoch 11, Batch 500] loss: 0.03566102458717069
[Epoch 11, Batch 600] loss: 0.02459884381169104
[Epoch 11, Batch 700] loss: 0.026862770903971978
[Epoch 11, Batch 800] loss: 0.030086956005252432
[Epoch 11, Batch 900] loss: 0.02717810491711134
[Epoch 11, Batch 1000] loss: 0.029448592714616098
[Epoch 11, Batch 1100] loss: 0.03272836531599751
[Epoch 11, Batch 1200] loss: 0.03609677288855892
[Epoch 11, Batch 1300] loss: 0.035832413374446336
[Epoch 11, Batch 1400] loss: 0.032801948683627416
[Epoch 11, Batch 1500] loss: 0.02832344853959512
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0535
Validation Accuracy: 0.9840
Overfitting: 0.0535
Early stopping epoch 11 for trial 12. Moving to next fold.
Fold 2 validation loss: 0.0535
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2859797716140746
[Epoch 1, Batch 200] loss: 2.206196656227112
[Epoch 1, Batch 300] loss: 1.6797992616891861
[Epoch 1, Batch 400] loss: 0.7441851752996445
[Epoch 1, Batch 500] loss: 0.49147517085075376
[Epoch 1, Batch 600] loss: 0.4701619079709053
[Epoch 1, Batch 700] loss: 0.38317819926887753
[Epoch 1, Batch 800] loss: 0.34469721756875515
[Epoch 1, Batch 900] loss: 0.33592551697045564
[Epoch 1, Batch 1000] loss: 0.2936792853474617
[Epoch 1, Batch 1100] loss: 0.28709152795374393
[Epoch 1, Batch 1200] loss: 0.26229013785719874
[Epoch 1, Batch 1300] loss: 0.224030549377203
[Epoch 1, Batch 1400] loss: 0.22974559985101223
[Epoch 1, Batch 1500] loss: 0.20652602687478067
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1938
Validation Accuracy: 0.9443
Overfitting: 0.1938
[Epoch 2, Batch 100] loss: 0.1876325076818466
[Epoch 2, Batch 200] loss: 0.16221513841301202
[Epoch 2, Batch 300] loss: 0.19585583083331584
[Epoch 2, Batch 400] loss: 0.1640452796779573
[Epoch 2, Batch 500] loss: 0.17017028755508362
[Epoch 2, Batch 600] loss: 0.18361570131033658
[Epoch 2, Batch 700] loss: 0.16661204857751727
[Epoch 2, Batch 800] loss: 0.13656136963516474
[Epoch 2, Batch 900] loss: 0.14512508508749306
[Epoch 2, Batch 1000] loss: 0.14667784547433257
[Epoch 2, Batch 1100] loss: 0.13509382840245962
[Epoch 2, Batch 1200] loss: 0.11491973456926644
[Epoch 2, Batch 1300] loss: 0.12504444763064385
[Epoch 2, Batch 1400] loss: 0.14347976848483085
[Epoch 2, Batch 1500] loss: 0.12856175792869182
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1245
Validation Accuracy: 0.9641
Overfitting: 0.1245
[Epoch 3, Batch 100] loss: 0.09104810554534197
[Epoch 3, Batch 200] loss: 0.10131486074998974
[Epoch 3, Batch 300] loss: 0.1264470753632486
[Epoch 3, Batch 400] loss: 0.10669090555980802
[Epoch 3, Batch 500] loss: 0.11532384813763201
[Epoch 3, Batch 600] loss: 0.10715911232866347
[Epoch 3, Batch 700] loss: 0.11462555410340429
[Epoch 3, Batch 800] loss: 0.0904136053705588
[Epoch 3, Batch 900] loss: 0.12189969756174833
[Epoch 3, Batch 1000] loss: 0.09765318318270147
[Epoch 3, Batch 1100] loss: 0.11180252032354474
[Epoch 3, Batch 1200] loss: 0.10369268725626171
[Epoch 3, Batch 1300] loss: 0.12124792201444506
[Epoch 3, Batch 1400] loss: 0.09835157043766231
[Epoch 3, Batch 1500] loss: 0.0820573697402142
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0913
Validation Accuracy: 0.9719
Overfitting: 0.0913
[Epoch 4, Batch 100] loss: 0.0891518495697528
[Epoch 4, Batch 200] loss: 0.09525869071949274
[Epoch 4, Batch 300] loss: 0.08068812333513051
[Epoch 4, Batch 400] loss: 0.0802868999633938
[Epoch 4, Batch 500] loss: 0.08888926299288868
[Epoch 4, Batch 600] loss: 0.07843950053211302
[Epoch 4, Batch 700] loss: 0.09474878740962595
[Epoch 4, Batch 800] loss: 0.09274044082732871
[Epoch 4, Batch 900] loss: 0.08507767360191792
[Epoch 4, Batch 1000] loss: 0.06924371188972145
[Epoch 4, Batch 1100] loss: 0.08444405072601512
[Epoch 4, Batch 1200] loss: 0.07469639224931597
[Epoch 4, Batch 1300] loss: 0.07615692004095763
[Epoch 4, Batch 1400] loss: 0.0892009447934106
[Epoch 4, Batch 1500] loss: 0.060245847213082016
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0838
Validation Accuracy: 0.9740
Overfitting: 0.0838
[Epoch 5, Batch 100] loss: 0.06590607128106057
[Epoch 5, Batch 200] loss: 0.0668036173901055
[Epoch 5, Batch 300] loss: 0.060694917575456205
[Epoch 5, Batch 400] loss: 0.06780457500834018
[Epoch 5, Batch 500] loss: 0.07754768030834384
[Epoch 5, Batch 600] loss: 0.06970525971380993
[Epoch 5, Batch 700] loss: 0.07195901826955378
[Epoch 5, Batch 800] loss: 0.07027345370035619
[Epoch 5, Batch 900] loss: 0.06380367704899982
[Epoch 5, Batch 1000] loss: 0.06255642950767651
[Epoch 5, Batch 1100] loss: 0.0666028939303942
[Epoch 5, Batch 1200] loss: 0.06232559906085953
[Epoch 5, Batch 1300] loss: 0.06536432704422623
[Epoch 5, Batch 1400] loss: 0.06995244842022658
[Epoch 5, Batch 1500] loss: 0.0712412061728537
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0729
Validation Accuracy: 0.9778
Overfitting: 0.0729
[Epoch 6, Batch 100] loss: 0.05004899273160845
[Epoch 6, Batch 200] loss: 0.056292425115825606
[Epoch 6, Batch 300] loss: 0.05381676473189145
[Epoch 6, Batch 400] loss: 0.06569121407577767
[Epoch 6, Batch 500] loss: 0.06312128689605742
[Epoch 6, Batch 600] loss: 0.04927406916627661
[Epoch 6, Batch 700] loss: 0.06282305412460118
[Epoch 6, Batch 800] loss: 0.06862776373745874
[Epoch 6, Batch 900] loss: 0.05614484313176945
[Epoch 6, Batch 1000] loss: 0.05283505021827296
[Epoch 6, Batch 1100] loss: 0.05292237828951329
[Epoch 6, Batch 1200] loss: 0.07114693616516889
[Epoch 6, Batch 1300] loss: 0.05490234923316166
[Epoch 6, Batch 1400] loss: 0.05747798240801785
[Epoch 6, Batch 1500] loss: 0.05185455312486738
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0629
Validation Accuracy: 0.9815
Overfitting: 0.0629
[Epoch 7, Batch 100] loss: 0.053308928849874065
[Epoch 7, Batch 200] loss: 0.046393853939371184
[Epoch 7, Batch 300] loss: 0.05161817992571741
[Epoch 7, Batch 400] loss: 0.058853301630588245
[Epoch 7, Batch 500] loss: 0.040057327062822876
[Epoch 7, Batch 600] loss: 0.04946787492488511
[Epoch 7, Batch 700] loss: 0.04170888198539615
[Epoch 7, Batch 800] loss: 0.047909647288033735
[Epoch 7, Batch 900] loss: 0.04624209580244496
[Epoch 7, Batch 1000] loss: 0.0562236189073883
[Epoch 7, Batch 1100] loss: 0.060626465991372246
[Epoch 7, Batch 1200] loss: 0.05147692080354318
[Epoch 7, Batch 1300] loss: 0.04379472786153201
[Epoch 7, Batch 1400] loss: 0.0467858880746644
[Epoch 7, Batch 1500] loss: 0.050289097387576476
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9818
Overfitting: 0.0608
[Epoch 8, Batch 100] loss: 0.04261134568136185
[Epoch 8, Batch 200] loss: 0.04010850230930373
[Epoch 8, Batch 300] loss: 0.03645247787702829
[Epoch 8, Batch 400] loss: 0.028461901179980487
[Epoch 8, Batch 500] loss: 0.04714437901973725
[Epoch 8, Batch 600] loss: 0.03635427232016809
[Epoch 8, Batch 700] loss: 0.050479754235129806
[Epoch 8, Batch 800] loss: 0.04474190301902126
[Epoch 8, Batch 900] loss: 0.05485091214242857
[Epoch 8, Batch 1000] loss: 0.04969836667529307
[Epoch 8, Batch 1100] loss: 0.041609718116233124
[Epoch 8, Batch 1200] loss: 0.04329851284332108
[Epoch 8, Batch 1300] loss: 0.05253005220147315
[Epoch 8, Batch 1400] loss: 0.040682557277032176
[Epoch 8, Batch 1500] loss: 0.047350720568792894
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0607
Validation Accuracy: 0.9822
Overfitting: 0.0607
[Epoch 9, Batch 100] loss: 0.03166541555721778
[Epoch 9, Batch 200] loss: 0.033343024664791304
[Epoch 9, Batch 300] loss: 0.03467484557360876
[Epoch 9, Batch 400] loss: 0.04352704186458141
[Epoch 9, Batch 500] loss: 0.04035577469447162
[Epoch 9, Batch 600] loss: 0.035932181476964614
[Epoch 9, Batch 700] loss: 0.028057199981121814
[Epoch 9, Batch 800] loss: 0.030389502252219244
[Epoch 9, Batch 900] loss: 0.043208658702496905
[Epoch 9, Batch 1000] loss: 0.041188150023808705
[Epoch 9, Batch 1100] loss: 0.044320695881033316
[Epoch 9, Batch 1200] loss: 0.0389564138778951
[Epoch 9, Batch 1300] loss: 0.03690478051430546
[Epoch 9, Batch 1400] loss: 0.039745275817695075
[Epoch 9, Batch 1500] loss: 0.03810171088669449
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0557
Validation Accuracy: 0.9842
Overfitting: 0.0557
Best model saved at epoch 9 with validation loss: 0.0557
[Epoch 10, Batch 100] loss: 0.029982258655363695
[Epoch 10, Batch 200] loss: 0.029879304710775614
[Epoch 10, Batch 300] loss: 0.03287406240939163
[Epoch 10, Batch 400] loss: 0.0323949216445908
[Epoch 10, Batch 500] loss: 0.029626568247331307
[Epoch 10, Batch 600] loss: 0.03687581793812569
[Epoch 10, Batch 700] loss: 0.03124957865511533
[Epoch 10, Batch 800] loss: 0.024657427931088022
[Epoch 10, Batch 900] loss: 0.027847066435206215
[Epoch 10, Batch 1000] loss: 0.035063648946234025
[Epoch 10, Batch 1100] loss: 0.050112729467218745
[Epoch 10, Batch 1200] loss: 0.038220891682431105
[Epoch 10, Batch 1300] loss: 0.030472609247663058
[Epoch 10, Batch 1400] loss: 0.03703509074053727
[Epoch 10, Batch 1500] loss: 0.0392774241528241
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0558
Validation Accuracy: 0.9828
Overfitting: 0.0558
[Epoch 11, Batch 100] loss: 0.03121578145539388
[Epoch 11, Batch 200] loss: 0.03355401107924991
[Epoch 11, Batch 300] loss: 0.027389888155448718
[Epoch 11, Batch 400] loss: 0.030977170953701717
[Epoch 11, Batch 500] loss: 0.03487771542859264
[Epoch 11, Batch 600] loss: 0.036489450053777545
[Epoch 11, Batch 700] loss: 0.0212074309081072
[Epoch 11, Batch 800] loss: 0.023190123103267977
[Epoch 11, Batch 900] loss: 0.034153602309525015
[Epoch 11, Batch 1000] loss: 0.0347461748929345
[Epoch 11, Batch 1100] loss: 0.030283048444543964
[Epoch 11, Batch 1200] loss: 0.0334314926029765
[Epoch 11, Batch 1300] loss: 0.031536509181023575
[Epoch 11, Batch 1400] loss: 0.02497245811740868
[Epoch 11, Batch 1500] loss: 0.0269788834018982
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0543
Validation Accuracy: 0.9850
Overfitting: 0.0543
Early stopping epoch 11 for trial 12. Moving to next fold.
Fold 3 validation loss: 0.0543
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2839745759963987
[Epoch 1, Batch 200] loss: 2.170368266105652
[Epoch 1, Batch 300] loss: 1.4551081174612046
[Epoch 1, Batch 400] loss: 0.657066133916378
[Epoch 1, Batch 500] loss: 0.5356276287138462
[Epoch 1, Batch 600] loss: 0.44224161803722384
[Epoch 1, Batch 700] loss: 0.4320736436545849
[Epoch 1, Batch 800] loss: 0.3616302837431431
[Epoch 1, Batch 900] loss: 0.3794227853417397
[Epoch 1, Batch 1000] loss: 0.29044358521699903
[Epoch 1, Batch 1100] loss: 0.28711068391799927
[Epoch 1, Batch 1200] loss: 0.27801125766709445
[Epoch 1, Batch 1300] loss: 0.2728643147274852
[Epoch 1, Batch 1400] loss: 0.23518997985869647
[Epoch 1, Batch 1500] loss: 0.23224576972424985
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2318
Validation Accuracy: 0.9316
Overfitting: 0.2318
[Epoch 2, Batch 100] loss: 0.2014094990864396
[Epoch 2, Batch 200] loss: 0.2109266272932291
[Epoch 2, Batch 300] loss: 0.17654203210026026
[Epoch 2, Batch 400] loss: 0.1681974451057613
[Epoch 2, Batch 500] loss: 0.18013938683085143
[Epoch 2, Batch 600] loss: 0.15803315486758948
[Epoch 2, Batch 700] loss: 0.16106833815574645
[Epoch 2, Batch 800] loss: 0.15802266523241998
[Epoch 2, Batch 900] loss: 0.15065477470867336
[Epoch 2, Batch 1000] loss: 0.1381615959852934
[Epoch 2, Batch 1100] loss: 0.14904311966151
[Epoch 2, Batch 1200] loss: 0.14530232140794397
[Epoch 2, Batch 1300] loss: 0.13732894921675323
[Epoch 2, Batch 1400] loss: 0.13284191505983473
[Epoch 2, Batch 1500] loss: 0.10694889100268483
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1311
Validation Accuracy: 0.9594
Overfitting: 0.1311
[Epoch 3, Batch 100] loss: 0.09810792091302574
[Epoch 3, Batch 200] loss: 0.12036104684695602
[Epoch 3, Batch 300] loss: 0.10948182135354728
[Epoch 3, Batch 400] loss: 0.09759156305808574
[Epoch 3, Batch 500] loss: 0.09891335870604961
[Epoch 3, Batch 600] loss: 0.10343254704959691
[Epoch 3, Batch 700] loss: 0.10250324020162224
[Epoch 3, Batch 800] loss: 0.11353333475999534
[Epoch 3, Batch 900] loss: 0.09941674108617007
[Epoch 3, Batch 1000] loss: 0.09771629734430462
[Epoch 3, Batch 1100] loss: 0.08818260750500485
[Epoch 3, Batch 1200] loss: 0.09566275153309106
[Epoch 3, Batch 1300] loss: 0.1103768855938688
[Epoch 3, Batch 1400] loss: 0.09361322288401425
[Epoch 3, Batch 1500] loss: 0.09758519188035279
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0872
Validation Accuracy: 0.9709
Overfitting: 0.0872
[Epoch 4, Batch 100] loss: 0.08406629401259125
[Epoch 4, Batch 200] loss: 0.0915011419961229
[Epoch 4, Batch 300] loss: 0.0881989483628422
[Epoch 4, Batch 400] loss: 0.09399581554811448
[Epoch 4, Batch 500] loss: 0.077676963172853
[Epoch 4, Batch 600] loss: 0.08099095528712497
[Epoch 4, Batch 700] loss: 0.08155906776897609
[Epoch 4, Batch 800] loss: 0.08995542034041136
[Epoch 4, Batch 900] loss: 0.07071116780862212
[Epoch 4, Batch 1000] loss: 0.07231671020854265
[Epoch 4, Batch 1100] loss: 0.06967146715847776
[Epoch 4, Batch 1200] loss: 0.07756120385834947
[Epoch 4, Batch 1300] loss: 0.07516996629070491
[Epoch 4, Batch 1400] loss: 0.07106258918996901
[Epoch 4, Batch 1500] loss: 0.07776837321929633
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0790
Validation Accuracy: 0.9759
Overfitting: 0.0790
[Epoch 5, Batch 100] loss: 0.05430802994407714
[Epoch 5, Batch 200] loss: 0.07146332152187825
[Epoch 5, Batch 300] loss: 0.06610630025621504
[Epoch 5, Batch 400] loss: 0.07572821765439584
[Epoch 5, Batch 500] loss: 0.0569032589206472
[Epoch 5, Batch 600] loss: 0.06701307120500133
[Epoch 5, Batch 700] loss: 0.05836014515953138
[Epoch 5, Batch 800] loss: 0.06316304109292105
[Epoch 5, Batch 900] loss: 0.05604469026206061
[Epoch 5, Batch 1000] loss: 0.06765561269130557
[Epoch 5, Batch 1100] loss: 0.06328638290986419
[Epoch 5, Batch 1200] loss: 0.07025552251841873
[Epoch 5, Batch 1300] loss: 0.06313987842993811
[Epoch 5, Batch 1400] loss: 0.06831673998618498
[Epoch 5, Batch 1500] loss: 0.06151207698276266
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0633
Validation Accuracy: 0.9799
Overfitting: 0.0633
[Epoch 6, Batch 100] loss: 0.052609772195573896
[Epoch 6, Batch 200] loss: 0.062418898330070076
[Epoch 6, Batch 300] loss: 0.060923789362423125
[Epoch 6, Batch 400] loss: 0.04422824791341554
[Epoch 6, Batch 500] loss: 0.07113206878420897
[Epoch 6, Batch 600] loss: 0.05624977251281962
[Epoch 6, Batch 700] loss: 0.056136383647099136
[Epoch 6, Batch 800] loss: 0.06067204166902229
[Epoch 6, Batch 900] loss: 0.05053450971492566
[Epoch 6, Batch 1000] loss: 0.052783720351289955
[Epoch 6, Batch 1100] loss: 0.047357085046824066
[Epoch 6, Batch 1200] loss: 0.05397166192065925
[Epoch 6, Batch 1300] loss: 0.05521065225359052
[Epoch 6, Batch 1400] loss: 0.05510673461249098
[Epoch 6, Batch 1500] loss: 0.040616985391825434
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0546
Validation Accuracy: 0.9832
Overfitting: 0.0546
[Epoch 7, Batch 100] loss: 0.041564039823133496
[Epoch 7, Batch 200] loss: 0.049505302096949894
[Epoch 7, Batch 300] loss: 0.05100118761998601
[Epoch 7, Batch 400] loss: 0.050363253698451446
[Epoch 7, Batch 500] loss: 0.0484264063637238
[Epoch 7, Batch 600] loss: 0.041500007809372616
[Epoch 7, Batch 700] loss: 0.03931771209579892
[Epoch 7, Batch 800] loss: 0.03947271740995348
[Epoch 7, Batch 900] loss: 0.05289400806999765
[Epoch 7, Batch 1000] loss: 0.05599236979382113
[Epoch 7, Batch 1100] loss: 0.04378803317144048
[Epoch 7, Batch 1200] loss: 0.05769187615253031
[Epoch 7, Batch 1300] loss: 0.05425271456188056
[Epoch 7, Batch 1400] loss: 0.0441938604018651
[Epoch 7, Batch 1500] loss: 0.0439528420829447
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9824
Overfitting: 0.0570
[Epoch 8, Batch 100] loss: 0.04661316975558293
[Epoch 8, Batch 200] loss: 0.03568186680553481
[Epoch 8, Batch 300] loss: 0.039330142876133324
[Epoch 8, Batch 400] loss: 0.05295900012832135
[Epoch 8, Batch 500] loss: 0.025039033698558342
[Epoch 8, Batch 600] loss: 0.03680328223417746
[Epoch 8, Batch 700] loss: 0.04706710668862797
[Epoch 8, Batch 800] loss: 0.04442757658136543
[Epoch 8, Batch 900] loss: 0.04665823745366651
[Epoch 8, Batch 1000] loss: 0.03282725105294958
[Epoch 8, Batch 1100] loss: 0.04544167004467454
[Epoch 8, Batch 1200] loss: 0.037696436471305786
[Epoch 8, Batch 1300] loss: 0.05107073942665011
[Epoch 8, Batch 1400] loss: 0.04126125239999965
[Epoch 8, Batch 1500] loss: 0.05275550499616657
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9826
Overfitting: 0.0552
[Epoch 9, Batch 100] loss: 0.02992773912032135
[Epoch 9, Batch 200] loss: 0.04483286444854457
[Epoch 9, Batch 300] loss: 0.037411265616538
[Epoch 9, Batch 400] loss: 0.04342910413950449
[Epoch 9, Batch 500] loss: 0.03437748013879172
[Epoch 9, Batch 600] loss: 0.03193749103927985
[Epoch 9, Batch 700] loss: 0.03649413360224571
[Epoch 9, Batch 800] loss: 0.03992920946853701
[Epoch 9, Batch 900] loss: 0.03864637514576316
[Epoch 9, Batch 1000] loss: 0.036429025185061616
[Epoch 9, Batch 1100] loss: 0.03397415257408284
[Epoch 9, Batch 1200] loss: 0.04185036531998776
[Epoch 9, Batch 1300] loss: 0.04427245120867156
[Epoch 9, Batch 1400] loss: 0.048657523156143724
[Epoch 9, Batch 1500] loss: 0.03002818185952492
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9849
Overfitting: 0.0491
Best model saved at epoch 9 with validation loss: 0.0491
[Epoch 10, Batch 100] loss: 0.02727247197472025
[Epoch 10, Batch 200] loss: 0.040617684135213494
[Epoch 10, Batch 300] loss: 0.03743099365208764
[Epoch 10, Batch 400] loss: 0.032199789845617485
[Epoch 10, Batch 500] loss: 0.044279978591948745
[Epoch 10, Batch 600] loss: 0.029221837568329648
[Epoch 10, Batch 700] loss: 0.0358946926810313
[Epoch 10, Batch 800] loss: 0.029063072043354624
[Epoch 10, Batch 900] loss: 0.033780437571113
[Epoch 10, Batch 1000] loss: 0.0480076258603367
[Epoch 10, Batch 1100] loss: 0.039024792824639006
[Epoch 10, Batch 1200] loss: 0.03215800127247349
[Epoch 10, Batch 1300] loss: 0.0347168980864808
[Epoch 10, Batch 1400] loss: 0.0366087838151725
[Epoch 10, Batch 1500] loss: 0.025403152202488854
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9839
Overfitting: 0.0532
[Epoch 11, Batch 100] loss: 0.031998829556396234
[Epoch 11, Batch 200] loss: 0.03733152968576178
[Epoch 11, Batch 300] loss: 0.024328260515467263
[Epoch 11, Batch 400] loss: 0.028428981270408257
[Epoch 11, Batch 500] loss: 0.037246029863599685
[Epoch 11, Batch 600] loss: 0.03397448366216849
[Epoch 11, Batch 700] loss: 0.03242245759931393
[Epoch 11, Batch 800] loss: 0.030608828180702402
[Epoch 11, Batch 900] loss: 0.024219309253967366
[Epoch 11, Batch 1000] loss: 0.032594033540808594
[Epoch 11, Batch 1100] loss: 0.0316494081512792
[Epoch 11, Batch 1200] loss: 0.037108826179464816
[Epoch 11, Batch 1300] loss: 0.031216744857665617
[Epoch 11, Batch 1400] loss: 0.027439325791201553
[Epoch 11, Batch 1500] loss: 0.033449500901188006
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9862
Overfitting: 0.0476
Early stopping epoch 11 for trial 12. Moving to next fold.
Fold 4 validation loss: 0.0476
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.279321057796478
[Epoch 1, Batch 200] loss: 2.1546465909481047
[Epoch 1, Batch 300] loss: 1.4744305717945099
[Epoch 1, Batch 400] loss: 0.7787522676587105
[Epoch 1, Batch 500] loss: 0.5858430562913418
[Epoch 1, Batch 600] loss: 0.46811638921499255
[Epoch 1, Batch 700] loss: 0.4198155127465725
[Epoch 1, Batch 800] loss: 0.3739632922410965
[Epoch 1, Batch 900] loss: 0.35089626014232633
[Epoch 1, Batch 1000] loss: 0.32855147406458857
[Epoch 1, Batch 1100] loss: 0.29353256195783617
[Epoch 1, Batch 1200] loss: 0.2726079458370805
[Epoch 1, Batch 1300] loss: 0.24818311367183923
[Epoch 1, Batch 1400] loss: 0.2550225134566426
[Epoch 1, Batch 1500] loss: 0.22693543411791325
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2231
Validation Accuracy: 0.9338
Overfitting: 0.2231
[Epoch 2, Batch 100] loss: 0.21755973238497972
[Epoch 2, Batch 200] loss: 0.19220974007621408
[Epoch 2, Batch 300] loss: 0.19897084001451731
[Epoch 2, Batch 400] loss: 0.19380924567580224
[Epoch 2, Batch 500] loss: 0.1729184011183679
[Epoch 2, Batch 600] loss: 0.17308052103966476
[Epoch 2, Batch 700] loss: 0.16832291448488831
[Epoch 2, Batch 800] loss: 0.17282285088673233
[Epoch 2, Batch 900] loss: 0.16455628165975214
[Epoch 2, Batch 1000] loss: 0.14779816393740475
[Epoch 2, Batch 1100] loss: 0.1285694885533303
[Epoch 2, Batch 1200] loss: 0.14191912841051818
[Epoch 2, Batch 1300] loss: 0.14319214620627463
[Epoch 2, Batch 1400] loss: 0.14283005768433213
[Epoch 2, Batch 1500] loss: 0.12793933156877757
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1319
Validation Accuracy: 0.9606
Overfitting: 0.1319
[Epoch 3, Batch 100] loss: 0.11653759069740773
[Epoch 3, Batch 200] loss: 0.12909914579242468
[Epoch 3, Batch 300] loss: 0.12360828321427107
[Epoch 3, Batch 400] loss: 0.11254204724915326
[Epoch 3, Batch 500] loss: 0.1168418494798243
[Epoch 3, Batch 600] loss: 0.1174738774355501
[Epoch 3, Batch 700] loss: 0.10790850040502846
[Epoch 3, Batch 800] loss: 0.0952433058526367
[Epoch 3, Batch 900] loss: 0.10536614422686398
[Epoch 3, Batch 1000] loss: 0.10462869781069457
[Epoch 3, Batch 1100] loss: 0.09758598137646914
[Epoch 3, Batch 1200] loss: 0.09444949006661772
[Epoch 3, Batch 1300] loss: 0.09425356023013592
[Epoch 3, Batch 1400] loss: 0.09330308748874813
[Epoch 3, Batch 1500] loss: 0.09202279248042032
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0865
Validation Accuracy: 0.9725
Overfitting: 0.0865
[Epoch 4, Batch 100] loss: 0.09340702334418893
[Epoch 4, Batch 200] loss: 0.08274730857461692
[Epoch 4, Batch 300] loss: 0.08161671462235973
[Epoch 4, Batch 400] loss: 0.08914289019769057
[Epoch 4, Batch 500] loss: 0.07493118919432164
[Epoch 4, Batch 600] loss: 0.08069425247143953
[Epoch 4, Batch 700] loss: 0.0826228173961863
[Epoch 4, Batch 800] loss: 0.08231663063634187
[Epoch 4, Batch 900] loss: 0.07351203682366758
[Epoch 4, Batch 1000] loss: 0.06945816179038956
[Epoch 4, Batch 1100] loss: 0.07390902685932815
[Epoch 4, Batch 1200] loss: 0.09173548882827162
[Epoch 4, Batch 1300] loss: 0.08996042413404211
[Epoch 4, Batch 1400] loss: 0.09379012969788164
[Epoch 4, Batch 1500] loss: 0.07066185087198391
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0785
Validation Accuracy: 0.9738
Overfitting: 0.0785
[Epoch 5, Batch 100] loss: 0.09066524786874652
[Epoch 5, Batch 200] loss: 0.0634250879427418
[Epoch 5, Batch 300] loss: 0.06917437894968316
[Epoch 5, Batch 400] loss: 0.07949963747058064
[Epoch 5, Batch 500] loss: 0.06055413401219994
[Epoch 5, Batch 600] loss: 0.07940650579752401
[Epoch 5, Batch 700] loss: 0.06171651422977448
[Epoch 5, Batch 800] loss: 0.07808110319310799
[Epoch 5, Batch 900] loss: 0.05953348269220442
[Epoch 5, Batch 1000] loss: 0.05678852661047131
[Epoch 5, Batch 1100] loss: 0.058870820854790507
[Epoch 5, Batch 1200] loss: 0.06585207459283993
[Epoch 5, Batch 1300] loss: 0.07492905748542399
[Epoch 5, Batch 1400] loss: 0.055797977664042264
[Epoch 5, Batch 1500] loss: 0.07172347166808322
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0712
Validation Accuracy: 0.9784
Overfitting: 0.0712
[Epoch 6, Batch 100] loss: 0.058940664600813764
[Epoch 6, Batch 200] loss: 0.062462628509383646
[Epoch 6, Batch 300] loss: 0.05854531820164993
[Epoch 6, Batch 400] loss: 0.060227655087364836
[Epoch 6, Batch 500] loss: 0.07021821119124069
[Epoch 6, Batch 600] loss: 0.04775563183706254
[Epoch 6, Batch 700] loss: 0.059833766269148325
[Epoch 6, Batch 800] loss: 0.0498377929686103
[Epoch 6, Batch 900] loss: 0.050604197403881696
[Epoch 6, Batch 1000] loss: 0.059381947700167075
[Epoch 6, Batch 1100] loss: 0.06947411385364831
[Epoch 6, Batch 1200] loss: 0.057697923011146485
[Epoch 6, Batch 1300] loss: 0.05292441512690857
[Epoch 6, Batch 1400] loss: 0.06966943103587254
[Epoch 6, Batch 1500] loss: 0.06335124908131547
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9792
Overfitting: 0.0665
[Epoch 7, Batch 100] loss: 0.04564903989201412
[Epoch 7, Batch 200] loss: 0.053911224781768394
[Epoch 7, Batch 300] loss: 0.05034732358937617
[Epoch 7, Batch 400] loss: 0.0568049243290443
[Epoch 7, Batch 500] loss: 0.06526961661991663
[Epoch 7, Batch 600] loss: 0.0592002503038384
[Epoch 7, Batch 700] loss: 0.0516781765356427
[Epoch 7, Batch 800] loss: 0.0439545432291925
[Epoch 7, Batch 900] loss: 0.042457849575439466
[Epoch 7, Batch 1000] loss: 0.043140082595054995
[Epoch 7, Batch 1100] loss: 0.05753126701805741
[Epoch 7, Batch 1200] loss: 0.04919207511178683
[Epoch 7, Batch 1300] loss: 0.044810494481935165
[Epoch 7, Batch 1400] loss: 0.04491413241601549
[Epoch 7, Batch 1500] loss: 0.0530963496491313
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0578
Validation Accuracy: 0.9828
Overfitting: 0.0578
[Epoch 8, Batch 100] loss: 0.04282405210658908
[Epoch 8, Batch 200] loss: 0.03710544011322781
[Epoch 8, Batch 300] loss: 0.04263772381003946
[Epoch 8, Batch 400] loss: 0.048334493567235765
[Epoch 8, Batch 500] loss: 0.05351579700596631
[Epoch 8, Batch 600] loss: 0.04654565356846433
[Epoch 8, Batch 700] loss: 0.06061929388786666
[Epoch 8, Batch 800] loss: 0.0587091202463489
[Epoch 8, Batch 900] loss: 0.04125725346617401
[Epoch 8, Batch 1000] loss: 0.04225384818040766
[Epoch 8, Batch 1100] loss: 0.0556795844680164
[Epoch 8, Batch 1200] loss: 0.04646887952578254
[Epoch 8, Batch 1300] loss: 0.03417427435575519
[Epoch 8, Batch 1400] loss: 0.04650462496385444
[Epoch 8, Batch 1500] loss: 0.03799245936505031
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0525
Validation Accuracy: 0.9845
Overfitting: 0.0525
[Epoch 9, Batch 100] loss: 0.057946612027008085
[Epoch 9, Batch 200] loss: 0.04854942991922144
[Epoch 9, Batch 300] loss: 0.030194429820985535
[Epoch 9, Batch 400] loss: 0.03727655161172152
[Epoch 9, Batch 500] loss: 0.04924008915317245
[Epoch 9, Batch 600] loss: 0.03483949937450234
[Epoch 9, Batch 700] loss: 0.03506938151782379
[Epoch 9, Batch 800] loss: 0.051003215786186044
[Epoch 9, Batch 900] loss: 0.03785563407596783
[Epoch 9, Batch 1000] loss: 0.044571660703513774
[Epoch 9, Batch 1100] loss: 0.037270679612411185
[Epoch 9, Batch 1200] loss: 0.04034727237885818
[Epoch 9, Batch 1300] loss: 0.04029304958545254
[Epoch 9, Batch 1400] loss: 0.034719747393974106
[Epoch 9, Batch 1500] loss: 0.04074748764629476
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9829
Overfitting: 0.0544
Best model saved at epoch 9 with validation loss: 0.0544
[Epoch 10, Batch 100] loss: 0.028181768614740577
[Epoch 10, Batch 200] loss: 0.04360764600685798
[Epoch 10, Batch 300] loss: 0.029822295585472603
[Epoch 10, Batch 400] loss: 0.029922630233340897
[Epoch 10, Batch 500] loss: 0.03545168907672633
[Epoch 10, Batch 600] loss: 0.03573863708457793
[Epoch 10, Batch 700] loss: 0.035347909898264335
[Epoch 10, Batch 800] loss: 0.033514300012320745
[Epoch 10, Batch 900] loss: 0.046943943771184424
[Epoch 10, Batch 1000] loss: 0.02759435443847906
[Epoch 10, Batch 1100] loss: 0.031013119124691003
[Epoch 10, Batch 1200] loss: 0.04904068968899082
[Epoch 10, Batch 1300] loss: 0.03634780121210497
[Epoch 10, Batch 1400] loss: 0.036864039652282375
[Epoch 10, Batch 1500] loss: 0.0417970217182301
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0469
Validation Accuracy: 0.9856
Overfitting: 0.0469
[Epoch 11, Batch 100] loss: 0.03779646291513927
[Epoch 11, Batch 200] loss: 0.0365973430610029
[Epoch 11, Batch 300] loss: 0.035564145453390664
[Epoch 11, Batch 400] loss: 0.03138474414125085
[Epoch 11, Batch 500] loss: 0.026049577459925786
[Epoch 11, Batch 600] loss: 0.03200590012391331
[Epoch 11, Batch 700] loss: 0.03544896250677994
[Epoch 11, Batch 800] loss: 0.032017236740794035
[Epoch 11, Batch 900] loss: 0.03450147432915401
[Epoch 11, Batch 1000] loss: 0.028245730575872586
[Epoch 11, Batch 1100] loss: 0.03490696365217445
[Epoch 11, Batch 1200] loss: 0.03132953314736369
[Epoch 11, Batch 1300] loss: 0.031489018874417525
[Epoch 11, Batch 1400] loss: 0.03873031712922966
[Epoch 11, Batch 1500] loss: 0.029967842749902048
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9839
Overfitting: 0.0529
Early stopping epoch 11 for trial 12. Moving to next fold.
Fold 5 validation loss: 0.0529
Mean validation loss across all folds for Trial 12 is 0.0522 with trial config:  l1: 256, l2: 64, lr: 0.001, batch_size: 32
[I 2024-12-10 05:47:57,384] Trial 11 finished with value: 0.05219271811079233 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.001, 'batch_size': 32}. Best is trial 8 with value: 0.049267951299149224.

Selected Hyperparameters for Trial 13:
  l1: 256, l2: 128, lr: 0.001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3002538800239565
[Epoch 1, Batch 200] loss: 2.294812858104706
[Epoch 1, Batch 300] loss: 2.277505259513855
[Epoch 1, Batch 400] loss: 2.2395595622062685
[Epoch 1, Batch 500] loss: 2.0384444403648376
[Epoch 1, Batch 600] loss: 1.1058161222934724
[Epoch 1, Batch 700] loss: 0.6518709602952003
[Epoch 1, Batch 800] loss: 0.5208959428966046
[Epoch 1, Batch 900] loss: 0.44700719088315966
[Epoch 1, Batch 1000] loss: 0.42301342010498044
[Epoch 1, Batch 1100] loss: 0.3326740702241659
[Epoch 1, Batch 1200] loss: 0.3330018448084593
[Epoch 1, Batch 1300] loss: 0.299642439186573
[Epoch 1, Batch 1400] loss: 0.27739725112915037
[Epoch 1, Batch 1500] loss: 0.2564887971803546
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2264
Validation Accuracy: 0.9332
Overfitting: 0.2264
[Epoch 2, Batch 100] loss: 0.2470700065791607
[Epoch 2, Batch 200] loss: 0.21491083689033985
[Epoch 2, Batch 300] loss: 0.20063395909965037
[Epoch 2, Batch 400] loss: 0.21897105624899268
[Epoch 2, Batch 500] loss: 0.17357606709003448
[Epoch 2, Batch 600] loss: 0.16127330210059881
[Epoch 2, Batch 700] loss: 0.17760239526629448
[Epoch 2, Batch 800] loss: 0.18066024325788022
[Epoch 2, Batch 900] loss: 0.1287950057722628
[Epoch 2, Batch 1000] loss: 0.1577188233099878
[Epoch 2, Batch 1100] loss: 0.1443129208125174
[Epoch 2, Batch 1200] loss: 0.14685503232292832
[Epoch 2, Batch 1300] loss: 0.12609630927443505
[Epoch 2, Batch 1400] loss: 0.15025335164740683
[Epoch 2, Batch 1500] loss: 0.12288143410347402
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1262
Validation Accuracy: 0.9602
Overfitting: 0.1262
[Epoch 3, Batch 100] loss: 0.12167024545837193
[Epoch 3, Batch 200] loss: 0.11944217137992381
[Epoch 3, Batch 300] loss: 0.11264319543726742
[Epoch 3, Batch 400] loss: 0.10502835645340383
[Epoch 3, Batch 500] loss: 0.10876343145035207
[Epoch 3, Batch 600] loss: 0.12030444119125605
[Epoch 3, Batch 700] loss: 0.1126563466899097
[Epoch 3, Batch 800] loss: 0.11278349289670586
[Epoch 3, Batch 900] loss: 0.11577176383696497
[Epoch 3, Batch 1000] loss: 0.10548164242878556
[Epoch 3, Batch 1100] loss: 0.09946957911364734
[Epoch 3, Batch 1200] loss: 0.10106947167776525
[Epoch 3, Batch 1300] loss: 0.11771517321001738
[Epoch 3, Batch 1400] loss: 0.09005643014563247
[Epoch 3, Batch 1500] loss: 0.08874969074502587
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0882
Validation Accuracy: 0.9722
Overfitting: 0.0882
[Epoch 4, Batch 100] loss: 0.08793418840505182
[Epoch 4, Batch 200] loss: 0.09556148506235332
[Epoch 4, Batch 300] loss: 0.06703815792221576
[Epoch 4, Batch 400] loss: 0.08532758623827248
[Epoch 4, Batch 500] loss: 0.0781974013755098
[Epoch 4, Batch 600] loss: 0.0742654864769429
[Epoch 4, Batch 700] loss: 0.07039450604934246
[Epoch 4, Batch 800] loss: 0.07921046355739236
[Epoch 4, Batch 900] loss: 0.0903070694138296
[Epoch 4, Batch 1000] loss: 0.08158860639669001
[Epoch 4, Batch 1100] loss: 0.0793385237781331
[Epoch 4, Batch 1200] loss: 0.09552460534730926
[Epoch 4, Batch 1300] loss: 0.0772529371920973
[Epoch 4, Batch 1400] loss: 0.07933818730991334
[Epoch 4, Batch 1500] loss: 0.07953875589650124
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0727
Validation Accuracy: 0.9776
Overfitting: 0.0727
[Epoch 5, Batch 100] loss: 0.06466267004609108
[Epoch 5, Batch 200] loss: 0.054647361235693095
[Epoch 5, Batch 300] loss: 0.06673202042584307
[Epoch 5, Batch 400] loss: 0.07033273206325248
[Epoch 5, Batch 500] loss: 0.07920381632167846
[Epoch 5, Batch 600] loss: 0.06472739151446148
[Epoch 5, Batch 700] loss: 0.07490133330225944
[Epoch 5, Batch 800] loss: 0.05987314580823295
[Epoch 5, Batch 900] loss: 0.05805068819085136
[Epoch 5, Batch 1000] loss: 0.07664692817605101
[Epoch 5, Batch 1100] loss: 0.06937729362864048
[Epoch 5, Batch 1200] loss: 0.06331720880465581
[Epoch 5, Batch 1300] loss: 0.056247482632752505
[Epoch 5, Batch 1400] loss: 0.058805896607227626
[Epoch 5, Batch 1500] loss: 0.05266158221755177
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0628
Validation Accuracy: 0.9806
Overfitting: 0.0628
[Epoch 6, Batch 100] loss: 0.049839632329531015
[Epoch 6, Batch 200] loss: 0.05457799813360907
[Epoch 6, Batch 300] loss: 0.05535881487594452
[Epoch 6, Batch 400] loss: 0.05171792499953881
[Epoch 6, Batch 500] loss: 0.05456968195270747
[Epoch 6, Batch 600] loss: 0.05529044097638689
[Epoch 6, Batch 700] loss: 0.05278498836210929
[Epoch 6, Batch 800] loss: 0.06585227583767846
[Epoch 6, Batch 900] loss: 0.05886573284398764
[Epoch 6, Batch 1000] loss: 0.06363998284447007
[Epoch 6, Batch 1100] loss: 0.06533935811021366
[Epoch 6, Batch 1200] loss: 0.06304846920305864
[Epoch 6, Batch 1300] loss: 0.044189613341586664
[Epoch 6, Batch 1400] loss: 0.04801748895086348
[Epoch 6, Batch 1500] loss: 0.05132512751617469
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0586
Validation Accuracy: 0.9820
Overfitting: 0.0586
[Epoch 7, Batch 100] loss: 0.0572749579930678
[Epoch 7, Batch 200] loss: 0.054122666707262394
[Epoch 7, Batch 300] loss: 0.054027595408260826
[Epoch 7, Batch 400] loss: 0.048669224838376976
[Epoch 7, Batch 500] loss: 0.0540963360236492
[Epoch 7, Batch 600] loss: 0.048308274436858485
[Epoch 7, Batch 700] loss: 0.0433990599802928
[Epoch 7, Batch 800] loss: 0.050676242871559224
[Epoch 7, Batch 900] loss: 0.04187117771652993
[Epoch 7, Batch 1000] loss: 0.04526834275340661
[Epoch 7, Batch 1100] loss: 0.05064272400690242
[Epoch 7, Batch 1200] loss: 0.04781867052661255
[Epoch 7, Batch 1300] loss: 0.03762881482485682
[Epoch 7, Batch 1400] loss: 0.03627105821855366
[Epoch 7, Batch 1500] loss: 0.0480754179880023
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0577
Validation Accuracy: 0.9809
Overfitting: 0.0577
[Epoch 8, Batch 100] loss: 0.055278715112362986
[Epoch 8, Batch 200] loss: 0.04161782977695111
[Epoch 8, Batch 300] loss: 0.04437663131917361
[Epoch 8, Batch 400] loss: 0.04198268387001008
[Epoch 8, Batch 500] loss: 0.04103157379664481
[Epoch 8, Batch 600] loss: 0.046926360765937716
[Epoch 8, Batch 700] loss: 0.03903656403126661
[Epoch 8, Batch 800] loss: 0.037259890676359646
[Epoch 8, Batch 900] loss: 0.03493768722226378
[Epoch 8, Batch 1000] loss: 0.04781151391915046
[Epoch 8, Batch 1100] loss: 0.042401796648046004
[Epoch 8, Batch 1200] loss: 0.04613840438891202
[Epoch 8, Batch 1300] loss: 0.038367060922901146
[Epoch 8, Batch 1400] loss: 0.04305125360377133
[Epoch 8, Batch 1500] loss: 0.036654705385444686
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0613
Validation Accuracy: 0.9821
Overfitting: 0.0613
[Epoch 9, Batch 100] loss: 0.025896165246958845
[Epoch 9, Batch 200] loss: 0.036565184966893864
[Epoch 9, Batch 300] loss: 0.04185385441989638
[Epoch 9, Batch 400] loss: 0.036694936395506375
[Epoch 9, Batch 500] loss: 0.03595589353470132
[Epoch 9, Batch 600] loss: 0.030960399395844433
[Epoch 9, Batch 700] loss: 0.040864756230148486
[Epoch 9, Batch 800] loss: 0.04707053775433451
[Epoch 9, Batch 900] loss: 0.03276982990500983
[Epoch 9, Batch 1000] loss: 0.032857384282979185
[Epoch 9, Batch 1100] loss: 0.03884496291866526
[Epoch 9, Batch 1200] loss: 0.0455158833094174
[Epoch 9, Batch 1300] loss: 0.03422781080356799
[Epoch 9, Batch 1400] loss: 0.040283058303175495
[Epoch 9, Batch 1500] loss: 0.04942075234343065
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0508
Validation Accuracy: 0.9850
Overfitting: 0.0508
Best model saved at epoch 9 with validation loss: 0.0508
[Epoch 10, Batch 100] loss: 0.0281460898660589
[Epoch 10, Batch 200] loss: 0.026742252068070228
[Epoch 10, Batch 300] loss: 0.03628305970109068
[Epoch 10, Batch 400] loss: 0.03256346511654556
[Epoch 10, Batch 500] loss: 0.026411907824804074
[Epoch 10, Batch 600] loss: 0.03286551079538185
[Epoch 10, Batch 700] loss: 0.04044622292043641
[Epoch 10, Batch 800] loss: 0.034217861393117346
[Epoch 10, Batch 900] loss: 0.03641860723786522
[Epoch 10, Batch 1000] loss: 0.03023691922542639
[Epoch 10, Batch 1100] loss: 0.03244008721027058
[Epoch 10, Batch 1200] loss: 0.032007865781488364
[Epoch 10, Batch 1300] loss: 0.04194242292433046
[Epoch 10, Batch 1400] loss: 0.04433738997729961
[Epoch 10, Batch 1500] loss: 0.026352950541768224
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9835
Overfitting: 0.0516
[Epoch 11, Batch 100] loss: 0.030450815387303008
[Epoch 11, Batch 200] loss: 0.02691308271489106
[Epoch 11, Batch 300] loss: 0.03690518562536454
[Epoch 11, Batch 400] loss: 0.03174749318684917
[Epoch 11, Batch 500] loss: 0.03582581314258278
[Epoch 11, Batch 600] loss: 0.03299055825351388
[Epoch 11, Batch 700] loss: 0.03414980740984902
[Epoch 11, Batch 800] loss: 0.02219569566543214
[Epoch 11, Batch 900] loss: 0.031984931443003004
[Epoch 11, Batch 1000] loss: 0.02213101514673326
[Epoch 11, Batch 1100] loss: 0.03510742283833679
[Epoch 11, Batch 1200] loss: 0.026302907521021553
[Epoch 11, Batch 1300] loss: 0.0225381132637267
[Epoch 11, Batch 1400] loss: 0.02766086755291326
[Epoch 11, Batch 1500] loss: 0.026081636712769977
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9848
Overfitting: 0.0486
Early stopping epoch 11 for trial 13. Moving to next fold.
Fold 1 validation loss: 0.0486
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.291874496936798
[Epoch 1, Batch 200] loss: 2.2449259877204897
[Epoch 1, Batch 300] loss: 1.999453318119049
[Epoch 1, Batch 400] loss: 1.0870896604657174
[Epoch 1, Batch 500] loss: 0.6242163917422294
[Epoch 1, Batch 600] loss: 0.496089936196804
[Epoch 1, Batch 700] loss: 0.4051248802244663
[Epoch 1, Batch 800] loss: 0.37719457656145094
[Epoch 1, Batch 900] loss: 0.3501582257449627
[Epoch 1, Batch 1000] loss: 0.3151565711200237
[Epoch 1, Batch 1100] loss: 0.3025836181268096
[Epoch 1, Batch 1200] loss: 0.25989853773266075
[Epoch 1, Batch 1300] loss: 0.25031124040484426
[Epoch 1, Batch 1400] loss: 0.22357511635869742
[Epoch 1, Batch 1500] loss: 0.22396420840173958
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2300
Validation Accuracy: 0.9303
Overfitting: 0.2300
[Epoch 2, Batch 100] loss: 0.20914620339870452
[Epoch 2, Batch 200] loss: 0.18618222407996654
[Epoch 2, Batch 300] loss: 0.19308277767151594
[Epoch 2, Batch 400] loss: 0.18094770312309266
[Epoch 2, Batch 500] loss: 0.1711343653127551
[Epoch 2, Batch 600] loss: 0.1491555783338845
[Epoch 2, Batch 700] loss: 0.1451640223711729
[Epoch 2, Batch 800] loss: 0.14714947913773357
[Epoch 2, Batch 900] loss: 0.14329027943778783
[Epoch 2, Batch 1000] loss: 0.13214157580398023
[Epoch 2, Batch 1100] loss: 0.12491252314299345
[Epoch 2, Batch 1200] loss: 0.14258265279233456
[Epoch 2, Batch 1300] loss: 0.13411835520528256
[Epoch 2, Batch 1400] loss: 0.11875056389719248
[Epoch 2, Batch 1500] loss: 0.128840979677625
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1465
Validation Accuracy: 0.9558
Overfitting: 0.1465
[Epoch 3, Batch 100] loss: 0.1152053086925298
[Epoch 3, Batch 200] loss: 0.10847878867760301
[Epoch 3, Batch 300] loss: 0.10329120893031359
[Epoch 3, Batch 400] loss: 0.11240268802270294
[Epoch 3, Batch 500] loss: 0.10598853033967316
[Epoch 3, Batch 600] loss: 0.09646874725818634
[Epoch 3, Batch 700] loss: 0.09264584504533559
[Epoch 3, Batch 800] loss: 0.0958250146266073
[Epoch 3, Batch 900] loss: 0.11600714790634811
[Epoch 3, Batch 1000] loss: 0.09366729041095823
[Epoch 3, Batch 1100] loss: 0.091111496752128
[Epoch 3, Batch 1200] loss: 0.0882054332876578
[Epoch 3, Batch 1300] loss: 0.10176427833270281
[Epoch 3, Batch 1400] loss: 0.09923360916320234
[Epoch 3, Batch 1500] loss: 0.08836252955719828
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1165
Validation Accuracy: 0.9648
Overfitting: 0.1165
[Epoch 4, Batch 100] loss: 0.09172766654752194
[Epoch 4, Batch 200] loss: 0.07640492264181376
[Epoch 4, Batch 300] loss: 0.07286932340823114
[Epoch 4, Batch 400] loss: 0.0825475981249474
[Epoch 4, Batch 500] loss: 0.07369775060098618
[Epoch 4, Batch 600] loss: 0.07376569957239554
[Epoch 4, Batch 700] loss: 0.07540782213676721
[Epoch 4, Batch 800] loss: 0.07839261231478303
[Epoch 4, Batch 900] loss: 0.0811719115683809
[Epoch 4, Batch 1000] loss: 0.07864530047401785
[Epoch 4, Batch 1100] loss: 0.08810623318888247
[Epoch 4, Batch 1200] loss: 0.0675574991828762
[Epoch 4, Batch 1300] loss: 0.08277038864791393
[Epoch 4, Batch 1400] loss: 0.07478839365532622
[Epoch 4, Batch 1500] loss: 0.08225934602087363
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0871
Validation Accuracy: 0.9748
Overfitting: 0.0871
[Epoch 5, Batch 100] loss: 0.06568710283609107
[Epoch 5, Batch 200] loss: 0.06193071122746915
[Epoch 5, Batch 300] loss: 0.07971517893485724
[Epoch 5, Batch 400] loss: 0.06548260992392897
[Epoch 5, Batch 500] loss: 0.07666118049994111
[Epoch 5, Batch 600] loss: 0.07043108665151522
[Epoch 5, Batch 700] loss: 0.062177537488751114
[Epoch 5, Batch 800] loss: 0.07682836140273139
[Epoch 5, Batch 900] loss: 0.06011515053105541
[Epoch 5, Batch 1000] loss: 0.07236083878902719
[Epoch 5, Batch 1100] loss: 0.057102082944475115
[Epoch 5, Batch 1200] loss: 0.061660792375332674
[Epoch 5, Batch 1300] loss: 0.049108246536925436
[Epoch 5, Batch 1400] loss: 0.06868136531789787
[Epoch 5, Batch 1500] loss: 0.05971843332750723
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0823
Validation Accuracy: 0.9755
Overfitting: 0.0823
[Epoch 6, Batch 100] loss: 0.05178452557534911
[Epoch 6, Batch 200] loss: 0.062487029782496394
[Epoch 6, Batch 300] loss: 0.05995285581564531
[Epoch 6, Batch 400] loss: 0.05886060163844377
[Epoch 6, Batch 500] loss: 0.06028079415264074
[Epoch 6, Batch 600] loss: 0.06250109725864604
[Epoch 6, Batch 700] loss: 0.04507460234221071
[Epoch 6, Batch 800] loss: 0.051550548897357655
[Epoch 6, Batch 900] loss: 0.05191289653885178
[Epoch 6, Batch 1000] loss: 0.05704364276141859
[Epoch 6, Batch 1100] loss: 0.0650416069990024
[Epoch 6, Batch 1200] loss: 0.05040766374964733
[Epoch 6, Batch 1300] loss: 0.06325368069810793
[Epoch 6, Batch 1400] loss: 0.06302175977150909
[Epoch 6, Batch 1500] loss: 0.05791691170888953
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0688
Validation Accuracy: 0.9783
Overfitting: 0.0688
[Epoch 7, Batch 100] loss: 0.045062882562633605
[Epoch 7, Batch 200] loss: 0.04430260896333493
[Epoch 7, Batch 300] loss: 0.05601149032008834
[Epoch 7, Batch 400] loss: 0.06345805415417999
[Epoch 7, Batch 500] loss: 0.04486850399640389
[Epoch 7, Batch 600] loss: 0.05093926016706973
[Epoch 7, Batch 700] loss: 0.05382061495562084
[Epoch 7, Batch 800] loss: 0.05195030585222412
[Epoch 7, Batch 900] loss: 0.04968335356330499
[Epoch 7, Batch 1000] loss: 0.05501723250490613
[Epoch 7, Batch 1100] loss: 0.03592308290360961
[Epoch 7, Batch 1200] loss: 0.049006232784595344
[Epoch 7, Batch 1300] loss: 0.048443640564801174
[Epoch 7, Batch 1400] loss: 0.04646520151523873
[Epoch 7, Batch 1500] loss: 0.04472035152546596
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0735
Validation Accuracy: 0.9785
Overfitting: 0.0735
[Epoch 8, Batch 100] loss: 0.04882942182128318
[Epoch 8, Batch 200] loss: 0.05035904101794585
[Epoch 8, Batch 300] loss: 0.05379177919588983
[Epoch 8, Batch 400] loss: 0.030508982170722447
[Epoch 8, Batch 500] loss: 0.04166747252224013
[Epoch 8, Batch 600] loss: 0.05264328693738207
[Epoch 8, Batch 700] loss: 0.04143765946384519
[Epoch 8, Batch 800] loss: 0.047013210052391514
[Epoch 8, Batch 900] loss: 0.03284687823150307
[Epoch 8, Batch 1000] loss: 0.036247801777208224
[Epoch 8, Batch 1100] loss: 0.04950771261937916
[Epoch 8, Batch 1200] loss: 0.04942888314370066
[Epoch 8, Batch 1300] loss: 0.053343102831277064
[Epoch 8, Batch 1400] loss: 0.04101258440525271
[Epoch 8, Batch 1500] loss: 0.033057793006883
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0680
Validation Accuracy: 0.9798
Overfitting: 0.0680
[Epoch 9, Batch 100] loss: 0.03840193438198185
[Epoch 9, Batch 200] loss: 0.035051364228129385
[Epoch 9, Batch 300] loss: 0.038997941369307225
[Epoch 9, Batch 400] loss: 0.029700988612603396
[Epoch 9, Batch 500] loss: 0.03369282182800817
[Epoch 9, Batch 600] loss: 0.05311097842350136
[Epoch 9, Batch 700] loss: 0.03207503742480185
[Epoch 9, Batch 800] loss: 0.03561510920291767
[Epoch 9, Batch 900] loss: 0.04383407504239585
[Epoch 9, Batch 1000] loss: 0.03979937923199031
[Epoch 9, Batch 1100] loss: 0.03552173434058204
[Epoch 9, Batch 1200] loss: 0.041439119777060114
[Epoch 9, Batch 1300] loss: 0.04516384550719522
[Epoch 9, Batch 1400] loss: 0.041428902698680756
[Epoch 9, Batch 1500] loss: 0.04405601711478084
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0637
Validation Accuracy: 0.9808
Overfitting: 0.0637
Best model saved at epoch 9 with validation loss: 0.0637
[Epoch 10, Batch 100] loss: 0.042663705886225214
[Epoch 10, Batch 200] loss: 0.04010609144635964
[Epoch 10, Batch 300] loss: 0.028677061006892473
[Epoch 10, Batch 400] loss: 0.029851151769980787
[Epoch 10, Batch 500] loss: 0.033427695003629194
[Epoch 10, Batch 600] loss: 0.033818678804673256
[Epoch 10, Batch 700] loss: 0.031638622956816104
[Epoch 10, Batch 800] loss: 0.028312195817416067
[Epoch 10, Batch 900] loss: 0.038741740322439
[Epoch 10, Batch 1000] loss: 0.030919075863203034
[Epoch 10, Batch 1100] loss: 0.04280223375884816
[Epoch 10, Batch 1200] loss: 0.033845751539920456
[Epoch 10, Batch 1300] loss: 0.04419357817503624
[Epoch 10, Batch 1400] loss: 0.0426529708088492
[Epoch 10, Batch 1500] loss: 0.031710883907508106
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0588
Validation Accuracy: 0.9835
Overfitting: 0.0588
[Epoch 11, Batch 100] loss: 0.026990323571371846
[Epoch 11, Batch 200] loss: 0.03232106372801354
[Epoch 11, Batch 300] loss: 0.02313213821966201
[Epoch 11, Batch 400] loss: 0.03598668085236568
[Epoch 11, Batch 500] loss: 0.02589670901070349
[Epoch 11, Batch 600] loss: 0.03940621090237983
[Epoch 11, Batch 700] loss: 0.042421679487015355
[Epoch 11, Batch 800] loss: 0.03256583035195945
[Epoch 11, Batch 900] loss: 0.03553171253064647
[Epoch 11, Batch 1000] loss: 0.031445234522107054
[Epoch 11, Batch 1100] loss: 0.03711280381132383
[Epoch 11, Batch 1200] loss: 0.031197627400106284
[Epoch 11, Batch 1300] loss: 0.03969950223865453
[Epoch 11, Batch 1400] loss: 0.03602876550692599
[Epoch 11, Batch 1500] loss: 0.023881406715954654
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9828
Overfitting: 0.0549
Early stopping epoch 11 for trial 13. Moving to next fold.
Fold 2 validation loss: 0.0549
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2980500078201294
[Epoch 1, Batch 200] loss: 2.2605701518058776
[Epoch 1, Batch 300] loss: 2.099457156658173
[Epoch 1, Batch 400] loss: 1.1726595270633697
[Epoch 1, Batch 500] loss: 0.5816436488926411
[Epoch 1, Batch 600] loss: 0.48890662714838984
[Epoch 1, Batch 700] loss: 0.3987755663692951
[Epoch 1, Batch 800] loss: 0.3409155589342117
[Epoch 1, Batch 900] loss: 0.285386087782681
[Epoch 1, Batch 1000] loss: 0.26997787941247225
[Epoch 1, Batch 1100] loss: 0.23942361500114204
[Epoch 1, Batch 1200] loss: 0.24693479783833028
[Epoch 1, Batch 1300] loss: 0.23700370833277704
[Epoch 1, Batch 1400] loss: 0.19327383188530803
[Epoch 1, Batch 1500] loss: 0.1872372068092227
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1954
Validation Accuracy: 0.9416
Overfitting: 0.1954
[Epoch 2, Batch 100] loss: 0.16743234196677803
[Epoch 2, Batch 200] loss: 0.16051452029496432
[Epoch 2, Batch 300] loss: 0.18294420896098018
[Epoch 2, Batch 400] loss: 0.17917843172326683
[Epoch 2, Batch 500] loss: 0.13320296462625264
[Epoch 2, Batch 600] loss: 0.1380219492316246
[Epoch 2, Batch 700] loss: 0.15999371651560068
[Epoch 2, Batch 800] loss: 0.15357000105082988
[Epoch 2, Batch 900] loss: 0.12735986366169527
[Epoch 2, Batch 1000] loss: 0.12915242387913167
[Epoch 2, Batch 1100] loss: 0.11890594355762005
[Epoch 2, Batch 1200] loss: 0.11807576050749048
[Epoch 2, Batch 1300] loss: 0.10965855936519801
[Epoch 2, Batch 1400] loss: 0.13482765776105224
[Epoch 2, Batch 1500] loss: 0.11164652174338699
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1250
Validation Accuracy: 0.9620
Overfitting: 0.1250
[Epoch 3, Batch 100] loss: 0.09231033784803003
[Epoch 3, Batch 200] loss: 0.11179714238271117
[Epoch 3, Batch 300] loss: 0.09888184763025493
[Epoch 3, Batch 400] loss: 0.1004167551221326
[Epoch 3, Batch 500] loss: 0.10455865270458162
[Epoch 3, Batch 600] loss: 0.0956496995082125
[Epoch 3, Batch 700] loss: 0.10480484307277947
[Epoch 3, Batch 800] loss: 0.09135047615040094
[Epoch 3, Batch 900] loss: 0.08203899312764407
[Epoch 3, Batch 1000] loss: 0.09962875032098964
[Epoch 3, Batch 1100] loss: 0.0876101491227746
[Epoch 3, Batch 1200] loss: 0.09152556287590415
[Epoch 3, Batch 1300] loss: 0.10393776225857437
[Epoch 3, Batch 1400] loss: 0.08984080030350014
[Epoch 3, Batch 1500] loss: 0.09853469111025333
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0950
Validation Accuracy: 0.9714
Overfitting: 0.0950
[Epoch 4, Batch 100] loss: 0.0764430170354899
[Epoch 4, Batch 200] loss: 0.08447748143458739
[Epoch 4, Batch 300] loss: 0.07792861774098128
[Epoch 4, Batch 400] loss: 0.07419373624259606
[Epoch 4, Batch 500] loss: 0.0821607956639491
[Epoch 4, Batch 600] loss: 0.07252477032365277
[Epoch 4, Batch 700] loss: 0.08539706618059427
[Epoch 4, Batch 800] loss: 0.07478499429766089
[Epoch 4, Batch 900] loss: 0.0774364606407471
[Epoch 4, Batch 1000] loss: 0.05976325357798487
[Epoch 4, Batch 1100] loss: 0.08053976571653038
[Epoch 4, Batch 1200] loss: 0.061814132060389965
[Epoch 4, Batch 1300] loss: 0.0738052424392663
[Epoch 4, Batch 1400] loss: 0.0811593311256729
[Epoch 4, Batch 1500] loss: 0.07805670991772785
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0764
Validation Accuracy: 0.9764
Overfitting: 0.0764
[Epoch 5, Batch 100] loss: 0.061652834545820955
[Epoch 5, Batch 200] loss: 0.059328947202302515
[Epoch 5, Batch 300] loss: 0.06289945705793798
[Epoch 5, Batch 400] loss: 0.06151826248504221
[Epoch 5, Batch 500] loss: 0.06853760437807069
[Epoch 5, Batch 600] loss: 0.07304992785211653
[Epoch 5, Batch 700] loss: 0.06846143542788923
[Epoch 5, Batch 800] loss: 0.057678849364165216
[Epoch 5, Batch 900] loss: 0.06511911928653717
[Epoch 5, Batch 1000] loss: 0.06270585917169229
[Epoch 5, Batch 1100] loss: 0.05835244779475033
[Epoch 5, Batch 1200] loss: 0.06097482313867658
[Epoch 5, Batch 1300] loss: 0.06097969083348289
[Epoch 5, Batch 1400] loss: 0.061144165106816216
[Epoch 5, Batch 1500] loss: 0.06614355825120583
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0670
Validation Accuracy: 0.9788
Overfitting: 0.0670
[Epoch 6, Batch 100] loss: 0.044324416724266485
[Epoch 6, Batch 200] loss: 0.063478831613902
[Epoch 6, Batch 300] loss: 0.05875478119123727
[Epoch 6, Batch 400] loss: 0.05131729710148648
[Epoch 6, Batch 500] loss: 0.051030764273600655
[Epoch 6, Batch 600] loss: 0.053735583201050756
[Epoch 6, Batch 700] loss: 0.05829153461847454
[Epoch 6, Batch 800] loss: 0.052611478846520184
[Epoch 6, Batch 900] loss: 0.05628161025233567
[Epoch 6, Batch 1000] loss: 0.046426128348102794
[Epoch 6, Batch 1100] loss: 0.0587338674813509
[Epoch 6, Batch 1200] loss: 0.04987523244228214
[Epoch 6, Batch 1300] loss: 0.054923604966024865
[Epoch 6, Batch 1400] loss: 0.04929760146420449
[Epoch 6, Batch 1500] loss: 0.050878972702194006
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0622
Validation Accuracy: 0.9812
Overfitting: 0.0622
[Epoch 7, Batch 100] loss: 0.04854597340687178
[Epoch 7, Batch 200] loss: 0.052794747229199857
[Epoch 7, Batch 300] loss: 0.040794425674248486
[Epoch 7, Batch 400] loss: 0.05335810086457059
[Epoch 7, Batch 500] loss: 0.05965292449458502
[Epoch 7, Batch 600] loss: 0.048070339364930985
[Epoch 7, Batch 700] loss: 0.0457581072091125
[Epoch 7, Batch 800] loss: 0.03460425381199457
[Epoch 7, Batch 900] loss: 0.04267838225117884
[Epoch 7, Batch 1000] loss: 0.05427999013103545
[Epoch 7, Batch 1100] loss: 0.04276114338892512
[Epoch 7, Batch 1200] loss: 0.033463556008355225
[Epoch 7, Batch 1300] loss: 0.048361496884026564
[Epoch 7, Batch 1400] loss: 0.05261879665020388
[Epoch 7, Batch 1500] loss: 0.04086575787514448
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0576
Validation Accuracy: 0.9822
Overfitting: 0.0576
[Epoch 8, Batch 100] loss: 0.03912821290141437
[Epoch 8, Batch 200] loss: 0.04425274070410524
[Epoch 8, Batch 300] loss: 0.03257867969223298
[Epoch 8, Batch 400] loss: 0.04591687783482484
[Epoch 8, Batch 500] loss: 0.039067606472526675
[Epoch 8, Batch 600] loss: 0.03741038060048595
[Epoch 8, Batch 700] loss: 0.043512642032583246
[Epoch 8, Batch 800] loss: 0.037100504559930414
[Epoch 8, Batch 900] loss: 0.03688159049546812
[Epoch 8, Batch 1000] loss: 0.041612372254021465
[Epoch 8, Batch 1100] loss: 0.03973812223761342
[Epoch 8, Batch 1200] loss: 0.04863137455482502
[Epoch 8, Batch 1300] loss: 0.0475143861270044
[Epoch 8, Batch 1400] loss: 0.02640567757363897
[Epoch 8, Batch 1500] loss: 0.05825543644081335
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9835
Overfitting: 0.0550
[Epoch 9, Batch 100] loss: 0.03381286818301305
[Epoch 9, Batch 200] loss: 0.039734312990913165
[Epoch 9, Batch 300] loss: 0.04047881735838019
[Epoch 9, Batch 400] loss: 0.0339055095121148
[Epoch 9, Batch 500] loss: 0.04182999623008073
[Epoch 9, Batch 600] loss: 0.031061353323748334
[Epoch 9, Batch 700] loss: 0.03643115123035386
[Epoch 9, Batch 800] loss: 0.03286873096425552
[Epoch 9, Batch 900] loss: 0.04638841109815985
[Epoch 9, Batch 1000] loss: 0.039927196655189616
[Epoch 9, Batch 1100] loss: 0.03554759697697591
[Epoch 9, Batch 1200] loss: 0.029852286251843906
[Epoch 9, Batch 1300] loss: 0.036940183047554455
[Epoch 9, Batch 1400] loss: 0.042328938194550574
[Epoch 9, Batch 1500] loss: 0.03334829012164846
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9834
Overfitting: 0.0552
Best model saved at epoch 9 with validation loss: 0.0552
[Epoch 10, Batch 100] loss: 0.02490421782626072
[Epoch 10, Batch 200] loss: 0.03623302289401181
[Epoch 10, Batch 300] loss: 0.03213289302017074
[Epoch 10, Batch 400] loss: 0.032329620748059826
[Epoch 10, Batch 500] loss: 0.03012527090788353
[Epoch 10, Batch 600] loss: 0.02533800721692387
[Epoch 10, Batch 700] loss: 0.03684430232038721
[Epoch 10, Batch 800] loss: 0.036680168679158666
[Epoch 10, Batch 900] loss: 0.03518720307503827
[Epoch 10, Batch 1000] loss: 0.03516794204711914
[Epoch 10, Batch 1100] loss: 0.0326799464278156
[Epoch 10, Batch 1200] loss: 0.03355952434387291
[Epoch 10, Batch 1300] loss: 0.03544001600530464
[Epoch 10, Batch 1400] loss: 0.030689427208853884
[Epoch 10, Batch 1500] loss: 0.0376530979690142
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0494
Validation Accuracy: 0.9866
Overfitting: 0.0494
[Epoch 11, Batch 100] loss: 0.0307793422753457
[Epoch 11, Batch 200] loss: 0.026991543819312937
[Epoch 11, Batch 300] loss: 0.018942795280308927
[Epoch 11, Batch 400] loss: 0.024256563608651048
[Epoch 11, Batch 500] loss: 0.026032994455235894
[Epoch 11, Batch 600] loss: 0.0356804162854678
[Epoch 11, Batch 700] loss: 0.036535601766372564
[Epoch 11, Batch 800] loss: 0.03271976841468131
[Epoch 11, Batch 900] loss: 0.04062568259134423
[Epoch 11, Batch 1000] loss: 0.02320020821876824
[Epoch 11, Batch 1100] loss: 0.028751455475576223
[Epoch 11, Batch 1200] loss: 0.022644837385741995
[Epoch 11, Batch 1300] loss: 0.030718989759043323
[Epoch 11, Batch 1400] loss: 0.035901801722357046
[Epoch 11, Batch 1500] loss: 0.02722572516897344
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9858
Overfitting: 0.0483
Early stopping epoch 11 for trial 13. Moving to next fold.
Fold 3 validation loss: 0.0483
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2809989833831787
[Epoch 1, Batch 200] loss: 2.118704767227173
[Epoch 1, Batch 300] loss: 1.2434368652105332
[Epoch 1, Batch 400] loss: 0.6097415345907211
[Epoch 1, Batch 500] loss: 0.47012085139751436
[Epoch 1, Batch 600] loss: 0.4335191690176725
[Epoch 1, Batch 700] loss: 0.4040525223314762
[Epoch 1, Batch 800] loss: 0.3464979711174965
[Epoch 1, Batch 900] loss: 0.32462829783558844
[Epoch 1, Batch 1000] loss: 0.3098560868576169
[Epoch 1, Batch 1100] loss: 0.25490147538483143
[Epoch 1, Batch 1200] loss: 0.24248112089931964
[Epoch 1, Batch 1300] loss: 0.273896007463336
[Epoch 1, Batch 1400] loss: 0.2268505317904055
[Epoch 1, Batch 1500] loss: 0.20715972736477853
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2216
Validation Accuracy: 0.9290
Overfitting: 0.2216
[Epoch 2, Batch 100] loss: 0.18894216805696487
[Epoch 2, Batch 200] loss: 0.2014332909695804
[Epoch 2, Batch 300] loss: 0.1739879285171628
[Epoch 2, Batch 400] loss: 0.16857678063213824
[Epoch 2, Batch 500] loss: 0.15029675463214517
[Epoch 2, Batch 600] loss: 0.16209807579405605
[Epoch 2, Batch 700] loss: 0.14347789337858557
[Epoch 2, Batch 800] loss: 0.13426619524136185
[Epoch 2, Batch 900] loss: 0.15240372823551296
[Epoch 2, Batch 1000] loss: 0.14300295621156692
[Epoch 2, Batch 1100] loss: 0.12909062289632856
[Epoch 2, Batch 1200] loss: 0.12965970660559833
[Epoch 2, Batch 1300] loss: 0.11335398800671101
[Epoch 2, Batch 1400] loss: 0.13253875996917486
[Epoch 2, Batch 1500] loss: 0.11796450013294817
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1203
Validation Accuracy: 0.9625
Overfitting: 0.1203
[Epoch 3, Batch 100] loss: 0.09712329557165504
[Epoch 3, Batch 200] loss: 0.11965235591866076
[Epoch 3, Batch 300] loss: 0.10855714581906796
[Epoch 3, Batch 400] loss: 0.09568028760142624
[Epoch 3, Batch 500] loss: 0.09923041167668999
[Epoch 3, Batch 600] loss: 0.09393840093165635
[Epoch 3, Batch 700] loss: 0.11465351052582264
[Epoch 3, Batch 800] loss: 0.10640136735513807
[Epoch 3, Batch 900] loss: 0.08086140347179026
[Epoch 3, Batch 1000] loss: 0.0824754826258868
[Epoch 3, Batch 1100] loss: 0.0978414341295138
[Epoch 3, Batch 1200] loss: 0.09857081491500139
[Epoch 3, Batch 1300] loss: 0.09014455855358391
[Epoch 3, Batch 1400] loss: 0.09161256701219828
[Epoch 3, Batch 1500] loss: 0.09264473950024694
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0877
Validation Accuracy: 0.9719
Overfitting: 0.0877
[Epoch 4, Batch 100] loss: 0.06954583169892431
[Epoch 4, Batch 200] loss: 0.08885054778773338
[Epoch 4, Batch 300] loss: 0.08390424211509526
[Epoch 4, Batch 400] loss: 0.08306197941303253
[Epoch 4, Batch 500] loss: 0.0931242671655491
[Epoch 4, Batch 600] loss: 0.06637137736659497
[Epoch 4, Batch 700] loss: 0.0742365310434252
[Epoch 4, Batch 800] loss: 0.07691499652341008
[Epoch 4, Batch 900] loss: 0.07791518218815327
[Epoch 4, Batch 1000] loss: 0.07625597695354372
[Epoch 4, Batch 1100] loss: 0.07039145235437899
[Epoch 4, Batch 1200] loss: 0.09621416731737555
[Epoch 4, Batch 1300] loss: 0.07344001847784966
[Epoch 4, Batch 1400] loss: 0.05919634810183197
[Epoch 4, Batch 1500] loss: 0.06293107326608151
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0712
Validation Accuracy: 0.9779
Overfitting: 0.0712
[Epoch 5, Batch 100] loss: 0.056475175590021534
[Epoch 5, Batch 200] loss: 0.07035911770304665
[Epoch 5, Batch 300] loss: 0.07368393574724905
[Epoch 5, Batch 400] loss: 0.06341882240725681
[Epoch 5, Batch 500] loss: 0.06664339803624898
[Epoch 5, Batch 600] loss: 0.07002297040540725
[Epoch 5, Batch 700] loss: 0.052831112551502885
[Epoch 5, Batch 800] loss: 0.053568447579164055
[Epoch 5, Batch 900] loss: 0.07534773616935127
[Epoch 5, Batch 1000] loss: 0.052103391122072934
[Epoch 5, Batch 1100] loss: 0.05349350987235084
[Epoch 5, Batch 1200] loss: 0.05879763716598973
[Epoch 5, Batch 1300] loss: 0.0584282240178436
[Epoch 5, Batch 1400] loss: 0.07703738345997407
[Epoch 5, Batch 1500] loss: 0.05746833486482501
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0662
Validation Accuracy: 0.9800
Overfitting: 0.0662
[Epoch 6, Batch 100] loss: 0.04096527610439807
[Epoch 6, Batch 200] loss: 0.03807191645959392
[Epoch 6, Batch 300] loss: 0.0649727849313058
[Epoch 6, Batch 400] loss: 0.06541929453611374
[Epoch 6, Batch 500] loss: 0.06380376133602113
[Epoch 6, Batch 600] loss: 0.052434709173394364
[Epoch 6, Batch 700] loss: 0.04932306761736981
[Epoch 6, Batch 800] loss: 0.05924439946422353
[Epoch 6, Batch 900] loss: 0.050972408086527136
[Epoch 6, Batch 1000] loss: 0.05217644706834108
[Epoch 6, Batch 1100] loss: 0.05705837742658332
[Epoch 6, Batch 1200] loss: 0.04320039716665633
[Epoch 6, Batch 1300] loss: 0.053304867283441124
[Epoch 6, Batch 1400] loss: 0.055552088841795924
[Epoch 6, Batch 1500] loss: 0.05982482115505263
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0596
Validation Accuracy: 0.9802
Overfitting: 0.0596
[Epoch 7, Batch 100] loss: 0.04045541831292212
[Epoch 7, Batch 200] loss: 0.05297681353869848
[Epoch 7, Batch 300] loss: 0.049365988976787775
[Epoch 7, Batch 400] loss: 0.05946373532060534
[Epoch 7, Batch 500] loss: 0.03632082122145221
[Epoch 7, Batch 600] loss: 0.05689044123049825
[Epoch 7, Batch 700] loss: 0.045829561849823224
[Epoch 7, Batch 800] loss: 0.03749710945121478
[Epoch 7, Batch 900] loss: 0.05052624538599048
[Epoch 7, Batch 1000] loss: 0.04318453904998023
[Epoch 7, Batch 1100] loss: 0.0408156017283909
[Epoch 7, Batch 1200] loss: 0.05333406717516482
[Epoch 7, Batch 1300] loss: 0.042557275532744826
[Epoch 7, Batch 1400] loss: 0.04639589969068766
[Epoch 7, Batch 1500] loss: 0.03850341791054234
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0593
Validation Accuracy: 0.9807
Overfitting: 0.0593
[Epoch 8, Batch 100] loss: 0.03947247808217071
[Epoch 8, Batch 200] loss: 0.043896396150812506
[Epoch 8, Batch 300] loss: 0.03813243042677641
[Epoch 8, Batch 400] loss: 0.03888299725484103
[Epoch 8, Batch 500] loss: 0.04245429655537009
[Epoch 8, Batch 600] loss: 0.044358119890093806
[Epoch 8, Batch 700] loss: 0.042899601808167064
[Epoch 8, Batch 800] loss: 0.03791468458599411
[Epoch 8, Batch 900] loss: 0.051409969350788745
[Epoch 8, Batch 1000] loss: 0.042509013142553155
[Epoch 8, Batch 1100] loss: 0.030993078383617104
[Epoch 8, Batch 1200] loss: 0.04033655937178992
[Epoch 8, Batch 1300] loss: 0.042867035047383976
[Epoch 8, Batch 1400] loss: 0.05002183056611102
[Epoch 8, Batch 1500] loss: 0.03278883857710753
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0577
Validation Accuracy: 0.9817
Overfitting: 0.0577
[Epoch 9, Batch 100] loss: 0.03995217236748431
[Epoch 9, Batch 200] loss: 0.04433178284205496
[Epoch 9, Batch 300] loss: 0.03032948778825812
[Epoch 9, Batch 400] loss: 0.0479467389016645
[Epoch 9, Batch 500] loss: 0.03420865303603932
[Epoch 9, Batch 600] loss: 0.03677748838555999
[Epoch 9, Batch 700] loss: 0.030940001491690055
[Epoch 9, Batch 800] loss: 0.026583203899208457
[Epoch 9, Batch 900] loss: 0.027830181324097793
[Epoch 9, Batch 1000] loss: 0.0369509317833581
[Epoch 9, Batch 1100] loss: 0.03576126749656396
[Epoch 9, Batch 1200] loss: 0.03762853959400672
[Epoch 9, Batch 1300] loss: 0.032492602040292695
[Epoch 9, Batch 1400] loss: 0.04306302230455913
[Epoch 9, Batch 1500] loss: 0.04066928324638866
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0530
Validation Accuracy: 0.9832
Overfitting: 0.0530
Best model saved at epoch 9 with validation loss: 0.0530
[Epoch 10, Batch 100] loss: 0.02067870598810259
[Epoch 10, Batch 200] loss: 0.029504258784872946
[Epoch 10, Batch 300] loss: 0.033425166202650874
[Epoch 10, Batch 400] loss: 0.030832298051100226
[Epoch 10, Batch 500] loss: 0.025974630515556783
[Epoch 10, Batch 600] loss: 0.029549843101995064
[Epoch 10, Batch 700] loss: 0.036442407512804496
[Epoch 10, Batch 800] loss: 0.034895165617053865
[Epoch 10, Batch 900] loss: 0.026251075190957637
[Epoch 10, Batch 1000] loss: 0.03147659609734546
[Epoch 10, Batch 1100] loss: 0.03552773383358726
[Epoch 10, Batch 1200] loss: 0.0434291372273583
[Epoch 10, Batch 1300] loss: 0.03642703881545458
[Epoch 10, Batch 1400] loss: 0.03376671503734542
[Epoch 10, Batch 1500] loss: 0.038759554377757015
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9834
Overfitting: 0.0510
[Epoch 11, Batch 100] loss: 0.02641714208846679
[Epoch 11, Batch 200] loss: 0.02956077415467007
[Epoch 11, Batch 300] loss: 0.025805257825413718
[Epoch 11, Batch 400] loss: 0.028855513567104935
[Epoch 11, Batch 500] loss: 0.03174275765486527
[Epoch 11, Batch 600] loss: 0.027072677407995797
[Epoch 11, Batch 700] loss: 0.02947622624167707
[Epoch 11, Batch 800] loss: 0.028627411444322206
[Epoch 11, Batch 900] loss: 0.021226988564594648
[Epoch 11, Batch 1000] loss: 0.037962591759278436
[Epoch 11, Batch 1100] loss: 0.030515169088321272
[Epoch 11, Batch 1200] loss: 0.031009746737545356
[Epoch 11, Batch 1300] loss: 0.025395203753723762
[Epoch 11, Batch 1400] loss: 0.028835800497909077
[Epoch 11, Batch 1500] loss: 0.025125395407376346
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9854
Overfitting: 0.0445
Early stopping epoch 11 for trial 13. Moving to next fold.
Fold 4 validation loss: 0.0445
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.294774968624115
[Epoch 1, Batch 200] loss: 2.2653174710273745
[Epoch 1, Batch 300] loss: 2.1669901609420776
[Epoch 1, Batch 400] loss: 1.4995845079421997
[Epoch 1, Batch 500] loss: 0.578923852443695
[Epoch 1, Batch 600] loss: 0.44952134624123574
[Epoch 1, Batch 700] loss: 0.3911690831929445
[Epoch 1, Batch 800] loss: 0.3172766347229481
[Epoch 1, Batch 900] loss: 0.3049370551109314
[Epoch 1, Batch 1000] loss: 0.28159168887883423
[Epoch 1, Batch 1100] loss: 0.24574656009674073
[Epoch 1, Batch 1200] loss: 0.21203831121325492
[Epoch 1, Batch 1300] loss: 0.20215852785855531
[Epoch 1, Batch 1400] loss: 0.18975959315896035
[Epoch 1, Batch 1500] loss: 0.1855230549816042
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1657
Validation Accuracy: 0.9488
Overfitting: 0.1657
[Epoch 2, Batch 100] loss: 0.17308811377733946
[Epoch 2, Batch 200] loss: 0.16102933367714287
[Epoch 2, Batch 300] loss: 0.13877432160079478
[Epoch 2, Batch 400] loss: 0.15451161049306392
[Epoch 2, Batch 500] loss: 0.16736918607726692
[Epoch 2, Batch 600] loss: 0.14268161136656998
[Epoch 2, Batch 700] loss: 0.13863004643470048
[Epoch 2, Batch 800] loss: 0.12582806922495365
[Epoch 2, Batch 900] loss: 0.1290120635740459
[Epoch 2, Batch 1000] loss: 0.12300464176572859
[Epoch 2, Batch 1100] loss: 0.103092818595469
[Epoch 2, Batch 1200] loss: 0.12998514075763523
[Epoch 2, Batch 1300] loss: 0.11579173875041306
[Epoch 2, Batch 1400] loss: 0.12194389300886542
[Epoch 2, Batch 1500] loss: 0.12128019046969712
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1058
Validation Accuracy: 0.9672
Overfitting: 0.1058
[Epoch 3, Batch 100] loss: 0.08896014839410782
[Epoch 3, Batch 200] loss: 0.08994609573855997
[Epoch 3, Batch 300] loss: 0.10618414600845426
[Epoch 3, Batch 400] loss: 0.10862973352195696
[Epoch 3, Batch 500] loss: 0.09167513251304626
[Epoch 3, Batch 600] loss: 0.09071038308087737
[Epoch 3, Batch 700] loss: 0.09591402151389047
[Epoch 3, Batch 800] loss: 0.08533433354459703
[Epoch 3, Batch 900] loss: 0.10156168464105576
[Epoch 3, Batch 1000] loss: 0.09193500220309943
[Epoch 3, Batch 1100] loss: 0.07506855383049697
[Epoch 3, Batch 1200] loss: 0.07932416446041315
[Epoch 3, Batch 1300] loss: 0.09483175695640966
[Epoch 3, Batch 1400] loss: 0.06901191342389211
[Epoch 3, Batch 1500] loss: 0.0891078727482818
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0821
Validation Accuracy: 0.9742
Overfitting: 0.0821
[Epoch 4, Batch 100] loss: 0.07849166613072157
[Epoch 4, Batch 200] loss: 0.0737474057613872
[Epoch 4, Batch 300] loss: 0.08127768016420304
[Epoch 4, Batch 400] loss: 0.08567098976112902
[Epoch 4, Batch 500] loss: 0.07019572739722207
[Epoch 4, Batch 600] loss: 0.07089751167222857
[Epoch 4, Batch 700] loss: 0.07321330096689053
[Epoch 4, Batch 800] loss: 0.06850376289570705
[Epoch 4, Batch 900] loss: 0.06714023956330493
[Epoch 4, Batch 1000] loss: 0.06317872739164158
[Epoch 4, Batch 1100] loss: 0.06211218514014036
[Epoch 4, Batch 1200] loss: 0.08670886412030086
[Epoch 4, Batch 1300] loss: 0.05651758884661831
[Epoch 4, Batch 1400] loss: 0.07192074897000567
[Epoch 4, Batch 1500] loss: 0.05389301240677014
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0667
Validation Accuracy: 0.9798
Overfitting: 0.0667
[Epoch 5, Batch 100] loss: 0.053460911179427056
[Epoch 5, Batch 200] loss: 0.06209514401620254
[Epoch 5, Batch 300] loss: 0.0581402341555804
[Epoch 5, Batch 400] loss: 0.06137761488324031
[Epoch 5, Batch 500] loss: 0.06607450690935365
[Epoch 5, Batch 600] loss: 0.060138976469170304
[Epoch 5, Batch 700] loss: 0.05354026449494995
[Epoch 5, Batch 800] loss: 0.06545054996386171
[Epoch 5, Batch 900] loss: 0.0542167534539476
[Epoch 5, Batch 1000] loss: 0.06290845778770744
[Epoch 5, Batch 1100] loss: 0.07376500432903413
[Epoch 5, Batch 1200] loss: 0.0516767930588685
[Epoch 5, Batch 1300] loss: 0.04637454462004825
[Epoch 5, Batch 1400] loss: 0.06162498618592508
[Epoch 5, Batch 1500] loss: 0.04967619915143587
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0616
Validation Accuracy: 0.9812
Overfitting: 0.0616
[Epoch 6, Batch 100] loss: 0.062359163009095935
[Epoch 6, Batch 200] loss: 0.05002861686283722
[Epoch 6, Batch 300] loss: 0.0545091344579123
[Epoch 6, Batch 400] loss: 0.06456159136025236
[Epoch 6, Batch 500] loss: 0.04955185432569124
[Epoch 6, Batch 600] loss: 0.04595102533814497
[Epoch 6, Batch 700] loss: 0.051102152151288466
[Epoch 6, Batch 800] loss: 0.0542624954204075
[Epoch 6, Batch 900] loss: 0.04414824364241213
[Epoch 6, Batch 1000] loss: 0.0460028369736392
[Epoch 6, Batch 1100] loss: 0.04983972886460833
[Epoch 6, Batch 1200] loss: 0.04541644677752629
[Epoch 6, Batch 1300] loss: 0.04262761884136126
[Epoch 6, Batch 1400] loss: 0.04369869515649043
[Epoch 6, Batch 1500] loss: 0.04465310193132609
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0529
Validation Accuracy: 0.9835
Overfitting: 0.0529
[Epoch 7, Batch 100] loss: 0.036051445576013065
[Epoch 7, Batch 200] loss: 0.044341668948763985
[Epoch 7, Batch 300] loss: 0.05654365921684075
[Epoch 7, Batch 400] loss: 0.047841543488902974
[Epoch 7, Batch 500] loss: 0.03919988339999691
[Epoch 7, Batch 600] loss: 0.05028007935849019
[Epoch 7, Batch 700] loss: 0.042527518981369215
[Epoch 7, Batch 800] loss: 0.04073111267993226
[Epoch 7, Batch 900] loss: 0.05133962831925601
[Epoch 7, Batch 1000] loss: 0.04305313681747066
[Epoch 7, Batch 1100] loss: 0.03880259751545964
[Epoch 7, Batch 1200] loss: 0.03527893988066353
[Epoch 7, Batch 1300] loss: 0.04281481694313698
[Epoch 7, Batch 1400] loss: 0.04373374747927301
[Epoch 7, Batch 1500] loss: 0.04902013736777008
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9844
Overfitting: 0.0514
[Epoch 8, Batch 100] loss: 0.04299100818345323
[Epoch 8, Batch 200] loss: 0.023488569456967524
[Epoch 8, Batch 300] loss: 0.040484916273271665
[Epoch 8, Batch 400] loss: 0.029900260114809497
[Epoch 8, Batch 500] loss: 0.04603194745490327
[Epoch 8, Batch 600] loss: 0.04538722036988475
[Epoch 8, Batch 700] loss: 0.034611268878215924
[Epoch 8, Batch 800] loss: 0.03809243695868645
[Epoch 8, Batch 900] loss: 0.037663498557813
[Epoch 8, Batch 1000] loss: 0.049481027280562556
[Epoch 8, Batch 1100] loss: 0.034922097515664066
[Epoch 8, Batch 1200] loss: 0.03850906329054851
[Epoch 8, Batch 1300] loss: 0.033261971160536634
[Epoch 8, Batch 1400] loss: 0.041418056850670834
[Epoch 8, Batch 1500] loss: 0.04725838030222804
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0489
Validation Accuracy: 0.9859
Overfitting: 0.0489
[Epoch 9, Batch 100] loss: 0.037196061357390134
[Epoch 9, Batch 200] loss: 0.03751906930352561
[Epoch 9, Batch 300] loss: 0.03829869849490933
[Epoch 9, Batch 400] loss: 0.031607004837715065
[Epoch 9, Batch 500] loss: 0.03457151168375276
[Epoch 9, Batch 600] loss: 0.03139822720142547
[Epoch 9, Batch 700] loss: 0.040467155201477
[Epoch 9, Batch 800] loss: 0.03647727721137926
[Epoch 9, Batch 900] loss: 0.029157186598167753
[Epoch 9, Batch 1000] loss: 0.02714891052848543
[Epoch 9, Batch 1100] loss: 0.025991923473775387
[Epoch 9, Batch 1200] loss: 0.0312598381692078
[Epoch 9, Batch 1300] loss: 0.03432230644393712
[Epoch 9, Batch 1400] loss: 0.04634152157610515
[Epoch 9, Batch 1500] loss: 0.03877158981660614
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9859
Overfitting: 0.0473
Best model saved at epoch 9 with validation loss: 0.0473
[Epoch 10, Batch 100] loss: 0.02592666150012519
[Epoch 10, Batch 200] loss: 0.02510059494554298
[Epoch 10, Batch 300] loss: 0.03140133498731302
[Epoch 10, Batch 400] loss: 0.027221127419616097
[Epoch 10, Batch 500] loss: 0.030543294472736307
[Epoch 10, Batch 600] loss: 0.029095653620170196
[Epoch 10, Batch 700] loss: 0.03733415786526166
[Epoch 10, Batch 800] loss: 0.02752119664248312
[Epoch 10, Batch 900] loss: 0.02928558743733447
[Epoch 10, Batch 1000] loss: 0.02773632643511519
[Epoch 10, Batch 1100] loss: 0.031001304463716226
[Epoch 10, Batch 1200] loss: 0.035577953396277735
[Epoch 10, Batch 1300] loss: 0.03995072358462494
[Epoch 10, Batch 1400] loss: 0.02675965911737876
[Epoch 10, Batch 1500] loss: 0.036306462725042364
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0501
Validation Accuracy: 0.9843
Overfitting: 0.0501
[Epoch 11, Batch 100] loss: 0.031626989904616494
[Epoch 11, Batch 200] loss: 0.03574405946914339
[Epoch 11, Batch 300] loss: 0.022668564323394095
[Epoch 11, Batch 400] loss: 0.021564112312335057
[Epoch 11, Batch 500] loss: 0.025178799177956533
[Epoch 11, Batch 600] loss: 0.02599752143374644
[Epoch 11, Batch 700] loss: 0.021173268502461724
[Epoch 11, Batch 800] loss: 0.023711424988287034
[Epoch 11, Batch 900] loss: 0.03360805925563909
[Epoch 11, Batch 1000] loss: 0.024133069563977188
[Epoch 11, Batch 1100] loss: 0.031602908789063806
[Epoch 11, Batch 1200] loss: 0.026150141319376416
[Epoch 11, Batch 1300] loss: 0.024081744683498982
[Epoch 11, Batch 1400] loss: 0.0328812812839169
[Epoch 11, Batch 1500] loss: 0.03838680753891822
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0500
Validation Accuracy: 0.9842
Overfitting: 0.0500
Early stopping epoch 11 for trial 13. Moving to next fold.
Fold 5 validation loss: 0.0500
Mean validation loss across all folds for Trial 13 is 0.0493 with trial config:  l1: 256, l2: 128, lr: 0.001, batch_size: 32
[I 2024-12-10 05:58:35,786] Trial 12 finished with value: 0.0492618556785242 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 32}. Best is trial 12 with value: 0.0492618556785242.

Selected Hyperparameters for Trial 14:
  l1: 256, l2: 128, lr: 0.001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.300813591480255
[Epoch 1, Batch 200] loss: 2.2725905346870423
[Epoch 1, Batch 300] loss: 2.191360397338867
[Epoch 1, Batch 400] loss: 1.694649812579155
[Epoch 1, Batch 500] loss: 0.7107283508777619
[Epoch 1, Batch 600] loss: 0.4925158430635929
[Epoch 1, Batch 700] loss: 0.4127213802188635
[Epoch 1, Batch 800] loss: 0.36000802643597124
[Epoch 1, Batch 900] loss: 0.33013324838131664
[Epoch 1, Batch 1000] loss: 0.29109961435198783
[Epoch 1, Batch 1100] loss: 0.2620016361400485
[Epoch 1, Batch 1200] loss: 0.2683915954083204
[Epoch 1, Batch 1300] loss: 0.22627633173018694
[Epoch 1, Batch 1400] loss: 0.205582415740937
[Epoch 1, Batch 1500] loss: 0.19964791253209113
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1899
Validation Accuracy: 0.9446
Overfitting: 0.1899
[Epoch 2, Batch 100] loss: 0.18768071204423906
[Epoch 2, Batch 200] loss: 0.2053999980352819
[Epoch 2, Batch 300] loss: 0.17840230565518142
[Epoch 2, Batch 400] loss: 0.18373452683910727
[Epoch 2, Batch 500] loss: 0.1515481471642852
[Epoch 2, Batch 600] loss: 0.15316115472465752
[Epoch 2, Batch 700] loss: 0.16222243262454866
[Epoch 2, Batch 800] loss: 0.15480208061635495
[Epoch 2, Batch 900] loss: 0.13431181211024523
[Epoch 2, Batch 1000] loss: 0.13156542582437397
[Epoch 2, Batch 1100] loss: 0.15185297662392258
[Epoch 2, Batch 1200] loss: 0.1303170725889504
[Epoch 2, Batch 1300] loss: 0.11747965233400465
[Epoch 2, Batch 1400] loss: 0.12466786652803422
[Epoch 2, Batch 1500] loss: 0.1296381595823914
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1046
Validation Accuracy: 0.9677
Overfitting: 0.1046
[Epoch 3, Batch 100] loss: 0.10271601924672723
[Epoch 3, Batch 200] loss: 0.10446975299157202
[Epoch 3, Batch 300] loss: 0.10950091576203703
[Epoch 3, Batch 400] loss: 0.10580429346300661
[Epoch 3, Batch 500] loss: 0.10854584654560312
[Epoch 3, Batch 600] loss: 0.11536574720405042
[Epoch 3, Batch 700] loss: 0.1011645220639184
[Epoch 3, Batch 800] loss: 0.09960910924244672
[Epoch 3, Batch 900] loss: 0.09894644698826596
[Epoch 3, Batch 1000] loss: 0.08980830679647625
[Epoch 3, Batch 1100] loss: 0.1026871542679146
[Epoch 3, Batch 1200] loss: 0.11124793810304254
[Epoch 3, Batch 1300] loss: 0.09385833755135536
[Epoch 3, Batch 1400] loss: 0.09856013503856957
[Epoch 3, Batch 1500] loss: 0.07915194992441683
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0881
Validation Accuracy: 0.9718
Overfitting: 0.0881
[Epoch 4, Batch 100] loss: 0.09784986039157957
[Epoch 4, Batch 200] loss: 0.09044486625585706
[Epoch 4, Batch 300] loss: 0.08471804079134017
[Epoch 4, Batch 400] loss: 0.09396091892849653
[Epoch 4, Batch 500] loss: 0.0703966001374647
[Epoch 4, Batch 600] loss: 0.08668513427022845
[Epoch 4, Batch 700] loss: 0.07227396508445963
[Epoch 4, Batch 800] loss: 0.09783220691606402
[Epoch 4, Batch 900] loss: 0.06128628992009908
[Epoch 4, Batch 1000] loss: 0.0727188986679539
[Epoch 4, Batch 1100] loss: 0.07389612120809033
[Epoch 4, Batch 1200] loss: 0.07133135004201904
[Epoch 4, Batch 1300] loss: 0.05781530627631582
[Epoch 4, Batch 1400] loss: 0.06900123945437371
[Epoch 4, Batch 1500] loss: 0.08166167217656038
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0714
Validation Accuracy: 0.9771
Overfitting: 0.0714
[Epoch 5, Batch 100] loss: 0.06586550762876868
[Epoch 5, Batch 200] loss: 0.08206965962424874
[Epoch 5, Batch 300] loss: 0.07717796019278467
[Epoch 5, Batch 400] loss: 0.06171105251181871
[Epoch 5, Batch 500] loss: 0.0725685046100989
[Epoch 5, Batch 600] loss: 0.06383470402332023
[Epoch 5, Batch 700] loss: 0.05903188301948831
[Epoch 5, Batch 800] loss: 0.05821449541603215
[Epoch 5, Batch 900] loss: 0.06695969495689497
[Epoch 5, Batch 1000] loss: 0.07111750078154727
[Epoch 5, Batch 1100] loss: 0.052993159655015915
[Epoch 5, Batch 1200] loss: 0.0629730499885045
[Epoch 5, Batch 1300] loss: 0.06846783978398889
[Epoch 5, Batch 1400] loss: 0.05794473231537268
[Epoch 5, Batch 1500] loss: 0.059166797435609625
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0638
Validation Accuracy: 0.9798
Overfitting: 0.0638
[Epoch 6, Batch 100] loss: 0.05933352407766506
[Epoch 6, Batch 200] loss: 0.06059601513901725
[Epoch 6, Batch 300] loss: 0.045524169635027645
[Epoch 6, Batch 400] loss: 0.05339110569097102
[Epoch 6, Batch 500] loss: 0.055653368176426736
[Epoch 6, Batch 600] loss: 0.05414788091555238
[Epoch 6, Batch 700] loss: 0.06068817715975456
[Epoch 6, Batch 800] loss: 0.06045949542080052
[Epoch 6, Batch 900] loss: 0.06400250895414501
[Epoch 6, Batch 1000] loss: 0.057031504730693995
[Epoch 6, Batch 1100] loss: 0.06558244141982868
[Epoch 6, Batch 1200] loss: 0.04382928069680929
[Epoch 6, Batch 1300] loss: 0.049352076360955836
[Epoch 6, Batch 1400] loss: 0.04154777449555695
[Epoch 6, Batch 1500] loss: 0.05049203452770598
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0565
Validation Accuracy: 0.9818
Overfitting: 0.0565
[Epoch 7, Batch 100] loss: 0.04039763274253346
[Epoch 7, Batch 200] loss: 0.044420526037574744
[Epoch 7, Batch 300] loss: 0.04568307046312839
[Epoch 7, Batch 400] loss: 0.04010619295819197
[Epoch 7, Batch 500] loss: 0.04582904997514561
[Epoch 7, Batch 600] loss: 0.06929430195596069
[Epoch 7, Batch 700] loss: 0.03889676154823974
[Epoch 7, Batch 800] loss: 0.04353702428517863
[Epoch 7, Batch 900] loss: 0.05946277966606431
[Epoch 7, Batch 1000] loss: 0.04736676035274286
[Epoch 7, Batch 1100] loss: 0.041915345889865424
[Epoch 7, Batch 1200] loss: 0.04854232121724635
[Epoch 7, Batch 1300] loss: 0.055537370576057586
[Epoch 7, Batch 1400] loss: 0.05871968881401699
[Epoch 7, Batch 1500] loss: 0.03823922650422901
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9841
Overfitting: 0.0512
[Epoch 8, Batch 100] loss: 0.03648568906995933
[Epoch 8, Batch 200] loss: 0.028568857392529026
[Epoch 8, Batch 300] loss: 0.04262993640382774
[Epoch 8, Batch 400] loss: 0.041729359925957395
[Epoch 8, Batch 500] loss: 0.052417968942318115
[Epoch 8, Batch 600] loss: 0.05499142644519452
[Epoch 8, Batch 700] loss: 0.04204579343087971
[Epoch 8, Batch 800] loss: 0.04146259862463921
[Epoch 8, Batch 900] loss: 0.04686043191701174
[Epoch 8, Batch 1000] loss: 0.03732862391916569
[Epoch 8, Batch 1100] loss: 0.04948196578247007
[Epoch 8, Batch 1200] loss: 0.04708302342507523
[Epoch 8, Batch 1300] loss: 0.047058022576384244
[Epoch 8, Batch 1400] loss: 0.04028194371581776
[Epoch 8, Batch 1500] loss: 0.03585553650453221
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9838
Overfitting: 0.0515
[Epoch 9, Batch 100] loss: 0.034630629426683296
[Epoch 9, Batch 200] loss: 0.037283343253657224
[Epoch 9, Batch 300] loss: 0.03949070482281968
[Epoch 9, Batch 400] loss: 0.04114798285299912
[Epoch 9, Batch 500] loss: 0.04386044412094634
[Epoch 9, Batch 600] loss: 0.03366456770163495
[Epoch 9, Batch 700] loss: 0.04124125948525034
[Epoch 9, Batch 800] loss: 0.039467600595671684
[Epoch 9, Batch 900] loss: 0.04614214494125918
[Epoch 9, Batch 1000] loss: 0.025374704077257774
[Epoch 9, Batch 1100] loss: 0.033165724872378635
[Epoch 9, Batch 1200] loss: 0.03735184684512206
[Epoch 9, Batch 1300] loss: 0.036251234788214785
[Epoch 9, Batch 1400] loss: 0.03022296697832644
[Epoch 9, Batch 1500] loss: 0.03426126778649632
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9853
Overfitting: 0.0466
Best model saved at epoch 9 with validation loss: 0.0466
[Epoch 10, Batch 100] loss: 0.027681943183415568
[Epoch 10, Batch 200] loss: 0.033307215317036024
[Epoch 10, Batch 300] loss: 0.027882825556735043
[Epoch 10, Batch 400] loss: 0.032535261940502096
[Epoch 10, Batch 500] loss: 0.03733394865092123
[Epoch 10, Batch 600] loss: 0.039272911024454515
[Epoch 10, Batch 700] loss: 0.03771639506448991
[Epoch 10, Batch 800] loss: 0.04562149403733201
[Epoch 10, Batch 900] loss: 0.02783575571491383
[Epoch 10, Batch 1000] loss: 0.04286814346502069
[Epoch 10, Batch 1100] loss: 0.026751580322888914
[Epoch 10, Batch 1200] loss: 0.038895625028526414
[Epoch 10, Batch 1300] loss: 0.032612687199143696
[Epoch 10, Batch 1400] loss: 0.0406555457675131
[Epoch 10, Batch 1500] loss: 0.030126447236689273
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0662
Validation Accuracy: 0.9789
Overfitting: 0.0662
[Epoch 11, Batch 100] loss: 0.03041868444706779
[Epoch 11, Batch 200] loss: 0.03612257715314627
[Epoch 11, Batch 300] loss: 0.025634361218544656
[Epoch 11, Batch 400] loss: 0.029013935633120127
[Epoch 11, Batch 500] loss: 0.0252818884793669
[Epoch 11, Batch 600] loss: 0.027070990691136103
[Epoch 11, Batch 700] loss: 0.03205682088359026
[Epoch 11, Batch 800] loss: 0.026232868898950983
[Epoch 11, Batch 900] loss: 0.02918895816692384
[Epoch 11, Batch 1000] loss: 0.031256553558050654
[Epoch 11, Batch 1100] loss: 0.026320468006160808
[Epoch 11, Batch 1200] loss: 0.0382739532389678
[Epoch 11, Batch 1300] loss: 0.030264060394256376
[Epoch 11, Batch 1400] loss: 0.02691487243107986
[Epoch 11, Batch 1500] loss: 0.03542638384504244
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0476
Validation Accuracy: 0.9853
Overfitting: 0.0476
Early stopping epoch 11 for trial 14. Moving to next fold.
Fold 1 validation loss: 0.0476
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2853620290756225
[Epoch 1, Batch 200] loss: 2.2221857261657716
[Epoch 1, Batch 300] loss: 1.8416226649284362
[Epoch 1, Batch 400] loss: 0.8351381823420525
[Epoch 1, Batch 500] loss: 0.5558478631079197
[Epoch 1, Batch 600] loss: 0.4285696129500866
[Epoch 1, Batch 700] loss: 0.39090314581990243
[Epoch 1, Batch 800] loss: 0.351337858736515
[Epoch 1, Batch 900] loss: 0.3421996480226517
[Epoch 1, Batch 1000] loss: 0.2636057713627815
[Epoch 1, Batch 1100] loss: 0.2463152151182294
[Epoch 1, Batch 1200] loss: 0.23440511241555215
[Epoch 1, Batch 1300] loss: 0.24637138981372117
[Epoch 1, Batch 1400] loss: 0.2081770204566419
[Epoch 1, Batch 1500] loss: 0.19514351028949023
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2250
Validation Accuracy: 0.9289
Overfitting: 0.2250
[Epoch 2, Batch 100] loss: 0.19696893028914927
[Epoch 2, Batch 200] loss: 0.17169010987505318
[Epoch 2, Batch 300] loss: 0.15572194065898656
[Epoch 2, Batch 400] loss: 0.16344748821109534
[Epoch 2, Batch 500] loss: 0.15192576330155133
[Epoch 2, Batch 600] loss: 0.15680305249989032
[Epoch 2, Batch 700] loss: 0.16203025992959738
[Epoch 2, Batch 800] loss: 0.14977985998615623
[Epoch 2, Batch 900] loss: 0.14221278004348278
[Epoch 2, Batch 1000] loss: 0.13466302750632167
[Epoch 2, Batch 1100] loss: 0.11850340179167689
[Epoch 2, Batch 1200] loss: 0.13162212498486042
[Epoch 2, Batch 1300] loss: 0.12839400747790933
[Epoch 2, Batch 1400] loss: 0.10638529336079955
[Epoch 2, Batch 1500] loss: 0.11046327823773026
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1267
Validation Accuracy: 0.9613
Overfitting: 0.1267
[Epoch 3, Batch 100] loss: 0.10755893842782825
[Epoch 3, Batch 200] loss: 0.11057421853765845
[Epoch 3, Batch 300] loss: 0.09905833217781038
[Epoch 3, Batch 400] loss: 0.10566092525841668
[Epoch 3, Batch 500] loss: 0.10387650775723159
[Epoch 3, Batch 600] loss: 0.0857733111619018
[Epoch 3, Batch 700] loss: 0.10365192221011967
[Epoch 3, Batch 800] loss: 0.0977007995871827
[Epoch 3, Batch 900] loss: 0.10470958843827248
[Epoch 3, Batch 1000] loss: 0.08327660710550845
[Epoch 3, Batch 1100] loss: 0.09358243995346129
[Epoch 3, Batch 1200] loss: 0.0911525416886434
[Epoch 3, Batch 1300] loss: 0.08927226293133572
[Epoch 3, Batch 1400] loss: 0.08703039295272902
[Epoch 3, Batch 1500] loss: 0.09148470853921026
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1050
Validation Accuracy: 0.9677
Overfitting: 0.1050
[Epoch 4, Batch 100] loss: 0.07716009626165032
[Epoch 4, Batch 200] loss: 0.07639032091014088
[Epoch 4, Batch 300] loss: 0.07596524487715214
[Epoch 4, Batch 400] loss: 0.09201458063209429
[Epoch 4, Batch 500] loss: 0.06946642211638392
[Epoch 4, Batch 600] loss: 0.08197252306155861
[Epoch 4, Batch 700] loss: 0.07783965647220611
[Epoch 4, Batch 800] loss: 0.0759902817197144
[Epoch 4, Batch 900] loss: 0.07749517884105445
[Epoch 4, Batch 1000] loss: 0.07764300250681117
[Epoch 4, Batch 1100] loss: 0.07715082874055952
[Epoch 4, Batch 1200] loss: 0.06184409622335806
[Epoch 4, Batch 1300] loss: 0.07826010201824829
[Epoch 4, Batch 1400] loss: 0.06311564463190734
[Epoch 4, Batch 1500] loss: 0.07173516548704356
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0827
Validation Accuracy: 0.9757
Overfitting: 0.0827
[Epoch 5, Batch 100] loss: 0.06800738588906824
[Epoch 5, Batch 200] loss: 0.05939598482567817
[Epoch 5, Batch 300] loss: 0.07873471315018833
[Epoch 5, Batch 400] loss: 0.06014344377676025
[Epoch 5, Batch 500] loss: 0.06966631959658116
[Epoch 5, Batch 600] loss: 0.05909554157638922
[Epoch 5, Batch 700] loss: 0.06762429486261681
[Epoch 5, Batch 800] loss: 0.0674514911416918
[Epoch 5, Batch 900] loss: 0.06380390977603384
[Epoch 5, Batch 1000] loss: 0.053847878384403886
[Epoch 5, Batch 1100] loss: 0.05472711582435295
[Epoch 5, Batch 1200] loss: 0.05563657997874543
[Epoch 5, Batch 1300] loss: 0.0532983954960946
[Epoch 5, Batch 1400] loss: 0.06650222901022061
[Epoch 5, Batch 1500] loss: 0.06846534059615805
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0749
Validation Accuracy: 0.9772
Overfitting: 0.0749
[Epoch 6, Batch 100] loss: 0.05510900946566835
[Epoch 6, Batch 200] loss: 0.04970149866770953
[Epoch 6, Batch 300] loss: 0.056486708824522794
[Epoch 6, Batch 400] loss: 0.05408175155171193
[Epoch 6, Batch 500] loss: 0.05763766066171229
[Epoch 6, Batch 600] loss: 0.05302058822941035
[Epoch 6, Batch 700] loss: 0.05194333794061094
[Epoch 6, Batch 800] loss: 0.04123277104343288
[Epoch 6, Batch 900] loss: 0.060885132893454284
[Epoch 6, Batch 1000] loss: 0.05718640567618422
[Epoch 6, Batch 1100] loss: 0.045176134932553395
[Epoch 6, Batch 1200] loss: 0.04784063312690705
[Epoch 6, Batch 1300] loss: 0.0506718574318802
[Epoch 6, Batch 1400] loss: 0.05826475638430566
[Epoch 6, Batch 1500] loss: 0.05810873330803588
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0702
Validation Accuracy: 0.9784
Overfitting: 0.0702
[Epoch 7, Batch 100] loss: 0.04325486800866202
[Epoch 7, Batch 200] loss: 0.048803513548336924
[Epoch 7, Batch 300] loss: 0.048194640128640456
[Epoch 7, Batch 400] loss: 0.03823994158185087
[Epoch 7, Batch 500] loss: 0.040996241461252796
[Epoch 7, Batch 600] loss: 0.05110749804996886
[Epoch 7, Batch 700] loss: 0.05360395216150209
[Epoch 7, Batch 800] loss: 0.04709011131315492
[Epoch 7, Batch 900] loss: 0.0644809542724397
[Epoch 7, Batch 1000] loss: 0.04429242276004516
[Epoch 7, Batch 1100] loss: 0.04640816922765225
[Epoch 7, Batch 1200] loss: 0.04322458322858438
[Epoch 7, Batch 1300] loss: 0.0349382590217283
[Epoch 7, Batch 1400] loss: 0.05455784790974576
[Epoch 7, Batch 1500] loss: 0.04679821508587338
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0623
Validation Accuracy: 0.9808
Overfitting: 0.0623
[Epoch 8, Batch 100] loss: 0.0353895572660258
[Epoch 8, Batch 200] loss: 0.03632169720600359
[Epoch 8, Batch 300] loss: 0.042730738300597294
[Epoch 8, Batch 400] loss: 0.04124340031994507
[Epoch 8, Batch 500] loss: 0.05284495283151045
[Epoch 8, Batch 600] loss: 0.04639886935707182
[Epoch 8, Batch 700] loss: 0.03831144173629582
[Epoch 8, Batch 800] loss: 0.039435683934716505
[Epoch 8, Batch 900] loss: 0.036586168847279624
[Epoch 8, Batch 1000] loss: 0.046646787591162135
[Epoch 8, Batch 1100] loss: 0.0400420283182757
[Epoch 8, Batch 1200] loss: 0.045829934051726015
[Epoch 8, Batch 1300] loss: 0.030928249143180438
[Epoch 8, Batch 1400] loss: 0.04324333822820336
[Epoch 8, Batch 1500] loss: 0.04040147188701667
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0600
Validation Accuracy: 0.9808
Overfitting: 0.0600
[Epoch 9, Batch 100] loss: 0.03142833579273429
[Epoch 9, Batch 200] loss: 0.03299043057792005
[Epoch 9, Batch 300] loss: 0.04025039836880751
[Epoch 9, Batch 400] loss: 0.026144894774188288
[Epoch 9, Batch 500] loss: 0.04086617983120959
[Epoch 9, Batch 600] loss: 0.029955627017770894
[Epoch 9, Batch 700] loss: 0.032801438233000225
[Epoch 9, Batch 800] loss: 0.038246516252984294
[Epoch 9, Batch 900] loss: 0.04137672490091063
[Epoch 9, Batch 1000] loss: 0.056713315970264376
[Epoch 9, Batch 1100] loss: 0.036553313445765526
[Epoch 9, Batch 1200] loss: 0.03401776347309351
[Epoch 9, Batch 1300] loss: 0.035880263974831905
[Epoch 9, Batch 1400] loss: 0.03241992464114446
[Epoch 9, Batch 1500] loss: 0.04362540438625729
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0674
Validation Accuracy: 0.9783
Overfitting: 0.0674
Best model saved at epoch 9 with validation loss: 0.0674
[Epoch 10, Batch 100] loss: 0.03053591343072185
[Epoch 10, Batch 200] loss: 0.03084977879188955
[Epoch 10, Batch 300] loss: 0.03148555670224596
[Epoch 10, Batch 400] loss: 0.0361219374180655
[Epoch 10, Batch 500] loss: 0.030069376587925946
[Epoch 10, Batch 600] loss: 0.033164285619277506
[Epoch 10, Batch 700] loss: 0.030166668717574795
[Epoch 10, Batch 800] loss: 0.045930170292849654
[Epoch 10, Batch 900] loss: 0.03471541830396745
[Epoch 10, Batch 1000] loss: 0.044866453919385096
[Epoch 10, Batch 1100] loss: 0.027901988716912456
[Epoch 10, Batch 1200] loss: 0.026109929139201994
[Epoch 10, Batch 1300] loss: 0.028298245474579743
[Epoch 10, Batch 1400] loss: 0.03371110641630366
[Epoch 10, Batch 1500] loss: 0.03525966632121708
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0612
Validation Accuracy: 0.9825
Overfitting: 0.0612
[Epoch 11, Batch 100] loss: 0.03279831823310815
[Epoch 11, Batch 200] loss: 0.030042897587409242
[Epoch 11, Batch 300] loss: 0.026077402968076056
[Epoch 11, Batch 400] loss: 0.028885823072632776
[Epoch 11, Batch 500] loss: 0.021288560032844545
[Epoch 11, Batch 600] loss: 0.023298699268489143
[Epoch 11, Batch 700] loss: 0.02386503618035931
[Epoch 11, Batch 800] loss: 0.026602879047277383
[Epoch 11, Batch 900] loss: 0.030542101278260816
[Epoch 11, Batch 1000] loss: 0.03608664508414222
[Epoch 11, Batch 1100] loss: 0.033983800718560817
[Epoch 11, Batch 1200] loss: 0.02326571052719373
[Epoch 11, Batch 1300] loss: 0.04547353062254842
[Epoch 11, Batch 1400] loss: 0.03149104413052555
[Epoch 11, Batch 1500] loss: 0.034004568675300106
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0636
Validation Accuracy: 0.9812
Overfitting: 0.0636
Early stopping epoch 11 for trial 14. Moving to next fold.
Fold 2 validation loss: 0.0636
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2927496695518492
[Epoch 1, Batch 200] loss: 2.2324901723861696
[Epoch 1, Batch 300] loss: 1.856298667192459
[Epoch 1, Batch 400] loss: 0.8727265149354935
[Epoch 1, Batch 500] loss: 0.5651612751185894
[Epoch 1, Batch 600] loss: 0.43683614999055864
[Epoch 1, Batch 700] loss: 0.3846140867471695
[Epoch 1, Batch 800] loss: 0.35638743050396443
[Epoch 1, Batch 900] loss: 0.3025801956653595
[Epoch 1, Batch 1000] loss: 0.28770035173743963
[Epoch 1, Batch 1100] loss: 0.2729950887709856
[Epoch 1, Batch 1200] loss: 0.21878940537571906
[Epoch 1, Batch 1300] loss: 0.20491615062579513
[Epoch 1, Batch 1400] loss: 0.21845386296510697
[Epoch 1, Batch 1500] loss: 0.19471749037504196
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2131
Validation Accuracy: 0.9345
Overfitting: 0.2131
[Epoch 2, Batch 100] loss: 0.18419980816543102
[Epoch 2, Batch 200] loss: 0.16041239365935325
[Epoch 2, Batch 300] loss: 0.1644757305458188
[Epoch 2, Batch 400] loss: 0.15263350376859308
[Epoch 2, Batch 500] loss: 0.14650776714086533
[Epoch 2, Batch 600] loss: 0.15085507243871688
[Epoch 2, Batch 700] loss: 0.1515235192887485
[Epoch 2, Batch 800] loss: 0.13149025103077291
[Epoch 2, Batch 900] loss: 0.13040344695560635
[Epoch 2, Batch 1000] loss: 0.11276286272332073
[Epoch 2, Batch 1100] loss: 0.1209272403921932
[Epoch 2, Batch 1200] loss: 0.12696580129675566
[Epoch 2, Batch 1300] loss: 0.1307461923547089
[Epoch 2, Batch 1400] loss: 0.09819792861584574
[Epoch 2, Batch 1500] loss: 0.10111546623054891
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1138
Validation Accuracy: 0.9674
Overfitting: 0.1138
[Epoch 3, Batch 100] loss: 0.08956955460831523
[Epoch 3, Batch 200] loss: 0.09519542302936315
[Epoch 3, Batch 300] loss: 0.09114279601722956
[Epoch 3, Batch 400] loss: 0.08969542812090367
[Epoch 3, Batch 500] loss: 0.10699976016301661
[Epoch 3, Batch 600] loss: 0.10050616651773453
[Epoch 3, Batch 700] loss: 0.10314216652885079
[Epoch 3, Batch 800] loss: 0.08106284252367914
[Epoch 3, Batch 900] loss: 0.08335161184892058
[Epoch 3, Batch 1000] loss: 0.08932101782876999
[Epoch 3, Batch 1100] loss: 0.07894164806697518
[Epoch 3, Batch 1200] loss: 0.08302980287699029
[Epoch 3, Batch 1300] loss: 0.07720383889507502
[Epoch 3, Batch 1400] loss: 0.09363781090360135
[Epoch 3, Batch 1500] loss: 0.0876304612471722
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0790
Validation Accuracy: 0.9769
Overfitting: 0.0790
[Epoch 4, Batch 100] loss: 0.07171415093820542
[Epoch 4, Batch 200] loss: 0.06856060366844759
[Epoch 4, Batch 300] loss: 0.06630609897896647
[Epoch 4, Batch 400] loss: 0.07934621840016916
[Epoch 4, Batch 500] loss: 0.0832797888154164
[Epoch 4, Batch 600] loss: 0.0707580581284128
[Epoch 4, Batch 700] loss: 0.05928683139616624
[Epoch 4, Batch 800] loss: 0.08349655667319894
[Epoch 4, Batch 900] loss: 0.07139209133340046
[Epoch 4, Batch 1000] loss: 0.09392222126945854
[Epoch 4, Batch 1100] loss: 0.06299446872901171
[Epoch 4, Batch 1200] loss: 0.052534327076282354
[Epoch 4, Batch 1300] loss: 0.0655998696363531
[Epoch 4, Batch 1400] loss: 0.06367386939120478
[Epoch 4, Batch 1500] loss: 0.07386496311519294
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0680
Validation Accuracy: 0.9805
Overfitting: 0.0680
[Epoch 5, Batch 100] loss: 0.06730756334029138
[Epoch 5, Batch 200] loss: 0.05518678804859519
[Epoch 5, Batch 300] loss: 0.06582809638231993
[Epoch 5, Batch 400] loss: 0.06398383708437905
[Epoch 5, Batch 500] loss: 0.049441302886698395
[Epoch 5, Batch 600] loss: 0.06247303287032992
[Epoch 5, Batch 700] loss: 0.063765100693563
[Epoch 5, Batch 800] loss: 0.060888520928565414
[Epoch 5, Batch 900] loss: 0.0608309801784344
[Epoch 5, Batch 1000] loss: 0.056410311590880155
[Epoch 5, Batch 1100] loss: 0.05466838966589421
[Epoch 5, Batch 1200] loss: 0.04166016721865162
[Epoch 5, Batch 1300] loss: 0.059051472827559334
[Epoch 5, Batch 1400] loss: 0.06218010741751641
[Epoch 5, Batch 1500] loss: 0.05031104414723814
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0640
Validation Accuracy: 0.9808
Overfitting: 0.0640
[Epoch 6, Batch 100] loss: 0.052185627408907746
[Epoch 6, Batch 200] loss: 0.05146012993296609
[Epoch 6, Batch 300] loss: 0.04439044436090626
[Epoch 6, Batch 400] loss: 0.041249104365706446
[Epoch 6, Batch 500] loss: 0.044325372809544204
[Epoch 6, Batch 600] loss: 0.04623958372161724
[Epoch 6, Batch 700] loss: 0.04739180940319784
[Epoch 6, Batch 800] loss: 0.04663430451764725
[Epoch 6, Batch 900] loss: 0.04756178692448884
[Epoch 6, Batch 1000] loss: 0.056872265986166896
[Epoch 6, Batch 1100] loss: 0.05787911756196991
[Epoch 6, Batch 1200] loss: 0.049816115628927946
[Epoch 6, Batch 1300] loss: 0.04547478110762313
[Epoch 6, Batch 1400] loss: 0.049367111651226876
[Epoch 6, Batch 1500] loss: 0.06261846414534375
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9815
Overfitting: 0.0635
[Epoch 7, Batch 100] loss: 0.04034824400674552
[Epoch 7, Batch 200] loss: 0.03828783553792164
[Epoch 7, Batch 300] loss: 0.037578087829751895
[Epoch 7, Batch 400] loss: 0.03977086002938449
[Epoch 7, Batch 500] loss: 0.04255192572367378
[Epoch 7, Batch 600] loss: 0.04980885152006522
[Epoch 7, Batch 700] loss: 0.04511021346959751
[Epoch 7, Batch 800] loss: 0.04122958673571702
[Epoch 7, Batch 900] loss: 0.05475572314695455
[Epoch 7, Batch 1000] loss: 0.04842354343971238
[Epoch 7, Batch 1100] loss: 0.051497887085424736
[Epoch 7, Batch 1200] loss: 0.04461399833788164
[Epoch 7, Batch 1300] loss: 0.03857056937587913
[Epoch 7, Batch 1400] loss: 0.03828234081622213
[Epoch 7, Batch 1500] loss: 0.03993448576395167
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9838
Overfitting: 0.0559
[Epoch 8, Batch 100] loss: 0.03526202161709079
[Epoch 8, Batch 200] loss: 0.039342744917375966
[Epoch 8, Batch 300] loss: 0.043567853309214116
[Epoch 8, Batch 400] loss: 0.03896052802796476
[Epoch 8, Batch 500] loss: 0.03656452334311325
[Epoch 8, Batch 600] loss: 0.03658469061367214
[Epoch 8, Batch 700] loss: 0.035970229459926485
[Epoch 8, Batch 800] loss: 0.0339041776524391
[Epoch 8, Batch 900] loss: 0.037871044225175864
[Epoch 8, Batch 1000] loss: 0.04254453256056877
[Epoch 8, Batch 1100] loss: 0.042914378602290526
[Epoch 8, Batch 1200] loss: 0.03914984520233702
[Epoch 8, Batch 1300] loss: 0.04343400876387023
[Epoch 8, Batch 1400] loss: 0.026594319485593588
[Epoch 8, Batch 1500] loss: 0.031076285106828437
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0559
Validation Accuracy: 0.9838
Overfitting: 0.0559
[Epoch 9, Batch 100] loss: 0.0311857684480492
[Epoch 9, Batch 200] loss: 0.03268841672979761
[Epoch 9, Batch 300] loss: 0.03185910946514923
[Epoch 9, Batch 400] loss: 0.04376307779690251
[Epoch 9, Batch 500] loss: 0.03957194795541
[Epoch 9, Batch 600] loss: 0.03622318770736456
[Epoch 9, Batch 700] loss: 0.02903894431539811
[Epoch 9, Batch 800] loss: 0.03211620064917952
[Epoch 9, Batch 900] loss: 0.03708664490433875
[Epoch 9, Batch 1000] loss: 0.03694287592094042
[Epoch 9, Batch 1100] loss: 0.033154259438160805
[Epoch 9, Batch 1200] loss: 0.031791870614688376
[Epoch 9, Batch 1300] loss: 0.02995696398196742
[Epoch 9, Batch 1400] loss: 0.03333276088786079
[Epoch 9, Batch 1500] loss: 0.02808193311735522
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0523
Validation Accuracy: 0.9845
Overfitting: 0.0523
Best model saved at epoch 9 with validation loss: 0.0523
[Epoch 10, Batch 100] loss: 0.038055067123495975
[Epoch 10, Batch 200] loss: 0.024481114873779006
[Epoch 10, Batch 300] loss: 0.027341946880042087
[Epoch 10, Batch 400] loss: 0.03718496323243017
[Epoch 10, Batch 500] loss: 0.027635701014951337
[Epoch 10, Batch 600] loss: 0.021375623276107945
[Epoch 10, Batch 700] loss: 0.03314245872534229
[Epoch 10, Batch 800] loss: 0.03823267275874968
[Epoch 10, Batch 900] loss: 0.027519581938395276
[Epoch 10, Batch 1000] loss: 0.02973596470488701
[Epoch 10, Batch 1100] loss: 0.02155911088862922
[Epoch 10, Batch 1200] loss: 0.029456473867176102
[Epoch 10, Batch 1300] loss: 0.020103490367473567
[Epoch 10, Batch 1400] loss: 0.04312973894862807
[Epoch 10, Batch 1500] loss: 0.03767974044487346
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0628
Validation Accuracy: 0.9813
Overfitting: 0.0628
[Epoch 11, Batch 100] loss: 0.023979365490959026
[Epoch 11, Batch 200] loss: 0.03176842968852725
[Epoch 11, Batch 300] loss: 0.025961773309390992
[Epoch 11, Batch 400] loss: 0.02898422180733178
[Epoch 11, Batch 500] loss: 0.02017914158437634
[Epoch 11, Batch 600] loss: 0.02030489240816678
[Epoch 11, Batch 700] loss: 0.02869194048573263
[Epoch 11, Batch 800] loss: 0.03136325143801514
[Epoch 11, Batch 900] loss: 0.023176923357823398
[Epoch 11, Batch 1000] loss: 0.03397280133736785
[Epoch 11, Batch 1100] loss: 0.02415493629028788
[Epoch 11, Batch 1200] loss: 0.03018915960972663
[Epoch 11, Batch 1300] loss: 0.034697458812152034
[Epoch 11, Batch 1400] loss: 0.02405767934251344
[Epoch 11, Batch 1500] loss: 0.021886258411686867
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9869
Overfitting: 0.0465
Early stopping epoch 11 for trial 14. Moving to next fold.
Fold 3 validation loss: 0.0465
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2959112620353697
[Epoch 1, Batch 200] loss: 2.2632676482200624
[Epoch 1, Batch 300] loss: 2.1417059993743894
[Epoch 1, Batch 400] loss: 1.3719309228658676
[Epoch 1, Batch 500] loss: 0.6548878133296967
[Epoch 1, Batch 600] loss: 0.5118201480805874
[Epoch 1, Batch 700] loss: 0.474775215536356
[Epoch 1, Batch 800] loss: 0.3906865829974413
[Epoch 1, Batch 900] loss: 0.33320027731359003
[Epoch 1, Batch 1000] loss: 0.31444774121046065
[Epoch 1, Batch 1100] loss: 0.3007052394002676
[Epoch 1, Batch 1200] loss: 0.26834791135042907
[Epoch 1, Batch 1300] loss: 0.2302761510759592
[Epoch 1, Batch 1400] loss: 0.27000091832131146
[Epoch 1, Batch 1500] loss: 0.2178503507003188
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2276
Validation Accuracy: 0.9261
Overfitting: 0.2276
[Epoch 2, Batch 100] loss: 0.1926651545241475
[Epoch 2, Batch 200] loss: 0.19916415870189666
[Epoch 2, Batch 300] loss: 0.1955784889869392
[Epoch 2, Batch 400] loss: 0.18271307926625013
[Epoch 2, Batch 500] loss: 0.16184689482674003
[Epoch 2, Batch 600] loss: 0.15035866852849722
[Epoch 2, Batch 700] loss: 0.18253744818270207
[Epoch 2, Batch 800] loss: 0.15975624419748782
[Epoch 2, Batch 900] loss: 0.1493894705362618
[Epoch 2, Batch 1000] loss: 0.15274307677522303
[Epoch 2, Batch 1100] loss: 0.12996461167931556
[Epoch 2, Batch 1200] loss: 0.1168613479565829
[Epoch 2, Batch 1300] loss: 0.11691552541218699
[Epoch 2, Batch 1400] loss: 0.14128769892267884
[Epoch 2, Batch 1500] loss: 0.11030328945256769
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1149
Validation Accuracy: 0.9637
Overfitting: 0.1149
[Epoch 3, Batch 100] loss: 0.1258386000338942
[Epoch 3, Batch 200] loss: 0.1033999686827883
[Epoch 3, Batch 300] loss: 0.11452904576901346
[Epoch 3, Batch 400] loss: 0.10535213368944824
[Epoch 3, Batch 500] loss: 0.10584481802303344
[Epoch 3, Batch 600] loss: 0.12191663744859398
[Epoch 3, Batch 700] loss: 0.089158795773983
[Epoch 3, Batch 800] loss: 0.11347774920519442
[Epoch 3, Batch 900] loss: 0.102625693930313
[Epoch 3, Batch 1000] loss: 0.09739167449995875
[Epoch 3, Batch 1100] loss: 0.11169554760679602
[Epoch 3, Batch 1200] loss: 0.0929097391385585
[Epoch 3, Batch 1300] loss: 0.11039045723155141
[Epoch 3, Batch 1400] loss: 0.09430498259142041
[Epoch 3, Batch 1500] loss: 0.08453149577602743
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0914
Validation Accuracy: 0.9698
Overfitting: 0.0914
[Epoch 4, Batch 100] loss: 0.09572518571279943
[Epoch 4, Batch 200] loss: 0.06928132775705308
[Epoch 4, Batch 300] loss: 0.08581957609392703
[Epoch 4, Batch 400] loss: 0.08983591698110104
[Epoch 4, Batch 500] loss: 0.07509875301271678
[Epoch 4, Batch 600] loss: 0.08073063129093498
[Epoch 4, Batch 700] loss: 0.08464973327703774
[Epoch 4, Batch 800] loss: 0.08347855319036171
[Epoch 4, Batch 900] loss: 0.07637417366029695
[Epoch 4, Batch 1000] loss: 0.09935850073816255
[Epoch 4, Batch 1100] loss: 0.08850298367906362
[Epoch 4, Batch 1200] loss: 0.08104891745606438
[Epoch 4, Batch 1300] loss: 0.07197476620320231
[Epoch 4, Batch 1400] loss: 0.08282890409696847
[Epoch 4, Batch 1500] loss: 0.07505601890850812
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0817
Validation Accuracy: 0.9738
Overfitting: 0.0817
[Epoch 5, Batch 100] loss: 0.060238434071652594
[Epoch 5, Batch 200] loss: 0.06954553746734746
[Epoch 5, Batch 300] loss: 0.06497638868633658
[Epoch 5, Batch 400] loss: 0.07473727904260158
[Epoch 5, Batch 500] loss: 0.07835771613288671
[Epoch 5, Batch 600] loss: 0.07004626428708434
[Epoch 5, Batch 700] loss: 0.060229385013226416
[Epoch 5, Batch 800] loss: 0.0655106977315154
[Epoch 5, Batch 900] loss: 0.06874495507334359
[Epoch 5, Batch 1000] loss: 0.07446002444718033
[Epoch 5, Batch 1100] loss: 0.07000006473565008
[Epoch 5, Batch 1200] loss: 0.06041786745190621
[Epoch 5, Batch 1300] loss: 0.06930914332391694
[Epoch 5, Batch 1400] loss: 0.06707211345201358
[Epoch 5, Batch 1500] loss: 0.050375519334338606
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0807
Validation Accuracy: 0.9737
Overfitting: 0.0807
[Epoch 6, Batch 100] loss: 0.06328295694664121
[Epoch 6, Batch 200] loss: 0.05032421119743958
[Epoch 6, Batch 300] loss: 0.06071939885383472
[Epoch 6, Batch 400] loss: 0.06064982342068106
[Epoch 6, Batch 500] loss: 0.0645529290032573
[Epoch 6, Batch 600] loss: 0.06113803441869095
[Epoch 6, Batch 700] loss: 0.04885434546857141
[Epoch 6, Batch 800] loss: 0.06969382375478744
[Epoch 6, Batch 900] loss: 0.05793196438578889
[Epoch 6, Batch 1000] loss: 0.05836369386641309
[Epoch 6, Batch 1100] loss: 0.05125459232076537
[Epoch 6, Batch 1200] loss: 0.061098336713621394
[Epoch 6, Batch 1300] loss: 0.06125160644645802
[Epoch 6, Batch 1400] loss: 0.05043667723890394
[Epoch 6, Batch 1500] loss: 0.05694070694851689
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0648
Validation Accuracy: 0.9799
Overfitting: 0.0648
[Epoch 7, Batch 100] loss: 0.05378709148848429
[Epoch 7, Batch 200] loss: 0.0474259447818622
[Epoch 7, Batch 300] loss: 0.04955606447998434
[Epoch 7, Batch 400] loss: 0.04949678077828139
[Epoch 7, Batch 500] loss: 0.05433745469083078
[Epoch 7, Batch 600] loss: 0.0647671085759066
[Epoch 7, Batch 700] loss: 0.04931705348542891
[Epoch 7, Batch 800] loss: 0.04128748939256184
[Epoch 7, Batch 900] loss: 0.050634078946895894
[Epoch 7, Batch 1000] loss: 0.063261972614564
[Epoch 7, Batch 1100] loss: 0.04732725979061797
[Epoch 7, Batch 1200] loss: 0.047951097083278
[Epoch 7, Batch 1300] loss: 0.0400109241087921
[Epoch 7, Batch 1400] loss: 0.04841351769049652
[Epoch 7, Batch 1500] loss: 0.05201425169478171
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0623
Validation Accuracy: 0.9818
Overfitting: 0.0623
[Epoch 8, Batch 100] loss: 0.03702294831862673
[Epoch 8, Batch 200] loss: 0.035925991574767974
[Epoch 8, Batch 300] loss: 0.047139636594511106
[Epoch 8, Batch 400] loss: 0.048752359905047345
[Epoch 8, Batch 500] loss: 0.044106993150780906
[Epoch 8, Batch 600] loss: 0.04086219626828097
[Epoch 8, Batch 700] loss: 0.056972542795119804
[Epoch 8, Batch 800] loss: 0.04784465285076294
[Epoch 8, Batch 900] loss: 0.054689185018651186
[Epoch 8, Batch 1000] loss: 0.03975172489183024
[Epoch 8, Batch 1100] loss: 0.04274229744914919
[Epoch 8, Batch 1200] loss: 0.03851953746634536
[Epoch 8, Batch 1300] loss: 0.03830266336910427
[Epoch 8, Batch 1400] loss: 0.04142244201619178
[Epoch 8, Batch 1500] loss: 0.05455898419488221
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0749
Validation Accuracy: 0.9765
Overfitting: 0.0749
[Epoch 9, Batch 100] loss: 0.0419703389715869
[Epoch 9, Batch 200] loss: 0.033865009539294985
[Epoch 9, Batch 300] loss: 0.03200054668588564
[Epoch 9, Batch 400] loss: 0.042001553250593134
[Epoch 9, Batch 500] loss: 0.041424333576869685
[Epoch 9, Batch 600] loss: 0.03408925679454114
[Epoch 9, Batch 700] loss: 0.04004837248357944
[Epoch 9, Batch 800] loss: 0.04309686507214792
[Epoch 9, Batch 900] loss: 0.03906040105852299
[Epoch 9, Batch 1000] loss: 0.032681881943135524
[Epoch 9, Batch 1100] loss: 0.044336600214010105
[Epoch 9, Batch 1200] loss: 0.04658025456825271
[Epoch 9, Batch 1300] loss: 0.04397454299381934
[Epoch 9, Batch 1400] loss: 0.04297324719300377
[Epoch 9, Batch 1500] loss: 0.04263024514424615
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9834
Overfitting: 0.0533
Best model saved at epoch 9 with validation loss: 0.0533
[Epoch 10, Batch 100] loss: 0.03940396627294831
[Epoch 10, Batch 200] loss: 0.035985116551164535
[Epoch 10, Batch 300] loss: 0.0386858403601218
[Epoch 10, Batch 400] loss: 0.037353973082499575
[Epoch 10, Batch 500] loss: 0.0273235058109276
[Epoch 10, Batch 600] loss: 0.0249437702546129
[Epoch 10, Batch 700] loss: 0.03131861076632049
[Epoch 10, Batch 800] loss: 0.038993983426480555
[Epoch 10, Batch 900] loss: 0.04675171876384411
[Epoch 10, Batch 1000] loss: 0.03512637297972106
[Epoch 10, Batch 1100] loss: 0.04511395330540836
[Epoch 10, Batch 1200] loss: 0.032669808891951105
[Epoch 10, Batch 1300] loss: 0.030173471724847332
[Epoch 10, Batch 1400] loss: 0.03186760965909343
[Epoch 10, Batch 1500] loss: 0.02686810118990252
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9831
Overfitting: 0.0524
[Epoch 11, Batch 100] loss: 0.02695372185204178
[Epoch 11, Batch 200] loss: 0.03296608920762083
[Epoch 11, Batch 300] loss: 0.034044152100104835
[Epoch 11, Batch 400] loss: 0.028101800447329878
[Epoch 11, Batch 500] loss: 0.03200659875757992
[Epoch 11, Batch 600] loss: 0.029298820384137798
[Epoch 11, Batch 700] loss: 0.026600931206921814
[Epoch 11, Batch 800] loss: 0.043441962640499696
[Epoch 11, Batch 900] loss: 0.03242744537885301
[Epoch 11, Batch 1000] loss: 0.029583927736384793
[Epoch 11, Batch 1100] loss: 0.028778540858766063
[Epoch 11, Batch 1200] loss: 0.03314954220841173
[Epoch 11, Batch 1300] loss: 0.025015817708917892
[Epoch 11, Batch 1400] loss: 0.028038450931198895
[Epoch 11, Batch 1500] loss: 0.034233821292582435
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0526
Validation Accuracy: 0.9848
Overfitting: 0.0526
Early stopping epoch 11 for trial 14. Moving to next fold.
Fold 4 validation loss: 0.0526
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.284681239128113
[Epoch 1, Batch 200] loss: 2.2057456040382384
[Epoch 1, Batch 300] loss: 1.708034405708313
[Epoch 1, Batch 400] loss: 0.7201635640859604
[Epoch 1, Batch 500] loss: 0.47056980699300766
[Epoch 1, Batch 600] loss: 0.4029109698534012
[Epoch 1, Batch 700] loss: 0.350467332303524
[Epoch 1, Batch 800] loss: 0.3469438189268112
[Epoch 1, Batch 900] loss: 0.30120214477181434
[Epoch 1, Batch 1000] loss: 0.26790176928043363
[Epoch 1, Batch 1100] loss: 0.24861451350152491
[Epoch 1, Batch 1200] loss: 0.21729071266949176
[Epoch 1, Batch 1300] loss: 0.22891465524211527
[Epoch 1, Batch 1400] loss: 0.19117903541773557
[Epoch 1, Batch 1500] loss: 0.17413885340094568
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2088
Validation Accuracy: 0.9377
Overfitting: 0.2088
[Epoch 2, Batch 100] loss: 0.21015378028154375
[Epoch 2, Batch 200] loss: 0.13726372197270392
[Epoch 2, Batch 300] loss: 0.17477446842938663
[Epoch 2, Batch 400] loss: 0.15519707660190762
[Epoch 2, Batch 500] loss: 0.14131776632741094
[Epoch 2, Batch 600] loss: 0.14368303609080613
[Epoch 2, Batch 700] loss: 0.1382347743026912
[Epoch 2, Batch 800] loss: 0.14076265254989268
[Epoch 2, Batch 900] loss: 0.13477094841189682
[Epoch 2, Batch 1000] loss: 0.13836813841946424
[Epoch 2, Batch 1100] loss: 0.1425137802772224
[Epoch 2, Batch 1200] loss: 0.13556248687207698
[Epoch 2, Batch 1300] loss: 0.10963262558914721
[Epoch 2, Batch 1400] loss: 0.12243135950528085
[Epoch 2, Batch 1500] loss: 0.10634260017424822
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1197
Validation Accuracy: 0.9627
Overfitting: 0.1197
[Epoch 3, Batch 100] loss: 0.09339437715243548
[Epoch 3, Batch 200] loss: 0.08672723167575896
[Epoch 3, Batch 300] loss: 0.10910818933974951
[Epoch 3, Batch 400] loss: 0.10533447285182775
[Epoch 3, Batch 500] loss: 0.10773784061893821
[Epoch 3, Batch 600] loss: 0.10763963562902062
[Epoch 3, Batch 700] loss: 0.08904964994639158
[Epoch 3, Batch 800] loss: 0.10396386891137809
[Epoch 3, Batch 900] loss: 0.09751750563737005
[Epoch 3, Batch 1000] loss: 0.09626070127822459
[Epoch 3, Batch 1100] loss: 0.08731404106598348
[Epoch 3, Batch 1200] loss: 0.0828249146277085
[Epoch 3, Batch 1300] loss: 0.08727789377328009
[Epoch 3, Batch 1400] loss: 0.09372527097817511
[Epoch 3, Batch 1500] loss: 0.08027133606374263
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0794
Validation Accuracy: 0.9750
Overfitting: 0.0794
[Epoch 4, Batch 100] loss: 0.0907853006478399
[Epoch 4, Batch 200] loss: 0.0809975407156162
[Epoch 4, Batch 300] loss: 0.07722971470560878
[Epoch 4, Batch 400] loss: 0.07513151159277186
[Epoch 4, Batch 500] loss: 0.07015705700498075
[Epoch 4, Batch 600] loss: 0.07115107393823564
[Epoch 4, Batch 700] loss: 0.07217334571992978
[Epoch 4, Batch 800] loss: 0.07569034323561936
[Epoch 4, Batch 900] loss: 0.07996224327129312
[Epoch 4, Batch 1000] loss: 0.08115746084949933
[Epoch 4, Batch 1100] loss: 0.056032226842362434
[Epoch 4, Batch 1200] loss: 0.07901306194253266
[Epoch 4, Batch 1300] loss: 0.08295616284478456
[Epoch 4, Batch 1400] loss: 0.06715637176297605
[Epoch 4, Batch 1500] loss: 0.062007021809695285
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0652
Validation Accuracy: 0.9808
Overfitting: 0.0652
[Epoch 5, Batch 100] loss: 0.07126769615337253
[Epoch 5, Batch 200] loss: 0.06322076698997989
[Epoch 5, Batch 300] loss: 0.04996577105484903
[Epoch 5, Batch 400] loss: 0.0668420041166246
[Epoch 5, Batch 500] loss: 0.06094966057687998
[Epoch 5, Batch 600] loss: 0.06610335820994806
[Epoch 5, Batch 700] loss: 0.06672524826135487
[Epoch 5, Batch 800] loss: 0.058426142244134095
[Epoch 5, Batch 900] loss: 0.05596068887040019
[Epoch 5, Batch 1000] loss: 0.04568135988898575
[Epoch 5, Batch 1100] loss: 0.058647555467905475
[Epoch 5, Batch 1200] loss: 0.06413388137123548
[Epoch 5, Batch 1300] loss: 0.07901448005519342
[Epoch 5, Batch 1400] loss: 0.06367232327815145
[Epoch 5, Batch 1500] loss: 0.05516759029123932
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0631
Validation Accuracy: 0.9809
Overfitting: 0.0631
[Epoch 6, Batch 100] loss: 0.05505778636550531
[Epoch 6, Batch 200] loss: 0.058549967342987654
[Epoch 6, Batch 300] loss: 0.0642121704656165
[Epoch 6, Batch 400] loss: 0.04955434296280146
[Epoch 6, Batch 500] loss: 0.04326996182324365
[Epoch 6, Batch 600] loss: 0.053230386304203424
[Epoch 6, Batch 700] loss: 0.04411452306434512
[Epoch 6, Batch 800] loss: 0.05474875524174422
[Epoch 6, Batch 900] loss: 0.056395013898145406
[Epoch 6, Batch 1000] loss: 0.05313978000485804
[Epoch 6, Batch 1100] loss: 0.05732706504524685
[Epoch 6, Batch 1200] loss: 0.04355764016276226
[Epoch 6, Batch 1300] loss: 0.04656636567786336
[Epoch 6, Batch 1400] loss: 0.05942956559709273
[Epoch 6, Batch 1500] loss: 0.07017268432420679
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0556
Validation Accuracy: 0.9840
Overfitting: 0.0556
[Epoch 7, Batch 100] loss: 0.050433346767676995
[Epoch 7, Batch 200] loss: 0.04497025601798668
[Epoch 7, Batch 300] loss: 0.04228612049599178
[Epoch 7, Batch 400] loss: 0.062004413563990966
[Epoch 7, Batch 500] loss: 0.05014562014606781
[Epoch 7, Batch 600] loss: 0.031673574178712444
[Epoch 7, Batch 700] loss: 0.04922505186812486
[Epoch 7, Batch 800] loss: 0.05129604992631357
[Epoch 7, Batch 900] loss: 0.04361180364037864
[Epoch 7, Batch 1000] loss: 0.04570172032748815
[Epoch 7, Batch 1100] loss: 0.04172756104089785
[Epoch 7, Batch 1200] loss: 0.03796507385093719
[Epoch 7, Batch 1300] loss: 0.04699996158480644
[Epoch 7, Batch 1400] loss: 0.04105458396719769
[Epoch 7, Batch 1500] loss: 0.05624872568412684
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0692
Validation Accuracy: 0.9773
Overfitting: 0.0692
[Epoch 8, Batch 100] loss: 0.03831078667077236
[Epoch 8, Batch 200] loss: 0.034846052075736225
[Epoch 8, Batch 300] loss: 0.03402754921000451
[Epoch 8, Batch 400] loss: 0.0442540825236938
[Epoch 8, Batch 500] loss: 0.039341590114636345
[Epoch 8, Batch 600] loss: 0.04678615326993167
[Epoch 8, Batch 700] loss: 0.040613231135066596
[Epoch 8, Batch 800] loss: 0.04949401984747965
[Epoch 8, Batch 900] loss: 0.03785641107300762
[Epoch 8, Batch 1000] loss: 0.04773968373949174
[Epoch 8, Batch 1100] loss: 0.034488572094414846
[Epoch 8, Batch 1200] loss: 0.04855509514571168
[Epoch 8, Batch 1300] loss: 0.043578202512580905
[Epoch 8, Batch 1400] loss: 0.040874061892391185
[Epoch 8, Batch 1500] loss: 0.04013996379246237
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0478
Validation Accuracy: 0.9847
Overfitting: 0.0478
[Epoch 9, Batch 100] loss: 0.03522932869673241
[Epoch 9, Batch 200] loss: 0.03369205027178396
[Epoch 9, Batch 300] loss: 0.0334006893762853
[Epoch 9, Batch 400] loss: 0.03385890962381381
[Epoch 9, Batch 500] loss: 0.04902254794142209
[Epoch 9, Batch 600] loss: 0.02896110811503604
[Epoch 9, Batch 700] loss: 0.037726343078538775
[Epoch 9, Batch 800] loss: 0.03693815335514955
[Epoch 9, Batch 900] loss: 0.04389564364566468
[Epoch 9, Batch 1000] loss: 0.03525873758015223
[Epoch 9, Batch 1100] loss: 0.033631178836221805
[Epoch 9, Batch 1200] loss: 0.029128330071398523
[Epoch 9, Batch 1300] loss: 0.04168690526334103
[Epoch 9, Batch 1400] loss: 0.036721969683712816
[Epoch 9, Batch 1500] loss: 0.03429935981577728
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0451
Validation Accuracy: 0.9857
Overfitting: 0.0451
Best model saved at epoch 9 with validation loss: 0.0451
[Epoch 10, Batch 100] loss: 0.029778277185978367
[Epoch 10, Batch 200] loss: 0.03042910151707474
[Epoch 10, Batch 300] loss: 0.029212975836126132
[Epoch 10, Batch 400] loss: 0.02802794065501075
[Epoch 10, Batch 500] loss: 0.045166975678876044
[Epoch 10, Batch 600] loss: 0.0235869354539318
[Epoch 10, Batch 700] loss: 0.032891663080081346
[Epoch 10, Batch 800] loss: 0.04325484281231184
[Epoch 10, Batch 900] loss: 0.02873323851614259
[Epoch 10, Batch 1000] loss: 0.041038887776667254
[Epoch 10, Batch 1100] loss: 0.02764720787992701
[Epoch 10, Batch 1200] loss: 0.02826467017439427
[Epoch 10, Batch 1300] loss: 0.038007829972193576
[Epoch 10, Batch 1400] loss: 0.03562200332904467
[Epoch 10, Batch 1500] loss: 0.037888665683567524
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0456
Validation Accuracy: 0.9864
Overfitting: 0.0456
[Epoch 11, Batch 100] loss: 0.022747849402658175
[Epoch 11, Batch 200] loss: 0.03479370908695273
[Epoch 11, Batch 300] loss: 0.028294575533363966
[Epoch 11, Batch 400] loss: 0.02970382329360291
[Epoch 11, Batch 500] loss: 0.03160393487312831
[Epoch 11, Batch 600] loss: 0.02600920964672696
[Epoch 11, Batch 700] loss: 0.033892558824154546
[Epoch 11, Batch 800] loss: 0.024381369330512825
[Epoch 11, Batch 900] loss: 0.024939821898879017
[Epoch 11, Batch 1000] loss: 0.032985224090734844
[Epoch 11, Batch 1100] loss: 0.027068052572140004
[Epoch 11, Batch 1200] loss: 0.036422313806542664
[Epoch 11, Batch 1300] loss: 0.029232926039549058
[Epoch 11, Batch 1400] loss: 0.036124196951277554
[Epoch 11, Batch 1500] loss: 0.025451473059656563
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0419
Validation Accuracy: 0.9869
Overfitting: 0.0419
Early stopping epoch 11 for trial 14. Moving to next fold.
Fold 5 validation loss: 0.0419
Mean validation loss across all folds for Trial 14 is 0.0504 with trial config:  l1: 256, l2: 128, lr: 0.001, batch_size: 32
[I 2024-12-10 06:09:25,861] Trial 13 finished with value: 0.05044026027128566 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 32}. Best is trial 12 with value: 0.0492618556785242.

Selected Hyperparameters for Trial 15:
  l1: 128, l2: 128, lr: 0.001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.30008868932724
[Epoch 1, Batch 200] loss: 2.2762317776679994
[Epoch 1, Batch 300] loss: 2.228552026748657
[Epoch 1, Batch 400] loss: 2.01776260137558
[Epoch 1, Batch 500] loss: 1.0873325300216674
[Epoch 1, Batch 600] loss: 0.5808889991044999
[Epoch 1, Batch 700] loss: 0.4683566002547741
[Epoch 1, Batch 800] loss: 0.38865163289010524
[Epoch 1, Batch 900] loss: 0.35018681041896343
[Epoch 1, Batch 1000] loss: 0.3296613682806492
[Epoch 1, Batch 1100] loss: 0.2931873627752066
[Epoch 1, Batch 1200] loss: 0.2772882179170847
[Epoch 1, Batch 1300] loss: 0.24926041930913925
[Epoch 1, Batch 1400] loss: 0.24680351372808218
[Epoch 1, Batch 1500] loss: 0.23400871332734824
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1778
Validation Accuracy: 0.9473
Overfitting: 0.1778
[Epoch 2, Batch 100] loss: 0.19452129006385804
[Epoch 2, Batch 200] loss: 0.18412771498784422
[Epoch 2, Batch 300] loss: 0.17678159803152085
[Epoch 2, Batch 400] loss: 0.1744488137960434
[Epoch 2, Batch 500] loss: 0.1729991691559553
[Epoch 2, Batch 600] loss: 0.16535922184586524
[Epoch 2, Batch 700] loss: 0.15288819659501315
[Epoch 2, Batch 800] loss: 0.14885804344899953
[Epoch 2, Batch 900] loss: 0.14014948665164412
[Epoch 2, Batch 1000] loss: 0.12577467469498516
[Epoch 2, Batch 1100] loss: 0.14273281970992685
[Epoch 2, Batch 1200] loss: 0.13040258765220641
[Epoch 2, Batch 1300] loss: 0.13318351791240274
[Epoch 2, Batch 1400] loss: 0.12028248261660338
[Epoch 2, Batch 1500] loss: 0.12333976969122887
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1057
Validation Accuracy: 0.9661
Overfitting: 0.1057
[Epoch 3, Batch 100] loss: 0.11311391736380756
[Epoch 3, Batch 200] loss: 0.09874162314459682
[Epoch 3, Batch 300] loss: 0.10601000894792378
[Epoch 3, Batch 400] loss: 0.10263971370179206
[Epoch 3, Batch 500] loss: 0.11693876410834492
[Epoch 3, Batch 600] loss: 0.1055726547492668
[Epoch 3, Batch 700] loss: 0.1257299727294594
[Epoch 3, Batch 800] loss: 0.09568857693579048
[Epoch 3, Batch 900] loss: 0.09325299303978682
[Epoch 3, Batch 1000] loss: 0.10958722205832601
[Epoch 3, Batch 1100] loss: 0.09955698674544693
[Epoch 3, Batch 1200] loss: 0.09806639481335878
[Epoch 3, Batch 1300] loss: 0.07623793046921491
[Epoch 3, Batch 1400] loss: 0.0940821404894814
[Epoch 3, Batch 1500] loss: 0.10300494671799243
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0821
Validation Accuracy: 0.9740
Overfitting: 0.0821
[Epoch 4, Batch 100] loss: 0.09042919432744384
[Epoch 4, Batch 200] loss: 0.08051661245059222
[Epoch 4, Batch 300] loss: 0.08344272674061358
[Epoch 4, Batch 400] loss: 0.07600171305704861
[Epoch 4, Batch 500] loss: 0.0825059044547379
[Epoch 4, Batch 600] loss: 0.07775018181768246
[Epoch 4, Batch 700] loss: 0.09845691576134413
[Epoch 4, Batch 800] loss: 0.07490105007542297
[Epoch 4, Batch 900] loss: 0.07420305506559088
[Epoch 4, Batch 1000] loss: 0.08966698558069766
[Epoch 4, Batch 1100] loss: 0.0837632869835943
[Epoch 4, Batch 1200] loss: 0.07133955756668002
[Epoch 4, Batch 1300] loss: 0.0821204258943908
[Epoch 4, Batch 1400] loss: 0.08427790485788136
[Epoch 4, Batch 1500] loss: 0.07366765082813799
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0661
Validation Accuracy: 0.9788
Overfitting: 0.0661
[Epoch 5, Batch 100] loss: 0.08171045416267589
[Epoch 5, Batch 200] loss: 0.06879590798635035
[Epoch 5, Batch 300] loss: 0.06037470600800589
[Epoch 5, Batch 400] loss: 0.07150455545866861
[Epoch 5, Batch 500] loss: 0.06861835532821715
[Epoch 5, Batch 600] loss: 0.0627500276803039
[Epoch 5, Batch 700] loss: 0.05759492486482486
[Epoch 5, Batch 800] loss: 0.0720932849496603
[Epoch 5, Batch 900] loss: 0.07522398930275813
[Epoch 5, Batch 1000] loss: 0.06798293757950886
[Epoch 5, Batch 1100] loss: 0.051804198725149034
[Epoch 5, Batch 1200] loss: 0.07112158704316243
[Epoch 5, Batch 1300] loss: 0.07452115647960454
[Epoch 5, Batch 1400] loss: 0.06290878107538447
[Epoch 5, Batch 1500] loss: 0.06851141638355329
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0741
Validation Accuracy: 0.9772
Overfitting: 0.0741
[Epoch 6, Batch 100] loss: 0.054187561641447245
[Epoch 6, Batch 200] loss: 0.06481595001416281
[Epoch 6, Batch 300] loss: 0.05267652051523328
[Epoch 6, Batch 400] loss: 0.05535252899629995
[Epoch 6, Batch 500] loss: 0.07040709997527302
[Epoch 6, Batch 600] loss: 0.06469085900112986
[Epoch 6, Batch 700] loss: 0.0622666211950127
[Epoch 6, Batch 800] loss: 0.06871615189709701
[Epoch 6, Batch 900] loss: 0.056099400706589225
[Epoch 6, Batch 1000] loss: 0.051736938250251115
[Epoch 6, Batch 1100] loss: 0.046388613763265314
[Epoch 6, Batch 1200] loss: 0.05552644284674898
[Epoch 6, Batch 1300] loss: 0.04657183108967729
[Epoch 6, Batch 1400] loss: 0.048808454426471144
[Epoch 6, Batch 1500] loss: 0.061509115715743974
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0582
Validation Accuracy: 0.9820
Overfitting: 0.0582
[Epoch 7, Batch 100] loss: 0.04771371161565185
[Epoch 7, Batch 200] loss: 0.04925587716512382
[Epoch 7, Batch 300] loss: 0.04348228325601667
[Epoch 7, Batch 400] loss: 0.037574046716326845
[Epoch 7, Batch 500] loss: 0.051495122471824285
[Epoch 7, Batch 600] loss: 0.04627385736210272
[Epoch 7, Batch 700] loss: 0.06388174159335903
[Epoch 7, Batch 800] loss: 0.04311073220334947
[Epoch 7, Batch 900] loss: 0.053399367808597165
[Epoch 7, Batch 1000] loss: 0.05355890631559305
[Epoch 7, Batch 1100] loss: 0.04473665236262605
[Epoch 7, Batch 1200] loss: 0.04573194123688154
[Epoch 7, Batch 1300] loss: 0.049073494175681846
[Epoch 7, Batch 1400] loss: 0.05285275599220768
[Epoch 7, Batch 1500] loss: 0.05870520995231345
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9821
Overfitting: 0.0549
[Epoch 8, Batch 100] loss: 0.03893998525338247
[Epoch 8, Batch 200] loss: 0.048715668705408464
[Epoch 8, Batch 300] loss: 0.03883002929156646
[Epoch 8, Batch 400] loss: 0.03929517696145922
[Epoch 8, Batch 500] loss: 0.04201079714926891
[Epoch 8, Batch 600] loss: 0.03735227015800774
[Epoch 8, Batch 700] loss: 0.043103283308446406
[Epoch 8, Batch 800] loss: 0.040425421558320525
[Epoch 8, Batch 900] loss: 0.04747491404064931
[Epoch 8, Batch 1000] loss: 0.04800463344785385
[Epoch 8, Batch 1100] loss: 0.04475568792637205
[Epoch 8, Batch 1200] loss: 0.03602865466207732
[Epoch 8, Batch 1300] loss: 0.05119427087483928
[Epoch 8, Batch 1400] loss: 0.04032008252746891
[Epoch 8, Batch 1500] loss: 0.05661358334240504
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9840
Overfitting: 0.0536
[Epoch 9, Batch 100] loss: 0.041971929875435306
[Epoch 9, Batch 200] loss: 0.03778784411028027
[Epoch 9, Batch 300] loss: 0.03192180301353801
[Epoch 9, Batch 400] loss: 0.0428138836286962
[Epoch 9, Batch 500] loss: 0.05930886705871671
[Epoch 9, Batch 600] loss: 0.03897855840972625
[Epoch 9, Batch 700] loss: 0.035345171489170754
[Epoch 9, Batch 800] loss: 0.0386481874610763
[Epoch 9, Batch 900] loss: 0.035465472016949204
[Epoch 9, Batch 1000] loss: 0.05175116369500756
[Epoch 9, Batch 1100] loss: 0.03825571384339128
[Epoch 9, Batch 1200] loss: 0.02510471458430402
[Epoch 9, Batch 1300] loss: 0.037965526507177855
[Epoch 9, Batch 1400] loss: 0.04306089353252901
[Epoch 9, Batch 1500] loss: 0.03289347498677671
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9844
Overfitting: 0.0493
Best model saved at epoch 9 with validation loss: 0.0493
[Epoch 10, Batch 100] loss: 0.02959288172889501
[Epoch 10, Batch 200] loss: 0.026847034417442045
[Epoch 10, Batch 300] loss: 0.02875221000344027
[Epoch 10, Batch 400] loss: 0.039983453182503584
[Epoch 10, Batch 500] loss: 0.03827140075620264
[Epoch 10, Batch 600] loss: 0.048805158105678856
[Epoch 10, Batch 700] loss: 0.03767533622216433
[Epoch 10, Batch 800] loss: 0.04065658251114655
[Epoch 10, Batch 900] loss: 0.038937532788550014
[Epoch 10, Batch 1000] loss: 0.027685950785817114
[Epoch 10, Batch 1100] loss: 0.03212445050565293
[Epoch 10, Batch 1200] loss: 0.03534957420430146
[Epoch 10, Batch 1300] loss: 0.03190942408313276
[Epoch 10, Batch 1400] loss: 0.030551949724467703
[Epoch 10, Batch 1500] loss: 0.03834250400774181
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0461
Validation Accuracy: 0.9862
Overfitting: 0.0461
[Epoch 11, Batch 100] loss: 0.03180802919610869
[Epoch 11, Batch 200] loss: 0.035718596530496145
[Epoch 11, Batch 300] loss: 0.03729897732497193
[Epoch 11, Batch 400] loss: 0.03034223589784233
[Epoch 11, Batch 500] loss: 0.03511416575376643
[Epoch 11, Batch 600] loss: 0.03642206869844813
[Epoch 11, Batch 700] loss: 0.030560682878131046
[Epoch 11, Batch 800] loss: 0.029940204713493585
[Epoch 11, Batch 900] loss: 0.0325229990776279
[Epoch 11, Batch 1000] loss: 0.03717477136815432
[Epoch 11, Batch 1100] loss: 0.02606205655640224
[Epoch 11, Batch 1200] loss: 0.035021542935865
[Epoch 11, Batch 1300] loss: 0.033517158564645794
[Epoch 11, Batch 1400] loss: 0.03023860913235694
[Epoch 11, Batch 1500] loss: 0.038095768032362684
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0519
Validation Accuracy: 0.9845
Overfitting: 0.0519
Early stopping epoch 11 for trial 15. Moving to next fold.
Fold 1 validation loss: 0.0519
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2982001900672913
[Epoch 1, Batch 200] loss: 2.2768859457969666
[Epoch 1, Batch 300] loss: 2.219143671989441
[Epoch 1, Batch 400] loss: 1.8116889011859894
[Epoch 1, Batch 500] loss: 0.7941871827840805
[Epoch 1, Batch 600] loss: 0.5548897278308869
[Epoch 1, Batch 700] loss: 0.47207212790846825
[Epoch 1, Batch 800] loss: 0.42382041171193124
[Epoch 1, Batch 900] loss: 0.3560876533389091
[Epoch 1, Batch 1000] loss: 0.34297351993620395
[Epoch 1, Batch 1100] loss: 0.2868474581837654
[Epoch 1, Batch 1200] loss: 0.253586006835103
[Epoch 1, Batch 1300] loss: 0.2465991911664605
[Epoch 1, Batch 1400] loss: 0.24454613976180553
[Epoch 1, Batch 1500] loss: 0.2354656373336911
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2398
Validation Accuracy: 0.9277
Overfitting: 0.2398
[Epoch 2, Batch 100] loss: 0.20946304835379123
[Epoch 2, Batch 200] loss: 0.18530830852687358
[Epoch 2, Batch 300] loss: 0.19720666438341142
[Epoch 2, Batch 400] loss: 0.18496719831600786
[Epoch 2, Batch 500] loss: 0.15683022199198604
[Epoch 2, Batch 600] loss: 0.15742347247898578
[Epoch 2, Batch 700] loss: 0.14970158165320754
[Epoch 2, Batch 800] loss: 0.14802983548492193
[Epoch 2, Batch 900] loss: 0.14171671506017447
[Epoch 2, Batch 1000] loss: 0.14215966256335377
[Epoch 2, Batch 1100] loss: 0.1346401109173894
[Epoch 2, Batch 1200] loss: 0.1524718615692109
[Epoch 2, Batch 1300] loss: 0.11963784133084118
[Epoch 2, Batch 1400] loss: 0.13197843787260355
[Epoch 2, Batch 1500] loss: 0.12715310038998723
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1322
Validation Accuracy: 0.9610
Overfitting: 0.1322
[Epoch 3, Batch 100] loss: 0.10578606313094496
[Epoch 3, Batch 200] loss: 0.11133087871596217
[Epoch 3, Batch 300] loss: 0.12288515791296958
[Epoch 3, Batch 400] loss: 0.10482829339802265
[Epoch 3, Batch 500] loss: 0.09975441643968225
[Epoch 3, Batch 600] loss: 0.11527495704591274
[Epoch 3, Batch 700] loss: 0.09799042074475438
[Epoch 3, Batch 800] loss: 0.104205914135091
[Epoch 3, Batch 900] loss: 0.10222613792866468
[Epoch 3, Batch 1000] loss: 0.09165210019797086
[Epoch 3, Batch 1100] loss: 0.09681564108002931
[Epoch 3, Batch 1200] loss: 0.08698469090508297
[Epoch 3, Batch 1300] loss: 0.10642892933916301
[Epoch 3, Batch 1400] loss: 0.11193741986993701
[Epoch 3, Batch 1500] loss: 0.11015960762277245
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1080
Validation Accuracy: 0.9673
Overfitting: 0.1080
[Epoch 4, Batch 100] loss: 0.07987430471926928
[Epoch 4, Batch 200] loss: 0.0892863859469071
[Epoch 4, Batch 300] loss: 0.11126833468675613
[Epoch 4, Batch 400] loss: 0.09477302238345146
[Epoch 4, Batch 500] loss: 0.08372015814762562
[Epoch 4, Batch 600] loss: 0.07968372392933816
[Epoch 4, Batch 700] loss: 0.08083035234361886
[Epoch 4, Batch 800] loss: 0.07529822551645339
[Epoch 4, Batch 900] loss: 0.07834311479935423
[Epoch 4, Batch 1000] loss: 0.07746060285018758
[Epoch 4, Batch 1100] loss: 0.09186597264138982
[Epoch 4, Batch 1200] loss: 0.08057631834410131
[Epoch 4, Batch 1300] loss: 0.08481807460775599
[Epoch 4, Batch 1400] loss: 0.08342467452166602
[Epoch 4, Batch 1500] loss: 0.07680292899254709
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0901
Validation Accuracy: 0.9721
Overfitting: 0.0901
[Epoch 5, Batch 100] loss: 0.08506771764252335
[Epoch 5, Batch 200] loss: 0.0640183851099573
[Epoch 5, Batch 300] loss: 0.07430560264270752
[Epoch 5, Batch 400] loss: 0.08068283939734101
[Epoch 5, Batch 500] loss: 0.06988080236827955
[Epoch 5, Batch 600] loss: 0.058411538425134496
[Epoch 5, Batch 700] loss: 0.06141677469946444
[Epoch 5, Batch 800] loss: 0.06866524879704229
[Epoch 5, Batch 900] loss: 0.07410121273249387
[Epoch 5, Batch 1000] loss: 0.07690320005873218
[Epoch 5, Batch 1100] loss: 0.08037855882896111
[Epoch 5, Batch 1200] loss: 0.06771558045526035
[Epoch 5, Batch 1300] loss: 0.061346389558166264
[Epoch 5, Batch 1400] loss: 0.07587280245264992
[Epoch 5, Batch 1500] loss: 0.07164886025711895
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0780
Validation Accuracy: 0.9768
Overfitting: 0.0780
[Epoch 6, Batch 100] loss: 0.060291130607947704
[Epoch 6, Batch 200] loss: 0.0705372811248526
[Epoch 6, Batch 300] loss: 0.0526302396832034
[Epoch 6, Batch 400] loss: 0.04843961974140257
[Epoch 6, Batch 500] loss: 0.06836346723837777
[Epoch 6, Batch 600] loss: 0.05942181897698902
[Epoch 6, Batch 700] loss: 0.07212042857892811
[Epoch 6, Batch 800] loss: 0.0685274112469051
[Epoch 6, Batch 900] loss: 0.06732728285016493
[Epoch 6, Batch 1000] loss: 0.055310746310278776
[Epoch 6, Batch 1100] loss: 0.06131469476502389
[Epoch 6, Batch 1200] loss: 0.06755314987618476
[Epoch 6, Batch 1300] loss: 0.05853678881656379
[Epoch 6, Batch 1400] loss: 0.04948351833503693
[Epoch 6, Batch 1500] loss: 0.06274498433223925
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0778
Validation Accuracy: 0.9764
Overfitting: 0.0778
[Epoch 7, Batch 100] loss: 0.05534892010968179
[Epoch 7, Batch 200] loss: 0.04788184260949493
[Epoch 7, Batch 300] loss: 0.05970759136718698
[Epoch 7, Batch 400] loss: 0.0526748944283463
[Epoch 7, Batch 500] loss: 0.06036837386433035
[Epoch 7, Batch 600] loss: 0.05434240120230242
[Epoch 7, Batch 700] loss: 0.05369118502247147
[Epoch 7, Batch 800] loss: 0.057199216663138944
[Epoch 7, Batch 900] loss: 0.05455317479732912
[Epoch 7, Batch 1000] loss: 0.05314236511243507
[Epoch 7, Batch 1100] loss: 0.043178070487920196
[Epoch 7, Batch 1200] loss: 0.059647497740807014
[Epoch 7, Batch 1300] loss: 0.04975292900402564
[Epoch 7, Batch 1400] loss: 0.049293581288075074
[Epoch 7, Batch 1500] loss: 0.06452449816511945
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0743
Validation Accuracy: 0.9788
Overfitting: 0.0743
[Epoch 8, Batch 100] loss: 0.04426015252713114
[Epoch 8, Batch 200] loss: 0.04418008014326915
[Epoch 8, Batch 300] loss: 0.052151419885340146
[Epoch 8, Batch 400] loss: 0.056524620272684845
[Epoch 8, Batch 500] loss: 0.042645166608854194
[Epoch 8, Batch 600] loss: 0.06701329400762916
[Epoch 8, Batch 700] loss: 0.0517100382904755
[Epoch 8, Batch 800] loss: 0.05574981145211495
[Epoch 8, Batch 900] loss: 0.037912992428755385
[Epoch 8, Batch 1000] loss: 0.03277583824412431
[Epoch 8, Batch 1100] loss: 0.05374009098741226
[Epoch 8, Batch 1200] loss: 0.060962204454699534
[Epoch 8, Batch 1300] loss: 0.04351286846213043
[Epoch 8, Batch 1400] loss: 0.04674930770357605
[Epoch 8, Batch 1500] loss: 0.03786407398874871
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0692
Validation Accuracy: 0.9793
Overfitting: 0.0692
[Epoch 9, Batch 100] loss: 0.05229215807281434
[Epoch 9, Batch 200] loss: 0.04772590368578676
[Epoch 9, Batch 300] loss: 0.04589888535090722
[Epoch 9, Batch 400] loss: 0.04153913675807416
[Epoch 9, Batch 500] loss: 0.029913116066018118
[Epoch 9, Batch 600] loss: 0.04644407818181207
[Epoch 9, Batch 700] loss: 0.04602528047631495
[Epoch 9, Batch 800] loss: 0.0448002260515932
[Epoch 9, Batch 900] loss: 0.045894451349158774
[Epoch 9, Batch 1000] loss: 0.04839328303001821
[Epoch 9, Batch 1100] loss: 0.04731948247615946
[Epoch 9, Batch 1200] loss: 0.052505828305147585
[Epoch 9, Batch 1300] loss: 0.0403986125002848
[Epoch 9, Batch 1400] loss: 0.03388557490892708
[Epoch 9, Batch 1500] loss: 0.0393668382865144
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0670
Validation Accuracy: 0.9802
Overfitting: 0.0670
Best model saved at epoch 9 with validation loss: 0.0670
[Epoch 10, Batch 100] loss: 0.03601445446664002
[Epoch 10, Batch 200] loss: 0.04580426644533873
[Epoch 10, Batch 300] loss: 0.03752038820530288
[Epoch 10, Batch 400] loss: 0.03269812601560261
[Epoch 10, Batch 500] loss: 0.0452495297009591
[Epoch 10, Batch 600] loss: 0.04338817871263018
[Epoch 10, Batch 700] loss: 0.046959408286493275
[Epoch 10, Batch 800] loss: 0.03626416800456354
[Epoch 10, Batch 900] loss: 0.03576939852326177
[Epoch 10, Batch 1000] loss: 0.039461929175886326
[Epoch 10, Batch 1100] loss: 0.03582457362266723
[Epoch 10, Batch 1200] loss: 0.0355632361973403
[Epoch 10, Batch 1300] loss: 0.041758582835900594
[Epoch 10, Batch 1400] loss: 0.04137243383971509
[Epoch 10, Batch 1500] loss: 0.03834398505045101
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0681
Validation Accuracy: 0.9795
Overfitting: 0.0681
[Epoch 11, Batch 100] loss: 0.027099289572215638
[Epoch 11, Batch 200] loss: 0.03382944649260025
[Epoch 11, Batch 300] loss: 0.044018901134550106
[Epoch 11, Batch 400] loss: 0.03212469644975499
[Epoch 11, Batch 500] loss: 0.026834145730244927
[Epoch 11, Batch 600] loss: 0.04021388145105448
[Epoch 11, Batch 700] loss: 0.04443237946514273
[Epoch 11, Batch 800] loss: 0.04276961272465996
[Epoch 11, Batch 900] loss: 0.04689522010390647
[Epoch 11, Batch 1000] loss: 0.02549289440008579
[Epoch 11, Batch 1100] loss: 0.03312975629698485
[Epoch 11, Batch 1200] loss: 0.03143735318531981
[Epoch 11, Batch 1300] loss: 0.03458842819090933
[Epoch 11, Batch 1400] loss: 0.04090432999102631
[Epoch 11, Batch 1500] loss: 0.03840226187836379
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0626
Validation Accuracy: 0.9823
Overfitting: 0.0626
Early stopping epoch 11 for trial 15. Moving to next fold.
Fold 2 validation loss: 0.0626
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2960190033912657
[Epoch 1, Batch 200] loss: 2.267525873184204
[Epoch 1, Batch 300] loss: 2.192301290035248
[Epoch 1, Batch 400] loss: 1.7032001423835754
[Epoch 1, Batch 500] loss: 0.7858002829551697
[Epoch 1, Batch 600] loss: 0.5616996353864669
[Epoch 1, Batch 700] loss: 0.46515782684087753
[Epoch 1, Batch 800] loss: 0.3866487988829613
[Epoch 1, Batch 900] loss: 0.3185161398351192
[Epoch 1, Batch 1000] loss: 0.29078897587955
[Epoch 1, Batch 1100] loss: 0.3036483146250248
[Epoch 1, Batch 1200] loss: 0.2974403178319335
[Epoch 1, Batch 1300] loss: 0.24609924253076315
[Epoch 1, Batch 1400] loss: 0.23024305868893863
[Epoch 1, Batch 1500] loss: 0.2165860115736723
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2293
Validation Accuracy: 0.9312
Overfitting: 0.2293
[Epoch 2, Batch 100] loss: 0.19673064310103655
[Epoch 2, Batch 200] loss: 0.19298988454043864
[Epoch 2, Batch 300] loss: 0.1888257459551096
[Epoch 2, Batch 400] loss: 0.17380241522565484
[Epoch 2, Batch 500] loss: 0.16493384968489408
[Epoch 2, Batch 600] loss: 0.15966648461297153
[Epoch 2, Batch 700] loss: 0.15085786812007426
[Epoch 2, Batch 800] loss: 0.13863067215308547
[Epoch 2, Batch 900] loss: 0.12538286675699056
[Epoch 2, Batch 1000] loss: 0.12404229160398245
[Epoch 2, Batch 1100] loss: 0.14160010224208236
[Epoch 2, Batch 1200] loss: 0.1233997739572078
[Epoch 2, Batch 1300] loss: 0.14934156065806747
[Epoch 2, Batch 1400] loss: 0.11567972952499986
[Epoch 2, Batch 1500] loss: 0.10845801196061075
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1182
Validation Accuracy: 0.9636
Overfitting: 0.1182
[Epoch 3, Batch 100] loss: 0.10661952059250325
[Epoch 3, Batch 200] loss: 0.09862795173190535
[Epoch 3, Batch 300] loss: 0.1149871009029448
[Epoch 3, Batch 400] loss: 0.11233686433173716
[Epoch 3, Batch 500] loss: 0.11355862635187805
[Epoch 3, Batch 600] loss: 0.09465818334836512
[Epoch 3, Batch 700] loss: 0.10086448080837726
[Epoch 3, Batch 800] loss: 0.10267227204982192
[Epoch 3, Batch 900] loss: 0.09639208030886948
[Epoch 3, Batch 1000] loss: 0.08880940940231084
[Epoch 3, Batch 1100] loss: 0.08151518173050136
[Epoch 3, Batch 1200] loss: 0.08651910866610706
[Epoch 3, Batch 1300] loss: 0.09555286685004831
[Epoch 3, Batch 1400] loss: 0.09075144837610423
[Epoch 3, Batch 1500] loss: 0.10016672390513122
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0993
Validation Accuracy: 0.9702
Overfitting: 0.0993
[Epoch 4, Batch 100] loss: 0.07836709949187934
[Epoch 4, Batch 200] loss: 0.07927766516106204
[Epoch 4, Batch 300] loss: 0.08534853096818551
[Epoch 4, Batch 400] loss: 0.08391496480908245
[Epoch 4, Batch 500] loss: 0.07679364322219044
[Epoch 4, Batch 600] loss: 0.09040545913390816
[Epoch 4, Batch 700] loss: 0.077721127953846
[Epoch 4, Batch 800] loss: 0.07530606319895014
[Epoch 4, Batch 900] loss: 0.07650301537010819
[Epoch 4, Batch 1000] loss: 0.06346283900085836
[Epoch 4, Batch 1100] loss: 0.06501583861652761
[Epoch 4, Batch 1200] loss: 0.07366438067285344
[Epoch 4, Batch 1300] loss: 0.07377274822443723
[Epoch 4, Batch 1400] loss: 0.06818331049755216
[Epoch 4, Batch 1500] loss: 0.0762771041598171
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0707
Validation Accuracy: 0.9788
Overfitting: 0.0707
[Epoch 5, Batch 100] loss: 0.05983167215483263
[Epoch 5, Batch 200] loss: 0.06987110556801782
[Epoch 5, Batch 300] loss: 0.056005240133963526
[Epoch 5, Batch 400] loss: 0.07184295209124685
[Epoch 5, Batch 500] loss: 0.061774518894962965
[Epoch 5, Batch 600] loss: 0.06380602359655313
[Epoch 5, Batch 700] loss: 0.04993744312552735
[Epoch 5, Batch 800] loss: 0.06715317087480799
[Epoch 5, Batch 900] loss: 0.07075371028739028
[Epoch 5, Batch 1000] loss: 0.063595873771701
[Epoch 5, Batch 1100] loss: 0.06976278170244768
[Epoch 5, Batch 1200] loss: 0.06272143569076434
[Epoch 5, Batch 1300] loss: 0.05579451231984422
[Epoch 5, Batch 1400] loss: 0.059656962249428035
[Epoch 5, Batch 1500] loss: 0.06193535046419129
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0757
Validation Accuracy: 0.9778
Overfitting: 0.0757
[Epoch 6, Batch 100] loss: 0.05859666207688861
[Epoch 6, Batch 200] loss: 0.05046665250789374
[Epoch 6, Batch 300] loss: 0.05807433391571976
[Epoch 6, Batch 400] loss: 0.052954571694135665
[Epoch 6, Batch 500] loss: 0.06532359750475734
[Epoch 6, Batch 600] loss: 0.05248483733041212
[Epoch 6, Batch 700] loss: 0.04765166141907685
[Epoch 6, Batch 800] loss: 0.053020682872738686
[Epoch 6, Batch 900] loss: 0.042621428646380084
[Epoch 6, Batch 1000] loss: 0.05026511798379943
[Epoch 6, Batch 1100] loss: 0.06040528010809794
[Epoch 6, Batch 1200] loss: 0.04828596738399938
[Epoch 6, Batch 1300] loss: 0.042989814431639385
[Epoch 6, Batch 1400] loss: 0.05964803071634378
[Epoch 6, Batch 1500] loss: 0.057151081184856595
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0622
Validation Accuracy: 0.9807
Overfitting: 0.0622
[Epoch 7, Batch 100] loss: 0.04052595819346607
[Epoch 7, Batch 200] loss: 0.04832904164562933
[Epoch 7, Batch 300] loss: 0.05367731986334547
[Epoch 7, Batch 400] loss: 0.036112989156972614
[Epoch 7, Batch 500] loss: 0.04966686277301051
[Epoch 7, Batch 600] loss: 0.046843947594752536
[Epoch 7, Batch 700] loss: 0.054324050486902704
[Epoch 7, Batch 800] loss: 0.04992751284502447
[Epoch 7, Batch 900] loss: 0.03575503881205805
[Epoch 7, Batch 1000] loss: 0.05083445137250237
[Epoch 7, Batch 1100] loss: 0.04996441492636222
[Epoch 7, Batch 1200] loss: 0.046645425813039765
[Epoch 7, Batch 1300] loss: 0.05511490895645693
[Epoch 7, Batch 1400] loss: 0.053114496688358485
[Epoch 7, Batch 1500] loss: 0.04622197462711483
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0597
Validation Accuracy: 0.9831
Overfitting: 0.0597
[Epoch 8, Batch 100] loss: 0.03842965477728285
[Epoch 8, Batch 200] loss: 0.0411532628594432
[Epoch 8, Batch 300] loss: 0.036561730495886874
[Epoch 8, Batch 400] loss: 0.04727928269770928
[Epoch 8, Batch 500] loss: 0.034966759207309225
[Epoch 8, Batch 600] loss: 0.04270601838827133
[Epoch 8, Batch 700] loss: 0.04885811619111337
[Epoch 8, Batch 800] loss: 0.04661586401809473
[Epoch 8, Batch 900] loss: 0.046156607864541004
[Epoch 8, Batch 1000] loss: 0.045383012712700295
[Epoch 8, Batch 1100] loss: 0.03440423765394371
[Epoch 8, Batch 1200] loss: 0.042445128771942106
[Epoch 8, Batch 1300] loss: 0.042818984478944916
[Epoch 8, Batch 1400] loss: 0.03354141351708677
[Epoch 8, Batch 1500] loss: 0.04088884370983578
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9844
Overfitting: 0.0527
[Epoch 9, Batch 100] loss: 0.030806850675144232
[Epoch 9, Batch 200] loss: 0.04312192474026233
[Epoch 9, Batch 300] loss: 0.033361165262176654
[Epoch 9, Batch 400] loss: 0.03658209826797247
[Epoch 9, Batch 500] loss: 0.03430814553255914
[Epoch 9, Batch 600] loss: 0.044046825148398056
[Epoch 9, Batch 700] loss: 0.03552236370742321
[Epoch 9, Batch 800] loss: 0.04534365664672805
[Epoch 9, Batch 900] loss: 0.033926430830033494
[Epoch 9, Batch 1000] loss: 0.041933111437247136
[Epoch 9, Batch 1100] loss: 0.04156363477697596
[Epoch 9, Batch 1200] loss: 0.03653455934021622
[Epoch 9, Batch 1300] loss: 0.030545324787963183
[Epoch 9, Batch 1400] loss: 0.03179859786905581
[Epoch 9, Batch 1500] loss: 0.04377752115484327
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0530
Validation Accuracy: 0.9831
Overfitting: 0.0530
Best model saved at epoch 9 with validation loss: 0.0530
[Epoch 10, Batch 100] loss: 0.03794822427909821
[Epoch 10, Batch 200] loss: 0.03549792010046076
[Epoch 10, Batch 300] loss: 0.03142982197517995
[Epoch 10, Batch 400] loss: 0.03414997420768486
[Epoch 10, Batch 500] loss: 0.032501484643726146
[Epoch 10, Batch 600] loss: 0.0330173898715293
[Epoch 10, Batch 700] loss: 0.034624973454047
[Epoch 10, Batch 800] loss: 0.03228697491053026
[Epoch 10, Batch 900] loss: 0.02964326230925508
[Epoch 10, Batch 1000] loss: 0.04026808987488039
[Epoch 10, Batch 1100] loss: 0.03758704233448953
[Epoch 10, Batch 1200] loss: 0.0338123251995421
[Epoch 10, Batch 1300] loss: 0.027614099096972496
[Epoch 10, Batch 1400] loss: 0.03127216709137429
[Epoch 10, Batch 1500] loss: 0.035094929617480376
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0516
Validation Accuracy: 0.9846
Overfitting: 0.0516
[Epoch 11, Batch 100] loss: 0.02308183139481116
[Epoch 11, Batch 200] loss: 0.035710479149711316
[Epoch 11, Batch 300] loss: 0.024018398888292724
[Epoch 11, Batch 400] loss: 0.03915550356032327
[Epoch 11, Batch 500] loss: 0.031967199706996324
[Epoch 11, Batch 600] loss: 0.033487806179618926
[Epoch 11, Batch 700] loss: 0.028671565464755987
[Epoch 11, Batch 800] loss: 0.037870603085320906
[Epoch 11, Batch 900] loss: 0.02285477103665471
[Epoch 11, Batch 1000] loss: 0.036325637475310944
[Epoch 11, Batch 1100] loss: 0.03248552059754729
[Epoch 11, Batch 1200] loss: 0.025907207975396886
[Epoch 11, Batch 1300] loss: 0.03041190945368726
[Epoch 11, Batch 1400] loss: 0.02616423629631754
[Epoch 11, Batch 1500] loss: 0.026348374613007763
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0509
Validation Accuracy: 0.9849
Overfitting: 0.0509
Early stopping epoch 11 for trial 15. Moving to next fold.
Fold 3 validation loss: 0.0509
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.300984778404236
[Epoch 1, Batch 200] loss: 2.2914140105247496
[Epoch 1, Batch 300] loss: 2.270059187412262
[Epoch 1, Batch 400] loss: 2.2038945055007932
[Epoch 1, Batch 500] loss: 1.7824688243865967
[Epoch 1, Batch 600] loss: 0.8390603867173195
[Epoch 1, Batch 700] loss: 0.561400941759348
[Epoch 1, Batch 800] loss: 0.5186219896376133
[Epoch 1, Batch 900] loss: 0.4155262427031994
[Epoch 1, Batch 1000] loss: 0.36147261984646323
[Epoch 1, Batch 1100] loss: 0.3653162609040737
[Epoch 1, Batch 1200] loss: 0.3119535206258297
[Epoch 1, Batch 1300] loss: 0.260885551944375
[Epoch 1, Batch 1400] loss: 0.2771958540380001
[Epoch 1, Batch 1500] loss: 0.2624173620343208
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2330
Validation Accuracy: 0.9272
Overfitting: 0.2330
[Epoch 2, Batch 100] loss: 0.22519540064036847
[Epoch 2, Batch 200] loss: 0.20773934617638587
[Epoch 2, Batch 300] loss: 0.1948493594676256
[Epoch 2, Batch 400] loss: 0.20010361924767495
[Epoch 2, Batch 500] loss: 0.18359670612961054
[Epoch 2, Batch 600] loss: 0.1576118508540094
[Epoch 2, Batch 700] loss: 0.15364040764048695
[Epoch 2, Batch 800] loss: 0.1497745227627456
[Epoch 2, Batch 900] loss: 0.15625563577748836
[Epoch 2, Batch 1000] loss: 0.1365058101899922
[Epoch 2, Batch 1100] loss: 0.15648187277838588
[Epoch 2, Batch 1200] loss: 0.13128897906281053
[Epoch 2, Batch 1300] loss: 0.11601389805786312
[Epoch 2, Batch 1400] loss: 0.13852009100839496
[Epoch 2, Batch 1500] loss: 0.11988735090009868
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1125
Validation Accuracy: 0.9644
Overfitting: 0.1125
[Epoch 3, Batch 100] loss: 0.12681280055083335
[Epoch 3, Batch 200] loss: 0.12114341210573912
[Epoch 3, Batch 300] loss: 0.12272719515487551
[Epoch 3, Batch 400] loss: 0.11319816617295146
[Epoch 3, Batch 500] loss: 0.09190865394193679
[Epoch 3, Batch 600] loss: 0.10362540455535055
[Epoch 3, Batch 700] loss: 0.1017145533952862
[Epoch 3, Batch 800] loss: 0.10108177714515477
[Epoch 3, Batch 900] loss: 0.10370776414638386
[Epoch 3, Batch 1000] loss: 0.08816347773652523
[Epoch 3, Batch 1100] loss: 0.10207325891591608
[Epoch 3, Batch 1200] loss: 0.11296085919253528
[Epoch 3, Batch 1300] loss: 0.09025213262997568
[Epoch 3, Batch 1400] loss: 0.08861035167705268
[Epoch 3, Batch 1500] loss: 0.09213756216224284
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0845
Validation Accuracy: 0.9726
Overfitting: 0.0845
[Epoch 4, Batch 100] loss: 0.09730767232831568
[Epoch 4, Batch 200] loss: 0.08711297030095011
[Epoch 4, Batch 300] loss: 0.09015711175976321
[Epoch 4, Batch 400] loss: 0.0666224334994331
[Epoch 4, Batch 500] loss: 0.08451354866381734
[Epoch 4, Batch 600] loss: 0.08303145885467529
[Epoch 4, Batch 700] loss: 0.08094963710056619
[Epoch 4, Batch 800] loss: 0.0732146932836622
[Epoch 4, Batch 900] loss: 0.07289279516786337
[Epoch 4, Batch 1000] loss: 0.07597631422337145
[Epoch 4, Batch 1100] loss: 0.0723313040100038
[Epoch 4, Batch 1200] loss: 0.07809142430662178
[Epoch 4, Batch 1300] loss: 0.0733543268381618
[Epoch 4, Batch 1400] loss: 0.08882611528038979
[Epoch 4, Batch 1500] loss: 0.06935267959255725
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0751
Validation Accuracy: 0.9770
Overfitting: 0.0751
[Epoch 5, Batch 100] loss: 0.0740598876401782
[Epoch 5, Batch 200] loss: 0.07205064053181559
[Epoch 5, Batch 300] loss: 0.07290552719729021
[Epoch 5, Batch 400] loss: 0.062094478617655116
[Epoch 5, Batch 500] loss: 0.0698968671541661
[Epoch 5, Batch 600] loss: 0.061722442060709
[Epoch 5, Batch 700] loss: 0.0719072009343654
[Epoch 5, Batch 800] loss: 0.05207896186504513
[Epoch 5, Batch 900] loss: 0.06571498214732856
[Epoch 5, Batch 1000] loss: 0.07999825018458068
[Epoch 5, Batch 1100] loss: 0.05931632503401488
[Epoch 5, Batch 1200] loss: 0.06435048746177927
[Epoch 5, Batch 1300] loss: 0.061162198996171355
[Epoch 5, Batch 1400] loss: 0.06910634218715131
[Epoch 5, Batch 1500] loss: 0.06655249229399487
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0640
Validation Accuracy: 0.9798
Overfitting: 0.0640
[Epoch 6, Batch 100] loss: 0.05249758176971227
[Epoch 6, Batch 200] loss: 0.0643306230334565
[Epoch 6, Batch 300] loss: 0.04541895028552972
[Epoch 6, Batch 400] loss: 0.04561444069258869
[Epoch 6, Batch 500] loss: 0.055239602869842204
[Epoch 6, Batch 600] loss: 0.05883082788903266
[Epoch 6, Batch 700] loss: 0.061903319626580924
[Epoch 6, Batch 800] loss: 0.0671384642017074
[Epoch 6, Batch 900] loss: 0.05557772691594437
[Epoch 6, Batch 1000] loss: 0.07162888143677265
[Epoch 6, Batch 1100] loss: 0.05886020741192624
[Epoch 6, Batch 1200] loss: 0.060971648576669396
[Epoch 6, Batch 1300] loss: 0.05439259672537446
[Epoch 6, Batch 1400] loss: 0.06530699186841957
[Epoch 6, Batch 1500] loss: 0.05524945719400421
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0705
Validation Accuracy: 0.9780
Overfitting: 0.0705
[Epoch 7, Batch 100] loss: 0.046874167811474764
[Epoch 7, Batch 200] loss: 0.056505884209182115
[Epoch 7, Batch 300] loss: 0.06275651055388153
[Epoch 7, Batch 400] loss: 0.0490648295218125
[Epoch 7, Batch 500] loss: 0.04997246394166723
[Epoch 7, Batch 600] loss: 0.0527676467364654
[Epoch 7, Batch 700] loss: 0.04433952371473424
[Epoch 7, Batch 800] loss: 0.0470964961219579
[Epoch 7, Batch 900] loss: 0.06014103469904512
[Epoch 7, Batch 1000] loss: 0.046276201102300546
[Epoch 7, Batch 1100] loss: 0.05342329599196091
[Epoch 7, Batch 1200] loss: 0.04810662382049486
[Epoch 7, Batch 1300] loss: 0.04852250745636411
[Epoch 7, Batch 1400] loss: 0.04399067110265605
[Epoch 7, Batch 1500] loss: 0.052676033520838245
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0651
Validation Accuracy: 0.9804
Overfitting: 0.0651
[Epoch 8, Batch 100] loss: 0.04441390700172633
[Epoch 8, Batch 200] loss: 0.0382683842361439
[Epoch 8, Batch 300] loss: 0.05048792250570841
[Epoch 8, Batch 400] loss: 0.0444200224764063
[Epoch 8, Batch 500] loss: 0.040984621952811724
[Epoch 8, Batch 600] loss: 0.04070601675135549
[Epoch 8, Batch 700] loss: 0.05508948981645517
[Epoch 8, Batch 800] loss: 0.03937418287794572
[Epoch 8, Batch 900] loss: 0.04992656633257866
[Epoch 8, Batch 1000] loss: 0.04840509548434056
[Epoch 8, Batch 1100] loss: 0.039017746323952454
[Epoch 8, Batch 1200] loss: 0.040821085323113945
[Epoch 8, Batch 1300] loss: 0.04775174872018397
[Epoch 8, Batch 1400] loss: 0.046841962848557156
[Epoch 8, Batch 1500] loss: 0.04331232803640887
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0541
Validation Accuracy: 0.9840
Overfitting: 0.0541
[Epoch 9, Batch 100] loss: 0.03230221973033622
[Epoch 9, Batch 200] loss: 0.045704550353111696
[Epoch 9, Batch 300] loss: 0.038787174050230536
[Epoch 9, Batch 400] loss: 0.038174562873318794
[Epoch 9, Batch 500] loss: 0.0311048046866199
[Epoch 9, Batch 600] loss: 0.04106602227315306
[Epoch 9, Batch 700] loss: 0.03976988443158916
[Epoch 9, Batch 800] loss: 0.030798518700757994
[Epoch 9, Batch 900] loss: 0.05465093996375799
[Epoch 9, Batch 1000] loss: 0.03806099045206793
[Epoch 9, Batch 1100] loss: 0.04221707220363896
[Epoch 9, Batch 1200] loss: 0.04214917943521868
[Epoch 9, Batch 1300] loss: 0.03768155572819523
[Epoch 9, Batch 1400] loss: 0.03748672951827757
[Epoch 9, Batch 1500] loss: 0.04093934718461242
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0532
Validation Accuracy: 0.9841
Overfitting: 0.0532
Best model saved at epoch 9 with validation loss: 0.0532
[Epoch 10, Batch 100] loss: 0.040670951328938824
[Epoch 10, Batch 200] loss: 0.03185795679630246
[Epoch 10, Batch 300] loss: 0.028959229114698247
[Epoch 10, Batch 400] loss: 0.01989173770765774
[Epoch 10, Batch 500] loss: 0.03535990443851915
[Epoch 10, Batch 600] loss: 0.039638114210683854
[Epoch 10, Batch 700] loss: 0.03922101489733905
[Epoch 10, Batch 800] loss: 0.041719345260062254
[Epoch 10, Batch 900] loss: 0.029333891536225565
[Epoch 10, Batch 1000] loss: 0.038687358771276194
[Epoch 10, Batch 1100] loss: 0.04499773049494252
[Epoch 10, Batch 1200] loss: 0.04160000062081963
[Epoch 10, Batch 1300] loss: 0.035610677731456236
[Epoch 10, Batch 1400] loss: 0.031274379106471316
[Epoch 10, Batch 1500] loss: 0.03931268299696967
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9861
Overfitting: 0.0465
[Epoch 11, Batch 100] loss: 0.02521658431796823
[Epoch 11, Batch 200] loss: 0.03133940333704231
[Epoch 11, Batch 300] loss: 0.03329418359906413
[Epoch 11, Batch 400] loss: 0.03531811557593755
[Epoch 11, Batch 500] loss: 0.030284059399273245
[Epoch 11, Batch 600] loss: 0.02717895588168176
[Epoch 11, Batch 700] loss: 0.02617688537662616
[Epoch 11, Batch 800] loss: 0.023148327476956183
[Epoch 11, Batch 900] loss: 0.02880752394790761
[Epoch 11, Batch 1000] loss: 0.02281217272291542
[Epoch 11, Batch 1100] loss: 0.04079989996098447
[Epoch 11, Batch 1200] loss: 0.04421776904957369
[Epoch 11, Batch 1300] loss: 0.040485750967054625
[Epoch 11, Batch 1400] loss: 0.03963049567537382
[Epoch 11, Batch 1500] loss: 0.03929989561787806
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9833
Overfitting: 0.0538
Early stopping epoch 11 for trial 15. Moving to next fold.
Fold 4 validation loss: 0.0538
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2856471276283266
[Epoch 1, Batch 200] loss: 2.2157403731346133
[Epoch 1, Batch 300] loss: 1.7673444902896882
[Epoch 1, Batch 400] loss: 0.8035769110918045
[Epoch 1, Batch 500] loss: 0.5591181924939156
[Epoch 1, Batch 600] loss: 0.4643540668487549
[Epoch 1, Batch 700] loss: 0.40057652547955513
[Epoch 1, Batch 800] loss: 0.3394323541224003
[Epoch 1, Batch 900] loss: 0.30789593487977984
[Epoch 1, Batch 1000] loss: 0.28323026333004236
[Epoch 1, Batch 1100] loss: 0.241041277423501
[Epoch 1, Batch 1200] loss: 0.23264938864856957
[Epoch 1, Batch 1300] loss: 0.19958015821874142
[Epoch 1, Batch 1400] loss: 0.21073372907936572
[Epoch 1, Batch 1500] loss: 0.18870577109977604
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2034
Validation Accuracy: 0.9414
Overfitting: 0.2034
[Epoch 2, Batch 100] loss: 0.17427287148311735
[Epoch 2, Batch 200] loss: 0.16792627453804015
[Epoch 2, Batch 300] loss: 0.14378769803792238
[Epoch 2, Batch 400] loss: 0.16078117568045855
[Epoch 2, Batch 500] loss: 0.1748402624949813
[Epoch 2, Batch 600] loss: 0.1351607156544924
[Epoch 2, Batch 700] loss: 0.1432006291858852
[Epoch 2, Batch 800] loss: 0.14981751572340726
[Epoch 2, Batch 900] loss: 0.1205556687247008
[Epoch 2, Batch 1000] loss: 0.1439269568491727
[Epoch 2, Batch 1100] loss: 0.10913461576215923
[Epoch 2, Batch 1200] loss: 0.12541393733583392
[Epoch 2, Batch 1300] loss: 0.11316557073034346
[Epoch 2, Batch 1400] loss: 0.11405631331726909
[Epoch 2, Batch 1500] loss: 0.11631724191829562
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1320
Validation Accuracy: 0.9593
Overfitting: 0.1320
[Epoch 3, Batch 100] loss: 0.11197633008472621
[Epoch 3, Batch 200] loss: 0.09742131287232042
[Epoch 3, Batch 300] loss: 0.09381494799628853
[Epoch 3, Batch 400] loss: 0.11286613952368497
[Epoch 3, Batch 500] loss: 0.10059434530325234
[Epoch 3, Batch 600] loss: 0.10973752188961954
[Epoch 3, Batch 700] loss: 0.0790245286282152
[Epoch 3, Batch 800] loss: 0.09694751377217471
[Epoch 3, Batch 900] loss: 0.08403133565559984
[Epoch 3, Batch 1000] loss: 0.09558217876590788
[Epoch 3, Batch 1100] loss: 0.08441121298354119
[Epoch 3, Batch 1200] loss: 0.08835890131536871
[Epoch 3, Batch 1300] loss: 0.10418070312356577
[Epoch 3, Batch 1400] loss: 0.08804678914602845
[Epoch 3, Batch 1500] loss: 0.0818147899582982
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1092
Validation Accuracy: 0.9683
Overfitting: 0.1092
[Epoch 4, Batch 100] loss: 0.08693656174931676
[Epoch 4, Batch 200] loss: 0.0736183072743006
[Epoch 4, Batch 300] loss: 0.0719491339661181
[Epoch 4, Batch 400] loss: 0.08393417880637571
[Epoch 4, Batch 500] loss: 0.072286280519329
[Epoch 4, Batch 600] loss: 0.08118443790823221
[Epoch 4, Batch 700] loss: 0.0911675935285166
[Epoch 4, Batch 800] loss: 0.07892907935660333
[Epoch 4, Batch 900] loss: 0.07231466558761895
[Epoch 4, Batch 1000] loss: 0.06972486880142242
[Epoch 4, Batch 1100] loss: 0.07548661984736099
[Epoch 4, Batch 1200] loss: 0.07492676158202811
[Epoch 4, Batch 1300] loss: 0.0720271587278694
[Epoch 4, Batch 1400] loss: 0.06569299505092203
[Epoch 4, Batch 1500] loss: 0.06509621135075577
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0745
Validation Accuracy: 0.9780
Overfitting: 0.0745
[Epoch 5, Batch 100] loss: 0.07285107448231429
[Epoch 5, Batch 200] loss: 0.06923550763865932
[Epoch 5, Batch 300] loss: 0.07127768915612251
[Epoch 5, Batch 400] loss: 0.05568114068359137
[Epoch 5, Batch 500] loss: 0.05735088448389433
[Epoch 5, Batch 600] loss: 0.06531202274374664
[Epoch 5, Batch 700] loss: 0.054786685917060825
[Epoch 5, Batch 800] loss: 0.06654086603433824
[Epoch 5, Batch 900] loss: 0.07989483139943332
[Epoch 5, Batch 1000] loss: 0.0577606692945119
[Epoch 5, Batch 1100] loss: 0.0648497063817922
[Epoch 5, Batch 1200] loss: 0.06192099992185831
[Epoch 5, Batch 1300] loss: 0.06268066624586936
[Epoch 5, Batch 1400] loss: 0.06432257048494648
[Epoch 5, Batch 1500] loss: 0.05639632425038144
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0697
Validation Accuracy: 0.9800
Overfitting: 0.0697
[Epoch 6, Batch 100] loss: 0.0472549445705954
[Epoch 6, Batch 200] loss: 0.054646881939843295
[Epoch 6, Batch 300] loss: 0.06203731245012022
[Epoch 6, Batch 400] loss: 0.061352033272851256
[Epoch 6, Batch 500] loss: 0.05065027717500925
[Epoch 6, Batch 600] loss: 0.06981289061484858
[Epoch 6, Batch 700] loss: 0.06380339647177607
[Epoch 6, Batch 800] loss: 0.04197478868882172
[Epoch 6, Batch 900] loss: 0.05108723322453443
[Epoch 6, Batch 1000] loss: 0.05180030582356267
[Epoch 6, Batch 1100] loss: 0.05573970499681309
[Epoch 6, Batch 1200] loss: 0.0546329504204914
[Epoch 6, Batch 1300] loss: 0.06223935637040995
[Epoch 6, Batch 1400] loss: 0.054138090424239636
[Epoch 6, Batch 1500] loss: 0.054642175305634734
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0717
Validation Accuracy: 0.9781
Overfitting: 0.0717
[Epoch 7, Batch 100] loss: 0.058429281073622406
[Epoch 7, Batch 200] loss: 0.050578984890598803
[Epoch 7, Batch 300] loss: 0.05394125226419419
[Epoch 7, Batch 400] loss: 0.050818766767624764
[Epoch 7, Batch 500] loss: 0.06140529340831563
[Epoch 7, Batch 600] loss: 0.05043668647180311
[Epoch 7, Batch 700] loss: 0.04851408858783543
[Epoch 7, Batch 800] loss: 0.04731720396259334
[Epoch 7, Batch 900] loss: 0.0584205172106158
[Epoch 7, Batch 1000] loss: 0.053711695545352996
[Epoch 7, Batch 1100] loss: 0.04672098935116083
[Epoch 7, Batch 1200] loss: 0.03818308446207084
[Epoch 7, Batch 1300] loss: 0.04806732697295956
[Epoch 7, Batch 1400] loss: 0.050713771631126295
[Epoch 7, Batch 1500] loss: 0.0427906420850195
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0618
Validation Accuracy: 0.9814
Overfitting: 0.0618
[Epoch 8, Batch 100] loss: 0.04023329236311838
[Epoch 8, Batch 200] loss: 0.04694947955780662
[Epoch 8, Batch 300] loss: 0.04130561513127759
[Epoch 8, Batch 400] loss: 0.04823649768368341
[Epoch 8, Batch 500] loss: 0.04428802940412425
[Epoch 8, Batch 600] loss: 0.049455804001772775
[Epoch 8, Batch 700] loss: 0.043156621596426706
[Epoch 8, Batch 800] loss: 0.052110500130802394
[Epoch 8, Batch 900] loss: 0.04699374971911311
[Epoch 8, Batch 1000] loss: 0.03390299999096896
[Epoch 8, Batch 1100] loss: 0.048033321959665046
[Epoch 8, Batch 1200] loss: 0.0403400095627876
[Epoch 8, Batch 1300] loss: 0.04166640791983809
[Epoch 8, Batch 1400] loss: 0.04456554899807088
[Epoch 8, Batch 1500] loss: 0.039936391446972266
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0585
Validation Accuracy: 0.9830
Overfitting: 0.0585
[Epoch 9, Batch 100] loss: 0.04778351828455925
[Epoch 9, Batch 200] loss: 0.03753257962875068
[Epoch 9, Batch 300] loss: 0.04940933009493165
[Epoch 9, Batch 400] loss: 0.04207167616696097
[Epoch 9, Batch 500] loss: 0.0340307438565651
[Epoch 9, Batch 600] loss: 0.04210238649626263
[Epoch 9, Batch 700] loss: 0.03608724839286879
[Epoch 9, Batch 800] loss: 0.041602571392431856
[Epoch 9, Batch 900] loss: 0.0386516586819198
[Epoch 9, Batch 1000] loss: 0.03690511242602952
[Epoch 9, Batch 1100] loss: 0.041791176131227986
[Epoch 9, Batch 1200] loss: 0.03425122572589316
[Epoch 9, Batch 1300] loss: 0.042137411579024044
[Epoch 9, Batch 1400] loss: 0.03558246835367754
[Epoch 9, Batch 1500] loss: 0.04354414550005458
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0527
Validation Accuracy: 0.9845
Overfitting: 0.0527
Best model saved at epoch 9 with validation loss: 0.0527
[Epoch 10, Batch 100] loss: 0.039746259459061545
[Epoch 10, Batch 200] loss: 0.03658921512018423
[Epoch 10, Batch 300] loss: 0.034952885293751026
[Epoch 10, Batch 400] loss: 0.04109999685548246
[Epoch 10, Batch 500] loss: 0.03880403061222751
[Epoch 10, Batch 600] loss: 0.03464802197820973
[Epoch 10, Batch 700] loss: 0.03156470047484618
[Epoch 10, Batch 800] loss: 0.03419069815136026
[Epoch 10, Batch 900] loss: 0.03964600500883535
[Epoch 10, Batch 1000] loss: 0.029728727489709852
[Epoch 10, Batch 1100] loss: 0.03740651816071477
[Epoch 10, Batch 1200] loss: 0.03331133371335454
[Epoch 10, Batch 1300] loss: 0.03791476987535134
[Epoch 10, Batch 1400] loss: 0.035605703244509644
[Epoch 10, Batch 1500] loss: 0.03739561964728637
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0555
Validation Accuracy: 0.9835
Overfitting: 0.0555
[Epoch 11, Batch 100] loss: 0.03280263580847532
[Epoch 11, Batch 200] loss: 0.03117350126907695
[Epoch 11, Batch 300] loss: 0.028684649377391905
[Epoch 11, Batch 400] loss: 0.03234208203619346
[Epoch 11, Batch 500] loss: 0.022284938819357194
[Epoch 11, Batch 600] loss: 0.03638749393634498
[Epoch 11, Batch 700] loss: 0.030318860951811074
[Epoch 11, Batch 800] loss: 0.0325089022872271
[Epoch 11, Batch 900] loss: 0.03364733799040551
[Epoch 11, Batch 1000] loss: 0.03846305783023127
[Epoch 11, Batch 1100] loss: 0.03612691769376397
[Epoch 11, Batch 1200] loss: 0.03526394609361887
[Epoch 11, Batch 1300] loss: 0.03329444852191955
[Epoch 11, Batch 1400] loss: 0.039695238159038124
[Epoch 11, Batch 1500] loss: 0.0357702092040563
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0477
Validation Accuracy: 0.9862
Overfitting: 0.0477
Early stopping epoch 11 for trial 15. Moving to next fold.
Fold 5 validation loss: 0.0477
Mean validation loss across all folds for Trial 15 is 0.0534 with trial config:  l1: 128, l2: 128, lr: 0.001, batch_size: 32
[I 2024-12-10 06:20:13,251] Trial 14 finished with value: 0.053357440952979965 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.001, 'batch_size': 32}. Best is trial 12 with value: 0.0492618556785242.

Selected Hyperparameters for Trial 16:
  l1: 256, l2: 128, lr: 0.001, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2875270080566406
[Epoch 1, Batch 200] loss: 2.233733854293823
[Epoch 1, Batch 300] loss: 1.95218541264534
[Epoch 1, Batch 400] loss: 0.910349945127964
[Epoch 1, Batch 500] loss: 0.48255740106105804
[Epoch 1, Batch 600] loss: 0.43747830733656884
[Epoch 1, Batch 700] loss: 0.3468474507331848
**STATS for Epoch 1** : 
Average training loss: 0.0239
Average validation loss: 0.2939
Validation Accuracy: 0.9120
Overfitting: 0.2699
[Epoch 2, Batch 100] loss: 0.3020150004327297
[Epoch 2, Batch 200] loss: 0.25735903061926363
[Epoch 2, Batch 300] loss: 0.2531365268677473
[Epoch 2, Batch 400] loss: 0.2390303323417902
[Epoch 2, Batch 500] loss: 0.2131924878805876
[Epoch 2, Batch 600] loss: 0.20326799303293228
[Epoch 2, Batch 700] loss: 0.19320220038294791
**STATS for Epoch 2** : 
Average training loss: 0.0116
Average validation loss: 0.1682
Validation Accuracy: 0.9491
Overfitting: 0.1566
[Epoch 3, Batch 100] loss: 0.1658330325037241
[Epoch 3, Batch 200] loss: 0.1628270133957267
[Epoch 3, Batch 300] loss: 0.16578875128179787
[Epoch 3, Batch 400] loss: 0.1525439027324319
[Epoch 3, Batch 500] loss: 0.1449966136738658
[Epoch 3, Batch 600] loss: 0.1308288262411952
[Epoch 3, Batch 700] loss: 0.12137252233922481
**STATS for Epoch 3** : 
Average training loss: 0.0091
Average validation loss: 0.1166
Validation Accuracy: 0.9649
Overfitting: 0.1074
[Epoch 4, Batch 100] loss: 0.12478075820952654
[Epoch 4, Batch 200] loss: 0.11639010483399033
[Epoch 4, Batch 300] loss: 0.11654744448140264
[Epoch 4, Batch 400] loss: 0.11132676534354687
[Epoch 4, Batch 500] loss: 0.11579700058326126
[Epoch 4, Batch 600] loss: 0.11048208421096206
[Epoch 4, Batch 700] loss: 0.10880042672157288
**STATS for Epoch 4** : 
Average training loss: 0.0080
Average validation loss: 0.0943
Validation Accuracy: 0.9710
Overfitting: 0.0863
[Epoch 5, Batch 100] loss: 0.10304292088374495
[Epoch 5, Batch 200] loss: 0.10002221781760454
[Epoch 5, Batch 300] loss: 0.09452046983875334
[Epoch 5, Batch 400] loss: 0.09172056429088116
[Epoch 5, Batch 500] loss: 0.10932606115937232
[Epoch 5, Batch 600] loss: 0.09097103991545737
[Epoch 5, Batch 700] loss: 0.07709536076523364
**STATS for Epoch 5** : 
Average training loss: 0.0075
Average validation loss: 0.0767
Validation Accuracy: 0.9741
Overfitting: 0.0693
[Epoch 6, Batch 100] loss: 0.07661357787437736
[Epoch 6, Batch 200] loss: 0.08607750838622451
[Epoch 6, Batch 300] loss: 0.09282360408455133
[Epoch 6, Batch 400] loss: 0.08216698428615928
[Epoch 6, Batch 500] loss: 0.0928695728071034
[Epoch 6, Batch 600] loss: 0.08561724505387247
[Epoch 6, Batch 700] loss: 0.07508924778085202
**STATS for Epoch 6** : 
Average training loss: 0.0047
Average validation loss: 0.0725
Validation Accuracy: 0.9752
Overfitting: 0.0678
[Epoch 7, Batch 100] loss: 0.08168911304324865
[Epoch 7, Batch 200] loss: 0.08112829519435763
[Epoch 7, Batch 300] loss: 0.07150598244741559
[Epoch 7, Batch 400] loss: 0.07686913968995214
[Epoch 7, Batch 500] loss: 0.07083971476182342
[Epoch 7, Batch 600] loss: 0.07898652462288737
[Epoch 7, Batch 700] loss: 0.07137890606187285
**STATS for Epoch 7** : 
Average training loss: 0.0047
Average validation loss: 0.0674
Validation Accuracy: 0.9774
Overfitting: 0.0626
[Epoch 8, Batch 100] loss: 0.07413434258662165
[Epoch 8, Batch 200] loss: 0.07694315603002906
[Epoch 8, Batch 300] loss: 0.05604098851094022
[Epoch 8, Batch 400] loss: 0.06364774808287621
[Epoch 8, Batch 500] loss: 0.07167200594674795
[Epoch 8, Batch 600] loss: 0.05478664296679199
[Epoch 8, Batch 700] loss: 0.0703531092312187
**STATS for Epoch 8** : 
Average training loss: 0.0050
Average validation loss: 0.0767
Validation Accuracy: 0.9753
Overfitting: 0.0717
[Epoch 9, Batch 100] loss: 0.0755870690383017
[Epoch 9, Batch 200] loss: 0.06005328942090273
[Epoch 9, Batch 300] loss: 0.05833661668002606
[Epoch 9, Batch 400] loss: 0.06711073707789182
[Epoch 9, Batch 500] loss: 0.056642019590362906
[Epoch 9, Batch 600] loss: 0.06143222758546472
[Epoch 9, Batch 700] loss: 0.05519300829619169
**STATS for Epoch 9** : 
Average training loss: 0.0040
Average validation loss: 0.0637
Validation Accuracy: 0.9802
Overfitting: 0.0597
Best model saved at epoch 9 with validation loss: 0.0637
[Epoch 10, Batch 100] loss: 0.049575886101229115
[Epoch 10, Batch 200] loss: 0.06835278660990297
[Epoch 10, Batch 300] loss: 0.06024189763236791
[Epoch 10, Batch 400] loss: 0.057410778193734587
[Epoch 10, Batch 500] loss: 0.05340009809937328
[Epoch 10, Batch 600] loss: 0.05660350545775145
[Epoch 10, Batch 700] loss: 0.05656497513875365
**STATS for Epoch 10** : 
Average training loss: 0.0038
Average validation loss: 0.0592
Validation Accuracy: 0.9813
Overfitting: 0.0554
[Epoch 11, Batch 100] loss: 0.05268035674933344
[Epoch 11, Batch 200] loss: 0.05010890450328589
[Epoch 11, Batch 300] loss: 0.05551895809359848
[Epoch 11, Batch 400] loss: 0.056117871743626896
[Epoch 11, Batch 500] loss: 0.05093540637753904
[Epoch 11, Batch 600] loss: 0.04540578543907031
[Epoch 11, Batch 700] loss: 0.053276655266527084
**STATS for Epoch 11** : 
Average training loss: 0.0033
Average validation loss: 0.0592
Validation Accuracy: 0.9819
Overfitting: 0.0558
Early stopping epoch 11 for trial 16. Moving to next fold.
Fold 1 validation loss: 0.0592
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2850093126296995
[Epoch 1, Batch 200] loss: 2.2083399748802184
[Epoch 1, Batch 300] loss: 1.7567900788784028
[Epoch 1, Batch 400] loss: 0.8335084682703018
[Epoch 1, Batch 500] loss: 0.5581413769721985
[Epoch 1, Batch 600] loss: 0.45716470465064046
[Epoch 1, Batch 700] loss: 0.39415972515940667
**STATS for Epoch 1** : 
Average training loss: 0.0228
Average validation loss: 0.3636
Validation Accuracy: 0.8898
Overfitting: 0.3408
[Epoch 2, Batch 100] loss: 0.32865999311208727
[Epoch 2, Batch 200] loss: 0.27173307560384274
[Epoch 2, Batch 300] loss: 0.2651388832181692
[Epoch 2, Batch 400] loss: 0.2714734072238207
[Epoch 2, Batch 500] loss: 0.22728236354887485
[Epoch 2, Batch 600] loss: 0.2306816042214632
[Epoch 2, Batch 700] loss: 0.20421024318784475
**STATS for Epoch 2** : 
Average training loss: 0.0138
Average validation loss: 0.2103
Validation Accuracy: 0.9374
Overfitting: 0.1965
[Epoch 3, Batch 100] loss: 0.18411214150488375
[Epoch 3, Batch 200] loss: 0.18417097780853509
[Epoch 3, Batch 300] loss: 0.1647905500046909
[Epoch 3, Batch 400] loss: 0.1642794531583786
[Epoch 3, Batch 500] loss: 0.16644925678148867
[Epoch 3, Batch 600] loss: 0.150730908960104
[Epoch 3, Batch 700] loss: 0.14283826364204288
**STATS for Epoch 3** : 
Average training loss: 0.0102
Average validation loss: 0.1582
Validation Accuracy: 0.9522
Overfitting: 0.1481
[Epoch 4, Batch 100] loss: 0.12398595321923495
[Epoch 4, Batch 200] loss: 0.14672286506742238
[Epoch 4, Batch 300] loss: 0.13265466637909412
[Epoch 4, Batch 400] loss: 0.12784756362438202
[Epoch 4, Batch 500] loss: 0.12186259953305126
[Epoch 4, Batch 600] loss: 0.12029288805089891
[Epoch 4, Batch 700] loss: 0.11383416433818638
**STATS for Epoch 4** : 
Average training loss: 0.0088
Average validation loss: 0.1327
Validation Accuracy: 0.9601
Overfitting: 0.1239
[Epoch 5, Batch 100] loss: 0.11688858723267913
[Epoch 5, Batch 200] loss: 0.10541334828361869
[Epoch 5, Batch 300] loss: 0.10660560762509703
[Epoch 5, Batch 400] loss: 0.10304036237299442
[Epoch 5, Batch 500] loss: 0.102301237732172
[Epoch 5, Batch 600] loss: 0.09771768639795482
[Epoch 5, Batch 700] loss: 0.09125703934580087
**STATS for Epoch 5** : 
Average training loss: 0.0062
Average validation loss: 0.1133
Validation Accuracy: 0.9665
Overfitting: 0.1070
[Epoch 6, Batch 100] loss: 0.08855650003999471
[Epoch 6, Batch 200] loss: 0.10097414402291179
[Epoch 6, Batch 300] loss: 0.08172776818275451
[Epoch 6, Batch 400] loss: 0.08900613612495363
[Epoch 6, Batch 500] loss: 0.10085782894864678
[Epoch 6, Batch 600] loss: 0.08951894711703062
[Epoch 6, Batch 700] loss: 0.08663023869972676
**STATS for Epoch 6** : 
Average training loss: 0.0043
Average validation loss: 0.0977
Validation Accuracy: 0.9710
Overfitting: 0.0935
[Epoch 7, Batch 100] loss: 0.08640535460785032
[Epoch 7, Batch 200] loss: 0.08185080300085247
[Epoch 7, Batch 300] loss: 0.07770452762022614
[Epoch 7, Batch 400] loss: 0.07309308269061149
[Epoch 7, Batch 500] loss: 0.07679636703804135
[Epoch 7, Batch 600] loss: 0.0714995743241161
[Epoch 7, Batch 700] loss: 0.08199135190807283
**STATS for Epoch 7** : 
Average training loss: 0.0052
Average validation loss: 0.0951
Validation Accuracy: 0.9724
Overfitting: 0.0899
[Epoch 8, Batch 100] loss: 0.07760886558331549
[Epoch 8, Batch 200] loss: 0.07098252578172833
[Epoch 8, Batch 300] loss: 0.06532237116247415
[Epoch 8, Batch 400] loss: 0.08150263989344239
[Epoch 8, Batch 500] loss: 0.06633923035347834
[Epoch 8, Batch 600] loss: 0.062161057414487006
[Epoch 8, Batch 700] loss: 0.07193500010762363
**STATS for Epoch 8** : 
Average training loss: 0.0045
Average validation loss: 0.0879
Validation Accuracy: 0.9740
Overfitting: 0.0834
[Epoch 9, Batch 100] loss: 0.05799652732443064
[Epoch 9, Batch 200] loss: 0.0677466229069978
[Epoch 9, Batch 300] loss: 0.054867490055039526
[Epoch 9, Batch 400] loss: 0.06966153890360147
[Epoch 9, Batch 500] loss: 0.06479242297820748
[Epoch 9, Batch 600] loss: 0.05473808955401182
[Epoch 9, Batch 700] loss: 0.06091262503527105
**STATS for Epoch 9** : 
Average training loss: 0.0046
Average validation loss: 0.0838
Validation Accuracy: 0.9752
Overfitting: 0.0792
Best model saved at epoch 9 with validation loss: 0.0838
[Epoch 10, Batch 100] loss: 0.06073806527070701
[Epoch 10, Batch 200] loss: 0.059630730100907386
[Epoch 10, Batch 300] loss: 0.059648458193987605
[Epoch 10, Batch 400] loss: 0.058851144243963066
[Epoch 10, Batch 500] loss: 0.05346395241795108
[Epoch 10, Batch 600] loss: 0.05785012532491237
[Epoch 10, Batch 700] loss: 0.0589762209309265
**STATS for Epoch 10** : 
Average training loss: 0.0040
Average validation loss: 0.0900
Validation Accuracy: 0.9740
Overfitting: 0.0860
[Epoch 11, Batch 100] loss: 0.060924210911616684
[Epoch 11, Batch 200] loss: 0.049336090635042636
[Epoch 11, Batch 300] loss: 0.055539121571928265
[Epoch 11, Batch 400] loss: 0.05222663079155609
[Epoch 11, Batch 500] loss: 0.05399071054533124
[Epoch 11, Batch 600] loss: 0.05172378755407408
[Epoch 11, Batch 700] loss: 0.057000372239854186
**STATS for Epoch 11** : 
Average training loss: 0.0032
Average validation loss: 0.0726
Validation Accuracy: 0.9789
Overfitting: 0.0694
Early stopping epoch 11 for trial 16. Moving to next fold.
Fold 2 validation loss: 0.0726
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2987020230293274
[Epoch 1, Batch 200] loss: 2.277650098800659
[Epoch 1, Batch 300] loss: 2.2198244309425355
[Epoch 1, Batch 400] loss: 1.849774329662323
[Epoch 1, Batch 500] loss: 0.8419093704223632
[Epoch 1, Batch 600] loss: 0.5218764534592628
[Epoch 1, Batch 700] loss: 0.4382228954136372
**STATS for Epoch 1** : 
Average training loss: 0.0257
Average validation loss: 0.3357
Validation Accuracy: 0.9020
Overfitting: 0.3100
[Epoch 2, Batch 100] loss: 0.34029087409377096
[Epoch 2, Batch 200] loss: 0.32868131026625635
[Epoch 2, Batch 300] loss: 0.28531808823347093
[Epoch 2, Batch 400] loss: 0.2574144082516432
[Epoch 2, Batch 500] loss: 0.22973971396684648
[Epoch 2, Batch 600] loss: 0.20141373679041863
[Epoch 2, Batch 700] loss: 0.22815289705991745
**STATS for Epoch 2** : 
Average training loss: 0.0124
Average validation loss: 0.1994
Validation Accuracy: 0.9398
Overfitting: 0.1870
[Epoch 3, Batch 100] loss: 0.20167492497712375
[Epoch 3, Batch 200] loss: 0.198304248675704
[Epoch 3, Batch 300] loss: 0.17314913883805275
[Epoch 3, Batch 400] loss: 0.16912716180086135
[Epoch 3, Batch 500] loss: 0.1511235740594566
[Epoch 3, Batch 600] loss: 0.14827727351337672
[Epoch 3, Batch 700] loss: 0.14760704576969147
**STATS for Epoch 3** : 
Average training loss: 0.0098
Average validation loss: 0.1430
Validation Accuracy: 0.9569
Overfitting: 0.1332
[Epoch 4, Batch 100] loss: 0.13093614391982555
[Epoch 4, Batch 200] loss: 0.14899331267923116
[Epoch 4, Batch 300] loss: 0.13621600534766912
[Epoch 4, Batch 400] loss: 0.12199147798120975
[Epoch 4, Batch 500] loss: 0.12279300631955266
[Epoch 4, Batch 600] loss: 0.11753457365557551
[Epoch 4, Batch 700] loss: 0.11045342147350311
**STATS for Epoch 4** : 
Average training loss: 0.0092
Average validation loss: 0.1321
Validation Accuracy: 0.9603
Overfitting: 0.1229
[Epoch 5, Batch 100] loss: 0.09783374617807566
[Epoch 5, Batch 200] loss: 0.11399172804318368
[Epoch 5, Batch 300] loss: 0.09824671864509582
[Epoch 5, Batch 400] loss: 0.1114696253463626
[Epoch 5, Batch 500] loss: 0.10076122883707285
[Epoch 5, Batch 600] loss: 0.10467468617483973
[Epoch 5, Batch 700] loss: 0.09633736820891499
**STATS for Epoch 5** : 
Average training loss: 0.0063
Average validation loss: 0.1031
Validation Accuracy: 0.9693
Overfitting: 0.0968
[Epoch 6, Batch 100] loss: 0.09381164801772685
[Epoch 6, Batch 200] loss: 0.08936226847581566
[Epoch 6, Batch 300] loss: 0.10157836135476828
[Epoch 6, Batch 400] loss: 0.09481591099873185
[Epoch 6, Batch 500] loss: 0.09242189792916179
[Epoch 6, Batch 600] loss: 0.0844990401994437
[Epoch 6, Batch 700] loss: 0.07954676397144794
**STATS for Epoch 6** : 
Average training loss: 0.0052
Average validation loss: 0.0922
Validation Accuracy: 0.9704
Overfitting: 0.0869
[Epoch 7, Batch 100] loss: 0.07993547056801617
[Epoch 7, Batch 200] loss: 0.08250790959224105
[Epoch 7, Batch 300] loss: 0.07309391947463155
[Epoch 7, Batch 400] loss: 0.08259858820587397
[Epoch 7, Batch 500] loss: 0.07398402693681419
[Epoch 7, Batch 600] loss: 0.07650012354366481
[Epoch 7, Batch 700] loss: 0.08348622237797826
**STATS for Epoch 7** : 
Average training loss: 0.0050
Average validation loss: 0.0888
Validation Accuracy: 0.9722
Overfitting: 0.0838
[Epoch 8, Batch 100] loss: 0.0709890856500715
[Epoch 8, Batch 200] loss: 0.07346454009413719
[Epoch 8, Batch 300] loss: 0.06721363313961774
[Epoch 8, Batch 400] loss: 0.0770878681819886
[Epoch 8, Batch 500] loss: 0.0670110592711717
[Epoch 8, Batch 600] loss: 0.07437906331382692
[Epoch 8, Batch 700] loss: 0.07080710456706583
**STATS for Epoch 8** : 
Average training loss: 0.0041
Average validation loss: 0.0787
Validation Accuracy: 0.9761
Overfitting: 0.0746
[Epoch 9, Batch 100] loss: 0.06264713359996676
[Epoch 9, Batch 200] loss: 0.06318629551213234
[Epoch 9, Batch 300] loss: 0.05969658629735932
[Epoch 9, Batch 400] loss: 0.060805244089569895
[Epoch 9, Batch 500] loss: 0.07017361966893076
[Epoch 9, Batch 600] loss: 0.06846638573333622
[Epoch 9, Batch 700] loss: 0.060701687424443665
**STATS for Epoch 9** : 
Average training loss: 0.0041
Average validation loss: 0.0742
Validation Accuracy: 0.9770
Overfitting: 0.0700
Best model saved at epoch 9 with validation loss: 0.0742
[Epoch 10, Batch 100] loss: 0.052319674212485553
[Epoch 10, Batch 200] loss: 0.05207179264165461
[Epoch 10, Batch 300] loss: 0.060131612909026445
[Epoch 10, Batch 400] loss: 0.05388169693294913
[Epoch 10, Batch 500] loss: 0.05904363637790084
[Epoch 10, Batch 600] loss: 0.05709099819883704
[Epoch 10, Batch 700] loss: 0.06547474188730121
**STATS for Epoch 10** : 
Average training loss: 0.0034
Average validation loss: 0.0677
Validation Accuracy: 0.9786
Overfitting: 0.0643
[Epoch 11, Batch 100] loss: 0.053159784874878824
[Epoch 11, Batch 200] loss: 0.048979135132394734
[Epoch 11, Batch 300] loss: 0.05867557276040316
[Epoch 11, Batch 400] loss: 0.06124313378240913
[Epoch 11, Batch 500] loss: 0.04872457306366414
[Epoch 11, Batch 600] loss: 0.051668704852927475
[Epoch 11, Batch 700] loss: 0.052406223914586006
**STATS for Epoch 11** : 
Average training loss: 0.0022
Average validation loss: 0.0632
Validation Accuracy: 0.9802
Overfitting: 0.0609
Early stopping epoch 11 for trial 16. Moving to next fold.
Fold 3 validation loss: 0.0632
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2963330507278443
[Epoch 1, Batch 200] loss: 2.2649151062965394
[Epoch 1, Batch 300] loss: 2.1161995947360994
[Epoch 1, Batch 400] loss: 1.2385445195436477
[Epoch 1, Batch 500] loss: 0.6420413699746131
[Epoch 1, Batch 600] loss: 0.48116279184818267
[Epoch 1, Batch 700] loss: 0.4081947433948517
**STATS for Epoch 1** : 
Average training loss: 0.0254
Average validation loss: 0.3460
Validation Accuracy: 0.8975
Overfitting: 0.3205
[Epoch 2, Batch 100] loss: 0.33631836488842964
[Epoch 2, Batch 200] loss: 0.3115952104330063
[Epoch 2, Batch 300] loss: 0.29201793745160104
[Epoch 2, Batch 400] loss: 0.25621538490056994
[Epoch 2, Batch 500] loss: 0.25181965686380864
[Epoch 2, Batch 600] loss: 0.24030295424163342
[Epoch 2, Batch 700] loss: 0.22405445359647275
**STATS for Epoch 2** : 
Average training loss: 0.0137
Average validation loss: 0.2114
Validation Accuracy: 0.9365
Overfitting: 0.1977
[Epoch 3, Batch 100] loss: 0.19759513795375824
[Epoch 3, Batch 200] loss: 0.20253819163888692
[Epoch 3, Batch 300] loss: 0.1776264651119709
[Epoch 3, Batch 400] loss: 0.176544059664011
[Epoch 3, Batch 500] loss: 0.16294146167114376
[Epoch 3, Batch 600] loss: 0.16552745390683413
[Epoch 3, Batch 700] loss: 0.14181028850376606
**STATS for Epoch 3** : 
Average training loss: 0.0106
Average validation loss: 0.1681
Validation Accuracy: 0.9474
Overfitting: 0.1575
[Epoch 4, Batch 100] loss: 0.13465847766026853
[Epoch 4, Batch 200] loss: 0.13707013752311467
[Epoch 4, Batch 300] loss: 0.14679117964580654
[Epoch 4, Batch 400] loss: 0.13396781830117108
[Epoch 4, Batch 500] loss: 0.13183456307277083
[Epoch 4, Batch 600] loss: 0.12684684325009585
[Epoch 4, Batch 700] loss: 0.12272936275228857
**STATS for Epoch 4** : 
Average training loss: 0.0069
Average validation loss: 0.1132
Validation Accuracy: 0.9629
Overfitting: 0.1063
[Epoch 5, Batch 100] loss: 0.11308880934491754
[Epoch 5, Batch 200] loss: 0.10025036730803549
[Epoch 5, Batch 300] loss: 0.117847383688204
[Epoch 5, Batch 400] loss: 0.11114961087703705
[Epoch 5, Batch 500] loss: 0.09798389707691968
[Epoch 5, Batch 600] loss: 0.10039907840080559
[Epoch 5, Batch 700] loss: 0.09797485796734691
**STATS for Epoch 5** : 
Average training loss: 0.0067
Average validation loss: 0.1012
Validation Accuracy: 0.9691
Overfitting: 0.0945
[Epoch 6, Batch 100] loss: 0.07858324483968318
[Epoch 6, Batch 200] loss: 0.0882275159098208
[Epoch 6, Batch 300] loss: 0.1005431125126779
[Epoch 6, Batch 400] loss: 0.09194498495198786
[Epoch 6, Batch 500] loss: 0.09911628767848014
[Epoch 6, Batch 600] loss: 0.09087966549210251
[Epoch 6, Batch 700] loss: 0.0904310735547915
**STATS for Epoch 6** : 
Average training loss: 0.0059
Average validation loss: 0.0842
Validation Accuracy: 0.9746
Overfitting: 0.0783
[Epoch 7, Batch 100] loss: 0.09210488811135292
[Epoch 7, Batch 200] loss: 0.07924132412299514
[Epoch 7, Batch 300] loss: 0.08542201059870422
[Epoch 7, Batch 400] loss: 0.07375341832637787
[Epoch 7, Batch 500] loss: 0.07835257767699659
[Epoch 7, Batch 600] loss: 0.07597040135413408
[Epoch 7, Batch 700] loss: 0.0760648312419653
**STATS for Epoch 7** : 
Average training loss: 0.0045
Average validation loss: 0.0765
Validation Accuracy: 0.9772
Overfitting: 0.0719
[Epoch 8, Batch 100] loss: 0.06725738387089222
[Epoch 8, Batch 200] loss: 0.08295253772754223
[Epoch 8, Batch 300] loss: 0.0681693003885448
[Epoch 8, Batch 400] loss: 0.0673932610778138
[Epoch 8, Batch 500] loss: 0.060843859207816424
[Epoch 8, Batch 600] loss: 0.07199391636997461
[Epoch 8, Batch 700] loss: 0.06882767972070723
**STATS for Epoch 8** : 
Average training loss: 0.0044
Average validation loss: 0.0748
Validation Accuracy: 0.9778
Overfitting: 0.0704
[Epoch 9, Batch 100] loss: 0.06307569751050324
[Epoch 9, Batch 200] loss: 0.07007619205396623
[Epoch 9, Batch 300] loss: 0.06857563519850374
[Epoch 9, Batch 400] loss: 0.054413869329728186
[Epoch 9, Batch 500] loss: 0.06021900377236307
[Epoch 9, Batch 600] loss: 0.06784922162536532
[Epoch 9, Batch 700] loss: 0.05590535783208907
**STATS for Epoch 9** : 
Average training loss: 0.0048
Average validation loss: 0.0763
Validation Accuracy: 0.9762
Overfitting: 0.0715
Best model saved at epoch 9 with validation loss: 0.0763
[Epoch 10, Batch 100] loss: 0.05537430646363646
[Epoch 10, Batch 200] loss: 0.05754832524806261
[Epoch 10, Batch 300] loss: 0.05991798859322443
[Epoch 10, Batch 400] loss: 0.0633801323454827
[Epoch 10, Batch 500] loss: 0.06337801588699221
[Epoch 10, Batch 600] loss: 0.06211775270756334
[Epoch 10, Batch 700] loss: 0.046621349225752055
**STATS for Epoch 10** : 
Average training loss: 0.0039
Average validation loss: 0.0711
Validation Accuracy: 0.9783
Overfitting: 0.0672
[Epoch 11, Batch 100] loss: 0.05439926109276712
[Epoch 11, Batch 200] loss: 0.05541746004950255
[Epoch 11, Batch 300] loss: 0.04930057678138837
[Epoch 11, Batch 400] loss: 0.049304464885499326
[Epoch 11, Batch 500] loss: 0.04922610090114176
[Epoch 11, Batch 600] loss: 0.04396061066770926
[Epoch 11, Batch 700] loss: 0.06828455867711454
**STATS for Epoch 11** : 
Average training loss: 0.0039
Average validation loss: 0.0603
Validation Accuracy: 0.9806
Overfitting: 0.0564
Early stopping epoch 11 for trial 16. Moving to next fold.
Fold 4 validation loss: 0.0603
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2955266189575196
[Epoch 1, Batch 200] loss: 2.271285963058472
[Epoch 1, Batch 300] loss: 2.201768045425415
[Epoch 1, Batch 400] loss: 1.7100775009393692
[Epoch 1, Batch 500] loss: 0.6795651543140412
[Epoch 1, Batch 600] loss: 0.4496849852800369
[Epoch 1, Batch 700] loss: 0.3997839008271694
**STATS for Epoch 1** : 
Average training loss: 0.0241
Average validation loss: 0.3529
Validation Accuracy: 0.8918
Overfitting: 0.3288
[Epoch 2, Batch 100] loss: 0.3351617766916752
[Epoch 2, Batch 200] loss: 0.2978002370148897
[Epoch 2, Batch 300] loss: 0.2715434216707945
[Epoch 2, Batch 400] loss: 0.23970817647874354
[Epoch 2, Batch 500] loss: 0.2300957553088665
[Epoch 2, Batch 600] loss: 0.22410471450537442
[Epoch 2, Batch 700] loss: 0.2015739732980728
**STATS for Epoch 2** : 
Average training loss: 0.0114
Average validation loss: 0.1847
Validation Accuracy: 0.9459
Overfitting: 0.1733
[Epoch 3, Batch 100] loss: 0.17701133459806442
[Epoch 3, Batch 200] loss: 0.16591362103819848
[Epoch 3, Batch 300] loss: 0.151248885858804
[Epoch 3, Batch 400] loss: 0.1662762601301074
[Epoch 3, Batch 500] loss: 0.14443917658179997
[Epoch 3, Batch 600] loss: 0.13539617598056794
[Epoch 3, Batch 700] loss: 0.13437752841040493
**STATS for Epoch 3** : 
Average training loss: 0.0085
Average validation loss: 0.1238
Validation Accuracy: 0.9630
Overfitting: 0.1153
[Epoch 4, Batch 100] loss: 0.11045578354969621
[Epoch 4, Batch 200] loss: 0.13116281209513544
[Epoch 4, Batch 300] loss: 0.12186893464066088
[Epoch 4, Batch 400] loss: 0.11229815965518355
[Epoch 4, Batch 500] loss: 0.11118665806949139
[Epoch 4, Batch 600] loss: 0.10883742578327656
[Epoch 4, Batch 700] loss: 0.10071760058403015
**STATS for Epoch 4** : 
Average training loss: 0.0068
Average validation loss: 0.1089
Validation Accuracy: 0.9673
Overfitting: 0.1021
[Epoch 5, Batch 100] loss: 0.09555648941546678
[Epoch 5, Batch 200] loss: 0.09509739795699716
[Epoch 5, Batch 300] loss: 0.10637346412055194
[Epoch 5, Batch 400] loss: 0.09336831507273019
[Epoch 5, Batch 500] loss: 0.09482699629850685
[Epoch 5, Batch 600] loss: 0.08598031804896891
[Epoch 5, Batch 700] loss: 0.08650256778113544
**STATS for Epoch 5** : 
Average training loss: 0.0062
Average validation loss: 0.0879
Validation Accuracy: 0.9730
Overfitting: 0.0817
[Epoch 6, Batch 100] loss: 0.0849500073865056
[Epoch 6, Batch 200] loss: 0.09068780149333179
[Epoch 6, Batch 300] loss: 0.08801003047265113
[Epoch 6, Batch 400] loss: 0.08333468177355825
[Epoch 6, Batch 500] loss: 0.07334677977487444
[Epoch 6, Batch 600] loss: 0.07844673554878683
[Epoch 6, Batch 700] loss: 0.0678550423681736
**STATS for Epoch 6** : 
Average training loss: 0.0044
Average validation loss: 0.0870
Validation Accuracy: 0.9726
Overfitting: 0.0825
[Epoch 7, Batch 100] loss: 0.07084449561312794
[Epoch 7, Batch 200] loss: 0.07663002128712833
[Epoch 7, Batch 300] loss: 0.07018762127496302
[Epoch 7, Batch 400] loss: 0.07246551016811281
[Epoch 7, Batch 500] loss: 0.08187397996429353
[Epoch 7, Batch 600] loss: 0.07445064570754767
[Epoch 7, Batch 700] loss: 0.0658984540309757
**STATS for Epoch 7** : 
Average training loss: 0.0044
Average validation loss: 0.0756
Validation Accuracy: 0.9765
Overfitting: 0.0712
[Epoch 8, Batch 100] loss: 0.07387761228717864
[Epoch 8, Batch 200] loss: 0.0673090772330761
[Epoch 8, Batch 300] loss: 0.05685779629740864
[Epoch 8, Batch 400] loss: 0.06352439385373146
[Epoch 8, Batch 500] loss: 0.06575103668030352
[Epoch 8, Batch 600] loss: 0.06034313688054681
[Epoch 8, Batch 700] loss: 0.05945133130531758
**STATS for Epoch 8** : 
Average training loss: 0.0048
Average validation loss: 0.0855
Validation Accuracy: 0.9742
Overfitting: 0.0806
[Epoch 9, Batch 100] loss: 0.0531696651969105
[Epoch 9, Batch 200] loss: 0.060262255789712074
[Epoch 9, Batch 300] loss: 0.06262903800234199
[Epoch 9, Batch 400] loss: 0.05927812759066001
[Epoch 9, Batch 500] loss: 0.05724314894061536
[Epoch 9, Batch 600] loss: 0.05606961625861004
[Epoch 9, Batch 700] loss: 0.05939027704298496
**STATS for Epoch 9** : 
Average training loss: 0.0041
Average validation loss: 0.0635
Validation Accuracy: 0.9805
Overfitting: 0.0594
Best model saved at epoch 9 with validation loss: 0.0635
[Epoch 10, Batch 100] loss: 0.0527097506611608
[Epoch 10, Batch 200] loss: 0.058958677635528145
[Epoch 10, Batch 300] loss: 0.050974346972070636
[Epoch 10, Batch 400] loss: 0.06345463862176985
[Epoch 10, Batch 500] loss: 0.0545837244996801
[Epoch 10, Batch 600] loss: 0.05179010926745832
[Epoch 10, Batch 700] loss: 0.05029508654028177
**STATS for Epoch 10** : 
Average training loss: 0.0033
Average validation loss: 0.0600
Validation Accuracy: 0.9816
Overfitting: 0.0567
[Epoch 11, Batch 100] loss: 0.04733006929978728
[Epoch 11, Batch 200] loss: 0.048124454861972484
[Epoch 11, Batch 300] loss: 0.04955191106069833
[Epoch 11, Batch 400] loss: 0.04853862375020981
[Epoch 11, Batch 500] loss: 0.04993296951288358
[Epoch 11, Batch 600] loss: 0.05463421464897692
[Epoch 11, Batch 700] loss: 0.05209949073381722
**STATS for Epoch 11** : 
Average training loss: 0.0030
Average validation loss: 0.0593
Validation Accuracy: 0.9818
Overfitting: 0.0563
Early stopping epoch 11 for trial 16. Moving to next fold.
Fold 5 validation loss: 0.0593
Mean validation loss across all folds for Trial 16 is 0.0629 with trial config:  l1: 256, l2: 128, lr: 0.001, batch_size: 64
[I 2024-12-10 06:29:58,178] Trial 15 finished with value: 0.06290469721561556 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 64}. Best is trial 12 with value: 0.0492618556785242.

Selected Hyperparameters for Trial 17:
  l1: 256, l2: 128, lr: 0.0005, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3007085633277895
[Epoch 1, Batch 200] loss: 2.2857948207855223
[Epoch 1, Batch 300] loss: 2.264930646419525
[Epoch 1, Batch 400] loss: 2.2264294028282166
[Epoch 1, Batch 500] loss: 2.1387541675567627
[Epoch 1, Batch 600] loss: 1.8528774905204772
[Epoch 1, Batch 700] loss: 1.1610337829589843
[Epoch 1, Batch 800] loss: 0.6631030642986298
[Epoch 1, Batch 900] loss: 0.4942967154085636
[Epoch 1, Batch 1000] loss: 0.4342816086113453
[Epoch 1, Batch 1100] loss: 0.39588781096041203
[Epoch 1, Batch 1200] loss: 0.34551133662462236
[Epoch 1, Batch 1300] loss: 0.3135971041768789
[Epoch 1, Batch 1400] loss: 0.2986229024454951
[Epoch 1, Batch 1500] loss: 0.2819214107841253
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2674
Validation Accuracy: 0.9193
Overfitting: 0.2674
[Epoch 2, Batch 100] loss: 0.27014397095888854
[Epoch 2, Batch 200] loss: 0.2705427385494113
[Epoch 2, Batch 300] loss: 0.2545374646037817
[Epoch 2, Batch 400] loss: 0.2562574641779065
[Epoch 2, Batch 500] loss: 0.23842619031667708
[Epoch 2, Batch 600] loss: 0.208719836845994
[Epoch 2, Batch 700] loss: 0.20042468439787625
[Epoch 2, Batch 800] loss: 0.20396440222859383
[Epoch 2, Batch 900] loss: 0.23302047759294509
[Epoch 2, Batch 1000] loss: 0.18387741576880218
[Epoch 2, Batch 1100] loss: 0.19584553595632315
[Epoch 2, Batch 1200] loss: 0.17256832597777247
[Epoch 2, Batch 1300] loss: 0.17184829943813384
[Epoch 2, Batch 1400] loss: 0.16679014021530747
[Epoch 2, Batch 1500] loss: 0.17986336147412657
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1527
Validation Accuracy: 0.9543
Overfitting: 0.1527
[Epoch 3, Batch 100] loss: 0.16088976342231034
[Epoch 3, Batch 200] loss: 0.15718782983720303
[Epoch 3, Batch 300] loss: 0.15123386695981025
[Epoch 3, Batch 400] loss: 0.1470469404757023
[Epoch 3, Batch 500] loss: 0.16455971732735633
[Epoch 3, Batch 600] loss: 0.15221814217977225
[Epoch 3, Batch 700] loss: 0.15198026365600525
[Epoch 3, Batch 800] loss: 0.12259063769131899
[Epoch 3, Batch 900] loss: 0.14009483027271927
[Epoch 3, Batch 1000] loss: 0.12783667393960058
[Epoch 3, Batch 1100] loss: 0.13642962188459934
[Epoch 3, Batch 1200] loss: 0.11154158754274249
[Epoch 3, Batch 1300] loss: 0.14353164732456208
[Epoch 3, Batch 1400] loss: 0.12063079982064664
[Epoch 3, Batch 1500] loss: 0.12388119640760124
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1236
Validation Accuracy: 0.9629
Overfitting: 0.1236
[Epoch 4, Batch 100] loss: 0.1168067687144503
[Epoch 4, Batch 200] loss: 0.10655639327131211
[Epoch 4, Batch 300] loss: 0.1307295669335872
[Epoch 4, Batch 400] loss: 0.10399002872407437
[Epoch 4, Batch 500] loss: 0.1247647837549448
[Epoch 4, Batch 600] loss: 0.11784447659738362
[Epoch 4, Batch 700] loss: 0.11408470517024398
[Epoch 4, Batch 800] loss: 0.10663844909053295
[Epoch 4, Batch 900] loss: 0.09697790872305631
[Epoch 4, Batch 1000] loss: 0.10442926743067801
[Epoch 4, Batch 1100] loss: 0.11523655566386878
[Epoch 4, Batch 1200] loss: 0.10614672514609992
[Epoch 4, Batch 1300] loss: 0.08870868062134832
[Epoch 4, Batch 1400] loss: 0.10101817914284766
[Epoch 4, Batch 1500] loss: 0.11574878180399537
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0974
Validation Accuracy: 0.9710
Overfitting: 0.0974
[Epoch 5, Batch 100] loss: 0.09135495231486856
[Epoch 5, Batch 200] loss: 0.08605730996001512
[Epoch 5, Batch 300] loss: 0.09037336125038564
[Epoch 5, Batch 400] loss: 0.11333054884336889
[Epoch 5, Batch 500] loss: 0.08677829961758107
[Epoch 5, Batch 600] loss: 0.0899360846541822
[Epoch 5, Batch 700] loss: 0.10292431915178896
[Epoch 5, Batch 800] loss: 0.08706659814342857
[Epoch 5, Batch 900] loss: 0.09502858394756913
[Epoch 5, Batch 1000] loss: 0.10072662814985961
[Epoch 5, Batch 1100] loss: 0.0842056997306645
[Epoch 5, Batch 1200] loss: 0.09828593431971967
[Epoch 5, Batch 1300] loss: 0.07141950670164078
[Epoch 5, Batch 1400] loss: 0.08090677064610645
[Epoch 5, Batch 1500] loss: 0.09568046314176172
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0846
Validation Accuracy: 0.9738
Overfitting: 0.0846
[Epoch 6, Batch 100] loss: 0.07782028500456363
[Epoch 6, Batch 200] loss: 0.07123778187204152
[Epoch 6, Batch 300] loss: 0.08509514981880784
[Epoch 6, Batch 400] loss: 0.09099058484192937
[Epoch 6, Batch 500] loss: 0.08810053174383939
[Epoch 6, Batch 600] loss: 0.08131880500819534
[Epoch 6, Batch 700] loss: 0.08949852148070932
[Epoch 6, Batch 800] loss: 0.07738856302574276
[Epoch 6, Batch 900] loss: 0.07214168986305594
[Epoch 6, Batch 1000] loss: 0.08430601236876101
[Epoch 6, Batch 1100] loss: 0.08172523374902084
[Epoch 6, Batch 1200] loss: 0.07277320796158165
[Epoch 6, Batch 1300] loss: 0.07654959081439301
[Epoch 6, Batch 1400] loss: 0.0834829194098711
[Epoch 6, Batch 1500] loss: 0.06656965294154361
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0726
Validation Accuracy: 0.9772
Overfitting: 0.0726
[Epoch 7, Batch 100] loss: 0.07610337030841037
[Epoch 7, Batch 200] loss: 0.06384855437092483
[Epoch 7, Batch 300] loss: 0.07876627990044653
[Epoch 7, Batch 400] loss: 0.06614549349062145
[Epoch 7, Batch 500] loss: 0.07644244811497629
[Epoch 7, Batch 600] loss: 0.06861710826400667
[Epoch 7, Batch 700] loss: 0.06713751246221364
[Epoch 7, Batch 800] loss: 0.06646534148370847
[Epoch 7, Batch 900] loss: 0.0809486746462062
[Epoch 7, Batch 1000] loss: 0.06705973356030881
[Epoch 7, Batch 1100] loss: 0.07489410392008722
[Epoch 7, Batch 1200] loss: 0.060484457642305645
[Epoch 7, Batch 1300] loss: 0.07230007284320891
[Epoch 7, Batch 1400] loss: 0.07153249478898943
[Epoch 7, Batch 1500] loss: 0.06448032886721194
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0653
Validation Accuracy: 0.9787
Overfitting: 0.0653
[Epoch 8, Batch 100] loss: 0.063881608187221
[Epoch 8, Batch 200] loss: 0.06873382635880261
[Epoch 8, Batch 300] loss: 0.06996381594333798
[Epoch 8, Batch 400] loss: 0.05979026595363393
[Epoch 8, Batch 500] loss: 0.06330840308917686
[Epoch 8, Batch 600] loss: 0.05972390054957941
[Epoch 8, Batch 700] loss: 0.06087887812638655
[Epoch 8, Batch 800] loss: 0.056575262630358336
[Epoch 8, Batch 900] loss: 0.06512043422553689
[Epoch 8, Batch 1000] loss: 0.06963960041757673
[Epoch 8, Batch 1100] loss: 0.04988796590827405
[Epoch 8, Batch 1200] loss: 0.07234576766844839
[Epoch 8, Batch 1300] loss: 0.07287950563826598
[Epoch 8, Batch 1400] loss: 0.06241472900728695
[Epoch 8, Batch 1500] loss: 0.06510275583714246
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0704
Validation Accuracy: 0.9780
Overfitting: 0.0704
[Epoch 9, Batch 100] loss: 0.0517203921219334
[Epoch 9, Batch 200] loss: 0.0600674319639802
[Epoch 9, Batch 300] loss: 0.05959026289521716
[Epoch 9, Batch 400] loss: 0.053154345395741986
[Epoch 9, Batch 500] loss: 0.060963470221031456
[Epoch 9, Batch 600] loss: 0.05372072467347607
[Epoch 9, Batch 700] loss: 0.05765837461338379
[Epoch 9, Batch 800] loss: 0.05602143843192607
[Epoch 9, Batch 900] loss: 0.060586892957799135
[Epoch 9, Batch 1000] loss: 0.04892612180206925
[Epoch 9, Batch 1100] loss: 0.05842441427288577
[Epoch 9, Batch 1200] loss: 0.058830472033005204
[Epoch 9, Batch 1300] loss: 0.06925544076133519
[Epoch 9, Batch 1400] loss: 0.0640697904175613
[Epoch 9, Batch 1500] loss: 0.042985799707239494
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0611
Validation Accuracy: 0.9800
Overfitting: 0.0611
Best model saved at epoch 9 with validation loss: 0.0611
[Epoch 10, Batch 100] loss: 0.04693256151629612
[Epoch 10, Batch 200] loss: 0.057668353312183174
[Epoch 10, Batch 300] loss: 0.04649263529805467
[Epoch 10, Batch 400] loss: 0.04667768945917487
[Epoch 10, Batch 500] loss: 0.05094535296666436
[Epoch 10, Batch 600] loss: 0.04752872312732506
[Epoch 10, Batch 700] loss: 0.06413857544073835
[Epoch 10, Batch 800] loss: 0.06165774084627628
[Epoch 10, Batch 900] loss: 0.0717606303980574
[Epoch 10, Batch 1000] loss: 0.04844824542524293
[Epoch 10, Batch 1100] loss: 0.03974297383101657
[Epoch 10, Batch 1200] loss: 0.04996866354253143
[Epoch 10, Batch 1300] loss: 0.048741101560881364
[Epoch 10, Batch 1400] loss: 0.06338675377657638
[Epoch 10, Batch 1500] loss: 0.05575212443480268
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0566
Validation Accuracy: 0.9827
Overfitting: 0.0566
[Epoch 11, Batch 100] loss: 0.050114935010205953
[Epoch 11, Batch 200] loss: 0.04997007368714548
[Epoch 11, Batch 300] loss: 0.049230532037327066
[Epoch 11, Batch 400] loss: 0.06475518410035874
[Epoch 11, Batch 500] loss: 0.04607073256396688
[Epoch 11, Batch 600] loss: 0.048220589726697655
[Epoch 11, Batch 700] loss: 0.03336055971914902
[Epoch 11, Batch 800] loss: 0.04475850048358552
[Epoch 11, Batch 900] loss: 0.05236285455990583
[Epoch 11, Batch 1000] loss: 0.04614151636138558
[Epoch 11, Batch 1100] loss: 0.057349168460350486
[Epoch 11, Batch 1200] loss: 0.047057427094550804
[Epoch 11, Batch 1300] loss: 0.0382033957191743
[Epoch 11, Batch 1400] loss: 0.0444705378508661
[Epoch 11, Batch 1500] loss: 0.05265838199178688
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0596
Validation Accuracy: 0.9812
Overfitting: 0.0596
Early stopping epoch 11 for trial 17. Moving to next fold.
Fold 1 validation loss: 0.0596
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.305511684417725
[Epoch 1, Batch 200] loss: 2.2990788197517396
[Epoch 1, Batch 300] loss: 2.2902077865600585
[Epoch 1, Batch 400] loss: 2.2772648429870603
[Epoch 1, Batch 500] loss: 2.254453008174896
[Epoch 1, Batch 600] loss: 2.2104010725021364
[Epoch 1, Batch 700] loss: 2.0972790217399595
[Epoch 1, Batch 800] loss: 1.7653157305717468
[Epoch 1, Batch 900] loss: 1.0734521406888962
[Epoch 1, Batch 1000] loss: 0.6613109332323074
[Epoch 1, Batch 1100] loss: 0.5342908945679664
[Epoch 1, Batch 1200] loss: 0.46800997987389564
[Epoch 1, Batch 1300] loss: 0.42242018833756445
[Epoch 1, Batch 1400] loss: 0.42465237736701966
[Epoch 1, Batch 1500] loss: 0.38150273337960244
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3658
Validation Accuracy: 0.8939
Overfitting: 0.3658
[Epoch 2, Batch 100] loss: 0.3461463586986065
[Epoch 2, Batch 200] loss: 0.3286357916146517
[Epoch 2, Batch 300] loss: 0.316526158452034
[Epoch 2, Batch 400] loss: 0.3146359281986952
[Epoch 2, Batch 500] loss: 0.29647412210702895
[Epoch 2, Batch 600] loss: 0.2737516222894192
[Epoch 2, Batch 700] loss: 0.2619632050395012
[Epoch 2, Batch 800] loss: 0.2716158264130354
[Epoch 2, Batch 900] loss: 0.2514962761849165
[Epoch 2, Batch 1000] loss: 0.2725750862434506
[Epoch 2, Batch 1100] loss: 0.229995880946517
[Epoch 2, Batch 1200] loss: 0.21787523783743382
[Epoch 2, Batch 1300] loss: 0.21363662444055082
[Epoch 2, Batch 1400] loss: 0.19881888641044498
[Epoch 2, Batch 1500] loss: 0.1912286525964737
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2020
Validation Accuracy: 0.9385
Overfitting: 0.2020
[Epoch 3, Batch 100] loss: 0.19761845555156468
[Epoch 3, Batch 200] loss: 0.20202010517939925
[Epoch 3, Batch 300] loss: 0.19965361127629877
[Epoch 3, Batch 400] loss: 0.18032174434512854
[Epoch 3, Batch 500] loss: 0.16997122906148435
[Epoch 3, Batch 600] loss: 0.17719967965036632
[Epoch 3, Batch 700] loss: 0.16439496271312237
[Epoch 3, Batch 800] loss: 0.16186306688934565
[Epoch 3, Batch 900] loss: 0.17616773257032037
[Epoch 3, Batch 1000] loss: 0.14960425842553376
[Epoch 3, Batch 1100] loss: 0.14589205401018263
[Epoch 3, Batch 1200] loss: 0.1663100928813219
[Epoch 3, Batch 1300] loss: 0.13947333814576268
[Epoch 3, Batch 1400] loss: 0.13420663595199586
[Epoch 3, Batch 1500] loss: 0.1412562707439065
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1461
Validation Accuracy: 0.9567
Overfitting: 0.1461
[Epoch 4, Batch 100] loss: 0.11370582590810954
[Epoch 4, Batch 200] loss: 0.13611608863808214
[Epoch 4, Batch 300] loss: 0.1348202976770699
[Epoch 4, Batch 400] loss: 0.11642687645740807
[Epoch 4, Batch 500] loss: 0.12162326083518565
[Epoch 4, Batch 600] loss: 0.11824159944429993
[Epoch 4, Batch 700] loss: 0.13188170433044433
[Epoch 4, Batch 800] loss: 0.12175564497709274
[Epoch 4, Batch 900] loss: 0.12925843788310887
[Epoch 4, Batch 1000] loss: 0.11439837267622352
[Epoch 4, Batch 1100] loss: 0.11323870264925062
[Epoch 4, Batch 1200] loss: 0.12597816593945027
[Epoch 4, Batch 1300] loss: 0.1297121355496347
[Epoch 4, Batch 1400] loss: 0.10908031600527465
[Epoch 4, Batch 1500] loss: 0.11160020949319005
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1244
Validation Accuracy: 0.9627
Overfitting: 0.1244
[Epoch 5, Batch 100] loss: 0.12777476935647428
[Epoch 5, Batch 200] loss: 0.10696186585351825
[Epoch 5, Batch 300] loss: 0.10193563950713724
[Epoch 5, Batch 400] loss: 0.10266528188250959
[Epoch 5, Batch 500] loss: 0.10955200801603496
[Epoch 5, Batch 600] loss: 0.09945131657179446
[Epoch 5, Batch 700] loss: 0.10180331716313958
[Epoch 5, Batch 800] loss: 0.10419924009591341
[Epoch 5, Batch 900] loss: 0.10521740335505456
[Epoch 5, Batch 1000] loss: 0.08490399772301316
[Epoch 5, Batch 1100] loss: 0.09813535044901073
[Epoch 5, Batch 1200] loss: 0.08488092781975866
[Epoch 5, Batch 1300] loss: 0.10353108715265989
[Epoch 5, Batch 1400] loss: 0.09641901294700801
[Epoch 5, Batch 1500] loss: 0.08467657178174705
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1038
Validation Accuracy: 0.9683
Overfitting: 0.1038
[Epoch 6, Batch 100] loss: 0.07783085580915212
[Epoch 6, Batch 200] loss: 0.09386450783815235
[Epoch 6, Batch 300] loss: 0.07950458707287908
[Epoch 6, Batch 400] loss: 0.09079563002567738
[Epoch 6, Batch 500] loss: 0.09170800156425685
[Epoch 6, Batch 600] loss: 0.09243043660651892
[Epoch 6, Batch 700] loss: 0.08585522424895316
[Epoch 6, Batch 800] loss: 0.09186254879459739
[Epoch 6, Batch 900] loss: 0.08525561462156475
[Epoch 6, Batch 1000] loss: 0.08939614166039973
[Epoch 6, Batch 1100] loss: 0.08446457564015873
[Epoch 6, Batch 1200] loss: 0.08018736977595836
[Epoch 6, Batch 1300] loss: 0.07605964096728712
[Epoch 6, Batch 1400] loss: 0.08342741393018514
[Epoch 6, Batch 1500] loss: 0.08500234007602557
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0942
Validation Accuracy: 0.9708
Overfitting: 0.0942
[Epoch 7, Batch 100] loss: 0.09375495579093694
[Epoch 7, Batch 200] loss: 0.0797165571525693
[Epoch 7, Batch 300] loss: 0.08377659948542714
[Epoch 7, Batch 400] loss: 0.07787986224051564
[Epoch 7, Batch 500] loss: 0.06911485414486379
[Epoch 7, Batch 600] loss: 0.0659979233663762
[Epoch 7, Batch 700] loss: 0.06326200398849323
[Epoch 7, Batch 800] loss: 0.08566092798486352
[Epoch 7, Batch 900] loss: 0.07450035356916487
[Epoch 7, Batch 1000] loss: 0.06096985480748117
[Epoch 7, Batch 1100] loss: 0.07290880182990804
[Epoch 7, Batch 1200] loss: 0.06591669122222811
[Epoch 7, Batch 1300] loss: 0.08686810479033738
[Epoch 7, Batch 1400] loss: 0.07184796078596264
[Epoch 7, Batch 1500] loss: 0.062251341813243925
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0841
Validation Accuracy: 0.9733
Overfitting: 0.0841
[Epoch 8, Batch 100] loss: 0.07185733663849532
[Epoch 8, Batch 200] loss: 0.06986145947128534
[Epoch 8, Batch 300] loss: 0.060237850251141936
[Epoch 8, Batch 400] loss: 0.07831882040016352
[Epoch 8, Batch 500] loss: 0.05761906017549336
[Epoch 8, Batch 600] loss: 0.07637799469288438
[Epoch 8, Batch 700] loss: 0.07680279444903135
[Epoch 8, Batch 800] loss: 0.05647981371032074
[Epoch 8, Batch 900] loss: 0.06308546702144667
[Epoch 8, Batch 1000] loss: 0.06520304125268012
[Epoch 8, Batch 1100] loss: 0.0607055857591331
[Epoch 8, Batch 1200] loss: 0.07675443254876882
[Epoch 8, Batch 1300] loss: 0.056895341005874796
[Epoch 8, Batch 1400] loss: 0.060090974126942455
[Epoch 8, Batch 1500] loss: 0.0695666668319609
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0884
Validation Accuracy: 0.9722
Overfitting: 0.0884
[Epoch 9, Batch 100] loss: 0.06276844431878999
[Epoch 9, Batch 200] loss: 0.051738570807501674
[Epoch 9, Batch 300] loss: 0.060625245687551794
[Epoch 9, Batch 400] loss: 0.06008146614767611
[Epoch 9, Batch 500] loss: 0.05772624344564974
[Epoch 9, Batch 600] loss: 0.0693269238062203
[Epoch 9, Batch 700] loss: 0.06819614546373487
[Epoch 9, Batch 800] loss: 0.05423835936235264
[Epoch 9, Batch 900] loss: 0.06544085939181969
[Epoch 9, Batch 1000] loss: 0.05640867852605879
[Epoch 9, Batch 1100] loss: 0.05551532231038436
[Epoch 9, Batch 1200] loss: 0.07017267033690587
[Epoch 9, Batch 1300] loss: 0.05750876945443451
[Epoch 9, Batch 1400] loss: 0.05610538652632385
[Epoch 9, Batch 1500] loss: 0.05834780826815404
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0864
Validation Accuracy: 0.9736
Overfitting: 0.0864
Best model saved at epoch 9 with validation loss: 0.0864
[Epoch 10, Batch 100] loss: 0.05178611770621501
[Epoch 10, Batch 200] loss: 0.06041853319853544
[Epoch 10, Batch 300] loss: 0.05889502835692838
[Epoch 10, Batch 400] loss: 0.06296948562841863
[Epoch 10, Batch 500] loss: 0.05271279806038365
[Epoch 10, Batch 600] loss: 0.04890954243950546
[Epoch 10, Batch 700] loss: 0.058811575497966256
[Epoch 10, Batch 800] loss: 0.0581366852123756
[Epoch 10, Batch 900] loss: 0.05511366716586053
[Epoch 10, Batch 1000] loss: 0.057422940446995197
[Epoch 10, Batch 1100] loss: 0.04988533603493124
[Epoch 10, Batch 1200] loss: 0.045685519240796564
[Epoch 10, Batch 1300] loss: 0.049766787351109086
[Epoch 10, Batch 1400] loss: 0.04390299356775358
[Epoch 10, Batch 1500] loss: 0.05598206189926714
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0747
Validation Accuracy: 0.9760
Overfitting: 0.0747
[Epoch 11, Batch 100] loss: 0.055875513477949425
[Epoch 11, Batch 200] loss: 0.044275183570571246
[Epoch 11, Batch 300] loss: 0.05301261343061924
[Epoch 11, Batch 400] loss: 0.04337942912476137
[Epoch 11, Batch 500] loss: 0.056587253850884735
[Epoch 11, Batch 600] loss: 0.06007038491545245
[Epoch 11, Batch 700] loss: 0.05613780988263897
[Epoch 11, Batch 800] loss: 0.05052704392350279
[Epoch 11, Batch 900] loss: 0.051652687425957994
[Epoch 11, Batch 1000] loss: 0.05332048194017261
[Epoch 11, Batch 1100] loss: 0.04411835400620476
[Epoch 11, Batch 1200] loss: 0.04367025661515072
[Epoch 11, Batch 1300] loss: 0.04398256049491465
[Epoch 11, Batch 1400] loss: 0.04186775763868354
[Epoch 11, Batch 1500] loss: 0.049247395149432126
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0703
Validation Accuracy: 0.9782
Overfitting: 0.0703
Early stopping epoch 11 for trial 17. Moving to next fold.
Fold 2 validation loss: 0.0703
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2852302765846253
[Epoch 1, Batch 200] loss: 2.2419337749481203
[Epoch 1, Batch 300] loss: 2.1375025904178617
[Epoch 1, Batch 400] loss: 1.80296138048172
[Epoch 1, Batch 500] loss: 1.0756617677211762
[Epoch 1, Batch 600] loss: 0.6836964955925942
[Epoch 1, Batch 700] loss: 0.571371656358242
[Epoch 1, Batch 800] loss: 0.5025084385275841
[Epoch 1, Batch 900] loss: 0.4666683587431908
[Epoch 1, Batch 1000] loss: 0.4044686432182789
[Epoch 1, Batch 1100] loss: 0.3964962626993656
[Epoch 1, Batch 1200] loss: 0.36285019025206566
[Epoch 1, Batch 1300] loss: 0.35222093999385834
[Epoch 1, Batch 1400] loss: 0.3546315947920084
[Epoch 1, Batch 1500] loss: 0.319400834813714
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2930
Validation Accuracy: 0.9147
Overfitting: 0.2930
[Epoch 2, Batch 100] loss: 0.2729315359145403
[Epoch 2, Batch 200] loss: 0.2860675948858261
[Epoch 2, Batch 300] loss: 0.2669791291281581
[Epoch 2, Batch 400] loss: 0.2811517642438412
[Epoch 2, Batch 500] loss: 0.2636017628014088
[Epoch 2, Batch 600] loss: 0.24463262444362044
[Epoch 2, Batch 700] loss: 0.2743181163817644
[Epoch 2, Batch 800] loss: 0.23556783631443978
[Epoch 2, Batch 900] loss: 0.22117002241313458
[Epoch 2, Batch 1000] loss: 0.2179917762055993
[Epoch 2, Batch 1100] loss: 0.20629902109503745
[Epoch 2, Batch 1200] loss: 0.20225724462419747
[Epoch 2, Batch 1300] loss: 0.18315120020881295
[Epoch 2, Batch 1400] loss: 0.16336217507719994
[Epoch 2, Batch 1500] loss: 0.18088462095707655
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1856
Validation Accuracy: 0.9427
Overfitting: 0.1856
[Epoch 3, Batch 100] loss: 0.17564501766115426
[Epoch 3, Batch 200] loss: 0.17663250479847192
[Epoch 3, Batch 300] loss: 0.1641320589184761
[Epoch 3, Batch 400] loss: 0.15738387698307632
[Epoch 3, Batch 500] loss: 0.16218200394883753
[Epoch 3, Batch 600] loss: 0.15620843574404716
[Epoch 3, Batch 700] loss: 0.1481175267882645
[Epoch 3, Batch 800] loss: 0.1438620427250862
[Epoch 3, Batch 900] loss: 0.1631901294272393
[Epoch 3, Batch 1000] loss: 0.15886148054152727
[Epoch 3, Batch 1100] loss: 0.1385386505909264
[Epoch 3, Batch 1200] loss: 0.17393041729927064
[Epoch 3, Batch 1300] loss: 0.1310164937749505
[Epoch 3, Batch 1400] loss: 0.14613403064198793
[Epoch 3, Batch 1500] loss: 0.14372634405270218
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1463
Validation Accuracy: 0.9577
Overfitting: 0.1463
[Epoch 4, Batch 100] loss: 0.13245650385506452
[Epoch 4, Batch 200] loss: 0.1411540679074824
[Epoch 4, Batch 300] loss: 0.11565471667796373
[Epoch 4, Batch 400] loss: 0.145328816389665
[Epoch 4, Batch 500] loss: 0.13589774830266832
[Epoch 4, Batch 600] loss: 0.11286618406884372
[Epoch 4, Batch 700] loss: 0.12329856796190143
[Epoch 4, Batch 800] loss: 0.12498252352699638
[Epoch 4, Batch 900] loss: 0.09800712987780572
[Epoch 4, Batch 1000] loss: 0.1143648387119174
[Epoch 4, Batch 1100] loss: 0.10773331151343882
[Epoch 4, Batch 1200] loss: 0.11145851373672486
[Epoch 4, Batch 1300] loss: 0.10633259044960142
[Epoch 4, Batch 1400] loss: 0.10589496616274119
[Epoch 4, Batch 1500] loss: 0.11150455351918936
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1194
Validation Accuracy: 0.9636
Overfitting: 0.1194
[Epoch 5, Batch 100] loss: 0.10233566898852586
[Epoch 5, Batch 200] loss: 0.09437201234512031
[Epoch 5, Batch 300] loss: 0.10399147898424417
[Epoch 5, Batch 400] loss: 0.1099737361446023
[Epoch 5, Batch 500] loss: 0.09930686889216304
[Epoch 5, Batch 600] loss: 0.09344667805358768
[Epoch 5, Batch 700] loss: 0.11402708814945071
[Epoch 5, Batch 800] loss: 0.10319161999970675
[Epoch 5, Batch 900] loss: 0.1010646176058799
[Epoch 5, Batch 1000] loss: 0.08975642693229019
[Epoch 5, Batch 1100] loss: 0.09097056396305561
[Epoch 5, Batch 1200] loss: 0.09259274987969547
[Epoch 5, Batch 1300] loss: 0.09347001604735851
[Epoch 5, Batch 1400] loss: 0.10486541014630348
[Epoch 5, Batch 1500] loss: 0.09117537427227944
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1018
Validation Accuracy: 0.9705
Overfitting: 0.1018
[Epoch 6, Batch 100] loss: 0.08947249077726155
[Epoch 6, Batch 200] loss: 0.09125653556082397
[Epoch 6, Batch 300] loss: 0.08412112127989531
[Epoch 6, Batch 400] loss: 0.08429988726507873
[Epoch 6, Batch 500] loss: 0.07210779168177396
[Epoch 6, Batch 600] loss: 0.08282472597202287
[Epoch 6, Batch 700] loss: 0.0781045990716666
[Epoch 6, Batch 800] loss: 0.06903399430215358
[Epoch 6, Batch 900] loss: 0.09244304179679602
[Epoch 6, Batch 1000] loss: 0.07969747205148452
[Epoch 6, Batch 1100] loss: 0.08993586386553944
[Epoch 6, Batch 1200] loss: 0.08350302775157616
[Epoch 6, Batch 1300] loss: 0.09289459642022849
[Epoch 6, Batch 1400] loss: 0.09421746337786317
[Epoch 6, Batch 1500] loss: 0.07229421702213586
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0875
Validation Accuracy: 0.9738
Overfitting: 0.0875
[Epoch 7, Batch 100] loss: 0.07541348107624798
[Epoch 7, Batch 200] loss: 0.08125512841623277
[Epoch 7, Batch 300] loss: 0.10661268286639825
[Epoch 7, Batch 400] loss: 0.08338907541241497
[Epoch 7, Batch 500] loss: 0.08374459033831955
[Epoch 7, Batch 600] loss: 0.0628103864309378
[Epoch 7, Batch 700] loss: 0.07601979069877415
[Epoch 7, Batch 800] loss: 0.06475547633832321
[Epoch 7, Batch 900] loss: 0.07781259293900802
[Epoch 7, Batch 1000] loss: 0.06341277353465558
[Epoch 7, Batch 1100] loss: 0.06028561128536239
[Epoch 7, Batch 1200] loss: 0.0687659118208103
[Epoch 7, Batch 1300] loss: 0.07787894915323705
[Epoch 7, Batch 1400] loss: 0.07118409752147273
[Epoch 7, Batch 1500] loss: 0.06469008701387793
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0849
Validation Accuracy: 0.9738
Overfitting: 0.0849
[Epoch 8, Batch 100] loss: 0.07339673149865121
[Epoch 8, Batch 200] loss: 0.07271687345579267
[Epoch 8, Batch 300] loss: 0.06260164978681132
[Epoch 8, Batch 400] loss: 0.062041867936495694
[Epoch 8, Batch 500] loss: 0.08547457167413086
[Epoch 8, Batch 600] loss: 0.057559839854948225
[Epoch 8, Batch 700] loss: 0.06979541930370033
[Epoch 8, Batch 800] loss: 0.06613596598384902
[Epoch 8, Batch 900] loss: 0.06552222218830138
[Epoch 8, Batch 1000] loss: 0.06487592198420317
[Epoch 8, Batch 1100] loss: 0.06235239515081048
[Epoch 8, Batch 1200] loss: 0.07288078550016508
[Epoch 8, Batch 1300] loss: 0.061889604084426536
[Epoch 8, Batch 1400] loss: 0.06752118474338203
[Epoch 8, Batch 1500] loss: 0.06257488412084058
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0788
Validation Accuracy: 0.9762
Overfitting: 0.0788
[Epoch 9, Batch 100] loss: 0.06316077386029065
[Epoch 9, Batch 200] loss: 0.062011512350291016
[Epoch 9, Batch 300] loss: 0.05522667247802019
[Epoch 9, Batch 400] loss: 0.056138600809499624
[Epoch 9, Batch 500] loss: 0.05738766218652017
[Epoch 9, Batch 600] loss: 0.05951039260718972
[Epoch 9, Batch 700] loss: 0.06878625015495345
[Epoch 9, Batch 800] loss: 0.07119601917685942
[Epoch 9, Batch 900] loss: 0.0564635411160998
[Epoch 9, Batch 1000] loss: 0.06637510318541899
[Epoch 9, Batch 1100] loss: 0.05936838471330702
[Epoch 9, Batch 1200] loss: 0.053695863012690095
[Epoch 9, Batch 1300] loss: 0.0562222285498865
[Epoch 9, Batch 1400] loss: 0.06443186945980414
[Epoch 9, Batch 1500] loss: 0.060211338398512455
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0729
Validation Accuracy: 0.9777
Overfitting: 0.0729
Best model saved at epoch 9 with validation loss: 0.0729
[Epoch 10, Batch 100] loss: 0.05237623271299526
[Epoch 10, Batch 200] loss: 0.06415587040828541
[Epoch 10, Batch 300] loss: 0.06370704609202221
[Epoch 10, Batch 400] loss: 0.04956677773268894
[Epoch 10, Batch 500] loss: 0.05408129391842522
[Epoch 10, Batch 600] loss: 0.04558572863577865
[Epoch 10, Batch 700] loss: 0.05471021018689498
[Epoch 10, Batch 800] loss: 0.0606028799014166
[Epoch 10, Batch 900] loss: 0.05539514121599495
[Epoch 10, Batch 1000] loss: 0.05043103708623676
[Epoch 10, Batch 1100] loss: 0.06239812446874567
[Epoch 10, Batch 1200] loss: 0.05271001219749451
[Epoch 10, Batch 1300] loss: 0.059816603835206476
[Epoch 10, Batch 1400] loss: 0.04812363879056648
[Epoch 10, Batch 1500] loss: 0.06023848367622122
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0662
Validation Accuracy: 0.9807
Overfitting: 0.0662
[Epoch 11, Batch 100] loss: 0.05128282696241513
[Epoch 11, Batch 200] loss: 0.04628330689389259
[Epoch 11, Batch 300] loss: 0.04653477660845965
[Epoch 11, Batch 400] loss: 0.05191072070039809
[Epoch 11, Batch 500] loss: 0.05001396189210936
[Epoch 11, Batch 600] loss: 0.0529831001884304
[Epoch 11, Batch 700] loss: 0.049717974393861365
[Epoch 11, Batch 800] loss: 0.053134260654915125
[Epoch 11, Batch 900] loss: 0.05308338286820799
[Epoch 11, Batch 1000] loss: 0.04514613853418268
[Epoch 11, Batch 1100] loss: 0.05339372453046962
[Epoch 11, Batch 1200] loss: 0.06138796854647808
[Epoch 11, Batch 1300] loss: 0.04957447568653151
[Epoch 11, Batch 1400] loss: 0.06369294371805154
[Epoch 11, Batch 1500] loss: 0.049356744643300775
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0672
Validation Accuracy: 0.9794
Overfitting: 0.0672
Early stopping epoch 11 for trial 17. Moving to next fold.
Fold 3 validation loss: 0.0672
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.30125837802887
[Epoch 1, Batch 200] loss: 2.2924196100234986
[Epoch 1, Batch 300] loss: 2.281797316074371
[Epoch 1, Batch 400] loss: 2.263907265663147
[Epoch 1, Batch 500] loss: 2.227256519794464
[Epoch 1, Batch 600] loss: 2.1276650619506836
[Epoch 1, Batch 700] loss: 1.8318755066394805
[Epoch 1, Batch 800] loss: 1.262972548007965
[Epoch 1, Batch 900] loss: 0.8268945524096489
[Epoch 1, Batch 1000] loss: 0.6368173731863499
[Epoch 1, Batch 1100] loss: 0.5789277404546738
[Epoch 1, Batch 1200] loss: 0.4752520774304867
[Epoch 1, Batch 1300] loss: 0.43598630592226983
[Epoch 1, Batch 1400] loss: 0.41112419664859773
[Epoch 1, Batch 1500] loss: 0.40680726297199726
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.4471
Validation Accuracy: 0.8538
Overfitting: 0.4471
[Epoch 2, Batch 100] loss: 0.3762860120087862
[Epoch 2, Batch 200] loss: 0.3198824059963226
[Epoch 2, Batch 300] loss: 0.31548844404518606
[Epoch 2, Batch 400] loss: 0.3250916600227356
[Epoch 2, Batch 500] loss: 0.28084204107522964
[Epoch 2, Batch 600] loss: 0.2758487681299448
[Epoch 2, Batch 700] loss: 0.27935675136744975
[Epoch 2, Batch 800] loss: 0.2582188006490469
[Epoch 2, Batch 900] loss: 0.23309141371399164
[Epoch 2, Batch 1000] loss: 0.22529747866094113
[Epoch 2, Batch 1100] loss: 0.23065564215183257
[Epoch 2, Batch 1200] loss: 0.2011286327801645
[Epoch 2, Batch 1300] loss: 0.21625528186559678
[Epoch 2, Batch 1400] loss: 0.2028544795513153
[Epoch 2, Batch 1500] loss: 0.22137930538505315
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2050
Validation Accuracy: 0.9326
Overfitting: 0.2050
[Epoch 3, Batch 100] loss: 0.19553192242980003
[Epoch 3, Batch 200] loss: 0.16271506428718566
[Epoch 3, Batch 300] loss: 0.19727290185168386
[Epoch 3, Batch 400] loss: 0.18456456933170556
[Epoch 3, Batch 500] loss: 0.19608737409114838
[Epoch 3, Batch 600] loss: 0.17064752537757158
[Epoch 3, Batch 700] loss: 0.15964536325074732
[Epoch 3, Batch 800] loss: 0.15766559563577176
[Epoch 3, Batch 900] loss: 0.15449379295110702
[Epoch 3, Batch 1000] loss: 0.17585091933608055
[Epoch 3, Batch 1100] loss: 0.16194344664923846
[Epoch 3, Batch 1200] loss: 0.12765854799188672
[Epoch 3, Batch 1300] loss: 0.1263479270786047
[Epoch 3, Batch 1400] loss: 0.15676274873316287
[Epoch 3, Batch 1500] loss: 0.14948405096307396
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1645
Validation Accuracy: 0.9476
Overfitting: 0.1645
[Epoch 4, Batch 100] loss: 0.14625291965901852
[Epoch 4, Batch 200] loss: 0.14898411767557262
[Epoch 4, Batch 300] loss: 0.12263997791334987
[Epoch 4, Batch 400] loss: 0.11338452356867493
[Epoch 4, Batch 500] loss: 0.12680554116377607
[Epoch 4, Batch 600] loss: 0.13346372197382153
[Epoch 4, Batch 700] loss: 0.12856427367776632
[Epoch 4, Batch 800] loss: 0.12121667546220123
[Epoch 4, Batch 900] loss: 0.12827052815817297
[Epoch 4, Batch 1000] loss: 0.11913338971324265
[Epoch 4, Batch 1100] loss: 0.12248514245729894
[Epoch 4, Batch 1200] loss: 0.11340933559928089
[Epoch 4, Batch 1300] loss: 0.12122339096851648
[Epoch 4, Batch 1400] loss: 0.12073221933096648
[Epoch 4, Batch 1500] loss: 0.11282316661905498
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1113
Validation Accuracy: 0.9637
Overfitting: 0.1113
[Epoch 5, Batch 100] loss: 0.0994277584925294
[Epoch 5, Batch 200] loss: 0.11078963885549456
[Epoch 5, Batch 300] loss: 0.10279761045239866
[Epoch 5, Batch 400] loss: 0.10650539842434227
[Epoch 5, Batch 500] loss: 0.10871577403740958
[Epoch 5, Batch 600] loss: 0.1108234566822648
[Epoch 5, Batch 700] loss: 0.11275835131295026
[Epoch 5, Batch 800] loss: 0.09037521307822317
[Epoch 5, Batch 900] loss: 0.08860876928083598
[Epoch 5, Batch 1000] loss: 0.1158854659460485
[Epoch 5, Batch 1100] loss: 0.09041531472466886
[Epoch 5, Batch 1200] loss: 0.09995129654183983
[Epoch 5, Batch 1300] loss: 0.11256977866403758
[Epoch 5, Batch 1400] loss: 0.10155188364908099
[Epoch 5, Batch 1500] loss: 0.08648406628053636
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0962
Validation Accuracy: 0.9708
Overfitting: 0.0962
[Epoch 6, Batch 100] loss: 0.08347748540341854
[Epoch 6, Batch 200] loss: 0.08089241528417915
[Epoch 6, Batch 300] loss: 0.10880667126737535
[Epoch 6, Batch 400] loss: 0.09394851529039443
[Epoch 6, Batch 500] loss: 0.09947621548548341
[Epoch 6, Batch 600] loss: 0.08824763955082744
[Epoch 6, Batch 700] loss: 0.08873549109790474
[Epoch 6, Batch 800] loss: 0.08178998340386898
[Epoch 6, Batch 900] loss: 0.08361878818832338
[Epoch 6, Batch 1000] loss: 0.08431556361727416
[Epoch 6, Batch 1100] loss: 0.07862282429356128
[Epoch 6, Batch 1200] loss: 0.06767127729719505
[Epoch 6, Batch 1300] loss: 0.08175508407410234
[Epoch 6, Batch 1400] loss: 0.08589815709274262
[Epoch 6, Batch 1500] loss: 0.09415217556990683
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0933
Validation Accuracy: 0.9710
Overfitting: 0.0933
[Epoch 7, Batch 100] loss: 0.07555418523494155
[Epoch 7, Batch 200] loss: 0.07361610623076559
[Epoch 7, Batch 300] loss: 0.08341361639089882
[Epoch 7, Batch 400] loss: 0.08616678813938052
[Epoch 7, Batch 500] loss: 0.07463344354648144
[Epoch 7, Batch 600] loss: 0.0823573541850783
[Epoch 7, Batch 700] loss: 0.08448629168793559
[Epoch 7, Batch 800] loss: 0.08239360779291019
[Epoch 7, Batch 900] loss: 0.06441962130367757
[Epoch 7, Batch 1000] loss: 0.08498589625116437
[Epoch 7, Batch 1100] loss: 0.0725113127520308
[Epoch 7, Batch 1200] loss: 0.06923596292501316
[Epoch 7, Batch 1300] loss: 0.07997363593196496
[Epoch 7, Batch 1400] loss: 0.06876690761186183
[Epoch 7, Batch 1500] loss: 0.07461796720977873
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0880
Validation Accuracy: 0.9722
Overfitting: 0.0880
[Epoch 8, Batch 100] loss: 0.07519091731403023
[Epoch 8, Batch 200] loss: 0.0681207674741745
[Epoch 8, Batch 300] loss: 0.0635372707573697
[Epoch 8, Batch 400] loss: 0.06875134615343996
[Epoch 8, Batch 500] loss: 0.0749804884986952
[Epoch 8, Batch 600] loss: 0.06138132066233084
[Epoch 8, Batch 700] loss: 0.06519533979473635
[Epoch 8, Batch 800] loss: 0.0775313325226307
[Epoch 8, Batch 900] loss: 0.08002238670829684
[Epoch 8, Batch 1000] loss: 0.06874504047445953
[Epoch 8, Batch 1100] loss: 0.05469786987872794
[Epoch 8, Batch 1200] loss: 0.052947474585380405
[Epoch 8, Batch 1300] loss: 0.08033904246287421
[Epoch 8, Batch 1400] loss: 0.07447501672431826
[Epoch 8, Batch 1500] loss: 0.06433084555203095
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0774
Validation Accuracy: 0.9751
Overfitting: 0.0774
[Epoch 9, Batch 100] loss: 0.06265510291559621
[Epoch 9, Batch 200] loss: 0.07500170847866684
[Epoch 9, Batch 300] loss: 0.07088913321029394
[Epoch 9, Batch 400] loss: 0.07600262663559988
[Epoch 9, Batch 500] loss: 0.06905313661089167
[Epoch 9, Batch 600] loss: 0.06549921005032956
[Epoch 9, Batch 700] loss: 0.06131941188126802
[Epoch 9, Batch 800] loss: 0.05406100393738598
[Epoch 9, Batch 900] loss: 0.05784484000876546
[Epoch 9, Batch 1000] loss: 0.060536777906818315
[Epoch 9, Batch 1100] loss: 0.06118136716075242
[Epoch 9, Batch 1200] loss: 0.06458006227854639
[Epoch 9, Batch 1300] loss: 0.05699034317163751
[Epoch 9, Batch 1400] loss: 0.049669751077890394
[Epoch 9, Batch 1500] loss: 0.05462243136484176
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0688
Validation Accuracy: 0.9782
Overfitting: 0.0688
Best model saved at epoch 9 with validation loss: 0.0688
[Epoch 10, Batch 100] loss: 0.05496398229850456
[Epoch 10, Batch 200] loss: 0.05453828213037923
[Epoch 10, Batch 300] loss: 0.05750660801539197
[Epoch 10, Batch 400] loss: 0.06169514554552734
[Epoch 10, Batch 500] loss: 0.05337628434412181
[Epoch 10, Batch 600] loss: 0.048430626662448045
[Epoch 10, Batch 700] loss: 0.052850443422794345
[Epoch 10, Batch 800] loss: 0.06074571739300154
[Epoch 10, Batch 900] loss: 0.05907797425112221
[Epoch 10, Batch 1000] loss: 0.05295644695521332
[Epoch 10, Batch 1100] loss: 0.05904325095936656
[Epoch 10, Batch 1200] loss: 0.05479008505179081
[Epoch 10, Batch 1300] loss: 0.06156883357441984
[Epoch 10, Batch 1400] loss: 0.05576996516902
[Epoch 10, Batch 1500] loss: 0.060162125299684704
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0713
Validation Accuracy: 0.9770
Overfitting: 0.0713
[Epoch 11, Batch 100] loss: 0.053034797176951545
[Epoch 11, Batch 200] loss: 0.057384537055622784
[Epoch 11, Batch 300] loss: 0.052180581727297976
[Epoch 11, Batch 400] loss: 0.04585552842530888
[Epoch 11, Batch 500] loss: 0.050321253845468164
[Epoch 11, Batch 600] loss: 0.06157895474694669
[Epoch 11, Batch 700] loss: 0.05228714495431632
[Epoch 11, Batch 800] loss: 0.04727825729874894
[Epoch 11, Batch 900] loss: 0.040756781281670554
[Epoch 11, Batch 1000] loss: 0.04509239544859156
[Epoch 11, Batch 1100] loss: 0.0629722848412348
[Epoch 11, Batch 1200] loss: 0.048593598434817975
[Epoch 11, Batch 1300] loss: 0.04288273118319921
[Epoch 11, Batch 1400] loss: 0.055867631565779445
[Epoch 11, Batch 1500] loss: 0.05927680233260617
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0595
Validation Accuracy: 0.9816
Overfitting: 0.0595
Early stopping epoch 11 for trial 17. Moving to next fold.
Fold 4 validation loss: 0.0595
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2899567818641664
[Epoch 1, Batch 200] loss: 2.2676676535606384
[Epoch 1, Batch 300] loss: 2.2223325681686403
[Epoch 1, Batch 400] loss: 2.1053768146038054
[Epoch 1, Batch 500] loss: 1.7470944714546204
[Epoch 1, Batch 600] loss: 1.0618125009536743
[Epoch 1, Batch 700] loss: 0.7275754857063294
[Epoch 1, Batch 800] loss: 0.5786200633645058
[Epoch 1, Batch 900] loss: 0.4739228215813637
[Epoch 1, Batch 1000] loss: 0.4848862886428833
[Epoch 1, Batch 1100] loss: 0.4163447551429272
[Epoch 1, Batch 1200] loss: 0.4135927404463291
[Epoch 1, Batch 1300] loss: 0.3783665730059147
[Epoch 1, Batch 1400] loss: 0.3449947874248028
[Epoch 1, Batch 1500] loss: 0.3311322370916605
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3233
Validation Accuracy: 0.9023
Overfitting: 0.3233
[Epoch 2, Batch 100] loss: 0.32126612197607757
[Epoch 2, Batch 200] loss: 0.29652851171791555
[Epoch 2, Batch 300] loss: 0.2934155920892954
[Epoch 2, Batch 400] loss: 0.29288420766592027
[Epoch 2, Batch 500] loss: 0.27314173080027104
[Epoch 2, Batch 600] loss: 0.26712832883000376
[Epoch 2, Batch 700] loss: 0.23824677530676128
[Epoch 2, Batch 800] loss: 0.24726687114685775
[Epoch 2, Batch 900] loss: 0.23377913258969785
[Epoch 2, Batch 1000] loss: 0.24545918446034193
[Epoch 2, Batch 1100] loss: 0.19286039665341378
[Epoch 2, Batch 1200] loss: 0.22600426718592645
[Epoch 2, Batch 1300] loss: 0.22012502390891314
[Epoch 2, Batch 1400] loss: 0.21072371946647764
[Epoch 2, Batch 1500] loss: 0.20437899142503738
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1909
Validation Accuracy: 0.9426
Overfitting: 0.1909
[Epoch 3, Batch 100] loss: 0.1894463473930955
[Epoch 3, Batch 200] loss: 0.16212557991966606
[Epoch 3, Batch 300] loss: 0.1921286181733012
[Epoch 3, Batch 400] loss: 0.16743079839274289
[Epoch 3, Batch 500] loss: 0.17132348403334619
[Epoch 3, Batch 600] loss: 0.17030630199238658
[Epoch 3, Batch 700] loss: 0.16453492829576136
[Epoch 3, Batch 800] loss: 0.1568526802677661
[Epoch 3, Batch 900] loss: 0.1623988962545991
[Epoch 3, Batch 1000] loss: 0.14794506983831524
[Epoch 3, Batch 1100] loss: 0.13626340478658677
[Epoch 3, Batch 1200] loss: 0.1368194600008428
[Epoch 3, Batch 1300] loss: 0.11970104152336716
[Epoch 3, Batch 1400] loss: 0.12850220512598753
[Epoch 3, Batch 1500] loss: 0.14543102283030748
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1235
Validation Accuracy: 0.9640
Overfitting: 0.1235
[Epoch 4, Batch 100] loss: 0.12444674200378358
[Epoch 4, Batch 200] loss: 0.12285037264227867
[Epoch 4, Batch 300] loss: 0.1211612967774272
[Epoch 4, Batch 400] loss: 0.1350671744160354
[Epoch 4, Batch 500] loss: 0.12561852390877903
[Epoch 4, Batch 600] loss: 0.11827065219171345
[Epoch 4, Batch 700] loss: 0.11011963282478973
[Epoch 4, Batch 800] loss: 0.11598823156207799
[Epoch 4, Batch 900] loss: 0.11965760138817132
[Epoch 4, Batch 1000] loss: 0.12394824149087072
[Epoch 4, Batch 1100] loss: 0.09332293429411948
[Epoch 4, Batch 1200] loss: 0.10386828310322016
[Epoch 4, Batch 1300] loss: 0.0985775292199105
[Epoch 4, Batch 1400] loss: 0.10667717599309981
[Epoch 4, Batch 1500] loss: 0.10879677964840084
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0996
Validation Accuracy: 0.9712
Overfitting: 0.0996
[Epoch 5, Batch 100] loss: 0.08977138528600336
[Epoch 5, Batch 200] loss: 0.1022927973838523
[Epoch 5, Batch 300] loss: 0.09146593951620162
[Epoch 5, Batch 400] loss: 0.1038791942363605
[Epoch 5, Batch 500] loss: 0.10470695218537003
[Epoch 5, Batch 600] loss: 0.09729155001696199
[Epoch 5, Batch 700] loss: 0.10618909674696625
[Epoch 5, Batch 800] loss: 0.08701039534062147
[Epoch 5, Batch 900] loss: 0.09134611339308321
[Epoch 5, Batch 1000] loss: 0.07708256046753377
[Epoch 5, Batch 1100] loss: 0.08357774995267392
[Epoch 5, Batch 1200] loss: 0.08342786583583801
[Epoch 5, Batch 1300] loss: 0.08294866024050862
[Epoch 5, Batch 1400] loss: 0.09345014831982552
[Epoch 5, Batch 1500] loss: 0.09736961133545265
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0966
Validation Accuracy: 0.9721
Overfitting: 0.0966
[Epoch 6, Batch 100] loss: 0.0829651043843478
[Epoch 6, Batch 200] loss: 0.07916701380163431
[Epoch 6, Batch 300] loss: 0.07098706578137354
[Epoch 6, Batch 400] loss: 0.09310750402742997
[Epoch 6, Batch 500] loss: 0.07986622604075819
[Epoch 6, Batch 600] loss: 0.07843430826440453
[Epoch 6, Batch 700] loss: 0.08730948026757687
[Epoch 6, Batch 800] loss: 0.08485018572187983
[Epoch 6, Batch 900] loss: 0.08060320038814098
[Epoch 6, Batch 1000] loss: 0.06279105090536177
[Epoch 6, Batch 1100] loss: 0.09228132663993165
[Epoch 6, Batch 1200] loss: 0.07753017942421138
[Epoch 6, Batch 1300] loss: 0.0875850304402411
[Epoch 6, Batch 1400] loss: 0.08418793019838632
[Epoch 6, Batch 1500] loss: 0.07958280385937541
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0766
Validation Accuracy: 0.9771
Overfitting: 0.0766
[Epoch 7, Batch 100] loss: 0.07881032796576619
[Epoch 7, Batch 200] loss: 0.06707035072613507
[Epoch 7, Batch 300] loss: 0.07778892305679619
[Epoch 7, Batch 400] loss: 0.05906495882663876
[Epoch 7, Batch 500] loss: 0.0767210364388302
[Epoch 7, Batch 600] loss: 0.0722684101574123
[Epoch 7, Batch 700] loss: 0.07315235337242484
[Epoch 7, Batch 800] loss: 0.07113405264681205
[Epoch 7, Batch 900] loss: 0.06610127571038901
[Epoch 7, Batch 1000] loss: 0.07034024666296318
[Epoch 7, Batch 1100] loss: 0.07511464855168015
[Epoch 7, Batch 1200] loss: 0.07012805685866624
[Epoch 7, Batch 1300] loss: 0.07510715590557084
[Epoch 7, Batch 1400] loss: 0.06347805886296555
[Epoch 7, Batch 1500] loss: 0.06898512772517279
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0704
Validation Accuracy: 0.9788
Overfitting: 0.0704
[Epoch 8, Batch 100] loss: 0.07144003071356565
[Epoch 8, Batch 200] loss: 0.06575379066169262
[Epoch 8, Batch 300] loss: 0.06740903150523081
[Epoch 8, Batch 400] loss: 0.057398703235667196
[Epoch 8, Batch 500] loss: 0.06383925575995818
[Epoch 8, Batch 600] loss: 0.057266799034550786
[Epoch 8, Batch 700] loss: 0.07283377843908966
[Epoch 8, Batch 800] loss: 0.07933981240727007
[Epoch 8, Batch 900] loss: 0.06445616104174405
[Epoch 8, Batch 1000] loss: 0.07280309036606923
[Epoch 8, Batch 1100] loss: 0.055837650604080406
[Epoch 8, Batch 1200] loss: 0.054953245716169476
[Epoch 8, Batch 1300] loss: 0.05305642639519647
[Epoch 8, Batch 1400] loss: 0.06207041218876839
[Epoch 8, Batch 1500] loss: 0.07634130142396316
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0704
Validation Accuracy: 0.9791
Overfitting: 0.0704
[Epoch 9, Batch 100] loss: 0.060561158423661256
[Epoch 9, Batch 200] loss: 0.05456073885317892
[Epoch 9, Batch 300] loss: 0.061091681073885414
[Epoch 9, Batch 400] loss: 0.05438081289175898
[Epoch 9, Batch 500] loss: 0.064745243008947
[Epoch 9, Batch 600] loss: 0.05620713039184921
[Epoch 9, Batch 700] loss: 0.06328730849083514
[Epoch 9, Batch 800] loss: 0.05828489795094356
[Epoch 9, Batch 900] loss: 0.05215905867516994
[Epoch 9, Batch 1000] loss: 0.06870635860832408
[Epoch 9, Batch 1100] loss: 0.07089383737649768
[Epoch 9, Batch 1200] loss: 0.0716168184671551
[Epoch 9, Batch 1300] loss: 0.047390099641634154
[Epoch 9, Batch 1400] loss: 0.0511567977280356
[Epoch 9, Batch 1500] loss: 0.050726062434259804
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0620
Validation Accuracy: 0.9817
Overfitting: 0.0620
Best model saved at epoch 9 with validation loss: 0.0620
[Epoch 10, Batch 100] loss: 0.059749076042789964
[Epoch 10, Batch 200] loss: 0.04849806247744709
[Epoch 10, Batch 300] loss: 0.06323498453130014
[Epoch 10, Batch 400] loss: 0.05591209005797282
[Epoch 10, Batch 500] loss: 0.0412280486873351
[Epoch 10, Batch 600] loss: 0.055379288622643796
[Epoch 10, Batch 700] loss: 0.03885418273857795
[Epoch 10, Batch 800] loss: 0.05671142274979502
[Epoch 10, Batch 900] loss: 0.06655591134680434
[Epoch 10, Batch 1000] loss: 0.05626389279495925
[Epoch 10, Batch 1100] loss: 0.05243883808376268
[Epoch 10, Batch 1200] loss: 0.057195844122907145
[Epoch 10, Batch 1300] loss: 0.05217269550077617
[Epoch 10, Batch 1400] loss: 0.05612070132512599
[Epoch 10, Batch 1500] loss: 0.054912506183609364
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9830
Overfitting: 0.0573
[Epoch 11, Batch 100] loss: 0.047803219008492305
[Epoch 11, Batch 200] loss: 0.05642338631208986
[Epoch 11, Batch 300] loss: 0.051432668925262985
[Epoch 11, Batch 400] loss: 0.046350656133145096
[Epoch 11, Batch 500] loss: 0.04790833501552697
[Epoch 11, Batch 600] loss: 0.05257910757209174
[Epoch 11, Batch 700] loss: 0.046450500478968024
[Epoch 11, Batch 800] loss: 0.044958584003616124
[Epoch 11, Batch 900] loss: 0.051698285250458866
[Epoch 11, Batch 1000] loss: 0.05542325512156822
[Epoch 11, Batch 1100] loss: 0.05012498887488619
[Epoch 11, Batch 1200] loss: 0.03971570902969688
[Epoch 11, Batch 1300] loss: 0.05916927897080313
[Epoch 11, Batch 1400] loss: 0.049333137492649254
[Epoch 11, Batch 1500] loss: 0.05593402018886991
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0594
Validation Accuracy: 0.9816
Overfitting: 0.0594
Early stopping epoch 11 for trial 17. Moving to next fold.
Fold 5 validation loss: 0.0594
Mean validation loss across all folds for Trial 17 is 0.0632 with trial config:  l1: 256, l2: 128, lr: 0.0005, batch_size: 32
[I 2024-12-10 06:41:17,428] Trial 16 finished with value: 0.06319404902141541 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.0005, 'batch_size': 32}. Best is trial 12 with value: 0.0492618556785242.

Selected Hyperparameters for Trial 18:
  l1: 256, l2: 64, lr: 0.0001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.302649097442627
[Epoch 1, Batch 200] loss: 2.300967676639557
[Epoch 1, Batch 300] loss: 2.2972423672676086
[Epoch 1, Batch 400] loss: 2.2964268922805786
[Epoch 1, Batch 500] loss: 2.2935433840751647
[Epoch 1, Batch 600] loss: 2.287333836555481
[Epoch 1, Batch 700] loss: 2.2844086384773252
[Epoch 1, Batch 800] loss: 2.283602819442749
[Epoch 1, Batch 900] loss: 2.28039434671402
[Epoch 1, Batch 1000] loss: 2.2734180879592896
[Epoch 1, Batch 1100] loss: 2.269892635345459
[Epoch 1, Batch 1200] loss: 2.26421373128891
[Epoch 1, Batch 1300] loss: 2.259319305419922
[Epoch 1, Batch 1400] loss: 2.251071288585663
[Epoch 1, Batch 1500] loss: 2.242908639907837
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2370
Validation Accuracy: 0.2066
Overfitting: 2.2370
[Epoch 2, Batch 100] loss: 2.2319885444641114
[Epoch 2, Batch 200] loss: 2.2165846037864685
[Epoch 2, Batch 300] loss: 2.202686085700989
[Epoch 2, Batch 400] loss: 2.184774465560913
[Epoch 2, Batch 500] loss: 2.160921804904938
[Epoch 2, Batch 600] loss: 2.1312716388702393
[Epoch 2, Batch 700] loss: 2.094292092323303
[Epoch 2, Batch 800] loss: 2.0415428221225738
[Epoch 2, Batch 900] loss: 1.9869845807552338
[Epoch 2, Batch 1000] loss: 1.9098326408863067
[Epoch 2, Batch 1100] loss: 1.8264430809020995
[Epoch 2, Batch 1200] loss: 1.7367109990119933
[Epoch 2, Batch 1300] loss: 1.6190228688716888
[Epoch 2, Batch 1400] loss: 1.5090809607505797
[Epoch 2, Batch 1500] loss: 1.3734632050991058
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.2859
Validation Accuracy: 0.7213
Overfitting: 1.2859
[Epoch 3, Batch 100] loss: 1.2045198971033095
[Epoch 3, Batch 200] loss: 1.099964429140091
[Epoch 3, Batch 300] loss: 0.976102015376091
[Epoch 3, Batch 400] loss: 0.8809951502084732
[Epoch 3, Batch 500] loss: 0.8209886592626572
[Epoch 3, Batch 600] loss: 0.7520871710777283
[Epoch 3, Batch 700] loss: 0.6769145220518112
[Epoch 3, Batch 800] loss: 0.677340724170208
[Epoch 3, Batch 900] loss: 0.6396207454800605
[Epoch 3, Batch 1000] loss: 0.5783238384127617
[Epoch 3, Batch 1100] loss: 0.5529721355438233
[Epoch 3, Batch 1200] loss: 0.547061729580164
[Epoch 3, Batch 1300] loss: 0.5165848930180073
[Epoch 3, Batch 1400] loss: 0.5015568207204342
[Epoch 3, Batch 1500] loss: 0.48248537912964823
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.4621
Validation Accuracy: 0.8649
Overfitting: 0.4621
[Epoch 4, Batch 100] loss: 0.4592319056391716
[Epoch 4, Batch 200] loss: 0.4820213931798935
[Epoch 4, Batch 300] loss: 0.4460926964879036
[Epoch 4, Batch 400] loss: 0.4419155210256577
[Epoch 4, Batch 500] loss: 0.4561252833902836
[Epoch 4, Batch 600] loss: 0.44104879945516584
[Epoch 4, Batch 700] loss: 0.43078274458646776
[Epoch 4, Batch 800] loss: 0.41313270255923273
[Epoch 4, Batch 900] loss: 0.4193030135333538
[Epoch 4, Batch 1000] loss: 0.38561702236533163
[Epoch 4, Batch 1100] loss: 0.3787875305116177
[Epoch 4, Batch 1200] loss: 0.38342080131173134
[Epoch 4, Batch 1300] loss: 0.3733310731500387
[Epoch 4, Batch 1400] loss: 0.38309834510087964
[Epoch 4, Batch 1500] loss: 0.3807287812232971
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3504
Validation Accuracy: 0.8920
Overfitting: 0.3504
[Epoch 5, Batch 100] loss: 0.3430411921441555
[Epoch 5, Batch 200] loss: 0.3513113538175821
[Epoch 5, Batch 300] loss: 0.3558455927670002
[Epoch 5, Batch 400] loss: 0.34749224931001665
[Epoch 5, Batch 500] loss: 0.35899870105087756
[Epoch 5, Batch 600] loss: 0.3558778318017721
[Epoch 5, Batch 700] loss: 0.35187589973211286
[Epoch 5, Batch 800] loss: 0.29809678830206393
[Epoch 5, Batch 900] loss: 0.31663738034665584
[Epoch 5, Batch 1000] loss: 0.353644795268774
[Epoch 5, Batch 1100] loss: 0.3269014125317335
[Epoch 5, Batch 1200] loss: 0.31647212386131285
[Epoch 5, Batch 1300] loss: 0.29983249567449094
[Epoch 5, Batch 1400] loss: 0.3046160442382097
[Epoch 5, Batch 1500] loss: 0.3359279376268387
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.2898
Validation Accuracy: 0.9122
Overfitting: 0.2898
[Epoch 6, Batch 100] loss: 0.3003251638263464
[Epoch 6, Batch 200] loss: 0.29881589315831664
[Epoch 6, Batch 300] loss: 0.3079838498681784
[Epoch 6, Batch 400] loss: 0.28818697698414325
[Epoch 6, Batch 500] loss: 0.3011861261725426
[Epoch 6, Batch 600] loss: 0.26981901470571756
[Epoch 6, Batch 700] loss: 0.2802621781080961
[Epoch 6, Batch 800] loss: 0.29235668800771236
[Epoch 6, Batch 900] loss: 0.2860686706006527
[Epoch 6, Batch 1000] loss: 0.29666447304189203
[Epoch 6, Batch 1100] loss: 0.28511569209396836
[Epoch 6, Batch 1200] loss: 0.2657196562737226
[Epoch 6, Batch 1300] loss: 0.2596819829568267
[Epoch 6, Batch 1400] loss: 0.26614586770534515
[Epoch 6, Batch 1500] loss: 0.26991712298244236
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2469
Validation Accuracy: 0.9258
Overfitting: 0.2469
[Epoch 7, Batch 100] loss: 0.2689231092482805
[Epoch 7, Batch 200] loss: 0.2537549459189177
[Epoch 7, Batch 300] loss: 0.2688203195855021
[Epoch 7, Batch 400] loss: 0.23792045023292302
[Epoch 7, Batch 500] loss: 0.24897066123783587
[Epoch 7, Batch 600] loss: 0.2382112792506814
[Epoch 7, Batch 700] loss: 0.2661204485967755
[Epoch 7, Batch 800] loss: 0.245735135525465
[Epoch 7, Batch 900] loss: 0.2610707175731659
[Epoch 7, Batch 1000] loss: 0.2606423528492451
[Epoch 7, Batch 1100] loss: 0.23209270488470793
[Epoch 7, Batch 1200] loss: 0.2461198304221034
[Epoch 7, Batch 1300] loss: 0.21785481739789248
[Epoch 7, Batch 1400] loss: 0.2192284619435668
[Epoch 7, Batch 1500] loss: 0.24250979773700237
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2169
Validation Accuracy: 0.9366
Overfitting: 0.2169
[Epoch 8, Batch 100] loss: 0.2623434552922845
[Epoch 8, Batch 200] loss: 0.21287890177220106
[Epoch 8, Batch 300] loss: 0.23341846968978644
[Epoch 8, Batch 400] loss: 0.22550893343985082
[Epoch 8, Batch 500] loss: 0.23512112095952034
[Epoch 8, Batch 600] loss: 0.23062047185376286
[Epoch 8, Batch 700] loss: 0.21370072960853576
[Epoch 8, Batch 800] loss: 0.2185031570121646
[Epoch 8, Batch 900] loss: 0.21623071536421776
[Epoch 8, Batch 1000] loss: 0.21871940290555358
[Epoch 8, Batch 1100] loss: 0.18726794730871915
[Epoch 8, Batch 1200] loss: 0.2146669802069664
[Epoch 8, Batch 1300] loss: 0.1846462121233344
[Epoch 8, Batch 1400] loss: 0.2284403173625469
[Epoch 8, Batch 1500] loss: 0.21408202830702067
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.1933
Validation Accuracy: 0.9415
Overfitting: 0.1933
[Epoch 9, Batch 100] loss: 0.2080093103647232
[Epoch 9, Batch 200] loss: 0.20192480333149432
[Epoch 9, Batch 300] loss: 0.21458464238792657
[Epoch 9, Batch 400] loss: 0.19463334307074548
[Epoch 9, Batch 500] loss: 0.18212233910337092
[Epoch 9, Batch 600] loss: 0.21467569306492806
[Epoch 9, Batch 700] loss: 0.20486756309866905
[Epoch 9, Batch 800] loss: 0.20233836023136972
[Epoch 9, Batch 900] loss: 0.17667092584073543
[Epoch 9, Batch 1000] loss: 0.1972972207516432
[Epoch 9, Batch 1100] loss: 0.19383783660829068
[Epoch 9, Batch 1200] loss: 0.2046645430289209
[Epoch 9, Batch 1300] loss: 0.2034733834862709
[Epoch 9, Batch 1400] loss: 0.1703352335654199
[Epoch 9, Batch 1500] loss: 0.19089117243885995
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1732
Validation Accuracy: 0.9488
Overfitting: 0.1732
Best model saved at epoch 9 with validation loss: 0.1732
[Epoch 10, Batch 100] loss: 0.18338112689554692
[Epoch 10, Batch 200] loss: 0.17503288021311164
[Epoch 10, Batch 300] loss: 0.19534038078039884
[Epoch 10, Batch 400] loss: 0.17723882235586644
[Epoch 10, Batch 500] loss: 0.19015710543841124
[Epoch 10, Batch 600] loss: 0.17734691462479532
[Epoch 10, Batch 700] loss: 0.1950312303006649
[Epoch 10, Batch 800] loss: 0.18413764342665673
[Epoch 10, Batch 900] loss: 0.19117661483585835
[Epoch 10, Batch 1000] loss: 0.1910616873204708
[Epoch 10, Batch 1100] loss: 0.17302844028919936
[Epoch 10, Batch 1200] loss: 0.15545642454177142
[Epoch 10, Batch 1300] loss: 0.15595356516540052
[Epoch 10, Batch 1400] loss: 0.16485122215002776
[Epoch 10, Batch 1500] loss: 0.1786746312957257
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1684
Validation Accuracy: 0.9487
Overfitting: 0.1684
[Epoch 11, Batch 100] loss: 0.1606098249927163
[Epoch 11, Batch 200] loss: 0.16999282414093614
[Epoch 11, Batch 300] loss: 0.16890294432640077
[Epoch 11, Batch 400] loss: 0.15987642491236329
[Epoch 11, Batch 500] loss: 0.1650807093270123
[Epoch 11, Batch 600] loss: 0.16241127249784768
[Epoch 11, Batch 700] loss: 0.17329207595437765
[Epoch 11, Batch 800] loss: 0.15609065936878325
[Epoch 11, Batch 900] loss: 0.1725270793400705
[Epoch 11, Batch 1000] loss: 0.16392005074769259
[Epoch 11, Batch 1100] loss: 0.16563574476167559
[Epoch 11, Batch 1200] loss: 0.16144491884857415
[Epoch 11, Batch 1300] loss: 0.16790125664323569
[Epoch 11, Batch 1400] loss: 0.15168842216953635
[Epoch 11, Batch 1500] loss: 0.1512723756209016
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1446
Validation Accuracy: 0.9569
Overfitting: 0.1446
Early stopping epoch 11 for trial 18. Moving to next fold.
Fold 1 validation loss: 0.1446
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.3050424242019654
[Epoch 1, Batch 200] loss: 2.304574735164642
[Epoch 1, Batch 300] loss: 2.3037269353866576
[Epoch 1, Batch 400] loss: 2.2996478128433226
[Epoch 1, Batch 500] loss: 2.2974186730384827
[Epoch 1, Batch 600] loss: 2.295817036628723
[Epoch 1, Batch 700] loss: 2.292443161010742
[Epoch 1, Batch 800] loss: 2.291380388736725
[Epoch 1, Batch 900] loss: 2.289508755207062
[Epoch 1, Batch 1000] loss: 2.2863392138481142
[Epoch 1, Batch 1100] loss: 2.2840582156181335
[Epoch 1, Batch 1200] loss: 2.2817268133163453
[Epoch 1, Batch 1300] loss: 2.2810316491127014
[Epoch 1, Batch 1400] loss: 2.273973641395569
[Epoch 1, Batch 1500] loss: 2.2691425395011904
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2677
Validation Accuracy: 0.1812
Overfitting: 2.2677
[Epoch 2, Batch 100] loss: 2.2657301592826844
[Epoch 2, Batch 200] loss: 2.2603028655052184
[Epoch 2, Batch 300] loss: 2.2561764097213746
[Epoch 2, Batch 400] loss: 2.2492478036880494
[Epoch 2, Batch 500] loss: 2.243339285850525
[Epoch 2, Batch 600] loss: 2.233105945587158
[Epoch 2, Batch 700] loss: 2.2258154821395872
[Epoch 2, Batch 800] loss: 2.213037347793579
[Epoch 2, Batch 900] loss: 2.1979875421524047
[Epoch 2, Batch 1000] loss: 2.1786939883232117
[Epoch 2, Batch 1100] loss: 2.1565786719322206
[Epoch 2, Batch 1200] loss: 2.1262309432029722
[Epoch 2, Batch 1300] loss: 2.102594337463379
[Epoch 2, Batch 1400] loss: 2.0512731957435606
[Epoch 2, Batch 1500] loss: 2.001263256072998
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.9660
Validation Accuracy: 0.5581
Overfitting: 1.9660
[Epoch 3, Batch 100] loss: 1.9201923203468323
[Epoch 3, Batch 200] loss: 1.8372990322113036
[Epoch 3, Batch 300] loss: 1.6960745084285735
[Epoch 3, Batch 400] loss: 1.542376046180725
[Epoch 3, Batch 500] loss: 1.384868675470352
[Epoch 3, Batch 600] loss: 1.2120752286911012
[Epoch 3, Batch 700] loss: 1.08294684112072
[Epoch 3, Batch 800] loss: 0.9650948703289032
[Epoch 3, Batch 900] loss: 0.8583789956569672
[Epoch 3, Batch 1000] loss: 0.7973154681921005
[Epoch 3, Batch 1100] loss: 0.7516230100393295
[Epoch 3, Batch 1200] loss: 0.7100068375468254
[Epoch 3, Batch 1300] loss: 0.6411531847715378
[Epoch 3, Batch 1400] loss: 0.6538536205887795
[Epoch 3, Batch 1500] loss: 0.6116519278287887
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.6193
Validation Accuracy: 0.8176
Overfitting: 0.6193
[Epoch 4, Batch 100] loss: 0.5669319739937783
[Epoch 4, Batch 200] loss: 0.5560742932558059
[Epoch 4, Batch 300] loss: 0.5624747115373612
[Epoch 4, Batch 400] loss: 0.5332722374796868
[Epoch 4, Batch 500] loss: 0.499971277564764
[Epoch 4, Batch 600] loss: 0.5289188504219056
[Epoch 4, Batch 700] loss: 0.5024540865421295
[Epoch 4, Batch 800] loss: 0.4859566830098629
[Epoch 4, Batch 900] loss: 0.4850392770767212
[Epoch 4, Batch 1000] loss: 0.47435534283518793
[Epoch 4, Batch 1100] loss: 0.4747478340566158
[Epoch 4, Batch 1200] loss: 0.46613708660006525
[Epoch 4, Batch 1300] loss: 0.42593229696154594
[Epoch 4, Batch 1400] loss: 0.4357334101200104
[Epoch 4, Batch 1500] loss: 0.41862032979726793
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.4392
Validation Accuracy: 0.8703
Overfitting: 0.4392
[Epoch 5, Batch 100] loss: 0.4335692772269249
[Epoch 5, Batch 200] loss: 0.4103046618402004
[Epoch 5, Batch 300] loss: 0.4046997004747391
[Epoch 5, Batch 400] loss: 0.4038435597717762
[Epoch 5, Batch 500] loss: 0.3731582801043987
[Epoch 5, Batch 600] loss: 0.3570784544199705
[Epoch 5, Batch 700] loss: 0.39163519307971
[Epoch 5, Batch 800] loss: 0.383306919336319
[Epoch 5, Batch 900] loss: 0.39335903838276864
[Epoch 5, Batch 1000] loss: 0.372532878741622
[Epoch 5, Batch 1100] loss: 0.3718312037736177
[Epoch 5, Batch 1200] loss: 0.35747764304280283
[Epoch 5, Batch 1300] loss: 0.39679063722491265
[Epoch 5, Batch 1400] loss: 0.3491824235767126
[Epoch 5, Batch 1500] loss: 0.3289837438613176
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3734
Validation Accuracy: 0.8901
Overfitting: 0.3734
[Epoch 6, Batch 100] loss: 0.3351011266559362
[Epoch 6, Batch 200] loss: 0.33687445051968096
[Epoch 6, Batch 300] loss: 0.3568526476621628
[Epoch 6, Batch 400] loss: 0.3379323247820139
[Epoch 6, Batch 500] loss: 0.30363726664334534
[Epoch 6, Batch 600] loss: 0.2976047320663929
[Epoch 6, Batch 700] loss: 0.3220694901049137
[Epoch 6, Batch 800] loss: 0.33913137689232825
[Epoch 6, Batch 900] loss: 0.3121187754720449
[Epoch 6, Batch 1000] loss: 0.3238808848708868
[Epoch 6, Batch 1100] loss: 0.3024682709574699
[Epoch 6, Batch 1200] loss: 0.30990432657301425
[Epoch 6, Batch 1300] loss: 0.3133285678178072
[Epoch 6, Batch 1400] loss: 0.2983071330189705
[Epoch 6, Batch 1500] loss: 0.2874054731428623
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.3219
Validation Accuracy: 0.9023
Overfitting: 0.3219
[Epoch 7, Batch 100] loss: 0.26979402706027034
[Epoch 7, Batch 200] loss: 0.28812790974974634
[Epoch 7, Batch 300] loss: 0.2981695377826691
[Epoch 7, Batch 400] loss: 0.2828593289852142
[Epoch 7, Batch 500] loss: 0.27788020130246877
[Epoch 7, Batch 600] loss: 0.2909975362569094
[Epoch 7, Batch 700] loss: 0.26573608197271825
[Epoch 7, Batch 800] loss: 0.2545126223936677
[Epoch 7, Batch 900] loss: 0.2786951335892081
[Epoch 7, Batch 1000] loss: 0.24846329778432846
[Epoch 7, Batch 1100] loss: 0.25332200691103934
[Epoch 7, Batch 1200] loss: 0.26597846575081346
[Epoch 7, Batch 1300] loss: 0.258584184423089
[Epoch 7, Batch 1400] loss: 0.2581756131350994
[Epoch 7, Batch 1500] loss: 0.2667332203499973
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2629
Validation Accuracy: 0.9218
Overfitting: 0.2629
[Epoch 8, Batch 100] loss: 0.2556286892294884
[Epoch 8, Batch 200] loss: 0.2416821939498186
[Epoch 8, Batch 300] loss: 0.24689408015459777
[Epoch 8, Batch 400] loss: 0.2636901541054249
[Epoch 8, Batch 500] loss: 0.24353903263807297
[Epoch 8, Batch 600] loss: 0.24468616608530283
[Epoch 8, Batch 700] loss: 0.22539877213537693
[Epoch 8, Batch 800] loss: 0.23484472051262856
[Epoch 8, Batch 900] loss: 0.20995293151587247
[Epoch 8, Batch 1000] loss: 0.23817552112042903
[Epoch 8, Batch 1100] loss: 0.23750012751668692
[Epoch 8, Batch 1200] loss: 0.2135883419960737
[Epoch 8, Batch 1300] loss: 0.22391997307538986
[Epoch 8, Batch 1400] loss: 0.22685544252395629
[Epoch 8, Batch 1500] loss: 0.21094092920422555
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2294
Validation Accuracy: 0.9337
Overfitting: 0.2294
[Epoch 9, Batch 100] loss: 0.22157868705689907
[Epoch 9, Batch 200] loss: 0.20328721351921558
[Epoch 9, Batch 300] loss: 0.19102212104946376
[Epoch 9, Batch 400] loss: 0.2179224754497409
[Epoch 9, Batch 500] loss: 0.22630177441984414
[Epoch 9, Batch 600] loss: 0.21101232886314392
[Epoch 9, Batch 700] loss: 0.2128760251402855
[Epoch 9, Batch 800] loss: 0.1932031412050128
[Epoch 9, Batch 900] loss: 0.20576848547905682
[Epoch 9, Batch 1000] loss: 0.1947358936816454
[Epoch 9, Batch 1100] loss: 0.1965732917934656
[Epoch 9, Batch 1200] loss: 0.2052445247396827
[Epoch 9, Batch 1300] loss: 0.2047927288338542
[Epoch 9, Batch 1400] loss: 0.20040371764451265
[Epoch 9, Batch 1500] loss: 0.19376010738313199
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.2056
Validation Accuracy: 0.9402
Overfitting: 0.2056
Best model saved at epoch 9 with validation loss: 0.2056
[Epoch 10, Batch 100] loss: 0.20081641722470522
[Epoch 10, Batch 200] loss: 0.18558757660910488
[Epoch 10, Batch 300] loss: 0.17338715935125948
[Epoch 10, Batch 400] loss: 0.19590163139626385
[Epoch 10, Batch 500] loss: 0.176348094381392
[Epoch 10, Batch 600] loss: 0.19003987904638053
[Epoch 10, Batch 700] loss: 0.18892194095999001
[Epoch 10, Batch 800] loss: 0.17001649161800741
[Epoch 10, Batch 900] loss: 0.1947952602431178
[Epoch 10, Batch 1000] loss: 0.1799995932355523
[Epoch 10, Batch 1100] loss: 0.192799716219306
[Epoch 10, Batch 1200] loss: 0.1702572288364172
[Epoch 10, Batch 1300] loss: 0.1752505241893232
[Epoch 10, Batch 1400] loss: 0.167662473320961
[Epoch 10, Batch 1500] loss: 0.1667341618798673
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1833
Validation Accuracy: 0.9445
Overfitting: 0.1833
[Epoch 11, Batch 100] loss: 0.17317878048866986
[Epoch 11, Batch 200] loss: 0.1645736673846841
[Epoch 11, Batch 300] loss: 0.15899638997390866
[Epoch 11, Batch 400] loss: 0.15914618700742722
[Epoch 11, Batch 500] loss: 0.16875311195850373
[Epoch 11, Batch 600] loss: 0.1816130991652608
[Epoch 11, Batch 700] loss: 0.1706864841002971
[Epoch 11, Batch 800] loss: 0.1691917302645743
[Epoch 11, Batch 900] loss: 0.1627586145326495
[Epoch 11, Batch 1000] loss: 0.17824484258890153
[Epoch 11, Batch 1100] loss: 0.16063308173790575
[Epoch 11, Batch 1200] loss: 0.1527735373750329
[Epoch 11, Batch 1300] loss: 0.1434904995933175
[Epoch 11, Batch 1400] loss: 0.17074636472389101
[Epoch 11, Batch 1500] loss: 0.14807831656187773
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1670
Validation Accuracy: 0.9502
Overfitting: 0.1670
Best model saved at epoch 11 with validation loss: 0.1670
[Epoch 12, Batch 100] loss: 0.1449568712245673
[Epoch 12, Batch 200] loss: 0.13707914086058737
[Epoch 12, Batch 300] loss: 0.1538307996094227
[Epoch 12, Batch 400] loss: 0.1586108174175024
[Epoch 12, Batch 500] loss: 0.15241632517427206
[Epoch 12, Batch 600] loss: 0.15961301675066353
[Epoch 12, Batch 700] loss: 0.14133203509263695
[Epoch 12, Batch 800] loss: 0.1646596832945943
[Epoch 12, Batch 900] loss: 0.14670128762722015
[Epoch 12, Batch 1000] loss: 0.16333881875500084
[Epoch 12, Batch 1100] loss: 0.14357551419176162
[Epoch 12, Batch 1200] loss: 0.14735693901777266
[Epoch 12, Batch 1300] loss: 0.14467959156259894
[Epoch 12, Batch 1400] loss: 0.1412168549373746
[Epoch 12, Batch 1500] loss: 0.13489446967840193
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1543
Validation Accuracy: 0.9523
Overfitting: 0.1543
[Epoch 13, Batch 100] loss: 0.13787341440096498
[Epoch 13, Batch 200] loss: 0.1368037173524499
[Epoch 13, Batch 300] loss: 0.15596463452093304
[Epoch 13, Batch 400] loss: 0.13323156410828232
[Epoch 13, Batch 500] loss: 0.12620972373522818
[Epoch 13, Batch 600] loss: 0.14019420087337495
[Epoch 13, Batch 700] loss: 0.13833818449638785
[Epoch 13, Batch 800] loss: 0.13229022288694978
[Epoch 13, Batch 900] loss: 0.13642924369312823
[Epoch 13, Batch 1000] loss: 0.13678001476451754
[Epoch 13, Batch 1100] loss: 0.14510295424610375
[Epoch 13, Batch 1200] loss: 0.12766604809090495
[Epoch 13, Batch 1300] loss: 0.14081266513094307
[Epoch 13, Batch 1400] loss: 0.12848786586895586
[Epoch 13, Batch 1500] loss: 0.12963911691680552
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1453
Validation Accuracy: 0.9563
Overfitting: 0.1453
Early stopping epoch 13 for trial 18. Moving to next fold.
Fold 2 validation loss: 0.1453
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3056926918029785
[Epoch 1, Batch 200] loss: 2.3042823600769045
[Epoch 1, Batch 300] loss: 2.300309841632843
[Epoch 1, Batch 400] loss: 2.297910897731781
[Epoch 1, Batch 500] loss: 2.2957300090789796
[Epoch 1, Batch 600] loss: 2.2954803895950318
[Epoch 1, Batch 700] loss: 2.2890778493881228
[Epoch 1, Batch 800] loss: 2.2885821151733396
[Epoch 1, Batch 900] loss: 2.2862573790550234
[Epoch 1, Batch 1000] loss: 2.282632219791412
[Epoch 1, Batch 1100] loss: 2.2829500818252564
[Epoch 1, Batch 1200] loss: 2.276758198738098
[Epoch 1, Batch 1300] loss: 2.2744970107078553
[Epoch 1, Batch 1400] loss: 2.272906627655029
[Epoch 1, Batch 1500] loss: 2.2663040113449098
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2650
Validation Accuracy: 0.1876
Overfitting: 2.2650
[Epoch 2, Batch 100] loss: 2.2608347082138063
[Epoch 2, Batch 200] loss: 2.2570858669281004
[Epoch 2, Batch 300] loss: 2.253075077533722
[Epoch 2, Batch 400] loss: 2.245637230873108
[Epoch 2, Batch 500] loss: 2.241140263080597
[Epoch 2, Batch 600] loss: 2.2335371708869936
[Epoch 2, Batch 700] loss: 2.224798815250397
[Epoch 2, Batch 800] loss: 2.2115660285949708
[Epoch 2, Batch 900] loss: 2.1949419808387756
[Epoch 2, Batch 1000] loss: 2.1813770604133604
[Epoch 2, Batch 1100] loss: 2.1622530579566956
[Epoch 2, Batch 1200] loss: 2.142280869483948
[Epoch 2, Batch 1300] loss: 2.1097759056091308
[Epoch 2, Batch 1400] loss: 2.0714847004413603
[Epoch 2, Batch 1500] loss: 2.019076837301254
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.9924
Validation Accuracy: 0.5284
Overfitting: 1.9924
[Epoch 3, Batch 100] loss: 1.9664681506156922
[Epoch 3, Batch 200] loss: 1.878362786769867
[Epoch 3, Batch 300] loss: 1.7812663853168487
[Epoch 3, Batch 400] loss: 1.6552240204811097
[Epoch 3, Batch 500] loss: 1.485975009202957
[Epoch 3, Batch 600] loss: 1.3451237487792969
[Epoch 3, Batch 700] loss: 1.2034291172027587
[Epoch 3, Batch 800] loss: 1.0404932326078415
[Epoch 3, Batch 900] loss: 0.932737808227539
[Epoch 3, Batch 1000] loss: 0.8452927190065384
[Epoch 3, Batch 1100] loss: 0.7730577823519706
[Epoch 3, Batch 1200] loss: 0.7126152694225312
[Epoch 3, Batch 1300] loss: 0.6522497779130936
[Epoch 3, Batch 1400] loss: 0.6360261002182961
[Epoch 3, Batch 1500] loss: 0.6051165890693665
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.5687
Validation Accuracy: 0.8418
Overfitting: 0.5687
[Epoch 4, Batch 100] loss: 0.576029708981514
[Epoch 4, Batch 200] loss: 0.5478222018480301
[Epoch 4, Batch 300] loss: 0.5077560013532638
[Epoch 4, Batch 400] loss: 0.5049649307131767
[Epoch 4, Batch 500] loss: 0.4728186784684658
[Epoch 4, Batch 600] loss: 0.4732233683764935
[Epoch 4, Batch 700] loss: 0.45795459896326063
[Epoch 4, Batch 800] loss: 0.4322068032622337
[Epoch 4, Batch 900] loss: 0.45010404378175733
[Epoch 4, Batch 1000] loss: 0.4341161985695362
[Epoch 4, Batch 1100] loss: 0.4163283258676529
[Epoch 4, Batch 1200] loss: 0.4047625333070755
[Epoch 4, Batch 1300] loss: 0.4072335904836655
[Epoch 4, Batch 1400] loss: 0.3678586642444134
[Epoch 4, Batch 1500] loss: 0.37016830161213876
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3680
Validation Accuracy: 0.8970
Overfitting: 0.3680
[Epoch 5, Batch 100] loss: 0.3528704822808504
[Epoch 5, Batch 200] loss: 0.3722323892265558
[Epoch 5, Batch 300] loss: 0.36039380080997946
[Epoch 5, Batch 400] loss: 0.3551978889852762
[Epoch 5, Batch 500] loss: 0.3511450032144785
[Epoch 5, Batch 600] loss: 0.3490210596472025
[Epoch 5, Batch 700] loss: 0.3228545582294464
[Epoch 5, Batch 800] loss: 0.33919422805309296
[Epoch 5, Batch 900] loss: 0.33331902146339415
[Epoch 5, Batch 1000] loss: 0.298414536267519
[Epoch 5, Batch 1100] loss: 0.3085668946057558
[Epoch 5, Batch 1200] loss: 0.3147702009230852
[Epoch 5, Batch 1300] loss: 0.3227013649791479
[Epoch 5, Batch 1400] loss: 0.3069967430084944
[Epoch 5, Batch 1500] loss: 0.29094013579189776
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.2900
Validation Accuracy: 0.9169
Overfitting: 0.2900
[Epoch 6, Batch 100] loss: 0.2791443283855915
[Epoch 6, Batch 200] loss: 0.28205769322812557
[Epoch 6, Batch 300] loss: 0.2990200129151344
[Epoch 6, Batch 400] loss: 0.287274420298636
[Epoch 6, Batch 500] loss: 0.2928763781487942
[Epoch 6, Batch 600] loss: 0.2563471232354641
[Epoch 6, Batch 700] loss: 0.2852391643822193
[Epoch 6, Batch 800] loss: 0.2719161493331194
[Epoch 6, Batch 900] loss: 0.26436713460832834
[Epoch 6, Batch 1000] loss: 0.25277031093835833
[Epoch 6, Batch 1100] loss: 0.26515901282429694
[Epoch 6, Batch 1200] loss: 0.2651300187408924
[Epoch 6, Batch 1300] loss: 0.2494377576559782
[Epoch 6, Batch 1400] loss: 0.2519744593650103
[Epoch 6, Batch 1500] loss: 0.23989403393119574
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2437
Validation Accuracy: 0.9283
Overfitting: 0.2437
[Epoch 7, Batch 100] loss: 0.2343905345350504
[Epoch 7, Batch 200] loss: 0.24258858136832714
[Epoch 7, Batch 300] loss: 0.24035359550267457
[Epoch 7, Batch 400] loss: 0.2363779689744115
[Epoch 7, Batch 500] loss: 0.23042284891009332
[Epoch 7, Batch 600] loss: 0.2306247006729245
[Epoch 7, Batch 700] loss: 0.22528309013694525
[Epoch 7, Batch 800] loss: 0.22878720290958882
[Epoch 7, Batch 900] loss: 0.2453959535062313
[Epoch 7, Batch 1000] loss: 0.23332124710083008
[Epoch 7, Batch 1100] loss: 0.23020290657877923
[Epoch 7, Batch 1200] loss: 0.22021651044487953
[Epoch 7, Batch 1300] loss: 0.2112422377243638
[Epoch 7, Batch 1400] loss: 0.21364735862240194
[Epoch 7, Batch 1500] loss: 0.210457429215312
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2141
Validation Accuracy: 0.9397
Overfitting: 0.2141
[Epoch 8, Batch 100] loss: 0.1979876696318388
[Epoch 8, Batch 200] loss: 0.20093353739008307
[Epoch 8, Batch 300] loss: 0.20451885014772414
[Epoch 8, Batch 400] loss: 0.21382576398551464
[Epoch 8, Batch 500] loss: 0.18056258756667376
[Epoch 8, Batch 600] loss: 0.20499646708369254
[Epoch 8, Batch 700] loss: 0.20949046611785888
[Epoch 8, Batch 800] loss: 0.20746851436793803
[Epoch 8, Batch 900] loss: 0.2043784864805639
[Epoch 8, Batch 1000] loss: 0.1785817542858422
[Epoch 8, Batch 1100] loss: 0.18829255118966104
[Epoch 8, Batch 1200] loss: 0.22010777490213512
[Epoch 8, Batch 1300] loss: 0.193392659612
[Epoch 8, Batch 1400] loss: 0.18641916032880546
[Epoch 8, Batch 1500] loss: 0.19877529975026845
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.1894
Validation Accuracy: 0.9446
Overfitting: 0.1894
[Epoch 9, Batch 100] loss: 0.17256487883627414
[Epoch 9, Batch 200] loss: 0.2109088857844472
[Epoch 9, Batch 300] loss: 0.1833611626178026
[Epoch 9, Batch 400] loss: 0.19038181085139513
[Epoch 9, Batch 500] loss: 0.192615484893322
[Epoch 9, Batch 600] loss: 0.18271483274176717
[Epoch 9, Batch 700] loss: 0.17012107452377678
[Epoch 9, Batch 800] loss: 0.1646864976733923
[Epoch 9, Batch 900] loss: 0.17530281972140074
[Epoch 9, Batch 1000] loss: 0.1836987983249128
[Epoch 9, Batch 1100] loss: 0.17968441914767028
[Epoch 9, Batch 1200] loss: 0.16450273746624589
[Epoch 9, Batch 1300] loss: 0.15735726609826087
[Epoch 9, Batch 1400] loss: 0.16744184371083976
[Epoch 9, Batch 1500] loss: 0.16799895878881216
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1765
Validation Accuracy: 0.9485
Overfitting: 0.1765
Best model saved at epoch 9 with validation loss: 0.1765
[Epoch 10, Batch 100] loss: 0.18114707494154572
[Epoch 10, Batch 200] loss: 0.1710990424454212
[Epoch 10, Batch 300] loss: 0.16876603592187167
[Epoch 10, Batch 400] loss: 0.16072955697774888
[Epoch 10, Batch 500] loss: 0.1665696935914457
[Epoch 10, Batch 600] loss: 0.17939995450899004
[Epoch 10, Batch 700] loss: 0.15598030334338545
[Epoch 10, Batch 800] loss: 0.16951689384877683
[Epoch 10, Batch 900] loss: 0.14763273868709803
[Epoch 10, Batch 1000] loss: 0.1537673531845212
[Epoch 10, Batch 1100] loss: 0.16586313975974917
[Epoch 10, Batch 1200] loss: 0.15849780013784767
[Epoch 10, Batch 1300] loss: 0.1483967637270689
[Epoch 10, Batch 1400] loss: 0.1446383626293391
[Epoch 10, Batch 1500] loss: 0.13890100756660104
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1635
Validation Accuracy: 0.9534
Overfitting: 0.1635
[Epoch 11, Batch 100] loss: 0.147983794817701
[Epoch 11, Batch 200] loss: 0.1406711571663618
[Epoch 11, Batch 300] loss: 0.15242780527099967
[Epoch 11, Batch 400] loss: 0.14400468377396464
[Epoch 11, Batch 500] loss: 0.15289504338987173
[Epoch 11, Batch 600] loss: 0.16200999973341823
[Epoch 11, Batch 700] loss: 0.17450192742049694
[Epoch 11, Batch 800] loss: 0.13376965773291885
[Epoch 11, Batch 900] loss: 0.15662989176809788
[Epoch 11, Batch 1000] loss: 0.15209403577260672
[Epoch 11, Batch 1100] loss: 0.1405923340842128
[Epoch 11, Batch 1200] loss: 0.12239038122817875
[Epoch 11, Batch 1300] loss: 0.14522754865698517
[Epoch 11, Batch 1400] loss: 0.14571876511909068
[Epoch 11, Batch 1500] loss: 0.14143283549696206
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1449
Validation Accuracy: 0.9570
Overfitting: 0.1449
Best model saved at epoch 11 with validation loss: 0.1449
[Epoch 12, Batch 100] loss: 0.12910923598334192
[Epoch 12, Batch 200] loss: 0.14951433580368756
[Epoch 12, Batch 300] loss: 0.13475570878013968
[Epoch 12, Batch 400] loss: 0.14258800197392701
[Epoch 12, Batch 500] loss: 0.1376451797410846
[Epoch 12, Batch 600] loss: 0.1341684140264988
[Epoch 12, Batch 700] loss: 0.1390106022451073
[Epoch 12, Batch 800] loss: 0.11300840236246586
[Epoch 12, Batch 900] loss: 0.13318672828376293
[Epoch 12, Batch 1000] loss: 0.1430878686159849
[Epoch 12, Batch 1100] loss: 0.1304741457477212
[Epoch 12, Batch 1200] loss: 0.12851544331759215
[Epoch 12, Batch 1300] loss: 0.14983056604862213
[Epoch 12, Batch 1400] loss: 0.12683054552413522
[Epoch 12, Batch 1500] loss: 0.15742651568725705
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1393
Validation Accuracy: 0.9588
Overfitting: 0.1393
[Epoch 13, Batch 100] loss: 0.1423638725746423
[Epoch 13, Batch 200] loss: 0.127108697257936
[Epoch 13, Batch 300] loss: 0.14210398362949492
[Epoch 13, Batch 400] loss: 0.1426920211967081
[Epoch 13, Batch 500] loss: 0.14459956211037933
[Epoch 13, Batch 600] loss: 0.13109181854873897
[Epoch 13, Batch 700] loss: 0.11187304696068168
[Epoch 13, Batch 800] loss: 0.1227986778691411
[Epoch 13, Batch 900] loss: 0.11864793177694083
[Epoch 13, Batch 1000] loss: 0.13123072105459868
[Epoch 13, Batch 1100] loss: 0.12431740357540548
[Epoch 13, Batch 1200] loss: 0.11911663210950792
[Epoch 13, Batch 1300] loss: 0.12196111653000116
[Epoch 13, Batch 1400] loss: 0.12147626827470959
[Epoch 13, Batch 1500] loss: 0.11805217223241925
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1300
Validation Accuracy: 0.9623
Overfitting: 0.1300
Early stopping epoch 13 for trial 18. Moving to next fold.
Fold 3 validation loss: 0.1300
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.3030178499221803
[Epoch 1, Batch 200] loss: 2.301074969768524
[Epoch 1, Batch 300] loss: 2.302213752269745
[Epoch 1, Batch 400] loss: 2.298966097831726
[Epoch 1, Batch 500] loss: 2.2985725688934324
[Epoch 1, Batch 600] loss: 2.294967567920685
[Epoch 1, Batch 700] loss: 2.293127658367157
[Epoch 1, Batch 800] loss: 2.2906468415260317
[Epoch 1, Batch 900] loss: 2.292070109844208
[Epoch 1, Batch 1000] loss: 2.289406101703644
[Epoch 1, Batch 1100] loss: 2.2885382628440856
[Epoch 1, Batch 1200] loss: 2.2860006618499757
[Epoch 1, Batch 1300] loss: 2.28351527929306
[Epoch 1, Batch 1400] loss: 2.2809595394134523
[Epoch 1, Batch 1500] loss: 2.2795475363731383
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2779
Validation Accuracy: 0.1042
Overfitting: 2.2779
[Epoch 2, Batch 100] loss: 2.277218782901764
[Epoch 2, Batch 200] loss: 2.2696015882492064
[Epoch 2, Batch 300] loss: 2.2701049757003786
[Epoch 2, Batch 400] loss: 2.2654469275474547
[Epoch 2, Batch 500] loss: 2.2597513222694396
[Epoch 2, Batch 600] loss: 2.255953004360199
[Epoch 2, Batch 700] loss: 2.250945267677307
[Epoch 2, Batch 800] loss: 2.2451308608055114
[Epoch 2, Batch 900] loss: 2.238088228702545
[Epoch 2, Batch 1000] loss: 2.228399875164032
[Epoch 2, Batch 1100] loss: 2.216600625514984
[Epoch 2, Batch 1200] loss: 2.2062105250358583
[Epoch 2, Batch 1300] loss: 2.191360971927643
[Epoch 2, Batch 1400] loss: 2.179592080116272
[Epoch 2, Batch 1500] loss: 2.1606763362884522
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 2.1522
Validation Accuracy: 0.3916
Overfitting: 2.1522
[Epoch 3, Batch 100] loss: 2.142320816516876
[Epoch 3, Batch 200] loss: 2.110438015460968
[Epoch 3, Batch 300] loss: 2.077645487785339
[Epoch 3, Batch 400] loss: 2.022770310640335
[Epoch 3, Batch 500] loss: 1.9751943910121919
[Epoch 3, Batch 600] loss: 1.910827897787094
[Epoch 3, Batch 700] loss: 1.830160163640976
[Epoch 3, Batch 800] loss: 1.722969295978546
[Epoch 3, Batch 900] loss: 1.612264701128006
[Epoch 3, Batch 1000] loss: 1.4800181770324707
[Epoch 3, Batch 1100] loss: 1.3377058923244476
[Epoch 3, Batch 1200] loss: 1.1968651413917542
[Epoch 3, Batch 1300] loss: 1.0674583524465562
[Epoch 3, Batch 1400] loss: 0.9901422619819641
[Epoch 3, Batch 1500] loss: 0.8768777143955231
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.8503
Validation Accuracy: 0.7780
Overfitting: 0.8503
[Epoch 4, Batch 100] loss: 0.8216622769832611
[Epoch 4, Batch 200] loss: 0.7564761996269226
[Epoch 4, Batch 300] loss: 0.7035928994417191
[Epoch 4, Batch 400] loss: 0.6833870247006416
[Epoch 4, Batch 500] loss: 0.6057135653495789
[Epoch 4, Batch 600] loss: 0.6165377727150917
[Epoch 4, Batch 700] loss: 0.5536572089791298
[Epoch 4, Batch 800] loss: 0.5478068765997887
[Epoch 4, Batch 900] loss: 0.5444254295527935
[Epoch 4, Batch 1000] loss: 0.5094292461872101
[Epoch 4, Batch 1100] loss: 0.5076261875033379
[Epoch 4, Batch 1200] loss: 0.5009628449380398
[Epoch 4, Batch 1300] loss: 0.5008688816428184
[Epoch 4, Batch 1400] loss: 0.437265882641077
[Epoch 4, Batch 1500] loss: 0.4509822891652584
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.4630
Validation Accuracy: 0.8550
Overfitting: 0.4630
[Epoch 5, Batch 100] loss: 0.44624713629484175
[Epoch 5, Batch 200] loss: 0.4399767632782459
[Epoch 5, Batch 300] loss: 0.4253569683432579
[Epoch 5, Batch 400] loss: 0.42330672577023504
[Epoch 5, Batch 500] loss: 0.4090057064592838
[Epoch 5, Batch 600] loss: 0.4212039914727211
[Epoch 5, Batch 700] loss: 0.39283873066306113
[Epoch 5, Batch 800] loss: 0.38635566405951977
[Epoch 5, Batch 900] loss: 0.3786792225390673
[Epoch 5, Batch 1000] loss: 0.3827833017706871
[Epoch 5, Batch 1100] loss: 0.4008704045414925
[Epoch 5, Batch 1200] loss: 0.3644565972685814
[Epoch 5, Batch 1300] loss: 0.367655658274889
[Epoch 5, Batch 1400] loss: 0.344893659055233
[Epoch 5, Batch 1500] loss: 0.3710261661559343
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.3515
Validation Accuracy: 0.8913
Overfitting: 0.3515
[Epoch 6, Batch 100] loss: 0.3303940398991108
[Epoch 6, Batch 200] loss: 0.35289857361465693
[Epoch 6, Batch 300] loss: 0.3311919800937176
[Epoch 6, Batch 400] loss: 0.30443383507430555
[Epoch 6, Batch 500] loss: 0.3604436931759119
[Epoch 6, Batch 600] loss: 0.3263249307125807
[Epoch 6, Batch 700] loss: 0.3121536126732826
[Epoch 6, Batch 800] loss: 0.29483825363218785
[Epoch 6, Batch 900] loss: 0.30764892991632226
[Epoch 6, Batch 1000] loss: 0.32836849853396416
[Epoch 6, Batch 1100] loss: 0.33030084684491157
[Epoch 6, Batch 1200] loss: 0.2785865240544081
[Epoch 6, Batch 1300] loss: 0.3075292161107063
[Epoch 6, Batch 1400] loss: 0.28412490874528884
[Epoch 6, Batch 1500] loss: 0.29865967221558093
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2986
Validation Accuracy: 0.9062
Overfitting: 0.2986
[Epoch 7, Batch 100] loss: 0.2821569737792015
[Epoch 7, Batch 200] loss: 0.29282529912889005
[Epoch 7, Batch 300] loss: 0.2639578511938453
[Epoch 7, Batch 400] loss: 0.2871808774024248
[Epoch 7, Batch 500] loss: 0.2674718252196908
[Epoch 7, Batch 600] loss: 0.2734428211674094
[Epoch 7, Batch 700] loss: 0.28244552958756686
[Epoch 7, Batch 800] loss: 0.2603060358017683
[Epoch 7, Batch 900] loss: 0.25482645697891715
[Epoch 7, Batch 1000] loss: 0.26405568651854994
[Epoch 7, Batch 1100] loss: 0.2619434479624033
[Epoch 7, Batch 1200] loss: 0.2849194771051407
[Epoch 7, Batch 1300] loss: 0.2539407204836607
[Epoch 7, Batch 1400] loss: 0.2579098246246576
[Epoch 7, Batch 1500] loss: 0.22661470375955106
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2456
Validation Accuracy: 0.9241
Overfitting: 0.2456
[Epoch 8, Batch 100] loss: 0.25080146741122006
[Epoch 8, Batch 200] loss: 0.23519162088632584
[Epoch 8, Batch 300] loss: 0.22525813195854424
[Epoch 8, Batch 400] loss: 0.2588028693944216
[Epoch 8, Batch 500] loss: 0.23219246085733175
[Epoch 8, Batch 600] loss: 0.23274958156049252
[Epoch 8, Batch 700] loss: 0.24374381620436908
[Epoch 8, Batch 800] loss: 0.2224476237781346
[Epoch 8, Batch 900] loss: 0.21682204123586415
[Epoch 8, Batch 1000] loss: 0.21909677512943745
[Epoch 8, Batch 1100] loss: 0.23531459171324967
[Epoch 8, Batch 1200] loss: 0.24598615057766438
[Epoch 8, Batch 1300] loss: 0.22254977580159901
[Epoch 8, Batch 1400] loss: 0.21532754588872194
[Epoch 8, Batch 1500] loss: 0.22921559810638428
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.2174
Validation Accuracy: 0.9324
Overfitting: 0.2174
[Epoch 9, Batch 100] loss: 0.21608925629407166
[Epoch 9, Batch 200] loss: 0.2179307061433792
[Epoch 9, Batch 300] loss: 0.21096148869022727
[Epoch 9, Batch 400] loss: 0.19759434044361116
[Epoch 9, Batch 500] loss: 0.19034761102870107
[Epoch 9, Batch 600] loss: 0.2055071260035038
[Epoch 9, Batch 700] loss: 0.21338640823960303
[Epoch 9, Batch 800] loss: 0.21780004370957612
[Epoch 9, Batch 900] loss: 0.19875345466658473
[Epoch 9, Batch 1000] loss: 0.23264790065586566
[Epoch 9, Batch 1100] loss: 0.19647911429405213
[Epoch 9, Batch 1200] loss: 0.19376400593668222
[Epoch 9, Batch 1300] loss: 0.19639569591730832
[Epoch 9, Batch 1400] loss: 0.18945535134524108
[Epoch 9, Batch 1500] loss: 0.19836151393130422
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1913
Validation Accuracy: 0.9396
Overfitting: 0.1913
Best model saved at epoch 9 with validation loss: 0.1913
[Epoch 10, Batch 100] loss: 0.18918751906603576
[Epoch 10, Batch 200] loss: 0.15781564500182868
[Epoch 10, Batch 300] loss: 0.19062352485954762
[Epoch 10, Batch 400] loss: 0.2208845518156886
[Epoch 10, Batch 500] loss: 0.16960640190169216
[Epoch 10, Batch 600] loss: 0.18243990004062652
[Epoch 10, Batch 700] loss: 0.20695403076708316
[Epoch 10, Batch 800] loss: 0.19148641474545003
[Epoch 10, Batch 900] loss: 0.18703401450067758
[Epoch 10, Batch 1000] loss: 0.1722600509598851
[Epoch 10, Batch 1100] loss: 0.18551272694021465
[Epoch 10, Batch 1200] loss: 0.16453804716467857
[Epoch 10, Batch 1300] loss: 0.18983053902164101
[Epoch 10, Batch 1400] loss: 0.17858222514390945
[Epoch 10, Batch 1500] loss: 0.16856684992089868
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1742
Validation Accuracy: 0.9452
Overfitting: 0.1742
[Epoch 11, Batch 100] loss: 0.18935684323310853
[Epoch 11, Batch 200] loss: 0.16736009310930966
[Epoch 11, Batch 300] loss: 0.16451271375641227
[Epoch 11, Batch 400] loss: 0.18342501813545822
[Epoch 11, Batch 500] loss: 0.18301538353785873
[Epoch 11, Batch 600] loss: 0.15370401959866287
[Epoch 11, Batch 700] loss: 0.17307274837046863
[Epoch 11, Batch 800] loss: 0.1591031288728118
[Epoch 11, Batch 900] loss: 0.15022697526961565
[Epoch 11, Batch 1000] loss: 0.16769336853176356
[Epoch 11, Batch 1100] loss: 0.1660946049168706
[Epoch 11, Batch 1200] loss: 0.15520870303735138
[Epoch 11, Batch 1300] loss: 0.16764215588569642
[Epoch 11, Batch 1400] loss: 0.16671717030927538
[Epoch 11, Batch 1500] loss: 0.15576295100152493
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1577
Validation Accuracy: 0.9499
Overfitting: 0.1577
Best model saved at epoch 11 with validation loss: 0.1577
[Epoch 12, Batch 100] loss: 0.16949893210083247
[Epoch 12, Batch 200] loss: 0.14763956222683192
[Epoch 12, Batch 300] loss: 0.16553426332771778
[Epoch 12, Batch 400] loss: 0.17184889315627516
[Epoch 12, Batch 500] loss: 0.1609184592589736
[Epoch 12, Batch 600] loss: 0.1638371615577489
[Epoch 12, Batch 700] loss: 0.16017501033842563
[Epoch 12, Batch 800] loss: 0.13583159387111665
[Epoch 12, Batch 900] loss: 0.14385794994421303
[Epoch 12, Batch 1000] loss: 0.15901506206020713
[Epoch 12, Batch 1100] loss: 0.1414500430878252
[Epoch 12, Batch 1200] loss: 0.1479175377637148
[Epoch 12, Batch 1300] loss: 0.14122058905661106
[Epoch 12, Batch 1400] loss: 0.14474585639312865
[Epoch 12, Batch 1500] loss: 0.13900435119867324
**STATS for Epoch 12** : 
Average training loss: 0.0000
Average validation loss: 0.1508
Validation Accuracy: 0.9533
Overfitting: 0.1508
[Epoch 13, Batch 100] loss: 0.1393461880274117
[Epoch 13, Batch 200] loss: 0.1473374842852354
[Epoch 13, Batch 300] loss: 0.152263103723526
[Epoch 13, Batch 400] loss: 0.14561780758202075
[Epoch 13, Batch 500] loss: 0.14632648697122932
[Epoch 13, Batch 600] loss: 0.128305602343753
[Epoch 13, Batch 700] loss: 0.1365111005306244
[Epoch 13, Batch 800] loss: 0.13746263938955963
[Epoch 13, Batch 900] loss: 0.13182030772790312
[Epoch 13, Batch 1000] loss: 0.14897679287940263
[Epoch 13, Batch 1100] loss: 0.14086544070392848
[Epoch 13, Batch 1200] loss: 0.14642281021922826
[Epoch 13, Batch 1300] loss: 0.14972800354473292
[Epoch 13, Batch 1400] loss: 0.13693187959492206
[Epoch 13, Batch 1500] loss: 0.13188512957654894
**STATS for Epoch 13** : 
Average training loss: 0.0000
Average validation loss: 0.1364
Validation Accuracy: 0.9576
Overfitting: 0.1364
Early stopping epoch 13 for trial 18. Moving to next fold.
Fold 4 validation loss: 0.1364
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.30484334230423
[Epoch 1, Batch 200] loss: 2.301722185611725
[Epoch 1, Batch 300] loss: 2.298328287601471
[Epoch 1, Batch 400] loss: 2.297379660606384
[Epoch 1, Batch 500] loss: 2.291635935306549
[Epoch 1, Batch 600] loss: 2.287805392742157
[Epoch 1, Batch 700] loss: 2.2840218639373777
[Epoch 1, Batch 800] loss: 2.2802531123161316
[Epoch 1, Batch 900] loss: 2.2761440896987915
[Epoch 1, Batch 1000] loss: 2.2723323702812195
[Epoch 1, Batch 1100] loss: 2.2660347843170165
[Epoch 1, Batch 1200] loss: 2.2598742508888243
[Epoch 1, Batch 1300] loss: 2.253601508140564
[Epoch 1, Batch 1400] loss: 2.2456926035881044
[Epoch 1, Batch 1500] loss: 2.2347840166091917
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 2.2308
Validation Accuracy: 0.4567
Overfitting: 2.2308
[Epoch 2, Batch 100] loss: 2.2279331374168394
[Epoch 2, Batch 200] loss: 2.212564396858215
[Epoch 2, Batch 300] loss: 2.197419946193695
[Epoch 2, Batch 400] loss: 2.17941282749176
[Epoch 2, Batch 500] loss: 2.1573719358444214
[Epoch 2, Batch 600] loss: 2.1278971886634825
[Epoch 2, Batch 700] loss: 2.095871787071228
[Epoch 2, Batch 800] loss: 2.0535817837715147
[Epoch 2, Batch 900] loss: 1.9974717950820924
[Epoch 2, Batch 1000] loss: 1.9375698375701904
[Epoch 2, Batch 1100] loss: 1.8396230244636536
[Epoch 2, Batch 1200] loss: 1.7349320793151854
[Epoch 2, Batch 1300] loss: 1.611139496564865
[Epoch 2, Batch 1400] loss: 1.4373844647407532
[Epoch 2, Batch 1500] loss: 1.2767831838130952
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 1.2165
Validation Accuracy: 0.6971
Overfitting: 1.2165
[Epoch 3, Batch 100] loss: 1.130892766714096
[Epoch 3, Batch 200] loss: 1.002074310183525
[Epoch 3, Batch 300] loss: 0.9028000748157501
[Epoch 3, Batch 400] loss: 0.8227044302225113
[Epoch 3, Batch 500] loss: 0.7296441704034805
[Epoch 3, Batch 600] loss: 0.6588134941458702
[Epoch 3, Batch 700] loss: 0.6308379998803139
[Epoch 3, Batch 800] loss: 0.6327930897474289
[Epoch 3, Batch 900] loss: 0.5775656369328499
[Epoch 3, Batch 1000] loss: 0.5704716861248016
[Epoch 3, Batch 1100] loss: 0.5125528922677041
[Epoch 3, Batch 1200] loss: 0.5160073532164097
[Epoch 3, Batch 1300] loss: 0.45048454478383065
[Epoch 3, Batch 1400] loss: 0.48388143703341485
[Epoch 3, Batch 1500] loss: 0.44897048458456995
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.4659
Validation Accuracy: 0.8624
Overfitting: 0.4659
[Epoch 4, Batch 100] loss: 0.4395292240381241
[Epoch 4, Batch 200] loss: 0.44152674719691276
[Epoch 4, Batch 300] loss: 0.43347432389855384
[Epoch 4, Batch 400] loss: 0.39635020405054094
[Epoch 4, Batch 500] loss: 0.39215073436498643
[Epoch 4, Batch 600] loss: 0.4097758209705353
[Epoch 4, Batch 700] loss: 0.3856459207832813
[Epoch 4, Batch 800] loss: 0.3858565109223127
[Epoch 4, Batch 900] loss: 0.382233389467001
[Epoch 4, Batch 1000] loss: 0.35404651865363124
[Epoch 4, Batch 1100] loss: 0.37925570368766787
[Epoch 4, Batch 1200] loss: 0.3680362683534622
[Epoch 4, Batch 1300] loss: 0.35421190693974497
[Epoch 4, Batch 1400] loss: 0.3085416647046804
[Epoch 4, Batch 1500] loss: 0.32751010678708553
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.3488
Validation Accuracy: 0.8938
Overfitting: 0.3488
[Epoch 5, Batch 100] loss: 0.3088900054246187
[Epoch 5, Batch 200] loss: 0.33199368603527546
[Epoch 5, Batch 300] loss: 0.3603138329833746
[Epoch 5, Batch 400] loss: 0.3110960890352726
[Epoch 5, Batch 500] loss: 0.316728453412652
[Epoch 5, Batch 600] loss: 0.33309825479984284
[Epoch 5, Batch 700] loss: 0.3153257884830236
[Epoch 5, Batch 800] loss: 0.2961826400458813
[Epoch 5, Batch 900] loss: 0.305127474591136
[Epoch 5, Batch 1000] loss: 0.2886343900859356
[Epoch 5, Batch 1100] loss: 0.27552521906793115
[Epoch 5, Batch 1200] loss: 0.28956401005387306
[Epoch 5, Batch 1300] loss: 0.2649156602099538
[Epoch 5, Batch 1400] loss: 0.27362133510410785
[Epoch 5, Batch 1500] loss: 0.2733763806521893
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.2869
Validation Accuracy: 0.9115
Overfitting: 0.2869
[Epoch 6, Batch 100] loss: 0.27576822392642497
[Epoch 6, Batch 200] loss: 0.2699779751896858
[Epoch 6, Batch 300] loss: 0.2804984718933701
[Epoch 6, Batch 400] loss: 0.26136215813457964
[Epoch 6, Batch 500] loss: 0.27367809183895586
[Epoch 6, Batch 600] loss: 0.24689860079437495
[Epoch 6, Batch 700] loss: 0.257052916623652
[Epoch 6, Batch 800] loss: 0.24445966228842736
[Epoch 6, Batch 900] loss: 0.28371885139495134
[Epoch 6, Batch 1000] loss: 0.25456116065382955
[Epoch 6, Batch 1100] loss: 0.2374051535874605
[Epoch 6, Batch 1200] loss: 0.23362366683781147
[Epoch 6, Batch 1300] loss: 0.2424741468206048
[Epoch 6, Batch 1400] loss: 0.22870498592033983
[Epoch 6, Batch 1500] loss: 0.2325359660387039
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.2370
Validation Accuracy: 0.9293
Overfitting: 0.2370
[Epoch 7, Batch 100] loss: 0.22386973205953836
[Epoch 7, Batch 200] loss: 0.22373885951936245
[Epoch 7, Batch 300] loss: 0.21561043214052916
[Epoch 7, Batch 400] loss: 0.22079691242426633
[Epoch 7, Batch 500] loss: 0.22372294295579195
[Epoch 7, Batch 600] loss: 0.2076860225945711
[Epoch 7, Batch 700] loss: 0.21495958048850297
[Epoch 7, Batch 800] loss: 0.24236096087843179
[Epoch 7, Batch 900] loss: 0.20918977815657855
[Epoch 7, Batch 1000] loss: 0.23425190411508084
[Epoch 7, Batch 1100] loss: 0.22293580133467913
[Epoch 7, Batch 1200] loss: 0.22923634316772223
[Epoch 7, Batch 1300] loss: 0.2141431988030672
[Epoch 7, Batch 1400] loss: 0.19314241249114275
[Epoch 7, Batch 1500] loss: 0.24666280917823313
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.2105
Validation Accuracy: 0.9389
Overfitting: 0.2105
[Epoch 8, Batch 100] loss: 0.2061029750853777
[Epoch 8, Batch 200] loss: 0.2035380531102419
[Epoch 8, Batch 300] loss: 0.18192292904481291
[Epoch 8, Batch 400] loss: 0.21851755989715457
[Epoch 8, Batch 500] loss: 0.20231750641018154
[Epoch 8, Batch 600] loss: 0.1880377857759595
[Epoch 8, Batch 700] loss: 0.2125675044953823
[Epoch 8, Batch 800] loss: 0.18832505382597448
[Epoch 8, Batch 900] loss: 0.1807971691340208
[Epoch 8, Batch 1000] loss: 0.19134980328381063
[Epoch 8, Batch 1100] loss: 0.2025499327853322
[Epoch 8, Batch 1200] loss: 0.17254832431674003
[Epoch 8, Batch 1300] loss: 0.20574696440249682
[Epoch 8, Batch 1400] loss: 0.19049812514334918
[Epoch 8, Batch 1500] loss: 0.1983940778300166
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.1874
Validation Accuracy: 0.9456
Overfitting: 0.1874
[Epoch 9, Batch 100] loss: 0.1787681540288031
[Epoch 9, Batch 200] loss: 0.1732754062488675
[Epoch 9, Batch 300] loss: 0.17410472005605698
[Epoch 9, Batch 400] loss: 0.18490191165357828
[Epoch 9, Batch 500] loss: 0.17596388172358274
[Epoch 9, Batch 600] loss: 0.18993484722450377
[Epoch 9, Batch 700] loss: 0.1760450213868171
[Epoch 9, Batch 800] loss: 0.18519299056380986
[Epoch 9, Batch 900] loss: 0.16241191988810896
[Epoch 9, Batch 1000] loss: 0.16314642235636712
[Epoch 9, Batch 1100] loss: 0.18238380864262582
[Epoch 9, Batch 1200] loss: 0.1748372822254896
[Epoch 9, Batch 1300] loss: 0.1818476366251707
[Epoch 9, Batch 1400] loss: 0.15982665851712227
[Epoch 9, Batch 1500] loss: 0.17301227366551758
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.1683
Validation Accuracy: 0.9503
Overfitting: 0.1683
Best model saved at epoch 9 with validation loss: 0.1683
[Epoch 10, Batch 100] loss: 0.17235897772014142
[Epoch 10, Batch 200] loss: 0.16109409984201192
[Epoch 10, Batch 300] loss: 0.16531158868223428
[Epoch 10, Batch 400] loss: 0.1593277788721025
[Epoch 10, Batch 500] loss: 0.15225573355332017
[Epoch 10, Batch 600] loss: 0.1551066517457366
[Epoch 10, Batch 700] loss: 0.14997315425425767
[Epoch 10, Batch 800] loss: 0.16114939460530878
[Epoch 10, Batch 900] loss: 0.16932838171720505
[Epoch 10, Batch 1000] loss: 0.15619767546653748
[Epoch 10, Batch 1100] loss: 0.15079809984192252
[Epoch 10, Batch 1200] loss: 0.16031206745654344
[Epoch 10, Batch 1300] loss: 0.17339147116057574
[Epoch 10, Batch 1400] loss: 0.15754461370408535
[Epoch 10, Batch 1500] loss: 0.15675202563405036
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.1537
Validation Accuracy: 0.9568
Overfitting: 0.1537
[Epoch 11, Batch 100] loss: 0.1559025490935892
[Epoch 11, Batch 200] loss: 0.1637092052027583
[Epoch 11, Batch 300] loss: 0.15311028860509396
[Epoch 11, Batch 400] loss: 0.1530197301506996
[Epoch 11, Batch 500] loss: 0.1493725886195898
[Epoch 11, Batch 600] loss: 0.1408974181301892
[Epoch 11, Batch 700] loss: 0.14338209733366966
[Epoch 11, Batch 800] loss: 0.14428402750752867
[Epoch 11, Batch 900] loss: 0.14001110108569265
[Epoch 11, Batch 1000] loss: 0.15814591371454298
[Epoch 11, Batch 1100] loss: 0.1435086876526475
[Epoch 11, Batch 1200] loss: 0.15585818961262704
[Epoch 11, Batch 1300] loss: 0.12875090080313384
[Epoch 11, Batch 1400] loss: 0.13689961750991642
[Epoch 11, Batch 1500] loss: 0.14081342832185328
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.1438
Validation Accuracy: 0.9583
Overfitting: 0.1438
Early stopping epoch 11 for trial 18. Moving to next fold.
Fold 5 validation loss: 0.1438
Mean validation loss across all folds for Trial 18 is 0.1400 with trial config:  l1: 256, l2: 64, lr: 0.0001, batch_size: 32
[I 2024-12-10 06:53:45,525] Trial 17 finished with value: 0.1400056362994015 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0001, 'batch_size': 32}. Best is trial 12 with value: 0.0492618556785242.

Selected Hyperparameters for Trial 19:
  l1: 256, l2: 64, lr: 0.0005, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.297816104888916
[Epoch 1, Batch 200] loss: 2.2884893822669983
[Epoch 1, Batch 300] loss: 2.273345911502838
[Epoch 1, Batch 400] loss: 2.246495385169983
[Epoch 1, Batch 500] loss: 2.1915000224113466
[Epoch 1, Batch 600] loss: 2.0315129315853118
[Epoch 1, Batch 700] loss: 1.5765077543258668
[Epoch 1, Batch 800] loss: 0.9441066706180572
[Epoch 1, Batch 900] loss: 0.6513013887405396
[Epoch 1, Batch 1000] loss: 0.5518496215343476
[Epoch 1, Batch 1100] loss: 0.4927230632305145
[Epoch 1, Batch 1200] loss: 0.45244982197880745
[Epoch 1, Batch 1300] loss: 0.4152573125064373
[Epoch 1, Batch 1400] loss: 0.38659335792064664
[Epoch 1, Batch 1500] loss: 0.3401868632435799
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3533
Validation Accuracy: 0.8903
Overfitting: 0.3533
[Epoch 2, Batch 100] loss: 0.326372457370162
[Epoch 2, Batch 200] loss: 0.33889875419437887
[Epoch 2, Batch 300] loss: 0.3186295934766531
[Epoch 2, Batch 400] loss: 0.28214225478470323
[Epoch 2, Batch 500] loss: 0.27867889642715454
[Epoch 2, Batch 600] loss: 0.2653234976530075
[Epoch 2, Batch 700] loss: 0.2567696231603622
[Epoch 2, Batch 800] loss: 0.2588127436488867
[Epoch 2, Batch 900] loss: 0.22122641034424306
[Epoch 2, Batch 1000] loss: 0.22657149378210306
[Epoch 2, Batch 1100] loss: 0.23069545909762382
[Epoch 2, Batch 1200] loss: 0.21446637742221356
[Epoch 2, Batch 1300] loss: 0.2142985191754997
[Epoch 2, Batch 1400] loss: 0.21018464092165232
[Epoch 2, Batch 1500] loss: 0.2130322839692235
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1925
Validation Accuracy: 0.9394
Overfitting: 0.1925
[Epoch 3, Batch 100] loss: 0.1920740992575884
[Epoch 3, Batch 200] loss: 0.17408866833895445
[Epoch 3, Batch 300] loss: 0.18002087997272612
[Epoch 3, Batch 400] loss: 0.1749363113567233
[Epoch 3, Batch 500] loss: 0.19727496270090342
[Epoch 3, Batch 600] loss: 0.15344109412282705
[Epoch 3, Batch 700] loss: 0.1410029428638518
[Epoch 3, Batch 800] loss: 0.15370654077269136
[Epoch 3, Batch 900] loss: 0.16089621344581245
[Epoch 3, Batch 1000] loss: 0.15001280199736355
[Epoch 3, Batch 1100] loss: 0.1497290269844234
[Epoch 3, Batch 1200] loss: 0.15279154473915696
[Epoch 3, Batch 1300] loss: 0.1297693401388824
[Epoch 3, Batch 1400] loss: 0.15284840192645788
[Epoch 3, Batch 1500] loss: 0.12788596732541918
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1220
Validation Accuracy: 0.9612
Overfitting: 0.1220
[Epoch 4, Batch 100] loss: 0.1266767103970051
[Epoch 4, Batch 200] loss: 0.12652922039851547
[Epoch 4, Batch 300] loss: 0.1377658059913665
[Epoch 4, Batch 400] loss: 0.12155555378645659
[Epoch 4, Batch 500] loss: 0.1312242761813104
[Epoch 4, Batch 600] loss: 0.11218605522997677
[Epoch 4, Batch 700] loss: 0.11710670121014118
[Epoch 4, Batch 800] loss: 0.12109106746967882
[Epoch 4, Batch 900] loss: 0.11433044037781656
[Epoch 4, Batch 1000] loss: 0.11584707404021173
[Epoch 4, Batch 1100] loss: 0.1411525438260287
[Epoch 4, Batch 1200] loss: 0.11495227506849914
[Epoch 4, Batch 1300] loss: 0.10566887076944113
[Epoch 4, Batch 1400] loss: 0.11980409181676804
[Epoch 4, Batch 1500] loss: 0.097361547825858
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0913
Validation Accuracy: 0.9708
Overfitting: 0.0913
[Epoch 5, Batch 100] loss: 0.08543457459192723
[Epoch 5, Batch 200] loss: 0.12512182898819446
[Epoch 5, Batch 300] loss: 0.10581866418477148
[Epoch 5, Batch 400] loss: 0.09110699301585555
[Epoch 5, Batch 500] loss: 0.10730009051039816
[Epoch 5, Batch 600] loss: 0.1099842529837042
[Epoch 5, Batch 700] loss: 0.09381360964849592
[Epoch 5, Batch 800] loss: 0.10493376707658171
[Epoch 5, Batch 900] loss: 0.10004305155947804
[Epoch 5, Batch 1000] loss: 0.08405504125636071
[Epoch 5, Batch 1100] loss: 0.11669940916355699
[Epoch 5, Batch 1200] loss: 0.08380781983491033
[Epoch 5, Batch 1300] loss: 0.10100862293504179
[Epoch 5, Batch 1400] loss: 0.09053850082680583
[Epoch 5, Batch 1500] loss: 0.08801390672335402
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0852
Validation Accuracy: 0.9720
Overfitting: 0.0852
[Epoch 6, Batch 100] loss: 0.0738725318457
[Epoch 6, Batch 200] loss: 0.09907365297432989
[Epoch 6, Batch 300] loss: 0.09023235076339915
[Epoch 6, Batch 400] loss: 0.08153943279292435
[Epoch 6, Batch 500] loss: 0.08068721159826964
[Epoch 6, Batch 600] loss: 0.08073312890715897
[Epoch 6, Batch 700] loss: 0.0865903109498322
[Epoch 6, Batch 800] loss: 0.09558345221914351
[Epoch 6, Batch 900] loss: 0.0823717309301719
[Epoch 6, Batch 1000] loss: 0.09230959220323712
[Epoch 6, Batch 1100] loss: 0.0988684218027629
[Epoch 6, Batch 1200] loss: 0.06969929055660032
[Epoch 6, Batch 1300] loss: 0.08097693721414544
[Epoch 6, Batch 1400] loss: 0.07896398272365332
[Epoch 6, Batch 1500] loss: 0.07700777768157423
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0752
Validation Accuracy: 0.9758
Overfitting: 0.0752
[Epoch 7, Batch 100] loss: 0.07323410398093984
[Epoch 7, Batch 200] loss: 0.0690960921603255
[Epoch 7, Batch 300] loss: 0.07843230933882296
[Epoch 7, Batch 400] loss: 0.07369239905383437
[Epoch 7, Batch 500] loss: 0.06958852887153626
[Epoch 7, Batch 600] loss: 0.08690380088053644
[Epoch 7, Batch 700] loss: 0.06823337064590305
[Epoch 7, Batch 800] loss: 0.07241588377859444
[Epoch 7, Batch 900] loss: 0.0733892248570919
[Epoch 7, Batch 1000] loss: 0.0806365066440776
[Epoch 7, Batch 1100] loss: 0.06369083794299513
[Epoch 7, Batch 1200] loss: 0.07260370511328801
[Epoch 7, Batch 1300] loss: 0.07515431002015248
[Epoch 7, Batch 1400] loss: 0.08394614228280262
[Epoch 7, Batch 1500] loss: 0.08035759893944487
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0740
Validation Accuracy: 0.9767
Overfitting: 0.0740
[Epoch 8, Batch 100] loss: 0.0690910907718353
[Epoch 8, Batch 200] loss: 0.07146109071560204
[Epoch 8, Batch 300] loss: 0.07109417083207518
[Epoch 8, Batch 400] loss: 0.059551901838276536
[Epoch 8, Batch 500] loss: 0.06941232778597622
[Epoch 8, Batch 600] loss: 0.06797104499302804
[Epoch 8, Batch 700] loss: 0.06507973829284311
[Epoch 8, Batch 800] loss: 0.06159245476359501
[Epoch 8, Batch 900] loss: 0.06825020065298304
[Epoch 8, Batch 1000] loss: 0.054852174541447314
[Epoch 8, Batch 1100] loss: 0.06694559063063935
[Epoch 8, Batch 1200] loss: 0.06287190061993897
[Epoch 8, Batch 1300] loss: 0.07827347296290099
[Epoch 8, Batch 1400] loss: 0.07182732688030229
[Epoch 8, Batch 1500] loss: 0.06170455137267709
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0738
Validation Accuracy: 0.9763
Overfitting: 0.0738
[Epoch 9, Batch 100] loss: 0.05250205066986382
[Epoch 9, Batch 200] loss: 0.05532468844903633
[Epoch 9, Batch 300] loss: 0.06618792180903256
[Epoch 9, Batch 400] loss: 0.04723795325495303
[Epoch 9, Batch 500] loss: 0.05662050121929497
[Epoch 9, Batch 600] loss: 0.05917914220131934
[Epoch 9, Batch 700] loss: 0.057015054025687274
[Epoch 9, Batch 800] loss: 0.06290669910842553
[Epoch 9, Batch 900] loss: 0.06506571696372702
[Epoch 9, Batch 1000] loss: 0.06831495472695678
[Epoch 9, Batch 1100] loss: 0.06480589656857774
[Epoch 9, Batch 1200] loss: 0.05754777966998517
[Epoch 9, Batch 1300] loss: 0.04811219999101013
[Epoch 9, Batch 1400] loss: 0.05838426713831723
[Epoch 9, Batch 1500] loss: 0.07893643337883986
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0695
Validation Accuracy: 0.9772
Overfitting: 0.0695
Best model saved at epoch 9 with validation loss: 0.0695
[Epoch 10, Batch 100] loss: 0.05380996350897476
[Epoch 10, Batch 200] loss: 0.04678848933777772
[Epoch 10, Batch 300] loss: 0.049193272206466646
[Epoch 10, Batch 400] loss: 0.04492507807677612
[Epoch 10, Batch 500] loss: 0.0636906988080591
[Epoch 10, Batch 600] loss: 0.057042484501143915
[Epoch 10, Batch 700] loss: 0.05950294266454875
[Epoch 10, Batch 800] loss: 0.05523196815047413
[Epoch 10, Batch 900] loss: 0.053106871775817126
[Epoch 10, Batch 1000] loss: 0.06728083413559943
[Epoch 10, Batch 1100] loss: 0.06147100118454546
[Epoch 10, Batch 1200] loss: 0.05183852093992755
[Epoch 10, Batch 1300] loss: 0.04599436688818969
[Epoch 10, Batch 1400] loss: 0.05504192027961835
[Epoch 10, Batch 1500] loss: 0.05276784963789396
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0646
Validation Accuracy: 0.9785
Overfitting: 0.0646
[Epoch 11, Batch 100] loss: 0.04754950818256475
[Epoch 11, Batch 200] loss: 0.04818867556925397
[Epoch 11, Batch 300] loss: 0.04819582496187649
[Epoch 11, Batch 400] loss: 0.05022110120858997
[Epoch 11, Batch 500] loss: 0.06555870970711113
[Epoch 11, Batch 600] loss: 0.04838757305871695
[Epoch 11, Batch 700] loss: 0.04816824002889916
[Epoch 11, Batch 800] loss: 0.05708513123798184
[Epoch 11, Batch 900] loss: 0.05396271600853652
[Epoch 11, Batch 1000] loss: 0.054407116593793034
[Epoch 11, Batch 1100] loss: 0.04375233363592997
[Epoch 11, Batch 1200] loss: 0.04823120180284604
[Epoch 11, Batch 1300] loss: 0.041270422800444066
[Epoch 11, Batch 1400] loss: 0.05528991721337661
[Epoch 11, Batch 1500] loss: 0.04880220182123594
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0553
Validation Accuracy: 0.9818
Overfitting: 0.0553
Early stopping epoch 11 for trial 19. Moving to next fold.
Fold 1 validation loss: 0.0553
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.303728201389313
[Epoch 1, Batch 200] loss: 2.2940399193763734
[Epoch 1, Batch 300] loss: 2.2784378957748412
[Epoch 1, Batch 400] loss: 2.251659767627716
[Epoch 1, Batch 500] loss: 2.1968584060668945
[Epoch 1, Batch 600] loss: 2.0378815007209776
[Epoch 1, Batch 700] loss: 1.5458358365297318
[Epoch 1, Batch 800] loss: 0.9170272159576416
[Epoch 1, Batch 900] loss: 0.6399637159705162
[Epoch 1, Batch 1000] loss: 0.5416673715412617
[Epoch 1, Batch 1100] loss: 0.46777129292488095
[Epoch 1, Batch 1200] loss: 0.4410471720993519
[Epoch 1, Batch 1300] loss: 0.4036869566142559
[Epoch 1, Batch 1400] loss: 0.3771200740337372
[Epoch 1, Batch 1500] loss: 0.34837129674851897
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.3479
Validation Accuracy: 0.9034
Overfitting: 0.3479
[Epoch 2, Batch 100] loss: 0.3459110641479492
[Epoch 2, Batch 200] loss: 0.3353783005475998
[Epoch 2, Batch 300] loss: 0.30692809842526914
[Epoch 2, Batch 400] loss: 0.28596691489219667
[Epoch 2, Batch 500] loss: 0.2651333435252309
[Epoch 2, Batch 600] loss: 0.2574135206080973
[Epoch 2, Batch 700] loss: 0.2784373354539275
[Epoch 2, Batch 800] loss: 0.2601253778487444
[Epoch 2, Batch 900] loss: 0.22195441763848067
[Epoch 2, Batch 1000] loss: 0.22946174442768097
[Epoch 2, Batch 1100] loss: 0.21190274361521005
[Epoch 2, Batch 1200] loss: 0.2314633995294571
[Epoch 2, Batch 1300] loss: 0.19531652342528105
[Epoch 2, Batch 1400] loss: 0.20979181995615362
[Epoch 2, Batch 1500] loss: 0.21277939837425947
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2077
Validation Accuracy: 0.9383
Overfitting: 0.2077
[Epoch 3, Batch 100] loss: 0.1906419973447919
[Epoch 3, Batch 200] loss: 0.17490560993552207
[Epoch 3, Batch 300] loss: 0.18598082000389696
[Epoch 3, Batch 400] loss: 0.18129447987303138
[Epoch 3, Batch 500] loss: 0.1690595370158553
[Epoch 3, Batch 600] loss: 0.17685508588328958
[Epoch 3, Batch 700] loss: 0.1710327037796378
[Epoch 3, Batch 800] loss: 0.18730866335332394
[Epoch 3, Batch 900] loss: 0.15435836832039057
[Epoch 3, Batch 1000] loss: 0.15687125520780681
[Epoch 3, Batch 1100] loss: 0.14719145288690924
[Epoch 3, Batch 1200] loss: 0.13247664399445058
[Epoch 3, Batch 1300] loss: 0.15820498385466636
[Epoch 3, Batch 1400] loss: 0.150138251632452
[Epoch 3, Batch 1500] loss: 0.143087144959718
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1947
Validation Accuracy: 0.9409
Overfitting: 0.1947
[Epoch 4, Batch 100] loss: 0.14626072173938154
[Epoch 4, Batch 200] loss: 0.12722418050281703
[Epoch 4, Batch 300] loss: 0.11934440380893648
[Epoch 4, Batch 400] loss: 0.14750468257814645
[Epoch 4, Batch 500] loss: 0.1253681768104434
[Epoch 4, Batch 600] loss: 0.15012218641117214
[Epoch 4, Batch 700] loss: 0.1220599603280425
[Epoch 4, Batch 800] loss: 0.13057251200079917
[Epoch 4, Batch 900] loss: 0.1249131974298507
[Epoch 4, Batch 1000] loss: 0.12917474951595068
[Epoch 4, Batch 1100] loss: 0.12378455838188529
[Epoch 4, Batch 1200] loss: 0.11943960066884757
[Epoch 4, Batch 1300] loss: 0.1070176331885159
[Epoch 4, Batch 1400] loss: 0.11263550605624914
[Epoch 4, Batch 1500] loss: 0.10559228022582828
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1250
Validation Accuracy: 0.9619
Overfitting: 0.1250
[Epoch 5, Batch 100] loss: 0.12610620288178326
[Epoch 5, Batch 200] loss: 0.11595119110308588
[Epoch 5, Batch 300] loss: 0.11113460887223482
[Epoch 5, Batch 400] loss: 0.0995781703107059
[Epoch 5, Batch 500] loss: 0.10667053843848408
[Epoch 5, Batch 600] loss: 0.09823934481944889
[Epoch 5, Batch 700] loss: 0.11488419086206704
[Epoch 5, Batch 800] loss: 0.10623821866698563
[Epoch 5, Batch 900] loss: 0.09712431717664004
[Epoch 5, Batch 1000] loss: 0.11883812157437205
[Epoch 5, Batch 1100] loss: 0.1012631148379296
[Epoch 5, Batch 1200] loss: 0.09676685564219951
[Epoch 5, Batch 1300] loss: 0.09942810763139277
[Epoch 5, Batch 1400] loss: 0.08210545395500958
[Epoch 5, Batch 1500] loss: 0.09424916278105229
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1100
Validation Accuracy: 0.9657
Overfitting: 0.1100
[Epoch 6, Batch 100] loss: 0.0986375132901594
[Epoch 6, Batch 200] loss: 0.09850258590187877
[Epoch 6, Batch 300] loss: 0.07989639768376947
[Epoch 6, Batch 400] loss: 0.08656428332440555
[Epoch 6, Batch 500] loss: 0.08039094996638596
[Epoch 6, Batch 600] loss: 0.08912845709361136
[Epoch 6, Batch 700] loss: 0.08987461881712079
[Epoch 6, Batch 800] loss: 0.0801448191376403
[Epoch 6, Batch 900] loss: 0.09643872417509555
[Epoch 6, Batch 1000] loss: 0.08501248786691576
[Epoch 6, Batch 1100] loss: 0.08805216372944415
[Epoch 6, Batch 1200] loss: 0.08070881760912016
[Epoch 6, Batch 1300] loss: 0.08660219750832766
[Epoch 6, Batch 1400] loss: 0.09088499252684415
[Epoch 6, Batch 1500] loss: 0.11031460284721106
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0931
Validation Accuracy: 0.9721
Overfitting: 0.0931
[Epoch 7, Batch 100] loss: 0.08071636776439846
[Epoch 7, Batch 200] loss: 0.08448657348752021
[Epoch 7, Batch 300] loss: 0.08433599703013897
[Epoch 7, Batch 400] loss: 0.09501112273894251
[Epoch 7, Batch 500] loss: 0.08303043279331178
[Epoch 7, Batch 600] loss: 0.07818066573701798
[Epoch 7, Batch 700] loss: 0.07334036430343986
[Epoch 7, Batch 800] loss: 0.08145101196831092
[Epoch 7, Batch 900] loss: 0.07664196252822876
[Epoch 7, Batch 1000] loss: 0.06583712038816884
[Epoch 7, Batch 1100] loss: 0.07425658663269133
[Epoch 7, Batch 1200] loss: 0.07374491840600968
[Epoch 7, Batch 1300] loss: 0.07256209223531186
[Epoch 7, Batch 1400] loss: 0.0707129365648143
[Epoch 7, Batch 1500] loss: 0.07491818842943758
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0930
Validation Accuracy: 0.9729
Overfitting: 0.0930
[Epoch 8, Batch 100] loss: 0.07651854121126235
[Epoch 8, Batch 200] loss: 0.05900117769953795
[Epoch 8, Batch 300] loss: 0.057877993842121216
[Epoch 8, Batch 400] loss: 0.07329594124574214
[Epoch 8, Batch 500] loss: 0.08257623882265762
[Epoch 8, Batch 600] loss: 0.07140232176985592
[Epoch 8, Batch 700] loss: 0.07273612163029611
[Epoch 8, Batch 800] loss: 0.08554405288770794
[Epoch 8, Batch 900] loss: 0.060802187812514605
[Epoch 8, Batch 1000] loss: 0.06606958461459726
[Epoch 8, Batch 1100] loss: 0.07040992909343913
[Epoch 8, Batch 1200] loss: 0.0743622316676192
[Epoch 8, Batch 1300] loss: 0.0706105893664062
[Epoch 8, Batch 1400] loss: 0.0731293892674148
[Epoch 8, Batch 1500] loss: 0.07097514999564737
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0772
Validation Accuracy: 0.9758
Overfitting: 0.0772
[Epoch 9, Batch 100] loss: 0.05164223927655257
[Epoch 9, Batch 200] loss: 0.06396114700124599
[Epoch 9, Batch 300] loss: 0.058672938265372065
[Epoch 9, Batch 400] loss: 0.07711247485363856
[Epoch 9, Batch 500] loss: 0.06711872518295423
[Epoch 9, Batch 600] loss: 0.05695548416813836
[Epoch 9, Batch 700] loss: 0.07035431735217572
[Epoch 9, Batch 800] loss: 0.05972107375622727
[Epoch 9, Batch 900] loss: 0.049898288848344234
[Epoch 9, Batch 1000] loss: 0.06621224709320814
[Epoch 9, Batch 1100] loss: 0.06791738125029952
[Epoch 9, Batch 1200] loss: 0.06351190474350005
[Epoch 9, Batch 1300] loss: 0.07308048563543706
[Epoch 9, Batch 1400] loss: 0.06041626430349425
[Epoch 9, Batch 1500] loss: 0.06023805092321709
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0788
Validation Accuracy: 0.9762
Overfitting: 0.0788
Best model saved at epoch 9 with validation loss: 0.0788
[Epoch 10, Batch 100] loss: 0.06481271684635431
[Epoch 10, Batch 200] loss: 0.053761828665155914
[Epoch 10, Batch 300] loss: 0.052669502794742584
[Epoch 10, Batch 400] loss: 0.07879249415593222
[Epoch 10, Batch 500] loss: 0.05449711476103403
[Epoch 10, Batch 600] loss: 0.0702788201952353
[Epoch 10, Batch 700] loss: 0.05291604484780692
[Epoch 10, Batch 800] loss: 0.05196524164755829
[Epoch 10, Batch 900] loss: 0.054751686727395284
[Epoch 10, Batch 1000] loss: 0.05691569436574355
[Epoch 10, Batch 1100] loss: 0.05532948399777524
[Epoch 10, Batch 1200] loss: 0.06253371595637873
[Epoch 10, Batch 1300] loss: 0.0693093459168449
[Epoch 10, Batch 1400] loss: 0.06569335893495008
[Epoch 10, Batch 1500] loss: 0.04794617579318583
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0751
Validation Accuracy: 0.9785
Overfitting: 0.0751
[Epoch 11, Batch 100] loss: 0.051775262702722105
[Epoch 11, Batch 200] loss: 0.0493642851873301
[Epoch 11, Batch 300] loss: 0.062366673283977436
[Epoch 11, Batch 400] loss: 0.054912301083095374
[Epoch 11, Batch 500] loss: 0.05469655997818336
[Epoch 11, Batch 600] loss: 0.06163213215535507
[Epoch 11, Batch 700] loss: 0.05162350506638177
[Epoch 11, Batch 800] loss: 0.051813247181707996
[Epoch 11, Batch 900] loss: 0.059041029919171706
[Epoch 11, Batch 1000] loss: 0.05229295941418968
[Epoch 11, Batch 1100] loss: 0.04364040968823247
[Epoch 11, Batch 1200] loss: 0.056438173428177835
[Epoch 11, Batch 1300] loss: 0.047372930047567936
[Epoch 11, Batch 1400] loss: 0.05826807982288301
[Epoch 11, Batch 1500] loss: 0.051681522334693
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0694
Validation Accuracy: 0.9795
Overfitting: 0.0694
Early stopping epoch 11 for trial 19. Moving to next fold.
Fold 2 validation loss: 0.0694
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3028110003471376
[Epoch 1, Batch 200] loss: 2.295529716014862
[Epoch 1, Batch 300] loss: 2.2880472898483277
[Epoch 1, Batch 400] loss: 2.276135199069977
[Epoch 1, Batch 500] loss: 2.2603079962730406
[Epoch 1, Batch 600] loss: 2.2237346315383912
[Epoch 1, Batch 700] loss: 2.1337205815315246
[Epoch 1, Batch 800] loss: 1.8623958253860473
[Epoch 1, Batch 900] loss: 1.2889297145605088
[Epoch 1, Batch 1000] loss: 0.8291446095705033
[Epoch 1, Batch 1100] loss: 0.6129495099186897
[Epoch 1, Batch 1200] loss: 0.553314961194992
[Epoch 1, Batch 1300] loss: 0.49930509373545645
[Epoch 1, Batch 1400] loss: 0.45720553666353225
[Epoch 1, Batch 1500] loss: 0.42924028873443604
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.4771
Validation Accuracy: 0.8578
Overfitting: 0.4771
[Epoch 2, Batch 100] loss: 0.38709806218743326
[Epoch 2, Batch 200] loss: 0.38774109944701196
[Epoch 2, Batch 300] loss: 0.38716101601719854
[Epoch 2, Batch 400] loss: 0.35870778538286685
[Epoch 2, Batch 500] loss: 0.3213955283910036
[Epoch 2, Batch 600] loss: 0.3042693681269884
[Epoch 2, Batch 700] loss: 0.3040723906084895
[Epoch 2, Batch 800] loss: 0.281699980199337
[Epoch 2, Batch 900] loss: 0.2881935481727123
[Epoch 2, Batch 1000] loss: 0.2649232069030404
[Epoch 2, Batch 1100] loss: 0.24659550089389085
[Epoch 2, Batch 1200] loss: 0.224318539313972
[Epoch 2, Batch 1300] loss: 0.2477990193106234
[Epoch 2, Batch 1400] loss: 0.21958018716424704
[Epoch 2, Batch 1500] loss: 0.2041908831894398
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2050
Validation Accuracy: 0.9384
Overfitting: 0.2050
[Epoch 3, Batch 100] loss: 0.21229743752628566
[Epoch 3, Batch 200] loss: 0.22162593130022287
[Epoch 3, Batch 300] loss: 0.1996788457967341
[Epoch 3, Batch 400] loss: 0.18412576092407107
[Epoch 3, Batch 500] loss: 0.1967596611008048
[Epoch 3, Batch 600] loss: 0.1701164347678423
[Epoch 3, Batch 700] loss: 0.18281643342226744
[Epoch 3, Batch 800] loss: 0.17275939878076316
[Epoch 3, Batch 900] loss: 0.1670551042817533
[Epoch 3, Batch 1000] loss: 0.15335239410400392
[Epoch 3, Batch 1100] loss: 0.16786892496049405
[Epoch 3, Batch 1200] loss: 0.15040767854079604
[Epoch 3, Batch 1300] loss: 0.15165523562580346
[Epoch 3, Batch 1400] loss: 0.131473267278634
[Epoch 3, Batch 1500] loss: 0.14766750125214456
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1474
Validation Accuracy: 0.9552
Overfitting: 0.1474
[Epoch 4, Batch 100] loss: 0.13940664996858687
[Epoch 4, Batch 200] loss: 0.13004054320976138
[Epoch 4, Batch 300] loss: 0.1387278138566762
[Epoch 4, Batch 400] loss: 0.1320758752990514
[Epoch 4, Batch 500] loss: 0.14420991218648851
[Epoch 4, Batch 600] loss: 0.12039513520896435
[Epoch 4, Batch 700] loss: 0.11720260297879577
[Epoch 4, Batch 800] loss: 0.12246126053854824
[Epoch 4, Batch 900] loss: 0.12523501406423748
[Epoch 4, Batch 1000] loss: 0.13307456948794424
[Epoch 4, Batch 1100] loss: 0.13920096800662576
[Epoch 4, Batch 1200] loss: 0.11863542865030467
[Epoch 4, Batch 1300] loss: 0.0995810454338789
[Epoch 4, Batch 1400] loss: 0.11352901910431683
[Epoch 4, Batch 1500] loss: 0.1239873152319342
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1229
Validation Accuracy: 0.9647
Overfitting: 0.1229
[Epoch 5, Batch 100] loss: 0.12050776902586222
[Epoch 5, Batch 200] loss: 0.10803995100781322
[Epoch 5, Batch 300] loss: 0.09711778394877911
[Epoch 5, Batch 400] loss: 0.12053111978806555
[Epoch 5, Batch 500] loss: 0.11242455287370831
[Epoch 5, Batch 600] loss: 0.10326036222279072
[Epoch 5, Batch 700] loss: 0.09300759653095156
[Epoch 5, Batch 800] loss: 0.0949113267310895
[Epoch 5, Batch 900] loss: 0.10008813909254968
[Epoch 5, Batch 1000] loss: 0.12309250897262246
[Epoch 5, Batch 1100] loss: 0.10582062510773539
[Epoch 5, Batch 1200] loss: 0.09229472323786467
[Epoch 5, Batch 1300] loss: 0.09706895194482058
[Epoch 5, Batch 1400] loss: 0.09756810258142651
[Epoch 5, Batch 1500] loss: 0.09060248364461586
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.1037
Validation Accuracy: 0.9699
Overfitting: 0.1037
[Epoch 6, Batch 100] loss: 0.09123973810113967
[Epoch 6, Batch 200] loss: 0.08198245901614427
[Epoch 6, Batch 300] loss: 0.09521186609286815
[Epoch 6, Batch 400] loss: 0.08278465081937611
[Epoch 6, Batch 500] loss: 0.10107588026672602
[Epoch 6, Batch 600] loss: 0.08572099512442946
[Epoch 6, Batch 700] loss: 0.08440550267696381
[Epoch 6, Batch 800] loss: 0.10010820387396961
[Epoch 6, Batch 900] loss: 0.08603635803097859
[Epoch 6, Batch 1000] loss: 0.09108238643966615
[Epoch 6, Batch 1100] loss: 0.09325350212398917
[Epoch 6, Batch 1200] loss: 0.09423674395307899
[Epoch 6, Batch 1300] loss: 0.07918900359421968
[Epoch 6, Batch 1400] loss: 0.09820702707394957
[Epoch 6, Batch 1500] loss: 0.08108602799009532
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0965
Validation Accuracy: 0.9708
Overfitting: 0.0965
[Epoch 7, Batch 100] loss: 0.08486227489076555
[Epoch 7, Batch 200] loss: 0.07503408857155591
[Epoch 7, Batch 300] loss: 0.07833854003809393
[Epoch 7, Batch 400] loss: 0.07008935643360019
[Epoch 7, Batch 500] loss: 0.07090355437714607
[Epoch 7, Batch 600] loss: 0.08010707634035498
[Epoch 7, Batch 700] loss: 0.08994619570672512
[Epoch 7, Batch 800] loss: 0.0861874054512009
[Epoch 7, Batch 900] loss: 0.09050939804874361
[Epoch 7, Batch 1000] loss: 0.08149759490508586
[Epoch 7, Batch 1100] loss: 0.0728341485094279
[Epoch 7, Batch 1200] loss: 0.06833920844481327
[Epoch 7, Batch 1300] loss: 0.07998802409972995
[Epoch 7, Batch 1400] loss: 0.09295825545676052
[Epoch 7, Batch 1500] loss: 0.0883758307667449
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0860
Validation Accuracy: 0.9750
Overfitting: 0.0860
[Epoch 8, Batch 100] loss: 0.06885220122523605
[Epoch 8, Batch 200] loss: 0.0810030649183318
[Epoch 8, Batch 300] loss: 0.07055140291806311
[Epoch 8, Batch 400] loss: 0.07309420909732581
[Epoch 8, Batch 500] loss: 0.0720075922855176
[Epoch 8, Batch 600] loss: 0.07858306399080903
[Epoch 8, Batch 700] loss: 0.060123598142527046
[Epoch 8, Batch 800] loss: 0.07578091803239659
[Epoch 8, Batch 900] loss: 0.07978587461635471
[Epoch 8, Batch 1000] loss: 0.07096945844590664
[Epoch 8, Batch 1100] loss: 0.0501524813240394
[Epoch 8, Batch 1200] loss: 0.08308937341207638
[Epoch 8, Batch 1300] loss: 0.0677728258492425
[Epoch 8, Batch 1400] loss: 0.0877902651624754
[Epoch 8, Batch 1500] loss: 0.06093939114827663
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0767
Validation Accuracy: 0.9762
Overfitting: 0.0767
[Epoch 9, Batch 100] loss: 0.06476854777778498
[Epoch 9, Batch 200] loss: 0.062422313515562565
[Epoch 9, Batch 300] loss: 0.06385223663412035
[Epoch 9, Batch 400] loss: 0.0658699587197043
[Epoch 9, Batch 500] loss: 0.06838922903407366
[Epoch 9, Batch 600] loss: 0.05889734829193913
[Epoch 9, Batch 700] loss: 0.062013816153630615
[Epoch 9, Batch 800] loss: 0.05658724815119058
[Epoch 9, Batch 900] loss: 0.07642872202442959
[Epoch 9, Batch 1000] loss: 0.06300959970569238
[Epoch 9, Batch 1100] loss: 0.06719934307271615
[Epoch 9, Batch 1200] loss: 0.06369644201593473
[Epoch 9, Batch 1300] loss: 0.05559420630801469
[Epoch 9, Batch 1400] loss: 0.07098912251647561
[Epoch 9, Batch 1500] loss: 0.07784996376838535
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0741
Validation Accuracy: 0.9772
Overfitting: 0.0741
Best model saved at epoch 9 with validation loss: 0.0741
[Epoch 10, Batch 100] loss: 0.0673931314307265
[Epoch 10, Batch 200] loss: 0.06120497687719762
[Epoch 10, Batch 300] loss: 0.0652688137255609
[Epoch 10, Batch 400] loss: 0.05952247016131878
[Epoch 10, Batch 500] loss: 0.055544929872266946
[Epoch 10, Batch 600] loss: 0.06693537866696715
[Epoch 10, Batch 700] loss: 0.057886948846280574
[Epoch 10, Batch 800] loss: 0.05447613099589944
[Epoch 10, Batch 900] loss: 0.0632801580161322
[Epoch 10, Batch 1000] loss: 0.04521248893812299
[Epoch 10, Batch 1100] loss: 0.05470515079388861
[Epoch 10, Batch 1200] loss: 0.05673882939736359
[Epoch 10, Batch 1300] loss: 0.06287067017983645
[Epoch 10, Batch 1400] loss: 0.057319094587583094
[Epoch 10, Batch 1500] loss: 0.06271928580594249
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0734
Validation Accuracy: 0.9778
Overfitting: 0.0734
[Epoch 11, Batch 100] loss: 0.058225893380586057
[Epoch 11, Batch 200] loss: 0.05363991955528036
[Epoch 11, Batch 300] loss: 0.06137411555042491
[Epoch 11, Batch 400] loss: 0.05397306670667604
[Epoch 11, Batch 500] loss: 0.05561036181519739
[Epoch 11, Batch 600] loss: 0.05291248166467995
[Epoch 11, Batch 700] loss: 0.04928367476852145
[Epoch 11, Batch 800] loss: 0.04349350140197203
[Epoch 11, Batch 900] loss: 0.04535452412441373
[Epoch 11, Batch 1000] loss: 0.05547916098963469
[Epoch 11, Batch 1100] loss: 0.061435904290992764
[Epoch 11, Batch 1200] loss: 0.07208282909239642
[Epoch 11, Batch 1300] loss: 0.044807560257613656
[Epoch 11, Batch 1400] loss: 0.06551616586511955
[Epoch 11, Batch 1500] loss: 0.054703496692236515
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0717
Validation Accuracy: 0.9782
Overfitting: 0.0717
Early stopping epoch 11 for trial 19. Moving to next fold.
Fold 3 validation loss: 0.0717
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.3023890471458435
[Epoch 1, Batch 200] loss: 2.2934054732322693
[Epoch 1, Batch 300] loss: 2.2789154696464538
[Epoch 1, Batch 400] loss: 2.2571469140052796
[Epoch 1, Batch 500] loss: 2.2141724228858948
[Epoch 1, Batch 600] loss: 2.090140722990036
[Epoch 1, Batch 700] loss: 1.7421403217315674
[Epoch 1, Batch 800] loss: 1.1222926497459411
[Epoch 1, Batch 900] loss: 0.7797917544841766
[Epoch 1, Batch 1000] loss: 0.6336330376565457
[Epoch 1, Batch 1100] loss: 0.5490545122325421
[Epoch 1, Batch 1200] loss: 0.4719439388811588
[Epoch 1, Batch 1300] loss: 0.4228263048827648
[Epoch 1, Batch 1400] loss: 0.39433071300387385
[Epoch 1, Batch 1500] loss: 0.42091278776526453
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.4143
Validation Accuracy: 0.8752
Overfitting: 0.4143
[Epoch 2, Batch 100] loss: 0.3632758095860481
[Epoch 2, Batch 200] loss: 0.3287614195048809
[Epoch 2, Batch 300] loss: 0.2964487938582897
[Epoch 2, Batch 400] loss: 0.32590000100433825
[Epoch 2, Batch 500] loss: 0.278404203876853
[Epoch 2, Batch 600] loss: 0.2944707891345024
[Epoch 2, Batch 700] loss: 0.2571617105975747
[Epoch 2, Batch 800] loss: 0.2664084069058299
[Epoch 2, Batch 900] loss: 0.24480138424783945
[Epoch 2, Batch 1000] loss: 0.22588053174316883
[Epoch 2, Batch 1100] loss: 0.20943977523595095
[Epoch 2, Batch 1200] loss: 0.1891032335907221
[Epoch 2, Batch 1300] loss: 0.221669397726655
[Epoch 2, Batch 1400] loss: 0.20509595483541487
[Epoch 2, Batch 1500] loss: 0.1825184261240065
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1771
Validation Accuracy: 0.9458
Overfitting: 0.1771
[Epoch 3, Batch 100] loss: 0.1956021159887314
[Epoch 3, Batch 200] loss: 0.16208203043788671
[Epoch 3, Batch 300] loss: 0.16603365257382394
[Epoch 3, Batch 400] loss: 0.176625918969512
[Epoch 3, Batch 500] loss: 0.16732488557696343
[Epoch 3, Batch 600] loss: 0.1791233091801405
[Epoch 3, Batch 700] loss: 0.14668459491804242
[Epoch 3, Batch 800] loss: 0.15154772570356725
[Epoch 3, Batch 900] loss: 0.14870782239362598
[Epoch 3, Batch 1000] loss: 0.13320481789298355
[Epoch 3, Batch 1100] loss: 0.15498812582343816
[Epoch 3, Batch 1200] loss: 0.1561707216873765
[Epoch 3, Batch 1300] loss: 0.12965477794408797
[Epoch 3, Batch 1400] loss: 0.1325083668436855
[Epoch 3, Batch 1500] loss: 0.1339183816406876
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1298
Validation Accuracy: 0.9597
Overfitting: 0.1298
[Epoch 4, Batch 100] loss: 0.12755948795005678
[Epoch 4, Batch 200] loss: 0.12442244241945445
[Epoch 4, Batch 300] loss: 0.11628616665489971
[Epoch 4, Batch 400] loss: 0.1416322730574757
[Epoch 4, Batch 500] loss: 0.1270872154412791
[Epoch 4, Batch 600] loss: 0.10854467599652708
[Epoch 4, Batch 700] loss: 0.12654560732655226
[Epoch 4, Batch 800] loss: 0.10584541955031454
[Epoch 4, Batch 900] loss: 0.11582305856514723
[Epoch 4, Batch 1000] loss: 0.14523419530130924
[Epoch 4, Batch 1100] loss: 0.1236414907919243
[Epoch 4, Batch 1200] loss: 0.10071117862127721
[Epoch 4, Batch 1300] loss: 0.10922706415876746
[Epoch 4, Batch 1400] loss: 0.10375289821997286
[Epoch 4, Batch 1500] loss: 0.11018457403406501
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1084
Validation Accuracy: 0.9670
Overfitting: 0.1084
[Epoch 5, Batch 100] loss: 0.10717414333019405
[Epoch 5, Batch 200] loss: 0.09492434940533713
[Epoch 5, Batch 300] loss: 0.07983943703584373
[Epoch 5, Batch 400] loss: 0.11155792912933976
[Epoch 5, Batch 500] loss: 0.10651147205382586
[Epoch 5, Batch 600] loss: 0.10701174357905983
[Epoch 5, Batch 700] loss: 0.09274146676063538
[Epoch 5, Batch 800] loss: 0.09367634286638349
[Epoch 5, Batch 900] loss: 0.09647809952963143
[Epoch 5, Batch 1000] loss: 0.0880211107665673
[Epoch 5, Batch 1100] loss: 0.09880752191646025
[Epoch 5, Batch 1200] loss: 0.11742925852537155
[Epoch 5, Batch 1300] loss: 0.08960189683130011
[Epoch 5, Batch 1400] loss: 0.10606297675520182
[Epoch 5, Batch 1500] loss: 0.09457184945698828
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0870
Validation Accuracy: 0.9744
Overfitting: 0.0870
[Epoch 6, Batch 100] loss: 0.09882670261897147
[Epoch 6, Batch 200] loss: 0.08565250570885836
[Epoch 6, Batch 300] loss: 0.08999476889148354
[Epoch 6, Batch 400] loss: 0.08469296924769878
[Epoch 6, Batch 500] loss: 0.06911890245275572
[Epoch 6, Batch 600] loss: 0.08036441382020712
[Epoch 6, Batch 700] loss: 0.10343564555980266
[Epoch 6, Batch 800] loss: 0.0918528585229069
[Epoch 6, Batch 900] loss: 0.08195634446572513
[Epoch 6, Batch 1000] loss: 0.07115017879521474
[Epoch 6, Batch 1100] loss: 0.08399532463867217
[Epoch 6, Batch 1200] loss: 0.07631121135549619
[Epoch 6, Batch 1300] loss: 0.08598837404511869
[Epoch 6, Batch 1400] loss: 0.08089538036379963
[Epoch 6, Batch 1500] loss: 0.08232142449822277
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0783
Validation Accuracy: 0.9755
Overfitting: 0.0783
[Epoch 7, Batch 100] loss: 0.07063817882444709
[Epoch 7, Batch 200] loss: 0.07532868713140488
[Epoch 7, Batch 300] loss: 0.08044869709061458
[Epoch 7, Batch 400] loss: 0.0734948060195893
[Epoch 7, Batch 500] loss: 0.08118193315109239
[Epoch 7, Batch 600] loss: 0.07141595358145424
[Epoch 7, Batch 700] loss: 0.07641123199369758
[Epoch 7, Batch 800] loss: 0.08788955973577686
[Epoch 7, Batch 900] loss: 0.09764277418144048
[Epoch 7, Batch 1000] loss: 0.06409228764940053
[Epoch 7, Batch 1100] loss: 0.07273912292439491
[Epoch 7, Batch 1200] loss: 0.07513298623729497
[Epoch 7, Batch 1300] loss: 0.06452651364263147
[Epoch 7, Batch 1400] loss: 0.07341066140681506
[Epoch 7, Batch 1500] loss: 0.06323364536627196
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0725
Validation Accuracy: 0.9778
Overfitting: 0.0725
[Epoch 8, Batch 100] loss: 0.065115276647266
[Epoch 8, Batch 200] loss: 0.07112888467498124
[Epoch 8, Batch 300] loss: 0.06935591531684622
[Epoch 8, Batch 400] loss: 0.0717505590710789
[Epoch 8, Batch 500] loss: 0.06475804551970214
[Epoch 8, Batch 600] loss: 0.06636871726019308
[Epoch 8, Batch 700] loss: 0.06982726972084492
[Epoch 8, Batch 800] loss: 0.05536544990900438
[Epoch 8, Batch 900] loss: 0.06246868874994107
[Epoch 8, Batch 1000] loss: 0.07555079656420276
[Epoch 8, Batch 1100] loss: 0.0671522965002805
[Epoch 8, Batch 1200] loss: 0.06747298597707413
[Epoch 8, Batch 1300] loss: 0.06432620564009994
[Epoch 8, Batch 1400] loss: 0.06425005412427709
[Epoch 8, Batch 1500] loss: 0.06717861079145222
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0686
Validation Accuracy: 0.9788
Overfitting: 0.0686
[Epoch 9, Batch 100] loss: 0.06383920842781662
[Epoch 9, Batch 200] loss: 0.05536612408002838
[Epoch 9, Batch 300] loss: 0.06370694140437991
[Epoch 9, Batch 400] loss: 0.07147488997317851
[Epoch 9, Batch 500] loss: 0.07785704331123271
[Epoch 9, Batch 600] loss: 0.06548002578318118
[Epoch 9, Batch 700] loss: 0.06964760375209153
[Epoch 9, Batch 800] loss: 0.05697934818570502
[Epoch 9, Batch 900] loss: 0.05402632091194391
[Epoch 9, Batch 1000] loss: 0.046336554386653
[Epoch 9, Batch 1100] loss: 0.042876305470126684
[Epoch 9, Batch 1200] loss: 0.07228698331862687
[Epoch 9, Batch 1300] loss: 0.057080176717136055
[Epoch 9, Batch 1400] loss: 0.05981591864489019
[Epoch 9, Batch 1500] loss: 0.05847857357468456
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9787
Overfitting: 0.0665
Best model saved at epoch 9 with validation loss: 0.0665
[Epoch 10, Batch 100] loss: 0.06289997533895075
[Epoch 10, Batch 200] loss: 0.0444958418700844
[Epoch 10, Batch 300] loss: 0.051382823454914614
[Epoch 10, Batch 400] loss: 0.047766323328251016
[Epoch 10, Batch 500] loss: 0.06179132485296577
[Epoch 10, Batch 600] loss: 0.058713063595350834
[Epoch 10, Batch 700] loss: 0.05595836766296998
[Epoch 10, Batch 800] loss: 0.05140509409597144
[Epoch 10, Batch 900] loss: 0.05989250791491941
[Epoch 10, Batch 1000] loss: 0.05924127449980006
[Epoch 10, Batch 1100] loss: 0.06088068652199581
[Epoch 10, Batch 1200] loss: 0.05188265829579905
[Epoch 10, Batch 1300] loss: 0.0531021041283384
[Epoch 10, Batch 1400] loss: 0.058381554756779225
[Epoch 10, Batch 1500] loss: 0.05465188312111422
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0686
Validation Accuracy: 0.9782
Overfitting: 0.0686
[Epoch 11, Batch 100] loss: 0.054364492263412105
[Epoch 11, Batch 200] loss: 0.05269237610511482
[Epoch 11, Batch 300] loss: 0.05058211041614413
[Epoch 11, Batch 400] loss: 0.05005989898578264
[Epoch 11, Batch 500] loss: 0.041249205271014944
[Epoch 11, Batch 600] loss: 0.04505595579161309
[Epoch 11, Batch 700] loss: 0.06193159041460603
[Epoch 11, Batch 800] loss: 0.060026976342778655
[Epoch 11, Batch 900] loss: 0.05132736747502349
[Epoch 11, Batch 1000] loss: 0.05319640281959437
[Epoch 11, Batch 1100] loss: 0.05488525587366894
[Epoch 11, Batch 1200] loss: 0.04703808804682921
[Epoch 11, Batch 1300] loss: 0.04528201494831592
[Epoch 11, Batch 1400] loss: 0.04520094147301279
[Epoch 11, Batch 1500] loss: 0.04924365301383659
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0609
Validation Accuracy: 0.9796
Overfitting: 0.0609
Early stopping epoch 11 for trial 19. Moving to next fold.
Fold 4 validation loss: 0.0609
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.3043609714508055
[Epoch 1, Batch 200] loss: 2.3014693999290468
[Epoch 1, Batch 300] loss: 2.296541452407837
[Epoch 1, Batch 400] loss: 2.291428637504578
[Epoch 1, Batch 500] loss: 2.283538453578949
[Epoch 1, Batch 600] loss: 2.272862558364868
[Epoch 1, Batch 700] loss: 2.2562694716453553
[Epoch 1, Batch 800] loss: 2.2260817432403566
[Epoch 1, Batch 900] loss: 2.1614281010627745
[Epoch 1, Batch 1000] loss: 1.9866012561321258
[Epoch 1, Batch 1100] loss: 1.5074578821659088
[Epoch 1, Batch 1200] loss: 0.9371648180484772
[Epoch 1, Batch 1300] loss: 0.6537742692232132
[Epoch 1, Batch 1400] loss: 0.5489743575453758
[Epoch 1, Batch 1500] loss: 0.44564799189567567
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.4546
Validation Accuracy: 0.8622
Overfitting: 0.4546
[Epoch 2, Batch 100] loss: 0.4272021032869816
[Epoch 2, Batch 200] loss: 0.388978017270565
[Epoch 2, Batch 300] loss: 0.3739933727681637
[Epoch 2, Batch 400] loss: 0.36277321934700013
[Epoch 2, Batch 500] loss: 0.31208626709878445
[Epoch 2, Batch 600] loss: 0.3123602223396301
[Epoch 2, Batch 700] loss: 0.30121911719441413
[Epoch 2, Batch 800] loss: 0.2855940009653568
[Epoch 2, Batch 900] loss: 0.28464450970292093
[Epoch 2, Batch 1000] loss: 0.27367678001523016
[Epoch 2, Batch 1100] loss: 0.24868564888834954
[Epoch 2, Batch 1200] loss: 0.23656503412872554
[Epoch 2, Batch 1300] loss: 0.22636863220483064
[Epoch 2, Batch 1400] loss: 0.2342573356255889
[Epoch 2, Batch 1500] loss: 0.21418951418250798
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.2145
Validation Accuracy: 0.9353
Overfitting: 0.2145
[Epoch 3, Batch 100] loss: 0.19901467617601157
[Epoch 3, Batch 200] loss: 0.1938555046916008
[Epoch 3, Batch 300] loss: 0.2056686721742153
[Epoch 3, Batch 400] loss: 0.21510547507554292
[Epoch 3, Batch 500] loss: 0.17709640458226203
[Epoch 3, Batch 600] loss: 0.18726132897660136
[Epoch 3, Batch 700] loss: 0.1689981788955629
[Epoch 3, Batch 800] loss: 0.15437924474477768
[Epoch 3, Batch 900] loss: 0.1691426013596356
[Epoch 3, Batch 1000] loss: 0.16008829429745675
[Epoch 3, Batch 1100] loss: 0.17453838240355254
[Epoch 3, Batch 1200] loss: 0.1505551910866052
[Epoch 3, Batch 1300] loss: 0.1606370741315186
[Epoch 3, Batch 1400] loss: 0.15142442310228943
[Epoch 3, Batch 1500] loss: 0.15066886560991408
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1520
Validation Accuracy: 0.9553
Overfitting: 0.1520
[Epoch 4, Batch 100] loss: 0.13489055858924984
[Epoch 4, Batch 200] loss: 0.14034386033192278
[Epoch 4, Batch 300] loss: 0.14164646359160543
[Epoch 4, Batch 400] loss: 0.1413130302913487
[Epoch 4, Batch 500] loss: 0.12098640454933048
[Epoch 4, Batch 600] loss: 0.1361365622188896
[Epoch 4, Batch 700] loss: 0.12811432981863619
[Epoch 4, Batch 800] loss: 0.12534062398597598
[Epoch 4, Batch 900] loss: 0.11169919872656464
[Epoch 4, Batch 1000] loss: 0.14165276256389916
[Epoch 4, Batch 1100] loss: 0.12141478315927089
[Epoch 4, Batch 1200] loss: 0.12274954678490758
[Epoch 4, Batch 1300] loss: 0.14075471974909307
[Epoch 4, Batch 1400] loss: 0.11748318549245595
[Epoch 4, Batch 1500] loss: 0.11317978361621499
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1199
Validation Accuracy: 0.9638
Overfitting: 0.1199
[Epoch 5, Batch 100] loss: 0.1081346901319921
[Epoch 5, Batch 200] loss: 0.10733572221361101
[Epoch 5, Batch 300] loss: 0.10154845570214092
[Epoch 5, Batch 400] loss: 0.10539651611819863
[Epoch 5, Batch 500] loss: 0.10070861156098544
[Epoch 5, Batch 600] loss: 0.09826437627431005
[Epoch 5, Batch 700] loss: 0.1235579649079591
[Epoch 5, Batch 800] loss: 0.09585112719796599
[Epoch 5, Batch 900] loss: 0.09647620873525739
[Epoch 5, Batch 1000] loss: 0.09718625714536756
[Epoch 5, Batch 1100] loss: 0.10044615726917983
[Epoch 5, Batch 1200] loss: 0.10382550950162113
[Epoch 5, Batch 1300] loss: 0.11624766178429127
[Epoch 5, Batch 1400] loss: 0.09885803253855556
[Epoch 5, Batch 1500] loss: 0.09743391292868182
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0982
Validation Accuracy: 0.9707
Overfitting: 0.0982
[Epoch 6, Batch 100] loss: 0.10004346045665442
[Epoch 6, Batch 200] loss: 0.09283192679286004
[Epoch 6, Batch 300] loss: 0.07653943598270416
[Epoch 6, Batch 400] loss: 0.09729739069007337
[Epoch 6, Batch 500] loss: 0.09949376431293785
[Epoch 6, Batch 600] loss: 0.1033906552940607
[Epoch 6, Batch 700] loss: 0.07733738201670348
[Epoch 6, Batch 800] loss: 0.0744286452140659
[Epoch 6, Batch 900] loss: 0.0893026714073494
[Epoch 6, Batch 1000] loss: 0.08676169006153941
[Epoch 6, Batch 1100] loss: 0.0828393181739375
[Epoch 6, Batch 1200] loss: 0.10161546788644045
[Epoch 6, Batch 1300] loss: 0.08047067036386579
[Epoch 6, Batch 1400] loss: 0.081578578222543
[Epoch 6, Batch 1500] loss: 0.088009011792019
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0857
Validation Accuracy: 0.9726
Overfitting: 0.0857
[Epoch 7, Batch 100] loss: 0.08156321599613875
[Epoch 7, Batch 200] loss: 0.08337925369152799
[Epoch 7, Batch 300] loss: 0.08151247524190694
[Epoch 7, Batch 400] loss: 0.08611659654648975
[Epoch 7, Batch 500] loss: 0.08862343300133943
[Epoch 7, Batch 600] loss: 0.07188038417836651
[Epoch 7, Batch 700] loss: 0.06415074537042528
[Epoch 7, Batch 800] loss: 0.07563607002142816
[Epoch 7, Batch 900] loss: 0.08273723777849228
[Epoch 7, Batch 1000] loss: 0.07259737747954205
[Epoch 7, Batch 1100] loss: 0.0835982460808009
[Epoch 7, Batch 1200] loss: 0.07001879771240055
[Epoch 7, Batch 1300] loss: 0.06875424497760832
[Epoch 7, Batch 1400] loss: 0.07123495242092759
[Epoch 7, Batch 1500] loss: 0.07175907377153636
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0780
Validation Accuracy: 0.9755
Overfitting: 0.0780
[Epoch 8, Batch 100] loss: 0.06279701191466301
[Epoch 8, Batch 200] loss: 0.05896657096222043
[Epoch 8, Batch 300] loss: 0.06423096681945026
[Epoch 8, Batch 400] loss: 0.06600054322276265
[Epoch 8, Batch 500] loss: 0.08291365262586624
[Epoch 8, Batch 600] loss: 0.07153920138254762
[Epoch 8, Batch 700] loss: 0.07023596284911036
[Epoch 8, Batch 800] loss: 0.05804200718179345
[Epoch 8, Batch 900] loss: 0.07174615575815552
[Epoch 8, Batch 1000] loss: 0.0704572344396729
[Epoch 8, Batch 1100] loss: 0.07752967688255012
[Epoch 8, Batch 1200] loss: 0.07823048766236752
[Epoch 8, Batch 1300] loss: 0.05930660796817392
[Epoch 8, Batch 1400] loss: 0.07153154941275716
[Epoch 8, Batch 1500] loss: 0.07026058443821967
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0794
Validation Accuracy: 0.9750
Overfitting: 0.0794
[Epoch 9, Batch 100] loss: 0.07547161362366751
[Epoch 9, Batch 200] loss: 0.06644961974583566
[Epoch 9, Batch 300] loss: 0.06448470091447234
[Epoch 9, Batch 400] loss: 0.06809984164661728
[Epoch 9, Batch 500] loss: 0.05722908133873716
[Epoch 9, Batch 600] loss: 0.05821422815788537
[Epoch 9, Batch 700] loss: 0.06442512701265514
[Epoch 9, Batch 800] loss: 0.06552708016010002
[Epoch 9, Batch 900] loss: 0.05717132901540026
[Epoch 9, Batch 1000] loss: 0.06518515484873205
[Epoch 9, Batch 1100] loss: 0.06502722083125263
[Epoch 9, Batch 1200] loss: 0.05823394200298935
[Epoch 9, Batch 1300] loss: 0.06304995413171127
[Epoch 9, Batch 1400] loss: 0.0555403197882697
[Epoch 9, Batch 1500] loss: 0.057240210683085026
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0786
Validation Accuracy: 0.9755
Overfitting: 0.0786
Best model saved at epoch 9 with validation loss: 0.0786
[Epoch 10, Batch 100] loss: 0.05614158149342984
[Epoch 10, Batch 200] loss: 0.05570093283778988
[Epoch 10, Batch 300] loss: 0.05939015288488008
[Epoch 10, Batch 400] loss: 0.05031712069758214
[Epoch 10, Batch 500] loss: 0.054136604592204096
[Epoch 10, Batch 600] loss: 0.07301336323027499
[Epoch 10, Batch 700] loss: 0.05873050858965143
[Epoch 10, Batch 800] loss: 0.06561752731679008
[Epoch 10, Batch 900] loss: 0.06240430816193111
[Epoch 10, Batch 1000] loss: 0.060459464555606246
[Epoch 10, Batch 1100] loss: 0.06307307486888021
[Epoch 10, Batch 1200] loss: 0.06343473825370893
[Epoch 10, Batch 1300] loss: 0.04263709827093407
[Epoch 10, Batch 1400] loss: 0.05532360662706196
[Epoch 10, Batch 1500] loss: 0.050660163424909116
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0665
Validation Accuracy: 0.9791
Overfitting: 0.0665
[Epoch 11, Batch 100] loss: 0.0447890076530166
[Epoch 11, Batch 200] loss: 0.05293887882726267
[Epoch 11, Batch 300] loss: 0.053721696848515424
[Epoch 11, Batch 400] loss: 0.05322883737506345
[Epoch 11, Batch 500] loss: 0.04818608412984759
[Epoch 11, Batch 600] loss: 0.04910463920561597
[Epoch 11, Batch 700] loss: 0.0515841838112101
[Epoch 11, Batch 800] loss: 0.05798248314880766
[Epoch 11, Batch 900] loss: 0.06550343102193437
[Epoch 11, Batch 1000] loss: 0.06263274813885801
[Epoch 11, Batch 1100] loss: 0.04864827962475829
[Epoch 11, Batch 1200] loss: 0.055447202302748334
[Epoch 11, Batch 1300] loss: 0.055167037874925884
[Epoch 11, Batch 1400] loss: 0.05657066440093331
[Epoch 11, Batch 1500] loss: 0.05393898634938523
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0668
Validation Accuracy: 0.9791
Overfitting: 0.0668
Early stopping epoch 11 for trial 19. Moving to next fold.
Fold 5 validation loss: 0.0668
Mean validation loss across all folds for Trial 19 is 0.0648 with trial config:  l1: 256, l2: 64, lr: 0.0005, batch_size: 32
[I 2024-12-10 07:04:57,992] Trial 18 finished with value: 0.06480896238215889 and parameters: {'l1': 256, 'l2': 64, 'lr': 0.0005, 'batch_size': 32}. Best is trial 12 with value: 0.0492618556785242.

Selected Hyperparameters for Trial 20:
  l1: 128, l2: 128, lr: 0.0001, batch_size: 64
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.3045486426353454
[Epoch 1, Batch 200] loss: 2.3039738535881042
[Epoch 1, Batch 300] loss: 2.3016303515434267
[Epoch 1, Batch 400] loss: 2.3002967619895935
[Epoch 1, Batch 500] loss: 2.298283829689026
[Epoch 1, Batch 600] loss: 2.2975496292114257
[Epoch 1, Batch 700] loss: 2.296392378807068
**STATS for Epoch 1** : 
Average training loss: 0.1530
Average validation loss: 2.2942
Validation Accuracy: 0.1221
Overfitting: 2.1412
[Epoch 2, Batch 100] loss: 2.293619918823242
[Epoch 2, Batch 200] loss: 2.292313838005066
[Epoch 2, Batch 300] loss: 2.29052205324173
[Epoch 2, Batch 400] loss: 2.2889144158363344
[Epoch 2, Batch 500] loss: 2.286398482322693
[Epoch 2, Batch 600] loss: 2.284945113658905
[Epoch 2, Batch 700] loss: 2.282222988605499
**STATS for Epoch 2** : 
Average training loss: 0.1520
Average validation loss: 2.2796
Validation Accuracy: 0.1874
Overfitting: 2.1275
[Epoch 3, Batch 100] loss: 2.279387364387512
[Epoch 3, Batch 200] loss: 2.2755983233451844
[Epoch 3, Batch 300] loss: 2.2722066617012024
[Epoch 3, Batch 400] loss: 2.2692242002487184
[Epoch 3, Batch 500] loss: 2.2649881052970886
[Epoch 3, Batch 600] loss: 2.260446534156799
[Epoch 3, Batch 700] loss: 2.2558482766151426
**STATS for Epoch 3** : 
Average training loss: 0.1501
Average validation loss: 2.2498
Validation Accuracy: 0.3599
Overfitting: 2.0997
[Epoch 4, Batch 100] loss: 2.2466095304489135
[Epoch 4, Batch 200] loss: 2.2398723268508913
[Epoch 4, Batch 300] loss: 2.2312620067596436
[Epoch 4, Batch 400] loss: 2.2205581164360044
[Epoch 4, Batch 500] loss: 2.210335540771484
[Epoch 4, Batch 600] loss: 2.1974138021469116
[Epoch 4, Batch 700] loss: 2.180109267234802
**STATS for Epoch 4** : 
Average training loss: 0.1443
Average validation loss: 2.1585
Validation Accuracy: 0.5559
Overfitting: 2.0142
[Epoch 5, Batch 100] loss: 2.144963240623474
[Epoch 5, Batch 200] loss: 2.118129050731659
[Epoch 5, Batch 300] loss: 2.0818433690071108
[Epoch 5, Batch 400] loss: 2.0313033771514895
[Epoch 5, Batch 500] loss: 1.9765219604969024
[Epoch 5, Batch 600] loss: 1.9075543129444121
[Epoch 5, Batch 700] loss: 1.8050470960140228
**STATS for Epoch 5** : 
Average training loss: 0.1145
Average validation loss: 1.6828
Validation Accuracy: 0.6517
Overfitting: 1.5683
[Epoch 6, Batch 100] loss: 1.6114851701259614
[Epoch 6, Batch 200] loss: 1.4837981581687927
[Epoch 6, Batch 300] loss: 1.3315174579620361
[Epoch 6, Batch 400] loss: 1.1827424746751785
[Epoch 6, Batch 500] loss: 1.037339761853218
[Epoch 6, Batch 600] loss: 0.9359210574626923
[Epoch 6, Batch 700] loss: 0.8308062523603439
**STATS for Epoch 6** : 
Average training loss: 0.0511
Average validation loss: 0.7389
Validation Accuracy: 0.8171
Overfitting: 0.6878
[Epoch 7, Batch 100] loss: 0.7042330372333526
[Epoch 7, Batch 200] loss: 0.6687217721343041
[Epoch 7, Batch 300] loss: 0.6239018642902374
[Epoch 7, Batch 400] loss: 0.5777309414744377
[Epoch 7, Batch 500] loss: 0.544775478541851
[Epoch 7, Batch 600] loss: 0.5336532536149025
[Epoch 7, Batch 700] loss: 0.49494448900222776
**STATS for Epoch 7** : 
Average training loss: 0.0331
Average validation loss: 0.4683
Validation Accuracy: 0.8660
Overfitting: 0.4351
[Epoch 8, Batch 100] loss: 0.4810485017299652
[Epoch 8, Batch 200] loss: 0.4430730898678303
[Epoch 8, Batch 300] loss: 0.43643966034054754
[Epoch 8, Batch 400] loss: 0.4391802254319191
[Epoch 8, Batch 500] loss: 0.40734206065535544
[Epoch 8, Batch 600] loss: 0.4090443493425846
[Epoch 8, Batch 700] loss: 0.41550202533602715
**STATS for Epoch 8** : 
Average training loss: 0.0280
Average validation loss: 0.3726
Validation Accuracy: 0.8918
Overfitting: 0.3445
[Epoch 9, Batch 100] loss: 0.39324369609355925
[Epoch 9, Batch 200] loss: 0.37157026037573815
[Epoch 9, Batch 300] loss: 0.3739154405891895
[Epoch 9, Batch 400] loss: 0.3672722263634205
[Epoch 9, Batch 500] loss: 0.34103275641798975
[Epoch 9, Batch 600] loss: 0.3548721678555012
[Epoch 9, Batch 700] loss: 0.34882813662290574
**STATS for Epoch 9** : 
Average training loss: 0.0237
Average validation loss: 0.3238
Validation Accuracy: 0.9061
Overfitting: 0.3001
Best model saved at epoch 9 with validation loss: 0.3238
[Epoch 10, Batch 100] loss: 0.33230761379003526
[Epoch 10, Batch 200] loss: 0.33504920795559884
[Epoch 10, Batch 300] loss: 0.33282167837023735
[Epoch 10, Batch 400] loss: 0.3083185791224241
[Epoch 10, Batch 500] loss: 0.3354609902203083
[Epoch 10, Batch 600] loss: 0.294649228900671
[Epoch 10, Batch 700] loss: 0.30125193655490873
**STATS for Epoch 10** : 
Average training loss: 0.0215
Average validation loss: 0.2863
Validation Accuracy: 0.9167
Overfitting: 0.2649
Best model saved at epoch 10 with validation loss: 0.2863
[Epoch 11, Batch 100] loss: 0.29570468902587893
[Epoch 11, Batch 200] loss: 0.3288164174556732
[Epoch 11, Batch 300] loss: 0.27441380843520163
[Epoch 11, Batch 400] loss: 0.27783889800310135
[Epoch 11, Batch 500] loss: 0.28339644901454447
[Epoch 11, Batch 600] loss: 0.29037918739020824
[Epoch 11, Batch 700] loss: 0.2712909188866615
**STATS for Epoch 11** : 
Average training loss: 0.0183
Average validation loss: 0.2585
Validation Accuracy: 0.9243
Overfitting: 0.2402
[Epoch 12, Batch 100] loss: 0.2822329707443714
[Epoch 12, Batch 200] loss: 0.2677621509879827
[Epoch 12, Batch 300] loss: 0.27169760294258594
[Epoch 12, Batch 400] loss: 0.24937970623373984
[Epoch 12, Batch 500] loss: 0.26648349575698377
[Epoch 12, Batch 600] loss: 0.25443319194018843
[Epoch 12, Batch 700] loss: 0.2484844421595335
**STATS for Epoch 12** : 
Average training loss: 0.0166
Average validation loss: 0.2377
Validation Accuracy: 0.9304
Overfitting: 0.2211
Best model saved at epoch 12 with validation loss: 0.2377
[Epoch 13, Batch 100] loss: 0.25288441121578215
[Epoch 13, Batch 200] loss: 0.26231646217405796
[Epoch 13, Batch 300] loss: 0.26008144713938236
[Epoch 13, Batch 400] loss: 0.24027530364692212
[Epoch 13, Batch 500] loss: 0.22986417733132838
[Epoch 13, Batch 600] loss: 0.22330859042704104
[Epoch 13, Batch 700] loss: 0.22907083839178086
**STATS for Epoch 13** : 
Average training loss: 0.0148
Average validation loss: 0.2189
Validation Accuracy: 0.9358
Overfitting: 0.2041
[Epoch 14, Batch 100] loss: 0.23963753685355185
[Epoch 14, Batch 200] loss: 0.23566834777593612
[Epoch 14, Batch 300] loss: 0.212569033280015
[Epoch 14, Batch 400] loss: 0.23046807534992694
[Epoch 14, Batch 500] loss: 0.22208304904401302
[Epoch 14, Batch 600] loss: 0.21273204147815705
[Epoch 14, Batch 700] loss: 0.21981009878218175
**STATS for Epoch 14** : 
Average training loss: 0.0156
Average validation loss: 0.2027
Validation Accuracy: 0.9423
Overfitting: 0.1872
Best model saved at epoch 14 with validation loss: 0.2027
[Epoch 15, Batch 100] loss: 0.22116322293877602
[Epoch 15, Batch 200] loss: 0.20514042913913727
[Epoch 15, Batch 300] loss: 0.20742587100714446
[Epoch 15, Batch 400] loss: 0.2022770619392395
[Epoch 15, Batch 500] loss: 0.22481904774904252
[Epoch 15, Batch 600] loss: 0.20929364696145059
[Epoch 15, Batch 700] loss: 0.19960696645081044
**STATS for Epoch 15** : 
Average training loss: 0.0143
Average validation loss: 0.1895
Validation Accuracy: 0.9451
Overfitting: 0.1753
[Epoch 16, Batch 100] loss: 0.2065763234347105
[Epoch 16, Batch 200] loss: 0.1946452097222209
[Epoch 16, Batch 300] loss: 0.1987877282500267
[Epoch 16, Batch 400] loss: 0.18205032050609588
[Epoch 16, Batch 500] loss: 0.20716707691550254
[Epoch 16, Batch 600] loss: 0.2094335275143385
[Epoch 16, Batch 700] loss: 0.1907372283935547
**STATS for Epoch 16** : 
Average training loss: 0.0123
Average validation loss: 0.1782
Validation Accuracy: 0.9487
Overfitting: 0.1659
Early stopping epoch 16 for trial 20. Moving to next fold.
Fold 1 validation loss: 0.1782
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2996464347839356
[Epoch 1, Batch 200] loss: 2.297878768444061
[Epoch 1, Batch 300] loss: 2.2959564876556398
[Epoch 1, Batch 400] loss: 2.29482634305954
[Epoch 1, Batch 500] loss: 2.293271300792694
[Epoch 1, Batch 600] loss: 2.2908242177963256
[Epoch 1, Batch 700] loss: 2.290346021652222
**STATS for Epoch 1** : 
Average training loss: 0.1527
Average validation loss: 2.2874
Validation Accuracy: 0.1061
Overfitting: 2.1347
[Epoch 2, Batch 100] loss: 2.285572278499603
[Epoch 2, Batch 200] loss: 2.2849336290359497
[Epoch 2, Batch 300] loss: 2.281334915161133
[Epoch 2, Batch 400] loss: 2.2781024241447447
[Epoch 2, Batch 500] loss: 2.275694177150726
[Epoch 2, Batch 600] loss: 2.271542844772339
[Epoch 2, Batch 700] loss: 2.266931130886078
**STATS for Epoch 2** : 
Average training loss: 0.1510
Average validation loss: 2.2629
Validation Accuracy: 0.1724
Overfitting: 2.1119
[Epoch 3, Batch 100] loss: 2.260635960102081
[Epoch 3, Batch 200] loss: 2.2537318325042723
[Epoch 3, Batch 300] loss: 2.2482510828971862
[Epoch 3, Batch 400] loss: 2.2406347036361693
[Epoch 3, Batch 500] loss: 2.2314802765846253
[Epoch 3, Batch 600] loss: 2.2178754687309263
[Epoch 3, Batch 700] loss: 2.206264615058899
**STATS for Epoch 3** : 
Average training loss: 0.1464
Average validation loss: 2.1892
Validation Accuracy: 0.3872
Overfitting: 2.0428
[Epoch 4, Batch 100] loss: 2.1785154724121094
[Epoch 4, Batch 200] loss: 2.1546575093269347
[Epoch 4, Batch 300] loss: 2.1249075055122377
[Epoch 4, Batch 400] loss: 2.0884823322296144
[Epoch 4, Batch 500] loss: 2.0381825160980225
[Epoch 4, Batch 600] loss: 1.9717523050308228
[Epoch 4, Batch 700] loss: 1.892486217021942
**STATS for Epoch 4** : 
Average training loss: 0.1213
Average validation loss: 1.7934
Validation Accuracy: 0.5300
Overfitting: 1.6721
[Epoch 5, Batch 100] loss: 1.7424718761444091
[Epoch 5, Batch 200] loss: 1.6188475692272186
[Epoch 5, Batch 300] loss: 1.4927452743053435
[Epoch 5, Batch 400] loss: 1.3534319138526916
[Epoch 5, Batch 500] loss: 1.245123064517975
[Epoch 5, Batch 600] loss: 1.1254386174678803
[Epoch 5, Batch 700] loss: 1.0483134710788726
**STATS for Epoch 5** : 
Average training loss: 0.0669
Average validation loss: 0.9832
Validation Accuracy: 0.7283
Overfitting: 0.9164
[Epoch 6, Batch 100] loss: 0.9434943550825119
[Epoch 6, Batch 200] loss: 0.8895905548334122
[Epoch 6, Batch 300] loss: 0.8232265478372573
[Epoch 6, Batch 400] loss: 0.7871997368335724
[Epoch 6, Batch 500] loss: 0.7488629612326622
[Epoch 6, Batch 600] loss: 0.7072955477237701
[Epoch 6, Batch 700] loss: 0.6530759480595588
**STATS for Epoch 6** : 
Average training loss: 0.0432
Average validation loss: 0.6560
Validation Accuracy: 0.8064
Overfitting: 0.6128
[Epoch 7, Batch 100] loss: 0.6325699937343597
[Epoch 7, Batch 200] loss: 0.5811336079239845
[Epoch 7, Batch 300] loss: 0.590536712706089
[Epoch 7, Batch 400] loss: 0.5611788871884346
[Epoch 7, Batch 500] loss: 0.5453221142292023
[Epoch 7, Batch 600] loss: 0.5084670287370682
[Epoch 7, Batch 700] loss: 0.48541503816843035
**STATS for Epoch 7** : 
Average training loss: 0.0336
Average validation loss: 0.4948
Validation Accuracy: 0.8573
Overfitting: 0.4613
[Epoch 8, Batch 100] loss: 0.4770702086389065
[Epoch 8, Batch 200] loss: 0.46463396698236464
[Epoch 8, Batch 300] loss: 0.44474094837903977
[Epoch 8, Batch 400] loss: 0.4447795456647873
[Epoch 8, Batch 500] loss: 0.4214937913417816
[Epoch 8, Batch 600] loss: 0.4133728976547718
[Epoch 8, Batch 700] loss: 0.4118350340425968
**STATS for Epoch 8** : 
Average training loss: 0.0267
Average validation loss: 0.4108
Validation Accuracy: 0.8782
Overfitting: 0.3841
[Epoch 9, Batch 100] loss: 0.3969823680818081
[Epoch 9, Batch 200] loss: 0.38360883355140685
[Epoch 9, Batch 300] loss: 0.38528465300798415
[Epoch 9, Batch 400] loss: 0.36240381613373757
[Epoch 9, Batch 500] loss: 0.3737372709810734
[Epoch 9, Batch 600] loss: 0.3659121173620224
[Epoch 9, Batch 700] loss: 0.3310998022556305
**STATS for Epoch 9** : 
Average training loss: 0.0234
Average validation loss: 0.3581
Validation Accuracy: 0.8922
Overfitting: 0.3347
Best model saved at epoch 9 with validation loss: 0.3581
[Epoch 10, Batch 100] loss: 0.3353402265161276
[Epoch 10, Batch 200] loss: 0.33280972346663473
[Epoch 10, Batch 300] loss: 0.3283789998292923
[Epoch 10, Batch 400] loss: 0.3270900811254978
[Epoch 10, Batch 500] loss: 0.33495837181806565
[Epoch 10, Batch 600] loss: 0.31043581999838354
[Epoch 10, Batch 700] loss: 0.3225772152841091
**STATS for Epoch 10** : 
Average training loss: 0.0215
Average validation loss: 0.3299
Validation Accuracy: 0.9028
Overfitting: 0.3085
[Epoch 11, Batch 100] loss: 0.28904269486665723
[Epoch 11, Batch 200] loss: 0.32614507623016836
[Epoch 11, Batch 300] loss: 0.30068208180367945
[Epoch 11, Batch 400] loss: 0.3016416199505329
[Epoch 11, Batch 500] loss: 0.28975566297769545
[Epoch 11, Batch 600] loss: 0.28843083828687666
[Epoch 11, Batch 700] loss: 0.2796234943717718
**STATS for Epoch 11** : 
Average training loss: 0.0195
Average validation loss: 0.3018
Validation Accuracy: 0.9100
Overfitting: 0.2823
Best model saved at epoch 11 with validation loss: 0.3018
[Epoch 12, Batch 100] loss: 0.26938240088522436
[Epoch 12, Batch 200] loss: 0.2647389787435532
[Epoch 12, Batch 300] loss: 0.2708992450684309
[Epoch 12, Batch 400] loss: 0.2787345048040152
[Epoch 12, Batch 500] loss: 0.2928831995278597
[Epoch 12, Batch 600] loss: 0.26720337718725207
[Epoch 12, Batch 700] loss: 0.27090996570885184
**STATS for Epoch 12** : 
Average training loss: 0.0159
Average validation loss: 0.2776
Validation Accuracy: 0.9173
Overfitting: 0.2618
[Epoch 13, Batch 100] loss: 0.2678302562981844
[Epoch 13, Batch 200] loss: 0.25113740913569926
[Epoch 13, Batch 300] loss: 0.25391011998057367
[Epoch 13, Batch 400] loss: 0.25626274466514587
[Epoch 13, Batch 500] loss: 0.2551947893202305
[Epoch 13, Batch 600] loss: 0.2555056021362543
[Epoch 13, Batch 700] loss: 0.22748289130628108
**STATS for Epoch 13** : 
Average training loss: 0.0159
Average validation loss: 0.2558
Validation Accuracy: 0.9230
Overfitting: 0.2399
Best model saved at epoch 13 with validation loss: 0.2558
[Epoch 14, Batch 100] loss: 0.24503612041473388
[Epoch 14, Batch 200] loss: 0.23051631964743138
[Epoch 14, Batch 300] loss: 0.23695006035268307
[Epoch 14, Batch 400] loss: 0.24297351881861687
[Epoch 14, Batch 500] loss: 0.23955948486924172
[Epoch 14, Batch 600] loss: 0.22975895941257476
[Epoch 14, Batch 700] loss: 0.2300572406128049
**STATS for Epoch 14** : 
Average training loss: 0.0138
Average validation loss: 0.2461
Validation Accuracy: 0.9265
Overfitting: 0.2323
[Epoch 15, Batch 100] loss: 0.2165822184085846
[Epoch 15, Batch 200] loss: 0.22678100280463695
[Epoch 15, Batch 300] loss: 0.22185435213148594
[Epoch 15, Batch 400] loss: 0.2186164827644825
[Epoch 15, Batch 500] loss: 0.22767780497670173
[Epoch 15, Batch 600] loss: 0.2208655985444784
[Epoch 15, Batch 700] loss: 0.2127996615320444
**STATS for Epoch 15** : 
Average training loss: 0.0150
Average validation loss: 0.2311
Validation Accuracy: 0.9313
Overfitting: 0.2161
Early stopping epoch 15 for trial 20. Moving to next fold.
Fold 2 validation loss: 0.2311
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3029567909240725
[Epoch 1, Batch 200] loss: 2.302020797729492
[Epoch 1, Batch 300] loss: 2.300378694534302
[Epoch 1, Batch 400] loss: 2.2994693660736085
[Epoch 1, Batch 500] loss: 2.297409038543701
[Epoch 1, Batch 600] loss: 2.2970104026794433
[Epoch 1, Batch 700] loss: 2.2960450863838195
**STATS for Epoch 1** : 
Average training loss: 0.1529
Average validation loss: 2.2936
Validation Accuracy: 0.1065
Overfitting: 2.1406
[Epoch 2, Batch 100] loss: 2.2931738662719727
[Epoch 2, Batch 200] loss: 2.2919524908065796
[Epoch 2, Batch 300] loss: 2.2897165560722352
[Epoch 2, Batch 400] loss: 2.2882451939582826
[Epoch 2, Batch 500] loss: 2.2865006637573244
[Epoch 2, Batch 600] loss: 2.283915390968323
[Epoch 2, Batch 700] loss: 2.281856734752655
**STATS for Epoch 2** : 
Average training loss: 0.1520
Average validation loss: 2.2788
Validation Accuracy: 0.2797
Overfitting: 2.1268
[Epoch 3, Batch 100] loss: 2.2771703505516054
[Epoch 3, Batch 200] loss: 2.274375014305115
[Epoch 3, Batch 300] loss: 2.2707911801338194
[Epoch 3, Batch 400] loss: 2.2668502736091614
[Epoch 3, Batch 500] loss: 2.2626827335357667
[Epoch 3, Batch 600] loss: 2.257353093624115
[Epoch 3, Batch 700] loss: 2.2507003235816954
**STATS for Epoch 3** : 
Average training loss: 0.1498
Average validation loss: 2.2442
Validation Accuracy: 0.4016
Overfitting: 2.0944
[Epoch 4, Batch 100] loss: 2.2395541286468506
[Epoch 4, Batch 200] loss: 2.231285264492035
[Epoch 4, Batch 300] loss: 2.218831753730774
[Epoch 4, Batch 400] loss: 2.208577883243561
[Epoch 4, Batch 500] loss: 2.1920056557655334
[Epoch 4, Batch 600] loss: 2.1750194597244263
[Epoch 4, Batch 700] loss: 2.1508102560043336
**STATS for Epoch 4** : 
Average training loss: 0.1420
Average validation loss: 2.1203
Validation Accuracy: 0.3934
Overfitting: 1.9783
[Epoch 5, Batch 100] loss: 2.1014122128486634
[Epoch 5, Batch 200] loss: 2.0603816866874696
[Epoch 5, Batch 300] loss: 2.00613422870636
[Epoch 5, Batch 400] loss: 1.9330284976959229
[Epoch 5, Batch 500] loss: 1.843190472126007
[Epoch 5, Batch 600] loss: 1.7541496407985688
[Epoch 5, Batch 700] loss: 1.6347006607055663
**STATS for Epoch 5** : 
Average training loss: 0.1037
Average validation loss: 1.5156
Validation Accuracy: 0.5750
Overfitting: 1.4119
[Epoch 6, Batch 100] loss: 1.462193604707718
[Epoch 6, Batch 200] loss: 1.3465220737457275
[Epoch 6, Batch 300] loss: 1.2364043498039246
[Epoch 6, Batch 400] loss: 1.1360965234041214
[Epoch 6, Batch 500] loss: 1.0349841701984406
[Epoch 6, Batch 600] loss: 0.9551989787817001
[Epoch 6, Batch 700] loss: 0.8806589186191559
**STATS for Epoch 6** : 
Average training loss: 0.0572
Average validation loss: 0.8065
Validation Accuracy: 0.7852
Overfitting: 0.7493
[Epoch 7, Batch 100] loss: 0.7815815752744675
[Epoch 7, Batch 200] loss: 0.738408418893814
[Epoch 7, Batch 300] loss: 0.7107789769768715
[Epoch 7, Batch 400] loss: 0.6688845124840737
[Epoch 7, Batch 500] loss: 0.6431384286284447
[Epoch 7, Batch 600] loss: 0.590809426009655
[Epoch 7, Batch 700] loss: 0.5700296029448509
**STATS for Epoch 7** : 
Average training loss: 0.0390
Average validation loss: 0.5469
Validation Accuracy: 0.8427
Overfitting: 0.5078
[Epoch 8, Batch 100] loss: 0.5462999016046524
[Epoch 8, Batch 200] loss: 0.5288670879602432
[Epoch 8, Batch 300] loss: 0.514462629854679
[Epoch 8, Batch 400] loss: 0.49885912746191025
[Epoch 8, Batch 500] loss: 0.4953485858440399
[Epoch 8, Batch 600] loss: 0.4862323260307312
[Epoch 8, Batch 700] loss: 0.4672685080766678
**STATS for Epoch 8** : 
Average training loss: 0.0311
Average validation loss: 0.4503
Validation Accuracy: 0.8662
Overfitting: 0.4192
[Epoch 9, Batch 100] loss: 0.4543703418970108
[Epoch 9, Batch 200] loss: 0.4414657278358936
[Epoch 9, Batch 300] loss: 0.4427827051281929
[Epoch 9, Batch 400] loss: 0.43243505313992503
[Epoch 9, Batch 500] loss: 0.42429286524653437
[Epoch 9, Batch 600] loss: 0.4059321235120297
[Epoch 9, Batch 700] loss: 0.40350892454385756
**STATS for Epoch 9** : 
Average training loss: 0.0266
Average validation loss: 0.3939
Validation Accuracy: 0.8819
Overfitting: 0.3673
Best model saved at epoch 9 with validation loss: 0.3939
[Epoch 10, Batch 100] loss: 0.4048791083693504
[Epoch 10, Batch 200] loss: 0.389293123036623
[Epoch 10, Batch 300] loss: 0.3650129850208759
[Epoch 10, Batch 400] loss: 0.38130552023649217
[Epoch 10, Batch 500] loss: 0.38651619508862495
[Epoch 10, Batch 600] loss: 0.36715991944074633
[Epoch 10, Batch 700] loss: 0.3625418657064438
**STATS for Epoch 10** : 
Average training loss: 0.0242
Average validation loss: 0.3554
Validation Accuracy: 0.8943
Overfitting: 0.3312
Best model saved at epoch 10 with validation loss: 0.3554
[Epoch 11, Batch 100] loss: 0.3632015188038349
[Epoch 11, Batch 200] loss: 0.3511581175029278
[Epoch 11, Batch 300] loss: 0.34247227996587754
[Epoch 11, Batch 400] loss: 0.34625427722930907
[Epoch 11, Batch 500] loss: 0.3284791687130928
[Epoch 11, Batch 600] loss: 0.3431526643037796
[Epoch 11, Batch 700] loss: 0.3305776283144951
**STATS for Epoch 11** : 
Average training loss: 0.0213
Average validation loss: 0.3251
Validation Accuracy: 0.9024
Overfitting: 0.3038
Best model saved at epoch 11 with validation loss: 0.3251
[Epoch 12, Batch 100] loss: 0.3236264902353287
[Epoch 12, Batch 200] loss: 0.3184245824813843
[Epoch 12, Batch 300] loss: 0.3134029596298933
[Epoch 12, Batch 400] loss: 0.30749112106859683
[Epoch 12, Batch 500] loss: 0.3125241930782795
[Epoch 12, Batch 600] loss: 0.3237224221229553
[Epoch 12, Batch 700] loss: 0.30160960301756856
**STATS for Epoch 12** : 
Average training loss: 0.0196
Average validation loss: 0.3030
Validation Accuracy: 0.9099
Overfitting: 0.2834
[Epoch 13, Batch 100] loss: 0.28712353594601153
[Epoch 13, Batch 200] loss: 0.3038657146692276
[Epoch 13, Batch 300] loss: 0.28776953302323816
[Epoch 13, Batch 400] loss: 0.2833698005974293
[Epoch 13, Batch 500] loss: 0.2833974351733923
[Epoch 13, Batch 600] loss: 0.2943339604139328
[Epoch 13, Batch 700] loss: 0.2799485716968775
**STATS for Epoch 13** : 
Average training loss: 0.0187
Average validation loss: 0.2817
Validation Accuracy: 0.9154
Overfitting: 0.2630
Best model saved at epoch 13 with validation loss: 0.2817
[Epoch 14, Batch 100] loss: 0.26722251877188685
[Epoch 14, Batch 200] loss: 0.2670122157037258
[Epoch 14, Batch 300] loss: 0.26212138779461386
[Epoch 14, Batch 400] loss: 0.2795687638223171
[Epoch 14, Batch 500] loss: 0.25948438331484797
[Epoch 14, Batch 600] loss: 0.2704584152251482
[Epoch 14, Batch 700] loss: 0.2542297774553299
**STATS for Epoch 14** : 
Average training loss: 0.0187
Average validation loss: 0.2573
Validation Accuracy: 0.9233
Overfitting: 0.2385
[Epoch 15, Batch 100] loss: 0.2511438613384962
[Epoch 15, Batch 200] loss: 0.26166843887418506
[Epoch 15, Batch 300] loss: 0.2505995014309883
[Epoch 15, Batch 400] loss: 0.2401373030245304
[Epoch 15, Batch 500] loss: 0.23883349038660526
[Epoch 15, Batch 600] loss: 0.2524572955071926
[Epoch 15, Batch 700] loss: 0.23935170590877533
**STATS for Epoch 15** : 
Average training loss: 0.0160
Average validation loss: 0.2454
Validation Accuracy: 0.9271
Overfitting: 0.2295
Best model saved at epoch 15 with validation loss: 0.2454
[Epoch 16, Batch 100] loss: 0.24254014529287815
[Epoch 16, Batch 200] loss: 0.24524983055889607
[Epoch 16, Batch 300] loss: 0.2296535786241293
[Epoch 16, Batch 400] loss: 0.24424552850425243
[Epoch 16, Batch 500] loss: 0.21182252787053585
[Epoch 16, Batch 600] loss: 0.23757486455142499
[Epoch 16, Batch 700] loss: 0.2131310474127531
**STATS for Epoch 16** : 
Average training loss: 0.0144
Average validation loss: 0.2280
Validation Accuracy: 0.9330
Overfitting: 0.2136
/home/ahussain/PycharmProjects/optunaNew/.venv/lib/python3.8/site-packages/optuna/trial/_trial.py:493: UserWarning: The reported value is ignored because this `step` 15 is already reported.
  warnings.warn(
[Epoch 17, Batch 100] loss: 0.22650807455182076
[Epoch 17, Batch 200] loss: 0.22325628042221068
[Epoch 17, Batch 300] loss: 0.21842027992010116
[Epoch 17, Batch 400] loss: 0.20722490027546883
[Epoch 17, Batch 500] loss: 0.21145023457705975
[Epoch 17, Batch 600] loss: 0.21019600793719292
[Epoch 17, Batch 700] loss: 0.21484882049262524
**STATS for Epoch 17** : 
Average training loss: 0.0144
Average validation loss: 0.2180
Validation Accuracy: 0.9349
Overfitting: 0.2036
Early stopping epoch 17 for trial 20. Moving to next fold.
Fold 3 validation loss: 0.2180
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2996256852149966
[Epoch 1, Batch 200] loss: 2.2963195419311524
[Epoch 1, Batch 300] loss: 2.2923582410812378
[Epoch 1, Batch 400] loss: 2.2896444368362427
[Epoch 1, Batch 500] loss: 2.286723184585571
[Epoch 1, Batch 600] loss: 2.283050014972687
[Epoch 1, Batch 700] loss: 2.280941195487976
**STATS for Epoch 1** : 
Average training loss: 0.1519
Average validation loss: 2.2767
Validation Accuracy: 0.2986
Overfitting: 2.1248
[Epoch 2, Batch 100] loss: 2.273839497566223
[Epoch 2, Batch 200] loss: 2.2680192255973814
[Epoch 2, Batch 300] loss: 2.2635774636268615
[Epoch 2, Batch 400] loss: 2.258105697631836
[Epoch 2, Batch 500] loss: 2.2496043610572816
[Epoch 2, Batch 600] loss: 2.240180368423462
[Epoch 2, Batch 700] loss: 2.229866347312927
**STATS for Epoch 2** : 
Average training loss: 0.1480
Average validation loss: 2.2198
Validation Accuracy: 0.5648
Overfitting: 2.0718
[Epoch 3, Batch 100] loss: 2.2123617839813234
[Epoch 3, Batch 200] loss: 2.1927819776535036
[Epoch 3, Batch 300] loss: 2.1726570606231688
[Epoch 3, Batch 400] loss: 2.1455497670173647
[Epoch 3, Batch 500] loss: 2.1096054220199587
[Epoch 3, Batch 600] loss: 2.060872832536697
[Epoch 3, Batch 700] loss: 2.0019361102581024
**STATS for Epoch 3** : 
Average training loss: 0.1296
Average validation loss: 1.9306
Validation Accuracy: 0.6682
Overfitting: 1.8010
[Epoch 4, Batch 100] loss: 1.8740752482414245
[Epoch 4, Batch 200] loss: 1.7580246531963348
[Epoch 4, Batch 300] loss: 1.6091972374916077
[Epoch 4, Batch 400] loss: 1.4297563862800597
[Epoch 4, Batch 500] loss: 1.2706182980537415
[Epoch 4, Batch 600] loss: 1.1081394356489183
[Epoch 4, Batch 700] loss: 0.9609255743026733
**STATS for Epoch 4** : 
Average training loss: 0.0590
Average validation loss: 0.8703
Validation Accuracy: 0.7956
Overfitting: 0.8113
[Epoch 5, Batch 100] loss: 0.8049093747138977
[Epoch 5, Batch 200] loss: 0.7534966558218003
[Epoch 5, Batch 300] loss: 0.6884412059187889
[Epoch 5, Batch 400] loss: 0.6588731157779694
[Epoch 5, Batch 500] loss: 0.6142634126543999
[Epoch 5, Batch 600] loss: 0.5714090126752853
[Epoch 5, Batch 700] loss: 0.5669885450601577
**STATS for Epoch 5** : 
Average training loss: 0.0374
Average validation loss: 0.5475
Validation Accuracy: 0.8437
Overfitting: 0.5101
[Epoch 6, Batch 100] loss: 0.5060093548893928
[Epoch 6, Batch 200] loss: 0.5287198913097382
[Epoch 6, Batch 300] loss: 0.5029694107174874
[Epoch 6, Batch 400] loss: 0.4891850435733795
[Epoch 6, Batch 500] loss: 0.48073964297771454
[Epoch 6, Batch 600] loss: 0.47814579129219054
[Epoch 6, Batch 700] loss: 0.45688877657055854
**STATS for Epoch 6** : 
Average training loss: 0.0308
Average validation loss: 0.4581
Validation Accuracy: 0.8642
Overfitting: 0.4273
[Epoch 7, Batch 100] loss: 0.44259566083550456
[Epoch 7, Batch 200] loss: 0.43463904976844786
[Epoch 7, Batch 300] loss: 0.42058668181300163
[Epoch 7, Batch 400] loss: 0.42301413908600805
[Epoch 7, Batch 500] loss: 0.42702832236886024
[Epoch 7, Batch 600] loss: 0.38902845203876496
[Epoch 7, Batch 700] loss: 0.4016329479217529
**STATS for Epoch 7** : 
Average training loss: 0.0280
Average validation loss: 0.3986
Validation Accuracy: 0.8786
Overfitting: 0.3706
[Epoch 8, Batch 100] loss: 0.3818163435161114
[Epoch 8, Batch 200] loss: 0.3810796225070953
[Epoch 8, Batch 300] loss: 0.3941023440659046
[Epoch 8, Batch 400] loss: 0.36394805029034616
[Epoch 8, Batch 500] loss: 0.36315272241830826
[Epoch 8, Batch 600] loss: 0.3757787911593914
[Epoch 8, Batch 700] loss: 0.3628570979833603
**STATS for Epoch 8** : 
Average training loss: 0.0245
Average validation loss: 0.3591
Validation Accuracy: 0.8914
Overfitting: 0.3346
[Epoch 9, Batch 100] loss: 0.3630045582354069
[Epoch 9, Batch 200] loss: 0.3556172386556864
[Epoch 9, Batch 300] loss: 0.3296153645217419
[Epoch 9, Batch 400] loss: 0.3411244389414787
[Epoch 9, Batch 500] loss: 0.3445862109959126
[Epoch 9, Batch 600] loss: 0.3320180743932724
[Epoch 9, Batch 700] loss: 0.3306039895117283
**STATS for Epoch 9** : 
Average training loss: 0.0210
Average validation loss: 0.3299
Validation Accuracy: 0.8972
Overfitting: 0.3089
Best model saved at epoch 9 with validation loss: 0.3299
[Epoch 10, Batch 100] loss: 0.31705374784767626
[Epoch 10, Batch 200] loss: 0.31550572723150255
[Epoch 10, Batch 300] loss: 0.3184669503569603
[Epoch 10, Batch 400] loss: 0.3156660932302475
[Epoch 10, Batch 500] loss: 0.3008966846764088
[Epoch 10, Batch 600] loss: 0.30758454285562037
[Epoch 10, Batch 700] loss: 0.3163255201280117
**STATS for Epoch 10** : 
Average training loss: 0.0201
Average validation loss: 0.3073
Validation Accuracy: 0.9058
Overfitting: 0.2873
[Epoch 11, Batch 100] loss: 0.2844052824378014
[Epoch 11, Batch 200] loss: 0.2923204217851162
[Epoch 11, Batch 300] loss: 0.2884525927901268
[Epoch 11, Batch 400] loss: 0.2882262546569109
[Epoch 11, Batch 500] loss: 0.28858517937362194
[Epoch 11, Batch 600] loss: 0.28958607874810693
[Epoch 11, Batch 700] loss: 0.29730132207274435
**STATS for Epoch 11** : 
Average training loss: 0.0194
Average validation loss: 0.2850
Validation Accuracy: 0.9118
Overfitting: 0.2656
Best model saved at epoch 11 with validation loss: 0.2850
[Epoch 12, Batch 100] loss: 0.2817343806475401
[Epoch 12, Batch 200] loss: 0.2759053123742342
[Epoch 12, Batch 300] loss: 0.2774135959893465
[Epoch 12, Batch 400] loss: 0.25257645554840563
[Epoch 12, Batch 500] loss: 0.2667982131242752
[Epoch 12, Batch 600] loss: 0.26971682347357273
[Epoch 12, Batch 700] loss: 0.26158041022717954
**STATS for Epoch 12** : 
Average training loss: 0.0181
Average validation loss: 0.2608
Validation Accuracy: 0.9202
Overfitting: 0.2427
[Epoch 13, Batch 100] loss: 0.24868105188012124
[Epoch 13, Batch 200] loss: 0.2514007046818733
[Epoch 13, Batch 300] loss: 0.23934383682906626
[Epoch 13, Batch 400] loss: 0.2675203066319227
[Epoch 13, Batch 500] loss: 0.24021829724311827
[Epoch 13, Batch 600] loss: 0.25348367117345333
[Epoch 13, Batch 700] loss: 0.2629898833483458
**STATS for Epoch 13** : 
Average training loss: 0.0157
Average validation loss: 0.2466
Validation Accuracy: 0.9237
Overfitting: 0.2309
Best model saved at epoch 13 with validation loss: 0.2466
[Epoch 14, Batch 100] loss: 0.2399457561969757
[Epoch 14, Batch 200] loss: 0.24333666644990445
[Epoch 14, Batch 300] loss: 0.23443330399692058
[Epoch 14, Batch 400] loss: 0.2324389300867915
[Epoch 14, Batch 500] loss: 0.23718129113316536
[Epoch 14, Batch 600] loss: 0.2405083728581667
[Epoch 14, Batch 700] loss: 0.23025643281638622
**STATS for Epoch 14** : 
Average training loss: 0.0145
Average validation loss: 0.2298
Validation Accuracy: 0.9287
Overfitting: 0.2153
[Epoch 15, Batch 100] loss: 0.22144257687032223
[Epoch 15, Batch 200] loss: 0.22802066221833228
[Epoch 15, Batch 300] loss: 0.2225418619811535
[Epoch 15, Batch 400] loss: 0.21064211457967758
[Epoch 15, Batch 500] loss: 0.21714364822953938
[Epoch 15, Batch 600] loss: 0.21403376564383506
[Epoch 15, Batch 700] loss: 0.22486899189651013
**STATS for Epoch 15** : 
Average training loss: 0.0157
Average validation loss: 0.2201
Validation Accuracy: 0.9327
Overfitting: 0.2044
Early stopping epoch 15 for trial 20. Moving to next fold.
Fold 4 validation loss: 0.2201
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.301808526515961
[Epoch 1, Batch 200] loss: 2.30030336856842
[Epoch 1, Batch 300] loss: 2.298113989830017
[Epoch 1, Batch 400] loss: 2.294643349647522
[Epoch 1, Batch 500] loss: 2.292835223674774
[Epoch 1, Batch 600] loss: 2.289043405056
[Epoch 1, Batch 700] loss: 2.2863298869132995
**STATS for Epoch 1** : 
Average training loss: 0.1524
Average validation loss: 2.2844
Validation Accuracy: 0.1856
Overfitting: 2.1320
[Epoch 2, Batch 100] loss: 2.2823391342163086
[Epoch 2, Batch 200] loss: 2.279608392715454
[Epoch 2, Batch 300] loss: 2.275781524181366
[Epoch 2, Batch 400] loss: 2.2728430223464966
[Epoch 2, Batch 500] loss: 2.2691636872291565
[Epoch 2, Batch 600] loss: 2.2637606692314147
[Epoch 2, Batch 700] loss: 2.258647928237915
**STATS for Epoch 2** : 
Average training loss: 0.1502
Average validation loss: 2.2529
Validation Accuracy: 0.2836
Overfitting: 2.1026
[Epoch 3, Batch 100] loss: 2.2485549736022947
[Epoch 3, Batch 200] loss: 2.2421644735336304
[Epoch 3, Batch 300] loss: 2.233548300266266
[Epoch 3, Batch 400] loss: 2.223255977630615
[Epoch 3, Batch 500] loss: 2.21433979511261
[Epoch 3, Batch 600] loss: 2.198441758155823
[Epoch 3, Batch 700] loss: 2.1807180786132814
**STATS for Epoch 3** : 
Average training loss: 0.1444
Average validation loss: 2.1594
Validation Accuracy: 0.5320
Overfitting: 2.0150
[Epoch 4, Batch 100] loss: 2.148676688671112
[Epoch 4, Batch 200] loss: 2.1159688210487366
[Epoch 4, Batch 300] loss: 2.0848178005218507
[Epoch 4, Batch 400] loss: 2.0299946212768556
[Epoch 4, Batch 500] loss: 1.9714810919761658
[Epoch 4, Batch 600] loss: 1.9002286338806151
[Epoch 4, Batch 700] loss: 1.7859502160549163
**STATS for Epoch 4** : 
Average training loss: 0.1136
Average validation loss: 1.6694
Validation Accuracy: 0.6889
Overfitting: 1.5558
[Epoch 5, Batch 100] loss: 1.5899041604995727
[Epoch 5, Batch 200] loss: 1.4441257262229918
[Epoch 5, Batch 300] loss: 1.2894157755374909
[Epoch 5, Batch 400] loss: 1.1298841458559037
[Epoch 5, Batch 500] loss: 0.9890800315141678
[Epoch 5, Batch 600] loss: 0.88058807015419
[Epoch 5, Batch 700] loss: 0.8116608911752701
**STATS for Epoch 5** : 
Average training loss: 0.0511
Average validation loss: 0.7408
Validation Accuracy: 0.8023
Overfitting: 0.6897
[Epoch 6, Batch 100] loss: 0.7002338337898254
[Epoch 6, Batch 200] loss: 0.6606839832663536
[Epoch 6, Batch 300] loss: 0.6273452442884445
[Epoch 6, Batch 400] loss: 0.6007287988066673
[Epoch 6, Batch 500] loss: 0.5588454127311706
[Epoch 6, Batch 600] loss: 0.5370208382606506
[Epoch 6, Batch 700] loss: 0.5262075901031494
**STATS for Epoch 6** : 
Average training loss: 0.0352
Average validation loss: 0.5143
Validation Accuracy: 0.8510
Overfitting: 0.4791
[Epoch 7, Batch 100] loss: 0.4767444941401482
[Epoch 7, Batch 200] loss: 0.4779358893632889
[Epoch 7, Batch 300] loss: 0.48515009552240373
[Epoch 7, Batch 400] loss: 0.4596728441119194
[Epoch 7, Batch 500] loss: 0.4412525998055935
[Epoch 7, Batch 600] loss: 0.44033505976200105
[Epoch 7, Batch 700] loss: 0.4367694121599197
**STATS for Epoch 7** : 
Average training loss: 0.0274
Average validation loss: 0.4307
Validation Accuracy: 0.8752
Overfitting: 0.4033
[Epoch 8, Batch 100] loss: 0.42106536135077477
[Epoch 8, Batch 200] loss: 0.399370187073946
[Epoch 8, Batch 300] loss: 0.4065983846783638
[Epoch 8, Batch 400] loss: 0.39433536887168885
[Epoch 8, Batch 500] loss: 0.3777665659785271
[Epoch 8, Batch 600] loss: 0.37070286467671393
[Epoch 8, Batch 700] loss: 0.3778783844411373
**STATS for Epoch 8** : 
Average training loss: 0.0254
Average validation loss: 0.3800
Validation Accuracy: 0.8856
Overfitting: 0.3547
[Epoch 9, Batch 100] loss: 0.36051957190036776
[Epoch 9, Batch 200] loss: 0.37085734471678733
[Epoch 9, Batch 300] loss: 0.35508502572774886
[Epoch 9, Batch 400] loss: 0.34812174245715144
[Epoch 9, Batch 500] loss: 0.3482943787425756
[Epoch 9, Batch 600] loss: 0.3287536524236202
[Epoch 9, Batch 700] loss: 0.34332723274827004
**STATS for Epoch 9** : 
Average training loss: 0.0219
Average validation loss: 0.3405
Validation Accuracy: 0.8996
Overfitting: 0.3185
Best model saved at epoch 9 with validation loss: 0.3405
[Epoch 10, Batch 100] loss: 0.33246933802962303
[Epoch 10, Batch 200] loss: 0.31988927230238917
[Epoch 10, Batch 300] loss: 0.31853300511837007
[Epoch 10, Batch 400] loss: 0.31496806055307386
[Epoch 10, Batch 500] loss: 0.29345436275005343
[Epoch 10, Batch 600] loss: 0.30945277616381645
[Epoch 10, Batch 700] loss: 0.31856348007917407
**STATS for Epoch 10** : 
Average training loss: 0.0219
Average validation loss: 0.3089
Validation Accuracy: 0.9103
Overfitting: 0.2871
Best model saved at epoch 10 with validation loss: 0.3089
[Epoch 11, Batch 100] loss: 0.2978428490459919
[Epoch 11, Batch 200] loss: 0.3037899078428745
[Epoch 11, Batch 300] loss: 0.29270411394536494
[Epoch 11, Batch 400] loss: 0.2716277404129505
[Epoch 11, Batch 500] loss: 0.2900954008102417
[Epoch 11, Batch 600] loss: 0.28608126178383825
[Epoch 11, Batch 700] loss: 0.278692484498024
**STATS for Epoch 11** : 
Average training loss: 0.0193
Average validation loss: 0.2860
Validation Accuracy: 0.9154
Overfitting: 0.2666
[Epoch 12, Batch 100] loss: 0.28312422581017016
[Epoch 12, Batch 200] loss: 0.26877162903547286
[Epoch 12, Batch 300] loss: 0.2639321696013212
[Epoch 12, Batch 400] loss: 0.2700017881393433
[Epoch 12, Batch 500] loss: 0.276284843608737
[Epoch 12, Batch 600] loss: 0.2468019775301218
[Epoch 12, Batch 700] loss: 0.25665979377925396
**STATS for Epoch 12** : 
Average training loss: 0.0177
Average validation loss: 0.2649
Validation Accuracy: 0.9204
Overfitting: 0.2473
Best model saved at epoch 12 with validation loss: 0.2649
[Epoch 13, Batch 100] loss: 0.24471415795385837
[Epoch 13, Batch 200] loss: 0.24510337866842746
[Epoch 13, Batch 300] loss: 0.24998449154198168
[Epoch 13, Batch 400] loss: 0.24192100271582603
[Epoch 13, Batch 500] loss: 0.2534788466244936
[Epoch 13, Batch 600] loss: 0.24232462637126445
[Epoch 13, Batch 700] loss: 0.24913261085748672
**STATS for Epoch 13** : 
Average training loss: 0.0161
Average validation loss: 0.2414
Validation Accuracy: 0.9288
Overfitting: 0.2253
[Epoch 14, Batch 100] loss: 0.22008720643818377
[Epoch 14, Batch 200] loss: 0.2504080453515053
[Epoch 14, Batch 300] loss: 0.24825812794268132
[Epoch 14, Batch 400] loss: 0.2284979124367237
[Epoch 14, Batch 500] loss: 0.21983423747122288
[Epoch 14, Batch 600] loss: 0.21489195041358472
[Epoch 14, Batch 700] loss: 0.22308646582067013
**STATS for Epoch 14** : 
Average training loss: 0.0150
Average validation loss: 0.2269
Validation Accuracy: 0.9336
Overfitting: 0.2118
Best model saved at epoch 14 with validation loss: 0.2269
[Epoch 15, Batch 100] loss: 0.21859454929828645
[Epoch 15, Batch 200] loss: 0.217505853921175
[Epoch 15, Batch 300] loss: 0.2096033874899149
[Epoch 15, Batch 400] loss: 0.22321134716272353
[Epoch 15, Batch 500] loss: 0.2280948603153229
[Epoch 15, Batch 600] loss: 0.20258173011243344
[Epoch 15, Batch 700] loss: 0.207171825543046
**STATS for Epoch 15** : 
Average training loss: 0.0130
Average validation loss: 0.2129
Validation Accuracy: 0.9380
Overfitting: 0.2000
[Epoch 16, Batch 100] loss: 0.20103948406875133
[Epoch 16, Batch 200] loss: 0.20195499904453754
[Epoch 16, Batch 300] loss: 0.21739244740456343
[Epoch 16, Batch 400] loss: 0.17966636650264264
[Epoch 16, Batch 500] loss: 0.20422024525701998
[Epoch 16, Batch 600] loss: 0.19810537677258253
[Epoch 16, Batch 700] loss: 0.20161203257739543
**STATS for Epoch 16** : 
Average training loss: 0.0134
Average validation loss: 0.2039
Validation Accuracy: 0.9423
Overfitting: 0.1904
Early stopping epoch 16 for trial 20. Moving to next fold.
Fold 5 validation loss: 0.2039
Mean validation loss across all folds for Trial 20 is 0.2103 with trial config:  l1: 128, l2: 128, lr: 0.0001, batch_size: 64
[I 2024-12-10 07:19:04,426] Trial 19 finished with value: 0.21026277628112983 and parameters: {'l1': 128, 'l2': 128, 'lr': 0.0001, 'batch_size': 64}. Best is trial 12 with value: 0.0492618556785242.

Selected Hyperparameters for Trial 21:
  l1: 256, l2: 128, lr: 0.001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2981179118156434
[Epoch 1, Batch 200] loss: 2.275881962776184
[Epoch 1, Batch 300] loss: 2.209105408191681
[Epoch 1, Batch 400] loss: 1.7537302881479264
[Epoch 1, Batch 500] loss: 0.7689455342292786
[Epoch 1, Batch 600] loss: 0.5365917414426804
[Epoch 1, Batch 700] loss: 0.43234190076589585
[Epoch 1, Batch 800] loss: 0.4137418457865715
[Epoch 1, Batch 900] loss: 0.3536336393654346
[Epoch 1, Batch 1000] loss: 0.3132832115888596
[Epoch 1, Batch 1100] loss: 0.3013455228507519
[Epoch 1, Batch 1200] loss: 0.24581906601786613
[Epoch 1, Batch 1300] loss: 0.24841309040784837
[Epoch 1, Batch 1400] loss: 0.22341566622257233
[Epoch 1, Batch 1500] loss: 0.23065995898097755
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1990
Validation Accuracy: 0.9393
Overfitting: 0.1990
[Epoch 2, Batch 100] loss: 0.2082714181393385
[Epoch 2, Batch 200] loss: 0.1729801771044731
[Epoch 2, Batch 300] loss: 0.17602458655834197
[Epoch 2, Batch 400] loss: 0.19027970395982266
[Epoch 2, Batch 500] loss: 0.16453916070982813
[Epoch 2, Batch 600] loss: 0.1351158650498837
[Epoch 2, Batch 700] loss: 0.13843284776434303
[Epoch 2, Batch 800] loss: 0.14565593605861069
[Epoch 2, Batch 900] loss: 0.14647542392835022
[Epoch 2, Batch 1000] loss: 0.1282204533740878
[Epoch 2, Batch 1100] loss: 0.1426355210132897
[Epoch 2, Batch 1200] loss: 0.15329257322475315
[Epoch 2, Batch 1300] loss: 0.12645992496982217
[Epoch 2, Batch 1400] loss: 0.11636089748702944
[Epoch 2, Batch 1500] loss: 0.12908413966186344
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1047
Validation Accuracy: 0.9659
Overfitting: 0.1047
[Epoch 3, Batch 100] loss: 0.09807870631106198
[Epoch 3, Batch 200] loss: 0.11067310666665435
[Epoch 3, Batch 300] loss: 0.09477703228127211
[Epoch 3, Batch 400] loss: 0.1085065484046936
[Epoch 3, Batch 500] loss: 0.10244619260542094
[Epoch 3, Batch 600] loss: 0.11842346604913473
[Epoch 3, Batch 700] loss: 0.10787021989002823
[Epoch 3, Batch 800] loss: 0.08611479912884533
[Epoch 3, Batch 900] loss: 0.1025929758604616
[Epoch 3, Batch 1000] loss: 0.10754172695335001
[Epoch 3, Batch 1100] loss: 0.09665211764164269
[Epoch 3, Batch 1200] loss: 0.08891038923058658
[Epoch 3, Batch 1300] loss: 0.0970996347349137
[Epoch 3, Batch 1400] loss: 0.08532233277801424
[Epoch 3, Batch 1500] loss: 0.08014539423398674
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0840
Validation Accuracy: 0.9748
Overfitting: 0.0840
[Epoch 4, Batch 100] loss: 0.08346650207880885
[Epoch 4, Batch 200] loss: 0.07187487953808158
[Epoch 4, Batch 300] loss: 0.08567790384404361
[Epoch 4, Batch 400] loss: 0.09263916244730354
[Epoch 4, Batch 500] loss: 0.06244377688039094
[Epoch 4, Batch 600] loss: 0.07992986552417278
[Epoch 4, Batch 700] loss: 0.09440375872422009
[Epoch 4, Batch 800] loss: 0.07843427959247493
[Epoch 4, Batch 900] loss: 0.07919641457963734
[Epoch 4, Batch 1000] loss: 0.07366397743579
[Epoch 4, Batch 1100] loss: 0.07926244266214781
[Epoch 4, Batch 1200] loss: 0.07819750402122735
[Epoch 4, Batch 1300] loss: 0.07262904649833217
[Epoch 4, Batch 1400] loss: 0.06414989366196096
[Epoch 4, Batch 1500] loss: 0.07831062738900073
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0657
Validation Accuracy: 0.9790
Overfitting: 0.0657
[Epoch 5, Batch 100] loss: 0.054087289017625155
[Epoch 5, Batch 200] loss: 0.06104927041102201
[Epoch 5, Batch 300] loss: 0.056981231165118516
[Epoch 5, Batch 400] loss: 0.06408615201245993
[Epoch 5, Batch 500] loss: 0.06819485466461629
[Epoch 5, Batch 600] loss: 0.05821446948219091
[Epoch 5, Batch 700] loss: 0.056552758540492507
[Epoch 5, Batch 800] loss: 0.05406903058406897
[Epoch 5, Batch 900] loss: 0.07211788923945278
[Epoch 5, Batch 1000] loss: 0.06373284431407228
[Epoch 5, Batch 1100] loss: 0.06253234387142584
[Epoch 5, Batch 1200] loss: 0.05830885648611002
[Epoch 5, Batch 1300] loss: 0.07193642315105535
[Epoch 5, Batch 1400] loss: 0.06040119552752003
[Epoch 5, Batch 1500] loss: 0.06514994922326878
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0682
Validation Accuracy: 0.9789
Overfitting: 0.0682
[Epoch 6, Batch 100] loss: 0.07553509118268266
[Epoch 6, Batch 200] loss: 0.06041831471142359
[Epoch 6, Batch 300] loss: 0.051626985546899956
[Epoch 6, Batch 400] loss: 0.051274029238848016
[Epoch 6, Batch 500] loss: 0.047977374936454
[Epoch 6, Batch 600] loss: 0.04542252964805812
[Epoch 6, Batch 700] loss: 0.04447008933580946
[Epoch 6, Batch 800] loss: 0.05394499370479025
[Epoch 6, Batch 900] loss: 0.055742705288575965
[Epoch 6, Batch 1000] loss: 0.06382798359612935
[Epoch 6, Batch 1100] loss: 0.05709442194318399
[Epoch 6, Batch 1200] loss: 0.045674711137544365
[Epoch 6, Batch 1300] loss: 0.04655662185396068
[Epoch 6, Batch 1400] loss: 0.05068576756399125
[Epoch 6, Batch 1500] loss: 0.05575440448708832
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9802
Overfitting: 0.0606
[Epoch 7, Batch 100] loss: 0.04389524662517943
[Epoch 7, Batch 200] loss: 0.03775452133035287
[Epoch 7, Batch 300] loss: 0.0556246186979115
[Epoch 7, Batch 400] loss: 0.04596070208586753
[Epoch 7, Batch 500] loss: 0.04840060559217818
[Epoch 7, Batch 600] loss: 0.0422332552226726
[Epoch 7, Batch 700] loss: 0.05754103716462851
[Epoch 7, Batch 800] loss: 0.05298598545836285
[Epoch 7, Batch 900] loss: 0.0422196908807382
[Epoch 7, Batch 1000] loss: 0.04428515296429396
[Epoch 7, Batch 1100] loss: 0.048390878417994825
[Epoch 7, Batch 1200] loss: 0.03970697348471731
[Epoch 7, Batch 1300] loss: 0.053260092583659574
[Epoch 7, Batch 1400] loss: 0.040979042194667276
[Epoch 7, Batch 1500] loss: 0.049046574928797784
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0570
Validation Accuracy: 0.9817
Overfitting: 0.0570
[Epoch 8, Batch 100] loss: 0.03620255270361668
[Epoch 8, Batch 200] loss: 0.045538391054142265
[Epoch 8, Batch 300] loss: 0.03596383830416016
[Epoch 8, Batch 400] loss: 0.04812385750527028
[Epoch 8, Batch 500] loss: 0.04537981800327543
[Epoch 8, Batch 600] loss: 0.04837234086007811
[Epoch 8, Batch 700] loss: 0.043899245981592686
[Epoch 8, Batch 800] loss: 0.04174970968277194
[Epoch 8, Batch 900] loss: 0.04586683600209653
[Epoch 8, Batch 1000] loss: 0.03397970696212724
[Epoch 8, Batch 1100] loss: 0.03486791833885945
[Epoch 8, Batch 1200] loss: 0.04227035336662084
[Epoch 8, Batch 1300] loss: 0.03802568224840797
[Epoch 8, Batch 1400] loss: 0.03487286190851591
[Epoch 8, Batch 1500] loss: 0.035942930647870526
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9848
Overfitting: 0.0485
[Epoch 9, Batch 100] loss: 0.027180446248676163
[Epoch 9, Batch 200] loss: 0.03535461224382743
[Epoch 9, Batch 300] loss: 0.03287997373729013
[Epoch 9, Batch 400] loss: 0.02862783627177123
[Epoch 9, Batch 500] loss: 0.03624018037342466
[Epoch 9, Batch 600] loss: 0.02920230525720399
[Epoch 9, Batch 700] loss: 0.04866428223438561
[Epoch 9, Batch 800] loss: 0.0337219687004108
[Epoch 9, Batch 900] loss: 0.04178205956937745
[Epoch 9, Batch 1000] loss: 0.03756261994596571
[Epoch 9, Batch 1100] loss: 0.031032308585708962
[Epoch 9, Batch 1200] loss: 0.03875798712135293
[Epoch 9, Batch 1300] loss: 0.04099118673068006
[Epoch 9, Batch 1400] loss: 0.03946872200001963
[Epoch 9, Batch 1500] loss: 0.029569680547574535
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0446
Validation Accuracy: 0.9866
Overfitting: 0.0446
Best model saved at epoch 9 with validation loss: 0.0446
[Epoch 10, Batch 100] loss: 0.026904213582165538
[Epoch 10, Batch 200] loss: 0.03143899557864643
[Epoch 10, Batch 300] loss: 0.023099351415003185
[Epoch 10, Batch 400] loss: 0.029585018401558045
[Epoch 10, Batch 500] loss: 0.027671957629499956
[Epoch 10, Batch 600] loss: 0.035902066134731285
[Epoch 10, Batch 700] loss: 0.03383555224456359
[Epoch 10, Batch 800] loss: 0.03589012728363741
[Epoch 10, Batch 900] loss: 0.032698850802698874
[Epoch 10, Batch 1000] loss: 0.03527235098881647
[Epoch 10, Batch 1100] loss: 0.0328639024856966
[Epoch 10, Batch 1200] loss: 0.03002752738422714
[Epoch 10, Batch 1300] loss: 0.04001043338968884
[Epoch 10, Batch 1400] loss: 0.03263345475366805
[Epoch 10, Batch 1500] loss: 0.03475007618719246
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0466
Validation Accuracy: 0.9851
Overfitting: 0.0466
[Epoch 11, Batch 100] loss: 0.026211053230508697
[Epoch 11, Batch 200] loss: 0.03044909218966495
[Epoch 11, Batch 300] loss: 0.030653597553027795
[Epoch 11, Batch 400] loss: 0.026042632670869353
[Epoch 11, Batch 500] loss: 0.026391347978496925
[Epoch 11, Batch 600] loss: 0.023232546357321554
[Epoch 11, Batch 700] loss: 0.03622920841880841
[Epoch 11, Batch 800] loss: 0.028316058790369424
[Epoch 11, Batch 900] loss: 0.030655656736053062
[Epoch 11, Batch 1000] loss: 0.039716741055599414
[Epoch 11, Batch 1100] loss: 0.022861322309472597
[Epoch 11, Batch 1200] loss: 0.022128557233372703
[Epoch 11, Batch 1300] loss: 0.02824547977303155
[Epoch 11, Batch 1400] loss: 0.02366955889359815
[Epoch 11, Batch 1500] loss: 0.028300543170480523
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0474
Validation Accuracy: 0.9852
Overfitting: 0.0474
Early stopping epoch 11 for trial 21. Moving to next fold.
Fold 1 validation loss: 0.0474
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2965086483955384
[Epoch 1, Batch 200] loss: 2.269959990978241
[Epoch 1, Batch 300] loss: 2.192040650844574
[Epoch 1, Batch 400] loss: 1.7269959616661072
[Epoch 1, Batch 500] loss: 0.7897830033302307
[Epoch 1, Batch 600] loss: 0.5235075260698795
[Epoch 1, Batch 700] loss: 0.4304964865744114
[Epoch 1, Batch 800] loss: 0.3645397911220789
[Epoch 1, Batch 900] loss: 0.3113086589425802
[Epoch 1, Batch 1000] loss: 0.3069272342324257
[Epoch 1, Batch 1100] loss: 0.24648625299334526
[Epoch 1, Batch 1200] loss: 0.24673489056527614
[Epoch 1, Batch 1300] loss: 0.21879603821784258
[Epoch 1, Batch 1400] loss: 0.170928645581007
[Epoch 1, Batch 1500] loss: 0.16444240391254425
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2168
Validation Accuracy: 0.9360
Overfitting: 0.2168
[Epoch 2, Batch 100] loss: 0.16778433175757526
[Epoch 2, Batch 200] loss: 0.16691483275964855
[Epoch 2, Batch 300] loss: 0.1729015346430242
[Epoch 2, Batch 400] loss: 0.1486396288126707
[Epoch 2, Batch 500] loss: 0.15516222483478487
[Epoch 2, Batch 600] loss: 0.14151353865861893
[Epoch 2, Batch 700] loss: 0.15733076518401504
[Epoch 2, Batch 800] loss: 0.1401108463294804
[Epoch 2, Batch 900] loss: 0.1237599452957511
[Epoch 2, Batch 1000] loss: 0.12416664572432637
[Epoch 2, Batch 1100] loss: 0.1256000951025635
[Epoch 2, Batch 1200] loss: 0.13281270402483641
[Epoch 2, Batch 1300] loss: 0.1156708981283009
[Epoch 2, Batch 1400] loss: 0.10890197370201349
[Epoch 2, Batch 1500] loss: 0.1154375962819904
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1315
Validation Accuracy: 0.9592
Overfitting: 0.1315
[Epoch 3, Batch 100] loss: 0.11801438563968986
[Epoch 3, Batch 200] loss: 0.10013723684474826
[Epoch 3, Batch 300] loss: 0.10767734199762344
[Epoch 3, Batch 400] loss: 0.10018820034340024
[Epoch 3, Batch 500] loss: 0.10031947920564561
[Epoch 3, Batch 600] loss: 0.08440313938539475
[Epoch 3, Batch 700] loss: 0.10434540680143982
[Epoch 3, Batch 800] loss: 0.08120445589534939
[Epoch 3, Batch 900] loss: 0.09631081026047468
[Epoch 3, Batch 1000] loss: 0.0990187930688262
[Epoch 3, Batch 1100] loss: 0.09538067550864071
[Epoch 3, Batch 1200] loss: 0.0812020574323833
[Epoch 3, Batch 1300] loss: 0.06742113844957202
[Epoch 3, Batch 1400] loss: 0.07447589383693412
[Epoch 3, Batch 1500] loss: 0.08707600392401219
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0969
Validation Accuracy: 0.9708
Overfitting: 0.0969
[Epoch 4, Batch 100] loss: 0.07572155498433858
[Epoch 4, Batch 200] loss: 0.07967020421521738
[Epoch 4, Batch 300] loss: 0.0869862411962822
[Epoch 4, Batch 400] loss: 0.08233091617934406
[Epoch 4, Batch 500] loss: 0.06256047184579075
[Epoch 4, Batch 600] loss: 0.07379965202650056
[Epoch 4, Batch 700] loss: 0.07809490553336218
[Epoch 4, Batch 800] loss: 0.08139814549358562
[Epoch 4, Batch 900] loss: 0.059457240044139326
[Epoch 4, Batch 1000] loss: 0.08196457240497694
[Epoch 4, Batch 1100] loss: 0.06951129842549562
[Epoch 4, Batch 1200] loss: 0.07720641534309834
[Epoch 4, Batch 1300] loss: 0.07755787204019725
[Epoch 4, Batch 1400] loss: 0.06513200124492868
[Epoch 4, Batch 1500] loss: 0.06998730577528477
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0809
Validation Accuracy: 0.9747
Overfitting: 0.0809
[Epoch 5, Batch 100] loss: 0.06018306167447008
[Epoch 5, Batch 200] loss: 0.058989543812349436
[Epoch 5, Batch 300] loss: 0.060754300803528165
[Epoch 5, Batch 400] loss: 0.07162830863147975
[Epoch 5, Batch 500] loss: 0.07221057689283043
[Epoch 5, Batch 600] loss: 0.060899980894755575
[Epoch 5, Batch 700] loss: 0.0534170584497042
[Epoch 5, Batch 800] loss: 0.06401626222184859
[Epoch 5, Batch 900] loss: 0.05876253860304132
[Epoch 5, Batch 1000] loss: 0.05591371430084109
[Epoch 5, Batch 1100] loss: 0.06314173355465755
[Epoch 5, Batch 1200] loss: 0.0631487261550501
[Epoch 5, Batch 1300] loss: 0.06650145605904982
[Epoch 5, Batch 1400] loss: 0.05372265837737359
[Epoch 5, Batch 1500] loss: 0.05753708455595188
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0762
Validation Accuracy: 0.9761
Overfitting: 0.0762
[Epoch 6, Batch 100] loss: 0.05327880351804197
[Epoch 6, Batch 200] loss: 0.04928903526160866
[Epoch 6, Batch 300] loss: 0.05041507233283483
[Epoch 6, Batch 400] loss: 0.054884816820267586
[Epoch 6, Batch 500] loss: 0.054496430770959704
[Epoch 6, Batch 600] loss: 0.05316063246689737
[Epoch 6, Batch 700] loss: 0.05563997627934441
[Epoch 6, Batch 800] loss: 0.06067883884301409
[Epoch 6, Batch 900] loss: 0.050408260398544374
[Epoch 6, Batch 1000] loss: 0.053010229617357255
[Epoch 6, Batch 1100] loss: 0.04973075099173002
[Epoch 6, Batch 1200] loss: 0.06544486010679976
[Epoch 6, Batch 1300] loss: 0.04231255103717558
[Epoch 6, Batch 1400] loss: 0.0611079019587487
[Epoch 6, Batch 1500] loss: 0.03873744349693879
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0713
Validation Accuracy: 0.9787
Overfitting: 0.0713
[Epoch 7, Batch 100] loss: 0.039372488528024406
[Epoch 7, Batch 200] loss: 0.04048025177791715
[Epoch 7, Batch 300] loss: 0.05169916829210706
[Epoch 7, Batch 400] loss: 0.044566946588456634
[Epoch 7, Batch 500] loss: 0.04257090500439517
[Epoch 7, Batch 600] loss: 0.0462042579613626
[Epoch 7, Batch 700] loss: 0.05047851166920737
[Epoch 7, Batch 800] loss: 0.03677750519302208
[Epoch 7, Batch 900] loss: 0.05201971256406978
[Epoch 7, Batch 1000] loss: 0.05148803416581359
[Epoch 7, Batch 1100] loss: 0.05167207942577079
[Epoch 7, Batch 1200] loss: 0.05016798469703645
[Epoch 7, Batch 1300] loss: 0.04840604842640459
[Epoch 7, Batch 1400] loss: 0.051987608559429646
[Epoch 7, Batch 1500] loss: 0.04469587968313135
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0621
Validation Accuracy: 0.9802
Overfitting: 0.0621
[Epoch 8, Batch 100] loss: 0.03835572722833604
[Epoch 8, Batch 200] loss: 0.04069483536703047
[Epoch 8, Batch 300] loss: 0.03477864273183513
[Epoch 8, Batch 400] loss: 0.04351432044873946
[Epoch 8, Batch 500] loss: 0.034755548842367714
[Epoch 8, Batch 600] loss: 0.032804820799501616
[Epoch 8, Batch 700] loss: 0.030961054368526676
[Epoch 8, Batch 800] loss: 0.040202585149672815
[Epoch 8, Batch 900] loss: 0.049261695311870426
[Epoch 8, Batch 1000] loss: 0.050174512867815796
[Epoch 8, Batch 1100] loss: 0.04882007896900177
[Epoch 8, Batch 1200] loss: 0.05349991908064112
[Epoch 8, Batch 1300] loss: 0.04544593291706406
[Epoch 8, Batch 1400] loss: 0.04902726960834116
[Epoch 8, Batch 1500] loss: 0.038745578506495806
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9813
Overfitting: 0.0603
[Epoch 9, Batch 100] loss: 0.03278146079741418
[Epoch 9, Batch 200] loss: 0.035318108891951853
[Epoch 9, Batch 300] loss: 0.031474288378376514
[Epoch 9, Batch 400] loss: 0.03180955567688216
[Epoch 9, Batch 500] loss: 0.03652217146242037
[Epoch 9, Batch 600] loss: 0.035120837415161074
[Epoch 9, Batch 700] loss: 0.029309974698117004
[Epoch 9, Batch 800] loss: 0.036920760507346134
[Epoch 9, Batch 900] loss: 0.041625788066303356
[Epoch 9, Batch 1000] loss: 0.04655744793184567
[Epoch 9, Batch 1100] loss: 0.03773893338860944
[Epoch 9, Batch 1200] loss: 0.03415522345050704
[Epoch 9, Batch 1300] loss: 0.03977682358614402
[Epoch 9, Batch 1400] loss: 0.039365796273923476
[Epoch 9, Batch 1500] loss: 0.04235128600237658
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9832
Overfitting: 0.0536
Best model saved at epoch 9 with validation loss: 0.0536
[Epoch 10, Batch 100] loss: 0.030588403404108247
[Epoch 10, Batch 200] loss: 0.0377173886745004
[Epoch 10, Batch 300] loss: 0.024092972437501886
[Epoch 10, Batch 400] loss: 0.0289653693017317
[Epoch 10, Batch 500] loss: 0.03687879201082978
[Epoch 10, Batch 600] loss: 0.03545091504463926
[Epoch 10, Batch 700] loss: 0.03060345901933033
[Epoch 10, Batch 800] loss: 0.02726389206247404
[Epoch 10, Batch 900] loss: 0.025980849400511943
[Epoch 10, Batch 1000] loss: 0.03852548346389085
[Epoch 10, Batch 1100] loss: 0.03818193573039025
[Epoch 10, Batch 1200] loss: 0.029829354820976733
[Epoch 10, Batch 1300] loss: 0.036017218385240996
[Epoch 10, Batch 1400] loss: 0.0355703703162726
[Epoch 10, Batch 1500] loss: 0.04187641511874972
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0585
Validation Accuracy: 0.9818
Overfitting: 0.0585
[Epoch 11, Batch 100] loss: 0.03174831240787171
[Epoch 11, Batch 200] loss: 0.030758301098830997
[Epoch 11, Batch 300] loss: 0.03435432899132138
[Epoch 11, Batch 400] loss: 0.022140836936450796
[Epoch 11, Batch 500] loss: 0.030504290986573323
[Epoch 11, Batch 600] loss: 0.030330819298978896
[Epoch 11, Batch 700] loss: 0.032728949824231676
[Epoch 11, Batch 800] loss: 0.03351592389924917
[Epoch 11, Batch 900] loss: 0.019564620461314918
[Epoch 11, Batch 1000] loss: 0.036519862368295436
[Epoch 11, Batch 1100] loss: 0.027383211051055695
[Epoch 11, Batch 1200] loss: 0.03271695284347516
[Epoch 11, Batch 1300] loss: 0.025505947881611063
[Epoch 11, Batch 1400] loss: 0.022339049977017567
[Epoch 11, Batch 1500] loss: 0.035423487599764485
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9830
Overfitting: 0.0554
Early stopping epoch 11 for trial 21. Moving to next fold.
Fold 2 validation loss: 0.0554
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.3005602312088014
[Epoch 1, Batch 200] loss: 2.2871978282928467
[Epoch 1, Batch 300] loss: 2.2589095520973204
[Epoch 1, Batch 400] loss: 2.146306895017624
[Epoch 1, Batch 500] loss: 1.5000051325559616
[Epoch 1, Batch 600] loss: 0.7559097540378571
[Epoch 1, Batch 700] loss: 0.5513615924119949
[Epoch 1, Batch 800] loss: 0.4259672553837299
[Epoch 1, Batch 900] loss: 0.37481243938207626
[Epoch 1, Batch 1000] loss: 0.2925134520977736
[Epoch 1, Batch 1100] loss: 0.29880842581391337
[Epoch 1, Batch 1200] loss: 0.26532879075035454
[Epoch 1, Batch 1300] loss: 0.24184701643884182
[Epoch 1, Batch 1400] loss: 0.2324446665123105
[Epoch 1, Batch 1500] loss: 0.1849825066886842
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2274
Validation Accuracy: 0.9297
Overfitting: 0.2274
[Epoch 2, Batch 100] loss: 0.18990074206143617
[Epoch 2, Batch 200] loss: 0.15738438805565239
[Epoch 2, Batch 300] loss: 0.16247515053488315
[Epoch 2, Batch 400] loss: 0.17442791687324644
[Epoch 2, Batch 500] loss: 0.16146227717399597
[Epoch 2, Batch 600] loss: 0.17921948362141848
[Epoch 2, Batch 700] loss: 0.16573028987273575
[Epoch 2, Batch 800] loss: 0.148529331125319
[Epoch 2, Batch 900] loss: 0.13850586969405412
[Epoch 2, Batch 1000] loss: 0.12077862781472504
[Epoch 2, Batch 1100] loss: 0.12389331133104861
[Epoch 2, Batch 1200] loss: 0.11173161364160478
[Epoch 2, Batch 1300] loss: 0.15168297143653034
[Epoch 2, Batch 1400] loss: 0.0875505370926112
[Epoch 2, Batch 1500] loss: 0.10433833989780396
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1223
Validation Accuracy: 0.9638
Overfitting: 0.1223
[Epoch 3, Batch 100] loss: 0.12436026021838188
[Epoch 3, Batch 200] loss: 0.12100187286734582
[Epoch 3, Batch 300] loss: 0.09266592250205577
[Epoch 3, Batch 400] loss: 0.10214866460300982
[Epoch 3, Batch 500] loss: 0.10230528469197452
[Epoch 3, Batch 600] loss: 0.11209659769199788
[Epoch 3, Batch 700] loss: 0.08350786492694169
[Epoch 3, Batch 800] loss: 0.1011666656192392
[Epoch 3, Batch 900] loss: 0.09929515592288225
[Epoch 3, Batch 1000] loss: 0.09604236030485482
[Epoch 3, Batch 1100] loss: 0.08920659986557439
[Epoch 3, Batch 1200] loss: 0.08824482813477516
[Epoch 3, Batch 1300] loss: 0.09023783966433258
[Epoch 3, Batch 1400] loss: 0.07868073679506779
[Epoch 3, Batch 1500] loss: 0.08466120750876144
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1033
Validation Accuracy: 0.9693
Overfitting: 0.1033
[Epoch 4, Batch 100] loss: 0.08644431329332292
[Epoch 4, Batch 200] loss: 0.08470943553606049
[Epoch 4, Batch 300] loss: 0.08171604402828962
[Epoch 4, Batch 400] loss: 0.0805879588983953
[Epoch 4, Batch 500] loss: 0.09124967340845615
[Epoch 4, Batch 600] loss: 0.0645857250620611
[Epoch 4, Batch 700] loss: 0.09283013883512467
[Epoch 4, Batch 800] loss: 0.07532693609595299
[Epoch 4, Batch 900] loss: 0.07042741703800857
[Epoch 4, Batch 1000] loss: 0.05975171108497307
[Epoch 4, Batch 1100] loss: 0.08878232862218283
[Epoch 4, Batch 1200] loss: 0.06058040166739374
[Epoch 4, Batch 1300] loss: 0.08709751978050917
[Epoch 4, Batch 1400] loss: 0.062003371610771865
[Epoch 4, Batch 1500] loss: 0.06403547473950312
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0880
Validation Accuracy: 0.9727
Overfitting: 0.0880
[Epoch 5, Batch 100] loss: 0.0660186100937426
[Epoch 5, Batch 200] loss: 0.061914168605580924
[Epoch 5, Batch 300] loss: 0.058216453331988306
[Epoch 5, Batch 400] loss: 0.07269063756335527
[Epoch 5, Batch 500] loss: 0.06323293365421705
[Epoch 5, Batch 600] loss: 0.05974272251129151
[Epoch 5, Batch 700] loss: 0.06800311357015744
[Epoch 5, Batch 800] loss: 0.06613480790285393
[Epoch 5, Batch 900] loss: 0.06263071893248708
[Epoch 5, Batch 1000] loss: 0.0747538503492251
[Epoch 5, Batch 1100] loss: 0.07139785791747272
[Epoch 5, Batch 1200] loss: 0.05297761547146365
[Epoch 5, Batch 1300] loss: 0.059959517000243066
[Epoch 5, Batch 1400] loss: 0.0574877141835168
[Epoch 5, Batch 1500] loss: 0.07029196704737842
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0711
Validation Accuracy: 0.9777
Overfitting: 0.0711
[Epoch 6, Batch 100] loss: 0.05793994575040415
[Epoch 6, Batch 200] loss: 0.05215911272913218
[Epoch 6, Batch 300] loss: 0.050776409420650453
[Epoch 6, Batch 400] loss: 0.04018792820395902
[Epoch 6, Batch 500] loss: 0.05612561472924426
[Epoch 6, Batch 600] loss: 0.055340484195039605
[Epoch 6, Batch 700] loss: 0.04956779419328086
[Epoch 6, Batch 800] loss: 0.06261091048130765
[Epoch 6, Batch 900] loss: 0.0556219170591794
[Epoch 6, Batch 1000] loss: 0.06068255614256486
[Epoch 6, Batch 1100] loss: 0.04898815711494535
[Epoch 6, Batch 1200] loss: 0.06474204869940876
[Epoch 6, Batch 1300] loss: 0.05453089997638017
[Epoch 6, Batch 1400] loss: 0.059294146281899884
[Epoch 6, Batch 1500] loss: 0.050284144252655094
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0620
Validation Accuracy: 0.9809
Overfitting: 0.0620
[Epoch 7, Batch 100] loss: 0.03888505220646039
[Epoch 7, Batch 200] loss: 0.047233348502777515
[Epoch 7, Batch 300] loss: 0.05623006182489917
[Epoch 7, Batch 400] loss: 0.050338080705842
[Epoch 7, Batch 500] loss: 0.050565495744813234
[Epoch 7, Batch 600] loss: 0.0464852065598825
[Epoch 7, Batch 700] loss: 0.03343137295683846
[Epoch 7, Batch 800] loss: 0.044829441991169006
[Epoch 7, Batch 900] loss: 0.047891901737893934
[Epoch 7, Batch 1000] loss: 0.04788927515794057
[Epoch 7, Batch 1100] loss: 0.04299546048161574
[Epoch 7, Batch 1200] loss: 0.05833194200182334
[Epoch 7, Batch 1300] loss: 0.05016349846031517
[Epoch 7, Batch 1400] loss: 0.04877038932987489
[Epoch 7, Batch 1500] loss: 0.043472113555762915
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0741
Validation Accuracy: 0.9772
Overfitting: 0.0741
[Epoch 8, Batch 100] loss: 0.04801461493014358
[Epoch 8, Batch 200] loss: 0.04199064694461413
[Epoch 8, Batch 300] loss: 0.04380851813359186
[Epoch 8, Batch 400] loss: 0.03666049408842809
[Epoch 8, Batch 500] loss: 0.04248607575718779
[Epoch 8, Batch 600] loss: 0.041749498801655134
[Epoch 8, Batch 700] loss: 0.05142555512720719
[Epoch 8, Batch 800] loss: 0.041391243092948574
[Epoch 8, Batch 900] loss: 0.04766564660705626
[Epoch 8, Batch 1000] loss: 0.044056293593603184
[Epoch 8, Batch 1100] loss: 0.04186514254717622
[Epoch 8, Batch 1200] loss: 0.04243880279944278
[Epoch 8, Batch 1300] loss: 0.04029523772362154
[Epoch 8, Batch 1400] loss: 0.04178760459646583
[Epoch 8, Batch 1500] loss: 0.039268741022096945
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0552
Validation Accuracy: 0.9832
Overfitting: 0.0552
[Epoch 9, Batch 100] loss: 0.031763933378388176
[Epoch 9, Batch 200] loss: 0.041248656888492406
[Epoch 9, Batch 300] loss: 0.04204758215229958
[Epoch 9, Batch 400] loss: 0.03208234434365295
[Epoch 9, Batch 500] loss: 0.03198521026701201
[Epoch 9, Batch 600] loss: 0.04535221152138547
[Epoch 9, Batch 700] loss: 0.044834406768204646
[Epoch 9, Batch 800] loss: 0.043144793721439784
[Epoch 9, Batch 900] loss: 0.03532324615167454
[Epoch 9, Batch 1000] loss: 0.03519814639177639
[Epoch 9, Batch 1100] loss: 0.04719354311324423
[Epoch 9, Batch 1200] loss: 0.03719490719609894
[Epoch 9, Batch 1300] loss: 0.028933031914639286
[Epoch 9, Batch 1400] loss: 0.02728873881918844
[Epoch 9, Batch 1500] loss: 0.053976670071424454
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0572
Validation Accuracy: 0.9827
Overfitting: 0.0572
Best model saved at epoch 9 with validation loss: 0.0572
[Epoch 10, Batch 100] loss: 0.031821153326891366
[Epoch 10, Batch 200] loss: 0.026257449217373507
[Epoch 10, Batch 300] loss: 0.030456364284036683
[Epoch 10, Batch 400] loss: 0.03172195214050589
[Epoch 10, Batch 500] loss: 0.04324135501810815
[Epoch 10, Batch 600] loss: 0.03235966409338289
[Epoch 10, Batch 700] loss: 0.03350817477330566
[Epoch 10, Batch 800] loss: 0.03962598951009568
[Epoch 10, Batch 900] loss: 0.04245647433097474
[Epoch 10, Batch 1000] loss: 0.04642194428335642
[Epoch 10, Batch 1100] loss: 0.032587833108846095
[Epoch 10, Batch 1200] loss: 0.03134399556554854
[Epoch 10, Batch 1300] loss: 0.032903544363798574
[Epoch 10, Batch 1400] loss: 0.029736287675914356
[Epoch 10, Batch 1500] loss: 0.03537779355712701
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9841
Overfitting: 0.0514
[Epoch 11, Batch 100] loss: 0.029710170557373204
[Epoch 11, Batch 200] loss: 0.026806551149347796
[Epoch 11, Batch 300] loss: 0.03195168922015
[Epoch 11, Batch 400] loss: 0.02431983831920661
[Epoch 11, Batch 500] loss: 0.029636708251782693
[Epoch 11, Batch 600] loss: 0.03435440543922596
[Epoch 11, Batch 700] loss: 0.024024271999223856
[Epoch 11, Batch 800] loss: 0.03737109291832894
[Epoch 11, Batch 900] loss: 0.028505698377848603
[Epoch 11, Batch 1000] loss: 0.02701643707987387
[Epoch 11, Batch 1100] loss: 0.030868548257567453
[Epoch 11, Batch 1200] loss: 0.045519580068794314
[Epoch 11, Batch 1300] loss: 0.03512483435857575
[Epoch 11, Batch 1400] loss: 0.032410353976592886
[Epoch 11, Batch 1500] loss: 0.036089765067445115
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0538
Validation Accuracy: 0.9841
Overfitting: 0.0538
Early stopping epoch 11 for trial 21. Moving to next fold.
Fold 3 validation loss: 0.0538
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2953400182724
[Epoch 1, Batch 200] loss: 2.250869212150574
[Epoch 1, Batch 300] loss: 1.9837226462364197
[Epoch 1, Batch 400] loss: 0.9999207106232643
[Epoch 1, Batch 500] loss: 0.561557115316391
[Epoch 1, Batch 600] loss: 0.4405450515449047
[Epoch 1, Batch 700] loss: 0.3568936287611723
[Epoch 1, Batch 800] loss: 0.35619110431522133
[Epoch 1, Batch 900] loss: 0.3047328458726406
[Epoch 1, Batch 1000] loss: 0.28139702036976816
[Epoch 1, Batch 1100] loss: 0.2776458016037941
[Epoch 1, Batch 1200] loss: 0.24571631629019974
[Epoch 1, Batch 1300] loss: 0.2387126311287284
[Epoch 1, Batch 1400] loss: 0.21137145871296525
[Epoch 1, Batch 1500] loss: 0.20011583706364036
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1766
Validation Accuracy: 0.9463
Overfitting: 0.1766
[Epoch 2, Batch 100] loss: 0.20165262293070554
[Epoch 2, Batch 200] loss: 0.18491256721317767
[Epoch 2, Batch 300] loss: 0.14731154618784786
[Epoch 2, Batch 400] loss: 0.15901132473722102
[Epoch 2, Batch 500] loss: 0.17456515250727533
[Epoch 2, Batch 600] loss: 0.14944029008969664
[Epoch 2, Batch 700] loss: 0.1596329827234149
[Epoch 2, Batch 800] loss: 0.13843802213668824
[Epoch 2, Batch 900] loss: 0.1269118845835328
[Epoch 2, Batch 1000] loss: 0.1430293047428131
[Epoch 2, Batch 1100] loss: 0.12588419063016773
[Epoch 2, Batch 1200] loss: 0.11806832882575691
[Epoch 2, Batch 1300] loss: 0.10903599822428077
[Epoch 2, Batch 1400] loss: 0.13115536257624627
[Epoch 2, Batch 1500] loss: 0.11183008633553981
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1215
Validation Accuracy: 0.9613
Overfitting: 0.1215
[Epoch 3, Batch 100] loss: 0.11420244100503624
[Epoch 3, Batch 200] loss: 0.11081026064231991
[Epoch 3, Batch 300] loss: 0.07846904952079058
[Epoch 3, Batch 400] loss: 0.12150348049588501
[Epoch 3, Batch 500] loss: 0.08910205675289035
[Epoch 3, Batch 600] loss: 0.10916268943343312
[Epoch 3, Batch 700] loss: 0.11192340500187128
[Epoch 3, Batch 800] loss: 0.0945798572525382
[Epoch 3, Batch 900] loss: 0.10345548304263502
[Epoch 3, Batch 1000] loss: 0.10511509791947901
[Epoch 3, Batch 1100] loss: 0.09804297276772558
[Epoch 3, Batch 1200] loss: 0.09505158588290215
[Epoch 3, Batch 1300] loss: 0.08904977245256304
[Epoch 3, Batch 1400] loss: 0.08761612120317296
[Epoch 3, Batch 1500] loss: 0.0793827030947432
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0880
Validation Accuracy: 0.9724
Overfitting: 0.0880
[Epoch 4, Batch 100] loss: 0.08444911232683808
[Epoch 4, Batch 200] loss: 0.08611789578106255
[Epoch 4, Batch 300] loss: 0.07549631556961685
[Epoch 4, Batch 400] loss: 0.06428769315127283
[Epoch 4, Batch 500] loss: 0.06871340328129008
[Epoch 4, Batch 600] loss: 0.06496319985715672
[Epoch 4, Batch 700] loss: 0.08283244469668716
[Epoch 4, Batch 800] loss: 0.08346942036179826
[Epoch 4, Batch 900] loss: 0.07221787035698071
[Epoch 4, Batch 1000] loss: 0.07907005414366722
[Epoch 4, Batch 1100] loss: 0.08524870474357157
[Epoch 4, Batch 1200] loss: 0.0831519085355103
[Epoch 4, Batch 1300] loss: 0.0688433591008652
[Epoch 4, Batch 1400] loss: 0.0795444960729219
[Epoch 4, Batch 1500] loss: 0.08096701667178423
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0863
Validation Accuracy: 0.9739
Overfitting: 0.0863
[Epoch 5, Batch 100] loss: 0.07079212625976652
[Epoch 5, Batch 200] loss: 0.058628466208465395
[Epoch 5, Batch 300] loss: 0.061599570293910805
[Epoch 5, Batch 400] loss: 0.06268759654834867
[Epoch 5, Batch 500] loss: 0.06593896337086334
[Epoch 5, Batch 600] loss: 0.06565463814884424
[Epoch 5, Batch 700] loss: 0.06965510869631544
[Epoch 5, Batch 800] loss: 0.08026675336994231
[Epoch 5, Batch 900] loss: 0.059209199342876676
[Epoch 5, Batch 1000] loss: 0.08762909615878016
[Epoch 5, Batch 1100] loss: 0.06422489256830886
[Epoch 5, Batch 1200] loss: 0.06443983075558207
[Epoch 5, Batch 1300] loss: 0.05118322142167017
[Epoch 5, Batch 1400] loss: 0.055882778777740894
[Epoch 5, Batch 1500] loss: 0.05077441823028494
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0664
Validation Accuracy: 0.9792
Overfitting: 0.0664
[Epoch 6, Batch 100] loss: 0.05584277022862807
[Epoch 6, Batch 200] loss: 0.05235758718336001
[Epoch 6, Batch 300] loss: 0.06262310308637098
[Epoch 6, Batch 400] loss: 0.05598945267498493
[Epoch 6, Batch 500] loss: 0.04415488639380783
[Epoch 6, Batch 600] loss: 0.05164253537310287
[Epoch 6, Batch 700] loss: 0.05904379985993728
[Epoch 6, Batch 800] loss: 0.06320715448120609
[Epoch 6, Batch 900] loss: 0.07097551483660937
[Epoch 6, Batch 1000] loss: 0.05758540893206373
[Epoch 6, Batch 1100] loss: 0.04961431773728691
[Epoch 6, Batch 1200] loss: 0.04429258272517472
[Epoch 6, Batch 1300] loss: 0.053000555094331506
[Epoch 6, Batch 1400] loss: 0.049042571475729345
[Epoch 6, Batch 1500] loss: 0.06693364939652384
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0606
Validation Accuracy: 0.9812
Overfitting: 0.0606
[Epoch 7, Batch 100] loss: 0.0468711675517261
[Epoch 7, Batch 200] loss: 0.03489574932609685
[Epoch 7, Batch 300] loss: 0.04163689297507517
[Epoch 7, Batch 400] loss: 0.04870012995088473
[Epoch 7, Batch 500] loss: 0.05406485520885326
[Epoch 7, Batch 600] loss: 0.04414482111984398
[Epoch 7, Batch 700] loss: 0.049667122907121664
[Epoch 7, Batch 800] loss: 0.06012425311957486
[Epoch 7, Batch 900] loss: 0.05238316136528738
[Epoch 7, Batch 1000] loss: 0.04695790555444546
[Epoch 7, Batch 1100] loss: 0.04200962787610479
[Epoch 7, Batch 1200] loss: 0.05692841050913557
[Epoch 7, Batch 1300] loss: 0.057546263086842374
[Epoch 7, Batch 1400] loss: 0.04596412080107257
[Epoch 7, Batch 1500] loss: 0.05159529941040091
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0555
Validation Accuracy: 0.9832
Overfitting: 0.0555
[Epoch 8, Batch 100] loss: 0.038827273842762224
[Epoch 8, Batch 200] loss: 0.0394783606659621
[Epoch 8, Batch 300] loss: 0.043941756600979716
[Epoch 8, Batch 400] loss: 0.04424583985935897
[Epoch 8, Batch 500] loss: 0.04482933320803568
[Epoch 8, Batch 600] loss: 0.042611780185252426
[Epoch 8, Batch 700] loss: 0.04882216016296297
[Epoch 8, Batch 800] loss: 0.045018100417219105
[Epoch 8, Batch 900] loss: 0.04412507434899453
[Epoch 8, Batch 1000] loss: 0.03451675029587932
[Epoch 8, Batch 1100] loss: 0.042335421012248846
[Epoch 8, Batch 1200] loss: 0.043815365553600716
[Epoch 8, Batch 1300] loss: 0.03939842570456676
[Epoch 8, Batch 1400] loss: 0.04592383104027249
[Epoch 8, Batch 1500] loss: 0.033530229169409724
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0485
Validation Accuracy: 0.9859
Overfitting: 0.0485
[Epoch 9, Batch 100] loss: 0.024114842607523314
[Epoch 9, Batch 200] loss: 0.0404063205170678
[Epoch 9, Batch 300] loss: 0.043625639676465655
[Epoch 9, Batch 400] loss: 0.05070125933270901
[Epoch 9, Batch 500] loss: 0.04285046115517616
[Epoch 9, Batch 600] loss: 0.033608004529960454
[Epoch 9, Batch 700] loss: 0.026920969709171915
[Epoch 9, Batch 800] loss: 0.03516144338005688
[Epoch 9, Batch 900] loss: 0.043356391126289966
[Epoch 9, Batch 1000] loss: 0.04215392310929019
[Epoch 9, Batch 1100] loss: 0.03866704173036851
[Epoch 9, Batch 1200] loss: 0.02968882037588628
[Epoch 9, Batch 1300] loss: 0.039066944043443075
[Epoch 9, Batch 1400] loss: 0.033162460574822035
[Epoch 9, Batch 1500] loss: 0.047030099379480814
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0496
Validation Accuracy: 0.9846
Overfitting: 0.0496
Best model saved at epoch 9 with validation loss: 0.0496
[Epoch 10, Batch 100] loss: 0.03352365186088718
[Epoch 10, Batch 200] loss: 0.03436480061034672
[Epoch 10, Batch 300] loss: 0.028584312248567584
[Epoch 10, Batch 400] loss: 0.029495826984057203
[Epoch 10, Batch 500] loss: 0.03697251142933965
[Epoch 10, Batch 600] loss: 0.039246223493246364
[Epoch 10, Batch 700] loss: 0.037863913140608926
[Epoch 10, Batch 800] loss: 0.03476846232777461
[Epoch 10, Batch 900] loss: 0.03902938012091908
[Epoch 10, Batch 1000] loss: 0.02594945883494802
[Epoch 10, Batch 1100] loss: 0.03705741189827677
[Epoch 10, Batch 1200] loss: 0.03250187959289178
[Epoch 10, Batch 1300] loss: 0.04077403261791915
[Epoch 10, Batch 1400] loss: 0.03330348941322882
[Epoch 10, Batch 1500] loss: 0.03195947923726635
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0445
Validation Accuracy: 0.9867
Overfitting: 0.0445
[Epoch 11, Batch 100] loss: 0.026533610473852606
[Epoch 11, Batch 200] loss: 0.035016871350235304
[Epoch 11, Batch 300] loss: 0.034909916840260846
[Epoch 11, Batch 400] loss: 0.03326023017638363
[Epoch 11, Batch 500] loss: 0.02628581513199606
[Epoch 11, Batch 600] loss: 0.039083086018799805
[Epoch 11, Batch 700] loss: 0.03275563111295923
[Epoch 11, Batch 800] loss: 0.037565590222366156
[Epoch 11, Batch 900] loss: 0.03236684234812856
[Epoch 11, Batch 1000] loss: 0.031335457008099185
[Epoch 11, Batch 1100] loss: 0.030563096779806075
[Epoch 11, Batch 1200] loss: 0.02274327538703801
[Epoch 11, Batch 1300] loss: 0.029387591793201863
[Epoch 11, Batch 1400] loss: 0.021281149662972895
[Epoch 11, Batch 1500] loss: 0.03460057770076674
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9829
Overfitting: 0.0539
Early stopping epoch 11 for trial 21. Moving to next fold.
Fold 4 validation loss: 0.0539
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.294417576789856
[Epoch 1, Batch 200] loss: 2.2643683695793153
[Epoch 1, Batch 300] loss: 2.1651054072380065
[Epoch 1, Batch 400] loss: 1.5153029263019562
[Epoch 1, Batch 500] loss: 0.6383072409033775
[Epoch 1, Batch 600] loss: 0.47445175632834435
[Epoch 1, Batch 700] loss: 0.37113407388329506
[Epoch 1, Batch 800] loss: 0.3489637717604637
[Epoch 1, Batch 900] loss: 0.3365264164656401
[Epoch 1, Batch 1000] loss: 0.2813809932023287
[Epoch 1, Batch 1100] loss: 0.25739240013062953
[Epoch 1, Batch 1200] loss: 0.24751632452011108
[Epoch 1, Batch 1300] loss: 0.2421514909528196
[Epoch 1, Batch 1400] loss: 0.1928533586859703
[Epoch 1, Batch 1500] loss: 0.20824716087430717
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1999
Validation Accuracy: 0.9390
Overfitting: 0.1999
[Epoch 2, Batch 100] loss: 0.19979979448020457
[Epoch 2, Batch 200] loss: 0.16075567074120045
[Epoch 2, Batch 300] loss: 0.1678909368813038
[Epoch 2, Batch 400] loss: 0.17866951260715724
[Epoch 2, Batch 500] loss: 0.18574172855820506
[Epoch 2, Batch 600] loss: 0.17036039859056473
[Epoch 2, Batch 700] loss: 0.14179888792335987
[Epoch 2, Batch 800] loss: 0.14298569779843093
[Epoch 2, Batch 900] loss: 0.14341736122965812
[Epoch 2, Batch 1000] loss: 0.12092966933734715
[Epoch 2, Batch 1100] loss: 0.12257333074696362
[Epoch 2, Batch 1200] loss: 0.13379061978310347
[Epoch 2, Batch 1300] loss: 0.12814297529868782
[Epoch 2, Batch 1400] loss: 0.12230186456814408
[Epoch 2, Batch 1500] loss: 0.13185324182966723
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1220
Validation Accuracy: 0.9633
Overfitting: 0.1220
[Epoch 3, Batch 100] loss: 0.10784093035850674
[Epoch 3, Batch 200] loss: 0.1187837325874716
[Epoch 3, Batch 300] loss: 0.11350154088810087
[Epoch 3, Batch 400] loss: 0.10628466080408544
[Epoch 3, Batch 500] loss: 0.09063528932631015
[Epoch 3, Batch 600] loss: 0.10776236419565975
[Epoch 3, Batch 700] loss: 0.1024304320756346
[Epoch 3, Batch 800] loss: 0.1204375069681555
[Epoch 3, Batch 900] loss: 0.10809005196904764
[Epoch 3, Batch 1000] loss: 0.0844218860939145
[Epoch 3, Batch 1100] loss: 0.09829355124384165
[Epoch 3, Batch 1200] loss: 0.09376149792689831
[Epoch 3, Batch 1300] loss: 0.09454800863284618
[Epoch 3, Batch 1400] loss: 0.07726773066911846
[Epoch 3, Batch 1500] loss: 0.08269824732560664
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1083
Validation Accuracy: 0.9671
Overfitting: 0.1083
[Epoch 4, Batch 100] loss: 0.08452909596264363
[Epoch 4, Batch 200] loss: 0.08562031138688325
[Epoch 4, Batch 300] loss: 0.0753792276699096
[Epoch 4, Batch 400] loss: 0.07384831795934588
[Epoch 4, Batch 500] loss: 0.08245157330762595
[Epoch 4, Batch 600] loss: 0.07454925196245313
[Epoch 4, Batch 700] loss: 0.0841492335824296
[Epoch 4, Batch 800] loss: 0.08087720450013876
[Epoch 4, Batch 900] loss: 0.08459316958440467
[Epoch 4, Batch 1000] loss: 0.07659285706933588
[Epoch 4, Batch 1100] loss: 0.09025618847925215
[Epoch 4, Batch 1200] loss: 0.0649785943259485
[Epoch 4, Batch 1300] loss: 0.0655934329982847
[Epoch 4, Batch 1400] loss: 0.06671270655235276
[Epoch 4, Batch 1500] loss: 0.07178203995339573
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0844
Validation Accuracy: 0.9736
Overfitting: 0.0844
[Epoch 5, Batch 100] loss: 0.06824612032389268
[Epoch 5, Batch 200] loss: 0.06417791410349309
[Epoch 5, Batch 300] loss: 0.06435532371280715
[Epoch 5, Batch 400] loss: 0.05966101547237486
[Epoch 5, Batch 500] loss: 0.06644064866704866
[Epoch 5, Batch 600] loss: 0.06686070973519236
[Epoch 5, Batch 700] loss: 0.0779634132666979
[Epoch 5, Batch 800] loss: 0.05792189773288556
[Epoch 5, Batch 900] loss: 0.04769927541026846
[Epoch 5, Batch 1000] loss: 0.05391206093830988
[Epoch 5, Batch 1100] loss: 0.06315541319781914
[Epoch 5, Batch 1200] loss: 0.0723166906251572
[Epoch 5, Batch 1300] loss: 0.07354791560210287
[Epoch 5, Batch 1400] loss: 0.05463320962968282
[Epoch 5, Batch 1500] loss: 0.07283265742706135
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0605
Validation Accuracy: 0.9812
Overfitting: 0.0605
[Epoch 6, Batch 100] loss: 0.05912340684561059
[Epoch 6, Batch 200] loss: 0.05824258285108954
[Epoch 6, Batch 300] loss: 0.048062093219487
[Epoch 6, Batch 400] loss: 0.06816154643893242
[Epoch 6, Batch 500] loss: 0.05467289119027555
[Epoch 6, Batch 600] loss: 0.05589243045193143
[Epoch 6, Batch 700] loss: 0.05539957134053111
[Epoch 6, Batch 800] loss: 0.05196435143006965
[Epoch 6, Batch 900] loss: 0.04909260713553522
[Epoch 6, Batch 1000] loss: 0.0505778542230837
[Epoch 6, Batch 1100] loss: 0.04977209392469376
[Epoch 6, Batch 1200] loss: 0.052691033729352056
[Epoch 6, Batch 1300] loss: 0.051872190654976294
[Epoch 6, Batch 1400] loss: 0.0552712132409215
[Epoch 6, Batch 1500] loss: 0.06349447619286366
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0635
Validation Accuracy: 0.9801
Overfitting: 0.0635
[Epoch 7, Batch 100] loss: 0.04731613836134784
[Epoch 7, Batch 200] loss: 0.04264579335344024
[Epoch 7, Batch 300] loss: 0.04037673086277209
[Epoch 7, Batch 400] loss: 0.04545215479214676
[Epoch 7, Batch 500] loss: 0.061314704878022895
[Epoch 7, Batch 600] loss: 0.05643106986186467
[Epoch 7, Batch 700] loss: 0.04731178901507519
[Epoch 7, Batch 800] loss: 0.0500999772612704
[Epoch 7, Batch 900] loss: 0.05785552095505409
[Epoch 7, Batch 1000] loss: 0.04951865125156473
[Epoch 7, Batch 1100] loss: 0.03948517361306585
[Epoch 7, Batch 1200] loss: 0.036654719109646974
[Epoch 7, Batch 1300] loss: 0.042219719067798
[Epoch 7, Batch 1400] loss: 0.047965061856084505
[Epoch 7, Batch 1500] loss: 0.048330266418633985
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0521
Validation Accuracy: 0.9835
Overfitting: 0.0521
[Epoch 8, Batch 100] loss: 0.040783931206678975
[Epoch 8, Batch 200] loss: 0.04427531830733642
[Epoch 8, Batch 300] loss: 0.04177624606410973
[Epoch 8, Batch 400] loss: 0.04690712623472791
[Epoch 8, Batch 500] loss: 0.04229781550588086
[Epoch 8, Batch 600] loss: 0.04427841326338239
[Epoch 8, Batch 700] loss: 0.04289699518412817
[Epoch 8, Batch 800] loss: 0.03632582519610878
[Epoch 8, Batch 900] loss: 0.04118873701954726
[Epoch 8, Batch 1000] loss: 0.04563182638143189
[Epoch 8, Batch 1100] loss: 0.036587218166096135
[Epoch 8, Batch 1200] loss: 0.0521078611665871
[Epoch 8, Batch 1300] loss: 0.04262148836627602
[Epoch 8, Batch 1400] loss: 0.0296730353042949
[Epoch 8, Batch 1500] loss: 0.04832643985340837
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0603
Validation Accuracy: 0.9823
Overfitting: 0.0603
[Epoch 9, Batch 100] loss: 0.03391544201003853
[Epoch 9, Batch 200] loss: 0.0399667241203133
[Epoch 9, Batch 300] loss: 0.028955484409816563
[Epoch 9, Batch 400] loss: 0.03310247063753195
[Epoch 9, Batch 500] loss: 0.04390103222161997
[Epoch 9, Batch 600] loss: 0.030005437592044472
[Epoch 9, Batch 700] loss: 0.0423792321459041
[Epoch 9, Batch 800] loss: 0.031231237546307966
[Epoch 9, Batch 900] loss: 0.03974412606068654
[Epoch 9, Batch 1000] loss: 0.03721511155425105
[Epoch 9, Batch 1100] loss: 0.038439820744097235
[Epoch 9, Batch 1200] loss: 0.037883702312828976
[Epoch 9, Batch 1300] loss: 0.0370769320090767
[Epoch 9, Batch 1400] loss: 0.040219365021330306
[Epoch 9, Batch 1500] loss: 0.04484051149338484
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9832
Overfitting: 0.0539
Best model saved at epoch 9 with validation loss: 0.0539
[Epoch 10, Batch 100] loss: 0.027731292891548947
[Epoch 10, Batch 200] loss: 0.02504558511223877
[Epoch 10, Batch 300] loss: 0.03614234066742938
[Epoch 10, Batch 400] loss: 0.039976095955935306
[Epoch 10, Batch 500] loss: 0.029304466710309496
[Epoch 10, Batch 600] loss: 0.029387701176747213
[Epoch 10, Batch 700] loss: 0.0274593439612363
[Epoch 10, Batch 800] loss: 0.03259258043923183
[Epoch 10, Batch 900] loss: 0.03213693089666776
[Epoch 10, Batch 1000] loss: 0.04194461967505049
[Epoch 10, Batch 1100] loss: 0.03359779881080613
[Epoch 10, Batch 1200] loss: 0.03592011646454921
[Epoch 10, Batch 1300] loss: 0.033178413758869284
[Epoch 10, Batch 1400] loss: 0.030330392469768413
[Epoch 10, Batch 1500] loss: 0.036677333781844935
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0577
Validation Accuracy: 0.9821
Overfitting: 0.0577
[Epoch 11, Batch 100] loss: 0.030089787931065076
[Epoch 11, Batch 200] loss: 0.026848013354465364
[Epoch 11, Batch 300] loss: 0.023605618206493092
[Epoch 11, Batch 400] loss: 0.030541819793579634
[Epoch 11, Batch 500] loss: 0.028837868526461533
[Epoch 11, Batch 600] loss: 0.03501513448631158
[Epoch 11, Batch 700] loss: 0.027708565285429358
[Epoch 11, Batch 800] loss: 0.024477223102294374
[Epoch 11, Batch 900] loss: 0.027312585481849963
[Epoch 11, Batch 1000] loss: 0.04154721557337325
[Epoch 11, Batch 1100] loss: 0.034629168950777965
[Epoch 11, Batch 1200] loss: 0.021971834899741225
[Epoch 11, Batch 1300] loss: 0.0295979513268685
[Epoch 11, Batch 1400] loss: 0.04649761123029748
[Epoch 11, Batch 1500] loss: 0.02436669748974964
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0442
Validation Accuracy: 0.9852
Overfitting: 0.0442
Early stopping epoch 11 for trial 21. Moving to next fold.
Fold 5 validation loss: 0.0442
Mean validation loss across all folds for Trial 21 is 0.0509 with trial config:  l1: 256, l2: 128, lr: 0.001, batch_size: 32
[I 2024-12-10 07:30:14,793] Trial 20 finished with value: 0.05092231572512538 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 32}. Best is trial 12 with value: 0.0492618556785242.

Selected Hyperparameters for Trial 22:
  l1: 256, l2: 128, lr: 0.001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.286047043800354
[Epoch 1, Batch 200] loss: 2.22463139295578
[Epoch 1, Batch 300] loss: 1.8516733860969543
[Epoch 1, Batch 400] loss: 0.8397823485732079
[Epoch 1, Batch 500] loss: 0.5528003522753715
[Epoch 1, Batch 600] loss: 0.4380670815706253
[Epoch 1, Batch 700] loss: 0.4211190650612116
[Epoch 1, Batch 800] loss: 0.3445764435082674
[Epoch 1, Batch 900] loss: 0.3416245196759701
[Epoch 1, Batch 1000] loss: 0.29152236342430116
[Epoch 1, Batch 1100] loss: 0.2637700318545103
[Epoch 1, Batch 1200] loss: 0.264189893566072
[Epoch 1, Batch 1300] loss: 0.2389703634381294
[Epoch 1, Batch 1400] loss: 0.23829798471182584
[Epoch 1, Batch 1500] loss: 0.22679711539298297
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1957
Validation Accuracy: 0.9372
Overfitting: 0.1957
[Epoch 2, Batch 100] loss: 0.17804111011326312
[Epoch 2, Batch 200] loss: 0.17529698561877013
[Epoch 2, Batch 300] loss: 0.1651169977709651
[Epoch 2, Batch 400] loss: 0.19264268064871432
[Epoch 2, Batch 500] loss: 0.14868190601468087
[Epoch 2, Batch 600] loss: 0.15809250371530653
[Epoch 2, Batch 700] loss: 0.16203788682818412
[Epoch 2, Batch 800] loss: 0.13482592221349476
[Epoch 2, Batch 900] loss: 0.14560942055657505
[Epoch 2, Batch 1000] loss: 0.12239896722137927
[Epoch 2, Batch 1100] loss: 0.11880822906270623
[Epoch 2, Batch 1200] loss: 0.1304484418965876
[Epoch 2, Batch 1300] loss: 0.12769425604492426
[Epoch 2, Batch 1400] loss: 0.13153999911621214
[Epoch 2, Batch 1500] loss: 0.1261626773327589
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1055
Validation Accuracy: 0.9673
Overfitting: 0.1055
[Epoch 3, Batch 100] loss: 0.10904323432594537
[Epoch 3, Batch 200] loss: 0.12125301773659886
[Epoch 3, Batch 300] loss: 0.12261238593608141
[Epoch 3, Batch 400] loss: 0.08693623253144324
[Epoch 3, Batch 500] loss: 0.09586930738762021
[Epoch 3, Batch 600] loss: 0.1115768461744301
[Epoch 3, Batch 700] loss: 0.11713727233931422
[Epoch 3, Batch 800] loss: 0.11483323419699445
[Epoch 3, Batch 900] loss: 0.09518839024007321
[Epoch 3, Batch 1000] loss: 0.09322089310735464
[Epoch 3, Batch 1100] loss: 0.08719286101870238
[Epoch 3, Batch 1200] loss: 0.08731882647611201
[Epoch 3, Batch 1300] loss: 0.0986491622775793
[Epoch 3, Batch 1400] loss: 0.0819525323715061
[Epoch 3, Batch 1500] loss: 0.08665975867770612
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0881
Validation Accuracy: 0.9715
Overfitting: 0.0881
[Epoch 4, Batch 100] loss: 0.07780315664131195
[Epoch 4, Batch 200] loss: 0.09175426355097444
[Epoch 4, Batch 300] loss: 0.08515438357833773
[Epoch 4, Batch 400] loss: 0.08210922688245774
[Epoch 4, Batch 500] loss: 0.07521882249275222
[Epoch 4, Batch 600] loss: 0.0803233302780427
[Epoch 4, Batch 700] loss: 0.0813893574057147
[Epoch 4, Batch 800] loss: 0.07769837278407067
[Epoch 4, Batch 900] loss: 0.07959823528770357
[Epoch 4, Batch 1000] loss: 0.08304401433328167
[Epoch 4, Batch 1100] loss: 0.07381192945642397
[Epoch 4, Batch 1200] loss: 0.08238055602647364
[Epoch 4, Batch 1300] loss: 0.05895393988583237
[Epoch 4, Batch 1400] loss: 0.07519991335691883
[Epoch 4, Batch 1500] loss: 0.07442236286238767
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0692
Validation Accuracy: 0.9782
Overfitting: 0.0692
[Epoch 5, Batch 100] loss: 0.06888093680143356
[Epoch 5, Batch 200] loss: 0.08824277627049014
[Epoch 5, Batch 300] loss: 0.08037418386898935
[Epoch 5, Batch 400] loss: 0.06720086096320302
[Epoch 5, Batch 500] loss: 0.06726256436435506
[Epoch 5, Batch 600] loss: 0.05936765066348016
[Epoch 5, Batch 700] loss: 0.05664442078676075
[Epoch 5, Batch 800] loss: 0.07719214977114461
[Epoch 5, Batch 900] loss: 0.06067167978500947
[Epoch 5, Batch 1000] loss: 0.050020645454060285
[Epoch 5, Batch 1100] loss: 0.05782582958228886
[Epoch 5, Batch 1200] loss: 0.06501454784767702
[Epoch 5, Batch 1300] loss: 0.06956895338953473
[Epoch 5, Batch 1400] loss: 0.050977290356531736
[Epoch 5, Batch 1500] loss: 0.05306820273865014
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0666
Validation Accuracy: 0.9785
Overfitting: 0.0666
[Epoch 6, Batch 100] loss: 0.04167420837446116
[Epoch 6, Batch 200] loss: 0.05416964132338762
[Epoch 6, Batch 300] loss: 0.04902316884370521
[Epoch 6, Batch 400] loss: 0.048781455343123524
[Epoch 6, Batch 500] loss: 0.06000531767844222
[Epoch 6, Batch 600] loss: 0.0505909701238852
[Epoch 6, Batch 700] loss: 0.050519483018433675
[Epoch 6, Batch 800] loss: 0.05866420660167933
[Epoch 6, Batch 900] loss: 0.052100323729682714
[Epoch 6, Batch 1000] loss: 0.06300137572921813
[Epoch 6, Batch 1100] loss: 0.06412659885594621
[Epoch 6, Batch 1200] loss: 0.05858996695373207
[Epoch 6, Batch 1300] loss: 0.06615057706134393
[Epoch 6, Batch 1400] loss: 0.05101568380137905
[Epoch 6, Batch 1500] loss: 0.05289801497361623
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0563
Validation Accuracy: 0.9828
Overfitting: 0.0563
[Epoch 7, Batch 100] loss: 0.05501697652158327
[Epoch 7, Batch 200] loss: 0.03897584541235119
[Epoch 7, Batch 300] loss: 0.03935118434834294
[Epoch 7, Batch 400] loss: 0.05638246892951429
[Epoch 7, Batch 500] loss: 0.03770414176513441
[Epoch 7, Batch 600] loss: 0.04289552041329443
[Epoch 7, Batch 700] loss: 0.049262370521901175
[Epoch 7, Batch 800] loss: 0.046963459037942815
[Epoch 7, Batch 900] loss: 0.04859095767838881
[Epoch 7, Batch 1000] loss: 0.045726733556948604
[Epoch 7, Batch 1100] loss: 0.04888036664982792
[Epoch 7, Batch 1200] loss: 0.03815003561903722
[Epoch 7, Batch 1300] loss: 0.04830249046848621
[Epoch 7, Batch 1400] loss: 0.05760343496542191
[Epoch 7, Batch 1500] loss: 0.049817843028577044
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0540
Validation Accuracy: 0.9828
Overfitting: 0.0540
[Epoch 8, Batch 100] loss: 0.03943253837875091
[Epoch 8, Batch 200] loss: 0.03871050636516884
[Epoch 8, Batch 300] loss: 0.03604544599191286
[Epoch 8, Batch 400] loss: 0.033993254060624166
[Epoch 8, Batch 500] loss: 0.05144076529075391
[Epoch 8, Batch 600] loss: 0.050858767494792116
[Epoch 8, Batch 700] loss: 0.04198878163122572
[Epoch 8, Batch 800] loss: 0.04223034152586479
[Epoch 8, Batch 900] loss: 0.04407346915162634
[Epoch 8, Batch 1000] loss: 0.03928800904832315
[Epoch 8, Batch 1100] loss: 0.03460902407299727
[Epoch 8, Batch 1200] loss: 0.03752418516873149
[Epoch 8, Batch 1300] loss: 0.04353590378712397
[Epoch 8, Batch 1400] loss: 0.03558204052620567
[Epoch 8, Batch 1500] loss: 0.04339234473416582
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0492
Validation Accuracy: 0.9851
Overfitting: 0.0492
[Epoch 9, Batch 100] loss: 0.03317143999331165
[Epoch 9, Batch 200] loss: 0.03178175392269623
[Epoch 9, Batch 300] loss: 0.05339870923897252
[Epoch 9, Batch 400] loss: 0.030820217514410615
[Epoch 9, Batch 500] loss: 0.03960401040676516
[Epoch 9, Batch 600] loss: 0.03301271467353217
[Epoch 9, Batch 700] loss: 0.03494638478150591
[Epoch 9, Batch 800] loss: 0.04406920129316859
[Epoch 9, Batch 900] loss: 0.036943871045368726
[Epoch 9, Batch 1000] loss: 0.04543033924768679
[Epoch 9, Batch 1100] loss: 0.034194621792412366
[Epoch 9, Batch 1200] loss: 0.03579256931669079
[Epoch 9, Batch 1300] loss: 0.031545074005844075
[Epoch 9, Batch 1400] loss: 0.03954917223803932
[Epoch 9, Batch 1500] loss: 0.033899598484276795
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0524
Validation Accuracy: 0.9833
Overfitting: 0.0524
Best model saved at epoch 9 with validation loss: 0.0524
[Epoch 10, Batch 100] loss: 0.03170393198612146
[Epoch 10, Batch 200] loss: 0.035195879306993444
[Epoch 10, Batch 300] loss: 0.03356072099617449
[Epoch 10, Batch 400] loss: 0.027046663503570018
[Epoch 10, Batch 500] loss: 0.03554966535331914
[Epoch 10, Batch 600] loss: 0.037059083461062986
[Epoch 10, Batch 700] loss: 0.027230159035534596
[Epoch 10, Batch 800] loss: 0.037779636239283716
[Epoch 10, Batch 900] loss: 0.03326268482458545
[Epoch 10, Batch 1000] loss: 0.0298184351195232
[Epoch 10, Batch 1100] loss: 0.031154491596389562
[Epoch 10, Batch 1200] loss: 0.028203211344371083
[Epoch 10, Batch 1300] loss: 0.031296181513462216
[Epoch 10, Batch 1400] loss: 0.028218540559755638
[Epoch 10, Batch 1500] loss: 0.039096865523024465
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9842
Overfitting: 0.0512
[Epoch 11, Batch 100] loss: 0.026015193072671538
[Epoch 11, Batch 200] loss: 0.03600272555020638
[Epoch 11, Batch 300] loss: 0.02922887395718135
[Epoch 11, Batch 400] loss: 0.0225076266907854
[Epoch 11, Batch 500] loss: 0.02037035135275801
[Epoch 11, Batch 600] loss: 0.028272770972398574
[Epoch 11, Batch 700] loss: 0.04368988702510251
[Epoch 11, Batch 800] loss: 0.033554572985740376
[Epoch 11, Batch 900] loss: 0.03290745483769569
[Epoch 11, Batch 1000] loss: 0.02957503407029435
[Epoch 11, Batch 1100] loss: 0.024179467179928905
[Epoch 11, Batch 1200] loss: 0.0398690731372335
[Epoch 11, Batch 1300] loss: 0.02704146063653752
[Epoch 11, Batch 1400] loss: 0.022101171132235323
[Epoch 11, Batch 1500] loss: 0.024626654055609834
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0440
Validation Accuracy: 0.9858
Overfitting: 0.0440
Early stopping epoch 11 for trial 22. Moving to next fold.
Fold 1 validation loss: 0.0440
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2987833762168886
[Epoch 1, Batch 200] loss: 2.28035005569458
[Epoch 1, Batch 300] loss: 2.2428943872451783
[Epoch 1, Batch 400] loss: 2.0490347254276275
[Epoch 1, Batch 500] loss: 1.1854432159662247
[Epoch 1, Batch 600] loss: 0.6052001884579659
[Epoch 1, Batch 700] loss: 0.44931456327438357
[Epoch 1, Batch 800] loss: 0.37033368468284605
[Epoch 1, Batch 900] loss: 0.33454115860164163
[Epoch 1, Batch 1000] loss: 0.2974428281933069
[Epoch 1, Batch 1100] loss: 0.28564822167158127
[Epoch 1, Batch 1200] loss: 0.24472557187080382
[Epoch 1, Batch 1300] loss: 0.23395490448921918
[Epoch 1, Batch 1400] loss: 0.21168761774897576
[Epoch 1, Batch 1500] loss: 0.2205371993035078
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1923
Validation Accuracy: 0.9431
Overfitting: 0.1923
[Epoch 2, Batch 100] loss: 0.16232340155169367
[Epoch 2, Batch 200] loss: 0.16876537336036562
[Epoch 2, Batch 300] loss: 0.17675512323155998
[Epoch 2, Batch 400] loss: 0.16596159831620752
[Epoch 2, Batch 500] loss: 0.15949557921849192
[Epoch 2, Batch 600] loss: 0.15922851411625744
[Epoch 2, Batch 700] loss: 0.13928153064101934
[Epoch 2, Batch 800] loss: 0.1357519856095314
[Epoch 2, Batch 900] loss: 0.14162652264349163
[Epoch 2, Batch 1000] loss: 0.11721710591576993
[Epoch 2, Batch 1100] loss: 0.11285926820710301
[Epoch 2, Batch 1200] loss: 0.11961712709628046
[Epoch 2, Batch 1300] loss: 0.13526932038366796
[Epoch 2, Batch 1400] loss: 0.12441645997576416
[Epoch 2, Batch 1500] loss: 0.14122850175946952
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1257
Validation Accuracy: 0.9630
Overfitting: 0.1257
[Epoch 3, Batch 100] loss: 0.1041666589025408
[Epoch 3, Batch 200] loss: 0.10096991062164307
[Epoch 3, Batch 300] loss: 0.1056538469903171
[Epoch 3, Batch 400] loss: 0.11052474157419055
[Epoch 3, Batch 500] loss: 0.09595568724907935
[Epoch 3, Batch 600] loss: 0.08849627203773708
[Epoch 3, Batch 700] loss: 0.09022840196732432
[Epoch 3, Batch 800] loss: 0.09278366547543555
[Epoch 3, Batch 900] loss: 0.09392280186526478
[Epoch 3, Batch 1000] loss: 0.09409117608796805
[Epoch 3, Batch 1100] loss: 0.08502375073265284
[Epoch 3, Batch 1200] loss: 0.1035491529898718
[Epoch 3, Batch 1300] loss: 0.08966353698633611
[Epoch 3, Batch 1400] loss: 0.08857603589072824
[Epoch 3, Batch 1500] loss: 0.09828791401349007
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0927
Validation Accuracy: 0.9712
Overfitting: 0.0927
[Epoch 4, Batch 100] loss: 0.07181636982131749
[Epoch 4, Batch 200] loss: 0.06562043192330748
[Epoch 4, Batch 300] loss: 0.09132019750308246
[Epoch 4, Batch 400] loss: 0.07249509380199015
[Epoch 4, Batch 500] loss: 0.08032237242907286
[Epoch 4, Batch 600] loss: 0.07201035962440074
[Epoch 4, Batch 700] loss: 0.06247507476713508
[Epoch 4, Batch 800] loss: 0.0784201623685658
[Epoch 4, Batch 900] loss: 0.08097772743785754
[Epoch 4, Batch 1000] loss: 0.07004955550655723
[Epoch 4, Batch 1100] loss: 0.08180856771301478
[Epoch 4, Batch 1200] loss: 0.06853957450948656
[Epoch 4, Batch 1300] loss: 0.06613167796633207
[Epoch 4, Batch 1400] loss: 0.07682991680689157
[Epoch 4, Batch 1500] loss: 0.07900117909070105
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0794
Validation Accuracy: 0.9750
Overfitting: 0.0794
[Epoch 5, Batch 100] loss: 0.05672846453962847
[Epoch 5, Batch 200] loss: 0.06101728539448231
[Epoch 5, Batch 300] loss: 0.058926860876381396
[Epoch 5, Batch 400] loss: 0.06382335165049881
[Epoch 5, Batch 500] loss: 0.06205527507001534
[Epoch 5, Batch 600] loss: 0.0691723509831354
[Epoch 5, Batch 700] loss: 0.05259785048896447
[Epoch 5, Batch 800] loss: 0.07295985448756255
[Epoch 5, Batch 900] loss: 0.06304342211922631
[Epoch 5, Batch 1000] loss: 0.06462386234663427
[Epoch 5, Batch 1100] loss: 0.06156184206018225
[Epoch 5, Batch 1200] loss: 0.04964228124707006
[Epoch 5, Batch 1300] loss: 0.06197690014494583
[Epoch 5, Batch 1400] loss: 0.06870581073686481
[Epoch 5, Batch 1500] loss: 0.05886339673306793
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0761
Validation Accuracy: 0.9764
Overfitting: 0.0761
[Epoch 6, Batch 100] loss: 0.04318844874389469
[Epoch 6, Batch 200] loss: 0.04156847653212026
[Epoch 6, Batch 300] loss: 0.055521675265626985
[Epoch 6, Batch 400] loss: 0.05826722147525288
[Epoch 6, Batch 500] loss: 0.046758899099659176
[Epoch 6, Batch 600] loss: 0.0501942353323102
[Epoch 6, Batch 700] loss: 0.05674121401039883
[Epoch 6, Batch 800] loss: 0.05826739052310586
[Epoch 6, Batch 900] loss: 0.04762820958625525
[Epoch 6, Batch 1000] loss: 0.05552359273598995
[Epoch 6, Batch 1100] loss: 0.05335865950153675
[Epoch 6, Batch 1200] loss: 0.05947816581407096
[Epoch 6, Batch 1300] loss: 0.0620798748312518
[Epoch 6, Batch 1400] loss: 0.061638848213478925
[Epoch 6, Batch 1500] loss: 0.04603018552530557
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0640
Validation Accuracy: 0.9802
Overfitting: 0.0640
[Epoch 7, Batch 100] loss: 0.03660680527216755
[Epoch 7, Batch 200] loss: 0.051267057105433195
[Epoch 7, Batch 300] loss: 0.03990674027823843
[Epoch 7, Batch 400] loss: 0.04478560789080802
[Epoch 7, Batch 500] loss: 0.05098314086324535
[Epoch 7, Batch 600] loss: 0.05950892011402175
[Epoch 7, Batch 700] loss: 0.040199902636231855
[Epoch 7, Batch 800] loss: 0.04563279517693445
[Epoch 7, Batch 900] loss: 0.060181207545101645
[Epoch 7, Batch 1000] loss: 0.03745978422928602
[Epoch 7, Batch 1100] loss: 0.04496116817172151
[Epoch 7, Batch 1200] loss: 0.046789030483923855
[Epoch 7, Batch 1300] loss: 0.04770967921707779
[Epoch 7, Batch 1400] loss: 0.0404600958462106
[Epoch 7, Batch 1500] loss: 0.033872330038575454
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0692
Validation Accuracy: 0.9788
Overfitting: 0.0692
[Epoch 8, Batch 100] loss: 0.03574197009264026
[Epoch 8, Batch 200] loss: 0.04030092444154434
[Epoch 8, Batch 300] loss: 0.04603376598679461
[Epoch 8, Batch 400] loss: 0.03854293184471316
[Epoch 8, Batch 500] loss: 0.03930551431607455
[Epoch 8, Batch 600] loss: 0.03964338092016988
[Epoch 8, Batch 700] loss: 0.04376998797175474
[Epoch 8, Batch 800] loss: 0.048259954547975215
[Epoch 8, Batch 900] loss: 0.040322502192575486
[Epoch 8, Batch 1000] loss: 0.038079536691075194
[Epoch 8, Batch 1100] loss: 0.04361046790145338
[Epoch 8, Batch 1200] loss: 0.042571782501181585
[Epoch 8, Batch 1300] loss: 0.03172846117930021
[Epoch 8, Batch 1400] loss: 0.04041646324039903
[Epoch 8, Batch 1500] loss: 0.03802270252024755
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0660
Validation Accuracy: 0.9802
Overfitting: 0.0660
[Epoch 9, Batch 100] loss: 0.0332849930197699
[Epoch 9, Batch 200] loss: 0.042732522395672275
[Epoch 9, Batch 300] loss: 0.04082928888325114
[Epoch 9, Batch 400] loss: 0.03217371157836169
[Epoch 9, Batch 500] loss: 0.028439631030196325
[Epoch 9, Batch 600] loss: 0.04704498844104819
[Epoch 9, Batch 700] loss: 0.03459757386066485
[Epoch 9, Batch 800] loss: 0.03371502705558669
[Epoch 9, Batch 900] loss: 0.029350337418727578
[Epoch 9, Batch 1000] loss: 0.03474873403960373
[Epoch 9, Batch 1100] loss: 0.03538175511232112
[Epoch 9, Batch 1200] loss: 0.04135600118723232
[Epoch 9, Batch 1300] loss: 0.03118035707011586
[Epoch 9, Batch 1400] loss: 0.036784458163310774
[Epoch 9, Batch 1500] loss: 0.040540681880665945
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0639
Validation Accuracy: 0.9804
Overfitting: 0.0639
Best model saved at epoch 9 with validation loss: 0.0639
[Epoch 10, Batch 100] loss: 0.02618378902800032
[Epoch 10, Batch 200] loss: 0.023500946945277976
[Epoch 10, Batch 300] loss: 0.025222130204201675
[Epoch 10, Batch 400] loss: 0.029111408651224337
[Epoch 10, Batch 500] loss: 0.02898447861254681
[Epoch 10, Batch 600] loss: 0.03707139562960947
[Epoch 10, Batch 700] loss: 0.02916713454411365
[Epoch 10, Batch 800] loss: 0.03817954457073938
[Epoch 10, Batch 900] loss: 0.03485572216450237
[Epoch 10, Batch 1000] loss: 0.03216184407094261
[Epoch 10, Batch 1100] loss: 0.033202492999844256
[Epoch 10, Batch 1200] loss: 0.04483484241995029
[Epoch 10, Batch 1300] loss: 0.03430209577316418
[Epoch 10, Batch 1400] loss: 0.030062479180051015
[Epoch 10, Batch 1500] loss: 0.03623341862126836
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0628
Validation Accuracy: 0.9814
Overfitting: 0.0628
[Epoch 11, Batch 100] loss: 0.03155280728591606
[Epoch 11, Batch 200] loss: 0.030129509961698206
[Epoch 11, Batch 300] loss: 0.025358378371747675
[Epoch 11, Batch 400] loss: 0.0315702221239917
[Epoch 11, Batch 500] loss: 0.02758697944751475
[Epoch 11, Batch 600] loss: 0.023471732593025083
[Epoch 11, Batch 700] loss: 0.037577289595501495
[Epoch 11, Batch 800] loss: 0.02406771956710145
[Epoch 11, Batch 900] loss: 0.030744594664138276
[Epoch 11, Batch 1000] loss: 0.02906897671346087
[Epoch 11, Batch 1100] loss: 0.045500814749975686
[Epoch 11, Batch 1200] loss: 0.024376565463026054
[Epoch 11, Batch 1300] loss: 0.03312703209521715
[Epoch 11, Batch 1400] loss: 0.02730225742503535
[Epoch 11, Batch 1500] loss: 0.033929875079775226
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9845
Overfitting: 0.0504
Early stopping epoch 11 for trial 22. Moving to next fold.
Fold 2 validation loss: 0.0504
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2720699095726014
[Epoch 1, Batch 200] loss: 2.0367952930927276
[Epoch 1, Batch 300] loss: 1.0647410851716996
[Epoch 1, Batch 400] loss: 0.6021913182735443
[Epoch 1, Batch 500] loss: 0.4571967796981335
[Epoch 1, Batch 600] loss: 0.4236067767441273
[Epoch 1, Batch 700] loss: 0.3962587302923202
[Epoch 1, Batch 800] loss: 0.34653713785111906
[Epoch 1, Batch 900] loss: 0.3072925651818514
[Epoch 1, Batch 1000] loss: 0.2722427789121866
[Epoch 1, Batch 1100] loss: 0.2620249261707068
[Epoch 1, Batch 1200] loss: 0.24006325658410788
[Epoch 1, Batch 1300] loss: 0.22972663562744855
[Epoch 1, Batch 1400] loss: 0.20915858309715987
[Epoch 1, Batch 1500] loss: 0.20831017922610046
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2161
Validation Accuracy: 0.9347
Overfitting: 0.2161
[Epoch 2, Batch 100] loss: 0.18334605671465398
[Epoch 2, Batch 200] loss: 0.19225662449374795
[Epoch 2, Batch 300] loss: 0.1509258989710361
[Epoch 2, Batch 400] loss: 0.16565589608624579
[Epoch 2, Batch 500] loss: 0.17208777440711856
[Epoch 2, Batch 600] loss: 0.15529084590263664
[Epoch 2, Batch 700] loss: 0.15781449843198062
[Epoch 2, Batch 800] loss: 0.15160953344777225
[Epoch 2, Batch 900] loss: 0.13265463368967176
[Epoch 2, Batch 1000] loss: 0.1451324949786067
[Epoch 2, Batch 1100] loss: 0.12531693044118583
[Epoch 2, Batch 1200] loss: 0.1287579308450222
[Epoch 2, Batch 1300] loss: 0.11270648618228733
[Epoch 2, Batch 1400] loss: 0.12320177445188164
[Epoch 2, Batch 1500] loss: 0.1113823065534234
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1160
Validation Accuracy: 0.9640
Overfitting: 0.1160
[Epoch 3, Batch 100] loss: 0.1014174799155444
[Epoch 3, Batch 200] loss: 0.10860339722596109
[Epoch 3, Batch 300] loss: 0.12547833794727922
[Epoch 3, Batch 400] loss: 0.10598691290710122
[Epoch 3, Batch 500] loss: 0.09689739064313471
[Epoch 3, Batch 600] loss: 0.10352530169999227
[Epoch 3, Batch 700] loss: 0.09640598425175995
[Epoch 3, Batch 800] loss: 0.09440388969145715
[Epoch 3, Batch 900] loss: 0.10647482170723378
[Epoch 3, Batch 1000] loss: 0.07500163659453392
[Epoch 3, Batch 1100] loss: 0.09081140047404915
[Epoch 3, Batch 1200] loss: 0.08806175337173044
[Epoch 3, Batch 1300] loss: 0.08905879816040396
[Epoch 3, Batch 1400] loss: 0.09273461676202714
[Epoch 3, Batch 1500] loss: 0.09384582293219865
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0924
Validation Accuracy: 0.9721
Overfitting: 0.0924
[Epoch 4, Batch 100] loss: 0.08535299269948154
[Epoch 4, Batch 200] loss: 0.0760209307493642
[Epoch 4, Batch 300] loss: 0.07256685282569379
[Epoch 4, Batch 400] loss: 0.07764707351103425
[Epoch 4, Batch 500] loss: 0.07413408953463659
[Epoch 4, Batch 600] loss: 0.07514838928473182
[Epoch 4, Batch 700] loss: 0.07530794172314927
[Epoch 4, Batch 800] loss: 0.08604278986807913
[Epoch 4, Batch 900] loss: 0.07394072991795837
[Epoch 4, Batch 1000] loss: 0.08369203289505095
[Epoch 4, Batch 1100] loss: 0.07851943630725146
[Epoch 4, Batch 1200] loss: 0.0706128939683549
[Epoch 4, Batch 1300] loss: 0.06782400954281911
[Epoch 4, Batch 1400] loss: 0.06777706403750926
[Epoch 4, Batch 1500] loss: 0.07097071641357616
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0820
Validation Accuracy: 0.9756
Overfitting: 0.0820
[Epoch 5, Batch 100] loss: 0.06639289591927082
[Epoch 5, Batch 200] loss: 0.06648445003665984
[Epoch 5, Batch 300] loss: 0.07332247062586247
[Epoch 5, Batch 400] loss: 0.07557385190390051
[Epoch 5, Batch 500] loss: 0.06275998385273851
[Epoch 5, Batch 600] loss: 0.05883882970083505
[Epoch 5, Batch 700] loss: 0.05721401855349541
[Epoch 5, Batch 800] loss: 0.06383571026846767
[Epoch 5, Batch 900] loss: 0.055555669245077294
[Epoch 5, Batch 1000] loss: 0.054736557917203756
[Epoch 5, Batch 1100] loss: 0.05604605609551072
[Epoch 5, Batch 1200] loss: 0.05946484227199107
[Epoch 5, Batch 1300] loss: 0.06771868300449568
[Epoch 5, Batch 1400] loss: 0.05226618662592955
[Epoch 5, Batch 1500] loss: 0.05485412852838636
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0735
Validation Accuracy: 0.9787
Overfitting: 0.0735
[Epoch 6, Batch 100] loss: 0.04952668950543739
[Epoch 6, Batch 200] loss: 0.04593283354770392
[Epoch 6, Batch 300] loss: 0.039836846612161025
[Epoch 6, Batch 400] loss: 0.058268522948492316
[Epoch 6, Batch 500] loss: 0.049387919668806714
[Epoch 6, Batch 600] loss: 0.06022014569607563
[Epoch 6, Batch 700] loss: 0.06157458573579788
[Epoch 6, Batch 800] loss: 0.05307396703166887
[Epoch 6, Batch 900] loss: 0.07661235508741811
[Epoch 6, Batch 1000] loss: 0.046490856062155216
[Epoch 6, Batch 1100] loss: 0.05707928401883691
[Epoch 6, Batch 1200] loss: 0.05572907121153548
[Epoch 6, Batch 1300] loss: 0.04605759668862447
[Epoch 6, Batch 1400] loss: 0.05567359254928306
[Epoch 6, Batch 1500] loss: 0.048209788169479
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0651
Validation Accuracy: 0.9808
Overfitting: 0.0651
[Epoch 7, Batch 100] loss: 0.04560401181399357
[Epoch 7, Batch 200] loss: 0.0340766811161302
[Epoch 7, Batch 300] loss: 0.04180858926963992
[Epoch 7, Batch 400] loss: 0.04290054203476757
[Epoch 7, Batch 500] loss: 0.059922492069890726
[Epoch 7, Batch 600] loss: 0.04738799318904057
[Epoch 7, Batch 700] loss: 0.03945673320733476
[Epoch 7, Batch 800] loss: 0.046181936375796796
[Epoch 7, Batch 900] loss: 0.045339989560307006
[Epoch 7, Batch 1000] loss: 0.04942680977692362
[Epoch 7, Batch 1100] loss: 0.05356790511053987
[Epoch 7, Batch 1200] loss: 0.0511478562396951
[Epoch 7, Batch 1300] loss: 0.05410179318045266
[Epoch 7, Batch 1400] loss: 0.04691075536073185
[Epoch 7, Batch 1500] loss: 0.04219510496594012
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9834
Overfitting: 0.0534
[Epoch 8, Batch 100] loss: 0.03399672346189618
[Epoch 8, Batch 200] loss: 0.04040657493227627
[Epoch 8, Batch 300] loss: 0.03423651895020157
[Epoch 8, Batch 400] loss: 0.040247119867708535
[Epoch 8, Batch 500] loss: 0.03799620444071479
[Epoch 8, Batch 600] loss: 0.04817425540997647
[Epoch 8, Batch 700] loss: 0.03949189229868352
[Epoch 8, Batch 800] loss: 0.039545329636894166
[Epoch 8, Batch 900] loss: 0.033973239437909794
[Epoch 8, Batch 1000] loss: 0.04912205456814263
[Epoch 8, Batch 1100] loss: 0.037536002919077875
[Epoch 8, Batch 1200] loss: 0.05602672845008783
[Epoch 8, Batch 1300] loss: 0.04145162552711554
[Epoch 8, Batch 1400] loss: 0.0299899488108349
[Epoch 8, Batch 1500] loss: 0.04461903313640505
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0565
Validation Accuracy: 0.9832
Overfitting: 0.0565
[Epoch 9, Batch 100] loss: 0.03509187268151436
[Epoch 9, Batch 200] loss: 0.045392301726387814
[Epoch 9, Batch 300] loss: 0.0350445293658413
[Epoch 9, Batch 400] loss: 0.038749176239361985
[Epoch 9, Batch 500] loss: 0.03568712448584847
[Epoch 9, Batch 600] loss: 0.03398187951883301
[Epoch 9, Batch 700] loss: 0.0363704230618896
[Epoch 9, Batch 800] loss: 0.024993146726628765
[Epoch 9, Batch 900] loss: 0.0397469511727104
[Epoch 9, Batch 1000] loss: 0.03679355040425435
[Epoch 9, Batch 1100] loss: 0.029763683153432793
[Epoch 9, Batch 1200] loss: 0.04364675441989675
[Epoch 9, Batch 1300] loss: 0.03153998478606809
[Epoch 9, Batch 1400] loss: 0.038958428371115586
[Epoch 9, Batch 1500] loss: 0.03259784680325538
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0534
Validation Accuracy: 0.9839
Overfitting: 0.0534
Best model saved at epoch 9 with validation loss: 0.0534
[Epoch 10, Batch 100] loss: 0.031087251355638727
[Epoch 10, Batch 200] loss: 0.02663828085467685
[Epoch 10, Batch 300] loss: 0.03263689216226339
[Epoch 10, Batch 400] loss: 0.041344745894311925
[Epoch 10, Batch 500] loss: 0.03501210939954035
[Epoch 10, Batch 600] loss: 0.03273284600407351
[Epoch 10, Batch 700] loss: 0.03071640650043264
[Epoch 10, Batch 800] loss: 0.027761255089426413
[Epoch 10, Batch 900] loss: 0.028357406586001162
[Epoch 10, Batch 1000] loss: 0.02950857370044105
[Epoch 10, Batch 1100] loss: 0.03640610156347975
[Epoch 10, Batch 1200] loss: 0.047409191313781775
[Epoch 10, Batch 1300] loss: 0.035544681621831845
[Epoch 10, Batch 1400] loss: 0.028747863863245585
[Epoch 10, Batch 1500] loss: 0.03415549126220867
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9844
Overfitting: 0.0483
[Epoch 11, Batch 100] loss: 0.030059254237567074
[Epoch 11, Batch 200] loss: 0.027844341480231377
[Epoch 11, Batch 300] loss: 0.0325363327312516
[Epoch 11, Batch 400] loss: 0.03452360840630717
[Epoch 11, Batch 500] loss: 0.02356464570155367
[Epoch 11, Batch 600] loss: 0.025326153161004186
[Epoch 11, Batch 700] loss: 0.037376120060507674
[Epoch 11, Batch 800] loss: 0.03230035606306046
[Epoch 11, Batch 900] loss: 0.03060103305586381
[Epoch 11, Batch 1000] loss: 0.030885321914684027
[Epoch 11, Batch 1100] loss: 0.021469059907831253
[Epoch 11, Batch 1200] loss: 0.03365709377860185
[Epoch 11, Batch 1300] loss: 0.033883411694550884
[Epoch 11, Batch 1400] loss: 0.03119379402618506
[Epoch 11, Batch 1500] loss: 0.024776372691849246
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0513
Validation Accuracy: 0.9841
Overfitting: 0.0513
Early stopping epoch 11 for trial 22. Moving to next fold.
Fold 3 validation loss: 0.0513
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.286979377269745
[Epoch 1, Batch 200] loss: 2.2186726117134095
[Epoch 1, Batch 300] loss: 1.8148855078220367
[Epoch 1, Batch 400] loss: 0.874980302453041
[Epoch 1, Batch 500] loss: 0.5747943559288978
[Epoch 1, Batch 600] loss: 0.48131022825837133
[Epoch 1, Batch 700] loss: 0.4080075013637543
[Epoch 1, Batch 800] loss: 0.38802113868296145
[Epoch 1, Batch 900] loss: 0.3259903076291084
[Epoch 1, Batch 1000] loss: 0.28646496184170245
[Epoch 1, Batch 1100] loss: 0.2672512712329626
[Epoch 1, Batch 1200] loss: 0.24878448959439992
[Epoch 1, Batch 1300] loss: 0.23741040252149104
[Epoch 1, Batch 1400] loss: 0.2159969614073634
[Epoch 1, Batch 1500] loss: 0.22312001353129746
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2091
Validation Accuracy: 0.9323
Overfitting: 0.2091
[Epoch 2, Batch 100] loss: 0.18479496719315647
[Epoch 2, Batch 200] loss: 0.1922982102073729
[Epoch 2, Batch 300] loss: 0.17730675965547563
[Epoch 2, Batch 400] loss: 0.17505213860422372
[Epoch 2, Batch 500] loss: 0.16560679897665978
[Epoch 2, Batch 600] loss: 0.1551611200440675
[Epoch 2, Batch 700] loss: 0.1551426801085472
[Epoch 2, Batch 800] loss: 0.15280156245455145
[Epoch 2, Batch 900] loss: 0.15562614299356936
[Epoch 2, Batch 1000] loss: 0.1444427330419421
[Epoch 2, Batch 1100] loss: 0.13881606221199036
[Epoch 2, Batch 1200] loss: 0.12374215237796307
[Epoch 2, Batch 1300] loss: 0.12377912080846727
[Epoch 2, Batch 1400] loss: 0.12316662965342402
[Epoch 2, Batch 1500] loss: 0.10969064434058964
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1180
Validation Accuracy: 0.9631
Overfitting: 0.1180
[Epoch 3, Batch 100] loss: 0.10735277078580112
[Epoch 3, Batch 200] loss: 0.11766117391642184
[Epoch 3, Batch 300] loss: 0.10724780908785761
[Epoch 3, Batch 400] loss: 0.10038994156755507
[Epoch 3, Batch 500] loss: 0.0971415235940367
[Epoch 3, Batch 600] loss: 0.11331491971388459
[Epoch 3, Batch 700] loss: 0.10997314863838255
[Epoch 3, Batch 800] loss: 0.0976631857547909
[Epoch 3, Batch 900] loss: 0.09955607579089701
[Epoch 3, Batch 1000] loss: 0.10542582485824824
[Epoch 3, Batch 1100] loss: 0.11477544721215964
[Epoch 3, Batch 1200] loss: 0.09474599986802787
[Epoch 3, Batch 1300] loss: 0.07935726906638592
[Epoch 3, Batch 1400] loss: 0.09636200848035514
[Epoch 3, Batch 1500] loss: 0.11086905186064541
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.1141
Validation Accuracy: 0.9667
Overfitting: 0.1141
[Epoch 4, Batch 100] loss: 0.10305207684636115
[Epoch 4, Batch 200] loss: 0.08764971046708524
[Epoch 4, Batch 300] loss: 0.09174646826926619
[Epoch 4, Batch 400] loss: 0.08692891759332269
[Epoch 4, Batch 500] loss: 0.06921928451396525
[Epoch 4, Batch 600] loss: 0.09247896272689105
[Epoch 4, Batch 700] loss: 0.07588198260637
[Epoch 4, Batch 800] loss: 0.058653630544431505
[Epoch 4, Batch 900] loss: 0.0820137875014916
[Epoch 4, Batch 1000] loss: 0.0687817410659045
[Epoch 4, Batch 1100] loss: 0.07256932880729437
[Epoch 4, Batch 1200] loss: 0.08346651401836425
[Epoch 4, Batch 1300] loss: 0.09349381638457999
[Epoch 4, Batch 1400] loss: 0.06659979111747816
[Epoch 4, Batch 1500] loss: 0.07928633122937753
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0823
Validation Accuracy: 0.9732
Overfitting: 0.0823
[Epoch 5, Batch 100] loss: 0.0556767713977024
[Epoch 5, Batch 200] loss: 0.06346996243810281
[Epoch 5, Batch 300] loss: 0.07047653285786509
[Epoch 5, Batch 400] loss: 0.06184069599490613
[Epoch 5, Batch 500] loss: 0.06844067459926009
[Epoch 5, Batch 600] loss: 0.0675652795471251
[Epoch 5, Batch 700] loss: 0.06446577631868422
[Epoch 5, Batch 800] loss: 0.07673036708962172
[Epoch 5, Batch 900] loss: 0.06538855904014781
[Epoch 5, Batch 1000] loss: 0.07441468193428591
[Epoch 5, Batch 1100] loss: 0.07475427255034446
[Epoch 5, Batch 1200] loss: 0.07666390188969671
[Epoch 5, Batch 1300] loss: 0.06707736924756319
[Epoch 5, Batch 1400] loss: 0.04833839336875826
[Epoch 5, Batch 1500] loss: 0.07036501642200164
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0678
Validation Accuracy: 0.9790
Overfitting: 0.0678
[Epoch 6, Batch 100] loss: 0.06046670244308189
[Epoch 6, Batch 200] loss: 0.052067860196111725
[Epoch 6, Batch 300] loss: 0.049810391220962626
[Epoch 6, Batch 400] loss: 0.0559514437825419
[Epoch 6, Batch 500] loss: 0.0704334434471093
[Epoch 6, Batch 600] loss: 0.06212035809177905
[Epoch 6, Batch 700] loss: 0.047624900562223044
[Epoch 6, Batch 800] loss: 0.05469744070898742
[Epoch 6, Batch 900] loss: 0.051100092221749945
[Epoch 6, Batch 1000] loss: 0.05533767487970181
[Epoch 6, Batch 1100] loss: 0.05203922024811618
[Epoch 6, Batch 1200] loss: 0.05668919167481363
[Epoch 6, Batch 1300] loss: 0.0668579758447595
[Epoch 6, Batch 1400] loss: 0.043383416895521804
[Epoch 6, Batch 1500] loss: 0.06526928022271022
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0621
Validation Accuracy: 0.9804
Overfitting: 0.0621
[Epoch 7, Batch 100] loss: 0.052875377498567105
[Epoch 7, Batch 200] loss: 0.047308879299089314
[Epoch 7, Batch 300] loss: 0.05250211387407035
[Epoch 7, Batch 400] loss: 0.04326270987512544
[Epoch 7, Batch 500] loss: 0.04336239675059914
[Epoch 7, Batch 600] loss: 0.04910068080876954
[Epoch 7, Batch 700] loss: 0.05005280502489768
[Epoch 7, Batch 800] loss: 0.04890495920495596
[Epoch 7, Batch 900] loss: 0.040198866014834495
[Epoch 7, Batch 1000] loss: 0.05612915760779288
[Epoch 7, Batch 1100] loss: 0.03724433475523256
[Epoch 7, Batch 1200] loss: 0.05874588745180517
[Epoch 7, Batch 1300] loss: 0.05465604041935876
[Epoch 7, Batch 1400] loss: 0.04448116195446346
[Epoch 7, Batch 1500] loss: 0.0481510825373698
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0579
Validation Accuracy: 0.9818
Overfitting: 0.0579
[Epoch 8, Batch 100] loss: 0.039256881139008326
[Epoch 8, Batch 200] loss: 0.0424317635956686
[Epoch 8, Batch 300] loss: 0.04607295858906582
[Epoch 8, Batch 400] loss: 0.038317856750800273
[Epoch 8, Batch 500] loss: 0.04083868649729993
[Epoch 8, Batch 600] loss: 0.03953664467611816
[Epoch 8, Batch 700] loss: 0.04357438311271835
[Epoch 8, Batch 800] loss: 0.049743855173583144
[Epoch 8, Batch 900] loss: 0.03987442353391089
[Epoch 8, Batch 1000] loss: 0.04163180244737305
[Epoch 8, Batch 1100] loss: 0.04839191292179748
[Epoch 8, Batch 1200] loss: 0.039968692399561405
[Epoch 8, Batch 1300] loss: 0.03502677159733139
[Epoch 8, Batch 1400] loss: 0.048604796215076934
[Epoch 8, Batch 1500] loss: 0.036659386015380734
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0493
Validation Accuracy: 0.9846
Overfitting: 0.0493
[Epoch 9, Batch 100] loss: 0.0334559102403
[Epoch 9, Batch 200] loss: 0.044454159504384735
[Epoch 9, Batch 300] loss: 0.03891015578818042
[Epoch 9, Batch 400] loss: 0.030494880616897715
[Epoch 9, Batch 500] loss: 0.03478618997090962
[Epoch 9, Batch 600] loss: 0.04129469040664844
[Epoch 9, Batch 700] loss: 0.042010015579871836
[Epoch 9, Batch 800] loss: 0.041530882758670486
[Epoch 9, Batch 900] loss: 0.033606853396631775
[Epoch 9, Batch 1000] loss: 0.04124438296305016
[Epoch 9, Batch 1100] loss: 0.035906921294517814
[Epoch 9, Batch 1200] loss: 0.03847738937707618
[Epoch 9, Batch 1300] loss: 0.03273601239779964
[Epoch 9, Batch 1400] loss: 0.03712375598493964
[Epoch 9, Batch 1500] loss: 0.03599905769282486
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0522
Validation Accuracy: 0.9833
Overfitting: 0.0522
Best model saved at epoch 9 with validation loss: 0.0522
[Epoch 10, Batch 100] loss: 0.038251271321787496
[Epoch 10, Batch 200] loss: 0.024272255637333727
[Epoch 10, Batch 300] loss: 0.031156554690387566
[Epoch 10, Batch 400] loss: 0.02584331577672856
[Epoch 10, Batch 500] loss: 0.03570516641862923
[Epoch 10, Batch 600] loss: 0.03358427237719298
[Epoch 10, Batch 700] loss: 0.037384252278134224
[Epoch 10, Batch 800] loss: 0.031348090143292213
[Epoch 10, Batch 900] loss: 0.03147741781169316
[Epoch 10, Batch 1000] loss: 0.03594899151357822
[Epoch 10, Batch 1100] loss: 0.034845584275899455
[Epoch 10, Batch 1200] loss: 0.034012904912233355
[Epoch 10, Batch 1300] loss: 0.032987260582740416
[Epoch 10, Batch 1400] loss: 0.03326946824148763
[Epoch 10, Batch 1500] loss: 0.03299851353047416
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0545
Validation Accuracy: 0.9832
Overfitting: 0.0545
[Epoch 11, Batch 100] loss: 0.03113121808914002
[Epoch 11, Batch 200] loss: 0.028313252377265598
[Epoch 11, Batch 300] loss: 0.036774713848717513
[Epoch 11, Batch 400] loss: 0.026836611344187987
[Epoch 11, Batch 500] loss: 0.022645223694853486
[Epoch 11, Batch 600] loss: 0.03060457005252829
[Epoch 11, Batch 700] loss: 0.03147379770467523
[Epoch 11, Batch 800] loss: 0.02883664656081237
[Epoch 11, Batch 900] loss: 0.02987941570521798
[Epoch 11, Batch 1000] loss: 0.026412188039103057
[Epoch 11, Batch 1100] loss: 0.02749943052243907
[Epoch 11, Batch 1200] loss: 0.029419446347747
[Epoch 11, Batch 1300] loss: 0.025693894557771272
[Epoch 11, Batch 1400] loss: 0.031166079951799475
[Epoch 11, Batch 1500] loss: 0.032172826000023635
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9851
Overfitting: 0.0475
Early stopping epoch 11 for trial 22. Moving to next fold.
Fold 4 validation loss: 0.0475
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.302007169723511
[Epoch 1, Batch 200] loss: 2.2832565689086914
[Epoch 1, Batch 300] loss: 2.2366126227378844
[Epoch 1, Batch 400] loss: 1.9558378314971925
[Epoch 1, Batch 500] loss: 0.9087883201241493
[Epoch 1, Batch 600] loss: 0.5468352377414704
[Epoch 1, Batch 700] loss: 0.4495258988440037
[Epoch 1, Batch 800] loss: 0.42159840911626817
[Epoch 1, Batch 900] loss: 0.3877500855922699
[Epoch 1, Batch 1000] loss: 0.3529143210500479
[Epoch 1, Batch 1100] loss: 0.33518181830644606
[Epoch 1, Batch 1200] loss: 0.278800584115088
[Epoch 1, Batch 1300] loss: 0.24870079331099987
[Epoch 1, Batch 1400] loss: 0.2371532258950174
[Epoch 1, Batch 1500] loss: 0.2189694442972541
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2374
Validation Accuracy: 0.9289
Overfitting: 0.2374
[Epoch 2, Batch 100] loss: 0.20773973021656275
[Epoch 2, Batch 200] loss: 0.2043024751916528
[Epoch 2, Batch 300] loss: 0.18349678989499807
[Epoch 2, Batch 400] loss: 0.17238844104111195
[Epoch 2, Batch 500] loss: 0.16390568563714625
[Epoch 2, Batch 600] loss: 0.16650599773973226
[Epoch 2, Batch 700] loss: 0.15463122118264436
[Epoch 2, Batch 800] loss: 0.15301449799910188
[Epoch 2, Batch 900] loss: 0.1342458121944219
[Epoch 2, Batch 1000] loss: 0.15471118099987508
[Epoch 2, Batch 1100] loss: 0.13403670785948635
[Epoch 2, Batch 1200] loss: 0.13444932838901877
[Epoch 2, Batch 1300] loss: 0.13402811517938973
[Epoch 2, Batch 1400] loss: 0.11732737120240927
[Epoch 2, Batch 1500] loss: 0.11870827111415565
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1238
Validation Accuracy: 0.9636
Overfitting: 0.1238
[Epoch 3, Batch 100] loss: 0.11053330948576331
[Epoch 3, Batch 200] loss: 0.10291212890297174
[Epoch 3, Batch 300] loss: 0.1260541856708005
[Epoch 3, Batch 400] loss: 0.10722362405620516
[Epoch 3, Batch 500] loss: 0.1061874465085566
[Epoch 3, Batch 600] loss: 0.11237019315827639
[Epoch 3, Batch 700] loss: 0.08973909596446901
[Epoch 3, Batch 800] loss: 0.10157298784703016
[Epoch 3, Batch 900] loss: 0.09322747737169265
[Epoch 3, Batch 1000] loss: 0.09440815765410662
[Epoch 3, Batch 1100] loss: 0.08017260925844312
[Epoch 3, Batch 1200] loss: 0.09754486847203225
[Epoch 3, Batch 1300] loss: 0.0808827648870647
[Epoch 3, Batch 1400] loss: 0.07693647977896034
[Epoch 3, Batch 1500] loss: 0.09525581096298992
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0836
Validation Accuracy: 0.9742
Overfitting: 0.0836
[Epoch 4, Batch 100] loss: 0.08849112731870264
[Epoch 4, Batch 200] loss: 0.08967658440815285
[Epoch 4, Batch 300] loss: 0.07981081166304647
[Epoch 4, Batch 400] loss: 0.07836687785573304
[Epoch 4, Batch 500] loss: 0.07177507798653096
[Epoch 4, Batch 600] loss: 0.06751290828455239
[Epoch 4, Batch 700] loss: 0.09227233498822898
[Epoch 4, Batch 800] loss: 0.07272928282152862
[Epoch 4, Batch 900] loss: 0.06883522741496563
[Epoch 4, Batch 1000] loss: 0.06938902066089213
[Epoch 4, Batch 1100] loss: 0.08053600209299475
[Epoch 4, Batch 1200] loss: 0.06208666712162085
[Epoch 4, Batch 1300] loss: 0.07258660116698593
[Epoch 4, Batch 1400] loss: 0.07559079298283905
[Epoch 4, Batch 1500] loss: 0.06900657792808489
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0883
Validation Accuracy: 0.9733
Overfitting: 0.0883
[Epoch 5, Batch 100] loss: 0.05460970824235119
[Epoch 5, Batch 200] loss: 0.07148635580902919
[Epoch 5, Batch 300] loss: 0.05718784081283957
[Epoch 5, Batch 400] loss: 0.07306021027965472
[Epoch 5, Batch 500] loss: 0.06250507265329361
[Epoch 5, Batch 600] loss: 0.07908346029464156
[Epoch 5, Batch 700] loss: 0.06848633302375674
[Epoch 5, Batch 800] loss: 0.07255518011050299
[Epoch 5, Batch 900] loss: 0.06338734861230477
[Epoch 5, Batch 1000] loss: 0.060578191627282646
[Epoch 5, Batch 1100] loss: 0.054904204176273196
[Epoch 5, Batch 1200] loss: 0.06123455458553508
[Epoch 5, Batch 1300] loss: 0.057008083120454106
[Epoch 5, Batch 1400] loss: 0.049994489075616
[Epoch 5, Batch 1500] loss: 0.07505570187116974
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0674
Validation Accuracy: 0.9796
Overfitting: 0.0674
[Epoch 6, Batch 100] loss: 0.05267300578765571
[Epoch 6, Batch 200] loss: 0.04648710146080703
[Epoch 6, Batch 300] loss: 0.058287152530392634
[Epoch 6, Batch 400] loss: 0.0462872628448531
[Epoch 6, Batch 500] loss: 0.05461253252462484
[Epoch 6, Batch 600] loss: 0.056337550822645424
[Epoch 6, Batch 700] loss: 0.0646762643987313
[Epoch 6, Batch 800] loss: 0.054071937974076716
[Epoch 6, Batch 900] loss: 0.05141833400411997
[Epoch 6, Batch 1000] loss: 0.05623081865429413
[Epoch 6, Batch 1100] loss: 0.05672312570968643
[Epoch 6, Batch 1200] loss: 0.04744950566557236
[Epoch 6, Batch 1300] loss: 0.05418898915755563
[Epoch 6, Batch 1400] loss: 0.05629121677717194
[Epoch 6, Batch 1500] loss: 0.051503194659017024
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0619
Validation Accuracy: 0.9805
Overfitting: 0.0619
[Epoch 7, Batch 100] loss: 0.054401332284323874
[Epoch 7, Batch 200] loss: 0.052956669663544745
[Epoch 7, Batch 300] loss: 0.04751616499968805
[Epoch 7, Batch 400] loss: 0.03714448919519782
[Epoch 7, Batch 500] loss: 0.038926420976640654
[Epoch 7, Batch 600] loss: 0.04818001382634975
[Epoch 7, Batch 700] loss: 0.053000500801717865
[Epoch 7, Batch 800] loss: 0.049041258690413085
[Epoch 7, Batch 900] loss: 0.04289309654850513
[Epoch 7, Batch 1000] loss: 0.04068680102878716
[Epoch 7, Batch 1100] loss: 0.04967463945911731
[Epoch 7, Batch 1200] loss: 0.03426832327037119
[Epoch 7, Batch 1300] loss: 0.052629217661451545
[Epoch 7, Batch 1400] loss: 0.05221690513775684
[Epoch 7, Batch 1500] loss: 0.04599951479700394
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0554
Validation Accuracy: 0.9832
Overfitting: 0.0554
[Epoch 8, Batch 100] loss: 0.03227062996535096
[Epoch 8, Batch 200] loss: 0.03862233127350919
[Epoch 8, Batch 300] loss: 0.04757547414250439
[Epoch 8, Batch 400] loss: 0.04610303297638893
[Epoch 8, Batch 500] loss: 0.03209959609201178
[Epoch 8, Batch 600] loss: 0.03539994034683332
[Epoch 8, Batch 700] loss: 0.03899232836964075
[Epoch 8, Batch 800] loss: 0.03749848702398594
[Epoch 8, Batch 900] loss: 0.03840118195628747
[Epoch 8, Batch 1000] loss: 0.042015259879408406
[Epoch 8, Batch 1100] loss: 0.03064199923304841
[Epoch 8, Batch 1200] loss: 0.051330008430522864
[Epoch 8, Batch 1300] loss: 0.04956673749024049
[Epoch 8, Batch 1400] loss: 0.04380713425460272
[Epoch 8, Batch 1500] loss: 0.04060466953320429
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9836
Overfitting: 0.0539
[Epoch 9, Batch 100] loss: 0.032270827506436034
[Epoch 9, Batch 200] loss: 0.03991497776587494
[Epoch 9, Batch 300] loss: 0.04043089915474411
[Epoch 9, Batch 400] loss: 0.04826916900463402
[Epoch 9, Batch 500] loss: 0.03521957096410915
[Epoch 9, Batch 600] loss: 0.03414806826272979
[Epoch 9, Batch 700] loss: 0.025705479723401366
[Epoch 9, Batch 800] loss: 0.026316897784126922
[Epoch 9, Batch 900] loss: 0.028017889764305436
[Epoch 9, Batch 1000] loss: 0.03737209415150573
[Epoch 9, Batch 1100] loss: 0.04214268897019793
[Epoch 9, Batch 1200] loss: 0.047641536042792726
[Epoch 9, Batch 1300] loss: 0.03215478957165033
[Epoch 9, Batch 1400] loss: 0.03513162722811103
[Epoch 9, Batch 1500] loss: 0.038674101899378005
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0520
Validation Accuracy: 0.9848
Overfitting: 0.0520
Best model saved at epoch 9 with validation loss: 0.0520
[Epoch 10, Batch 100] loss: 0.02107750516239321
[Epoch 10, Batch 200] loss: 0.03436223232769407
[Epoch 10, Batch 300] loss: 0.03359406763163861
[Epoch 10, Batch 400] loss: 0.02562534135300666
[Epoch 10, Batch 500] loss: 0.02153353802888887
[Epoch 10, Batch 600] loss: 0.0442685466556577
[Epoch 10, Batch 700] loss: 0.03156998888705857
[Epoch 10, Batch 800] loss: 0.025492142718285322
[Epoch 10, Batch 900] loss: 0.04960781346890144
[Epoch 10, Batch 1000] loss: 0.03140842805383727
[Epoch 10, Batch 1100] loss: 0.03232630487531424
[Epoch 10, Batch 1200] loss: 0.032264680569642226
[Epoch 10, Batch 1300] loss: 0.02969968554971274
[Epoch 10, Batch 1400] loss: 0.03546617717925983
[Epoch 10, Batch 1500] loss: 0.039452763897133994
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9858
Overfitting: 0.0481
[Epoch 11, Batch 100] loss: 0.03418604146223515
[Epoch 11, Batch 200] loss: 0.022237004874041302
[Epoch 11, Batch 300] loss: 0.0238556580391014
[Epoch 11, Batch 400] loss: 0.027941946579376237
[Epoch 11, Batch 500] loss: 0.03161258522537537
[Epoch 11, Batch 600] loss: 0.02765384498925414
[Epoch 11, Batch 700] loss: 0.024207307774049697
[Epoch 11, Batch 800] loss: 0.023169902540976183
[Epoch 11, Batch 900] loss: 0.03136637942458037
[Epoch 11, Batch 1000] loss: 0.035933944779681044
[Epoch 11, Batch 1100] loss: 0.02827567028667545
[Epoch 11, Batch 1200] loss: 0.030974369222531096
[Epoch 11, Batch 1300] loss: 0.024596457672014366
[Epoch 11, Batch 1400] loss: 0.04195889667083975
[Epoch 11, Batch 1500] loss: 0.027799792858422732
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0473
Validation Accuracy: 0.9846
Overfitting: 0.0473
Early stopping epoch 11 for trial 22. Moving to next fold.
Fold 5 validation loss: 0.0473
Mean validation loss across all folds for Trial 22 is 0.0481 with trial config:  l1: 256, l2: 128, lr: 0.001, batch_size: 32
[I 2024-12-10 07:41:22,389] Trial 21 finished with value: 0.04811396317985685 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 32}. Best is trial 21 with value: 0.04811396317985685.

Selected Hyperparameters for Trial 23:
  l1: 256, l2: 128, lr: 0.001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2992200207710267
[Epoch 1, Batch 200] loss: 2.2811114597320556
[Epoch 1, Batch 300] loss: 2.2398567271232603
[Epoch 1, Batch 400] loss: 2.0297949254512786
[Epoch 1, Batch 500] loss: 1.0880918216705322
[Epoch 1, Batch 600] loss: 0.577109315097332
[Epoch 1, Batch 700] loss: 0.44439831778407096
[Epoch 1, Batch 800] loss: 0.40912187710404396
[Epoch 1, Batch 900] loss: 0.3326948688924313
[Epoch 1, Batch 1000] loss: 0.3217442245036364
[Epoch 1, Batch 1100] loss: 0.3135450431704521
[Epoch 1, Batch 1200] loss: 0.27393889844417574
[Epoch 1, Batch 1300] loss: 0.24598896123468875
[Epoch 1, Batch 1400] loss: 0.2527818512171507
[Epoch 1, Batch 1500] loss: 0.2669584661722183
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2081
Validation Accuracy: 0.9381
Overfitting: 0.2081
[Epoch 2, Batch 100] loss: 0.20890435356646775
[Epoch 2, Batch 200] loss: 0.20530224515125156
[Epoch 2, Batch 300] loss: 0.18318769097328186
[Epoch 2, Batch 400] loss: 0.18280283406376838
[Epoch 2, Batch 500] loss: 0.16303821075707675
[Epoch 2, Batch 600] loss: 0.14704989559948445
[Epoch 2, Batch 700] loss: 0.15255337180569767
[Epoch 2, Batch 800] loss: 0.1550990147702396
[Epoch 2, Batch 900] loss: 0.14072128176689147
[Epoch 2, Batch 1000] loss: 0.13024018333293497
[Epoch 2, Batch 1100] loss: 0.14469343246892094
[Epoch 2, Batch 1200] loss: 0.12776321449317038
[Epoch 2, Batch 1300] loss: 0.12341751785948872
[Epoch 2, Batch 1400] loss: 0.12307327981106937
[Epoch 2, Batch 1500] loss: 0.10834037254564464
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1049
Validation Accuracy: 0.9657
Overfitting: 0.1049
[Epoch 3, Batch 100] loss: 0.12950714774429797
[Epoch 3, Batch 200] loss: 0.11488406244665385
[Epoch 3, Batch 300] loss: 0.10696164901833981
[Epoch 3, Batch 400] loss: 0.09845358456484973
[Epoch 3, Batch 500] loss: 0.10826848440803588
[Epoch 3, Batch 600] loss: 0.10135770376771688
[Epoch 3, Batch 700] loss: 0.08700220896396786
[Epoch 3, Batch 800] loss: 0.09933118873275816
[Epoch 3, Batch 900] loss: 0.09886198764201254
[Epoch 3, Batch 1000] loss: 0.09041764757595956
[Epoch 3, Batch 1100] loss: 0.09374308039434254
[Epoch 3, Batch 1200] loss: 0.08694301443174482
[Epoch 3, Batch 1300] loss: 0.09141634918749332
[Epoch 3, Batch 1400] loss: 0.07888968714745716
[Epoch 3, Batch 1500] loss: 0.07005808878922835
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0916
Validation Accuracy: 0.9700
Overfitting: 0.0916
[Epoch 4, Batch 100] loss: 0.08522200458683074
[Epoch 4, Batch 200] loss: 0.07040417974349111
[Epoch 4, Batch 300] loss: 0.0647897012438625
[Epoch 4, Batch 400] loss: 0.07415856182109565
[Epoch 4, Batch 500] loss: 0.07581336661241948
[Epoch 4, Batch 600] loss: 0.06437037476105616
[Epoch 4, Batch 700] loss: 0.07874265816994011
[Epoch 4, Batch 800] loss: 0.07632461185799912
[Epoch 4, Batch 900] loss: 0.07846374666201882
[Epoch 4, Batch 1000] loss: 0.0894957296946086
[Epoch 4, Batch 1100] loss: 0.06913433253765106
[Epoch 4, Batch 1200] loss: 0.06583095159614459
[Epoch 4, Batch 1300] loss: 0.08660020525101572
[Epoch 4, Batch 1400] loss: 0.06169190682005137
[Epoch 4, Batch 1500] loss: 0.08263521555345506
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0716
Validation Accuracy: 0.9766
Overfitting: 0.0716
[Epoch 5, Batch 100] loss: 0.06540712872054427
[Epoch 5, Batch 200] loss: 0.057725579801481214
[Epoch 5, Batch 300] loss: 0.06646533597027883
[Epoch 5, Batch 400] loss: 0.06486474138218909
[Epoch 5, Batch 500] loss: 0.06602058822056278
[Epoch 5, Batch 600] loss: 0.05707145473686978
[Epoch 5, Batch 700] loss: 0.060603213268332186
[Epoch 5, Batch 800] loss: 0.0588147760136053
[Epoch 5, Batch 900] loss: 0.06007913520908915
[Epoch 5, Batch 1000] loss: 0.06407422702293843
[Epoch 5, Batch 1100] loss: 0.07290923296124674
[Epoch 5, Batch 1200] loss: 0.06559396161697804
[Epoch 5, Batch 1300] loss: 0.06687809774652123
[Epoch 5, Batch 1400] loss: 0.05904222376411781
[Epoch 5, Batch 1500] loss: 0.05447471427731216
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0616
Validation Accuracy: 0.9810
Overfitting: 0.0616
[Epoch 6, Batch 100] loss: 0.06437745767878368
[Epoch 6, Batch 200] loss: 0.041439277152530846
[Epoch 6, Batch 300] loss: 0.05846857420518063
[Epoch 6, Batch 400] loss: 0.0582013410248328
[Epoch 6, Batch 500] loss: 0.055638209058670327
[Epoch 6, Batch 600] loss: 0.05777029455406591
[Epoch 6, Batch 700] loss: 0.05655917206546292
[Epoch 6, Batch 800] loss: 0.055985947232693435
[Epoch 6, Batch 900] loss: 0.057065222198143604
[Epoch 6, Batch 1000] loss: 0.0696369418199174
[Epoch 6, Batch 1100] loss: 0.03766754397773184
[Epoch 6, Batch 1200] loss: 0.04845648607937619
[Epoch 6, Batch 1300] loss: 0.05546166223939508
[Epoch 6, Batch 1400] loss: 0.04709567983518355
[Epoch 6, Batch 1500] loss: 0.04572547881049104
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0560
Validation Accuracy: 0.9817
Overfitting: 0.0560
[Epoch 7, Batch 100] loss: 0.04434343943139538
[Epoch 7, Batch 200] loss: 0.03919169872300699
[Epoch 7, Batch 300] loss: 0.04004459443734959
[Epoch 7, Batch 400] loss: 0.05251204741536639
[Epoch 7, Batch 500] loss: 0.035501894539920614
[Epoch 7, Batch 600] loss: 0.0442654752812814
[Epoch 7, Batch 700] loss: 0.047546848544152455
[Epoch 7, Batch 800] loss: 0.03880854719900526
[Epoch 7, Batch 900] loss: 0.04902000317524653
[Epoch 7, Batch 1000] loss: 0.062446052166633306
[Epoch 7, Batch 1100] loss: 0.041368507978040724
[Epoch 7, Batch 1200] loss: 0.055091897703241556
[Epoch 7, Batch 1300] loss: 0.04954932227439713
[Epoch 7, Batch 1400] loss: 0.050862956739147196
[Epoch 7, Batch 1500] loss: 0.04898617994738743
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0573
Validation Accuracy: 0.9820
Overfitting: 0.0573
[Epoch 8, Batch 100] loss: 0.041246020469116046
[Epoch 8, Batch 200] loss: 0.03923302255570889
[Epoch 8, Batch 300] loss: 0.03910201648250222
[Epoch 8, Batch 400] loss: 0.04057582192588598
[Epoch 8, Batch 500] loss: 0.042091133490321224
[Epoch 8, Batch 600] loss: 0.03070993029163219
[Epoch 8, Batch 700] loss: 0.04157212714664638
[Epoch 8, Batch 800] loss: 0.04208138965885155
[Epoch 8, Batch 900] loss: 0.04920148375676945
[Epoch 8, Batch 1000] loss: 0.04704394120490178
[Epoch 8, Batch 1100] loss: 0.042882047123275695
[Epoch 8, Batch 1200] loss: 0.031397082249168304
[Epoch 8, Batch 1300] loss: 0.05279216636467027
[Epoch 8, Batch 1400] loss: 0.042804782660678026
[Epoch 8, Batch 1500] loss: 0.034064111738698555
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0518
Validation Accuracy: 0.9837
Overfitting: 0.0518
[Epoch 9, Batch 100] loss: 0.034300779089098794
[Epoch 9, Batch 200] loss: 0.03188997580728028
[Epoch 9, Batch 300] loss: 0.02803067375381943
[Epoch 9, Batch 400] loss: 0.03615043504047208
[Epoch 9, Batch 500] loss: 0.032591589288786055
[Epoch 9, Batch 600] loss: 0.04011948140396271
[Epoch 9, Batch 700] loss: 0.035876788219902665
[Epoch 9, Batch 800] loss: 0.04170069535612129
[Epoch 9, Batch 900] loss: 0.03460127784434008
[Epoch 9, Batch 1000] loss: 0.03596116156724747
[Epoch 9, Batch 1100] loss: 0.038090612775995396
[Epoch 9, Batch 1200] loss: 0.0429237530863611
[Epoch 9, Batch 1300] loss: 0.03601997747609857
[Epoch 9, Batch 1400] loss: 0.04063641294487752
[Epoch 9, Batch 1500] loss: 0.04058771183714271
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9840
Overfitting: 0.0504
Best model saved at epoch 9 with validation loss: 0.0504
[Epoch 10, Batch 100] loss: 0.02130029512103647
[Epoch 10, Batch 200] loss: 0.027395636288129025
[Epoch 10, Batch 300] loss: 0.03473035760922358
[Epoch 10, Batch 400] loss: 0.031207408121554182
[Epoch 10, Batch 500] loss: 0.029186315253027714
[Epoch 10, Batch 600] loss: 0.04064540830790065
[Epoch 10, Batch 700] loss: 0.03848979843431152
[Epoch 10, Batch 800] loss: 0.030352420985873322
[Epoch 10, Batch 900] loss: 0.03888386579812504
[Epoch 10, Batch 1000] loss: 0.03116033333004452
[Epoch 10, Batch 1100] loss: 0.026231595310382546
[Epoch 10, Batch 1200] loss: 0.04788576330407523
[Epoch 10, Batch 1300] loss: 0.02935685725271469
[Epoch 10, Batch 1400] loss: 0.0310146360550425
[Epoch 10, Batch 1500] loss: 0.035389184845262205
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0506
Validation Accuracy: 0.9839
Overfitting: 0.0506
[Epoch 11, Batch 100] loss: 0.03033767176500987
[Epoch 11, Batch 200] loss: 0.021319424202665686
[Epoch 11, Batch 300] loss: 0.02339196193148382
[Epoch 11, Batch 400] loss: 0.02832540488394443
[Epoch 11, Batch 500] loss: 0.024247033922147238
[Epoch 11, Batch 600] loss: 0.032379502787662204
[Epoch 11, Batch 700] loss: 0.03295591003028676
[Epoch 11, Batch 800] loss: 0.029474418222380335
[Epoch 11, Batch 900] loss: 0.03376340071758022
[Epoch 11, Batch 1000] loss: 0.03226266132667661
[Epoch 11, Batch 1100] loss: 0.03127450529776979
[Epoch 11, Batch 1200] loss: 0.027775992139067965
[Epoch 11, Batch 1300] loss: 0.020842048209015047
[Epoch 11, Batch 1400] loss: 0.031233098830562085
[Epoch 11, Batch 1500] loss: 0.03576038884348236
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0511
Validation Accuracy: 0.9844
Overfitting: 0.0511
Early stopping epoch 11 for trial 23. Moving to next fold.
Fold 1 validation loss: 0.0511
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.300611000061035
[Epoch 1, Batch 200] loss: 2.285619204044342
[Epoch 1, Batch 300] loss: 2.248341851234436
[Epoch 1, Batch 400] loss: 2.0720256757736206
[Epoch 1, Batch 500] loss: 1.1250084656476975
[Epoch 1, Batch 600] loss: 0.5378224512934685
[Epoch 1, Batch 700] loss: 0.40675771579146386
[Epoch 1, Batch 800] loss: 0.3619665390253067
[Epoch 1, Batch 900] loss: 0.3511514239758253
[Epoch 1, Batch 1000] loss: 0.3018611620739102
[Epoch 1, Batch 1100] loss: 0.3012623220682144
[Epoch 1, Batch 1200] loss: 0.26757929753512144
[Epoch 1, Batch 1300] loss: 0.23358637612313032
[Epoch 1, Batch 1400] loss: 0.20707458507269622
[Epoch 1, Batch 1500] loss: 0.20721471294760704
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1920
Validation Accuracy: 0.9417
Overfitting: 0.1920
[Epoch 2, Batch 100] loss: 0.17619527738541366
[Epoch 2, Batch 200] loss: 0.15908352477476
[Epoch 2, Batch 300] loss: 0.16585350777953864
[Epoch 2, Batch 400] loss: 0.16279995918273926
[Epoch 2, Batch 500] loss: 0.14615413361229002
[Epoch 2, Batch 600] loss: 0.1587771960347891
[Epoch 2, Batch 700] loss: 0.1589407266303897
[Epoch 2, Batch 800] loss: 0.12638324251398445
[Epoch 2, Batch 900] loss: 0.1320290434360504
[Epoch 2, Batch 1000] loss: 0.12157770611345768
[Epoch 2, Batch 1100] loss: 0.0946143963560462
[Epoch 2, Batch 1200] loss: 0.11705383616965265
[Epoch 2, Batch 1300] loss: 0.09716497966321186
[Epoch 2, Batch 1400] loss: 0.11896257892251015
[Epoch 2, Batch 1500] loss: 0.11955709806643426
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1141
Validation Accuracy: 0.9655
Overfitting: 0.1141
[Epoch 3, Batch 100] loss: 0.0921831548307091
[Epoch 3, Batch 200] loss: 0.08396771541796624
[Epoch 3, Batch 300] loss: 0.08311327081639319
[Epoch 3, Batch 400] loss: 0.09688910270575433
[Epoch 3, Batch 500] loss: 0.10413537804037333
[Epoch 3, Batch 600] loss: 0.09486246992368251
[Epoch 3, Batch 700] loss: 0.08929536445531994
[Epoch 3, Batch 800] loss: 0.0919749170402065
[Epoch 3, Batch 900] loss: 0.08490048074629158
[Epoch 3, Batch 1000] loss: 0.07714380655437708
[Epoch 3, Batch 1100] loss: 0.09162770892959088
[Epoch 3, Batch 1200] loss: 0.08611170602962374
[Epoch 3, Batch 1300] loss: 0.08764670493081211
[Epoch 3, Batch 1400] loss: 0.08031001590192317
[Epoch 3, Batch 1500] loss: 0.0872385390754789
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0904
Validation Accuracy: 0.9718
Overfitting: 0.0904
[Epoch 4, Batch 100] loss: 0.07187872276175768
[Epoch 4, Batch 200] loss: 0.07318432643078268
[Epoch 4, Batch 300] loss: 0.07069359948625788
[Epoch 4, Batch 400] loss: 0.08462977811694145
[Epoch 4, Batch 500] loss: 0.06592319354531355
[Epoch 4, Batch 600] loss: 0.07462976988172158
[Epoch 4, Batch 700] loss: 0.07798161943326704
[Epoch 4, Batch 800] loss: 0.06905722607858479
[Epoch 4, Batch 900] loss: 0.06560392430052162
[Epoch 4, Batch 1000] loss: 0.05095542229479179
[Epoch 4, Batch 1100] loss: 0.06699371656868607
[Epoch 4, Batch 1200] loss: 0.0678795016091317
[Epoch 4, Batch 1300] loss: 0.09069141689222306
[Epoch 4, Batch 1400] loss: 0.05824691327521578
[Epoch 4, Batch 1500] loss: 0.0650559153035283
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.1029
Validation Accuracy: 0.9705
Overfitting: 0.1029
[Epoch 5, Batch 100] loss: 0.062499581186566504
[Epoch 5, Batch 200] loss: 0.06187842804007232
[Epoch 5, Batch 300] loss: 0.053413220837246624
[Epoch 5, Batch 400] loss: 0.05269566403119825
[Epoch 5, Batch 500] loss: 0.06474390036659315
[Epoch 5, Batch 600] loss: 0.06900292676175013
[Epoch 5, Batch 700] loss: 0.045392078885342926
[Epoch 5, Batch 800] loss: 0.06344628197839483
[Epoch 5, Batch 900] loss: 0.05731582139385864
[Epoch 5, Batch 1000] loss: 0.06194158491678536
[Epoch 5, Batch 1100] loss: 0.06659071356523782
[Epoch 5, Batch 1200] loss: 0.0623651601979509
[Epoch 5, Batch 1300] loss: 0.047750870482414026
[Epoch 5, Batch 1400] loss: 0.05245373088400811
[Epoch 5, Batch 1500] loss: 0.045860042574349794
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0743
Validation Accuracy: 0.9770
Overfitting: 0.0743
[Epoch 6, Batch 100] loss: 0.047080443566665055
[Epoch 6, Batch 200] loss: 0.05806772815180011
[Epoch 6, Batch 300] loss: 0.05275839180103503
[Epoch 6, Batch 400] loss: 0.05717581347853411
[Epoch 6, Batch 500] loss: 0.043262801842065525
[Epoch 6, Batch 600] loss: 0.04351917989435606
[Epoch 6, Batch 700] loss: 0.05787402754882351
[Epoch 6, Batch 800] loss: 0.0528805539465975
[Epoch 6, Batch 900] loss: 0.030707629129465203
[Epoch 6, Batch 1000] loss: 0.04355170478695072
[Epoch 6, Batch 1100] loss: 0.05744744694791734
[Epoch 6, Batch 1200] loss: 0.06043279285077006
[Epoch 6, Batch 1300] loss: 0.051914685865631326
[Epoch 6, Batch 1400] loss: 0.04766293241060339
[Epoch 6, Batch 1500] loss: 0.042803817454259846
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0672
Validation Accuracy: 0.9788
Overfitting: 0.0672
[Epoch 7, Batch 100] loss: 0.042489241356379354
[Epoch 7, Batch 200] loss: 0.04327503659005742
[Epoch 7, Batch 300] loss: 0.05403015226358548
[Epoch 7, Batch 400] loss: 0.0355412020010408
[Epoch 7, Batch 500] loss: 0.03398681508959271
[Epoch 7, Batch 600] loss: 0.044285931484773756
[Epoch 7, Batch 700] loss: 0.05769191818893887
[Epoch 7, Batch 800] loss: 0.03630297504249029
[Epoch 7, Batch 900] loss: 0.043256272966973486
[Epoch 7, Batch 1000] loss: 0.051359601840376856
[Epoch 7, Batch 1100] loss: 0.04487889080774039
[Epoch 7, Batch 1200] loss: 0.04101671234471724
[Epoch 7, Batch 1300] loss: 0.04619356382172555
[Epoch 7, Batch 1400] loss: 0.04944180650287308
[Epoch 7, Batch 1500] loss: 0.0415117986802943
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0668
Validation Accuracy: 0.9805
Overfitting: 0.0668
[Epoch 8, Batch 100] loss: 0.03553920673788525
[Epoch 8, Batch 200] loss: 0.03354059730714653
[Epoch 8, Batch 300] loss: 0.03789621507399715
[Epoch 8, Batch 400] loss: 0.04178971102461219
[Epoch 8, Batch 500] loss: 0.03690584910858888
[Epoch 8, Batch 600] loss: 0.04821763010462746
[Epoch 8, Batch 700] loss: 0.03153980560367927
[Epoch 8, Batch 800] loss: 0.036248811822733845
[Epoch 8, Batch 900] loss: 0.039537198401521895
[Epoch 8, Batch 1000] loss: 0.045635706741595644
[Epoch 8, Batch 1100] loss: 0.0360975313547533
[Epoch 8, Batch 1200] loss: 0.04682677049364429
[Epoch 8, Batch 1300] loss: 0.03625500818830915
[Epoch 8, Batch 1400] loss: 0.03651305907929782
[Epoch 8, Batch 1500] loss: 0.04938340088061523
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0569
Validation Accuracy: 0.9822
Overfitting: 0.0569
[Epoch 9, Batch 100] loss: 0.034397170881275085
[Epoch 9, Batch 200] loss: 0.03357200413825922
[Epoch 9, Batch 300] loss: 0.035708736210945065
[Epoch 9, Batch 400] loss: 0.03766871831045137
[Epoch 9, Batch 500] loss: 0.030875999171985313
[Epoch 9, Batch 600] loss: 0.025693891874398106
[Epoch 9, Batch 700] loss: 0.027029976244957652
[Epoch 9, Batch 800] loss: 0.029636452671547887
[Epoch 9, Batch 900] loss: 0.040162783508130816
[Epoch 9, Batch 1000] loss: 0.043846440635388714
[Epoch 9, Batch 1100] loss: 0.04374258698575431
[Epoch 9, Batch 1200] loss: 0.02762945472379215
[Epoch 9, Batch 1300] loss: 0.029598561829188838
[Epoch 9, Batch 1400] loss: 0.03768924961856101
[Epoch 9, Batch 1500] loss: 0.03096610174688976
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0562
Validation Accuracy: 0.9838
Overfitting: 0.0562
Best model saved at epoch 9 with validation loss: 0.0562
[Epoch 10, Batch 100] loss: 0.023607259711134247
[Epoch 10, Batch 200] loss: 0.034251947005977855
[Epoch 10, Batch 300] loss: 0.024880558693548663
[Epoch 10, Batch 400] loss: 0.03146085470070829
[Epoch 10, Batch 500] loss: 0.03439250037481543
[Epoch 10, Batch 600] loss: 0.02648045885085594
[Epoch 10, Batch 700] loss: 0.024043771286669652
[Epoch 10, Batch 800] loss: 0.030036285086534917
[Epoch 10, Batch 900] loss: 0.03203483449411579
[Epoch 10, Batch 1000] loss: 0.0382603512800415
[Epoch 10, Batch 1100] loss: 0.03607467597699724
[Epoch 10, Batch 1200] loss: 0.03487819965404924
[Epoch 10, Batch 1300] loss: 0.03332546998921316
[Epoch 10, Batch 1400] loss: 0.030526060007396154
[Epoch 10, Batch 1500] loss: 0.032620102625805884
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9832
Overfitting: 0.0550
[Epoch 11, Batch 100] loss: 0.024137024969677442
[Epoch 11, Batch 200] loss: 0.029955326650670033
[Epoch 11, Batch 300] loss: 0.029010518969153055
[Epoch 11, Batch 400] loss: 0.027062399495916906
[Epoch 11, Batch 500] loss: 0.026178300667525037
[Epoch 11, Batch 600] loss: 0.027117366051243152
[Epoch 11, Batch 700] loss: 0.023973527898342582
[Epoch 11, Batch 800] loss: 0.029176733230269748
[Epoch 11, Batch 900] loss: 0.022230870263447288
[Epoch 11, Batch 1000] loss: 0.02883868802629877
[Epoch 11, Batch 1100] loss: 0.035337732081825377
[Epoch 11, Batch 1200] loss: 0.03269868384959409
[Epoch 11, Batch 1300] loss: 0.02676429030660074
[Epoch 11, Batch 1400] loss: 0.023338790267007425
[Epoch 11, Batch 1500] loss: 0.03435355037130648
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0550
Validation Accuracy: 0.9831
Overfitting: 0.0550
Early stopping epoch 11 for trial 23. Moving to next fold.
Fold 2 validation loss: 0.0550
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2958168959617615
[Epoch 1, Batch 200] loss: 2.2611680889129637
[Epoch 1, Batch 300] loss: 2.127840543985367
[Epoch 1, Batch 400] loss: 1.3135014098882676
[Epoch 1, Batch 500] loss: 0.6481094512343407
[Epoch 1, Batch 600] loss: 0.5060039414465427
[Epoch 1, Batch 700] loss: 0.4450698818266392
[Epoch 1, Batch 800] loss: 0.4240797473490238
[Epoch 1, Batch 900] loss: 0.37556255474686623
[Epoch 1, Batch 1000] loss: 0.3221122761815786
[Epoch 1, Batch 1100] loss: 0.30627296086400746
[Epoch 1, Batch 1200] loss: 0.2798757130652666
[Epoch 1, Batch 1300] loss: 0.26609900753945115
[Epoch 1, Batch 1400] loss: 0.2502678334712982
[Epoch 1, Batch 1500] loss: 0.2447271502763033
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2364
Validation Accuracy: 0.9276
Overfitting: 0.2364
[Epoch 2, Batch 100] loss: 0.212048867251724
[Epoch 2, Batch 200] loss: 0.19986737731844187
[Epoch 2, Batch 300] loss: 0.18589744485914708
[Epoch 2, Batch 400] loss: 0.16658896170556545
[Epoch 2, Batch 500] loss: 0.1635827480815351
[Epoch 2, Batch 600] loss: 0.16943006157875062
[Epoch 2, Batch 700] loss: 0.17842901077121495
[Epoch 2, Batch 800] loss: 0.17057378364726902
[Epoch 2, Batch 900] loss: 0.16333804635331034
[Epoch 2, Batch 1000] loss: 0.1500604347139597
[Epoch 2, Batch 1100] loss: 0.14252576699480415
[Epoch 2, Batch 1200] loss: 0.14219068038277327
[Epoch 2, Batch 1300] loss: 0.10810591183602809
[Epoch 2, Batch 1400] loss: 0.15419130767695605
[Epoch 2, Batch 1500] loss: 0.11958888345398008
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1357
Validation Accuracy: 0.9590
Overfitting: 0.1357
[Epoch 3, Batch 100] loss: 0.12463539764285088
[Epoch 3, Batch 200] loss: 0.13456704953685403
[Epoch 3, Batch 300] loss: 0.12675416535697878
[Epoch 3, Batch 400] loss: 0.10939627003856003
[Epoch 3, Batch 500] loss: 0.1023821571143344
[Epoch 3, Batch 600] loss: 0.11451177939772605
[Epoch 3, Batch 700] loss: 0.09637885388918221
[Epoch 3, Batch 800] loss: 0.1096248035505414
[Epoch 3, Batch 900] loss: 0.1018038181355223
[Epoch 3, Batch 1000] loss: 0.092436968118418
[Epoch 3, Batch 1100] loss: 0.09399905004538596
[Epoch 3, Batch 1200] loss: 0.11176434718072414
[Epoch 3, Batch 1300] loss: 0.0960639961110428
[Epoch 3, Batch 1400] loss: 0.07769114251248538
[Epoch 3, Batch 1500] loss: 0.08708514714613556
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0993
Validation Accuracy: 0.9690
Overfitting: 0.0993
[Epoch 4, Batch 100] loss: 0.08959021092392504
[Epoch 4, Batch 200] loss: 0.0960273040784523
[Epoch 4, Batch 300] loss: 0.08568481855560094
[Epoch 4, Batch 400] loss: 0.08063051661476493
[Epoch 4, Batch 500] loss: 0.08507028208114206
[Epoch 4, Batch 600] loss: 0.061489982842467726
[Epoch 4, Batch 700] loss: 0.0844570647040382
[Epoch 4, Batch 800] loss: 0.074221450118348
[Epoch 4, Batch 900] loss: 0.08555109439883381
[Epoch 4, Batch 1000] loss: 0.07804579128045588
[Epoch 4, Batch 1100] loss: 0.07980675919447094
[Epoch 4, Batch 1200] loss: 0.07682919595390558
[Epoch 4, Batch 1300] loss: 0.07666821139864624
[Epoch 4, Batch 1400] loss: 0.07520264501916245
[Epoch 4, Batch 1500] loss: 0.08556774924043566
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0807
Validation Accuracy: 0.9758
Overfitting: 0.0807
[Epoch 5, Batch 100] loss: 0.0604567434755154
[Epoch 5, Batch 200] loss: 0.06131516183260828
[Epoch 5, Batch 300] loss: 0.059917406062595546
[Epoch 5, Batch 400] loss: 0.06568682155804709
[Epoch 5, Batch 500] loss: 0.06753572042565793
[Epoch 5, Batch 600] loss: 0.06703930423595011
[Epoch 5, Batch 700] loss: 0.06355763937113806
[Epoch 5, Batch 800] loss: 0.05856972636654973
[Epoch 5, Batch 900] loss: 0.06983016698621214
[Epoch 5, Batch 1000] loss: 0.06898874380625784
[Epoch 5, Batch 1100] loss: 0.06690938969142735
[Epoch 5, Batch 1200] loss: 0.06967920408584177
[Epoch 5, Batch 1300] loss: 0.06988382989773527
[Epoch 5, Batch 1400] loss: 0.0680390323814936
[Epoch 5, Batch 1500] loss: 0.05744248125120066
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0689
Validation Accuracy: 0.9804
Overfitting: 0.0689
[Epoch 6, Batch 100] loss: 0.07238327440107241
[Epoch 6, Batch 200] loss: 0.057146929972805086
[Epoch 6, Batch 300] loss: 0.050363563298014925
[Epoch 6, Batch 400] loss: 0.05510269645601511
[Epoch 6, Batch 500] loss: 0.047170505245449024
[Epoch 6, Batch 600] loss: 0.05094915040535852
[Epoch 6, Batch 700] loss: 0.05612414727685973
[Epoch 6, Batch 800] loss: 0.05819719907362014
[Epoch 6, Batch 900] loss: 0.05881595350569114
[Epoch 6, Batch 1000] loss: 0.054958808205556126
[Epoch 6, Batch 1100] loss: 0.05238600211800076
[Epoch 6, Batch 1200] loss: 0.04502193490392528
[Epoch 6, Batch 1300] loss: 0.05388296141289175
[Epoch 6, Batch 1400] loss: 0.050930981168639845
[Epoch 6, Batch 1500] loss: 0.05307853602222167
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9816
Overfitting: 0.0608
[Epoch 7, Batch 100] loss: 0.05157948295585811
[Epoch 7, Batch 200] loss: 0.06698418387386482
[Epoch 7, Batch 300] loss: 0.04157661336008459
[Epoch 7, Batch 400] loss: 0.04636346163693816
[Epoch 7, Batch 500] loss: 0.04371092011919245
[Epoch 7, Batch 600] loss: 0.044282962003489953
[Epoch 7, Batch 700] loss: 0.049413609254406764
[Epoch 7, Batch 800] loss: 0.05697409207234159
[Epoch 7, Batch 900] loss: 0.051733421058161186
[Epoch 7, Batch 1000] loss: 0.04529527215869166
[Epoch 7, Batch 1100] loss: 0.05127997941744979
[Epoch 7, Batch 1200] loss: 0.03860972444876097
[Epoch 7, Batch 1300] loss: 0.043105656604748216
[Epoch 7, Batch 1400] loss: 0.042171466608997434
[Epoch 7, Batch 1500] loss: 0.04835203386726789
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0598
Validation Accuracy: 0.9822
Overfitting: 0.0598
[Epoch 8, Batch 100] loss: 0.03906681654334534
[Epoch 8, Batch 200] loss: 0.046492052063113076
[Epoch 8, Batch 300] loss: 0.03511995661421679
[Epoch 8, Batch 400] loss: 0.04292516277637333
[Epoch 8, Batch 500] loss: 0.037365127581288106
[Epoch 8, Batch 600] loss: 0.03601571941922885
[Epoch 8, Batch 700] loss: 0.03510668583563529
[Epoch 8, Batch 800] loss: 0.041815811538835984
[Epoch 8, Batch 900] loss: 0.044964856808946935
[Epoch 8, Batch 1000] loss: 0.04537644060794264
[Epoch 8, Batch 1100] loss: 0.043468408258340786
[Epoch 8, Batch 1200] loss: 0.0424221678666072
[Epoch 8, Batch 1300] loss: 0.04482321054150816
[Epoch 8, Batch 1400] loss: 0.04247621891088784
[Epoch 8, Batch 1500] loss: 0.054153001981321724
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0536
Validation Accuracy: 0.9848
Overfitting: 0.0536
[Epoch 9, Batch 100] loss: 0.03339571567135863
[Epoch 9, Batch 200] loss: 0.044466512800427155
[Epoch 9, Batch 300] loss: 0.03197497167624533
[Epoch 9, Batch 400] loss: 0.04885803255951032
[Epoch 9, Batch 500] loss: 0.04004875528626144
[Epoch 9, Batch 600] loss: 0.03241581783164293
[Epoch 9, Batch 700] loss: 0.0446877343102824
[Epoch 9, Batch 800] loss: 0.03308153557823971
[Epoch 9, Batch 900] loss: 0.05237145947030512
[Epoch 9, Batch 1000] loss: 0.03838251725421287
[Epoch 9, Batch 1100] loss: 0.0296216007968178
[Epoch 9, Batch 1200] loss: 0.02909030641661957
[Epoch 9, Batch 1300] loss: 0.027040544854535255
[Epoch 9, Batch 1400] loss: 0.04393461127270712
[Epoch 9, Batch 1500] loss: 0.03685858342796564
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0512
Validation Accuracy: 0.9851
Overfitting: 0.0512
Best model saved at epoch 9 with validation loss: 0.0512
[Epoch 10, Batch 100] loss: 0.031409442935255355
[Epoch 10, Batch 200] loss: 0.03237857919477392
[Epoch 10, Batch 300] loss: 0.03175002887233859
[Epoch 10, Batch 400] loss: 0.02987739083444467
[Epoch 10, Batch 500] loss: 0.03281156548880972
[Epoch 10, Batch 600] loss: 0.028956247861497104
[Epoch 10, Batch 700] loss: 0.029792979697231204
[Epoch 10, Batch 800] loss: 0.04711526960512856
[Epoch 10, Batch 900] loss: 0.033465054129483175
[Epoch 10, Batch 1000] loss: 0.03191687407437712
[Epoch 10, Batch 1100] loss: 0.03535831778659485
[Epoch 10, Batch 1200] loss: 0.03468275908380747
[Epoch 10, Batch 1300] loss: 0.03122276301102829
[Epoch 10, Batch 1400] loss: 0.03992153526312905
[Epoch 10, Batch 1500] loss: 0.03072935682022944
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0481
Validation Accuracy: 0.9865
Overfitting: 0.0481
[Epoch 11, Batch 100] loss: 0.02920580122503452
[Epoch 11, Batch 200] loss: 0.028580539281247184
[Epoch 11, Batch 300] loss: 0.03441412911866792
[Epoch 11, Batch 400] loss: 0.022565033313585444
[Epoch 11, Batch 500] loss: 0.027639322266622912
[Epoch 11, Batch 600] loss: 0.024374517038231715
[Epoch 11, Batch 700] loss: 0.029456352917768526
[Epoch 11, Batch 800] loss: 0.03301368530897889
[Epoch 11, Batch 900] loss: 0.022501538196520413
[Epoch 11, Batch 1000] loss: 0.030778438071574783
[Epoch 11, Batch 1100] loss: 0.026054399789427408
[Epoch 11, Batch 1200] loss: 0.03751375675026793
[Epoch 11, Batch 1300] loss: 0.023526200367778072
[Epoch 11, Batch 1400] loss: 0.032923687497968784
[Epoch 11, Batch 1500] loss: 0.030719486685411537
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0497
Validation Accuracy: 0.9850
Overfitting: 0.0497
Early stopping epoch 11 for trial 23. Moving to next fold.
Fold 3 validation loss: 0.0497
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2968367767333984
[Epoch 1, Batch 200] loss: 2.259237871170044
[Epoch 1, Batch 300] loss: 2.147159526348114
[Epoch 1, Batch 400] loss: 1.4995026713609696
[Epoch 1, Batch 500] loss: 0.6191415286064148
[Epoch 1, Batch 600] loss: 0.468994622528553
[Epoch 1, Batch 700] loss: 0.38513211891055105
[Epoch 1, Batch 800] loss: 0.3424508219957352
[Epoch 1, Batch 900] loss: 0.3051836397498846
[Epoch 1, Batch 1000] loss: 0.2940032249316573
[Epoch 1, Batch 1100] loss: 0.28858103320002554
[Epoch 1, Batch 1200] loss: 0.23681879237294198
[Epoch 1, Batch 1300] loss: 0.23330588966608048
[Epoch 1, Batch 1400] loss: 0.2364337358996272
[Epoch 1, Batch 1500] loss: 0.20340905632823705
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1806
Validation Accuracy: 0.9451
Overfitting: 0.1806
[Epoch 2, Batch 100] loss: 0.17934666462242604
[Epoch 2, Batch 200] loss: 0.1641725352220237
[Epoch 2, Batch 300] loss: 0.16678242716938257
[Epoch 2, Batch 400] loss: 0.1555233344435692
[Epoch 2, Batch 500] loss: 0.134271028470248
[Epoch 2, Batch 600] loss: 0.12974279296584426
[Epoch 2, Batch 700] loss: 0.12388306869193912
[Epoch 2, Batch 800] loss: 0.14364943476393818
[Epoch 2, Batch 900] loss: 0.1356480770278722
[Epoch 2, Batch 1000] loss: 0.125569239333272
[Epoch 2, Batch 1100] loss: 0.1173641799390316
[Epoch 2, Batch 1200] loss: 0.11929225494153797
[Epoch 2, Batch 1300] loss: 0.14453797419555486
[Epoch 2, Batch 1400] loss: 0.0996605330426246
[Epoch 2, Batch 1500] loss: 0.1178001113794744
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1020
Validation Accuracy: 0.9689
Overfitting: 0.1020
[Epoch 3, Batch 100] loss: 0.0925987372873351
[Epoch 3, Batch 200] loss: 0.10118945792317391
[Epoch 3, Batch 300] loss: 0.09284990520682186
[Epoch 3, Batch 400] loss: 0.09666189455427229
[Epoch 3, Batch 500] loss: 0.09302181573584675
[Epoch 3, Batch 600] loss: 0.09052116505801677
[Epoch 3, Batch 700] loss: 0.07433786305133254
[Epoch 3, Batch 800] loss: 0.08272520463215187
[Epoch 3, Batch 900] loss: 0.0756158934161067
[Epoch 3, Batch 1000] loss: 0.10338228608947247
[Epoch 3, Batch 1100] loss: 0.09443280653096736
[Epoch 3, Batch 1200] loss: 0.090734431296587
[Epoch 3, Batch 1300] loss: 0.07694946917705238
[Epoch 3, Batch 1400] loss: 0.060055376421660187
[Epoch 3, Batch 1500] loss: 0.08020761322695762
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0819
Validation Accuracy: 0.9737
Overfitting: 0.0819
[Epoch 4, Batch 100] loss: 0.07083203111542388
[Epoch 4, Batch 200] loss: 0.06437831963179633
[Epoch 4, Batch 300] loss: 0.07403937128838152
[Epoch 4, Batch 400] loss: 0.0766217176662758
[Epoch 4, Batch 500] loss: 0.07190839907620102
[Epoch 4, Batch 600] loss: 0.06244053031085059
[Epoch 4, Batch 700] loss: 0.06532807875424623
[Epoch 4, Batch 800] loss: 0.06446007362101228
[Epoch 4, Batch 900] loss: 0.06571876594796777
[Epoch 4, Batch 1000] loss: 0.06674227960873395
[Epoch 4, Batch 1100] loss: 0.07273405663203449
[Epoch 4, Batch 1200] loss: 0.061017628735862674
[Epoch 4, Batch 1300] loss: 0.07694338937057182
[Epoch 4, Batch 1400] loss: 0.06552407362498343
[Epoch 4, Batch 1500] loss: 0.06628164311870932
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0599
Validation Accuracy: 0.9813
Overfitting: 0.0599
[Epoch 5, Batch 100] loss: 0.049360244593117386
[Epoch 5, Batch 200] loss: 0.05562140530673787
[Epoch 5, Batch 300] loss: 0.04607760876766406
[Epoch 5, Batch 400] loss: 0.05211276903515682
[Epoch 5, Batch 500] loss: 0.07622054124018178
[Epoch 5, Batch 600] loss: 0.05822243839967996
[Epoch 5, Batch 700] loss: 0.03995691717136651
[Epoch 5, Batch 800] loss: 0.05494009165558964
[Epoch 5, Batch 900] loss: 0.05985714402748272
[Epoch 5, Batch 1000] loss: 0.06607737952610478
[Epoch 5, Batch 1100] loss: 0.06864385279244743
[Epoch 5, Batch 1200] loss: 0.06554876789450645
[Epoch 5, Batch 1300] loss: 0.06308938100119121
[Epoch 5, Batch 1400] loss: 0.042209299630485475
[Epoch 5, Batch 1500] loss: 0.053194178713019936
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0584
Validation Accuracy: 0.9809
Overfitting: 0.0584
[Epoch 6, Batch 100] loss: 0.04728767102817073
[Epoch 6, Batch 200] loss: 0.04696905043558217
[Epoch 6, Batch 300] loss: 0.041136867876630276
[Epoch 6, Batch 400] loss: 0.04047781719011254
[Epoch 6, Batch 500] loss: 0.04430926170200109
[Epoch 6, Batch 600] loss: 0.048421936180675404
[Epoch 6, Batch 700] loss: 0.04732380531262606
[Epoch 6, Batch 800] loss: 0.05234996612300165
[Epoch 6, Batch 900] loss: 0.053750491549726574
[Epoch 6, Batch 1000] loss: 0.04337246970972046
[Epoch 6, Batch 1100] loss: 0.041871287245303396
[Epoch 6, Batch 1200] loss: 0.06026990831247531
[Epoch 6, Batch 1300] loss: 0.05105094220256433
[Epoch 6, Batch 1400] loss: 0.0330973699549213
[Epoch 6, Batch 1500] loss: 0.052641619159840045
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0483
Validation Accuracy: 0.9854
Overfitting: 0.0483
[Epoch 7, Batch 100] loss: 0.040921075966907666
[Epoch 7, Batch 200] loss: 0.04963266005623154
[Epoch 7, Batch 300] loss: 0.03550143793108873
[Epoch 7, Batch 400] loss: 0.044530291815754026
[Epoch 7, Batch 500] loss: 0.045134086589096116
[Epoch 7, Batch 600] loss: 0.04052847856655717
[Epoch 7, Batch 700] loss: 0.0406417429324938
[Epoch 7, Batch 800] loss: 0.03801246197079308
[Epoch 7, Batch 900] loss: 0.04230092662444804
[Epoch 7, Batch 1000] loss: 0.04017555489292136
[Epoch 7, Batch 1100] loss: 0.038771815999643876
[Epoch 7, Batch 1200] loss: 0.04051724371383898
[Epoch 7, Batch 1300] loss: 0.038184017392923125
[Epoch 7, Batch 1400] loss: 0.05137091067561414
[Epoch 7, Batch 1500] loss: 0.0433174086548388
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0463
Validation Accuracy: 0.9854
Overfitting: 0.0463
[Epoch 8, Batch 100] loss: 0.03468964799802052
[Epoch 8, Batch 200] loss: 0.033815118662314486
[Epoch 8, Batch 300] loss: 0.04217787330853753
[Epoch 8, Batch 400] loss: 0.03987903021043167
[Epoch 8, Batch 500] loss: 0.03776272548246198
[Epoch 8, Batch 600] loss: 0.03672341176425107
[Epoch 8, Batch 700] loss: 0.04059872756537516
[Epoch 8, Batch 800] loss: 0.036344416964566334
[Epoch 8, Batch 900] loss: 0.03304775374359451
[Epoch 8, Batch 1000] loss: 0.042114270398160444
[Epoch 8, Batch 1100] loss: 0.03795109304774087
[Epoch 8, Batch 1200] loss: 0.04156222833204083
[Epoch 8, Batch 1300] loss: 0.037856977145420384
[Epoch 8, Batch 1400] loss: 0.033841179492883386
[Epoch 8, Batch 1500] loss: 0.03589077529031783
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9837
Overfitting: 0.0491
[Epoch 9, Batch 100] loss: 0.03446541572920978
[Epoch 9, Batch 200] loss: 0.02429924983123783
[Epoch 9, Batch 300] loss: 0.02903340121265501
[Epoch 9, Batch 400] loss: 0.04028432615683414
[Epoch 9, Batch 500] loss: 0.03135652975877747
[Epoch 9, Batch 600] loss: 0.030381433740258215
[Epoch 9, Batch 700] loss: 0.03269963934464613
[Epoch 9, Batch 800] loss: 0.028069965536124074
[Epoch 9, Batch 900] loss: 0.03306450008123647
[Epoch 9, Batch 1000] loss: 0.03083453361876309
[Epoch 9, Batch 1100] loss: 0.035362589636351915
[Epoch 9, Batch 1200] loss: 0.034165515753265936
[Epoch 9, Batch 1300] loss: 0.03229913831812155
[Epoch 9, Batch 1400] loss: 0.03502524321374949
[Epoch 9, Batch 1500] loss: 0.037414458143757656
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0491
Validation Accuracy: 0.9839
Overfitting: 0.0491
Best model saved at epoch 9 with validation loss: 0.0491
[Epoch 10, Batch 100] loss: 0.029333679627161473
[Epoch 10, Batch 200] loss: 0.03023354417120572
[Epoch 10, Batch 300] loss: 0.0244650872371858
[Epoch 10, Batch 400] loss: 0.030214012771029957
[Epoch 10, Batch 500] loss: 0.028181044886587188
[Epoch 10, Batch 600] loss: 0.026599321128451266
[Epoch 10, Batch 700] loss: 0.020839750614832155
[Epoch 10, Batch 800] loss: 0.027485869979136622
[Epoch 10, Batch 900] loss: 0.024974304633797146
[Epoch 10, Batch 1000] loss: 0.040009835307719184
[Epoch 10, Batch 1100] loss: 0.03372384428337682
[Epoch 10, Batch 1200] loss: 0.034448398393869865
[Epoch 10, Batch 1300] loss: 0.034843594091944395
[Epoch 10, Batch 1400] loss: 0.029182047453941776
[Epoch 10, Batch 1500] loss: 0.030064188036194536
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0410
Validation Accuracy: 0.9871
Overfitting: 0.0410
[Epoch 11, Batch 100] loss: 0.025659979506162927
[Epoch 11, Batch 200] loss: 0.022573422489804217
[Epoch 11, Batch 300] loss: 0.02605385796749033
[Epoch 11, Batch 400] loss: 0.028567404190980597
[Epoch 11, Batch 500] loss: 0.028937239266233518
[Epoch 11, Batch 600] loss: 0.02080120516315219
[Epoch 11, Batch 700] loss: 0.02886706507386407
[Epoch 11, Batch 800] loss: 0.02642146264668554
[Epoch 11, Batch 900] loss: 0.027625307634298223
[Epoch 11, Batch 1000] loss: 0.024824909002054484
[Epoch 11, Batch 1100] loss: 0.028255900677468162
[Epoch 11, Batch 1200] loss: 0.02625155117828399
[Epoch 11, Batch 1300] loss: 0.03036655537900515
[Epoch 11, Batch 1400] loss: 0.028830770360073074
[Epoch 11, Batch 1500] loss: 0.037378256105585025
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0430
Validation Accuracy: 0.9857
Overfitting: 0.0430
Early stopping epoch 11 for trial 23. Moving to next fold.
Fold 4 validation loss: 0.0430
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2889694571495056
[Epoch 1, Batch 200] loss: 2.236062777042389
[Epoch 1, Batch 300] loss: 1.9492128133773803
[Epoch 1, Batch 400] loss: 0.9288535249233246
[Epoch 1, Batch 500] loss: 0.5453943228721618
[Epoch 1, Batch 600] loss: 0.42794406980276106
[Epoch 1, Batch 700] loss: 0.38540405839681624
[Epoch 1, Batch 800] loss: 0.3227703620493412
[Epoch 1, Batch 900] loss: 0.2815814510732889
[Epoch 1, Batch 1000] loss: 0.29100111316889526
[Epoch 1, Batch 1100] loss: 0.2522619389370084
[Epoch 1, Batch 1200] loss: 0.22088524386286734
[Epoch 1, Batch 1300] loss: 0.20291471853852272
[Epoch 1, Batch 1400] loss: 0.19242794532328844
[Epoch 1, Batch 1500] loss: 0.2129368595033884
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1855
Validation Accuracy: 0.9441
Overfitting: 0.1855
[Epoch 2, Batch 100] loss: 0.17759051298722625
[Epoch 2, Batch 200] loss: 0.14766575099900364
[Epoch 2, Batch 300] loss: 0.17007456723600625
[Epoch 2, Batch 400] loss: 0.14596619993448257
[Epoch 2, Batch 500] loss: 0.15453424479812383
[Epoch 2, Batch 600] loss: 0.14013219637796281
[Epoch 2, Batch 700] loss: 0.11707099284976721
[Epoch 2, Batch 800] loss: 0.13063787396997215
[Epoch 2, Batch 900] loss: 0.13762513758614658
[Epoch 2, Batch 1000] loss: 0.12674340570345521
[Epoch 2, Batch 1100] loss: 0.12549470060504972
[Epoch 2, Batch 1200] loss: 0.1024560218024999
[Epoch 2, Batch 1300] loss: 0.1152859078720212
[Epoch 2, Batch 1400] loss: 0.10049083797261119
[Epoch 2, Batch 1500] loss: 0.10749436307698489
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1058
Validation Accuracy: 0.9676
Overfitting: 0.1058
[Epoch 3, Batch 100] loss: 0.09773134903982282
[Epoch 3, Batch 200] loss: 0.1074546701926738
[Epoch 3, Batch 300] loss: 0.0804021841287613
[Epoch 3, Batch 400] loss: 0.10740706098964438
[Epoch 3, Batch 500] loss: 0.1091138513525948
[Epoch 3, Batch 600] loss: 0.09373465244658291
[Epoch 3, Batch 700] loss: 0.07378180242842064
[Epoch 3, Batch 800] loss: 0.10296445940155535
[Epoch 3, Batch 900] loss: 0.07956740723922849
[Epoch 3, Batch 1000] loss: 0.08025766465812921
[Epoch 3, Batch 1100] loss: 0.09511614383663983
[Epoch 3, Batch 1200] loss: 0.09007634163368493
[Epoch 3, Batch 1300] loss: 0.09013001705519855
[Epoch 3, Batch 1400] loss: 0.06665081528015435
[Epoch 3, Batch 1500] loss: 0.07486430084798484
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0864
Validation Accuracy: 0.9748
Overfitting: 0.0864
[Epoch 4, Batch 100] loss: 0.06779863535659388
[Epoch 4, Batch 200] loss: 0.05658390875905752
[Epoch 4, Batch 300] loss: 0.09698902374133468
[Epoch 4, Batch 400] loss: 0.06956264790147543
[Epoch 4, Batch 500] loss: 0.06522245505359024
[Epoch 4, Batch 600] loss: 0.052559466334059834
[Epoch 4, Batch 700] loss: 0.07601463109720498
[Epoch 4, Batch 800] loss: 0.07194715771591291
[Epoch 4, Batch 900] loss: 0.07992456439416856
[Epoch 4, Batch 1000] loss: 0.08414943884592503
[Epoch 4, Batch 1100] loss: 0.06628444666508586
[Epoch 4, Batch 1200] loss: 0.07644542670343071
[Epoch 4, Batch 1300] loss: 0.061532163639785725
[Epoch 4, Batch 1400] loss: 0.06642591815441846
[Epoch 4, Batch 1500] loss: 0.08044882559799589
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0791
Validation Accuracy: 0.9757
Overfitting: 0.0791
[Epoch 5, Batch 100] loss: 0.055405228552408516
[Epoch 5, Batch 200] loss: 0.06182583787944168
[Epoch 5, Batch 300] loss: 0.06017379838973284
[Epoch 5, Batch 400] loss: 0.06779319776454941
[Epoch 5, Batch 500] loss: 0.06617203248664737
[Epoch 5, Batch 600] loss: 0.06692745809676126
[Epoch 5, Batch 700] loss: 0.06282991365878843
[Epoch 5, Batch 800] loss: 0.062354910026770086
[Epoch 5, Batch 900] loss: 0.06117759058950469
[Epoch 5, Batch 1000] loss: 0.049687780840322375
[Epoch 5, Batch 1100] loss: 0.06185459938831627
[Epoch 5, Batch 1200] loss: 0.04850615199422464
[Epoch 5, Batch 1300] loss: 0.04945366124273278
[Epoch 5, Batch 1400] loss: 0.0639296683750581
[Epoch 5, Batch 1500] loss: 0.07359256177209318
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0722
Validation Accuracy: 0.9766
Overfitting: 0.0722
[Epoch 6, Batch 100] loss: 0.04332174964947626
[Epoch 6, Batch 200] loss: 0.047688039365457374
[Epoch 6, Batch 300] loss: 0.04235658137360588
[Epoch 6, Batch 400] loss: 0.05286074386909604
[Epoch 6, Batch 500] loss: 0.05346942250966094
[Epoch 6, Batch 600] loss: 0.05084448620211333
[Epoch 6, Batch 700] loss: 0.06165762591874227
[Epoch 6, Batch 800] loss: 0.03662465975852683
[Epoch 6, Batch 900] loss: 0.05918463859357871
[Epoch 6, Batch 1000] loss: 0.05294293810380623
[Epoch 6, Batch 1100] loss: 0.06211778056225739
[Epoch 6, Batch 1200] loss: 0.04570709299587179
[Epoch 6, Batch 1300] loss: 0.04658794566639699
[Epoch 6, Batch 1400] loss: 0.06669598850246984
[Epoch 6, Batch 1500] loss: 0.04692252485896461
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0561
Validation Accuracy: 0.9816
Overfitting: 0.0561
[Epoch 7, Batch 100] loss: 0.0466974768450018
[Epoch 7, Batch 200] loss: 0.04140989558887668
[Epoch 7, Batch 300] loss: 0.04828132093010936
[Epoch 7, Batch 400] loss: 0.038299544058390894
[Epoch 7, Batch 500] loss: 0.0373752083897125
[Epoch 7, Batch 600] loss: 0.03229087158921175
[Epoch 7, Batch 700] loss: 0.04984172027208842
[Epoch 7, Batch 800] loss: 0.0398702016135212
[Epoch 7, Batch 900] loss: 0.04374994133599103
[Epoch 7, Batch 1000] loss: 0.036868335204781034
[Epoch 7, Batch 1100] loss: 0.04580988651345251
[Epoch 7, Batch 1200] loss: 0.04544398080557585
[Epoch 7, Batch 1300] loss: 0.05781559425406158
[Epoch 7, Batch 1400] loss: 0.05668835095362738
[Epoch 7, Batch 1500] loss: 0.0524834720484796
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0544
Validation Accuracy: 0.9827
Overfitting: 0.0544
[Epoch 8, Batch 100] loss: 0.033876319433329624
[Epoch 8, Batch 200] loss: 0.03799330888665281
[Epoch 8, Batch 300] loss: 0.04157545103545999
[Epoch 8, Batch 400] loss: 0.03553287396556698
[Epoch 8, Batch 500] loss: 0.0354351815499831
[Epoch 8, Batch 600] loss: 0.04015282211941667
[Epoch 8, Batch 700] loss: 0.03970359576342162
[Epoch 8, Batch 800] loss: 0.043301951121538874
[Epoch 8, Batch 900] loss: 0.04568225744646043
[Epoch 8, Batch 1000] loss: 0.04461707607260905
[Epoch 8, Batch 1100] loss: 0.0388556561578298
[Epoch 8, Batch 1200] loss: 0.04373280029685702
[Epoch 8, Batch 1300] loss: 0.04446974805672653
[Epoch 8, Batch 1400] loss: 0.0334798891301034
[Epoch 8, Batch 1500] loss: 0.0377024833066389
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0549
Validation Accuracy: 0.9824
Overfitting: 0.0549
[Epoch 9, Batch 100] loss: 0.037481832112534905
[Epoch 9, Batch 200] loss: 0.027698640690068714
[Epoch 9, Batch 300] loss: 0.04161761317343917
[Epoch 9, Batch 400] loss: 0.0409556659986265
[Epoch 9, Batch 500] loss: 0.038654223306803036
[Epoch 9, Batch 600] loss: 0.03457104216562584
[Epoch 9, Batch 700] loss: 0.02522290336317383
[Epoch 9, Batch 800] loss: 0.04142513482482173
[Epoch 9, Batch 900] loss: 0.0404929577227449
[Epoch 9, Batch 1000] loss: 0.033522720624459906
[Epoch 9, Batch 1100] loss: 0.037318732936983
[Epoch 9, Batch 1200] loss: 0.03532774243853055
[Epoch 9, Batch 1300] loss: 0.0439413595222868
[Epoch 9, Batch 1400] loss: 0.026087055403040724
[Epoch 9, Batch 1500] loss: 0.032992451697937214
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0539
Validation Accuracy: 0.9839
Overfitting: 0.0539
Best model saved at epoch 9 with validation loss: 0.0539
[Epoch 10, Batch 100] loss: 0.030777484067948536
[Epoch 10, Batch 200] loss: 0.023614896022481843
[Epoch 10, Batch 300] loss: 0.03045672188512981
[Epoch 10, Batch 400] loss: 0.03488172557612415
[Epoch 10, Batch 500] loss: 0.03785857175447745
[Epoch 10, Batch 600] loss: 0.027581868959241546
[Epoch 10, Batch 700] loss: 0.024087078434531575
[Epoch 10, Batch 800] loss: 0.03488388721365482
[Epoch 10, Batch 900] loss: 0.046129286909126675
[Epoch 10, Batch 1000] loss: 0.024826474030851385
[Epoch 10, Batch 1100] loss: 0.030164684900664724
[Epoch 10, Batch 1200] loss: 0.03848554366384633
[Epoch 10, Batch 1300] loss: 0.03294954099314054
[Epoch 10, Batch 1400] loss: 0.036540865530259904
[Epoch 10, Batch 1500] loss: 0.03502648816778674
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0504
Validation Accuracy: 0.9841
Overfitting: 0.0504
[Epoch 11, Batch 100] loss: 0.02845411581627559
[Epoch 11, Batch 200] loss: 0.021319344532676043
[Epoch 11, Batch 300] loss: 0.034397290668275675
[Epoch 11, Batch 400] loss: 0.027099342074070592
[Epoch 11, Batch 500] loss: 0.028189978134760166
[Epoch 11, Batch 600] loss: 0.029406115325982682
[Epoch 11, Batch 700] loss: 0.030529440672835334
[Epoch 11, Batch 800] loss: 0.038132879027980376
[Epoch 11, Batch 900] loss: 0.02783763865416404
[Epoch 11, Batch 1000] loss: 0.033012452389375536
[Epoch 11, Batch 1100] loss: 0.02964802605827572
[Epoch 11, Batch 1200] loss: 0.024813088224909734
[Epoch 11, Batch 1300] loss: 0.026678056764649228
[Epoch 11, Batch 1400] loss: 0.03544348955765599
[Epoch 11, Batch 1500] loss: 0.02883782177232206
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0486
Validation Accuracy: 0.9851
Overfitting: 0.0486
Early stopping epoch 11 for trial 23. Moving to next fold.
Fold 5 validation loss: 0.0486
Mean validation loss across all folds for Trial 23 is 0.0495 with trial config:  l1: 256, l2: 128, lr: 0.001, batch_size: 32
[I 2024-12-10 07:52:36,009] Trial 22 finished with value: 0.049495910143665965 and parameters: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 32}. Best is trial 21 with value: 0.04811396317985685.

Selected Hyperparameters for Trial 24:
  l1: 128, l2: 64, lr: 0.001, batch_size: 32
Training set size: 60000
Fold 1/5
Inner Training set size for fold 1 is 48000
 Inner Validation set size for fold 1 is 12000
[Epoch 1, Batch 100] loss: 2.2908179211616515
[Epoch 1, Batch 200] loss: 2.2432575368881227
[Epoch 1, Batch 300] loss: 2.0214721930027006
[Epoch 1, Batch 400] loss: 1.0426785531640053
[Epoch 1, Batch 500] loss: 0.5327541223168373
[Epoch 1, Batch 600] loss: 0.4074261360615492
[Epoch 1, Batch 700] loss: 0.353053075671196
[Epoch 1, Batch 800] loss: 0.3252622966468334
[Epoch 1, Batch 900] loss: 0.28377799697220324
[Epoch 1, Batch 1000] loss: 0.2690793378278613
[Epoch 1, Batch 1100] loss: 0.2538204522430897
[Epoch 1, Batch 1200] loss: 0.2362013640254736
[Epoch 1, Batch 1300] loss: 0.1920736051723361
[Epoch 1, Batch 1400] loss: 0.18224848732352256
[Epoch 1, Batch 1500] loss: 0.2020634087920189
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1691
Validation Accuracy: 0.9477
Overfitting: 0.1691
[Epoch 2, Batch 100] loss: 0.17809272130951284
[Epoch 2, Batch 200] loss: 0.1812239739112556
[Epoch 2, Batch 300] loss: 0.17205307675525547
[Epoch 2, Batch 400] loss: 0.1715412977337837
[Epoch 2, Batch 500] loss: 0.15123614422045648
[Epoch 2, Batch 600] loss: 0.14449848780408503
[Epoch 2, Batch 700] loss: 0.14199699630960821
[Epoch 2, Batch 800] loss: 0.13653356803581118
[Epoch 2, Batch 900] loss: 0.14051762462593614
[Epoch 2, Batch 1000] loss: 0.12635181879624724
[Epoch 2, Batch 1100] loss: 0.1197765031736344
[Epoch 2, Batch 1200] loss: 0.12125315464101732
[Epoch 2, Batch 1300] loss: 0.13263754067942501
[Epoch 2, Batch 1400] loss: 0.11465283597819508
[Epoch 2, Batch 1500] loss: 0.11635597945190966
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1024
Validation Accuracy: 0.9672
Overfitting: 0.1024
[Epoch 3, Batch 100] loss: 0.10652852106373757
[Epoch 3, Batch 200] loss: 0.1091577163664624
[Epoch 3, Batch 300] loss: 0.10733274050056935
[Epoch 3, Batch 400] loss: 0.12102242527063936
[Epoch 3, Batch 500] loss: 0.09899425925221295
[Epoch 3, Batch 600] loss: 0.10784845459274947
[Epoch 3, Batch 700] loss: 0.11394351104740054
[Epoch 3, Batch 800] loss: 0.1114529136940837
[Epoch 3, Batch 900] loss: 0.09584102388471365
[Epoch 3, Batch 1000] loss: 0.09160646297503262
[Epoch 3, Batch 1100] loss: 0.09264659393578768
[Epoch 3, Batch 1200] loss: 0.10254720363300293
[Epoch 3, Batch 1300] loss: 0.08805050504859536
[Epoch 3, Batch 1400] loss: 0.09228003821335733
[Epoch 3, Batch 1500] loss: 0.10047036518342793
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0899
Validation Accuracy: 0.9728
Overfitting: 0.0899
[Epoch 4, Batch 100] loss: 0.09362493006512523
[Epoch 4, Batch 200] loss: 0.09502460192888976
[Epoch 4, Batch 300] loss: 0.09722955899313092
[Epoch 4, Batch 400] loss: 0.07860881156288087
[Epoch 4, Batch 500] loss: 0.07428245308343322
[Epoch 4, Batch 600] loss: 0.08806295027025043
[Epoch 4, Batch 700] loss: 0.08883572264108806
[Epoch 4, Batch 800] loss: 0.07694124258123339
[Epoch 4, Batch 900] loss: 0.08633693185634911
[Epoch 4, Batch 1000] loss: 0.07866066114045679
[Epoch 4, Batch 1100] loss: 0.08032713397406041
[Epoch 4, Batch 1200] loss: 0.06729197073262184
[Epoch 4, Batch 1300] loss: 0.07589488300378434
[Epoch 4, Batch 1400] loss: 0.07560273503651843
[Epoch 4, Batch 1500] loss: 0.08737190110376104
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0809
Validation Accuracy: 0.9743
Overfitting: 0.0809
[Epoch 5, Batch 100] loss: 0.058052346780896186
[Epoch 5, Batch 200] loss: 0.07464405476115644
[Epoch 5, Batch 300] loss: 0.07580578537425026
[Epoch 5, Batch 400] loss: 0.0707894806819968
[Epoch 5, Batch 500] loss: 0.08142679997952655
[Epoch 5, Batch 600] loss: 0.053655774970538916
[Epoch 5, Batch 700] loss: 0.08064929011277855
[Epoch 5, Batch 800] loss: 0.06889372252393514
[Epoch 5, Batch 900] loss: 0.07340101212030277
[Epoch 5, Batch 1000] loss: 0.05916774419602007
[Epoch 5, Batch 1100] loss: 0.06259805081412197
[Epoch 5, Batch 1200] loss: 0.06920406008139253
[Epoch 5, Batch 1300] loss: 0.06457358870189638
[Epoch 5, Batch 1400] loss: 0.0815166988875717
[Epoch 5, Batch 1500] loss: 0.07378342084120959
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0650
Validation Accuracy: 0.9790
Overfitting: 0.0650
[Epoch 6, Batch 100] loss: 0.056490172401536254
[Epoch 6, Batch 200] loss: 0.04874645338393748
[Epoch 6, Batch 300] loss: 0.0625872036011424
[Epoch 6, Batch 400] loss: 0.06586564731085673
[Epoch 6, Batch 500] loss: 0.06726405392633751
[Epoch 6, Batch 600] loss: 0.061421664404915643
[Epoch 6, Batch 700] loss: 0.06982115281745792
[Epoch 6, Batch 800] loss: 0.06569955166894942
[Epoch 6, Batch 900] loss: 0.0668505968817044
[Epoch 6, Batch 1000] loss: 0.057241129820467904
[Epoch 6, Batch 1100] loss: 0.06490110629703849
[Epoch 6, Batch 1200] loss: 0.061278482265770436
[Epoch 6, Batch 1300] loss: 0.050488031720742586
[Epoch 6, Batch 1400] loss: 0.061723764600465074
[Epoch 6, Batch 1500] loss: 0.0585592053970322
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0590
Validation Accuracy: 0.9824
Overfitting: 0.0590
[Epoch 7, Batch 100] loss: 0.047636427904944864
[Epoch 7, Batch 200] loss: 0.05188158388482407
[Epoch 7, Batch 300] loss: 0.051916315654525536
[Epoch 7, Batch 400] loss: 0.05073428955452983
[Epoch 7, Batch 500] loss: 0.051015030649723486
[Epoch 7, Batch 600] loss: 0.060637417589314284
[Epoch 7, Batch 700] loss: 0.051182649759575725
[Epoch 7, Batch 800] loss: 0.06598067186307162
[Epoch 7, Batch 900] loss: 0.047888645245693626
[Epoch 7, Batch 1000] loss: 0.0583696503425017
[Epoch 7, Batch 1100] loss: 0.050296873499173674
[Epoch 7, Batch 1200] loss: 0.05855144144501537
[Epoch 7, Batch 1300] loss: 0.05612012361292727
[Epoch 7, Batch 1400] loss: 0.058177330251783135
[Epoch 7, Batch 1500] loss: 0.04629526206292212
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0652
Validation Accuracy: 0.9781
Overfitting: 0.0652
[Epoch 8, Batch 100] loss: 0.0591339022340253
[Epoch 8, Batch 200] loss: 0.056308907989878206
[Epoch 8, Batch 300] loss: 0.05277897143503651
[Epoch 8, Batch 400] loss: 0.04516757238307036
[Epoch 8, Batch 500] loss: 0.03938146485364996
[Epoch 8, Batch 600] loss: 0.05157965885824524
[Epoch 8, Batch 700] loss: 0.05110785241588019
[Epoch 8, Batch 800] loss: 0.03900770773063414
[Epoch 8, Batch 900] loss: 0.045462883558357134
[Epoch 8, Batch 1000] loss: 0.05159860816318542
[Epoch 8, Batch 1100] loss: 0.04496489733806811
[Epoch 8, Batch 1200] loss: 0.04603179085766897
[Epoch 8, Batch 1300] loss: 0.04753028690000065
[Epoch 8, Batch 1400] loss: 0.046543041865807024
[Epoch 8, Batch 1500] loss: 0.057872587656020186
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0548
Validation Accuracy: 0.9817
Overfitting: 0.0548
[Epoch 9, Batch 100] loss: 0.042206417234847325
[Epoch 9, Batch 200] loss: 0.033277253919513895
[Epoch 9, Batch 300] loss: 0.042269001649692654
[Epoch 9, Batch 400] loss: 0.05006146048894152
[Epoch 9, Batch 500] loss: 0.039911418926203625
[Epoch 9, Batch 600] loss: 0.048681615500536284
[Epoch 9, Batch 700] loss: 0.04642673195514362
[Epoch 9, Batch 800] loss: 0.04977305419044569
[Epoch 9, Batch 900] loss: 0.0514303812518483
[Epoch 9, Batch 1000] loss: 0.04193194712686818
[Epoch 9, Batch 1100] loss: 0.04375976825424004
[Epoch 9, Batch 1200] loss: 0.04320473060011864
[Epoch 9, Batch 1300] loss: 0.04087709972285666
[Epoch 9, Batch 1400] loss: 0.04519262271729531
[Epoch 9, Batch 1500] loss: 0.048451849829871205
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0590
Validation Accuracy: 0.9820
Overfitting: 0.0590
Best model saved at epoch 9 with validation loss: 0.0590
[Epoch 10, Batch 100] loss: 0.04003246939217206
[Epoch 10, Batch 200] loss: 0.03233463238808326
[Epoch 10, Batch 300] loss: 0.04445157687878236
[Epoch 10, Batch 400] loss: 0.04086723776417785
[Epoch 10, Batch 500] loss: 0.043930911942152304
[Epoch 10, Batch 600] loss: 0.040008758963085714
[Epoch 10, Batch 700] loss: 0.03629635421442799
[Epoch 10, Batch 800] loss: 0.04259277061151806
[Epoch 10, Batch 900] loss: 0.06156849879946094
[Epoch 10, Batch 1000] loss: 0.03785609809681773
[Epoch 10, Batch 1100] loss: 0.03632246953435242
[Epoch 10, Batch 1200] loss: 0.04629237000946887
[Epoch 10, Batch 1300] loss: 0.03605855569941923
[Epoch 10, Batch 1400] loss: 0.0319864318909822
[Epoch 10, Batch 1500] loss: 0.03422544154571369
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0510
Validation Accuracy: 0.9837
Overfitting: 0.0510
[Epoch 11, Batch 100] loss: 0.03854740286566084
[Epoch 11, Batch 200] loss: 0.034274171721772294
[Epoch 11, Batch 300] loss: 0.025845586150535383
[Epoch 11, Batch 400] loss: 0.043376602796488445
[Epoch 11, Batch 500] loss: 0.03647973176382948
[Epoch 11, Batch 600] loss: 0.03628620581293944
[Epoch 11, Batch 700] loss: 0.041923666766961104
[Epoch 11, Batch 800] loss: 0.04226927149225958
[Epoch 11, Batch 900] loss: 0.044417643569759094
[Epoch 11, Batch 1000] loss: 0.03761365309590474
[Epoch 11, Batch 1100] loss: 0.028479549789917655
[Epoch 11, Batch 1200] loss: 0.03769719412259292
[Epoch 11, Batch 1300] loss: 0.04057934441865654
[Epoch 11, Batch 1400] loss: 0.027271181331016123
[Epoch 11, Batch 1500] loss: 0.03691446272016037
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0465
Validation Accuracy: 0.9858
Overfitting: 0.0465
Early stopping epoch 11 for trial 24. Moving to next fold.
Fold 1 validation loss: 0.0465
Fold 2/5
Inner Training set size for fold 2 is 48000
 Inner Validation set size for fold 2 is 12000
[Epoch 1, Batch 100] loss: 2.2937753891944883
[Epoch 1, Batch 200] loss: 2.260114598274231
[Epoch 1, Batch 300] loss: 2.1242705273628233
[Epoch 1, Batch 400] loss: 1.4202009862661362
[Epoch 1, Batch 500] loss: 0.6448639830946923
[Epoch 1, Batch 600] loss: 0.4887193560600281
[Epoch 1, Batch 700] loss: 0.3825993609428406
[Epoch 1, Batch 800] loss: 0.34188130669295785
[Epoch 1, Batch 900] loss: 0.31787811301648616
[Epoch 1, Batch 1000] loss: 0.29887467741966245
[Epoch 1, Batch 1100] loss: 0.27222764529287813
[Epoch 1, Batch 1200] loss: 0.24937690317630767
[Epoch 1, Batch 1300] loss: 0.19343949045985936
[Epoch 1, Batch 1400] loss: 0.21151261191815138
[Epoch 1, Batch 1500] loss: 0.2173425112850964
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2047
Validation Accuracy: 0.9397
Overfitting: 0.2047
[Epoch 2, Batch 100] loss: 0.19157766483724117
[Epoch 2, Batch 200] loss: 0.18571240140125156
[Epoch 2, Batch 300] loss: 0.1795528793334961
[Epoch 2, Batch 400] loss: 0.16531348307617008
[Epoch 2, Batch 500] loss: 0.13872176670469344
[Epoch 2, Batch 600] loss: 0.13774538394063712
[Epoch 2, Batch 700] loss: 0.12798562572337688
[Epoch 2, Batch 800] loss: 0.11834319971501828
[Epoch 2, Batch 900] loss: 0.1430381595902145
[Epoch 2, Batch 1000] loss: 0.1380736232176423
[Epoch 2, Batch 1100] loss: 0.11759012760594487
[Epoch 2, Batch 1200] loss: 0.10339622308500111
[Epoch 2, Batch 1300] loss: 0.12541261542588472
[Epoch 2, Batch 1400] loss: 0.11299633028917015
[Epoch 2, Batch 1500] loss: 0.11216019609943033
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1206
Validation Accuracy: 0.9650
Overfitting: 0.1206
[Epoch 3, Batch 100] loss: 0.08954000826925039
[Epoch 3, Batch 200] loss: 0.09669644531793892
[Epoch 3, Batch 300] loss: 0.10501232883892954
[Epoch 3, Batch 400] loss: 0.09160714549012482
[Epoch 3, Batch 500] loss: 0.1039028361113742
[Epoch 3, Batch 600] loss: 0.10429842105135322
[Epoch 3, Batch 700] loss: 0.11210115493740887
[Epoch 3, Batch 800] loss: 0.08294333781581371
[Epoch 3, Batch 900] loss: 0.0941655234573409
[Epoch 3, Batch 1000] loss: 0.09203096899203957
[Epoch 3, Batch 1100] loss: 0.09319051186554134
[Epoch 3, Batch 1200] loss: 0.08266200351994485
[Epoch 3, Batch 1300] loss: 0.08525652190903202
[Epoch 3, Batch 1400] loss: 0.07914497018558904
[Epoch 3, Batch 1500] loss: 0.09024802731815726
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0937
Validation Accuracy: 0.9730
Overfitting: 0.0937
[Epoch 4, Batch 100] loss: 0.08823618641821668
[Epoch 4, Batch 200] loss: 0.07986347286496312
[Epoch 4, Batch 300] loss: 0.0721924120048061
[Epoch 4, Batch 400] loss: 0.0886332405009307
[Epoch 4, Batch 500] loss: 0.08174308249726892
[Epoch 4, Batch 600] loss: 0.07921997100580484
[Epoch 4, Batch 700] loss: 0.0680128071596846
[Epoch 4, Batch 800] loss: 0.0715326100209495
[Epoch 4, Batch 900] loss: 0.07688107945956289
[Epoch 4, Batch 1000] loss: 0.07349583379924297
[Epoch 4, Batch 1100] loss: 0.06415765745565295
[Epoch 4, Batch 1200] loss: 0.0678469785139896
[Epoch 4, Batch 1300] loss: 0.07531677565071732
[Epoch 4, Batch 1400] loss: 0.06476365640992299
[Epoch 4, Batch 1500] loss: 0.06738264077110216
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0807
Validation Accuracy: 0.9751
Overfitting: 0.0807
[Epoch 5, Batch 100] loss: 0.05207824010634795
[Epoch 5, Batch 200] loss: 0.06037759090657346
[Epoch 5, Batch 300] loss: 0.06980750069022179
[Epoch 5, Batch 400] loss: 0.06697286327369512
[Epoch 5, Batch 500] loss: 0.05961640718393028
[Epoch 5, Batch 600] loss: 0.06454269406734965
[Epoch 5, Batch 700] loss: 0.06538786493008956
[Epoch 5, Batch 800] loss: 0.07660155239515007
[Epoch 5, Batch 900] loss: 0.05155273476266302
[Epoch 5, Batch 1000] loss: 0.06794136070413515
[Epoch 5, Batch 1100] loss: 0.04679592251544818
[Epoch 5, Batch 1200] loss: 0.056798377514351156
[Epoch 5, Batch 1300] loss: 0.06651241238578223
[Epoch 5, Batch 1400] loss: 0.07237310847034678
[Epoch 5, Batch 1500] loss: 0.0640997735154815
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0734
Validation Accuracy: 0.9792
Overfitting: 0.0734
[Epoch 6, Batch 100] loss: 0.05501079958397895
[Epoch 6, Batch 200] loss: 0.05583297266857699
[Epoch 6, Batch 300] loss: 0.05424096958711743
[Epoch 6, Batch 400] loss: 0.05222605359856971
[Epoch 6, Batch 500] loss: 0.06539275840390474
[Epoch 6, Batch 600] loss: 0.04370665495400317
[Epoch 6, Batch 700] loss: 0.055758502496173604
[Epoch 6, Batch 800] loss: 0.057668535301927476
[Epoch 6, Batch 900] loss: 0.04494462425122037
[Epoch 6, Batch 1000] loss: 0.05660211376613006
[Epoch 6, Batch 1100] loss: 0.05486322278506123
[Epoch 6, Batch 1200] loss: 0.0519338825030718
[Epoch 6, Batch 1300] loss: 0.06048297482542694
[Epoch 6, Batch 1400] loss: 0.05359775147982873
[Epoch 6, Batch 1500] loss: 0.05270072858489584
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0735
Validation Accuracy: 0.9788
Overfitting: 0.0735
[Epoch 7, Batch 100] loss: 0.04451788996579126
[Epoch 7, Batch 200] loss: 0.03801693089772016
[Epoch 7, Batch 300] loss: 0.044560408720280976
[Epoch 7, Batch 400] loss: 0.058596673217834905
[Epoch 7, Batch 500] loss: 0.04711496636038646
[Epoch 7, Batch 600] loss: 0.0528803852153942
[Epoch 7, Batch 700] loss: 0.04927644334267825
[Epoch 7, Batch 800] loss: 0.0384844853595132
[Epoch 7, Batch 900] loss: 0.0475066263473127
[Epoch 7, Batch 1000] loss: 0.06114270154386759
[Epoch 7, Batch 1100] loss: 0.04947596422804054
[Epoch 7, Batch 1200] loss: 0.03228770075947977
[Epoch 7, Batch 1300] loss: 0.05305910339346156
[Epoch 7, Batch 1400] loss: 0.04741126478998922
[Epoch 7, Batch 1500] loss: 0.04470586561481468
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0682
Validation Accuracy: 0.9798
Overfitting: 0.0682
[Epoch 8, Batch 100] loss: 0.0418427306402009
[Epoch 8, Batch 200] loss: 0.04418365410296246
[Epoch 8, Batch 300] loss: 0.04019992063287645
[Epoch 8, Batch 400] loss: 0.043688697735778985
[Epoch 8, Batch 500] loss: 0.043456327590392904
[Epoch 8, Batch 600] loss: 0.035151914811576715
[Epoch 8, Batch 700] loss: 0.046397629526327366
[Epoch 8, Batch 800] loss: 0.037322295827325436
[Epoch 8, Batch 900] loss: 0.04778687122394331
[Epoch 8, Batch 1000] loss: 0.033766227686428466
[Epoch 8, Batch 1100] loss: 0.043675781134516
[Epoch 8, Batch 1200] loss: 0.040520114882383496
[Epoch 8, Batch 1300] loss: 0.038524178143125025
[Epoch 8, Batch 1400] loss: 0.050656900957692416
[Epoch 8, Batch 1500] loss: 0.046409482802264396
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0691
Validation Accuracy: 0.9798
Overfitting: 0.0691
[Epoch 9, Batch 100] loss: 0.0391360327496659
[Epoch 9, Batch 200] loss: 0.03408157133497298
[Epoch 9, Batch 300] loss: 0.03687787942122668
[Epoch 9, Batch 400] loss: 0.04228616110340226
[Epoch 9, Batch 500] loss: 0.03519106387568172
[Epoch 9, Batch 600] loss: 0.0449467786072637
[Epoch 9, Batch 700] loss: 0.03516889004909899
[Epoch 9, Batch 800] loss: 0.04794170175271575
[Epoch 9, Batch 900] loss: 0.030133998122764752
[Epoch 9, Batch 1000] loss: 0.03739207003149204
[Epoch 9, Batch 1100] loss: 0.040567826725309716
[Epoch 9, Batch 1200] loss: 0.04128382019931451
[Epoch 9, Batch 1300] loss: 0.04229800017667003
[Epoch 9, Batch 1400] loss: 0.046595288076787256
[Epoch 9, Batch 1500] loss: 0.03483107838779688
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0575
Validation Accuracy: 0.9826
Overfitting: 0.0575
Best model saved at epoch 9 with validation loss: 0.0575
[Epoch 10, Batch 100] loss: 0.027189040831290187
[Epoch 10, Batch 200] loss: 0.02497866483638063
[Epoch 10, Batch 300] loss: 0.03375283492496237
[Epoch 10, Batch 400] loss: 0.03536837963561993
[Epoch 10, Batch 500] loss: 0.038421313780127093
[Epoch 10, Batch 600] loss: 0.028203919649822638
[Epoch 10, Batch 700] loss: 0.0340605219360441
[Epoch 10, Batch 800] loss: 0.03712119619944133
[Epoch 10, Batch 900] loss: 0.041521532367914914
[Epoch 10, Batch 1000] loss: 0.033111418990883976
[Epoch 10, Batch 1100] loss: 0.037345879334025084
[Epoch 10, Batch 1200] loss: 0.03474291491089389
[Epoch 10, Batch 1300] loss: 0.03610727886174572
[Epoch 10, Batch 1400] loss: 0.04138388569350354
[Epoch 10, Batch 1500] loss: 0.029869599679950624
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0587
Validation Accuracy: 0.9827
Overfitting: 0.0587
[Epoch 11, Batch 100] loss: 0.029443454650463538
[Epoch 11, Batch 200] loss: 0.02924951640132349
[Epoch 11, Batch 300] loss: 0.024967259653203656
[Epoch 11, Batch 400] loss: 0.030197767730569466
[Epoch 11, Batch 500] loss: 0.02057864151778631
[Epoch 11, Batch 600] loss: 0.034595737184863536
[Epoch 11, Batch 700] loss: 0.03335863865097053
[Epoch 11, Batch 800] loss: 0.03142081190482713
[Epoch 11, Batch 900] loss: 0.029684763438417576
[Epoch 11, Batch 1000] loss: 0.029811311509402003
[Epoch 11, Batch 1100] loss: 0.03388390130130574
[Epoch 11, Batch 1200] loss: 0.036263758834684266
[Epoch 11, Batch 1300] loss: 0.026850369790772675
[Epoch 11, Batch 1400] loss: 0.031145614560227842
[Epoch 11, Batch 1500] loss: 0.03813765023252927
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0694
Validation Accuracy: 0.9800
Overfitting: 0.0694
Early stopping epoch 11 for trial 24. Moving to next fold.
Fold 2 validation loss: 0.0694
Fold 3/5
Inner Training set size for fold 3 is 48000
 Inner Validation set size for fold 3 is 12000
[Epoch 1, Batch 100] loss: 2.2748641204833984
[Epoch 1, Batch 200] loss: 2.1147270679473875
[Epoch 1, Batch 300] loss: 1.2586356049776077
[Epoch 1, Batch 400] loss: 0.6471330706775188
[Epoch 1, Batch 500] loss: 0.4925423341989517
[Epoch 1, Batch 600] loss: 0.45978577718138697
[Epoch 1, Batch 700] loss: 0.37314192473888397
[Epoch 1, Batch 800] loss: 0.36827754706144333
[Epoch 1, Batch 900] loss: 0.32149975292384625
[Epoch 1, Batch 1000] loss: 0.3008266095817089
[Epoch 1, Batch 1100] loss: 0.2618714512139559
[Epoch 1, Batch 1200] loss: 0.282926322594285
[Epoch 1, Batch 1300] loss: 0.27246932085603476
[Epoch 1, Batch 1400] loss: 0.20749141030013563
[Epoch 1, Batch 1500] loss: 0.19197918105870485
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1998
Validation Accuracy: 0.9378
Overfitting: 0.1998
[Epoch 2, Batch 100] loss: 0.21656977146863937
[Epoch 2, Batch 200] loss: 0.18973471514880658
[Epoch 2, Batch 300] loss: 0.17872406456619502
[Epoch 2, Batch 400] loss: 0.17483170289546252
[Epoch 2, Batch 500] loss: 0.18421340389177204
[Epoch 2, Batch 600] loss: 0.14500450383871794
[Epoch 2, Batch 700] loss: 0.17115335378795862
[Epoch 2, Batch 800] loss: 0.14214091213420033
[Epoch 2, Batch 900] loss: 0.1426158348377794
[Epoch 2, Batch 1000] loss: 0.12972689992748201
[Epoch 2, Batch 1100] loss: 0.13432207999750972
[Epoch 2, Batch 1200] loss: 0.14205931794829665
[Epoch 2, Batch 1300] loss: 0.11913592713419348
[Epoch 2, Batch 1400] loss: 0.13042238149791957
[Epoch 2, Batch 1500] loss: 0.11679576328024269
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1314
Validation Accuracy: 0.9594
Overfitting: 0.1314
[Epoch 3, Batch 100] loss: 0.11361060931347311
[Epoch 3, Batch 200] loss: 0.10158761805389077
[Epoch 3, Batch 300] loss: 0.11347459071315825
[Epoch 3, Batch 400] loss: 0.11556752484757453
[Epoch 3, Batch 500] loss: 0.09437032765708864
[Epoch 3, Batch 600] loss: 0.1147221229923889
[Epoch 3, Batch 700] loss: 0.104476736811921
[Epoch 3, Batch 800] loss: 0.12079792262520642
[Epoch 3, Batch 900] loss: 0.11150101311970502
[Epoch 3, Batch 1000] loss: 0.09511083244346082
[Epoch 3, Batch 1100] loss: 0.1053616484021768
[Epoch 3, Batch 1200] loss: 0.09447068506851793
[Epoch 3, Batch 1300] loss: 0.09456518315244467
[Epoch 3, Batch 1400] loss: 0.07918118857778608
[Epoch 3, Batch 1500] loss: 0.08239263754803687
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0988
Validation Accuracy: 0.9710
Overfitting: 0.0988
[Epoch 4, Batch 100] loss: 0.09524702112656086
[Epoch 4, Batch 200] loss: 0.08422944275662303
[Epoch 4, Batch 300] loss: 0.06742760148365051
[Epoch 4, Batch 400] loss: 0.07430374304763973
[Epoch 4, Batch 500] loss: 0.07129734047222883
[Epoch 4, Batch 600] loss: 0.07139240065123886
[Epoch 4, Batch 700] loss: 0.07300011510495097
[Epoch 4, Batch 800] loss: 0.07914815986296161
[Epoch 4, Batch 900] loss: 0.09279941208660603
[Epoch 4, Batch 1000] loss: 0.08847029543481767
[Epoch 4, Batch 1100] loss: 0.08957102643791587
[Epoch 4, Batch 1200] loss: 0.06995544498553499
[Epoch 4, Batch 1300] loss: 0.07998839291743934
[Epoch 4, Batch 1400] loss: 0.08091036109020934
[Epoch 4, Batch 1500] loss: 0.08102745718322694
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0818
Validation Accuracy: 0.9752
Overfitting: 0.0818
[Epoch 5, Batch 100] loss: 0.0784260309394449
[Epoch 5, Batch 200] loss: 0.06331456374377012
[Epoch 5, Batch 300] loss: 0.0730502072989475
[Epoch 5, Batch 400] loss: 0.06105711882701144
[Epoch 5, Batch 500] loss: 0.07252220775582828
[Epoch 5, Batch 600] loss: 0.07394817100837826
[Epoch 5, Batch 700] loss: 0.07938516145106406
[Epoch 5, Batch 800] loss: 0.06519940258469432
[Epoch 5, Batch 900] loss: 0.06478586583863943
[Epoch 5, Batch 1000] loss: 0.05753074349602685
[Epoch 5, Batch 1100] loss: 0.07037998100626282
[Epoch 5, Batch 1200] loss: 0.05842883339617402
[Epoch 5, Batch 1300] loss: 0.050053022453794255
[Epoch 5, Batch 1400] loss: 0.06296985534019768
[Epoch 5, Batch 1500] loss: 0.06995828667655588
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0725
Validation Accuracy: 0.9776
Overfitting: 0.0725
[Epoch 6, Batch 100] loss: 0.04382436833577231
[Epoch 6, Batch 200] loss: 0.062461388002848256
[Epoch 6, Batch 300] loss: 0.05597484320751391
[Epoch 6, Batch 400] loss: 0.0636270087887533
[Epoch 6, Batch 500] loss: 0.05500793025363237
[Epoch 6, Batch 600] loss: 0.06735829946934245
[Epoch 6, Batch 700] loss: 0.06361612869426608
[Epoch 6, Batch 800] loss: 0.06214890265837312
[Epoch 6, Batch 900] loss: 0.05415842737420462
[Epoch 6, Batch 1000] loss: 0.06124587950122077
[Epoch 6, Batch 1100] loss: 0.04548335999017581
[Epoch 6, Batch 1200] loss: 0.06921263618278317
[Epoch 6, Batch 1300] loss: 0.05297593740513548
[Epoch 6, Batch 1400] loss: 0.05116586619988084
[Epoch 6, Batch 1500] loss: 0.0546800331841223
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0591
Validation Accuracy: 0.9815
Overfitting: 0.0591
[Epoch 7, Batch 100] loss: 0.04387846273370087
[Epoch 7, Batch 200] loss: 0.04648395456955768
[Epoch 7, Batch 300] loss: 0.044316359555814415
[Epoch 7, Batch 400] loss: 0.05366950271069072
[Epoch 7, Batch 500] loss: 0.05791329858184326
[Epoch 7, Batch 600] loss: 0.05719389841658994
[Epoch 7, Batch 700] loss: 0.046585766286589204
[Epoch 7, Batch 800] loss: 0.04987420845893212
[Epoch 7, Batch 900] loss: 0.060134794877376406
[Epoch 7, Batch 1000] loss: 0.03904966053552925
[Epoch 7, Batch 1100] loss: 0.04141048026038334
[Epoch 7, Batch 1200] loss: 0.049664417583262545
[Epoch 7, Batch 1300] loss: 0.05568178381072357
[Epoch 7, Batch 1400] loss: 0.048803324115579014
[Epoch 7, Batch 1500] loss: 0.04604276659199968
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0651
Validation Accuracy: 0.9806
Overfitting: 0.0651
[Epoch 8, Batch 100] loss: 0.042958028849679974
[Epoch 8, Batch 200] loss: 0.037643731487914917
[Epoch 8, Batch 300] loss: 0.03907006034278311
[Epoch 8, Batch 400] loss: 0.04130093353916891
[Epoch 8, Batch 500] loss: 0.054439856285462156
[Epoch 8, Batch 600] loss: 0.036348386507015676
[Epoch 8, Batch 700] loss: 0.04999014269036706
[Epoch 8, Batch 800] loss: 0.056883007833966985
[Epoch 8, Batch 900] loss: 0.04818639183999039
[Epoch 8, Batch 1000] loss: 0.03713667949370574
[Epoch 8, Batch 1100] loss: 0.0497691562329419
[Epoch 8, Batch 1200] loss: 0.0392976451094728
[Epoch 8, Batch 1300] loss: 0.04701422703801654
[Epoch 8, Batch 1400] loss: 0.04619923761114478
[Epoch 8, Batch 1500] loss: 0.04909720640513115
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0528
Validation Accuracy: 0.9841
Overfitting: 0.0528
[Epoch 9, Batch 100] loss: 0.04634548307163641
[Epoch 9, Batch 200] loss: 0.04720903879730031
[Epoch 9, Batch 300] loss: 0.03762583855597768
[Epoch 9, Batch 400] loss: 0.03826638580998406
[Epoch 9, Batch 500] loss: 0.0421009097393835
[Epoch 9, Batch 600] loss: 0.04028969759208849
[Epoch 9, Batch 700] loss: 0.03281380778411403
[Epoch 9, Batch 800] loss: 0.043240039716474714
[Epoch 9, Batch 900] loss: 0.032796090088086205
[Epoch 9, Batch 1000] loss: 0.04086231729132123
[Epoch 9, Batch 1100] loss: 0.0559315123129636
[Epoch 9, Batch 1200] loss: 0.0393774982218747
[Epoch 9, Batch 1300] loss: 0.02569090491568204
[Epoch 9, Batch 1400] loss: 0.04706212575547397
[Epoch 9, Batch 1500] loss: 0.04012647908413783
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0568
Validation Accuracy: 0.9829
Overfitting: 0.0568
Best model saved at epoch 9 with validation loss: 0.0568
[Epoch 10, Batch 100] loss: 0.03655081653152593
[Epoch 10, Batch 200] loss: 0.039601412256597544
[Epoch 10, Batch 300] loss: 0.03750186145363841
[Epoch 10, Batch 400] loss: 0.03634793796692975
[Epoch 10, Batch 500] loss: 0.028722789238090626
[Epoch 10, Batch 600] loss: 0.03666542158491211
[Epoch 10, Batch 700] loss: 0.03607411402947037
[Epoch 10, Batch 800] loss: 0.03724555513152154
[Epoch 10, Batch 900] loss: 0.03552440162515268
[Epoch 10, Batch 1000] loss: 0.037367455165367575
[Epoch 10, Batch 1100] loss: 0.03692821420205292
[Epoch 10, Batch 1200] loss: 0.041925045949174095
[Epoch 10, Batch 1300] loss: 0.03935920360556338
[Epoch 10, Batch 1400] loss: 0.03620803573750891
[Epoch 10, Batch 1500] loss: 0.032679487554705705
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0533
Validation Accuracy: 0.9837
Overfitting: 0.0533
[Epoch 11, Batch 100] loss: 0.03243257735390216
[Epoch 11, Batch 200] loss: 0.041870157085941176
[Epoch 11, Batch 300] loss: 0.02863314917834941
[Epoch 11, Batch 400] loss: 0.029403988898120587
[Epoch 11, Batch 500] loss: 0.03677092591198743
[Epoch 11, Batch 600] loss: 0.03331709514604882
[Epoch 11, Batch 700] loss: 0.03696248370280955
[Epoch 11, Batch 800] loss: 0.03529033678380074
[Epoch 11, Batch 900] loss: 0.026335122399032115
[Epoch 11, Batch 1000] loss: 0.03266846378799528
[Epoch 11, Batch 1100] loss: 0.03119649361964548
[Epoch 11, Batch 1200] loss: 0.033148931618779895
[Epoch 11, Batch 1300] loss: 0.04066946794395335
[Epoch 11, Batch 1400] loss: 0.029411741119984073
[Epoch 11, Batch 1500] loss: 0.032659845643793234
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0514
Validation Accuracy: 0.9833
Overfitting: 0.0514
Early stopping epoch 11 for trial 24. Moving to next fold.
Fold 3 validation loss: 0.0514
Fold 4/5
Inner Training set size for fold 4 is 48000
 Inner Validation set size for fold 4 is 12000
[Epoch 1, Batch 100] loss: 2.2888118028640747
[Epoch 1, Batch 200] loss: 2.239113461971283
[Epoch 1, Batch 300] loss: 2.0164298701286314
[Epoch 1, Batch 400] loss: 1.115974172949791
[Epoch 1, Batch 500] loss: 0.665598523914814
[Epoch 1, Batch 600] loss: 0.4881726068258285
[Epoch 1, Batch 700] loss: 0.45772801876068114
[Epoch 1, Batch 800] loss: 0.3840555743128061
[Epoch 1, Batch 900] loss: 0.3830714309960604
[Epoch 1, Batch 1000] loss: 0.2943617758154869
[Epoch 1, Batch 1100] loss: 0.3127258053421974
[Epoch 1, Batch 1200] loss: 0.25725384294986725
[Epoch 1, Batch 1300] loss: 0.24574349373579024
[Epoch 1, Batch 1400] loss: 0.2500836292654276
[Epoch 1, Batch 1500] loss: 0.21912186075001955
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.1960
Validation Accuracy: 0.9401
Overfitting: 0.1960
[Epoch 2, Batch 100] loss: 0.19168707769364118
[Epoch 2, Batch 200] loss: 0.1959483122639358
[Epoch 2, Batch 300] loss: 0.18864913880825043
[Epoch 2, Batch 400] loss: 0.16586939338594675
[Epoch 2, Batch 500] loss: 0.19249789545312523
[Epoch 2, Batch 600] loss: 0.17515970034524797
[Epoch 2, Batch 700] loss: 0.1632578173466027
[Epoch 2, Batch 800] loss: 0.16127161361277104
[Epoch 2, Batch 900] loss: 0.13163633273914457
[Epoch 2, Batch 1000] loss: 0.1331437784433365
[Epoch 2, Batch 1100] loss: 0.1364273334108293
[Epoch 2, Batch 1200] loss: 0.1443233472853899
[Epoch 2, Batch 1300] loss: 0.14490690618753432
[Epoch 2, Batch 1400] loss: 0.11732813505455851
[Epoch 2, Batch 1500] loss: 0.1376082313247025
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1134
Validation Accuracy: 0.9639
Overfitting: 0.1134
[Epoch 3, Batch 100] loss: 0.11645552821457386
[Epoch 3, Batch 200] loss: 0.11184954171068967
[Epoch 3, Batch 300] loss: 0.09260827987454831
[Epoch 3, Batch 400] loss: 0.1256377113191411
[Epoch 3, Batch 500] loss: 0.09716306906193495
[Epoch 3, Batch 600] loss: 0.13597764312289656
[Epoch 3, Batch 700] loss: 0.10815849225968123
[Epoch 3, Batch 800] loss: 0.10867006791289896
[Epoch 3, Batch 900] loss: 0.10681286974810064
[Epoch 3, Batch 1000] loss: 0.1121472995262593
[Epoch 3, Batch 1100] loss: 0.10165123843587935
[Epoch 3, Batch 1200] loss: 0.0783545902511105
[Epoch 3, Batch 1300] loss: 0.09406314946245402
[Epoch 3, Batch 1400] loss: 0.10134305276558735
[Epoch 3, Batch 1500] loss: 0.10161166266538203
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0889
Validation Accuracy: 0.9722
Overfitting: 0.0889
[Epoch 4, Batch 100] loss: 0.08333382399287075
[Epoch 4, Batch 200] loss: 0.08634136200649664
[Epoch 4, Batch 300] loss: 0.08350829048082233
[Epoch 4, Batch 400] loss: 0.08678297305945307
[Epoch 4, Batch 500] loss: 0.09798548683524132
[Epoch 4, Batch 600] loss: 0.09602894093375652
[Epoch 4, Batch 700] loss: 0.08102943083271384
[Epoch 4, Batch 800] loss: 0.07154593328014017
[Epoch 4, Batch 900] loss: 0.08715435477439314
[Epoch 4, Batch 1000] loss: 0.07069115176331252
[Epoch 4, Batch 1100] loss: 0.0737591406237334
[Epoch 4, Batch 1200] loss: 0.09748599970480427
[Epoch 4, Batch 1300] loss: 0.07121603400446475
[Epoch 4, Batch 1400] loss: 0.08640118045732378
[Epoch 4, Batch 1500] loss: 0.0785249492013827
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0726
Validation Accuracy: 0.9768
Overfitting: 0.0726
[Epoch 5, Batch 100] loss: 0.06634940423537046
[Epoch 5, Batch 200] loss: 0.06655270284507424
[Epoch 5, Batch 300] loss: 0.0774445179128088
[Epoch 5, Batch 400] loss: 0.058740303318481894
[Epoch 5, Batch 500] loss: 0.06706799630774185
[Epoch 5, Batch 600] loss: 0.06378159998450428
[Epoch 5, Batch 700] loss: 0.07052597123431043
[Epoch 5, Batch 800] loss: 0.06578716993099079
[Epoch 5, Batch 900] loss: 0.08855930014047772
[Epoch 5, Batch 1000] loss: 0.06803551667835564
[Epoch 5, Batch 1100] loss: 0.0747757761972025
[Epoch 5, Batch 1200] loss: 0.07152491168933921
[Epoch 5, Batch 1300] loss: 0.0627587855188176
[Epoch 5, Batch 1400] loss: 0.0550379670818802
[Epoch 5, Batch 1500] loss: 0.07094892412424088
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0690
Validation Accuracy: 0.9784
Overfitting: 0.0690
[Epoch 6, Batch 100] loss: 0.064168154920917
[Epoch 6, Batch 200] loss: 0.06844755142694339
[Epoch 6, Batch 300] loss: 0.06276214187964797
[Epoch 6, Batch 400] loss: 0.07291118003660813
[Epoch 6, Batch 500] loss: 0.06566280326107517
[Epoch 6, Batch 600] loss: 0.05369572350173257
[Epoch 6, Batch 700] loss: 0.05157574765384197
[Epoch 6, Batch 800] loss: 0.05809673299081623
[Epoch 6, Batch 900] loss: 0.06645832542679272
[Epoch 6, Batch 1000] loss: 0.05944802403682843
[Epoch 6, Batch 1100] loss: 0.04459807174978778
[Epoch 6, Batch 1200] loss: 0.06656205601524562
[Epoch 6, Batch 1300] loss: 0.055368761393474415
[Epoch 6, Batch 1400] loss: 0.049793222481384875
[Epoch 6, Batch 1500] loss: 0.05964486355194822
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0608
Validation Accuracy: 0.9789
Overfitting: 0.0608
[Epoch 7, Batch 100] loss: 0.04877195788314566
[Epoch 7, Batch 200] loss: 0.03953065955254715
[Epoch 7, Batch 300] loss: 0.058162505959626284
[Epoch 7, Batch 400] loss: 0.05226507092826069
[Epoch 7, Batch 500] loss: 0.04377635934855789
[Epoch 7, Batch 600] loss: 0.0444495989906136
[Epoch 7, Batch 700] loss: 0.05670177520019934
[Epoch 7, Batch 800] loss: 0.04330155565519817
[Epoch 7, Batch 900] loss: 0.07078607045696117
[Epoch 7, Batch 1000] loss: 0.05507963694049977
[Epoch 7, Batch 1100] loss: 0.056619810505653734
[Epoch 7, Batch 1200] loss: 0.05248504684073851
[Epoch 7, Batch 1300] loss: 0.05427199584897607
[Epoch 7, Batch 1400] loss: 0.04844568048021756
[Epoch 7, Batch 1500] loss: 0.05528813355369493
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0564
Validation Accuracy: 0.9825
Overfitting: 0.0564
[Epoch 8, Batch 100] loss: 0.036944827784900554
[Epoch 8, Batch 200] loss: 0.040622475692071024
[Epoch 8, Batch 300] loss: 0.03818795831524767
[Epoch 8, Batch 400] loss: 0.05397984448354691
[Epoch 8, Batch 500] loss: 0.04925902067683637
[Epoch 8, Batch 600] loss: 0.03867269573383965
[Epoch 8, Batch 700] loss: 0.043879508760292084
[Epoch 8, Batch 800] loss: 0.04355265008402057
[Epoch 8, Batch 900] loss: 0.04883650001836941
[Epoch 8, Batch 1000] loss: 0.046584577977191656
[Epoch 8, Batch 1100] loss: 0.04847678090736736
[Epoch 8, Batch 1200] loss: 0.04756458975491114
[Epoch 8, Batch 1300] loss: 0.04707881797570735
[Epoch 8, Batch 1400] loss: 0.04378668824210763
[Epoch 8, Batch 1500] loss: 0.05217571852146648
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0563
Validation Accuracy: 0.9827
Overfitting: 0.0563
[Epoch 9, Batch 100] loss: 0.032885301435599104
[Epoch 9, Batch 200] loss: 0.04096277399308747
[Epoch 9, Batch 300] loss: 0.029651296570664273
[Epoch 9, Batch 400] loss: 0.05074255040846765
[Epoch 9, Batch 500] loss: 0.043866091300733386
[Epoch 9, Batch 600] loss: 0.038801090209162795
[Epoch 9, Batch 700] loss: 0.03841520416899584
[Epoch 9, Batch 800] loss: 0.04676672750734724
[Epoch 9, Batch 900] loss: 0.0349262066691881
[Epoch 9, Batch 1000] loss: 0.04631159775919514
[Epoch 9, Batch 1100] loss: 0.0390953246562276
[Epoch 9, Batch 1200] loss: 0.04384599826589693
[Epoch 9, Batch 1300] loss: 0.0468098600427038
[Epoch 9, Batch 1400] loss: 0.04468485019227955
[Epoch 9, Batch 1500] loss: 0.045582290861639195
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0602
Validation Accuracy: 0.9810
Overfitting: 0.0602
Best model saved at epoch 9 with validation loss: 0.0602
[Epoch 10, Batch 100] loss: 0.03400534063926898
[Epoch 10, Batch 200] loss: 0.0375409272237448
[Epoch 10, Batch 300] loss: 0.033973771809833124
[Epoch 10, Batch 400] loss: 0.03976990165625466
[Epoch 10, Batch 500] loss: 0.029597352954151574
[Epoch 10, Batch 600] loss: 0.03298006179393269
[Epoch 10, Batch 700] loss: 0.03645103574963286
[Epoch 10, Batch 800] loss: 0.043474650870193726
[Epoch 10, Batch 900] loss: 0.04692772872396745
[Epoch 10, Batch 1000] loss: 0.03233443585922942
[Epoch 10, Batch 1100] loss: 0.039634570431080644
[Epoch 10, Batch 1200] loss: 0.03514649902965175
[Epoch 10, Batch 1300] loss: 0.03677475679665804
[Epoch 10, Batch 1400] loss: 0.03723464653856354
[Epoch 10, Batch 1500] loss: 0.03626618628855795
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0484
Validation Accuracy: 0.9844
Overfitting: 0.0484
[Epoch 11, Batch 100] loss: 0.02759489983320236
[Epoch 11, Batch 200] loss: 0.031591122220270336
[Epoch 11, Batch 300] loss: 0.03193295675038826
[Epoch 11, Batch 400] loss: 0.039835602089297026
[Epoch 11, Batch 500] loss: 0.024541064162622205
[Epoch 11, Batch 600] loss: 0.03212663820479065
[Epoch 11, Batch 700] loss: 0.027319428788032382
[Epoch 11, Batch 800] loss: 0.0381870990851894
[Epoch 11, Batch 900] loss: 0.04995918420492671
[Epoch 11, Batch 1000] loss: 0.026874238009913825
[Epoch 11, Batch 1100] loss: 0.03561913608049508
[Epoch 11, Batch 1200] loss: 0.03658394370810129
[Epoch 11, Batch 1300] loss: 0.03417624341789633
[Epoch 11, Batch 1400] loss: 0.03325714217760833
[Epoch 11, Batch 1500] loss: 0.02533820213895524
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0530
Validation Accuracy: 0.9831
Overfitting: 0.0530
Early stopping epoch 11 for trial 24. Moving to next fold.
Fold 4 validation loss: 0.0530
Fold 5/5
Inner Training set size for fold 5 is 48000
 Inner Validation set size for fold 5 is 12000
[Epoch 1, Batch 100] loss: 2.2884827756881716
[Epoch 1, Batch 200] loss: 2.2191409397125246
[Epoch 1, Batch 300] loss: 1.84853187084198
[Epoch 1, Batch 400] loss: 0.892473328113556
[Epoch 1, Batch 500] loss: 0.5909551683068276
[Epoch 1, Batch 600] loss: 0.4906148299574852
[Epoch 1, Batch 700] loss: 0.4327401101589203
[Epoch 1, Batch 800] loss: 0.4054401831328869
[Epoch 1, Batch 900] loss: 0.3246361672133207
[Epoch 1, Batch 1000] loss: 0.32230220414698124
[Epoch 1, Batch 1100] loss: 0.29688246455043554
[Epoch 1, Batch 1200] loss: 0.3000939105451107
[Epoch 1, Batch 1300] loss: 0.2445458970591426
[Epoch 1, Batch 1400] loss: 0.2576761144399643
[Epoch 1, Batch 1500] loss: 0.24004569716751575
**STATS for Epoch 1** : 
Average training loss: 0.0000
Average validation loss: 0.2062
Validation Accuracy: 0.9400
Overfitting: 0.2062
[Epoch 2, Batch 100] loss: 0.2077653263323009
[Epoch 2, Batch 200] loss: 0.19258432857692243
[Epoch 2, Batch 300] loss: 0.19363470809534192
[Epoch 2, Batch 400] loss: 0.19610468873754144
[Epoch 2, Batch 500] loss: 0.17645902665331958
[Epoch 2, Batch 600] loss: 0.17305981086567043
[Epoch 2, Batch 700] loss: 0.15854761601425707
[Epoch 2, Batch 800] loss: 0.1596369603369385
[Epoch 2, Batch 900] loss: 0.15028343791142107
[Epoch 2, Batch 1000] loss: 0.1681881080940366
[Epoch 2, Batch 1100] loss: 0.14499895507469773
[Epoch 2, Batch 1200] loss: 0.12611219890415667
[Epoch 2, Batch 1300] loss: 0.12730976918246598
[Epoch 2, Batch 1400] loss: 0.12805767074227334
[Epoch 2, Batch 1500] loss: 0.131255520042032
**STATS for Epoch 2** : 
Average training loss: 0.0000
Average validation loss: 0.1215
Validation Accuracy: 0.9647
Overfitting: 0.1215
[Epoch 3, Batch 100] loss: 0.12269217831082642
[Epoch 3, Batch 200] loss: 0.1104805345274508
[Epoch 3, Batch 300] loss: 0.11580903531983494
[Epoch 3, Batch 400] loss: 0.10528645655140281
[Epoch 3, Batch 500] loss: 0.10274177031591535
[Epoch 3, Batch 600] loss: 0.10761935336515308
[Epoch 3, Batch 700] loss: 0.11149427941534668
[Epoch 3, Batch 800] loss: 0.10418187343515456
[Epoch 3, Batch 900] loss: 0.11872018271125853
[Epoch 3, Batch 1000] loss: 0.08855069254990668
[Epoch 3, Batch 1100] loss: 0.10352575932629407
[Epoch 3, Batch 1200] loss: 0.08982572573237121
[Epoch 3, Batch 1300] loss: 0.10187333408743143
[Epoch 3, Batch 1400] loss: 0.10200247197411955
[Epoch 3, Batch 1500] loss: 0.09488525756169111
**STATS for Epoch 3** : 
Average training loss: 0.0000
Average validation loss: 0.0975
Validation Accuracy: 0.9709
Overfitting: 0.0975
[Epoch 4, Batch 100] loss: 0.09993961956351996
[Epoch 4, Batch 200] loss: 0.0804774788301438
[Epoch 4, Batch 300] loss: 0.07291452881880105
[Epoch 4, Batch 400] loss: 0.08118629640899598
[Epoch 4, Batch 500] loss: 0.09529505463782698
[Epoch 4, Batch 600] loss: 0.07744847715366632
[Epoch 4, Batch 700] loss: 0.08036821253132075
[Epoch 4, Batch 800] loss: 0.07863149523967877
[Epoch 4, Batch 900] loss: 0.08586508024483919
[Epoch 4, Batch 1000] loss: 0.0717548539931886
[Epoch 4, Batch 1100] loss: 0.07487442024052143
[Epoch 4, Batch 1200] loss: 0.06082225009682588
[Epoch 4, Batch 1300] loss: 0.07179661751491949
[Epoch 4, Batch 1400] loss: 0.07049715319182724
[Epoch 4, Batch 1500] loss: 0.09281820852542295
**STATS for Epoch 4** : 
Average training loss: 0.0000
Average validation loss: 0.0789
Validation Accuracy: 0.9758
Overfitting: 0.0789
[Epoch 5, Batch 100] loss: 0.07138744764262811
[Epoch 5, Batch 200] loss: 0.07442574581597
[Epoch 5, Batch 300] loss: 0.054084668677533046
[Epoch 5, Batch 400] loss: 0.06711912839906291
[Epoch 5, Batch 500] loss: 0.07733464168850332
[Epoch 5, Batch 600] loss: 0.06426549442810937
[Epoch 5, Batch 700] loss: 0.060990147616248575
[Epoch 5, Batch 800] loss: 0.08392974234418943
[Epoch 5, Batch 900] loss: 0.07219258459517733
[Epoch 5, Batch 1000] loss: 0.058619336320552974
[Epoch 5, Batch 1100] loss: 0.06934725590515882
[Epoch 5, Batch 1200] loss: 0.0647122878790833
[Epoch 5, Batch 1300] loss: 0.06317215729970485
[Epoch 5, Batch 1400] loss: 0.06290778612252325
[Epoch 5, Batch 1500] loss: 0.07412046822486446
**STATS for Epoch 5** : 
Average training loss: 0.0000
Average validation loss: 0.0727
Validation Accuracy: 0.9777
Overfitting: 0.0727
[Epoch 6, Batch 100] loss: 0.05868534936569631
[Epoch 6, Batch 200] loss: 0.060212787894997746
[Epoch 6, Batch 300] loss: 0.058672856703633446
[Epoch 6, Batch 400] loss: 0.04324575770762749
[Epoch 6, Batch 500] loss: 0.07197603798471391
[Epoch 6, Batch 600] loss: 0.06623640499543398
[Epoch 6, Batch 700] loss: 0.05881916699931025
[Epoch 6, Batch 800] loss: 0.06391538209049032
[Epoch 6, Batch 900] loss: 0.061738816178403794
[Epoch 6, Batch 1000] loss: 0.05899834065930918
[Epoch 6, Batch 1100] loss: 0.05565378563478589
[Epoch 6, Batch 1200] loss: 0.05605737396050245
[Epoch 6, Batch 1300] loss: 0.05303751307539642
[Epoch 6, Batch 1400] loss: 0.05647038562223315
[Epoch 6, Batch 1500] loss: 0.04567117345053703
**STATS for Epoch 6** : 
Average training loss: 0.0000
Average validation loss: 0.0682
Validation Accuracy: 0.9790
Overfitting: 0.0682
[Epoch 7, Batch 100] loss: 0.04816660779819358
[Epoch 7, Batch 200] loss: 0.04343050602590665
[Epoch 7, Batch 300] loss: 0.046628591895569116
[Epoch 7, Batch 400] loss: 0.05316832567914389
[Epoch 7, Batch 500] loss: 0.0571954124327749
[Epoch 7, Batch 600] loss: 0.06465786035405471
[Epoch 7, Batch 700] loss: 0.049437211211770776
[Epoch 7, Batch 800] loss: 0.048178706655162384
[Epoch 7, Batch 900] loss: 0.06078107305453159
[Epoch 7, Batch 1000] loss: 0.048909308185684494
[Epoch 7, Batch 1100] loss: 0.04399586496176198
[Epoch 7, Batch 1200] loss: 0.06323290601198096
[Epoch 7, Batch 1300] loss: 0.045158675455022605
[Epoch 7, Batch 1400] loss: 0.047812357688089835
[Epoch 7, Batch 1500] loss: 0.057004595901817084
**STATS for Epoch 7** : 
Average training loss: 0.0000
Average validation loss: 0.0604
Validation Accuracy: 0.9808
Overfitting: 0.0604
[Epoch 8, Batch 100] loss: 0.04041929419152439
[Epoch 8, Batch 200] loss: 0.05830323307192884
[Epoch 8, Batch 300] loss: 0.04823311478132382
[Epoch 8, Batch 400] loss: 0.04713949640514329
[Epoch 8, Batch 500] loss: 0.03803349954425357
[Epoch 8, Batch 600] loss: 0.04943899418052752
[Epoch 8, Batch 700] loss: 0.04929214003263041
[Epoch 8, Batch 800] loss: 0.0499412588524865
[Epoch 8, Batch 900] loss: 0.05380506738903932
[Epoch 8, Batch 1000] loss: 0.04703064229048323
[Epoch 8, Batch 1100] loss: 0.0411697268509306
[Epoch 8, Batch 1200] loss: 0.03905096196162049
[Epoch 8, Batch 1300] loss: 0.045341859619657046
[Epoch 8, Batch 1400] loss: 0.046406240937067196
[Epoch 8, Batch 1500] loss: 0.04025426718115341
**STATS for Epoch 8** : 
Average training loss: 0.0000
Average validation loss: 0.0515
Validation Accuracy: 0.9842
Overfitting: 0.0515
[Epoch 9, Batch 100] loss: 0.031501824508886785
[Epoch 9, Batch 200] loss: 0.03330045116541441
[Epoch 9, Batch 300] loss: 0.0436581898725126
[Epoch 9, Batch 400] loss: 0.04616520806448534
[Epoch 9, Batch 500] loss: 0.03996014782343991
[Epoch 9, Batch 600] loss: 0.03467904785822611
[Epoch 9, Batch 700] loss: 0.0437960359826684
[Epoch 9, Batch 800] loss: 0.04204938484588638
[Epoch 9, Batch 900] loss: 0.05014877301291563
[Epoch 9, Batch 1000] loss: 0.0426031977403909
[Epoch 9, Batch 1100] loss: 0.04439993389998562
[Epoch 9, Batch 1200] loss: 0.04063853107858449
[Epoch 9, Batch 1300] loss: 0.0336913244612515
[Epoch 9, Batch 1400] loss: 0.04824520997877699
[Epoch 9, Batch 1500] loss: 0.0376141574094072
**STATS for Epoch 9** : 
Average training loss: 0.0000
Average validation loss: 0.0678
Validation Accuracy: 0.9796
Overfitting: 0.0678
Best model saved at epoch 9 with validation loss: 0.0678
[Epoch 10, Batch 100] loss: 0.032555598975741305
[Epoch 10, Batch 200] loss: 0.04496742370654829
[Epoch 10, Batch 300] loss: 0.027931003599078394
[Epoch 10, Batch 400] loss: 0.028609452600358055
[Epoch 10, Batch 500] loss: 0.04516432192234788
[Epoch 10, Batch 600] loss: 0.03174451040686108
[Epoch 10, Batch 700] loss: 0.036785972063662485
[Epoch 10, Batch 800] loss: 0.03722892572986893
[Epoch 10, Batch 900] loss: 0.03808149154065177
[Epoch 10, Batch 1000] loss: 0.0398244136502035
[Epoch 10, Batch 1100] loss: 0.0346827763156034
[Epoch 10, Batch 1200] loss: 0.04804817964090034
[Epoch 10, Batch 1300] loss: 0.04668678173213266
[Epoch 10, Batch 1400] loss: 0.04759994193504099
[Epoch 10, Batch 1500] loss: 0.04030663516372442
**STATS for Epoch 10** : 
Average training loss: 0.0000
Average validation loss: 0.0588
Validation Accuracy: 0.9820
Overfitting: 0.0588
[Epoch 11, Batch 100] loss: 0.04298668895149604
[Epoch 11, Batch 200] loss: 0.033487223100964914
[Epoch 11, Batch 300] loss: 0.031192900046589783
[Epoch 11, Batch 400] loss: 0.024925407043192536
[Epoch 11, Batch 500] loss: 0.03707281819282798
[Epoch 11, Batch 600] loss: 0.03211973325669533
[Epoch 11, Batch 700] loss: 0.030142484663811045
[Epoch 11, Batch 800] loss: 0.04060846471169498
[Epoch 11, Batch 900] loss: 0.0445410745969275
[Epoch 11, Batch 1000] loss: 0.04055720727425069
[Epoch 11, Batch 1100] loss: 0.03948718316474697
[Epoch 11, Batch 1200] loss: 0.029878931974526495
[Epoch 11, Batch 1300] loss: 0.028959031698468606
[Epoch 11, Batch 1400] loss: 0.037847178989322855
[Epoch 11, Batch 1500] loss: 0.03245400017971406
**STATS for Epoch 11** : 
Average training loss: 0.0000
Average validation loss: 0.0475
Validation Accuracy: 0.9852
Overfitting: 0.0475
Early stopping epoch 11 for trial 24. Moving to next fold.
Fold 5 validation loss: 0.0475
Mean validation loss across all folds for Trial 24 is 0.0536 with trial config:  l1: 128, l2: 64, lr: 0.001, batch_size: 32
[I 2024-12-10 08:03:50,978] Trial 23 finished with value: 0.053573305698802386 and parameters: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 32}. Best is trial 21 with value: 0.04811396317985685.
Study statistics: 
  Number of finished trials:  24
  Number of pruned trials:  0
  Number of complete trials:  24
Best hyperparameters found:
{'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 32}
Best trial:
  Value:  0.04811396317985685
Loaded best model checkpoint from: instances/1151165_20241210/best_checkpoint_trial_21/model.pth
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 32} on final Train set with train set size : 60000
[Epoch 1, Batch 100] loss: 2.2923245525360105
[Epoch 1, Batch 200] loss: 2.2634502816200257
[Epoch 1, Batch 300] loss: 2.15489963054657
[Epoch 1, Batch 400] loss: 1.4358431106805802
[Epoch 1, Batch 500] loss: 0.7115878343582154
[Epoch 1, Batch 600] loss: 0.5138100607693196
[Epoch 1, Batch 700] loss: 0.4339649806916714
[Epoch 1, Batch 800] loss: 0.40661405965685843
[Epoch 1, Batch 900] loss: 0.3519654906541109
[Epoch 1, Batch 1000] loss: 0.34127303689718247
[Epoch 1, Batch 1100] loss: 0.26876363474875686
[Epoch 1, Batch 1200] loss: 0.2867581029981375
[Epoch 1, Batch 1300] loss: 0.2583519826456904
[Epoch 1, Batch 1400] loss: 0.25783974163234236
[Epoch 1, Batch 1500] loss: 0.22751053005456925
[Epoch 1, Batch 1600] loss: 0.22112612249329686
[Epoch 1, Batch 1700] loss: 0.22338332202285527
[Epoch 1, Batch 1800] loss: 0.1933098131045699
**STATS for Epoch 1** : 
Average training loss: 0.0069
Average validation loss: 0.1682
Overfitting: 0.1613
Best model saved at epoch 1 with training loss: 0.0069
[Epoch 2, Batch 100] loss: 0.16016658199951053
[Epoch 2, Batch 200] loss: 0.14651065239682792
[Epoch 2, Batch 300] loss: 0.16574052711948753
[Epoch 2, Batch 400] loss: 0.15000175017863512
[Epoch 2, Batch 500] loss: 0.16207028613425792
[Epoch 2, Batch 600] loss: 0.14509156696498393
[Epoch 2, Batch 700] loss: 0.1414893283136189
[Epoch 2, Batch 800] loss: 0.1345309610106051
[Epoch 2, Batch 900] loss: 0.12319918116554618
[Epoch 2, Batch 1000] loss: 0.15679772395640612
[Epoch 2, Batch 1100] loss: 0.12907265329733492
[Epoch 2, Batch 1200] loss: 0.13308797348290682
[Epoch 2, Batch 1300] loss: 0.12026861194521189
[Epoch 2, Batch 1400] loss: 0.11195652483031154
[Epoch 2, Batch 1500] loss: 0.11808773188851773
[Epoch 2, Batch 1600] loss: 0.11330560216680169
[Epoch 2, Batch 1700] loss: 0.11368213668465614
[Epoch 2, Batch 1800] loss: 0.11906461428385227
**STATS for Epoch 2** : 
Average training loss: 0.0042
Average validation loss: 0.0906
Overfitting: 0.0864
Best model saved at epoch 2 with training loss: 0.0042
[Epoch 3, Batch 100] loss: 0.10255904209334403
[Epoch 3, Batch 200] loss: 0.10195663566701114
[Epoch 3, Batch 300] loss: 0.10185893008485436
[Epoch 3, Batch 400] loss: 0.0871179501246661
[Epoch 3, Batch 500] loss: 0.09716442194767297
[Epoch 3, Batch 600] loss: 0.08957486723549664
[Epoch 3, Batch 700] loss: 0.10142880610190332
[Epoch 3, Batch 800] loss: 0.09427238903474063
[Epoch 3, Batch 900] loss: 0.07798212204128503
[Epoch 3, Batch 1000] loss: 0.08979463657364249
[Epoch 3, Batch 1100] loss: 0.09528507687617094
[Epoch 3, Batch 1200] loss: 0.08294858551584185
[Epoch 3, Batch 1300] loss: 0.08862656220793724
[Epoch 3, Batch 1400] loss: 0.08401783501263708
[Epoch 3, Batch 1500] loss: 0.0810673928912729
[Epoch 3, Batch 1600] loss: 0.08386926648207009
[Epoch 3, Batch 1700] loss: 0.08523773551918566
[Epoch 3, Batch 1800] loss: 0.07643702262081206
**STATS for Epoch 3** : 
Average training loss: 0.0026
Average validation loss: 0.0692
Overfitting: 0.0667
Best model saved at epoch 3 with training loss: 0.0026
[Epoch 4, Batch 100] loss: 0.06156689036404714
[Epoch 4, Batch 200] loss: 0.08069506042171269
[Epoch 4, Batch 300] loss: 0.06435765555594117
[Epoch 4, Batch 400] loss: 0.08321714376099408
[Epoch 4, Batch 500] loss: 0.06291733921971172
[Epoch 4, Batch 600] loss: 0.08500526194926351
[Epoch 4, Batch 700] loss: 0.07345829785917886
[Epoch 4, Batch 800] loss: 0.06984513553325086
[Epoch 4, Batch 900] loss: 0.07564922476885841
[Epoch 4, Batch 1000] loss: 0.05964024341898039
[Epoch 4, Batch 1100] loss: 0.07473287847824395
[Epoch 4, Batch 1200] loss: 0.05879375398159027
[Epoch 4, Batch 1300] loss: 0.060680494210682806
[Epoch 4, Batch 1400] loss: 0.06630848957225681
[Epoch 4, Batch 1500] loss: 0.07260536603862419
[Epoch 4, Batch 1600] loss: 0.05909358303528279
[Epoch 4, Batch 1700] loss: 0.0798960027215071
[Epoch 4, Batch 1800] loss: 0.0727527504763566
**STATS for Epoch 4** : 
Average training loss: 0.0025
Average validation loss: 0.0556
Overfitting: 0.0532
Best model saved at epoch 4 with training loss: 0.0025
[Epoch 5, Batch 100] loss: 0.06659515551873482
[Epoch 5, Batch 200] loss: 0.05741409858688712
[Epoch 5, Batch 300] loss: 0.06282539473846555
[Epoch 5, Batch 400] loss: 0.06016389473574236
[Epoch 5, Batch 500] loss: 0.059271580756176265
[Epoch 5, Batch 600] loss: 0.05852596267708577
[Epoch 5, Batch 700] loss: 0.06579022978665307
[Epoch 5, Batch 800] loss: 0.06985775425098836
[Epoch 5, Batch 900] loss: 0.05454247444868088
[Epoch 5, Batch 1000] loss: 0.04786852553253993
[Epoch 5, Batch 1100] loss: 0.05657260774984024
[Epoch 5, Batch 1200] loss: 0.04811205049220007
[Epoch 5, Batch 1300] loss: 0.052804785550106315
[Epoch 5, Batch 1400] loss: 0.05911692679161206
[Epoch 5, Batch 1500] loss: 0.04988099162641447
[Epoch 5, Batch 1600] loss: 0.05708629546221346
[Epoch 5, Batch 1700] loss: 0.0557962328242138
[Epoch 5, Batch 1800] loss: 0.05137436260352843
**STATS for Epoch 5** : 
Average training loss: 0.0021
Average validation loss: 0.0578
Overfitting: 0.0556
Best model saved at epoch 5 with training loss: 0.0021
[Epoch 6, Batch 100] loss: 0.05779001150745899
[Epoch 6, Batch 200] loss: 0.05740859812358394
[Epoch 6, Batch 300] loss: 0.05409852412878536
[Epoch 6, Batch 400] loss: 0.051209329400444405
[Epoch 6, Batch 500] loss: 0.040543632484623233
[Epoch 6, Batch 600] loss: 0.05458165827614721
[Epoch 6, Batch 700] loss: 0.04450896889145952
[Epoch 6, Batch 800] loss: 0.051170791464392094
[Epoch 6, Batch 900] loss: 0.04734617505571805
[Epoch 6, Batch 1000] loss: 0.052672326994361356
[Epoch 6, Batch 1100] loss: 0.04907976086367853
[Epoch 6, Batch 1200] loss: 0.04439637740026228
[Epoch 6, Batch 1300] loss: 0.03847979394486174
[Epoch 6, Batch 1400] loss: 0.056218364669475704
[Epoch 6, Batch 1500] loss: 0.050448016619775445
[Epoch 6, Batch 1600] loss: 0.05164254866656847
[Epoch 6, Batch 1700] loss: 0.04372438478516415
[Epoch 6, Batch 1800] loss: 0.04657839826773852
**STATS for Epoch 6** : 
Average training loss: 0.0018
Average validation loss: 0.0439
Overfitting: 0.0422
Best model saved at epoch 6 with training loss: 0.0018
[Epoch 7, Batch 100] loss: 0.04526701759139542
[Epoch 7, Batch 200] loss: 0.03694745332701132
[Epoch 7, Batch 300] loss: 0.040150777359958735
[Epoch 7, Batch 400] loss: 0.043081802919041366
[Epoch 7, Batch 500] loss: 0.04776642166310921
[Epoch 7, Batch 600] loss: 0.0408491542225238
[Epoch 7, Batch 700] loss: 0.04404471866553649
[Epoch 7, Batch 800] loss: 0.03387616886408068
[Epoch 7, Batch 900] loss: 0.052964312392869035
[Epoch 7, Batch 1000] loss: 0.051362939114915206
[Epoch 7, Batch 1100] loss: 0.0322020830825204
[Epoch 7, Batch 1200] loss: 0.04756120310950791
[Epoch 7, Batch 1300] loss: 0.04877848267846275
[Epoch 7, Batch 1400] loss: 0.03411371522175614
[Epoch 7, Batch 1500] loss: 0.035396833546983544
[Epoch 7, Batch 1600] loss: 0.04331627697974909
[Epoch 7, Batch 1700] loss: 0.04000625533750281
[Epoch 7, Batch 1800] loss: 0.036338699404732326
**STATS for Epoch 7** : 
Average training loss: 0.0017
Average validation loss: 0.0520
Overfitting: 0.0503
Best model saved at epoch 7 with training loss: 0.0017
[Epoch 8, Batch 100] loss: 0.03615644565405091
[Epoch 8, Batch 200] loss: 0.03584839725983329
[Epoch 8, Batch 300] loss: 0.045314719600137325
[Epoch 8, Batch 400] loss: 0.03890600948710926
[Epoch 8, Batch 500] loss: 0.04505507611087523
[Epoch 8, Batch 600] loss: 0.028599845229182394
[Epoch 8, Batch 700] loss: 0.03746065290295519
[Epoch 8, Batch 800] loss: 0.03448034890345298
[Epoch 8, Batch 900] loss: 0.03578262223978527
[Epoch 8, Batch 1000] loss: 0.03228426032641437
[Epoch 8, Batch 1100] loss: 0.029736204888904466
[Epoch 8, Batch 1200] loss: 0.04801219045650214
[Epoch 8, Batch 1300] loss: 0.04434760289266706
[Epoch 8, Batch 1400] loss: 0.04301079660304822
[Epoch 8, Batch 1500] loss: 0.03983565589005593
[Epoch 8, Batch 1600] loss: 0.0385186748788692
[Epoch 8, Batch 1700] loss: 0.030368887038202955
[Epoch 8, Batch 1800] loss: 0.0317417340236716
**STATS for Epoch 8** : 
Average training loss: 0.0014
Average validation loss: 0.0477
Overfitting: 0.0462
Best model saved at epoch 8 with training loss: 0.0014
[Epoch 9, Batch 100] loss: 0.02968975134892389
[Epoch 9, Batch 200] loss: 0.03578453402296873
[Epoch 9, Batch 300] loss: 0.031643813074333595
[Epoch 9, Batch 400] loss: 0.03171839976042975
[Epoch 9, Batch 500] loss: 0.029568247284914834
[Epoch 9, Batch 600] loss: 0.029035805427120066
[Epoch 9, Batch 700] loss: 0.02382854595343815
[Epoch 9, Batch 800] loss: 0.02796390115021495
[Epoch 9, Batch 900] loss: 0.03376511726848548
[Epoch 9, Batch 1000] loss: 0.030660916687338613
[Epoch 9, Batch 1100] loss: 0.03537729152303655
[Epoch 9, Batch 1200] loss: 0.039921800500887915
[Epoch 9, Batch 1300] loss: 0.04443545215763152
[Epoch 9, Batch 1400] loss: 0.03356660196994198
[Epoch 9, Batch 1500] loss: 0.04140739453956485
[Epoch 9, Batch 1600] loss: 0.025164952654158697
[Epoch 9, Batch 1700] loss: 0.03798292156599928
[Epoch 9, Batch 1800] loss: 0.03812162845904823
**STATS for Epoch 9** : 
Average training loss: 0.0014
Average validation loss: 0.0406
Overfitting: 0.0391
Best model saved at epoch 9 with training loss: 0.0014
[Epoch 10, Batch 100] loss: 0.026376130967983046
[Epoch 10, Batch 200] loss: 0.021148338073980994
[Epoch 10, Batch 300] loss: 0.022672075155132917
[Epoch 10, Batch 400] loss: 0.030348448582808486
[Epoch 10, Batch 500] loss: 0.030159027334302663
[Epoch 10, Batch 600] loss: 0.03726216090028174
[Epoch 10, Batch 700] loss: 0.028404505727812647
[Epoch 10, Batch 800] loss: 0.03815059707092587
[Epoch 10, Batch 900] loss: 0.0306875202813535
[Epoch 10, Batch 1000] loss: 0.03671019278932363
[Epoch 10, Batch 1100] loss: 0.023845631789881735
[Epoch 10, Batch 1200] loss: 0.027708034305251202
[Epoch 10, Batch 1300] loss: 0.026112937625148335
[Epoch 10, Batch 1400] loss: 0.03568916330754291
[Epoch 10, Batch 1500] loss: 0.03386973606044194
[Epoch 10, Batch 1600] loss: 0.029442895131360274
[Epoch 10, Batch 1700] loss: 0.025806447220384145
[Epoch 10, Batch 1800] loss: 0.029776077931455803
**STATS for Epoch 10** : 
Average training loss: 0.0010
Average validation loss: 0.0388
Overfitting: 0.0378
Best model saved at epoch 10 with training loss: 0.0010
[Epoch 11, Batch 100] loss: 0.0212060283961182
[Epoch 11, Batch 200] loss: 0.026643930604914202
[Epoch 11, Batch 300] loss: 0.02569425248337211
[Epoch 11, Batch 400] loss: 0.03073852585919667
[Epoch 11, Batch 500] loss: 0.02520225582193234
[Epoch 11, Batch 600] loss: 0.02744674287678208
[Epoch 11, Batch 700] loss: 0.0245468046280439
[Epoch 11, Batch 800] loss: 0.03194143014057772
[Epoch 11, Batch 900] loss: 0.022258719938981812
[Epoch 11, Batch 1000] loss: 0.029717004733829527
[Epoch 11, Batch 1100] loss: 0.02298392713870271
[Epoch 11, Batch 1200] loss: 0.0186428848200012
[Epoch 11, Batch 1300] loss: 0.022921601073176135
[Epoch 11, Batch 1400] loss: 0.01923040499052149
[Epoch 11, Batch 1500] loss: 0.024305196442001034
[Epoch 11, Batch 1600] loss: 0.037360553331673145
[Epoch 11, Batch 1700] loss: 0.028523824609874283
[Epoch 11, Batch 1800] loss: 0.038126816993462855
**STATS for Epoch 11** : 
Average training loss: 0.0018
Average validation loss: 0.0397
Overfitting: 0.0379
[Epoch 12, Batch 100] loss: 0.01713423745793989
[Epoch 12, Batch 200] loss: 0.02312153245686204
[Epoch 12, Batch 300] loss: 0.020406912406324407
[Epoch 12, Batch 400] loss: 0.01656334170984337
[Epoch 12, Batch 500] loss: 0.0158982652251143
[Epoch 12, Batch 600] loss: 0.022290021715016338
[Epoch 12, Batch 700] loss: 0.018528086169826565
[Epoch 12, Batch 800] loss: 0.02389399300911464
[Epoch 12, Batch 900] loss: 0.02159608607631526
[Epoch 12, Batch 1000] loss: 0.023438413997500903
[Epoch 12, Batch 1100] loss: 0.017184729478467487
[Epoch 12, Batch 1200] loss: 0.032705964525302986
[Epoch 12, Batch 1300] loss: 0.031649877044837925
[Epoch 12, Batch 1400] loss: 0.02666727888648893
[Epoch 12, Batch 1500] loss: 0.020821414573438234
[Epoch 12, Batch 1600] loss: 0.022569603083538822
[Epoch 12, Batch 1700] loss: 0.03079315189126646
[Epoch 12, Batch 1800] loss: 0.03439898537653789
**STATS for Epoch 12** : 
Average training loss: 0.0010
Average validation loss: 0.0387
Overfitting: 0.0377
[Epoch 13, Batch 100] loss: 0.01844246759166708
[Epoch 13, Batch 200] loss: 0.020392509143275676
[Epoch 13, Batch 300] loss: 0.031419221913965886
[Epoch 13, Batch 400] loss: 0.01977468597193365
[Epoch 13, Batch 500] loss: 0.018803706396429334
[Epoch 13, Batch 600] loss: 0.019430433096131308
[Epoch 13, Batch 700] loss: 0.024696471922070487
[Epoch 13, Batch 800] loss: 0.01352396975737065
[Epoch 13, Batch 900] loss: 0.018403584089828656
[Epoch 13, Batch 1000] loss: 0.022988982734968886
[Epoch 13, Batch 1100] loss: 0.016003071802842897
[Epoch 13, Batch 1200] loss: 0.021737420357603697
[Epoch 13, Batch 1300] loss: 0.02205415199001436
[Epoch 13, Batch 1400] loss: 0.022230291964297065
[Epoch 13, Batch 1500] loss: 0.029718170189007652
[Epoch 13, Batch 1600] loss: 0.01970375202217838
[Epoch 13, Batch 1700] loss: 0.018863257457123837
[Epoch 13, Batch 1800] loss: 0.021436677817982853
**STATS for Epoch 13** : 
Average training loss: 0.0009
Average validation loss: 0.0465
Overfitting: 0.0457
Best model saved at epoch 13 with training loss: 0.0009
[Epoch 14, Batch 100] loss: 0.019708705495286267
[Epoch 14, Batch 200] loss: 0.019373459656198976
[Epoch 14, Batch 300] loss: 0.01945829036849318
[Epoch 14, Batch 400] loss: 0.02428306997710024
[Epoch 14, Batch 500] loss: 0.016411267736621084
[Epoch 14, Batch 600] loss: 0.021502068736735963
[Epoch 14, Batch 700] loss: 0.01418497675433173
[Epoch 14, Batch 800] loss: 0.010284149524231907
[Epoch 14, Batch 900] loss: 0.020583621720870724
[Epoch 14, Batch 1000] loss: 0.029319259959738702
[Epoch 14, Batch 1100] loss: 0.020950379825080745
[Epoch 14, Batch 1200] loss: 0.023275761880358913
[Epoch 14, Batch 1300] loss: 0.021196559900345163
[Epoch 14, Batch 1400] loss: 0.01865409085577994
[Epoch 14, Batch 1500] loss: 0.020143790309666655
[Epoch 14, Batch 1600] loss: 0.02443727411897271
[Epoch 14, Batch 1700] loss: 0.016453002905254834
[Epoch 14, Batch 1800] loss: 0.016882590493769386
**STATS for Epoch 14** : 
Average training loss: 0.0009
Average validation loss: 0.0396
Overfitting: 0.0387
[Epoch 15, Batch 100] loss: 0.015531817113587748
[Epoch 15, Batch 200] loss: 0.017177087199961534
[Epoch 15, Batch 300] loss: 0.014292643061489798
[Epoch 15, Batch 400] loss: 0.02411976223658712
[Epoch 15, Batch 500] loss: 0.015843879588901474
[Epoch 15, Batch 600] loss: 0.018173312935759897
[Epoch 15, Batch 700] loss: 0.014276778583880514
[Epoch 15, Batch 800] loss: 0.025265051599999425
[Epoch 15, Batch 900] loss: 0.012715647896184236
[Epoch 15, Batch 1000] loss: 0.0130813135067001
[Epoch 15, Batch 1100] loss: 0.02181250356414239
[Epoch 15, Batch 1200] loss: 0.02214253063662909
[Epoch 15, Batch 1300] loss: 0.01889836583788565
[Epoch 15, Batch 1400] loss: 0.017758822069881715
[Epoch 15, Batch 1500] loss: 0.013768838126852643
[Epoch 15, Batch 1600] loss: 0.012108955003350274
[Epoch 15, Batch 1700] loss: 0.015784135538415286
[Epoch 15, Batch 1800] loss: 0.012174791560901212
**STATS for Epoch 15** : 
Average training loss: 0.0007
Average validation loss: 0.0398
Overfitting: 0.0391
Best model saved at epoch 15 with training loss: 0.0007
[Epoch 16, Batch 100] loss: 0.010349909873111756
[Epoch 16, Batch 200] loss: 0.013979421392650692
[Epoch 16, Batch 300] loss: 0.014605414305442536
[Epoch 16, Batch 400] loss: 0.015659397679264657
[Epoch 16, Batch 500] loss: 0.0208761533589859
[Epoch 16, Batch 600] loss: 0.015107134883292019
[Epoch 16, Batch 700] loss: 0.011230751910625258
[Epoch 16, Batch 800] loss: 0.012711328372533899
[Epoch 16, Batch 900] loss: 0.02537584376612358
[Epoch 16, Batch 1000] loss: 0.014083379170187982
[Epoch 16, Batch 1100] loss: 0.021040336941805435
[Epoch 16, Batch 1200] loss: 0.018268967952317326
[Epoch 16, Batch 1300] loss: 0.01779655893697054
[Epoch 16, Batch 1400] loss: 0.014777679485996486
[Epoch 16, Batch 1500] loss: 0.020258391234019655
[Epoch 16, Batch 1600] loss: 0.012501873280016298
[Epoch 16, Batch 1700] loss: 0.0209062732593884
[Epoch 16, Batch 1800] loss: 0.016421806654470857
**STATS for Epoch 16** : 
Average training loss: 0.0007
Average validation loss: 0.0380
Overfitting: 0.0373
Best model saved at epoch 16 with training loss: 0.0007
[Epoch 17, Batch 100] loss: 0.01100762237168965
[Epoch 17, Batch 200] loss: 0.01217918516784266
[Epoch 17, Batch 300] loss: 0.014487650269002188
[Epoch 17, Batch 400] loss: 0.00878399154637009
[Epoch 17, Batch 500] loss: 0.02154698714162805
[Epoch 17, Batch 600] loss: 0.01242797311177128
[Epoch 17, Batch 700] loss: 0.014993125468463405
[Epoch 17, Batch 800] loss: 0.011043687771561964
[Epoch 17, Batch 900] loss: 0.017002071813694782
[Epoch 17, Batch 1000] loss: 0.01074343226318888
[Epoch 17, Batch 1100] loss: 0.01202795181026886
[Epoch 17, Batch 1200] loss: 0.013329960423670855
[Epoch 17, Batch 1300] loss: 0.018980381448345726
[Epoch 17, Batch 1400] loss: 0.016992041692938074
[Epoch 17, Batch 1500] loss: 0.008050189317873446
[Epoch 17, Batch 1600] loss: 0.020430556060091476
[Epoch 17, Batch 1700] loss: 0.011671964254783234
[Epoch 17, Batch 1800] loss: 0.011760752938207587
**STATS for Epoch 17** : 
Average training loss: 0.0006
Average validation loss: 0.0389
Overfitting: 0.0384
Best model saved at epoch 17 with training loss: 0.0006
[Epoch 18, Batch 100] loss: 0.012901088696162332
[Epoch 18, Batch 200] loss: 0.011403758430824383
[Epoch 18, Batch 300] loss: 0.011068242016335716
[Epoch 18, Batch 400] loss: 0.009160412230703513
[Epoch 18, Batch 500] loss: 0.010820139281604498
[Epoch 18, Batch 600] loss: 0.013085976521178964
[Epoch 18, Batch 700] loss: 0.007821757264100598
[Epoch 18, Batch 800] loss: 0.009017285985373746
[Epoch 18, Batch 900] loss: 0.011010177188763919
[Epoch 18, Batch 1000] loss: 0.014184808025329404
[Epoch 18, Batch 1100] loss: 0.017432335204066476
[Epoch 18, Batch 1200] loss: 0.013572410542983561
[Epoch 18, Batch 1300] loss: 0.014518990455326276
[Epoch 18, Batch 1400] loss: 0.011403068535364581
[Epoch 18, Batch 1500] loss: 0.019715268497511717
[Epoch 18, Batch 1600] loss: 0.01511396388972571
[Epoch 18, Batch 1700] loss: 0.014992580410034862
[Epoch 18, Batch 1800] loss: 0.011636239102135732
**STATS for Epoch 18** : 
Average training loss: 0.0003
Average validation loss: 0.0414
Overfitting: 0.0411
Best model saved at epoch 18 with training loss: 0.0003
[Epoch 19, Batch 100] loss: 0.005968591730234039
[Epoch 19, Batch 200] loss: 0.013647874651651364
[Epoch 19, Batch 300] loss: 0.006927597645189962
[Epoch 19, Batch 400] loss: 0.006897493405122077
[Epoch 19, Batch 500] loss: 0.0101053821982714
[Epoch 19, Batch 600] loss: 0.008186280017780519
[Epoch 19, Batch 700] loss: 0.007145643260073485
[Epoch 19, Batch 800] loss: 0.010758657092083013
[Epoch 19, Batch 900] loss: 0.019165714185764956
[Epoch 19, Batch 1000] loss: 0.011799140559487569
[Epoch 19, Batch 1100] loss: 0.00852159768823185
[Epoch 19, Batch 1200] loss: 0.011796143735009536
[Epoch 19, Batch 1300] loss: 0.01294841185954283
[Epoch 19, Batch 1400] loss: 0.010938544506188919
[Epoch 19, Batch 1500] loss: 0.014263330442008736
[Epoch 19, Batch 1600] loss: 0.016591481086379645
[Epoch 19, Batch 1700] loss: 0.010301509803703084
[Epoch 19, Batch 1800] loss: 0.007946190154689248
**STATS for Epoch 19** : 
Average training loss: 0.0006
Average validation loss: 0.0390
Overfitting: 0.0384
[Epoch 20, Batch 100] loss: 0.010257760394706565
[Epoch 20, Batch 200] loss: 0.01053647575652576
[Epoch 20, Batch 300] loss: 0.012146611468961056
[Epoch 20, Batch 400] loss: 0.008756676725752185
[Epoch 20, Batch 500] loss: 0.008420341513265157
[Epoch 20, Batch 600] loss: 0.012146576758586889
[Epoch 20, Batch 700] loss: 0.007671197685813241
[Epoch 20, Batch 800] loss: 0.008059348201531974
[Epoch 20, Batch 900] loss: 0.00803018303546196
[Epoch 20, Batch 1000] loss: 0.01320804315724672
[Epoch 20, Batch 1100] loss: 0.009865426651158487
[Epoch 20, Batch 1200] loss: 0.01290335926853004
[Epoch 20, Batch 1300] loss: 0.010747067191550741
[Epoch 20, Batch 1400] loss: 0.007235148865984229
[Epoch 20, Batch 1500] loss: 0.013300294844511881
[Epoch 20, Batch 1600] loss: 0.008916954817177612
[Epoch 20, Batch 1700] loss: 0.014140109340369236
[Epoch 20, Batch 1800] loss: 0.015294728505559761
**STATS for Epoch 20** : 
Average training loss: 0.0005
Average validation loss: 0.0424
Overfitting: 0.0419
[Epoch 21, Batch 100] loss: 0.005788183751737961
[Epoch 21, Batch 200] loss: 0.008655791156415944
[Epoch 21, Batch 300] loss: 0.006499559355870588
[Epoch 21, Batch 400] loss: 0.006302763907497138
[Epoch 21, Batch 500] loss: 0.006657624843173835
[Epoch 21, Batch 600] loss: 0.008424295680724754
[Epoch 21, Batch 700] loss: 0.019194942706208168
[Epoch 21, Batch 800] loss: 0.01111332058759217
[Epoch 21, Batch 900] loss: 0.006242496733466396
[Epoch 21, Batch 1000] loss: 0.006573432684363069
[Epoch 21, Batch 1100] loss: 0.007576102098159936
[Epoch 21, Batch 1200] loss: 0.010037196168432273
[Epoch 21, Batch 1300] loss: 0.0053201244226966085
[Epoch 21, Batch 1400] loss: 0.005375309070295771
[Epoch 21, Batch 1500] loss: 0.009071247672163735
[Epoch 21, Batch 1600] loss: 0.010622277260881673
[Epoch 21, Batch 1700] loss: 0.015009766426992428
[Epoch 21, Batch 1800] loss: 0.012822266647799552
**STATS for Epoch 21** : 
Average training loss: 0.0003
Average validation loss: 0.0396
Overfitting: 0.0392
[Epoch 22, Batch 100] loss: 0.007649175820283745
[Epoch 22, Batch 200] loss: 0.012472749763546745
[Epoch 22, Batch 300] loss: 0.005286301584183093
[Epoch 22, Batch 400] loss: 0.008344644113203686
[Epoch 22, Batch 500] loss: 0.005479022108920617
[Epoch 22, Batch 600] loss: 0.005573031328385696
[Epoch 22, Batch 700] loss: 0.007635765187515063
[Epoch 22, Batch 800] loss: 0.008067073657639413
[Epoch 22, Batch 900] loss: 0.008652731983165723
[Epoch 22, Batch 1000] loss: 0.008476266562965976
[Epoch 22, Batch 1100] loss: 0.013993677930820923
[Epoch 22, Batch 1200] loss: 0.007516975382268356
[Epoch 22, Batch 1300] loss: 0.009300555225345307
[Epoch 22, Batch 1400] loss: 0.009986671236838447
[Epoch 22, Batch 1500] loss: 0.011994479502645846
[Epoch 22, Batch 1600] loss: 0.0066992190992277755
[Epoch 22, Batch 1700] loss: 0.007142546186196341
[Epoch 22, Batch 1800] loss: 0.007167756256176289
**STATS for Epoch 22** : 
Average training loss: 0.0003
Average validation loss: 0.0408
Overfitting: 0.0405
[Epoch 23, Batch 100] loss: 0.005883704576910986
[Epoch 23, Batch 200] loss: 0.008804287984930851
[Epoch 23, Batch 300] loss: 0.005417339706609709
[Epoch 23, Batch 400] loss: 0.008525030240762135
[Epoch 23, Batch 500] loss: 0.007889105597560047
[Epoch 23, Batch 600] loss: 0.005867293705268822
[Epoch 23, Batch 700] loss: 0.005435952402904149
[Epoch 23, Batch 800] loss: 0.010927306914854853
[Epoch 23, Batch 900] loss: 0.0051517717799833915
[Epoch 23, Batch 1000] loss: 0.006137995532335481
[Epoch 23, Batch 1100] loss: 0.007256680625159788
[Epoch 23, Batch 1200] loss: 0.006581601037960354
[Epoch 23, Batch 1300] loss: 0.006501585750684171
[Epoch 23, Batch 1400] loss: 0.006020585986207152
[Epoch 23, Batch 1500] loss: 0.008896262491198285
[Epoch 23, Batch 1600] loss: 0.008345988154833322
[Epoch 23, Batch 1700] loss: 0.005332194641605384
[Epoch 23, Batch 1800] loss: 0.010455900531651423
**STATS for Epoch 23** : 
Average training loss: 0.0005
Average validation loss: 0.0467
Overfitting: 0.0461
[Epoch 24, Batch 100] loss: 0.011646733495108492
[Epoch 24, Batch 200] loss: 0.007368296935965191
[Epoch 24, Batch 300] loss: 0.006755406836437033
[Epoch 24, Batch 400] loss: 0.006453701322061534
[Epoch 24, Batch 500] loss: 0.009200610969419359
[Epoch 24, Batch 600] loss: 0.00750669873280458
[Epoch 24, Batch 700] loss: 0.007013139429018338
[Epoch 24, Batch 800] loss: 0.008461668375275622
[Epoch 24, Batch 900] loss: 0.0033997531038312445
[Epoch 24, Batch 1000] loss: 0.004825675099982618
[Epoch 24, Batch 1100] loss: 0.006665221993225714
[Epoch 24, Batch 1200] loss: 0.005469880257805926
[Epoch 24, Batch 1300] loss: 0.005257544593951025
[Epoch 24, Batch 1400] loss: 0.004447696596816968
[Epoch 24, Batch 1500] loss: 0.004698012624803596
[Epoch 24, Batch 1600] loss: 0.0035719415401445076
[Epoch 24, Batch 1700] loss: 0.011040491424355424
[Epoch 24, Batch 1800] loss: 0.004712424276085585
**STATS for Epoch 24** : 
Average training loss: 0.0002
Average validation loss: 0.0409
Overfitting: 0.0407
Best model saved at epoch 24 with training loss: 0.0002
qt.qpa.xcb: X server does not support XInput 2
+++FINAL STATS++++
Training Loss 0.00015614199764483298
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 32} on final Test set to find Test loss for overfitting
 Testing loss : 0.0409
Calculated Overfitting : 0.0407
Using best hyperparameters {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 32} on final Test set with testing set size : 10000
Test set accuracy with best hyperparameters: 0.9865
Total time taken for hyperparameter tuning and evaluation: 4:24:56
/home/ahussain/PycharmProjects/optunaNew/custom_early_stopping.py:497: ExperimentalWarning:

plot_timeline is experimental (supported from v3.2.0). The interface can change in the future.


Process finished with exit code 0

